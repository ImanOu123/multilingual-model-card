{'en': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'ar': 'مقارنة النماذج اللغوية القائمة على المحولات للمشاعر العربية والكشف عن السخرية', 'es': 'Evaluación comparativa de modelos de lenguaje basados en transformadores para la detección del sentimiento árabe y el sarcasmo', 'fr': 'Analyse comparative des modèles de langage basés sur les transformateurs pour la détection du sentiment et du sarcasme en arabe', 'pt': 'Benchmarking de modelos de linguagem baseados em transformador para detecção de sentimento e sarcasmo em árabe', 'ja': 'アラビア語感情と皮肉検出のためのベンチマーク変換ベースの言語モデル', 'zh': '试于转换器言,阿拉伯语情刺检', 'hi': 'अरबी भावना और व्यंग्य का पता लगाने के लिए बेंचमार्किंग ट्रांसफॉर्मर-आधारित भाषा मॉडल', 'ru': 'Сравнительный анализ языковых моделей на основе трансформаторов для обнаружения арабских чувств и сарказма', 'ga': 'Tagarmharcáil Múnlaí Teanga Bunaithe ar Chlaochladán le haghaidh Meon Araibise agus Brath Sarcasm', 'ka': 'Name', 'hu': 'Transzformátor alapú nyelvi modellek összehasonlítása arab érzés és szarkazmus felismeréséhez', 'kk': 'Араб синтиментті және саркассм анықтау үшін белгілеу түрлендіруші тіл үлгілері', 'el': 'Αξιολόγηση γλωσσικών μοντέλων βασισμένων στον μετασχηματιστή για την ανίχνευση αραβικών συναισθημάτων και σαρκασμού', 'mk': 'Споредбено обележување на јазичните модели базирани на трансформи за арапско чувство и детекција на сарказам', 'ms': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'ml': 'അറബി സെന്റിമെന്റിനും സര്\u200dക്കാസം ഡിറ്റീഷനുമായി പരിശോധിക്കുന്ന ഭാഷ മോഡലുകള്\u200d ബെന്\u200dമെങ്കിങ്ങി', 'mt': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'no': 'Comment', 'mn': 'Араб мэдрэмжтэй болон саркассмын нээлттэй хэл загваруудын төвөгтэй шилжүүлэгч төвөгтэй хэл загварууд', 'pl': 'Porównywanie modeli językowych opartych na transformatorze dla wykrywania arabskich sentymentów i sarkazmu', 'sr': 'Pregledni modeli jezika na transformatoru za otkrivanje sentimenta i sarkasma', 'ro': 'Benchmarking modele lingvistice bazate pe transformatori pentru detectarea sentimentelor arabe și sarcasmului', 'so': 'Benchmarking Models of Language-based Transforms for Sentiment and Sarcasm', 'it': 'Benchmarking di modelli linguistici basati su trasformatori per il rilevamento del sentimento arabo e del sarcasmo', 'lt': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'si': 'Name', 'ta': 'அரபி உணர்வு மற்றும் Sarcasm கண்டுபிடிப்பு', 'sv': 'Benchmarking av transformatorbaserade språkmodeller för arabisk känsla och sarkasm detektering', 'ur': 'ابریبی سنٹیمینٹ اور سارکاسم اچانک کے لئے بنچم مارکینگ ترنسفور بنیادی زبان موڈل', 'uz': 'Language Models for Arab Sentiment and Sarcasm detection', 'vi': 'Chế độ biến hình cho giọng nói Ả Rập và trinh sát', 'da': 'Benchmarking Transformer-baserede sprogmodeller til arabisk følelse og sarkasme detektion', 'hr': 'Modeli jezika na temelju transformatora za otkrivanje sentimenta i sarkasma', 'bg': 'Базирани на трансформатори езикови модели за откриване на арабски сентименти и сарказъм', 'nl': 'Benchmarking Transformer-gebaseerde taalmodellen voor Arabische gevoelens en sarcasme detectie', 'ko': 'Transformer의 아랍어 감정과 풍자를 바탕으로 언어 모델을 측정하는 기준 테스트', 'de': 'Benchmarking Transformer-basierte Sprachmodelle für die Erkennung arabischer Gefühle und Sarkasmus', 'id': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'fa': 'Name', 'sw': 'Mradi wa Lugha za Kiarabu na Uchunguzi wa Kiarabu', 'tr': 'Arabça Sentiýat we Sarkasm Deteksi üçin terjime edip görkezilen Diller', 'sq': 'Paraqitja e modeleve gjuhësore me bazë në Transformer për ndjenjat arabe dhe zbulimin e sarkazmit', 'hy': 'Արաբական զգացմունքների և Սարկազմի հայտնաբերման լեզվային մոդելների համեմատությունը', 'bn': 'আরবী সেন্টিমেন্ট এবং সার্কাম ডিটেক্টরের জন্য অনুবাদ ভিত্তিক ভিত্তিক ভাষা মোডেল', 'af': 'Name', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'bs': 'Pregledni modeli jezika na transformatoru za otkrivanje sentimenta i sarkasma', 'et': 'Transformeritel põhinevad keelemudelid araabia sentimentide ja sarkasmi tuvastamiseks', 'cs': 'Srovnávací modely jazyka založené na transformátoru pro detekci arabských sentimentů a sarkasmu', 'az': 'Arapça Sentiment və Sarkasm Gedişatları üçün Benchmarking Transformer tabanlı Dil Modelləri', 'ca': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'fi': 'Muuntajapohjaiset kielimallit arabian tunteiden ja sarkasmin havaitsemiseen', 'sk': 'Primerjalna analiza jezikovnih modelov na podlagi transformatorjev za zaznavanje arabskih sentimentov in sarkazma', 'jv': 'Bench-marking Transformer-basa Language Modes kanggo Sentiment lan Sarkasm detection', 'bo': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection', 'ha': 'KCharselect unicode block name', 'he': 'Benchmarking Transformer-based Language Models for Arabic Sentiment and Sarcasm Detection'}
{'en': 'The introduction of transformer-based language models has been a revolutionary step for natural language processing (NLP) research. These models, such as BERT, GPT and ELECTRA, led to state-of-the-art performance in many NLP tasks. Most of these models were initially developed for English and other languages followed later. Recently, several Arabic-specific models started emerging. However, there are limited direct comparisons between these models. In this paper, we evaluate the performance of 24 of these models on Arabic sentiment and sarcasm detection. Our results show that the models achieving the best performance are those that are trained on only Arabic data, including dialectal Arabic, and use a larger number of parameters, such as the recently released MARBERT. However, we noticed that AraELECTRA is one of the top performing models while being much more efficient in its computational cost. Finally, the experiments on AraGPT2 variants showed low performance compared to BERT models, which indicates that it might not be suitable for classification tasks.', 'fr': "L'introduction de modèles de langage basés sur des transformateurs a été une étape révolutionnaire pour la recherche sur le traitement du langage naturel (NLP). Ces modèles, tels que BERT, GPT et ELECTRA, ont permis d'obtenir des performances de pointe dans de nombreuses tâches de PNL. La plupart de ces modèles ont été initialement développés pour l'anglais et d'autres langues ont été suivies plus tard. Récemment, plusieurs modèles spécifiques à l'arabe ont commencé à émerger. Toutefois, il existe peu de comparaisons directes entre ces modèles. Dans cet article, nous évaluons la performance de 24 de ces modèles sur la détection du sentiment et du sarcasme en arabe. Nos résultats montrent que les modèles qui obtiennent les meilleures performances sont ceux qui sont formés uniquement sur des données arabes, y compris l'arabe dialectal, et utilisent un plus grand nombre de paramètres, comme le MARBERT récemment publié. Cependant, nous avons remarqué qu'AraElectra est l'un des modèles les plus performants tout en étant beaucoup plus efficace en termes de coût de calcul. Enfin, les expériences sur les variants arAGPT2 ont montré de faibles performances par rapport aux modèles BERT, ce qui indique qu'il pourrait ne pas être adapté aux tâches de classification.", 'ar': 'كان إدخال نماذج اللغة القائمة على المحولات خطوة ثورية لأبحاث معالجة اللغة الطبيعية (NLP). أدت هذه النماذج ، مثل BERT و GPT و ELECTRA ، إلى أداء متطور في العديد من مهام البرمجة اللغوية العصبية. تم تطوير معظم هذه النماذج مبدئيًا للغة الإنجليزية ولغات أخرى تم اتباعها لاحقًا. في الآونة الأخيرة ، بدأت تظهر عدة نماذج خاصة بالعربية. ومع ذلك ، هناك مقارنات مباشرة محدودة بين هذه النماذج. في هذا البحث قمنا بتقييم أداء 24 من هذه النماذج على المشاعر العربية وكشف السخرية. تظهر نتائجنا أن النماذج التي تحقق أفضل أداء هي تلك التي يتم تدريبها على البيانات العربية فقط ، بما في ذلك اللغة العربية اللهجة ، وتستخدم عددًا أكبر من المعلمات ، مثل MARBERT الذي تم إصداره مؤخرًا. ومع ذلك ، لاحظنا أن AraELECTRA هو أحد أفضل النماذج أداءً بينما يكون أكثر كفاءة في التكلفة الحسابية. أخيرًا ، أظهرت التجارب على متغيرات AraGPT2 أداءً منخفضًا مقارنة بنماذج BERT ، مما يشير إلى أنها قد لا تكون مناسبة لمهام التصنيف.', 'pt': 'A introdução de modelos de linguagem baseados em transformadores foi um passo revolucionário para a pesquisa de processamento de linguagem natural (PLN). Esses modelos, como BERT, GPT e ELECTRA, levaram a um desempenho de ponta em muitas tarefas de PNL. A maioria desses modelos foi desenvolvida inicialmente para o inglês e outros idiomas seguiram posteriormente. Recentemente, vários modelos específicos para o árabe começaram a surgir. No entanto, existem comparações diretas limitadas entre esses modelos. Neste artigo, avaliamos o desempenho de 24 desses modelos no sentimento árabe e na detecção de sarcasmo. Nossos resultados mostram que os modelos que alcançam o melhor desempenho são aqueles que são treinados apenas em dados árabes, incluindo árabe dialetal, e usam um número maior de parâmetros, como o recém-lançado MARBERT. No entanto, notamos que o AraELECTRA é um dos modelos de melhor desempenho, sendo muito mais eficiente em seu custo computacional. Por fim, os experimentos com variantes AraGPT2 mostraram baixo desempenho em comparação com os modelos BERT, o que indica que pode não ser adequado para tarefas de classificação.', 'ja': '変圧器ベースの言語モデルの導入は、自然言語処理（ ＮＬＰ ）研究にとって画期的なステップであった。 BERT、GPT、ELECTRAなどのこれらのモデルは、多くのNLPタスクで最先端のパフォーマンスにつながりました。 これらのモデルのほとんどは、当初は英語やその他の言語のために開発され、後にそれに続いた。 最近、いくつかのアラビア語専用モデルが登場し始めた。 しかし、これらのモデル間の直接的な比較は限られている。 本稿では，これらのモデルのうち，アラビア語の感情と皮肉の検出に関する24のパフォーマンスを評価する． 私たちの結果は、最高のパフォーマンスを達成したモデルは、方言アラビア語を含むアラビア語データのみでトレーニングされ、最近リリースされたMARBERTなどのより多くのパラメータを使用しているモデルであることを示しています。 しかし、AraELECTRAは計算コストがはるかに効率的でありながら、最高のパフォーマンスを発揮するモデルの1つであることに気づきました。 最後に、ＡｒａＧＰＴ ２変異体の実験は、ＢＥＲＴモデルと比較して低い性能を示し、これは、分類タスクに適していない可能性があることを示した。', 'es': 'La introducción de modelos de lenguaje basados en transformadores ha sido un paso revolucionario para la investigación del procesamiento del lenguaje natural (NLP). Estos modelos, como BERT, GPT y ELECTRA, dieron lugar a un rendimiento de vanguardia en muchas tareas de PNL. La mayoría de estos modelos se desarrollaron inicialmente para el inglés y otros idiomas, seguidos más tarde. Recientemente, comenzaron a surgir varios modelos específicos para el árabe. Sin embargo, existen comparaciones directas limitadas entre estos modelos. En este artículo, evaluamos el desempeño de 24 de estos modelos en la detección del sentimiento árabe y el sarcasmo. Nuestros resultados muestran que los modelos que obtienen el mejor rendimiento son aquellos que se entrenan solo con datos árabes, incluido el árabe dialectal, y utilizan un mayor número de parámetros, como el recientemente publicado MARBERT. Sin embargo, nos dimos cuenta de que AraElectra es uno de los modelos de mejor rendimiento, a la vez que es mucho más eficiente en su costo computacional. Por último, los experimentos con variantes de AraGPT2 mostraron un rendimiento bajo en comparación con los modelos BERT, lo que indica que podría no ser adecuado para tareas de clasificación.', 'ru': 'Внедрение языковых моделей на основе трансформаторов стало революционным шагом в исследованиях в области обработки естественного языка (NLP). Эти модели, такие как BERT, GPT и ELECTRA, привели к современной производительности во многих задачах NLP. Большинство из этих моделей были первоначально разработаны для английского и других языков, а затем. В последнее время начали появляться несколько моделей, специфичных для арабского мира. Однако между этими моделями существует ограниченное число прямых сопоставлений. В этой статье мы оцениваем эффективность 24 из этих моделей по арабским настроениям и обнаружению сарказма. Наши результаты показывают, что модели, достигшие наилучшей производительности, являются теми, которые обучены только арабским данным, включая диалектный арабский, и используют большее количество параметров, таких как недавно выпущенный MARBERT. Тем не менее, мы заметили, что AraELECTRA является одной из самых производительных моделей, в то время как она гораздо более эффективна в своих вычислительных затратах. Наконец, эксперименты над вариантами AraGPT2 показали низкую производительность по сравнению с моделями BERT, что указывает на то, что они могут не подходить для задач классификации.', 'zh': '盖转换器言模者,自然语言理(NLP)治之革命性也。 若BERT,GPT与ELECTRA,NLP事有先进之性。 其初为英语及语言,后复见。 近者,阿拉伯语式始见。 然此间直较有限。 于本文中,估其24形于阿拉伯情刺检。 吾之的结果表明,获得最佳性者,唯用阿拉伯语数(阿拉伯语方言)习而用大参数者,近出MARBERT也。 然留意于AraELECTRA,性最佳者,计算成本高效多矣。 终于AraGPT2变体之实验,比于BERT,性能下,明其或非其任也。', 'hi': 'ट्रांसफॉर्मर-आधारित भाषा मॉडल की शुरुआत प्राकृतिक भाषा प्रसंस्करण (एनएलपी) अनुसंधान के लिए एक क्रांतिकारी कदम रहा है। इन मॉडलों, जैसे BERT, GPT और ELECTRA, ने कई NLP कार्यों में अत्याधुनिक प्रदर्शन का नेतृत्व किया। इनमें से अधिकांश मॉडल शुरू में अंग्रेजी और बाद में अनुसरण की जाने वाली अन्य भाषाओं के लिए विकसित किए गए थे। हाल ही में, कई अरबी-विशिष्ट मॉडल उभरने लगे। हालांकि, इन मॉडलों के बीच सीमित प्रत्यक्ष तुलनाएं हैं। इस पेपर में, हम अरबी भावना और व्यंग्य का पता लगाने पर इन मॉडलों में से 24 के प्रदर्शन का मूल्यांकन करते हैं। हमारे परिणाम बताते हैं कि सबसे अच्छा प्रदर्शन प्राप्त करने वाले मॉडल वे हैं जो केवल अरबी डेटा पर प्रशिक्षित होते हैं, जिसमें बोलचाल अरबी भी शामिल है, और हाल ही में जारी किए गए MARBERT जैसे मापदंडों की एक बड़ी संख्या का उपयोग करते हैं। हालांकि, हमने देखा कि AraELECTRA शीर्ष प्रदर्शन करने वाले मॉडलों में से एक है, जबकि इसकी कम्प्यूटेशनल लागत में बहुत अधिक कुशल है। अंत में, AraGPT2 वेरिएंट पर प्रयोगों ने BERT मॉडल की तुलना में कम प्रदर्शन दिखाया, जो इंगित करता है कि यह वर्गीकरण कार्यों के लिए उपयुक्त नहीं हो सकता है।', 'ga': 'Ba chéim réabhlóideach é tabhairt isteach samhlacha teanga atá bunaithe ar chlaochladán le haghaidh taighde ar phróiseáil teanga nádúrtha (NLP). Mar thoradh ar na samhlacha seo, mar BERT, GPT agus ELECTRA, bhí feidhmíocht úrscothach i go leor tascanna NLP. Forbraíodh an chuid is mó de na múnlaí seo ar dtús don Bhéarla agus do theangacha eile ina dhiaidh sin. Le déanaí, thosaigh roinnt samhlacha a bhaineann go sonrach le hAraibis ag teacht chun cinn. Mar sin féin, tá comparáidí díreacha teoranta idir na samhlacha seo. Sa pháipéar seo, déanaimid measúnú ar fheidhmíocht 24 de na samhlacha seo maidir le meon Araibis agus braite searbhas. Léiríonn ár dtorthaí gurb iad na samhlacha a bhaineann an fheidhmíocht is fearr amach iad siúd atá oilte ar shonraí Araibis amháin, lena n-áirítear Araibis chanúinteach, agus a úsáideann líon níos mó paraiméadair, mar shampla MARBERT a eisíodh le déanaí. Mar sin féin, thugamar faoi deara go bhfuil AraELECTRA ar cheann de na samhlacha is fearr feidhmíochta agus é i bhfad níos éifeachtaí ó thaobh costais ríomhaireachta de. Ar deireadh, léirigh na turgnaimh ar leagan AraGPT2 feidhmíocht íseal i gcomparáid le samhlacha BERT, rud a léiríonn go bhféadfadh sé nach mbeadh sé oiriúnach do thascanna aicmithe.', 'hu': 'A transzformátor alapú nyelvmodellek bevezetése forradalmi lépést jelentett a természetes nyelvfeldolgozás (NLP) kutatásában. Ezek a modellek, mint például a BERT, a GPT és az ELECTRA, a legkorszerűbb teljesítményt eredményeztek számos NLP feladatban. A legtöbb ilyen modellt eredetileg angol nyelvre fejlesztették ki, majd később más nyelveket követtek. A közelmúltban számos arab specifikus modell kezdett kialakulni. Ezen modellek között azonban korlátozott mértékű közvetlen összehasonlítás áll rendelkezésre. Ebben a tanulmányban 24 ilyen modell teljesítményét értékeljük az arab érzelmek és a szarkazmus felismerése terén. Eredményeink azt mutatják, hogy a legjobb teljesítményt elérő modellek azok, amelyek kizárólag arab adatokra képeznek, beleértve a dialektális arabot is, és nagyobb számú paramétert használnak, mint például a nemrégiben kiadott MARBERT. Azonban észrevettük, hogy az AraELECTRA az egyik legjobb teljesítményű modell, miközben sokkal hatékonyabb a számítási költségeiben. Végül az AraGPT2 változatokon végzett kísérletek alacsony teljesítményt mutattak a BERT modellekhez képest, ami azt jelzi, hogy nem alkalmas osztályozási feladatokra.', 'el': 'Η εισαγωγή γλωσσικών μοντέλων βασισμένων σε μετασχηματιστές υπήρξε ένα επαναστατικό βήμα για την έρευνα επεξεργασίας φυσικής γλώσσας (ΝΛΠ). Αυτά τα μοντέλα, όπως η BERT, η GPT και η ELECTRA, οδήγησαν σε υπερσύγχρονες επιδόσεις σε πολλές εργασίες NLP. Τα περισσότερα από αυτά τα μοντέλα αναπτύχθηκαν αρχικά για τα αγγλικά και άλλες γλώσσες ακολούθησαν αργότερα. Πρόσφατα, άρχισαν να αναδύονται διάφορα αραβικά μοντέλα. Ωστόσο, υπάρχουν περιορισμένες άμεσες συγκρίσεις μεταξύ αυτών των μοντέλων. Στην παρούσα εργασία αξιολογούμε την απόδοση των 24 αυτών μοντέλων στην ανίχνευση αραβικών συναισθημάτων και σαρκασμού. Τα αποτελέσματα μας δείχνουν ότι τα μοντέλα που επιτυγχάνουν την καλύτερη απόδοση είναι εκείνα που εκπαιδεύονται μόνο σε αραβικά δεδομένα, συμπεριλαμβανομένων των διαλεκτικών αραβικών, και χρησιμοποιούν μεγαλύτερο αριθμό παραμέτρων, όπως το πρόσφατα κυκλοφορημένο MARBERT. Ωστόσο, παρατηρήσαμε ότι το AraELECTRA είναι ένα από τα κορυφαία μοντέλα επιδόσεων ενώ είναι πολύ πιο αποδοτικό στο υπολογιστικό του κόστος. Τέλος, τα πειράματα σε παραλλαγές AraGPT2 έδειξαν χαμηλή απόδοση σε σύγκριση με τα μοντέλα BERT, γεγονός που δείχνει ότι μπορεί να μην είναι κατάλληλα για εργασίες ταξινόμησης.', 'kk': 'Түрлендіруші тіл үлгілерінің іске асыру - табиғи тіл өңдеу (NLP) зерттеу үшін революциялық қадам болды. Бұл үлгілер, BERT, GPT және ELECTRA секілді, NLP тапсырмалардың көпшілікті күй- жайымдық істеу үшін болды. Бұл үлгілердің көпшілігі ағылшынша және басқа тілдер үшін кейін жасалған. Жуырда бірнеше арабша ерекше үлгілер көрсетілген. Бірақ бұл үлгілердің арасында тәуелді салыстырылуы шектелген. Бұл қағазда, араб сезімі мен сарказмды анықтау үлгілерінің 24 жасауын бағалаймыз. Біздің нәтижелеріміз ең жақсы жылдамдығын жеткізу үлгілері - тек араб деректеріне оқылған, диалекталды араб тілінде, және соңғы шығарылған MARBERT секілді үлкен параметрлерді қолданады. Бірақ, AraELECTRA компьютерлік бағаларындағы ең жақсы орындау үлгілердің бірі деп ойладық. Соңында, AraGPT2 варианттарының тәжірибелері BERT үлгілеріне салыстырылған тәжірибелерді төмен көрсетті. Бұл классификациялық тапсырмалар үшін дұрыс емес дегенді көрсетеді.', 'ka': 'ტრანფორმენტერის ენის მოდელების ჩვენება იყო რეგჲლუციონიური ნაწილის პროცესის (NLP) პასუხისთვის. ეს მოდელები, როგორც BERT, GPT და ELECTRA, მრავალი NLP სამუშაო სამუშაო მუშაო მოქმედებაში გადატანა. ამ მოდელების უფრო მეტი დავიწყება ინგლისური და სხვა ენებისთვის შემდეგ. მიმდინარე, რამდენიმე არაბური განსაკუთრებული მოდელები დაიწყება. მაგრამ, ამ მოდელების შორის მიზეზი შემდგომარება არსებობს. ამ დოკუნეში, ჩვენ 24-ის მოდელის გამოყენებას აპაბიური სინტემინტი და საპკასმის განახლების შესახებ. ჩვენი წარმოდგენები ჩვენი მოდელები, რომლებიც საუკეთესო პროცესტის მიღება, იგივეა, რომლებიც მხოლოდ აპაბიური მონაცემებით განაკეთებულია, რომლებიც დიალექტალური აპაბიური მაგრამ ჩვენ დავხედავთ, რომ AraELECTRA არის ყველაზე მნიშვნელოვანი მოდელების ერთი, როცა უფრო ეფექტიური იყო თავის კომპუტაციალური ღირებში. საბოლოოდ, არაGPT2 გარიანტების ექსპერიმენტები გაჩვენეთ ცოტა კონფიქცია BERT მოდელთან, რომელიც უნდა იყოს კლასიფიკაციის დავალებისთვის.', 'mk': 'Вклучувањето на јазички модели базирани на трансформатори претставува револуционерен чекор за истражување на природното обработување јазик (НЛП). Овие модели, како што се БЕРТ, ГПТ и ЕЛЕКТРА, доведоа до најнови изведувања во многу НЛП задачи. Повеќето од овие модели првично беа развиени за англиски и други јазици следени подоцна. Неодамна почнаа да се појавуваат неколку арапски специфични модели. Сепак, постојат ограничени директни споредби помеѓу овие модели. Во овој весник ја проценуваме изведбата на 24 од овие модели за арапско чувство и детекција на сарказам. Нашите резултати покажуваат дека моделите кои ја постигнуваат најдобрата резултат се оние кои се обучени само на арапски податоци, вклучително и дијалектален арапски, и користат поголем број параметри, како што е неодамна објавениот MARBERT. Сепак, забележавме дека АРЕЛЕКТРА е еден од највисоките модели и дека е многу поефикасен во своите пресметувачки трошоци. Конечно, експериментите на варијантите на AraGPT2 покажаа ниска ефективност во споредба со моделите на BERT, што покажува дека можеби не е соодветна за класификациските задачи.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പരിശോധനത്തിനായി മാറ്റുന്ന ഭാഷ മോഡലുകളെ പരിചയപ്പെടുത്തുന്നത് സ്വാഭാവികമായ ഭാഷ പ്രവര്\u200dത്തന BERT, GPT, ELECTRA പോലെ ഈ മോഡലുകള്\u200d പല NLP ജോലികളിലേക്കും പ്രദര്\u200dശിപ്പിച്ചിരിക്കുന്നു. ഇംഗ്ലീഷിലും മറ്റു ഭാഷകള്\u200dക്കും ആദ്യം മോഡലുകള്\u200d വികസിപ്പിക്കപ്പെട്ടിരുന്നു. അടുത്തുതന്നെ, പല അറബിയിലെ പ്രത്യേകിച്ച മോഡലുകള്\u200d പുറപ്പെടുന്നതായി തുടങ്ങി. എന്നാലും, ഈ മോഡലുകള്\u200dക്കിടയില്\u200d നേരിട്ടുള്ള താല്\u200dപ്പര്യങ്ങള്\u200d നിറഞ്ഞിരിക്കുന്നു. ഈ പത്രത്തില്\u200d, ഈ മോഡലുകളുടെ പ്രകടനത്തെക്കുറിച്ച് നമ്മള്\u200d അറബിയിലെ അഭിപ്രായത്തെക്കുറിച്ചും സർക്കാസം കണ്ട നമ്മുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നത് ഏറ്റവും നല്ല പ്രവര്\u200dത്തനങ്ങള്\u200d നേടുന്ന മോഡലുകളാണ് അറബിയിലെ വിവരങ്ങളില്\u200d മാത്രമേ പരിശീലിക്കപ്പെടുന്നുള്ളൂ, ഡയലക്ട എന്നാലും നമ്മള്\u200d കണ്ടുപിടിച്ചു കൊണ്ടിരിക്കുന്നത് അറലെക്സ്റ്റാര മോഡലുകളില്\u200d ഒന്നാണെന്നാണ്. അതിന്റെ കണക്കിട്ടി Finally, the experiments on AraGPT2 variants showed low performance compared to BERT models, which indicates that it might not be suitable for classification tasks.', 'ms': 'Pengenalan model bahasa berasaskan pengubah telah menjadi langkah revolusi untuk proses bahasa semulajadi (NLP). Model ini, seperti BERT, GPT dan ELECTRA, menyebabkan prestasi terbaik dalam banyak tugas NLP. Kebanyakan model ini dibuat awalnya untuk bahasa Inggeris dan bahasa lain diikuti kemudian. Baru-baru ini, beberapa model spesifik Arab mula muncul. Namun, terdapat perbandingan langsung terhad antara model ini. Dalam kertas ini, kami menilai prestasi 24 daripada model ini mengenai perasaan Arab dan pengesan sarkasme. Hasil kami menunjukkan bahawa model yang mencapai prestasi terbaik adalah yang dilatih hanya pada data Arab, termasuk Arab dialektal, dan menggunakan bilangan parameter yang lebih besar, seperti MARBERT yang baru-baru ini dilepaskan. Namun, kami perasan bahawa AraELECTRA adalah salah satu daripada model yang paling berkesan sementara lebih efisien dalam biaya pengiraannya. Akhirnya, eksperimen pada varian AraGPT2 menunjukkan prestasi rendah dibandingkan dengan model BERT, yang menunjukkan bahawa ia mungkin tidak sesuai untuk tugas klasifikasi.', 'mt': 'L-introduzzjoni ta’ mudelli lingwistiċi bbażati fuq it-trasformaturi kienet pass rivoluzzjonarju għar-riċerka dwar l-ipproċessar naturali tal-lingwi (NLP). Dawn il-mudelli, bħall-BERT, il-GPT u l-ELECTRA, wasslu għal prestazzjoni avvanzata f’ħafna kompiti tal-NLP. Il-biċċa l-kbira ta’ dawn il-mudelli ġew żviluppati inizjalment għall-Ingliż u lingwi oħra segwiti aktar tard. Dan l-aħħar, bdew jitfaċċaw diversi mudelli speċifiċi għall-Għarab. Madankollu, hemm paraguni diretti limitati bejn dawn il-mudelli. F’dan id-dokument, aħna jevalwaw il-prestazzjoni ta’ 24 minn dawn il-mudelli dwar is-sentiment Għarbi u l-individwazzjoni tas-sarkazmu. Ir-riżultati tagħna juru li l-mudelli li jiksbu l-a ħjar prestazzjoni huma dawk li jitħarrġu fuq dejta Għarbija biss, inkluż dik Għarbija dijalektali, u jużaw numru akbar ta’ parametri, bħall-MARBERT li ġie rilaxxat dan l-aħħar. Madankollu, irrimarkajna li AraELECTRA hija wieħed mill-mudelli bl-ogħla prestazzjoni filwaqt li hija ħafna aktar effiċjenti fl-ispiża komputattiva tagħha. Fl-aħħar nett, l-esperimenti fuq varjanti AraGPT2 urew prestazzjoni baxxa meta mqabbla mal-mudelli BERT, li jindika li jista’ ma jkunx adattat għal kompiti ta’ klassifikazzjoni.', 'mn': 'Түүнчлэн хэл загварын суурилсан загварын танилцуулалт нь байгалийн хэл процесс (NLP) судалгааны хувьсгал алхам юм. БЕРТ, GPT болон ЭЛЕКТРА зэрэг эдгээр загварууд нь NLP ажлын олон ажил дээр урлагийн үйл ажиллагааг авч ирсэн. Эдгээр загваруудын ихэнх нь англи хэл болон бусад хэл дараа нь хөгжүүлсэн. Саяхан Араб хэдэн тодорхой загварууд гарч ирсэн. Гэхдээ эдгээр загваруудын хооронд шууд харьцуулалт хязгаарлагддаг. Энэ цаасан дээр бид Араб сэтгэл хөдлөл болон саркассмын нээлттэй 24 загварын үйл ажиллагааг үнэлдэг. Манай үр дүнд хамгийн сайн үйл ажиллагааг хүртэх загварууд нь зөвхөн Араб өгөгдлийн талаар суралцагдсан, диалектик Араб болон саяхан гаргасан MARBERT шиг олон параметр хэрэглэдэг. Гэхдээ бид AraELECTRA нь тооцооллын зардалд илүү үр дүнтэй байгаа хамгийн өндөр үйлдвэрлэлийн загварын нэгийг анзаарсан. Эцэст нь, AraGPT2 хувилбарын туршилтууд BERT загвартай харьцуулахад бага үйл ажиллагааг харуулсан. Энэ нь хувилбарын ажиллагаанд хэрэггүй байж магадгүй гэсэн үг.', 'no': 'Innføring av transformeringsspråk-modeller er ein revolusjonssteg for naturspråk-handsaming (NLP). Desse modelane, som BERT, GPT og ELECTRA, førte til status-of-the-art-performance i mange NLP-oppgåver. Dei fleste av desse modelane ble utvikla for engelsk og andre språk etter seinare. Nyleg starta opp fleire arabiske modeller. Det er imidlertid begrenset direkte sammenlikningar mellom desse modelane. I denne papiret evaluerer vi utviklinga av 24 av desse modelane om arabiske sentiment og sarkasm-oppdaging. Resultatet våre viser at modelane som oppnår det beste utviklinga er dei som vert trenta på berre arabiske data, inkludert dialektiske arabiske, og brukar eit større tal parametra, som det siste lagde MARBERT. I tillegg har vi merke på at AraELECTRA er ein av dei øvste utføringsmodulane, mens det er mykje meir effektivt i datakostnaden sin. Eksperimentane på AraGPT2-variantane viste låg utvikling samanlikna med BERT-modeller, som viser at det kanskje ikkje kan vera passande for klassifikasjonsprogrammer.', 'ro': 'Introducerea modelelor de limbaj bazate pe transformator a fost un pas revoluționar pentru cercetarea prelucrării limbajului natural (PNL). Aceste modele, cum ar fi BERT, GPT și ELECTRA, au condus la performanțe de ultimă generație în multe sarcini NLP. Cele mai multe dintre aceste modele au fost inițial dezvoltate pentru engleză, iar alte limbi au fost urmate mai târziu. Recent, mai multe modele specifice arabei au început să apară. Cu toate acestea, există comparații directe limitate între aceste modele. În această lucrare, evaluăm performanța a 24 dintre aceste modele privind detectarea sentimentului arab și sarcasmului. Rezultatele noastre arată că modelele care obțin cea mai bună performanță sunt cele care sunt instruite doar pe date arabe, inclusiv dialectale arabe, și utilizează un număr mai mare de parametri, cum ar fi recent lansat MARBERT. Cu toate acestea, am observat că AraELECTRA este unul dintre cele mai performante modele, în timp ce este mult mai eficient în costul său de calcul. În cele din urmă, experimentele pe variantele AraGPT2 au arătat performanțe scăzute în comparație cu modelele BERT, ceea ce indică faptul că s-ar putea să nu fie potrivit pentru sarcini de clasificare.', 'sr': 'Uvedenje jezičkih modela na transformaciji je revolucionaran korak za istraživanje prirodnog jezika (NLP). Ovi modeli, kao što su BERT, GPT i ELECTRA, doveli su do predstave umjetnosti u mnogim zadacima NLP-a. Većina ovih modela je početno razvijena za engleski i drugi jezici kasnije. Nedavno se pojavilo nekoliko arapskih modela. Međutim, postoje ograničene direktne usporedbe između tih modela. U ovom papiru procjenjujemo izvršnost 24 modela o arapskom detektivu sentimenta i sarkazama. Naši rezultati pokazuju da su modeli koji ostvaruju najbolje izvedbe oni koji su obučeni samo na arapskim podacima, uključujući dijalektni arapski, i koristili veći broj parametara, poput nedavno oslobođenog MARBERT-a. Međutim, primetili smo da je AraELECTRA jedan od najboljih izvođača modela dok je mnogo efikasniji u svojim računalnim troškovima. Konačno, eksperimenti na varijantima AraGPT2 pokazali su nisku funkciju u usporedbi s modelima BERT, što ukazuje na to da možda nije odgovarajuće za klasifikacijske zadatke.', 'si': 'ප්\u200dරවර්තනය කරපු භාෂාව අධික භාෂා මොඩේලන්ගේ පරීක්ෂණය ස්වභාවික භාෂාව පරීක්ෂණය (NLP) විශ මේ මොඩේල්ස්, BERT, GPT සහ ELECTRA වගේ, NLP වැඩේ ගොඩක් ක්\u200dරියාලයෙන් ස්ථානයේ ක්\u200dරියාත්මක වෙන්න පුළුවන්. මේ මෝඩේල්ස් ගොඩක් මෝඩේල්ස් පස්සේ ඉංග්\u200dරීසි වලින් සහ අනිත් භාෂාවට පස්සේ පස්සේ  අවසානයෙන්, අරාබික් විශේෂ විශේෂ විදිහට පටන් ගත්තා විදිහට. නමුත්, මේ මොඩල් අතර ප්\u200dරමාණයක් තියෙනවා. මේ පත්තරේ අපි අරාබි දේවල් සහ සාර්කාස්ම් හොයාගන්නේ අරාබි දේවල් 24 ක් ගැන ප්\u200dරමාණය අවශ්\u200dය කරනවා. අපේ ප්\u200dරතිචාරය පෙන්වන්නේ හොඳම ප්\u200dරතිචාරයක් ලබාගන්න හොඳම ප්\u200dරතිචාරයක් තමයි අරාබි දත්තේ විතරයි, ඩායිලෙක්ටල් අරාබි වලින්  ඒත් අපි දැනගෙන හිටියා ඇරෙලෙක්ට්\u200dරා තමයි උපරිම ප්\u200dරශ්නයක් කරන්නේ මොඩල් එකක් කියලා, ඒ වගේම එයාගේ පරිගණනය විශ අන්තිමේදි, AraGPT2 වෙනස් වලින් පරීක්ෂණය පෙන්වන්නේ BERT මොඩල් වලින් පරීක්ෂණය, ඒක පෙන්වන්නේ ඒක විශේෂණ වැඩක් වලට ය', 'so': 'Isu soo saarista qaababka luuqada ee lagu beddelayo waa qaab revolutionary ah oo loo baaraandegay baaritaanka afka dabiicadda (NLP). Tusaaladan, tusaale ahaan BERT, GPT iyo ELECTRA waxay ka sababtay shaqooyin badan oo NLP. Inta badan tusaalahaas waxaa marka hore loo hormariyey Ingiriis iyo luqado kale dabadeed. Dhab ahaantii, tusaalooyin badan oo Carabi ah ayaa bilaabay inay soo baxaan. However, there are limited direct comparisons between these models.  Warqadan, waxaynu qiimeynaynaa dabeecadan 24 ka mid ah oo ku saabsan fikrada Carabiga iyo garsoorida sarcasm. Arimahaaga waxaa tusaya in tusaalayaasha dhamaystirka ugu wanaagsan ay yihiin kuwa lagu baray macluumaadka Carabiga oo kaliya, kuwaas oo ka mid ah macluumaadka afka Carabiga, waxayna isticmaalaan parameters aad u weyn, tusaale ahaan ugu dhowaad la soo daayay MARBERT. Si kastaba ha ahaatee waxaan ogaanay in AraELECTRA uu yahay mid ka mid ah sameynta ugu sarreeya sameynta, iyadoo aad uga faa’iido badan kharashkiisa xisaabta. ugu dambeyso imtixaanka kala duwan ee AraGPT2 waxay muuqatay tababar yar oo la barbardhigay modelalka BERT, taasina waxay caddaysaa inaanay u habboonayn shaqada fasaxa.', 'it': "L'introduzione di modelli linguistici basati su trasformatori è stata un passo rivoluzionario per la ricerca sull'elaborazione del linguaggio naturale (NLP). Questi modelli, come BERT, GPT ed ELECTRA, hanno portato a prestazioni all'avanguardia in molte attività NLP. La maggior parte di questi modelli sono stati inizialmente sviluppati per l'inglese e altre lingue sono seguite successivamente. Recentemente, diversi modelli specifici per l'arabo hanno iniziato ad emergere. Tuttavia, vi sono limitati confronti diretti tra questi modelli. In questo articolo valutiamo le prestazioni di 24 di questi modelli sul sentiment arabo e sul rilevamento del sarcasmo. I nostri risultati mostrano che i modelli che ottengono le migliori prestazioni sono quelli che sono formati solo su dati arabi, compreso l'arabo dialettale, e utilizzano un numero maggiore di parametri, come il MARBERT recentemente rilasciato. Tuttavia, abbiamo notato che AraELECTRA è uno dei modelli più performanti pur essendo molto più efficiente nel suo costo computazionale. Infine, gli esperimenti sulle varianti AraGPT2 hanno mostrato prestazioni basse rispetto ai modelli BERT, il che indica che potrebbe non essere adatto per compiti di classificazione.", 'sv': 'Införandet av transformatorbaserade språkmodeller har varit ett revolutionerande steg för forskning om naturlig språkbearbetning (NLP). Dessa modeller, som BERT, GPT och ELECTRA, ledde till toppmodern prestanda i många NLP-uppgifter. De flesta av dessa modeller utvecklades ursprungligen för engelska och andra språk följde senare. Nyligen började flera arabiska-specifika modeller dyka upp. Det finns dock begränsade direkta jämförelser mellan dessa modeller. I denna uppsats utvärderar vi prestandan hos 24 av dessa modeller på arabisk sentiment och sarkasm detektering. Våra resultat visar att de modeller som uppnår bästa prestanda är de som är utbildade på enbart arabiska data, inklusive dialektiska arabiska, och använder ett större antal parametrar, såsom nyligen släppt MARBERT. Vi märkte dock att AraELECTRA är en av de topppresterande modellerna samtidigt som den är mycket effektivare i sin beräkningskostnad. Slutligen visade experimenten på AraGPT2 varianter låg prestanda jämfört med BERT-modeller, vilket tyder på att det kanske inte är lämpligt för klassificeringsuppgifter.', 'ta': 'மாற்றம் அடிப்படையில் உள்ள மொழி மாதிரிகளின் முன்னேற்றம் இயல்பான மொழி செயல்படுத்தல் (NLP) ஆராய்ச்சிக்கு ஒரு புரட BERT, GPT மற்றும் ELECTRA போன்ற இந்த மாதிரிகள், பல NLP பணிகளில் உள்ள கலை செயல்பாட்டின் நிலையில் காண்பித்தது. Most of these models were initially developed for English and other languages followed later.  சமீபத்தில், பல அரபி குறிப்பிட்ட மாதிரிகள் வளர்ந்து தொடங்கியது. ஆனால், இந்த மாதிரிகளுக்கிடையில் நேரான ஒப்பீடுகள் எல்லாம் உள்ளன. இந்த காகிதத்தில், நாம் இந்த 24 மாதிரிகளின் செயல்பாட்டை மதிப்பிடுகிறோம் அரேபி உணர்வு மற்றும் சிக்கல் கண்டுபி முடிவு ஆனால், ஆரெலிக்ட்ரா மேல் செயல்படுத்தும் மாதிரிகளில் ஒன்றாக இருக்கும் என்பதை நாம் கவனித்தோம். இறுதியாக, ஆராஜிபிடி2 மாறிகளின் சோதனைகள் BERT மாதிரிகளுக்கு ஒப்பிடும் குறைந்த செயல்பாட்டை காண்பித்தது, இது வகைப்படுத்தல் பணி', 'lt': 'Transformatoriais pagrįstų kalbų modelių įvedimas buvo revoliucinis žingsnis gamtos kalbų apdorojimo (NLP) moksliniams tyrimams. Šie modeliai, pavyzdžiui, BERT, GPT ir ELECTRA, daugelyje NLP užduočių lėmė pažangiausius rezultatus. Dauguma šių modelių iš pradžių buvo parengti anglų ir kitų kalbų, po kurių vėliau. Neseniai atsirado keletas arabų specifinių modelių. Tačiau šių modelių tiesioginis palyginimas yra ribotas. Šiame dokumente vertiname 24 šių modelių arabų jausmų ir sarkazmo aptikimo rezultatus. Mūsų rezultatai rodo, kad geriausius rezultatus pasiekiantys modeliai yra tie, kurie mokomi tik arabų duomenimis, įskaitant dialektinę arabų kalbą, ir naudoja daugiau parametrų, pavyzdžiui, neseniai paskelbtą MARBERT. Tačiau pastebėjome, kad AraELECTRA yra vienas iš geriausiai veikiančių modelių, tačiau yra daug veiksmingesnis skaičiavimo sąnaudų požiūriu. Galiausiai AraGPT2 variantų eksperimentai parodė mažą veiksmingumą lyginant su BERT modeliais, o tai rodo, kad jis gali būti netinkamas klasifikavimo užduotims atlikti.', 'pl': 'Wprowadzenie modeli językowych opartych na transformatorach było rewolucyjnym krokiem w badaniach nad przetwarzaniem języka naturalnego (NLP). Modele te, takie jak BERT, GPT i ELECTRA, doprowadziły do najnowocześniejszej wydajności w wielu zadaniach NLP. Większość z tych modeli została początkowo opracowana dla angielskiego, a później inne języki. Ostatnio zaczęło się pojawiać kilka specyficznych modeli arabskich. Istnieje jednak ograniczona liczba bezpośrednich porównań między tymi modelami. W niniejszym artykule oceniamy wydajność 24-tych modeli w wykrywaniu arabskich sentymentów i sarkazmu. Nasze wyniki pokazują, że modele osiągające najlepszą wydajność to te, które są trenowane tylko na danych arabskich, w tym dialektalnym arabskim, i wykorzystują większą liczbę parametrów, takich jak niedawno wydany MARBERT. Zauważyliśmy jednak, że AraELECTRA jest jednym z najlepiej wydajnych modeli, jednocześnie jest znacznie bardziej efektywny pod względem kosztów obliczeniowych. Wreszcie, eksperymenty na wariantach AraGPT2 wykazały niską wydajność w porównaniu z modelami BERT, co wskazuje, że może nie być odpowiednie do zadań klasyfikacyjnych.', 'ur': 'تبدیل کرنے والی زبان مدل کی معلومات طبیعی زبان پرسس (NLP) تحقیق کے لئے ایک انقلاب قدم ہے۔ یہ موڈل، جیسے BERT, GPT اور ELECTRA، بہت سی NLP کاموں میں استیٹ کی عملکرد کی طرف لے گئے۔ ان کی اکثریت مدلکوں کی ابتدا انگلیسی اور دوسری زبانوں کے لئے تولید کی گئی تھی۔ اچھا، بہت سی عربی معلوم موڈل پیدا ہونے لگے۔ لیکن ان نمڈلوں کے درمیان مقدار مقدار ہیں. اس کاغذ میں ہم ان مڈالیوں میں سے 24 کی عملکرد کا ارزش کرتے ہیں عربی sentiment اور sarcasm detection پر۔ ہمارے نتیجے دکھاتے ہیں کہ بہترین عملکرد کو پہنچانے کی مدل ایسے ہیں جو صرف عربی ڈاٹوں پر آموزش کی جاتی ہیں، جیسے ڈائیلکتل عربی، اور بہترین پارامتر استعمال کرتے ہیں، جیسے اخیر سے آزاد ہوئی MARBERT. لیکن ہم نے سمجھ لیا کہ AraELECTRA سب سے زیادہ مطابق نمونوں میں سے ایک ہے حالانکہ اس کی کمپیوٹریشن قیمت میں زیادہ مفید ہے۔ آخر میں، AraGPT2 ویرائینٹوں کے آزمائش نے BERT موڈل کے مقابلہ میں کم عملکرد دکھائی، جو نشان دیتا ہے کہ یہ کلاسپیٹ کے کاموں کے لئے مناسب نہیں ہو سکتا۔', 'vi': 'Việc giới thiệu các mô hình ngôn ngữ dựa trên máy biến đổi đã là một bước cách mạng cho nghiên cứu ngôn ngữ tự nhiên. Những mô hình này, như BERT, GPT và Excđời, đã dẫn đến một trình độ hiện đại trong nhiều công việc của NMB. Phần lớn các mô hình này được phát triển cho tiếng Anh và các ngôn ngữ khác sau đó. Gần đây, vài mẫu đặc trưng của Ả Rập. Tuy nhiên, có những so sánh trực tiếp giới hạn giữa các mô-đun này. Trong tờ giấy này, chúng tôi đánh giá khả năng của tập hợp 244 của các mô hình này về cảm tính Ả Rập và phát hiện mỉa mai. Kết quả của chúng tôi cho thấy các mẫu đạt được hiệu quả tốt nhất là mẫu được đào tạo chỉ dựa trên dữ liệu Ả Rập, kể cả tiếng Ả Rập, và sử dụng một số lượng lớn các tham số, như kết quả MABERT được phát hành gần đây. Tuy nhiên, chúng tôi nhận thấy rằng AraElectmạng là một trong những mô hình đỉnh của nó, trong khi nó còn hiệu quả hơn nhiều trong chi phí tính toán của nó. Cuộc thí nghiệm lượng AraGP2 thấy khả năng rất thấp so với một một một cây BERT, cho thấy nó có thể không phù hợp cho một nhiệm phân hạng.', 'uz': "Boshqaruvchi tilning asosiy modellarini ishga tushirish asl tilni boshqarish (NLP) ta'minlovchisi uchun rivojlanuvchi qadam edi. Bu modellar BERT, GPT va ELECTRA kabi NLP vazifalarda barcha kunlar vazifalarining holatini bajaradi. Bu modellarning ko'pchiligi ingliz tili va boshqa tillar uchun yaratildi. Keyin keyin keyin. Yaqinda, ko'pchilik arab-foydalanuvchi modellar Lekin, bu modellar orasidagi direktoriya moslamalar bor. Bu qogʻozda biz arab hisob va sarkasm aniqlanishda 24 modellarning hayotini qiymatimiz. Bizning natijalarimiz eng yaxshi bajarish modellari esa faqat arab maʼlumotlarida o'rganishlar, dialektal arab maʼlumotlarida ko'proq parametrlarni ishlatish mumkin. Yaqinda chiqindilar MARBERT kabi ko'proq parametrlarni ishlatish mumkin. Lekin, biz AraELECTRA eng yuqori ishlab chiqaruvchi modellardan biri ko'proq kompyuterning qiymatiga ko'proq. Oxiri, AraGPT2 variantlaridagi imtiyozlar BERT modellariga kamaytirish imtiyozni yaratadi. Bu imtiyozlar uchun darajalashtirish vazifalari yetarli emas.", 'hr': 'Uvedenje jezičkih modela na transformaciji bio je revolucionarni korak za istraživanje prirodnog obrazovanja jezika (NLP). Ovi modeli, kao što su BERT, GPT i ELECTRA, doveli su do postupka umjetnosti u mnogim zadatkima NLP-a. Većina tih modela je početno razvijena za engleski i drugi jezici kasnije. Nedavno se pojavilo nekoliko arapskih modela. Međutim, postoje ograničene direktne usporedbe između tih modela. U ovom papiru procjenjujemo učinku 24 ovih modela o otkrivanju arapskih osjećaja i sarkazama. Naši rezultati pokazuju da su modeli koji ostvaruju najbolju učinku oni koji su obučeni samo na arapskim podacima, uključujući dijalektno arapski, i koriste veći broj parametara, poput nedavno oslobođenog MARBERT-a. Međutim, primijetili smo da je AraELECTRA jedan od najboljih izvodnjih modela dok je mnogo učinkovitiji u svojim računalnim troškovima. Konačno, eksperimenti na varijantima AraGPT2 pokazali su nisku učinku u usporedbi s modelima BERT-a, što ukazuje na to da možda nije odgovarajuće za klasifikacijske zadatke.', 'de': 'Die Einführung transformatorbasierter Sprachmodelle war ein revolutionärer Schritt für die Erforschung natürlicher Sprachverarbeitung (NLP). Diese Modelle, wie BERT, GPT und ELECTRA, führten zu modernster Leistung bei vielen NLP-Aufgaben. Die meisten dieser Modelle wurden zunächst für Englisch entwickelt, später folgten weitere Sprachen. In letzter Zeit entstanden mehrere arabisch-spezifische Modelle. Allerdings gibt es nur begrenzte direkte Vergleiche zwischen diesen Modellen. In diesem Beitrag bewerten wir die Leistung von 24 dieser Modelle zur Erkennung arabischer Gefühle und Sarkasmus. Unsere Ergebnisse zeigen, dass die Modelle, die die beste Leistung erzielen, diejenigen sind, die nur auf arabischen Daten trainiert werden, einschließlich dialektalem Arabisch, und eine größere Anzahl von Parametern verwenden, wie das kürzlich veröffentlichte MARBERT. Wir haben jedoch festgestellt, dass AraELECTRA eines der leistungsstärksten Modelle ist und gleichzeitig viel effizienter in seinen Rechenkosten ist. Schließlich zeigten die Experimente an AraGPT2-Varianten eine geringe Performance im Vergleich zu BERT-Modellen, was darauf hindeutet, dass es möglicherweise nicht für Klassifizierungsaufgaben geeignet ist.', 'bg': 'Въвеждането на трансформаторни езикови модели е революционна стъпка в изследванията за обработка на естествения език (НЛП). Тези модели, като BERT, GPT и ELECTRA, доведоха до най-съвременно изпълнение в много задачи на НЛО. Повечето от тези модели първоначално са разработени за английски и други езици последвани по-късно. Наскоро започнаха да се появяват няколко специфични арабски модела. Въпреки това, има ограничени директни сравнения между тези модели. В настоящата статия оценяваме ефективността на 24 от тези модели за откриване на арабски сантименти и сарказъм. Нашите резултати показват, че моделите, които постигат най-добра производителност, са тези, които са обучени само на арабски данни, включително диалекталния арабски, и използват по-голям брой параметри, като наскоро пуснатия МАРБЕРТ. Въпреки това забелязахме, че е един от най-добрите модели, като същевременно е много по-ефективен в изчислителните си разходи. И накрая, експериментите с вариантите на AraGPT2 показват ниска производителност в сравнение с моделите BERT, което показва, че може да не е подходящ за задачи по класификация.', 'da': 'Introduktionen af transformer-baserede sprogmodeller har været et revolutionerende skridt for forskning i naturlig sprogbehandling (NLP). Disse modeller, såsom BERT, GPT og ELECTRA, førte til state-of-the-art ydeevne i mange NLP-opgaver. De fleste af disse modeller blev oprindeligt udviklet til engelsk og andre sprog fulgt senere. For nylig begyndte flere arabisk-specifikke modeller at dukke op. Der er imidlertid begrænsede direkte sammenligninger mellem disse modeller. I denne artikel evaluerer vi ydeevnen af 24 af disse modeller på arabisk sentiment og sarkasme detektion. Vores resultater viser, at de modeller, der opnår den bedste ydeevne, er dem, der er trænet på kun arabiske data, herunder dialektisk arabisk, og bruger et større antal parametre, såsom den nyligt udgivet MARBERT. Vi bemærkede dog, at AraELECTRA er en af de bedst ydende modeller, samtidig med at den er meget mere effektiv i sine beregningsomkostninger. Endelig viste forsøgene på AraGPT2 varianter lav ydeevne sammenlignet med BERT modeller, hvilket indikerer, at det måske ikke er egnet til klassificeringsopgaver.', 'nl': 'De introductie van transformatorgebaseerde taalmodellen is een revolutionaire stap geweest voor onderzoek naar natuurlijke taalverwerking (NLP). Deze modellen, zoals BERT, GPT en ELECTRA, hebben geleid tot state-of-the-art prestaties in veel NLP-taken. De meeste van deze modellen werden aanvankelijk ontwikkeld voor het Engels en later volgden andere talen. Onlangs zijn verscheidene Arabisch-specifieke modellen ontstaan. Er zijn echter beperkte directe vergelijkingen tussen deze modellen. In dit artikel evalueren we de prestaties van 24 van deze modellen op het gebied van Arabisch sentiment en sarcasme detectie. Onze resultaten tonen aan dat de modellen die de beste prestaties behalen, alleen zijn getraind op Arabische data, inclusief dialectisch Arabisch, en een groter aantal parameters gebruiken, zoals de onlangs uitgebrachte MARBERT. We merkten echter dat AraELECTRA een van de best presterende modellen is, terwijl het veel efficiënter is in zijn rekenkosten. Ten slotte vertoonden de experimenten met AraGPT2 varianten lage prestaties in vergelijking met BERT modellen, wat aangeeft dat het niet geschikt is voor classificatietaken.', 'sw': 'Kuanzishwa kwa mifano ya lugha ya mabadiliko imekuwa hatua ya mapinduzi ya utafiti wa lugha asili (NLP). Mfano huu, kama vile BERT, GPT na ELECTRA, ulisababisha utendaji wa sanaa katika kazi nyingi za NLP. Wengi wa mifano hii zilianzishwa kwa ajili ya lugha nyingine za Kiingereza na zilifuatiliwa baadaye. Recently, several Arabic-specific models started emerging.  Hata hivyo, kuna ulinganisho wa moja kwa moja kati ya mifano hii. Katika gazeti hili, tunatathmini utendaji wa mifano 24 ya hizi kuhusu hisia za Kiarabu na utambuzi wa kejeli. Matokeo yetu yanaonyesha kuwa mifano ya kutekeleza ufanisi bora ni wale ambao hufundishwa kwa takwimu za Kiarabu pekee, ikiwa ni pamoja na Kiarabu, na kutumia idadi kubwa zaidi ya parameters, kama vile ilivyoachiwa hivi karibuni MARBERT. Hata hivyo, tuligundua kuwa AraELECTRA ni moja ya mifano ya juu ya utendaji wakati akiwa na ufanisi zaidi katika gharama zake za kompyuta. Mwisho, majaribio katika mabadiliko ya AraGPT2 yalionyesha utendaji wa michoro ya BERT ukilinganishwa na mifano ya BERT, ambayo inaonyesha kwamba haiwezekani kuwa sahihi kwa kazi za usambazaji.', 'tr': 'Terjime edilen dil nusgalarynyň girişi tebigy dil işlemegi üçin bir revolucionaly adım boldy. Bu nusgalar, BERT, GPT we ELECTRA ýaly NLP işinde möhüm taýýarlanmagyna sebep etdiler. Bu nusgalaryň köp bölegi başlangyç iňlisçe we soňra yzarlanýan diller üçin döredildi. Soňra birnäçe Arapça hasaplanyň nusgalary ortaya başlady. Ýöne bu nusgalar arasynda çykyp düzgün derejesi bar. Bu kagyzda, bu nusgyň 24 nusgyny arabça duýgular we sarkasm tanyşynda deňleýäris. Biziň netijelerimiz diňe arabça maglumatlarda öwrenmeli modelleriň beýik performansyny ýetmegini görkezýär, diňe dialektal arapça we ýagdaýynda ullanylýan parameterleriň birnäçe köp sany ulanýarlar, ýaly ýa ňky boşadylýan MARBERT ýaly. Ýöne, AraELECTRA iň ýokary taýýarlanan nusgalaryň biri we ol wagtyň kalýumyň bedelinde has hem täsirli bolup geçýän nusgalarynyň biri diýip pikir etdik. AraGPT2 wariantlaryň synaglary BERT nusgalaryna görä düşük performans görkezilýär. Bu synaglary klasifikasiýa görenler üçin uygun däldir diýip görkeýär.', 'id': 'Pengenalan model bahasa berbasis transformator telah menjadi langkah revolusi untuk penelitian proses bahasa alam (NLP). Model-model ini, seperti BERT, GPT dan ELECTRA, menyebabkan prestasi terbaik dalam banyak tugas NLP. Kebanyakan dari model ini awalnya dikembangkan untuk bahasa Inggris dan bahasa lain yang diikuti kemudian. Recently, several Arabic-specific models started emerging.  Namun, ada perbandingan langsung terbatas antara model ini. Dalam kertas ini, kami mengevaluasi prestasi 24 dari model ini tentang perasaan Arab dan deteksi sarkasme. Hasil kami menunjukkan bahwa model yang mencapai prestasi terbaik adalah yang dilatih hanya pada data Arab, termasuk Arab dialektal, dan menggunakan sejumlah parameter yang lebih besar, seperti yang baru-baru ini dibebaskan MARBERT. Namun, kami menyadari bahwa AraELECTRA adalah salah satu model yang paling berpengaruh sementara jauh lebih efisien dalam biaya komputasi. Akhirnya, eksperimen pada varian AraGPT2 menunjukkan prestasi rendah dibandingkan dengan model BERT, yang menunjukkan bahwa mungkin tidak cocok untuk tugas klasifikasi.', 'af': "Die inligting van transformeerder-gebaseerde taal modele is 'n revolusionele stap vir natuurlike taal verwerking (NLP) ondersoek. Hierdie modele, soos BERT, GPT en ELECTRA, het gelei na state-of-the-art prestasie in baie NLP-opdragte. Die meeste van hierdie modele was begin ontwikkel vir Engels en ander tale later. Onlangs het verskeie Arabiese-spesifieke modele begin voorkom. Maar daar is beperk direk vergelykings tussen hierdie modele. In hierdie papier, ons evalueer die prestasie van 24 van hierdie modele op Arabiese sentiment en sarkasme opdekking. Ons resultate wys dat die modele wat die beste prestasie bereik het is die wat slegs Arabiese data opgelei word, insluitend dialektiese Arabiese, en gebruik 'n groter aantal parameters, soos die onlangs verlos MARBERT. Maar ons het aanmerk dat AraELECTRA een van die boonste uitvoerde modele is terwyl baie meer effektief is in sy rekenaar koste. Eindelik het die eksperimente op AraGPT2-variante lae prestasie gewys vergelyk met BERT-modele, wat wys dat dit dalk nie geskik kan wees vir klassifikasie-opdragte.", 'fa': 'معرفی مدل زبان\u200cهای تغییر دهنده\u200cای یک قدم انقلابی برای تحقیقات زبان طبیعی (NLP) است. این مدل\u200cها، مثل BERT، GPT و ELECTRA، به عنوان عملکرد هنری در بسیاری از کارهای NLP رهبری کردند. بیشتر از این مدلها در ابتدا برای انگلیسی و دیگر زبانهای دنبال شده اند. اخیرا چند مدل مخصوص عربی شروع به ظاهر شدن شد. با این حال، مقایسه مستقیم بین این مدل محدودیت دارد. در این کاغذ، ما عملکرد ۲۴ از این مدل را در مورد تشخیص احساسات عربی و سارکاسم ارزیابی می کنیم. نتیجه\u200cهای ما نشان می\u200cدهند که مدل\u200cها به بهترین عملکرد رسیدن آنها هستند که تنها بر داده\u200cهای عربی آموزش داده می\u200cشوند، شامل دیالکت عربی، و از تعداد بزرگتری پارامتر، مثل MARBERT که تازگی آزاد شده است استفاده می\u200cکنند. اما ما متوجه شدیم که آرالکترا یکی از بالاترین مدلهای اجرایی است در حالی که در هزینه های محاسبه اش بسیار موثرتر است. بالاخره، آزمایش\u200cهایی که روی تغییرات AraGPT2 در مقایسه با مدل BERT کمی نشان داده\u200cاند، که نشان می\u200cدهد که ممکن است برای وظیفه\u200cهای classification مناسب نباشد.', 'hy': 'Փոփոխիչների հիմնված լեզվի մոդելների ներդրումը հեղափոխական քայլ է եղել բնական լեզվի վերլուծության (ՆԼՊ) հետազոտության համար: Այս մոդելները, ինչպիսիք են Բերթը, GPT-ը և Էլեկտրան, հանգեցրին ամենաբարձր արտադրողություններին շատ ՆԼՊ-ի առաջադրանքներում: Այս մոդելներից շատերը սկզբում զարգացել են անգլերենի և այլ լեզուների համար, որոնք հետևում էին հետո: Վերջերս բազմաթիվ արաբական կոնկրետ մոդելներ սկսեցին զարգանալ: Այնուամենայնիվ, այս մոդելների միջև սահմանափակ անմիջական համեմատություններ կան: Այս աշխատանքում մենք գնահատում ենք արաբերական զգացմունքների և սարկազմի հայտնաբերման 24 մոդելների արտադրողությունը: Մեր արդյունքները ցույց են տալիս, որ լավագույն արդյունքները հասնելու մոդելները այն են, ովքեր սովորեցվում են միայն արաբական տվյալների վրա, ներառյալ դիալեկտալ արաբական և օգտագործում են ավելի մեծ քանակությամբ պարամետրեր, ինչպիսիք են օրինակ վերջերս հր Այնուամենայնիվ, մենք նկատեցինք, որ Արաելեկտրան ամենաարդյունավետ մոդելներից մեկն է, մինչդեռ շատ ավելի արդյունավետ է իր հաշվարկների արժեքը: Վերջապես, ԱրաGPT2 տարբերակների փորձարկումները ցույց տվեցին ցածր արդյունավետություն BER մոդելների հետ համեմատած, ինչը ցույց է տալիս, որ այն հնարավոր է, որ չի համապատասխանում դասակարգման խնդիրների համար:', 'az': 'transformer-based dil modell…ôrin tanńĪŇümasńĪ t…ôbi…ôtli dil iŇül…ôm…ôsi (NLP) araŇütńĪrmasńĪ √ľ√ß√ľn d…ôyiŇüiklik adńĪmdńĪr. Bu modell…ôr, BERT, GPT v…ô ELECTRA kimi, NLP iŇül…ôrinin √ßoxluńüunda m√∂vcuddur. Bu modell…ôrin …ôks…ôriyy…ôti ilk d…ôf…ô ńįngiliz…ô v…ô dig…ôr dill…ôr √ľ√ß√ľn t…ôhsil edildi. Son zamanlarda bir ne√ß…ô …ôr…ôb m…ôs…ôl…ôsi modeli ortaya √ßńĪxdńĪ. Ancaq bu modell…ôrin arasńĪnda m√ľ…ôyy…ôn m√ľdd…ôtl…ôr var. Bu kańüńĪzda, …ôr…ôb hissl…ôri v…ô sarkasm keŇüfetm…ôsi bar…ôsind…ôki 24 modell…ôrin performansńĪnńĪ deńüerl…ôŇüdiririk. Sonu√ßlarńĪmńĪz …ôn yaxŇüńĪ performans √ßatmaq modell…ôrinin yalnńĪz …ôr…ôb m…ôlumatlarńĪna t…ôhsil edil…ônl…ôrin, dialektal …ôr…ôb m…ôlumatlarńĪna dahil edil…ônl…ôrin v…ô yenid…ôn √ßńĪxarńĪlmńĪŇü MARBERT kimi daha b√∂y√ľk bir sayńĪ parametru istifad…ô edirl…ôr. Lakin biz AraELECTRA, hesablama maliyy…ôtind…ô daha faydalńĪ olan …ôn y√ľks…ôk performans modellerind…ôn biridir. Sonunda, AraGPT2 variantlarńĪndakńĪ eksperimentl…ôr BERT modell…ôri il…ô qarŇüńĪlaŇüdńĪńüńĪ d√ľŇü√ľk performans g√∂st…ôrdil…ôr, bu da klasifikasiya iŇül…ôri √ľ√ß√ľn uyńüun olmadńĪńüńĪnńĪ g√∂st…ôrir.', 'sq': 'Futja e modeleve gjuhësore bazuar në transformues ka qenë një hap revolucionar për kërkimin e procesimit natyror të gjuhës (NLP). Këto modele, të tilla si BERT, GPT dhe ELECTRA, çuan në shfaqje më të larta në shumë detyra NLP. Shumica e këtyre modeleve u zhvilluan fillimisht për anglisht dhe gjuhë të tjera u ndoqën më vonë. Kohët e fundit, filluan të dalin disa modele specifike arabe. Megjithatë, ka krahasime të kufizuara të drejtpërdrejta midis këtyre modeleve. Në këtë letër, ne vlerësojmë shfaqjen e 24 prej këtyre modeleve mbi ndjenjat arabe dhe zbulimin e sarkazmit. Rezultatet tona tregojnë se modelet që arrijnë performancën më të mirë janë ato që janë stërvitur vetëm në të dhënat arabe, duke përfshirë dialektalin arab, dhe përdorin një numër më të madh parametrash, të tillë si MARBERT i lëshuar kohët e fundit. Megjithatë, ne vëmë re se AraELECTRA është një nga modelet më të performantë ndërsa është shumë më efikas në koston e saj llogaritës. Më në fund, eksperimentet mbi variantet e AraGPT2 treguan performancë të ulët krahasuar me modelet BERT, gjë që tregon se mund të mos jetë e përshtatshme për detyra klasifikuese.', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার (এনএলপি) গবেষণার জন্য বিপ্লবী পদক্ষেপ। এই মডেল, যেমন বের্ট, জিপিটি এবং এলেক্ট্রা, অনেক এনএলপি কাজের মধ্যে শিল্প-শিল্পের প্রতিষ্ঠানের দায়িত্ব প্রদর্শন করেছে। এদের বেশীরভাগ মডেল প্রথমে ইংরেজি এবং অন্যান্য ভাষার জন্য উন্নয়ন করা হয়েছিল। সম্প্রতি বেশ কিছু আরবী নির্দিষ্ট মডেল উঠতে শুরু করেছে। তবে এই মডেলের মধ্যে সরাসরি তুলনা সীমিত আছে। এই কাগজটিতে আমরা আরবী অনুভূতি এবং বিদ্রূপ আবিষ্কারের ২৪ জন মডেলের প্রদর্শনের মূল্যায়ন করি। আমাদের ফলাফল দেখা যাচ্ছে যে ভালো প্রদর্শনের মডেল হচ্ছে যারা শুধুমাত্র আরবী তথ্যে প্রশিক্ষণ প্রদান করা হয়েছে, যার মধ্যে ডায়ালেক্টাল আরবী রয়েছে এবং বেশ However, we noticed that AraELECTRA is one of the top performing models while being much more efficient in its computational cost.  অবশেষে, আরাজিপিটি২ ভেরেন্টের পরীক্ষার পরীক্ষা দেখা গেছে বার্টি মডেলের তুলনায় কম প্রদর্শন করা হয়েছে, যা নির্দেশ করছে যে এটি ক্লাসিফাশন', 'am': 'የደረጃ ቋንቋ ምሳሌዎችን ለመግለጥ የፍጥረት ቋንቋ ምሳሌ (NLP) ትምህርት ለመግለጽ የዓመፀኛ ደረጃ ነው፡፡ እነዚህም ምሳሌዎች እንደ BERT፣ GPT እና ELECTRA በብዙ NLP ስራ የዓርቲ አካባቢ ሥርዓት አግኝተዋል፡፡ እነዚህ ምሳሌዎች በመጀመሪያ ለመጀመሪያ ለእንግሊዝኛ እና ሌሎች ቋንቋዎች ተለይተዋል፡፡ በቅርቢቱ ዘመን ብዙ አረቢ-የተለያዩ ዓይነቶች ሲወጡ ጀመሩ፡፡ ነገር ግን በዚህ ዓይነቶች መካከል ቀጥተኛ ተሳካቾች አሉ፡፡ በዚህ ካላት፣ የእነዚህን 24 ምሳሌዎች በአረብኛ ስሜት እና የሳርካሲም ማስታወቂያውን እናሳውቃለን፡፡ ፍሬዎቻችን መልካሙን የድምፅ ሥርዓት ማግኘት ምሳሌዎች በዐረብኛ ዳታ ብቻ የተማሩ ናቸው፡፡ እናም አረቢካዊ አረብኛ እና በተለየው ማርብERT እንደሆነ የበለጠ ምርጫዎች የሚጠይቁ ናቸው፡፡ ነገር ግን AraELECTRA ከቁጥጥር ዋጋው እጅግ የበለጠ ሆኖ ከላይኛው የድምፅ አካባቢ መሆኑን አየን፡፡ በመጨረሻው የAraGPT2 variant ፈተናዎች BERT ሞዴላዎችን ከመተካከል ትንሽ አድራሻ ያሳየዋል፡፡', 'bs': 'Uvedenje jezičkih modela na transformaciji bio je revolucionarni korak za istraživanje prirodnog jezika (NLP). Ovi modeli, kao što su BERT, GPT i ELECTRA, doveli su do postupka umjetnosti u mnogim zadacima NLP-a. Većina ovih modela je početno razvijena za engleski i drugi jezici nakon toga. Nedavno se pojavilo nekoliko arapskih modela. Međutim, postoje ograničene direktne usporedbe između tih modela. U ovom papiru procjenjujemo izvršnost 24 ovih modela o arapskom osjećaju i detekciji sarkazma. Naši rezultati pokazuju da su modeli koji ostvaruju najbolji performans oni koji su obučeni samo na arapskim podacima, uključujući dijalektno arapski, i koriste veći broj parametara, poput nedavno oslobođenog MARBERT-a. Međutim, primetili smo da je AraELECTRA jedan od najboljih modela izvršavanja dok je mnogo efikasniji u svojim računalnim troškovima. Konačno, eksperimenti na varijantima AraGPT2 pokazali su nisku funkciju u usporedbi s modelima BERT-a, što ukazuje na to da možda nije odgovarajuće za klasifikacijske zadatke.', 'cs': 'Zavedení transformátorových jazykových modelů bylo revolučním krokem pro výzkum zpracování přirozeného jazyka (NLP). Tyto modely, jako jsou BERT, GPT a ELECTRA, vedly k nejmodernějšímu výkonu v mnoha úkolech NLP. Většina z těchto modelů byla původně vyvinuta pro angličtinu a další jazyky následovaly později. Nedávno se začalo objevovat několik arabských modelů. Přímé srovnání mezi těmito modely však existuje omezené. V tomto článku hodnotíme výkon 24 těchto modelů na detekci arabského sentimentu a sarkasmu. Naše výsledky ukazují, že modely dosahující nejlepšího výkonu jsou ty, které jsou trénovány pouze na arabských datech, včetně dialektální arabštiny, a používají větší počet parametrů, jako je například nedávno vydaný MARBERT. Nicméně jsme si všimli, že AraELECTRA je jedním z nejvýkonnějších modelů a zároveň je mnohem efektivnější ve svých výpočetních nákladech. Nakonec experimenty na variantách AraGPT2 ukázaly nízký výkon ve srovnání s BERT modely, což naznačuje, že nemusí být vhodné pro klasifikační úlohy.', 'ca': "L'introducció de models de llenguatge basats en transformadors ha estat un pas revolucionari per a la recerca sobre el processament natural de llenguatges (NLP). Aquests models, com BERT, GPT i ELECTRA, van portar a un rendiment més avançat en moltes tasques del NLP. La majoria d'aquests models van ser desenvolupats inicialment per anglès i altres llengües seguides més tard. Recentment, van començar a aparèixer varis models àrabs específics. Però hi ha comparacions directes limitades entre aquests models. En aquest article, evaluem el rendiment de 24 d'aquests models sobre el sentiment àrab i la detecció del sarcàsme. Els nostres resultats demostren que els models que aconsegueixen el millor rendiment són aquells que s'entrenen només en dades àrabs, incloent l'àrab dialectal, i utilitzen un nombre més gran de paràmetres, com el MARBERT publicat recentment. Però ens vam adonar que AraELECTRA és un dels models de millor rendiment mentre és molt més eficient en el seu cost computacional. Finalment, els experiments en variants AraGPT2 van mostrar baix rendiment comparat amb els models BERT, que indica que potser no és adequat per a tasques de classificació.", 'ko': '변환기 기반 언어 모델의 도입은 자연언어처리(NLP) 연구의 혁명적인 한 걸음이다.이러한 모델, 예를 들어 BERT, GPT, ELECTRA는 많은 NLP 작업에서 가장 선진적인 성능을 실현했다.대부분의 모델은 처음에는 영어를 위해 개발되었지만, 나중에는 다른 언어를 위해 개발되었다.최근 일부 아랍 특유의 패턴이 등장하기 시작했다.그러나 이들 모델 간의 직접적인 비교는 한계가 있다.본고에서 우리는 그 중 24개의 모델이 아랍 정서와 풍자 검측 방면에서의 성능을 평가했다.우리의 결과에 따르면 가장 좋은 성능을 얻은 모델은 아랍어 데이터(아랍어 사투리 포함)만 기반으로 훈련된 모델이며 최근에 발표된 MARBERT 등 대량의 파라미터를 사용했다.그러나 AraELECTRA는 성능이 가장 좋은 모델 중 하나이며 원가 계산에 있어 효율이 높다는 것을 알아차렸다.마지막으로, AraGPT2 변형의 실험은 버트 모델에 비해 성능이 낮은 것으로 나타나 분류 작업에 적합하지 않을 수 있음을 나타냈다.', 'et': 'Transformaatoril põhinevate keelemudelite kasutuselevõtt on olnud revolutsiooniline samm looduskeele töötlemise (NLP) uurimistöös. Need mudelid, nagu BERT, GPT ja ELECTRA, viisid kaasaegse jõudluseni paljudes NLP ülesannetes. Enamik neist mudelitest töötati algselt välja inglise keele ja hiljem järgnesid teistele keeltele. Hiljuti hakkasid tekkima mitmed araabia-spetsiifilised mudelid. Nende mudelite vahel on siiski piiratud otsesed võrdlused. Käesolevas töös hindame 24 mudeli tulemuslikkust araabia sentimentaalsuse ja sarkasmi tuvastamisel. Meie tulemused näitavad, et parimat jõudlust saavutavad mudelid on need, mis on koolitatud ainult araabia andmetel, sealhulgas dialektilisel araabia keelel, ja kasutavad suuremat hulka parameetreid, näiteks hiljuti välja lastud MARBERT. Siiski märkasime, et AraELECTRA on üks parimaid tulemuslikke mudeleid, olles samas arvutuskulude poolest palju tõhusam. Lõpuks näitasid AraGPT2 variantidega tehtud katsed BERT mudelitega võrreldes madalat jõudlust, mis näitab, et see ei pruugi klassifitseerimisülesannete jaoks sobida.', 'fi': 'Muuntajapohjaisten kielimallien käyttöönotto on ollut vallankumouksellinen askel luonnollisen kielen prosessoinnin (NLP) tutkimuksessa. Nämä mallit, kuten BERT, GPT ja ELECTRA, johtivat huippuluokan suorituskykyyn monissa NLP-tehtävissä. Suurin osa näistä malleista kehitettiin aluksi englanniksi ja muita kieliä myöhemmin. Viime aikoina alkoi syntyä useita arabiakohtaisia malleja. Näiden mallien välillä on kuitenkin vain vähän suoria vertailuja. Tässä työssä arvioimme 24 mallin suorituskykyä arabialaisen tunteen ja sarkasmin havaitsemisessa. Tuloksemme osoittavat, että parhaiten suoriutuvat mallit on koulutettu vain arabialaisella datalla, mukaan lukien dialektinen arabia, ja niissä käytetään suurempaa määrää parametreja, kuten äskettäin julkaistu MARBERT. Huomasimme kuitenkin, että AraELECTRA on yksi suorituskykyisimmistä malleista, mutta sen laskennalliset kustannukset ovat paljon tehokkaampia. Lopuksi AraGPT2-varianttien kokeet osoittivat heikkoa suorituskykyä verrattuna BERT-malleihin, mikä osoittaa, että se ei ehkä sovellu luokitustehtäviin.', 'he': 'ההצגה של דוגמני שפת מבוססים על משנה הייתה צעד מהפכה עבור מחקר עיבוד שפת טבעי (NLP). דוגמנים אלה, כמו BERT, GPT ואלקטרה, הובילו להופעה מוקדמת במשימות רבות NLP. רוב הדוגמנים האלה התפתחו בהתחלה לאנגלית ואחר כך לשפות אחרות. לאחרונה, כמה דוגמנים ספציפיים לערבים התחילו להתגלות. עם זאת, יש שיוואות ישירות מוגבלות בין הדוגמנים האלה. בעיתון הזה, אנו מעריכים את ההופעה של 24 מהדוגמנים האלה על רגשות ערביים וגילוי סרקזם. התוצאות שלנו מראות שהדוגמנים שמגיעים להופעה הטובה ביותר הם אלה שאומנים רק על נתונים ערביים, כולל ערביים דיאלקטאליים, ושימושים במספר גדול יותר של פרמטרים, כמו MARBERT השחרר לאחרונה. בכל אופן, שמנו לב שאראאלקטרה היא אחת מהמודלים המופעילים ביותר בעוד היא הרבה יותר יעילה בעלות החישוב שלה. סוף סוף, הניסויים על שונים AraGPT2 הראו ביצועים נמוכים בהשוואה לדוגמנים BERT, מה שמצביע שאולי זה לא מתאים למשימות מסווג.', 'ha': "An introduce wa misãlai masu shige da aka baka cikin harshen zuwa (NLP) ta kasance wata ƙyama mai revolutionary wa aikin aiki na fassarar harshen asimi (NLP). Wannan misãlai, kamar BERT, GPT da ELEctra, sun led to-state-of-art cikin wasu aikin NLP. Babu yawa daga waɗannan misalin aka buɗe su wajen farko wa harshen Ingiriya da wasu harshe daban. A yanzu, misãlai masu cikin arabu na fara ta fara. A lokacin da za'a sami masu daidaita tsakanin waɗannan misalin. Ga wannan takardan, Munã ƙaddara aikin waɗannan misalin 24 na zama a kan gane na akan arabu da sarkasm. MatamayinMu na nũna cewa misãlai da ke sãmu mafi kyaun aikin ƙwarai su ne waɗand a aka sanar da su a kan data na Larabci kawai, da kuma masu yin amfani da tsarin masu ƙaranci, kamar da aka saka na MARBERT a yanzu. A lokacin da muka gane, AraELEctra yana daga saman mai nuna samoyi, kuma yana da mafi kyauta cikin aikin lissafi. Ga ƙarshe, jarrabai da variants na AraGPT2 suka nuna mai rauni ga performance sami da misãlai na BERT, da yana kasa kasa kasa da daidai ga aikin classified.", 'sk': 'Uvedba transformatorskih jezikovnih modelov je bil revolucionaren korak za raziskave obdelave naravnega jezika (NLP). Ti modeli, kot so BERT, GPT in ELECTRA, so pripeljali do najsodobnejšega delovanja pri številnih nalogah NLP. Večina teh modelov je bila sprva razvita za angleščino, kasneje pa za druge jezike. Nedavno se je začelo pojavljati več arabskih modelov. Vendar pa so neposredne primerjave med temi modeli omejene. V prispevku smo ocenili učinkovitost 24 teh modelov pri odkrivanju arabskega sentimenta in sarkazma. Naši rezultati kažejo, da so modeli, ki dosegajo najboljšo zmogljivost, tisti, ki so usposobljeni samo na arabskih podatkih, vključno z dialektično arabsko, in uporabljajo večje število parametrov, kot je nedavno izdan MARBERT. Vendar smo opazili, da je AraELECTRA eden izmed najbolj uspešnih modelov, hkrati pa je veliko bolj učinkovit v svojih računskih stroških. Končno, eksperimenti na različicah AraGPT2 so pokazali nizko učinkovitost v primerjavi z modeli BERT, kar kaže, da morda ni primeren za klasifikacijske naloge.', 'jv': 'Wang tengah nggawe model sing paling transformer sampeyan anyar tentang kanggo ngilangno nggawe barang nggawe idiomatan (NLP). model iki, koyo ngono BERT, GLPT karo el ESTRA, dadi neng langgar-langgar dadi state-of-the-arts seneng akeh operasi NLP. Banyak kudu model iki dadi bisa ditambah kanggo ingkang karo tindan liyane wis maning, dadi. Neng-jejer, sampeyan karo model sing paling arap kuwi bisa nguasah. politenessoffpolite"), and when there is a change ("assertive Awak dhéwé éntuk kuwi, awak dhéwé éntuk kanggo ngerasakno karo 24 model iki dadi, nik awak dhéwé kuwi matèran karo sarkasm. Rejalekan dhéwé menehi ngomong nik model sing gawe nggawe akeh luwih dumadhi iki dadi arap, dialectal arab sing berarti, lan nambah akeh parameter sing wis luwih dumadhi, koyok ngono MARBERT nganggo akeh dhéwé. Nanging, awak dhéwé ngerasakno nêmêng, araélecTRA kuwi banjuré sing paling apik model sing bisa basa sing luwih nêmên ngerasakno ning kompjuter Ngubah ngono, suratan karo variante araPPT 2 iki wis kelas pipilihan karo model BERT, sing ngomong nik nik singakake ora iso ngejarakake nggawe tasks', 'bo': 'འགྱུར་བརྗོད་པ་དང་གཞུང་བརྟེན་པའི་སྐད་རིགས་དཔེ་གཞི་ཚོགས་དེ་ནི་མཐུན་རྒྱུན་གྱི་སྐད་རིགས་ལས་འཚོལ་བཤེར་དང་། དཔེར་ན། BERT། GPT དང་ ELECTRA འདི་དག་གིས་NLP ལས་སྒྲུབ་མང་ཙམ་ནང་གི་སྣང་གནས་སྟངས་འདི་དག་རེད། སྔོན་ལ་གྱི་མིག་དཔེ་འདི་དག་ཆེ་ཤོས་རང་ཉིད་ཀྱི་དབྱིན་ཡིག་དང་སྐད་རིགས་གཞན་ཞིག་གིས་རྗེས་སུ་ ཉེ་ཆར་བར་ན། ཨ་རབ་ཀྱི་མ་དབྱིབས་དམིགས་བསལ་བ་མང་པོ་ཞིག་འགོ་འཛུགས་བྱུང་། ཡིན་ནའང་། མ་དབྱིབས་འདི་དག་དབར་གྱི་སྡོམ་རིས་ཐང་ཀང་བ་ཁག་པོ་ཡོད་པ་རེད། འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྣམ་པ་གཉིས་ཀྱི་ལས་འགན་སྟངས་ལ་བསམ་བློ་གཏོང་རྒྱུ་དེ་རེད། Our results show that the models achieving the best performance are those that are trained on only Arabic data, including dialectal Arabic, and use a larger number of parameters, such as the recently released MARBERT. Examples: ཡིན་ནའང་། AraELECTRA ནི་རྩིས་འཁོར་གྱི་སྐྱེས་པའི་མིག་དཔེ་ལས་དེ་ལས་མཐོང་ནུས་མཐོང་བ་དེ་རེད། མཐའ་མར་རང་ AraGPT2་ཡི་སྒེར་གྱི་བརྟག་ཞིག་དག་གིས་BERT དཔེ་དབྱིབས་དང་མཐུན་རྐྱེན་ཚད་ཉུང་བའི་མཐུན་རྐྱེན་བྱེད་སྣང་བྱེད་ཐུབ་མེ'}
{'en': 'Kawarith : an Arabic Twitter Corpus for Crisis Events', 'ar': 'كوارث: مجموعة تويتر عربية لأحداث الأزمات', 'fr': 'Kawarith\xa0: un corpus Twitter arabe pour les événements de crise', 'pt': 'Kawarith: um corpus do Twitter em árabe para eventos de crise', 'es': 'Kawarith: un corpus de Twitter en árabe para eventos de crisis', 'ja': 'Kawarith:アラビア語のツイッターコーパス', 'zh': 'Kawarith:危机阿拉伯语Twitter语料库', 'ru': 'Kawarith: арабский Twitter Corpus for Crisis Events', 'hi': 'Kawarith: संकट घटनाओं के लिए एक अरबी चहचहाना कॉर्पस', 'ga': 'Kawarith: Corpas Twitter Araibis le haghaidh Imeachtaí Géarchéime', 'ka': 'Name', 'hu': 'Kawarith: egy arab Twitter Corpus a válsághelyzetekért', 'el': 'Kawarith: Ένα Αραβικό Σώμα Twitter για τα γεγονότα κρίσης', 'it': 'Kawarith: un corpo Twitter arabo per eventi di crisi', 'kk': 'Каварит: Кризис оқиғаларының араб Твиттер корпус', 'ms': 'Kawarith: an Arabic Twitter Corpus for Crisis Events', 'ml': 'കാവാരിത്: പ്രശ്നത്തിനുവേണ്ടി ഒരു അറബി ട്രൂട്ടെര്\u200d കോര്\u200dപ്പുസ്', 'mt': "Kawarith: Korp Għarbi ta' Twitter għal Avvenimenti ta' Kriżi", 'mn': 'Каварит: Араб Твиттерийн хувьд', 'no': 'Kawarith: ein arabisk Twitter- korpus for krissehendingar', 'pl': 'Kawarith: arabski korpus twitterowy na rzecz wydarzeń kryzysowych', 'mk': 'Каварит: Арапски Твитер корпус за кризни настани', 'ro': 'Kawarith: un corpus Twitter arab pentru evenimentele de criză', 'sr': 'Kawarith: Arapski Twitter korpus za krizne događaje', 'si': 'Name', 'so': 'Kawarith: Korpus af Carabi ah ee dhacdooyinka xasaradaha', 'ta': 'காவாரித்: சிக்கல் நிகழ்வுகளுக்கான ஒரு அரபி தொடர்பு கார்புஸ்', 'sv': 'Kawarith: en arabisk Twitter-korpus för krishändelser', 'ur': 'کاواریث: ایک عربی ٹویٹر کورپوس کیسیس ایڈمنٹ کے لئے', 'lt': 'Kavaritas: Arabų Twitter korpusas krizių įvykiams', 'uz': 'Kawarith: Muhim hodisalar uchun arab Twitterning Korpus', 'vi': 'Kawarith: an Ả Rập Twitter Corpus for Crisis events', 'hr': 'Kawarith: Arapski Twitter korpus za krizne događaje', 'da': 'Kawarith: et arabisk Twitter korpus for krisebegivenheder', 'bg': 'Каварит: арабски Туитър корпус за кризисни събития', 'nl': 'Kawarith: een Arabisch Twitter Corpus voor crisisgebeurtenissen', 'de': 'Kawarith: ein arabisches Twitter-Korpus für Krisen-Ereignisse', 'id': 'Kawarith: Korpus Twitter Arab untuk Peristiwa Krisis', 'ko': 'Kawarith: 위기 사건에 사용되는 아랍어 트위터 자료 라이브러리', 'fa': 'کاواریت: یک کورپوس توئیتر عربی برای اتفاقات کریسیس', 'tr': 'Kawarit:', 'sq': 'Kavarit: një Korp Arab Twitter për ngjarje krize', 'am': 'ካዋሪት: አረቢኛ ትዊተር ኮርፓስ ለጉዳይ ጉዳይ', 'sw': 'Kawarith: Shirika la Twita la Kiarabu la Matukio', 'af': 'Name', 'hy': 'Կավարիթ. Արաբական Թվիթերի Կորպուսը ճգնաժամի իրադարձությունների համար', 'bn': 'কাওয়ারিথ: সংকটের জন্য আরবী টুইটার কোর্পাস', 'bs': 'Kawarith: Arapski Twitter korpus za krizne događaje', 'ca': 'Kawarith: Un cos àrab de Twitter per eventos de crisi', 'cs': 'Kawarith: arabský Twitter sbor pro krizové události', 'az': 'Kawarith: Crisis Eventlar캼 칲칞칲n 톛r톛bc톛 Twitter korpusu', 'fi': 'Kawarith: Arabian Twitter Corpus kriisitapahtumia varten', 'et': 'Kawarith: Araabia Twitter korpus kriisisündmuste jaoks', 'jv': 'Kawarwith:', 'he': 'קאורית: גוף טוויטר ערבי לאירועי משבר', 'ha': 'Kawarith: KCharselect unicode block name', 'bo': 'Kawarith:ཨ་རབ་གྱི་ཌིས་ཌིར་གཡོན་གྱི་གནད་དོན་འགྱུར་བ་དང་།', 'sk': 'Kawarith: arabski Twitter korpus za krizne dogodke'}
{'en': 'Social media (SM) platforms such as Twitter provide large quantities of real-time data that can be leveraged during mass emergencies. Developing tools to support crisis-affected communities requires available datasets, which often do not exist for low resource languages. This paper introduces Kawarith a multi-dialect Arabic Twitter corpus for crisis events, comprising more than a million Arabic tweets collected during 22 crises that occurred between 2018 and 2020 and involved several types of hazard. Exploration of this content revealed the most discussed topics and information types, and the paper presents a labelled dataset from seven emergency events that serves as a gold standard for several tasks in crisis informatics research. Using annotated data from the same event, a BERT model is fine-tuned to classify tweets into different categories in the multi- label setting. Results show that BERT-based models yield good performance on this task even with small amounts of task-specific training data.', 'fr': "Les plateformes de médias sociaux (SM) telles que Twitter fournissent de grandes quantités de données en temps réel qui peuvent être exploitées lors de situations d'urgence de masse. Le développement d'outils pour soutenir les communautés touchées par des crises nécessite des ensembles de données disponibles, qui n'existent souvent pas pour les langues à faibles ressources. Cet article présente Kawarith, un corpus Twitter arabe multi-dialecte pour les événements de crise, comprenant plus d'un million de tweets en arabe collectés lors de 22 crises survenues entre 2018 et 2020 et impliquant plusieurs types de risques. L'exploration de ce contenu a révélé les sujets et les types d'informations les plus discutés, et l'article présente un ensemble de données étiqueté de sept événements d'urgence qui sert de référence pour plusieurs tâches dans la recherche informatique de crise. À l'aide de données annotées provenant du même événement, un modèle BERT est affiné pour classer les tweets en différentes catégories dans le paramètre multi-étiquettes. Les résultats montrent que les modèles basés sur BERT offrent de bonnes performances pour cette tâche, même avec de petites quantités de données d'entraînement spécifiques à la tâche.", 'ar': 'توفر منصات الوسائط الاجتماعية (SM) مثل Twitter كميات كبيرة من البيانات في الوقت الفعلي التي يمكن الاستفادة منها أثناء حالات الطوارئ الجماعية. يتطلب تطوير أدوات لدعم المجتمعات المتضررة من الأزمات مجموعات بيانات متاحة ، والتي لا توجد غالبًا للغات منخفضة الموارد. تقدم هذه الورقة لكواريث مجموعة تغريدات عربية متعددة اللهجات لأحداث الأزمات ، تضم أكثر من مليون تغريدة عربية تم جمعها خلال 22 أزمة حدثت بين عامي 2018 و 2020 وتضمنت عدة أنواع من المخاطر. كشف استكشاف هذا المحتوى عن الموضوعات وأنواع المعلومات الأكثر مناقشة ، وتقدم الورقة مجموعة بيانات معنونة من سبعة أحداث طارئة تعمل كمعيار ذهبي للعديد من المهام في أبحاث معلوماتية الأزمات. باستخدام البيانات المشروحة من نفس الحدث ، تم ضبط نموذج BERT جيدًا لتصنيف التغريدات إلى فئات مختلفة في الإعداد متعدد التسميات. تظهر النتائج أن النماذج المستندة إلى BERT تحقق أداءً جيدًا في هذه المهمة حتى مع وجود كميات صغيرة من بيانات التدريب الخاصة بالمهمة.', 'es': 'Las plataformas de redes sociales (SM), como Twitter, proporcionan grandes cantidades de datos en tiempo real que se pueden aprovechar durante emergencias masivas. El desarrollo de herramientas para apoyar a las comunidades afectadas por crisis requiere conjuntos de datos disponibles, que a menudo no existen para los idiomas de bajos recursos. Este artículo presenta Kawarith, un corpus de Twitter en árabe multidialecto para eventos de crisis, que comprende más de un millón de tuits en árabe recopilados durante 22 crisis que ocurrieron entre 2018 y 2020 y que implicaron varios tipos de peligro. La exploración de este contenido reveló los temas y tipos de información más discutidos, y el documento presenta un conjunto de datos etiquetado de siete eventos de emergencia que sirve como estándar de oro para varias tareas en la investigación de informática de crisis. Con datos anotados del mismo evento, se ajusta un modelo BERT para clasificar los tuits en diferentes categorías en la configuración de etiquetas múltiples. Los resultados muestran que los modelos basados en BERT ofrecen un buen rendimiento en esta tarea, incluso con pequeñas cantidades de datos de capacitación específicos de la tarea.', 'pt': 'Plataformas de mídia social (SM), como o Twitter, fornecem grandes quantidades de dados em tempo real que podem ser aproveitados durante emergências em massa. O desenvolvimento de ferramentas para apoiar comunidades afetadas por crises requer conjuntos de dados disponíveis, que muitas vezes não existem para idiomas de poucos recursos. Este artigo apresenta Kawarith um corpus de Twitter em árabe multidialeto para eventos de crise, compreendendo mais de um milhão de tweets em árabe coletados durante 22 crises que ocorreram entre 2018 e 2020 e envolveram vários tipos de risco. A exploração desse conteúdo revelou os tópicos e tipos de informações mais discutidos, e o artigo apresenta um conjunto de dados rotulados de sete eventos de emergência que serve como padrão-ouro para várias tarefas na pesquisa de informática de crise. Usando dados anotados do mesmo evento, um modelo BERT é ajustado para classificar os tweets em diferentes categorias na configuração de vários rótulos. Os resultados mostram que os modelos baseados em BERT apresentam bom desempenho nesta tarefa, mesmo com pequenas quantidades de dados de treinamento específicos da tarefa.', 'ja': 'Twitterなどのソーシャルメディア（ SM ）プラットフォームは、大量の緊急時に活用できる大量のリアルタイムデータを提供します。 危機の影響を受けるコミュニティをサポートするためのツールを開発するには、利用可能なデータセットが必要ですが、これは多くの場合、リソースの少ない言語には存在しません。 この論文では、2018年から2020年にかけて発生した22の危機の間に収集された100万を超えるアラビア語のツイートで構成され、いくつかの種類の危険を伴う、危機事象のための多方言のアラビア語ツイッターコーパスであるKawarithを紹介します。 このコンテンツの探索は、最も議論されたトピックと情報タイプを明らかにし、この論文は、危機情報学研究のいくつかのタスクのゴールドスタンダードとなる7つの緊急事態からのラベル付きデータセットを提示している。 同じイベントからの注釈付きデータを使用して、BERTモデルを微調整して、マルチラベル設定でツイートを異なるカテゴリに分類します。 結果は、BERTベースのモデルは、少量のタスク固有のトレーニングデータであっても、このタスクで良好なパフォーマンスを発揮することを示しています。', 'zh': 'Twitter等社交媒体(SM)台大给实时数,可大用此数。 开支危殆社区器用所须数集,而低资源言语常无此数集。 本文言于Kawarith危机之事者多方言阿拉伯语Twitter语料库,其在2018至2020之间者22次危机之间,收拾者过一百万条阿拉伯语推文,涉几危之危。 探论最多,与信息相类,而七紧急事件标数集,数集是危机信息学治中几项黄金之准。 用同事带注之数,微调 BERT 模,以多标置中将推文分类为异。 结果表明虽少特定于任数,BERT形于任。', 'hi': 'ट्विटर जैसे सोशल मीडिया (एसएम) प्लेटफ़ॉर्म बड़ी मात्रा में वास्तविक समय डेटा प्रदान करते हैं जिन्हें बड़े पैमाने पर आपात स्थितियों के दौरान लाभ उठाया जा सकता है। संकट प्रभावित समुदायों का समर्थन करने के लिए उपकरण विकसित करने के लिए उपलब्ध डेटासेट की आवश्यकता होती है, जो अक्सर कम संसाधन भाषाओं के लिए मौजूद नहीं होते हैं। यह पेपर कावरिथ को संकट की घटनाओं के लिए एक बहु-बोली अरबी ट्विटर कॉर्पस का परिचय देता है, जिसमें 2018 और 2020 के बीच हुए 22 संकटों के दौरान एकत्र किए गए एक मिलियन से अधिक अरबी ट्वीटशामिल हैं और इसमें कई प्रकार के खतरे शामिल हैं। इस सामग्री की खोज से सबसे अधिक चर्चा किए गए विषयों और सूचना प्रकारों का पता चला, और पेपर सात आपातकालीन घटनाओं से एक लेबल डेटासेट प्रस्तुत करता है जो संकट सूचना विज्ञान अनुसंधान में कई कार्यों के लिए एक सोने के मानक के रूप में कार्य करता है। एक ही घटना से एनोटेट किए गए डेटा का उपयोग करते हुए, एक BERT मॉडल को मल्टी-लेबल सेटिंग में विभिन्न श्रेणियों में ट्वीट्स को वर्गीकृत करने के लिए ठीक किया जाता है। परिणाम बताते हैं कि BERT-आधारित मॉडल इस कार्य पर अच्छा प्रदर्शन करते हैं, यहां तक कि कार्य-विशिष्ट प्रशिक्षण डेटा की छोटी मात्रा के साथ भी।', 'ru': 'Платформы социальных сетей (SM), такие как Twitter, предоставляют большое количество данных в режиме реального времени, которые могут быть использованы во время массовых чрезвычайных ситуаций. Для разработки инструментов поддержки общин, затронутых кризисом, требуются имеющиеся наборы данных, которые зачастую отсутствуют для языков с ограниченными ресурсами. В этой статье Kawarith представляет мультидиалектный арабский Twitter-корпус для кризисных событий, включающий более миллиона арабских твитов, собранных во время 22 кризисов, которые произошли в период с 2018 по 2020 год и включали несколько типов опасностей. Изучение этого содержания выявило наиболее обсуждаемые темы и типы информации, и в документе представлен маркированный набор данных по семи чрезвычайным ситуациям, который служит золотым стандартом для нескольких задач в исследованиях в области кризисной информатики. Используя аннотированные данные одного и того же события, модель BERT тонко настраивается для классификации твитов по различным категориям в настройках с несколькими метками. Результаты показывают, что модели, основанные на BERT, дают хорошие результаты в выполнении этой задачи даже при небольшом объеме данных о подготовке, связанной с конкретными задачами.', 'ga': 'Soláthraíonn ardáin meán sóisialta (SM) ar nós Twitter méideanna móra sonraí fíor-ama ar féidir iad a ghiaráil le linn olléigeandálaí. Teastaíonn tacair shonraí atá ar fáil chun uirlisí a fhorbairt chun tacú le pobail atá buailte ag géarchéimeanna, nach mbíonn ann go minic do theangacha lagacmhainne. Tugann an páipéar seo isteach corpas ilchanúint Araibis Twitter Kawraith le haghaidh imeachtaí géarchéime, ina bhfuil níos mó ná milliún tweets Araibis a bailíodh le linn 22 géarchéime a tharla idir 2018 agus 2020 agus a bhain go leor cineálacha guaise. Nocht iniúchadh an ábhair seo na hábhair agus na cineálacha faisnéise is mó a pléadh, agus cuireann an páipéar tacar sonraí lipéadaithe ó sheacht dteagmhas éigeandála i láthair a fheidhmíonn mar chaighdeán óir do roinnt tascanna i dtaighde faisnéisíochta géarchéime. Ag baint úsáide as sonraí anótáilte ón imeacht céanna, déantar samhail BERT a mhionchoigeartú chun tweets a rangú i gcatagóirí éagsúla sa socrú illipéid. Léiríonn torthaí go n-éiríonn go maith le samhlacha atá bunaithe ar BERT ar an tasc seo fiú le méideanna beaga sonraí oiliúna a bhaineann go sonrach le tasc.', 'el': 'Οι πλατφόρμες κοινωνικών μέσων (όπως το Twitter) παρέχουν μεγάλες ποσότητες δεδομένων σε πραγματικό χρόνο που μπορούν να χρησιμοποιηθούν κατά τη διάρκεια μαζικών καταστάσεων έκτακτης ανάγκης. Η ανάπτυξη εργαλείων για την υποστήριξη κοινοτήτων που πλήττονται από κρίση απαιτεί διαθέσιμα σύνολα δεδομένων, τα οποία συχνά δεν υπάρχουν για γλώσσες με χαμηλούς πόρους. Η παρούσα εργασία εισάγει το Kawarith ένα πολυδιαλεκτικό αραβικό σώμα Twitter για γεγονότα κρίσης, το οποίο περιλαμβάνει περισσότερα από ένα εκατομμύριο αραβικά tweets που συλλέχθηκαν κατά τη διάρκεια 22-κρίσεων που συνέβησαν μεταξύ 2018 και 2020 και περιελάμβαναν διάφορους τύπους κινδύνου. Η διερεύνηση αυτού του περιεχομένου αποκάλυψε τα πιο συζητημένα θέματα και τους τύπους πληροφοριών, και η εργασία παρουσιάζει ένα μαρκαρισμένο σύνολο δεδομένων από επτά συμβάντα έκτακτης ανάγκης που χρησιμεύει ως χρυσό πρότυπο για διάφορες εργασίες στην έρευνα πληροφορικής κρίσεων. Χρησιμοποιώντας σχολιασμένα δεδομένα από το ίδιο συμβάν, ένα μοντέλο προσαρμόζεται ώστε να ταξινομεί τα tweets σε διαφορετικές κατηγορίες στη ρύθμιση πολλαπλών ετικετών. Τα αποτελέσματα δείχνουν ότι τα μοντέλα με βάση το BERT αποδίδουν καλές επιδόσεις σε αυτή την εργασία ακόμη και με μικρές ποσότητες δεδομένων κατάρτισης ειδικά για την εργασία.', 'hu': 'A közösségi média (SM) platformok, mint például a Twitter, nagy mennyiségű valós idejű adatot biztosítanak, amelyek tömeges vészhelyzetek esetén felhasználhatók. A válság által érintett közösségek támogatására szolgáló eszközök kifejlesztéséhez rendelkezésre álló adatkészletek szükségesek, amelyek gyakran nem léteznek az alacsony erőforrású nyelvek esetében. Ez a tanulmány bemutatja a Kawarith egy több dialektusú arab Twitter korpuszát a válsághelyzetekre, amely több mint egymillió arab tweetet tartalmaz, amelyek a 2018 és 2020 között bekövetkezett 22 válság során gyűjtöttek össze, és több típusú veszélyt is magában foglaltak. Ennek a tartalomnak a feltárása feltárta a leginkább megvitatott témákat és információtípusokat, és a tanulmány hét vészhelyzeti eseményből származó címkézett adatkészletet mutat be, amely a válságinformatikai kutatások számos feladatának aranyszínvonalául szolgál. Ugyanabból az eseményből származó jegyzetelt adatok segítségével a BERT modellt finomhangoljuk, hogy a tweeteket különböző kategóriákba soroljuk a többcímkés beállításban. Az eredmények azt mutatják, hogy a BERT-alapú modellek jó teljesítményt nyújtanak ebben a feladatban, még kis mennyiségű feladatspecifikus edzési adat esetén is.', 'ka': 'სოციალური მედია (SM) პლატატურები, როგორც ტვირუტერი, უფრო დიდი მონაცემები რეალური დროის მონაცემები, რომლებიც შეიძლება მოიძლება მასური გა კრიზის განახლებელი საზოგადოებების გამოყენება საზოგადოებელი მონაცემები უნდა იყოს, რომლებიც ზოგიერთად არ არსებობს მცირე რესურსის ენების ამ კავარიტის შესახებ კავარიტის მრავალექტური არაბული Twitter კორპუსს კრიზის მოვლენებისთვის, რომელიც უფრო მეტი მილიონის აპაბული tweets, რომელიც შეიძლება 22 კრიზების განმავლობაში, რომელიც მოხდა 2018-2020 ამ ინფორმაციის გამოყენება აღმოჩნდა ყველაზე განსაკუთრებული ტემები და ინფორმაციის ტიპები, და აღმოჩნეთ შვიდი განსაკუთრებული მონაცემების ნაწილი, რომელიც კრიზის ინფორმაციის გამოყენებაში უფრო მე იგივე მოვლენისთვის მონიშნული მონაცემების გამოყენება, BERT მოდელის გამოყენება განსხვავებული კატეგორიებში განსხვავებული ტვირების კლასიფიკაციაში მრავალური რედაქტირებში. შედეგი გამოჩვენება, რომ BERT-ის ბაზეული მოდელები მარტივი გამოყენება ამ რაოდენობაზე მარტივი რაოდენობით სპექტიკური განათლების მონაცემები.', 'it': "Le piattaforme di social media (SM) come Twitter forniscono grandi quantità di dati in tempo reale che possono essere sfruttati durante le emergenze di massa. Lo sviluppo di strumenti a supporto delle comunità colpite dalla crisi richiede set di dati disponibili, che spesso non esistono per i linguaggi a basso contenuto di risorse. Questo articolo introduce Kawarith un corpus Twitter arabo multi-dialetto per eventi di crisi, comprendente più di un milione di tweet arabi raccolti durante 22 crisi avvenute tra il 2018 e il 2020 e implicavano diversi tipi di pericolo. L'esplorazione di questo contenuto ha rivelato gli argomenti e i tipi di informazioni più discussi, e l'articolo presenta un set di dati etichettato da sette eventi di emergenza che funge da gold standard per diversi compiti nella ricerca informatica di crisi. Utilizzando dati annotati dello stesso evento, un modello BERT viene perfezionato per classificare i tweet in diverse categorie nell'impostazione multi-label. I risultati mostrano che i modelli basati su BERT offrono buone prestazioni in questo compito anche con piccole quantità di dati di allenamento specifici per attività.", 'kk': 'Твиттер секілді социалдық медиақтар (SM) платформалары, массалық тәжірибелер кезінде қолданатын реалдық уақыт деректерін келтіреді. Көпшілікті қолдау құрылғыларын жасау үшін қолдау құрылғылары бар деректер қорлары керек, олар көпшілік ресурстар тілдерінде жоқ. Бұл қағаз Каваритды бірнеше диалекттік араб Твиттер корпусын қиындық оқиғалар үшін көп диалекттік түрінде таңдайды. 2018 және 2020 жылдың араб 22 кризисінде бірнеше түрлі қауіпсіздік түрінде жинақта Бұл мазмұның зерттеулері ең көп айтылған тақырыптар мен мәлімет түрлерін көрсетті, және қағаз жазылған деректер жинағын 7 қауіпсіздік оқиғалардың алтын стандарты болып тұрады. Бұл оқиғадан белгіленген деректерді қолдану үшін BERT үлгісі бірнеше белгілер параметрлерінде tweets- тізбектерді түрлі санаттарына баптау үшін дұрыс бапталады. Нәтижелер BERT негіздеген үлгілер осы тапсырманың жақсы істеуін көрсетеді, сондай-ақ, тапсырманың ерекше оқыту деректерінің кішкентай саны болса да.', 'lt': 'Socialinės žiniasklaidos (SM) platformos, pvz., Twitter, teikia didelį realaus laiko duomenų kiekį, kurį galima panaudoti masinėmis avarijomis. Siekiant sukurti priemones, skirtas padėti krizei nukentėjusioms bendruomenėms, reikalingi turimi duomenų rinkiniai, kurie dažnai nėra naudojami mažai išteklių turinčioms kalboms. Šiame dokumente Kavaritui pristatomas daugiadialektinis arabų Twitter korpusas krizių įvykiams, kurį sudaro daugiau kaip milijonas arabų tweetų, surinktų per 22 krizes, įvykusias 2018–2020 m. ir susijusias su kelių rūšių pavojumi. Exploration of this content revealed the most discussed topics and information types, and the paper presents a labelled dataset from seven emergency events that serves as a gold standard for several tasks in crisis informatics research.  Naudojant to paties įvykio anotuotus duomenis, BERT model is yra tiksliai pritaikytas, kad įvairiose kategorijose suskirstytų tweetus. Iš rezultatų matyti, kad BERT grindžiami modeliai duoda gerų rezultatų šioje užduotyje, net ir nedideliu konkrečioms užduotims skirtų mokymo duomenų kiekiu.', 'ms': 'Platform media sosial (SM) seperti Twitter menyediakan kuantiti besar data masa sebenar yang boleh digunakan semasa keadaan darurat massa. Pembangunan alat untuk menyokong komuniti yang terkena krisis memerlukan set data yang tersedia, yang sering tidak wujud untuk bahasa sumber rendah. Kertas ini memperkenalkan Kawarith korpus Twitter Arab berbilang-dialekt untuk peristiwa krisis, yang mengandungi lebih dari satu juta tweet Arab yang dikumpulkan semasa 22 krisis yang berlaku antara 2018 dan 2020 dan melibatkan beberapa jenis bahaya. Exploration of this content revealed the most discussed topics and information types, and the paper presents a labelled dataset from seven emergency events that serves as a gold standard for several tasks in crisis informatics research.  Using annotated data from the same event, a BERT model is fine-tuned to classify tweets into different categories in the multi- label setting.  Hasil menunjukkan bahawa model berasaskan BERT memberikan prestasi yang baik pada tugas ini walaupun dengan jumlah kecil data latihan khusus tugas.', 'mk': 'Платформи на социјалните медиуми (СМ), како што е Твитер, обезбедуваат големи количини на податоци во реално време кои може да бидат искористени за време на масовни итни случаи. Developing tools to support crisis-affected communities requires available datasets, which often do not exist for low resource languages.  Овој весник го претставува Каварит мултидијалектен арапски Твитер корпус за кризни настани, кој вклучува повеќе од милион арапски Твитери собрани за време на 22 кризи кои се случија меѓу 2018 и 2020 година и вклучуваат неколку видови опасност. Истражувањето на оваа содржина ги откри најразговараните теми и типови на информации, а весникот претставува означен податок од седум итни настани кои служат како златен стандард за неколку задачи во истражувањето на информатиката за кризи. Користејќи анотирани податоци од истиот настан, моделот BERT е фино прилагоден за да ги класификува твитовите во различни категории во поставувањето на мултиетикети. Резултатите покажуваат дека моделите базирани на БЕРТ даваат добри резултати на оваа задача дури и со мали количини податоци за обука специфични за задачите.', 'ml': 'സോഷ്യല്\u200d മീഡിയ (SM) പ്ലാറ്റ്ഫോമുകള്\u200d, ടൂട്ടര്\u200d പോലെയുള്ള ടൈറ്റര്\u200d പ്ലാറ്റ്ഫോമുകള്\u200d വളരെ സമയത്തെ ഡേറ്റാകള്\u200d നല്\u200dകുന്നു. ജന കഷ്ടപ്പെട്ട സമൂഹങ്ങളെ പിന്തുണയ്ക്കാനുള്ള ഉപകരണങ്ങള്\u200d വികസിക്കുന്നതിനായി ലഭ്യമായ ഡാറ്റാസറ്റുകള്\u200d ആവശ്യമുണ് ഈ പത്രത്തില്\u200d കാവാരിതിനെ അറബിക്ക് ട്രൂപ്പുകള്\u200dക്കായി ഒരു പല ഡയലക്ടറിക്കുന്ന അറബി കോര്\u200dപ്പുസിനെ പരിചയപ്പെടുത്തുന്നു. പ്രശ്നങ്ങള്\u200dക്കായി ഒരു ലക ഈ വസ്തുക്കളുടെ വിശദീകരണം ഏറ്റവും സംസാരിക്കപ്പെട്ട വിവരങ്ങളും വിവരങ്ങളുടെ തരത്തില്\u200d വെളിപ്പെടുത്തിയിരിക്കുന്നു. പേപ്പറില്\u200d നിന്നും ഏഴ് എഴുന ഒരേ സംഭവത്തില്\u200d നിന്നും അറിയിപ്പിക്കപ്പെട്ട വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു, പല- ലെബിലേറ്റ് സജ്ജീകരണത്തില്\u200d ടൂട്ടുകള്\u200d വ്യത്യസ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ബെര്\u200dട്ടി അടിസ്ഥാനമായ മോഡലുകള്\u200d ഈ ജോലിയില്\u200d നല്ല പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് നല്ല പ്രദര', 'no': 'Socielle mediaplattformar (SM) som Twitter tilbyr stor mengda data for realtid som kan leverast under masse avstandar. Utviklingsverktøya for å støtta krisspåverka fellesskap krev tilgjengelege datasett, som ofte ikkje finst for låge ressursspråk. Denne papiret introduserer Kawarith eit multidialekt arabisk Twitter-korpus for krisiske hendingar, som inneheld fleire enn millioner arabiske tweeter samla under 22 krisser som oppstod mellom 2018 og 2020 og inkluderer fleire typar vanskeleg. Utforskinga av denne innhaldet viste dei mest diskuterte emne og informasjonstypane, og papiret viser eit merkelapp dataset frå sju avvikingshendingar som tjener som gull standard for fleire oppgåver i krizinformasjonssøket. Bruk annoterarte data frå det samme hendinga er ein BERT- modell fint for å klassifisera tweeter i ulike kategoriar i innstillinga for fleire merkelappar. Resultat viser at BERT-baserte modeller gjer godt utvikling på denne oppgåva sjølv med lite mengdar oppgåvespesifikke opplæringsdata.', 'mn': 'Твиттер шиг нийгмийн хэвлэл (SM) платформууд масс гэнэтийн үед ашиглах боломжтой маш олон бодит цаг өгөгдлийг хангадаг. Хямралтын нөлөөлдөг нийгмийн дэмжих хэрэгсэл хөгжүүлэх нь хэрэглэгдэх өгөгдлийн сангууд хэрэгтэй. Энэ нь ихэвчлэн бага нөөц хэл дээр байхгүй. Энэ цаас Каваритаас олон диалект Араб Твиттерийн корпус хямралын явдалд тулгарч байна. 2018-2020 оны хооронд 22 хямралын үед олон сая араб tweets цуглуулсан бөгөөд олон төрлийн аюултай холбоотой. Энэ бүхнийг судлах нь хамгийн ярилцсан сэдвүүд болон мэдээллийн төрлүүдийг харуулсан. Харин цаас нь хямралын мэдээллийн судалгаанд олон ажил хийх алт стандарт болсон 7 аваргүй үйл явцуудын нэрлэгдсэн өгөгдлийн санг харуулдаг. Яг ижил үйл явдлаас анзаарсан өгөгдлийг ашиглаж, BERT загвар нь олон загварын орчинд tweets-г өөр категориудад хуваалцах боломжтой байдаг. Үүний үр дүн нь BERT-д суурилсан загварууд энэ ажил дээр жижиг хэмжээний дасгал өгөгдлийн бага хэмжээний ажил дээр сайн ажиллагааг гаргадаг.', 'mt': 'Pjattaformi tal-midja soċjali (SM) bħal Twitter jipprovdu kwantitajiet kbar ta’ dejta f’ħin reali li tista’ tiġi ingranata waqt emerġenzi massivi. L-iżvilupp ta’ għodod għall-appoġġ tal-komunitajiet affettwati mill-kriżi jeħtieġ settijiet ta’ dejta disponibbli, li spiss ma jeżistux għal lingwi b’riżorsi baxxi. Dan id-dokument jintroduċi lill-Kawarith korpus Għarbi b’diversi dijaletti fuq Twitter għal avvenimenti ta’ kriżi, li jinkludi aktar minn miljun tweet Għarbi miġbura matul 22 kriżi li seħħew bejn l-2018 u l-2020 u involuti diversi tipi ta’ periklu. L-esplorazzjoni ta’ dan il-kontenut żvelat l-aktar suġġetti u tipi ta’ informazzjoni diskussi, u d-dokument jippreżenta sett ta’ dejta ttikkettat minn seba’ avvenimenti ta’ emerġenza li jservi bħala standard tad-deheb għal diversi kompiti fir-riċerka fl-informatika ta’ kriżi. Bl-użu ta’ dejta annotata mill-istess avveniment, mudell BERT huwa a ġġustat finament biex jikklassifika tweets f’kategoriji differenti fis-sett b’ħafna tikketti. Results show that BERT-based models yield good performance on this task even with small amounts of task-specific training data.', 'pl': 'Platformy mediów społecznościowych (SM), takie jak Twitter, dostarczają dużych ilości danych w czasie rzeczywistym, które mogą być wykorzystane podczas masowych sytuacji kryzysowych. Opracowanie narzędzi wspierania społeczności dotkniętych kryzysem wymaga dostępnych zbiorów danych, które często nie istnieją dla języków o niskich zasobach. Niniejszy artykuł przedstawia Kawarith wielodiektowy arabski korpus Twittera dla zdarzeń kryzysowych, składający się z ponad miliona arabskich tweetów zebranych podczas 22-kryzysów, które miały miejsce od 2018 do 2020 i wiązały się z kilkoma rodzajami zagrożeń. Badanie tych treści ujawniło najczęściej dyskutowane tematy i rodzaje informacji, a w artykule przedstawiono oznaczony zbiór danych z siedmiu zdarzeń nadzwyczajnych, który służy jako złoty standard dla kilku zadań w badaniach informatyki kryzysowej. Korzystając z adnotacji danych z tego samego zdarzenia, model BERT jest dostosowany do klasyfikacji tweetów do różnych kategorii w ustawieniu wielu etykiet. Wyniki pokazują, że modele oparte na BERT dają dobrą wydajność w tym zadaniu nawet przy niewielkich ilościach danych szkoleniowych.', 'ro': 'Platformele de social media (SM), cum ar fi Twitter, furnizează cantități mari de date în timp real care pot fi utilizate în timpul urgențelor de masă. Dezvoltarea de instrumente care să sprijine comunitățile afectate de criză necesită seturi de date disponibile, care adesea nu există pentru limbile cu resurse reduse. Această lucrare prezintă Kawarith un corpus Twitter arab multidialect pentru evenimentele de criză, cuprinzând peste un milion de tweet-uri arabe colectate în timpul a 22 de crize care au avut loc între 2018 și 2020 și care au implicat mai multe tipuri de pericole. Explorarea acestui conținut a scos în evidență cele mai discutate subiecte și tipuri de informații, iar lucrarea prezintă un set de date etichetat din șapte evenimente de urgență, care servește ca standard de aur pentru mai multe sarcini în cercetarea informatică de criză. Folosind date adnotate din același eveniment, un model BERT este reglat fin pentru a clasifica tweeturile în diferite categorii în setarea multi-etichetă. Rezultatele arată că modelele bazate pe BERT oferă performanțe bune în această sarcină, chiar și cu cantități mici de date de antrenament specifice sarcinii.', 'so': 'Jardiinooyinka sooshalka (SM) sida Twitterka waxay bixiyaan qiyaastii badan oo ku saabsan waqtiga degdega ah, kuwaas oo lagu soo bandhigi karo marka ay xaaladaha degdega ah. Macluumaad horumarinta si ay u taageeraan bulshada dhibaatada leh waxay u baahan yihiin sawirro ah, kuwaas oo marar badan aysan ku jirin luuqadaha hoose ee rasmiga. Qoraalkan waxaa soo bandhigaya Kawarith oo kala duduwan af Carabi ah oo ku qoran dhacdooyinka xasaradaha, kaas oo qabanqaabiya in ka badan kun oo twiti oo Carabi ah oo soo ururiyey waqtiga 22 xasaradaha oo ka dhexaysay 2018 iyo 2020, waxayna qabanqaabisay noocyo khatar ah. Baaritaanka waxyaabahan wuxuu muujiyey maadooyin iyo noocyo macluumaad ah oo ugu wada sheekaysan, warqaduna wuxuu ka soo bandhigayaa taariikhda warqadda lagu qoray todobada dhacdooyinka xaaladaha degdegta ah oo u adeega sida standard dahab ah oo loogu talogalay shaqooyin badan oo lagu barto macluumaadka xasaradda. Isku isticmaalaya macluumaad la taxeeyey isla dhacdooyinkaas, model BERT ayaa si fiican looga qeyb-qaybo kala duduwan oo lagu qoro qoraalka kala duduwan. Xilliyadu waxay muuqataa in qaababka BERT-aasiga ah ay ka soo saaraan shaqo wanaagsan, xitaa xittaa ay ku jiraan macluumaad yar oo waxbarasho gaar ah.', 'si': 'සාමාජික මිඩියාව (SM) ප්ලේටර්ම් වගේ ට්විටර් වලින් වැඩි ප්\u200dරමාණයක් ඇත්ත කාලකාලේ දත්ත සුදානම් කරනවා ඒ ප්\u200dරශ්නයක් සමාජයෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් සමාජයෙන් ප්\u200dරශ්නයක් වෙනුවෙන් තොරතුර මේ පැත්තේ කාවාර්ත්ව අරාබි ට්විටර් කොර්පුස් එකක් අවස්ථාවක් වෙනුවෙන් ප්\u200dරවේශනය කරනවා, 2018 සහ 2020යි අතර අවස්ථාවක් අතර අරාබි මිලි මේ සාමාන්\u200dය විශ්වාසයේ පරීක්ෂණය සහ තොරතුරු වර්ගයක් පැහැදිලි වුනා, සහ පැත්තේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා ප්\u200dරශ්නයක් තිය එකම අවස්ථානයෙන් ප්\u200dරතිචාර දත්ත පාවිච්චි කරනවා, BERT මොඩේලයක් වෙනස් ප්\u200dරතිචාරයෙන් වෙනස් ප්\u200dරතිචාරයෙන් ටි ප්\u200dරතිචාරයක් පෙන්වන්නේ BERT-විශේෂ විශේෂ පරීක්ෂණ දත්තේ පොඩි ප්\u200dරමාණයක් තියෙනවා කියලා.', 'sr': 'Platforme društvenih medija (SM) poput Twitter pružaju velike količine realnog vremena podataka koje se mogu uticati tokom masovnih hitnih slučajeva. Razvoj alata za podršku zajednica koje su pogođene na krizu zahteva dostupne sete podataka, koje često ne postoje za niske jezike resursa. Ovaj papir predstavlja Kawarith višedijalektni arapski Twitter korpus za krizne događaje, uključujući više od miliona arapskih tweeta prikupljenih tokom 22 kriza koje se dogodilo između 2018. i 2020. godine i uključuje nekoliko vrsta opasnosti. Istraživanje ovog sadržaja otkrilo je najraspravljenije tema i tipe informacija, a papir predstavlja označenu kompletu podataka iz sedam hitnih događaja koji služi kao zlatni standard za nekoliko zadataka u istraživanju krizne informatike. Koristeći annotirane podatke iz iste događaje, BERT model je dobro određen kako bi klasifikovao tweet u različite kategorije u postavljanju multietiketa. Rezultati pokazuju da modeli na BERT-u pružaju dobre funkcije na ovom zadatku čak i sa malim količinama podataka o obuci specifičnih zadataka.', 'sv': 'Sociala medier (SM) plattformar som Twitter tillhandahåller stora mängder realtidsdata som kan utnyttjas vid massnödsituationer. Att utveckla verktyg för att stödja krisdrabbade samhällen kräver tillgängliga datamängder, som ofta inte finns för språk med låga resurser. Denna uppsats introducerar Kawarith en multidialekt arabisk Twitter korpus för krishändelser, bestående av mer än en miljon arabiska tweets samlade under 22 kriser som inträffade mellan 2018 och 2020 och involverade flera typer av fara. Undersökningen av detta innehåll avslöjade de mest diskuterade ämnena och informationstyperna, och uppsatsen presenterar ett märkt dataset från sju nödhändelser som fungerar som guldstandard för flera uppgifter inom krisinformatikforskning. Med hjälp av kommenterade data från samma händelse finjusteras en BERT-modell för att klassificera tweets i olika kategorier i inställningen med flera etiketter. Resultaten visar att BERT-baserade modeller ger bra prestanda på denna uppgift även med små mängder uppgiftsspecifika träningsdata.', 'ta': 'தொடர்பு போன்ற சமூக ஊடகம் (SM) தளங்கள் பெரிய உண்மையான நேர தரவுகளை வழங்குகின்றன, அது மக்கள் நிகழ்ச்சியில் கொடுக்கப்படும். @ info: whatsthis இந்த தாள் கவாரித் தொகுதி நிகழ்ச்சிகளுக்கு பல-விளக்கமான அரபி தொடர்பு குறிப்பை குறிப்பிடுகிறது, 2018-2020 இடையில் ஏற்பட்ட 22 பிரச்சனைகளில் ஒன்று மில் இந்த உள்ளடக்கங்களின் விளக்கம் மிக விவாதமான தலைப்புகள் மற்றும் தகவல் வகைகளை வெளிப்படுத்தியது, மற்றும் காகிதத்தில் சிகிச்சை தகவல் அறிவிப்புகளில் சில ஒரே நிகழ்விலிருந்து வெளிப்படுத்தப்பட்ட தகவலை பயன்படுத்தி, ஒரு பிரெட் மாதிரி தொடர்புகளை பல- விளக்கச்சீட்டு அமைப்பில் வகைப்படுத @ info', 'ur': 'سوسیلی میڈیا (SM) پٹرومٹ جیسے ٹویٹر بہت سی موقعیت ڈیٹ کو پہنچا سکتے ہیں جو ماس اضطراری کے موقعیت میں استعمال کر سکتے ہیں۔ مصیبت کے باعث کمونٹیوں کی مدد کرنے کے لئے ابزار ڈولنے کی ضرورت ہے کہ موجود ڈاٹ سٹ ہیں، جو بہت سے وقت کم سراسر زبانوں کے لئے موجود نہیں ہیں. یہ کاغذ کاوارت کو ایک مختلف طریقہ عربی ٹویٹر کی کورپوس کے ساتھ پیش کرتا ہے جس میں 22 کریزوں کے درمیان جمع ہوئے ایک میلیون عربی ٹویٹ سے زیادہ ہے جو 2018 اور 2020 کے درمیان موجود تھی اور بہت سی طرح خطرات میں شامل ہوتے ہیں۔ اس منصوبت کی تحقیق نے سب سے زیادہ بحث کی موضوع اور معلومات کی طرح ظاہر کی، اور کاغذ نے سات اضطراری حادثہ سے ایک لابلیجہ ڈیٹ سٹ کو دکھایا ہے جو مصیبت معلومات تحقیق میں بہت سی کاموں کے لئے سونے کی استاندارڈ کے طور پر ایک ایڈیٹ سے نوٹ ڈیٹا کا استعمال کرنا، ایک BERT موڈیل مثبت کے لئے ٹیوٹ کو مختلف کاٹیوں میں تقسیم کرنے کے لئے بہتر تنظیم کیا جاتا ہے. نتائج دکھاتے ہیں کہ BERT بنیادی موڈل اس کام پر اچھی فعالیت حاصل کرتی ہیں، اگرچہ بہت کم کام کی تعلیم دیٹے کے ساتھ۔', 'uz': "Name @ info: whatsthis Bu qogʻoz Kawarith krisis hodisalar uchun bir necha dialek arab Twitterni ko'plab bog'liqlaydi. Bu xavfsiz hodisalarning 22 muammolari orasidagi 22 muammolarda bir mingdan ko'proq Twitterdan xabar tarqatish va bir necha tur xavfsiz turlariga qaraydi. Exploration of this content revealed the most discussed topics and information types, and the paper presents a labelled dataset from seven emergency events that serves as a gold standard for several tasks in crisis informatics research.  @ info: whatsthis Natijalar bilan BERT asosida modellar bu vazifaning juda yaxshi bajarish imkoniyatini ko'rsatadi va vazifa haqida qo'shimcha taʼminlovchi maʼlumotlar maʼlumotidan bajaradi.", 'vi': 'Mạng xã hội (SM) platform như Twitter cung cấp một lượng lớn dữ liệu thời gian thực có thể hỗ trợ trong trường hợp khẩn cấp hàng loạt. Việc phát triển công cụ hỗ trợ các cộng đồng bị khủng hoảng đòi hỏi dữ liệu có sẵn, mà thường không tồn tại cho ngôn ngữ có nguồn thấp. Tờ giấy này giới thiệu Kawarith là một tập thể Twitter Đa thổ của Ả Rập cho các sự kiện khủng hoảng, gồm hơn một triệu tweet của Ả Rập được thu thập trong suốt các cơn khủng hoảng diễn ra giữa 208 và 2020 và liên quan đến nhiều loại nguy hiểm. Khám phá nội dung này đã tiết lộ các chủ đề và các loại thông tin được thảo luận nhiều nhất, và tờ báo có một bộ dữ liệu được dán nhãn từ bảy sự kiện khẩn cấp phục vụ tiêu chuẩn vàng cho nhiều nhiệm vụ trong nghiên cứu dữ liệu khủng hoảng. Sử dụng dữ liệu ghi chú từ cùng một sự kiện, mô hình BERT được chỉnh cẩn thận để phân loại Twitter thành các loại khác nhau trong thiết lập đa nhãn. Kết quả cho thấy các mô hình dựa trên BERT mang lại hiệu quả tốt cho nhiệm vụ này dù có một lượng nhỏ dữ liệu về huấn luyện đặc nhiệm.', 'hr': 'Platforme društvenih medija (SM) poput Twitter pružaju velike količine realnog vremena podataka koje se mogu primjenjivati tijekom masovnih hitnih slučajeva. Razvoj alata za podršku zajednica koje su pogođene na krizu zahtijeva dostupne sete podataka, koje često ne postoje za niske jezike resursa. Ovaj papir predstavlja Kawarith višedijalektni arapski Twitter korpus za krizne događaje, uključujući više od milijuna arapskih tweeta prikupljenih tijekom 22 kriza koje se dogodilo između 2018. i 2020. godine i uključuje nekoliko vrsta opasnosti. Istraživanje ovog sadržaja otkrilo je najraspravljenije teme i vrste informacija, a u novinama se nalazi označena kompleta podataka iz sedam hitnih događaja koja služi kao zlatni standard za nekoliko zadataka u istraživanju krizne informatike. Koristeći annotirane podatke iz iste događaje, BERT model je dobro određen kako bi klasifikirao tweet u različite kategorije u multietiketnim nastavkama. Rezultati pokazuju da modeli na temelju BERT-a pružaju dobre učinke na ovom zadatku čak i sa malim količinama podataka o obuci specifičnih zadataka.', 'nl': 'Social media (SM) platforms zoals Twitter bieden grote hoeveelheden real-time data die kunnen worden benut tijdens massale noodsituaties. Voor het ontwikkelen van instrumenten ter ondersteuning van door crisis getroffen gemeenschappen zijn beschikbare datasets nodig, die vaak niet bestaan voor talen met weinig middelen. Dit artikel introduceert Kawarith een multi-dialect Arabisch Twitter corpus voor crisisgebeurtenissen, bestaande uit meer dan een miljoen Arabische tweets verzameld tijdens 22-crises die plaatsvonden tussen 2018 en 2020 en verschillende soorten gevaren omvatten. Het onderzoek van deze inhoud onthulde de meest besproken onderwerpen en informatietypen, en het artikel presenteert een gelabelde dataset van zeven noodgebeurtenissen die dient als een gouden standaard voor verschillende taken in crisisinformatica onderzoek. Met behulp van geannoteerde gegevens van dezelfde gebeurtenis wordt een BERT-model verfijnd om tweets in verschillende categorieën te classificeren in de instelling voor meerdere labels. Uit de resultaten blijkt dat BERT-gebaseerde modellen ook bij kleine hoeveelheden taakspecifieke trainingsgegevens goede prestaties leveren op deze taak.', 'bg': 'Платформата на социалните медии като Туитър предоставя големи количества данни в реално време, които могат да бъдат използвани по време на масови извънредни ситуации. Разработването на инструменти за подпомагане на засегнатите от криза общности изисква налични набори от данни, които често не съществуват за езици с нисък ресурс. Настоящата статия представя на Каварит многодиалектен арабски корпус за кризисни събития, включващ повече от един милион арабски туитове, събрани по време на 22 кризи, настъпили между 2018 и 2020 г. и включващи няколко вида опасности. Разглеждането на това съдържание разкри най-обсъжданите теми и видове информация, а статията представя обозначен набор от данни от седем извънредни събития, които служат като златен стандарт за няколко задачи в областта на информационните изследвания при кризи. Използвайки анотирани данни от едно и също събитие, моделът е фино настроен, за да класифицира туитовете в различни категории в настройката за многоетикети. Резултатите показват, че базираните на BERT модели дават добра производителност на тази задача дори и при малки количества специфични за задачата данни за обучение.', 'da': 'Sociale medier (SM) platforme såsom Twitter leverer store mængder realtidsdata, der kan udnyttes i massenødsituationer. Udvikling af værktøjer til støtte for kriseramte samfund kræver tilgængelige datasæt, som ofte ikke findes for sprog med lave ressourcer. Denne artikel introducerer Kawarith et multidialekt arabisk Twitter korpus for krisebegivenheder, der omfatter mere end en million arabiske tweets indsamlet under 22 kriser, der opstod mellem 2018 og 2020 og involverede flere typer farer. Undersøgelsen af dette indhold afslørede de mest diskuterede emner og informationstyper, og artiklen præsenterer et mærket datasæt fra syv nødhændelser, der fungerer som guldstandard for flere opgaver inden for kriseinformatik forskning. Ved hjælp af annoterede data fra samme begivenhed finjusteres en BERT-model for at klassificere tweets i forskellige kategorier i indstillingen med flere etiketter. Resultaterne viser, at BERT-baserede modeller giver gode resultater på denne opgave selv med små mængder opgavespecifikke træningsdata.', 'de': 'Social Media (SM)-Plattformen wie Twitter liefern große Mengen an Echtzeitdaten, die in Massennotfällen genutzt werden können. Die Entwicklung von Instrumenten zur Unterstützung von Krisengemeinschaften erfordert verfügbare Datensätze, die es für ressourcenarme Sprachen oft nicht gibt. Dieser Beitrag stellt Kawarith ein mehrdialektes arabisches Twitter-Korpus für Krisenereignisse vor, das mehr als eine Million arabische Tweets umfasst, die während 22-Krisen zwischen 2018 und 2020 gesammelt wurden und mehrere Arten von Gefahren beinhalten. Die Untersuchung dieser Inhalte enthüllte die am meisten diskutierten Themen und Informationstypen, und der Beitrag präsentiert einen markierten Datensatz von sieben Notfallereignissen, der als Goldstandard für mehrere Aufgaben in der Kriseninformatikforschung dient. Mithilfe von annotierten Daten desselben Ereignisses wird ein BERT-Modell fein abgestimmt, um Tweets in verschiedene Kategorien in der Multi-Label-Einstellung einzuordnen. Die Ergebnisse zeigen, dass BERT-basierte Modelle bei dieser Aufgabe auch bei geringen Mengen aufgabenspezifischer Trainingsdaten gute Leistungen erbringen.', 'id': 'Platform media sosial (SM) seperti Twitter menyediakan jumlah besar data waktu nyata yang dapat digunakan dalam keadaan darurat massal. Mengembangkan alat untuk mendukung komunitas yang terkena krisis membutuhkan set data yang tersedia, yang sering tidak ada untuk bahasa sumber daya rendah. Kertas ini memperkenalkan Kawarith sebuah korpus Twitter Arab multi-dialekt untuk kejadian krisis, yang mengandung lebih dari satu juta tweet Arab yang dikumpulkan selama 22 krisis yang terjadi antara 2018 dan 2020 dan melibatkan beberapa jenis bahaya. Penjelasan isi ini mengungkapkan topik yang paling didiskusikan dan tipe informasi, dan kertas mempersembahkan set data berlipat dari tujuh peristiwa darurat yang layak sebagai standar emas untuk beberapa tugas dalam penelitian informasi krisis. Menggunakan data anotasi dari peristiwa yang sama, model BERT disesuaikan dengan baik untuk mengklasifikasi tweet ke kategori yang berbeda dalam pengaturan multi-label. Results show that BERT-based models yield good performance on this task even with small amounts of task-specific training data.', 'ko': '트위터 등 소셜미디어(SM) 플랫폼은 대규모 유사시 이를 활용할 수 있는 실시간 데이터를 대거 제공한다.위기에 처한 지역사회를 지원하는 도구를 개발하려면 사용할 수 있는 데이터 집합이 필요하지만 저자원 언어는 이런 데이터 집합을 갖추지 못한다.본고는 위기 사건에 사용되는 다사투리 아랍어 트위터 자료 라이브러리인 Kawarith를 소개한다. 이 자료 라이브러리는 2018년부터 2020년까지 발생한 22차례의 위기 기간에 수집된 100만 개의 아랍어 트위터를 포함하고 다양한 유형의 위해와 관련된다.이 내용에 대한 탐색은 가장 많이 토론된 주제와 정보 유형을 제시했다. 본고는 7개의 긴급 사건에서 나온 표기 데이터 집합을 위기 정보학 연구에서 몇 가지 임무의 금 기준으로 제시했다.동일한 이벤트의 주석 데이터를 사용하여 여러 탭 설정에서 트윗을 다른 종류로 분류할 수 있도록 버트 모델을 미세하게 조정합니다.그 결과 버트 모델을 바탕으로 소량의 임무에 대한 훈련 데이터가 있어도 이 임무에 좋은 성능을 낼 수 있다는 것이 밝혀졌다.', 'sw': 'Jukwaa la vyombo vya habari vya kijamii kama vile Twita hutoa kiasi kikubwa cha taarifa za muda halisi ambazo zinaweza kutumika wakati wa tukio la umma. Vifaa vya kutengeneza kusaidia jamii zilizoathirika na matatizo yanahitaji seti zinazopatikana, ambazo mara nyingi hazipo kwa lugha ndogo za rasilimali. Kawarith inaonyesha makampuni ya Twita yenye lugha mbalimbali ya Kiarabu kwa matukio ya mgogoro, ikiwa ni pamoja na twiti milioni za Kiarabu zilizokusanywa wakati wa matatizo 22 yaliyotokea kati ya 2018 na 2020 na kuhusisha aina kadhaa za hatari. Utafiti wa maudhui haya ulionyesha mada na a in a za taarifa zilizojadiliwa zaidi, na gazeti hilo linaleta taarifa maarufu kutoka matukio saba ya dharura yanayotumika kama kiwango cha dhahabu kwa kazi kadhaa katika utafiti wa taarifa za matatizo. Kwa kutumia taarifa zilizotajwa kutoka kwenye tukio hilo hilo, Mradi wa BERT unatumiwa vizuri kwa kutangaza twiti katika makundi tofauti katika seti ya vifaa vingi. Matokeo yanaonyesha kuwa mifano yenye msingi wa BERT yanatoa ufanisi mzuri katika kazi hii hata kwa kiasi kidogo cha mafunzo maalum ya kazi.', 'fa': 'استفاده\u200cهای رسانه\u200cهای اجتماعی (SM) مانند توئیتر تعداد زیادی از داده\u200cهای زمان واقعی را می\u200cدهد که می\u200cتوانند در طول اضطراری جمعی تحت تاثیر قرار دهند. ابزارهای توسعه برای پشتیبانی از جامعه های تحت تاثیر بحران نیاز به مجموعه داده های موجود است که اغلب برای زبانهای کم منابع وجود ندارند. این کاغذ کاواریث را برای اتفاقات بحران در عربی چندین dialect ی معرفی می کند که بیشتر از یک میلیون توئیت عربی در طول ۲۲ کریس که بین ۲۰۰۸ و ۲۰۰۲ اتفاق افتاد و چندین نوع خطر درگیر شده است. تحقيقات اين محتويات بيشترين موضوع و نوع اطلاعات را نشون داد، و اين کاغذ يه مجموعه اطلاعات مشخص شده از هفت حادثه اضطراري که به عنوان استاندارد طلا براي چندين وضعيت در تحقيقات اطلاعات بحران استفاده ميکنه. استفاده از داده\u200cهای یادآوری از یک رویداد، یک مدل BERT برای تنظیم توئیت\u200cها در تنظیم برچسب\u200cهای متفاوت به کلاس\u200cهای متفاوت تنظیم می\u200cشود. نتیجه\u200cها نشان می\u200cدهند که مدل\u200cهای بنیاد BERT در این وظیفه عملکرد خوبی به دست می\u200cآورند حتی با اندازه\u200cهای داده\u200cهای آموزش ویژه\u200cای برای وظیفه\u200cهای کوچک.', 'af': "Soziale media (SM) platforme soos Twitter verskaf groot hoeveelheid reël-tyd data wat in masse uitbreidings kan aanbetaal word. Ontwikkeling van hulpmiddels om krisseffekteerde gemeenskappe te ondersteun benodig beskikbare datastelle, wat dikwels bestaan nie vir lae hulpbron tale nie. Hierdie papier introduseer Kawarith 'n multidialekte Arabiese Twitter-korpus vir krisiegebeurtenis, wat meer as 'n miljoen Arabiese tweete versamel het gedurende 22 krisies wat tussen 2018 en 2020 gebeur het en verskeie soorte gevaardigheid insluit. Verspreiding van hierdie inhoud het die mees gespreek onderwerpe en inligting tipes geopenbaar, en die papier stel 'n etiketeerde datastel van sewe nugtige gebeurtenis wat dien as 'n goue standaard vir verskeie opdragte in krisis informatike ondersoek. Gebruik van aanmerkte data van dieselfde gebeurtenis, 'n BERT model is fyn- tuned na klassifiseer tweets in verskillende kategories in die multi- label instelling. Resultate wys dat BERT-gebaseerde modele goeie prestasie op hierdie taak gee selfs met klein hoeveelheid taak-spesifieke onderwerp data.", 'tr': 'Twitter ýaly sosyal medýdanlar (SM) platformlary gaty wagtlar ýagdaýynda etmäge mümkin edip biljek sany haýsy wagt maglumaty saýlaýarlar. Kriz täsirli jemgyýetlerini desteklemek üçin önlemek isleýän guramlar. Bu köplenç iň az resurs dilleri üçin däldir. Bu kağıt 2018 we 2020-nji ýyllarda bolan 22 krizis wagtlarynda jemgylanan bir milyon arap tweets bolan, Kawarith krizis çykyşlary üçin köp dialektli arapça Twitter korpusyny tanyşdyrýar. Bu manynyň sözleşmesi iň gürrüňli temalary we maglumat türlerini görkezildi we bu kagyz krizis maglumatynyň barlamasynda birnäçe iş üçin altyn standart diýip kabul edildi. Aynı faýldan täzelenýän maglumatlary ullanýar, bir BERT modeli multi-etiket düzümlerinde täzelenýän kategoriýara hat edildi. Netijenler BERT tabanly nusgalary bu zada gowy etmäge rugsat berýändigini görkezýär. Hatda kiçi görnüş taýýarlama maglumatynyň hatda.', 'am': 'በትዊተር እንደሆነ የማኅበራዊ አውታር (SM) ፕላጦማር ሰነፎች በቁጥጥር ጉዳይ ጊዜ የተሰጡትን የreal-time ዳታ ያሰናዳሉ፡፡ የጭንቀት ጉዳይ-ጉዳዩ ማኅበረሰቦችን ለመደጋገም መሣሪያዎችን ማቀናጃ ያስፈልጋል፤ እነዚህም ብዙ ጊዜ ለማንበብ የኩነቶች ቋንቋዎች አይደሉም። ይህ ገጽ በ2018 እና 2020 መካከል በተሰበሰቡ 22 ሁኔታ ሽብር ውስጥ ከመቶ ሚሊዮን አረቢያ Twitters የሚበልጠውን አረቢያ ትዊተር ካዋሪትን የሚያሳውቃትን እና ብዙ ዓይነት የጥፋት አካባቢ አካባቢ አካባቢ አካባቢ አካባቢ አካባቢ አካባቢዎችን ያሳያል፡፡ የዚህ ውስጥ መረጃ መግለጫ በተጨማሪው ጉዳዮች እና የመረጃ ዓይነቶች ላይ የተገለጸ ነው፡፡ በአንድ ሁኔታ ላይ የተጠቃሚ ዳታ በመጠቀም ጊዜ BERT ሞዴል ትዊተቶችን በተለየ ክፍሎች ውስጥ በብዙ-label ማዘጋጀት በመጠቀም የተጠቃሚ ሆኗል፡፡ ፍጥረቶቹ BERT-based ሞዴላዎች በዚህ ስራ ላይ የተመሳሰለ ትንሽ የስራ ትምህርት ዳታዎችን እንዲያሳዩ ያሳያል፡፡', 'sq': 'Platformet e medias sociale (SM) të tilla si Twitter ofrojnë sasi të mëdha të dhënash në kohë reale që mund të përdoren gjatë emergjencës masive. Zhvillimi i mjeteve për të mbështetur komunitetet e prekura nga kriza kërkon grupe të dhënash të disponueshme, të cilat shpesh nuk ekzistojnë për gjuhët e ulëta të burimeve. Ky artikull paraqet Kawarithin një korpus shumë-dialekt arab Twitter për ngjarje krize, që përfshin më tepër se një milion tweete arabe të mbledhura gjatë 22 krizave që ndodhën midis 2018 dhe 2020 dhe përfshijnë disa lloje rreziku. Zbulimi i këtij përmbajtje zbuloi temat më të diskutuara dhe llojet e informacionit dhe gazeta paraqet një sërë të dhënash me etiketë nga shtatë ngjarje urgjente që shërben si një standard ari për disa detyra në kërkimin e informacionit të krizës. Duke përdorur të dhënat e anotuara nga e njëjta ngjarje, një model BERT është i rregulluar mirë për të klasifikuar tweetet në kategori të ndryshme në përcaktimin multi-label. Rezultatet tregojnë se modelet me bazë në BERT japin rezultate të mira në këtë detyrë edhe me sasi të vogla të dhënash të trainimit specifik për detyrat.', 'az': 'Twitter kimi sosyal media (SM) platformları, qüvvətli təhlükəsizlər sırasında istifadə edilə biləcək reyal zamanlı məlumatları təmin edir. Kriz təsirlərini dəstəkləmək üçün istifadə edən vasitələrin faydalanması üçün mümkün verilən qurma qurmaqlarına ehtiyacı vardır. Bu çox çox düşük ressurs dilləri üçün yoxdur. Bu kağıt, 2018-2020 arasında olan 22 kriz sırasında toplanmış və bir çox təhlükəsizlik təhlükəsizliklə birlikdə olan, çox dialektli ərəbcə Twitter korpusu ilə birlikdə təşkil edir. Bu məlumatın söhbəti ən mübahisə edilən məsələlər və məlumat türünü göstərdi. Kağıt krizin informatiki araştırmalarında çoxlu işlər üçün altın standartdır. Aynı vaxtlardan məlumatlar istifadə edərək, çoxlu etiket qurğularında tweetləri müxtəlif kategoriyalara dəyişdirmək üçün BERT modeli təmizlənir. Sonuçlar belə göstərir ki, BERT tabanlı modellərin bu işdə yaxşı performans verir, hətta kiçik qiymətlər təhsil edilən təhsil məlumatları ilə.', 'ca': "Les plataformes dels mitjans socials (SM), com Twitter, proporcionen grans quantitats de dades en temps real que es poden aprofitar durant emergencies massives. El desenvolupament d'eines per sostenir les comunitats afectades per la crisi requereix conjunts de dades disponibles, que sovint no existeixen per a llengües amb baix recursos. Aquest article introdueix a Kawarith un cos àrab multidialecte de Twitter per eventos de crisi, compost de més d'un milió de tweets àrabs recollits durant 22 crises que van ocórrer entre 2018 i 2020 i que van implicar diversos tipus de perill. L'exploració d'aquest contingut va revelar els temes i tipus d'informació més discutits, i el paper presenta un conjunt de dades etiquetat de set esdeveniments d'emergència que serveix com un estàndard d'or per a diverses tasques en recerca informàtica en crisi. Utilitzant les dades anotates del mateix esdeveniment, un model BERT es ajusta finament per classificar els tweets en diferents categories en la configuració multietiquetada. Els resultats mostren que els models basats en BERT donen bons resultats en aquesta tasca fins i tot amb petites quantitats de dades de capacitació específices per a les tasques.", 'bn': 'সামাজিক প্রচার মাধ্যম (এসএম) প্ল্যাটফর্ম, যেমন টুইটারে বিশাল সময়ের তথ্য প্রদান করে, যা গণজরুরী অবস্থায় প্রচার করতে পারে। সংকট-আক্রান্ত সম্প্রদায়ের সমর্থন করার জন্য বিদ্যমান ডাটাসেট প্রয়োজন, যা প্রায়শই কম রিসোর্স ভাষার জন্য উপস্থিত না। এই পত্রিকা ২০১৮ থেকে ২০২০ সালের মধ্যে বেশ কিছু ধরনের ঝুঁকির মধ্যে সংগ্রহ করা ২২ লক্ষ আরবী টুইটের মাধ্যমে কাওয়ারিথের একটি বহুভাষী আরবী টুইটার কোর্পাসের সা এই বিষয়গুলোর বিশেষ বিষয় এবং তথ্য ধরনের সবচেয়ে আলোচনা প্রকাশ করা হয়েছে এবং পত্রিকাটি সাতটি জরুরী ঘটনা থেকে লেবেল করা ডাটাসেট উপস্থাপন করেছে যা সংকটের তথ্ একই অনুষ্ঠান থেকে ব্যাখ্যা করা তথ্য ব্যবহার করে, বহুল লেবেল বৈশিষ্ট্যের বিভিন্ন বিভিন্ন বিভিন্ন বিভিন্ন বিভাগে টুইট বিভ ফলাফল দেখা যাচ্ছে যে বেরেট ভিত্তিক মডেল এই কাজের উপর ভালো প্রদর্শন করেছে এমনকি কাজের কাজের নির্দিষ্ট প্রশিক্ষণের তথ্য', 'bs': 'Platforme društvenih medija (SM) poput Twitter pružaju velike količine realnog vremena podataka koje se mogu uticati tijekom masovnih hitnih slučajeva. Razvoj alata za podršku zajednica koje su pogođene na krizu zahtijeva dostupne sete podataka, koje često ne postoje za niske jezike resursa. Ovaj papir predstavlja Kawarith višedijalektni arapski Twitter korpus za krizne događaje, uključujući više od milijuna arapskih tweeta prikupljenih tokom 22 kriza koje se dogodilo između 2018. i 2020. godine i uključuje nekoliko vrsta opasnosti. Istraživanje ovog sadržaja otkrilo je najraspravljenije teme i tipe informacija, a novine predstavljaju označenu kompletu podataka iz sedam hitnih događaja koji služi kao zlatni standard za nekoliko zadataka u istraživanju krizne informatike. Koristeći annotirane podatke iz iste događaje, BERT model je dobro određen kako bi klasifikovao tweet u različite kategorije u postavljanju multietiketa. Rezultati pokazuju da modeli na BERT-u pružaju dobre učinke na ovom zadatku čak i sa malim količinama podataka o obuci specifičnim zadacima.', 'cs': 'Platformy sociálních médií (SM), jako je Twitter, poskytují velké množství dat v reálném čase, které lze využít během hromadných nouzových situací. Vývoj nástrojů na podporu komunit postižených krizí vyžaduje dostupné datové soubory, které často neexistují pro jazyky s nízkými zdroji. Tento článek představuje Kawarith multidialektní arabský Twitter korpus pro krizové události, který obsahuje více než milion arabských tweetů shromážděných během 22 krizí, které nastaly mezi 2018 a 2020 a zahrnovaly několik druhů nebezpečí. Průzkum tohoto obsahu odhalil nejvíce diskutovaná témata a typy informací a příspěvek představuje označený datový soubor ze sedmi mimořádných událostí, který slouží jako zlatý standard pro několik úkolů krizové informatiky. Pomocí anotovaných dat ze stejné události je model BERT jemně vyladěn tak, aby tweety klasifikoval do různých kategorií v nastavení více štítků. Výsledky ukazují, že modely založené na BERT přinášejí dobrý výkon v tomto úkolu i s malým množstvím údajů o tréninku specifickém pro úkol.', 'et': 'Sotsiaalmeedia platvormid, nagu Twitter, pakuvad suurtes kogustes reaalajas andmeid, mida saab massihädaolukordade ajal kasutada. Kriisist mõjutatud kogukondade toetamiseks vajalike vahendite väljatöötamine nõuab olemasolevaid andmekogumeid, mida sageli vähese ressursiga keelte puhul puudub. Käesolevas artiklis tutvustatakse Kawarithi mitmedialektilist araabia Twitteri korpust kriisisündmuste jaoks, mis sisaldab enam kui miljonit araabia säutsu, mis koguti ajavahemikul 2018–2020 aset leidnud 22 kriisi ajal ja mis hõlmasid mitut tüüpi ohte. Selle sisu uurimine paljastas kõige arutatumad teemad ja infotüübid ning töös on esitatud seitsme hädaolukorra sündmuse märgistatud andmekogum, mis on kuldstandard mitmete kriisiinformaatika uuringute ülesannete jaoks. Kasutades sama sündmuse annoteeritud andmeid, on BERT mudel täpselt häälestatud, et klassifitseerida säutsud erinevatesse kategooriatesse mitme sildi seadetes. Tulemused näitavad, et BERT-põhised mudelid annavad selle ülesande täitmisel head tulemused isegi väikeste koguste ülesandepõhiste koolitusandmete puhul.', 'fi': 'Sosiaalisen median alustat, kuten Twitter, tarjoavat suuria määriä reaaliaikaista dataa, jota voidaan hyödyntää massahätätilanteissa. Kriiseistä kärsivien yhteisöjen tukemiseen tarkoitettujen välineiden kehittäminen edellyttää saatavilla olevia tietoaineistoja, joita ei useinkaan ole olemassa vähävaraisten kielten osalta. Tässä artikkelissa esitellään Kawarithin monimurteellinen arabiankielinen Twitter-korpus kriisitapahtumille, joka sisältää yli miljoona arabiankielistä twiittiä, jotka on kerätty vuosien 2018 ja 2020 välisenä aikana tapahtuneiden 22 kriisien aikana ja joihin liittyi useita vaaroja. Sisällön tutkiminen paljasti eniten käsiteltyjä aiheita ja tietotyyppejä, ja julkaisussa esitellään seitsemän hätätilanteen leimattu aineisto, joka toimii kultaisena standardina useille kriisiinformatiikan tutkimustehtäville. BERT-malli on hienoviritetty saman tapahtuman annotoitujen tietojen avulla, jotta tweetit voidaan luokitella eri luokkiin usean tarran asetuksissa. Tulokset osoittavat, että BERT-pohjaiset mallit tuottavat tässä tehtävässä hyvää suorituskykyä myös pienillä määrillä tehtäväkohtaista harjoitusdataa.', 'hy': 'Social media (SM) platforms such as Twitter provide large quantities of real-time data that can be leveraged during mass emergencies.  Գործիքներ զարգացնելը ճգնաժամի վրա ազդեցող համայնքների աջակցությանը պահանջում է հասանելի տվյալների համակարգեր, որոնք հաճախ չկան ցածր ռեսուրսների լեզուների համար: Այս աշխատանքը ներկայացնում է Կավարիթին բազմադիալեկտ արաբական Թվիթերի կորպուսը ճգնաժամային իրադարձությունների համար, որը ներառում է ավելի քան միլիոն արաբական թվիթեր, որոնք հավաքվել են 2018-2020 թվականների ընթացքում 22 ճգնաժամի ընթացքում և ներառում են որո Այս պարունակության ուսումնասիրությունը բացահայտեց ամենաքննարկված թեմաները և տեղեկատվության տեսակները, և թղթին ներկայացնում է 7 անհրաժեշտ իրադարձությունների պիտակ տվյալներ, որոնք ծառայում են որպես ոսկու ստանդարտ ճգնաժամի ինֆորմատիկայի հետազ Օգտագործելով նույն իրադարձություններից գրված տվյալներ, BER մոդելը լավ է կազմված, որպեսզի թվիթերը դասակարգեն բազմաթիվ պիտակների տարբեր կատեգորիաների մեջ: Արդյունքները ցույց են տալիս, որ BER-ի հիմնված մոդելները լավ արդյունք են ստանում այս խնդրի վրա նույնիսկ խնդիրների մասնավոր ուսուցման տվյալների փոքր քանակությամբ:', 'jv': 'Kasunyatan media (SM) sing di sistem sing dibutuhke dipunangé kapan-kapan anyar tentang Perangkat kang dipunangé perusahaan kanggo keamanan akeh pakan dengané dataset sing bisa nêmên, sing dikondas akeh durung kanggo langgambar akeh durung. Perintah iki nggawe Kawarwith sing sampeyan dialectu multi-dialectu YouTube kanggo kejahatan krês, sampeyan siji karo milion sing katêpakan karo tentang karo 22 krês sing apik maneh nang 2020 lan tambah sing katêpakan karo akeh menar sing katêpakan. Rasané perbudhakan iki menehi wong hal-wong liyane karo informasi sing berarti sawar karo perbudhakan sing berarti dataset sing ngecat perbudhakan 7 politenessoffpolite"), and when there is a change ("assertivepoliteness Pamita ratong ngomong ke model sing basa BERT iso nggawe akeh pengin nggawe mungkin karo nganggo barang langkung dadi nggawe barang task-special', 'he': "פלטפורמות תקשורת חברתית (SM) כמו טוויטר מספקות כמויות גדולות של נתונים בזמן אמיתי שאפשר להשתמש במהלך מקרים חירום מסיים. פיתוח כלים לתמוך בקהילות שמשפיעות על משבר דורשים קבוצות נתונים זמינות, שלעתים קרובות לא קיימות לשפות משאבים נמוכות. העיתון הזה מציג את קאורית' גופוס טויטר ערבי רב-דיאלקט לאירועים משבר, שמכיל יותר ממיליון טוויטרים ערביים שנאספו במהלך 22 משבר שקרה בין 2018 ל-2020 וערב מספר סוגים של סכנה. חקירת התוכן הזו חשפה את הנושאים והסוגי המידע הכי מדוברים, והעיתון מציג קבוצת מידע מסוימת מ-7 אירועים חירום שמשרת כסטנדרט זהב עבור מספר משימות במחקר אינפורטיקה משבר. באמצעות נתונים מצוינים מאותו אירוע, דוגמנית BERT מתאימה מצוינת כדי להקליף טוויטים לקטגוריות שונות בסטגוריה של תוויטים רבים. התוצאות מראות שמודלים מבוססים על BERT נותנים ביצועים טובים על המשימה הזאת אפילו עם כמויות קטנות של נתוני אימונים מסוימים למשימה.", 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་གླེང་སྟེགས། དཔེར་ན་ཌིས་ཌིར་ངོ་མ་དང་འཛམ་གླིང་ནང་དུ་ཉར་འཇུག་བྱེད་པའི་ཚད་གཞི་རྩི གནད་དོན་འགན་འགྲོས་ཀྱི་ཚོགས་སྡུད་ལ་རྒྱབ་སྐྱོར་བྱེད་པའི་ལག་ཆ་སྒྲིག་ཆ་མང་ཙམ་སྤྱོད་པའི་ཆ་འཕྲིན་སྒྲིག་ཆས་ ཤོག་བྱང་འདིས་ཀྱིས་རྩིས་ཐོག་ཏུ་མང་ཆེ་བའི་ཨ་རིའི་ཌིས་ཌིའི་སྒོ་འབྱེད་པ་ཞིག་ངོ་འཛིན་བྱེད་ཀྱི་ཡོད། Exploration of this content revealed the most discussed topics and information types, and the paper presents a labelled dataset from seven emergency events that serves as a gold standard for several tasks in crisis informatics research. Using annotated data from the same event, a BERT model is fine-tuned to classify tweets into different categories in the multi-label setting. གྲུབ་འབྲས་བྱུང་། BERT་ལ་གཞི་བྱས་ཡོད་པའི་མིག་གཟུགས་རིས་དེ་ལས་འགུལ་སྐྱོན་པ་ཞིག་ཏུ་མངོན་གསལ་བ་རེད།', 'ha': "Mitandin Jamaica (SM) platforms kamar Twitter na samar da gwargwadon data masu gaskiyar da za'a iya samar da shi a lokacin bayani. Yi developer kayan aiki da za'a ƙarfafa jamii da ke cikin crisis-da-zartar da, ana buƙata tsari da ake da, da yawa ba za'a ƙunsa da wa lugha masu rauni ba. Wannan karatun na introduce Kawarith a multi-dialakan Arabic-Twitter Corbas for crisis, wanda ke samun kodi millions na arabu ta samu a tsakanin 22-crisis wanda ya faɗa tsakanin 2018 da 2020 kuma ya haɗa wasu ainai na hatari. Bayan bayanin wannan maɓalli ya bayyana mafi yawanci madaidaita da nau'i masu da aka yi wa magana, kuma takardan na bãyar da wani taƙaita na da aka rubũta shi daga bakin wahala bakwai na ƙayyade, wanda ke yi serva kamar wata gyãriya ga aikin wasu aikin da ke cikin fitina ɗin matalauta. Using annotated data from the same event, a BERT model is fine-tuned to classify tweets into different categories in the multi- label setting.  Matunan ya nuna cewa misalin BERT-based zasu fitar da mai kyau a kan wannan aikin, kuma kõ da ƙarami yawan mutane na tsarin aikin da aka ƙayyade shi.", 'sk': 'Platforme družbenih medijev, kot je Twitter, zagotavljajo velike količine podatkov v realnem času, ki jih je mogoče izkoristiti v množičnih izrednih razmerah. Razvoj orodij za podporo skupnostim, ki so jih prizadele krize, zahteva razpoložljive nabore podatkov, ki pogosto ne obstajajo za jezike z nizkimi viri. Ta prispevek predstavlja Kawarith večnarečni arabski Twitter korpus za krizne dogodke, ki vsebuje več kot milijon arabskih tweetov, zbranih med 22 krizami, ki so se zgodile med letoma 2018 in 2020 in vključevale več vrst nevarnosti. Raziskava te vsebine je razkrila najbolj obravnavane teme in vrste informacij, v prispevku pa je predstavljen označen nabor podatkov iz sedmih izrednih dogodkov, ki služi kot zlati standard za več nalog v kriznem raziskovanju informatike. Z uporabo označenih podatkov iz istega dogodka je model BERT natančno nastavljen za razvrstitev tweetov v različne kategorije v nastavitvi več oznak. Rezultati kažejo, da modeli, ki temeljijo na BERT, zagotavljajo dobro uspešnost pri tej nalogi tudi z majhnimi količinami podatkov o usposabljanju za posamezno nalogo.'}
{'en': 'ArCOV-19 : The First Arabic COVID-19 Twitter Dataset with Propagation Networks', 'pt': 'ArCOV-19: o primeiro conjunto de dados árabe COVID-19 do Twitter com redes de propagação', 'ar': 'ArCOV-19: أول مجموعة بيانات Twitter عربية لـ COVID-19 مع شبكات الانتشار', 'fr': 'ArcOV-19\xa0: Le premier jeu de données Twitter COVID-19 en arabe avec des réseaux de propagation', 'ja': 'ArCOV -19 ：伝播ネットワークを備えた最初のアラビア語の新型コロナウイルスのTwitterデータセット', 'es': 'ARCoV-19: El primer conjunto de datos árabe de Twitter sobre COVID-19 con redes de propagación', 'hi': 'ArCOV-19: प्रचार नेटवर्क के साथ पहला अरबी कोविड -19 ट्विटर डेटासेट', 'zh': 'ArCOV-19曰:首有传网络之阿拉伯语COVID-19 Twitter数集', 'ru': 'ArCOV-19: Первый арабский набор данных о COVID-19 в Twitter с сетями распространения', 'ga': 'ArCOV-19: An Chéad Tacar Sonraí Twitter Araibis COVID-19 le Líonraí Iomadaithe', 'ka': 'ArCOV-19: პირველი აპაბური COVID-19 Twitter მონაცემები პროპაგრაციის ქსელებით', 'hu': 'ArCOV-19: Az első arab COVID-19 Twitter adatkészlet terjesztési hálózatokkal', 'el': 'ArCOV-19: Το πρώτο αραβικό σύνολο δεδομένων με δίκτυα διάδοσης', 'it': 'ArCOV-19: Il primo set di dati Twitter COVID-19 arabo con reti di propagazione', 'kk': 'ArCOV- 19: Бірінші араб COVID- 19 Твиттер деректер қоры пропагация желілерімен', 'lt': 'ArCOV-19: Pirmasis arabų COVID-19 Twitter duomenų rinkinys su propagavimo tinklais', 'mk': 'ArCOV-19: Првиот арапски COVID-19 Твитер податок со пропагациски мрежи', 'ml': 'ആര്\u200dക്കോവി- 19: ആദ്യത്തെ അറബി കോവിഡി- 19 ടൂറര്\u200d ഡാറ്റാസറ്റ് പ്രവചന ശേഖരം', 'mt': 'ArCOV-19: L-Ewwel Sett ta’ Dejta Għarab COVID-19 fuq Twitter b’Netwerks ta’ Propagazzjoni', 'mn': 'ArCOV-19: Анхны Араб COVID-19 Twitter өгөгдлийн сан', 'ms': 'ArCOV-19: Dataset Twitter COVID-19 Arab Pertama dengan Rangkaian Propagasi', 'no': 'ArCOV-19: Den første arabiske COVID-19 Twitter-databasen med propagasjonsnettverk', 'pl': 'ArCOV-19: Pierwszy arabski zestaw danych na Twitterze COVID-19 z sieciami propagacyjnymi', 'sr': 'ArCOV-19: Prvi arapski COVID-19 podatak Twitter sa propagacijskim mrežama', 'si': 'ArCOV-19: පළමු අරාබික COVID-19 ට්විටර් දත්ත සංවේදනය සමග', 'ro': 'ArCOV-19: Primul set de date Twitter COVID-19 arab cu rețele de propagare', 'so': 'ArCOV-19: The First Carabi COVID-19 Twitter Dataset with Propagation Network', 'sv': 'ArCOV-19: Den första arabiska COVID-19 Twitter datauppsättningen med spridningsnätverk', 'ta': 'ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation Networks', 'ur': 'ArCOV-19: پہلی عربی COVID-19 ٹویٹر ڈاٹیسٹ پراپاژن نیٹورک کے ساتھ', 'uz': 'ArCOV- 19: Propaganda tarmoq bilan birinchi Arabcha COVID- 19 Twitter maʼlumotlar satri', 'vi': '(First Arab COVID-19 Twitter Name with Propagation Networks)', 'bg': 'АрКОВ-19: Първият арабски набор от данни с мрежи за разпространение', 'da': 'ArCOV-19: Det første arabiske COVID-19 Twitter datasæt med propagationsnetværk', 'nl': 'ArCOV-19: De eerste Arabische COVID-19 Twitter Dataset met verspreidingsnetwerken', 'hr': 'ArCOV-19: Prvi arapski COVID-19 podatak Twitter sa propagacijskim mrežama', 'ko': 'ArcoV-19: 최초의 아랍 코로나 트위터 데이터 세트', 'id': 'ArCOV-19: Dataset Twitter COVID-19 Arab Pertama dengan Rangkaian Propagasi', 'fa': 'ArCOV-19: اولین اطلاعات توئیتر عربی COVID-19', 'de': 'ArCOV-19: Der erste arabische COVID-19 Twitter Datensatz mit Verbreitungsnetzwerken', 'sw': 'ArCOV-19: Taarifa za kwanza za za Kiarabu COVID-19 za Twita zenye mitandao ya Utagaji', 'sq': 'ArCOV-19: Dataseti i parë arab COVID-19 në Twitter me rrjete propagacioni', 'tr': 'ArCOV-19: Ilkinji Arapça COVID-19', 'af': 'ArCOV- 19: Die Eerste Arabiese KOVID- 19 Twitter Dataset met propagasienetwerke', 'bn': 'ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation Networks', 'az': 'ArCOV-19: ńįlk …ôr…ôb COVID-19 Twitter veril…ônl…ôri propagasyon ańülarńĪ il…ô', 'bs': 'ArCOV-19: Prvi arapski COVID-19 podatak Twitter sa propagacijskim mrežama', 'ca': 'ArCOV-19: El primer conjunt de dades de Twitter COVID-19 àrab amb xarxes de propagació', 'cs': 'ArCOV-19: První arabská sada dat COVID-19 Twitter s propagačními sítěmi', 'et': 'ArCOV-19: Esimene Araabia COVID-19 Twitter andmekogum koos paljundusvõrkudega', 'fi': 'ArCOV-19: Ensimmäinen arabialainen COVID-19 Twitter-tietokokonaisuus propagaatioverkoilla', 'am': 'አርኮቪ-19: የመጀመሪያው ዐረብኛ COVID-19 ትዊተር ዳታዎችን በመናገር መረብ ላይ', 'hy': 'ArCOV-19: Առաջին արաբական COVID-19 թվիթերի տվյալների համակարգը պրոպագացիոն ցանցերով', 'he': 'ArCOV-19: קופסת נתוני טוויטר הערבית הראשונה COVID-19', 'sk': 'ArCOV-19: Prvi arabski nabor podatkov COVID-19 Twitter s širjenimi omrežji', 'jv': 'paper size', 'ha': 'ArCOV-19: The First Arabic COV-19 Twitter Dataset with prophesied Networks', 'bo': 'ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation Networks'}
{'en': 'In this paper, we present ArCOV-19, an Arabic COVID-19 Twitter dataset that spans one year, covering the period from 27th of January 2020 till 31st of January 2021. ArCOV-19 is the first publicly-available Arabic Twitter dataset covering COVID-19 pandemic that includes about 2.7 M tweets alongside the propagation networks of the most-popular subset of them (i.e., most-retweeted and -liked). The propagation networks include both retweetsand conversational threads (i.e., threads of replies). ArCOV-19 is designed to enable research under several domains including natural language processing, information retrieval, and social computing. Preliminary analysis shows that ArCOV-19 captures rising discussions associated with the first reported cases of the disease as they appeared in the Arab world. In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.', 'ar': 'في هذه الورقة ، نقدم ArCOV-19 ، مجموعة بيانات Twitter العربية COVID-19 التي تمتد لعام واحد ، وتغطي الفترة من 27 يناير 2020 حتى 31 يناير 2021. ArCOV-19 هي أول مجموعة بيانات عربية متاحة للجمهور على Twitter تغطي COVID - 19 جائحة تضم حوالي 2.7 مليون تغريدة جنبًا إلى جنب مع شبكات الانتشار للمجموعة الفرعية الأكثر شيوعًا منها (أي الأكثر إعادة تغريد وإعجابًا). تتضمن شبكات الانتشار كلاً من إعادة التغريد وخيوط المحادثة (أي سلاسل الردود). تم تصميم ArCOV-19 لتمكين البحث في العديد من المجالات بما في ذلك معالجة اللغة الطبيعية واسترجاع المعلومات والحوسبة الاجتماعية. يُظهر التحليل الأولي أن ArCOV-19 يلتقط المناقشات المتزايدة المرتبطة بالحالات الأولى المبلغ عنها للمرض كما ظهرت في العالم العربي. بالإضافة إلى تغريدات المصدر وشبكات الانتشار ، نصدر أيضًا استعلامات البحث والزاحف المستقل عن اللغة تُستخدم لجمع التغريدات للتشجيع على تنظيم مجموعات البيانات المماثلة.', 'es': 'En este documento, presentamos ARCoV-19, un conjunto de datos de Twitter árabe sobre COVID-19 que abarca un año, que abarca el período comprendido entre el 27 de enero de 2020 y el 31 de enero de 2021. ARCoV-19 es el primer conjunto de datos de Twitter en árabe disponible públicamente que cubre la pandemia de COVID-19 que incluye alrededor de 2,7 millones de tuits junto con las redes de propagación del subconjunto más popular de ellos (es decir, los más retwitteados y los que más me gustan). Las redes de propagación incluyen tanto retweets como hilos conversacionales (es decir, hilos de respuestas). ARCoV-19 está diseñado para permitir la investigación en varios dominios, incluidos el procesamiento del lenguaje natural, la recuperación de información y la computación social. El análisis preliminar muestra que ARCoV-19 captura las crecientes discusiones asociadas con los primeros casos reportados de la enfermedad tal como aparecieron en el mundo árabe.Además de los tuits fuente y las redes de propagación, también publicamos las consultas de búsqueda y el rastreador independiente del idioma utilizado para recopilar tuits para fomentar la conservación de conjuntos de datos similares.', 'fr': "Dans cet article, nous présentons ARCoV-19, un ensemble de données Twitter COVID-19 en arabe qui s'étend sur un an, couvrant la période du 27 janvier 2020 au 31 janvier 2021. ARCoV-19 est le premier ensemble de données Twitter en arabe accessible au public couvrant la pandémie de COVID-19 qui inclut environ 2,7 millions de tweets aux côtés des réseaux de propagation du sous-ensemble le plus populaire d'entre eux (c'est-à-dire les plus retweetés et aimés). Les réseaux de propagation comprennent à la fois des retweets et des fils de conversation (c'est-à-dire des fils de réponses). ArcOV-19 est conçu pour permettre la recherche dans plusieurs domaines, notamment le traitement du langage naturel, la récupération d'informations et l'informatique sociale. L'analyse préliminaire montre qu'ARCoV-19 capture les discussions croissantes associées aux premiers cas signalés de la maladie tels qu'ils sont apparus dans le monde arabe.Outre les tweets sources et les réseaux de propagation, nous publions également les requêtes de recherche et le robot indépendant de la langue utilisé pour collecter les Tweets pour encourager la conservation d'ensembles de données similaires.", 'pt': 'Neste artigo, apresentamos o ArCOV-19, um conjunto de dados árabe do Twitter COVID-19 que abrange um ano, cobrindo o período de 27 de janeiro de 2020 a 31 de janeiro de 2021. O ArCOV-19 é o primeiro conjunto de dados árabe do Twitter disponível publicamente cobrindo COVID -19 que inclui cerca de 2,7 milhões de tweets ao lado das redes de propagação do subconjunto mais popular deles (ou seja, mais retuitados e curtidos). As redes de propagação incluem tanto retuítes quanto threads de conversação (ou seja, threads de respostas). O ArCOV-19 foi projetado para permitir pesquisas em vários domínios, incluindo processamento de linguagem natural, recuperação de informações e computação social. A análise preliminar mostra que o ArCOV-19 captura discussões crescentes associadas aos primeiros casos relatados da doença conforme surgiram no mundo árabe. usado para coletar os tweets para incentivar a curadoria de conjuntos de dados semelhantes.', 'hi': 'इस पेपर में, हम ArCOV-19, एक अरबी कोविड -19 ट्विटर डेटासेट प्रस्तुत करते हैं जो एक वर्ष तक फैला हुआ है, जो 27 जनवरी 2020 से 31 जनवरी 2021 तक की अवधि को कवर करता है। ArCOV-19 कोविड-19 महामारी को कवर करने वाला पहला सार्वजनिक रूप से उपलब्ध अरबी ट्विटर डेटासेट है जिसमें उनमें से सबसे लोकप्रिय सबसेट के प्रचार नेटवर्क के साथ-साथ लगभग 2.7M ट्वीट्स शामिल हैं (यानी, सबसे अधिक-रीट्वीट और -पसंद किया गया)। प्रोपेगेशन नेटवर्क में रीट्वीट और संवादी धागे दोनों शामिल हैं (यानी, उत्तरों के धागे)। ArCOV-19 को प्राकृतिक भाषा प्रसंस्करण, सूचना पुनर्प्राप्ति और सामाजिक कंप्यूटिंग सहित कई डोमेन के तहत अनुसंधान को सक्षम करने के लिए डिज़ाइन किया गया है। प्रारंभिक विश्लेषण से पता चलता है कि ArCOV-19 बीमारी के पहले रिपोर्ट किए गए मामलों से जुड़ी बढ़ती चर्चाओं को कैप्चर करता है क्योंकि वे अरब दुनिया में दिखाई दिए थे। स्रोत tweets और प्रचार नेटवर्क के अलावा, हम खोज क्वेरी और भाषा-स्वतंत्र क्रॉलर भी जारी करते हैं जो समान डेटासेट के क्यूरेशन को प्रोत्साहित करने के लिए ट्वीट्स एकत्र करने के लिए उपयोग किया जाता है।', 'ja': '本稿では、2020年1月27日から2021年1月31日までの期間を対象とした、1年間にわたるアラビア語の新型コロナウイルス感染症(COVID -19)のTwitterデータセットであるArCOV -19を紹介します。 ArCOV -19は、新型コロナウイルス感染症のパンデミックをカバーする最初の一般公開されているアラビア語のTwitterデータセットであり、最も人気のあるサブセット（つまり、最もリツイートされ、「いいね」された）の伝播ネットワークと並んで、約270万件のツイートが含まれています。 伝播ネットワークは、リツイート及び会話型スレッド（すなわち、返信のスレッド）の両方を含む。 ArCOV -19は、自然言語処理、情報検索、ソーシャルコンピューティングを含むいくつかの領域で研究を可能にするように設計されています。 予備的な分析によると、ArCOV -19は、アラブ世界で最初に報告された疾患の症例に関連する議論の増加を捕捉することが示されています。ソースツイートと伝播ネットワークに加えて、私たちは、同様のデータセットのキュレーションを奨励するためにツイートを収集するために使用される検索クエリと言語に依存しないクローラもリリースします。', 'zh': '本文引ArCOV-19,此一阿拉伯语COVID-19 Twitter数集,跨度为一年,涵盖自2020年1月27日至2021年1月31日。 ArCOV-19首公可用者阿拉伯语Twitter数集,涵盖COVID-19大行,其大约270万条推文及其最受欢迎子集者网络(最为转喜)。 传网络包转和会话线程(即复线程)。 ArCOV-19旨在数域,兼自然语言处分,信息检索与世计。 初分析表明,ArCOV-19捕得阿拉伯世界首报病病例议。 自源推文传播网络之外,发于搜推文搜访语言之虫,以劝类集之治。', 'ga': 'Sa pháipéar seo, cuirimid i láthair ArCOV-19, tacar sonraí Araibis Twitter COVID-19 a mhairfidh bliain amháin, a chlúdaíonn an tréimhse ó 27 Eanáir 2020 go 31 Eanáir 2021. Is é ArCOV-19 an chéad tacar sonraí Araibis Twitter atá ar fáil go poiblí a chlúdaíonn COVID -19 paindéim lena n-áirítear thart ar 2.7M tweets taobh le líonraí iomadúcháin an fho-thacar is mó ráchairt acu (i.e., is mó a reitítear agus a thaitin). Áiríonn na líonraí iomadaithe an dá retweets agus snáitheanna comhrá (i.e., snáitheanna freagraí). Tá ArCOV-19 deartha chun taighde a chumasú i réimsí éagsúla lena n-áirítear próiseáil teanga nádúrtha, aisghabháil faisnéise agus ríomhaireacht shóisialta. Léiríonn réamhanailís go nglacann ArCOV-19 plé méadaitheach a bhaineann leis na chéad chásanna den ghalar a tuairiscíodh mar a bhí siad sa domhan Arabach. Chomh maith leis na tweets foinse agus na líonraí iomadaithe, scaoilimid freisin na ceisteanna cuardaigh agus an crawler teanga-neamhspleách. a úsáidtear chun na tvuíteanna a bhailiú chun tacair sonraí cosúla a choimeád.', 'ru': 'В этой статье мы представляем ArCOV-19, арабский набор данных о COVID-19 в Twitter, который охватывает период с 27 января 2020 года по 31 января 2021 года. ArCOV-19 является первым общедоступным арабским набором данных в Twitter, охватывающим пандемию COVID-19, который включает около 2,7 млн твитов наряду с сетями распространения наиболее популярного их подмножества (т. е. наиболее ретвитенных и -понравившихся). Сети распространения включают как ретвиты, так и разговорные потоки (т.е. потоки ответов). ArCOV-19 предназначен для проведения исследований в нескольких областях, включая обработку естественного языка, поиск информации и социальные вычисления. Предварительный анализ показывает, что ArCOV-19 фиксирует растущие обсуждения, связанные с первыми зарегистрированными случаями заболевания, как они появились в арабском мире. В дополнение к исходным твитам и сетям распространения, мы также выпускаем поисковые запросы и независимый от языка сканер, используемый для сбора твитов, чтобы стимулировать курирование аналогичных наборов данных.', 'el': 'Σε αυτή την εργασία, παρουσιάζουμε το ArCOV-19, ένα αραβικό σύνολο δεδομένων που εκτείνεται σε ένα έτος, καλύπτοντας την περίοδο από την 27η Ιανουαρίου 2020 έως την 31η Ιανουαρίου 2021 2021. Το ArCOV-19 είναι το πρώτο δημοσίως διαθέσιμο αραβικό σύνολο δεδομένων που καλύπτει την πανδημία του COVID-19, το οποίο περιλαμβάνει περίπου 2.7μαζί με τα δίκτυα διάδοσης του δημοφιλέστερου υποσύνολου από αυτά (δηλ., τα πιο δημοφιλή και αγαπημένα). Τα δίκτυα διάδοσης περιλαμβάνουν τόσο τα retweets όσο και τα νήματα συνομιλίας (δηλ. νήματα απαντήσεων). Το έχει σχεδιαστεί για να επιτρέψει την έρευνα σε διάφορους τομείς, συμπεριλαμβανομένης της επεξεργασίας φυσικής γλώσσας, της ανάκτησης πληροφοριών και των κοινωνικών υπολογιστών. Προκαταρκτική ανάλυση δείχνει ότι το ArCOV-19 καταγράφει αυξανόμενες συζητήσεις που σχετίζονται με τις πρώτες αναφερθείσες περιπτώσεις της νόσου όπως εμφανίστηκαν στον αραβικό κόσμο. Εκτός από τα πηγαία tweets και τα δίκτυα διάδοσης, απελευθερώνουμε επίσης τα ερωτήματα αναζήτησης και το ανεξάρτητο από τη γλώσσα ανιχνευτή που χρησιμοποιείται για τη συλλογή των tweets για να ενθαρρύνουμε τη δημιουργία παρόμοιων συνόλων δεδομένων.', 'hu': 'Ebben a tanulmányban bemutatjuk az ArCOV-19-et, egy arab COVID-19 Twitter adatkészletet, amely egy évre kiterjed, és lefedi a 2020. január 27-től 2021. január 31-ig terjedő időszakot. Az ArCOV-19 az első nyilvánosan hozzáférhető arab Twitter adatkészlet a COVID-19 járványt lefedő, amely körülbelül 2,7 millió tweetet tartalmaz a legnépszerűbb részhalmaz (azaz a leginkább retweetelt és -kedvelt) terjesztő hálózatai mellett. A terjesztési hálózatok magukban foglalják a retweeteket és a beszélgetési szálakat (azaz a válaszok szálait). Az ArCOV-19 célja, hogy lehetővé tegye a kutatást több területen, beleértve a természetes nyelv feldolgozását, az információk visszakeresését és a közösségi számítástechnika területén. Az előzetes elemzés azt mutatja, hogy az ArCOV-19 egyre növekvő vitákat rögzít a betegség első jelentett eseteivel kapcsolatban, ahogy azok az arab világban megjelentek. A forrás-tweetek és a terjesztő hálózatok mellett kiadjuk a keresési lekérdezéseket és a tweetek gyűjtésére használt nyelvfüggetlen feltérképezőt is, hogy ösztönözzük a hasonló adatkészletek kezelését.', 'ka': 'ამ დოკუნეში ჩვენ აპკოვი-19-ს, აპაბური COVID-19 Twitter-ის მონაცემები, რომელიც ერთ წლის გადასრულება, რომელიც პერიოდის გადასრულება 2020 წლის 27-დან 31-იანუარზე. ArCOV-19 არის პირველი ადამიანურად ხელსახულებული აპაბური Twitter მონაცემების სახელი, რომელიც COVID-19 პონდემიკის შესახებ, რომელიც შესახებ 2.7M tweets, რომელიც შესახებ მათგანი უფრო პოპოლური სოსტეტის პროპაგიაციის ქსელები პროპაგიაციის ქსელები იყენებენ ორივე შესაბამისი და კონტაქციონის კონტაქციონის კონტაქციონის კონტაქციები (მაგალითად, შესაბამისი კონ ArCOV- 19 იქნება რამდენიმე დიომენტების გამოყენება, რამდენიმე დიომენტების გამოყენება, ანუ თავისუფალური ენის გამოყენება, ინფორმაციის გამოყენება და სო პირველი ანალიზი ჩვენებს, რომ ArCOV-19 წარმოდგენა, როგორც აპაბის მსოფლიოში ჩვენ ჩვენებენ პირველი შეტყობინებული შემთხვევათან დაკავშირებული განსაზღვრებით. ჩვენ შემდეგ საძიებო კითხვები და ენის განსაზღვრებული კითხვების გახსნა, რომლებიც საძიებო კითხვები და სახელის განსაზღვრებული კითხვები გამოყენებულია, რომლებიც გამოყენებულია საძიებო სა', 'it': "In questo articolo presentiamo ArCOV-19, un set di dati Twitter COVID-19 arabo che copre il periodo dal 27 gennaio 2020 al 31 gennaio 2021. ArCOV-19 è il primo dataset Twitter arabo pubblicamente disponibile che copre la pandemia COVID-19 che include circa 2,7 milioni di tweet accanto alle reti di propagazione del sottoinsieme più popolare di loro (cioè, più retweeted e -like). Le reti di propagazione includono sia retweet che conversazioni (cioè thread di risposte). ArCOV-19 è progettato per consentire la ricerca in diversi settori, tra cui l'elaborazione del linguaggio naturale, il recupero di informazioni e il social computing. L'analisi preliminare mostra che ArCOV-19 cattura crescenti discussioni associate ai primi casi segnalati della malattia come sono apparsi nel mondo arabo. Oltre ai tweet sorgente e alle reti di propagazione, rilasciamo anche le query di ricerca e il crawler indipendente dalla lingua utilizzato per raccogliere i tweet per incoraggiare la cura di set di dati simili.", 'kk': 'Бұл қағазда, біз АрCOV-19, Араб COVID-19 Твиттер деректер қорын бір жыл бойынша келтіреміз, 2020 жылдың 27 қаңтарынан 31 қаңтарына дейін айналыстырылатын. ArCOV-19 - бірінші Араб Твиттер деректер қоры COVID-19 пандемиясын жазылатын, олардың ең маңызды субтитуларының пропагациялық желілерінің жағында 2,7M tweets жазылатын пандемиясы (т.е. қайтарылған және - жақсы). Пропагациялық желінде қайта апта және қатынау ілеспелері (яғни, жауаптардың ілеспелері). ArCOV- 19 бірнеше доменде зерттеулерді қолдану үшін табиғи тілдерді өңдеу, мәліметті алу және әлемдік есептеу үшін құрылады. Алдыңғы анализ ArCOV-19 Араб әлемінде көрсетілген алғашқы хабарлаған аурулардың бірінші жағдайларына сәйкес көтерілген дискуссияларын түсіруді көрсетеді. Бастапқы tweets және пропагациялық желілердің қосымша, іздеу сұрақтарын және тілден тәуелсіз крулерді ұқсас деректер жинақтарын құрастыру үшін қолданылатын tweets жинақтау үшін қолданылатын.', 'mk': 'Во овој весник го претставуваме ArCOV-19, арапски компјутер на Твитер COVID-19 кој трае една година, кој го покрива периодот од 27-ми јануари 2020 до 31-ви јануари 2021 година. ArCOV-19 е првиот јавно достапен арапски Твитер податок кој ја покрива пандемијата COVID-19, кој вклучува околу 2,7 милиони твитови заедно со мрежите за пропагација на најпопуларниот подгруп од нив (т.е., најретвитирани и најобожавани). Мрежата за пропагација вклучуваат и ретвитови, и конверзационални жици (т.е. жици на одговори). ArCOV-19 is designed to enable research under several domains including natural language processing, information retrieval, and social computing.  Прелиминарната анализа покажува дека АРКОВ-19 ги фати растечките дискусии поврзани со првите пријавени случаи на болеста како што се појавија во арапскиот свет. Покрај твитовите на изворот и мрежите за пропагација, ние исто така ги објавуваме прашањата за пребарување и јазичкиот независен пребарувач кој се користи за собирање на твитовите за охрабрување на корацијата на слични податоци.', 'ms': 'In this paper, we present ArCOV-19, an Arabic COVID-19 Twitter dataset that spans one year, covering the period from 27th of January 2020 till 31st of January 2021.  ArCOV-19 adalah set data Twitter Arab pertama yang tersedia secara awam yang meliputi pandemi COVID-19 yang termasuk sekitar 2.7M tweet bersama rangkaian penyebaran bagi subset yang paling populer daripada mereka (iaitu yang paling diulang dan -suka). Rangkaian penyebaran mengandungi retweet dan benang perbualan (iaitu benang jawapan). ArCOV-19 direka untuk membolehkan kajian dibawah beberapa domain termasuk pemprosesan bahasa semulajadi, pemulihan maklumat, dan komputer sosial. Analisis awal menunjukkan bahawa ArCOV-19 menangkap pembicaraan yang meningkat berkaitan dengan kes pertama yang dilaporkan penyakit seperti yang muncul di dunia Arab. Selain tweet sumber dan rangkaian penyebaran, kami juga melepaskan pertanyaan pencarian dan pencari bebas bahasa yang digunakan untuk mengumpulkan tweet untuk mendorong curasi set data yang sama.', 'mt': 'In this paper, we present ArCOV-19, an Arabic COVID-19 Twitter dataset that spans one year, covering the period from 27th of January 2020 till 31st of January 2021.  ArCOV-19 is the first publicly-available Arabic Twitter dataset covering COVID-19 pandemic that includes about 2.7M tweets alongside the propagation networks of the most-popular subset of them (i.e., most-retweeted and -liked).  In-netwerks ta’ propagazzjoni jinkludu kemm ir-retweets kif ukoll il-ħjut ta’ konverżjoni (jiġifieri ħjut ta’ tweġibiet). ArCOV-19 huwa mfassal biex jippermetti riċerka f’diversi oqsma inkluż l-ipproċessar tal-lingwi naturali, l-irkupru tal-informazzjoni, u l-kompjuter soċjali. Analiżi preliminari turi li ArCOV-19 jaqbad diskussjonijiet li qed jiżdiedu assoċjati mal-ewwel każijiet irrappurtati tal-marda kif dehru fid-dinja Għarbija. Minbarra t-tweets tas-sors u n-netwerks ta’ propagazzjoni, irrilaxxajna wkoll il-mistoqsijiet dwar it-tiftix u t-trawler indipendenti mil-lingwa użati biex jiġbru t-tweets biex jinkoraġġixxu l-kurazzjoni ta’ settijiet ta’ dejta simili.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d അര്\u200dക്കോവി-19, ഒരു അറബി കോവിഡി-19 ട്ടൂറര്\u200d ഡാറ്റാസറ്റ് കാണിക്കുന്നു. അത് ഒരു വര്\u200dഷം പ്രദര്\u200dശിപ്പിക്കുന്നു. 2020 ജാ ആര്\u200dക്കോവി- 19 ആദ്യത്തെ പ്രപസ്സിദ്ധമായ അറബി വിവരങ്ങള്\u200d കോവിഡി-19 പാന്\u200dഡെമിക്ക് വെച്ചുള്ള വിവരങ്ങളാണ്. അതില്\u200d ഏറ്റവും പ്രധാനപ്പെട്ട വിവരങ്ങളുടെ നെറ്റുകള്\u200d കൂടി പ്രൊപ്പഷന്\u200d നെറ്റുകള്\u200d രണ്ടിലും വീണ്ടും സംസാരിക്കുന്ന ത്രൂഡുകളും ഉള്\u200dപ്പെടുത്തുന്നു. (അതായത് ഉത്തരം ഉത്തരങ ആര്\u200dക്കോവി- 19 സംവിധാനം സ്വാഭാവികമായ ഭാഷ പ്രക്രിയശ്ചിത്തം, വിവരങ്ങള്\u200d തിരിച്ചെടുക്കുന്നതും, സാമൂഹ്യ കണക്ടിങ ആദ്യ വിശ്വാസം കാണിച്ചുകൊണ്ടിരിക്കുന്നു അര്\u200dക്കോവി-19 രോഗയുടെ ആദ്യത്തെ റിപ്പോര്\u200dട്ട് ചെയ്ത കേസുകളുമായി സം സ്രോതസ്സിന്റെ ടൂട്ടുകളും പ്രപഞ്ചന നേര്\u200dവറുകളും കൂടാതെ, തെരച്ചില്\u200d ചോദ്യങ്ങളും ഭാഷ സ്വാതന്ത്ര്യാപ്തിയുള്ള ക്രൂവരും തുടങ്ങുന്നതിന', 'lt': 'In this paper, we present ArCOV-19, an Arabic COVID-19 Twitter dataset that spans one year, covering the period from 27th of January 2020 till 31st of January 2021.  ArCOV-19 yra pirmasis viešai prieinamas Arabų Twitter duomenų rinkinys, apimantis COVID-19 pandemiją, kuriame yra apie 2,7 mln. tweetų kartu su populiariausio jų pogrupio dauginimo tinklais (t. y. labiausiai pakartotiniu ir mėgstamu). Plėtojimo tinklai apima ir retweets, ir pokalbio siūlus (t. y. atsakymų siūlus). ArCOV-19 skirtas tam, kad būtų galima atlikti mokslinius tyrimus keliose srityse, įskaitant natūralų kalbų apdorojimą, informacijos gavimą ir socialinę skaičiavimą. Išankstinė analizė rodo, kad ArCOV-19 apima didėjančias diskusijas, susijusias su pirmaisiais ligos atvejais, apie kuriuos pranešta Arab ų pasaulyje. In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.', 'no': 'I denne papiret presenterer vi ArCOV-19, en arabisk COVID-19-dataset på Twitter som utgår ein år, og dekker perioden frå 27. januar 2020 til 31. januar 2021. ArCOV-19 er den første offentlig tilgjengelege arabiske Twitter-datasettet som dekkar COVID-19 pandemikk som inneheld omtrent 2,7M-tweets blant propagasjonsnettverket av dei mest populære undergruppene av dei (t.d. mest retweeted og -liked). Programnettverket inneheld både retweet og samtaletrådar (t.d. trådar av svar). ArCOV- 19 er designert for å slå på forskning under fleire domene, inkludert naturspråkshandtering, informasjonshenting og sosialdatamaskin. Preliminar analyse viser at ArCOV-19 får opp diskusjonar som er assosiert med de første rapporterte tilfellene av sykdommen som dei oppstod i arabiske verden. I tillegg til kjeldetweetene og propagasjonsnettverkene, søkjespørjingane og språk-uavhengige krawler brukte for å samla tweetene for å oppfordre kurasjonen av liknande datasett.', 'pl': 'W niniejszym artykule przedstawiamy ArCOV-19, arabski zestaw danych dotyczących COVID-19 Twitter, który obejmuje jeden rok, obejmujący okres od 27ego stycznia 2020 do 31ego stycznia 2021. ArCOV-19 jest pierwszym publicznie dostępnym arabskim zestawem danych dotyczących pandemii COVID-19, który obejmuje około 2,7M tweety wraz z sieciami propagacyjnymi najpopularniejszej z nich podzbioru (tj. najbardziej retweetowanych i polubionych). Sieci propagacyjne obejmują zarówno retweety, jak i wątki konwersacyjne (tj. wątki odpowiedzi). ArCOV-19 ma na celu umożliwienie badań w kilku dziedzinach, w tym przetwarzania języka naturalnego, odzyskiwania informacji i obliczenia społecznościowego. Wstępna analiza pokazuje, że ArCOV-19 uwzględnia rosnące dyskusje związane z pierwszymi zgłoszonymi przypadkami choroby, jak pojawiły się one w świecie arabskim. Oprócz tweetów źródłowych i sieci propagacyjnych, udostępniamy również zapytania wyszukiwania i niezależny od języka crawler używany do gromadzenia tweetów, aby zachęcić do tworzenia podobnych zbiorów danych.', 'mn': 'Энэ цаасан дээр бид АрCOV-19, Араб COVID-19 Twitter өгөгдлийн санг нэг жил нэмэгдүүлдэг. 2020 оны 1-р сарын 27-ээс 2021 оны 1-р сарын 31-нд хүртэл тэмдэглэсэн. ArCOV-19 бол хамгийн алдартай хамгийн олон хүмүүсийн дэлгэрүүлэлтийн сүлжээний хамтдаа хамт 2.7М tweets бүрдсэн COVID-19 пандемикийн хамгийн анхны Араб Twitter өгөгдлийн сан юм. Хөгжиж буй сүлжээнд хоёр дахин хойш хойш хоёр дахин хойш холбоотой, ярилцлагын дараа (яг л хариултын дараа). ArCOV-19 нь байгалийн хэл процесс, мэдээлэл авах, нийгмийн тооцоолох боломжтой олон хэсэгт судалгааг боловсруулахын тулд зориулагдсан. Эхний шинжилгээ нь АрCOV-19 нь Арабын ертөнцөд харагдаж байсан анхны мэдээллийн өвчинтэй холбогдсон ярилцлагуудыг авч үздэг. Мөн эх үүсвэрийн tweets болон дэвшүүлэлтийн сүлжээний нэмэлт нь бид хайлтын квери болон хэлний хамааралгүй сурагчид tweets-г цуглуулахын тулд төстэй өгөгдлийн сангуудыг урам зориулахын тулд ашигладаг.', 'ro': 'În această lucrare, prezentăm ArCOV-19, un set de date Twitter COVID-19 arab care se întinde pe un an, acoperind perioada 27 ianuarie 2020 până la 31 ianuarie 2021. ArCOV-19 este primul set de date Twitter arab disponibil public care acoperă pandemia COVID-19, care include aproximativ 2,7 milioane de tweet-uri alături de rețelele de propagare ale celui mai popular subset al acestora (adică cel mai retweeted și -like). Rețelele de propagare includ atât retweet-uri, cât și fire conversaționale (adică fire de răspunsuri). ArCOV-19 este conceput pentru a permite cercetarea în mai multe domenii, inclusiv prelucrarea limbajului natural, recuperarea informațiilor și calculul social. Analiza preliminară arată că ArCOV-19 surprinde discuții în creștere asociate cu primele cazuri raportate de boală așa cum au apărut în lumea arabă. Pe lângă tweeturile sursă și rețelele de propagare, lansăm și interogările de căutare și crawlerul independent de limbă folosit pentru a colecta tweeturile pentru a încuraja curățarea seturilor de date similare.', 'sr': 'U ovom papiru predstavljamo ArCOV-19, arapsku kompletu podataka COVID-19 Twitter-a koja traje godinu dana, pokrivajući period od 27. januara 2020. do 31. januara 2021. ArCOV-19 je prvi javno dostupni arapski Twitter podatak koji pokriva pandemiju COVID-19, uključujući oko 2,7M tweets zajedno sa propagacijskim mrežama najpopularnijih podataka njih (tj. najponovnijih i -voljenih). Mreži proširenja uključuju i retweet i razgovorne trgovine (tj. trgovine odgovora). ArCOV-19 je dizajniran kako bi omogućio istraživanje pod nekoliko domena uključujući prirodnu obradu jezika, prikupljanje informacija i društveno računalo. Preliminarna analiza pokazuje da ArCOV-19 uhvata rastuće diskusije povezane sa prvim prijavljenim slučajevima bolesti kao što su se pojavili u arapskom svijetu. Pored izvornih tweeta i propagacijskih mreža, takođe oslobodimo pretraživanje ispitivanja i jezički nezavisni krawler koji se koristi za skupljanje tweeta kako bi ohrabrili korištenje sličnih podataka.', 'so': "Warqadan waxaynu ku qornaa ArCOV-19, taas oo ah qoraal labaad oo Carabi ah COVID-19 oo ah sanad, kaas oo ku daboolaya xiliga ah 27aad oo Januar 2020 ilaa 31aad oo Januar 2021. ArCOV-19 waa kooxda ugu horeeyay e e ku qoran taarifka labaad oo afka Carabiga ah oo ku qoran cudurada COVID-19, kaas oo ku qoran qiyaastii 2.7M tweetyo iyo shabakada propaganda ee kooxahooda ugu wada populan (tusaale ahaan inta badan weerar-weerar iyo -la jeclaado). Shabakada ogeysiiska waxaa ka mid ah labada weelal oo ku qoran labaad iyo kooxaha hadalka (tusaale ahaan kooxaha jawaabaha). ArCOV-19 waxaa loogu talagalay in lagu sameeyo waxbarasho ka hooseeya guryo badan, kuwaas oo ka mid ah baaraandegista luqada asalka ah, helitaanka macluumaadka iyo xisaabinta bulshada. Analyska hore wuxuu muujiyaa in ArCOV-19 la qabsaday hadal kordhaya oo la xiriira xaalada ugu horraysay ee cudurka marka ay ka muuqatay dunida Carabiga. Inta dheer waxaa dheer oo ah tweetiyada iyo shabakadda ogeysiiska, waxaynu sii daayeynaa su'aalaha raadinta iyo qofka luqada ah oo aan xor laheyn oo isticmaali karta tweetka si aan u dhiirrigelino bandhigyada sawirada la mid ah.", 'si': 'මේ පැත්තට, අපි ArCOV-19, අරාබික COVID-19 ට්විටර් දත්ත සූදානයක් පිළිගත්තා අවුරුද්දක් වෙනවා, ජානුවාරි 2021 වල ජානුවාරි 31වෙන ArCOV-19 තමයි පළමුවෙනි සාර්වාධිකයෙන් පුළුවන් අරාබික් ට්විටර් දත්ත සැට COVID-19 පැන්ඩීමික් සම්බන්ධ කරනවා, ඒ වගේම 2.7M ට්විට් වලින් ඔවුන්ගේ වැඩි ප්\u200dරවාහනය ජාලයේ ප්\u200dරතික්\u200dරියාත්මක ජාලයේ දෙන්නම ප්\u200dරතික්\u200dරියාත්මක සහ ප්\u200dරතික්\u200dරියාත්මක වාර්තාව ArCOV- 19 විස්තර කරලා තියෙන්නේ ස්වභාවික භාෂාව පරීක්ෂණය, තොරතුරු පිළිගන්න, සමාජික පරීක්ෂණය සමග ස ප්\u200dරධාන විශ්ලේෂණය පෙන්වන්නේ ArCOV-19 වලින් අරාබ් ලෝකයේ පෙන්වන්න පුළුවන් ප්\u200dරධාන විස්තර සමඟ විස්තර කත මුළු ට්විට්ස් සහ ප්\u200dරවේශන ජාලය සමඟ, අපි පරීක්ෂණය සහ භාෂාව ස්වේශ කරපු ක්\u200dරෝල්ලර් සම්බන්ධ කරපු ට්විට්ස් එකතු කරනවා වග', 'sv': 'I denna uppsats presenterar vi ArCOV-19, en arabisk COVID-19 Twitter datauppsättning som sträcker sig över ett år och täcker perioden 27 januari 2020 till 31 januari 2021. ArCOV-19 är den första offentligt tillgängliga arabiska Twitter-datauppsättningen som täcker COVID-19-pandemin och innehåller cirka 2,7 miljoner tweets tillsammans med spridningsnätverk för den mest populära deluppsättningen av dem (dvs. mest retweetade och gillade). Utbredningsnätverk omfattar både retweets och konversationstrådar (dvs trådar av svar). ArCOV-19 är utformad för att möjliggöra forskning inom flera områden, inklusive behandling av naturligt språk, informationssökning och social databehandling. Preliminära analys visar att ArCOV-19 fångar stigande diskussioner i samband med de första rapporterade fallen av sjukdomen som de uppträdde i arabvärlden. Förutom källtweets och spridningsnätverk släpper vi också sökfrågorna och den språkoberoende crawler som används för att samla in tweets för att uppmuntra till kurering av liknande dataset.', 'ta': 'இந்த காகிதத்தில், நாம் அர்கோவி-19, ஒரு அரபி COVID-19 தொடர்பு தகவல் அமைப்பை காண்பிக்கிறோம். அது ஒரு வருடத்தில் வரும், 2020 ஜன்யூரியில் இருந்து  ஆர்கோவி- 19 என்பது முதல் பொதுவான அரபி தகவல் அமைப்பு COVID-19 துன்பந்தத்தை பற்றி மூடப்பட்டுள்ளது. அது 2. 7M துவங்களை சேர்த்துள்ளது அதில் பெரிய பிணையத்தின் பிணையத்தின் ப இந்த விரிவாக்க வலைப்பின்னல்கள் இருவரும் மீண்டும் மற்றும் பேச்சு நூல்களும் சேர்க்கப்படுகிறது (அதாவது, பதில் நூ ஆர்கோவி- 19 வடிவமைக்கப்பட்டுள்ளது இயற்கையான மொழி செயல்படுத்தல், தகவல் மீட்டுதல், மற்றும் சமூக கணக்கீடு முன்னுரிமை ஆய்வு காண்பிக்கப்படுகிறது அர்கோவி-19 பிடித்துக் கொண்டு வரும் விவாதத்தில் தொடர்புடைய முதல் அறிக்கப்பட In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.', 'ur': 'اس کاغذ میں ہم ArCOV-19 کو پیش کرتے ہیں، ایک عربی COVID-19 ٹویٹر ڈاٹسٹ جو ایک سال طول ہوتا ہے، جو 2020 کی جنوری 27 سے 31 جنوری تک پورے ہوتے ہیں۔ ArCOV-19 سب سے پہلے صاف صاف صاف صاف صاف صاف عربی ٹویٹر ڈاٹ سٹ ہے جو COVID-19 پاندمیک کو پورا کرتا ہے جو ان میں سے سب سے زیادہ محبوب ترین سٹٹ کے پیچھے 2.7M ٹویٹوں میں شامل ہوتا ہے پراپاژن نیٹورک دونوں دوبارہ ہفتے اور رابطہ کی ترڈیز میں شامل ہوتے ہیں (یعنی جواب کے ترڈیز). ArCOV-19 طراحی کی گئی ہے کہ بہت سی ڈومین کے اندر تحقیقات کو قابل کر سکے جیسے طبیعی زبان پردازی، معلومات حاصل کرنے، اور سوسیل کمپیوٹینگ. ابتداء تحلیل دکھاتا ہے کہ آرکووی-19 اس بیماری کے پہلے گزارے کیسٹوں کے ساتھ اضافہ ہونے والی بحث کو پکڑتا ہے جس طرح وہ عربی دنیا میں ظاہر ہوتے ہیں۔ سورج ٹیوٹ اور پراپاژن نیٹ ورک کے علاوہ، ہم نے جہاز سواریوں کو بھی آزاد کردیا اور زبان-مستقل کرولر کو بھی ویٹوں کو جمع کرنے کے لئے استعمال کیا گیا تھا جیسا ڈیٹ سٹ کے کرونٹ کو مہربانی کرنے کے لئے۔', 'uz': "Bu qogʻozda ArCOV-19, bir yil keladigan Arab COVID-19 Twitter maʼlumotlar tarkibini hozir qilamiz, 2020 Januardan 27 marta 2021 januardan 31 marta qaraydi. ArCOV-19 - COVID-19 pandemik bilan birinchi offentliga boʻlgan arab xabarlar tarkibi. Bu ko'pchilik tarmoqning tarmoqlarining tarmoqlarida 2. 7M Twitter yozuvlari bor. Name ArCOV-19 asl tilni boshqarish, maʼlumot olish, va ijodkorlik kompyuterga ega bo'lgan bir nechta domaner davomida qidirishni foydalanish uchun yaratiladi. Preliminary analysis shows that ArCOV-19 captures rising discussions associated with the first reported cases of the disease as they appeared in the Arab world. Manba tweeti va propaganda tarmoqlar bilan boshqa, biz qidirish soʻrovlarini va foydalanish uchun foydalanadigan Twittlarni olib tashlash uchun ishlash uchun ishlatiladigan tilni saqlash.", 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu ArCOV-19, là một tập tin trên Twitter của Arab COVID-19, bao gồm cả một năm, từ phát thứ hai tháng giêng 2020 cho đến 18th Tháng Giêng 2021. The ArCOV-19 là tập tin cấp cao đầu tiên trên Twitter có thể công khai bao gồm cả đại dịch COVID-19, gồm có khoảng 2.7M tweet cùng với hệ thống truyền thông của nhóm người nổi tiếng nhất (tức là dịch vụ hay thích nhất). Các mạng truyền hình gồm cả những sợi nối lặp lại và đối thoại (tức là những dòng của câu trả lời). ArCOV-19 được thiết kế để tiến hành nghiên cứu trong nhiều lĩnh vực bao gồm việc xử lý ngôn ngữ tự nhiên, thu thập thông tin, và tính to án xã hội. Khám nghiệm sơ bộ cho thấy rằng ArCOV-19 thu hồi cuộc thảo luận bắt đầu khi liên quan đến các ca bệnh đầu tiên được báo cáo khi xảy ra ở thế giới Ả Rập. Ngoài những dòng tweet nguồn và mạng truyền hình, chúng tôi cũng công bố các câu hỏi tìm kiếm và máy kích hoạt ngôn ngữ để thu thập các tweet để khuyến khích việc quản lý dữ liệu tương tự.', 'nl': 'In dit artikel presenteren we ArCOV-19, een Arabische COVID-19 Twitter dataset die een jaar beslaat en de periode van 27e januari 2020 tot 31e januari 2021 bestrijkt. ArCOV-19 is de eerste publiekelijk beschikbare Arabische Twitter-dataset over COVID-19-pandemie die ongeveer 2,7M-tweets bevat naast de propagatienetwerken van de meest populaire subset ervan (d.w.z. meest retweeted en -liked). De verspreidingsnetwerken omvatten zowel retweets als conversational threads (d.w.z. threads van antwoorden). ArCOV-19 is ontworpen om onderzoek mogelijk te maken onder verschillende domeinen, waaronder natuurlijke taalverwerking, informatieterugwinning en social computing. Uit voorlopige analyse blijkt dat ArCOV-19 de toenemende discussies vastlegt die verband houden met de eerste gerapporteerde gevallen van de ziekte zoals ze in de Arabische wereld verschenen. Naast de brontweets en de propagatienetwerken geven we ook de zoekopdrachten en de taalonafhankelijke crawler vrij die gebruikt wordt om de tweets te verzamelen om de curatie van vergelijkbare datasets aan te moedigen.', 'bg': 'В настоящата статия представяме арабски набор от данни, обхващащ периода от 27 януари 2020 г. до 31 януари 2021 г. АрКОВ-19 е първият обществено достъпен арабски набор от данни в Туитър, обхващащ пандемията, който включва около 2,7 млн. туитове заедно с мрежите за разпространение на най-популярната подгрупа от тях (т.е. най-ретуитираните и харесваните). Разпространителните мрежи включват както ретуийтове, така и разговорни теми (т.е. теми на отговори). АрКОВ-19 е предназначен да даде възможност за изследвания в няколко области, включително обработка на естествен език, извличане на информация и социални изчисления. Предварителният анализ показва, че улавя нарастващите дискусии, свързани с първите докладвани случаи на болестта, както се появяват в арабския свят. В допълнение към източниците на туитове и мрежите за разпространение, ние също публикуваме заявките за търсене и независимия от езика обхождач, използван за събиране на туитове, за да насърчим създаването на подобни набори от данни.', 'id': 'Dalam kertas ini, kami mempersembahkan ArCOV-19, sebuah set data Arab COVID-19 Twitter yang berlangsung satu tahun, menutupi periode dari 27 Januari 2020 sampai 31 Januari 2021. ArCOV-19 adalah set data Arab Twitter pertama yang tersedia publik yang meliputi pandemi COVID-19 yang termasuk sekitar 2,7M tweet di samping jaringan propagasi yang paling populer dari mereka (i.e., paling retweeted dan -liked). Jaringan propagasi termasuk retweet dan benang konversasi (i.e., benang jawaban). ArCOV-19 dirancang untuk memungkinkan penelitian di bawah beberapa domain termasuk proses bahasa alami, penerimaan informasi, dan komputer sosial. Analisi awal menunjukkan bahwa ArCOV-19 menangkap diskusi yang meningkat yang berhubungan dengan kasus pertama yang dilaporkan penyakit seperti yang muncul di dunia Arab. Selain tweet sumber dan jaringan propagasi, kami juga melepaskan pertanyaan pencarian dan perangkat bebas bahasa yang digunakan untuk mengumpulkan tweet untuk mendorong curasi set data yang sama.', 'da': 'I denne artikel præsenterer vi ArCOV-19, et arabisk COVID-19 Twitter datasæt, der dækker perioden fra 27. januar 2020 til 31. januar 2021. ArCOV-19 er det første offentligt tilgængelige arabiske Twitter datasæt, der dækker COVID-19 pandemi, der omfatter omkring 2,7 millioner tweets sideløbende med spredningsnetværk af de mest populære delsæt af dem (dvs. mest retweetede og -liked). Udbredelsesnetværket omfatter både retweets og samtaletråde (dvs. tråde af svar). ArCOV-19 er designet til at muliggøre forskning inden for flere områder, herunder behandling af naturligt sprog, informationssøgning og social computing. Foreløbig analyse viser, at ArCOV-19 fanger stigende diskussioner i forbindelse med de første rapporterede tilfælde af sygdommen, som de optrådte i den arabiske verden. Ud over kildetweets og spredningsnetværk frigiver vi også søgeforespørgslerne og den sproguafhængige crawler, der bruges til at indsamle tweets for at tilskynde til kuratering af lignende datasæt.', 'hr': 'U ovom papiru predstavljamo ArCOV-19, arapski komplet podataka COVID-19 Twitter-a koji spaja godinu dana, pokrivajući razdoblje od 27. siječnja 2020. do 31. siječnja 2021. ArCOV-19 je prvi javno dostupni arapski Twitter podatak koji obuhvaća pandemiju COVID-19, uključujući oko 2,7M tweets zajedno s propagacijskim mrežama najpopularnijih podataka njih (tj. najviše povratnih i -voljenih). Proširenja mreža uključuju i retweet i razgovorne trgovine (tj. trgovine odgovora). ArCOV-19 je dizajniran kako bi omogućio istraživanje pod nekoliko domena uključujući obradu prirodnog jezika, prikupljanje informacija i društveno računalo. Preliminarna analiza pokazuje da ArCOV-19 uhvati rastuće rasprave povezane s prvim prijavljenim slučajevima bolesti kao što su se pojavili u arapskom svijetu. Osim izvornih tweeta i propagacijskih mreža, također objavljujemo pretraživanje ispitivanja i jezički nezavisni krawler koji se koristi za skupljanje tweeta kako bi potaknuli usmjerenje sličnih podataka.', 'fa': 'در این کاغذ، ما یک مجموعه اطلاعات عربی COVID-19 را پیشنهاد می\u200cکنیم که یک سال طول می\u200cکشد، و دوره\u200cای از 27 ژانویه 2020 تا 31 ژانویه 2021 را پوشاندیم. ArCOV-19 اولین مجموعه داده\u200cهای عربی در دسترس عمومی است که در مورد پاندمیک COVID-19 شامل است که حدود ۲.7M tweets در کنار شبکه\u200cهای گسترش عمومی از زیر جمعیت مشهور آن\u200cها (یعنی بیشترین نوشته\u200cها و -دوست دارند). شبکه\u200cهای گسترش دو هفته\u200cی دوباره و نقطه\u200cهای گفتگو (یعنی نقطه\u200cهای جواب) شامل می\u200cشوند. ArCOV-19 طراحی شده تا تحقیقات زیر چند دامنه\u200cها را فعال کند که شامل پرداخت زبان طبیعی، گیری اطلاعات و محاسبات اجتماعی باشد. تحلیل اولیه نشان می دهد که آرکووی-۱۹ در دنیای عربی به عنوان اولین پرونده گزارش داده شده بیماری که در دنیای عربی ظاهر شد، مذاکره\u200cهای بالا رشد می\u200cگیرد. اضافه به تویتهای منبع و شبکه های گسترش، ما همچنین سوال جستجویی را آزاد می\u200cکنیم و کلاورهای مستقل به زبان استفاده می\u200cکنیم تا تویتها را جمع کنیم تا ترکیب مجموعه\u200cهای داده\u200cهای مانند را تحویل دهیم.', 'de': 'In diesem Beitrag stellen wir ArCOV-19 vor, einen arabischen COVID-19 Twitter-Datensatz, der ein Jahr umfasst und den Zeitraum von 27th Januar 2020 bis 31st Januar 2021 abdeckt. ArCOV-19 ist der erste öffentlich verfügbare arabische Twitter-Datensatz zur COVID-19-Pandemie, der neben den Verbreitungsnetzwerken der beliebtesten Teilmenge von ihnen (d. h. am meisten retweeted und -liked) etwa 2,7M-Tweets enthält. Die Verbreitungsnetzwerke umfassen sowohl Retweets als auch Konversationsthreads (d. h. Threads von Antworten). ArCOV-19 wurde entwickelt, um Forschung in verschiedenen Bereichen zu ermöglichen, einschließlich natürlicher Sprachverarbeitung, Informationsabruf und Social Computing. Die vorläufige Analyse zeigt, dass ArCOV-19 zunehmende Diskussionen im Zusammenhang mit den ersten berichteten Fällen der Krankheit erfasst, wie sie in der arabischen Welt aufgetreten sind. Neben den Quell-Tweets und den Verbreitungsnetzwerken veröffentlichen wir auch die Suchanfragen und den sprachunabhängigen Crawler, mit dem die Tweets gesammelt werden, um die Kuration ähnlicher Datensätze zu fördern.', 'tr': 'Bu kagyzda biz ArCOV-19, arapça COVID-19 Twitter datu setirini bir ýyl geçirip, 2020-nji ýylyň 27-nji januardan 31-nji Ýanwar 2021-e çenli baglaýarys. ArCOV Çykyşyk aňlaryň ikisi ýene-de asty we gürrüňlik threads (diýmek bolsa, jogaplaryň threads) hem bar. ArCOV-19 dogal dil işleýişi, maglumat almak we sosial kompýuterler bilen birnäçe sahypalarda barlag etmäge tasarlanýar. Öňki analýusy ArCOV-19 arap dünýäde görünýän ýaly ilkinji rapor edilen durumlary bilen daşary edilen taryşmalary çykýar. Kaynakly tweets we üýtgetmek şebekleriň üstünde, arama soraglaryny we dillerden daşary çykyşlygyny bejermek üçin tweets toplamak üçin ulandyk.', 'af': "In hierdie papier, voorsien ons Arkov-19, 'n Arabiese Kovid-19 Twitter-datastel wat een jaar spans, wat die periode van 27 Januarie 2020 tot 31 Januarie 2021 oordek. ArCOV-19 is die eerste openbaar-beskikbaar Arabiese Twitter-datastel oordek van COVID-19 pandemiek wat omtrent 2.7M tweets insluit by die propagasie netwerke van die mees-populêre subartikel van hulle (i.e. mees-weet en -liked). Die propagasie-netwerke insluit beide herweet en gesprekslyfsprakes (i.e. drukke van antwoordes). ArCOV- 19 is ontwerp om ondersoek onder verskeie domeine te aktiveer, insluitend natuurlike taal verwerking, informasie ontvang en sosiale rekenaar. Voreinige analisie wys dat ArCOV-19 opstaan opstaande diskusies wat met die eerste raporteerde gevalle van die sykdom geassosieer het soos hulle in die Arabiese wêreld verskyn het. In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.", 'sq': 'Në këtë letër, ne paraqesim ArCOV-19, një set të dhënash arabe COVID-19 në Twitter që zgjat një vit, duke mbuluar periudhën nga 27 janari 2020 deri më 31 janar 2021. ArCOV-19 është grupi i parë i të dhënave arabe në dispozicion publik për Twitter që mbulon pandemikën COVID-19 që përfshin rreth 2.7M tweets së bashku me rrjetet e përhapjes së nëngrupit më popullor të tyre (pra, më të ripërtëriturit dhe më të pëlqyer). Rrjetet e përhapjes përfshijnë si retweetsand fije bisedimesh (pra, fije përgjigjesh). ArCOV-19 është projektuar për të mundësuar kërkimin nën disa fusha duke përfshirë procesimin natyror të gjuhës, marrjen e informacionit dhe llogaritjen sociale. Analiza paraprake tregon se ArCOV-19 përfshin diskutime në rritje të lidhura me rastet e para të raportuara të sëmundjes siç dukeshin në botën arabe. In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.', 'ko': '본문에서 ArcoV-19를 보여줬는데, 2020년 1월 27일부터 2021년 1월 31일까지 아랍 코로나-19 트위터 데이터 세트다.ArcOV-19는 약 270만 개의 트위터와 가장 인기 있는 트위터 서브집합(즉 가장 리트윗되고 사랑받는 트위터)의 전파망을 포함해 코로나 팬데믹(세계적 대유행)을 포괄하는 최초의 아랍어 트위터 데이터 집합이다.전파 네트워크는 전송과 대화 라인(즉 회복 라인)을 포함한다.ArcOV-19는 자연 언어 처리, 정보 검색과 사회 계산 등 여러 분야의 연구를 지원하기 위한 것이다.ArcOV-19는 아랍 세계에서 발생한 첫 보고 사례와 관련한 논의의 증가가 포착된 것으로 잠정 분석됐다.원본 트윗과 전파 네트워크를 제외하고는 유사한 데이터 집합에 대한 정리를 장려하기 위해 검색 조회와 트윗을 수집하는 언어에 독립된 파충류도 발표했다.', 'sw': 'Katika gazeti hili, tunawasilisha ArCOV-19, seti ya taarifa za Twita za Kiarabu COVID-19 ambazo zinazidi kwa mwaka mmoja, kwa kuzingatia kipindi hiki kuanzia tarehe 27 Januari 2020 mpaka 31 Januari 2021. ArCOV-19 ni seti ya kwanza ya taarifa za mtandao wa Twita za Kiarabu zinazopatikana hadharani zinazohusu ugonjwa wa COVID-19 ambazo zinajumuisha twiti za takriban 2.7M pamoja na mitandao ya propaganda ya kundi la watu maarufu zaidi (yaani, twiti zilizotumwa tena na -inapendwa). Mitandao ya propaganda yanajumuisha twita na matangazo ya mazungumzo (yaani matangazo ya majibu). ArCOV-19 imelengwa ili kuwezesha utafiti chini ya maeneo kadhaa ikiwa ni pamoja na upasuaji wa lugha asili, upatikanaji wa habari na kompyuta ya kijamii. Uchambuzi wa awali unaonyesha kwamba ArCOV-19 inaongezeka mijadala yanayohusiana na matukio ya kwanza yaliyoripotiwa na ugonjwa huo yalivyoonekana katika ulimwengu wa Kiarabu. Zaidi ya twiti za vyanzo na mitandao ya propaganda, pia tunaachia maswali ya kutafuta na mlipuko huru wa lugha uliotumika kukusanya twiti hizo ili kuhamasisha kufungiwa kwa seti za taarifa hizo.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք ArCOV-19-ը, արաբական COVID-19 թվիթերի տվյալների համակարգը, որը մեկ տարի է տևում, որը ծախսում է 2020 թվականի հունվարի 27-ից մինչև 2021 թվականի 31-ը: ArCOV-19-ը առաջին հանրային հասանելի արաբական Թվիթերի տվյալների համակարգը է, որը ներառում է COVID-19 համաճարակի, որը ներառում է մոտ 2.7 միլիոն թվիթեր նրանց ամենահայտնի ենթահամակարգի տարածման ցանցերի կողմից (այսինքն ամենահայտնի և ամենասիրալի): Շարունակման ցանցերը ներառում են և վերջնական և խոսակցական թելերը (այսինքն՝ պատասխանների թելերը): ArCOV-19-ը նախագծված է, որպեսզի հնարավորություն տա հետազոտություններ բազմաթիվ ոլորտներում, ներառյալ բնական լեզվի վերաբերյալ, տեղեկատվության վերաբերյալ և սոցիալական հաշվարկներ: Անընդհանուր վերլուծությունը ցույց է տալիս, որ ArCOV-19-ը ներկայացնում է աճող քննարկումները, որոնք կապված են հիվանդության առաջին հայտարարված դեպքերի հետ, ինչպես նրանք հայտնվեցին արաբական աշխարհում: In addition to the source tweets and the propagation networks, we also release the search queries and the language-independent crawler used to collect the tweets to encourage the curation of similar datasets.', 'bn': 'এই কাগজটিতে আমরা আরবী কোভিড-১৯ টুইটারের তথ্য সংগ্রহ করছি, যা এক বছরের শেষ হয়েছে, ২০২০১ সালের ২৭ জানুয়ারির জানুয়ারি ২০১২ থেকে ৩১ জানুয়া ArCOV-19 is the first publicly-available Arabic Twitter dataset covering COVID-19 pandemic that includes about 2.7M tweets alongside the propagation networks of the most-popular subset of them (i.e., most-retweeted and -liked).  প্রচারাভিযান নেটওয়ার্কের মধ্যে পুনরায় টুইট এবং আলোচনাকারী থ্রীড (যেমন উত্তরের ত্রীড)। আর্কোভি-১৯ নির্মাণ করা হয়েছে প্রাকৃতিক ভাষা প্রক্রিয়া, তথ্য পুনরুদ্ধার এবং সামাজিক কমিউটিং সহ বেশ কয়েকটি ডোমে প্রাথমিক বিশ্লেষণ দেখাচ্ছে যে আর্কোভি-১৯ এই রোগের প্রথম রিপোর্টের ঘটনার সাথে আলোচনার সাথে যুক্ত হয়েছে আর্কোভি এই ঘটনা সূত্র টুইট এবং প্রচারাভিযান নেটওয়ার্ক ছাড়াও আমরা অনুসন্ধান অনুসন্ধান এবং ভাষা স্বাধীন ক্রাউয়ারও টুইট সংগ্রহ করার জন্য এই ধরনের ডাটাসেটের আট', 'am': 'በዚህ ካላት አርኮቪ-19፣ አርኮቪ-19፣ አርቢ ኮቪድ-19 የትዊተር ዳታተር አቀረብናል፡፡ አርኮቪ-19 የመጀመሪያው የህዝብ አረብኛ የሆኑት የCOVID-19 ፍርሃት የጦማሪያው የኢትዮጵያ ትዊተር ማድረጊያው ነው፡፡ የፕሮግራም መረብ ሁለተኛውን ትዊተር እና የተማካሪዎችን ድረአምቦች (ምናልባት መልዕክቶች) አርኮቪ-19 በተለይ ቋንቋ ማቀናጃ፣ መረጃ ማድረግ እና ማኅበራዊ ቁጥጥር ውስጥ ካሉት ከሀገሮች በታች ምርምርመራ ማግኘት ነው፡፡ የመጀመሪያው Analysis አርኮቪ-19 የተማረኩት በዓረብ ዓለምም በተገለጡት የመጀመሪያው ወቅት የደዌውን ወቅት የተያያዙትን ውይይት እንዲያሳየው ነው፡፡ ከዋናው ትዊተሮችና የpropaganda መረብ ጥያቄዎች በቀር፣ መረጃዎቹን እናስፈቅዳለን፣ የቋንቋ-ነፃ ተንቀሳቃሾችን እናሳብቃለን፡፡', 'az': 'Bu kańüńĪzda ArCOV-19, bir il uzanan …ôr…ôbc…ô COVID-19 Twitter veril…ônl…ôrini g√∂st…ôrdik, 2020-nin 27 Januardan 31 Januara q…ôd…ôr uzanan m√ľdd…ôti il…ô birlikd…ô. ArCOV-19, onlarńĪn …ôn m…ôŇühur subgruplarńĪn propagasyon Ňü…ôklil…ôrinin yanńĪnda, COVID-19 pandemisini √∂rt…ôn ilk a√ßńĪq-aŇükar …ôr…ôb Twitter veri setidir. Propropagasyon ańülarńĪ h…ôr ikisi d…ô yeni h…ôyat v…ô m√ľhŇü…ôr…ô istifad…ô edir. ArCOV-19 t…ôbi…ôtli dil iŇül…ôm…ôsi, m…ôlumat almasńĪ v…ô sosial hesaplamalar i√ß…ôrisind…ô bir ne√ß…ô domenin altńĪnda araŇütńĪrma qabiliyy…ôti yaratmaq √ľ√ß√ľn tasarlanmńĪŇüdńĪr. ∆Źvv…ôlki analizi g√∂st…ôrir ki, ArCOV-19, Arab d√ľnyasńĪnda g√∂r√ľn…ôn ilk x…ôst…ôlik m…ôs…ôl…ôl…ôri il…ô …ôlaq…ô edil…ôn m…ôs…ôl…ôl…ôrl…ô birlikd…ô y√ľks…ôk m√ľbahis…ôl…ôr √ß…ôkir. Qaynaq tweetl…ôrin v…ô propagasyon ańülarńĪnńĪn istifad…ôsind…ô, arama soruŇümalarńĪnńĪ v…ô dill…ôrin bańüńĪmsńĪz crawlerini bel…ô yayńĪndńĪrńĪrńĪq ki, b…ônz…ôr veri qurńüularńĪnńĪ t…ôŇükil etm…ôk √ľ√ß√ľn tweetl…ôri toplamaq √ľ√ß√ľn istifad…ô etdik.', 'cs': 'V tomto článku představujeme ArCOV-19, arabský datový soubor COVID-19 Twitter, který trvá jeden rok a pokrývá období od 27th ledna 2020 do 31st ledna 2021. ArCOV-19 je první veřejně dostupná arabská datová sada Twitteru pokrývající pandemii COVID-19, která obsahuje asi 2,7M tweety vedle propagačních sítí nejpopulárnější podskupiny z nich (tj. nejvíce retweetovaných a oblíbených). Propagační sítě zahrnují retweety i konverzační vlákna (tj. vlákna odpovědí). ArCOV-19 je navržen tak, aby umožnil výzkum v několika oblastech, včetně zpracování přirozeného jazyka, vyhledávání informací a sociálního výpočtu. Předběžná analýza ukazuje, že ArCOV-19 zachycuje rostoucí diskuse spojené s prvními hlášenými případy onemocnění, jak se objevily v arabském světě. Kromě zdrojových tweetů a propagačních sítí uvolňujeme také vyhledávací dotazy a jazykově nezávislý crawler, který se používá ke sběru tweetů, abychom podpořili tvorbu podobných datových sad.', 'ca': "En aquest article presentem l'ArCOV-19, un conjunt de dades àrab COVID-19 de Twitter que dura un any, que cobreix el període del 27 de janar de 2020 al 31 de janar de 2021. ArCOV-19 és el primer conjunt de dades de Twitter àrab disponible al públic que cobre la pandèmia COVID-19 que inclou uns 2,7 milions de tweets juntament amb les xarxes de propagació del subconjunt més popular d'ells (és a dir, el més repetit i preferit). The propagation networks include both retweetsand conversational threads (i.e., threads of replies).  L'ArCOV-19 està dissenyat per permetre la recerca en diversos domínios, incloent el processament natural de llenguatges, la recuperació d'informació i la computació social. L'anàlisi preliminar mostra que l'ArCOV-19 captura debats creixents associats als primers casos notificats de la malaltia com van aparèixer al món àrab. A més dels tweets de fonts i les xarxes de propagació, també alliberam les preguntes de cerca i el buscador independent del llenguatge que utilitzava per recollir els tweets per animar la curació de conjunts de dades similars.", 'bs': 'U ovom papiru predstavljamo ArCOV-19, arapski komplet podataka COVID-19 Twitter-a koji traje godinu dana, pokrivajući period od 27. januara 2020. do 31. januara 2021. ArCOV-19 je prvi javno dostupni arapski Twitter podatak koji pokriva pandemiju COVID-19, uključujući oko 2,7M tweets zajedno sa propagacijskim mrežama najpopularnijih podataka njih (tj. najviše povratnih i -voljenih). Mreža propagacije uključuje i retweet i razgovorne trgovine (tj. trgovine odgovora). ArCOV-19 je dizajniran kako bi omogućio istraživanje pod nekoliko domena uključujući prirodnu obradu jezika, prikupljanje informacija i socijalno računalo. Preliminarna analiza pokazuje da ArCOV-19 uhvati rastuće diskusije povezane sa prvim prijavljenim slučajevima bolesti kao što su se pojavili u arapskom svijetu. Pored izvornih tweeta i propagacijskih mreža, također objavljujemo pretraživanje ispitivanja i jezički nezavisni krawler koji se koristi za skupljanje tweeta kako bi poticali uklanjanje sličnih dataseta.', 'et': 'Käesolevas töös tutvustame ArCOV-19, Araabia COVID-19 Twitteri andmekogumit, mis kestab ühe aasta ja hõlmab ajavahemikku 27. jaanuarist 2020 kuni 31. jaanuarini 2021. ArCOV-19 on esimene avalikult kättesaadav Araabia Twitteri andmekogum, mis hõlmab COVID-19 pandeemiat, mis sisaldab umbes 2,7 miljonit säutsu koos nende populaarseima alamhulga (st kõige retweeteeritud ja -meeldinud) levivõrkudega. Levitusvõrgud hõlmavad nii retweeteid kui vestluslõimeid (st vastuste lõimeid). ArCOV-19 eesmärk on võimaldada teadusuuringuid mitmes valdkonnas, sealhulgas looduskeele töötlemine, teabe hankimine ja sotsiaalne arvuti. Esialgne analüüs näitab, et ArCOV-19 kajastab kasvavaid arutelusid seoses esimeste teatatud haigusjuhtudega Araabia maailmas. Lisaks lähtesäutsudele ja levitusvõrkudele avaldame ka otsingupäringud ja keelesõltumatu indeksi, mida kasutatakse säutsude kogumiseks, et soodustada sarnaste andmekogumite kureerimist.', 'fi': 'Tässä artikkelissa esittelemme ArCOV-19, arabialaisen COVID-19 Twitter-aineiston, joka kattaa ajanjakson 27.1.2020 ja 31.1.2021. ArCOV-19 on ensimmäinen julkisesti saatavilla oleva arabialainen Twitter-tietokokonaisuus, joka kattaa COVID-19-pandemian, joka sisältää noin 2,7 miljoonaa twiittiä niiden suosituimman osajoukon (eli eniten uudelleentwiittatun ja -tykätyn) leviämisverkostojen rinnalla. Levitysverkostoihin kuuluu sekä uudelleentwiittaus- että keskusteluketjuja (eli vastausketjuja). ArCOV-19 on suunniteltu mahdollistamaan tutkimus useilla aloilla, kuten luonnollisen kielen käsittely, tiedonhaku ja sosiaalinen tietojenkäsittely. Alustava analyysi osoittaa, että ArCOV-19 vangitsee kasvavat keskustelut, jotka liittyvät ensimmäisiin ilmoitettuihin tautitapauksiin, kuten ne ilmenivät arabimaailmassa. Julkaisemme lähdetwiittien ja levitysverkkojen lisäksi myös hakukyselyt ja kieliriippumaton indeksaattori, jota käytetään twiittien keräämiseen kannustamaan samankaltaisten aineistojen kuratointia.', 'ha': "Ga wannan takardan, Munã halatar da ArCOV-19, ma'abũcin COKID-19 na Twitter set which spana shekara guda, yana rufe lokacin tare 27 January 2020 zuwa 31 January 2021. ArCOV-19 is the farkon data set of Public-iya-iya-labari na Larabci, yana rufe COV-19 ɗin agogon wanda ke ƙunsa da taki 2.7M-Twitter alongside zangaren sanarwa na ƙarƙashin da suke mafi popular (misali, re-retired da-liked). Ana haɗi cikin shirin bayani na haɗi dukansu da sauran da aka yi sauki-biyu (misali, tsumarni da ake mayarwa). An design ArCOV-19 ne dõmin a iya karatar da research a cikin wasu cikin wurãre guda, kamar shirin jarraba lugha masu natsuwa, da motsari masu tsari ga information, da lissafi na jami. Ana ƙarami na farko na nũna cẽwa ArCOV-19 ɗin za'a kore mazaɓa masu husũma da na farkon jarrabun jiran da suka nuna a cikin dunar arabu. Gansa da wato ta'ura da mitandanin bayani, za'a saka tambayi masu basu'a da harshen-huru wanda aka yi amfani da su sami Twitter dõmin su ƙara tsarin da ake daidaita.", 'sk': 'V prispevku predstavljamo ArCOV-19, arabski nabor podatkov COVID-19 Twitter, ki traja eno leto in zajema obdobje od 27. januarja 2020 do 31. januarja 2021. ArCOV-19 je prvi javno dostopen arabski nabor podatkov Twitterja, ki pokriva pandemijo COVID-19, ki vključuje približno 2,7 milijona tweetov poleg omrežij za širjenje najbolj priljubljene podskupine (tj. najbolj retweetirane in -všeč). Razširjalna omrežja vključujejo retweete in pogovorne niti (tj. niti odgovorov). ArCOV-19 je zasnovan tako, da omogoča raziskave na več področjih, vključno z obdelavo naravnega jezika, pridobivanjem informacij in socialnim računalništvom. Predhodna analiza kaže, da ArCOV-19 zajema naraščajoče razprave, povezane s prvimi poročanimi primeri bolezni, kot so se pojavili v arabskem svetu. Poleg izvornih tweetov in širjenih omrežij objavljamo tudi iskalne poizvedbe in jezikovno neodvisni brskalnik, ki se uporablja za zbiranje tweetov za spodbujanje urejanja podobnih naborov podatkov.', 'bo': 'འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ArCOV-19, ཨ་རིའི་ཌིས་ཌིའི་གནད་སྡུད་ཅིག་ངོ་ལ་གཅིག་སུ་འབྱུང་ཡོད། ArCOV-19 ནི་སྤྱི་ཚོགས་ཆེན་མཁན་གྱི་ཌིས་ཌིར་གྱི་གནད་སྡུད་ཆ་དང་པོ་དེ་རེད། བྱ་སྤྱོད་དྲ་རྒྱ་ནང་དུ་ཚོགས་པ་དང་སླེབས་ཚུལ་གྱི་འོད་རིམ་གཉིས་ཀྱི་ནང་དུ་ཡོད། ArCOV-19 is designed to enable research under several domains including natural language processing, information retrieval, and social computing. འཛམ་གླིང་གི་ནང་དུ་ཡོད་པའི་སྔོན་འགྱུར་བའི་དབྱེ་ཞིབ་དཔྱད་ནས་ ཐོག་མའི་Tweets དང་བྱ་སྤྱོད་དྲ་ཐོག་ཏུ་ཞིབ་བཤེར་གྱི་དྲི་ཚིག་དང་སྐད་ཡིག', 'he': 'בעיתון הזה, אנו מציגים את ארקוב-19, קבוצת נתונים ערבית קוויד-19 טוויטר שמארכה שנה אחת, מכסה את התקופה מ-27 בינואר 2020 עד 31 בינואר 2021. ArCOV-19 הוא המערכת הנתונים הערבית הראשונה שזמינה לציבור הציבור על פנדמיה COVID-19 שכוללת כ-2.7 מיליון טוויטים לצד רשתות התרבות של התרבות הכי פופולרית שלהם (כלומר, הכי פופולרית והאהובה). רשתות ההרבות כוללות גם חוטים ושיחות (כלומר חוטים של תשובות). ArCOV-19 מעוצב כדי לאפשר מחקר תחת מספר תחומות כולל עיבוד שפה טבעי, גילוי מידע, וחשב חברתי. ניתוח קודמי מראה שארקוב-19 תופס דיון עלה שקשור למקרים הראשונים מדווחים על המחלה כפי שהם הופיעו בעולם הערבי. בנוסף לטוויטים המקוריים ולרשתות ההתפשטות, אנחנו גם משחררים את השאלות החיפושים והזחל עצמאי לשפה שהשתמש לאסוף את הטוויטים כדי לעודד את הטיפול של קבוצות נתונים דומות.', 'jv': 'Nan pepulan iki, kita mulai arCoV-19, dataset arab (corid-19) iki dadi iki banget mruput, sampek tanggal sing katêpakan mruput, kawula tanggal tanggal sing katêpakan tanggal-tanggal 2020 sampek 31 Janir 2020 ARCOMV-19 iku sabên populêr sing perusahaan-perusahaan dhéwé Google-19 sing isinêt karo coriêm-19 sing katêngé katêpakan karo 2.7 Jejaring The default language Ndeleksyon tualke mungkasi as éwé éntuk digasaé arCoV-19 kang digasaé surat sing perusahaan karo perusahaan sing paling dhéwé kuwi sakjane tualke wong dhéwé kuwi dunyo arap. Nambah kang tuwit perbudhakan lan tambah sing wis dipunanggé, awak dhéwé iso ngubah perusahaan winih lan nganggo dolanan sing wis dipunanggé kanggo nggambar tuwit kanggo nggawe gerakan sampeyan dataset sing menyang.'}
{'en': 'ALUE : Arabic Language Understanding Evaluation', 'ar': 'ALUE: تقييم فهم اللغة العربية', 'es': 'ALUE: Evaluación de la comprensión del idioma árabe', 'fr': 'ALUE\xa0: Évaluation de la compréhension de la langue arabe', 'pt': 'ALUE: Avaliação de Compreensão da Língua Árabe', 'ja': 'ALUE:アラビア語理解評価', 'hi': 'ALUE: अरबी भाषा समझ मूल्यांकन', 'zh': 'ALUE:阿拉伯语解估', 'ru': 'ALUE: Оценка понимания арабского языка', 'ga': 'ALUE: Meastóireacht Tuiscint Teanga Araibis', 'ka': 'ALUE: აპაბური ენის განსხვავება', 'el': 'ΑΛΟΥΑ: Αξιολόγηση κατανόησης της αραβικής γλώσσας', 'hu': 'ALUE: Arab Language Understanding Evaluation', 'kk': 'ALUE: Араб тілінің түсінімін оқу', 'it': 'ALUE: Valutazione della comprensione della lingua araba', 'mk': 'ALUE: Arabic Language Understanding Evaluation', 'ms': 'ALUE: Pemahaman Bahasa Arab', 'ml': 'ALUE: അറബി ഭാഷ ബോധപൂര്\u200dത്തീകരണം', 'mt': 'ALUE: Evalwazzjoni tal-Ftehim tal-Lingwa Għarbija', 'lt': 'ALUE: Arabic Language Understanding Evaluation', 'no': 'ALUE: Evaluering av arabisk språk for forståking', 'ro': 'ALUE: Evaluarea înțelegerii limbii arabe', 'mn': 'ALUE: Араб хэл ойлголтын үнэлгээ', 'pl': 'ALUE: Ocena rozumienia języka arabskiego', 'so': 'ALUE: Qiimeynta waxgarashada afka Carabiga', 'si': 'ALUE: අරාබි භාෂාව තේරුම් ගන්න අවශ්\u200dයය', 'sr': 'Evaluacija razumevanja Arapskog jezika', 'sv': 'ALUE: Utvärdering av förståelse för arabiska språk', 'ta': 'ALUE: அரேபிய மொழி புரிந்து கொள்ளும் மதிப்பு', 'ur': 'ALUE: عربی زبان سمجھنے کی ارزش', 'uz': 'ALUE: Арабча тилни кўриб чиқиш', 'vi': 'ALUE: Đánh giá ngôn ngữ', 'bg': 'ALUE: Оценка за разбиране на арабския език', 'nl': 'ALUE: Evaluatie van het begrip Arabische taal', 'da': 'ALUE: Evaluering af arabisk sprogforståelse', 'hr': 'ALUE: procjena razumijevanja arapskog jezika', 'de': 'ALUE: Bewertung des Verständnisses der arabischen Sprache', 'fa': 'ALUE: ارزیابی درک زبان عربی', 'ko': '가치: 아랍어 이해 평가', 'sw': 'ALUE: Uthibitisho wa lugha ya Kiarabu', 'tr': 'ALUE: Arapça dili düşünýän Taýýarlama', 'af': 'ALUE: Arabiese taal Verstaan Evaluering', 'sq': 'ALUE: Përkuptimi i gjuhës arabe', 'am': 'ALUE: የዐረብኛ ቋንቋ ማስታወቂያው', 'hy': 'ALUE: Արաբական լեզուն հասկանալու գնահատումը', 'az': 'ALUE: Arap√ßa dili anlama deƒüerlendirm…ôsi', 'bn': 'ALUE: আরবী ভাষা বুঝতে পারে মূল্যায়ন', 'id': 'ALUE: Bahasa Arab Memahami Evaluasi', 'et': 'ALUE: Araabia keele mõistmise hindamine', 'bs': 'Očekivanje razumijevanja Arapskog jezika', 'cs': 'ALUE: Hodnocení porozumění arabskému jazyku', 'fi': 'ALUE: Arabian kielen ymmärtäminen arviointi', 'ca': 'ALUE: Evaluació de la comprensió del llenguatge àrab', 'jv': 'AlUE: Ngucap Jabun Habangkat Tulung Kemerdekaan', 'he': 'ALUE: Arabic Language Understanding Evaluation', 'ha': 'KCharselect unicode block name', 'bo': 'ALUE: ཨ་རབ་ཀྱི་སྐད་ཡིག་རྟོགས་ཀྱི་དབྱེ་ཞིབ་བཟོ་བྱེད།', 'sk': 'ALUE: Evaluacija razumevanja arabskega jezika'}
{'en': 'The emergence of Multi-task learning (MTL)models in recent years has helped push thestate of the art in Natural Language Un-derstanding (NLU). We strongly believe thatmany NLU problems in Arabic are especiallypoised to reap the benefits of such models. Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks. For five of these, we providenew privately held evaluation datasets to en-sure the fairness and validity of our benchmark. We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels. Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks. But in order to en-tice participation from the wider community, we stick to publishing singly trained baselinesonly. Nonetheless, our analysis reveals thatthere is plenty of room for improvement inArabic NLU. We hope that ALUE will playa part in helping our community realize someof these improvements. Interested researchersare invited to submit their results to our online, and publicly accessible leaderboard.', 'ar': 'ساعد ظهور نماذج التعلم متعدد المهام (MTL) في السنوات الأخيرة في دفع حالة الفن في إلغاء فهم اللغة الطبيعية (NLU). نعتقد اعتقادًا راسخًا أن العديد من مشكلات NLU باللغة العربية مهيأة بشكل خاص لجني فوائد هذه النماذج. في نهاية توثي ، نقترح معيار تقييم عدم فهم اللغة العربية (ALUE) ، استنادًا إلى 8 مهام تم اختيارها بعناية ونشرها مسبقًا. بالنسبة لخمسة من هؤلاء ، قدمنا مجموعات بيانات تقييم خاصة جديدة للتأكد من عدالة وصلاحية معيارنا ، كما نقدم مجموعة بيانات تشخيصية للباحثين المساعدين للتحقيق في الأعمال الداخلية لنماذجهم ، وتُظهر تجاربنا الأولية أن نماذج MTL تفوق أداؤها على نظائرها المدربة بشكل فردي في معظمها. مهام. ولكن من أجل تعزيز المشاركة من المجتمع الأوسع ، فإننا نتمسك بنشر خطوط الأساس المدربة بشكل فردي فقط. ومع ذلك ، يكشف تحليلنا أن هناك متسعًا كبيرًا للتحسين في NLU العربي. نأمل أن تلعب ALUE دورًا في مساعدة مجتمعنا على تحقيق بعض هذه التحسينات. تمت دعوة الباحثين المهتمين لإرسال نتائجهم إلى لوحة المتصدرين الخاصة بنا عبر الإنترنت والمتاحة للجمهور.', 'es': 'La aparición de modelos de aprendizaje multitarea (MTL) en los últimos años ha ayudado a impulsar el estado del arte en la comprensión del lenguaje natural (NLU). Creemos firmemente que muchos problemas de NLU en árabe están especialmente preparados para cosechar los beneficios de tales modelos. Con este fin, proponemos el Arabic Language Understanding Evaluation Benchmark (ALUE), basado en 8 tareas cuidadosamente seleccionadas y publicadas previamente. Para cinco de ellos, proporcionamos nuevos conjuntos de datos de evaluación privados para garantizar la imparcialidad y validez de nuestro punto de referencia. También proporcionamos un conjunto de datos de diagnóstico para ayudar a los investigadores a analizar el funcionamiento interno de sus modelos. Nuestros experimentos iniciales muestran que los modelos MTL superan a sus homólogos entrenados individualmente en la mayoría de tareas. Pero para atraer la participación de la comunidad en general, nos limitamos a publicar únicamente líneas de base capacitadas individualmente. Sin embargo, nuestro análisis revela que hay mucho margen de mejora en la NLU árabe. Esperamos que ALUE contribuya a ayudar a nuestra comunidad a realizar algunas de estas mejoras. Se invita a los investigadores interesados a enviar sus resultados a nuestra tabla de clasificación en línea y de acceso público.', 'fr': "L'émergence des modèles d'apprentissage multitâche (MTL) ces dernières années a contribué à faire progresser l'état de l'art en matière de compréhension du langage naturel (NLU). Nous sommes fermement convaincus que de nombreux problèmes de NLU en arabe sont particulièrement bien placés pour profiter des avantages de tels modèles. À cette fin, nous proposons le référentiel d'évaluation de la compréhension de la langue arabe (ALUE), basé sur 8 tâches soigneusement sélectionnées et publiées précédemment. Pour cinq d'entre eux, nous fournissons de nouveaux ensembles de données d'évaluation privés afin de garantir l'équité et la validité de notre benchmark. Nous fournissons également un ensemble de données de diagnostic pour aider les chercheurs à sonder le fonctionnement interne de leurs modèles.Nos premières expériences montrent que les modèles MTL surpassent leurs homologues formés individuellement sur la plupart tâches. Mais afin de susciter la participation de la communauté au sens large, nous nous en tenons à publier uniquement des références formées individuellement. Néanmoins, notre analyse révèle qu'il existe de nombreuses possibilités d'amélioration en arabe NLU. Nous espérons qu'ALUE contribuera à aider notre communauté à réaliser certaines de ces améliorations. Les chercheurs intéressés sont invités à soumettre leurs résultats à notre classement en ligne et accessible au public.", 'pt': 'O surgimento de modelos de aprendizagem multitarefa (MTL) nos últimos anos ajudou a impulsionar o estado da arte em compreensão de linguagem natural (NLU). Acreditamos firmemente que muitos problemas de NLU em árabe estão especialmente preparados para colher os benefícios de tais modelos. Para isso propomos o Benchmark de Avaliação de Entendimento da Língua Árabe (ALUE), baseado em 8 tarefas cuidadosamente selecionadas e previamente publicadas. Para cinco deles, fornecemos novos conjuntos de dados de avaliação de propriedade privada para garantir a justiça e a validade de nosso benchmark. Também fornecemos um conjunto de dados de diagnóstico para ajudar os pesquisadores a sondar o funcionamento interno de seus modelos. Nossos experimentos iniciais mostram que os modelos MTL superam seus homólogos treinados individualmente na maioria tarefas. Mas, para atrair a participação da comunidade mais ampla, nos limitamos a publicar apenas linhas de base treinadas individualmente. No entanto, nossa análise revela que há muito espaço para melhorias no NLU árabe. Esperamos que o ALUE ajude nossa comunidade a realizar algumas dessas melhorias. Os pesquisadores interessados são convidados a enviar seus resultados para nossa tabela de classificação online e acessível ao público.', 'zh': '近年以来,多任务学(MTL)形有助于推动自然语言非立(NLU)之艺也。 吾固信之,阿拉伯语之多NLU,尤其益也。 最后,我们据8个精选和先前的事务发出了阿拉伯语非立评准(ALUE)。 其五,供新私评数集,以保公平性有效性。 给一诊数集,以助研究。 吾初实验明,在大众之中,MTL模形之性优于独练之计数器。 然博社区之与,固以一培训为本也。 虽然,吾之分析表明,Arabic NLU中犹有大改其间者。 愿ALUE助我者社区遂其改进也。 有兴者邀以在线访之排行榜。', 'ja': '近年のマルチタスク学習（ MTL ）モデルの出現は、自然言語理解（ NLU ）における芸術の状態を推進するのに役立っている。 私たちは、アラビア語のNLU問題は、そのようなモデルの利点を得るために特に強調されていると強く信じています。 この最後に、8つの慎重に選択され、以前に発表されたタスクに基づいて、アラビア語未理解評価ベンチマーク（ ALUE ）を提案します。 これらのうち5つについて、私たちはベンチマークの公平性と妥当性を保証するために、プライベートに保持されている評価データセットを更新しました。また、研究者が彼らのモデルの内部動作を調査するのに役立つ診断データセットも提供しています。最初の実験では、ほとんどのタスクでMTLモデルが単一のトレーニングを受けたカウンターパートを上回っていることが示されています。 しかし、より広範なコミュニティからの参加を促進するために、私たちは単一のトレーニングを受けたベースラインのみを公開することに固執します。 それにもかかわらず、私たちの分析は、アラビア語NLUに改善の余地があることを明らかにしました。 私たちのコミュニティがこれらの改善の一部を実現するのに役立つことを願っています。 興味のある研究者は、当社のオンラインおよび一般にアクセス可能なリーダーボードに結果を提出するよう招待されています。', 'ru': 'Появление моделей многозадачного обучения (MTL) в последние годы помогло подтолкнуть состояние искусства к непониманию естественного языка (NLU). Мы твердо верим, что многие проблемы НЛУ на арабском языке особенновыражены, чтобы пожинать плоды такихмоделей. На этом мы предлагаем Непонятный контрольный параметр оценки арабского языка (ALUE),основанный на 8 тщательно отобранных и ранее опубликованных задачах. Мы также предоставляем диагностический набор данных, чтобы помочь исследователям исследовать внутреннюю работу своих моделей. Наши первоначальные эксперименты показывают, что моделиMTL превосходят их единолично обученных коллег по большинству задач. Но для того, чтобы привлечь к участию широкую общественность,мы придерживаемся публикацииодиночно обученных исходных данных. Тем не менее, наш анализ показывает, что в арабском НЛУ есть много возможностей для улучшения. Мы надеемся, ЧТО Alue сыграет свою роль впомощи нашему сообществу реализовать некоторые из этих улучшений. Заинтересованным исследователям предлагается представить свои результаты в нашу онлайн и общедоступную таблицу лидеров.', 'hi': 'हाल के वर्षों में मल्टी-टास्क लर्निंग (एमटीएल) मॉडल के उद्भव ने प्राकृतिक भाषा अन-डरस्टैंडिंग (एनएलयू) में कला की स्थिति को आगे बढ़ाने में मदद की है। हम दृढ़ता से मानते हैं कि अरबी में कई एनएलयू समस्याओं को विशेष रूप से इस तरह के मॉडल के लाभों को प्राप्त करने के लिए प्रस्तुत किया जाता है। इस अंत में हम अरबी भाषा अन-derstanding मूल्यांकन बेंचमार्क (ALUE) का प्रस्ताव करते हैं, जो 8 सावधानीपूर्वक चयनित और पहले से प्रकाशित कार्यों पर आधारित है। इनमें से पांच के लिए, हम अपने बेंचमार्क की निष्पक्षता और वैधता को सुनिश्चित करने के लिए नए निजी तौर पर आयोजित मूल्यांकन डेटासेट प्रदान करते हैं। हम शोधकर्ताओं को उनके मॉडल के आंतरिक कामकाज की जांच करने में मदद करने के लिए एक नैदानिक डेटासेट भी प्रदान करते हैं। हमारे शुरुआती प्रयोगों से पता चलता है कि एमटीएल मॉडल अधिकांश कार्यों पर अपने एकल प्रशिक्षित काउंटरपार्ट्स को पछाड़ते हैं। लेकिन व्यापक समुदाय से भागीदारी को एन-टीस करने के लिए, हम अकेले प्रशिक्षित बेसलाइन को प्रकाशित करने के लिए चिपके रहते हैं। फिर भी, हमारे विश्लेषण से पता चलता है कि अरबी एनएलयू में सुधार के लिए बहुत सारे कमरे हैं। हमें उम्मीद है कि ALUE हमारे समुदाय को इन सुधारों में से कुछ का एहसास करने में मदद करने में एक भूमिका निभाएगा। इच्छुक शोधकर्ताओं को हमारे ऑनलाइन और सार्वजनिक रूप से सुलभ लीडरबोर्ड पर अपने परिणाम प्रस्तुत करने के लिए आमंत्रित किया जाता है।', 'ga': 'Chabhraigh teacht chun cinn na múnlaí foghlama Ilthasc (MTL) le blianta beaga anuas chun staid na healaíne i dTuiscint Teanga Nádúrtha (NLU) a bhrú chun cinn. Creidimid go láidir go bhfuil go leor fadhbanna de chuid NLU san Araibis go háirithe chun leas a bhaint as samhlacha den sórt sin. Chuige seo molaimid Tagarmharc Measúnaithe Tuiscint na Teanga Araibise (ALUE), bunaithe ar 8 dtasc a roghnaíodh go cúramach agus a foilsíodh roimhe seo. I gcás cúig cinn díobh seo, soláthraímid tacair sonraí measúnaithe nua atá á gcoinneáil go príobháideach chun cothroime agus bailíocht ár tagarmhairc a chinntiú. Cuirimid tacar sonraí diagnóiseacha ar fáil freisin chun cabhrú le taighdeoirí oibriú inmheánach a gcuid samhlacha a iniúchadh. tascanna. Ach chun rannpháirtíocht an phobail i gcoitinne a mhealladh, cloímid le foilsiú bonnlíne aonair oilte go díreach. Mar sin féin, léiríonn ár n-anailís go bhfuil go leor spáis le feabhsú in NLU Arabach. Tá súil againn go nglacfaidh ALUE páirt i gcuidiú lenár bpobal roinnt de na feabhsuithe seo a bhaint amach. Tugtar cuireadh do thaighdeoirí ar spéis leo a gcuid torthaí a chur isteach chuig ár gclár ceannairí ar líne agus a bhfuil rochtain phoiblí orthu.', 'el': "Η εμφάνιση μοντέλων εκμάθησης πολλαπλών εργασιών (ΜΤL) τα τελευταία χρόνια συνέβαλε στην προώθηση της κατάστασης της τέχνης στην κατανόηση της φυσικής γλώσσας (NLU). Πιστεύουμε ακράδαντα ότι πολλά προβλήματα NLU στα αραβικά είναι ιδιαίτερα σκόπιμο να αποκομίσουν τα οφέλη αυτών των μοντέλων. Για το σκοπό αυτό προτείνουμε τον Benchmark Αξιολόγησης της Αραβικής Γλώσσας (ALUE), βασισμένο σε οκτώ προσεκτικά επιλεγμένες και προηγουμένως δημοσιευμένες εργασίες. Για πέντε από αυτά, παρέχουμε νέα ιδιωτικά σύνολα δεδομένων αξιολόγησης για να διασφαλίσουμε την ορθότητα και την εγκυρότητα του δείκτη αναφοράς μας. Παρέχουμε επίσης ένα διαγνωστικό σύνολο δεδομένων για να βοηθήσουμε τους ερευνητές να διερευνήσουν την εσωτερική λειτουργία των μοντέλων τους. Τα αρχικά πειράματά μας δείχνουν ότι τα μοντέλα MTL ξεπερνούν τα μόνα εκπαιδευμένα μέρη τους στις περισσότερες εργασίες. Αλλά για να εξασφαλιστεί η συμμετοχή της ευρύτερης κοινότητας, εμμένουμε στην έκδοση μεμονωμένα εκπαιδευμένων βάσεων. Παρ 'όλα αυτά, η ανάλυσή μας αποκαλύπτει ότι υπάρχει άφθονο περιθώριο βελτίωσης στην αραβική NLU. Ελπίζουμε ότι η ΑΛΟΥΗ θα διαδραματίσει ένα ρόλο στη βοήθεια της κοινότητάς μας να πραγματοποιήσει ορισμένες από αυτές τις βελτιώσεις. Οι ενδιαφερόμενοι ερευνητές καλούνται να υποβάλουν τα αποτελέσματά τους στον διαδικτυακό και δημόσιο πίνακα κατάταξής μας.", 'hu': 'Az elmúlt években a Multi-Task Learning (MTL) modellek megjelenése segített előmozdítani a Natural Language Unstanding (NLU) művészeti állapotát. Határozottan hiszünk abban, hogy sok NLU-probléma arabul különösen az ilyen modellek előnyeit élvezi. Ennek érdekében 8 gondosan kiválasztott és korábban publikált feladat alapján javasoljuk az Arab Language Ununderstanding Evaluation Benchmarkot (ALUE). Ezek közül öt esetében új, magántulajdonban lévő értékelési adatkészletet biztosítunk, hogy biztosítsuk referenciaértékünk méltányosságát és érvényességét. Diagnosztikai adatkészletet is biztosítunk, hogy segítsük a kutatókat modelleik belső működésének vizsgálatában. Kezdeti kísérleteink azt mutatják, hogy az MTL modellek a legtöbb feladatnál jobban teljesítik az egyedül képzett országi alkatrészeiket. A szélesebb közösség részvételének biztosítása érdekében azonban kizárólag az egyénileg képzett alapok kiadásához ragaszkodunk. Mindazonáltal elemzésünk azt mutatja, hogy az arab NLU-ban rengeteg hely van javításra. Reméljük, hogy az ALUE részt vesz abban, hogy segítsen közösségünknek megvalósítani ezeket a fejlesztéseket. Az érdeklődő kutatókat felkérjük, hogy küldjék el eredményeiket online és nyilvánosan hozzáférhető ranglistánkra.', 'ka': 'ბოლო წლის შემდეგ მრავალური დასწავლების (MTL) მოდელების შესახებ მოხმარება თავისუფალური ენის განსხვავება (NLU). ჩვენ ძალიან ვფიქრობთ, რომ არაბულში NLU პრობლემები განსაკუთრებულია, რომელიც ასეთი მოდელების გამოიყენება. საუკეთესო დასრულებაში ჩვენ აპაბიური ენათის არსებულ განსაზღვრებულ ბენქმარი (ALUE), რომელიც 8 მხოლოდ მონიშნული და პირველი განსაზღვრებულ რამეების ბაზაზე. ჱა ოვრ ჲრ რვჱთ, ოპვეჟრაგთჳმვ ოპთგთრნთ ეანარა ჱა ჲუვნწგანვ, ჱა ეა ჟთდსპვმ ფვჟრთნჟრგჲრჲ თ ოპაგთლნჲჟრრა ნა ნაქთწ ბვნფმაპკ. ჩვენ ასევე დიაგონტიკური მონაცემების სექტი, რომელიც მსწავლობისთვის შესაძლებლობად გავაკეთებთ საშუალო მუშაობის შესაძლებლობა. ჩვენი პირველი ექსპერიმენტები გამოჩვენება, რომ MTL მოდელები უფრო მეტად გავაკეთებენ მათი ერთადერთი განაკეთებული კონტაქტები უფრო მეტად დავაკ მაგრამ უფრო დიდი საზოგადოებლიდან დანაწილად, ჩვენ ერთადერთად განსწავლებული ფესტლინონის გარეშე დავხმარებთ. მაგრამ, ჩვენი ანალიზია აღმოჩნდა, რომ აქ უფრო დიდი ადგილი არაბური NLU-ში გაუკეთესება. ნაეწგამვ ჟვ, ფვ ALUE ღვ თდპავ ნაფალჲ გ ოჲმჲღ ნა ნაქარა ჲბღარა ეა პაჱბვპვ ნვღჲ ჲრ რვჱთ ოჲ-ეჲბპვნთ. თნრვპვჟთპანთ პაჱსფთრვლთ ჟა ოჲკანვნთ ეა ოპვეაეარ ნვდჲგთრვ პვჱსლრართ ნა ნაქარა თნრვპნვრა თ ოსბლთკალნჲ ეჲჟრთდნარა ლთევპბჲპეა.', 'it': "L'emergere di modelli di apprendimento multi-task (MTL) negli ultimi anni ha contribuito a spingere lo stato dell'arte nell'Understanding del linguaggio naturale (NLU). Crediamo fermamente che molti problemi dell'NLU in arabo siano particolarmente destinati a cogliere i benefici di tali modelli. A tal fine proponiamo il benchmark di valutazione indipendente della lingua araba (ALUE), basato su 8 compiti attentamente selezionati e precedentemente pubblicati. Per cinque di questi, forniamo nuovi set di dati di valutazione privati per garantire l'equità e la validità del nostro benchmark. Forniamo anche un set di dati diagnostici per aiutare i ricercatori a sondare il funzionamento interno dei loro modelli. I nostri esperimenti iniziali mostrano che i modelli MTL superano le loro parti di paesi individualmente addestrate nella maggior parte dei compiti. Ma al fine di facilitare la partecipazione della comunità più ampia, ci limitiamo a pubblicare solo linee di base individualmente formate. Tuttavia, la nostra analisi rivela che c'è molto spazio per migliorare nelNLU arabo. Speriamo che ALUE possa contribuire ad aiutare la nostra comunità a realizzare alcuni di questi miglioramenti. I ricercatori interessati sono invitati a presentare i loro risultati alla nostra classifica online e pubblicamente accessibile.", 'kk': 'Көп тапсырмаларды оқыту үлгілері (MTL) соңғы жылдар бойынша тапсырмалардың көмегімен тапсырмаларды бақылады. Біз Араб тіліндегі NLU мәселелері осы үлгілердің пайдалануларын жасау үшін әдеттегі мәселелеріне сенеміз. Біз араб тілінің аяқталмаған бағалау белгісін (ALUE), 8 таңдалған және алдын- ала жарияланған тапсырмалардың негізінде тұрады. Бұлардың бес тәртібі жеке мәліметтің дұрыстығын және дұрыстығын тексеру үшін жеке мәліметтің деректер жиынын көрсеттік. Мұндай-ақ біз диагностикалық деректер жинағын зерттеушілерінің ішкі жұмысын зерттеу үшін береміз. Біздің бастапқы тәжірибеміз MTL үлгілерін көпшілікті тапсырмалардың көпшілігіне көмектесетінін көрсетеді. Бірақ көпшілікті қоғамдастыру үшін бір-бірінші бағдарламаның бағдарламасын басып шығаруға қатынаймыз. Біздің анализиямыз бұл жерде Араб НЛU-де жақсарту үшін көп орын бар екенін көрсетеді. Біз ALUE біздің көмектесуімізге көмектесетін деп үміттенеміз. Интернеттегі зерттеушілеріміздің нәтижелерін онлайн жерімізге және көпшілікті жеткізетін басып шығару үшін шақырылады.', 'lt': 'Daugiaužduočių mokymosi (MTL) modelių atsiradimas pastaraisiais metais padėjo paskatinti pažangą gamtinės kalbos nesuvokimo (NLU) srityje. Mes tvirtai tikime, kad daugelis NLU problemų arabų kalba yra ypač pasirengusios pasinaudoti tokių modelių teikiama nauda. Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks.  Penkioms iš jų pateikėme privačių vertinimo duomenų rinkinius, kad užtikrintume mūsų lyginamojo rodiklio teisingumą ir pagrįstumą. Taip pat teikiame diagnostinių duomenų rinkinį, kuris padėtų mokslininkams ištirti jų modelių vidaus veikimą. Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks.  Tačiau norint paskatinti platesnės bendruomenės dalyvavimą, mes išlaikome atskirai parengtus bazinius leidinius. Vis dėlto mūsų analizė atskleidžia, kad arabų nacionalinėje nacionalinėje sąjungoje yra daug vietos tobulinimui. Tikimės, kad ALUE padės mūsų bendruomenei įgyvendinti kai kuriuos šiuos patobulinimus. Suinteresuotieji mokslininkai kviečiami pateikti savo rezultatus internete ir viešai prieinamai vadovaujančiai lentelei.', 'mk': 'Почнувањето на моделите за учење со повеќето задачи (МТЛ) во последниве години помогна во поттикнувањето на техничката состојба во недоразбирањето на природниот јазик (НЛУ). We strongly believe thatmany NLU problems in Arabic are especiallypoised to reap the benefits of such models.  До овој крај го предлагаме benchmark за евалуација на арапскиот јазик (ALUE), базиран на 8 внимателно избрани и претходно објавени задачи. За пет од овие, ние обезбедивме приватни податоци за проценка за да ја осигураме правдата и валидноста на нашата споредба. We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels. Нашите првични експерименти покажуваат дека моделите на МТЛ ги надминуваат своите единствени обучени земји на повеќето задачи. Но, со цел да го интицираме учеството од пошироката заедница, се држиме до објавувањето на основни основи кои се обучени сами. Сепак, нашата анализа открива дека има многу место за подобрување во Арапската НЛУ. Се надеваме дека ALUE ќе учествува во помошта на нашата заедница да ги оствари овие подобрувања. Заинтересираните истражувачи се поканети да ги пренесат своите резултати на нашата онлајн и јавно пристапна водечка табла.', 'ms': 'Kemunculan model pembelajaran berbilang-tugas (MTL) dalam tahun-tahun terakhir telah membantu mendorong keadaan seni dalam bahasa alam tidak memahami (NLU). Kami yakin bahawa banyak masalah NLU dalam bahasa Arab khususnya bersedia untuk mengambil keuntungan dari model tersebut. Sampai akhir ini kami melamar Benchmark Evaluasi Bahasa Arab (ALUE), berdasarkan 8 tugas terpilih dengan hati-hati dan diterbitkan sebelumnya. Untuk lima daripada ini, kami menyediakan set data penilaian secara peribadi untuk memastikan keadilan dan kehendak tanda referensi kami. Kami juga menyediakan set data diagnostik untuk membantu penyelidik menyelidiki kerja dalam model mereka. Eksperimen awal kami menunjukkan bahawa model MTL melebihi tugas mereka dilatih tunggal pada kebanyakan tugas. Tetapi untuk mempelajari ketertarikan dari komuniti yang lebih luas, kita tetap menerbitkan garis dasar yang dilatih sendirian. Namun, analisis kami mengungkapkan bahawa ada banyak ruang untuk peningkatan di NLU Arab. Kami berharap bahawa ALUE akan bermain peran dalam membantu komuniti kami menyadari beberapa peningkatan ini. Peneliti tertarik diundang untuk menghantar keputusan mereka ke papan pemimpin kami secara online, dan yang boleh didapati secara awam.', 'ml': 'The emergence of Multi-task learning (MTL)models in recent years has helped push thestate of the art in Natural Language Un-derstanding (NLU).  അറബിയിലെ NLU പ്രശ്നങ്ങള്\u200d വിശ്വസിക്കുന്നത് ഇത്തരം മോഡലുകളുടെ ഉപകരണങ്ങള്\u200d കൊയ്തെടുക്കാനാണെന്നാണ്. ഈ അവസാനത്തിനുള്ളില്\u200d ഞങ്ങള്\u200d അറബി ഭാഷ പ്രായശ്ചിത്തമാക്കുന്നു. എട്ട് സൂക്ഷ്മമായി തെരഞ്ഞെടുത്ത് മുമ്പ് പ്രസിദ്ധമായ ഈ അഞ്ചിലേക്ക്, നമ്മള്\u200d സ്വകാര്യമായ വിലാസങ്ങള്\u200d വെക്കുന്നത് നമ്മുടെ ബെന്\u200dച്മാര്\u200dക്കിന്\u200dറെ നീതിയും വിശ്വാസവും ഉറപ നോക്കുന്നവര്\u200dക്ക് അവരുടെ അകത്തുള്ള ജോലികള്\u200d പരിശോധിക്കാന്\u200d സഹായിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു ഡിയാഗിസ്റ്റിക്ക് ഡാറ്റ നമ്മുടെ ആദ്യത്തെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് എംടിഎല്\u200d മോഡലുകള്\u200d അവരുടെ ഒരേ പരിശീലിക്കപ്പെട്ട ക പക്ഷെ വിശാലമായ സമൂഹത്തില്\u200d നിന്നും ഒരു ടിസ്സ് പങ്കെടുക്കാന്\u200d വേണ്ടി, നമ്മള്\u200d ഒരേ പരിശീലനം പ്രസിദ്ധീകരിക്കുന എന്നാലും നമ്മുടെ അന്വേഷണം വ്യക്തമാക്കുന്നു ഇവിടെ അറബിക്ക് NLU-ലെ മെച്ചപ്പെടുത്താനുള്ള മുറിയില്\u200d ഒര നമുക്ക് പ്രതീക്ഷിക്കുന്നത് നമ്മുടെ സമുദായത്തില്\u200d ഒരു മെച്ചപ്പെട്ട മുന്\u200dകൂട്ടത്തില്\u200d നിന്നും സഹായ താല്\u200dപര്യമുള്ള പരിശീലിക്കാര്\u200d അവരുടെ ഫലങ്ങള്\u200d ഞങ്ങളുടെ ഓണ്\u200dലൈനിലേക്ക് കൊടുക്കാന്\u200d ക്ഷണിക്കപ്പെട്ടിരിക്', 'mn': 'Өнгөрсөн жилийн дотор олон ажлын суралцах (MTL) загварын тухай байдал нь байгалийн хэл дээрх урлагийн тогтвортой (NLU) байдалд тусалдаг. Бид Араб хэлний НЛУ асуудлын тухай бодлогыг ялангуяа ийм загварын ашиг гаргаж чаддаг гэдэгт итгэдэг. Түүний төгсгөлд бид Араб хэл болон өмнө нь хэвлэгдсэн 8 даалгавартай сонгогдсон, хэвлэгдсэн ажил дээр санал өгдөг. Эдгээрийн тавын хувьд бид өөрсдийгөө үнэлэх өгөгдлийн сангуудыг баталж, баталгааны шударга болон зөв байдлыг баталж байв. Мөн бид судлаачид өөрсдийн дотор ажиллагааны судалгаанд туслахын тулд диагностикийн өгөгдлийн санг өгдөг. Бидний анхны туршилтууд MTL загваруудыг ихэнх ажлын тухай ганц сургалтыг хийдэг. Гэхдээ илүү өргөн нийгэмд оролцохын тулд бид ганц сургалтын сургалтыг хэвлэхэд зогсож байна. Гэвч бидний шинжилгээ нь Араб НЛУ-д сайжруулахад маш олон зай байгааг харуулдаг. Бид ALUE бидний нийгэмд эдгээр сайжруулалтыг ойлгохын тулд нэг хэсэг тоглох гэж найдаж байна. Харин сонирхолтой судлаачид бидний онлайн дээр үр дүнг өгөх болон олон нийтэд ашигтай удирдагч буудалдаг.', 'mt': 'Il-ħolqien ta’ mudelli ta’ tagħlim b’ħafna kompiti (MTL) f’dawn l-aħħar snin għen biex titmexxa l-aktar avvanzata f’nuqqas ta’ fehim tal-lingwa naturali (NLU). Aħna nemmnu bil-qawwa li ħafna problemi tan-NLU fl-Għarab huma ppreparati b’mod speċjali biex jgawdu l-benefiċċji ta’ mudelli bħal dawn. Għal dan il-għan nipproponu l-Punt ta’ Valutazzjoni ta’ Mhux Qed Jinftiehem fil-Lingwa Għarbija (ALUE), ibbażat fuq 8 kompiti magħżula bir-reqqa u ppubblikati minn qabel. Għal ħames minn dawn, ipprovdejna settijiet ta’ dejta ta’ evalwazzjoni miżmuma privatament biex niżguraw il-ġustizzja u l-validità tal-punt ta’ riferiment tagħna. Aħna nipprovdu wkoll sett ta’ dejta dijanjostika biex ngħinu lir-riċerkaturi jistudjaw il-ħidmiet interni tal-mudelli tagħhom. L-esperimenti inizjali tagħna juru li l-mudelli MTL jaqbżu l-partijiet tagħhom imħarrġa waħedhom fil-biċċa l-kbira tal-kompiti. Iżda sabiex niċċentifikaw il-parteċipazzjoni mill-komunità usa’, aħna nżammu għall-pubblikazzjoni ta’ linji bażi mħarrġa waħedhom biss. Madankollu, l-analiżi tagħna turi li hemm biżżejjed spazju għat-titjib fl-NLU Għarab. Nittamaw li l-ALUE se jkollha sehem biex tgħin lill-komunità tagħna twettaq xi wħud minn dawn it-titjib. Ir-riċerkaturi interessati huma mistiedna jissottomettu r-riżultati tagħhom lit-tabella ewlenija tagħna onlajn, u aċċessibbli għall-pubbliku.', 'pl': 'Pojawienie się modeli uczenia się wielozadaniowego (MTL) w ostatnich latach przyczyniło się do podniesienia stanu sztuki w zakresie rozumienia języka naturalnego (NLU). Jesteśmy głęboko przekonani, że wiele problemów NLU w języku arabskim jest szczególnie oczekiwanych, aby czerpać korzyści z takich modeli. W związku z tym proponujemy wskaźnik oceny języka arabskiego (ALUE), oparty na osiem starannie wybranych i wcześniej opublikowanych zadań. Dla pięciu z nich dostarczamy nowe prywatne zbiory danych oceniających, aby zapewnić rzetelność i ważność naszego wskaźnika. Dostarczamy również zestaw danych diagnostycznych, aby pomóc badaczom zbadać wewnętrzne funkcjonowanie ich modeli. Nasze wstępne eksperymenty pokazują, że modele MTL przewyższają swoje pojedynczo przeszkolone części w większości zadań. Ale aby zapewnić uczestnictwo szerszej społeczności, trzymamy się wydawania pojedynczo wyszkolonych podstawowych. Niemniej jednak nasza analiza pokazuje, że w arabskiej NLU istnieje dużo miejsca do poprawy. Mamy nadzieję, że ALUE odegra rolę w realizacji niektórych z tych ulepszeń. Zainteresowani badacze są zapraszani do przesyłania swoich wyników do naszego online i publicznie dostępnego leaderboard.', 'ro': 'Apariţia modelelor de învăţare multifuncţională (MTL) în ultimii ani a contribuit la dezvoltarea stadiului artei în domeniul limbajului natural (NLU). Credem cu tărie cămulte probleme NLU în limba arabă sunt îndeosebi proiectate pentru a culege beneficiile unor astfel de modele. În acest scop, propunem benchmarkul de evaluare fără înţelegere al limbii arabe (ALUE), bazat pe 8 sarcini atent selectate şi publicate anterior. Pentru cinci dintre acestea, furnizăm noi seturi de date de evaluare private pentru a asigura corectitudinea și validitatea benchmark-ului nostru. De asemenea, oferim un set de date de diagnosticare pentru a ajuta cercetătorii să sondeze funcționarea interioară a modelelor lor. Experimentele noastre iniţiale arată că modelele MTL depăşesc componentele lor individuale antrenate în majoritatea sarcinilor. Însă pentru a facilita participarea comunităţii mai largi, rămânem la publicarea numai a unor linii de bază instruite individual. Cu toate acestea, analiza noastră arată că există suficient loc de îmbunătățire în NLU arabă. Sperăm că ALUE va juca un rol în a ajuta comunitatea noastră să realizeze unele dintre aceste îmbunătățiri. Cercetătorii interesați sunt invitați să își prezinte rezultatele în clasamentul nostru online și accesibil public.', 'no': 'Utviklinga av fleire oppgåver-læring (MTL)modeller i siste år har hjelpt til å trykke kunstheten i naturspråk utan-derstand (NLU). Vi tror sterkt at måten NLU-problemer i arabisk er spesielt skriven ut for å opprette fordelene av slike modeller. Til slutten foreslår vi den arabiske språket utformande evalueringsbenchmarken (ALUE), basert på 8 forsiktig valde og førehandsviste oppgåver. For fem av desse tilbyr vi privat holdt evalueringsdatasett for å sikre på at det er rett og gyldig av vårt benchmarkt. Vi tilbyr også ein diagnostisk dataset for å hjelpe forskere å prøve dei innere arbeidsomodelane sine. Våre første eksperimenter viser at MTL-modeller utfører dei enkelt trengte trekantane på dei fleste oppgåver. Men for å avkryssa deltakelsen frå den bredere samfunnet, blir vi i stand til å publisera enkelt trengte baselinesone. Men analysen vårt viser at her er mange rom for forbedring i arabiske NLU. Vi håper at ALUE vil spela ein del i å hjelpa samfunnet vårt å forstå noen av desse forbetringane. Interesarte forskere er inviterte til å senda sine resultat til vårt nettverk og offentlig tilgjengeleg lederbord.', 'sr': 'Pojavljivanje modela multitask učenja (MTL) u poslednjih godina pomoglo je da nastavi stanje umjetnosti u prirodnom jeziku bez odvratnosti (NLU). Stvarno verujemo da su problemi sa NLU na arapskom posebno napravljeni da bi dobili koristi takvih modela. Za kraj svega predlažemo bezodređenu ocjenu (ALUE), na osnovu 8 pažljivo odabranih i ranije objavljenih zadataka. Za pet od ovih, pružili smo privatne podatke za procjenu da bismo uverili poštenost i validnost našeg kriterija. Također pružamo i dijagnostičku setu podataka za pomoć istraživačima da istražuju unutrašnje radnje njihovih imodela. Naši prvi eksperimenti pokazuju da modeli MTL iznose svoje jedine obučene kolege na većinu zadataka. Ali, kako bismo uključili učešće iz šire zajednice, držali smo se objavljivanja jednostavno obučenog baselinesona. Ipak, naša analiza pokazuje da je ovde dosta mjesta za poboljšanje na arapskom NLU. Nadamo se da će ALUE igrati ulogu u pomaganju našoj zajednici da shvati neke od ovih poboljšanja. Zanimljivi istraživači su pozvani da predaju svoje rezultate našoj internetu i javno dostupnim vodećim tablama.', 'so': 'Xaaladda waxbarashada waxbarashada badan (MTL)modellada sanadkii ugu dambeeyey waxay caawiyey in la wado xaaladda farshaxanka ee afka asalka ah ee aan la barto (NLU). Si adag ayaannu u aaminsanahay in dhibaatooyinka afka Carabiga NLU ay khaas u leeyihiin in ay soo ururiyaan manfacyada modelladan oo kale. Taas darteed waxaynu soo jeedinaynaa kaalmada kaartaynta afka Carabiga ee aan la mid ahayn (ALUE), oo ku saleysan 8 si taxadar leh loo doortay oo horay loo soo bandhigay shaqooyin. Shan ka mid ah ayaannu gaar ahaan u siinnaa kooban qiimeynta oo gaarka loo leeyahay si xaqiiqada iyo xaqnimada bangiyadeena. Waxaynu sidoo kale u siinaynaa kooban macluumaadka aqoonsiga si ay u caawiyaan baaritaanka inay caddeeyaan shaqada hoose ee jimicsiga. Imtixaanka ugu horeeyay waxay muujiyaan in qaababka MTL ay ka samaystaan wadajirkooda oo kaliya oo la tababaray shaqada badan. Laakiin si aan uga qayb galno bulshada ballaadhan, waxaynu u sii wadnaa baaritaanka aasaasiga ah oo kaliya. Si kastaba ha ahaatee, baaritaankeenu waxay muuqataa in halkan waa qol badan oo hagaajinta afka Carabiga NLU. We hope that ALUE will playa part in helping our community realize someof these improvements.  waxaa loo yeeraa cilmi-baaritaanka xiiseysan si ay resultigooda ugu dhiibaan shabakadda internetka iyo hogaamiyaha aad u bannaan karto.', 'si': 'මුලින් අවුරුද්දු වලින් ගොඩක් වැඩක් ඉගෙනගන්න පුළුවන් විදියට (MTL) මොඩේල්ස් එක්ක උදව් කළා ස්වභාවික භාෂාව අපි හොඳටම විශ්වාස කරනවා අරාබි වල NLU ප්\u200dරශ්නයක් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් ඉන්නවා ඒ වගේ මොඩේල අන්තිම අවසානය අපි අරාබි භාෂාව අන්තිමත් විශේෂණ බෙන්ච්මාර්ක් (ALUE) යුද්ධ කරනවා, පස්සේ තෝරාගෙන හා ප්\u200dරකාශ අපි පුද්ගලික විශ්වාස කරලා තියෙන්නේ පුද්ගලික විශ්වාස දත්ත සේට්ටුවට අපේ බෙන්ච්මාර්ක් ගැන සාධාරණය ස අපි පරීක්ෂකයන්ට උදව් කරන්න පුළුවන් පරීක්ෂකයන්ට උදව් කරන්න තියෙනවා ඔවුන්ගේ අන්තිම වැඩ කරන්න. අපේ පටන් ගත්ත පරීක්ෂණය පෙන්වන්නේ MTL මොඩේල්ස් ඔවුන්ගේ එකම ප්\u200dරශ්නයක් ගොඩක් වැඩේ වැඩේ වැඩේ ඉන්න පුළ ඒත් විශාල සමාජයෙන් සාමාජිකයෙන් සාමාජිකයෙන් ප්\u200dරකාශනය කරන්න, අපි ප්\u200dරකාශනය කරලා ප්\u200dරකාශනය කරනවා. නමුත්, අපේ විශ්ලේෂණය ප්\u200dරකාශ කරනවා මෙතන අරාබි NLU වලට වැඩි කාමරයක් තියෙනවා කියලා. අපි හිතන්නේ ALUE අපේ සමාජිකයෙන් මේ වැඩේ කිසිම දැනගන්න උදව් කරනවා කියලා. ප්\u200dරශ්න විශ්වාස කරුණාකරුන්ට අතුරුදන් වෙනවා ඔවුන්ගේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති', 'sv': 'Framväxten av Multi-Task Learning (MTL)modeller under de senaste åren har bidragit till att driva på konsten inom Natural Language Unstanding (NLU). Vi är övertygade om att många NLU-problem på arabiska är särskilt avsedda att skörda fördelarna med sådana modeller. I detta syfte föreslår vi det arabiska språkets understanding Evaluation Benchmark (ALUE), baserat på åtta noggrant utvalda och tidigare publicerade uppgifter. För fem av dessa tillhandahåller vi nya privatägda utvärderingsdata för att säkerställa rättvisan och validiteten av vårt riktmärke. Vi tillhandahåller också en diagnostisk datauppsättning för att hjälpa forskare att undersöka hur deras modeller fungerar. Våra inledande experiment visar att MTL-modeller presterar bättre än sina enskilt utbildade landsdelar på de flesta uppgifter. Men för att underlätta deltagandet från det bredare samhället håller vi oss till att enbart publicera individuellt utbildade baslinjer. Ändå visar vår analys att det finns gott om utrymme för förbättringar i arabiska NLU. Vi hoppas att ALUE kommer att spela en roll för att hjälpa vårt samhälle att förverkliga några av dessa förbättringar. Intresserade forskare uppmanas att skicka in sina resultat till vår online,och offentligt tillgängliga leaderboard.', 'ta': 'அண்மைய ஆண்டுகளில் பல பணி கற்றுக்கொள்ளும் மாதிரிகளின் வெளியேற்றம் சாதாராயமான மொழி நிலையில் உள்ள கலைத்தின் நிலையை நகர்த்தி உதவி நாங்கள் உறுதியாக நம்புகிறோம் அரபி பிரச்சினைகள் என்னவென்றால் இந்த மாதிரிகளின் பயன்பாடுகளை குடைக்கும் சிறப்பு  Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks.  இந்த ஐந்து பேருக்கு, நாம் தனிப்பட்ட மதிப்பீட்டு தரவுத்தளங்களை வழங்குகிறோம், எங்கள் பென்க்மார்க்கு நிச்சயமாக நி நாம் ஒரு கண்டறிவு தகவல் அமைப்பை வழங்குகிறோம் ஆராய்ச்சியாளர்கள் தங்கள் உள்ளே வேலைகளை கண்டறிய உதவுகிறது. நம்முடைய முதல் சோதனைகள் பெரும்பாலான வேலைகளில் பயிற்சி செய்யப்பட்ட மாதிரிகளை காட்டுகிறது. ஆனால் பெரிய சமுதாயத்திலிருந்து ஒரு முறை பகிர்ந்து கொள்ளும் பொழுது, ஒரே பயிற்சி அடிப்படைகளை மட்டும் வெளிப்பட ஆனாலும், எங்கள் ஆராய்ச்சி தெரிவிக்கிறது இது அரபி NLU முன்னேற்றத்திற்கு நிறைய அறையானது. நம்முடைய சமூகத்திற்கு இந்த முன்னேற்றங்களை அறிந்து கொள்ள உதவும் பொருட்டு எல்லாய் ஒரு பகுதியை விளைய ஆர்வமுள்ள ஆராய்ச்சியாளர்கள் அவர்களுடைய விளைவுகளை எங்கள் ஆன்லைனில் கொடுக்க அழைக்கப்பட்டுள்ளன, மற்றும் பொத', 'ur': 'اگلے سالوں میں بہت سے کام کی تعلیم (MTL) موڈل کی اضطراری مدد کرتی ہے کہ نطبیعی زبان میں آثار کی حالت ناپاک کرتی ہے۔ ہم مضبوط سمجھتے ہیں کہ اس طرح کی مدل کے فائدہ اٹھانے کے لئے NLU مشکلات مخصوص طرح کی جاتی ہیں۔ ہم نے عربی زبان کی غیر قابل تحقیقات سنچم (ALUE) کی پیشنهاد کریں، 8 دقیقا منتخب اور پہلے منتخب کیے ہوئے کاموں پر بنیاد رکھا ہے۔ ان میں سے پانچ کے لئے ہم نے خصوصی طرح تحقیق ڈیٹ سٹ کو دکھایا تھا کہ ہمارے سنچم کی عدالت اور validity کو مطمئن کریں۔ ہم نے بھی ایک دیاگنٹیک ڈیٹ سٹ دی ہے جسے تحقیقات کرنے والوں کے اندر کے کاموں کی تحقیق کرنے کے لئے مدد کریں۔ ہمارے آغاز تجربے دکھاتے ہیں کہ MTL موڈل اکثر کاموں پر ایک طرح کی آموزش دی گئی ہیں۔ لیکن اکثر اجتماعی سے مشترک کرنے کے لئے ہم ایک طرح کی آموزش کی بنیادین کے ساتھ پھیلاتے ہیں۔ لیکن ہماری تحلیل ظاہر کرتی ہے کہ یہ عربی NLU میں بہت سی جگہ ہے۔ ہم امید رکھتے ہیں کہ ALUE ہماری جماعت کی مدد کرنے میں ایک حصہ کھیل دے گا کہ یہ بہترین باتیں سمجھ سکیں۔ علاقہ دار تحقیقات کرنے والوں کو بلایا جاتا ہے کہ اپنے نتائج ہمارے آنلاین میں بھیج دیں', 'uz': "Yaqinda ko'pchilik vazifalar o'rganish modellari (MTL) taʼminlovchi holatini tabiiy tillar o'zgarishga (NLU) saqlash holatini yordam berdi. Biz juda yaxshi ishonamiz, arabda NLU muammolari bu modellarning vazifalarini o'tib qo'yishga asoslangan. Bu yerda biz 8 ta taqdim tanlangan va avval berilgan vazifalar asosida yaratilgan arab tilni tasavvur qilamiz. Bu besh narsa uchun biz shaxsiy qiymatlar tarkibini saqlab qolamiz, balbalarning haqida va haqiqiqiyligimizga ishonch hosil qilamiz. Biz o'qituvchilarning ichki ishlarini o'rganish uchun diagnostic maʼlumot tartibi beramiz. Bizning birinchi tajribalarimiz, MTL modellari ularning ko'pchilik vazifalarda bitta o'rganilgan hamma ishlarni bajaradi. Lekin ko'proq jamiyatdan bir qiziqarish uchun, biz faqat bir o'rganilgan asboblarni o'rganishga harakat qilamiz. Lekin, bizning analytikimizni anglatadi, bu arab NLU'da yaxshi ko'p xonalar. Biz umid qilamiz, AQUE jamiyatlarning bir narsa o'rganishga yordam beradi. Agar qiziqarli taʼminlovchilar natijalarini online va publicly imkoniyatli boshqaruvchiga joʻnatishga yetadilar.", 'vi': 'Sự xuất hiện của các mô hình tổ chức đa nhiệm vụ trong những năm gần đây đã giúp đẩy tình hình nghệ thuật về ngôn ngữ tự nhiên bất đồng (Ntrường). Chúng tôi tin chắc rằng nhiều vấn đề Ntrường hợp ở Ả Rập được đặc biệt hướng tới để tận hưởng lợi ích từ các mô hình đó. Cuối cùng, chúng tôi đề xuất tiêu đề nghị tiêu chuẩn Đánh giá Ngôn ngữ Á Rập (ALUE), dựa trên tám nhiệm vụ được chọn cẩn thận và được công bố trước. Năm trong số đó, chúng tôi cung cấp dữ liệu đánh giá tư nhân mới để đảm bảo sự công bằng và giá trị của tiêu chuẩn chuẩn. Chúng tôi cung cấp dữ liệu chẩn đoán để giúp các nhà nghiên cứu nghiên cứu về hoạt động nội bộ của mô-đun. Những thí nghiệm đầu tiên của chúng tôi cho thấy các mô hình MTV hoàn thành các đối tác riêng trong hầu hết các nhiệm vụ. Nhưng để có được sự tham gia của cộng đồng rộng hơn, chúng tôi tiếp tục công bố những căn cứ được đào tạo một mình. Tuy nhiên, phân tích của chúng tôi cho thấy rằng có rất nhiều chỗ để cải thiện trong Ntrường Ả Rập. Chúng tôi hy vọng ALUE sẽ có phần trong việc giúp cộng đồng nhận ra một số những cải tiến này. Các nhà nghiên cứu có hứng thú được mời giao kết quả của họ cho bảng làm việc trực tuyến và công khai.', 'nl': 'De opkomst van Multi-task learning (MTL)modellen in de afgelopen jaren heeft bijgedragen aan de ontwikkeling van de stand van de techniek in Natural Language Understanding (NLU). Wij zijn er sterk van overtuigd dat veel NLU-problemen in het Arabisch vooral de vruchten van dergelijke modellen zullen plukken. Hiertoe stellen wij de Arabisch Language Understanding Evaluation Benchmark (ALUE) voor, gebaseerd op acht zorgvuldig geselecteerde en eerder gepubliceerde taken. Voor vijf daarvan bieden we nieuwe particuliere evaluatiedatasets aan om de eerlijkheid en geldigheid van onze benchmark te verzekeren. We bieden ook een diagnostische dataset om onderzoekers te helpen de interne werking van hun modellen te onderzoeken. Onze eerste experimenten tonen aan dat MTL-modellen bij de meeste taken beter presteren dan hun enkelopgeleide counterparts. Maar om participatie van de bredere gemeenschap te bewerkstelligen, houden we ons bij het publiceren van enkelgeschoolde basislijnen. Niettemin blijkt uit onze analyse dat er veel ruimte voor verbetering is in Arabische NLU. We hopen dat ALUE een bijdrage zal leveren aan het realiseren van een aantal van deze verbeteringen. Geïnteresseerde onderzoekers worden uitgenodigd om hun resultaten in te dienen op ons online en publiek toegankelijke leaderboard.', 'da': 'Fremkomsten af Multi-Task Learning (MTL)modeller i de seneste år har bidraget til at fremme kunstens tilstand inden for Natural Language Unforstanding (NLU). Vi er overbevist om, at mange NLU-problemer på arabisk især er berettiget til at høste fordelene ved sådanne modeller. I denne forbindelse foreslår vi det arabiske sprog Unforstanding Evaluation Benchmark (ALUE), baseret på 8 omhyggeligt udvalgte og tidligere offentliggjorte opgaver. For fem af disse leverer vi nye privatejede evalueringsdatasæt for at sikre retfærdigheden og gyldigheden af vores benchmark. Vi leverer også et diagnostisk datasæt til at hjælpe forskere med at undersøge deres modeller. Vores indledende eksperimenter viser, at MTL-modeller udfører deres enkeltstrænede landes dele på de fleste opgaver. Men for at sikre deltagelse fra det bredere samfund holder vi os til kun at udgive individuelt uddannede basislinjer. Ikke desto mindre viser vores analyse, at der er masser af plads til forbedringer i arabisk NLU. Vi håber, at ALUE vil spille en rolle i at hjælpe vores samfund med at realisere nogle af disse forbedringer. Interesserede forskere inviteres til at indsende deres resultater til vores online og offentligt tilgængelige leaderboard.', 'de': 'Das Aufkommen von Multi-Task Learning (MTL)-Modellen in den letzten Jahren hat dazu beigetragen, den Stand der Technik im Natural Language Understanding (NLU) voranzutreiben. Wir sind der festen Überzeugung, dass viele NLU-Probleme in arabischer Sprache besonders geeignet sind, die Vorteile solcher Modelle zu ernten. Zu diesem Zweck schlagen wir den Arabisch Language Understanding Evaluation Benchmark (ALUE) vor, der auf acht sorgfältig ausgewählten und zuvor veröffentlichten Aufgaben basiert. Für fünf davon stellen wir neue privat gehaltene Evaluationsdatensätze zur Verfügung, um die Fairness und Gültigkeit unseres Benchmarks sicherzustellen. Außerdem stellen wir einen diagnostischen Datensatz zur Verfügung, mit dem Forscher die inneren Funktionsweisen ihrer Modelle untersuchen können. Unsere ersten Experimente zeigen, dass MTL-Modelle bei den meisten Aufgaben ihre einzeln trainierten Länderbetreffen. Aber um die Beteiligung der breiteren Gemeinschaft zu ermöglichen, halten wir uns an der Veröffentlichung von allein ausgebildeten Einzelpersonen fest. Dennoch zeigt unsere Analyse, dass es in der arabischen NLU viel Verbesserungspotenzial gibt. Wir hoffen, dass ALUE dazu beitragen wird, dass unsere Community einige dieser Verbesserungen realisiert. Interessierte Forscher sind eingeladen, ihre Ergebnisse in unsere online und öffentlich zugängliche Bestenliste einzureichen.', 'bg': 'Появата на моделите за многофункционално обучение през последните години спомогна за тласкането на състоянието на изкуството в неразбирането на естествения език (НЛУ). Силно вярваме, че много проблеми на НЛУ на арабски език са особено насочени да се възползват от ползите от такива модели. За целта предлагаме индикатор за оценка на арабския език (АЛУЕ), основан на 8 внимателно подбрани и предварително публикувани задачи. За пет от тях предоставяме нови частни набори от данни за оценка, за да гарантираме справедливостта и валидността на нашия показател. Също така предоставяме диагностичен набор от данни, за да помогнем на изследователите да изследват вътрешната работа на техните модели. Нашите първоначални експерименти показват, че моделите на МТЛ превъзхождат своите самостоятелно обучени контингенти при повечето задачи. Но за да привлечем участието на широката общност, ние се придържаме към публикуването на самостоятелно обучени базови линии. Въпреки това, нашият анализ показва, че има достатъчно място за подобрение в арабския НЛУ. Надяваме се, че ще играе роля в подпомагането на нашата общност да реализира някои от тези подобрения. Заинтересованите изследователи са поканени да представят резултатите си в нашата онлайн и публично достъпна класация.', 'hr': 'Pojavljivanje modela multizadatačnog učenja (MTL) u posljednjih godina pomoglo je natjerati stanje umjetnosti u prirodnoj jezici. Ozbiljno vjerujemo da su problemi sa NLU na arapskom posebno napravljeni da bi dobili koristi takvih modela. Cijeli kraj predlažemo temelj 8 pažljivo odabranih i ranije objavljenih zadataka o nepristojnoj ocjeni arapskog jezika (ALUE). Za pet od njih, pružili smo privatne podatke o procjenama kako bi se uvjerili pravednost i validnost našeg kriterija. Također pružamo i dijagnostičku setu podataka za pomoć istraživačima ispitivanja unutrašnjih djelovanja njihovih rmodela. Naši početni eksperimenti pokazuju da modeli MTL-a nadmađuju svoje jedinstveno obučene kolege na većinu zadataka. Ali kako bismo se uključili učešće šire zajednice, držali smo se objavljivanja jednostavno obučenog početnog položaja. Ipak, naša analiza pokazuje da je ovdje dosta mjesta za poboljšanje na arapskom NLU. Nadamo se da će ALUE igrati dio pomoći našoj zajednici da shvati neke od ovih poboljšanja. Zanimljivi istraživači su pozvani da predaju svoj rezultat našoj internetu i javno dostupnim vodećim tablama.', 'ko': '최근 몇 년 동안 다중 임무 학습(MTL) 모델의 출현은 자연 언어 이해(NLU)의 발전을 추진했다.우리는 아랍어의 많은 NLU 문제가 특히 이런 모델에서 이익을 얻기 쉽다고 굳게 믿는다.이를 위해 우리는 8가지 정성스럽게 고르고 이전에 발표한 임무에 따라 아랍어 유엔 이해평가기준(ALUE)을 제시했다.그 중 다섯 가지에 대해 우리는 우리의 기준의 공평성과 유효성을 확보하기 위해 새로운 개인 평가 데이터 집합을 제공했다.우리는 또한 연구원들이 그 모델의 내부 작업 메커니즘을 탐색하도록 돕기 위해 진단 데이터 집합을 제공했다.우리의 초보적인 실험은 MTL 모델이 대부분의 임무에서 단독 훈련 모델보다 우수하다는 것을 보여 주었다.그러나 보다 광범위한 지역사회가 참여할 수 있도록 단독 교육을 거친 기선만 출판하기로 했다.그럼에도 불구하고 아랍국가대학은 여전히 개선할 여지가 많다는 분석이 나온다.우리는 ALUE가 우리 지역사회의 이러한 개선을 돕는 데 역할을 발휘하기를 바란다.관심 있는 연구원들이 그들의 연구 결과를 우리의 온라인, 공개 방문 가능한 순위에 제출하는 것을 환영합니다.', 'fa': 'اضطراری مدل یادگیری چندین کار (MTL) در سال اخیر کمک کرده است که وضعیت هنری در زبان طبیعی ناپایدار (NLU) را فشار دهد. ما به شدت اعتقاد داریم که مشکلات NLU در عربی مخصوصاً برای بردن سودهای این مدل\u200cها هستند. به تمام پایان ما پیشنهاد می\u200cکنیم برچسب ارزیابی زبان عربی (ALUE) که بر اساس ۸ کار انتخاب شده و پیش از این منتشر شده است. برای پنج از اینها، ما به خصوصی داده\u200cهای ارزیابی محافظت کرده\u200cایم تا مطمئن شویم که عدالت و قابلیت ارزیابی ماست. ما همچنین یک مجموعه اطلاعات تشخیص را برای کمک به محققان تحقیقات کار داخلی مودل\u200cهایشان می\u200cدهیم. آزمایش های اولیه ما نشان می دهند که مدلهای MTL تنها همکاران خود را بر بیشتر کارها انجام می دهند. ولی برای بازگیری از جامعه\u200cهای گسترده\u200cتر، ما به طریق انتشار پایین\u200cشناسی آموزش داده\u200cایم. با این حال، تحلیل ما نشان می دهد که اینجا جای بسیاری برای بهبود در NLU عربی وجود دارد. ما امیدواریم که ALUE یک قسمت در کمک به جامعه ما به فهمیدن بعضی از این پیشرفتها بازی کند. محققان علاقه\u200cمند دعوت می\u200cشوند تا نتیجه\u200cهایشان را به آنلاین ما ارسال کنند،و به طور عمومی دسترسی به صفحه\u200cی رهبری.', 'id': 'Kemunculan model pembelajaran multitask (MTL) selama bertahun-tahun terakhir telah membantu mendorong keadaan seni dalam bahasa alam tidak mengerti (NLU). Kami sangat percaya bahwa banyak masalah NLU dalam bahasa Arab khususnya siap untuk mengambil keuntungan dari model tersebut. Sampai akhirnya kami mengusulkan Benchmark Evaluasi Bahasa Arab (ALUE), berdasarkan 8 tugas yang dipilih dengan hati-hati dan diterbitkan sebelumnya. For five of these, we providenew privately held evaluation datasets to en-sure the fairness and validity of our benchmark. Kami juga menyediakan set data diagnostik untuk membantu peneliti menyelidiki fungsi dalam model mereka. Eksperimen awal kami menunjukkan bahwa model MTL melebihi layanan negara terlatih mereka pada kebanyakan tugas. Tapi untuk mempelajari partisipasi dari komunitas yang lebih luas,kita tetap mempublikasikan garis dasar terlatih sendirian. Namun, analisis kami mengungkapkan bahwa ada banyak ruang untuk memperbaiki NLU Arab. Kami berharap bahwa ALUE akan bermain bagian dalam membantu komunitas kita menyadari beberapa perbaikan ini. Peneliti tertarik diundang untuk mengirim hasilnya ke papan pemimpin online,dan secara publik.', 'tr': 'Son ýyllar içinde köp-taýýarlyk öwrenmeniň döredilmesi (MTL) nusgalarynyň tebigy dilinde bolup durmaýan (NLU) sungatyň durumyny täze etmegine kömek etdi. Biz Arapça NLU meseleleriniň beýleki nusgalarynyň bardygyna ynanýarys. Ahyrsoňy biz Arapça dilinde çykyş bolmadyk deňlenme çykgyny (ALUE) teklip edip, öňki görkezilýän 8 sany üstünde tapylýardyk we öňki görkezilýän zada baýram. Bütün bunlardan 5 boyunca gizli olarak çözümlenme veri setlerini benchmark ımızın adaletliğini ve değerliğini kontrol etmek için temin ediyorduk. Biz hem diňe çözümleriniň içi işlerini barlamak üçin diagnostik veri setini temin edýäris. Biziň başlangyç deneylerimiz MTL nusgalarynyň köp işi üçin ýeke-täk şeklinde täzeden ukypdygyny görkez. Emma döwletlerden bäsleşigini daşyrtmak üçin biz ýeke-täk şekilde bilim alynylan beýikde publikat etmek üçin saglanýarys. Yine-de biziň analyzamyz şu ýerde arap NLU-da gelişmek üçin köp ýer bar. Biz ALUE jemgyýetimize bu gelişmeleriň birnäçesini çykarmak üçin bir bölüm oýnap biljekdigini umyt edýäris. Gyzalan araştyranlar netijelerini internetmize goýbermege çagyrylýar we halkara elýeterli goýunçy bölegimize çagyrylýar.', 'sw': 'Upasuaji wa modeli za kujifunza kwa majukumu mengi (MTL) katika miaka ya hivi karibuni umesaidia kusukuma hali ya sanaa katika lugha ya asili ya asili (NLU). Tunaamini kwa nguvu kwamba matatizo yoyote ya NLU kwa Kiarabu yanahusishwa na watu maalum kuvunja faida za mifano hiyo. Kwa mwisho huu tunapendekeza Benchmark ya Uthibitisho wa Kiarabu wa Uchunguzi (ALUE), kwa kutumia kazi 8 zilizochaguliwa kwa makini na zilizochapishwa kabla. Kwa baadhi ya hawa tano, tunatoa taarifa za uchunguzi binafsi zinazofanywa ili kuhakikisha kwamba haki na ukweli wa bendera yetu. We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels. Majaribio yetu ya mwanzo yanaonyesha kuwa mifano ya MTL wanafanya wenzao waliofundishwa pekee katika kazi nyingi. Lakini ili kushiriki katika jamii kubwa zaidi, tunaendelea kuchapisha msingi wa mafunzo pekee. Hata hivyo, uchambuzi wetu unaonyesha kuwa hapa ni vyumba vingi vya kuboresha NLU ya Kiarabu. Tunatumaini kwamba ALUE itafanya sehemu katika kusaidia jamii yetu kutambua baadhi ya maendeleo haya. Watafiti wenye maslahi wameitwa kuwasilisha matokeo yao kwenye mtandao wetu, na kiongozi wa umma unaowezeka.', 'af': "Die uitbreiding van multi-taak leer (MTL)modele in onlangse jaar het hulp om die staat van die kuns in Natuurlike Taal Onderstaande (NLU) te druk. Ons glo sterk dat die mense van NLU probleme in Arabiese is spesiaal uitgevoer om die voordele van sodanige modele te kry. Tot die einde voorstel ons die Arabiese Taal Onderstaande Evaluering Benchmark (ALUE), gebaseer op 8 versigtig gekose en vooraf gepubliseer taak. Vir vyf van hierdie, het ons privaat gehou van evalueringsdatastelle om seker te stel die regverdigheid en geldigheid van ons benchmark. Ons verskaf ook 'n diagnosiese dataset om resekers die binneste werke van hul rmodels te probeer. Ons aanvanklike eksperimente wys dat MTL-modelles hulle enkelkeen onderwerp onderwerp op meeste opdragte. Maar om deelnimmering van die breede gemeenskap te verkies, staan ons op eintlik onderwerp baselinesoneel te publiseer. Ons analisie verduidelik dat hier baie kamer is vir verbetering in Arabiese NLU. Ons hoop dat ALUE 'n deel sal speel in die help van ons gemeenskap om iets van hierdie verbeteringe te bevestig. Interesteerde ondersoekers word aangeroep om hul resultate aan ons online te onderskryf en openlik toeganklik leierbord.", 'am': 'በአሁኑ ዓመታት የብዙ አድራሻ ትምህርት (MTL) models በጥያቄ ቋንቋ አዳራዊ ቋንቋ-አዳራቢ (NLU) የጥናት ሁኔታ አግኝቷል፡፡ በዐረብኛ የNLU ጉዳይ የዚህን ዓይነቶች ጥቅም ለማጭድ በተለየ ነው ብለን በብርቱ እናምናለን፡፡ ስለዚህም በ8 ተጠንቀቅ የተመረጠውና ቀድሞው የተለጠውን ስራዎችን በመሠረት ላይ የዐረብኛ ቋንቋ አካባቢ ማስረጃ (ALUE) እናሳልቃለን፡፡ ከእነዚህ ለአምስት ሰዎች የመረመሪያችን ውድቅና እውነተኛነት እንዲያረጋግጥ ለብቻው የተጠበቀውን የዳታ መስመር ማድረጊያውን እናደርጋለን፡፡ ተማሪዎችን የእነዚህን ውስጥነት ስራዎችን ለማግኘት እናስረዳለን፡፡ የመጀመሪያ ፈተናዎቻችን የMTL ሞዴሎችን በብዙ ስራ ተማሪዎቻቸውን አብልጠዋል የሚያሳየው ነው፡፡ ነገር ግን ከሰፊው ማኅበረሰብ ተግባር ለመግኘት ብቻውን የተማረ መሠረት ብቻ ለመዘጋጀት እንቆማለን፡፡ ምንም እንኳ፣ አረብኛ አፍሪካዊ አፍሪካዊ አፍሪካዊ አፍሪካዊ የስፋት ቦታ እንደሆነ እናውቀዋለን፡፡ ማኅበረሰቦቻችንን ማግኘት ማድረግ ማድረግ እናስፈራለን፡፡ የሚጠቅሙት ምርታተኞች ፍሬያቸውን ወደ መረብ እና በህዝብ የሚጠቅሙትን መሪ ለመስጠት ይጠራሉ፡፡', 'sq': 'Njerëzimi i modeleve të mësimit me shumë detyra (MTL) në vitet e fundit ka ndihmuar në nxitjen e gjendjes së artit në gjuhën natyrore (NLU). Ne besojmë me forcë se shumë probleme të NLU-së në arabisht janë të gatshme veçanërisht për të fituar përfitimet e modeleve të tilla. Deri në fund të kësaj propozojmë Benchmark për vlerësimin e Pakuptueshëm të gjuhës arabe (ALUE), bazuar në 8 detyra të zgjedhura me kujdes dhe publikuara më parë. Për pesë prej këtyre, ne ofruam të dhëna të vlerësimit të mbajtur privat për të siguruar drejtësinë dhe vlerësinë e referencës sonë. Ne gjithashtu ofrojmë një sërë të dhënash diagnostike për të ndihmuar kërkuesit të hetojnë punën e brendshme të modeleve të tyre. Eksperimentet tona fillestare tregojnë se modelet MTL kryejnë pjesët e tyre të trajnuara vetëm në shumicën e detyrave. Por me qëllim që të njoftojmë pjesëmarrjen nga komuniteti më i gjerë, ne qëndrojmë në botimin e linjave bazë të trajnuara vetëm. Megjithatë, analiza jonë zbulon se ka mjaft vend për përmirësim në NLU arabe. Shpresojmë se ALUE do të luajë një pjesë në ndihmën e komunitetit tonë të realizojë disa nga këto përmirësime. Interested researchersare invited to submit their results to our online,and publicly accessible leaderboard.', 'bn': 'সাম্প্রতিক বছরগুলোতে মাল্টিক কাজ শিক্ষার (এমটিএল) মডেলের উদ্যোগ সাহায্য করেছে প্রাকৃতিক ভাষায় শিল্পের পরিস্থিতির (এনএ আমরা শক্তিশালী বিশ্বাস করি যে আরবীতে এনএলইউ সমস্যাগুলো বিশেষ করে এই মডেলের সুবিধা কাটাতে পারে। এই পর্যন্ত আমরা আরবী ভাষা অদ্ভুত প্রতিষ্ঠানের প্রস্তাব করছি সচেতনতার সাথে নির্বাচিত এবং পূর্বে প্রকাশিত কাজের উপর ভিত্তিতে ৮ জন ন এদের পাঁচ জনের জন্য আমরা ব্যক্তিগতভাবে মূল্যায়নের তথ্য প্রদান করি যাতে আমাদের বেনম্যার্কের ন্যায়বিচার এবং বৈধতার জন এছাড়াও আমরা গবেষকদের সাহায্য করার জন্য একটি ডায়াগনিস্টিক ডাটাসেট প্রদান করি। আমাদের প্রথম পরীক্ষা দেখাচ্ছে যে এমটিএল মডেল তাদের একমাত্র প্রশিক্ষিত অংশীদার্টদের বেশীরভাগ কাজে প্রশি কিন্তু ব্যাপক সম্প্রদায় থেকে একটি টিস অংশগ্রহণের জন্য আমরা শুধুমাত্র একা প্রশিক্ষিত বেস লাইন প্রকাশ করতে থাকি। তবুও, আমাদের বিশ্লেষণ প্রকাশ করেছে যে এখানে আরবী এনএলইউ-এর উন্নয়নের জন্য অনেক রুম। আমরা আশা করি যে সকলেই আমাদের সম্প্রদায়ের কিছু উন্নতি বুঝতে সাহায্য করবে। আগ্রহী গবেষকদের আমন্ত্রণ জানানো হয়েছে তাদের ফলাফল অনলাইনে প্রদান করার জন্য এবং প্রকাশ্যে প্রবেশিত নেতৃত্ব বোর্', 'hy': 'Վերջին տարիների ընթացքում բազմախնդիրների ուսումնասիրության (MTL) մոդելների առաջացումը օգնեց բնական լեզվի տեխնոլոգիայի նորաձևությունը ճնշել: Մենք ուժեղ հավատում ենք, որ շատ ՆԼՄ-ի խնդիրներ արաբերեն հատկապես պատրաստ են օգտագործել նման մոդելների առավելությունները: Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks.  Դրանցից հինգ-ը մենք տրամադրեցինք անձնական գնահատման տվյալների համակարգեր, որպեսզի վստահենք մեր համեմատական նպատակի արդարությունը և ճշմարտությունը: We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels. Մեր սկզբնական փորձարկումները ցույց են տալիս, որ MTL մոդելները գերազանցում են իրենց առանձին վարժեցված հաշվարկները: Բայց ավելի լայն համայնքի մասնակցության մեջ մենք միայն հրատարակում ենք առանձին վարժեցված հիմքերը: Այնուամենայնիվ, մեր վերլուծությունը բացահայտում է, որ Արաբական ՆԼՄ-ում բավական տեղ կա զարգացման համար: Մենք հույս ունենք, որ ALAE-ը կօգնի մեր համայնքին հասկանալ այս բարելավումները: Interested researchersare invited to submit their results to our online,and publicly accessible leaderboard.', 'bs': 'Pojavljivanje modela multitask učenja (MTL) u posljednjih godina pomoglo je da nastavi stanje umjetnosti u prirodnom jeziku bez odvratnosti (NLU). Stvarno vjerujemo da su problemi sa NLU na arapskom posebno napravljeni da bi dobili koristi takvih modela. Za kraj svega predlažemo kritiku za bezodređenu evaluaciju arapskog jezika (ALUE), na osnovu 8 pažljivo odabranih i ranije objavljenih zadataka. Za pet od ovih, pružili smo privatne podatke o procjenama kako bi se uvjerili pravednost i validnost našeg kriterija. Također pružamo i dijagnostičku setu podataka za pomoć istraživačima da istražuju unutrašnje radnje njihovih modela. Naši prvi eksperimenti pokazuju da modeli MTL-a iznose svoje jedino obučene kolege na većinu zadataka. Ali, kako bismo uključili učešće iz šire zajednice, držali smo se objavljivanja jednostavno obučenog baselinesona. Ipak, naša analiza pokazuje da je ovdje dosta mjesta za poboljšanje na arapskom NLU. Nadamo se da će ALUE igrati dio pomoći našoj zajednici da shvati neke od ovih poboljšanja. Zanimljivi istraživači su pozvani da predaju svoj rezultat našoj internetu i javno dostupnim vodećim tablama.', 'az': 'Son il içində çoxlu işin öyrənməsi (MTL) modellərin təsiri təhsil edilməsinə kömək etdi. Biz ərəbcə NLU problemlərinin bu modellərin faydalarını qazanmaq üçün özlərinə müəyyən edildiyini güman edirik. Bütün bunların sonuna qədər ərəb dilini təklif edirik ki, əvvəlcə seçilmiş və daha öncə müəyyən edilmiş işlərə dayanan 8 nəfər təklif edilmişdir. Bunlardan beş nəfər üçün, müəyyən edilmiş tərzlərin düzgünlüyünü və dəyərliyini təsdiqlənmək üçün gizli tərzlərini təsdiqlədik. Biz də xəbərdarlıqlarının iç işlərini sınamaq üçün dijagnostik verilənlərin qurğunu təmin edirik. Əvvəlki təcrübələrimiz MTL modellərin çox işlərdə tək təcrübə edilmiş yoldaşlarını göstərir. Lakin böyük toplumdan iştirak etmək üçün təkcə təhsil edilmiş təhsil olaraq yayındırıq. Ancaq analizimiz belə göstərir ki, ərəb NLU-da yaxşılıq etmək üçün çox yer var. Biz ümid edirik ki, ALUE toplumumuza bu yaxşılıqların bir qismini anlamaq üçün bir parça oynayacaq. İlginçi araştırmacılar sonuçlarını internetə göndərmək üçün çağırılırlar.', 'cs': 'Vznik modelů víceúlohového učení (MTL) v posledních letech pomohl posunout stav umění v oblasti porozumění přírodního jazyka (NLU). Pevně jsme přesvědčeni, že mnoho problémů NLU v arabštině je především předpokládáno, že z těchto modelů bude těžit přínosy. Za tímto účelem navrhujeme referenční hodnocení arabského jazyka (ALUE), založený na osmi pečlivě vybraných a dříve publikovaných úkolech. Pro pět z nich poskytujeme nové soukromé hodnotící sady, které umožňují zajistit spravedlivost a platnost našeho benchmarku. Poskytujeme také diagnostický datový soubor, který výzkumníkům pomáhá zkoumat vnitřní fungování jejich modelů. Naše počáteční experimenty ukazují, že modely MTL při většině úkolů překonávají své jednotlivě trénované části. Abychom však mohli zapojit širší komunitu, zůstáváme u publikování jednotlivě vyškolených základně. Naše analýza nicméně ukazuje, že v arabské NLU existuje spousta prostoru pro zlepšení. Doufáme, že ALUE bude hrát podíl na pomoci naší komunitě realizovat některá z těchto zlepšení. Zájemci výzkumníci jsou vyzváni, aby předložili své výsledky do našeho online a veřejně přístupného žebříčku.', 'ca': "L'aparició de models d'aprenentatge multitasca (MTL) en els últims anys ha ajudat a impulsar l'estat d'art en la comprensió del llenguatge natural (NLU). Creiem fortament que molts problemes de la NLU en àrabestan especialment disposats a aprofitar els beneficis d'aquests models. Fins a aquest punt proposem el benchmark d'evaluació del llenguatge àrab (ALUE), basat en 8 tasques seleccionades i publicades previament. Per cinc d'aquests, vam proporcionar conjunts de dades d'evaluació privats per assegurar la justesa i la validez del nostre punt de referència. També proporcionem un conjunt de dades de diagnòsticper ajudar els investigadors a investigar el funcionament interior dels seus models. Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks.  Però per tal d'estimular la participació de la comunitat més ampla,ens mantenim a publicar les línies de base entrenades sols. Tot i així, la nostra anàlisi revela que hi ha molt espai per millorar a l'UEàrab. Esperem que ALUE participen en ajudar la nostra comunitat a concretizar algunes d'aquestes millors. Els investigadors interessats són convidatsde presentar els seus resultats a la nostra taula de lideratge on-line i accessible al públic.", 'et': 'Mitme ülesandega õppe mudelite esilekerkimine viimastel aastatel on aidanud tõsta looduskeele mõistmatuse kunsti taset. Usume kindlalt, et paljud araabia keelsed NLi probleemid on eriti suunatud sellistest mudelitest kasu saamiseks. Selleks pakume välja araabia keele eristamatu hindamise võrdlusnäitaja (ALUE), mis põhineb 8 hoolikalt valitud ja varasemalt avaldatud ülesandel. Viie neist esitame uued eravalduses olevad hindamisandmekogumid, et kindlustada oma võrdlusaluse õiglus ja kehtivus. Lisaks pakume diagnostilist andmekogumit, mis aitab teadlastel uurida oma mudelite sisemist toimimist. Meie esialgsed eksperimendid näitavad, et MTL mudelid suudavad enamikul ülesannetel üle oma üksiktreenitud maaosade. Kuid selleks, et laiemalt kogukonnalt osaleda, jääme me ainult üksikute väljaõppega baasjoonete avaldamise juurde. Sellegipoolest näitab meie analüüs, et araabia NLU-s on palju arenguruumi. Loodame, et ALUE aitab meie kogukonnal mõningaid neid parandusi realiseerida. Huvitatud teadlased kutsutakse esitama oma tulemused meie veebis ja avalikult kättesaadavale edetabelile.', 'fi': 'Monitehtäväoppimisen (MTL) mallien syntyminen viime vuosina on edistänyt luonnonkielen ymmärtämättömyyden (NLU) nykytaidetta. Uskomme vahvasti, että monet arabiankieliset NLU-ongelmat ovat erityisen valmiita hyötymään tällaisista malleista. Tämän vuoksi ehdotamme arabiankielisen arvioinnin vertailuarvoa (ALUE), joka perustuu kahdeksaan huolella valittuun ja aiemmin julkaistuun tehtävään. Näistä viidestä annamme uusia yksityisiä arviointiaineistoja, joilla varmistetaan vertailuarvomme oikeudenmukaisuus ja pätevyys. Tarjoamme myös diagnostisen aineiston, jonka avulla tutkijat voivat tutkia malliensa sisäistä toimintaa. Alustavat kokeemme osoittavat, että MTL-mallit suoriutuvat useimmissa tehtävissä paremmin kuin yksittäiset koulutetut maanosat. Laajemman yhteisön osallistumisen mahdollistamiseksi pidämme kuitenkin kiinni pelkästään yksittäiskoulutettujen peruslinjojen julkaisemisesta. Analyysimme osoittaa kuitenkin, että arabialaisessa NLUssa on paljon parantamisen varaa. Toivomme, että ALUE auttaa yhteisöämme toteuttamaan joitakin näistä parannuksista. Kiinnostuneita tutkijoita pyydetään toimittamaan tulokset verkossa ja julkisesti saatavilla olevaan tulostaulukkoomme.', 'sk': 'Pojav modelov večopravilnega učenja (MTL) v zadnjih letih je pripomogel k spodbujanju stanja umetnosti v naravnem jeziku. Trdno verjamemo, da so številni problemi NLP v arabskem jeziku zlasti pripravljeni izkoristiti prednosti takih modelov. V ta namen predlagamo referenčno vrednotenje arabskega jezika (ALUE), ki temelji na osmih skrbno izbranih in predhodno objavljenih nalogah. Za pet izmed njih zagotavljamo nove zasebne vrednotenjske nabore podatkov o oceni, da bi zagotovili pravičnost in veljavnost našega merila. Zagotavljamo tudi diagnostični nabor podatkov, ki raziskovalcem pomaga preiskovati notranje delovanje njihovih modelov. Naši prvotni poskusi kažejo, da modeli MTL pri večini nalog presegajo njihove posamezno usposobljene državne dele. Vendar se za udeležbo širše skupnosti držimo objavljanja samostojno usposobljenih osnovnih podatkov. Kljub temu naša analiza kaže, da je v arabskem NLU veliko prostora za izboljšave. Upamo, da bo ALUE pomagal naši skupnosti uresničiti nekatere od teh izboljšav. Zainteresirani raziskovalci so vabljeni, da svoje rezultate predložijo na naši spletni in javno dostopni lestvici.', 'bo': 'འཕྲལ་ཁམས་ཀྱི་སྣ་མང་བྱ་འགུལ་གྱི་མིག་ཆས་གསར་བརྗོད་པ་དེ་ཅིག་ཆགས་པ་ཡིན་པས། མ་ཤེས་པའི་སྒེར་གྱི་གནས་སྟངས་ལ་རང་བཞིན་པའི་སྐད་ར ང་ཚོས་རྒྱལ་ཁབ་ནང་གི་ཉེན་སྒྲིག་དབུགས་ཀྱི་དཀའ་ངལ tothe end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE), based on 8 carefully selected and previously published tasks. འདི་ལས་༥་ཀྱང་ང་ཚོས་རང་དབང་གིས་གསལ་བཤད་ཀྱི་ཚད་ལྟར་འཛིན་གྱི་ཡིག་ཆ་གསལ་བཤད་བྱས་མེད། ང་ཚོས་དབྱིབས་ཆ་འཕྲིན་ཡིག་ཆ་ཀྱང་བརྟག་ཞིབ་བྱེད་མཁན་གྱི་ནང་འཁོད་ཀྱི་ལས་ཀ་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་འགོ་འཛུགས་ཀྱི་བརྟག་ཞིག་ནི་MTL མིག་དཔེ་དབྱིབས་ཁོང་ཚོའི་གོ་སྐབས་ཀྱི་དབྱེ་བ་མང་ཆེ་བའི་ལས་ཀ་ལ་རྒྱུན་སྒྲིག འོན་ཀྱང་། ཆེ་ཆུང་བའི་ཚོགས་སྡེ་ནས་བྱེད་རྒྱུ་དང་། དེ་མིན་ནའང་ཡང་ ང་ཚོའི་དབྱེ་ཞིབ་དཔྱད་ནིས་འདིའི་ནང་གི་སྐྱོན་བརྗོད་ཀྱི་ཁང་ཆེ་བའི་རེ་བ་ཡོད། ང་ཚོས་རྒྱལ་ཁབ་ལ་ཚོགས་ཚོགས་སྤྱི་ཚོགས་ཀྱི་ཁ་གཏད་ཁྲོད་ཀྱི་ཆ་ཤས་ཞིག་རྩེ་རོགས་བྱེད་དགོས། འཛམ་གླིང་སྐོར་གྱི་འཚོལ་ཞིབ་ལ་ཁོང་ཚོའི་གྲུབ་འབྲས་འདི་ང་ཚོའི་དྲ་རྒྱའི་ཐོག་ཏུ་སྐྱེལ་ཞིབ་བྱེད་ཀྱི་ཡོད', 'jv': 'Menu item to Open \'Search for Open Files\' dialog Awak dhéwé isih luwih-luwih Kasunyatan barêng-luwih ingkang NLU kuwi kesempatan kanggo nggawe barang mangan kuwi model kuwi. To-do end we proposal the Hebrew Language un-derstaying invaluation Bench (AlUE), supported on 8 Carely selected and preview tasks. Saiki lima iki, kita ngomong pengguna perusahaan dataset kejahatan kanggo nganggo perusahaan karo hal-hal sing nyimpen banget kanggo ngilanggar sampek. Awak dhéwé éntuk data yang dipunangé kanggo sabanjuré nglanggar aturan pangan kanggo ngilanggar oleh dumadhi kanggo maneh Kita perbudhakan anyari sampeyan anyar mên ngerasakno dadi MTL Wis kanggo ngilangno sistem sing wis nguasai nggo populer sing gak bukane, awak dhéwé wis nguasai sing ngerasai sing luwih apik. Nanging, akeh panjenengan ngerasakno ngono cah akeh dumadhi kanggo nyerampun kanggo nggawe barang arap NLU . Awak dhéwé ngerti "KELUE" nganggep ngejaraké ning bantêpakan ning sampeyan kita ngubah piye cara sing luwih apik nyeramé iki. Jejaring', 'ha': "Bayan fitarwa na masu amfani da multi-aikin aiki (MTL) motsalar na farko cikin shekara na ƙarshe sun taimake su gabatar da state of the art in Natural language Un-der-state (NLU). Ina amince da yawa cewa mataimako na NLU na Larabci za'a sami amfani da misãlai. Daga wannan, Munã buɗar da aikin Lãrabci na Babbar da Bagaske Hakima na Larabci (AIUU), a kan karatun 8 carely selected and gaban da aka bayyana aiki. Ga shan daga waɗannan, muna gajiya danne masu ƙidãya a kanana zuwa ga tabbacin gaskiya da gaskiyar bangonmu. Kayya, Munã samar da data masu diagnoni don su iya taimakon watani su sami aikin aiki na guda. Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks.  Amma kuma dõmin a sami shirin ciki daga jamii mafi girma, sai muna ƙara da za'a yi bayani kawai da aka sanar. A lokacin da analyyinmu ya bayyana cewa, wannan yana da ma'auni mai yawa wa improve a cikin NLU na Larabci. Munã kwaɗayin cẽwa AUU zai yi rabo da rabo a kan taimakon jamiyarmu su gane wani abu daga mafarinta. Ina kira watan da ke da amfani zuwa matsalarsu zuwa kanmu, da kuma a sami gaba ga shaidarmu da ake samu.", 'he': 'The emergence of Multi-task learning (MTL)models in recent years has helped push thestate of the art in Natural Language Un-derstanding (NLU).  We strongly believe thatmany NLU problems in Arabic are especiallypoised to reap the benefits of such models.  Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks.  עבור חמישה מאלה, סיפקנו קבוצות נתונים בערכת הערכה פרטית כדי לוודא את הוגנות וקבלות המרמז שלנו. We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels. Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks.  But in order to en-tice participation from the wider community,we stick to publishing singly trained baselinesonly.  Nonetheless, our analysis reveals thatthere is plenty of room for improvement inArabic NLU.  We hope that ALUE will playa part in helping our community realize someof these improvements.  Interested researchersare invited to submit their results to our online,and publicly accessible leaderboard.'}
{'en': 'Quranic Verses Semantic Relatedness Using AraBERT', 'pt': 'Versos do Alcorão Relação Semântica Usando AraBERT', 'es': 'Versos coránicos Relación semántica usando AraBert', 'fr': "Versets coraniques Relation sémantique à l'aide d'AraBert", 'ar': 'آيات قرآنية ارتباط دلالي باستخدام أرابرت', 'ja': 'AraBERTを使用したクルアーンの節の意味的関連性', 'zh': '古兰经文 语义相关 用AraBERT', 'ru': 'Коранические стихи Семантическая родственность с помощью AraBERT', 'hi': 'कुरान की आयतें AraBERT का उपयोग कर शब्दार्थ संबंधितता', 'ga': 'Véarsaí Quranic Gaolmhaireacht Shéimeantach Ag Úsáid AraBERT', 'ka': 'კურანიკური გერსები სემანტიკური დაკავშირება AraBERT გამოყენება', 'it': 'Correlazione semantica usando AraBERT', 'kk': 'АраBERT қолданылатын кураникалық нұсқалар Semantic Relatedness', 'el': 'Κορανικοί στίχοι Σημαντική Σχέση Χρησιμοποιώντας το AraBERT', 'hu': 'Korán versek Szemantikus kapcsolat az AraBERT használatával', 'mk': 'Куранска верзија семантична врска користејќи AraBERT', 'lt': 'Koranijos versijos Semantinis ryšys AraBERT vartojimu', 'ml': 'അരാബെര്\u200dട്ട് ഉപയോഗിക്കുന്ന കുരാനിക് വചനങ്ങള്\u200d സെമാന്റിക് ബന്ധങ്ങള്\u200d', 'mn': 'Кораник хэлбэрүүд АраBERT-г ашиглаж', 'mt': 'Relazzjoni Semantika tal-Verżjonijiet Koraniċi bl-użu ta’ AraBERT', 'no': 'Koraniske versjonar semantisk relasjon ved bruk av AraBERT', 'ms': 'Hubungan Semantik Versi Quranik menggunakan AraBERT', 'pl': 'Korańskie wersety semantyczne związek przy użyciu AraBERT', 'ro': 'Versetele Coranice Relația semantică folosind AraBERT', 'sr': 'Koraničke verzije semantična povezanost koristeći AraBERT', 'si': 'කුරානික් වර්ස් සෙමාන්තික සම්බන්ධතාවය AraBERT භාවිත කරන්න', 'so': 'Aayaadkii quraanka ee isticmaalka xarafta Quraanka', 'sv': 'Koranska Verser Semantisk Relation med AraBERT', 'ta': 'அராபெர்ட் பயன்படுத்தும் குர்னிக் தெளிவான தெரிவுகள்', 'ur': 'قرنیک آیتیں سیمنٹی نسبت', 'vi': 'Quranic thơ cục liên của Semantic Sử dụng AraBERT', 'uz': 'QFontDatabase', 'bg': 'Коранически стихове Семантична връзка с използването на AraBERT', 'nl': 'Koranversen Semantische Verwantheid Gebruikend AraBERT', 'hr': 'Koraničke verzije semantička povezanost s korištenjem AraBERT', 'da': 'Koranske vers Semantisk forbindelse ved hjælp af AraBERT', 'de': 'Koranverse Semantische Verwandtschaft mit AraBERT', 'fa': 'Versions Quranic Semantic Relationship Using AraBERT', 'id': 'Hubungan Semantik Versi Quranik Menggunakan AraBERT', 'ko': '아랍트의 코란경 시구의 의미 관련 사용', 'tr': 'AraBERT Using Quranic Verses Semantic Relatedness', 'sw': 'Quranic Verses Semantic Relatedness Using AraBERT', 'af': 'Koraniese Versies Semantiese Relatiteit gebruik AraBERT', 'sq': 'Verset koranike lidhje Semantike duke përdorur AraBERT', 'am': 'የዐረቢብ ተግባር', 'hy': 'Օգտագործելով ARABERT', 'az': 'AraBERT vasit톛sil톛 Quran ay톛l톛ri', 'bn': 'আরাবেরেট ব্যবহার করে কোরানিক আয়াতসমূহ সেমান্টিক সম্পর্ক', 'bs': 'Koraničke verzije semantične povezanosti koristeći AraBERT', 'ca': 'Relació Semàtica Versos Corànics amb AraBERT', 'et': 'Koraani salmid Semantiline seos AraBERT kasutamisega', 'cs': 'Koránské verše Sémantická souvislost pomocí AraBERT', 'fi': 'Koraanijakeet Semanttinen yhteys AraBERTin avulla', 'jv': 'Versi Kjaran semanti Relatidness Using araBERT', 'sk': 'Koranični verzi Semantična povezanost z uporabo AraBERT', 'ha': "ãyõyin Alƙur'ãni ne Semantic Relative", 'he': 'יחסים סמנטיים קוראניים בשימוש באראברט', 'bo': 'Quranic Verses Semantic Relatedness Using AraBERT'}
{'en': 'Bidirectional Encoder Representations from Transformers (BERT) has gained popularity in recent years producing state-of-the-art performances across Natural Language Processing tasks. In this paper, we used AraBERT language model to classify pairs of verses provided by the QurSim dataset to either be semantically related or not. We have pre-processed The QurSim dataset and formed three datasets for comparisons. Also, we have used both versions of AraBERT, which are AraBERTv02 and AraBERTv2, to recognise which version performs the best with the given datasets. The best results was AraBERTv02 with 92 % accuracy score using a dataset comprised of label ‘2’ and label’ -1’, the latter was generated outside of QurSim dataset.', 'ar': 'اكتسبت تمثيلات التشفير ثنائية الاتجاه من المحولات (BERT) شعبية في السنوات الأخيرة لإنتاج أحدث العروض عبر مهام معالجة اللغة الطبيعية. في هذا البحث ، استخدمنا نموذج لغة AraBERT لتصنيف أزواج الآيات التي توفرها مجموعة بيانات KorSim لتكون إما مرتبطة معنويًا أو لا. لقد عالجنا مجموعة بيانات KorSim مسبقًا وشكلنا ثلاث مجموعات بيانات لإجراء المقارنات. أيضًا ، استخدمنا كلا الإصدارين من AraBERT ، وهما AraBERTv02 و AraBERTv2 ، للتعرف على الإصدار الأفضل أداءً مع مجموعات البيانات المحددة. كانت أفضل النتائج هي AraBERTv02 بنسبة دقة 92٪ باستخدام مجموعة بيانات تتألف من الملصق "2" والتسمية "-1" ، وقد تم إنشاء الأخير خارج مجموعة بيانات QurSim.', 'fr': "Les représentations d'encodeur bidirectionnelles provenant de transformateurs (BERT) ont gagné en popularité ces dernières années, produisant des performances de pointe pour les tâches de traitement du langage naturel Dans cet article, nous avons utilisé le modèle de langage AraBert pour classer des paires de versets fournis par le jeu de données QurSim afin qu'ils soient sémantiquement liés ou non. Nous avons prétraité l'ensemble de données QurSim et formé trois ensembles de données à des fins de comparaison. Nous avons également utilisé les deux versions d'ArabErt, AraberTV02 et AraberTV2, pour identifier la version qui fonctionne le mieux avec les ensembles de données donnés. Les meilleurs résultats ont été AraberTV02 avec un score de précision de 92\xa0% en utilisant un ensemble de données composé de l'étiquette «\xa02\xa0» et de l'étiquette «\xa0-1\xa0», cette dernière ayant été générée en dehors de l'ensemble de données QurSim.", 'pt': "As representações de codificador bidirecional de transformadores (BERT) ganharam popularidade nos últimos anos, produzindo desempenhos de última geração em tarefas de processamento de linguagem natural. Neste artigo, usamos o modelo de linguagem AraBERT para classificar pares de versos fornecidos pelo conjunto de dados QurSim para serem semanticamente relacionados ou não. Pré-processamos o conjunto de dados do QurSim e formamos três conjuntos de dados para comparações. Além disso, usamos as duas versões do AraBERT, que são AraBERTv02 e AraBERTv2, para reconhecer qual versão tem o melhor desempenho com os conjuntos de dados fornecidos. Os melhores resultados foram AraBERTv02 com pontuação de precisão de 92% usando um conjunto de dados composto de rótulo '2' e rótulo '-1', este último foi gerado fora do conjunto de dados QurSim.", 'es': "Bidirectional Encoder Representations from Transformers (BERT) ha ganado popularidad en los últimos años al producir actuaciones de vanguardia en tareas de procesamiento de lenguaje natural. En este artículo, utilizamos el modelo de lenguaje araBert para clasificar los pares de versos proporcionados por el conjunto de datos QurSim para que estén relacionados semánticamente o no. Hemos procesado previamente el conjunto de datos de QurSim y hemos formado tres conjuntos de datos para realizar comparaciones. Además, hemos utilizado ambas versiones de araBert, que son ArabertV02 y ArabertV2, para reconocer qué versión funciona mejor con los conjuntos de datos dados. Los mejores resultados fueron ArabertV02 con una puntuación de precisión del 92% utilizando un conjunto de datos compuesto por la etiqueta `2' y la etiqueta '-1', esta última se generó fuera del conjunto de datos de QurSim.", 'zh': '近年以来,Transformers(BERT)双向编码器表示法益受欢迎,自然语言事最先进。 本文,用AraBERT语模将QurSim数集经文对分类为语义相关或不相关。 余预处理《古兰经》数据集,并为三集较之。 用二版之AraBERT,AraBERTv02AraBERTv2,以识给定数为最。 太上AraBERTv02,2、-1数集,准确度分为92%,后生于QurSim之外。', 'ja': 'トランスフォーマーからの双方向エンコーダ表現（ BERT ）は、近年人気を博し、自然言語処理タスク全体で最先端のパフォーマンスを生み出しています。この論文では、AraBERT言語モデルを使用して、QurSimデータセットによって提供される節のペアを意味的に関連しているか否かのいずれかに分類した。私たちは、QurSimデータセットを前処理し、比較のための3つのデータセットを形成しました。また、AraBERTの両方のバージョン（ AraBERTv 02とAraBERTv 2 ）を使用して、どのバージョンが指定されたデータセットで最高のパフォーマンスを発揮するかを認識しました。最良の結果は、ラベル「2」およびラベル「-1」からなるデータセットを使用して92%の精度スコアでAraBERTv 02であり、後者はQurSimデータセット外で生成された。', 'ru': 'Двунаправленные представления кодировщика от Transformers (BERT) приобрели популярность в последние годы, производя самые современные характеристики для задач обработки на естественном языке. В этой статье мы использовали языковую модель AraBERT для классификации пар стихов, предоставленных набором данных QurSim, как семантически связанных или нет. Мы предварительно обработали набор данных QurSim и сформировали три набора данных для сравнения. Кроме того, мы использовали обе версии AraBERT, а именно AraBERTv02 и AraBERTv2, чтобы определить, какая версия лучше всего работает с указанными наборами данных. Наилучшими результатами был AraBERTv02 с показателем точности 92% с использованием набора данных, состоящего из метки «2» и метки «-1», последний был создан за пределами набора данных QurSim.', 'hi': "ट्रांसफॉर्मर (BERT) से द्विदिश एन्कोडर प्रतिनिधित्व ने हाल के वर्षों में प्राकृतिक भाषा प्रसंस्करण कार्यों में अत्याधुनिक प्रदर्शन का उत्पादन करने के लिए लोकप्रियता हासिल की है। इस पेपर में, हमने कुरानसिम डेटासेट द्वारा प्रदान किए गए छंदों के जोड़े को वर्गीकृत करने के लिए अराबर्ट भाषा मॉडल का उपयोग किया, या तो शब्दार्थ से संबंधित होने या नहीं। हमने कुरान डेटासेट को पूर्व-संसाधित किया है और तुलना के लिए तीन डेटासेट का गठन किया है। इसके अलावा, हमने AraBERT के दोनों संस्करणों का उपयोग किया है, जो AraBERTv02 और AraBERTv2 हैं, यह पहचानने के लिए कि कौन सा संस्करण दिए गए डेटासेट के साथ सबसे अच्छा प्रदर्शन करता है। सबसे अच्छा परिणाम AraBERTv02 था जिसमें लेबल '2' और लेबल '-1' शामिल डेटासेट का उपयोग करके 92% सटीकता स्कोर था, उत्तरार्द्ध कुरान डेटासेट के बाहर उत्पन्न हुआ था।", 'ga': "Tá an-tóir ar Léirithe Ionchódóra Déthreo ó Transformers (BERT) le blianta beaga anuas ag táirgeadh léirithe den scoth thar thascanna Próiseála Teanga Nádúrtha. Sa pháipéar seo, d’úsáideamar múnla teanga AraBERT chun péirí véarsaí a chuir tacar sonraí QurSim ar fáil a rangú le bheith gaolmhar nó gan a bheith gaolmhar. Rinneamar tacar sonraí The QurSim a réamhphróiseáil agus rinneamar trí thacar sonraí le haghaidh comparáidí. Chomh maith leis sin, d'úsáideamar an dá leagan de AraBERT, is iad sin AraBERTv02 agus AraBERTv2, chun a aithint cén leagan is fearr a fheidhmíonn leis na tacair shonraí a tugadh. Ba iad AraBERTv02 na torthaí ab fhearr le scór cruinnis 92% ag baint úsáide as tacar sonraí a bhí comhdhéanta de lipéad `2' agus lipéad '-1', gineadh an dara ceann lasmuigh de thacar sonraí QurSim.", 'ka': "ორდირექციონალური ინფორმაციის რესპენტერესტი ტრანფორმაციებიდან (BERT) უკვე წლის განმავლობაში პოლუგარიტება მიიღეთ, რომელიც წარმოიდგინეთ მონაცემები წარმოდგინეთ ნახვა ამ კაურაში, ჩვენ გამოყენეთ აპაბერტის ენის მოდელს კლასიფიკაციისთვის კურსიმიმის მონაცემების კონფიკაციის კონფიკაციის კონფიკაციის კონფიკაციაში, ან სმენტიკურად ჩვენ კურსიმის მონაცემების შესახებ გადაწყვეტა და შემდეგ სამი მონაცემების შესახებ გადაწყვეტა. ასევე, ჩვენ გამოყენეთ ორივე ვერსიები AraBERT, რომლებიც AraBERTv02 და AraBERTv2, რომ განვიცნოთ, რომელიც ვერსია უკეთესი მონაცემებით მონაცემებით გამოყენებს. ყველაზე საუკეთესო შედეგი იყო AraBERTv02, 92% მართლა მონაცემების შესაძლებელად მონაცემების კონფიგურაცია, რომელიც `2' და etiket '-1' დაყენებულია.", 'hu': "A transzformátorok kétirányú kódolói reprezentációi (BERT) az elmúlt években népszerűvé váltak, amelyek korszerű teljesítményeket eredményeznek a természetes nyelvfeldolgozási feladatokban. Ebben a tanulmányban AraBERT nyelvi modellt használtunk arra, hogy a QurSim adatkészlet által biztosított versek párjait szemantikailag összefüggésbe hozzuk vagy sem. Előre feldolgoztuk a QurSim adatkészletet, és három adatkészletet alakítottunk összehasonlításra. Az AraBERT mindkét verzióját használtuk, amelyek AraBERTv02 és AraBERTv2, hogy felismerjük, melyik verzió teljesíti a legjobban az adott adatkészletekkel. A legjobb eredmény az AraBERTv02 volt 92%-os pontossági pontszámmal, a `2' címkéből és a `1' címkéből álló adatkészlet használatával, amely utóbbit a QurSim adatkészleten kívül generálták.", 'it': "Le rappresentazioni bidirezionali di encoder da trasformatori (BERT) hanno guadagnato popolarità negli ultimi anni producendo prestazioni all'avanguardia in tutte le attività di elaborazione del linguaggio naturale. In questo articolo, abbiamo usato il modello del linguaggio AraBERT per classificare coppie di versetti forniti dal dataset QurSim per essere semanticamente correlati o meno. Abbiamo pre-elaborato il set di dati QurSim e formato tre set di dati per il confronto. Inoltre, abbiamo utilizzato entrambe le versioni di AraBERT, che sono AraBERTv02 e AraBERTv2, per riconoscere quale versione funziona meglio con i set di dati forniti. I risultati migliori sono stati AraBERTv02 con un punteggio di precisione del 92% utilizzando un set di dati composto da etichetta `2' e etichetta '-1', quest'ultima è stata generata al di fuori del set di dati QurSim.", 'lt': 'Pastaraisiais metais dvikrypčių kodų atstovybės iš transformatorių (BERT) tapo populiaresnės, nes gamtinės kalbos perdirbimo užduotys sukūrė pažangiausius rezultatus. Šiame dokumente naudojome AraBERT kalbos model į, kad klasifikuotume QurSim duomenų rinkinio pateiktų verčių poras, kad jos būtų arba semantiškai susijusios, arba ne. Mes iš anksto apdorojome QurSim duomenų rinkinį ir sukūrėme tris palyginimo duomenų rinkinius. Be to, mes naudojome abi AraBERT versijas, kurios yra AraBERTv02 ir AraBERTv2, kad pripažintume, kuri versija geriausiai veikia su konkrečiais duomenų rinkiniais. Geriausi rezultatai buvo AraBERTv02 su 92 % tikslumu, naudojant duomenų rinkinį, sudarytą iš etiketės „2“ ir etiketės „1“, pastaroji buvo sukurta ne QurSim duomenų rinkinyje.', 'el': "Οι αμφίδρομες αναπαραστάσεις κωδικοποιητών από μετασχηματιστές (BERT) έχουν κερδίσει δημοτικότητα τα τελευταία χρόνια, παρέχοντας παραστάσεις τελευταίας τεχνολογίας σε όλες τις εργασίες επεξεργασίας φυσικής γλώσσας. Σε αυτή την εργασία, χρησιμοποιήσαμε γλωσσικό μοντέλο για να ταξινομήσουμε ζεύγη στίχων που παρέχονται από το σύνολο δεδομένων του QurSim είτε να σχετίζονται σημασιολογικά είτε όχι. Έχουμε προ-επεξεργαστεί το σύνολο δεδομένων QurSim και διαμορφώσει τρία σύνολα δεδομένων για συγκρίσεις. Επίσης, έχουμε χρησιμοποιήσει και τις δύο εκδόσεις του AraBERT, οι οποίες είναι AraBERTv02 και AraBERTv2, για να αναγνωρίσουμε ποια έκδοση αποδίδει καλύτερα με τα δεδομένα σύνολα δεδομένων. Τα καλύτερα αποτελέσματα ήταν το AraBERTv02 με βαθμολογία ακρίβειας 92% χρησιμοποιώντας ένα σύνολο δεδομένων που αποτελείται από ετικέτα `2' και ετικέτα '-1', το τελευταίο δημιουργήθηκε εκτός του συνόλου δεδομένων QurSim.", 'ms': "Perwakilan Pengekod Dua Arah dari Penukar (BERT) telah memperoleh popularitas dalam tahun-tahun terakhir menghasilkan penampilan terbaik di seluruh tugas Pemprosesan Bahasa Semulajadi. Dalam kertas ini, kami menggunakan model bahasa AraBERT untuk mengklasifikasikan pasangan ayat yang diberikan oleh set data QurSim sama ada berkaitan semantik atau tidak. Kami telah memproses set data QurSim dan membentuk tiga set data untuk perbandingan. Juga, kami telah menggunakan kedua-dua versi AraBERT, yang adalah AraBERTv02 dan AraBERTv2, untuk mengenali versi mana yang lebih baik dengan set data yang diberikan. The best results was AraBERTv02 with 92% accuracy score using a dataset comprised of label `2' and label '-1', the latter was generated outside of QurSim dataset.", 'kk': "Түрлендірушілерден (BERT) екі бағытты кодтардың таңбалары соңғы жылдарда таңбалардың күй- жағдайлығын Түрлі тіл процессорындағы тапсырмалардың күй- жағдайлығын жасап береді. Бұл қағаздың араBERT тіл үлгісін QuraSim деректер қорларының бірнеше нұсқаларын салыстыру үшін қолдандық. Біз QuraSim деректер жинағын алдын- ала өзгертіп, салыстыру үшін үш деректер жинағын жасадық. Сонымен қатар, AraBERT және AraBERTv2 нұсқаларының екі нұсқасын қолдандық. Бұл AraBERTv02 және AraBERTv2, келтірілген деректер жиындарының қай нұсқасының ең жақсы орындалатын нұс Ең жақсы нәтижелер - AraBERTv02, 92% деген дұрыс нәтижелері '- 2' және '- 1' деген белгілерден қолданатын деректер жиынын қолдану үшін, соңғылар QurSim деректер жиының сыртында құрылды.", 'mt': "Rappreżentazzjonijiet Bidirezzjonali tal-Kodifikaturi mit-Trasformaturi (BERT) kisbu popolarità f’dawn l-aħħar snin li pproduċew prestazzjonijiet l-aktar avvanzati fil-kompiti tal-ipproċessar tal-lingwi naturali. F’dan id-dokument, użajna mudell tal-lingwa AraBERT biex nikklassifikaw pari ta’ verżi pprovduti mis-sett tad-dejta QurSim biex jew ikunu relatati semantikament jew le. Ipproċessajna minn qabel is-sett tad-dejta tal-QurSim u ffurmawna tliet settijiet tad-dejta għat-tqabbil. Barra minn hekk, użajna ż-żewġ verżjonijiet ta’ AraBERT, li huma AraBERTv02 u AraBERTv2, biex irrikonoxxu liema verżjoni tagħmel l-aħjar bis-settijiet ta’ dejta mogħtija. L-a ħjar riżultati kienu AraBERTv02 b'punteġġ ta' preċiżjoni ta' 92% bl-użu ta' sett ta' dejta magħmul mit-tikketta `2' u t-tikketta '-1', dan tal-aħħar ġie ġġenerat barra s-sett ta' dejta QurSim.", 'mk': "Бидирекционалните презентации на кодирачите од Трансформерите (БЕРТ) во последниве години ја добија популарноста, произведувајќи најсовремени изведби низ задачите за процес на природен јазик. Во овој весник, го употребивме јазичкиот модел на АраБЕРТ за да класификуваме парови верзи обезбедени од компјутерот на податоци QurSim за да бидат семантично поврзани или не. Препроцесиравме податоци од QurSim и формиравме три податоци за споредба. Исто така, ги употребивме двете верзии на AraBERT, кои се AraBERTv02 и AraBERTv2, за да признаеме која верзија е најдобра со дадените податоци. The best results was AraBERTv02 with 92% accuracy score using a dataset comprised of label `2' and label '-1', the latter was generated outside of QurSim dataset.", 'mn': "Өнгөрсөн жилүүдийн хоёр чиглэлийн кодчуудын төлөөлөлт нь Байгалийн хэл Процессорын үйл ажиллагаанд байдал болон урлагийн үйл ажиллагааг бүтээж байна. Энэ цаасан дээр бид Араберт хэл загварыг ашиглаж, Курсим өгөгдлийн сангийн хоёр хэлбэрүүдийг нэг хэлбэрээр холбоотой эсвэл холбоотой хэлбэрээр хуваалцахын тулд ашигласан. Бид QuraSim өгөгдлийн санг өмнө судалж, харьцуулахын тулд гурван өгөгдлийн санг бүтээсэн. Мөн бид AraBERT-ын хоёр хувилбарыг ашигласан. AraBERTv02 болон AraBERTv2, өгөгдлийн сангийн хамгийн сайн хувилбарыг мэдэх тулд. Хамгийн сайн үр дүнг нь AraBERTv02, 92% нь тодорхой тооны оноо бөгөөд `2' болон '-1' label гэх өгөгдлийн санг ашиглаж байсан бөгөөд хамгийн сүүлийн нь QurSim өгөгдлийн сангийн гадна үүсгэгдсэн.", 'ml': "Bidirectional Encoder Representations from Transformers (BERT) has gained popularity in recent years producing state-of-the-art performances across Natural Language Processing tasks.  ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d അരാബെര്\u200dട്ടി ഭാഷ മോഡല്\u200d ഉപയോഗിച്ചു കുര്\u200dസിമിലെ ഡാറ്റാസറ്റ് നല്\u200dകിയ ചില ദൃഷ്ടാന്തങ്ങള്\u200d വിഭാഗമാക്കാ നമ്മള്\u200d കുര്\u200dസിമിലെ ഡാറ്റാസെറ്റ് മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിച്ചിട്ടുണ്ട് താല്\u200dക്കാലികമായി മൂന്ന ഞങ്ങള്\u200d രണ്ട് അരാബെര്\u200dട്ടിയുടെയും അരാബെര്\u200dട്ടിവി02 എന്ന അരാബെര്\u200dട്ടിട്ടുവിന്റെയും പതിപ്പുകളും ഉപയോഗിച്ചിരിക്കുന്നു. കൊടുത്ത വിവ ഏറ്റവും നല്ല ഫലങ്ങള്\u200d അരാബെര്\u200dട്ടിട്ടുവില്\u200d 92% കൃത്യമായ സ്കോര്\u200d ഉപയോഗിച്ച് `2' എന്ന ലേബറ്റും ലേബറ്റും '- 1' ഉപയോഗിച്ചുള്ള ഡാറ്റാസെറ്റുമു", 'no': 'Bidirektionale koderingsrepresentasjonar frå transformatorar (BERT) har fått popularitet i løpet av siste år som produserer tilstanden av kunsten over naturspråk-handteringsoppgåver. I denne papiret brukte vi AraBERT språk-modellen for å klassifisera par versjonar som er tilgjengelege av QurSim-datasettet som enten er semantisk relatert eller ikkje. Vi har forhandsama KurSim-datasettet og laga tre datasett for sammenlikningar. Vi har også brukt begge versjonar av AraBERT, som er AraBERTv02 og AraBERTv2, for å gjenkjenne kva versjon utfører best med dei gitte datasettene. Den beste resultatene var AraBERTv02 med 92% nøyaktighetspoeng ved å bruka eit datasett med merkelapp « 2 » og merkelapp « - 1 », den siste vart laga utenfor QurSim- datasettet.', 'sr': "Predstavi za dvosmjerno kodiranje transformatora (BERT) dobili su popularnost u poslednjih godina, proizvodeći predstave state-of-the-art preko zadataka prirodnog procesa jezika. U ovom papiru, koristili smo model AraBERT jezika kako bi klasifikovali par stihova koje je donela QurSim podaci da su ili semantički povezani ili ne. Preobradili smo podatke Kursima i formirali tri podatke za usporedbu. Takođe, koristili smo obe verzije AraBERT, koje su AraBERTv02 i AraBERTv2, kako bi prepoznali koja verzija najbolje izvršava sa određenim setima podataka. Najbolji rezultat je bio AraBERTv02 sa 92% tačnim rezultatima korištenjem seta podataka sastavljenog od etikete `2' i etikete '-1', poslednji je stvoren izvan sete podataka KurSima.", 'pl': "Reprezentacje koderów dwukierunkowych z transformatorów (BERT) zyskały popularność w ostatnich latach produkując najnowocześniejsze wykonania w zakresie zadań przetwarzania języka naturalnego. W niniejszym artykule użyliśmy modelu językowego AraBERT do klasyfikacji par wersetów dostarczonych przez zbiór danych QurSim jako związanych semantycznie lub nie. Przetworzyliśmy wstępnie zbiór danych QurSim i utworzyliśmy trzy zbiory danych do porównania. Użyliśmy również obu wersji AraBERT, czyli AraBERTv02 i AraBERTv2, aby rozpoznać, która wersja działa najlepiej z danymi zbiorami danych. Najlepszym wynikiem był AraBERTv02 z wynikiem dokładności 92% przy użyciu zbioru danych składającego się z etykiety `2' i etykiety '-1', która została generowana poza zbiorem danych QurSim.", 'ro': "Reprezentările codificatoarelor bidirecționale de la transformatori (BERT) au câștigat popularitate în ultimii ani, producând performanțe de ultimă oră în cadrul sarcinilor de procesare a limbajului natural. În această lucrare, am folosit modelul limbajului AraBERT pentru a clasifica perechile de versete furnizate de setul de date QurSim ca fie legate semantic sau nu. Am pre-procesat setul de date QurSim și am format trei seturi de date pentru comparații. De asemenea, am folosit ambele versiuni ale AraBERT, care sunt AraBERTv02 și AraBERTv2, pentru a recunoaște care versiune performează cel mai bine cu seturile de date date date date date. Cele mai bune rezultate au fost AraBERTv02 cu un scor de precizie de 92% folosind un set de date format din eticheta `2' și eticheta '-1', aceasta din urmă fiind generată în afara setului de date QurSim.", 'si': 'අන්තිම අවුරුද්දු වලින් දෙවෙනි ප්\u200dරධාන කෝඩාර් ප්\u200dරධානය (BERT) වලින් ප්\u200dරධානයක් ලැබුනා ස්ථානික භාෂාව ප්\u200dරධානය කර මේ පත්තරේ අපි අරාබෙර්ට් භාෂාව මොඩල් භාවිතා කරලා කුර්සිම් දත්ත සෙට් එක්ක ප්\u200dරවේශනය කරලා තියෙන්නේ කුර්සිම්  අපිට කුර්සිම් දත්ත සෙට් වැඩ කරලා තියෙනවා ඒ වගේම දත්ත සෙට් තුනක් හදලා තියෙනවා. ඒවගේම, අපි AraBERT ගේ දෙන්නම සංවිධානය භාවිත කරලා තියෙනවා, AraBERTv02 සහ AraBERTv2, දෙන්න තොරතුරු සේට් එක්ක හොඳම සංවිධානය ක හොඳම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'sv': "Bidirectional Encoder Representations from Transformers (BERT) har vunnit popularitet de senaste åren och skapat toppmoderna prestanda inom Natural Language Processing-uppgifter. I denna uppsats använde vi AraBERT språkmodell för att klassificera par verser som tillhandahålls av QurSim datauppsättningen för att antingen vara semantiskt relaterade eller inte. Vi har förbehandlat The QurSim dataset och skapat tre dataset för jämförelser. Dessutom har vi använt båda versionerna av AraBERT, som är AraBERTv02 och AraBERTv2, för att känna igen vilken version som presterar bäst med de givna datauppsättningarna. Det bästa resultatet var AraBERTv02 med 92% noggrannhetspoäng med hjälp av en datauppsättning bestående av etiketten `2' och etiketten '-1', den senare genererades utanför QurSim dataset.", 'so': "Qodeynta midowga ah ee ka soo jeeda Transformers (BERT) waxay gaadhay popular ugu dambeysay sanadkii ugu dambeeyey oo soo bandhigay shaqooyin la xiriira farshaxanta afka asalka ah oo dhan. Kanu warqaddan ayaan u isticmaalnay Tusaale luqada AraBERT si aan u kala qaybsanno calaamado noocyo ah oo lagu soo qoray taariikhda Quruum si ay u xidhiidhaan ama aan u ahayn. Waxaannu horay u baaraandeynay kooxda macluumaadka ee QurSim, waxaana sameynay saddex databases oo u eg tusaale ahaan. Sidoo kale waxaan u isticmaalnay labada warqadood oo AraBERTv02 iyo AraBERTv2 si aan u ogaano tilmaamaha uu ugu wanaagsan sameynayo sawirada la siiyey. ArBERTv02 waxaa ugu wanaagsanaan fasax 92% oo saxda ah isticmaalaya saxda macluumaadka oo lagu qoray calaamadda `2' iyo '-1', asalkii dambena waxaa laga abuurey dibadda ka baxsan xarunta macluumaadka QurSim.", 'ta': "மாற்றுபவர் In this paper, we used AraBERT language model to classify pairs of verses provided by the QurSim dataset to either be semantically related or not.  நாங்கள் முன் செயல்படுத்தப்பட்ட குர்சிம் தரவுத்தளத்தை ஒப்பீடுகளுக்கு உருவாக்கி மூன்று தரவுத்தளங AraBERTv02 மற்றும் AraBERTv2 இரு பதிப்புகளையும் நாம் பயன்படுத்தி கொடுக்கப்பட்ட தகவல் அமைப்புகளுடன் சிறந்த பதிப்புகளை அறிந்து கொள்ளும். சிறந்த முடிவுகள் ஆர்பெர்டிவி02, 92% சரியான மதிப்பெண்ணுடன் '2' மற்றும் '1' விளக்கச் சீட்டு குர்சிம் தரவுத்தளத்தின் வெளியே உருவாக்கப்", 'ur': "ٹرانسفورٹ (BERT) سے دوسری دئیرسیٹ کیونڈر کی نمایش اگلوں سالوں میں بہترین نمایش حاصل کی گئی ہے جو طبیعی زبان پرینس کے کاموں میں موجود رہی ہے۔ ہم نے اس کاغذ میں عربی زبان مدل کو استعمال کیا ہے کہ کرسیم ڈیٹ سٹ کے ذریعے آیتوں کا جوڑا کلاس کرے یا نہ ہو۔ ہم نے اس سے پہلے کرسیم ڈاٹ سٹ کو پھیر لیا ہے اور تین ڈاٹ سٹ کو مثالیں بنایا ہے اور ہم نے AraBERT کے دونوں نسخے استعمال کئے ہیں، جو AraBERTv02 اور AraBERTv2 ہیں، تاکہ معلوم کریں کہ کون نسخہ بہترین کام کرتا ہے، جسے دیے گئے ڈاٹ سٹ کے ساتھ۔ سب سے بہترین نتیجے آراBERTv02 تھا کہ 92% دقیق اسکور کے ساتھ لیبل `2' اور لیبل '-1' کے مطابق ایک ڈیٹسٹ کا استعمال کیا گیا تھا، یہ آخری کرسیم ڈیٹسٹ کے باہر پیدا کیا گیا تھا.", 'uz': "Keyingi yilda tarjima qiluvchilardan bir xil kodlash (BERT) taʼminlovchisi nativiy tilning vazifalari bajarish vazifalarini yaratadi. Bu hujjatda, biz araBERT tili modelini QurSim maʼlumotlar tomonidan bir necha bogʻ'liq bo'lgan yoki hech qanday bogʻ'liq bo'lishi uchun yaratganмиз. Biz quyidagi Quranish maʼlumotlarini boshqarishmiz va uchta maʼlumotlar tizimini kamaytirish uchun yaratdik. Шунингдек, биз AraBERTv02 va AraBERTv2 (AraBERTv2) ikkita versiyalardan foydalanamiz. Koʻrsatilgan maʼlumot setlari bilan eng yaxshi ko'proq versiyatini aniqlash uchun. @ info: status", 'vi': 'Diễn xuất mã hóa hai hướng từ Transformers (BERT) đã trở nên nổi tiếng trong những năm gần đây sản xuất các trình diễn tối tân trong các công việc sản xuất ngôn ngữ tự nhiên. Trong tờ giấy này, chúng tôi đã sử dụng mô hình ngôn ngữ AraBERT để phân loại các cặp câu thơ do tập tin Qur Sim cung cấp hoặc theo ngữ pháp hoặc không. Chúng tôi đã xem sơ bộ dữ liệu của Qursim và tạo ra ba tập tin để so sánh. Chúng tôi cũng đã sử dụng cả hai phiên bản AraberT, đó là AraBERTv2 và AraBERTv2, để nhận ra phiên bản nào thực hiện tốt nhất với các tập tin đã đưa ra. The best results was AraBERTv-2 with 92=\'accuracy score, using a dataset bao gồm nhãn "2" và nhãn "1", the latter was formed outside of QurSim dataset.', 'bg': "Двупосочните кодери от трансформатори (БЕРТ) придобиха популярност през последните години, създавайки най-съвременни изпълнения в задачите за обработка на естествения език. В тази статия използвахме езиков модел за класифициране на двойки стихове, предоставени от набора от данни на КурСим, като семантично свързани или не. Предварително обработихме набора от данни и формирахме три набора от данни за сравнения. Също така сме използвали и двете версии на AraBERT, които са AraBERTv02 и AraBERTv2, за да разпознаем коя версия се представя най-добре с дадените набори от данни. Най-добрият резултат е АраBERTv02 с оценка на точност 92%, като се използва набор от данни, състоящ се от етикет `2' и етикет '-1', като последният е генериран извън набор от данни от QurSim.", 'da': "Bidirectional Encoder Representations from Transformers (BERT) har vundet popularitet i de seneste år og har produceret state-of-the-art performances på tværs af Natural Language Processing opgaver. I denne artikel brugte vi AraBERT sprogmodel til at klassificere par af vers leveret af QurSim datasættet til enten at være semantisk relateret eller ej. Vi har forbehandlet QurSim datasættet og dannet tre datasæt til sammenligninger. Vi har også brugt begge versioner af AraBERT, som er AraBERTv02 og AraBERTv2, til at genkende, hvilken version der fungerer bedst med de givne datasæt. De bedste resultater var AraBERTv02 med 92% nøjagtighed score ved hjælp af et datasæt bestående af etiket `2' og etiket '-1', sidstnævnte blev genereret uden for QurSim datasæt.", 'nl': "Bidirectionele Encoder Representaties van Transformers (BERT) hebben de afgelopen jaren aan populariteit gewonnen door state-of-the-art performances te produceren voor de verwerking van natuurlijke taal taken. In dit artikel gebruikten we AraBERT taalmodel om paren van verzen die door de QurSim dataset worden verstrekt, te classificeren als semantisch gerelateerd of niet. We hebben de QurSim dataset vooraf verwerkt en drie datasets gevormd voor vergelijkingen. Ook hebben we beide versies van AraBERT, AraBERTv02 en AraBERTv2, gebruikt om te herkennen welke versie het beste presteert met de gegeven datasets. De beste resultaten waren AraBERTv02 met 92% nauwkeurigheidsscore met behulp van een dataset bestaande uit label `2' en label '-1', dit laatste werd gegenereerd buiten QurSim dataset.", 'hr': "Predstavi za dvosmjerno kodiranje transformatora (BERT) u posljednjih godina dobili su popularnost proizvodnjom izvođenja stanja umjetnosti preko zadataka prirodnog procesa jezika. U ovom papiru smo koristili araBERT jezički model kako bi klasifikirali par stihova koje je donijela QurSim podaci da su ili semantički povezani ili ne. Preobradili smo KurSim podatke i formirali tri podatke za usporedbu. Također, koristili smo obe verzije AraBERT-a, koje su AraBERTv02 i AraBERTv2, kako bi prepoznali koja verzija najbolje izvršava s određenim podacima. Najbolji rezultat je bio AraBERTv02 s 92% tačnim rezultatima korištenjem seta podataka iz etikete `2' i etikete '-1', posljednji je stvoren izvan sete podataka QurSim.", 'de': "Bidirektionale Encoder Representations von Transformers (BERT) haben in den letzten Jahren an Popularität gewonnen, indem sie State-of-the-Art-Performances für die Verarbeitung natürlicher Sprache produzieren. In diesem Beitrag haben wir AraBERT-Sprachmodell verwendet, um Versenpaare, die vom QurSim-Datensatz bereitgestellt werden, als semantisch verwandt zu klassifizieren oder nicht. Wir haben den QurSim Datensatz vorverarbeitet und drei Datensätze für Vergleiche gebildet. Außerdem haben wir beide Versionen von AraBERT, AraBERTv02 und AraBERTv2, verwendet, um zu erkennen, welche Version mit den angegebenen Datensätzen am besten abschneidet. Die besten Ergebnisse waren AraBERTv02 mit 92% Genauigkeit unter Verwendung eines Datensatzes bestehend aus Label `2' und Label '-1', letzteres wurde außerhalb des QurSim-Datensatzes generiert.", 'id': "Perwakilan Encoder Bidirectional dari Transformers (BERT) telah meningkat popularitas dalam bertahun-tahun terakhir memproduksi pertunjukan terbaik di seluruh tugas Proses Bahasa Alam. Dalam kertas ini, kami menggunakan model bahasa AraBERT untuk mengklasifikasi pasangan ayat yang diberikan oleh set data QurSim untuk sama ada berhubungan semantis atau tidak. Kami telah memproses dataset QurSim dan membentuk tiga dataset untuk perbandingan. Juga, kami telah menggunakan kedua versi AraBERT, yang adalah AraBERTv02 dan AraBERTv2, untuk mengenali versi mana yang paling berhasil dengan set data yang diberikan. Hasil terbaik adalah AraBERTv02 dengan skor akurasi 92% menggunakan set data yang terdiri dari label `2' dan label '-1', yang terakhir dihasilkan diluar set data QurSim.", 'ko': "최근 몇 년 동안Transformers의 양방향 인코더 표시(BERT)는 자연 언어 처리 임무에서 가장 선진적인 성능을 얻었다.본고에서 우리는AraBERT 언어 모델을 사용하여QurSim 데이터 집합이 제공하는 쌍의 시구를 의미 관련 또는 비의미 관련으로 분류한다.우리는 QurSim 데이터 집합을 미리 처리하여 세 개의 데이터 집합을 비교하였다.또한 AraBERT의 두 가지 버전, 즉 AraBERTv02와 AraBERTv2를 사용하여 주어진 데이터 집합에서 가장 잘 표현된 버전을 식별했다.가장 좋은 결과는AraBERTv02인데 라벨'2'와 라벨'1'으로 구성된 데이터 집합을 사용하는데 정확도는 92%이고 후자는QurSim 데이터 집합 밖에서 생성된 것이다.", 'tr': "BERT Bu kagyzda, KurSim verileri tarapyndan berilen iki sany sanlamak üçin AraBERT dili nusgasyny ulandyk. Biz QuraSim veri setini öňünden işledik we daýynlamak üçin üç sany düzenledik. Munuň üçin AraBERT we AraBERTv02 we AraBERTv2-iň iki wersiýasyny ulandyk. Berilen veri setirleri bilen iň gowy edip biljek wersiýany tanamak üçin. Iň gowy netijeler AraBERTv02 we 92% dogry noty bilen '-2' we etiket '-1' etiketinden oluşan veriler ullanýardy.", 'fa': 'Representations of two directional Encoder from Transformers (BERT) has gained popularity in recent years producing state-of-the-art performances across natural Language Processing tasks. در این کاغذ، ما از مدل زبان AraBERT استفاده کردیم تا جفت از آیتهایی که توسط مجموعه داده\u200cهای QurSim ارائه می\u200cشود به عنوان یک نسبت نسبت به یک نسبت یا نه. ما مجموعه داده\u200cهای کورسیم را پیش\u200cفرض کردیم و سه مجموعه داده\u200cها را برای مقایسه ساختیم. همچنین، ما از هر دو نسخه آراBERT استفاده کرده ایم، که AraBERTv02 و AraBERTv2 هستند، برای شناسایی که کدام نسخه بهترین نسخه با مجموعه داده ها انجام می دهد. بهترین نتیجه\u200cهای AraBERTv02 با امتیاز دقیق ۲۲ درصد با استفاده از مجموعه داده\u200cای از نقاشی « ۲ » و نقاشی «- ۱ » بود، آن\u200cها بیرون مجموعه داده\u200cهای کرسیم تولید شده\u200cاند.', 'af': "Bidireksionale enkoder voorstellings van Transformers (BERT) het populariteit in onlangse jaar verkry wat state-of-the-art uitvoerings voor Natuurlike Taal Prosessering Opdragte produseer het. In hierdie papier het ons AraBERT taal model gebruik om paar versele te klassifiseer wat deur die KurSim datastel verskaf is om of semantiese verwante of nie te wees. Ons het voorafverwerk die KurSim datastel en drie datastel vir vergelykings geformeer. Ons het ook beide weergawes van AraBERT gebruik, wat AraBERTv02 en AraBERTv2 is, om te herken watter weergawe die beste uitvoer met die gegewe datastelle. Die beste resultate was AraBERTv02 met 92% presies telling gebruik 'n datastel gebruik van etiket `2' en etiket '- 1', die laaste was genereer buite van KurSim datastel.", 'sw': "Representations from Transfers (BERT) have gained popularity in recent years producing state-art performances across the Natural language Processing. Katika gazeti hili, tulitumia mtindo wa lugha ya AraBERT katika kutangaza ishara mbili zilizotolewa na taarifa za Qur'ani zinazowekwa ama la kuwa na uhusiano wa kimapenzi au la. Tumevutiwa na seti ya taarifa za Qur'ani kabla na tumetengeneza seti tatu za data kwa mfano. Pia, tumetumia toleo zote la AraBERT, ambalo ni AraBERTv02 na AraBERTv2, ili kutambua toleo gani linafanya vizuri zaidi kwa seti zinazopewa. Matokeo bora zaidi yalikuwa AraBERTv02 yenye vipimo vya sahihi 92 kwa kutumia seti ya taarifa yenye alama ya `2' na alama ya '-1', kipindi cha pili kilitengenezwa nje ya seti ya data ya QurSim.", 'sq': "Përfaqësuesit dy-drejtorë të koduesve nga Transformuesit (BERT) kanë fituar popullaritet në vitet e fundit duke prodhuar shfaqje më të larta nëpërmjet detyrave të procesimit të gjuhës natyrore. Në këtë letër, ne përdorëm modelin e gjuhës AraBERT për të klasifikuar çifte versete të dhëna nga QurSim për të qenë ose në lidhje semantike ose jo. Ne kemi paraprocesuar kompletin e të dhënave QurSim dhe kemi formuar tre komplete të të dhënave për krahasim. Also, we have used both versions of AraBERT, which are AraBERTv02 and AraBERTv2, to recognise which version performs the best with the given datasets.  Rezultatet më të mira ishin AraBERTv02 me rezultat 92% të saktësisë duke përdorur një grup të dhënash të përbërë nga etiketa `2' dhe etiketa '-1', e fundit u gjenerua jashtë grupit të dhënash QurSim.", 'am': "በአሁኑ ዓመታት ውስጥ የባሕላዊ ቋንቋ ፕሮጀክት የ-የ-አርእስት ስርዓት አካባቢ የፊደል የፊደል ኮድ (BERT) አካባቢ አግኝቷል፡፡ In this paper, we used AraBERT language model to classify pairs of verses provided by the QurSim dataset to either be semantically related or not.  ከ በፊት የኩርሲን ዳታተር ሰርተናል እና ሦስት ዳታ ሰርተቶችን ለመተካከል ፈጠርነው፡፡ ደግሞም በተሰጠው የዳታ ጽሑፎች የተሻለ ማን እንደሆነ እናውቅ ዘንድ AraBERTv02 እና AraBERTv2 የሚሉትን ሁለቱን ክፍሎች ተጠቀምን፡፡ ከውጤቶች የተሻለ ፍጥረቶች AraBERTv02 በ92% እርግጠኛ ነጥብ `2' እና ምልክት '-1' የተደረገ የዳታ ሳጥን የተደረገ ነው፡፡", 'hy': 'Վերջին տարիների ընթացքում Երկու ուղղությամբ ձայնագրողների ներկայացումները փոխակերպեցին բնական լեզվի վերլուծության խնդիրների ընթացքում: Այս թղթի մեջ մենք օգտագործեցինք Արաբերթ լեզվի մոդելը, որպեսզի դասակարգենք Քորսիմ տվյալների համակարգում տրամադրված մի զույգ բառեր, որպեսզի կամ սեմանտիկապես կապված լինեն, թե ոչ: Մենք նախընտրել ենք Կորսիմ տվյալների համակարգը և կառուցել ենք երեք տվյալների համակարգ համեմատության համար: Մենք նաև օգտագործել ենք երկու տարբերակը՝ Արաբերթ-2 և Արաբերթ-2, որպեսզի ճանաչենք, թե որն է ամենալավը տվյալ տվյալների համակարգերի հետ: Ամենալավ արդյունքները Արաբերթվա02-ն էին, որի 92 տոկոսը ճշգրիտություն էր օգտագործում տվյալների համակարգը, որը կազմված էր «2» և «1» պիտակից, իսկ վերջինը ստեղծվել էր QUrSIM-ի տվյալների համակարգից դուրս:', 'az': "Tərfümcülərin (BERT) iki yönəlli Kodlayıcı Tərfümcüləri son illərdə məşhurluq əldə etdi və təbiətli Dil İşləməsi işləri ilə eyni təhsil etdi. Bu kağızda, QurSim verilənlərinin bir cüt ayələri seçmək üçün AraBERT dili modeli kullandıq. Biz Qur'an verilənlərini əvvəlcə təhsil etdik və üç verilənlər yaratdıq. Ayrıca araBERT və AraBERTv2 arasındakı iki versiyonu istifadə etdik, verilən verilən verilən quruların ən yaxşı versiyonunu tanımaq üçün. Ən yaxşı sonuçlar AraBERTv02, QurSim veri qurularının dışında yaradılmışdır.", 'bn': "সাম্প্রতিক বছরগুলোতে ট্রান্সফার্মার (বেরেটি) থেকে বাইডিয়াল এনকোডার প্রতিনিধি জনপ্রিয় হয়েছে যা স্বাভাবিক ভাষার প্রক্রিয়া কাজে In this paper, we used AraBERT language model to classify pairs of verses provided by the QurSim dataset to either be semantically related or not.  আমরা কুরিসিম ডাটাসেটের পূর্বে প্রক্রিয়া করেছি এবং তুলনায় তিনটি ডাটাসেট তৈরি করেছি। এছাড়াও আমরা আরাবেরেটের দুটো সংস্করণ ব্যবহার করেছি, যারা আরাবেরিটিভি২ এবং আরাবেরিটিভি২, যাতে প্রদান করা ডাটাসেটের সেরা সংস্করণ কোনট সবচেয়ে ভাল ফলাফল হচ্ছে আরাবেরিটিভি২, যার মধ্যে ৯২% সঠিক স্কোর রয়েছে `২' এবং লেবেলেট '-১' লেবেল ব্যবহার করে, তার পরে কুরিম ডাটাসেটের বাইরে", 'ca': "Representacions bidireccionals del codificador dels transformadors (BERT) han guanyat popularitat en els últims anys produint actuacions més avançades a través de tasques de processament de llenguatges naturals. En aquest article vam utilitzar el model de llenguatge AraBERT per classificar parells de versos proporcionats pel conjunt de dades QurSim per estar o no relacionats semànticament. Hem pre-processat el conjunt de dades del QurSim i hem format tres conjunts de dades per a comparar. També hem utilitzat les dues versions d'AraBERT, que són AraBERTv02 i AraBERTv2, per reconèixer quina versió és la millor amb els conjunts de dades dadas. Els millors resultats van ser AraBERTv02 amb una puntuació de precisió del 92% utilitzant un conjunt de dades compost de l'etiqueta `2' i l'etiqueta `1', l'última va ser generada fora del conjunt de dades QurSim.", 'cs': "Obousměrné zastoupení snímačů od transformátorů (BERT) získalo v posledních letech popularitu a produkují nejmodernější výkony napříč úkoly zpracování přirozeného jazyka. V tomto článku jsme použili jazykový model AraBERT k klasifikaci dvojic veršů poskytnutých datovou sadou QurSim tak, aby byly buď sémanticky související, nebo ne. Předzpracovali jsme datovou sadu QurSim a vytvořili jsme tři datové sady pro srovnání. Dále jsme použili obě verze AraBERT, tedy AraBERTv02 a AraBERTv2, abychom rozpoznali, která verze s danými datovými sadami funguje nejlépe. Nejlepším výsledkem byl AraBERTv02 s 92% skóre přesnosti pomocí datové sady složené ze štítku `2' a štítku '-1', který byl generován mimo datovou sadu QurSim.", 'et': "Kahesuunalised kodeerijad Transformeritelt (BERT) on viimastel aastatel populaarseks saanud, pakkudes kaasaegseid esitusi looduskeele töötlemise ülesannetes. Käesolevas töös kasutasime AraBERT keelemudelit, et klassifitseerida QurSim andmekogumi antud salmide paarid semantiliselt seotud või mitte. Oleme eelnevalt töödelnud QurSim andmekogumi ja moodustanud võrdluseks kolm andmekogumit. Samuti oleme kasutanud AraBERTi mõlemat versiooni, milleks on AraBERTv02 ja AraBERTv2, et tuvastada, milline versioon toimib antud andmekogumitega kõige paremini. Parim tulemus oli AraBERTv02 92% täpsuse skooriga, kasutades andmekogumit, mis koosnes märgistusest `2' ja märgistusest '-1', viimane loodi väljaspool QurSim andmekogumit.", 'fi': "Kaksisuuntaiset koodaajien esitykset muuntajilta (BERT) ovat saaneet suosiota viime vuosina tuottaen huippuluokan esityksiä luonnollisen kielen prosessointitehtävissä. Tässä työssä käytimme AraBERT-kielimallia luokitellaksemme QurSim-aineiston jakeiden parit semanttisesti toisiinsa liittyviksi tai ei. Olemme esikäsitelleet QurSim-aineiston ja muodostaneet kolme aineistoa vertailua varten. Olemme myös käyttäneet molempia AraBERT-versioita, jotka ovat AraBERTv02 ja AraBERTv2, tunnistaaksemme, mikä versio suoriutuu parhaiten annetuilla aineistoilla. Paras tulos oli AraBERTv02 92%:n tarkkuudella käyttäen tietoaineistoa, joka koostui etiketeistä `2' ja '-1', jälkimmäinen tuotettiin QurSim-aineiston ulkopuolella.", 'bs': "Predstavi za dvosmjerno kodiranje transformatora (BERT) u posljednjih godina dobili su popularnost proizvodnjom predstava države umjetnosti preko zadataka prirodnog procesa jezika. U ovom papiru smo koristili araBERT jezički model kako bi klasifikovali par stihova koje je donijela QurSim podaci da su ili semantički povezani ili ne. Preobradili smo podatke Kursima i formirali tri podatke za usporedbu. Također, koristili smo obe verzije AraBERT-a, koje su AraBERTv02 i AraBERTv2, kako bi prepoznali koja verzija najbolje izvršava sa određenim serijama podataka. Najbolji rezultat je bio AraBERTv02 sa 92% tačnim rezultatima koristeći kompletu podataka koja sadrži etiketu `2' i etiketu '-1', poslednji je stvoren izvan kompleta podataka QurSim.", 'sk': "Dvosmerne predstavitve kodirnikov iz transformatorjev (BERT) so v zadnjih letih postale priljubljene, kar ustvarja najsodobnejše predstave pri opravilih obdelave naravnega jezika. V tem prispevku smo uporabili jezikovni model AraBERT za razvrstitev parov verzov, ki jih zagotavlja nabor podatkov QurSim, da so semantično povezani ali ne. Predhodno smo obdelali nabor podatkov QurSim in oblikovali tri nabore podatkov za primerjavo. Prav tako smo uporabili obe različici AraBERT, ki sta AraBERTv02 in AraBERTv2, da bi prepoznali, katera različica je najboljša z danimi nabori podatkov. Najboljši rezultat je bil AraBERTv02 z 92-odstotno točnostjo z uporabo nabora podatkov, sestavljenih iz oznake `2' in oznake '-1', slednji pa je bil ustvarjen zunaj nabora podatkov QurSim.", 'ha': "KCharselect unicode block name Daga wannan takardan, mun yi amfani da misalin harshen AraBERT dõmin mu rarraba wasu ãyõyi biyu wanda aka bai wa data na Alƙur'ani, ko kuwa ya yi haɗa da tamani ko kuma ba. Haƙĩƙa, Mun sami tsarin mutane na Alƙur'ani gaba ɗaya kuma Muka sami taki uku masu misãlai. Kuma kamar haka, mun yi amfani da laban versiyori na AraBERTv2 ne AraBERTv2 da AraBERTv2, dõmin a san wanne versiyori ya sami mafi kyaun da tsarin da aka bai wa. Babbar matsala na AraBERTv2 da kimar tabbatacce na 92% ya yi amfani da wani tsari na tsari da aka haɗa label `2' da kuma `-1', an sami ƙarshen ta ƙara bayan tsarin tsari na KurSim.", 'bo': "དབྱིབས་སྔོན་གྱི་ལོ་ངོ་རྣམ་པ(BERT)ཡིས་གཞུང་དང་མཉམ་སྦྲེལ་ནང་ལས་ཕན་ཚུན་ཕན་ཐེབས་བྱུང་ཡོད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག་ཆའི་སྒེར་གྱི་arabBERT སྐད་རིགས་མིང་ལ་ལག་ལེན་འཐབ་ཡོད་པ་ལྟར་ QurSim་ཡིག ང་ཚོས་ཀྱིས་QuraSim་ཡིག་སྣོད་ཀྱི་སྔ་དོན་ལས་སྦྱོར་བྱེད་ཀྱི་ཡོད་པའི་ཆ་འཕྲིན་གསུམ་སྒྲིག་ཆས་བྱུང་། Also, we have used both versions of AraBERT, which are AraBERTv02 and AraBERTv2, to recognise which version performs the best with the given datasets. ཚང་ཤོས་བ་འདི་ནི་AraBERTv02 རྣམས་92% ཐོག་ནས་ངོས་འཛིན་པའི་ཚིག་ཡིག་ཆ་སྒྲིག་འགོད་བྱས་ནས་ཁ་ཡིག་`2' དང་ཁ་ཡིག་ '-1'་ཡིན།", 'jv': 'Disc Image Nang pepulan iki, kita nambah model araBERT kanggo kelas pirsak dipunangke dipunangke dipunangke dipunangke dipunangke CyrSim Awak dhéwé wis mulai perusahaan dataset kur Sim lan ngupakan telu dataset kanggo ngregani barang. Mungkin, awak dhéwé wis nggunakake versi durung araBERT, sampeyan araBERT V02 lan araBERT V2, kanggo ngerasakno versi sing dadi nggawe dataset sing apik dhéwé. Laptop" and "Desktop', 'he': 'מייצגים של קודד שתי כיוונים ממעברים (BERT) קיבלו פופולריות בשנים האחרונות לייצר הופעות חדשות במהלך משימות מעבדת שפת טבעית. בעיתון הזה, השתמשנו בדוגמנית שפה AraBERT כדי לקlassifika זוגות של פסים שנספקו על ידי קבוצת מידע QurSim כדי להיות קשורים סמנטית או לא. עבדנו קודם את קבוצת המידע של קורסים ויצרנו שלושה קבוצות מידע לשוואות. בנוסף, השתמשנו בשני גרסאות של AraBERT, אשר הם AraBERTv02 ואראBERTv2, כדי לזהות איזו גרסה מבצעת את הטוב ביותר עם קבוצות נתונים נתונים. התוצאות הטובות ביותר היו AraBERTv02 עם נקודת מדויקת 92% באמצעות קבוצת נתונים שמכילה בתווית "- 2" ותווית "- 1", האחרונה נוצרה מחוץ לקבוצת נתונים QurSim.'}
{'en': 'AraELECTRA : Pre-Training Text Discriminators for Arabic Language Understanding', 'fr': 'AraElectra\xa0: Discriminateurs de texte pré-entraînement pour la compréhension de la langue arabe', 'ar': 'AraELECTRA: محددات النص قبل التدريب لفهم اللغة العربية', 'es': 'AraElectra: Preentrenamiento de discriminadores de textos para la comprensión del idioma árabe', 'pt': 'AraELECTRA: Discriminadores de texto pré-treinamento para compreensão da língua árabe', 'ja': 'AraELECTRA ：アラビア語理解のための事前トレーニングテキスト識別子', 'hi': 'AraELECTRA: अरबी भाषा की समझ के लिए पूर्व-प्रशिक्षण पाठ भेदभावपूर्ण', 'ru': 'AraELECTRA: Предварительное обучение текстовым дискриминаторам для понимания арабского языка', 'zh': 'AraELECTRA曰:阿拉伯语解鉴别器预培训', 'ga': 'AraELECTRA: Idirdhealaithe Téacs RéamhOiliúna le haghaidh Tuiscint na Teanga Araibise', 'ka': 'AraELECTRA: წინ შესწავლა ტექსტის დისკრიმინატორი არაბური ენის განსხვავებისთვის', 'hu': 'AraELECTRA: Szövegmegkülönböztetők előképzése az arab nyelv megértéséhez', 'el': 'AraELECTRA: Προενταξιακοί Διακριτές Κειμένου για την κατανόηση της Αραβικής Γλώσσας', 'it': 'AraELECTRA: Discriminatori di testo pre-formazione per la comprensione della lingua araba', 'lt': 'AraELECTRA: Premokymo teksto diskriminatoriai arabų kalbos supratimui', 'mk': 'ААЕЛЕКТРА: Преобучувачки дискриминатори на текст за разбирање на арапскиот јазик', 'kk': 'AraELECTRA: Араб тілді түсініктерінің алдындағы оқыту мәтін дискриминаторы', 'ms': 'AraELECTRA: Diskriminator Teks Pra-Latihan untuk Pemahaman Bahasa Arab', 'ml': 'അരേലിക്ട്രാ: അറബി ഭാഷയ്ക്കുള്ള വിവരങ്ങള്\u200dക്കായി പഠിപ്പിക്കുന്ന പദാവലിയുടെ മുമ്പില്\u200d വിവേച', 'mt': 'AraELECTRA: Diskriminaturi tat-Test ta’ Qabel it-Taħriġ għall-Ftehim tal-Lingwa Għarbija', 'mn': 'AraELECTRA: Араб хэлний ойлголтын тулд өмнөх сургалтын текст дискриминаторууд', 'no': 'AraELECTRA: Forlæringstekstdiskriminatorer for arabisk språk forståking', 'pl': 'AraELECTRA: Dyskryminatorzy tekstów przedszkoleniowych dla zrozumienia języka arabskiego', 'ro': 'AraELECTRA: Discriminatorii de text pre-formare pentru înțelegerea limbii arabe', 'sr': 'AraELECTRA: Diskriminacije teksta pre obuke za razumevanje arapskog jezika', 'si': 'AraELECTRA: අරාබි භාෂාව තේරුම්ගන්න ප්\u200dරධානය පාළික විශ්වාස කරනවා', 'so': 'AraELECTRA: Takoorista qoraalka hore ee loogu talagalay waxgarashada afka Carabiga', 'sv': 'AraELECTRA: Förutbildning av textdiskriminerare för förståelse av arabiska språk', 'ta': 'அரேபிய மொழி புரிந்து கொள்ளும் முன்பு பயிற்சி உரை பிரிவாக்குபவர்கள்', 'ur': 'عربی زبان سمجھنے کے لئے پیش ترین تدبیر کرنے والے', 'uz': 'AraELECTRA: AQSH tili tushunishdan oldin matn discriminatori', 'vi': 'Name=Đánh giá chữ)', 'da': 'AraELECTRA: Pre-Training Tekstdiskriminatorer for arabisk sprogforståelse', 'nl': 'AraELECTRA: Pre-Training Tekst Discriminators voor het begrijpen van Arabische Taal', 'bg': 'АраЕЛЕКТРА: Предобучителни текстови дискриминатори за разбиране на арабския език', 'hr': 'AraELECTRA: Diskriminacije teksta predobučenja za razumijevanje arapskog jezika', 'de': 'AraELECTRA: Vortraining Textdiskriminatoren für das Verstehen der arabischen Sprache', 'fa': 'AraELECTRA: جدایی\u200cکننده\u200cهای متن پیش آموزش برای درک زبان عربی', 'id': 'AraELECTRA: Diskriminator Teks Pre-Pelatihan untuk Pemahaman Bahasa Arab', 'sw': 'AraELECTRA: Wachambuzi wa Maandishi ya Kiarabu wa Kufundisha', 'ko': 'AraELECTRA: 아랍어 이해를 위한 사전 교육 텍스트 감별기', 'tr': 'AraELECTRA: Arapça dil düşünmesi üçin öňünden okamaly metin diskriminatçylar', 'am': 'AraELECTRA: Pre-Training Text Discriminators for Arabic Language Understanding', 'sq': 'AraELECTRA: Diskriminatorët e tekstit të paratrajnimit për kuptimin e gjuhës arabe', 'hy': 'Արաելեկտրա. Արաբերական լեզվի հասկանալու համար նախապատրաստվող տեքստի խտրականները', 'az': 'AraELECTRA: Arab dilini anlamaq 칲칞칲n 톛vv톛l t톛hsil m톛tn diskriminatoru', 'bn': 'আরবি ভাষা বুঝতে পারার পূর্ব প্রশিক্ষণের লেখা বিচারক', 'bs': 'AraELECTRA: Diskriminacije teksta predobučenja za razumijevanje arapskog jezika', 'ca': 'AraELECTRA: Discriminadors de text de pré-capacitació per entendre la llengua àrab', 'cs': 'AraELECTRA: Předškolení diskriminační texty pro porozumění arabskému jazyku', 'et': 'AraELECTRA: Koolituseelsed tekstidiskrimineerijad araabia keele mõistmiseks', 'fi': 'AraELECTRA: arabian kielen ymmärtämistä edeltävät tekstit', 'af': 'AraELECTRA: Voorsoeking teks diskriminatorers vir Arabiese taal Verstaan', 'ha': 'KCharselect unicode block name', 'sk': 'AraELECTRA: Predusposabljanje besedilnih diskriminatorjev za razumevanje arabskega jezika', 'jv': 'araelecTRA:Diskripunkat Wurunggo Kemerdekaan kanggo langgambar barang', 'bo': 'AraELECTRA: Pre-Training Text Discriminators for Arabic Language Understanding', 'he': 'AraELECTRA: Pre-Training Text Discriminators for Arabic Language Understanding'}
{'en': 'Advances in English language representation enabled a more sample-efficient pre-training task by Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA). Which, instead of training a model to recover masked tokens, it trains a discriminator model to distinguish true input tokens from corrupted tokens that were replaced by a generator network. On the other hand, current Arabic language representation approaches rely only on pretraining via masked language modeling. In this paper, we develop an Arabic language representation model, which we name AraELECTRA. Our model is pretrained using the replaced token detection objective on large Arabic text corpora. We evaluate our model on multiple Arabic NLP tasks, including reading comprehension, sentiment analysis, and named-entity recognition and we show that AraELECTRA outperforms current state-of-the-art Arabic language representation models, given the same pretraining data and with even a smaller model size.', 'ar': 'مكّن التقدم في تمثيل اللغة الإنجليزية من أداء مهمة ما قبل التدريب أكثر فاعلية من خلال التعلم الفعال لبرنامج التشفير الذي يصنف الاستبدالات الرمزية بدقة (ELECTRA). والتي ، بدلاً من تدريب نموذج لاستعادة الرموز المميزة المقنعة ، تقوم بتدريب نموذج مميز لتمييز رموز الإدخال الحقيقية عن الرموز المميزة التالفة التي تم استبدالها بشبكة مولد. من ناحية أخرى ، تعتمد مناهج تمثيل اللغة العربية الحالية فقط على التدريب المسبق عبر نمذجة اللغة المقنعة. في هذه الورقة ، نقوم بتطوير نموذج تمثيل اللغة العربية ، والذي نطلق عليه اسم AraELECTRA. تم اختبار نموذجنا مسبقًا باستخدام هدف اكتشاف الرمز الذي تم استبداله في مجموعة نصوص عربية كبيرة. نقوم بتقييم نموذجنا على العديد من مهام البرمجة اللغوية العصبية للغة العربية ، بما في ذلك فهم القراءة ، وتحليل المشاعر ، والتعرف على الكيانات المسماة ، ونوضح أن AraELECTRA يتفوق على أحدث نماذج تمثيل اللغة العربية ، بالنظر إلى نفس بيانات التدريب المسبق وحتى مع حجم نموذج أصغر.', 'pt': 'Os avanços na representação do idioma inglês permitiram uma tarefa de pré-treinamento mais eficiente em amostras por meio do aprendizado eficiente de um codificador que classifica as substituições de token com precisão (ELECTRA). Que, em vez de treinar um modelo para recuperar tokens mascarados, treina um modelo discriminador para distinguir tokens de entrada verdadeiros de tokens corrompidos que foram substituídos por uma rede geradora. Por outro lado, as abordagens atuais de representação da língua árabe dependem apenas do pré-treinamento por meio de modelagem de linguagem mascarada. Neste artigo, desenvolvemos um modelo de representação da língua árabe, que denominamos AraELECTRA. Nosso modelo é pré-treinado usando o objetivo de detecção de token substituído em grandes corpora de texto em árabe. Avaliamos nosso modelo em várias tarefas de PNL em árabe, incluindo compreensão de leitura, análise de sentimentos e reconhecimento de entidade nomeada e mostramos que o AraELECTRA supera os modelos atuais de representação de idioma árabe de última geração, com os mesmos dados de pré-treinamento e até mesmo com um tamanho do modelo menor.', 'es': 'Los avances en la representación del idioma inglés permitieron una tarea de preentrenamiento más eficiente en cuanto a las muestras mediante el aprendizaje eficiente de un codificador que clasifica con precisión los reemplazos de tokens (ELECTRA). Que, en lugar de entrenar un modelo para recuperar tokens enmascarados, entrena un modelo discriminador para distinguir los verdaderos tokens de entrada de los tokens corruptos que fueron reemplazados por una red generadora. Por otro lado, los enfoques actuales de representación del idioma árabe se basan únicamente en el preentrenamiento a través de modelos de lenguaje enmascarado. En este artículo, desarrollamos un modelo de representación en lengua árabe, que llamamos AraElectra. Nuestro modelo está preentrenado utilizando el objetivo de detección de token reemplazado en grandes corpus de texto árabe. Evaluamos nuestro modelo en múltiples tareas de PNL árabe, incluida la comprensión lectora, el análisis de sentimientos y el reconocimiento de entidades nombradas, y demostramos que AraElectra supera a los modelos actuales de representación en lengua árabe de última generación, con los mismos datos de preentrenamiento y con un tamaño de modelo aún más pequeño.', 'fr': "Les progrès de la représentation de la langue anglaise ont permis une tâche de pré-formation plus efficace en termes d'échantillonnage grâce à l'apprentissage efficace d'un encodeur qui classe les remplacements de jetons avec précision (ELECTRA). Ce qui, au lieu d'entraîner un modèle pour récupérer des jetons masqués, entraîne un modèle discriminateur pour distinguer les vrais jetons d'entrée des jetons corrompus qui ont été remplacés par un réseau générateur. D'autre part, les approches actuelles de représentation de la langue arabe reposent uniquement sur la préformation via une modélisation linguistique masquée. Dans cet article, nous développons un modèle de représentation de la langue arabe, que nous appelons AraElectra. Notre modèle est préentraîné à l'aide de l'objectif de détection de jeton remplacé sur de grands corpus de texte en arabe. Nous évaluons notre modèle sur plusieurs tâches de PNL en arabe, y compris la compréhension en lecture, l'analyse des sentiments et la reconnaissance d'entités nommées, et nous montrons qu'AraElectra surpasse les modèles de représentation de la langue arabe de pointe actuels, compte tenu des mêmes données de pré-entraînement et avec une taille de modèle encore plus petite.", 'zh': '英语言进步高效学正类令牌易编码器(ELECTRA),成高效预训练任务。 非练模以复屏蔽之令牌也,练鉴别器模形以别真输令牌与生成器网络易坏之令牌也。 其一,今之阿拉伯语法,赖掩码言建模预训练。 于本文中,开一阿拉伯语以示模形,命之曰AraELECTRA。 吾法用大阿拉伯语文本语料库上代令牌检习。 凡诸阿拉伯语NLP事,评我形势,兼观解释,情析名识,明AraELECTRA优于前阿拉伯语,给定同预练数,甚至尺寸。', 'ja': '英語表現の進歩により、トークンの置換を正確に分類するエンコーダを効率的に学習することで、よりサンプル効率の高い事前トレーニングタスクが可能になりました（ ELECTRA ）。これは、マスクされたトークンを回復するためのモデルをトレーニングする代わりに、識別子モデルをトレーニングして、ジェネレータネットワークによって置き換えられた破損したトークンから真の入力トークンを区別します。一方、現在のアラビア語表現のアプローチは、マスク付き言語モデリングを介した事前トレーニングのみに依存しています。本稿では、アラビア語表現モデルを開発し、これをAraELECTRAと名付けます。当社のモデルは、大規模なアラビア語テキストコーラで置き換えられたトークン検出目標を使用して事前に訓練されています。私たちは、読み取り理解、感情分析、名前付きエンティティ認識を含む複数のアラビア語NLPタスクでモデルを評価し、同じ事前トレーニングデータとさらに小さいモデルサイズで、AraELECTRAが現在の最先端のアラビア語表現モデルよりも優れていることを示します。', 'hi': 'अंग्रेजी भाषा प्रतिनिधित्व में प्रगति ने एक अधिक नमूना-कुशल पूर्व-प्रशिक्षण कार्य को सक्षम किया, जो टोकन प्रतिस्थापन को सही ढंग से वर्गीकृत करने वाले एक एनकोडर को कुशलतापूर्वक सीखता है (ELECTRA)। जो, नकाबपोश टोकन को पुनर्प्राप्त करने के लिए एक मॉडल को प्रशिक्षित करने के बजाय, यह एक जनरेटर नेटवर्क द्वारा प्रतिस्थापित किए गए दूषित टोकन से सही इनपुट टोकन को अलग करने के लिए एक भेदभावपूर्ण मॉडल को प्रशिक्षित करता है। दूसरी ओर, वर्तमान अरबी भाषा प्रतिनिधित्व दृष्टिकोण केवल नकाबपोश भाषा मॉडलिंग के माध्यम से प्रीट्रेनिंग पर भरोसा करते हैं। इस पेपर में, हम एक अरबी भाषा प्रतिनिधित्व मॉडल विकसित करते हैं, जिसे हम AraELECTRA नाम देते हैं। हमारे मॉडल को बड़े अरबी पाठ निगम पर प्रतिस्थापित टोकन का पता लगाने के उद्देश्य का उपयोग करके पूर्व-प्रशिक्षित किया गया है। हम कई अरबी एनएलपी कार्यों पर अपने मॉडल का मूल्यांकन करते हैं, जिसमें पढ़ने की समझ, भावना विश्लेषण और नामित-इकाई मान्यता शामिल है और हम दिखाते हैं कि AraELECTRA वर्तमान अत्याधुनिक अरबी भाषा प्रतिनिधित्व मॉडल को बेहतर बनाता है, एक ही प्रीट्रेनिंग डेटा और यहां तक कि एक छोटे मॉडल आकार के साथ भी।', 'ru': 'Достижения в представлении английского языка позволили сделать более примерно-эффективную задачу предварительного обучения за счет эффективного обучения кодировщика, который точно классифицирует замены токенов (ELECTRA). Который, вместо обучения модели для восстановления маркеров в масках, обучает модель дискриминатора, чтобы отличить истинные входные маркеры от поврежденных маркеров, которые были заменены сетью генератора. С другой стороны, нынешние подходы к представлению арабского языка основываются только на предварительной подготовке с помощью моделирования языка в масках. В этой статье мы разрабатываем модель представления арабского языка, которую мы называем AraELECTRA. Наша модель предварительно обучена с использованием замененной цели обнаружения токенов на больших арабских текстовых корпусах. Мы оцениваем нашу модель на нескольких арабских задачах NLP, включая понимание чтения, анализ настроений и распознавание именованных сущностей, и мы показываем, что AraELECTRA превосходит современные модели представления арабского языка, учитывая те же предварительные данные и даже меньший размер модели.', 'ga': 'Mar gheall ar dhul chun cinn i léiriú an Bhéarla bhí tasc réamhoiliúint níos sampla-éifeachtaí trí Ionchódóir a Fhoghlaim go hÉifeachtach a Rangaíonn Athsholáthair Chomhartha go Cruinneil (ELECTRA). In ionad múnla a oiliúint chun comharthaí folaithe a aisghabháil, cuireann sé oiliúint ar mhúnla idirdhealaithe chun idirdhealú a dhéanamh idir fíorchomharthaí ionchuir agus comharthaí truaillithe ar cuireadh líonra gineadóra ina n-ionad. Ar an taobh eile de, ní bhraitheann cur chuige reatha ionadaíochta teanga Araibis ach ar réamhoiliúint trí shamhaltú teanga faoi cheilt. Sa pháipéar seo, forbraímid samhail ionadaíochta teanga Araibis, ar a dtugaimid AraELECTRA. Déantar ár samhail a réamhthraenáil trí úsáid a bhaint as an gcuspóir athsholáthair chun comharthaí a bhrath ar chorpra mór téacs Araibise. Déanaimid meastóireacht ar ár múnla ar thascanna iolracha NLP Araibis, lena n-áirítear léamhthuiscint, anailís meon, agus aithint eintiteas ainmnithe agus léirímid go n-éiríonn le AraELECTRA na samhlacha ionadaíochta teanga Araibis nua-aimseartha atá ann faoi láthair, ag tabhairt na sonraí réamhoiliúint céanna agus fiú amháin. méid múnla níos lú.', 'el': 'Οι πρόοδοι στην αναπαράσταση της αγγλικής γλώσσας επέτρεψαν μια πιο αποδοτική εργασία προ-εκπαίδευσης με την αποτελεσματική εκμάθηση ενός κωδικοποιητή που ταξινομεί με ακρίβεια αντικαταστάσεις σημάτων (ΗΛΕΚΤΡΑ). Το οποίο, αντί να εκπαιδεύσει ένα μοντέλο για να ανακτήσει τα μασκοποιημένα σήματα, εκπαιδεύει ένα μοντέλο διάκρισης για να διακρίνει τα αληθινά σήματα εισόδου από τα κατεστραμμένα σήματα που αντικαταστάθηκαν από ένα δίκτυο γεννήτριας. Από την άλλη πλευρά, οι τρέχουσες προσεγγίσεις αναπαράστασης αραβικής γλώσσας βασίζονται μόνο στην προεπιλογή μέσω μοντελοποίησης μασκαρισμένης γλώσσας. Στην παρούσα εργασία, αναπτύσσουμε ένα μοντέλο αναπαράστασης αραβικής γλώσσας, το οποίο ονομάζουμε AraELECTRA. Το μοντέλο μας έχει προετοιμαστεί χρησιμοποιώντας τον αντικατασταθεί στόχο ανίχνευσης σημάτων σε μεγάλα αραβικά σώματα κειμένου. Αξιολογούμε το μοντέλο μας σε πολλαπλές εργασίες αραβικής ανάγνωσης, συμπεριλαμβανομένης της κατανόησης ανάγνωσης, της ανάλυσης συναισθημάτων και της αναγνώρισης ονομαστικής οντότητας και δείχνουμε ότι το AraELECTRA ξεπερνά τα σύγχρονα μοντέλα αναπαράστασης αραβικής γλώσσας, λαμβάνοντας υπόψη τα ίδια δεδομένα προετοιμασίας και με ακόμη μικρότερο μέγεθος μοντέλου.', 'hu': 'Az angol nyelvű ábrázolás előrehaladása lehetővé tette a mintahatékonyabb előképzési feladat lehetővé tételét a Token cserék pontos osztályozására szolgáló kódoló hatékony tanulásával (ELECTRA). Ami ahelyett, hogy egy modellt képezne a maszkos tokenek visszaállítására, egy diszkriminatív modellt képez arra, hogy megkülönböztesse a valódi bemeneti tokeneket a sérült tokenektől, amelyeket generátor hálózat váltott ki. Másrészről a jelenlegi arab nyelvi reprezentációs megközelítések csak a maszkos nyelvi modellezéssel történő előkészítésre támaszkodnak. Ebben a tanulmányban egy arab nyelvű reprezentációs modellt dolgozunk ki, amelyet AraELECTRA-nak nevezünk el. Modellünket előkészítettük a kicserélt token detektor célkitűzéssel nagy arab szövegkorpusokon. Modellünket több arab NLP feladat alapján értékeljük, beleértve az olvasásértést, az érzelmek elemzését és a nevezett entitások felismerését, és megmutatjuk, hogy az AraELECTRA felülmúlja a jelenlegi korszerű arab nyelvű reprezentációs modelleket, ugyanazokat az előkészítési adatokat és még kisebb modellméretet is.', 'ka': 'ანგლისური языკის გამოსახულება უფრო ეფექტიურად გამოსახულებელი სამუშაო სამუშაო სამუშაო სამუშაო დასწავლად, რომელიც კლასიფიკურად ტოკენის შეცვლების მუშაოდ (ELEC რომელიც მასკენტის მოდელის გარეშე, მასკენტის მოდელის გარეშე, მასკენტის მოდელის გარეშე დისკრიმინატორის მოდელის გარეშე სინამდვილეების მოდელის გარეშე კომპორტირებული მოდენის გარეშე მეორე მხოლოდ, მიმდინარე აპაბური ენის გამოსახულება მხოლოდ მაქსირებული ენის მოდელირების გამოსახულებაზე დარჩენა. ჩვენ აპაბური ენის გამოსახულების მოდელის განვითარებით, რომელიც აპაELECTRA. ჩვენი მოდელი იყენებულია, რომელიც გადაცვლით ტექსტის კოპორაში გადაიცვლით ტექსტის განსაკუთრების მიხედვით. ჩვენ ჩვენი მოდელის მრავალ აპაბიური NLP დავამუშავებთ, რომლებიც კითხვა შესაძლებლობა, სენტიმენტის ანალიზაცია და სახელ ინტერტის განაცნობა და ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენი მოდელის შესაძლებლობა აპაბიური ენის განაცნობის მოდელის', 'it': "I progressi nella rappresentazione in lingua inglese hanno permesso un compito di pre-formazione più efficiente da campione grazie all'apprendimento efficiente di un codificatore che classifica accuratamente le sostituzioni dei token (ELECTRA). Che, invece di addestrare un modello per recuperare i token mascherati, allena un modello discriminatore per distinguere i token di input veri da quelli corrotti che sono stati sostituiti da una rete generatrice. D'altra parte, gli attuali approcci di rappresentazione della lingua araba si basano solo sul pretraining tramite la modellazione della lingua mascherata. In questo articolo sviluppiamo un modello di rappresentazione in lingua araba, che chiamiamo AraELECTRA. Il nostro modello è pretrained utilizzando l'obiettivo di rilevamento token sostituito su grandi corpora di testo arabo. Valutiamo il nostro modello su molteplici attività di NLP arabo, tra cui comprensione della lettura, analisi sentimentale e riconoscimento di entità nominative e dimostriamo che AraELECTRA supera gli attuali modelli di rappresentazione in lingua araba all'avanguardia, dati gli stessi dati di pre-formazione e con dimensioni del modello ancora più ridotte.", 'lt': 'Anglų kalbos atstovavimo pažanga suteikė galimybę veiksmingiau mokytis koduotojo, kuris tiksliai klasifikuoja žymenų pakaitalus (ELECTRA), parengiamojo mokymo užduotis. Vietoj modelio, skirto paslėptiems ženklams atkurti, jis sukuria diskriminacinį model į, skirtą tikrosioms įėjimo ženklams atskirti nuo sugadintų ženklų, kurie buvo pakeisti generatoriaus tinklu. On the other hand, current Arabic language representation approaches rely only on pretraining via masked language modeling.  Šiame dokumente sukuriame arabų kalbų atstovavimo model į, kurį pavadiname AraELECTRA. Mūsų model is iš anksto mokomas naudojant pakeistą ženklų aptikimo tikslą didelio arabų teksto korpora. Vertiname savo model į dėl daugelio arabų NLP užduočių, įskaitant skaitymo supratimą, jausmų analizę ir vardinio subjekto pripažinimą, ir parodome, kad AraELECTRA geriau nei dabartiniai pažangiausi arabų kalbų atstovavimo modeliai, atsižvelgiant į tuos pačius ikimokymo duomenis ir net mažesnio modelio dydžio.', 'mk': 'Напредоците во претставувањето на англискиот јазик овозможија поефикасна задача за предобука со ефикасно учење на кодер кој точно ги класификува замените на токените (ЕЛЕКТРА). Кој, наместо да обучува модел за обнова на маскирани симболи, обучува дискриминаторски модел за разлика на вистинските симболи од корумпирани симболи кои беа заменети со генераторска мрежа. Од друга страна, актуелните пристапи за претставување на арапскиот јазик се зависат само од претренирање преку маскирано јазичко моделирање. Во овој весник, развиваме модел за претставување на арапски јазик, кој го нарекуваме АраЕЛЕКТРА. Нашиот модел е претрениран користејќи ја заменетата објектива за детекција на знаци на големиот арапски текст корпора. Го проценуваме нашиот модел за повеќе арапски НЛП задачи, вклучително и разбирање на читањето, анализа на чувствата и препознавање на именуваниот ентитет и покажуваме дека АраЕЛЕКТРА ги надминува актуелните модели за претставување на најсовремениот арапски јазик, со оглед на истите податоци за претренирање и уште помала големина на', 'kk': 'Ағылшын тілінің алдын- ала ауыстыруы токен алмастыруды дұрыс (ELECTRA) классификациялау кодтамасын оқу үшін тапсырмалардың алдын- ала бақылау тапсырмасын қолданды. Бұл үлгі белгілерді қалпына келтіру үшін үлгілерді оқыту орнына, жасаушы желінен алмастырылған қиын белгілерден шын келтіру белгілерді таңдау үшін дискриминатордың үлгісін ұстайды. Біріншіден, назардағы араб тілінің мәліметтері тек қалқан тілдерді моделдеу арқылы қалқалап тұрады. Бұл қағазда Араб тілдерін көрсету үлгісін құрамыз. Біз AraELECTRA деп аталамыз. Біздің үлгіміз үлкен Араб мәтін корпорасында алмастырылған белгілерді анықтау мақсатымен алмастырылады. Біз үлгімізді бірнеше араб NLP тапсырмаларында оқу, сезімдік анализ және аталған мақсаттарды анықтау үшін оқу үшін оқу үшін, AraELECTRA әзіргі әртүрлі араб тілінің түсіндіру үлгілерін өзгерту үлгілеріне сәйкес келтіріп, бір', 'ms': 'Kemajuan dalam perwakilan bahasa Inggeris membolehkan tugas pralatihan yang lebih efisien sampel dengan Mempelajari Pengekod dengan Efisien yang Mengklasifikasikan Penggantian Token dengan Tepat (ELECTRA). Yang, selain melatih model untuk mengembalikan token bertopeng, ia melatih model diskriminator untuk membezakan token input sebenar dari token rosak yang diganti oleh rangkaian generator. Di sisi lain, pendekatan mewakili bahasa Arab semasa hanya bergantung pada pralatihan melalui model bahasa bertopeng. Dalam kertas ini, kami mengembangkan model mewakili bahasa Arab, yang kami nama AraELECTRA. Model kita dilatih sebelum menggunakan objektif pengesan token yang diganti pada korpra teks Arab besar. Kami menilai model kami pada beberapa tugas NLP Arab, termasuk pemahaman pembacaan, analisis perasaan, dan pengenalan-entiti bernama dan kami menunjukkan bahawa AraELECTRA melampaui prestasi model mewakili bahasa Arab yang kini state-of-the-art, diberikan data sebelum latihan yang sama dan dengan saiz model yang lebih kecil.', 'ml': 'ഇംഗ്ലീഷ് ഭാഷയിലെ പ്രതിനിധിയിലുള്ള മുന്നറിയിപ്പുകള്\u200d കൂടുതല്\u200d ഉദാഹരണമുള്ള പരിശീലനത്തിന്റെ പണിയായി പ്രാവര്\u200dത്തികമാക്കിയിരിക്കുന്നു മുഖം വീണ്ടെടുക്കാന്\u200d ഒരു മോഡല്\u200d പരിശീലിപ്പിക്കാന്\u200d പകരം, ഒരു ജനറല്\u200d നെറ്റോര്\u200dവര്\u200dക്ക് പകരം മാറ്റിയിട്ടുള്ള മോഡലുകളില്\u200d നിന്നും യഥാര്\u200dത്ഥ മറ്റുവശത്ത്, ഇപ്പോഴത്തെ അറബി ഭാഷയുടെ പ്രതിനിധിയില്\u200d മുഖ്യഭാഷയുടെ മോഡലിങ്ങ് മുഖം മൂടിക്കൊണ്ട് മാ ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d ഒരു അറബി ഭാഷ പ്രതിനിധിയുടെ മോഡല്\u200d നിര്\u200dമ്മിക്കുന്നു. അതിനെ ഞങ്ങള്\u200d അരേലിക്ട്രാ എന്ന് പ നമ്മുടെ മാതൃകയാണ് മാറ്റിക്കൊണ്ടിരിക്കുന്നത് അറബി ടെക്സ്റ്റ് കോര്\u200dപ്പോറിയില്\u200d മാറ്റിയ സ്ഥാനം  നമ്മള്\u200d പല അറബി എംഎല്\u200dപി ജോലികളില്\u200d നമ്മുടെ മോഡല്\u200d വിലാസപ്പെടുത്തുന്നു. പരിശോധനത്തില്\u200d വായിക്കുന്നതും വിചാരിക്കുന്നതും വായിക്കുന്നതും പേരിട്ട സാധാരണ തിരിച്ചറിയുന്നതും നമ്', 'mt': "L-avvanzi fir-rappreżentanza tal-lingwa Ingliża ppermettew kompitu ta’ taħriġ ta’ qabel aktar effiċjenti fil-kampjun billi jitgħallem b’mod Effiċjenti Kodifikatur li jikklassifika b’mod pre ċiż is-sostituzzjonijiet tat-Token (ELECTRA). Li minflok iħarreġ mudell biex jirkupra tokens maskrati, iħarreġ mudell diskriminatorju biex jiddistingwi tokens ta’ input reali minn tokens korrotti li ġew sostitwiti minn netwerk ta’ ġeneraturi. On the other hand, current Arabic language representation approaches rely only on pretraining via masked language modeling.  F’dan id-dokument, aħna niżviluppaw mudell ta’ rappreżentanza tal-lingwa Għarbija, li aħna nagħtu l-isem AraELECTRA. Il-mudell tagħna huwa mħarreġ minn qabel bl-użu tal-objettiv sostitwit għall-identifikazzjoni tat-tokens fuq korpra kbira tat-test Għarbi. Aħna jevalwaw il-mudell tagħna dwar kompiti multipli tal-NLP Għarab, inkluż il-fehim tal-qari, l-analiżi tas-sentimenti, u r-rikonoxximent tal-entità msejħa u nuru li AraELECTRA tippreżenta mudelli attwali ta' rappreżentazzjoni tal-lingwa Għaraba l-aktar avvanzati, minħabba l-istess dejta ta' qabel it-taħriġ u b'daqs ta' mudell saħansitra iżgħar.", 'mn': 'Англи хэлний илтгэлийн дэвшүүлэлт нь Токен Альцуулалтыг зөв (ELECTRA) классифицируулдаг кодлогчийг эзэмшигтэй боловсруулан илүү өргөн эффективны урд суралцах үйл ажиллагааг ашигладаг. Энэ загварыг дасгал хөгжүүлэхийн оронд, газрын зураг эргүүлэх загварын загварын загвар нь генератор сүлжээгээр орлуулагдсан бүтээгдэхүүний шинжлэх ухаанаас хуваалцах үнэн бий болгон тодорхойлолтуудыг за Нөгөө талаар, одоогийн Араб хэлний үзүүлэлтийн ойлголт зөвхөн нүүрстөрөгчийн хэл загварын аргаар зөвхөн нүүрстөрөгч байдаг. Энэ цаасан дээр бид Араб хэлний үзүүлэлтийн загварыг бүтээж, Аралектра гэж нэрлэдэг. Бидний загвар нь Араб текст корпора дээр оролцсон тэмдэгтийг олж мэдэх зорилго ашиглаж байдаг. Бид олон Араб NLP даалгаврын загварын загварыг үнэлдэг. Мөн уншиж, мэдрэмжтэй шинжилгээ, нэрлэгдсэн загваруудыг хүлээн зөвшөөрөх боломжтой.', 'no': 'Avanseringar i engelsk språk er slått på eit meir prøveeffektivt føreøvingsoppgåve ved å lære eit kodar som klassifiserer tokens erstatningar akkurat (ELECTRA). Kva, i staden for å trenga eit modell for å gjenoppretta maskerte teikn, treng han ein diskriminermodell for å distisera sanne inntekens frå øydelagte teikn som ble erstatta av ein generernettverk. På den andre siden er det nærmere representasjonen av arabiske språk berre på trekking av maskerte språk. I denne papiret utviklar vi ein arabisk språk representasjonsmodul, som vi namnar AraELECTRA. Modellen vårt er trekket med målet for oppdaging av bytt teikn på stor arabisk tekstkorpora. Vi evaluerer modellen vårt på fleire arabiske NLP-oppgåver, inkludert lesing av forståelse, sentimentanalyse, og gjenkjenning av namnet entitet, og vi viser at AraELECTRA utfører gjeldande modeller for representasjon av køste arabiske språk, gitt samme data og til og med mindre modellstorleik.', 'pl': 'Postępy w reprezentacji języka angielskiego umożliwiły bardziej efektywne przykładowe zadanie przedszkoleniowe dzięki efektywnemu uczeniu się kodera, który precyzyjnie klasyfikuje wymiany tokenów (ELECTRA). Który, zamiast szkolić model do odzyskiwania zamaskowanych tokenów, szkoli model dyskryminacyjny, aby odróżnić prawdziwe tokeny wejściowe od uszkodzonych tokenów, które zostały zastąpione siecią generatora. Z drugiej strony, obecne podejścia do reprezentacji języka arabskiego opierają się tylko na wstępnym treningu poprzez modelowanie języka maskowanego. W artykule opracowujemy model reprezentacji języka arabskiego, który nazywamy AraELECTRA. Nasz model jest wstępnie trenowany przy użyciu zastąpionego obiektu wykrywania tokenów na dużych arabskich korpusach tekstowych. Oceniamy nasz model na wielu arabskich zadaniach NLP, w tym zrozumienie czytania, analizę sentymentów i rozpoznawanie nazwanych jednostek i pokazujemy, że AraELECTRA przewyższa obecne najnowocześniejsze modele reprezentacji języka arabskiego, biorąc pod uwagę te same dane wstępnego treningu i przy jeszcze mniejszym rozmiarze modelu.', 'ro': 'Avansurile în reprezentarea limbii engleze au permis o sarcină de pre-formare mai eficientă din eșantioane prin învățarea eficientă a unui codor care clasifică înlocuirea cu precizie a token-urilor (ELECTRA). Care, în loc să antreneze un model pentru recuperarea jetoanelor mascate, antrenează un model discriminatoriu pentru a distinge jetoanele de intrare reale de jetoanele corupte care au fost înlocuite de o rețea generatoare. Pe de altă parte, abordările actuale de reprezentare a limbii arabe se bazează doar pe pregătirea prin modelarea limbii mascate. În această lucrare, dezvoltăm un model de reprezentare în limba arabă, pe care îl numim AraELECTRA. Modelul nostru este pregătit folosind obiectivul de detectare a token-ului înlocuit pe corpuri mari de text arab. Evaluăm modelul nostru pe mai multe sarcini ale PNL arabe, inclusiv înțelegerea citirii, analiza sentimentului și recunoașterea entităților denumite și arătăm că AraELECTRA depășește modelele actuale de reprezentare a limbii arabe de ultimă generație, având în vedere aceleași date de pre-formare și cu o dimensiune chiar mai mică a modelului.', 'sr': 'Napredak na predstavljanju engleskog jezika omogućio je veći uzorak-efikasniji predobuku učenjem kodera koji precizno klasifikuje zamjene Token a (ELECTRA). Što umjesto obuke model a za oporavak maskiranih znakova, obučava diskriminacijski model da razlikuje prave znakove ulaska od korumpiranih znakova koje su zamijenjene generatorom mrežom. Sa druge strane, trenutni pristupi predstavljanja arapskog jezika oslanjaju se samo na pretkivanje putem maskiranog jezika. U ovom papiru razvijamo model predstavljanja arapskog jezika, koji zovemo AraELECTRA. Naš model se pretvara koristeći cilj za identifikaciju znakova na velikoj arapskoj tekstskoj korpori. Procjenjujemo naš model na višestrukim arapskim NLP zadatkima, uključujući čitanje razumijevanja, analizu sentiment a i priznanje imena entiteta, i pokazujemo da AraELECTRA nadmašuje trenutne modele predstavljanja arapskog jezika, s obzirom na isti podaci pretvaranja i još manje veličine modela.', 'si': 'ඉංග්\u200dරීසි භාෂාව ප්\u200dරතිනිධානයේ ප්\u200dරතිනිධානය සක්\u200dරිය කරලා තියෙන්නේ වඩා සාම්ප්\u200dරේස්ටල් ප්\u200dරතිස්ථානය කරන්න පුළුවන් ප්\u200dර මොකද්ද, මස්කර් ටොක්න්ස් එක ප්\u200dරධානය කරන්න බැරි වෙනුවෙන්, ඒක ප්\u200dරධානයක් ප්\u200dරධානය කරනවා ඇත්ත ඇතුළු ටොක්න්ස් වලින් විශේ අනිත් පැත්තෙන්, ප්\u200dරස්තූත අරාබි භාෂාව ප්\u200dරතිනිධානය සම්බන්ධ වෙන්නේ මාස්ක් භාෂාව මොඩිල මේ පැත්තට, අපි අරාබි භාෂාව ප්\u200dරතිනිධානයක් නිර්මාණය කරනවා, ඒක අපි AraELECTRA කියලා. අපේ මෝඩේල් ප්\u200dරතිචාරය ප්\u200dරතිස්ථාපනය කරන්න පුළුවන් ටෝකෙන් හොයාගන්න අරක්ෂාව ප්\u200dරතිචාර අපි අරාබික් NLP වැඩි වැඩේ අපේ මොඩේලය අවශ්\u200dය කරනවා, කියවන්න, දැනුම් විශ්ලේෂණය, නම් අයිති අයිතියක් අඳුරගන්න, අපි පෙන්වන්නේ AraELECTRA කියලා දැනුම් අරාබික් භාෂ', 'so': 'Horumarinta noocyada afka Ingiriiska waxaa lagu qabanqaabiyey shaqo ka mid ah sameynta hore oo faa’iido leh oo Effective Learning an Encoder that Classifies Token Replacements si rasmi ah (ELECTRA). Taas, taas oo ka bedela tusaale in loo soo celiyo calaamado maskax ah, waxay tababaridaa tusaale takoorista si uu uga kala sooco calaamada input oo runta ah calaamado kharribay oo lagu beddelay shabakadda generator. Hada kale, wakiilka afka Carabiga ah ee sasa waxay ku soo dhowaadaan inay ku tiirsato dib u soo daabacno tusaale ahaan luqada maskax ah. Warqadan, waxaynu horumarinaa model u dhiga af Carabi ah, kaas oo aan magaca AraELECTRA. Tusaalkayaga waxaa lagu soo bandhigay isticmaalka calaamada la beddelay oo ku qoran korporada warqada Carabiga ah. Tusaalka aan ku qiimeynaynaa shuqullada afka Carabiga ah oo kala duduwan, kuwaas oo ah akhriska hoose-dhigista, sawirida maandooriyaha, iyo aqoonsashada aqoonsashada macluumaadka lagu magacaabay, waxaynu tusaynaa in AraELECTRA uu sameeyo qaabab u eg qoraalka afka Carabiga ah oo aad u qoran karto, iyadoo lagu siinayo sidoo kale macluumaad la mid ah iyo xataa mid ka yar model.', 'sv': 'Framsteg i engelskspråkig representation möjliggjorde en mer exempeleffektiv förberedelseuppgift genom att effektivt lära sig en kodare som klassificerar Token Replacements korrekt (ELECTRA). Som, i stället för att träna en modell för att återställa maskerade tokens, tränar den en diskrimineringsmodell för att skilja sanna indata tokens från skadade tokens som ersattes av ett generatornätverk. Å andra sidan, nuvarande arabiska språkrepresentationsmetoder förlitar sig bara på förbebildning via maskerad språkmodellering. I denna uppsats utvecklar vi en arabisk språkrepresentationsmodell, som vi kallar AraELECTRA. Vår modell är förberedd med hjälp av det ersatta token detekteringsmålet på stora arabiska textkorpor. Vi utvärderar vår modell på flera arabiska NLP-uppgifter, inklusive läsförståelse, sentimentalanalys och namngiven entitetsigenkänning, och vi visar att AraELECTRA överträffar nuvarande state-of-the-art arabiska språkrepresentationsmodeller, med samma förberedande data och med en ännu mindre modellstorlek.', 'ta': 'முன்னேற்றம் ஆங்கிலத்தில் மொழியின் குறிப்பிடுதல் முன் பயிற்சி செயல்பாட்டை விளைவாக கற்றுக்கொண்டு ஒரு குறியீட்டாளரை சரியாக மாற்றும் Token Which, instead of training a model to recover masked tokens, it trains a discriminator model to distinguish true input tokens from corrupted tokens that were replaced by a generator network.  மற்றொரு பக்கத்தில், தற்போதைய அரபி மொழி குறிப்பிடுதல் நெருங்குகிறது முகத்தில் மொழி மாதிரி மாதிரியி இந்த காகிதத்தில், நாம் ஒரு அரபி மொழி பிரதிநிர்வாக மாதிரி உருவாக்குகிறோம், அதை AraELECTRA பெயரிடுகிறோம். எங்கள் மாதிரி பெரிய அரபி உரை நிறுவனத்தில் மாற்றப்பட்ட குறியீட்டு கண்டுபிடிப்பு காட்சியை பயன்படுத்தி ப நாம் பல அரபி NLP பணிகளில் எங்கள் மாதிரியை மதிப்பீடு செய்கிறோம், கூட்டம், உணர்வு ஆய்வு, மற்றும் பெயர் பொருள் அடையாளம் புரியும் மற்றும் AraELECTRA தற்போதைய அரபி மொழி பிரிவு மாதிரிகள் ம', 'ur': 'انگلیسی زبان کی روشنی میں اضافہ ایک اضافہ نمونہ-اضافہ پیش ترینس کے کام کو فعال طور پر سیکھنے کے ذریعے ایک ایسکوڈر کی تلاش کرتی ہے جو ٹوکنوں کو دقیق (ELECTRA) کلاسیف کرتا ہے۔ جو ماسک ٹوکنوں کو اٹھانے کے لئے ایک مدل کی آموزش کے بدلے، یہ ایک جدائی موڈل کی آموزش کرتا ہے کہ حقیقی ایمٹ ٹوکنوں کو خرابی ٹوکنوں سے جدائی کرے جو ایک جناتور نیٹ ورک سے بدل دی گئی تھی۔ اور دوسری طرف، موجود عربی زبان کی نمونش کے قریب ہوتی ہے، صرف ماسک زبان نمونڈی کے ذریعہ پرٹرینٹ پر مسلط ہے. اس کاغذ میں ہم ایک عربی زبان کی نمایش موڈل کو ایجاد کرتے ہیں، جسے ہم AraELECTRA کا نام رکھتے ہیں۔ ہمارا مدل بڑے عربی ٹاکسٹ کوپرا پر بدل دینے والی ٹاکن شناسیٹ کا موقع استعمال کرتا ہے. ہم نے بہت سے عربی NLP کے کاموں پر ہماری مدل کا ارزش کرتا ہے، سمجھ پڑھنے، احساسات تحلیل، اور نام داری پہچان لینے کے ساتھ، اور ہم دکھاتے ہیں کہ عربی زبان کی مدل میں آرائل اکترا ایک دوسرے سے زیادہ اضافہ کرتا ہے، جیسا دکھانے والی ڈیٹا اور بھی چھوٹی مدل کی اندازہ سے۔', 'uz': "@ info Bu modelni o'rganish uchun qo'llangan belgilarni tiklash uchun o'rganish modelini o'rganadi. Generator tarmoq orqali oʻzgartirib boʻlgan buzuq belgilarni o'zgartirish haqiqiqiy kiritish imkoniyatlarini o'rganadi. Бошқа тарафда, ҳозирги Арабча кўриниши назорат келади, фақат асосий тил моделявий усули билан қабул қилишга ишонадир. Bu hujjatda, biz arab tilni tahrirlash modelini yaratib, biz AraELECTRA nomimiz. Bizning modelimiz katta arab matn kompaniyasida almashtirilgan signal aniqlashni foydalanadi. Biz bir necha arab NLP vazifalarda modelimizni qiymatimiz, o'zgarishni o'qish, hissiyotni aniqlash va ma'lumotning nomini aniqlash va biz AraELECTRA hozir arab tildagi taʼminlovchi modellarni bajarayotganimizni ko'rsatdik, bir necha taʼminlovchi maʼlumot va bir kichkina modelning oʻlchamini ko'rsatdik.", 'vi': 'Sự tiến bộ của đại diện ngôn ngữ Anh đã cho phép một nhiệm vụ ưu tiên hàng mẫu hiệu quả hơn bằng cách tiết học mã hóa Token thay thế một cách chính xác. Thay vì huấn luyện một mô hình để phục hồi những vật thể đeo mặt nạ, nó huấn luyện một mô hình mô phỏng để phân biệt những vật nhập thực sự với những vật thể bị hỏng thay thế bằng mạng máy phát. Mặt khác, diện tích hiện tại của sự đại diện ngôn ngữ Ả Rập chỉ dựa vào việc làm người mẫu bằng ngôn ngữ đeo mặt nạ. Trong tờ giấy này, chúng tôi phát triển một mô hình ngôn ngữ tiếng Ả Rập, mà chúng tôi đặt tên AraElectray. Mẫu của chúng tôi được xem thường bằng mục tiêu phát hiện biểu tượng thay thế trên cơ thể chữ Ả Rập lớn. Chúng tôi đánh giá mẫu của chúng tôi về nhiều công việc ngôn ngữ Á Rập, bao gồm khả năng đọc thấu đáo, phân tích cảm xúc, và nhận diện với tên gọi thực thể và chúng tôi cho thấy rằng Arathorn thực hiện được các mô hình bào ngôn ngữ Á học hiện đại, dựa vào những dữ liệu trước đó và với kích thước mô hình nhỏ hơn.', 'bg': 'Напредъкът в представянето на английски език позволи по-ефективна задача за предобучение чрез ефективно изучаване на кодер, който класифицира точно заместванията на токени (ЕЛЕКТРА). Което, вместо да обучава модел за възстановяване на маскирани токени, обучава дискриминационен модел, за да разграничава истинските входни токени от повредените токени, които са заменени от генераторна мрежа. От друга страна, съвременните подходи за представяне на арабски език разчитат само на предварително обучение чрез маскирано езиково моделиране. В настоящата статия разработваме модел за представяне на арабски език, който наричаме АраЕЛЕКТРА. Нашият модел е предварително трениран с помощта на заместената цел за откриване на символи върху големи арабски текстови корпуси. Ние оценяваме нашия модел на множество задачи на арабски НЛП, включително разбиране за четене, анализ на сантименталности и разпознаване на имена на субекти и показваме, че превъзхожда съвременните модели на арабски език за представяне, като се имат предвид същите предтренировъчни данни и дори с по-малък размер на модела.', 'da': 'Fremskridt i engelsk sprogrepræsentation muliggjorde en mere prøveeffektiv prætræningsopgave ved effektivt at lære en koder, der klassificerer Token Replacements nøjagtigt (ELECTRA). Som i stedet for at træne en model til at gendanne maskerede tokens, træner den en diskrimineringsmodel til at skelne ægte input tokens fra beskadigede tokens, der blev erstattet af et generatornetværk. På den anden side er nuværende arabiske sprogrepræsentationsmetoder kun afhængige af foruddannelse via maskeret sprogmodellering. I denne artikel udvikler vi en arabisk sprogrepræsentationsmodel, som vi navngiver AraELECTRA. Vores model er forudtrænet ved hjælp af det erstattede token detekteringsmål på store arabiske tekstkorpora. Vi evaluerer vores model på flere arabiske NLP-opgaver, herunder læseforståelse, sentimentalanalyse og navngivne enhedsgenkendelse, og vi viser, at AraELECTRA overgår nuværende state-of-the-art arabiske sprogrepræsentationsmodeller, givet de samme forudgående data og med endda en mindre modelstørrelse.', 'nl': 'Vooruitgang in de Engelse taalweergave maakte een meer sample-efficiënte pre-training taak mogelijk door Efficient Learning an Encoder that Classified Token Replacements Accuraty (ELECTRA). In plaats van een model te trainen om gemaskerde tokens te herstellen, traint het een discriminatormodel om echte invoertokens te onderscheiden van beschadigde tokens die werden vervangen door een generatornetwerk. Aan de andere kant, de huidige benaderingen van de Arabische taalrepresentatie berusten alleen op pretraining via gemaskerde taalmodellering. In dit artikel ontwikkelen we een Arabisch taalrepresentatiemodel, dat we AraELECTRA noemen. Ons model is vooraf getraind met behulp van het vervangen token detectie objectief op grote Arabische tekstcorpora. We evalueren ons model op meerdere Arabische NLP-taken, waaronder leesbegrip, sentimentanalyse en naamsbekendheid. We tonen aan dat AraELECTRA de huidige state-of-the-art Arabische taalrepresentatiemodellen overtreft, gezien dezelfde pretraining gegevens en met nog een kleinere modelgrootte.', 'id': 'Kemajuan dalam representation bahasa Inggris memungkinkan tugas pra-pelatihan yang lebih efisien sampel dengan Mempelajari Efisien Pengkode yang Mengklasifikasi Pergantian Token dengan Tepat (ELECTRA). Yang, selain melatih model untuk mengembalikan token bertopeng, melatih model diskriminator untuk membedakan token input sejati dari token korup yang diganti oleh jaringan generator. Di sisi lain, pendekatan representation bahasa Arab saat ini hanya bergantung pada pralatihan melalui model bahasa bertopeng. Dalam kertas ini, kami mengembangkan model representation bahasa Arab, yang kami sebut AraELECTRA. Our model is pretrained using the replaced token detection objective on large Arabic text corpora.  Kami mengevaluasi model kami pada beberapa tugas NLP Arab, termasuk pemahaman pembacaan, analisis perasaan, dan pengenalan-entitas bernama dan kami menunjukkan bahwa AraELECTRA melebihi model representation bahasa Arab yang terbaik saat ini, mengingat data pretraining yang sama dan bahkan dengan ukuran model yang lebih kecil.', 'de': 'Fortschritte in der englischen Sprachdarstellung ermöglichten eine beispieleffizientere Vorbereitung durch effizientes Lernen eines Encoders, der Token Replacements Accuraty (ELECTRA) klassifiziert. Anstatt ein Modell zur Wiederherstellung maskierter Token zu trainieren, trainiert es ein Diskriminierungsmodell, um echte Eingabetoken von beschädigten Token zu unterscheiden, die durch ein Generatornetzwerk ersetzt wurden. Auf der anderen Seite basieren aktuelle Ansätze der arabischen Sprachdarstellung nur auf einer Vorausbildung mittels maskierter Sprachmodellierung. In dieser Arbeit entwickeln wir ein arabisches Repräsentationsmodell, das wir AraELECTRA nennen. Unser Modell wird mit dem ersetzten Token-Erkennungsziel auf großen arabischen Textkorpora vortrainiert. Wir bewerten unser Modell anhand mehrerer arabischer NLP-Aufgaben, einschließlich Leseverständnis, Stimmungsanalyse und Named-Entity-Erkennung, und wir zeigen, dass AraELECTRA aktuelle State-of-the-Art-Darstellungsmodelle in arabischer Sprache übertrifft, wenn dieselben Vortrainingsdaten und mit noch kleinerer Modellgröße vorliegen.', 'sw': 'Advances in English language representation enabled a more sample-efficient pre-training task by Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA).  Ambayo, badala ya mafunzo mifano ya kutafuta alama zilizowekwa, inafundisha mtindo wa ubaguzi wa kutofautisha alama za habari za kweli kutoka ishara za ufisadi zilizobadilishwa na mtandao wa kutengenezwa. Kwa upande mwingine, uwakilishi wa lugha ya Kiarabu wa sasa unaingia kungemea tu kutegemea kutengeneza matumizi ya lugha iliyopigwa. Katika karatasi hii, tunatengeneza modeli ya uwakilishi wa lugha ya Kiarabu, ambayo tunaita AraELECTRA. Mfano wetu umechukuliwa kwa kutumia lengo la kutambua alama zilizobadilikwa kwenye kampuni kubwa ya maandishi ya Kiarabu. Tutathmini mtindo wetu kuhusu kazi nyingi za NLP za Kiarabu, ikiwa ni pamoja na kusoma comprehension, uchambuzi wa hisia, na utambulisho wa entity unaoitwa na tunaonyesha kwamba AraELECTRA inaonyesha mifano ya sasa ya uwakilishi wa lugha ya Kiarabu ya sanaa, kwa kuzingatia takwimu hizo za kujieleza na hata kwa kiwango kidogo cha mifano.', 'ko': '영어 언어 표징의 발전은 효과적인 학습을 통해 기호화폐 교체를 정확하게 분류할 수 있는 인코더(ELECTRA)를 통해 더욱 효과적인 샘플 예훈련 임무를 실현했다.그것은 차단된 영패를 복구하기 위한 모형을 훈련하는 것이 아니라, 실제 입력 영패와 생성기 네트워크로 교체된 파손 영패를 구분하기 위한 감별기 모형을 훈련시킨다.한편, 현재의 아랍어 표시 방법은 복면 언어 모델링을 통한 예비 훈련에만 의존한다.본고에서 우리는 아랍어 표시 모델을 개발했는데 우리는AraELECTRA라고 부른다.우리의 모델은 대형 아랍어 텍스트 자료 라이브러리에서 교체된 표기 검측 목표를 사용하여 예비 훈련을 하는 것이다.우리는 여러 개의 아랍어 NLP 임무(독해, 정서 분석과 명명 실체 식별 포함)에서 우리의 모델을 평가한 결과 같은 훈련 전 데이터와 더 작은 모델 사이즈에서 아라엘ECTRA가 현재 가장 선진적인 아랍어 표시 모델보다 우수하다는 것을 알 수 있다.', 'tr': 'Iňlisçe dilinde ilerlemeler täsirli ön namaýyn efektiv öňünden öňünden geçirjek täblisasyny saýlaw(ELECTRA). Maskeli işaretlerni almak üçin bir nusga öwrenmegiň ýerine, ol gyzyklanýan çykyş işaretlerden çykmak üçin bir diskriminator nusga çykýar. Diňe bir ýagdaýda, häzirki arabça diller namaýyşlary diňe masker diller modelleýäniň ýüzünde ýakynlaşýar. Bu kagyzda Arabça dili temsil nusgasyny çykarýarys we bu nusgasy AraELECTRA diýip atlandyrýarys. Biziň modelimiz uly arabça metin korporasynda yer alan token tanyş maksadyny ullanýar. Biz modelimizi birnäçe arabça NLP täbliklerinde çykýarys, duýgular analizi we ady taýýarlanmasy bilen çykýarys we AraELECTRA häzirki sanat täblikleriniň arabça dilinde çykyş modellerinde çykýandygyny görkez, şol bir döwürme hatda bir nusga bile kiçi bir nusga görýäris.', 'fa': 'پیشرفت در نمایش زبان انگلیسی یک کار پیش آموزش پیش از نمونه\u200cهای فعالیت بیشتری را از طریق یادگیری یک رمز\u200cکننده\u200cای که دقیقاً جایگزینش\u200cهای Token (ELECTRA) را کلاس می\u200cدهد. که به جای آموزش یک مدل برای بازیابی نشانه\u200cهای ماسک آموزش می\u200cدهد، مدل جدایی\u200cکننده را آموزش می\u200cدهد تا نشانه\u200cهای واقعی وارد شدن را از نشانه\u200cهای خرابی که توسط شبکه ژنراتور جایگزین شده\u200cاند جدایی کند. از طرف دیگر، نمایش زبان عربی فعلی نزدیک می\u200cشوند تنها بر روی نمایش زبان ماسک\u200cشده\u200cای است. در این کاغذ، ما یک مدل نمایش زبان عربی را توسعه می\u200cکنیم که آن را آرالکترا نام می\u200cدهیم. مدل ما با استفاده از هدف کشف علامت جایگزینی در شرکت متن عربی بزرگ تغییر داده شده است. ما مدل خودمون را در مورد کارهای NLP متعدد عربی ارزیابی می کنیم، شامل خواندن درک، تحلیل احساسات و شناسایی از عنوان یک تنظیم، و نشان می دهیم که AraELECTRA مدل نمایش کردن زبان عربی فعلی را بیشتر انجام می دهد، با توجه به همان داده های تغییر کردن و حتی با اندازه یک مدل کوچک.', 'af': "Vorderings in Engelske taal voorstelling het 'n meer voorbeeld- effektief voor- onderriening taak geaktiveer deur effektief 'n Enkodeerder te leer wat Token vervangings akkuraat klassifiseer (ELECTRA). Wat, in plaas van onderwerp van 'n model om maskeerde tekens te herstel, trein dit 'n diskrimineerder model om waardie invoer tekens te verkies van korrupteerde tekens wat deur 'n genereerdernetwerk vervang is. Op die ander kant, die huidige Arabiese taal voorstelling toekom slegs op die pretraining deur maskerde taal modellering. In hierdie papier ontwikkel ons 'n Arabiese taal voorstelling model wat ons AraELECTRA genoem. Ons model is voorstrek deur die vervangde token-opslag objek op groot Arabiese teks korpora te gebruik. Ons evalueer ons model op veelvuldige Arabiese NLP-taak, insluitend lees verstanding, sentimentanalisie en genoem-entiteiterkenning en ons wys dat AraELECTRA uitvoer die huidige state-of-the-art-Arabiese taal-voorstelling modele, gegee dieselfde pretraining data en selfs 'n kleiner model grootte.", 'sq': 'Përparimet në përfaqësimin e gjuhës angleze mundësuan një detyrë më efikase paratrajnimi nga Mësimi Efikas i një kodifikuesi që klasifikon saktësisht zëvendësimet e tokave (ELECTRA). E cila, në vend të trajnimit të një modeli për të rikthyer toka të maskuara, trainon një model diskriminues për të dalluar toka të vërteta të hyrjes nga toka të korruptuara që u zëvendësuan nga një rrjet gjenerator. Nga ana tjetër, përfaqësimi aktual i gjuhës arabe mbështetet vetëm në parastërvitjen nëpërmjet modelimit të gjuhës së maskuar. Në këtë letër, ne zhvillojmë një model përfaqësimi të gjuhës arabe, të cilin e quajmë AraELECTRA. Modeli ynë është i stërvitur përpara duke përdorur objektivin e zëvendësuar të zbulimit të shenjave në një korpër të madhe teksti arab. Ne vlerësojmë modelin tonë mbi detyrat e shumëfishta të NLP-së arabe, duke përfshirë kuptimin e leximit, analizën e ndjenjave dhe njohjen e njësisë së quajtur dhe tregojmë se AraELECTRA mbivlerëson modelet aktuale të përfaqësimit të gjuhës arabe më të moderne, duke marrë parasysh të njëjtat të dhëna parastërvitëse dhe me një madhësi edhe më të vogël modeli.', 'am': 'የኢንጂልኛ ቋንቋ አካባቢዎች የፊደል ትምህርት ማድረግ በጥያቄ ይችላል፡፡ ይህም ምሳሌ ማሳየት የተለየ ምልክቶች ማድረግ ፋንታ አዲስ ምሳሌ የሚያስተምር ነው፤ እውነተኛውን የውስጥ ምልክቶችን ከረከሰ ምልክቶች በተለየ በአውራጅ መረብ የተለወጠውን ምልክቶች ለመለየት ያስተምራል፡፡ በሌላው ክፍል፣ የአሁኑ የዐረብኛ ቋንቋ መልዕክት በመስፎ ቋንቋ ምሳሌ በመፍጠር ብቻ ነው፡፡ በዚህ ፕሮግራም አረቢያ ቋንቋ ምሳሌ እናደርጋለን፡፡ ምሳሌያችን በታላቁ አረቢ ጽሑፍ ኮርፖርት ላይ በተለወጠው ምልክት ማግኘት አካባቢ ነው፡፡ የአረብኛ አርቢ የNLP ሥርዓቶችን እናስተውላለን፣ አስተያየት እና የስሜት ማስታወቂያውን እና የአርብኛ ቋንቋ መልዕክቶችን እናሳውቃለን፡፡', 'hy': 'Անգլերենի ներկայացման ոլորտում առաջընթացները հնարավորություն տվեցին ավելի արդյունավետ նախապատրաստման խնդիր՝ արդյունավետ սովորելով կոդեր, որը ճշգրիտ նշանների փոխարինումներ է դասակարգում (ELELCEthr). Այն, պատրաստվում է դիմակային նշաններ վերականգնելու մոդել սովորեցնելու փոխարեն, դիմակայող մոդել է սովորեցնում, որպեսզի տարբերակի իրական նշանները կոռուցված նշաններից, որոնք փոխարինվել են գեներատորի ցանցով: Մյուս կողմից, ներկայիս արաբական լեզվի ներկայացման մոտեցումները հիմնված են միայն նախավարժությունների վրա ծածկված լեզվի մոդելների միջոցով: Այս թղթի մեջ մենք զարգանում ենք արաբական լեզվի ներկայացման մոդել, որը մենք անվանում ենք Արաելեկտրա: Մեր մոդելը նախապատրաստված է օգտագործելով փոխարինված նշանների հայտնաբերման օբյեկտիվ մեծ արաբական տեքստի կոպորա: We evaluate our model on multiple Arabic NLP tasks, including reading comprehension, sentiment analysis, and named-entity recognition and we show that AraELECTRA outperforms current state-of-the-art Arabic language representation models, given the same pretraining data and with even a smaller model size.', 'az': "İngilizə dilində göstərilməsi tərzlərində daha çox nümunə-təhsil ön təhsil işləri, Token əvəzini doğrudan (ELECTRA) ilə dəyişdirilmiş Kodlayıcı öyrənməsi ilə daha çox yaradıldı. Bu, maski möcüzələri geri qaytarmaq üçün modeli təhsil etmək yerinə, generator a ğı ilə əvəz olunan fəsad giriş möcüzələrindən istifadə etmək üçün diskriminator modeli təhsil edir. Digər tərəfindən, ağıllı ərəbcə dil göstəricisi yalnız maski dil modelləri vasitəsilə süslənməyə təvəkkül edir. Bu kağıdında AraELECTRA adlı ərəbcə dil göstəricisi modeli təhsil edirik. Bizim modelimiz böyük ərəb mətn korporasında əvəz edilmiş token keşfetməsi məqsədilə təkrarlanmışdır. Biz modelimizi çoxlu ərəb NLP işlərində değerləşdiririk, oxumaq, duyguları analizi və adı ilə təsdiqlənmək üçün araELECTRA'nın hökmünün ərəb dilinin təsdiqlənməsi modellərindən üstün olduğunu göstəririk, eyni təsdiqlənmək məlumatlarını və daha kiçik modellərin böyüklüyü ilə istifadə edir.", 'hr': 'Napredak na predstavljanju engleskog jezika omogućio je učinkovitiji zadatak predobučenja uzoraka učinkovitijim učinkovitim učenjem kodera koji precizno klasifikira zamjene Token a (ELECTRA). Što, umjesto obuke model a za obnovu maskiranih znakova, obučava diskriminacijski model da razlikuje prave znakove ulaska od korumpiranih znakova koje su zamijenjene generatorom mrežom. S druge strane, trenutni pristupi zastupanja arapskog jezika oslanjaju se samo na pretkivanje putem maskiranog jezika. U ovom papiru razvijamo model zastupanja arapskog jezika, koji zovemo AraELECTRA. Naš model se pretvara koristeći cilj za otkrivanje zamjene znakova na velikoj arapskoj tekstskoj korpori. Procjenjujemo naš model na višestrukim arapskim NLP zadatkima, uključujući čitanje razumijevanja, analizu osjećaja i priznanje imena entiteta, i pokazujemo da AraELECTRA nadmašuje trenutne modele predstavljanja arapskog jezika, s obzirom na isti podaci pretvaranja i još manje veličine model a.', 'bn': 'ইংরেজি ভাষায় প্রতিনিধিত্বের উন্নয়নগুলো কার্যকর করে একটি এনকোডার শিক্ষা দিয়েছে যে সঠিকভাবে টোকেন প্রতিস্থাপন (ELECTRA) ক্লাসিফিফাই করেছে। যার পরিবর্তে মুখোশিত চিহ্ন পুনরুদ্ধারের জন্য একটি মডেল প্রশিক্ষণ দেয়ার পরিবর্তে এটি একটি বৈষম্যের মডেল প্রশিক্ষণ প্রদান করে দুর্নীতির প্রতীক থেক অন্যদিকে, বর্তমান আরবী ভাষার প্রতিনিধিত্ব কেবল মুখোশিত ভাষা মডেলের মাধ্যমে বৃষ্টির উপর নির্ভর করে। এই পত্রিকায় আমরা আরবী ভাষার প্রতিনিধিত্বের মডেল তৈরি করি, যার নাম আমরা আরালেক্ট্রা। আমাদের মডেল বিশাল আরবী লেখা কোর্পোরায় প্রতিস্থাপনের লক্ষ্যের উদ্দেশ্য ব্যবহার করে ভাবছে। We evaluate our model on multiple Arabic NLP tasks, including reading comprehension, sentiment analysis, and named-entity recognition and we show that AraELECTRA outperforms current state-of-the-art Arabic language representation models, given the same pretraining data and with even a smaller model size.', 'et': 'Ingliskeelse esindamise edusammud võimaldasid tõhusamat eelkoolituse ülesannet, õppides efektiivselt kodeerijat, mis klassifitseerib tokeni asendamise täpselt (ELECTRA). Selle asemel, et treenida mudelit maskeeritud tokenite taastamiseks, treenib see diskrimineerimismudelit eristama tõelisi sisendtokeneid rikutud tokenitest, mis asendati generaatorivõrguga. Teisest küljest toetuvad praegused araabia keele esindamise lähenemisviisid ainult eelõpetamisele maskeeritud keele modelleerimise kaudu. Käesolevas töös töötame välja araabia keele esindusmudeli, mida nimetame AraELECTRA. Meie mudel on eeltreenitud, kasutades asendatud märgi tuvastamise eesmärki suurtes araabia tekstikorpustes. Hindame oma mudelit mitmete araabia uue õppeprogrammi ülesannete, sealhulgas lugemise mõistmise, sentimentaalüüsi ja nimetatud üksuste tuvastamise kohta ning näitame, et AraELECTRA ületab praeguseid kaasaegseid araabia keele esindusmudeleid, arvestades samasuguseid koolituseelseid andmeid ja isegi väiksema mudeli suurusega.', 'cs': 'Pokroky v anglickém jazyce umožnily efektivnější úlohu předškolení díky efektivnímu učení kódéru, který přesně klasifikuje výměny tokenů (ELECTRA). Který místo tréninku modelu k obnově maskovaných tokenů trénuje diskriminační model, aby rozlišoval skutečné vstupní tokeny od poškozených tokenů, které byly nahrazeny generátorovou sítí. Na druhou stranu, současné přístupy reprezentace arabského jazyka spoléhají pouze na předškolení prostřednictvím maskovaného jazykového modelování. V tomto článku vyvíjíme model reprezentace arabského jazyka, který pojmenujeme AraELECTRA. Náš model je předtrénován pomocí nahrazeného objektu detekce tokenů na velkých arabských textových korpusech. Vyhodnocujeme náš model na několika úlohách arabského NLP, včetně porozumění čtení, analýzy sentimentů a rozpoznávání pojmenovaných entit a ukazujeme, že AraELECTRA překonává současné modely reprezentace arabského jazyka s ohledem na stejná data předškolení a s ještě menší velikostí modelu.', 'ca': "Els avanços en la representació del llenguatge anglès van permetre una tasca de pré-entrenament més eficient en la mostra aprenent eficientment un codificador que classifica exactament els substitucions de tomànies (ELECTRA). En comptes d'entrenar un model per recuperar fitxes mascarades, treina un model discriminator per distingir les fitxes d'entrada veritables de les fitxes corruptes que van ser substituïdes per una xarxa de generadors. D'altra banda, els enfocaments actuals de representació del llenguatge àrab només confien en la pré-formació mitjançant modelar el llenguatge mascat. En aquest article desenvolupem un model de representació del llenguatge àrab, que anomenem AraELECTRA. El nostre model es pré-entrena utilitzant l'objectiu de detecció de fitxes substituït en gran corpora de text àrab. Evaluam el nostre model en múltiples tasques del NLP àrab, incloent la comprensió lectora, l'anàlisi de sentiments i el reconeixement de l'entitat anomenada, i demostram que AraELECTRA supera els models actuals de representació del llenguatge àrab d'última edat, tenint en compte les mateixes dades de pré-formació i amb una mida encara més petita.", 'bs': 'Napredak na predstavljanju engleskog jezika omogućio je učinkovitiji predobučavanje uzoraka učinkovitijim učenjem kodera koji precizno klasifikira zamjene Token a (ELECTRA). Što, umjesto obuke model a za oporavak maskiranih znakova, obučava diskriminacijski model da razlikuje prave znakove ulaska od korumpiranih znakova koje su zamijenjene generatorom mrežom. S druge strane, trenutni pristupi predstavljanja arapskog jezika oslanjaju se samo na pretkivanje putem maskiranog jezika. U ovom papiru razvijamo model zastupanja arapskog jezika, koji zovemo AraELECTRA. Naš model se pretvara koristeći cilj za otkrivanje zamjene znakova na velikoj arapskoj tekstskoj korpori. Procjenjujemo naš model na višestrukim arapskim NLP zadatkima, uključujući čitanje razumijevanja, analizu osjećaja i priznanje imena entiteta, i pokazujemo da AraELECTRA nadmašuje trenutne modele predstavljanja arapskog jezika, s obzirom na isti podaci pretvaranja i čak manje veličine model a.', 'fi': 'Englannin kielen edustuksen edistys mahdollisti n瓣ytteenottotehokkaamman esikoulutuksen oppimalla kooderin, joka luokittelee polettien korvaamisen t瓣sm瓣llisesti (ELECTRA). Sen sijaan, ett瓣 se kouluttaisi mallin palauttamaan naamioituja poletteja, se kouluttaa erottelijamallia erottamaan todelliset sy繹tt繹poletit vioittuneista poleteista, jotka korvattiin generaattoriverkolla. Toisaalta nykyiset arabiankieliset l瓣hestymistavat perustuvat vain esikoulutukseen maskitun kielimallinnuksen avulla. T瓣ss瓣 ty繹ss瓣 kehit瓣mme arabiankielisen esitysmallin, jonka nimeksi tulemme AraELECTRA. Mallimme on esikoulutettu k瓣ytt瓣m瓣ll瓣 korvattua tokenin tunnistusta suurissa arabialaisissa tekstikorpussa. Arvioimme malliamme useissa arabiankielisiss瓣 NLP-teht瓣viss瓣, kuten lukemisen ymm瓣rt瓣misess瓣, tunteiden analysoinnissa ja nimettyjen entiteettien tunnistamisessa, ja osoitamme, ett瓣 AraELECTRA on parempi kuin nykyiset arabiankieliset esitysmallit, kun otetaan huomioon samat esikoulutustiedot ja jopa pienempi mallikoko.', 'sk': 'Napredek pri predstavitvi angleškega jezika je omogočil bolj učinkovito predusposabljanje z učinkovitim učenjem kodirnika, ki natančno razvršča zamenjave žetonov (ELECTRA). Namesto da usposablja model za obnovitev maskiranih žetonov, usposablja diskriminatorski model, ki razlikuje resnične vhodne žetone od poškodovanih žetonov, ki jih je zamenjalo generatorsko omrežje. Po drugi strani pa se trenutni pristopi arabskega jezika opirajo le na predurjenje prek maskiranega jezikovnega modeliranja. V prispevku razvijamo model arabskega jezika, ki ga imenujemo AraELECTRA. Naš model je predtreniran z uporabo zamenjanega cilja zaznavanja žetonov na velikih arabskih besedilnih korpusih. Naš model ocenjujemo na več arabskih nalogah NLP, vključno z razumevanjem branja, analizo sentimenta in prepoznavanjem imenovanih entitet, ter pokažemo, da AraELECTRA presega trenutne najsodobnejše modele reprezentacije arabskega jezika, ob upoštevanju enakih predšolskih podatkov in celo manjše velikosti modela.', 'ha': '@ action: button Wanda, ana ƙidãya wani misali da ya canza tsarin ayuka da aka tsare shi, yana sanar da wata misãlai mai yin ɓarna dõmin ya rarraba ayuka da gaske daga ayukan da aka turbuɗe daga ayukan da aka canza shi na jerin mai ƙẽtare. Ga da wani gefen, masu wakilishi na Larabci na yanzu yana zuwa, yana dõgara kawai a kan danganta da bakin ayuka da aka rufe. Ga wannan karatun, Munã ƙarfafa misãlan mai gaya cikin harshen Larabci, wanda Muke kiran AraELEctra. Ana baka misalinmu da aka yi amfani da matsayin ayuka da aka bada bayani ga matsayin Larabci. Ana ƙaddara misalinmu a kan aikin NLP masu yawa na Larabci, kamar karatun matsayi, Ana yi fasalin littafin, da kuma sanar da sunan-abun-abun shine kuma munã nuna cewa AraELEctra na samar da muhalli na-halin-da-harshen Larabci na sanar da, da kuma ko da ƙarami masu motsi da ke ƙaranci.', 'jv': 'Tulungan Inggris Tool Options, Layersdock Nanging kabeh-kabeh, kelangan banget arap saiki tau ngomong nik nggawe modusan banget karo cara-cara Nang pember iki, kita ngubungu disebarke sistem basa di arab, sing ngenanye araelecTRA. modellu gadhah gadhah buturan nggo kelas token detection object Awak dhéwé éntuk model dhéwé ning perusahaan NLP sing butawak dhéwé, gambar perusahaan langkung sampek, dadi kejahatan dhéwé, ngono nambah-nambah layang lan nganggep ono sampek awak dhéwé nggawe barang-sistem sing nyenggawe barang-sistem sing berarti parang dhéwé kuwi tindakan arap kuwi nggawe gedung, dadi padha pakan', 'bo': 'Advances in English language representation enabled a more sample-efficient pre-training task by Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA). Which, instead of training a model to recover masked tokens, it trains a discriminator model to distinguish true input tokens from corrupted tokens that were replaced by a generator network. ཕྱོགས་གཞན་ཞིག་ནས་ད་ལྟོའི་སྐད་ཡིག་གཟུགས་རིས་ངོ་བའི་སྐད་རིགས་མ་དབྱེ་བ་དང་བསྟུན་ནས་ཕན་ཚུན་བསྐྱེད་པའི་ ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཨ་རིའི་སྐད་ཡིག་གི་མིང་དཔེ་ལ་ཞིག་གསར་བསྐྲུན་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མ་དབྱིབས་རྩོམ་པ་སྒྲིག་དབྱིབས་ཆེན་པོ་ཞིག་གི་དམིགས We evaluate our model on multiple Arabic NLP tasks, including reading comprehension, sentiment analysis, and named-entity recognition and we show that AraELECTRA outperforms current state-of-the-art Arabic language representation models, given the same pretraining data and with even a smaller model size.', 'he': 'Advances in English language representation enabled a more sample-efficient pre-training task by Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA).  Which, instead of training a model to recover masked tokens, it trains a discriminator model to distinguish true input tokens from corrupted tokens that were replaced by a generator network.  On the other hand, current Arabic language representation approaches rely only on pretraining via masked language modeling.  In this paper, we develop an Arabic language representation model, which we name AraELECTRA.  Our model is pretrained using the replaced token detection objective on large Arabic text corpora.  We evaluate our model on multiple Arabic NLP tasks, including reading comprehension, sentiment analysis, and named-entity recognition and we show that AraELECTRA outperforms current state-of-the-art Arabic language representation models, given the same pretraining data and with even a smaller model size.'}
{'en': 'AraGPT2 : Pre-Trained Transformer for Arabic Language Generation', 'ar': 'AraGPT2: محول تم تدريبه مسبقًا لتوليد اللغة العربية', 'fr': 'AragPT2\xa0: Transformateur pré-entraîné pour la génération de la langue arabe', 'pt': 'AraGPT2: Transformador pré-treinado para geração de idioma árabe', 'es': 'AraGpt2: Transformador preentrenado para la generación de la lengua árabe', 'ja': 'AraGPT 2 ：アラビア語生成のための事前トレーニング済みトランスフォーマー', 'zh': 'AraGPT2:阿拉伯语生豫教转换器', 'hi': 'AraGPT2: अरबी भाषा पीढ़ी के लिए पूर्व प्रशिक्षित ट्रांसफॉर्मर', 'ru': 'AraGPT2: Предварительно обученный трансформатор для создания арабского языка', 'ga': 'AraGPT2: Trasfhoirmeoir RéamhOilte do Ghiniúint Teanga Araibis', 'hu': 'AraGPT2: Előképzett transzformátor az arab nyelv generációjához', 'el': 'Προπαιδευμένος μετασχηματιστής για την παραγωγή αραβικής γλώσσας', 'ka': 'AraGPT2', 'it': 'AraGPT2: Trasformatore pre-addestrato per la generazione della lingua araba', 'kk': 'AraGPT2: Араб тілін құру үшін алдын- оқылған түрлендіруші', 'lt': 'AraGPT2: Pre-Trained Transformer for Arabic Language Generation', 'ml': 'അരാജിപിടി2: അറബി ഭാഷയുടെ ജനിപ്പിക്കുവേണ്ടി മുമ്പ് പരിശീലിക്കപ്പെട്ട വിവരങ്ങള്\u200d', 'mt': 'AraGPT2: Trasformatur imħarreġ minn qabel għall-Ġenerazzjoni tal-Lingwa Għarbija', 'mn': 'AraGPT2: Араб хэл төрөлхтний өмнө дасгал хөгжүүлэгч', 'pl': 'AraGPT2: Wstępnie przeszkolony transformator do generowania języka arabskiego', 'ro': 'AraGPT2: Transformator pre-instruit pentru generarea limbii arabe', 'no': 'AraGPT2: Førehandsformerer for arabisk språk', 'mk': 'AraGPT2: Преобучен трансформер за генерација арапски јазик', 'si': 'AraGPT2: අරාබි භාෂාව සිද්ධානය සඳහා ප්\u200dරධාන ප්\u200dරවෘත්තකය', 'sr': 'AraGPT2: Preobučeni transformator za generaciju arapskog jezika', 'sv': 'AraGPT2: Pre-Trained Transformer för arabiska språk generation', 'ta': 'AraGPT2: அரபி மொழி உருவாக்கத்திற்கு முன் பயிற்சி மொழிபெயர்ப்பு', 'so': 'AraGPT2: Turjubaal u baahan afka Carabiga', 'ms': 'AraGPT2: Penukar Latihan Terdahulu untuk Jenerasi Bahasa Arab', 'ur': 'AraGPT2: عربی زبان پیدائش کے لئے پیش ترین تغییر پھیلانے والا', 'uz': 'AraGPT2: Ereb tili yaratish uchun oldin tarjima', 'vi': 'AraGP2: Transformer Tua hình cho chế độ ngôn ngữ Ả Rập.', 'bg': 'Предварително обучен трансформатор за генериране на арабски език', 'da': 'AraGPT2: Pre-Trænet Transformer til Arabisk Sprog Generation', 'nl': 'AraGPT2: Vooropgeleide Transformator voor Arabische Taalgeneratie', 'hr': 'AraGPT2: Preobučeni transformator za generaciju arapskog jezika', 'ko': 'AraGPT2: 아랍어 생성을 위한 사전 트레이닝 변환기', 'de': 'AraGPT2: Vortrainierter Transformator für die Generierung arabischer Sprache', 'sw': 'AraGPT2: Tafsiri ya zamani kwa ajili ya Uzalishaji wa lugha ya Kiarabu', 'tr': 'AraGPT2: Arapça dil döredilmesi üçin öňünden eğitilen terjimeçi', 'af': 'AraGPT2: Vooroefende Transformeerder vir Arabiese Taal Genereering', 'sq': 'AraGPT2: Transformues i stërvitur për Gjenerimin e Gjuhave Arabe', 'am': 'AraGPT2: Pre-trained Translators for Arabic language Generation', 'hy': 'ԱրաGPT2: Արաբական լեզվի ստեղծման նախապատրաստված վերափոխողը', 'az': 'AraGPT2', 'bn': 'আরজিপিটি২: আরবী ভাষা প্রজন্মের জন্য পূর্ববর্তী প্রশিক্ষিত অনুবাদক', 'bs': 'AraGPT2: Preobučeni transformator za generaciju arapskog jezika', 'ca': 'AraGPT2: Transformador pré-capacitat per a la generació de llenguatges àrabs', 'cs': 'AraGPT2: Předškolený transformátor pro generování arabského jazyka', 'et': 'AraGPT2: AraGPT2: Araabia keele generatsiooni eelõpetatud transformaator', 'fi': 'AraGPT2: Pre-Trained Transformer for Arabic Language Generation', 'id': 'AraGPT2: Pre-Trained Transformer for Arabic Language Generation', 'fa': 'AraGPT2: تغییردهنده پیش آموزش برای تولید زبان عربی', 'ha': 'KCharselect unicode block name', 'sk': 'AraGPT2: Predusposobljen transformator za generacijo arabskega jezika', 'he': 'AraGPT2: Transformer מוכשר מראש ליצירת שפת ערבית', 'jv': 'araPPT 2: Transformer siji Rasak Teko nggo Generasi Language', 'bo': 'AraGPT2: Pre-Trained Transformer for Arabic Language Generation'}
{'en': 'Recently, pre-trained transformer-based architectures have proven to be very efficient at language modeling and understanding, given that they are trained on a large enough corpus. Applications in language generation for Arabic are still lagging in comparison to other NLP advances primarily due to the lack of advanced Arabic language generation models. In this paper, we develop the first advanced Arabic language generation model, AraGPT2, trained from scratch on a large Arabic corpus of internet text and news articles. Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available. The mega model was evaluated and showed success on different tasks including synthetic news generation, and zero-shot question answering. For text generation, our best model achieves a perplexity of 29.8 on held-out Wikipedia articles. A study conducted with human evaluators showed the significant success of AraGPT2-mega in generating news articles that are difficult to distinguish from articles written by humans. We thus develop and release an automatic discriminator model with a 98 % percent accuracy in detecting model-generated text. The models are also publicly available, hoping to encourage new research directions and applications for Arabic NLP.', 'ar': 'في الآونة الأخيرة ، أثبتت البنى القائمة على المحولات المدربة مسبقًا أنها فعالة للغاية في نمذجة اللغة وفهمها ، نظرًا لأنها مدربة على مجموعة كبيرة بما يكفي. لا تزال التطبيقات في مجال إنشاء اللغة للغة العربية متأخرة مقارنة بالتطورات الأخرى في البرمجة اللغوية العصبية ، ويرجع ذلك أساسًا إلى عدم وجود نماذج متقدمة لتوليد اللغة العربية. في هذه الورقة ، قمنا بتطوير أول نموذج متقدم لتوليد اللغة العربية ، AraGPT2 ، تم تدريبه من الصفر على مجموعة كبيرة من النصوص والمقالات الإخبارية على الإنترنت باللغة العربية. أكبر نموذج لدينا ، AraGPT2-mega ، يحتوي على 1.46 مليار متغير ، مما يجعله أكبر نموذج متاح باللغة العربية. تم تقييم النموذج الضخم وأظهر نجاحه في مهام مختلفة بما في ذلك توليد الأخبار التركيبية والإجابة على الأسئلة بدون طلقة. بالنسبة لتوليد النص ، يحقق أفضل نموذج لدينا ارتباكًا قدره 29.8 في مقالات ويكيبيديا المعلقة. أظهرت دراسة أجريت مع مقيمين بشريين النجاح الكبير لـ AraGPT2-mega في إنشاء مقالات إخبارية يصعب تمييزها عن المقالات التي كتبها البشر. وبالتالي فإننا نطور ونصدر نموذجًا للمميز التلقائي بدقة 98٪ في اكتشاف النص الناتج عن النموذج. النماذج متاحة للجمهور أيضًا ، على أمل تشجيع اتجاهات وتطبيقات بحثية جديدة للغة العربية البرمجة اللغوية العصبية.', 'fr': "Récemment, les architectures basées sur des transformateurs pré-entraînées se sont révélées très efficaces pour la modélisation et la compréhension du langage, étant donné qu'elles sont formées sur un corpus suffisamment important. Les applications dans la génération de langues pour l'arabe sont toujours en retard par rapport aux autres avancées de la PNL, principalement en raison du manque de modèles avancés de génération de la langue arabe. Dans cet article, nous développons le premier modèle avancé de génération de langue arabe, AraGPT2, formé de toutes pièces sur un vaste corpus arabe de textes et d'articles de presse sur Internet. Notre plus grand modèle, ARAGPT2-Mega, compte 1,46 milliard de paramètres, ce qui en fait le plus grand modèle de langue arabe disponible. Le méga modèle a été évalué et a montré son succès sur différentes tâches, y compris la génération de nouvelles synthétiques et la réponse aux questions sans réponse. Pour la génération de texte, notre meilleur modèle atteint une perplexité de 29,8 sur les articles Wikipédia diffusés. Une étude menée auprès d'évaluateurs humains a montré le succès significatif d'ARAGPT2-Mega dans la production d'articles de presse difficiles à distinguer des articles écrits par des humains. Nous développons et publions donc un modèle de discrimination automatique avec une précision de 98\xa0% pour la détection du texte généré par le modèle. Les modèles sont également accessibles au public, dans l'espoir d'encourager de nouvelles orientations de recherche et de nouvelles applications pour la PNL arabe.", 'es': 'Recientemente, las arquitecturas preentrenadas basadas en transformadores han demostrado ser muy eficientes en el modelado y la comprensión del lenguaje, dado que están capacitadas en un corpus lo suficientemente grande. Las aplicaciones en la generación de idiomas para el árabe siguen estando rezagadas en comparación con otros avances de la PNL, principalmente debido a la falta de modelos avanzados de generación de idioma árabe. En este artículo, desarrollamos el primer modelo avanzado de generación de lengua árabe, AraGPT2, entrenado desde cero en un gran corpus árabe de textos de Internet y artículos de noticias. Nuestro modelo más grande, ARAGPT2-mega, tiene 1460 millones de parámetros, lo que lo convierte en el modelo de idioma árabe más grande disponible. El mega modelo fue evaluado y mostró éxito en diferentes tareas, incluida la generación de noticias sintéticas y la respuesta a preguntas de tiro cero. Para la generación de texto, nuestro mejor modelo logra una perplejidad de 29.8 en los artículos de Wikipedia publicados. Un estudio realizado con evaluadores humanos mostró el éxito significativo de ARAGPT2-mega en la generación de artículos de noticias que son difíciles de distinguir de los artículos escritos por humanos. Por lo tanto, desarrollamos y lanzamos un modelo discriminador automático con una precisión del 98% en la detección del texto generado por el modelo. Los modelos también están disponibles públicamente, con la esperanza de fomentar nuevas direcciones de investigación y aplicaciones para la PNL árabe.', 'pt': 'Recentemente, arquiteturas baseadas em transformadores pré-treinadas provaram ser muito eficientes na modelagem e compreensão da linguagem, uma vez que são treinadas em um corpus grande o suficiente. As aplicações na geração de idiomas para o árabe ainda estão atrasadas em comparação com outros avanços da PNL, principalmente devido à falta de modelos avançados de geração do idioma árabe. Neste artigo, desenvolvemos o primeiro modelo avançado de geração de língua árabe, AraGPT2, treinado do zero em um grande corpus árabe de texto da internet e artigos de notícias. Nosso maior modelo, AraGPT2-mega, possui 1,46 bilhão de parâmetros, o que o torna o maior modelo de idioma árabe disponível. O megamodelo foi avaliado e mostrou sucesso em diferentes tarefas, incluindo geração de notícias sintéticas e resposta a perguntas de tiro zero. Para geração de texto, nosso melhor modelo atinge uma perplexidade de 29,8 em artigos da Wikipédia retidos. Um estudo realizado com avaliadores humanos mostrou o sucesso significativo do AraGPT2-mega na geração de notícias difíceis de distinguir de artigos escritos por humanos. Assim, desenvolvemos e lançamos um modelo de discriminador automático com 98% de precisão na detecção de texto gerado pelo modelo. Os modelos também estão disponíveis publicamente, esperando encorajar novas direções de pesquisa e aplicações para a PNL árabe.', 'ja': '最近、事前訓練された変圧器ベースのアーキテクチャは、十分に大きなコーパスで訓練されていることを考えると、言語モデリングと理解において非常に効率的であることが証明されています。 アラビア語のための言語生成における応用は、主に高度なアラビア語生成モデルの欠如のために、他のNLPの進歩と比較して依然として遅れている。 この論文では、インターネットのテキストやニュース記事の大規模なアラビア語コーパスでゼロから訓練された、最初の高度なアラビア語生成モデルAraGPT 2を開発しました。 当社の最大のモデルであるAraGPT 2 - megaには14.6億のパラメータがあり、利用可能な最大のアラビア語モデルとなっています。 メガモデルは評価され、合成ニュース生成、ゼロショットの質問応答など、さまざまなタスクで成功を収めました。 テキスト生成のために、当社のベストモデルは、ホールドアウトされたウィキペディアの記事で29.8の複雑さを達成します。 ヒト評価者を対象に実施した研究では、ヒトが書いた記事と区別しにくいニュース記事を生成するAraGPT 2 - megaの有意な成功が示された。 したがって、モデル生成テキストの検出に98 ％の精度を持つ自動識別モデルを開発し、リリースします。 これらのモデルはまた、アラビア語NLPの新しい研究方向と応用を奨励することを望んで、一般に公開されています。', 'zh': '近者,豫教之本于转换器架构已验于言建模解之甚效,盖足以大语料库也。 比诸NLP进步,阿拉伯语言生而用滞后,此无先进之阿拉伯语也。 先入者阿拉伯语成模AraGPT2,先大者阿拉伯语语料库互联网文新闻从头始。 吾大形AraGPT2-mega有14.6亿个参数,此其大阿拉伯语也。 质于大体,异务而成,合新闻成零镜头问。 文本之生,维基百科文之惑29.8。 一与人物论明,AraGPT2-mega于生成难与文章分别者新闻文章取重大成功。 是以发一自动鉴别器,检其本98%准确率。 此亦明矣,愿阿拉伯语NLP新究方用。', 'ru': 'В последнее время предварительно обученные архитектуры на основе трансформаторов доказали свою высокую эффективность в языковом моделировании и понимании, учитывая, что они обучены на достаточно большом корпусе. По сравнению с другими достижениями NLP заявки на создание языка на арабском языке все еще отстают, в первую очередь из-за отсутствия передовых моделей создания языка на арабском языке. В этой статье мы разрабатываем первую передовую модель генерации арабского языка, AraGPT2, обученную с нуля на большом арабском корпусе интернет-текста и новостных статей. Наша самая большая модель, AraGPT2-mega, имеет 1,46 миллиарда параметров, что делает ее самой большой доступной моделью арабского языка. Мегамодель была оценена и показала успех в различных задачах, включая генерацию синтетических новостей и ответы на вопросы с нулевым выстрелом. Для генерации текста наша лучшая модель достигает растерянности в 29,8 по невыполненным статьям Википедии. Исследование, проведенное с оценщиками человека, показало значительный успех AraGPT2-mega в создании новостных статей, которые трудно отличить от статей, написанных людьми. Таким образом, мы разрабатываем и выпускаем автоматическую модель дискриминатора с 98% точностью в обнаружении текста, сгенерированного моделью. Модели также общедоступны, надеясь стимулировать новые направления исследований и применения для арабского NLP.', 'hi': 'हाल ही में, पूर्व-प्रशिक्षित ट्रांसफॉर्मर-आधारित आर्किटेक्चर भाषा मॉडलिंग और समझ में बहुत कुशल साबित हुए हैं, यह देखते हुए कि उन्हें एक बड़े पर्याप्त कॉर्पस पर प्रशिक्षित किया जाता है। अरबी के लिए भाषा पीढ़ी में अनुप्रयोग अभी भी अन्य एनएलपी अग्रिमों की तुलना में पिछड़ रहे हैं, मुख्य रूप से उन्नत अरबी भाषा पीढ़ी मॉडल की कमी के कारण। इस पेपर में, हम पहले उन्नत अरबी भाषा पीढ़ी मॉडल, AraGPT2, इंटरनेट पाठ और समाचार लेख के एक बड़े अरबी कॉर्पस पर खरोंच से प्रशिक्षित विकसित करते हैं। हमारे सबसे बड़े मॉडल, AraGPT2-मेगा में 1.46 बिलियन पैरामीटर हैं, जो इसे उपलब्ध सबसे बड़ा अरबी भाषा मॉडल बनाता है। मेगा मॉडल का मूल्यांकन किया गया था और सिंथेटिक समाचार पीढ़ी सहित विभिन्न कार्यों पर सफलता दिखाई गई थी, और शून्य-शॉट प्रश्न का उत्तर दिया गया था। पाठ पीढ़ी के लिए, हमारा सबसे अच्छा मॉडल आयोजित किए गए विकिपीडिया लेखों पर 29.8 की एक उलझन प्राप्त करता है। मानव मूल्यांकनकर्ताओं के साथ किए गए एक अध्ययन ने समाचार लेखों को उत्पन्न करने में AraGPT2-मेगा की महत्वपूर्ण सफलता को दिखाया जो मनुष्यों द्वारा लिखे गए लेखों से अलग करना मुश्किल है। इस प्रकार हम मॉडल-जनित पाठ का पता लगाने में 98% प्रतिशत सटीकता के साथ एक स्वचालित भेदभावपूर्ण मॉडल विकसित और जारी करते हैं। मॉडल भी सार्वजनिक रूप से उपलब्ध हैं, अरबी एनएलपी के लिए नए शोध दिशाओं और अनुप्रयोगों को प्रोत्साहित करने की उम्मीद करते हैं।', 'ga': 'Le déanaí, tá cruthaithe go bhfuil ailtireachtaí réamh-oilte atá bunaithe ar chlaochladáin an-éifeachtach maidir le múnlú agus tuiscint teanga, ós rud é go bhfuil siad oilte ar chorpas mór go leor. Tá iarratais i nginiúint teanga don Araibis fós chun deiridh i gcomparáid le dul chun cinn eile NLP go príomha mar gheall ar an easpa samhlacha giniúna teanga Araibis chun cinn. Sa pháipéar seo, forbraímid an chéad mhúnla ardghinte teanga Araibise, AraGPT2, atá oilte ón tús ar chorpas mór Araibis de théacs idirlín agus d’ailt nuachta. Tá 1.46 billiún paraiméadair ag ár múnla is mó, AraGPT2-mega, rud a fhágann gurb é an tsamhail teanga Araibis is mó atá ar fáil. Rinneadh meastóireacht ar an tsamhail mega agus léirigh sé rath ar thascanna éagsúla lena n-áirítear giniúint nuachta shintéiseach, agus freagairt ceisteanna gan lámhaigh. Maidir le giniúint téacs, baineann ár múnla is fearr amach perplexity de 29.8 ar ailt Vicipéid atá fágtha amach. Léirigh staidéar a rinneadh le meastóirí daonna rath suntasach AraGPT2-mega maidir le hailt nuachta a ghiniúint atá deacair idirdhealú a dhéanamh idir ailt a scríobh daoine. Mar sin déanaimid múnla uathoibríoch idirdhealaithe a fhorbairt agus a scaoileadh le cruinneas 98% faoin gcéad maidir le téacs samhail-ghinte a bhrath. Tá na samhlacha ar fáil go poiblí freisin, ag súil treoracha taighde nua agus iarratais ar NLP Araibis a spreagadh.', 'hu': 'A közelmúltban az előre képzett transzformátor alapú architektúrák nagyon hatékonynak bizonyultak a nyelvi modellezésben és megértésben, mivel elég nagy korpuszon képezték őket. Az arab nyelv generálására vonatkozó alkalmazások továbbra is lemaradnak a többi NLP előrehaladáshoz képest, elsősorban a fejlett arab nyelv generálási modellek hiánya miatt. Ebben a tanulmányban fejlesztjük ki az első fejlett arab nyelv generációs modellt, az AraGPT2-t, amelyet a semmiből képzett egy nagy arab korpusz internetes szöveg és hírek. A legnagyobb modellünk, az AraGPT2-mega, 1,46 milliárd paraméterrel rendelkezik, ami a legnagyobb arab nyelvű modellt teszi lehetővé. A mega modellt értékelték és sikeresen mutatták különböző feladatokban, beleértve a szintetikus hírek generálását és a nulla lövéses kérdések megválaszolását. A szöveggeneráláshoz a legjobb modellünk 29.8-as zavart ér el a kitartott Wikipédia cikkeken. Egy emberi értékelőkkel végzett tanulmány kimutatta, hogy az AraGPT2-mega jelentős sikert hozott létre olyan hírek készítésében, amelyeket nehéz megkülönböztetni az emberek által írt cikkektől. Így kifejlesztünk és kiadunk egy 98%-os pontossággal rendelkező automatikus diszkriminátor modellt a modellek által generált szövegek felismerésében. A modellek nyilvánosan hozzáférhetők, remélve, hogy új kutatási irányokat és alkalmazásokat ösztönöznek az arab NLP-re.', 'ka': 'მიმდინარე, პრეტრანსტრინსტრინსტრინსტრინსტრინსტრინსტრინსტრიქტური აქტიქტრიქტურები გამოწვება ძალიან ეფექტიურია ენის მოდელირებაში და გაგრძნობაში,  ადრების წარმოდგენისთვის პროგრამები უკვე დარჩენება სხვა NLP წარმოდგენისთვის, რომლებიც წარმოდგენით აპაბული ენის წარმოდგენისთვის მოდელების არაა. ამ დომენტში, ჩვენ პირველი განვითარებული აპაბური ენის წარმოდგენის მოდელს, AraGPT2, რომელიც ინტერნეტის ტექსტის და ახალგაზომის დიდი აპაბური კორპუსზე განვითარებულია. ჩვენი უფრო დიდი მოდელი, AraGPT2-mega, აქვს 1,46 მილიარდი პარამეტრები, რომელიც მისი უფრო დიდი აპაბული ენის მოდელი დახმარება. მეგმა მოდელის განსაზღვრება იყო და გამოჩვენება სექსია განსხვავებული საქმების შესახებ სინტეტიკური ნუტაციის შესახებ, და 0-სტატის კითხვის გასაგები ტექსტის წარმოდგენისთვის, ჩვენი საუკეთესო მოდელი 29.8 წარმოდგენა საკეთესო წარმოდგენისთვის. ადამიანის განსაზღვრებით გავაკეთებული სწავლება აპაGPT2-mega-ის მნიშვნელოვანი წარმატების შემდეგ ახალგაზრულების შექმნა, რომლებიც ადამიანის წერილიდან განსხვავება ძალიან რ ამიტომ ჩვენ ავტომატური დისკრიმინატორის მოდელის განვითარებით 98% წუთით წარმოადგენა მოდელის შექმნა ტექსტის განვითარებით. მოდელები უბრალოდ აქვს, რომელიც იმედია ახალი სწავლობა და პროგრამები არაბული NLP-ისთვის.', 'el': 'Πρόσφατα, οι προ-εκπαιδευμένες αρχιτεκτονικές βασισμένες σε μετασχηματιστές έχουν αποδειχθεί πολύ αποτελεσματικές στη μοντελοποίηση και κατανόηση γλωσσών, δεδομένου ότι εκπαιδεύονται σε ένα αρκετά μεγάλο σώμα. Οι εφαρμογές στη δημιουργία γλωσσών για τα αραβικά εξακολουθούν να υστερούν σε σύγκριση με άλλες εξελίξεις κυρίως λόγω της έλλειψης προηγμένων μοντέλων αραβικής γλώσσας. Σε αυτή την εργασία, αναπτύσσουμε το πρώτο προηγμένο μοντέλο παραγωγής αραβικής γλώσσας, εκπαιδευμένο από το μηδέν σε ένα μεγάλο αραβικό σώμα κειμένων και άρθρων ειδήσεων στο διαδίκτυο. Το μεγαλύτερο μοντέλο μας, έχει παραμέτρους 1.46 δισεκατομμυρίων, γεγονός που το καθιστά το μεγαλύτερο διαθέσιμο μοντέλο αραβικής γλώσσας. Το μέγα μοντέλο αξιολογήθηκε και έδειξε επιτυχία σε διάφορες εργασίες, συμπεριλαμβανομένης της δημιουργίας συνθετικών ειδήσεων και της απάντησης σε ερωτήσεις μηδενικού πυροβολισμού. Για τη δημιουργία κειμένου, το καλύτερο μοντέλο μας επιτυγχάνει μια σύγχυση 29.8 σε καθυστερημένα άρθρα της Βικιπαίδειας. Μια μελέτη που διεξήχθη με ανθρώπους αξιολογητές έδειξε τη σημαντική επιτυχία του στην παραγωγή ειδησεογραφικών άρθρων που είναι δύσκολο να διακριθούν από άρθρα γραμμένα από ανθρώπους. Έτσι αναπτύσσουμε και απελευθερώνουμε ένα αυτόματο μοντέλο διάκρισης με ακρίβεια 98% στην ανίχνευση κειμένου που παράγεται από μοντέλο. Τα μοντέλα είναι επίσης διαθέσιμα στο κοινό, ελπίζοντας να ενθαρρύνουν νέες ερευνητικές κατευθύνσεις και εφαρμογές για τα αραβικά.', 'kk': 'Соңғы уақытта, алдын- оқылған түрлендіруші архитектуралар тілдерді моделдеу және түсініктеу үшін, олар жеткілікті корпус арқылы оқылған. Араб тілдерін құру үшін қолданбалар әлі басқа NLP бағдарламасына салыстырып қалды, негізінде араб тілдерін құру үлгілері жоқ деген үшін. Бұл қағазда бірінші араб тілді құру үлгісін, AraGPT2, интернет мәтінді және жаңалық мақалаларының үлкен араб корпусынан жасалған. Біздің ең үлкен үлгіміз, AraGPT2-mega, 1,46 млрд. параметрлері бар. Бұл үлкен араб тілінің үлкен үлгісін қол жеткізеді. Мега үлгісі бағалады және синтетикалық жаңалық құрылуы және нөл сұрақ жауап беру үшін басқа тапсырмалардың сәттілігін көрсетті. Мәтін құру үшін, ең жақсы моделіміз Википедия мақалаларының 29,8 жазылмауын жеткізеді. Адам бағалаушыларымен істеген зерттеу адамдар жазылған мақалалардан айырмашылық жаңалық мақалаларды құру үшін AraGPT2-mega-ның маңызды сәтті көрсетті. Біз бұл үлгі құрылған мәтінді анықтау үшін 98% деген автоматты дискриминатор үлгісін жасап, шығару үлгісін шығару. Бұл үлгілер де көпшілікті қол жеткізілген, жаңа зерттеу бағыттарын және Араб NLP үшін қолданбаларды көмектесу үшін.', 'it': "Recentemente, architetture pre-addestrate basate su trasformatori hanno dimostrato di essere molto efficienti nella modellazione e comprensione del linguaggio, dato che sono addestrate su un corpus abbastanza grande. Le applicazioni nella generazione delle lingue per l'arabo sono ancora in ritardo rispetto ad altri progressi NLP principalmente a causa della mancanza di modelli avanzati di generazione della lingua araba. In questo articolo, sviluppiamo il primo modello avanzato di generazione della lingua araba, AraGPT2, addestrato da zero su un grande corpus arabo di testi e articoli di notizie su Internet. Il nostro modello più grande, AraGPT2-mega, ha 1,46 miliardi di parametri, il che lo rende il più grande modello di lingua araba disponibile. Il mega modello è stato valutato e ha mostrato successo su diversi compiti tra cui la generazione di notizie sintetiche e la risposta alle domande zero-shot. Per la generazione di testo, il nostro modello migliore raggiunge una perplessità di 29,8 su articoli di Wikipedia. Uno studio condotto con valutatori umani ha mostrato il significativo successo di AraGPT2-mega nella generazione di articoli di notizie difficili da distinguere dagli articoli scritti da esseri umani. Sviluppiamo e rilasciamo un modello discriminatore automatico con una precisione del 98% nel rilevamento del testo generato dal modello. I modelli sono anche pubblicamente disponibili, sperando di incoraggiare nuove direzioni di ricerca e applicazioni per il PNL arabo.", 'lt': 'Pastaruoju metu iš anksto parengtos transformatorių architektūros yra labai veiksmingos kalbų modeliavimo ir supratimo srityje, atsižvelgiant į tai, kad jos mokomos pakankamai dideliu korpusu. Kalbų kūrimo paraiškos arabų kalba vis dar atsilieka, palyginti su kitomis NLP pažanga, visų pirma dėl pažangių arabų kalbų kūrimo modelių trūkumo. Šiame dokumente parengiame pirmąjį pažangią arabų kalbų generacijos model į AraGPT2, kuris iš pradžių buvo apmokytas dideliu arabų tekstų ir naujienų korpusu. Mūsų didžiausias modelis, AraGPT2-mega, turi 1,46 milijardo parametrų, todėl jis yra didžiausias arabų kalbos modelis. Didelis modelis buvo įvertintas ir parodė sėkmę įvairiose užduotyse, įskaitant sintetinių naujienų kūrimą, ir atsakymą į nulinius klausimus. Tekstų kūrimui mūsų geriausias modelis sukuria 29,8 perpleksiją dėl išsaugotų Wikipedia straipsnių. Su žmogaus vertintojais atliktas tyrimas parodė, kad AraGPT2-mega sėkmingai sukūrė naujienų straipsnius, kuriuos sunku atskirti nuo žmonių rašytų straipsnių. We thus develop and release an automatic discriminator model with a 98% percent accuracy in detecting model-generated text.  Modeliai taip pat yra prieinami visuomenei, tikintis skatinti naujas mokslinių tyrimų kryptis ir paraiškas arabų NLP.', 'ml': 'അടുത്തുതന്നെ പരിശീലിക്കപ്പെട്ട മാറ്റങ്ങളുടെ അടിസ്ഥാനത്തിലുള്ള ആര്\u200dക്കിട്ടുകള്\u200d ഭാഷ മോഡലിങ്ങിലും ബുദ്ധിമുട്ടിലും വളരെ സാധ്യതയുള അറബി തലമുറയ്ക്കുള്ള പ്രയോഗങ്ങള്\u200d മറ്റുള്ള NLP മുന്\u200dഗണങ്ങളോടൊപ്പം താരതമ്യം ചെയ്യുന്നുണ്ട്. പ്രധാനപ്പെട്ട അറബി തലമു ഈ പത്രത്തില്\u200d നമ്മള്\u200d ആദ്യത്തെ മുന്നറിയിപ്പുള്ള അറബി ഭാഷയുടെ തലമുറതലമുറയില്\u200d നിന്നും പഠിപ്പിക്കുന്നു. ഇന്റര്\u200dനെറ്റ് ടെക്സ നമ്മുടെ ഏറ്റവും വലിയ മോഡല്\u200d, അരാജിപിടി2-മെഗ, 1.46 ബില്ല്യണ്\u200d പരാമീറ്റര്\u200d ഉണ്ട്, അത് ഏറ്റവും വലിയ അറബി ഭാഷയിലെ മോഡല്\u200d ലഭ്യമാക്കു മെഗാ മോഡല്\u200d പരിഗണിക്കപ്പെടുകയും വ്യത്യസ്തമായ ജോലികളില്\u200d വിജയം കാണിക്കുകയും ചെയ്തു. സിന്റീറ്റിക്ക് വാര്\u200dത്തകള ടെക്സ്റ്റ് തലമുറയ്ക്കായി നമ്മുടെ ഏറ്റവും നല്ല മോഡല്\u200d 29. 8 വിക്കിപീഡിയയുടെ പാര്\u200dട്ടുകളില്\u200d ഒരു പ്രശ്നമുണ്ട മനുഷ്യരുടെ വിലാസക്കാരോടൊപ്പം നടത്തിയ ഒരു പഠനം മനുഷ്യരാല്\u200d എഴുതിയ പാര്\u200dത്തകളില്\u200d നിന്നും വേര്\u200dതിരിച്ചുവെക്കാന്\u200d പ്രയാസമുള്ള വി അതുകൊണ്ട് നമ്മള്\u200d ഒരു സ്വയമായ വ്യത്യാസീകരിക്കുന്ന മോഡല്\u200d പുറപ്പെടുത്തുകയും ചെയ്യുന്നു. മോഡല്\u200d സൃഷ്ടിക്കുന്ന വാച ഈ മോഡലുകളും പ്രസ്താവികമായി ലഭ്യമല്ല, പുതിയ പഠിപ്പിക്കുന്ന നേര്\u200dവഴികളും പ്രയോഗങ്ങളും ആശ്രയിക്കുന്നതിന', 'mk': 'Неодамна, предобучени трансформаторски архитектури се докажаа дека се многу ефикасни во моделирањето и разбирањето на јазиците, со оглед на тоа што се обучени на доволно голем корпус. Апликациите во генерацијата на јазици за арапски сé уште задоцнуваат во споредба со другите напредоци на НЛП, главно поради недостатокот на напредени модели за генерација на арапски јазик. Во овој весник, го развиваме првиот напредок модел на генерација на арапски јазик, АраГПТ2, обучен од нула на голем арапски корпус на интернет текст и вести. Нашиот најголем модел, АраГПТ2-мега, има 1,46 милијарди параметри, што го прави најголемиот арапски модел достапен. The mega model was evaluated and showed success on different tasks including synthetic news generation, and zero-shot question answering.  За генерацијата на текст, нашиот најдобар модел постигнува загатка од 29,8 на издржаните статии на Википедија. Студијата спроведена со човечки евалуатори покажа значителен успех на АраГПТ2-мега во генерирањето новински статии кои се тешки да се разликуваат од статиите напишани од луѓето. Така развиваме и ослободуваме автоматски дискриминаторски модел со 98% точност во детектирањето на текст генериран од модел. Моделите се, исто така, јавно достапни, со надеж дека ќе охрабрат нови истражувачки насоки и апликации за арапската НЛП.', 'mn': 'Сүүлийн үед сургалтын өмнө сургалтын өөрчлөгчийн барилгууд хэлний загвар болон ойлголтын тулд маш үр дүнтэй гэдгийг баталсан. Араб хэл төрөлхтний програм нь бусад NLP хөгжлийн хувьд харьцуулахад хамаагүй байна. Ялангуяа Араб хэл төрөлхтний загваруудын тулд улам хөгжлийн загварууд байхгүй. Энэ цаасан дээр бид анхны хөгжсөн Араб хэлний бүтээлийн загвар, АраGPT2, интернет текст болон мэдээллийн бүтээлүүдийн том Араб корпус дээр суралцагдсан. Бидний хамгийн том загвар, AraGPT2-mega, 1.46 тэрбум параметр байна. Энэ нь үүнийг хамгийн том Араб хэл загвартай болгодог. Мега загварыг үнэлгээд, шинжлэх ухааны шинжлэх ухааны үйлдлийн амжилтыг харуулсан. Мөн тэр асуулт асуусан. Текст үеийн хувьд бидний хамгийн шилдэг загвар нь Википедийн баримтууд дээр 29.8 гарч ирдэг. Хүн төрөлхтний оюутнуудын судалгаагаар хийсэн судалгаагаар хүмүүсийн бичсэн баримтуудаас ялгах хэцүү мэдээллийн баримтуудыг бүтээхэд AraGPT2-mega-ын чухал амжилтыг харуулсан. Тиймээс бид загвар бүтээгдэхүүний текст олж мэдэхийн тулд автоматически ялгаагч загварын загварыг 98% нь тодорхойлдог. Энэ загварууд мөн олон нийтэд ашиглаж байна. Араб НLP-ын шинэ судалгааны загварууд болон хэрэглээ дэмжих гэж найдаж байна.', 'pl': 'Ostatnio wstępnie przeszkolone architektury oparte na transformatorach okazały się bardzo skuteczne w modelowaniu i zrozumieniu języka, biorąc pod uwagę, że są one szkolone na wystarczająco dużym korpusie. Aplikacje w generowaniu języków dla języka arabskiego wciąż opóźniają się w porównaniu z innymi postępami NLP głównie ze względu na brak zaawansowanych modeli generowania języka arabskiego. W niniejszym artykule opracowujemy pierwszy zaawansowany model generacji języka arabskiego, AraGPT2, przeszkolony od podstaw na dużym arabskim korpusie tekstów internetowych i artykułów wiadomościowych. Nasz największy model, AraGPT2-mega, posiada 1,46 miliardy parametrów, co czyni go największym dostępnym modelem języka arabskiego. Model mega został oceniony i wykazał sukces w różnych zadaniach, w tym generowaniu wiadomości syntetycznych i odpowiedzi na pytania zero-shot. W przypadku generowania tekstu nasz najlepszy model osiąga zagadkę 29,8 w przestrzeganych artykułach Wikipedii. Badanie przeprowadzone z ludźmi oceniającymi wykazało znaczący sukces AraGPT2-mega w generowaniu artykułów wiadomościowych trudnych do odróżnienia od artykułów pisanych przez ludzi. W ten sposób opracowujemy i udostępniamy model automatycznego dyskryminatora o dokładności 98% w wykrywaniu tekstu generowanego przez model. Modele są również publicznie dostępne, mając nadzieję zachęcić do nowych kierunków badań i zastosowań dla arabskiego NLP.', 'no': 'Nyleg har det vist at første transformasjonsbaserte arkitekturar er svært effektiv på språk modellering og forståking, dersom dei er trent på ein stor nok korpus. Programmer i språk-generering for arabisk er fortsatt i sammenligning med andre NLP-avansert hovudsakelig på grunn av manglar avanserte arabiske språk-genereringsmodeller. I denne papiret utviklar vi den første avanserte arabiske språk-genereringsmodellen, AraGPT2, som trengte frå skrap på ein stor arabisk korpus av internett-tekst og nye artikler. Vår største modell, AraGPT2-mega, har 1,46 milliarder parametra, som gjer det største arabiske språk-modellen tilgjengeleg. Mega-modellen vart evaluert og vist suksess på ulike oppgåver, inkludert syntetiske nyhetsgenering, og svar på spørsmål med nullsatt. For å laga tekst, har vår beste modell nådd ein forskjellig av 29,8 på innlegg i Wikipedia. Eit studie gjennomført med menneskelige evalueringar viste den signifikante suksessen av AraGPT2-mega i å laga nye artiklar som er vanskeleg å skilja seg frå artiklar skriven av mennesker. Vi utviklar og løyser ut eit automatisk diskrimineringsmodell med ein 98 prosent nøyaktig i oppdaging av modellelaga tekst. Modellene er også tilgjengelege offentlig, og håper å oppretta nye forskningsretningar og program for arabisk NLP.', 'ms': 'Baru-baru ini, arkitektur berdasarkan pengubah terlatih telah terbukti sangat efisien dalam pemodelan dan pemahaman bahasa, kerana mereka dilatih pada korpus yang cukup besar. Aplikasi dalam generasi bahasa untuk bahasa Arab masih tertinggal dibandingkan dengan kemajuan NLP lainnya terutama kerana kekurangan model generasi bahasa Arab yang maju. Dalam kertas ini, kami mengembangkan model generasi bahasa Arab yang maju pertama, AraGPT2, dilatih dari awal pada korpus Arab besar teks internet dan artikel berita. Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available.  Model mega telah diuji dan menunjukkan sukses pada tugas yang berbeza termasuk generasi berita sintetik, dan jawapan soalan-tembakan sifar. Untuk generasi teks, model terbaik kita mencapai kekacauan 29.8 pada artikel Wikipedia yang ditahan. A study conducted with human evaluators showed the significant success of AraGPT2-mega in generating news articles that are difficult to distinguish from articles written by humans.  Oleh itu, kami mengembangkan dan melepaskan model diskriminator automatik dengan akurat 98% dalam mengesan teks yang dijana model. Model ini juga tersedia secara umum, berharap untuk mendorong arah dan aplikasi penelitian baru untuk NLP Arab.', 'mt': 'Dan l-a ħħar, arkitetturi bbażati fuq trasformaturi mħarrġa minn qabel urew li huma effiċjenti ħafna fl-immudellar u l-fehim tal-lingwi, minħabba li huma mħarrġa fuq korpus kbir biżżejjed. Applications in language generation for Arabic are still lagging in comparison to other NLP advances primarily due to the lack of advanced Arabic language generation models.  F’dan id-dokument, a ħna niżviluppaw l-ewwel mudell avvanzat tal-ġenerazzjoni tal-lingwi Għarab, AraGPT2, imħarreġ mill-bidu fuq korpus Għarab kbir ta’ test tal-internet u artikoli tal-aħbarijiet. L-akbar mudell tagħna, AraGPT2-mega, għandu 1.46 biljun parametru, li jagħmilha disponibbli l-akbar mudell lingwistiku Għarbi. Il-mudell mega ġie evalwat u wera suċċess fuq kompiti differenti inkluż il-ġenerazzjoni sintetika tal-aħbarijiet, u tweġiba għal mistoqsijiet mingħajr skop. Għall-ġenerazzjoni tat-test, l-a ħjar mudell tagħna jikseb perplessità ta’ 29.8 fuq artikoli tal-Wikipedia miżmuma. Studju mwettaq ma’ evalwaturi umani wera s-suċċess sinifikanti ta’ AraGPT2-mega fil-ġenerazzjoni ta’ artikoli tal-aħbarijiet li huma diffiċli biex jiġu distinti mill-artikoli miktuba mill-bniedem. We thus develop and release an automatic discriminator model with a 98% percent accuracy in detecting model-generated text.  Il-mudelli huma disponibbli wkoll għall-pubbliku, li jittama li jinkoraġġixxu direzzjonijiet u applikazzjonijiet ġodda ta’ riċerka għall-NLP Għarab.', 'ro': 'Recent, arhitecturile pre-instruite bazate pe transformatori s-au dovedit a fi foarte eficiente în modelarea și înțelegerea limbilor, având în vedere că sunt instruite pe un corpus suficient de mare. Aplicațiile în generarea limbilor arabe sunt încă în întârziere în comparație cu alte progrese PNL, în principal din cauza lipsei modelelor avansate de generare a limbilor arabe. În această lucrare, dezvoltăm primul model avansat de generație a limbii arabe, AraGPT2, instruit de la zero pe un corpus arab mare de text și articole de știri pe internet. Cel mai mare model al nostru, AraGPT2-mega, are 1,46 miliarde de parametri, ceea ce îl face cel mai mare model de limbă arabă disponibil. Mega modelul a fost evaluat și a arătat succes în diferite sarcini, inclusiv generarea de știri sintetice și răspunsul la întrebări zero-shot. Pentru generarea de text, cel mai bun model al nostru atinge o perplexitate de 29.8 pe articolele Wikipedia susținute. Un studiu realizat cu evaluatori umani a arătat succesul semnificativ al AraGPT2-mega în generarea de articole de știri dificil de distins de articolele scrise de oameni. Astfel, dezvoltăm și lansăm un model de discriminare automată cu o precizie de 98% în detectarea textului generat de modele. Modelele sunt, de asemenea, disponibile publicului, sperând să încurajeze noi direcții de cercetare și aplicații pentru PNL arab.', 'so': "Hadii u dhowayd, dhismaha isbedelka ee horay lagu tababaray waxay caddaadeen inay si faa’iido ah u yihiin sameynta iyo waxgarashada luuqada, sababtoo ah in lagu baro korpus weyn oo ku filan. Dalbashada ku qoran qarniga afka Carabiga waxaa weli lagula dhigi karaa barbardhigga horumarinta kale ee NLP sababtoo ah baahida tusaalooyin kale oo afka Carabi ah. Kanu warqaddan, waxaynu horumarinaynaa modelka ugu horeeya qaranka afka Carabiga, AraGPT2, oo laga baray scratch aad u weyn xaraf internetka iyo warqadaha warqadaha. Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available.  Tusaale mega waxaa lagu qiimeeyay oo lagu muujiyey suucnimo ku saabsan shaqooyin kala duduwan, kuwaas oo ka mid ah qarniga warbixinta, iyo jawaabta su'aalaha nooca ah. Muuqashada qoraalka ee ugu wanaagsan ayaa sameynaya dhibaato 29.8 oo ku saabsan warqadaha Wikipedia la soo saaray. Waxbarasho lagu sameeyay qiimeeyayaasha dadku waxay muuqatay liibaanka muhiimka ah ee AraGPT2-mega in lagu sameeyo warqadaha warqada ee ay ku adag tahay in laga kala soocaa qoraalka dadka qoran. Sidaa darteed waxaynu horumarinnaa oo u bixinaynaa qaababka takoorida oo si rasmi ah u leh boqolkiiba 98 boqolkiiba si a an u ogaano qoraalka sameynta. Sidoo kale noocyada waxaa lagu heli karaa si bayaan ah, waxaan rajaynayaa in loo dhiirrigeliyo hagitaan waxbarashada cusub iyo codsiyada afka Carabiga NLP.", 'si': 'අවසානයෙන්, ප්\u200dරධාන ප්\u200dරවේශකයෙන් ස්ථාපනය කරලා තියෙන්නේ භාෂාව ප්\u200dරවේශකයෙන් හා තේරුම්ගත්වයෙන් ගොඩක් ප්\u200dරයෝජ අරාබි භාෂාව ප්\u200dරවෘතියෙන් භාෂාව ප්\u200dරවෘතියෙන් තාමත් අනිත් NLP ප්\u200dරවෘතියෙන් සම්බන්ධ වෙනුවෙන් ඉන්නේ  මේ පත්තරේ අපි පලවෙනි අරාබි භාෂා නිර්මාණය, AraGPT2, ලොකු අරාබි කොර්පුස් එකේ ඉන්ටර්නෙට් පාළුවක් සහ වාර්තාව පිළි අපේ ලොකු මොඩල්, AraGPT2-Mega, ප්\u200dරමාණයක් 1.46 බිලියන් තියෙනවා, ඒකෙන් ඒක ලොකු අරාබි භාෂාව ප්\u200dරමාණයක් ලැබෙන් මෙගා මොඩල් විශ්වාස කරලා තියෙන්නේ වෙනස් වැඩක් විදිහට සමහර වැඩක් ප්\u200dරශ්නයක් තියෙන්නේ, සහ ශූන්ය විකිපිඩියා ප්\u200dරතිපත්තියක් තියෙන්නේ අපේ හොඳම ප්\u200dරතිපත්තියක් අවස්ථාවක් 29.8 වලින් අවස්ථාවක් වෙනව මිනිස්සු විශ්වාස කරපු අධ්\u200dයානයක් පෙන්වන්න පුළුවන් AraGPT2-Mega ගේ විශේෂ සාර්ථක විශ්වාස කරන්න පුළුවන් විදිහට අපි ඉතින් ස්වයංක්\u200dරියාත්මක විශ්වාස කරනවා සහ ප්\u200dරතිචාරකයෙන් ප්\u200dරතිචාරකයෙක් ප්\u200dරතිචාරකයෙන් ප්\u200d මොඩේල් ලොකු විදියටත් ප්\u200dරතිකාරයෙන් පිළිබඳ වෙනවා, අලුත් පරීක්ෂණ ප්\u200dරවේශනය සහ අරාබි NLP සඳහා අ', 'sv': 'Nyligen har förutbildade transformatorbaserade arkitekturer visat sig vara mycket effektiva på språkmodellering och förståelse, med tanke på att de är utbildade på en tillräckligt stor korpus. Tillämpningarna för språkgenerering för arabiska släpar fortfarande efter jämfört med andra framsteg inom NLP främst på grund av bristen på avancerade modeller för arabiska språkgenerering. I denna uppsats utvecklar vi den första avancerade arabiska språkgenerationens modell, AraGPT2, utbildad från grunden på en stor arabisk korpus av internettext och nyhetsartiklar. Vår största modell, AraGPT2-mega, har 1,46 miljarder parametrar, vilket gör den till den största arabiska språkmodellen tillgänglig. Megamodellen utvärderades och visade framgång på olika uppgifter, inklusive syntetisk nyhetsgenerering och noll-skott frågesvar. För textgenerering uppnår vår bästa modell en förvirring på 29,8 på utdragna Wikipediaartiklar. En studie utförd med humana utvärderare visade den betydande framgången med AraGPT2-mega att generera nyhetsartiklar som är svåra att skilja från artiklar skrivna av människor. På så sätt utvecklar och släpper vi en automatisk diskrimineringsmodell med 98% noggrannhet i detektering av modellgenererad text. Modellerna är också offentligt tillgängliga, i hopp om att uppmuntra nya forskningsriktningar och tillämpningar för arabisk NLP.', 'ta': 'சமீபத்தில், முன்பயிற்சி மாற்றும் அடிப்படையான அடிப்படைப்புகள் மொழி மாற்றுதல் மற்றும் புரிந்து கொள்ள முடியும் மிகவும் தெளிவாக் முன்னேற்றப்பட்ட அரபி உருவாக்கத்திற்கான பயன்பாடுகள் இன்னும் மற்ற NLP முன்னேற்றங்களை ஒப்பிடுவதில் இருக்கின்றன முக்கியமாக மே இந்த காக்கியத்தில், நாம் முதல் முன்னேற்றப்பட்ட அரபி மொழி உருவாக்க மாதிரியை உருவாக்குகிறோம், AraGPT2, ஒரு பெரிய அரபி பொத்தான் இணைய எங்கள் பெரிய மாதிரி, AraGPT2-மெகா, 1.46 பில்லியன் அளபுருகள் உள்ளது, அது பெரிய அரபி மொழி மாதிரி மாதிரி கிடைக்கும். மெகா மாதிரி மதிப்பெடுக்கப்பட்டது மற்றும் வேறு வேலைகளில் வெற்றியடைந்தது செய்தி தலைமுறையில் சேர்க்கப்பட்டு உரை தலைமுறைக்கு, எங்கள் சிறந்த மாதிரி 29. 8 விகிபிடியா கட்டுரைகளில் ஒரு பிரச்சனையை பெறுகிறது. A study conducted with human evaluators showed the significant success of AraGPT2-mega in generating news articles that are difficult to distinguish from articles written by humans.  அதனால் நாம் ஒரு தானியங்கி வேறுபடுத்தி மாதிரியை உருவாக்கும் மாதிரி உரையை கண்டறிந்து 98% சரிவுடன் வெளியேற்றுவோம். அரபி NLP க்கான புதிய ஆராய்ச்சி தேர்வுகள் மற்றும் பயன்பாடுகளை ஆராய்ச்சிக் கொள்வதற்கு நம்பிக்கை கொண்டு', 'sr': 'Nedavno su predobučene arhitekture bazirane na transformaciji dokazale da su veoma efikasne na modelima jezika i razumijevanju, s obzirom na to da su obučeni na dovoljno velikom korpusu. Aplikacije u generaciji jezika za Arapski još uvijek ostaju u usporedbi sa drugim napredkama NLP, glavno zbog nedostatka naprednih modela generacije arapskih jezika. U ovom papiru razvijamo prvi napredni model generacije arapskog jezika, AraGPT2, obučen od ogrebotine na velikom arapskom korpusu teksta i novinskih članaka. Naš najveći model, AraGPT2-mega, ima 1,46 milijardi parametara, što ga čini najvećim arapskim jezikom dostupnim. Veliki model je procenio i pokazao uspeh na različitim zadacima, uključujući generaciju sintetičkih vijesti, i odgovor na pitanje bez pucnjave. Za generaciju teksta, naš najbolji model postiže kompleksnost od 29,8 na održanim člancima Wikipedije. Istraživanje provedeno sa ljudskim procjenama pokazalo je značajan uspjeh AraGPT2-mega u stvaranju novinskih članaka koje je teško odvojiti od članaka napisanih od ljudi. Zato razvijamo i oslobodimo automatski diskriminacijski model sa preciznošću 98% u otkrivanju teksta koji je stvoren modelom. Modeli su takođe javno dostupni, nadajući se da će potaknuti nove istraživačke upute i prijave za arapski NLP.', 'ur': 'اچھے سے پہلے تغییر دینے والی معماریں زبان کی مدل اور سمجھ میں بہت فائدہ اٹھانے والی ہیں، اس وجہ سے کہ یہ ایک بڑے کافی جسم پر آموزش کی جاتی ہیں. عربی زبان کی نسل کی کاربریاں ابھی بھی دوسرے NLP کے مقابلہ میں ہٹ رہی ہیں، جو سب سے زیادہ آگے بڑھی عربی زبان کی نسل کی مدل کے ناکام ہیں۔ اس کاغذ میں ہم پہلی آغاز عربی زبان کی نسل موڈل، AraGPT2، کو ایک بڑے عربی کورپوس پر آموزش دی گئی ہے جو انٹرنیٹ ٹیکسٹ اور نیویٹ لکھوں کی ایک بڑی عربی کورپوس پر آموزش دی گئی ہے۔ ہمارے سب سے بڑے موڈل، AraGPT2-mega، کے پاس 1.46 میلیارد پارامتر ہے، جو اسے سب سے بڑا عربی زبان موڈل موجود بناتا ہے۔ مگا موڈل کا ارزش کیا گیا تھا اور مختلف کاموں میں موفقیت دکھائی گئی ہے جیسے سینٹیٹیک خبروں کی نسل، اور صفر-شٹ سوال جواب دینے کی۔ ٹیکسٹ نسل کے لئے، ہماری بہترین نمادل 29.8 کے مطابق ویکیپیڈیا لکھائیوں کے ذریعے ایک پیچیدگی حاصل کرتا ہے. انسان کے ارزیابی کرنے والوں کے ساتھ ایک مطالعہ نے AraGPT2-mega کی بڑی موفقیت دکھائی تھی کہ لوگوں کی لکھی ہوئی مطالعہ سے جدا کرنا مشکل ہے. ہم اسی طرح ایک آٹوٹی تقسیم کرنے والی موڈل کو 98 فیصد دقیق کے ساتھ آزاد کریں اور آزاد کریں۔ نمڈلے بھی ظاہر طور پر موجود ہیں، نو تحقیقات کی طریقے اور عربی NLP کے لئے اپنا کاروبار سفارش کرنا امید رکھتے ہیں.', 'uz': "Yaqinda o'rganilgan shifokorlar asosiy maktablari tilning modeli va tushunishda juda effektiv bo'lganligini ko'rsatadi. Chunki ular juda katta kopus bilan o'rganadi. Арабча таркиб олиш учун dasturlar эса, бошқа NLP тарзда мосламаларига мослаб қўшиб қолади. Арабча таркиб олинган араб таркибида мосламалари камбағал бўлгани учун. Bu hujjatda biz birinchi oldingi oldinga Arab tilning foydalanuvchi modeli AraGPT2, Internet matn va xabarlar maqolalarining katta arab Korpusdan o'rganadi. Bizning eng katta modelmiz AraGPT2-mega, 1.46 milliard parametrlar bor. Buni eng katta arab tilning modeli imkoniyatli mumkin. Name Matn generasi uchun eng yaxshi modelmiz Wikipediya maqolalari 29.8 ta'sirida murakkablik topadi. Inson qiymatlari bilan ishga tushirilgan o'qituvchilar AraGPT2-mega juda muhim muvaffaqiyatli ko'rsatadi. Bu xabar maqolalarni inson tomonidan yozilgan maqolalardan ajratish qiyin edi. Biz model yaratilgan matnni aniqlashda 98% aniqlash modelini avtomatik ajratish modelini chiqaramiz. Umumiy qilib, bu modellar arab NLP uchun yangi qidirish qoidalarini va dasturlarni amalga oshirish uchun ishlatiladi.", 'vi': 'Gần đây, các kiến trúc mẫu được huấn luyện trước đây đã chứng tỏ là rất hiệu quả trong việc tạo ra và hiểu biết ngôn ngữ, vì chúng được huấn luyện trên một cơ thể đủ lớn. Ứng dụng sản xuất ngôn ngữ cho A Rập vẫn còn kém so với những tiến bộ khác của NLP, vì thiếu các mô hình phát triển ngôn ngữ Á Rập. Trong tờ giấy này, chúng tôi phát triển hình mẫu phát triển ngôn ngữ tiếng Ả Rập đầu tiên, AraGP2, được đào tạo từ đầu trên một tập hợp văn bản internet và các bài báo. Người mẫu lớn nhất, AraGP2-mega, có hàng tỷ thông số, 46, thứ làm cho nó trở thành mô hình ngôn ngữ tiếng Ả Rập lớn nhất. Siêu xe đã được đánh giá và cho thấy thành công trong các công việc khác nhau, bao gồm sản xuất tin tức tổng hợp, và trả lời hỏi bằng không. Đối với thế hệ văn bản, mẫu tốt nhất đạt được sự phức tạp của 29.8 trên các bài Wikipedia bị kẹt. Một nghiên cứu tiến hành với các thẩm tra người cho thấy thành công đáng kể của AraGP2-mega trong việc tạo ra các bài báo khó phân biệt từ các bài viết của con người. Chúng tôi phát triển và phát hành một mô hình phân biệt tự động với độ chính xác số 97 để phát hiện văn bản tạo mẫu. Các mô hình cũng được công bố, hi vọng sẽ thúc đẩy các hướng dẫn nghiên cứu mới và ứng dụng cho ngôn ngữ Chọc tức thời Ả Rập.', 'nl': 'Onlangs hebben voorgetrainde transformatorgebaseerde architecturen bewezen zeer efficiënt te zijn in taalmodellering en -begrip, gezien het feit dat ze zijn getraind op een groot genoeg corpus. Toepassingen in taalgeneratie voor Arabisch lopen nog steeds achter in vergelijking met andere NLP-vooruitgang, voornamelijk vanwege het ontbreken van geavanceerde Arabische taalgeneratiemodellen. In dit artikel ontwikkelen we het eerste geavanceerde Arabische taalgeneratie model, AraGPT2, dat vanaf nul getraind is op een groot Arabisch corpus van internet tekst en nieuwsberichten. Ons grootste model, AraGPT2-mega, heeft 1.46 miljard parameters, waardoor het het grootste Arabisch taalmodel beschikbaar is. Het megamodel werd geëvalueerd en toonde succes op verschillende taken, waaronder synthetisch nieuws genereren en zero-shot vragen beantwoorden. Voor het genereren van tekst bereikt ons beste model een verwarring van 29.8 op uitgestelde Wikipedia-artikelen. Een studie uitgevoerd met menselijke beoordelaars toonde het significante succes van AraGPT2-mega aan bij het genereren van nieuwsberichten die moeilijk te onderscheiden zijn van artikelen geschreven door mensen. Zo ontwikkelen en brengen we een automatisch discriminatormodel uit met een 98% nauwkeurigheid in het detecteren van door model gegenereerde tekst. De modellen zijn ook openbaar beschikbaar, in de hoop nieuwe onderzoeksrichtingen en toepassingen voor Arabisch NLP te stimuleren.', 'bg': 'Напоследък предварително обучените трансформаторни архитектури се оказаха много ефективни в езиковото моделиране и разбиране, като се има предвид, че са обучени върху достатъчно голям корпус. Приложенията в езиковото генериране на арабски език все още изостават в сравнение с други напредъци в НЛП главно поради липсата на модерни модели за генериране на арабски език. В настоящата статия разработваме първия модел за генериране на напреднал арабски език, обучен от нулата върху голям арабски корпус от интернет текстове и новинарски статии. Нашият най-голям модел, има 1,46 милиарда параметри, което го прави най-големият арабски език модел на разположение. Мега моделът беше оценен и показа успех по различни задачи, включително генериране на синтетични новини и нулев отговор на въпроси. За генериране на текст, нашият най-добър модел постига объркване от 29.8 на статиите в Уикипедия. Проучване, проведено с човешки оценители, показа значимия успех на AraGPT2-мега в генерирането на новинарски статии, които трудно се различават от статиите, написани от хора. По този начин разработваме и пускаме автоматичен дискриминационен модел с 98% точност при откриването на генериран от модела текст. Моделите също са публично достъпни, надявайки се да насърчат нови изследователски направления и приложения за арабското НЛП.', 'hr': 'Nedavno su predobučene arhitekture bazirane na transformaciji dokazale da su vrlo učinkovite na modelima jezika i razumijevanju, s obzirom da su obučeni na dovoljno velikom korpusu. Prijave u generaciji jezika za arapski još uvijek ostaju u usporedbi s drugim napredkama NLP-a primarno zbog nedostatka naprednih modela generacije arapskih jezika. U ovom papiru razvijamo prvi napredni model generacije arapskog jezika, AraGPT2, obučen od ogrebotine na velikom arapskom korpusu internetskog teksta i novinskih članaka. Naš najveći model AraGPT2-mega ima 1,46 milijardi parametara, što ga čini najvećim arapskim jezičkim modelom dostupnim. Veliki model je procijenjen i pokazao uspjeh na različitim zadacima uključujući sintetičku vijesti, i odgovor na pitanje bez pucnjave. Za generaciju teksta, naš najbolji model postiže kompleksnost od 29,8 o održanim člancima Wikipedije. Istraživanje provedeno s ljudskim procjenama pokazalo je značajan uspjeh AraGPT2-mega u stvaranju novinskih članaka koje je teško odvojiti od članaka napisanih od ljudi. Zato razvijamo i oslobodimo automatski diskriminacijski model sa preciznošću 98% u otkrivanju teksta proizvođenog model a. Modeli su također javno dostupni, nadajući se da će poticati nove istraživačke upute i prijave za arapski NLP.', 'da': 'For nylig har forududdannede transformer-baserede arkitekturer vist sig at være meget effektive til sprogmodellering og forståelse, da de er trænet på et stort nok korpus. Ansøgninger i sproggenerering af arabisk er stadig forsinket i forhold til andre NLP fremskridt primært på grund af manglen på avancerede arabiske sproggenereringsmodeller. I denne artikel udvikler vi den første avancerede arabiske sproggenerationsmodel, AraGPT2, trænet fra bunden på et stort arabisk korpus af internettekst og nyhedsartikler. Vores største model, AraGPT2-mega, har 1,46 milliarder parametre, hvilket gør den til den største arabiske sprogmodel tilgængelig. Megamodellen blev evalueret og viste succes på forskellige opgaver, herunder syntetisk nyhedsgenerering og zero-shot spørgsmål besvarelse. For tekstgenerering opnår vores bedste model en forvirring på 29,8 på udholdte Wikipedia artikler. En undersøgelse udført med menneskelige evaluatorer viste den betydelige succes AraGPT2-mega i at generere nyhedsartikler, der er svære at skelne fra artikler skrevet af mennesker. Vi udvikler og frigiver således en automatisk diskrimineringsmodel med 98% nøjagtighed i detektering af modellegenereret tekst. Modellerne er også offentligt tilgængelige og håber at fremme nye forskningsretninger og anvendelser for arabisk NLP.', 'de': 'Vor kurzem haben sich vortrainierte transformatorbasierte Architekturen als sehr effizient bei der Sprachmodellierung und -verständigung erwiesen, da sie auf einem ausreichend großen Korpus trainiert werden. Anwendungen in der Sprachgenerierung für Arabisch hinken im Vergleich zu anderen NLP-Fortschritten immer noch zurück, vor allem aufgrund des Fehlens fortgeschrittener arabischer Sprachgenerierungsmodelle. In dieser Arbeit entwickeln wir das erste fortgeschrittene arabische Sprachgenerationsmodell, AraGPT2, das von Grund auf auf einem großen arabischen Korpus von Internettexten und Nachrichtenartikeln trainiert wurde. Unser größtes Modell, AraGPT2-mega, hat 1,46 Milliarden Parameter, was es zum größten verfügbaren arabischen Sprachmodell macht. Das Megamodell wurde evaluiert und zeigte Erfolge bei verschiedenen Aufgaben, einschließlich synthetischer Nachrichtengenerierung und Zero-Shot-Fragebeantworterung. Für die Textgenerierung erreicht unser bestes Modell eine Verwirrung von 29,8 bei ausgedehnten Wikipedia-Artikeln. Eine Studie mit humanen Evaluatoren zeigte den signifikanten Erfolg von AraGPT2-mega bei der Generierung von Nachrichtenartikeln, die schwer von Artikeln zu unterscheiden sind, die von Menschen geschrieben wurden. Wir entwickeln und veröffentlichen daher ein automatisches Diskriminierungsmodell mit 98% Genauigkeit zur Erkennung modellgenerierter Texte. Die Modelle sind auch öffentlich zugänglich, um neue Forschungsrichtungen und Anwendungen für arabisches NLP zu fördern.', 'fa': 'اخیرا، معماری\u200cهای پیش آموزشی بر اساس تغییر\u200cپذیر\u200cکننده\u200cها ثابت شده است که در مدل\u200cسازی و درک زبان بسیار موثر است، با وجود اینکه آنها در یک کورپوس کافی بزرگ آموزشی می\u200cشوند. کاربردهای در نسل زبان برای عربی هنوز در مقایسه با پیشرفت های دیگر NLP به دلیل ناتوانی از مدلهای نسل زبان عربی پیشرفت پیدا می کنند. در این کاغذ، ما اولین مدل نسل زبان عربی پیشرفته\u200cای را توسعه می\u200cکنیم، AraGPT2، آموزش می\u200cدهیم که در یک کورپوس بزرگ عربی از متن\u200cهای اینترنت و متن\u200cهای خبری آموزش می\u200cدهد. بزرگترین مدل ما، AraGPT2-mega، ۱.۶۴ میلیارد پارامتر دارد که بزرگترین مدل زبان عربی را در دسترس می دهد. مدل مگا ارزیابی شد و موفقیت را در کار های مختلف نشان داد، شامل نسل خبرهای سناتیک، و جواب سوال صفر-شلیک. برای نسل متن، بهترین مدل ما به عنوان مقاله های ویکیپدیا بازداشته می شود که در ۲۹.۸ متصل شده است. مطالعه\u200cای که با ارزیابگران انسان انجام می\u200cشود، موفقیت بزرگی AraGPT2-mega را نشان داد در تولید مطالعه\u200cهای خبری که برای جدایی از مطالعه\u200cهای نوشته شده\u200cاند سخت است. بنابراین ما یک مدل جدایی خودکار را با دقیق 98 درصد در کشف متن تولید شده مدل توسعه می کنیم و آزاد می کنیم. مدلها همچنین به طور عمومی موجود هستند، امیدوارند مسیرهای تحقیقات جدید و کاربرد برای NLP عربی تشویق کنند.', 'id': 'Baru-baru ini, arsitektur berdasarkan transformator yang terlatih telah terbukti sangat efisien dalam pemodelan dan pemahaman bahasa, karena mereka dilatih pada tubuh yang cukup besar. Aplikasi dalam generasi bahasa untuk bahasa Arab masih tertunda dibandingkan dengan kemajuan NLP lainnya terutama karena kekurangan model generasi bahasa Arab yang maju. In this paper, we develop the first advanced Arabic language generation model, AraGPT2, trained from scratch on a large Arabic corpus of internet text and news articles.  Model terbesar kita, AraGPT2-mega, memiliki 1,46 miliar parameter, yang membuat model bahasa Arab terbesar tersedia. Model mega telah diuji dan menunjukkan sukses pada tugas yang berbeda termasuk generasi berita sintetis, dan menjawab pertanyaan zero-shot. Untuk generasi teks, model terbaik kita mencapai kekacauan 29,8 pada artikel Wikipedia. Sebuah studi yang dilakukan dengan evaluasi manusia menunjukkan sukses yang signifikan dari AraGPT2-mega dalam menghasilkan artikel berita yang sulit untuk dibedakan dari artikel yang ditulis oleh manusia. Jadi kami mengembangkan dan melepaskan model diskriminator otomatis dengan akurasi 98% dalam mendeteksi teks yang dibuat model. Model-model juga tersedia publik, berharap untuk mendorong arah penelitian dan aplikasi baru untuk NLP Arab.', 'ko': '최근에 사전 훈련을 거친transformer 기반의 체계 구조는 언어 모델링과 이해에 매우 효과적임을 증명했다. 왜냐하면 그들은 충분한 어료 라이브러리에서 훈련했기 때문이다.다른 NLP의 발전에 비해 아랍어 언어 생성에 대한 응용이 여전히 정체된 것은 고급 아랍어 생성 모델이 부족하기 때문이다.본고에서 우리는 첫 번째 고급 아랍어 생성 모델인 아라GPT2를 개발했는데 이것은 인터넷 텍스트와 뉴스 기사의 대형 아랍어 어료 라이브러리에서 처음부터 훈련한 것이다.우리의 최대 모델인 아라GPT2 mega는 14.6억 개의 매개 변수를 가지고 있어 사용할 수 있는 최대 아랍어 모델이 되었다.메가 모델을 평가한 결과 이 모델은 서로 다른 임무에서 성공을 거두었고 합성 뉴스 생성과 제로 퀴즈를 포함했다.텍스트 생성에 있어서 우리의 가장 좋은 모델은 위키백과 문장의 복잡도는 29.8이다.인간 평가원이 진행한 연구에 따르면 아라GPT2 mega는 인간이 쓴 글과 구분하기 어려운 뉴스 기사를 만드는 데 큰 성공을 거뒀다.따라서 우리는 모델이 생성한 텍스트를 검출할 때 98%의 정확도를 가진 자동 감별기 모델을 개발하고 발표했다.이들 모델도 공개적으로 획득할 수 있어 아랍어 NLP의 새로운 연구 방향과 응용을 장려하고자 한다.', 'sq': 'Recently, pre-trained transformer-based architectures have proven to be very efficient in language modeling and understanding, given that they are trained on a large enough corpus. Aplikatat në gjenerimin e gjuhëve për arabisht janë ende të vonuara në krahasim me përparimet e tjera të NLP kryesisht për shkak të mungesës së modeleve të gjenerimit të gjuhëve arabe të avancuara. Në këtë gazetë, ne zhvillojmë modelin e parë të gjenerimit të gjuhës arabe të avancuar, AraGPT2, të stërvitur nga zero në një korpus të madh arab të tekstit të internetit dhe artikujve të lajmeve. Modeli ynë më i madh, AraGPT2-mega, ka 1.46 miliard parametra, që e bën modelin më të madh të gjuhës arabe në dispozicion. Modeli mega u vlerësua dhe tregoi sukses në detyra të ndryshme duke përfshirë gjenerimin sintetik të lajmeve dhe përgjigjen e pyetjeve zero-shot. Për gjenerimin e tekstit, modeli ynë më i mirë arrin një huti prej 29.8 në artikujt e Wikipedias. Një studim i kryer me vlerësuesit njerëzor tregoi suksesin e rëndësishëm të AraGPT2-mega në krijimin e artikujve të lajmeve që janë të vështirë të dallohen nga artikujt e shkruara nga njerëzit. Kështu zhvillojmë dhe lëshojmë një model diskriminues automatik me 98% saktësi në zbulimin e tekstit të gjeneruar nga modeli. Modelet janë gjithashtu në dispozicion publik, duke shpresuar të inkurajojnë drejtime të reja kërkimi dhe aplikime për NLP arabe.', 'sw': 'Hivi karibuni, majengo ya mabadiliko yaliyojifunza kabla yameonyesha kuwa yenye ufanisi mkubwa katika mifano ya lugha na kuelewa, kwa sababu wamefundishwa kwa makundi makubwa yanayotosha. Matumizi ya kizazi cha lugha kwa Kiarabu bado yanaendelea kulinganisha na maendeleo mengine ya NLP hasa kwa sababu ya ukosefu wa mifano ya kizazi cha Kiarabu. Katika karatasi hii, tunaendelea modeli ya kwanza ya uzalishaji wa lugha ya Kiarabu, AraGPT2, inayofundishwa kutoka kwenye vifaa vikubwa vya Kiarabu vya maandishi ya intaneti na makala za habari. Mfano wetu mkubwa, AraGPT2-mega, una parameter bilioni 1.46, ambayo inaifanya kuwa mtindo mkubwa wa lugha ya Kiarabu unapatikana. Mradi wa Mega ulivutiwa na kuonyesha mafanikio katika kazi tofauti ikiwa ni pamoja na kizazi cha habari cha pamoja, na jibu la swali lililopigwa kishindo. Kwa kizazi cha maandishi, mifano yetu bora inafanikiwa kuwa na wasiwasi wa makala 29.8 za Wikipedia zilizotengwa. Utafiti uliofanywa na watafiti wa binadamu ulionyesha mafanikio makubwa ya vifaa vya AraGPT2-mega katika kutengeneza makala za habari ambazo ni vigumu kutofautisha kutoka makala zilizoandikwa na binadamu. We thus develop and release an automatic discriminator model with a 98% percent accuracy in detecting model-generated text.  Mradi huo pia unapatikana hadharani, kwa matumaini ya kuhamasisha maelekezo mapya ya utafiti na matumizi ya NLP ya Kiarabu.', 'tr': 'Soňky wagtlar, öňki bilim alynylan terjime etmäge taýýarlanan arhitekturlary dil modelleýäniň we düşünjegiňde örän täsirli bolandygyny kanıtlandyrylýar, sebäbi olar ýeterlik uly korpusda bilim alýarlar. Arapça dil döredilişinde programler heniz hem beýleki NLP bilen gelişmäge çalyşýar. Öňe-de öňki arab dil döredilişi nusgalaryň ýok bolmagynyň sebäbi. Bu kagyzda biz ilkinji gelişmiş arabça dil döredilişi nusgasyny, AraGPT2, internet we habar makalasynyň uly aräp korpusynda öwrendik. Biziň iň uly nusgamyz, AraGPT2-mega, 1 Mega modeli değerlendirildi ve sintetik haberler döredilmesi dahil başarılı işlerinde başarılı şekilde gösterildi ve sıfır-atlı sorag cevap berdi. Metin döredilişi üçin biziň iň gowy nusgymyz Wikipediýanyň 29.8-nji urşan makalarynyň çykylygyny başarýar. Adamlar deňleýşenleri bilen işlenýän bir studiýa AraGPT2-mega ýagdaýynyň esasy başarnygyny üýtgetmek üçin adamlaryň ýazylan makalaryndan tapawutlandyrmak kyn hasaplanýar. Şonuň üçin modeli döredilen metin tapylmak üçin 98% dogry bir diskriminat nusgasyny geliştirip we çykarýarys. Bu nusgalar hem halkara mejbur bar, araşdyrma yönlerini we uygulamalary arabça NLP üçin täze çykarmak üçin umyt edýärler.', 'af': "Onlangs het voorafgeleerde transformeerder-gebaseerde arkitektuure bevestig om baie effektief te wees by taal modellering en verstanding, gegee dat hulle op 'n groot genoeg korpus opgelei word. Toepassinge in taal generasie vir Arabies word nog steeds in vergelyking met ander NLP gevorderde vanweë die mislukking van gevorderde Arabiese taal generasie modele. In hierdie papier ontwikkel ons die eerste gevorderde Arabiese taal generasie model, AraGPT2, onderwerp van skrap op 'n groot Arabiese korpus van internet teks en nuusartikels. Ons grootste model, AraGPT2-mega, het 1,46 biljoen parameters, wat dit die grootste Arabiese taal model beskikbaar maak. Die mega model was evalueer en het sukses gewys op verskillende opdragte insluitend sintetiese nuusgenering en zero-skoot vraag antwoord. Vir teks generasie, ons beste model bereik 'n perpleksie van 29.8 op uitgehou Wikipedia-artikels. 'n Studie wat met menslike evalueerders gedoen het, het die betekende sukses van AraGPT2-mega vertoon in die genereer van nuusartikels wat moeilik is om te verkies van artikels wat deur mense geskrywe is. Ons ontwikkel en verlos 'n outomatiese diskriminasie model met 'n 98% persent waarskynlik in ontdekking van model genereerde teks. Die modele is ook openbaar beskikbaar, hoop om nuwe forsoeking rigtings en toepassings vir Arabiese NLP te bevestig.", 'am': 'በቅርብ ዘመን፣ ቀድሞ ተማሪዎች የደረጃ መሠረት መሠረቶች በቋንቋ ምሳሌ እና ማስተዋል እጅግ ብልሃት እንዲሆኑ ሞከረዋል፡፡ Applications in language generation for Arabic are still lagging in comparison to other NLP advances primarily due to the lack of advanced Arabic language generation models.  በዚህ ፕሮግራም የመጀመሪያውን የበለጠ የዐረብኛ ቋንቋ ትውልድ model AraGPT2፣ የኢንተርኔት ጽሑፍ እና የዜና ጽሑፎች ላይ የተማረከ የዐረብኛ ኮፖስስ ነው፡፡ ትልቁ ዓይነታችን AraGPT2-ሜጋ፣ 1.46 ቢልዮን ፓርቲዎች አለበት፣ ትልቁ ዐረብኛ ቋንቋ ሞዴል አለበት፡፡ የሜጋው ሞዴል ተረጋገጠና በተለያዩ ስራ ላይ ድል አግኝቷል፤ እናም የዜና ትውልድ እና የzero-shot ጥያቄ መልስ አግኝቷል፡፡ ለጽሑፍ ትውልድ፣ መልካሙን ምሳሌ የWikipedia ጽሑፎችን የ29.8 ውጤት አግኝቷል፡፡ ከሰው አስተዳሪዎች ጋር የተፈጸመ ትምህርት የሰው ጽሑፎች ከመለየት የሚችሉትን የዜና ጽሑፎች አካላት በመፍጠር የAraGPT2-ሜga ትልቅ ዕድል አግኝቷል፡፡ እንደዚሁም የ 98 በመቶ ውጤት በሞዴል የተፈጠረውን ጽሑፍ ለማግኘት እናሳውቃለን፡፡ አዲስ ትምህርት መግለጫ እና ፕሮግራሞች ለአረብኛ NLP ለማድረግ ተስፋ ያደርጋሉ፡፡', 'bs': 'Nedavno su predobučene arhitekture bazirane na transformaciji dokazale da su veoma efikasne na modelima jezika i razumijevanju, s obzirom na to da su obučeni na dovoljno velikom korpusu. Prijave u generaciji jezika za arapski još uvijek ostaju u usporedbi sa drugim napredkama NLP, glavno zbog nedostatka naprednih modela generacije arapskih jezika. U ovom papiru razvijamo prvi napredni model generacije arapskog jezika, AraGPT2, obučen od ogrebotine na velikom arapskom korpusu teksta i novinskih članaka internet a. Naš najveći model, AraGPT2-mega, ima 1,46 milijardi parametara, što ga čini najvećim arapskim jezičkim modelom dostupnim. Veliki model je procijenjen i pokazao uspjeh na različitim zadacima, uključujući generaciju sintetičkih vijesti, i odgovor na pitanje bez pucnjave. Za generaciju teksta, naš najbolji model postiže kompleksnost od 29,8 na održanim člancima Wikipedije. Istraživanje provedeno s ljudskim procjenama pokazalo je značajan uspjeh AraGPT2-mega u stvaranju novinskih članaka koje je teško odvojiti od članaka napisanih od ljudi. Zato razvijamo i oslobodimo automatski diskriminacijski model sa preciznošću 98% u otkrivanju teksta koji je proizveden iz model a. Modeli su također javno dostupni, nadajući se da će poticati nove istraživačke upute i prijave za arapski NLP.', 'az': "Son zamanlarda, …ôvv…ôlc…ô t…ôhsil edilmiŇü transformer-tabanlńĪ arhitektarlar dil modell…ôrind…ô v…ô anlayńĪŇülarńĪnda √ßox faydalńĪ olduńüunu kanńĪtladńĪ, √ß√ľnki onlar yet…ôr q…ôd…ôr b√∂y√ľk korpusda t…ôhsil edilmiŇül…ôr. Arap√ßa dil n…ôsilind…ô olan proqramlar h…ôl…ô d…ô baŇüqa NLP n…ôsill…ôri il…ô qarŇüńĪlaŇüdńĪrńĪlńĪr. ∆Źlb…ôtt…ô, …ôr…ôb dill…ôrinin n…ôsill…ôrinin modell…ôrini yoxdur. Bu kańüńĪzda, biz ilk geliŇümiŇü …ôr…ôb dil n…ôsili modelini, AraGPT2, internet m…ôktubunun v…ô x…ôb…ôr m…ôktubunun b√∂y√ľk …ôr…ôb korpusu il…ô t…ôhsil edilmiŇüik. Bizim …ôn b√∂y√ľk modelimiz, AraGPT2-mega, 1,46 milyard parametru var, bu da …ôr…ôb dilinin …ôn b√∂y√ľk modeli faydalanńĪr. Mega modeli deńüerl…ôŇüdirildi v…ô sintetik x…ôb…ôrl…ôr n…ôsilind…ô f…ôrqli iŇül…ôr bar…ôsind…ô baŇüarńĪsńĪzlńĪq g√∂st…ôrildi v…ô sńĪfńĪr-f…ôrqli sual cavab verildi. M…ôtn n…ôsili √ľ√ß√ľn …ôn yaxŇüńĪ modell…ôrimiz Wikipedia m…ôktublarńĪndan istifad…ô edil…ôn 29.8 m…ôktublarńĪn √ßoxluńüuna nail olur. ńįnsan deńüerlendiricil…ôri il…ô t…ôhsil edil…ôn t…ôhsil, insanlarńĪn yazńĪldńĪńüńĪ m…ôs…ôl…ôl…ôrd…ôn ayńĪrmaq √ß…ôtin x…ôb…ôr m…ôs…ôl…ôl…ôrini yaratmaq √ľ√ß√ľn AraGPT2-mega'nńĪn b√∂y√ľk baŇüarńĪlńĪ olduńüunu g√∂st…ôrdi. Bel…ôlikl…ô, modell…ôrin yaratdńĪńüńĪ metinl…ôri keŇüfetm…ôsind…ô 98% …ôdal…ôti olan avtomatik diskriminat modelini t…ôhsil edirik. Modell…ôr d…ô a√ßńĪq-aŇükar m√∂vcuddur, …ôr…ôb NLP √ľ√ß√ľn yeni araŇüdńĪrma y√∂nl…ôrini v…ô uyńüulamalarńĪ t…ôŇükil etm…ôk ist…ôyirl…ôr.", 'bn': 'সম্প্রতি প্রশিক্ষণের পূর্ববর্তী পরিবর্তনের ভিত্তিক কাঠামো ভিত্তিক ভিত্তিক কাঠামো ভাষার মডেলিং এবং বুঝতে খুব দক্ষতা প্রমাণ করেছে, য আরবী প্রজন্মের প্রজন্মে অ্যাপলিকেশন এখনো অন্যান্য এনএলপি উন্নয়নের তুলনায় রাখা হয়েছে প্রধান আরবী প্রজন্মের মডেলের অভাবের কা এই কাগজটিতে আমরা প্রথম উন্নত আরবী ভাষা প্রজন্ম মডেল, AraGPT2, ইন্টারনেট টেক্সট এবং সংবাদ প্রবন্ধের বিশাল আরবী কোর্পাসের প্রশিক্ষণ প্রদা আমাদের সবচেয়ে বড় মডেল AraGPT2-মেগা, ১.৪৬ বিলিয়ন প্যারামিটার আছে, যারা এটাকে সবচেয়ে বড় আরবী ভাষার মডেল পাওয়া যায়। মেগা মডেলের মূল্য এবং বিভিন্ন কাজের উপর সফলতা প্রদর্শন করা হয়েছে, যার মধ্যে সিন্টেটিক সংবাদ প্রজন্ম এবং শুধু গুলি প্রশ টেক্সট প্রজন্মের জন্য, আমাদের সর্বোচ্চ মডেল ২৯. মানুষের মূল্যায়নের সাথে একটি গবেষণা প্রদর্শন করা হয়েছে আরাজিপিটি২-মেগার গুরুত্বপূর্ণ সফলতা দেখিয়েছে সংবাদ প্রবন্ধ তৈরি করার জন্য We thus develop and release an automatic discriminator model with a 98% percent accuracy in detecting model-generated text.  এই মডেলগুলো প্রকাশ্যে পাওয়া যাচ্ছে, আশা করছি আরবী এনএলপির জন্য নতুন গবেষণা নির্দেশ এবং অ্যাপ্লিকেশন উৎসাহিত করত', 'ca': "Recentment, arquitectures pré-entrenades basades en transformadors han demostrat ser molt eficients en la modelació i l'comprensió del llenguatge, dada que estan entrenades en un corpus prou gran. Les aplicacions en la generació de llengües per a l'àrab encara estan atrasades en comparació amb altres avanços del NLP, principalment a causa de la falta de models avançats de generació de llengües àrabs. En aquest article, desenvolupem el primer model avançat de generació de llenguatges àrabs, AraGPT2, entrenat de zero en un gran corpus àrab de text a Internet i articles de notícies. El nostre model més gran, AraGPT2-mega, té 1,46 mil milions de paràmetres, que el fa disponible el model de llenguatge àrab més gran. El mega model va ser avaluat i va mostrar èxit en diverses tasques, incloent la generació de notícies sintètiques, i resposta a preguntes de zero. Per a la generació de text, el nostre millor model aconsegueix una perplexitat de 29,8 en articles de Wikipedia. Un estudi fet amb evaluadors humans va demostrar l'èxit significatiu d'AraGPT2-mega en generar articles de notícies difícils de distingir d'articles escrits pels humans. Així que desenvolupem i alliberam un model discriminator automàtic amb una precisió del 98% en la detecció del text generat pel model. Els models també estan a disposició del públic, esperant animar noves direccions i aplicacions de recerca per a la NLP àrab.", 'cs': 'V poslední době se předškolené transformátorové architektury ukázaly jako velmi efektivní při modelování a porozumění jazyků, protože jsou trénovány na dostatečně velkém korpusu. Aplikace v generování jazyků pro arabštinu stále zaostávají ve srovnání s ostatními pokroky NLP především kvůli nedostatku pokročilých modelů generace arabštiny. V tomto článku vyvíjíme první pokročilý model generace arabského jazyka, AraGPT2, vyškolený od nuly na velkém arabském korpusu internetových textů a zpravodajských článků. Náš největší model AraGPT2-mega má 1,46 miliardy parametrů, což z něj dělá největší dostupný model arabského jazyka. Mega model byl vyhodnocen a ukázal úspěch na různých úkolech včetně syntetického generování zpráv a nulového odpovědi na otázky. Pro generování textů dosahuje náš nejlepší model zmatenosti 29,8 na vydržených článcích Wikipedie. Studie provedená s lidskými hodnotiteli ukázala významný úspěch AraGPT2-mega při generování zpravodajských článků, které jsou obtížně odlišitelné od článků psaných lidmi. Proto vyvíjíme a uvolňujeme automatický diskriminační model s 98% přesností při detekci textu generovaného modelem. Modely jsou také veřejně dostupné a doufají, že podpoří nové směry výzkumu a aplikace arabského NLP.', 'hy': 'Վերջերս նախապատրաստված վերափոխողների հիմնված ճարտարապետությունները բավականին արդյունավետ են ապացուցել լեզվի մոդելավորման և հասկացության մեջ, հաշվի առնելով, որ նրանք պատրաստված են բավականին մեծ մարմնի վրա: Արաբերենի լեզվի սերունդի ծրագրերը դեռևս հետաքրքիր են, համեմատած այլ ՆԼՊ-ի առաջընթացներին, հիմնականում առաջընթացի արաբերենի սերունդի մոդելների բացակայության պատճառով: Այս թղթի մեջ մենք զարգանում ենք առաջին զարգացած արաբական լեզվի ստեղծման մոդելը, ԱրաGPT2, որը զրոյից ուսուցանված է ինտերնետի տեքստի և նորությունների մեծ արաբական կորպոսի վրա: Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available.  Մեգա մոդելը գնահատվել էր և ցույց տվեց հաջողություն տարբեր առաջադրանքներում, ներառյալ սինթետիկ նորությունների սերունդը, և զրոյի հարցերի պատասխանը: For text generation, our best model achieves a perplexity of 29.8 on held-out Wikipedia articles.  Մարդկային գնահատողների հետ կատարված ուսումնասիրությունը ցույց տվեց ԱրաGPT2-մեգայի կարևոր հաջողությունը ստեղծելով նորությունների հոդվածներ, որոնք դժվար են տարբերակել մարդկանց գրված հոդվածներից: Այսպիսով, մենք ստեղծում ենք և հրապարակում ենք ավտոմատիկ խտրականության մոդել 98 տոկոսի ճշգրտությամբ մոդելի ստեղծված տեքստի հայտնաբերման մեջ: Մոդելները նաև հանրային հասանելի են, հույս ունելով խրախուսել նոր ուսումնասիրության ուղղություններ և ծրագրեր արաբական ՆԼՊ-ի համար:', 'et': 'Hiljuti on eelnevalt koolitatud transformaatoril põhinevad arhitektuurid osutunud väga tõhusaks keele modelleerimisel ja mõistmisel, arvestades, et neid koolitatakse piisavalt suure korpusega. Araabia keele genereerimise rakendused on võrreldes teiste NLP edusammudega endiselt maha jäänud peamiselt arenenud araabia keele genereerimise mudelite puudumise tõttu. Käesolevas töös töötame välja esimese arenenud araabia keele generatsiooni mudeli AraGPT2, mida koolitatakse nullist suure araabia keele teksti ja uudisteartiklite korpuse põhjal. Meie suurim mudel, AraGPT2-mega, on 1,46 miljardit parameetrit, mis teeb sellest suurima araabia keele mudeli saadaval. Megamudelit hinnati ja see näitas edukust erinevates ülesannetes, sealhulgas sünteetiliste uudiste genereerimisel ja null shot küsimustele vastamisel. Teksti genereerimiseks saavutab meie parim mudel 29,8 segaduse Vikipeedia artiklites. Inimhindajatega läbi viidud uuring näitas AraGPT2-mega märkimisväärset edukust uudisteartiklite loomisel, mida on raske eristada inimese kirjutatud artiklitest. Seega töötame välja ja anname välja automaatse diskrimineerimismudeli, millel on 98% täpsus mudeli genereeritud teksti tuvastamisel. Mudelid on ka avalikult kättesaadavad, lootes julgustada uusi uurimissuundi ja rakendusi Araabia NLP.', 'fi': 'Viime aikoina esikoulutetut muuntajapohjaiset arkkitehtuurit ovat osoittautuneet erittäin tehokkaiksi kielimallinnuksessa ja ymmärtämisessä, koska ne on koulutettu riittävän suurella korpusella. Arabian kielen tuottamisen sovellukset ovat edelleen jäljessä muihin NLP-kehitykseen verrattuna pääasiassa kehittyneiden arabian kielen tuottamisen mallien puuttumisen vuoksi. Tässä artikkelissa kehitämme ensimmäisen kehittyneen arabiankielisen sukupolven mallin, AraGPT2, joka on koulutettu tyhjästä suurelle arabiankieliselle tekstille ja uutisartikkeleille. Suurin mallimme, AraGPT2-mega, on 1,46 miljardia parametria, mikä tekee siitä suurimman saatavilla olevan arabiankielisen mallin. Megamalli arvioitiin ja se osoitti menestystä erilaisissa tehtävissä, kuten synteettisessä uutisten tuottamisessa ja nollashot-kysymysvastauksessa. Tekstin tuottamisessa paras mallimme saavuttaa 29,8:n hämmennyksen Wikipedia-artikkeleissa. Ihmisarvioijien kanssa tehty tutkimus osoitti AraGPT2-megan merkittävän menestyksen tuottamassa uutisartikkeleita, joita on vaikea erottaa ihmisten kirjoittamista artikkeleista. Kehitämme ja julkaisemme automaattisen diskriminaattorimallin, jolla on 98 prosentin tarkkuus mallinnetun tekstin havaitsemisessa. Mallit ovat myös julkisesti saatavilla toivoen rohkaisevansa arabian NLP:n uusiin tutkimussuuntiin ja sovelluksiin.', 'sk': 'Pred kratkim so se predhodno usposobljene transformatorske arhitekture izkazale za zelo učinkovite pri modeliranju in razumevanju jezikov, saj so usposobljene na dovolj velikem korpusu. Aplikacije v jezikovni generaciji za arabščino še vedno zaostajajo v primerjavi z drugimi napredki NLP, predvsem zaradi pomanjkanja naprednih modelov arabščine. V tem prispevku smo razvili prvi napredni model generacije arabskega jezika, AraGPT2, usposobljen iz nič na velikem arabskem korpusu internetnih besedil in novic. Naš največji model, AraGPT2-mega, ima 1,46 milijarde parametrov, zaradi česar je največji arabski jezikovni model, ki je na voljo. Megamodel je bil ocenjen in pokazal uspeh pri različnih nalogah, vključno s sintetičnim ustvarjanjem novic in brezstrelnim odgovorom na vprašanja. Pri ustvarjanju besedila naš najboljši model doseže zmedenost 29,8 na zaprtih Wikipedijskih člankih. Študija, opravljena z ocenjevalci ljudi, je pokazala pomemben uspeh AraGPT2-mega pri ustvarjanju novic, ki jih je težko razlikovati od člankov, ki jih napišejo ljudje. Tako razvijamo in izdajamo avtomatski diskriminatorski model z 98-odstotno natančnostjo pri zaznavanju besedila, ki ga ustvari model. Modeli so tudi javno dostopni, v upanju, da bodo spodbudili nove raziskovalne smeri in aplikacije arabskega NLP.', 'jv': 'Jung-Jung, akeh dumaten sing beraksi lan akeh lansangan luwih dumateng. Drongen dumateng kuwi tindang model lan akeh dumateng, awak dhéwé wis dipoleh cara sistem sing gawe kudu beraksi. Aplikasi kanggo kalih banget kanggo tanggal arab sing isih durung bisa nggerarangke karo NLP sing bisa supoyo kaya kuwi model sing paling arab sing bisa nguasai. Nang pepul iki, awak dhéwé nggawe model sing perusahaan anyar luwih basa arap, araPPT 2, sing tuksuhan kanggo nggolok barang basa sing titik karo perusahaan anyar tentang karo perusahaan balêr. Kita model sing gawe kudu, araPPT 2-mela, dadi 1.49 militan parameters, sing ngejaraké kuwi model sing wis barêng arap sing kudu nggawe Metu model kang deweke nggo ngerasakno lan nambah perusahaan langgar sampeyan operasi sing paling kelangan senetik balêr, lan gambaran seneng pisan sing wis nul Mbak Generation Teks, model sing paling dhéwé kuwi duluran kanggo ngerasakno ning itong-itong sing paling-itong sing paling-itong Una granang sing gagalé karo deweksul-uwong sing wis ngerasai barang-barang araPPT-2 iso nggawe barang sing susahe kuwi masalah kanggo nggawe barang dhéwé kuwi susahe perkaran uwong. Awak dhéwé ngono nglanggar-sistem sing beraksi lan basa sawar sistem otomatik, gambar ditambah ning dokumen sing wis rabi 0% kebutaan tapi model sing gagetyeng teks. model lak kedoko akeh akeh Publik, supoyo nggawe ngubah perusahaan sing dibutuhke tarjamahan lan aplikasi kanggo NLP arab.', 'he': 'לאחרונה, ארכיטקטורות מבוססות על מעבר מאומנות מראש הוכיחו להיות יעילות מאוד בנוגע לדוגמא ושפה והבנה, בהתחשב בהם מאומנים על גופוס גדול מספיק. היישומים בדורת שפות ערבית עדיין מתעכבים בהשוואה לקדמות נוספות של NLP בעיקר בגלל חוסר דוגמנים של דוגמנים של דוגמני שפות ערבית מתקדמות. In this paper, we develop the first advanced Arabic language generation model, AraGPT2, trained from scratch on a large Arabic corpus of internet text and news articles.  Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available.  המודל הגדול הוערך והופיע הצלחה במשימות שונות כולל דור חדשות סינטטיות, וענות לשאלות אפס. לדור טקסטים, הדוגמא הטובה ביותר שלנו משיגה בעיה של 29.8 על מאמרים של ויקיפדיה. מחקר ביצע עם מערכים אנושיים הראה את הצלחה המשמעותית של AraGPT2-mega ביצירת מאמרים חדשות שקשה להבדיל מאמרים שנכתבים על ידי בני אדם. We thus develop and release an automatic discriminator model with a 98% percent accuracy in detecting model-generated text.  The models are also publicly available, hoping to encourage new research directions and applications for Arabic NLP.', 'ha': "A yanzu, masu tsari da aka sanar da shi a gaba-wa-tunkuɗar transformanci sun jarraba su zama mai amfani da matsayin misalin harshen da fahimci, kuma aka sanar da su a kan karatun mai girma. Shiryoyin ayukan cikin zayen harshe wa Larabci sun ci daidai da wasu tsofarin NLP masu kamata maimainli sabõda manan da aka gabatar da misãlai masu salon Larabci. A cikin wannan takarda, Munã ƙarfafa na farkon da aka gabatar da motel na harshen Larabci, AraGPT2, wanda aka yi wa tunkuɗe daga karatun sarki mai Larabci na littãfin da kuma takardar lãbãri. Babbayinmu mafi girma, AraGPT2-mega, yana da parameters 1.46 billioni, wannan da ke samar da misalin harshe na Larabci. The mega model was evaluated and showed success on different tasks including synthetic news generation, and zero-shot question answering.  Ga kiyayen matsayi, misalinmu mafi kyãwo ya sami wani matangaki na 29.8 a kan makala na Wikimedia wanda aka riƙe. Wata fitina da aka samar da masu qiimako na mutum, ya nũna babban rabo na AraGPT2-mega cikin ta ƙiƙira makala da za'a yin rarrabe daga makala na rubũtan mutum. Kayya, ko kuma Muke buɗe wata misali mai yin gaura farat ɗaya da yana da tsari na %98 a cikin gane misalin ayuka wanda aka gina shi. Ana sami misalin a bayyane, don a yi kwaɗayin su ƙara wa shiryoyin tafarki da shiryoyin ayuka na LP na Larabci.", 'bo': 'འཕྲལ་ཁམས་དེ་ལྟ་བུའི་སྔོན་གྱིས་འགྱུར་བ་ཅན་གྱི་བཟོ་བརྩིས་གཞི་བཟོ་བ་ཡིན་པའི་བཟོ་བརྩིས་གཞི་བཟོ་བ་ནི་སྐད་ཡིག་ཆའི་མིང་དཔྱད་དང་རྟོགས་ ཨ་རབ་ཀྱི་སྐད་རིགས་ལ་བཅས་ཀྱི་ཉེར་སྤྱོད་མིའི་ནང་དུ་ནུས་པ་གཞན་དང་མཉམ་ཕར་རིས་ཕར་མེད་ཅིག་མཐུན་ནུས་མེད་འདུག་པས In this paper, we develop the first advanced Arabic language generation model, AraGPT2, trained from scratch on a large Arabic corpus of internet text and news articles. Our largest model, AraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic language model available. ཆས་གཞུང་གིས་མི་དབྱིབས་ཞིབ་འཇུག་བྱས་པར་ལས་རྐྱེན་གྱིས་བྱ་རིམ་འདྲ་བ་དང་གསར་བརྗོད་ཀྱི་གསར་འགུལ་ལ་སུ་མཐུན་སྐྱེ ཚིག་ཡིག་གི་མི་རབས་དང་། Human evaluators འུ་ཅག་གིས་འདི་ལྟ་བུའི་རྣམ་གྲངས་གསར་འཛུགས་པའི་ཡིག་གེ་རྟོགས་པ་དང་རང་འགུལ་གྱིས་བཤད་སྡུད་མིག་སྟོན་པ་ཡོད། Models are also publicly available, hoping to encourage new research directions and applications for Arabic NLP.'}
{'en': 'SERAG : Semantic Entity Retrieval from Arabic Knowledge Graphs', 'pt': 'SERAG: Recuperação semântica de entidades a partir de gráficos de conhecimento em árabe', 'es': 'SERAG: Recuperación semántica de entidades a partir de gráficos de conocimiento árabes', 'fr': "SERAG\xa0: Extraction d'entités sémantiques à partir de graphes de connaissances arabes", 'ar': 'سراج: استرجاع الكيان الدلالي من الرسوم البيانية المعرفية العربية', 'ja': 'SERAG ：アラビア語の知識グラフからのセマンティックエンティティの検索', 'zh': 'SERAG曰:检阿拉伯语图谱语义体也', 'hi': 'SERAG: अरबी ज्ञान रेखांकन से शब्दार्थ इकाई पुनर्प्राप्ति', 'ru': 'SERAG: Семантическое извлечение сущностей из арабских графов знаний', 'ga': 'SERAG: Aonán Séimeantach Aisghabháil ó Ghrafanna Eolais Araibise', 'el': 'SERAG: Ανάκτηση σημασματικής οντότητας από αραβικά γραφήματα γνώσης', 'ka': 'Constellation name (optional)', 'hu': 'SERAG: Szemantikus entitás visszaszerezése arab tudásgrafokból', 'kk': 'СЕРАГ: Араб білім графиктерінен семантикалық нысандарды алу', 'lt': 'SERAG: Semantinio subjekto gavimas iš arabų žinių grafikų', 'it': 'SERAG: Recupero di entità semantiche dai grafici di conoscenza araba', 'mk': 'СЕРАГ: Земање семантични ентитети од графичките графики на арапско знаење', 'ml': 'സെരാഗ്: അറബിയിലെ അറിവ് ഗ്രാഫ്സില്\u200d നിന്നും സെമാന്റിക് എന്റിറ്റി വീണ്ടെടുക്കുക', 'mn': 'СЕРАГ: Арабын мэдлэг графиктээс Semantic Entity Retrieval from Arabic Knowledge Graphs', 'ms': 'SERAG: Pemulihan Entiti Semantik dari Graf Pengetahuan Arab', 'mt': 'SERAG: Qligħ ta’ Entità Semantika minn Grafiki tal-Għarfien Għarbi', 'pl': 'SERAG: Odzyskiwanie jednostek semantycznych z arabskich wykresów wiedzy', 'no': 'Constellation name (optional)', 'ro': 'SERAG: Recuperarea entităților semantice din graficele de cunoștințe arabe', 'si': 'SERAG: සෙමැන්ටික් ඉන්තිත්වය ආරබික දන්න ග්\u200dරාෆ්ස් වලින් පිළිගන්න', 'sr': 'SERAG: Uzimanje semantičkih podataka iz arapskih znanstvenih grafa', 'sv': 'SERAG: Semantic Entity Retrieval från arabiska kunskapsgrafer', 'so': 'SERAG: Retrieval of Semantic Entity from Graphs of Carabi Knowledge', 'ur': 'سیمنٹی اینٹیٹی عربی علم گراف سے پھیرنا', 'ta': 'SERAG: அரேபிய அறிவு வரைபடங்களிலிருந்து செமாண்டிக் உள்ள மீட்டெடுப்பு', 'uz': 'SERAG: Semantic Entity Restoration of Arab Knowledge Graphs', 'vi': 'Giờ thực thể kỳ diệu lấy lại từ đồ hoạ về tri thức Ả Rập', 'bg': 'СЕРАГ: Извличане на семантична същност от арабски графики на знанието', 'nl': 'SERAG: Semantic Entity Retrieval uit Arabische kennisgrafieken', 'de': 'SERAG: Semantic Entity Retrieval aus arabischen Wissensgrafiken', 'id': 'SERAG: Penerimaan Entitas Semantik dari Graf Pengetahuan Arab', 'hr': 'SERAG: Uzimanje semantičkih podataka iz arapskih znanstvenih grafa', 'da': 'SERAG: Semantic Entity Hentning fra arabisk viden grafer', 'ko': 'SERAG: 아랍어 지식도에서 의미 실체 검색', 'fa': 'بازیابی از گرافهای دانش عربی', 'sw': 'SERAG: Kurudishwa kwa Ujadala wa Kiarabu', 'tr': 'part-type', 'sq': 'SERAG: Rimarrja e njësisë Semantike nga grafikët e njohurive arabe', 'am': 'SERAG: Semantic Entity Retrieval from Arabic Knowledge Graphs', 'af': 'Constellation name (optional)', 'az': 'SERAG: Arap√ßa bilgi grafikl…ôrind…ôn Semantik Entity Retrieval', 'bn': 'সেরাং: আরবি জ্ঞানের গ্রাফ থেকে সেম্যান্টিক এন্টিটি পুনরুদ্ধার', 'ca': 'SERAG: Semantic Entity Retrieval from Arabic Knowledge Graphs', 'hy': 'ՍԵՌԱԳ. Սեմանտիկ անհատականությունը Արաբական գիտելիքի գրաֆիկներից ստանալը', 'cs': 'SERAG: Získání sémantických entit z arabských znalostních grafů', 'et': 'SERAG: Semantilise olemi hankimine araabia teadmiste graafikutest', 'bs': 'SERAG: Uzimanje semantičkih podataka iz arapskih znanstvenih grafa', 'fi': 'SERAG: Semanttisen kokonaisuuden nouto arabialaisista tietokaavioista', 'jv': 'Kernel', 'sk': 'SERAG: Pridobivanje semantičnih entitet iz arabskih grafikov znanja', 'bo': 'SERAG: Semantic Entity Retrieval from Arabic Knowledge Graphs', 'ha': 'KCharselect unicode block name', 'he': 'SERAG: Semantic Entity Retrieval from Arabic Knowledge Graphs'}
{'en': 'Knowledge graphs (KGs) are widely used to store and access information about entities and their relationships. Given a query, the task of entity retrieval from a KG aims at presenting a ranked list of entities relevant to the query. Lately, an increasing number of models for entity retrieval have shown a significant improvement over traditional methods. These models, however, were developed for English KGs. In this work, we build on one such system, named KEWER, to propose SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs). Like KEWER, SERAG uses random walks to generate entity embeddings. DBpedia-Entity v2 is considered the standard test collection for entity retrieval. We discuss the challenges of using it for non-English languages in general and Arabic in particular. We provide an Arabic version of this standard collection, and use it to evaluate SERAG. SERAG is shown to significantly outperform the popular BM25 model thanks to its multi-hop reasoning.', 'fr': "Les graphes de connaissances (KG) sont largement utilisés pour stocker et accéder à des informations sur les entités et leurs relations. En fonction d'une requête, la tâche de récupération d'entité auprès d'un KG vise à présenter une liste classée des entités pertinentes pour la requête. Ces derniers temps, un nombre croissant de modèles de récupération d'entités ont montré une amélioration significative par rapport aux méthodes traditionnelles. Ces modèles ont cependant été développés pour les KG anglais. Dans ce travail, nous nous appuyons sur un tel système, nommé KEWER, pour proposer SERAG (Sémantique Entité Retrieval from Arabic Knowledge Graphs). Comme KEWER, SERAG utilise des marches aléatoires pour générer des intégrations d'entités. DBPedia-Entity v2 est considéré comme la collection de test standard pour la récupération d'entités. Nous discutons des défis liés à son utilisation pour les langues autres que l'anglais en général et l'arabe en particulier. Nous fournissons une version arabe de cette collection standard, et nous l'utilisons pour évaluer SERAG. Il a été démontré que SERAG surpasse de manière significative le modèle BM25 populaire grâce à son raisonnement multi-sauts.", 'ja': 'ナレッジグラフ（ KG ）は、エンティティとその関係に関する情報を保存およびアクセスするために広く使用されています。所与のクエリでは、KGからエンティティを取得するタスクは、クエリに関連するエンティティのランク付けされたリストを提示することを目的としています。最近では、エンティティ検索のためのモデルの数が増加しており、従来の方法よりも大幅に改善されていることが示されています。しかし、これらのモデルは英語のKGのために開発された。この研究では、SERAG （アラビア語の知識グラフからのセマンティックエンティティ検索）を提案するために、KEWERという名前のそのようなシステムを構築しています。KEWERと同様に、SERAGはランダムウォークを使用してエンティティ埋め込みを生成します。DBpedia - Entity v 2は、エンティティ取得のための標準的なテストコレクションと見なされます。英語以外の言語、特にアラビア語に使用する際の課題について説明します。この標準コレクションのアラビア語版を提供し、SERAGの評価に使用します。SERAGは、そのマルチホップ推論により、人気のあるBM 25モデルを大幅に上回る性能を示しています。', 'ar': 'تُستخدم الرسوم البيانية المعرفية (KGs) على نطاق واسع لتخزين المعلومات حول الكيانات وعلاقاتها والوصول إليها. بالنظر إلى الاستعلام ، تهدف مهمة استرجاع الكيانات من KG إلى تقديم قائمة مرتبة بالكيانات ذات الصلة بالاستعلام. في الآونة الأخيرة ، أظهر عدد متزايد من نماذج استرجاع الكيانات تحسنًا كبيرًا مقارنة بالطرق التقليدية. ومع ذلك ، تم تطوير هذه النماذج لرياض الأطفال الإنجليزية. في هذا العمل ، نبني على أحد هذه الأنظمة ، المسمى KEWER ، لاقتراح SERAG (استرجاع الكيان الدلالي من الرسوم البيانية للمعرفة العربية). مثل KEWER ، تستخدم SERAG مسارات عشوائية لإنشاء حفلات زفاف للكيانات. تعتبر DBpedia-Entity v2 مجموعة الاختبار القياسية لاسترداد الكيان. نناقش تحديات استخدامه للغات غير الإنجليزية بشكل عام والعربية بشكل خاص. نحن نقدم نسخة عربية من هذه المجموعة القياسية ، ونستخدمها لتقييم SERAG. تبين أن SERAG تفوقت بشكل كبير على نموذج BM25 الشهير بفضل المنطق متعدد القفزات.', 'es': 'Los gráficos de conocimiento (KG) se utilizan ampliamente para almacenar y acceder a información sobre las entidades y sus relaciones. Dada una consulta, la tarea de recuperación de entidades de un KG tiene como objetivo presentar una lista clasificada de entidades relevantes para la consulta. Últimamente, un número cada vez mayor de modelos para la recuperación de entidades ha mostrado una mejora significativa con respecto a los métodos tradicionales. Sin embargo, estos modelos se desarrollaron para los KG ingleses. En este trabajo, nos basamos en uno de esos sistemas, llamado KEWER, para proponer SERAG (Semantic Entity Retrieval from Arabic Knowledge Graphs). Al igual que KEWER, SERAG utiliza caminatas aleatorias para generar incrustaciones de entidades. DBPEDIA-entity v2 se considera la colección de pruebas estándar para la recuperación de entidades. Discutimos los desafíos de usarlo para idiomas distintos del inglés en general y árabe en particular. Proporcionamos una versión en árabe de esta colección estándar y la utilizamos para evaluar SERAG. Se ha demostrado que SERAG supera significativamente al popular modelo BM25 gracias a su razonamiento multisalto.', 'pt': 'Os gráficos de conhecimento (KGs) são amplamente utilizados para armazenar e acessar informações sobre entidades e seus relacionamentos. Dada uma consulta, a tarefa de recuperação de entidades de um KG visa apresentar uma lista ordenada de entidades relevantes para a consulta. Ultimamente, um número crescente de modelos para recuperação de entidades tem mostrado uma melhoria significativa em relação aos métodos tradicionais. Esses modelos, no entanto, foram desenvolvidos para KGs ingleses. Neste trabalho, construímos um desses sistemas, denominado KEWER, para propor o SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs). Assim como o KEWER, o SERAG usa passeios aleatórios para gerar embeddings de entidades. DBpedia-Entity v2 é considerado a coleção de teste padrão para recuperação de entidade. Discutimos os desafios de usá-lo para idiomas diferentes do inglês em geral e árabe em particular. Fornecemos uma versão em árabe desta coleção padrão e a utilizamos para avaliar o SERAG. O SERAG demonstrou ter um desempenho significativamente superior ao popular modelo BM25, graças ao seu raciocínio multi-hop.', 'zh': '知图谱(KG)博于存储访问信息。 给定询之, KG 求其实体之指,以列其列。 近者,益多之实体检索模形见旧法之大改进也。 然为英国KG发也。 于此立KEWER之统,立SERAG(于阿拉伯语图谱之中,检语义体)。 与 KEWER 同,SERAG 用随机游走以成实体。 DBpedia-Entity v2 为实体检索之准。 议以非英语语挑战,特阿拉伯语。 合阿拉伯语版本,以质其SERAG。 SERAG多推理显优于流行之BM25型号。', 'ru': 'Графы знаний (KG) широко используются для хранения и доступа к информации о сущностях и их взаимоотношениях. Учитывая запрос, задача извлечения сущности из KG направлена на представление ранжированного списка сущностей, имеющих отношение к запросу. В последнее время все большее число моделей поиска информации о сущностях значительно улучшилось по сравнению с традиционными методами. Эти модели, однако, были разработаны для английских КГ. В этой работе мы основываемся на одной такой системе, названной KEWER, чтобы предложить SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs). Как и KEWER, SERAG использует случайные ходы для создания вложений сущностей. DBpedia-Entity v2 считается стандартной тестовой коллекцией для поиска сущностей. Мы обсуждаем проблемы его использования для неанглоязычных языков в целом и для арабского языка в частности. Мы предоставляем арабскую версию этой стандартной коллекции и используем ее для оценки SERAG. Показано, что SERAG значительно превосходит популярную модель BM25 благодаря своим мультихоповым рассуждениям.', 'hi': 'नॉलेज ग्राफ (केजी) का व्यापक रूप से उपयोग संस्थाओं और उनके संबंधों के बारे में जानकारी को संग्रहीत करने और एक्सेस करने के लिए किया जाता है। एक क्वेरी को देखते हुए, एक केजी से एंटिटी पुनर्प्राप्ति के कार्य का उद्देश्य क्वेरी के लिए प्रासंगिक संस्थाओं की एक रैंक सूची प्रस्तुत करना है। हाल ही में, इकाई पुनर्प्राप्ति के लिए मॉडल की बढ़ती संख्या ने पारंपरिक तरीकों पर एक महत्वपूर्ण सुधार दिखाया है। हालांकि, इन मॉडलों को अंग्रेजी केजी के लिए विकसित किया गया था। इस काम में, हम एक ऐसी प्रणाली पर निर्माण करते हैं, जिसका नाम KEWER है, SERAG (अरबी ज्ञान ग्राफ़ से शब्दार्थ इकाई पुनर्प्राप्ति) का प्रस्ताव करने के लिए। KEWER की तरह, SERAG इकाई एम्बेडिंग उत्पन्न करने के लिए यादृच्छिक चलता है का उपयोग करता है। DBpedia-Entity v2 को एंटिटी पुनर्प्राप्ति के लिए मानक परीक्षण संग्रह माना जाता है। हम सामान्य रूप से गैर-अंग्रेजी भाषाओं और विशेष रूप से अरबी के लिए इसका उपयोग करने की चुनौतियों पर चर्चा करते हैं। हम इस मानक संग्रह का एक अरबी संस्करण प्रदान करते हैं, और SERAG का मूल्यांकन करने के लिए इसका उपयोग करते हैं। SERAG को अपने मल्टी-हॉप तर्क के लिए लोकप्रिय BM25 मॉडल धन्यवाद को काफी हद तक बेहतर प्रदर्शन करने के लिए दिखाया गया है।', 'ga': 'Úsáidtear graif eolais (KGanna) go forleathan chun faisnéis a stóráil agus a rochtain faoi eintitis agus a gcaidrimh. I bhfianaise ceiste, is é is aidhm don tasc maidir le haonáin a aisghabháil ó KG liosta rangaithe de na heintitis a bhaineann leis an gceist a chur i láthair. Le déanaí, tá méadú suntasach tagtha ar líon na múnlaí d’aisghabháil aonáin ar mhodhanna traidisiúnta. Forbraíodh na samhlacha seo, áfach, do KGanna Béarla. San obair seo, cuirimid le córas amháin dá leithéid, darb ainm KEWER, chun SERAG (Aisghabháil Aonán Séimeantach ó Ghrafanna Eolais Araibise) a mholadh. Cosúil le KEWER, úsáideann SERAG siúlóidí randamacha chun leabaithe aonáin a ghiniúint. Meastar DBpedia-Entity v2 an bailiúchán caighdeánach tástála le haghaidh aisghabháil aonáin. Pléimid na dúshláin a bhaineann le húsáid a bhaint as do theangacha nach Béarla iad i gcoitinne agus an Araibis go háirithe. Cuirimid leagan Araibis den bhailiúchán caighdeánach seo ar fáil, agus úsáidimid é chun SERAG a mheas. Léirítear go sáraíonn SERAG an tsamhail mhóréilimh BM25 a bhuíochas dá réasúnaíocht il-hop.', 'hu': 'A tudásdiagramokat széles körben használják az entitásokról és kapcsolataikról szóló információk tárolására és elérésére. Egy lekérdezés esetén a KG-ból történő entitás lekérdezésének feladata a lekérdezés szempontjából releváns entitások rangsorolt listájának bemutatása. Az utóbbi időben egyre növekvő számú modell mutatott jelentős javulást a hagyományos módszerekhez képest. Ezeket a modelleket azonban angol KG-k számára fejlesztették ki. Ebben a munkában egy ilyen rendszerre építünk, a KEWER néven, hogy javasoljuk a SERAG (Semantic Entity Retrieval from Arab knowledge Graphs). A KEWER-hez hasonlóan a SERAG véletlenszerű sétákat használ az entitások beágyazásához. A DBpedia-Entity v2 az entitás visszakereséséhez szükséges standard tesztgyűjteménynek tekinthető. Megvitatjuk, milyen kihívásokat jelent a nem angol nyelvek használata általában és különösen az arab nyelvek esetében. Ennek a szabványos gyűjteménynek arab változatát biztosítjuk, és a SERAG értékeléséhez használjuk. A SERAG jelentősen felülmúlja a népszerű BM25 modellt a multi-hop érvelésének köszönhetően.', 'ka': 'მეცნიერების გრაფიკები (KGs) ძალიან გამოყენებულია ინფორმაციის შესახებ ინფორმაციის და შესახებ ინფორმაციის შესახებ. Name საბოლოოდ, ინტერტიკის მიღებისთვის მოდელების უფრო დიდი მოდელეები გამოიყენება საშუალოდ საუკეთესო მეტისებზე. მაგრამ ეს მოდელები ინგლისური KGs-ის განვითარებულია. ამ სამუშაოში, ჩვენ ვაკეთებთ ერთი ასეთი სისტემაზე, რომელიც სახელი KEWER, რომ SERAG (სემანტიკური ინტერტიკური მიღება აპაბური ცნობილის გრაფიდან). როგორც KEWER, SERAG გამოიყენება შემთხვევაში მოთავსდება ინტერტიკის შექმნა. Name ჩვენ განსაკუთრებულია განსაკუთრებულიად ანგლისური ენებისთვის გამოყენება. ჩვენ ამ სტანდარტული კოლექციის აპაბიური ვერსია დავიყენებთ, და გამოყენებთ SERAG-ს განსაზღვრებისთვის. SERAG მოჩვენებულია, რომ უფრო მნიშვნელოვანი BM25 მოდელის მომდელის გამოყენება, რადგან მნიშვნელოვანი განსაზღვრებისთვის.', 'el': 'Τα γραφήματα γνώσης (ΚΓ) χρησιμοποιούνται ευρέως για την αποθήκευση και πρόσβαση σε πληροφορίες σχετικά με οντότητες και τις σχέσεις τους. Δεδομένου ενός ερωτήματος, το καθήκον ανάκτησης οντότητας από ένα KG αποσκοπεί στην παρουσίαση ενός ταξινομημένου καταλόγου οντοτήτων σχετικών με το ερώτημα. Πρόσφατα, ένας αυξανόμενος αριθμός μοντέλων ανάκτησης οντοτήτων έδειξε σημαντική βελτίωση έναντι των παραδοσιακών μεθόδων. Αυτά τα μοντέλα, ωστόσο, αναπτύχθηκαν για αγγλικές ΚG. Στην εργασία αυτή, χτίζουμε πάνω σε ένα τέτοιο σύστημα, το ΚΕWER, για να προτείνουμε SERAG (Σήμανση Οντότητας από Γράφηματα Αραβικής γνώσης). Όπως και το KEWER, το SERAG χρησιμοποιεί τυχαίους περιπάτους για να δημιουργήσει ενσωματώσεις οντότητας. Το DBpedia-Entity v2 θεωρείται η τυποποιημένη συλλογή δοκιμών για ανάκτηση οντότητας. Συζητούμε τις προκλήσεις της χρήσης του για τις μη αγγλικές γλώσσες γενικότερα και τα αραβικά ειδικότερα. Παρέχουμε μια αραβική έκδοση αυτής της πρότυπης συλλογής και τη χρησιμοποιούμε για την αξιολόγηση της SERAG. Αποδεικνύεται ότι η SERAG ξεπερνά σημαντικά το δημοφιλές μοντέλο BM25 χάρη στη λογική πολλαπλών χορού.', 'it': "I grafici della conoscenza (KG) sono ampiamente utilizzati per memorizzare e accedere alle informazioni sulle entità e le loro relazioni. Data una query, il compito di recupero di entità da un KG mira a presentare un elenco classificato di entità rilevanti per la query. Ultimamente, un numero crescente di modelli per il recupero di entità ha mostrato un miglioramento significativo rispetto ai metodi tradizionali. Questi modelli, tuttavia, sono stati sviluppati per i KG inglesi. In questo lavoro, costruiamo su un tale sistema, chiamato KEWER, per proporre SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs). Come KEWER, SERAG utilizza percorsi casuali per generare incorporazioni di entità. DBpedia-Entity v2 è considerata la raccolta di test standard per il recupero di entità. Discutiamo le sfide dell'utilizzo per le lingue non inglesi in generale e l'arabo in particolare. Forniamo una versione araba di questa collezione standard e la utilizziamo per valutare SERAG. SERAG ha dimostrato di superare significativamente il popolare modello BM25 grazie al suo ragionamento multi-hop.", 'lt': 'Žinių grafikai (KG) plačiai naudojami saugoti ir gauti informaciją apie subjektus ir jų santykius. Atsižvelgiant į klausimą, ūkio subjekto užduotis gauti iš KG yra pateikti klausimui svarbių subjektų sąrašą. Pastaruoju metu vis daugiau ūkio subjektų atgavimo modelių pastebimai pagerėjo, palyginti su tradiciniais metodais. Tačiau šie modeliai buvo sukurti anglų KG. Šiame darbe mes remiamės tokia sistema, vadinama KEWER, kuri siūlo SERAG (Semantinio subjekto gavimas iš arabų žinių grafikų). Like KEWER, SERAG uses random walks to generate entity embeddings.  DBpedia-Entity v2 laikomas standartiniu bandymų surinkimu subjektui gauti. Mes diskutuojame apie uždavinius, susijusius su jų naudojimu ne anglų kalbomis apskritai ir ypač arabų kalba. We provide an Arabic version of this standard collection, and use it to evaluate SERAG.  Įrodyta, kad SERAG gerokai viršija populiarų BM25 model į, nes jis pagrįstas daugialypiu požiūriu.', 'mk': 'Графите за знаење (KG) се широко употребени за зачувување и пристап до информации за ентитетите и нивните односи. Со оглед на прашањето, задачата на преземањето на ентитетите од КГ има за цел претставување рангирана листа на ентитети релевантни за прашањето. Во последно време, зголемениот број модели за преземање на ентитетите покажаа значително подобрување во однос на традиционалните методи. Сепак, овие модели беа развиени за англиски КГ. In this work, we build on one such system, named KEWER, to propose SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs).  Како КЕВЕР, СЕРАГ користи случајни прошетки за генерирање вградени ентитети. DBpedia- Entity v2 се смета за стандардна тестова колекција за преземање на ентитетите. Разговараме за предизвиците од користењето на неанглиските јазици генерално и особено на арапски јазик. Ние обезбедуваме арапска верзија на оваа стандардна колекција, и ја користиме за проценка на SERAG. СЕРАГ се покажува дека значително го надминува популарниот модел БМ25 благодарение на неговото мултихоп размислување.', 'ms': 'Graf pengetahuan (KG) digunakan secara luas untuk menyimpan dan mengakses maklumat mengenai entiti dan hubungan mereka. Berdasarkan pertanyaan, tugas pemulihan entiti dari KG bermaksud memperkenalkan senarai tertinggi entiti yang berkaitan dengan pertanyaan. Akhir-akhir ini, jumlah model yang meningkat untuk pemulihan entiti telah menunjukkan peningkatan yang signifikan atas kaedah tradisional. Model ini, bagaimanapun, telah dikembangkan untuk KG Inggeris. Dalam kerja ini, kami membina pada satu sistem seperti itu, bernama KEWER, untuk melamar SERAG (Pemulihan Entiti Semantik dari Graf pengetahuan Arab). Seperti KEWER, SERAG menggunakan berjalan rawak untuk menghasilkan penyembedding entiti. DBpedia-Entity v2 is considered the standard test collection for entity retrieval.  Kami membincangkan cabaran menggunakannya untuk bahasa bukan bahasa Inggeris secara umum dan bahasa Arab secara khusus. Kami menyediakan versi Arab koleksi piawai ini, dan menggunakannya untuk menilai SERAG. SERAG ditunjukkan untuk melampaui batas yang signifikan model BM25 terkenal kerana alasan multi-hop.', 'kk': 'Білім графиктері (KG) бірліктері мен қатынастары туралы мәліметтерді сақтау және қатынау үшін көп қолданылады. Сұраныс келтірілсе, KG- ден алу нысандарының тапсырмасы сұраныстағы нысандар тізімін көрсетуге болады. Соңғы уақытта бірліктерді алу үшін үлгілер саны көтеріп, әдеттегі әдістер арқылы үлкен жақсартылығын көрсетті. Бұл үлгілер ағылшын KG үшін жасалған. Бұл жұмыс ішінде, KEWER деп аталатын жерде SERAG (Араб мәліметтерінен Semantic Entity Retrieval) жүйесіне құрамыз. KEWER секілді, SERAG нысандарды ендіру үшін кездейсоқ жүргізуді қолданады. DBpedia- Entity v2 нысанды алу үшін стандартты сынақтар жинағын қалады. Біз оны ағылшын тілдері емес және әдетте араб тілдеріне қолдану үшін әсер етіп тұрмыз. Біз осы стандартты жинақтардың араб нұсқасын келтіріп, SERAG дегенді бағалау үшін қолданамыз. SERAG көп-хоп тәуелдеріне көптеген BM25 үлгісін өзгерту үшін көптеген болады.', 'mn': 'Мэдлэг график (КГ) нь биетүүд болон харилцааны тухай мэдээллийг хадгалж, ашиглах боломжтой ихэвчлэн хэрэглэгддэг. Кверийн хувьд, KG-ээс авсан бүтээлүүдийн даалгавар нь кверийн тухай холбоотой бүтээлүүдийн цуврал жагсаалт гаргах зорилго юм. Хамгийн сүүлийн үед нэгж авахын тулд олон загварын тоо нэмэгдсэн нь уламжлалтын арга загвараас илүү их сайжруулагдсан. Гэхдээ эдгээр загварууд Англи хэлний КГ-д хөгжигдсэн. Энэ ажил дээр бид KEWER гэдэг нэгэн систем дээр, SERAG (Араб мэдлэгийн графикаас Semantic Entity Retrieval) сургуульд сургаж байна. KEWER шиг, SERAG нь санамсаргүй алхам ашигладаг. DBpedia-Entity v2 Entity-г авах шалгалтын стандарт цуглуулга гэж үздэг. Бид үүнийг Англи хэл биш хэл дээр, ялангуяа Араб хэл дээр ашиглах сорилтуудыг ярьдаг. Бид энэ стандарт цуглуулалтын Араб хувилбарыг хангаж, SERAG-г үнэлэхэд ашиглаж байна. SERAG олон холбоотой ойлголтын үр дүнд олон хүмүүсийн BM25 загвараас илүү чухал болж чадна.', 'mt': 'Grafiki tal-għarfien (KGs) jintużaw b’mod wiesa’ biex jaħżnu u jaċċessaw informazzjoni dwar l-entitajiet u r-relazzjonijiet tagħhom. Minħabba mistoqsija, il-kompitu tal-irkupru tal-entità minn KG għandu l-għan li jippreżenta list a kklassifikata ta’ entitajiet rilevanti għall-mistoqsija. Dan l-a ħħar, għadd dejjem jikber ta’ mudelli għall-irkupru tal-entitajiet wera titjib sinifikanti fuq il-metodi tradizzjonali. Madankollu, dawn il-mudelli ġew żviluppati għall-KGs Ingliżi. F’din il-ħidma, aħna nibnu fuq sistema waħda bħal din, imsejħa KEWER, biex nipproponu SERAG (Qligħ ta’ Entità Semantika mill-Grafiki tal-Għarfien Għarbi). Like KEWER, SERAG uses random walks to generate entity embeddings.  DBpedia-Entity v2 huwa kkunsidrat il-ġbir standard tat-test għall-irkupru tal-entità. Aħna niddiskutu l-isfidi tal-użu tiegħu għal-lingwi mhux Ingliżi b’mod ġenerali u b’mod partikolari fl-Għarab. Aħna nipprovdu verżjoni Għarbija ta’ din il-ġbir standard, u nużaha biex nivvalutaw is-SERAG. Intwera li SERAG huwa ogħla b’mod sinifikanti mill-mudell popolari tal-BM25 bis-saħħa tar-raġunament multi hop tiegħu.', 'pl': 'Wykresy wiedzy (KG) są szeroko stosowane do przechowywania i uzyskiwania dostępu do informacji o podmiotach i ich relacjach. W przypadku zapytania zadaniem pobierania podmiotów z KG jest przedstawienie rankingowej listy podmiotów istotnych dla danego zapytania. Ostatnio coraz większa liczba modeli odzyskiwania jednostek wykazała znaczącą poprawę w stosunku do tradycyjnych metod. Modele te zostały jednak opracowane dla angielskich KG. W niniejszej pracy budujemy na jednym z takich systemów, o nazwie KEWER, aby zaproponować SERAG (Semantic Entity Retrieval z arabskich wykresów wiedzy). Podobnie jak KEWER, SERAG używa losowych spacerów do generowania osadzeń jednostek. DBpedia-Entity v2 jest uważany za standardową kolekcję testów do pobierania jednostek. Omawiamy wyzwania związane z używaniem go w językach innych niż angielski w ogóle, a w szczególności w arabskim. Dostarczamy wersję arabską tej standardowej kolekcji i wykorzystujemy ją do oceny SERAG. Wykazano, że SERAG znacznie przewyższa popularny model BM25 dzięki rozumowaniu multi-hop.', 'no': 'Kvitningsgrafar (KGs) er breidd brukt for å lagra og tilgang informasjon om einingar og forbindelsane sine. Gjennomsiktig ei spørjing må oppgåva for oppgåva til oppgåva til oppgåva frå ein KG vise ei rangert liste over einingar som er relevante til spørjinga. Nyleg har eit økt tal modeller for oppretting av einingar vist ein betydelig forbedring over tradisjonelle metodar. Desse modelane var imidlertid utvikla for engelsk KGs. I denne arbeida bygger vi på eit slik system, kalla KEWER, for å foreslå SERAG (semiantisk entitetshenting frå arabiske kunnskapsgraf). Som KEWER, SERAG brukar tilfeldige trekk for å laga einingar. @ info Vi diskuterer utfordringane for å bruka det for ikkje-engelske språk generelt og spesielt arabisk. Vi gjev ein arabisk versjon av denne standardssamlinga, og bruk den for å evaluera SERAG. SERAG vert vist at det populære BM25-modellet utfører betydelig, takk av det fleire høp-rasjonen.', 'ml': 'അറിവുള്ള ഗ്രാഫുകള്\u200d (കെജികള്\u200d) വസ്തുക്കളെക്കുറിച്ചും അവയുടെ ബന്ധങ്ങളെക്കുറിച്ചും വിവരങ്ങള്\u200d സൂക്ഷിക്കുവാ ഒരു ചോദ്യം കൊടുത്തതിനാല്\u200d, കെജിയില്\u200d നിന്നുള്ള വസ്തുക്കളുടെ ജോലിയുടെ നിര്\u200dണ്ണയിക്കപ്പെട്ട വസ്തുക്കളുടെ പട്ടിക ക ക അവസാനം സാധാരണ രീതിയിലേക്ക് വീണ്ടെടുക്കുന്നതിനുള്ള മോഡലുകള്\u200d കൂടുതല്\u200d പാരമ്പര്യമായ രീതികളില്\u200d മെച്ചപ്പെടു എങ്കിലും ഇംഗ്ലീഷ് കെജിസിനു വേണ്ടി ഈ മോഡലുകള്\u200d ഉണ്ടാക്കിയിരുന്നു. ഈ പ്രവര്\u200dത്തനത്തില്\u200d, കെയ്വെര്\u200d എന്ന പേരുള്ള ഒരു സിസ്റ്റമില്\u200d ഞങ്ങള്\u200d പണിയുന്നു, സെരാജിന് പ്രൊദ്ദേശിപ്പിക്കുന്നത് (അറബി കെവെര്\u200d പോലെ, സെരാഗ് സെറാജ് സാധാരണ നടക്കുന്നത് സാധാരണ വ്യവസ്ഥകള്\u200d ഉണ്ടാക്കാന്\u200d ഉപയോഗിക്കുന്നു. ഡിബിപെഡിയ- എന്റിറ്റി v2 വസ്തുവിനുള്ള വീണ്ടെടുക്കുന്നതിനുള്ള സാധാരണ പരീക്ഷണ സംഘടിപ്പിക്കപ് സാധാരണ ഇംഗ്ലീഷ് അല്ലാത്ത ഭാഷകള്\u200dക്ക് വേണ്ടി അതിനെ ഉപയോഗിക്കുന്നതിന്\u200dറെ വിലാസങ്ങള്\u200d ഞങ്ങള്\u200d സംസാ We provide an Arabic version of this standard collection, and use it to evaluate SERAG.  പ്രധാനപ്പെട്ട ബിഎം25 മോഡല്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതില്\u200d സെരാജ് കാണിക്കുന്നു. അതിന്റെ പല-ഹോപ്പ് കാരണങ', 'ro': 'Graficele cunoștințelor (KG) sunt utilizate pe scară largă pentru a stoca și a accesa informații despre entități și relațiile acestora. Având în vedere o interogare, sarcina de recuperare a entităților dintr-un KG vizează prezentarea unei liste clasate de entități relevante pentru interogare. În ultimul timp, un număr tot mai mare de modele pentru recuperarea entităților au arătat o îmbunătățire semnificativă față de metodele tradiționale. Aceste modele, însă, au fost dezvoltate pentru KG-urile engleze. În această lucrare, construim pe un astfel de sistem, numit KEWER, pentru a propune SERAG (Recuperarea Semantică a Entităților din Grafice de cunoaștere arabă). Ca KEWER, SERAG folosește plimbări aleatorii pentru a genera încorporări de entități. DBpedia-Entity v2 este considerată colecția standard de teste pentru recuperarea entităților. Discutăm provocările utilizării acestuia pentru limbile non-engleze în general și arabă în special. Oferim o versiune arabă a acestei colecții standard și o folosim pentru a evalua SERAG. S-a demonstrat că SERAG depășește semnificativ popularul model BM25 datorită raționamentului său multi-hop.', 'so': 'Shaqooyinka aqoonta (KGs) waxaa loo isticmaalaa in aad aad u kaydsato iyo aad u isticmaasho macluumaad la xiriira dhamaanka iyo xiriirkooda. Jabsi la siiyo, shaqada ku baaraandegista xafiiska KG wuxuu aimaa in uu soo bandhigo liiska saqafka ah oo la xiriira querida. Ugu dambeeyey, tusaalooyin badan oo korsocod ah oo loo soo celin karo ayaa tusay hagaajin aad u weyn oo ka sii kordha qaababka caadiga ah. Si kastaba ha ahaatee modelladan waxaa loo hormariyey Ingiriiska KGs. Markaas waxan, waxaynu ku dhisaynaa nidaam caynkaas ah oo la odhan jiray KEWER, si aan u soo jeedno SERAG (Semantic Entity Retrieval from Arab aqoon Graphs). Sida KEWER, SERAG wuxuu isticmaalaa socodka fudud si uu u sameeyo qalabka shaqaalaha. DBpedia-Entity v2 waxaa looga xisaabiyaa ururka imtixaanka standardka ah ee loo soo celinayo bogga. We discuss the challenges of using it for non-English languages in general and Arabic in particular.  Waxaannu siinaynaa warqad Carabi ah ee ururkan standard, waxaynu isticmaalnaa si aan ugu qiimeynayno SERAG. SERAG waxaa si weyn looga muujiyaa qaababka BM25 ee caadiga ah, waxaana ku mahad naqayaa sababtiisa badan.', 'sr': 'Grafi znanja (KG) se široko koriste za čuvanje i pristup informacijama o entitetima i njihovim odnosima. S obzirom na pitanje, zadatak prikupljanja entiteta iz KG-a je cilj da predstavi redovnu listu entiteta koje su relevantne na pitanje. U poslednje vrijeme, povećan broj modela za povlačenje entiteta pokazao je značajno poboljšanje u tradicionalnim metodama. Međutim, ove modele su razvijene za engleske KGs. U ovom poslu, izgradili smo na jednom takvom sistemu po imenu KEWER, kako bi predložili SERAG (Semantički otkupljanje podataka iz arapskih znanja Grafa). Kao KEWER, SERAG koristi nasumične šetnje kako bi stvorila integraciju entiteta. DBpedia-Entity v2 se smatra standardnom kolekcijom testova za uzbunu entiteta. Razgovaramo o izazovima da ga koristimo za ne-engleske jezike općenito i posebno na arapskom. Mi pružamo arabsku verziju ove standardne kolekcije i koristimo ga za procjenu SERAG. SERAG pokazuje da značajno iznosi popularni model BM25 zahvaljujući njegovom multihopskom razmišljanju.', 'ur': 'علم گراف (KGs) اکثر متحدوں اور رابطہ کے بارے میں اطلاعات کو ذخیره اور دسترسی کرنے کے لئے استعمال کئے جاتے ہیں. Name آخر میں، انٹیٹیوں کو اٹھانے کے لئے بہت زیادہ نمونوں کی تعداد سنتی طریقوں پر ایک بڑی اضافہ دکھائی ہے. لیکن یہ موڈل انگلیسی کجی کے لئے تولید کی گئی تھی۔ اس کام میں ہم ایک ایسی سیستم پر بناتے ہیں جس کا نام KEWER ہے کہ SERAG کی پیشنهاد کریں۔ KEWER کی طرح، SERAG نے انٹیٹی ایمبڈینگ پیدا کرنے کے لئے طرح طرح طرح طرح طرح طرح طرح طرح کے چلنے کے لئے استعمال کرتا ہے. Name ہم اس کے استعمال کرنے کی چالوں میں مخصوص انگلیسی زبانوں اور عربی زبانوں کے لئے بحث کرتے ہیں۔ ہم اس استاندارڈ کالکٹ کی ایک عربی ورزی دیتے ہیں، اور اسے SERAG کے مطابق استعمال کرتے ہیں. SERAG دکھائی جاتی ہے کہ اس کے ملی-هوپ منطقی کے شکریہ سے زیادہ محبوب BM25 موڈل کو اضافہ کرتا ہے.', 'si': 'Name Name අන්තිමයෙන්, විශාල විශාල විශාල විශාල විධානයක් පෙන්වන්න පුළුවන් විශාල විධානය විධාන ඒත් මේ මොඩේල් ඉංග්\u200dරීසි KGs වලට විස්තර කරලා තියෙනවා. මේ වැඩේදී, අපි ඒ වගේ පද්ධතියෙන් නිර්මාණය කරනවා, කෙවෙර් කියලා, SERAG (සෙමැන්ටික් ඉන්ටිටික් ප්\u200dරතිකාරය අරාබික් ද KAWER වගේ, SERAG භාවිතා කරන්න අන්තිම ඇතුල් සිදුවීම් සිදුවීම් විදිහට ප්\u200dරයෝජනය කරනවා. Name අපි ඒක පාවිච්චි කරනවා ඉංග්\u200dරීසි භාෂාවක් නැති විශේෂයෙන් සහ අරාබි භාෂාවක් විශේෂය අපි මේ ප්\u200dරමාණය සංගීතයේ අරාබික් වර්ගයක් දෙන්න, ඒ වගේම ඒක SERAG විශ්ලේෂණය කරන්න පාවිච්චි  SERAG පෙන්වන්නේ ලොකු BM25 මොඩේල් එක ගොඩක් හොප් හිතන්න ස්තූතියි.', 'sv': 'Kunskapsgrafer (KG) används ofta för att lagra och komma åt information om enheter och deras relationer. Med en fråga syftar uppgiften att hämta entiteter från en KG till att presentera en rangordnad lista över entiteter som är relevanta för frågan. På senare tid har ett ökande antal modeller för entitetshämtning visat en betydande förbättring jämfört med traditionella metoder. Dessa modeller utvecklades dock för engelska KG. I detta arbete bygger vi på ett sådant system, som heter KEWER, för att föreslå SERAG (Semantic Entity Retrieval from Arabic Knowledge Graphs). Liksom KEWER använder SERAG slumpmässiga promenader för att generera entitetsinbäddningar. DBpedia-Entity v2 anses vara standardtestsamlingen för entitetshämtning. Vi diskuterar utmaningarna med att använda den för icke-engelska språk i allmänhet och arabiska i synnerhet. Vi tillhandahåller en arabisk version av denna standardsamling och använder den för att utvärdera SERAG. SERAG har visat sig avsevärt överträffa den populära BM25-modellen tack vare sitt multi-hop resonemang.', 'ta': 'அறிவு வரைபடங்கள் (KGs) பொருள்கள் மற்றும் அவை இணைப்புகள் பற்றிய தகவல்களை சேமிக்க பயன்படுத்தப்படுகிறது. @ info சமீபத்தில், பொருள் மீட்டுதலுக்கான அதிகரிக்கும் மாதிரிகள் மரபார்ந்த முறைகளை விட முன்னேற்றம் காட்டியுள்ளது. ஆனால் இந்த மாதிரிகள் ஆங்கிலத்தில் KGகளுக்கு உருவாக்கப்பட்டது. இந்த வேலையில், நாம் KEWER பெயர் என்ற ஒரு போன்ற அமைப்பில் கட்டுகிறோம், SERAG (அரபி அறிவு கிராப்ஸிலிருந்து செமாண்டிக் மீட் KEWER போல, SERAG குறிப்பில்லாத நடைகளை பயன்படுத்தி பொருள் உள்ளீடுகளை உருவாக்க. DBpedia- Entity v2 பொருள் மீட்டலுக்கான இயல்பான சோதனை தொகுப்பு என கருதப்படும். பொதுவான மற்றும் அரபி மொழிகளுக்கு அதை பயன்படுத்துவதற்கான சவால்களிகளை நாம் விவாதம் செய்கிறோம். நாம் இந்த நிலையான தொகுப்பின் அரபி பதிப்பை வழங்குகிறோம் மற்றும் SERAG ஐ மதிப்பிட பயன்படுத்துகிறோம். பிஎம்25 மாதிரி முறைமையை மிகவும் வெளிப்படுத்துகிறது அதன் பல-hop காரணத்திற்கு நன்றி.', 'vi': 'Những biểu đồ về tri thức (KG) được sử dụng rộng rãi để lưu và truy cập thông tin về thực thể và mối quan hệ của chúng. Dựa vào một yêu cầu, nhiệm vụ phục hồi thực thể từ một KG nhằm cung cấp một danh sách các thực thể được xếp hạng liên quan tới yêu cầu. Gần đây, một số mô hình ngày càng tăng cho việc tìm kiếm thực thể đã cho thấy một tiến bộ đáng kể hơn các phương pháp truyền thống. Những mẫu này, tuy nhiên, được phát triển cho KG tiếng Anh. Trong công việc này, chúng ta xây dựng một hệ thống như thế, tên là KHÔNG CÓ, để đề xuất SerafiG (Semantic Entity Retrievel from Ả Rập knowledge Graphs). Giống như KEWER, tập đoàn serAG dùng bộ đi ngẫu nhiên để tạo ra sự tổ hợp. Lượng thực đơn MạngComment v2 là bộ sưu tập thử tiêu chuẩn cho việc lấy lại thực thể. Chúng ta thảo luận về thử thách sử dụng nó cho những ngôn ngữ không Anh nói chung và đặc biệt là tiếng Ả Rập. Chúng tôi cung cấp một phiên bản tiếng Ả Rập của bộ sưu tập tiêu chuẩn này, và dùng nó để đánh giá SerafiG. Sau khi sử dụng các mô hình BM25 nổi tiếng, tập đoàn sẽ được dàn xếp cao hơn hẳn.', 'uz': "Knowledge graphs (KGs) are widely used to store and access information about entities and their relationships.  Name Keyingi esa, quyidagi tiklash uchun ko'proq modellar soni taʼminlovchi usullarda juda katta yaxshi improvementni koʻrsatadi. Ammo, bu modellar ingliz KGs uchun yaratildi. Bu ishda, biz KEWER nomli bir tizimni quyimiz, SERAG (Arab ilmiy darajadagi Semantic Entity Retrieval). KEWER kabi, SERAG haqida quyidagi narsalarni yaratishga foydalanadi. Name Biz buni ingliz tildan foydalanuvchi qandaydir o'ylaymiz. Biz bu стандарт жамиятининг арабий версиясини яратамиз ва уни SERAG qiymatiga foydalanamiz. SERAG'ning bir necha-hop sabablarining ko'paytuvchilari uchun umuman BM25 modelini bajarishni juda qiyin ko'rsatadi.", 'bg': 'Графите на знанието (КГ) се използват широко за съхраняване и достъп до информация за субектите и техните взаимоотношения. При дадена заявка задачата за извличане на субекти от КГ има за цел да представи класиран списък на субекти, свързани с заявката. Напоследък все по-голям брой модели за извличане на обекти показват значително подобрение спрямо традиционните методи. Тези модели обаче са разработени за английските КГ. В тази работа ние изграждаме върху една такава система, наречена КЕВЕР, за да предложим СЕРАГ (извличане на семантични същества от арабски знания графики). Подобно на KEWER, SERAG използва случайни разходки, за да генерира вграждания на обекти. DBpedia-Entity v2 се счита за стандартна колекция от тестове за извличане на entiтети. Обсъждаме предизвикателствата при използването му за чужди езици като цяло и арабски по-специално. Ние предоставяме арабска версия на тази стандартна колекция и я използваме за оценка на СЕРАГ. Доказано е, че значително надминава популярния модел благодарение на своите мулти-хоп разсъждения.', 'da': "Vidensgrafer (KG'er) bruges i vid udstrækning til at gemme og få adgang til oplysninger om enheder og deres relationer. Givet en forespørgsel har opgaven med enhedshentning fra en KG til formål at præsentere en rangeret liste over enheder, der er relevante for forespørgslen. På det seneste har et stigende antal modeller for enhedshentning vist en betydelig forbedring i forhold til traditionelle metoder. Disse modeller blev dog udviklet til engelske KG'er. I dette arbejde bygger vi på et sådant system, kaldet KEWER, til at foreslå SERAG (Semantic Entity Retrieval from Arabic Knowledge Graphs). Ligesom KEWER bruger SERAG tilfældige gåture til at generere enhedsindlejringer. DBpedia-Entity v2 betragtes som standardtestsamlingen for enhedshentning. Vi diskuterer udfordringerne ved at bruge det til ikke-engelske sprog generelt og arabisk i særdeleshed. Vi leverer en arabisk version af denne standardsamling, og bruger den til at evaluere SERAG. SERAG har vist sig betydeligt bedre end den populære BM25 model takket være dens multi-hop ræsonnement.", 'nl': "Kennisgrafieken (KG's) worden veel gebruikt om informatie over entiteiten en hun relaties op te slaan en te openen. Bij een query heeft de taak om entiteiten uit een KG te halen tot doel een gerangschikte lijst van entiteiten te presenteren die relevant zijn voor de query. De laatste tijd heeft een toenemend aantal modellen voor entity retrieval een significante verbetering laten zien ten opzichte van traditionele methoden. Deze modellen zijn echter ontwikkeld voor Engelse KG's. In dit werk bouwen we op een dergelijk systeem, genaamd KEWER, om SERAG (Semantic Entity Retrieval from Arabic Knowledge Graphs) voor te stellen. Net als KEWER gebruikt SERAG random walks om entiteitsinsluitingen te genereren. DBpedia-Entity v2 wordt beschouwd als de standaardtestverzameling voor het ophalen van entiteiten. We bespreken de uitdagingen van het gebruik voor niet-Engelse talen in het algemeen en Arabisch in het bijzonder. Wij bieden een Arabische versie van deze standaardcollectie en gebruiken deze om SERAG te evalueren. SERAG blijkt aanzienlijk beter te presteren dan het populaire BM25 model dankzij zijn multi-hop redenering.", 'hr': 'Grafovi znanja (KGs) se široko koriste za čuvanje i pristup informacijama o entitetima i njihovim odnosima. S obzirom na zahtjev, zadatak prikupljanja entiteta iz KG-a je cilj predstavljati redovnu listu entitata relevantnih na zahtjev. U posljednje vrijeme, povećan broj modela za prikupljanje entiteta pokazao je značajno poboljšanje nad tradicionalnim metodama. Međutim, te modele su razvijene za engleske KGs. U ovom poslu, izgradili smo na jednom takvom sustavu po imenu KEWER, kako bi predložili SERAG (Semantički povlačenje podataka iz arapskih znanja Grafa). Kao KEWER, SERAG koristi nasumične šetnje kako bi stvorio integracije entiteta. DBpedia-Entity v2 smatra se standardnom kolekcijom testova za uzbunu entiteta. Razgovaramo o izazovima korištenja njega za ne-engleske jezike općenito i posebno na arapskom. Mi pružamo arapsku verziju ove standardne kolekcije i koristimo ga za procjenu SERAG-a. SERAG se pokazuje da značajno iznosi popularni model BM25 zahvaljujući njegovom multihopskom razmišljanju.', 'de': 'Wissensgraphen (KGs) werden häufig verwendet, um Informationen über Entitäten und ihre Beziehungen zu speichern und darauf zuzugreifen. Bei einer Abfrage zielt die Aufgabe des Entity Retrievals aus einer KG darauf ab, eine Rangliste der für die Abfrage relevanten Entitäten darzustellen. In letzter Zeit zeigt eine zunehmende Anzahl von Modellen für Entity Retrieval eine signifikante Verbesserung gegenüber herkömmlichen Methoden. Diese Modelle wurden jedoch für englische KGs entwickelt. In dieser Arbeit bauen wir auf einem solchen System namens KEWER auf, um SERAG (Semantic Entity Retrieval from Arabic Knowledge Graphs) vorzuschlagen. Wie KEWER verwendet SERAG zufällige Wege, um Entity-Einbettungen zu generieren. DBpedia-Entity v2 wird als Standardtestsammlung für Entity Retrieval betrachtet. Wir diskutieren die Herausforderungen der Verwendung für nicht-englische Sprachen im Allgemeinen und Arabisch im Besonderen. Wir stellen eine arabische Version dieser Standardsammlung zur Verfügung und verwenden diese zur Bewertung der SERAG. SERAG übertrifft das beliebte BM25-Modell dank seiner Multi-Hop-Argumentation deutlich.', 'id': 'Graf pengetahuan (KG) digunakan secara luas untuk menyimpan dan mengakses informasi tentang entitas dan hubungan mereka. Mengingat pertanyaan, tugas dari entitas retrieval dari KG bermaksud untuk mempersembahkan daftar tertinggi entitas yang relevan untuk pertanyaan. Pada akhir-akhir ini, jumlah model yang meningkat untuk mengembalikan entitas telah menunjukkan peningkatan yang signifikan atas metode tradisional. Model ini, bagaimanapun, dikembangkan untuk KG Inggris. Dalam pekerjaan ini, kami membangun pada satu sistem seperti itu, bernama KEWER, untuk melamar SERAG. Seperti KEWER, SERAG menggunakan jalan-jalan acak untuk menghasilkan embedding entitas. DBpedia-Entity v2 dianggap koleksi ujian standar untuk pemulihan entitas. Kami membahas tantangan menggunakannya untuk bahasa bukan Inggris secara umum dan bahasa Arab secara khusus. Kami menyediakan versi Arab dari koleksi standar ini, dan menggunakannya untuk mengevaluasi SERAG. SERAG ditunjukkan untuk melampaui model BM25 yang populer berkat alasan multi-hop.', 'ko': '지식 그래프(KG)는 실체와 그 관계에 대한 정보를 저장하고 접근하는 데 광범위하게 사용된다.KG에서 엔티티를 검색하는 작업은 해당 질의와 관련된 엔티티의 정렬 목록을 표시하기 위한 질의를 지정합니다.최근에 점점 더 많은 실체 검색 모델이 전통적인 방법보다 현저한 개선을 보이고 있다.그러나 이 모델들은 영국 KG를 위해 개발된 것이다.이 작업에서 우리는 이러한 KEWER라는 시스템을 바탕으로 SERAG(아랍어 지식도에서 의미 실체를 검색하는 것)를 제시했다.KEWER와 마찬가지로 SERAG는 무작위 유동을 사용하여 실체 삽입을 생성합니다.DBpedia Entity v2는 솔리드 검색의 표준 테스트 컬렉션으로 간주됩니다.우리는 그것을 비영어어, 특히 아랍어에 사용하는 도전에 대해 토론했다.우리는 이 표준 집합의 아랍어 버전을 제공하였으며, 이를 사용하여 SERAG를 평가하였다.다중 점프 추리로 인해 SERAG의 표현은 유행하는 BM25 모델보다 현저히 우수하다.', 'fa': 'گرافیک دانش (KGs) برای ذخیره و دسترسی اطلاعات درباره\u200cی شرکتها و رابطه\u200cهایشان وسیع استفاده می\u200cشود. با توجه به یک سؤال، کار برداشتن entity از یک KG هدف دارد که یک فهرست صف از entities relevant to the query را پیشنهاد کند. اخیرا، تعداد افزایش مدل برای بازیابی شرکت\u200cها بر روی روش\u200cهای سنتی بهتر شدنی را نشان داده است. ولی این مدلها برای KGs انگلیسی توسعه داده شدند. در این کار، ما روی یک سیستم به نام KEWER ساخته می\u200cشویم تا پیشنهاد SERAG (بازیابی از دانش های عربی) کنیم. مثل KEWER، SERAG از راه\u200cهای تصادفی استفاده می\u200cکند تا ابتدایی\u200cها را تولید کند. واحد DBpedia- Entity v2 به عنوان مجموعه آزمایش استاندارد برای بازیابی واحد محسوب می شود. ما در مورد چالش\u200cهای استفاده از آن برای زبانهای غیر انگلیسی در کل و مخصوص عربی صحبت می\u200cکنیم. ما نسخه عربی از این جمع استاندارد را پیشنهاد می کنیم و برای ارزیابی SERAG استفاده می کنیم. SERAG نشان داده می\u200cشود که با دلیل\u200cهای متعدد هوپ از مدل BM25 محبوب بیشتر از آن انجام می\u200cدهد.', 'af': "Kennis grafie (Kg) word heeltemal gebruik om inligting oor entiteite en hul verbindings te stoor en toegang te kry. Gegewe 'n navraag, die taak van entiteit ontvang van' n Kg doel om 'n rangeerde lys van entiteite wat relevante na die navraag te voorsien. Laaste het 'n grootmaak aantal modele vir entiteit ontvang 'n betaling verbetering oor tradisionele metodes vertoon. Hierdie modele is egter ontwikkeld vir Engels Kg. In hierdie werk bou ons op een soos stelsel, genaamd KEWER, om SERAG te voorstel (Semantiese Entity Retrieval van Arabske kennis Graf). Soos KEWER, SERAG gebruik willekeurige wandel om entiteit inbêding te genereer. Name Ons bespreek die uitdagings om dit te gebruik vir nie-Engels tale in algemeen en Arabiese in besonderhede. Ons verskaf 'n Arabiese weergawe van hierdie standaard versameling, en gebruik dit om SERAG te evalueer. Serag is vertoon om betekenlik die populêre BM25-model te uitvoer dankie aan sy multi-hop redening.", 'tr': "Bilim grafikleri (KG) birn채챌e guramlar we bagla첵y힊lar hakynda maglumatlary we 첵erine 첵etirmek 체챌in ullanyl첵ar. Name So흫ra, birn채챌e nusgalar almak 체챌in birn채챌e 체첵tge힊ik nusgalar d채pli 첵체ze 체첵tge힊ik g철rkezil첵채r. 횦철ne bu nusgalar i흫lis챌e KG 체챌in d철redildi. Bu i힊de KEWER di첵ip atlandyran bir sistemada SERAG (Semantik Entity Retrieval from Arabic knowledge Graphs) teklip etmek 체챌in guruldyk. KEWER 첵aly, SERAG birem giri힊ini bejermek 체챌in hassas bir y체r체힊 ulan첵ar. unit description in lists Biz muny i흫lis챌e 첵ok diller 체챌in ulanmaky흫 kyn챌ylyklary umumy we arap챌a g체rr체흫 ed첵채ris. Biz bu standart koleksi첵any흫 arab챌a bir wersi첵any sa첵la첵rys we ony SERAG'y de흫lemek 체챌in ullanyrys. SERAG multi-Hop seb채plini흫 체챌in me첵hur BM25 nusgasyny 철r채n 첵igrendir.", 'sw': 'Takwimu za maarifa (KGs) zinatumiwa kwa kiasi kikubwa kuhifadhi na kupata taarifa kuhusu vifaa na mahusiano yao. Kutokana na swali, kazi ya kupatikana kwa vifaa kutoka KG inakusudia kuweka orodha ya vitu vinavyohusiana na swali hilo. Hivi karibuni, kuongezeka kwa baadhi ya mifano kwa ajili ya kurejeshwa kwa ajili ya entity imeonyesha maendeleo makubwa zaidi ya njia za kitamaduni. Hata hivyo, mifano hii iliundwa kwa ajili ya KGs za Kiingereza. Katika kazi hii, tunajenga kwenye mfumo mmoja kama huo, unaoitwa KEWER, ili kupendekeza SERAG (Kurudishwa kwa Uhuru wa Kiarabu kutoka Graphs za Kiarabu). Kama KEWER, SERAG hutumia matembezi ya kawaida ili kutengeneza vifaa vya habari. DBpedia-Entity v2 inachukuliwa kuwa mkusanyiko wa mtihani wa kawaida wa kurejeshwa kwa ajili ya entity. Tunajadili changamoto za kutumia lugha isiyo ya Kiingereza kwa ujumla na Kiarabu hasa. Tunatoa toleo la Kiarabu la mkusanyiko huu wa kiwango cha kawaida, na tunatumia kutathmini SERAG. SERAG inaonyesha kufanya mtindo maarufu wa BM25 kwa kushukuru sababu zake za watu wengi.', 'am': "የእውቀት ቀለም Given a query, the task of entity retrieval from a KG aims at presenting a ranked list of entities relevant to the query.  በኋለኛው፣ አካባቢ ማስታወቂያ ላይ የሚጨመር ብዛት የባሕላዊ ሥርዓቶች ላይ ትልቅ ማድረግ አሳየ፡፡ እንግዲህ እነዚህ ምሳሌዎች ለእንግሊዝኛ KGs ተዘጋጅተዋል፡፡ በዚህ ስራ፣ KEWER የሚባልን እንደዚህ ያለ ስርዓት ላይ እናደርጋለን፡፡ እንደ KEWER፣ SERAG አካባቢ አካሄዱን ለመፍጠር በተቀናቀለ እየሄደ ነው፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s በቋንቋዎች እና በተለየ በአረብኛ ቋንቋ ለመጠቀም የግንኙነቶችን ጥቃት እናሳውቃለን፡፡ የዚህን ዓረባዊ ስብሰባ አረብኛ ክፍል እናጠቃታለን የSERAG ማስታወቂያ እናደርጋታለን፡፡ SERAG የባሕላዊውን BM25 ሞዴል በብዙ-hop ምክንያት በመስጠት ያሳያል፡፡", 'sq': 'Grafiket e njohurive (KGs) përdoren gjerësisht për të ruajtur dhe hyrë në informacion rreth njësive dhe marrëdhënieve të tyre. Duke dhënë një pyetje, detyra e marrjes së njësisë nga një KG synon të paraqesë një list ë të renditur të njësive të rëndësishme për pyetjen. Së fundmi, një numër në rritje modelesh për marrjen e njësisë kanë treguar një përmirësim të rëndësishëm lidhur me metodat tradicionale. Këto modele, megjithatë, u zhvilluan për KG angleze. In this work, we build on one such system, named KEWER, to propose SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs).  Si KEWER, SERAG përdor shëtitje të rastësishme për të gjeneruar përfshirje të njësisë. DBpedia-Entity v2 konsiderohet koleksioni standard i testit për marrjen e njësisë. Ne diskutojmë sfidat e përdorimit të saj për gjuhët jo-angleze në përgjithësi dhe në arabisht në veçanti. Ne japim një version arab të kësaj koleksioni standard, dhe e përdorim për të vlerësuar SERAG. SERAG tregohet se e kalon ndjeshëm modelin popullor BM25 falë arsyetimit të tij shumëhop ësh.', 'hy': 'Գիտության գրաֆիկները լայնորեն օգտագործվում են կազմակերպությունների և նրանց հարաբերությունների մասին տեղեկատվության պահելու և հասանելիության համար: Հարցը հաշվի առնելով, KG-ից կազմակերպության վերադարձման խնդիրը նպատակում է ներկայացնել հարցի հետ կապված կազմակերպությունների դասակարգված ցուցակ: Վերջերս, էության վերականգնման մոդելների աճը ցույց է տալիս ավանդական մեթոդների նկատմամբ նշանակալի զարգացում: Այնուամենայնիվ, այս մոդելները ստեղծվել են անգլերեն KG-ների համար: Այս աշխատանքի ընթացքում մենք կառուցում ենք մեկ այդպիսի համակարգի վրա, որը կոչվում է ՔԵՎԷր, որպեսզի առաջարկենք SERAG-ը: Օրինակ, SERAG-ը օգտագործում է պատահական քայլեր էության ներգրավման համար: DBpeda- ENTITY v2 համարվում է էության վերադարձման համար ստանդարտ փորձարկումների հավաքածուն: Մենք քննարկում ենք այն օգտագործելու մարտահրավերները ոչ անգլերեն լեզուների համար ընդհանուր առմամբ և հատկապես արաբերեն: Մենք ապահովում ենք այս ստանդարտ հավաքածուի արաբերական տարբերակը և օգտագործում ենք այն SERAG-ի գնահատման համար: SERAG-ը ցույց է տալիս, որ նշանակալիորեն գերազանցում է BM25-ի հայտնի մոդելը, շնորհիվ իր բազմահուսական մտածողություններին:', 'az': "Bilim grafikləri (KG) bütün məxluqat və ilişkileri haqqında bilgi almaq və əlaqələri haqqında istifadə edilir. Qəta görə, KG tərəfindən alınmış entitlərin işi soruşmağa qoşulan dərəcəli entitlərin listesini göstərmək istəyir. Sonradan, hər şeyi almaq üçün modellərin çox yüksək sayısı nəticə metodların üstündə möhkəm bir improvement göstərdi. Ancaq bu modellər İngilis KGs üçün hazırlanmışdır. Bu işdə, KEWER adlı bir sistem üzerində SERAG təklif etmək üçün inşa edirik. KEWER kimi, SERAG istifadə edir bir şey inşallarını yaratmaq üçün rastgele yürüyüş. DBpedia-Entity v2 ünvanı almaq üçün standart sınama koleksiyonu hesab edilir. Biz onu ingiliz dili olmayan və ərəb dillərinə istifadə etmək üçün çətinliklərə mübahisə edirik. Biz bu standart koleksiyonun ərəbcə bir versiyasını təmin edirik və SERAG'i değerləşdirmək üçün istifadə edirik. SERAG çoxlu-Hop razılığına görə məşhur BM25 modelini çox yüksək göstərir.", 'bs': 'Grafi znanja (KGs) se široko koriste za čuvanje i pristup informacijama o entitetima i njihovim odnosima. Uz obzir na pitanje, zadatak prikupljanja entiteta iz KG-a je cilj predstavljati redovnu listu entitata relevantnih na pitanje. U poslednje vrijeme, povećan broj modela za prikupljanje entiteta pokazao je značajno poboljšanje u odnosu na tradicionalne metode. Međutim, te modele su razvijene za engleske KGs. U ovom poslu, izgradimo na jednom takvom sustavu po imenu KEWER, kako bi predložili SERAG (Semantički povlačenje podataka iz grafa znanja arapskih podataka). Kao KEWER, SERAG koristi nasumične šetnje kako bi stvorila integraciju entiteta. DBpedia-Entity v2 se smatra standardnom kolekcijom testova za uzbunu entiteta. Razgovaramo o izazovima korištenja njega za ne-engleske jezike općenito i posebno na arapskom. Mi pružamo arabsku verziju ove standardne kolekcije i koristimo ga za procjenu SERAG-a. SERAG pokazuje da značajno iznosi popularni model BM25 zahvaljujući njegovom multihopskom razumijevanju.', 'ca': "Els gràfics del coneixement s'utilitzen ampliament per emmagatzemar i accedir a informació sobre les entitats i les seves relacions. Dada una pregunta, la tasca de recuperació d'una entitat d'un KG mira a presentar una llista classificada d'entitats pertinents a la pregunta. Lately, an increasing number of models for entity retrieval have shown a significant improvement over traditional methods.  No obstant això, aquests models van ser desenvolupats per a KG anglès. En aquesta feina, construïm un sistema d'aquest tipus, anomenat KEWER, per proposar SERAG. Com KEWER, SERAG utilitza passes aleatòries per generar integracions d'entitats. DBpedia-Entity v2 es considera la col·lecció de proves estándar per a la recuperació d'entitats. Discutem els reptes d'utilitzarla llengües no angleses en general i àrab en particular. Oferem una versió àrab d'aquesta col·lecció estàndard i l'utilitzem per avaluar SERAG. Es demostra que SERAG supera significativament el model BM25 popular gràcies al seu raonament multi hop.", 'bn': 'জ্ঞানের গ্রাফ (কে. জি.) বস্তু এবং তাদের সম্পর্কের তথ্য সংরক্ষণ ও প্রবেশ করার জন্য ব্যাপক ব্যবহার করা হয়েছে। একটি অনুসন্ধান দিয়ে কে- জি- এর বস্তু পুনরুদ্ধারের কাজের লক্ষ্য হচ্ছে অনুসন্ধানের সাথে যোগ্য বস্তুর তালিকা উপস্থাপন করা। সম্প্রতি পৃথিবীর উদ্ধারের জন্য বাড়তে থাকার বেশ কিছু মডেল প্রদর্শন করেছে ঐতিহ্যবাহী পদ্ধতির উপর। তবে এই মডেলগুলো ইংরেজি কেজির জন্য উন্নয়ন করা হয়েছে। এই কাজে আমরা এমন একটি সিস্টেমের উপর নির্মাণ করি, যার নাম কেওয়ার, সেরাগ (আরবী জ্ঞানী গ্রাফ্স থেকে সেম্যান্টিক এন্টিটি পুনরুদ্ধার কেউয়ারের মত, সেরাগ ব্যবহার করে বৈশিষ্ট্যের প্রবেশাধিকার তৈরি করার জন্য হাঁটতে ব্যবহার করে। DBpedia-Entity v2 বস্তুর পুনরুদ্ধারের জন্য ন্যান্ডার পরীক্ষা সংগ্রহ বিবেচনা করা হয়। আমরা সাধারণ ভাষায় বিশেষ করে আরবী ভাষায় এটি ব্যবহার করার চ্যালেঞ্জ নিয়ে আলোচনা করি। আমরা এই স্ট্যান্ডার্ড সংগ্রহের আরবী সংস্করণ দিয়েছি এবং সেরাগের মূল্যায়নের জন্য এটা ব্যবহার করি। বিএম২৫ জনপ্রিয় মডেল প্রদর্শন করা হয়েছে তাদের বহুহাপের কারণে ধন্যবাদ।', 'cs': 'Znalostní grafy (KG) jsou široce používány pro ukládání a přístup k informacím o entitách a jejich vztazích. Úkolem vyhledávání entity z KG je při dotazu prezentovat seznam subjektů relevantních pro dotaz. V poslední době rostoucí počet modelů pro vyhledávání entit prokázal výrazné zlepšení oproti tradičním metodám. Tyto modely byly však vyvinuty pro anglické KG. V této práci vycházíme z jednoho takového systému KEWER, který navrhuje SERAG (Sémantic Entity Retrieval z arabských znalostních grafů). Stejně jako KEWER, SERAG používá náhodné procházky k generování vložení entity. DBpedia-Entity v2 je považována za standardní kolekci testů pro vyhledávání entity. Diskutujeme výzvy spojené s jeho používáním pro neanglické jazyky obecně a arabštinu zejména. Poskytujeme arabskou verzi této standardní kolekce a používáme ji k vyhodnocení SERAG. Prokázalo se, že SERAG výrazně překonává populární model BM25 díky multi-hop uvažování.', 'fi': 'Tietokaavioita (KG) käytetään laajalti tallentamaan ja käyttämään tietoja yhteisöistä ja niiden suhteista. Kyselyn perusteella KG:n entiteettihaun tehtävänä on esittää kyselyn kannalta merkityksellisten entiteettien listaus. Viime aikoina yhä useammat yhteisöhakumallit ovat osoittaneet merkittävää parannusta perinteisiin menetelmiin verrattuna. Nämä mallit kuitenkin kehitettiin englantilaisille KG:ille. Tässä työssä rakennamme yhden tällaisen järjestelmän, nimeltään KEWER, ehdottaaksemme SERAG (Semanttinen Entity Retrieval from Arabic Knowledge Graphs). KEWERin tavoin SERAG käyttää satunnaisia kävelylenkkejä luodakseen entiteettiupotuksia. DBpedia-Entity v2:ta pidetään vakiotestikokoelmana entiteetin noutoa varten. Keskustelemme haasteista, joita sen käyttö ei-englantilaisille kielille yleensä ja arabialle erityisesti. Tarjoamme tästä standardikokoelmasta arabiankielisen version ja käytämme sitä SERAG:n arviointiin. SERAG:n on osoitettu suoriutuvan merkittävästi suositusta BM25-mallista multi-hop-päättelynsä ansiosta.', 'et': 'Teadmisgraafikuid (KG) kasutatakse laialdaselt teabe salvestamiseks ja juurdepääsuks üksuste ja nende suhete kohta. Päringu korral on KG-st olemi hankimise ülesande eesmärk esitada päringu jaoks oluliste olemite järjestatud nimekiri. Viimasel ajal on üha suurem hulk olemite taastamise mudeleid näidanud olulist paranemist traditsiooniliste meetoditega võrreldes. Need mudelid töötati siiski välja Inglise KG jaoks. Selles töös toetume ühele sellisele süsteemile nimega KEWER, et pakkuda välja SERAG (Semantiline Entity Retrieval from Araabia teadmiste Graphs). Nagu KEWER, kasutab SERAG suvalisi jalutuskäike olemi manustamise genereerimiseks. DBpedia-Entity v2 loetakse olemi taastamise standardseks testikoguks. Arutame väljakutseid, mis tulenevad selle kasutamisest mitte-inglise keeltes üldiselt ja eriti araabia keeles. Pakume selle standardkollektsiooni araabia versiooni ja kasutame seda SERAG hindamiseks. SERAG on näidanud, et populaarse BM25 mudeli tulemuslikkus on märkimisväärselt suurem tänu oma multi-hop põhjendustele.', 'jv': 'graphs (KGs) kang dipunanggunaké kanggo ngejaraké karo akeh informasi babagan Entèni lan barang ngregani kuwi. politenessoffpolite"), and when there is a change ("assertivepoliteness text-tool-action Kampéné model iki, dadi nggawe kanggo KGs Inggris. Nang barêng-barêng iki, kéné nggawe ning sistem sing dibenakno ning kevehar, jeneng KEKEKER, nggunakake SERG (semanti Entit retription from larab Graph). KEKER Name Awak dhéwé pisan karo perbudhakan kanggo nggunakake kuwi nggawe barang Inggris lan karo Perancis. Awak dhéwé ngewehke versi arap sing kok akeh nggambar iki, lan nggunakake kuwi nggawe SERIG. SERG menehi sawetara tanggal sing dikarepak, populer, model EM5 seneng pisan neng multi-top maneh.', 'sk': 'Grafi znanja (KG) se pogosto uporabljajo za shranjevanje in dostop do informacij o subjektih in njihovih odnosih. Glede na poizvedbo je naloga pridobivanja entitet iz KG namenjena predstavitvi razvrščenega seznama entitet, pomembnih za poizvedbo. V zadnjem času je vedno večje število modelov za pridobivanje entitet pokazalo znatno izboljšanje v primerjavi s tradicionalnimi metodami. Ti modeli pa so bili razviti za angleške KG. V tem delu gradimo na enem takšnem sistemu, imenovanem KEWER, da predlagamo SERAG (Semantično pridobivanje entitet iz arabskih grafov znanja). Kot KEWER, SERAG uporablja naključne sprehode za ustvarjanje vgradnje entitet. DBpedia-Entity v2 velja za standardno zbirko preskusov za pridobivanje entitet. Razpravljamo o izzivih njene uporabe za ne-angleške jezike na splošno in zlasti arabščino. Zagotavljamo arabsko različico te standardne zbirke in jo uporabljamo za oceno SERAG. SERAG je zahvaljujoč svojemu multi-hop razmišljanju pokazal, da znatno presega priljubljen model BM25.', 'ha': "Fomat na San'a (KGs) ana amfani da ɗabi'a wa adana ko don a sami da masana masu tsarin abubuwa da danganyensu. Gida wani tambayi, aikin da aka motsa masu abun daga KG yana aimar ya bãyar da wani jerin da aka saje da maɓallin da inganci da inganci zuwa tambayin. Ga ƙarshe, an a ƙara yawan motel na motsi wa motsi wa masu tsari da abun sun nuna wani mai girma wa hanyoyin kawaici. @ info: whatsthis Daga wannan aikin, Munã samar da wani na'ura wanda aka suna KEWER, dõmin Mu buɗa SNAG (Semantic Entity Reset from Grafs na Larabci). Kamar KEWER, NASA na yi amfani da shirin tafiyar da za'a iya iya buƙata zuwa an ƙiƙiro abun da ke cikin. QXml Munã jayayya masu kansala da za'a yi amfani da shi zuwa harshen Ingiriya na zaman harshe da Larabci. Munã bãyar da version na Larabci na haɗi wannan littafan na'ura, kuma Muke amfani da shi dõmin ka ƙaddara SAR. Ana nuna SNAG mai girma ga tafiyar da misalin BM25 mai umarin sa baka multi-jumfen.", 'bo': 'དབྱིན་ཡིག་འབྲི་རིས(KGs)ཡིས་ལག་ལེན་འཐབ་པ་ལས་དབང་དང་འབྲེལ་བ་ཐད་ཀར་ཉར་འཇོག་དང་འདྲི་ཞིབ Given a query, the task of entity retrieval from a KG aims at presenting a ranked list of entities relevant to the query. མཇུག་མ་དུ་དང་དབུགས་བསྐྱར་འཇུག་ཆས་པའི་མིག་དཔེ་གཏོང་གི་ཚད་ལྟར་སྔོན་སྲོལ་རྒྱུན་གྱི་ཐབས་ལམ་ལ་གསལ་པོ་ཞིག་ ཡིན་ནའང་། མ་དབྱིན་ཡིག་གི་རྣམ་པ་འདི་ཚོས་དབྱིན་ཡིག་ཆགས་པ་རེད། In this work, we build on one such system, named KEWER, to propose SERAG (Semantic Entity Retrieval from Arabic knowledge Graphs) to propose. Like KEWER, SERAG uses random walks to generate entity embeddings. DBpedia-Entity v2 ནི་དབྱིབས་ཞིབ་ལྟ་ཀློག་འཇུག་བྱེད་པའི་ཚད་འཛིན་སྒྲིག་ཆ་མཉམ་ཞིབ་ཡིན་པ ང་ཚོས་དབྱིན་ཡིག་མིན་པའི་སྐད་རིགས་ལ་ཁྱད་པར་སྤྱད་པར་གདོང་ལེན་བྱེད་པའི་དཀའ We provide an Arabic version of this standard collection, and use it to evaluate SERAG. SERAG འདི་ལྟ་བུའི་རྣམ་གྲངས་ཀྱི་མི་མང་ཆེ་བ་ཡིན་པའི་BM25་དབྱིབས་ཕན་ཐོགས་བཀོད་བྱས་ཏེ།', 'he': 'Knowledge graphs (KGs) are widely used to store and access information about entities and their relationships.  בהתחשב בשאלה, המשימה של השיג של יחידה מ KG מטרה להציג רשימה מודרגת של יחידות רלוונטיות לשאלה. לאחרונה, מספר גדול של דוגמנים לשחזור היחידות הראה שיפור משמעותי על שיטות מסורתיות. These models, however, were developed for English KGs.  בעבודה הזו, אנו בונים על מערכת אחת כזאת, בשם KEWER, כדי להציע SERAG. Like KEWER, SERAG uses random walks to generate entity embeddings.  DBpedia-Entity v2 נחשב לאספת הבדיקות הסטנדרטית לשחזור היחידות. אנחנו מדברים על האתגרים של השימוש בו לשפות לא אנגליות בצורה כללית ובצורה ערבית במיוחד. אנחנו מספקים גרסה ערבית של האוסף הסטנדרטי הזה, ושתמשו בו כדי להעריך את SERAG. מוצג שSERAG מעליף באופן משמעותי את המודל המפופולרי BM25 הודות להסבירת המולט-הופ שלו.'}
{'en': 'Introducing A large Tunisian Arabizi Dialectal Dataset for Sentiment Analysis', 'ar': 'تقديم مجموعة بيانات كبيرة تونسية لهجات العرابيزي لتحليل المشاعر', 'es': 'Presentamos un gran conjunto de datos dialectales de Arabizi tunecino para el análisis de sentimientos', 'fr': "Présentation d'un vaste jeu de données dialectal arabizi tunisien pour l'analyse des sentiments", 'pt': 'Apresentando um grande conjunto de dados dialetais tunisianos arabizi para análise de sentimentos', 'ja': 'センチメント分析のための大規模なチュニジアアラビジ方言データセットの紹介', 'zh': '介以情析大体突尼斯阿拉比兹方言数集', 'hi': 'भावना विश्लेषण के लिए एक बड़े ट्यूनीशियाई Arabizi Dialectal डेटासेट का परिचय', 'ru': 'Знакомство с большим набором диалектных данных Тунисского арабского языка для анализа сентиментов', 'ga': 'Tacar Sonraí Dialectal Araibis Túinéise mór a thabhairt isteach le haghaidh Anailíse Mothúcháin', 'ka': 'Name', 'el': 'Εισαγωγή ενός μεγάλου συνόλου διαλεκτικών δεδομένων της Τυνησίας για ανάλυση συναισθημάτων', 'hu': 'Bemutatjuk a nagy tunéziai Arabizi Dialektális Adatkészletet az érzelmek elemzéséhez', 'it': "Presentazione di un grande set di dati dialettali tunisini Arabizi per l'analisi dei sentimenti", 'lt': 'Įvedamas didelis Tuniso Arabizo dialektinių duomenų rinkinys jautrumo analizei atlikti', 'ms': 'Name', 'ml': 'ഒരു വലിയ തുണിസിയന്\u200d അറബിയ ഡൈലക്ടല്\u200d ഡേറ്റാസെറ്റ് പരിചയപ്പെടുത്തുന്നു', 'mt': 'L-introduzzjoni ta’ Sett ta’ Dejta Dijalettwali Tuneżin Għarabiżi kbir għall-Analiżi tas-Sentimenti', 'no': 'Name', 'mk': 'Внесување голем туниски дијалектален датотек за анализа на чувствата', 'pl': 'Przedstawiamy duży tunezyjski zestaw dialektów danych Arabizi do analizy sentymentów', 'ro': 'Introducerea unui set mare de date dialecte tunisiane Arabizi pentru analiza sentimentelor', 'si': 'Name', 'kk': 'Сентиментті анализ үлкен Тунис Арабия диалектикалық деректер бағдарламасы', 'mn': 'Том Тунис Арабын Диалактикийн мэдээллийг мэдээллийн хувьд', 'so': 'Introducing A large Tunisian Arabizi Dialectal Dataset for Sentiment Analysis', 'sv': 'Introducerar ett stort tunisiskt Arabizi Dialektal Dataset för Sentiment Analysis', 'ta': 'Name', 'ur': 'ایک بڑے ٹونیسی عربی ڈیلٹیٹ ڈیٹیسٹ کو آزمائش کرتا ہے', 'sr': 'Predstavljajući veliki Tunisijski arapski dijalektni podatak za analizu sentimenta', 'uz': 'Name', 'vi': 'Giới thiệu Một bộ nhớ phân tích cảm xúc lớn của Tunisia', 'bg': 'Представяне на голям тунизийски диалектичен набор от данни за анализ на чувствата', 'hr': 'Predstavljajući veliki Tunisijski arapski dijalektni podaci za analizu sentimenta', 'da': 'Introduktion af et stort tunesisk Arabizi dialektisk datasæt til følelsesanalyse', 'nl': 'Introductie van een grote Tunesische dialectale dataset voor sentimentanalyse', 'id': 'Memperkenalkan Satu Dataset Dialeksi Tunisia yang besar untuk Analisi Sentiment', 'de': 'Einführung eines großen dialektalen Datensatzes in Tunesien für die Stimmungsanalyse', 'fa': 'با تولید یک داده\u200cهای دایلاکتیک تانیس بزرگ عربی برای تحلیل سنتی', 'sw': 'Inaonyesha kituo kikubwa cha Takwimu za Kiarabu cha Tunisia kwa ajili ya uchambuzi wa Wakati', 'tr': 'Sentiment Taýramçylygy üçin Ullakan Tünsiýa Arabça', 'af': 'Name', 'sq': 'Duke paraqitur një bazë të madhe të dhënash dialektike Tunizi për analizën e ndjenjave', 'am': 'አረቢኛ ዳሌካል ዳታ ማጠቃለያ ለስሜት አዳራቢ', 'hy': 'Introducing A large Tunisian Arabizi Dialectal Dataset for Sentiment Analysis', 'bn': 'সেন্টাইমেন্ট বিশ্লেষণের জন্য একটি বিশাল তিউনিশিয়ার আরবী ডায়ালেক্টল ডাটাল সেট চিহ্নিত করা হচ্ছে', 'az': 'Sentiment Analizi üçün Büyük Tunizi Arabsi Dialektik Veriləri', 'bs': 'Predstavljajući veliki Tunisijski arapski dijalektni podaci za analizu sentimenta', 'ca': "Introducir un gran conjunt de dades dialectals tunisienses per a l'anàlisi del sentiment", 'cs': 'Představujeme velkou tuniskou dialektální sadu dat Arabizi pro analýzu sentimentů', 'ko': '정서 분석에 쓰이는 대형 튀니지 아랍어 사투리 데이터 집합을 소개하다', 'fi': 'Esittelyssä suuri tunisialainen Arabizi Dialektinen datajoukko tunteiden analysointia varten', 'et': 'Tutvustame suurt Tuneesia Arabizi dialektuaalset andmekogumit tunnete analüüsiks', 'ha': 'IntIntucing A Large Tunisian Dialeral Dataset for Sautin Analyze', 'jv': 'gagal', 'he': 'Introducing A large Tunisian Arabizi Dialectal Dataset for Sentiment Analysis', 'sk': 'Predstavljamo velik tunizijski Arabizi dialektni nabor podatkov za analizo čustva', 'bo': 'སྤྱིར་བཏང་དུས་ཚོད་ལྟ་བུའི་ཊུ་ནེ་ཤི་ཡ་ ཨ་རེ་བི་ལྟ་བུའི་བཀོད་སྤྱོད་ཆེན་པོ་ཞིག་བྱེད་པ'}
{'en': 'On various Social Media platforms, people, tend to use the informal way to communicate, or write posts and comments : their local dialects. In Africa, more than 1500 dialects and languages exist. Particularly, Tunisians talk and write informally using Latin letters and numbers rather than Arabic ones. In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for Sentiment Analysis. The dataset consists of a total of 100k comments (about movies, politic, sport, etc.) annotated manually by Tunisian native speakers as Positive, negative and Neutral. We evaluate our dataset on sentiment analysis task using the Bidirectional Encoder Representations from Transformers (BERT) as a contextual language model in its multilingual version (mBERT) as an embedding technique then combining mBERT with Convolutional Neural Network (CNN) as classifier. The dataset is publicly available.', 'ar': 'على منصات التواصل الاجتماعي المختلفة ، يميل الأشخاص إلى استخدام الطريقة غير الرسمية للتواصل أو كتابة المنشورات والتعليقات: لهجاتهم المحلية. يوجد في إفريقيا أكثر من 1500 لهجة ولغة. على وجه الخصوص ، يتحدث التونسيون ويكتبون بشكل غير رسمي باستخدام الأحرف والأرقام اللاتينية بدلاً من الأحرف العربية. في هذا البحث ، نقدم مجموعة كبيرة من البيانات الخاصة باللهجة العربية التونسية ذات الزحف المشترك والمخصصة لتحليل المشاعر. تتكون مجموعة البيانات من إجمالي 100 ألف تعليق (حول الأفلام والسياسة والرياضة وما إلى ذلك) تم شرحها يدويًا من قبل الناطقين باللغة التونسية على أنها إيجابية وسلبية وحيادية. نقوم بتقييم مجموعة البيانات الخاصة بنا حول مهمة تحليل المشاعر باستخدام تمثيلات التشفير ثنائية الاتجاه من المحولات (BERT) كنموذج لغوي سياقي في نسخته متعددة اللغات (mBERT) كأسلوب تضمين ثم دمج mBERT مع الشبكة العصبية التلافيفية (CNN) كمصنف. مجموعة البيانات متاحة للجمهور.', 'pt': 'Em várias plataformas de mídia social, as pessoas tendem a usar a maneira informal de se comunicar, ou escrever postagens e comentários: seus dialetos locais. Na África, existem mais de 1500 dialetos e idiomas. Particularmente, os tunisianos falam e escrevem informalmente usando letras e números latinos em vez de árabes. Neste artigo, apresentamos um grande conjunto de dados dialetais tunisianos arabizi baseados em rastreamento comum dedicado à Análise de Sentimentos. O conjunto de dados consiste em um total de 100 mil comentários (sobre filmes, política, esporte, etc.) anotados manualmente por falantes nativos da Tunísia como Positivo, negativo e Neutro. Avaliamos nosso conjunto de dados na tarefa de análise de sentimento usando as Representações de Codificador Bidirecional de Transformadores (BERT) como um modelo de linguagem contextual em sua versão multilíngue (mBERT) como uma técnica de incorporação, combinando mBERT com Rede Neural Convolucional (CNN) como classificador. O conjunto de dados está disponível publicamente.', 'es': 'En varias plataformas de redes sociales, las personas tienden a usar la forma informal de comunicarse o escribir publicaciones y comentarios: sus dialectos locales. En África existen más de 1500 dialectos e idiomas. En particular, los tunecinos hablan y escriben informalmente utilizando letras y números latinos en lugar de los árabes. En este artículo, presentamos un gran conjunto de datos dialectales Arabizi tunecinos basado en rastreo común dedicado al análisis de sentimientos. El conjunto de datos consta de un total de 100 000 comentarios (sobre películas, política, deporte, etc.) anotados manualmente por hablantes nativos tunecinos como positivos, negativos y neutros. Evaluamos nuestro conjunto de datos en la tarea de análisis de sentimientos utilizando Bidirectional Encoder Representations from Transformers (BERT) como modelo de lenguaje contextual en su versión multilingüe (mBERT) como técnica de incrustación y luego combinando mBERT con la Red Neural Convolucional (CNN) como clasificador. El conjunto de datos está disponible públicamente.', 'fr': "Sur diverses plateformes de médias sociaux, les gens ont tendance à utiliser la méthode informelle pour communiquer, ou à écrire des messages et des commentaires\xa0: leurs dialectes locaux. En Afrique, il existe plus de 1 500 dialectes et langues. En particulier, les Tunisiens parlent et écrivent de façon informelle en utilisant des lettres et des chiffres latins plutôt que des chiffres arabes. Dans cet article, nous présentons un vaste jeu de données dialectal arabizi tunisien basé sur l'exploration commune, dédié à l'analyse des sentiments. Le jeu de données comprend un total de 100 000 commentaires (sur les films, la politique, le sport, etc.) annotés manuellement par des locuteurs natifs tunisiens comme étant positifs, négatifs et neutres. Nous évaluons notre ensemble de données sur la tâche d'analyse des sentiments en utilisant les représentations de codeurs bidirectionnels à partir de transformateurs (BERT) comme modèle de langage contextuel dans sa version multilingue (mBERT) comme technique d'intégration, puis en combinant mBERT avec un réseau de neurones convolutionnels (CNN) comme classificateur. L'ensemble de données est accessible au public.", 'ja': 'さまざまなソーシャルメディアプラットフォームでは、人々は非公式なコミュニケーション方法を使用したり、投稿やコメントを書いたりする傾向があります。つまり、地元の方言です。アフリカには1500以上の方言や言語が存在する。特にチュニジア人はアラビア文字ではなくラテン文字や数字を使って非公式に会話したり書いたりしている。本稿では、センチメント分析専用の大規模なコモンクロールベースのチュニジア・アラビジ方言データセットを紹介する。このデータセットは、チュニジアのネイティブスピーカーがポジティブ、ネガティブ、ニュートラルとして手動で注釈を付けた合計10万件のコメント（映画、政治、スポーツなどについて）で構成されています。私たちは、多言語版（ mBERT ）のコンテキスト言語モデルとしての双方向エンコーダ表現（ BERT ）を使用してセンチメント分析タスクのデータセットを評価し、mBERTと畳み込みニューラルネットワーク（ CNN ）を分類子として組み合わせます。データセットは一般公開されています。', 'zh': '诸社交媒体台上,人向用非正法交流,或帖论:其为地方言。 在非洲,1500多方言语。 特是,突尼斯人用拉丁字母数而非阿拉伯语非正言作也。 本文中,我们介了一个专用情析的大体基于公共行的突尼斯阿拉比兹方言数据集。 该数集凡包10万条论(其电影政,体育等),突尼斯母语人士手动注为积极,消极中立。 吾以变形金刚之双向编码器(BERT)为多言版本(mBERT)中之上下文语形为嵌术,然后以mBERT与卷积神经网络(CNN)为分类器合,料情析数集。 数集是明可用也。', 'hi': 'विभिन्न सोशल मीडिया प्लेटफार्मों पर, लोग, संवाद करने के लिए अनौपचारिक तरीके का उपयोग करते हैं, या पोस्ट और टिप्पणियां लिखते हैं: उनकी स्थानीय बोलियां। अफ्रीका में, 1500 से अधिक बोलियां और भाषाएं मौजूद हैं। विशेष रूप से, ट्यूनीशियाई अरबी लोगों के बजाय लैटिन अक्षरों और संख्याओं का उपयोग करके अनौपचारिक रूप से बात करते हैं और लिखते हैं। इस पेपर में, हम भावना विश्लेषण के लिए समर्पित एक बड़े आम-क्रॉल-आधारित ट्यूनीशियाई अरबिज़ी बोलचाल डेटासेट पेश करते हैं। डेटासेट में कुल 100k टिप्पणियां (फिल्मों, राजनीति, खेल, आदि के बारे में) शामिल हैं, जो ट्यूनीशियाई मूल वक्ताओं द्वारा सकारात्मक, नकारात्मक और तटस्थ के रूप में मैन्युअल रूप से एनोटेट की गई हैं। हम अपने बहुभाषी संस्करण (mBERT) में एक प्रासंगिक भाषा मॉडल के रूप में ट्रांसफॉर्मर्स (BERT) से द्विदिश एन्कोडर प्रतिनिधित्व का उपयोग करके भावना विश्लेषण कार्य पर हमारे डेटासेट का मूल्यांकन करते हैं, एक एम्बेडिंग तकनीक के रूप में फिर क्लासिफायर के रूप में Convolutional Neural Network (CNN) के साथ mBERT का संयोजन करते हैं। डेटासेट सार्वजनिक रूप से उपलब्ध है।', 'ru': 'На различных платформах социальных сетей люди, как правило, используют неформальный способ общения или написания постов и комментариев: их местные диалекты. В Африке существует более 1500 диалектов и языков. В частности, тунисцы неофициально говорят и пишут латинскими буквами и цифрами, а не арабскими. В этой статье мы представляем большой диалектный набор данных тунисского арабского языка на основе общего сканирования, посвященный анализу настроений. Набор данных состоит из в общей сложности 100 000 комментариев (о фильмах, политике, спорте и т.д.), аннотированных вручную носителями тунисского языка как положительные, отрицательные и нейтральные. Мы оцениваем наш набор данных по задаче анализа настроений, используя двунаправленные представления кодировщика от трансформаторов (BERT) в качестве контекстной языковой модели в его многоязычной версии (mBERT) в качестве метода встраивания, а затем объединяем mBERT со сверточной нейронной сетью (CNN) в качестве классификатора. Набор данных является общедоступным.', 'ga': 'Ar ardáin éagsúla Meáin Shóisialta, bíonn claonadh ag daoine úsáid a bhaint as an mbealach neamhfhoirmiúil chun postálacha agus tuairimí a chur in iúl, nó a scríobh: a gcanúintí áitiúla. San Afraic, tá níos mó ná 1500 canúint agus teanga ann. Go háirithe, bíonn na Túinéisigh ag caint agus ag scríobh go neamhfhoirmiúil ag úsáid litreacha agus uimhreacha Laidine seachas na cinn Arabacha. Sa pháipéar seo, tugaimid isteach tacar sonraí mór canúinteach Túinéiseach Arabizi bunaithe ar shreangán atá tiomnaithe d’Anailís Mothúchán. Is éard atá sa tacar sonraí ná 100k trácht ar an iomlán (faoi scannáin, polaitíocht, spórt, etc.) arna nótáil de láimh ag cainteoirí dúchais na Túinéise mar Dearfach, diúltach agus Neodrach. Déanaimid measúnú ar ár dtacar sonraí ar thasc anailíse meon agus úsáid á baint as Léirithe Ionchódóra Déthreo ó Chlaochladáin (BERT) mar mhúnla teanga comhthéacsúil ina leagan ilteangach (mBERT) mar theicníc leabú agus ansin comhcheanglaítear mBERT le Convolutional Neural Network (CNN) mar aicmitheoir. Tá an tacar sonraí ar fáil go poiblí.', 'hu': 'A különböző közösségi média platformokon az emberek hajlamosak informális módon kommunikálni, vagy bejegyzéseket és megjegyzéseket írni: a helyi dialektusok. Afrikában több mint 1500 dialektus és nyelv létezik. Különösen a tunéziak nem hivatalosan beszélnek és írnak latin betűkkel és számokkal, hanem arabokkal. Ebben a tanulmányban bemutatunk egy nagy, közös feltérképezésű tunéziai arabizi dialektuális adatkészletet, amely az érzelmek elemzésére szolgál. Az adatkészlet összesen 100 ezer megjegyzésből áll (filmekről, politikáról, sportról stb.), amelyeket a tunéziai anyanyelvűek manuálisan megjegyeztek pozitív, negatív és semleges formában. Adatkészletünket értékeljük az érzelmek elemzésére vonatkozó feladatokra a Transzformátorok kétirányú kódoló reprezentációi (BERT) mint kontextuális nyelvi modell (mBERT) használatával, mint beágyazási technika, majd kombináljuk az mBERT és a Convolutional Neural Network (CNN) mint osztályozó. Az adatkészlet nyilvánosan hozzáférhető.', 'el': 'Σε διάφορες πλατφόρμες κοινωνικών μέσων, οι άνθρωποι τείνουν να χρησιμοποιούν τον άτυπο τρόπο επικοινωνίας, ή να γράφουν δημοσιεύσεις και σχόλια: τις τοπικές διαλέκτες τους. Στην Αφρική υπάρχουν περισσότερες από 1500 διαλέκτες και γλώσσες. Ειδικότερα, οι Τυνήσιοι μιλούν και γράφουν ανεπίσημα χρησιμοποιώντας λατινικά γράμματα και αριθμούς και όχι αραβικά. Σε αυτή την εργασία, εισάγουμε ένα μεγάλο σύνολο διαλεκτικών δεδομένων της Τυνησίας που βασίζεται σε κοινή αναρρίχηση αφιερωμένο στην ανάλυση συναισθημάτων. Το σύνολο δεδομένων αποτελείται από συνολικά 100σχόλια (για ταινίες, πολιτικά, αθλητικά κ.λπ.) που σχολιάζουν χειροκίνητα από φυσικούς ομιλητές της Τυνησίας ως Θετικά, αρνητικά και Ουδέτερα. Αξιολογούμε το σύνολο δεδομένων μας σχετικά με την εργασία ανάλυσης συναισθημάτων χρησιμοποιώντας την αμφίδρομη αναπαράσταση κωδικοποιητή από μετασχηματιστές (BERT) ως ένα πλαίσιο γλωσσικού μοντέλου στην πολύγλωσση έκδοση του (mBERT) ως τεχνική ενσωμάτωσης στη συνέχεια συνδυάζοντας το mBERT με το Convolutional Neural Network (CNN) ως ταξινομητή. Το σύνολο δεδομένων είναι διαθέσιμο στο κοινό.', 'ka': 'განსხვავებული სოციალური მედია პლატატებში, ადამიანები უნდა გამოყენება ინფორმალური გზა, რომელიც კომუნიკაციას, ან დაწერა პოსტი და კომენტრები: მათი ლოკა აფრიკაში 1500-ზე მეტი დიალექტი და ენები არსებობს. განსაკუთრებით, ტუნიზები უბრალოდ ლატინური სიტყვები და რიცხვების გამოყენებით და ინფორმალურად დაწერებით. ამ დოკუნეში ჩვენ შევცვალობთ დიალექტური საზოგადო საზოგადოებო ტუნისური აპაბიზი დიალექტური მონაცემების საზოგადოება, რომელიც საზოგადო მონაცემების საერთო 100k კომენტრების (ფილმების, პოლიტიკური, სპორტის, განსაზღვრებით და განსაზღვრებით) მონაცემულია, როგორც ტუნისური მართლური მუშაობელი მუშაობელი როგორ ჩვენ მონაცემების კონტექსტური ანალიზაციის რაოდენობის შესახებ გავამუშაოთ განცემების კონტექსტური ინფორმაციების გამოყენება (BERT) როგორც კონტექსტური ენის მოდელის მრავალენგური ვერსიაში (mBERT) როგორც ინბიზაციის ტექნე მონაცემების კონფიგურაცია ადგილურად ხელსახულია.', 'kk': 'Әртүрлі социалдық медиа платформаларында адамдар мәліметті байланысу немесе жазбаларды және түсініктемелерін жазып, жергілікті диалекттерді қолданады. Африкада 1500- ден артық диалекттер мен тілдер бар. Әсіресе, Тунис әріптері араб әріптерінің орнына латын әріптері мен сандарды мәліметті түрде сөйлейді. Бұл қағазда, сентименттік анализ үшін қолданылатын Тунис Арабзияның диалекталық деректер жиынын келтіреміз. Деректер жиында 100 км түсініктемелер (фильм, саясаты, спорт және т. б.) туралы Тунис негізгі орындаушыларының қолмен түсініктемелері Позитивті, негативті және Нейтрал ретінде белгіледі. Біз көпшілік тіл моделі (mBERT) көпшілік тілінің көпшілік нұсқасындағы көпшілік анализ тапсырмасындағы деректер жинағымызды көпшілік анализ тапсырмасын қолданып, көпшілік нұсқасындағы көпшілік тіл моделі (көпшілі Деректер жиыны көпшілікті қол жеткізеді.', 'it': "Su varie piattaforme di Social Media, le persone tendono a usare il modo informale per comunicare, o scrivere post e commenti: i loro dialetti locali. In Africa esistono più di 1500 dialetti e lingue. In particolare, i tunisini parlano e scrivono informalmente usando lettere e numeri latini piuttosto che arabi. In questo articolo, presentiamo un ampio set di dati dialettali tunisini Arabizi basato su crawl, dedicato all'analisi dei sentimenti. Il dataset consiste in un totale di 100k commenti (su film, politica, sport, ecc.) annotati manualmente da madrelingua tunisina come Positive, negative e Neutral. Valutiamo il nostro set di dati sull'attività di analisi del sentiment utilizzando il modello bidirezionale Encoder Representations from Transformers (BERT) come modello di linguaggio contestuale nella sua versione multilingue (mBERT) come tecnica di incorporazione, quindi combinando mBERT con Convolutional Neural Network (CNN) come classificatore. Il set di dati è disponibile al pubblico.", 'mk': 'На различни платформи за социјални медиуми, луѓето, имаат тенденција да го користат неформалниот начин за комуникација, или да пишуваат постови и коментари: нивните локални дијалекти. Во Африка постојат повеќе од 1500 дијалекти и јазици. Особено, Тунисите зборуваат и пишуваат неформално користејќи латински букви и броеви наместо арапски. Во овој весник, воведуваме голем туниски дијалектален компјутер на податоци од Арабизи посветен на анализа на чувствата. Податоците се состојат од вкупно 100 илјади коментари (за филмовите, политиката, спортот итн.) кои рачно се анотираат од туниските родни говорници како позитивни, негативни и неутрални. Ги проценуваме нашите податоци за задачата за анализа на чувствата користејќи ги Бидирекционалните претставувања на кодерот од трансформерите (БЕРТ) како контекстен јазички модел во неговата мултијазичка верзија (МБЕРТ) како техника за вградување, а потоа комбинирајќи mBERT со Конволуционалната Неурална мрежа (С The dataset is publicly available.', 'lt': 'Įvairiose socialinės žiniasklaidos platformose žmonės dažnai naudojasi neformaliu būdu bendrauti arba rašyti pareigas ir komentarus: jų vietos dialektus. Afrikoje egzistuoja daugiau kaip 1500 dialektų ir kalbų. Visų pirma tuniečiai kalba ir rašo neoficialiai naudodami Lotynų raides ir numerius, o ne arabų raides. In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for Sentiment Analysis.  Duomenų rinkinį sudaro iš viso 100k komentarų (apie filmus, politiką, sport ą ir t. t.), kuriuos rankiniu būdu pažymėjo Tuniso vietiniai kalbėtojai kaip teigiamus, neigiamus ir neutralius. Vertiname savo duomenų rinkinį apie jautrumo analizės užduotis, naudojant dvikrypčius kodatorių atstovavimus iš transformatorių (BERT) kaip kontekstinį kalbos model į daugiakalbėje versijoje (mBERT), kaip įterpimo metodą, o po to mBERT derinamas su konvoliuciniu nerviniu tinklu (CNN) kaip klasifikatorius. Duomenų rinkinys yra viešas.', 'ms': 'Pada pelbagai platform Media Sosial, orang, cenderung menggunakan cara informal untuk berkomunikasi, atau menulis pos dan komentar: dialekt setempat mereka. Di Afrika, lebih dari 1500 dialekt dan bahasa wujud. Terutama, orang Tunisia bercakap dan menulis secara tidak secara rasmi menggunakan huruf dan nombor Latin daripada yang Arab. Dalam kertas ini, kami memperkenalkan sebuah set data dialektal Tunisia berdasarkan merangkak biasa yang didedikasikan untuk Analisi Sentiment. Set data terdiri dari total 100k komen (mengenai filem, politik, sukan, dll.) yang dicatat secara manual oleh pembicara asli Tunisia sebagai positif, negatif dan Neutral. Kami menilai set data kami pada tugas analisis perasaan menggunakan Perwakilan Pengekod Dua Arah dari Penukar (BERT) sebagai model bahasa kontekstual dalam versi berbilang bahasa (mBERT) sebagai teknik penyembedding kemudian menggabungkan mBERT dengan Rangkaian Neural Konveolutional (CNN) sebagai pengklasifikasi. Set data tersedia secara awam.', 'ml': 'വ്യത്യസ്തോഷ്യല്\u200d മീഡിയ പ്ലാറ്റ്ഫോമുകളില്\u200d, ആളുകള്\u200d സംസാരിക്കാന്\u200d അനുയോജ്യമായ രീതിയില്\u200d ഉപയോഗിക്കുന്നു ആഫ്രിക്കയില്\u200d 1500 കൂടുതല്\u200d ഡയലക്ട്രെക്കും ഭാഷകളും ഉണ്ട്. പ്രത്യേകിച്ച്, ടൂണിഷ്യക്കാര്\u200d സംസാരിക്കുന്നു, അറബിക്ക് പകരം ലാറ്റിന്\u200d കത്തുകളും നമ്പരുകളും ഉപയോഗിക്ക In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for Sentiment Analysis.  ഡാറ്റാസെറ്റ് മൊത്തം 100 ലക്ഷം കാര്യങ്ങളുടെ (സിനിമയെക്കുറിച്ച്, രാഷ്ട്രീയ, കളിയെക്കുറിച്ച്) കൈകാര്യം വിശദീകരിച്ചിരിക്കുന്നു. ന ട്രാന്\u200dസ്ഫോര്\u200dമാരില്\u200d നിന്നുള്ള ബൈഡഡലിക്കല്\u200d ഏകോഡിയര്\u200d പ്രതിനിധികള്\u200d ഉപയോഗിച്ച് നമ്മുടെ ഡാറ്റാസെറ്റിന്\u200dറെ ഡേറ്റാസെറ്റ് നമ്മുടെ ഡേറ്റാസെറ്റ് വിലയിക്കുന്നു. അതിന്\u200dറെ പല ഭാഷ മോഡല്\u200d  ഡാറ്റാസെറ്റ് പ്രസിദ്ധമാണ്.', 'no': 'On various social media platforms, people tend to use the informal way to communicate, or write posts and comments: their local dialects. I Afrika finst fleire enn 1500 dialektar og språk. Eigenskapalt snakkar Tunisiane og skriv informalt med latinske bokstavar og nummer i staden for arabiske. I denne papiret introduserer vi ein stor vanleg-krawlbasert tunisisk arabisk dialektisk dataset som er spesifisert for Sentiment Analysis. Datasettet inneheld eit totalt 100 km-kommentar (om filmar, politikk, sport osv.) oppmerkt manuelt av Tunisianske innstillingar som positiv, negativ og neutral. Vi evaluerer datasettet vårt om sentimentanalyseoppgåva ved hjelp av Bidirectional Encoder Representations frå Transformers (BERT) som ein kontekst språk-modell i sin fleirspråk versjon (mBERT) som ein innebyggingsteknikk, og så kombinerer mBERT med Convolutional Neural Network (CNN) som klassifiserer. Datasettet er tilgjengeleg offentlig.', 'mn': 'Хүмүүс өөр өөр нийгмийн медиа платформуудад тэдний орон нутгийн диалектуудыг харилцах, бичих захирамжуудыг ашигладаг. Африкт 1500-аас илүү диалект болон хэл байдаг. Ялангуяа Тунис хүмүүс араб хүмүүсийн оронд латын үсэг, тоонуудыг ашиглаж, мэдээлэл бичдэг. Энэ цаасан дээр бид Тунис Арабын Диалектикийн мэдээллийн суурилуулалт санааны шинжилгээнд зориулагдсан маш олон нийтлэг гүйлтэй байдаг. Тунисийн орон нутгийн илтгэгчид зөвхөн эерэг, сөрөг, сэтгэл хөдлөл гэдэг 100 кг илтгэл тайлбар байдаг. Бид мэдрэмжлийн шинжилгээний ажлын тухай өгөгдлийн санаануудыг Трансформатчийн (BERT) хоёр шугам хэл загвар болгон (mBERT) хэлбэрийн хувилбарын (мBERT) хувилбарын тухай холбоотой техник болгон мBERT-г Convolutional Neural Network (CNN) хувилбар болгон холбоотой. Өгөгдлийн санг олон нийтэд хэрэглэгддэг.', 'pl': 'Na różnych platformach mediów społecznościowych ludzie wykorzystują nieformalny sposób komunikacji lub piszą posty i komentarze: swoje lokalne dialekty. W Afryce istnieją ponad 1500-dialekty i języki. Szczególnie Tunezyjczycy mówią i piszą nieformalnie używając łacińskich liter i cyfr, a nie arabskich. W niniejszym artykule przedstawiamy duży, oparty na wspólnym crawlowaniu tunezyjski zestaw dialektów Arabizi dedykowany do analizy sentymentów. Zestaw danych składa się z łącznie 100k komentarzy (dotyczących filmów, polityki, sportu itp.), które ręcznie podawane są przez native speakerów Tunezji jako Pozytywne, Negatywne i Neutralne. Nasz zestaw danych dotyczący analizy sentymentów oceniamy za pomocą dwukierunkowych reprezentacji kodera z transformatorów (BERT) jako kontekstowego modelu językowego w jego wielojęzycznej wersji (mBERT) jako techniki osadzania, a następnie łączymy mBERT z Convolutional Neuroral Network (CNN) jako klasyfikator. Zestaw danych jest publicznie dostępny.', 'mt': 'Fuq diversi pjattaformi tal-Midja Soċjali, in-nies għandhom it-tendenza li jużaw il-mod informali kif jikkomunikaw, jew jiktbu postijiet u kummenti: id-dijaletti lokali tagħhom. Fl-Afrika, jeżistu aktar minn 1500 dijaletti u lingwa. B’mod partikolari, it-Tuneżini jitkellmu u jiktbu b’mod informali bl-użu ta’ ittri u numri Latini minflok dawk Għarab. F’dan id-dokument, a ħna nintroduċu sett kbir ta’ dejta dijalettika Tuneżina Arabizi bbażat fuq crawl komuni ddedikat għall-Analiżi tas-Sentiment. Is-sett tad-dejta jikkonsisti f’total ta’ 100k kumment (dwar il-films, il-politika, l-isport, eċċ.) annotat manwalment minn kelliema nattivi Tuneżini bħala Pożittivi, negattivi u Newtrali. Aħna jevalwaw is-sett tad-dejta tagħna dwar il-kompitu ta’ analiżi tas-sentimenti bl-użu tar-Rappreżentazzjonijiet tal-Kodifikatur Bidirezzjonali mit-Trasformaturi (BERT) bħala mudell lingwistiku kuntestwali fil-verżjoni multilingwistika tiegħu (mBERT) bħala teknika ta’ inkorporazzjoni imbagħad jikkombina mBERT man-Netwerk Newrali Konveoluzzjonali (CNN) bħala klassifikatur. The dataset is publicly available.', 'so': 'Qorshooyinka macluumaadka bulshada ee dadku waxay isticmaalaan qaab aan rasmi ah oo la xiriira ama ay qoraan boostada iyo commentarada: warqadahooda degmada ah. Afrikada waxaa jira in ka badan 1500 luuqadood iyo luuqado. Si gaar ah, Tunisiyadu waxay si rasmi ah ugu hadlaan warqadaha Luqada iyo nambarka afka Carabiga. In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for Sentiment Analysis.  Taariikhda waxaa ka mid ah tusaale qof oo ka mid ah fiidiyo, siyaasadeed, jimicsi, etc.) oo ay si rasmi ah ugu naadiyeen dadka magaalada Tunisiya oo ku hadla afkooda hooyo ah sida boos, negative iyo nøytral. Waxaynu qiimeynaynaa macluumaadkayagii ku saabsan shahaadada malaysiga ah, isticmaalka Bidirectional Encoder Representations from Transformers (BERT) oo ah model joogtada ah oo ku qoran afkiisa luuqadaha kala duduwan (mBERT) as an embedding technique then combining mBERT with Convolutional Neural Network (CNN) as classifier. Rugta macluumaadku wuxuu si bayaan ah u helaa.', 'sv': 'På olika sociala medier tenderar människor att använda det informella sättet att kommunicera, eller skriva inlägg och kommentarer: deras lokala dialekter. I Afrika finns mer än 1500 dialekter och språk. Tunisar talar och skriver informellt med latinska bokstäver och siffror snarare än arabiska. I denna uppsats introducerar vi ett stort gemensamt krypbaserat tunisiskt arabizi dialektiskt dataset dedikerat för Sentiment Analysis. Datauppsättningen består av totalt 100 000 kommentarer (om filmer, politik, sport osv.) som manuellt kommenteras av tunisiska infödda talare som Positiv, negativ och Neutral. Vi utvärderar vårt dataset på sentimental analysuppgift med hjälp av Bidirectional Encoder Representations from Transformers (BERT) som en kontextuell språkmodell i dess flerspråkiga version (mBERT) som en inbäddningsteknik och sedan kombinera mBERT med Convolutional Neural Network (CNN) som klassificerare. Datauppsättningen är allmänt tillgänglig.', 'ro': 'Pe diferite platforme de Social Media, oamenii, tind să folosească modul informal de a comunica, sau să scrie postări și comentarii: dialectele lor locale. În Africa există peste 1500 de dialecte și limbi. În special, tunisienii vorbesc și scriu informal folosind litere și numere latine mai degrabă decât cele arabe. În această lucrare, introducem un set larg de date dialectale tunisiane arabizi bazat pe crawl, dedicat analizei sentimentelor. Setul de date constă din un total de 100.000 de comentarii (despre filme, politică, sport etc.) adnotate manual de vorbitori nativi tunisieni ca pozitive, negative și neutre. Evaluăm setul nostru de date cu privire la sarcina de analiză a sentimentelor utilizând reprezentanțele codificatoare bidirecționale de la transformatori (BERT) ca model de limbaj contextual în versiunea sa multilingvă (mBERT) ca tehnică de încorporare, apoi combinând mBERT cu Rețeaua Neurală Convoluțională (CNN) ca clasificator. Setul de date este disponibil publicului.', 'ta': 'பல்வேறு சமூக ஊடக திட்டங்களில், மக்கள் தொடர்பு கொள்ள, அல்லது நிறுவனங்கள் மற்றும் குறிப்புகளை எழுத வேண்டும் தகவல் வழியை பயன்படுத்த ஆப்பிரிக்காவில், 1500 க்கும் மேற்பட்ட மொழிகள் உள்ளன. குறிப்பாக, துனீசியன்கள் பேசுகிறார்கள் மற்றும் எழுதுகிறார்கள் இந்த காக்கியத்தில், நாம் ஒரு பெரிய பொது கிரால் அடிப்படையில் துன்சிய அரபி விளக்கம் தகவல் அமைப்பை குறிப்பிடுகிறோம். இந்த தகவல் அமைப்பு மொத்த 100k குறிப்புகளில் உள்ளது (சிதிரைப்படங்கள், அரசியல், விளையாட்டும் பற்றி) கைமுறையாக குறிப்பிடப்பட்டுள்ளது, நேர்மறை மற் மாற்றுபவர்களிலிருந்து பைதிசையான குறியீட்டாளர் மாதிரி மொழி மாதிரியாக மாற்றியமைக்கப்பட்டுள்ள பைதிசையின் அறிவிப்பு அமைப்பை முழுமையான தொழில்நுட்பமாக மாற்றியமைக்கும் பின்னர்  தகவல் அமைப்பு பொதுவாக கிடைக்கும்.', 'ur': 'مختلف سوسیل میڈیا پٹرومٹ پر، لوگوں کو ان کی محلی دیالکت کا استعمال کرنا چاہتا ہے کہ ان کو اپنا ارتباط کریں، یا پوسٹ اور توضیح لکھیں۔ آفریقا میں 1500 سے زیادہ دیالکت اور زبانیں موجود ہیں۔ مخصوصاً ٹونیسی لوگ عربی کے بغیر لاتین حرف اور نمبر کے استعمال سے بات کرتے ہیں اور غیر معمولی طور پر لکھتے ہیں۔ اس کاغذ میں، ہم ایک بڑے معمولی تونیسی آرابی دیالکتال ڈیزاسٹ کو معرفی کرتے ہیں جو سنتیمنٹ تحلیل کے لئے مقرر کیا گیا ہے۔ ڈاٹ سٹ میں 100ک کمٹر (فیلم, سیاسی، اسپارٹ، غیر اولاد کے بارے میں) ہے جو تونیسی کی ملک صحبت کرنے والوں کے ذریعہ مثبت، منفی اور نائٹرال کے ذریعہ مطلع کیا گیا ہے. ہم اپنے ڈیٹ سٹ کو حسن تحلیل کے تابع کے بارے میں تقویت دیتے ہیں کہ ٹرانسفور (BERT) سے دودئیرسینٹیونل انکوڈر نمونٹ کے مطابق ایک کنٹکسٹیول زبان نمونٹ کی حالت میں (mBERT) ایک ایمبڈینگ ٹیکنیک کے طور پر مBERT کو کرتا ہے پھر مBERT کو Convolutional Neural Network (CNN) کے ساتھ کلاسپیر کے طور پر ڈاٹ سٹ عمومی طور پر موجود ہے.', 'si': 'විවිධ සාමාජික මිඩියාව ප්\u200dරවේශනයෙන්, මිනිස්සුන්, සම්බන්ධ විදිහට සම්බන්ධ විදිහට ප්\u200dරවේශනය කරන්න, නැත් අෆ්රිකාවේ 1500 වඩා වඩා දායිලක්ට් සහ භාෂාවට වඩා ඉන්නවා. විශේෂයෙන්, ටුනිසියාන් කතා කරනවා ලැටින් අක්ෂර සහ අංකය භාවිතා කරනවා අරාබියාන් වලට වඩා අත මේ පැත්තේ, අපි ලොකු සාමාන්\u200dය-ක්\u200dරාල් ස්ථානයින් ටුනිසියාන් අරාබිසි ඩායිලෙක්ටල් දත්ත සූදානය සඳහා සංව දත්ත සෙට් එක්ක 100k කියන සම්පූර්ණයක් තියෙනවා (චිත්\u200dරපටිය, රජාත්\u200dරික, ස්පෝර්ට් වලින්) ටුනිසියාන් ස්ථානික සිපිකරුවන් අත අපි අපේ දත්ත සූද්ධ විශ්ලේෂණ විශ්ලේෂණ වැඩසටහන් විශ්වාස කරනවා බිද්\u200dරිකේෂණික කෝඩාර් ප්\u200dරතිනිස්ථාපනය (BERT) වෙනුවෙන් සම්බන්ධ භාෂා මොඩේලයක් විදිය දත්ත සෙට් සාමාන්\u200dයයෙන් ප්\u200dරවේශයෙන්.', 'sr': 'Na raznim platformama društvenih medija ljudi koriste neformalni naèin da komuniciraju ili napišu pozicije i komentare: njihove lokalne dijalekte. U Africi postoje više od 1500 dijalekata i jezika. Posebno, Tunizi govore i napišu informalno korištenjem latinskih pisma i brojeva umjesto arapskih. U ovom papiru predstavljamo veliku zajedničku raspoloženost Tunisijske Arabijske dijalektne podatke posvećene za analizu sentimenta. Podaci se sastavljaju od ukupnih 100k komentara (o filmovima, politici, sportu, itd.) koje su manuelno izjavili Tunisijski govornici kao pozitivni, negativni i neutralni. Procjenjujemo naš komplet podataka o zadatku analize sentiment a koristeći predstavljanje dvosmjernog kodera od transformatora (BERT) kao kontekstualni jezički model u svojoj multijezičkoj verziji (mBERT) kao ugrađenu tehniku, a zatim kombinujemo mBERT sa konvolucionalnom neuronskom mrežom (CNN) kao klasifikator. Podaci su javno dostupni.', 'uz': "Ko'pchilik jamiyat media platformlarida odamlar, ularning lokal dialeklari uchun ma'lumot yozuvchidan foydalanadi, yoki postlar va izohlarni yozishga ishlatadi. Afrikada 1500 dan ortiq dialeklar va tillar mavjud. Mualliflik, Tunisistonlar arabdan tashqi Latin harflari va raqamlari bilan yozishni o'rganishlar bilan o'zgartiradi. Bu qogʻozda biz Sentiment Analysis uchun bir katta ta'mincha muvaffaqiyatlarni o'rganamiz. Maʼlumotlar tarkibi Tunisiston natijasi gapiruvchilari bilan qo'llangan, negativ va Neutral kabi hammasi 100k izohlar (film, politik, sport, etc) dan iborat. Biz bir necha tillar versiyasi (mBERT) bilan bir xil tildagi bir xil tildagi bir xil kompyuter modeli deb qiymatmiz va keyin mBERT bilan bogʻliq Neural Tarmoq (CNN) bilan birlashtirish mumkin. Maʼlumotlar bazasini ochib boʻlmadi.", 'vi': 'Trên các quốc lộ truyền thông xã hội, con người, thường dùng cách giao tiếp không chính thức, hoặc viết bài viết và bình luận: ngữ điệu địa phương của họ. Ở Châu Phi, nhiều phương ngữ và ngôn ngữ hơn 15007 tồn tại. Đặc biệt, người Ý nói và viết thư bằng chữ cái Latin hơn là chữ cái Ả Rập. Trong bài báo này, chúng ta sẽ giới thiệu một bộ dữ liệu phương văn tự Ý của Tunisia, Name Bộ dữ liệu gồm cả bộ ghi chú hàng trăm bình luận (về phim, chính trị, thể thao, v.v.) được ghi nhận bằng tay bởi những người thổ dân Tunisia như là tích cực, âm và trung lập. Chúng tôi đánh giá dữ liệu của chúng tôi về nhiệm vụ phân tích cảm xúc, sử dụng các đơn vị Encoder bảo mật Bidirection từ Transformers (BERT) như một mô hình ngôn ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ nối tiếp trong phiên bản đa dạng của nó (mBERT) như một kỹ thuật ghép ghép ghép lại mBERT sau đó kết hợp kênh tâm thần (CNN) thành phân loại. Bộ dữ liệu có công khai.', 'bg': 'На различни платформи в социалните медии хората са склонни да използват неформалния начин за комуникация или да пишат публикации и коментари: техните местни диалекти. В Африка съществуват повече от 1500 диалекта и езика. Особено тунизийците говорят и пишат неформално, като използват латински букви и цифри, а не арабски. В тази статия представяме голям диалектен набор от данни от тунизийски арабици, базиран на общо обхождане, посветен на анализ на чувствата. Наборът от данни се състои от общо 100 000 коментара (за филми, политически, спортни и т.н.), анотирани ръчно от тунизийски носители като позитивни, негативни и неутрални. Ние оценяваме нашия набор от данни за задачата за анализ на сентимента, като използваме двупосочния кодер Представления от трансформатори (BERT) като контекстуален езиков модел в неговата многоезична версия (mBERT) като вградена техника, след което комбинираме mBERT с конвелуционална неврална мрежа (CNN) като класификатор. Наборът от данни е публично достъпен.', 'da': 'På forskellige sociale medieplatforme har folk en tendens til at bruge den uformelle måde at kommunikere, eller skrive indlæg og kommentarer: deres lokale dialekter. I Afrika findes mere end 1500 dialekter og sprog. Især taler tunesiske og skriver uformelt ved hjælp af latinske bogstaver og tal frem for arabiske. I denne artikel introducerer vi et stort almindeligt crawl-baseret tunesisk arabizi dialektalt datasæt dedikeret til følelsesanalyse. Datasættet består af i alt 100.000 kommentarer (om film, politik, sport osv.) manuelt kommenteret af tunesisk indfødte talere som Positive, negative og Neutrale. Vi evaluerer vores datasæt på sentimental analyseopgave ved hjælp af Bidirectional Encoder Representations from Transformers (BERT) som en kontekstuel sprogmodel i dens flersprogede version (mBERT) som en integreringsteknik og derefter kombinerer mBERT med Convolutional Neural Network (CNN) som klassificering. Datasættet er offentligt tilgængeligt.', 'nl': 'Op verschillende Social Media platforms gebruiken mensen de informele manier om te communiceren, of schrijven berichten en opmerkingen: hun lokale dialecten. In Afrika bestaan meer dan 1500-dialecten en talen. Vooral Tunesiërs praten en schrijven informeel met Latijnse letters en cijfers in plaats van Arabische. In dit artikel introduceren we een grote common-crawl-gebaseerde Tunesische Arabizi dialectische dataset gewijd aan Sentiment Analysis. De dataset bestaat uit een totaal van 100k commentaren (over films, politiek, sport, enz.) die handmatig door Tunesische moedertaalsprekers geannoteerd worden als positief, negatief en neutraal. We evalueren onze dataset over sentimentanalyse taak met behulp van de Bidirectional Encoder Representations from Transformers (BERT) als contextueel taalmodel in zijn meertalige versie (mBERT) als een embedding techniek en combineren vervolgens mBERT met Convolutional Neural Network (CNN) als classificator. De dataset is openbaar beschikbaar.', 'hr': 'Na raznim platformama društvenih medija ljudi koriste neformalni način da komuniciraju ili napišu postove i komentare: njihove lokalne dijalekte. U Africi postoje više od 1500 dijalekata i jezika. Posebno, Tunizi govore i napišu informalno koristeći latinske pisma i brojeve umjesto arapskih. U ovom papiru predstavljamo veliku zajedničku raspoloženost Tunisijske Arabizijske dijalektne podatke posvećene za analizu sentimenta. Podaci se sastavljaju od ukupnih 100k komentara (o filmovima, politici, sportu itd.) koje su manuelno izjavili Tunisijski govornici kao pozitivni, negativni i neutralni. Procjenjujemo naš komplet podataka o zadatku analize osjećaja koristeći predstavljanje dvosmjernog kodera od transformatora (BERT) kao kontekstualni jezički model u svojoj multijezičkoj verziji (mBERT) kao ugrađenu tehniku, a zatim kombiniranje mBERT sa konvolucionalnom neuronskom mrežom (CNN) kao klasifikator. Podaci su javno dostupni.', 'de': 'Auf verschiedenen Social Media Plattformen neigen Menschen dazu, informell zu kommunizieren oder Beiträge und Kommentare zu schreiben: ihre lokalen Dialekte. In Afrika gibt es mehr als 1500-Dialekte und Sprachen. Vor allem Tunesier sprechen und schreiben informell mit lateinischen Buchstaben und Zahlen anstatt arabischen. In diesem Beitrag stellen wir einen großen Common-Crawl-basierten tunesischen Arabizi dialektalen Datensatz für Sentiment Analysis vor. Der Datensatz besteht aus insgesamt 100k Kommentaren (zu Filmen, Politik, Sport usw.), die von tunesischen Muttersprachlern manuell als Positiv, Negativ und Neutral kommentiert wurden. Wir evaluieren unseren Datensatz zur Sentimentanalyse unter Verwendung der Bidirektional Encoder Representations from Transformers (BERT) als kontextuelles Sprachmodell in seiner mehrsprachigen Version (mBERT) als Einbettungstechnik und kombinieren mBERT mit Convolutional Neural Network (CNN) als Klassifikator. Der Datensatz ist öffentlich zugänglich.', 'id': 'Di berbagai platform Social Media, orang-orang, cenderung menggunakan cara informal untuk berkomunikasi, atau menulis pos dan komentar: dialekt lokal mereka. Di Afrika, lebih dari 1500 dialekt dan bahasa ada. Terutama, orang Tunisia berbicara dan menulis secara tidak resmi menggunakan huruf dan angka Latin daripada huruf Arab. Dalam kertas ini, kami memperkenalkan dataset dialektal Tunisia berdasarkan merangkak umum yang didedikasikan untuk Analisi Sentiment. The dataset consists of a total of 100k comments (about movies, politic, sport, etc.) annotated manually by Tunisian native speakers as Positive, negative and Neutral.  Kami mengevaluasi dataset kami pada tugas analisis sentimen menggunakan Perwakilan Koder Biarah dari Transformers (BERT) sebagai model bahasa kontekstual dalam versi multibahasa (mBERT) sebagai teknik penyembedding kemudian menggabungkan mBERT dengan Jaringan Neural Konvelusional (CNN) sebagai klasifikasi. Set data tersedia publik.', 'fa': 'مردم به طریق رسانه های اجتماعی مختلف استفاده می کنند که از طریق غیر معمولی برای ارتباط با ارتباط، یا پست و توضیح نوشته می کنند: دیالکت های محلی آنها. در آفریقا بیش از ۱۵۰۰ دیالکت و زبان وجود دارد. مخصوصاً تونیس\u200cها با استفاده از نامه\u200cهای لاتین و شماره\u200cها به جای عربی صحبت می\u200cکنند و به طور رسمی می می\u200cنویسند. در این کاغذ، ما یک مجموعه داده\u200cهای دایلکتی تونیسی عربی بسیار معرفی می\u200cکنیم که برای تحلیل سنتیمتر تعریف شده است. مجموعه داده\u200cها از جمله ۱۰۰۰ کیلومتر (درباره فیلم\u200cها، سیاسی\u200cها، ورزش و غیره\u200cها) توسط صحبت\u200cکننده\u200cهای متولد تونیسی به عنوان مثبت، منفی و عصبی به دست یاد می\u200cگیرند. ما مجموعه داده\u200cهای خود را در مورد کار تحلیل احساسات با استفاده از نمایش\u200cهای رمزگار\u200cکننده\u200cها (BERT) به عنوان مدل زبان متوسط در نسخه\u200cهای زیادی زبان (mBERT) به عنوان تکنیک پیوند\u200cکننده\u200cای (mBERT) ارزیابی می\u200cکنیم، سپس mBERT را با شبکه عصبی\u200cهای متوسط (CNN) به عنوان کلاس مجموعه داده ها به طور عمومی در دسترس هستند.', 'ko': '각종 소셜미디어 플랫폼에서 사람들은 비공식적인 방식으로 의사소통을 하거나 댓글과 평론을 쓰는 경향이 있다. 그들의 사투리다.아프리카에는 1500여 종의 사투리와 언어가 있다.특히 튀니지인들은 아라비아 자모와 숫자가 아닌 라틴 자모와 숫자로 비공식적인 대화와 쓰기를 한다.본고에서 우리는 감정 분석에 사용되는 인터넷 기반의 튀니지 아랍어 사투리 데이터 집합을 소개했다.총 10만건의 리뷰(영화, 정치, 스포츠 등에 관한)로 구성된 이 데이터집은 튀니지를 모국어로 하는 사람이 수동으로 긍정적, 부정적, 중성적으로 주석을 달았다.우리는 감정 분석 임무에서 우리의 데이터 집합을 평가하고 Transformers(BERT)에서 온 양방향 인코더를 사용하여 상하문 언어 모델로 표시하고 다국어 버전(mBERT)에 삽입 기술로 사용한 다음에 mBERT와 권적신경 네트워크(CNN)를 결합시켜 분류기로 한다.이 데이터 세트는 공개된 것이다.', 'sw': 'Katika majukwaa mbalimbali ya mitandao ya kijamii, watu wanatumia njia isiyo rasmi ya kuwasiliana, au kuandika makala na maoni: hotuba zao za ndani yao. Nchini Afrika, zaidi ya lugha 1500 zipo. Hasa, wa-Tunisia wanazungumza na kuandika kwa kutumia barua na namba za Kilatini badala ya wale wa Kiarabu. Katika gazeti hili, tunaonyesha seti kubwa ya takwimu za lugha za Kiarabu za Tunisia yenye kawaida zilizotengenezwa kwa ajili ya uchambuzi wa Seneti. Taarifa hiyo inajumuisha maoni ya jumla ya milioni 100 (kuhusu filamu, siasa, michezo, etc.) yanayochapishwa kwa manufaa na wazungumzaji wa asili wa Tunisia kama chanya, hasi na Nøytrol. Tutathmini takwimu zetu kuhusu jukumu la uchambuzi wa hisia kwa kutumia Representative wa Kielekjia Encoder kutoka kwa Wasafiri (BERT) kama modeli ya lugha ya zamani katika toleo la lugha mbalimbali (mBERT) kama kiteknolojia kinachotengeneza na kisha kuunganisha mBERT na Mtandao wa Neural (CNN) wa Kujitoleza (CNN). Taasisi ya taarifa zinapatikana hadharani.', 'af': "Op verskeie sosiale media platforme, mense het die onformele manier gebruik om te kommuniseer of te skryf pos en kommentaar: hulle plaaslike dialekte. In Afrika bestaan meer as 1500 dialekte en tale. Eenvoudiglik, Tunisiërs praat en skryf informasies met Latynse letters en getalle in plaas van Arabiese. In hierdie papier, introduseer ons 'n groot gemeenskaplike-kraal-gebaseerde Tunisië Arabiese dialektiese datastel wat vir Sentiment Analisie gespesifiseer is. Die datastel bestaan van 'n totaal van 100k kommentaar (aangaande filme, politieke, sport, ensfh.) wat hand deur Tunisië-wetlike sprekkers as positiewe, negatiewe en neutraal aangetrek word. Ons evalueer ons datastel op sentimentanalisie taak deur te gebruik die Bidireksionale enkoder voorstellings van Transformers (BERT) as 'n contextual taal model in sy multitaal weergawe (mBERT) as 'n inbêring tekniks dan kombinieer mBERT met Convolutional Neural Network (CNN) as klassifiseerder. Die datastel is openlik beskikbaar.", 'tr': "Çeşitli Sosyal Medya platformlarynda adamlar resmi ýazgytlaryny ýazmak, ýada terjimelerini ýazmak üçin resmi ýoly ulanýarlar. Afrika, 1500-den köp dialektler we diller bar. Aýratyn bölegi, Túnesler Arapça harplary we rakamlary ulanyp resmi ýazylýar. Bu kagyzda Sentiýat Analizi üçin beýleki düzümlenmiş túnez arábiýasynda ullanýan uly bölegi bilen üýtgedýäris Veri setir 100k terjimelerinden (filmler, syýasatçy, sport we bölekler barada) Tuniziýanyň ene çykyşlaryndan elimden gelen terjimelerdir. Biz sentiment analizi täblisasinde terjime edip bidirectional Ködler ködlemeleri (BERT) terjime edip görkezilýän dil nusgasyna görä terjime edip çykýarys. Sonra mBERT'i terjime edip görkezilýän tekniki bilen terjime edip duran Neural Network (CNN) bilen birleşdirýäris Maglumat setirini publika meýilleşdirýär.", 'sq': 'Në platforma të ndryshme të Mediave Sociale, njerëzit, kanë tendencë të përdorin mënyrën jozyrtare për të komunikuar ose për të shkruar poste dhe komente: dialektet e tyre lokale. In Africa, more than 1500 dialects and languages exist.  Veçanërisht, tunezët flasin dhe shkruajnë në mënyrë jozyrtare duke përdorur letra dhe numra latine në vend të ato arabe. Në këtë letër, ne paraqesim një grup të madh të dhënash dialektale tunizi me bazë të përbashkët-crawl, të dedikuar për Analizën e Sentimenteve. Të dhënat përbëhen nga një total prej 100.000 komentesh (rreth filmave, politikës, sportit, etj.) të shënuara manualisht nga folësit vendas tunizinë si pozitive, negative dhe neutrale. Ne vlerësojmë grupin tonë të dhënash mbi detyrën e analizës së ndjenjave duke përdorur Përfaqësitë e Koduesit Bidrejtues nga Transformuesit (BERT) si një model gjuhësh kontekstual në version in e tij shumëgjuhës (mBERT) si një teknikë përfshirëse pastaj duke kombinuar mBERT me Rrjetin Neural Konveolutional (CNN) si klasifikues. Të dhënat janë në dispozicion publik.', 'am': 'በተለያዩ ማኅበራዊ ሚዲያ ፕላውንቶች ላይ፣ ሰዎች ማነጋገር፣ ወይም ጽሑፎችን እና አስተያየትን ለመጠቀም፣ የአገራዊ ዝርዝሮች እና አስተያየት በመጠቀም ይጠቀማሉ፡፡ በአፍሪካ፣ ከ1500 በላይ ቋንቋዎች እና ቋንቋዎች የሚበልጡ ናቸው፡፡ በተለይም፣ Tunisians በአረቢኛ ቋንቋ እና ቁጥር በመጠቀም እና በመጻፍ ይናገራሉ፡፡ In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for Sentiment Analysis.  የዳታ ሰርቨርስቲው በጥያቄ፣ negative እና ውጤት በጥያቄ እና በጥያቄ የቲንስ እና በጥያቄ የሚታወቁት (ስለፊልሞች፣ ፖለቲካ፣ የጨዋታ ጨዋታ እና የፖለቲካ እና የጨዋታ አካባቢዎች) በሙሉ 100 ሺሕ ትርጉም ነው አዲስ የቋንቋ ቋንቋ ምሳሌ (mBERT) የፊደል ቋንቋ አካባቢ (BERT) በተጠቃሚ የልዩ ቋንቋ አካባቢ (MBERT) የተሰኘውን የድምፅ አካባቢ ስራዎችን በመጠቀም እናሳውቃለን፡፡ የዳታ ሳጥን ግልፅ ነው', 'hy': 'Տարբեր սոցիալական լրատվամիջոցների պլատֆորմերում մարդիկ հակված են օգտագործել ոչ տեղեկատվական միջոցը հաղորդակցվելու, կամ գրելու աշխատանքներ և մեկնաբանություններ՝ իրենց տեղական դիալեկտներ: Աֆրիկայում ավելի քան 1500 դիալեկտ և լեզուներ կան: Հատկապես, թունիսացիները խոսում և գրում են ոչ պաշտոնական լատիներեն տառեր և թվեր օգտագործելով, ոչ թե արաբերեն: Այս թղթի մեջ մենք ներկայացնում ենք մի մեծ տարածված թունիսական արաբիզի դիալեկտալ տվյալների համակարգ, որը նվիրված է զգացմունքների վերլուծության համար: Տվյալների համակարգը կազմված է 100,000 մեկնաբանություններից (ֆիլմերի, քաղաքականության, սպորտի մասին և այլն), որոնք ձեռքով գրված են Թունիսյան բնիկ խոսնակների կողմից որպես դրական, բացասական և նեյրոնական: Մենք գնահատում ենք զգացմունքների վերլուծության մեր տվյալների համակարգը, օգտագործելով Երկու ուղղությամբ կոդավորվող ներկայացուցիչների (BER) ներկայացուցիչները որպես կոնտեքստալ լեզվի մոդել իր բազլեզու տարբերակում (mBER) որպես ներգրավման տեխնիկա, հետո միավորելով mBER-ը Կանվոլյուցիոն Նյա Տվյալների համակարգը հասանելի է:', 'az': "ńįnsanlar m√ľxt…ôlif sosyal media platformlarńĪnda informal yolu il…ô iletiŇüim etm…ôk, yazmaq v…ô Ňü…ôkild…ô yazmaq ist…ôyirl…ôr: yerli dialektl…ôri. Afrika'da 1500-d…ôn √ßox dialekt v…ô dill…ôr var. √Ėzellikle, T√ľnizl…ôr …ôr…ôb dilind…ôn …ôvv…ôl Latin harfleri v…ô sayńĪlarńĪ istifad…ô ed…ôr…ôk danńĪŇüńĪr v…ô yazńĪrlar. Bu kańüńĪzda, Sentiment Analizi √ľ√ß√ľn m√ľ…ôyy…ôn edil…ôn b√∂y√ľk m√ľxt…ôlif Tunizi ArabsiyalńĪ dialektal veril…ôr qutusunu tanńĪyńĪrńĪq. Veril…ôr qurulusu, T√ľnizi yerli danńĪŇüanlarńĪn …ôlind…ô pozitiv, negativ v…ô Neutral olaraq bildirilmiŇü 100k koment…ô√ßil…ôrind…ôn olub. Biz sentiment analizi g√∂revi bar…ôsind…ôki veril…ônl…ôrimizi Transformers (BERT) il…ô m√ľxt…ôlif dil modeli olaraq (mBERT) √ßoxlu dil versiyonu il…ô birl…ôŇüdirib mBERT'i Convolutional Neural Network (CNN) il…ô klasifikat√ßńĪ kimi birl…ôŇüdiririk. Veri qurńüularńĪ a√ßńĪq-aŇükar m√∂vcuddur.", 'bn': 'বিভিন্ন সোশ্যাল মিডিয়া প্ল্যাটফর্মে লোকেরা যোগাযোগ করার জন্য আনুষ্ঠানিক উপায় ব্যবহার করে অথবা পোস্ট ও মন্তব্য লিখেন: তা In Africa, more than 1500 dialects and languages exist.  বিশেষ করে তিউনিশিয়ানরা আরবীর চেয়ে ল্যাটিন চিঠি এবং সংখ্যা ব্যবহার করে কথা বলে লিখেছেন। এই পত্রিকায় আমরা সেন্টাইমেন্ট বিশ্লেষণের জন্য বিশেষ একটি বিশাল সাধারণ ক্রাউল ভিত্তিক তিউনিশিয়ার আরবের ডায়ালেক্টাল ডাটা তিউনিশিয়ার স্থানীয় ভাষাকারীদের নিজেতিভাবে, নেতিবাচক এবং নিউট্রেল হিসেবে বিবেচনা করেছে এই তথ্যের মোট ১০০ হাজার মন্তব্যের মধ্যে রয়েছে ( ট্রান্সফার্মার (বিআরটি) থেকে বাইডেডিয়াল এনকোডার প্রতিনিধি ব্যবহার করে আমাদের অনুভূতিবিশ্লেষণ কাজের উপর ডাটাসেটের মূল্যায়ন করা হচ্ছে যা তার বহুভাষায় ভাষার মডেল হিসেবে বিভিন্ন ভাষায় এক ডাটাসেট প্রকাশ্যে পাওয়া যাচ্ছে।', 'bs': 'Na raznim platformama društvenih medija ljudi koriste neformalni način da komuniciraju ili napišu postove i komentare: njihove lokalne dijalekte. U Africi postoje više od 1500 dijalekata i jezika. Posebno, Tunizi govore i napišu informalno korištenjem latinskih pisma i brojeva umjesto arapskih. U ovom papiru predstavljamo veliku zajedničku raspoloženost Tunisijske Arabijske dijalektne podatke posvećene za analizu sentimenta. Podaci se sastavljaju od ukupnih 100k komentara (o filmovima, politici, sportu, itd.) koje su manuelno izjavili Tunisijski govornici kao pozitivni, negativni i neutralni. Procjenjujemo naš komplet podataka o zadatku analize osjećanja koristeći predstave dvosmjernog kodera iz transformatora (BERT) kao kontekstualni jezički model u svojoj multijezičkoj verziji (mBERT) kao ugrađenu tehniku, a zatim kombinujemo mBERT sa konvolucionom neuronskom mrežom (CNN) kao klasifikator. Podaci su javno dostupni.', 'ca': "En diverses plataformes de mitjans socials, la gent tendeix a utilitzar la manera informal de comunicar-se, o escriure posts i comentaris: els seus dialectes locals. In Africa, more than 1500 dialects and languages exist.  En particular, els tunís parlen i escriuen informalment utilitzant lletres i números llatins en lloc d'àrabs. En aquest article, introduïm un gran conjunt de dades dialectals tunisienses basat en un crawl comú dedicat a l'anàlisi del sentiment. El conjunt de dades consisteix en un total de 100.000 comentaris (sobre pel·lícules, política, esport, etc.) anotats manualment pels oradors natius tunisisos com positivs, negatius i neutres. Evaluam el nostre conjunt de dades sobre la tasca d'an àlisi del sentiment utilitzant les Representacions Bidireccionals del Codificador dels Transformers (BERT) com un model de llenguatge contextual en la seva versió multillengua (mBERT) com una tècnica d'incorporació, i llavors combinant mBERT amb la Red Neural Convolutional (CNN) com a classificador. El conjunt de dades està disponible al públic.", 'et': 'Erinevatel sotsiaalmeedia platvormidel kipuvad inimesed suhtlema mitteametlikult või kirjutama postitusi ja kommentaare: oma kohalikke murdeid. Aafrikas eksisteerib üle 1500 dialekti ja keele. Eriti tunisialased räägivad ja kirjutavad mitteametlikult ladina tähtede ja numbrite asemel araabia. Käesolevas dokumendis tutvustame suurt ühise crawl-põhist Tuneesia Arabizi dialektuaalset andmekogumit, mis on pühendatud tunnete analüüsile. Andmekogum koosneb kokku 100 000 kommentaarist (filmide, poliitika, spordi jne kohta), mida Tuneesia emakeelena kõnelejad käsitsi märgivad positiivse, negatiivse ja neutraalse all. Hindame oma sentimentaalse analüüsi andmekogumit, kasutades kahesuunalist kodeerijate representatsiooni transformaatoritelt (BERT) kontekstuaalse keelemudelina selle mitmekeelses versioonis (mBERT) manustamismeetodina ning kombineerides mBERT konvolutsioonivõrguga (CNN). Andmekogum on avalikult kättesaadav.', 'cs': 'Na různých platformách sociálních médií lidé mají tendenci používat neformální způsob komunikace nebo psát příspěvky a komentáře: své místní dialekty. V Africe existují více než 1500 dialekty a jazyky. Obzvláště Tunišané mluví a píšou neformálně latinskými písmeny a čísly spíše než arabskými. V tomto článku představujeme rozsáhlý dialektální datový soubor tuniského Arabizi založený na běžném crawlu určený pro analýzu sentimentů. Datová sada se skládá z celkem 100k komentářů (o filmech, politice, sportu apod.), které tuniskými rodilými mluvčími ručně označili jako kladné, negativní a Neutrální. Náš datový soubor pro úlohu analýzy sentimentů vyhodnocujeme pomocí obousměrného kódování reprezentací z transformátorů (BERT) jako kontextového jazykového modelu v jeho vícejazyčné verzi (mBERT) jako metody vložení a kombinování mBERT s Convolucionální neuronovou sítí (CNN) jako klasifikátor. Soubor dat je veřejně dostupný.', 'fi': 'Eri sosiaalisen median alustoilla ihmiset yleensä käyttävät epävirallista tapaa kommunikoida tai kirjoittaa viestejä ja kommentteja: heidän paikallisia murteita. Afrikassa on yli 1500 murretta ja kieltä. Erityisesti tunisialaiset puhuvat ja kirjoittavat epävirallisesti käyttäen latinalaisia kirjaimia ja numeroita arabialaisten sijaan. Tässä artikkelissa esittelemme suuren Tunisian Arabizin murretiedoston, joka on omistettu tunteiden analysointiin. Aineisto koostuu yhteensä 100 000 kommentista (elokuvista, politiikasta, urheilusta jne.), jotka tunisialaisia äidinkielenään puhuvia kommentoivat manuaalisesti positiivisiksi, negatiivisiksi ja neutraaleiksi. Arvioimme tunteiden analyysin aineistoa käyttäen kaksisuuntaista koodaajien representaatioita muuntajilta (BERT) kontekstuaalisena kielimallina monikielisessä versiossaan (mBERT) upotustekniikana ja yhdistämme mBERT:n konvolutional neural network (CNN) luokittelijana. Aineisto on julkisesti saatavilla.', 'he': 'במדיות חברתיות שונות, אנשים נוטים להשתמש בדרך לא רשמית לתקשר, או לכתוב משימות ותערות: הדיאלקטים המקומיים שלהם. באפריקה, קיימים יותר מ-1500 דיאלקטים ושפות. במיוחד, טוניסים מדברים וכתובים באופן לא רשמי באמצעות מכתבים ומספרים לטינים במקום ערביים. בעיתון הזה, אנחנו מציגים קבוצת מידע דיאלקטאלית טוניסית רביזית מבוססת על זחלה משותפת גדולה מוקדשת לניתוח רגשות. קבוצת המידע מורכבת בסך הכל מאה אלף תגובות (על סרטים, פוליטיקה, ספורט, וכו"כ) שנכתבו ידנית על ידי דיבורים מקומיים טוניסיים כחיוביים, שליליים ונוטרלים. אנו מעריכים את קבוצת הנתונים שלנו על משימת ניתוח רגשות באמצעות מייצגים של קודד שתי כיוונים ממעברים (BERT) כדוגמנית שפה קונטקסטית בגרסה רבת-שפותית שלה (mBERT) כטכניקה שילוב אחר כך mBERT עם רשת נוירולית קונבנולציונית (CNN) כקלאסיפור. The dataset is publicly available.', 'jv': 'Nang sampeyan Kasama Media Sumerang, wong-wong, tentang penggunaké ngerasakno karo komunikasi, nggambar tarjamahan lan komentar: dialects lokal. Nanging Afrika, luwih basa karo 1.500 dialects lan luwih dumadhi Manculine-Manculine, Tunisi kuwi nggambar lan basa gambar barang Latin karo nomer arap kuwi tanggal arap. Nan pepulan iki, kita nyibagi nggawe barang-barang sing basa Tunisian karbot dialectal dataset sing nyimpen kanggo Sentiment Test. dataset nduwe akeh sing karo akeh stok komentar (babagan film, politik, kartik, njl.) Awak dhéwé éntuk dataset nganggo penting nggawe seneng dipunalisi task nggawe Bidirectial dataset kang dipuluhayo', 'ha': "Daga duk platformi na jamii, wasu mutane sun yi amfani da hanyar da ba'a koma ba, ko kuma su rubũta takardar da mawaƙa: misalin lokacinsu. In Africa, more than 1500 dialects and languages exist.  Kayyai, Tunisi masu magana da suna rubũtun karãtun littattafan na Larabci, da kuma don tallar Larabci. Ga wannan takardan, Munã ƙara da tsarin littafan taƙaita mai tsakanin Tunisiya na Larabci wanda aka ƙayyade wa Analyya na Saukar. Danset na ƙunsa da jama'a guda na fatauci 100,000 (game da filamu, siyasa, jigon, etc.) wanda aka yi wa fassarar magana na Tunisiya da hannuwansa kamar Positive, negative da Neutral. Tuna ƙaddara danne-set a kan aikin hisãbi da ke amfani da the Bidiridal Encoder Repositions from Transformers (BERT) kamar wata motel na zaman harshen zaman cikin versiyori multilala (mBERT) kamar an embedded technci, sa'an nan kuma Mu koma mBERT da Conversation Neural Networks (CNN) kamar classifiserer. An sami tsarin bayani.", 'sk': 'Na različnih platformah socialnih medijev ljudje običajno uporabljajo neformalen način komuniciranja ali pisanja objav in komentarjev: njihova lokalna narečja. V Afriki obstaja več kot 1500 narečij in jezikov. Zlasti Tunizijci govorijo in pišejo neuradno z latinskimi črkami in številkami namesto arabskimi. V tem prispevku predstavljamo velik nabor podatkov tunizijskega arabiškega narečja, ki temelji na skupnem iskanju, namenjen analizi čustev. Zbirka podatkov je sestavljena iz skupno 100k komentarjev (o filmih, politiki, športu itd.), ki jih tunizijski materni govorci ročno označijo kot pozitivni, negativni in nevtralni. Naš nabor podatkov o nalogi analize sentimenta ocenjujemo z uporabo dvosmernih predstavitev kodirnikov iz transformatorjev (BERT) kot kontekstualnega jezikovnega modela v njegovi večjezični različici (mBERT) kot tehniko vdelave, nato pa združujemo mBERT s konvolucionalnim živčnim omrežjem (CNN). Zbirka podatkov je javno dostopna.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་འཇུག་ཟམ་གླེང་སྟེགས་འདྲ་བའི་མི་མང་པོ་ཞིག་གིས་གནས་སྟངས་ལས་སྦྲེལ་མཐུད་དང་། ཨ་རིའི་ནང་དུ་འཛམ་གླིང་༡༥༠ལྷག་ནས་dialects and languages་ཡོད། ཁྱད་དུ་འཕགས་པ་ཞིག་ནི་ ཊ་ནེ་སི་ཡི་གེ་དང་ཨང་ཀིའི་ཡིག་རྩལ་ལས་སྤྱོད་མ་བྱས་པ ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྤྱིར་བཏང་བའི་གླེང་སྒྲུང་ཆེན་པོ་ཞིག་གིས་སྤྲོད་ནས་དུས་གཏོང་། སྡེབ་ཆ་ཚང་ནང་དུ་ཡོད་པའི་མཆན་བཤད་ལྡ100k བསྡམས་ཡོད། We evaluate our dataset on sentiment analysis task using the Bidirectional Encoder Representations from Transformers (BERT) as a contextual language model in its multilingual version (mBERT) as an embedding technique then combining mBERT with Convolutional Neural Network (CNN) as classifier. སྒྲིག་ཆ་སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་སྤྱད་ཚར་བ'}
{'en': 'Improving Cross-Lingual Transfer for Event Argument Extraction with Language-Universal Sentence Structures', 'ar': 'تحسين النقل عبر اللغات لاستخراج وسيطة الحدث باستخدام تراكيب الجمل العامة اللغوية', 'fr': "Amélioration du transfert multilingue pour l'extraction d'arguments d'événements avec des structures de phrases universelles", 'pt': 'Melhorando a transferência entre idiomas para extração de argumentos de eventos com estruturas de sentenças universais de linguagem', 'es': 'Mejora de la transferencia multilingüe para la extracción de argumentos de eventos con estructuras de oraciones universales del lenguaje', 'ja': '言語-普遍的な文章構造を持つイベント引数抽出のためのクロスリンガル転送の改善', 'ru': 'Улучшение кросс-лингвальной передачи для извлечения аргументов событий с помощью универсальных языковых структур предложений', 'zh': '语言通句结构改事参数提取跨语移', 'hi': 'भाषा-यूनिवर्सल वाक्य संरचनाओं के साथ घटना तर्क निष्कर्षण के लिए क्रॉस-लिंगुअल स्थानांतरण में सुधार', 'ga': 'Aistriú Trastheangach a Fheabhsú le haghaidh Astarraingt Argóinte Imeachta le Struchtúir Phianbhreithe Uilíoch Teanga', 'ka': 'მოვლენების არგუმენტის ექსტრექციისთვის კროსი- ლინგუალური ტრანსტრიქციის უფრო მეტირება', 'el': 'Βελτίωση της γλωσσικής μεταφοράς για την εξαγωγή επιχειρημάτων συμβάντος με δομές λέξεων γλωσσικών-καθολικών', 'hu': 'Nyelvközi transzfer javítása az események argumentumainak kivonásához nyelvi-univerzális mondatstruktúrákkal', 'kk': 'Оқиға аргументін тіл- Universal сөз құрылымының аргументті тарқату үшін бірнеше тілі транспорттауын жақсарту', 'it': "Migliorare il trasferimento cross-lingual per l'estrazione di argomenti di eventi con strutture di frase Language-Universal", 'mk': 'Подобрување на трансферот преку јазик за екстракција на аргументи за настани со структури на јазик- универзални реченици', 'lt': 'Įvykių argumentų ekstrakcijos tarpkalbinio perdavimo gerinimas naudojant kalbų ir universalių sakinių struktūras', 'ms': 'Menembak Pemindahan Selata-Lingua untuk Ekstraksi Argumen Peristiwa dengan Struktur Hukuman Universal-Bahasa', 'ml': 'ഭാഷ- Universal Sentence Structure', 'mt': 'Improving Cross-Lingual Transfer for Event Argument Extraction with Language-Universal Sentence Structures', 'mn': 'Өөрчлөлтийн аргументын аргументын хамтдаа хэл-Universal өгүүлэлтийн структуруудыг нэмэгдүүлэх хэлбэрийн хэлбэрийн транформацийг сайжруулах', 'pl': 'Poprawa transferu między językami dla ekstrakcji argumentów zdarzeń za pomocą językowych uniwersalnych struktur zdań', 'no': 'Forbetra kryss- lingual- overføring for hendingar- argumentekstrahering med språk- universell setningsstruktur', 'ro': 'Îmbunătățirea transferului translingvistic pentru extragerea argumentelor de evenimente cu structuri lingvistice-universale de sentință', 'sr': 'Poboljšanje prijenosa preko jezika za izvlačenje argumenta događaja sa strukturama jezika-univerzalne kazne', 'si': 'Name', 'so': 'Horumarinta guuritaanka jardiinada xaaladaha dhacda ee iskuulka-luqada', 'sv': 'Förbättra tvärspråklig överföring för extraktion av händelseargument med språkuniversella meningsstrukturer', 'ta': 'மொழி- உலகளாவிய வாக்கியம் அமைப்புகளுடன் நிகழ்வுக்கான குறுக்கோடு மாற்றுதல் மாற்றுதல் மேம்படுத்தல்', 'ur': 'Name', 'uz': 'Name', 'vi': 'Tăng cường truyền ngôn ngữ học cho biện pháp đại sự', 'hr': 'Poboljšanje prijenosa preko jezika za izvlačenje argumenta događaja sa strukturama jezika-univerzalne kazne', 'bg': 'Подобряване на междуезиковия трансфер за извличане на аргументи за събития с езикови и универсални структури на изречения', 'da': 'Forbedring af tværsproget overførsel til ekstraktion af hændelsesargumenter med sproguniverselle sætningsstrukturer', 'nl': 'Verbetering van cross-linguale overdracht voor extractie van gebeurtenisargumenten met taal-universele zinnenstructuren', 'id': 'Improving Cross-Lingual Transfer for Event Argument Extraction with Language-Universal Sentence Structures', 'fa': 'افزایش انتقال متصل زبان برای اخراج آرگوم اتفاق با ساختارهای ویژه\u200cهای زبان-جهانی', 'sw': 'Kuboresha Uhamiaji wa Kimataifa wa Kirusi kwa ajili ya Tume ya Utoa kwa Miundombinu ya Mashitaka ya Kimataifa ya Lugha', 'tr': 'Vaqialar Argument Açmak üçin Çaltylyk-Dil-Universal Sözler strukturlary bilen gowylaşdyr', 'de': 'Verbesserung des sprachübergreifenden Transfers für die Extraktion von Ereignisargumenten mit sprachuniversellen Satzstrukturen', 'ko': '언어 통용문 구조를 이용하여 이벤트 논원 추출의 다중 언어 이동 개선', 'af': 'Verbeter Kruis- Linguale Oordrag vir Gebeurtenis Argument Uitpakking met Taal- Universele UitdrukkingsstruktureComment', 'sq': 'Duke përmirësuar transferimin ndërgjuhësor për ekstraksionin e argumenteve të ngjarjeve me strukturat e fjalimit gjuhësor-universal', 'am': 'የቋንቋ-Universal Sentence Structures', 'az': 'Vaqiyat Argumenti Çıqışması üçün Çift Dili-Universal Sözü Quruluqları ilə', 'hy': 'Լեզվի-համաշխարհային նախադասությունների կառուցվածքների օգնությամբ միջլեզվային փոխանցումը բարելավելը', 'ca': 'Improving Cross-Lingual Transfer for Event Argument Extraction with Language-Universal Sentence Structures', 'bs': 'Poboljšanje prijenosa preko jezika za izvlačenje argumenta događaja sa strukturama jezika-univerzalne kazne', 'bn': 'অন্যান্য আর্গুমেন্ট এক্সট্র্যাকশনের জন্য ক্রস- লিঙ্গুয়াল ট্রান্সফার্স করা হচ্ছে ভাষা- বিশ্ববিদ্যালয়ের শাস', 'et': 'Sündmuste argumentide väljavõtmise keeleülese ülekande parandamine keele-universaalsete lausestruktuuridega', 'cs': 'Zlepšení přenosu mezi jazyky pro extrakci argumentů událostí pomocí jazykových univerzálních vět', 'fi': 'Parannetaan kielienvälistä siirtoa tapahtumaargumenttien purkamiseen kielillä ja universaaleilla lauserakenteilla', 'sk': 'Izboljšanje medjezikovnega prenosa za ekstrakcijo argumentov dogodkov z jezikovno-univerzalnimi stavkovnimi strukturami', 'he': 'שיפור העברה לישונית לצורך חיפוש סכם אירועים עם מבני גזר שפה-יוניברסלי', 'ha': 'KCharselect unicode block name', 'jv': 'Progress', 'bo': 'Improving Cross-Lingual Transfer for Event Argument Extraction with Language-Universal Sentence Structures'}
{'en': 'We study the problem of Cross-lingual Event Argument Extraction (CEAE). The task aims to predict argument roles of entity mentions for events in text, whose language is different from the language that a predictive model has been trained on. Previous work on CEAE has shown the cross-lingual benefits of universal dependency trees in capturing shared syntactic structures of sentences across languages. In particular, this work exploits the existence of the syntactic connections between the words in the dependency trees as the anchor knowledge to transfer the representation learning across languages for CEAE models (i.e., via graph convolutional neural networks   GCNs). In this paper, we introduce two novel sources of language-independent information for CEAE models based on the semantic similarity and the universal dependency relations of the word pairs in different languages. We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models. Extensive experiments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE.', 'fr': "Nous étudions le problème de l'extraction d'arguments d'événements multilingues (CEAE). La tâche vise à prédire les rôles d'argument des mentions d'entités pour des événements dans un texte dont la langue est différente de celle sur laquelle un modèle prédictif a été formé. Des travaux antérieurs sur le CEAE ont montré les avantages interlinguistiques des arbres de dépendance universels pour capturer les structures syntaxiques partagées des phrases entre les langues. En particulier, ce travail exploite l'existence de connexions syntaxiques entre les mots dans les arbres de dépendance comme connaissances d'ancrage pour transférer l'apprentissage de la représentation entre les langues pour les modèles CEAE (c'est-à-dire via des réseaux de neurones convolutionnels de graphes — GCN). Dans cet article, nous présentons deux nouvelles sources d'informations indépendantes de la langue pour les modèles CEAE basées sur la similitude sémantique et les relations de dépendance universelles des paires de mots dans différentes langues. Nous proposons d'utiliser les deux sources d'information pour produire des structures de phrases partagées afin de combler le fossé entre les langues et d'améliorer les performances multilingues des modèles CEAE. Des expériences approfondies sont menées avec l'arabe, le chinois et l'anglais afin de démontrer l'efficacité de la méthode proposée pour le CEAE.", 'ar': 'ندرس مشكلة استخراج حجة الأحداث عبر اللغات (CEAE). تهدف المهمة إلى التنبؤ بأدوار الجدل التي يذكرها الكيان للأحداث في النص ، والتي تختلف لغتها عن اللغة التي تم تدريب النموذج التنبئي عليها. أظهر العمل السابق على CEAE الفوائد عبر اللغات لأشجار التبعية الشاملة في التقاط الهياكل النحوية المشتركة للجمل عبر اللغات. على وجه الخصوص ، يستغل هذا العمل وجود الروابط النحوية بين الكلمات في أشجار التبعية كمعرفة مرساة لنقل التعلم التمثيلي عبر اللغات لنماذج CEAE (أي عبر الشبكات العصبية التلافيفية للرسم البياني - GCNs). في هذه الورقة ، نقدم مصدرين جديدين للمعلومات المستقلة عن اللغة لنماذج CEAE بناءً على التشابه الدلالي وعلاقات التبعية العالمية لأزواج الكلمات في لغات مختلفة. نقترح استخدام مصدري المعلومات لإنتاج هياكل جمل مشتركة لسد الفجوة بين اللغات وتحسين الأداء عبر اللغات لنماذج CEAE. يتم إجراء تجارب مكثفة باللغات العربية والصينية والإنجليزية لإثبات فعالية الطريقة المقترحة لـ CEAE.', 'es': 'Estudiamos el problema de la extracción multilingüe de argumentos de eventos (CEAE). La tarea tiene como objetivo predecir los roles de argumento de las menciones de entidades para eventos en el texto, cuyo lenguaje es diferente del lenguaje en el que se ha entrenado un modelo predictivo. El trabajo anterior sobre CEAE ha demostrado los beneficios multilingües de los árboles de dependencia universal en la captura de estructuras sintácticas compartidas de oraciones en todos los idiomas. En particular, este trabajo explota la existencia de las conexiones sintácticas entre las palabras en los árboles de dependencias como el conocimiento ancla para transferir el aprendizaje de la representación a través de los idiomas para los modelos CEAE (es decir, a través de redes neuronales convolucionales gráficas — GCN). En este artículo, presentamos dos fuentes novedosas de información independiente del idioma para los modelos CEAE basadas en la similitud semántica y las relaciones de dependencia universal de los pares de palabras en diferentes idiomas. Proponemos utilizar las dos fuentes de información para producir estructuras de oraciones compartidas para cerrar la brecha entre los idiomas y mejorar el rendimiento multilingüe de los modelos CEAE. Se realizan extensos experimentos con árabe, chino e inglés para demostrar la eficacia del método propuesto para la CEAE.', 'pt': 'Estudamos o problema de Extração de Argumentos de Eventos Cruzados (CEAE). A tarefa visa prever papéis de argumento de menções de entidade para eventos em texto, cuja linguagem é diferente da linguagem em que um modelo preditivo foi treinado. Trabalhos anteriores no CEAE mostraram os benefícios multilíngues das árvores de dependência universal na captura de estruturas sintáticas compartilhadas de frases entre idiomas. Em particular, este trabalho explora a existência das conexões sintáticas entre as palavras nas árvores de dependência como o conhecimento âncora para transferir o aprendizado de representação entre linguagens para modelos CEAE (ou seja, via redes neurais convolucionais de grafos – GCNs). Neste artigo, apresentamos duas novas fontes de informação independente de idioma para modelos CEAE baseados na similaridade semântica e nas relações de dependência universal dos pares de palavras em diferentes idiomas. Propomos usar as duas fontes de informação para produzir estruturas de frases compartilhadas para preencher a lacuna entre os idiomas e melhorar o desempenho multilíngue dos modelos CEAE. Extensos experimentos são conduzidos com árabe, chinês e inglês para demonstrar a eficácia do método proposto para CEAE.', 'ja': '私たちは、クロスリンガルイベント引数抽出（ CEAE ）の問題を研究しています。 このタスクは、予測モデルが訓練されている言語とは異なる、テキスト内のイベントに対するエンティティの言及の引数の役割を予測することを目的としています。 CEAEに関する以前の研究は、言語間で文の共有構文構造を取り込む際の普遍的依存性ツリーのクロスリンガルの利点を示しています。 特に、この研究は、CEAEモデルの言語間で表現学習を転送するためのアンカー知識として、依存木の単語間の構文接続の存在を利用する（すなわち、グラフ畳み込みニューラルネットワーク– GCNを介して）。 本稿では、異なる言語における単語ペアの意味的類似性と普遍的依存関係に基づいて、CEAEモデルのための言語非依存情報の2つの新規ソースを紹介する。 2つの情報源を使用して、言語間のギャップを埋め、CEAEモデルのクロスリンガルパフォーマンスを向上させるための共有文構造を作成することを提案します。 CEAEのために提案された方法の有効性を実証するために、アラビア語、中国語、および英語を用いた広範な実験が実施されている。', 'zh': '治跨语事参数取(CEAE)。 其旨在占文本中事体提参数角色,文本事语与训练占模形所用语不同。 前CEAE之事已展通用赖树于获跨语句法共其跨语。 特赖树中单词间句法相连为锚点知,为CEAE模则(即图卷积神经网络 - GCN)跨语移学。 本文之中,我们基于异言语中单词对的语义相似性和普靠关系,为CEAE模引入了两种新语言无关信息来源。 请用此二信息源以生共享之句,以弥合言语之间,而增CEAE形之跨语。 因阿拉伯文、中文、英文诸语大实验,验所提CEAE法有效性。', 'ru': 'Изучаем проблему межязыкового извлечения аргументов событий (CEAE). Задача направлена на прогнозирование роли аргументов упоминаний сущностей для событий в тексте, язык которых отличается от языка, на котором была обучена прогностическая модель. Предыдущая работа по CEAE показала межязыковые преимущества универсальных деревьев зависимостей в захвате общих синтаксических структур предложений между языками. В частности, эта работа использует существование синтаксических связей между словами в деревьях зависимостей в качестве якорных знаний для передачи обучения представлению между языками для моделей CEAE (т.е. через граф сверточных нейронных сетей – GCN). В данной работе мы вводим два новых источника языково-независимой информации для моделей CEAE, основанных на семантическом сходстве и универсальных зависимостях пар слов в разных языках. Мы предлагаем использовать два источника информации для создания общих структур предложений, чтобы сократить разрыв между языками и улучшить межъязыковую производительность моделей CEAE. Проводятся обширные эксперименты с арабским, китайским и английским языками, чтобы продемонстрировать эффективность предлагаемого метода для CEAE.', 'hi': 'हम क्रॉस-लिंगुअल इवेंट तर्क निष्कर्षण (CEAE) की समस्या का अध्ययन करते हैं। कार्य का उद्देश्य पाठ में घटनाओं के लिए उल्लेखित इकाई की तर्क भूमिकाओं की भविष्यवाणी करना है, जिसकी भाषा उस भाषा से अलग है जिस पर एक भविष्यवाणी मॉडल को प्रशिक्षित किया गया है। CEAE पर पिछले काम ने भाषाओं में वाक्यों की साझा वाक्यात्मक संरचनाओं को कैप्चर करने में सार्वभौमिक निर्भरता पेड़ों के क्रॉस-लिंगुअल लाभों को दिखाया है। विशेष रूप से, यह काम निर्भरता पेड़ों में शब्दों के बीच वाक्यात्मक कनेक्शन के अस्तित्व का फायदा उठाता है क्योंकि एंकर ज्ञान सीईएई मॉडल के लिए भाषाओं में प्रतिनिधित्व सीखने को स्थानांतरित करने के लिए (यानी, ग्राफ कनवल्शनल न्यूरल नेटवर्क - जीसीएन के माध्यम से)। इस पत्र में, हम विभिन्न भाषाओं में शब्द जोड़े के शब्दार्थ समानता और सार्वभौमिक निर्भरता संबंधों के आधार पर CEAE मॉडल के लिए भाषा-स्वतंत्र जानकारी के दो उपन्यास स्रोतों का परिचय देते हैं। हम भाषाओं के बीच की खाई को पाटने और CEAE मॉडल के क्रॉस-लिंगुअल प्रदर्शन में सुधार करने के लिए साझा वाक्य संरचनाओं का उत्पादन करने के लिए जानकारी के दो स्रोतों का उपयोग करने का प्रस्ताव करते हैं। CEAE के लिए प्रस्तावित विधि की प्रभावशीलता को प्रदर्शित करने के लिए अरबी, चीनी और अंग्रेजी के साथ व्यापक प्रयोग किए जाते हैं।', 'ga': 'Déanaimid staidéar ar an bhfadhb a bhaineann le Sliocht Argóinte Imeachtaí Trasteangacha (CEAE). Tá sé mar aidhm ag an tasc róil argóintí na n-aonán a luaitear le haghaidh imeachtaí i dtéacs a thuar, a bhfuil a dteanga éagsúil leis an teanga ar cuireadh oiliúint ar shamhail thuarthach. Léiríodh in obair roimhe seo ar CEAE na buntáistí tras-teangacha a bhaineann le crainn spleáchais uilíoch ó thaobh struchtúir chomhréireacha roinnte abairtí trasna teangacha a ghabháil. Baineann an saothar seo, go háirithe, leas as na naisc chomhréire idir na focail sna crainn spleáchais mar an t-eolas ancaire chun an fhoghlaim ionadaíochta a aistriú thar theangacha do mhúnlaí CEAE (i.e., trí ghraif líonraí néaracha comhráiteacha – GCNanna). Sa pháipéar seo, tugaimid dhá fhoinse nua faisnéise teanga-neamhspleách isteach do mhúnlaí CEAE bunaithe ar chosúlacht shéimeantach agus ar chaidreamh spleáchais uilíoch na bpéirí focal i dteangacha éagsúla. Tá sé beartaithe againn an dá fhoinse faisnéise a úsáid chun struchtúir abairtí comhroinnte a tháirgeadh chun an bhearna idir teangacha a líonadh agus chun feidhmíocht thrastheangach na samhlacha CEAE a fheabhsú. Déantar turgnaimh fhairsing le Araibis, Sínis, agus Béarla chun éifeachtacht an mhodha atá beartaithe do CEAE a léiriú.', 'ka': 'ჩვენ შევსწავლობთ Cross-lingual Event Argument Extraction (CEAE) პრობლემა. დავალების მიხედვით, რომ ინტერტის პროლის არგუმენტი ტექსტის მოვლენებისთვის განსაზღვრება, რომელიც ენათი განსხვავებულია ენათიდან, რომელიც განსაზღვრებული მოდელის განსაზღვრე CEAE-ზე წინა სამუშაო მუშაო გამოსახულება უნივერსალური დასახულებელი ხელების სამუშაო სინტაქტიური სტრუქტურაციაში გამოყენება ენაში. განსაკუთრებით, ეს სამუშაო გამოიყენება სინტაქტიკური კავშირებების არსებობას, როგორც განსაკუთრებულობაში სიტყვების სიტყვების განმავლობაში, როგორც კონფორის ცოდნა, რომ CEAE მოდელების განმავლობაში გამოსვლა ამ დომენტში ჩვენ CEAE მოდელებისთვის ორი პრომენტიური ინფორმაციის გამოყენება, რომელიც სენმანტიური განსხვავებულობაზე და სენსალური დამხმარებელობაში სიტყვების ზოგების განსხვავებული ენები ჩვენ მუშაობთ გამოიყენოთ ორი ინფორმაციის გამოსახულება, რომ გავამყენოთ სტრუქტურაციის სტრუქტურაციას, რომელიც ენების შორის განსხვავება და CEAE მოდელების მრავალ გაფართლებული ექსპერიმენტები იქნება აპაბიური, ჩინეთიური და ანგლისური გამოყენებული, რომ CEAE-ისთვის მინდა გამოყენება ეფექტიურობა.', 'el': 'Μελετάμε το πρόβλημα της εκχύλισης επιχειρημάτων διασταυρούμενης γλώσσας συμβάντος (ΚΕΑΕ). Η εργασία αποσκοπεί στην πρόβλεψη ρόλων ορίων των αναφορών οντότητας για γεγονότα στο κείμενο, της οποίας η γλώσσα είναι διαφορετική από τη γλώσσα στην οποία έχει εκπαιδευτεί ένα προβλέψιμο μοντέλο. Προηγούμενες εργασίες για την CEAE έχουν δείξει τα γλωσσικά οφέλη των δέντρων καθολικής εξάρτησης στην καταγραφή κοινών συντακτικών δομών των προτάσεων σε διάφορες γλώσσες. Ειδικότερα, η παρούσα εργασία αξιοποιεί την ύπαρξη των συντακτικών συνδέσεων μεταξύ των λέξεων στα δένδρα εξάρτησης ως τη γνώση αγκύρων για να μεταφέρει την εκμάθηση αναπαράστασης σε διάφορες γλώσσες για μοντέλα CEAE (δηλ. μέσω νευρωνικών δικτύων γραφής και GCN). Στην παρούσα εργασία, εισάγουμε δύο νέες πηγές γλωσσικής ανεξάρτητης πληροφορίας για μοντέλα βασισμένες στη σημασιολογική ομοιότητα και τις καθολικές σχέσεις εξάρτησης των ζευγαριών λέξεων σε διαφορετικές γλώσσες. Προτείνουμε να χρησιμοποιήσουμε τις δύο πηγές πληροφοριών για την παραγωγή κοινών δομών προτάσεων για τη γεφύρωση του χάσματος μεταξύ των γλωσσών και τη βελτίωση της γλωσσικής απόδοσης των μοντέλων CEAE. Εκτεταμένα πειράματα διεξάγονται με αραβικά, κινέζικα και αγγλικά για να καταδειχθεί η αποτελεσματικότητα της προτεινόμενης μεθόδου για την CEAE.', 'hu': 'Tanulmányozzuk a Cross-lingual Event Argument Extraction (CEAE) problémáját. A feladat célja, hogy megjósolja az entitás említéseinek argumentum szerepét olyan eseményekre vonatkozóan, amelyek nyelve eltér attól a nyelvtől, amelyre egy prediktív modell képzett. A CEAE-vel kapcsolatos korábbi munkák megmutatták az univerzális függőségi fák nyelveken átnyúló előnyeit a mondatok közös szintaktikus struktúráinak nyelvek közötti rögzítésében. Ez a munka különösen a függőségfákban lévő szavak közötti szintaktikus kapcsolatok létezését használja ki, mint horgony tudást, hogy a reprezentációs tanulást a CEAE modellek számára (pl. gráf konvuluációs neurális hálózatok - GCN-ek) nyelveken keresztül továbbítsa. Jelen tanulmányban két új nyelvfüggetlen információforrást mutatunk be a CEAE modellek szemantikai hasonlóságán és univerzális függőségi viszonyán alapuló szópárok különböző nyelveken. Javasoljuk, hogy a két információforrást használjuk fel közös mondatszerkezetek kialakítására a nyelvek közötti szakadék áthidalására és a CEAE modellek nyelvközi teljesítményének javítására. Széleskörű kísérleteket végeznek arab, kínai és angol nyelven, hogy bizonyítsák a javasolt módszer hatékonyságát a CEAE.', 'it': "Studiamo il problema dell'estrazione di argomenti di eventi multilingue (CEAE). Il compito mira a prevedere i ruoli degli argomenti delle menzioni di entità per eventi nel testo, la cui lingua è diversa da quella su cui è stato addestrato un modello predittivo. I lavori precedenti su CEAE hanno mostrato i vantaggi cross-lingual degli alberi di dipendenza universale nel catturare strutture sintattiche condivise di frasi tra le lingue. In particolare, questo lavoro sfrutta l'esistenza delle connessioni sintattiche tra le parole negli alberi delle dipendenze come conoscenza di ancoraggio per trasferire l'apprendimento della rappresentazione attraverso le lingue per i modelli CEAE (cioè attraverso reti neurali convoluzionali grafiche - GCN). In questo articolo introduciamo due nuove fonti di informazioni indipendenti dal linguaggio per i modelli CEAE basate sulla somiglianza semantica e sulle relazioni di dipendenza universali delle coppie di parole in lingue diverse. Proponiamo di utilizzare le due fonti di informazione per produrre strutture di frase condivise per colmare il divario tra le lingue e migliorare le prestazioni cross-lingual dei modelli CEAE. Ampi esperimenti sono condotti con arabo, cinese e inglese per dimostrare l'efficacia del metodo proposto per CEAE.", 'lt': 'We study the problem of Cross-lingual Event Argument Extraction (CEAE).  Šios užduoties tikslas – numatyti subjekto nurodytų argument ų vaidmenį renginiuose tekste, kurių kalba skiriasi nuo kalbos, kuria mokomas prognozuojamasis model is. Ankstesnis darbas CEAE srityje parodė, kad universalių priklausomybės medžių nauda yra tarpkalbinė, nes jie gauna bendrą sintaksinę skirtingų kalbų sakinių struktūrą. In particular, this work exploits the existence of the syntactic connections between the words in the dependency trees as the anchor knowledge to transfer the representation learning across languages for CEAE models (i.e., via graph convolutional neural networks - GCNs).  Šiame dokumente pristatome du naujus EEAE modelių, grindžiamų semantiniu panašumu ir universaliu žodžių poros priklausomybės santykiu, nepriklausomos nuo kalbos šaltinius. We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  Extensive experiments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE.', 'kk': 'Біз тілдік оқиғалар аргументті тарқату (CEAE) мәселесін зерттейміз. Тапсырма мәтіндегі оқиғалар үшін аргументтің рөлін таңдау үшін, олардың тілі таңдау үлгісінен басқа болады. CEAE- де алдыңғы жұмыс сөздерді тілдерде ортақ синтактикалық құрылымдарды түсіндіру үшін әлемдік тәуелсіздік ағаштардың бірнеше тілдерінің пайдалануларын көрсетті. Әрине, бұл жұмыс CEAE үлгілері үшін таңдау оқыту үшін, тәуелдік ағаштардың сөздерінің синтактикалық қосылымдардың барлығын қолданады (т.е. графикалық невралдық желілер - GCNs арқылы). Бұл қағазда CEAE үлгілерінің екі жаңа тілдері тәуелсіз мәліметті келтіріп, семантикалық ұқсас және сөздердің әлемдік тәуелсіздік қатынасын түрлі тілдерде негізделген. Екі мәліметтің көзі қолдану үшін бөлек сөйлеме құрылымын құру үшін тілдер арасындағы аралығын көшірмелеу және CEAE үлгілерінің бірнеше тілді істеу үшін жұмыс істеу Кеңейтілген тәжірибелер CEAE үшін келтірілген тәжірибенің эффективнігін көрсету үшін араб, қытайлық және ағылшын тілінен істейді.', 'ms': 'Kami mempelajari masalah Ekstraksi Argumen Peristiwa Selasa Bahasa (CEAE). Tugas bermaksud meramalkan peran argumen bagi entiti disebut untuk peristiwa dalam teks, bahasa yang berbeza dari bahasa yang model ramalan telah dilatih padanya. Kerja sebelumnya pada CEAE telah menunjukkan keuntungan saling bahasa pokok dependensi universal dalam menangkap struktur sintaktik berkongsi kalimat melalui bahasa. Terutama, kerja in i mengeksploitasi wujud sambungan sintaktik antara perkataan di pokok dependensi sebagai pengetahuan penyancar untuk memindahkan perkembangan belajar melalui bahasa untuk model CEAE (iaitu melalui rangkaian saraf konvolusi graf - GCNs). Dalam kertas ini, kami memperkenalkan dua sumber baru maklumat bebas bahasa untuk model CEAE berdasarkan persamaan semantik dan hubungan dependensi universal pasangan perkataan dalam bahasa yang berbeza. Kami cadangkan menggunakan dua sumber maklumat untuk menghasilkan struktur kalimat berkongsi untuk memecahkan ruang antara bahasa dan meningkatkan prestasi saling bahasa model CEAE. Eksperimen luas dilakukan dengan bahasa Arab, Cina, dan Inggeris untuk menunjukkan kegunaan kaedah yang diusulkan untuk CEAE.', 'mk': 'Го проучуваме проблемот со екстракцијата на меѓујазичните аргументи за настани (ЦЕА). Оваа задача има за цел предвидување на улогите на аргументите на ентитетите кои ги споменуваат настаните во текстот, чиј јазик е различен од јазикот на кој е обучен предвидлив модел. Претходната работа на ЦЕЕА покажа прекујазични бенефиции од универзалните дрвја на зависност во зафатувањето на заедничките синтактички структури на речениците меѓу јазиците. Посебно, оваа работа го искористува постоењето на синтактичките врски помеѓу зборовите во дрвјата на зависноста како засновачко знаење за пренесување на претставувањето на учењето низ јазиците за моделите на ЦЕА (т.е., преку графички конволуционални нервни мрежи - ГЦН). Во овој весник, воведуваме два нови извори на информации кои се независни од јазикот за моделите на ЦЕЕ базирани на семантичната сличност и универзалните односи на зависност на зборовите парови на различни јазици. Ние предложуваме да се користат двата извори на информации за да се создадат заеднички структури на реченици за преминување на разликата помеѓу јазиците и подобрување на прекујазичните резултати на моделите на ЦЕА. Истензивни експерименти се спроведуваат со арапски, кинески и англиски за да се покаже ефикасноста на предложениот метод за ЦЕЕ.', 'mt': 'Aħna nistudjaw il-problema tal-Estrazzjoni tal-Argument tal-Avvenimenti Translingwi (CEAE). Il-kompitu għandu l-għan li jipprevedi r-rwoli ta’ argument tal-entità li ssemmi għal avvenimenti fit-test, li l-lingwa tagħhom hija differenti mil-lingwa li mudell ta’ tbassir ġie mħarreġ fuqha. Xogħol preċedenti dwar is-CEAE wera l-benefiċċji translingwi tas-siġar tad-dipendenza universali fil-kisba ta’ strutturi sintattiċi kondiviżi tas-sentenzi bejn il-lingwi. B’mod partikolari, dan ix-xogħol jisfrutta l-e żistenza tal-konnessjonijiet sintattiċi bejn il-kliem fis-siġar tad-dipendenza bħala l-għarfien ankrat għat-trasferiment tar-rappreżentanza tat-tagħlim bejn il-lingwi għall-mudelli CEAE (jiġifieri, permezz tan-netwerks newrali konvoluzzjonali tal-graff - GCNs). F’dan id-dokument, aħna nintroduċu żewġ sorsi ġodda ta’ informazzjoni indipendenti mil-lingwa għall-mudelli tas-CEAE bbażati fuq is-similarità semantika u r-relazzjonijiet ta’ dipendenza universali tal-pari tal-kelma f’lingwi differenti. Aħna nipproponu li nużaw iż-żewġ sorsi ta’ informazzjoni biex nipproduċu strutturi ta’ sentenzi kondiviżi biex nilqgħu d-distakk bejn il-lingwi u jtejbu l-prestazzjoni translingwistika tal-mudelli tas-CEAE. Saru esperimenti estensivi bl-Għarab, iċ-Ċiniż u l-Ingliż biex juru l-effettività tal-metodu propost għas-CEAE.', 'ml': 'നമ്മള്\u200d ക്രോസ്-ഭാഷാല്\u200d സംഭവം ആര്\u200dഗമെന്റ് പുറത്താക്കുന്നതിന്റെ പ്രശ്നം പഠിക്കുന്നു. പദാവലിയിലുള്ള സംഭവങ്ങള്\u200dക്കുള്ള വസ്തുക്കളുടെ വിഭാഗങ്ങള്\u200d പ്രവചിപ്പിക്കാനുള്ള ജോലി ലക്ഷ്യമാണ്. അവയുടെ ഭാഷ പ്രവചിക്ക സീഎയിലെ മുമ്പുള്ള പണിയിടം പ്രപഞ്ച ഭാഷകളിലെ ക്രിസ്ലോവില്\u200d ആശ്രയിക്കുന്ന ഉപകരണങ്ങള്\u200d കാണിച്ചിരിക്കുന്നു. ഭാഷകളില്\u200d  പ്രത്യേകിച്ച്, ഈ ജോലി ആശ്രയിച്ച വാക്കുകളുടെ ഇടയിലുള്ള സിനിട്ടാക്കിക്കാരുടെ ബന്ധങ്ങള്\u200d സിയായി മോഡലുകള്\u200dക്ക് വേണ്ടി പഠിക്കുന്നതിന്റെ പ്രതിനിധികള്\u200dക് ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഭാഷയിലെ സ്വാതന്ത്ര്യ വിവരങ്ങളുടെ രണ്ട് നോവല്\u200d സ്രോതസ്സ് വിവരങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. സീയേയിയുടെ മോഡലുകള്\u200dക്ക് സെമ വിവരങ്ങളുടെ രണ്ട് സ്രോതസ്സുകള്\u200d ഉപയോഗിക്കാന്\u200d ഞങ്ങള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. പങ്കെടുത്ത വാക്കുകളുടെ അടിസ്ഥാനങ്ങള്\u200d ഉണ്ടാക്കാന്\u200d വേണ Extensive experiments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE.', 'no': 'Vi studerer problemet med ekstraksjon av krysspråk- hendingar- argument (CEAE). Oppgåva må forhåndsvisa argumentrollar på eininga som mener for hendingar i tekst, kva språk er ulik frå språket som ein foregåve modell er trent på. Førre arbeid på CEAE har vist dei krysspråka fordelene av universelle avhengighetstrær i å henta delte syntaktiske strukturer av setningar på språk. Dette arbeidet bruker spesielt eksisterende syntaktiske tilkoplingar mellom ord i avhengighetstråda som ankoravitenskapen for å overføra representasjonen på språk for CEAE-modeller (t.d. via grafen konvolusjonelle neiralnettverk – GCNs). I denne papiret introduserer vi to novel kjelde av språk-uavhengige informasjon for CEAE-modeller basert på semantiske likhet og den universele avhengighetsrelasjonen av ordpar i ulike språk. Vi foreslår å bruka dei to kjeldene av informasjon for å produsera delte setningsstrukturar for å bryta mellom språk og forbedra den krysspråksfunksjonen av CEAE-modellen. Ekstra eksperimenter gjeld med arabisk, kinesisk og engelsk for å demonstrare effektiviteten av den foreslåtte metoden for CEAE.', 'mn': 'Бид хэл хэлний аргументын аргумент гаргах (CEAE) асуудлыг судалж байна. Үүний зорилго нь бизнесийн аргументын дүр зураг бичсэн үйл явдлын талаар хэлэх, хэл нь таамаглалтын загварын талаар өөр хэлбэртэй. CEAE-ийн өмнөх ажил нь хэлний хэл дээр хуваалцагдсан өгүүлбэрийн шинжлэх ухааны бүтээлүүдийн олон хэлний ашиг үзүүлсэн. Ялангуяа энэ үйл ажиллагаа CEAE загварын хэлбэрээр суралцах суралцааны мэдлэг болон хамааралтай модон хоорондын синтактик холбоотой холбоотой байдлыг ашигладаг. Энэ цаасан дээр бид CEAE загварын тулд хэл дээр хамааралтай мэдээллийн хоёр шинэ эх үүсвэрийг танилцуулдаг. Бид хоёр мэдээллийн эх үүсвэрийг ашиглан хэлний хоорондын ялгааг нэмэгдүүлэх, CEAE загварын олон хэлний үйл ажиллагааг сайжруулахын тулд хуваалцааг өгүүлбэл бүтээгдэхүүний бүтээгдэхүүнийг аш Хятад, Араб, Хятад, Англи хэлбэртэй олон туршилтууд CEAE-ийн төлөөлөгдсөн арга замын үр дүнг үзүүлэхээр ажилладаг.', 'pl': 'Badamy problem Cross-lingual Event Argument Extraction (CEAE). Celem zadania jest przewidywanie ról argumentów wspomnianych jednostek dla zdarzeń w tekście, których język różni się od języka, na którym trenowano model predykcyjny. Poprzednie prace nad CEAE pokazały wielojęzyczne korzyści płynące z uniwersalnych drzew zależności w przechwytywaniu wspólnych struktur składni zdań w różnych językach. W szczególności w niniejszej pracy wykorzystuje istnienie połączeń składniowych między słowami w drzewach zależności jako wiedzę kotwicą do przenoszenia nauki reprezentacyjnej między językami dla modeli CEAE (tj. poprzez wykresowe konwolucyjne sieci neuronowe z GCN). W artykule przedstawiono dwa nowe źródła informacji niezależnych od języka dla modeli CEAE oparte na podobieństwie semantycznym i uniwersalnych zależnościach par słów w różnych językach. Proponujemy wykorzystanie dwóch źródeł informacji do tworzenia wspólnych struktur zdań, aby wypełnić lukę między językami i poprawić wydajność modeli CEAE między językami. Przeprowadzane są obszerne eksperymenty z językiem arabskim, chińskim i angielskim w celu wykazania skuteczności proponowanej metody CEAE.', 'ro': 'Studiem problema Extractiei Argumentelor de Evenimente Interlingve (CEAE). Sarcina își propune să prezică rolurile argumentelor menționate de entitate pentru evenimentele din text, a căror limbă este diferită de limba pe care a fost instruit un model predictiv. Lucrările anterioare privind CEAE au arătat beneficiile translingvistice ale arborilor de dependență universală în captarea structurilor sintactice comune ale propozițiilor în diferite limbi. În special, această lucrare exploatează existența conexiunilor sintactice dintre cuvintele din arborii de dependență ca cunoștințe de ancoră pentru a transfera învățarea reprezentării peste limbi pentru modelele CEAE (adică prin intermediul rețelelor neuronale convoluționale grafice - GCN). În această lucrare, introducem două surse noi de informații independente de limbă pentru modelele CEAE bazate pe similitudinea semantică și relațiile de dependență universale ale perechilor de cuvinte în diferite limbi. Propunem utilizarea celor două surse de informații pentru a produce structuri comune de propoziții pentru a reduce decalajul dintre limbi și pentru a îmbunătăți performanța translingvistică a modelelor CEAE. Experimente ample sunt efectuate cu arabă, chineză și engleză pentru a demonstra eficacitatea metodei propuse pentru CEAE.', 'sr': 'Proučavamo problem izvlačenja kroz jezičke argumenta događaja (CEAE). Taj zadatak je cilj da predvidi uloge argument a entiteta spominje za događaje u tekstu, čiji je jezik drugačiji od jezika na kojem je predviđeni model obučen. Prethodni rad na CEAE pokazao je cross-lingual benefits od univerzalne zavisnosti drveća u hvatanju zajedničkih sintaktičnih struktura rečenica na jezicima. Posebno, ovaj rad iskorištava postojanje sintaktičkih veza između reèi u drveæama zavisnosti kao znanje sidra da prenese učenje predstave na jezicima za modele CEAE (tj. kroz graf konvolucione neuralne mreže - GCNs). U ovom papiru predstavljamo dva novog izvora neovisnih informacija o jezicima za modele CEAE-a na temelju semantičke sličnosti i univerzalne odnose ovisnosti riječi parova na različitim jezicima. Predlažemo da iskoristimo dva izvora informacija kako bi proizveli strukture zajedničke rečenice kako bi prekinuli prazninu između jezika i poboljšali cross-lingual performance modela CEAE-a. Eksperimenti su provedeni arapskim, kineskim i engleskim kako bi pokazali učinkovitost predložene metode CEAE-a.', 'so': 'We study the problem of Cross-lingual Event Argument Extraction (CEAE).  Shaqada waxaa loola jeedaa inuu ka hor dhigo qaybaha ku saabsan waxyaabaha ay ku qoran dhacdooyinka, luuqadiisuna waa mid ka duwan luqada, kaas oo lagu baray tusaale horumar ah. Shaqo hore oo ku saabsan CEAE wuxuu tusay manfacyada luuqadaha kala duwan ee geedaha caalamiga ah oo ku xiran ku saabsan qoraalka isku xiran ee lagu qabsado qalcadaha kala duwan oo luqadaha oo dhan. Si gaar ah, shuqulkaasu wuxuu isticmaalaa xiriirka isku xiran e e hadallada ku xiran geedaha ku xiran sida aqoonta bannaanka si uu u wareejiyo barashada barashada luuqadaha oo dhan ee modellada CEAE (tusaale ahaan shabakado kooxa ah ee naxdinta- GCNs). Qoraalkan waxaan ku soo bandhignaa laba nooc oo warqad ah oo macluumaad xor ah oo afka ku qoran ee CEAE tusaale ahaan isku mid ah iyo xiriirka caalamiga ah ee hadalka labada noocyo oo kala duduwan ku qoran. Waxaynu soo jeedinaynaa in aan isticmaalno labada soul oo macluumaad ah si aan u soo saarno dhismo qayb ah oo lagu qeybeeyay si aan u kala soobixino kala duwan luqadaha iyo hagaajinno sameynta qaababka afka ah ee CEAE. Imtixaano dheeraad ah waxaa lagu sameeyaa Carabi, Shiino iyo Ingiriis si ay u muujiyaan effektada qaabka loo soo jeeday CEAE.', 'sv': 'Vi studerar problemet med Cross-lingual Event Argument Extraction (CEAE). Uppgiften syftar till att förutsäga argumentroller för entitetsomnämningar för händelser i text, vars språk skiljer sig från det språk som en prediktiv modell tränats på. Tidigare arbete med CEAE har visat de tvärspråkliga fördelarna med universella beroendeträd när det gäller att fånga gemensamma syntaktiska strukturer av meningar över språk. Framför allt utnyttjar detta arbete förekomsten av syntaktiska kopplingar mellan orden i beroendeträden som ankarkunskapen för att överföra representationslärandet över språk för CEAE modeller (dvs via grafkonvulutionella neurala nätverk - GCN). I denna uppsats introducerar vi två nya källor till språkoberoende information för CEAE-modeller baserade på semantisk likhet och universella beroendeförhållanden mellan ordparen på olika språk. Vi föreslår att använda de två informationskällorna för att skapa gemensamma meningsstrukturer för att överbrygga klyftan mellan språk och förbättra CEAE-modellernas tvärspråkliga prestanda. Omfattande experiment utförs med arabiska, kinesiska och engelska för att visa effektiviteten av den föreslagna metoden för CEAE.', 'ta': 'We study the problem of Cross-lingual Event Argument Extraction (CEAE).  பணி உரையில் உள்ள நிகழ்வுகளுக்கான உரையில் தருமதிப்பு பங்களை முன்வெளிப்படுத்த வேண்டும், அதன் மொழி மொழியில் இருந்து மாறுபட்டு முந்தைய வேலை CEAE முழுமையான மொழிகளில் பல மொழிகளின் பயன்பாடுகளை பொதுவான சார்பு மரங்களின் சார்ந்த ஒத்திசைவு உருவமைப்புகள குறிப்பிட்டு, சார்ந்த மரங்களில் உள்ள வார்த்தைகளுக்கிடையே ஒத்திசைப்படுத்தல் இணைப்புகள் இருப்பதை இந்த வேலை பயன்படுத்துகிறது சிஏ மாதிரிகளுக்கான மொழிகளில் கற இந்த காகிதத்தில், நாம் மொழி- சுதந்திரமான தகவல் மூலம் இரண்டு புதிய மூலம் CEAE மாதிரிகளுக்கு அறிவிக்கிறோம். பாதிப்பு ஒத்திசையை அடிப்படையில We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  நீண்ட பரிசோதனைகள் சீஐபிற்கான முறையின் விளைவை காட்டுவதற்கு அரேபி, சீனா மற்றும் ஆங்கிலம் செயல்படுத்தப்பட்டுள்ளது.', 'ur': 'ہم کلاس زبان کے مسئلہ کی تحقیق کرتے ہیں۔ اس کام کا ارادہ یہ ہے کہ ایک ٹیکسٹ کے ارادہ رول کی پیش بینی کریں جن کی زبان اس زبان سے مختلف ہے جس پر ایک پیش بینی موڈل تعلیم کی گئی ہے۔ CEAE کے بارے میں پہلے کاروبار نے کلمات کے شریک سینٹکتیک ساختاروں کو زبانوں کے مختلف طریقے سے پکڑ لیا ہے ویسے ہی بات ہے کہ یہ کام سفارش کرتا ہے کہ مضبوطی درختوں کے درمیان کلمات کے درمیان سینٹاکتیک اتصال کی موجود ہے کہ ان کی مضبوطی کو CEAE موڈل کے لئے (یعنی گراف کنvolutional neural networks - GCNs کے ذریعے) سینٹاکتیک اتصال کی جاتی ہے۔ ہم اس کاغذ میں دو نو سورج سے CEAE موڈل کے لئے استعمال کرتے ہیں جو سیمانتیک شباهت اور کلمات جوڑوں کی عمومی اعتبارت کی نسبت مختلف زبانوں میں بنیاد ہے۔ ہم ان دونوں منبعوں کو استعمال کرنے کے لئے پیشنهاد کرتے ہیں کہ زبانوں کے درمیان فاصلہ پیدا کریں اور CEAE موڈلوں کی مختلف زبان کی عملکرد کو بہتر کریں۔ اضافہ آزمائش کی جاتی ہے کہ CEAE کے لئے پیش کیا گیا طریقہ کا اثبات دکھانے کے لئے عربی, چینی اور انگلیسی کے ساتھ کیا جاتا ہے.', 'si': 'අපි ක්\u200dරොස් භාෂාවික සිද්ධ විදියට ප්\u200dරශ්නයක් අධ්\u200dයානය කරනවා (CEAE). මේ වැඩේ අල්ලගත්තේ පාළුවේ සැකසුම් සඳහා සැකසුම් වලින් ප්\u200dරතිකාරයේ ප්\u200dරතිකාරයේ ප්\u200dරතිකාරයේ ප්\u200dරතිකාරය ප්\u200dරතිකා CEAE ගැන කලින් වැඩ පෙන්වන්න පුළුවන් භාෂාවක් වලින් සාමාන්\u200dය විශ්වාස වලින් වලින් සමාන්\u200dය විශ්වාසික සං විශේෂයෙන්, මේ වැඩය ප්\u200dරවේශ කරනවා CEAE මෝඩල් වලට ප්\u200dරවේශ කරනවා කිරීමේ භාෂාවක් සඳහා ප්\u200dරවේශ කරනවා වචන වර්ගයක් අතර අතරික සම්බන්ධතාවක් වලි මේ පත්තරේදී, අපි භාෂාව නිදහස් තොරතුරු දෙකක් ප්\u200dරදේශ කරනවා CEAE මොඩේල් වලට සිමාන්තික සමාන්\u200dයතාවය සහ වෙනස් භාෂාවල් වල ව අපි ප්\u200dරයෝජනය කරනවා තොරතුරු දෙකක් භාවිතා කරන්න කියලා භාෂාවල් අතර විශේෂය සහ CEAE මොඩේල්ස් වලින් භාෂාවල් ප්\u200dර පරීක්ෂණය අරාබික්, චීනි සහ ඉංග්\u200dරීසි සමඟ පරීක්ෂණය කරනවා CEAE වෙනුවෙන් ප්\u200dරයෝජනය කරපු විදියට.', 'vi': 'Chúng tôi nghiên cứu vấn đề về ngôn ngữ chung ví dụ Nhiệm vụ nhằm dự đoán vai trò lập luận của thực thể đề cập đến các sự kiện trong văn bản, ngôn ngữ khác với ngôn ngữ mà mô hình dự đoán đã được đào tạo. Những nghiên cứu trước về CEO đã cho thấy lợi ích ngôn ngữ trải rộng của cây cối bị phụ thuộc chung trong việc bắt các cấu trúc cú pháp chung của câu nói qua ngôn ngữ. Đặc biệt, công việc này khai thác sự tồn tại của các kết nối cấu pháp thuật giữa các từ trong các cây phụ thuộc như là kiến thức neo chuyển sự phân phát học xuyên các ngôn ngữ cho các mô hình của CEO (tức là, qua các mạng lưới dây thần kinh bọc đồ thị - GCNs). Trong tờ giấy này, chúng tôi giới thiệu hai nguồn tin độc lập ngôn ngữ cho các mô hình của CEO dựa trên nét chữ giống nhau và mối quan hệ của từ hai chữ hai trong các ngôn ngữ khác nhau. Chúng tôi đề nghị sử dụng hai nguồn thông tin để tạo ra cấu trúc chia sẻ câu để lấp chỗ trống giữa các ngôn ngữ và cải thiện khả năng ngôn ngữ khác nhau của mô hình CEO. Có nhiều thí nghiệm được tiến hành bằng tiếng Ả Rập, Trung Quốc và Anh để chứng minh hiệu quả của phương pháp yêu cầu cho CEO.', 'uz': "Biz kryss tili hodisa (CEAE) qidirish uchun muammolarni o'rganamiz. Bu vazifa matnning taʼminlovchi modeli o'rganilgan holatning xususiyatlarini koʻrsatish uchun ishlatiladi. Ikkinchi vazifa CEAE tilida bir necha tillar uchun umumiy ishlatuvchi darajadagi imkoniyatlarni ko'rsatish mumkin. In particular, this work exploits the existence of the syntactic connections between the words in the dependency trees as the anchor knowledge to transfer the representation learning across languages for CEAE models (i.e., via graph convolutional neural networks - GCNs).  Bu qogʻozda biz boshqa tillar uchun CEAE modellari uchun ikkita novel manbalarini o'rganamiz, bu so'z ikkita so'zlar o'z ikkita so'zlarining umumiy qo'llari bilan bog'liq munosabati. Biz bu ikkita maʼlumot manbasiga foydalanish uchun bir hil tugmalar tartiblarini yaratishni talab qilamiz. Tillar orasidagi gapirishni ajratish va CEAE modellarining bir necha tillar bajarish imkoniyatini oshirish uchun. Koʻproq tajribalar CEAE uchun qo'llangan usulning effektini ko'rsatish uchun arab, Xitoycha va ingliz tilida bajarildi.", 'bg': 'Проучваме проблема с извличането на аргументи от междуезични събития. Задачата има за цел да прогнозира аргументните роли на споменаването на обекти за събития в текст, чийто език е различен от езика, на който е обучен прогнозиращ модел. Предишна работа по СЕАЕ показа междуезичните ползи от универсалните дървета за зависимост при улавянето на споделени синтактични структури на изречения между езиците. В частност, тази работа експлоатира съществуването на синтактични връзки между думите в дърветата на зависимостта като водещо знание за прехвърляне на изучаването на представяне през езиците за моделите на ЦЕЕ (т.е. чрез графични конволюционни невронни мрежи - ГГН). В настоящата статия представяме два нови източника на езикова независима информация за моделите на СЕАЕ, базирани на семантичната сходство и универсалните зависимости на думичните двойки в различни езици. Предлагаме да се използват двата източника на информация за създаване на общи структури на изречения за преодоляване на пропастта между езиците и подобряване на междуезичното представяне на моделите на ЦИЕ. Провеждат се обширни експерименти с арабски, китайски и английски език, за да се демонстрира ефективността на предложения метод за СЕАЕ.', 'nl': "We bestuderen het probleem van Cross-lingual Event Argument Extraction (CEAE). De taak beoogt argumentrollen van entiteitsvermeldingen te voorspellen voor gebeurtenissen in tekst, waarvan de taal verschilt van de taal waarop een voorspellend model is getraind. Eerder werk over CEAE heeft de meertalige voordelen van universele afhankelijkheidsbomen aangetoond bij het vastleggen van gedeelde syntactische structuren van zinnen in verschillende talen. In het bijzonder exploiteert dit werk het bestaan van syntactische verbindingen tussen de woorden in de afhankelijkheidsbomen als ankerkennis om het representatieleren over talen voor CEAE modellen over te dragen (d.w.z. via grafiekconvolutionele neurale netwerken van GCN's). In dit artikel introduceren we twee nieuwe bronnen van taal-onafhankelijke informatie voor CEAE modellen gebaseerd op de semantische gelijkenis en de universele afhankelijkheidsrelaties van de woordparen in verschillende talen. We stellen voor om de twee informatiebronnen te gebruiken om gemeenschappelijke zinnenstructuren te creëren om de kloof tussen talen te overbruggen en de meertalige prestaties van de CEAE-modellen te verbeteren. Uitgebreide experimenten worden uitgevoerd met Arabisch, Chinees en Engels om de effectiviteit van de voorgestelde methode voor CEAE aan te tonen.", 'da': "Vi studerer problemet med Cross-lingual Event Argument Extraction (CEAE). Opgaven har til formål at forudsige argumentroller for entitetsnævnelser for begivenheder i tekst, hvis sprog er anderledes end det sprog, som en forudsigende model er blevet trænet i. Tidligere arbejde med CEAE har vist de tværsprogede fordele ved universelle afhængighedstræer ved at fange fælles syntaktiske strukturer af sætninger på tværs af sprog. Dette arbejde udnytter især eksistensen af syntaktiske forbindelser mellem ordene i afhængighedstræerne som ankerkendskab til at overføre repræsentationslæring på tværs af sprog for CEAE modeller (dvs. via grafkonvulutionelle neurale netværk - GCN'er). I denne artikel introducerer vi to nye kilder til sproguafhængig information for CEAE modeller baseret på den semantiske lighed og de universelle afhængighedsrelationer mellem ordparrene på forskellige sprog. Vi foreslår at bruge de to informationskilder til at producere fælles sætningsstrukturer for at bygge bro over kløften mellem sprogene og forbedre CEAE-modellernes tværsprogede præstation. Omfattende eksperimenter udføres med arabisk, kinesisk og engelsk for at demonstrere effektiviteten af den foreslåede metode til CEAE.", 'hr': 'Proučavamo problem izvlačenja Argumenta o međujezičkim događajima (CEAE). Cilj zadataka je predviđati uloge argument a entiteta spominje za događaje u tekstu, čiji je jezik različit od jezika na kojem je predviđavajući model obučen. Prethodni rad na CEAE pokazao je cross-jezičke koristi univerzalne drveće zavisnosti u hvatanju zajedničkih sintaktičkih struktura kazne na jezicima. Posebno, ovaj rad iskoristi postojanje sintaktičkih veza između riječi u drveću zavisnosti kao znanje anchora kako bi prebacili učenje predstave na jezika za modele CEAE (tj. kroz graf konvolucione neuralne mreže - GCNs). U ovom papiru predstavljamo dva novog izvora neovisnih jezika informacija za modele CEAE-a na temelju semantičke sličnosti i univerzalne odnose ovisnosti riječi par na različitim jezicima. Predlažemo iskoristiti dva izvora informacija kako bi proizveli strukture zajedničke rečenice kako bi prekinuli prazninu između jezika i poboljšali cross-lingual performance modela CEAE-a. Prošireni eksperimenti su provedeni arapskim, kineskim i engleskim kako bi pokazali učinkovitost predložene metode CEAE-a.', 'id': 'Kami mempelajari masalah ekstraksi Argumen Peristiwa Selasa Bahasa (CEAE). Tugas ini bermaksud untuk memprediksi peran argumen dari entitas menyebutkan peristiwa dalam teks, bahasa yang berbeda dari bahasa yang telah dilatih model prediksi. Pekerjaan sebelumnya pada CEAE telah menunjukkan keuntungan saling bahasa dari pohon tergantung universal dalam menangkap struktur sintaksi berbagi kalimat di seluruh bahasa. In particular, this work exploits the existence of the syntactic connections between the words in the dependency trees as the anchor knowledge to transfer the representation learning across languages for CEAE models (i.e., via graph convolutional neural networks - GCNs).  Dalam kertas ini, kami memperkenalkan dua sumber baru informasi independen bahasa untuk model CEAE berdasarkan persamaan semantis dan hubungan dependensi universal dari pasangan kata dalam bahasa yang berbeda. We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  Eksperimen yang luas dilakukan dengan bahasa Arab, Cina dan Inggris untuk menunjukkan efektivitas metode yang diusulkan untuk CEAE.', 'ko': '우리는 다중 언어 이벤트 논원 추출(CEAE) 문제를 연구한다.이 임무는 텍스트에서 사건 실체가 언급한 논점 역할을 예측하는 데 목적을 둔다. 그 언어는 예측 모델 훈련의 언어와 다르다.앞서 CEAE에 관한 연구에 따르면 유니버설 의존 트리는 크로스 언어 문장을 포획하는 공유 문법 구조에 있어 크로스 언어 장점을 가진다.특히 이 작업은 트리에 의존하는 단어 간의 문법적 연결을 닻지식으로 삼아 CEAE모델의 서로 다른 언어 사이에서 학습을 전달한다(즉, 도권적신경망-GCN을 통해).본고에서 우리는 서로 다른 언어에서 단어가 맞는 의미의 유사성과 보편적인 의존 관계를 바탕으로 CEAE모델에 언어와 무관한 두 가지 새로운 정보원을 소개했다.이 두 가지 정보원을 사용하여 공유된 문장 구조를 만들어 언어 간의 차이를 메우고 CEAE 모델의 다중 언어 성능을 향상시키는 것을 권장합니다.아랍어, 중국어, 영어로 대량의 실험을 진행하여 제시한 방법이 CEAE에 대한 유효성을 증명하였다.', 'de': 'Wir untersuchen das Problem der Cross-lingual Event Argument Extraction (CEAE). Die Aufgabe zielt darauf ab, Argumentrollen von Entitätserwähnungen für Ereignisse im Text vorherzusagen, deren Sprache sich von der Sprache unterscheidet, auf der ein Vorhersagemodell trainiert wurde. Frühere Arbeiten zu CEAE haben gezeigt, welche Vorteile universeller Abhängigkeitsbäume bei der Erfassung gemeinsamer syntaktischer Strukturen von Sätzen in verschiedenen Sprachen haben. Insbesondere nutzt diese Arbeit die Existenz syntaktischer Verbindungen zwischen den Wörtern in den Abhängigkeitsbäumen als Ankerwissen, um das Repräsentationslernen sprachübergreifend für CEAE-Modelle zu übertragen (d.h. über Graphenconvolutionale neuronale Netze mit GCNs). In diesem Beitrag stellen wir zwei neuartige Quellen sprachunabhängiger Informationen für CEAE-Modelle vor, die auf der semantischen Ähnlichkeit und den universellen Abhängigkeitsverhältnissen der Wortpaare in verschiedenen Sprachen basieren. Wir schlagen vor, die beiden Informationsquellen zu nutzen, um gemeinsame Satzstrukturen herzustellen, um die Lücke zwischen den Sprachen zu schließen und die sprachübergreifende Leistung der CEAE-Modelle zu verbessern. Umfangreiche Experimente werden mit Arabisch, Chinesisch und Englisch durchgeführt, um die Wirksamkeit der vorgeschlagenen Methode für CEAE zu demonstrieren.', 'tr': "Biz 횉apraz Diller Taryha Argument A챌makyny흫 (CEAE) meselesini 철wren첵채rik. G철rev 힊u zady흫 mekdepde bolup ge챌첵채n zady흫 arg체m rollerini t채ze etmegini ama챌la첵ar, onu흫 dili 철흫체nden 철흫체nden gelen nusgadan 체첵tge첵채r. CEAE'de 철흫ki i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n s철zleri흫 dillerinde 체첵tge첵채n adamlary흫 baglaryny흫 a흫satlyklaryny alyp bardyr. A첵ratyn bolsa, bu i 힊e CEAE modelleri 체챌in sungatlanmak 체챌in aga챌lary흫 arasyndaky sintaktik bagla첵y힊lary흫 barlygyny ulan첵ar (mesel창 grafik g철rn체힊 n채yral 힊ebekeleri - GCNs) di첵ip g철챌체r첵채r. Bu kagyzda, CEAE nusgalaryny흫 semantik 첵aly g철rn체힊ligine we s철z bi챌imlerini흫 umumiy baglanylyklaryna da힊ary edip otyr첵arys. Biz iki da힊ary informasi첵any흫 첵체z체ni ulanmagy teklip edip, diller arasyny흫 gapysyny k철챌체rmek we CEAE modellerini흫 챌asla힊dyrylyk t채sirini geli힊tirmek 체챌in payla힊yk s철zler strukturlaryny 체retmek 체챌in teklip ed첵채ris. CEAE 체챌in teklip edilen t채sirini g철rkezmek 체챌in arab챌a, hyt we i흫lis챌e suratlar bar.", 'sw': 'Tunafoma tatizo la tukio la kufukuzwa kwa lugha ya Cross (CEAE). Kazi hiyo inakusudia kutabiri jukumu la maudhui ya utambulisho wa matukio kwa maandishi, ambao lugha yake ni tofauti na lugha ambayo muundo wa kutabiri umefundishwa. Kazi iliyopita kwenye CEAE imeonyesha manufaa ya lugha mbalimbali ya miti ya ulimwengu yenye kutegemea kwa kutafuta muundo wa ushirikiano wa sentensi katika lugha mbalimbali. Kwa hakika, kazi hii inatumia uwepo wa muungano wa pamoja kati ya maneno katika miti ya kutegemea kama maarifa ya kigaidi ya kuhamisha kujifunza katika lugha mbalimbali kwa ajili ya mifano ya CEAE (yaani kupitia mitandao ya kijamii ya kiserikali - GCNs). Katika karatasi hii, tunaonyesha vyanzo viwili vya habari huru vya lugha kwa ajili ya mifano ya CEAE inayohusiana na usawa wa kimataifa na mahusiano ya kutegemea maneno ya wanandoa katika lugha tofauti. Tunazipendekeza kutumia vyanzo viwili vya taarifa ili kutengeneza miundombinu ya usambazaji wa hukumu ili kugundua tofauti kati ya lugha na kuboresha utendaji wa mifano ya CEAE. Majaribio mengi yanaendeshwa kwa lugha ya Kiarabu, Kichina na Kiingereza ili kuonyesha ufanisi wa mbinu hiyo ya CEAE.', 'sq': 'Ne studiojmë problemin e nxjerrjes së argumenteve të ngjarjeve ndërgjuhësore (CEAE). Detyra synon të parashikojë rolin e argumentit të njësisë që përmend për ngjarjet në tekst, gjuha e të cilëve është ndryshe nga gjuha në të cilën është trajnuar një model parashikues. Previous work on CEAE has shown the cross-lingual benefits of universal dependency trees in capturing shared syntactic structures of sentences across languages.  Në veçanti, ky punë shfrytëzon ekzistencën e lidhjeve sintaktike midis fjalëve në pemët e varësisë si njohurinë e ankimit për të transferuar përfaqësimin e mësimit nëpërmjet gjuhëve për modelet e CEAE (pra, nëpërmjet rrjeteve nervore konvolutive grafike - GCNs). Në këtë letër, ne paraqesim dy burime të reja të informacionit të pavarur nga gjuha për modelet e CEAE bazuar në ngjashmërinë semantike dhe marrëdhëniet universale të varësisë së fjalëve çifte në gjuhë të ndryshme. We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  Extensive experiments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE.', 'am': 'የቋንቋ-ቋንቋ ጉዳይ አርጉም መውጣትን እናስተምራለን፡፡ ስራው የአካባቢው ቦታዎች በጽሑፍ ውስጥ የሚታወቁ የአካባቢ ቦታዎችን ለመቀበል ይችላል፤ ቋንቋው ከቋንቋው የተለየ ነው፤ የሚታወቀው ሞዴል የተማረ ነው፡፡ የቀድሞው በCEAE ላይ የቋንቋ ቋንቋዎች የዓለማዊ የታመነ ዛፎችን በቋንቋዎች ቋንቋዎች ላይ የተሰናክል የድምፅ ግንኙነትን በመያዝ አሳየ፡፡ በተለይም፣ ይህ ሥራ በተደገመች ዛፎች መካከል ቃላትን የሲንተርካዊ ግንኙነት በመቀላቀል የቋንቋዎችን ማወቅ ለCEAE ሞላት ለመቀላቀል የግንኙነት እውቀት ይፈልጋል፡፡ In this paper, we introduce two novel sources of language-independent information for CEAE models based on the semantic similarity and the universal dependency relations of the word pairs in different languages.  በቋንቋዎች መካከል የልዩነትን ግንኙነት ለመቀነስ እና የቋንቋ-ቋንቋውን የCEAE ዓይነቶች መደበቂያ እንዲያሳድጉ የሁለት የመረጃ ምንጮች ለመጠቀም እናዘጋጅታለን፡፡ የፊደል ፈተናዎች የCEAE ሥርዓት ጥቅም ለማሳየት በዐረብኛ፣ ቻይና እና እንግሊዘኛ ነው፡፡', 'az': "Biz çox dilli olaraq Argument Extraction (CEAE) problemini öyrənirik. Gözəl məlumatın məlumatdakı olaraq yada salmaq məlumatının argument rollərini təmin etmək niyyətində idi. Dili təmin edici modellərin təhsil edildiyi dildən fərqli idi. CEAE'nin əvvəlki işləri dillərdə şəkillərin paylaşılmış sintaktik qurularını tutmaq üçün universel bağımlılıq ağaclarının çox dilli faydalarını göstərdi. Özellikle, bu i şin CEAE modellərinin dillərindən öyrənməsini öyrənmək üçün bağlılıq ağaclarının sözlərinin arasında sintaktik bağlantıların varlığını istifadə edir. Bu kağızda, CEAE modellərinin semantik bənzərinə və dillərin üniversal bağımlılıq əlaqələrinə dayanan iki yeni dil bağımlılıq məlumatının mənbələrini tanıdırıq. Biz iki məlumatın mənbəsini istifadə etməyi təklif edirik ki, dillərin arasındakı boşluqları və CEAE modellerinin çoxlu dillərin performansını yaxşılaşdırmaq üçün paylaşır cümlələr qurulması üçün. CEAE üçün təklif edilmiş metodların etkinliğini göstərmək üçün ərəb, Çin və İngilizce ilə genişliyi təcrübələr edilir.", 'hy': 'Մենք ուսումնասիրում ենք միջլեզվային իրադարձությունների բանավեճի վերացման խնդիրը: Այս խնդիրը նպատակում է կանխատեսել էության բանավեճի դերը տեքստի իրադարձությունների համար, որոնց լեզուն տարբերվում է այն լեզվից, որի վրա կանխատեսողական մոդելը ուսուցանվել է: ԱՄՆ-ի վերաբերյալ նախորդ աշխատանքը ցույց է տալիս, որ համընդհանուր կախվածության ծառերի լեզվային առավելությունները տարբեր լեզվով հանդիսանում են նախադասությունների համայնական սինտակտիկ կառուցվածքներ: Այս աշխատանքը հատկապես օգտագործում է կախվածության ծառերի բառերի միջև գոյություն ունեցող սինտակտիկ կապեր որպես կախվածության գիտելիք, որպեսզի CEAE-ի մոդելների լեզուներում սովորելու ներկայացումը փոխանցվի (այսինքն գծագրի կոնվոլյուցիոնալ նեյրոնալ ցանցերի միջո Այս աշխատանքում մենք ներկայացնում ենք երկու լեզվից անկախ տեղեկատվության երկու նոր աղբյուր CEAE մոդելների համար, հիմնված սեմանտիկ նմանության և տարբեր լեզուներում բառերի զույգերի համընդհանուր կախվածության հարաբերությունների վրա: Մենք առաջարկում ենք օգտագործել տեղեկատվության երկու աղբյուրները, որպեսզի ստեղծենք ընդհանուր նախադասությունների կառուցվածքներ լեզուների միջև տարբերությունը հաղթահարելու և CEAE մոդելների լեզվային հաջողությունը բարելավելու Արաբական, չինական և անգլերենի հետ լայն փորձեր են կատարվում, որպեսզի ապացուցեն CEAE-ի առաջարկած մեթոդի արդյունավետությունը:', 'bn': 'আমরা ক্রস-ভাষার অনুষ্ঠান আর্গামেন্ট বিদেশের সমস্যা গবেষণা করছি। এই কাজের লক্ষ্য হচ্ছে টেক্সটে অনুষ্ঠানের জন্য বস্তুর কথা উল্লেখের ভূমিকা ভবিষ্যদ্বাণী করা, যাদের ভাষা ভাষা ভিন্ন ভাষার থেক Previous work on CEAE has shown the cross-lingual benefits of universal dependency trees in capturing shared syntactic structures of sentences across languages.  বিশেষ করে, এই কাজ নির্ভরশীল গাছগুলোর মধ্যে শব্দগুলোর মধ্যে সিয়াই মডেলের জন্য প্রতিনিধিত্বের প্রতিনিধিত্ব জ্ঞান হিসেবে প্রতিনিধিত্ব শিক্ষা প্রদান করার জন্য এই পত্রিকায় আমরা ভাষা স্বাধীন তথ্যের দুটি উপস্থাপনের সূত্র উপস্থাপন করেছি সিএই মডেলের জন্য সেমেন্টিক সমতা এবং বিভিন্ন ভাষায় শব্দ জোড়ার সার আমরা তথ্যের দুটি উৎস ব্যবহার করার প্রস্তাব দিচ্ছি শেয়ার করা শাস্তি কাঠামো তৈরি করার জন্য ভাষার মধ্যে পার্থক্য তৈরি করার জন্য এবং সিএই মড প্রস্তাবিত পদ্ধতির কার্যক্রম প্রদর্শনের জন্য আরবী, চীন এবং ইংরেজী দ্বারা বিশেষ পরীক্ষা করা হয়েছে।', 'ca': "Estudem el problema de l'extracció d'arguments translingües. The task aims to predict argument roles of entity mentions for events in text, whose language is different from the language that a predictive model has been trained on.  La feina anterior sobre els CEAE ha demostrat els beneficis translingüístics dels arbres de dependencia universal en capturar estructures sinàctiques comunes de frases a través de les llengües. In particular, this work exploits the existence of the syntactic connections between the words in the dependency trees as the anchor knowledge to transfer the representation learning across languages for CEAE models (i.e., via graph convolutional neural networks - GCNs).  In this paper, we introduce two novel sources of language-independent information for CEAE models based on the semantic similarity and the universal dependency relations of the word pairs in different languages.  We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  Es fan extensos experiments amb àrab, xinès i anglès per demostrar l'eficacia del mètode proposat per a CEAE.", 'cs': 'Studujeme problém extrakce argumentů mezi jazyky (CEAE). Úloha si klade za cíl předpovědět argumentové role zmínek entit pro události v textu, jejichž jazyk se liší od jazyka, na kterém byl prediktivní model trénován. Předchozí práce na CEAE ukázaly výhody univerzálních závislostních stromů v zachycení sdílených syntaktických struktur vět napříč jazyky. Tato práce zejména využívá existence syntaktických spojení mezi slovy v závislostních stromech jako kotevní znalosti pro přenos reprezentačního učení napříč jazyky pro CEAE modely (tj. prostřednictvím grafových konvolučních neuronových sítí s GCN). V tomto článku představujeme dva nové zdroje jazykově nezávislých informací pro CEAE modely založené na sémantické podobnosti a univerzálních závislostních vztazích slovních párů v různých jazycích. Navrhujeme využít dva zdroje informací k vytvoření sdílených větových struktur, které překlenují mezeru mezi jazyky a zlepšují výkonnost modelů CEAE mezi jazyky. Pro demonstraci účinnosti navrhované metody CEAE jsou provedeny rozsáhlé experimenty s arabštinou, čínštinou a angličtinou.', 'et': 'Uurime keeleülese sündmuste argumentide ekstraktsiooni (CEAE) probleemi. Ülesande eesmärk on ennustada olemi märkide argumentirolle sündmuste puhul tekstis, mille keel erineb keelest, mida ennustav mudel on koolitatud. Varasemad tööd CEAE-ga on näidanud universaalse sõltuvuse puude keeleülest kasu lausete ühiste süntaktiliste struktuuride jäädvustamisel eri keeltes. Eelkõige kasutatakse käesolevas töös süntaktiliste seoste olemasolu sõltuvuspuudes olevate sõnade vahel kui ankruteadmisi, et edastada esindusõppe keelte vahel CEAE mudelite jaoks (st graafiliste konvolutsioonivõrkude kaudu – GCN). Käesolevas töös tutvustame CEAE mudelitele kahte uut keelesõltumatu informatsiooni allikat, mis põhinevad semantilisel sarnasusel ja erinevate keelte universaalsetel sõltuvussuhetel. Me teeme ettepaneku kasutada kahte teabeallikat ühiste lausestruktuuride loomiseks, et ületada keeltevaheline lõhe ja parandada CEAE mudelite keeleülest toimimist. Põhjalikud eksperimendid viiakse läbi araabia, hiina ja inglise keelega, et tõestada kavandatud meetodi tõhusust CEAE jaoks.', 'fi': 'Tutkimme Cross-Language Event Argument Extraction (CEAE) -ongelmaa. Tehtävän tavoitteena on ennustaa entiteettimainintojen argumenttirooleja tekstissä tapahtumille, joiden kieli eroaa siitä kielestä, jota ennustava malli on koulutettu. Aiemmat CEAE-tutkimukset ovat osoittaneet universaalisten riippuvuuspuiden monikieliset edut lauseiden yhteisten syntaktisten rakenteiden kuvaamisessa eri kielillä. Tässä työssä hyödynnetään erityisesti riippuvuuspuiden sanojen syntaktisten yhteyksien olemassaoloa ankkuritietona, joka siirtää representaatiooppimista eri kielille CEAE-malleille (eli graafisten konvolutionaalisten neuroverkkojen kautta - GCN). Tässä työssä esitellään kaksi uutta kielestä riippumatonta tietolähdettä CEAE-malleille, jotka perustuvat eri kielien sanaparien semanttiseen samankaltaisuuteen ja yleismaailmallisiin riippuvuussuhteisiin. Ehdotamme näiden kahden tietolähteen käyttöä yhteisten lauserakenteiden tuottamiseen kielten välisen kuilun kuromiseksi umpeen ja CEAE-mallien monikielisen suorituskyvyn parantamiseksi. Laajat kokeet tehdään arabian, kiinan ja englannin kielellä, jotta voidaan osoittaa ehdotetun menetelmän tehokkuus CEAE:lle.', 'bs': 'Proučavamo problem izvlačenja Argumenta o kroz jezičkim događajima (CEAE). Taj zadatak je cilj predvidjeti uloge argument a entiteta spominje za događaje u tekstu, čiji je jezik različit od jezika na kojem je predviđavajući model obučen. Prethodni rad na CEAE pokazao je cross-lingual benefits od univerzalne zavisnosti drveća u hvatanju zajedničkih sintaktičnih struktura kazne na jezicima. Posebno, ovaj rad iskoristi postojanje sintaktičkih veza između riječi u drveću zavisnosti kao znanje sidra za prenošenje učenja predstave na jezicima za modele CEAE (tj. kroz graf konvolucione neuralne mreže - GCNs). U ovom papiru predstavljamo dva novog izvora neovisnih informacija o jezicima za modele CEAE-a na temelju semantičke sličnosti i univerzalne odnose ovisnosti riječi par na različitim jezicima. Predlažemo da iskoristimo dva izvora informacija kako bi proizveli strukture zajedničke rečenice kako bi prekinuli prazninu između jezika i poboljšali cross-lingual performance modela CEAE-a. Eksperimenti su provedeni s arapskim, kineskim i engleskim kako bi pokazali učinkovitost predložene metode CEAE-a.', 'fa': 'ما مشکل خارج کردن آرمونت اتفاق\u200cهای متوسط زبان (CEAE) را مطالعه می\u200cکنیم. این وظیفه هدف است که نقش\u200cهای ارائه\u200cای از عنوان برای اتفاقات در متن را پیش\u200cبینی کند، که زبانش از زبانی متفاوت است که یک مدل پیش\u200cبینی بر آن آموزش داده شده است. کارهای قبلی روی CEAE، سودهای متوسط زبانی از درختان بستگی جهانی را نشان داده است که در دستگیر ساختارهای سنتاکتیک مشترک جمله\u200cها از جمله\u200cهای زبان مشترک است. مخصوصاً این کار موجود ارتباطات سنتاکتیک بین کلمات در درختان بستگی به عنوان دانش آهنگ آهنگ برای تغییر دادن نمایش یادگیری در زبانها برای مدل CEAE (یعنی از طریق شبکه\u200cهای عصبی معمولی - GCNs) استفاده می\u200cکند. در این کاغذ، ما دو منبع رمانی از اطلاعات مستقل به زبان برای مدل CEAE را معرفی می کنیم که بر اساس شبیه\u200cهای semantic و رابطه\u200cهای بستگی جهانی جفت کلمه در زبان\u200cهای مختلف است. ما پیشنهاد می\u200cکنیم از دو منبع اطلاعات استفاده کنیم تا ساختار جمله\u200cهای مشترک را تولید کنیم تا فاصله بین زبانها را برابر کند و عملکرد متوسط زبان مدل CEAE را بهبود دهیم. آزمایش\u200cهای گسترده\u200cای با عربی، چینی و انگلیسی انجام می\u200cشود تا نشان دهند فعالیت روش پیشنهاد CEAE.', 'af': "Ons leer die probleem van die Kruislinglike Gebeurtenis Argument Extraction (CEAE). Die taak bepaal om argument roles van entiteite te voorskou vir gebeurtenis in teks, wie se taal is anders van die taal wat 'n voorskou model is onderwerp op. Vorige werk op CEAE het die kruistale voordele van universele afhanklikheidsboom vertoon in die opvang van gedeelde sintaktieke strukture van setnings oor tale. Hierdie werk uitgebruik die eksistensie van die sintaktieke verbindings tussen die woorde in die afhanklikheidsboom as die anker kennis om die voorstelling leer oor tale vir CEAE-modele te oordra (i.e. deur graaf konvolusionele neuralnetwerke - GCNs). In hierdie papier, introduseer ons twee nuwe bronne van taal-afhanklike inligting vir CEAE-modele wat gebaseer is op die semantiese gelykenis en die universele afhanklikheidverhouding van die woorde paar in verskillende tale. Ons voorstel om die twee bronne van inligting te gebruik om gedeelde setstructure te produseer om die spasie tussen tale te brui en die kruistale prestasie van die CEAE-modeller te verbeter. Ekstensiewe eksperimente word met Arabiese, Sjinese en Engels gedoen om die effektiviteit van die voorgestelde metode vir CEAE te wys.", 'he': 'אנחנו לומדים את הבעיה של חטיפת האירועים בין שפתיים. המשימה מתכוונת לחזות תפקידי טיעון של יחידות מזכירות לאירועים בטקסט, שפה שלהם שונה מהשפה שמודל צפוי הואמן עליה. העבודה הקודמת על CEAE הראה את היתרונות בין שפתיים של עצי תלויות אוניברסליים בכך שיתפסו מבנים סינטקטיים משותפים של משפטים ברחבי שפות. במיוחד, העבודה הזו מנצלת את קיומו של הקשר הסינטקטי בין המילים בעצי ההתמודדות כידע העגור כדי להעביר את היציגה ללמוד דרך שפות למודלים CEAE (כלומר, דרך רשתות עצביות משתנות גרף - GCNs). בעיתון הזה, אנו מכירים שני מקורות חדשים של מידע עצמאי לשפה למודלים של CEAE מבוססים על הדמיון הסמנטי והיחסי ההתלויות האוניברסליים של זוגות המילים בשפות שונות. We propose to use the two sources of information to produce shared sentence structures to bridge the gap between languages and improve the cross-lingual performance of the CEAE models.  ניסויים רחבים מבצעים עם ערבי, סיני ואנגלית כדי להוכיח את היעילות של השיטה המוצעת עבור CEAE.', 'ha': "Munã karanta matsalar al'amarin Kashi-Lugha (CEAU). Kayan aikin ya yi kuskure bayani'ar jãyayya masu sunayen abuni wa masu cikin matsayin, wanda harshensa yana da sãɓãni daga harshen da aka sanar da wani motsi na bayani a kan shi. Previous work on CEAE has shown the cross-lingual benefits of universal dependency trees in capturing shared syntactic structures of sentences across languages.  A cikin ƙayyade, wannan aikin yana amfani da the presence of the syntactic links between words in itãce-deposite as the ilmi of anchorer to transfer the learning of Reposition throughout languages for misãlai-CEAU (misali, through graph-integrated neural Networks - GCNs). A cikin wannan takardan, Munã ƙara wa sourcen biyu na noveli na maganar da ba'a huru ba ga misãlai na CEAU, a kan daidaita da kuma da universal dependanci na maganar biyu cikin lugha daban. Munã kwaɗayin mu yi amfani da sourcen biyu na lãbãri dõmin ka sami tsarin da aka yi rabawa da shi dõmin ya sami gaɓanci tsakanin harshe da kuma ka gyara aikin misalin na CEAU. Ana tafiyar jarrabo masu yawa da aka yi Larabci, China da Ingiriya dõmin su nuna aikin hanyarsa na da aka buƙata wa CEAU.", 'sk': 'Proučujemo problem medjezičnega izvlečevanja argumentov dogodkov (CEAE). Cilj naloge je napovedati argumentne vloge omembe entitet za dogodke v besedilu, katerih jezik se razlikuje od jezika, na katerem je bil usposobljen napovedni model. Predhodno delo o CEAE je pokazalo večjezične koristi dreves univerzalne odvisnosti pri zajemanju skupnih sintaktičnih struktur stavkov v različnih jezikih. To delo zlasti izkorišča obstoj sintaktičnih povezav med besedami v drevesih odvisnosti kot sidrno znanje za prenos učenja reprezentacije prek jezikovnih modelov CEAE (tj. prek grafskih konvolucijskih nevronskih omrežij – GCN). V prispevku predstavljamo dva nova vira jezikovno neodvisnih informacij za modele CEAE, ki temeljijo na semantični podobnosti in univerzalnih odvisnostih besednih parov v različnih jezikih. Predlagamo uporabo obeh virov informacij za izdelavo skupnih stavkov za premostitev vrzeli med jeziki in izboljšanje medjezične učinkovitosti modelov CEAE. Izvedeni so obsežni poskusi z arabščino, kitajščino in angleščino, da bi dokazali učinkovitost predlagane metode za CEAE.', 'jv': "Awakdhéwé Iwurung perbudhakan kanggo Ketokaké akèh 'Progress argument extract' (CAE). task Awak dhéwé éntuk karo CeAE wis ngerasakno akeh bantuan karo perusahaan ning nguasakno universel Genjer-Genjer Nang peurén iki, kita mulai perbudhakan duruh pawang nggawe informasi luwih-perbudhakan kanggo model CeAE sing basa karo semanti karo perbudhakan universel karo perbudhakan langa sampek. Awak dhéwé nggunakake sistem durung informasi kanggo nggawe aturan tambah nggawe ngubah tarjamahan karo nggawe barang langgar sampek karo akeh bantuan sistem sing model CeAE Wang dhéwé éntuk sing berarti karo Perusahaan arab, Cinan lan Inggris kanggo ngomongkan Effect kanggo ngerasakno tambah nggawe CeAE.", 'bo': 'ང་ཚོས་ཤེས་དུ་Cross-lingual Event Argument Extraction(CEAE)ཡི་དཀའ་ངལ་བསམ་བྱེད་ཀྱི་དཀའ་ངལ་བསམ་བློ་གཏོང་། The task aims to predict argument roles of entity mentions for events in text, whose language is different from the language that a predictive model has been trained on. CEAE ལ་སྔོན་གྱི་ལས་ཚོགས་སྔོན་གྱི་དོན་ལྟའི་ནང་དུ་སྤྱི་ཚོགས་སྐྱེས་པའི་རྩིས་ཐོག་ཏུ་མངོན་འཆར་བྱེད་པའི་རྩིས་ཐོག་ལས་ དམིགས་བསལ་ནི། འདིས་རྟེན་འབྲེལ་གྱི་ཤོག་བྱང་ལས་སྦྲེལ་མཐུད་དང་མཉམ་དུ་སྦྲེལ་མཐུད་འདི་ལག་ལེན་འཐབ་པ་ལས་་སྦྲེལ་མཐུད་དང་མཉམ་དུ་སྔོན་པ་(དཔེར་ན། དབྱིབས་ ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྐད་ཡིག ང་ཚོས་སྐད་ཡིག་ཆ་དབར་གྱི་བར་སྟོང་དང་། CEAE མིག་དཔེ་དབྱིབས་ཀྱི་མཐུན་འགྱུར་བར་གྱི་འབྱུང་རིམ་གཉིས་བེད་སྤྱོད་དགོས་པ་ལྟར། དམིགས་བསལ་གྱི་སྒེར་ཞིག་བྱེད་རྒྱུ་དང་། ཨིན་རིའི་བྱ་ཚིག་དང་ ཨིན་རིའི་བྱ་ཚིག་གིས་སྔོན་འཆར་བྱས་པའི་ཐབས་ལམ'}
{'en': 'BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification', 'ar': 'نموذج متعدد المهام قائم على BERT للغة العربية الفصحى على مستوى الدولة والمقاطعة والتعرف على اللهجات العربية', 'pt': 'Modelo multitarefa baseado em BERT para MSA em nível de país e província e identificação árabe dialetal', 'es': 'Modelo multitarea basado en BERT para identificación de MSA y árabe dialectal a nivel de país y provincia', 'fr': "Modèle multitâche basé sur BERT pour le MSA au niveau du pays et de la province et l'identification arabe dialectale", 'ja': '国と都道府県レベルのMSAと方言アラビア語識別のためのBERTベースのマルチタスクモデル', 'zh': '盖BERT之多任务模形,施于国省级MSA方言阿拉伯语识', 'ru': 'Многозадачная модель на основе BERT для СУО на уровне страны и провинции и диалектической арабской идентификации', 'hi': 'BERT-आधारित बहु-कार्य मॉडल देश और प्रांत स्तर MSA और बोलचाल अरबी पहचान के लिए', 'ga': 'Samhail IlTasc bunaithe ar BERT le haghaidh MSA Leibhéal Tíre agus Cúige agus Sainaithint Araibis Chanúnach', 'ka': 'BERT- დაბათი მრავალ დავალების მოდელი ქვეყანის და პროვინციის MSA და დიალექტური არაბული იდენტიფიკაციისთვის', 'hu': 'BERT-alapú többfeladatos modell ország- és tartományszintű MSA és dialektikus arab azonosító számára', 'el': 'Με βάση το BERT μοντέλο πολλαπλών εργασιών για το επίπεδο MSA σε επίπεδο χώρας και επαρχίας και διαλεκτική αραβική αναγνώριση', 'it': 'Modello multi-task basato su BERT per MSA a livello nazionale e provinciale e identificazione dialettica araba', 'kk': 'BERT- негіздеген ел мен өлке деңгейі MSA және диалектикалық араб идентификациясы үшін көптеген тапсырмалар үлгісі', 'ms': 'Model Tugas Berberasaskan-BERT untuk Aras Negara dan Provinsi MSA dan Identifikasi Arab Dialektik', 'mk': 'Мултизадачен модел со седиште на BERT за ниво на земја и провинција MSA и дијалектална арапска идентификација', 'mt': 'BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification', 'mn': 'BERT-д суурилсан олон-үйл ажиллагааны загвар MSA болон Dialectal Arabic Identification', 'pl': 'Model wielozadaniowy oparty na BERT dla MSA na poziomie kraju i prowincji oraz dialektalnej identyfikacji arabskiej', 'lt': 'BERT grindžiamas daugiafunkcinis šalies ir provincijos lygmens MSA ir dialektinio arabų identifikavimo modelis', 'ml': 'ബെര്\u200dട്ടി അടിസ്ഥാനമാക്കിയ രാജ്യത്തിനും പ്രദേശം നില എസ്എംഎം, ഡയലക്ട്രല്\u200d അറബി തിരിച്ചറിയുന്നതിനുമായി പല', 'sr': 'BERT-bazirani model multi-task za nivo zemlje i provincije MSA i dijalektičku arapsku identifikaciju', 'ro': 'Model multifuncțional bazat pe BERT pentru MSA la nivel de țară și provincie și identificare dialectă arabă', 'sv': 'BERT-baserad flerfunktionsmodell för MSA och dialektisk arabisk identifiering på land- och provinsnivå', 'no': 'BERT-basert fleire oppgåver- modell for landnivå og provinsenivå MSA og dialektisk arabisk identifikasjon', 'ta': 'Name', 'si': 'BERT- අධාරිත ගොඩක් වැඩි වැඩි වැඩි වැඩක් මොඩල්', 'so': 'BERT-based Model of Multi-Tax for Country and Province Level MSA and Dialectal Identification Carabi', 'ur': 'BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification', 'vi': 'Mô hình tổ chức đa tác vụ BERT cho đất nước và đất nước cùng cấp chán và tự xưng tiếng Ả Rập', 'uz': 'Name', 'bg': 'Базиран на BERT многофункционален модел за MSA на ниво държава и провинция и диалектална арабска идентификация', 'hr': 'Model multizadataka na BERT-u za razinu zemlje i provincije MSA i dijalektičku arapsku identifikaciju', 'da': 'BERT-baseret Multi-Task Model for MSA og dialektisk arabisk identifikation på land- og provinsniveau', 'nl': 'BERT-gebaseerd multitask model voor land- en provincieniveau MSA en dialectische Arabische identificatie', 'de': 'BERT-basiertes Multi-Task-Modell für Länder- und Provinzebene MSA und dialektale arabische Identifikation', 'id': 'Berdasarkan BERT Multi-Task Model untuk Level Negara dan Provinsi MSA dan Identifikasi Arab Dialektik', 'ko': 'BERT 기반 국가 및 성급 MSA 멀티태스킹 모델 및 아랍어 사투리 식별', 'fa': 'Model Multi Task based BERT for Country and Province Level MSA and Dialectal Arabic Identification', 'sw': 'Mradi wa kazi nyingi yenye msingi wa BERT kwa ajili ya Taifa na Mkuu MSA na Utambulisho wa Kiarabu wa Kiarabu', 'tr': 'BERT tabanly Ýurt we welaýaty derejesi MSA we Dialektik Arapça Kimligi', 'af': 'BERT-gebaseerde Multi-Task Model vir Land en Provinsie Vlak MSA en Dialectal Arabiese Identifikasie', 'sq': 'Model me shumëdetyrë bazuar në BERT për nivelin e vendit dhe provincës MSA dhe identifikimin dialektal arab', 'am': 'BERT-based Multi-Task Model for Country and Province ደረጃዎች MSA and Dialectal Arabic Identification', 'hy': 'BER-ի հիմնված բազմախնդիրների մոդելը երկրի և նահանգության մակարդակի MSA և դիալեկտալ արաբական ինքնության համար', 'az': 'BERT-tabanl캼 칖lk톛 v톛 칖niversitesi S톛viyy톛si MSA v톛 Dialektik Arap칞a Kimlik Modeli', 'bn': 'দেশ এবং প্রদেশের স্তর এমএসএ এবং ডায়ালেক্টাল আরবী পরিচয়ের জন্য বেরেট ভিত্তিক বহুবার কাজ মডেল', 'bs': 'BERT-bazirani model multi-task za nivo zemlje i provincije MSA i dijalektičku arapsku identifikaciju', 'ca': 'Model multitasca basat en BERT per a nivell nacional i provincial MSA i identificació àrab dialectal', 'cs': 'Víceúkolový model založený na BERT pro MSA na úrovni zemí a provincie a dialektální arabskou identifikaci', 'et': 'BERT-põhine mitmeülesandemudel riigi ja provintsi tasandil MSA ja dialektuaalne araabia identifitseerimine', 'fi': 'BERT-pohjainen monitehtävämalli maa- ja maakuntatason MSA:lle ja dialektiiviselle arabialaiselle tunnistukselle', 'jv': 'BERT-basa Multi-task model kanggo Kemerdekaan lan Gambar Neri', 'he': 'מודל משימות רבות מבוסס על BERT עבור רמת המדינה והמחוזה MSA ו זיהוי ערבי דיאלקטי', 'sk': 'Večopravilni model BERT za MSA na ravni držav in provinc ter dialektno arabsko identifikacijo', 'bo': 'BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification', 'ha': 'KCharselect unicode block name'}
{'en': 'Dialect and standard language identification are crucial tasks for many Arabic natural language processing applications. In this paper, we present our deep learning-based system, submitted to the second NADI shared task for country-level and province-level identification of Modern Standard Arabic (MSA) and Dialectal Arabic (DA). The system is based on an end-to-end deep Multi-Task Learning (MTL) model to tackle both country-level and province-level MSA / DA identification. The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers. Our key idea is to leverage both the task-discriminative and the inter-task shared features for country and province MSA / DA identification. The obtained results show that our MTL model outperforms single-task models on most subtasks.', 'ar': 'يعتبر تحديد اللهجة واللغة القياسية من المهام الحاسمة للعديد من تطبيقات معالجة اللغة العربية الطبيعية. في هذه الورقة ، نقدم نظامنا القائم على التعلم العميق ، والذي تم تقديمه إلى مهمة NADI المشتركة الثانية لتحديد مستوى اللغة العربية الفصحى الحديثة (MSA) واللهجة العربية (DA) على مستوى الدولة وعلى مستوى المقاطعة. يعتمد النظام على نموذج التعلم متعدد المهام العميق الشامل (MTL) لمعالجة تحديد MSA / DA على مستوى الدولة وعلى مستوى المقاطعة. يتكون نموذج MTL الأخير من مشفر مشترك لمحولات تمثيل التشفير ثنائية الاتجاه (BERT) ، وطبقتان من طبقات الانتباه الخاصة بالمهمة ، واثنين من المصنفات. تتمثل فكرتنا الأساسية في الاستفادة من كل من الميزات التمييزية للمهام والميزات المشتركة بين المهام لتحديد البلد والمقاطعة MSA / DA. تظهر النتائج التي تم الحصول عليها أن نموذج MTL الخاص بنا يتفوق على نماذج المهام الفردية في معظم المهام الفرعية.', 'pt': 'A identificação do dialeto e do idioma padrão são tarefas cruciais para muitos aplicativos de processamento de idioma natural árabe. Neste artigo, apresentamos nosso sistema baseado em aprendizado profundo, submetido à segunda tarefa compartilhada do NADI para identificação em nível de país e província de árabe moderno padrão (MSA) e árabe dialetal (DA). O sistema é baseado em um modelo de aprendizagem multitarefa profunda (MTL) de ponta a ponta para lidar com a identificação MSA/DA em nível de país e província. O último modelo MTL consiste em um codificador compartilhado de Transformadores de Representação de Codificador Bidirecional (BERT), duas camadas de atenção específicas para tarefas e dois classificadores. Nossa ideia principal é alavancar os recursos de discriminação de tarefas e compartilhados entre tarefas para a identificação MSA/DA do país e da província. Os resultados obtidos mostram que nosso modelo MTL supera os modelos de tarefa única na maioria das subtarefas.', 'es': 'La identificación de dialectos y idiomas estándar son tareas cruciales para muchas aplicaciones de procesamiento de lenguaje natural árabe. En este artículo, presentamos nuestro sistema basado en el aprendizaje profundo, presentado a la segunda tarea compartida de NADI para la identificación a nivel nacional y provincial del árabe estándar moderno (MSA) y el árabe dialectal (DA). El sistema se basa en un modelo de aprendizaje multitarea (MTL) profundo de extremo a extremo para abordar la identificación de MSA/DA tanto a nivel nacional como provincial. El último modelo MTL consiste en un codificador Bidirectional Encoder Representation Transformers (BERT) compartido, dos capas de atención específicas de la tarea y dos clasificadores. Nuestra idea clave es aprovechar tanto las características discriminatorias de tareas como las compartidas entre tareas para la identificación de MSA/DA de país y provincia. Los resultados obtenidos muestran que nuestro modelo MTL supera a los modelos de una sola tarea en la mayoría de las subtareas.', 'fr': "L'identification du dialecte et de la langue standard sont des tâches cruciales pour de nombreuses applications de traitement du langage naturel arabe. Dans cet article, nous présentons notre système basé sur l'apprentissage profond, soumis à la deuxième tâche partagée NADI pour l'identification au niveau des pays et des provinces de l'arabe standard moderne (MSA) et de l'arabe dialectal (DA). Le système est basé sur un modèle d'apprentissage multitâche (MTL) approfondi de bout en bout pour traiter l'identification MSA/DA au niveau des pays et des provinces. Ce dernier modèle MTL se compose d'un codeur BERT (Bidirectional Encoder Representation Transformers) partagé, de deux couches d'attention spécifiques aux tâches et de deux classificateurs. Notre idée clé est de tirer parti à la fois des fonctionnalités discriminantes et des fonctionnalités partagées entre les tâches pour l'identification MSA/DA de pays et de province. Les résultats obtenus montrent que notre modèle MTL surpasse les modèles à tâche unique pour la plupart des sous-tâches.", 'ja': '方言と標準言語の識別は、多くのアラビア語の自然言語処理アプリケーションにとって重要なタスクです。この論文では、現代標準アラビア語（ MSA ）と方言アラビア語（ DA ）の国レベルおよび州レベルの識別のために、第2のNADI共有タスクに提出された深層学習ベースのシステムを紹介します。このシステムは、エンドツーエンドのDEEPマルチタスクラーニング（ MTL ）モデルに基づいており、国レベルと州レベルのMSA/DA識別の両方に取り組んでいます。後者のMTLモデルは、共有双方向エンコーダ表現トランスフォーマー（ BERT ）エンコーダ、2つのタスク固有の注意レイヤー、および2つの分類子で構成されています。当社の主要なアイデアは、タスク区別機能とタスク間共有機能の両方を利用して、国と都道府県のMSA/DA識別を行うことです。得られた結果は、MTLモデルがほとんどのサブタスクでシングルタスクモデルよりも優れていることを示しています。', 'hi': 'बोली और मानक भाषा की पहचान कई अरबी प्राकृतिक भाषा प्रसंस्करण अनुप्रयोगों के लिए महत्वपूर्ण कार्य हैं। इस पेपर में, हम अपनी गहरी शिक्षा-आधारित प्रणाली प्रस्तुत करते हैं, जो आधुनिक मानक अरबी (एमएसए) और डायलेक्टल अरबी (डीए) की देश-स्तरीय और प्रांत-स्तरीय पहचान के लिए दूसरे नाडीआई साझा कार्य के लिए प्रस्तुत की गई है। यह प्रणाली देश-स्तर और प्रांत-स्तरीय एमएसए / डीए पहचान दोनों से निपटने के लिए एक एंड-टू-एंड डीप मल्टी-टास्क लर्निंग (एमटीएल) मॉडल पर आधारित है। उत्तरार्द्ध एमटीएल मॉडल में एक साझा द्विदिश एन्कोडर प्रतिनिधित्व ट्रांसफॉर्मर (BERT) एनकोडर, दो कार्य-विशिष्ट ध्यान परतें और दो क्लासिफायर शामिल हैं। हमारा प्रमुख विचार देश और प्रांत एमएसए / डीए पहचान के लिए कार्य-भेदभावपूर्ण और अंतर-कार्य साझा सुविधाओं दोनों का लाभ उठाना है। प्राप्त परिणामों से पता चलता है कि हमारा एमटीएल मॉडल अधिकांश उप-कार्यों पर एकल-कार्य मॉडल से बेहतर प्रदर्शन करता है।', 'zh': '方言准言,多阿拉伯语自然语言应用程序之要务也。 本文,我们介了深度学习的系统,该系统提交给第二NADI共享职务,用于现代准阿拉伯语(MSA)和方言阿拉伯语(DA)的国家级和省级识别。 统端到端深多任务学(MTL)模形,以决国家级省级MSA / DA。 后 MTL 共双向编码器转换器 (BERT) 编码器、二特定于事者,与二器为之。 凡我大要,以职分职,以知国省MSA / DA。 结果表明,吾MTL多优于任。', 'ru': 'Диалект и стандартная идентификация языка являются важнейшими задачами для многих приложений обработки арабского естественного языка. В этом документе мы представляем нашу систему глубокого обучения, представленную для второй совместной задачи НАДИ по определению на страновом и провинциальном уровнях современного стандартного арабского языка (MSA) и диалектного арабского языка (DA). Система основана на сквозной модели глубокого многозадачного обучения (MTL) для решения как на страновом, так и на провинциальном уровне идентификации СУО/ПА. Последняя модель MTL состоит из общего двунаправленного преобразователя представления кодера (BERT), двух уровней внимания, специфичных для конкретной задачи, и двух классификаторов. Наша ключевая идея заключается в использовании как дискриминационных, так и межзадачных общих функций для идентификации MSA/DA страны и провинции. Полученные результаты показывают, что наша модель MTL превосходит однозадачные модели по большинству подзадач.', 'ga': 'Is tascanna ríthábhachtacha iad canúint agus sainaithint teanga chaighdeánach do go leor feidhmeanna próiseála teanga nádúrtha Araibis. Sa pháipéar seo, cuirimid ár gcóras domhainfhoghlama i láthair, a cuireadh faoi bhráid an dara tasc comhroinnte de chuid NADI chun Araibis Chaighdeánach Nua-Aimseartha (MSA) agus Araibis Chanúnach (DA) a shainaithint ar leibhéal tíre agus cúige. Tá an córas bunaithe ar mhúnla domhain Foghlama Ilthasc (MTL) ó cheann go ceann chun dul i ngleic le sainaithint MSA/DA ar leibhéal na tíre agus ar an gcúige. Is éard atá sa tsamhail MTL deiridh ná ionchódóir comhroinnte Ionchódóra Léiriúcháin Ionchódóra Déthreo (BERT), dhá shraith aird a bhaineann go sonrach le tasc, agus dhá aicmitheora. Is é an príomh-smaoineamh atá againn ná na gnéithe tasc-idirdhealaitheacha agus idir-tasc roinnte a ghiaráil le haghaidh sainaithint tíre agus cúige MSA/DA. Léiríonn na torthaí a fuarthas go sáraíonn ár samhail MTL samhlacha aon tasc ar fhormhór na bhfothascanna.', 'el': 'Η διαλεκτική και η τυπική αναγνώριση γλώσσας είναι κρίσιμες εργασίες για πολλές εφαρμογές επεξεργασίας αραβικής φυσικής γλώσσας. Στην παρούσα εργασία, παρουσιάζουμε το σύστημα που βασίζεται στη βαθιά μάθηση, που υποβλήθηκε στο δεύτερο κοινό έργο της NADI για τον προσδιορισμό σε επίπεδο χώρας και επαρχίας των σύγχρονων προτύπων αραβικών (MSA) και διαλεκτικών αραβικών (DA). Το σύστημα βασίζεται σε ένα ολοκληρωμένο μοντέλο βαθιάς μάθησης πολλαπλών εργασιών (ΜΤL) για την αντιμετώπιση τόσο σε επίπεδο χώρας όσο και σε επίπεδο επαρχίας αναγνώρισης MSA/DA. Το τελευταίο μοντέλο αποτελείται από έναν κοινόχρηστο κωδικοποιητή αναπαράστασης μετασχηματιστών αμφίδρομης κατεύθυνσης κωδικοποιητή (BERT), δύο στρώματα προσοχής ειδικά για την εργασία και δύο ταξινομητές. Βασική ιδέα μας είναι να αξιοποιήσουμε τόσο τα διακριτικά χαρακτηριστικά των καθηκόντων όσο και τα κοινά χαρακτηριστικά μεταξύ των καθηκόντων για την αναγνώριση της χώρας και της επαρχίας MSA/DA. Τα αποτελέσματα που λαμβάνονται δείχνουν ότι το μοντέλο μας ξεπερνά τα μοντέλα μιας εργασίας στις περισσότερες δευτερεύουσες εργασίες.', 'kk': 'Диалекті және стандартты тіл идентификациясы - көп араб тілді өңдеу қолданбаларының маңызды тапсырмалары. Бұл қағазда, біз біздің тұрақты оқыту жүйесімізді таңдап, ел деңгейінде және ел деңгейінде Араб стандартты (MSA) және диалекты араб (DA) деңгейіндегі екінші ортақ тапсырмаға жі Жүйе ел деңгейінде және ауыл деңгейінде MSA/DA идентификациясын шешу үшін бірнеше тапсырмалар оқыту үлгісіне негізделген. Соңғы MTL үлгісі ортақтастырылған екі бағытты кодтардың түрлендіруші (BERT) кодтарынан, екі тапсырманың белгілі түрлендіруші қабаттарынан, екі классификациясы. Біздің негізгі идеямыз, ел мен ауыл MSA/DA идентификациясы үшін тапсырмалар дискриминациялық және тапсырмалардың ортақтастырылған мүмкіндіктерін өзгерту. Табылған нәтижелер MTL моделіміздің көпшілігінде бір тапсырма үлгілерін жасайды.', 'it': "Il dialetto e l'identificazione della lingua standard sono compiti cruciali per molte applicazioni di elaborazione della lingua naturale araba. In questo articolo presentiamo il nostro sistema basato sull'apprendimento profondo, sottoposto al secondo compito condiviso NADI per l'identificazione a livello nazionale e provinciale dell'arabo standard moderno (MSA) e dell'arabo dialettale (DA). Il sistema si basa su un modello end-to-end deep Multi-Task Learning (MTL) per affrontare sia l'identificazione MSA/DA a livello nazionale che provinciale. Quest'ultimo modello MTL consiste in un codificatore BERT (Bidirectional Encoder Representation Transformers) condiviso, due livelli di attenzione specifici per attività e due classificatori. La nostra idea chiave è quella di sfruttare sia le funzionalità task-discriminative che inter-task condivise per l'identificazione MSA/DA paese e provincia. I risultati ottenuti mostrano che il nostro modello MTL supera i modelli single-task sulla maggior parte delle sottoattività.", 'lt': 'Daugelio arabų gamtos kalbų apdorojimo programų dialektas ir standartinis kalbų identifikavimas yra esminės užduotys. Šiame dokumente pristatome savo giliai mokymosi pagrindu grindžiamą sistemą, kuri buvo pateikta antrajai bendrai NADI užduotims nustatyti šiuolaikinę standartinę arabišką (MSA) ir dialektinę arabišką (DA) šalies ir provincijų lygmeniu. The system is based on an end-to-end deep Multi-Task Learning (MTL) model to tackle both country-level and province-level MSA/DA identification.  The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers.  Mūsų pagrindinė idėja yra sutelkti dėmesį ir į užduočių diskriminacinius, ir užduočių tarpusavio bendrus požymius šalies ir provincijos MSA/DA identifikavimui. The obtained results show that our MTL model outperforms single-task models on most subtasks.', 'ka': 'დიალექტი და სტანდარტური ენის ინდიდინტიფიკაცია მნიშვნელოვანი რაოდენობები არაბური ენის პროცესი პროცესი პროგრამებისთვის. ამ დოკუნეში ჩვენ ჩვენი ძალიან სწავლის ბაზის სისტემა, რომელიც NADI-ს მეორე გაყოფილი საქმე დავამუშავებულია ქვეყანის დონეზე და პროვინტის დონეზე იდენტიფიკაციის მოდინარებული არაბული ( სისტემა დასაწყებელი მრავალური მოსწავლების (MTL) მოდელზე, რომელიც ორივე ქვეყნების დონე და პროვინტის დონე MSA/DA ინდიდინტიფიკაციის გამოყენება. შემდეგ MTL მოდელი იყოს გაყოფილი ორედირექციონალური კოდირენსტრანსტრანსტრანსტრაციის კოდირებისგან (BERT) კოდირებისგან, ორი დავალების განსაკუთრებული მონაცემები და ორი კო ჩვენი მნიშვნელოვანი იდეა, რომ დავაკეთებული დისკრიმინატიური და საერთო დავაკეთებული ფუნქციების განსაზღვრება ქვეყანის და პროვინტის MSA/DA ინდიდინტიფიკაციის გამოყენება. ჩვენი MTL მოდელი ერთადერთი დავალების მოდელზე უფრო მეტად გამოყენება.', 'ml': 'സ്വാഭാവികമായ അറബി ഭാഷ പ്രയോഗങ്ങള്\u200d ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d നമ്മുടെ ആഴത്തെ പഠിക്കുന്ന സിസ്റ്റം കാണിക്കുന്നു, രണ്ടാമത്തെ നാഡിയില്\u200d പങ്കാളിയുള്ള ജോലിക്ക് കൊടുത്തിരിക്കുന് ഈ സിസ്റ്റത്തിന്റെ അടിസ്ഥാനത്ത് ഒരു ആഴത്തിലേക്ക് അവസാനിപ്പിക്കുന്നുണ്ട്- അളവിലേക്കു് ആഴത്തിലേക്കു് ആഴത്തെ പല-ടാസ്ക് പ അവസാനത്തെ MTL മോഡല്\u200d പങ്കെടുത്ത Bidirectional Encoder Representation Transformers (BERT) എന്\u200dകോഡര്\u200d, രണ്ടു ജോലി- പ്രത്യേക ശ്രദ്ധ ക്രമങ്ങള്\u200d, രണ്ടു വിഭിന്നതകള്\u200d. നമ്മുടെ പ്രധാന ആശയം രാജ്യത്തിനും പ്രദേശം MSA/DA തിരിച്ചറിയുന്നതിനുമുള്ള ജോലിയുടെ വ്യത്യാസവും വിഭാഗിച്ചിരിക്കു സമ്പാദിച്ച ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് നമ്മുടെ എംടിഎല്\u200d മോഡല്\u200d കൂടുതല്\u200d സബ്ജോട്ടുകളില്\u200d ഒരു മോ', 'mt': 'Id-dijaleka u l-identifikazzjoni standard tal-lingwa huma kompiti kruċjali għal ħafna applikazzjonijiet tal-ipproċessar naturali tal-lingwa Għarbija. In this paper, we present our deep learning-based system, submitted to the second NADI shared task for country-level and province-level identification of Modern Standard Arabic (MSA) and Dialectal Arabic (DA).  Is-sistema hija bbażata fuq mudell ta’ Tagħlim Multikompiti (MTL) profond minn tmiem sa tmiem biex tiġi indirizzata kemm l-identifikazzjoni MSA/DA fil-livell tal-pajjiż kif ukoll fil-livell tal-provinċja. Dan tal-a ħħar mudell MTL jikkonsisti f’kodifikatur komuni ta’ Trasformaturi tar-Rappreżentanza Bidirezzjonali tal-Kodiċi (BERT), żewġ saffi ta’ attenzjoni speċifiċi għall-kompiti, u żewġ klassifikaturi. Our key idea is to leverage both the task-discriminative and the inter-task shared features for country and province MSA/DA identification.  Ir-riżultati miksuba juru li l-mudell MTL tagħna jwettaq mudelli ta’ kompitu wieħed fuq ħafna sottomistoqsijiet.', 'hu': 'A tárcsázás és a szabványos nyelvazonosítás kulcsfontosságú feladat számos arab természetes nyelvfeldolgozó alkalmazás számára. Jelen tanulmányban bemutatjuk a modern standard arab (MSA) és dialektikus arab (DA) országszintű és tartományszintű azonosítására irányuló második NADI közös feladatunkat. A rendszer egy end-to-end mély Multi-Task Learning (MTL) modellre épül, amely mind az országszintű, mind a tartományszintű MSA/DA azonosítását kezeli. Az utóbbi MTL modell egy megosztott kétirányú kódoló reprezentációs transzformátorokból (BERT) kódolóból, két feladatspecifikus figyelem rétegből és két osztályozóból áll. Kulcsfontosságú ötletünk, hogy mind a feladat-diszkriminatív, mind a feladatok közötti megosztott funkciókat kihasználjuk az ország és tartomány MSA/DA azonosításához. Az elért eredmények azt mutatják, hogy MTL modellünk a legtöbb részfeladatban felülmúlja az egyfeladatos modelleket.', 'ms': 'Dialeksi dan pengenalan bahasa piawai adalah tugas penting bagi banyak aplikasi pemprosesan bahasa alam Arab. Dalam kertas ini, kami memperkenalkan sistem berdasarkan belajar dalam kami, dihantar ke tugas berkongsi NADI kedua untuk pengenalan aras negara dan aras provinsi Arab Standar Modern (MSA) dan Arab Dialektik (DA). Sistem ini berdasarkan model belajar berbilang tugas (MTL) yang mendalam akhir-akhir untuk menangani pengenalan MSA/DA aras negara dan provinsi. The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers.  Idea utama kita adalah untuk menggunakan kedua-dua ciri-ciri yang diskriminatif dan berkongsi antara-tugas untuk pengenalan negara dan provinsi MSA/DA. The obtained results show that our MTL model outperforms single-task models on most subtasks.', 'mn': 'Шинэ сонголт болон стандарт хэл тодорхойлолт нь олон Араб байгалийн хэл үйлдвэрлэх програмын тулд чухал ажил юм. Энэ цаасан дээр бид суралцах сургалтын үндсэн системийг тайлбарлаж, улсын түвшинд, орчин үеийн Араб стандарт (MSA) болон Диалект Араб (DA) болон улсын түвшинд хуваалцах хоёр дахь даалгавар руу дамжуулагдс Энэ систем улсын түвшинд болон орон нутгийн түвшинд MSA/DA танихын тулд хамгийн гүн гүнзгий олон-Task Learning (MTL) загвар дээр суурилсан. Сүүлийн MTL загвар нь хоёр ажлын төвөгтэй анхаарлын давхар, хоёр анхаарлын давхар, хоёр анхаарлын төвөгтэй холбоотой байдаг. Бидний хамгийн чухал санаа нь улс болон орон нутгийн MSA/DA-ын тодорхойлолтын хоёр даалгаварын ялгаатай болон хоорондох үйл ажиллагааг ашиглах юм. Шинэ гарсан үр дүнд бидний MTL загвар ихэнх суурь асуудлын нэг даалгаварын загварыг дамжуулдаг гэдгийг харуулсан.', 'ro': 'Dialectul și identificarea limbii standard sunt sarcini esențiale pentru multe aplicații de prelucrare a limbii naturale arabe. În această lucrare, prezentăm sistemul nostru bazat pe învățare profundă, supus celei de-a doua sarcini comune NADI pentru identificarea la nivel de țară și provincie a Arabei Standard Moderne (MSA) și Arabei Dialectale (DA). Sistemul se bazează pe un model complet de învățare multisarcină (MTL) pentru a aborda identificarea MSA/DA atât la nivel de țară, cât și la nivel de provincie. Cel de-al doilea model MTL constă dintr-un codificator BERT (bidirecțional Encoder Representation Transformers), două straturi de atenție specifice sarcinilor și două clasificatoare. Ideea noastră cheie este de a valorifica atât caracteristicile discriminatorii de sarcini, cât și caracteristicile partajate inter-sarcini pentru identificarea MSA/DA a țării și provinciei. Rezultatele obținute arată că modelul nostru MTL depășește modelele cu o singură sarcină la majoritatea subactivităților.', 'pl': 'Dialekt i standardowa identyfikacja języka są kluczowymi zadaniami dla wielu arabskich aplikacji przetwarzania języka naturalnego. W niniejszym artykule przedstawiamy nasz system oparty na głębokim uczeniu, poddany drugiemu wspólnemu zadaniu NADI dotyczącemu identyfikacji na poziomie kraju i prowincji współczesnego standardowego arabskiego (MSA) i dialektalnego arabskiego (DA). System opiera się na kompleksowym modelu wielozadaniowego uczenia się (MTL) w celu rozwiązania identyfikacji MSA/DA na poziomie kraju i prowincji. Ten ostatni model MTL składa się ze wspólnego kodera transformatorów reprezentacyjnych koderów dwukierunkowych (BERT), dwóch warstw uwagi specyficznych dla zadania oraz dwóch klasyfikatorów. Naszą kluczową ideą jest wykorzystanie zarówno funkcji dyskryminacyjnych, jak i wspólnych między zadaniami do identyfikacji MSA/DA kraju i prowincji. Uzyskane wyniki pokazują, że nasz model MTL przewyższa modele jednozadaniowe w większości podzadań.', 'sr': 'Dijaletiranje i standardna identifikacija jezika su ključni zadatak za mnoge aplikacije prirodne obrade arapskog jezika. U ovom papiru predstavljamo naš duboki sistem na osnovu učenja, predan drugim zajedničkom zadatku NADI za identifikaciju modernog standardnog arapskog (MSA) i dijalektnog arapskog (DA) na zemlji i pokrajinskog nivoa. Sistem se temelji na modelu učenja mnogo zadataka (MTL) na kraju do kraja kako bi se riješio identifikacija zemaljske i provincijske nivoe MSA/DA. Posljednji MTL model se sastoji od zajedničkog kodera za dvosmjerne transformacije kodera za predstavljanje kodera (BERT), dva sloja pažnje na zadatke i dva klasifikatora. Naša ključna ideja je da utičemo na diskriminaciju zadataka i zajedničke funkcije za identifikaciju zemlje i provincije MSA/DA. Nabavljeni rezultati pokazuju da naš model MTL iznosi jedan zadatak na većini podataka.', 'si': 'අරාබික භාෂාව පරීක්ෂණය සහ ප්\u200dරමාණය භාෂාව පරීක්ෂණය විශේෂ වැඩක් අරාබික භාෂාව ප්\u200dරක්\u200d මේ පත්තරේ අපි අපේ ගොඩක් ඉගෙනීමේ පද්ධතිය පෙන්වන්නේ, දෙවෙනි NADI භාවිත වැඩකට රාජ්ය සහ ප්\u200dරදේශ ප්\u200dරමාණය අරාබිය (MSA) සහ අරාබිය (DA පද්ධතිය අවසානයෙන් අවසානයෙන් අවසානයෙන් ගොඩක් වැඩක් ඉගෙනීම (MTL) නිර්මාණයක් තියෙනවා දේශ ස්ථානය සහ ප්\u200dරදේශ-ස්ථා අන්තිම MTL මොඩල් එකේ සම්බන්ධ විදිහට සම්බන්ධ විදිහට සංකේතකයෙන් ප්\u200dරතිනිධානකය (BERT) සංකේතකයෙන්, වැඩක් විශේෂ අපේ වැදගත් අදහස තමයි රාජ්ය සහ ප්\u200dරදේශ MSA/DA පරික්ෂණය සඳහා වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැඩේ අ ගත්ත ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර', 'so': 'Aqoonsiga afka caadiga ah iyo aqoonsiga afka caadiga ah waa shaqooyin muhiim ah oo loo baaraandegayo codsiyo badan oo af Carabi ah. Qoraalkan waxaynu ku soo bandhignaa nidaamka hoose ee waxbarashada, waxaana loo dhiibay shaqada labaad ee NADI oo loo sharciyey aqoonsashada afka waddanka iyo gobolka ee asalka ah Carabiga (MSA) iyo Dialectal Carabiga (DA). Isticmaalku wuxuu ku saleysan yahay qaab aad u dheer waxbarasho shaqo badan (MTL) si uu u qabsado aqoonsiga dowladda iyo gobolka oo dhan ee MSA/DA. Tusaalada ugu dambeeya MTL waxaa ka mid ah qayb la qaybsan koordiyuhu (BERT) codsigiisa (BERT), laba qasnaan oo gaar ah oo la jeedo, iyo laba fasax. Fikiradayada muhiimka ah waa in loo soo bandhigaa aqoonsiga dowladda iyo gobolka MSA/DA. Arrimaha la helay waxay muuqataa in qaababkayaga MTL uu ka samaysto qaabab kali ah oo ku saabsan meelaha badan.', 'sv': 'Dialekt och standardiserad språkidentifiering är viktiga uppgifter för många arabiska naturliga språkbearbetningsapplikationer. I denna uppsats presenterar vi vårt djupinlärningsbaserade system, inlämnat till den andra NADI delade uppgiften för landsnivå och provinsnivå identifiering av Modern Standard Arabic (MSA) och Dialektal Arabic (DA). Systemet är baserat på en heltäckande modell för multi-Task Learning (MTL) för att hantera både landsnivå och provinsnivå MSA/DA identifiering. Den senare MTL-modellen består av en gemensam BERT-kodare (Bidirectional Encoder Representation Transformers), två uppgiftsspecifika uppmärksamhetslager och två klassificerare. Vår huvudidé är att utnyttja både uppgiftsdiscriminerande och de delade funktionerna för land och provins MSA/DA identifiering. De erhållna resultaten visar att vår MTL-modell överträffar enkeluppgiftsmodeller på de flesta underuppgifter.', 'mk': 'Dialect and standard language identification are crucial tasks for many Arabic natural language processing applications.  In this paper, we present our deep learning-based system, submitted to the second NADI shared task for country-level and province-level identification of Modern Standard Arabic (MSA) and Dialectal Arabic (DA).  Системот се базира на модел од крај до крај на длабоко мултизадачно учење (МТЛ) за решавање на идентификацијата на MSA/ДА на ниво на земја и провинција. The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers.  Нашата клучна идеја е да ги искористиме дискриминативните и меѓузадачните заеднички карактеристики за идентификацијата на земјата и покраината MSA/DA. The obtained results show that our MTL model outperforms single-task models on most subtasks.', 'no': 'Vel og standard språk- identifisering er viktige oppgåver for mange arabiske naturspråk- handlingsprogrammer. I denne papiret presenterer vi vårt dyp læringsbasert system, som er sendt til den andre delte NADI-oppgåva for identifikasjon av landnivå og provinsenivå i moderne arabiske (MSA) og dialektiske arabiske (DA). Systemet er basert på ein dyp multioppgåver-læring (MTL) modell for å løysa både landnivå og provinsenivå MSA/DA-identifikasjon. Det siste MTL-modellen inneheld ein delt bikdirektionalt koderingstransformasjonsformatorar (BERT), to oppgåvelege oppmerkslag og to klassifikatorar. Nøkkelideen vårt er å levera både oppgåvediskriminasjonen og delte funksjonar for landet og provinset MSA/DA-identifikasjon. Dette opptekte resultatet viser at MTL-modellen vår utfører enkelte oppgåvemodeller på dei fleste underspørjingane.', 'ta': 'Dialect and standard language identification are crucial tasks for many Arabic natural language processing applications.  இந்த காக்கியத்தில், நாம் எங்கள் ஆழமான கற்றுக்கொள்ள முறைமையை காண்பிக்கிறோம், இரண்டாவது NADI பகிர்ந்த பணிக்கு கொடுக்கப்பட்டுள்ளோம் நாடு நில முடிவிலிருந்து முடிவில் உள்ள ஆழமான பல பணி கற்றுக்கொள்ள (MTL) மாதிரி அமைப்பு அடிப்படையில் உள்ளது இரு நாடு நிலையும் மற்றும் பிராந் கடைசி MTL மாதிரி பங்கிடப்பட்ட Bidirectional Encoder Representation Transfers (BERT) குறியீடு, இரண்டு பணிக்குறிப்பிட்ட குறிப்பிட்ட கவனம் அடுக்குகள், மற்றும் இரண்டு வகை எங்கள் முக்கிய கருத்து என்னவென்றால் நாடு மற்றும் பிரநாட்டின் MSA/DA அடையாளத்திற்கும் இடையேற்ற பணி குணங்களை ஒப்புக்கொ பெற்ற முடிவுகள் பெரும்பாலான துணை பணிகளில் எங்கள் MTL மாதிரி ஒரே பணி மாதிரிகளை செயல்படுத்துகிறது என்பதை கா', 'ur': 'ڈائیلٹ اور استاندارڈ زبان کی شناسایی بہت سی عربی طبیعی زبان پردازش کاربریاں کے لئے اہم کام ہیں. اس کاغذ میں ہم اپنی عمیق سیکھنے کی بنیادی سیسٹم کو پیش کرتے ہیں، دوسری NADI کے ساتھ ملک سطح اور منطقه سطح کی معلومات کے لئے ملک سطح اور منطقه سطح عربی (MSA) اور دیالکتال عربی (DA) کے ذریعہ مشترک کام کے لئے پیش کیا جاتا سیسٹم ایک عمیق مثالٹاکس کی تعلیم (MTL) موڈل پر بنیاد ہے کہ دونوں ملک سطح اور منطقه سطح MSA/DA پہچان کرنے کے لئے استعمال کرے۔ آخرین MTL موڈل ایک مشترک دودئیرسینٹ اکنوڈر ریسپینسٹ ٹرنفسٹر (BERT) کا کوڈر ہے، دو کام خاص توجه لائر اور دو کلاسپیر سے ہے. ہماری اصلی فکر یہ ہے کہ کشور اور منطقه MSA/DA کی شناسایی کے لئے کام-جدائی اور inter-task کے مشترکین فرصت کو فائدہ پہنچانا ہے. پائی ہوئی نتیجے دکھاتے ہیں کہ ہمارے MTL موڈل اکثر زیادہ سٹسٹسٹ کے ذریعے ایک ٹاکس موڈل سے کام کرتا ہے۔', 'uz': "Koʻp arab tilni boshqarish dasturlari uchun dialek va andoza tillar identifikati muhim vazifalar. Bu qogʻozda biz juda yaxshi o'rganish asosiy tizimimizni hosil qilamiz, davlat darajasi va provador darajasi (MSA) va Dialektal arab (DA) uchun ikkinchi narsa bilan birlashtirilgan vazifani qo'shib beramiz. Name Name Bizning muhim fikrimimiz, bu vazifani ajratish va har bir vazifaning boshqa xususiyatlarini ko'rsatish mumkin, va MSA/DA tashkilotning boshqa shakllarini ko'rsatish. Muvaffaqiyatli natijalar ko'pchilik vazifalarda MTL modellarimiz bir vazifa modellarini bajaradi.", 'vi': 'Việc nhận dạng ngôn ngữ chuẩn là việc quan trọng cho nhiều ứng dụng xử lý ngôn ngữ tự nhiên Ả rập. Trong tờ giấy này, chúng tôi giới thiệu hệ thống nghiên cứu sâu, được gửi đến một nhiệm vụ chung của NASI cho việc xác định cấp quốc gia và cấp độ nhận dạng của Chuột Rập chuẩn hiện đại (MSA) và Văn học Ả Rập (DA). The system is based on a end-to-end deep multiTask Learning (MTV) model to handle both country-level và tỉnh-level MSA/DA identification. Mẫu MTV cuối cùng gồm một bộ mã hóa Mô hình Diễn biến theo giao thức (BERT) bị chia sẻ, hai lớp tập trung đặc nhiệm, và hai phân loại. Ý tưởng chủ chốt của chúng ta là động lực cho cả sự phân biệt nhiệm vụ và chia sẻ các nhiệm vụ cho việc xác định đất nước và tỉnh MSA/DA. Những kết quả xác định cho thấy mô hình MTV hoàn thiện quy mô đơn vị trên hầu hết các mặt phụ đề.', 'bg': 'Диалектът и стандартната езикова идентификация са решаващи задачи за много приложения за обработка на арабски естествен език. В настоящата статия представяме нашата система, базирана на дълбоко обучение, представена на втората споделена задача на НАДИ за идентификация на ниво държава и провинция на съвременен стандартен арабски (МСА) и диалектален арабски (ДА). Системата се основава на модел на задълбочено многозадачи обучение от край до край, за да се справи както с идентифицирането на МСА/ДА на ниво държава, така и на ниво провинция. Последният модел се състои от споделен двупосочен кодер трансформатор за представяне на кодери (BERT), два слоя на внимание, специфични за задачата, и два класификатора. Нашата основна идея е да използваме както дискриминационните, така и споделените между задачите характеристики за идентификацията на МСА/ДА в страната и провинцията. Получените резултати показват, че нашият модел надминава моделите с една задача при повечето подзадачи.', 'da': 'Dialekt og standard sprogidentifikation er afgørende opgaver for mange arabiske natursprogbehandlingsapplikationer. I denne artikel præsenterer vi vores deep learning-baserede system, der er indsendt til den anden NADI delte opgave for land- og provinsniveau identifikation af Modern Standard Arabic (MSA) og Dialektal Arabic (DA). Systemet er baseret på en end-to-end dyb Multi-Task Learning (MTL) model til at tackle både landeniveau og provinsniveau MSA/DA identifikation. Sidstnævnte MTL-model består af en delt BERT-koder (Bidirectional Encoder Representation Transformers), to opgavespecifikke opmærksomhedslag og to klassificeringer. Vores nøgleidé er at udnytte både opgaveforskelsbehandling og interopgavefælles funktioner til land og provins MSA/DA identifikation. De opnåede resultater viser, at vores MTL model overgår single-task modeller på de fleste underopgaver.', 'nl': 'Dialect en standaardtaal identificatie zijn cruciale taken voor veel Arabische natuurlijke taal verwerkingstoepassingen. In dit artikel presenteren we ons deep learning-gebaseerd systeem, dat is ingediend bij de tweede gezamenlijke NADI-taak voor de identificatie van Modern Standaard Arabisch (MSA) en Dialectaal Arabisch (DA) op landenniveau en provincieniveau. Het systeem is gebaseerd op een end-to-end diep Multi-Task Learning (MTL) model om zowel op land- als provincieniveau MSA/DA identificatie aan te pakken. Het laatste MTL-model bestaat uit een gedeelde BERT-encoder (Bidirectional Encoder Representation Transformers), twee taakspecifieke aandachtslagen en twee classificatoren. Ons belangrijkste idee is om gebruik te maken van zowel de taken-discriminerende als de inter-task gedeelde functies voor land en provincie MSA/DA identificatie. De verkregen resultaten tonen aan dat ons MTL-model op de meeste subtaken beter presteert dan single-task modellen.', 'hr': 'Dijaliranje i standardna identifikacija jezika su ključni zadatak za mnoge aplikacije obrade prirodnog jezika Arapskog jezika. U ovom papiru predstavljamo naš duboki sustav na temelju učenja, predan drugim zajedničkom zadatku NADI za identifikaciju modernog standardnog arapskog (MSA) i dijalektnog arapskog (DA) na zemlji i pokrajinskog nivoa. Sistem se temelji na modelu učenja višestrukih zadataka (MTL) na kraju do kraja kako bi se riješio identifikacija zemaljske i provincijske razine MSA/DA. Posljednji model MTL sastoji se od podijeljenog kodera za dvosmjerne transformacije predstavljanja kodera (BERT), dva slojeva posebne pažnje na zadatke i dva klasifikatora. Naša ključna ideja je utjecati na diskriminaciju zadataka i zajedničke funkcije za identifikaciju zemlje i provincije MSA/DA. Naučeni rezultati pokazuju da naš model MTL iznosi jednozadatačne modele na većini podataka.', 'de': 'Dialekt und Standard-Spracherkennung sind wichtige Aufgaben für viele arabische Anwendungen zur Verarbeitung natürlicher Sprache. In diesem Beitrag stellen wir unser Deep Learning-basiertes System vor, das der zweiten gemeinsamen NADI-Aufgabe zur Identifizierung von Modernem Standardarabisch (MSA) und Dialektalem Arabisch (DA) auf Länderebene und Provinzebene unterzogen wurde. Das System basiert auf einem End-to-End Deep Multi-Task Learning (MTL)-Modell, um sowohl die Identifikation von MSA/DA auf Landes- als auch Provinzebene zu bewältigen. Das letztgenannte MTL-Modell besteht aus einem gemeinsamen BERT-Encoder (Bidirektional Encoder Representation Transformers), zwei aufgabenspezifischen Aufmerksamkeitsschichten und zwei Klassifikatoren. Unsere Kernidee ist es, sowohl die aufgabendiskriminierenden als auch die aufgabendiskriminierenden Funktionen für die Identifikation von Land und Provinz MSA/DA zu nutzen. Die erhaltenen Ergebnisse zeigen, dass unser MTL-Modell bei den meisten Teilaufgaben Einzelaufgabenmodelle übertrifft.', 'id': 'Dialeksi dan identifikasi bahasa standar adalah tugas penting bagi banyak aplikasi proses bahasa alam Arab. Dalam kertas ini, kami memperkenalkan sistem berdasarkan belajar dalam kami, yang dipanggil ke tugas NADI kedua yang sama untuk identifikasi tingkat negara dan provinsi dari Arab Standard Modern (MSA) dan Arab Dialektik (DA). Sistem ini berdasarkan model belajar multitask (MTL) yang mendalam dari akhir ke akhir untuk menangani identifikasi MSA/DA. Model MTL yang terakhir terdiri dari pengekode Representation Transformers Bidirectional Encoder (BERT), dua lapisan perhatian spesifik tugas, dan dua klasifikasi. Ide kunci kita adalah untuk menggunakan kedua-dua karakteristik yang diskriminatif dan intertugas berbagi untuk identifikasi negara dan provinsi MSA/DA. Hasil yang diperoleh menunjukkan bahwa model MTL kita melampaui model tugas tunggal pada kebanyakan subtasks.', 'ko': '사투리와 표준 언어 식별은 많은 아랍어 자연 언어 처리 응용 프로그램의 관건적인 임무이다.본고에서 우리는 심도 있는 학습을 바탕으로 하는 우리의 시스템을 소개했다. 이 시스템은 두 번째 NADI 공유 임무에 제출되어 국가급과 성급에서 현대 표준 아랍어(MSA)와 사투리 아랍어(DA)를 식별하는 데 사용된다.이 시스템은 국가급과 성급 MSA/DA 식별 문제를 해결하기 위해 끝에서 끝까지의 심도 있는 멀티태스킹 학습(MTL) 모델을 바탕으로 한다.다음 MTL 모델은 공유된 양방향 인코더 표시 변환기 (BERT) 인코더, 작업에 대한 두 개의 주의층과 두 개의 분류기로 구성되어 있다.우리의 주된 생각은 임무의 구분성과 임무 간의 공유 특성을 이용하여 국가와 성의 MSA/DA를 식별하는 것이다.그 결과 우리의 MTL 모델은 대부분의 하위 임무에서 단일 임무 모델보다 우수하다는 것을 알 수 있다.', 'fa': 'برگزیدن و شناسایی زبان استاندارد کارهای مهم برای بسیاری از کاربردهای پرداخت زبان طبیعی عربی است. در این کاغذ، سیستم عمیق یادگیری ما را پیشنهاد می\u200cکنیم، که به کار دوم مشترک NADI برای شناسایی سطح کشور و سطح استاندارد عربی استاندارد مدرن (MSA) و عربی دیالکتی (DA) ارائه می\u200cشود. این سیستم بر اساس یک مدل یادگیری عمیق چندین کار (MTL) برای حل شناسایی سطح کشور و سطح استان MSA/DA است. این مدل آخرین MTL از یک قالب تغییر دهنده\u200cهای نمایش\u200cدهنده\u200cی دو طریقه\u200cای (BERT) شرکت می\u200cکند، دو لایه توجه ویژه\u200cای برای کار و دو تنظیم\u200cکننده است. ایده\u200cی کلید ما این است که برای شناسایی کشور و استان MSA/DA، هر یک از ویژه\u200cهای مشترک و مشترک\u200cهای عملیات و مشترک\u200cهای مشترک را تأثیر دهیم. نتیجه\u200cهای دریافت شده نشان می\u200cدهند که مدل MTL ما مدل\u200cهای یک کار را بیشتر از زیر سوال\u200cها انجام می\u200cدهد.', 'sw': 'Utambulisho na utambulisho wa lugha za kawaida ni kazi muhimu kwa matumizi mengi ya lugha za asili ya Kiarabu. Katika karatasi hii, tunaonyesha mfumo wetu wa kujifunza kwa kina, uliotumiwa na kazi ya pili ya NADI inayoshirikisha kwa ajili ya kutambua kiwango cha nchi na kiwango cha jimbo cha Kiarabu cha Modern Standard (MSA) na Kiarabu cha Kidialectal (DA). Mfumo huo unajikita na mtindo wa Kufunza Mitandao ya Kuu (MTL) wa mwisho wa mwisho ili kupambana na utambulisho wa kiwango cha nchi na kilicho cha mkono cha MSA/DA. Mradi wa pili wa MTL unajumuisha jumbe ya watambulishi wa Uwekezaji wa Kiongozi wa Uwekezaji (BERT), vipande viwili maalum vya kazi, na wataalamu wawili. Wazo letu muhimu ni kuitumia kazi hizo za ubaguzi na kazi zinazosambazwa kwa ajili ya utambulisho wa nchi na jimbo la MSA/DA. Matokeo yaliyopata yanaonyesha kuwa mtindo wetu wa MTL unafanya mifano ya kazi moja kwa moja kwenye kazi nyingi.', 'tr': 'Saýlaw we standart dil tanymasy arabça dil işleýän uygulamalar üçin örän wajyp zady. Bu kagyzda çukur öwrenmek sistemamyzy görkezip, NADI-iň ikinji derejede we provinciýasynyň Modern Standardy Arapça (MSA) we Dialektik Arapça (DA) bilen bölegi paýlaşdyrylýar. Bu sistem ýurtyň derejesi we provinciýa-derejesi MSA/DA kimligini çözmek üçin iň soňunda gaty bir çoklu-Taýgy öwrenmesi (MTL) nusgasyna daýan ýar. Soňky MTL nusgasynyň paylaşyk Bidirectional Ködleme Taýýarlançylarynyň (BERT) ködlemeleri, iki işiň häzirki üns kalamlaryň we iki klasifikatçylaryň içine bar. Biziň açyk ideýimiz ýurt we provinciýa MSA/DA kimligini hem görevi-diskriminçylyk we meselelerimiz üçin üýtgetmekdir. Ilkinji netijeler MTL nusgymyzyň köp soraglaryň ýeke-täk nusgalarynyň üstüne çykarýandygyny görkezýär.', 'af': "Dialeksie en standaard taal identifikasie is belangrike taak vir baie Arabiese natuurlike taal verwerking toepassings. In hierdie papier het ons ons diep leer-gebaseerde stelsel voorgestel, voorgestel aan die tweede NADI gedeelde taak vir land-vlak en provinsie-vlak-identifikasie van Moderne Standaard Arabiese (MSA) en Dialekteel Arabiese (DA). Die stelsel is gebaseer op 'n end-to-end diep Multi-Task Learning (MTL) model om beide landvlak en provinsie-vlak MSA/DA identifikasie te probeer. Die laaste MTL model bestaan van 'n gedeelde tweederigtinglike enkoder voorstelling Transformeerders (BERT) enkoder, twee taak spesifieke aandag laag en twee klassifiseerders. Ons sleutel idee is om beide die taak-diskriminasie en die inter-taak gedeelde funksies vir land en provinsie MSA/DA-identifikasie te verwyder. Die ontvangde resultate vertoon dat ons MTL-modell een-taak-modele op die meeste subtaske uitvoer.", 'am': 'በአካባቢው ቋንቋ ማቀናጃ እና የአካባቢ ቋንቋ ፕሮግራሞች ላይ የሚያስፈልገው ሥራ ናቸው፡፡ በዚህ ፕሮግራም ውስጥ የጥልቅ ትምህርት መሠረታችንን እና ለሁለተኛው NADI ስራ ለሀገር ደረጃና የአውራሲው የአርባዊ ስርዓት (አሜሪካ) እና ዳሌካል ዐረብኛ (አ) እና ለዳሌክቲል አረቢያ (አ). የስርቨሮች ደረጃና አውቶማቲ አሜሪካ እና የአሜሪካ ደረጃን እና የአሜሪካ መግለጫ መቆጣጠር (MTL) ሞዴል ነው፡፡ የመጨረሻው MTL ሞዴል የተካፈለ Bidirectional Encoder Representation Transformers (BERT) encoder, ሁለት task-specific ጥያቄ ደረጃዎች እና ሁለት classifiers. የዋነታችን አሳብ የስራ-ልዩነኛ እና የአገሪቱ እና የአሜሪካ/አ.አ.አ.አ.አ.አ.አ.አ. የተገኘው ውጤቶች የMTL ሞዴል በብዙ ስራ ላይ አንድ ዶላዎችን የሚያደርግ ነው፡፡', 'sq': 'Dialekti dhe identifikimi standard i gjuhës janë detyra vendimtare për shumë aplikacione të përdorimit të gjuhës natyrore arabe. Në këtë letër, ne paraqesim sistemin tonë të thellë bazuar në mësim, të paraqitur në detyrën e dytë të përbashkët të NADI për identifikimin e nivelit të vendit dhe të nivelit të krahinës të Arabit Modern Standard (MSA) dhe Arabit Dialektik (DA). Sistemi është bazuar në një model të thellë Mësimi Multi-Task (MTL) për të trajtuar si identifikimin e nivelit të vendit ashtu edhe të nivelit të krahinës MSA/DA. Modeli i fundit MTL përbëhet nga një kodues i përbashkët i përfaqësimit të koduesit dy-drejtues (BERT), dy shtresa vëmendjeje specifike për detyrat dhe dy klasifikues. Ideja jonë kryesore është të përdorim si funksionet diskriminuese për detyrat, ashtu edhe funksionet e përbashkëta ndër detyrat për identifikimin e vendit dhe provincës MSA/DA. Rezultatet e fituara tregojnë se modeli ynë MTL paraqet modelet me një detyrë të vetme në shumicën e nëndetyrave.', 'hy': 'Dialect and standard language identification are crucial tasks for many Arabic natural language processing applications.  Այս թղթի մեջ մենք ներկայացնում ենք մեր խորը ուսումնասիրությամբ հիմնված համակարգը, որը ներկայացվել է երկրի և նահանգային մակարդակի երկրորդ համագործակցած առաջադրանքին ժամանակակից ստանդարտ արաբերենի (MSA) և դիալեկտալ արաբերենի (DA) նշանակության համար: Համակարգը հիմնված է վերջ-վերջ խորը բազմախնդիրների ուսումնասիրության (MTL) մոդելի վրա, որպեսզի վերաբերվի երկրի և նահանգային մակարդակի MSA-ի և DA-ի հայտնաբերությանը: Վերջին MTL մոդելը կազմված է երկաուղղակի կոդավորիչների ներկայացման փոխակերպիչների (BER) կոդավորիչներից, երկու հատուկ ուշադրության շերտերից և երկու դասակարգիչներից: Մեր հիմնական գաղափարն այն է, որ մենք օգտագործենք աշխատանքների խտրականությունը, ինչպես նաև աշխատանքների միջև ընդհանուր հատկությունները երկրի և նահանգների MSA-ի և DA-ի հայտնաբերման համար: Ընդհանուր արդյունքները ցույց են տալիս, որ մեր MTL մոդելը առավել լավ է ընդունում մեկ խնդրի մոդելները մեծ մասում:', 'az': 'Seçim və standart dil tanımlaması çoxlu ərəb dili işləmə proqramları üçün çoxlu mövcuddur. Bu kağızda, bizim derin öyrənmək sistemimizi göstərdik, ülke seviyesi və province seviyesi Modern Standard Arabic (MSA) və Dialectal Arabic (DA) təşkil edilən ikinci NADI paylaşılmış iş işinə göndərildik. Sistem ölkə səviyyəsi və province-səviyyəsi MSA/DA kimliğini çəkmək üçün çoxlu-Task Öyrənməsi (MTL) modeli ilə dayanılır. Son MTL modeli paylaşılan iki yönəlli Encoder Representation Transformers (BERT) kodlayıcısıdır, iki işin müəyyən edilmiş paylaşım layers və iki klassifiklərdir. Bizim anahtar fikrimiz, ülke və province MSA/DA kimliğinin paylaşılması üçün işlər-diskriminatlı və işləri ilə birlikdə paylaşılan özellikləri təsir etməkdir. Qazandıqları sonuçlar MTL modeliyimizin çox çətinliklərdə tək iş modellərini göstərir.', 'bn': 'অনেক আরবী ভাষার প্রাকৃতিক প্রক্রিয়ার অ্যাপ্লিকেশনের জন্য ডায়ালেক্ট এবং স্থান্য ভাষা পরিচিতি গুরুত এই কাগজটিতে আমরা আমাদের গভীর শিক্ষাভিত্তিক সিস্টেম উপস্থাপন করি, দ্বিতীয় নাডিআই দ্বিতীয় কাজে প্রদেশের দ্বিতীয় স্তর এবং প্রদেশের পরিচিতির জন্য দেশের স্তর এবং প্রদেশের স্তরের এমএসএ/DA পরিচিতির সাথে মোকাবেলা করার জন্য এই সিস্টেমের ভিত্তিতে রয়েছে। সর্বশেষ MTL মডেলের মধ্যে একটি শেয়ার করা বাইডেডিয়াল এনকোডার প্রতিনিধিত্ব প্রতিনিধি ট্রান্সফার্মার (BERT) এনকোডার, দুটি কাজ-নির্দ আমাদের গুরুত্বপূর্ণ ধারণা হচ্ছে দেশ এবং প্রদেশের এমএসএ/ডিএ পরিচয়ের জন্য কাজ-বৈষম্য এবং কাজের মধ্যে কাজের বিভিন্ন বৈষম্যে অর্জনের ফলাফল দেখাচ্ছে যে আমাদের এমটিএল মডেল বেশীরভাগ সাবটাসের মধ্যে একাকাজের মডেল প্রদর্শন করে।', 'ca': "La dialecta i l'identificació de llenguatges estàndard són tasques crucials per a moltes aplicacions de processament de llenguatges naturals àrabs. En aquest paper, presentem el nostre sistema basat en l'aprenentatge profund, submetit a la segona tasca compartida de la NADI per identificar a nivell nacional i provincial l'àrab Modern Standard (MSA) i l'àrab Dialectal (DA). El sistema està basat en un model profund d'aprenentatge multitascat (MTL) de final a final per abordar la identificació MSA/DA a nivell nacional i provincial. L'últim model MTL consisteix en un codificador compartit de transformadors de representació bidireccional del codificador (BERT), dues capes d'atenció específica per a les tasques i dos classificadors. La nostra idea clau és aprofitar les característiques compartides per a la identificació dels països i provincies MSA/DA. Els resultats obtenits demostren que el nostre model MTL supera els models d'una sola tasca en la majoria de subtaskes.", 'bs': 'Dijaletiranje i standardna identifikacija jezika su ključni zadatak za mnoge aplikacije prirodne obrade arapskog jezika. U ovom papiru predstavljamo naš duboki sistem na osnovu učenja, predan drugim zajedničkom zadatku NADI za identifikaciju modernog standardnog arapskog (MSA) i dijalektnog arapskog (DA) na zemlji i pokrajinskog nivoa. Sistem se temelji na model dubokog učenja multizadataka (MTL) na kraju do kraja kako bi se riješio identifikacija zemaljske i provincijske razine MSA/DA. Posljednji MTL model se sastoji od zajedničkog kodera za dvosmjerne transformacije predstavljanja kodera (BERT), dva slojeva posebne pažnje na zadatke i dva klasifikatora. Naša ključna ideja je utjecati na diskriminaciju zadataka i zajedničke funkcije za identifikaciju zemlje i provincije MSA/DA. Naučeni rezultati pokazuju da naš model MTL iznosi jednozadatak na većini podataka.', 'et': 'Dialekt ja standardne keele identifitseerimine on olulised ülesanded paljude araabia looduskeele töötlemise rakenduste jaoks. Käesolevas töös tutvustame meie sügavõppepõhist süsteemi, mis on esitatud teisele NADI jagatud ülesandele kaasaegse standardse araabia (MSA) ja dialektilise araabia (DA) riigi tasandil ja provintsi tasandil tuvastamiseks. Süsteem põhineb täielikul mitme ülesandega õppe mudelil, et käsitleda nii riigi kui ka provintsi tasandi MSA/DA identifitseerimist. Viimane MTL mudel koosneb ühisest kahesuunalisest kodeerijate esindamise transformaatorist (BERT), kahest ülesandepõhisest tähelepanu kihist ja kahest klassifitseerijast. Meie põhieesmärk on kasutada nii ülesandeid diskrimineerivaid kui ka ülesandevahelisi ühiseid funktsioone riigi ja provintsi MSA/DA identifitseerimiseks. Saadud tulemused näitavad, et meie MTL mudel ületab enamiku alamülesannete puhul ühe ülesandega mudeleid.', 'cs': 'Dialekt a standardní identifikace jazyka jsou klíčovými úkoly pro mnoho aplikací zpracování arabského přirozeného jazyka. V tomto článku představujeme náš systém založený na hlubokém učení, který byl předložen druhému sdílenému úkolu NADI pro identifikaci moderní standardní arabštiny (MSA) a dialektální arabštiny (DA) na úrovni zemí a provincií. Systém je založen na komplexním modelu víceúkolového učení (MTL) pro řešení identifikace MSA/DA na úrovni zemí i provincie. Druhý MTL model se skládá ze sdíleného snímače reprezentačních transformátorů (BERT), dvou vrstev pozornosti specifických pro úkoly a dvou klasifikátorů. Naší klíčovou myšlenkou je využít jak diskriminační, tak mezi úkoly sdílené funkce pro identifikaci zemí a provincie MSA/DA. Získané výsledky ukazují, že náš MTL model překonává jednotlivé modely na většině dílčích úkolů.', 'fi': 'Dialekti ja vakiokielen tunnistus ovat tärkeitä tehtäviä monissa arabian luonnollisen kielen käsittelysovelluksissa. Tässä artikkelissa esittelemme syvään oppimiseen perustuvaa järjestelmäämme, joka on toimitettu toiseen NADI-yhteiseen tehtävään modernin standardin arabian (MSA) ja dialektisen arabian (DA) maa- ja maakuntatason tunnistamiseksi. Järjestelmä perustuu kattavaan monitehtäväoppimisen (MTL) malliin, jossa käsitellään sekä maakohtaista että maakuntatason MSA/DA-tunnistetta. Jälkimmäinen MTL-malli koostuu jaetusta kaksisuuntaisesta koodaajien edustamisen muuntajasta (BERT), kahdesta tehtäväkohtaisesta huomiokerroksesta ja kahdesta luokittelijasta. Keskeisenä ajatuksenamme on hyödyntää sekä tehtäviä syrjiviä että tehtävien välisiä yhteisiä ominaisuuksia maan ja maakunnan MSA/DA tunnistamisessa. Saadut tulokset osoittavat, että MTL-mallimme suoriutuu yhden tehtävän malleista useimmissa alitehtävissä.', 'jv': 'Ngawe Nan pepulan iki, kita nambah sistem sing nggawe basa gambar n\' al sistem sing nyebutakne ning disebarke sistem sing dibenalke nggo nambah segala kanggo nambah dhéwé lan nambah-nambah sing berarti Gambar uwong (SMA) lan diaelectal arab sing isi (Da). Sistem dadi basa ning model end-to-end deep Multi-task Learning The last MTL model is compromise a share Bidirectial Kita pangunahing punika wis diguwasi nggawe task-Diskripatif lan inter-task diputara pawaran kanggo langgambar lan mulasar SMA/Da Rasane sing wis mbut banjur dadi model MTL dumateng model sing kotak-task" lan nganggo barang pangutung', 'sk': 'Dialekt in standardna identifikacija jezika sta ključna naloga za številne aplikacije za obdelavo arabskega naravnega jezika. V prispevku predstavljamo sistem globokega učenja, ki je bil predložen drugi NADI skupni nalogi za identifikacijo sodobne standardne arabščine (MSA) in dialektične arabščine (DA) na ravni države in province. Sistem temelji na modelu poglobljenega večopravilnega učenja (MTL) od konca do konca za obravnavo identifikacije MSA/DA na ravni države in province. Slednji model MTL je sestavljen iz skupnega kodirnika BERT (Bidirectional Encoder Representation Transformers), dveh plasti pozornosti, specifičnih za opravila, in dveh klasifikatorjev. Naša ključna ideja je izkoristiti diskriminativne in mednaložbene skupne značilnosti za identifikacijo MSA/DA države in province. Dobljeni rezultati kažejo, da naš model MTL presega enonalogne modele pri večini podopravil.', 'he': 'דיאלקט וזיהוי שפה סטנדרטי הם משימות חשובות עבור שיעורי עיבוד שפת טבעיים רבים ערביים. בעיתון הזה, אנו מציגים את מערכת המבוססת על הלימודים העמוקה שלנו, שנשלחה למשימה המשותפת השנייה של NADI עבור זיהוי רמה מדינה ורמה המחוזית של ערבית סטנדרטית מודרנית (MSA) ו ערבית דיאלקטית (DA). המערכת מבוססת על דוגמנית למידה רבה-משימות (MTL) עמוקה סוף-סוף כדי להתמודד עם זיהוי MSA/DA ברמה מדינה וגם ברמה המחוזית. דוגמנית MTL האחרונה מורכבת ממתקן מייצג משותף של קודד שתי כיוונים (BERT), שתי שכבות תשומת לב ספציפית למשימות, ושני מסווגים. Our key idea is to leverage both the task-discriminative and the inter-task shared features for country and province MSA/DA identification.  התוצאות הנקבלות מראות שמודל MTL שלנו מוביל מודלים משימה אחת ברוב השאלות.', 'ha': "Shiryoyin harshe na shiryoyin ayuka na ƙayyade Ga wannan takardan, Munã halatar da tsarin da aka samar da shi masu ƙaranci, da aka saka zuwa na NADA da aikin na biyu wanda aka raba wa aikin NADA na ƙasan-daraja da sifar-daraja na Madaidaici (MAA) da Larabci na Dialakal (DA). @ item: inmenu Text Completion @ info: whatsthis Maɓallinmu na wajen gaura da za'a cika aikin da za'a yi gaura da fassarar aiki da kuma masu raba fassarar aikin da ke iya haɗa su ga wuri da bayani na MAA/DA. Ana sami matsala ya nuna cewa misalinmu na MTL na samar da misalin aiki guda a kan masu yawa.", 'bo': 'དབྱིབས་དམ་པ་དང་སྔོན་སྒྲིག་སྐད་རིགས་དམིགས་འཛུགས་ནི་ཨ་རབ་ཀྱི་སྤྱིར་བཏང་བའི་སྐད་རིགས In this paper, we present our deep learning-based system, submitted to the second NADI shared task for country-level and province-level identification of Modern Standard Arabic (MSA) and Dialectal Arabic (DA). The system is based on an end-to-end deep Multi-Task Learning (MTL) model to tackle both country-level and province-level MSA/DA identification. The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers. ང་ཚོའི་གཙོ་ཆེ་བསམ་ནི་རྒྱལ་ཁབ་དང་རྒྱལ་ཁབ་གྱི་ཁྱད་ཆོས་དང་ཐོག་ལས་མཐུན་སྣེ་ཁྱད་དུ་གཏོང་ནི་ གྲངས་འབོར་ཡོད་པའི་འབྲས་བ་མང་ཙམ་མཁན་ལ་ང་ཚོའི་MTL མིག་དཔེ་དབྱིབས་གཞན་གཅིག་ལས་སྒྲུབ་བྱེད་མི་འདུག'}
{'en': 'Country-level Arabic Dialect Identification using RNNs with and without Linguistic Features', 'ar': 'تحديد اللهجة العربية على مستوى الدولة باستخدام RNNs مع وبدون ميزات لغوية', 'pt': 'Identificação de dialeto árabe em nível de país usando RNNs com e sem recursos linguísticos', 'es': 'Identificación de dialectos árabes a nivel de país mediante RNN con y sin características lingüísticas', 'fr': "Identification du dialecte arabe au niveau du pays à l'aide de RNN avec et sans caractéristiques linguistiques", 'ja': '言語的特徴の有無にかかわらず、RNNを使用した国レベルのアラビア語方言識別', 'hi': 'भाषाई विशेषताओं के साथ और बिना RNNs का उपयोग करके देश-स्तरीय अरबी बोली पहचान', 'zh': '用不言 RNN 国家级阿拉伯语方言', 'ru': 'Идентификация арабского диалекта на уровне страны с использованием RNN с лингвистическими признаками и без них', 'ga': 'Sainaithint Canúint Araibise ag leibhéal tíre ag baint úsáide as RNNanna le Gnéithe Teangeolaíochta agus gan Gnéithe Teangeolaíocha acu', 'hu': 'Országszintű arab dialekt azonosítás nyelvi jellemzőkkel és anélkül', 'el': 'Αναγνώριση αραβικού διαλέκτου σε επίπεδο χώρας με χρήση RNN με και χωρίς γλωσσικά χαρακτηριστικά', 'ka': 'Name', 'it': 'Identificazione dialettica araba a livello nazionale utilizzando RNN con e senza caratteristiche linguistiche', 'kk': 'Ел- деңгейі араб диалективтің идентификациясы, тілігвистикалық мүмкіндіктерімен және жоқ', 'lt': 'Country-level Arabic Dialect Identification using RNNs with and without Linguistic Features', 'ms': 'Pengenalan Dialeksi Arab-tahap negara menggunakan RNN dengan dan tanpa Ciri-ciri Bahasa', 'mk': 'Идентификација на арапски дијалект на ниво на земја користејќи РНН со и без јазички објекти', 'ml': 'RNNs ഉപയോഗിച്ചും ലിങ്ഗിസ്റ്റിക്ക് വിശേഷതകളില്ലാത്ത രാജ്യത്തിലെ അറബി ഡയലേക്ക് തിരിച്ചറിയുക', 'mn': 'Улс-түвшин Араб Диалоктын Хэрэглэгчийн Хэрэглэгчийн Хэрэглэгчийн Хэрэглэгчийн Хэрэглэгчийг ашиглаж', 'mt': 'Identifikazzjoni tad-Dijaletta Għarbija fil-livell tal-pajjiż bl-użu ta’ RNNs bi u mingħajr Karatteristiċi Lingwistiċi', 'no': 'Country-level Arabic Dialect Identification using RNN with and without Linguistic Features', 'pl': 'Identyfikacja dialektu arabskiego na poziomie kraju przy użyciu RNN z i bez cech językowych', 'ro': 'Identificarea dialectelor arabe la nivel național utilizând RNN-uri cu și fără caracteristici lingvistice', 'sr': 'Идентификација арабског диалекта на страни користи RNN са лингвистичким функцијама и без', 'si': 'Name', 'so': 'Identification of dialect Arabic Dialect using RNs with and without Linguistic Features', 'sv': 'Arabisk dialekt identifiering på landsnivå med hjälp av RNN med och utan språkliga funktioner', 'ur': 'Country-level Arabic Dialect Identification using RNN with and without Linguistic Features', 'ta': 'Name', 'uz': 'Name', 'vi': 'Biểu tượng ngôn ngữ quốc gia Name', 'bg': 'Идентификация на арабски диалект на ниво държава, използвайки RNN с и без лингвистични характеристики', 'da': "Arabisk dialekt identifikation på landeniveau ved hjælp af RNN'er med og uden sproglige funktioner", 'hr': 'Identifikacija dijalekta na zemlji na arapskoj nivou koristeći RNN sa i bez Linguističkih karakteristika', 'nl': "Landelijke Arabische dialectidentificatie met behulp van RNN's met en zonder taalkundige kenmerken", 'de': 'Länderebene arabische Dialektidentifikation mittels RNNs mit und ohne sprachliche Merkmale', 'id': 'Country-level Arabic Dialect Identification using RNNs with and without Linguistic Features', 'fa': 'با استفاده از RNN با و بدون ویژه\u200cهای لینگیستیک', 'sw': 'Utambulisho wa Tamko la Kiarabu kwa kutumia RNN na bila Tamko za Kilinguistic', 'af': 'Land-vlak Arabiese Dialeksie Identifikasie gebruik RNN met en sonder Linguistiese Funksies', 'tr': 'Selah derejesi Arapça Diýatlandyrma Kimligi Diller bilen we çykyş özelliklerinden ullanýan', 'sq': 'Identifikimi i dialektit arab në nivel të vendit duke përdorur RNN me dhe pa funksione gjuhësore', 'ko': '언어 특성이 있거나 없는 RNN을 사용하여 국가급 아랍어 사투리 식별', 'am': 'የመስመር ምርጫዎች', 'az': '칖lk톛 s톛viyy톛si Arap칞as캼 Dialekt Kimlikl톛ri, Linguistik M칲mk칲nl칲kl톛ri il톛 v톛 olmadan RNN qullan캼rlar', 'bs': 'Identifikacija dijalekta na zemlji na arapskoj nivou koristeći RNN sa i bez Lingističkih karakteristika', 'ca': 'Identificació de diàlectes àrabs a nivell nacional utilitzant RNN amb i sense característiques lingüístiques', 'bn': 'RNNs ব্যবহার করে এবং লিঙ্গিস্টিক বৈশিষ্ট্য ছাড়া দেশের স্তরের আরবী ডায়ালেক্টর পরিচয় ব্যবহার করে', 'et': 'Riigi tasandil araabia dialekti identifitseerimine, kasutades RNN-sid koos keeleliste omadustega ja ilma', 'cs': 'Identifikace arabského dialektu na úrovni zemí pomocí RNN s a bez jazykových vlastností', 'fi': 'Maatason arabiankielinen dialektitunnistus käyttäen RNN-numeroita, joilla on ja ilman kielellisiä ominaisuuksia', 'hy': 'Արքային մակարդակի արաբական դիալեկտի հայտնաբերումը՝ օգտագործելով ՌՆԹ-ներ լեզվական առանձնահատկություններով և առանց դրանց', 'jv': 'name', 'ha': 'KCharselect unicode block name', 'sk': 'Identifikacija arabskega dialekta na ravni države z uporabo RNN z jezikovnimi značilnostmi in brez njih', 'bo': 'Country-level Arabic Dialect Identification using RNNs with and without Linguistic Features', 'he': 'זיהוי דיאלקט ערבי ברמה מדינית באמצעות RNN עם ולא תכונות שפתיות'}
{'en': 'This work investigates the value of augmenting recurrent neural networks with feature engineering for the Second Nuanced Arabic Dialect Identification (NADI) Subtask 1.2 : Country-level DA identification. We compare the performance of a simple word-level LSTM using pretrained embeddings with one enhanced using feature embeddings for engineered linguistic features. Our results show that the addition of explicit features to the LSTM is detrimental to performance. We attribute this performance loss to the bivalency of some linguistic items in some text, ubiquity of topics, and participant mobility.', 'ar': 'يبحث هذا العمل في قيمة زيادة الشبكات العصبية المتكررة باستخدام هندسة الميزات للمهمة الفرعية الثانية لتعريف اللهجات العربية الدقيقة (NADI) 1.2: تحديد DA على مستوى الدولة. نحن نقارن أداء LSTM البسيط على مستوى الكلمة باستخدام حفلات الزفاف المسبقة الصنع بأداء محسّن باستخدام ميزة التضمين للميزات اللغوية المصممة هندسيًا. تظهر نتائجنا أن إضافة ميزات واضحة إلى LSTM يضر بالأداء. نعزو هذا الخسارة في الأداء إلى ثنائية التكافؤ لبعض العناصر اللغوية في بعض النصوص ، ووجود الموضوعات في كل مكان ، وتنقل المشاركين.', 'es': 'Este trabajo investiga el valor de aumentar las redes neuronales recurrentes con ingeniería de características para la segunda subtarea 1.2 de identificación de dialectos árabes matizados (NADI): identificación de DA a nivel de país. Comparamos el rendimiento de un LSTM simple a nivel de palabra que utiliza incrustaciones previamente entrenadas con uno mejorado que utiliza incrustaciones de funciones para funciones lingüísticas diseñadas. Nuestros resultados muestran que la adición de funciones explícitas al LSTM es perjudicial para el rendimiento. Atribuimos esta pérdida de rendimiento a la bivalencia de algunos elementos lingüísticos en algún texto, la ubicuidad de los temas y la movilidad de los participantes.', 'pt': 'Este trabalho investiga o valor de aumentar as redes neurais recorrentes com engenharia de recursos para a Subtarefa 1.2 de Identificação do Segundo Dialeto Árabe Nuanced (NADI): Identificação de DA em nível de país. Comparamos o desempenho de um LSTM simples em nível de palavra usando embeddings pré-treinados com um aprimorado usando embeddings de recursos para recursos linguísticos projetados. Nossos resultados mostram que a adição de recursos explícitos ao LSTM é prejudicial ao desempenho. Atribuímos essa perda de desempenho à bivalência de alguns itens linguísticos em algum texto, ubiquidade de tópicos e mobilidade dos participantes.', 'fr': "Ce travail étudie la valeur de l'augmentation des réseaux de neurones récurrents avec l'ingénierie des caractéristiques pour la sous-tâche 1.2\xa0: identification de l'AD au niveau du pays (Second Nuanced Arabic Dialect Identification) (NADI). Nous comparons les performances d'un LSTM simple au niveau des mots utilisant des intégrations préentraînées avec un module amélioré utilisant des intégrations de fonctionnalités pour les fonctionnalités linguistiques techniques. Nos résultats montrent que l'ajout de fonctionnalités explicites au LSTM nuit aux performances. Nous attribuons cette perte de performance à la bivalence de certains éléments linguistiques dans certains textes, à l'omniprésence des sujets et à la mobilité des participants.", 'ja': 'この研究では、第2のニュアンスのあるアラビア方言識別（ NADI ）サブタスク1.2 ：国レベルのDA識別のための機能エンジニアリングを使用した再帰的ニューラルネットワークの拡張の価値を調査します。私たちは、事前に訓練された埋め込みを使用した単語レベルのLSTMのパフォーマンスと、工学的な言語機能のための機能埋め込みを使用した強化されたLSTMのパフォーマンスを比較します。私たちの結果は、LSTMに明示的な機能を追加することは、パフォーマンスに有害であることを示しています。このパフォーマンスの損失は、いくつかのテキスト内のいくつかの言語アイテムの二価性、トピックの普遍性、および参加者の移動性に起因すると考える。', 'hi': 'यह काम दूसरी बारीक अरबी बोली पहचान (NADI) Subtask 1.2 के लिए सुविधा इंजीनियरिंग के साथ आवर्तक तंत्रिका नेटवर्क को बढ़ाने के मूल्य की जांच करता है: देश स्तर डीए पहचान। हम एक सरल शब्द-स्तरीय LSTM के प्रदर्शन की तुलना pretrained embeddings का उपयोग कर इंजीनियर भाषाई सुविधाओं के लिए सुविधा embeddings का उपयोग कर एक बढ़ाया के साथ. हमारे परिणामों से पता चलता है कि LSTM के लिए स्पष्ट सुविधाओं के अलावा प्रदर्शन के लिए हानिकारक है. हम इस प्रदर्शन के नुकसान को कुछ पाठ, विषयों की सर्वव्यापकता और प्रतिभागी गतिशीलता में कुछ भाषाई वस्तुओं की द्विपक्षीयता के लिए जिम्मेदार ठहराते हैं।', 'zh': '考用特征工增递归神经网络之直,以第二细微差别阿拉伯语方言识(NADI)子职1.2:国家级DA识。 吾将用预练销单词级 LSTM 与用功销增强型 LSTM 之性较之,以成其功。 吾之的结果表明,加之LSTM中显式功能害性。 吾辈以此性损归因于某文本中某语项目之二价性,题无不在及参与者之流动性。', 'ru': 'В данной работе исследуется значение дополнения рекуррентных нейронных сетей конструкцией признаков для подзадачи 1.2 «Идентификация второго нюансового арабского диалекта (NADI)»: «Идентификация DA на уровне страны». Мы сравниваем производительность простого LSTM уровня слова с использованием предварительно обученных вложений с одной улучшенной функцией с использованием вложений для инженерных лингвистических особенностей. Наши результаты показывают, что добавление явных признаков к LSTM наносит ущерб производительности. Мы относим эту потерю производительности на счет двоякости некоторых лингвистических элементов в некотором тексте, повсеместности тем и мобильности участников.', 'ga': 'Fiosraíonn an obair seo an luach a bhaineann le líonraí néaracha athfhillteacha a mhéadú le gné-innealtóireacht don Dara Aitheantas Canúint Araibise Nuashonraithe (NADI) Fothasc 1.2: Sainaithint DA ag leibhéal tíre. Déanaimid comparáid idir feidhmíocht LSTM leibhéal focal simplí ag baint úsáide as leabaithe réamhoilte le ceann feabhsaithe ag baint úsáide as leabú gné le haghaidh gnéithe teangeolaíochta innealtóireachta. Léiríonn ár dtorthaí go ndéanann gnéithe follasacha a chur leis an LSTM dochar don fheidhmíocht. Cuirimid i leith an chaillteanais feidhmíochta seo don débhlas atá i roinnt míreanna teanga i dtéacs áirithe, uileláithreacht na dtopaicí, agus soghluaisteacht rannpháirtithe.', 'hu': 'Jelen munka az ismétlődő neurális hálózatok fejlesztésének értékét vizsgálja a második Nuanced Arab Dialekt Identification (NADI) 1.2. alcsoport: Országszintű DA azonosítás. Összehasonlítjuk egy egyszerű szószintű LSTM teljesítményét, amely előkészített beágyazásokat használ, és amelyeket a fejlesztett nyelvi funkciók számára fejlesztett beágyazásokkal használnak. Eredményeink azt mutatják, hogy az LSTM kifejezett funkcióinak hozzáadása káros a teljesítményre. Ezt a teljesítményvesztést bizonyos nyelvi elemek kettősségének tulajdonítjuk bizonyos szövegekben, a témák mindenütt jelenlétének és a résztvevők mobilitásának.', 'el': 'Η παρούσα εργασία διερευνά την αξία της ενίσχυσης επαναλαμβανόμενων νευρωνικών δικτύων με μηχανική χαρακτηριστικών για την Υποεργασία 1.2: Αναγνώριση σε επίπεδο χώρας. Συγκρίνουμε την απόδοση ενός απλού επιπέδου λέξεων χρησιμοποιώντας προκαθορισμένες ενσωματώσεις με μια βελτιωμένη χρήση ενσωματωμένων χαρακτηριστικών για μηχανικά γλωσσικά χαρακτηριστικά. Τα αποτελέσματά μας δείχνουν ότι η προσθήκη ρητών χαρακτηριστικών στο LSTM είναι επιζήμια για την απόδοση. Αποδίδουμε αυτή την απώλεια απόδοσης στη διμερότητα ορισμένων γλωσσικών στοιχείων σε κάποιο κείμενο, την πανταχού παρουσία θεμάτων και την κινητικότητα των συμμετεχόντων.', 'it': "Questo lavoro indaga il valore dell'aumento delle reti neurali ricorrenti con feature engineering per la Seconda Identificazione Dialettica Araba Nuanced (NADI) Sottotask 1.2: Identificazione DA a livello nazionale. Confrontiamo le prestazioni di un LSTM semplice a livello di parola che utilizza incorporazioni pre-addestrate con una migliorata che utilizza incorporazioni di funzionalità per funzionalità linguistiche ingegnerizzate. I nostri risultati mostrano che l'aggiunta di funzionalità esplicite al LSTM è dannosa per le prestazioni. Attribuiamo questa perdita di performance alla bivalenza di alcuni elementi linguistici in alcuni testi, all'ubiquità degli argomenti e alla mobilità dei partecipanti.", 'kk': 'Бұл жұмыс қайталанатын невралды желілерді екінші қайталанатын араб диалекті идентификациясы (NADI) 1. 2- тапсырмасы: Ел- деңгейіндегі DA идентификациясы үшін қайталанатын невралдық желілерді Біз инженерлік лингвистикалық мүмкіндіктерді инженерлік үшін қарапайым сөз деңгейінің LSTM жұмысын қарапайым салыстырамыз. Біздің нәтижелеріміз LSTM- ге түсінікті мүмкіндіктерді қосу нәтижесінің қауіпсіздігін көрсетеді. Біз бұл әрекетті кейбір мәтіндегі лингвистикалық нысандар, нақыштардың көпшілігін және қатысушылардың көпшілігіне қатысуға арналған.', 'mk': 'Оваа работа ја истражува вредноста на зголемувањето на рецидентните нервни мрежи со инженерство на карактеристики за втората развиена арапска идентификација на дијалектот (НАДИ) подзадача 1.2: идентификација на ДА на ниво на земја. Ги споредуваме изведувањата на едноставен ЛСТМ на зборно ниво користејќи претренирани вградувања со една подобрена користејќи вградувања на карактеристики за инженерирани јазични карактеристики. Нашите резултати покажуваат дека додавањето на експлицитни карактеристики на ЛСТМ е штетно за изведувањето. Ја припишуваме оваа загуба на резултатите на двојноста на некои јазички предмети во некои тексти, насекаде на теми и мобилноста на учесниците.', 'ml': 'രണ്ടാമത്തെ നുയാങ്ങ് ചെയ്ത അറബി ഡയലക്ട്രിക്ക് തിരിച്ചറിയുന്നതിനുള്ള പ്രത്യേക പ്രവൃത്തികളുടെ വിഭാഗത്തിന്റെ മൂല്യം ആവര്\u200dത്തിക്കുന്നതിനുള എഞ്ചിനീയറ്റപ്പെട്ട ഭാഷ വിശേഷതകള്\u200dക്ക് വേണ്ടി ഒരു സാധാരണ വാക്ക്-നില LSTM പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനെക്കുറിച്ച് ഞങ്ങള്\u200d താല്\u200dക നമ്മുടെ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് എല്\u200dസ്റ്റിഎമിലേക്കുള്ള വ്യക്തമായ പ്രകടനത്തിന്റെ കൂട്ടിയ ചില ല ലേഖനങ്ങളിലുള്ള ഭാഷകങ്ങളുടെ ബൈവാലിസ്റ്റിക്ക് നഷ്ടമായ ഈ പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് നമ്മള്\u200d വ്യക്തമാക്കുന്നു. വിഷയങ്ങളു', 'lt': 'Šiuo darbu tiriama rekurencinių nervų tinklų, turinčių charakteristikų inžineriją antrajam branduoliniam arabų dialekto identifikavimui (NADI), didinimo vertė 1.2 poskirsnyje: šalies lygmens DA identifikavimas. We compare the performance of a simple word-level LSTM using pretrained embeddings with one enhanced using feature embeddings for engineered linguistic features.  Mūsų rezultatai rodo, kad aiškių savybių įtraukimas į LSTM kenkia veiklos rezultatams. Šis veiklos nuostolis priskiriamas tam tikrų kalbinių dalykų dvivalentiškumui tam tikruose tekstuose, temų įvairovei ir dalyvių judumui.', 'mt': 'Dan ix-xogħol jinvestiga l-valur taż-żieda fin-netwerks newrali rikorrenti b’inġinerija tal-karatteristiċi għat-Tieni Identifikazzjoni tad-Dijaletti Għarab Nuanced (NADI) Sottokompitu 1.2: Identifikazzjoni DA fil-livell tal-pajjiż. Aħna nqabblu l-prestazzjoni ta’ LSTM sempliċi fil-livell tal-kliem bl-użu ta’ inkorporazzjonijiet imħarrġa minn qabel ma’ inkorporazzjoni waħda mtejba bl-użu ta’ inkorporazzjonijiet ta’ karatteristiċi għal karatteristiċi lingwistiċi inġinerizzati. Ir-riżultati tagħna juru li ż-żieda ta’ karatteristiċi espliċiti mal-LSTM hija ta’ ħsara għall-prestazzjoni. Dan it-telf fil-prestazzjoni huwa attribwit għad-bivalenza ta’ xi elementi lingwistiċi f’xi test, kullimkien ta’ suġġetti, u l-mobilità tal-parteċipanti.', 'ms': 'Kerja ini menyelidiki nilai untuk meningkatkan rangkaian saraf berulang dengan teknik ciri untuk Pengenalan Dialeksi Arab Kedua (NADI) Subtugas 1.2: Pengenalan DA aras negara. Kami membandingkan prestasi LSTM aras perkataan sederhana menggunakan penyembedding terlatih sebelum dilatih dengan satu yang ditambah menggunakan penyembedding ciri untuk ciri-ciri bahasa yang direka. Hasil kami menunjukkan bahawa tambahan ciri-ciri eksplicit ke LSTM merugikan prestasi. We attribute this performance loss to the bivalency of some linguistic items in some text, ubiquity of topics, and participant mobility.', 'no': 'Dette arbeidet undersøker verdien for å auka gjentaande neuralnettverk med funksjonsengineering for den andre Nuanced Arabic Dialect Identification (NADI) underoppgåva 1.2: Land-level DA identifikasjon. Vi samanliknar utviklinga av ein enkel ord- nivå LSTM ved å bruka pretrained innbygging med ein forbetra med innbygging av funksjonar for ingeniørte lingviske funksjonar. Resultatet våra viser at tillegget av eksplisitte funksjonar til LSTM er forandrande til utviklinga. Vi attributtar denne utføringsfeilinga til det gjennomsnittsfeiligheten av nokre lingviske element i noen tekst, omslag av emne og deltakarsmobilitet.', 'ka': 'ეს სამუშაო განსხვავება განსხვავებული ნეიროლური ქსელების მნიშვნელობა, რომელიც განსხვავებული მეორე ნუანსიური არაბური დიალექტის განსხვავება (NADI) სამუშაო სამუშაო 1.2: ქვე ჩვენ მარტივი სიტყვის სიტყვის დონეზე LSTM გამოყენებთ, რომლის გამოყენება პრერეინცირებული ინბედინტებით ერთი უფრო მეტირებული გამოყენებული ფუნქციების ინბეინზიერ ჩვენი წარმოდგენები გამოჩვენება, რომ LSTM-ს გამოყენება გამოსახულებელია. ჩვენ ატრიბუტირებთ ეს პროცემენტის დასრულებას რამდენიმე ლენგურისტიკური ელემენტების ორგანათობაზე, რამდენიმე ტექსტიში, ტექსტის სამყაროდ და მოთავსებელ', 'pl': 'Niniejsza praca bada wartość rozszerzania powtarzających się sieci neuronowych o inżynierię funkcjonalną dla drugiego nuancowanego dialektu arabskiego (NADI) podzadania 1.2: identyfikacja DA na poziomie kraju. Porównujemy wydajność prostego LSTM na poziomie słów wykorzystującego wstępnie trenowane osadzenia z jednym ulepszonym przy użyciu osadzeń funkcji dla zaprojektowanych funkcji językowych. Nasze wyniki pokazują, że dodanie wyraźnych cech do LSTM jest szkodliwe dla wydajności. Utratę wydajności przypisujemy dwuwalencji niektórych elementów językowych w niektórych tekstach, wszechobecności tematów i mobilności uczestników.', 'ro': 'Această lucrare investighează valoarea creșterii rețelelor neurale recurente cu tehnologie de caracteristici pentru Subsarcina 1.2: Identificarea DA la nivel național. Comparăm performanțele unui LSTM simplu la nivel de cuvânt utilizând încorporări pre-instruite cu una îmbunătățită utilizând încorporări de caracteristici pentru caracteristici lingvistice proiectate. Rezultatele noastre arată că adăugarea de caracteristici explicite la LSTM este dăunătoare performanței. Atribuim această pierdere de performanță bivalenței unor elemente lingvistice din anumite texte, ubiquității subiectelor și mobilității participanților.', 'so': 'Shaqadaasu wuxuu baarayaa qiimaha la kordhiyo shabakada neurada ee soo socda oo ku qoran maamulka aqoonsiga labaad ee afka labaad ee nuanced (NADI) Waxaynu isbarbardhignaa muuqashada heerka LSTM oo fudud ah oo lagu isticmaalayo qalabka afka lagu soo bandhigay Our results show that the addition of explicit features to the LSTM is detrimental to performance.  Waxyaabaha luuqadaha qaarkood waxaynu ku qornaa khasaarada sameynta, dhamaantooda maadooyinka iyo dhaqdhaqaaqyada qayb-qaadashada.', 'si': 'මේ වැඩේ පරීක්ෂණය කරන්නේ පුනරුද්ධ න්\u200dයූරල් ජාලයේ විශේෂණය සඳහා දෙවෙනි න්යූන්ස් අරාබි දියාලෙක්ට පරීක්ෂණය (NADI) ප්\u200dරතික අපි සාමාන්\u200dය වචන ලැබුණු LSTM වලට ප්\u200dරිට්\u200dරේන්ඩ් ඇම්බෙන්ඩින්ග් භාෂාත්මක විශේෂතාවක් සඳහා විශේෂතාවක් භාවි අපේ ප්\u200dරතිචාරය පෙන්වන්නේ LSTM වලට ප්\u200dරතිශීල විශේෂ අවශ්\u200dයය සම්බන්ධ වෙන්න ප්\u200dරතිචාරයක් වි අපි මේ ක්\u200dරියාත්මක නැති වෙනුවෙන් භාෂාවික අයිතියක් වලින් පාළුවක්, විදේශ අයිතිකාරය, සහ සම්බන්ධ සංවේ', 'sr': 'Ovaj rad istražuje vrijednost povećanja rekonstruiranih neuralnih mreža sa funkcionalnim inženjerstvom za drugu nuanciranu arapsku identifikaciju dijalekta (NADI) podzadatak 1.2: identifikacija tužilaštva na zemlji. Uspoređujemo provedbu jednostavnog LSTM nivoa riječi koristeći pretkišene ugradnje sa jednim poboljšanim korištenjem funkcionalnih ugradnji za inženjerene jezičke funkcije. Naši rezultati pokazuju da je dodavanje pojasnih karakteristika LSTM štetno za izvođenje. Pripisujemo gubitak izvedbe na dvovalentnost nekih lingvističkih predmeta u nekom tekstu, svjetlost tema i mobilnost učesnika.', 'sv': 'Detta arbete undersöker värdet av att öka återkommande neurala nätverk med funktionsteknik för den andra Nuanced Arabic Dialect Identification (NADI) Underuppgift 1.2: Landsnivå DA identifiering. Vi jämför prestandan hos en enkel LSTM på ordnivå med förkränade inbäddningar med en förbättrad med funktionsinbäddningar för avancerade språkliga funktioner. Våra resultat visar att tillägg av explicita funktioner till LSTM är skadlig för prestanda. Vi tillskriver denna prestationsförlust till tvåvalensen hos vissa språkliga objekt i viss text, allestädes förekomst av ämnen och deltagarnas rörlighet.', 'ta': 'இந்த வேலை தேடுகிறது மீண்டும் நிலையான புதிய வலைப்பின்னல்களின் மதிப்பை தேர்ந்தெடுக்கிறது இரண்டாம் துணைப்பிடப்பட்ட அரபி உரையாடல் அடையாளம் (NADI) உப நாம் எளிய வார்த்தை- மட்டத்தின் செயல்பாட்டை LSTM மூலம் ஒப்பிடுகிறோம் பொறியிடப்பட்ட மொழி குணங்களை பயன்படுத்தி மேம்படுத்தும் தன் நம் முடிவுகள் LSTM கூட்டுதல் வெளிப்படையான குணங்கள் என்பதை காட்டுகிறது என்பது செயல்படுத்தலுக்கு தகுதியானது. நாம் இந்த செயல்பாட்டின் இழப்பை சில மொழி உருப்படிகளின் ஒத்திசையில் குறிப்பிடுகிறோம், தலைப்புகளின் ஒத்திசையாக, மற்', 'ur': 'یہ کام دوسری نائنس عربی ڈائیلٹ شناسیٹ (NADI) Subtask 1.2 کے لئے دوبارہ نیورل نیورل نیٹ ورک کے مطابق اضافہ کرنے کی ارزش کا تحقیق کرتا ہے۔ ہم ایک ساده لفظ سطح LSTM کی عملکرد کو اس طرح مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید استعمال کرتے ہیں۔ ہمارے نتیجے دکھاتے ہیں کہ LSTM کے کھول کھول کھول کھول کھول کھول کھول دینے کا اضافہ کرنا کامیابی کے لئے مصیبت ہے۔ ہم اسے ایک ٹیکسٹ میں ایک زبان شناسی اتمام کے دوسرے برابر خسارہ کے ذریعے خسارہ کے ذریعے پیش کرتے ہیں، موضوع کی جگہ، اور مشرکین حرکت کے ذریعے.', 'mn': 'Энэ ажил хоёр дахь Nuanced Arabic Dialect Identification (NADI) Subtask 1.2: Улс-түвшин DA идентификацийн инженерчлэлтэй дахин дахин дахин мэдрэлийн сүлжээний утгыг судалдаг. Бид энгийн үг хэмжээний LSTM-ын үйл ажиллагааг инженерийн хэлний чадваруудын хувьд нэмэгдүүлэгдсэн хэлбэртэй холбоотой нэг нэмэгдүүлэгддэгтэй харьцуулдаг. Бидний үр дүнд LSTM-д тодорхой чадваруудыг нэмэх нь үйл ажиллагаанд хохиромжтой гэдгийг харуулдаг. Бид энэ үйл ажиллагааны алдагдлыг зарим текст, сэдэв бүрэн, оролцогчдын хөдөлгөөнөөс хоёр дахин ижил хэлбэртэй зүйлсийг харуулдаг.', 'uz': "Name Biz oddiy so'zlar darajasi LSTM bajarishini o'xshash qilamiz, biz tashkilotli tillar imkoniyatlariga qo'shilgan xossalardan foydalanish mumkin. Natijalarning natijalarimizni ko'rsatadi, LSTM'ning shaxsiy xususiyatlarini qoʻshish bajarishga juda zarur. Biz bu amalni bir necha lingvistik narsalarning bir necha matn, mavzularning o'xshash va qismlarning hammasini bajaramiz.", 'vi': 'Công trình này nghiên cứu giá trị của việc tăng cường các mạng thần kinh liên tục với bộ phận kỹ thuật đặc trưng cho bộ phận nhận diện A.A.I.I. Phân tích phân biệt ngôn ngữ A.2: Chúng tôi so sánh kết quả của một tập hợp ngôn ngữ đơn giản, dùng sự nhúng tay trước với một sự tăng cường, sử dụng sự gắn kết đặc trưng cho các tính năng ngôn ngữ. Kết quả của chúng tôi cho thấy việc thêm các tính năng dứt khoát vào LSTM là không có tác dụng. Chúng tôi quy định sự mất đi khả năng này cho sự kết hợp của một số thứ ngôn ngữ trong một số văn bản, bất hợp chủ đề, và sự di chuyển của người tham gia.', 'hr': 'Ovaj rad istražuje vrijednost povećanja povratnih neuralnih mreža s funkcionalnim inženjerstvom za drugu povratnu arapsku identifikaciju dijalekta (NADI) podzadatak 1.2: identifikacija tužilaštva na zemlji. Uspoređujemo učinkovitost jednostavnog razine riječi LSTM koristeći pretkišene integracije sa jednim poboljšanim korištenjem funkcionalnih integracija za inženjerene jezičke funkcije. Naši rezultati pokazuju da je dodanje pojasnih karakteristika LSTM-u štetno djelovanju. Pripisujemo gubitak uspjeha na dvovalentnost nekih lingvističkih predmeta u nekom tekstu, svjetlost tema i mobilnost učesnika.', 'da': 'Dette arbejde undersøger værdien af at øge tilbagevendende neurale netværk med feature engineering til den anden Nuanced Arabic Dialect Identification (NADI) Underopgave 1.2: Land-niveau DA identifikation. Vi sammenligner ydeevnen af en simpel LSTM på ordniveau ved hjælp af forudtrænede indlejringer med en forbedret ved hjælp af funktionsindlejringer til konstruerede sproglige funktioner. Vores resultater viser, at tilføjelsen af eksplicitte funktioner til LSTM er skadelig for ydeevnen. Vi tilskriver dette tab af performance til bivalensen af nogle sproglige elementer i nogle tekster, allestedsnærværelsen af emner og deltagernes mobilitet.', 'nl': 'Dit werk onderzoekt de waarde van het uitbreiden van terugkerende neurale netwerken met feature engineering voor de Second Nuanced Arabic Dialect Identification (NADI) Subtask 1.2: Country-level DA identificatie. We vergelijken de prestaties van een eenvoudige LSTM op woordniveau met behulp van vooraf getrainde embeddings met één verbeterd met feature embeddings voor technische linguïstische functies. Onze resultaten tonen aan dat de toevoeging van expliciete functies aan de LSTM nadelig is voor de prestaties. We schrijven dit prestatieverlies toe aan de bivalentie van sommige taalkundige items in sommige teksten, alomtegenwoordigheid van onderwerpen en mobiliteit van deelnemers.', 'id': 'Pekerjaan ini menyelidiki nilai dari meningkatkan jaringan saraf berkurang dengan teknik fitur untuk Identifikasi Dialek Arab Kedua (NADI) Subtask 1.2: Identifikasi DA tingkat negara. Kami membandingkan prestasi dari LSTM tingkat kata sederhana menggunakan embedding terlatih sebelumnya dengan satu yang diperbaiki menggunakan embedding fitur untuk fitur bahasa yang direncanakan. Our results show that the addition of explicit features to the LSTM is detrimental to performance.  Kami atribut kehilangan pertunjukan ini kepada dua valensi beberapa item bahasa dalam beberapa teks, di mana-mana topik, dan mobilitas peserta.', 'ko': '이 작업은 특징 공학으로 귀속신경 네트워크를 강화하여 두 번째 미세한 아랍 방언 식별(NADI) 서브퀘스트 1.2: 국가급 DA 식별의 가치를 연구했다.우리는 미리 훈련된 삽입을 사용하는 간단한 단어급 LSTM과 특징을 사용한 삽입된 공학 언어 특징을 비교하여 LSTM의 성능을 향상시켰다.결과적으로 LSTM에 명시적 기능을 추가하는 것은 성능에 좋지 않습니다.우리는 이러한 성능 손실을 일부 텍스트에서 일부 언어 항목의 2가성, 주제의 보편성과 참여자의 유동성에 기인할 것이다.', 'bg': 'Настоящата работа изследва стойността на увеличаването на повтарящи се невронни мрежи с инженеринг на функции за Втората нуанширана арабска диалектна идентификация (NADI) Подзадача 1.2: Идентификация на ДА на ниво държава. Сравняваме ефективността на проста дума-ниво използваща предварително тренирани вграждания с едно подобрено използване на вграждания на функции за инженерни лингвистични функции. Нашите резултати показват, че добавянето на изрични функции към ЛТМ е вредно за производителността. Приписваме тази загуба на представяне на двувалентността на някои езикови елементи в даден текст, навлизането на темите и мобилността на участниците.', 'fa': 'این کار ارزش افزایش شبکه\u200cهای عصبی بازگشت را با مهندسی ویژه\u200cای برای شناسایی شناسایی دومین شناسایی Dialect عربی (NADI) زیر کار ۱.۲ تحقیق می\u200cکند. ما عملکرد یک سطح کلمه ساده LSTM را با استفاده از ابتدایی\u200cهای پیش\u200cرین با یکی از ابتدایی\u200cهای ویژه\u200cهای بیشتر برای ویژه\u200cهای زبان مهندسی مقایسه می\u200cکنیم. نتیجه\u200cهای ما نشان می\u200cدهند که اضافه کردن ویژه\u200cهای خاصی به LSTM به انجام\u200cدادن خطرناک است. ما این عملکرد را به دو برابر برخی از چیزهای زبان\u200cشناسی در بعضی متن، همه\u200cی موضوع و حرکت\u200cهای مشترک نسبت می\u200cدهیم.', 'sw': 'Kazi hii inachunguza thamani ya kuongeza mitandao ya neura yanayoendelea kwa ajili ya utambulisho wa Kiarabu wa pili wa Utafiti wa Taifa (NADI) 1.2: Utambulisho wa DA wa ngazi ya nchi. Tunawalinganisha utendaji wa LSTM wa ngazi rahisi kwa kutumia vifaa vinavyotangazwa na moja kwa kutumia vifaa vya lugha zilizotengenezwa. Matokeo yetu yanaonyesha kuwa kuongezea vipengele vya wazi kwa LSTM ni vibaya kufanya kazi. We attribute this performance loss to the bivalency of some linguistic items in some text, ubiquity of topics, and participant mobility.', 'de': 'Diese Arbeit untersucht den Wert der Erweiterung wiederkehrender neuronaler Netze mit Feature Engineering für die zweite nuancierte arabische Dialektidentifikation (NADI) Teilaufgabe 1.2: Länderebene DA Identifikation. Wir vergleichen die Leistung eines einfachen LSTM auf Wortebene, das vorgetrainierte Einbettungen verwendet, mit einem, das durch Feature Einbettungen für technische linguistische Features verbessert wird. Unsere Ergebnisse zeigen, dass die Hinzufügung expliziter Features zum LSTM leistungsnachteilig ist. Wir führen diesen Leistungsverlust auf die Bivalenz einiger sprachlicher Elemente in einigen Texten, die Allgegenwart von Themen und die Mobilität der Teilnehmer zurück.', 'tr': "Bu işe ikinji Nuanced Arapça Dialect Kimligi (NADI) Subtask 1.2: Country-level DA kimligi bilen tekrarlanan näral şebekeleriň azalyşygyny barlaýar. Biz ýeňil kelime derejesi LSTM'i pretrained ekleýän guramlaryň enjiniýet lingwistiki özellikleri üçin gelişmiş özellikleri bilen karşılaştyrýarys. Biziň netijelerimiz LSTM'a açık möhümleriň toplamynyň etkinleşmegi näsirli bolandygyny görkezýär. Biz bu zady käbir metin, meýdanlaryň her ýerinde we iştirakçi hereketleriň birnäçe dil zadynyň ikinji ýagdaýyna süýtgedýäris.", 'am': 'ይህ ሥራ የሁለተኛው ነጥብ አረቢያ Dialect (NADI) አዲስ ስራ 1.2: አገር-level DA identification አካባቢ የንግግር ደረጃ LSTM አካሄዱን በመጠቀም እናሳያታለን፡፡ ፍሬዎቻችን ለLSTM ግልፅ የሚጨመር የግልፅ ምርጫዎች ለመፈጸም ጉዳይ ነው፡፡ ይህ የቋንቋ ቋንቋዊ ነገሮች በጥቅነት፣ የጦማሪያዎች ብልሃት እና ተጋሪዎች መንቀሳቅስ እናስቀራለን፡፡', 'sq': 'Ky punë heton vlerën e rritjes së rrjeteve neurale të përsëritura me inxhinierinë e karakteristikave për Identifikimin e Dytë të Dialektit Arab (NADI) nëndetyrën 1.2: Identifikimi në nivel të vendit DA. Ne krahasojmë shfaqjen e një LSTM të thjeshtë me fjalë duke përdorur përfshirje të parastërvitura me një të përmirësuar duke përdorur përfshirje të funksioneve për funksione gjuhësore të inxhinieruara. Rezultatet tona tregojnë se shtimi i karakteristikave të qarta në LSTM është i dëmshëm për performancën. Ne e atribuojmë këtë humbje paraqitjeje dyvalencës së disa objekteve gjuhësore në disa tekste, gjithandej të temave dhe lëvizjes së pjesëmarrësve.', 'af': "Hierdie werk ondersoek die waarde van vergroot herhaalde neuralnetwerke met funksie inženiering vir die tweede Nuanced Arabiese Dialect Identifikasie (NADI) Subtaak 1. 2: Land- vlak DA identifikasie. Ons vergelyk die prestasie van 'n eenvoudige woord vlak LSTM deur te gebruik pretrained inbêdings met een verbeter met gebruik van funksie inbêdings vir ingenieërde lingwisiese funksies. Ons resultate wys dat die byvoeg van eksplisiese funksies aan die LSTM is verkeerd na prestasie. Ons eienskap hierdie prestasie verloor aan die bievalligheid van sommige lingwisiese items in sommige teks, onderwerp van onderwerpe en deelnadeerde mobiliteit.", 'az': "Bu işlər ikinci Nuanced Arab Dialect Identification (NADI) Subtask 1.2: Country-level DA identification üçün fərqli inženjeri ilə tekrar nöral ağlarını artırmaq qiymətini incidir. Biz asanlıq söz səviyyəsi LSTM'nin performansını mühendisə dil özellikləri üçün fəaliyyətlərini istifadə etmək üçün daha xeyirli bir inşanslı inşanslı inşanslı inşanslı inşanslı inşanslı inşanslı inşanslı inşanslı inşanslı inşans Bizim sonuçlarımız LSTM-ə açıq xüsusiyyətlərin əlavə edilməsini göstərir. Biz bu performansının zərərini bəzi mətnlərin, məsələlərin hər yerlərində və iştirakçilərin mobilitəsindəki dil məsələlərinin ikiqatlığına təsdiqləyirik.", 'bn': 'এই কাজের মূল্য অনুসন্ধান করে দ্বিতীয় নিউরেল নেটওয়ার্কের বৈশিষ্ট্য ইঞ্জিনিয়ন্ত্রণের মাধ্যমে পুনরায় বৃদ্ধি প্রদান করা হয়েছে এবং দ্বিতীয় নুয়ান্ডিয় আমরা একটি সাধারণ শব্দ-স্তর এলস্টিএমের প্রদর্শনের তুলনা করি প্রকাশিত ভাষার বৈশিষ্ট্যের বৈশিষ্ট্য ব্যবহার করে প্রকাশিত ভাষার বৈশিষ্ট্ আমাদের ফলাফল দেখা যাচ্ছে যে এলস্টিএমের সাথে সুস্পষ্ট বৈশিষ্ট্য যোগ করা হয়েছে তা প্রদর্শনের জন্য ক্ষতিকর। We attribute this performance loss to the bivalency of some linguistic items in some text, ubiquity of topics, and participant mobility.', 'hy': 'Այս աշխատանքը ուսումնասիրում է կրկնօրինակ նյարդային ցանցերի աճի արժեքը երկրորդ զարգացած արաբական դիալեկտի հայտնաբերման (NAD) ենթախնդիր 1.2. երկրի մակարդակի DA հայտնաբերման համար: Մենք համեմատում ենք պարզ բառի մակարդակի LSMT-ի արտադրողությունը, օգտագործելով նախավարժված ներգրավումներ մեկի հետ, որը բարելավված է օգտագործելով հնարավորությունների ներգրավումներ ճարտարագիտական հատկանիշների համար: Մեր արդյունքները ցույց են տալիս, որ LSMT-ի բացատրական հատկությունների ավելացումը վնասում է արդյունքին: Մենք այս արտադրողականության կորստը պատասխանում ենք որոշ լեզվաբանական առարկաների երկու տարբերակին որոշ տեքստում, թեմաների ամենուրեք և մասնակիցների շարժունությունը:', 'bs': 'Ovaj rad istražuje vrijednost povećanja rekonstruiranih neuralnih mreža sa funkcionalnim inženjerstvom za drugu nuanciranu arapsku identifikaciju dijalekta (NADI) podzadatak 1.2: identifikacija tužilaštva na zemlji. Uspoređujemo učinkovitost jednostavnog LSTM nivoa riječi koristeći pretkinuto ugrađenje sa jednim poboljšanim korištenjem funkcionalnih ugrađenja za inženjerene jezičke funkcije. Naši rezultati pokazuju da je dodavanje pojasnih karakteristika LSTM štetno za izvođenje. Pripisujemo gubitak izvođenja dvovalentnosti nekih lingvističkih predmeta u nekom tekstu, svjetlost tema i mobilnost učesnika.', 'ca': "Aquesta feina investiga el valor d'augmentar les xarxes neurals recurrents amb enginyeria de característiques per la Segona Identificació de Dialektes àrabs Nuanced (NADI) Subtasca 1.2: Identificació DA a nivell nacional. Comparem el desenvolupament d'un LSTM simple a nivell de paraules utilitzant incorporacions pré-entrenades amb una millorada utilitzant incorporacions de característiques per característiques lingüístices enginyerades. Els nostres resultats demostren que l'afecció de característiques explícites al LSTM és perjudicial al rendiment. Atribuem aquesta pèrdua de rendiment a la bivalencia d'alguns objectes lingüístics en algun text, a la ubicació de temes i a la mobilitat dels participants.", 'et': 'Käesolevas töös uuritakse korduvate närvivõrkude suurendamise väärtust funktsioonitehnoloogia abil teise nuanced araabia dialect identification (NADI) alaülesande 1.2: riigi tasandil DA identifitseerimine. Me võrdleme lihtsa sõnatasemel LSTM-i jõudlust, kasutades eeltreenitud manustamisi, ühe täiustatud funktsioonide manustamisega disainitud keeleliste funktsioonide jaoks. Meie tulemused näitavad, et selgete funktsioonide lisamine LSTM-ile kahjustab jõudlust. Selle tulemuslikkuse kaotuse omistame teatud keeleliste elementide kahekordsusele mõnes tekstis, teemade kõikjalgsusele ja osalejate liikuvusele.', 'cs': 'Tato práce zkoumá hodnotu rozšíření rekurentních neuronových sítí o funkční inženýrství pro druhou nuancovanou arabskou identifikaci dialektu (NADI) Subúlohu 1.2: DA identifikace na úrovni zemí. Porovnáváme výkon jednoduchého LSTM na úrovni slov využívajícího předtrénované vložení s jedním vylepšeným pomocí vložení funkcí pro inženýrské jazykové funkce. Naše výsledky ukazují, že přidání explicitních funkcí do LSTM je škodlivé pro výkon. Tuto ztrátu výkonu připisujeme bivalenci některých jazykových položek v některých textech, všudypřítomnosti témat a mobilitě účastníků.', 'fi': 'Tässä työssä tutkitaan toistuvien hermoverkkojen lisäämisen arvoa ominaisuussuunnittelulla toisen Nuanced Arabic Dialect Identification (NADI) -alatehtävän 1.2: Maatason DA-tunnistus. Vertaamme yksinkertaisen sanatason LSTM:n suorituskykyä esikoulutettujen upotusten avulla yhteen tehostettuun ominaisuusupotukseen suunniteltuja kieliominaisuuksia varten. Tuloksemme osoittavat, että eksplisiittisten ominaisuuksien lisääminen LSTM:ään on haitallista suorituskyvylle. Suorituskyvyn menetys johtuu joidenkin tekstien kielellisten kohtien bivalenssista, aiheiden yleisyydestä ja osallistujien liikkuvuudesta.', 'sk': 'V tem delu je raziskana vrednost povečevanja ponavljajočih se nevronskih omrežij z inženiringom funkcij za drugo Nuanced Arabic Dialect Identification (NADI) podnalogo 1.2: identifikacija DA na ravni države. Učinkovitost preprostega LSTM na ravni besed primerjamo z uporabo predtreniranih vdelav z eno izboljšano vdelavo funkcij za oblikovane jezikovne funkcije. Naši rezultati kažejo, da dodajanje eksplicitnih funkcij LSTM škoduje zmogljivosti. To izgubo uspešnosti pripisujemo dvovalnosti nekaterih jezikovnih elementov v nekaterih besedilih, vseprisotnosti tem in mobilnosti udeležencev.', 'jv': 'This job istraes the value of agementing recurring Neral network with option design for the Second Nuanced Hebrew diaelect ID (NDN) Subtask 1.2: ount-rate Da ID. Awak dhéwé ngregani uwong kelas-kuwi susah-kelas Cyrillin Rejalaké awak dhéwé ngerasakno kanggo nambah akeh apakno kanggo KST dumadhil kanggo nggawe barang. Awak dhéwé nggawe perbudhakan iki bakal segala winih ning limian karo pernik, iso nggawe gerakan urip, nik nggawe gerakno', 'ha': "Wannan aikin yana ƙidãya kimar ƙaramako na tsarin neural wanda aka daura da yana da muhalli masu inganci na masu iya amfani da masu shirya wa Zanin Dialog na Dama na Nuanced Arabic (NADA) Subaikin 1.2: Nashin DA na Country-levels. Tuna samfani da aikin mai sauri na LSM mai amfani da fassarawa da aka samu da kiman da aka yi amfani da masu amfani da tsarin masu tsari ga fassarar linguistic da aka nuna. MatamayinMu na nũna cewa, za'a ƙara wasu misfealumi bayyananne zuwa LSM za'a shafe shi. Munã ƙayyade wannan aikin da aka yi hasara ga wa'yan abu na lugha cikin wani matsayi, da buƙata daga maɓalli, da shirin mutane.", 'he': 'העבודה הזו חוקרת את הערך של הגדילה של רשתות עצביות חוזרות עם הנדסה של תכונות לזיהוי הדיאלקט הערבי השני (NADI) Subtask 1.2: Country-level DA identification. אנחנו משוותים את ההופעה של LSTM ברמה מילים פשוטה בשימוש בתערוכות מתאמנות מראש עם אחד משותף בשימוש בתערוכות תכונות עבור תכונות שפתיות מהנדסה. התוצאות שלנו מראות שהתוספת של תכונות ברורות ל-LSTM היא פגיעה לביצוע. אנו מחזיקים את אובדן ההופעה הזו לתפקיד דו-valence של כמה פריטים שפתיים בטקסט מסוים, בכל מקום של נושאים, והתנועות של משתתפים.', 'bo': 'This work investigates the value of augmenting recurrent neural networks with feature engineering for the Second Nuanced Arabic Dialect Identification (NADI) Subtask 1.2: Country-level DA identification. We compare the performance of a simple word-level LSTM using pretrained embeddings with one enhanced using feature embeddings for engineered linguistic features. ང་ཚོའི་གྲུབ་འབྲས་འབྲས་མངོན་གསལ་འཆར་བའི་ཁྱད་ཆོས་ཁ་སྐོང་ནི་སྒྲུབ་ན་ཉེན་ཁ་ཡོད། ང་ཚོས་ཡིག'}
{'en': 'Arabic Dialect Identification based on a Weighted Concatenation of TF-IDF Features', 'ar': 'تحديد اللهجة العربية على أساس التسلسل المرجح لميزات TF-IDF', 'es': 'Identificación del dialecto árabe basada en una concatenación ponderada de características de TF-IDF', 'pt': 'Identificação do dialeto árabe com base em uma concatenação ponderada de recursos TF-IDF', 'fr': 'Identification du dialecte arabe basée sur une concaténation pondérée de caractéristiques TF-IDF', 'ja': 'TF - IDF機能の加重連結に基づくアラビア語方言識別', 'zh': '基于TF-IDF特征加权连阿拉伯语方言识别', 'hi': 'TF-IDF सुविधाओं के भारित संयोजन के आधार पर अरबी बोली पहचान', 'ru': 'Идентификация арабского диалекта на основе взвешенной конкатенации функций TF-IDF', 'ga': 'Aitheantas Canúint Araibise bunaithe ar Chomhghatánú Ualaithe de Ghnéithe TF-IDF', 'el': 'Αναγνώριση αραβικού διαλέκτου με βάση μια ζυγισμένη αλληλουχία χαρακτηριστικών TF-IDF', 'ka': 'Name', 'hu': 'Arab Dialekt azonosítás a TF-IDF funkciók súlyos összefüggésén alapuló', 'it': 'Identificazione dialettica araba basata su una concatenazione ponderata delle caratteristiche TF-IDF', 'lt': 'Arabų dialekto identifikavimas, pagrįstas svertiniu TF-IDF charakteristikų deriniu', 'mk': 'Arabic Dialect Identification based on a Weighted Concatenation of TF-IDF Features', 'kk': 'ТF- IDF мүмкіндіктерінің тең тең біріктіріміне негізделген араб диалекті идентификациясы', 'ms': 'Pengenalan Dialeksi Arab berdasarkan Kesatuan Bertimbangan Ciri-ciri TF-IDF', 'ml': 'ടിഎഫ്- ഐഡിഎഫ് വിശേഷങ്ങളുടെ വിശേഷതകള്\u200dക്ക് അടിസ്ഥാനമായി അറബി ഡയലേക്റ്റ് തിരിച്ചറിയുക', 'mn': 'TF-IDF Features-ын Weight Concatenation based on an Arabic Dialect Identification', 'no': 'Arabisk dialektidentifisering basert på ein vekt samsvar med TF-IDF-funksjonar', 'pl': 'Identyfikacja dialektu arabskiego oparta na ważonym połączeniu cech TF-IDF', 'ro': 'Identificarea dialectului arab bazată pe o concatenare ponderată a caracteristicilor TF-IDF', 'sr': 'Arapska identifikacija dijalekta zasnovana na osnovu važne koncentracije funkcija TF-IDF-a', 'so': 'Identification of Arabic Dialect based on a Weighted Concatenation of TF-IDF Features', 'si': 'Name', 'sv': 'Arabisk dialekt identifiering baserad på en viktad sammankoppling av TF-IDF-funktioner', 'ta': 'TF- IDF பண்புகளின் விருப்பங்களை அடிப்படையிலான அரபி உரையாடல் அடையாளம்', 'ur': 'Name', 'mt': 'Identifikazzjoni tad-Dijaletta Għarbija bbażata fuq Konċentrazzjoni Piżata tal-Karatteristiċi TF-IDF', 'uz': 'Name', 'vi': 'KCharselect unicode block name dựa trên chứng minh cách cân bằng', 'bg': 'Арабска идентификация на диалекта въз основа на претеглено съвпадение на характеристиките на TF-IDF', 'nl': 'Arabische dialectidentificatie gebaseerd op een gewogen aaneenschakeling van TF-IDF-functies', 'da': 'Arabisk Dialekt Identifikation baseret på en vægtet sammenhæng af TF-IDF-funktioner', 'id': 'Identifikasi Dialek Arab berdasarkan Concatenation Berberat dari Features TF-IDF', 'hr': 'Arapska identifikacija dijalekta temeljena na temelju svećene završetke funkcija TF-IDF-a', 'ko': 'TF-IDF 특징을 바탕으로 가중 결합된 아랍어 사투리 식별', 'fa': 'شناسایی Dialect عربی بر اساس یک تنظیم وزن از ویژه\u200cهای TF-IDF', 'sw': 'Utambulisho wa Tamko la Kiarabu kwa kutumia Mkutano wa TF-IDF', 'de': 'Arabische Dialektkennung basierend auf einer gewichteten Verkettung von TF-IDF Features', 'af': 'Name', 'sq': 'Identifikimi i dialektit arab bazuar në një bashkëkalim të peshuar të funksioneve TF-IDF', 'az': 'TF-IDF Features Based on a Weight Concatenation of a Weight Dialect Identification', 'tr': 'TF-IDF hasaplaryna daýanýar Arabça Diýseçmek Kimligi', 'bn': 'TF-IDF বৈশিষ্ট্যের উপর ভিত্তিক আরবী ডায়ালেক্টর পরিচয়', 'am': '瘠ｨTF-IDF 瘉昵渥瘡ｫ瘠若何', 'bs': 'Arapska identifikacija dijalekta bazirana na osnovu svežene završetke funkcija TF-IDF-a', 'cs': 'Identifikace arabského dialektu založená na váženém spojení funkcí TF-IDF', 'et': 'Araabia dialekti identifitseerimine, mis põhineb TF-IDF funktsioonide kaalutud kokkupuutel', 'fi': 'Arabian dialektin tunnistus perustuu TF-IDF-ominaisuuksien painotettuun yhdistämiseen', 'hy': 'Արաբական դիալեկտի հայտնաբերությունը, հիմնված ԹՖ-IDF ֆունկցիաների կենտրոնացված համեմատության վրա', 'ca': 'La identificació de la diàlecta àrab basada en una concatenació pesada de les característiques TF-IDF', 'he': 'זיהוי דיאלקט ערבי מבוסס על שילוי משקל של תכונות TF-IDF', 'jv': 'diaselect', 'ha': 'KCharselect unicode block name', 'sk': 'Identifikacija arabskega dialekta, ki temelji na tehtani komatenaciji funkcij TF-IDF', 'bo': 'TF-IDF ངོ་བོའི་ནང་དུ་Weighted Concatenation of a Weight Dialect Identification based on an Arabic Dialect Identification'}
{'en': 'In this paper, we analyze the impact of the weighted concatenation of TF-IDF features for the Arabic Dialect Identification task while we participated in the NADI2021 shared task. This study is performed for two subtasks : subtask 1.1 (country-level MSA) and subtask 1.2 (country-level DA) identification. The classifiers supporting our comparative study are Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier. In the evaluation phase, our system gives F1 scores of 14.87 % and 21.49 %, for country-level MSA and DA identification respectively, which is very close to the average F1 scores achieved by the submitted systems and recorded for both subtasks (18.70 % and 24.23 %).', 'ar': 'في هذه الورقة ، نقوم بتحليل تأثير التسلسل المرجح لميزات TF-IDF لمهمة تحديد اللهجة العربية أثناء مشاركتنا في المهمة المشتركة NADI2021. يتم إجراء هذه الدراسة لمهمتين فرعيتين: المهمة الفرعية 1.1 (MSA على مستوى الدولة) والمهمة الفرعية 1.2 (DA على مستوى الدولة) تحديد. المصنفات التي تدعم دراستنا المقارنة هي تصنيف ناقلات الدعم الخطي (LSVC) ، والانحدار الخطي (LR) ، و Perceptron ، و Stochastic Gradient Descent (SGD) ، و Passive Aggressive (PA) ، و Complement Naive Bayes (CNB) ، و MutliLayer Perceptron (MLP) ، و ريدج كلاسيفاير. في مرحلة التقييم ، يعطي نظامنا درجات F1 بنسبة 14.87٪ و 21.49٪ لتحديد MSA على مستوى الدولة و DA على التوالي ، وهو قريب جدًا من متوسط درجات F1 التي حققتها الأنظمة المقدمة والمسجلة لكلا المهمتين الفرعيتين (18.70٪ و 24.23٪).', 'es': 'En este artículo, analizamos el impacto de la concatenación ponderada de las características de TF-IDF para la tarea de identificación del dialecto árabe mientras participábamos en la tarea compartida NADI 2021. Este estudio se realiza para dos subtareas: identificación de la subtarea 1.1 (MSA a nivel de país) y la subtarea 1.2 (DA a nivel de país). Los clasificadores que respaldan nuestro estudio comparativo son la clasificación vectorial de soporte lineal (LSVC), la regresión lineal (LR), el perceptrón, el descenso de gradiente estocástico (SGD), el agresivo pasivo (PA), el complemento Naive Bayes (CNB), el perceptrón multicapa (MLP) y el clasificador de crestas. En la fase de evaluación, nuestro sistema proporciona puntuaciones F1 de 14.87% y 21.49%, para la identificación de MSA y DA a nivel de país respectivamente, lo que está muy cerca de las puntuaciones F1 promedio alcanzadas por los sistemas presentados y registradas para ambas subtareas (18.70% y 24.23%).', 'pt': 'Neste artigo, analisamos o impacto da concatenação ponderada de recursos TF-IDF para a tarefa de identificação do dialeto árabe enquanto participamos da tarefa compartilhada NADI2021. Este estudo é realizado para duas subtarefas: identificação da subtarefa 1.1 (MSA em nível de país) e subtarefa 1.2 (DA em nível de país). Os classificadores que suportam nosso estudo comparativo são Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Agressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) e Classificador de Ridge. Na fase de avaliação, nosso sistema fornece pontuações F1 de 14,87% e 21,49%, para identificação MSA e DA em nível de país, respectivamente, o que é muito próximo das pontuações médias F1 alcançadas pelos sistemas enviados e registradas para ambas as subtarefas (18,70% e 24,23%).', 'fr': "Dans cet article, nous analysons l'impact de la concaténation pondérée des fonctionnalités TF-IDF pour la tâche d'identification des dialectes arabes alors que nous participions à la tâche partagée NADI2021. Cette étude est réalisée pour deux sous-tâches\xa0: identification de la sous-tâche 1.1 (MSA au niveau du pays) et de la sous-tâche 1.2 (DA au niveau du pays). Les classificateurs qui soutiennent notre étude comparative sont la classification par vecteur de support linéaire (LSVC), la régression linéaire (LR), le perceptron, la descente de gradient stochastique (SGD), l'agressivité passive (PA), le bayésien naïf du complément (CNB), le perceptron multicouche (MLP) et RidgeClassifier. Dans la phase d'évaluation, notre système donne des scores F1 de 14,87\xa0% et 21,49\xa0%, respectivement pour l'identification MSA et DA au niveau du pays, ce qui est très proche des scores F1 moyens obtenus par les systèmes soumis et enregistrés pour les deux sous-tâches (18,70\xa0% et 24,23\xa0%).", 'ja': '本稿では、NADI 2021共有タスクに参加している間のアラビア語方言識別タスクのためのTF - IDF機能の加重連結の影響を分析する。この研究は、サブタスク1.1 （国レベルのMSA ）とサブタスク1.2 （国レベルのDA ）の2つのサブタスクに対して実行されます。当社の比較研究をサポートする分類子は、リニアサポートベクター分類（ LSVC ）、リニア回帰（ LR ）、パーセプトロン、確率勾配降下（ SGD ）、パッシブアグレッシブ（ PA ）、補完ナイブベイズ（ CNB ）、MutliLayerパーセプトロン（ MLP ）、およびRidgeClassifierです。評価段階では、当社のシステムは、国レベルのMSAとDAの識別について、それぞれ14.87 ％と21.49 ％のF 1スコアを与えており、提出されたシステムによって達成され、両方のサブタスクで記録された平均F 1スコア（ 18.70 ％と24.23 ％ ）に非常に近い。', 'zh': '于本文,论参NADI2021共享TF-IDF特征加权阿拉伯语方言识事。 治二子:子 1.1(国家级 MSA)、子 1.2(国家级 DA)标。 持吾校之者,线性持向量类(LSVC),线性归(LR),感知器,随机梯度降(SGD),动攻(PA),补码素贝叶斯(CNB),多感知器(MLP)、RidgeClassifier。 于评估,则吾之系统为国家级 MSA 、 DA 标识分 F1 分数 14.87% 与 21.49%,与提交之统得之均 F1 分数甚近,而录二子之均(18.70% 24.23%)。', 'hi': 'इस पेपर में, हम अरबी बोली पहचान कार्य के लिए टीएफ-आईडीएफ सुविधाओं के भारित संयोजन के प्रभाव का विश्लेषण करते हैं, जबकि हमने NADI2021 साझा कार्य में भाग लिया था। यह अध्ययन दो उप-कार्यों के लिए किया जाता है: सबटास्क 1.1 (देश-स्तरीय एमएसए) और सबटास्क 1.2 (देश-स्तरीय डीए) पहचान। हमारे तुलनात्मक अध्ययन का समर्थन करने वाले क्लासिफायर रैखिक समर्थन वेक्टर वर्गीकरण (LSVC), रैखिक प्रतिगमन (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), और RidgeClassifier हैं। मूल्यांकन चरण में, हमारी प्रणाली क्रमशः देश-स्तरीय एमएसए और डीए पहचान के लिए 14.87% और 21.49% के एफ 1 स्कोर देती है, जो प्रस्तुत प्रणालियों द्वारा प्राप्त औसत एफ 1 स्कोर के बहुत करीब है और दोनों उप-कार्यों (18.70% और 24.23%) के लिए दर्ज की गई है।', 'ru': 'В этой статье мы анализируем влияние взвешенной конкатенации функций TF-IDF для задачи идентификации арабского диалекта, в то время как мы участвовали в совместной задаче NADI2021. Это исследование выполняется для двух подзадач: подзадача 1.1 (MSA на уровне страны) и подзадача 1.2 (DA на уровне страны). Классификаторами, поддерживающими наше сравнительное исследование, являются Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) и RidgeClassifier. На этапе оценки наша система дает баллы F1 14,87% и 21,49% для идентификации MSA и DA на страновом уровне, соответственно, что очень близко к средним баллам F1, достигнутым представленными системами и зарегистрированным для обеих подзадач (18,70% и 24,23%).', 'ga': 'Sa pháipéar seo, déanaimid anailís ar an tionchar a bhíonn ag comhghaolú ualaithe gnéithe TF-IDF don tasc Aitheantas Canúint Araibise agus sinn rannpháirteach i dtasc comhroinnte NADI2021. Déantar an staidéar seo ar dhá fhothasc: fothasc 1.1 (MSA ag leibhéal tíre) agus sainaithint fhothasc 1.2 (DA ag leibhéal tíre). Is iad na haicmitheoirí a thacaíonn lenár staidéar comparáideach Aicmiú Veicteoir Tacaíochta Líneach (LSVC), Aischéimniú Líneach (CD), Perceptron, Giniúint Grádán Stochastic (SGD), Éighníomhach Ionsaitheach (PA), Cuan Comhlánaithe Naive (CNB), MutliLayer Perceptron (MLP), agus Aicmitheoir Ridge. Sa chéim mheastóireachta, tugann ár gcóras scóir F1 de 14.87% agus 21.49%, maidir le sainaithint MSA ag leibhéal tíre agus DA faoi seach, atá an-ghar do na meánscóir F1 a bhain na córais a cuireadh isteach agus a taifeadadh don dá fhothasc (18.70% agus 24.23%).', 'ka': 'ამ დომენტში ჩვენ ვაანალიზებთ TF-IDF ფუნქციების განმავლობაზე განმავლობაში აპაბიური დიალექტის განმავლობაზე გავაკეთებთ, როცა ჩვენ NADI2021-ის გაყოფილი დავაკეთებულ დავაკეთებულია. ეს სწავლის შესახებ ორი საკითხვა: საკითხვა 1.1 (ქვეყნების MSA) და საკითხვა 1.2 (ქვეყნების საკუთარი DA) ინდიდინტიფიკაცია. კლასიფიკაციები, რომლებიც ჩვენი კომპორატიური სწავლის მხარდაჭერები არის ლინიური მხარდაჭერების კლასიფიკაცია (LSVC), ლინიური რეგრესი (LR), პერსპექტრონი, სტოქტიური გრადიენტის გამოსახულები (SGD), პასიგური ადგრესიური (PA), კომპლექტიური ნაიგურ ჩვენი სისტემა 14,87% და 21,49%-ის განსაზღვრებისთვის ჩვენი განსაზღვრებისთვის, რომელიც განსაზღვრებული სისტემებით გავაკეთებული განსაზღვრებისთვის ქვეყნების დონეში MSA და DA განსაზღვრებისთვის, რომელიც მხოლოდ ძალიან დამატებული განსაზღვრებული სის', 'el': 'Σε αυτή την εργασία, αναλύουμε τον αντίκτυπο της σταθμισμένης αλληλουχίας χαρακτηριστικών για την εργασία αναγνώρισης αραβικής διαλέκτου ενώ συμμετέχαμε στην κοινή εργασία NADI2021. Η μελέτη αυτή πραγματοποιείται για δύο δευτερεύουσες εργασίες: τον προσδιορισμό δευτερεύουσας εργασίας 1.1 (σε επίπεδο χώρας MSA) και τον προσδιορισμό δευτερεύουσας εργασίας 1.2 (σε επίπεδο χώρας DA). Οι ταξινομητές που υποστηρίζουν τη συγκριτική μας μελέτη είναι η γραμμική διανυσματική ταξινόμηση στήριξης (LSVC), η γραμμική παλινδρόμηση (LR), η perceptron, η stochastic gradient Abstieg (SGD), η παθητική επιθετική (PA), η συμπληρωματική αφελής Bayes (CNB), η perceptron MutliLayer (MLP) και η RidgeClassifier. Κατά τη φάση αξιολόγησης, το σύστημά μας δίνει βαθμολογίες F1 14.87% και 21.49%, για αναγνώριση MSA σε επίπεδο χώρας και DA αντίστοιχα, η οποία είναι πολύ κοντά στις μέσες βαθμολογίες F1 που επιτυγχάνονται από τα υποβληθέντα συστήματα και καταγράφονται και για τις δύο δευτερεύουσες εργασίες (18.70% και 24.23%).', 'it': "In questo articolo analizziamo l'impatto della concatenazione ponderata delle funzionalità di TF-IDF per il compito di identificazione dialettica araba mentre abbiamo partecipato al compito condiviso NADI2021. Questo studio è eseguito per due sottoattività: sottoattività 1.1 (MSA a livello nazionale) e sottoattività 1.2 (DA a livello nazionale). I classificatori che supportano il nostro studio comparativo sono Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stocastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) e RidgeClassifier. Nella fase di valutazione, il nostro sistema fornisce punteggi F1 del 14,87% e del 21,49%, rispettivamente per l'identificazione MSA e DA a livello nazionale, che è molto vicino ai punteggi medi F1 ottenuti dai sistemi presentati e registrati per entrambe le sottoattività (18,70% e 24,23%).", 'kk': 'Бұл қағазда, біз NADI2021 ортақ тапсырмасына қатысу үшін Араб диалекты идентификациялау тапсырмасының TF-IDF мүмкіндіктерінің тең тең біріктіру нәтижесін анализирамыз. Бұл зерттеу екі ішкі сұрақ үшін орындалады: 1. 1 (ел деңгейі MSA) және 1. 2 (ел деңгейі DA) идентификациясы. Сәйкестік зерттеулерімізді қолдау классификациялары Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Completion Naive Bayes (CNB), MutliLayer Perceptron (MLP) және RidgeClassifier. Бағалау этапында жүйеміз 14,87% және 21,49% деңгейіндегі F1 деңгейінде, MSA және DA деңгейіндегі идентификациясы үшін береді. Бұл жүйелердің орташа F1 деңгейіне жақын және екі ішкі суреттер үшін жазылады (18,70% және 24,23%).', 'hu': 'Ebben a tanulmányban elemezzük a TF-IDF funkciók súlyozott összefüggésének hatását az arab Dialekt Identification feladathoz, miközben részt vettünk a NADI2021 megosztott feladatban. A tanulmány két altfeladatra vonatkozik: 1.1 altfeladat (országszintű MSA) és 1.2 altfeladat (országszintű DA) azonosítására. Az összehasonlító tanulmányunkat alátámasztó osztályozók a Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) és RidgeClassifier. Az értékelési szakaszban rendszerünk 14,87%, illetve 21,49%-os F1 pontszámot ad országszintű MSA és DA azonosításra, ami nagyon közel van a benyújtott rendszerek által elért F1 átlagos pontszámhoz és mindkét altfeladat esetében rögzített (18,70% és 24,23%).', 'mk': 'Во овој документ го анализираме влијанието на тежираната концентрација на функциите TF-IDF за задачата за идентификација на арапскиот дијалект додека учествувавме во заедничката задача на НАДИ2021. Оваа студија се спроведува за две подпрашања: подпрашање 1.1 (MSA на ниво на земја) и подпрашање 1.2 (DA на ниво на земја) идентификација. Класификаторите кои ја поддржуваат нашата споредлива студија се Линеарна поддршка Векторска класификација (LSVC), Линеарна регресија (LR), Перцептрон, Стохастички градиентен пад (SGD), Пасивна агресивна (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) и RidgeClassifier. In the evaluation phase, our system gives F1 scores of 14.87% and 21.49%, for country-level MSA and DA identification respectively, which is very close to the average F1 scores achieved by the submitted systems and recorded for both subtasks (18.70% and 24.23%).', 'ms': 'Dalam kertas ini, kami menganalisis kesan persatuan berat ciri-ciri TF-IDF untuk tugas pengenalpasti Dialeksi Arab semasa kami berpartisipasi dalam tugas kongsi NADI2021. kajian ini dilakukan untuk dua subtanya: subtanya 1.1 (MSA-tahap negara) dan subtanya 1.2 (DA-tahap negara) pengenalan. Klasifikasi yang menyokong kajian perbandingan kami ialah Klasifikasi Vektor Sokongan Linear (LSVC), Regression Linear (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), dan RidgeClassifier. Dalam fase penilaian, sistem kami memberikan skor F1 14.87% dan 21.49%, untuk pengenalan MSA dan DA aras negara secara berdasarkan, yang sangat dekat dengan skor F1 rata-rata yang dicapai oleh sistem yang dihantar dan direkam untuk kedua-dua subtasken (18.70% dan 24.23%).', 'lt': 'Šiame dokumente analizuojame TF-IDF savybių svertinio suderinimo poveikį arabų dialektų identifikavimo uždaviniui, kai dalyvavome bendrame NADI2021 uždavinyje. This study is performed for two subtasks: subtask 1.1 (country-level MSA) and subtask 1.2 (country-level DA) identification.  Klasifikatoriai, remiantys mūsų lyginamąjį tyrimą, yra Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) ir RidgeClassifier. Vertinimo etape Mūsų sistema suteikia F1 rezultatus atitinkamai 14,87 % ir 21,49 % šalies lygmeniu MSA ir DA identifikavimui, kuris yra labai artimas pateiktų sistemų pasiektam vidutiniam F1 rezultatui ir užregistruotam abiejų paklausų atveju (18,70 % ir 24,23 %).', 'ml': 'In this paper, we analyze the impact of the weighted concatenation of TF-IDF features for the Arabic Dialect Identification task while we participated in the NADI2021 shared task.  ഈ പഠനത്തിന്റെ രണ്ടു സബ്ജോട്ടുകള്\u200dക്കായി പ്രവര്\u200dത്തിച്ചിരിക്കുന്നു: 1. 1 (രാജ്യത്തിന്റെ നിലവിലുള്ള എസ്എ) ഉപേക് നമ്മുടെ താല്\u200dക്കാലികമായ പഠനം പിന്തുണയ്ക്കുന്ന ക്ലാസ്ഫിക്കറ്റുകള്\u200d ലൈനിയര്\u200d പിന്തുണയ്ക്കുന്ന വെക്റ്റര്\u200d ക്ലാസിഷന്\u200d (LSVC), ലൈന്\u200dലൈന്\u200d റെക്രഷന്\u200d (LR), പെര്\u200dസെപ്റ്റരോണ്\u200d, സ്റ്റോക്സിക് ഗ്രാഡിയന്\u200d നമ്മുടെ സിസ്റ്റത്തിന്റെ വിലാസപ്രകാരം 14.87 ശതമാനത്തിനും 21.49 ശതമാനം F1 സ്കോര്\u200d നല്\u200dകുന്നു. രാജ്യത്തിലെ നിലവില്\u200d എസ്എ എം. എ.എ.എ.എ.എ.എ.എ.എ.എ.എ.എ.എ. എ.', 'mn': 'Энэ цаасан дээр бид НАДИ2021-ийн хуваалтын ажил дээр оролцсон үед Араб диалект идентификацийн ТФ-IDF-ийн жингийн түвшингийн нөлөөг судалж байна. Энэ судалгаа хоёр суурь асуулт хийгддэг: 1.1 суурь асуулт (улсын түвшинд MSA) болон 1.2 суурь асуулт (улсын түвшинд DA) удирдлага. Харьцуулсан судалгаанд дэмжиж буй классификаторууд нь Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Completion Naive Bayes (CNB), MutliLayer Perceptron (MLP), RidgeClassifier юм. Дэлхийн шалгалтын хэмжээнд бидний систем F1 нь 14.87% болон 21.49%, улсын түвшинд MSA болон DA-ын тодорхойлолтын хувьд нэмэгддэг. Энэ нь F1-ийн дундаж дундаж хэмжээний тоог ойролцоогоор ирсэн бөгөөд хамгийн доогуур нь (18.70% болон 24.23%).', 'pl': 'W niniejszym artykule analizujemy wpływ ważonego łączenia cech TF-IDF na zadanie Identyfikacja dialektu arabskiego, podczas gdy uczestniczyliśmy w wspólnym zadaniu NADI2021. Badanie przeprowadzane jest dla dwóch podzadań: identyfikacji podzadania 1.1 (MSA na poziomie kraju) i podzadania 1.2 (DA na poziomie kraju). Klasyfikatory wspierające nasze badania porównawcze to Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayer (CNB), MutliLayer Perceptron (MLP) i RidgeClassifier. W fazie oceny nasz system podaje punkty F1 w wysokości 14,87% i 21,49%, odpowiednio dla identyfikacji MSA na poziomie kraju i DA, które są bardzo bliskie średniej ocenie F1 osiągniętej przez przesłane systemy i zarejestrowanej dla obu podzadań (18,70% i 24,23%).', 'ro': 'În această lucrare, analizăm impactul concatenării ponderate a caracteristicilor TF-IDF pentru sarcina de identificare dialectă arabă în timp ce am participat la sarcina partajată NADI2021. Acest studiu este realizat pentru două subactivități: subactivitatea 1.1 (MSA la nivel de țară) și subactivitatea 1.2 (DA la nivel de țară). Clasificatorii care susțin studiul nostru comparativ sunt Clasificarea Vectorială Linear Support (LSVC), Regresia Lineară (LR), Perceptron, Descenderea Gradientului Stocastic (SGD), Agresiva Pasivă (PA), Bayer Naive Complement (CNB), Perceptron MutliLayer (MLP) și RidgeClassifier. În faza de evaluare, sistemul nostru oferă scoruri F1 de 14,87% și 21,49%, pentru identificarea MSA la nivel național și respectiv DA, ceea ce este foarte aproape de scorurile F1 medii obținute de sistemele depuse și înregistrate pentru ambele subsarcini (18,70% și 24,23%).', 'sr': 'U ovom papiru analiziramo uticaj težine sastavljanja funkcija TF-IDF-a za posao identifikacije arapske dijalekte dok smo sudjelovali u zajedničkom zadatku NADI2021. Ova studija se obavlja za dve podkaze: identifikacija podpitanja 1,1 (MSA na zemlji) i podpitanja 1,2 (NA na zemlji). Klasifikatori koji podržavaju naše komparativno ispitivanje su klasifikacija linearne podrške vektora (LSVC), linijske regresije (LR), Perceptron, Stochastic Gradient Descent (SGD), Pasivna Aggresivna (PA), kompletna Naive Bayes (CNB), MutliLayer Perceptron (MLP) i RidgeClassifier. U fazi procjene, naš sistem daje rezultate F1 od 14,87% i 21,49%, odnosno za identifikaciju MSA i tužilaštva na zemlji, što je veoma blizu prosječnim rezultatima F1 postignutim podignutim sistemima i snimljenim za obe podrške (18,70% i 24,23%).', 'no': 'I denne papiret analyserer vi effekten av vekta samsvaring av TF-IDF-funksjonar for den arabiske dialektidentifikasjonsprogrammet mens vi delta i delt NADI2021-oppgåva. Denne studien er utført for to underspørjingar: underspørjing 1.1 (land-nivå MSA) og underspørjing 1.2 (land-nivå DA) identifikasjon. Klassifikatorane som støttar sammenlignbart studiet vårt er lineær støtte vektorklassifikasjon (LSVC), lineær regresjon (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), og RidgeClassifier. I evalueringsfasen gir systemet vårt F1-poeng i 14,87 % og 21,49 %, for landnivå MSA og DA-identifikasjon, som er svært nært gjennomsnittlige F1-poeng oppnådd av filene og registrert for både underpoeng (18,70 % og 24,23 %).', 'mt': 'F’dan id-dokument, nagħmlu analiżi tal-impatt tal-konċentrazzjoni peżata tal-karatteristiċi TF-IDF għall-kompitu ta’ Identifikazzjoni tad-Djaletti Għarab waqt li pparteċipawna fil-kompitu kondiviż tan-NADI2021. Dan l-istudju jitwettaq għal żewġ sottomistoqsijiet: sottomistoqsija 1.1 (MSA fil-livell tal-pajjiż) u sottomistoqsija 1.2 (DA fil-livell tal-pajjiż) identifikazzjoni. Il-klassifikaturi li jappoġġjaw l-istudju komparattiv tagħna huma l-Klassifikazzjoni tal-Vetturi ta’ Appoġġ Lineari (LSVC), ir-Regressjoni Lineari (LR), il-Perceptron, id-Diżintegrazzjoni Stokastika tal-Gradjent (SGD), l-Aggressiv Passiv (PA), il-Bajżi Mhux Komplimentati (CNB), il-Perceptron MutliLayer (MLP), u l-RidgeClassifier. In the evaluation phase, our system gives F1 scores of 14.87% and 21.49%, for country-level MSA and DA identification respectively, which is very close to the average F1 scores achieved by the submitted systems and recorded for both subtasks (18.70% and 24.23%).', 'si': 'මේ පත්තරේ අපි විශ්ලේෂණය කරනවා TF-IDF ගැන බලාපොරොත්තු සම්බන්ධතාවක් අරාබි දායිලෙක්ට් පරික්ෂණය වැඩක් සඳහා අපි NADI2021 භාගත ව මේ පරීක්ෂණය විදිහට ප්\u200dරයෝජනය වෙනුවෙන් ප්\u200dරයෝජනය කරන්නේ: 1.1 (රටස්ථානය MSA) සහ 1.2 (රටස්ථානය DA) පරීක්ෂණය. The classifiers assisting our comparator study are Linear Aid Vector Classication (LSVC), Linear regression (LR), Percepron, Stochastic Gradient Depent (SGD), Pastive Aggressive (PA), Suppment Nave Bay (CNB), Murliclayer Percepron (MLP), and Ridge Classified. අපේ පද්ධතිය පද්ධතිය 14.87% සහ 21.49% ගැන F1 ස්කෝර් දෙනවා, රටස්ථානයේ MSA සහ DA පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා සමාන්\u200dය F1 ස්කෝර් සඳහා ගොඩක් ලඟින් ඉන්නේ, සමාන්\u200dය පද්ධත', 'so': 'Qoraalkan waxaynu ku analyeynaa saamaynta ku saabsan TF-IDF tashihiisa aqoonsiga ee Carabi Dialect, markaynu ka qayb galnay shaqada NADI2021 oo la qaybsaday. Waxbarashadan waxaa lagu sameeyaa laba shaqo: shahaado 1.1 (shahaadada dowladda MSA) iyo shahaadada 1.2 (ADA) shahaadada wadanka ah. Qoraalka kaalmeeya waxbarashada compariska ah waa Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier. Xiliga qiimeynta, nidaamkayagu wuxuu F1 koox ah 14.87 % iyo 21.49 boqolkiiba, si loo aqoonsado AMSA iyo DA heerka waddanka ah, taasoo ugu dhow qiimaha ugu dhow kooxda F1 oo ay soo gaadhay nidaamka la soo dhiibay iyo loo qoray labada samooyin (18.70 % iyo 24.23%).', 'sv': 'I denna uppsats analyserar vi effekten av den viktade sammankopplingen av TF-IDF-funktioner för uppgiften Arabic Dialect Identification medan vi deltog i den delade uppgiften NADI2021. Denna studie utförs för två deluppgifter: deluppgift 1.1 (landsnivå MSA) och deluppgift 1.2 (landsnivå DA) identifiering. Klassificeringsgrupperna som stöder vår jämförande studie är Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stokastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) och RidgeClassifier. I utvärderingsfasen ger vårt system F1 poäng på 14,87% respektive 21,49%, för MSA respektive DA på landsnivå, vilket ligger mycket nära de genomsnittliga F1 poäng som uppnåtts av de inlämnade systemen och registrerats för båda deluppgifterna (18,70% och 24,23%).', 'ta': 'இந்த காகிதத்தில், நாம் நாடி2021 பகிர்ந்த பணியில் பங்கிடப்பட்ட போது TF-IDF குணங்களின் தாக்கத்தை ஆய்வு செய்கிறோம். இரண்டு துணை பணிகளுக்காக இந்த ஆராய்ச்சி செய்யப்பட்டுள்ளது: உப செயல் 1. 1 (நாட்டின் நிலை MSA) மற்றும் துணை பணி 1. 2 (நாட்டில எங்கள் ஒப்பிடும் படிப்புக்கு ஆதரிக்கும் வகுப்பார்கள் என்பது Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier. மதிப்பிடும் காலத்தில், எங்கள் அமைப்பு 14.87% மற்றும் 21.49%, நாட்டு நிலையில் MSA மற்றும் DA அடையாளத்திற்கு F1 புள்ளிகள் கொடுக்கப்பட்டுள்ளது, வழங்கப்பட்ட முறைமைகள் மூலம் அடைந்த', 'ur': 'اس کاغذ میں ہم نے TF-IDF کی بوجھ کی تعلق کی تاثیر تحقیق کی جب ہم NADI2021 شریک کام میں شریک ہوتے تھے۔ یہ مطالعہ دو سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ ہمارے مقابلہ تحقیقات کی مدد کرنے والے کلاسپیر لینیر پشتیبانی ویکتور کلاسپیف (LSVC), لینیر ریگرس (LR), پرسپٹرون، استوچسٹیک گریڈینٹ ڈونس (SGD), پاسپٹی گریڈینٹ ڈونس (PA), کامل نایو بیز (CNB), MutliLayer پرسپٹرون (MLP) اور RidgeClassifier ہیں. ارزیابی فصل میں، ہماری سیستم 14.87% اور 21.49% کی F1 اسکور دیتا ہے، ملک سطح MSA اور DA کی شناسایی کے لئے، جو متوسط F1 اسکور کے قریب ہے جن کو پہنچایا گیا تھا اور ان دونوں سٹسٹسٹوں کے لئے راک کیا گیا ہے (18.70% اور 24.23%).', 'vi': 'Trong tờ giấy này, chúng tôi phân tích tác động của sự kết hợp được cân nhắc của các tính năng TF-IDF cho nhiệm vụ nhận diện cấu hình nhân tạo Á Rập trong khi chúng tôi tham gia nhiệm vụ chia sẻ NADI2021. Nghiên cứu này được thực hiện cho hai yêu cầu phụ: phụ đề 1.1 (National-level MSA) và phụ đề 1.2 (quốc gia DA) được xác định. Những phân loại hỗ trợ cho nghiên cứu tương đối của chúng ta là Linear hỗ trợ Vector classification (LSVC), Linear Regrittion (LR), Percipiptron, Stotrừng Gradient Desnãy (SGD), Passive aggressive (PA), Complment Naive Bayes (CNB), Mutlilớp Percipphần (MLP) và GenericName Trong giai đoạn đánh giá, hệ thống của chúng tôi cung cấp điểm F1 ở 14.877. và 21.42=, for country-level MSA and DA identification, which is very closer to the trung bình F1 scores by the departed systems and recorded for both subtasks (18.70=$and 24.23=).', 'uz': "Bu qogʻozda biz NADI2021 bilan birlashtirilgan vazifani o'rganish uchun TF-IDF xossalarining qiymatini analyzmiz. @ info: status Ikkilangan tizimizni qoʻllash mumkin: Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), RidgeClassifier. Qiymatlar davomida, tizimmiz davlat boshqa MSA va DA uchun 14.87% va 21.49% F1 foizga ega bo'ladi. Bu loyihani qoʻshilgan tizimlar uchun o'zgartirdi va ikkita vazifalar uchun yozib olingan oddiy F1 scorga (18.70% va 24.23%).", 'nl': 'In dit artikel analyseren we de impact van de gewogen aaneenschakeling van TF-IDF functies voor de Arabische Dialect Identificatie taak terwijl we deelnamen aan de gedeelde NADI2021 taak. Dit onderzoek wordt uitgevoerd voor twee subtaken: subtaak 1.1 (landniveau MSA) en subtaak 1.2 (landniveau DA) identificatie. De classificatoren die onze vergelijkende studie ondersteunen zijn Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) en RidgeClassifier. In de evaluatiefase geeft ons systeem F1-scores van respectievelijk 14,87% en 21,49%, voor MSA- en DA-identificatie op landenniveau, die zeer dicht bij de gemiddelde F1-scores van de ingediende systemen liggen en voor beide subtaken worden geregistreerd (18,70% en 24,23%).', 'da': 'I denne artikel analyserer vi virkningen af den vægtede sammenkobling af TF-IDF-funktioner til opgaven Arabic Dialect Identification, mens vi deltog i NADI2021 delte opgave. Denne undersøgelse er udført for to underopgaver: underopgave 1.1 (landeniveau MSA) og underopgave 1.2 (landeniveau DA) identifikation. Klassificeringerne, der understøtter vores sammenlignende undersøgelse, er Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stokastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) og RidgeClassifier. I evalueringsfasen giver vores system F1 scores på henholdsvis 14,87% og 21,49% for MSA og DA identifikation på landsniveau, hvilket er meget tæt på de gennemsnitlige F1 scores opnået af de indsendte systemer og registreret for begge underopgaver (18,70% og 24,23%).', 'de': 'In diesem Beitrag analysieren wir den Einfluss der gewichteten Verkettung von TF-IDF-Features auf die arabische Dialektidentifizierung, während wir an der gemeinsamen Aufgabe NADI2021 teilnahmen. Diese Studie wird für zwei Teilaufgaben durchgeführt: Subtask 1.1 (MSA auf Länderebene) und Subtask 1.2 (DA auf Länderebene). Die Klassifikatoren, die unsere vergleichende Studie unterstützen, sind Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayers (CNB), MutliLayer Perceptron (MLP) und RidgeClassifier. In der Evaluierungsphase liefert unser System F1-Werte von 14,87% und 21,49%, für die länderspezifische MSA- und DA-Identifikation, die sehr nahe an den durchschnittlichen F1-Werten der eingereichten Systeme liegen und für beide Teilaufgaben aufgezeichnet werden (18,70% und 24,23%).', 'id': 'Dalam kertas ini, kami menganalisis dampak dari konsentrasi berat dari fitur TF-IDF untuk tugas Identifikasi Dialek Arab sementara kami berpartisipasi dalam tugas bersama NADI2021. Studi ini dilakukan untuk dua subtasks: subtask 1.1 (MSA tingkat negara) dan subtask 1.2 (DA tingkat negara) identifikasi. Klasifikasi yang mendukung studi perbandingan kami adalah Klasifikasi Vektor Support Linear (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), dan RidgeClassifier. Dalam fase evaluasi, sistem kami memberikan skor F1 14,87% dan 21,49%, untuk identifikasi MSA dan DA tingkat negara secara respektif, yang sangat dekat dengan nilai F1 rata-rata yang dicapai oleh sistem yang dihantar dan direkam untuk kedua subtasks (18,70% dan 24,23%).', 'bg': 'В настоящата статия анализираме въздействието на претегленото конкатениране на функциите на ТФ-ИДФ за задачата за идентифициране на диалект на арабски език, докато участвахме в споделената задача НАДИ2021. Това проучване се извършва за две подзадачи: подзадача 1.1 (МСП на ниво държава) и подзадача 1.2 (ДА на ниво държава). Класификаторите, подкрепящи нашето сравнително проучване, са Класификация на векторите за линейна подкрепа (ЛСVC), Линейна регресия (LR), Перцептрон, Стохастичен градиент спускане (SGD), Пасивна агресивна (PA), Неактивна комплимент Байс (CNB), MutliLayer Perceptron (MLP) и RidgeClassifier. Във фазата на оценяване системата ни дава резултати от 14,87% и 21,49%, съответно за идентифициране на МСА и ДА на национално ниво, което е много близо до средните резултати, постигнати от подадените системи и записани за двете подзадачи (18,70% и 24,23%).', 'hr': 'U ovom papiru analiziramo utjecaj težine usklađenja karakteristika TF-IDF-a za zadatak identifikacije arapskog dijalekta dok smo sudjelovali u zajedničkom zadatku NADI2021. U ovom ispitivanju provedena se dva podmeta: identifikacija podpitanja 1,1 (MSA na zemlji) i podpitanja 1,2 (NA na zemlji). Klasifikatori koji podržavaju naše usporedno ispitivanje su klasifikacija linearne podrške vektora (LSVC), linearne regresije (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggresivne (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) i RidgeClassifier. U fazi procjene, naš sustav daje F1 rezultate od 14,87% i 21,49%, odnosno za identifikaciju MSA i tužilaštva na zemlji, što je vrlo blizu prosječnim rezultatima F1 postignutim podanim sustavima i zabilježenim za oba podataka (18,70% i 24,23%).', 'fa': 'در این کاغذ، ما تاثیر سنگین ترکیب ویژه\u200cهای TF-IDF برای کارهای شناسایی دیالکت عربی را تحلیل می\u200cکنیم در حالی که ما در کار مشترک NADI2021 شرکت می\u200cکردیم. این مطالعه برای دو زیر سؤال انجام می شود: شناسایی زیر سؤال ۱.۱ (سطح کشور MSA) و زیر سؤال ۱.۲ (سطح کشور DA). گروهی که پشتیبانی مطالعه مقایسه ما می\u200cکنند، کلاس پشتیبانی Vector Support Linear Classification (LSVC), Regression Linear (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Completion Naive Bayes (CNB), MutliLayer Perceptron (MLP) و RidgeClassifier هستند. در مراحل ارزیابی، سیستم ما نمونه\u200cهای F1 14.87% و 21.49%، برای شناسایی MSA و DA در سطح کشور، که بسیار نزدیک به نمونه\u200cهای متوسط F1 که توسط سیستم\u200cهای فرستاده شده\u200cاند و برای هر دوی زیر پایه\u200cها ثبت شده\u200cاند (18.70% و 24.23%).', 'sw': 'In this paper, we analyze the impact of the weighted concatenation of TF-IDF features for the Arabic Dialect Identification task while we participated in the NADI2021 shared task.  Utafiti huu unafanyika kwa ajili ya kazi mbili: kazi 1.1 (yenye kiwango cha Nchi) na utambulisho wa ndege 1.2 (DA kwa kiwango cha nchi). Wanachama wanaomwunga mkono utafiti wetu wa ushirikiano ni kuunga mkono Vector ya Linear (LSVC), Regression of Linear (LR), Perceptron, Descent of Stochastic Gradient (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier. Katika kiwango cha tathmini, mfumo wetu unawapa score za F1 za asilimia 14.87 na 21.49, kwa ajili ya kutambua kwa kiwango cha ndege cha MSA na DA, ambacho ni karibu sana score za wastani za F1 zilizopatikana na mfumo uliotolewa na kurekodiwa kwa kazi zote (asilimia 18.70 na asilimia 24.23).', 'tr': 'Bu kagyzda biz TF-IDF üýtgeşmeleriniň çykyşlygyny arap dialekt kimligi täblisasynda çözümleýäris we NADI2021-iň paylaşyk täblisasynda goşulýarys. Bu çalışma iki alt sorag üçin gerçekleýär: 1.1 (ýurt-derejesi MSA) we 1.2 (ýurt-derejesi DA) kimligi. Ködleşikli öwrenmegimizi destekleýän klasifikatçylar hatly destekleýän vektör klassifasyýasy (LSVC), hatly regresiýasy (LR), Perceptron, Stochastik Gradiýat Tasgasy (SGD), Pasiwça Aggresiýa (PA), Tamamlama Naive Baylar (CNB), MutliLayer Perceptron (MLP), we RidgeClassifier. Taýýarlama phasesynda biziň sistemamyz 14.87% we 21.49% diýip F1 अंश berýär, ýurt derejesinde MSA we DA identifikaçy üçin, we bu sistemlerde gelen orta sany F1 अंश we her iki अंश (18.70% we 24.23%) üçin ýazylýar.', 'af': 'In hierdie papier, ons analyseer die effek van die gewigte samelewing van TF-IDF-funksies vir die Arabiese Dialeksie Identifikasie taak terwyl ons gedeel het in die gedeelde taak NADI2021. Hierdie studie is uitgevoer vir twee subtaske: subtask 1. 1 (landvlak MSA) en subtask 1. 2 (landvlak DA) identifikasie. Die klassifiseerders wat ondersteun ons vergelykbare studie is Lineer ondersteunde vektor klassifikasie (LSVC), Lineer Regresie (LR), Perseptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Voltooiïng Naive Bayes (CNB), MutliLayer Perceptron (MLP), en RidgeClassifier. In die evalueringsfase gee ons stelsel F1 aantal van 14,87% en 21,49%, vir landvlak MSA en DA-identifikasie respektief, wat baie naby is tot die gemiddelde F1 aantal wat deur die onderhouerde stelsels bereik is en opgeneem is vir beide onderhouers (18,70% en 24,23%).', 'ko': '본고에서 우리는 TF-IDF 특징의 가중 직렬이 NADI2021 공유 임무에 참여하는 아랍어 사투리 식별 임무에 대한 영향을 분석했다.본 연구는 두 가지 하위 임무에 대해 하위 임무 1.1(국가급 MSA)과 하위 임무 1.2(국가급 DA) 식별을 실시했다.비교 연구를 지원하는 분류기는 선형 지원 벡터 분류(LSVC), 선형 회귀(LR), 감지기, 무작위 사다리 하락(SGD), 수동 공격(PA), 부호화 소박 베일러스(CNB), 다차원 감지기(MLP)와 척상 분류기가 있다.평가 단계에서 우리 시스템이 국가급 MSA와 DA 감정에 부여한 F1 점수는 각각 14.87%와 21.49%로 제출한 시스템이 받은 평균 F1 점수와 매우 가깝고 두 개의 하위 임무의 F1 점수(18.70%와 24.23%)를 기록했다.', 'hy': 'Այս թղթի մեջ մենք վերլուծում ենք ԹՖ-ԻԴՖ հատկանիշների կենտրոնացված համեմատության ազդեցությունը արաբական դիալեկտի հայտնաբերման խնդրի համար, մինչ մենք մասնակցեցինք NAD2021-ի ընդհանուր խնդրին: Այս ուսումնասիրությունը կատարվում է երկու ենթահարցերի համար՝ 1.1 ենթահարցերի (երկրի մակարդակի MSA) և 1.2 ենթահարցերի (երկրի մակարդակի DA) ենթահարցերի համար: Մեր համեմատական ուսումնասիրությունը աջակցում են գծային աջակցության վեկտորների դասակարգման (LSVC), գծային ռեգրեսիայի (LR), Պերցեպտոնի, Ստոխստատիկ Գրեդինտի Դեքսիայի (GSD), Պասիվ Ագրեսիվ (AP), Գլխավոր Նայվ Բեյսերի (CNB), ՄուլիԼեյսերի Պերցեպտոնի (MLP) և Ridge Քալ Արժեքի փուլում մեր համակարգը F1-ի գնահատականները տալիս է 14.87 և 21.49 տոկոս երկրի մակարդակի MSA-ի և DA-ի հայտնաբերման համար, ինչը շատ մոտ է ներկայացված համակարգերի միջին F1-ի գնահատականներին, որոնք գրված են երկու ենթախնդիրների համար (18.70 և 24.23 տոկոս):', 'am': 'በዚህ ፕሮግራም፣ በNADI2021 በተካፈሉት ስራ ላይ የTF-IDF ምርጫዎችን ለመቀበል አረባዊ Dialect Identification ስራ እናሳውቃለን፡፡ ይህ ትምህርት ለሁለት ደብዳቤዎች ተፈጸመ፤ አዲስ ስራ 1.1 (የአገር-ደረጃ MSA) እና አዲስ ስራ 1.2 (የአገር-ደረጃ DA) identification ነው። The classifiers supporting our comparative study are Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier.  በተመሳሳይ ክፍል፣ ስርዓታችን በአገሪቱ ደረጃዎች አሜሲ እና ዲ አዲስ ማስታወቂያውን 14.87 በመቶ እና 21.49 በመቶ የF1 score ይሰጣል፡፡', 'bn': 'এই কাগজটিতে আমরা বিশ্লেষণ করি যে টিএফ-আইডিএফ বৈশিষ্ট্যাবলীর পরিচিতির জন্য টিএফ-আইডিএফ বৈশিষ্ট্যাবলীর প্রভাব বিশ্লেষণ করেছি, যখন আমরা নাডি২০২০১২ এই গবেষণা দুটি সাবকাজের জন্য প্রদর্শন করা হয়েছে: ১. ১ (দেশের স্তরের এমএসএ) এবং ১. ২ (দেশের স্তর ডিএ) পরিচয়। আমাদের তুলনামূলক গবেষণার সমর্থন করা শ্রেণীরা হচ্ছে লাইনিয়ার সমর্থন করে ভেক্টর ক্লাসিকেশন (এলএসভিসি), লাইনের রেগ্রেশন (এলআর), পার্সেপ্টরোন, স্টোকাস্টিক গ্রেডিয়েন্ট ডেসেন্ট (এসজিডি), পাসিভ এগ্রেজ মুল্যায়ন পর্যায়ে আমাদের সিস্টেম ১৪. ৮৭% এবং ২১. ৪৯%, দেশের স্তরে এমএসএ এবং ডিএ-এর পরিচিতির জন্য, যা জমা দিয়েছে সিস্টেমের দ্বারা অর্জন করেছে এবং উভয় সাবটাক্সের জন্য রেকর্ড করে', 'bs': 'U ovom papiru analiziramo utjecaj težine potvrde funkcija TF-IDF-a za zadatak identifikacije arapske dijalekte dok smo sudjelovali u zajedničkom zadatku NADI2021. Ova ispitivanja se obavlja za dva podmetaka: identifikacija podpitanja 1,1 (MSA na zemlji) i podpitanja 1,2 (NA na zemlji). Klasifikatori koji podržavaju naše usporedno ispitivanje su klasifikacija linearne podrške vektora (LSVC), linearne regresije (LR), Perceptron, Stochastic Gradient Descent (SGD), Pasivna Aggresivna (PA), kompletna Naive Bayes (CNB), MutliLayer Perceptron (MLP) i RidgeClassifier. U fazi procjene, naš sistem daje rezultate F1 od 14,87% i 21,49%, odnosno za identifikaciju MSA i tužilaštva na zemlji, što je vrlo blizu prosječnim rezultatima F1 postignutim podanim sustavima i zabilježenim za oba podataka (18,70% i 24,23%).', 'sq': 'Në këtë letër, ne analizojmë ndikimin e bashkëkalimit të peshuar të funksioneve TF-IDF për detyrën e identifikimit të dialektit arab ndërsa morëm pjesë në detyrën e përbashkët të NADI2021. Ky studim kryehet për dy nënpyetje: nënpyetje 1.1 (niveli i vendit MSA) dhe nënpyetje 1.2 (niveli i vendit DA) identifikimi. Klasifikuesit që mbështesin studimin tonë krahasues janë Klasifikimi Linear Support Vector (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) dhe RidgeClassifier. Në fazën e vlerësimit, sistemi ynë jep rezultate F1 prej 14.87% dhe 21.49%, respektivisht për identifikimin e nivelit të vendit MSA dhe DA, që është shumë afër rezultateve mesatare F1 të arritura nga sistemet e paraqitura dhe të rregjistruara për të dy nënkërkesat (18.70% dhe 24.23%).', 'az': 'Bu kağızda, NADI2021 paylaşdığımız işlərdə sərbəst Dialect Identification işin in TF-IDF özelliklərinin ağırlığı təsirini analiz edirik. Bu təhsil iki dəstək üçün icra edilir: 1.1 (ülkedən səviyyədə MSA) subtask və 1.2 (ülkedən səviyyədə DA) identifikası. Bizim karşılaşdırma çalışmalarımızı desteklənlər Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Completion Naive Bayes (CNB), MutliLayer Perceptron (MLP) və RidgeClassifier. Vəziyyət fəzisində sistemimiz 14,87 % və 21,49 % F1 dərəcələrini verir, ülke seviyesində MSA və DA təsdiqlənməsi üçün, bu sistemlərin ortalama F1 dərəcələrinə yaxınlaşdırır və ikisinin dərəcələrinə yazılır (18,70 % və 24,23 %).', 'cs': 'V tomto článku analyzujeme vliv váženého řetězení funkcí TF-IDF na úlohu identifikace arabského dialektu při účasti na sdíleném úkolu NADI2021. Tato studie je prováděna pro dva podúkoly: identifikaci podúkolů 1.1 (MSA na úrovni země) a podúkolů 1.2 (DA na úrovni země). Klasifikátory podporující naši srovnávací studii jsou Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Pasivní agresivní (PA), Complement Naive Bayes (ČNB), MutliLayer Perceptron (MLP) a RidgeClassifier. Ve fázi hodnocení náš systém poskytuje F1 skóre 14,87% a 21,49%, pro identifikaci MSA a DA na úrovni země, které jsou velmi blízké průměrným skórím F1 dosaženým předloženými systémy a zaznamenaným pro oba dílčí úkoly (18,70% a 24,23%).', 'et': 'Käesolevas töös analüüsime TF-IDF funktsioonide kaalutud seostamise mõju Araabia dialekti identifitseerimise ülesandele, kui osalesime NADI2021 jagatud ülesandes. Käesolev uuring viiakse läbi kahe alamülesande puhul: alamülesanne 1.1 (riigi tasandil MSA) ja alamülesanne 1.2 (riigi tasandil DA) identifitseerimine. Meie võrdlevat uuringut toetavad klassifikaatorid on lineaarne tugivektori klassifikatsioon (LSVC), lineaarne regressioon (LR), Perceptron, Stohastic Gradient Descent (SGD), Passiivne Aggressiivne (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) ja RidgeClassifier. Hindamisetapis annab meie süsteem F1 punktid vastavalt 14,87% ja 21,49% riigi tasandil MSA ja DA identifitseerimisel, mis on väga lähedal esitatud süsteemide poolt saavutatud ja mõlema alamülesande puhul registreeritud keskmistele F1 punktidele (18,70% ja 24,23%).', 'ca': "En aquest paper, analitzem l'impacte de la concatenació ponderada de les característiques TF-IDF per la tasca d'identificació del diàlecte àrab mentre vam participar en la tasca compartida NADI2021. Aquest estudi es fa per dues subterrànies: subterrània 1.1 (MSA a nivell de país) i subterrània 1.2 (DA a nivell de país). Els classificadors que suporten el nostre estudi comparatiu són Classificació de Vectors de Suport Linear (LSVC), Regression Linear (LR), Perceptron, Gradient Descent Stochastic (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) i RidgeClassifier. En la fase d'evaluació, el nostre sistema dóna puntuacions F1 de 14,87% i 21,49%, respectivament, per identificar MSA a nivell nacional i DA, que està molt prop de les puntuacions F1 mitjanes aconseguides pels sistemes submetits i registrades per ambdues subtaskes (18,70% i 24,23%).", 'fi': 'Tﾃ､ssﾃ､ artikkelissa analysoimme TF-IDF-ominaisuuksien painotetun yhdistﾃ､misen vaikutusta arabialaiseen dialektitunnistustehtﾃ､vﾃ､ﾃ､n osallistuessamme NADI2021 jaettuun tehtﾃ､vﾃ､ﾃ､n. Tﾃ､mﾃ､ tutkimus suoritetaan kahdella alatehtﾃ､vﾃ､llﾃ､: alatehtﾃ､vﾃ､llﾃ､ 1.1 (maakohtaiset MSA) ja alatehtﾃ､vﾃ､llﾃ､ 1.2 (maakohtaiset DA) tunnistamisella. Vertailututkimustamme tukevat luokittelijat ovat Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stokastinen Gradient Descent (SGD), Passiivinen Aggressiivinen (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) ja RidgeClassifier. Arviointivaiheessa jﾃ､rjestelmﾃ､mme antaa F1-pisteet 14,87% ja 21,49% maakohtaiselle MSA-tunnistukselle, mikﾃ､ on hyvin lﾃ､hellﾃ､ toimitettujen jﾃ､rjestelmien keskimﾃ､ﾃ､rﾃ､isiﾃ､ F1-pisteitﾃ､ ja kirjattuja molempien osatehtﾃ､vien osalta (18,70% ja 24,23%).', 'jv': "Nan pepulan iki, kita diwurani nggawe ngupakan seneng nggawe gerangkamu nggawe gerangkamu nggawe cara nggawe TiF-ID nggawe barang arap diaselect Workspace 1.1 Genjer Where's this data set", 'ha': "A cikin wannan takardan, munã anayyar da aikin da aka yi nau'a wa TF-IDF masu shirya wa aikin Nasãra na Larabci a lokacin da muka yi nasara a cikin aikin NADA2021 wanda aka raba shi. An cika wannan fitina wa aikin biyu: sub-aikin 1.1 (ƙasan-levels MAA) da ƙanƙan aikin 1.2 (nasa-DA). Classifier masu ƙarfafa da kuma daidai kwamfyutan mu, linje Support Active Classification (LSV C), Linline Regression (LR), Perceptron, Stajatic Grade descenter (SGD), Paris Aggressive (PA), Compliment Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RijClassifier. Ga lokacin evaluation, na'asarmu yana iya F1'ar faƙatan 14.87% da 21.49%, wa'anar AMA da DA-nau'in ƙasa-yanzu, yana mafi kusa ga nau'in F1 da aka samar da na'urar da aka saka da kuma aka rubũta wa aikin da dukansu (18,70% da 24.23%).", 'he': 'בעיתון הזה, אנו מנתחים את ההשפעה של התקליט המשקל של תכונות TF-IDF עבור משימה זיהוי דיאלקט ערבי בזמן שהשתתפנו במשימה המשותפת NADI2021. המחקר הזה מבצע עבור שתי תתשאלות: תתשאלה 1.1 (MSA רמה מדינה) ותשאלה 1.2 (DA רמה מדינה) זיהוי. המסמכים שמתמיכים במחקר השוואי שלנו הם מסגרת Vector Support Linear Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), RidgeClassifier. בשלב הערכה, המערכת שלנו נותנת נקודות F1 של 14.87% ו-21.49%, עבור זיהוי MSA ברמה המדינה וברמה המחוזית המחוזית, אשר קרוב מאוד לציון F1 הממוצע שנשגש על ידי המערכות המוסרות והרשום לשניהם (18.70% ו-24.23%).', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག་ཆ་འདིའི་ནང་དུ་TF-IDF (Arabic Dialect Identification task)གི་མཐའ་མཇུག་བསྡུས་ཀྱི་གནོད་འགྱུར ལྟ་བུ་འདི་རྒྱབ་སྐྱོར་གཉིས་ཀྱི་རྗེས་སུ་འབྲི་བཞིན་པ་ཡིན། subtask 1.1 (country-level MSA)དང་subtask 1.2 (country-level DA)identification The classifiers supporting our comparative study are Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stochastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP), and RidgeClassifier. In the evaluation phase, our system gives F1 scores of 14.87% and 21.49%, for country-level MSA and DA identification respectively, which is very close to the average F1 scores achieved by the submitted systems and recorded for both subtasks (18.70% and 24.23%).', 'sk': 'V tem prispevku analiziramo učinek tehtanega povezovanja funkcij TF-IDF za nalogo identifikacije arabskega dialekta med sodelovanjem v skupni nalogi NADI2021. Ta študija se izvaja za dve podnalogi: podnalogo 1.1 (MSA na ravni države) in podnalogo 1.2 (DA na ravni države). Klasifikatorji, ki podpirajo našo primerjalno študijo, so Linear Support Vector Classification (LSVC), Linear Regression (LR), Perceptron, Stohastic Gradient Descent (SGD), Passive Aggressive (PA), Complement Naive Bayes (CNB), MutliLayer Perceptron (MLP) in RidgeClassifier. V fazi ocenjevanja naš sistem daje ocene F1 14,87% oziroma 21,49% za identifikacijo MSA na ravni države, kar je zelo blizu povprečnih ocen F1, doseženih s predloženimi sistemi in zabeleženih za obe podnalogi (18,70% oziroma 24,23%).'}
{'en': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'ar': 'نهج قائم على التعلم الآلي لتحديد اللهجة العربية', 'fr': "Approche basée sur l'apprentissage automatique pour l'identification des dialectes arabes", 'es': 'Enfoque basado en el aprendizaje automático para la identificación de dialectos árabes', 'pt': 'Abordagem baseada em aprendizado de máquina para identificação do dialeto árabe', 'zh': '盖机器学之阿拉伯语方言识别方法', 'ja': 'アラビア語方言識別のための機械学習ベースのアプローチ', 'hi': 'अरबी बोली पहचान के लिए मशीन लर्निंग-आधारित दृष्टिकोण', 'ru': 'Подход к идентификации арабского диалекта на основе машинного обучения', 'ga': 'Cur Chuige Meaisín-Bhunaithe chun Canúint Araibise a Aithint', 'ka': 'Name', 'hu': 'Gépi tanulás alapú megközelítés az arab dialekt azonosításhoz', 'lt': 'Mokymosi mechanizmais pagrįstas metodas arabų dialektų identifikavimui', 'el': 'Προσέγγιση βασισμένη στη μηχανική μάθηση για τον προσδιορισμό αραβικών διαλεκτών', 'it': "Approccio basato sull'apprendimento automatico per l'identificazione dialettica araba", 'mk': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'kk': 'Араб диалектік идентификациясының машинаның оқыту негізіндегі жағдайы', 'ms': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'mt': 'Approċċ ibbażat fuq it-Tagħlim tal-Magni għall-Identifikazzjoni tad-Dijaletta Għarbija', 'mn': 'Араб диалогын идентификацийн машин суралцах суралцах үндсэн арга барилга', 'ml': 'അറബി ഡയലേക്ക് തിരിച്ചറിയുന്നതിനുള്ള മെഷീന്\u200d പഠിക്കുന്നത്- അടിസ്ഥാനമായ സമീപത്തിലേക്കു്', 'pl': 'Podejście oparte na uczeniu maszynowym do identyfikacji dialektu arabskiego', 'no': 'Name', 'ro': 'Abordare bazată pe învățare automată pentru identificarea dialectelor arabe', 'sr': 'Na osnovu mašinskog pristupa za arapsku identifikaciju dijalekta', 'so': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'sv': 'Maskininlärningsbaserad metod för arabisk dialekt identifiering', 'si': 'Name', 'ur': 'عربی دیالکت شناخت کے لئے ماشین سیکھنے کی بنیادی تقریبا', 'ta': 'அரபி உரையாடல் அடிப்படையான அடையாளம்', 'uz': 'Name', 'vi': 'Máy để nhận diện cấu hình nhân tạo', 'bg': 'Базиран на машинно обучение подход за идентифициране на арабски диалект', 'da': 'Maskinlæringsbaseret tilgang til arabisk dialekt identifikation', 'hr': 'Pristup na osnovu učenja strojeva za arapsku identifikaciju dijalekta', 'id': 'Pendekatan Berdasarkan Belajar Mesin untuk Identifikasi Dialek Arab', 'ko': '기계 학습 기반의 아랍어 사투리 식별 방법', 'sw': 'Utambulisho wa Kiarabu wa Kujifunza Mashiniki', 'nl': 'Machine Learning-gebaseerde aanpak voor Arabische dialectidentificatie', 'de': 'Machine Learning-basierter Ansatz zur Identifikation arabischer Dialekte', 'fa': 'دسترسی بر پایه یادگیری ماشین برای شناسایی Dialect عربی', 'af': 'Masjien leer- gebaseerde toegang vir Arabiese Dialeksie Identifikasie', 'sq': 'Metoda bazuar në mësimin e makinës për identifikimin e dialektit arab', 'az': 'Arap칞a Dialekt Kimlikl톛ri 칲칞칲n Makinel톛 칐yr톛nm톛 B칲t칲n Yax캼nl캼q', 'am': 'መኪን ለመማር-Based Approach for Arabic Dialect Identification', 'hy': 'Մեքենայի ուսուցման հիմնված մոտեցումը արաբական դիլեկտի հայտնաբերման համար', 'bn': 'আরবী ডায়ালেক্টর পরিচয়পত্রের জন্য মেশিন শিক্ষা-ভিত্তিক প্রস্থান', 'bs': 'Motorski pristup na osnovu učenja za arapsku identifikaciju dijalekta', 'ca': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'cs': 'Přístup založený na strojovém učení pro identifikaci arabského dialektu', 'fi': 'Koneoppimiseen perustuva lähestymistapa arabiankielisen dialektin tunnistamiseen', 'et': 'Masinõppepõhine lähenemisviis araabia dialekti identifitseerimiseks', 'tr': 'Arabça dijalet bejermek üçin maşynyň öwrenmesini temel Approach', 'he': 'Machine Learning-Based Approach for Arabic Dialect Identification', 'jv': 'Language', 'ha': 'KCharselect unicode block name', 'bo': 'ཨ་རབ་ཀྱིས་ཁྱད་ཆོས་འཐབ་པའི་ལག་ལེན་སྨན་གཞི་རྟེན་ནས་གནད་སྤྱིར་ན།', 'sk': 'Pristop, ki temelji na strojnem učenju za identifikacijo arabskih dialektov'}
{'en': 'This paper describes our systems submitted to the Second Nuanced Arabic Dialect Identification Shared Task (NADI 2021). Dialect identification is the task of automatically detecting the source variety of a given text or speech segment. There are four subtasks, two subtasks for country-level identification and the other two subtasks for province-level identification. The data in this task covers a total of 100 provinces from all 21 Arab countries and come from the Twitter domain. The proposed systems depend on five machine-learning approaches namely Complement Nave Bayes, Support Vector Machine, Decision Tree, Logistic Regression and Random Forest Classifiers. F1 macro-averaged score of Nave Bayes classifier outperformed all other classifiers for development and test data.', 'es': 'Este documento describe nuestros sistemas presentados a la Segunda tarea compartida de identificación de dialectos árabes matizados (NADI 2021). La identificación de dialectos es la tarea de detectar automáticamente la variedad de origen de un segmento de texto o voz determinado. Hay cuatro subtareas, dos subtareas para la identificación a nivel de país y las otras dos subtareas para la identificación a nivel de provincia. Los datos de esta tarea cubren un total de 100 provincias de los 21 países árabes y provienen del dominio de Twitter. Los sistemas propuestos dependen de cinco enfoques de aprendizaje automático, a saber, Complement Naïve Bayes, Support Vector Machine, Decision Tree, Logistic Regression y Random Forest Classifiers. La puntuación macropromediada F1 del clasificador Naïve Bayes superó a todos los demás clasificadores en datos de desarrollo y prueba.', 'fr': "Cet article décrit nos systèmes soumis à la deuxième tâche partagée d'identification de dialecte arabe nuancé (NADI 2021). L'identification de dialecte consiste à détecter automatiquement la variété source d'un texte ou d'un segment vocal donné. Il y a quatre sous-tâches, deux sous-tâches pour l'identification au niveau du pays et les deux autres sous-tâches pour l'identification au niveau de la province. Les données de cette tâche couvrent un total de 100 provinces des 21 pays arabes et proviennent du domaine Twitter. Les systèmes proposés dépendent de cinq approches d'apprentissage automatique, à savoir la méthode bayésienne naïve du complément, la machine à vecteur de support, l'arbre de décision, la régression logistique et les classificateurs de forêts aléatoires. Le score moyen macro F1 du classificateur naïf bayésien a surpassé tous les autres classificateurs pour les données de développement et de test.", 'pt': 'Este artigo descreve nossos sistemas submetidos à segunda tarefa compartilhada de identificação de dialeto árabe com nuances (NADI 2021). A identificação do dialeto é a tarefa de detectar automaticamente a variedade de origem de um determinado texto ou segmento de fala. Existem quatro subtarefas, duas subtarefas para identificação em nível de país e as outras duas subtarefas para identificação em nível de província. Os dados desta tarefa abrangem um total de 100 províncias de todos os 21 países árabes e vêm do domínio do Twitter. Os sistemas propostos dependem de cinco abordagens de aprendizado de máquina: Complemento Naïve Bayes, Máquina de Vetor de Suporte, Árvore de Decisão, Regressão Logística e Classificadores de Floresta Aleatória. A pontuação média macro F1 do classificador Naïve Bayes superou todos os outros classificadores para dados de desenvolvimento e teste.', 'ar': 'تصف هذه الورقة أنظمتنا المقدمة إلى المهمة المشتركة الثانية لتحديد اللهجات العربية الدقيقة (NADI 2021). تحديد اللهجة هو مهمة الكشف التلقائي عن تنوع المصدر لنص معين أو مقطع كلام. هناك أربع مهام فرعية ، ومهمتان فرعيتان للتعريف على مستوى الدولة والمهمتين الفرعيتين الأخريين لتحديد مستوى المقاطعة. تغطي البيانات في هذه المهمة ما مجموعه 100 مقاطعة من جميع البلدان العربية البالغ عددها 21 دولة وتأتي من نطاق Twitter. تعتمد الأنظمة المقترحة على خمسة مناهج للتعلم الآلي وهي Complement Naïve Bayes و Support Vector Machine و Decision Tree والانحدار اللوجستي ومصنفات الغابات العشوائية. تفوق متوسط الدرجة الكلية F1 لمصنف Naïve Bayes على جميع المصنفات الأخرى لبيانات التطوير والاختبار.', 'ja': '本稿では、第2回ニュアンスアラビア方言識別共有タスク（ NADI 2021 ）に提出された当社のシステムについて説明します。方言識別は、与えられたテキストまたは音声セグメントのソースの多様性を自動的に検出するタスクです。4つのサブタスクがあり、国レベルの識別のための2つのサブタスクと、県レベルの識別のための他の2つのサブタスクがあります。このタスクのデータは、すべての21のアラブ諸国からの合計100の都道府県をカバーしており、Twitterドメインからのものです。提案されているシステムは、5つの機械学習アプローチ、すなわちComplement Naïve Bayes、Support Vector Machine、Decision Tree、Logistic回帰、およびRandom Forest Classifiersに依存している。Naïve Bayes分類子のF 1マクロ平均スコアは、開発および試験データに関する他の分類子を上回った。', 'zh': '本文引我等提交与第二细微差别阿拉伯语方言识共(NADI 2021)之统。 方言识者,自动检测给定文本语音片段种类之务也。 有四子职,二子以国/,二子以省级。 凡此数者,凡覆21阿拉伯国之100省,Twitter域名也。 所建统依五机器学术,即补码素贝叶斯,扶持向量机,决策树,逻辑归与随机林分类器。 朴贝叶斯分类器者 F1 宏均分于开测试数据,优于诸器。', 'hi': 'यह पेपर दूसरी बारीक अरबी बोली पहचान साझा कार्य (NADI 2021) को प्रस्तुत हमारे सिस्टम का वर्णन करता है। बोली पहचान किसी दिए गए पाठ या वाक् खंड की स्रोत विविधता का स्वचालित रूप से पता लगाने का कार्य है। चार उप-कार्य हैं, देश-स्तर की पहचान के लिए दो उप-कार्य और प्रांत-स्तर की पहचान के लिए अन्य दो उप-कार्य हैं। इस कार्य में डेटा सभी 21 अरब देशों के कुल 100 प्रांतों को कवर करता है और ट्विटर डोमेन से आता है। प्रस्तावित प्रणालियां पांच मशीन-सीखने के दृष्टिकोणों पर निर्भर करती हैं अर्थात् पूरक भोले बेयस, समर्थन वेक्टर मशीन, निर्णय ट्री, लॉजिस्टिक प्रतिगमन और यादृच्छिक वन क्लासिफायर। F1 मैक्रो-भोले Bayes क्लासिफायर के औसत स्कोर ने विकास और परीक्षण डेटा के लिए अन्य सभी क्लासिफायरों को पछाड़ दिया।', 'ru': 'В этой статье описываются наши системы, представленные для второй совместной задачи по идентификации диалекта арабского языка (НАДИ 2021). Диалектная идентификация - это задача автоматического обнаружения исходного разнообразия данного текста или речевого сегмента. Существуют четыре подзадачи, две подзадачи для идентификации на страновом уровне и две другие подзадачи для идентификации на уровне провинций. Данные, содержащиеся в этой задаче, охватывают в общей сложности 100 провинций из всех 21 арабской страны и поступают из сети "Твиттер". Предлагаемые системы зависят от пяти подходов машинного обучения, а именно: комплементарные наивные байесовские, поддерживающие векторные машины, дерево решений, логистическая регрессия и случайные лесные классификаторы. Макроусредненная оценка F1 классификатора Наив-Байеса превосходила все другие классификаторы для данных разработки и испытаний.', 'ga': 'Déanann an páipéar seo cur síos ar ár gcórais a cuireadh isteach chuig an Dara Tasc Comhroinnte um Shainaithint Chanúint Araibise Nuashonraithe (NADI 2021). Is éard atá i sainaithint canúintí an tasc chun éagsúlacht foinse de mhír téacs nó urlabhra ar leith a bhrath go huathoibríoch. Tá ceithre fhothasc ann, dhá fhothasc le haghaidh aitheantais ar leibhéal na tíre agus an dá fhothasc eile le haghaidh aitheantais ar leibhéal cúige. Clúdaíonn na sonraí sa tasc seo 100 cúigí san iomlán ó na 21 tír Arabacha ar fad agus tagann siad ó fhearann Twitter. Braitheann na córais atá beartaithe ar chúig chur chuige meaisínfhoghlama, is iad sin Cuan Naí Comhlánaithe, Meaisín Veicteoir Tacaíochta, Crann Cinnidh, Aischéimniú Lóistíochta agus Aicmitheoirí Randamach Foraoise. D’éirigh níos fearr leis an scór macraimheánach F1 d’aicmitheoir Naïve Bayes ná gach aicmitheoir eile maidir le forbairt agus sonraí tástála.', 'hu': 'Ez a tanulmány ismerteti a második nuanced arab dialekt azonosító megosztott feladat (NADI 2021) keretében benyújtott rendszereinket. A tárcsás azonosítás feladata egy adott szöveg vagy beszédszegmens forráskálájának automatikus felismerése. Négy részfeladat, két részfeladat országszintű azonosításra és a másik két részfeladat tartományszintű azonosításra. Ebben a feladatban szereplő adatok összesen 100 tartományt fednek fel mind a 21 arab országból, és a Twitter domainből származnak. A javasolt rendszerek öt gépi tanulási megközelítéstől függnek, nevezetesen Komplement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression és Random Forest Classifiers. A Naive Bayes osztályozó F1 makro-átlagos pontszáma felülmúlta az összes többi osztályozót a fejlesztési és tesztadatok tekintetében.', 'el': 'Η παρούσα εργασία περιγράφει τα συστήματά μας που υποβλήθηκαν στη δεύτερη κοινή εργασία ταυτοποίησης αραβικών διαλεκτών (NADI 2021). Η αναγνώριση διαλεκτών είναι το καθήκον της αυτόματης ανίχνευσης της ποικιλίας πηγής ενός συγκεκριμένου κειμένου ή τμήματος ομιλίας. Υπάρχουν τέσσερις δευτερεύουσες εργασίες, δύο δευτερεύουσες εργασίες για τον προσδιορισμό σε επίπεδο χώρας και οι άλλες δύο δευτερεύουσες εργασίες για τον προσδιορισμό σε επίπεδο επαρχίας. Τα δεδομένα σε αυτό το έργο καλύπτουν συνολικά 100 επαρχίες από όλες τις 21-αραβικές χώρες και προέρχονται από τον τομέα του Twitter. Τα προτεινόμενα συστήματα εξαρτώνται από πέντε προσεγγίσεις μηχανικής μάθησης, συγκεκριμένα από τη συμπλήρωση αφελής μηχανής, τη διανυσματική μηχανή υποστήριξης, το δέντρο αποφάσεων, την λογιστική υποβάθμιση και τους τυχαίους δασικούς ταξινομητές. Η μακρομέση βαθμολογία F1 του ταξινομητή Naive Bayes ξεπερνούσε όλους τους άλλους ταξινομητές για δεδομένα ανάπτυξης και δοκιμής.', 'lt': 'This paper describes our systems submitted to the Second Nuanced Arabic Dialect Identification Shared Task (NADI 2021).  Dialekcijos identifikavimas yra užduotis automatiškai aptikti tam tikro teksto arba kalbos segmento šaltinio įvairovę. There are four subtasks, two subtasks for country-level identification and the other two subtasks for province-level identification.  The data in this task covers a total of 100 provinces from all 21 Arab countries and come from the Twitter domain.  Siūlomos sistemos priklauso nuo penkių mašinų mokymosi metodų, būtent nuo papildomų nepilnamečių įlankų, paramos vektorių mašinų, sprendimų medžio, logistinės regresijos ir atsitiktinių miškų klasifikatorių. F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.', 'it': "Questo articolo descrive i nostri sistemi sottoposti al secondo compito condiviso di identificazione dialettica araba Nuanced (NADI 2021). L'identificazione dialettica è il compito di rilevare automaticamente la varietà di origine di un determinato segmento di testo o discorso. Ci sono quattro sottoattività, due sottoattività per l'identificazione a livello nazionale e le altre due sottoattività per l'identificazione a livello provinciale. I dati in questo compito coprono un totale di 100 province di tutti i 21 paesi arabi e provengono dal dominio Twitter. I sistemi proposti dipendono da cinque approcci di apprendimento automatico: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression e Random Forest Classifiers. Il punteggio macro-medio F1 del classificatore Naive Bayes ha superato tutti gli altri classificatori per i dati di sviluppo e test.", 'kk': 'Бұл қағаз біздің жүйелерімізді Екінші Nuanced Arabic Dialect идентификациясының ортақ тапсырмасына жіберілген тапсырманы (NADI 2021) анықтайды. Таңдау идентификациясы - келтірілген мәтін не сөздің сегментін автоматты түрде анықтау тапсырмасы. Ел деңгейіндегі идентификациялау үшін төрт ішкі сұрақ, екі ішкі сұрақ және басқа екі ішкі сұрақ, ауыл деңгейіндегі идентификациялау үшін. Бұл тапсырманың мәліметі барлық 21 Араб елдерінен 100 провинциясы бар және Twitter доменінен келеді. Келтірілген жүйелер бес машиналық оқыту көмегімен тәуелді: толтыру көмегімен, вектор машинасын қолдау, шешім бұтағы, логистикалық регрессия және кездейсоқ орман классификаторларына тәуелді. F1 Naive Bayes классификациясының макро орташасында барлық басқа классификацияларды жасау және сынақтар деректерінің барлық классификацияларына арналған.', 'ms': 'This paper describes our systems submitted to the Second Nuanced Arabic Dialect Identification Shared Task (NADI 2021).  Dialect identification is the task of automatically detecting the source variety of a given text or speech segment.  Terdapat empat sub-tanya, dua sub-tanya untuk pengenalpasti aras negara dan dua sub-tanya lain untuk pengenalpasti aras provinsi. The data in this task covers a total of 100 provinces from all 21 Arab countries and come from the Twitter domain.  The proposed systems depend on five machine-learning approaches namely Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression and Random Forest Classifiers.  Skor makro-rata-rata F1 bagi pengeklasifikasi Naive Bayes melampaui semua pengeklasifikasi lain untuk pengembangan dan data ujian.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ സിസ്റ്റത്തെ രണ്ടാമത്തെ നുയാങ്ക് ചെയ്ത അറബി ഡയലക്ട്രിക്ക് കൊടുത്തിരിക്കുന്നു ഒരു നല്\u200dകപ്പെട്ട ട ടെക്സ്റ്റ് അല്ലെങ്കില്\u200d സംസാരിക്കുന്ന വ്യത്യസ്തമായി സ്വയം കണ്ടുപിടിക്കുന്ന ജോലിയാണ നാലു സബ്ട്ജിസുകളുണ്ട്, രാജ്യത്തിന്റെ നില തിരിച്ചറിയാനുള്ള രണ്ടു സബ്ട്ടുജോലികള്\u200d, പ്രൊസിന്റെ നില തിരിച ഈ ജോലിയിലെ വിവരങ്ങള്\u200d 21 അറബിലെ രാജ്യങ്ങളില്\u200d നിന്നും മൊത്തം 100 പ്രദേശങ്ങള്\u200d പൂര്\u200dണ്ണമായി വെച്ചിരിക്കുന്ന പ്രൊദ്ദേശിക്കപ്പെട്ട അഞ്ചു മെഷീന്\u200d പഠിക്കുന്ന സിസ്റ്റത്തില്\u200d ആശ്രയിച്ചിരിക്കുന്നു. സമ്പൂര്\u200dണ്ണമെന്റ് നേവ് ബെയ്സ്, വെക്റ്റര്\u200d മെഷീന എഫ്\u200c1 മാക്രോ-സാധാരണ സ്കോര്\u200d നാവ് ബെയ്സ് ക്ലാസ്ഫിഫര്\u200d വികസിപ്പിക്കുന്നതിനും പരീക്ഷ വിവരങ്ങള്\u200dക്കും വേറെ എല്ല', 'mk': 'This paper describes our systems submitted to the Second Nuanced Arabic Dialect Identification Shared Task (NADI 2021).  Dialect identification is the task of automatically detecting the source variety of a given text or speech segment.  There are four subtasks, two subtasks for country-level identification and the other two subtasks for province-level identification.  The data in this task covers a total of 100 provinces from all 21 Arab countries and come from the Twitter domain.  Предложените системи зависат од пет пристапи на машинско учење, а потоа од комплементните наивни заливи, поддршка на векторната машина, дрвото на одлуките, логистичката регресија и случајните класификатори на шумите. Ф1 макро-просечен резултат на класификаторот Naive Bayes ги надмина сите други класификатори за развој и тестови податоци.', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tagħna ppreżentati għat-Tieni Kompitu Konġunt ta’ Identifikazzjoni tad-Djalett Għarab Nuanced (NADI 2021). L-identifikazzjoni tad-dijalek hija l-kompitu li tiġi identifikata awtomatikament il-varjetà tas-sors ta’ test jew segment tad-diskors partikolari. Hemm erba’ sottotalbiet, żewġ sottotalbiet għall-identifikazzjoni fil-livell tal-pajjiż u ż-żewġ sottotalbiet l-oħra għall-identifikazzjoni fil-livell tal-provinċja. The data in this task covers a total of 100 provinces from all 21 Arab countries and come from the Twitter domain.  Is-sistemi proposti jiddependu fuq ħames approċċi ta’ tagħlim bil-magna, jiġifieri l-Bajżi Mhux Komplimentati, il-Makkinarju tal-Vetturi ta’ Appoġġ, is-Siġar tad-Deċiżjonijiet, ir-Regressjoni Loġistika u l-Klassifikaturi tal-Foresti Random. Il-punteġġ makro-medju F1 tal-klassifikatur Naive Bayes qabeż il-klassifikaturi l-oħra kollha għall-iżvilupp u d-dejta tat-testijiet.', 'mn': 'Энэ цаас бидний системийг хоёр дахь нуансийн Араб диалектын идентификацийн хуваалтын ажил (NADI 2021) руу тайлбарлаж байна. Шинэ сонголтын тодорхойлолт нь өгөгдсөн текст эсвэл ярианы хэлбэрийн эх үүсвэрийг автоматжуулах үйл ажил юм. Улсын түвшинд тодорхойлох хоёр суурь суурь, улсын түвшинд хоёр суурь суурь суурь, улсын түвшинд тодорхойлох хоёр суурь суурь суурь суурь суурь. Энэ ажил дээрх мэдээллүүд бүх 21 Араб улс орнуудаас 100 орон нутагтай байдаг ба Твиттерээс гарч ирдэг. Энэ санал дэвшүүлсэн систем нь машины суралцах таван хүрээний тулд хамааралтай: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression, Random Forest Classifiers юм. F1 Макро дундаж Нэйв Бейс классификацийн дундаж нь хөгжлийн болон шалгалтын өгөгдлийн хувьд бусад бүх классификацийг давхарлаа.', 'pl': 'Niniejszy artykuł opisuje nasze systemy zgłoszone do Drugiego Nuanced Arabic Dialect Identification Shared Task (NADI 2021). Identyfikacja dialektu to zadanie automatycznego wykrywania różnorodności źródłowej danego tekstu lub segmentu mowy. Istnieją cztery podzadania, dwa podzadania identyfikacji na poziomie kraju i dwa pozostałe podzadania identyfikacji na poziomie prowincji. Dane w tym zadaniu obejmują łącznie setki prowincji ze wszystkich 21-tych krajów arabskich i pochodzą z domeny Twitter. Proponowane systemy opierają się na pięciu podejściach uczenia maszynowego, mianowicie Complement Naive Bayes, Support Vector Machine, Decision Tree, Regresji Logistycznej i Klasyfikacjach Lasów Losowych. Makro-średni wynik F1 klasyfikatora Naive Bayes przewyższył wszystkie inne klasyfikatory w zakresie danych rozwojowych i testowych.', 'no': 'Denne papiret beskriver systemet våre som er sendt til den andre nulserte arabiske dialektidentifikasjonen delt oppgåva (NADI 2021). Dialect- identifikasjon er oppgåva for automatisk oppdaging av kjeldevariasjonen av eit gitt tekst eller talesegment. Det finst fire underspørsmål, to underspørsmål for identifisering av landnivå og andre to underspørsmål for identifisering av provinsenivå. Data i denne oppgåva dekker totalt 100 provinsiar frå alle 21 arabiske land og kommer frå Twitter-domenet. Dette første systemet er avhengig av fem maskinelæringstilnærmingar som er komplettering av Naive Bayes, støtte vektormaskina, beslutningstetre, logistisk regresjon og tilfeldig skogsklassifiserar. F1 makro- gjennomsnittsfarge poeng av Naive Bayes- klassifiserer utførte alle andre klassifiserar for utviklingar og test data.', 'ro': 'Această lucrare descrie sistemele noastre depuse la a doua sarcină comună de identificare dialectă arabă nuanced (NADI 2021). Identificarea dialectelor este sarcina de a detecta automat varietatea sursă a unui anumit text sau segment de vorbire. Există patru subactivități, două subactivități pentru identificarea la nivel de țară și celelalte două subactivități pentru identificarea la nivel de provincie. Datele din această sarcină acoperă un total de 100 de provincii din toate cele 21 de țări arabe și provin din domeniul Twitter. Sistemele propuse depind de cinci abordări de învățare automată și anume Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression și Random Forest Classificators. Scorul macro-mediu F1 al clasificatorului Naive Bayes a depășit toți ceilalți clasificatori pentru dezvoltare și date de testare.', 'si': 'මේ පැත්තේ අපේ පද්ධතියේ දෙවෙනි නුවන්ස් අරාබික් විශ්වාස සංඥානය සම්බන්ධ කර්මය (NADI 2021) වෙනුවෙන්. ස්වයංක්\u200dරීය විදිහට පරීක්ෂණය ස්වයංක්\u200dරීය විදිහට පරීක්ෂණය යුතුයි. දේශ ප්\u200dරමාණය සඳහා අනිත් ප්\u200dරමාණය සඳහා අනිත් ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා අනිත් ප්\u200dරමාණය සඳහා අනිත් ප්\u200dරමාණ මේ වැඩේ තොරතුරු අරාබ් දේශ 21 වලින් සියලු ප්\u200dරදේශ 100ක් ඇතුළත් කරනවා ඒ වගේම ට්විටර් ඩොමේන් වලින්  ප්\u200dරශ්නය කරපු පද්ධතිය පහත් පද්ධතියේ අවශ්\u200dය විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත ව F1 මැක්රෝවේස් විශේෂණය සහ පරීක්ෂණය දත්ත සඳහා අනිත් විශේෂකයෝ සේරම විශේෂකයෙන් ප්\u200dරතික්\u200dරියාත්ම', 'sr': 'Ovaj papir opisuje naše sisteme podignute Drugom zajedničkom zadatku o identifikaciji dijaleta Arapskog dijaleta (NADI 2021). Identifikacija dijalekta je zadatak automatskog otkrivanja različita izvora određenog teksta ili govornog segment a. Postoje četiri podrška, dva podrška za identifikaciju na nivou zemlje i druga dva podrška za identifikaciju na nivou provincije. Podaci u ovom zadatku pokrivaju ukupno 100 provincija iz svih 21 arapskih zemalja i dolaze iz Twitter domena. Predloženi sistemi zavise od pet pristupa mašinskog učenja, to je kompletna baza, podrška vektorskoj mašini, odlučivanja drveta, logičke regresije i nasumičnih klasifikatora šume. F1 makro-srednji rezultat klasifikatora Naive Bayes iznosio je sve ostale klasifikatore za razvoj i test podataka.', 'so': 'Kanu wuxuu ku qoran yahay nidaamkayaga loo dhiibay Second Nuanced Carabi Dialect Identification Shared Shaqad (NADI 2021). Aqoonsiga sawirku waa shuqulka aad si automatic ah ugu ogaato asalka ay noocyo kala duduwan yihiin qoraal ama qeyb luqad ah. Waxaa jira afar shabakad, labo shahaado oo lagu yaqaan aqoonsiga wadanka iyo labada shaqo oo kale ee aqoonsiga heerka gobolka. Macluumaadka arimahan waxaa ku qoran 100 gobol oo ka mid ah 21 wadamada Carabiga oo dhan waxaana ka imaanaya xafiiska Twitterka. Isticmaalka la soo jeedo waxay ku xiran yihiin shan qaabab waxbarasho oo machine ah Complement Naive Bayes, Support Vector machine, Decision tree, Logistic Regression and Random Forest Classifiers. F1 macro-average score of Naive Bayes classifier ayaa ka baxay fasaxyada kale oo dhan si ay u koraan iyo imtixaanka.', 'ta': 'இந்த தாள் எங்கள் அமைப்புகளை குறிப்பிடுகிறது இரண்டாவது துணைக்கப்பட்ட அரபி உரையாடல் அடையாளம் பகிர்ந்த பணிக்கு (NADI 2021). கொடுக்கப்பட்ட உரை அல்லது பேச்சு துண்டத்தை தானாகவே கண்டுபிடிக்கும் செயல் நான்கு உப பணிகள் உள்ளன, நாட்டு நிலை அடையாளத்திற்கு இரண்டு உப பணிகள் மற்றும் பிராநிலை அடையாளத்திற்கு மற்ற இரண்டு உப ச் இந்த செயலில் உள்ள தகவல் அனைத்து 21 அரபு நாடுகளில் இருந்தும் மொத்தமான 100 பிராந்தியங்களை மற்றும் Twitter டோமைனில் இருந் திருத்தப்பட்ட அமைப்புகள் ஐந்து இயந்திரத்தை கற்றுக்கொள்ளும் முறைமையில் சார்ந்திருக்கும் சார்ந்திருக்கும் முறைமை F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.', 'ur': 'This paper describes our systems submitted to the second Nuanced Arabic Dialect Identification Shared Task (NADI 2021). Dialect identification is the task of automatically detecting the source variety of a given text or speech segment. چار سٹسٹسٹ ہیں، دو سٹسٹسٹ ہیں ملک سطح شناسایی کے لئے اور دوسرے دو سٹسٹسٹ ہیں منطقه سطح شناسایی کے لئے. اس کام میں ڈیٹا پورے ۱۰۰ منطقه کو پورے ۱۲ عربی ملک سے پورے کرتا ہے اور ٹویٹر ڈیمین سے آتا ہے۔ پیشنهاد کی سیسٹم پانچ ماشین سکونت کی آمیزش پر اعتماد ہے یعنی Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression اور Random Forest Classifiers. اف ۱ میکرومتوسط اسکور نائیو بیز کلیسفر نے تمام دوسرے کلیسٹر کو توسعہ اور ٹیسٹ ڈیٹ کے لئے انجام دیا۔', 'sv': 'Denna uppsats beskriver våra system som lämnats in till den andra Nuanced Arabic Dialect Identification Shared Task (NADI 2021). Dialekt identifiering är uppgiften att automatiskt identifiera källvariationen för ett visst text- eller talsegment. Det finns fyra deluppgifter, två deluppgifter för identifiering på landsnivå och de andra två deluppgifterna för identifiering på provinsnivå. Uppgifterna i denna uppgift omfattar totalt 100 provinser från alla 21 arabländer och kommer från Twitter-domänen. De föreslagna systemen är beroende av fem maskininlärningsmetoder, nämligen Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression och Random Forest Classifiers. F1 makro-genomsnittspoäng för Naive Bayes klassificerare överträffade alla andra klassificerare för utveckling och testdata.', 'ka': 'ამ დოკუმენტი ჩვენი სისტემები, რომელიც მეორე ნუანსიური აპაბიური დიალექტიფიკაციის იდენტიფიკაცია გაყოფილი დავალება (NADI 2021). Dialect იდენტიფიკაცია არის მონიშნული ტექსტის ან სიტყვების სექმენტის მსოფლიო განსხვავება. არსებობს ოთხი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკ ამ დავალების მონაცემები 100 პროვინციების ყველაფერი 21 აპაბი ქვეყნების განმავლობაში და Twitter-ის დემომინიდან მოთავსდება. პროგრამეტული სისტემები დააყენება ხუთი მანქანის სწავლების მიღებზე, ანუ დასრულებული ნაიგ ბეზები, გვეკტორის მაქანის მხარდაჭერები, გადაწყვეტის ხე, ლოგისტიკური რეგრესი და პანელი F1 მაკრო განსაზღვრებული მონაცემების კლასიფიკაციერის მაკრო-განსაზღვრებული მონაცემები უფრო გავაკეთება ყველა სხვა კლასიფიკაციერი განვითარებისთვის და ტე', 'vi': 'Tờ giấy này mô tả hệ thống của chúng tôi được gửi đến Công việc chia sẻ bộ phận nhân tạo Á Rập. Nhận diện thoại là nhiệm vụ giám sát tự động các nguồn của một đoạn văn bản hay đoạn văn bản riêng. Có bốn phụ đề, hai phụ đề cho việc xác định cấp quốc gia và hai phụ đề khác cho việc nhận diện cấp tỉnh. Dữ liệu trong nhiệm vụ này bao gồm toàn bộ các tỉnh hàng trăm từ các quốc gia Á Rập khác đến từ Twitter. Các hệ thống được đề xuất phụ thuộc vào năm phương pháp nghiên cứu cỗ máy, gồm phức tạp Nai sừng tấm, Cổ Máy Bóng Phục sinh, cây quyết định, Hồi phục lôgícic và các trường Tự Động. F1 số lượng đĩa vi phân loại Nai Bayes đã được chia ra bởi tất cả các phân loại khác để phát triển và kiểm tra dữ liệu.', 'uz': "Bu hujjat ikkinchi nuqta qo'shilgan arab dialeksi (NADI 2021) tizimimizni anglatadi. Tanlangan obʼektlarni avtomatik aniqlash vazifasi koʻrsatish. Davlat darajasi identifikatidagi ikkita sub vazifalar va boshqa ikkita sub-vazifalar mavjud. Bu vazifaning ma'lumotlari hamma 21 Arab davlatdan butun 100 provinclarni qaraydi va Twitter domenadan keladi. Tashkilotgan tizim, Naiv Bayes, Vector Mashini qoʻllash, Decision Tree, Logistik boshqarish va Tasodifiy daraxt klassifierlariga ishlatadi. F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.", 'nl': 'Deze paper beschrijft onze systemen die zijn ingediend bij de tweede nuanced Arabische dialect identification Shared Task (NADI 2021). Dialectidentificatie is de taak om automatisch de bronverscheidenheid van een bepaalde tekst of spraaksegment te detecteren. Er zijn vier subtaken, twee subtaken voor identificatie op landenniveau en de andere twee subtaken voor identificatie op provincieniveau. De gegevens in deze taak bestrijken in totaal 100 provincies uit alle 21-Arabische landen en komen uit het Twitter-domein. De voorgestelde systemen zijn afhankelijk van vijf machine-learning benaderingen, namelijk Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression en Random Forest Classifiers. F1 macro-gemiddelde score van Naive Bayes classificator overtrof alle andere classificatoren voor ontwikkelings- en testgegevens.', 'bg': 'Настоящата статия описва нашите системи, подадени на Втората споделена задача за идентификация на диалект с нуанширан арабски диалект (NADI 2021). Идентификацията на диалекта е задачата за автоматично откриване на сорта източник на даден текст или речен сегмент. Има четири подзадачи, две подзадачи за идентификация на ниво държава и другите две подзадачи за идентификация на ниво провинция. Данните в тази задача обхващат общо 100 провинции от всички 21 арабски страни и идват от домейна на Туитър. Предложените системи зависят от пет подхода за машинно обучение, а именно допълване на наивни Байес, поддръжка на векторна машина, дърво на решения, логистична регресия и случайни горски класификатори. Макросредненият резултат на Нейния класификатор на Байс превъзхожда всички останали класификатори за разработка и тестови данни.', 'hr': 'Ovaj papir opisuje naše sustave podignute Drugom zajedničkom zadatku o identifikaciji dijaleta iz Arapskog dijaleta (NADI 2021). Identifikacija dijalekta je zadatak automatskog otkrivanja različita izvora određenog teksta ili govornog segment a. Postoje četiri podrška, dvije podrške za identifikaciju na razini zemlje i druge dvije podrške za identifikaciju na razini pokrajine. Podaci u ovom zadatku pokrivaju ukupno 100 pokrajina iz svih 21 arapskih zemalja i dolaze iz Twitter domena. Predloženi sustavi zavise od pet pristupa za učenje strojeva, to su kompletne zaljeve, podrška vektorskoj mašini, odlučivanje drveta, logičke regresije i slučajnih klasifikatora šume. F1 makro-srednji rezultat klasifikatora Naive Bayes iznosio je sve ostale klasifikatore za razvoj i ispitivanje podataka.', 'da': 'Denne artikel beskriver vores systemer, der er indsendt til Anden Nuanced Arabic Dialect Identification Shared Task (NADI 2021). Dialekt identifikation er opgaven med automatisk at registrere kildeortet for et givet tekst- eller talesegment. Der er fire underopgaver, to underopgaver til identifikation på landsniveau og de andre to underopgaver til identifikation på provinsniveau. Dataene i denne opgave dækker i alt 100 provinser fra alle 21 arabiske lande og kommer fra Twitter-domænet. De foreslåede systemer afhænger af fem maskinlæringsmetoder, nemlig Komplement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression og Random Forest Classifiers. F1 makro-gennemsnitsscore for Naive Bayes klassificerer bedre end alle andre klassificerere for udviklings- og testdata.', 'de': 'Diese Arbeit beschreibt unsere Systeme, die der zweiten nuanced arabischen Dialect Identification Shared Task (NADI 2021) unterzogen wurden. Dialektidentifikation ist die Aufgabe, die Quellenvielfalt eines bestimmten Text- oder Sprachsegments automatisch zu erkennen. Es gibt vier Teilaufgaben, zwei Teilaufgaben zur Identifizierung auf Länderebene und die anderen beiden Teilaufgaben zur Identifizierung auf Provinzebene. Die Daten in dieser Aufgabe umfassen insgesamt 100 Provinzen aus allen 21-arabischen Ländern und stammen aus der Twitter-Domain. Die vorgeschlagenen Systeme basieren auf fünf maschinellen Lernansätzen: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression und Random Forest Classifiers. Der Makro-Durchschnittswert F1 des Naive Bayes Klassifikators übertraf alle anderen Klassifikatoren für Entwicklungs- und Testdaten.', 'id': 'Kertas ini menjelaskan sistem kami yang dikirim ke Tugas Identifikasi Dialek Arab Kedua (NADI 2021). Identifikasi dialeks adalah tugas untuk mendeteksi secara otomatis variasi sumber dari segmen teks atau pidato yang diberikan. Ada empat subtasks, dua subtasks untuk identifikasi tingkat negara dan dua subtasks lainnya untuk identifikasi tingkat provinsi. Data dalam tugas ini meliputi total 100 provinsi dari semua 21 negara Arab dan berasal dari Twitter domain. Sistem yang diusulkan bergantung pada lima pendekatan pembelajaran mesin, yaitu Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression dan Random Forest Classifiers. Skor makro-rata-rata F1 dari klasifikasi Naive Bayes melebihi semua klasifikasi lainnya untuk pengembangan dan data tes.', 'ko': '본고는 우리가 두 번째 미묘한 아랍어 사투리 식별 공유 임무(NADI 2021)에 제출한 시스템을 묘사한다.사투리 식별은 주어진 텍스트나 음성 세션의 원본 변체를 자동으로 검출하는 작업이다.모두 네 개의 하위 임무가 있는데 두 개의 하위 임무는 국가급 식별에 사용되고 다른 두 개의 하위 임무는 성급 식별에 사용된다.이 임무의 데이터는 트위터 도메인 이름에서 나온 21개 아랍 국가 100개 성을 포함한다.제시된 시스템은 다섯 가지 기계 학습 방법, 즉 상호 보완 소박 베일스, 지원 벡터 머신, 결정 트리, 논리 회귀와 무작위 삼림 분류기에 의존한다.데이터 개발 및 테스트 측면에서 소박 베일러스 분류기의 F1 매크로는 다른 모든 분류기보다 평균 점수가 우수하다.', 'tr': 'Bu käze biziň sistemlerimizi ikinji täze Arapça dilini paýlaşýar (NADI 2021). Saýlaw hatlary öz bellenen metin ýa çykyş segmentiniň çeşitlisini otomatik a ňlamak zadydyr. Ýurt derejesi kimligi üçin dört sany alt sorag bar we welaýat derejesi kimligi üçin beýleki iki alt sorag bar. Bu zadyň maglumaty 21 Arab ça ülkeden 100 welaýatyny ýazyp, Twitter domenyndan geldi. Bu teklip sistemalar maşynyň öwrenmesi üçin beş ýagdaýynda ynamly bolýar. Tamamlama Naive Baylar, Vektor Makineye Destek Makineye, Kararyň Treei, Logistik Regresi we Taýdaly Ot Sözleyici. F1 Makro ortalamasynda Naive Bayes klasifikatynyň beýleki klasifikatçylary gelişme we testi maglumatlary üçin üstüne çykardy.', 'fa': 'این کاغذ سیستم\u200cهای ما را توضیح می\u200cدهد که به کارهای مشترک مشترک شناسایی دایلاکت عربی دوم (NADI 2021) فرستاده شده است. شناسایی انتخاب کار خودکار کشف تنوع منبع یک بخش متن یا سخنرانی داده است. چهار زیر خواب وجود دارد، دو زیر خواب برای شناسایی سطح کشور و دو زیر خواب برای شناسایی سطح استان وجود دارد. اطلاعات در این وظیفه جمعیت ۱۰۰ استان را از همه ۲۱ کشور عربی پوشیده می\u200cکند و از دومین توئیتر می\u200cآیند. این سیستم پیشنهاد بستگی دارد از پنج نزدیک یادگیری ماشین به عنوان کامل سایب\u200cها، دستگاه پشتیبانی ویکتورها، درخت تصمیم، بازگشت منطقی و کلاسفارهای جنگل تصادفی. نقطه\u200cهای مکرو متوسط F1 از مجموعه\u200cکننده\u200cی مجموعه\u200cای Naive Bayes از همه\u200cی بقیه\u200cی مجموعه\u200cکننده\u200cها برای توسعه و آزمایش داده\u200cها بیشتر از آن انجام داده\u200cاند.', 'sw': 'Gazeti hili linaelezea mfumo wetu uliotolewa kwa Kiarabu wa pili wa Utambulisho wa Kutambuliwa kwa Kiarabu (NADI 2021). Utambulisho wa utambulisho ni jukumu la kujitambua vyanzo vingi vya maandishi au sehemu ya hotuba. Kuna kazi nne, kazi mbili za kutambua kiwango cha nchi na kazi nyingine mbili za kutambua kiwango cha jimbo. Takwimu katika juhudi hili zinajumuisha majimbo 100 kutoka nchi zote 21 za Kiarabu na zinatoka kwenye tovuti ya Twita. The proposed systems depend on five machine-learning approaches namely Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression and Random Forest Classifiers.  Kiwango cha wastani cha F1 cha wataalamu wa Naive Bayes walifanya viwango vingine kwa ajili ya maendeleo na taarifa za jaribio.', 'am': "ይህ ፕሮግራም የሁለተኛው ነጥብ አረቢያ ቋንቋ የሚያሳውቀውን ስራ (NADI 2021) ስርዓታችንን ያሳያል፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s There are four subtasks, two subtasks for country-level identification and the other two subtasks for province-level identification.  የዚህ ስራ ዳታ ከ21 አረብ ሀገሮች ሁሉ በ100 ሀገሮች ሙሉ ይሸፍናሉ፡፡ የተዘጋጀው ስርዓቶች አምስት የሳንቃ ትምህርት ግንኙነት፣ የናይብ ባይስ፣ የዌctor መኪን፣ የፍርድ ዛፍ፣ Logistic Regression and Random Forest Classifiers የሚባል ነው፡፡ የነዌብ ባይስ ክፍላፊዎችን የF1 ማክሮር ተቃውሞ ለግንኙነት እና ለፈተና ዳታ የሚደረገውን ሁለተኛውን ክፍሎች አቀረበ፡፡", 'sq': 'Ky artikull përshkruan sistemet tona të paraqitura në Detyrën e Dytë të Përbashkët të Identifikimit të Dialektit Arab (NADI 2021). Identifikimi i dialektit është detyra e zbulimit automatik të ndryshimit të burimit të një segmenti të dhënë teksti apo fjalimi. Ka katër nënkërkesa, dy nënkërkesa për identifikimin e nivelit të vendit dhe dy nënkërkesa të tjera për identifikimin e nivelit të krahinës. Të dhënat në këtë detyrë mbulojnë 100 provinca nga të gjitha 21 vendet arabe dhe vijnë nga domenia e Twitter. Sistemet e propozuara varen nga pesë qasje mësimi i makinave, veçanërisht nga kompletimi i mjeteve të mëdha, mjetet e përkrahjes së vektorit, pemën e vendimeve, regresionin logjik dhe klasifikuesit e pyllit të rastësishëm. F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.', 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգերը, որոնք ներկայացված են Երկրորդ Արաբական դիալեկտի ինքնության համագործակցությանը (NADi2021). Դիալեկցիայի հայտնաբերումը նշանակում է ինքնաբերաբար հայտնաբերել որոշ տեքստի կամ խոսքի բաղադրամի աղբյուրների բազմազանությունը: Կան չորս ենթահարցեր, երկու ենթահարցեր երկրի մակարդակի հայտնաբերելու համար և երկու այլ ենթահարցեր նահանգի մակարդակի հայտնաբերելու համար: Այս խնդրի տվյալները ներառում են ամբողջ 21 արաբական երկրների 100 նահանգներ և գալիս են Թվիթերի ոլորտից: The proposed systems depend on five machine-learning approaches namely Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression and Random Forest Classifiers.  F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.', 'af': "Hierdie papier beskrywe ons stelsels wat na die tweede Nuanced Arabiese Dialeksie Identifikasie Gedeelde Taak (NADI 2021) voorgestuur is. Dialeksie identifikasie is die taak van outomaties die bron verskeiding van 'n gegewe teks of spraak segment. Daar is vier subtaske, twee subtaske vir landvlak identifikasie en die ander twee subtaske vir provinsie vlak identifikasie. Die data in hierdie taak bedek 'n totaal van 100 provinsies van alle 21 arabe lande en kom van die Twitter domein. Die voorgestelde stelsels afhang van vyf masjien-leer toegang, naamlik Voltooiïng Naive Bayes, Ondersteuning Vektor Masjien, Besluit Boom, Logistiese Regresie en Lukrake Voorskouklassifiers. F1 makro- gemiddelde skakel van Naive Bayes klassifiseerder uitgevoer alle ander klassifiseerders vir ontwikkeling en toets data.", 'az': 'Bu kağıt ikinci Nuanced Arapça Dialekt Kimliğini paylaşdırılmış sistemlərimizi (NADI 2021). Seçim tanıdırması verilən metin və söz segmentinin mənbəsini otomatik olaraq tanıtma işidir. Ülkə səviyyəsi təsdiqlənməsi üçün dörd dəstək var, iki dəstək təsdiqlənməsi və digər iki dəstək təsdiqlənməsi üçün. Bu işdə verilən məlumatlar 21 Arab ülkesindən 100 ölkələrin hamısını örtür və Twitter domeindən gəlir. Təsdiq edilmiş sistemlər beş maşın öyrənməsi yaxınlıqlarına bağlıdır: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression və Random Forest Classifierlar. F1 Makro-ortalamalı Naive Bayes klasifikatçısı təhsil və sınama məlumatı üçün bütün başqa klasifikatçıları üstün etdi.', 'bn': 'এই পত্রিকা ব্যাখ্যা করেছে দ্বিতীয় নুয়াঙ্কেড আরবী ডায়ালেক্টরের প্রতি আমাদের সিস্টেমের প্রতি জমা দেয়া হয়েছে (নাড ডায়ালেক্ট পরিচয় স্বয়ংক্রিয়ভাবে প্রদান করা একটি টেক্সট অথবা বক্তৃতার বিভিন্ন ভাগ সনাক্ত করার কাজ। দেশের স্তর পরিচিতির জন্য চারটি সাবটাকাজ, দুটি সাবটাকাজ এবং প্রদেশের পরিচিতির জন্য অন্য দুটি সাবটাকাজ রয়েছে। এই কাজের তথ্য প্রকাশ করা হয়েছে সারা ২১ আরব দেশ থেকে ১০০ প্রদেশ এবং টুইটার ডোমেইন থেকে এসেছে। প্রস্তাবিত পাঁচটি মেশিন শিক্ষার প্রতি নির্ভর করে যাওয়া প্রস্তাবিত সিস্টেমেন্ট নেভ বেয়েস, সমর্থন করে ভেক্টর মেশিন, সিদ্ধান্ত গাছ, লোগিস্ট এফ১ ম্যাক্রো গড় স্কোর নাইভ বেয়েস ক্লাসিফারের অন্যান্য সব ক্লাসিফার উন্নয়ন এবং পরীক্ষা তথ্যের জন্য প্রদর্শন কর', 'ca': "Aquest article descriu els nostres sistemes submetits a la Segona Tarefa Compartida d'Identificació de Dialektes Árabes Nuanced (NADI 2021). La identificació de la diàlecta és la tasca de detectar automàticament la varietat de fonts d'un segment de text o discurs. Hi ha quatre subtaskes, dues subtaskes per identificar a nivell nacional i les altres dues subtaskes per identificar a nivell provincial. Les dades d'aquesta tasca cobreixen un total de 100 provincies de tots els 21 països àrabs i provenen del domini de Twitter. Els sistemes proposats depenen de cinc enfocaments d'aprenentatge automàtic: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression i Random Forest Classifiers. F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.", 'cs': 'Tento článek popisuje naše systémy předložené Druhému nuanced arabskému dialect Identification Shared Task (NADI 2021). Identifikace dialektu je úkolem automatické detekce zdrojové rozmanitosti daného textu nebo řečového segmentu. Existují čtyři podúkoly, dva podúkoly pro identifikaci na úrovni země a další dva podúkoly pro identifikaci na úrovni provincie. Údaje v tomto úkolu pokrývají celkem sto provincií ze všech 21-arabských zemí a pocházejí z domény Twitter. Navržené systémy jsou závislé na pěti přístupech strojového učení, konkrétně Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression a Random Forest Classifiers. Makro-průměrné skóre F1 klasifikátoru Naive Bayes předčilo všechny ostatní klasifikátory pro vývoj a testovací data.', 'fi': 'Tässä artikkelissa kuvataan järjestelmiämme, jotka on lähetetty toiseen Nuanced Arabic Dialect Identification Shared Task (NADI 2021) -tehtävään. Dialektin tunnistus on tehtävä tunnistaa automaattisesti tietyn tekstin tai puheen segmentin lähdevaihtelu. On neljä alatehtävää, kaksi alatehtävää maakohtaista tunnistamista varten ja kaksi muuta alatehtävää maakohtaista tunnistamista varten. Tämän tehtävän tiedot kattavat yhteensä 100 provinssia kaikista 21 arabimaasta ja tulevat Twitter-verkkotunnuksesta. Ehdotetut järjestelmät riippuvat viidestä koneoppimisen lähestymistavasta: Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression ja Random Forest Classifiers. Naive Bayes -luokituksen F1 makrokeskiarvo ylitti kaikki muut luokitukset kehitys- ja testitietojen osalta.', 'et': 'Käesolevas artiklis kirjeldatakse meie süsteeme, mis on esitatud teisele nuanced araabia dialekti identifitseerimise jagatud ülesandele (NADI 2021). Dialekti identifitseerimine on ülesanne automaatselt tuvastada antud teksti või kõnesigmendi lähtevariant. On neli alamülesannet, kaks alamülesannet riigi tasandil identifitseerimiseks ja kaks ülejäänud alamülesannet provintsi tasandil identifitseerimiseks. Selle ülesande andmed hõlmavad kokku 100 provintsi kõigist 21 Araabia riigist ja pärinevad Twitteri domeenist. Kavandatud süsteemid sõltuvad viiest masinõppe lähenemisviisist, nimelt Complement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression ja Random Forest Classifiers. Naive Bayesi klassifikaatori F1 makrokeskmine skoor ületas kõiki teisi klassifikaatoreid arendus- ja testiandmete osas.', 'bs': 'Ovaj papir opisuje naše sisteme podignute Drugom zajedničkom zadatku o identifikaciji dijaleta Arapskog dijaleta (NADI 2021). Identifikacija dijalekta je zadatak automatskog otkrivanja različita izvora određenog teksta ili govornog segment a. Postoje četiri podrška, dva podrška za identifikaciju na nivou zemlje i druga dva podrška za identifikaciju na nivou pokrajine. Podaci u ovom zadatku pokrivaju ukupno 100 provincija iz svih 21 arapskih zemalja i dolaze iz Twitter domena. Predloženi sistemi zavise od pet pristupa za učenje strojeva, to je kompletna baza, podrška vektorskoj mašini, odlučivanje drveta, logičke regresije i slučajnih klasifikatora šume. F1 makro-srednji rezultat klasifikatora Naive Bayes iznosio je sve ostale klasifikatore za razvoj i test podataka.', 'ha': "Wannan karatun yana bayyana tsaroyinmu wanda aka aika zuwa na'ura na Nuanced Arabic Dialog Shirin zaɓen akwatin bayani ni'ani ne aikin ka gane nau'in kwanan kwanan da aka bai wa matsayi ko rabon magana farat ɗaya. Kuna da aikin huɗu, taskõki biyu wa shaidar daraja na ƙasan, da sauran taskõki biyu wa shaidar daraja na province. Takardan da ke cikin wannan aikin yana rufe jama'a 100 provinces daga duk mataifa 21 arabu kuma yana daga Twitter. Ana ƙayyade na'urar da aka karɓi, ana ƙayyade kowanta masu karatun mafakin mafakin ayuka kamar Compliment Naive Bayes, Support Vertor Machine, Tafiyar da Geri na Taimaki, Logistic Regression and Classifiers F1 macro-aged score of Naive Bayes classifiserer outperformed all other classifiers for Development and Test data.", 'he': 'This paper describes our systems submitted to the Second Nuanced Arabic Dialect Identification Shared Task (NADI 2021).  זיהוי חיבור הוא המשימה של לגלות באופן אוטומטי את מגוון המקור של טקסט או חלק הנאום מסוים. ישנן ארבעה תחתונות, שתי תחתונות לזהות רמה מדינה ושני השאלות האחרות לזהות רמה מדינה. הנתונים במשימה הזאת מכילים בסך הכל 100 מחוזות מכל 21 מדינות ערביות ובואים מתחום הטוויטר. המערכות המוצעות תלויות בחמש גישות לימוד מכונות, בין הן בייס נויבי מלא, מכונת קטור תמיכה, עץ החלטות, חזרה לוגיסטית וקlassifikatורי יערות אקראיים. נקודת מקרו-ממוצע F1 של מסווג Naive Bayes עברה את כל מסווגים אחרים לפיתוח ובדיקות נתונים.', 'sk': 'Ta prispevek opisuje naše sisteme, predložene drugemu nuanced arabskemu dialektu identifikacije skupne naloge (NADI 2021). Identifikacija dialekta je naloga samodejnega zaznavanja izvorne raznolikosti danega besedila ali govornega segmenta. Obstajajo štiri podnaloge, dve podnalogi za identifikacijo na ravni države in drugi dve podnalogi za identifikacijo na ravni province. Podatki v tej nalogi zajemajo skupno 100 provinc iz vseh 21 arabskih držav in prihajajo iz domene Twitter. Predlagani sistemi so odvisni od petih pristopov strojnega učenja, in sicer komplement Naive Bayes, Support Vector Machine, Decision Tree, Logistic Regression in Random Forest Classifiers. Makrovprečni rezultat F1 za razvojne in testne podatke je presegel vse ostale klasifikatorje.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི་རྩ་ལག་ཆ་རྣམས་ཟུར་བ་གཉིས་པ་ལ་འཛུགས་སྤྱོད་པའི་ཨ་རིའི་ནང་དུ་བཤད་པ་དང་། འདེམས རྒྱལ་ཁབ་ཀྱི་གནས་ཚུལ་འདི་བཞིན་ཡོད་པ་དང་། རྒྱལ་ཁབ་ཀྱི་གནས་ཚུལ་འདི་ངོས་འཛིན་བྱེད་ཀྱི་subtasks་གཉིས་ཡོད། བྱ་འགུལ་འདིའི་ནང་གི་རྒྱལ་ཁབ་གཙོ་བོ་༡༠༠་ཙམ་གྱི་རྒྱལ་ཁབ་ཕྱི་རྒྱལ་ཁབ་༢༠་ནས་ཌིས་ཌིར་ཐོག་ལས་ཡོད་ གྲོས་འཆར་བཀོད་པའི་མ་ལག་གི་ཐབས་ལམ་ལ་ངོ་མ་ཚོའི་མཐའ་འཁོར་གྱི་གནད་སྡུད་ལྔའི་ནང་དུ་མཚམས་ཡོད། F1 macro-averaged score of Naive Bayes classifier outperformed all other classifiers for development and test data.', 'jv': 'Perintah iki-Perintah sing ngerasakno sistem awak dhéwé ngewehku tanggal Sistem Panjenengan Dijamahan sing berarti (NTI 2020). Multiple Ana tanggal apat, durung menyang dipunanggap kanggo nambah nambarang dhéwé lan nganggo dolanan sing wis ambalo kanggo nambah-nambarang suwitan. Daftar nang nggawe iki bakal mruput ning tahun kotak saben mruput kanggo saben ning puluh sing utawa Yupun Bapak lan dumadhi sak Jabun Yukono nggawe sistem sing dipun ngomong sampeyan 5 sampeyan panjenengan kelas liyane: kompletement F1 macro-Averaged'}
{'en': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'ar': 'نظرة عامة على المهمة المشتركة WANLP 2021 حول السخرية واكتشاف المشاعر باللغة العربية', 'pt': 'Visão geral da tarefa compartilhada WANLP 2021 sobre detecção de sarcasmo e sentimento em árabe', 'es': 'Descripción general de la tarea compartida de WANLP 2021 sobre detección de sarcasmo y sentimiento en árabe', 'fr': 'Aperçu de la tâche partagée WANLP 2021 sur la détection du sarcasme et des sentiments en arabe', 'ja': 'アラビア語での皮肉と感情検出に関するWANLP 2021共有タスクの概要', 'zh': 'WANLP 2021阿拉伯语刺刺情检概述', 'hi': 'अरबी में व्यंग्य और भावना का पता लगाने पर WANLP 2021 साझा कार्य का अवलोकन', 'ru': 'Обзор совместной задачи WANLP 2021 по выявлению сарказма и сентиментов на арабском языке', 'ga': 'Forbhreathnú ar Thasc Comhroinnte WANLP 2021 ar Shearbhas agus Brath Meon in Araibis', 'ka': 'WANLP 2021 წლის საზოგადომი დავალების დანახვა საპკასმის და სენტიმენტის განახვაზე', 'hu': 'A WANNP 2021 megosztott feladatának áttekintése arab nyelven a szarkazmus és az érzékelés felismerésével kapcsolatban', 'el': 'Επισκόπηση της κοινής εργασίας για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά', 'it': 'Panoramica del compito condiviso WANNP 2021 sulla rilevazione del sarcasmo e dei sentimenti in arabo', 'kk': 'WANLP 2021 жылы Саркассм және Sentiment тапсырмасын араб тілінде ортақ тапсырманың қарау', 'lt': '2021 m. WANLP bendros užduoties dėl sarkazmo ir jautrumo nustatymo arabų kalba apžvalga', 'mk': 'Преглед на заедничката задача на WANLP 2021 за сарказам и детективирање на чувствата на арапски', 'ms': 'Paparan ringkasan Tugas Berkongsi WANLP 2021 mengenai Sarkasm dan Pengesanan dalam bahasa Arab', 'ml': 'സര്\u200dക്കാസം, സെന്റിമെന്റ് ഡിറ്റീഷന്\u200d അറബിയില്\u200d വ്യാന്\u200dഎല്\u200dപി 2021 പങ്കെടുത്ത പണിയുടെ നിരീക്ഷിക്കുക', 'mt': 'Ħarsa ġenerali lejn il-WANLP 2021 Kompitu Konġunt dwar is-Sarkazmu u d-Detezzjoni tas-Sentimenti fl-Għarab', 'mn': 'WANLP 2021 оны Sarcasm болон Sentiment Detection нь Араб хэлний хуваалтын ажил', 'no': 'Oversyning av WANLP 2021 delt oppgåve ved oppdaging av sarkasm og sentiment på arabisk', 'sr': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'pl': 'Przegląd wspólnego zadania WALLP 2021 dotyczącego sarkazmu i wykrywania sentymentów w języku arabskim', 'ro': 'Prezentare generală a sarcinii partajate WANNP 2021 privind detectarea sarcasmului și sentimentelor în limba arabă', 'ta': 'சார்காஸ்ம் மற்றும் சென்டிமென்ட் கண்டுபிடிப்பு அரபி மொழியில் WANLP 2021 பகிர்ந்த பணி', 'sv': 'Översikt över WANNP 2021 delad uppgift om sarkasm och känslodetektering på arabiska', 'si': 'WANLP 2021 සර්කාස්ම් සහ සන්ටායිමන් හොයාගන්න අරාබික් වල සමාගත වැඩක් ගැන බලන්න', 'so': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection Arabic', 'ur': 'WANLP 2021 کے بارے میں سارکاسم اور سنٹیمنٹ آزمائش کے بارے میں مشترک ٹاکس کی اوورویز', 'vi': 'Xem rộng của WANDL 2021 đã chia sẻ nhiệm vụ trinh sát Sarcasm và tình cảm bằng tiếng Ả Rập', 'uz': 'Name', 'nl': 'Overzicht van de WALLP 2021 Gedeelde Task over sarcasme en sentimentdetectie in het Arabisch', 'da': 'Oversigt over WANNP 2021 delt opgave om sarkasme og følelsesdetektion på arabisk', 'bg': 'Общ преглед на споделената задача за откриване на сарказъм и чувства на арабски език', 'hr': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'de': 'Überblick über die gemeinsame Aufgabe WALLP 2021 zu Sarkasmus und Sentiment Detection auf Arabisch', 'id': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'fa': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'ko': 'WANLP 2021 아랍어 풍자 및 정서 감지 공유 작업 개요', 'sw': 'Tazama la WANLP 2021 lilishiriki kazi ya Sarcasm na Kutambua Wakati kwa Kiarabu', 'tr': 'WANLP 2021-nji ýyldaky Sarkasm we Sentiýat Aňlama Görnöşi Arabça', 'sq': 'Shfaqja e përgjithshme e detyrës së përbashkët WANLP 2021 mbi sarkazmin dhe zbulimin e ndjenjave në arabisht', 'af': 'Oorsig van die WANLP 2021 Gedeelde Opdrag op Sarcasm en Sentiment Opdekking in Arabiese', 'am': 'የWANLP 2021 የተሰራጨው ስራ በSarcasm እና Sentiment Detection በዐረብኛ', 'az': 'WANLP 2021 Sarkasm və Sentiment Detection barəsindəki paylaşılmış Görüş', 'hy': '2021 թվականին ընդհանուր պատկերացումը Սարկազմի և զգացմունքների հայտնաբերման մասին արաբերենով', 'bs': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic', 'bn': 'সার্কাস্ম এবং সেন্টাইমেন্ট ডিটেক্টরেশনের ওয়ানএলপি ২০২১ সালে শেয়ার করা কাজের ওপর দেখা যাচ্ছে', 'cs': 'Přehled společného úkolu WALLP 2021 o sarkasmu a detekci citů v arabštině', 'et': 'Ülevaade WARLP 2021 ühisest ülesandest sarkasmi ja tunnete tuvastamise kohta araabia keeles', 'ca': 'Vista general de la tasca compartida WANLP 2021 sobre el sarcasme i la detecció del sentiment en àrab', 'fi': 'Yleiskatsaus WANLP 2021 Shared Task on Sarkasm ja Sentiment Detection arabiaksi', 'jv': 'Tarjamahan ng WANLP 2020 1 Sampeyan task nang Sarkasm lan Sentiment detection in arab', 'sk': 'Pregled skupne naloge WALLP 2021 o sarkazmu in zaznavanju čustev v arabščini', 'ha': 'Suritory of the WANLP 2021 Shared Tasks on Sarcasm and SeTiment Division Arabic', 'he': 'תצוגה כללית של משימה משותפת WANLP 2021 על סרקזם וגילוי רגשות בערבית', 'bo': 'Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic'}
{'en': 'This paper provides an overview of the WANLP 2021 shared task on sarcasm and sentiment detection in Arabic. The shared task has two subtasks : sarcasm detection (subtask 1) and sentiment analysis (subtask 2). This shared task aims to promote and bring attention to Arabic sarcasm detection, which is crucial to improve the performance in other tasks such as sentiment analysis. The dataset used in this shared task, namely ArSarcasm-v2, consists of 15,548 tweets labelled for sarcasm, sentiment and dialect. We received 27 and 22 submissions for subtasks 1 and 2 respectively. Most of the approaches relied on using and fine-tuning pre-trained language models such as AraBERT and MARBERT. The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748 F1-PN respectively.', 'pt': 'Este artigo fornece uma visão geral da tarefa compartilhada WANLP 2021 sobre detecção de sarcasmo e sentimento em árabe. A tarefa compartilhada tem duas subtarefas: detecção de sarcasmo (subtarefa 1) e análise de sentimento (subtarefa 2). Esta tarefa compartilhada visa promover e chamar a atenção para a detecção de sarcasmo árabe, que é crucial para melhorar o desempenho em outras tarefas, como análise de sentimentos. O conjunto de dados usado nesta tarefa compartilhada, ArSarcasm-v2, consiste em 15.548 tweets rotulados para sarcasmo, sentimento e dialeto. Recebemos 27 e 22 submissões para as subtarefas 1 e 2, respectivamente. A maioria das abordagens baseou-se no uso e no ajuste fino de modelos de linguagem pré-treinados, como AraBERT e MARBERT. Os principais resultados alcançados para as tarefas de detecção de sarcasmo e análise de sentimento foram 0,6225 F1-score e 0,748 F1-PN, respectivamente.', 'ar': 'تقدم هذه الورقة لمحة عامة عن مهمة WANLP 2021 المشتركة حول السخرية واكتشاف المشاعر باللغة العربية. تتضمن المهمة المشتركة مهمتين فرعيتين: اكتشاف السخرية (المهمة الفرعية 1) وتحليل المشاعر (المهمة الفرعية 2). تهدف هذه المهمة المشتركة إلى تعزيز ولفت الانتباه إلى اكتشاف السخرية العربية ، وهو أمر بالغ الأهمية لتحسين الأداء في مهام أخرى مثل تحليل المشاعر. تتكون مجموعة البيانات المستخدمة في هذه المهمة المشتركة ، وهي ArSarcasm-v2 ، من 15،548 تغريدة معنونة بالسخرية والمشاعر واللهجة. تلقينا 27 و 22 طلبًا للمهمتين الفرعيتين 1 و 2 على التوالي. اعتمدت معظم الأساليب على استخدام نماذج اللغة المدربة مسبقًا مثل AraBERT و MARBERT وضبطها. كانت أعلى النتائج المحققة لمهمتي الكشف عن السخرية وتحليل المشاعر 0.6225 درجة F1 و 0.748 F1-PN على التوالي.', 'fr': "Cet article donne un aperçu de la tâche partagée WANLP 2021 sur la détection du sarcasme et des sentiments en arabe. La tâche partagée comporte deux sous-tâches\xa0: la détection des sarcasmes (sous-tâche 1) et l'analyse des sentiments (sous-tâche 2). Cette tâche partagée vise à promouvoir et à attirer l'attention sur la détection du sarcasme arabe, qui est cruciale pour améliorer les performances dans d'autres tâches telles que l'analyse des sentiments. L'ensemble de données utilisé dans cette tâche partagée, à savoir ARSARCASM-v2, comprend 15 548 tweets étiquetés pour le sarcasme, le sentiment et le dialecte. Nous avons reçu 27 et 22 soumissions pour les sous-tâches 1 et 2 respectivement. La plupart des approches reposaient sur l'utilisation et la mise au point de modèles linguistiques préformés tels que AraBert et MARBERT. Les meilleurs résultats obtenus pour les tâches de détection du sarcasme et d'analyse des sentiments étaient respectivement de 0,6225 F1-score et 0,748 F1-PN.", 'es': 'Este documento proporciona una descripción general de la tarea compartida de WANLP 2021 sobre detección de sarcasmo y sentimientos en árabe. La tarea compartida tiene dos subtareas: detección de sarcasmo (subtarea 1) y análisis de sentimientos (subtarea 2). Esta tarea compartida tiene como objetivo promover y llamar la atención sobre la detección del sarcasmo árabe, que es crucial para mejorar el desempeño en otras tareas como el análisis de sentimientos. El conjunto de datos utilizado en esta tarea compartida, ArSarcasm-v2, consta de 15,548 tuits etiquetados como sarcasmo, sentimiento y dialecto. Recibimos 27 y 22 envíos para las subtareas 1 y 2 respectivamente. La mayoría de los enfoques se basaron en el uso y el ajuste de modelos lingüísticos previamente entrenados, como ARaBert y MARBERT. Los mejores resultados obtenidos para las tareas de detección de sarcasmo y análisis de sentimientos fueron 0.6225 F1 score y 0.748 F1-PN respectivamente.', 'zh': '本文概述WANLP 2021阿拉伯语刺与情检同。 共享二子:刺检(子 1)情析(子 2)。 此同职指阿拉伯语刺检之关,此所以重他务(情析)性至重也。 凡此数集(即 ArSarcasm-v2)包 15,548 条为刺情方言之推文。 各得 27 22 1 与 2 交。 大抵法赖于用微预训之语,如AraBERT与MARBERT。 刺情析务得分分为0.6225 F10.748 F1-PN。', 'ru': 'В этом документе представлен обзор совместной задачи WANLP 2021 по обнаружению сарказма и чувств на арабском языке. Общая задача имеет две подзадачи: обнаружение сарказма (подзадача 1) и анализ настроений (подзадача 2). Эта совместная задача направлена на поощрение и привлечение внимания к обнаружению арабского сарказма, что имеет решающее значение для повышения эффективности выполнения других задач, таких как анализ настроений. Набор данных, используемый в этой общей задаче, а именно ArSarcasm-v2, состоит из 15 548 твитов, обозначенных как сарказм, настроения и диалект. Мы получили 27 и 22 представления по подзадачам 1 и 2 соответственно. Большинство подходов основывались на использовании и доработке предварительно подготовленных языковых моделей, таких как AraBERT и MARBERT. Самые высокие результаты, достигнутые для задач обнаружения сарказма и анализа настроений, составили 0,6225 балла по шкале F1 и 0,748 балла по шкале F1-PN соответственно.', 'ja': '本稿では、アラビア語による皮肉と感情の検出に関するWANLP 2021共有タスクの概要を提供する。共有タスクには、皮肉検出（サブタスク1 ）と感情分析（サブタスク2 ）の2つのサブタスクがあります。この共有タスクは、感情分析などの他のタスクのパフォーマンスを向上させるために重要なアラビア語の皮肉検出を促進し、注意を喚起することを目的としています。この共有タスクで使用されるデータセット、すなわちArSarcasm - v 2は、皮肉、感情、方言のラベルが付けられた15,548のツイートで構成されています。サブタスク1とサブタスク2については、それぞれ27件と22件の提出を受けました。ほとんどのアプローチは、AraBERTやMARBERTなどの事前にトレーニングされた言語モデルを使用して微調整することに依存していた。皮肉検出及び感情分析タスクで達成された上位の結果は、それぞれ０ ． ６ ２ ２ ５ Ｆ １スコア及び０ ． ７ ４ ８ Ｆ １ － ＰＮであった。', 'hi': 'यह पेपर अरबी में व्यंग्य और भावना का पता लगाने पर WANLP 2021 साझा कार्य का अवलोकन प्रदान करता है। साझा कार्य में दो उप-कार्य हैं: व्यंग्य का पता लगाना (सबटास्क 1) और भावना विश्लेषण (सबटास्क 2)। इस साझा कार्य का उद्देश्य अरबी व्यंग्य का पता लगाने को बढ़ावा देना और ध्यान देना है, जो भावना विश्लेषण जैसे अन्य कार्यों में प्रदर्शन में सुधार करने के लिए महत्वपूर्ण है। इस साझा कार्य में उपयोग किए जाने वाले डेटासेट, अर्थात् ArSarcasm-v2, में व्यंग्य, भावना और बोली के लिए लेबल किए गए 15,548 ट्वीट शामिल हैं। हमें उप-कार्यों 1 और 2 के लिए क्रमशः 27 और 22 प्रस्तुतियां प्राप्त हुईं। अधिकांश दृष्टिकोणों ने अराबर्ट और मार्बर्ट जैसे पूर्व-प्रशिक्षित भाषा मॉडल का उपयोग करने और ठीक-ट्यूनिंग करने पर भरोसा किया। व्यंग्य का पता लगाने और भावना विश्लेषण कार्यों के लिए शीर्ष प्राप्त परिणाम क्रमशः 0.6225 F1-स्कोर और 0.748 F1-PN थे।', 'ga': 'Tugann an páipéar seo forbhreathnú ar thasc roinnte WANLP 2021 maidir le searbhas agus braite meon in Araibis. Tá dhá fhothasc ag an tasc comhroinnte: braite searbhas (fothasc 1) agus anailís meon (fothasc 2). Tá sé mar aidhm ag an tasc comhroinnte seo braite searbhas na hAraibe a chur chun cinn agus aird a thabhairt air, rud atá ríthábhachtach chun feabhas a chur ar fheidhmíocht i dtascanna eile cosúil le hanailís sentiment. Is éard atá sa tacar sonraí a úsáidtear sa tasc comhroinnte seo, eadhon ArSarcasm-v2, ná 15,548 tvuít atá lipéadaithe le haghaidh searbhas, meon agus canúint. Fuaireamar 27 agus 22 aighneacht le haghaidh fhothasc 1 agus 2 faoi seach. Bhí formhór na gcur chuige ag brath ar mhúnlaí teanga réamhoilte mar AraBERT agus MARBERT a úsáid agus a mhionchoigeartú. Ba iad na torthaí ba mhó a baineadh amach do thascanna braite searbhas agus anailís meoin ná 0.6225-scór F1 agus 0.748 F1-PN faoi seach.', 'lt': 'Šiame dokumente apžvelgiama bendra WANLP 2021 užduotis sarkazmo ir jautrumo nustatymo arabų kalba. Bendra užduotis apima du paklausimus: sarkazmo nustatymą (1 paklausimą) ir jautrumo analizę (2 paklausimą). Šios bendros užduoties tikslas – skatinti ir atkreipti dėmesį į arabų sarkazmo aptikimą, kuris yra labai svarbus siekiant pagerinti kitų užduočių, pavyzdžiui, jautrumo analizės, rezultatus. Šiame bendrame uždavinyje naudojamų duomenų rinkinyje, t. y. ArSarcasm-v2, yra 15 548 tweetai, paženklinti sarkazmu, jausmu ir dialektu. Gavome atitinkamai 27 ir 22 prašymus dėl 1 ir 2 paklausymų. Dauguma metodų buvo grindžiami iš anksto parengtų kalbų modelių, pavyzdžiui, AraBERT ir MARBERT, naudojimu ir tobulinimu. Geriausi sarkazmo nustatymo ir jautrumo analizės rezultatai buvo atitinkamai 0,6225 F1 ir 0,748 F1-PN.', 'si': 'මේ පැත්තේ WANLP 2021 වල සාර්කාස්ම් වලින් සංවේදනාවක් හා අරාබික වලින් හොයාගන්න වැඩසටහන් ගැන ප්\u200dරකාශයක භාවිත වැඩේ විශේෂ දෙකක් තියෙනවා: sarcasm හොයාගන්න (subtask 1) සහ හැතිවිශේෂ විශේෂ (subtask 2). මේ සම්බන්ධ වැඩක් අදහස් කරනවා අරාබි සර්කාස්ම් පරීක්ෂණයට අවධානය කරන්න, ඒක අනිත් විශේෂණ විශ්ලේෂණය වගේ වැඩක්  මේ වැදගත් වැඩේ භාවිත කරපු දත්ත සෙට්, අර්සර්කාස්ම්-v2, සාර්කාස්ම්, සංවේදනය සහ ඩායාලක්ට් වලට ලේබල් කරපු 15,548 ටු අපිට ප්\u200dරතිචාරයක් 27 සහ 22 දෙයක් ලැබුණා, 1 සහ 2 දෙයක් ප්\u200dරතිචාරයක් ලැබුණා. ගොඩක් අවස්ථාවන් විශ්වාස කරනවා ඇරාබෙර්ට් සහ MARBERT වගේ භාෂාව පාවිච්චි කරන්න සහ ප්\u200dරශ්ණිත භාෂාව ප්\u200d සාර්කාස්ම් පරීක්ෂණය සහ හැඟීම් විශේෂණය විස්තර කරන්නේ උපරිම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප', 'hu': 'Ez a tanulmány áttekintést nyújt a WANNP 2021 közös feladatáról arab nyelven a szarkazmus és érzelmek felismerésével kapcsolatban. A megosztott feladatnak két alcsoportja van: a szarkazmus felismerése (1. alcsoport) és az érzelmek elemzése (2. alcsoport). Ez a közös feladat célja, hogy elősegítse és felhívja a figyelmet az arab szarkazmus felismerésére, ami kulcsfontosságú más feladatok teljesítményének javításához, mint például az érzelmek elemzése. Ebben a megosztott feladatban használt adatkészlet, nevezetesen az ArSarcasm-v2, 15 548 tweetből áll, amelyeket szarkazmusra, érzelemre és dialektusra jelöltek. 27, illetve 22 beadványt kaptunk az 1. és 2. alcsoporthoz. A legtöbb megközelítés olyan előre képzett nyelvi modellek használatára és finomhangolására épült, mint az AraBERT és a MARBERT. A szarkazmus detektálási és érzelmi elemzési feladatok legmagasabb eredményei 0,6225 F1 pontszám, illetve 0,748 F1-PN voltak.', 'it': "Questo articolo fornisce una panoramica del compito condiviso WANNP 2021 sul sarcasmo e la rilevazione dei sentimenti in arabo. L'attività condivisa ha due sottoattività: rilevamento del sarcasmo (sottoattività 1) e analisi del sentiment (sottoattività 2). Questo compito condiviso mira a promuovere e portare l'attenzione alla rilevazione del sarcasmo arabo, che è fondamentale per migliorare le prestazioni in altri compiti come l'analisi del sentiment. Il dataset utilizzato in questo compito condiviso, vale a dire ArSarcasm-v2, consiste di 15.548 tweet etichettati per sarcasmo, sentimento e dialetto. Abbiamo ricevuto 27 e 22 contributi per le sottoattività 1 e 2 rispettivamente. La maggior parte degli approcci si basava sull'utilizzo e sulla messa a punto di modelli linguistici pre-formati come AraBERT e MARBERT. I risultati migliori ottenuti per il rilevamento del sarcasmo e l'analisi del sentiment sono stati rispettivamente 0,6225 F1-score e 0,748 F1-PN.", 'kk': 'Бұл қағаз 2021 жылы WANLP сарказм мен сезімдерді араб тілінде ортақ тапсырманы көрсетеді. Ортақ тапсырманың екі ішкі сұрақтары бар: саркассм анықтау (1- сурет) және сезімдік анализ (2- сурет). Бұл ортақ тапсырманың мақсаты араб сарказмды анықтау үшін жұмыс істеу және назарды түсіндіру үшін. Бұл басқа тапсырмаларды, мысалы, сезімдік анализ секілді, жұмыс і Бұл ортақтастырылған тапсырмада қолданылатын деректер жинағы: ArSarcasm-v2, саркассм, сезім және диалект үшін белгіленген 15 548 tweets болады. Біз 27 және 22 суреттерді 1 және 2 суреттерді алдық. АраBERT және MARBERT секілді тіл үлгілерін қолдану және өзгерту үлгілерінің көпшілігі өзгертілген. Сарказмды анықтау және сезімді анализ тапсырмаларының жоғары нәтижесі 0,6225 F1- нәтижесі және 0,748 F1- PN.', 'ml': 'ഈ പത്രത്തില്\u200d വാന്\u200dഎല്\u200dപി 2021 പങ്കെടുത്ത ജോലിയെക്കുറിച്ചൊരു മുഴുകാണിക്കുന്നു. അറബിഭാഷയിലെ സർക്കാസം, വി പങ്കാളിയുള്ള ജോലിയില്\u200d രണ്ടു സബ്ജോട്ടുകളുണ്ട്: സര്\u200dക്കാസം തിരിച്ചറിയുന്നത് (സബ്ബട്ട് 1) ശ്രദ്ധിക്കുന ഈ പങ്കെടുത്ത ജോലിയുടെ ലക്ഷ്യത്തില്\u200d അറബിയിലെ സർക്കാസം കണ്ടുപിടിക്കാനും ശ്രദ്ധിക്കാനും ആഗ്രഹിക്കുന്നു. മറ്റു ജോലികളിലെ  ഈ പങ്കെടുത്ത ജോലിയില്\u200d ഉപയോഗിക്കുന്ന ഡാറ്റാസെറ്റ് ആര്\u200dസര്\u200dക്കാസം- v2 എന്ന പേരില്\u200d ഉള്\u200dപെട്ടിരിക്കുന്നു. സർക്കാസം, തീരുമാ ഞങ്ങള്\u200dക്ക് 27, 22 സബ്ജിറ്റുകള്\u200d കിട്ടി. അറബെര്\u200dട്ടിയെയും മാര്\u200dബെര്\u200dട്ടിയെയും പോലെയുള്ള മോഡലുകളെയും ഉപയോഗിക്കുകയും ചെയ്യുന്നതില്\u200d മിക്കവാറും ആശ്രയിച്ച സര്\u200dക്കാസം കണ്ടുപിടിക്കുന്നതിനുള്ള മുകളില്\u200d സമ്പാദിച്ച ഫലങ്ങള്\u200d', 'el': 'Η παρούσα εργασία παρέχει μια επισκόπηση της κοινής εργασίας για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά. Η κοινή εργασία έχει δύο δευτερεύουσες εργασίες: ανίχνευση σαρκασμού (δευτερεύουσα εργασία 1) και ανάλυση συναισθημάτων (δευτερεύουσα εργασία 2). Αυτό το κοινό έργο έχει ως στόχο να προωθήσει και να φέρει την προσοχή στην ανίχνευση αραβικού σαρκασμού, η οποία είναι ζωτικής σημασίας για τη βελτίωση της απόδοσης σε άλλα καθήκοντα, όπως η ανάλυση συναισθημάτων. Το σύνολο δεδομένων που χρησιμοποιείται σε αυτή την κοινή εργασία, δηλαδή το ArSarcasm-v2, αποτελείται από 15,548 tweets με ετικέτα σαρκασμού, συναισθημάτων και διαλέκτου. Λάβαμε 27 και 22 αιτήσεις για τις δευτερεύουσες εργασίες 1 και 2 αντίστοιχα. Οι περισσότερες από τις προσεγγίσεις βασίστηκαν στη χρήση και τον συντονισμό προ-εκπαιδευμένων γλωσσικών μοντέλων όπως AraBERT και MARBERT. Τα κορυφαία αποτελέσματα που επιτεύχθηκαν για την ανίχνευση σαρκασμού και την ανάλυση συναισθημάτων ήταν το 0.6225 και το 0.748 F1-PN αντίστοιχα.', 'ka': 'ეს დოკუმენტი განახლება WANLP 2021 წლის გაყოფილი საქაპკასმის და სენტიმენტის განახლების შესახებ. საზოგადოებული დავალება აქვს ორი საზოგადოება: საპკასმის განახლება (საზოგადოება 1) და სენტიმენტის ანალიზი (საზოგადოება 2). ეს საზოგადო დავალების მიზეზია, რომ აპაბიური საპკასმის განახლებისთვის აღმოქმედება და აღმოქმედება, რომელიც უფრო მნიშვნელოვანია სხვა დავალებში, როგორც სენტიმენტი მონაცემების კონფიგურაცია, რომელიც ArSarcasm-v2-ში გამოყენებულია, არის 15 548 tweets, რომელიც საპკასმის, sentiment და ეთალექტისთვის ნიშნავს. ჩვენ მივიღეთ 27 და 22 წინაწერები, როგორც 1 და 2 წინაწერებისთვის. უფრო მეტი წარმოდგენები იყენებულია, როგორც აპაბერტი და MARBERT. სამუშაო შესაძლებელი შედეგები საპკასმის განვიცნობის და სენტიმენტის ანალიზიციის მოქმედებისთვის იყო 0,6225 F1-score და 0,748 F1-PN.', 'mk': 'Овој весник обезбедува преглед на заедничката задача на WANLP 2021 за детекција на сарказам и чувства на арапски јазик. Соделената задача има две потпрашања: детекција на сарказам (подпрашање 1) и анализа на чувствата (подпрашање 2). Оваа заедничка задача има за цел промовирање и привлекување внимание на откривањето на арапскиот сарказам, што е клучно за подобрување на резултатите во другите задачи како што е анализата на чувствата. Податоците кои се користат во оваа заедничка задача, имено ArSarcasm-v2, се состојат од 15.548 твитови означени за сарказам, чувство и дијалект. Примивме 27 и 22 поднесувања за потпрашања 1 и 2. Повеќето од пристапите се потпираа на користење и финетизирање на предобучени јазички модели како што се АраБЕРТ и МаРБЕРТ. Највисоките постигнати резултати за задачите за детекција на сарказмот и анализа на чувствата беа 0,6225 Ф1-оценка, односно 0,748 Ф1-ПН.', 'ms': 'Kertas ini menyediakan paparan ringkasan tugas kongsi WANLP 2021 mengenai sarkasm dan pengesan perasaan dalam bahasa Arab. Tugas berkongsi mempunyai dua subtanya: pengesan sarkasma (subtanya 1) dan analisis sentimen (subtanya 2). Tugas berkongsi ini bertujuan untuk mempromosikan dan menarik perhatian kepada pengesan sarkasma Arab, yang penting untuk meningkatkan prestasi dalam tugas lain seperti analisis perasaan. Set data yang digunakan dalam tugas berkongsi ini, iaitu ArSarcasm-v2, terdiri dari 15,548 tweet yang ditabel untuk sarkasm, perasaan dan dialekt. Kami menerima 27 dan 22 tunjukan untuk subtasks 1 dan 2 respectively. Kebanyakan pendekatan bergantung pada penggunaan dan penyesuaian model bahasa terlatih sebelum seperti AraBERT dan MARBERT. Keputusan tertinggi yang dicapai untuk tugas pengesan sarkasma dan analisis perasaan adalah 0.6225 F1-skor dan 0.748 F1-PN berdasarkan itu.', 'sr': 'Ovaj papir predstavlja pregled delnog zadatka WANLP 2021. na arapskom jeziku o sarkazmu i detekciji sentimenta. Podijeljeni zadatak ima dva podataka: otkrivanje sarkazma (podpitanje 1) i analiza sentimenta (podpitanje 2). Ovaj zajednički zadatak je cilj promovisati i privesti pažnju na otkrivanje arapskog sarkazma, što je ključno za poboljšanje izvođenja drugih zadataka poput analize sentimenta. Zeta podataka koja se koristi u ovom zajedničkom zadatku, a to je ArSarcasm-v2, sastoji se od 15.548 tweeta označene za sarkazam, sentiment i dijalekt. Dobili smo 27 i 22 podatke za podatke 1 i 2. Većina pristupa se oslanja na korištenje i ispravljanje predobučenih jezičkih modela kao što su AraBERT i MARBERT. Najveći postignuti rezultati za otkrivanje sarkazma i analizu sentimenta bili su 0,6225 F1 rezultata i 0,748 F1-PN.', 'ro': 'Această lucrare oferă o imagine de ansamblu a sarcinii comune WANNP 2021 privind detectarea sarcasmului și sentimentelor în limba arabă. Activitatea partajată are două subactivități: detectarea sarcasmului (subactivitatea 1) și analiza sentimentului (subactivitatea 2). Această sarcină comună își propune să promoveze și să atragă atenția asupra detectării sarcasmului arab, care este crucială pentru îmbunătățirea performanței în alte sarcini, cum ar fi analiza sentimentului. Setul de date folosit în această sarcină comună, și anume ArSarcasm-v2, constă din 15.548 tweet-uri etichetate pentru sarcasm, sentiment și dialect. Am primit 27 și 22 de trimiteri pentru subactivitățile 1 și respectiv 2. Majoritatea abordărilor s-au bazat pe utilizarea și reglarea fină a modelelor lingvistice pre-instruite, cum ar fi AraBERT și MARBERT. Cele mai bune rezultate obținute pentru detectarea sarcasmului și analiza sentimentului au fost 0,6225 F1-scor și, respectiv, 0,748 F1-PN.', 'pl': 'Niniejszy artykuł zawiera przegląd wspólnego zadania WALLP 2021 dotyczącego sarkazmu i wykrywania sentymentów w języku arabskim. Wspólne zadanie ma dwa podzadania: wykrywanie sarkazmu (podzadanie 1) i analizę sentymentów (podzadanie 2). To wspólne zadanie ma na celu promowanie i zwrócenie uwagi na wykrywanie sarkazmu arabskiego, co ma kluczowe znaczenie dla poprawy wydajności w innych zadaniach, takich jak analiza sentymentów. Zestaw danych używanych w tym wspólnym zadaniu, mianowicie ArSarcasm-v2, składa się z 15,548 tweetów oznaczonych sarkazmem, sentymentem i dialektem. Otrzymaliśmy 27 i 22 zgłoszenia odpowiednio do podzadań 1 i 2. Większość podejść opierała się na użyciu i dostosowaniu wstępnie przeszkolonych modeli językowych, takich jak AraBERT i MARBERT. Najlepszymi osiągniętymi wynikami wykrywania sarkazmu i analizy sentymentów były odpowiednio 0.6225 F1-score i 0.748 F1-PN.', 'so': 'Warqaddan waxaa ka qoran warqadda WANLP 2021 oo lagu qeybeeyey shaqo ku saabsan baaritaanka sarcasm iyo fikrada afka Carabiga ah. Shaqoda la qaybsado waxaa ku yaala laba shahaado: baaritaanka sarcasm (sub-task 1) iyo baaritaanka maandooriyaha (sub-task 2). Shaqadan la qaybsaday waxaa loogu talagalay in la horumariyo oo la sii jeedo baaritaanka sarkaalka Carabiga, taas oo muhiim ah in la hagaajiyo sameynta shaqaalaha kale, tusaale ahaan baaritaanka fikradda. ArSarcasm-v2 waxaa ka mid ah 15,548 tweeti oo lagu qoray sarkasm, xisaab iyo warqad. We received 27 and 22 submissions for subtasks 1 and 2 respectively.  Dhaqdhaqaaqa badankoodu waxay ku xiran yihiin isticmaalidda iyo modellada afka hore oo la tababaray, sida AraBERT iyo MARBERT. Shaqooyinka sarkaalka iyo baaritaanka kaleemeyska waxaa lagu helay resultooyin u dhexeeya 0.6225 F1 score iyo 0.748 F1-PN.', 'no': 'Denne papiret gjev ei oversikt over delt oppgåva WANLP 2021 om sarkasm og sentimentoppdaging i arabisk. Den delte oppgåva har to underspørsmål: oppdaging av sarkasm (underspørsmål 1) og sentimentanalyse (underspørsmål 2). Denne delte oppgåva måtar å promotera og gjera oppmerksomhet til arabisk sarkasm-oppdaging, som er viktig for å forbedra utviklinga i andre oppgåver som sentimentanalyser. Datasettet som er brukt i denne delte oppgåva, dvs. ArSarcasm-v2, inneheld 15.548 tweeter som er merket for sarkasm, sentiment og dialekt. Vi motteke 27 og 22 tillegg for subtaskar 1 og 2. Dei fleste tilnærmingane vart på å bruka og finne opplærte språkkmodeller som AraBERT og MARBERT. Den øvste oppnådd resultatene for oppgåva for oppdaging av sarkasm og sentimentanalyser var 0,6225 F1-poeng og 0,748 F1-PN respectively.', 'mt': 'Dan id-dokument jipprovdi ħarsa ġenerali lejn il-kompitu kondiviż WANLP 2021 dwar is-sarkazmu u s-sejbien tas-sentimenti fl-Għarab. Il-kompitu kondiviż għandu żewġ sottomistoqsijiet: detezzjoni tas-sarkasmu (sottomistoqsija 1) u analiżi tas-sentimenti (sottomistoqsija 2). Dan il-kompitu kondiviż għandu l-għan li jippromwovi u jġib l-attenzjoni għad-detezzjoni tas-sarkazmu Għarbi, li huwa kruċjali għat-titjib tal-prestazzjoni f’kompiti oħra bħall-analiżi tas-sentimenti. Is-sett tad-dejta użat f’dan il-kompitu kondiviż, jiġifieri ArSarcasm-v2, jikkonsisti minn 15,548 tweet ittikkettati għas-sarkasmu, is-sentiment u d-dijalekt. Irċevejna 27 u 22 sottomissjoni għas-sottomistoqsijiet 1 u 2 rispettivament. Il-biċċa l-kbira tal-approċċi kienu jiddependu fuq l-użu u l-irfinar ta’ mudelli lingwistiċi mħarrġa minn qabel bħal AraBERT u MARBERT. The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748 F1-PN respectively.', 'mn': 'Энэ цаас 2021 оны WANLP-ын саркассм, сэтгэл хөдлөлийн мэдрэмжүүдийг Араб хэлний тухай хуваалцах ажлыг харуулдаг. Хоёр даалгаварын тухай хоёр даалгавар байдаг: саркассмын нээлт (1-даалгавар) болон сэтгэл санааны шинжилгээ (2-даалгавар). Энэ хуваалцан үйл ажиллагаа, мэдрэмжүүдийн шинжилгээ мэт өөр үйл ажиллагаанд ажиллагааг сайжруулах боломжтой болгох, анхаарлыг Араб хэлбэрийн саркассмын шинжилгээнд дэмжих, анхаар Энэ хуваалцагдсан ажил дээр хэрэглэгдсэн өгөгдлийн сангууд: ArSarcasm-v2, 15,548 tweets нь саркассм, мэдрэмж, диалект гэдэг. Бид 27 болон 22 сурагчид 1 болон 2 сурагчид авсан. Ихэнх арга барилга нь Араберт болон МАРБЕРТ зэрэг сургалтын өмнө сургалтын загварыг ашиглаж, сайхан тодорхойлдог хэл загваруудыг ашиглаж байдаг. Саркассмын мэдрэмж, сэтгэл санааны шинжилгээний хамгийн их үр дүн нь 0.6225 F1-той, 0.748 F1-PN байсан юм.', 'sv': 'Denna uppsats ger en översikt över WANNP 2021 delade uppgift om sarkasm och sentimentdetektering på arabiska. Den delade uppgiften har två underuppgifter: sarkasm detektering (subaktivitet 1) och sentimentalanalys (subaktivitet 2). Denna gemensamma uppgift syftar till att främja och uppmärksamma arabisk sarkasm detektering, vilket är avgörande för att förbättra prestationen i andra uppgifter som sentimentalanalys. Datauppsättningen som används i denna gemensamma uppgift, nämligen ArSarcasm-v2, består av 15 548 tweets märkta för sarkasm, sentiment och dialekt. Vi fick 27 och 22 bidrag för delaktiviteter 1 respektive 2. De flesta av tillvägagångssätten baserades på att använda och finjustera färdigutbildade språkmodeller som AraBERT och MARBERT. De högst uppnådda resultaten för sarkasm detektering och sentimentalanalys uppgifter var 0,6225 F1-poäng respektive 0,748 F1-PN.', 'ur': 'This paper provides an overview of the WANLP 2021 shared task on sarcasm and sentiment detection in Arabic. Shared task has two subtasks: sarcasm detection (subtask 1) and sentiment analysis (subtask 2). یہ مشترک کام کا ارادہ ہے کہ عربی سارکاسم کا اظہار کرنا اور اظہار کرنا ہے، جو دوسرے کاموں میں عملہ کو اضافہ کرنے کے لئے ضروری ہے جیسے احساس تحلیل. اس مشترک کام میں استعمال کیا جاتا ہے، یعنی ArSarcasm-v2، 15,548 ٹویٹ میں سے ہے جو سارکاسم, احساسات اور دیالکت کے لئے لکھی جاتی ہیں. ہم نے 27 اور 22 مسلمانوں کو 1 اور 2 مسلمانوں کے لئے حاصل کیا۔ بہت سی تقریبیں آراBERT اور MARBERT کے مطابق استعمال اور نیک تنظیم کی زبان کی مدل پر مستقل ہیں. Sarcasm detection and sentiment analysis tasks for the top achieved results were 0.6225 F1-score and 0.748 F1-PN respectively.', 'ta': 'This paper provides an overview of the WANLP 2021 shared task on sarcasm and sentiment detection in Arabic.  பங்கிடப்பட்ட பணியில் இரண்டு துணை செயல்கள் உள்ளன: சற்று கண்டுபிடிப்பு (துணை செயல் 1) மற்றும் உணர்வு ஆராய்வு (துணை ச இந்த பங்கிடப்பட்ட பணிக்கு ஆராய்ச்சி கண்டுபிடிப்பதற்கு மேம்படுத்தி கவனத்தை எடுத்துக் கொள்வதற்கு, இது உணர்வு ஆராய்ச்சி போன்ற மற் இந்த பகிர்ந்த பணியில் பயன்படுத்தப்பட்ட தகவல் அமைப்பு, ஆர்சார்காஸ்ம்- v2, சரகாசம், உணர்வு மற்றும் விளக்கத்திற்கு குறிப்பிடப்பட்ட 15, 1 மற்றும் 2 துணை பணிகளுக்கு 27 மற்றும் 22 கட்டளைகள் கிடைத்தது. பெரும்பாலான வழிமுறைகள் அராபெர்ட் மற்றும் MARBERT போன்ற மொழி மாதிரிகளை பயன்படுத்தி மற்றும் நன்றாக முன்பயிற்சி முன செயல் கண்டுபிடிப்பு மற்றும் உணர்வு ஆய்வு செயல்களுக்கு மேல் அடைந்த முடிவுகள் 0. 6225 F1- மதிப்பு மற்றும் 0. 748 F1- PN.', 'vi': 'Tờ giấy này cung cấp một hình ảnh tổng quát về công việc chia sẻ WANDL 2021 về mỉa mai và tình cảm bằng tiếng Ả Rập. Nhiệm vụ chia sẻ có hai phần phụ: phát hiện mỉa mai (phụ đề 1) và phân tích cảm xúc (phụ đề 2). Nhiệm vụ chia sẻ này nhằm thúc đẩy và gây chú ý tới việc phát hiện mỉa mai bằng tiếng Ả Rập, một điều rất quan trọng để cải thiện khả năng thực hiện các nhiệm vụ khác như phân tích cảm xúc. Bộ dữ liệu được dùng trong nhiệm vụ chung này, là ArSarcass-v2, gồm các tweet của 15,58 được đánh dấu là mỉa mai, tình cảm và phương ngữ. Chúng tôi nhận được sự giúp đỡ của 27 và 22. Hầu hết các phương pháp dựa vào sử dụng và độ cẩn thận các mô hình ngôn ngữ được đào tạo như AraBERT và MABERT. Kết quả tối đa được đạt đến cho nhiệm vụ thám thính mỉa mai và phân tích cảm xúc là 0.625 F1-điểm và 0.748 F1-PN.', 'uz': "Бу саҳифа араб тилида тақдим қилинган вазифани кўриб чиқиш учун WANLP 2021 таркибида кўринади. Boʻlishilgan vazifaning ikkita sub vazifalar bor: sarkasm aniqlash (sub- vazifa 1) va sentiment analysi (sub- vazifa 2). Bu birlashtirilgan vazifa Arab sarkasmni aniqlashga tayyorlash va taqdim qilishga ega. Bu boshqa vazifalarga o'zgarishni o'zgartirish juda muhim. ArSarcasm-v2 (ArSarcasm-v2) bilan ishlatilgan maʼlumotlar satri sarkasm, hissiyot va dialect uchun yaratilgan 15,548 tweetidan iborat. Biz 1 va 2 vazifalar uchun 27 va 22 submit qabul qildik. Ko'pchilik murakkablarida araBERT va MARBERT kabi o'rganilgan tildan foydalanish va yaxshi o'rganish modellariga ishonadi. The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748 F1-PN respectively.", 'da': 'Denne artikel giver et overblik over WANNP 2021 delte opgave om sarkasme og sentimentdetektion på arabisk. Den delte opgave har to underopgaver: sarkasme detektion (underopgave 1) og sentiment analyse (underopgave 2). Denne fælles opgave har til formål at fremme og gøre opmærksom på arabisk sarkasme detektion, hvilket er afgørende for at forbedre ydeevnen i andre opgaver som følelsesanalyse. Datasættet, der anvendes i denne delte opgave, nemlig ArSarcasm-v2, består af 15.548 tweets mærket for sarkasme, sentiment og dialekt. Vi modtog 27 og 22 indsendelser til henholdsvis underopgaver 1 og 2. De fleste tilgange var baseret på at bruge og finjustere forududdannede sprogmodeller som AraBERT og MARBERT. De bedste resultater for sarkasme detektion og sentiment analyse opgaver var henholdsvis 0,6225 F1-score og 0,748 F1-PN.', 'bg': 'Настоящата статия представя общ преглед на споделената задача за откриване на сарказъм и сентименти на арабски език. Споделената задача има две подзадачи: откриване на сарказъм (подзадача 1) и анализ на чувствата (подзадача 2). Тази споделена задача има за цел да популяризира и насочи вниманието към откриването на арабски сарказъм, което е от решаващо значение за подобряване на изпълнението на други задачи като анализ на сантимента. Наборът от данни, използван в тази споделена задача, а именно се състои от 15 548 туита, обозначени със сарказъм, сантимент и диалект. Получихме съответно 27 и 22 предложения за подзадачи 1 и 2. Повечето от подходите разчитаха на използването и фината настройка на предварително обучени езикови модели като AraBERT и MARBERT. Най-добрите резултати за откриване на сарказъм и анализ на сентимента са съответно 0,6225 и 0,748.', 'de': 'Dieser Beitrag gibt einen Überblick über die gemeinsame Aufgabe WALLP 2021 zum Thema Sarkasmus und Sentiment Detection in Arabisch. Die geteilte Aufgabe hat zwei Teilaufgaben: Sarkasmus-Erkennung (Teilaufgabe 1) und Sentiment-Analyse (Teilaufgabe 2). Diese gemeinsame Aufgabe zielt darauf ab, die Erkennung von arabischem Sarkasmus zu fördern und darauf aufmerksam zu machen, was entscheidend ist, um die Leistung in anderen Aufgaben wie der Sentimentanalyse zu verbessern. Der Datensatz, der in dieser gemeinsamen Aufgabe verwendet wird, nämlich ArSarcasm-v2, besteht aus 15,548 Tweets, die für Sarkasmus, Sentiment und Dialekt gekennzeichnet sind. Wir erhielten 27 und 22 Einreichungen für Teilaufgaben 1 bzw. 2. Die meisten Ansätze beruhten auf der Verwendung und Feinabstimmung vortrainierter Sprachmodelle wie AraBERT und MARBERT. Die besten Ergebnisse für die Sarkasmus-Erkennung und Sentiment-Analyse waren 0.6225 F1-Score bzw. 0.748 F1-PN.', 'hr': 'Ovaj papir predstavlja pregled delnog zadatka WANLP 2021. na arapskom jeziku o sarkazmu i otkrivanju osjećaja. Podijeljeni zadatak ima dva podataka: otkrivanje sarkazma (podpitanje 1) i analiza osjećaja (podpitanje 2). Ovaj zajednički zadatak je cilj promovirati i privesti pažnju na otkrivanje arapskog sarkazma, što je ključno za poboljšanje učinka u drugim zadatacima poput analize osjećaja. Zeta podataka koja se koristi u ovom zajedničkom zadatku, a to je ArSarcasm-v2, sastoji se od 15.548 tweets označenih za sarkazam, osjećaj i dijalekt. Dobili smo 27 i 22 podatke za podatke 1 i 2. Većina pristupa se oslanjala na korištenje i ispravljanje predobučenih jezičkih modela poput AraBERT i MARBERT. Najviši postignuti rezultati za otkrivanje sarkazma i analiziranje osjećaja bili su 0,6225 F1 rezultata i 0,748 F1-PN.', 'ko': '본고는 WANLP 2021의 아랍어 풍자와 정서 검측에 대한 공유 임무를 개괄적으로 기술한다.공유 임무에는 두 개의 하위 임무가 있는데 그것이 바로 풍자 검측(하위 임무1)과 정서 분석(하위 임무2)이다.이 공유 임무는 아랍어 풍자 검측에 대한 관심을 촉진하고 불러일으키기 위한 것으로 정서 분석 등 다른 임무의 성능을 향상시키는 데 매우 중요하다.이 공유 임무에 사용된 데이터 세트, 즉 ArSarcasm-v2는 풍자, 정서, 사투리로 표시된 15548개의 트윗으로 구성됐다.우리는 각각 27부와 22부의 하위 임무 1과 2에 관한 제출을 받았다.대부분의 방법은 아라비트와 MARBERT 같은 미리 훈련된 언어 모델을 사용하고 미세하게 조정하는 데 의존한다.풍자 감지와 정서 분석 임무 중 F1이 0.6225, F1-PN이 0.748로 가장 높은 점수를 받았다.', 'sw': 'Gazeti hili linatoa mtazamo wa jumbe la WANLP 2021 lililoshirikiana na vitendo vya kejeli na kutambua hisia kwa lugha ya Kiarabu. Kazi hiyo inayoshirikishwa ina kazi mbili: Ugunduzi wa kejeli (Ujumbe wa kazi 1) na uchambuzi wa hisia (jukumu la 2). Kazi hii ilishirikiana na lengo la kukuza na kusikiliza utambuzi wa kejeli wa Kiarabu, ambalo ni muhimu kuboresha utendaji katika kazi nyingine kama vile uchambuzi wa hisia. Taarifa hizi zinazotumiwa katika kazi hii inayoshirikishwa, ni ArSarcasm-v2, ina twiti 15,548 zilizowekwa kwa kejeli, hisia na kuonyesha. Tulipokea ujumbe wa jumbe 27 na 22 kwa ajili ya mipango ya 1 na 2. Matokeo mengi yalitegemea kutumia mifano ya lugha zilizofunzwa vizuri kama vile AraBERT na MARBERT. Matokeo ya juu yaliyopata kwa ajili ya kutambua kemikali na uchambuzi wa hisia zilikuwa ni vipindi 0.6225 F1 na 0.748 F1-PN.', 'fa': 'این کاغذ یک نگاهی از کار مشترک WANLP 2021 در مورد شناسایی سارکاسم و احساسات در عربی پیشنهاد می\u200cکند. وظیفه مشترک دو پاسخ دارد: شناسایی سارکاسم (پاسپرس ۱) و تحلیل احساسات (پاسپرس ۲). این وظیفه مشترک را هدف می\u200cدهد که توجه به کشف سارکاسم عربی را توسعه دهد، که برای تحصیل عملکرد در کارهای دیگر مثل تحلیل احساسات مهم است. مجموعه داده\u200cها در این کار مشترک استفاده می\u200cشود، به عنوان ArSarcasm-v2، از ۱۵.۵۴۸ تویت\u200cهایی است که برای سارکاسم، احساسات و دیالکت نشان داده می\u200cشود. ما ۲۷ و ۲۲ تسلیم را دریافت کردیم. بیشترین دسترسی بر استفاده از مدل های پیش آموزش زبانی\u200cهای آراBERT و MARBERT بستگی دارند. نتیجه\u200cهای بالا برای شناسایی و تحلیل احساسات سارکاسم موفق شدند، مقدار 0.6225 F1 و 0.748 F1-PN respectively.', 'id': 'Kertas ini menyediakan overview dari tugas WANLP 2021 berbagi tentang sarkasme dan deteksi perasaan dalam bahasa Arab. Tugas berbagi memiliki dua subtasks: deteksi sarkasme (subtask 1) dan analisis sentimen (subtask 2). Tugas bersama ini bertujuan untuk mempromosikan dan menarik perhatian pada deteksi sarkasme Arab, yang penting untuk meningkatkan prestasi dalam tugas lain seperti analisis sentimen. Set data yang digunakan dalam tugas berbagi ini, yaitu ArSarcasm-v2, terdiri dari 15.548 tweet yang ditabel untuk sarkasme, sentimen dan dialeks. We received 27 and 22 submissions for subtasks 1 and 2 respectively.  Kebanyakan pendekatan bergantung pada menggunakan dan memperbaiki model bahasa yang terlatih sebelumnya seperti AraBERT dan MARBERT. Hasil tertinggi yang mencapai untuk deteksi sarkasme dan tugas analisis sentimen adalah 0,6225 F1-skor dan 0,748 F1-PN secara respektif.', 'tr': 'Bu kagyz WANLP 2021-nji ýylda sarkasm we duýgym tanyşynyň garaşy bar. Paýlaşan zadyň iki alt soragy bar: sarcasm deteksi (1-sorag) we duýgular analizi (2-sorag). Bu paylaşyk işi arapça sarkasm deteksiyona üýtgetmek we üns bermegi amaçlandyrýar. Bu duýgym analizi ýaly başga zadalarda etkinleşmek üçin wajyp däldir. Bu paylaşyk işinde ullanýan veri setir, ady ArSarcasm-v2, 15,548 tweets, sarkasm, duýgym we dialekt üçin etiketlenýän tweets diýilir. Biz 27 we 22 süýtgetmek üçin 1 we 2 süýtgetmek aldyk. Köp nusgalar AraBERT we MARBERT ýaly öňünden eğlenen dil nusgalaryny ulanmak we taýýarlanmagyna ynanýardy. Sarkasm tanyşygynyň we duýgular çözgüleriniň iň üst netijesi 0.6225 F1-अ we 0.748 F1-PN hasaplanýardy.', 'nl': 'Dit artikel geeft een overzicht van de gedeelde taak WANLP 2021 over sarcasme en sentimentdetectie in het Arabisch. De gedeelde taak heeft twee subtaken: sarcasmedetectie (subtaak 1) en sentimentanalyse (subtaak 2). Deze gedeelde taak heeft tot doel de detectie van Arabisch sarcasme te bevorderen en aandacht te vestigen, wat cruciaal is om de prestaties in andere taken zoals sentimentanalyse te verbeteren. De dataset die wordt gebruikt in deze gedeelde taak, namelijk ArSarcasm-v2, bestaat uit 15,548 tweets gelabeld voor sarcasme, sentiment en dialect. We ontvingen 27 en 22 inzendingen voor respectievelijk subtaken 1 en 2. De meeste benaderingen waren gebaseerd op het gebruik en finetunen van voorgetrainde taalmodellen zoals AraBERT en MARBERT. De top behaalde resultaten voor de sarcasme detectie en sentimentanalyse taken waren respectievelijk 0.6225 F1-score en 0.748 F1-PN.', 'sq': 'Ky dokument ofron një përmbledhje të detyrës së përbashkët WANLP 2021 mbi sarkazmin dhe zbulimin e ndjenjave në arabisht. Detyra e përbashkët ka dy nënpyetje: zbulimi i sarkazmit (nënpyetje 1) dhe analiza e ndjenjave (nënpyetje 2). Kjo detyrë e përbashkët synon të nxisë dhe sjellë vëmendje në zbulimin e sarkazmit arab, i cili është vendimtar për të përmirësuar performancën në detyra të tjera të tilla si analiza e ndjenjave. Të dhënat e përdorura në këtë detyrë të përbashkët, veçanërisht ArSarcasm-v2, përbëhen nga 15,548 tweets të etiketuar për sarkazëm, ndjesi dhe dialekt. We received 27 and 22 submissions for subtasks 1 and 2 respectively.  Shumica e qasjeve mbështeteshin në përdorimin dhe rregullimin e modeleve të gjuhës paratrajnuar të tilla si AraBERT dhe MARBERT. Rezultatet më të larta të arritura për detyrat e zbulimit të sarkazmit dhe analizës së ndjenjave ishin respektivisht 0.6225 F1 dhe 0.748 F1-PN.', 'am': 'ይህ ገጽ በዐረብኛ ቋንቋ እና ስሜት ማግኘት የWANLP 2021 ስራዎችን ያሳያል፡፡ የተካፈሉት ስራዎች ሁለት ደብዳቤዎች ናቸው፤ የሳርስብ ማግኘት (ደብዳቤ ስራ 1) እና የስሜት Analysis (ደብዳቤ 2). ይህ የተካፈለው ስራ አረቢ የሳርካሲ አፍቃሪን ለማድረግ እና ለማስታወቂያው ነው፤ ይህም የመስማት ትምህርት አካባቢ ትርፍን ለማድረግ ያስፈልጋል፡፡ አርሰርካስም-v2 በሚባል በዚህ ስራ ውስጥ የተጠቀም የዳታ ደረጃዎች ለሳርካሲም፣ ስሜት እና ዲያሌክ የተለየ 15,548 ትዊት ናቸው፡፡ አዳራሽ 1 እና 2 ለሥርዓት 27 እና 22 ጥልቶች ተቀበልን፡፡ አብዛኞቹ ልግስና እንደ AraBERT እና MARBERT የሚል የቋንቋ ምሳሌዎች በመጠቀም እና በመጠቀም ተደጋግሟል፡፡ The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748 F1-PN respectively.', 'az': 'Bu kağıt 2021-ci WANLP sarkasm və sentiment keşfini arabsızca paylaşır. Bölüşülmüş işin iki subtask ı var: sarkasm keşif (1 subtask) və hiss analizi (2 subtask). Bu paylaşılmış iş ərəbcə sarkasm keşfini təşkil etmək və gözləmək istəyir. Bu, sentiment analizi kimi başqa işlərdə performansını yaxşılaşdırmaq üçün çox mövcuddur. Bu paylaşılmış işlərdə istifadə edilən verilən qutusu, Adəmi ArSarcasm-v2, sarkasm, sentiment və dialekt üçün etiket edilən 15,548 twetlərdir. Biz 27 və 22 tərəfindən 1 və 2 tərəfindən istifadə etdik. Yaxınlıqların çoxu AraBERT və MARBERT kimi əvvəlcə təhsil edilmiş dil modellərinin istifadəsinə və düzəltməsinə təvəkkül edildi. Sarkasm tanıması və hiss analizi işlərinin ən yüksək sonuçları 0,6225 F1-score və 0,748 F1-PN idi.', 'bn': 'এই পত্রিকা আরবী ভাষায় বিদ্রোহ এবং আবেগ সন্ধানের উপর উয়ানএলপি ২০২১ শেয়ার কর্মসূচির উপর একটি পর্যবেক্ষণ প্রদান করেছে। শেয়ার করা কাজের মধ্যে দুটি সাবটার্ক রয়েছে: বিদ্রোহ সনাক্ত (সাবটাবাস ১) এবং আবেগ বিশ্লেষণ (সাবটাবাস ২)। এই ভাগাভাগি করা কাজের লক্ষ্য হচ্ছে আরবী বিদ্রোহীদের আবিষ্কারের প্রতি মনোযোগ আকর্ষণ এবং মনোযোগ আকর্ষণ করার জন্য, যা অন্যান্য কাজের মত অনু এই শেয়ার করা কাজে ব্যবহার করা ডাটাসেট, যার মধ্যে আর্সার্কাস্ম-ভি২, যার মধ্যে বিদ্রোহ, অনুভূতি এবং ডায়ালেক্টের জন্য লেবেল করা ১৫ ১ এবং ২ সাবটাসের জন্য আমরা ২৭ এবং ২২ জন সাবেক কাজ পেয়েছি। Most of the approaches relied on using and fine-tuning pre-trained language models such as AraBERT and MARBERT.  বিদ্রোহ সনাক্ত এবং অনুভূতিবিশ্লেষণ কাজের জন্য সর্বোচ্চ অর্জনের ফলাফল ছিল ০. 6225 এফ১ স্কোর এবং ০. 748 এফ১-পিএন।', 'hy': "Այս հոդվածը պատկերացնում է 2021 թվականի ՈւԱՆԼՊ-ի կազմակերպության և զգացմունքների հայտնաբերման հանրային խնդիրը արաբերենով: Երկու ենթահարց կա' սարկազմի հայտնաբերումը (ենթահարց 1) և զգացմունքների վերլուծությունը (ենթահարց 2): Այս ընդհանուր խնդիրը նպատակում է խրախուսել և ուշադրություն դարձնել արաբական սարկազմի հայտնաբերման վրա, որը կարևոր է բարելավելու համար այլ խնդիրների, ինչպիսիք են զգացմունքների վերլուծությունը: Այս ընդհանուր խնդրի մեջ օգտագործվող տվյալների համակարգը, հատկապես ArՍարկազմ-v2, կազմում է 15.548 թվիթեր, որոնք նշանակում են սարկազմ, զգացմունք և դիալեկտ: Մենք ստացանք 27 և 22 ներկայացումներ 1 և 2 ենթահարցերի համար: Մոտեցումներից շատերը հիմնված էին նախապատրաստված լեզվի մոդելների օգտագործման և բարելավման վրա, ինչպիսիք են Արաբերթը և Մարբերթը: Սարկազմի հայտնաբերման և զգացմունքների վերլուծության ամենաբարձր արդյունքները 0.6225 F1-գնահատականն էին, և 0.748 F1-PN-ը:", 'cs': 'Tento článek poskytuje přehled společného úkolu WALLP 2021 v oblasti sarkasmu a detekce sentimentů v arabštině. Sdílený úkol má dva podúkoly: detekci sarkasmu (podúkol 1) a analýzu sentimentu (podúkol 2). Tento společný úkol si klade za cíl podpořit a upozornit na detekci arabského sarkasmu, což je klíčové pro zlepšení výkonu v jiných úkolech, jako je analýza sentimentů. Datová sada použitá v tomto sdíleném úkolu, konkrétně ArSarcasm-v2, se skládá z 15,548 tweetů označených sarkasmem, sentimentem a dialektem. Obdrželi jsme 27 a 22 příspěvky pro podúkoly 1 a 2. Většina přístupů spoléhala na použití a jemné ladění předškolených jazykových modelů, jako jsou AraBERT a MARBERT. Nejlepšími dosaženými výsledky pro detekci sarkasmu a analýzu sentimentů byly 0,6225 F1-skóre a 0,748 F1-PN.', 'et': 'Käesolev töö annab ülevaate WARLP 2021 ühisest ülesandest sarkasmi ja tunnete tuvastamise kohta araabia keeles. Jagatud ülesandel on kaks alamülesannet: sarkasmi tuvastamine (alamülesanne 1) ja sentimentaalüüs (alamülesanne 2). Selle ühise ülesande eesmärk on edendada ja juhtida tähelepanu araabia sarkasmi avastamisele, mis on oluline muude ülesannete, näiteks sentimentaalüüsi tulemuslikkuse parandamiseks. Selles ühises ülesandes kasutatav andmekogum ArSarcasm-v2 koosneb 15 548 säutsu sarkasmi, sentimentaalsuse ja dialekti märgistusega. Saime vastavalt 27 ja 22 ettepanekut alaülesannete 1 ja 2 kohta. Enamik lähenemisviise tugines eelõpetatud keelemudelite nagu AraBERT ja MARBERT kasutamisele ja täpsustamisele. Sarkasmi tuvastamise ja sentimentaalüüsi ülesannete puhul saavutati parimad tulemused vastavalt 0,6225 F1-skoori ja 0,748 F1-PN.', 'bs': 'Ovaj papir predstavlja pregled delnog zadatka WANLP 2021. na arapskom jeziku o sarkazmu i otkrivanju osjećaja. Podijeljeni zadatak ima dva podataka: otkrivanje sarkazma (podpitanje 1) i analiza osjećaja (podpitanje 2). Ovaj zajednički zadatak je cilj promovirati i privesti pažnju na otkrivanje arapskog sarkazma, što je ključno za poboljšanje učinka u drugim zadacima poput analize osjećanja. Zeta podataka koja se koristi u ovom zajedničkom zadatku, a to je ArSarcasm-v2, sastoji se od 15.548 tweeta označene za sarkazam, osjećaj i dijalekt. Dobili smo 27 i 22 podatke za podatke 1 i 2. Većina pristupa se oslanjala na korištenje i ispravljanje predobučenih jezičkih modela poput AraBERT i MARBERT. Najveći postignuti rezultati za otkrivanje sarkazma i analiziranje osjećaja bili su 0,6225 F1 rezultata i 0,748 F1-PN.', 'ca': "Aquest article proporciona una visió general de la tasca compartida WANLP 2021 sobre el sarcasme i la detecció de sentiments en àrab. La tasca compartida té dues subpreguntes: la detecció del sarcasme (subpregunta 1) i l'anàlisi del sentiment (subpregunta 2). Aquesta tasca compartida té l'objectiu de promoure i portar atenció a la detecció del sarcasme àrab, que és crucial per millorar el rendiment en altres tasques com l'anàlisi del sentiment. El conjunt de dades utilitzat en aquesta tasca compartida, a saber ArSarcasm-v2, consisteix en 15.548 tweets etiquetats per sarcasme, sentiment i dialecte. Vam rebre 27 i 22 presentacions per subpreguntes 1 i 2 respectivament. Most of the approaches relied on using and fine-tuning pre-trained language models such as AraBERT and MARBERT.  Els millors resultats obtenits per a les tasques de detecció del sarcasme i anàlisi del sentiment eren 0,6225 puntuacions F1 i 0,748 F1-PN, respectivament.", 'af': "Hierdie papier verskaf 'n oorskou van die WANLP 2021 gedeelde taak op sarkasm en sentiment opdekking in Arabiese. Die gedeelde taak het twee subtaske: sarkasm opdekking (subtask 1) en sentiment analisie (subtask 2). Hierdie gedeelde taak doel doen om aandag te bevestig en aandag te bring na Arabiese sarkasme-opkenning, wat is daardie betaling om die prestasie in ander taak te verbeter soos sentimentanalisie. Die datastel wat in hierdie gedeelde taak gebruik word, naamlik ArSarcasm-v2, bestaan van 15,548 tweete wat vir sarkasm, sentiment en dialekte gemerk is. Ons het 27 en 22 onderdragte ontvang vir onderdragte 1 en 2 respektief. Die meeste van die toegang het op die gebruik en fyn-tuning van vooraf-onderwyse taal modele soos AraBERT en MARBERT geloof. Die boonste gevaardige resultate vir die sarkasme-opdekking en sentiment-analiseerde taak was 0.6225 F1-telling en 0.748 F1-PN respectively.", 'fi': 'Tämä artikkeli tarjoaa yleiskatsauksen WANLP 2021:n jaettuun tehtävään sarkasmin ja tunteiden havaitsemiseen arabiaksi. Jaetussa tehtävässä on kaksi alatehtävää: sarkasmin havaitseminen (alatehtävä 1) ja tunteiden analysointi (alatehtävä 2). Tämän yhteisen tehtävän tavoitteena on edistää arabialaisen sarkasmin havaitsemista ja kiinnittää huomiota siihen, mikä on ratkaisevan tärkeää muiden tehtävien, kuten tunteiden analysoinnin, suorituskyvyn parantamiseksi. Tässä yhteisessä tehtävässä käytetty aineisto, ArSarcasm-v2, koostuu 15 548 tweetistä, jotka on merkitty sarkasmille, tunteille ja murteelle. Saimme 27 ja 22 vastausta alatehtäviin 1 ja 2. Useimmat lähestymistavat perustuivat ennalta koulutettujen kielimallien, kuten AraBERTin ja MARBERTin, käyttöön ja hienosäätöön. Sarkasmin tunnistus- ja tunneanalyysitehtävissä saavutetut tulokset olivat 0,6225 F1-pistettä ja 0,748 F1-PN.', 'jv': 'Awak iki ngewehke nggawe barang beraksi karo WANLP 2020 kuwi wis dipun nggawe sarkasm karo jadongkapan kuwi wis arap. Awak dhéwé wis nambah durung panggunaké: sarkasm detection (panggunaké 1) lan dadi seneng dolanan (panggunaké 2). Mbak saiki wis dipun nggo populer, dadi penting sarkasm arap kuwi, ingkang dianggap kanggo nggawe barang kanggo tukang nggawe operasi sing wis ngerasakno ora tau ngerasakno ngerti Daftar setung dipunanggé uwong ing dikarolan iki, nambah arSarkasm-V2, dadi wis mungkin karo Awak dhéwé éntuk asai-asai kanggo 22 isuk kanggo tarjamahan 1 lan 2. Banyak hal-hal nganggo dolanan sing paling-upan lan model sing paling-upan bangsane, koyo araBERT karo MARBERT. iku', 'ha': 'Wannan takardan na samar da wani surfati na WANLP 2021 wanda aka yi raba aikin sarkasm da gane hisani cikin Larabci. Ana raba aikin da su yana da aikin biyu: gane sarcasm (bincike aikin 1) da Anarari na hisia (subaikin 2). Wannan aikin da aka raba shi yana aimar ta promote kuma ana gaya zuwa ganin sarkasm na Larabci, wanda yana da muhimu ga gyarawa a cikin aikin wasu misãlai kamar anadi. @ info: whatsthis Mun karɓi misãlai 27 da 22 ga aikin kawai 1 da 2. Babu mafi yawan hanyai sun ƙaddara a kan yin amfani da kuma mai tunkuɗe misãlai na zaman-tunkuɗewa kamar AraBERT da MARBERT. Sura da aka samar da matsala na gane sarcasm da aikin analyza na aikin sarcasm na wato 0.6325 F1-score da 0.748 F1-PN.', 'sk': 'Ta prispevek vsebuje pregled skupne naloge WALLP 2021 o sarkazmu in odkrivanju čustev v arabščini. Skupno opravilo ima dve podopravili: zaznavanje sarkazma (podopravilo 1) in analiza čustev (podopravilo 2). Ta skupna naloga je namenjena spodbujanju in opozarjanju na odkrivanje arabskega sarkazma, ki je ključnega pomena za izboljšanje uspešnosti pri drugih nalogah, kot je analiza čustva. Zbirka podatkov, ki se uporablja v tem skupnem opravilu, in sicer ArSarcasm-v2, je sestavljena iz 15.548 tweetov, označenih za sarkazem, sentiment in narečje. Prejeli smo 27 in 22 predlogov za podnaloga 1 oziroma 2. Večina pristopov se je opirala na uporabo in natančno nastavitev vnaprej usposobljenih jezikovnih modelov, kot sta AraBERT in MARBERT. Najboljši doseženi rezultati za naloge odkrivanja sarkazma in analize sentimenta sta bili 0,6225 F1-score oziroma 0,748 F1-PN.', 'bo': 'འོག་གི་ཤོག་བྱང་དེའི་ནང་དུ་WANLP 2021ལ་སྦྱར་བའི་བྱ་ཚིགས་དང་སེམས་ཚོར་རྟོགས་པ་ལ་བལྟ་སྟངས་བྱེད་ཀྱི་ཡོད། དབྱེ་སྤྱོད་ཀྱི་ལས་འགུལ་གྱིས་subtasks་གཉིས་ཡོད། sarcasm detection (subtask 1) and sentiment analysis (subtask 2)རེད། This shared task aims to promote and bring attention to Arabic sarcasm detection, which is crucial to improve the performance in other tasks such as sentiment analysis. The dataset used in this shared task, namely ArSarcasm-v2, consists of 15,548 tweets labelled for sarcasm, sentiment and dialect. ང་ཚོས་རྗེས་འཛིན་བྱས་པའི་subtasks ༡ དང་། ༢་གཉིས་ཀྱིས་བཏོན་པ་ཡིན། ཕལ The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748 F1-PN respectively.', 'he': 'העבודה הזו מספקת תצוגה על המשימה המשותפת של WANLP 2021 על זיהוי סרקזם ומרגשות בערבית. למשימה המשותפת יש שתי תת-שאלות: זיהוי סרקזם (תת-שאלה 1) וניתוח רגשות (תת-שאלה 2). המשימה המשותפת הזו מטורפת לקדם ולהביא תשומת לב לגילוי הסרקזם הערבי, שהיא קריטית לשפר את ההופעה במשימות אחרות כמו ניתוח רגשות. The dataset used in this shared task, namely ArSarcasm-v2, consists of 15,548 tweets labelled for sarcasm, sentiment and dialect.  We received 27 and 22 submissions for subtasks 1 and 2 respectively.  Most of the approaches relied on using and fine-tuning pre-trained language models such as AraBERT and MARBERT.  התוצאות הגדולות ביותר שגורמות עבור זיהוי הסרקזם ומשימות ניתוח הרגשות היו 0.6225 נקודות F1 ו-0.748 F1-PN בהתאם.'}
{'en': 'Sarcasm and Sentiment Detection In Arabic Tweets Using BERT-based Models and Data Augmentation', 'ar': 'كشف السخرية والمشاعر في التغريدات العربية باستخدام النماذج القائمة على BERT وزيادة البيانات', 'es': 'Detección de sarcasmo y sentimiento en tuits árabes mediante modelos basados en BERT y aumento de datos', 'fr': "Détection du sarcasme et des sentiments dans les tweets arabes à l'aide de modèles basés sur BERT et d'augmentation des données", 'pt': 'Detecção de sarcasmo e sentimento em tweets árabes usando modelos baseados em BERT e aumento de dados', 'zh': '用BERT模、数阿拉伯语推刺情检', 'ja': 'BERTベースのモデルとデータ拡張を使用したアラビア語ツイートでの皮肉と感情の検出', 'hi': 'व्यंग्य और भावना का पता लगाना अरबी Tweets में BERT-आधारित मॉडल और डेटा संवर्धन का उपयोग कर', 'ru': 'Обнаружение сарказма и сентиментов в арабских твитах с использованием моделей на основе BERT и увеличения данных', 'ga': 'Sarcasm agus Meon a Bhrath i dTweetanna Araibis ag 횣s찼id M첬nla챠 bunaithe ar BERT agus M챕ad첬 Sonra챠', 'hu': 'Szarkazmus és érzékelés arab tweetekben BERT-alapú modellek és adatbővítés segítségével', 'it': 'Rilevamento di sarcasmo e sentimento nei tweet arabi utilizzando modelli basati su BERT e aumento dei dati', 'kk': 'Саркассм және сентиментті табу араб tweets беттерінде BERT негіздеген үлгілер және деректерді күшейту', 'lt': 'Sarkazmas ir jausmų nustatymas arabų dvietais, naudojant BERT pagrįstus modelius ir duomenų didinimą', 'mk': 'Детектирање на сарказам и чувства на арапски твитови користејќи модели и податоци базирани на BERT', 'ms': 'Pengesanan Sarkasm dan Sentiment Dalam Tweet Arab Menggunakan Model Berasas BERT dan Penguasaan Data', 'el': 'Σαρκασμός και ανίχνευση συναισθημάτων σε αραβικά tweets χρησιμοποιώντας μοντέλα βασισμένα στο BERT και αύξηση δεδομένων', 'ka': 'Sarcasm და Sentiment Detection in Arabic Tweets Using BERT-based Models and Data Augmentation', 'mt': 'Sarkazmu u Sejbien tas-Sentiment fit-Tweets Għarab bl-Użu ta’ Mudelli bbażati fuq BERT u Żieda fid-Dejta', 'ml': 'സർക്കാസം, സെന്റിമെന്റ് ഡേറ്റാ ഓഗ്മെന്റേഷനും ഉപയോഗിക്കുന്ന അറബി ട്രൂട്ടുകൾ', 'mn': 'Sarcasm and Sentiment Detection In Arabic Tweets Using BERT-based Models and Data Augmentation', 'no': 'Sarkasm- og sentiserte oppdaging i arabiske tweeter Bruk BERT- basert modell og dataaugmentasjon', 'pl': 'Sarkazm i wykrywanie sentymentów w arabskich tweetach przy użyciu modeli opartych na BERT i rozszerzeniu danych', 'ro': 'Detectarea sarcasmului și sentimentelor în tweeturile arabe folosind modele bazate pe BERT și mărirea datelor', 'sr': 'Sarkazam i otkrivanje sentimenta na arapskim tweetima korištenje modela i povećanja podataka na BERT-u', 'si': 'Sarcasm සහ Sentiment Detection In Arab Tweets Using BERT-based Models and Data Agmentation', 'so': 'Sarcasm and Sentiment Detection In Arabic Tweets using BERT-based Models and Data Augmentation', 'ta': 'Sarcasm and Sentiment Detection In Arabic Tweets using BERT- based Models and Data Augmentation', 'sv': 'Sarkasm och känslodetektering i arabiska tweets med hjälp av BERT-baserade modeller och dataförstärkning', 'ur': 'Sarcasm and Sentiment Detection in Arabic Tweets using BERT-based Models and Data Augmentation', 'vi': 'Phát hiện Sarcasm và cảm xúc trong băng Tweet Ả Rập Sử dụng các mô-típ cây chuối và các dữ liệu gia tăng.', 'uz': 'Name', 'bg': 'Сарказъм и откриване на чувства в арабски туитове с помощта на базирани модели и увеличаване на данни', 'da': 'Opdagelse af sarkasme og følelser i arabiske tweets ved hjælp af BERT-baserede modeller og dataudvidelse', 'nl': 'Sarcasme en Sentiment Detection in Arabische Tweets met behulp van BERT-gebaseerde modellen en Data Augmentation', 'hr': 'Poremećaj i otkrivanje osjetljivosti na arapskim tweetovima Koristeći modele i povećanje podataka na BERT-u', 'de': 'Sarkasmus und Sentiment Detection in arabischen Tweets mit BERT-basierten Modellen und Datenarweiterung', 'id': 'Deteksi Sarkasme dan Sentimen Dalam Tweet Arab Menggunakan Model Berdasarkan BERT dan Data Augmentation', 'fa': 'پیدا کردن سارکاسم و احساسات در تویتهای عربی با استفاده از مدل\u200cهای بنیاد BERT و افزایش داده\u200cها', 'ko': '버트 모델과 데이터를 바탕으로 강화된 아랍어 추문 풍자와 정서 검측', 'sw': 'Uchunguzi wa Kiarabu na Uchunguzi wa Kiarabu kwa kutumia Simulizi za BERT na Uongezeko wa Taarifa', 'tr': 'BERT tabanly Modeller we Maglumaty Aňlamak', 'af': 'Sarkasm en Sentiment Opdekking in Arabiese Tweets gebruik BERT-gebaseerde Modelle en Data Opgradering', 'sq': 'Detektimi i sarkazmit dhe ndjenjave në tweetet arabe duke përdorur modele dhe rritje të të dhënave me bazë në BERT', 'am': 'Sarcasm and Sentiment Detection In Arabic Tweets using BERT-based Models and Data Augmentation', 'hy': 'Սարկազմը և զգացմունքների հայտնաբերումը արաբական թվիթերում BER-ի հիմնված մոդելներով և տվյալների աճով', 'bn': 'আরবী টুইটারে সার্কাস্ম এবং সেন্টিমেন্ট ডিটেকটিশন ব্যবহার করে BERT ভিত্তিক মডেল এবং ডাটা অ্যাগমেন্ট ব্যবহার করে', 'az': 'Sarkasm v톛 Sentiment Tan캼ma Arap칞a T칬vetl톛rd톛 BERT tabanl캼 Modell톛r v톛 Data Augmentation', 'bs': 'Sarkazam i otkrivanje sentimenta na arapskim tweetima Koristeći modele i povećanje podataka na BERT-u', 'ca': 'Detection of Sarcasm and Sentiment In Arabic Tweets Using BERT-based Models and Data Augmentation', 'cs': 'Sarkasmus a detekce sentimentů v arabských tweetech pomocí modelů založených na BERT a rozšíření dat', 'et': 'Sarkasmi ja tunnete tuvastamine araabia tweetides BERT-põhiste mudelite ja andmete suurendamise abil', 'fi': 'Sarkasmin ja tunteiden tunnistus arabialaisissa twieteissä BERT-pohjaisten mallien ja datan lisäämisen avulla', 'jv': 'Sarkasm lan Sentiment detection In Gabons', 'sk': 'Zaznavanje sarkazma in čustva v arabskih tweetih z uporabo BERT-ovih modelov in povečanja podatkov', 'ha': 'KCharselect unicode block name', 'bo': 'Sarcasm and Sentiment Detection In Arabic Tweets Using BERT-based Models and Data Augmentation', 'he': 'סרקזם וגילוי רגשות בטוויטים ערביים בשימוש מודלים מבוססים על BERT וגילוי נתונים'}
{'en': 'In this paper, we describe our efforts on the shared task of sarcasm and sentiment detection in Arabic (Abu Farha et al., 2021). The shared task consists of two sub-tasks : Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). Our experiments were based on fine-tuning seven BERT-based models with data augmentation to solve the imbalanced data problem. For both tasks, the MARBERT BERT-based model with data augmentation outperformed other models with an increase of the F-score by 15 % for both tasks which shows the effectiveness of our approach.', 'ar': 'في هذه الورقة ، نصف جهودنا في المهمة المشتركة للسخرية واكتشاف المشاعر باللغة العربية (أبو فرحة وآخرون ، 2021). تتكون المهمة المشتركة من مهمتين فرعيتين: الكشف عن السخرية (المهمة الفرعية 1) وتحليل المشاعر (المهمة الفرعية 2). استندت تجاربنا إلى الضبط الدقيق لسبعة نماذج تستند إلى BERT مع زيادة البيانات لحل مشكلة البيانات غير المتوازنة. لكلتا المهمتين ، تفوق نموذج MARBERT BERT مع زيادة البيانات في الأداء على النماذج الأخرى بزيادة درجة F بنسبة 15٪ لكلتا المهمتين مما يدل على فعالية نهجنا.', 'es': 'En este artículo, describimos nuestros esfuerzos en la tarea compartida de detección de sarcasmo y sentimientos en árabe (Abu Farha et al., 2021). La tarea compartida consta de dos subtareas: Detección de sarcasmo (subtarea 1) y Análisis de opinión (subtarea 2). Nuestros experimentos se basaron en el ajuste fino de siete modelos basados en Bert con el aumento de datos para resolver el problema de los datos desequilibrados. Para ambas tareas, el modelo basado en MARBERT BERT con aumento de datos superó a otros modelos con un aumento del puntaje F en un 15% para ambas tareas, lo que demuestra la eficacia de nuestro enfoque.', 'pt': 'Neste artigo, descrevemos nossos esforços na tarefa compartilhada de detecção de sarcasmo e sentimento em árabe (Abu Farha et al., 2021). A tarefa compartilhada consiste em duas subtarefas: Detecção de Sarcasmo (Subtarefa 1) e Análise de Sentimentos (Subtarefa 2). Nossos experimentos foram baseados no ajuste fino de sete modelos baseados em BERT com aumento de dados para resolver o problema de dados desequilibrados. Para ambas as tarefas, o modelo baseado em MARBERT BERT com aumento de dados superou outros modelos com um aumento do F-score em 15% para ambas as tarefas, o que mostra a eficácia de nossa abordagem.', 'fr': "Dans cet article, nous décrivons nos efforts sur la tâche commune de détection du sarcasme et des sentiments en arabe (Abu Farha et al., 2021). La tâche partagée comprend deux sous-tâches\xa0: la détection des sarcasmes (sous-tâche 1) et l'analyse des sentiments (sous-tâche 2). Nos expériences étaient basées sur le réglage fin de sept modèles basés sur BERT avec augmentation des données afin de résoudre le problème des données déséquilibrées. Pour les deux tâches, le modèle basé sur MARBERT BERT avec augmentation des données a surpassé les autres modèles avec une augmentation du score F de 15\xa0% pour les deux tâches, ce qui montre l'efficacité de notre approche.", 'ja': '本稿では，アラビア語による皮肉と感情の検出という共通の課題に対する取り組みについて述べる（ Abu Farha et al., 2021 ） ．共有タスクは、皮肉検出（サブタスク1 ）と感情分析（サブタスク2 ）の2つのサブタスクで構成されています。私たちの実験は、不均衡なデータ問題を解決するために、7つのBERTベースのモデルをデータ拡張で微調整することに基づいていました。両方のタスクについて、データ拡張機能を備えたMARBERT BERTベースのモデルは、両方のタスクのFスコアが15%増加し、当社のアプローチの有効性を示し、他のモデルよりも優れていました。', 'zh': '本文中,述阿拉伯语刺情检共同任务上努力(Abu Farha等,2021)。 共事:刺检(子 1)情析(子 2)。 吾实验基于微调7基于BERT形,与数增强,以决不平之数。 凡此二者,有数于MARBERT BERT BERT,有二于F,有分于15%,明吾道之有效性也。', 'hi': 'इस पेपर में, हम अरबी में व्यंग्य और भावना का पता लगाने के साझा कार्य पर हमारे प्रयासों का वर्णन करते हैं (अबू फरहा एट अल। साझा कार्य में दो उप-कार्य होते हैं: व्यंग्य का पता लगाना (Subtask 1) और भावना विश्लेषण (Subtask 2)। हमारे प्रयोग असंतुलित डेटा समस्या को हल करने के लिए डेटा वृद्धि के साथ सात BERT-आधारित मॉडल को ठीक करने पर आधारित थे। दोनों कार्यों के लिए, डेटा वृद्धि के साथ MARBERT BERT-आधारित मॉडल ने दोनों कार्यों के लिए F-स्कोर में 15% की वृद्धि के साथ अन्य मॉडलों को पछाड़ दिया जो हमारे दृष्टिकोण की प्रभावशीलता को दर्शाता है।', 'ru': 'В этой статье мы описываем наши усилия по общей задаче обнаружения сарказма и чувств на арабском языке (Abu Farha et al., 2021). Общая задача состоит из двух подзадач: Обнаружение сарказма (Подзадача 1) и Анализ настроений (Подзадача 2). Наши эксперименты были основаны на тонкой настройке семи моделей на основе BERT с расширением данных для решения проблемы несбалансированных данных. Для обеих задач модель на основе MARBERT BERT с расширением данных превзошла другие модели с увеличением F-оценки на 15% для обеих задач, что показывает эффективность нашего подхода.', 'ga': "Sa pháipéar seo, déanaimid cur síos ar ár n-iarrachtaí ar an tasc roinnte a bhaineann le searbhas agus braite meon in Araibis (Abu Farha et al., 2021). Tá dhá fhothasc sa tasc comhroinnte: Brath Sarcasm (Fothasc 1) agus Anailís Mothúchán (Fothasc 2). Bhí ár dturgnaimh bunaithe ar mhionchoigeartú a dhéanamh ar sheacht múnla bunaithe ar BERT le méadú sonraí chun fadhb mhíchothromaithe na sonraí a réiteach. Maidir leis an dá thasc, d'éirigh níos fearr leis an tsamhail bunaithe ar MARBERT BERT le méadú sonraí ná samhlacha eile le méadú 15% ar an scór-F don dá thasc a léiríonn éifeachtacht ár gcur chuige.", 'hu': 'Ebben a tanulmányban leírjuk a szarkazmus és az érzelmek felismerésének közös feladatával kapcsolatos erőfeszítéseinket arabul (Abu Farha et al., 2021). A megosztott feladat két alcsoportból áll: Szarkazmus felismerése (1. alcsoport) és Érzelmelemzés (2. alcsoport). Kísérleteink hét BERT alapú modell finomhangolásán alapultak adatbővítéssel a kiegyensúlyozatlan adatprobléma megoldására. Mindkét feladat esetében a MARBERT BERT alapú, adatbővítéssel ellátott modell más modelleket is felülmúlta, az F pontszám 15%-kal növekedett mindkét feladat esetében, ami mutatja megközelítésünk hatékonyságát.', 'ka': 'ჩვენ ამ დოკუნეში ჩვენი ძალიან აღწერებთ საპკასმის და სენტიმენტების განახლების საზოგადო დავაწერებაში (Abu Farha et al., 2021). საზოგადოებული დავალება არის ორი საზოგადო დავალებისგან: საზოგადომის განახლება (საზოგადომი 1) და საზოგადომი ანალიზი (საზოგადომი 2). ჩვენი ექსპერიმენტები ბერტი დაბათებული შვიდი მოდელეების შესაძლებლოდ მონაცემების აზექტირება, რომელიც განმავლობაში მონაცემების პრობლემა გადაუწყ ორივე დავალებისთვის, MARBERT BERT-ის მოდელი, რომელიც მონაცემების აგგენციაციაში სხვა მოდელები გააკეთებულია, რომელიც F-score გააკეთებულია 15% დამატებული ორივე დავალებისთვის, რომელიც ჩვენი', 'el': 'Στην παρούσα εργασία περιγράφουμε τις προσπάθειές μας για το κοινό έργο του σαρκασμού και της ανίχνευσης συναισθημάτων στα αραβικά (Αμπού Φάρχα κ.α., 2021). Η κοινή εργασία αποτελείται από δύο δευτερεύουσες εργασίες: ανίχνευση σαρκασμού (δευτερεύουσα εργασία 1) και ανάλυση συναισθημάτων (δευτερεύουσα εργασία 2). Τα πειράματά μας βασίστηκαν σε τελειοποίηση επτά μοντέλων βασισμένων στο BERT με αύξηση δεδομένων για την επίλυση του προβλήματος των ανισορροπιών δεδομένων. Και για τις δύο εργασίες, το μοντέλο βασισμένο στο MARBERT BERT με αύξηση δεδομένων υπερνίκησε άλλα μοντέλα με αύξηση της βαθμολογίας F κατά 15% και για τις δύο εργασίες, γεγονός που δείχνει την αποτελεσματικότητα της προσέγγισής μας.', 'it': "In questo articolo, descriviamo i nostri sforzi sul compito condiviso del sarcasmo e della rilevazione dei sentimenti in arabo (Abu Farha et al., 2021). L'attività condivisa consiste in due sottocompiti: rilevamento del sarcasmo (sottotask 1) e analisi del sentimento (sottotask 2). I nostri esperimenti si sono basati sulla messa a punto di sette modelli basati su BERT con aumento dei dati per risolvere il problema dei dati sbilanciati. Per entrambe le attività, il modello basato su MARBERT BERT con aumento dei dati ha superato altri modelli con un aumento del punteggio F del 15% per entrambe le attività, il che dimostra l'efficacia del nostro approccio.", 'mk': 'Во овој весник ги опишуваме нашите напори за заедничката задача на сарказам и детекција на чувства на арапски (Абу Фарха итн., 2021). Соделената задача се состои од две подзадачи: Детектирање на сарказам (подзадача 1) и анализа на чувствата (подзадача 2). Нашите експерименти беа базирани на подобрување на седум модели базирани на БЕРТ со зголемување на податоците за решавање на небалансираниот проблем со податоците. За двете задачи, моделот базиран на MARBERT BERT со зголемување на податоците ги надмина другите модели со зголемување на F-оценката за 15 отсто за двете задачи кои ја покажуваат ефикасноста на нашиот пристап.', 'kk': 'Бұл қағазда, біз араб тілінде сарказм мен сезімді анықтау тапсырмасының ортақ тапсырмаларын (Abu Farha et al., 2021). Ортақ тапсырманың екі ішкі тапсырмасынан тұрады: Sarcasm тапсырмасын анықтау (1- ішкі тапсырма) және Sentiment анализ (2- ішкі тапсырма). Біздің тәжірибеміз берт негіздеген жеті моделдерді баптауға негізделген деректерді өзгерту үшін деректерді өзгерту үшін. Екі тапсырма үшін MARBERT BERT негіздеген үлгі деректерді көтеру үшін басқа үлгілерді F- score көтеріп 15% деген үлгілерді өзгертеді. Бұл екі тапсырма үшін біздің тәртіпсіздігімізді көрсете', 'ms': 'Dalam kertas ini, kami menggambarkan usaha kami untuk tugas berkongsi sarkasme dan pengesan perasaan dalam bahasa Arab (Abu Farha et al., 2021). Tugas berkongsi terdiri dari dua sub-tugas: Pengesanan Sarkasm (Subtask 1) dan Analisi Sentiment (Subtask 2). Eksperimen kami berdasarkan penyesuaian tujuh model berdasarkan BERT dengan peningkatan data untuk menyelesaikan masalah data yang tidak seimbang. Untuk kedua-dua tugas, model berasaskan-MARBERT BERT dengan peningkatan data melampaui model lain dengan peningkatan skor-F dengan 15% untuk kedua-dua tugas yang menunjukkan keefektivitas pendekatan kita.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d നമ്മുടെ പ്രവര്\u200dത്തനങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. അറബിയിലെ പങ്കാളിയുടെയും വികാരണത്തിന്റെയും പ്രശ പങ്കെടുത്ത ജോലി നമ്മുടെ പരീക്ഷണങ്ങള്\u200d ഏഴ് ബെര്\u200dട്ടി അടിസ്ഥാനമായി സൂക്ഷിക്കുന്നതിന് അടിസ്ഥാനമായിരുന്നു. ഡേറ്റാ കൂട്ടുന്നതിനുള് രണ്ട് ജോലികള്\u200dക്കും മാര്\u200dബെര്\u200dട്ട് ബെര്\u200dട്ടിന്\u200dറെ അടിസ്ഥാനമായ മോഡല്\u200d, ഡേറ്റാ കൂട്ടുന്നതിനുമായി മറ്റു മോഡലുകള്\u200d പ്രവര്\u200dത്തിപ്പിച്ചു. എഫ് സ്കോ', 'mt': 'F’dan id-dokument, aħna niddeskrivu l-isforzi tagħna dwar il-kompitu komuni tas-sarkazmu u s-sejbien tas-sentimenti fl-Għarab (Abu Farha et al., 2021). Il-kompitu kondiviż jikkonsisti f’żewġ sottokompiti: Detezzjoni tas-Sarkazmu (Subkompitu 1) u Analiżi tas-Sentiment (Subkompitu 2). L-esperimenti tagħna kienu bbażati fuq l-irfinar ta’ seba’ mudelli bbażati fuq BERT b’żieda fid-dejta biex tissolva l-problema tad-dejta żbilanċjata. Għaż-żewġ kompiti, il-mudell ibbażat fuq MARBERT BERT b’żieda fid-dejta wettaq mudelli oħra b’żieda fil-punteġġ F b’15% għaż-żewġ kompiti li juru l-effettività tal-approċċ tagħna.', 'no': 'I denne papiret beskriver vi forsøkene våre på den delte oppgåva av sarkasm og sentimentoppdaging på arabisk (Abu Farha et al., 2021). Den delte oppgåva inneheld to underoppgåver: Sarkasm- oppdaging (Subtask 1) og Sentiment- analyse (Subtask 2). Eksperimentane våre vart basert på fine-tuning av sju BERT-baserte modeller med data-augmentasjon for å løysa den ulike dataproblemet. For begge oppgåver er MARBERT BERT-basert modellen med data-augmentasjon utført andre modeller med økt av F-scoren på 15 % for begge oppgåver som viser effektiviteten av tilnærminga vårt.', 'mn': 'Энэ цаасан дээр бид өөрсдийгөө араб хэлний саркассм, сэтгэл хөдлөлийн мэдрэмжүүдийн хуваалцах үйл ажиллагааг тайлбарладаг. Холбоотой ажил нь хоёр суб-даалгавартай байдаг: Саркассм Detection (Subtask 1) болон Sentiment Analysis (Subtask 2). Бидний туршилтууд БЕРТ-д суурилсан 7 загвар дээр өгөгдлийн нэмэгдүүлэлт өгөгдлийн асуудлыг шийдэхэд суурилсан. Хоёр даалгаварын тулд MARBERT BERT-ын загвар нь өгөгдлийн нэмэлт загвараас бусад загваруудыг F-score-ын нэмэлт нь 15%-аар нэмэгдүүлсэн. Энэ хоёр даалгаварын үр дүнг харуулдаг.', 'lt': 'Šiame dokumente apibūdiname mūsų pastangas bendrai vykdyti sarkazmo ir jausmų aptikimo arabų kalba užduotį (Abu Farha et al., 2021 m.). Bendrą užduotį sudaro dvi subužduotys: sarkazmo nustatymas (1 subužduotis) ir jutimo analizė (2 subužduotis). Mūsų eksperimentai buvo pagrįsti patobulintais septyniais BERT pagrįstais modeliais ir duomenų didinimu siekiant išspręsti disbalansuotų duomenų problem ą. Abiejų užduočių atveju MARBERT BERT pagrįstas modelis su duomenų didinimu viršijo kitus modelius, o abiejų užduočių atveju F balas padidėjo 15 %, o tai rodo mūsų požiūrio veiksmingumą.', 'pl': 'W artykule opisujemy nasze wysiłki na rzecz wspólnego zadania wykrywania sarkazmu i sentymentów w języku arabskim (Abu Farha et al., 2021). Wspólne zadanie składa się z dwóch podzadań: Wykrywanie sarkazmu (Podzadanie 1) i Analiza sentymentów (Podzadanie 2). Nasze eksperymenty opierały się na dostrojeniu siedmiu modeli opartych na BERT z powiększeniem danych w celu rozwiązania problemu niezrównoważonych danych. Dla obu zadań model oparty na MARBERT BERT z powiększeniem danych przewyższył inne modele ze wzrostem F-score o 15% dla obu zadań, co pokazuje skuteczność naszego podejścia.', 'ro': 'În această lucrare, descriem eforturile noastre asupra sarcinii comune de detectare a sarcasmului și sentimentelor în limba arabă (Abu Farha et al., 2021). Activitatea partajată constă din două subsarcini: detectarea sarcasmului (subsarcina 1) și analiza sentimentelor (subsarcina 2). Experimentele noastre s-au bazat pe reglarea fină a șapte modele bazate pe BERT cu mărirea datelor pentru a rezolva problema dezechilibrată a datelor. Pentru ambele sarcini, modelul bazat pe MARBERT BERT cu augmentare a datelor a depășit alte modele, cu o creștere a scorului F cu 15% pentru ambele sarcini, ceea ce arată eficiența abordării noastre.', 'sr': 'U ovom papiru opisujemo naše napore na zajedničkom zadatku sarkazma i detekcije sentimenta na arapskom (Abu Farha et al., 2021). Podijeljeni zadatak sastoji od dva podzadataka: detekcija sarkazma (podzadatak 1) i analiza sentimenta (podzadatak 2). Naši eksperimenti su temeljeni na osnovu finalnih sedam modela baziranih na BERT-u sa povećanjem podataka kako bi rešili problem sa nelabalansiranim podacima. Za obe zadatke, model na MARBERT BERT-u sa povećanjem podataka iznosio je druge modele sa povećanjem F-rezultata za 15% za obe zadatke koje pokazuju učinkovitost našeg pristupa.', 'si': 'මේ පත්තරේ අපි අපේ උත්සාහ කරනවා සර්කාස්ම් සහ හිතුවක් හොයාගන්නේ අරාබි වල (Abu Farha et al., 2021). සම්බන්ධ වැඩේ සබ් වැඩ දෙකක් තියෙනවා: සර්කාස්ම් හොයාගන්න (සබ් වැඩ 1) සහ සම්බන්ධ විශ්ලේෂණය (සබ් වැඩ 2). අපේ පරීක්ෂණය සිද්ධ වුනා BERT සිද්ධ විදියට පරීක්ෂණය සඳහා තොරතුරු විශාල කරන්න දත්ත ප්\u200dරශ්නයක් විසඳන්න. මාර්බෙර්ට් බෙර්ට් අධාරිත මොඩේල් එක්ක අනිත් මොඩේල් එක්ක වැඩ කරන්න විතරයි F-ස්කෝර් එක 15% විශාල වෙනුවෙන් අනිත් මොඩේල් එක්ක අප', 'so': 'Qoraalkan waxaynu ku qoraynaa hawlahayaga la qaybsaday oo la xiriira baaritaanka sarkaalka iyo fikrada afka Carabiga (Abu Farha et al, 2021). Shaqoda la qaybsado waxaa ka mid ah labo sub-shaqo: Shaqeynta sarcasm (Sub-task 1) iyo fasaxa sameynta (Sub-task 2). Imtixaankayadii waxay ku saleysan jireen samooyin saxda ah todobo BERT-based oo lagu kordhinayo data si ay u xalliyaan dhibaatada macluumaadka aan la garanayn. Shaqooyinka labadoodaba waxaa lagu sameeyaa model ku saleysan MARBERT BERT oo ku qoran koritaanka data, waxayna sameeyeen modello kale oo la kordhiyey kooxda F-scorta 15% ee labada shaqooyin oo tusiya effektada qaababkayaga.', 'sv': 'I denna uppsats beskriver vi våra insatser för den gemensamma uppgiften sarkasm och sentimentdetektering på arabiska (Abu Farha et al., 2021). Den delade uppgiften består av två underuppgifter: Sarkasm Detection (deluppgift 1) och Sentiment Analysis (deluppgift 2). Våra experiment baserades på finjustering av sju BERT-baserade modeller med dataförstärkning för att lösa problemet med obalanserad data. För båda uppgifterna överträffade MARBERT BERT-modellen med dataförstärkning andra modeller med en ökning av F-poängen med 15% för båda uppgifterna vilket visar hur effektivt vårt tillvägagångssätt är.', 'ta': 'இந்த காகிதத்தில், நாம் எங்கள் முயற்சிகளை விவரிக்கிறோம் பங்கிட்ட செயல் மற்றும் உணர்வு கண்டுபிடிப்பு அரபி மொழியில் (அபு ப பகிர்ந்த செயல் இரண்டு துணை பணிகளில் உள்ளது: சார்காஸ் கண்டுபிடிப்பு (உப செயல் 1) மற்றும் உணர்வு விளக்கம் (உப பணி 2). Our experiments were based on fine-tuning seven BERT-based models with data augmentation to solve the imbalanced data problem.  இரு பணிகளுக்கும், MARBERT பெர்ட் அடிப்படையில் தரவு மேம்படுத்தல் மாதிரி மற்ற மாதிரிகள் செய்துள்ளது மற்ற மாதிரிகளுடன் F- score அதிகரித்தது 15% இரு பணிகளுக்', 'ur': 'اس کاغذ میں ہم نے اپنی کوشش کو صارکاسم اور احساسات کا مشترک کام کے بارے میں بیان کیا ہے (Abu Farha et al., 2021). Shared task consists of two sub-tasks: Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). ہماری آزمائش سات BERT بنیادی موڈل پر بنیاد رکھی گئی تھی جن کے ساتھ ڈیٹا اضافہ کرنے کے لئے ڈیٹا مسئلہ حل کرنے کے لئے۔ دونوں کاموں کے لئے، MARBERT BERT بنیادی موڈل ڈاٹ افزایش کے ساتھ دوسرے موڈل پر F-score کی افزایش 15% کے ذریعہ دکھائی جاتی تھی جو ہماری طریقہ کی فعالیت دکھاتی تھی۔', 'uz': "Bu hujjatda, biz arabdagi sarkasm va hissiyotni aniqlash vazifasini anglatamiz (Abu Farha et al, 2021). @ info: whatsthis Bizning imtiyozlarimiz yetti BERT asosida bajarish modellari asosida o'xshash maʼlumot muammolarini o'zgartirish mumkin. Bu ikkita vazifalar uchun MARBERT BERT asosida maʼlumot qoʻshimcha modeli boshqa modellarni F- scorning 15% darajada ko'payishi mumkin. Bu ikkita vazifalarning fikrimning effektini ko'rsatadi.", 'vi': 'Trong tờ giấy này, chúng tôi mô tả nỗ lực của chúng tôi về một nhiệm vụ có chế độ mỉa mai và cảm xúc bằng tiếng Ả Rập (Abu Farha et al., 2021). Nhiệm vụ chia sẻ gồm hai nhiệm vụ: phát hiện Sarcasm (giấu 1) và kết quả cảm thất (giấu 2). Các thí nghiệm của chúng tôi được dựa trên độ chín của bảy mô hình nền BERT cùng với việc gia tăng dữ liệu để giải quyết vấn đề dữ liệu thiếu cân bằng. Đối với cả hai nhiệm vụ, mẫu mã MABERT, cùng với việc gia tăng dữ liệu, đã thực hiện các mô hình khác với việc tăng số F-điểm đến 15. cho cả hai nhiệm vụ cho thấy hiệu quả của phương pháp này.', 'bg': 'В тази статия описваме усилията си по споделената задача за откриване на сарказъм и сентименти на арабски език (Абу Фарха и др., 2021). Споделената задача се състои от две подзадачи: откриване на сарказъм (подзадача 1) и анализ на чувствата (подзадача 2). Нашите експерименти бяха базирани на фина настройка на седем модела базирани на BERT с увеличаване на данните за решаване на проблема с дисбалансираните данни. И за двете задачи базираният модел с увеличение на данните надмина другите модели с увеличение на рейтинга с 15% за двете задачи, което показва ефективността на нашия подход.', 'hr': 'U ovom papiru opisujemo svoje napore na zajedničkom zadatku sarkazma i otkrivanja osjećaja na arapskom (Abu Farha et al., 2021). Podijeljeni zadatak sastoji se od dva podzadataka: otkrivanje sarkasma (podzadatak 1) i analiza sentimenta (podzadatak 2). Naši eksperimenti su temeljeni na ispravnoj prilagodbi sedam modela baziranih na BERT-u s povećanjem podataka kako bi riješili problem s nelabalansiranim podacima. Za obe zadatke, model na MARBERT BERT-u s povećanjem podataka iznosio je drugi modeli s povećanjem F-rezultata za 15% za oba zadatka koji pokazuju učinkovitost našeg pristupa.', 'da': 'I denne artikel beskriver vi vores indsats på den fælles opgave med sarkasme og følelsesdetektion på arabisk (Abu Farha et al., 2021). Den delte opgave består af to underopgaver: Sarkasme Detection (underopgave 1) og Sentiment Analysis (underopgave 2). Vores eksperimenter var baseret på finjustering af syv BERT-baserede modeller med dataaugmentation for at løse det ubalancerede dataproblem. For begge opgaver har den MARBERT BERT-baserede model med dataaugmentation overgået andre modeller med en stigning i F-scoren med 15% for begge opgaver, hvilket viser effektiviteten af vores tilgang.', 'nl': 'In dit artikel beschrijven we onze inspanningen op het gebied van sarcasme en sentimentdetectie in het Arabisch (Abu Farha et al., 2021). De gedeelde taak bestaat uit twee deeltaken: Sarcasme Detection (Subtaak 1) en Sentiment Analysis (Subtaak 2). Onze experimenten waren gebaseerd op het finetunen van zeven BERT-gebaseerde modellen met data augmentatie om het onevenwichtige dataprobleem op te lossen. Voor beide taken presteerde het MARBERT BERT-gebaseerde model met data augmentatie beter dan andere modellen met een verhoging van de F-score met 15% voor beide taken, wat de effectiviteit van onze aanpak laat zien.', 'de': 'In diesem Beitrag beschreiben wir unsere Bemühungen zur gemeinsamen Aufgabe von Sarkasmus und Sentiment Detection im Arabischen (Abu Farha et al., 2021). Die gemeinsame Aufgabe besteht aus zwei Unteraufgaben: Sarkasmus-Erkennung (Teilaufgabe 1) und Sentiment-Analyse (Teilaufgabe 2). Unsere Experimente basierten auf der Feinabstimmung von sieben BERT-basierten Modellen mit Datenauswertung, um das Problem der Ungleichgewichte zu lösen. Für beide Aufgaben übertraf das MARBERT BERT-basierte Modell mit Datenauswertung andere Modelle mit einer Erhöhung des F-Scores um 15% für beide Aufgaben, was die Effektivität unseres Ansatzes zeigt.', 'id': 'Dalam kertas ini, kami menggambarkan usaha kami untuk tugas bersama sarkasme dan deteksi perasaan dalam bahasa Arab (Abu Farha et al., 2021). Tugas berbagi terdiri dari dua sub-tugas: Deteksi Sarkasme (Subtask 1) dan Analisi Sentiment (Subtask 2). Eksperimen kami berdasarkan memperbaiki tujuh model berdasarkan BERT dengan peningkatan data untuk memecahkan masalah data yang tidak seimbang. Untuk kedua tugas, model berbasis MARBERT BERT dengan peningkatan data melampaui model lain dengan peningkatan skor F dengan 15% untuk kedua tugas yang menunjukkan efektif pendekatan kita.', 'ko': '본고에서 우리는 아랍어로 풍자와 정서 측정이라는 공통된 임무를 수행하려는 우리의 노력(Abu Farha 등, 2021년)을 묘사했다.공유 임무는 두 개의 하위 임무로 구성된다. 풍자 검측(하위 임무1)과 정서 분석(하위 임무2)이다.우리의 실험은 버트 기반의 7개 모델을 마이크로스피커로 조정하여 데이터 강화를 통해 데이터의 불균형 문제를 해결했다.이 두 가지 임무에 대해 마르버트의 데이터 증강 모델을 바탕으로 다른 모델보다 우수하고 두 임무의 F 점수가 15% 증가한 것은 우리 방법의 유효성을 나타낸다.', 'fa': 'در این کاغذ، ما تلاش\u200cهایمان را در کار مشترک سارکاسم و تشخیص احساسات به عربی (Abu Farha et al., 2021) توصیف می\u200cکنیم. وظیفه مشترک از دو وظیفه\u200cای است: شناسایی سارکاسم (زیر وظیفه ۱) و تحلیل مجموعه (زیر وظیفه ۲). آزمایشات ما بر اساس تنظیم کردن هفت مدل بنیاد BERT با افزایش داده\u200cها برای حل مشکل داده\u200cهای نابرانگیز بنیاد داشتند. برای هر دو وظیفه، مدل MARBERT BERT با افزایش داده\u200cها از مدل\u200cهای دیگر با افزایش امتیاز F به 15 درصد برای هر دو وظیفه که فعالیت دسترسی ما را نشان می\u200cدهد.', 'sw': 'Katika karatasi hii, tunaelezea jitihada zetu za kushirikiana na kazi za kejeli na uchunguzi wa hisia kwa Kiarabu (Abu Farha et al, 2021). Kazi hiyo ya kushirikiana ni pamoja na kazi mbili za subira: Utafiti wa Uamuzi (Ufanyakazi wa Uamuzi wa Uamuzi 1) na Uchambuzi wa Wakati (Ujumbe wa 2). Majaribio yetu yalitokana na mifano saba yenye msingi wa BERT yenye kuongeza data ili kutatua tatizo la taarifa zisizo na usawa. Kwa kazi zote mbili, muundo wa MARBERT BERT wenye kuongezeka kwa takwimu ulifanya mifano mingine na kuongezeka kwa vipindi vya F kwa asilimia 15 kwa kazi zote ambazo zinaonyesha ufanisi wa hatua yetu.', 'af': "In hierdie papier beskrywe ons versoek op die gedeelde taak van sarkasm en sentiment-opdekking in Arabiese (Abu Farha et al., 2021). Die gedeelde taak bestaan van twee sub- taak: Sarcasm Opdekking (Subtask 1) en Sentiment Analysis (Subtask 2). Ons eksperimente was gebaseer op fyn-tuning sewe BERT-gebaseerde modele met data augmentasie om die onbalanse data probleem te los. Vir beide opdragte het die MARBERT BERT-gebaseerde model met data augmentation uitgevoer ander modele met 'n vergroot van die F-score deur 15% vir beide opdragte wat die effektiviteit van ons toegang vertoon.", 'sq': 'Në këtë letër, ne përshkruajmë përpjekjet tona për detyrën e përbashkët të zbulimit të sarkazmit dhe ndjenjave në arabisht (Abu Farha et al., 2021). Detyra e përbashkët përbëhet nga dy nëndetyra: zbulimi i sarkazmit (nëndetyra 1) dhe analiza e ndjenjave (nëndetyra 2). Eksperimentet tona ishin bazuar në rregullimin e shtatë modeleve të bazuar në BERT me rritjen e të dhënave për të zgjidhur problemin e të dhënave të paekuilibruara. Për të dy detyrat, modeli i bazuar në MARBERT BERT me rritje të të dhënave kaloi modele të tjera me një rritje të pikës F me 15% për të dy detyrat që tregojnë efektshmërinë e qasjes sonë.', 'tr': 'Bu kagyzda biz özümizi sarkasm we duýgular tanyşyklaryň (Abu Farha et al., 2021). Paýlaşan zadyň iki sub-taskidir: Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). Bizim deneylerimiz BERT tabanly yedi tane taýýarlama modellerine daýanýar, hasaplanjak problemini çözmek üçin daýanýar. Iki işiň üçin, MARBERT BERT tabanly nusgasynda veri üýtgetmesi bilen başga nusgalary üstün etdi. Bu iki işiň üçin F-score artylygynyň 15%-den artylygyny bar we bu nusgasymyzyň etkinlik bardygyny görkezýär.', 'am': 'በዚህ ካላት፣ በዐረብኛ አቡ ፋርሐ እና አል 2021 በተካፈለው ስራ ላይ ተግባራችንን እናሳውቃለን፡፡ አዲስ ዶሴ ፍጠር ፈተናዎቻችን ባሕላዊው የዳታ መከራን ለመፍታት በ7 BERT-ተመሳሳይ ምሳሌዎች ላይ የተመሳሰሉ ናቸው፡፡ ለሁለቱ ስራዎች ማርብERT BERT-መሠረት የዳታ አካባቢ እና ሌሎችን ዓይነቶች በF-score በ15 በመቶው በሚያሳየው ሥርዓት የሥርዓታችንን ጥቅም የሚያሳየው ሥርዓት ነው፡፡', 'hy': "Այս թղթի մեջ մենք նկարագրում ենք մեր ջանքերը արաբերենով սարկազմի և զգացմունքների հայտնաբերման ընդհանուր խնդրի վրա (Աբու Ֆարա և այլն., 2021 թ․։ Համադրված խնդիրը կազմված է երկու ենթախնդիրներից՝ Սարկազմի հայտնաբերման (ենթախնդիր 1) և զգացմունքների վերլուծության (ենթախնդիր 2): Our experiments were based on fine-tuning seven BERT-based models with data augmentation to solve the imbalanced data problem.  Երկու առաջադրանքների համար, ՄարԲԵՌԹ ԲԵՌԹ-ի հիմնված մոդելը տվյալների աճի միջոցով արտադրեց այլ մոդելներ' F-գնահատականը 15 տոկոսով աճելով երկու առաջադրանքների համար, որոնք ցույց են տալիս մեր մոտեցումը արդյունավետությունը", 'bn': 'এই পত্রিকায় আমরা আরবী ভাষায় শেয়ার করা বিদ্রোহ এবং আবেগ আবিষ্কারের কাজের উপর আমাদের প্রচেষ্টা বর্ণনা করি (আবু ফারহা et al, ২০২১)। শেয়ার করা কাজের মধ্যে দুটি সাব-কাজের মধ্যে রয়েছে: সার্কাস্ম সনাক্ত (সাবকাজ ১) এবং সেন্টাইমেন্ট বিশ্লেষণ (সাবকাজ আমাদের পরীক্ষা ভিত্তিক ভিত্তিক সাতটি বিবেরেট ভিত্তিক মডেলের উপর ভিত্তি করেছিল যেখানে তথ্য বৃদ্ধি করা হয়েছিল, যা দুটো কাজের জন্য মার্বার্ট বার্ট ভিত্তিক মডেল, যার মাধ্যমে তথ্য বাড়ানোর মোডেল অন্যান্য মডেল প্রদর্শন করেছে যার ফলে এফ-স্কোর বৃদ্ধি হয়েছে ১৫', 'az': 'Bu kańüńĪzda, sarkasm v…ô sentiment keŇüfetm…ôsi bar…ôsind…ô √ßal ńĪŇümalarńĪmńĪzńĪ …ôr…ôb dilind…ô (Abu Farha et al., 2021). Bu paylaŇüńĪlmńĪŇü iŇü iki sub-task: Sarcasm Detection (Subtask 1) v…ô Sentiment Analysis (Subtask 2). Bizim eksperimentl…ôrimiz yeddi BERT tabanlńĪ modell…ôr…ô t…ômizl…ônm…ôk √ľ√ß√ľn veril…ôn m…ôlumat problemini √ß…ôkm…ôk √ľ√ß√ľn t…ômizl…ônm…ôy…ô dayandńĪ. ńįki iŇü √ľ√ß√ľn, MARBERT BERT-in modeli veri y√ľkselm…ôsi il…ô baŇüqa modell…ôrin F-score artńĪńüńĪnńĪ 15%-d…ôn artńĪrmańüńĪnńĪ g√∂st…ôrir.', 'ca': "En aquest article, descrivim els nostres esforços en la tasca compartida de la detecció del sarcasme i del sentiment en àrab (Abu Farha et al., 2021). La tasca compartida consisteix en dues sub-tasques: la detecció del sarcasme (Subtasca 1) i l'anàlisi del sentiment (Subtasca 2). Els nostres experiments van basar-se en ajustar set models basats en BERT amb augments de dades per resoldre el problema de dades desequilibrats. Per ambdues tasques, el model basat en MARBERT BERT amb augmentació de dades va superar altres models amb un increment de puntuació F en un 15% per ambdues tasques que demostren l'eficacia del nostre enfocament.", 'bs': 'U ovom papiru opisujemo svoje napore na zajedničkom zadatku sarkazma i otkrivanja osjećaja na arapskom (Abu Farha et al., 2021). Podijeljeni zadatak sastoji se od dva podzadataka: otkrivanje sarkasma (podzadatak 1) i analiza sentimenta (podzadatak 2). Naši eksperimenti su temeljeni na ispravnoj prilici sedam modela baziranih na BERT-u s povećanjem podataka kako bi riješili problem sa nelibanciranim podacima. Za obe zadatke, model na MARBERT BERT-u s povećanjem podataka iznosio je druge modele sa povećanjem F-rezultata za 15% za oba zadatka koji pokazuju učinkovitost našeg pristupa.', 'cs': 'V tomto článku popisujeme naše snahy o společný úkol detekce sarkasmu a sentimentů v arabštině (Abu Farha et al., 2021). Sdílený úkol se skládá ze dvou dílčích úkolů: detekce sarkasmu (podúkol 1) a analýza sentimentů (podúkol 2). Naše experimenty byly založeny na jemném ladění sedmi modelů založených na BERT s rozšířením dat pro řešení problému nevyvážených dat. U obou úkolů byl model založený na MARBERT BERT s rozšířením dat předčil ostatní modely se zvýšením F-skóre o 15% u obou úkolů, což ukazuje efektivitu našeho přístupu.', 'et': 'Käesolevas dokumendis kirjeldame oma jõupingutusi sarkasmi ja tundete avastamise jagatud ülesandel araabia keeles (Abu Farha et al., 2021). Ühisülesanne koosneb kahest alamülesandest: sarkasmi tuvastamine (alaülesanne 1) ja tunnete analüüs (alaülesanne 2). Meie eksperimendid põhinesid seitsme BERT-põhise mudeli täpsustamisel andmete suurendamisega tasakaalustamata andmeprobleemi lahendamiseks. Mõlema ülesande puhul ületas MARBERT BERT-põhine andmete suurendamisega mudel teisi mudeleid, suurendades F-skoori 15% võrra mõlema ülesande puhul, mis näitab meie lähenemisviisi efektiivsust.', 'fi': 'Tässä artikkelissa kuvailemme ponnistelujamme sarkasmin ja tunteiden havaitsemisen yhteisessä tehtävässä arabiaksi (Abu Farha et al., 2021). Jaettu tehtävä koostuu kahdesta alitehtävästä: Sarkasmin tunnistus (alitehtävä 1) ja Tunteanalyysi (alitehtävä 2). Kokeet perustuivat seitsemän BERT-pohjaisen mallin hienosäätöön datan augmentaatiolla epätasapainoisen dataongelman ratkaisemiseksi. Molemmissa tehtävissä MARBERT BERT-pohjainen datan lisäämiseen perustuva malli ylitti muut mallit lisäämällä F-pisteitä 15% molemmissa tehtävissä, mikä osoittaa toimintamme tehokkuuden.', 'ha': "Ga wannan karatun, Munã bayyana aikinmu a kan mãsu rabon aikin sarkasm da gane hisia'a cikin Larabci (Abu Farha et al, 2021). Ana haɗa aikin da suka haɗa shi na biyu mai aikin aiki: Sarcasm Kayan jarrabõyinmu sun kasance a kan tunkuɗe misãlai bakwai BERT-da, da wasu data da za'a sami cikin matabbata da ba'a daidaita ba. Ga duk aikin su biyu, misãlin MARBERT BERT da shirin ƙaranci da data na samar da wasu motel na daban da ya ƙara F-score da 15% ga duk aikin da ke nũna fikancin hanyarmu.", 'sk': 'V prispevku opisujemo naša prizadevanja pri skupni nalogi sarkazma in odkrivanja čustev v arabščini (Abu Farha et al., 2021). Skupno opravilo sestavljata dve podnalogi: zaznavanje sarkazma (podnaloga 1) in analiza čustev (podnaloga 2). Naši eksperimenti so temeljili na finem nastavitvi sedmih BERT modelov s povečanjem podatkov za reševanje problema neravnoteženih podatkov. Pri obeh nalogah je model, ki temelji na MARBERT BERT s povečanjem podatkov, presegel druge modele s povečanjem F-rezultata za 15% pri obeh nalogah, kar kaže na učinkovitost našega pristopa.', 'jv': 'Nang pepul iki, kéné rambarang nggawe wigatining kanggo nyelarani ning sarkasm karo al èh dumadhi sing luwih (Ab Faha et al, 2020). The share task comprs of Two Sub-tasks: Sarkasm detection (Subtask 1) and Sentiment Test (Subtask 2). Awakdhéwé éntuk dhéwé ngerasai pertama akeh saben nggawe barang BERT sampek dadi ampungan kanggo ngilangno kuwi ngregani kuwi nggawe data seneng pisan. Diwong langgambar sing dibenakake, model MARBERT BERT wis diangkat saben nggawe sistem dadi ampungan anyar, sing uwong ngegoleki model sing dibenakake kalalah sistem barêng lanjut sampek kotak 10% kanggo awak dhéwé sing paling dhéwé', 'he': 'בעיתון הזה, אנחנו מתארים את המאמצים שלנו על המשימה המשותפת של זיהוי סרקזם ומרגשות בערבית (Abu Farha et al., 2021). המשימה המשותפת מורכבת משני תחת משימות: גילוי סרקזם (תחת משימה 1) ואנליזה רגשות (תחת משימה 2). הניסויים שלנו היו מבוססים על שיפור 7 דוגמנים מבוססים על BERT עם שיפור נתונים כדי לפתור את בעיית הנתונים האזורים. For both tasks, the MARBERT BERT-based model with data augmentation outperformed other models with an increase of the F-score by 15% for both tasks which shows the effectiveness of our approach.', 'bo': 'འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོའི་སྐྱེས་ཆེན་དང་སེམས་ཚོར་བསམ་བློ་གཏོང་གི་བྱ་སྟངས་བཤད་ཀྱི་ཡོད། མཉམ་སྤྱོད་ཀྱི་ལས་འགུལ་དེ་ལས་གནད་དོན་གཉིས་ལས་ཀྱི་ནང་དོན་འདུག: Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་བཏོན་བཤེར་བྱེད་ཀྱི་ཐབས་ལམ་ལུགས་ཀྱིས་བཏོན་གཏོང་བའི་བྱ་ཚིག་ལ། For both tasks, the MARBERT BERT-based model with data augmentation outperformed other models with an increase of the F-score by 15% for both tasks which shows the effectiveness of our approach.'}
{'en': 'Multi-task Learning Using a Combination of Contextualised and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'ar': 'التعلم متعدد المهام باستخدام مزيج من تضمين الكلمات السياقية والثابتة لاكتشاف السخرية العربية وتحليل المشاعر', 'fr': "Apprentissage multitâche utilisant une combinaison d'intégration de mots contextualisés et statiques pour la détection du sarcasme arabe et l'analyse des sentiments", 'es': 'Aprendizaje multitarea mediante una combinación de incrustaciones de palabras contextualizadas y estáticas para la detección del sarcasmo árabe y el análisis de sentimientos', 'pt': 'Aprendizagem multitarefa usando uma combinação de incorporação de palavras contextualizadas e estáticas para detecção de sarcasmo árabe e análise de sentimentos', 'zh': '多任务学用上下文静词阿拉伯语刺检情析', 'ja': 'アラビア語の皮肉検出と感情分析のためのコンテキスト化された単語埋め込みと静的単語埋め込みの組み合わせを使用したマルチタスク学習', 'hi': 'अरबी व्यंग्य का पता लगाने और भावना विश्लेषण के लिए प्रासंगिक और स्थैतिक शब्द एम्बेडिंग के संयोजन का उपयोग करके बहु-कार्य सीखना', 'ru': 'Многозадачное обучение с использованием комбинации контекстуализированных и статических вложений слов для обнаружения арабского сарказма и анализа настроений', 'ga': 'Foghlaim Ilthasc Ag Úsáid Teaglaim de Leabú Focal Comhthéacsaithe agus Statach chun Sarcasm Araibis a Bhrath agus Anailís Mothúchán', 'ka': 'Multi task Learning Use a Combination of Contextualized and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'el': 'Μάθηση πολλαπλών εργασιών Χρησιμοποιώντας συνδυασμό περιεχομένων και στατικών ενσωμάτωσης λέξεων για ανίχνευση αραβικού σαρκασμού και ανάλυση συναισθημάτων', 'it': "Utilizzo di una combinazione di incorporazioni contestualizzate e statiche di parole per il rilevamento del sarcasmo arabo e l'analisi dei sentimenti", 'lt': 'Daugiaužduočių mokymasis naudojant kontekstinių ir statinių žodžių įrangų derinį arabų sarkazmo aptikimui ir jautrumo analizei', 'mk': 'Учење со повеќе задачи користејќи комбинација на контекстуални и статички вградувања на зборови за детективирање и анализа на чувствата на арапскиот сарказам', 'ml': 'അറബി സർക്കാസം ഡിറ്റീഷനും സെന്റിമെന്റ് അന്യായം ഉപയോഗിക്കുന്നതിനും കൂടുതല്\u200d ജോലി പഠിക്കുന്നു', 'kk': 'Көптеген тапсырмалар үйрену Араб сарказм анықтау және сезімді анализ үшін контекстуализацияланған және статистикалық сөздерді ендіру', 'mt': 'Tagħlim Multikompitu bl-Użu ta’ Kombinazzjoni ta’ Embeddings ta’ Kliem Kuntest u Statiċi għall-Iskopri u l-Analiżi tas-Sentiment tas-Sarkazmu Għarab', 'ms': 'Belajar-tugas berbilang Mengguna Kombinasi Penciptaan Kata Konteksual dan Statik untuk Pengesanan Sarkasma Arab dan Analisi Sentiment', 'mn': 'Олон даалгавар суралцах Сургууль Араб Саркассмын Тайлбар болон Сургууль Санжилт', 'hu': 'Többfeladatos tanulás kontextualizált és statikus szóbeágyazások kombinációjával arab szarkazmus felismeréséhez és érzelmek elemzéséhez', 'no': 'Fleiroppgåver- læring Bruk ein kombinasjon av kontekstualiserte og statistiske ord- innbygging for arabisk sarkasm- oppdaging og sentimentanalyser', 'si': 'Multi-Job ඉගෙනීම් සම්බන්ධ විශ්ලේෂණය සහ ස්ථිර වචන සම්බන්ධ විශ්ලේෂණය සඳහා අරාබික සාර්කාස්ම් පරීක්ෂණය සහ', 'so': 'Multi-task Learning Using a Combination of Contextualised and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'sv': 'Multi-task lärande med hjälp av en kombination av kontextualiserade och statiska ordinbäddningar för arabisk sarkasm detektering och känsloanalys', 'pl': 'Wielozadaniowe uczenie się za pomocą połączenia kontekstualizowanych i statycznych osadzeń słowa do wykrywania sarkazmu arabskiego i analizy sentymentów', 'ro': 'Învățare cu mai multe sarcini utilizând o combinație de încorporări de cuvinte contextualizate și statice pentru detectarea sarcasmului arab și analiza sentimentelor', 'sr': 'Višestruko učenje korištenje kombinacije kontekstualiziranih i statističkih reči za otkrivanje i analizu saosetljivosti arapskih sarkasma', 'ta': 'அரபி சார்காஸ்ம் கண்டுபிடிப்பு மற்றும் உணர்வு வார்த்தை உடைப்புகளுக்கான ஒரு சூழல் மற்றும் நிலையான வார்த்தையை பயன்படுத்த', 'ur': 'Multi-task Learning Using a Combination of Contextualized and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'uz': 'Arab Sarkasm aniqlash va Sentiment Analysis uchun katta vazifalar', 'vi': 'Trình giáo dục đa nhiệm vụ Sử dụng kết hợp các môi trường chữ viết và tĩnh mạch cho phát hiện tử thần nghe được', 'da': 'Multi-task læring ved hjælp af en kombination af kontekstualiserede og statiske ord indlejringer til arabisk sarkasme detektion og følelsesanalyse', 'bg': 'Многофункционално обучение с помощта на комбинация от контекстуализирани и статични вграждания на думи за откриване на арабски сарказъм и анализ на чувствата', 'nl': 'Multi-task leren met behulp van een combinatie van contextualiseerde en statische woordinsluitingen voor Arabische sarcasme detectie en sentimentanalyse', 'hr': 'Većina zadataka učenje korištenje kombinacije kontekstualiziranih i statističkih uključenja riječi za otkrivanje i analizu saosjetljivosti arapskih poremećaja', 'id': 'Belajar Multi-Tugas Menggunakan Kombinasi Penciptaan Kata Konteksual dan Statik untuk Deteksi Sarkasme Arab dan Analisi Sentiment', 'sw': 'Kusoma kazi nyingi kwa kutumia Miungano ya Kuzungumzwa na Hadithi ya Static kwa ajili ya Kuchunguza Kiarabu na Uchambuzi wa Wakati', 'de': 'Multi-Task-Lernen mit einer Kombination aus kontextualisierten und statischen Word-Einbettungen für arabische Sarkasmus-Erkennung und Stimmungsanalyse', 'tr': 'Multi-task Learning Use a Combination of Contextualized and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'ko': '어경화와 정적 단어 삽입을 결합하여 다중 임무 학습을 하여 아랍어 풍자 검측과 감정 분석에 사용한다', 'fa': 'یادگیری زیادی از استفاده از ترکیب کلمات متوسط و استفاده برای شناسایی و تحلیل سنتی عربی', 'sq': 'Mësimi me shumë detyra duke përdorur një kombinim të përfshirjeve të fjalëve kontekstuale dhe statike për zbulimin dhe analizën e ndjenjave të sarkazmit arab', 'af': "Veelvuldige taak leer deur te gebruik van 'n kombinasie van Konteksualiseerde en Statiese Woord Inbetering vir Arabiese Sarkasme Opdekking en Sentiment Analisie", 'hy': 'Բազմախնդիրներ սովորելը Արաբական սարկազմի հայտնաբերման և զգացմունքների վերլուծության համար կոնտեքստալիզացված և կայուն բառերի համադրման օգտագործելով', 'az': 'Multi-task Learning Using a Combination of Contextualized and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'am': 'Multi-task Learn using a Combination of Contextualised and Static Word Embedding for Arabic Sarcasm Detection and Sentiment Analysis', 'bs': 'Većina zadataka učenje korištenje kombinacije kontekstualiziranih i statističkih uključenja riječi za otkrivanje arapskih sarkasma i analizu sentimenta', 'bn': 'Multi-task Learning Using a Combination of Contextualised and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis', 'ca': "Aprendre multitasca utilitzant una combinació d'incorporacions de paraules contextualitzades i estátiques per detectar i analitzar el sarcasme àrab", 'cs': 'Víceúlohové učení pomocí kombinace kontextualizovaných a statických slovních vložení pro detekci arabského sarkasmu a analýzu sentimentů', 'et': 'Mitme ülesandega õppimine kontekstualiseeritud ja staatiliste sõnade manustamise kombinatsiooni abil araabia sarkasmi tuvastamiseks ja tunnete analüüsiks', 'fi': 'Monitehtäväoppiminen kontekstualisoitujen ja staattisten sanaupotusten yhdistelmällä arabian sarkasmin havaitsemiseen ja tunteiden analysointiin', 'ha': 'KCharselect unicode block name', 'jv': 'Multi-task Learning Using a combbintion of contextual and Statc Word embedding for Hebrew Sarkasm detection and Sentiment Test', 'sk': 'Večopravilno učenje s kombinacijo kontekstualiziranih in statičnih besednih vdelav za zaznavanje arabskega sarkazma in analizo čustev', 'he': 'ללמוד במשימות רבות בשימוש שילוב של שילובים מילים קונטקסטיים וסטטיים', 'bo': 'Multi-task Learning Using a Combination of Contextualized and Static Word Embeddings for Arabic Sarcasm Detection and Sentiment Analysis'}
{'en': 'Sarcasm detection and sentiment analysis are important tasks in Natural Language Understanding. Sarcasm is a type of expression where the sentiment polarity is flipped by an interfering factor. In this study, we exploited this relationship to enhance both tasks by proposing a multi-task learning approach using a combination of static and contextualised embeddings. Our proposed system achieved the best result in the sarcasm detection subtask.', 'es': 'La detección del sarcasmo y el análisis de sentimientos son tareas importantes en la comprensión del lenguaje natural. El sarcasmo es un tipo de expresión en la que la polaridad del sentimiento es cambiada por un factor de interferencia. En este estudio, aprovechamos esta relación para mejorar ambas tareas al proponer un enfoque de aprendizaje multitarea mediante una combinación de incrustaciones estáticas y contextualizadas. Nuestro sistema propuesto logró el mejor resultado en la subtarea de detección de sarcasmo.', 'ar': 'يعد اكتشاف السخرية وتحليل المشاعر من المهام المهمة في فهم اللغة الطبيعية. السخرية هي نوع من التعبير حيث تنقلب قطبية المشاعر بواسطة عامل تداخل. في هذه الدراسة ، استغلنا هذه العلاقة لتعزيز كلتا المهمتين من خلال اقتراح نهج تعلم متعدد المهام باستخدام مزيج من حفلات الزفاف الثابتة والسياقية. حقق نظامنا المقترح أفضل نتيجة في المهمة الفرعية للكشف عن السخرية.', 'pt': 'A detecção de sarcasmo e a análise de sentimentos são tarefas importantes no Natural Language Understanding. O sarcasmo é um tipo de expressão em que a polaridade do sentimento é invertida por um fator interferente. Neste estudo, exploramos essa relação para aprimorar ambas as tarefas, propondo uma abordagem de aprendizagem multitarefa usando uma combinação de embeddings estáticos e contextualizados. Nosso sistema proposto obteve o melhor resultado na subtarefa de detecção de sarcasmo.', 'fr': "La détection des sarcasmes et l'analyse des sentiments sont des tâches importantes dans la compréhension du langage naturel. Le sarcasme est un type d'expression où la polarité des sentiments est inversée par un facteur d'interférence. Dans cette étude, nous avons exploité cette relation pour améliorer les deux tâches en proposant une approche d'apprentissage multitâche utilisant une combinaison d'intégrations statiques et contextualisées. Le système que nous avons proposé a obtenu le meilleur résultat dans la sous-tâche de détection des sarcasmes.", 'ja': '皮肉検出と感情分析は、自然言語理解の重要なタスクです。皮肉は、感情の極性が干渉因子によってひっくり返される表現の一種です。この研究では、静的埋め込みとコンテキスト化された埋め込みの組み合わせを使用したマルチタスク学習アプローチを提案することにより、この関係を利用して両方のタスクを強化しました。私たちの提案したシステムは、皮肉検出サブタスクで最高の結果を達成しました。', 'zh': '刺刺检情,自然语言解之要务也。 刺刺一表达方式,情两极性扰因翻。 于此论之,吾等用此,以一用静,以销多任务学,以增二务。 我们系统在刺检测子中取了最佳效。', 'ru': 'Обнаружение сарказма и анализ чувств являются важными задачами в понимании естественного языка. Сарказм - это тип выражения, при котором полярность настроения перевернута мешающим фактором. В этом исследовании мы использовали эту связь для улучшения обеих задач, предлагая многозадачный подход к обучению с использованием комбинации статических и контекстуализированных вложений. Наша предлагаемая система достигла наилучшего результата в подзадаче обнаружения сарказма.', 'hi': 'व्यंग्य का पता लगाने और भावना विश्लेषण प्राकृतिक भाषा समझ में महत्वपूर्ण कार्य हैं। व्यंग्य एक प्रकार की अभिव्यक्ति है जहां भावना ध्रुवीयता को एक हस्तक्षेप कारक द्वारा फ़्लिप किया जाता है। इस अध्ययन में, हमने स्थैतिक और प्रासंगिक एम्बेडिंग के संयोजन का उपयोग करके एक बहु-कार्य सीखने के दृष्टिकोण का प्रस्ताव करके दोनों कार्यों को बढ़ाने के लिए इस संबंध का शोषण किया। हमारे प्रस्तावित प्रणाली व्यंग्य का पता लगाने subtask में सबसे अच्छा परिणाम प्राप्त किया.', 'ga': 'Is tascanna tábhachtacha iad braite searbhas agus anailís ar mheon i dTuisceana Teanga Nádúrtha. Is cineál slonn é searbhas ina ndéantar polaraíocht na meon a smeach trí fhachtóir trasnaíochta. Sa staidéar seo, bhaineamar leas as an ngaol seo chun an dá thasc a fheabhsú trí chur chuige foghlama ilthasc a mholadh ag baint úsáide as meascán de leabaithe statacha agus comhthéacsúla. Bhain ár gcóras beartaithe an toradh ab fhearr amach san fhothasc braite searbhas.', 'ka': 'საპრაკაზმის განახლება და სენტიმენტის ანალიზია მნიშვნელოვანი დავალება ჩემი ენერგიის განსხვავებაში. სერკაზმი არის სხვა გამოსახულების ტიპი, სადაც სენტიმენტის პოლიტურობა ინტერფერენტის ფაქტორიდან გადატვირდება. ამ კვლევაში, ჩვენ გამოვიყენეთ ეს პრობლემა, რომელიც ორივე დავალების უფრო მეტი დავალების სწავლების პრობლემა გამოყენებული სტატიკალური და კონტექსტუალური კომბიუნცი ნაქარა ოპვეოჲლადანა ჟთჟრვმა ეჲჟრигნა ნაი-ეჲბპთწრ პვჱსლრ გ ჟყპკაჱმა ევრვკუთწ.', 'hu': 'A szarkazmus felismerése és az érzelmek elemzése fontos feladat a természetes nyelv megértésében. A szarkazmus egy olyan kifejezéstípus, ahol az érzelmi polaritást egy zavaró tényező fordítja meg. Ebben a tanulmányban ezt a kapcsolatot arra használtuk ki, hogy mindkét feladatot erősítsük azáltal, hogy többfeladatos tanulási megközelítést javasolunk statikus és kontextuális beágyazások kombinációjával. Javasolt rendszerünk a legjobb eredményt érte el a szarkazmus detektálásában.', 'it': "Il rilevamento del sarcasmo e l'analisi del sentiment sono compiti importanti nella comprensione del linguaggio naturale. Il sarcasmo è un tipo di espressione in cui la polarità sentimentale è capovolta da un fattore interferente. In questo studio, abbiamo sfruttato questa relazione per migliorare entrambi i compiti proponendo un approccio di apprendimento multi-task utilizzando una combinazione di incorporazioni statiche e contestualizzate. Il nostro sistema proposto ha ottenuto il miglior risultato nel sottotask di rilevamento del sarcasmo.", 'el': 'Η ανίχνευση σαρκασμού και η ανάλυση συναισθημάτων είναι σημαντικά καθήκοντα στην κατανόηση της φυσικής γλώσσας. Ο σαρκασμός είναι ένας τύπος έκφρασης όπου η πολικότητα των συναισθημάτων αντιστρέφεται από έναν παρεμβατικό παράγοντα. Στην παρούσα μελέτη, αξιοποιήσαμε αυτή τη σχέση για να ενισχύσουμε και τις δύο εργασίες προτείνοντας μια προσέγγιση μάθησης πολλαπλών εργασιών χρησιμοποιώντας έναν συνδυασμό στατικών και πλαισιωμένων ενσωμάτωσης. Το προτεινόμενο σύστημά μας πέτυχε το καλύτερο αποτέλεσμα στην υποεργασία ανίχνευσης σαρκασμού.', 'lt': 'Sarkazmo aptikimas ir jausmų analizė yra svarbios užduotys suprantant natūralią kalbą. Sarkazmas yra išraiškos tipas, kai jautrumo poliarumą sukelia trukdantis veiksnys. Šiame tyrime pasinaudojome šiais santykiais, kad sustiprintume abi užduotis, pasiūlydami daugiafunkcinį mokymosi metodą, naudojant statinių ir kontekstinių integracijų derinį. Mūsų siūloma sistema pasiekė geriausią rezultatą sarkazmo nustatymo subtaskaitoje.', 'mk': 'Детектирањето на сарказмот и анализата на чувствата се важни задачи во разбирањето на природниот јазик. Sarcasm is a type of expression where the sentiment polarity is flipped by an interfering factor.  Во оваа студија, го искористивме овој однос за да ги зајакнеме двете задачи со предложување на пристап на учење со мултизадачи користејќи комбинација на статички и контекстуални вградувања. Нашиот предложен систем го постигна најдобриот резултат во подпрашањето за детекција на сарказмот.', 'ml': 'സാർക്കാസം കണ്ടുപിടിക്കുകയും സാധാരണ ഭാഷയിലെ പ്രധാനപ്പെട്ട ജോലികളാണ്. സർക്കാസം ഒരു തരം പ്രഭാഷണമാണ്. അവിടെ വിചാരപ്രശ്നം തടസ്സപ്പെടുത്തുന്ന ഒരു ഫാക്ടറിനാലാണ്. ഈ പഠനത്തില്\u200d നമ്മള്\u200d രണ്ടു ജോലികള്\u200dക്കും മെച്ചപ്പെടുത്താന്\u200d ഈ ബന്ധം ഉപയോഗിച്ചു. ഒരു സ്റ്റാറ്റിക്ക് സ്റ്റാസ്റ്റിക്ക് വിവരങ്ങള്\u200d  നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട സിസ്റ്റത്തിന്റെ പരിചയപ്പെട്ടതിന്റെ ഏറ്റവും നല്ല ഫലം എത്തി.', 'mt': 'L-identifikazzjoni tas-sarkazmu u l-analiżi tas-sentimenti huma kompiti importanti fil-Ftehim tal-Lingwa Naturali. Is-sarkasmu huwa tip ta’ espressjoni fejn il-polarità tas-sentiment tinqaleb minn fattur li jinterferixxi. F’dan l-istudju, a ħna sfruttajna din ir-relazzjoni biex insaħħu ż-żewġ kompiti billi pproponejna approċċ ta’ tagħlim b’diversi kompiti bl-użu ta’ kombinazzjoni ta’ inkorporazzjonijiet statiċi u kuntestwalizzati. Is-sistema proposta tagħna kisbet l-aħjar riżultat fis-sottotalba għall-individwazzjoni tas-sarkazmu.', 'ms': 'Pengesanan sarkasme dan analisis perasaan adalah tugas penting dalam Pemahaman Bahasa Alami. Sarkasme adalah jenis ungkapan di mana polariti perasaan diputar oleh faktor yang mengganggu. Dalam kajian ini, kami mengeksploitasi hubungan ini untuk meningkatkan kedua-dua tugas dengan melaporkan pendekatan pembelajaran berbilang-tugas menggunakan kombinasi penyambungan statik dan kontekstualisasi. Sistem kami yang diusulkan mencapai keputusan terbaik dalam subtanya pengesan sarkasma.', 'kk': 'Сарказм анықтау және сезімдік анализ - табиғи тіл түсінімінде маңызды тапсырмалар. Саркассм - сезімдік поляриясы интерфейс факторынан аударылған өрнегінің түрі. Бұл зерттеулерде, көптеген тапсырмаларды бірнеше тапсырма оқыту арқылы статикалық және контекстуалды ендіруді қолдану үшін бұл қатынасды қолдандық. Біздің қолданыстағы жүйеміз сарказмды анықтау суретінің ең жақсы нәтижесін жеткізді.', 'pl': 'Wykrywanie sarkazmu i analiza sentymentów to ważne zadania w rozumieniu języka naturalnego. Sarkazm jest rodzajem wyrażenia, w którym polaryzacja sentymentów jest przewracana przez czynnik ingerujący. W niniejszym badaniu wykorzystaliśmy tę relację do wzmocnienia obu zadań, proponując wielozadaniowe podejście do uczenia się z wykorzystaniem połączenia statycznych i kontekstowych osadzeń. Nasz zaproponowany system osiągnął najlepszy wynik w podzadaniu wykrywania sarkazmu.', 'ro': 'Detectarea sarcasmului și analiza sentimentului sunt sarcini importante în înțelegerea limbajului natural. Sarcasmul este un tip de expresie în care polaritatea sentimentului este răsturnată de un factor care interferează. În acest studiu, am exploatat această relație pentru a îmbunătăți ambele sarcini, propunând o abordare de învățare multi-task folosind o combinație de încorporări statice și contextualizate. Sistemul nostru propus a obținut cel mai bun rezultat în subsarcina detectării sarcasmului.', 'si': 'සාර්කාස්ම් පරීක්ෂණය සහ හැඟීම් විශ්ලේෂණය සාමාන්\u200dය භාෂාව තේරුම් ගන්නේ වැදගත් වැඩක්  සාර්කාස්ම් තමයි ප්\u200dරකාරයක් තමයි කියලා හිතන්න ප්\u200dරකාරයක් තියෙන්නේ කියලා මේ පරීක්ෂණයේදී, අපි මේ සම්බන්ධය ප්\u200dරයෝජනය කරලා දෙන්නම් වැඩ කරන්න ක්\u200dරියාවක් විශ්වාස කරලා ගොඩක් වැඩි වැඩි වැඩි වැඩි ව අපේ පද්ධතියේ සැර්කාස්ම් පරීක්ෂණයේ හොඳම ප්\u200dරතිචාරයක් ලැබුනා.', 'no': 'Oppdaging av sarkasm og sentimentanalyser er viktige oppgåver i naturspråk forståking. Sarkasm er eit type uttrykk der sentimentpolariteten blir flytta av ein grensefaktor. I denne studien brukte vi denne forholdet for å forbetra begge oppgåver ved å foreslå ein fleire oppgåver læringstilnærming med kombinasjon av statiske og kontekstualiserte innbygging. Vårt foreslått systemet har oppnådd den beste resultatet i underspørjinga for oppdaging av sarkasm.', 'so': 'Baaritaanka sarcasm iyo baaritaanka fikradu waa shaqooyin muhiim ah oo ku qoran waxyaabaha garashada afka dabiiciga ah. Sarkasm waa nooc u eg expression, taasoo ay ku leedahay xaalad iskujeedo. Waxbarashadan, waxaan ku isticmaalnay xiriirkaas si aan u kordhino labada shaqaalaha, si aan u soo jeedinno qaab waxbarasho badan oo lagu isticmaalo qalabka lagu soo bandhigayo static iyo la soo jeeday. nidaamka la soo jeeday wuxuu gaadhay arimaha ugu wanaagsan oo lagu soo ogaado sarkaanka.', 'sr': 'Detekcija sarkazma i analiza sentimenta su važni zadatak u razumijevanju prirodnog jezika. Sarkazam je vrsta izraza u kojem je polarnost sentiment a preokrenuta faktorom miješanja. U ovoj studiji smo iskoristili ovu vezu kako bi poboljšali obe zadatke predložili pristup multizadatka učenja koristeći kombinaciju statičnih i kontekstualiziranih integracija. Naš predloženi sistem je postigao najbolji rezultat u podpitanju detekcije sarkazma.', 'ta': 'சார்காஸ்ம் கண்டுபிடிப்பு மற்றும் உணர்வு ஆய்வு இயல்பான மொழி புரிந்து கொள்ள முக்கியமான பணிகள். Sarcasm is a type of expression where the sentiment polarity is flipped by an interfering factor. இந்த ஆராய்ச்சியில், நாங்கள் இரு பணிகளையும் மேம்படுத்த இந்த உறவை பயன்படுத்தினோம் பல பணிகள் கற்றுக் கொள்ளும் முறையை பயன்படுத்தினோம் ஒரு  எங்கள் பரிந்துரைக்கப்பட்ட கண்டுபிடிப்பு துணை பணியில் சிறந்த முடிவு அடைந்தது.', 'ur': 'Sarcasm detection and sentiment analysis are important tasks in Natural Language Understanding. سارکاسم ایک طرح کا اثر ہے جہاں احساس پالیٹی ایک اثرات کے ذریعہ اڑاتی ہے. اس مطالعہ میں ہم نے اس رابطہ کو استعمال کیا کہ دونوں کاموں کو زیادہ کر دیں اور ایک بہت سے کام کی تعلیم کا طریقہ پیش کریں کہ ایک ایستی اور متوسط مطالعہ کی ترکیب کے مطالعہ سے ملے۔ ہماری پیشنهاد سیسٹم نے sarcasm detection subtask میں بہترین نتیجہ پہنچا۔', 'mn': 'Өвчний хэл ойлголтын тухай сэтгэл санааны шинжилгээ нь байгалийн хэл ойлголтын чухал ажил юм. Саркассм бол сэтгэл хөдлөл хөдлөл хөдлөл үүсгэдэг хэлбэрээр илэрхийлэл юм. Энэ судалгаанд бид хоёр даалгаварыг нэмэгдүүлэхэд олон даалгаварын суралцах арга замыг ашиглаж, статистик болон орчин үеийн холбоотой холбоотой холбоотой холбоотой. Бидний санал өгсөн систем саркассмын нээлтийн хамгийн сайн үр дүн гарсан.', 'sv': 'Sarkasm detektering och sentimentalanalys är viktiga uppgifter i Natural Language Understanding. Sarkasm är en typ av uttryck där sentimentpolariteten vänds av en störande faktor. I denna studie utnyttjade vi denna relation för att förbättra båda uppgifterna genom att föreslå en multi-task inlärningsmetod med en kombination av statiska och kontextuella inbäddningar. Vårt föreslagna system uppnådde det bästa resultatet i underuppgiften för sarkasm detektering.', 'uz': "Sarkasm aniqlash va hissiyotni aniqlash asosiy tildagi muhim vazifalar. Sarkasm - hisob polariyati interference factor orqali o'zgartiradi. Bu taʼminotda, biz ikkita vazifalarni oshirish uchun ushbu munosabatlarni ko'proq vazifa o'rganish usulini tashkilotni o'rganish orqali bir necha vazifa o'rganish muvaffaqiyatlarini foydalanishimiz mumkin. Bizning talab qilingan tizimmiz sarkasm qidirish muvaffaqiyatlariga eng yaxshi natijaga erishildi.", 'vi': 'Âm tiết và phân tích tình cảm là những nhiệm vụ quan trọng trong hiểu biết ngôn ngữ tự nhiên. Âm điệu là một dạng biểu tượng mà cực tinh thần tình cảm bị đảo lộn bởi một nhân tố cản trở. Trong nghiên cứu này, chúng tôi tận dụng mối quan hệ này để tăng cường hai nhiệm vụ bằng cách đề xuất một phương pháp học tập đa nhiệm vụ, sử dụng một sự kết hợp giữa các tình huống. Hệ thống chúng tôi đề nghị đạt được kết quả tốt nhất trong âm mưu phát hiện mỉa mai.', 'hr': 'Detekcija bolesti i analiza osjećaja su važni zadatak u razumijevanju prirodnog jezika. Sarkazam je vrsta izraza u kojem se polarnost osjećaja pretvara faktor miješanja. U ovom ispitivanju, iskoristili smo taj odnos kako bi poboljšali obe zadatke predložili pristup multizadatka učenja koristeći kombinaciju statičnih i kontekstualiziranih integracija. Naš predloženi sustav postigao je najbolji rezultat u podpitanju otkrivanja sarkazma.', 'nl': 'Sarcasme detectie en sentimentanalyse zijn belangrijke taken in Natural Language Understanding. Sarcasme is een vorm van expressie waarbij de sentimentpolariteit wordt omgedraaid door een interfererende factor. In deze studie gebruikten we deze relatie om beide taken te verbeteren door een multitask leeraanpak voor te stellen met behulp van een combinatie van statische en contextualiseerde embeddings. Ons voorgestelde systeem behaalde het beste resultaat in de sarcasme detectie subtaak.', 'de': 'Sarkasmus-Erkennung und Stimmungsanalyse sind wichtige Aufgaben im Natural Language Understanding. Sarkasmus ist eine Ausdrucksform, bei der die Polarität der Gefühle durch einen Störfaktor umgedreht wird. In dieser Studie nutzten wir diese Beziehung aus, um beide Aufgaben zu verbessern, indem wir einen Multi-Task-Lernansatz vorschlugen, der eine Kombination aus statischen und kontextualisierten Einbettungen verwendet. Unser vorgeschlagenes System erzielte das beste Ergebnis in der Sarkasmus-Detektion Teilaufgabe.', 'da': 'Sarkasme detektion og sentimentalanalyse er vigtige opgaver i Natural Language Forståelse. Sarkasme er en type udtryk, hvor følelsespolariteten vendes af en forstyrrende faktor. I denne undersøgelse udnyttede vi dette forhold til at forbedre begge opgaver ved at foreslå en multi-task learning tilgang ved hjælp af en kombination af statiske og kontekstualiserede indlejringer. Vores foreslåede system opnåede det bedste resultat i sarkasme detektion subtask.', 'bg': 'Откриването на сарказма и анализа на сантимента са важни задачи в разбирането на естествения език. Сарказмът е вид израз, при който полярността на сантимента се обръща от интерферентен фактор. В това проучване ние използваме тази връзка, за да подобрим и двете задачи, като предложим подход за обучение с множество задачи, използвайки комбинация от статични и контекстуализирани вграждания. Нашата предложена система постигна най-добрия резултат в подзадачата за откриване на сарказъм.', 'fa': 'شناسایی و تحلیل احساسات دریافت زبان طبیعی مهم هستند. سارکاسم یک نوع عبارت است که قطعیت احساسات توسط یک faktor interference تغییر می\u200cدهد. در این مطالعه، ما این رابطه را استفاده کردیم تا هر دو کار را با پیشنهاد یک روش یادگیری چندین کار با استفاده از ترکیب ترکیب استفاده از ترکیب پیوندهای استاندازی و موقعیت استفاده کنیم. سیستم پیشنهاد ما بهترین نتیجه\u200cای در آشکار سارکاسم رسید.', 'ko': '풍자 검측과 감정 분석은 자연 언어 이해의 중요한 임무이다.풍자는 감정이 극성적으로 방해 요소에 의해 뒤집히는 표현 방식이다.본 연구에서 우리는 이러한 관계를 이용하여 정적 삽입과 상황 삽입을 결합한 다중 임무 학습 방법을 제시하여 이 두 가지 임무를 강화했다.우리가 제시한 시스템은 풍자 검출 서브 임무에서 가장 좋은 효과를 거두었다.', 'sw': 'Ugunduzi wa sera na uchambuzi wa hisia ni kazi muhimu katika ufahamu wa lugha ya asili. Uchaguzi ni aina ya kujieleza ambapo hisia za uchaguzi hugeuzwa na sababu ya kuingilia kati. Katika utafiti huu, tulitumia uhusiano huu wa kuongeza kazi zote kwa kupendekeza mbinu za kujifunza za kazi nyingi kwa kutumia muunganiko wa viungo vya takwimu na vifaa vinavyochanganyika. Our proposed system achieved the best result in the sarcasm detection subtask.', 'tr': 'Sarkasm deteksiýasy we duýgular analizi tebigy dil düşünmesinde wajyp zadlar. Sensiýal polaritet bir faýl edip, ol ýerde görnöşim faktör tarapyndan çalşyrlýar. Bu araşdyrmada biz bu temasyny statik we contextualizalýan integralaryň birleşigini ulanarak, her iki zady hem köp-täblik öwrenmek üçin ulandyk. Biziň teklip eden sistemamyz sarkasy deteksiyonyň astynyň iň gowy netijesini ýetdi.', 'af': "Sarkasme opdekking en sentimentanalisie is belangrike taak in Natuurlike Taal Verstaan. Sarkasme is 'n tipe uitdrukking waar die sentiment polariteit deur 'n interferende faktor omgedraai word. In hierdie studie het ons hierdie verwanting gebruik om beide taak te verbeter deur 'n multi-taak leer toegang te voorstel deur 'n kombinasie van statiese en contextualiseerde inbêdings te gebruik. Ons voorgestelde stelsel het die beste resultaat van die sarkasme-opdekking ondersoek.", 'id': 'Deteksi sarkasme dan analisis sentimen adalah tugas penting dalam Bahasa Alami Memahami. Sarkasme adalah jenis ekspresi di mana polaritas sentimen diputar oleh faktor yang mengganggu. In this study, we exploited this relationship to enhance both tasks by proposing a multi-task learning approach using a combination of static and contextualised embeddings.  Sistem kami yang diusulkan mencapai hasil terbaik dalam deteksi sarkasme subtask.', 'hy': "Sarcasm detection and sentiment analysis are important tasks in Natural Language Understanding.  Սարկազմը մի տեսակ արտահայտություն է, որտեղ զգացմունքների մոտավորությունը շրջվում է ներխուժող գործոնի կողմից: Այս ուսումնասիրության ընթացքում մենք օգտագործեցինք այս հարաբերությունը երկու խնդիրներին բարելավելու համար, առաջարկելով բազմախնդիրների ուսումնասիրության մոտեցում' օգտագործելով վիճակական և կոնտեքստալիզացված ներդրումների համադրություն: Մեր առաջարկած համակարգը հասավ լավագույն արդյունքին սարկազմի հայտնաբերման ենթահարցում:", 'am': 'የሳርካሲ ግለጽ እና የስሜት ማስታወቂያው በአዳራዊ ቋንቋ ማስታወቂያ የግልጾች ስራዎችን ናቸው፡፡ ሰርካሲም የስሜት ርኵሰት በመግገዛት የሚነካው አካባቢ ነው፡፡ በዚህ ትምህርት ውስጥ፣ ይህንን ግንኙነት ሁለትን ስራ ለማድረግ የብዙ ስራ ትምህርት መግለጫ በጥቅምት እና በተጨማሪው አካባቢዎችን በመጠቀም ነው፡፡ የተዘጋጀው ስርዓታችን የሳርካም አቀናቢ ጉዳይ የተሻለ ፍሬ አግኝቷል፡፡', 'sq': 'Zbulimi i sarkazmit dhe analiza e ndjenjave janë detyra të rëndësishme në kuptimin e gjuhës natyrore. Sarkazmi është një lloj shprehjeje ku polariteti i ndjenjave kthehet nga një faktor ndërhyrës. Në këtë studim, ne e shfrytëzuam këtë marrëdhënie për të përmirësuar të dy detyrat duke propozuar një metodë mësimi me shumë detyra duke përdorur një kombinim të përfshirjeve statike dhe kontekstuale. Sistemi ynë i propozuar arriti rezultatin më të mirë në nënpyetjen e zbulimit të sarkazmit.', 'az': 'Sarkasm keşif və sentiment analizi təbiətli dil anlayışında mövcuddur. Sarkasm bir ifadədir ki, sentiment polarisi bir interferens faktörü tarafından dəyişdirildir. Bu təhsil içində, biz bu ilişkisini statik və contextualized inşallarının birləşdirilməsini istifadə etmək üçün hər ikisini daha yaxşılaşdırdıq. Bizim təbliğ etdiyimiz sistemimiz sarkasm keşfetməsinin ən yaxşı nəticəsini başa düşdü.', 'bn': 'সার্কাস্ম আবিষ্কার এবং আবেগ বিশ্লেষণ প্রাকৃতিক ভাষায় গুরুত্বপূর্ণ কাজ। Sarcasm is a type of expression where the emotion polarity is flipped by a intercepting factor. এই গবেষণায় আমরা এই সম্পর্ক ব্যবহার করেছি দুটো কাজের বাড়িয়ে দিতে যাচ্ছি একটি স্টেটিক এবং প্রতিযোগিতা ব্যবহার করে বহুকাজের শিক্ষা পদক্ষেপ আমাদের প্রস্তাবিত সিস্টেম বিদ্রোহীদের সনাক্তির সাবক্ষেত্রে সবচেয়ে ভাল ফলাফল অর্জন করেছে।', 'bs': 'Detekcija sarkazma i analiza osjećanja su važni zadatak u razumijevanju prirodnog jezika. Sarkazam je vrsta izraza u kojem je polarnost osjećaja preokrenuta faktorom miješanja. U ovoj studiji smo iskoristili ovu vezu kako bi poboljšali obe zadatke predložili pristup multizadatka učenja koristeći kombinaciju statičnih i kontekstualiziranih integracija. Naš predloženi sistem je postigao najbolji rezultat u podpitanju detekcije sarkazma.', 'ca': "La detecció del sarcasme i l'anàlisi del sentiment són tasques importants en la comprensió del llenguatge natural. Sarcasm is a type of expression where the sentiment polarity is flipped by an interfering factor.  En aquest estudi, vam aprofitar aquesta relació per millorar les dues tasques proposant un enfocament d'aprenentatge multitascat utilitzant una combinació d'integracions estatiques i contextualitzades. El nostre sistema proposat va aconseguir el millor resultat en la subpregunta de detecció del sarcasme.", 'et': 'Sarkasmi tuvastamine ja sentimentaalne analüüs on loodusliku keele mõistmise olulised ülesanded. Sarkasm on tüüpi väljendus, kus sentimentaalset polaarsust pöörab segav faktor. Selles uuringus kasutasime seda seost mõlema ülesande täiustamiseks, pakkudes välja mitme ülesandega õppimise lähenemisviisi, kasutades kombinatsiooni staatilistest ja kontekstipõhistest manustamistest. Meie pakutud süsteem saavutas parima tulemuse sarkasmi tuvastamise alamülesandes.', 'fi': 'Sarkasmin havaitseminen ja tunteiden analysointi ovat tärkeitä tehtäviä luonnollisen kielen ymmärtämisessä. Sarkasmi on eräänlainen ilmaisu, jossa tunteiden polariteettia kääntää häiritsevä tekijä. Tässä tutkimuksessa hyödynsimme tätä suhdetta molempien tehtävien tehostamiseksi ehdottamalla monitehtäväoppimista staattisen ja kontekstuaalisen upotuksen yhdistelmällä. Ehdotettu järjestelmä saavutti parhaan tuloksen sarkasmin havaitsemisen alatehtävässä.', 'cs': 'Detekce sarkasmu a analýza sentimentů jsou důležitými úkoly v porozumění přirozenému jazyce. Sarkasmus je druh výrazu, kdy polarita sentimentu je převrácena rušivým faktorem. V této studii jsme tento vztah využili k posílení obou úkolů navržením multi-úlohového učení kombinací statických a kontextualizovaných vložení. Náš navržený systém dosáhl nejlepšího výsledku v podúkolu detekce sarkasmu.', 'jv': 'Rasané awak dhéwé karo Sensitif kuwi basa sing dikarepaké ning Kasama Ingkang Daerahing. Mi Nang barêng-barêng iki, kéné gênggunaké iki aturan kanggo nglanggar nggawe tasks iki dadi supoyo layar multi-task öyenge kuwi nggawe komunikasi karo statik lan contextual embedding. Sistem awak dhéwé ngerasah sing paling dhéwé ning acara dadi sabanjuré karo dolanan karo sarkas.', 'ha': "Ana gane Sarkasm da Ana yi wa aikin muhimma cikin Lugha Kiasala. Sarkasm yana da wata magana wadda aka buɗe surori na hisani da wani fakta mai intercewa. A cikin wannan littafin, mun yi amfani da wannan mazauni dõmin ya ƙara wa aikin dukansu da za'a buƙata wata hanyor wa lũra masu yawa da za'a yi amfani da komkoma da mataimaki da wanda aka samirta. Tsarinmu da aka tuna ya sãmu mafi kyaun matsayi a cikin jarrabin sarki.", 'sk': 'Odkrivanje sarkazma in analiza čustva sta pomembna naloga v razumevanju naravnega jezika. Sarkazem je vrsta izraza, kjer polarnost sentimenta obrne moteči faktor. V tej študiji smo izkoristili ta odnos za izboljšanje obeh nalog s predlogom večopravilnega učenja s kombinacijo statičnih in kontekstualnih vdelav. Naš predlagani sistem je dosegel najboljši rezultat v podnalogi za odkrivanje sarkazma.', 'he': 'גילוי סרקזם וניתוח רגשות הם משימות חשובות בהבנה של שפת טבעית. סרקזם הוא סוג של ביטוי שבו הקוטב של הרגשות הופך על ידי גורם מפריע. במחקר הזה ניצלנו את מערכת היחסים הזו כדי לשפר את שני המשימות על ידי הצעה גישה ללמוד במשימות רבות בשימוש שילוב של תוכניות סטטיות וקונטליזציות. המערכת המוצעת שלנו השיגה את התוצאה הטובה ביותר בתשומת זיהוי הסרקזם.', 'bo': 'མདུན་ཤུགས་རྟོགས་དང་སེམས་ཚོར་ཞིབ་ནི་རང་བཞིན་སྐད་ཡིག་རྟོགས་ཀྱི་ལས་ཀ་གལ་ཆེན་ཡོད། སེམས་རྟགས་ནི་ཚོར་བ་སྐྱེས་པའི་བརྗོད་འབྲེལ་ཞིག་རེད། ལྟ་བ་འདིའི་ནང་དུ་ང་ཚོས་མཐུན་འབྲེལ་འདི་རྒྱལ་ཁབ་གཉིས་ཀྱི་ལས་འགུལ་གྱི་ཐབས་ལམ་སྣ་མང་པོ་ཞིག་གི་སྤྲོད་རྒྱུ་དང་། ང་ཚོའི་འཆར་བཀོད་པའི་མ་ལག་གིས་སྐྱེས་ཚད་རྙེད་བཤུད་ཀྱི་ཆེས་ཤུགས་དུ་རྙེད་ཐུབ་པ།'}
{'en': 'Sarcasm and Sentiment Detection in Arabic : investigating the interest of character-level features', 'ar': 'كشف السخرية والمشاعر في اللغة العربية: التحقق من الاهتمام بميزات مستوى الشخصية', 'fr': "Détection du sarcasme et des sentiments en arabe\xa0: enquête sur l'intérêt des caractéristiques au niveau du personnage", 'es': 'Detección de sarcasmo y sentimiento en árabe: investigando el interés de las características a nivel de personaje', 'pt': 'Detecção de sarcasmo e sentimento em árabe: investigando o interesse dos recursos de nível de personagem', 'ja': 'アラビア語での皮肉と感情の検出：キャラクターレベルの特徴の関心を調査する', 'zh': '阿拉伯语中刺情检,勘字符特征', 'hi': 'अरबी में व्यंग्य और भावना का पता लगाना: चरित्र-स्तर की विशेषताओं के हित की जांच करना', 'ru': 'Обнаружение сарказма и сентиментов на арабском языке: исследование интереса к характеристикам на уровне персонажей', 'ga': 'Sarcasm agus Braite Mothúcháin san Araibis: ag fiosrú spéise gnéithe ar leibhéal na gcarachtar', 'ka': 'საპკასმი და სენტიმენტი განსახულება არაბულია: სიმბოლოების ინტერესტი', 'hu': 'Szarkazmus és érzékelés arabul: a karakterszintű jellemzők érdeklődésének vizsgálata', 'el': 'Σαρκασμός και ανίχνευση συναισθημάτων στα αραβικά: διερεύνηση του ενδιαφέροντος των χαρακτηριστικών επιπέδου χαρακτήρων', 'it': "Sarcasmo e rilevamento dei sentimenti in arabo: investigare l'interesse delle caratteristiche a livello di personaggio", 'kk': 'Саркассм және сентиментті араб тілінде анықтау: таңбаның деңгейінің қасиеттерін зерттеу', 'mk': 'Сарказам и детективација на чувствата на арапски: истражување на интересот на карактеристичките карактеристики', 'lt': 'Sarkazmas ir jausmas arabų kalba: charakteristikų savybių interesų tyrimas', 'ms': 'Pengesanan Sarkasm dan Sentiment dalam bahasa Arab: menyelidiki kepentingan ciri-ciri aras-aksara', 'ml': 'സര്\u200dക്കാസം, സെന്റിമെന്\u200dറ് ഡിറ്ററിന്\u200dറ് അറബിയില്\u200d: അക്ഷരസഞ്ചയത്തിന്\u200dറെ താല്\u200dപര്യം അന്വേഷിക്കുന്നു', 'mt': 'Sarkazmu u Sejbien tas-Sentimenti fl-Għarab: investigazzjoni tal-interess tal-karatteristiċi fil-livell tal-karattru', 'no': 'Sarkasm- og Sentiment- oppdaging i arabisk: undersøker interessen på karakternivåfunksjonar', 'mn': 'Араб хэлний салбар болон сэтгэл санаа зориулалт: харилцааны түвшинд сонирхолтой байдлыг судалж,', 'pl': 'Sarkazm i wykrywanie sentymentów w języku arabskim: badanie zainteresowania cechami na poziomie znaków', 'ro': 'Sarcasmul și detectarea sentimentelor în arabă: investigarea interesului caracteristicilor la nivel de caracter', 'si': 'සාර්කාස්ම් සහ Sentiment හොයාගන්න අරාබික් වල: අක්ෂර- ස්තූතිය සැකසුම් ගැන පරීක්ෂණය කරන්න', 'so': 'Baaritaanka waxyaabaha ku saabsan xarafka sarcasm iyo wakhtiga la soo qabsado', 'sv': 'Sarkasm och känslodetektering på arabiska: undersöka intresset för karaktärsfunktioner', 'ta': 'Sarcasm and Sentiment Detection in Arabic: investigating the interest of character- level features', 'ur': 'Sarcasm and Sentiment Detection in Arabic: investigating the interest of character-level features', 'sr': 'Sarkazam i otkrivanje sentimenta na arapskom jeziku: istraživanje interesa karaktera', 'vi': 'Phát hiện cảm xúc bằng tiếng Ả Rập: điều tra sự quan tâm của tính cách', 'uz': 'Sarkasm va Sentiment aniqlash Arabi: character- level xossalarini qidirish', 'hr': 'Sarkazam i otkrivanje sentimenta na arapskom jeziku: istraživanje interesa karaktera', 'bg': 'Сарказъм и откриване на чувства на арабски език: изследване на интереса на характеристиките на ниво характер', 'da': 'Sarkasme og følelsesdetektion på arabisk: undersøgelse af interessen for karakterniveau funktioner', 'nl': 'Sarcasme en gevoelsdetectie in het Arabisch: onderzoek naar de interesse van kenmerken op karakterniveau', 'de': 'Sarkasmus und Sentiment Detection auf Arabisch: Untersuchung des Interesses von Charaktereigenschaften', 'id': 'Sarcasm and Sentiment Detection in Arabic: investigating the interest of character-level features', 'fa': 'آشنایی سارکاسم و سنتی در عربی: تحقیق علاقه\u200cای از ویژه\u200cهای سطح شخصیت', 'ko': '아랍어에서의 풍자와 정서 검측: 역할급 특징을 연구하는 취미', 'tr': 'Senýam we Senýat Aňlama Arabça: Karakter derejesi üçin gyzyklanýanýar', 'af': 'Sarkasm en Sentiment Opdekking in Arabs: ondersoek die belang van karaktervlak funksies', 'sq': 'Sarkazmi dhe zbulimi i ndjenjave në arabisht: hetimi i interesit të karakteristikave', 'sw': 'Kuchunguza maslahi ya Kiarabu na Kutambua Wakatili kwa Kiarabu: Kuchunguza maslahi ya tabia', 'am': 'አረቢኛ', 'hy': 'Սարկազմը և զգացմունքների հայտնաբերումը արաբերենով. բնավորության մակարդակի հատկանիշների հետաքրքրությունների հետաքննությունը', 'bn': 'সার্কাস্ম এবং সেন্টাইমেন্ট ডিটেক্টর আরবী ভাষায়: অক্ষর-স্তরের বৈশিষ্ট্যের আগ্রহ তদন্ত করা হচ্ছে', 'az': 'S…ôrkasm v…ô Sentiment ńįnŇüallarńĪ ArabsńĪzca: Karakter s…ôviyy…ôl…ôrinin s…ôviyy…ôsini araŇüdńĪrmaq', 'bs': 'Sarkazam i otkrivanje sentimenta na arapskom jeziku: istraživanje interesa karaktera', 'ca': "Sarcasme i Detecció de Sentiments en àrab: investigar l'interès de les característiques", 'cs': 'Sarkasmus a detekce sentimentů v arabštině: zkoumání zájmu znakových vlastností', 'et': 'Sarkasm ja tunnete tuvastamine araabia keeles: iseloomustaseme funktsioonide huvi uurimine', 'fi': 'Sarkasmi ja tunteentunnistus arabiaksi: hahmotason ominaisuuksien kiinnostuksen tutkiminen', 'jv': "Janet Smith (that's happened)", 'he': 'Sarcasm and Sentiment Detection in Arabic: investigating the interest of character-level features', 'sk': 'Sarkazem in zaznavanje čustev v arabščini: raziskovanje zanimanja značilnih značilnosti', 'ha': 'KCharselect unicode block name', 'bo': 'འོད་རྟགས་དང་དུས་ཚོད་མཚམས་བཙོག་སྟངས། དབྱེ་བ་ཀྱི་རྣམ་པ་གཙོ་རིམ་གྱི་དཀའ་བརྟན་བསལ་བ།'}
{'en': 'We present three methods developed for the Shared Task on Sarcasm and Sentiment Detection in Arabic. We present a baseline that uses character n-gram features. We also propose two more sophisticated methods : a recurrent neural network with a word level representation and an ensemble classifier relying on word and character-level features. We chose to present results from an ensemble classifier but it was not very successful as compared to the best systems : 22th/37 on sarcasm detection and 15th/22 on sentiment detection. It finally appeared that our baseline could have been improved and beat those results.', 'ar': 'نقدم ثلاث طرق تم تطويرها للمهمة المشتركة حول السخرية واكتشاف المشاعر باللغة العربية. نقدم خط الأساس الذي يستخدم ميزات الحرف n-gram. نقترح أيضًا طريقتين أكثر تعقيدًا: شبكة عصبية متكررة بتمثيل مستوى الكلمة ومصنف مجموعة يعتمد على ميزات مستوى الكلمة والحرف. لقد اخترنا عرض النتائج من مصنف مجموعة ولكنه لم يكن ناجحًا جدًا مقارنة بأفضل الأنظمة: 22/37 في اكتشاف السخرية و 15/22 في اكتشاف المشاعر. اتضح أخيرًا أنه كان من الممكن تحسين خط الأساس لدينا والتغلب على تلك النتائج.', 'fr': "Nous présentons trois méthodes développées pour la tâche partagée sur la détection du sarcasme et des sentiments en arabe. Nous présentons une ligne de base qui utilise des caractéristiques n-grammes de caractères. Nous proposons également deux méthodes plus sophistiquées\xa0: un réseau de neurones récurrent avec une représentation au niveau des mots et un classificateur d'ensemble basé sur des caractéristiques au niveau des mots et des caractères. Nous avons choisi de présenter les résultats d'un classificateur d'ensemble mais cela n'a pas été très efficace par rapport aux meilleurs systèmes\xa0: 22e/37 sur la détection des sarcasmes et 15e/22 sur la détection des sentiments. Il est finalement apparu que notre base de référence aurait pu être améliorée et battre ces résultats.", 'es': 'Presentamos tres métodos desarrollados para la tarea compartida sobre detección de sarcasmo y sentimiento en árabe. Presentamos una línea de base que utiliza características de n-gramas de caracteres. También proponemos dos métodos más sofisticados: una red neuronal recurrente con una representación a nivel de palabra y un clasificador de conjunto basado en características a nivel de palabras y caracteres. Elegimos presentar los resultados de un clasificador de conjunto, pero no tuvo mucho éxito en comparación con los mejores sistemas: 22th/37 en la detección de sarcasmo y 15th/22 en la detección de sentimientos. Finalmente, parecía que nuestra línea de base podría haberse mejorado y superar esos resultados.', 'pt': 'Apresentamos três métodos desenvolvidos para a Shared Task on Sarcasm and Sentiment Detection em árabe. Apresentamos uma linha de base que usa recursos de caracteres n-gram. Também propomos dois métodos mais sofisticados: uma rede neural recorrente com uma representação em nível de palavra e um classificador de ensemble baseado em recursos de nível de palavra e caractere. Optamos por apresentar resultados de um classificador ensemble, mas não teve muito sucesso em comparação com os melhores sistemas: 22/37 na detecção de sarcasmo e 15/22 na detecção de sentimento. Finalmente, parecia que nossa linha de base poderia ter sido melhorada e superar esses resultados.', 'ja': 'アラビア語での皮肉と感情の検出に関する共有タスクのために開発された3つの方法を提示します。n - gramの文字機能を使用したベースラインを提示します。また、単語レベルの表現を持つ再帰的なニューラルネットワークと、単語および文字レベルの機能に依存するアンサンブル分類子の2つのより洗練された方法を提案します。私たちはアンサンブル分類器からの結果を提示することを選択したが、皮肉検出で22位/37位、センチメント検出で15位/22位という最良のシステムと比較して、あまり成功しなかった。ようやくベースラインを改善し、それらの結果を打ち破ることができたように見えました。', 'zh': '我们介然为阿拉伯语刺情检测的三种法。 立字符 n-gram 特徵之基线。 又有二术:有单词级之递归神经网络,有单词字符之集成分类器。 吾曹择集成分类器,而比之至统,不亦难乎:刺检为22/37,情检为15/22。 卒以观之,吾基线固可以改善而破之也。', 'ru': 'Мы представляем три метода, разработанные для общей задачи по обнаружению сарказма и чувств на арабском языке. Мы представляем базовую линию, в которой используются особенности n-грамм символов. Мы также предлагаем два более сложных метода: рекуррентную нейронную сеть с представлением на уровне слова и ансамблевый классификатор, основанный на особенностях на уровне слова и символа. Мы решили представить результаты из ансамблевого классификатора, но он не был очень успешным по сравнению с лучшими системами : 22/37 по обнаружению сарказма и 15/22 по обнаружению чувств. В конце концов оказалось, что наш базовый уровень мог бы быть улучшен и превзойти эти результаты.', 'hi': 'हम अरबी में व्यंग्य और भावना का पता लगाने पर साझा कार्य के लिए विकसित तीन तरीकों को प्रस्तुत करते हैं। हम एक आधार रेखा प्रस्तुत करते हैं जो वर्ण एन-ग्राम सुविधाओं का उपयोग करता है। हम दो और परिष्कृत तरीकों का भी प्रस्ताव करते हैं: एक शब्द स्तर के प्रतिनिधित्व के साथ एक आवर्तक तंत्रिका नेटवर्क और शब्द और चरित्र-स्तर की विशेषताओं पर भरोसा करने वाला एक पहनावा क्लासिफायर। हमने एक पहनावा क्लासिफायर से परिणाम प्रस्तुत करने का फैसला किया, लेकिन यह सबसे अच्छी प्रणालियों की तुलना में बहुत सफल नहीं था: व्यंग्य का पता लगाने पर 22 वें / 37 और भावना का पता लगाने पर 15 वां / 22। यह अंत में दिखाई दिया कि हमारी आधार रेखा में सुधार किया जा सकता है और उन परिणामों को हराया जा सकता है।', 'ga': 'Cuirimid i láthair trí mhodh a forbraíodh don Tasc Comhroinnte ar Sarcasm agus Brath Mothúchán san Araibis. Cuirimid bunlíne i láthair a úsáideann gnéithe carachtar n-gram. Molaimid freisin dhá mhodh níos sofaisticiúla: líonra néarach athfhillteach le hionadaíocht ar leibhéal na bhfocal agus aicmitheoir ensemble ag brath ar ghnéithe ar leibhéal na bhfocal agus na gcarachtar. Roghnaíomar torthaí ó aicmitheora ensemble a chur i láthair ach níor éirigh go han-mhaith leis i gcomparáid leis na córais is fearr : 22/37 ar bhrath searbhas agus 15/22 ar bhrath meon. Dhealraigh sé ar deireadh go bhféadfaí ár mbunlíne a fheabhsú agus na torthaí sin a shárú.', 'ka': 'ჩვენ სამი მეტოვები განვითარებული საზოგადომი დავალებისთვის საპკასმის და სენტიმენტის განვითარებისთვის. ჩვენ ჩვენ გავაჩვენოთ ფესტური ხაზი, რომელიც n-გრამის ფესტურების გამოყენება. ჩვენ შეგიძლიათ ორი უფრო სპექსიტიკური მეტივები: რეკურენტური ნეიროლური ქსელი, რომელიც სიტყვების დონეზე გამოსახულებული და კლასიფიკაციის კლასიფიკაცია, რომელიც სიტყ ჩვენ მონიშნეთ, რომ გავაჩვენოთ წარმოდგენები ანსემბლის კლასიფიკაციის შემდეგ, მაგრამ ეს არ იყო ძალიან წარმოდგენელი, როგორც საუკეთესო სისტემისთან შედგენა: 22მე/37 საპკას ნაი-ნაკპაწ ჟვ თჱდლვზეალჲ, ფვ ნაქარა ბაჱლთნა მჲზვ ეა ბყევ ოჲ-ეჲბპვ თ ეა ოჲბვეთ რვჱთ პვჱსლრართ.', 'el': 'Παρουσιάζουμε τρεις μεθόδους που αναπτύχθηκαν για την κοινή εργασία για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά. Παρουσιάζουμε μια γραμμή βάσης που χρησιμοποιεί χαρακτηριστικά γραμμάτων χαρακτήρων. Επίσης προτείνουμε δύο πιο εξελιγμένες μεθόδους: ένα επαναλαμβανόμενο νευρωνικό δίκτυο με αναπαράσταση σε επίπεδο λέξης και έναν ταξινομητή συνόλου που βασίζεται σε χαρακτηριστικά σε επίπεδο λέξης και χαρακτήρων. Επιλέξαμε να παρουσιάσουμε αποτελέσματα από έναν ταξινομητή συνόλων, αλλά δεν ήταν πολύ επιτυχής σε σύγκριση με τα καλύτερα συστήματα: 22η/37 στην ανίχνευση σαρκασμού και 15η/22 στην ανίχνευση συναισθημάτων. Τελικά φάνηκε ότι η βάση μας θα μπορούσε να βελτιωθεί και να νικήσει αυτά τα αποτελέσματα.', 'hu': 'Három módszert mutatunk be az arab nyelvű szarkazmus és érzékelés megosztott feladatához. Bemutatunk egy alapvonalat, amely karakter n-gram funkciókat használ. Két kifinomultabb módszert is javasolunk: egy visszatérő neurális hálózatot szószintű reprezentációval és egy szó- és karakterszintű jellemzőkre támaszkodó együttes osztályozót. Úgy döntöttünk, hogy egy együttesosztályozó eredményeit mutatjuk be, de ez nem volt túl sikeres a legjobb rendszerekhez képest: 22/37 a szarkazmus detektálásáról és 15/22 a sentiment detektálásáról. Végül úgy tűnt, hogy a kiindulásunk javulhatott volna és legyőzhette volna ezeket az eredményeket.', 'it': 'Presentiamo tre metodi sviluppati per il compito condiviso sul sarcasmo e la rilevazione dei sentimenti in arabo. Presentiamo una linea di base che utilizza caratteristiche di carattere n-gram. Proponiamo anche due metodi più sofisticati: una rete neurale ricorrente con una rappresentazione a livello di parola e un classificatore ensemble basato su caratteristiche a livello di parola e carattere. Abbiamo scelto di presentare i risultati di un classificatore di ensemble ma non ha avuto molto successo rispetto ai migliori sistemi: 22/37 sulla rilevazione del sarcasmo e 15/22 sulla rilevazione del sentiment. Alla fine è apparso che la nostra base di riferimento avrebbe potuto essere migliorata e battere quei risultati.', 'kk': 'Біз саркассм және сентимен тапсырманы араб тілінде ортақ тапсырманың үш әдістерін көрсетедік. Біз n- грамм символдарын қолданатын негізгі жолды таңдаймыз. Сонымен қатар екі жұмыс әдістерін таңдаймыз: сөз деңгейінде қайталанатын невралдық желі мен сөз мен таңбалардың деңгейінде қайталанатын классификациясы. Біз ензембл классификациясының нәтижелерін таңдадық, бірақ бұл ең жақсы жүйелерімен салыстырылғанда тым сәтті емес: саркасты анықтау үшін 22-ші/37 және 15-ші/22 сезімді анықтау үшін Соңында біздің негізгі жолымыз жақсартылып, оның нәтижелерін жетілдіре алады.', 'lt': 'Mes pristatome tris metodus, sukurtus bendrai Sarkazmo ir Sentimento nustatymo užduotims arabų kalba. We present a baseline that uses character n-gram features.  Taip pat siūlome du sudėtingesnius metodus: pakartotinį nervinį tinklą su žodžių lygio atstovavimu ir ensemblio klasifikatorių, grindžiamų žodžių ir simbolių lygio savybėmis. Mes nusprendėme pateikti ensemblio klasifikatoriaus rezultatus, tačiau jis nebuvo labai sėkmingas, palyginti su geriausiomis sistemomis: 22/37 dėl sarkazmo aptikimo ir 15/22 dėl jausmų aptikimo. Galiausiai pasirodė, kad mūsų bazinis rodiklis galėjo būti patobulintas ir pasiekti šiuos rezultatus.', 'mk': 'Презентираме три методи развиени за заедничката задача за Сарказам и Детектирање на чувствата на арапски. Презентираме основа која користи карактеристики на n-грам. Ние, исто така, предложуваме два пософистицирани методи: рецидентна нервна мрежа со претставување на зборно ниво и класификатор на ансембл кој се потпира на зборови и карактеристички карактеристики. Одлучивме да ги претставиме резултатите од класификаторот на ансамблот, но не беше многу успешен во споредба со најдобрите системи: 22/37 за детекција на сарказам и 15/22 за детекција на чувства. Конечно се чинеше дека нашата основа можеше да се подобри и да ги победи тие резултати.', 'ms': 'Kami memperkenalkan tiga kaedah yang dikembangkan untuk Tugas Berkongsi tentang Sarkasm dan Pengesanan Sentiment dalam bahasa Arab. Kami memperkenalkan dasar yang menggunakan ciri n-gram aksara. Kami juga cadangkan dua kaedah yang lebih canggih: rangkaian saraf berkurang dengan perwakilan aras perkataan dan pengklasifikasi ensemble bergantung pada ciri-ciri aras perkataan dan aksara. Kami memilih untuk memperlihatkan keputusan dari klasifikasi ensemble tetapi ia tidak sangat berjaya dibandingkan dengan sistem terbaik: 22/37 pada pengesan sarkasm dan 15/22 pada pengesan perasaan. Akhirnya muncul bahawa asas kita boleh telah diperbaiki dan mengalahkan hasil itu.', 'mt': 'Aħna nippreżentaw tliet metodi żviluppati għall-Kompitu Konġunt dwar is-Sarkazmu u d-Detezzjoni tas-Sentimenti fl-Għarab. Aħn a nippreżentaw linja bażi li tuża karatteristiċi n-gramma tal-karattru. We also propose two more sophisticated methods: a recurrent neural network with a word level representation and an ensemble classifier relying on word and character-level features.  Aħżelna nippreżentaw riżultati minn klassifikatur tal-ensemble iżda ma kienx ta’ suċċess kbir meta mqabbel mal-aqwa sistemi : it-22/37 dwar id-detezzjoni tas-sarkazmu u l-15/22 dwar id-detezzjoni tas-sentimenti. Fl-aħħar deher li l-linja bażi tagħna setgħet titjieb u qabżet dawk ir-riżultati.', 'ml': 'സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റക്റ്റീഷനും അറബി ഭാഷയില്\u200d പങ്കാളിക്കപ്പെട്ട ട ടാസ്കിന് മൂന്ന് രീതികള്\u200d  നമ്മള്\u200d ഒരു ബേസ്ലൈന്\u200d കാണിക്കുന്നു. അതിന്റെ അക്ഷരത്തിന്റെ n-ഗ്രാമിന്റെ വിശേഷതകള്\u200d ഉപയോഗിക വാക്ക് നില പ്രതിനിധിയുമുള്ള രണ്ടു സോഫിസ്റ്റിക്കേറ്റ് രീതികളും വാക്കുകളില്\u200d ആശ്രയിക്കുന്ന ഒരു വാക്ക് നില പ്രതിനിധിയുമുള്ള നെ ഞങ്ങള്\u200d ഒരു ക്ലാസ്ഫിക്കറില്\u200d നിന്നുള്ള ഫലങ്ങള്\u200d കൊണ്ടുവരാന്\u200d തെരഞ്ഞെടുത്തിരുന്നു. പക്ഷെ ഏറ്റവും നല്ല സിസ്റ്റത്തിനെക്കുറിച്ച് അത് വിജയിച് അവസാനം നമ്മുടെ ബെസ്ലൈന്\u200d മെച്ചപ്പെടുത്തിയിരുന്നു എന്ന് തോന്നിയപ്പോള്\u200d ആ ഫലങ്ങള്\u200d മുന്\u200dകൂട്', 'mn': 'Бид саркассм болон сэтгэл хөдлөлийн нээлттэй ажлын хуваалцааны 3 арга замыг Араб хэлний хэлбэрээр үзүүлсэн. Бид n грамм дүрсийг ашигладаг суурь шулууныг харуулж байна. Мөн бид хоёр илүү нарийн төвөгтэй аргыг санал болгож байна: үгний түвшинд илэрхийлж буй мэдрэлийн сүлжээ, мөн үг болон харин дүнгийн төвшинд итгэлтэй хүмүүстэй холбогдож буй загвар хуваалцагч. Бид эмзэглэгчдийн үр дүнг тайлбарлахыг сонгосон ч хамгийн сайн системтэй харьцуулахад маш амжилттай биш: 22/37 саркассмын нээлттэй болон 15/22 сэтгэл хөдлөлийн нээлттэй. Эцэст нь бидний суурь шугам нь сайжруулж, тэдгээр үр дүнг ялж чадна.', 'no': 'Vi presenterer tre metodar utvikla for den delte oppgåva i Sarkasm- og Sentiment- oppdaginga i arabisk. Vi viser ein grunnlinje som brukar n- gram- funksjonar. Vi foreslår også to fleire sofistikerte metodar: eit rekurserande neuralnettverk med eit ordnivårepresentasjon og ein ensemble klassifiserer som tilhøyrer funksjonar på ordet og teiknivå. Vi valte å gjera resultat frå ein ensembelklassifiserer, men det var ikkje veldig suksessfull som sammenlignet med dei beste systema: 22. og 37. om oppdaging av sarkasm og 15. og 22. på oppdaging av sentimentar. Det viste til slutt at grunnlinja vår kunne ha forbetra og slått disse resultatene.', 'pl': 'Przedstawiamy trzy metody opracowane dla wspólnego zadania na temat sarkazmu i detekcji sentymentów w języku arabskim. Przedstawiamy bazę bazową, która wykorzystuje funkcje n-gram znaków. Proponujemy również dwie bardziej zaawansowane metody: powtarzającą się sieć neuronową z reprezentacją na poziomie słowa oraz klasyfikator zespołu oparty na cechach słowa i znaków. Zdecydowaliśmy się na przedstawienie wyników klasyfikatora zespołu, ale nie był on zbyt udany w porównaniu z najlepszymi systemami: 22th/37 o wykrywaniu sarkazmu i 15th/22 o detekcji sentymentów. W końcu okazało się, że nasza baza danych mogła zostać poprawiona i pokonana te wyniki.', 'si': 'අපි සර්කාස්ම් වල සහ සංවේදනය පරීක්ෂණය සඳහා අරාබික වලින් සම්බන්ධ වැඩසටහන් වැඩසටහන් තුනක් වි අපි අක්ෂර n-ග්\u200dරාම් විශේෂතාවක් භාවිත කරන අධ්\u200dයාත්මක පෙන්වන්නේ. අපි තවත් තව ප්\u200dරශ්නයක් දෙකක් ප්\u200dරශ්නයක් තියෙනවා: වචන ස්ථානයක් ප්\u200dරශ්නයක් තියෙන ප්\u200dරශ්නයක් සහ වචන සහ අක්ෂර ස්ථා අපි තෝරාගත්තා අන්ස්මෙන්බ්ල් විශේෂකයෙන් ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිපද්ධතියෙන් ප්\u200dරතිප්\u200dරතිප්\u200dරති අන්තිමට පේන විදිහට අපේ මූලික ප්\u200dරතිකාරය වැඩ කරන්න පුළුවන් කියලා ඒ ප්\u200dරතිකාරය ගැන පටන්', 'ro': 'Prezentăm trei metode dezvoltate pentru Sarcasmul și Detectarea Sentimentelor în limba arabă. Vă prezentăm o bază de referință care utilizează caracteristici n-gram. De asemenea, propunem două metode mai sofisticate: o rețea neurală recurentă cu o reprezentare la nivel de cuvânt și un clasificator ansamblu bazat pe caracteristici la nivel de cuvânt și caracter. Am ales să prezentăm rezultatele unui clasificator de ansambluri, dar nu a fost foarte reușit în comparație cu cele mai bune sisteme: 22/37 privind detectarea sarcasmului și 15/22 privind detectarea sentimentelor. În cele din urmă a apărut că baza noastră de referință ar fi putut fi îmbunătățită și bate aceste rezultate.', 'sr': 'Predstavljamo tri metode razvijene za zajednički zadatak o detekciji sarkasma i sentimenta na arapskom jeziku. Predstavljamo početnu liniju koja koristi karakterne funkcije n gram a. Takoðe predlažemo dve sofisticirane metode: rekonstruirana neuralna mreža sa predstavljanjem nivoa rijeèi i klasifikacijom povezanom na reèi i karakterske funkcije. Izabrali smo da predstavimo rezultate od klasifikatora ensembla, ali nije bilo veoma uspješno u usporedbi sa najboljim sistemima: 22. /37 na detekciji sarkazma i 15. /22 na detekciji sentimenta. Konačno se pojavilo da je naša početna linija mogla poboljšati i pobijediti te rezultate.', 'so': 'Waxaannu keenaynaa saddex qaabab oo loo horumariyey shaqada shariigta ah oo ku saabsan sarkasm iyo garsoorida wakhtiga oo afka Carabiga ah. Waxaan keenaynaa xaraf-n-gram Sidoo kale waxaan soo jeedaynaa laba qaab oo kale oo sawirfaal ah: shabakad neurada oo ku soo socda oo ay leedahay heer hadal ah, iyo mid kaloo fasax ah oo ku kalsoonaya hadal iyo heer heer. Waxaan dooranaynay inaan soo bixino midhihiisa fasax ka mid ah, laakiin ma liibaanayn sida loo barbarto nidaamka ugu fiican: 22aad/37 oo ku saabsan garsoorida sarcasm iyo 15aad/22 oo ku saabsan fikrada. Ugu dambaysta waxay u muuqatay in shabakaddeena lagu kordhin karo oo la garaaci karo arimahaas.', 'ur': 'ہم تین طریقے پیش کرتے ہیں کہ سارکاسم اور سنٹیمنٹ آزمائش کے بارے میں شریک ٹاکس کے لئے تخلیق کیا گیا ہے۔ ہم ایک بنسٹ لین کو پیش کریں جو شخص n-گرم فرصت استعمال کرتا ہے۔ ہم نے بھی دوسرے مصنوعی طریقے پیشنهاد کریں: ایک دوبارہ نئورل نیٹورل نیٹورک کے ساتھ ایک لفظ سطح کی پیشنهاد اور ایک انامبل کلاسیٹر کلاسیٹر لفظ اور شخصیت سطح پر بھروسہ رکھتا ہے. ہم نے انتخاب کیا کہ نتیجے ایک انسمبل کلاسیر سے پیش کریں لیکن یہ بہترین سیستموں کے مقابلہ میں بہت موفق نہیں تھے: 22th/37 sarcasm detection اور 15th/22 sentiment detection پر۔ بالآخر ظاہر ہوا کہ ہماری بنیادی لین بہتر ہوسکتی ہے اور ان نتائج کو غالب کر سکتی ہے۔', 'sv': 'Vi presenterar tre metoder som utvecklats för Shared Task on Sarkasm och Sentiment Detection på arabiska. Vi presenterar en baslinje som använder tecken n-gram funktioner. Vi föreslår också två mer sofistikerade metoder: ett återkommande neuralt nätverk med en ordnivårepresentation och en ensembleklassificerare baserad på ord- och teckennivåfunktioner. Vi valde att presentera resultat från en ensembleklassificerare men det var inte särskilt framgångsrikt jämfört med de bästa systemen: 22/37 på sarkasm detektering och 15/22 på sentiment detection. Det visade sig slutligen att vår baslinje kunde ha förbättrats och överträffat dessa resultat.', 'ta': 'சார்காஸ்ம் மற்றும் சென்டிமென்ட் கண்டுபிடிப்பு அரபி மூலம் பங்கிடப்பட்ட பணிக்கான மூன்று முறைகளை நாம்  நாம் ஒரு அடிப்படை கோட்டை காண்பிக்கிறோம். அது எழுத்து n-gram தன்மைகளை பயன்படுத்துகிறது. மேலும் இரண்டு முறைகளுக்கு மேலும் துறைப்படுத்தப்பட்ட முறைகளை நாம் பரிந்துரைக்கிறோம்: மீண்டும் நிகழ்ந்த புதிய புதிய வலைப்பின்ன We chose to present results from an ensemble classifier but it was not very successful as compared to the best systems : 22th/37 on sarcasm detection and 15th/22 on sentiment detection.  இறுதியாக எங்கள் அடிப்படைக்கோடு மேம்படுத்தப்பட்டு அந்த முடிவு', 'uz': "Биз уч усулни арабча, Sarkasm ва Сентент аниқлашини аниқлаш учун таржима қилганмиз. Biz bir asboblarni hozir qilamiz, bu belgi n-gram xususiyatlaridan foydalanadi. Biz yana yana ikkita foydalanuvchi usullarni tahrirlash: davom etilgan nervchi tarmoq va so'z darajasi taqdimoti bilan bir foydalanuvchi taʼminlovchi soʻz va harf darajadagi imkoniyatlarni ishlash mumkin. Biz birinchi darajadagi natijalarni hozirganishni tandik, lekin eng yaxshi tizimlar bilan o'xshash muvaffaqiyatli emas: sarkasm aniqlashda 22chi/37 va hissiyotni aniqlashda 15/22. Endi bizning asosiy satrlarimiz yaxshi ko'rib chiqaradi va bu natijalarni ko'rib chiqaradi.", 'vi': 'Chúng tôi giới thiệu ba phương pháp phát triển cho "Tập đoàn" về Sarcasm và l tình báo trinh sát bằng tiếng Ả Rập. Chúng tôi giới thiệu một đường cơ bản dùng tính n ăng n-gram. Chúng tôi cũng đề xuất hai phương pháp tinh vi hơn: một mạng lưới thần kinh liên tục có mức đại diện từ và một người phân loại kết hợp dựa vào các tính năng từ và đặc trưng. Chúng tôi chọn trình bày kết quả của một tập đoàn phân loại nhưng nó không được thành công nhiều so với hệ thống tốt nhất: 22th/37 trên phát hiện mỉa mai và 15/22 on đa cảm. Cuối cùng thì cơ sở của chúng ta đã có thể cải thiện và đánh bại kết quả.', 'bg': 'Представяме три метода, разработени за Споделена задача по сарказъм и откриване на чувства на арабски език. Представяме базова линия, която използва символи n-грам функции. Предлагаме и два по-сложни метода: повтаряща се невронна мрежа с представяне на ниво дума и ансамбъл класификатор, разчитащ на функции на ниво дума и знак. Избрахме да представим резултати от ансамбъл класификатор, но той не беше много успешен в сравнение с най-добрите системи: 22/37 за откриване на сарказъм и 15/22 за откриване на сентименти. Най-накрая се оказа, че нашата база може да бъде подобрена и да победи тези резултати.', 'nl': 'We presenteren drie methoden ontwikkeld voor de Shared Task on Sarcasme and Sentiment Detection in Arabic. We presenteren een basislijn die gebruik maakt van tekens n-gram functies. We stellen ook twee meer geavanceerde methoden voor: een terugkerend neuraal netwerk met een woordniveau representatie en een ensemble classificator gebaseerd op woord- en karaktereigenschappen. We kozen ervoor om resultaten van een ensemble classificator te presenteren, maar die was niet erg succesvol vergeleken met de beste systemen: 22e/37 op sarcasme detectie en 15e/22 op sentiment detectie. Uiteindelijk bleek dat onze baseline had kunnen worden verbeterd en die resultaten had kunnen verslaan.', 'da': 'Vi præsenterer tre metoder udviklet til den delte opgave om sarkasme og følelsesdetektion på arabisk. Vi præsenterer en basislinje, der bruger karakter n-gram funktioner. Vi foreslår også to mere sofistikerede metoder: et tilbagevendende neuralt netværk med en ordniveau repræsentation og en ensemble klassifikation afhængig af ord og tegn niveau funktioner. Vi valgte at præsentere resultater fra en ensemble klassifikation, men det var ikke særlig vellykket i forhold til de bedste systemer: 22/37 om sarkasme detektion og 15/22 om sentiment detektion. Det viste sig endelig, at vores basislinje kunne være blevet forbedret og slå disse resultater.', 'de': 'Wir stellen drei Methoden vor, die für die gemeinsame Aufgabe Sarkasmus und Sentiment Detection in Arabisch entwickelt wurden. Wir stellen eine Grundlinie vor, die Zeichen n-Gramm-Features verwendet. Wir schlagen auch zwei weitere anspruchsvolle Methoden vor: ein wiederkehrendes neuronales Netzwerk mit einer Wortebene-Darstellung und einen Ensemble-Klassifikator, der auf Wort- und Zeichenebene basiert. Wir haben uns entschieden, die Ergebnisse eines Ensembleklassifikators vorzustellen, aber dieser war im Vergleich zu den besten Systemen nicht sehr erfolgreich: 22th/37 zur Sarkasmus-Erkennung und 15th/22 zur Sentiment-Erkennung. Es zeigte sich schließlich, dass unsere Grundlinie hätte verbessert werden können und diese Ergebnisse hätte schlagen können.', 'id': 'Kami mempersembahkan tiga metode yang dikembangkan untuk Task Bersama tentang Sarkasme dan Deteksi Sentiment dalam bahasa Arab. Kami mempersembahkan dasar yang menggunakan karakter n-gram fitur. Kami juga mengusulkan dua metode yang lebih canggih: jaringan saraf yang berkurang dengan representation tingkat kata dan klasifikasi ensemble bergantung pada ciri-ciri tingkat kata dan karakter. Kami memilih untuk memperlihatkan hasil dari klasifikasi ensemble tapi itu tidak sangat sukses dibandingkan dengan sistem terbaik: 22/37 pada deteksi sarkasme dan 15/22 pada deteksi sentimen. Akhirnya tampak bahwa dasar dasar kita bisa telah diperbaiki dan mengalahkan hasil tersebut.', 'hr': 'Predstavljamo tri metode razvijene za zajednički zadatak o pronalaženju sarkasma i sentimenta na arapskom jeziku. Predstavljamo početnu liniju koja koristi karakterne funkcije n gram a. Također predlažemo dvije sofisticirane metode: rekonstruirana neuralna mreža sa predstavljanjem razine riječi i klasifikacijom osiguranjem riječi i razine karaktera. Izabrali smo da predstavimo rezultate iz klasifikatora ensembla, ali nije bio vrlo uspješan u usporedbi s najboljim sustavima : 22. /37 na detekciji sarkazma i 15. /22 na detekciji osjećaja. Konačno se pojavilo da je naša početna linija mogla poboljšati i pobijediti te rezultate.', 'ko': '우리는 세 가지 방법으로 개발한 공유 임무의 풍자와 정서 검출 아랍어를 제시했다.우리는 문자 n-gram 특징을 사용하는 기선을 제시했다.우리는 또 두 가지 더 복잡한 방법을 제시했는데 그것이 바로 단어급 표시를 가진 귀속신경 네트워크와 단어와 문자급 특징을 바탕으로 하는 집적분류기이다.우리는 집적 분류기의 결과를 보여주는 것을 선택했지만 가장 좋은 시스템에 비해 성공하지 못했다. 22/37개는 풍자 검출에, 15/22개는 감정 검출에 사용되었다.결국 우리의 기선은 개선되고 그 결과를 뛰어넘을 수 있을 것으로 보인다.', 'tr': 'Biz Sarkasm we Sentiýat Aňlamasynda bölünýän işi üçin üç ýoly görkezildik. Biz karakter n-gram karakterlerini ullanýan beýikligi görkezdiriz. Biz de iki sofistikli yöntemi teklif ediyoruz: bir tekrarlanan nöral şebekesi kelime seviyeli temsilcisi we kelime we karakter seviyeli özelliklerine güvenilir. Biz ensemble klasifikatından sonuçları sunmak seçdik fakat en iyi sistemlere karşılaştırmak için çok başarılı değildi : 22i/37 sertiksel keşfedilmesinde ve 15/22 duygusal keşfedilmesinde. Soňunda biziň esasy çyzgymyz gelişmiş we netijelerimizi ýeňdi.', 'fa': 'ما سه روش توسعه دادیم که برای کارهای مشترک در مورد کشف سارکاسم و احساسات در عربی توسعه داده شده است. ما یک خط بنیادی را نشان می دهیم که از ویژگی های n گرم استفاده می کند. ما همچنین دو روش پیچیده\u200cتر پیشنهاد می\u200cکنیم: شبکه عصبی بازگشت با یک نمایش سطح کلمه و یک نمایش\u200cکننده\u200cی کلمه\u200cای که بر ویژه\u200cهای کلمه و سطح شخصیت اعتماد دارد. ما انتخاب کردیم نتیجه\u200cها را از یک محرمانه\u200cکننده\u200cی انتخاب کنیم اما در مقایسه با بهترین سیستم موفق نبود: 22م/37 در detection sarcasm و 15م/22 در detection of sentiments. بالاخره ظاهراً خط پایین ما ممکن بود بهتر بشه و نتیجه\u200cها رو شکست بده.', 'sw': 'Tunaweza kuweka mbinu tatu zilizopangwa kwa ajili ya kazi za kushirikiana kwa Sarcasm na Kutambua Wakatili kwa Kiarabu. Tunaonyesha msingi unaotumia tabia za n-gram. Pia tunapendekeza mbinu mbili za kisasa: Mtandao wa neura unaoendelea kwa uwakilishi wa kiwango cha maneno na mwangalizi wa aina inayotegemea maneno na tabia za tabia. Tuliamua kuwasilisha matokeo kutoka kwa mfanyakazi wa kigaidi lakini haikuwa na mafanikio sana kama ilivyofananisha mifumo bora zaidi: 22/37 kuhusu uchunguzi wa kejeli na 15/22 kuhusu kutambua hisia. Hatimaye ilionekana kuwa mstari wetu wa msingi unaweza kuwa umeboreshwa na kushambulia matokeo hayo.', 'af': "Ons stel drie metodes ontwikkeld vir die Gedeelde Opdrag op Sarkasm en Sentiment Deteksie in Arabiese. Ons stel 'n basislien wat karakter n- gram funksies gebruik. Ons voorstel ook twee meer sofistikeerde metodes: â\x80\x99n herhaalde neuralnetwerk met â\x80\x99n woord vlak voorstelling en â\x80\x99n ensemble klassifiseerder wat op woord en karaktervlak funksies vertrou. Ons het gekies om resultate van 'n ensemble klassifiseerder te voorsien, maar dit was nie baie suksesvol soos vergelyk met die beste stelsels : 22de/37 op sarkasme opdekking en 15de/22 op sentiment opdekking. Dit het eindelik verskyn dat ons basislien kon verbeter word en daardie resultate geslaan het.", 'am': 'በዐረብኛ ቋንቋ ላይ ሳርካሲም እና የሳንቲት ጥያቄ ሦስት ሥርዓቶችን አቀረብን፡፡ የ-ግራም ምርጫዎችን የሚጠቀም የደረጃ መስመር አቀረብናል፡፡ We also propose two more sophisticated methods: a recurrent neural network with a word level representation and an ensemble classifier relying on word and character-level features.  በተሻለ ስርዓት ማግኘት ላይ 22ኛ/37 እና በአሳማሚ ላይ 15ኛ/22ኛ ፍሬዎችን አቀረብን፡፡ በመጨረሻም የመጀመሪያው ደረጃችን መሻለልና እነዚህን ፍሬዎች መክፈት ይችላል፡፡', 'sq': 'We present three methods developed for the Shared Task on Sarcasm and Sentiment Detection in Arabic.  Ne paraqesim një bazë që përdor karakterin n-gram. Ne propozojmë gjithashtu dy metoda më të sofistikuara: një rrjet neural të përsëritur me një përfaqësim të nivelit të fjalës dhe një klasifikues ensemble mbështetur në karakteristikat e nivelit të fjalës dhe karakterit. Ne zgjodhëm të paraqesim rezultate nga një klasifikues ensemble por nuk ishte shumë i suksesshëm krahasuar me sistemet më të mira: 22/37 për zbulimin e sarkazmit dhe 15/22 për zbulimin e ndjenjave. Më në fund dukej se baza jonë mund të kishte përmirësuar dhe të kishte mundur këto rezultate.', 'hy': "We present three methods developed for the Shared Task on Sarcasm and Sentiment Detection in Arabic.  Մենք ներկայացնում ենք հիմք, որը օգտագործում է n-գրամային հատկություններ: Մենք նաև առաջարկում ենք երկու ավելի բարդ մեթոդ' կրկնվող նյարդային ցանց, որը ունի բառերի մակարդակի ներկայացուցիչ և համակարգչային դասակարգչային, որը կախված է բառերի և բնավորների մակարդակի առանձնահատկությունների վրա: Մենք որոշեցինք ներկայացնել էնզեմբլի դասակարգչի արդյունքները, բայց այն շատ հաջողակ չէր համեմատել լավագույն համակարգերի հետ. սարկազմի հայտնաբերման 22-րդ սեպտեմբերի 37-ը և զգացմունքների հայտնաբերման 15-րդ սեպտեմբերի 22-ը: Վերջապես պարզվեց, որ մեր հիմքը կարող էր բարելավվել և հաղթահարել այդ արդյունքները:", 'az': 'Biz Sarkasm və Sentiment keşfini ərəbcə paylaşdırmaq üçün üç yol göstəririk. Biz n-gram karakterlərini istifadə edir. Biz də iki daha sofistikli yol təklif edirik: sözlərin səviyyəsi göstəricisi və sözlərin və karakter səviyyəsinə təvəkkül edən bir nöral a ğı. Biz ensemble klasifikatından sonuçları göstərməyi seçdik, amma ən yaxşı sistemlərlə qarşılaşdığı kimi bu çox başarılı deyildi: sarkasm keşfini 22/37 və 15/22 hiss keşfini. Sonunda bizim baz çizgimiz yaxşılaşdırılmış və sonuçlarımızı yenmiş olardı.', 'bn': 'আমরা আরবী ভাষায় শেয়ার করা কাজের জন্য তিনটি পদ্ধতি তৈরি করেছি। We present a baseline that uses character n-gram features.  আমরা আরো দুটি সাফিক্সিক পদ্ধতিও প্রস্তাব করছি: বার্তার একটি শব্দ স্তরের প্রতিনিধিত্বের নিউরেল নেটওয়ার্ক এবং একটি বিশ্লেষক শব্দ এবং অক্ষর- আমরা বিদ্রোহীদের ক্লাসিফারের ফলাফল উপস্থাপন করতে বেছে নিলাম কিন্তু সেরা সিস্টেমের তুলনায় তা খুব সফল হয়নি: বিদ্রোহী সনাক্তি এবং আবেগ সনাক্তির শেষ পর্যন্ত মনে হচ্ছে যে আমাদের বেসেলাইন উন্নত হয়ে যেত এবং এই ফলাফলের মারা যেত।', 'bs': 'Predstavljamo tri metode razvijene za zajednički zadatak o pronalaženju sarkasma i sentimenta na arapskom jeziku. Predstavljamo početnu liniju koja koristi karakterne funkcije n gram a. Također predlažemo dvije sofisticirane metode: rekonstruirana neuralna mreža sa predstavljanjem razine riječi i klasifikacijom povezanom na riječi i karakterske funkcije. Izabrali smo da predstavimo rezultate iz klasifikatora ensembla, ali nije bilo vrlo uspješno u usporedbi s najboljim sustavima : 22th/37 o detekciji sarkazma i 15/22 o detekciji osjećaja. Konačno se pojavilo da je naša početna linija mogla biti poboljšana i pobijediti te rezultate.', 'cs': 'Představujeme tři metody vyvinuté pro sdílený úkol o sarkasmu a detekci citů v arabštině. Představujeme základní linii, která používá funkce n-gramu znaků. Navrhujeme také dvě další sofistikované metody: recidivující neuronovou síť s reprezentací na úrovni slova a klasifikátor souboru spoléhající na prvky slova a znaků. Rozhodli jsme se prezentovat výsledky souborového klasifikátoru, ale nebyl příliš úspěšný ve srovnání s nejlepšími systémy: 22th/37 na detekci sarkasmu a 15th/22 na detekci sentimentu. Nakonec se ukázalo, že náš základ mohl být zlepšen a porazit tyto výsledky.', 'fi': 'Esittelemme kolme menetelmää, jotka on kehitetty sarkasmia ja tunteiden havaitsemista varten arabiaksi. Esittelemme perusaikataulun, joka käyttää merkin n gramman ominaisuuksia. Lisäksi ehdotamme kahta kehittyneempää menetelmää: toistuvaa neuroverkkoa, jossa on sanatason esitys, sekä sana- ja merkkitason ominaisuuksiin perustuvaa ryhmäluokittelijaa. Päätimme esitellä tulokset ryhmäluokittelijasta, mutta se ei ollut kovin onnistunut verrattuna parhaisiin järjestelmiin: 22/37 sarkasmin havaitsemisessa ja 15/22 tunteiden havaitsemisessa. Lopulta näytti siltä, että lähtötasoamme olisi voitu parantaa ja voittaa nämä tulokset.', 'et': 'Esitleme kolme meetodit, mis on välja töötatud sarkasmi ja tunnete tuvastamise jagatud ülesandeks araabia keeles. Esitame lähtejoone, mis kasutab märgi n-grammi funktsioone. Samuti pakume välja kaks keerukamat meetodit: korduv närvivõrk sõnataseme esitusega ning ansambli klassifitseerija, mis tugineb sõna- ja märgitasemel funktsioonidele. Otsustasime esitada ansambli klassifikaatori tulemusi, kuid see ei olnud eriti edukas võrreldes parimate süsteemidega: 22/37 sarkasmi tuvastamisel ja 15/22 sentimentide tuvastamisel. Lõpuks ilmnes, et meie algväärtust oleks võimalik parandada ja neid tulemusi võita.', 'ca': "We present three methods developed for the Shared Task on Sarcasm and Sentiment Detection in Arabic.  Presentam una base que utilitza característiques n-gram. També proposem dos mètodes més sofisticats: una xarxa neural recurrent amb una representació de nivell de paraules i un classificador d'ensembles basat en característiques de nivell de paraules i caràcters. Vam escollir presentar resultats d'un classificador d'ensembles però no va tenir molt èxit comparat amb els millors sistemes: el 22/37 sobre la detecció del sarcasme i el 15/22 sobre la detecció del sentiment. Finalment va semblar que la nostra base podria haver estat millorada i superat aquests resultats.", 'he': 'אנחנו מציגים שלושה שיטות שפותחות עבור המשימה המשותפת על סרקזם וגילוי רגשות בערבית. We present a baseline that uses character n-gram features.  We also propose two more sophisticated methods: a recurrent neural network with a word level representation and an ensemble classifier relying on word and character-level features.  We chose to present results from an ensemble classifier but it was not very successful as compared to the best systems : 22th/37 on sarcasm detection and 15th/22 on sentiment detection.  It finally appeared that our baseline could have been improved and beat those results.', 'sk': 'Predstavljamo tri metode, razvite za skupno nalogo sarkazma in detekcije čustev v arabščini. Predstavljamo osnovno osnovo, ki uporablja znak n-gram funkcije. Predlagamo tudi dve bolj sofisticirani metodi: ponavljajočo se nevronsko omrežje s predstavitvijo besedne ravni in klasifikator ansambla, ki temelji na besedne in znakovne funkcije. Odločili smo se za predstavitev rezultatov ansambelnega klasifikatorja, vendar ni bil zelo uspešen v primerjavi z najboljšimi sistemi: 22/37 na odkrivanju sarkazma in 15/22 na odkrivanju sentimenta. Končno se je zdelo, da bi lahko izboljšali našo izhodišče in premagali te rezultate.', 'jv': 'Awak dhéwé éntukno telu maneh nggawe kanggo Kemerdekaan Tarjamahan kanggo Kemerdekaan Sarkasm lan Sentiment kanggo Kemerdekaan arab. string" in "context_BAR_stringLink UnknownMonitor vendor Awak dhéwé wis dipoleh dadi winih ning acara asar tentang karo ngono nggawe sistem sing luwih dumadhi sing gak dhéwé: 22/34 uwong, dinopakan karo perusahaan karo perangkat sabanjur pukan-pukan sing paling dhéwé. Bandhéwé éntuk dhéwé élasaé sing bisa diangéwa lan ijol-ijol sing ditambut kuwi.', 'ha': 'Tuna halatar da shiryoyin uku wanda aka buɗe wa Taimar da aka Shara shi a kan Sarkasm da Saukar da Sakamati a Larabci. Muna halatar da wani layin da ke amfani da fassarar n-gram. Tuna ƙayyade hanyõyi biyu masu sofi-biyu: wata shirin neural wanda ke dace yana da mai gaya wata magana, da wani tsofali mai daidaita kan kalma da takardar-daraja. Mun zãɓe su gaba matsala daga wani misalin mai bastarwa, kuma amma ba ta ci mafanici ba da kamfan da mafiya kyãwo na tsari: 22/37 a kan ganin sarkasm da 15/22 a kan ganin hisani. Ga ƙarshen ya bayyana cewa an improve ƙaraminmu, kuma a karɓi waɗannan matsayi.', 'bo': 'ང་ཚོས་སྦྱར་བའི་བྱ་ཚིག་དང་མཉམ་དུ་དམིགས་བསལ་གྱི་ཐབས་ལམ་གསུམ་གཅིག་གནང་བ་དེ་ཚོར་ཡོད། ང་ཚོས་ཡིག་འབྲུ་གཟུགས་རིས་ལ་རང་ཉིད་ཀྱི་རྨང་གཞིའི་སྟོན་པ་ཞིག་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དུས་མཐུན་བཟོ་བྱས་པའི་ཐབས་ལམ་གཉིས་ཀྱང་ཁྱད་པར་བསམ་བྱེད་ཀྱི་ཡོད། འུ་ཚོས་མཚོན་རྟགས་དབྱེ་བ་ཞིག་གིས་གནད་སྡུད་པ་ཞིག་གིས་གནད་སྡུད་དགོས་པ་ཡིན་ནའང་མ་ལག་ལེན་གྱི་ཐབས་ལམ་ལ་མཉམ་དུ་བཅུག་པ་མ་ མཇུག་རྫོགས་དུ་ང་ཚོའི་གཞི་རྩལ་གཞི་འདི་དག་ཡར་རྒྱས་རྐྱེན་བྱས་མི་འདུག'}
{'en': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'ar': 'كشف السخرية في مهمة الكشف عن السخرية 2021 باللغة العربية باستخدام نموذج أرابرت المُدرب مسبقًا', 'pt': 'SarcasmDet na tarefa de detecção de sarcasmo 2021 em árabe usando o modelo pré-treinado AraBERT', 'es': 'SarcasMDET en Sarcasm Detection Task 2021 en árabe utilizando el modelo preentrenado de AraBert', 'fr': "SarcasMDet à Sarcasm Detection Task 2021 en arabe à l'aide du modèle pré-entraîné AraBert", 'ja': 'AraBERT事前訓練済みモデルを使用したアラビア語での皮肉検出タスク2021での皮肉', 'zh': 'SarcasmDet 于 Sarcasm Detection Task 2021 上用 AraBERT 预练模形之阿拉伯语', 'hi': 'अरबी में व्यंग्य का पता लगाने के कार्य 2021 में व्यंग्यDet AraBERT Pretrained मॉडल का उपयोग कर', 'ru': 'SarcasmDet в задаче обнаружения сарказма 2021 на арабском языке с использованием предварительно обученной модели AraBERT', 'ga': 'SarcasmDet ag Tasc Braite Sarcasm 2021 i Araibis ag baint úsáide as Múnla Réamhthraenáilte AraBERT', 'ka': 'SarcasmDet in Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'hu': 'SarcasmDet a Sarcasm Detection Task 2021 arab nyelven AraBERT Pretrained Model használatával', 'el': 'SarcasmDet στην εργασία ανίχνευσης σαρκασμού 2021 στα αραβικά χρησιμοποιώντας το προκαθορισμένο μοντέλο AraBERT', 'it': 'SarcasmDet al Sarcasm Detection Task 2021 in arabo utilizzando AraBERT Pretrained Model', 'kk': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'lt': 'SarkasmDet pagal Sarkasmo aptikimo užduotį 2021 m. arabų kalba naudojant AraBERT išankstinio mokymo modelį', 'ml': 'സര്\u200dക്കാസ്മിലെ സാര്\u200dക്കാസം ഡിറ്ററിഷന്\u200d ടാസ്ക് 2021 ല്\u200d അറബില്\u200d അരാബെര്\u200dട്ടി പ്രിട്ടിനെടുത്ത മോഡില്\u200d ഉപ', 'ms': 'SarkasmDet di tugas pengesan Sarkasm 2021 dalam bahasa Arab menggunakan Model Terlatih AraBERT', 'mk': 'SarcasmDet на задачата за детективирање на Сарказам 2021 на арапски користејќи го претренираниот модел AraBERT', 'mt': 'SarkasmDet f’Sarkasm Detection Task 2021 bl-Għarab bl-użu tal-Mudell Imħarreġ minn Qabel AraBERT', 'no': 'SarcasmDet på Sarcasm Detection Task 2021 i arabisk med AraBERT Pretrained Model', 'sr': 'SarkasmDet na Sarkasm Detection Task 2021 na arapskom korištenju AraBERT Pretrained Model', 'ro': 'SarcasmDet la Sarcasm Detection Task 2021 în arabă folosind AraBERT Pretrained Model', 'pl': 'SarcasmDet w zadaniu wykrywania sarkasmu 2021 w języku arabskim przy użyciu modelu wstępnego AraBERT', 'si': 'SarcasmDet at Sarcasm Detection Job 2021 in AraBERT Using Precrained Model', 'mn': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'ur': 'عربی میں Sarcasm Detection Task 2021 میں SarcasmDet AraBERT Pretrained Model کے مطابق', 'ta': 'Sarcasmdet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'so': 'SarcasmIt at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'sv': 'SarcasmDet vid Sarkasm Detection Task 2021 på arabiska med AraBERT Pretrained Model', 'uz': 'SarcasmIt at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'vi': 'SarcasmDet at Sarcasm Điều tra nhiệm vụ 2021 in Ả Rập dùng AraBERT Prendered Model', 'hr': 'SarcasmDet na zadatku za detekciju Sarcasm 2021 na arapskom korištenju AraBERT-ovog modela', 'bg': 'СаркасмДет на задача за откриване на сарказъм 2021 на арабски език с помощта на предварително трениран модел', 'da': 'SarcasmDet på Sarcasm Detection Task 2021 på arabisk ved hjælp af AraBERT Pretrained Model', 'nl': 'SarcasmDet bij Sarcasme Detection Task 2021 in het Arabisch met behulp van AraBERT Voorgetraind Model', 'de': 'SarcasmDet bei Sarkasm Detection Task 2021 auf Arabisch mit AraBERT Vortrainiertem Modell', 'id': 'SarkasmDet di Sarkasm Detection Task 2021 dalam bahasa Arab menggunakan AraBERT Pretrained Model', 'ko': 'SarcasmDet 풍자 검출 퀘스트 2021에서 아라비아 특수 훈련 모형 사용', 'fa': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'sw': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'tr': 'Arabça AraBERT Pretrained Model', 'sq': 'SarkasmDet në detyrën e zbulimit të Sarkasmit 2021 në arabisht duke përdorur modelin e paraprakuar AraBERT', 'af': 'SarcasmDet by Sarcasm Detection Task 2021 in Arabiese gebruik AraBERT Pretrained Model', 'am': 'SarcasmIt at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model', 'hy': 'ՍարկազմԴ 2021 թվականին Սարկազմի հայտնաբերման գործընթացը արաբերենով օգտագործելով Արաբերթ նախապատրաստված մոդելը', 'az': 'AraBERT Pretrained Model vasitəsilə SarcasmDet at Sarcasm Detection Task 2021 in Arabic', 'bn': 'আরবী ভাষায় সার্কাস্ম ডিটেক্টরেশন টাস্ক ২০১১-এর সার্কাসমেট আরবি আরবী আরবী আরবী প্রশিক্ষিত মডেল ব্যবহার করে', 'ca': 'SarcasmDet a Sarcasm Detection Task 2021 en àrab utilitzant AraBERT Pretrained Model', 'bs': 'SarcasmDet na Sarcasm Detection Task 2021 na arapskom korištenju AraBERT Pretrained Model', 'et': 'SarcasmDet sarcasmi tuvastamise ülesandel 2021 araabia keeles, kasutades AraBERT eelkreenitud mudelit', 'cs': 'SarcasmDet na úkolu detekce sarkasmu 2021 v arabštině pomocí AraBERT Pretrénovaného modelu', 'fi': 'SarcasmDet Sarcasm Detection Task 2021 arabiaksi käyttäen AraBERT-esiasennettua mallia', 'ha': 'SarcasmIt at Sarcasm Discection Task 2021 in Arabic by use AraBERT PreTrafied Model', 'jv': 'SarkasmDet at Sarkasm detection task 2020 1 in Hebrew use araBERT Prescaned model', 'sk': 'SarcasmDet na nalogi odkrivanja sarcasma 2021 v arabščini z uporabo AraBERT predtreniranega modela', 'he': 'SarcasmDet במשימת גילוי סרקזם 2021 בערבית', 'bo': 'SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model'}
{'en': 'This paper presents one of the top five winning solutions for the Shared Task on Sarcasm and Sentiment Detection in Arabic (Subtask-1 Sarcasm Detection). The goal of the task is to identify whether a tweet is sarcastic or not. Our solution has been developed using ensemble technique with AraBERT pre-trained model. We describe the architecture of the submitted solution in the shared task. We also provide the experiments and the hyperparameter tuning that lead to this result. Besides, we discuss and analyze the results by comparing all the models that we trained or tested to achieve a better score in a table design. Our model is ranked fifth out of 27 teams with an F1 score of 0.5985. It is worth mentioning that our model achieved the highest accuracy score of 0.7830', 'ar': 'تقدم هذه الورقة واحدة من أفضل خمسة حلول فائزة للمهمة المشتركة حول السخرية واكتشاف المشاعر باللغة العربية (اكتشاف المهمة الفرعية 1 للسخرية). الهدف من المهمة هو تحديد ما إذا كانت التغريدة ساخرة أم لا. تم تطوير حلنا باستخدام تقنية التجميع مع نموذج AraBERT المدرب مسبقًا. نصف بنية الحل المقدم في المهمة المشتركة. نقدم أيضًا التجارب وضبط المعلمة الفائقة التي تؤدي إلى هذه النتيجة. إلى جانب ذلك ، نناقش النتائج ونحللها من خلال مقارنة جميع النماذج التي قمنا بتدريبها أو اختبارها لتحقيق درجة أفضل في تصميم الجدول. يحتل نموذجنا المرتبة الخامسة من بين 27 فريقًا بدرجة F1 تبلغ 0.5985. الجدير بالذكر أن نموذجنا حقق أعلى درجة دقة بلغت 0.7830', 'es': 'Este documento presenta una de las cinco mejores soluciones ganadoras para la tarea compartida sobre detección de sarcasmo y sentimiento en árabe (detección de sarcasmo subtarea 1). El objetivo de la tarea es identificar si un tuit es sarcástico o no. Nuestra solución se ha desarrollado utilizando la técnica de ensamble con el modelo ARaBert previamente entrenado. Describimos la arquitectura de la solución presentada en la tarea compartida. También proporcionamos los experimentos y el ajuste de hiperparámetros que conducen a este resultado. Además, discutimos y analizamos los resultados comparando todos los modelos que entrenamos o probamos para lograr una mejor puntuación en el diseño de una tabla. Nuestro modelo ocupa el quinto lugar de 27 equipos con un puntaje de F1 de 0.5985. Vale la pena mencionar que nuestro modelo logró la puntuación de precisión más alta de 0.7830', 'pt': 'Este artigo apresenta uma das cinco principais soluções vencedoras para a Tarefa Compartilhada sobre Detecção de Sarcasmo e Sentimento em árabe (Detecção de Sarcasmo Subtarefa-1). O objetivo da tarefa é identificar se um tweet é sarcástico ou não. Nossa solução foi desenvolvida utilizando a técnica de ensemble com modelo pré-treinado AraBERT. Descrevemos a arquitetura da solução submetida na tarefa compartilhada. Também fornecemos os experimentos e o ajuste de hiperparâmetros que levam a esse resultado. Além disso, discutimos e analisamos os resultados comparando todos os modelos que treinamos ou testamos para obter uma melhor pontuação em um design de tabela. Nosso modelo está classificado em quinto lugar entre 27 equipes com uma pontuação F1 de 0,5985. Vale ressaltar que nosso modelo alcançou a maior pontuação de precisão de 0,7830', 'fr': "Cet article présente l'une des cinq meilleures solutions gagnantes pour la tâche partagée sur la détection du sarcasme et des sentiments en arabe (sous-tâche 1). L'objectif de la tâche est de déterminer si un tweet est sarcastique ou non. Notre solution a été développée en utilisant la technique d'ensemble avec le modèle pré-entraîné AraBert. Nous décrivons l'architecture de la solution soumise dans la tâche partagée. Nous fournissons également les expériences et le réglage des hyperparamètres qui ont conduit à ce résultat. En outre, nous discutons et analysons les résultats en comparant tous les modèles que nous avons entraînés ou testés pour obtenir un meilleur score dans une conception de tableau. Notre modèle est classé cinquième sur 27 équipes avec un score F1 de 0,5985. Il convient de mentionner que notre modèle a obtenu le score de précision le plus élevé de 0,7830", 'hi': 'यह पेपर अरबी में व्यंग्य और भावना का पता लगाने पर साझा कार्य के लिए शीर्ष पांच विजेता समाधानों में से एक प्रस्तुत करता है (Subtask-1 व्यंग्य का पता लगाना)। कार्य का लक्ष्य यह पहचानना है कि कोई ट्वीट व्यंग्यात्मक है या नहीं। हमारे समाधान AraBERT पूर्व प्रशिक्षित मॉडल के साथ पहनावा तकनीक का उपयोग कर विकसित किया गया है. हम साझा कार्य में सबमिट किए गए समाधान की वास्तुकला का वर्णन करते हैं। हम प्रयोगों और हाइपरपैरामीटर ट्यूनिंग भी प्रदान करते हैं जो इस परिणाम की ओर ले जाते हैं। इसके अलावा, हम उन सभी मॉडलों की तुलना करके परिणामों पर चर्चा और विश्लेषण करते हैं जिन्हें हमने टेबल डिज़ाइन में बेहतर स्कोर प्राप्त करने के लिए प्रशिक्षित या परीक्षण किया था। हमारा मॉडल 0.5985 के F1 स्कोर के साथ 27 टीमों में से पांचवें स्थान पर है। यह ध्यान देने योग्य है कि हमारे मॉडल ने 0.7830 का उच्चतम सटीकता स्कोर हासिल किया', 'ja': 'この論文では、アラビア語での皮肉と感情の検出に関する共有タスク（ Subtask -1 Sarcasm Detection ）の上位5つの勝利ソリューションの1つを紹介します。タスクの目標は、ツイートが皮肉であるかどうかを特定することです。当社のソリューションは、AraBERT事前トレーニングモデルを使用したアンサンブルテクニックを使用して開発されています。共有タスクで提出されたソリューションのアーキテクチャについて説明します。この結果につながる実験とハイパーパラメータチューニングも提供します。さらに、テーブルデザインでより良いスコアを達成するためにトレーニングまたはテストしたすべてのモデルを比較することによって、結果を議論し、分析します。当社のモデルは、F 1スコア0.5985で27チーム中5位にランクされています。私たちのモデルが最高の精度スコア0.7830を達成したことは、注目に値する。', 'ru': 'В этой статье представлено одно из пяти лучших решений для общей задачи по обнаружению сарказма и сентиментов на арабском языке (Subtask-1 Sarcasm Detection). Цель задачи состоит в том, чтобы определить, является ли твит саркастичным или нет. Наше решение было разработано с использованием ансамблевой техники с предварительно обученной моделью AraBERT. Архитектуру представленного решения мы описываем в общей задаче. Мы также предоставляем эксперименты и настройку гиперпараметров, которые приводят к этому результату. Кроме того, мы обсуждаем и анализируем результаты, сравнивая все модели, которые мы обучали или тестировали, чтобы достичь лучшего результата в дизайне таблицы. Наша модель занимает пятое место из 27 команд с результатом F1 0.5985. Стоит отметить, что наша модель достигла наивысшей оценки точности 0,7830', 'zh': '本文引阿拉伯语刺情检共(Subtask-1刺检)五获奖解决方案之一。 其事定推文有刺意。 吾解决方案以集成术与AraBERT预练模形者也。 共述解决方案体系结构。 供实验、超参数调。 凡试法以论之,以表格计得其分。 27车第五,F1分为0.5985。 值得一提的是得0.7830上准确度分', 'ga': 'Cuirtear i láthair sa pháipéar seo ceann de na cúig réiteach buaiteacha is fearr don Tasc Comhroinnte ar Choimhthíocha agus ar Bhrath Mothúcháin in Araibis (Fothasc-1 Brath Coimhthíocha). Is é sprioc an taisc a aithint an bhfuil tweet sarcastic nó nach bhfuil. Forbraíodh ár réiteach ag baint úsáide as teicníc ensemble le múnla réamh-oilte AraBERT. Déanaimid cur síos ar ailtireacht an réitigh a cuireadh isteach sa tasc roinnte. Cuirimid ar fáil freisin na turgnaimh agus an tiúnadh hipearpharaiméadair as a dtagann an toradh seo. Thairis sin, déanaimid na torthaí a phlé agus a anailísiú trí chomparáid a dhéanamh idir na samhlacha go léir a ndearnamar oiliúint nó tástáil orthu chun scór níos fearr a bhaint amach i ndearadh tábla. Tá ár múnla sa chúigiú háit as 27 bhfoireann le scór F1 de 0.5985. Is fiú a lua gur bhain ár múnla an scór cruinneas is airde de 0.7830 amach', 'ka': 'ეს დოკუმენტი აპაბიური (Subtask-1 Sarcasm Detection) საზოგადომი საქაღალდე და სენტიმენტის განახლების ერთი მეტი ხუთი წინაღალდე. დავალების მისამართი არის იდენტიფიკაცია თუ არა, თუ არა. ჩვენი პასუხი განვითარებულია, რომელიც აპაბერტის წინ განვითარებული მოდელზე გამოყენებული ინსნემბლური ტექნიკის გამოყენებით. ჩვენ აღწერეთ გადასტანებული პასუხის არქტიქტიკურას საერთო დავალებში. ჩვენ ასევე ექსპერიმენტები და ჰიპეროპარამეტრის შენახვა, რომელიც ამ შედეგის გადავიწყებთ. დამატებით, ჩვენ განვისაუბრებთ და ანალიზაცით შედეგების შესაბამისად ყველა მოდელების შესაბამისად, რომლებიც ჩვენ განვიყენეთ ან შევცვალობთ, რომ მაგილის დიზაინოში უფრო ჩვენი მოდელი 27 ჯგუფიდან ხუთი ჯგუფიდან, რომელიც F1 წერტილი 0.5985-ია. უფრო უფრო მუშაობს, რომ ჩვენი მოდელი 0.7830-ის უფრო მართლა წარმოდგენა.', 'el': 'Η παρούσα εργασία παρουσιάζει μία από τις πέντε κορυφαίες νικηφόρες λύσεις για την κοινή εργασία για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά (Υποεργασία-1 ανίχνευση σαρκασμού). Ο στόχος του έργου είναι να προσδιορίσει αν ένα tweet είναι σαρκαστικό ή όχι. Η λύση μας έχει αναπτυχθεί χρησιμοποιώντας τεχνική συνόλου με προπαιδευμένο μοντέλο. Περιγράφουμε την αρχιτεκτονική της υποβληθείσας λύσης στην κοινή εργασία. Παρέχουμε επίσης τα πειράματα και τον συντονισμό υπερπαραμέτρων που οδηγούν σε αυτό το αποτέλεσμα. Εκτός αυτού, συζητάμε και αναλύουμε τα αποτελέσματα συγκρίνοντας όλα τα μοντέλα που εκπαιδεύσαμε ή δοκιμάσαμε για να επιτύχουμε μια καλύτερη βαθμολογία σε ένα σχέδιο πίνακα. Το μοντέλο μας κατατάσσεται πέμπτο από τις 27 ομάδες με βαθμολογία F1 0.5985. Αξίζει να σημειωθεί ότι το μοντέλο μας πέτυχε την υψηλότερη βαθμολογία ακρίβειας 0.7830', 'hu': 'Ez a tanulmány bemutatja az arab nyelvű szarkazmus és érzelmek felismerésével foglalkozó megosztott feladat egyik legjobb öt nyertes megoldását (Subtask-1 szarkazmus felismerés). A feladat célja annak megállapítása, hogy egy tweet szarkasztikus-e vagy sem. Megoldásunkat együttes technikával fejlesztettük ki AraBERT előre képzett modelljével. Leírjuk a benyújtott megoldás architektúráját a megosztott feladatban. Az eredményhez vezető kísérleteket és hiperparaméteres hangolást is biztosítjuk. Emellett megvitatjuk és elemezzük az eredményeket, összehasonlítva az összes olyan modellt, amelyet képzett vagy tesztelt, hogy jobb pontszámot érjen el egy asztal tervezésében. Modellünk a 27 csapat közül az ötödik helyen áll, 0,5985 F1 pontszámmal. Érdemes megemlíteni, hogy modellünk a legmagasabb pontossági pontszámot érte el, 0,7830', 'it': "Questo articolo presenta una delle prime cinque soluzioni vincenti per il compito condiviso sul sarcasmo e la rilevazione dei sentimenti in arabo (Subtask-1 Sarcasm Detection). L'obiettivo del compito è identificare se un tweet è sarcastico o meno. La nostra soluzione è stata sviluppata utilizzando la tecnica ensemble con modello pre-addestrato AraBERT. Descriviamo l'architettura della soluzione presentata nell'attività condivisa. Forniamo anche gli esperimenti e la sintonizzazione degli iperparametri che portano a questo risultato. Inoltre, discutiamo e analizziamo i risultati confrontando tutti i modelli che abbiamo addestrato o testato per ottenere un punteggio migliore nella progettazione di un tavolo. Il nostro modello si classifica quinto su 27 squadre con un punteggio F1 di 0,5985. Vale la pena ricordare che il nostro modello ha ottenuto il punteggio di precisione più alto di 0,7830", 'lt': 'Šiame dokumente pateikiamas vienas iš penkių geriausių laimėtojų sprendimų bendrai užduotims dėl sarkazmo ir jautrumo nustatymo arabų kalba (Sarkazmo nustatymas 1-ajame posėdyje). The goal of the task is to identify whether a tweet is sarcastic or not.  Our solution has been developed using ensemble technique with AraBERT pre-trained model.  We describe the architecture of the submitted solution in the shared task.  Taip pat teikiame eksperimentus ir hiperparametrų koregavimą, kurie lemia šį rezultatą. Besides, we discuss and analyze the results by comparing all the models that we trained or tested to achieve a better score in a table design.  Our model is ranked fifth out of 27 teams with an F1 score of 0.5985.  Verta paminėti, kad mūsų model is pasiekė aukščiausią tikslumą 0,7830', 'ms': 'Kertas ini memperkenalkan salah satu dari lima solusi yang menang untuk Tugas Berkongsi tentang Sarkasm dan Pengesanan Sentiment dalam bahasa Arab (Pengesanan Sarkasm Subtask-1). Tujuan tugas adalah untuk mengenalpasti sama ada tweet sarkastik atau tidak. Solusi kita telah dikembangkan menggunakan teknik ensemble dengan model terlatih AraBERT. Kami menggambarkan arkitektur penyelesaian yang dihantar dalam tugas berkongsi. Kami juga menyediakan eksperimen dan penyesuaian hyperparameter yang membawa kepada hasil ini. Besides, we discuss and analyze the results by comparing all the models that we trained or tested to achieve a better score in a table design.  Our model is ranked fifth out of 27 teams with an F1 score of 0.5985.  It is worth mentioning that our model achieved the highest accuracy score of 0.7830', 'kk': 'Бұл қағаз саркассм және сентимен тапсырманы араб тілінде ортақтастыру тапсырмасының ең жоғары бес жоғары шешімдерінің бірін көрсетеді (Subtask- 1 Sarcasm Detection). Тапсырманың мақсаты - tweet саркастикалық не емес дегенді анықтау. Біздің шешіміміз АраBERT бағытталған үлгі арқылы ензембл техникалық арқылы жасалған. Біз жіберілген шешімінің архитектурасын ортақ тапсырмасында таңдаймыз. Біз сондай-ақ осы нәтижеге көмектесетін эксперименттерді және гиперпараметрлерді баптауға арналадық. Қосымша, біз кесте дизайнында жақсы нәтижелерді салыстырып, оқыту не сынап көрген үлгілерді салыстырып, нәтижелерді талқылап анализирақ. Біздің үлгіміз 27 топтың бесінші ретінде 0,5985 деген F1 нөмірі бар. Өзіміздің үлгіміз 0,7830 деген ең дұрыс нәтижесін жеткіздік.', 'mt': 'Dan id-dokument jippreżenta waħda mill-ħames soluzzjonijiet rebbieħa għall-Kompitu Konġunt dwar is-Sarkazmu u s-Sejbien tas-Sentimenti fl-Għarab (Sejbien tas-Sarkazmu Subkompitu-1). L-għan tal-kompitu huwa li jiġi identifikat jekk tweet huwiex sarkastiku jew le. Is-soluzzjoni tagħna ġiet żviluppata bl-użu ta’ teknika ta’ ensemble b’mudell imħarreġ minn qabel b’AraBERT. We describe the architecture of the submitted solution in the shared task.  Aħna nipprovdu wkoll l-esperimenti u l-aġġustament tal-iperparaturi li jwasslu għal dan ir-riżultat. Barra minn hekk, niddiskutu u janalizzaw ir-riżultati billi nqabblu l-mudelli kollha li tħarrġu jew ittestjawna biex niksbu punteġġ a ħjar f’disinn ta’ tabella. Our model is ranked fifth out of 27 teams with an F1 score of 0.5985.  Ta’ min isemmi li l-mudell tagħna kiseb l-ogħla punteġġ ta’ preċiżjoni ta’ 0.7830', 'mn': 'Энэ цаас Сарказм болон Сентимент Араб (Subtask-1 Sarcasm Detection) дээрх хамгийн их таван ялагдах шийдэлүүдийн нэгийг харуулдаг. Энэ ажлын зорилго бол tweet нь сайхан эсэхийг мэдэх. Бидний шийдэл АраBERT-ын өмнө сургалтын загвартай эмзэг техник ашиглан хөгжигдсэн. Бид хуваалцагдсан ажлын шийдлийн архитектурыг тайлбарлаж байна. Мөн бид энэ үр дүнд хүргэх туршилтуудыг болон гиперпараметрыг дамжуулдаг. Үүнээс гадна бид ширээний дизайнд илүү сайн оноо гаргахад сургалтын эсвэл шалгалтын бүх загваруудыг харьцуулж, үр дүнг талаар ярилцдаг. Бидний загвар нь 27 багтаас 5 дахь хэмжээтэй F1 0.5985. Бидний загвар нь 0.7830-ын хамгийн өндөр тодорхойлолт хүртэл', 'pl': 'W artykule przedstawiono jedno z pięciu najlepszych rozwiązań dla wspólnego zadania dotyczącego wykrywania sarkazmu i sentymentów w języku arabskim (Subtask-1 wykrywanie sarkazmu). Celem zadania jest określenie, czy tweet jest sarkastyczny, czy nie. Nasze rozwiązanie zostało opracowane przy użyciu techniki zespołu z wstępnie przeszkolonym modelem AraBERT. Opisujemy architekturę zgłoszonego rozwiązania w ramach wspólnego zadania. Zapewniamy również eksperymenty i strojenie hiperparametrów, które prowadzą do tego wyniku. Ponadto omawiamy i analizujemy wyniki porównując wszystkie modele, które przeszkololiśmy lub testowaliśmy, aby osiągnąć lepszy wynik w projekcie tabeli. Nasz model jest piąty spośród 27 drużyn z wynikiem F1 0,5985. Warto wspomnieć, że nasz model osiągnął najwyższy wynik dokładności 0.7830', 'no': 'Denne papiret viser ein av dei øvste fem vinnende løysingane for den delte oppgåva på Sarkasm- og Sentiment- oppdaginga i arabisk (Subtask- 1 Sarkasm- oppdaging). Målet på oppgåva er å identifisera om ein tweet er sarkastisk eller ikkje. Løsningen vårt er utvikla med ensemble-teknikk med AraBERT-føretrained modell. Vi skildrar arkitekturen til den sendte løysinga i den delte oppgåva. Vi tilbyr også eksperimentene og hyperparameter-innstillingane som fører til denne resultatet. I tillegg diskuterer vi og analyserer resultatet ved å sammenligne alle modelane vi trenga eller testa for å oppnå eit bedre poeng i ei tabelldesign. Modellen vårt er rankert femte av 27 grupper med eit F1- poeng med 0,5985. Det er verdt å avgjere at modellen vår oppnådd den høgste nøyaktighetspoeng på 0,7830', 'ml': 'ഈ പത്രത്തില്\u200d അഞ്ച് മുകളില്\u200d വിജയിക്കുന്ന പരിഹാരങ്ങളില്\u200d ഒരെണ്ണം സർക്കാസം, അറബിയിലെ സെന്റിമെന്റ് ഡിറ്റക്റ്റീഷനും (സബ്ബസ്- ഈ ജോലിയുടെ ലക്ഷ്യം ഒരു ടൂട്ടിയുടെ വിഷയത്തിലാണോ അല്ലെങ്കില്\u200d നിരീക്ഷിക്കുക എന്നതാണ്. നമ്മുടെ തീരുമാനം അറബെര്\u200dട്ടിയുടെ മുന്നില്\u200d പരിശീലിക്കപ്പെട്ട മോഡല്\u200d ഉപയോഗിച്ചു നമ്മള്\u200d പങ്കുചേര്\u200dന്ന ജോലിയില്\u200d സമ്മതിച്ച പരിഹാരത്തിന്റെ ആര്\u200dക്കിട്ടറി വിശദീകരിക്കുന്നു. നമ്മള്\u200d പരീക്ഷിക്കുന്ന പരീക്ഷണങ്ങളും ഹൈപ്പര്\u200dപാരാമീറ്റര്\u200d ടൂണിങും നല്\u200dകുന്നു. അതിനു ശേഷം, നമ്മള്\u200d പരിശീലിച്ച എല്ലാ മോഡലുകളെയും പരിശോധിക്കുകയോ ചെയ്ത് ഒരു ടേബിള്\u200d ഡിസൈനില്\u200d നല്ല സ്കോര്\u200d പ്രാപിക്കാന്\u200d പരീ ഞങ്ങളുടെ മോഡല്\u200d 27 ടീമില്\u200d നിന്നും അഞ്ചാമത്തേത് റെഞ്ച് ചെയ്തിരിക്കുന്നു. ഒരു എഫ്1 സ്കോര്\u200d 0.5985. നമ്മുടെ മോഡല്\u200d 0.7830 ന്റെ ഏറ്റവും കൃത്യതയുള്ള സ്കോര്\u200d എത്തിയതാണെന്ന് പറയുന്നത് വിലയാണ്.', 'mk': 'Овој весник претставува едно од првите пет победнички решенија за заедничката задача за сарказам и детективирање на чувствата на арапски (детективирање на сарказам-1). Целта на задачата е да се идентификува дали твитот е саркастичен или не. Нашето решение е развиено користејќи техника на ансембл со предобучен модел на Араберт. Ја опишуваме архитектурата на поднесеното решение во заедничката задача. Исто така ги обезбедуваме експериментите и хиперпараметрите кои водат до овој резултат. Покрај тоа, разговараме и ги анализираме резултатите споредувајќи ги сите модели кои ги трениравме или ги тестиравме за да постигнеме подобра оценка во дизајнот на масата. Нашиот модел е рангиран на петти од 27 тимови со оценка од 0,5985. Вреди да се спомнува дека нашиот модел постигна највисока точност од 0,7830', 'si': 'මේ පැත්තේ සාර්කාස්ම් වල සහ සංවිධාන කාර්යයේ සම්බන්ධ වැඩක් සහ සංවිධාන සොයාගන්න අරාබි වල (Subjob-1 Sarcasm හොයාගන්න). වැඩේ ඉලක්කය තමයි ට්විට් එකක් සාර්කාසික් කියලා හොයාගන්න. අපේ විස්තරය අරාබෙර්ට් වලින් ප්\u200dරශ්නයක් තියෙන්නේ ඇන්ස්මෙන්බ්ල් තාක්ෂණය ප්\u200dරයෝජනය කරන්න. අපි විස්තර කරන්නේ කැමතියි වැඩක් තියෙන්නේ විස්තර විස්තර ක්\u200dරියාවේ. අපි පරීක්ෂණය සහ හායිපර් ප්\u200dරමාණය සම්බන්ධ කරන්න පුළුවන් වෙනවා මේ ප්\u200dරතිචාරයට. ඒ වගේම, අපි ප්\u200dරතිචාරය සහ විශ්ලේෂණය කරනවා විශ්ලේෂණය කරනවා අපි ප්\u200dරධානය කරපු හෝ පරීක්ෂණය කරපු හැම මොඩේල්ලම් එක අපේ මෝඩේල් එකේ පහත්වෙනි කණ්ඩායම් 27 වල ඉන්නේ F1 ස්කෝර් 0.5985 වලින්. ඒක කියන්න වැඩි තියෙන්නේ අපේ මොඩල් එක 0.7830 වලින් සිද්ධ විශේෂතාවක් ලැබුනා කියලා.', 'so': 'Qoraalkan waxaa ka mid ah mid ka mid ah shanta ugu sarreeya oo guulaysan xalalka shaqada la sharciyey Sarcasm iyo garsoorida Sentiment ee Carabiga (Subtask-1 Sarcasm Detection). Ujeedada shaqadu waa in la caddeeyo in twiti uu yahay sarkisiin ama aysan aheyn. Xaruntayada waxaa la horumariyey isticmaalka teknikada la xiriiray AraBERT model horay loo tababaray. Waxaynu sawiraynaa dhismeedka la soo dhiibay shaqada wadajirka ah. Waxaynu sidoo kale siinaynaa imtixaanka iyo imtixaanka heerka ee sababta ah. Taas waxaa kaloo, waxaynu kala sheekeynaynaa oo analyeynaa resultiyada, si aan u barno noocyada aan ku tababarinnay ama ku tijaabinnay si aan u helno scor ka fiican qorshaha miiska. Tusaalkayaga waxaa laga dhigay shan koox oo ka mid ah 27 koox, koox F1 oo ah 0.5985. Waxaa muhiim ah in la sheego in modellkayagu gaadhay scorka ugu sarreeya saxda 0.7830', 'ro': 'Această lucrare prezintă una dintre primele cinci soluții câștigătoare pentru sarcasmul comun și detectarea sentimentelor în arabă (Subtask-1 Sarcasm Detection). Scopul sarcinii este de a identifica dacă un tweet este sarcastic sau nu. Soluția noastră a fost dezvoltată folosind tehnica ansamblului cu modelul pre-instruit AraBERT. Descriem arhitectura soluției trimise în sarcina partajată. De asemenea, oferim experimentele și reglarea hiperparametrului care duc la acest rezultat. În plus, discutăm și analizăm rezultatele prin compararea tuturor modelelor pe care le-am instruit sau testat pentru a obține un scor mai bun într-un design de tabel. Modelul nostru este clasat pe locul cinci din 27 de echipe cu un scor F1 de 0,5985. Merită menționat faptul că modelul nostru a obținut cel mai mare scor de precizie de 0.7830', 'ur': 'This paper presents one of the top five winning solutions for the Shared Task on Sarcasm and Sentiment Detection in Arabic (Subtask-1 Sarcasm Detection). اس کام کا موقع یہ ہے کہ ایک ٹویٹ کو معلوم کرنا چاہے یا نہ ہو۔ ہمارا حل آراBERT سے پہلے آموزش کی موڈل کے مطابق انکسمبل ٹیکنیک کے استعمال سے توسعہ کیا گیا ہے. ہم مشترک کام میں مسلسل حل کے معمار کا ساختار بیان کرتے ہیں۔ ہم نے آزمائش اور ہیپر پارامیٹ ٹونگ کو بھی پیدا کیا ہے جو اس نتیجہ کی طرف پہنچاتا ہے۔ اس کے علاوہ ہم نے نتیجے کا بحث اور تحقیق کرلیا اور تمام نمڈلوں کو جو ہم نے تدریس کی یا آزمائش کی تھی ایک ٹیبل ڈیزانین میں بہتر اسکور پہنچانے کے لئے۔ ہماری مدل 27 ٹیموں میں سے پانچویں جماعت ہے جو 0.5985 کی F1 اسکور کے ساتھ ہے یہ مطلب ہے کہ ہماری مدل 0.7830 کے سب سے بالاترین دقیقیت کا امتیاز پہنچ گیا ہے', 'sv': 'Denna uppsats presenterar en av de fem bästa vinnande lösningarna för Shared Task on Sarkasm and Sentiment Detection på arabiska (Subtask-1 Sarkasm Detection). Målet med uppgiften är att identifiera om en tweet är sarkastisk eller inte. Vår lösning har utvecklats med hjälp av ensembleteknik med AraBERT färdigutbildad modell. Vi beskriver arkitekturen för den inlämnade lösningen i den delade uppgiften. Vi tillhandahåller också de experiment och hyperparameter tuning som leder till detta resultat. Dessutom diskuterar och analyserar vi resultaten genom att jämföra alla modeller som vi tränat eller testat för att uppnå en bättre poäng i en bordsdesign. Vår modell rankas femte av 27 lag med en F1 poäng på 0,5985. Det är värt att nämna att vår modell uppnådde högsta noggrannhetspoäng på 0,7830', 'sr': 'Ovaj papir predstavlja jednu od najvećih pet pobjedničkih rješenja za zajednički zadatak o detekciji sarkasma i sentimenta na arapskom (detekcija sarkasma podtask-1). Cilj zadatka je da identifikujemo da li je tweet sarkastičan ili ne. Naše rešenje je razvijeno koristeći tehniku ensemble sa predobučenim modelom AraBERT. Mi opisujemo arhitekturu predanog rješenja u zajedničkom zadatku. Takođe pružamo eksperimente i hiperparametru koji vode do ovog rezultata. Osim toga, razgovaramo i analiziramo rezultate uspoređivanjem svih modela koje smo obučili ili testirali kako bi postigli bolji rezultat u dizajnu stola. Naš model je peti od 27 ekipa sa rezultatom F1 od 0,5985. Vrijedno je spomenuti da je naš model postigao najviši tačniji rezultat 0,7830', 'ta': 'இந்த தாள் சார்காஸ்ம் மற்றும் சென்டிமென்ட் கண்டுபிடிப்பு அரபி மொழியில் பகிர்ந்த செயலுக்கான மேல் ஐந்து வெற்றி தீர்வுகள்  இந்த பணியின் இலக்கு ஒரு தொடர் சிரமமா அல்லது இல்லை என்பதை கண்டுபிடிக்க வேண்டும். ஆராபெர்ட் முன் பயிற்சி மாதிரியை பயன்படுத்தி எங்கள் தீர்வு உருவாக்கப்பட்டது. நாம் பங்கிடப்பட்ட பணியில் கூட்டிய தீர்வுகளின் அட்டவணையை விவரிக்கிறோம். இந்த முடிவிற்கு கொண்டிருக்கும் சோதனைகளையும் அளபுருக்களையும் நாம் வழங்குகிறோம். அதற்கும் தவிர, நாம் முடிவுகளை விவாதம் மற்றும் ஆராய்வு செய்து முடிவுகளை ஒரு மேசை வடிவமைப்பில் சிறந்த மதிப்பெண்ணை பெற மாத எங்கள் மாதிரி 27 குழுக்களில் ஐந்தாவது நிறுவப்பட்டுள்ளது ஒரு F1 மதிப்பு 0.5985. It is worth mentioning that our model achieved the highest accuracy score of 0.7830', 'uz': "Bu qogʻoz Sarkasm va Sentiment Tayyorligini Arabda qidirish uchun eng 5 ta yuqori muvaffaqiyatlarni koʻrsatiladi (1 Sarkasm qidirish). Vazifaning maqsadi, Twitter sarkastik yoki emas, aniqlash. Bizning qiymiz araBERT pre-trained modeli bilan birinchi tekniki ishlatilgan edi. Biz qizilgan vazifani qo'shilgan muammolarning arxituvchisini anglatamiz. Biz bu natijaga sababchi tizim va hyperparametr yordam beramiz. Ko'pchilik, biz jadvali dizayni bajarish yoki o'rganish uchun hamma modellarni o'rganish uchun o'rganish va natijalarni analyzmaymiz. Bizning modelmiz 27 guruhdan 5 dan boshlanadi 0.5985ning F1 scori bilan. Bu qiymati, modelmiz 0.7830 ning eng eng yaxshi darajaga erishilgan", 'vi': 'Tờ giấy này giới thiệu một trong năm giải pháp thắng lợi hàng đầu cho tập đoàn tìm kiếm âm mưu về Sarcasm và cảm xúc bằng tiếng Ả rập (giấu-1 mặt thám tử Sarcasm). Mục tiêu của nhiệm vụ này là xác định tweet có mỉa mai hay không. Các giải pháp của chúng tôi được phát triển bằng nhạc chung với AraBERT đã được huấn luyện sẵn. Chúng tôi mô tả kiến trúc của giải được đưa ra trong nhiệm vụ chung. Chúng tôi cung cấp các thí nghiệm và độ cấp siêu tham số dẫn đến kết quả này. Hơn nữa, chúng ta thảo luận và phân tích kết quả bằng cách so sánh tất cả các mẫu chúng ta đã đào tạo hoặc thử để đạt điểm số tốt hơn trong thiết kế bàn. Mẫu của chúng tôi được xếp hạng thứ năm ở ngoài tàu 27 với điểm F1 của 0.5985. Đáng đề cập đến việc mẫu của chúng ta đạt được tỉ số chính xác cao nhất', 'bg': 'Настоящата статия представя едно от петте печеливши решения за Споделена задача по откриване на сарказъм и сентименти на арабски език (Подзадача-1 откриване на сарказъм). Целта на задачата е да се определи дали туитът е саркастичен или не. Нашето решение е разработено с помощта на ансамбълна техника с предварително обучен модел. Описваме архитектурата на подаденото решение в споделената задача. Предоставяме и експериментите и настройките на хиперпараметрите, които водят до този резултат. Освен това обсъждаме и анализираме резултатите чрез сравняване на всички модели, които сме обучавали или тествали, за да постигнем по-добър резултат в дизайна на таблицата. Нашият модел се класира на пето място от 27 отбора с резултат от 0.5985. Заслужава да се отбележи, че нашият модел постигна най-високата оценка на точност от 0.7830', 'nl': 'Dit artikel presenteert een van de top vijf winnende oplossingen voor de Shared Task on Sarcasm and Sentiment Detection in Arabic (Subtask-1 Sarcasm Detection). Het doel van de taak is om vast te stellen of een tweet sarcastisch is of niet. Onze oplossing is ontwikkeld met behulp van ensemble techniek met AraBERT voorgetraind model. We beschrijven de architectuur van de ingediende oplossing in de gedeelde taak. We verzorgen ook de experimenten en de hyperparameter tuning die tot dit resultaat leiden. Daarnaast bespreken en analyseren we de resultaten door alle modellen die we hebben getraind of getest te vergelijken om een betere score te behalen in een tafelontwerp. Ons model staat op de vijfde plaats van 27-teams met een F1-score van 0.5985. Het is vermeldenswaard dat ons model de hoogste nauwkeurigheidsscore van 0.7830 behaalde', 'da': 'Denne artikel præsenterer en af de fem bedste vindende løsninger til den delte opgave om sarkasme og følelsesdetektion på arabisk (Subtask-1 Sarkasm Detection). Målet med opgaven er at identificere, om et tweet er sarkastisk eller ej. Vores løsning er udviklet ved hjælp af ensemble teknik med AraBERT prætrænet model. Vi beskriver arkitekturen af den indsendte løsning i den delte opgave. Vi leverer også de eksperimenter og hyperparameter tuning, der fører til dette resultat. Desuden diskuterer og analyserer vi resultaterne ved at sammenligne alle de modeller, vi har trænet eller testet for at opnå en bedre score i et borddesign. Vores model er placeret femte ud af 27 hold med en F1 score på 0,5985. Det er værd at nævne, at vores model opnåede den højeste nøjagtighed score på 0,7830', 'hr': 'Ovaj papir predstavlja jednu od najvećih pet pobjedničkih rješenja za zajednički zadatak o otkrivanju sarkasma i sentimenta na arapskom jeziku (otkrivanje sarkasma podtask-1). Cilj zadatka je identificirati je li tweet sarkastičan ili ne. Naša rješenje je razvijena koristeći ensemble tehniku s predobučenim modelom AraBERT-a. Opišemo arhitekturu podanih rješenja u zajedničkom zadatku. Također pružamo eksperimente i hiperparametre koji vode do ovog rezultata. Osim toga, razgovaramo i analiziramo rezultate uspoređivanjem svih modela koje smo obučili ili testirali kako bi postigli bolji rezultat u dizajnu stola. Naš model je određen peti od 27 ekipa sa rezultatom F1 od 0,5985. Vrijedno je spomenuti da je naš model postigao najviši točniji rezultat 0,7830', 'de': 'Dieser Beitrag stellt eine der fünf besten Lösungen für die Shared Task on Sarkasm and Sentiment Detection in Arabic (Subtask-1 Sarkasm Detection) vor. Ziel der Aufgabe ist es herauszufinden, ob ein Tweet sarkastisch ist oder nicht. Unsere Lösung wurde in Ensembletechnik mit AraBERT vortrainiertem Modell entwickelt. Wir beschreiben die Architektur der eingereichten Lösung in der gemeinsamen Aufgabe. Wir liefern auch die Experimente und die Hyperparameter-Abstimmung, die zu diesem Ergebnis führen. Außerdem diskutieren und analysieren wir die Ergebnisse, indem wir alle Modelle vergleichen, die wir trainiert oder getestet haben, um eine bessere Punktzahl in einem Tischdesign zu erzielen. Unser Modell ist Fünfter von 27-Teams mit einer F1-Punktzahl von 0.5985. Es ist erwähnenswert, dass unser Modell die höchste Genauigkeit von 0.7830 erreicht hat', 'id': 'Kertas ini mempersembahkan salah satu dari lima solusi pemenangan terbaik untuk Tugas Bersama tentang Sarkasme dan Deteksi Sentiment dalam bahasa Arab (Deteksi Sarkasme Subtask-1). Tujuan tugas adalah untuk mengidentifikasi apakah tweet sarkastik atau tidak. Solusi kami telah dikembangkan menggunakan teknik ensemble dengan model yang dilatih-dilatih AraBERT. We describe the architecture of the submitted solution in the shared task.  Kami juga menyediakan eksperimen dan tuning hyperparameter yang membawa ke hasil ini. Selain itu, kami mendiskusikan dan menganalisis hasilnya dengan membandingkan semua model yang kami pelatih atau diuji untuk mencapai skor yang lebih baik dalam desain meja. Model kita ditangkap ke-lima dari 27 tim dengan nilai F1 0,5985. Ini layak disebutkan bahwa model kita mencapai skor akurasi tertinggi 0,7830', 'fa': 'این کاغذ یکی از بالای پنج راه حل پیروزی برای کارهای مشترک در مورد بازرسی سارکاسم و شناسایی مجموعه در عربی (بازرسی زیر کار-۱ سارکاسم) را نشان می\u200cدهد. هدف این کار اینه که مشخص کنیم که آیا توئیت سارکاسیک است یا نه. راه حل ما با استفاده از تکنیک انجمل با مدل پیش آموزش AraBERT توسعه شده است. ما معماری راه حل فرستاده در کار مشترک توصیف می کنیم. ما همچنین آزمایش\u200cها و تنظیمات هیپر پارامتر را پیشنهاد می\u200cکنیم که به این نتیجه می\u200cرسد. به علاوه، ما نتیجه\u200cها را با مقایسه کردن تمام مدل\u200cهایی که آموزش دادیم یا امتحان کردیم برای رسیدن یک امتیاز بهتر در طراحی میز بحث و تحلیل می\u200cکنیم. مدل ما پنجم از 27 تیم با امتیاز F1 0.5985 درجه دارد. ارزش این است که مدل ما به بالاترین امتیاز دقیق 0.7830 رسید', 'sw': 'Gazeti hili linaonyesha moja ya suluhisho la ushindi wa mafanikio matano ya juu kwa ajili ya kazi ya kushirikiana kwa Sarcasm na Utafiti wa Seneti kwa Kiarabu (Uchunguzi wa Sarcasm-1). Lengo la kazi ni kutambua kama twiti ni kejeli au la. ufumbuzi wetu umetengenezwa kwa kutumia teknolojia ya mfululizo na muundo wa zamani wa AraBERT. Tunaelezea ujenzi wa suluhisho hilo lililotolewa katika kazi hiyo ya ushirikiano. Pia tunatoa majaribio na wimbi la upasuaji ambalo linasababisha matokeo haya. Zaidi yake, tunajadili na uchambuzi matokeo kwa kulinganisha mifano yote ambayo tuliwafunza au tulijaribu kupata vipimo vizuri katika ubunifu wa meza. Our model is ranked fifth out of 27 teams with an F1 score of 0.5985.  Inastahili kutaja kwamba mifano yetu ilifanikiwa kiwango kikubwa cha sahihi cha 0.7830', 'af': "Hierdie papier stel een van die boonste vyf wen oplossing vir die Gedeelde Opdrag op Sarkasm en Sentiment Opdekking in Arabiese (Subtask-1 Sarcasm Opdekking). Die doel van die taak is om te identifiseer of 'n tweet sarkasies is of nie. Ons oplossing is ontwikkeld deur die gebruik van ensemble tekniks met AraBERT voor-opgelei model. Ons beskryf die arkitektuur van die voorgestuurde oplossing in die gedeelde taak. Ons verskaf ook die eksperimente en die hiperparameter tuning wat lei na hierdie resultaat. Ons bespreek en analiseer die resultate deur die vergelyking van al die modele wat ons opgelei of toegestel het om 'n beter punt in 'n tabel ontwerp te bereik. Ons model is gerankeer vyfde uit 27 teams met 'n F1 punt van 0.5985. Dit is waarde om te meng dat ons model die hoogste presisie telling van 0.7830 bereik het", 'tr': 'Bu kagyz Sarkasm we Sentiment Taýramyň Arapça (Subtask-1 Sarkasm Deteksi) üçin iň üst beş ýeňiji çözümlerden birini tanaýar. Göreviň maksady tweet sarkasy dälmidigini tanyşdyrmak. Biziň çözümüz AraBERT öňünden eğitilen nusga bilen ensemble tekniki ullanýar. Biz bölünen zadyň aýrylan çözümüň arhitekturuny tassyýarys. Biz hem deneyleri hem hiper parametreleri bu neticede ulaşan şekilde temin ediyoruz. Munuň ýagdaýynda, biz täblisaň dizaynynda gowy bir nömert tapmak üçin we üýtgetmek üçin netijelerini taryşdyryp we çözümlendik. Biziň nusgymyz 27 topardan 5-nji derejä 0,5985 derejä bar. Munuň nusgymyzyň 0.7830 iň ýokary takyklygyny bardygyny aýtmagyňyz gerek.', 'sq': 'Ky dokument paraqet një nga pesë zgjidhjet më të mira fituese për Detyrën e Përbashkët mbi Sarkazmin dhe Detektimin e Sentimenteve në Arabisht (Detektimin e Sarkazmit Subtask-1). Qëllimi i detyrës është të identifikohet nëse një tweet është sarkastik apo jo. Zgjidhja jonë është zhvilluar duke përdorur teknikën e ansamblit me modelin e paratrajnuar AraBERT. Ne përshkruajmë arkitekturën e zgjidhjes së paraqitur në detyrën e përbashkët. Ne gjithashtu japim eksperimentet dhe rregullimin e hyperparametrave që shpien në këtë rezultat. Përveç kësaj, ne diskutojmë dhe analizojmë rezultatet duke krahasuar të gjitha modelet që kemi trajnuar apo testuar për të arritur një rezultat më të mirë në një dizajn tabele. Modeli ynë është renditur i pesti nga 27 ekipe me një rezultat F1 prej 0.5985. Vlen të përmendemi se modeli ynë arriti rezultatin më të lartë të saktësisë 0.7830', 'am': 'ይህ ፕሮግራም በሰርካሲም እና ሰንተርናዊ ጥያቄ በዐረብኛ (Subtask-1 Sarcasm Detection) ላይ ላይኞቹ አምስት ድጋፍ ማሸንጎች አንዱን ያቀርባል፡፡ የስራው ጉዳዩ ትዊተር አካባቢ መሆኑን ማረጋገጥ ነው፡፡ መፍትረታችን ከቀድሞ የተማረከ አርብERT ሞዴል ጋር የተጠቃሚ ስህተት ነው፡፡ በተካፈሉት ስራ ውስጥ የተገኘውን መሠረት እናሳውቃለን፡፡ ስለዚህ መፈትነቱን እና የhyperparameter ግንኙነት እናደርጋለን፡፡ በተጨማሪም፣ ፍሬዎቹን በማስተካከል እናስተዋልናለን፡፡ ሞዴሌያችን ከ27 ቡድን አምስተኛ የ.5985 የ. ሞዴሌያችን የ0.7830 ትልቁ እርግጠኛ ደረጃ እንዳገኘን ማስታወስ ይገባዋል፡፡', 'ko': '본고는 아랍어 풍자와 정서적 검측 공유 임무(Subtask-1 풍자 검측)의 5대 수상 솔루션 중 하나를 소개한다.이 임무의 목표는 추문이 풍자적 의미를 지니고 있는지 확인하는 것이다.Dell의 솔루션은 통합 기술과 AraBERT 사전 훈련 모델을 사용하여 개발되었습니다.우리는 공유 임무에서 제출한 해결 방안의 체계 구조를 묘사했다.우리는 또한 이 결과를 야기하는 실험과 초파라미터 조정도 제공했다.그 밖에 우리는 우리가 훈련하거나 테스트한 모든 모델을 비교하여 결과를 토론하고 분석함으로써 표 디자인에서 더욱 좋은 점수를 얻도록 한다.우리 모델은 F1 27개 팀 중 0.5985위에 올랐다.특히 우리 모델은 가장 높은 정확도 점수인 0.7830을 얻었다', 'hy': 'Այս հոդվածը ներկայացնում է լավագույն հինգ հաղթանակի լուծումներից մեկը Սարկազմի և զգացմունքների հայտնաբերման համագործակցության համար արաբերենով (Սարկազմի հայտնաբերման ենթախնդիր-1): Այս խնդիրը նպատակն է պարզել, արդյոք թվիթը սարկաստական է, թե ոչ: Our solution has been developed using ensemble technique with AraBERT pre-trained model.  Մենք նկարագրում ենք ընդհանուր խնդրի ընթացքում առաջարկված լուծության ճարտարապետությունը: Մենք նաև ներկայացնում ենք փորձարկումները և հիպերպարամետրերի կարգավորումը, որոնք հանգեցնում են այս արդյունքին: Ավելին, մենք քննարկում ենք և վերլուծում ենք արդյունքները համեմատելով բոլոր մոդելները, որոնք մենք վարժեցրել ենք կամ ստուգել, որպեսզի ավելի լավ գնահատականներ ստանանք սեղանի դիզայնի մեջ: Մեր մոդելը դասակարգում է հինգերորդ 27 թիմերից, որոնց F1 գնահատականը 0.59 85 է: Արժանի է նշել, որ մեր մոդելը հասավ 0,7830 ճշգրիտության ամենաբարձր գնահատականին,', 'bn': 'এই পত্রিকাটি আরবী ভাষায় শেয়ার করা কাজ এবং সেন্টাইমেন্ট ডিটেক্টরের জন্য সর্বোচ্চ পাঁচটি বিজয়ী সমাধানের একটি সমাধান উপস্থাপন করেছে (স কাজের লক্ষ্য হচ্ছে একটি টুইট বিদ্রোহীত কিনা। আমাদের সমাধান এনস্পেল প্রযুক্তি ব্যবহার করা হয়েছে আরাবেরেটির পূর্ব প্রশিক্ষিত মডেলের সাথে। আমরা শেয়ার কর্মসূচিত সমাধানের কাঠামো বর্ণনা করি। We also provide the experiments and the hyperparameter tuning that lead to this result.  তাছাড়াও, আমরা তার ফলাফল আলোচনা করি এবং বিশ্লেষণ করি একটি টেবিল ডিজাইনে ভালো স্কোর অর্জন করার জন্য যে সমস্ত মডেল প্রশিক্ষণ করেছি অথবা পরীক্ষা  আমাদের মডেল ২৭ টি দলের মধ্যে ৫ টি রেখা হয়েছে যার স্কোর ০. এটা উল্লেখ করার জন্য যে আমাদের মডেলের সর্বোচ্চ সঠিক স্কোর অর্জন করেছে', 'az': 'Bu kağıt Sarkasm və Sentiment Detection ərəbcə (Subtask-1 Sarcasm Detection) paylaşılan işin ən üst beş qənimətli çətinliklərindən birini göstərir. Gözmənin məqsədi tweet sarkastik olub olmadığını təsdiqləməkdir. Bizim çətinliklərimiz AraBERT öyrənmiş modeli ilə ensemble tekniki kullanarak təhsil edildi. Biz təklif edilmiş çətinliklərin arhitektarını paylaşdırırıq. Biz həmçinin bu sonuçta yol göstərən eksperimentləri və hiperparametrləri təmin edirik. Əksinə, biz sonuçları mübahisə edir və analiz edirik, təhsil etdiyimiz və ya sınamadığımız bütün modelləri bir masa dizaynında daha yaxşı nöqtələr tapmaq üçün qarşılaşdırırıq. Bizim modelimiz 27 dəstədən beşinci dəstədir. F1 dəstədir 0,5985. Modelimizin ən yüksək nöqtəsini 0.7830 ilə müəyyən etdiyini xatırlayıb', 'bs': 'Ovaj papir predstavlja jednu od najboljih pet pobjedničkih rješenja za zajednički zadatak o detekciji sarkasma i sentimenta na arapskom jeziku (detekcija sarkasma podtask-1). Cilj zadatka je identifikacija da li je tweet sarkastičan ili ne. Naše rješenje je razvijeno koristeći ensemble tehniku sa predobučenim modelom AraBERT-a. Opišemo arhitekturu predanog rješenja u zajedničkom zadatku. Također pružamo eksperimente i hiperparametre koji vode do ovog rezultata. Osim toga, razgovaramo i analiziramo rezultate uspoređivanjem svih modela koje smo obučili ili testirali kako bi postigli bolji rezultat u dizajnu stola. Naš model je peti od 27 ekipa sa rezultatom F1 od 0,5985. Vrijedno je spomenuti da je naš model postigao najviši rezultat tačnosti od 0,7830', 'cs': 'Tento článek představuje jedno z pěti nejlepších vítězných řešení pro Sdílený úkol o detekci sarkasmu a sentimentu v arabštině (Subtask-1 detekce sarkasmu). Cílem úkolu je zjistit, zda je tweet sarkastický nebo ne. Naše řešení bylo vyvinuto pomocí souborové techniky s předcvičeným modelem AraBERT. Popisujeme architekturu předloženého řešení ve sdíleném úkolu. Poskytujeme také experimenty a hyperparametry ladění, které vedou k tomuto výsledku. Kromě toho diskutujeme a analyzujeme výsledky porovnáním všech modelů, které jsme trénovali nebo testovali, abychom dosáhli lepšího skóre v návrhu tabulky. Náš model je pátý z 27 týmů s F1 skóre 0,5985. Stojí za zmínku, že náš model dosáhl nejvyššího skóre přesnosti 0,7830', 'ca': "Aquest article presenta una de les cinc millors solucions guanyades per la Task Shared on Sarcasm and Sentiment Detection in Arabic (Subtask-1 Sarcasm Detection). L'objectiu de la tasca és identificar si un tweet és sarcàstic o no. La nostra solució s'ha desenvolupat utilitzant tècnica d'ensemble amb un model pré-entrenat AraBERT. Descrivem l'arquitectura de la solució submetida en la tasca compartida. També provem els experiments i l'ajustament hiperparamètric que porten a aquest resultat. Besides, we discuss and analyze the results by comparing all the models that we trained or tested to achieve a better score in a table design.  El nostre model es classe quinta de cada 27 equips amb una puntuació F1 de 0,5985. Val la pena mencionar que el nostre model va aconseguir la puntuació de precisió més alta de 0,7830", 'et': 'Käesolevas artiklis esitatakse üks viiest parimast võitnud lahendusest sarkasmi ja tunnete tuvastamise jagatud ülesande jaoks araabia keeles (alaülesanne-1 sarkasmi tuvastamine). Ülesande eesmärk on tuvastada, kas säuts on sarkastiline või mitte. Meie lahendus on välja töötatud kasutades ansamblitehnikat AraBERT eelkoolitud mudeliga. Kirjeldame esitatud lahenduse arhitektuuri jagatud ülesandes. Samuti pakume katseid ja hüperparameetrite häälestamist, mis viivad selle tulemuseni. Lisaks arutame ja analüüsime tulemusi, võrreldes kõiki mudeleid, mida oleme koolitanud või testinud, et saavutada parem tulemus tabeli disainis. Meie mudel on 27 meeskonnast viiendal kohal F1 skooriga 0,5985. Väärib märkimist, et meie mudel saavutas kõrgeima täpsuskooriga 0,7830', 'fi': 'Tämä artikkeli esittelee yhden viidestä voittaneesta ratkaisusta arabiankielisessä Shared Task on Sarkasm and Sentiment Detection (Subtask-1 Sarkasm Detection). Tehtävän tavoitteena on selvittää, onko twiitti sarkastinen vai ei. Ratkaisumme on kehitetty yhdistelmätekniikalla AraBERT-esikoulutetulla mallilla. Kuvaamme toimitetun ratkaisun arkkitehtuuria jaetussa tehtävässä. Tarjoamme myös kokeet ja hyperparametrien viritys, jotka johtavat tähän tulokseen. Lisäksi keskustelemme ja analysoimme tuloksia vertaamalla kaikkia malleja, joita koulutimme tai testasimme paremman pistemäärän saavuttamiseksi taulukon suunnittelussa. Mallimme sijoittui viidenneksi 27 joukkueesta F1-pisteellä 0,5985. On syytä mainita, että mallimme saavutti korkeimman tarkkuuspisteen 0,7830', 'jv': 'Awasan iki rambarang panjenengan wong liyane ning limo perusahaan kanggo Kemerdekaan Tarang Sarkasm lan Sentiment detection in arab (Subtask-1 Sarkasm detection). Rayongno apa kanggo nggunakake bukane dadi iki tentang sarkasik apa or a. Rasané awakdhéwé wis diuruti nggawe sistem simbol sing berarti araBERT model model model ro-teko. Awak dhéwé ngerwih akeh Arkturaturatura kanggo nyenggawe gerakan nang nggawe gerakan. We tambah ngewehke test podho akeh perusahaan kelompok nggawe barang nggawe ngubah ujaran winih. Nanging, awak dhéwé pisan-saka karo ditambahak lan ujaran dadi nggawe model sing ditambah gak dhéwé nyoteré uga nyoteré nggawe barang kelompok sing luwih apik dhéwé. Ndoleh sing ditambah sing wis digowolèh sing sampek pitik, sing sampek karo F1 kotak 0.5 Punika andhados sing paling nggambar dadi model nambarang kelas ping 0.5830', 'he': 'העיתון הזה מציג אחד מחמשת הפתרונות המנצחים ביותר עבור המשימה המשותפת על סרקזם וגילוי רגשות בערבית (גילוי סרקזם Subtask-1). המטרה של המשימה היא לזהות אם טוויט סרקסטי או לא. הפתרון שלנו פותח באמצעות טכניקת אנסמבל עם מודל מאומן מראש ארברט. אנחנו מתארים את הארכיטקטורה של הפתרון המועבר במשימה המשותפת. אנחנו גם מספקים את הניסויים ואת התרגיל היפרפרמטרי שמוביל לתוצאה הזאת. חוץ מזה, אנחנו מדברים ונבחנים את התוצאות על ידי להשוות את כל הדוגמנים שאימינו או בדקנו כדי להשיג נקודה טובה יותר בעיצוב שולחן. המודל שלנו מוצב חמישי מתוך 27 קבוצות עם נקודת F1 של 0.5985. שווה להזכיר שהמודל שלנו השיג את נקודת הדיוק הגבוהה ביותר של 0.7830', 'ha': "This paper presents one of the top five winning solutions for the Shared Task on Sarcasm and Sentiment Detection in Arabic (Subtask-1 Sarcasm Detection).  Yagon aikin ni ne ka gane shin wata na'ura ta zama sarcasti ko ba. An buɗe suluyinmu da mai amfani da tamko na AraBERT da misalin wanda aka yi wa zaman shirin da shi. Tuna bayyana arziki na da sulfin da aka cika a cikin aikin da aka raba shi. Kayya, Munã samar da jarrabai da sanyi na Hyperparameter da ke gabatar da wannan. Bayan haka, muna jãyayya kuma mu yi anayyar fassaran a sami-sami duk misãlai da muka sanar da su ko kuma aka jarraba su sami mafiya kyakkyawan score cikin wani zabanci. Ana dangane misalinmu shan daga jama'a 27 na F1 mai nau'in 0.5985. Ina kamata a tuna cewa misalinmu ya sami matsayin taƙaitacce na 0.7830", 'bo': 'ཤོག་བྱང་འདིས་མའི་རྒྱལ་ཁབ་མི་དང་མཉམ་དུ་རྒྱ་ཅག་གི་ཐབས་ཤེས་ཐོག་ལས་གཞན་ཞིག་སྟོན་པ་ཡིན། ལས་འགུལ་གྱི་དམིགས་ཡུལ་ནི་tweet་ཞིག་ཡིན་མིན་དགོས་མིན་འདུག ང་ཚོའི་ཐབས་ཤེས་འདི་(AraBERT)སྔོན་གྲངས་སྒྲིག་འཛུགས་ཀྱི་ཐབས་ལམ་ལུགས་ཀྱིས་གསར་བསྐྲུན་བྱས་པ་ཡིན། ང་ཚོས་དུས་མཐུན་གྱི་བྱ་འགུལ་ནང་དུ་འཇུག་ཡོད་པའི་ཐབས་ཤེས་ཀྱི་བཟོ་བཀོད་བྱེད་སྲིད་དམ། We also provide the experiments and the hyperparameter tuning that leads to this result. Besides, we discuss and analyze the results by comparing all the models that we trained or tested to achieve a better score in a table design. ང་ཚོའི་མིག ང་ཚོའི་མིག་གཟུགས་གྱི་ཚད་ལྟར་ཚད་དམའ་ཕྱོགས་ཡོད།7830 དེ་རིང་མཐོང་བ་ཞིག་ཡོད།', 'sk': 'Ta prispevek predstavlja eno izmed petih najboljših zmagovalnih rešitev za skupno nalogo o sarkazmu in zaznavanju čustev v arabščini (Podnaloga-1 zaznavanje sarkazma). Cilj naloge je ugotoviti, ali je tweet sarkastičen ali ne. Naša rešitev je bila razvita z uporabo ensemble tehnike s predhodno usposobljenim modelom AraBERT. Opisujemo arhitekturo oddane rešitve v skupnem opravilu. Zagotavljamo tudi poskuse in nastavitev hiperparametrov, ki vodijo do tega rezultata. Poleg tega razpravljamo in analiziramo rezultate s primerjavo vseh modelov, ki smo jih usposobili ali testirali, da bi dosegli boljši rezultat v oblikovanju tabele. Naš model se uvršča na peto izmed 27 ekip z rezultatom F1 0,5985. Omeniti je treba, da je naš model dosegel najvišjo točnostno oceno 0,7830'}
{'en': 'Sarcasm and Sentiment Detection in Arabic language A Hybrid Approach Combining Embeddings and Rule-based Features', 'ar': 'كشف السخرية والمشاعر في اللغة العربية نهج هجين يجمع بين الزخارف والميزات القائمة على القواعد', 'fr': 'Détection du sarcasme et des sentiments en langue arabe Une approche hybride combinant intégration et fonctionnalités basées sur des règles', 'es': 'Detección de sarcasmo y sentimientos en árabe Un enfoque híbrido que combina incrustaciones y funciones basadas en reglas', 'zh': '阿拉伯语刺情检合,混于法则', 'pt': 'Detecção de sarcasmo e sentimento em árabe Uma abordagem híbrida que combina recursos incorporados e baseados em regras', 'hi': 'अरबी भाषा में व्यंग्य और भावना का पता लगाना एम्बेडिंग और नियम-आधारित विशेषताओं के संयोजन वाला एक हाइब्रिड दृष्टिकोण', 'ru': 'Обнаружение сарказма и сентиментов в арабском языке Гибридный подход, объединяющий вложения и функции, основанные на правилах', 'ja': 'アラビア語の皮肉と感情の検出埋め込みとルールベースの機能を組み合わせたハイブリッドアプローチ', 'ga': 'Sarcasm agus Brath Meon i dteanga Araibis Cur Chuige Hibrideach a Chomhcheanglaíonn Leabaithe agus Gnéithe Bunaithe ar Riail', 'ka': 'საპკასმი და სენტიმენტი განსახულება აპაბიური ენაში A ჰიბრიდის გადაწყვეტილი შებრუნებები და კონფიგური განსახულებები', 'el': 'Σαρκασμός και ανίχνευση συναισθημάτων στην αραβική γλώσσα Μια υβριδική προσέγγιση που συνδυάζει ενσωμάτωση και χαρακτηριστικά βασισμένα σε κανόνες', 'hu': 'Szarkazmus és érzékelés arab nyelven Hibrid megközelítés a beágyazások és a szabályalapú funkciók kombinálásával', 'kk': 'Саркассм және сентиментті араб тілінде анықтау', 'it': 'Rilevamento del sarcasmo e dei sentimenti in lingua araba Un approccio ibrido che combina incorporazioni e caratteristiche basate su regole', 'lt': 'Sarkazmas ir jausmų nustatymas arabų kalba Hibridinis metodas, derinantis įrangą ir taisyklių pagrindu grindžiamas savybes', 'ml': 'സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റീഷന്\u200d അറബിഭാഷയിലെ ഒരു ഹൈബ്രിഡിങ്ങുകളും നിയമപരമായ വിഭാഗങ്ങളും', 'mk': 'Детектирање на сарказмот и чувствата на арапски јазик Хибриден пристап кој комбинира вградувања и власти базирани на правила', 'ms': 'Pengesanan Sarkasme dan Sentiment dalam bahasa Arab A Hybrid Approach Combining Embedding and Rule-based Features', 'mt': 'Sarkazmu u Sejbien tas-Sentiment fil-lingwa Għarbija Approċċ ibridu li jgħaqqad l-Embeddings u l-Karatteristiċi bbażati fuq ir-Regoli', 'pl': 'Sarkazm i wykrywanie sentymentów w języku arabskim Hybrydowe podejście łączące osadzenia i funkcje oparte na regułach', 'ro': 'Detectarea sarcasmului și sentimentelor în limba arabă O abordare hibridă care combină încorporarea și caracteristicile bazate pe reguli', 'si': 'Sarcasm and Sentiment Detection in Arab language A hybri approach Combining Embeading and Rule-based Featuries', 'mn': 'Араб хэл дээр салбар болон сэтгэл санаа олж мэдэх A Hybrid Approach Combining Embeddings, Rule-based Features', 'so': 'Sarcasm and Sentiment Detection afka Carabi A Hybrid Approach Combining Embedding and Rule-based Features', 'no': 'Oppdaging av sarkasm og sentiment i arabisk språk A Hybrid Approach Combining Embedding and Rule-based Features', 'sv': 'Sarkasm och känslodetektering på arabiska språket En hybrid metod som kombinerar inbäddade funktioner och regelbaserade funktioner', 'ta': 'Sarcasm and Sentiment Detection Arabic language A Hybrid Approach Combining Embedding and Rule- based Features', 'ur': 'Sarcasm and Sentiment Detection in Arabic language A Hybrid Approach Combining Embeddings and Rule-based Features', 'sr': 'Sarkazam i otkrivanje sentimenta na arapskom jeziku Hibridni pristup kombinacijskim udruženjima i pravilima', 'vi': 'Phát hiện cảm xúc trong ngôn ngữ Ả Rập A phương pháp hoà trộn các môi trường và các đặc tính quy định', 'uz': 'Name', 'bg': 'Откриване на сарказъм и сентименти на арабски език Хибриден подход, съчетаващ вграждания и базирани на правила функции', 'nl': 'Sarcasme- en gevoelsdetectie in het Arabisch Een hybride aanpak die embeddings en op regels gebaseerde functies combineert', 'hr': 'Označenje sarkasma i osjećajnog otkrića na arapskom jeziku Hibridni pristup kombinacijskim uključenjima i pravilnim karakterima', 'da': 'Sarkasme og følelser detektering på arabisk sprog En hybrid tilgang, der kombinerer indlejringer og regelbaserede funktioner', 'de': 'Sarkasmus und Sentiment Detection in arabischer Sprache Ein hybrider Ansatz, der Einbettungen und regelbasierte Funktionen kombiniert', 'ko': '아랍어 중의 풍자와 감정 검측은 삽입과 규칙에 기초한 특징을 결합한 혼합 방법', 'id': 'Deteksi Sarkasme dan Sentiment dalam bahasa Arab A Hybrid Approach Combining Embeddings and Rule-based Features', 'fa': 'پیدا کردن سارکاسم و سنتی در زبان عربی A Hybrid Approach Combining Embeddings and Rule-based Features', 'sw': 'Uchunguzi wa Kiarabu na Utafiti wa Wakatili kwa lugha ya Kiarabu', 'af': "Sarkasm en Sentiment Opdekking in Arabiese taal 'n Hybrid Toegang Toegang Kombineerde Inbêding en Reël- gebaseerde Funksies", 'sq': 'Sarkazmi dhe zbulimi i ndjenjave në gjuhën arabe Një qasje hibride që kombinon përfshirjet dhe funksionet bazuar në rregulla', 'am': 'አርቢ ቋንቋ A Hybrid Approach Combining Embedding and Rule-based Features', 'hy': 'Սարկազմը և զգացմունքների հայտնաբերումը արաբական լեզվով Հիբրիդ մոտեցումը, որը համադրում է ներգրավված և կանոններով հիմնված առանձնահատկություններ', 'az': 'Arab dilində Sarkasm və Sentiment Detection A Hybrid Approach Combining Embeddings and Rule-based Features', 'tr': 'Senzam we Senzam dilinde bir hybrid A ňlap bilen birleştirilýän guramlar we karara daýanýan özellikler', 'bn': 'Sarcasm and Sentiment Detection in Arabic language A Hybrid Approach Combining Embeddings and Rule-based Features', 'bs': 'Sarkazam i otkrivanje sentimenta na arapskom jeziku Hibridni pristup kombinacijskim udruženjima i pravilnim karakterima', 'fi': 'Sarkasmin ja tunteiden tunnistus arabiankielellä Hybridi lähestymistapa, jossa yhdistyvät upotukset ja sääntöpohjaiset ominaisuudet', 'cs': 'Sarkasmus a detekce citů v arabském jazyce Hybridní přístup kombinující vložení a funkce založené na pravidlech', 'ca': 'Detecció del sarcasme i del sentiment en àrab Un enfocament híbrid combinant incorporacions i característiques basades en les regles', 'et': 'Sarkasmi ja tunnete tuvastamine araabia keeles Hübriidne lähenemisviis, mis ühendab manustamisi ja reeglipõhiseid funktsioone', 'jv': 'Sarkasm and Sentiment detection in an arab language A Hybud Method combining embedding and rule-supported Attributions', 'sk': 'Zaznavanje sarkazma in čustev v arabskem jeziku hibridni pristop, ki združuje vdelave in funkcije, ki temeljijo na pravilih', 'ha': 'KCharselect unicode block name', 'bo': 'Sarcasm and Sentiment Detection in Arabic language A Hybrid Approach Combining Embeddings and Rule-based Features', 'he': 'סרקזם וגילוי רגשות בשפה ערבית גישה היברידית'}
{'en': 'This paper presents the ArabicProcessors team’s system designed for sarcasm (subtask 1) and sentiment (subtask 2) detection shared task. We created a hybrid system by combining rule-based features and both static and dynamic embeddings using transformers and deep learning. The system’s architecture is an ensemble of Naive bayes, MarBERT and Mazajak embedding. This process scored an F1-score of 51 % on sarcasm and 71 % for sentiment detection.', 'es': 'Este artículo presenta el sistema del equipo de ArabicProcessors diseñado para la tarea compartida de detección de sarcasmo (subtarea 1) y sentimiento (subtarea 2). Creamos un sistema híbrido mediante la combinación de funciones basadas en reglas e incrustaciones estáticas y dinámicas mediante transformadores y aprendizaje profundo. La arquitectura del sistema es un conjunto de incrustaciones de Naive bayes, MarBert y Mazajak. Este proceso obtuvo una puntuación F1 de 51% en sarcasmo y 71% en detección de sentimientos.', 'fr': "Cet article présente le système de l'équipe ArabicProcessors conçu pour la tâche partagée de détection du sarcasme (sous-tâche 1) et des sentiments (sous-tâche 2). Nous avons créé un système hybride en combinant des fonctionnalités basées sur des règles et des intégrations statiques et dynamiques à l'aide de transformateurs et de Deep Learning. L'architecture du système est un ensemble d'enchâssements naïfs bayes, MarBert et Mazajak. Ce processus a obtenu un score F1 de 51\xa0% pour le sarcasme et de 71\xa0% pour la détection des sentiments.", 'ja': 'この論文では、アラビア語処理者チームの皮肉（サブタスク1 ）と感情（サブタスク2 ）の検出共有タスクのために設計されたシステムを紹介します。変圧器とディープラーニングを使用したルールベースの機能と静的および動的な埋め込みの両方を組み合わせて、ハイブリッドシステムを作成しました。システムのアーキテクチャは、Naive Bayes、MarBERT、Mazajakの組み込みのアンサンブルです。このプロセスは、皮肉で51%、感情検出で71%のF 1スコアを記録しました。', 'zh': '本文引阿拉伯语处理器团队之统,当专为刺(子1)情(子2)检共事而设计。 吾以转换器深学,则与静合,创一混合系统。 其架构素贝叶斯,MarBERT与Mazajak嵌合。 分刺为51%,检情为71%。', 'ar': 'تقدم هذه الورقة نظام فريق المعالجين العرب المصمم للسخرية (المهمة الفرعية 1) والمشاعر (المهمة الفرعية 2) الكشف عن المهمة المشتركة. أنشأنا نظامًا هجينًا من خلال الجمع بين الميزات المستندة إلى القواعد وكلا من الزخارف الثابتة والديناميكية باستخدام المحولات والتعلم العميق. بنية النظام عبارة عن مجموعة من تضمين Naive bayes و MarBERT و Mazajak. سجلت هذه العملية درجة F1 بنسبة 51٪ على السخرية و 71٪ لاكتشاف المشاعر.', 'pt': 'Este artigo apresenta o sistema da equipe ArabicProcessors projetado para tarefa compartilhada de detecção de sarcasmo (subtarefa 1) e sentimento (subtarefa 2). Criamos um sistema híbrido combinando recursos baseados em regras e embeddings estáticos e dinâmicos usando transformadores e aprendizado profundo. A arquitetura do sistema é um conjunto de Naive bayes, MarBERT e Mazajak embedding. Esse processo obteve uma pontuação F1 de 51% no sarcasmo e 71% na detecção de sentimentos.', 'ru': 'В этой статье представлена система команды ArabProcessors, предназначенная для обнаружения сарказма (подзадача 1) и сентиментальности (подзадача 2). Мы создали гибридную систему, объединив функции, основанные на правилах, и статические и динамические вставки с использованием трансформаторов и глубокого обучения. Архитектура системы представляет собой ансамбль из Naive bayes, MarBERT и Mazajak embedding. Этот процесс набрал 51% баллов F1 по сарказму и 71% по выявлению настроений.', 'hi': 'यह पेपर अरबीप्रोसेसरों की टीम की प्रणाली को व्यंग्य (सबटास्क 1) और भावना (सबटास्क 2) का पता लगाने वाले साझा कार्य के लिए डिज़ाइन किया गया है। हमने नियम-आधारित सुविधाओं और ट्रांसफॉर्मर और गहरी शिक्षा का उपयोग करके स्थैतिक और गतिशील एम्बेडिंग दोनों के संयोजन से एक हाइब्रिड सिस्टम बनाया है। सिस्टम की वास्तुकला भोले bayes, MarBERT और Mazajak एम्बेडिंग का एक पहनावा है। इस प्रक्रिया ने व्यंग्य पर 51% और भावना का पता लगाने के लिए 71% का F1-स्कोर किया।', 'ga': 'Cuireann an páipéar seo i láthair córas na foirne ArabicProcessors atá deartha le haghaidh searbhas (fothasc 1) agus braite meon (fothasc 2) tasc comhroinnte. Chruthaíomar córas hibrideach trí ghnéithe bunaithe ar rialacha agus leabaithe statacha agus dinimiciúla araon a chomhcheangal le trasfhoirmeoirí agus foghlaim dhomhain. Is éard atá in ailtireacht an chórais ná ensemble de chuanta Naive, MarBERT agus Mazajak á neadú. Scóráil an próiseas seo scór F1 de 51% maidir le searbhas agus 71% maidir le meon a bhrath.', 'hu': 'Ez a tanulmány bemutatja az ArabicProcessors csapat szarkazmus (1. részfeladat) és sentiment (2. részfeladat) felismerésére tervezett rendszerét. Hibrid rendszert hoztunk létre a szabályalapú funkciók és a statikus és dinamikus beágyazások kombinációjával transzformátorokkal és mélytanulással. A rendszer architektúrája Naive bayes, Marbert és Mazajak beágyazások együttese. Ez a folyamat 51%-os F1 pontszámot ért el a szarkazmus és 71%-os érzékelés esetén.', 'ka': 'ამ დომენტი აპაბიური პროცესორტების სისტემა, რომელიც საპკასმის (საპკითხები 1) და სენტიმენტის (საპკითხები 2) განახლებისთვის განახლება. ჩვენ ჰიბრიდის სისტემის შექმნა, რომელიც კონფიგურაციების განსაზღვრებით განსაზღვრებით და სტრატიკური და დინამიკური ინტებიზიციების გამოყენებით. სისტემის არქტიქტურაცია ნაიგური ბეიზების, MarBERT და Mazajak-ის ინსტემბლია. ეს პროცესი შეიძლება საპკასმის 51% და 71% სენტიმენტების განახლებისთვის F1 წერტილი.', 'el': 'Η παρούσα εργασία παρουσιάζει το σύστημα της ομάδας σχεδιασμένο για την ανίχνευση σαρκασμού (δευτερεύουσα εργασία 1) και συναισθημάτων (δευτερεύουσα εργασία 2). Δημιουργήσαμε ένα υβριδικό σύστημα συνδυάζοντας χαρακτηριστικά βασισμένα σε κανόνες και στατικές και δυναμικές ενσωματώσεις χρησιμοποιώντας μετασχηματιστές και βαθιά μάθηση. Η αρχιτεκτονική του συστήματος είναι ένα σύνολο Naive bayes, MarBERT και Mazajak ενσωμάτωσης. Αυτή η διαδικασία σημείωσε ένα F1-σκορ 51% στον σαρκασμό και 71% για την ανίχνευση συναισθημάτων.', 'kk': 'Бұл қағаз араб процессор тобының жүйесін саркассм (1- сурет) және (2- сурет) ортақ тапсырманы анықтау үшін құрылған жүйесін көрсетеді. Біз ережелердің негіздеген мүмкіндіктерін және статикалық және динамикалық ендіруді түрлендірушілерді және түрлендіру арқылы гибрид жүйесін жасадық. Жүйеңіздің архитектурасы Naive bayes, MarBERT және Mazajak ендірудің сұлбасы. Бұл процес саркассмда 51% деген F1 нөмірі және 71% сезімді анықтау үшін.', 'it': "Questo articolo presenta il sistema del team ArabicProcessors progettato per il rilevamento di sarcasmo (sottomissione 1) e sentiment (sottomissione 2). Abbiamo creato un sistema ibrido combinando funzionalità basate su regole e incorporazioni statiche e dinamiche utilizzando trasformatori e deep learning. L'architettura del sistema è un insieme di baie Naive, Marbert e Mazajak embedding. Questo processo ha ottenuto un punteggio F1 del 51% sul sarcasmo e del 71% per il rilevamento del sentiment.", 'lt': 'Šiame dokumente pristatoma ArabicProcessors komandos sistema, skirta sarkazmui (1 paklausa) ir jausmams (2 paklausa) aptikti bendrą užduotį. Sukūrėme hibridinę sistemą derindami taisyklėmis pagrįstus požymius ir statinius bei dinamiškus įdėjimus naudojant transformatorius ir gilų mokymąsi. Sistemos architektūra yra Naivo įlankų, MarBERT ir Mazajak įrangos komplektas. Šis procesas parodė F1 rezultatą 51 % sarkazmui ir 71 % jautrumo nustatymui.', 'ml': 'ഈ പത്രത്തില്\u200d സര്\u200dക്കാസം (സബ്ബസ്ക് 1) നിര്\u200dമ്മിക്കപ്പെട്ട അറബിക്പ്രോസറുകളുടെ ടീമിന്റെ സിസ്റ്റം കാണിക്കുന്നു. സബ് നിയമത്തിന്റെ അടിസ്ഥാനത്തിലുള്ള വിശേഷതകളെയും മാറ്റങ്ങളെയും ആഴത്തില്\u200d പഠിക്കുന്നതിനെയും കൂട്ടിചേര്\u200dക്കുന്നതിന സിസ്റ്റത്തിന്റെ ആര്\u200dക്കിക്കറ്റിക്കൂട്ടര്\u200d നാവീസ് ബൈയുടെയും മാര്\u200dബെര്\u200dട്ടിയുടെയും മാസാജാക്കിന്റെയും ഒരു പ ഈ പ്രക്രിയയില്\u200d സർക്കാസം ചെയ്യുന്നതിനുള്ള 51% എഫ്\u200c1 സ്കോര്\u200d സ്കോര്\u200d സ്കോര്\u200d ചെയ്തിരിക്കുന്നു. വികാരണ', 'ms': 'Kertas ini memperkenalkan sistem pasukan ArabicProcessors yang direka untuk tugas terkongsi sarkasm (subtask 1) dan sentimen (subtask 2). Kami mencipta sistem hibrid dengan menggabungkan ciri-ciri berdasarkan peraturan dan kedua-dua penyambungan statik dan dinamik menggunakan pengubah dan belajar dalam. Arkitektur sistem adalah satu kumpulan dari Naive Bayes, MarBERT dan Mazajak embedding. Proses ini mencetak skor F1 51% pada sarkasm dan 71% untuk pengesan perasaan.', 'mk': 'Овој весник го претставува системот на тимот Арапски процесори дизајниран за заедничка задача за детекција на сарказам (подпрашање 1) и чувства (подпрашање 2). Ние создадовме хибриден систем со комбинација на правила базирани карактеристики и статички и динамички вградувања со користење трансформатори и длабоко учење. Архитектурата на системот е ансембл на наивни бајови, марберт и мазајак. Овој процес постигна оценка Ф1 од 51 отсто за сарказмот и 71 отсто за детекција на чувствата.', 'no': 'Denne papiret viser systemet for Arabiske prosessor- gruppa designert for sarkasm (subtask 1) og oppdaging av sentimentar (subtask 2) delt oppgåve. Vi oppretta ein hybrid system ved å kombinere regelbaserte funksjonar og både statiske og dynamiske innbygging med transformarar og dypt læring. Systemarkitekturen er ein ensemble av innbygging av Naive Bayes, MarBERT og Mazajak. Denne prosessen scored an F1- score of 51% on sarcasm and 71% for sentimentoppdaging.', 'mn': 'Энэ цаас Араб Процессорын багийн системийг саркассм (1-р суудал) болон сэтгэл хөдлөл (2-р суудал) мэдрэмж (2-р суудал) нээлттэй ажилд зохион байгуулдаг. Бид гибрид системийг дүрэм дээр суурилсан чадваруудыг нэгтгэж, өөрчлөгчид, гүн гүнзгий сургалтыг ашиглаж байдаг. Энэ системийн архитектур бол Найв, МарBERT, Мазазаак холбогдолтын загвар юм. Энэ үйл явц сэтгэл хөдлөлд 51% болон 71% сэтгэл хөдлөлийг олж мэдсэн.', 'pl': 'W artykule przedstawiono system zespołu ArabicProcessors przeznaczony do wykrywania wspólnego zadania sarkazmu (podzadanie 1) i sentymentu (podzadanie 2). Stworzyliśmy system hybrydowy, łącząc funkcje oparte na regułach i zarówno statyczne, jak i dynamiczne osadzenia za pomocą transformatorów i głębokiego uczenia. Architektura systemu to zespół Naive bayes, MarBERT i Mazajak osadzenia. Proces ten uzyskał wynik F1 51% na sarkazm i 71% dla wykrywania sentymentów.', 'ro': 'Această lucrare prezintă sistemul echipei ArabicProcessors conceput pentru detectarea sarcasmului (subactivitatea 1) și a sentimentelor (subactivitatea 2). Am creat un sistem hibrid combinând caracteristici bazate pe reguli și încorporări statice și dinamice folosind transformatoare și învățare profundă. Arhitectura sistemului este un ansamblu de baie Naive, Marbert și Mazajak încorporate. Acest proces a marcat un scor F1 de 51% pe sarcasm și 71% pentru detectarea sentimentelor.', 'si': 'මේ පැත්තේ අරාබික් පරීක්ෂක කණ්ඩායමේ පද්ධතිය සාර්කාස්ම (අභිප්\u200dරශ්න 1) සහ හ හැකියුම (අභිප්\u200dරශ්න 2) පරීක් අපි හිබ්\u200dරිඩ් පද්ධතියක් සිද්ධා කරනවා නීති පද්ධතිය සහ ස්ථායික සහ හා විද්\u200dයාවක් පද්ධතිය සහ ගොඩක් ඉගෙනීම පද්ධතියේ ස්ථාපනය නැයිව් බේයි, MarBERT සහ මැජාක් සංවිධානයේ සංවිධානයක්. මේ පරීක්ෂණය සර්කාස්ම් වලට F1-ප්\u200dරමාණයක් 51% තියෙනවා, 71% තියෙනවා සංවේදනය හොයාගන්න.', 'sr': 'Ovaj papir predstavlja sistem Arapskog procesora tima koji je dizajniran za sarkazam (podpitanje 1) i zajednički zadatak otkrivanja sentimenta (podpitanje 2). Napravili smo hibridni sistem kombinirajući vladavine funkcije i statične i dinamične integracije koristeći transformatore i duboko učenje. Sistemska arhitektura je ensemble Najve Bayes, MarBERT i Mazajak ugrađenja. Ovaj proces je rezultat F1 rezultata od 51% na sarkazmu i 71% za otkrivanje sentimenta.', 'so': 'Warqaddan waxaa soo saara nidaamka kooxda ArabicProcessors oo loo qoray sarcasm (subtask 1) iyo xisaabta (subtask 2) oo lagu qeybiyay shaqada. Waxaannu abuurnay nidaam hibir ah oo ku soo ururiyey tababaro sharciga ku saleysan iyo sidoo kale baaritaanka caadiga ah iyo cilmiga hoose u bedela. Tirada dhismaha nidaamka waa mid ka mid ah Naive bayes, MarBERT iyo Mazajak. Xaruntan waxaa lagu qoray boqolkiiba F1 boqolkiiba 51 boqolkiiba oo ku saabsan sarcasm iyo 71 boqolkiiba daryeelka xisaabta.', 'sv': 'Denna uppsats presenterar ArabicProcessors-teamets system utformat för sarkasm (subaktivitet 1) och sentiment (subaktivitet 2) detektering delad uppgift. Vi skapade ett hybridsystem genom att kombinera regelbaserade funktioner och både statiska och dynamiska inbäddningar med transformatorer och djupinlärning. Systemets arkitektur är en ensemble av Naive bayes, Marbert och Mazajak inbäddade. Denna process fick en F1-poäng på 51% på sarkasm och 71% för sentimentdetektering.', 'ta': 'இந்த தாள் பரிமாற்றம் (உப செயல் 1) மற்றும் உணர்வு (உப செயல் 2) பகிர்ந்த பணியை கண்டுபிடிப்பதற்கான அரபி செயல்பாட்டாளர் குழுவின் அமை மாற்றங்கள் மற்றும் ஆழமான கற்றத்தை பயன்படுத்தி ஒரு ஹைப்ரிட் அமைப்பை சேர்த்து விதியில் அடிப்படையான தன்மைகளை மற்றும் நில அமைப்பின் கட்டுப்பாடு நாய்வ் பேய், மார்பெர்ட் மற்றும் மாஜாக் உட்பொதிந்துள்ளது. இந்த செயல்பாடு சட்டத்தில் 51% புள்ளியை மதிப்பிட்டுள்ளது மற்றும் உணர்வு கண்டுபிடிப்பதற்கு 71% புள்ளிகள்.', 'mt': 'Dan id-dokument jippreżenta s-sistema tat-tim tal-ArabicProcessors iddisinjata għas-sarkazmu (sottomistoqsija 1) u s-sensazzjoni (sottomistoqsija 2) kompitu kondiviż ta’ detezzjoni. Ħolqien sistema ibrida billi kkombinaw karatteristiċi bbażati fuq ir-regoli u inkorporazzjonijiet kemm statiċi kif ukoll dinamiċi bl-użu ta’ trasformaturi u tagħlim profond. L-arkitettura tas-sistema hija ensemble ta’ Naive Bayes, MarBERT u Mazajak inkorporazzjoni. Dan il-proċess kellu punteġġ F1 ta’ 51% fuq is-sarkasmu u 71% għad-detezzjoni tas-sentimenti.', 'ur': 'یہ کاغذ عربی پرسسور ٹیم کا سیستم سارکاسم (1) کے لئے طراحی کیا گیا ہے اور احساسات (2) شناسایی کا مشترک کام ہے۔ ہم نے ایک ہیبریڈ سیستم پیدا کی کہ قانون کی بنیاد رکھی ہوئی فکرتوں اور دونوں سٹیٹیک اور دائمی انڈینگ کو تغییرات اور عمیق تعلیم کے مطابق جمع کرے۔ سیسٹم کی معماری نایو بیس، ماربرٹ اور مزاجک کے انڈینگ کا ایک انڈیل ہے۔ یہ پروسس سارکاسم پر 51% کی F1 اسکور اور 71% احساس شناسایی کے لئے۔', 'vi': 'Tờ giấy này giới thiệu hệ thống thí nghiệm Arabella Prossors đã được thiết kế cho s ự mỉa mai (subtitle 1) và mềm (phần phụ 2) bị phát hiện. Chúng tôi tạo ra một hệ thống nhân tạo bằng cách kết hợp các tính năng quy định và cả sự gắn kết tĩnh động và động cơ sử dụng máy biến đổi và học sâu. Kiến trúc của hệ thống là một kết hợp gồm các vịnh làm móng, Marmorit và Mazajak tham gia. Quá trình này ghi được một điểm F1 của 51=* về mỉa mai và 71=* để được phát hiện cảm xúc.', 'uz': "Bu hujjat sarkasm (sub- vazifa 1) va hisob (sub- vazifa 2) qidirilgan vazifani aniqlash uchun yaratilgan Arab Processors jamoasi tizimini koʻrsatiladi. Biz qoidadagi xususiyatlarni birlashtirish va o'zgarishlar va eng yuqori o'rganish orqali o'zgarishlar bilan o'rganish uchun statik va dynamik muvaffaqiyatlarni birlashtirish mumkin. Tizimning arxituvlari Naiv bayes, MarBERT va Mazajak birinchi bir misol. This process scored an F1-score of 51% on sarcasm and 71% for sentiment detection.", 'hr': 'Ovaj papir predstavlja sustav tima Arapskih procesora dizajniran za sarkazam (podpitanje 1) i zajednički zadatak otkrivanja osjećaja (podpitanje 2). Napravili smo hibridni sustav kombinirajući vladavine funkcije i statične i dinamične integracije koristeći transformatore i duboko učenje. Arhitektura sustava je ensemble nasilnih zaljeva, MarBERT i Mazajak ugrađenja. Ovaj proces je rezultat F1 rezultata od 51% na sarkazmu i 71% za otkrivanje osjećaja.', 'bg': 'Настоящата статия представя системата на екипа на арабските процесори, предназначена за откриване на споделена задача за сарказъм (подзадача 1) и сентимент (подзадача 2). Създадохме хибридна система чрез комбиниране на функции, базирани на правила и статични и динамични вграждания с помощта на трансформатори и дълбоко обучение. Архитектурата на системата е ансамбъл от Наивни заливи, Марберт и Мазаяк вграждане. Този процес има резултат от 51% за сарказъм и 71% за откриване на сентименти.', 'nl': 'Dit artikel presenteert het systeem van het ArabicProcessors team ontworpen voor sarcasme (subtaak 1) en sentiment (subtaak 2) detectie gedeelde taak. We creëerden een hybride systeem door regelgebaseerde functies en statische en dynamische embeddings te combineren met behulp van transformatoren en deep learning. De architectuur van het systeem is een ensemble van Naive bayes, MarBERT en Mazajak embedding. Dit proces scoorde een F1-score van 51% op sarcasme en 71% voor sentimentdetectie.', 'da': 'Denne artikel præsenterer ArabicProcessors-teamets system designet til sarkasme (underopgave 1) og sentiment (underopgave 2) detektering delt opgave. Vi skabte et hybridsystem ved at kombinere regelbaserede funktioner og både statiske og dynamiske indlejringer ved hjælp af transformere og deep learning. Systemets arkitektur er et ensemble af Naive bayes, Marbert og Mazajak indlejring. Denne proces scorede en F1-score på 51% på sarkasme og 71% for sentiment detektion.', 'id': "Kertas ini memperkenalkan sistem tim ArabicProcessors yang dirancang untuk sarkasme (subtask 1) dan sensasi (subtask 2) deteksi tugas berbagi. We created a hybrid system by combining rule-based features and both static and dynamic embeddings using transformers and deep learning.  The system's architecture is an ensemble of Naive bayes, MarBERT and Mazajak embedding.  Proses ini mencetak skor F1 51% pada sarkasme dan 71% untuk deteksi perasaan.", 'de': 'Dieser Beitrag stellt das System des ArabicProcessors-Teams vor, das für die gemeinsame Aufgabe der Sarkasmus-Erkennung (Subtask 1) und Sentiment-Erkennung (Subtask 2) entwickelt wurde. Wir haben ein Hybridsystem geschaffen, indem wir regelbasierte Funktionen und statische und dynamische Einbettungen mit Transformatoren und Deep Learning kombiniert haben. Die Architektur des Systems ist ein Ensemble aus Naive Bayes, MarBERT und Mazajak Einbettung. Dieser Prozess erzielte einen F1-Score von 51% für Sarkasmus und 71% für Sentiment Detection.', 'ko': '본고는 Arabic Processor팀이 풍자(하위 임무 1)와 정서(하위 임무 2)를 측정하고 공유하는 임무를 설계하는 시스템을 소개한다.우리는transformers와 심도 있는 학습을 사용하여 규칙을 바탕으로 하는 기능과 정적과 동적 삽입을 결합시켜 혼합 시스템을 만들었다.이 시스템의 구조는 Naive bayes, MarBERT, Mazajak이 끼워 넣은 집합이다.이 과정은 풍자와 정서 측정에서 F1이 각각 51%, 71%의 점수를 받았다.', 'sw': "This paper presents the ArabicProcessors team's system designed for sarcasm (subtask 1) and sentiment (subtask 2) detection shared task.  Tumetengeneza mfumo wa mahindi kwa kuunganisha vipengele vya utawala na vyote vilivyokuwa vikali na mabadiliko na kujifunza kwa kina. Ujengo wa mfumo huo ni mfumo wa mabua ya Nazi, MarBERT na Mazajak. Mchakato huu ulinukuu score ya F1 ya asilimia 51 kuhusu kejeli na asilimia 71 kwa kutambua hisia.", 'af': "Hierdie papier stel die Arabiese Prosessors team se stelsel ontwerp vir sarkasm (ondersoek 1) en sentiment (ondersoek 2) ontdekking gedeelde taak. Ons het 'n hibrid stelsel skep deur die reël-gebaseerde funksies en beide statiese en dinamiese inbêdings te kombinerer deur transformers en diep leer te gebruik. Die stelsel se arkitektuur is 'n ensemble van Naive bayes, MarBERT en Mazajak inbêring. Hierdie proses het 'n F1- telling van 51% op sarkasm en 71% vir sentiment-opdekking gegee.", 'tr': 'Bu kagyz sarkasm üçin tassyklanan aräbi procesörler toparynyň sistemasyny we duýgular(astsorag 1) işi tapylýar. Biz bir hybrid sistemini kural tabanly özelliklerini birleştirerek, hem statik hem dinamik birleşmeleri we çulyk öwrenmeleri ulanarak bejerdik. Bu sistemiň arhitektura Naive baylar, MarBERT we Mazajak baglanmasynyň bir bölegidir. Bu proses sarkasm üçin 51% we 71% duýgular tanyşdy.', 'fa': 'این کاغذ سیستم تیم پردازگاران عربی را نشان می دهد که طراحی شده برای کارهای مشترک سارکاسم (زیر سوال ۱) و تشخیص احساسات (زیر سوال ۲) است. ما یک سیستم هیبریدی را با ترکیب ویژه های قانون بر اساس قانون ساختیم و با استفاده از تغییر دهندگان و یادگیری عمیق و استفاده کنیم. معماری سیستم یک انجمن ساحل نایو، MarBERT و Mazajak است. این فرایند یک امتیاز F1 با ۱۵ درصد درصد در سارکاسم و ۱۷ درصد برای شناسایی احساسات ثبت کرد.', 'hy': 'Այս հոդվածը ներկայացնում է Արաբական պրոցեսորների թիմի համակարգը, որը նախագծված է սարկազմի (ենթահարց 1) և զգացմունքների (ենթահարց 2) բացահայտության համար: We created a hybrid system by combining rule-based features and both static and dynamic embeddings using transformers and deep learning.  Համակարգչային կառուցվածքը Նայվի Բեյեյի, Մարբերթի և Մաջակի ներգրավման համակարգ է: Այս գործընթացը ստացավ 51 տոկոս F1 գնահատականներ սարկազմի դեպքում և 71 տոկոս զգացմունքների հայտնաբերման դեպքում:', 'am': 'ይህም ገጽ ለስራስብ (Subtask 1) እና ስሜት (Subtask 2) ማግኘት የተለየ የዓረባዊ ፕሮስኮር የስርቨርስቲ ስርዓት ያሳያል፡፡ የኬብሪዲ ስርዓት፣ የሥርዓት ምርጫዎች እና የስታሪክ እና ጥልቅ ትምህርት በመቀላቀል እና ጥልቅ ትምህርት በመቀላቀል እና በመቀላቀል ነው፡፡ የሲስተም መሠረት የናይብ ባይዎች፣ ማርብሬት እና ማዛጃክ መግለጫ ነው፡፡ ይህም ፕሮጀክት የሳርካሲም መቶ 51 በመቶ የF1 ነጥብ እና 71 በመቶ ስሜት ማግኘት ነው፡፡', 'sq': 'Ky dokument paraqet sistemin e ekipit ArabicProcessors të dizajnuar për sarkazmin (nënpyetje 1) dhe detyrën e përbashkët të zbulimit (nënpyetje 2). Ne krijuam një sistem hibridë duke kombinuar karakteristika të bazuara në rregulla dhe përfshirje statike dhe dinamike duke përdorur transformuesit dhe mësimin e thellë. Arkitektura e sistemit është një ansambl i pjesëmarrjeve Naive Bayes, MarBERT dhe Mazajak. This process scored an F1-score of 51% on sarcasm and 71% for sentiment detection.', 'az': 'Bu kağıt, sarkasm (subtask 1) və sentiment (subtask 2) tanıması üçün tasarlanmış Arab Prozesör ekibinin sistemini göstərir. Biz bir hibrid sistemini düzgün tərzlərini birləşdirib, hər ikisi də statik və dinamik tərzlərini transformatörlər və derin öyrənmək vasitəsilə birləşdirdik. Sistemin arhitektarı Naive bayes, MarBERT və Mazajak inşallarının bir körpüs üdür. Bu proses sarkasm üzərində 51% F1 dəqiqəsini və 71% sentiment keşfetməsi üçün.', 'bs': 'Ovaj papir predstavlja sistem tim Arapskih procesora dizajniran za sarkazam (podpitanje 1) i dijeljeni zadatak otkrivanja osjećaja (podpitanje 2). Napravili smo hibridni sistem kombinirajući vladavine funkcije i statične i dinamične integracije koristeći transformatore i duboko učenje. Arhitektura sustava je ensemble nasilnih zaljeva, MarBERT i Mazajak ugrađenja. Ovaj proces je rezultat F1 rezultata od 51% na sarkazmu i 71% za otkrivanje osjećaja.', 'bn': 'এই পত্রিকা আরব প্রক্রিয়ার দলের বিদ্রোহের (সাব কাজ ১) এবং অনুভূতির (সাবটাবাস ২) আবিষ্কারের জন্য নির্মিত ব্যবস্থাকে উপস্থ আমরা একটি হাইব্রিড সিস্টেম সৃষ্টি করেছি নিয়মের ভিত্তিক বৈশিষ্ট্য এবং স্ট্যাটিক এবং ডায়ান্ডামিক বিভিন্ন বিভিন্ন ব এই সিস্টেমের আর্কিটারেক্টার হচ্ছে নাইভ বেয়ার, মার্বের্ট এবং মাজাকের একটি প্রতিষ্ঠান। এই প্রক্রিয়া বিদ্রোহে ৫১% এবং ৭১% আবেগ সন্ধানের জন্য একটি F1- স্কোর স্কোর করেছে।', 'cs': 'Tento článek představuje systém týmu ArabicProcessors navržený pro detekci sarkasmu (podúkol 1) a sentimentu (podúkol 2) sdílených úkolů. Vytvořili jsme hybridní systém kombinací funkcí založených na pravidlech a statických i dynamických vložení pomocí transformátorů a hlubokého učení. Architektura systému tvoří soubor Naive bayes, MarBERT a Mazajak embeding. Tento proces získal F1 skóre 51% na sarkasmus a 71% pro detekci sentimentů.', 'et': 'Käesolevas töös tutvustatakse ArabicProcessors meeskonna süsteemi, mis on loodud sarkasmi (alaülesanne 1) ja sentimentaalsuse (alaülesanne 2) tuvastamiseks jagatud ülesandeks. Lõime hübriidsüsteemi, kombineerides reeglipõhiseid funktsioone ning nii staatilisi kui dünaamilisi manustamisi transformaatorite ja sügavõppe abil. Süsteemi arhitektuur on ansambl Naive bayes, MarBERT ja Mazajak. Selle protsessi F1-skoor oli sarkasmi puhul 51% ja sentimentaalse tuvastamise puhul 71%.', 'fi': 'Tässä artikkelissa esitellään ArabicProcessors-tiimin järjestelmä, joka on suunniteltu sarkasmin (alatehtävä 1) ja tunteen (alatehtävä 2) havaitsemiseen jaettuun tehtävään. Luomme hybridijärjestelmän yhdistämällä sääntöpohjaiset ominaisuudet sekä staattiset ja dynaamiset sulautukset muuntajien ja syväoppimisen avulla. Järjestelmän arkkitehtuuri on yhdistelmä Naive bayes-, MarBERT- ja Mazajak-upotusta. Tämän prosessin F1-pisteet olivat 51% sarkasmista ja 71% tunteiden havaitsemisesta.', 'ca': "Aquest article presenta el sistema de l'equip ArabicProcessors dissenyat per a la detecció compartida del sarcasme (subpregunta 1) i del sentiment (subpregunta 2). Vam crear un sistema híbrid combinant característiques basades en les regles i integracions estatiques i dinàmices fent servir transformadors i aprenentatge profund. L'arquitectura del sistema és un conjunt de baies Naive, MarBERT i Mazajak. Aquest procés va obtenir una puntuació F1 del 51% en el sarcasme i del 71% en la detecció de sentiments.", 'he': 'העיתון הזה מציג את המערכת של צוות המעבדים הערביים שנועדת לסרקזם (subtask 1) ומשימה משותפת לגילוי (subtask 2). יצרנו מערכת היברידית על ידי שילוב תכונות מבוססים על חוקים, וכל התקפות סטטיות ודינמיות באמצעות משתנים וללמד עמוק. הארכיטקטורה של המערכת היא אסמבל של ביי נייב, מרברט ומאזאק. התהליך הזה קיבל נקודת F1 של 51% על סרקזם ו-71% על זיהוי רגשות.', 'ha': "Wannan karatun na gaurar da na'urar Mun halitta wani kybrid da Muka haɗa wasu takardar da aka ƙayyade rubutun, da kuma duk masu da za'a yi amfani da shifotto da sanar da masu ƙari. Baytes, MarBERT da Mazajak ke shiga. Wannan jararin ya score F1-score na 51% na kan sarcasm kuma 71% na gane cewa.", 'sk': 'V prispevku je predstavljen sistem ekipe ArabicProcessors, zasnovan za sarkazem (podnaloga 1) in sentimentalno (podnaloga 2) odkrivanje skupnega opravila. Hibridni sistem smo ustvarili s kombinacijo funkcij, ki temeljijo na pravilih, ter statičnih in dinamičnih vdelav s pomočjo transformatorjev in globokega učenja. Arhitektura sistema je ansambel Naive bayes, MarBERT in Mazajak vgradnje. Ta proces je dosegel rezultat F1 51% pri sarkazmu in 71% pri odkrivanju čustva.', 'bo': 'འོག་གི་ཤོག་བུ་འདིས་ཨ་རབ་སྦྱོར་མཁན་དབུགས་ཀྱི་མ་ལག་གི་སྦྱོར་ཆས་དེ་སྟོན་པ། We created a hybrid system by combining rule-based features and both static and dynamic embeddings using transformers and deep learning. མ་ལག་གི་སྒྲིག་འགོད་གཞུང་ནི་Naive bayes, MarBERT དང་Mazajak ཁོང་ཚོའི་མཚོན་རྟགས་ཅིག་རེད། This process scored an F1-score of 51% on sarcasm and 71% for sentiment detection.', 'jv': 'Perintah iki gunakake sistem sing dibenakno nang karo sarkasm (supiturasan 1) lan mulasar (supiturasan 2) nggawe barang. Awak dhéwé nggawe sistem HyBridge nggawe barang nggawe rule-basa buktuan karo sistem dadi stop lan dynamics embedding nggawe transformer karo deep Learning. Arkturaturati sistem kuwi nyumbang nggawe bayes Nave, MarBERT lan mulambang Majarak. Ngucap multi-second'}
{'en': 'iCompass at Shared Task on Sarcasm and Sentiment Detection in Arabic', 'ar': 'iCompass at Shared Task on السخرية والكشف عن المشاعر باللغة العربية', 'fr': 'iCompass participe à une tâche partagée sur la détection du sarcasme et des sentiments en arabe', 'pt': 'iCompass na tarefa compartilhada sobre detecção de sarcasmo e sentimento em árabe', 'es': 'iCompass participa en una tarea compartida sobre detección de sarcasmo y sentimientos en árabe', 'ja': 'アラビア語での皮肉と感情の検出に関する共有タスクでのiCompass', 'hi': 'अरबी में व्यंग्य और भावना का पता लगाने पर साझा कार्य पर iCompass', 'zh': 'iCompass at Shared Task on Sarcasm and Sentiment Detection in Arabic', 'ru': 'iCompass в общей задаче по обнаружению сарказма и сентиментов на арабском языке', 'ga': 'iCompass ag Tasc Comhroinnte ar Sarcasm agus Brath Meinte san Araibis', 'ka': 'Comment', 'hu': 'iCompass az arab nyelvű szarkazmus és érzelmek felismerésével foglalkozó megosztott feladatban', 'kk': 'Comment', 'it': 'iCompass al compito condiviso sul sarcasmo e rilevamento dei sentimenti in arabo', 'mk': 'iCompass на заедничка задача за детекција на сарказам и чувства на арапски', 'ms': 'iCompass pada Tugas Berkongsi mengenai Sarkasm dan Pengesanan dalam bahasa Arab', 'el': 'Στο κοινό έργο για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά', 'mn': 'iCompass in Sharcasm and Sentiment Detection on Arabic', 'mt': 'iCompass f’Kompitu Konġunt dwar is-Sarkazmu u d-Detezzjoni tas-Sentimenti fl-Għarab', 'lt': 'iCompass bendrame darbe apie sarkazmą ir jausmų aptikimą arabų kalba', 'pl': 'iCompass na wspólnym zadaniu na temat sarkazmu i wykrywania sentymentów w języku arabskim', 'no': 'Comment', 'ml': 'സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റീഷനും അറബിയിലെ പങ്കെടുത്ത ജോലിയിലെ iCompass', 'ro': 'iCompass la sarcina partajată privind detectarea sarcasmului și sentimentelor în limba arabă', 'sr': 'iCompass na zajednièkom zadatku o sarkazmu i otkrivanju sentimenta na arapskom', 'si': 'Name', 'so': 'iCompass at Shared Task on Sarcasm and Sentiment Detection Arabic', 'sv': 'iCompass på delad uppgift om sarkasm och känslodetektering på arabiska', 'ta': 'Sarcasm மற்றும் Sentiment Detection in Arabic', 'ur': 'Sarcasm اور Sentiment Detection پر iCompass', 'uz': 'Name', 'vi': 'Hợp đồng tại công việc chia sẻ về phòng phát hiện vết tích bằng tiếng Ả Rập', 'bg': 'Споделена задача за откриване на сарказъм и сентименти на арабски език', 'hr': 'Comment', 'de': 'iCompass bei Shared Task zu Sarkasmus und Sentiment Detection auf Arabisch', 'nl': 'iCompass bij Gedeelde Taak over Sarcasme en Sentiment Detection in het Arabisch', 'da': 'iCompass på delt opgave om sarkasme og følelser detektering på arabisk', 'id': 'iCompass di Shared Task on Sarcasm and Sentiment Detection in Arabic', 'sw': 'iCompass kwenye kazi ya Shabiki kwenye Sarcasm na Utafiti wa Kiarabu', 'fa': 'Comment', 'tr': 'iCompass Sarkasm we Sentiýat Aňlamakda Arabça', 'ko': '아랍어에서 풍자와 정서 검측의 공유 임무를 비교해 봤어요.', 'am': 'iCompass at Shared Task on Sarcasm and Sentiment Detection in Arabic', 'af': 'Comment', 'sq': 'iCompass në punën e përbashkët për zbulimin e sarkazmit dhe ndjenjave në arabisht', 'hy': 'iCմպասը Սարկազմի և զգացմունքների հայտնաբերման ընթացքում արաբերենով', 'az': 'Sarkasm və Sentiment keşfini Arabski dilində paylaşın işdə iCompass', 'ca': 'iCompass a Shared Task on Sarcasm and Sentiment Detection in Arabic', 'cs': 'iCompass na sdíleném úkolu o sarkasmu a detekci citů v arabštině', 'bs': 'iCompass na zajedničkom zadatku o sarkazmu i otkrivanju sentimenta na arapskom', 'bn': 'সার্কাম এবং সেন্টিমেন্ট ডিটেক্টরেশনে শেয়ার করা কাজের iCompassName', 'fi': 'iCompass arabiankielisessä Shared Task on Sarkasm and Sentiment Detection -ohjelmassa', 'et': 'iCompass sarkasmi ja tunnete tuvastamise jagatud ülesandes araabia keeles', 'jv': 'iCompasset nang Samar task nang Sarkasm lan Sentiment detection in larab', 'ha': 'KCharselect unicode block name', 'he': 'iCompass במשימה משותפת על סרקזם וגילוי רגשות בערבית', 'sk': 'iCompass na skupni nalogi o sarkazmu in zaznavanju čustev v arabščini', 'bo': 'iCompass at Shared Task on Sarcasm and Sentiment Detection in Arabic'}
{'en': 'We describe our submitted system to the 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic (Abu Farha et al., 2021). We tackled both subtasks, namely Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). We used state-of-the-art pretrained contextualized text representation models and fine-tuned them according to the downstream task in hand. As a first approach, we used Google’s multilingual BERT and then other Arabic variants : AraBERT, ARBERT and MARBERT. The results found show that MARBERT outperforms all of the previously mentioned models overall, either on Subtask 1 or Subtask 2.', 'ar': 'نصف نظامنا المقدم إلى المهمة المشتركة 2021 حول كشف السخرية والمشاعر باللغة العربية (أبو فرحة وآخرون ، 2021). لقد تناولنا كلا المهمتين الفرعيتين ، وهما اكتشاف السخرية (المهمة الفرعية 1) وتحليل المشاعر (المهمة الفرعية 2). استخدمنا نماذج تمثيل نصي سياقية متطورة للغاية وقمنا بضبطها وفقًا لمهمة المصب في متناول اليد. كطريقة أولى ، استخدمنا BERT متعدد اللغات من Google ثم المتغيرات العربية الأخرى: AraBERT و ARBERT و MARBERT. تظهر النتائج التي تم العثور عليها أن MARBERT يتفوق في الأداء على جميع النماذج المذكورة سابقًا بشكل عام ، سواء في المهمة الفرعية 1 أو المهمة الفرعية 2.', 'fr': "Nous décrivons notre système soumis à la tâche partagée 2021 sur la détection du sarcasme et des sentiments en arabe (Abu Farha et al., 2021). Nous avons abordé les deux sous-tâches, à savoir la détection des sarcasmes (sous-tâche 1) et l'analyse des sentiments (sous-tâche 2). Nous avons utilisé des modèles de représentation textuelle contextualisée pré-entraînés de pointe et les avons affinés en fonction de la tâche en aval en cours. Dans un premier temps, nous avons utilisé le BERT multilingue de Google, puis d'autres variantes arabes\xa0: AraBert, ARBERT et MARBERT. Les résultats trouvés montrent que MARBERT surpasse globalement tous les modèles mentionnés précédemment, que ce soit pour la sous-tâche 1 ou la sous-tâche 2.", 'pt': 'Descrevemos nosso sistema submetido à Tarefa Compartilhada de 2021 sobre Detecção de Sarcasmo e Sentimentos em árabe (Abu Farha et al., 2021). Abordamos ambas as subtarefas, ou seja, Detecção de Sarcasmo (Subtarefa 1) e Análise de Sentimentos (Subtarefa 2). Usamos modelos de representação de texto contextualizados pré-treinados de última geração e os ajustamos de acordo com a tarefa de downstream em mãos. Como primeira abordagem, usamos o BERT multilíngue do Google e depois outras variantes em árabe: AraBERT, ARBERT e MARBERT. Os resultados encontrados mostram que o MARBERT supera em geral todos os modelos mencionados anteriormente, seja na Subtarefa 1 ou na Subtarefa 2.', 'es': 'Describimos nuestro sistema presentado a la Tarea Compartida sobre Sarcasmo y Detección de Sentimientos de 2021 en árabe (Abu Farha et al., 2021). Abordamos ambas subtareas, a saber, Detección de sarcasmo (subtarea 1) y Análisis de sentimientos (subtarea 2). Utilizamos modelos de representación de texto contextualizados preentrenados de última generación y los ajustamos de acuerdo con la tarea posterior en cuestión. Como primer enfoque, utilizamos el BERT multilingüe de Google y, a continuación, otras variantes árabes: ARABert, ARBERT y MARBERT. Los resultados encontrados muestran que MARBERT supera en general a todos los modelos mencionados anteriormente, ya sea en la subtarea 1 o en la subtarea 2.', 'ja': 'アラビア語での皮肉と感情検出に関する2021年の共有タスクに提出されたシステムについて説明します（ Abu Farha et al., 2021 ）。両方のサブタスク、すなわち皮肉検出（サブタスク1 ）と感情分析（サブタスク2 ）に取り組んだ。最先端の事前訓練された文脈化されたテキスト表現モデルを使用し、手元の下流のタスクに応じて微調整しました。最初のアプローチとして、Googleの多言語BERTを使用し、次にAraBERT、ARBERT、MARBERTという他のアラビア語のバリアントを使用しました。発見された結果は、MARBERTがサブタスク1またはサブタスク2のいずれかで、前述のすべてのモデルを全体的に上回っていることを示しています。', 'zh': '以阿拉伯语述2021年讥检(Abu Farha等,2021)。 治此二子者,刺检(子1)情析(子2)。 用最先进的预练的上下文化文本表示模样,并随手头的下流务务微调。 一法,用Google多言BERT,然后他阿拉伯语变体:AraBERT,ARBERTMARBERT。 结果显示,MARBERT在子1或子2上之总优于前。', 'ru': 'Мы описываем нашу систему, представленную к Общей задаче 2021 года по обнаружению сарказма и сентиментов на арабском языке (Abu Farha et al., 2021). Мы занимались обеими подзадачами, а именно обнаружением сарказма (подзадача 1) и анализом настроений (подзадача 2). Мы использовали самые современные предварительно обученные контекстуализированные модели текстового представления и настраивали их в соответствии с поставленной задачей. В качестве первого подхода мы использовали многоязычный BERT Google, а затем и другие арабские варианты: AraBERT, ARBERT и MARBERT. Полученные результаты показывают, что MARBERT превосходит все ранее упомянутые модели в целом, либо по подзадаче 1, либо по подзадаче 2.', 'hi': 'हम अरबी में व्यंग्य और भावना का पता लगाने पर 2021 साझा कार्य के लिए हमारे प्रस्तुत प्रणाली का वर्णन करते हैं (अबू फरहा एट अल। हमने दोनों उप-कार्यों से निपटा, अर्थात् व्यंग्य का पता लगाना (सबटास्क 1) और भावना विश्लेषण (सबटास्क 2)। हमने अत्याधुनिक प्रीट्रेनाइज्ड टेक्स्ट प्रतिनिधित्व मॉडल का उपयोग किया और उन्हें हाथ में डाउनस्ट्रीम कार्य के अनुसार ठीक-ठाक किया। पहले दृष्टिकोण के रूप में, हमने Google के बहुभाषी BERT और फिर अन्य अरबी संस्करणों का उपयोग किया: AraBERT, ARBERT और MARBERT। पाए गए परिणामों से पता चलता है कि MARBERT कुल मिलाकर पहले से उल्लिखित सभी मॉडलों को मात देता है, या तो Subtask 1 या Subtask 2 पर।', 'ga': "Déanaimid cur síos ar an gcóras a cuireadh isteach chuig an Tasc Comhroinnte 2021 ar Sheanamhas agus ar Bhrath Mothúcháin in Araibis (Abu Farha et al., 2021). Chuamar i ngleic leis an dá fhothasc, eadhon Brath Sarcasm (Fothasc 1) agus Anailís Mothúchán (Fothasc 2). D’úsáideamar samhlacha den scoth um léiriú téacs comhthéacsaithe réamhoilte agus rinneamar mionchoigeartú orthu de réir an taisc iartheachtach atá idir lámha. Mar chéad chur chuige, d'úsáideamar BERT ilteangach Google agus ansin leaganacha Araibis eile: AraBERT, ARBERT agus MARBERT. Léiríonn na torthaí a fuarthas go sáraíonn MARBERT na samhlacha go léir a luadh roimhe seo ar an iomlán, ar Fhothasc 1 nó ar Fhothasc 2.", 'ka': 'ჩვენ 2021 წლის საზოგადომი საქაღალდე და სენტიმენტის განსახულებაზე ჩვენი სისტემის შეტყობინება აპაბიურად (Abu Farha et al., 2021). ჩვენ ორივე საკუთარი საკუთარი გავაკეთებდით, ანუ საკუთარი განახვა (საკუთარი 1-ი) და საკუთარი ანალიზი (საკუთარი 2-ი). ჩვენ გამოყენეთ ტექსტუალური ტექსტურაციის მოდელების შესაბამისი მხარდაჭერების შესაბამისი მხარდაჭერების შესაბამისი მოდელების გამოყენება. როგორც პირველი პროგორმა, ჩვენ Google-ის მრავალენგური BERT და შემდეგ სხვა აპაბური გარიანტები გამოყენეთ: AraBERT, ARBERT და MARBERT. მოიძებნა შედეგი შედეგი, რომ MARBERT უფრო მეტად გავაკეთებს ყველა წინასწორედ ამოხსნა მოდელები, ან Subtask 1 ან Subtask 2-ზე.', 'el': 'Περιγράφουμε το σύστημά μας στην κοινή εργασία για τον σαρκασμό και την ανίχνευση συναισθημάτων στα αραβικά (Αμπού Φάρχα κ.α., 2021). Αντιμετωπίσαμε και τις δύο δευτερεύουσες εργασίες, δηλαδή την ανίχνευση σαρκασμού (δευτερεύουσα εργασία 1) και την ανάλυση συναισθημάτων (δευτερεύουσα εργασία 2). Χρησιμοποιήσαμε μοντέλα αναπαράστασης κειμένου τελευταίας τεχνολογίας και τα τελειοποιήσαμε σύμφωνα με το επόμενο έργο. Ως πρώτη προσέγγιση, χρησιμοποιήσαμε το πολύγλωσσο BERT της Google και στη συνέχεια άλλες αραβικές παραλλαγές: AraBERT, ARBERT και MARBERT. Τα αποτελέσματα που βρέθηκαν δείχνουν ότι το MARBERT ξεπερνά συνολικά όλα τα προαναφερθέντα μοντέλα, είτε σε Υποεργασία 1 είτε Υποεργασία 2.', 'hu': 'Leírjuk a benyújtott rendszerünket a 2021. évi szarkazmus és érzelmek felismerésével foglalkozó megosztott feladatra arabul (Abu Farha et al., 2021). Mindkét részfeladatot foglalkoztunk, nevezetesen Szarkazmus Észlelés Észlelés Észlelés Észlelés Észlelés Észlelés Észlelés Észlelés Észlelés 2. A legkorszerűbb, előzetes kontextuális szövegreprezentációs modelleket használtuk, és finomhangoltuk őket a készült downstream feladatnak megfelelően. Első megközelítésként a Google többnyelvű BERT, majd más arab változatokat használtunk: AraBERT, ARBERT és MARBERT. A talált eredmények azt mutatják, hogy a MARBERT teljesítményt nyújt az összes korábban említett modellnél, akár az 1. vagy a 2. alcsoportnál.', 'it': "Descriviamo il nostro sistema presentato al 2021 Shared Task on Sarcasm and Sentiment Detection in Arabo (Abu Farha et al., 2021). Abbiamo affrontato entrambe le sottoattività, vale a dire Sarcasm Detection (Sottotask 1) e Sentiment Analysis (Sottotask 2). Abbiamo utilizzato modelli di rappresentazione testuale contestualizzata pre-addestrati all'avanguardia e li abbiamo perfezionati in base al compito a valle in corso. Come primo approccio, abbiamo utilizzato il multilingue BERT di Google e poi altre varianti arabe: AraBERT, ARBERT e MARBERT. I risultati trovati mostrano che MARBERT supera complessivamente tutti i modelli menzionati in precedenza, sia su Subtask 1 che Subtask 2.", 'kk': 'Біз жүйеңізді 2021 жылы Саркассм және Сентиментті араб тілінде (Abu Farha et al., 2021) ортақтастырған тапсырмаға таңдадық. Біз екі ішкі сұрақтарды шешудік: Саркассм анықтау (1- ішкі тапсырма) және Sentiment Analysis (2- ішкі тапсырма). Біз күй- жағдайды бағытталған мәтін түсіндіру үлгілерін қолданып, оларды қолданыстағы төменгі тапсырманың қасиетіне түзету үлгілерін қолдандық. Алғашқы жағдай болғанда, Google көп тілді BERT және басқа араб айнымаларды қолдандық: AraBERT, ARBERT және MARBERT. Табылған нәтижелер MARBERT алдыңғы мәліметтің барлық үлгілерін, немесе 1- жұмыс не 2- жұмыс ішінде жасайды.', 'lt': 'Aprašome savo pateiktą sistemą 2021 m. bendram Sarkazmo ir jutimo aptikimo arabų kalba uždaviniui (Abu Farha ir kt., 2021 m.). We tackled both subtasks, namely Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2).  Naudojome naujausius iš anksto parengtus kontekstinius teksto atstovavimo modelius ir patobulinome juos pagal dabartinę užduotį. Pirmiausia naudojome Google daugiakalbį BERT ir kitas arabų variantus: AraBERT, ARBERT ir MARBERT. The results found show that MARBERT outperforms all of the previously mentioned models overall, either on Subtask 1 or Subtask 2.', 'mk': 'Го опишуваме нашиот поднесен систем на Соделената задача 2021 за Сарказам и Детектирање на чувствата на арапски (Абу Фарха и други, 2021). Ние ги решивме двете потпрашања, имено детекцијата на сарказмот (подзадача 1) и анализа на чувствата (подзадача 2). Користевме најсовремени претренирани контекстуални текстови претставувачки модели и ги прилагодивме според следната задача на раката. Како прв пристап, го користевме мултијазичниот БЕРТ на Гугл, а потоа другите арапски варијанти: АраБЕРТ, АРБЕРТ и МаРБЕРТ. The results found show that MARBERT outperforms all of the previously mentioned models overall, either on Subtask 1 or Subtask 2.', 'ms': 'Kami menggambarkan sistem kami yang dihantar kepada Tugas Berkongsi 2021 mengenai Sarkasm dan Pengesanan Sentiment dalam bahasa Arab (Abu Farha et al., 2021). Kami menangani kedua-dua sub-tanya, iaitu Deteksi Sarkasm (Subtask 1) dan Analisi Sentiment (Subtask 2). Kami menggunakan model persembahan teks kontekstualisasi yang terbaik dan memperbaikinya sesuai dengan tugas bawah yang ada di tangan. Sebagai pendekatan pertama, kami menggunakan BERT berbilang bahasa Google dan kemudian varian Arab lain: AraBERT, ARBERT dan MARBERT. The results found show that MARBERT outperforms all of the previously mentioned models overall, either on Subtask 1 or Subtask 2.', 'ml': 'ഞങ്ങള്\u200d ഞങ്ങളുടെ 2021 പങ്കാളിയാക്കപ്പെട്ട ട ടാസ്കിന് വിവരിച്ചുകൊടുക്കുന്നു. സാര്\u200dക്കാസം, സെന്റിമെന്റ് ഡിറ്റീഷന്\u200d അ സർക്കാസം ഡിറ്റക്റ്റീഷനും സെന്റിമെന്റ് അനാലസിസും നമ്മൾ രണ്ടുപേരെയും കൈകാര്യം ചെയ്തു. നമ്മള്\u200d ആലോചിക്കപ്പെട്ട ട ടെക്സ്റ്റ് പ്രതിനിധികളുടെ മോഡലുകള്\u200d ഉപയോഗിച്ച് താഴ്വരയുടെ കൈയ്യിലുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200dക് ആദ്യത്തെ വഴിയായി ഞങ്ങള്\u200d ഗൂഗിളിന്റെ പല ഭാഷ ബെര്\u200dട്ടിനെയും പിന്നെ മറ്റു അറബിഭാഷയെയും ഉപയോഗിച്ചു. അരാബെര്\u200dട്ട്, ആര്\u200dബെര്\u200dട്ട്,  മുമ്പ് പറഞ്ഞ എല്ലാ മോഡലുകളും മൊത്തത്തില്\u200d മാര്\u200dബെര്\u200dട്ട് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന്റെ ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക', 'mt': 'Aħna niddeskrivu s-sistema sottomessa tagħna għall-Ħidma Konġunta tal-2021 dwar is-Sarkazmu u d-Detezzjoni tas-Sentimenti fl-Għarab (Abu Farha et al., 2021). Aħna ttrattajna ż-żewġ sottomistoqsijiet, jiġifieri d-Detezzjoni tas-Sarkazmu (Subkompitu 1) u l-Analiżi tas-Sentiment (Subkompitu 2). Aħna użajna mudelli ta’ rappreżentazzjoni tat-test kontekstwali mħarrġa minn qabel l-aktar avvanzati u rranġajnhom skont il-kompitu downstream li hemm. Bħala l-ewwel approċċ, użajna l-BERT multilingwi ta’ Google u mbagħad varjanti oħra Għarab: AraBERT, ARBERT u MARBERT. Ir-riżultati misjuba juru li MARBERT jaqbeż il-mudelli kollha msemmija qabel b’mod ġenerali, jew fis-Subkompitu 1 jew fis-Subkompitu 2.', 'pl': 'Opisujemy nasz przesłany system do 2021 Shared Task on Sarkasm and Sentiment Detection w języku arabskim (Abu Farha et al., 2021). Zajęliśmy się oboma podzadaniami, a mianowicie wykrywaniem sarkazmu (podzadanie 1) i analizą sentymentów (podzadanie 2). Wykorzystaliśmy najnowocześniejsze, wstępnie przeszkolone modele reprezentacji tekstu i dostosowaliśmy je do dalszego zadania. Jako pierwsze podejście wykorzystaliśmy wielojęzyczny BERT Google, a następnie inne arabskie warianty: AraBERT, ARBERT i MARBERT. Znalezione wyniki pokazują, że MARBERT przewyższa wszystkie wymienione wcześniej modele, zarówno w podzadaniu 1, jak i w podzadaniu 2.', 'ro': 'Descriem sistemul nostru depus la sarcasmul și detectarea sentimentelor în arabă (Abu Farha et al., 2021). Am abordat ambele subsarcini, și anume detectarea sarcasmului (subsarcina 1) și analiza sentimentelor (subsarcina 2). Am folosit modele de reprezentare textuală contextualizată de ultimă generație și le-am reglat fin în funcție de sarcina din aval. Ca o primă abordare, am folosit BERT multilingv de la Google și apoi alte variante arabe: AraBERT, ARBERT și MARBERT. Rezultatele găsite arată că MARBERT depășește toate modelele menționate anterior, fie pe Subsarcina 1, fie pe Subsarcina 2.', 'sr': 'Opišemo svoj podignut sistem na zajednički zadatak 2021. godine o detekciji sarkazma i sentimenta na arapskom (Abu Farha et al., 2021). Uradili smo obe podatke, a to je detekcija Sarkasma (Subtask 1) i analiza Sentimenta (Subtask 2). Koristili smo modele predstavljanja teksta koji su predstavljeni u stanju umjetnosti i ispravljali ih u skladu sa zadatkom u rukama. Kao prvi pristup, koristili smo Google multijezički BERT i onda druge arabske variante: AraBERT, ARBERT i MARBERT. Pronađeni rezultati pokazuju da MARBERT iznosi sve prethodno spomenute modele, ili na Subtask 1 ili Subtask 2.', 'si': 'අපි 2021 සාර්කාස්ම් සහ සංවිධානය පද්ධතියට අපේ පද්ධතිය විස්තර කරනවා අරාබික් වල (Abu Farha et al., 2021). අපි දෙන්නම ප්\u200dරශ්නයක් හොයාගත්තා, සාර්කාස්ම් හොයාගත්තා (ප්\u200dරශ්නයක් 1) සහ ප්\u200dරශ්නයක් විශ්ලේෂණය (ප අපි ස්ථානයේ ක්\u200dරියාත්මක ප්\u200dරතිස්ථානයක් ප්\u200dරතිස්ථානය කරලා තියෙන්නේ පාළුවන් ප්\u200dරතිස්ථානයේ ප්\u200dරතිස්ථා මුලින් විදියට, අපි ගුගුල් ගේ බොහොම භාෂාවක් BERT වලට පාවිච්චි කළා, ඊට පස්සේ අනිත් අරාබික විදියට: AraBERT, ARBE ප්\u200dරතිචාරය පෙන්වන්න පුළුවන් විදිහට MARBERT ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාර කරනවා මුලින් කියලා තියෙන සියලුම මොඩ', 'so': "We describe our submitted system to the 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic (Abu Farha et al., 2021).  Waxaannu qabannay labada samooyin, kuwaas oo ah Shaqeynta Sarcasm (Subtask 1) iyo fasaxa sanad (Subtask 2). Waxaannu isticmaalnay samooyin xarunta farshaxanta ah oo la soo jeedo qoraal-muuqashada, waxaana ku hagaajinay si waafaqsan shaqada hoose. Dhaqdhaqaaq ugu horeeyay, waxaynu isticmaalnay Google's bir luuqadood oo kala duduwan BERT kadibna qaar kale oo Carabi ah: AraBERT, ARBERT iyo MARBERT. Midhihii la soo saaray waxay muuqatay in MARBERT uu dhamaan tusaalihii hore oo la soo sheegay oo dhan, waxayna ku qoran yihiin Sub-task 1 ama Sub-task 2.", 'sv': 'Vi beskriver vårt inlämnade system till 2021 Shared Task on Sarkasm and Sentiment Detection på arabiska (Abu Farha et al., 2021). Vi tog itu med båda underuppgifterna, nämligen Sarkasm Detection (deluppgift 1) och Sentiment Analysis (deluppgift 2). Vi använde toppmoderna, kontextualiserade textrepresentationsmodeller och finjusterade dem enligt den efterföljande uppgiften. Som ett första tillvägagångssätt använde vi Googles flerspråkiga BERT och sedan andra arabiska varianter: AraBERT, ARBERT och MARBERT. Resultaten visar att MARBERT överlappar alla tidigare nämnda modeller totalt, antingen på deluppgift 1 eller deluppgift 2.', 'ta': '2021 பகிர்ந்த பணிக்கு எங்கள் வழங்கப்பட்ட அமைப்பை நாம் விவரிக்கிறோம் சார்காஸ்ம் மற்றும் சென்டிமென்ட் தீர்வு அரபி கண்டு நாங்கள் இருவரும் துணை பணிகளை tackled, Sarcasm Detection (Subtask 1) மற்றும் Sentiment Analysis (Subtask 2). நாங்கள் கலை நிலைமையை பயன்படுத்தி நினைவூட்டப்பட்ட உரை குறிப்பிட்ட மாதிரிகளை பயன்படுத்தினோம் மற்றும் கீழ் நீர் பணியின் க முதல் வழியாக, நாம் கூகுலின் பல மொழி பெர்ட் மற்றும் மற்ற அரபி மாறிகளை பயன்படுத்தினோம்: அராபெர்ட், ஆர்பெர்ட் மற்றும் MARBERT முடிவுகள் கண்டுபிடிக்கப்பட்டது MARBERT முந்தைய குறிப்பிட்ட மாதிரிகளை அனைத்தையும் வெளியிடும் என்பதை காட்டு', 'ur': 'ہم نے اپنے تسلیم سیسٹم کو 2021 میں شریک تابع کے بارے میں عربی (Abu Farha et al., 2021) کے بارے میں بیان کیا ہے۔ ہم نے دونوں سپٹ سپٹ سپٹ سپٹ سپٹ سپٹ سٹ کاسم ڈیٹ (Subtask 1) اور Sentiment Analysis (Subtask 2) کو حل کیا۔ ہم نے ان کی حالت-of-the-art-pretrained contextualized text representation models استعمال کیا اور ان کو نیچے کام کے مطابق ٹھیک ٹھیک ٹھیک ٹھیک کر دیا۔ ہم نے گگل کی بہت سی زبان BERT اور اس کے بعد دوسری عربی متفاوت استعمال کیا: عربی، آربرت اور ماربرت. نتائج موجود ہوئے کہ MARBERT پہلے سے ذکر کیے ہوئے موڈلوں کو سب سے زیادہ اضافہ کرتا ہے یا Subtask 1 یا Subtask 2 پر۔', 'mn': 'Бид 2021 оны Саркассм болон Сэтгэл Тайлбарын тухай хуваалтын системийг Араб (Abu Farha et al., 2021) хэлэхэд тайлбарлаж байна. Бид хоёр дахин сурагчдыг зохицуулсан. Яг л Саркассмын Detection (Subtask 1) болон Sentiment Analysis (Subtask 2). Бид урлагийн хувьд орчин үеийн хувьд орчин үеийн төлөвлөгөөний загварыг ашиглаж, тэднийг гар доош дахь ажил дээр тодорхойлдог. Эхний арга хэмжээнд бид Google-ын олон хэлний BERT болон өөр араб хэлбэрүүдийг ашиглаж, АРБЕРТ, АРБЕРТ, МАРБЕРТ. МАРБЕРТ өмнө нь хэлсэн бүх загваруудыг нэмэгдүүлж байгааг харуулсан нь Subtask 1 эсвэл Subtask 2-д харуулсан.', 'no': 'Vi beskriver system et vårt som er sendt til den delte oppgåva 2021 på Sarkasm- og Sentiment- oppdaging i arabisk (Abu Farha et al., 2021). Vi løyste begge underspørsmål, som er «Sarkasm Detection» (Subtask 1) og «Sentiment Analysis» (Subtask 2). Vi brukte kontekstualiserte tekstrepresentasjonsmodular for tilstanden av kunsten og finne oppsett av dei etter nedstrømmeoppgåva i hånd. Som første tilnærming brukte vi Google sin fleirspråk BERT og deretter andre arabiske variantar: AraBERT, ARBERT og MARBERT. Dette finne resultatet viser at MARBERT utfører alle førehandsviste modelane, anten på Subtask 1 eller Subtask 2.', 'uz': "Biz 2021-yil Sarkasm va Sentiment Tayyorlariga qanday qilingan vazifani o'rganishga qaramamiz (Abu Farha et al, 2021). Biz ikkita vazifalarni, Sarkasm aniqlashni (Subtask 1) va Sentiment Analysis (Subtask 2) bilan birlashdik. Biz yozib qo'llangan matn taʼminlovchisi modellaridan foydalanamiz va ularni ishlab chiqaramiz. Birinchi darajada, biz Google tilidagi BERT va keyin arab varianlaridan foydalanamiz: AraBERT, ARBERT va MARBERT. @ info: status", 'vi': 'Chúng tôi mô tả hệ thống được gửi đến Kế hoạch chia sẻ của chúng tôi về Sarcasm và tình báo trinh sát bằng tiếng Ả Rập (Abu Farha et al., 2021). Chúng tôi xử lý cả hai mặt phụ đề, là âm mưu phát hiện ra (giấu 1) và phân tích tình cảm (giấu 2). Chúng tôi đã sử dụng các mô hình văn bản định sẵn tinh vi và chỉnh sửa chúng theo công việc xuôi dòng. Cách tiếp cận đầu tiên, chúng tôi s ử dụng loại BERT đa dạng của Google và các biến thể khác nhau là AraBERT, ARBERT và MABERT. Kết quả tìm thấy cho thấy MABERT hoàn thành tất cả các mô hình được đề cập đến, cả trong phần phụ đề này, hoặc giấu 1 hoặc giấu 2.', 'bg': 'Описваме подадената от нас система към Споделената задача за откриване на сарказъм и чувства през 2021 г. на арабски език (Абу Фарха и др., 2021). Разгледахме и двете подзадачи, а именно откриване на сарказма (подзадача 1) и анализ на чувствата (подзадача 2). Използвахме най-съвременни предварително обучени контекстуализирани модели за представяне на текста и ги прецизно настроихме според текущата задача надолу по веригата. Като първи подход използвахме многоезичния BERT на Гугъл, а след това и други арабски варианти: AraBERT, ARBERT и MARBERT. Резултатите показват, че МАРБЕРТ превъзхожда всички гореспоменати модели като цяло, както при Подзадача 1, така и при Подзадача 2.', 'hr': 'Mi opisujemo svoj podignut sustav na zajednički zadatak 2021. godine o otkrivanju Sarkazma i Sentimenta na arapskom (Abu Farha et al., 2021). Uradili smo obe podatke, a to je detekcija Sarkasma (podzadatak 1) i analiza Sentimenta (podzadatak 2). Koristili smo modele predstavljanja teksta predstavljanja predstavljanja stanja umjetnosti i ispravljali ih u skladu s donjem zadatkom u ruci. Kao prvi pristup, koristili smo Google multijezički BERT i drugi arapski varianti: AraBERT, ARBERT i MARBERT. Nalazeni rezultati pokazuju da MARBERT iznosi sve prethodno spomenute modele, ili na subtask 1 ili Subtask 2.', 'da': 'Vi beskriver vores indsendte system til 2021 Shared Task on Sarkasm and Sentiment Detection på arabisk (Abu Farha et al., 2021). Vi tacklede begge underopgaver, nemlig Sarkasm Detection (Underopgave 1) og Sentiment Analysis (Underopgave 2). Vi brugte state-of-the-art forudtrænede kontekstualiserede tekstrepræsentationsmodeller og finjusterede dem i henhold til den efterfølgende opgave. Som en første tilgang brugte vi Googles flersprogede BERT og derefter andre arabiske varianter: AraBERT, ARBERT og MARBERT. Resultaterne viser, at MARBERT overgår alle de tidligere nævnte modeller generelt, enten på Underopgave 1 eller Underopgave 2.', 'nl': "We beschrijven ons ingediende systeem voor de 2021 Shared Task on Sarcasme and Sentiment Detection in Arabic (Abu Farha et al., 2021). We hebben beide subtaken aangepakt, namelijk Sarcasme Detection (Subtaak 1) en Sentiment Analysis (Subtaak 2). We gebruikten state-of-the-art vooraf getrainde contextualiseerde tekstrepresentatiemodellen en verfijnen deze volgens de onderliggende taak. Als eerste aanpak gebruikten we Google's meertalige BERT en vervolgens andere Arabische varianten: AraBERT, ARBERT en MARBERT. De gevonden resultaten tonen aan dat MARBERT alle eerder genoemde modellen overtreft, zowel op Subtaak 1 als Subtaak 2.", 'de': 'Wir beschreiben unser eingereichtes System zur 2021 Shared Task on Sarkasm and Sentiment Detection auf Arabisch (Abu Farha et al., 2021). Wir haben beide Teilaufgaben angegangen, nämlich Sarkasmus-Erkennung (Teilaufgabe 1) und Sentiment-Analyse (Teilaufgabe 2). Wir nutzten modernste, vortrainierte Textdarstellungsmodelle und passten diese an die nachfolgende Aufgabe an. Als ersten Ansatz verwendeten wir Googles mehrsprachiges BERT und dann weitere arabische Varianten: AraBERT, ARBERT und MARBERT. Die gefundenen Ergebnisse zeigen, dass MARBERT alle oben genannten Modelle insgesamt übertrifft, entweder auf Subtask 1 oder Subtask 2.', 'id': 'Kami menggambarkan sistem kami yang dikirim ke tugas berbagi 2021 tentang Sarkasme dan Deteksi Sentiment dalam bahasa Arab (Abu Farha et al., 2021). Kami mengatasi kedua subtasks, namely Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2). Kami menggunakan model penggambaran teks kontekstualisasi yang terbaik dan memperbaikinya sesuai dengan tugas turun di tangan. Sebagai pendekatan pertama, kami menggunakan BERT berbilang bahasa Google dan kemudian varian Arab lainnya: AraBERT, ARBERT dan MARBERT. Hasil yang ditemukan menunjukkan bahwa MARBERT melampaui semua model yang sebelumnya disebutkan secara keseluruhan, baik pada Subtask 1 atau Subtask 2.', 'ko': '2021년 아랍어 풍자와 정서 감지 공유 임무에 제출된 시스템(Abu Farha et al., 2021)을 설명합니다.우리는 풍자검측(자임무1)과 정서분석(자임무2) 두 개의 하위 임무를 처리했다.우리는 가장 선진적인 예훈련 어경화 텍스트 표시 모델을 사용하고 수중의 하류 임무에 따라 이를 미세하게 조정했다.첫 번째 방법으로 우리는 구글의 다국어 BERT를 사용했고 그 다음에 다른 아랍어 변체인 아라BERT, ARBERT와 MARBERT를 사용했다.그 결과 하위 퀘스트 1이든 하위 퀘스트 2든 MARBERT의 전체적인 표현은 앞에서 언급한 모든 모델보다 우수하다는 것을 알 수 있다.', 'fa': 'ما سیستم تحویل داده شده\u200cایم به کار مشترک در سال ۲۰۱۱ در مورد کشف سارکاسم و آزمایش سنتی در عربی (Abu Farha et al., 2021) توصیف می\u200cکنیم. ما هر دوی زیر سوال ها را حل کردیم، یعنی کشف سارکاسم (Subtask 1) و تحلیل سنتی (Subtask 2). ما از مدل نمایش متن\u200cهای متن\u200cشناسایی\u200cشده\u200cی موقعیت هنر استفاده کردیم و آنها را به توجه به کار پایین\u200cترین دستگیر کردیم. به عنوان یک دستور اول، ما از BERT multilingual Google استفاده کردیم و بعد متغیرات دیگر عربی: AraBERT, ARBERT و MARBERT. نتیجه یافته نشون میده که MARBERT تمام مدل\u200cهای پیش\u200cگفته\u200cشده\u200cاند، یا در Subtask 1 یا Subtask 2، بیشتر از آن انجام می\u200cدهد.', 'af': "Ons beskrywe ons voorgestuurde stelsel aan die 2021 Gedeelde Opdrag op Sarkasm en Sentiment Opdekking in Arabiese (Abu Farha et al., 2021). Ons het beide subtaske gehandel, naamlik Sarkasm Opdekking (Subtask 1) en Sentiment Analysis (Subtask 2). Ons gebruik state-of-the-art voorgeskryf contextualiseerde teks verteenwoordigheidmodele en het hulle gevind volgens die onderstreem taak in hand. As 'n eerste toegang, gebruik ons Google se multitaalse BERT en dan ander Arabiese variante: AraBERT, ARBERT en MARBERT. Die resultate gevind vertoon dat MARBERT uitvoer alle van die vorige gemerkte modele in die hele manier, of op Subtask 1 of Subtask 2.", 'sw': 'Tunaelezea mfumo wetu uliotolewa kwa kazi ya mwaka 2021 iliyoashirikishwa kwa Sarcasm na Utafiti wa Kiarabu (Abu Farha et al, 2021). Tulikutana na kazi zote hizo, yaani Uchunguzi wa Sarcasm (Uchunguzi wa Kazi 1) na Uchambuzi wa Timu (Ujumbe wa 2). Tulitumia hali ya sanaa iliyoendelea kutengeneza mifano ya uwakilishi wa maandishi yaliyotajwa na kuwapa vizuri kwa mujibu wa kazi ya chini ya mto. Kama mbinu ya kwanza, tulitumia BERT ya lugha mbalimbali za Google na kisha tofauti nyingine za Kiarabu: AraBERT, ARBERT na MARBERT. Matokeo yalionyesha kwamba MARBERT inaonyesha mifano yote yaliyotajwa hapo awali kwa ujumla, au kwenye Ujumbe wa 1 au Ujumbe wa 2.', 'sq': 'Ne e përshkruajmë sistemin tonë të paraqitur në detyrën e përbashkët të 2021 mbi Sarkazmin dhe Detektimin e Sentimenteve në arabisht (Abu Farha et al., 2021). Ne trajtuam të dy nëndetyrat, veçanërisht zbulimin e Sarkazmit (Subdetyra 1) dhe Analizën e Sentimenteve (Subdetyra 2). Kemi përdorur modele të përfaqësimit të tekstit kontekstualizuar dhe i kemi rregulluar sipas detyrës së poshtme në dorë. Si një qasje e parë, ne përdorëm BERT shumëgjuhës të Google dhe pastaj variante të tjera arabe: AraBERT, ARBERT dhe MARBERT. Rezultatet e gjetura tregojnë se MARBERT kryen të gjitha modelet e përmendur më parë në përgjithësi, ose në Subtask 1 ose Subtask 2.', 'tr': "2021-nji ýylda Sarkasm we Sentiment Detection (Abu Farha et al., 2021) sistemamyzy jemgyýetlendirdik. Biz ikimiz alt soraglary çözdik diýmek Sarcasm Detection (Subtask 1) we Sentiment Analysis (Subtask 2). Biz suçlu önüne getirilen metin örneklerini kullandık ve onları ellerinde indirilen görevlere göre şekillendirdik. Ilkinji gezek olarak Google'yň çoklu dilli BERT we soňra başka arapça wariantlaryny ulandyk: AraBERT, ARBERT we MARBERT. Netijeler tapyldylar MARBERT öňünden berilen nusgalaryň hemmesiniň üstünde ýa Subtask 1 ýa Subtask 2-inde täsir edýändigini görkeýär.", 'hy': "Մենք նկարագրում ենք մեր ներկայացված համակարգը 2021 թվականին ընդհանուր Սարկազմի և զգացմունքների հայտնաբերման խնդիրը արաբերենով (Աբու Ֆարա և այլն., 2021 թվականը): Մենք վերաբերեցինք երկու ենթախնդիրներին, հատկապես Սարկազմի հայտնաբերման (ենթախնդիր 1) և զգացմունքների վերլուծության (ենթախնդիր 2): Մենք օգտագործեցինք ամենաբարձր տեքստի ներկայացման մոդելներ, որոնք նախապատրաստված էին տեքստի ներկայացման կոնտեքստում, և բարձրացրեցինք դրանք ըստ ձեռքում գտնվող վերջնական խնդրի: Առաջին մոտեցումն այն էր, որ մենք օգտագործեցինք Google-ի բազլեզու BER-ը, հետո նաև այլ արաբական տարբերակներ' Արաբերթը, Արբերթը և Մարբերթը: Բացահայտված արդյունքները ցույց են տալիս, որ MARBER-ը գերազանցում է նախկինում նշված բոլոր մոդելները, կամ ենթախնդիր 1 կամ ենթախնդիր 2:", 'az': "Biz h…ômin sistemimizi 2021-ci ild…ô Sarkasm v…ô Sentiment Detection bar…ôsind…ô t…ôsdiql…ônmiŇü Ňü…ôkild…ô t…ôsdiql…ôyirik (Abu Farha et al., 2021). Biz h…ôr ikisini d…ô √ß…ôkdik: Sarkasm Detection (Subtask 1) v…ô Sentiment Analysis (Subtask 2). Biz sanatńĪn v…ôziyy…ôti t…ômizl…ôndirilmiŇü m…ôtn g√∂st…ôricisi modell…ôrini istifad…ô etdik v…ô onlarńĪ …ôlind…ô aŇüańüńĪ t…ômizl…ôndirdik. ńįlk t…ôrzim olaraq Google'un √ßox dilli BERT v…ô sonra baŇüqa …ôr…ôbc…ô d…ôyiŇüiklikl…ôrini kullandńĪq: AraBERT, ARBERT v…ô MARBERT. G√∂r√ľnm√ľŇü sonu√ßlar, MARBERT, …ôvv…ôlc…ô bel…ô deyil…ôn modell…ôrin hamńĪsńĪnńĪ, ya Subtask 1, ya da Subtask 2 √ľzerind…ô √ľst√ľn etdiyini g√∂st…ôrir.", 'am': 'በዐረብኛ ቋንቋ ውስጥ በ2021 የተሰራጨውን ስራዎችን እና በዓረብኛ (አቡ ፋርሐ et al., 2021) እናሳውቃለን፡፡ ሳርካሲም መግለጫ እና የሳንሰዓት Analysis (Submission 2) የሚባልን ሁለትን ስራዎችን አቀናብናል፡፡ የ-አካባቢው ሥርዓት የጽሑፍ መልዕክት አካባቢ እና እንደታችኛው ፈሳሽ ስራ እጁን በመጠቀም አቀረብን፡፡ የመጀመሪያ ደረጃዎች፣ የጎግል ቋንቋ ቋንቋ ብሬት እና ከዚያም በኋላ ሌሎችን አረቢያ መለያየት፤ አርቢርት፣ አርቢርት እና ማርብሬት፡፡ ፍሬዎቹም ማርBERT አስቀድሞው የተናገረውን ዓይነቶች በሙሉ እንዲያወጣ ያሳያል፡፡', 'bs': 'Opišemo svoj podignut sistem na zajednički zadatak 2021. godine o otkrivanju sarkazma i sentimenta na arapskom (Abu Farha et al., 2021). Uradili smo obe podatke, a to je detekcija Sarkazma (Subtask 1) i Sentiment Analysis (Subtask 2). Koristili smo modele predstavljanja teksta koji su predstavljeni u suštini umjetnosti i ispravljali ih u skladu s donjem zadatkom u ruci. Kao prvi pristup, koristili smo Google multijezički BERT i drugi arapski varianti: AraBERT, ARBERT i MARBERT. Pronađeni rezultati pokazuju da MARBERT iznosi sve prethodno spomenute modele, ili na Subtask 1 ili Subtask 2.', 'ca': "Descrivem el nostre sistema submetit a la Task Shared on Sarcasm and Sentiment Detection in Arabic 2021 (Abu Farha et al., 2021). Vam abordar les dues subtaskes, a saber la detecció del sarcasme (Subtasca 1) i l'anàlisi del sentiment (Subtasca 2). Vam utilitzar models de representació de textos contextualitzats i actualitzats segons la tasca avall a mà. Com a primer enfocament, vam utilitzar el BERT multilingüe de Google i després altres variants àrabs: AraBERT, ARBERT i MARBERT. Els resultats descoberts mostran que MARBERT supera tots els models mencionats anteriorment en general, tant en Subtasca 1 com en Subtasca 2.", 'bn': 'আমরা ২০২১ সার্কাস এবং সেন্টাইমেন্ট ডিটেক্টরেশনের বিষয়টিকে ২০১২ সালের শেয়ার করা কাজের কাছে আমাদের জমা ব্যবস্থা বর্ণন We tackled both subtasks, namely Sarcasm Detection (Subtask 1) and Sentiment Analysis (Subtask 2).  আমরা প্রতিযোগিতার প্রতিনিধিত্বের প্রতিনিধিত্বের মডেল ব্যবহার করেছিলাম এবং নীচের প্রান্তের কাজ অনুসারে তাদের সুন্দর কর প্রথম প্রতিক্রিয়া হিসেবে আমরা গুগলের বহুভাষায় ভাষায় ব্যবহার করেছি এবং তারপর আরবী ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ফলাফল পাওয়া গেছে যে পূর্ববর্তী উল্লেখিত সকল মডেলের আউটপালন করে, সাববাস ১ অথবা সাবটাস ২ এ।', 'et': "Kirjeldame oma esitatud süsteemi 2021. aasta sarkasmi ja tunnete tuvastamise jagatud ülesandele araabia keeles (Abu Farha et al., 2021). Tegelesime mõlema alamülesandega, nimelt sarkasmi tuvastamisega (alaülesanne 1) ja tunnete analüüsiga (alaülesanne 2). Kasutasime kaasaegseid kontekstualiseeritud tekstiesitusmudeleid ja täpsustasime neid vastavalt käesolevale ülesandele. Esimese lähenemisena kasutasime Google'i mitmekeelset BERT-i ja seejärel teisi araabia variante: AraBERT, ARBERT ja MARBERT. Leitud tulemused näitavad, et MARBERT ületab kõiki eelnevalt nimetatud mudeleid üldiselt, kas alaülesandel 1 või alaülesandel 2.", 'cs': 'Popisujeme náš předložený systém pro sdílený úkol o sarkasmu a detekci sentimentů v arabštině (Abu Farha et al., 2021). Zabývali jsme se oběma podúkoly, konkrétně detekcí sarkasmu (subúkol 1) a analýzou sentimentů (subúkol 2). Použili jsme nejmodernější předtrénované kontextualizované modely reprezentace textu a jemně je vyladili podle následného úkolu. Jako první přístup jsme použili Google vícejazyčný BERT a další arabské varianty: AraBERT, ARBERT a MARBERT. Zjištěné výsledky ukazují, že MARBERT celkově překonává všechny dříve zmíněné modely, ať už na Subúkolu 1 nebo Subúkolu 2.', 'fi': 'Kuvaamme lähetettyä järjestelmäämme vuoden 2021 sarkasmin ja tunteiden havaitsemisen jaettuun tehtävään arabiaksi (Abu Farha et al., 2021). Käsiteltiin molempia alitehtäviä eli sarkasmin havaitsemista (alatehtävä 1) ja tunteiden analysointia (alatehtävä 2). Käytimme viimeisimpiä esikoulutettuja kontekstualisoituja tekstiesitysmalleja ja hienosäädimme niitä alaspäin tehtävän mukaan. Ensimmäisenä lähestymistapana käytimme Googlen monikielistä BERT-versiota ja sen jälkeen muita arabialaisia versioita: AraBERT, ARBERT ja MARBERT. Tulokset osoittavat, että MARBERT suoriutuu kaikista edellä mainituista malleista, joko alatehtävässä 1 tai alatehtävässä 2.', 'jv': 'Awakdhéwé nggawe sistem sing berarti kanggo nggawe Tarjamahan ning Sarkasm lan Sentiment We nambah duruh duruh basan, namely Sarkasm detection (Subtask 1) lan Sentiment Test (Subtask 2). Awakdhéwé wis nambah state-of-the-arts Ngawe Perintain contextual tekan kelangan anyar tentang karo nggawe barang kelangan manut. Tampilan perusahaan, kita sampeyan BERT multilengu Google lan sampeyan variant arab liyane: araBERT, ARBERT lan MARBERT. Rejaliane ono bukane mungkin MARBERT iso nggawe akeh model sing dumadhi nang saben, maneh ni Subtask 1 Uto Subtask 2.', 'ha': "Tuna bayyana na'uranmu wanda aka bai wa aikin da aka yi shirin aiki a 2021 na Sarcasm da Sakamant na Larabci (Abu Farha et al, 2021). Mun karɓi abubuwa biyu, kamar Sarcasm Mai gane (Subaikin 1) da Analyze na Saukar (Subaikin 2). Mun yi amfani da halin-kunyar da aka ambaci misãlai masu tsari na matsayin da kuma Muka gyara su da kuma da aikin da ke damƙar. Kayya da na farko, mun yi amfani da Google's mulki-harshen BERT kuma da wasu variants na Larabci: AraBERT, ArBERT da MARBERT. Mataimakin ya nuna cewa MARBERT na tafiyar da duk misãlai na zaman a faɗi, ko kan Subaikin 1 ko Subaikin 2.", 'he': 'אנחנו מתארים את המערכת המועברת שלנו למשימה משותפת של 2021 על סרקזם ובגלל רגשות בערבית (Abu Farha et al., 2021). התמודדדנו עם שני השאלות, בין הן גילוי סרקזם (Subtask 1) ואנליזה רגשות (Subtask 2). השתמשנו בדוגמנים של מייצג טקסט מקונטוקטואליזציה מוקדמת ומתאים אותם לפי המשימה המאוחרת ביד. בתור גישה ראשונה, השתמשנו בברט רבולוגי של גוגל ואז שונים ערביים אחרים: ארברט, ארברט ומארברט. התוצאות שנמצאו מראות שמארברט מפעיל את כל הדוגמנים הנזכרים קודם באופן כללי, או על Subtask 1 או Subtask 2.', 'sk': 'Opisujemo naš sistem, predložen v skupno nalogo o sarkazmu in odkrivanju čustev 2021 v arabščini (Abu Farha et al., 2021). Ukvarjali smo se z obema podnalogama, in sicer z odkrivanjem sarkazma (podnaloga 1) in analizo čustva (podnaloga 2). Uporabili smo najsodobnejše vnaprej trenirane kontekstualizirane modele predstavitve besedila in jih natančno nastavili glede na zadevno nalogo. Kot prvi pristop smo uporabili Googlov večjezični BERT, nato pa druge arabske različice: AraBERT, ARBERT in MARBERT. Najdeni rezultati kažejo, da je MARBERT na splošno boljši od vseh prej omenjenih modelov, bodisi pri podnalogi 1 ali podnalogi 2.', 'bo': 'ང་ཚོས་དུས་མཐུན་གྱི་མ་ལག་གསལ་གྱིས་2021 རིང་སྤྱད་པའི་ལས་འགན་སྦྲེལ་བའི་བྱ་རིམ་ལ་བཤད་པ་ཡིན། ང་ཚོས་རྒྱབ་སྐྱོར་གཉིས་ཀྱིས་གནད་དོན་དག་བརྟན་པར་ Sarcasm Detection (Subtask 1)དང་Sentiment Analysis (Subtask 2)ལ་དུ་བཏོན་བྱུང་། ང་ཚོས་རང་ཉིད་ཀྱི་གནས་སྟངས་སྔོན་ལྟར་འཇུག་བྱེད་པའི་ཡིག་གེ་མིང་ཚོའི་གནས་སྟངས་ལ་ལག་ལེན་འཐབ་བྱེད་ཀྱི་ཡོད། སྔོན་འཛིན་གྱི་ཐབས་ལམ་ལྟར་ངེད་གཉིས་ཀྱི་སྣ་བརྗོད་ཀྱི་BERT་དང་ ཨ་རབ་ཀྱི་སྔོན་སྒྲིག་སྟངས་གཞན་ཚུ་སྤྱོད་པ་ཡིན། AraBERT, ARBERT་ གྲུབ་འབྲས་བྱ་ཚིག་དག་པས། MARBERT་གིས་སྔོན་གྱིས་ཟིན་པའི་མིག་དཔེ་དབྱིབས་ཡོངས་བསྡུར་བ་ཡིན་ན། ཡང་ན་Subtask 1 དང་Subtask 2 ཐོག'}
{'en': 'AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'pt': 'Abordagem baseada em segmentação AraBERT e Farasa para detecção de sarcasmo e sentimento em tweets em árabe', 'ar': 'نهج أرابرت وفراسة القائم على التقسيم للسخرية والكشف عن المشاعر في التغريدات العربية', 'es': 'Enfoque basado en la segmentación de AraBert y Farasa para la detección de sarcasmo y sentimiento en tuits árabes', 'fr': 'Approche basée sur la segmentation AraBert et Farasa pour la détection du sarcasme et des sentiments dans les tweets en arabe', 'ja': 'アラビア語のツイートで皮肉と感情を検出するためのAraBERTとFarasaのセグメンテーションベースのアプローチ', 'zh': 'AraBERT与Farasa略分,阿拉伯语推文刺情', 'hi': 'अरबी ट्वीट्स में व्यंग्य और भावना का पता लगाने के लिए AraBERT और Farasa विभाजन आधारित दृष्टिकोण', 'ru': 'AraBERT и Farasa основанный на сегментации подход к обнаружению сарказма и сентиментов в арабских твитах', 'ga': 'Cur Chuige Bunaithe ar Dheighleán AraBERT agus Farasa Chun Sarcasm agus Brath Meinteála in Araibis Tweets', 'ka': 'AraBERT და Farasa Segmentation Based Approach for Sarcasm and Sentiment Detection in Arabic Tweets', 'el': 'Προσέγγιση βάσει τμημάτων AraBERT και Farasa για τον σαρκασμό και την ανίχνευση συναισθημάτων σε αραβικά τουίτετ', 'hu': 'AraBERT és Farasa szegmentációs alapú megközelítés a szarkazmus és az érzelmek felismerésére arab tweetekben', 'it': 'Approccio basato sulla segmentazione di AraBERT e Farasa per la rilevazione del sarcasmo e dei sentimenti nei tweet arabi', 'lt': 'AraBERT ir Farasos segmentacija grindžiamas metodas sarkazmui ir jautrumui aptikti arabų dviejuose tinkluose', 'kk': 'AraBERT және Farasa сегментациясы Саркассм және Сентиментті табу үшін негізделген қатынау', 'ms': 'Pendekatan Berasas Segmentasi AraBERT dan Farasa Untuk Pengesanan Sarkasm dan Sentiment dalam Tweets Arab', 'ml': 'അരാബെര്\u200dട്ടിയും ഫാറാസ സ സെഗ്മെന്റേഷന്\u200d അടിസ്ഥാനത്തില്\u200d സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റീഷനും അറബിയിലെ ടൂട്ടു', 'mt': 'L-Approċċ Ibbażat fuq is-Segmentazzjoni tal-AraBERT u l-Farasa għas-Sarkazmu u d-Detezzjoni tas-Sentiment fit-Tweets Għarab', 'mn': 'AraBERT, Farasa Segmentation Based Approach for Sarcasm and Sentiment Detection in Arabic Tweets', 'no': 'AraBERT og Farasa Segmentation Based Approach For Sarcasm- og Sentiment- oppdaging i arabiske tweeter', 'pl': 'Podejście oparte na segmentacji AraBERT i Farasa do wykrywania sarkazmu i sentymentów w arabskich tweetach', 'ro': 'Abordarea bazată pe segmentare AraBERT și Farasa pentru detectarea sarcasmului și sentimentelor în tweeturile arabe', 'so': 'AraBERT iyo Farasa Segmentation Based on Approach for Sarcasm and Sentiment in Arabic Tweets', 'sv': 'AraBERT och Farasa segmenteringsbaserad metod för sarkasm och känslodetektering i arabiska tweets', 'ta': 'ஆர்பெர்ட் மற்றும் ஃபாராசா பிரிவு சார்காஸ்ம் மற்றும் சென்டிமென்ட் கண்டுபிடிப்பதற்கு அடிப்படையான தொடர்பு', 'ur': 'AraBERT اور Farasa Segmentation Based Approach for Sarcasm and Sentiment Detection in Arabic Tweets', 'si': 'AraBERT සහ FarasaSecmentation', 'mk': 'АраБЕРТ и Фараса-сегментација-базиран пристап за сарказам и детекција на чувства на арапски твитови', 'sr': 'AraBERT i Farasa Segmentacija Na osnovu pristupa za detekciju sarkasma i sentimenta na arapskim tweetima', 'uz': 'AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'vi': 'Cách tiếp cận mật mã AraBERT và Farasa Vị trí Vị tha cho Sarcasm và cảm xúc phát hiện bằng Tweet tiếng Ả Rập.', 'hr': 'AraBERT i Farasa segmentacija temeljeni pristup za otkrivanje sarkasma i osjećajnog otkrivanja na arapskim tweetima', 'bg': 'Подход на сегментация за откриване на сарказъм и сентименти в арабски туитове', 'nl': 'AraBERT en Farasa Segmentatie Gebaseerde Aanpak voor Sarcasme en Sentiment Detection in Arabische Tweets', 'de': 'AraBERT und Farasa Segmentierungsbasierter Ansatz für Sarkasmus und Sentiment Detection in arabischen Tweets', 'da': 'AraBERT og Farasa segmenteringsbaseret tilgang til opdagelse af sarkasme og følelser i arabiske tweets', 'ko': '아라베트와 파라시아의 분할을 바탕으로 한 아랍어 트윗 풍자와 정서 검출 방법', 'id': 'AraBERT dan Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'fa': 'AraBERT و Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'sw': 'Kuhusu Ubaguzi wa AraBERT na Kupambana na Farasa kwa Kuhusu Uchaguzi wa Kiarabu na Kutambua Wakati kwa Kiarabu', 'am': 'አርቢERT እና የፋራሳ የሳርካሲም እና የሳንቲት ምርጫዎች በዐረብኛ Tweets', 'tr': 'AraBERT we Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'af': 'AraBERT en Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'az': 'AraBERT və Farasa Segmentation Based Approach for Sarcasm and Sentiment Detection in Arabic Tweets', 'bn': 'AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets', 'sq': 'Përqasje e bazuar në segmentimin e AraBERT dhe Farasa për Sarkazmin dhe zbulimin e ndjenjave në Tweets arabe', 'bs': 'AraBERT i Farasa segmentacija temeljeni pristup za otkrivanje sarkazma i sentimenta na arapskim tweetima', 'ca': 'AraBERT i Farasa Segmentation Based Approach for Sarcasm and Sentiment Detection on Arabic Tweets', 'cs': 'AraBERT a Farasa segmentační přístup pro detekci sarkasmu a citů v arabských tweetech', 'et': 'AraBERT ja Farasa segmentatsioonipõhine lähenemine sarkasmi ja tunnete tuvastamiseks araabia tweetides', 'hy': 'Արաբերթը և Ֆարասայի սեգրմացիայի հիմնված մոտեցումը Սարկազմի և զգացմունքների հայտնաբերման համար արաբական թվիթերում', 'fi': 'AraBERT- ja Farasa-segmentointipohjainen lähestymistapa sarkasmin ja tunteiden havaitsemiseen arabiankielisissä tweeteissä', 'jv': 'araBERT karo Faasa segmentation Ngawe Tarjamahan kanggo Sarkasm lan Sentiment', 'he': 'גישה מבוססת על סגמנטציה של ארבארט ופאראסה לגלות סרקזם וחושה בטוויטים ערביים', 'sk': 'AraBERT in Farasa Segmentacijski pristop za zaznavanje sarkazma in sentimenta v arabskih tweetih', 'ha': 'KCharselect unicode block name', 'bo': 'AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets'}
{'en': 'This paper presents our strategy to tackle the EACL WANLP-2021 Shared Task 2 : Sarcasm and Sentiment Detection. One of the subtasks aims at developing a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet. We approach the task in two steps. The first step involves pre processing the provided dataset by performing insertions, deletions and segmentation operations on various parts of the text. The second step involves experimenting with multiple variants of two transformer based models, AraELECTRA and AraBERT. Our final approach was ranked seventh and fourth in the Sarcasm and Sentiment Detection subtasks respectively.', 'ar': 'تقدم هذه الورقة استراتيجيتنا للتعامل مع المهمة المشتركة 2 لـ EACL WANLP-2021: الكشف عن السخرية والمشاعر. تهدف إحدى المهام الفرعية إلى تطوير نظام يحدد ما إذا كانت تغريدة عربية معينة ساخرة بطبيعتها أم لا ، بينما تهدف المهمة الأخرى إلى تحديد المشاعر في التغريدة العربية. نقترب من المهمة في خطوتين. تتضمن الخطوة الأولى المعالجة المسبقة لمجموعة البيانات المقدمة عن طريق إجراء عمليات الإدراج والحذف والتجزئة على أجزاء مختلفة من النص. تتضمن الخطوة الثانية تجربة متغيرات متعددة لنموذجين يعتمدان على المحولات ، AraELECTRA و AraBERT. احتل نهجنا الأخير المرتبة السابعة والرابعة في المهام الفرعية للكشف عن السخرية والمشاعر على التوالي.', 'es': 'Este documento presenta nuestra estrategia para abordar la tarea compartida 2 de EACL WANLP-2021: detección de sarcasmo y sentimientos. Una de las subtareas tiene como objetivo desarrollar un sistema que identifique si un tuit en árabe es de naturaleza sarcástica o no, mientras que la otra apunta a identificar el sentimiento del tuit en árabe. Abordamos la tarea en dos pasos. El primer paso consiste en procesar previamente el conjunto de datos proporcionado mediante la realización de operaciones de inserción, eliminación y segmentación en varias partes del texto. El segundo paso consiste en experimentar con múltiples variantes de dos modelos basados en transformadores, AraElectra y AraBert. Nuestro enfoque final ocupó el séptimo y cuarto lugar en las subtareas de detección de sarcasmo y sentimiento, respectivamente.', 'fr': "Cet article présente notre stratégie pour aborder la tâche partagée 2 de l'EACL WANLP-2021\xa0: Sarcasme et détection des sentiments. L'une des sous-tâches vise à développer un système qui identifie si un tweet en arabe donné est de nature sarcastique ou non, tandis que l'autre vise à identifier le sentiment du tweet arabe. Nous abordons la tâche en deux étapes. La première étape consiste à prétraiter l'ensemble de données fourni en effectuant des insertions, des suppressions et des opérations de segmentation sur différentes parties du texte. La deuxième étape consiste à expérimenter plusieurs variantes de deux modèles basés sur des transformateurs, AraElectra et AraBert. Notre approche finale a été classée septième et quatrième dans les sous-tâches de détection des sarcasmes et des sentiments, respectivement.", 'pt': 'Este artigo apresenta nossa estratégia para lidar com a tarefa compartilhada EACL WANLP-2021 2: detecção de sarcasmo e sentimento. Uma das subtarefas visa desenvolver um sistema que identifique se um determinado tweet árabe é de natureza sarcástica ou não, enquanto a outra visa identificar o sentimento do tweet árabe. Abordamos a tarefa em duas etapas. A primeira etapa envolve o pré-processamento do conjunto de dados fornecido, realizando operações de inserções, exclusões e segmentação em várias partes do texto. A segunda etapa envolve a experimentação de múltiplas variantes de dois modelos baseados em transformadores, AraELECTRA e AraBERT. Nossa abordagem final ficou em sétimo e quarto nas subtarefas Sarcasm e Sentiment Detection, respectivamente.', 'ja': '本稿では、EACL WANLP -2021共有タスク2 ：皮肉と感情の検出に取り組むための戦略を紹介します。サブタスクの1つは、特定のアラビア語のツイートが本質的に皮肉であるかどうかを識別するシステムを開発することを目的とし、もう1つはアラビア語のツイートの感情を識別することを目的としています。私たちは2つのステップでタスクに取り組みます。第１のステップは、テキストの様々な部分に挿入、削除、およびセグメンテーション操作を実行することによって、提供されたデータセットを事前処理することを含む。2番目のステップは、2つの変圧器ベースのモデル、AraELECTRAとAraBERTの複数のバリアントを実験することです。私たちの最終的なアプローチは、皮肉と感情検出サブタスクでそれぞれ7位と4位にランク付けされました。', 'zh': '本文引对EACL WANLP-2021共同任务2:刺情检策。 其一旨在发一统,当统可以识给定之阿拉伯语推文有刺性,而一指在识阿拉伯语推文之情。 分两步成务。 第一步及对文本诸部分插入、删割操作以预处理所供数集。 第二步及二变压器之多变体,AraELECTRAAraBERT。 我们的终于分别在刺情检测子中排名第七和第四。', 'hi': 'यह पेपर EACL WANLP-2021 साझा कार्य 2 से निपटने के लिए हमारी रणनीति प्रस्तुत करता है: व्यंग्य और भावना का पता लगाना। उप-कार्यों में से एक का उद्देश्य एक ऐसी प्रणाली विकसित करना है जो यह पहचानती है कि कोई दिया गया अरबी ट्वीट प्रकृति में व्यंग्यात्मक है या नहीं, जबकि दूसरे का उद्देश्य अरबी ट्वीट की भावना की पहचान करना है। हम दो चरणों में कार्य करते हैं। पहले चरण में पाठ के विभिन्न भागों पर सम्मिलन, विलोपन और विभाजन संचालन करके प्रदान किए गए डेटासेट को पूर्व-प्रसंस्करण करना शामिल है। दूसरे चरण में दो ट्रांसफॉर्मर आधारित मॉडल, AraELECTRA और AraBERT के कई रूपों के साथ प्रयोग करना शामिल है। हमारा अंतिम दृष्टिकोण व्यंग्य और भावना का पता लगाने वाले उपकारों में क्रमशः सातवें और चौथे स्थान पर था।', 'ru': 'В этом документе представлена наша стратегия решения Совместной задачи 2 EACL WANLP-2021: Обнаружение сарказма и сентиментов. Одна из подзадач направлена на разработку системы, которая определяет, является ли данный арабский твит саркастическим по своей природе, а другая - на выявление настроений арабского твита. Мы подходим к задаче в два этапа. Первый этап включает предварительную обработку предоставленного набора данных путем выполнения операций вставки, удаления и сегментации различных частей текста. Второй этап заключается в экспериментировании с несколькими вариантами двух моделей на основе трансформаторов, AraELECTRA и AraBERT. Наш окончательный подход занял седьмое и четвертое места в подзадачах «Сарказм» и «Обнаружение сентиментов» соответственно.', 'ga': 'Cuireann an páipéar seo i láthair ár straitéis chun dul i ngleic le Tasc Comhroinnte 2 EACL WANLP-2021: Sarcasm agus Brath Meon. Tá sé mar aidhm ag ceann de na subtascanna córas a fhorbairt a shainaithníonn an bhfuil tvuít áirithe Araibis sarcastach nó nach bhfuil, agus tá sé mar aidhm ag an gceann eile meon an tweet Araibis a aithint. Déanaimid an tasc in dhá chéim. Is éard atá i gceist leis an gcéad chéim ná an tacar sonraí a cuireadh ar fáil a réamhphróiseáil trí oibríochtaí a chur isteach, a scriosadh agus a dheighilt ar chodanna éagsúla den téacs. Baineann an dara céim le triail a bhaint as leaganacha iolracha de dhá mhúnla atá bunaithe ar chlaochladán, AraELECTRA agus AraBERT. Rinneadh ár gcur chuige deiridh a rangú sa seachtú agus sa cheathrú háit sna fo-thascanna Sarcasm agus Brath Mothúcháin faoi seach.', 'ka': 'ეს დოკუმენტი ჩვენი სტრატიგია EACL WANLP-2021-ის გაყოფილი დავალება 2: საპკასმი და სტრატიმენტის განახლება. ერთი სისტემის მიზეზი იქნება სისტემის განვითარება, რომელიც განვითარება, თუ არა არაბული სისტემის სისტემის სისტემის სისტემის შეცვალობა, თუ არა არაბული სისტემის სისტემის შეცვალობა. ჩვენ მივიღეთ საქმე ორი ნაწილში. პირველი კონფიგურაცია მონაცემების კონფიგურაციის პროცესის პირველი პროცესია ტექსტის განსხვავებული ნაწილად დაყენებული მონაცემების კონფიგურაციის, წ მეორე კონფიგურაცია გამოყენება ექსპერიმენტის მრავალ გარიანტებით ორი ტრანფიგურაციის მოდელების, AraELECTRA და AraBERT. ნაქთჲრ ოჲჟლვენთწრ ოპთჟლვე ბვქვ პვნეთპან ჟვემთ თ ფვრგყპრთ გ ჟაპკაჱმა თ ჟვნრთმვნრნა ევრვკუთწ.', 'el': 'Η παρούσα εργασία παρουσιάζει τη στρατηγική μας για την αντιμετώπιση της κοινής εργασίας 2: Σαρκασμός και ανίχνευση συναισθημάτων. Μια από τις δευτερεύουσες εργασίες στοχεύει στην ανάπτυξη ενός συστήματος που προσδιορίζει αν ένα συγκεκριμένο αραβικό tweet είναι σαρκαστικό ή όχι, ενώ η άλλη στοχεύει στον προσδιορισμό του συναισθήματος του αραβικού tweet. Προσεγγίζουμε το έργο σε δύο στάδια. Το πρώτο βήμα περιλαμβάνει την προεπεξεργασία του παρεχόμενου συνόλου δεδομένων με την εκτέλεση παρεμβάσεων, διαγραφών και εργασιών τμηματοποίησης σε διάφορα μέρη του κειμένου. Το δεύτερο βήμα περιλαμβάνει τον πειραματισμό με πολλαπλές παραλλαγές δύο μοντέλων βασισμένων σε μετασχηματιστές, AraELECTRA και AraBERT. Η τελική προσέγγισή μας κατατάχθηκε έβδομη και τέταρτη στις δευτερεύουσες εργασίες Σαρκασμού και Ανίχνευσης Συναισθημάτων αντίστοιχα.', 'hu': 'Ez a tanulmány bemutatja stratégiánkat az EACL WANNP-2021 Shared Task 2: Sarcasm and Sentiment Detection kezelésére. Az egyik részfeladat célja egy olyan rendszer kidolgozása, amely meghatározza, hogy egy adott arab tweet szarkasztikus-e vagy sem, míg a másik célja, hogy azonosítsa az arab tweet hangulatát. Két lépésben közelítjük meg a feladatot. Az első lépés a megadott adatkészlet előzetes feldolgozását jelenti a szöveg különböző részein a beszúrások, törlések és szegmentációs műveletek elvégzésével. A második lépés két transzformátor alapú modell, az AraELECTRA és az AraBERT többféle változatával való kísérletezést jelenti. A végső megközelítésünk a hetedik, illetve a negyedik lett a Szarkazmus és az Érzelmészlelés részfeladatokban.', 'it': "Questo articolo presenta la nostra strategia per affrontare l'EACL WANNP-2021 Shared Task 2: Sarcasm and Sentiment Detection. Uno dei sottocompiti mira a sviluppare un sistema che identifichi se un dato tweet arabo è sarcastico o meno, mentre l'altro mira a identificare il sentiment del tweet arabo. Approfondiamo il compito in due fasi. Il primo passo prevede l'elaborazione preliminare del set di dati fornito eseguendo operazioni di inserimento, cancellazione e segmentazione su varie parti del testo. Il secondo passo prevede la sperimentazione di molteplici varianti di due modelli basati su trasformatori, AraELECTRA e AraBERT. Il nostro approccio finale è stato classificato settimo e quarto rispettivamente nelle sottoattività Sarcasmo e Sentiment Detection.", 'kk': 'Бұл қағаз EACL WANLP- 2021 ортақ тапсырманы 2- ортақ тапсырманы шешу стратегиясын көрсетеді: Саркассм және сентименттік тапсырманы шешу. Басқалардың бірі араб тійтіні таңдау жүйесін жасау үшін, әрі араб тійтінің сезімін анықтау үшін, қайталанған жағдай, қайталанған жағдай таңдау үшін. Біз тапсырманы екі қадамда келеміз. Бірінші қадам келтірілген деректер жиынының бірнеше бөліктерінде ендіру, өшіру және сегментациялау операцияларын орындап алдын- ала процессерді қолданады. Екінші қадам, екі түрлендіруші үлгілерінің бірнеше түрлендіруші үлгілері, AraELECTRA және AraBERT тәжірибелерінің тәжірибелері бар. Біздің соңғы тәсіліміміз сарказм мен сентименттік табуының жетінші және төртінші ретінде сәйкес келді.', 'mk': 'Овој документ ја претставува нашата стратегија за решавање на EACL WANLP-2021 заедничка задача 2: Сарказам и Детектирање на чувствата. One of the subtasks aims at developing a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet.  Се приближуваме до задачата во два чекори. Првиот чекор вклучува преобработување на обезбедениот компјутер податоци со извршување на внесувања, бришење и сегментации на различни делови од текстот. Вториот чекор вклучува експериментирање со повеќе варијанти на два модели базирани на трансформатори, АРЕЛЕКТРА и АРАБЕРТ. Our final approach was ranked seventh and fourth in the Sarcasm and Sentiment Detection subtasks respectively.', 'ml': 'ഈ പത്രത്തില്\u200d എക്സില്\u200d വാന്\u200dലിപി-2021 പങ്കുചേര്\u200dത്ത ടാസ്ക് 2: സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റക്റ്റീഷന്\u200d ഒരു അറബി ട്വീറ്റ് സ്വഭാവികമാണോ എന്ന് നിരീക്ഷിക്കുന്ന ഒരു സിസ്റ്റത്തിന്റെ ലക്ഷ്യം ഉണ്ടാക്കുവാന്\u200d ഉദ്ദേശിക്കുന്നു. മറ്റൊരു അറബി  നമ്മള്\u200d രണ്ടു പടിയില്\u200d ജോലിയെ അടുത്തെത്തി. പദാവലിയുടെ വ്യത്യസ്ത ഭാഗങ്ങളില്\u200d ചേര്\u200dക്കുന്നത്, മായ്ച്ചുകളയുന്നതും വേര്\u200dപെടുത്തുന്നതിനുമുമ്പ് ഡാറ്റാസറ്റ് പ് രണ്ടാമത്തെ പടിയില്\u200d രണ്ട് മാറ്റങ്ങളുടെ അടിസ്ഥാനമായ മോഡലുകളില്\u200d പല മാറ്റങ്ങളുമായി പരീക്ഷിക്കുന്നതില്\u200d പരീക്ഷണത്തി നമ്മുടെ അവസാന സമ്പ്രദായം സർക്കാസം, സെന്റിമെന്റ് ഡിറ്റക്റ്റീഷനും സബ്ട്ടീമെന്റ് ജോലികളില്\u200d ഏഴും നാലാമത്', 'mn': 'Энэ цаас бидний EACL WANLP-2021 оны хуваалтын ажил 2: Сарказм болон сэтгэл хөдлөлийн олох стратегийг тайлбарладаг. Харин нэг нь Араб tweet гэдэг нь байгальд сайхан эсэхийг тодорхойлдог системийг хөгжүүлэх зорилго юм. Харин нөгөө нь Араб tweet гэдэг мэдрэмжийг тодорхойлдог. Бид үүнийг хоёр шатаар ойртож байна. Эхний алхам нь өгөгдлийн хэлбэрүүдийн олон хэсэгт оруулах, устгах, хэвлэх үйл ажиллагааг үйлдвэрлэхээр гаргасан өгөгдлийн хэлбэрүүдийг өмнө үйлдвэрлэх юм. Хоёр дахь алхам нь хоёр шилжүүлэгч загварын олон төрлийн төрлийн туршилт, AraELECTRA, AraBERT. Манай сүүлийн арга хэмжээнд сарказм болон сэтгэл санааны нээлттэй холбоотой 7-4 дүрс байлаа.', 'lt': 'This paper presents our strategy to tackle the EACL WANLP-2021 Shared Task 2: Sarcasm and Sentiment Detection.  One of the subtasks aims at developing a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet.  We approach the task in two steps.  The first step involves pre processing the provided dataset by performing insertions, deletions and segmentation operations on various parts of the text.  Antrasis etapas – eksperimentuoti su įvairiais dviejų transformatorių modelių variantais, AraELECTRA ir AraBERT. Mūsų galutinis požiūris buvo atitinkamai septintas ir ketvirtas Sarkazmo ir Sentimento aptikimo paklausose.', 'ms': 'Kertas ini memperkenalkan strategi kita untuk menangani EACL WANLP-2021 Tugas Berkongsi 2: Sarkasm dan Pengesanan. Salah satu subtanya bertujuan untuk mengembangkan sistem yang mengenalpasti sama ada tweet Arab yang diberikan adalah sarkastik dalam sifat atau tidak, sementara yang lain bertujuan untuk mengenalpasti perasaan tweet Arab. Kami mendekati tugas dalam dua langkah. The first step involves pre processing the provided dataset by performing insertions, deletions and segmentation operations on various parts of the text.  Langkah kedua melibatkan eksperimen dengan variasi berbilang dari dua model berasaskan pengubah, AraELECTRA dan AraBERT. Pendekatan terakhir kami ditangkap ke-7 dan ke-4 dalam Sarkasm dan Sentiment Detection subtasks sesuai.', 'pl': 'W niniejszym artykule przedstawiono naszą strategię rozwiązania wspólnego zadania EACL WALLP-2021: Sarkasm and Sentiment Detection. Jedno z podzadań ma na celu stworzenie systemu identyfikacji, czy dany arabski tweet ma sarkastyczny charakter, czy nie, natomiast drugie ma na celu zidentyfikowanie sentymentu arabskiego tweeta. Podchodzimy do zadania w dwóch etapach. Pierwszy krok polega na wstępnym przetwarzaniu dostarczonego zbioru danych poprzez wykonanie operacji wstawiania, usuwania i segmentacji na różnych częściach tekstu. Drugi etap polega na eksperymentowaniu z wieloma wariantami dwóch modeli opartych na transformatorach AraELECTRA i AraBERT. Nasze ostateczne podejście znalazło siódme i czwarte miejsce odpowiednio w podzadaniach Sarkasm i Detection Sentiment.', 'mt': 'Dan id-dokument jippreżenta l-istrateġija tagħna biex tindirizza l-EACL WANLP-2021 Kompitu Konġunt 2: Sarkazmu u Sejbien tas-Sentiment. Waħda mis-sottomistoqsijiet għandha l-għan li tiżviluppa sistema li tidentifika jekk tweet Għarbi partikolari huwiex ta’ natura sarkastika jew le, filwaqt li l-oħra għandha l-għan li tidentifika s-sentiment tat-tweet Għarbi. Aħna naħdmu l-kompitu f’żewġ passi. L-ewwel pass jinvolvi l-ipproċessar minn qabel tas-sett tad-dejta pprovdut billi jitwettqu l-inserzjonijiet, it-tħassir u l-operazzjonijiet ta’ segmentazzjoni fuq diversi partijiet tat-test. It-tieni pass jinvolvi l-esperimentazzjoni b’varjanti multipli ta’ żewġ mudelli bbażati fuq it-trasformaturi, AraELECTRA u AraBERT. Our final approach was ranked seventh and fourth in the Sarcasm and Sentiment Detection subtasks respectively.', 'ro': 'Această lucrare prezintă strategia noastră de abordare a sarcinii partajate EACL WANNP-2021 2: detectarea sarcasmului și sentimentelor. Unul dintre subactivități urmărește dezvoltarea unui sistem care identifică dacă un anumit tweet arab este sarcastic sau nu, în timp ce celălalt își propune să identifice sentimentul tweet arab. Ne apropiem de sarcină în doi paşi. Primul pas presupune prelucrarea prealabilă a setului de date furnizat prin efectuarea de inserări, ștergeri și operațiuni de segmentare pe diferite părți ale textului. Al doilea pas implică experimentarea cu mai multe variante a două modele bazate pe transformator, AraELECTRA și AraBERT. Abordarea noastră finală a fost clasată pe locul șaptea și al patrulea în subactivitățile Sarcasm și respectiv Sentiment Detection.', 'so': 'Kanu wuxuu keenaa qoraalkayagii aan u tacliino EACL WANLP-2021 Shaqada la sharciyey 2: Sarcasm iyo Xilliyeed. Shaqooyinka mid ka mid ah waxey ku qoran tahay horumarinta nidaam, kaas oo aqoonsan in twiti la siiyo Carabi uu dabiicadeed yahay ama aan aheyn, iyadoo ay ku qoran karto in kale uu aqoonsado fikrada Twitterka Carabiga ah. Waxaynu u soo dhowaynaa shaqada laba maro. Xarunta kowaad waxaa ka mid ah ka hor baaraandegista taariikhda lagu sameeyo qalabka, deletinta iyo qeybaha kala duduwan ee qoraalka. Xarunta labaad waxaa ka mid ah imtixaanka kala duduwan labada noocyo ee isbedelka, AraELECTRA iyo AraBERT. Dhaqdhaqaalkayagii ugu dambaysta ahaa waxaa lagu kala soocay shuqullada heshiiska heshiiska ee Sarkasm iyo heshiiska wakhtiga.', 'sv': 'Denna uppsats presenterar vår strategi för att hantera EACL WANNP-2021 Shared Task 2: Sarkasm och känslodetektering. En av underuppgifterna syftar till att utveckla ett system som identifierar om en viss arabisk tweet är sarkastisk till sin natur eller inte, medan den andra syftar till att identifiera känslan av den arabiska tweeten. Vi närmar oss uppgiften i två steg. Det första steget innebär förbehandling av den tillhandahållna datauppsättningen genom att utföra infogningar, raderingar och segmentering av olika delar av texten. Det andra steget innebär att experimentera med flera varianter av två transformatorbaserade modeller, AraELECTRA och AraBERT. Vårt slutliga tillvägagångssätt rankades sjunde och fjärde i Sarkasm respektive Sentiment Detection underaktiviteterna.', 'ta': 'இந்த காகிதம் EACL WANLP-2021 பகிர்ந்த பணி 2: Sarcasm மற்றும் Sentiment Detection. One of the subtasks aims at developing a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet.  நாம் இரண்டு படிகளில் பணியை நெருங்குகிறோம். முதல் படி கொடுக்கப்பட்ட தரவுத்தளத்தை முன் செயல்படுத்தும் முன் செயல்படுத்தும் உரையின் பல பகுதிகளில் உள்ள செருகுகள், நீக் இரண்டாவது படி இரண்டு மாற்றம் அடிப்படையில் உள்ள மாறிகளின் பல மாறிகளைக் கொண்டு பரிசோதனையில் செயல்படுத்தப்படுகிறது, AraELECTRA மற எங்கள் இறுதியாக அணுகும் சார்காஸ்ம் மற்றும் சென்டிமென்ட் கண்டுபிடிப்பு துணை பணிகளில் ஏழு நான்காவது நி', 'ur': 'This paper presents our strategy to tackle the EACL WANLP-2021 Shared Task 2: Sarcasm and Sentiment Detection. ان میں سے ایک ایسا ہے کہ ایک سیسٹم کو ایجاد کرنا چاہتا ہے جو پہچان دیتا ہے کہ ایک عربی ٹویٹ طبیعت میں Sarcastic ہے یا نہیں، اور دوسرے کو عربی ٹویٹ کا احساس پہچان کرنا چاہتا ہے. ہم دو قدموں میں اس کام کے پاس آتے ہیں The first step involves pre-processing the provided data set by performing insertions, deletions and segmentation operations on various parts of the text. دوسری سپے میں دو تغییر دینے والی مدل، AraELECTRA اور AraBERT کے بہت سی تغییرات کے ساتھ آزمائش میں شامل ہے. ہمارا آخرین طریقہ ساتھا اور چوتھا درجہ Sarcasm اور Sentiment Detection میں درجہ ہے.', 'sr': 'Ovaj papir predstavlja našu strategiju za rješavanje EACL WANLP-2021 zajedničkog zadatka 2: Sarkasma i otkrivanje sentimenta. Jedan od subaskova je cilj da razvije sistem koji identifikuje da li je dao arapski tweet sarkastičan u prirodi ili ne, dok je drugi cilj da identifikuje osjećaj arapskog tweet a. Približavamo se zadatku u dva koraka. Prvi korak uključuje predobrazovanje pruženih podataka izvršavajući uključenje, delenje i segmentaciju operacije na različitim dijelovima teksta. Drugi korak uključuje eksperiment sa višestrukim variantima dva modela na transformaciji, AraELECTRA i AraBERT. Naš poslednji pristup je postavljen sedmi i četvrti u Sarkazmu i Sentimentnom detekciju podupire odgovorno.', 'si': 'මේ පැත්තේ අපේ ව්\u200dයාපෘතිය පෙන්වනවා EACL WANLP-2021 සමාගත වැඩක් 2: සර්කාස්ම් සහ සංවේදනය හොයාගන්න. අරාබික් ට්විට් එකක් ස්වභාවිතයෙන් සාර්කස්ටික් කියලා හොයාගන්න හැකි පද්ධතියක් විස්තර කරනවා කියලා, අරාබික් ට්විට් එකේ දැන අපි පැත්තක් දෙකකින් වැඩේට ගියා. පළමු පැත්තේ පැත්තේ පැත්තේ වෙනස් පැත්තේ තියෙන්න තොරතුරු සැකසුම් විසින් පරිස්සම් කරනවා. දෙවෙනි පැත්තෙන් පරීක්ෂණය තියෙන්නේ වෙනස් වෙනස් දෙකක් අධාරණය කරනවා, AraELECTRA සහ AraBERT. අපේ අන්තිම ප්\u200dරවේශනය සර්කාස්ම් සහ සංවේශනය පරීක්ෂණය සම්බන්ධ විශ්වාස කරනවා.', 'no': 'Denne papiret viser strategien vårt for å handtera EACL WANLP- 2021 delt oppgåve 2: Sarkasm og Sentiment- oppdaging. Ein av underspørsmålene må utvikla eit system som identifiserer om ein gitt arabisk tweet er sarkastisk i natur eller ikkje, mens den andre målene må identifisera sentimenten av den arabiske tweeten. Vi nærmer oppgåva i to steg. Den første stegen involverer førehandsaming av datasettet ved å utføra innsetjingar, sletting og segmentering på ulike deler av teksten. Den andre stegen involverer eksperimentering med fleire variantar av to transformeringsbaserte modeller, AraELECTRA og AraBERT. Den siste tilnærminga vårt vart rankert på sytten og fjerde i Sarkasma og Sentiment-oppdaging, sårbar.', 'uz': "Bu sahifa, EACL WANLP-2021 bilan birlashtirilgan vazifa 2: Sarkasm va Sentimet aniqlashni anglatadi. Ushbu vazifalar biri arabdan foydalanishni aniqlashga ega bo'ladi va boshqa arab Twitterdan hisobni aniqlashni anglatadi. Biz vazifani ikki qadam orqali olib boramiz. @ info: whatsthis Ikkinchi darajada ikkita transformer asosida ko'p variant modellari, AraELECTRA va AraBERT bilan bir nechta o'zgarishni tajriba qiladi. Bizning oxirgi tilimiz Sarkasm va Sentiment Detection vazifalari haqida yetti va to'rtinchi ajratilgan edi.", 'vi': 'Tờ giấy này giới thiệu chiến lược xử lý công việc chia sẻ của chúng ta với EAM-2021: phát hiện âm mưu Sarcasm và tình báo. Một trong những yêu cầu phụ thuộc nhằm phát triển một hệ thống để xác định xem một dòng tweet tiếng Ả Rập có thiên vị hay không, trong khi phần còn lại nhằm xác định ý nghĩa của tweet. Chúng ta sẽ tiếp cận nhiệm vụ trong hai bước. Bước đầu tiên là xử lý trước bộ nhớ đã cung cấp bằng việc thực hiện các cài đặt, xóa bỏ và phân chia các phần khác nhau của văn bản. Bước thứ hai là thử nghiệm với nhiều biến thể của hai mẫu máy biến hình, AraElectmạng và AraBERT. Cách tiếp cận cuối cùng của chúng tôi được phân loại thứ bảy và thứ tư, là Sarcasm và l tình báo trinh sát phần dưới.', 'bg': 'Настоящата статия представя нашата стратегия за справяне с споделената задача 2: Сарказъм и откриване на чувства. Една от подзадачите цели да разработи система, която идентифицира дали даден арабски туит е саркастичен по природа или не, докато другата има за цел да идентифицира настроението на арабския туит. Приближаваме задачата на две стъпки. Първата стъпка включва предварителна обработка на предоставения набор от данни чрез извършване на вмъквания, изтриване и сегментиране операции на различни части на текста. Втората стъпка включва експериментиране с множество варианти на два трансформаторни модела – АраЕЛЕКТРА и АраБЕРТ. Окончателният ни подход се класира на седмо и четвърто място съответно в подзадачите "Сарказъм" и "Откриване на чувства".', 'nl': 'Dit document presenteert onze strategie om de EACL WALLP-2021 Shared Task 2: Sarcasme and Sentiment Detection aan te pakken. Een van de subtaken is gericht op het ontwikkelen van een systeem dat identificeert of een bepaalde Arabische tweet sarcastisch van aard is of niet, terwijl de andere gericht is op het identificeren van het sentiment van de Arabische tweet. We benaderen de taak in twee stappen. De eerste stap is het vooraf verwerken van de verstrekte dataset door invoegen, verwijderen en segmentatie operaties uit te voeren op verschillende delen van de tekst. De tweede stap is experimenteren met meerdere varianten van twee transformatormodellen, AraELECTRA en AraBERT. Onze eindaanpak werd zevende en vierde in respectievelijk Sarcasme en Sentiment Detection subtaken.', 'hr': 'Ovaj papir predstavlja našu strategiju za rješavanje EACL WANLP-2021 zajedničkog zadatka 2: Sarkasma i otkrivanje sentimenta. Jedan od subaskova je cilj razvijanja sustava koji identificira da li je dao arapski tweet sarkastičan u prirodi ili ne, dok je drugi cilj identificirati osjećaj arapskog tweet a. Približavamo se zadatku u dva koraka. Prvi korak uključuje predobrazovanje pruženih podataka provođenim uključivanjem, izbrisanjem i segmentacijom operacijama na raznim dijelovima teksta. Drugi korak uključuje eksperimentiranje s višestrukim variantima dva modela na transformaciji, AraELECTRA i AraBERT. Naš zadnji pristup je bio redovno sedmi i četvrti u Sarkazmu i Sentimentnoj detekciji.', 'id': 'Kertas ini memperkenalkan strategi kita untuk menangani EACL WANLP-2021 Tugas Bersama 2: Sarkasme dan Deteksi Sentiment. One of the subtasks aims at developing a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet.  Kita mendekati tugas dalam dua langkah. Langkah pertama melibatkan praproses set data yang diberikan dengan melakukan penyisihan, hapusan dan operasi segmentasi pada berbagai bagian dari teks. Langkah kedua melibatkan eksperimen dengan berbagai varian dari dua model berdasarkan transformer, AraELECTRA dan AraBERT. Pendekatan akhir kami ditandai ke-7 dan ke-4 dalam Sarkasme dan Sentiment Detection subtasks.', 'ko': '본고는 EACL WANLP-2021 공유 임무 2: 풍자와 정서 검측을 해결하는 전략을 소개한다.그 중 하나는 하나의 시스템을 개발하여 주어진 아랍어 추문이 풍자적인지 식별하는 데 목적을 두고, 다른 하나는 아랍어 추문의 감정을 식별하는 데 목적을 둔다.우리는 두 단계로 나누어 이 임무를 완성한다.첫 번째 단계는 텍스트의 각 부분에 대한 삽입, 삭제, 세그먼트 조작을 통해 제공된 데이터 집합을 미리 처리하는 것이다.두 번째 단계는 아라엘ECTRA와 아라베트 두 변압기 기반 모델의 다양한 변형을 시험하는 것이다.우리의 최종 방법은 풍자와 정서 검측 서브 미션에서 각각 7위와 4위를 차지했다.', 'da': 'Dette papir præsenterer vores strategi for at tackle EACL WANNP-2021 delt opgave 2: sarkasme og følelsesdetektion. En af underopgaverne sigter mod at udvikle et system, der identificerer, om et givet arabisk tweet er sarkastisk i sin natur eller ej, mens den anden sigter mod at identificere følelsen af det arabiske tweet. Vi nærmer os opgaven i to trin. Det første skridt involverer forhåndsbehandling af det leverede datasæt ved at udføre indsætninger, sletning og segmentering operationer på forskellige dele af teksten. Det andet trin består i at eksperimentere med flere varianter af to transformer baserede modeller, AraELECTRA og AraBERT. Vores endelige tilgang blev placeret syvende og fjerde i Sarkasm og Sentiment Detection underopgaver henholdsvis.', 'fa': 'این کاغذ استراتژی ما را برای حل کار مشترک EACL WANLP-2021 نشان می دهد: کاربرد سارکاسم و بازرسی سنتی. یکی از مطالعه\u200cها هدف توسعه یک سیستم است که مشخص می\u200cکند که آیا توئیت عربی داده شده در طبیعت یا نه، در حالی که دیگر هدف می\u200cکند احساس توئیت عربی را شناسایی کند. ما در دو قدم به کار نزدیک می\u200cشویم. اولین قدم شامل پیش از پردازش مجموعه داده\u200cهای پیشنهاد با انجام عملیات ورود، حذف و جدایی در بخش\u200cهای مختلف متن است. مرحله دوم مشترک آزمایش با متعدد متعدد دو مدل تغییر دهنده، AraELECTRA و AraBERT است. آخرين دسترسي ما هفتم و چهارم درجه در آزمايش سارکاسم و آزمايش سنتيمتر به نظر ميرسه.', 'sw': 'Makala hii inaonyesha mkakati wetu wa kukabiliana na chama cha EACL WANLP-2021 Miongoni mwa kazi hizo inakusudia kuendeleza mfumo unaotambua ikiwa twiti iliyotolewa Kiarabu ni ya kejeli au la, wakati mwingine linalenga kutambua hisia za twita ya Kiarabu. Tunakaribia kazi kwa hatua mbili. Hatua ya kwanza inahusisha upasuaji wa taarifa zilizotolewa kwa kufanya shughuli za kuondolewa, kufutwa na kuchangwa katika sehemu mbalimbali za maandishi. Hatua ya pili inahusisha kujaribu na mabadiliko mbalimbali ya mifano miwili ya mabadiliko, AraELECTRA na AraBERT. Mpango wetu wa mwisho ulikuwa wa kiwango cha saba na nne katika majukumu ya Sarkasm na Uchunguzi wa Seneti.', 'tr': "Bu kagyz EACL WANLP-2021'i çözmek üçin biziň strategiýamyzy 2-nji paýlaşýar: Sarkasm we Sentiment Taýşary. Subtalardan biri arap tweet edilen ýagdaýyny tanap-tanamaga maksady bar, beýleki maksady arap tweetiniň duýgyny tanap bilmek üçin. Biz bu işe iki adımda gollaşýarys. Ilkinji adım metin ediň birnäçe bölgelerinde berilen veri setirini öň işlemek üçin meýilleşdirýär. Ikinji adım iki transformer modelleriniň birnäçe wariantlaryny, AraELECTRA we AraBERT suratynda synanyşy bar. Biziň soňky ýaryşymyz Sarkasm we Sentiýat deteksiyonyň içinde ýetginje we dördünji derejesi diýipdir.", 'de': 'Dieses Papier stellt unsere Strategie zur Bewältigung der EACL WALLP-2021 Shared Task 2: Sarkasmus und Sentiment Detection vor. Eine der Teilaufgaben zielt darauf ab, ein System zu entwickeln, das identifiziert, ob ein bestimmter arabischer Tweet sarkastischer Natur ist oder nicht, während die andere darauf abzielt, die Stimmung des arabischen Tweets zu identifizieren. Wir nähern uns der Aufgabe in zwei Schritten. Der erste Schritt beinhaltet die Vorbearbeitung des bereitgestellten Datensatzes durch Einfügen, Löschen und Segmentieren verschiedener Textteile. Im zweiten Schritt wird mit mehreren Varianten der beiden Transformatormodelle AraELECTRA und AraBERT experimentiert. Unser letzter Ansatz wurde Siebter und Vierter in den Teilaufgaben Sarkasmus und Sentiment Detection.', 'sq': 'Ky dokument paraqet strategjinë tonë për të trajtuar EACL WANLP-2021 Detyrën e Përbashkët 2: Sarkazmi dhe Detektimi i Sentimenteve. Një nga nënpyetjet synon të zhvillojë një sistem që identifikon nëse një tweet arab i caktuar është sarkastik në natyrë apo jo, ndërsa tjetri synon të identifikojë ndjenjën e tweetit arab. Ne i afrohemi detyrës në dy hapa. Hapi i parë përfshin përpara procesimit të grupit të dhënash të dhëna duke kryer shtimet, fshirjet dhe operacionet e segmentimit në pjesë të ndryshme të tekstit. Hapi i dytë përfshin eksperimentimin me variante të shumta të dy modeleve bazuar në transformues, AraELECTRA dhe AraBERT. Përqafimi ynë përfundimtar u rendit i shtatë dhe i katërti në nëndetyrimet e Sarkazmit dhe të Detektimit të Sentimenteve respektivisht.', 'af': "Hierdie papier stel ons strategie om die EACL WANLP- 2021 Gedeelde Opdrag 2: Sarcasm en Sentiment Deteksie te kry. Een van die subtaske doel om 'n stelsel te ontwikkel wat identifiseer of 'n gegewe Arabiese tweet sarkasies is in natuur of nie, terwyl die ander doel om die sentiment van die Arabiese tweet te identifiseer. Ons naby die taak in twee stappe. Die eerste stap insluit voor verwerking van die verskaf datastel deur voeg by voeg by voeg by, uitvee en segmentasie operasies op verskeie dele van die teks. Die tweede stap insluit eksperimentering met veelvuldige variante van twee transformeerder gebaseerde modele, AraELECTRA en AraBERT. Ons eindelike toegang is gerankeer sewende en vierde in die Sarkasm en Sentiment Deteksie ondersoek respektief.", 'hy': 'Այս փաստաթղթին ներկայացնում է մեր ռազմավարությունը, որպեսզի հաղթահարենք ԱԱԿԼ-2021-ին համագործակցած 2. խնդիրը՝ Սարկազմ և զգացմունքների հայտնաբերություն: Հենց հարցերից մեկը նպատակն է զարգացնել մի համակարգ, որը բացահայտում է, թե արդյոք որոշ արաբական թվիթերը սարկաստական են բնության մեջ, թե ոչ, իսկ մյուսը նպատակն է բացահայտել արաբական թվիթերի զգացմունքը: Մենք մոտենում ենք խնդիրը երկու քայլերով: Առաջին քայլը ներառում է տրամադրված տվյալների համակարգի նախավերաշարժումը, կատարելով տեքստի տարբեր մասերի վրա ներմուծման, ջնջման և սեգրմացիայի գործողություններ: Երկրորդ քայլը ներառում է փորձարկումներ երկու վերափոխողների հիմնված մոդելների՝ ԱրաԷԼԷկտրայի և Արաբերթի բազմաթիվ տարբերակներով: Մեր վերջնական մոտեցումը դասակարգված էր Սարկազմի եօթներորդ և չորրորդ ենթախնդիրներում:', 'am': 'ይህ ገጽ የEACL WANLP-2021 ስራ 2: ሰርካሲም እና ሰዓቲት ምርመራ ለመቀናቀል ስራታችንን ያቀርባል፡፡ ከስራቶቹ አንዱ የዐረብኛ ትዊተር በሥርዓት መሆኑን ማረጋገጥ፣ ሁለተኛውም የዐረብኛ ትዊተር አዳማዊ ትዊተር መሆኑን ማረጋገጥ ያሳያል፡፡ ስራውን በሁለት ደረጃዎች እንቅረብ ። የመጀመሪያው ደረጃ በጽሑፉ በተለዩ ክፍሎች ላይ የሚጨመር፣ ማስወገድ እና ማሰሪያ ክፍሎች በጥያቄ ላይ የተሰጠውን ዳታ ሳጥን በመስጠት ያስተካክላል፡፡ ሁለተኛውም ደረጃ በሁለት ለውጦች፣ AraELECTRA እና AraBERT በሁለት ምርጫዎች ላይ የተለየ ምሳሌዎችን ያሳያል፡፡ የኋለኛውም ልግስናችን በሰርካም እና በሳንቲት ጥያቄ ውስጥ በተለየ ሰባተኛና አራተኛ ደረጃ ነበር።', 'bn': 'এই পত্রিকা আমাদের কৌশল উপস্থাপন করেছে এACL WANLP-2021 শেয়ার করা কাজ ২: সার্কাস্ম এবং সেন্টাইমেন্ট সনিক্তির। সাবটাসের একটি উদ্দেশ্য হচ্ছে একটি সিস্টেম উন্নয়নের উদ্দেশ্য যা চিহ্নিত করা হয়েছে যে একটি আরবী টুইট প্রকৃতিতে বিদ্রোহীত কিনা, আর অন্যরা আরবী টুইটে আমরা দুই পদক্ষেপের মধ্যে কাজ করি। প্রথম পদক্ষেপ লেখার বিভিন্ন অংশের মধ্যে প্রবেশ, মুছে ফেলা এবং বিভিন্ন অংশের মাধ্যমে প্রদান করা ডাটাসেট প্রক্রিয়া দ্বিতীয় পদক্ষেপের মধ্যে রয়েছে দুটি পরিবর্তনের ভিত্তিক মডেল, AraELECTRA এবং AraBERT এর বেশ কিছু পরীক্ষায়। আমাদের শেষ পদ্ধতি সার্কাম এবং সেন্টাইমেন্ট ডিটেক্টরের সাবেক কাজে সপ্তাহ ও চতুর্থ পরিচালিত হয়েছে।', 'bs': 'Ovaj papir predstavlja našu strategiju za rješavanje EACL WANLP-2021 zajedničkog zadatka 2: Sarkasma i otkrivanje sentimenta. Jedan od subaskova je cilj da razvije sistem koji identifikuje da li je dao arapski tweet sarkastičan u prirodi ili ne, dok je drugi cilj da identifikuje osjećaj arapskog tweet a. Približavamo se zadatku u dva koraka. Prvi korak uključuje predobrazovanje pruženih podataka izvršavajući uključene, delecije i segmentacije operacije na različitim dijelovima teksta. Drugi korak uključuje eksperimentiranje sa višestrukim variantima dva modela na transformaciji, AraELECTRA i AraBERT. Naš zadnji pristup je bio redovno sedmi i četvrti u Sarkazmu i suštinskom detekciju podupire.', 'az': "Bu kağıt EACL WANLP-2021 paylaşılmış 2-ci işi ilə çəkmək üçün stratejimizi göstərir: Sarkasm və Sentiment Detection. Subasklardan biri ərəb tweet in in təbiətində sarkastik olduğunu təşkil edən və ya yoxdur, digərinin ərəb tweetinin duygularını təşkil etmək istəyir. Biz bu işə iki adımda yaxınlaşırıq. İlk adım metin növbənöv bölümlərində daxil edilən verilənlər qurulması ilə əvvəlcə işlədilməsi ilə məlumatın fərqli bölümlərində daxil edilir. İkinci adım iki transformer modeli, AraELECTRA və AraBERT'un çoxlu dəyişiklikləri ilə təcrübə edir. Bizim son yaxınlığımız Sarkasm və Sentiment Detection-ın altından yeddi və dördüncü dərəcələrdə idi.", 'et': 'Käesolevas dokumendis tutvustatakse meie strateegiat EACL WARLP-2021 ühise ülesande 2: sarkasmi ja tunnete tuvastamise lahendamiseks. Ühe alamülesande eesmärk on arendada välja süsteem, mis tuvastab, kas antud araabia säuts on sarkastiline või mitte, samas kui teise eesmärk on tuvastada araabia säutsu tunded. Läheneme ülesandele kahes etapis. Esimene samm hõlmab esitatud andmekogumi eeltöötlust, tehes lisamise, kustutamise ja segmenteerimise toiminguid teksti erinevates osades. Teine samm hõlmab katsetamist kahe transformaatoril põhineva mudeli mitme variandiga, AraELECTRA ja AraBERT. Meie lõplik lähenemine oli sarkasmi ja tunnete tuvastamise alamülesannetes seitsmendal ja neljandal kohal.', 'cs': 'Tento článek představuje naši strategii řešení EACL WALLP-2021 Shared Task 2: Sarkasmus and Sentiment Detection. Jeden z dílčích úkolů si klade za cíl vytvořit systém, který identifikuje, zda daný arabský tweet je sarkastický nebo ne, zatímco druhý se snaží identifikovat sentiment arabského tweetu. K úkolu přistupujeme ve dvou krocích. První krok zahrnuje předzpracování poskytnuté datové sady provedením vkládání, odstranění a segmentačních operací na různých částech textu. Druhým krokem je experimentování s více variantami dvou transformátorových modelů AraELECTRA a AraBERT. Náš konečný přístup byl sedmý a čtvrtý v podúkolech Sarkasmus a Detekce sentimentu.', 'ca': "Aquest paper presenta la nostra estratègia per abordar l'EACL WANLP-2021 Task Shared 2: Sarcasm and Sentiment Detection. Una de les subpreguntes mira a desenvolupar un sistema que identifique si un tweet àrab és sarcàstic o no, mentre l'altra mira a identificar el sentiment del tweet àrab. Aproximem la tasca en dos passos. El primer pas consisteix en pré-processar el conjunt de dades proporcionat fent inspeccions, eliminacions i operacions de segmentació en diverses parts del text. El segon pas consisteix en experimentar amb múltiples variants de dos models basats en transformadors, AraELECTRA i AraBERT. El nostre enfocament final va ser classificat segon i quart a les subtaskes del Sarcasme i de la Detecció del Sentiment respectivament.", 'fi': 'Tässä artikkelissa esitellään strategiamme EACL WANLP-2021 Shared Task 2: Sarkasm and Sentiment Detection -ohjelman käsittelemiseksi. Toisen alitehtävän tavoitteena on kehittää järjestelmä, joka tunnistaa, onko tietty arabialainen twiitti luonteeltaan sarkastinen vai ei, kun taas toisen tavoitteena on tunnistaa arabialaisen twiitin tunne. Lähestymme tehtävää kahdessa vaiheessa. Ensimmäisessä vaiheessa aineiston esikäsittely tapahtuu lisäämällä, poistamalla ja segmentoimalla tekstin eri osia. Toisessa vaiheessa kokeillaan useita muunnelmia kahdesta muuntajapohjaisesta mallista, AraELECTRA ja AraBERT. Lopullinen lähestymistapamme sijoittui seitsemänneksi sarkasmin ja sentiment detection -alitehtävissä neljänneksi.', 'jv': 'Gambar iki bakal ning ngerasati perintahaan nggawe nggawe geraksi ETCL WANLP-2020 1 Siyang Mesang 2: Sarkasm lan Sentiment detection Omahé awak dhéwé mbukakipun nggawe sistem sing bisa melalui nung dhéwé éntuk sistem sing berarti tuwit arap sing sarkasik nang rakyata uga, sampeyan bener dhéwé kuwi bisa mengko awak dhéwé kuwi siwih arap. Awak dhéwé dadi nganggo nggabèh iki bakal. Laptop" and "Desktop Laptop" and "Desktop Awak dhéwé éntuk sing katêpakan tanggal sedhaya lan wis munggo cara-cara sing katêpakan karo Sarkasm lan Sentiment', 'sk': 'Ta prispevek predstavlja našo strategijo za reševanje skupne naloge 2 EACL WALLP-2021: sarkazem in zaznavanje čustev. Ena od podnalog je namenjena razvoju sistema, ki ugotavlja, ali je določen arabski tweet sarkastičen ali ne, druga pa prepoznava občutek arabskega tweeta. Približujemo se nalogi v dveh korakih. Prvi korak vključuje predhodno obdelavo zagotovljenega nabora podatkov z izvedbo vstavljanja, brisanja in segmentacije na različnih delih besedila. Drugi korak vključuje eksperimentiranje z več različicami dveh transformatorskih modelov, AraELECTRA in AraBERT. Naš končni pristop je bil sedmi in četrti v podnalogah Sarkazma oziroma Detekcija čustev.', 'he': 'העיתון הזה מציג את האסטרטגיה שלנו להתמודד עם EACL WANLP-2021 משימה משותפת 2: זיהוי סרקזם וחושה. אחד השאלות המטרה לפתח מערכת שמזהה אם טוויט ערבי מסוים הוא סרקסטי בטבע או לא, בעוד השני ממטרה לזהות את הרגשה של טוויט ערבי. אנחנו מתקרבים למשימה בשני צעדים. הצעד הראשון כולל מעבד מראש את קבוצת הנתונים המסופקת על ידי ביצוע הוספות, מחיקות ומבצעי סגמנציה על חלקים שונים של הטקסט. השלב השני כולל ניסויים עם שונים רבים של שני דוגמנים מבוססים במעבר, AraELECTRA ואראBERT. הגישה האחרונה שלנו הוצבה בשביעית ורביעית בסרקזם ובעקבות הבחינה של רגשות.', 'ha': "Wannan takardar na gaurar da juyin mu zuwa tacilin EAL WANLP-2021 Bayani daga aikin da aka yi amfani da wajen developer wata na'ura wanda ke gane ko an kasar wani littãfi na Larabci na sarcasti, da kuma yana kasancẽwa, idan na yi nufin ya gane hisãbin na'abci na'arabu. Lalle ne Mũ, Mãsu kusantar da al'amarin zuwa ga aikin ƙwarai biyu ne. Babbar ta farko yana tafiyar da shirin aiki na ƙararra, cire da kuma surori masu saka kan ƙananan matsayin. Gabbata ta biyu na haɗi da jarraba wasu daban-dabam biyu na shige, AraELEctra da AraBERT. Our final approach was ranked seventh and fourth in the Sarcasm and Sentiment Detection subtasks respectively.", 'bo': 'ཤོག་བྱང་འདིས་ EACL WANLP-2021 རྩོམ་པ་དང་མཉམ་དུ་གཏོང་གི་ཐབས་ལམ་དེ་སྟོན་ཞུགས་པ། དེའི་ནང་དུ་ཆེན་པོ་དང་མཉམ་དུ་གཏོང One of the subtasks aims to develop a system that identifies whether a given Arabic tweet is sarcastic in nature or not, while the other aims to identify the sentiment of the Arabic tweet. ང་ཚོས་རྒྱལ་ཁབ་འདིའི་གོ་མ་གཉིས་ནང་གི་གདོང་ལེན་བྱེད་ཀྱི་ཡོད། The first step involves pre processing the provided dataset by performing insertions, deletions and segmentation operations on various parts of the text. The second step involves experimenting with multiple variants of two transformer based models, AraELECTRA and AraBERT. ང་ཚོའི་མཐའ་མཇུག་གི་གཟུགས་སྐོར་དེ་ཚོར་སྐྱེས་བ་དང་རང་ཉིད་རྟོགས་པའི་ཕྱོགས་ལ་༧་དང་བཞི་པ་བརྙན་ཡོད།'}
