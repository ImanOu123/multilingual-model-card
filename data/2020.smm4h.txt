{'en': 'Conversation-Aware Filtering of Online Patient Forum Messages', 'ar': 'تصفية المحادثات الواعية لرسائل منتدى المريض عبر الإنترنت', 'pt': 'Filtragem com reconhecimento de conversa de mensagens do fórum de pacientes on-line', 'fr': 'Filtrage basé sur la conversation des messages de forum de patients en ligne', 'es': 'Filtrado de mensajes de foros de pacientes en línea basado en conversaciones', 'zh': '对话感知过在线患者论坛消息', 'ja': '会話-オンライン患者フォーラムメッセージのフィルタリング', 'hi': 'वार्तालाप-ऑनलाइन रोगी फोरम संदेशों के जागरूक फ़िल्टरिंग', 'ru': 'Фильтрация сообщений онлайн-форума пациентов с помощью диалоговой системы', 'ga': 'Comhrá-Aware Scagadh Teachtaireachtaí Fóram Othair Ar Líne', 'ka': 'Name', 'hu': 'Az online páciens fórum üzenetek beszélgetési tudatosságának szűrése', 'el': 'Φιλτράρισμα διαδικτυακών μηνυμάτων φόρουμ ασθενών με επίγνωση της συνομιλίας', 'it': 'Filtrazione consapevole della conversazione dei messaggi del forum dei pazienti online', 'kk': 'Желіде пациенттің форум хаттарды сүзгілеу', 'mk': 'Name', 'lt': 'Interneto pacientų forumo pranešimų filtravimas sąmoningai', 'ms': 'Penapis Awas-Perbualan Mesej Forum Pasien Dalam Talian', 'mt': 'Filtrar ta’ messaġġi tal-Forum tal-Pazjenti Online b’Konxjenza tal-Konversjonijiet', 'mn': 'Conversation-Aware Filtering of Online Patient Forum Messages', 'ml': 'ഓണ്\u200dലൈന്\u200d രോഗിയുടെ ഫോര്\u200dമ്മ് സന്ദേശങ്ങളുടെ സംസാരം- അറിയുന്ന ഫില്\u200dറ്റര്\u200d', 'no': 'Name', 'ro': 'Filtrarea conștientă de conversație a mesajelor forumului pacienților online', 'pl': 'Filtrowanie komunikatów na forum pacjentów online', 'sr': 'Послани онлайн форум пациента', 'si': 'සංවාදය සම්බන්ධ පණිවිඩයේ සම්බන්ධ ප්\u200dරතික්\u200dරියාව සඳහා ප්\u200dරතික්\u200dරීය', 'ta': 'Name', 'ur': 'آنلاین پیٹیٹ فورمی پیغام کی بات-Aware Filtering', 'sv': 'Konversationsmedveten filtrering av meddelanden från patientforum online', 'so': 'Filtering of Online Patient Forum Messages', 'uz': 'Name', 'vi': 'Bộ lọc dịch bệnh qua mạng', 'bg': 'Филтриране, осъзнаващо разговорите, на съобщения от онлайн форума на пациентите', 'nl': 'Gesprekksbewust filteren van berichten van online patiëntenforums', 'da': 'Samtalebevidst filtrering af online patientforum meddelelser', 'hr': 'Filtriranje poruka online foruma pacijenata', 'de': 'Konversationsbewusste Filterung von Nachrichten im Online-Patientenforum', 'fa': 'پالایۀ پیام\u200cهای فورم بیماران در آنلاین پیام\u200cهای بیماری\u200cهای ارتباط- آگاهی', 'ko': '온라인 환자 포럼 소식의 대화 감지 필터', 'sw': 'Uchunguzi wa Ujumbe wa Jukwaa la Wagonjwa Mtandaoni', 'tr': 'Çaltylyk Söýgüliler', 'af': 'Gespraak- Aware Filtering van Aanlyn Patiente Forum Boodskappe', 'sq': 'Conversation-Aware Filtering of Online Patient Forum Messages', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Conversation-Aware Filtering of Online Patient Forum Messages', 'bn': 'অনলাইন রোগী ফোরাম বার্তার কথোপকথন- সচেতনতা ফিল্টার', 'az': 'İnternet Patient Forum İsmarışlarının Qonuşma-Aware Filtering', 'bs': 'filteriranje poruka o online forumu pacijenata', 'ca': 'Filtrar els missatges de fòrum de pacients en línia', 'cs': 'Filtrování zpráv online fóra pacientů s informací o konverzaci', 'id': 'Penapis Pembicaraan-Awas dari Pesan Forum Pasien Online', 'et': 'Vestlusteadlik patsientide foorumi sõnumite filtreerimine', 'fi': 'Keskustelutietoinen potilasfoorumin verkkoviestien suodatus', 'jv': 'New', 'he': 'מסנן מודע לשיחה של הודעות הפורום המטופל באינטרנט', 'ha': 'filter-action', 'sk': 'Filtriranje sporočil spletnega foruma bolnikov, ki se zavedajo pogovorov', 'bo': 'ཆ་འཕྲིན་སྙུགས་སྣོད་ཀྱི་གྲ་རྒྱའི་ཆ་འཕྲིན་ལ་གླེང་སྒྲོམ་Aware་ཚགས་མ་བྱེད་པ'}
{'en': 'Previous approaches to NLP tasks on online patient forums have been limited to single posts as units, thereby neglecting the overarching conversational structure. In this paper we explore the benefit of exploiting  conversational context  for filtering posts relevant to a specific  medical topic . We experiment with two approaches to add conversational context to a BERT model : a sequential CRF layer and manually engineered features. Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves  precision  for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher  recall  for two out of three target classes. Thus, depending on the end goal, conversation-aware modelling may be beneficial for identifying relevant messages. We hope our findings encourage other researchers in this domain to move beyond studying messages in isolation towards more discourse-based data collection and classification. We release our code for the purpose of follow-up research.', 'es': 'Los enfoques anteriores de las tareas de PNL en los foros de pacientes en línea se han limitado a publicaciones individuales como unidades, descuidando así la estructura conversacional general. En este artículo exploramos el beneficio de aprovechar el contexto conversacional para filtrar publicaciones relevantes para un tema médico específico. Experimentamos con dos enfoques para agregar contexto conversacional a un modelo BERT: una capa CRF secuencial y funciones diseñadas manualmente. Aunque ninguno de los dos enfoques puede superar la puntuación F1 de la línea de base BERT, encontramos que agregar una capa secuencial mejora la precisión para todas las clases objetivo, mientras que agregar una capa no secuencial con características diseñadas manualmente conduce a una mayor recuperación de dos de las tres clases objetivo. Por lo tanto, dependiendo del objetivo final, el modelado sensible a la conversación puede ser beneficioso para identificar mensajes relevantes. Esperamos que nuestros hallazgos alienten a otros investigadores en este campo a ir más allá del estudio de los mensajes de forma aislada hacia una recopilación y clasificación de datos más basada en el discurso. Publicamos nuestro código con el propósito de realizar investigaciones de seguimiento.', 'ar': 'كانت المناهج السابقة لمهام البرمجة اللغوية العصبية في منتديات المرضى عبر الإنترنت مقتصرة على المنشورات الفردية كوحدات ، وبالتالي أهملت هيكل المحادثة الشامل. في هذه الورقة ، نستكشف فائدة استغلال سياق المحادثة لتصفية المشاركات ذات الصلة بموضوع طبي معين. نقوم بتجربة طريقتين لإضافة سياق محادثة إلى نموذج BERT: طبقة CRF متسلسلة وميزات مصممة يدويًا. على الرغم من أن أيًا من النهجين لا يمكن أن يتفوق على درجة F1 لخط الأساس BERT ، فإننا نجد أن إضافة طبقة متسلسلة تعمل على تحسين الدقة لجميع الفئات المستهدفة بينما تؤدي إضافة طبقة غير متسلسلة بميزات مصممة يدويًا إلى استدعاء أعلى لاثنين من ثلاث فئات مستهدفة. وبالتالي ، اعتمادًا على الهدف النهائي ، قد تكون النمذجة المدركة للمحادثات مفيدة لتحديد الرسائل ذات الصلة. نأمل أن تشجع النتائج التي توصلنا إليها الباحثين الآخرين في هذا المجال على الانتقال إلى ما بعد دراسة الرسائل في عزلة نحو المزيد من جمع البيانات القائمة على الخطاب وتصنيفها. نصدر الكود الخاص بنا لغرض متابعة البحث.', 'fr': "Les approches précédentes des tâches de PNL sur les forums de patients en ligne se limitaient à des publications uniques en tant qu'unités, négligeant ainsi la structure conversationnelle globale. Dans cet article, nous explorons les avantages de l'exploitation du contexte conversationnel pour filtrer les publications pertinentes à un sujet médical spécifique. Nous expérimentons deux approches pour ajouter un contexte conversationnel à un modèle BERT\xa0: une couche CRF séquentielle et des entités conçues manuellement. Bien qu'aucune des deux approches ne puisse surpasser le score F1 de la base BERT, nous constatons que l'ajout d'une couche séquentielle améliore la précision pour toutes les classes cibles, tandis que l'ajout d'une couche non séquentielle avec des entités conçues manuellement entraîne un rappel plus élevé pour deux classes cibles sur trois. Ainsi, en fonction de l'objectif final, la modélisation sensible à la conversation peut être utile pour identifier les messages pertinents. Nous espérons que nos résultats encourageront d'autres chercheurs dans ce domaine à aller au-delà de l'étude isolée des messages pour se tourner vers une collecte et une classification de données davantage basées sur le discours. Nous publions notre code à des fins de recherche de suivi.", 'pt': 'As abordagens anteriores para tarefas de PNL em fóruns de pacientes on-line foram limitadas a postagens únicas como unidades, negligenciando assim a estrutura de conversação abrangente. Neste artigo, exploramos o benefício de explorar o contexto conversacional para filtrar postagens relevantes para um tópico médico específico. Experimentamos duas abordagens para adicionar contexto conversacional a um modelo BERT: uma camada CRF sequencial e recursos projetados manualmente. Embora nenhuma abordagem possa superar a pontuação F1 da linha de base do BERT, descobrimos que adicionar uma camada sequencial melhora a precisão para todas as classes de destino, enquanto a adição de uma camada não sequencial com recursos projetados manualmente leva a uma recuperação mais alta para duas das três classes de destino. Assim, dependendo do objetivo final, a modelagem consciente da conversa pode ser benéfica para identificar mensagens relevantes. Esperamos que nossas descobertas encorajem outros pesquisadores neste domínio a ir além do estudo de mensagens isoladas para uma coleta e classificação de dados mais baseada no discurso. Nós liberamos nosso código para fins de pesquisa de acompanhamento.', 'ja': 'オンライン患者フォーラム上のNLPタスクに対する以前のアプローチは、単一の投稿をユニットとして限定しており、それによって包括的な会話構造を無視している。 この論文では、特定の医療トピックに関連する投稿をフィルタリングするために会話コンテキストを利用する利点を探求します。 BERTモデルに会話コンテキストを追加するための2つのアプローチを実験しました。順次CRFレイヤーと手動で設計された機能です。 どちらのアプローチも、BERTベースラインのF 1スコアを上回ることはできないが、我々は、順次層を追加することは、すべての標的クラスの精度を向上させる一方で、手動で操作された特徴を有する非順次層を追加することは、３つの標的クラスのうちの２つのより高いリコールにつながることを見出す。 したがって、最終目標に応じて、会話を意識したモデリングは、関連するメッセージを識別するのに有益であり得る。 私たちの調査結果は、この分野の他の研究者が、メッセージを孤立的に研究することを超えて、より多くの話題に基づくデータ収集と分類に移行することを奨励することを願っています。 フォローアップリサーチの目的でコードをリリースします。', 'zh': '前在线患者论坛处NLP务止于帖以为单元,忽于总言结构。 本文中,我们探讨了利用对话上下文过去与特定医学主题相关的帖子。 试二法以益BERT会话上下文:次CRF重手动之功。 虽二者皆不能优BERT基线之F1数,然见加之以次第之精,而加之以手动计功能之非次层会致三趣类中二者益高。 故因最终目标而知之建模利于知也。 我们希望我们的研究果然能奖励该领他的研究人员越孤地研究信息,转更多基于话语的数据收拾和分类。 吾发代码以续之也。', 'ru': 'Предыдущие подходы к задачам NLP на онлайн-форумах пациентов были ограничены отдельными постами как единицами, тем самым пренебрегая всеобъемлющей разговорной структурой. В этой статье мы исследуем преимущество использования разговорного контекста для фильтрации сообщений, относящихся к конкретной медицинской теме. Мы экспериментируем с двумя подходами для добавления разговорного контекста к модели BERT: последовательный слой CRF и вручную сконструированные признаки. Хотя ни один из подходов не может превзойти показатель F1 базовой линии BERT, мы обнаружили, что добавление последовательного слоя улучшает точность для всех целевых классов, в то время как добавление непоследовательного слоя с вручную сконструированными функциями приводит к более высокому отзыву для двух из трех целевых классов. Таким образом, в зависимости от конечной цели, моделирование, основанное на диалоге, может быть полезным для идентификации соответствующих сообщений. Мы надеемся, что наши выводы побудят других исследователей в этой области перейти от изучения сообщений в отрыве к сбору и классификации данных на основе дискурса. Мы выпускаем наш код с целью последующего исследования.', 'hi': 'ऑनलाइन रोगी मंचों पर एनएलपी कार्यों के लिए पिछले दृष्टिकोण इकाइयों के रूप में एकल पदों तक सीमित हैं, जिससे व्यापक संवादात्मक संरचना की उपेक्षा की जाती है। इस पेपर में हम एक विशिष्ट चिकित्सा विषय के लिए प्रासंगिक पदों को फ़िल्टर करने के लिए संवादी संदर्भ का शोषण करने के लाभ का पता लगाते हैं। हम एक BERT मॉडल के लिए संवादी संदर्भ जोड़ने के लिए दो दृष्टिकोणों के साथ प्रयोग करते हैं: एक अनुक्रमिक सीआरएफ परत और मैन्युअल रूप से इंजीनियर विशेषताएं। यद्यपि न तो दृष्टिकोण BERT बेसलाइन के F1 स्कोर को मात दे सकता है, हम पाते हैं कि एक अनुक्रमिक परत जोड़ने से सभी लक्ष्य वर्गों के लिए सटीकता में सुधार होता है जबकि मैन्युअल रूप से इंजीनियर सुविधाओं के साथ एक गैर-अनुक्रमिक परत जोड़ने से तीन लक्ष्य वर्गों में से दो के लिए उच्च याद आती है। इस प्रकार, अंतिम लक्ष्य के आधार पर, वार्तालाप-जागरूक मॉडलिंग प्रासंगिक संदेशों की पहचान करने के लिए फायदेमंद हो सकती है। हमें उम्मीद है कि हमारे निष्कर्ष इस डोमेन में अन्य शोधकर्ताओं को अधिक प्रवचन-आधारित डेटा संग्रह और वर्गीकरण की ओर अलगाव में संदेशों का अध्ययन करने से परे जाने के लिए प्रोत्साहित करते हैं। हम अनुवर्ती अनुसंधान के उद्देश्य के लिए अपना कोड जारी करते हैं।', 'ga': 'Bhí cur chuige roimhe seo maidir le tascanna NLP ar fhóraim othar ar líne teoranta do phoist aonair mar aonaid, rud a fhágann faillí sa struchtúr uileghabhálach comhrá. Sa pháipéar seo déanaimid iniúchadh ar an leas a bhaineann le comhthéacs comhrá a shaothrú chun postálacha a bhaineann le topaic leighis ar leith a scagadh. Déanaimid turgnamh le dhá chur chuige chun comhthéacs comhrá a chur le samhail BERT: ciseal CRF seicheamhach agus gnéithe a dhéantar innealtóireacht de láimh. Cé nach féidir le ceachtar den dá chur chuige feidhmiú níos fearr ná scór F1 bhunlíne BERT, feicimid go bhfeabhsaíonn ciseal seicheamhach beachtas do gach sprioc-aicme ach má chuirtear ciseal neamhsheicheamhach le gnéithe a ndearnadh innealtóireacht láimhe air, beidh cuimhne níos airde ar dhá cheann as trí sprioc-aicme. Mar sin, ag brath ar an sprioc deiridh, d’fhéadfadh samhaltú feasach ar chomhrá a bheith tairbheach chun teachtaireachtaí ábhartha a aithint. Tá súil againn go spreagfaidh ár dtorthaí taighdeoirí eile sa réimse seo chun bogadh níos faide ná staidéar a dhéanamh ar theachtaireachtaí ina n-aonar i dtreo bailiú agus rangú sonraí atá bunaithe ar dhioscúrsa. Eisímid ár gcód chun críche taighde leantach.', 'ka': 'წინა NLP პაციენტის ფორმების მომხმარებისთვის პროგრამის წინაღალდეგი დახმარება ერთი პროგრამის განმავლობაში, ამიტომ უფრო არაფერადებული კონტრაციონალური სტრუქ ამ დოკუნტში ჩვენ ვხედავთ კონტაქციო კონტექსტის გამოყენება, რომელიც განსაკუთრებული მედიცინური თემაზე მნიშვნელოვანი პოსტრუქტურება. ჩვენ ექსპერიმენტირებით ორი გახსნა BERT მოდელში კონტექსტური კონტექსტის დამატებისთვის: შემდეგ CRF მონაცემი და ხელხილურად ინექნერიური ფუნქ თუმცა არც მიზეზი შეიძლება გავაკეთოთ BERT-ის ფესტის F1 წერტილი, ჩვენ ვფიქრობთ, რომ წერტილი წერტილის დამატება ყველა მიზეზი კლასებისთვის უფრო მუშაობა, მაგრამ მიზეზი კლასებისთვის დამატება არსწერტილი წერტილი ამიტომ, საკუთარი მისამართისგან დამატებული, შეიძლება შესაძლებელია მოდელირება, რომელიც შესაძლებელია შესაძლებელია შესაძლებელია შესაძლებელი შესახებ ჩვენ იმედით, რომ ჩვენი მონაცემები ამ დიომინში სხვა მსწავლობელი მოწყობინებს იზოლაციაში უფრო მეტი მონაცემების კოლექციაციაში და კლასიფიკაციაში გადასწავლა ჩვენ ჩვენი კოდის გახსნა მიზეზით შემდეგების სწორედ.', 'el': 'Οι προηγούμενες προσεγγίσεις των εργασιών σε διαδικτυακά φόρουμ ασθενών περιορίστηκαν σε μεμονωμένες δημοσιεύσεις ως μονάδες, παραμελώντας έτσι την γενική δομή συνομιλίας. Σε αυτή την εργασία διερευνούμε το όφελος της αξιοποίησης του περιβάλλοντος συνομιλίας για το φιλτράρισμα δημοσιεύσεων που σχετίζονται με ένα συγκεκριμένο ιατρικό θέμα. Πειραματιζόμαστε με δύο προσεγγίσεις για να προσθέσουμε πλαίσιο συνομιλίας σε ένα μοντέλο: ένα διαδοχικό στρώμα και χειροκίνητα σχεδιασμένα χαρακτηριστικά. Αν και καμία προσέγγιση δεν μπορεί να ξεπεράσει το σκορ F1 της γραμμής βάσης διαπιστώνουμε ότι η προσθήκη ενός διαδοχικού στρώματος βελτιώνει την ακρίβεια για όλες τις κατηγορίες στόχων, ενώ η προσθήκη ενός μη διαδοχικού στρώματος με χειροκίνητα κατασκευασμένα χαρακτηριστικά οδηγεί σε υψηλότερη ανάκληση για δύο από τις τρεις κατηγορίες στόχων. Έτσι, ανάλογα με τον τελικό στόχο, η μοντελοποίηση με συνείδηση συνομιλίας μπορεί να είναι ευεργετική για τον εντοπισμό σχετικών μηνυμάτων. Ελπίζουμε τα ευρήματά μας να ενθαρρύνουν άλλους ερευνητές σε αυτόν τον τομέα να προχωρήσουν πέρα από τη μελέτη μηνυμάτων μεμονωμένα προς τη συλλογή και ταξινόμηση δεδομένων βασισμένων στο διάλογο. Απελευθερώνουμε τον κώδικα μας με σκοπό την παρακολούθηση της έρευνας.', 'hu': 'Az online betegfórumokon az NLP-feladatok korábbi megközelítése egyetlen posztokra korlátozódott, ezáltal figyelmen kívül hagyva az átfogó beszélgetési struktúrát. Ebben a tanulmányban feltárjuk a beszélgetési kontextus kiaknázásának előnyeit egy adott orvosi témához releváns bejegyzések szűrésére. Két megközelítéssel kísérletezünk, hogy beszélgetési kontextust adjunk hozzá egy BERT modellhez: egy szekvenciális CRF réteget és kézzel tervezett funkciókat. Bár egyik megközelítés sem tudja felülmúlni a BERT alapértékének F1 pontszámát, úgy találtuk, hogy egy szekvenciális réteg hozzáadása javítja a pontosságot minden célosztály számára, míg egy manuálisan tervezett funkciókkal rendelkező, nem szekvenciális réteg hozzáadása a három célosztályból kettő esetében magasabb visszahívást eredményez. Így a végső céltól függően a beszélgetés-tudatos modellezés hasznos lehet a releváns üzenetek azonosításában. Reméljük, hogy eredményeink arra ösztönzik a kutatókat, hogy az üzenetek elszigetelt tanulmányozásán túl lépjenek a diskurzus alapú adatgyűjtés és osztályozás felé. A kódunkat követő kutatások céljából adjuk ki.', 'it': "I precedenti approcci ai compiti della PNL sui forum dei pazienti online sono stati limitati a singoli post come unità, trascurando così la struttura conversazionale globale. In questo articolo esploriamo il vantaggio di sfruttare il contesto conversazionale per filtrare i post pertinenti a un argomento medico specifico. Sperimentiamo due approcci per aggiungere un contesto conversazionale a un modello BERT: un livello CRF sequenziale e funzionalità ingegnerizzate manualmente. Sebbene nessuno dei due approcci possa superare il punteggio F1 della base BERT, scopriamo che l'aggiunta di un livello sequenziale migliora la precisione per tutte le classi target, mentre l'aggiunta di un livello non sequenziale con funzionalità ingegnerizzate manualmente porta a un richiamo più elevato per due classi target su tre. Pertanto, a seconda dell'obiettivo finale, la modellazione consapevole della conversazione può essere utile per identificare i messaggi pertinenti. Speriamo che i nostri risultati incoraggino altri ricercatori in questo campo ad andare oltre lo studio dei messaggi in isolamento verso una raccolta e una classificazione dei dati basata sul discorso. Rilasciamo il nostro codice a scopo di ricerca di follow-up.", 'kk': 'Онлайн пациенттер форумындағы NLP тапсырмаларына алдыңғы жағдай бірліктер ретінде шектелген, сондықтан ол үлкен қатынау құрылғысын шектелген. Бұл қағазда біз медицина нақышына сүзгілеу жіберілген мәліметтерді сүзгілеу үшін сұрақ контексті пайдалану мүмкіндігін зерттейміз. Біз BERT үлгісіне қатынау контексті қосу үшін екі арқылы тәжірибелерді тәжірибелеміз: келесі CRF қабатты және қолмен инженерлік мүмкіндіктері. БЕРТ негізгі беттерінің F1 деңгейіндегі нәтижесін шектеуге болмайды, біз келесі қабатты қосу барлық мақсатты класстардың дұрыстығын жасайды, бірақ қолмен инженерлікті қабатты қосу үш мақсатты класстардан екі деңгейінде жоғары ес Сонымен аяқтау мақсатына тәуелді, сұхбат түсініктерінің моделігі мақсатты хаттарды анықтау үшін пайдалы болуы мүмкін. Біз іздегеніміз осы домендегі басқа зерттеушілерді өзгертуге үміттенеміз, хаттарды бір-бірінен айналысқан дискурстардың негіздеген деректер жинақтауы және классификациясын Біз кодымызды келесі зерттеулердің мақсатына шығару үшін.', 'mk': 'Претходните пристапи кон задачите на НЛП на онлајн форумите за пациенти се ограничени на единствени места како единици, со што ја заборавија сеопфатната разговарачка структура. Во овој весник ја истражуваме користта од искористувањето на контекстниот контекст за филтрирање постови релевантни за специфична медицинска тема. Експериментираме со два пристапи за да додадеме контекст за разговори на модел BERT: секвенцијален CRF слој и рачно инженерирани карактеристики. Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves precision for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher recall for two out of three target classes.  Затоа, во зависност од крајната цел, моделирањето свесно за разговорот може да биде корисно за идентификување на релевантните пораки. Се надеваме дека нашите откритија ги охрабруваат другите истражувачи во овој домен да се движат надвор од студирањето на пораките во изолација кон повеќе собирање и класификација на податоци базирани на дискурс. Го ослободуваме нашиот код за цел на следното истражување.', 'lt': 'Ankstesni požiūriai į NLP užduotis internetiniuose pacientų forumuose buvo susiję tik su vienintelėmis pareigomis kaip vienetai, taigi buvo pamiršta bendra pokalbių struktūra. Šiame dokumente ištiriame naudą išnaudoti pokalbių kontekstą filtravimo postuose, susijusiuose su konkrečia medicinine tema. Eksperimentuojame dviem metodais, kuriais siekiama pridėti konversacinį kontekstą prie BERT modelio: sekacinis CRF sluoksnis ir rankiniu būdu sukurtos savybės. Nors nė vienas metodas negali viršyti BERT pradinio taško F1, mes nustatome, kad pridedant eilinį sluoksnį pagerėja tikslumas visoms tikslinėms klasėms, o pridėjus ne eilinį sluoksnį su rankiniu būdu sukurtomis savybėmis, dviejų iš trijų tikslinių klasių atšaukimas padidėja. Taigi, atsižvelgiant į galutinį tikslą, sąmoningas modeliavimas gali būti naudingas nustatant atitinkamas žinias. Tikimės, kad mūsų išvados skatina kitus šios srities mokslininkus ne tik atskirai tirti pranešimus, bet ir rinkti ir klasifikuoti diskursais pagrįstus duomenis. We release our code for the purpose of follow-up research.', 'ms': 'Pendekatan terdahulu untuk tugas NLP pada forum pesakit online telah terbatas kepada pos tunggal sebagai unit, dengan itu mengabaikan struktur perbualan yang meliputi. Dalam kertas ini kami mengeksplorasi keuntungan dari mengeksplorasi konteks perbualan untuk penapisan pos yang berkaitan dengan topik perubatan tertentu. Kami eksperimen dengan dua pendekatan untuk menambah konteks perbualan ke model BERT: lapisan CRF sekuensial dan ciri-ciri direka secara manual. Walaupun kedua-dua pendekatan tidak dapat melampaui skor F1 dari dasar dasar BERT, kami mendapati bahawa menambah lapisan berturut-turut meningkatkan ketepatan untuk semua kelas sasaran sementara menambah lapisan bukan berturut-turut dengan ciri-ciri direka secara manual mengarah kepada pengingatan yang lebih tinggi untuk dua daripada tiga kelas sasaran. Oleh itu, bergantung pada tujuan akhir, pemodelan yang sedar perbualan mungkin berguna untuk mengenalpasti mesej yang berkaitan. Kami berharap penemuan kami mendorong penyelidik lain dalam domain ini untuk bergerak melampaui mempelajari mesej secara terpisah ke arah koleksi dan klasifikasi data yang berasaskan diskors. Kami melepaskan kod kami untuk tujuan penyelidikan.', 'mt': "Previous approaches to NLP tasks on online patient forums have been limited to single posts as units, thereby neglecting the overarching conversational structure.  F’dan id-dokument nistudjaw il-benefiċċju tal-isfruttar tal-kuntest ta’ konverżjoni għall-postijiet ta’ filtrazzjoni rilevanti għal suġġett mediku speċifiku. Aħna ninsperimentaw b’żewġ approċċi biex inżidu l-kuntest ta’ konverżjoni ma’ mudell BERT: saff sekwenzjali tas-CRF u karatteristiċi inġinerizzati manwalment. Għalkemm l-ebda approċċ ma jista’ jaqbeż il-punteġġ F1 tal-linja bażi BERT, instabu li ż-żieda ta’ saff sekwenzjali ttejjeb il-preċiżjoni għall-klassijiet kollha fil-mira filwaqt li ż-żieda ta’ saff mhux sekwenzjali b’karatteristiċi inġinerizzati manwalment twassal għal ġbir lura ogħla għal tnejn minn tliet klassijiet fil-mira. Għalhekk, skont l-għan finali, l-immudellar konxju mill-konverżjoni jista’ jkun ta’ benefiċċju għall-identifikazzjoni tal-messaġġi rilevanti. Nittamaw li s-sejbiet tagħna jinkoraġġixxu riċerkaturi oħra f'dan il-qasam biex imorru lil hinn mill-istudju ta' messaġġi iżolati lejn ġbir u klassifikazzjoni ta' dejta aktar ibbażati fuq diskors. Aħna nħelsu l-kodiċi tagħna għall-iskop tar-riċerka ta' segwitu.", 'ml': 'ഓണ്\u200dലൈന്\u200d രോഗിയുടെ ഫോര്\u200dമുകളിലേക്കുള്ള NLP ജോലികളുടെ മുമ്പുള്ള സമ്മാനങ്ങള്\u200d ഒരു പോസ്റ്റുകള്\u200d യൂണിറ്റുകളായി നിര്\u200dബന്ധിതമായ ഈ പത്രത്തില്\u200d നമ്മള്\u200d സംസാരിക്കുന്ന സംസാരത്തിന്റെ ഉപയോഗങ്ങള്\u200d പരിശോധിക്കുന്നു. പ്രത്യേകിച്ചൊരു മെഡിക്കല്\u200d വി ബെര്\u200dട്ടി മോഡലിലേക്ക് സംസാരിക്കാനുള്ള രണ്ട് വഴികളുമായി നമ്മള്\u200d പരീക്ഷിക്കുന്നു: പിന്നീടൊരു സിഎഫ് സ്റ്റേയര്\u200d കൊ ബെര്\u200dട്ടി ബേസ്ലൈനിലെ F1 സ്കോര്\u200d പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d സാധിക്കുന്നില്ലെങ്കിലും നമ്മള്\u200d കണ്ടെത്തുന്നു, എല്ലാ ലക്ഷ്യങ്ങള്\u200dക്കും ഒരു സ്ഥിരതയും കൂട്ടിച്ചേര്\u200dക്കുന്നു. ക അതുകൊണ്ട്, അവസാന ലക്ഷ്യത്തെ ആശ്രയിച്ചിരിക്കുന്നു, സംസാരിക്കുന്ന മാതൃകയില്\u200d വിചാരിക്കുന്ന സന്ദേശങ്ങള ഞങ്ങള്\u200d പ്രതീക്ഷിക്കുന്നു നമ്മുടെ കണ്ടുപിടികള്\u200d ഈ ഡോമെയിനിലെ മറ്റുള്ള അന്വേഷിക്കുന്നവര്\u200dക്ക് ആശ്വാസപ്പെടുത്തുന്നത We release our code for the purpose of follow-up research.', 'no': 'Førre tilnærmingar til NLP- oppgåver på internettformar har vært begrenset til enkelte postar som einingar, slik at det overarkiverte konvertasjonsstrukturen er avgrensa. I denne papiret utforskar vi fordel til å bruka samtalekontekst for filtering av postar som er relevante til eit spesielt medisinsk emne. Vi eksperimenterer med to tilnærmingar for å leggja samtalekontekst til ein BERT-modell: ein sekvensisk CRF-lag og manuelt ingeniar funksjonar. Selv om ingen tilnærming kan utføre F1-poeng på BERT-baselinja, finn vi at å legge til eit sekvensisk lag forbetrar nøyaktighet for alle målklassar, mens å legge til eit ikkje-sekvensisk lag med manuelt ingeniare funksjonar fører til ein høgare rekning for to av tre målklassar. Deretter, avhengig av sluttmålet, kan modelleringa med samtale være nyttig for å identifisera relevant meldingar. Vi håper at finningane våre oppfordrer andre forskere i denne domenet å flytte bort å studera meldingar i isolation mot meir datasamling og klassifikasjon på diskursbasert. Vi løyser koden vårt for målet av følgjande forskning.', 'mn': 'Өмнөх NLP өвчтөн өвчтөн өвчтөнүүдийн форумуудын ажиллагааны тухай өмнөх ойлголт нь нэгж болгон ганц захидалд хязгаарлагддаг. Энэ нь илүү их ярианы бүтэц юм. Энэ цаасан дээр бид харилцааны нөхцөл байдлыг ашиглах хэрэгтэй зүйлийг судалж байна. Бид BERT загвар руу ярилцлагын тухай хоёр арга зам ашиглах туршилттай туршилт хийдэг: дараагийн CRF давхар болон гар инженерчлэл. БЕРТ суурь шугамын F1 хэмжээсүүдийг дамжуулж чадахгүй ч, бид дараагийн дамжуулалт нь бүх зорилготой хичээлийн тодорхойлолтыг нэмэх нь тодорхойлолтой болно. Гэхдээ гар инженерчлэлтэй хэмжээсүүдийг нэмэх нь гурван зорилготой хичээлийн хоёр дахь хи Иймээс, төгсгөл зорилгоос хамааралтай, ярианы мэдрэгчийн модель нь холбоотой захиагуудыг тайлбарлах хэрэгтэй байж болно. Бидний ололтууд нь энэ холбооны бусад судлаачид холбоотой мэдээллийн цуглуулалт болон хуваалцааныг судалж байхаас гадна хөдөлгөж байна гэж найдаж байна. Дараагийн судалгааны зорилго дээр бид кодыг нээж өгдөг.', 'pl': 'Dotychczasowe podejście do zadań NLP na forach pacjentów online ograniczyło się do pojedynczych postów jako jednostek, zaniedbując tym samym nadrzędną strukturę konwersacji. W niniejszym artykule badamy korzyści z wykorzystania kontekstu konwersacyjnego do filtrowania postów istotnych dla konkretnego tematu medycznego. Eksperymentujemy z dwoma podejściami, aby dodać kontekst konwersacji do modelu BERT: sekwencyjną warstwę CRF i ręcznie projektowane funkcje. Chociaż żadne podejście nie może przewyższyć wyniku F1 podstawowego BERT, zauważamy, że dodanie warstwy sekwencyjnej poprawia precyzję dla wszystkich klas docelowych, podczas gdy dodanie warstwy niesekwencyjnej z ręcznie konstruowanymi funkcjami prowadzi do wyższego odwoływania dwóch z trzech klas docelowych. W zależności od celu końcowego modelowanie konwersacji może być korzystne dla identyfikacji istotnych komunikatów. Mamy nadzieję, że nasze wyniki zachęcają innych badaczy w tej dziedzinie do przejścia poza badanie wiadomości w izolacji w kierunku gromadzenia i klasyfikacji danych opartych na dyskursie. Udostępniamy nasz kod w celu dalszych badań.', 'ro': 'Abordările anterioare privind sarcinile PNL pe forumurile online ale pacienților au fost limitate la posturi unice ca unități, neglijând astfel structura conversațională generală. În această lucrare explorăm beneficiul exploatării contextului conversațional pentru filtrarea posturilor relevante pentru un anumit subiect medical. Experimentăm cu două abordări pentru a adăuga context conversațional unui model BERT: un strat CRF secvențial și caracteristici proiectate manual. Deși nici o abordare nu poate depăși scorul F1 al bazei BERT, constatăm că adăugarea unui strat secvențial îmbunătățește precizia pentru toate clasele țintă, în timp ce adăugarea unui strat non-secvențial cu caracteristici proiectate manual duce la o rechemare mai mare pentru două din trei clase țintă. Astfel, în funcție de obiectivul final, modelarea conștientă de conversație poate fi benefică pentru identificarea mesajelor relevante. Sperăm că rezultatele noastre încurajează alți cercetători din acest domeniu să treacă dincolo de studiul mesajelor în mod izolat către colectarea și clasificarea datelor bazate pe discurs. Ne eliberăm codul în scopul cercetării ulterioare.', 'so': "Shaqooyinkii hore ee NLP-ga ee ku qoran jardiinada shabakadda bukaanka waxaa lagu xadgudbay kooxo kaliya oo ay isku mid u yihiin, sidaas darteed waxay ka tageen dhismaha la-sheekeysto. Qoraalkan waxaynu ka baaraynaa faa'iidada ku isticmaalka kooxda kala sheekeysiga ee boostada la xiriira mada caafimaad gaar ah. Waxaynu imtixaamaynaa laba qaab ah si aan ugu daro qalabka hadalka ee BERT: xarunta CRF ee dabadeed iyo qalabka qof lagu sameeyo. In kastoo aysan sameyn karin kooxda F1 ee barxadda BERT, waxaynu aragnaa in lagu daray darafka xilliga ah uu kordhiyo saxda kooxaha waxqabadka oo dhan, laakiin ku daro darafka aan kooxaha la qorin karo qof-ka-dabaqa ah oo qabanqaabiyay waxyaabo lagu sameeyo, waxay leedahay xusuus dheer oo ka mid ah laba fasalka waxqabadka. Sidaas darteed, goor ku xiran goalka ugu dambaysta, waxaa faa’iido ah in loo caddeeyo warqada la xiriira. Waxaan rajaynaynaa in xaaladeenu ay ku dhiirrigeliyaan baaritaanka kale ee gurigan ku yaala inay u dhaqdhaqaaqdo wax ka barashada farriinyo gooni ah si loo soo diro ururka macluumaadka oo ku saabsan. We release our code for the purpose of follow-up research.", 'si': 'අන්ලයින් රෝගිකයෝ විදියට NLP ක්\u200dරියාවට පිරිසිදුම් විදියට සීමාවිත වෙලා යුනික් වලින් එක පොස්ට් වලින් සීමාවිත මේ පත්තරේ අපි පරීක්ෂණය කරනවා වාර්තාව ප්\u200dරවේශනය සඳහා විශේෂ වෛද්\u200dය ප්\u200dරශ්නයකට සම්බන්ධ වෙන්න පොස්ටල අපි පරීක්ෂණය කරන්න බෙර්ට් මෝඩල් එක්ක සම්බන්ධ පරීක්ෂණයක් සඳහා ප්\u200dරවේශනය දෙකක් තියෙනවා: පරීක්ෂණ CRF පරීක්ෂ BERT පස්සේ ප්\u200dරමාණයේ F1 ප්\u200dරමාණය නැති නමුත් අපි හොයාගන්නවා කියලා සියළු ප්\u200dරමාණය සම්පූර්ණය සඳහා සියළු ඉලක්ෂ ක්\u200dරාස්තුවක් සඳහා සියළු ප්\u200dරමාණය සඳහා සිය ඉතින්, අවසාන අරමුණ අරමුණ විසින්, කතා කරන්න පුළුවන් අවස්ථාවක් නිර්මාණය සඳහා ප්\u200dරයෝජනය වෙන් අපි බලාපොරොත්තු වෙනවා අපේ හොයාගන්න අනිත් පරීක්ෂකයන්ට මේ ඩෝමේන් එකේ අනිත් පරීක්ෂකයන්ට ප්\u200dරශ්නයක් කරන්න, පණිවි අපි අපේ කෝඩ් එක ප්\u200dරකාශ කරනවා පරීක්ෂණ පරීක්ෂණයට.', 'sr': 'Prethodni pristupi zadacima NLP-a na internetskim forumima pacijenata ograničeni su na jednostavne postupke kao jedinice, tako da zanemaruju široku razgovornu strukturu. U ovom papiru istražujemo korist iskorištavanja razgovornog konteksta za filtriranje postova relevantnih za određenu medicinsku temu. Eksperimentiramo sa dva pristupa da dodamo razgovorni kontekst BERT modelu: sekvencijalni CRF sloj i ručno inženjerirane karakteristike. Iako nijedan pristup ne može izvršiti rezultat F1 početne linije BERT-a, smatramo da dodavanje sekvencijskog sloja poboljšava preciznost za sve klase ciljeva, dok dodavanje nekosekvencijskog sloja sa ručno inženjerenim karakteristikama vodi do većeg sjećanja za dva od tri klase ciljeva. Zato, ovisno o krajnjem cilju, modeliranje svijesti razgovora može biti korisno za identifikaciju relevantnih poruka. Nadamo se da se naši nalazi ohrabruju drugim istraživačima u ovoj oblasti da se presele izvan proučavanja poruka u izolaciji ka kolekciji i klasifikaciji podataka na temelju diskursa. Puštamo naš kod za svrhu istraživanja.', 'sv': 'Tidigare tillvägagångssätt för NLP-uppgifter på patientforum online har begränsats till enstaka inlägg som enheter, vilket försummar den övergripande konversationsstrukturen. I denna uppsats undersöker vi fördelarna med att utnyttja konversationskontext för att filtrera inlägg som är relevanta för ett specifikt medicinskt ämne. Vi experimenterar med två metoder för att lägga till konversationskontext till en BERT-modell: ett sekventiellt CRF-lager och manuellt konstruerade funktioner. Även om inget tillvägagångssätt kan överträffa F1-poängen för BERT-baseline, finner vi att tillägg av ett sekventiellt lager förbättrar precisionen för alla målklasser medan tillägg av ett icke-sekventiellt lager med manuellt konstruerade funktioner leder till en högre återkallelse för två av tre målklasser. Beroende på slutmålet kan konversationsmedvetna modeller vara fördelaktiga för att identifiera relevanta meddelanden. Vi hoppas att våra resultat uppmuntrar andra forskare inom detta område att gå bortom att studera meddelanden isolerat mot mer diskursbaserad datainsamling och klassificering. Vi släpper vår kod för uppföljningsforskning.', 'ur': 'اولین مریضی فورموں کے NLP تاسکیوں کے پہلے طریقے پر ایک پوسٹ کو یونیٹ کے طور پر محدودہ کر دیا گیا ہے، اس کے ذریعہ سے زیادہ سخنرانی ساختار کو غفلت کر دیا گیا ہے. ہم اس کاغذ میں ایک مخصوص موضوع کے معاملہ میں پوسٹ فیلٹرینگ کے لئے صحبت کی کنٹنسیٹ کا استعمال کرنے کے لئے فائدہ استعمال کرتے ہیں. ہم نے ایک BERT موڈل کے ساتھ رابطہ سند کے ساتھ دو طریقے سے آزمائش کریں: ایک سفارشی CRF لائر اور manually engineered features. اگرچہ کوئی تقریبا بھی BERT بنسٹ لین کے F1 اسکور کو اضافہ نہیں کر سکتا، ہم دیکھتے ہیں کہ ایک سکوئنسیل لائر کو جمع کرنے کے لئے تمام موقع کلاس کے لئے دقیق ترقیت کو اضافہ کرتا ہے، حالانکہ ایک غیر سکوئنسیل لائر کو اپنے ہاتھ سے انجینر کی فوائل کے ساتھ جمع کرنے کے لئے تین موقع کلاس میں اسی طرح، آخری مقصد پر اعتماد ہے، بات سے خبردار موڈلینگ معلوم ہونے کے لئے مناسب ہے. ہم امید رکھتے ہیں کہ ہمارے نتیجے اس ڈومین میں دوسرے تحقیقات کرنے والوں کو اس طرح آزمائش دیتے ہیں کہ پیغام پڑھنے کے بعد ایک دوسرے سے زیادہ سخنرانی کے بنیاد دار ڈیٹا کلکسیونٹ اور کلکسیونٹ کی طرف چل ہم اپنا کوڈ اچھی تحقیق کے مطابق چھوڑ دیتے ہیں.', 'ta': 'முந்தைய அணுகல்கள் இணைய நோயாளிகளில் NLP பணிகளுக்கு செய்யும் முன்னோட்டங்கள் தனிப்பட்ட அஞ்சல்கள் அலகுகளாக உள்ளன, அதனால் மேலேற்கோள் இந்த காகிதத்தில் நாம் ஒரு குறிப்பிட்ட மருத்துவ தலைப்புக்கு தொடர்புடைய பேச்சு மூலங்களை வடிகட்டுவதற்கு பயன்படுத் BERT மாதிரியை சேர்க்க இரண்டு முறைகளால் நாம் பரிசோதனை செய்கிறோம்: பின்வரும் CRF அடுக்கு மற்றும் கைமுறையாக பொறுத்துப BERT அடிக்கோட்டின் F1 மதிப்பெண்களை விட முடியாது எனினும் நாம் கண்டுபிடிக்கிறோம். பின்வரும் அடுக்கை சேர்த்து எல்லா இலக்க வகுப்புகளுக்கும் சரியான விருப்பத்தை அதிகரிக் அதனால், இறுதியின் சார்ந்தது, பேச்சு உணர்ந்து கொள்ளும் மாதிரிமாற்றம் தொடர்புடைய செய்திகளை அடையாளம் செய்ய நாங்கள் நம்முடைய கண்டுபிடிப்புகள் இந்த களத்தில் உள்ள மற்ற ஆராய்ச்சியாளர்களை ஆராய்ச்சிக்கிறோம் என்று நம்புகிறோம் அதி நாம் பின்பற்ற ஆராய்ச்சிக்கு எங்கள் குறியீட்டை விடுவோம்.', 'uz': "Name Bu qogʻozda, biz mahsus tibbiy mavzuga bog'liq postlarni filterlash uchun muloqat tarkibini aniqlash uchun foydalanamiz. Biz BERT modeliga muloqat muhit qoʻshish uchun ikkita usul bilan sinab qilamiz: keyingi CRF qatlam va qoʻlbola qoʻlbola ishga tushirilgan imkoniyatlar. Hech qachon murakkablar BERT asosiy satrning F1 scorini bajarishi mumkin, biz o'ylaymiz, keyin qanday darajani qoʻllab qoʻllanmagan xossalarni qoʻllab qoʻllash qoʻllanmagan darajaga ikkita darajadagi darajaga qoʻshish qoʻllanmagan darajaga ikkita darajaga bir kichkina eslab qoladi. Shunday qilib, oxiri maqsad bilan bog'liq muloqat modeli bogʻ'liq xabarlarni aniqlash uchun foydali boʻlishi mumkin. Biz bu domeydagi boshqa ta'qituvchilarni o'rganishni o'rganishni o'rganishni o'rganishni o'rganamiz va ko'proq ma'lumotlar to ʻplami va tabiifsiyatlarni o'rganishni o'zgartiradimiz mumkin. Biz qoidamizni taʼminlovchi qidirish uchun chiqaramiz.", 'vi': 'Các phương pháp trước trước để giải quyết các công việc của đài ngôn ngữ bệnh nhân trực tuyến đã được giới hạn trong vai trò đơn vị, bỏ qua cấu trúc cuộc đối thoại tổng quát. Trong tờ giấy này, chúng tôi khám phá lợi ích của việc khai thác các ngữ cảnh đối thoại cho các trạm lọc liên quan đến một chủ đề y học cụ thể. Thử nghiệm với hai phương pháp để thêm ngữ cảnh cuộc đối thoại vào mô hình BERT: lớp CRF lặp lại và tính năng được ghép bằng tay. Mặc dù không phương pháp nào có thể vượt qua điểm F1 của đường cơ sở thực phẩm BERT, nhưng chúng tôi thấy rằng việc thêm một lớp lặp lại tăng độ chính xác cho tất cả các lớp nhắm, trong khi việc thêm lớp không nối với các tính năng được ghép bằng tay, dẫn đến triệu hồi cao hơn cho hai trong ba lớp nhắm. Do đó, tùy thuộc vào mục đích cuối, mô hình biết đối thoại có thể hữu ích để xác định các thông điệp liên quan. Chúng tôi hy vọng kết quả của chúng tôi khuyến khích các nhà nghiên cứu khác trong lĩnh vực này hành động vượt xa việc cô lập các thông điệp để thu thập và phân loại dữ liệu. Chúng tôi giải mã cho mục đích nghiên cứu tiếp theo.', 'hr': 'Prethodni pristupi zadatkima NLP-a na internetskim forumima pacijenata ograničeni su na jednostavne postupke kao jedinice, tako zanemarujući cjelokupnu razgovornu strukturu. U ovom papiru istražujemo korist iskorištavanja razgovornog konteksta za filtriranje mjesta važnih za određenu medicinsku temu. Eksperimentiramo s dvije pristupe da dodamo razgovorni kontekst BERT modelu: sekvencijalni CRF sloj i ručno inženjerirane karakteristike. Iako nijedan pristup ne može izvršiti rezultat F1 početne linije BERT-a, smatramo da dodavanje sekvencijskog sloja poboljšava preciznost svih ciljnih klasa, dok dodavanje nekosekvencijskog sloja s ručno inženjerenim karakteristikama dovede do većeg sjećanja za dva od tri ciljnih klasa. Stoga, ovisno o krajnjem cilju, modeliranje svijesti razgovora može biti korisno za identifikaciju relevantnih poruka. Nadamo se da su naši nalazi poticali druge istraživače u ovoj oblasti da se krenu izvan proučavanja poruka u izolaciji ka skupljanju i klasifikaciji podataka na temelju diskursa. Puštamo naš kod za svrhu istraživanja.', 'bg': 'Предишните подходи към задачите на НЛП в онлайн форумите на пациентите бяха ограничени до единични публикации като единици, като по този начин пренебрегваха всеобхватната структура на разговора. В тази статия изследваме ползата от използването на разговорния контекст за филтриране на публикации, свързани с конкретна медицинска тема. Експериментираме с два подхода за добавяне на разговорен контекст към модела: последователен слой и ръчно проектирани функции. Въпреки че нито един от подходите не може да превъзхожда резултата от базовата линия, откриваме, че добавянето на последователен слой подобрява прецизността за всички целеви класове, докато добавянето на несеквенциален слой с ръчно проектирани функции води до по-високо изтегляне за два от три целеви класове. По този начин, в зависимост от крайната цел, моделирането, осъзнаващо разговора, може да бъде полезно за идентифициране на съответните съобщения. Надяваме се нашите открития да насърчат други изследователи в тази област да преминат отвъд изучаването на посланията изолирано към по-дискурсно базирано събиране и класификация на данни. Ние публикуваме нашия код за целите на последващи изследвания.', 'da': 'Tidligere tilgange til NLP-opgaver på online patientfora har været begrænset til enkelte indlæg som enheder og dermed forsømt den overordnede samtalestruktur. I denne artikel undersøger vi fordelene ved at udnytte samtalekontakt til filtrering af indlæg, der er relevante for et specifikt medicinsk emne. Vi eksperimenterer med to tilgange til at tilføje konversationskontekst til en BERT-model: et sekventielt CRF-lag og manuelt konstruerede funktioner. Selvom ingen af metoderne kan overgå F1-scoren for BERT-baseline, finder vi ud af, at tilføjelse af et sekventielt lag forbedrer præcisionen for alle målklasser, mens tilføjelse af et ikke-sekventielt lag med manuelt konstruerede funktioner fører til en højere tilbagekaldelse for to ud af tre målklasser. Afhængigt af slutmålet kan samtalebevidst modellering således være gavnlig til identificering af relevante budskaber. Vi håber, at vores resultater opmuntrer andre forskere på dette område til at bevæge sig ud over at studere budskaber isoleret i retning af mere diskursbaseret dataindsamling og klassificering. Vi frigiver vores kode med det formål at opfølge op forskning.', 'nl': 'Eerdere benaderingen van NLP-taken op online patiëntenforums zijn beperkt tot enkele posten als eenheden, waardoor de overkoepelende gespreksstructuur wordt verwaarloosd. In dit artikel onderzoeken we het voordeel van het benutten van gesprekscontext voor het filteren van berichten die relevant zijn voor een specifiek medisch onderwerp. We experimenteren met twee benaderingen om conversatiecontext toe te voegen aan een BERT-model: een sequentiële CRF-laag en handmatig ontworpen functies. Hoewel geen van beide benaderingen de F1-score van de BERT-baseline kan overtreffen, vinden we dat het toevoegen van een sequentiële laag de precisie voor alle doelklassen verbetert, terwijl het toevoegen van een niet-sequentiële laag met handmatig ontworpen functies leidt tot een hogere terugroepactie voor twee van de drie doelklassen. Afhankelijk van het einddoel kan conversatiebewuste modellering dus nuttig zijn voor het identificeren van relevante berichten. We hopen dat onze bevindingen andere onderzoekers in dit domein aanmoedigen om verder te gaan dan alleen het bestuderen van berichten naar meer discoursgebaseerde gegevensverzameling en classificatie. Wij geven onze code vrij voor vervolgonderzoek.', 'de': 'Bisherige Ansätze für NLP-Aufgaben in Online-Patientenforen beschränkten sich auf einzelne Beiträge als Einheiten, wodurch die übergreifende Gesprächsstruktur vernachlässigt wurde. In diesem Beitrag untersuchen wir den Nutzen von Gesprächskontext für die Filterung von Beiträgen, die für ein bestimmtes medizinisches Thema relevant sind. Wir experimentieren mit zwei Ansätzen, um einem BERT-Modell Konversationskontext hinzuzufügen: einer sequentiellen CRF-Ebene und manuell konstruierten Features. Obwohl keiner der beiden Ansätze die F1-Punktzahl der BERT-Basislinie übertreffen kann, stellen wir fest, dass das Hinzufügen einer sequenziellen Ebene die Präzision für alle Zielklassen verbessert, während das Hinzufügen einer nicht sequenziellen Ebene mit manuell konstruierten Funktionen zu einem höheren Abruf für zwei von drei Zielklassen führt. Abhängig vom Endziel kann eine konversationsbewusste Modellierung daher hilfreich sein, um relevante Botschaften zu identifizieren. Wir hoffen, dass unsere Ergebnisse andere Forscher in diesem Bereich ermutigen, über die isolierte Untersuchung von Botschaften hinauszugehen, hin zu einer diskursbasierten Datenerhebung und Klassifizierung. Wir veröffentlichen unseren Code zum Zwecke der Nachforschung.', 'fa': 'دسترسی قبلی به کار NLP در فورمهای بیماران آنلاین محدود به یک پست به عنوان واحد محدود شده\u200cاند، بنابراین ساختار ارتباطی بیشتری را نادیده گرفته\u200cاند. در این کاغذ ما سود استفاده از محیط مکالمه برای فیلتر کردن پست های مربوط به یک موضوع پزشکی خاص را تحقیق می کنیم. ما با دو دسترسی برای اضافه کردن محیط گفتگوی به یک مدل BERT آزمایش می کنیم: یک طبقه CRF ردیابی و ویژگی های مهندسی دستی. اگرچه هیچ دستیابی نمی\u200cتواند امتیاز پایین BERT F1 را برتر کند، ما می\u200cیابیم که اضافه کردن یک طبقه پایین برای تمام کلاس هدف دقیق را بهتر می\u200cکند، در حالی که اضافه کردن یک طبقه غیرپایین با ویژه\u200cهای دستی مهندسی به یادآوری بالاتر برای دو از سه کلاس هدف می\u200cکند. بنابراین، بستگی به هدف پایان، مدل\u200cسازی با بحث برای شناسایی پیام\u200cهای مربوط به سودی است. ما امیدواریم نتیجه\u200cهایمان به محققان دیگر در این دامنه تشویق کنند تا از مطالعه پیام\u200cها در تنهایی به سمت جمع و گروه\u200cسازی داده\u200cهای بیشتری بر اساس گفتگوها حرکت کنند. ما کد خود را برای هدف تحقیقات پیروزی آزاد می کنیم.', 'id': 'Pendekatan sebelumnya untuk tugas NLP di forum pasien online telah terbatas ke pos tunggal sebagai unit, dengan itu mengabaikan struktur konversasi yang luas. Dalam kertas ini kami mengeksplorasi keuntungan dari mengeksplorasi konteks konversasi untuk posting filtrasi yang relevan untuk topik medis spesifik. Kami eksperimen dengan dua pendekatan untuk menambahkan konteks konversasi ke model BERT: lapisan CRF sekuensial dan fitur rekayasa secara manual. Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves precision for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher recall for two out of three target classes.  Jadi, tergantung pada tujuan akhir, model yang sadar percakapan mungkin berguna untuk mengidentifikasi pesan relevanti. Kami berharap penemuan kami mendorong para peneliti lain di daerah ini untuk bergerak melampaui mempelajari pesan secara isolasi menuju koleksi dan klasifikasi data berbasis diskursi. Kami melepaskan kode kami untuk tujuan penelitian.', 'sw': 'Matokeo yaliyopita kwenye majukwaa ya wagonjwa mtandaoni yamekuwa vizuizi kwenye makala moja kama viungo, na hivyo wanapuuza muundo wa mazungumzo ya juu. Katika karatasi hii tunatafuta faida ya kutumia mazingira ya mazungumzo kwa kuchuja makala zinazohusiana na mada maalum ya matibabu. Tunajaribu kwa njia mbili za kuongeza muktadha wa mazungumzo kwa muundo wa BERT: daraja la CRF na vipengele vilivyoundwa kwa mkono. Ingawa hatuna mbinu yoyote haiwezi kutekeleza vipimo vya F1 vya msingi wa BERT, tunagundua kwamba kuongeza daraja la kufuatia kuboresha uhakika kwa darasa zote ambapo kuongeza daraja lisilo la kufuatia vifaa vinavyotengenezwa kwa mkono linapelekea kukumbuka zaidi kwa darasa mbili kati ya mitatu la lengo. Kwa hiyo, kulingana na lengo la mwisho, mifano ya mazungumzo yanaweza kuwa na faida kwa kutambua ujumbe muhimu. Tunatumaini kwamba matokeo yetu yanawahamasisha watafiti wengine katika eneo hili ili kuhamisha zaidi ya kusoma ujumbe wa kujitenga kwa ajili ya mkusanyiko wa data na usambazaji wa mazungumzo. Tunaachia sheria zetu kwa lengo la utafiti wa ufuatiliaji.', 'ko': '이전에 온라인 환자 포럼에서 NLP 작업을 처리하는 방법은 단일 게시물 단위로 제한되어 전체 세션 구조를 무시했다.본고에서 우리는 대화 언어 환경을 이용하여 특정 의학 주제와 관련된 댓글을 필터하는 장점을 연구했다.우리는 버트 모델에 대화 상하문을 추가하는 두 가지 방법을 시험했다. 그것이 바로 순서 CRF층과 수동 디자인의 특징이다.이 두 가지 방법 모두 BERT 기선의 F1 점수를 초과할 수 없지만, 순서층을 추가하면 모든 목표류의 정밀도를 높일 수 있고, 수동적인 디자인 특징을 가진 비순서층을 추가하면 목표류의 3분의 2의 리콜률을 높일 수 있다는 것을 발견했다.따라서 최종 목표에 따라 대화 감지 모델링은 관련 정보를 식별하는 데 도움이 될 수 있다.우리는 이 분야의 다른 연구자들이 고립된 정보를 초월하여 언어 기반의 데이터 수집과 분류로 전환하도록 격려할 수 있기를 바란다.우리가 코드를 발표한 것은 후속 연구를 위해서이다.', 'sq': 'Përqasjet e mëparshme ndaj detyrave të NLP në forumet e pacientëve në internet janë kufizuar në vende të vetme si njësi, duke harruar kështu strukturën e përgjithshme bisedimore. Në këtë letër ne eksplorojmë përfitimin e shfrytëzimit të kontekstit bisedimor për postin e filtrimit të rëndësishëm për një temë mjekësore të caktuar. We experiment with two approaches to add conversational context to a BERT model: a sequential CRF layer and manually engineered features.  Megjithëse asnjë metodë nuk mund të kalojë rezultatin F1 të bazës së BERT, ne zbulojmë se shtimi i një shtrese sekuencuese përmirëson saktësinë për të gjitha klasat objektive ndërsa shtimi i një shtrese jo sekuencuese me karakteristika të inxhinieruara manualisht shpie në një tërheqje më të lartë për dy nga tre klasat objektive. Kështu, në varësi të qëllimit përfundimtar, modelimi i ndërgjegjshëm për bisedën mund të jetë i dobishëm për identifikimin e mesazheve të rëndësishëm. Shpresojmë që zbulimet tona inkurajojnë kërkimtarë të tjerë në këtë fushë të lëvizin përtej studimit të mesazheve në izolim drejt mbledhjes dhe klasifikimit të të dhënave më të bazuara në diskurse. Ne lëshojmë kodin tonë për qëllim të kërkimit të vazhdueshëm.', 'am': 'የቀድሞው የNLP ሥርዓቶች በመንግሥት ውጤቶች ላይ የኢንተርኔት ጦማሪያዎች በአንድ ደብዳቤዎች በኩል ተቃውሞ ነበር፡፡ በዚህ ካላት ውስጥ በተለያዩ መድኃኒት ጉዳይ ላይ የተጠቃሚ የውይይት ጉዳይ ለመጠቀም የሚጠቅመውን ጥቅም እናደርጋለን፡፡ የBERT ምሳሌ ለመጨመር በሁለት ልማድ ጥያቄዎችን እና በእጃችን ያስተካክሉ ነበር፡፡ ምንም እንኳን የF1 ደረጃን የBERT ብጤስልክ ማሳየት ቢችል፣ በኋላው ደረጃን ለመጨመር ለሁሉም ደረጃዎች ማስታወቂያውን እንዲያበዛ እናገኘዋለን፡፡ ስለዚህም በመጨረሻው አቃውሞ በተጠቃሚ፣ የንግግር ማወቅ ሞዴል የተጠቃሚ መልእክትን ለማግኘት ይጠቅማል፡፡ ፍጥረታችን በዚህ ዶሜን ያሉትን ሌሎችን አስተማሪዎች ለብቻው መልእክቶችን በተለየ እና በተለያዩ የዳታ ሰብስብ እና በተለያየ ለመዘርጋት እንዲያሳስብ ተስፋ እናደርጋለን፡፡ ለጥያቄ ትምህርት ለማግኘት የኮድራችንን እናስቀራለን፡፡', 'tr': 'NLP täzelikleriniň öňki ýakynlaşyk forumlarynda NLP täzelikleri birnäçe ýerlere mümkin edýär, şonuň üçin aşa arşiw düzenini boýun gaýşartýar. Bu kagyzda biz lukmanyň häzirki mesele üçin bellenen meýdançalary filtremek üçin söhbet kontekstyny ulanmaklygyny gözləýäris. BERT nusgasyna bir nusga eklemek üçin iki goll bilen synanyşýarys: diňe bir CRF gaty we el inženjerilýän özellikler. BERT baseliniň F1 sanyny çykyp bilmeýändigine garamazdan hemme maksady klaslaryň dogrylygyny gowurap bilmeýändigini düşünýäris. Bu şekilde elimden mühendislerle bir gat eklemek üçin üç maksady klaslardan ikisi üçin ýokaryň hatyna ýokaryr. Şonuň üçin soňky maksadyna baglanýan, söhbet bilen tanyşyp biljek mesajlary tanyşdyrmak üçin bir faydaly bolar. Bu domuzun diğer araştırmacıları, mesajlarımızı yalnız konuşmak üzere daha fazla konuşma tabanlı veri koleksiyonuna ve klasifikasyona taşımak için cesaretlendirmelerimizi umuyoruz. Biz öz kodymyzy yzarlanjak barlamasynyň maksady üçin çykarýarys.', 'af': "Vorige toegang tot NLP-opdragte op aanlyn paciente forume is beperk na enkele pos as eenhede, daarom verwerp die oorskryfende gesprekslykstruktuur. In hierdie papier ondersoek ons die voordeel van die gebruik van gesprekslys konteks vir filtering van pos wat betrokke aan 'n spesifieke mediese onderwerp is. Ons eksperimenteer met twee toegange om konversatiewe konteks by 'n BERT model te voeg: ' n sekwensiele CRF laag en manuele inženeer funksies. Alhoewel geen toegang kan die F1 aantal van die BERT baselyn uitvoer nie, vind ons dat by 'n volgende laag toevoeg van 'n volgende laag presisie vir alle doel klasse verbeter terwyl by 'n non- sequential laag byvoeg met hand inženeer funksies lei na 'n hoër rekening vir twee uit drie doel klasse. Daarom, afhanklik van die einde doel, kan die gesprek-bewys modellering nuttig wees vir die identifiseer van relevante boodskappe. Ons hoop ons bevestings wat ander ondersoekers in hierdie domein moet bevestig om buite te ondersoek boodskappe in isolation na meer diskurse-gebaseerde data versameling en klasifikasie te beweeg. Ons verlos ons kode vir die doel van volg-ondersoek.", 'hy': 'Անլայն հիվանդների ֆորմերում հիմնված ՆԼՊ խնդիրների նախորդ մոտեցումները սահմանափակվել են միակ տեղերով որպես միավորներ, այնպես անտեսելով խոսակցության ընդհանուր կառուցվածքը: Այս թղթի մեջ մենք ուսումնասիրում ենք, թե որքան օգտակար է օգտագործել խոսակցական կոնտեքստը ֆիլտրելիս տեղադրությունների համար, որոնք կարևոր են որոշակի բժշկական թեմայի համար: Մենք փորձում ենք երկու մոտեցումներով, որպեսզի ավելացնենք հաղորդակցման կոնտեքստը BER-ի մոդելի մեջ. հաջորդակցված ԿՌՖ շերտ և ձեռքով ճարտարագործված հատկություններ: Չնայած ոչ մի մոտեցում չի կարող գերազանցել BER հիմքի F1-ի գնահատականը, մենք հայտնաբերում ենք, որ հաջորդական շերտի ավելացումը բարելավում է ճշգրտությունը բոլոր նպատակային դասերի համար, մինչդեռ ոչ հաջորդական շերտի ավելացումը ձեռքով ճարտարագրված հատկություններով հանգեցնում է ավելի բարձր վեր Այսպիսով, կախված վերջնական նպատակից, խոսակցությամբ գիտակցած մոդելը կարող է օգտակար լինել նշանակալի հաղորդագրությունների հայտնաբերման համար: Մենք հույս ունենք, որ մեր հայտնաբերությունները խրախուսում են այս ոլորտում գտնվող այլ հետազոտողներին շարժվել առանց առանձին հաղորդագրություններ ուսումնասիրելու, որպեսզի ավելի խոսակցությամբ հիմնված տվյա We release our code for the purpose of follow-up research.', 'az': 'Əvvəlki NLP işlərinin online səbir forumlarında təkcə bir məlumat olaraq təkcə təkcə bir məlumat olaraq təkrar edilmişdir, bununla böyük müzakirə quruluşu unutdurmaqdan vaz keçmişdir. Bu kağızda biz müzakirə məsələlərə bağlı məsələlər filtrləmək üçün müzakirə məlumatlarını istifadə etmək faydasını keşfetirik. Belə bir BERT modeli ilə söhbət məlumatı əlavə etmək üçün iki tərəflə imtahana çəkirik: sıradan CRF səviyyəsi və əlində inženjerlənmiş xüsusiyyətlər. Nə qədər də, BERT səviyyəsinin F1 nöqtəsini a şa bilməyəcəyi halda, biz görürük ki, sevgili səviyyəni toplamaq bütün məqsəd səviyyələri üçün nöqtəsini daha yaxşılaşdırır. Halbuki əl inženjerlənmiş fərqlərlə birlikdə səviyyəni əlində müəyyən etmək üç məqsəd səviyyələrindən iki nəfər Beləliklə, sonun məqsədilə bağlı, müzakirə-bilən modelləri məlumatları tanıtmaq üçün faydalı olar. Biz ümid edirik ki, tapındıqlarımız bu domain içində digər araştırmacılara məktubları təkrarlaşdırmaqdan uzaqlaşdırmaq üçün daha çox danışmaq üçün verilər koleksiyonuna və klasifikasiya yönəldir. Biz kodumuzu izlənmək məqsədilə yayındırırıq.', 'bn': 'অনলাইন রোগী ফোরামে এনএলপি কাজের পূর্ববর্তী প্রতিযোগিতা একটি পোস্টের ইউনিট হিসেবে সীমাবদ্ধ হয়েছে, যার ফলে তারা বিভিন্ন আলোচন এই পত্রিকায় আমরা বিশেষ মেডিকেল বিষয়ের সাথে যুক্ত পোস্ট পরিশোধ করার জন্য আলোচনার প্রতিক্রিয়া ব্যবহার করার সুবিধা খুঁজ বিবেরেটি মডেলে যোগ করার জন্য আমরা দুটি প্রযুক্তি দিয়ে পরীক্ষা করছি: পরবর্তী সিআরএফ স্তর এবং হাতে প্রকাশিত বৈশিষ্ট্য। যদিও কোন ধরনের ক্ষেত্রেও বিবেরেট বেসালাইনের F1 স্কোরের বেশি পালন করতে পারে না, তবুও আমরা দেখতে পাচ্ছি যে পরবর্তীতে একটি স্তর সকল লক্ষ্য শ্রেণীর জন্য সঠিক স্তর যোগ করে যাওয়া যায়, কিন্ তাই শেষ লক্ষ্যের উপর নির্ভর করে কথোপকথন-সচেতন মডেলিং সম্ভবত প্রয়োজনীয় বার্তা সনাক্ত করার জন্য সুবিধার। আমরা আশা করি এই ডোমেইনের অন্যান্য গবেষকদের উৎসাহ দিচ্ছি যে বার্তা পাঠানোর বাইরে আলাদা ভিত্তিক তথ্য সংগ্রহ এবং বিভিন্ন বিভি অনুসরণের গবেষণার উদ্দেশ্যে আমরা আমাদের কোড ছেড়ে দেই।', 'bs': 'Prethodni pristupi zadacima NLP-a na internetskim forumima pacijenata ograničeni su na jednostavne mjesta kao jedinice, zato zanemarujući cjelokupnu razgovornu strukturu. U ovom papiru istražujemo korist iskorištavanja razgovornog konteksta za filtriranje mjesta relevantnih za određenu medicinsku temu. Eksperimentiramo sa dva pristupa da dodamo konverzacioni kontekst model BERT-a: sekvencijalni sloj CRF-a i ručno inženjerne karakteristike. Iako nijedan pristup ne može izvršiti rezultat F1 početne linije BERT-a, smatramo da dodavanje sekvencijskog sloja poboljšava preciznost za sve ciljne klase, dok dodavanje nekosekvencijskog sloja sa ručno inženjerenim karakteristikama vodi do većeg sjećanja za dva od tri ciljne klase. Stoga, ovisno o krajnjem cilju, modeliranje svijesti razgovora može biti korisno za identifikaciju relevantnih poruka. Nadamo se da se naši nalazi ohrabruju drugim istraživačima u ovoj oblasti da se kreću izvan proučavanja poruka u izolaciji ka skupljanju i klasifikaciji podataka na temelju diskursa. Puštamo naš kod za svrhu istraživanja.', 'et': 'Varasemad lähenemisviisid uue õppekava ülesannetele patsientide foorumites on piirdunud üksikute postitustega üksustena, jättes seega tähelepanuta üldist vestlusstruktuuri. Käesolevas dokumendis uurime vestluskonteksti kasutamise eeliseid konkreetse meditsiiniteemaga seotud postituste filtreerimiseks. Eksperimenteerime BERT mudelile vestluskonteksti lisamiseks kahe lähenemisviisiga: järjestikuse CRF kihi ja käsitsi projekteeritud funktsioonide abil. Kuigi kumbki lähenemisviis ei suuda ületada BERT algtaseme F1 skoori, leiame, et järjestikuse kihi lisamine parandab täpsust kõigi sihtklasside puhul, samas kui käsitsi projekteeritud funktsioonidega mittesjärjestikuse kihi lisamine toob kaasa suurema tagasikutsumise kahel sihtklassil kolmest. Sõltuvalt lõppeesmärgist võib vestlusteadlik modelleerimine olla kasulik asjakohaste sõnumite tuvastamisel. Loodame, et meie tulemused julgustavad teisi selles valdkonnas tegutsevaid teadlasi minema sõnumite eraldi uurimisest kaugemale diskursuspõhisema andmete kogumise ja klassifitseerimise suunas. Me avaldame oma koodi järeluuringute eesmärgil.', 'cs': 'Předchozí přístupy k NLP úlohám na online fórech pacientů byly omezeny na jednotlivé příspěvky jako jednotky, čímž zanedbávaly překračující strukturu konverzace. V tomto článku zkoumáme přínos využití konverzačního kontextu pro filtrování příspěvků relevantních pro konkrétní lékařské téma. Experimentujeme se dvěma přístupy k přidání konverzačního kontextu do modelu BERT: sekvenční vrstvou CRF a ručně navrženými funkcemi. Ačkoli žádný přístup nemůže překonat skóre F1 základní hodnoty BERT, zjišťujeme, že přidání sekvenční vrstvy zlepšuje přesnost pro všechny cílové třídy, zatímco přidání nesekvenční vrstvy s ručně navrženými funkcemi vede k vyššímu stažení pro dvě ze tří cílových tříd. Proto v závislosti na konečném cíli může být modelování konverzace orientované na identifikaci relevantních zpráv přínosem. Doufáme, že naše zjištění povzbuzují ostatní výzkumníky v této oblasti, aby se posunuli dál od studia zpráv izolovaně směrem ke sběru a klasifikaci dat založených na diskurzu. Vydáváme náš kód za účelem následného výzkumu.', 'ca': "Els enfocaments anteriors a les tasques del NLP en fòrums de pacients en línia s'han limitat a un lloc únic com a unitats, ignorant així l'estructura general de conversació. En aquest paper explorem el benefici d'explotar el context conversacional per filtrar posts pertinents a un tema mèdic específic. We experiment with two approaches to add conversational context to a BERT model: a sequential CRF layer and manually engineered features.  Encara que cap d'aquests enfocaments no pot superar la puntuació F1 de la base BERT, descobrim que afegir una capa seqüencial millora la precisió de totes les classes alvo mentre afegir una capa no seqüencial amb característiques enginyerades manualment porta a una recuperació més alta de dos de cada tres classes alvo. Així que, segons l'objectiu final, la modelació conscient de la conversa pot ser beneficiosa per identificar missatges relevants. Esperem que els nostres descobriments encorajin altres investigadors d'aquest domini a anar més enllà d'estudiar missatges aïllats cap a una col·lecció i classificació de dades basades en discurs. Vam publicar el nostre codi amb el propòsit de la recerca de seguiment.", 'fi': 'Aiemmat lähestymistavat potilasfoorumien NLP-tehtäviin ovat rajoittuneet yksittäisiin viesteihin yksikköinä, mikä on jättänyt huomiotta kokonaisvaltaisen keskustelurakenteen. Tässä artikkelissa selvitämme, miten hyödyllistä on hyödyntää keskustelukontekstia tietyn lääketieteellisen aiheen viestien suodattamiseksi. Kokeilemme kahta tapaa lisätä keskustelukontekstia BERT-malliin: peräkkäistä CRF-kerrosta ja manuaalisesti suunniteltuja ominaisuuksia. Vaikka kumpikaan lähestymistapa ei pysty ylittämään BERT-lähtötilanteen F1-pisteitä, huomaamme, että sekvenssiaalisen kerroksen lisääminen parantaa tarkkuutta kaikissa kohdeluokissa, kun taas ei-sekvenssiaalisen kerroksen lisääminen manuaalisesti suunnitelluilla ominaisuuksilla johtaa parempaan takaisinkutsuun kahdella kolmesta kohdeluokasta. Lopputavoitteesta riippuen keskustelutietoinen mallinnus voi olla hyödyllistä merkityksellisten viestien tunnistamisessa. Toivomme havaintomme kannustavan muita alan tutkijoita siirtymään viestien eristäytymisestä diskurssipohjaisempaan tiedonkeruuseen ja luokitteluun. Julkaisemme koodimme jatkotutkimusta varten.', 'jv': 'Awak sing dibutuhke NLP karo perusahaan online Nang pepul iki kita isikake ndheke nggawe barang nggawe aturan sing paling nggawe ngubah winih kanggo kalagayan pancen sing dumadhil kanggo nggawe tema sing apik. Awak dhéwé éntuk karo nganggo sampek durung kanggo nambah kontèks conversations nang model BERT politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness We yaakaar that we find find that emphasise the second R&D of this domain to remove abrupt Awakdhéwé mbukaké kode kanggo tukang tarjamahan', 'ha': "Tsarin da ya gabãta zuwa masu aikin NLP a kan jama'a-jama'a masu shagala ne, an kange su zuwa wurãre maila guda kamar ɗabi'a, don haka kuma su manta da tsarin da ake sarrafa. Daga wannan takardan, muna gane amfani da za'a yi amfani da mazaɓa na mazaɓa wa fililin posten da ke da amfani da wani madaidaici wanda aka ƙayyade. We experiment with two approaches to add conversational context to a BERT model: a sequential CRF layer and manually engineered features.  Ingawa wani hanyoyi bã ya iya samar F1-score na Baselin BERT, ko kuma munã gane cewa, a ƙara daraja guda na daban, ya improve korreki ga tsarin wa tsarin duk kure na goan, kuma amma, a ƙara wani runduna na dabam da tsarin da aka nuna da hannayen da hannunsa, yana ƙara wata matsayi ta ƙaranci wa matsayin biyu daga darafõfi uku na goa. Kamar haka, a kan ƙarami, misalin mai gaya da magana mai yiwuwa yana da amfani ga gane wa jumbe masu da amfani. Munã kwaɗayin musamman da musamman masu ƙaranci cikin wannan Domen, su motsa musamman wasu mutane da ke karya bayan karãtunsa a cikin karãtun ayukan da aka baka su ga samun data da aka faɗa da shi kaɗai. Munã sakar kodinmu dõmin yin aiki na ƙaranci.", 'sk': 'Prejšnji pristopi k nalogam NLP na spletnih forumih bolnikov so bili omejeni na posamezne objave kot enote, s čimer so zanemarili splošno strukturo pogovora. V tem prispevku raziskujemo prednosti izkoriščanja pogovornega konteksta za filtriranje objav, pomembnih za določeno medicinsko temo. Eksperimentiramo z dvema pristopoma za dodajanje pogovornega konteksta BERT modelu: zaporedno plastjo CRF in ročno izdelane funkcije. Čeprav noben pristop ne more preseči rezultata F1 osnovne vrednosti BERT, ugotavljamo, da dodajanje zaporedne plasti izboljša natančnost za vse ciljne razrede, medtem ko dodajanje nezaporedne plasti z ročno izdelanimi funkcijami vodi do večjega odpoklica dveh od treh ciljnih razredov. Zato je lahko glede na končni cilj modeliranje, ki se zaveda pogovorov, koristno za prepoznavanje ustreznih sporočil. Upamo, da naše ugotovitve spodbujajo druge raziskovalce na tem področju, da preidejo od ločenega preučevanja sporočil k bolj diskurzivnemu zbiranju in klasifikaciji podatkov. Naš kodeks objavljamo za namene nadaljnjih raziskav.', 'bo': 'Previous approaches to NLP tasks on online patient forums have been limited to single posts as units, thereby neglecting the overarching conversational structure. ཤོག་བྱང་འདིའི་ནང་གི་ང་ཚོས་ཀྱིས་སྨན་གཞུང་གི་གཏམ་གླེང་གཏམ་གླེང་སྒྲུང་གི་ཚོགས འུ་ཚོས་BERT མ་དབྱིབས་ནང་གི་གཏམ་གླེང་སྒྲུབ་དང་མཐུན་གཟུགས་རིས་གཉིས་ཀྱིས་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད། Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves precision for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher recall for two out of three classes. དེར་བརྟེན། མཐའ་མཇུག་གི་དམིགས་ཡུལ་དང་མཉམ་དུ་གཏམ་གླེང་སྒྲོམ་གྱི་རྣམ་པ་ལ་རྟོགས་པའི་འཕྲིན་དོན་རྟོགས་ནི་ཕ We hope our findings encourage other researchers in this domain to move beyond studying messages in isolation towards more discourse-based data collection and classification. ང་ཚོས་གཞི་རྗེས་ཀྱི་འཚོལ་ཞིབ་ཀྱི་དམིགས་ཡུལ་ལ་བཞག་ཡོད།', 'he': 'Previous approaches to NLP tasks on online patient forums have been limited to single posts as units, thereby neglecting the overarching conversational structure.  בעיתון הזה אנו חוקרים את היתרון של ניצלון הקשר השיחתי עבור משימות מסננות רלוונטיות לנושא רפואי מסוים. We experiment with two approaches to add conversational context to a BERT model: a sequential CRF layer and manually engineered features.  Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves precision for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher recall for two out of three target classes.  Thus, depending on the end goal, conversation-aware modelling may be beneficial for identifying relevant messages.  We hope our findings encourage other researchers in this domain to move beyond studying messages in isolation towards more discourse-based data collection and classification.  אנחנו משחררים את הקוד שלנו למטרה של מחקר מעקב.'}
{'en': 'Overview of the Fifth  Social Media Mining  for Health Applications (# SMM4H) Shared Tasks at COLING 2020 SMM 4 H ) Shared Tasks at  COLING  2020', 'es': 'Descripción general de las tareas compartidas de la quinta minería de redes sociales para aplicaciones de salud (#SMM4H) en COLING 2020', 'pt': 'Visão geral da quinta tarefa compartilhada de mineração de mídia social para aplicativos de saúde (#SMM4H) na COLING 2020', 'ar': 'نظرة عامة على خامس تعدين الوسائط الاجتماعية للتطبيقات الصحية (# SMM4H) المهام المشتركة في COLING 2020', 'fr': 'Aperçu des tâches partagées de la cinquième exploration des médias sociaux pour les applications de santé (#SMM4H) au COLING 2020', 'ja': 'COLING 2020での第5回ソーシャルメディアマイニング・フォー・ヘルス・アプリケーションズ（# SMM 4 H ）の共有タスクの概要', 'hi': 'स्वास्थ्य अनुप्रयोगों के लिए पांचवें सोशल मीडिया खनन का अवलोकन (#SMM4H) COLING 2020 में साझा कार्य', 'zh': 'COLING 2020上五康应用程序社交媒体掘(#SMM4H)共事概述', 'ru': 'Обзор пятых общих задач по майнингу в социальных сетях для приложений здравоохранения (#SMM4H) на выставке COLING 2020', 'ga': 'Forbhreathnú ar an gCúigiú Tascanna Comhroinnte um Mhianadóireacht Meán Sóisialta le haghaidh Feidhmchláir Sláinte (#SMM4H) ag COLING 2020', 'ka': 'მეხუთე სოციალური მედიახის მიღება საჯანმრთელო პროგრამებისთვის (# SMM4H) გაყოფილი დავალების COLING 2020', 'hu': 'Áttekintés az ötödik közösségi média egészségügyi alkalmazások bányászatáról (#SMM4H) megosztott feladatokról a COLING 2020-on', 'el': 'Επισκόπηση των πέμπτων κοινών εργασιών εξόρυξης κοινωνικών μέσων για εφαρμογές υγείας (#Κοινές εργασίες στο COLING 2020)', 'mk': 'Преглед на петото минирање на социјалните медиуми за здравствени апликации (#SMM4H) споделени задачи на COLING 2020', 'it': 'Panoramica della quinta attività condivisa di estrazione dei social media per applicazioni sanitarie (#SMM4H) a COLING 2020', 'kk': 'COLING 2020 жылы Бесінші социалдық медиа балау балалары (# SMM4H) ортақ тапсырмалар', 'lt': 'Penktosios socialinės žiniasklaidos kasybos sveikatos srityje apžvalga (#SMM4H) Bendros užduotys COLING 2020', 'ms': 'Paparan ringkasan Perlombongan Media Sosial Kelima untuk Aplikasi Kesehatan (#SMM4H) Tugas Berkongsi di COLING 2020', 'ml': 'ആശ്വാസത്തിനുള്ള പ്രയോഗങ്ങള്\u200dക്കുള്ള ആദ്യത്തെ സോഷ്യല്\u200d മീഡിയ മിനിങ്ങിനെ നോക്കുക (# SM4H) കോളിങ് 2020 ല്\u200d പങ്കുചേര', 'mt': 'Ħarsa ġenerali lejn il-Ħames Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (#SMM4H) Kompiti Konġunti fil-COLING 2020', 'mn': 'COLING 2020 оны 5-р нийгмийн Media Mining for Health Applications (#SMM4H)', 'ro': 'Prezentare generală a celei de-a cincea activități partajate de Mining Social Media pentru Aplicații de Sănătate (#SMM4H) la COLING 2020', 'no': 'Oversyning av den femte sosiale mediamining for helseprogramma (# SMM4H) delte oppgåva på COLING 2020', 'pl': 'Przegląd piątych zadań związanych z eksploatacją mediów społecznościowych dla aplikacji zdrowotnych (#SMM4H) na COLING 2020', 'sr': 'Pregled petog rudarstva socijalnih medija za zdravstvene aplikacije (#SMM4H) podeljenih zadataka na COLING 2020', 'so': 'Overview of the Fifth Media Mining for Health Applications (#SMM4H) Shared Shaqooyin at COLING 2020', 'sv': 'Översikt över femte sociala medier Mining for Health Applications (#SMM4H) delade uppgifter på COLING 2020', 'ta': 'உடல் பயன்பாடுகளுக்கான ஐந்தாம் சமூக ஊடகங்கள் நினைவு கண்காணி', 'ur': 'COLING 2020 میں پانچویں سوسیل میڈیا مینڈیو مینڈیو مینڈیو (سلامتی کاربریوں کے لئے) (#SMM4H) شریک کاربریوں کے بارے میں', 'si': 'ස්වාස්ථ්\u200dය වැඩසටහන් සමාජික මාධ්\u200dයාත්මක ප්\u200dරමාණය (#SMM4H) සමාජික වැඩසටහන්', 'uz': 'Name', 'vi': 'Ghi chú về bộ phận phân chia vật lý đối với sức khỏe mạnh', 'da': 'Oversigt over de femte sociale medier Mining for Health Applications (#SMM4H) delte opgaver på COLING 2020', 'de': 'Überblick über die fünften Social Media Mining for Health Applications (#SMM4H) Shared Tasks bei COLING 2020', 'nl': 'Overzicht van de vijfde Social Media Mining for Health Applications (#SMM4H) Gedeelde taken op COLING 2020', 'bg': 'Преглед на петата споделена задача за минно дело в социалните медии за здравни приложения (#СММ4Х) по време на КОЛИНГ 2020', 'hr': 'Pregled petog rudarstva društvenih medija za zdravlje aplikacije (#SMM4H) zajedničkih zadataka na COLING 2020', 'ko': '코린 2020년 제5회 건강 응용 소셜미디어 발굴(SMM4H) 공유 임무 개요', 'fa': 'Overview of the Fifth Social Mining for Health Applications (#SMM4H) Shared Tasks at COLING 2020', 'id': 'Pandangan Overview of the Fifth Social Media Mining for Health Applications (#SMM4H) Shared Tasks at COLING 2020', 'tr': 'Beşinci Sosyal Medýdançalary Saýlaw Uyglamalary üçin Kökünleýän Görnöşi (#SMM4H) COLING 2020', 'sq': 'Overview of the Fifth Social Media Mining for Health Applications (#SMM4H) Shared Tasks at COLING 2020', 'sw': 'Tazama ya Mitandao ya Taftari ya Mitandao ya Kijamii Kufuatilia Mipango ya Afya (#SMM4H) Kushirikisha kazi katika COLING 2020', 'hy': 'Overview of the Fifth Social Media Mining for Health Applications (#SMM4H) Shared Tasks at COLING 2020', 'bn': 'স্বাস্থ্য অ্যাপ্লিকেশনের জন্য পাঁচমাত্র সামাজিক মিডিয়া মিডিয়া মন্তব্যের উপর নজর রাখবে (#SM4H) ২০২০ সালে কাজ শেয়া', 'am': 'የአምስት ማኅበራዊ ሚዲያ ማስታወቂያ ለጤና ፕሮግራሞች (#SMM4H) ስራዎችን በተካፈለ COLING 2020', 'bs': 'Pregled petog rudarstva socijalnih medija za zdravlje aplikacije (#SMM4H) podeljenih zadataka na COLING 2020', 'ca': 'Overview of the Fifth Social Media Mining for Health Applications (#SMM4H) Shared Tasks at COLING 2020', 'af': 'Oorsig van die vyfde sosiale media Mining vir gesondige toepassings (# SMM4H) Gedeelde Opdragte by KOLING 2020', 'cs': 'Přehled pátého těžby sociálních médií pro zdravotní aplikace (#SMM4H) Sdílené úkoly na COLING 2020', 'et': 'Ülevaade viiendast sotsiaalmeedia kaevandamisest tervishoiualaste rakenduste jaoks (#SMM4H) jagatud ülesannetest COLING 2020 raames', 'az': 'COLING 2020', 'fi': 'Yleiskatsaus viidenteen sosiaalisen median kaivostoimintaan terveyssovelluksia varten (#SMM4H) jaettuihin tehtäviin COLING 2020 -tapahtumassa', 'jv': 'Tarjamahan kanggo Kelombak Media Media Minggu kanggo Aplikasi Saasah (#SMM4H) Ngawe Tarjamahan sing gak Bebas nang COMLING 2020', 'ha': '@ action: button', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་འཇུག་སྣོད་ཀྱི་ཞབས་ཞུ་བའི་འཇུག་སྣོད་ཀྱི་མཐའ་བསྡུར་ནས་ཀློག་སྟངས། #SMM4H COLING 2020', 'sk': 'Pregled petih skupnih nalog rudarjenja v družbenih omrežjih za zdravstvene aplikacije (#SMM4H) na COLING 2020', 'he': 'תצוגה כללית של מחקר החמישי של מדיה חברתית לתוכניות בריאות (#SMM4H) משימות משותפות ב-COLING 2020'}
{'en': 'The vast amount of data on  social media  presents significant opportunities and challenges for utilizing  it  as a resource for  health informatics . The fifth iteration of the Social Media Mining for Health Applications (# SMM4H) shared tasks sought to advance the use of Twitter data (tweets) for  pharmacovigilance ,  toxicovigilance , and epidemiology of birth defects. In addition to re-runs of three tasks, # SMM4H 2020 included new tasks for detecting adverse effects of medications in French and Russian tweets, characterizing chatter related to prescription medication abuse, and detecting self reports of birth defect pregnancy outcomes. The five tasks required methods for  binary classification , multi-class classification, and named entity recognition (NER). With 29 teams and a total of 130 system submissions, participation in the # SMM4H shared tasks continues to grow.', 'ar': 'يقدم الكم الهائل من البيانات على وسائل التواصل الاجتماعي فرصًا وتحديات كبيرة لاستخدامها كمصدر للمعلوماتية الصحية. سعى الإصدار الخامس من مهام التنقيب عن وسائل التواصل الاجتماعي للتطبيقات الصحية (# SMM4H) إلى تعزيز استخدام بيانات Twitter (التغريدات) للتيقظ الدوائي ، واليقظة السمية ، ووبائيات العيوب الخلقية. بالإضافة إلى إعادة تشغيل ثلاث مهام ، تضمن # SMM4H 2020 مهامًا جديدة للكشف عن الآثار الضارة للأدوية في التغريدات الفرنسية والروسية ، وتوصيف الأحاديث المتعلقة بتعاطي الأدوية الموصوفة ، واكتشاف التقارير الذاتية لنتائج الحمل بعيوب خلقية. تتطلب المهام الخمس طرقًا للتصنيف الثنائي ، والتصنيف متعدد الفئات ، والتعرف على الكيانات المسماة (NER). مع وجود 29 فريقًا وإجمالي 130 عملية إرسال للنظام ، تستمر المشاركة في المهام المشتركة # SMM4H في النمو.', 'es': 'La enorme cantidad de datos en las redes sociales presenta importantes oportunidades y desafíos para utilizarlos como un recurso para la informática de la salud. La quinta edición de Social Media Mining for Health Applications (#SMM4H) compartió tareas que buscaban avanzar en el uso de los datos de Twitter (tuits) para la farmacovigilancia, la toxicovigilancia y la epidemiología de los defectos de nacimiento. Además de las repeticiones de tres tareas, #SMM4H 2020 incluyó nuevas tareas para detectar los efectos adversos de los medicamentos en tuits franceses y rusos, caracterizar las conversaciones relacionadas con el abuso de medicamentos recetados y detectar autoinformes de resultados de embarazos con defectos de nacimiento. Las cinco tareas requerían métodos de clasificación binaria, clasificación de varias clases y reconocimiento de entidades con nombre (NER). Con 29 equipos y un total de 130 envíos al sistema, la participación en las tareas compartidas de #SMM4H sigue creciendo.', 'fr': "La grande quantité de données sur les médias sociaux présente des opportunités et des défis importants pour l'utilisation de ces données en tant que ressource pour l'informatique de la santé. La cinquième itération du Social Media Mining for Health Applications (#SMM4H) partageait des tâches visant à faire progresser l'utilisation des données Twitter (tweets) pour la pharmacovigilance, la toxicovigilance et l'épidémiologie des malformations congénitales. En plus des réexécutions de trois tâches, #SMM4H 2020 incluait de nouvelles tâches pour détecter les effets indésirables des médicaments dans les tweets en français et en russe, caractériser les conversations liées à l'abus de médicaments sur ordonnance et détecter les auto-déclarations des issues de grossesse malformations congénitales. Les cinq tâches nécessitaient des méthodes de classification binaire, de classification multiclasse et de reconnaissance d'entités nommées (NER). Avec 29 équipes et un total de 130 soumissions système, la participation aux tâches partagées #SMM4H continue de croître.", 'pt': 'A grande quantidade de dados nas mídias sociais apresenta oportunidades e desafios significativos para utilizá-los como um recurso para informática em saúde. A quinta iteração das tarefas compartilhadas de mineração de mídia social para aplicativos de saúde (#SMM4H) buscou avançar no uso de dados do Twitter (tweets) para farmacovigilância, toxicovigilância e epidemiologia de defeitos congênitos. Além de reexecuções de três tarefas, o #SMM4H 2020 incluiu novas tarefas para detectar efeitos adversos de medicamentos em tweets em francês e russo, caracterizando conversas relacionadas ao abuso de medicamentos prescritos e detectando auto-relatos de resultados de gravidez de defeitos congênitos. As cinco tarefas exigiam métodos para classificação binária, classificação multiclasse e reconhecimento de entidade nomeada (NER). Com 29 equipes e um total de 130 submissões do sistema, a participação nas tarefas compartilhadas #SMM4H continua crescendo.', 'ja': 'ソーシャルメディア上の膨大なデータは、健康情報学のリソースとして利用するための大きな機会と課題を提示しています。ソーシャルメディア・マイニング・フォー・ヘルス・アプリケーションズ（# SMM 4 H ）の5回目の反復は、薬害、毒性警戒、および出生欠陥の疫学のためのTwitterデータ（ツイート）の使用を促進するために求められたタスクを共有しました。3つのタスクの再実行に加えて、# SMM 4 H 2020には、フランス語とロシア語のツイートで薬の有害作用を検出するための新しいタスク、処方薬の乱用に関連するChatterの特徴付け、および出生欠陥妊娠転帰の自己報告の検出が含まれていました。必要な5つのタスクは、バイナリ分類、マルチクラス分類、および名前付きエンティティ認識（ NER ）のためのメソッドです。29チーム、合計130システムの提出により、# SMM 4 H共有タスクへの参加は増え続けています。', 'zh': '社交媒体上大据以为健信息学资给大机挑战。 宜社交媒体掘(#SMM4H)共享者五迭代旨进Twitter数(推文)戒于药,戒生缺流行病学之用。 除重行三务外,2020#SMM4H兼检测法语、俄语推文中药物之不良反应,表征与处方药滥用喋喋及检测生缺陷者自言新事。 此五者,二元之类,多类之类,名实之 (NER) 也。 有29团队与凡130统,与#SMM4H共事而长之。', 'hi': 'सोशल मीडिया पर डेटा की विशाल मात्रा स्वास्थ्य सूचना विज्ञान के लिए एक संसाधन के रूप में इसका उपयोग करने के लिए महत्वपूर्ण अवसर और चुनौतियां प्रस्तुत करती है। सोशल मीडिया माइनिंग फॉर हेल्थ एप्लीकेशन्स (#SMM4H) के पांचवें पुनरावृत्ति ने साझा किए गए कार्यों ने फार्माकोविजिलेंस, टॉक्सिकोविजिलेंस और जन्म दोषों के महामारी विज्ञान के लिए ट्विटर डेटा (ट्वीट्स) के उपयोग को आगे बढ़ाने की मांग की। तीन कार्यों के पुन: रन के अलावा, #SMM4H 2020 में फ्रांसीसी और रूसी ट्वीट्स में दवाओं के प्रतिकूल प्रभावों का पता लगाने के लिए नए कार्य शामिल थे, जो पर्चे दवा के दुरुपयोग से संबंधित बकवास की विशेषता है, और जन्म दोष गर्भावस्था के परिणामों की आत्म रिपोर्ट का पता लगाने के लिए। पांच कार्यों को बाइनरी वर्गीकरण, बहु-वर्ग वर्गीकरण, और नामित इकाई मान्यता (एनईआर) के लिए विधियों की आवश्यकता होती है। 29 टीमों और कुल 130 सिस्टम सबमिशन के साथ, साझा कार्यों #SMM4H में भागीदारी बढ़ रही है।', 'ru': 'Огромный объем данных в социальных сетях создает значительные возможности и проблемы для их использования в качестве ресурса для медицинской информатики. Пятая итерация социальных сетей Mining for Health Applications (#SMM4H) была направлена на продвижение использования данных Twitter (твитов) для фармаконадзора, токсиконадзора и эпидемиологии врожденных дефектов. В дополнение к повторным запускам трех задач, #SMM4H 2020 включил новые задачи по обнаружению нежелательных эффектов лекарств во французских и российских твитах, характеризующих болтовню, связанную со злоупотреблением рецептурными лекарственными средствами, и обнаружению самостоятельных сообщений о исходах беременности с врожденными дефектами. Пять задач требовали методов двоичной классификации, многоклассовой классификации и распознавания именованных сущностей (NER). С 29 командами и в общей сложности 130 системных заявок, участие в совместных задачах #SMM4H продолжает расти.', 'ga': 'Cruthaíonn an t-uafás sonraí ar na meáin shóisialta deiseanna agus dúshláin shuntasacha chun é a úsáid mar acmhainn faisnéise sláinte. Leis an gcúigiú atriall de na Meáin Shóisialta Mianadóireacht le haghaidh Feidhmchláir Sláinte (#SMM4H) rinneadh iarracht úsáid sonraí Twitter (tweets) a chur chun cinn le haghaidh faireachas cógas, tocsain-aireachas, agus eipidéimeolaíocht lochtanna breithe. I dteannta le trí thasc a athreáchtáil, chuimsigh #SMM4H 2020 tascanna nua maidir le héifeachtaí díobhálacha cógas a bhrath i dtvuíteanna na Fraince agus na Rúise, ag tréithriú comhráite a bhaineann le mí-úsáid cógais ar oideas, agus féintuairiscí ar thorthaí toirchis lochtanna breithe a bhrath. Bhí modhanna ag teastáil le haghaidh aicmiú dénártha, aicmiú ilaicme, agus aithint aonáin ainmnithe (NER) leis na cúig thasc. Le 29 foireann agus iomlán de 130 aighneacht córais, tá rannpháirtíocht i dtascanna comhroinnte #SMM4H ag fás i gcónaí.', 'ka': 'სოციალური მედიაში დიდი მონაცემები უფრო დიდი მონაცემები იყოს მნიშვნელოვანი შესაძლებლობა და განცემებები, რომლებიც მისი გამოყენებაში რესურსი სისტემი სოციალური მედიახის მისაღების მეხუთე მედიახური პროგრამებისთვის (# SMM4H) საზოგადოებული დავალებების პროგრამის გამოყენება Twitter მონაცემების (tweets) გამოყენებას, ტაპმაკოვიგლიანციისთვის, ტოქსიკოვიგლიან სამი სამუშაო დამუშაობის დამატებით, #SMM4H 2020 ახალი სამუშაო დამუშაობა ფრანუს და პროსური tweets-ში მედიცირების შეცდომა ეფექტურების შეცდომა ეფექტურების შეცდომა, რომელიც პრესპრიპტის მედიცირების ბინერი კლასიფიკაციის, მრავალი კლასიფიკაციის, და სახელი ინტერტის განაცნობისთვის (NER) ხუთი დავაჭირდება. 29 ჯგუფი და 130 სისტემის მისამართებით, სხვადასხვა საერთო დასამართლად #SMM4H დასამართლად იქნება.', 'hu': 'A közösségi médiában található hatalmas adatmennyiség jelentős lehetőségeket és kihívásokat jelent az egészségügyi informatikai forrásként való felhasználására. A Közösségi Média Egészségügyi Alkalmazások Bányászata (#SMM4H) ötödik iterációjának célja, hogy elősegítse a Twitter adatok (tweetek) felhasználását farmakovigilancia, toxikológiai és születési rendellenességek epidemiológiája céljából. A három feladat ismételt futtatása mellett a #SMM4H 2020 új feladatokat is tartalmazott a gyógyszerek káros hatásainak felderítésére francia és orosz tweetekben, a vényköteles gyógyszerrel való visszaéléssel kapcsolatos beszélgetések jellemzésére, valamint a születési rendellenességek terhességi kimeneteléről szóló önjelentések felderítésére. Az öt feladat a bináris osztályozáshoz, a többosztályos osztályozáshoz és a nevezett entitások felismeréséhez (NER) szükséges módszereket írta elő. 29 csapattal és összesen 130 rendszer beadvánnyal a #SMM4H megosztott feladatokban való részvétel folyamatosan növekszik.', 'el': 'Ο τεράστιος όγκος των δεδομένων στα μέσα κοινωνικής δικτύωσης παρουσιάζει σημαντικές ευκαιρίες και προκλήσεις για τη χρήση τους ως πόρου για την πληροφορική υγείας. Η πέμπτη επανάληψη των κοινών καθηκόντων της Εξόρυξης Κοινωνικών Μέσων για Εφαρμογές Υγείας (#SMM4H) αποσκοπούσε στην προώθηση της χρήσης δεδομένων του Twitter (tweets) για τη φαρμακοεπαγρύπνηση, την τοξικοεπαγρύπνηση και την επιδημιολογία των γεννητικών ελαττωμάτων. Εκτός από τις επαναλήψεις τριών εργασιών, το #SMM4H 2020 περιελάμβανε νέες εργασίες για την ανίχνευση δυσμενών επιπτώσεων των φαρμάκων σε γαλλικά και ρωσικά tweets, τον χαρακτηρισμό των συνομιλιών σχετικά με την κατάχρηση συνταγογραφούμενων φαρμάκων και την ανίχνευση των αυτοαναφορών σχετικά με τα αποτελέσματα της εγκυμοσύνης λόγω γενετήσιου ελαττώματος. Οι πέντε εργασίες απαιτούσαν μεθόδους για τη δυαδική ταξινόμηση, την ταξινόμηση πολλαπλών κατηγοριών και την αναγνώριση ονομαστικών οντοτήτων. Με 29 ομάδες και συνολικά 130 υποβολές συστήματος, η συμμετοχή στις κοινές εργασίες συνεχίζει να αυξάνεται.', 'it': "La grande quantità di dati sui social media presenta opportunità e sfide significative per utilizzarli come risorsa per l'informatica sanitaria. La quinta iterazione del Social Media Mining for Health Applications (#SMM4H) ha condiviso compiti volti a promuovere l'uso dei dati di Twitter (tweet) per farmacovigilanza, tossicovigilanza ed epidemiologia dei difetti congeniti. Oltre alle ripetizioni di tre compiti, #SMM4H 2020 ha incluso nuovi compiti per rilevare gli effetti avversi dei farmaci nei tweet francesi e russi, caratterizzare le chiacchiere relative all'abuso di farmaci da prescrizione e rilevare auto-segnalazioni di esiti di gravidanza con difetti congeniti. I cinque compiti richiedevano metodi per la classificazione binaria, la classificazione multi-classe e il riconoscimento delle entità denominate (NER). Con 29 team e un totale di 130 richieste di sistema, la partecipazione alle attività condivise #SMM4H continua a crescere.", 'lt': 'Didelis socialinių žiniasklaidos duomenų kiekis suteikia dideles galimybes ir uždavinius jį naudoti kaip sveikatos informacinės įrangos išteklių. Penktajame Social Media Mining for Health Applications kartojime (#SMM4H) buvo siekiama skatinti Twitter duomenų (tweetų) naudojimą farmakologiniam budrumui, toksikologiniam budrumui ir gimimo defektų epidemiologijai. Be trijų užduočių atnaujinimo, #SMM4H 2020 buvo įtrauktos naujos užduotys, skirtos vaistų nepageidaujamo poveikio nustatymui prancūzų ir rusų tweetuose, apibūdinant pokalbį, susijusį su piktnaudžiavimu receptiniais vaistais, ir pačių pranešimų apie gimdymo defektų nėštumo rezultatus nustatymui. Penkioms užduotims reikėjo dviejų rūšių klasifikavimo, daugiaklassifikavimo ir vardinio subjekto pripažinimo (NER) metodų. Dalyvaujant #SMM4H bendrose užduotyse ir toliau didėja 29 komandose ir iš viso 130 sistemų.', 'mk': 'Големата количина податоци за социјалните медиуми претставуваат значителни можности и предизвици за користење на нив како ресурс за здравствена информатика. Петтата итерација на Социјалните медиуми за здравствени апликации (#SMM4H) ги сподели задачите со цел да се унапреди употребата на податоците од Твитер (твитови) за фармацевигланција, токсиковизиланција и епидемиологија на раѓачките дефекти. Покрај повторното спроведување на три задачи, #SMM4H 2020 вклучуваше нови задачи за откривање на негативни ефекти на лековите на француските и руските твитови, карактеризирање на разговорот поврзан со злоупотребата на лековите со рецепт и откривање на самоизвештаи за резултатите Петте задачи бараа методи за бинарна класификација, мултикласификација и препознавање на именуваниот ентитет (NER). Со 29 тимови и вкупно 130 системски поднесувања, учеството во заедничките задачи #SMM4H продолжува да расте.', 'kk': 'Қолымшалық медиақтардың көп мәліметі оны саулық мәліметтерінің ресурсы ретінде пайдалану үшін маңызды мүмкіндіктер мен мәліметтерді көрсетеді. Социалдық медиа бағалау бағдарламаларының бесінші қайталануы (# SMM4H) бөлікті тапсырмалар Twitter деректерін (tweets) фармаковигализациялансын, токсикавигациялансын және төлімінің эпидемиологиясын қолдану үшін қолданылады. Үш тапсырманың қайта жұмысына қосымша, #SMM4H 2020 деген жаңа тапсырмаларды француз және руссиялық tweetтерінде қарсы эффекттерді анықтау үшін, рецептивтің медицина жетістіктеріне қатынау сәйкестігін таңдау және өзіңіздің жаң Бинарлық классификациясы, көп класс классификациясы және аталған нысанды анықтау үшін бес тапсырмалар керек. 29 топ және 130 жүйелік жіберілген жұмыс ішінде #SMM4H ортақ тапсырмаларында қатысу жалғастырылады.', 'ms': 'Jumlah besar data pada media sosial menghasilkan peluang dan cabaran yang penting untuk menggunakannya sebagai sumber untuk informasi kesehatan. Ulangan ke-lima Perlombongan Media Sosial untuk Aplikasi Kesehatan (#SMM4H) berkongsi tugas untuk melanjutkan penggunaan data Twitter (tweet) untuk farmakovigilans, toksikovigilans, dan epidemiologi cacat lahir. Selain melaksanakan semula tiga tugas, #SMM4H 2020 termasuk tugas baru untuk mengesan kesan negatif dari ubat-ubatan dalam tweet Perancis dan Rusia, menandakan perbualan yang berkaitan dengan penyalahgunaan ubat resep, dan mengesan laporan diri mengenai hasil kehamilan cacat lahir. Lima tugas memerlukan kaedah untuk kelasukan binari, kelasukan berbilang-kelas, dan pengenalan entiti bernama (NER). Dengan 29 pasukan dan total 130 penghantaran sistem, pesertaan dalam tugas berkongsi #SMM4H terus berkembang.', 'mt': 'L-ammont kbir ta’ dejta dwar il-midja soċjali jippreżenta opportunitajiet u sfidi sinifikanti għall-użu tagħha bħala riżorsa għall-informatika tas-saħħa. Il-ħames iterazzjoni tal-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (#SMM4H) ippruvat li jsir progress fl-użu tad-dejta fuq Twitter (tweets) għall-farmakoviġilanza, it-tossikoviġilanza, u l-epidemjoloġija tad-difetti tat-twelid. Minbarra t-twettiq mill-ġdid ta’ tliet kompiti, #SMM4H 2020 inkluda kompiti ġodda biex jinstabu effetti avversi ta’ mediċini fit-tweets Franċiżi u Russi, li jikkaratterizzaw it-taħlit relatat mal-abbuż tal-mediċina bi preskrizzjoni, u li jinstabu rapporti awtonomi ta’ riżultati ta’ difetti fit-tqala. Il-ħames kompiti kienu jeħtieġu metodi għall-klassifikazzjoni binarja, il-klassifikazzjoni multiklassi, u r-rikonoxximent tal-entità msejħa (NER). B’29 tim u total ta’ 130 sottomissjoni tas-sistema, il-parteċipazzjoni fil-kompiti kondiviżi #SMM4H tkompli tikber.', 'no': 'Den store mengda data på sosiale mediar gjev viktige muligheter og utfordringar for å bruka det som ressurs for helseinformatikk. Den femte gjentakinga av den delte oppgåva i sosiale mediene for helseprogramma (# SMM4H) søkte å forbedra bruken av Twitter-data (tweets) for pharmakovigilans, toksikokivigilans og epidemiologikk av fødselsdefektar. I tillegg til å gjenoppretta tre oppgåver, inkluderte nye oppgåver for oppdaging av negativ effektar av medikamenter i fransk og russisk twett, karakterisering av prateverdiar relatert til bruk av preskriptasjonsmedikamenter, og oppdaging av selvrapporter om fødselsdefektet av grønnslag. Dei fem oppgåvene krevst metodane for binærklassifikasjon, multiklassesklassifikasjon og gjenkjenning av namnet entitet (NER). Med 29 grupper og totalt 130 systemoppføringar, vil deltaka i delte oppgåver #SMM4H fortsette å auke.', 'ml': 'സോഷ്യല്\u200d മീഡിയിലെ വിവരങ്ങളുടെ വിപാരമായ വിവരങ്ങള്\u200d സാമൂഹിക വിവരങ്ങള്\u200dക്ക് പ്രധാനപ്പെട്ട അവസരങ്ങളും വിലാസങ്ങളും കൊടുക സോഷ്യല്\u200d മീഡിയയുടെ ആശ്വാസപ്രയോഗങ്ങള്\u200dക്കുള്ള മിനിങ്ങിന്\u200dറെ (#SM4H) അഞ്ചാമത്തേത് ജോലികള്\u200d പങ്കുചേര്\u200dത്തിരിക്കുന്നു. ട്രൂട്ടര്\u200d ഡേറ്റാകള്\u200d ഉപയോഗിക്കാന മൂന്നു ജോലികളുടെ വീണ്ടും പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനു ശേഷം #SM4H 2020 ഫ്രെഞ്ചിലും റഷ്യന്\u200d ടൂട്ടുകളിലും മരുന്നുകളുടെ വിരോധപ്രഭാവങ്ങള്\u200d കണ്ടുപിടിക്കാന്\u200d പുതിയ ജോലി അഞ്ച് ജോലികള്\u200dക്ക് ആവശ്യമുള്ള ബൈനറി ക്ലാസ്ഫിക്ഷന്\u200d, പല-ക്ലാസ് ക്ലാസ്സിഫിക്ഷന്\u200d, പേരിട്ട വസ്തുക്കള്\u200d തിരിച 29 ടീമും 130 സിസ്റ്റത്തിന്റെ മൊത്തം കീഴടങ്ങളും കൊണ്ട് #SM4H പങ്കുചേര്\u200dത്ത ജോലികളില്\u200d പങ്കെടുക്കുന്നത് വളരുന്നു.', 'pl': 'Ogromna ilość danych w mediach społecznościowych stwarza istotne możliwości i wyzwania dla wykorzystania ich jako źródła informatyki zdrowotnej. Piąta iteracja Social Media Mining for Health Applications (#SMM4H) miała na celu rozwój wykorzystania danych Twittera (tweetów) w celu nadzoru nad bezpieczeństwem farmakoterapii, nad nadzorem toksycznym i epidemiologią wad wrodzonych. Oprócz ponownych uruchomień trzech zadań #SMM4H 2020 obejmowało nowe zadania dotyczące wykrywania niepożądanych skutków leków w francuskich i rosyjskich tweetach, charakteryzowania rozmów związanych z nadużywaniem leków na receptę oraz wykrywania samodzielnych zgłoszeń o wynikach ciąży wrodzonej. Pięć zadań wymagało metod klasyfikacji binarnej, klasyfikacji wieloklasowej i rozpoznawania nazwanych jednostek (NER). Dzięki 29 zespołom i łącznie 130 zgłoszeniom systemowym udział w wspólnych zadaniach #SMM4H wciąż rośnie.', 'mn': 'Нийгмийн хэвлэлийн мэдээллийн маш олон мэдээлэл үүнийг эрүүл мэндийн мэдээллийн боломж болон сорилтуудыг ашиглах боломжтой боломж олгодог. Нийгмийн Media Mining for Health Applications (#SMM4H)-ын таван дахин давталт нь Twitter өгөгдлийн (tweets) хэрэглээ эмчилгээ, toxicovigilance, төрсөн алдагдлын эпидемиологи ашиглахыг хичээсэн. Гурван ажлын дахин дахин ажиллах нэмэлт нь, #SMM4H 2020 нь Француз болон Оросын tweets-д эмчилгээний эсрэг нөлөөг олж, эмчилгээний эмчилгээний зөрчилдөөнтэй яриаг харуулж, төрсөн халдварын үр дүнг олж мэдэх шинэ ажиллагаа байсан. Хоёр дахь даалгавар нь хоёр дахь хэлбэрийн, олон хэлбэрийн хэлбэрийн, нэрлэгдсэн бүтэц таних арга хэрэгтэй. 29 баг, 130 системийн сургалтын нийтлэл нь #SMM4H хуваалцах ажиллагаанд оролцож байна.', 'ro': 'Cantitatea vastă de date de pe rețelele sociale prezintă oportunități și provocări semnificative pentru utilizarea acestora ca resursă pentru informatica medicală. A cincea iterație a Social Media Mining for Health Applications (#SMM4H) a împărtășit sarcini menite să avanseze utilizarea datelor Twitter (tweet-uri) pentru farmacovigilență, toxicovidență și epidemiologie a defectelor congenitale. În plus față de reluarea a trei sarcini, #SMM4H 2020 a inclus noi sarcini pentru detectarea efectelor adverse ale medicamentelor în tweeturile franceze și rusești, caracterizarea palavragealei legate de abuzul de medicamente pe bază de prescripție medicală și detectarea auto-rapoartelor privind rezultatele sarcinii defectelor nașterii. Cele cinci sarcini necesitau metode de clasificare binară, clasificare multi-clasă și recunoaștere a entităților denumite (NER). Cu 29 de echipe și un total de 130 de trimiteri de sistem, participarea la sarcinile partajate #SMM4H continuă să crească.', 'sr': 'Velika količina podataka o društvenim medijima predstavlja značajne prilike i izazove za korištenje njega kao resursa za zdravstvenu informatiku. Peti ponovni nastup socijalnih medija za rudarstvo zdravstvenih aplikacija (#SMM4H) pokušao je unaprijediti korištenje Twitter podataka (tweets) za farmakovigilanciju, toksikovigilnost i epidemiologiju rođenih defekata. Pored ponovnog obavljanja tri zadatka, #SMM4H 2020 uključivalo je nove zadatke za otkrivanje nevoljnih učinka lijekova na francuskim i ruskim tweetima, karakteriziranje razgovora povezanog sa zlostavljanjem lijekova recepta i otkrivanje samih izveštaja o rezultatima trudnoće. Pet zadataka zahteva metode za binarnu klasifikaciju, multiklasnu klasifikaciju i priznanje imena entiteta (NER). Sa 29 timova i ukupno 130 podataka sistema, učestvovanje u podijeljenim zadacima #SMM4H nastavlja da raste.', 'si': 'සාමාජික මාධ්\u200dයමයේ ගොඩක් තොරතුරු සාමාජික අවස්ථාවක් සහ අවස්ථාවක් තියෙනවා ඒක ආරක්ෂිත තොරතුරු විස සාමාජික මාධ්\u200dය මිනිස්ත්\u200dරව්\u200dය ප්\u200dරවේශනය සඳහා සාමාජික මිනිස්ත්\u200dරව්\u200dය ප්\u200dරවේශනය (#SMM4H) සම්බන්ධ ව්\u200dයාප්ත ව්\u200dයාප්ති වෙනුවෙන් Twitter දත්ත (tweets)  In plus to re-runs of three Jobs, #SMM4H 2020included new Jobs for Detection adverse Effects of Medics in French and Russian tweets, characharacharacharacharacharacharacted chatter linked to Prescription Mediation Abuse, and Detection Self Rapporters of Born defict utergy Outends. බායිනාරි වර්ගය, වර්ගයක් වර්ගය, නම් නම් වර්ගය අඳුරණය (NER) වෙනුවෙන් විධානය පහය අවශ්\u200dය විධානය පහ කණ්ඩායම් 29ක් සහ පද්ධතිය පිළිගන්න පුළුවන් 130 ක් තියෙනවා, #SMM4H කොටස් කාර්යාලයේ සම්බන්ධ වැඩ කරන්න පටන', 'so': "Macluumaad badan oo ku saabsan shabakada bulshada waxaad ka heleysaa fursado aad u weyn iyo dhibaatooyin ku saabsan isticmaalka macluumaadka caafimaadka. Shaqada shanaad ee daryeelka caafimaadka ee macluumaadka bulshada (SMM4H) shaqooyinka la qaybiyey waxay doonayeen inuu horumariyo isticmaalka macluumaadka Twitterka (twitter) si ay u baaraandegaan farmashiyaha, toksisovigilanka iyo cudurada dhalmada. #SMM4H 2020 waxaa ka dheer shaqooyin cusub oo ku qoran si ay u ogaato faa'iidooyinka caafimaadka ee afraansiga iyo Ruushka, oo ay ku qoraan sheeko la xiriira isticmaalka daawooyinka, iyo in lagu ogaado wargelinta suurtooyinka uurka. Shankii shaqada waxaa loo baahan yahay qaabab loo kala soocayyo labaad, fasalka kala duduwan, iyo aqoonsiga entity (NER). Waxyaabaha la qaybsaday #SMM4H waxaa sii socda inay kordhaan 29 koox iyo koox koox ka mid ah 130 nidaamka.", 'sv': 'Den stora mängden data på sociala medier innebär betydande möjligheter och utmaningar för att använda den som en resurs för hälsoinformatik. Den femte iterationen av Social Media Mining for Health Applications (#SMM4H) delade uppgifter syftade till att främja användningen av Twitter-data (tweets) för farmakovigilans, toxikovalutans och epidemiologi av födelseskador. Förutom att upprepa tre uppgifter inkluderade #SMM4H 2020 nya uppgifter för att upptäcka biverkningar av mediciner i franska och ryska tweets, karaktärisera prat om receptbelagd medicinering missbruk och upptäcka självrapporter om graviditetsutfall med fosterskador. De fem uppgifterna krävde metoder för binär klassificering, flerklassklassificering och namngiven entitetsigenkänning (NER). Med 29 team och totalt 130 systeminlämningar fortsätter deltagandet i de delade uppgifterna #SMM4H att växa.', 'ta': 'சமூக ஊடகங்களின் பெரிய தகவல்கள் முக்கியமான வாய்ப்புகளையும் சவால்களையும் அதை பயன்படுத்துவதற்கான மருத்துவ தகவல்களுக்கு மூ தொழில்நுட்ப பயன்பாடுகளுக்கான சமூக ஊடகங்களின் ஐந்தாவது நிறுவனம் (# SMM4H) பங்கிடப்பட்ட பணிகளை முன்னேற்றுவதற்காக தேவைப்பட்டுள்ளது மருத்துவர்க்காவல், புதிர்ந மூன்று பணிகளின் மீண்டும் இயக்குவதற்குக் கூடுதலாக, #SM4H 2020 பிரெஞ்சு மற்றும் ரஷ்ஷியன் தொடர்ந்து மருத்துவ வ விளைவுகளை கண்டறிவதற்கான புதிய பணிகள் சேர்ந்தது, மருத்துவ ம இரும வகுப்பு, பல வகுப்பு வகுப்பு, மற்றும் பெயரிடப்பட்ட பொருள் அடையாளம் (NER) ஐந்து பணிகளுக்கு தேவையான முறைகள். 29 குழுக்கள் மற்றும் மொத்தமான 130 அமைப்பு ஒப்புக்கொள்ளும் கொண்டு #SM4H பகிர்ந்த பணிகளில் பகிர்ந்து கொள்வது தொடர்', 'ur': 'سوسیل میڈیا کے معاملہ میں بہت بڑے ڈیٹے اسے استعمال کرنے کے لئے بہت اہم فرصت اور چالیں پیش کرتے ہیں۔ سوسیل میڈیا مینڈیو مینڈیونگ کی پانچویں تکرار سلامتی کاربریوں کے لئے (SMM4H) مشترک کاربریوں کے لئے توئیٹ ڈیٹ (ٹویٹ) کے استعمال کی پیشرفت کی تلاش کی تھی۔ تین کاموں کے دوبارہ چلنے کے علاوہ، #SMM4H 2020 نے نو کام شامل کیے کہ فرنس اور روسی ٹیوٹوں میں داروغ کے مخالف اثرات کا مشاہدہ کریں، سرنوشتی داروغ کے مطابق سرنوشتی کی بات کریں، اور زائدگی کے مطابق اثرات حاملہ ہونے کے لئے خود راپوروں کو مشاہدہ کر پانچ ٹاکسٹ کے لئے دوئناری کلاسیفوں کے لئے مطالب طریقے ہیں، بہت سے کلاس کلاسیفوں کے لئے، اور نام داری شناسایی (NER) کے لئے۔ 29 ٹیموں کے ساتھ اور 130 سیسٹم تحویل کے ساتھ ملتے ہیں #SMM4H شریک کاموں میں مشارکت ادامه رہتی ہے.', 'uz': "Ushbu jamiyat media haqida ko'p maʼlumotlar juda muhim imkoniyatlar va bu tibbiy maʼlumotni qo'llash uchun murakkab qiladi. Name Uch vazifalarni qaytadan ishga tushirishdan ortiq, #SMM4H 2020, Fransuzcha va Ruscha Twitterdan shifokorlarning bizar effektlarini aniqlash uchun yangi vazifalarni kiritilgan, o'z narsalarni saqlash muvaffaqiyatlarini aniqlash va o'zimni foydalanish muvaffaqiyatlarini aniqlash uchun yangi vazifalar bor. @ info: whatsthis 29 guruhi va 130 tizimning umuman ishlatuvchisi bilan, #SMM4H bilan birlashtirilgan vazifalarga qismi davom etadi.", 'vi': 'Một lượng lớn dữ liệu về các phương tiện truyền thông xã hội mang lại cơ hội và thử thách đáng kể để sử dụng nó như một nguồn tin về sức khỏe. Lần lặp đi thứ năm của Bộ Tư liệu vật lý y tế xã hội (\\ 35; SMM4H) đã chia sẻ các nhiệm vụ nhằm phát triển khả năng sử dụng dữ liệu Twitter (tweet) cho việc tăng cường thuốc kích thích, nhiễm độc và dịch bệnh bẩm sinh. Ngoài việc quản lý lại ba nhiệm vụ, \\ 35; SMM4H 2020 bao gồm những nhiệm vụ mới để phát hiện tác động tiêu cực của thuốc trên Twitter của Pháp và Nga, mô tả các cuộc nói chuyện liên quan đến lạm dụng thuốc men theo toa, và phát hiện báo cáo về khuyết tật thai nghén. Năm nhiệm vụ cần phải có phương pháp phân loại nhị phân, phân hạng đa, và nhận dạng thực thể tên (NER). Với phòng phòng 29 và tổng hợp các hệ thống 130, sự tham gia vào các công việc chia sẻ đang tiếp tục phát triển.', 'nl': 'De enorme hoeveelheid gegevens op sociale media biedt belangrijke kansen en uitdagingen om het te gebruiken als bron voor gezondheidsinformatica. De vijfde iteratie van de Social Media Mining for Health Applications (#SMM4H) gedeelde taken probeerde het gebruik van Twitter-gegevens (tweets) voor farmacovigilantie, toxicovigilantie en epidemiologie van geboorteafwijkingen te bevorderen. Naast de herhaling van drie taken omvat #SMM4H 2020 nieuwe taken voor het opsporen van bijwerkingen van medicijnen in Franse en Russische tweets, het karakteriseren van chatter gerelateerd aan misbruik van voorgeschreven medicijnen en het detecteren van zelfmeldingen van zwangerschapsuitslagen met geboorteafwijkingen. De vijf taken vereiste methoden voor binaire classificatie, multi-class classificatie en naamloze entiteitsherkenning (NER). Met 29-teams en een totaal van 130-systeeminzendingen blijft de deelname aan de #SMM4H gedeelde taken toenemen.', 'da': 'Den store mængde data på sociale medier giver betydelige muligheder og udfordringer for at udnytte det som en ressource til sundhedsinformatik. Den femte iteration af Social Media Mining for Health Applications (#SMM4H) delte opgaver søgte at fremme brugen af Twitter-data (tweets) til lægemiddelovervågning, toksikoovervågning og epidemiologi af fødselsdefekter. Ud over genkørsler af tre opgaver inkluderede #SMM4H 2020 nye opgaver til at detektere bivirkninger af medicin i franske og russiske tweets, karakterisere snak relateret til receptpligtig medicin misbrug og detektere selv rapporter om graviditetsresultater af fødselsdefekter. De fem opgaver krævede metoder til binær klassificering, flerklasse klassificering og navngivet enhedsgenkendelse (NER). Med 29 teams og i alt 130 systemindsendelser vokser deltagelsen i de delte opgaver #SMM4H fortsat.', 'bg': 'Огромното количество данни в социалните медии представя значителни възможности и предизвикателства за използването им като ресурс за здравна информатика. Петата итерация на Социалните медии Минно миниране за здравни приложения (#SMM4H) сподели задачи, целящи напредък в използването на данни в Туитър (туитове) за фармакологична бдителност, токсикобдителност и епидемиология на вродени дефекти. В допълнение към повторното изпълнение на три задачи включваше нови задачи за откриване на нежелани ефекти от медикаменти във френски и руски туитове, характеризиране на разговорите, свързани с злоупотребата с лекарствени продукти по предписание, и откриване на самодоклади за резултати от бременност с дефекти при раждане. Петте задачи изискват метода за двоична класификация, многокласна класификация и разпознаване на наименовани обекти (НЕР). С 29 екипа и общо 130 подавания на системата участието в споделените задачи продължава да нараства.', 'de': 'Die große Datenmenge in sozialen Medien birgt erhebliche Chancen und Herausforderungen, sie als Ressource für die Gesundheitsinformatik zu nutzen. Die fünfte Iteration des Social Media Mining for Health Applications (#SMM4H) zielte darauf ab, die Nutzung von Twitter-Daten (Tweets) für Pharmakovigilanz, Toxicovigilanz und Epidemiologie von Geburtsfehlern voranzutreiben. Neben den Wiederholungen von drei Aufgaben umfasste #SMM4H 2020 neue Aufgaben zur Erkennung unerwünschter Wirkungen von Medikamenten in französischen und russischen Tweets, Charakterisierung von Gesprächen im Zusammenhang mit verschreibungspflichtigen Medikamenten und Erkennung von Selbstberichten über Geburtsfehler Schwangerschaftsergebnisse. Die fünf Aufgaben erforderten Methoden für binäre Klassifizierung, Mehrklassenklassifizierung und Named Entity Recognition (NER). Mit 29-Teams und insgesamt 130-System-Einreichungen wächst die Teilnahme an den #SMM4H Shared Tasks weiter.', 'ko': '소셜 미디어의 대량 데이터는 이를 건강 정보학 자원으로 이용하기 위해 커다란 기회와 도전을 제공했다.건강 애플리케이션을 위한 소셜미디어 발굴(SMM4H)의 5차 교체 공유 임무는 트위터 데이터(트위터)를 약물 경계, 독극물 경계, 출생결함 역학에 활용하도록 추진하기 위한 것이다.#SMM4H 2020에는 3가지 임무 재실행 외에도 프랑스와 러시아 트위터의 약물 불량 반응을 감지하는 새로운 임무, 처방약 남용과 관련된 채팅, 출산 결함 임신 결말을 측정하는 자기보고가 포함됐다.이 다섯 가지 작업은 바이너리 분류, 여러 종류의 분류, 명명된 실체 식별 (NER) 방법이 필요하다.29개 팀과 130개 시스템이 제출했으며 #SMM4H 공유 임무에 참여하는 인원은 계속 증가했다.', 'id': 'The vast amount of data on social media presents significant opportunities and challenges for utilizing it as a resource for health informatics.  iterasi kelima dari Social Media Mining for Health Applications (#SMM4H) berbagi tugas berusaha untuk maju penggunaan data Twitter (tweet) untuk farmakovigilans, toksikovigilans, dan epidemiologi cacat lahir. Selain menjalankan ulang tiga tugas, #SMM4H 2020 termasuk tugas baru untuk mendeteksi efek negatif dari obat-obatan di tweet Perancis dan Rusia, mengkaraterisasi percakapan berkaitan dengan penyalahgunaan resep obat, dan mendeteksi laporan diri tentang hasil kehamilan cacat kelahiran. The five tasks required methods for binary classification, multi-class classification, and named entity recognition (NER).  With 29 teams and a total of 130 system submissions, participation in the #SMM4H shared tasks continues to grow.', 'sw': 'Kiwango kikubwa cha taarifa kwenye mitandao ya kijamii kinaonyesha fursa kubwa na changamoto za kutumia huduma hiyo kama rasilimali kwa ajili ya taarifa za afya. Uchapishaji wa tano wa Vyombo vya Habari vya kijamii kwa ajili ya Matumizi ya Afya (#SMM4H) ulisambazwa na kazi za kutafuta kukuza matumizi ya taarifa za Twita (twita) kwa ajili ya kuzuia dawa, kukosa vibaya na ugonjwa wa magonjwa ya kuzaliwa. Zaidi ya kufanyika tena kazi tatu, #SMM4H 2020 ilijumuisha kazi mpya kwa kutambua madhara mbaya ya madawa katika twiti za Kifaransa na Urusi, akielezea mazungumzo yanayohusiana na unyanyasaji wa madawa, na kujigundua taarifa za matokeo ya utoaji wa mimba. Kazi hizo mitano zinahitaji mbinu za kutangaza darasa la binafsi, usafi wa darasa nyingi, na jina la kutambua entity (NER). Wakati timu 29 na jumla ya ujumbe wa mfumo 130, ushiriki wa kazi zilizoshirikishwa na SMM4H bado unaendelea kukua.', 'fa': 'مقدار زیادی داده های رسانه های اجتماعی فرصت و چالش های مهم برای استفاده از آن به عنوان منابع برای اطلاعات سلامتی وجود دارد. بازگشت پنجم از کارهای مشترک وزارت رسانه\u200cهای اجتماعی برای کاربردهای سلامت (#SMM4H) تلاش کردند تا استفاده از داده\u200cهای توئیتر (tweets) برای داروکاویژیلانس، حفاظت سمیکوژیک و اپیدمیولوژی شکست تولد را پیشرفت کند. در اضافه به دوباره اجرا کردن سه وظیفه #SMM4H 2020، وظیفه\u200cهای جدید برای شناسایی اثرات مخالف داروها در تویت\u200cهای فرانسوی و روسی شامل شد، با مشخص صحبت با تجاوز داروهای پزشکی پزشکی و تشخیص گزارش\u200cهای خودخواهی از نتایج حاملگی در مورد نابودی حاملگی. پنج تاثیر روش\u200cهای نیاز برای گروه\u200cبندی دویینی، گروه\u200cبندی چندین کلاس و شناسایی عنوان\u200cها (NER) است. با ۲۹ تیم و کل تحویل سیستم ۱۳۰ شرکت در کار مشترک SMM4H ادامه می دهد.', 'af': "Die groot hoeveelheid data op sosiale media stel betekende moontlikhede en uitdagings om dit as hulpbron te gebruik vir gesondige informatike. Die vyfde iterasie van die Sosiale Media Mining vir gesondige toepassings (# SMM4H) het gedeelde taak gesoek om die gebruik van Twitter data (tweets) vir farmakovigilanse, toxikovigilanse en epidemiologie van gebore defekte te voorsoek. In addition to re-run of three tasks, #SMM4H 2020 included new tasks for detecting adverse effects of medications in French and Russian tweets, characterizing chatter related to prescription medication abuse, and detecting self-reports of birth defect pregnancy outcomes. Die vyf taak benodig metodes vir binêre klasifikasie, multiklasklas klasifikasie en genaamde entiteiterkening (NER). Met 29 teams en 'n totaal van 130 stelsel onderskrywings, deelnadering in die #SMM4H gedeelde taak gaan voortgaan groei.", 'tr': "Sosial mediýaly maglumatlaryň köp sany maglumatlarynda muny saýlaw informatiki üçin ulanmak üçin möhüm mümkinçilikler we kynçylyklar görkezýär. Sosyal Medýdançalaryň Saglyk Uygulamalary üçin Beşinji ýerleşdirişi (#SMM4H) Twitter maglumatynyň (tweets) ilatyka baglanşygy, toksikovigilýanlygy we dogluşyklaryň epidemiologiýasy üçin ulanmaklygyny gözleýärler. Üç zadyň ýene işi diňe ýene-de '#SMM4H 2020' hem Fransuz we Russiýa tweetlerde nusgalaryň täsiri täsirini tanamak üçin täze zadlary dahil etdi. 2 29 topar we 130 sistema süýşiklikleri bilen #SMM4H paýlaşyş görevleriniň üýtgewini dowam edýär.", 'hy': 'Սոցիալական լրատվամիջոցների հսկայական տվյալները հնարավորություններ և մարտահրավեր են ներկայացնում այն օգտագործելու համար որպես առողջապահության ինֆորմատիկայի ռեսուրս: Առողջապահության ծրագրերի սոցիալական լրատվամիջոցների հանքարության (ՍՄՄ4H) հինգերորդ կրկնօրինակումը փորձում էր առաջ դնել Թվիթերի տվյալների (թվիթերի) օգտագործումը ֆարմակորգավորման, թունկսիկովիլենսի և ծննդյան թերությունների համաճարակի Ավելին երեք խնդիրների վերարտադրման, #SMM4H 2020-ը ներառում էր նոր խնդիրներ դեղամիջոցների բացասական ազդեցությունների հայտնաբերելու ֆրանսիական և ռուսական թվիթերում, բնորոշ շփման, որը կապված է նախատեսված դեղամիջոցների չարաշահույթի հետ, և հղիության պակասի մասին Հինգ խնդիրները պահանջում էին երկարագույն դասակարգում, բազմադասակարգում դասակարգում և անվանելի անհատականության ճանաչման (ՆԵՌ) մեթոդներ: 29 թիմի և համաշխարհում 130 համակարգի ներկայացման դեպքում #SMM4H-ի ընդհանուր խնդիրների մասնակցությունը շարունակում է աճել:', 'sq': 'Shumica e madhe e të dhënave mbi mediat shoqërore paraqet mundësi dhe sfida të rëndësishme për përdorimin e saj si një burim për informacionin shëndetësor. Përsëritja e pestë e Mining of Social Media for Health Applications (#SMM4H) u përpoq të përparonte përdorimin e të dhënave të Twitter-it (tweets) për farmakoviġilancë, toksikoviġilancë dhe epidemiologjinë e defekteve të lindjes. Përveç ripërtëritjeve të tre detyrave, #SMM4H 2020 përfshinte detyra të reja për zbulimin e efekteve të dëmshme të ilaçeve në tweetet franceze dhe ruse, karakterizimin e bisedës lidhur me abuzimin e ilaçeve me receta dhe zbulimin e vetë-raporteve të rezultateve të varfërisë së lindjes. Pesë detyrat kërkuan metoda për klasifikimin binar, klasifikimin e shumë klasave dhe njohjen e emëruar të njësisë (NER). Me 29 ekipe dhe një total prej 130 paraqitjesh të sistemit, pjesëmarrja në detyrat e përbashkëta #SMM4H vazhdon të rritet.', 'am': 'በማኅበራዊ ሚዲያ ላይ ብዙ ዳታዎች የድጋፍ ስልጣናት እና የጤና መረጃዎችን ለመጠቀም የሚችሉትን ጥቃት ያሳያል፡፡ የአምስተኛው ማኅበራዊ ሚዲያ ለጤና ፕሮግራሞች (SMM4H) የተሰራ ስራዎችን ለመጠቀም የTwitter ዳታዎችን (Twittes) ለመጠቀም ይፈልጋል፡፡ #SM4H 2020 ከሦስት ስራ በላይ በፍሪስና በሮሽኛ ትዊተሮች ያሉት አዲስ መድኃኒቶችን ለማግኘት እና አዲስ ስርዓቶች ጨምሯል፡፡ የሕፃንነትን ጥቃት እና የሕፃንነትን ጉዳይ እና የእርግዝነት ውጤት የሆኑትን ጉዳይ ማግኘት እና የፍላጎት ጉዳይ ውጤቶችን ለማግኘት ነው፡፡ The five tasks required methods for binary classification, multi-class classification, and named entity recognition (NER).  የ29 ቡድን እና በ130 ድምፅ ውጤቶች በሙሉ #SM4H የተካፈሉት ስራዎችን ተካፋይነት እየጨመረ ይኖራል፡፡', 'bn': 'সামাজিক প্রচার মাধ্যমের ব্যাপক তথ্য ব্যবহার করার জন্য বিশাল সুযোগ এবং চ্যালেঞ্জ তুলে ধরেছে। সামাজিক প্রচার মাধ্যমের স্বাস্থ্য অ্যাপ্লিকেশনের জন্য স্বাস্থ্য মিনিং (#এসএমএফ৪এইচ) পাঁচমাত্র কাজ শেয়ার করেছে টুইটারের তথ্য (টুইট) ব্যবহারের জন্য কার্যকর স তিন কাজের পুনরায় চালানো ছাড়াও, #এসএমএম৪হ ২০২০ এর মধ্যে ফ্রেঞ্চ ও রাশিয়ান টুইটে মেডিকেন্দ্রের বিরুদ্ধ প্রভাব সন্ধানের জন্য নতুন কাজ রয়েছে, যার মধ্যে মেডিকেশনের অপব্যবহ বাইনারি শ্রেণীবিভাগ, বহু শ্রেণীবিভাগ এবং নামের বস্তুর স্বীকৃতির (NER) জন্য পাঁচটি কাজের প্রয়োজনীয় পদ্ধতি। ২৯ টি দল এবং ১৩০ টি সিস্টেমের ব্যবস্থা প্রদান করার সাথে #এসএমএম৪H শেয়ার কর্মে অংশগ্রহণ চলছে।', 'ca': "La gran quantitat de dades dels mitjans socials presenten oportunitats i reptes significatius per utilitzar-la com a recurso per a l'informàtica sanitària. The fifth iteration of the Social Media Mining for Health Applications (#SMM4H) shared tasks sought to advance the use of Twitter data (tweets) for pharmacovigilance, toxicovigilance, and epidemiology of birth defects.  In addition to re-runs of three tasks, #SMM4H 2020 included new tasks for detecting adverse effects of medications in French and Russian tweets, characterizing chatter related to prescription medication abuse, and detecting self reports of birth defect pregnancy outcomes.  The five tasks required methods for binary classification, multi-class classification, and named entity recognition (NER).  Amb 29 equips i un total de 130 presentacions del sistema, la participació en les tasques compartides #SMM4H continua creixent.", 'cs': 'Obrovské množství dat na sociálních médiích představuje významné příležitosti a výzvy pro jejich využití jako zdroje pro zdravotní informatiku. Pátá iterace sdílených úkolů Sociálních médií Mining for Health Applications (#SMM4H) usilovala o rozšíření využívání dat na Twitteru (tweetů) pro farmakovigilanci, toxikovigilanci a epidemiologii vrozených vad. Kromě opakování tří úkolů #SMM4H 2020 zahrnovala nové úkoly pro detekci nežádoucích účinků léků ve francouzských a ruských tweetech, charakterizaci chatů souvisejících s zneužíváním léků na předpis a detekci samozřejmých hlášení o výsledcích těhotenství vrozené vady. Pět úkolů vyžadovalo metody binární klasifikace, klasifikace více tříd a rozpoznávání pojmenovaných entit (NER). S 29ti týmy a celkem 130 systémovými příspěvky se účast na sdílených úkolech #SMM4H stále zvyšuje.', 'et': 'Sotsiaalmeedias pakutavate andmete suur hulk pakub märkimisväärseid võimalusi ja väljakutseid selle kasutamiseks tervishoiuinfo ressursina. Sotsiaalmeedia tervisealaste rakenduste kaevandamise (#SMM4H) viienda iteratsiooni eesmärk oli edendada Twitteri andmete (säutsud) kasutamist ravimiohutuse, toksilisuse ja sünnidefektide epidemioloogia valdkonnas. Lisaks kolmele ülesandele hõlmas #SMM4H 2020 uusi ülesandeid ravimite kõrvaltoimete tuvastamiseks prantsuse ja vene säutsudes, retseptiravimite kuritarvitamisega seotud vestluste iseloomustamiseks ja sünnidefekti raseduse tulemuste tuvastamiseks. Viis ülesannet nõudsid binaarse klassifitseerimise, mitmeklassilise klassifitseerimise ja nimelise olemi tunnustamise meetodit (NER). 29 meeskonnaga ja kokku 130 süsteemi esitamisega osalemine #SMM4H jagatud ülesannetes kasvab jätkuvalt.', 'fi': 'Sosiaalisen median laaja tietomäärä tarjoaa merkittäviä mahdollisuuksia ja haasteita hyödyntää sitä terveysinformatiikan resurssina. Viidennessä iteraatiossa Social Media Mining for Health Applications (#SMM4H) jaettiin tehtäviä, joilla pyrittiin edistämään Twitterin datan (tweetit) käyttöä lääketurvatoimintaan, toksikologiaan ja synnynnäisten vikojen epidemiologiaan. Kolmen tehtävän uudelleensuorittamisen lisäksi #SMM4H 2020 sisälsi uusia tehtäviä lääkkeiden haittavaikutusten havaitsemiseksi ranskankielisissä ja venäjänkielisissä tweeteissä, reseptilääkkeiden väärinkäyttöön liittyvän keskustelun luonnehtimiseksi ja syntymävikojen raskauden tulosten havaitsemiseksi. Viisi tehtävää edellyttivät binääriluokitusta, moniluokkaista luokitusta ja nimettyä entiteettitunnistusta (NER). Osallistuminen #SMM4H jaettuihin tehtäviin kasvaa 29 tiimin ja 130 järjestelmälähetyksen myötä.', 'hr': 'Velika količina podataka o društvenim medijima predstavlja značajne mogućnosti i izazove za korištenje njega kao resursa za zdravstvene informatike. Peti ponovni potez podjeljenih zadataka za rudarstvo socijalnih medija za zdravstvene aplikacije (#SMM4H) tražio je unaprijediti korištenje podataka o Twitter-u (tweets) za farmakovigilanciju, toksikološku oprezu i epidemiologiju rođenih defekata. Uz ponovno obavljanje tri zadatka, #SMM4H 2020 uključivalo je nove zadatke za otkrivanje nuspojava lijekova na francuskim i ruskim tweetima, karakteriziranje razgovora povezanog s zlostavljanjem lijekova recepta i otkrivanje samih izvješća o rezultatima trudnoće. Pet zadataka zahtijevaju metode za binarnu klasifikaciju, multiklasičnu klasičnu klasifikaciju i priznanje imena entitata (NER). S 29 timova i ukupno 130 podataka sustava, učestvovanje u podjeljenim zadatkima #SMM4H nastavlja rasti.', 'az': 'Sosyal media haqqında böyük məlumatlar onu sağlıq məlumatları üçün istifadə etmək üçün möhkəm fırsatlar və çətinliklər göstərir. Sosial Media Mining for Health Applications (#SMM4H) beşinci dəfə səviyyət işləri Twitter verilənlərini (tweets) pharmakovigilance, toxicovigilance və doğum günahlarının epidemioloji istifadəsini artırmaq üçün hazırlanmışdır. Üç işlərin yenidən işi ilə birlikdə, #SMM4H 2020, Fransızca və Rusya tweetlərdə ilaçların təsirlərini keşfetməsi üçün yeni işlər, receptif ilaçları istifadə etməsi haqqındakı sohbəti təhsil edir və doğulma müvafiqlərinin təhsil edilməsi haqqında təhsil edilir. İkil klasifikasiya, çoxlu sınıf klasifikasiya və adlı ünvanın tanıması üçün beş işlər lazımdır. 29 timallar və 130 sistem təbliğləri ilə birlikdə #SMM4H paylaşılan işlərdə səviyyə artırmağa devam edir.', 'bs': 'Velika količina podataka o društvenim medijima predstavlja značajne prilike i izazove za korištenje njega kao resursa za informatiku zdravstva. Peti ponovni potez zajedničkih zadataka o rudarstvu socijalnih medija za zdravstvene aplikacije (#SMM4H) tražio je unaprijediti korištenje podataka o Twitter (tweets) za farmakovigilanciju, toksikološku oprezu i epidemiologiju rođenih defekata. Uz ponovno obavljanje tri zadatka, #SMM4H 2020 uključivalo je nove zadatke za otkrivanje nuspojava lijekova na francuskim i ruskim tweetima, karakteriziranje razgovora povezanog sa zlostavljanjem lijekova recepta i otkrivanje samih izvještaja o rezultatima trudnoće. Pet zadataka zahtijevaju metode za binarnu klasifikaciju, multiklasnu klasifikaciju i priznanje imena entiteta (NER). Sa 29 tima i ukupno 130 podataka sistema, učestvovanje u podijeljenim zadacima #SMM4H nastavlja rasti.', 'jv': 'Ana kudu akeh akeh data ning media sothik wong liyane ing kapan kanggo dianggawe ngubah sing berarti kanggo nggawe barang pengguna kanggo kebebasan informasi sing resmi. Terus sing perusahaan tanggal kuwi tanggal sing dibenakake aplikasi welas (SMM4H) (#SMM4H) sing ngewehke nggawe ngubah data (tuytes) kanggo ngerasakno dhéwé ngerasakno pangan, tokakowitan, lan akeh pembalkurik kuwi mau. Nambah nambah 3 nggambar obah, #SMM4H 2020 kuwi alam sing gawe ngubah pertaman kanggo ngerasah luwih dumadhi kuwi nganggep kuwi nganggep kuwi maur sing nganggep kuwi etiket Perancis lan tuwit Rusi, nyong berarti nggawe pawaran karo pawaran dhuwur kesempatan kanggo ngerasah perbudhakan maneh. politenessoffpolite"), and when there is a change ("assertivepoliteness Nggo alamat-alamat sing itéh sing nganggo cara-cara sing suji-suji cara-cara sing katêpakan karo #SMM4H, njaluké ngulinggo cara-cara sing gawe ngulinggo.', 'he': 'כמות העצומה של נתונים על התקשורת החברתית מציגה הזדמנויות ואתגרים משמעותיים להשתמש בה כמשאב למידע בריאות. המחזור החמישי של מחקר התקשורת החברתית לתוכניות בריאות (#SMM4H) חולק משימות כדי להקדים את השימוש של נתוני טוויטר בנוסף לשחזור שלושה משימות, #SMM4H 2020 כולל משימות חדשות לגלות השפעות שליליות של תרופות בטיוויטים צרפתיים ורוסיים, מאפיינים פטפוטים קשורים להתעללות בתרופות מרשם, ולגלות דיווחים עצמיים על תוצאות ההריון של פגיעות הלידה. חמישה משימות דורשות שיטות להקליטה בינרית, להקליטה במעמדים רבים, והזיהוי של ישות בשם (NER). עם 29 קבוצות וכל 130 השימושים במערכת, השתתפות במשימות המשותפות #SMM4H ממשיכות לגדול.', 'ha': "Akwai ƙidãya na data a kan mitandai da jamii na bãyar da fursa mai girma da murafa na yi amfani da shi kamar wani asali wa masu tsari. Fiftunsa na Shirin Ayuka na SMM4H Ga sake fara-tafiyar aikin uku,  #SMM4H 2020 yana da aikin nãje na gane misãlai wa madawara cikin Faransa da Ruushiya, yana karatun mazaɓa da takarda na rubutu, kuma yana gane surori na zartar da matsayin bakwaida. Ana buƙata shiryoyin aikin shan da aka buƙata wa sifori-biyu, mai fasa-biyu, da kuma aka suna ganin shaidar abun (NER). Daga jama'a 29 da jama'a guda na 130, shirin aikin #SMM4H da aka raba shi yana ƙara ƙara.", 'sk': 'Velika količina podatkov na družbenih omrežjih predstavlja pomembne priložnosti in izzive za njihovo uporabo kot vira za zdravstveno informatiko. Peta ponovitev programa Social Media Mining for Health Applications (#SMM4H) je skupna naloga poskušala napredovati pri uporabi Twitterjevih podatkov (tweetov) za farmakovigilanco, toksikovigilanco in epidemiologijo prirojenih okvar. Poleg ponovnega izvajanja treh nalog je #SMM4H 2020 vključeval nove naloge za odkrivanje neželenih učinkov zdravil v francoskih in ruskih tweetih, označevanje klepetanja v zvezi z zlorabo zdravil na recept in odkrivanje samoporočil o izidih nosečnosti prirojenih napak. Pet nalog zahteva metode za binarno razvrščanje, večrazredno razvrščanje in prepoznavanje imenovanih entitet (NER). Z 29 ekipami in skupno 130 sistemskimi oddajami se udeležba v skupnih opravilih #SMM4H še naprej povečuje.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་གི་གནས་ཚུལ་མང་ཆེ་བའི་གྲངས་སུ་མཐུན་རྐྱེན་ཡང་ན་གདོང་ལེན་དགོས། སྤྱི་ཚོགས་འབྲེལ་མཐུད་འཇུག་ཟམ་ཞབས་ཞུ་བའི་ཉེར་སྤྱོད་ཀྱི་ཆ་fifth iteration of the Social Media Mining for Health Applications (#SMM4H)ཀྱི་མཉམ་དུ་དམིགས་བསལ་བ་ཡོད་པའི་བྱ་འགུལ་ལ་བཙལ་འདོད་པ་དེ་ཚོར་Twitter data ( ལཱ་གི་གནད་དོན་གསུམ་ཀྱི་མ་འོངས་བསྡད་མི་ #SMM4H 2020 དེ་གིས་བྱ་འགུལ་གསརཔ་ནང་དུ་ཡོད། The five tasks required methods for binary classification, multi-class classification, and named entity recognition (NER). དམག་མོ་༢༠དང་མ་ལག་གི་སྔར་དུས་ཡོངས་བསྡོམས་པ་ལྟར་130 རིགས་གནང་བ་དེ། #SMM4H རྒྱལ་སྤྲོད་ཀྱི་ལས་འགུལ་གྱི་ནང་དུ་མཉམ'}
{'en': 'Ensemble BERT for Classifying Medication-mentioning Tweets BERT  for Classifying Medication-mentioning Tweets', 'ar': 'فرقة بيرت لتصنيف التغريدات التي تذكر الدواء', 'fr': "L'Ensemble BERT pour la classification des tweets mentionnant des médicaments", 'es': 'Ensemble BERT para clasificar los tuits que mencionan medicamentos', 'pt': 'Ensemble BERT para classificação de tweets que mencionam medicamentos', 'ja': '薬に関するツイートを分類するためのBERTアンサンブル', 'ru': 'Ансамбль BERT для классификации медикаментозных твитов', 'zh': 'Ensemble BERT 以类药物之推文', 'hi': 'दवा का उल्लेख Tweets वर्गीकृत करने के लिए Ensemble BERT', 'ga': 'Ensemble BERT le haghaidh Cógas a Aicmiú - tweets á lua', 'el': 'Σύνολο BERT για την ταξινόμηση φαρμάκων-αναφέροντας tweets', 'ka': 'Name', 'hu': 'BERT együttes a gyógyszereket említő tweetek osztályozására', 'it': 'Ensemble BERT per la classificazione dei tweet di menzione dei farmaci', 'lt': 'Bendras BERT, skirtas klasifikuoti vaistus paminėjančius Tweetus', 'mk': 'Name', 'ms': 'Ensemble BERT for Classifying Medication-mentioning Tweets', 'kk': 'Классификациялау жасалған tweets үшін BERT қолдануға болады', 'ml': 'മെഡിക്കല്\u200d മെഡിക്കല്\u200d പ്രസ്താവിക്കുന്നതിനുള്ള ബെര്\u200dട്ടികള്\u200d', 'mt': 'Ensemble BERT for Classifying Medication-mentioning Tweets', 'pl': 'Zespół BERT do klasyfikacji tweetów wymieniających leki', 'ro': 'Ansamblul BERT pentru clasificarea Tweeturilor de menționare a medicamentelor', 'si': 'Name', 'sr': 'Uhvatljiv BERT za klasifikaciju medicinskih tweets', 'so': 'BERT ee fasax-tababarida daawooyinka lagu sheego Tweets', 'sv': 'Ensemble BERT för klassificering av tweets som nämner läkemedel', 'ta': 'வகைப்படுத்தும் மருத்துவ- குறிப்பிடும் தொடர்புகளுக்கான பிரெட்', 'mn': 'Хэрэглэгчдийн хэлэлцүүлэх Твиттүүдийн хувьд БЕРТ', 'no': 'Ensemble BERT for klassifisering av medieringstweeter', 'ur': 'مڈیکٹ-منظور ٹویٹ کے لئے مطابق BERT', 'uz': 'Name', 'vi': 'Comment=Game thẻ Comment', 'nl': 'Ensemble BERT voor het classificeren van medicatie-vermeldende Tweets', 'da': 'Ensemble BERT til klassificering af tweets om medicin', 'bg': 'Ансамбъл за класифициране на туитове за споменаване на медикаменти', 'hr': 'Uhvatljiv BERT za klasifikaciju Tweets o spominjanju lijekova', 'de': 'Ensemble BERT zur Klassifizierung medikamentöser Tweets', 'id': 'Ensemble BERT untuk Classifying Medication-mentioning Tweets', 'ko': '추문을 분류하는 데 사용되는 집합', 'fa': 'BERT برای کلاس\u200cشناسایی توئیت\u200cهای درمانی', 'sw': 'Mtumiaji wa Twita unaoendelea BERT kwa Kusimulia madawa', 'tr': 'Hatlar Ta첵첵arlamak 체챌in BERT Ta첵첵arlan첵ar', 'af': 'Ensembler BERT vir Klassifisering Medikasie- mentioning Tweets', 'sq': 'Ensemble BERT for Classifying Medication-mentioning Tweets', 'am': 'አዲስ ዶሴ ፍጠር', 'az': 'Tövratı Sınıflandırmaq üçün BERT Ensemble for Classifying Medication-mentioning Tweets', 'hy': 'Անսեմպ BER-ը բժշկում նշող թվիթերի դասավորման համար', 'bn': 'ক্লাসিকিং মেডিকেশন-উল্লেখযোগ্য টুইটের জন্য প্রাপ্ত BERT', 'bs': 'Uhvatljiv BERT za klasifikaciju Tweets o spominjanju lijekova', 'ca': 'Ensemble BERT for Classifying Medication-menting Tweets', 'cs': 'Soubor BERT pro klasifikaci medikačních tweetů', 'et': 'Ensemble BERT for Classifing Medicine-Maining Tweets', 'fi': 'Ensemble BERT for Classifing Medication-menting Tweets', 'he': 'סמל BERT לסווג טוויטים מזכירים תרופות', 'jv': 'Language', 'ha': '@ item Text character set', 'bo': 'དབྱེ་སྤྱོད་ཅན་གྱི་BERT སྣང་ཚུལ་གྲངས་སྒྲུབ་གཏོང་བའི་Tweets', 'sk': 'Ensemble BERT za uvrstitev Tweets za omenjanje zdravil'}
{'en': 'Twitter is a valuable source of patient-generated data that has been used in various  population health studies . The first step in many of these studies is to identify and capture Twitter messages (tweets) containing medication mentions. In this article, we describe our submission to Task 1 of the Social Media Mining for Health Applications (SMM4H) Shared Task 2020. This task challenged participants to detect tweets that mention  medications  or  dietary supplements  in a natural, highly imbalance dataset. Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models. Our system ranked first in this task, and improved the average F1 score across all participating teams by 19.07 % with a precision,  recall , and  F1  on the test set of 83.75 %, 87.01 %, and 85.35 % respectively.', 'ar': 'يعد Twitter مصدرًا قيمًا للبيانات التي ينتجها المريض والتي تم استخدامها في دراسات صحة السكان المختلفة. تتمثل الخطوة الأولى في العديد من هذه الدراسات في تحديد رسائل Twitter (التغريدات) التي تحتوي على ذكر الأدوية والتقاطها. في هذه المقالة ، نصف إرسالنا إلى المهمة 1 الخاصة بتعدين وسائل التواصل الاجتماعي للتطبيقات الصحية (SMM4H) المهمة المشتركة 2020. وقد حثت هذه المهمة المشاركين على اكتشاف التغريدات التي تذكر الأدوية أو المكملات الغذائية في مجموعة بيانات طبيعية شديدة الاختلال. قام نظامنا بدمج خطوة معالجة مسبقة يدوية مع مجموعة من 20 مصنفًا قائمًا على BERT تم إنشاؤها عن طريق تقسيم مجموعة بيانات التدريب إلى مجموعات فرعية باستخدام التحقق المتقاطع 10 أضعاف واستغلال نموذجي تضمين BERT. احتل نظامنا المرتبة الأولى في هذه المهمة ، وحسّن متوسط درجة F1 عبر جميع الفرق المشاركة بنسبة 19.07٪ بدقة واسترجاع و F1 في مجموعة الاختبار بنسبة 83.75٪ و 87.01٪ و 85.35٪ على التوالي.', 'fr': "Twitter est une source précieuse de données générées par les patients qui ont été utilisées dans diverses études sur la santé de la population. La première étape de bon nombre de ces études consiste à identifier et à enregistrer les messages Twitter (tweets) contenant des mentions de médicaments. Dans cet article, nous décrivons notre soumission à la tâche 1 de la tâche partagée 2020 de Social Media Mining for Health Applications (SMM4H). Cette tâche a mis les participants au défi de détecter les tweets qui mentionnent des médicaments ou des compléments alimentaires dans un ensemble de données naturel très déséquilibré. Notre système combinait une étape de prétraitement artisanale avec un ensemble de 20 classificateurs basés sur BERT générés en divisant le jeu de données d'apprentissage en sous-ensembles à l'aide d'une validation croisée 10 fois et en exploitant deux modèles d'intégration BERT. Notre système s'est classé premier dans cette tâche et a amélioré le score moyen de F1 parmi toutes les équipes participantes de 19,07\xa0% avec une précision, un rappel et une F1 sur l'ensemble de tests de 83,75\xa0%, 87,01\xa0% et 85,35\xa0% respectivement.", 'pt': 'O Twitter é uma fonte valiosa de dados gerados por pacientes que tem sido usada em vários estudos de saúde da população. O primeiro passo em muitos desses estudos é identificar e capturar mensagens do Twitter (tweets) contendo menções a medicamentos. Neste artigo, descrevemos nossa submissão à Tarefa 1 da Tarefa Compartilhada de Mineração de Mídia Social para Aplicativos de Saúde (SMM4H) 2020. Essa tarefa desafiou os participantes a detectar tweets que mencionam medicamentos ou suplementos alimentares em um conjunto de dados natural e altamente desequilibrado. Nosso sistema combinou uma etapa de pré-processamento artesanal com um conjunto de 20 classificadores baseados em BERT gerados pela divisão do conjunto de dados de treinamento em subconjuntos usando validação cruzada de 10 vezes e explorando dois modelos de incorporação de BERT. Nosso sistema ficou em primeiro lugar nesta tarefa e melhorou a pontuação média da F1 em todas as equipes participantes em 19,07% com precisão, recall e F1 no conjunto de teste de 83,75%, 87,01% e 85,35%, respectivamente.', 'es': 'Twitter es una fuente valiosa de datos generados por los pacientes que se han utilizado en varios estudios de salud de la población. El primer paso en muchos de estos estudios es identificar y capturar los mensajes de Twitter (tuits) que contienen menciones de medicamentos. En este artículo, describimos nuestro envío a la Tarea 1 de la Tarea Compartida de Minería de Redes Sociales para Aplicaciones de Salud (SMM4H) 2020. Esta tarea desafió a los participantes a detectar tuits que mencionaban medicamentos o suplementos dietéticos en un conjunto de datos natural y altamente desequilibrado. Nuestro sistema combinó un paso de preprocesamiento artesanal con un conjunto de 20 clasificadores basados en BERT generados al dividir el conjunto de datos de entrenamiento en subconjuntos utilizando una validación cruzada de 10 veces y aprovechando dos modelos de incrustación de BERT. Nuestro sistema ocupó el primer lugar en esta tarea y mejoró la puntuación media de F1 en todos los equipos participantes en un 19,07%, con una precisión, recuperación y F1 en el conjunto de pruebas del 83,75%, 87,01% y 85,35%, respectivamente.', 'ja': 'Twitterは、さまざまな集団健康研究で使用されてきた患者生成データの貴重なソースです。これらの研究の多くの最初のステップは、薬の言及を含むTwitterメッセージ（ツイート）を特定してキャプチャすることです。この記事では、ソーシャルメディアマイニングfor Health Applications (SMM 4 H) Shared Task 2020のタスク1への提出について説明します。このタスクは、自然で非常に不均衡なデータセットで薬や栄養補助食品に言及するツイートを検出するよう参加者に課題を与えました。当社のシステムは、10倍クロスバリデーションを使用し、2つのBERT埋め込みモデルを利用してトレーニングデータセットをサブセットに分割することによって生成された20個のBERTベースの分類子のアンサンブルと手作りの前処理ステップを組み合わせました。私たちのシステムはこのタスクで1位になり、すべての参加チームの平均F 1スコアを19.07 ％向上させ、83.75 ％、87.01 ％、85.35 ％のテストセットで精度、リコール、F 1を達成しました。', 'hi': 'ट्विटर रोगी-जनित डेटा का एक मूल्यवान स्रोत है जिसका उपयोग विभिन्न जनसंख्या स्वास्थ्य अध्ययनों में किया गया है। इनमें से कई अध्ययनों में पहला कदम ट्विटर संदेशों (ट्वीट्स) की पहचान करना और कैप्चर करना है जिसमें दवा का उल्लेख है। इस लेख में, हम स्वास्थ्य अनुप्रयोगों (SMM4H) साझा कार्य 2020 के लिए सोशल मीडिया माइनिंग के कार्य 1 के लिए हमारे सबमिशन का वर्णन करते हैं। इस कार्य ने प्रतिभागियों को उन ट्वीट्स का पता लगाने के लिए चुनौती दी जो प्राकृतिक, अत्यधिक असंतुलन डेटासेट में दवाओं या आहार की खुराक का उल्लेख करते हैं। हमारे सिस्टम ने 10-गुना क्रॉस सत्यापन का उपयोग करके प्रशिक्षण डेटासेट को सबसेट में विभाजित करके और दो BERT एम्बेडिंग मॉडल का शोषण करके उत्पन्न 20 BERT-आधारित क्लासिफायरों की एक टुकड़ी के साथ एक हस्तनिर्मित प्रीप्रोसेसिंग चरण को जोड़ा। हमारी प्रणाली इस कार्य में पहले स्थान पर है, और क्रमशः 83.75%, 87.01%, और 85.35% के परीक्षण सेट पर एक परिशुद्धता, याद और F1 के साथ 19.07% द्वारा सभी भाग लेने वाली टीमों में औसत F1 स्कोर में सुधार हुआ।', 'zh': 'Twitter者,生数之宝,已施于众口矣。 凡此诸论,识获含药Twitter消息(推文)。 本文中,我们将我们向2020年健应用程序社交媒体挖掘(SMM4H)共享职务的事务1提交的文件。 其务参与者在自然,高不平之数集检提及药物膳补充剂之推文。 吾之系统,以手工之预处理步驿与 20 BERT 之分类器合,此器是倍用 10 验练数为子集而用二 BERT 嵌模形者也。 吾属第一于此,尽以参赛伍之均F1分数增19.07%,精度,召率F1试集上之精度为83.75%,87.01%85.35%。', 'ru': 'Twitter является ценным источником данных, генерируемых пациентами, которые использовались в различных исследованиях здоровья населения. Первым шагом во многих из этих исследований является выявление и захват сообщений в Twitter (твитов), содержащих упоминания о лекарствах. В этой статье мы описываем наше участие в Задаче 1 Совместной задачи 2020 «Майнинг социальных сетей для приложений здравоохранения» (SMM4H). Это задание поставило перед участниками задачу обнаружить твиты, в которых упоминаются лекарства или пищевые добавки в наборе данных о естественных, сильно дисбалансных веществах. Наша система объединила ручную предварительную обработку с ансамблем из 20 классификаторов на основе BERT, сгенерированных путем деления обучающего набора данных на подмножества с использованием 10-кратной перекрестной проверки и двух моделей встраивания BERT. Наша система заняла первое место в этом задании и улучшила средний балл F1 среди всех участвующих команд на 19,07% с точностью, отзывом и F1 на тестовом наборе 83,75%, 87,01% и 85,35% соответственно.', 'ga': "Is foinse luachmhar sonraí arna ghiniúint ag othair é Twitter a úsáideadh i staidéir éagsúla ar shláinte an daonra. Is í an chéad chéim i go leor de na staidéir seo ná teachtaireachtaí Twitter (tweets) ina luaitear cógais a aithint agus a ghabháil. San Airteagal seo, déanaimid cur síos ar ár n-aighneacht do Thasc 1 den Tasc Comhroinnte um Mhianadóireacht ar na Meáin Shóisialta le haghaidh Feidhmchláir Sláinte (SMM4H) 2020. Thug an tasc seo dúshlán do rannpháirtithe tweets a bhrath a luann cógais nó forlíontaí aiste bia i tacar sonraí nádúrtha éagothroime. Chomhcheangail ár gcóras céim réamhphróiseála lámhdhéanta le ensemble de 20 aicmitheora bunaithe ar BERT a ghintear tríd an tacar sonraí oiliúna a roinnt ina bhfo-thacair ag baint úsáide as tras-bhailíochtú 10-huaire agus ag baint leasa as dhá mhúnla leabaithe BERT. Bhí ár gcóras rangaithe sa chéad áit sa tasc seo, agus d'fheabhsaigh sé an meánscór F1 thar na foirne rannpháirteacha go léir 19.07% le beachtas, athghairm, agus F1 ar an tacar tástála de 83.75%, 87.01%, agus 85.35% faoi seach.", 'el': 'Το Twitter είναι μια πολύτιμη πηγή δεδομένων που παράγονται από ασθενείς που έχουν χρησιμοποιηθεί σε διάφορες μελέτες υγείας του πληθυσμού. Το πρώτο βήμα σε πολλές από αυτές τις μελέτες είναι ο εντοπισμός και η καταγραφή μηνυμάτων που περιέχουν αναφορές φαρμάκων. Σε αυτό το άρθρο, περιγράφουμε την υποβολή μας στην εργασία 1 της Κοινής Εργασίας 2020. Αυτό το έργο προκάλεσε τους συμμετέχοντες να εντοπίσουν τα tweets που αναφέρουν φάρμακα ή συμπληρώματα διατροφής σε ένα φυσικό, εξαιρετικά ανισορροπικό σύνολο δεδομένων. Το σύστημά μας συνδύασε ένα χειροποίητο βήμα προεπεξεργασίας με ένα σύνολο 20-βασισμένων ταξινομητών που παράγονται διαιρώντας το σύνολο δεδομένων εκπαίδευσης σε υποσύνολα χρησιμοποιώντας 10πλάσια διασταυρούμενη επικύρωση και αξιοποιώντας δύο μοντέλα ενσωμάτωσης BERT. Το σύστημά μας κατατάχθηκε πρώτος σε αυτό το έργο, και βελτίωσε το μέσο σκορ F1 σε όλες τις συμμετέχουσες ομάδες κατά 19.07% με ακρίβεια, ανάκληση και F1 στο σύνολο δοκιμής 83.75%, 87.01%, και 85.35% αντίστοιχα.', 'hu': 'A Twitter a betegek által generált adatok értékes forrása, amelyeket különböző populációs egészségügyi vizsgálatokban használtak fel. Sok ilyen tanulmány első lépése az, hogy azonosítsuk és rögzítsük a Twitter üzeneteket (tweeteket), amelyek gyógyszeres említéseket tartalmaznak. Ebben a cikkben bemutatjuk a Közösségi Média Bányászati Alkalmazások (SMM4H) Megosztott Feladata 2020 1. feladatához való benyújtásunkat. Ez a feladat arra kérte a résztvevőket, hogy észleljenek olyan tweeteket, amelyek gyógyszereket vagy étrend-kiegészítőket említenek egy természetes, rendkívül kiegyensúlyozatlan adatkészletben. Rendszerünk egy kézzel készített előfeldolgozási lépést ötvözött egy 20 BERT alapú osztályozóból álló együttesével, amelyeket az edzési adatok 10-szeres keresztvalidálással és két BERT beágyazási modell kihasználásával generáltunk. Rendszerünk az első helyen állt ebben a feladatban, és 19,07%-kal javította az F1 átlagos pontszámot az összes résztvevő csapat esetében, pontossággal, visszahívással és F1-vel a tesztkészleten 83,75%, 87,01%, 85,35%-kal.', 'it': "Twitter è una preziosa fonte di dati generati dai pazienti che sono stati utilizzati in vari studi sulla salute della popolazione. Il primo passo in molti di questi studi è quello di identificare e catturare messaggi Twitter (tweet) contenenti menzioni di farmaci. In questo articolo, descriviamo la nostra presentazione al Task 1 del Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Questo compito ha sfidato i partecipanti a rilevare tweet che menzionano farmaci o integratori alimentari in un set di dati naturali e altamente sbilanciati. Il nostro sistema ha combinato una fase di preelaborazione artigianale con un insieme di 20 classificatori basati su BERT generati dividendo il set di dati di allenamento in sottoinsiemi utilizzando 10 volte la convalida incrociata e sfruttando due modelli di incorporazione BERT. Il nostro sistema si è classificato primo in questo compito e ha migliorato il punteggio medio F1 di tutte le squadre partecipanti del 19,07% con precisione, richiamo e F1 sul set di test rispettivamente dell'83,75%, 87,01% e 85,35%.", 'lt': 'Twitter yra vertingas pacientų sukauptų duomenų šaltinis, kuris buvo naudojamas įvairiuose gyventojų sveikatos tyrimuose. Pirmasis daugelio šių tyrimų žingsnis – nustatyti ir surinkti Twitter pranešimus (tweetus), kuriuose yra vaistų paminėjimų. Šiame straipsnyje apibūdiname savo pasiūlymą dėl bendros socialinės žiniasklaidos kasybos sveikatos srityje (SMM4H) užduoties „2020 m.“ 1 užduoties. Šioje užduotyje dalyviams buvo iškeltas uždavinys nustatyti tweetus, kuriuose natūraliame, labai disbalansuotame duomenų rinkinyje nurodomi vaistai arba mitybos papildai. Mūsų sistema derino rankinius parengiamuosius procesus su 20 BERT grindžiamų klasifikatorių rinkiniu, gautu padalijant mokymo duomenų rinkinį į pogrupius, naudojant 10 kartų kryžminį patvirtinimą ir naudojant du BERT įterpimo modelius. Our system ranked first in this task, and improved the average F1 score across all participating teams by 19.07% with a precision, recall, and F1 on the test set of 83.75%, 87.01%, and 85.35% respectively.', 'mk': 'Twitter is a valuable source of patient-generated data that has been used in various population health studies.  Првиот чекор во многу од овие студии е идентификувањето и снимањето на пораките од Твитер (твитови) кои содржат медицински спомени. Во оваа статија, го опишуваме нашето поднесување на задачата 1 на Социјалната медиумска минирање за здравствени апликации (SMM4H) споделена задача 2020. Оваа задача ги предизвика учесниците да откријат твитови кои споменуваат лекови или диетарни дополнители во природен, високо нерамнотежен податок. Нашиот систем комбинираше рачно направен чекор на препроцес со ансембл од 20 класификатори на основа на BERT генерирани со поделба на наборот на податоци за обука користејќи 10 пати крсто валидација и искористувајќи два BERT модели за вградување. Нашиот систем се рангираше прв во оваа задача и го подобри просечниот резултат на Ф1 во сите учествувачки тимови за 19,07 отсто со прецизност, повлекување и Ф1 на тестот од 83,75 отсто, 87,01 отсто и 85,35 отсто.', 'ms': 'Twitter adalah sumber berharga data yang dijana oleh pesakit yang telah digunakan dalam pelbagai kajian kesehatan populasi. Langkah pertama dalam banyak kajian ini adalah untuk mengenalpasti dan tangkap mesej Twitter (tweet) yang mengandungi sebutan ubat. Dalam artikel ini, kami menggambarkan penghantaran kami ke Tugas 1 Media Sosial Menjemput untuk Aplikasi Kesehatan (SMM4H) Tugas Berkongsi 2020. Tugas ini menantang peserta untuk mengesan tweet yang menyebutkan ubat atau tambahan dieti dalam set data yang tidak seimbang secara alami. Sistem kami menggabungkan langkah persiapan buatan tangan dengan kumpulan 20 pengendali berasaskan BERT yang dijana dengan membahagi set data latihan ke bawah kumpulan menggunakan pengesahihan salib 10 kali dan mengeksploitasi dua model penyembedding BERT. Sistem kami ditandai pertama dalam tugas ini, dan meningkatkan nilai F1 rata-rata di seluruh pasukan yang berpartisipasi dengan 19.07% dengan ketepatan, pengingatan, dan F1 pada set ujian 83.75%, 87.01%, dan 85.35% respectively.', 'ml': 'വിവിധ സംസ്ഥാനങ്ങളില്\u200d ഉപയോഗിക്കപ്പെട്ടിരിക്കുന്ന രോഗിയുടെ സൃഷ്ടിക്കുന്ന വിവരങ്ങളുടെ വിലയി ഈ പഠനത്തില്\u200d പലതിലും ആദ്യ പടിയാണ് ടൂട്ടര്\u200d സന്ദേശങ്ങള്\u200d തിരിച്ചറിയുകയും പിടികൂടുകയും ചെയ്യുന്നത് മെഡിക്കല്\u200d മ ഈ ലിപ്പോര്\u200dട്ടില്\u200d, ഞങ്ങള്\u200d സോഷ്യല്\u200d മീഡിയയുടെ കാര്യത്തില്\u200d ഞങ്ങളുടെ കീഴ്പ്പെടുത്തുന്നത് സാമൂഹിക മിനിങ്ങിന്\u200dറെ ആശ്വാസപ ഈ ജോലിയില്\u200d പങ്കാളികളെ പരിചയപ്പെടുത്തിയ ടൂട്ടുകള്\u200d കണ്ടുപിടിക്കാന്\u200d വിധിച്ചിരിക്കുന്നു. അത് സ്വാഭാവികമായ, വളര നമ്മുടെ സിസ്റ്റത്തില്\u200d ഒരു കൈക്കൊണ്ടുള്ള പ്രെക്രോസിസ്റ്റ് ചേര്\u200dത്ത് 20 ബെര്\u200dട്ടി അടിസ്ഥാനത്തിലുള്ള ക്ലാസ്പിളുകളുടെ ഒരു കൂട്ടത്തില്\u200d ഉണ്ടാക്കി. ട് നമ്മുടെ സിസ്റ്റത്തിന്റെ സിസ്റ്റം ആദ്യം ഈ പ്രവര്\u200dത്തനത്തില്\u200d വേര്\u200dതിരിച്ചു, എല്ലാ പങ്കെടുക്കുന്ന ഗ്രൂപ്പുകളിലും ഏറ്റവും ശരാശരി F1 സ്കോര്\u200d മുന്\u200dകൂട്ടി വരുത്തി.', 'ka': 'Twitter არის მნიშვნელოვანი პოციენტის შექმნილი მონაცემების გამოყენება, რომელიც განსხვავებული ჯანმრთელობის სწავლებში გამოყენებულია. პირველი კონფიგურაციის ბევრი სწავლაში არის Twitter შეტყობინებების (tweets) განსაზღვრება და გააკეთება, რომლებიც მედიციაციის შესახებ. ამ ახალგაში ჩვენ აღწერეთ საზოგადომი მედიაში საზოგადომი პროგრამებისთვის (SMM4H) საზოგადომი პროგრამებისთვის საზოგადომი მედიაში. ეს დავალება გადაწყვეტილი მონაცემებელები, რომლებიც ამბობენ მედიკაციები ან დიატური დამატებები ნათეულად, ძალიან განბალიზომის მონაცემების სეტში. ჩვენი სისტემა გადაყენებული პრეპროცესტის ნაწილი 20 BERT-ის კლასიფიკაციების სენემბელი, რომელიც შექმნა განაკლების მონაცემების სენესტებში გაყოფილი 10-ჯერ კრესი გადაწყენება და ექსპროცესტის ორი BERT- ჩვენი სისტემა პირველი იყო ამ დავალებაში, და სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორედ სწორე', 'mn': 'Твиттер бол өвчтөн бүтээгдэхүүний эрүүл мэндийн судалгаанд хэрэглэгдсэн мэдээллийн үнэ цэнэтэй эх үүсвэр юм. Эдгээр судалгаануудын анхны алхам нь эмчилгээний нэр тодорхойлолтуудыг тодорхойлох, туйтуудыг барих юм. Энэ хэвлэлд бид нийгмийн мэдээллийн баялаг болон эрүүл мэндийн хэрэглээний (SMM4H) Засгийн 1-р даалгаварыг тайлбарлаж байна. Энэ үйл ажиллагаанд оролцогчдыг байгалийн, өндөр тэгш байдалтай өгөгдлийн санд эмийн эсвэл хоолны нэмэлт нэмэлт хэмээх tweets-г олж мэдэхэд зориулсан. Бидний систем гар бүтээгдэхүүний аль боловсруулалтын алхам нь БЕРТ-ын 20 хэлбэртэй классификаторыг 10 дахин шалгаж, 2 BERT-ын бүтээгдэхүүний загварыг ашиглаж бүтээсэн. Бидний систем эхлээд энэ ажил дээр хуваалцаж, дундаж F1 оноо бүх оролцогчдын баг дээр 19.07%-аар хуваалцаж, тодорхойлолтой, санах, F1-г тестийн багтаа 83.75%, 87.01%, 85.35%.', 'pl': 'Twitter jest cennym źródłem danych generowanych przez pacjentów, które zostały wykorzystane w różnych badaniach zdrowia populacji. Pierwszym krokiem w wielu z tych badań jest identyfikacja i przechwytywanie wiadomości na Twitterze (tweety) zawierających wzmianki o lekach. W tym artykule opisujemy naszą zgłoszenie do Zadania 1 Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Zadanie to wyzwało uczestników do wykrycia tweetów, które wspominają leki lub suplementy diety w naturalnym zbiorze danych o wysokim zakłóceniu równowagi. Nasz system połączył ręcznie wykonany etap przetwarzania wstępnego z zespołem 20-klasyfikatorów opartych na BERT generowanych poprzez podzielenie zbioru danych treningowych na podzbiory za pomocą 10-krotnej walidacji krzyżowej i wykorzystanie dwóch modeli osadzania BERT. Nasz system zajął pierwszy miejsce w tym zadaniu i poprawił średni wynik F1 we wszystkich uczestniczących zespołach o 19,07% z precyzją, odwołaniem i F1 na zestawie testowym 83,75%, 87,01%, odpowiednio i 85,35% .', 'ro': 'Twitter este o sursă valoroasă de date generate de pacienți, care au fost utilizate în diferite studii de sănătate a populației. Primul pas în multe dintre aceste studii este identificarea și captarea mesajelor Twitter (tweet-uri) care conțin mențiuni de medicamente. În acest articol, descriem depunerea noastră la Activitatea 1 a Activității Partajate pentru Aplicații de Mining Social Media pentru Sănătate (SMM4H) 2020. Această sarcină a provocat participanții să detecteze tweet-uri care menționează medicamente sau suplimente alimentare într-un set de date natural, extrem de dezechilibrat. Sistemul nostru a combinat o etapă de pre-procesare manuală cu un ansamblu de 20 de clasificatoare bazate pe BERT generate prin împărțirea setului de date de instruire în subseturi utilizând validarea încrucișată de 10 ori și exploatând două modele de încorporare BERT. Sistemul nostru s-a clasat pe primul loc în această sarcină și a îmbunătățit scorul mediu F1 pentru toate echipele participante cu 19,07% cu o precizie, rechemare și F1 pe setul de teste de 83,75%, 87,01%, respectiv 85,35%.', 'mt': 'Twitter is a valuable source of patient-generated data that has been used in various population health studies.  L-ewwel pass f’ħafna minn dawn l-istudji huwa li jiġu identifikati u maqbuda messaġġi ta’ Twitter (tweets) li fihom imsemmija medikazzjoni. F’dan l-artikolu, aħna niddeskrivu s-sottomissjoni tagħna lill-Kompitu 1 tal-Mifħa tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (SMM4H) Kompitu Konġunt 2020. Dan il-kompitu sfida lill-parteċipanti biex isibu tweets li jsemmu medikazzjonijiet jew supplimenti tad-dieta f’sett ta’ dejta ta’ żbilanċ naturali u għoli. Is-sistema tagħna kkombinat pass ta’ preproċessar magħmul bl-idejn ma’ ensemble ta’ 20 klassifikatur ibbażat fuq BERT iġġenerat billi qassam is-sett tad-dejta tat-taħriġ f’sottosettijiet bl-użu ta’ validazzjoni inkroċjata ta’ 10 darbiet u bl-isfruttar ta’ żewġ mudelli ta’ inkorporazzjoni BERT. Is-sistema tagħna kklassifikat l-ewwel f’dan il-kompitu, u tejbet il-punteġġ medju F1 fit-timijiet parteċipanti kollha b’19.07% bi preċiżjoni, riferiment, u F1 fis-sett tat-test ta’ 83.75%, 87.01%, u 85.35% rispettivament.', 'no': 'Twitter er ein verdileg kjelde for data laga av pasienter som er brukt i forskjellige befolkningshelsestudiar. Den første stegen i mange av desse studiane er å identifisera og henta Twitter-meldingar (tweets) som inneheld legemiddelar. I denne artikkelen beskriver vi søket vårt til oppgåve 1 av den sosiale mediamining for helseprogramma (SMM4H) delte oppgåva 2020. Denne oppgåva utfordre deltakarar å oppdaga tweeter som mener medikamenter eller dietarsupplementar i eit naturleg, stor ulikhetsdataset. Sistemet vårt kombinerte ein handsamlingsstegn med ein ensembel av 20 BERT-baserte klassifikatorar som er generert ved å dele opplæringsdatasettet til undergrupper med 10 gangar kryssverding og bruka to BERT-innebyggingsmodeller. Sistemet vårt rangerte først i denne oppgåva, og forbedra gjennomsnittlige F1- scoren i alle deltakarane med 19,07% med eit nøyaktig, rekning og F1 på testsettet 83,75%, 87,01%, og 85,35%.', 'kk': 'Твиттер - пациенттің құрылған деректер көзі, әртүрлі адамдардың саулық зерттеулерінде қолданылған. Бұл зерттеулердің бірінші қадамы - медицина мәліметтері бар Твиттер хаттарын (tweets) анықтау және алу. Бұл мақалада, біз 2020 жылы ортақ тапсырманың социалдық медиа бағалау бағдарламаларының (SMM4H) 1- тапсырмасына жіберімізді таңдаймыз. Бұл тапсырма қатысушыларды таңдау үшін қатысушыларды таңдау үшін қатысушыларды таңдау үшін қатысушыларды таңдайды. Біздің жүйеміз қолдану арқылы алдын- процесс қадамын біріктіріп, BERT- негіздеген 20 классификациялық классификациялық классификациялық қадамымен, оқыту деректер жиынын 10- қатар тексеру және екі BERT ендіру үлгілері Біздің жүйеіміз бұл тапсырманың алғашқы ретінде жұмыс істеп, барлық қатысушылардың орташа F1 нөмірін 19,07% деп жақсартып, еске салу, еске салу және F1 теститу жиынында 83,75%, 87,01%, және 85,35%.', 'so': 'Twitterka waa warqad qiimaan ah oo macluumaadka bukaanka oo lagu isticmaalay waxbarashada caafimaadka ee kala duduwan. Dhacdooyinka ugu horeeya ee waxbarashadan badan waa in ay aqoonsadaan oo qabsadaan warqada Twitterka (twitter) oo ku jira macluumaadka dawooyinka. Maktabadan waxaynu ku qoraynaa lifaaqnimadayada shaqada 1 ee daryeelka caafimaadka ee macluumaadka bulshada (SMM4H) ee loo sharciyey shaqo 2020. Shaqadan waxaa dhibaataysan in dadka ka qeybqaaday ay soo ogaadaan tweetyo ku saabsan daryeelka caafimaadka ama qalabka cuntada ee dabiicadda ah oo aad u baahan. Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models.  nidaamkayagii wuxuu marka hore u qoray shaqadan, waxaana hormariyey qiimaha F1 ee ugu dhexeeya kooxda qayb-qaadashada oo dhan waxay ku jirtay 19.07 % si saxda ah, xusuustana iyo F1-kooxda imtixaanka u dhexeeya 83.75%, 87.01 boqolkiiba iyo 85.35 boqolkiiba.', 'sr': 'Twitter je vrijedan izvor podataka od pacijenata koji se koristi u raznim studijama zdravlja populacije. Prvi korak u mnogim od tih ispitivanja je da identifikujemo i uhvatimo Twitter poruke (tweets) koji sadrže spomenute lekova. U ovom članku opisujemo svoj podatak zadatku 1 Socijalnog medijskog rudarstva za zdravlje aplikacije (SMM4H) zajedničkog zadatka 2020. Ovaj zadatak je izazvao učesnike da otkriju tweet koji spominju lekove ili dodatke hrane u prirodnom, visoko nelegalnom kompletu podataka. Naš sistem je kombinirao korak za preobrađivanje ruku sa ensemblom 20 klasifikatora baziranih na BERT-u, koji je proizveden podjelom podataka obuke u podskupine koristeći 10 puta ukrštenu validaciju i iskorištavajući dva modela integracije BERT-a. Naš sistem je prvi postigao u ovom zadatku, i poboljšao prosječni rezultat F1 u svim sudionicima za 19,07% sa preciznim, sjećanjem i F1 na testovom setu od 83,75%, 87,01%, i 85,35%.', 'si': 'ට්විටර් තමයි රෝගිකයෙන් නිර්මාණය කරපු දත්තේ විවිදිහට ප්\u200dරයෝජනය කරපු විදිහට ප්\u200dරයෝජනය මේ අධ්\u200dයානය ගොඩක් අධ්\u200dයානයේ පළමු පැත්තක් තමයි Twitter පණිවිඩය (ට්විට්) සම්බන්ධ විද්\u200dයාවක් තියෙන්න මේ ලේඛනයේදී, අපි අපේ සාමාජික මාධ්\u200dයමාධ්\u200dයම පරීක්ෂණාව (SMM4H) සාමාජික කාර්යම් එක්ක කාර්යයෙන් ප්\u200dරවේශනය මේ වැඩේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කළා සාමාන්\u200dය, ගොඩක් අමාරුක්\u200dරීය දත්ත සෙට්ටුවෙන් ප්\u200dරශ්නයක් තියෙන්න තුව අපේ පද්ධතිය සම්බන්ධ කරලා තියෙන්නේ පුරාපරීක්ෂණ පැත්තක් සමග BERT-අධ්\u200dයාත්මක පරීක්ෂණ කරුණු 20 වලට පරීක්ෂණ කරුණු පද්ධතියක් පද්ධති අපේ පද්ධතිය මේ වැඩේ පටන් ගත්තා, ඒ වගේම සාමාන්\u200dය F1 ස්කෝර් වැඩ කරලා සියළු කණ්ඩායම් 19.07% විශේෂයෙන් ප්\u200dරමාණයක් තියෙනවා, මතක් ගත්තා, සහ F1 පරීක', 'ta': 'Twitter is a valuable source of patient-generated data that has been used in various population health studies. இந்த பல படிப்புகளில் முதல் படி மருந்து குறிப்புகளைக் கொண்டிருக்கும் தொடர்பு செய்திகளையும் கண்டுபிடிக்க இந்த கட்டுரையில், நாம் சாலிக ஊடகங்களின் செயல் 1க்கு எங்கள் அனுப்புதலை விவரிக்கிறோம் சார்பு பயன்பாடுகளுக்கு (SMM4H) சேர்க்கப இந்த செயல் பங்கீட்டாளர்களுக்கு சவாலானது இயற்கையான, மிகவும் உயர்ந்த ஒழுங்கும் தரவுத்தளத்தில் மருத்துவ அல்லது உணவு  Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models.  எங்கள் அமைப்பு முதலில் இந்த வேலையில் வரிசைப்படுத்தப்பட்டது, அனைத்து பங்கிடும் குழுக்களுக்கும் சராசரியான F1 மதிப்பு 19. 07% முழுவதும் அதிகரித்தது, சரியாக, நினைவு க', 'ur': 'ٹویٹر صبر کے پیدا کئے ہوئے ڈاکٹوں کا ایک مقدار سراسر ہے جو مختلف جمعیت سلامتی تحقیقات میں استعمال کیا گیا ہے۔ ان میں سے بہت سے تحقیقات میں پہلی قدم یہ ہے کہ توئیٹر کے پیغام (ٹویٹ) کے ذریعے داروغ یاد رکھنے اور پکڑنے کے لئے۔ اس مقالہ میں، ہم نے اپنے تسلیم کام ۱ کی تابع کی تعریف کی ہے سوسیل میڈیا میڈیو مینینگ سلامتی کاربریوں کے لئے (SMM4H) شریک تابع ۲۰۰۲۔ اس کام نے مشرکین کو توئیٹوں کا اظہار کرنا چاہا جو داروغ یا غذای اضافہ کا ذکر کرتی ہیں ایک طبیعی، بہت زیادہ نابرابریس ڈیٹ سٹ میں۔ ہماری سیسٹم نے ایک ہاندکرپٹ پرپرس سٹ کو 20 BERT بنیادی کلاسیٹر کے ساتھ پیدا کیا ہے جو تدریس ڈیٹ سٹ کو سٹیٹوں میں تقسیم کرنے کے ذریعہ 10 دفعہ کرسٹ والیڈیٹ کے مطابق اور دو BERT انڈیڈنگ موڈل کے مطابق استعمال کرتے ہیں ہماری سیستم نے اس کام میں پہلے درجہ کی اور تمام شرکت گروہوں میں متوسط F1 اسکور کو 19.07% کے ذریعہ مضبوط، یاد کرو، اور F1 کو آزمائش سٹ میں 83.75%, 87.01%، اور 85.35%.', 'sv': 'Twitter är en värdefull källa till patientgenererad data som använts i olika folkhälsostudier. Det första steget i många av dessa studier är att identifiera och fånga Twitter-meddelanden (tweets) som innehåller läkemedelsomnämnanden. I den här artikeln beskriver vi vårt bidrag till uppgift 1 i Social Media Mining for Health Applications (SMM4H) delad uppgift 2020. Denna uppgift utmanade deltagarna att upptäcka tweets som nämner läkemedel eller kosttillskott i en naturlig datauppsättning med hög obalans. Vårt system kombinerade ett handgjort förbehandlingssteg med en uppsättning av 20 BERT-baserade klassificerare som genererats genom att dela upp träningsdatauppsättningen i delmängder med hjälp av 10-faldig korsvalidering och utnyttja två BERT-inbäddningsmodeller. Vårt system rankades först i denna uppgift och förbättrade den genomsnittliga F1-poängen för alla deltagande lag med 19,07% med en precision, återkallande och F1 på testset på 83,75%, 87,01% respektive 85,35%.', 'uz': "Twitterda bir qiimal narsa bo'lgan qo'llangan ma'lumotlarning qiymatidir. Bu bir necha jamiyat tibbiyotlarida foydalanilgan. Bu ko'pchilikdagi birinchi qadam tibbiy narsa bilan Twitterning xabarlarini aniqlash va qabul qilish uchun. Bu maqolada, biz 2020 ish bilan bog'liq boshlangan sosial mediya dasturlari (SMM4H) vazifani qanday qanday qanday qilamiz. Bu vazifa o'qituvchilarini o'rganishga murakkab qiladi, asl, juda juda balandlik maʼlumotlar tarkibida tibbiy narsa yoki dietarlik qoʻshishlarini aniqlash uchun Twittlarni aniqlash uchun. Bizning tizimimiz 20 BERT asosida yaratilgan darajalar bilan birga qo'llab qo'llangan bir qadam bilan birlashtirilgan va ta'lim maʼlumotlar tarkibini 10 marta qo'llash va ikkita BERT bilan foydalanish mumkin. Bizning tizimmiz shu vazifani birinchi marta o'zgartirdi va hamma qismlarda qismlashtirilgan guruhlar soni 19.07% darajaga o'zgartirdi, aniqlik, va F1 faqat 83.75%, 87.01%, va 85.35%.", 'vi': 'Twitter là một nguồn đáng giá của những dữ liệu được tạo ra từ bệnh nhân đã được sử dụng trong nhiều nghiên cứu sức khỏe dân số. Bước đầu tiên trong nhiều nghiên cứu này là nhận diện và ghi nhận các thông điệp trên Twitter có chứa các loại thuốc nhắc đến. Trong bài báo này, chúng tôi mô tả sự tham gia của chúng tôi vào Nhiệm vụ lần đầu của Bộ truyền thông Xã hội ứng dụng sức khỏe (SMM44H) Nhiệm vụ chia sẻ 2020. Nhiệm vụ này đã thách thức các thành viên phát hiện tweet có liên quan đến các loại thuốc men hay bổ sung dinh dưỡng trong dữ liệu thiên nhiên, thiếu cân bằng cao. Hệ thống của chúng tôi kết hợp một bước khai thác sẵn tay với một kết hợp của các phân loại loại loại có nguồn gốc 20 BERT tạo ra bằng cách phân chia dữ liệu đào tạo thành nhóm dưới bằng cách sử dụng thuyết thập giá mười lần khai thác và khai thác hai mô hình. Hệ thống của chúng tôi xếp hạng đầu trong nhiệm vụ này, và nâng điểm F1 trung bình trên tất cả các đội có thể tham gia cùng với độ chính xác, gọi lại, và F1 trên phạm vi kiểm tra của 83', 'bg': 'Туитър е ценен източник на данни, генерирани от пациентите, които са използвани в различни проучвания за здравето на населението. Първата стъпка в много от тези проучвания е да се идентифицират и улавят съобщения в Туитър (туитове), съдържащи споменавания за лекарства. В тази статия описваме нашето представяне към Задача 1 на Споделената задача 2020 за минно дело в социалните медии за здравни приложения. Тази задача предизвика участниците да открият туитове, които споменават лекарства или хранителни добавки в естествен, силно дисбалансиран набор от данни. Нашата система комбинира ръчно изработена стъпка за предварителна обработка с ансамбъл от 20 базирани класификатори, генерирани чрез разделяне на набора от данни за обучение на подгрупи, използвайки 10-кратно кръстосано валидиране и използвайки два вграждащи модела. Системата ни се класира на първо място в тази задача и подобри средния резултат на всички участващи отбори с 19,07% с прецизност, изтегляне и Ф1 на тестовия набор съответно 83,75%, 87,01% и 85,35%.', 'da': 'Twitter er en værdifuld kilde til patientgenererede data, der er blevet brugt i forskellige folkesundhedsundersøgelser. Det første skridt i mange af disse undersøgelser er at identificere og fange Twitter-beskeder (tweets), der indeholder medicin omtaler. I denne artikel beskriver vi vores indsendelse til opgave 1 i Social Media Mining for Health Applications (SMM4H) delte opgave 2020. Denne opgave udfordrede deltagerne til at opdage tweets, der nævner medicin eller kosttilskud i et naturligt datasæt med stærk ubalance. Vores system kombinerede et håndlavet forbearbejdningstrin med et sæt af 20 BERT-baserede klassificeringsmodeller, der blev genereret ved at opdele træningsdatasættet i delmængder ved hjælp af 10-dobbelt krydsgodkendelse og udnytte to BERT-indlejringsmodeller. Vores system rangerede først i denne opgave og forbedrede den gennemsnitlige F1 score på tværs af alle deltagende hold med 19,07% med en præcision, tilbagekaldelse og F1 på testsættet på henholdsvis 83,75%, 87,01% og 85,35%.', 'hr': 'Twitter je vrijedan izvor podataka iz pacijenata koji se koristi u raznim ispitivanjima zdravstva stanovništva. Prvi korak u mnogim od tih ispitivanja je identificiranje i uhvatiti poruke Twitter-a (tweets) sadržajući spomenute lijekova. U ovom članku opisujemo svoj podatak zadatku 1 Socijalnog medija za rudarstvo zdravstvenih aplikacija (SMM4H) zajedničkog zadatka 2020. Ovaj zadatak je izazvao učesnike da otkriju tweet koji spominju lijekove ili dodatke hrane u prirodnoj, visokoj neslaganosti podataka. Naš sustav je kombinirao korak preobrađivanja rukama s ensemblom 20 klasifikatora osnovanih na BERT-u, koji je proizveden podjelom podataka obuke u podatke koristeći 10 puta ukrštenu validaciju i iskorištavajući dva modela integracije BERT-a. Naš sustav je prvi postignut u ovom zadatku, i poboljšao prosječni rezultat F1 u svim sudjelujućim timovima za 19,07% s preciznim, sjećanjem, i F1 na testu skupu 83,75%, 87,01%, te 85,35%.', 'nl': 'Twitter is een waardevolle bron van door patiënten gegenereerde gegevens die is gebruikt in verschillende populatiegezondheidsstudies. De eerste stap in veel van deze studies is het identificeren en vastleggen van Twitter berichten (tweets) die medicijnvermeldingen bevatten. In dit artikel beschrijven we onze inzending aan Task 1 van de Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Deze taak daagde deelnemers uit om tweets te detecteren die medicijnen of voedingssupplementen vermelden in een natuurlijke, zeer onbalans dataset. Ons systeem combineerde een handgemaakte preprocessing stap met een ensemble van 20-BERT-gebaseerde classificatoren, gegenereerd door de trainingsdataset te verdelen in subsets met behulp van 10-voudige kruisvalidatie en gebruik te maken van twee BERT-inbeddingsmodellen. Ons systeem scoorde als eerste in deze taak, en verbeterde de gemiddelde F1 score van alle deelnemende teams met 19,07% met een precisie, terugroeping en F1 op de testset van respectievelijk 83,75%, 87,01%, en 85,35% .', 'de': 'Twitter ist eine wertvolle Quelle von Patientendaten, die in verschiedenen Studien zur Bevölkerungsgesundheit verwendet wurden. Der erste Schritt in vielen dieser Studien besteht darin, Twitter-Nachrichten (Tweets) mit Medikamentenangaben zu identifizieren und zu erfassen. In diesem Artikel beschreiben wir unsere Einreichung an Task 1 des Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Diese Aufgabe forderte die Teilnehmer heraus, Tweets zu erkennen, die Medikamente oder Nahrungsergänzungsmittel in einem natürlichen Datensatz mit hohem Ungleichgewicht erwähnen. Unser System kombinierte einen handgefertigten Vorverarbeitungsschritt mit einem Ensemble von 20-BERT-basierten Klassifikatoren, die durch Aufteilung des Trainingsdatensatzes in Teilmengen mittels 10-facher Kreuzvalidierung und Nutzung von zwei BERT-Einbettungsmodellen generiert wurden. Unser System rangierte in dieser Aufgabe an erster Stelle und verbesserte die durchschnittliche F1-Punktzahl aller teilnehmenden Teams um 19,07% mit einer Präzision, Rückruf und F1 auf dem Testsatz von 83,75%, 87,01%, bzw. 85,35% .', 'id': 'Twitter adalah sumber yang berharga dari data yang dihasilkan oleh pasien yang telah digunakan dalam berbagai penelitian kesehatan populasi. Langkah pertama dalam banyak studi ini adalah untuk mengidentifikasi dan menangkap pesan Twitter (tweet) yang mengandung sebutan medis. Dalam artikel ini, kami menggambarkan pengiriman kami ke Tugas 1 dari Media Sosial Pertambangan untuk Aplikasi Kesehatan (SMM4H) Tugas Bersama 2020. Tugas ini menantang para peserta untuk mendeteksi tweet yang menyebutkan obat atau suplimen diet dalam set data yang tidak seimbang secara alami. Sistem kami menggabungkan langkah preproses buatan tangan dengan sebuah ensemble dari 20 klasifikasi berdasarkan BERT yang dihasilkan dengan membagi dataset latihan ke sub-set menggunakan validasi salib 10 kali dan mengeksploitasi dua model embedding BERT. Our system ranked first in this task, and improved the average F1 score across all participating teams by 19.07% with a precision, recall, and F1 on the test set of 83.75%, 87.01%, and 85.35% respectively.', 'ko': '트위터는 환자 생성 데이터의 귀중한 원천으로 다양한 사람들의 건강 연구에 사용되고 있다.많은 연구의 첫걸음은 약물에 대한 언급이 담긴 트위터 소식을 식별하고 포착하는 것이다.본고에서 우리는 건강 응용 소셜미디어 발굴(SMM4H)에 제출한 공유 임무 2020 임무 1의 상황을 묘사했다.이 임무는 참가자들이 약물이나 식이보충제에 대한 추문을 자연스럽고 고도로 불균형한 데이터에서 집중적으로 검출하도록 요구한다.우리 시스템은 수동으로 제작된 예처리 절차를 버트 기반 분류기 20개와 조합하여 10배의 교차 검증을 통해 훈련 데이터 집합을 서브집합으로 나누고 두 개의 버트 삽입 모델을 이용하여 생성한다.우리 시스템은 이 임무에서 1위를 차지했고 모든 참가팀의 F1 평균 득점은 19.07% 높아졌다. 테스트집의 정확도, 회상률과 F1 성적은 각각 83.75%, 87.01%와 85.35%였다.', 'fa': 'توئیتر منبع ارزشمند داده های تولید شده از بیماران است که در تحقیقات سلامتی مختلف مردم استفاده شده است. اولین قدم در بسیاری از این مطالعه\u200cها اینه که پیغام\u200cهای توئیتر (توئیت) را با مطالعه\u200cهای دارویی شناسایی و دستگیری کنیم. در این مقاله، ما تسلیم کردن ما به وظیفه ۱ رسانه اجتماعی برای کاربردهای سلامتی (SMM4H) مشترک کار ۲۰۰۲ را توصیف می\u200cکنیم. این وظیفه مشترک\u200cکنندگان را برای شناسایی توئیت\u200cهایی که داروها یا اضافه\u200cهای غذایی در یک مجموعه داده\u200cهای طبیعی، بسیار نابرابری می\u200cکنند چالش کرد. سیستم ما یک قدم پیش\u200cپردازشی دستهای ساخته شده با یک دسته\u200cای از ۲۰ گروه\u200cشناسی بنیاد BERT تولید شده با تقسیم داده\u200cهای آموزش به زیر گروه\u200cها با استفاده از ۱۰ بار تأثیر قانونی و استفاده از دو مدل\u200cهای پیوند BERT. سیستم ما اول در این وظیفه درجه گرفته بود، و در تمام تیم\u200cهای مشترک بین ۱۱ درجه با دقیق، یادآوری، و F1 در مجموعه آزمایش 83.75%، 87.01%، و 85.35%.', 'sw': 'Twita ni chanzo muhimu cha taarifa zinazozaliwa na wagonjwa ambazo zimetumiwa katika tafiti mbalimbali za afya ya watu. Hatua ya kwanza katika tafiti hizi ni kutambua na kuchukua ujumbe wa Twita (twiti) ambao una taja za madawa. Katika makala hii, tunaelezea ujumbe wetu wa kazi 1 wa Mitandao ya Kijamii Kufuatilia Mipango ya Afya (SMM4H) ilishirikisha kazi 2020. Kazi hii iliwagombea washiriki kutambua twiti ambazo zinataja madawa au vifaa vya chakula katika seti ya taarifa za asili za usawa. Mfumo wetu uliunganisha hatua ya upasuaji wa mikononi yenye mwangalizi wa wataalamu 20 wenye asili ya BERT iliyotengenezwa kwa kugawanya takwimu za mafunzo katika vipande vya kompyuta kwa kutumia usahihi wa mara 10 na kutumia mifano miwili ya BERT. Mfumo wetu ulikuwa wa kwanza katika kazi hii, na kuongezeka kiwango cha wastani cha F1 katika timu zote za ushiriki kwa asilimia 19.07 yenye urahisi, kukumbuka, na F1 kwa kiwango cha jaribio cha asilimia 83.75, asilimia 87.01, na asilimia 85.35.', 'tr': "Twitter hasaplanýan hasaplanýan hasaplanýan hasaplanýan çeşme. Bu okuwçylaryň köpüsi ilkinji adımy ilaç çykyşlaryny Twitter mesajlaryny tanamak we capturamak. Bu maksada, sosial Media Mining for Health Applications (SMM4H) Beýleki Görevlerimizi 2020-nji ýylda tarif edip görýäris. Bu zady nusgalary ýa-da tiýmit ilatyny ýa-da diýjek ilatyny beýleki, beýleki täsirlerden habarlanç hasaplamak üçin çykypdyr. Biziň sistemimiz, BERT'yň 20 sany diýilip taýýarlanan klasifikatçylar bilen elimden gelen öň-işleme adımlaryny 10-foldar geçirmek we iki BERT taýýarlama modellerini ulanyp birleşdirdi. Bizim sistemimiz bu görevimizde ilkinji derejle çykdy we ortalama F1 noktalaryny bütün partisipçiler tarapynda 19,07% derejli, hatırlatmak, hatırlatmak ve F1 testi düzeninde 83,75%, 87,01% we 85,35%-de geliştirdi.", 'af': "Twitter is 'n waardelike bron van pasiënt genereerde data wat gebruik is in verskeie populasie gesondige studie. Die eerste stap in baie van hierdie studie is om Twitter-boodskappe (tweets) te identifiseer en te vang wat medikasie bemenging bevat. In hierdie artikel beskrywe ons onderskrywing tot taak 1 van die sosiale mediamining vir gesondige toepassings (SMM4H) Gedeelde taak 2020. Hierdie taak het deelnaders uitgevaar om tweets te beskry wat medikasie of dietary-byvoegings in 'n natuurlike, baie ongelukkige datastel aanwys. Ons stelsel het gekombineer 'n handgebruikte voorafverwerking stap met 'n ensemble van 20 BERT-gebaseerde klassifiseerders genereer deur die onderwerking datastel in subartikels te deel deur 10-folde kruis geldigheid te gebruik en twee BERT-inbetering modele te gebruik. Ons stelsel het eerste in hierdie opdrag rangeer, en die gemiddelde F1 aantal verbeter oor alle gedeeltende teams met 19,07% met 'n presisie, herhaal en F1 op die toets stel van 83,75%, 87,01%, en 85,35%.", 'sq': 'Twitter është një burim i vlefshëm i të dhënave të gjeneruara nga pacientët që janë përdorur në studime të ndryshme shëndetësore të popullsisë. Hapi i parë në shumë nga këto studime është identifikimi dhe kapja e mesazheve të Twitter (Twitter) që përmbajnë përmendimet e ilaçeve. Në këtë artikull, ne përshkruajmë paraqitjen tonë në Task 1 të Social Media Mining for Health Applications (SMM4H) Task 2020. Kjo detyrë sfidoi pjesëmarrësit për të zbuluar tweetet që përmendin ilaçe apo suplimente ushqimore në një set të dhënash natyrore dhe të pakuilibrimit të lartë. Sistemi ynë kombinoi një hap paraprocesimi me dorë me një grup prej 20 klasifikuesve me bazë BERT të gjeneruar duke ndarë grupin e të dhënave të trajnimit në nëngrupe duke përdorur validim kryqësor 10 herë dhe duke shfrytëzuar dy modele të përfshirjes BERT. Sistemi ynë u rendit i pari në këtë detyrë dhe përmirësoi rezultatin mesatar të F1 në të gjitha ekipet pjesëmarrëse me 19.07% me një saktësi, kujtim dhe F1 në grupin e testimeve 83.75%, 87.01% dhe 85.35% respektivisht.', 'am': 'ትዊተር በብዙ የሕዝብ ጤና ትምህርት ውስጥ የተጠቀም የሆኑት የዳታ ዋጋ ምንጭ ነው፡፡ በዚህ በብዙ ትምህርት ውስጥ የመጀመሪያው እርምጃዎች ማወቅ እና የጤክም ማስታወሻ የሚኖረውን ትዊተር መልእክቶችን (twitter) ለማግኘት ነው፡፡ በዚህ ጽሑፍ ውስጥ ለጤና ፕሮግራሞች (SMM4H) ስራ 2020 የተሰራጨውን ለማኅበራዊ ሚዲያ አሳብ ለማድረግ ስራ 1 እናሳውቃለን፡፡ ይህ ስራ ተጋሪዎችን በአካባቢ፣ የበዛ የደካማ እና የፍጥረት እና የጥብቀት ጥያቄ ማግኘት ትዊተቶችን ለማግኘት አቃውሎ ነበር፡፡ የሥርዓታችን ስርዓት የሀያ BERT-መሠረት ክፍተቶችን በሥር እጥፍ መስቀል የሚያስተካክል እና ሁለት BERT አካባቢ ሞዴላዎችን በመጠቀም የተለየ ሁለት እጥፍ መስኮት በተለየ አካባቢዎች አካባቢ ነው፡፡ ስርዓታችን አስቀድሞ በዚህ ስራ ላይ ደረጃ ነበር፤ የጋዜጠኞች ቡድን ሁሉ አካባቢ የF1 ደረጃ ቁጥር በቁጥጥር 19.07 በመቶ እና F1 በተፈተና 83.75 በመቶ፣ 87.01 በመቶ እና 85.35 በመቶ ያሳመረ ነበር፡፡', 'hy': 'Թվիթերը հիվանդների կողմից ստեղծված տվյալների արժեքավոր աղբյուր է, որը օգտագործվել է բնակչության առողջապահության տարբեր ուսումնասիրություններում: Այս ուսումնասիրություններից շատերի առաջին քայլն այն է, որ հայտնաբերենք և ձայնագրենք Թվիթերի հաղորդագրությունները, որոնք պարունակում են դեղամիջոցներ: Այս հոդվածի մեջ մենք նկարագրում ենք մեր ներկայացումը Առողջապահության ծրագրերի սոցիալական լրատվամիջոցների (SMM4H) համագործակցած 2020-ի առաջին խնդիրը: This task challenged participants to detect tweets that mention medications or dietary supplements in a natural, highly imbalance dataset.  Մեր համակարգը համադրեց ձեռքով պատրաստված նախամշակման քայլը 20 BERT-ի հիմնված դասակարգչի համակարգի հետ, որը ստեղծվել է պատրաստման տվյալների համակարգի բաժանելով տասը անգամ խաչը հավասարման միջոցով և օգտագործելով երկու BERT-ի ներգրավման մոդելներ Մեր համակարգը առաջինը դասակարգվեց այս խնդրի մեջ և բարելավեց F1-ի միջին գնահատականը բոլոր մասնակցում գտնվող թիմերի ընթացքում 19.07 տոկոսով, ճշգրտությամբ, հիշողությամբ, և F1-ը փորձարկումների ընթացքում, հարաբերաբար, 8375 տոկոսով', 'az': 'Twitter müxtəlif nüfus sağlığı təhsimlərində istifadə edilən səbir təhsimlərinin qiymətli mənbəsidir. Bu təhsillərdən çox ilk adım, Tövrat ismarışlarını təsdiqləmək və tutmaq idi. Bu məlumatda, biz 2020-ci şəkildə paylaşılan Cənnət Mədyənin Sağlamlıq Uygulamalarının (SMM4H) 1-sini təsdiqlədiyimizi təsdiqləyirik. Bu işlər təbiətli, çox müqayisədə verilən məlumatlarda ilaçlar və yemək ilaçlarını söyləyən tweetləri keşfetmək üçün müvəffəq etdi. Sistemimiz 10-fold qarşılıqlı təsdiqləmə və iki BERT içərisində olan modelləri ilə yaratdığı 20 BERT tabanlı klasifikatçıları ilə birləşdirdi. Sistemimiz bu işlərdə ilk dərəcədə səf çəkdi və bütün iştirakçı takımların arasında ortalama F1 dərəcəsini 19,07%-ə düzəltdi. Təsdiq dərəcəsində 83,75%, 87,01%, və 85,35%-ə düzəltdi.', 'ca': "Twitter is a valuable source of patient-generated data that has been used in various population health studies.  The first step in many of these studies is to identify and capture Twitter messages (tweets) containing medication mentions.  En aquest article, descrivim la nostra presentació a la primera tasca de la Miniera dels mitjans socials per aplicacions sanitàries (SMM4H) Task 2020 compartida. Aquesta tasca va desafiar als participants detectar tweets que mencionen medicaments o suplements dietàtics en un conjunt de dades naturals i altament desequilibrats. El nostre sistema va combinar un pas de preprocessió artificial amb un conjunt de 20 classificadors basats en BERT generats dividint el conjunt de dades d'entrenament en subconjunts utilitzant una validació cruzada de 10 vegades i explotant dos models d'incorporació BERT. El nostre sistema es va classificar primer en aquesta tasca, i va millorar la mitjana de puntuació F1 en tots els equips participants en un 19,07% amb precisió, recordació i F1 en el conjunt de provas de 83,75%, 87,01% i 85,35%, respectivament.", 'bn': 'টুইটার একটি মূল্যবান উৎস, যা বিভিন্ন জনস্বাস্থ্য গবেষণায় ব্যবহৃত হয়েছে। এই অনেক গবেষণায় প্রথম পদক্ষেপ হচ্ছে টুইটার বার্তাকে চিহ্নিত করা এবং গ্রেফতার করার (টুইট) যার মধ্যে মেডিকেশনে In this article, we describe our submission to Task 1 of the Social Media Mining for Health Applications (SMM4H) Shared Task 2020.  এই কাজের অংশগ্রহণকারীদের চ্যালেঞ্জ করেছে টুইট খুঁজে বের করার জন্য যারা স্বাভাবিক, অত্যন্ত অসম্পূর্ণ বৈষম্যের ডা আমাদের সিস্টেম একটি হাতের হাতে প্রক্রিয়ার পদক্ষেপ সংযুক্ত করেছে যা ২০ বার্টি-ভিত্তিক শ্রেণীবিদের সাথে তৈরি করেছে এবং ট্রেনিং ডাটাসেট বিভক্ত করে ১০ আমাদের সিস্টেম এই কাজে প্রথম ভাগ করেছে এবং সকল অংশগ্রহণকারীদের সারা ফি১ স্কোর ১৯. ০৭% পরীক্ষার পরীক্ষায় ৮৩. ৭৫%, ৮৭. 01%, এবং ৮৫.', 'cs': 'Twitter je cenným zdrojem dat generovaných pacienty, které byly použity v různých populačních studiích zdraví. Prvním krokem v mnoha těchto studiích je identifikace a zachycení Twitterových zpráv (tweetů) obsahujících zmínky o lécích. V tomto článku popisujeme náš příspěvek k Úkolu 1 Sociální média Mining for Health Applications (SMM4H) Shared Task 2020. Tento úkol vyzval účastníky k detekci tweetů, které zmiňují léky nebo doplňky stravy v přirozeném datovém souboru s vysokou nerovnováhou. Náš systém kombinoval ručně vytvořený krok předzpracování s souborem 20klasifikátorů založených na BERT generovaným rozdělením tréninkové sady do podmnožin pomocí desetinásobné křížové validace a využitím dvou modelů BERT vkládání. Náš systém se v tomto úkolu dostal na první místo a zlepšil průměrné skóre F1 u všech zúčastněných týmů o 19,07% s přesností, odvoláním a F1 na testovací sadě 83,75%, 87,01%, resp. 85,35% .', 'bs': 'Twitter je vrijedan izvor podataka od pacijenata koji se koristi u raznim ispitivanjima zdravstva stanovništva. Prvi korak u mnogim od tih ispitivanja je identifikacija i uhvatiti Twitter poruke (tweets) koji sadrže spomenute lijekova. U ovom članku opisujemo svoj podatak zadatku 1 Socijalnog medijskog rudarstva za aplikacije zdravlja (SMM4H) zajedničkog zadatka 2020. Ovaj zadatak je izazvao učesnike da otkriju tweet koji spominju lijekove ili dodatke za hranu u prirodnom, visoko nelegalnom kompletu podataka. Naš sistem je kombinirao korak za preobradivanje ruku sa ensemblom 20 klasifikatora baziranih na BERT-u koji je proizveden podjelom podataka za obuku u podatke koristeći 10 puta ukrštenu validaciju i iskorištavajući dva modela integracije BERT-a. Naš sistem je prvi put bio u ovom zadatku, i poboljšao prosječni rezultat F1 u svim sudionicima za 19,07% sa preciznim, sjećanjem i F1 na test skupini 83,75%, 87,01%, i 85,35%.', 'et': 'Twitter on väärtuslik patsientide loodud andmete allikas, mida on kasutatud erinevates rahvastiku tervise uuringutes. Paljude nende uuringute esimene samm on tuvastada ja jäädvustada Twitteri sõnumid (säutsud), mis sisaldavad ravimite mainimist. Selles artiklis kirjeldame oma esitamist sotsiaalmeedia kaevandamise tervise rakenduste jaoks (SMM4H) jagatud ülesandele 1. See ülesanne kutsus osalejaid avastama säutsud, mis mainivad ravimeid või toidulisandeid looduslikus väga tasakaalustamatuse andmekogumis. Meie süsteem kombineeris käsitööna valmistatud eeltöötluse etapi 20 BERT-põhise klassifikaatoriga, mis moodustati koolitusandmete jagamisel alamhulkideks, kasutades 10-kordset ristvalideerimist ja kasutades kahte BERT-i manustamismudelit. Meie süsteem oli selles ülesandes esimesel kohal ja parandas kõigi osalevate meeskondade keskmist F1 skoori 19,07%, täpsuse, tagasikutsumise ja F1 testikomplektis vastavalt 83,75%, 87,01% ja 85,35%.', 'fi': 'Twitter on arvokas potilasl채ht철isen datan l채hde, jota on k채ytetty useissa v채est철terveystutkimuksissa. Ensimm채inen askel monissa n채ist채 tutkimuksista on tunnistaa ja tallentaa Twitter-viestit (tweetit), jotka sis채lt채v채t l채채kityst채. T채ss채 artikkelissa kuvailemme teht채v채채mme 1 Social Media Mining for Health Applications (SMM4H) Shared Task 2020. T채m채 teht채v채 haastoi osallistujat havaitsemaan tweetit, joissa mainitaan l채채kkeit채 tai ravintolisi채 luonnollisessa, eritt채in ep채tasapainoisessa aineistossa. J채rjestelm채mme yhdisti k채sity철n채 tehdyn esik채sittelyvaiheen 20 BERT-pohjaisen luokittelijan muodostamaan kokonaisuuteen, joka syntyi jakamalla koulutusaineisto osajoukkoihin k채ytt채m채ll채 10-kertaista ristikk채isvalidointia ja hy철dynt채m채ll채 kahta BERT-upotusmallia. J채rjestelm채mme sijoittui ensimm채isen채 t채ss채 teht채v채ss채 ja paransi kaikkien osallistuvien joukkueiden keskim채채r채ist채 F1-pistett채 19,07 prosentilla tarkkuudella, takaisinvedolla ja F1:ll채 testisarjassa 83,75%, 87,01% ja 85,35%.', 'ha': "Twitter is a valuable source of patient-generated data that has been used in various population health studies.  Babbata farkon da ke cikin masu yawa daga tafiti, yana gane kuma ana kãma jumuin Twitter (Twitter) wanda yana da ambaton dawada. A cikin wannan makala, munã describe sallama zuwa Tafiyar 1 of the Socic Media Mining for Header Applications (SMM4H) Shared Taimar 2020. Wannan aikin na musamma wa mãsu haɗa da shi dõmin su gane Twitter waɗanda ke ambatar dawada ko kuma addinda ake ci da abinci cikin tsarin bayani na asali, mai girma da balanci. Tsarinmu ya haɗa wata hanyor aiki da hannayenmu ta sami da wata samfanel na danganta 20 BERT-da aka danne shi da ya raba danahan na tsarin kuma ya yi amfani da misãlai biyu masu shiga BERT. SisteminMu ya ranar ta farko a cikin wannan aikin, kuma ya kyautata nau'in F1 kowace jama'a na haɗi jama'a duk jama'a 19.07, da hakki, kuma F1 a sami jarrabar nau'in 83.7%, 87.01%, da kuma 85.35%.", 'jv': 'Tom kuwi kelas sing perusahaan kelas kuwi kapan-kapan dadi sing rumangsa oleh dumateng kapan winih. Ketoke perusahaan ing akeh akeh sing sampeyan iki dadi melu lan nganggo perusahaan mripat Nang artik iki, kita ngubah tanggal nggawe Tarjamahan 1 ning Ndang Media Ming kanggo Aplikasi Saasar (SMM4H) sing berarti task 2020 Digawe System Sistem-sistem sing ditambah tanggal uwong ing nggawe iki, lan lagi nglanggar popularan kanggo kalah-popularan sing nêmên, 19.2007% sing dirampakan, nambah, lan F1 sing ditambah sekolahan liyane, ujaran oleh-ujaran liyane', 'he': 'טוויטר הוא מקור ערך של נתונים יוצרים על ידי מטופלים שהשתמשו במחקרים בריאות אוכלוסיות שונים. הצעד הראשון ברבים מהמחקרים האלה הוא לזהות ולתפוס הודעות טוויטר (טוויטרים) שמכילות זיכרונות תרופות. במאמר הזה, אנחנו מתארים את ההעברה שלנו למשימה 1 של מחקר מדיה חברתית לתוכניות בריאות (SMM4H) משימה משותפת 2020. המשימה הזו איגרה את השתתפים לגלות טוויטים שמזכירים תרופות או תוספי דיאטה בסט נתונים של אי-איזון טבעי. המערכת שלנו שילבה צעד מערכת התהליך הימנית עם אסמפל של 20 מסמכים מבוססים על BERT שנוצרים על ידי לחלק את קבוצת נתונים האימונים לתחתונים בשימוש באישור צלב 10 פעמים ולניצל שני דוגמנים של תוכנית BERT. המערכת שלנו התייצבה ראשונה במשימה הזאת, ושיפרה את נקודת F1 הממוצעת בכל הקבוצות המשתתפות ב-19.07% עם מדויקה, זיכרון, ו-F1 בסט הבדיקות של 83.75%, 87.01% ו-85.35% בהתאם.', 'sk': 'Twitter je dragocen vir podatkov, ki jih ustvarijo bolniki in so jih uporabljali v različnih študijah zdravstvenega varstva populacije. Prvi korak v številnih od teh študij je prepoznavanje in zajemanje Twitterjevih sporočil (tweets), ki vsebujejo omembe zdravil. V tem članku opisujemo našo predložitev nalogi 1 skupne naloge za rudarjenje v socialnih omrežjih za zdravstvene aplikacije (SMM4H) 2020. Ta naloga je udeležence izzvala k zaznavanju tweetov, ki omenjajo zdravila ali prehranska dopolnila v naravnem naboru podatkov o zelo neravnovesju. Naš sistem je združil ročno izdelan korak predobdelave s kompletom 20 klasifikatorjev na podlagi BERT, ki so bili ustvarjeni z razdelitvijo nabora podatkov o usposabljanju na podnabore z uporabo 10-kratnega navzkrižnega preverjanja in izkoriščanjem dveh modelov vključevanja BERT. Naš sistem se je uvrstil na prvo mesto v tej nalogi in izboljšal povprečni rezultat F1 vseh sodelujočih ekip za 19,07% z natančnostjo, odpoklicem in F1 na testnem nizu 83,75%, 87,01% oziroma 85,35%.', 'bo': 'ཌིས་ཌིར་ནི་སྐྱེས་པ་ཅིག་གིས་རྒྱ་ནག་གི་མི་འབོར་སྐྱེས་པའི་གནས་ཚུལ་གསལ་བཅས་ཅིག་རེད། འདི་ལས་བརྗོད་ཐོག་ནང་གི་གྲངས་སུ་ཐོག་མའི་གྲངས་ཀ་འདི་ཌིས་ཌིར་གྱི་འཕྲིན་ཡིག་ཆ་གསར་འཛུགས་དང་captur་ དགོས་པ་རེད། ང་ཚོས་རྩིས་ཐོག་འདིའི་ནང་དུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་འཇུག་ཟམ་གྱི་ བྱ་འགུལ་གྱི་དོན་ལྡན་༡(SMM4H)དང་མཉམ་སྤྱོད་ཀྱི་ལས་ བྱ་འགུལ་འདིས་མཉམ་དུ་གདོང་ལེན་བྱེད་མཁན་ཚོས་རང་བཞིན་གྱི་སྨན་རྟགས་དང་འཛམ་གླིང་གི་ཆ་སྐྱེས་སྤྱོད་སྤྲོད་ཀྱི་ནང Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models. ང་ཚོའི་མ་ལག'}
{'en': 'SMM4H Shared Task 2020-A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter :  Machine Learning ,  Deep Learning , and Post-Processing SMM 4 H  Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from  T witter: Machine Learning, Deep Learning, and Post-Processing', 'ar': 'SMM4H Shared Task 2020 - خط أنابيب هجين لتحديد إساءة استخدام العقاقير الطبية من Twitter: التعلم الآلي والتعلم العميق والمعالجة اللاحقة', 'fr': "Tâche partagée SMM4H 2020 - Un pipeline hybride pour identifier l'abus de médicaments sur ordonnance à partir de Twitter\xa0: apprentissage automatique, apprentissage profond et post-traitement", 'es': 'Tarea compartida de SMM4H 2020: un canal híbrido para identificar el abuso de medicamentos recetados desde Twitter: aprendizaje automático, aprendizaje profundo y procesamiento posterior', 'pt': 'Tarefa compartilhada SMM4H 2020 - Um pipeline híbrido para identificar o abuso de medicamentos prescritos no Twitter: aprendizado de máquina, aprendizado profundo e pós-processamento', 'ja': 'SMM 4 H共有タスク2020 - Twitterから処方薬乱用を識別するためのハイブリッドパイプライン：機械学習、ディープラーニング、および後処理', 'zh': 'SMM4H 2020年共同任务 - 以识Twitter处方药滥用混合管道:机器学,深学后处理', 'hi': 'SMM4H साझा कार्य 2020 - चहचहाना से पर्चे दवा के दुरुपयोग की पहचान करने के लिए एक हाइब्रिड पाइपलाइन: मशीन लर्निंग, डीप लर्निंग, और पोस्ट-प्रोसेसिंग', 'ru': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identification Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'ga': 'Tasc Comhroinnte SMM4H 2020 - Píblíne Hibrideach chun Mí-Úsáid Drugaí ar Oideas a Aithint ó Twitter: Foghlaim le Meaisín, Foghlaim dhomhain, agus Iarphróiseáil', 'ka': 'SMM4H shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'el': 'Κοινή εργασία 2020.Ένας υβριδικός αγωγός για τον εντοπισμό της κατάχρησης συνταγογραφούμενων φαρμάκων από το Twitter: Μηχανική Μάθηση, Βαθιά Μάθηση και Μεταεπεξεργασία', 'hu': 'SMM4H Megosztott feladat 2020 - Hibrid csővezeték a Twitterről történő visszaélés azonosítására: gépi tanulás, mélytanulás és utófeldolgozás', 'it': "SMM4H Shared Task 2020 - Una pipeline ibrida per identificare l'abuso di droghe su prescrizione da Twitter: apprendimento automatico, apprendimento profondo e post-elaborazione", 'kk': 'SMM4H Ортақ тапсырма 2020 - Твиттерден шығару құрылғысын идентификациялау үшін гибрид пипелин: Машин оқыту, ділік оқыту және кейін өткізу', 'lt': 'SMM4H bendroji užduotis 2020 m. – hibridinis vamzdynas, skirtas nustatyti narkotikų piktnaudžiavimą pagal receptus iš Twitter: mašinų mokymasis, gilus mokymasis ir apdorojimas po apdorojimo', 'mk': 'SMM4H заедничка задача 2020 - Хибриден цевк за идентификување на препишана злоупотреба на дрога од Твитер: машинско учење, длабоко учење и постпроцесирање', 'ms': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'mt': 'Xogħol Konġunt tal-SMM4H 2020 - Pipeline ibrida għall-identifikazzjoni tal-abbuż tal-mediċina bil-preskrizzjoni minn Twitter: Tagħlim bil-Magni, Tagħlim fil-fond, u Post-Proċessar', 'ml': 'SMM4H പങ്കുചേര്\u200dത്ത ജോലി 2020 - ടൂട്ടരില്\u200d നിന്നുള്ള മെഷിന്\u200d മരുന്നുപാതകം തിരിച്ചറിയാന്\u200d ഒരു ഹൈബ്രിഡ് പൈപ്പെലിന്\u200d: മെഷീന്\u200d പഠിക്കുന', 'mn': 'SMM4H Холбоотой ажил 2020 - Твиттерээс дарааллын эм зэвсэг хэрэглэх Hybrid Pipeline: Машин суралцах, гүн суралцах, эцэст нь ажиллах', 'pl': 'SMM4H Shared Task 2020.Hybrydowy rurociąg do identyfikacji nadużywania leków na receptę z Twittera: uczenie maszynowe, głębokie uczenie się i postprocesing', 'sr': 'SMM4H zajednièki zadatak 2020 - Hibridna prašina za identifikaciju zlostavljanja lijeka za preskripce iz Twitter: Nauèenje mašina, duboko učenje i posle procesa', 'no': 'Name', 'ro': 'SMM4H Sarcină partajată 2020 - O conductă hibridă pentru identificarea abuzului de medicamente pe bază de prescripție medicală de pe Twitter: învățare automată, învățare profundă și post-procesare', 'si': 'SMM4H ශාමිත කාර්ය 2020යි - A hybri Pipeline for ID Prescription Drug Abuse from Twitter: machine Training, Deep Training, and Post-processing', 'so': 'SMM4H Shared Shaqo 2020 - A Hybrid Pipeline for Identification Rug isticmaalka dhaqdhaqaaqa ee Twitterka: Machine Learning, Deep Learning, and Post Processing', 'ta': 'SMM4H பகிர்ந்த பணி', 'sv': 'SMM4H delad uppgift 2020 - En hybrid pipeline för att identifiera receptbelagda drogmissbruk från Twitter: maskininlärning, djupinlärning och efterbehandling', 'ur': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'vi': 'SMM24H sẻ chia Nhiệm vụ 2020- Một đường ống truyền nhân tạo để xác định áp dụng thuốc của người kê trên Twitter: máy để học, học sâu, và tái chế thuốc phiện.', 'uz': 'Name', 'bg': 'Споделена задача 2020 - Хибриден тръбопровод за идентифициране на злоупотребата с лекарствени продукти по рецепта от машинно обучение, задълбочено обучение и следобработка', 'hr': 'SMM4H zajednički zadatak 2020 - Hibridna prašina za identifikaciju zlostavljanja lijeka pripisivanja iz Twitter: učenje strojeva, duboko učenje i nakon postizanja', 'nl': 'SMM4H Shared Task 2020.Een hybride pijplijn voor het identificeren van misbruik van voorgeschreven geneesmiddelen vanaf Twitter: Machine Learning, Deep Learning en Post-Processing', 'da': 'SMM4H delt opgave 2020 - En hybrid pipeline til identificering af receptpligtigt stofmisbrug fra Twitter: Machine Learning, Deep Learning og efterbehandling', 'de': 'SMM4H Shared Task 2020.Eine hybride Pipeline zur Identifizierung des Missbrauchs von verschreibungspflichtigen Medikamenten von Twitter: Maschinelles Lernen, Deep Learning und Post-Processing', 'ko': 'SMM4H 공유 임무 2020 - 트위터에서 처방약 남용을 식별하는 혼합 파이프: 기계 학습, 심도 있는 학습과 후처리', 'id': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'sw': 'SMM4H ilishiriki kazi 2020 - Pili ya Hybrid kwa ajili ya kutambua matumizi ya dawa ya Udhalilishaji wa Nadha kutoka Twita: Kufundisha Mashine, Kufundisha Kuzidi Ufunzi, na Baada ya Kutangaza', 'fa': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'tr': 'SMM4H Paýlaşdy Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'af': "SMM4H Gedeelde Opdrag 2020 - 'n Hybrid Pipeline vir identifiseer van preskripte Drug Abuse van Twitter: Masjien Leer, Deep Leer en Post-Proses", 'sq': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning and Post-Processing', 'am': 'SM4H ስራውን 2020 - የHybrid Pipeline ከTwitter የሕፃፍ Drug Abuse ለማግኘት: መኪን ትምህርት፣ ጥልቅ ትምህርት እና post-Processing', 'hy': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'bn': 'টুইটার থেকে নির্ধারণ করার জন্য একটি হাইব্রিড পাইপেলাইন: মেশিন শিক্ষা, গভীর শিক্ষা এবং প্রক্রিয়া', 'az': 'SMM4H paylaşılmış Task 2020 - Tövratdakı preskripci uyuşturucu istifadə etmək üçün Hybrid Pipeline: Machine Learning, Deep Learning, and Post Processing', 'bs': 'SMM4H zajednički zadatak 2020 - Hibridna prašina za identifikaciju zlostavljanja lijeka pripisivanja iz Twitter: Naučenje strojeva, duboko učenje i nakon procesa', 'ca': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing', 'cs': 'SMM4H Sdílený úkol 2020.Hybridní potrubí pro identifikaci zneužívání léků na předpis z Twitteru: strojové učení, hluboké učení a post-processing', 'et': 'SMM4H ühine ülesanne 2020 - hübriidne juhtmestik retseptiravimite kuritarvitamise tuvastamiseks Twitterist: masinõpe, sügavõpe ja järeltöötlus', 'fi': 'SMM4H Jaettu tehtävä 2020 - hybridiputki reseptilääkkeiden väärinkäytön tunnistamiseksi Twitteristä: koneoppiminen, syväoppiminen ja jälkikäsittely', 'jv': 'SMM4H', 'he': 'SMM4H משימה משותפת 2020 - צינור היברידי לזהות התעללות בסמים מתוך טוויטר:', 'sk': 'Skupna naloga SMM4H 2020 - hibridni vodovod za prepoznavanje zlorabe zdravil na recept iz Twitterja: strojno učenje, globoko učenje in post-procesiranje', 'ha': '@ info: whatsthis', 'bo': 'SMM4H Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter: Machine Learning, Deep Learning, and Post-Processing'}
{'en': 'This paper presents our approach to multi-class text categorization of  tweets  mentioning prescription medications as being indicative of potential abuse / misuse (A), consumption / non-abuse (C), mention-only (M), or an unrelated reference (U) using natural language processing techniques. Data augmentation increased our  training and validation corpora  from 13,172 tweets to 28,094 tweets. We also created word-embeddings on domain-specific social media and medical corpora. Our hybrid pipeline of an attention-based CNN with  post-processing  was the best performing system in task 4 of SMM4H 2020, with an  F1 score  of 0.51 for class A.', 'ar': 'تقدم هذه الورقة نهجنا لتصنيف نصوص متعددة الفئات للتغريدات مع ذكر الأدوية الموصوفة على أنها مؤشر على إساءة استخدام / سوء استخدام محتمل (أ) ، أو استهلاك / عدم إساءة استخدام (ج) ، أو ذكر فقط (م) ، أو مرجع غير ذي صلة (يو ) باستخدام تقنيات معالجة اللغة الطبيعية. أدت زيادة البيانات إلى زيادة هيئة التدريب والتحقق لدينا من 13،172 تغريدة إلى 28،094 تغريدة. أنشأنا أيضًا حفلات تضمين الكلمات على وسائل التواصل الاجتماعي الخاصة بالمجال والشركات الطبية. كان خط الأنابيب الهجين الخاص بنا لشبكة CNN القائمة على الانتباه والمعالجة اللاحقة هو أفضل نظام أداء في المهمة 4 من SMM4H 2020 ، مع درجة F1 من 0.51 للفئة A.', 'es': 'Este artículo presenta nuestro enfoque para la categorización de textos de múltiples clases de tuits que mencionan medicamentos recetados como indicativos de posible abuso/uso indebido (A), consumo/no abuso (C), solo mención (M) o una referencia no relacionada (U) mediante técnicas de procesamiento del lenguaje natural. El aumento de datos aumentó nuestros corpus de capacitación y validación de 13 172 tuits a 28 094 tuits. También creamos incrustaciones de palabras en redes sociales y cuerpos médicos específicos del dominio. Nuestro pipeline híbrido de una CNN basada en la atención con posprocesamiento fue el sistema con mejor desempeño en la tarea 4 de SMM4H 2020, con una puntuación F1 de 0.51 para la clase A.', 'fr': "Cet article présente notre approche de la catégorisation de textes multi-classes de tweets mentionnant des médicaments sur ordonnance comme indiquant un abus potentiel (A), une consommation/non-abus (C), une mention uniquement (M) ou une référence non liée (U) à l'aide de techniques de traitement du langage naturel. L'augmentation des données a fait passer nos corpus de formation et de validation de 13 172 tweets à 28 094 tweets. Nous avons également créé des intégrations de mots sur les réseaux sociaux et les corpus médicaux spécifiques à un domaine. Notre pipeline hybride d'un CNN axé sur l'attention avec post-traitement était le système le plus performant pour la tâche 4 du SMM4H 2020, avec un score F1 de 0,51 pour la classe A.", 'pt': 'Este artigo apresenta nossa abordagem para a categorização de texto multiclasse de tweets que mencionam medicamentos prescritos como indicativos de potencial abuso/uso indevido (A), consumo/não abuso (C), apenas menção (M) ou uma referência não relacionada (U ) usando técnicas de processamento de linguagem natural. O aumento de dados aumentou nossos corpora de treinamento e validação de 13.172 tweets para 28.094 tweets. Também criamos incorporações de palavras em mídias sociais específicas de domínio e corpora médicos. Nosso pipeline híbrido de uma CNN baseada em atenção com pós-processamento foi o sistema com melhor desempenho na tarefa 4 do SMM4H 2020, com pontuação F1 de 0,51 para classe A.', 'ja': '本稿では、自然言語処理技術を使用して、潜在的な乱用/誤用（ A ）、消費/非乱用（ C ）、言及のみ（ M ）、または無関係な参照（ U ）を示す処方薬に言及するツイートの多クラステキスト分類に対する当社のアプローチを紹介します。データ拡張により、トレーニングと検証コーポラルが13,172ツイートから28,094ツイートに増加しました。また、ドメイン固有のソーシャルメディアや医療法人にもワード埋め込みを作成しました。後処理を伴う注意力ベースのCNNの当社のハイブリッドパイプラインは、クラスAのF 1スコアが0.51であるSMM 4 H 2020のタスク4で最高のパフォーマンスを発揮したシステムでした。', 'zh': '本文引我辈多类文本分类之法,推文明潜滥/误用(A),消费/非滥(C),但及(M)用自然语言术者不关参(U)。 据增我培训验语料库从 13,172 条推文加至 28,094 条推文。 特定域社交媒体医语料库上创词嵌。 凡治CNN后期,管道SMM4H 2020务4中性能至统,A级F1为0.51。', 'hi': 'यह पेपर संभावित दुरुपयोग / दुरुपयोग (ए), खपत / गैर-दुरुपयोग (सी), केवल उल्लेख -केवल (एम), या प्राकृतिक भाषा प्रसंस्करण तकनीकों का उपयोग करके एक असंबंधित संदर्भ (यू) के संकेत के रूप में पर्चे दवाओं का उल्लेख करते हुए ट्वीट्स के बहु-वर्ग पाठ वर्गीकरण के लिए हमारे दृष्टिकोण को प्रस्तुत करता है। डेटा वृद्धि ने हमारे प्रशिक्षण और सत्यापन निगम को 13,172 ट्वीट्स से 28,094 ट्वीट्स तक बढ़ा दिया। हमने डोमेन-विशिष्ट सोशल मीडिया और मेडिकल कॉर्पोरेट पर शब्द-एम्बेडिंग भी बनाई है। पोस्ट-प्रोसेसिंग के साथ एक ध्यान-आधारित सीएनएन की हमारी हाइब्रिड पाइपलाइन SMM4H 2020 के कार्य 4 में सबसे अच्छा प्रदर्शन करने वाली प्रणाली थी, जिसमें कक्षा ए के लिए 0.51 का एफ 1 स्कोर था।', 'ru': 'В этой статье представлен наш подход к многоклассовой классификации текстов твитов, в которых упоминаются рецептурные лекарственные препараты, как указывающие на потенциальное злоупотребление/неправильное использование (A), потребление/не злоупотребление (C), только упоминание (M) или несвязанную ссылку (U) с использованием методов обработки на естественном языке. Расширение данных увеличило наши тренинговые и валидационные корпорации с 13 172 твитов до 28 094 твитов. Мы также создали текстовые вставки в социальных сетях и медицинских корпорациях, относящихся к конкретным доменам. Наш гибридный конвейер CNN на основе внимания с пост-обработкой был лучшей системой в задаче 4 SMM4H 2020 с оценкой F1 0,51 для класса A.', 'ga': 'Cuireann an páipéar seo i láthair ár gcur chuige maidir le catagóiriú téacs ilranga tweets ina luaitear cógais ar oideas mar tháscaire ar mhí-úsáid/mí-úsáid fhéideartha (A), tomhaltas/neamh-mhí-úsáid (C), tagairt amháin (M), nó tagairt neamhghaolmhar (U). ) ag baint úsáide as teicnící próiseála teanga nádúrtha. Mhéadaigh breisiú sonraí ár gcorpas oiliúna agus bailíochtaithe ó 13,172 tvuít go 28,094 tvuít. Chruthaíomar freisin leabú focal ar na meáin shóisialta a bhaineann go sonrach le fearann agus le corpora leighis. Ba é ár bpíblíne hibrideach de CNN aird-bhunaithe le hiarphróiseáil an córas ab fhearr i dtasc 4 de SMM4H 2020, le scór F1 de 0.51 d’aicme A.', 'ka': 'ეს დომენტი ჩვენი მოხმარება მრავალკლასის ტექსტის კატეგორიზაციაში, რომელიც პრესკრიპტის მედიციაციების შესახებ, რომელიც შესაძლებელი გამოყენება/არასწორად გამოყენება (A), გამოყენება/არასწორად გამოყენება (C), მხოლოდ ამ Data augmentation increased our training and validation corpora from 13,172 tweets to 28,094 tweets. ჩვენ ასევე შევქმნით სიტყვების შემდეგ სოციალური მედია და მედიციური კოპორაში. ჩვენი ჰიბრიტური გარეშე CNN-ს, რომელიც შემდეგ გარეშე იყო საუკეთესო სისტემა SMM4H 2020-ის სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო, რომელიც A კლასის F1', 'el': 'Η παρούσα εργασία παρουσιάζει την προσέγγισή μας στην κατηγοριοποίηση κειμένων πολλαπλών κλάσεων που αναφέρουν συνταγογραφούμενα φάρμακα ως ενδεικτικά πιθανής κατάχρησης/κατάχρησης (Α), κατανάλωσης/μη κατάχρησης (Γ), αναφοράς μόνο (Μ), ή μη σχετικής αναφοράς (U) χρησιμοποιώντας τεχνικές επεξεργασίας φυσικής γλώσσας. Η αύξηση δεδομένων αύξησε τα σώματά μας εκπαίδευσης και επικύρωσης από 13,172 tweets σε 28,094 tweets. Δημιουργήσαμε επίσης ενσωμάτωση λέξεων σε συγκεκριμένα μέσα κοινωνικής δικτύωσης και ιατρικά σώματα. Ο υβριδικός μας αγωγός με βάση την προσοχή με μετεπεξεργασία ήταν το καλύτερο σύστημα στην εργασία 4 του με βαθμολογία F1 0,51 για την κατηγορία Α.', 'hu': 'Ez a tanulmány bemutatja a több osztályú szöveges kategorizálást olyan tweetek tekintetében, amelyek a vényköteles gyógyszereket úgy említik, mint amelyek potenciális visszaélésre/visszaélésre utalnak (A), fogyasztásra/visszaélésre (C), csak említésre (M), vagy egy nem kapcsolódó referencia (U), természetes nyelvfeldolgozási technikákat alkalmazva. Az adatok bővítése 13 172 tweetről 28 094 tweetre növelte a képzési és validálási cégünket. Szóbeágyazásokat is készítettünk domain-specifikus közösségi médiákon és orvosi corporákon. A figyelem alapú, utófeldolgozással ellátott CNN hibrid csővezetékünk volt a legjobb teljesítményű rendszer az SMM4H 2020 4. feladatában, F1 pontszáma 0,51 volt az A osztályban.', 'it': "Questo articolo presenta il nostro approccio alla categorizzazione di testi multi-classe di tweet che menzionano farmaci da prescrizione come indicativi di potenziale abuso / abuso (A), consumo / non abuso (C), menzione-only (M), o un riferimento non correlato (U) utilizzando tecniche di elaborazione del linguaggio naturale. L'aumento dei dati ha aumentato i nostri corpi di formazione e convalida da 13.172 tweet a 28.094 tweet. Abbiamo anche creato embedding di parole sui social media e sui corpora medici specifici del dominio. La nostra pipeline ibrida di una CNN basata sull'attenzione con post-elaborazione è stata il sistema più performante nel task 4 di SMM4H 2020, con un punteggio F1 di 0,51 per la classe A.", 'kk': 'Бұл қағаз біздің бірнеше класс мәтін санаттарына қатынасыз келтіреді. Рескрипті медицина (А), потенциал жеңілдіру/қарамастыру (C), пайдалану/жеңілдіру (C), тек (M), немесе табиғлық тілді өңдеу технологияларын қолданатын тілдер менеджеріне қатынас Деректерді көтеру және тексеру корпорасымызды 13,172 tweet-ден 28,094 tweet-ге көтерді. Сонымен қатар, доменге әлемдік медицина және медицина корпорасында сөздерді ендіру құрылдық. Сәйкес өңдеу арқылы белсендірілген CNN гибрид сызығымыз SMM4H 2020 жылы 4- тапсырмасындағы ең жақсы оқу жүйесі, A класындағы F1 0,51 жылдамасы бар.', 'lt': 'Šiame dokumente pristatomas mūsų požiūris į įvairių klasių tekstų kategorijavimą tweetams, kuriuose nurodomi receptiniai vaistai kaip galimas piktnaudžiavimas (A), vartojimas (C), tik paminėjimas (M) arba nesusijusi nuoroda (U) naudojant natūralių kalbų apdorojimo metodus. Duomenų didinimas padidino mūsų mokymo ir patvirtinimo korporą nuo 13 172 tweetų iki 28 094 tweetų. Taip pat sukūrėme žodžių įtraukimą į konkrečios srities socialinę žiniasklaidą ir medicinos korporas. Mūsų dėmesiu pagrįsto CNN mišinys po perdirbimo buvo geriausiai veikianti sistema SMM4H 2020 4 užduotyje, o A klasės F1 balas buvo 0,51.', 'mk': 'Овој документ го претставува нашиот пристап кон повеќекласна категоризација на текст на твитови споменувајќи ги лековите со рецепт како индикативни за потенцијално злоупотреба/злоупотреба (А), потрошувачка/незлоупотреба (Ц), само споменување (М), или неповрзана референција (U) користејќи при Зголемувањето на податоците ја зголеми нашата обука и валидација од 13.172 твитови на 28.094 твитови. Ние, исто така, создадовме зборови на социјални медиуми и медицински корпора специфични за домени. Нашиот хибриден гасовод од ЦНН базиран на внимание со пост-процесирање беше најдобриот систем во задачата 4 на СММ4Х 2020, со оценка Ф1 од 0,51 за класата А.', 'ms': 'Kertas ini memperkenalkan pendekatan kita kepada kategorisasi teks berkelas berbilang tweet yang menyebutkan ubat resep sebagai indikasi terhadap penyalahgunaan/kesalahan potensi (A), konsumsi/tidak-penyalahgunaan (C), sebutan-sahaja (M), atau rujukan tidak berkaitan (U) menggunakan teknik pemprosesan bahasa biasa. Data augmentation increased our training and validation corpora from 13,172 tweets to 28,094 tweets.  We also created word-embeddings on domain-specific social media and medical corpora.  Saluran paip hibrid kita dari CNN berdasarkan perhatian dengan post-proses adalah sistem prestasi terbaik dalam tugas 4 SMM4H 2020, dengan skor F1 0.51 untuk kelas A.', 'mt': 'Dan id-dokument jippreżenta l-approċċ tagħna għall-kategorizzazzjoni tat-testi ta’ diversi klassijiet ta’ tweets li jsemmu mediċini ta’ preskrizzjoni bħala indikattivi ta’ abbuż/użu ħażin potenzjali (A), konsum/mhux abbuż (C), referenza biss (M), jew referenza mhux relatata (U) bl-użu ta’ tekniki ta’ pproċessar tal-lingwi naturali. Iż-żieda fid-dejta żiedet it-taħriġ u l-validazzjoni korpra tagħna minn 13,172 tweet għal 28,094 tweet. Aħna ħolqu wkoll inkorporazzjonijiet tal-kliem fuq midja soċjali u korpra medika speċifiċi għad-dominju. Il-pajp ibridu tagħna ta’ CNN ibbażat fuq l-attenzjoni b’post-ipproċessar kien is-sistema bl-aħjar prestazzjoni fil-kompitu 4 tal-SMM4H 2020, b’punteġġ F1 ta’ 0.51 għall-klassi A.', 'ml': 'ഈ പത്രത്തില്\u200d റെപ്രിപ്റ്റ് മെഡിക്ടറുകള്\u200d പ്രസ്താവിക്കുന്ന ഉപയോഗിക്കുന്നതിനെക്കുറിച്ച് നമ്മുടെ പല-ക്ലാസിലെ ടെക്സ്റ്റ് വിഭാഗങ്ങള്\u200dക്ക് നമ്മുടെ രീതിയില്\u200d നിന ഡേറ്റാ കൂട്ടിചേര്\u200dക്കുന്നത് ഞങ്ങളുടെ പരിശീലനവും വിശ്വാസവും കോര്\u200dപ്പോര്\u200dണയും 13,172 ടൂട്ടില്\u200d നിന്നും 28,094 ട് ഞങ്ങള്\u200d ഡൊമെയിനില്\u200d പ്രത്യേക സോഷ്യല്\u200d മെഡിക്കല്\u200d കോര്\u200dപ്പോരയിലും വാക്കുകള്\u200d ഉണ്ടാക്കിയിരുന്നു. പിന്നീട് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനുമായി നമ്മുടെ ഹൈബ്രിഡ് പൈപ്പൈലൈന്\u200d എസ് എം എം എം എം 2020-ലെ ഏറ്റവും നല്ല പ്രവര്\u200dത്തനങ്ങളുടെ സിസ്റ്റ', 'mn': 'Энэ цаас бидний олон ангийнхээ текстүүдийн хуваарилалтын арга загварыг тайлбарлаж буй эмчилгээ (А), хэрэглээ/зөвхөн зөвхөн зөвхөн зөвхөн (M), эсвэл байгалийн хэл үйлдвэрлэлийн технологийг ашиглаж буй холбоотой (U) гэдэг tweets-ийн хуваарилалтыг харуул Дасгал өгөгдлийн нэмэлт нь бидний сургалт болон удирдах корпора 13,172 tweets-аас 28,094 tweets руу нэмэгдсэн. Бид мөн өөрсдийн нийгмийн мэдээлэл болон эмнэлгийн корпора дээр үг бий болгосон. Бидний анхаарлын төвөгтэй CNN-ийн гибрид хоолойн шугам нь СМ4H 2020 оны 4 даалгаварын хамгийн сайн үйл ажиллагааны систем байсан ба A-сын F1 оноо 0.51 байсан.', 'pl': 'W artykule przedstawiono nasze podejście do wieloklasjowej kategoryzacji tekstowej tweetów wspominających leki na receptę jako wskazujące na potencjalne nadużycie/niewłaściwe użycie (A), konsumpcję/nienadużycie (C), wspomnienie tylko (M) lub niepowiązane odniesienie (U) przy użyciu technik przetwarzania języka naturalnego. Rozszerzenie danych zwiększyło nasze korpusy szkoleniowe i walidacyjne z 13,172 tweetów do 28,094 tweetów. Stworzyliśmy również osadzenia słów na specyficznych dla domeny mediach społecznościowych i korporach medycznych. Nasz hybrydowy rurociąg CNN oparty na uwadze z post-processing był najlepiej wydajnym systemem w zadaniu 4 SMM4H 2020, z wynikiem F1 0,51 dla klasy A.', 'ro': 'Această lucrare prezintă abordarea noastră cu privire la categorizarea textelor multiple de tweet-uri care menționează medicamentele pe bază de prescripție medicală ca fiind indicative de potențial abuz / abuz (A), consum / non-abuz (C), mențiune-only (M), sau o referință neafiliată (U) utilizând tehnici de prelucrare a limbajului natural. Mărirea datelor a crescut corpurile noastre de formare și validare de la 13.172 tweet-uri la 28.094 tweet-uri. De asemenea, am creat încorporări de cuvinte pe rețelele sociale specifice domeniului și corporele medicale. Conducta noastră hibridă de CNN bazată pe atenție cu post-procesare a fost cel mai performant sistem în sarcina 4 a SMM4H 2020, cu un scor F1 de 0,51 pentru clasa A.', 'no': 'Denne papiret viser tilnærminga vårt til fleirklasse tekstkategorisering av tweets som mener preskriptiske medikamenter som indikator av potensielle misbruk/misbruk (A), bruk/ikkje-bruk (C), referanse berre (M), eller ein ukjend referanse (U) som brukar naturspråk-handteringsteknikk. Dette økte opplæring og validering av vårt korpora frå 13,172 tweet til 28,094 tweet. Vi oppretta også ordinnbygging på domenespesifikke sosiale medier og medisinske korpora. Hybridrøyebrytaren vårt på ein oppmerksbasert CNN med postprosessering var den beste utføringssystemet i oppgåva 4 av SMM4H 2020, med ein F1- poeng 0,51 for klasse A.', 'sr': 'Ovaj papir predstavlja naš pristup kategorizaciji višeklasnih tekstova tweeta koji spominju recept lekove kao indikator potencijalnog zlostavljanja/pogrešnog upotrebe (A), potrošnje/nezakonito zlostavljanje (C), samo spominjanje (M), ili nesavezane referencije (U) koristeći prirodne tehnike obrade jezika. Povećanje podataka povećalo je našu obuku i validaciju korporacije od 13.172 tweets na 28.094 tweets. Takoðe smo stvorili reèi-integracije na domenu specifičnim društvenim medijima i medicinskim korporacijama. Naša hibridna cijevina na pozornosti osnovana na CNN sa postprocessiranjem bila je najbolji izvodnji sistem u zadatku 4 SMM4H 2020, sa rezultatom F1 od 0,51 za klasu A.', 'sv': 'Denna uppsats presenterar vårt tillvägagångssätt för flerklassig textkategorisering av tweets som nämner receptbelagda läkemedel som indikativa på potentiellt missbruk/missbruk (A), konsumtion/icke-missbruk (C), endast omnämnande (M), eller en icke-relaterad referens (U) med hjälp av naturliga språkbehandlingstekniker. Dataförstärkning ökade våra tränings- och valideringskorpor från 13 172 tweets till 28 094 tweets. Vi skapade även ordinbäddningar på domänspecifika sociala medier och medicinska corpora. Vår hybridprodukt av ett uppmärksamhetsbaserat CNN med efterbehandling var det bästa presterande systemet i uppgift 4 i SMM4H 2020, med en F1-poäng på 0,51 för klass A.', 'si': 'This papers presents our approach to Multi-Classes text category of tweets දත්ත වැඩි වැඩි වැඩි වුනා අපේ ප්\u200dරධානය සහ විශ්වාස කර්පෝරා 13,172 ට්විට් වල 28,094 ට්විට් වල. අපි විශේෂ සාමාජික මිඩියාව සහ වෛද්\u200dය කොර්පෝරාවට වචන සම්බන්ධයක් නිර්මාණය කළා. අපේ හිබ්\u200dරිඩ් පායිප්ලින් එකේ අවධානය සඳහා පස්සේ ප්\u200dරක්\u200dරියාව සඳහා අධිකාරී CNN එකේ හොඳම පද්ධතිය SMM4H 2020යේ වැඩේ 4 වැඩේ හොඳම පද', 'so': 'Qoraalkan wuxuu soo bandhigaa qaabilaada qoraalka qoraalka kala duduwan ee tweeteedka ku qoran daawooyinka warqadda qoraalka ah oo lagu sheego tusaale ahaan isticmaalka isticmaalka luqada dabiicadda ah ee isticmaalaya isticmaalka isticmaalka isticmaalka isticmaalka isticmaalka afka naturada. Horumarinta macluumaadka waxaa kordhisay shirkadeena waxbarashada iyo shaqeynta, tan iyo 13,172 twitter iyo ilaa 28,094 twitter. We also created word-embeddings on domain-specific social media and medical corpora.  Hebrid pipeline of an focused CNN with post-processing was the best performing system in the task 4 of SM4H 2020, with F1 score 0.51 fasalka A.', 'ta': 'இந்த காகிதத்தில் சாத்தியமான உழைப்பு மருந்துகளை குறிப்பிடும் பல வகுப்பு உரை வகைப்படுத்தலுக்கு எங்கள் வழிமுறையை அளிக்கிறது என்று குறிப்பிடும் சிறுநிரல் மருத்துகளை குறிப Data augmentation increased our training and validation corpora from 13,172 tweets to 28,094 tweets.  குறிப்பிட்ட சமூக ஊடகங்கள் மற்றும் மருத்துவ நிறுவனத்தில் வார்த்தையை உருவாக்கினோம். பின்செயல்படுத்தலுடன் எஸ்எம்4ஹ் 2020 செயல்பாட்டில் சிறந்த செயல்படுத்தல் அமைப்பு என்பது எம்எம்4H 2020-ல் சிறந்த செயல்படுத்தல் முறைமையாகும், வக', 'ur': 'This paper presents our approach to multi-class text categorization of tweets mentioning prescription medications as indicative of potential abuse/misuse (A), consumption/non-abuse (C), mention-only (M), or an unrelated reference (U) using natural language processing techniques. ڈاٹا افزایش نے ہماری تعلیم اور validation corpora کو 13,172 ٹویٹ سے 28,094 ٹویٹ تک بڑھا دیا۔ اور ہم نے ڈومین کے مطابق مخصوص سوسیلی میڈیا اور پزشکی کورپورا پر کلمات انبودینگ پیدا کی۔ ہماری حیبرائیڈ پیپ لین کا ایک اظہار بنیاد سی ان کی پیپ لین ہے جس کے ساتھ پوسٹ پرسسینگ کے ساتھ SMM4H 2020 کی عملہ میں سب سے بہترین عمل سیستم تھا، ایک کلاس A کے لئے F1 اسکو 0.51 ہے۔', 'uz': "Bu qogʻoz bizning bir necha darajada matn kategoriyatlarimizni o'zgartiradi. Davlat narsalarni tahrirlash mumkin (A), foydalanish/misfoydalanish (C), foydalanish/unutish (C), faqat hisoblanuvchi (M), yoki tabiiy tilni boshqaruvchi teknikolar yordamida qo'llash imkoniyatlarimizni (U) hisoblash mumkin. Maʼlumot qoʻshishni taʼminlovchi va haqiqiqiylik kompaniyalarimizni 13,172 xabardan 28,094 xabarga oshirish mumkin. Biz hozir domen shaxsiy jamiyat medya va tibbiy kompaniyalarda so'zlarni yaratdik. Bizning keyingi harakat boshqaruvchi CNN asosidagi hybrid pipelining eng yaxshi bajarish tizimi SMM4H 2020 tashkilotidagi 4 (SMM4H 2020) vazifasidagi eng yaxshi bajarish tizimi edi.", 'vi': 'Bài báo này đưa ra phương pháp phân loại văn bản đa hạng của chúng ta về việc sử dụng thuốc kê toa như thể là biểu lộ về khả năng lạm dụng (A), tiêu thụ/không lạm dụng (C), chỉ điểm nhắc đến (M) hoặc một điểm liên quan (U) sử dụng kỹ thuật xử lý ngôn ngữ tự nhiên. Việc gia tăng dữ liệu tăng chương trình huấn luyện và thẩm quyền bằng cấp 1,172 tweet-2,094. Chúng tôi cũng đã tạo ra sự nhúng tay vào các phương tiện xã hội và ngành y. Hệ thống giao dịch của chúng tôi với một CNN dựa trên sự chú ý có hậu quả tốt nhất trong nhiệm vụ 4 của SMM4 2020, với một điểm F1 của 0.51 với hạng A.', 'bg': 'Настоящата статия представя нашия подход към многокласно текстово категоризиране на туитове, в които се посочват лекарства с рецепта като индикативни за потенциална злоупотреба/злоупотреба (А), консумация/не злоупотреба (В), само споменаване (М) или несвързана справка (U), използвайки техники за обработка на естествен език. Увеличаването на данните увеличи корпората ни за обучение и валидиране от 13 172 туита на 28 094 туита. Също така създадохме слова-вграждане в специфични домейни социални медии и медицински корпуси. Нашият хибриден тръбопровод от базиран на вниманието CNN с пост-обработка беше най-добре представящата се система в задача 4 на С оценка от 0,51 за клас А.', 'nl': 'Dit artikel presenteert onze benadering van multi-class tekstcategorisering van tweets waarin voorgeschreven medicijnen worden vermeld als indicatief voor potentieel misbruik/misbruik (A), consumptie/niet-misbruik (C), vermelding-only (M) of een niet-gerelateerde referentie (U) met behulp van natuurlijke taalverwerkingstechnieken. Data augmentatie vergroot onze training- en validatiecorpora van 13.172 tweets naar 28.094 tweets. We creëerden ook woord-embeddings op domeinspecifieke sociale media en medische corpora. Onze hybride pijplijn van een aandachtsgebonden CNN met nabewerking was het best presterende systeem in taak 4 van SMM4H 2020, met een F1 score van 0,51 voor klasse A.', 'da': 'Denne artikel præsenterer vores tilgang til tekstkategorisering i flere klasser af tweets, der nævner receptpligtig medicin som indikativ på potentielt misbrug/misbrug (A), forbrug/ikke-misbrug (C), omtale-only (M), eller en ikke-relateret reference (U) ved hjælp af teknikker til behandling af naturligt sprog. Dataforøgelse øgede vores trænings- og valideringskorpora fra 13.172 tweets til 28.094 tweets. Vi skabte også word-embeddings på domænespecifikke sociale medier og medicinske corpora. Vores hybrid pipeline af et opmærksomhedsbaseret CNN med efterbehandling var det bedst ydende system i opgave 4 af SMM4H 2020, med en F1 score på 0,51 for klasse A.', 'de': 'Dieses Papier stellt unseren Ansatz zur mehrstufigen Textkategorisierung von Tweets vor, in denen verschreibungspflichtige Medikamente als Indiz für potenziellen Missbrauch/Missbrauch (A), Konsum/Nichtmissbrauch (C), Erwähnung (M) oder eine nicht verwandte Referenz (U) unter Verwendung natürlicher Sprachverarbeitungstechniken erwähnt werden. Die Datenauswertung hat unsere Schulungs- und Validierungskorpora von 13.172 Tweets auf 28.094 Tweets erweitert. Wir haben auch Word-Embeddings auf domänenspezifischen Social Media und medizinischen Korpora erstellt. Unsere hybride Pipeline eines aufmerksamkeitsbasierten CNN mit Nachbearbeitung war das leistungsstärkste System in Aufgabe 4 von SMM4H 2020, mit einer F1-Punktzahl von 0,51 für Klasse A.', 'ko': '본고는 처방약을 언급한 트윗을 자연 언어 처리 기술로 여러 종류의 텍스트로 분류하는 방법을 소개한다. 이 트윗들은 잠재적인 남용/오용(A), 소비/미남용(C), 언급(M)만 하거나 관련이 없는 인용(U)을 나타낸다.데이터 확충은 우리의 교육과 검증 자료 라이브러리를 13172개의 추문에서 28094개의 추문으로 증가시켰다.우리는 특정 분야의 소셜 미디어와 의학 자료 라이브러리에 단어 삽입을 만들었다.우리의 주의력 기반 CNN과 후처리 혼합 파이프라인은 SMM4H 2020 퀘스트 4에서 가장 잘 표현된 시스템으로 A종의 F1 점수는 0.51이다.', 'id': 'Kertas ini memperlihatkan pendekatan kita untuk kategorisasi teks multi-kelas tweet yang menyebutkan obat resep sebagai indikasi dari potensi penyalahgunaan/salah gunaan (A), konsumsi/tidak-penyalahgunaan (C), hanya menyebutkan (M), atau referensi tidak terkait (U) menggunakan teknik proses bahasa alam. Peningkatan data meningkatkan pelatihan dan validasi kami dari 13.172 tweet ke 28.094 tweet. We also created word-embeddings on domain-specific social media and medical corpora.  Pipa hibrid kita dari CNN yang berdasarkan perhatian dengan post-proses adalah sistem yang terbaik dalam tugas 4 SMM4H 2020, dengan skor F1 0,51 untuk kelas A.', 'fa': 'این کاغذ دسترسی ما را به عنوان تنظیم متن چندین کلاس از توئیت\u200cها که داروهای پذیرش را به عنوان نشان داده می\u200cشود از استفاده از سوء استفاده/غلط استفاده (A), استفاده/غلط استفاده (C), فقط یادآوری (M) یا یک ارتباط غلط (U) با استفاده از تکنیک\u200cهای پرداخت زبان طبی افزایش داده\u200cها آموزش و تأیید شرکت ما را از ۱۳.172 تویت به ۲۸.094 تویت افزایش داد. ما همچنین در رسانه های اجتماعی و شرکت پزشکی مخصوص صحبت کلمات را ایجاد کردیم. لوله\u200cهای هیبرید ما از یک سی\u200cان\u200cای بر اساس توجه با پردازی بعد از پردازی بهترین سیستم اجرا در کار ۴ از SMM4H 2020 بود، با یک امتیاز F1 از 0.51 برای کلاس A.', 'sw': 'Gazeti hili linaleta mbinu yetu katika makundi ya ujumbe wa jumbe za twita zinazotaja dawa za madawa kama zinaonyesha udhalilishaji/matumizi ya vibaya (A), matumizi/uvunjifu (C), kutaja tu (M), au mtazamo usio na maana (U) kwa kutumia mbinu za kuchukua lugha za asili. Kuongezeka kwa taarifa kuliongeza kampuni yetu ya mafunzo na uhakika kutoka twiti 13,172 hadi twiti 28,094. Pia tulitengeneza maneno kwenye mitandao maalum ya kijamii na kampuni ya afya. Mstari wetu wa kihybrid wa CNN yenye msimamo mkali wa baada ya upasuaji ulikuwa mfumo bora wa kufanya kazi ya SMM4H 2020, na score ya F1 0.51 kwa darasa A.', 'tr': "Bu kagyz biziň ýarymyzy köp-synp metin kategoriýasyna görkezýär. ýarymly dil işleýän tekniklerden üýtgeýär Maglumatlar ýetişdirilip biziň bilim we hakykatymyzy korpoýalarymyzy 13.172 tweet we 28.094 tweet bilen artdyrdy. Biz hem söz taýýarlamalaryny sosyal medýdanlar we lukmançylyk korporasynda döredik. Öňümizdeki üns berilýän CNN'yň hybrid pipelinimiz, SMM4H 2020'yň 4-nji işi üçin iň gowy edilýän sistemady, A klasy üçin F1 depli 0.51.", 'hr': 'Ovaj papir predstavlja naš pristup kategorizaciji višeklasičnih tekstova Tweets koji spominju lijekove za recept kao indikator potencijalnog zlostavljanja/pogrešnog uporabe (A), potrošnja/ne zlostavljanja (C), samo spominjanja (M) ili nesavršena referencija (U) s prirodnim tehnikama obrade jezika. Povećanje podataka povećalo je našu obuku i potvrdu tijela od 13.172 tweets na 28.094 tweets. Također smo stvorili riječi-integracije na domenu specifičnim društvenim medijima i medicinskim korporacijama. Naš hibridni cijevi na pozornosti baziranog CNN-a s postprocessiranjem bio je najbolji sustav provedbe u zadatku 4 SMM4H 2020, s rezultatom F1 od 0,51 za klasu A.', 'sq': 'Ky dokument paraqet qasjen tonë ndaj kategorizimit të tekstit të shumë klasave të tweeteve që përmendin ilaçet me receta si tregues të abuzimit/keqpërdorimit të mundshëm (A), konsumit/jo-abuzimit (C), përmendimit-vetëm (M) ose një referencë të paligjshme (U) duke përdorur teknika natyrore të procesimit të gjuhës. Rritja e të dhënave rriti korprën tonë të trajnimit dhe valitimit nga 13,172 tweets në 28,094 tweets. Ne krijuam gjithashtu fjalë-përfshirje në mediat shoqërore specifike në domeni dhe korpra mjekësore. Tubacioni ynë hibridë i një CNN me bazë vëmendjeje me pas-procesim ishte sistemi më i mirë në detyrën 4 të SMM4H 2020, me një rezultat F1 prej 0.51 për klasën A.', 'am': 'ይህ ፕሮግራም የደብዳቤ መድኃኒት፣ የሥርዓት ጥቃቄ/ጥቃት (A)፣ ጥቃቄ/የማትጠቃቀፍ (C)፣ ብቻ (M) ወይም ያልተደረገ የቋንቋ ፕሮጀክት ስህተት (U) የተጠቃሚ የሀገር ጥያቄዎችን ለመግለጥ የTwitters ክፍተት ያሳያል፡፡ Data augmentation increased our training and validation corpora from 13,172 tweets to 28,094 tweets.  በዶሜን-አካባቢ ማኅበራዊ አውታር እና መድኃኒት ኮሬፖር ላይ ቃላትን አፈረስን፡፡ በክፍለ ስርዓት 4 የSM4H 2020 የስራ ሥራ 4 የተሻለ የኬብሪዲ ኮፕሌን ነው፡፡', 'af': "Hierdie papier stel ons toegang tot multiklas teks kategorisasie van tweets wat voor die preskriptiese mediese as indikatief van potensiele misgebruik/misgebruik (A), consumption/non-abuse (C), mention-only (M), of 'n onverwante verwysing (U) gebruik natuurlike taal verwerking tekenieke. Data-vergroot het ons onderwerp en geldigheidsverdigheid van 13,172 tweet tot 28,094 tweet vergroot. Ons het ook woord-inbettings geskep op domein-spesifieke sosiale media en mediese korpora. Ons hibridpipeline van 'n aandag-gebaseerde CNN met post-prosessering was die beste uitvoerde stelsel in taak 4 van SMM4H 2020, met 'n F1 telling van 0.51 vir klas A.", 'hy': 'Այս աշխատանքը ներկայացնում է մեր մոտեցումը թվիթերի բազմադասական տեքստի կատեգորիզացիայի վերաբերյալ, որոնք նշում են բժշկական դեղամիջոցներ որպես ցույց են տալիս պոտենցիալ չարաշահումը, սպառումը, ոչ չարաշահումը (C), միայն նշելը (M), կամ անկապ հղում (U Տվյալների աճը բարձրացրեց մեր ուսուցման և հավասարման կորպորան 13,172 թվիթերից 28,084 թվիթերին: We also created word-embeddings on domain-specific social media and medical corpora.  Մեր ուշադրության վրա հիբրիդ CNN-ի խողովակաշարը, որը հետաձևագործման միջոցով լավագույն արդյունքներ ուներ SMM4H 2020-ի 4-րդ հանձնարարության համար, F1-ի գնահատականը 0.51 էր A-ի համար:', 'bn': 'এই পত্রিকাটি আমাদের টুইটের টুইট বিভাগের প্রতি আমাদের পদক্ষেপ উপস্থাপন করেছে যেখানে প্রেসিকেট মেডিকেশন উল্লেখ করা হয়েছে যেটি সম্ভাব্য নির্যাতন/অপব্যবহারের (A), ব্যবহার/অপব্যবহা ১৩,১৭২ টুইট থেকে ২৮,০৯৪ টুইট থেকে তথ্য যোগ করা আমাদের প্রশিক্ষণ এবং বৈধ কর্পোরা আমাদের টুইট বৃদ্ধি করেছে। আমরা ডোমেইন-নির্দিষ্ট সামাজিক প্রচার মাধ্যম এবং চিকিৎসা কর্পোরায় শব্দ প্রবেশ করেছি। Our hybrid pipeline of an attention-based CNN with post-processing was the best performing system in task 4 of SMM4H 2020, with an F1 score of 0.51 for class A.', 'az': "Bu kańüńĪt bizim √ßoxlu sńĪnńĪf metin kategoriyasńĪna t…ôhsil edir, t…ôbi…ôtli dil iŇül…ôm…ô metodlarńĪnńĪ istifad…ô ed…ôr…ôk, m√ľv…ôff…ôqiyy…ôti/yanlńĪŇü istifad…ô etm…ôyi (A), istifad…ô/istifad…ô etm…ôyi (C), yalnńĪz adlandńĪrmańüńĪ (M) v…ô ya t…ôbi…ôtli dil iŇül…ôm…ô metodlarńĪnńĪ istifad…ô ed…ôn twetl…ôrd…ôn istifad…ô edilm…ôz. Data artńĪrmasńĪ bizim t…ôhsil v…ô validaŇüdńĪrma korporasńĪmńĪzńĪ 13.172 twetd…ôn 28.094 twetd…ôn artńĪrdńĪ. Biz h…ôm√ßinin domain-specific sosyal media v…ô medicin korporasńĪnda s√∂z inŇüallarńĪ yaratdńĪq. SńĪnńĪf A √ľ√ß√ľn F1 d…ôr…ôc…ôsi 0.51 d…ôr…ôc…ôsi il…ô, SMM4H 2020'nin 4. iŇüind…ô …ôn yaxŇüńĪ performancńĪ sistemi olan CNN'nin hibrid pipeline idi.", 'ca': "Aquest paper presenta el nostre enfocament a la categorització de textos de múltiples classes de tweets que mencionen medicaments prescriptius com indicant l'abus/abus potencial (A), consum/no abus (C), només menció (M), o una referència no vinculada (U) utilitzant tècniques de processament de llenguatges naturals. L'augment de les dades va augmentar la nostra capacitació i validació de 13.172 tweets a 28.094 tweets. També vam crear integracions de paraules en mitjans socials específics per domini i corpores mèdics. El nostre tub híbrid de CNN basat en l'atenció amb post-processament va ser el sistema de millor rendiment de la tasca 4 de SMM4H 2020, amb una puntuació F1 de 0,51 per a classe A.", 'bs': 'Ovaj papir predstavlja naš pristup kategorizaciji višeklasnih tekstova o tweetima koji spominju lijekove recepta kao indikativne za potencijalnu zloupotrebu/pogrešnu uporabu (A), potrošnju/nezakonitu zloupotrebu (C), samo spominju (M), ili nesavezanu referenciju (U) koristeći prirodne tehnike obrade jezika. Povećanje podataka povećalo je našu obuku i validaciju korporacije od 13.172 tweets na 28.094 tweets. Također smo stvorili riječi-integracije na domenu specifičnim društvenim medijima i medicinskim korporacijama. Naš hibridni cijevi na pozornosti baziranog CNN sa postprocessiranjem bio je najbolji izvršni sistem zadatka 4 SMM4H 2020, s rezultatom F1 od 0,51 za klasu A.', 'cs': 'Tento článek představuje náš přístup k vícetřídní kategorizaci textů tweetů zmiňujících léky na předpis jako indikaci potenciálního zneužití/zneužití (A), konzumace/nezneužití (C), zmínka pouze (M) nebo nesouvisející reference (U) pomocí technik zpracování přirozeného jazyka. Rozšíření dat zvýšilo naše tréninkové a validační korpusy z 13,172 tweetů na 28,094 tweety. Také jsme vytvořili slovní vložení na doménově specifických sociálních médiích a medicínských korpusech. Náš hybridní potrubí CNN založený na pozornosti s post-processing byl nejlépe výkonným systémem v úkolu 4 SMM4H 2020, s F1 skóre 0,51 pro třídu A.', 'et': 'Käesolevas artiklis tutvustatakse meie lähenemisviisi mitmeklassilisele tekstikategooriale säutsudes, kus retseptiravimid viitavad võimalikule kuritarvitamisele/väärkasutamisele (A), tarbimisele/mittekasutamisele (C), ainult mainimisele (M) või sõltumatule viitele (U), kasutades looduslikku keelt. Andmete suurendamine suurendas meie koolitus- ja valideerimiskorporeid 13 172 säutsult 28 094 säutsule. Samuti lõime sõnade manustamise domeenispetsiifilistes sotsiaalmeedias ja meditsiinikorpustes. Meie tähelepanupõhise CNN-i hübriidjuhtme koos järeltöötlusega oli SMM4H 2020 ülesande 4 parim tulemuslik süsteem, F1 skooriga 0,51 klassi A puhul.', 'fi': 'T채ss채 artikkelissa esitell채채n l채hestymistapamme twiittien moniluokkaiseen tekstiluokitteluun, jossa reseptil채채kkeet mainitaan viitteen채 mahdollisesta v채채rink채yt철st채/v채채rink채yt철st채 (A), kulutuksesta/v채채rink채yt철st채 (C), vain maininnasta (M) tai liittym채tt철m채st채 viittauksesta (U) luonnollisen kielen k채sittelytekniikoiden avulla. Tietojen lis채채minen lis채si koulutus- ja validointikorporaamme 13 172 tweetist채 28 094 tweetiin. Olemme my철s luoneet sanaupotuksia verkkotunnuskohtaiseen sosiaaliseen mediaan ja l채채ketieteellisiin korpusiin. J채lkik채sittelyll채 varustetun huomiopohjaisen CNN:n hybridiputkemme oli SMM4H 2020:n teht채v채ss채 4 parhaiten suoriutunut j채rjestelm채 F1-pisteell채 0,51 luokassa A.', 'jv': 'This paper Presents us method to multi-category text kategorialization of tuts listed prescript meds as being poive of potanse use/misuse (A), conteation/non-ubuse (C), listed-only (M), or an unreaded reference (U) use normal language manusing teks. Go nyenyane Daftar kang dipunangé podho sing nyimpen podho karo perusahaan mripur karo 13. We again create word-embedding on domain-special media and therapist. Awak dhéwé mulalah piwatiré sing nggawe ping atens-basa nang kontoh tapi-perusahaan ing sistem sing luwih dumadhi kanggo nganggo SMM4H 2020, karo perusahaan F1 sing dumadhi 0.31 kanggo kelas A.', 'he': 'הנייר הזה מציג את הגישה שלנו לקטגוריזציה טקסטית רבות של טוויטים שמזכירים תרופות מרשם כאילו הם מדעים על התעללות/השימוש לא פוטנציאלי (A), הצרכה/לא התעללות (C), רק הזכרה (M), או התייחסות לא קשורה (U) בשימוש בטכניקות עיבוד שפה טבעית. גידול נתונים העלה את האימון והאישור שלנו מתוך 13,172 טוויטים ל-28,094 טוויטים. יצרנו גם תוספות מילים על תקשורת חברתית ספציפית לתחום וקופורה רפואית. צינור היבריד שלנו של CNN מבוסס על תשומת לב עם אחרי העבודה היה מערכת ההופעה הטובה ביותר במשימה 4 של SMM4H 2020, עם נקודת F1 של 0.51 לכיתה A.', 'sk': 'V prispevku je predstavljen naš pristop k večrazredni besedilni kategorizaciji tweetov, ki navajajo zdravila na recept kot nakazujejo morebitno zlorabo/zlorabo (A), uživanje/nezlorabo (C), samo omenjanje (M) ali nepovezano referenco (U) z uporabo tehnik obdelave naravnega jezika. Povečanje podatkov je povečalo naše korpuse za usposabljanje in validacijo s 13.172 tweetov na 28.094 tweetov. Ustvarjali smo tudi besedne vključitve v domenske družbene medije in medicinske korpuse. Naš hibridni cevovod CNN, ki temelji na pozornosti, s postopno obdelavo je bil najboljši sistem v nalogi 4 SMM4H 2020, z rezultatom F1 0,51 za razred A.', 'ha': "Wannan takardan na gaya mataimayinmu zuwa category-matsayin mai yawa na jumla'ura-jumla na jumla'ura, yana ambaci dawakin misalin misalin (A), abuse/misuse (C), abun/abun-mai-bayani (C), ambaci-kawai (M), ko wani muhimmi wanda ya yi amfani da kunnufi na fassarar-harshe na asiyya (U). Ƙara data na ƙara shirin tafiyarmu da inganci daga 13,172 Twitter zuwa 28,094. Kayya, Mun sami maganar da ke cikin mitandai da jamii masu kamfata. Bibirin da aka samar da kyauta a kan CNN da bayan-aikin aiki 4 na SMM4H 2020, da wata F1 score 0.51 na daraja A.", 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་གོ་སྐབས་ཡིག་ཆ་འདི་ལྟ་བུའི་བཟོ་རྣམ་མཁན་གྱི་ཤོག་བྱང་སྒྲུབ་ཀྱི་དབྱེ་བ་སྤྱོད་མི་རྣམས་པས། ང་ཚོའི་གློག་འཕྲིན་དང་ཞིབ་བཤེར་གྱི་ནང་དུ་ཡིག་ཆ་བསྐྱེད་ཚད་དང་རྩ་སྒྲིག ང་ཚོས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་དང་སྨན་གྱི་ཞབས་ཏོག ང་ཚོའི་hybrid pipeline of an attention-based CNN with post-processing was the best performing system in task 4 of SMM4H 2020, with an F1 score of 0.51 for class A.'}
{'en': 'How Far Can We Go with Just Out-of-the-box BERT Models? BERT  Models?', 'ar': 'إلى أي مدى يمكن أن نذهب مع نماذج بيرت الجاهزة فقط؟', 'fr': "Jusqu'où pouvons-nous aller avec des modèles BERT prêts à l'emploi\xa0?", 'es': '¿Hasta dónde podemos llegar con los modelos BERT listos para usar?', 'pt': 'Até onde podemos ir com modelos BERT prontos para uso?', 'ja': 'すぐに使えるBERTモデルを使えば、どれだけ遠くに行くことができますか？', 'zh': '用开箱即用BERT模可走多远?', 'hi': 'हम बस आउट-ऑफ-द-बॉक्स BERT मॉडल के साथ कितनी दूर जा सकते हैं?', 'ru': 'Насколько далеко мы можем зайти, используя модели BERT, которые не входят в комплект поставки?', 'ga': 'Cé chomh fada agus is féidir linn dul le múnlaí BERT atá díreach lasmuigh den bhosca?', 'el': 'Πόσο μακριά μπορούμε να πάμε με απλά έξω από το κουτί μοντέλα BERT;', 'hu': 'Milyen messzire mehetünk a BERT modellekkel?', 'ka': 'კჲლკჲ ეალვფ მჲზვმ ეა ჲრთევმ ჟჲ ჟამჲ თჱლთჱანთ მჲევლთ?', 'it': 'Fino a che punto possiamo andare con i modelli BERT appena fuori dagli schemi?', 'kk': 'Біз BERT үлгілерімен қанша көмектесе аламыз?', 'mk': 'Колку далеку можеме да одиме со само Берт модели?', 'lt': 'Kaip toli galime eiti su tik iš dėžutės išoriniais BERT modeliais?', 'ms': 'Seberapa jauh kita boleh pergi dengan Model BERT Out-of-the-box?', 'mn': 'Бид зүгээр л BERT загвартай хэр хол явж болох вэ?', 'no': 'Kor langt kan vi gå med bare ut-av-boksen BERT-modeller?', 'mt': "Kemm 'il bogħod nistgħu nimxu ma' Mudelli BERT Just Out-of-the-box?", 'ml': 'ബെര്\u200dട്ടിന്\u200dറെ പെട്ടിയില്\u200d നിന്നും പുറത്ത് പോകാന്\u200d എത്ര ദൂരെ പോകും?', 'pl': 'Jak daleko możemy iść dzięki niestandardowym modelom BERT?', 'ro': 'Cât de departe putem merge cu modelele BERT doar out-of-the-box?', 'sr': 'Koliko daleko možemo da idemo sa samo izvan kutije BERT Modelima?', 'si': 'අපි කොච්චර දුරටත් යන්න පුළුවන් බෙර්ට් මොඩල් එක්ක?', 'ta': 'எவ்வளவு தூரம் நாம் பெட்டி வெளியே பெட்டி மாதிரிகளுடன் செல்ல முடியும்?', 'ur': 'ہم کس قدر دور کر سکتے ہیں صرف باکس بیٹ کی مدل کے ساتھ؟', 'so': 'Sidee baynu u fog karnaa qaababka BERT-ka-baxsan oo kaliya?', 'sv': 'Hur långt kan vi gå med just out-of-the-box BERT-modeller?', 'uz': 'Qancha uzoq biz BERT modellaridan chiqish mumkin?', 'vi': 'Chúng ta có thể đi xa tới mức nào với mẫu thực phẩm thiếu sót?', 'bg': 'Колко далеч можем да стигнем с просто извън кутията модели?', 'nl': 'Hoe ver kunnen we gaan met gewoon out-of-the-box BERT modellen?', 'da': 'Hvor langt kan vi gå med BERT-modeller, der er udført af boksen?', 'hr': 'Koliko daleko možemo ići sa samo izvan kutije BERT Modelima?', 'id': 'Seberapa jauh kita bisa pergi dengan Just Out-of-the-box BERT Models?', 'de': 'Wie weit können wir mit nur Out-of-the-Box BERT Modellen gehen?', 'fa': 'چقدر ميتونيم با مدل برت خارج از جعبه بريم؟', 'ko': '우리는 상자를 열면 바로 사용할 수 있는 버트 모형으로 얼마나 멀리 갈 수 있습니까?', 'sw': 'Ni umbali gani tunaweza kwenda na miundo mbinu ya BERT?', 'tr': 'Just Out-of-the-box BERT nusgalary bilen näçe uzaklaşdyryp bileris?', 'af': 'Hoe ver Kan ons gaan met net uit-die-boks BERT Modelle?', 'sq': 'Sa larg mund të shkojmë me modele BERT jashtë kutisë?', 'hy': 'Ինչքա՞ն հեռու կարող ենք գնալ պարզապես արկղից դուրս գտնվող BER մոդելների հետ:', 'am': 'ከ-ቦታ ብሬት ሞዴል ጋር እንዴት ይሄዳል?', 'az': 'N…ô q…ôd…ôr uzaqlaŇüa bil…ôrik ki, sadece Out-of-the-box BERT Modell…ôri il…ô?', 'bn': 'আমরা কিভাবে দূরে যেতে পারি বেরেট মোডেলের সাথে?', 'bs': 'Koliko daleko možemo ići sa samo izvan kutije BERT Modelima?', 'ca': 'Quant lluny podem anar amb models BERT just out-of-the-box?', 'cs': 'Jak daleko můžeme jít s právě vyrobenými modely BERT?', 'et': 'Kui kaugele me saame minna just väljaspool kasti BERT mudelitega?', 'fi': 'Kuinka pitkälle voimme mennä juuri valmiilla BERT-malleilla?', 'jv': "Kiye ora iso lunga 'Simple Out-of-the-box BERT model'?", 'ha': 'Yãya mai nĩsa zã Mu iya tafiyar da shirin ayuka mai fitarwa kawai?', 'sk': 'Kako daleč lahko gremo z modeli BERT?', 'bo': 'འུ་ཚོས་རང་ཉིད་ཀྱིས་Out-of-the-box BERT མིག་དབྱིབས་ཅི་སྦྱར་འགྲོ་ཐུབ་པ་ཡིན་ནམ།', 'he': 'כמה רחוק נוכל ללכת עם דוגמני ברט מחוץ לקופסה?'}
{'en': 'Social media have been seen as a promising data source for  pharmacovigilance . Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat-forms such as  Twitter  still need further development before they can be included reliably in routine pharmacovigilance practices. As the Bidirectional Encoder Representations from Transformer (BERT) models have shown great performance in many major NLP tasks recently, we decided to test its performance on the SMM4H Shared Tasks 1 to 3, by submitting results of pretrained and fine-tuned BERT models without more added knowledge than the one carried in the training datasets and additional datasets. Our three submissions all ended up above average over all teams’ submissions : 0.766 F1 for task 1 (15 % above the average of 0.665), 0.47 F1 for task 2 (2 % above the average of 0.46) and 0.380 F1 score for task 3 (30 % above the average of 0.292). Used in many of the high-ranking submission in the 2019 edition of the SMM4H Shared Task, BERT contin-ues to be state-of-the-art in ADR extraction for Twitter data.', 'ar': 'يُنظر إلى وسائل التواصل الاجتماعي على أنها مصدر بيانات واعد للتيقظ الدوائي. Howev-er ، لا تزال طرق الاستخراج التلقائي للتفاعلات الدوائية الضارة من أشكال الوسائط الاجتماعية مثل Twitter بحاجة إلى مزيد من التطوير قبل أن يتم تضمينها بشكل موثوق في ممارسات اليقظة الدوائية الروتينية. نظرًا لأن تمثيلات التشفير ثنائي الاتجاه من نماذج المحولات (BERT) أظهرت أداءً رائعًا في العديد من مهام البرمجة اللغوية العصبية الرئيسية مؤخرًا ، فقد قررنا اختبار أدائها على SMM4H المشتركة المهام من 1 إلى 3 ، من خلال إرسال نتائج نماذج BERT المحددة مسبقًا والمضبوطة دون المزيد المعرفة المضافة أكثر من تلك الموجودة في مجموعات بيانات التدريب ومجموعات البيانات الإضافية. انتهت عمليات الإرسال الثلاثة الخاصة بنا جميعها فوق المتوسط على عمليات إرسال جميع الفرق: 0.766 F1 للمهمة 1 (15٪ أعلى من المتوسط 0.665) ، 0.47 F1 للمهمة 2 (2٪ أعلى من المتوسط 0.46) و 0.380 F1 للمهمة 3 (30٪ أعلى من المتوسط البالغ 0.292). تُستخدم BERT في العديد من الطلبات عالية الترتيب في إصدار 2019 من SMM4H Shared Task ، وتستمر في أن تكون على أحدث طراز في استخراج ADR لبيانات Twitter.', 'es': 'Las redes sociales se han considerado una fuente de datos prometedora para la farmacovigilancia. Sin embargo, los métodos para la extracción automática de Reacciones Adversas a Medicamentos de las plataformas de redes sociales como Twitter aún necesitan un mayor desarrollo antes de que puedan incluirse de manera confiable en las prácticas de farmacovigilancia rutinarias. Como los modelos Bidirectional Encoder Representations from Transformer (BERT) han demostrado un gran rendimiento en muchas tareas importantes de PNL recientemente, decidimos probar su rendimiento en las Tareas Compartidas 1 a 3 del SMM4H, enviando los resultados de los modelos BERT preentrenados y ajustados sin más conocimientos adicionales que el incluidos en los conjuntos de datos de entrenamiento y en los conjuntos de datos adicionales. Nuestros tres envíos terminaron por encima de la media de todos los equipos: 0.766 F1 para la tarea 1 (15% por encima del promedio de 0.665), 0.47 F1 para la tarea 2 (2% por encima del promedio de 0.46) y 0.380 puntos de F1 para la tarea 3 (30% por encima del promedio de 0.292). Utilizado en muchos de los envíos de alto rango en la edición de 2019 de la Tarea Compartida SMM4H, BERT continúa siendo un estado de vanguardia en la extracción de ADR para datos de Twitter.', 'fr': "Les réseaux sociaux sont considérés comme une source de données prometteuse pour la pharmacovigilance. Cependant, les méthodes d'extraction automatique des effets indésirables des médicaments à partir de plateformes de médias sociaux telles que Twitter doivent encore être développées avant de pouvoir être incluses de manière fiable dans les pratiques de pharmacovigilance de routine. Étant donné que les modèles BERT (Bidirectional Encoder Représentations from Transformer) ont récemment montré d'excellentes performances dans de nombreuses tâches NLP majeures, nous avons décidé de tester leurs performances sur les tâches partagées SMM4H 1 à 3, en soumettant les résultats de modèles BERT préentraînés et affinés sans plus de connaissances supplémentaires que celui-ci inclus dans les ensembles de données d'entraînement et les ensembles de données supplémentaires. Nos trois soumissions se sont toutes retrouvées au-dessus de la moyenne par rapport à toutes les équipes\xa0: 0,766 F1 pour la tâche 1 (15\xa0% au-dessus de la moyenne de 0,665), 0,47 F1 pour la tâche 2 (2\xa0% au-dessus de la moyenne de 0,46) et 0,380 score F1 pour la tâche 3 (30\xa0% au-dessus de la moyenne de 0,292). Utilisé dans de nombreuses soumissions de haut niveau dans l'édition 2019 de la tâche partagée SMM4H, BERT continue d'être à la pointe de la technologie en matière d'extraction ADR pour les données Twitter.", 'pt': 'As mídias sociais têm sido vistas como uma fonte de dados promissora para a farmacovigilância. No entanto, métodos para extração automática de Reações Adversas a Medicamentos de plataformas de mídia social como o Twitter ainda precisam de mais desenvolvimento antes que possam ser incluídos de forma confiável nas práticas rotineiras de farmacovigilância. Como os modelos Bidirectional Encoder Representations from Transformer (BERT) mostraram grande desempenho em muitas tarefas importantes de PNL recentemente, decidimos testar seu desempenho nas Tarefas Compartilhadas SMM4H 1 a 3, enviando resultados de modelos BERT pré-treinados e ajustados sem mais conhecimento adicional do que aquele transportado nos conjuntos de dados de treinamento e conjuntos de dados adicionais. Nossos três envios terminaram acima da média de todos os envios de equipes: 0,766 F1 para a tarefa 1 (15% acima da média de 0,665), 0,47 F1 para a tarefa 2 (2% acima da média de 0,46) e 0,380 F1 para a tarefa 3 (30% acima da média de 0,292). Usado em muitos dos envios de alto escalão na edição de 2019 da Tarefa Compartilhada SMM4H, o BERT continua sendo o estado da arte na extração de ADR para dados do Twitter.', 'ja': 'ソーシャルメディアは、薬事警戒の有望なデータソースと見なされてきました。 Howev - er、Twitterなどのソーシャルメディアプラットフォームから有害薬物反応を自動抽出するための方法は、日常的な薬物警戒診療に確実に含めることができる前に、さらに開発する必要があります。 トランスフォーマーからの双方向エンコーダ表現（ BERT ）モデルは、最近多くの主要なNLPタスクで優れたパフォーマンスを示しているため、トレーニングデータセットおよび追加データセットに含まれるものよりも多くの知識を追加することなく、事前に訓練され微調整されたBERTモデルの結果を提出することによって、SMM 4 H共有タスク1から3でそのパフォーマンスをテストすることにしました。 私たちの3つの提出物は、すべてのチームの提出物の平均を上回る結果になりました。タスク1の0.766 F 1 （ 0.665の平均を15 ％上回る）、タスク2の0.47 F 1 （ 0.46の平均を2 ％上回る）、タスク3の0.380 F 1スコア（ 0.292の平均を30 ％上回る）。 SMM 4 H共有タスクの2019年版の高位の提出物の多くで使用されているBERTは、TwitterデータのADR抽出において最先端であることを証明しています。', 'ru': 'Социальные сети рассматриваются как перспективный источник данных для фармаконадзора. Howev-er, методы автоматического извлечения нежелательных лекарственных реакций из социальных медиа-платформ, таких как Twitter, все еще нуждаются в дальнейшей разработке, прежде чем они могут быть надежно включены в рутинные практики фармаконадзора. Поскольку в последнее время двунаправленные представления кодировщика от трансформатора (BERT) показали высокую производительность во многих основных задачах NLP, мы решили проверить его производительность на SMM4H Shared Tasks 1-3, представив результаты предварительно подготовленных и доработанных моделей BERT без дополнительных знаний, чем те, которые были перенесены в обучающие наборы данных и дополнительные наборы данных. Наши три заявки оказались выше среднего по всем заявкам команд: 0,766 F1 для задачи 1 (на 15% выше среднего значения 0,665), 0,47 F1 для задачи 2 (на 2% выше среднего значения 0,46) и 0,380 F1 для задачи 3 (на 30% выше среднего значения 0,292). Используемый во многих высокопоставленных материалах, представленных в 2019 году в издании SMM4H Shared Task, BERT продолжает оставаться самым современным в области извлечения ADR для данных Twitter.', 'zh': '社交媒体为药戒者有前数据源。 Howev-er从Twitter等社交媒体平台自取药物不良反应之法犹须更开,然后可以入常药戒行。 Transformer (BERT) 双向编码器者,近 NLP 能也,故试于 SMM4H 共事 1 试于 3 ,先预训练 BERT 形,而无过于练数集数。 吾三交终于诸团队平均值:任1为0.766 F1(高于0.665之平均值,15%)于0.47 F1(0.46之平均值出于2%),3为0.380 F1得分(高于0.292之平均值30%)。 2019年版SMM4H共事者多上中,BERT contin-uesTwitter数ADR取最新术也。', 'hi': 'सोशल मीडिया को फार्माकोविजिलेंस के लिए एक आशाजनक डेटा स्रोत के रूप में देखा गया है। Howev-er, सोशल मीडिया प्लैट-रूपों जैसे ट्विटर से प्रतिकूल दवा प्रतिक्रियाओं के स्वचालित निष्कर्षण के लिए तरीकों को अभी भी आगे के विकास की आवश्यकता है इससे पहले कि उन्हें नियमित फार्माकोविजिलेंस प्रथाओं में मज़बूती से शामिल किया जा सके। ट्रांसफॉर्मर (BERT) मॉडल से द्विदिश एन्कोडर अभ्यावेदन के रूप में हाल ही में कई प्रमुख NLP कार्यों में महान प्रदर्शन दिखाया गया है, हम SMM4H साझा कार्य 1 से 3 पर अपने प्रदर्शन का परीक्षण करने का फैसला किया है, pretrained और ठीक ट्यून BERT मॉडल के परिणाम प्रस्तुत करके प्रशिक्षण डेटासेट और अतिरिक्त डेटासेट में एक से अधिक जोड़ा ज्ञान के बिना. हमारे तीन सबमिशन सभी टीमों के प्रस्तुतियों पर औसत से ऊपर समाप्त हो गए: कार्य 1 के लिए 0.766 F1 (0.665 के औसत से 15%), कार्य 2 के लिए 0.47 F1 (0.46 के औसत से 2%) और कार्य 3 के लिए 0.380 F1 स्कोर (0.292 के औसत से 30%) SMM4H साझा कार्य के 2019 संस्करण में कई उच्च रैंकिंग सबमिशन में उपयोग किया जाता है, BERT contin-ues ट्विटर डेटा के लिए एडीआर निष्कर्षण में अत्याधुनिक होने के लिए।', 'ga': 'Breathnaíodh ar na meáin shóisialta mar fhoinse sonraí a bhfuil gealladh fúthu le haghaidh faireachas cógas. Mar sin féin, tá gá fós le tuilleadh forbartha a dhéanamh ar mhodhanna chun Frithghníomhartha díobhálacha Drugaí a bhaint go huathoibríoch ó ardáin meán sóisialta ar nós Twitter sular féidir iad a áireamh go hiontaofa i ngnáthchleachtais faireachais cógas. Toisc gur léirigh na samhlacha Ionchódóra Déthreo ó Thrasfhoirmeoir (BERT) feidhmíocht iontach i go leor tascanna móra NLP le déanaí, shocraigh muid a fheidhmíocht a thástáil ar Thascanna Comhroinnte 1 go 3 SMM4H, trí thorthaí samhlacha BERT réamh-oilte agus mionchoigeartaithe a chur isteach gan níos mó. eolas breise ná an ceann a iompraítear sna tacair sonraí oiliúna agus sna tacair sonraí breise. Chríochnaigh ár dtrí aighneacht os cionn an mheáin thar aighneachtaí na foirne go léir: 0.766 F1 do thasc 1 (15% os cionn an mheáin de 0.665), 0.47 F1 do thasc 2 (2% os cionn an mheáin de 0.46) agus 0.380 scór F1 do thasc 3 (30% os cionn an mheáin 0.292). Úsáidtear BERT i go leor de na haighneachtaí ardchéime in eagrán 2019 de Thasc Comhroinnte SMM4H, agus leanann BERT de bheith ar thús cadhnaíochta maidir le heastóscadh ADR le haghaidh sonraí Twitter.', 'el': 'Τα μέσα κοινωνικής δικτύωσης έχουν θεωρηθεί ως ελπιδοφόρα πηγή δεδομένων για τη φαρμακοεπαγρύπνηση. Ωστόσο, οι μέθοδοι αυτόματης εκχύλισης ανεπιθύμητων ενεργειών φαρμάκων από πλατφόρμες κοινωνικών μέσων όπως το Twitter εξακολουθούν να χρειάζονται περαιτέρω ανάπτυξη προτού μπορούν να συμπεριληφθούν αξιόπιστα στις πρακτικές ρουτίνας φαρμακοεπαγρύπνησης. Δεδομένου ότι οι αμφίδρομες αναπαραστάσεις κωδικοποιητή από μοντέλα έχουν δείξει εξαιρετική απόδοση σε πολλές σημαντικές εργασίες πρόσφατα, αποφασίσαμε να δοκιμάσουμε την απόδοσή του στις κοινές εργασίες 1 έως 3, υποβάλλοντας αποτελέσματα προκαθορισμένων και συντονισμένων μοντέλων χωρίς περισσότερες πρόσθετες γνώσεις από αυτές που μεταφέρονται στα σύνολα δεδομένων εκπαίδευσης και στα πρόσθετα σύνολα δεδομένων. Οι τρεις υποβολές μας κατέληξαν πάνω από τον μέσο όρο σε όλες τις υποβολές όλων των ομάδων: 0.766 F1 για εργασία 1 (15% πάνω από τον μέσο όρο 0.665), 0.47 F1 για εργασία 2 (2% πάνω από τον μέσο όρο 0.46) και 0.380 βαθμολογία για εργασία 3 (30% πάνω από τον μέσο όρο 0.292). Χρησιμοποιείται σε πολλές από τις υψηλού βαθμού υποβολή στην 2019 έκδοση της κοινής εργασίας SMM4H, το BERT συνεχίζει να είναι υπερσύγχρονο στην εξαγωγή ADR για δεδομένα στο Twitter.', 'ka': 'სოციალური მედიახი აღმოჩნდა როგორც გასაკეთებელი მონაცემების ფოსტაკოვიგლიანციისთვის. Howev-er, სოციალური მედია პლატიფორმებიდან, როგორც Twitter უნდა უფრო მეტად განვითარება, სანამ ისინი შეიძლება დარწმუნელად აკეთება პერმაკოგულანციის პრაქტიკში. როგორც ორდირექციონალური კოდირების რესპენტერესტი რესპენტრუმენტერების (BERT) მოდელებიდან მნიშვნელოვანი მნიშვნელოვანი NLP სამუშაოდ დავამუშავებენ, ჩვენ განვიწყეთ, რომ მისი მუშაობა SMM4H გაყოფილი სამუშაო სამუშაო სამუშაო დავარჩენ ჩვენი სამი წარმოდგენები ყველაფერი საშუალოდ გადარჩენა ყველაფერი ჯგუფის წარმოდგენებით: 0.766 F1 საშუალოდ 1 (15% უფრო 0.665 სიშუალოდ), 0.47 F1 საშუალოდ 2 (2% უფრო 0.46 სიშუალოდ) და 0.380 F1 საშუალოდ 3 (30% უფრო 0.292 2019 წლის SMM4H საზოგადომი დავალების მრავალში გამოყენებულია, BERT contin-ues, რომელიც ADR ექსტრექციაში შესაძლებელია.', 'it': "I social media sono stati visti come una fonte di dati promettente per la farmacovigilanza. Howev-er, i metodi per l'estrazione automatica delle reazioni avverse ai farmaci da piattaforme di social media come Twitter hanno ancora bisogno di ulteriore sviluppo prima che possano essere inclusi in modo affidabile nelle pratiche di farmacovigilanza di routine. Poiché recentemente i modelli BERT (Bidirectional Encoder Representations from Transformer) hanno mostrato grandi prestazioni in molte delle principali attività NLP, abbiamo deciso di testarne le prestazioni sulle attività condivise SMM4H da 1 a 3, presentando i risultati di modelli BERT pre-addestrati e perfezionati senza più conoscenze aggiuntive di quelle contenute nei set di dati di formazione e nei set di dati aggiuntivi. I nostri tre contributi sono finiti tutti al di sopra della media rispetto ai contributi di tutte le squadre: 0,766 F1 per l'attività 1 (15% sopra la media di 0,665), 0,47 F1 per l'attività 2 (2% sopra la media di 0,46) e 0,380 F1 per l'attività 3 (30% sopra la media di 0,292). Utilizzato in molte delle presentazioni di alto rango nell'edizione 2019 della SMM4H Shared Task, BERT continua ad essere all'avanguardia nell'estrazione ADR per i dati Twitter.", 'kk': 'Әлемдік медиақтар фармаковигализация үшін мұғалған деректер көзі ретінде көрінілді. Howev-er, Твиттердің социалдық медиақтар платформаларының автоматты түрде қарсы наркотикалық реакцияларды автоматты түрде тарқату әдістері, оларды әдімгі фармаковигализациялық тәжірибелерінде сенімді қосыл Трансформацияның (BERT) үлгілерінен екі бағытты кодтардың суреттері жаңа көп негізгі NLP тапсырмаларында жақсы істеу көрсетілген болса, біз оның істемін 1- 3 SMM4H ортақ тапсырмаларында тексеру үшін шешіміз. Трансформацияның және кеңейтілген BERT моделдерінің нәтижелерін қосы Біздің үш жіберіміз барлық топтардың жіберілімдерінің орташасынан жоғары болды: 1- тапсырма үшін 0, 766 F1 (0, 665 орташасынан 15%), 2- тапсырма үшін 0, 47 F1 (0, 46 орташасынан 2%) және 3- тапсырма үшін 0, 380 F1 (0, 292 орташасынан 30%). 2019 жылы SMM4H ортақтастырылған тапсырманың көптеген жоғары жоғары жіберілімінде, BERT contin-ues, Твиттер деректері үшін ADR тарқатуының күй- жайы болу үшін қолданылады.', 'lt': 'Socialinė žiniasklaida buvo laikoma perspektyviu farmakologinio budrumo duomenų šaltiniu. Howev-er, nepageidaujamų narkotikų reakcijų automatinio ištraukimo iš socialinių žiniasklaidos platformų, pvz., Twitter, metodai vis dar turi būti tobulinami, kol jie gali būti patikimai įtraukti į įprastą farmakologinio budrumo praktiką. Kadangi dvikrypčiai transformuotojo (BERT) modeliai parodė didelius rezultatus daugelyje svarbių NLP užduočių neseniai, nusprendėme išbandyti savo rezultatus SMM4H bendrose užduotyse nuo 1 iki 3, pateikdami iš anksto apmokytų ir patobulintų BERT modelių rezultatus be daugiau žinių nei mokymo duomenų rinkiniuose ir papildomuose duomenų rinkiniuose. Visi trys mūsų pareiškimai buvo didesni nei vidutiniškai visiems komandų pareiškimams: 0,766 F1 1 užduoties atveju (15 % viršijo vidurkį 0,665), 0,47 F1 2 užduoties atveju (2 % viršijo vidurkį 0,46) ir 0,380 F1 3 užduoties atveju (30 % viršijo vidurkį 0,292). Naudojamas daugelyje aukšto rango pranešimų, pateiktų 2019 m. SMM4H bendros užduoties leidinyje, BERT toliau yra naujausia ADR duomenų rinkimo Twitter srityje.', 'ms': 'Media sosial telah dilihat sebagai sumber data yang berjanji untuk pharmacovigilance. Howev-er, kaedah untuk ekstraksi automatik Reaksi Narkoba Dari platform media sosial seperti Twitter masih memerlukan pembangunan lanjut sebelum mereka boleh disertai dengan yakin dalam praktek farmakovigilans rutin. Sebagaimana Perwakilan Pengekod Dua Arah dari Model Transformer (BERT) telah menunjukkan prestasi yang besar dalam banyak tugas NLP utama akhir-akhir ini, kami memutuskan untuk menguji prestasinya pada Tugas Berkongsi SMM4H 1 hingga 3, dengan menghantar keputusan dari model BERT yang dilatih dan disesuaikan dengan baik tanpa pengetahuan tambahan daripada yang dibawa dalam set data latihan dan set data tambahan. Tiga penghantaran kami semua berakhir di atas rata-rata atas penghantaran semua pasukan: 0.766 F1 untuk tugas 1 (15% di atas rata-rata 0.665), 0.47 F1 untuk tugas 2 (2% di atas rata-rata 0.46) dan 0.380 F1 untuk tugas 3 (30% di atas rata-rata 0.292). Digunakan dalam banyak penghantaran tertinggi dalam edisi 2019 Tugas Berkongsi SMM4H, BERT terus-menerus menjadi state-of-the-art dalam ekstraksi ADR untuk data Twitter.', 'ml': 'സോഷ്യല്\u200d മീഡിയ ഒരു വാഗ്ദത്തിലെ ഡേറ്റാ സോര്\u200dട്ടായിരിക്കുന്നു. സോഷ്യല്\u200d മെഡിക്ക് പ്ലാറ്റ് ഫോമുകളില്\u200d നിന്നും സ്വയം പ്രതികരിക്കുന്നതിനുള്ള മാര്\u200dഗ്ഗങ്ങള്\u200dക്ക് വേണ്ടി ഹോവേവ്-er, ടൂട്ടര്\u200d വിശ്വസിക്കുന്നതിന് മ ട്രാന്\u200dസ്ഫോര്\u200dഫര്\u200d മോഡലുകളില്\u200d നിന്നുള്ള ബൈഡിഡയലില്\u200d നിന്നുള്ള പ്രതിനിധികള്\u200d ഏറ്റവും പ്രധാന പ്രവര്\u200dത്തനങ്ങള്\u200d കാണിച്ചിരിക്കുന്നു. അടുത്ത് പ്രധാനപ്പെട്ട NLP ജോലികളില്\u200d ഞങ്ങള്\u200d അതിന്\u200dറെ പ്രകടനം പരീക്ഷി ഞങ്ങളുടെ മൂന്നു കീഴടങ്ങള്\u200d എല്ലാ ഗ്രൂപ്പുകളുടെയും അടിസ്ഥാനങ്ങള്\u200dക്കും മീതെ അവസാനിച്ചു: 0. 766 F1 ജോലി 1 (0. 665 കഴുത്തില്\u200d 15% മീതെ 0. 47 F1), ജോലി 2 (0. 46 ശരാസ്യത്തില്\u200d 2% മീതെ 0. 380 F1 സ്കോര്\u200d എസ്എംഎംഎംഎഫ്\u200cഎംഎംഎം പങ്കെടുത്ത ടാസ്കിന്\u200dറെ എഴുത്തിലെ എഴുതിയിരിക്കുന്ന പ്രതികരണത്തില്\u200d, ബെര്\u200dട്ടി കോണിന്\u200d - യൂ എഡിംആര്\u200d പു', 'mk': 'Социјалните медиуми се сметаат за ветувачки извор на податоци за фармацевизија. Хауев-ер, методите за автоматско извлекување на Негативни наркотички реакции од платформите на социјалните медиуми како што е Твитер сé уште се потребни понатамошни развоји пред да можат да бидат вмешани доверливо во рутинската практика на фармацевизија. Со оглед на тоа што бидирекционалните кодерски претставувања од моделите на Трансформер (БЕРТ) покажаа голема резултатност во многу големи задачи на НЛП неодамна, одлучивме да ја тестираме нејзината резултат на SMM4H споделените задачи 1 до 3, со испраќање резултати од претренираните и финетизирани модели на БЕРТ без повеќе додадено Нашите три поднесувања завршија над просекот од сите поднесувања на тимовите: 0,766 F1 за задачата 1 (15 отсто над просекот од 0,665), 0,47 F1 за задачата 2 (2 отсто над просекот од 0,46) и 0,380 F1 за задачата 3 (30 отсто над просекот од 0,292). Користена во многумина од високите рангирани поднесувања во изданието 2019 година на SMM4H Shared Task, BERT продолжува да е најнова во извлекувањето на АДР за податоци од Твитер.', 'hu': 'A közösségi médiát a farmakovigilancia ígéretes adatforrásának tekintik. Howev-er, a mellékhatások automatikus extrakciójának módszerei a közösségi média platformokból, mint például a Twitter, tovább kell fejleszteni, mielőtt megbízhatóan bevonnák őket a rutin farmakovigilancia gyakorlatba. Mivel a BERT modellek az utóbbi időben nagy teljesítményt mutattak számos fontos NLP feladatban, úgy döntöttünk, hogy teszteljük teljesítményét az SMM4H Shared Tasks 1–3 között, előkészített és finomhangolt BERT modellek eredményeit anélkül, hogy több hozzáadott tudás nélkül küldjük be a képzési adatkészletekben és további adatkészletekben található eredményeket. Három beadványunk mindegyike az átlag felett végzett az összes csapat beadványához képest: 0,766 F1 az 1. feladathoz (15%-kal 0,665 átlag felett), 0,47 F1 a 2. feladathoz (2%-kal 0,46 átlag felett), és 0,380 F1 pontszám a 3. feladathoz (30%-kal 0,292 átlag felett). Az SMM4H megosztott feladat 2019-es kiadásának számos magas rangú beadványában használt BERT továbbra is korszerű a Twitter-adatok ADR kitermelése terén.', 'mn': 'Нийгмийн мэдээллийн хэрэглэгчид эмийн хэрэглэгчдийн амлалтай мэдээллийн эх үүсвэр гэж үздэг. Хоуэв, Твиттер гэх мэт нийгмийн мэдээллийн платформаас автоматжуулан эмчилгээний урвалыг автоматжуулах арга зам нь тэднийг эмчилгээний эмчилгээний үйл ажиллагаанд итгэлтэй байлгахаас өмнө нь илүү хөгжлийн хэрэгтэй. Трансформаторын (BERT) хэлбэрээс хоёр чиглэлтийн коддогч загварууд саяхан NLP даалгавраас гайхалтай үйл ажиллагааг харуулсан тул бид SMM4H хуваалтын 1-3 даалгаврын үйл ажиллагааг шалгахыг шийдсэн бөгөөд сургалтын өгөгдлийн санд болон нэмэлт өгөгдлийн санаас илүү мэдлэг нэмэгдсэн BERT загварын Бидний гурван дамжуулалт бүх багийн дамжуулалтын дундаж дундаж дээр төгсгөл байлаа: 1 даалгаварын төлөө 0.766 F1 (0.665 дундаж 15%), 2 даалгаварын төлөө 0.47 F1 (0.46 дундаж 2%), 3 даалгаварын төлөө 0.380 F1 (0.292 дундаж 30%). 2019 оны SMM4H хуваалцааны хэвлэлд, BERT contin-ues нь ДОХ-ын мэдээллийн тусламжтайгаар ADR-ын хувьд урлагийн хувьд хэрэглэгдсэн.', 'mt': "Il-midja soċjali dehret bħala sors ta’ dejta promettenti għall-farmakoviġilanza. Howev-er, metodi għall-estrazzjoni awtomatika ta’ Reazzjonijiet Avversi tal-Mediċini minn pjattaformi tal-midja soċjali bħal Twitter għadhom jeħtieġu aktar żvilupp qabel ma jkunu jistgħu jiġu inklużi b’mod affidabbli fil-prattiki ta’ farmakoviġilanza ta’ rutina. Peress li r-Rappreżentanzi Bidirezzjonali tal-Kodifikaturi mit-Transformaturi (BERT) urew prestazzjoni kbira f’ħafna kompiti ewlenin tal-NLP reċentement, iddeċidew li jittestjaw il-prestazzjoni tiegħu fuq il-Kompiti Kondiviżi SMM4H 1 sa 3, billi jissottomettu riżultati ta’ mudelli BERT imħarrġa minn qabel u aġġustati finament mingħajr aktar għarfien miżjud minn dak li jinġarr fis-settijiet tad-dejta tat-taħriġ u settijiet tad-dejta addizzjonali. It-tliet sottomissjonijiet tagħna kollha ntemmu 'l fuq mill-medja fuq is-sottomissjonijiet tat-timijiet kollha: 0.766 F1 għall-kompitu 1 (15% ogħla mill-medja ta' 0.665), 0.47 F1 għall-kompitu 2 (2% ogħla mill-medja ta' 0.46) u 0.380 F1 għall-kompitu 3 (30% ogħla mill-medja ta' 0.292). Użat f’ħafna mis-sottomissjonijiet ta’ grad għoli fl-edizzjoni 2019 tal-SMM4H Shared Task, il-BERT ikompli jkun l-aktar avvanzat fl-estrazzjoni tal-ADR għad-dejta fuq Twitter.", 'no': 'Sosialmedia har blitt sett som eit foreslåande datakjelde for farmakovigilans. Howev-er, metodar for automatisk utpakking av motsetjingar av narkotikarelateksjonar frå sosiale mediaplatformar som Twitter treng framleis utviklingar før dei kan verta satt inn i rutinene farmakovigilans-praksis. Som det nye nye utviklinga i fleire store NLP-oppgåver har vist dei fleire rekkefølgjande representasjonane frå transformeringsmodelane (BERT), bestemte vi å testa utviklinga på SMM4H-delte oppgåver 1 til 3, ved å senda resultat av følgjande og finnstillingsBERT-modeller utan meir kunnskap enn dei som er vedtatt i opplæringsdatasetta og ekstra datasett. Våre tre oppføringar slutta alt over gjennomsnittlig over alle oppføringar av grupper: 0,766 F1 for oppgåve 1 (15% over gjennomsnittlig 0,665), 0,47 F1 for oppgåve 2 (2% over gjennomsnittlig 0,46) og 0,380 F1 for oppgåve 3 (30% over gjennomsnittlig 0,292). Brukt i mange av den høg rankeringsoppføringa i utdataen av SMM4H-delte oppgåva 2019, BERT contin-ues som er state-of-the-art i ADR-extraction for Twitter-data.', 'ro': 'Social media a fost văzută ca o sursă de date promițătoare pentru farmacovigilență. Howev-er, metodele de extragere automată a reacțiilor adverse la medicamente de pe platformele de socializare precum Twitter necesită încă dezvoltare în continuare înainte de a putea fi incluse în mod fiabil în practicile de farmacovigilență de rutină. Deoarece modelele BERT (Bidirectional Encoder Representations from Transformer) au demonstrat recent performanțe excelente în multe sarcini majore NLP, am decis să testăm performanța acestuia pe SMM4H Shared Tasks 1 to 3, prin prezentarea rezultatelor modelelor BERT pre-instruite și reglate fin fără mai multe cunoștințe adăugate decât cea purtată în seturile de date de instruire și seturile de date suplimentare. Cele trei depuneri ale noastre au ajuns toate peste medie față de depunerile tuturor echipelor: 0,766 F1 pentru sarcina 1 (cu 15% peste media de 0,665), 0,47 F1 pentru sarcina 2 (cu 2% peste media de 0,46) și 0,380 F1 pentru sarcina 3 (cu 30% peste media de 0,292). Utilizat în multe dintre depunerile de rang înalt din ediția 2019 a sarcinii partajate SMM4H, BERT continuă să fie de ultimă generație în extragerea SAL pentru datele Twitter.', 'sr': 'Socijalni mediji smatraju obećavajućim izvorom podataka za farmakovigilanciju. Howev-er, metode za automatsku izvlačenje nuspojavnih reakcija iz forma socijalnih medija, poput Twitter, još uvek trebaju daljnji razvoj pre nego što se mogu pouzdano uključiti u rutinsku farmakovigilanciju. Dok su predstavnici dvosmjernih kodera iz modela transformera (BERT) pokazali veliku funkciju u mnogim velikim zadacima NLP nedavno, odlučili smo da testiramo svoj učinkovit na podjeljenim zadacima SMM4H 1 do 3, podajući rezultate modela BERT-a bez dodatnih znanja nego one koji su nosili u setama podataka i dodatnih seta podataka. Naše tri podatke su završile iznad prosjeka iznad podataka svih timova: 0,766 F1 za zadatak 1 (15% iznad prosjeka 0,665), 0,47 F1 za zadatak 2 (2% iznad prosjeka 0,46) i 0,380 F1 za zadatak 3 (30% iznad prosjeka 0,292). Koristili su se u mnogim od visokog podnošenja u izdanju SMM4H zajedničkog zadatka 2019. godine, BERT kontin-ues za izvlačenje ADR-a za podatke o Twitter.', 'pl': 'Media społecznościowe zostały postrzegane jako obiecujące źródło danych dotyczące nadzoru nad bezpieczeństwem farmakoterapii. Jednakże metody automatycznego ekstrakcji działań niepożądanych z platform mediów społecznościowych, takich jak Twitter, nadal wymagają dalszego rozwoju, zanim będą mogły zostać niezawodnie włączone do rutynowych praktyk nadzoru nad bezpieczeństwem farmakoterapii. Ponieważ reprezentacje kodera dwukierunkowego z modeli Transformera (BERT) wykazały się ostatnio świetną wydajnością w wielu głównych zadaniach NLP, zdecydowaliśmy się przetestować jego wydajność na SMM4H Shared Tasks 1–3, przesyłając wyniki wstępnie przeszkolonych i dostrojonych modeli BERT bez większej wiedzy dodanej niż ta, która jest noszona w zestawach danych szkoleniowych i dodatkowych zbiorach danych. Nasze trzy zgłoszenia zakończyły się ponad średnią w przypadku zgłoszeń wszystkich zespołów: 0.766 F1 dla zadania 1 (15% powyżej średniej 0.665), 0.47 F1 dla zadania 2 (2% powyżej średniej 0.46) i 0.380 F1 dla zadania 3 (30% powyżej średniej 0.292). Używany w wielu wysokiej rangi zgłoszeń w 2019 edycji SMM4H Shared Task, BERT nadal jest najnowocześniejszym etapem w ekstrakcji ADR danych na Twitterze.', 'si': 'සාමාජික මාධ්\u200dයමත්වය ප්\u200dරශ්නයක් විදියට තියෙන්නේ ප්\u200dරතිචාර දත්ත ක්\u200dරමයක් විදියට. Howev-er, සාමාජික මධ්\u200dයමාධ්\u200dයම ප්\u200dරතික්\u200dරියාවන් ස්වයංක්\u200dරියාවක් ප්\u200dරතික්\u200dරියාවන් ස්වයංක්\u200dරියාවක් නිර්මාණය කරගන්න විදියට පස් වගේම බිදිරික්ෂණික කෝඩාර් ප්\u200dරධාන (BERT) මොඩල් වලින් හොඳ ප්\u200dරධානයක් පෙන්වන්න පුළුවන් විදිහට ප්\u200dරධාන NLP ක්\u200dරියාවක් වෙනුවෙන්, අපි තීරණය කරලා තියෙන්නේ ඒකේ ප්\u200dරධානය SMM4H අපේ සියළුම් තුනක් සියළුම සියළුම් කණ්ඩායම් ගැන සියළුම් සියළුම් වලින් ඉවරයි: 0.766 F1 වෙනුවෙන් වැඩ 1 (15% වැඩ 0.665 වලින්), 0.47 F1 වැඩ 2 වැඩ 2 (2% වැඩ 0.46 වලින්) සහ 0.380 2019 විදියට SMM4H සමාගත වැඩක් වලින් අධ්\u200dයත්වය පිළිගන්න ප්\u200dරයෝජනය කරලා තියෙන්නේ, BERT contin-ue විදියට ADR පිළිගන්න විදියට ට්\u200dවිටර් දත', 'so': "Macluumaadka bulshada waxaa looga arkay sida sourcee macluumaad loo ballanqaaday ilaalinta farmashiga. Howev-er, qaababka ay automatic ka soo bixiso dib u soo saarista dhakhaatiirta dawooyinka ee shabakadda bulshada, tusaale ahaan Twitterka weli u baahan yahay horumarinta sii koritaanka intaan si aamin ah looga dhigi karo qalabka daryeelka farmashiyaha ee caadiga ah. Sida uu u muujiyey modellada Bidirectional Encoder Representations from Transfer (BERT) waxay sameeyeen muuqasho aad u weyn in badan shuqullada waaweyn ee NLP hivi karibuni, waxaynu go'aannay inuu tijaabiyo performances ku saabsan SM4H Shared Shaqooyinka 1-3, waxaana soo dirray results of pretrained and fine-tuned BERT models aan aqoon dheeraad ah ka badan kii qaaday koorasyada waxbarashada iyo macluumaad dheeraad ah. Saddeyda lifaaqyada oo dhamaantood waxay ka dhamaadeen ugu badnaan dhamaantood hoos u soo diritaanka kooxda oo dhan: 0.766 F1 shaqo 1 (15% ka sarreeya average 0.665), 0.47 F1 shaqada 2 (2% ka sarreeya average 0.46) iyo 0.380 F1 score u qoran shaqo 3 (30% ka sarreeya average 0.292). Waxa lagu isticmaalay buuxinta heerka sare ee 2019 edition of the SMM4H Shared Task, BERT contin-ues to be state-of-art in ADR extraction data for Twitter.", 'sv': 'Sociala medier har setts som en lovande datakälla för farmakovigilans. Howev-er, metoder för automatisk extraktion av biverkningar från sociala medier plattformar som Twitter fortfarande behöver utvecklas innan de kan inkluderas tillförlitligt i rutinmässiga farmakovigilansmetoder. Eftersom BERT-modellerna (Bidirectional Encoder Representations from Transformer) har visat stor prestanda i många större NLP-uppgifter nyligen, bestämde vi oss för att testa dess prestanda på SMM4H Shared Tasks 1 till 3, genom att skicka in resultat från förbelagda och finjusterade BERT-modeller utan mer kunskap än den som finns i träningsdatauppsättningar och ytterligare datauppsättningar. Våra tre inlämningar hamnade alla över genomsnittet över alla lags inlämningar: 0,766 F1 för uppgift 1 (15% över genomsnittet på 0,665), 0,47 F1 för uppgift 2 (2% över genomsnittet på 0,46) och 0,380 F1 för uppgift 3 (30% över genomsnittet på 0,292). BERT används i många av de högt rankade inlämningarna i 2019 års upplaga av SMM4H Shared Task och fortsätter att vara den senaste inom ADR utvinning för Twitter-data.', 'ur': 'سوسیل میڈیا فرمواجی کے لئے ایک وعدہ دار ڈیٹ سورس کے طور پر دیکھا گیا ہے۔ Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat forms such as Twitter still need further development before they can be reliably included in routine pharmacovigilance practices. جیسے ٹرانسفور (BERT) موڈلوں سے دوسری دئیرسیٹ کیونڈر کا نمونڈر بہت اچھے NLP کاموں میں بہت اچھی فعالیت دکھائی گئی ہے، ہم نے اس کا فعالیت SMM4H Shared Tasks 1-3 پر امتحان کرنے کا فیصلہ کیا تھا، اس کے نتیجے کو ترینس ڈیٹسٹ اور اضافہ ڈیٹسٹ میں اٹھائے ہوئے کسی سے زیادہ علم کے بغیر پہلے ترینس ہماری تین مضبوطی تمام تیموں کے مضبوطی پر متوسط ہو گئی: 0.766 F1 task 1 کے لئے (0.665 کے متوسط پر 15%), 0.47 F1 task 2 کے لئے (0.46 کے متوسط پر 2%) اور 0.380 F1 اسکور 3 کے لئے (0.292 کے متوسط پر 30%). ۲۰۱۹ میں SMM4H Shared Task کے بہت سے اعتباری مسلمانوں میں استعمال کیا گیا تھا، BERT contin-ues کو ٹویٹر ڈیٹوں کے لئے ADR اخراج میں استعمال کرنے کے لئے استعمال کیا گیا ہے.', 'ta': 'மருத்துவப் பாதுகாப்புக்கு சமூக ஊடகங்கள் பார்க்கப்பட்டுள்ளது. பாதுகாப்பு மருந்து விளைவுகளிலிருந்து தானாகவே வெளியேறுவதற்கான முறைமை மாறியிலிருந்து இரைதிசை குறியாக்கி மாதிரிகள் (BERT) மாதிரிகள் சிறந்த செயல்பாட்டை சமீபத்தில் பெரிய NLP செயல்களில் காட்டியிருக்கிறது, நாங்கள் SM4H பங்கிடப்பட்ட பணிகளில் சோதிக்க முடியவில்லை 1-3,  எங்கள் மூன்று கூட்டல்கள் அனைத்தும் சராசரி கூட்டத்திற்கும் மேல் முடிந்தது: 0. 766 F1 செயலில் 1 (சராசரி 0. 665க்கு மேல் 15% மேல், 0. 47 F1 செயல் 2 (சராசரி 0. 46 க்கு மேல் 2% மற்றும் 0. 380 F1 புள்ளி 3 (0 SMM4H பகிர்ந்த பணியின் தொகுப்பில் 2019 அதிக உயர்நிலையில் உள்ள அனுப்புதலில் பயன்படுத்தப்பட்டது, BERT தொடர்புகள் மூலம் ADR தகவல் வெளியீட்டிற்கான நிலை', 'uz': "Name Name Vazifaning bir necha katta NLP vazifalarda Bidirected Encoder Replacements (BERT) modellarini ko'proq bajarishni ko'rsatadi, biz SM4H vazifalarini 1 to 3 ga qaytarishga qaror qilishni qaror qildik. Biz taʼminlovchi maʼlumot va qoʻshimcha maʼlumotlar satrlaridan qoʻshilganligidan koʻproq va yaxshi bajarilgan BERT modellarning natijalarini joʻnatishga qaror qildik. Bizning uch imkoniyatlarimiz hamma guruhning o'rtacha hamma maqsadlaridan ortiq tugatdi: 1 vazifa uchun 0. 766 F1 (0. 665 dan ortiq 15% dan yuqori), vazifa 2 (0. 46 dan 2% dan ortiq) va vazifa 3 uchun 0. 380 F1 scori (0. 292 dan 30% dan yuqori). 2019-yilda SMM4H shartlangan vazifaning bir necha darajada, BERT kontin oynasida ADR taʼminlovchisi uchun xabar soʻzi bo'lishi uchun ishlatiladi.", 'vi': 'Mạng xã hội được xem là nguồn dữ liệu đầy hứa hẹn cho việc tăng cường thuốc men. Tuy nhiên, phương pháp khai thác các phản ứng phản ứng trái phép từ các truyền thông xã hội như Twitter vẫn cần phải được phát triển thêm trước khi có thể được liên quan đến các hoạt động bí mật về thuốc chống đối. Khi các mô- tơ mã hóa hai hướng từ mô hình transformer (BERT) đã cho thấy hiệu quả lớn trong nhiều công việc lớn gần đây, chúng tôi quyết định thử vai diễn của nó trên các tập tin chia sẻ SMR4H 1-3, bằng cách cung cấp kết quả của các mô hình BERT sẵn sàng và chỉnh cẩn thận mà không có thêm kiến thức nào hơn cái được thực hiện trong các tập tin chuyên gia và các tập tin gia dữ liệu khác. Ba tài liệu của chúng tôi đều kết thúc trên mức trung bình trong tất cả các đơn vị tham khảo: 0 Được dùng trong nhiều bài đệ trình cao cấp trong phiên bản 2009 của "SMM4H sẻ chia Nhiệm vụ"giao thức"của BERT tiếp theo là thời trang cao nhất trong giải cứu ADngược cho dữ liệu Twitter.', 'bg': 'Социалните медии се разглеждат като обещаващ източник на данни за фармакологична бдителност. Въпреки това, методите за автоматично извличане на нежелани лекарствени реакции от платформите на социалните медии като Туитър все още се нуждаят от допълнително развитие, преди да могат да бъдат включени надеждно в рутинните практики за фармакологична бдителност. Тъй като двупосочните кодери от моделите на трансформатори (БРТ) показаха отлична производителност в много от основните задачи на НЛП наскоро, решихме да тестваме ефективността му на споделените задачи от 1 до 3, като представим резултати от предварително тренирани и фино настроени модели без повече допълнителни знания от тези, които се извършват в наборите от данни за обучение и допълнителните набори от данни. Трите ни предложения се оказаха над средната стойност за всички отбори: 0,766 за задача 1 (15% над средната стойност от 0,665), 0,47 за задача 2 (2% над средната стойност от 0,46) и 0,380 за задача 3 (30% над средната стойност от 0,292). Използван в много от високопоставените предложения в изданието на Споделената задача през 2019 г., BERT продължава да бъде най-съвременен в извличането на АРС за данни в Туитър.', 'nl': 'Sociale media worden gezien als een veelbelovende gegevensbron voor geneesmiddelenbewaking. Hoe dan ook, methoden voor automatische extractie van bijwerkingen van sociale media platforms zoals Twitter moeten nog verder worden ontwikkeld voordat ze betrouwbaar kunnen worden opgenomen in routine farmacovigilantie praktijken. Omdat de Bidirectionele Encoder Representaties van Transformer (BERT)-modellen onlangs geweldige prestaties hebben laten zien in veel belangrijke NLP-taken, hebben we besloten om de prestaties ervan te testen op de SMM4H Shared Tasks 1 tot 3, door resultaten van vooraf getrainde en verfijnde BERT-modellen in te dienen zonder meer toegevoegde kennis dan die welke wordt meegenomen in de trainingsdatasets en aanvullende datasets. Onze drie inzendingen eindigden allemaal boven het gemiddelde over de inzendingen van alle teams: 0.766 F1 voor taak 1 (15% boven het gemiddelde van 0.665), 0.47 F1 voor taak 2 (2% boven het gemiddelde van 0.46) en 0.380 F1 score voor taak 3 (30% boven het gemiddelde van 0.292). BERT wordt gebruikt in veel van de hoge inzendingen in de 2019-editie van de SMM4H Shared Task en blijft state-of-the-art in ADR-extractie voor Twitter-gegevens.', 'da': 'Sociale medier er blevet set som en lovende datakilde til lægemiddelovervågning. Howev-er, metoder til automatisk ekstraktion af bivirkninger fra sociale medier platformer som Twitter stadig har brug for yderligere udvikling, før de kan medtages pålideligt i rutinemæssig lægemiddelovervågning praksis. Da BERT-modellerne (Bidirectional Encoder Representations from Transformer) har vist stor ydeevne i mange større NLP-opgaver for nylig, besluttede vi at teste dens ydeevne på SMM4H Shared Tasks 1 til 3 ved at indsende resultater af forudtrænede og finjusterede BERT-modeller uden mere viden end den, der bæres i træningsdatasæt og yderligere datasæt. Vores tre indsendelser endte alle over gennemsnittet i forhold til alle holds indsendelser: 0,766 F1 for opgave 1 (15% over gennemsnittet på 0,665), 0,47 F1 for opgave 2 (2% over gennemsnittet på 0,46) og 0,380 F1 score for opgave 3 (30% over gennemsnittet på 0,292). BERT bruges i mange af de højtrangerede indsendelser i 2019-udgaven af SMM4H Shared Task, og BERT er fortsat avanceret inden for ADR-udtrækning af Twitter-data.', 'hr': 'Društveni mediji smatraju obećavajućim izvorom podataka za farmakovigilanciju. Howev-er, metode za automatsku izvlačenje nuspojavnih reakcija iz formulara društvenih medija, poput Twitter, još uvijek trebaju daljnji razvoj prije nego se pouzdano uključuju u rutinsku farmakovigilanciju. Dok su predstavnici dvosmjernog kodera iz modela transformera (BERT) pokazali veliku učinku u mnogim velikim zadacima NLP-a nedavno, odlučili smo testirati svoj učinkovit na podjeljenim zadacima SMM4H-a od 1 do 3, podaći rezultate modela BERT-a bez dodatnih znanja nego one koji su nosili u podacima podataka i dodatnih podataka. Naše tri isporuke su završile iznad prosječnih isporuka svih podataka timova: 0,766 F1 za zadatak 1 (15% iznad prosječnog 0,665), 0,47 F1 za zadatak 2 (2% iznad prosječnog 0,46) i 0,380 F1 za zadatak 3 (30% iznad prosječnog 0,292). Koristili su se u mnogim od visokog podnošenja u izdanju SMM4H zajedničkog zadatka 2019. godine, BERT kontin-ues za izvlačenje ADR-a za podatke o Twitter-u.', 'de': 'Soziale Medien gelten als vielversprechende Datenquelle für Pharmakovigilanz. Allerdings müssen Methoden zur automatischen Extraktion unerwünschter Arzneimittelwirkungen aus Social-Media-Plattformen wie Twitter noch weiterentwickelt werden, bevor sie zuverlässig in routinemäßige Pharmakovigilanz-Praktiken einbezogen werden können. Da die bidirektionalen Encoder Repräsentationen von Transformer (BERT)-Modellen in letzter Zeit in vielen wichtigen NLP-Aufgaben eine hervorragende Leistung gezeigt haben, haben wir beschlossen, ihre Leistung auf den SMM4H Shared Tasks 1 bis 3 zu testen, indem wir Ergebnisse von vortrainierten und fein abgestimmten BERT-Modellen ohne mehr zusätzliches Wissen als in den Trainingsdatensätzen und zusätzlichen Datensätzen eingereicht haben. Unsere drei Einreichungen landeten alle über dem Durchschnitt aller Teams: 0.766 F1 für Aufgabe 1 (15% über dem Durchschnitt von 0.665), 0.47 F1 für Aufgabe 2 (2% über dem Durchschnitt von 0.46) und 0.380 F1 für Aufgabe 3 (30% über dem Durchschnitt von 0.292). BERT wird in vielen der hochrangigen Einreichungen in der 2019-Ausgabe des SMM4H Shared Task verwendet und ist weiterhin State-of-the-Art in der ADR-Extraktion für Twitter-Daten.', 'id': 'Social media have been seen as a promising data source for pharmacovigilance.  Howev-er, metode untuk ekstraksi otomatis dari Reaksi Alami obat dari platform media sosial seperti Twitter masih membutuhkan perkembangan lanjut sebelum mereka dapat termasuk dengan yakin dalam praktek farmakovigilans rutin. Sebagai Bidirectional Encoder Representations from Transformer (BERT) models have shown great performance in many major NLP tasks recently, we decided to test its performance on the SMM4H Shared Tasks 1 to 3, by submitting results of pre-training and fine-tuned BERT models without more added knowledge than the one carried in the training datasets and additional datasets. Tiga pengiriman kami semua berakhir di atas rata-rata atas pengiriman semua tim: 0,766 F1 untuk tugas 1 (15% di atas rata-rata 0,665), 0,47 F1 untuk tugas 2 (2% di atas rata-rata 0,46) dan 0,380 F1 skor untuk tugas 3 (30% di atas rata-rata 0,292). Digunakan dalam banyak pengiriman tinggi di edisi 2019 SMM4H Shared Task, BERT terus menjadi state-of-the-art dalam ekstraksi ADR untuk data Twitter.', 'ko': '소셜 미디어는 약물 경계의 유망한 데이터 원천으로 여겨진다.그러나 트위터 등 소셜미디어 플랫폼에서 약물 불량 반응을 자동으로 추출하는 방법은 더 개발돼야 정규 약물 경계 실천에 믿을 수 있다.Transformer(BERT) 모델의 양방향 인코더가 최근 많은 주요 NLP 작업에서 좋은 성능을 보였다고 밝혔기 때문에 우리는 SMM4H 공유 작업 1에서 3에서 그 성능을 시험하기로 결정했다. 방법은 예비 훈련과 미세 조정된 BERT 모델의 결과를 제출하는 것이고 훈련 데이터 집합과 부가 데이터에 집중된 지식보다 더 많은 부가 지식이 필요하지 않다는 것이다.우리의 세 차례 제출 결과는 모두 모든 팀의 평균 수준보다 높았다. 임무 1의 F1 성적은 0.766(평균 0.665보다 15% 높음), 임무 2의 F1 성적은 0.47(평균 0.46보다 2%), 임무 3의 F1 성적은 0.380(평균 0.292보다 30%) 순이었다.2019년판 SMM4H 공유 임무의 많은 고급 제출에서 버트 콘틴은 가장 선진적인 트위터 데이터 ADR 추출 기술을 사용했다.', 'fa': 'رسانه\u200cهای اجتماعی به عنوان منبع اطلاعات قول\u200cدهنده برای داروکاویژیلنس دیده شده\u200cاند. Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat forms such as Twitter still need further development before they can be included reliably in pharmacovigilance practices routine. همانطور که نمایش\u200cدهندگان رمزگار دورانی از مدل تغییر\u200cدهنده (BERT) عملکرد بزرگی در بسیاری از کارهای بزرگ NLP اخیرا نشان داده\u200cاند، تصمیم گرفتیم عملکرد آن را روی کار\u200cهای مشترک SMM4H ۱ تا ۳ امتحان کنیم، با فرستادن نتیجه\u200cهای مدل\u200cهای BERT پیش\u200cفرض و پاکیزه\u200cشده بدون دانش بیشتری از آن که در مجموعه\u200cهای داده\u200cهای سه فرستادن ما همه بالای متوسط بر روی تمام فرستادن گروه پایان یافتند: 0.766 F1 برای کار 1 (15% بالای متوسط 0.665), 0.47 F1 برای کار 2 (2% بالای متوسط 0.46) و 0.380 F1 برای کار 3 (30% بالای متوسط 0.292). در بسیاری از تحویل درجه بالا در نسخه ۲۰۱۹ از کار مشترک SMM4H استفاده می\u200cشود، BERT contin-ues که در استخراج ADR برای داده\u200cهای توئیتر استفاده می\u200cشود.', 'sw': 'Vyombo vya habari vya kijamii vimeonekana kuwa chanzo cha taarifa kinachoahidiwa kwa ajili ya usalama wa dawa. Howev-er, njia za kujitengeneza maoni ya dawa za madawa kutoka kwenye mitandao ya kijamii kama vile Twita bado inahitaji maendeleo zaidi kabla ya kuwaingiza katika mazingira ya usalama wa dawa. Wakati maoni ya Mradi wa Uandishi wa Kiraia kutoka BERT (BERT) wameonyesha utendaji mkubwa katika kazi nyingi kubwa za NLP hivi karibuni, tuliamua kujaribu utendaji wake kwenye kazi za SMM4H zilizoshirikisha majukumu 1 hadi 3, kwa kutuma matokeo ya modeli za BERT zilizotengenezwa na vizuri bila kujua zaidi ya yale yaliyobeba katika seti za mafunzo na seti za taarifa za ziada. Maasilisho yetu matatu yalimalizika zaidi ya wastani wa jumbe zote: 0.766 F1 kwa ajili ya kazi 1 (asilimia 15 zaidi ya wastani wa 0.665), 0.47 F1 kwa ajili ya kazi 2 (asilimia 2 zaidi ya wastani wa 0.46) na score 0.380 F1 kwa kazi 3 (asilimia 30 zaidi ya wastani wa 0.292). Imetumiwa katika ujumbe mkuu wa juu katika toleo la mwaka 2019 la MM4H lililoshirikishwa na kazi hiyo ya SMM4H, mahusiano ya BERT ili kuwa hali ya sanaa katika uteuzi wa ADR kwa takwimu za Twita.', 'tr': 'Sosial mediýatlar pharmakovigilançy üçin söz berýän data çeşmesi hökmünde görülýärler. Howev-er Transformer (BERT) nusgalarynyň Bidirectional Ködler ködlemeleri ýagdaýynyň birnäçe esasy NLP işinde gaty ukyp görkezilýän bolmagyny görkezilip, biz SMM4H Paýlanan Görevleriň 1 we 3-de üstine çykarmagyna karar berdik, Ewr nusgalarynyň üstüne süýtgedilen we gowy düzlenýän BERT modelleriniň netijesini görkezilýän we eğitim veri setirlerin Biziň üç gönderilenimiz hemme toparyň göndermeleriniň ortalamasynda ýokary boldy: 0.766 F1 taýýarlamak üçin 1 (15% ortalamasynda 0.665), 0.47 F1 taýýarlamak üçin 2 (2% ortalamasynda 0.46) we 0.380 F1 taýýarlamak üçin 3 (30% ortalamasynda 0.292). 2019-nji ýyldaky SMM4H Paýlaşan Görevinde, BERT contin-ues da ADR verileri üçin durum-of-the-art hasaplamak üçin ullanýar', 'af': "Soziale media is gesien as 'n beloftende data bron vir farmakovigilans. Howev-er, metodes vir outomatiese uittrekking van Adverse Drug Reactions van sosiale media platforme soos Twitter nog verdere ontwikkeling nodig voordat hulle vertroulik in routine farmakovigilanse praksies kan ingesluit word. Soos die tweederigtinglike enkoder voorstellings van Transformer (BERT) modele het groot prestasie in baie groot NLP opdragte onlangs vertoon, het ons besluit om sy prestasie te toets op die SMM4H Gedeelde Opdragte 1 tot 3 deur resultate van voorstel en fyn-geïnstalleerde BERT modele sonder meer bygevoeg kennis as die een wat in die onderwerking datastelle en addisionele datastelle gebring het. Ons drie onderdragte het al gevolg bo gemiddelde oor alle teams se onderdragte: 0. 766 F1 vir taak 1 (15% bo die gemiddelde van 0. 665), 0. 47 F1 vir taak 2 (2% bo die gemiddelde van 0. 46) en 0. 380 F1 telling vir taak 3 (30% bo die gemiddelde van 0. 292). Gebruik word in baie van die hoë-ranking onderskrywing in die 2019 uitgewing van die SMM4H deelde taak, BERT contin-ues om state-of-the-art in ADR uittrek vir Twitter data te wees.", 'sq': 'Media sociale është parë si një burim premtues i të dhënave për farmakovigilancën. Howev-er, metodat për nxjerrjen automatike të Reaksioneve të Pafavorshme të Drogëve nga platformat e medias sociale të tilla si Twitter ende kanë nevojë për zhvillim të mëtejshëm përpara se ato të përfshihen në mënyrë të besueshme në praktikat rutine të farmakovigilancës. Ndërsa përfaqësimet dy-drejtore të koduesve nga modelet e Transformer (BERT) kanë treguar performancë të madhe në shumë detyra të mëdha NLP kohët e fundit, vendosëm të testojmë performancën e saj në detyrat e përbashkëta 1 deri 3 SMM4H, duke dërguar rezultate të modeleve BERT të parastërvitura dhe të përshtatura pa më shumë njohuri të shtuar se ajo që mbahet në grupet e të dhënave të trajnimit dhe të dhënave shtesë. Të tre paraqitjet tona përfunduan mbi mesataren mbi paraqitjet e të gjitha ekipave: 0.766 F1 për detyrën 1 (15% mbi mesataren 0.665), 0.47 F1 për detyrën 2 (2% mbi mesataren 0.46) dhe 0.380 F1 për detyrën 3 (30% mbi mesataren 0.292). Përdorur në shumë nga paraqitjet e rangut të lartë në edicionin 2019 të SMM4H Task Shared, BERT vazhdon të jetë më i larti në nxjerrjen e ADR për të dhënat e Twitter.', 'am': 'ማኅበራዊ ሚዲያዎች ለfarm-አካባቢ መጠበቅ የተስፋ የዳታ ዕድሜ ነው፡፡ ሀዌብ-አ፣ ማኅበራዊ አውታር ሚዲያ ፕላላት-ፎርማዎች፣ በትዊተር ውስጥ በተመሳሳይ የሕዝብን አካባቢ አድራጊዎች ለመውጣት የሚችል ሥርዓት፣ ለዘላለም ማህበራዊ የሕንፃ አካባቢ ግንኙነት እንዲያስፈልጋል፡፡ የBidirectional Encoder Representatives from BERT models (BERT) በመጨረሻው ብዙ ታላላቅ NLP ስራ ውስጥ ትልቅ ስራዎችን እንዳሳየ፣ እኛ የSM4H ስራዎችን 1 to 3 በመጠቀም ፈተና ፈተናል፡፡ የሦስቱ መልዕክቶች ሁሉም ከውጤት የበለጠ ጠቅላላ ደረጃዎች ሁሉ በላይ ደረሱ፤ 0.766 F1 ለስራ 1 (average 0.665 በላይ 15 በመቶ), 0.47 F1 ለስራ 2 (average 0.46 በላይ 2 በመቶ በላይ 2 በመቶ) ለስራ 3 (በላይ 0.380 F1 score 30 በመቶ ከ0.292 በላይ). በ2019 የSM4H የተሰራጨው ስራ ክፍል ውስጥ በብዙ ደረጃዎች አካባቢ ጥያቄ ውስጥ BERT ግንኙነት አዳራዊ የኢትዮጵያ ትዊተር ዳታዎችን ለመውጣት የተጠቀም ነው፡፡', 'hy': 'Սոցիալական լրատվամիջոցները դիտարկվել են որպես ֆարմակոստիկայի դիտարկության խոստացող տվյալների աղբյուր: Հովեվը, այնպիսի մեթոդներ, որոնք օգտագործում են անհրաժեշտ թմրադեղերի արձագանքների ավտոմատիկ վերացումը սոցիալական լրատվամիջոցներից, ինչպիսիք են Թվիթերը, դեռևս պետք է զարգանան, մինչև դրանք կարելի է վստահելի ներառել սո Որովհետև վերջերս բազմաթիվ հիմնական ՆԼՊ-ի առաջադրանքների ընթացքում Երկու ուղղությամբ կոդավորվող ներկայացումները ցույց են տալիս մեծ արդյունք, մենք որոշեցինք ստուգել դրա արդյունքը SMM4H-ի կիսված առաջադրանքների 1-3 վրա, ներկայացնելով նախապատրաստված և բարձրացված BERT-ի մոդելների արդյունքները առանց ավելին գիտելիքների,  Մեր երեք ներկայացումները վերջացրեցին բոլոր թիմերի ներկայացումների միջին բարձրությամբ: 0.766 F1 1-ի համար (15 տոկոսը 0.665-ի միջին բարձրությամբ), 0.47 F1-ի համար 2-ի համար (2 տոկոսը 0.46-ի միջին բարձրությամբ) և 0.380 F1-ի համար 3-ի համար (30 տոկոսը 0.29-ի միջին բարձրությամբ): Օգտագործվում է SMM4H-ի կիսված հանձնարարության 2019 թվականի բարձր դասակարգման ներկայացումներից շատերին, BER-ը շարունակում է լինել Թվիթերի տվյալների ADR-ի լավագույնը:', 'bn': 'সামাজিক প্রচার মাধ্যম চাকুরি করার জন্য প্রতিশ্রুত তথ্য উৎস হিসেবে দেখা গেছে। Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat-forms such as Twitter still need further development before they can be included reliably in routine pharmacovigilance practices.  ট্রান্সফার্নের বাইডেল এনকোডার (বেরেটি) মডেলের প্রতিনিধি সম্প্রতি অনেক প্রধান এনএলপি কাজের মধ্যে ভালো প্রদর্শন করেছে, আমরা সিদ্ধান্ত নিয়েছি এসএমএফ৪H শেয়ার কর্মসূচীর উপর ১ থেকে ৩ থেকে তার প্রভাব পরী আমাদের তিনটি প্রতিযোগিতা সকল দলের প্রদানের মধ্যে সর্বোচ্চ পরিমাণ শেষ হয়েছে: ১ কাজের জন্য ০. ৭৬৬ এফ১ (গড়ি 0. 665 এর উপরে ১৫ শতাংশ), ০. 47 এফ১ কাজ ২ (গড়ে 0. 46 এর উপর ২% এবং ০. 380 F1 স্কোর ৩ (০. 292 এর উপরে  ২০১৯ সালে SMM4H শেয়ার করা কাজের সংস্করণে অনেক উচ্চমর্যাদা প্রদান করা হয়েছিল, বের্টির সংস্করণ ব্যবহার করা হয়েছিল যাতে এডিআর তথ্য বিনিময়ের জন্য এডা', 'az': 'Sosyal mediyalar pharmakovigilanlıq üçün vəd verilən məlumat mənbəsi olaraq görülür. Howev-er, Twitter kimi sosyal media platformlarından təşviq uyuşturucu reaksiyonların automatlı çıxarılması üçün metodlar, onlar rutinik pharmacovigilans praksilərində güvenilir olaraq daha da artıq gelişməyə ehtiyacı vardır. Transformer (BERT) modellerindən iki yönəli Kodlayıcı Görüntüləri yenidən çox böyük NLP işlərində böyük performans göstərdiyi kimi, biz onun performansını 1-3 SMM4H paylaşılmış işlərində imtahana çəkməyə karar verdik, təhsil veri qutuqlarında və əlavə veri qutuqlarında daşınmasından daha çox bilgi olmadan, təhsil edilmiş və təmizlənmiş BERT modellerinin sonuçlarını təhsil etmə Üç təkliflərimiz bütün təkliflərin təkliflərinin ortasından üstün oldu: 1 təklif üçün 0,766 F1 (0,665 ortasından 15%), 2 təklif üçün 0,47 F1 (0,46 ortasından 2%) və 3 təklif üçün 0,380 F1 score (0,292 ortasından 30%). 2019-ci SMM4H paylaşılmış Task in yayınlığında çox yüksək səviyyədə istifadə edilmişdir, BERT contin-ues, Twitter məlumatları üçün ADR məlumatının vəziyyəti-state-of-the-art olaraq istifadə edilmişdir.', 'bs': 'Socijalni mediji smatraju obećavajućim izvorom podataka za farmakovigilanciju. Howev-er, metode za automatsku izvlačenje nuspojavnih reakcija iz forma socijalnih medija, poput Twitter, još uvijek trebaju daljnji razvoj prije nego što se mogu pouzdano uključiti u rutinsku farmakovigilanciju. Kako su predstavnici dvosmjernog kodera iz modela transformera (BERT) pokazali veliku učinku u mnogim velikim zadacima NLP-a nedavno, odlučili smo testirati svoj učinkovit na podjeljenim zadacima SMM4H 1 do 3, podajući rezultate modela BERT-a bez dodatnih znanja nego onaj koji je nosio u setama podataka i dodatnih seta podataka. Naše tri podatke su završile iznad prosječnih podataka svih timova: 0,766 F1 za zadatak 1 (15% iznad prosječnog 0,665), 0,47 F1 za zadatak 2 (2% iznad prosječnog 0,46) i 0,380 F1 za zadatak 3 (30% iznad prosječnog 0,292). Koristili su se u mnogim od visokog podnošenja u izdanju SMM4H zajedničkog zadatka 2019. godine, BERT kontin-ues za izvlačenje ADR-a za podatke o Twitter.', 'cs': 'Sociální média jsou považovány za slibný zdroj dat pro farmakovigilanci. Metody automatické extrakce nežádoucích léčivých účinků z platformy sociálních médií, jako je Twitter, však stále potřebují další rozvoj, než mohou být spolehlivě začleněny do rutinních farmakovigilančních postupů. Vzhledem k tomu, že reprezentace obousměrného kódování z modelů Transformer (BERT) v poslední době prokázaly skvělý výkon v mnoha hlavních úlohách NLP, jsme se rozhodli otestovat jeho výkon na SMM4H Shared Tasks 1 až 3, předložením výsledků předtrénovaných a jemně vyladěných modelů BERT bez více přidaných znalostí, než které jsou v souborech školení a dalších datových sadách. Všechny naše tři příspěvky skončily nadprůměrně u všech týmů: 0.766 F1 pro úkol 1 (15% nad průměrem 0.665), 0.47 F1 pro úkol 2 (2% nad průměrem 0.46) a 0.380 F1 skóre pro úkol 3 (30% nad průměrem 0.292). BERT se používá v mnoha vysoce postavených příspěvcích v 2019 edici sdíleného úkolu SMM4H a je nadále nejmodernější v extrakci ADR pro Twitterová data.', 'et': 'Sotsiaalmeediat on peetud ravimiohutuse järelevalve paljulubavaks andmeallikaks. Kuid meetodid kõrvaltoimete automaatseks ekstraheerimiseks sotsiaalmeedia platvormidelt, nagu Twitter, vajavad veel täiendavat arengut, enne kui neid saab usaldusväärselt kaasata ravimiohutuse järelevalve tavadesse. Kuna kahesuunalised kodeerijad Transformeri mudelitest (BERT) on viimasel ajal näidanud suurepärast jõudlust paljudes suuremates NLP ülesannetes, otsustasime testida selle jõudlust SMM4H jagatud ülesannetes 1 kuni 3, esitades eeltreenitud ja täpsustatud BERT mudelite tulemused ilma rohkemate teadmisteta kui koolitusandmekogumites ja täiendavates andmekogumites. Meie kolm esitatud tulemust olid kõigi meeskondade esitatud tulemuste puhul keskmisest kõrgemad: 0,766 F1 1. ülesande puhul (15% üle 0,665 keskmise), 0,47 F1 2. ülesande puhul (2% üle 0,46 keskmise) ja 0,380 F1 skoor 3. ülesande puhul (30% üle 0,292 keskmise). BERT, mida kasutatakse paljudes SMM4H jagatud ülesande 2019. aasta väljaandes esitatud kõrgetasemelistes esitustes, on jätkuvalt viimase tasemega vaidluste kohtuvälise lahendamise Twitteri andmete väljavõtmisel.', 'ca': "Els mitjans socials han estat vists com una fontde dades prometedora per a la farmacovigilància. Howev-er, els mètodes d'extracció automàtica de reaccions adversas a medicaments de plataformes de mitjans socials com Twitter encara necessiten més desenvolupament abans que es puguin incloure de manera fiable en pràctiques de farmacovigilància de rutina. Com els models de codificadors bidireccionals de Transformer (BERT) han demostrat un gran rendiment en moltes tasques importants de NLP recentment, vam decidir testar el seu rendiment en les tasques compartides SMM4H 1 a 3, enviant resultats de models BERT pré-entrenats i fins ajustats sense més coneixement que el portat en els conjunts de dades d'entrenament i en conjunts de dades adicionals. Totes les nostres tres presentacions van acabar més enllà de la mitjana en tots els equips: 0,766 F1 per a la tasca 1 (15% més enllà de la mitjana de 0,665), 0,47 F1 per a la tasca 2 (2% més enllà de la mitjana de 0,46) i 0,380 F1 per a la tasca 3 (30% més enllà de la mitjana de 0,292). Utilitzat en moltes de les presentacions d'alt rangde l'edició 2019 de la SMM4H Shared Task, el BERT continua a ser l'última en l'extracció ADR per a les dades de Twitter.", 'fi': 'Sosiaalinen media on nähty lupaavana lääketurvatoiminnan tietolähteenä. Kuitenkin menetelmiä haittavaikutusten automaattiseksi erottamiseksi sosiaalisen median platform-muodoista, kuten Twitter, on edelleen kehitettävä, ennen kuin ne voidaan luotettavasti sisällyttää rutiininomaisiin lääketurvatoimintakäytäntöihin. Koska Bidirectional Encoder Representations from Transformer (BERT) -mallit ovat viime aikoina osoittaneet suurta suorituskykyä monissa tärkeissä NLP-tehtävissä, päätimme testata sen suorituskykyä SMM4H Shared Tasks 1–3 lähettämällä esikoulutettujen ja hienoviritettyjen BERT-mallien tulokset ilman lisätietoa kuin koulutustiedoissa ja lisätiedoissa. Kaikki kolme työtämme päätyivät kaikkien joukkueiden tekemien ehdotusten keskiarvon yläpuolelle: 0,766 F1 tehtävässä 1 (15% yli 0,665 keskiarvon), 0,47 F1 tehtävässä 2 (2% yli 0,46 keskiarvon) ja 0,380 F1-pisteet tehtävässä 3 (30% yli 0,292 keskiarvon). BERT:tä käytetään monissa SMM4H Shared Task -julkaisun 2019 korkean tason julkaisuissa, ja se on edelleen uusinta tekniikkaa Twitter-tietojen ADR-hankinnassa.', 'ha': "An gane mutane da jamii kamar wani zance wa data wa tsarin farmakokin. @ info: whatsthis As the Bidiridal Encoder Repositions from Transformer (BERT) motels have nuna mai girma performance in many major tasks of NLP lately, we zãɓe to jarraba performance on the SMM4H Shared Tasks 1 to 3, by Submiting the matsalar of late and fin-tuned BERT motels bã da addin wani ilmi fãce the one who was ɗaud in the data set and addive data set. Tunu sakarinMu uku sun ƙara tsakanin duk jama'a-biyu: 0.766 F1 wa aikin 1 (15% bisa tsakanin 0.665), 0.47 F1 wa aikin 2 (2% bisa gwargwadon 0.46) da 0.380 F1 score wa aikin 3 (30% bisa tsakanin 0.292). Yi amfani da cikin masu yawa daga ranked-ranked inputs in the 2019 edition of the SMM4H Shared Taaikin, BERT contin-es to be state-of-the-art in ADR Extractin data for Twitter data.", 'sk': 'Družbeni mediji so bili obravnavani kot obetaven vir podatkov za farmakovigilanco. Vendar pa je treba metode za avtomatsko ekstrakcijo neželenih učinkov zdravil iz platform socialnih medijev, kot je Twitter, še naprej razviti, preden jih je mogoče zanesljivo vključiti v rutinske farmakovigilance. Ker so predstavitve dvosmernih kodirnikov iz transformatorjev (BERT) v zadnjem času pokazali odlično učinkovitost pri številnih večjih nalogah NLP, smo se odločili, da preizkusimo njegovo učinkovitost na skupnih nalogah SMM4H 1 do 3, tako da predložimo rezultate predtreniranih in natančno nastavljenih BERT modelov brez dodatnega znanja kot tisto v naborih podatkov usposabljanja in dodatnih naborih podatkov. Naši trije prispevki so se končali nad povprečjem vseh prispevkov ekip: 0,766 F1 za nalogo 1 (15% nad povprečjem 0,665), 0,47 F1 za nalogo 2 (2% nad povprečjem 0,46) in 0,380 F1 za nalogo 3 (30% nad povprečjem 0,292). BERT, ki se uporablja v številnih visokih predložitvah v izdaji skupne naloge SMM4H za leto 2019, je še naprej najsodobnejši pri pridobivanju ARS za podatke Twitterja.', 'jv': 'Media sing sotiné dikondisih kaya perbudhakan data kanggo ngilangno pak. Name Taning kamu model Bidirectial decoder representations from Transformer Awak dhéwé telu mituhé gawe lan mulai kanggo kalagayut sabên dengané sabên ning gunggo sing gawe: 0. Ngawe jeneng nggawe akeh sing paling-seneng nggawe luwih dumadhi kanggo awak dhéwé 2011 lan kelompok SMM4H Taraké Daftar, BERT conten-es kanggo kelompok state-of-the-arts kanggo kelompok DER kanggo awak dhéwé Google', 'he': 'התקשורת החברתית נראתה כמקור מידע מבטיח לפרמוקרפיגנציה. הוואב-ר, שיטות לחלץ אוטומטי של תגובות תרופות רפואיות ממתקנות התקשורת החברתית כמו טוויטר עדיין זקוקות לפיתוח נוסף לפני שהם יכולים להיות כוללים באופן אמין בפרקטיקות שגרתיות של פארקופיגנציה. כפי שהמודלים של קודד שתי כיוונים (BERT) הראו ביצועים גדולים במשימות רבות של NLP לאחרונה, החלטנו לבדוק את ביצועיו על משימות משותפות SMM4H 1-3, על ידי שליחת תוצאות של מודלים BERT מתאימים מראש ומתאימים ללא ידע נוסף יותר מאשר אחד שנשאר במערכת נתונים האימונים ומערכת נתונים נוספים. כל שלושת השימושים שלנו הסתיימו מעל הממוצע על כל השימושים של הקבוצות: 0.766 F1 עבור משימה 1 (15% מעל הממוצע של 0.665), 0.47 F1 עבור משימה 2 (2% מעל הממוצע של 0.46) ו-0.380 F1 עבור משימה 3 (30% מעל הממוצע של 0.292). בשימוש בהרבה מהמשימות הגבוהות בעורך 2019 של המשימה המשותפת SMM4H, BERT ממשיך להיות מוקדם ביותר בהוצאה ADR עבור מידע טוויטר.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་གསལ་གྱིས་གསོག་ཆའི་ནང་དུ་ཆ་འཕྲིན་ཡིག་ཆའི་ནང་དུ་བློ་གཏོང་བ་རེད། Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat-forms such as Twitter still need further development before they can be included reliably in routine pharmacovigilance practices. As the Bidirectional Encoder Representations from Transformer (BERT) models have shown great performance in many major NLP tasks recently, we decided to test its performance on the SMM4H Shared Tasks 1 to 3, by submitting results of pretrained and fine-tuned BERT models without more added knowledge than the one carried in the training datasets and additional datasets. ང་ཚོའི་མཇུག་སྡུད་མི་གྲངས་མཇུག་བསྡུ་ཡོད་པའི་ཚོགས་གཟུགས་ཀྱི་ནང་དུ་བཏོན་གཏོང་ཚར་བར་མཇུག 2019ལྟ་བུའི་དཔེ་བསྐྲུན་ཐོག་ལས་མཐོ་རིམ་པ་མང་པོ་ཞིག་གིས་སྤྱོད་སྤྱད་ཡོད་པའི་ SMM4H མཉམ་སྤྱོད་གྱི་བྱ་སྤྱོད་ཀྱི་ནང་དུ་ཡོད།'}
{'en': 'FBK@SMM4H2020 : RoBERTa for Detecting Medications on Twitter FBK @ SMM 4 H 2020:  R o BERT a for Detecting Medications on  T witter', 'ar': 'FBK @ SMM4H2020: RoBERTa لاكتشاف الأدوية على تويتر', 'es': 'FBK @SMM4H2020: RoBerta para detectar medicamentos en Twitter', 'fr': 'FBK @SMM4H2020\xa0: Roberta pour la détection de médicaments sur Twitter', 'pt': 'FBK@SMM4H2020: RoBERTa para detectar medicamentos no Twitter', 'ja': 'FBK @ SMM 4 H 2020: RoBERTa for Detecting Medications on Twitter', 'zh': 'FBK@SMM4H2020:RoBERTa以检药于Twitter', 'ru': 'FBK@SMM4H2020: RoBERTa для обнаружения лекарств в Twitter', 'hi': 'FBK@SMM4H2020: चहचहाना पर दवाओं का पता लगाने के लिए RoBERTa', 'ga': 'FBK@SMM4H2020: RoBERTa as Cógais a Bhrath ar Twitter', 'ka': 'FBK@SMM4H2020 : RoBERTa Twitter-ში მედიციების განახსნა', 'el': 'FBK@SMM4H2020 RoBERTa για την ανίχνευση φαρμάκων στο Twitter', 'hu': 'FBK@SMM4H2020 RoBERTa a gyógyszerek felismeréséért a Twitteren', 'kk': 'FBK@SMM4H2020 : Твиттердегі медикаменттерді анықтау үшін RoBERTa', 'it': 'FBK@SMM4H2020 RoBERTa per il rilevamento dei farmaci su Twitter', 'lt': 'FBK@SMM4H2020 : RoBERTa, skirtas vaistų nustatymui Twitter', 'mk': 'FBK@SMM4H2020 : RoBERTa for Detecting Medications on Twitter', 'ml': 'FBK@SMM4H2020 - ടൂട്ടരില്\u200d മെഡിക്കലേഷന്\u200d ഡിറ്റീറ്റ് ചെയ്യുന്നതിന് റോബെര്\u200dട്ട', 'ms': 'FBK@SMM4H2020 : RoBERTa for Detecting Medications on Twitter', 'mn': 'FBK@SMM4H2020 : Твиттерт эмчилгээ олохын тулд Роберта', 'mt': 'FBK@SMM4H2020 : RoBERTa għad-Detezzjoni tal-Medikazzjonijiet fuq Twitter', 'ro': 'FBK@SMM4H2020 RoBERTa pentru detectarea medicamentelor pe Twitter', 'pl': 'FBK@SMM4H2020 RoBERTa do wykrywania leków na Twitterze', 'no': 'FBK@SMM4H2020 : RoBERTa for oppdaging av medikasjonar på Twitter', 'sr': 'FBK@SMM4H2020 RoBERTa za otkrivanje lijekova na Twitter-u', 'so': 'FBK@SMM4H2020 : RoBERta for Detection Medicinations on Twitter', 'si': 'FBK@SMM4H2020 @ info: whatsthis', 'ta': 'FBK@SMM4H2020 - டுவிட்டரில் சிகிச்சைகளை கண்டுபிடிப்பதற்கான ரோபெர்டா', 'sv': 'FBK@SMM4H2020 RoBERTa för att upptäcka läkemedel på Twitter', 'ur': 'FBK@SMM4H2020 : ٹویٹر پر میڈیکسوں پتچا کرنے کے لئے روبرٹا', 'uz': 'FBK@SMM4H2020 Twitterda narsalarni aniqlash uchun RoBERTA', 'vi': 'FBK@SMM4H2020 RoBERTa cho việc trinh thám y trên Twitter.', 'bg': 'FBK@SMM4H2020 Роберта за откриване на лекарства в Туитър', 'hr': 'FBK@SMM4H2020 RoBERTa za otkrivanje lijekova na Twitter-u', 'da': 'FBK@SMM4H2020 RoBERTa til detektering af medicin på Twitter', 'nl': 'FBK@SMM4H2020 RoBERTa voor het opsporen van medicijnen op Twitter', 'de': 'FBK@SMM4H2020 RoBERTa zum Nachweis von Medikamenten auf Twitter', 'id': 'FBK@SMM4H2020 : RoBERTa untuk Detektif Medikasi di Twitter', 'fa': 'FBK@SMM4H2020 : RoBERTa for Detecting Medications on Twitter', 'sw': 'FBK@SMM4H2020 : RoBERTa kwa ajili ya kuchunguza Madaktari kwenye mtandao wa Twita', 'tr': 'FBK@SMM4H2020 : RoBERTa Taýýarlary Aňlamak üçin', 'af': 'FBK@SMM4H2020 : RoBERTa vir ontdekking van medikasies op Twitter', 'sq': 'FBK@SMM4H2020 : RoBERTa për Detektimin e Medikacioneve në Twitter', 'am': 'FBK@SMM4H2020 - RoBERta for Detecting Meditation on Twitter', 'hy': 'FBK@SMM4H2020 Ռոբերտա Թվիթերում բժշկումներ հայտնաբերելու համար', 'az': 'FBK@SMM4H2020 Tövratdakı Medikamalar keşfetmək üçün RoBERTa', 'bn': 'FBK@SMM4H2020 টুইটারে মেডিকেশন সন্ধান করার জন্য রোবের্তা', 'bs': 'FBK@SMM4H2020 RoBERTa za otkrivanje lijekova na Twitter-u', 'ca': 'FBK@SMM4H2020 : RoBERTa per detectar medicacions a Twitter', 'cs': 'FBK@SMM4H2020 RoBERTa pro detekci léků na Twitteru', 'ko': 'FBK@SMM4H2020: RoBERTA, 트위터에서 약물 검출', 'et': 'FBK@SMM4H2020 RoBERTa ravimite tuvastamise eest Twitteris', 'fi': 'FBK@SMM4H2020 RoBERTa for Detecting Medications on Twitter', 'jv': 'FBK@SMM4H2020 : RBERT kanggo Ketoken Media Nan Google', 'ha': 'FBK@SMM4H2020 @ info: whatsthis', 'he': 'FBK@SMM4H2020 : RoBERTa עבור גילוי תרופות בטוויטר', 'sk': 'FBK@SMM4H2020 RoBERTa za odkrivanje zdravil na Twitterju', 'bo': 'FBK@SMM4H2020 : RoBERTa ཌིས་ཌིའི་ནང་གི་སྒྲ་བརྙན་གཏོང་བ'}
{'en': 'This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer. We developed such a system for our participation in Subtask 1 of the Social Media Mining for Health Application workshop, which featured an extremely unbalanced dataset. The  model  showed promising results, with an F1 of 0.8 (task mean : 0.66).', 'ar': 'تصف هذه الورقة مُصنِّفًا للتغريدات التي تذكر الأدوية أو المكملات الغذائية ، بناءً على محول مُحدد مسبقًا. قمنا بتطوير مثل هذا النظام لمشاركتنا في Subtask 1 من ورشة عمل تطبيق Social Media Mining for Health Application ، والتي تضمنت مجموعة بيانات غير متوازنة للغاية. أظهر النموذج نتائج واعدة ، مع F1 من 0.8 (متوسط المهمة: 0.66).', 'fr': "Cet article décrit un classificateur pour les tweets qui mentionnent des médicaments ou des suppléments, basé sur un transformateur préentraîné. Nous avons développé un tel système pour notre participation à la sous-tâche 1 de l'atelier Social Media Mining for Health Application, qui présentait un ensemble de données extrêmement déséquilibré. Le modèle a donné des résultats prometteurs, avec un F1 de 0,8 (moyenne de la tâche\xa0: 0,66).", 'es': 'Este artículo describe un clasificador para tuits que mencionan medicamentos o suplementos, basado en un transformador previamente entrenado. Desarrollamos un sistema de este tipo para nuestra participación en la subtarea 1 del taller de aplicaciones de Social Media Mining for Health, que presentó un conjunto de datos extremadamente desequilibrado. El modelo mostró resultados prometedores, con una F1 de 0.8 (media de la tarea: 0.66).', 'pt': 'Este artigo descreve um classificador para tweets que mencionam medicamentos ou suplementos, baseado em um transformador pré-treinado. Desenvolvemos esse sistema para nossa participação na Subtarefa 1 do workshop Social Media Mining for Health Application, que contou com um conjunto de dados extremamente desequilibrado. O modelo apresentou resultados promissores, com F1 de 0,8 (média da tarefa: 0,66).', 'ja': 'この論文では、事前に訓練された変圧器に基づいて、薬またはサプリメントについて言及したツイートの分類子について説明します。私たちは、ソーシャルメディアマイニングフォーヘルスアプリケーションワークショップのサブタスク1に参加するためのこのようなシステムを開発しました。このワークショップには、非常にバランスの悪いデータセットが含まれていました。このモデルは有望な結果を示し、F 1は0.8であった（タスク平均： 0.66 ）。', 'zh': '本文述预练变压器之推文分类器,言及药补充剂。 为社交媒体掘健用研讨会子务1发此一统,当研讨会极不平之数。 其形见所欲,F1为0.8(任平均值:0.66)。', 'ru': 'Эта статья описывает классификатор для твитов, в которых упоминаются лекарства или добавки, на основе предварительно обученного трансформатора. Мы разработали такую систему для нашего участия в подзадаче 1 семинара Social Media Mining for Health Application, на котором был представлен чрезвычайно несбалансированный набор данных. Модель показала многообещающие результаты, со средним значением F1 0,8 (среднее задание: 0,66).', 'hi': 'यह पेपर उन ट्वीट्स के लिए एक क्लासिफायर का वर्णन करता है जो दवाओं या सप्लीमेंट्स का उल्लेख करते हैं, जो एक पूर्वप्रशिक्षित ट्रांसफार्मर के आधार पर होता है। हमने स्वास्थ्य अनुप्रयोग कार्यशाला के लिए सोशल मीडिया माइनिंग के सबटास्क 1 में हमारी भागीदारी के लिए ऐसी प्रणाली विकसित की, जिसमें एक अत्यंत असंतुलित डेटासेट शामिल था। मॉडल ने 0.8 के F1 (कार्य का मतलब: 0.66) के साथ आशाजनक परिणाम दिखाए।', 'ga': 'Déanann an páipéar seo cur síos ar aicmitheoir le haghaidh tweets a luann cógais nó forlíontaí, bunaithe ar chlaochladán réamhoilte. D’fhorbraíomar a leithéid de chóras dár rannpháirtíocht i bhFothasc 1 den cheardlann um Mianadóireacht ar na Meáin Shóisialta le haghaidh Feidhmchláir Sláinte, a raibh tacar sonraí neamhchothromaithe ann. Léirigh an tsamhail torthaí gealltanais, le F1 de 0.8 (meán tasc: 0.66).', 'ka': 'ეს დოკლიფიკაცია კლასიფიკაცია ტვიტებისთვის, რომელიც ამოხსენებს მედიკაციები ან დამატებები, რომელიც გადაწყენებული ტრანფორმენტებისთვის. ჩვენ ასეთი სისტემის გავაკეთეთ სამუშაო სამუშაო სამუშაო მედიაში სამუშაო სამუშაო სამუშაო სამუშაო პროგრამების სამუშაო, რომელიც გავა მოდელის მონაცემები 0.8-ის F1-ს გამოიყენება (სამუშაო მონაცემები: 0.66).', 'it': 'Questo articolo descrive un classificatore per tweet che menzionano farmaci o integratori, basato su un trasformatore pre-addestrato. Abbiamo sviluppato un sistema di questo tipo per la nostra partecipazione al Subtask 1 del workshop Social Media Mining for Health Application, che presentava un set di dati estremamente sbilanciato. Il modello ha mostrato risultati promettenti, con una F1 di 0,8 (task mean: 0,66).', 'kk': 'Бұл қағаз медицина не қосымшаларды есептеп жатқан tweets үшін классификаторын таңдайды. Бұл қағаз өзгертілген трансформацияның негізінде. Біз 1- тапсырманың социалдық медиа бағдарламалардың саулық бағдарламалардың бағдарламалардың 1- тапсырмасына қатысу жүйесін жасадық. Бұл өте балансыз деректер жинағын көрсету. Бұл үлгі 0, 8 деген F1 (тапсырманың орташасы: 0, 66) нәтижесін көрсетті.', 'el': 'Αυτή η εργασία περιγράφει έναν ταξινομητή για τα tweets που αναφέρουν φάρμακα ή συμπληρώματα, με βάση έναν προκαθορισμένο μετασχηματιστή. Αναπτύξαμε ένα τέτοιο σύστημα για τη συμμετοχή μας στην Υποεργασία 1 του εργαστηρίου Εξόρυξη Κοινωνικών Μέσων για την Εφαρμογή Υγείας, το οποίο περιείχε ένα εξαιρετικά ανισόρροπο σύνολο δεδομένων. Το μοντέλο έδειξε πολλά υποσχόμενα αποτελέσματα, με F1 των 0.8 (μέσος όρος εργασίας: 0.66).', 'hu': 'Ez a tanulmány leírja a tweetek osztályozóját, amelyek gyógyszereket vagy kiegészítőket említenek, egy előkészített transzformátor alapján. Egy ilyen rendszert fejlesztettünk ki a Social Media Mining for Health Application workshop 1. alcsoportján való részvételünkre, amely rendkívül kiegyensúlyozatlan adatkészletet tartalmazott. A modell ígéretes eredményeket mutatott, F1 0,8 (feladatátlag: 0,66).', 'mk': 'Овој весник опишува класификатор за твитови кој споменува лекови или дополнители, базиран на претрениран трансформатор. Ние развивме ваков систем за нашето учество во подзадачата 1 на работилницата за социјална медиумска минирање за здравствена апликација, која имаше екстремно небалансиран податок. Моделот покажа ветувачки резултати, со F1 од 0,8 (просечна задача: 0,66).', 'ms': 'Kertas ini menggambarkan pengklasifikasi untuk tweet yang menyebutkan ubat atau tambahan, berdasarkan pengubah terlatih. Kami mengembangkan sistem seperti ini untuk berpartisipasi dalam Subtask 1 dari Pelabuhan Media Sosial untuk Aplikasi Kesehatan, yang mengandungi set data yang sangat tidak seimbang. Model menunjukkan hasil yang berjanji, dengan F1 0.8 (bermata tugas: 0.66).', 'ml': 'ഈ പത്രത്തില്\u200d മെഡിക്കല്\u200d അല്ലെങ്കില്\u200d ഉപയോഗിക്കുന്നതിനെക്കുറിച്ച് വിശദീകരിക്കുന്ന ഒരു ടൂട്ടുകള്\u200d വിവരിക്ക സോഷ്യല്\u200d മിഡിയയില്\u200d പങ്കെടുക്കുന്നതിനുള്ള സാമൂഹ്യ പ്രയോഗപ്രയോഗത്തിനുള്ള ശേഖരത്തില്\u200d ഞങ്ങള്\u200d ഇതുപോലുള്ള ഒരു സിസ്റ്റം നിര്\u200dമ് മോഡല്\u200d പ്രതീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചിരിക്കുന്നു, 0. 8-ല്\u200d ഒരു F1 (ജോലിയുടെ അര്\u200dത്ഥം: 0. 66).', 'mt': 'Dan id-dokument jiddeskrivi klassifikatur għal tweets li jsemmu mediċini jew supplimenti, ibbażat fuq trasformatur imħarreġ minn qabel. Aħna żviluppajna sistema bħal din għall-parteċipazzjoni tagħna fis-Sottokompitu 1 tal-workshop dwar il-Minjieri tal-Midja Soċjali għall-Applikazzjoni tas-Saħħa, li kien fih sett ta’ dejta estremament mhux bilanċjat. The model showed promising results, with an F1 of 0.8 (task mean: 0.66).', 'lt': 'This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer.  Mes sukūrėme tokią sistemą, kad dalyvautume Social in ės žiniasklaidos kasybos praktinio seminaro, kuriame dalyvavo itin nesubalansuotas duomenų rinkinys, 1 posėdyje. Modelis parodė perspektyvius rezultatus, kurių F1 buvo 0,8 (užduočių vidurkis – 0,66).', 'pl': 'W artykule opisano klasyfikator tweetów, które wspominają o lekach lub suplementach, oparty na wstępnie trenowanym transformatorze. Opracowaliśmy taki system dla naszego udziału w Podzadaniu 1 warsztatu Social Media Mining for Health Application, który zawierał wyjątkowo niezrównoważony zbiór danych. Model wykazał obiecujące wyniki, z F1 od 0.8 (średnia zadania: 0.66).', 'ro': 'Această lucrare descrie un clasificator pentru tweets-uri care menționează medicamente sau suplimente, bazat pe un transformator pre-instruit. Am dezvoltat un astfel de sistem pentru participarea la Subsarcina 1 a atelierului Social Media Mining for Health Application, care a prezentat un set de date extrem de dezechilibrat. Modelul a prezentat rezultate promițătoare, cu un F1 de 0,8 (media sarcinii: 0,66).', 'mn': 'Энэ цаас нь эмийн эсвэл нэмэлт нэмэлт гэдэг tweets-ийн хувилбарыг тайлбарладаг. Бид нийгмийн Media Mining for Health Application Workshop-ын 1-р субтайгаар оролцох системийг хөгжүүлсэн. Энэ нь маш балансаргүй өгөгдлийн санг харуулсан. Загвар нь 0.8-ын F1-тэй амлалтай үр дүнг харуулсан (ажлын mean: 0.66).', 'no': 'Denne papiret beskriver ein klassifiserer for tweeter som mener medikamenter eller supplementar, basert på ein pretrained transformer. Vi utvikla slike systemet for deltaken vår i Subtask 1 av arbeidsområdet for sosiale medier-mining for helseprogrammet, som viste ein ekstremt ubebalansert dataset. Modellen viste forståande resultat, med ein F1 av 0,8 (oppgåvegjennomsnitt: 0,66).', 'so': 'Warqaddaas wuxuu ku qoraa fascis, kaas oo ku saabsan daawooyinka ama qalabka ku saabsan wareejinta hore. Waxaannu horumarinnay nidaam caynkaas ah oo a an ka qayb galno sub-task 1 ee warqadda caafimaadka ee shabakadda bulshada ah ee daryeelka caafimaadka, kaas oo qabanqaabinaya koox macluumaad aan kala qiimo lahayn. Tusaale wuxuu tusay resultooyin ballan ah, kaasoo leh F1 oo ka mid ah 0.8 (shaqo macnaheedu waa 0.66).', 'sv': 'Denna uppsats beskriver en klassificerare för tweets som nämner mediciner eller kosttillskott, baserad på en förkränad transformator. Vi utvecklade ett sådant system för vårt deltagande i Underuppgift 1 i workshopen Social Media Mining for Health Application, som innehöll ett extremt obalanserat dataset. Modellen visade lovande resultat, med en F1 på 0,8 (arbetsmedelvärde: 0,66).', 'ur': 'This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer. ہم نے سوسیل میڈیا مینینگ کارشاپ کے لئے اس طرح کا سیستم ایجاد کیا تھا جو ایک بہت نابرالکس ڈیٹ سٹ کو دکھایا تھا۔ موڈل نے 0.8 میں سے F1 کے ساتھ وعدہ کا نتیجہ دکھایا (کام کا معنی 0.66).', 'sr': 'Ovaj papir opisuje klasifikatora za tweets koji spominju lekove ili dodatke, na osnovu pretkišnog transformatora. Razvili smo takav sistem za sudjelovanje u podzadatku 1 radionici za rudarstvo socijalnih medija za zdravstvene aplikacije, koji je uključio izuzetno nepravednost kompleta podataka. Model je pokazao obećavajuće rezultate, sa F1 od 0,8 (zadatak znači 0,66).', 'ta': 'இந்த காகிதத்தில் ஒரு வகுப்பான் தொடர்புகளை குறிப்பிடுகிறது மருத்துவ அல்லது சேர்ப்புகளை குறிப்பிடுகிறது, முன நாங்கள் தொழில்நுட்பமான தொழில்நுட்பத்தை உருவாக்கினோம் சாலிக ஊடகங்கள் துணை பணியில் ஒன்றில் பார்ப்போம், அது மிகவும் சமமில்லாத The model showed promising results, with a F1 of 0. 8 (work mean: 0. 66).', 'si': 'මේ පැත්තේ විශේෂකයෙක් විස්තර කරනවා විද්\u200dයාවක් නැති විද්\u200dයාවක් නැති විද්\u200dයාවක් නැති විද්\u200dයාවක්, ප්\u200dරි අපි සාමාජික මාධ්\u200dයම විශ්වාස කරන්නේ සාමාජික මාධ්\u200dයම විශ්වාස කරන්නේ සාමාජික මාධ්\u200dයම විශ්වාස කරපු විදියට අපේ  මොඩල් එක පොරොන්දු ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන්, 0.8 වල F1 වලින් (ව', 'uz': "Bu qogʻoz o'zgarishni tasavvur qiladigan tizim yoki qo'shishlarni anglatadi. Bunday tizimni saqlash uchun sosial dastur workshopiga qayta ishlashimiz uchun bir tizimni yaratdik. Bu muammolar juda juda kamid emas. Name", 'vi': 'Bài viết này mô tả một người phân loại cho những tweet có liên quan đến thuốc men hay bổ sung, dựa trên một máy biến thế trước. Chúng tôi đã phát triển một hệ thống như vậy để chúng tôi có thể tham gia vào nhóm bảo trợ dịch y tế phân vân Mô hình cho thấy kết quả hứa hẹn, với một khẩu F1 của 0.8 (nghĩa vụ: 0.62).', 'bg': 'Тази статия описва класификатор за туитове, които споменават лекарства или добавки, базиран на предварително трениран трансформатор. Разработихме такава система за участието си в подзадача 1 на семинара "Социални медии минно дело за здравеопазване", в която имаше изключително небалансиран набор от данни. Моделът показа обещаващи резултати, с Ф1 от 0,8 (средна стойност на задачата: 0,66).', 'da': 'Denne artikel beskriver en klassificering af tweets, der nævner medicin eller kosttilskud, baseret på en forudtrænet transformer. Vi udviklede et sådant system til vores deltagelse i Subtask 1 af Social Media Mining for Health Application workshop, som indeholdt et ekstremt ubalanceret datasæt. Modellen viste lovende resultater med en F1 på 0,8 (opgavens gennemsnit: 0,66).', 'nl': 'Dit artikel beschrijft een classificator voor tweets die medicijnen of supplementen vermelden, gebaseerd op een vooraf getrainde transformator. We ontwikkelden een dergelijk systeem voor onze deelname aan Subtask 1 van de Social Media Mining for Health Application workshop, die een extreem onevenwichtige dataset bevatte. Het model vertoonde veelbelovende resultaten, met een F1 van 0.8 (taakmedrag: 0.66).', 'hr': 'Ovaj papir opisuje klasifikatora za tweets koji spominju lijekove ili dodatke na temelju pretkišnog transformatora. Razvili smo takav sustav za sudjelovanje u podzadatku 1 radionice za rudarstvo socijalnih medija za zdravstvene aplikacije, koja je uključivala izuzetno nepravednost kompleta podataka. Model je pokazao obećavajuće rezultate, s F1 od 0,8 (srednji zadatak: 0,66).', 'de': 'Dieses Papier beschreibt einen Klassifikator für Tweets, die Medikamente oder Ergänzungen erwähnen, basierend auf einem vortrainierten Transformator. Ein solches System haben wir für unsere Teilnahme an Subtask 1 des Workshops Social Media Mining for Health Application entwickelt, der einen extrem unausgewogenen Datensatz aufwies. Das Modell zeigte vielversprechende Ergebnisse mit einem F1 von 0.8 (Aufgabenmittel: 0.66).', 'id': 'Kertas ini menggambarkan klasifikasi untuk tweet yang menyebutkan obat atau suplimen, berdasarkan transformer terlatih. Kami mengembangkan sistem seperti ini untuk berpartisipasi kami di Subtask 1 dari workshop Social Media Mining for Health Application, yang memiliki set data yang sangat tidak seimbang. The model showed promising results, with an F1 of 0.8 (task mean: 0.66).', 'fa': 'این کاغذ یک راهنمایی برای توئیت\u200cها که داروهای یا اضافه\u200cها را یاد می\u200cکند، بر اساس یک تغییرگر پیش\u200cفرض می\u200cکند، توصیف می\u200cکند. ما این سیستم را برای مشارکت در زیر کار ۱ از کارگاه رسانه\u200cهای اجتماعی برای کاربرد سلامتی توسعه دادیم که یک مجموعه داده\u200cهای بسیار نابرابر است. مدل نتایج قول دادن را نشان داد، با یک F1 از 0.8 (معنی کار: 0.66).', 'sw': 'Gazeti hili linaelezea mwandishi wa twiti zinazotaja dawa au vifaa, kwa kutumia mabadiliko yanayoendelea. Tumeunda mfumo wa a in a hiyo wa kushiriki katika kazi 1 ya warsha ya Mitandao ya Kijamii ya Kumbukumbu kwa ajili ya matumizi ya Afya, ambayo ilionyesha seti za taarifa zisizo sahihi. Mfano huo ulionyesha matokeo yanayoahidi, na F1 ya 0.8 (maana ya kazi: 0.66).', 'af': "Hierdie papier beskrywe 'n klassifiseerder vir tweets wat medikasie of supplemente bepaal, gebaseer op 'n voorrein transformeerder. Ons het so 'n stelsel ontwikkel vir ons deelnadering in Subtask 1 van die sosiale Media Mining vir die gesondige toepassingswerk wat 'n ekstrem onbalanse datastel gedoen het. Die model het beloftende resultate vertoon, met 'n F1 van 0. 8 (taak bedoel: 0. 66).", 'tr': 'Bu kagyz döwletler ýa-da ilatyny ýa-da ilatyny diýjek tweets üçin klasifikatyny ýazylýar. Biz sosial Medya Taýramçylygy Saýlaw Uyglamasynyň 1-nji Subtask sistemasynda çykyşymyz üçin şeýle bir sistemasyny bejerdik. Ol sebäbi örän täzeliksiz bir datawaty guruldy. Bu nusga sözlän netijeleri görkezildi, 0.8 tarapyndan bir F1 bilen (gören meýdany: 0.66).', 'sq': 'This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer.  Ne zhvilluam një sistem të tillë për pjesëmarrjen tonë në Subtask 1 të seminarit të Mining Social Media për Aplikacionet Shëndetësore, i cili paraqiti një set të dhënash jashtëzakonisht të paekuilibruar. Modeli tregoi rezultate premtuese, me një F1 prej 0.8 (mesatare e detyrës: 0.66).', 'am': 'ይህ ገጾች በተለየ ውጤት የተለወጠውን ማህረቦች ወይም ጨዋታውን በሚያሳየው ትዊተሮች ላይ የሚታወቀውን ትርጉም ይናገራል፡፡ አዲስ ማኅበራዊ ሚዲያ ለጤና ፕሮግራም ማነሻ ሰርቨርስቲ ማኅበራዊ ሚዲያ ማኅበረሰብ ማኅበረሰብ ማኅበረሰብ ማኅበረሰብ ማኅበረሰብ ማኅበረሰብ እና እንደዚህ ያለ ስርዓት አቀረብን፡፡ ሞዴል የተስፋ ውጤቶች ያሳየዋል፥ ከ0.8 በላይ F1 (ስራ ማሰናከል 0.66).', 'hy': 'Այս հոդվածը նկարագրում է թվիթերի դասակարգիչ, որը նշում է դեղամիջոցներ կամ ավելացումներ, հիմնված նախկինում սովորեցված վերափոխողի վրա: Մենք զարգացրեցինք այսպիսի համակարգ մեր մասնակցության համար առողջապահության ծրագրերի սոցիալական լրատվամիջոցների հանքարարության 1 ենթախնդիրը, որը ներկայացրեց չափազանց անհավասարակշռություն ունեցող տվյալների համակարգ: Մոդելը ցույց տվեց խոստացնող արդյունքներ, F1-ը 0.8 է (գործի միջին՝ 0.66):', 'az': 'Bu kağıt, əvvəlki transformatörə dayanan ilaçlar və ilaçlar danışan tweets üçün klasifikatçısını təsdiqləyir. Biz sosyal Media Mining for Health Application workshop (Subtask 1) ilə bu sistemi müəyyən etdik ki, çox çəkinməmiş veri quruluşu göstərdi. Model vəd verici sonuçlarını göstərdi, F1 0.8 ilə (iş mean: 0.66).', 'bn': 'এই পত্রিকা টুইটের জন্য এক বিশ্লেষণীয় ব্যাখ্যা করছে যেখানে চিকিৎসা বা সামগ্রীর কথা উল্লেখ করা হয়েছে, যেখানে একটি প্র সামাজিক মিডিয়া স্বাস্থ্য অ্যাপ্লিকেশন কর্মশালায় অংশগ্রহণের জন্য সাবটাবাস ১-এ অংশগ্রহণের জন্য আমরা এমন একটি সিস্টেম উন্নয়ন করেছ মডেলটি প্রতিশ্রুতিশীল ফলাফল প্রদর্শন করেছে, যা ০. ৮ এর একটি F1 (কাজের মানে 0. 66)।', 'bs': 'Ovaj papir opisuje klasifikatora za tweets koji spominju lijekove ili dodatke, na osnovu pretkišnog transformatora. Razvili smo takav sistem za sudjelovanje u podzadatku 1 radionice za rudarstvo socijalnih medija za zdravstvenu aplikaciju, koja je uključivala izuzetno nepravednost kompleta podataka. Model je pokazao obećavajuće rezultate, s F1 od 0,8 (srednji zadatak: 0,66).', 'ca': 'Aquest article descriu un classificador de tweets que mencionen medicaments o suplements, basat en un transformador pré-entrenat. Vam desenvolupar un sistema així per a la nostra participació en la Subtasca 1 del taller Social Media Mining for Health Applications, que conté un conjunt de dades extremadament desequilibrats. El model va mostrar resultats prometedors, amb un F1 de 0,8 (mitjana de tasca: 0,66).', 'ko': "본고는 약물이나 보충제를 언급하는 데 사용되는 예훈련 변환기를 기반으로 한 추문 분류기를 묘사한다.우리는'건강한 소셜미디어 발굴 응용 세미나'에 참여하는 하위 임무 1을 개발했는데 이 세미나의 데이터 집합이 매우 불균형적이다.이 모델은 F1이 0.8(작업 평균:0.66)이라는 희망적인 결과를 보여 준다.", 'cs': 'Tento článek popisuje klasifikátor tweetů, které zmiňují léky nebo doplňky, založený na předtrénovaném transformátoru. Takový systém jsme vyvinuli pro naši účast v Subtasku 1 workshopu Social Media Mining for Health Application, který obsahoval extrémně nevyvážený datový soubor. Model vykazoval slibné výsledky s F1 o 0.8 (průměr úkolu: 0.66).', 'et': 'Käesolevas artiklis kirjeldatakse klassifitseerijat säutsudele, mis mainivad ravimeid või toidulisandeid, mis põhinevad eeltreenitud trafol. Töötasime välja sellise süsteemi, et osaleda sotsiaalmeedia kaevandamine tervise rakenduse töötoa 1. alaülesandes, kus oli väga tasakaalustatud andmekogum. Mudel näitas paljulubavaid tulemusi, F1 0,8 (ülesande keskmine: 0,66).', 'fi': 'Tässä artikkelissa kuvataan luokittelija tweeteille, joissa mainitaan lääkkeitä tai lisäravinteita, joka perustuu esikoulutettuun muuntajaan. Kehitimme tällaisen järjestelmän osallistuaksemme Sosiaalisen median kaivostoiminta terveyssovellusten työpajan alatehtävään 1, jossa oli erittäin epätasapainoinen aineisto. Malli osoitti lupaavia tuloksia, F1 0,8 (tehtävän keskiarvo 0,66).', 'sk': 'Ta članek opisuje klasifikator za tweete, ki omenjajo zdravila ali dopolnila, ki temelji na predtreniranem transformatorju. Takšen sistem smo razvili za sodelovanje v podnalogi 1 delavnice Družbenih medijev Rudarjenje za zdravje, ki je predstavljala izjemno neuravnotežen nabor podatkov. Model je pokazal obetavne rezultate s F1 0,8 (povprečje opravila: 0,66).', 'jv': 'Perintah iki dadi panjenengan kelas nang tuytir kesempatan dhéwé uga, supoyo karo perusahaan langgar. Awak dhéwé nggawe sistem kanggo ngilangno ning Subtask 1 ning arep menyang Media Ming kanggo ngilangno Aplikasi kanggo wé-nggilik, sing isin akeh dataset sing ora bisa balan. Display routing', 'ha': 'Wannan takardan na bayyana wani mai fassara wa Twitter wanda ke ambata dawada ko da ƙarami, a kan shige ta misãlan. Mun developed such a system for mu yi shirin zama a cikin Sub-Mission 1 of the Socket Media Mining for Header Application workouts, which feature an extremely balanced data set. @ info: whatsthis', 'bo': 'ཤོག་བྱང་འདིས་བློ་གཏོང་མཁན་གྱི་གྲོང་རིམ་བཟོ་བཅོས་པ་ཞིག་དང་། སྔོན་སྒྲིག་གི་ལག་ལེན་འཐབ་སྟེ། ང་ཚོས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནག་ལ་རང་ཉིད་ཀྱི་ལས་འགན་སྤྲོད་ཀྱི་འཇུག མ་དབྱིབས་འདིས་བདེན་བཤད་ཀྱི་རྐྱེན་འབྲས་བ་མངོན', 'he': 'העיתון הזה מתאר מסווג לטוויטים שמזכירים תרופות או תוספות, מבוססים על משתנה מאומנת מראש. פיתחנו מערכת כזו לשתתפות שלנו בתפקיד 1 של מעבדת המכרות במדיה החברתית לתוכנית בריאות, אשר כיוונה קבוצת נתונים לא מאוזנת ביותר. המודל הראה תוצאות מבטיחות, עם F1 של 0.8 (ממוצע המשימה: 0.66).'}
{'en': 'Autobots Ensemble : Identifying and Extracting Adverse Drug Reaction from Tweets Using Transformer Based Pipelines', 'fr': "Ensemble Autobots\xa0: identifier et extraire les effets indésirables des tweets à l'aide de pipelines basés sur des transformateurs", 'ar': 'فرقة Autobots: تحديد واستخراج التفاعلات الضارة للأدوية من التغريدات باستخدام خطوط الأنابيب القائمة على المحولات', 'es': 'Autobots Ensemble: identificación y extracción de reacciones adversas a medicamentos de tuits mediante canalizaciones basadas en transformadores', 'pt': 'Autobots Ensemble: identificando e extraindo reações adversas a medicamentos de tweets usando pipelines baseados em transformadores', 'zh': 'Autobots Ensemble曰:用Transformer之道,以知药不良反应', 'ja': 'サイバトロンアンサンブル：トランスフォーマーベースのパイプラインを使用したツイートからの有害な薬物反応の特定と抽出', 'hi': 'Autobots Ensemble: ट्रांसफॉर्मर आधारित पाइपलाइनों का उपयोग करके Tweets से प्रतिकूल दवा प्रतिक्रिया की पहचान और निकालना', 'ru': 'Autobots Ensemble: Выявление и извлечение нежелательной лекарственной реакции из твитов с использованием трубопроводов на основе трансформаторов', 'ga': 'Autobots Ensemble: Frithghníomh Díobhálach Drugaí a Aithint agus a Bhaint as Tweetanna ag Úsáid Píblínte Bunaithe ar Chlaochladán', 'ka': 'Name', 'el': 'Σύνολο Εντοπισμός και εξαγωγή ανεπιθύμητης αντίδρασης φαρμάκων από τη χρήση αγωγών βασισμένων στον μετασχηματιστή', 'hu': 'Autobots Ensemble: A mellékhatások felismerése és kivonása Tweetekből transzformátor alapú csővezetékek segítségével', 'it': 'Autobots Ensemble: Identificazione ed estrazione di reazioni avverse alla droga dai tweet utilizzando condutture basate su trasformatori', 'kk': 'Автобоботтарды қолдану: Түрлендіруші негізгі пиплейлерді қолдану және тарқату', 'mk': 'Автоботи Ensemble: Идентификување и извлекување на негативна реакција на дрогата од твитови со користење трансформирани цевки', 'lt': 'Autobotų suvienodinimas: nepageidaujamų narkotikų reakcijų nustatymas ir ekstrahavimas iš Tweetų, kuriuose naudojami transformatoriais pagrįsti vamzdynai', 'ms': 'Autobot Ensemble: Mengenalpasti dan mengekstrak Reaksi Sakit dadah dari Tweets menggunakan Pipeline Berasas Transformer', 'ml': 'ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനമായ പൈപ്പെലിനുകള്\u200d ഉപയോഗിക്കുന്ന ടൂട്ടുകളില്\u200d നിന്നും വികസിക്കുന്ന മരുന്നിന്റെ പ്രത', 'mt': 'Autobots Ensemble: Identifikazzjoni u Estrazzjoni tar-Reazzjoni Avversi tal-Mediċina minn Tweets bl-Użu ta’ Pipelines Bażati fuq Trasformatori', 'mn': 'Автоботуудын шинжлэх ухаан: Туйтуудын эсрэг эм урвал тайлбарлах, татах', 'no': 'Comment', 'pl': 'Zespół Autobots: Identyfikowanie i wyodrębnianie niepożądanych reakcji lekowych z tweetów za pomocą rurociągów opartych na transformatorach', 'ro': 'Ansamblul Autobots: Identificarea si extragerea reactiilor adverse la medicamente din tweets folosind conducte bazate pe transformator', 'sr': 'Autobot Ensemble: Identifikacija i izvlačenje nuspojavne reakcije droge iz Tweets Koristenjem transformatorskih prašina', 'si': 'Name', 'so': 'Autobots', 'sv': 'Autobots Ensemble: Identifiera och extrahera biverkningar från tweets med hjälp av transformatorbaserade rörledningar', 'ta': 'தானியங்கி பெட்டிகள் ஒதுக்கப்படும்: மாற்று அடிப்படையான பைப்லைன்களை பயன்படுத்தி முன்னோட்டு மருந்து விளைவை அடையாளம் மற', 'ur': 'Name', 'uz': 'Avto- qoĘ»yish', 'vi': 'Autobots Ensemble: xác định và chiết xuất phản ứng phản ứng phản ứng phản ứng trái nguyên từ Tweet Dùng ống dẫn biến hình', 'bg': 'Ансамбъл: Идентифициране и извличане на нежелана лекарствена реакция от туитове с помощта на трансформаторни тръбопроводи', 'da': 'Autobots Ensemble: Identificering og udvinding af bivirkninger fra tweets ved hjælp af transformatorbaserede rørledninger', 'hr': 'Autobot Ensemble: Identifikacija i izvlačenje nuspojavnih reakcija droge iz Tweets Korištenja transformatorskih svinja', 'nl': 'Autobots Ensemble: Identificeren en Extraheren van ongewenste drugsreacties uit Tweets met behulp van Transformer Based Pipelines', 'de': 'Autobots Ensemble: Identifizieren und Extrahieren unerwünschter Arzneimittelreaktionen aus Tweets mithilfe von Transformer-basierten Pipelines', 'ko': '자동차인 합주: 변압기 기반 파이프를 사용하여 트위터에서 불량 약물 반응을 식별하고 추출', 'fa': 'Name', 'tr': 'Otomatik Gaýşartma', 'af': 'Comment', 'id': 'Autobot Ensemble: Identifikasi dan Ekstraksi Reaksi Alih obat dari Tweet Menggunakan Pipeline Berdasarkan Transformer', 'sw': 'Autobots Ensemble: Identifying and Extracting Adverse Drug Reaction from Tweets Using Transformer Based Pipelines', 'hy': 'Comment', 'am': 'Autobots Enable: Identification and Extract Advanced Drug Reaction from Tweets using Transformer Based Pipelines', 'sq': 'Autobots Ensemble: Identifikimi dhe nxjerrimi i reagimit të keq të drogës nga Tweets duke përdorur tuba të bazuar në transformues', 'az': 'Avtomatik botlar Ensemble: Tövidlərin Üstündəki Tövidlərin Ölçü Uyuqları İşləndirməsi və Çıkarması', 'bn': 'স্বয়ংক্রিয়বোট: টুইটার থেকে টুইটারে ট্রান্সফেক্রান্সভার ভিত্তিক পাইপেলাইন ব্যবহার করে প্রাপ্ত মাদক পরিচয় এবং প্রা', 'bs': 'Autobot Ensemble: Identifikacija i izvlačenje nuspojavne reakcije droge iz Tweets Koristeći transformator bazirane svinje', 'cs': 'Autobots Ensemble: Identifikace a extrakce nežádoucí lékové reakce z tweetů pomocí transformátorových potrubí', 'et': 'Autobots Ensemble: kõrvaltoimete tuvastamine ja ekstraheerimine tweetidest transformaatoripõhiste torustike abil', 'fi': 'Autobots Ensemble: Haittavaikutusten tunnistaminen ja erottaminen tweeteistä muuntajapohjaisten putkien avulla', 'ca': 'Autobots Ensemble: Identificar i extrair la reacció adversa dels medicaments de Tweets amb tubs basats en transformadors', 'he': 'Autobots Ensemble: זיהוי ומוציא תגובת תרופות לא רצינית מטוויטים', 'ha': 'Autobots Ensemble: Identifying and Extracting Adverse Drug Reaction from Tweets Using Transformer Based Pipelines', 'sk': 'Autobots Ensemble: prepoznavanje in odstranjevanje neželenih učinkov zdravil iz tweetov z uporabo cevovodov na osnovi transformatorjev', 'bo': 'རང་འགུལ་གྱིས་འཛུགས་སྤྱོད་དགོས། འདྲ་བ་ཚོའི་ངོ་འཛིན་དང་ཕྱིར་འདྲེན་པ', 'jv': 'Name'}
{'en': 'This paper details a  system  designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020. We specifically describe the systems designed to solve task 2 : Automatic classification of multilingual tweets that report adverse effects, and task 3 : Automatic extraction and normalization of adverse effects in English tweets. Fine tuning RoBERTa large for classifying English tweets enables us to achieve a F1 score of 56 %, which is an increase of +10 % compared to the average F1 score for all the submissions. Using BERT based NER and question answering, we are able to achieve a F1 score of 57.6 % for extracting adverse reaction mentions from tweets, which is an increase of +1.2 % compared to the average F1 score for all the submissions.', 'ar': 'توضح هذه الورقة بالتفصيل نظامًا مصممًا لتعدين الوسائط الاجتماعية للتطبيقات الصحية (SMM4H) المهمة المشتركة 2020. نحن نصف على وجه التحديد الأنظمة المصممة لحل المهمة 2: التصنيف التلقائي للتغريدات متعددة اللغات التي تبلغ عن التأثيرات الضارة ، والمهمة 3: الاستخراج التلقائي والتطبيع الآثار السلبية في التغريدات الإنجليزية. تمكّننا الضبط الدقيق لـ RoBERT من تصنيف التغريدات باللغة الإنجليزية من تحقيق درجة F1 بنسبة 56٪ ، وهي زيادة بنسبة + 10٪ مقارنة بمتوسط درجة F1 لجميع عمليات الإرسال. باستخدام NER المستند إلى BERT والإجابة على الأسئلة ، يمكننا تحقيق درجة F1 بنسبة 57.6٪ لاستخراج ردود الفعل السلبية من التغريدات ، وهي زيادة بنسبة + 1.2٪ مقارنة بمتوسط درجة F1 لجميع عمليات الإرسال.', 'es': 'Este documento detalla un sistema diseñado para la tarea compartida de minería de redes sociales para aplicaciones de salud (SMM4H) 2020. Describimos específicamente los sistemas diseñados para resolver la tarea 2: clasificación automática de tuits multilingües que informan efectos adversos, y la tarea 3: extracción automática y normalización de los efectos adversos en los tuits en inglés. El ajuste fino de RobertA large para clasificar los tweets en inglés nos permite lograr una puntuación de F1 del 56%, lo que supone un aumento del +10% en comparación con la puntuación media de F1 para todos los envíos. Con NER basada en BERT y respuestas a preguntas, podemos lograr una puntuación F1 del 57,6% para extraer menciones de reacciones adversas de los tuits, lo que supone un aumento del +1,2% en comparación con la puntuación media de F1 para todos los envíos.', 'fr': "Cet article détaille un système conçu pour la tâche partagée 2020 de Social Media Mining for Health Applications (SMM4H). Nous décrivons spécifiquement les systèmes conçus pour résoudre la tâche 2\xa0: classification automatique des tweets multilingues qui signalent des effets indésirables, et la tâche 3\xa0: extraction automatique et normalisation des effets indésirables dans les tweets en anglais. Le réglage fin de Roberta large pour la classification des tweets en anglais nous permet d'atteindre un score F1 de 56\xa0%, soit une augmentation de +10\xa0% par rapport au score moyen de F1 pour toutes les soumissions. En utilisant le NER basé sur BERT et la réponse aux questions, nous sommes en mesure d'obtenir un score F1 de 57,6\xa0% pour l'extraction des mentions d'effets indésirables des tweets, ce qui représente une augmentation de +1,2\xa0% par rapport au score F1 moyen pour toutes les soumissions.", 'pt': 'Este artigo detalha um sistema projetado para a tarefa compartilhada de mineração de mídia social para aplicativos de saúde (SMM4H) 2020. Descrevemos especificamente os sistemas projetados para resolver a tarefa 2: classificação automática de tweets multilíngues que relatam efeitos adversos e tarefa 3: extração automática e normalização de efeitos adversos em tweets em inglês. O ajuste fino do RoBERTa grande para classificar os tweets em inglês nos permite atingir uma pontuação F1 de 56%, o que representa um aumento de +10% em comparação com a pontuação média da F1 para todos os envios. Usando NER baseado em BERT e respostas a perguntas, conseguimos uma pontuação F1 de 57,6% para extrair menções de reações adversas de tweets, o que representa um aumento de +1,2% em comparação com a pontuação F1 média para todos os envios.', 'ja': '本稿では、ソーシャルメディアマイニングfor Health Applications (SMM 4 H) Shared Task 2020用に設計されたシステムについて詳述する。タスク2 ：悪影響を報告する多言語ツイートの自動分類、およびタスク3 ：英語ツイートの悪影響の自動抽出と正規化を解決するために設計されたシステムについて具体的に説明します。ファインチューニングRoBERTa英語のツイートを分類するための大規模な機能により、F 1スコア56%を達成することができます。これは、すべての提出物の平均F 1スコアと比較して+10%増加しています。BERTベースのNERと質問応答を使用して、ツイートから有害反応の言及を抽出した場合、57.6%のF 1スコアを達成することができます。これは、すべての提出物の平均F 1スコアと比較して+1.2%の増加です。', 'zh': '本文具言健康宜社交媒体发掘(SMM4H)共享2020计之系统。 专言旨在决事2之统:自类告不良反应多言推文,及务3:自取规范化英语推不良反应。 微调RoBERTa以类英语推文,使得56%之F1分,比诸提交之均F1,增+10%也。 用BERTNER问答,得推文不良反应提及,得57.6%F1分数,比诸提交均F1分数,增+1.2%。', 'ru': 'В этой статье подробно описывается система, разработанная для совместной задачи «Майнинг социальных сетей для приложений здравоохранения» (SMM4H) 2020. Мы конкретно описываем системы, предназначенные для решения задачи 2: Автоматическая классификация многоязычных твитов, сообщающих о побочных эффектах, и задачи 3: Автоматическое извлечение и нормализация побочных эффектов в английских твитах. Тонкая настройка RoBERTa large для классификации английских твитов позволяет нам получить оценку F1 56%, что на +10% выше среднего показателя F1 по всем заявкам. Используя NER на основе BERT и ответы на вопросы, мы можем получить оценку F1 57,6% для извлечения упоминаний о нежелательных реакциях из твитов, что представляет собой увеличение на +1,2% по сравнению со средним баллом F1 для всех представлений.', 'hi': 'यह पेपर स्वास्थ्य अनुप्रयोगों (SMM4H) साझा कार्य 2020 के लिए सोशल मीडिया माइनिंग के लिए डिज़ाइन की गई एक प्रणाली का विवरण देता है। हम विशेष रूप से कार्य 2 को हल करने के लिए डिज़ाइन किए गए सिस्टम का वर्णन करते हैं: बहुभाषी ट्वीट्स का स्वचालित वर्गीकरण जो प्रतिकूल प्रभावों की रिपोर्ट करता है, और कार्य 3: अंग्रेजी ट्वीट्स में प्रतिकूल प्रभावों का स्वचालित निष्कर्षण और सामान्यीकरण। अंग्रेजी ट्वीट्स को वर्गीकृत करने के लिए ठीक ट्यूनिंग RoBERTa बड़े हमें 56% के F1 स्कोर को प्राप्त करने में सक्षम बनाता है, जो सभी प्रस्तुतियों के लिए औसत F1 स्कोर की तुलना में +10% की वृद्धि है। BERT आधारित NER और प्रश्न का उत्तर देने का उपयोग करते हुए, हम tweets से प्रतिकूल प्रतिक्रिया का उल्लेख निकालने के लिए 57.6% का F1 स्कोर प्राप्त करने में सक्षम हैं, जो सभी प्रस्तुतियों के लिए औसत F1 स्कोर की तुलना में +1.2% की वृद्धि है।', 'ga': 'Sonraíonn an páipéar seo córas atá deartha le haghaidh Tasc Comhroinnte Mianadóireacht Meáin Shóisialta le haghaidh Feidhmchláir Sláinte (SMM4H) 2020. Déanaimid cur síos go sonrach ar na córais atá deartha chun tasc 2 a réiteach: Aicmiú uathoibríoch tweets ilteangach a thuairiscíonn éifeachtaí díobhálacha, agus tasc 3: Eastóscadh agus normalú uathoibríoch éifeachtaí díobhálacha i tweets Béarla. Cuireann mionchoigeartú RoBERTa mór le haghaidh tweets Béarla a rangú ar ár gcumas scór F1 de 56% a bhaint amach, sin méadú de +10% i gcomparáid leis an meánscór F1 do na haighneachtaí go léir. Trí úsáid a bhaint as NER bunaithe ar BERT agus freagra ceisteanna, táimid in ann scór F1 de 57.6% a bhaint amach chun tagairtí frithghníomhartha díobhálacha a bhaint as tweets, ar méadú é +1.2% i gcomparáid leis an meánscór F1 do na haighneachtaí go léir.', 'ka': 'ამ დომენტის განსაზღვრებით სოციალური მედია მიღებაზე (SMM4H) სხვადასხვა რაოდენობა 2020. ჩვენ განსაკუთრებულად აღწერეთ სისტემები, რომელიც დავაკეთებულიან დავაკეთებელი დავალებისთვის 2: მრავალენგური tweets-ის ავტომატურად კლასიფიკაცია, რომელიც განსაკუთრებული ეფექტები, და 3 პრობერტის დიდი კლასიფიკაციაში კლასიფიკაციის შესაძლებელია, რომ ჩვენ 56%-ის F1 წერტილის შესაძლებელია, რომელიც +10% წერტილის შესაძლებელია, რომელიც ყველა წერტილების განმავლობაში F1 წერტილის შესაძლებელია BERT დაბათებული NER და კითხვის პასუხის გამოყენება, ჩვენ შეგვიძლია გავაკეთოთ F1 წერტილის 57,6% წერტილის გამოყენებას, რომელიც შეგვიძლია გავაკეთოთ გარექტირებული რექიციის მისამართების გამოყენება, რომელიც +1,2% წერტილი', 'hu': 'Ez a tanulmány részletezi a Social Media Mining for Health Applications (SMM4H) Shared Task 2020 számára kialakított rendszert. Kifejezetten ismertetjük a 2. feladat megoldására tervezett rendszereket: a káros hatásokat jelentő többnyelvű tweetek automatikus osztályozása, valamint a 3. feladat: a káros hatások automatikus kivonása és normalizálása angol tweetekben. Az angol tweetek osztályozásához szükséges RoBERTa nagy finomhangolással 56%-os F1 pontszámot érünk el, ami +10%-os növekedést jelent az összes beadvány átlagos F1 pontszámához képest. BERT alapú NER és kérdésválasz segítségével 57,6%-os F1 pontszámot tudunk elérni a mellékhatások említéseinek kivonásával tweetekből, ami +1,2%-os növekedést jelent az összes beadott F1 pontszámhoz képest.', 'el': 'Αυτή η εργασία περιγράφει ένα σύστημα σχεδιασμένο για την εξόρυξη κοινωνικών μέσων για εφαρμογές υγείας (Κοινή εργασία 2020. Περιγράφουμε συγκεκριμένα τα συστήματα που έχουν σχεδιαστεί για την επίλυση του έργου 2: Αυτόματη ταξινόμηση πολυγλωσσικών tweets που αναφέρουν δυσμενείς επιπτώσεις, και εργασία 3: Αυτόματη εξαγωγή και ομαλοποίηση των δυσμενών επιπτώσεων στα αγγλικά tweets. Ο λεπτός συντονισμός του RoBERTa large για την ταξινόμηση των Αγγλικών tweets μας επιτρέπει να επιτύχουμε μια βαθμολογία F1 56%, η οποία είναι μια αύξηση +10% σε σύγκριση με τη μέση βαθμολογία F1 για όλες τις υποβολές. Χρησιμοποιώντας τη βάση του και την απάντηση σε ερωτήσεις, είμαστε σε θέση να επιτύχουμε μια βαθμολογία F1 57,6% για την εξαγωγή αναφορών ανεπιθύμητων ενεργειών από τα tweets, η οποία είναι μια αύξηση +1,2% σε σύγκριση με τη μέση βαθμολογία F1 για όλες τις υποβολές.', 'it': 'Questo articolo descrive in dettaglio un sistema progettato per Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Descriviamo in modo specifico i sistemi progettati per risolvere il task 2: Classificazione automatica dei tweet multilingue che segnalano effetti avversi, e task 3: Estrazione automatica e normalizzazione degli effetti avversi nei tweet inglesi. La messa a punto RoBERTa large per la classificazione dei tweet inglesi ci permette di ottenere un punteggio F1 del 56%, che è un aumento del +10% rispetto al punteggio medio F1 per tutte le candidature. Utilizzando NER basato su BERT e risposta alle domande, siamo in grado di ottenere un punteggio F1 del 57,6% per estrarre le menzioni di reazioni avverse dai tweet, che è un aumento del +1,2% rispetto al punteggio medio F1 per tutte le domande presentate.', 'kk': 'Бұл қағаз 2020 жылы ортақ тапсырма үшін социалдық медиа бағалау қолданбалары (SMM4H) үшін құрылған жүйенің егжей- тегжейі. Біз 2- тапсырманы шешу үшін құрылған жүйелерді түсіндіреміз: қарсы эффекттерді есептеп беретін көптеген тілдер тілдерінің автоматты түрлендіру және 3- тапсырмасы: Ағылшын tweets тілдерінде қарсы Ағылшынша tweets классификациясының үлкен RoBERTa баптауы 56% деген F1 нөмірін жеткізуге мүмкіндік береді, бұл барлық жіберушілердің орташа F1 нөміріне салыстырылған +10% деген өзгертілген. BERT негіздеген NER және сұрақ жауап беруді қолдануға болады. Біз белсенді қарсы реакцияларды таңдау үшін 57,6% F1 нәтижесін жеткізе аламыз. Бұл +1,2% нәтижесін бағыттау үшін барлық жіберушілердің орташа F1 нәтижесіне', 'mk': 'Овој весник детализира систем дизајниран за Социјалните медиуми минирање за здравствени апликации (SMM4H) заедничка задача 2020. Специфично ги опишуваме системите дизајнирани за решавање на задачата 2: Автоматска класификација на мултијазични твитови кои известуваат негативни ефекти, и задача 3: Автоматска екстракција и нормализација на негативни ефекти на англиски твит Фино прилагодување на RoBERTa големо за класификација на англиски твитови ни овозможува да постигнеме резултат F1 од 56 отсто, што е зголемување од +10 отсто во споредба со просечниот резултат F1 за сите поднесувања. Користејќи БЕРТ заснован НЕР и одговори на прашања, можеме да постигнеме оценка Ф1 од 57,6 отсто за извлекување на негативни реакции спомени од твитови, што претставува зголемување од +1,2 отсто во споредба со просечната оценка Ф1 за сите поднесувања.', 'lt': 'Šiame dokumente išsamiai aprašyta sistema, skirta socialinės žiniasklaidos kasybai sveikatos priežiūros programoms (SMM4H) įgyvendinti bendrą užduotį „2020“. We specifically describe the systems designed to solve task 2: Automatic classification of multilingual tweets that report adverse effects, and task 3: Automatic extraction and normalization of adverse effects in English tweets.  Puikus koregavimas RoBERTa didelis anglų tweetams klasifikuoti leidžia mums pasiekti F1 tašką 56 %, t. y. padidinti +10 %, palyginti su vidutiniu F1 tašku visiems pareiškimams. Naudodami BERT pagrįstą NER ir atsakymus į klausimus, galime pasiekti F1 rezultatą 57,6 proc. ištraukiant nepageidaujamų reakcijų paminėjimus iš tweetų, t. y. padidinti +1,2 proc., palyginti su vidutiniu F1 rezultatu visoms paraiškoms.', 'ms': 'Kertas ini menjelaskan sistem yang direka untuk Perlombongan Media Sosial untuk Aplikasi Kesehatan (SMM4H) Tugas Berkongsi 2020. Kami secara khusus menggambarkan sistem yang direka untuk menyelesaikan tugas 2: Klasifikasi automatik tweet berbilang bahasa yang melaporkan kesan negatif, dan tugas 3: ekstraksi automatik dan normalisasi kesan negatif dalam tweet Inggeris. Penyesuaian baik RoBERTa besar untuk mengklasifikasi tweet Inggeris membolehkan kita mencapai skor F1 56%, yang merupakan peningkatan +10% dibandingkan dengan skor F1 rata-rata untuk semua penghantaran. Dengan menggunakan NER berasaskan BERT dan menjawab soalan, kita mampu mencapai skor F1 57.6% untuk mengekstrak sebutan reaksi negatif dari tweet, yang merupakan peningkatan +1.2% dibandingkan dengan skor F1 rata-rata untuk semua penghantaran.', 'ml': 'സോഷ്യല്\u200d മീഡിയ മിനിങ്ങിനുള്ള സാമൂഹ്യ പ്രയോഗങ്ങള്\u200dക്കുള്ള സിസ്റ്റം വിശദീകരിച്ചുകൊടുക്കുന്ന പേപ്പറിന്\u200dറെ വ ജോലി തീരുമാനിക്കാനുള്ള സിസ്റ്റീമുകള്\u200d നമ്മള്\u200d പ്രത്യേകിച്ച് വിവരിച്ചുകൊടുക്കുന്നു: ഇംഗ്ലീഷ് ടൂട്ടുകളില്\u200d വിരോധമുള്ള പ്രഭാവങ്ങള്\u200d  ഇംഗ്ലീഷ് ടൂട്ടുകള്\u200d വിശദീകരിക്കുന്നതിനായി റോബെര്\u200dട്ടാ വലുതായി കേള്\u200dപ്പിക്കുന്നത് നമുക്ക് 56% എഫ്\u200c1 സ്കോര്\u200d എത്തിക്കാന്\u200d സാധിക്കും. എല്ലാ ക ബെര്\u200dട്ടിന്റെ അടിസ്ഥാനത്തുള്ള NER ഉപയോഗിച്ച് ചോദ്യം ഉത്തരം നല്\u200dകുന്നതിനാല്\u200d നമുക്ക് 57. 6% എഫ്1 സ്കോര്\u200d നേടാന്\u200d കഴിയും, വിഭ്രമത്തിന്റെ പ്രഖ്യാപങ്ങള്\u200d ടൂട്ടില്\u200d നി', 'mt': 'Din id-dokument tiddeskrivi sistema mfassla għall-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (SMM4H) Kompitu Konġunt 2020. Aħna niddeskrivu speċifikament is-sistemi mfassla biex isolvu l-kompitu 2: Klassifikazzjoni awtomatika ta’ tweets multilingwi li jirrappurtaw effetti negattivi, u kompitu 3: Estrazzjoni awtomatika u normalizzazzjoni ta’ effetti negattivi fit-tweets Ingliżi. L-a ġġustament fin ta’ RoBERTa kbir għall-klassifikazzjoni ta’ tweets Ingliżi jippermettilna niksbu punteġġ F1 ta’ 56%, li huwa żieda ta’ +10% meta mqabbel mal-punteġġ medju ta’ F1 għas-sottomissjonijiet kollha. Bl-użu ta’ NER ibbażat fuq BERT u t-tweġiba għall-mistoqsijiet, nistgħu niksbu punteġġ F1 ta’ 57.6% għall-estrazzjoni ta’ sejħiet ta’ reazzjonijiet avversi minn tweets, li huwa żieda ta’ +1.2% meta mqabbel mal-punteġġ F1 medju għas-sottomissjonijiet kollha.', 'mn': 'Энэ цаас нийгмийн Media Mining for Health Applications (SMM4H) хуваалцааны ажил 2020 онд зориулагдсан системийг дэвшүүлдэг. Бид 2 даалгаварыг шийдэхийн тулд зориулсан системийг тодорхой тайлбарлаж байна: Ямар ч эсрэг нөлөө өгдөг олон хэлний tweets, 3 даалгавар: Англи tweets дээр эсрэг нөлөө автоматаар гаргаж, нормализах. Англи хэлний tweets хичээлд том RoBERTa-г сайн тодорхойлох нь бидэнд F1 оноо 56%-той гаргаж чадна. Энэ нь F1-ийн дундаж дундаж тооны нэмэлт нь +10%-ын нэмэлт юм. БЕРТ-ын НЕР болон асуулт хариултыг ашиглан, бид туйтаас эсрэг урвал гаргахад 57.6% F1 оноо гаргаж чадна. Энэ нь +1.2% дундаж F1 оноо гаргаж чадна.', 'no': 'Dette papiret detaljerer eit systemet designert for sosial media mining for helseprogrammer (SMM4H) delt oppgåve 2020. Vi beskriver systema som er lagt til å løysa oppgåve 2: Automatisk klassifisering av fleirspråk tweet som rapporterer negativ effektar, og oppgåve 3: Automatisk utpakking og normalisering av negativ effektar i engelske tweet. Det finst oppsettet av RoBERTa for å klassifisera engelske tweeter kan gjera oss å oppnå eit F1- poeng med 56%, som er økt på +10% samanlikna med gjennomsnittlig F1- poeng for alle oppføringane. Bruk BERT-basert NER og spørsmål-svar, kan vi oppnå eit F1-poeng med 57,6% for å pakka ut negativreaksjonsmenningar frå tweets, som er økt av +1,2% samanlikna med gjennomsnittsfargen F1-poeng for alle søknadene.', 'pl': 'Niniejszy artykuł opisuje system przeznaczony do wydobywania mediów społecznościowych dla aplikacji zdrowotnych (SMM4H) Shared Task 2020. Szczegółowo opisujemy systemy przeznaczone do rozwiązywania zadania 2: Automatyczna klasyfikacja wielojęzycznych tweetów zgłaszających skutki niepożądane oraz zadanie 3: Automatyczna ekstrakcja i normalizacja niepożądanych skutków w angielskich tweetach. Dobrze dostrojenie RoBERTa duża do klasyfikacji angielskich tweetów pozwala nam osiągnąć wynik F1 56%, co jest wzrostem +10% w porównaniu do średniego wyniku F1 dla wszystkich zgłoszeń. Wykorzystując NER oparty na BERT i odpowiadanie na pytania, jesteśmy w stanie osiągnąć wynik F1 57,6% za wydobycie wzmianek o działaniach niepożądanych z tweetów, co jest wzrostem +1,2% w porównaniu ze średnim wynikiem F1 dla wszystkich zgłoszeń.', 'ro': 'Această lucrare detaliază un sistem conceput pentru Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Descriem în mod specific sistemele concepute pentru a rezolva sarcina 2: Clasificarea automată a tweeturilor multilingve care raportează efecte adverse, și sarcina 3: Extragerea automată și normalizarea efectelor adverse în tweeturile în limba engleză. Reglarea fină RoBERTa large pentru clasificarea tweeturilor în limba engleză ne permite să obținem un scor F1 de 56%, ceea ce reprezintă o creștere de +10% comparativ cu scorul mediu F1 pentru toate depunerile. Folosind NER bazat pe BERT și răspunsul la întrebări, putem obține un scor F1 de 57,6% pentru extragerea mențiunilor de reacții adverse din tweet, ceea ce reprezintă o creștere de +1,2% comparativ cu scorul F1 mediu pentru toate depunerile.', 'sr': 'Ovaj papir detalje sistema koji je dizajniran za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) zajednički zadatak 2020. Posebno opisujemo sisteme dizajnirane za rešenje zadataka 2: automatska klasifikacija multijezičkih tweeta koji prijavljuju nevoljne efekte, i zadatak 3: automatska ekstrakcija i normalizacija nevoljnih efekta na engleskim tweetima. Dobra tuning RoBERTa velika za klasifikaciju engleskih tweeta omogućava nam da postignemo rezultat F1 od 56%, što je povećanje od +10% u usporedbi sa prosječnim rezultatima F1 za sve podatke. Koristeći BERT-based NER i odgovor na pitanja, možemo postići F1 rezultat od 57,6% za izvlačenje spomena nuspojave iz tweeta, što je povećanje od +1,2% u usporedbi s prosječnim rezultatom F1 za sve podatke.', 'so': "Kanu warqaddan wuxuu ku qoran yahay nidaam loo qoray daryeelka caafimaadka ee daryeelka caafimaadka (SMM4H) Shaqada 2020. Si gaar ah ayaannu u qornaa nidaamka loo qoray in lagu xalliyo shaqada 2: Automatic-classification of tweets oo luuqadaha kala duduwan oo ay wargeliyaan saamayaasha, iyo shaqo 3: Automatic extraction and normalization of adverse effects in ay ku dhacdo afka Ingiriis. RuBERta si fiican looga baro Twitteetka Ingiriiska waxaa inagu caawinaya inaynu gaadhno kooras F1 oo ah 56%, taasoo korodhsan +10% oo isbarbarbardhigga qiimaha F1 oo dhan. Isku isticmaalaya NER-based BERT iyo jawaabta su'aalaha, waxaynu heli karnaa koox F1 oo 57.6% si a an uga soo bixino macluumaad ka gees ah Twitteetka, taasoo ah korodha +1.2% oo la barbaranayo qiimaha ugu dhexeeya iskuulka F1 oo dhan.", 'sv': 'Denna uppsats beskriver ett system utformat för Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Vi beskriver specifikt de system som utformats för att lösa uppgift 2: Automatisk klassificering av flerspråkiga tweets som rapporterar negativa effekter, och uppgift 3: Automatisk extraktion och normalisering av negativa effekter i engelska tweets. Finjusterande RoBERTa stor för klassificering av engelska tweets gör att vi kan uppnå en F1-poäng på 56%, vilket är en ökning med +10% jämfört med den genomsnittliga F1-poängen för alla inlämningar. Med BERT-baserad NER och frågesvar kan vi uppnå en F1-poäng på 57,6% för att extrahera biverkningar omnämnanden från tweets, vilket är en ökning med +1,2% jämfört med den genomsnittliga F1-poängen för alla inlämningar.', 'si': 'මේ පැත්තේ සාමාජික මිඩියාව මනින් විදියට සාමාජික වැඩසටහන් වැඩසටහන් විස්තර කරලා තියෙන්නේ (SMM අපි විශේෂයෙන් විශේෂයෙන් විශ්වාස කරපු පද්ධතියක් විස්තර කරනවා වැඩ කරන්න 2: ස්වයංක්\u200dරියාවක් විස්තර කරපු විස්තර විස්තර කරප අංග්\u200dරීසි ට්විට් විශේෂණය සඳහා හොඳ සංවිධානය RoBERTa ලොකු සංවිධානය සඳහා අපිට F1 ප්\u200dරමාණයක් 56% තියෙන්න පුළුවන් වෙනවා, ඒක +10% වි BERT ආධාරිත NER සහ ප්\u200dරශ්න ප්\u200dරතිච්චාරයක් පාවිච්චි කරනවා, අපිට පුළුවන් විරෝධ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචා', 'ur': 'This paper details a system designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020. ہم مخصوص طور پر کام 2 کو حل کرنے کے لئے طراحی کی سیستموں کو توصیف دیتے ہیں: ملتی زبان ٹیوٹوں کی آٹوٹی کلاسپیٹ جو مخالف اثرات گزاری کرتے ہیں، اور کام 3: انگلیسی ٹویٹوں کو کلاسیف کرنے کے لئے بہترین ترونگ روBERTa کو 56% کی F1 سکوٹ پہنچ سکتا ہے، جو +10% کے متوسط F1 سکوٹ کے مقابلہ میں اضافہ ہوتا ہے۔ BERT بنیادی NER اور سوال جواب کے مطابق استعمال کر رہے ہیں، ہم 57.6% کی F1 اسکور پہنچ سکتے ہیں، جو ٹویٹ سے مخالف reaksyon کے ذریعے نکالنے کے لئے، جو +1.2% کی افزایش ہے، جو تمام مطابق کے لئے متوسط F1 اسکور کے مطابق ہے.', 'ta': 'சாலிக ஊடகங்களுக்கான சார்ந்த பயன்பாடுகளுக்கான நினைவூட்டும் அமைப்பை இந்த த தாள் விவரங்களை கூறுகிறது (SMM4H) பங்கி நாம் செயலை தீர்வு செய்ய வடிவமைக்கப்பட்ட அமைப்புகளை குறிப்பிடுகிறோம்: ஆங்கிலத்தில் எதிர்மறை விளைவுகளை அறிக்கும் தன்னியக்கமாக வகைப்படுத்தல் மற்ற வகைப்படுத்துவதற்கு ரோபெர்டா பெரிய வகைப்படுத்தல் ஆங்கிலத்திற்கு ஆங்கிலத்தை வகைப்படுத்துவதற்கு நமக்கு F1 புள்ளி BERT அடிப்படையில் உள்ள NER மற்றும் கேள்வி விடையை பயன்படுத்தி, நாம் ஒரு F1 புள்ளி 57.6% பெற முடியும். தேர்வுகளில் இருந்து வெளியேற்றும் விளைவு குறிப்புகளை பெருக்க', 'uz': "Name 2. Ishni sollash uchun yaratilgan tizimlarni taʼrif qilamiz: Angliyalar tweetidagi shaxsiy effektlar haqida xabar beruvchi bir necha tildagi tweetilarning автоматик тарзда nasifiyalash va vazifa 3: Angliyalar Twitterda shaxsiy effektlarni avtomatik chiqarish va oddiylashtirish. Eng ingliz Twittlarni fashqarish uchun RoBERTAning katta yozilishi mumkin, bizni 56% foizga erishish imkoniyatini imkoniyatlarning asosiy F1 qiymatiga oshirish imkoniyatini beradi. BERT asosida NER va savol javobi bilan ishlatish mumkin, biz Twittlardan tashkilotni ajratish uchun 57.6% F1 scorini bajarishimiz mumkin. Bu hamma muammolar uchun F1 scori ko'payishi mumkin.", 'vi': "Tờ giấy này chi tiết một hệ thống được thiết kế cho công ty nhận sức khỏe xã hội (SMM4H) sẻ chia Nhiệm vụ 2020. Chúng tôi mô tả cụ thể các hệ thống được thiết kế để giải quyết nhiệm vụ 2: Bản phân loại các tweet đa dạng báo cáo tác động xấu, và nhiệm vụ 3: Việc khai thác và tổng hợp các hiệu ứng tiêu cực trên Twitter của người Anh. Một độ tinh chỉnh RoBERTa lớn cho việc liệt kê các dòng tweet tiếng Anh cho phép chúng ta đạt được điểm F1 của 56 cao. So với điểm F1 trung bình trong tất cả các tài liệu. Bằng cách sử dụng góc giao thông và câu hỏi trả lời, chúng tôi có thể đạt được một điểm F1 trong số 57.6='để thoát ra các phản ứng phụ được nhắc đến từ tweet, đó là một tăng số lượng +1.2=' so với điểm F1 trung bình trong tất cả các tài liệu.", 'bg': 'Настоящата статия подробно описва система, предназначена за съвместна задача 2020 в социалните медии за здравни приложения. Специално описваме системите, предназначени за решаване на задача 2: Автоматична класификация на многоезични туитове, които съобщават за неблагоприятни ефекти, и задача 3: Автоматична извличане и нормализиране на неблагоприятните ефекти в английски туитове. Фината настройка за класифициране на английски туитове ни позволява да постигнем резултат от 56%, което е увеличение с +10% в сравнение със средния резултат за всички участници. Използвайки базата на БЕРТ и отговора на въпроси, ние сме в състояние да постигнем резултат от 57,6% за извличане на споменатите нежелани реакции от туитове, което е увеличение с +1,2% в сравнение със средния резултат за всички подадени предложения.', 'da': 'Dette papir beskriver et system designet til Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Vi beskriver specifikt de systemer, der er designet til at løse opgave 2: Automatisk klassificering af flersprogede tweets, der rapporterer negative virkninger, og opgave 3: Automatisk udvinding og normalisering af negative virkninger i engelske tweets. Finjustering RoBERTa large til klassificering af engelske tweets gør det muligt for os at opnå en F1 score på 56%, hvilket er en stigning på +10% i forhold til den gennemsnitlige F1 score for alle indsendelser. Ved hjælp af BERT-baseret NER og spørgsmål besvarelse kan vi opnå en F1 score på 57,6% for at udtrække bivirkninger omtaler fra tweets, hvilket er en stigning på +1,2% i forhold til den gennemsnitlige F1 score for alle indsendelser.', 'nl': 'Dit document beschrijft een systeem dat is ontworpen voor Social Media Mining for Health Applications (SMM4H) Shared Task 2020. We beschrijven specifiek de systemen die ontworpen zijn om taak 2 op te lossen: Automatische classificatie van meertalige tweets die bijwerkingen melden, en taak 3: Automatische extractie en normalisatie van bijwerkingen in Engelse tweets. Finetuning RoBERTa large voor het classificeren van Engelse tweets stelt ons in staat om een F1 score van 56%, wat een toename is van +10% ten opzichte van de gemiddelde F1 score voor alle inzendingen. Met behulp van BERT gebaseerde NER en vragenbeantwoording, zijn we in staat om een F1 score van 57,6% te bereiken voor het extraheren van bijwerkingen vermeldingen uit tweets, wat een toename is van +1,2% ten opzichte van de gemiddelde F1 score voor alle inzendingen.', 'hr': 'Ovaj papir detalja sustava za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) zajednički zadatak 2020. Posebno opisujemo sustave dizajnirane za rješavanje zadataka 2: automatska klasifikacija višejezičkih tweeta koji prijavljuju nevoljne učinke i zadatak 3: automatska izvlačenja i normalizacija nuspojava na engleskim tweetima. Dobra prilagodba RoBERTa velika za klasifikaciju engleskih tweets omogućava nam da postignemo rezultat F1 od 56%, što je povećanje od +10% u usporedbi s prosječnim rezultatom F1 za sve podatke. Koristeći BERT-based NER i odgovor na pitanja, možemo postići F1 rezultat od 57,6% za izvlačenje spomena nuspojave iz tweets, što je povećanje +1,2% u usporedbi s prosječnim rezultatom F1 za sve podatke.', 'de': 'Dieses Papier beschreibt ein System, das für Social Media Mining for Health Applications (SMM4H) Shared Task 2020 entwickelt wurde. Wir beschreiben speziell die Systeme zur Lösung der Aufgabe 2: Automatische Klassifizierung mehrsprachiger Tweets, die negative Auswirkungen melden, und Aufgabe 3: Automatische Extraktion und Normalisierung von unerwünschten Effekten in englischen Tweets. Feinabstimmung RoBERTa large für die Klassifizierung englischer Tweets ermöglicht es uns, eine F1-Punktzahl von 56% zu erreichen, die eine Erhöhung von +10% gegenüber dem durchschnittlichen F1-Punktestand für alle Einreichungen darstellt. Mit BERT basiertem NER und Fragebeantworter können wir einen F1-Score von 57,6% für das Extrahieren von unerwünschten Reaktionen aus Tweets erzielen, der eine Erhöhung von +1,2% gegenüber dem durchschnittlichen F1-Score für alle Einreichungen darstellt.', 'ko': '본고는 건강한 응용 소셜미디어 발굴(SMM4H) 공유 임무 2020을 위해 설계된 시스템을 상세히 소개한다.우리는 임무 2: 좋지 않은 영향을 보고하는 다국어 추문의 자동 분류와 임무 3: 영어 추문에서 좋지 않은 영향을 자동으로 추출하고 표준화하기 위해 설계된 시스템을 구체적으로 묘사했다.RoBERTA large를 미세하게 조정하여 영어 트윗을 분류한 결과 우리의 F1 득점은 56%에 달했고 제출한 모든 F1 평균 득점에 비해 +10% 증가했다.BERT 기반 NER와 질의응답을 사용하면 트위터에서 불량반응 언급을 추출하는 데 사용된 F1 평균 점수 57.6%에 비해 +1.2% 증가한 F1 점수를 얻을 수 있다.', 'id': 'Kertas ini detail sistem yang direncanakan untuk Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Kami secara khusus menggambarkan sistem yang direncanakan untuk memecahkan tugas 2: Klasifikasi otomatis tweet multibahasa yang melaporkan efek negatif, dan tugas 3: ekstraksi otomatis dan normalisasi efek negatif dalam tweet Inggris. Penyesuaian baik RoBERTa besar untuk mengklasifikasi tweet Inggris memungkinkan kita untuk mencapai skor F1 56%, yang merupakan peningkatan +10% dibandingkan dengan skor F1 rata-rata untuk semua pengiriman. Menggunakan BERT berdasarkan NER dan menjawab pertanyaan, kita dapat mencapai skor F1 57,6% untuk mengekstraksi reaksi negatif sebutan dari tweet, yang merupakan peningkatan +1,2% dibandingkan dengan nilai F1 rata-rata untuk semua pengiriman.', 'fa': 'این کاغذ یک سیستم مشترک برای کاغذ رسانه\u200cهای اجتماعی برای کاربرد سلامتی (SMM4H) مشترک کار ۲۰۰۲ طراحی شده است. ما به طور خاص سیستم\u200cهای طراحی برای حل کار ۲ توصیف می\u200cکنیم: مجموعه\u200cسازی خودکار از توئیت\u200cهای بسیاری زبان\u200cها که اثرات مخالف را گزارش می\u200cدهند، و کار ۳: اثرات\u200cسازی خودکار و عامل\u200cسازی اثرات مخالف در توئی روBERTa تنظیم خوبی برای کلاس کردن توئیت های انگلیسی به ما اجازه می دهد که یک امتیاز F1 در ۵۶ درصد رسیده باشیم، که افزایش +۱۰ درصد در مقایسه با امتیاز متوسط F1 برای تمام تحویل\u200cها است. با استفاده از NER بنیاد BERT و جواب سوال، ما می توانیم یک امتیاز F1 از 57.6 درصد برای اخراج کردن واکنش مخالفی از توئیت، که افزایش +1.2 درصد در مقایسه با امتیاز متوسط F1 برای تمام تسلیم\u200cها است.', 'sw': 'Makala hii inaelezea mfumo ulioandaliwa kwa ajili ya kudhibiti matumizi ya afya ya vyombo vya habari vya kijamii (SMM4H) ilishiriki kazi 2020. Tunaelezea mifumo yenye lengo la kutatua kazi 2: Kusambazwa kwa uhuru wa twiti za lugha nyingi ambazo zinaripoti athari mbaya, na kazi 3: Kutengeneza na utaratibu wa athari mbaya katika twiti za Kiingereza. Fine tuning RoBERTa large for classifying English tweets enables us to achieve a F1 score of 56%, which is an increase of +10% compared to the average F1 score for all the submissions.  Using BERT based NER and question answering, we are able to achieve a F1 score of 57.6% for extracting adverse reaction mentions from tweets, which is an increase of +1.2% compared to the average F1 score for all the submissions.', 'af': "Hierdie papier besonderhede 'n stelsel ontwerp vir sosiale media mining vir gesondige toepassings (SMM4H) Gedeelde taak 2020. Ons beskryf spesifieke die stelsels ontwerp om taak 2 te los: Outomatiese klasifikasie van multitaalske tweets wat teenwoordige effekte rapporteer, en taak 3: Outomatiese uittrek en normalisering van nuutste effekte in Engelske tweets. Fine tuning RoBERTa groot vir klassifisering van Engelske tweets laat ons toe om 'n F1 punt van 56%, wat is 'n vergroot van +10% vergelyk met die gemiddelde F1 punt vir al die voorskrifte. By gebruik van BERT gebaseerde NER en vraag antwoord, is ons in staat om 'n F1 telling van 57.6% te bereik vir uittrek teenwoordige reaksie nommers van tweets, wat is 'n vergroot van +1.2% vergelyk met die gemiddelde F1 telling vir al die onderdragte.", 'sq': 'Ky dokument detajon një sistem të dizajnuar për Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Ne specifikisht përshkruajmë sistemet e dizajnuara për të zgjidhur detyrën 2: klasifikimin automatik të tweeteve shumëgjuhësore që raportojnë efekte të dëmshme dhe detyrën 3: nxjerrjen automatike dhe normalizimin e efekteve të dëmshme në tweetet angleze. Rregullimi i mirë RoBERTa i madh për klasifikimin e tweeteve angleze na lejon të arrijmë një rezultat F1 prej 56%, që është një rritje prej +10% krahasuar me rezultatin mesatar F1 për të gjitha paraqitjet. Using BERT based NER and question answering, we are able to achieve a F1 score of 57.6% for extracting adverse reaction mentions from tweets, which is an increase of +1.2% compared to the average F1 score for all the submissions.', 'tr': 'Bu kagyz sistemi sosial Media Taýramy Saýlaw Programleri (SMM4H) Beýleki Taýram 2020-nji ýylda tasarlanýan Biz 2-nji täzelikleri çözmek üçin düzenlenen sistemleri takyklaýarys: wajyp täzelikleriň otomatik klasifikasy we görevimiz 3: Iňlisçe täzelikleriň otomatik arşiw we normaliziýarys. Iňlisler tweets klasifikasynda RoBERTa örän uly düzenlemek üçin bize F1 nokady 56%-de ýetmek üçin mümkin edýär. Bu +10% hem süýtgewler üçin orta nokady F1 düzeninden gurlanýar. BERT tabanly NER we soragy jogaplaryny ulanyp, gürrüňli terjime etmek üçin 57.6% F1 sanyny tapyp bileris, bu +1.2% üýtgeýär ähli göndermeler üçin ortalama F1 sanyny gurlap bileris.', 'am': 'ይህ ፕሮግራም ማኅበራዊ ሚዲያ ማስታወቂያ ለጤና ፕሮግራሞች (SMM4H) የተሳካ ስራ 2020 የተሰራጨ ስርዓት የተዘጋጀ ስርዓት ይዘረዝራል፡፡ 2 ለስራ ለመፈጸም የተፈጠረውን ስርዓቶች በተለየን እናሳውቃለን፡፡ በንግግሊዝኛ ትዊተሮችን ለመግለጽ የሮብERTA ትልቅ ማድረግ ትልቅ ነው፡፡ የBERT መረብ እና ጥያቄ መልስ በመጠቀም፣ የ57.6 በመቶ የአፍሪካዊ ተቃውሞ ትዊተሮችን ለማውጣት እናስችላለን፡፡', 'hy': "This paper details a system designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020.  Մենք հատկապես նկարագրում ենք համակարգերը, որոնք նախագծված են 2-րդ խնդիրը լուծելու համար' բազլեզու թվիթերի ավտոմատիկ դասակարգում, որոնք հայտարարում են բացասական ազդեցություններ, և 3-րդ խնդիրը' անգլերենի թվիթերի բացասական ազդեցություն Հիանալի կազմակերպում ՌոԲԵՌԹ-ը, որը մեծ է անգլերեն թվիթերի դասակարգման համար, մեզ հնարավորություն է տալիս հասնել F1 գնահատականի 56 տոկոսի, որը +10 տոկոսի աճ է, համեմատած F1 միջին գնահատականի բոլոր ներկայացումների համար: Օգտագործելով BER-ի հիմնված ՆԵՌ-ը և հարցերի պատասխանը, մենք կարողանում ենք հասնել F1-ի 57.6 տոկոսի գնահատականը թվիթերից հանելու համար, ինչը +1.2 տոկոսի աճ է, համեմատած F1-ի միջին գնահատականին բոլոր ներկայացումների համար:", 'bn': 'স্বাস্থ্য অ্যাপ্লিকেশনের (SMM4H) জন্য সামাজিক মিডিয়া মনিং ব্যবস্থা বিস্তারিত একটি সিস্টেম বিস্তারিত বর্ণনা কর আমরা বিশেষ করে কাজের সমাধানের জন্য ডিজাইন করা সিস্টেমের বর্ণনা করি: মাল্টিভাল টুইটের স্বয়ংক্রিয়ভাবে বিভিন্ন প্রভাব প্রতিবেদন এবং কাজ ৩: ইংরেজী ট ইংরেজি টুইট ব্যবহার করার জন্য রোবের্তা বিশাল টুইটের বিশাল টুইটের সংগ্রহ করা হয়েছে যাতে আমরা ৫৬ শতাংশের একটি F1 স্কোর অর্জন করতে পারি, যা সকল প্রতিষ্ঠানের সাধা বেরেট ভিত্তিক NER এবং প্রশ্নের উত্তর ব্যবহার করে আমরা টুইট থেকে বিভিন্ন প্রতিক্রিয়া উল্লেখ করার জন্য ৫৭. ৬% F1 সোকোর অর্জন করতে পারি, যা সকল প্রতিক্রিয়ার সাধারণ F1 স্কোরের তু', 'az': 'Bu kağıt 2020-ci şəkildə paylaşdırılmış iş iş üçün sosyal Media Mining Programları (SMM4H) üçün hazırlanmış sistemin detaylarını. Biz 2. işi çəkmək üçün müəyyən edilmiş sistemləri təsdiqləyirik: müxtəlif təsirlərə xəbər verən çoxlu dil twetlərin automatlı klasifikasyonu və 3. işi: İngilizə twetlərdə təsirli təsirlərin otomatik çıxarılması və normalizasyonu. İngilizci tweetləri seçmək üçün böyük RoBERTa tərzini yaxşı tərzi olaraq 56%-dən F1 dəqiqəsini qəbul edə bilər. Bu, bütün göndərilənlər üçün ortalama F1 dəqiqəsi ilə +10%-dən artır. BERT tabanlı NER və sual cavab verməyi istifadə edərək, Tövtlərdən təsirli reaksiyonun sözlərini çıxartmaq üçün 57,6% F1 dəqiqəsini artıra bilərik, bu da bütün təsirlər üçün ortalama F1 dəqiqəsi ilə +1,2% artıra bilər.', 'bs': 'Ovaj papir detalja sistema dizajniranog za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) zajednički zadatak 2020. Posebno opisujemo sisteme dizajnirane za rješavanje zadataka 2: automatska klasifikacija multijezičkih tweeta koji prijavljuju nevoljne učinke, i zadatak 3: automatska izvlačenja i normalizacija nevoljnih učinka na engleskim tweetima. Dobra tuning RoBERTa velika za klasifikaciju engleskih tweets omogućava nam da postignemo rezultat F1 od 56%, što je povećanje od +10% u usporedbi s prosječnim rezultatom F1 za sve podatke. Koristeći BERT-based NER i odgovor na pitanja, možemo postići F1 rezultat od 57,6% za izvlačenje spomena nuspojave iz tweets, što je povećanje od +1,2% u usporedbi s prosječnim rezultatima F1 za sve podatke.', 'ca': "This paper details a system designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020.  Descrivem específicament els sistemes dissenyats per resoldre la tasca 2: Classificació automàtica de tweets multillengües que denuncien efectes adversos, i tasca 3: Extracció automàtica i normalització d'efectes adversos en tweets anglesos. La millor ajustament de RoBERTa gran per classificar tweets anglesos ens permet aconseguir una puntuació F1 del 56%, que és un augment de +10% comparat amb la mitjana de puntuació F1 per totes les presentacions. Utilitzant NER basat en BERT i responent a preguntes, podem aconseguir una puntuació F1 del 57,6% per extrair les mencions de reacció adversa dels tweets, que és un augment de +1,2% comparat amb la mitjana de puntuació F1 per totes les presentacions.", 'cs': 'Tento článek popisuje systém navržený pro Social Media Mining for Health Applications (SMM4H) Shared Task 2020. Konkrétně popisujeme systémy určené k řešení úkolu 2: Automatická klasifikace vícejazyčných tweetů, které hlásí nežádoucí účinky, a úkol 3: Automatická extrakce a normalizace nežádoucích účinků v anglických tweetech. Jemné ladění RoBERTa large pro klasifikaci anglických tweetů nám umožňuje dosáhnout F1 skóre 56%, což je zvýšení +10% ve srovnání s průměrným F1 skóre pro všechny příspěvky. Pomocí BERT založeného NER a odpovědi na otázky jsme schopni dosáhnout F1 skóre 57,6% pro extrakci zmínek o nežádoucích reakcích ze tweetů, což je zvýšení +1,2% ve srovnání s průměrným F1 skóre u všech příspěvků.', 'fi': 'Tässä artikkelissa esitellään järjestelmä, joka on suunniteltu Social Media Mining for Health Applications (SMM4H) Shared Task 2020 -ohjelmaan. Kuvailemme erityisesti järjestelmiä, jotka on suunniteltu ratkaisemaan tehtävä 2: Haittavaikutuksia raportoivien monikielisten twiittien automaattinen luokittelu ja tehtävä 3: Haittavaikutusten automaattinen uuttaminen ja normalisointi englanninkielisissä twiitteissä. Hienosäätö RoBERTa suuri englanninkielisten twiittien luokitteluun mahdollistaa 56%:n F1-pisteen saavuttamisen, mikä on +10%:n lisäys kaikkien lähetettyjen F1-pisteiden keskimääräiseen tulokseen verrattuna. Käyttämällä BERT-pohjaista NER- ja kysymysvastausta pystymme saavuttamaan 57,6%:n F1-pisteen poistaessamme twiitteistä haittavaikutuksista, mikä on +1,2%:n lisäys verrattuna kaikkien lähetettyjen F1-pisteiden keskiarvoon.', 'et': 'Käesolevas dokumendis kirjeldatakse sotsiaalmeedia kaevandamise süsteemi tervishoiu rakenduste jaoks (SMM4H) jaoks 2020. aasta jagatud ülesannet. Kirjeldame konkreetselt süsteeme, mis on mõeldud 2. ülesande lahendamiseks: kahjulikku mõju teatavate mitmekeelsete säutside automaatne klassifitseerimine ja 3. ülesanne: kahjulike mõjude automaatne ekstraheerimine ja normaliseerimine inglise säutsides. Peenhäälestamine RoBERTa suur inglise säutsude klassifitseerimiseks võimaldab meil saavutada F1 skoori 56%, mis on +10% suurem võrreldes kõigi esitatud esituste keskmise F1 skooriga. BERT-põhise NER-i ja küsimustele vastamise abil saavutame kõrvaltoimete märkuste eraldamisel säutsudest F1 skoori 57,6%, mis on +1,2% suurem võrreldes kõigi esitatud esituste keskmise F1 skooriga.', 'sk': 'Ta prispevek podrobno opisuje sistem, zasnovan za skupno nalogo za rudarjenje v socialnih omrežjih za zdravstvene aplikacije (SMM4H) 2020. Posebej opisujemo sisteme za reševanje naloge 2: Avtomatska klasifikacija večjezičnih tweetov, ki poročajo o neželenih učinkih, in naloga 3: Avtomatska ekstrakcija in normalizacija neželenih učinkov v angleških tweetih. Fino uglaševanje RoBERTa velik za razvrščanje angleških tweetov nam omogoča doseganje rezultata F1 56%, kar pomeni povečanje za +10% v primerjavi s povprečnim rezultatom F1 za vse prispevke. Z uporabo BERT-ovega NER-a in odgovorom na vprašanja lahko dosežemo rezultat F1 57,6% za ekstrakcijo omenjenih neželenih učinkov iz tweetov, kar pomeni povečanje za +1,2% v primerjavi s povprečnim rezultatom F1 za vse prispevke.', 'jv': 'Pesene nang kaper iki sistem sing dibenalke kanggo Aplikasi Halahan (SMM4H) Sampeyan task 2020 section Fining Ngawe ngubah BERT sing basa NR karo kesempatan sing luwih-luwih, kita iso nglanggar Advertu F1 sing paling 75.6% kanggo nggawe ngubah weruh-luwih dhéwé menehi nyebuté Tuit, sing wis nambah +.2% sing bisa nyebuté sak tau karo perusahaan puntuan F1 sing dumadhi sabané.', 'ha': "This paper details a system designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020.  Tuna ƙayyade tsarin da ake yi wa solar aikin 2: Taimari farat ɗaya na sifilaɗar littattafani masu cikin mulki-lingui wanda ke yin bayan aiki, da aikin 3: Cikakken farat ɗaya da kuma a normal aikin haske cikin littattafani na Ingiriya. Babu mai amfani da RoBERTa mai girma wa fasalin littattafani na Ingiriya, yana amfani da mu kai wani nau'in F1 na kasar 65%, wanda yana ƙaranci+10% sami da tsakanin F1 score wa duk wasiyyar. Ina amfani da amfani da BERT da ya binge NER da tambayi, za'a iya cika matsayin F1 na 57.6% dõmin ya fita rabo-rabo daga Twitter, wanda yana ƙaranci+1.2% sammenliki da ma'aunin F1 na kasar duk wasiyyar.", 'he': 'הנייר הזה מפרט מערכת שנועדת למכרת מדיה חברתית לתוכניות בריאות (SMM4H) משימה משותפת 2020. אנו מתארים במיוחד את המערכות המתוכננות לפתור את משימה 2: שיגור אוטומטי של טוויטים רבות שפות שמדווחים על השפעות הלא נעימות, ומשימה 3: חיפוש אוטומטי ונורמליזציה של השפעות הלא נעימות בטוויטים אנגליים. התאמה טובה של רוברטה גדולה כדי להקליף טוויטים אנגליים מאפשרת לנו להשיג נקודת F1 של 56%, וזה מגבילה של +10% בהשוואה לציון F1 הממוצע לכל ההצעות. בשימוש של NER מבוסס על BERT ומעניין שאלות, אנחנו מסוגלים להשיג נקודת F1 של 57.6% כדי להוציא זיכרונות של תגובות בלתי נעימות מתוך טוויטים, וזה מגבילה של +1.2% בהשוואה לציון F1 הממוצע לכל ההעברות.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དུ་འཇུག་སྣོད་ཀྱི་བྱ་རིམ་ལ་རང་ཉིད་ཀྱི་འཇུག་སྣོད་ཀྱི་གནས་སྟངས་གསལ་བཤད་ཞིག We specifically describe the systems designed to solve task 2: Automatic classification of multilingual tweets that report adverse effects, and task 3: Automatic extraction and normalization of adverse effects in English tweets. Fine tuning RoBERTa large for classifying English tweets enables us to achieve a F1 score of 56%, which is an increase of +10% compared to the average F1 score for all the submissions. Using BERT based NER and question answering, we are able to achieve a F1 score of 57.6% for extracting adverse reaction mentions from tweets, which is an increase of +1.2% compared to the average F1 score for all the submissions.'}
{'en': 'SpeechTrans@SMM4H’20 : Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications S peech T rans@ SMM 4 H ’20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications', 'ar': "SpeechTrans @ SMM4H'20: تأثير المعالجة المسبقة و N-grams على التصنيف التلقائي للتغريدات التي تشير إلى الأدوية", 'fr': "SpeechTrans @SMM4H '20\xa0: Impact du prétraitement et des N-grammes sur la classification automatique des tweets mentionnant des médicaments", 'pt': "SpeechTrans@SMM4H'20: Impacto do Pré-processamento e N-grams na Classificação Automática de Tweets que Mencionam Medicamentos", 'es': "SpeechTrans @SMM4H '20: Impacto del preprocesamiento y los N-gramas en la clasificación automática de tuits que mencionan medicamentos", 'ja': "SpeechTrans @ SMM 4 H '20 ：前処理とNグラムが薬剤に言及するツイートの自動分類に与える影響", 'zh': 'SpeechTrans@SMM4H 20曰:预处理与N-gram推文自别也', 'ru': "SpeechTrans@SMM4H'20: Влияние предварительной обработки и N-грамм на автоматическую классификацию твитов, в которых упоминаются лекарства", 'hi': "SpeechTrans@SMM4H'20: Tweets के स्वचालित वर्गीकरण पर Preprocessing और N-grams का प्रभाव जो दवाओं का उल्लेख करता है", 'ga': "SpeechTrans@SMM4H'20: Tionchar na Réamhphróiseála agus N-gram ar Aicmiú Uathoibríoch Tweetanna a Luann Cógais", 'hu': "SpeechTrans@SMM4H '20: Az előfeldolgozás és az N-gramm hatása a gyógyszereket említő tweetek automatikus osztályozására", 'ka': "SpeechTrans@SMM4H '20: პრეპროცესის და N-გრამების ავტომატური კლასიფიკაციაციის შემდეგ, რომელიც მენუსის მედიციაციები", 'it': "SpeechTrans@SMM4H '20: Impatto della Preelaborazione e N-grammi sulla classificazione automatica dei Tweet che menzionano farmaci", 'mk': "SpeechTrans@SMM4H '20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications", 'ms': "SpeechTrans@SMM4H '20: Impak Preproses dan N-gram pada Klasifikasi Automatik Tweets That Mention Medications", 'el': "SpeechTrans@SMM4H '20: Επίδραση της προεπεξεργασίας και των Ν-γραμμάτων στην αυτόματη ταξινόμηση των tweets που αναφέρουν φάρμακα", 'kk': "SpeechTrans@SMM4H '20: Твиттерді автоматты түрде классификациялау және N- граммалардың әсері", 'lt': 'SpeechTrans@SMM4H "20: Išankstinio apdorojimo ir N-gramų poveikis automatiniam Tweetų, kurie minimi vaistai, klasifikavimui', 'mn': "SpeechTrans@SMM4H '20: Өмнөх үйлдэл болон Н-граммын нөлөө нь автоматически хуваалцах Твиттүүдийн Твиттүүд", 'ml': "SpeechTrans@SMM4H '20: ആ മെനേഷന്\u200d മെഡിക്ഷനുകളുടെ ടൂട്ടുകളുടെ സ്വയമായ ക്ലാസിഷനില്\u200d പ്രഭാവം പ്രവര്\u200dത്തിപ്പിക്കുക", 'no': 'SpeechTrans@SMM4H « 20: Påvirkning av førehandsaming og N- gramar på automatisk klassifisering av Tweets som menymedikasjonar', 'pl': "SpeechTrans@SMM4H '20: Wpływ przetwarzania wstępnego i N-gramów na automatyczną klasyfikację tweetów wymieniających leki", 'mt': "SpeechTrans@SMM4H '20: L-impatt tal-ipproċessar minn qabel u l-N-grammi fuq il-Klassifikazzjoni Awtomatika tat-Tweets li Jimmissru Medikazzjonijiet", 'ro': "SpeechTrans@SMM4H '20: Impactul prelucrării prealabile și al N-gramelor asupra clasificării automate a tweeturilor care menționează medicamente", 'sr': "SpeechTrans@SMM4H '20: utjecaj predobrađivanja i N-grama na automatsku klasifikaciju Tweets That Mention Medications", 'si': "SpeechTrans@SMM4H '20: ස්වයංක්\u200dරියාව ප්\u200dරක්\u200dරියාපනය සහ N- ග්\u200dරෑම් ස්වයංක්\u200dරිය ක්\u200dරාසික්\u200dෂිකරණයේ ට්විට් අර මතක පද්", 'ta': "SpeechTrans@SMM4H '20: முன்செயல்படுத்தல் மற்றும் N- கிராம்களின் விளைவு", 'ur': "SpeechTrans@SMM4H '20: ٹیوٹوں کی آٹوٹی کلاسیفٹ پر پیش پرپروسیس اور N-گرم کے اثر", 'so': "SpeechTrans@SMM4H '20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medication", 'sv': "SpeechTrans@SMM4H '20: Påverkan av förbehandling och N-gram på automatisk klassificering av tweets som nämner läkemedel", 'uz': 'SpeechTrans@SMM4H Comment', 'vi': "SpeechTrans@SMM4H '20: Tác dụng của quá trình xử lý và N-grams về Automatic classification of Tweet That Mention Medications", 'bg': "SpeechTrans@SMM4H '20: Въздействие на предварителната обработка и N-грамовете върху автоматичната класификация на туитове, които споменават лекарства", 'hr': "SpeechTrans@SMM4H '20: utjecaj predobrađivanja i N-grama na automatsku klasifikaciju Tweets That Mention Medications", 'nl': "SpeechTrans@SMM4H '20: Effect van voorbewerking en N-grammen op automatische classificatie van tweets waarin medicijnen worden genoemd", 'da': "SpeechTrans@SMM4H '20: Virkningen af forbehandling og N-gram på automatisk klassificering af tweets, der nævner medicin", 'de': "SpeechTrans@SMM4H '20: Auswirkungen von Vorverarbeitung und N-Gramm auf die automatische Klassifizierung von Tweets, die Medikamente erwähnen", 'id': "SpeechTrans@SMM4H '20: Impak Preproses dan N-gram pada Klasifikasi Otomatis Tweets That Mention Medications", 'ko': 'SpeechTrans@SMM4H20:예처리와 N-gram이 약물에 대한 트윗 자동 분류에 미친 영향', 'sw': "SpeechTrans@SMM4H '20: Matokeo ya utatuzi na vipimo vya N kuhusu Kutangaza Uwezekano wa Twita", 'fa': 'SpeechTrans@SMM4H اثر پیش\u200cپردازی و گرم\u200cهای N بر کلاس\u200cسازی توئیت\u200cهای خودکار', 'af': "SpeechTrans@SMM4H '20: Impact of Preprocessing en N- grams op Outomatiese Klassifikasie van Tweets Wat Mensiemedikasie", 'tr': "SpeechTrans@SMM4H '20: Otomatik Klasifikasyonun Etkileri Şu Menüs Ortamları", 'sq': "SpeechTrans@SMM4H '20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications", 'am': "SpeechTrans@SMM4H '20: የፕሮግራም እና N-grams በሐሳብ ክፍል ላይ የTweets That Mention Medication", 'hy': "SpeechTrans@SMM4H '20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications", 'bn': "SpeechTrans@SMM4H '২০: স্বয়ংক্রিয়ভাবে টুইটারের স্বয়ংক্রিয়ভাবে স্বাভাবিক পরিস্থিতির উপর প্রভাব", 'bs': "SpeechTrans@SMM4H '20: utjecaj predobrađivanja i N-grama na automatsku klasifikaciju Tweets That Mention Medications", 'az': "SpeechTrans@SMM4H '20: √Ėn-iŇül…ôm…ô v…ô N-gramlarńĪn Avtomatik Klasifikasyonu T√∂vtl…ôrin ńįdar…ôti O Men√ľs ńįdar…ôtl…ôri", 'ca': "SpeechTrans@SMM4H '20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications", 'cs': "SpeechTrans@SMM4H '20: Vliv předzpracování a N-gramů na automatickou klasifikaci tweetů zmiňujících léky", 'et': 'SpeechTrans@SMM4H "20: Eeltöötluse ja N-grammide mõju ravimeid mainivate tweetide automaatsele klassifitseerimisele', 'fi': "SpeechTrans@SMM4H '20: Esikäsittelyn ja N-grammien vaikutus lääkkeiden automaattiseen luokitteluun", 'ha': "SpeechTrans@SMM4H '20: Effect of Preparing and N-gram on Natural Classification of Twitter that Mention Media", 'he': 'SpeechTrans@SMM4H "20: השפעה של העבודה הקדמית ו-N-גרם על שיעור אוטומטי של טוויטים שמזכירים תרופות', 'jv': "SpeechTrans@SMM4H '200: Effect of pretracing and N-gram on Automatically", 'sk': 'SpeechTrans@SMM4H "20: Vpliv predobdelave in N-gramov na avtomatsko klasifikacijo tweetov, ki omenjajo zdravila', 'bo': "SpeechTrans@SMM4H '20ཡིན།"}
{'en': 'This paper describes our  system  developed for automatically classifying tweets that mention medications. We used the  Decision Tree classifier  for this  task . We have shown that using some elementary preprocessing steps and TF-IDF n-grams led to acceptable  classifier  performance. Indeed, the F1-score recorded was 74.58 % in the development phase and 63.70 % in the test phase.', 'ar': 'تصف هذه الورقة نظامنا الذي تم تطويره لتصنيف التغريدات التي تشير إلى الأدوية تلقائيًا. استخدمنا مصنف شجرة القرار لهذه المهمة. لقد أظهرنا أن استخدام بعض خطوات المعالجة الأولية و TF-IDF n-grams أدى إلى أداء مقبول للمصنف. في الواقع ، كانت درجة F1 المسجلة 74.58٪ في مرحلة التطوير و 63.70٪ في مرحلة الاختبار.', 'es': 'Este artículo describe nuestro sistema desarrollado para clasificar automáticamente los tuits que mencionan medicamentos. Utilizamos el clasificador Árbol de decisiones para esta tarea. Hemos demostrado que el uso de algunos pasos de preprocesamiento elementales y n-gramas TF-IDF condujo a un rendimiento aceptable del clasificador. De hecho, la puntuación F1 registrada fue del 74,58% en la fase de desarrollo y del 63,70% en la fase de prueba.', 'fr': "Cet article décrit notre système développé pour classer automatiquement les tweets qui mentionnent des médicaments. Nous avons utilisé le classificateur d'arbre de décision pour cette tâche. Nous avons montré que l'utilisation de certaines étapes élémentaires de prétraitement et de n-grammes TF-IDF conduisait à des performances de classificateur acceptables. En effet, le score F1 enregistré était de 74,58\xa0% en phase de développement et de 63,70\xa0% en phase de test.", 'pt': 'Este artigo descreve nosso sistema desenvolvido para classificar automaticamente tweets que mencionam medicamentos. Usamos o classificador Árvore de Decisão para esta tarefa. Mostramos que o uso de algumas etapas elementares de pré-processamento e n-gramas TF-IDF levaram a um desempenho aceitável do classificador. De fato, o F1-score registrado foi de 74,58% na fase de desenvolvimento e 63,70% na fase de teste.', 'ja': '本稿では、医薬品について言及したツイートを自動的に分類するために開発されたシステムについて説明します。このタスクには意思決定ツリー分類子を使用しました。いくつかの基本的な前処理工程及びＴＦ － ＩＤＦ ｎ － ｇｒａｍｓを使用することにより、許容可能な分類子性能がもたらされたことを示した。実際、記録されたF 1スコアは、開発段階で74.58%、テスト段階で63.70%であった。', 'zh': '本文引我辈为自类提及药物之推文而开发之统。 我们因为用了决定树分类器。 吾已验之,用其本预处理TF-IDF n-grams可以生可受之器。 事上,F1得分在开发阶段为74.58%,在测试阶段为63.70%。', 'ru': 'В этой статье описывается наша система, разработанная для автоматической классификации твитов, в которых упоминаются лекарства. Для этой задачи мы использовали классификатор дерева решений. Мы показали, что использование некоторых элементарных этапов предварительной обработки и n-грамм TF-IDF привело к приемлемой производительности классификатора. Действительно, зарегистрированный балл F1 составил 74,58% на этапе разработки и 63,70% на этапе тестирования.', 'hi': 'यह पेपर स्वचालित रूप से उन ट्वीट्स को वर्गीकृत करने के लिए विकसित हमारी प्रणाली का वर्णन करता है जो दवाओं का उल्लेख करते हैं। हमने इस कार्य के लिए निर्णय ट्री क्लासिफायर का उपयोग किया। हमने दिखाया है कि कुछ प्राथमिक प्रीप्रोसेसिंग चरणों और टीएफ-आईडीएफ एन-ग्राम का उपयोग करके स्वीकार्य क्लासिफायरप्रदर्शन का नेतृत्व किया। दरअसल, एफ 1-स्कोर विकास चरण में 74.58% और परीक्षण चरण में 63.70% दर्ज किया गया था।', 'ga': 'Déanann an páipéar seo cur síos ar ár gcóras a forbraíodh chun tweets a luaitear cógais a rangú go huathoibríoch. D’úsáideamar an t-aicmitheoir Crann Cinnidh don tasc seo. Léiríomar gur baineadh úsáid as roinnt céimeanna réamhphróiseála tosaigh agus TF-IDF n-gram mar thoradh ar fheidhmíocht aicmitheora inghlactha. Go deimhin, ba é an scór F1 a taifeadadh ná 74.58% sa chéim forbartha agus 63.70% sa chéim tástála.', 'ka': 'ეს დაახლოები ჩვენი სისტემის განვითარებულია ავტომატურად კლასიფიკაციისთვის, რომელიც ექსექციების შესახებ განვითარებულია. ჩვენ ამ რაოდენობისთვის განსაზღვრებული ხე კლასიფიკაციას გამოყენეთ. ჩვენ გამოჩვენეთ, რომ გამოყენებული ელემენტური პრეპროცესის ნაწილად და TF-IDF n-გრამების გამოყენება, რომლებიც კლასიფიკაციური გამოყენებას გავაკეთებული ნამდვილად, F1 წერტილის შენახვა 74,58% იყო განვითარების ფაზაში და 63,70% ტესტის ფაზაში.', 'hu': 'Ez a tanulmány ismerteti a gyógyszereket említő tweetek automatikus osztályozására kifejlesztett rendszerünket. Ehhez a feladathoz a Decision Tree osztályozót használtuk. Kimutattuk, hogy néhány elemi előfeldolgozási lépés és TF-IDF n-gramm használata elfogadható osztályozói teljesítményt eredményezett. Az F1-pontszám a fejlesztési szakaszban 74,58%, a tesztfázisban pedig 63,70%.', 'el': 'Αυτή η εργασία περιγράφει το σύστημά μας που αναπτύχθηκε για την αυτόματη ταξινόμηση tweets που αναφέρουν φάρμακα. Χρησιμοποιήσαμε τον ταξινομητή Δέντρο Αποφάσεων για αυτήν την εργασία. Έχουμε δείξει ότι η χρήση ορισμένων στοιχειώδους προεπεξεργασίας βημάτων και γραμμάτων οδήγησε σε αποδεκτή απόδοση ταξινομητή. Πράγματι, η βαθμολογία F1 που καταγράφηκε ήταν 74.58% στη φάση ανάπτυξης και 63.70% στη φάση δοκιμής.', 'it': "Questo articolo descrive il nostro sistema sviluppato per classificare automaticamente i tweet che menzionano i farmaci. Abbiamo usato il classificatore dell'albero delle decisioni per questo compito. Abbiamo dimostrato che l'utilizzo di alcuni passaggi elementari di preelaborazione e TF-IDF n-grammi ha portato a prestazioni accettabili del classificatore. Infatti, il punteggio F1 registrato è stato del 74,58% nella fase di sviluppo e del 63,70% nella fase di test.", 'kk': 'Бұл қағаз біздің жүйемізді медицина туралы tweets классификациялау үшін автоматты түрде жасалған. Біз бұл тапсырма үшін Шешім Бұтақ классификациясын қолдандық. Біз кейбір элементтерді алдын- процессердің қадамдарын және TF- IDF n- граммаларын қолдану үшін классификациялық жұмыс істеу үшін көрсеттік. Шынымен, F1 деңгейінің жазуы 74,58% және сынақ деңгейінде 63,70% болды.', 'ms': 'Kertas ini menggambarkan sistem kami yang dikembangkan untuk mengklasifikasikan tweet secara automatik yang menyebutkan ubat. Kami menggunakan pemikiran pokok keputusan untuk tugas ini. Kami telah menunjukkan bahawa menggunakan beberapa langkah pemprosesan dasar dan n-gram TF-IDF membawa kepada prestasi pengelasah yang diterima. Sebenarnya, skor F1 yang direkam adalah 74.58% dalam fasa pembangunan dan 63.70% dalam fasa ujian.', 'lt': 'Šiame dokumente aprašoma mūsų sistema, sukurta automatiškai klasifikuojant tweetus, kuriuose minimi vaistai. Šiai užduotims naudojome Sprendimo medžio klasifikatorių. We have shown that using some elementary preprocessing steps and TF-IDF n-grams led to acceptable classifier performance.  Iš tiesų F1 rezultatas buvo 74,58 % vystymosi etape ir 63,70 % bandymo etape.', 'mk': 'Овој весник го опишува нашиот систем развиен за автоматска класификација на твитови кои споменуваат лекови. Го користевме класификаторот на дрвото на одлуките за оваа задача. Ние покажавме дека користењето на некои елементарни чекори за препроцес и TF-IDF n-грами доведе до прифатлива класификаторска перформанса. Всушност, регистрираниот резултат на Ф1 беше 74,58 отсто во фазата на развојот и 63,70 отсто во тестовата фаза.', 'mn': 'Энэ цаас бидний системийг эмчилгээний тухай хэлж байгаа tweets-г автоматаар хичээлдэг гэдгийг тайлбарладаг. Бид энэ ажлын хувьд шийдвэрлэлийн мод хуваалцагч хэрэглэсэн. Бид зарим анхны үйл ажиллагааны алхам, ТF-IDF n-грамм ашиглаж буй анхны үйл ажиллагааг хүлээн зөвшөөрөх болсон. Үнэндээ F1 оноо нь хөгжлийн давхарт 74.58%, шалгалтын давхарт 63.70%.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ സിസ്റ്റമുണ്ടാക്കിയ ടൂട്ടുകള്\u200d സ്വയം വിശദീകരിക്കുന്നതിനായി വിവരിക്കുന്ന ഈ ജോലിക്ക് വേണ്ടി തീരുമാന വൃക്ഷത്തെ ഞങ്ങള്\u200d ഉപയോഗിച്ചു. ഞങ്ങള്\u200d കാണിച്ചിരിക്കുന്നു എന്തെങ്കിലും മൂലകങ്ങളുടെ മുന്\u200dപുരോഗപ്രക്രിയ നടപടികള്\u200d ഉപയോഗിച്ച് ടിഎഫ്-ഐഡിഎഫ് n-ഗ തീര്\u200dച്ചയായും, എഫ്\u200c1 സ്കോര്\u200dട്ട് റെക്കോര്\u200dട്ട് ചെയ്യപ്പെട്ടിരുന്നത് 74.58 ശതമാനമായിരുന്നു. പരീക്ഷയുടെ പരിശോധനത', 'ro': 'Această lucrare descrie sistemul nostru dezvoltat pentru clasificarea automată a tweeturilor care menționează medicamente. Am folosit clasificatorul Arbore de Decizie pentru această sarcină. Am arătat că utilizarea unor pași elementare de pre-procesare și TF-IDF n-grame a condus la performanțe acceptabile de clasificare. Într-adevăr, scorul F1 înregistrat a fost de 74,58% în faza de dezvoltare și 63,70% în faza de testare.', 'no': 'Denne papiret beskriver systemet vårt utvikla for automatisk klassifisering av tweets som mener medikamenter. Vi brukte beslutningstetreklassifiseringen for denne oppgåva. Vi har vist at med nokre elementære forhandlingsteg og TF-IDF-n-gram har ført til akseptabel klassifiseringsfunksjon. F1-poeng som er registrert var 74,58% i utviklingsfasjonen og 63,70% i testfasen.', 'mt': 'Dan id-dokument jiddeskrivi s-sistema tagħna żviluppata biex tikklassifika awtomatikament tweets li jsemmu l-mediċini. Użajna l-klassifikatur tas-Siġar tad-Deċiżjoni għal dan il-kompitu. Intwera li l-użu ta’ xi passi elementari ta’ preproċessar u n-grammi TF-IDF wasslu għal prestazzjoni aċċettabbli tal-klassifikatur. Tabilħaqq, il-punteġġ F1 irreġistrat kien 74.58% fil-fażi tal-iżvilupp u 63.70% fil-fażi tat-test.', 'pl': 'Niniejszy artykuł opisuje nasz system opracowany do automatycznej klasyfikacji tweetów, które wspominają leki. Do tego zadania użyliśmy klasyfikatora Drzewa Decyzji. Wykazaliśmy, że zastosowanie niektórych elementarnych kroków przetwarzania wstępnego i n-gramów TF-IDF doprowadziło do akceptowalnej wydajności klasyfikatora. W rzeczywistości wynik F1 wynosił 74,58% w fazie rozwoju i 63,70% w fazie testowej.', 'si': 'මේ පැත්තේ අපේ පද්ධතිය ස්වයංක්\u200dරියාවිතයෙන් විශ්වාස කරලා තියෙනවා විද්\u200dයාවක් කියලා තියෙන අපි මේ වැඩේ වෙනුවෙන් තීරණා ගස් විශේෂකය පාවිච්චි කරනවා. අපිට පෙන්වන්න පුළුවන් විදියට පස්සේ ප්\u200dරක්\u200dරියාස කරන්න පුළුවන් විදියට සහ TF-IDF n-Grams වලින් ප්\u200dරතික්\u200dරිය ඇත්තටම, F1-ස්කෝර් ලිපින්තුවේ 74.58% විකාශ විදියට සහ 63.70% පරීක්ෂා විදියට.', 'sv': 'Denna uppsats beskriver vårt system utvecklat för att automatiskt klassificera tweets som nämner mediciner. Vi använde klassificeringen Beslutsträd för den här uppgiften. Vi har visat att användning av några elementära förbehandlingssteg och TF-IDF n-gram ledde till acceptabel klassificeringsprestanda. F1-poängen var 74,58% i utvecklingsfasen och 63,70% i testfasen.', 'sr': 'Ovaj papir opisuje naš sistem razvijen za automatsku klasifikaciju tweets koji spominju lekove. Koristili smo klasifikaciju drveta odluke za ovaj zadatak. Pokazali smo da koristeći neke elementarne korake preobrađivanja i TF-IDF n-grame dovede do prihvatljive klasifikacije. Zapravo, snimljen je rezultat F1 74,58% u razvojnoj fazi i 63,70% u testnoj fazi.', 'so': 'Kanu wuxuu warqaddan u qoraa nidaamkan oo horumariyey si ay u kala fasaxaan tweetka caafimaadka. Waxaannu u isticmaalnay geedka xukunka arinkan. Waxan muujinnay in isticmaalka tallaabooyin horumarinta ah iyo TF-IDF n-grams uu u keenay fasax la aqbali karo. Sida runta ah, scorta F1 waxaa lagu qoray 74.58% fasalka horumarinta iyo 63.70% fasaxa imtixaanka.', 'ta': 'இந்த காகிதம் மருத்துக்களை குறிப்பிடுகிறது என்று தானாகவே வகைப்படுத்துவதற்காக எங்கள் அமைப்பு உருவாக்கப நாங்கள் இந்த பணிக்கு தீர்ப்பு மரத்தை வகுப்பாளரை பயன்படுத்தினோம். நாம் சில முதன்மை முன்செயல்படுத்தல் படிகளை பயன்படுத்தி மற்றும் TF-IDF n-கிராம்களை பயன்படுத்தி ஏற்றுக் கொள்ளும் வகுப் நிச்சயமாக, F1- புள்ளிகள் பதிவு செய்யப்பட்டது வளர்வு காலத்தில் 74.58% மற்றும் சோதனைக் காலத்தில் 63.70% ஆகும்.', 'ur': 'یہ کاغذ ہماری سیسٹم کو اپنا طریقہ دکھاتا ہے جو مواد کے ذریعہ توئیٹوں کا ذکر کرتا ہے۔ ہم نے فیصلہ کے درخت کو اس کام کے لئے مختلف کر دیا۔ ہم نے دکھایا ہے کہ بعض ابتدائمی پیشپرسس سٹیوں اور TF-IDF n-گرم کے مطابق قبول کرنے والی کلاسپیر کی عملکرد کی وجہ سے۔ بے شک، F1-score ریکورد کیا گیا تھا، توسعہ فوج میں 74.58%، اور تست فوج میں 63.70%.', 'uz': 'Bu qogʻoz tizimimizni avtomatik tayyorlash uchun avtomatik foydalanuvchi Twittlarni anglatadi. Биз бу ишига махфий дарахтни ўргатдик. Biz bir necha elemental preprocessor qadamlarini ishlatish va TF-IDF n-grammalarni ishlatish mumkin. Hullas, F1 scori taʼminlovchi darajada 74.58% va sinov fasida 63.70% edi.', 'vi': "Bài báo này mô tả hệ thống của chúng tôi được phát triển để tự động liệt kê tweet nhắc đến thuốc. Chúng tôi dùng người phân loại cây quyết định cho nhiệm vụ này. Chúng tôi đã cho thấy rằng sử dụng một số bước sơ khai xử và TF-IDF n-gram đã tạo ra một số hiệu ứng phân loại có thể chấp nhận. Thực tế là số F1-số lượng đã được ghi nhận là 74.58=. trong giai đoạn phát triển và 63.70='trong giai đoạn thử nghiệm.", 'bg': 'Тази статия описва нашата система, разработена за автоматично класифициране на туитове, които споменават лекарства. За тази задача използвахме класификатора Дърво на решенията. Показахме, че използването на някои елементарни стъпки за предварителна обработка и n-грамове доведе до приемливо представяне на класификатора. Всъщност отчетеният резултат е 74,58% във фазата на развитие и 63,70% във фазата на тестване.', 'da': 'Denne artikel beskriver vores system udviklet til automatisk klassificering af tweets, der nævner medicin. Vi brugte klassificeringen Beslutningstræ til denne opgave. Vi har vist, at brugen af nogle elementære forbearbejdningstrin og TF-IDF n-grams førte til acceptabel klassificering ydeevne. Faktisk var F1-scoren registreret 74,58% i udviklingsfasen og 63,70% i testfasen.', 'nl': 'Dit artikel beschrijft ons systeem ontwikkeld voor het automatisch classificeren van tweets die medicijnen vermelden. Voor deze taak hebben we de Decision Tree classificator gebruikt. We hebben aangetoond dat het gebruik van enkele elementaire preprocessing stappen en TF-IDF n-grammen leidde tot acceptabele classificator prestaties. Inderdaad was de geregistreerde F1-score 74,58% in de ontwikkelingsfase en 63,70% in de testfase.', 'de': 'Dieser Artikel beschreibt unser System zur automatischen Klassifizierung von Tweets, die Medikamente erwähnen. Für diese Aufgabe haben wir den Decision Tree Klassifikator verwendet. Wir haben gezeigt, dass die Verwendung einiger elementarer Vorverarbeitungsschritte und TF-IDF n-Gramm zu einer akzeptablen Klassifizierungsleistung führte. Tatsächlich lag der erzielte F1-Score bei 74,58% in der Entwicklungsphase und 63,70% in der Testphase.', 'id': 'Kertas ini menjelaskan sistem kami yang dikembangkan untuk mengklasifikasi secara otomatis tweet yang menyebutkan obat. Kami menggunakan pemikiran pohon keputusan untuk tugas ini. Kami telah menunjukkan bahwa menggunakan beberapa langkah pemroses dasar dan TF-IDF n-gram menyebabkan prestasi klasifikasi yang diterima. Sebenarnya, skor F1 yang direkam adalah 74,58% dalam fase pengembangan dan 63,70% dalam fase tes.', 'fa': 'این کاغذ سیستم ما را توسعه می\u200cدهد که برای تحصیل کردن توئیت\u200cهایی که داروها را ذکر می\u200cکنند، توسعه می\u200cدهد. ما از درخت تصمیم\u200cگیری برای این کار استفاده کردیم. ما نشان دادیم که با استفاده از بعضی قدم\u200cهای پیش\u200cپردازش ابتدایی و n-گرم\u200cهای TF-IDF به اجرای رابطه\u200cکننده\u200cی قابل پذیرفته است. در حقیقت، نقاط F1 ثبت شده 74.58% در مراحل توسعه و 63.70% در مراحل تست بود.', 'sw': 'Gazeti hili linaelezea mfumo wetu ulioandaliwa kwa ajili ya kutangaza twiti zinazotaja matibabu. Tulitumia mti wa uamuzi kwa kazi hii. Tumeonyesha kwamba kwa kutumia baadhi ya hatua za msingi za upasuaji na vipimo vya TF-IDF vilisababisha utendaji unaofanywa. Kwa hakika, score ya F1 ilirekodiwa ni asilimia 74.58 katika hatua ya maendeleo na asilimia 63.70 katika hatua ya jaribio.', 'ko': '본고는 우리가 개발한 시스템을 묘사하는데 이 시스템은 약물을 자동으로 분류하여 언급하는 추문에 사용된다.우리는 결정 트리 분류기를 사용하여 이 임무를 완성한다.우리는 일부 기본적인 예처리 절차와 TF-IDF n-grams를 사용하면 받아들일 수 있는 분류기 성능을 얻을 수 있다는 것을 이미 증명하였다.실제로 F1의 성적은 개발 단계에서 74.58%, 테스트 단계에서 63.70%였다.', 'tr': 'Bu kagyz biziň sistemamyzy dermanlary aýdan tweets klasifikasy üçin awtomatik taýýarlandyrylýar. Biz bu işiň üçin kararym agaçlary klasifikatyny ulandyk. Biz bu n äçe elementer öň-işlemek adımlaryny we TF-IDF n-gramlaryny ulanyp görkezildik. Bu käbir klasifikatçy eserdenler üçin gowy görkezildi. Çyndanam, F1 अंशy gelişmek phasesynda 74,58% we test phasesynda 63,70% ýazyldy.', 'af': 'Hierdie papier beskrywe ons stelsel ontwikkeld vir outomaties klassifiseer tweets wat medikamente bepaal. Ons het die besluit Boom klassifiseerder vir hierdie taak gebruik. Ons het vertoon dat die gebruik van sommige elementeerde voorafverandering stappe en TF-IDF n-grame gelei het na aanvaarbare klassifiseerder prestasie. In die ontwikkelingsfase was 74,58% en 63,70% in die toets fase.', 'sq': 'Kjo letër përshkruan sistemin tonë të zhvilluar për klasifikimin automatik të tweeteve që përmendin ilaçet. We used the Decision Tree classifier for this task.  Ne kemi treguar se përdorimi i disa hapash elementare të përprocesimit dhe TF-IDF n-gram çoi n ë performancë të pranueshme klasifikues. Në të vërtetë, rezultati F1 regjistruar ishte 74.58% në fazën e zhvillimit dhe 63.70% në fazën e testit.', 'am': 'ይህ ገጽ ሕዝባችን ማውሳትን ለመግለጽ በሐሳብ ለመግለጽ ትዊቶችን ይናገራል፡፡ ለዚህ ስራ የፍርድ ዛፍ ትክክል ነበር፡፡ እና TF-IDF n-gram (TF-IDF n-gram) የሚቀበል የፊደል ደረጃዎችን በመጠቀም አሳይተናል፡፡ በእውነት F1-score-recorded 74.58 በመቶ እውቀት ክፍለ ፍትወት 63.70 በመቶ ነበር።', 'az': 'Bu kağıt bizim sistemimizi təhsil edir ki, ilaçları söyləyən tweets seçmək üçün təhsil edilmişdir. Biz bu işin üçün karar ağacını seçdik. Biz göstərdik ki, bir neçə elemental ön işləmə adımların ı və TF-IDF n-gramlarını qəbul edəcək klasifikatçı performansını istifadə edərək. Əslində, F1 nöqtəsi yazılmış təhsil fəzində 74,58%-dir və test fəzində 63,70%-dir.', 'hy': 'Այս աշխատանքը նկարագրում է մեր համակարգը, որը ստեղծվել է թվիթերի ավտոմատ դասակարգելու համար, որոնք նշում են դեղամիջոցներ: Մենք օգտագործեցինք որոշումների ծառի դասակարգիչը այս խնդրի համար: Մենք ցույց տվեցինք, որ որոշ տարրական նախամշակման քայլեր և ԹՖ-IDF n-գրամ օգտագործելը հանգեցրեց ընդունելի դասակարգչի արդյունք: Իրականում F1-ի գնահատականը զարգացման դեպքում 74.58 տոկոսն էր, իսկ փորձարկումների դեպքում 63.70 տոկոսը:', 'hr': 'Ovaj papir opisuje naš sustav razvijen za automatsku klasifikaciju tweets koji spominju lijekove. Koristili smo klasifikator drveta odluke za ovaj zadatak. Pokazali smo da koristeći neke elementarne korake preobrađivanja i TF-IDF n-grame dovede do prihvatljivih klasifikacijskih učinka. Zapravo, zabilježeni rezultat F1 bio je 74,58% u razvojnoj fazi i 63,70% u testnoj fazi.', 'bn': 'এই পত্রিকা আমাদের সিস্টেমের উন্নয়নের ব্যাখ্যা করেছে স্বয়ংক্রিয়ভাবে টুইটের ব্যবহারের জন্য যা মেডিক আমরা এই কাজের জন্য সিদ্ধান্ত গাছ ব্যবহার করেছিলাম। আমরা দেখিয়েছি যে কিছু উপাদানের প্রেসিং পদক্ষেপ ব্যবহার করে এবং TF-IDF n-গ্রাম ব্যবহার করে গ্রহণযোগ্য ক্লাসিফারের সত্যিই, এফ১ স্কোর রেকর্ড করা হয়েছে উন্নয়ন পর্যায়ের ৭৪.৫৮% এবং পরীক্ষা পরীক্ষায় ৬৩.৭০% রয়েছে।', 'bs': 'Ovaj papir opisuje naš sistem razvijen za automatsku klasifikaciju tweets koji spominju lijekove. Koristili smo klasifikator drveta odluke za ovaj zadatak. Pokazali smo da koristeći neke elementarne korake preobrađivanja i TF-IDF n-grame dovede do prihvatljivih klasifikacijskih učinka. Zapravo, zabilježeni rezultat F1 bio je 74,58% u razvojnoj fazi i 63,70% u testnoj fazi.', 'ca': 'Aquest article descriu el nostre sistema desenvolupat per classificar automàticament tweets que mencionen medicaments. Vam utilitzar el classificador Decisions Tree per aquesta tasca. Hem demostrat que utilitzar algunes etapes elementars de preprocessió i n-grams TF-IDF van portar a un rendiment de classificador acceptable. De fet, la puntuació F1 registrada va ser del 74,58% en la fase de desenvolupament i del 63,70% en la fase de prova.', 'cs': 'Tento článek popisuje náš systém vyvinutý pro automatickou klasifikaci tweetů, které zmiňují léky. Pro tento úkol jsme použili klasifikátor stromu rozhodování. Ukázali jsme, že použití některých elementárních kroků předzpracování a TF-IDF n-gramů vedlo k přijatelnému výkonu klasifikátoru. Zaznamenané skóre F1 bylo skutečně 74,58% ve fázi vývoje a 63,70% ve fázi testu.', 'et': 'Käesolevas artiklis kirjeldatakse meie süsteemi, mis on välja töötatud automaatseks klassifitseerimiseks säutsud, mis mainivad ravimeid. Selle ülesande jaoks kasutasime otsustuspuu klassifitseerijat. Oleme näidanud, et mõned elementaarsed eeltöötluse etapid ja TF-IDF n-grammid viisid vastuvõetava klassifikaatori jõudluseni. F1-skoor oli arengufaasis 74,58% ja katsetamisefaasis 63,70%.', 'fi': 'Tässä artikkelissa kuvataan järjestelmäämme, joka on kehitetty automaattisesti luokittelemaan lääkkeitä sisältävät tweetit. Tähän tehtävään käytimme päätöspuun luokitusta. Olemme osoittaneet, että joidenkin alkeellisten esikäsittelyvaiheiden ja TF-IDF n-grammien käyttö johti hyväksyttävään luokituksen suorituskykyyn. F1-pisteet olivat kehitysvaiheessa 74,58% ja testivaiheessa 63,70%.', 'ha': "Wannan takardan na bayyana na tsarin na'urarmu wanda aka buɗe na kafin da farat-ƙarai, na fassarar da littattafai da ke faɗa madaidaici. Kuma Muka ƙaddara itãciyar nan a kankana. Mun n ũna cewa, da za'a yi amfani da wasu hanyõyin pre-aiki da na TF-IDF n-gram na haɗi da fasafar mai haɗuwa. Ga gaske, F1-score aka rubuta shi ne 74.58% cikin fasa na tsumarni kuma 63.70% a cikin jarraba.", 'sk': 'Ta članek opisuje naš sistem, razvit za samodejno razvrščanje tweetov, ki omenjajo zdravila. Za to opravilo smo uporabili klasifikator Drevesa odločitev. Pokazali smo, da je uporaba nekaterih elementarnih korakov predobdelave in n-gramov TF-IDF privedla do sprejemljive učinkovitosti klasifikatorja. Zabeleženi rezultat F1 je bil 74,58% v razvojni fazi in 63,70% v preskusni fazi.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི་སྒྲིག་འགོད་དུ་རང་འགུལ་གྱིས་གླེང་སྒྲུབ་ཀྱི་གྲོང་རིམ ང་ཚོས་བྱ་བ་འདིའི་དོན་ལ་དབྱིབས་སྡོད་པ་ཞིག་བེད་སྤྱོད་ཀྱི་ཡོད། ང་ཚོས་ཀྱིས་རྣམ་པ་ལྟར་མཁན་གྱི་སྔོན་ལས་འགུལ་གྱི་གྲལ་རིམ་དང་TF-IDF་n-grams་བེད་སྤྱོད་བཞིན་པའི་ལྟ་བུ དངོས་གནས་སུ། F1 ཚིག་རྣམ་པས་ཡར་རྒྱས་འགྲོ་བཞིན་པའི་གནས་ཚད་ཀྱི་འགྱུར་མཚམས་དང་བརྟག་དཔྱད་འགྲོ་བཞིན་པའི་ཚད་ལྟར་བཞིན་པའི་འགྱུ', 'he': 'This paper describes our system developed for automatically classifying tweets that mention medications.  We used the Decision Tree classifier for this task.  הראינו שהשימוש בצעדים פרופסוסים יסודיים ו-TF-IDF n-גרם הוביל לביצוע מסווג מקובל. למעשה, הציון F1 שנקלט היה 74.58% בשלב הפיתוח ו-63.70% בשלב הבדיקה.', 'jv': 'Perintah iki dipoleh sistem sing diowasi nggawe kanggo nyelarane tentang mrogram kuwi bagian sing nyimpen. tasklist section Lah, F1 dadi nyong wektu, 75.'}
{'en': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets? Use RoBERTa R o BERT a', 'fr': 'Vous souhaitez identifier, extraire et normaliser les effets indésirables des médicaments dans les tweets\xa0? Utilisez Roberta', 'es': '¿Quiere identificar, extraer y normalizar las reacciones adversas a los medicamentos en los tuits? Usar RoBerta', 'hi': 'Tweets में प्रतिकूल दवा प्रतिक्रियाओं की पहचान, निकालें और सामान्य करना चाहते हैं? RoBERTa का उपयोग करें', 'ar': 'هل تريد تحديد التفاعلات الضارة مع الأدوية واستخراجها وتطبيعها في التغريدات؟ استخدم RoBERTa', 'zh': '欲知取法推文中药不良反应? 用罗伯塔', 'pt': 'Quer identificar, extrair e normalizar reações adversas a medicamentos em tweets? Usar RoBERTa', 'ja': 'ツイートで薬物の有害反応を特定し、抽出し、正常化したいですか？ RoBERTaを使用してください', 'ru': 'Хотите выявить, извлечь и нормализовать нежелательные лекарственные реакции в твитах? Используйте RoBERTa', 'ga': 'Ar mhaith leat Frithghníomhartha díobhálacha Drugaí in Tweetanna a Aithint, a Bhaint agus a Normalú? Úsáid RoBERTa', 'el': 'Θέλετε να εντοπίσετε, να εξαγάγετε και να κανονικοποιήσετε τις ανεπιθύμητες αντιδράσεις φαρμάκων στα tweets; Χρήση RoBERTa', 'hu': 'Szeretné azonosítani, kivonni és normalizálni a mellékhatásokat Tweetekben? A RoBERTa alkalmazása', 'kk': 'Твиттерде қарсы наркот реакцияларын анықтау, тарқату және нормализациялау керек пе? RoBERTa қолданылсын', 'it': 'Vuoi identificare, estrarre e normalizzare le reazioni avverse alla droga nei tweet? Usa RoBERTa', 'lt': 'Ar norite nustatyti, ištraukti ir normalizuoti nepageidaujamas vaisto reakcijas Tweetuose? Vartoti RoBERTa', 'ka': 'გსურთ იდენტიფიკაცია, ექსტრაქტირება და ნორმალიზაცია შესაძლებელი პროგრამების რეაქციაში? RoBERTa- ს გამოყენება', 'ms': 'Ingin Mengenalpasti, Ekstrak dan Normalkan Reaksi Darah dadah dalam Tweet? Guna RoBERTa', 'mk': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  Користи RoBERTa', 'no': 'Vil du identifisera, pakka ut og normalisera motsetjingar i Tweets? Bruk RoBERTa', 'mn': 'Твитт дээр эсрэг нарийн урвалыг тайлбарлах, татаж, нормализах уу? RoBERTa хэрэглэх', 'ro': 'Doriți să identificați, extrageți și normalizați reacțiile adverse la medicamente în Tweets? Utilizați RoBERTa', 'sr': 'Želite li identifikovati, izvaditi i normalizirati nuspojavne reakcije droge u Tweets-u? Koristi RoBERTa', 'ml': 'ടൂട്ടുകളില്\u200d മയക്കുമരുന്നുള്ള പ്രതികരണങ്ങള്\u200d തിരിച്ചറിയാന്\u200d, പുറത്താക്കി നോര്\u200dമാലിസ് ചെയ്യണമോ? റോബെര്\u200dട്ട ഉപയോഗിക്കുക', 'mt': 'Tixtieq tidentifika, Estratta u Normalizza Reazzjonijiet Avversi tal-Mediċina fit-Tweets? Uża RoBERTa', 'si': 'ට්විට්ස් වල ප්\u200dරතික්\u200dරියාව අඳිශ්නය, නික්\u200dරියාත්මක සහ සාමාන්\u200dයය කරන්න ඕනද? RoBERTa භාවිතා කරන්න', 'sv': 'Vill du identifiera, extrahera och normalisera biverkningar i Tweets? Använd RoBERTa', 'ta': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  RoBERTAயை பயன்படுத்து', 'pl': 'Chcesz zidentyfikować, wyciągnąć i normalizować działania niepożądane w tweetach? Użyj RoBERTa', 'so': 'Ma rabtid in aad Tweet ka aqoonsato, soo saaro iyo Normalize jawaabayaasha dawooyinka? Isticmaal RoBERta', 'ur': 'کیا ٹویٹوں میں مخالف ڈراگ رکنٹیوں کو پہچان کرنا، نکالنا اور عامل کرنا چاہتے ہیں؟ روبرٹا استعمال کریں', 'vi': 'Có muốn xác định phản ứng phản ứng phản ứng phản ứng phản ứng đỏ trong Tweet không? Dùng RoBERTa', 'uz': 'Twitterda davom etishni aniqlashni istaysizmi, olib tashlashni istaysizmi? RoBERTAdan foydalanish', 'hr': 'Želite li identificirati, izvući i normalizirati nuspojavne reakcije droge u Tweets-u? Koristi RoBERTa', 'da': 'Vil du identificere, udtrække og normalisere bivirkninger i Tweets? Brug RoBERTa', 'nl': 'Wil je bijwerkingen in Tweets identificeren, extraheren en normaliseren? RoBERTa gebruiken', 'ko': '추문에서 약물의 불량 반응을 식별하고 추출하며 규범화하고 싶습니까?로베르타 사용하기', 'bg': 'Искате ли да идентифицирате, извлечете и нормализирате нежеланите лекарствени реакции в Туитс? Използване на RoBERTa', 'sw': 'Je, unataka kutambua, kutengeneza na kuzuia maoni yanayotokea madawa katika twita? Tumia RoBERTa', 'de': 'Möchten Sie unerwünschte Arzneimittelwirkungen in Tweets identifizieren, extrahieren und normalisieren? RoBERTa verwenden', 'id': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  Use RoBERTa', 'sq': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  Use RoBERTa', 'fa': 'می\u200cخواهید واکنش\u200cهای مخالف مواد توئیت\u200cها را شناسایی، خارج و عامل کنید؟ استفاده از RoBERTa', 'hy': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  Օգտագործել', 'az': 'Tweets i√ßind…ô t…ôdbir uyuŇüturucu reaksiyonlarńĪnńĪ tanńĪtmaq, √ßńĪxartmaq v…ô normal etm…ôk ist…ôyirsiniz? RoBERTa qullan', 'tr': 'Tweets içinde naçan narkotik reaksiyonlary tanap, açmak we düzenlemek isleýärmi? RoBERTa ullan', 'bn': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  RoBERTA ব্যবহার করো', 'ca': 'Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets?  Use RoBERTa', 'af': 'Wil jy identifiseer, uitpak en Normaliseer Adverse Drugsreaksies in Tweets? Gebruik RoBERTa', 'cs': 'Chcete identifikovat, extrahovat a normalizovat nežádoucí léčivé účinky ve tweetech? Použít RoBERTa', 'am': 'በTweet መግለጫ፣ ማውጣት እና ማውጣት ይፈልጋሉ? RoBERTAን ተጠቀም', 'fi': 'Haluatko tunnistaa, purkaa ja normalisoida haittavaikutukset Tweets? Käytä RoBERTaa', 'bs': 'Želite li identificirati, izvući i normalizirati nuspojavne reakcije droge u Tweets-u? Koristi RoBERTa', 'et': 'Soovite tuvastada, ekstraheerida ja normaliseerida kõrvaltoimeid Tweets? RoBERTa kasutamine', 'jv': 'Opo kowe gelem menehi, dibujuhi lan njujuhi Keterarangke Nari Rasane Nang Tuwit ? Ngawe RBERT', 'ha': 'Yana son ka gane, ka fita kuma ka ƙayyade Ciki-Madaidaici na Kwamfyuta? Yi amfani da RoBERTA', 'sk': 'Želite prepoznati, izvleči in normalizirati neželene učinke zdravil v Tweets? Uporabi RoBERTa', 'he': 'רוצה לזהות, להוציא ולנורמליז תגובות תרופות לא רצויות בטוויטים? השתמש ברוברטה', 'bo': 'Tweets་ནང་དུ་འཕགས་རིས་མཐུན་བཟོ་བྱེད་མི་འདུག་གམ RoBERTa སྤྱོད་པ'}
{'en': 'This paper presents our approach for task 2 and task 3 of Social Media Mining for Health (SMM4H) 2020 shared tasks. In task 2, we have to differentiate adverse drug reaction (ADR) tweets from nonADR tweets and is treated as  binary classification . Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes. Extracting ADR mentions is treated as sequence labeling and normalizing ADR mentions is treated as multi-class classification. Our system is based on pre-trained language model RoBERTa and it achieves a) F1-score of 58 % in task 2 which is 12 % more than the average score b) relaxed F1-score of 70.1 % in ADR extraction of task 3 which is 13.7 % more than the average score and relaxed F1-score of 35 % in ADR extraction + normalization of task 3 which is 5.8 % more than the average score. Overall, our  models  achieve promising results in both the  tasks  with significant improvements over average scores.', 'es': 'Este documento presenta nuestro enfoque para las tareas 2 y 3 de las tareas compartidas de Social Media Mining for Health (SMM4H) 2020. En la tarea 2, tenemos que diferenciar los tuits de reacciones adversas a medicamentos (ADR) de los tuits que no son ADR y se trata como clasificación binaria. La tarea 3 consiste en extraer menciones de ADR y luego asignarlas a los códigos de MedDRA. La extracción de menciones de ADR se trata como un marcaje de secuencia y la normalización de las menciones de ADR se trata como Nuestro sistema se basa en el modelo lingüístico RoBerta previamente entrenado y logra a) una puntuación F1 del 58% en la tarea 2, que es un 12% más que la puntuación media b) una puntuación F1 relajada del 70,1% en la extracción ADR de la tarea 3, que es un 13,7% más que la puntuación media y una puntuación F1 relajada del 35% en la extracción ADR + normalización de la tarea 3, lo que supone un 5,8% más que la puntuación media. En general, nuestros modelos logran resultados prometedores en ambas tareas con mejoras significativas con respecto a los puntajes promedio.', 'ar': 'تقدم هذه الورقة نهجنا للمهمة 2 والمهمة 3 الخاصة بالتعدين على وسائل التواصل الاجتماعي من أجل الصحة (SMM4H) 2020 المهام المشتركة. في المهمة 2 ، يتعين علينا التفريق بين تغريدات التفاعلات العكسية للأدوية (ADR) والتغريدات التي لا تحتوي على نتائج (nonADR) ويتم التعامل معها على أنها تصنيف ثنائي. تتضمن المهمة 3 استخراج إشارات ADR ثم تعيينها إلى رموز MedDRA. يتم التعامل مع استخلاص إشارات ADR على أنها تصنيف تسلسل ويتم التعامل مع تسوية إشارات ADR على أنها تصنيف متعدد الفئات. يعتمد نظامنا على نموذج اللغة RoBERTa الذي تم تدريبه مسبقًا ويحقق أ) درجة F1 بنسبة 58٪ في المهمة 2 والتي تزيد بنسبة 12٪ عن متوسط الدرجة ب) درجة F1 المريحة بنسبة 70.1٪ في استخلاص ADR للمهمة 3 والتي هي 13.7٪ أكثر من متوسط الدرجات ودرجة F1 المخففة بنسبة 35٪ في استخراج ADR + تطبيع المهمة 3 وهو 5.8٪ أكثر من متوسط الدرجة. بشكل عام ، تحقق نماذجنا نتائج واعدة في كلتا المهمتين مع تحسينات كبيرة على متوسط الدرجات.', 'pt': 'Este artigo apresenta nossa abordagem para as tarefas 2 e 3 das tarefas compartilhadas de Social Media Mining for Health (SMM4H) 2020. Na tarefa 2, temos que diferenciar tweets de reação adversa a medicamentos (RAM) de tweets sem RAM e é tratado como classificação binária. A tarefa 3 envolve extrair menções de ADR e depois mapeá-las para códigos MedDRA. A extração de menções de ADR é tratada como rotulagem de sequência e a normalização de menções de ADR é tratada como classificação multiclasse. Nosso sistema é baseado no modelo de linguagem pré-treinado RoBERTa e atinge a) F1-score de 58% na tarefa 2, que é 12% a mais que a pontuação média b) F1-score relaxado de 70,1% na extração de ADR da tarefa 3, que é 13,7% a mais que a pontuação média e F1-score relaxado de 35% na extração de RAM + normalização da tarefa 3 que é 5,8% a mais que a pontuação média. No geral, nossos modelos alcançam resultados promissores em ambas as tarefas com melhorias significativas em relação às pontuações médias.', 'fr': "Cet article présente notre approche pour les tâches 2 et 3 des tâches partagées Social Media Mining for Health (SMM4H) 2020. Dans la tâche 2, nous devons différencier les tweets d'effets indésirables d'un médicament (EIM) des tweets non-ADR et nous sommes traités comme une classification binaire. La tâche 3 consiste à extraire les mentions ADR, puis à les mapper aux codes MedDRA. L'extraction des mentions ADR est traitée comme un étiquetage de séquence et la normalisation des mentions ADR est traitée comme une classification multi-classes. Notre système est basé sur le modèle linguistique pré-entraîné Roberta et il atteint a) un score F1 de 58\xa0% dans la tâche 2, soit 12\xa0% de plus que le score moyen b) un score F1 assoupli de 70,1\xa0% dans l'extraction ADR de la tâche 3, soit 13,7\xa0% de plus que le score moyen et un score F1 relâché de 35\xa0% dans l'extraction ADR + normalisation de la tâche 3, soit 5,8\xa0% de plus que la note moyenne. Dans l'ensemble, nos modèles obtiennent des résultats prometteurs dans les deux tâches avec des améliorations significatives par rapport aux scores moyens.", 'ja': '本稿では、2020年のソーシャルメディアマイニング・フォー・ヘルス（ SMM 4 H ）の共有タスクのタスク2とタスク3に対する当社のアプローチを紹介します。タスク2では、有害薬物反応（ ADR ）ツイートを非ADRツイートと区別する必要があり、バイナリ分類として扱われます。タスク3では、ADRの言及を抽出し、それをMedDRAコードにマッピングします。ADR言及の抽出は配列標識として扱われ、ADR言及の正規化はマルチクラス分類として扱われる。私たちのシステムは、事前にトレーニングされた言語モデルRoBERTaに基づいており、a ）タスク2のF 1スコアは、平均スコアよりも12 ％高い58 ％、b ）タスク3のADR抽出の緩和されたF 1スコアは、平均スコアよりも13.7 ％高い70.1 ％、ADR抽出の緩和されたF 1スコアは、平均スコアよりも5.8 ％高い35 ％+タスク3の正規化を達成します。全体として、当社のモデルは、平均スコアよりも大幅に改善された両方のタスクで有望な結果を達成します。', 'zh': '本文言吾法,施于2020年社交媒体康发掘(SMM4H)共享其任2与任3。 务2之中,必别药物不良反应(ADR)推文非ADR推文,视为二元。 任 3 及取 ADR ,然后射于 MedDRA 代码。 提ADR提及为序标记,归一化ADR提及为多类。 臣等之统,先训之RoBERTa,其成a)务2中F1分为58%,高于均分12% b)于任3者ADR取中放F1分为70.1%,高于均分13.7%,于ADR取中放F1分为35%+务3之标准化,高于均分数5.8%。 总体而言,吾两务皆有所欲,而显于均分矣。', 'hi': 'यह पेपर स्वास्थ्य के लिए सोशल मीडिया माइनिंग (SMM4H) 2020 साझा कार्यों के कार्य 2 और कार्य 3 के लिए हमारे दृष्टिकोण को प्रस्तुत करता है। कार्य 2 में, हमें गैर-एडीआर ट्वीट्स से प्रतिकूल दवा प्रतिक्रिया (एडीआर) ट्वीट्स को अलग करना होगा और इसे बाइनरी वर्गीकरण के रूप में माना जाता है। कार्य 3 में एडीआर का उल्लेख निकालना और फिर उन्हें मेडड्रा कोड में मैप करना शामिल है। एडीआर उल्लेखों को निकालने को अनुक्रम लेबलिंग के रूप में माना जाता है और एडीआर उल्लेखों को सामान्य करने को बहु-वर्ग वर्गीकरण के रूप में माना जाता है। हमारी प्रणाली पूर्व प्रशिक्षित भाषा मॉडल RoBERTa पर आधारित है और यह एक) कार्य 2 में 58% का F1-स्कोर प्राप्त करता है जो औसत स्कोर से 12% अधिक है b) कार्य 3 के एडीआर निष्कर्षण में 70.1% का आराम से F1-स्कोर जो औसत स्कोर से 13.7% अधिक है और एडीआर निष्कर्षण में 35% का आराम से F1-स्कोर + कार्य 3 का सामान्यीकरण जो औसत स्कोर से 5.8% अधिक है। कुल मिलाकर, हमारे मॉडल औसत स्कोर पर महत्वपूर्ण सुधार के साथ दोनों कार्यों में आशाजनक परिणाम प्राप्त करते हैं।', 'ru': 'В данном документе представлен наш подход к задаче 2 и задаче 3 разделяемых задач Social Media Mining for Health (SMM4H) 2020. В задании 2 мы должны отличать твиты о нежелательных лекарственных реакциях (НЛР) от твитов без НЛР и рассматривать их как бинарную классификацию. Задача 3 включает извлечение упоминаний НЛР и их последующее сопоставление с кодами MedDRA. Извлечение упоминаний о НЛР рассматривается как маркировка последовательностей, а нормализация упоминаний о НЛР рассматривается как классификация по нескольким классам. Наша система основана на предварительно обученной языковой модели RoBERTa и достигает a) F1-балла 58% в задании 2, что на 12% больше среднего балла b) релаксированного F1-балла 70,1% при извлечении ADR задачи 3, что на 13,7% больше среднего балла и релаксированного F1-балла 35% при извлечении ADR + нормализация задачи 3, что на 5,8% больше среднего балла. В целом, наши модели достигают многообещающих результатов в обеих задачах со значительным улучшением по сравнению со средними баллами.', 'ga': 'Cuireann an páipéar seo i láthair ár gcur chuige do thasc 2 agus tasc 3 de thascanna comhroinnte Mianadóireacht ar na Meáin Shóisialta le haghaidh Sláinte (SMM4H) 2020. I dtasc 2, ní mór dúinn tvuíteanna frithghníomhartha díobhálacha drugaí (ADR) a idirdhealú ó thíogaireachtaí nonADR agus láimhseáiltear é mar aicmiú dénártha. Baineann Tasc 3 le tagairtí ADR a bhaint amach agus ansin iad a mhapáil chuig cóid MedDRA. Déileáiltear le hasbhaint tagairtí ADR mar lipéadú seichimh agus caitear le normalú tagairtí ADR mar aicmiú ilaicme. Tá ár gcóras bunaithe ar mhúnla teanga réamh-oilte RoBERTa agus éiríonn leis a) scór F1 de 58% i dtasc 2 atá 12% níos mó ná an meánscór b) scór F1 réchúiseach de 70.1% in eastóscadh ADR de thasc 3 a 13.7% níos mó ná an meánscór agus scór F1 réchúiseach de 35% in eastóscadh ADR + normalú thasc 3 atá 5.8% níos mó ná an meánscór. Tríd is tríd, baineann ár múnlaí torthaí dóchais amach sa dá thasc agus feabhsuithe suntasacha thar na meánscóir.', 'ka': 'ამ დოკუმენტი ჩვენი მოხმარება სოციალური მედიახის გარეშე (SMM4H) 2020-ის გარეშე საზოგადო დავალებისთვის და სამუშაო დავალებისთვის. მეორე დავალებში, ჩვენ უნდა განსხვავება განსაკუთრებული ნაპირო რექიცია (ADR) ტივიტებით nonADR ტივიტებით და უნდა იყოს ბინერი კლასიფიკაცია. სამუშაო სამუშაო შესახებ ADR შესახებ გამოყენება და შემდეგ შესახებ MedDRA კოდეების შესახებ. ADR ამოსახულებების გამოყენება როგორც წერტილის ამოსახულება და ADR ამოსახულებების ნორმალიზება მრავალკლასის კლასიფიკაციაში გამოყენება. ჩვენი სისტემა პროBERTa-ის წინასწარმოადგენული ენის მოდელზე დაბაზიან და ეს მიიღება a) პროცენტში 58% F1- score, რომელიც 12% უფრო მეტია პროცენტში b) პროცენტულია პროცენტში 70 ჩვენი მოდელები გავაკეთებენ, რომელიც ჩვენი მოდელები გავაკეთებენ საუკეთესო შესაძლებლობებით, რომლებიც საუკეთესო შესაძლებლობებით საშუალო', 'el': 'Η παρούσα εργασία παρουσιάζει την προσέγγισή μας για το έργο 2 και το έργο 3 της εξόρυξης κοινωνικών μέσων για την υγεία (ΜΜΧ) 2020 κοινών εργασιών. Στο έργο 2, πρέπει να διαφοροποιήσουμε τα tweets ανεπιθύμητων αντιδράσεων (ADR) από τα tweets μη ADR και αντιμετωπίζεται ως δυαδική ταξινόμηση. Η εργασία 3 περιλαμβάνει την εξαγωγή αναφορών ADR και στη συνέχεια την αντιστοίχισή τους στους κωδικούς MedDRA. Η εξαγωγή αναφορών ADR αντιμετωπίζεται ως σήμανση ακολουθίας και η ομαλοποίηση αναφορών ADR αντιμετωπίζεται ως ταξινόμηση πολλαπλών κατηγοριών. Το σύστημά μας βασίζεται στο προ-εκπαιδευμένο γλωσσικό μοντέλο και επιτυγχάνει α) βαθμολογία 58% στην εργασία 2 το οποίο είναι 12% μεγαλύτερο από το μέσο σκορ β) χαλαρή βαθμολογία F1 70,1% στην εξαγωγή εργασίας 3 η οποία είναι 13,7% μεγαλύτερη από το μέσο σκορ και χαλαρή βαθμολογία F1 35% στην εξαγωγή και ομαλοποίηση της εργασίας 3 η οποία είναι 5,8% μεγαλύτερη από το μέσο σκορ. Συνολικά, τα μοντέλα μας επιτυγχάνουν πολλά υποσχόμενα αποτελέσματα και στις δύο εργασίες με σημαντικές βελτιώσεις σε σχέση με τις μέσες βαθμολογίες.', 'hu': 'Ez a tanulmány bemutatja a Social Media Mining for Health (SMM4H) 2020 megosztott feladatainak 2. és 3. feladatát. A második feladatban meg kell különböztetnünk a mellékhatások (ADR) tweetjeit a nem ADR tweetektől, és ezeket bináris osztályozásként kezeljük. A harmadik feladat az ADR-említések kivonása, majd a MedDRA-kódokhoz történő leképezése. Az ADR említések kivonása sorozatcímkézésként kezelhető, az ADR említések normalizálását pedig többosztályos osztályozásként kezelik. Rendszerünk a RoBERTa előre képzett nyelvi modellre épül, és a) F1 pontszámot 58%-kal ér el a 2. feladatban, ami 12%-kal több, mint az átlagos pontszám b) lazított F1 pontszámot 70,1%-kal a 3. feladat ADR kivonása során, ami 13,7%-kal több, mint az átlagos pontszám és lazított F1 pontszámot 35%-kal az ADR kivonás során + a 3. feladat normalizálása során, ami 5,8%-kal több, mint az átlagos pontszám. Összességében modelleink ígéretes eredményeket érnek el mindkét feladatban, jelentős javulással az átlagos pontszámokhoz képest.', 'mk': 'Овој документ го претставува нашиот пристап за задачата 2 и задачата 3 на Социјалната медиумска минирање за здравје (СММ4Х) 2020 заеднички задачи. Во задачата 2, ние мораме да разликуваме негативни реакции на лековите (АДР) твитови од твитови без АДР и се третира како бинарна класификација. Работата 3 вклучува извлекување на спомените на АДР и потоа мапирање на кодовите на MedDRA. Екстрактирањето на спомените на АДР се третира како означување на секвенца и нормализацијата на спомените на АДР се третира како мултикласификација. Нашиот систем се базира на предобучен јазички модел RoBERTa и постигнува a) F1-оценка од 58% во задачата 2 што е 12% повеќе од просечната оценка b) релаксиран F1-оценка од 70,1% во АДР-екстракција на задачата 3 што е 13,7% повеќе од просечната оценка и релаксиран F1-оценка од 35% во АДР екстракција + нормализација на задачата 3 што е 5,8% повеќе од просечната оценка. Вкупно, нашите модели постигнуваат ветувачки резултати во двете задачи со значителни подобрувања во однос на просечните резултати.', 'ms': 'This paper presents our approach for task 2 and task 3 of Social Media Mining for Health (SMM4H) 2020 shared tasks.  Dalam tugas 2, kita perlu membezakan reaksi dadah negatif (ADR) tweet dari tweet bukan ADR dan dianggap sebagai klasifikasi binari. Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes.  Mengekstrak sebutan ADR dianggap sebagai label urutan dan normalisasi sebutan ADR dianggap sebagai klasifikasi kelas berbilang. Sistem kita berdasarkan model bahasa yang dilatih-dilatih RoBERTa dan ia mencapai a) skor-F1 58% dalam tugas 2 yang 12% lebih daripada skor rata-rata b) skor-F1 relaxed 70.1% dalam ekstraksi ADR tugas 3 yang 13.7% lebih daripada skor rata-rata dan skor-F1 relaxed 35% dalam ekstraksi ADR + normalisasi tugas 3 yang 5.8% lebih daripada skor rata-rata. Secara keseluruhan, model kita mencapai keputusan yang berjanji dalam kedua-dua tugas dengan peningkatan yang signifikan atas skor rata-rata.', 'ml': 'ഈ പത്രത്തില്\u200d സോഷ്യല്\u200d മീഡിയ മിനിങ്ങ് വേണ്ടി മൂന്ന് ജോലിക്കും നമ്മുടെ പ്രായോഗ്യം കാണിച്ചുകൊടുക്കുന്നു. 2020 പങ് ജോലി 2-ല്\u200d, നമുക്ക് വ്യത്യാസകരമായ മയക്കുമരുന്നുള്ള പ്രതികാരം വ്യത്യസ്തമാക്കേണ്ടതുണ്ട്, അഡേആര്\u200d ട്ടീറ്റുകളില്\u200d നിന്നും  ടാസ്ക് 3 എഡിആര്\u200d മെന്നറിയിപ്പുകള്\u200d പുറത്തെടുക്കുകയും പിന്നെ മെഡ്ഡിRA കോഡുകളിലേക്ക് മാപ്പ് ചെയ്യു ADR മെന്\u200dഷനുകള്\u200d പുറത്തെടുക്കുന്നത് സെക്കന്റ് ലേബിള്\u200d എന്നും സാധാരണമാക്കുന്ന ADR മെന്\u200dഷനുകള്\u200d പല-ക്ലാസ് ക്ലാസിഫിക് ഞങ്ങളുടെ സിസ്റ്റം മുന്\u200dപരിശീലന ഭാഷ മോഡല്\u200d റോബെര്\u200dട്ടാ അടിസ്ഥാനത്താണ്. ജോലിയില്\u200d 58% നേടുന്ന F1- സ്കോര്\u200d എത്തുന്നു. അത് 12% കൂടുതല്\u200d സാധാരണ സ്കോര്\u200d b നേടുന്നു) എഡ്ആര്\u200d പുറത്തെടുക്കുന്നതില്\u200d എഫ്1% സ്കോര്\u200d വിശാലമായിരുന്നു. അത് എഡി മൊത്തം, നമ്മുടെ മോഡലുകള്\u200d വാഗ്ദാനം ചെയ്യുന്ന രണ്ട് ജോലികള്\u200dക്കും നല്ല മെച്ചപ്പെടുത്തുന്നതാണ്.', 'it': "Questo articolo presenta il nostro approccio per il compito 2 e il compito 3 dei compiti condivisi Social Media Mining for Health (SMM4H) 2020. Nel compito 2, dobbiamo distinguere i tweet sulle reazioni avverse al farmaco (ADR) dai tweet non ADR ed è trattato come classificazione binaria. Il compito 3 consiste nell'estrarre le menzioni ADR e quindi mapparle ai codici MedDRA. Estrarre le menzioni ADR è trattata come etichettatura di sequenza e normalizzare le menzioni ADR è trattata come classificazione multi-classe. Il nostro sistema si basa sul modello linguistico pre-addestrato RoBERTa e raggiunge a) F1-score del 58% nel task 2 che è il 12% in più del punteggio medio b) F1-score rilassato del 70,1% nell'estrazione ADR del task 3 che è il 13,7% in più del punteggio medio e F1-score rilassato del 35% nell'estrazione ADR + normalizzazione del task 3 che è il 5,8% in più del punteggio medio. Nel complesso, i nostri modelli raggiungono risultati promettenti in entrambi i compiti con miglioramenti significativi rispetto ai punteggi medi.", 'mn': 'Энэ цаас нийгмийн Media Mining for Health (SMM4H) 2020 оны хуваалцааны ажил 2 дахь ажил болон 3 даалгаварын талаар биднийг харуулдаг. 2-р ажил дээр бид эсрэг эм урвалыг (АДР) нь ДОХР биш tweets-ээс ялгаалж, хоёр дахь хуваалтын хуваалтыг харьцуулах хэрэгтэй. 3 даалгавар нь ДОХ-ын хэлэлцээг гаргаж, дараа нь MedDRA кодын зурагт зурагтай. ДОХ-ын нэр тодорхойлолтуудыг дарааллын тэмдэглэл гэж үздэг ба ДОХ-ын нэр тодорхойлолтуудыг олон ангид хэлбэртэй гэж үздэг. Бидний систем RoBERTa-ын өмнө сургалтын хэл загвар дээр суурилсан бөгөөд энэ нь a) 2 даалгаварын F1-тоо 58%-той байдаг бөгөөд энэ нь дундаж оноос 12%-аас илүү b) даалгавартай F1-тоо 70.1% байдаг бөгөөд энэ нь дундаж оноос 13.7% байдаг бөгөөд ADR 3 дахь даалгавартай F1-тоо 35%-аас илүү байдаг бөгөөд энэ нь дундаж оноос 5.8% байдаг бөгөөд Ихэнхдээ бидний загварууд дундаж оноо дээр маш чухал сайжруулах үйл ажиллагаанд амлалтай үр дүнг гаргадаг.', 'no': 'Denne papiret viser tilnærminga vårt for oppgåve 2 og oppgåve 3 på den delte oppgåva i sosiale mediaminering for helse (SMM4H) 2020. I oppgåve 2 må vi forskjellere negativt narkotikarelateksjon (ADR) frå nonADR-tweets og behandla som binærklassifikasjon. Oppgåve 3 inneheld å pakka ut ADR-mengdar og så kartera dei til MedDRA-kodar. Då pakka ut ADR- omsetjingar vert behandlet som sekvensmerkelapp og normaliserer ADR- omsetjingar vert behandlet som multiklassesklassifikasjon. Sistemet vårt er basert på føretrained språk- modellen RoBERTa, og det oppnår a) F1- poeng med 58% i oppgåve 2, som er 12% meir enn gjennomsnittlig poeng b) relaksert F1- poeng med 70, 1% i ADR- utpakking av oppgåve 3, som er 13, 7% meir enn gjennomsnittlig poeng og relaksert F1- poeng med 35% i ADR- utpakking + normalisering av oppgåve 3 som er 5, 8% meir enn gjennomsnittlig poeng. Generelt, våre modeller når det gjelder alvorleg resultatet i begge oppgåver med betydelige forbedringar over gjennomsnittsverdiar.', 'lt': 'Šiame dokumente pristatomas mūsų požiūris į 2 užduotį ir 3 užduotį „Socialinės žiniasklaidos kasyba sveikatos labui“ (SMM4H) 2020 m. bendras užduotis. 2 užduotyje turime atskirti nepageidaujamą vaisto reakciją (ADR) nuo ne ADR tweetų ir ją vertinti kaip dvigubą klasifikaciją. 3 užduotis apima ADR paminėjimų ištraukimą, o vėliau jų mapavimą pagal MedDRA kodus. Extracting ADR mentions is treated as sequence labeling and normalizing ADR mentions is treated as multi-class classification.  Mūsų sistema grindžiama iš anksto parengtu kalbos modeliu RoBERTa ir ji pasiekia a) F1 tašką 58% 2 užduotyje, kuris yra 12% didesnis už vidutinį tašką b) atpalaiduotą F1 tašką 70,1% 3 užduoties ADR ekstrakcijoje, kuris yra 13,7% didesnis už vidutinį tašką ir atpalaiduotą F1 tašką 35% ADR ekstrakcijoje + 3 užduoties normalizavimą, kuris yra 5,8% didesnis už vidutinį tašką. Apskritai mūsų modeliai pasiekia pažadėtinų rezultatų abiejose užduotyse, o vidutiniai rezultatai gerokai pagerėja.', 'kk': 'Бұл қағаз 2020 жылы ортақ тапсырмалар үшін 2- тапсырма және 3- тапсырманың социалдық медиа балау баласы (SMM4H) балаларының тәсілімізді көрсетеді. 2- тапсырмасында қарсы наркотикалық реакциясын (ADR) бақылау керек. ДОПР-тың tweets- тізбектерінен түрлену керек және бинарлық классификациясы ретінде қатынау керек. 3- тапсырма ADR мәліметтерді тарқату және оны MedDRA кодтарына картап беру үшін болады. ADR мәліметтерді тарқату реттеу жарлығы ретінде қалады және ADR мәліметтерді көп класс классификациясы ретінде қалады. Біздің жүйеміз RoBERTa тіл моделіне негізделген, 2- тапсырмада 58% деген F1- нүктесі, бұл 12% деген орташа нүктесінен артық b) 3- тапсырманың ADR тарқатуында 70, 1% деген F1- нүктесі, ол орташа нүктесінен артық 13, 7% деген және 35% деген F1- нүктесі, ADR тарқатуында + 3- тапсырманың нормализациясы Біздің үлгілеріміз орташа нәтижелерден артық жақсарту үшін әлемді тапсырмалардың екеуінде болатын нәтижелерін жеткізеді.', 'pl': 'Niniejszy artykuł przedstawia nasze podejście do zadań wspólnych zadań 2 i zadań 3 Social Media Mining for Health (SMM4H) 2020. W zadaniu 2 musimy odróżnić tweety dotyczące reakcji niepożądanych leków (ADR) od tweetów nieADR i jest traktowane jako klasyfikacja binarna. Zadanie 3 polega na wyodrębnieniu wzmianek ADR, a następnie na mapowaniu ich do kodów MedDRA. Wyciąganie wzmianek ADR traktowane jest jako etykietowanie sekwencji, a normalizacja wzmianek ADR traktowana jest jako klasyfikacja wieloklasowa. Nasz system oparty jest na wstępnie przeszkolonym modelu językowym RoBERTa i osiąga a) wynik F1 58% w zadaniu 2 który jest 12% większy niż średni wynik b) złagodzony wynik F1 70,1% w ekstrakcji ADR zadania 3 który jest 13,7% większy niż średni wynik i złagodzony wynik F1 35% w ekstrakcji ADR oraz normalizację zadania 3, który jest 5,8% większy niż średni wynik. Ogólnie rzecz biorąc, nasze modele osiągają obiecujące rezultaty w obu zadaniach ze znaczną poprawą nad średnimi wynikami.', 'si': 'මේ පත්තුවේ අපේ වැඩේ දෙවෙනි වැඩේ සමාජික මිඩියාව ස්වාස්ථ්\u200dය විධානය (SMM4H) 2020ක් වැඩි වැඩේ තියෙනවා. 2 වැඩේ අපිට විරුද්ධ ව්\u200dයාප්\u200dතික ප්\u200dරතික්\u200dරියාව (ADR) නොADR ටුයිට් වලින් වෙනස් කරන්න වෙනවා ඒ වගේම බායිනාර් විශේෂණ වැඩ 3යි ADR කිරීම් නිර්මාණය කරලා ඒවා MedDRA කෝඩ් වලට සැකසුම් කරලා තියෙනවා. Name අපේ පද්ධතිය ප්\u200dරීක්ෂණිත භාෂාව ප්\u200dරමාණය RoBERTa වලට අධිරූපය වෙලා තියෙන්නේ. ඒ වගේම ඒක සාමාන්\u200dය ස්කෝර් 2 වල F1- ස්කෝර් 58% තියෙන්නේ. ඒක 12% වඩා සාමාන්\u200dය ස්කෝර් b) සාමාන්\u200dය ස්කෝර් 3 වල F1- ස්කෝර් 70.1% ත සාමාන්\u200dයයෙන්, අපේ මොඩල් එක්ක පොරොන්දු වෙනුවෙන් ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් ලැබෙනවා සාම', 'so': 'Qoraalkan wuxuu soo saaraa qaabilaada shaqada 2 iyo shaqada 3 ee maareynta caafimaadka sooshalka (SMM4H) 2020 oo shaqada la qaybsaday. Shaqada 2 waa in aan ka kala soocno dib u yeelashada daawooyinka (ADR) tweetka oo aan aheyn adigoo isticmaalaya labaad. Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes.  Macluumaadka ka soo bixinta ADR waxaa loola dhaqdhaqaaqaaqaa sida tababarida iyo si caadi ah oo lagu qorayo macluumaadka ADR lagu qoro fasalka kala duduwan. Sirkayada waxaa ku saleysan qaababka afka hore ee RoBERta, waxayna gaadhaa (a) Shaqo-F1-score 58 oo ka badan 12% oo qiimaha dhexe b) waxay qabsatay F1-score 70.1% oo ka badnaan iskuulka shaqada 3, taasoo ah 13.7 % oo ka badnaan kooxda ugu dhexeeya 35% ee ADR extraction + normalization shaqo 3 oo ka badan 5.8% qiimaha ugu dhexeeya. Sida caadiga ah modelalkayagu waxay heli karaan sabab ballan ah labadooda shaqaalaha lagu sameeyo horumar badan oo ka kordhiya qiimaha guud.', 'mt': 'Dan id-dokument jippreżenta l-approċċ tagħna għall-kompitu 2 u l-kompitu 3 tal-Minjieri tal-Midja Soċjali għas-Saħħa (SMM4H) 2020. Fit-tieni kompitu, irridu niddifferenzjaw it-tweets tar-reazzjoni avversa tal-mediċina (ADR) minn tweets mhux ADR u huwa ttrattat bħala klassifikazzjoni binarja. Il-kompitu 3 jinvolvi l-estrazzjoni tas-semmijiet tal-ADR u mbagħad l-immappjar tagħhom għall-kodiċijiet MedDRA. L-estrazzjoni tas-semmijiet tal-ADR hija ttrattata bħala tikkettar tas-sekwenza u s-semmijiet normalizzanti tal-ADR huma ttrattati bħala klassifikazzjoni ta’ diversi klassijiet. Is-sistema tagħna hija b b a żata fuq mudell lingwistiku mħarreġ minn qabel RoBERTa u tilħaq a) punteġġ F1 ta’ 58% fil-kompitu 2 li huwa 12% aktar mill-punteġġ medju b) punteġġ F1 rilassat ta’ 70.1% fl-estrazzjoni ADR tal-kompitu 3 li huwa 13.7% aktar mill-punteġġ medju u punteġġ F1 rilassat ta’ 35% fl-estrazzjoni ADR + normalizzazzjoni tal-kompitu 3 li huwa 5.8% aktar mill-punteġġ medju. Overall, our models achieve promising results in both the tasks with significant improvements over average scores.', 'sr': 'Ovaj papir predstavlja naš pristup zadatku 2 i zadatku 3 delovanja rudarstva socijalnih medija za zdravlje (SMM4H) 2020. U zadatku 2, moramo diferencirati tujtove protiv nuspojave (ADR) od tweets bez ADR-a i tretirati se kao binarna klasifikacija. Task 3 uključuje izvlačenje spomena ADR-a i mapiranje ih na MedDRA kodove. Ekstrakcija spomena ADR-a se tretira kao etiketiranje sekvencija i normalizacija spomena ADR-a se tretira kao klasifikacija multiklasa. Naš sistem je baziran na predobučenom jezičkom modelu RoBERTa i postiže a) F1 rezultat od 58% u zadatku 2 koji je 12% više od prosječnog rezultata b) opušteni F1 rezultat od 70,1% u izvlačenju zadatka 3 ADR koji je 13,7% više od prosječnog rezultata i opuštenog F1 rezultata od 35% u izvlačenju ADR + normalizaciju zadatka 3 koji je 5,8% više od prosječnog rezultata. U svemu, naši modeli postignu obećavajuće rezultate u oba zadatka sa značajnim poboljšanjem preko prosječnih rezultata.', 'ur': 'This paper presents our approach for task 2 and task 3 of Social Media Mining for Health (SMM4H) 2020 shared tasks. ٹوئیٹ 2 میں ہم کو مخالف مخالف ڈراگر واکنش (ADR) ٹویٹوں سے متفرق کرنا ضروری ہے اور ان کو دوبارہ کلاسیفوں کے طور پر سمجھا جاتا ہے۔ Task 3 includes extracting ADR mentions and then mapping them to MedDRA codes. ADR مذہروں کو اٹھانے کا ذریعہ سطح لیبلینگ اور ADR مذہروں کو عامل کرنا multi-class classification کے طور پر سمجھا جاتا ہے. ہماری سیستم پہلے تدریس کی زبان موڈل RoBERTa پر بنیاد ہے اور یہ کام 2 میں 58% کی F1-score پہنچتی ہے جو عمومی اسکور (b) سے 12% زیادہ ہے۔ اور ہمارے مدلکوں کو دوسرے کاموں میں وعدہ دینے والی نتیجے پہنچ رہے ہیں جن کے ذریعہ عمدہ اسکور پر اضافہ ہے۔', 'ro': 'Această lucrare prezintă abordarea noastră pentru sarcinile 2 și 3 ale Social Media Mining for Health (SMM4H) 2020. În sarcina 2, trebuie să diferențiem tweeturile reacțiilor adverse la medicament (ADR) de tweeturile non-ADR și sunt tratate ca clasificare binară. Sarcina 3 implică extragerea mențiunilor ADR și apoi maparea lor la codurile MedDRA. Extragerea mențiunilor ADR este tratată ca etichetare secvențială și normalizarea mențiunilor ADR este tratată ca clasificare multiclasă. Sistemul nostru se bazează pe modelul lingvistic pre-instruit RoBERTa și obține a) scorul F1 de 58% în sarcina 2, care este cu 12% mai mult decât scorul mediu b) scorul F1 relaxat de 70,1% în extracția ADR a sarcinii 3, care este cu 13,7% mai mult decât scorul mediu și scorul F1 relaxat de 35% în extracția ADR + normalizarea sarcinii 3, care este cu 5,8% mai mult decât scorul mediu. În general, modelele noastre obțin rezultate promițătoare în ambele sarcini, cu îmbunătățiri semnificative față de scorurile medii.', 'sv': 'Denna uppsats presenterar vårt tillvägagångssätt för uppgift 2 och uppgift 3 i Social Media Mining for Health (SMM4H) 2020 delade uppgifter. I uppgift 2 måste vi skilja på ADR-tweets från icke-ADR-tweets och behandlas som binär klassificering. Uppgift 3 innebär att extrahera ADR-omnämnanden och sedan kartlägga dem till MedDRA-koder. Uttagning av ADR-omnämnanden behandlas som sekvensmärkning och normalisering av ADR-omnämnanden behandlas som flerklassklassificering. Vårt system är baserat på färdigutbildad språkmodell RoBERTa och uppnår a) F1-poäng på 58% i uppgift 2 vilket är 12% mer än genomsnittspoängen b) avslappnad F1-poäng på 70,1% i ADR extraktion av uppgift 3 vilket är 13,7% mer än genomsnittspoängen och avslappnad F1-poäng på 35% i ADR extraktion + normalisering av uppgift 3 som är 5,8% mer än genomsnittspoängen. Sammantaget uppnår våra modeller lovande resultat i båda uppgifterna med betydande förbättringar jämfört med genomsnittet.', 'ta': 'இந்த தாள் எங்கள் செயல் 2 மற்றும் செயல் 3 என்று கூறுகிறது சாலிக ஊடகங்களின் சிகிச்சையை (SMM4H) 2020 பகிர்ந்த பணிகள். செயல் 2, நாம் வேறுபடுத்த வேண்டும் எதிர்மறை மருந்து விகிதத்தை (ADR) தொடர்புகளிலிருந்து வித்தியாசமாக்க வேண்டும் மற்று செயல் 3 ADR குறிப்புகளை வெளியேற்றுதல் மற்றும் மேட்டிரா குறியீடுகளுக்கு வரைபடம் செய்யும். ADR குறிப்புகளை வெளியேற்றுதல் மற்றும் ADR குறிப்புகளை இயல்பாக்குதல் மற்றும் பல வகுப்பு வகுப்பாக கருதப்படுகிறது. எங்கள் அமைப்பு முன்பயிற்சி மொழி மாதிரி ரோபெர்டா அடிப்படையில் உள்ளது இது செயலில் 58% புள்ளியை அடைக்கும், அது 12% அதிகமாகும் சராசரி புள்ளியை விட b அதிகமாக இருக்கும்) ADR செயலை வெளியேற்றத்தில் F1- புள்ளியை விட 13.7% அதிகமாக இருக்கும் சரா மொத்தமாக, எங்கள் மாதிரிகள் வாக்களிக்கப்படும் விளைவுகள் இருவரும் செயல்களுக்கும் முன்னேற்றங்கள் சராசரி மதிப்ப', 'vi': 'Tờ giấy này giới thiệu phương pháp của chúng ta cho nhiệm vụ 2 và nhiệm vụ 3 của Phòng chống truyền thông Xã hội (SMS4H) 2020 đã chia sẻ nhiệm vụ. Trong nhiệm vụ 2, chúng ta phải phân biệt các phản ứng gây hại (giải phóng) trên Twitter và được xem như phân loại nhị phân. Nhiệm vụ thứ ba gồm rút các chỉ thị dị ứng và rồi chuyển chúng sang mã Meddra. Việc trích dẫn dị tố được xem như chỉ thị dãy số và giải pháp định hình thường được coi là phân cấp nhiều lớp. Hệ thống của chúng ta dựa trên một mô hình ngôn ngữ đã được đào tạo trước Roeta và nó đạt được a) F1-số 58=.* trong nhiệm vụ 2 mà là 12=. nhiều hơn so với tỉ số trung b ình b) thư giãn F1-số 701.1=. trong giải cứu nhiệm vụ 3 là 13.7=. nhiều hơn so với tỉ số trung bình và thư giãn F1-điểm của 35=. trong giải cứu cộng hưởng cộng hưởng cộng hưởng cám cám cám cám cám cám cám cám cám trợ Trên hết, mẫu của chúng ta đạt được kết quả hứa hẹn về cả hai nhiệm vụ với cải tiến đáng kể trên điểm trung bình.', 'uz': "Bu qogʻoz 2020 bo'lgan vazifalarning 2 va Social Media Mind (SMM4H) vazifasi 3 ta vazifasini beradi. 2 vazifasida biz dop raqamli xabarlarni o'zgartirishimiz kerak va biz ikkita sinf sifatida boshlanamiz kerak. Vazifa 3 uchun ADR hisoblarini olib tashlash va keyin ularni MedDRA kodlarga diagramma qiladi. ADR hisobotini ajratish uchun sequence lab chiqarish va oddiy ADR hisoblarini bir necha klassifning sifatida qoʻllaniladi. Biz tizimmiz oldin o'rganilgan til modeli RoBERTa asosida, u vazifani 2 bilan 58% bajaradi, u 12% dan ortiq scori b bo'lgan F1 scori, ADR vazifani ajratish 3% dan 13.7% dan ortiq boʻlgan, ADR soni ajratish va vazifa 3 dan 5.8% dan ortiq boʻlgan. Umumiy, bizning modellarimiz eng yaxshi ishlarni bajaradi va ikkita vazifalar o'zgartiradi, o'rtacha darajada katta yaxshi o'zgarishlar bilan bajaradi.", 'hr': 'Ovaj papir predstavlja naš pristup zadatku 2 i zadatku 3 zajedničkih zadataka za rudarstvo socijalnih medija za zdravlje (SMM4H) 2020. U zadatku 2, moramo razlikovati nuspojavne reakcije na lijekove (ADR) tweets od tweets non ADR-a i tretirati se kao binarnu klasifikaciju. Treći zadatak uključuje izvlačenje spomena ADR-a i onda ih mapirati na MedDRA kodove. Izvlačenje spomena ADR-a liječeno je kao etiketiranje sekvence i normaliziranje spomena ADR-a liječeno je kao multiklasična klasična klasifikacija. Naš sustav se temelji na predobučenom jezičkom modelu RoBERTa i postiže a) F1 rezultat od 58% u zadatku 2 koji je 12% više od prosječnog rezultata b) opušteni F1 rezultat od 70,1% u izvlačenju zadatka 3 ADR-a koji je 13,7% više od prosječnog rezultata i opuštenog F1 rezultata od 35% u izvlačenju ADR-a + normalizaciju zadatka 3 koji je 5,8% više od prosječnog rezultata. Općenito, naši modeli postignu obećavajuće rezultate u oba zadatka s značajnim poboljšanjem u prosječnim rezultatima.', 'nl': 'Deze paper presenteert onze aanpak voor taak 2 en taak 3 van Social Media Mining for Health (SMM4H) 2020 gedeelde taken. In taak 2 moeten we tweets van ongewenste drugsreacties (ADR) onderscheiden van tweets die niet-ADR zijn en worden we behandeld als binaire classificatie. Taak 3 omvat het extraheren van ADR-vermeldingen en vervolgens toewijzen aan MedDRA-codes. Het extraheren van ADR vermeldingen wordt behandeld als sequentie labeling en het normaliseren van ADR vermeldingen wordt behandeld als multi-class classificatie. Ons systeem is gebaseerd op voorgetrainde taalmodel RoBERTa en het bereikt a) F1-score van 58% in taak 2 die 12% meer is dan de gemiddelde score b) ontspannen F1-score van 70,1% in ADR extractie van taak 3 die 13,7% meer is dan de gemiddelde score en ontspannen F1-score van 35% in ADR extractie en normalisatie van taak 3 die 5,8% meer is dan de gemiddelde score. Over het algemeen bereiken onze modellen veelbelovende resultaten in beide taken met significante verbeteringen ten opzichte van gemiddelde scores.', 'da': 'Denne artikel præsenterer vores tilgang til opgave 2 og opgave 3 i Social Media Mining for Health (SMM4H) 2020 delte opgaver. I opgave 2 skal vi skelne mellem bivirkninger (ADR) tweets og ikke-ADR tweets og behandles som binær klassificering. Opgave 3 indebærer at udtrække ADR-omtaler og derefter kortlægge dem til MedDRA-koder. Udtrækning af ADR omtaler behandles som sekvensmærkning og normalisering af ADR omtaler behandles som multi-class klassificering. Vores system er baseret på prætrænet sprogmodel RoBERTa og det opnår a) F1-score på 58% i opgave 2, som er 12% mere end gennemsnitsscoren b) afslappet F1-score på 70,1% i ADR udtrækning af opgave 3, som er 13,7% mere end gennemsnitsscoren og afslappet F1-score på 35% i ADR udtrækning + normalisering af opgave 3, som er 5,8% mere end gennemsnitsscoren. Samlet set opnår vores modeller lovende resultater i begge opgaver med betydelige forbedringer i forhold til gennemsnitsscorer.', 'bg': 'Настоящата статия представя нашия подход към задача 2 и задача 3 на споделените задачи на Социалните медии Минно дело за здраве (СММ4Х) 2020. В задача 2 трябва да разграничим туитовете на нежеланите лекарствени реакции (АРР) от туитовете, които не са АРР и се третират като двоична класификация. Задача 3 включва извличане на споменатите АРС и след това свързване с кодовете на MedDRA. Извличането на споменатите АРС се третира като последователно етикетиране, а нормализирането на споменатите АРС се третира като многокласна класификация. Системата ни е базирана на предварително обучен езиков модел и постига а) оценка от 58% при задача 2, което е 12% повече от средния резултат б) отпуснат резултат от 70,1% при екстракция на задача 3, което е 13,7% повече от средния резултат и отпуснат резултат от 35% при екстракция на АРР + нормализация на задача 3, което е 5,8% повече от средния резултат. Като цяло нашите модели постигат обещаващи резултати и в двете задачи със значителни подобрения спрямо средните резултати.', 'de': 'Dieser Beitrag stellt unseren Ansatz für Aufgaben 2 und Aufgabe 3 von Social Media Mining for Health (SMM4H) 2020 gemeinsam genutzten Aufgaben vor. In Aufgabe 2 müssen wir unerwünschte Arzneimittel-Tweets (ADR) von Nicht-ADR-Tweets unterscheiden und werden als binäre Klassifizierung behandelt. Aufgabe 3 besteht darin, ADR-Erwähnungen zu extrahieren und sie dann MedDRA-Codes zuzuordnen. Das Extrahieren von ADR-Erwähnungen wird als Sequenz-Kennzeichnung behandelt und das Normalisieren von ADR-Erwähnungen wird als Mehrklassenklassifizierung behandelt. Unser System basiert auf dem vortrainierten Sprachmodell RoBERTa und erreicht a) F1-Score von 58% in Aufgabe 2, der 12% höher ist als die durchschnittliche Punktzahl b) entspannte F1-Punktzahl von 70,1% in ADR-Extraktion von Aufgabe 3, die 13,7% höher ist als die durchschnittliche Punktzahl und entspannte F1-Punktzahl von 35% in ADR-Extraktion, Normalisierung von Aufgabe 3, die 5,8% höher als die durchschnittliche Punktzahl ist. Insgesamt erzielen unsere Modelle in beiden Aufgabenstellungen vielversprechende Ergebnisse mit deutlichen Verbesserungen gegenüber Durchschnittswerten.', 'id': 'This paper presents our approach for task 2 and task 3 of Social Media Mining for Health (SMM4H) 2020 shared tasks.  Dalam tugas 2, kita harus membedakan reaksi obat negatif (ADR) tweet dari tweet bukan ADR dan diperlakukan sebagai klasifikasi binari. Tugas 3 melibatkan mengekstrak sebutan ADR dan kemudian memetakannya ke kode MedDRA. Mengekstrak sebutan ADR diperlakukan sebagai label urutan dan normalisasi sebutan ADR diperlakukan sebagai klasifikasi multikelas. Sistem kita berdasarkan model bahasa terlatih sebelum RoBERTa dan ia mencapai a) F1-skor 58% dalam tugas 2 yang 12% lebih dari nilai rata-rata b) relaxed F1-skor 70.1% dalam ADR ekstraksi tugas 3 yang 13.7% lebih dari nilai rata-rata dan relaxed F1-skor 35% dalam ADR ekstraksi + normalisasi tugas 3 yang 5.8% lebih dari nilai rata-rata. Overall, our models achieve promising results in both the tasks with significant improvements over average scores.', 'ko': '본고는 소셜미디어 건강발굴(SMM4H) 2020에서 임무를 공유하는 임무 2와 임무 3의 방법을 소개한다.임무 2에서는 약물불량반응(ADR) 트윗과 비 ADR 트윗을 구분해 이원적으로 분류해야 한다.작업 3은 ADR 언급을 추출한 다음 MedDRA 코드에 매핑합니다.추출된 ADR 언급은 시퀀스 태그로, 표준화된 ADR 언급은 여러 범주로 분류됩니다.우리 시스템은 사전 훈련된 언어 모델인 로베르타를 바탕으로 a)퀘스트 2의 F1 점수는 58%로 평균 점수보다 12% 높았고 b)퀘스트 3의 ADR에서 추출한 이완 F1 점수는 70.1%로 평균 점수보다 13.7% 높았으며 퀘스트 3의 ADR에서 추출한 이완 F1 점수는 35%로 평균 점수보다 5.8% 높았다.전반적으로 말하자면, 우리의 모델은 이 두 가지 임무에서 모두 만족스러운 결과를 얻었고, 평균 점수보다 현저하게 높아졌다.', 'fa': 'این کاغذ روش ما را برای وظیفه ۲ و وظیفه ۳ از وظیفه\u200cهای مشترک سرمایه\u200cگذاری رسانه\u200cهای اجتماعی برای سلامت (SMM4H) نشان می\u200cدهد. در وظیفه ۲، ما باید واکنش مختلف مواد مختلف (ADR) را از تویت های غیر ADR جدا کنیم و به عنوان classification binary treated می\u200cشود. وظیفه ۳ شامل استخراج یادآوری ADR و سپس نقشه\u200cبندی آن\u200cها به کدهای MedDRA است. اخراج کردن اشاره\u200cهای ADR به عنوان برچسب برچسب\u200cهای برچسب\u200cها درمان می\u200cشود و عادی کردن اشاره\u200cهای ADR به عنوان برچسب\u200cهای برچسب\u200cهای بیشتر کلاس درمان می\u200cشود. سیستم ما بر روی مدل زبان پیش آموزش شده RoBERTa بنیاد می\u200cرسد و آن به (a) نقاط F1 58% در کار ۲ رسیده است که 12% بیشتر از نقاط متوسط b) نقاط F1 متوسط 70.1% در استخراج ADR از کار ۳ است که 13.7% بیشتر از نقاط متوسط و نقاط F1 متوسط از 35% در استخراج ADR + نقاط کاری ۳ است که 5.8% بیشتر از نقاط متوسط است. در کل، مدل\u200cهای ما نتیجه\u200cی قول\u200cدهنده در هر دو وظیفه\u200cای با بهترین شدید بیش از امتیاز متوسط رسیده\u200cاند.', 'af': "Hierdie papier stel ons toegang vir taak 2 en taak 3 van sosiale media-mining vir gesondheid (SMM4H) 2020 gedeelde taak voorsien. In taak 2, moet ons neerdaagde narkotika reaksie (ADR) tweets van nonADR tweets verskillig en as binêre klasifikasie behandel word. Opdrag 3 involves extracting ADR mentions and then mapping them to MedDRA codes. Uitpakking van ADR-nommers is behandel as sekwensieetiketting en normalisering van ADR-nommers is behandel as multiklas klasifikasie. Ons stelsel is gebaseer op voor- opgelei taal model RoBERTa en dit bereik 'n) F1- telling van 58% in taak 2 wat is 12% meer as die gemiddelde telling b) opgelaai F1- telling van 70. 1% in ADR uittrek van taak 3 wat is 13. 7% meer as die gemiddelde telling en opgelaai F1- telling van 35% in ADR uittrek + normalisering van taak 3 wat is 5. 8% meer as die gemiddelde telling. Op die hele manier, ons modele het beloftende resultate bereik in beide die opdragte met betekende verbeteringe oor gemiddelde punte.", 'tr': 'Bu kagyz biziň 2-nji görevimiz we 3-nji görevimiz üçin sosyal medýýallaryň saglygyň taýýarlanmagynyň (SMM4H) 2020-nji beýleki zadlary paýlaşýar. 2-nji täblikde, nusgalan ilat täsirini (ADR) nonADR tweetlerinden çykarmalydyr we ikinji klasifikasy hökmünde duýmalydyrys. 3-nji Görev ADR agzalaryny açmak we soňra ony MedDRA kodlara görkezmek bilen meýilleşdirýär. ADR agzalary açylmak üçin sıralan etiketlemek üçin gözlenýär we ADR agzalaryny düzenlemek üçin bir çoklu klasifikasyon diýip gözlenýär. Biziň sistemimiz RoBERTa öňünden eğlenen dil nusgasyna daýanýar we bu 2-nji işde 58% F1-score daýanýar. Bu 2-nji işinde orta sanatdan 12% köp b) süýtgeli F1-score da 70.1% ADR 3-nji işiň çekmesinde rahatlandyrylýar. Bu 3-nji işiň orta sanatyndan 13.7% we rahatlandyrylýan F1-score da 35% ADR çekmesinde + taýýarlyk 3-nji işiň normalizasynda 5.8% kö Her zamanki modellerimiz ortalama noktaları üzerinde önemli gelişmeler için söz verilen sonuçlarına ulaştı.', 'hy': 'Այս աշխատանքը ներկայացնում է մեր մոտեցումը 2-րդ և 3-րդ հանձնարարության համար, որը հանդիսանում է 2020-ի սոցիալական մեդիայի առողջության (SMM4H) հանրային հանձնարարությունները: Երկրորդ խնդրում մենք պետք է տարբերենք դեղամիջոցների բացասական արձագանքը (ADR) թվիթերից ոչ ADR թվիթերից և վերաբերվում է որպես երկու դասակարգման: Երրորդ խնդիրը ներառում է ԱԴՌ-ի նշանները վերցնելը և հետո դրանք քարտեզագրել ՄԵԴՌ-ի կոդների վրա: ԱԴՌ-ի մեջբերումները վերաբերվում են որպես հաջորդականության պիտակ և նորմալ ԱԴՌ-ի մեջբերումները վերաբերվում են որպես բազմադասական դասակարգում: Մեր համակարգը հիմնված է նախապատրաստված լեզվի մոդելի ՌոBERտայի վրա և այն հասնում է a) F1-գնահատականի 58 տոկոսին 2-ի դեպքում, որը 12 տոկոսից ավելին է, քան միջին գնահատականը b) հանգստացած F1-գնահատականը 70.1 տոկոսից ADR-ի վերացման դեպքում 3-ի դեպքում, որը 13.7 տոկոսից ավելին է, քան միջին գնահատականը, և հանգստացած F1-գնահատականը 35 տոկոսից ADR Ընդհանուր առմամբ, մեր մոդելները հասնում են խոստացնող արդյունքներ երկու խնդիրներում, որոնք մեծ բարելավում են միջին գնահատականների համեմատ:', 'az': "Bu kağıt bizim 2. və 3. işimizin sosial Media Mining for Health (SMM4H) 2020 paylaşılan işlərimizin tərzimi göstərir. İkinci görevdə, neçə-neçə uyuşturucu reaksiyonu (ADR) bitlərindən ayırmalıyıq və ikili klasifikasyon olaraq davranmalıyıq. Üçüncü görev ADR yaddaşlarını çıxartmaq və sonra onları MedDRA kodlarına mapa etmək istəyir. ADR yaddaşlarını çıxartmaq seçmə etiketi kimi görünür və ADR yaddaşlarını normalizləmək çoxlu sınıf klasifikasyonu kimi görünür. Bizim sistemimiz əvvəl təhsil edilmiş dil modeli RoBERTa'ya dayandırılmış və bu 2'nin f1-score 58%-dən artır, bu da orta nöqtədən 12%-dən artır b) 3'nin ADR çıxarılmasından 70.1%-dən rahatlı F1 nöqtəsidir, bu da orta nöqtəsindən 13.7%-dən artır və 3'nin ADR çıxarılmasında rahatlı F1-score 35%-dən artır və bu da 5.8% orta nöqtəsindən artır. Əlbəttə, modellərimiz orta nöqtələrin üstündə möhkəm düzəltməsi ilə hər ikisinin və ’ d verən sonuçlarına nail olur.", 'sw': 'Makala hii inaonyesha mbinu yetu ya kazi ya 2 na kazi 3 ya Mitandao ya kijamii ya Kumbukumbu ya Afya (SMM4H) 2020 zilizoshirikiana na kazi zetu. Katika kazi ya 2, tunatakiwa kutofautisha mwitikio mbaya wa madawa (ADR) kwenye twiti za twiti zisizo na ADR na hutumiwa kama sifa binafsi. Kazi 3 inahusisha kuondoa tahadhari za ADR na kisha kutengeneza ramani kwenye sheria za MedDRA. Kutokana na matamko ya ADR yanachukuliwa kama maarifa yanayoelezea na kuharimisha maneno ya ADR yanachukuliwa kama sifa za darasa nyingi. Mfumo wetu umejikita na muundo wa lugha iliyoendelea RoBERTa na inafikia) score ya F1 ya asilimia 58 katika kazi 2 ambayo ni zaidi ya asilimia 12 ya kiwango cha wastani b) ilifukuza score ya F1 ya asilimia 70.1 katika kazi ya ADR kuondolewa kwa kiwango cha wastani 3 ambacho ni asilimia 13.7 zaidi ya score ya wastani na kupumzika score ya F1 kwa asilimia 35 katika uteuzi wa ADR + utaratibu wa kazi 3 ambayo ni asilimia 5.8 zaidi ya score ya wastani. Kwa ujumla, mifano yetu hupata matokeo ya kuahidini yanasababisha kazi zote zenye maboresho makubwa zaidi ya vipindi vya wastani.', 'am': 'ይህም ገጽ ለስራ 2 እና ለስራ 3 የማኅበራዊ ሚዲያ አሳብ ለጤና አሳብ (SMM4H) 2020 የተካፈሉት ስራዎችን ያቀርባል፡፡ በስራ 2፣ የተቃወመ የረኀብ ጥያቄ (ADR) ትዊተሮችን ከኤድአር ትዊተር እና የሀብት መግለጫ እንዲሆን ያስፈልጋል፡፡ ስራ 3 የADR ማስታወሻ ማውጣት እና ከዚያም ወደ ሜድDRA ኮድ ማህበረሰብ ነው። ADR ማስታወቂያውን ለማውጣት በቁጥጥር ማሳየት እና የADR ማስታወቂያውን በማስተካከል በብዙ-ክፍል መግለጫ ሆኖ ይጠቀማል፡፡ የድምፅ ቋንቋ ምሳሌ RoBERta የተመሠረተ ነው፡፡ በጠቅላላላ፣ ሞዴላዎቻችን በተስፋ የሚደርሱትን ፍሬዎች በሁለታቸው ትልቅ ድምፅ የሚያደርጉትን አግኝተዋል፡፡', 'sq': 'Ky dokument paraqet qasjen tonë për detyrën 2 dhe detyrën 3 të Social Media Mining for Health (SMM4H) 2020. Në detyrën e dytë, ne duhet të diferencojmë reaksionin e keq të drogës (ADR) tweetet nga tweetet jo ADR dhe trajtohet si klasifikim binar. Detyra 3 përfshin nxjerrjen e përmendimeve të ADR dhe pastaj hartimin e tyre në kodet e MedDRA. Ekstraktimi i përmendimeve ADR trajtohet si etiketat e sekuencës dhe normalizimi i përmendimeve ADR trajtohet si klasifikim shumë-klasësh. Sistemi ynë është bazuar në model in e gjuhës së paratrajnuar RoBERTa dhe arrin a) rezultat F1 prej 58% në detyrën 2 që është 12% më shumë se rezultati mesatar b) rezultat F1 të relaksuar prej 70.1% në ADR ekstrahimin e detyrës 3 që është 13.7% më shumë se rezultati mesatar dhe rezultat F1 të relaksuar prej 35% në ADR ekstrahimin + normalizimin e detyrës 3 që është 5.8% më shumë se rezultati mesatar. Në përgjithësi, modelet tona arrijnë rezultate premtuese në të dy detyrat me përmirësime të rëndësishme mbi rezultatet mesatare.', 'cs': 'Tento článek představuje náš přístup k úkolům 2 a úkolům 3 Social Media Mining for Health (SMM4H) 2020 sdíleným úkolům. V úkolu 2 musíme odlišit tweety nežádoucí léčivé reakce (ADR) od tweetů jiných nežádoucích léčiv a je považováno za binární klasifikaci. Úkol 3 zahrnuje extrahování zmínek ADR a následné mapování jejich na kódy MedDRA. Extrakce ADR zmínek je považována za sekvenční označení a normalizace ADR zmínek je považována za vícetřídní klasifikaci. Náš systém je založen na předcvičeném jazykovém modelu RoBERTa a dosahuje a) F1 skóre 58% v úkolu 2, což je 12% větší než průměrné skóre b) uvolněné F1 skóre 70,1% v ADR extrakci úkolu 3, což je 13,7% větší než průměrné skóre a uvolněné F1 skóre 35% v ADR extrakci, normalizace úkolu 3, která je 5,8% větší než průměrné skóre. Celkově dosahují naše modely slibných výsledků v obou úkolech s výrazným zlepšením nad průměrným skórem.', 'ca': "Aquest paper presenta el nostre enfocament per a la tasca 2 i la tasca 3 de Social Media Mining for Health (SMM4H) 2020. In task 2, we have to differentiate adverse drug reaction (ADR) tweets from nonADR tweets and is treated as binary classification.  La tasca 3 consisteix en extrair les mencions de l'ADR i després en mapejar-les a codis MedDRA. L'extracció de les mencions ADR es tracta com etiquetar seqüències i normalitzar les mencions ADR es tracta com una classificació multiclasse. El nostre sistema es basa en el model de llenguatge pre-entrenat RoBERTa i aconsegueix a) puntuació F1 del 58% en la tasca 2, que és el 12% més que la mitjana puntuació b) puntuació F1 relaxada del 70,1% en l'extracció ADR de la tasca 3, que és el 13,7% més que la mitjana puntuació i puntuació F1 relaxada del 35% en l'extracció ADR + normalització de la tasca 3, que és el 5,8% més que la mitjana puntuació. En general, els nostres models aconsegueixen resultats prometedors en les dues tasques amb millores significatives sobre les puntuacions mitjanes.", 'fi': 'Tässä artikkelissa esitellään lähestymistapamme sosiaalisen median kaivostoiminnan (SMM4H) 2020 jaettuihin tehtäviin 2 ja 3. Tehtävässä 2 meidän on erotettava haittavaikutusten (ADR) tweetit muista kuin ADR tweeteistä ja niitä käsitellään binääriluokitteluna. Tehtävään 3 kuuluu ADR-mainintojen poimiminen ja niiden yhdistäminen MedDRA-koodeihin. ADR-mainintojen purkamista käsitellään sekvenssimerkinnöinä ja ADR-mainintojen normalisointia moniluokkaisena luokitteluna. Järjestelmämme perustuu ennalta koulutettuun kielimalliin RoBERTa ja se saavuttaa a) F1-pisteen 58% tehtävässä 2, mikä on 12% enemmän kuin keskiarvo b) rennon F1-pisteen 70,1% ADR-ekstraktiossa tehtävästä 3, mikä on 13,7% enemmän kuin keskiarvo ja rennon F1-pisteen 35% ADR-ekstraktiossa + normalisoitumisen tehtävän 3, joka on 5,8% enemmän kuin keskiarvo. Kaiken kaikkiaan malleillamme saavutetaan lupaavia tuloksia molemmissa tehtävissä ja parannuksia keskimääräisiin tuloksiin verrattuna.', 'et': 'Käesolevas artiklis tutvustatakse meie lähenemisviisi sotsiaalmeedia tervishoiu kaevandamise (SMM4H) 2020. aasta jagatud ülesannete 2. ja 3. ülesandele. Ülesandes 2 tuleb eristada kõrvaltoimete (ADR) säutseid mitteADR säutseid ja neid käsitletakse kahekordse klassifikatsioonina. Ülesanne 3 hõlmab vaidluste kohtuvälise lahendamise märgete väljavõtmist ja seejärel nende kaardistamist MedDRA koodidega. ADR-märgete ekstraheerimist käsitletakse järjestuse märgistusena ja ADR-märgete normaliseerimist käsitletakse mitmeklassilise klassifikatsioonina. Meie süsteem põhineb eelõpetatud keelemudelil RoBERTa ja see saavutab a) F1-skoori 58% ülesandes 2, mis on 12% rohkem kui keskmine skoor b) lõdvestunud F1-skoori 70,1% ADR ekstraheerimisel ülesandes 3, mis on 13,7% rohkem kui keskmine skoor ja lõdvestunud F1-skoori 35% ADR ekstraheerimisel + ülesande 3 normaliseerimine, mis on 5,8% rohkem kui keskmine skoor. Kokkuvõttes saavutavad meie mudelid mõlemas ülesandes paljulubavaid tulemusi, mis on oluliselt paranenud keskmisest tulemusest.', 'bn': 'এই পত্রিকাটি স্বাস্থ্যের জন্য সামাজিক মিডিয়া মিনিং এর ২ এবং তিন কাজের জন্য আমাদের প্রতিক্রিয়া উপস্থাপন করেছে ২০২০ টি শে দ্বিতীয় কাজে আমাদের অএডিআর টুইট থেকে বিভিন্ন ভিন্ন ভিন্ন ভিন্ন মাদক প্রতিক্রিয়া (এডিআর) টুইট বিভিন্ন করা দরকার এবং বাইন কাজ ৩ এর মধ্যে এডিআরের মন্তব্য বের করে মেডিড্রা কোডে ম্যাপ করা হয়। এডিআর উল্লেখযোগ্য উল্লেখ করা হচ্ছে সেকেন্ড লেবেলিং এবং স্বাভাবিকভাবে এডিআর মেনেন্টগুলো বহুশ্রেণীর বিভাগ হিস আমাদের সিস্টেম রোবের্তার পূর্ব প্রশিক্ষিত ভাষার মডেলের উপর ভিত্তিতে রয়েছে এবং এটি কাজের দ্বারা ৫৮% ফেসবুকের স্কোর অর্জন করা হয়েছে যা সাধারণ স্কোর bের চেয়ে ১২% বেশী) এডিআর কাজের বের করার ৩০. সাধারণত, আমাদের মডেলগুলো প্রতিশ্রুতিশীল ফলাফল অর্জন করেছে যার ফলে সাধারণত স্কোরের বেশী বিশাল উন্নতি পায়।', 'bs': 'Ovaj papir predstavlja naš pristup zadatku 2 i zadatku 3 zajedničkih zadataka za rudarstvo socijalnih medija za zdravlje (SMM4H) 2020. U zadatku 2, moramo diferencirati nuspojavne reakcije na drogu (ADR) tweets od non ADR tweets i tretirati se kao binarnu klasifikaciju. Task 3 uključuje izvlačenje spomena ADR-a i onda ih mapiranje na MedDRA kodove. Izvlačenje spomena ADR-a tretira se kao etiketiranje sekvence i normaliziranje spomena ADR-a tretira se kao klasifikacija multiklasa. Naš sistem je baziran na predobučenom jezičkom modelu RoBERTa i postiže a) F1 rezultat od 58% u zadatku 2 koji je 12% više od prosječnog rezultata b) opušteni F1 rezultat od 70,1% u izvlačenju zadatka 3 ADR-a koji je 13,7% više od prosječnog rezultata i opuštenog F1 rezultata od 35% u izvlačenju ADR-a + normalizaciju zadatka 3 koji je 5,8% više od prosječnog rezultata. Općenito, naši modeli postignu obećavajuće rezultate u obje zadatke sa značajnim poboljšanjem preko prosječnih rezultata.', 'sk': 'V prispevku je predstavljen naš pristop k nalogi 2 in 3 skupnih nalog socialnih medijev rudarjenje za zdravje (SMM4H) 2020. V nalogi 2 moramo razlikovati neželene učinke na zdravilo (ADR) tweets od non ADR tweets in se obravnavamo kot binarno klasifikacijo. Naloga 3 vključuje pridobivanje omenitev ARS in njihovo preslikavo v kode MedDRA. Izvlečevanje omemb ADR se obravnava kot označevanje zaporedja, normalizacija omemb ADR pa se obravnava kot razvrstitev več razredov. Naš sistem temelji na vnaprej usposobljenem jezikovnem modelu RoBERTa in dosega a) rezultat F1 58% v nalogi 2, kar je 12% več od povprečne rezultate b) sproščeno rezultat F1 70,1% pri ekstrakciji ADR 3, kar je 13,7% več od povprečne rezultate in sproščeno rezultat F1 35% pri ekstrakciji ADR + normalizacija naloge 3, kar je 5,8% več od povprečne rezultate. Na splošno naši modeli dosegajo obetavne rezultate pri obeh nalogah z znatnimi izboljšavami v primerjavi s povprečnimi rezultati.', 'jv': 'Perintah iki dadi nggawe perintah dumadhi kanggo nggawe 2 nggo 3 nggawe barang Media Minng kanggo Kemerdekaan Sak Jaakan (SMM4H) 2020 ngerasakno 1=task 2 3 Name Kita sistem wis basa oleh-cara perusahaan anyar luwih model Punika, maneh sing paling nggawe model sing rumangsa akeh lan sawalik iki dadi sing luwih dumadhi kanggo kalagayan sing luwih dumadhi', 'ha': "Bu takardan na gaurar da aikin mu wa aikin 2 and aikin 3 of society Media Mining for Heatherhood (SMM4H) 2020 Shared tasks. Kayyan aikin 2, ana hana mu rarrabe masu iya motsi ga aikin madawara (ADR) daga Twitter na nonADR kuma ana yi amfani da shi kamar fassar labari. Tafiyar 3 na ƙunsa da mai fitarwa na ADR kuma ka sami su zuwa kodin MedDR. Extracting ADR mentions is treated as sequence labeling and normalizing ADR mentions is treated as multi-class classification.  Ana kasar da tsarin mu a kan misalin harshen RoBERTa a gabãnin an yi amfani da shi, kuma yana sãmu a) F1-score na 58 cikin aikin 2 wanda ke da 12% ko kuma mafi ƙaranci score b) ya saka F1-score na 70.1% cikin rabon aikin ADR 3 da ke ƙara 13.7% da ke ƙaranci F1-score na halartar nau'i na 35% a ADR Extractin+na normal aikin aikin 3 wanda ke kasa 5.8%. Gansa, misãlai masu sami matsayin da ake yi wa'adi da su sami aikin dukansu da suka kyautata mafiya kyauta kan nauyi.", 'he': 'העיתון הזה מציג את הגישה שלנו למשימה 2 ומשימה 3 של מחקר מדיה חברתית לבריאות (SMM4H) 2020 משותפים משותפים. במשימה 2, אנחנו צריכים להפריד את תגובת התרופות הלא רצינית (ADR) טוויטים מתוך טוויטים ללא ADR ומטפלים בתור מסווג בינרי. Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes.  הוצאת הזכרונות של ADR מתייחסת כתווית רצף והזכרונות של ADR נורמלי מתייחסת כקליזציה רבה-מעמד. המערכת שלנו מבוססת על מודל שפה מאומן מראש RoBERTa והיא משיגה a) נקודת F1 של 58% במשימה 2 שהיא 12% יותר מהנקודת הממוצעת b) נקודת F1 מרגיעה של 70.1% בהוצאה ADR של משימה 3 שהיא 13.7% יותר מהנקודת הממוצעת והנקודת F1 מרגיעה של 35% בהוצאה ADR + נורמליזציה של משימה 3 שהיא 5.8% יותר מהנקודה הממוצעת. באופן כללי, הדוגמנים שלנו מגיעים לתוצאות מבטיחות בשני המשימות עם שיפורים משמעותיים מעל נקודות ממוצעים.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་གཟུགས་སྐོར་ལ་བྱ་རིམ་དང་། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་སྤྲོད་ཀྱི་ཞབས་ཞུ་གཏོང་(SMM4H)སྤྱི་ཚ In task 2, we have to differentiate adverse drug reaction (ADR) tweets from nonADR tweets and is treated as binary classification. Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes. Extracting ADR mentions is treated as sequence labeling and normalizing ADR mentions is treated as multi-class classification. Our system is based on pre-trained language model RoBERTa and it achieves a) F1-score of 58% in task 2 which is 12% more than the average score b) relaxed F1-score of 70.1% in ADR extraction of task 3 which is 13.7% more than the average score and relaxed F1-score of 35% in ADR extraction + normalization of task 3 which is 5.8% more than the average score. འཇུག་བརྡན་ན། མིག་དཔེ་དབྱིབས་མ་ཚད་རྒྱ་ནག་གི་ཚད་ལྟར་འགྱུར་རྐྱེན་པའི་ཁས་མཐུན་རྐྱེན་ཐུབ་པ་ཡིན།'}
{'en': 'Detecting Tweets Reporting Birth Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture CNN   RNN  Based Architecture', 'ar': 'الكشف عن التغريدات التي تُبلغ عن نتيجة الحمل بعيب الولادة باستخدام بنية CNN RNN ثنائية العرض', 'pt': 'Detecção de Tweets que relatam resultado de gravidez com defeito de nascença usando arquitetura baseada em duas visualizações CNN RNN', 'es': 'Detección de tweets que informan el resultado de un embarazo con defectos de nacimiento mediante una arquitectura basada en CNN RNN', 'fr': "Détection des tweets signalant l'issue d'une grossesse avec une anomalie congénitale à l'aide de l'architecture CNN RNN", 'ja': '2ビューCNN RNNベースのアーキテクチャを使用した出産不良妊娠の結果を報告するツイートの検出', 'zh': '用双视图 CNN RNN 架构检报妊娠之推文', 'hi': 'Tweets रिपोर्टिंग जन्म दोष गर्भावस्था परिणाम का पता लगाना दो-दृश्य सीएनएन RNN आधारित वास्तुकला का उपयोग कर', 'ru': 'Обнаружение твитов, сообщающих об исходе беременности с врожденным дефектом, с использованием архитектуры на основе двух проекций CNN RNN', 'ga': 'Tweets a Bhrath Ag Tuairisciú Locht Breithe Toradh Toirchis Ag Úsáid Ailtireacht Bhunaithe CNN RNN Dhá Amharc', 'ka': 'Tweets rapportering Birth Defect Pregnancy Outcome using Two-View CNN RNN Based Architecture', 'it': "Rilevamento dei tweet che segnalano i risultati della gravidanza con difetti di nascita utilizzando l'architettura basata su CNN RNN a due visualizzazioni", 'el': 'Ανίχνευση Τουίτερ που αναφέρουν το αποτέλεσμα εγκυμοσύνης γέννησης χρησιμοποιώντας αρχιτεκτονική βασισμένη σε δύο όψεις', 'hu': 'A születési hibát jelentő tweetek észlelése a terhesség eredményéről kétnézetes CNN RNN alapú architektúra használatával', 'kk': 'Туиттерді хабарлау Туз деген тапсырмаларды анықтау CNN RNN негізіндегі архитектурасы қолданады', 'mk': 'Детектирање на Твитови за извештај за резултатот на бременоста со двогледна архитектура базирана на CNN RNN', 'lt': 'Tweetų, pranešančių apie gimdymo defektų nėštumo rezultatus, nustatymas naudojant dviejų vaizdų CNN RNN pagrįstą architektūrą', 'ms': 'Mengesan Tweets Melapor Keputusan Kehamilan Lahiran menggunakan Arkitektur berdasarkan CNN RNN Dua-Paparan', 'mn': 'Tweets Reporting Bird Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture', 'ml': 'രണ്ട്- കാഴ്ച സിNN RNN അടിസ്ഥാനമായ ആര്\u200dക്ടിക്കറ്റര്\u200d ഉപയോഗിക്കുന്ന രണ്ട് കാഴ്ച ഉപയോഗിച്ച് പിറന്\u200d ഡിപ്പെറ്റ് പ്ര', 'no': 'Finn tweets rapportering av fødselsdefekt fødselskrift ved å bruka to- visning CNN RNN-basert arkitektur', 'mt': 'Żvelar ta’ Tweets li jirrapportaw Riżultat tat-Tqala ta’ Difett fit-Tqala bl-użu ta’ Arkitettura bbażata fuq CNN RNN b’żewġ viżta', 'pl': 'Wykrywanie tweetów zgłaszających wady urodzeniowe w ciąży za pomocą architektury CNN RNN', 'sr': 'Otkrivajući rezultat trudnoće na putu Tweets izvještavajući račune s dva pogleda CNN RNN Based Architecture', 'ro': 'Detectarea tweeturilor care raportează rezultatele sarcinii defectelor nașterii utilizând arhitectura bazată pe CNN RNN în două vizualizări', 'so': 'Finding Tweets Reporting Birth Defect Pregnancy Outcome using Two-View CNN RNN Based Architecture', 'si': 'Tweets වාර්තාවක් වාර්තාවෙන්න පුළුවන් නිර්භාවිත ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පරීක්ෂණය කරනව', 'ta': 'இரண்டு காட்சி CNN RNN அடிப்படையான காட்சி அடிப்படையில் உருவாக்கத்தை பயன்படுத்தி குழந்தை பாதுகாப்பு முடிவு வெளிய', 'sv': 'Upptäckt av tweets som rapporterar graviditetsresultat med hjälp av CNN RNN-baserad arkitektur', 'ur': 'ٹویٹ راپیٹ ڈیفکسٹ پرینٹنسی آواٹ ڈیٹ ڈیفکسٹ ڈیفکسٹ آواٹ کا استعمال کرتا ہے', 'uz': 'Name', 'vi': 'Phát hiện Tweet báo cáo kết quả thai thảm hại bằng kiến trúc dựa trên kênh CNN', 'bg': 'Откриване на туитове, докладващи за резултат от бременност при рожден дефект, използвайки архитектура, базирана на два вида', 'da': 'Registrering af tweets Rapportering af fødselsdefekt Graviditetsresultat ved hjælp af to-View CNN RNN-baseret arkitektur', 'hr': 'Otkrivanje rezultata trudnoće na računima s dvije poglede CNN RNN-a', 'nl': 'Detecteren van Tweets die Geboortedefect Zwangerschapsuitslag melden met behulp van Two-View CNN RNN gebaseerde architectuur', 'de': 'Erkennung von Tweets, die Geburtsfehler-Schwangerschaftsergebnis mit Two-View CNN RNN-basierter Architektur melden', 'ko': '투시도 CNN RNN 기반 아키텍처 검사로 출생결함 임신 결과를 보고하는 트윗 사용', 'fa': 'تشخیص Tweets Reporting Birth Defect Pregnancy Outcome using Two-View CNN RNN Based Architecture', 'sw': 'Kugundua Twita Kuripoti Matokeo ya Kutetea Uzazi wa Uzazi wa Kutokana na Utumiaji wa Maonyesho mawili ya CNN RNN', 'tr': 'Tweets Bildirilýän Tuş Taýdalyk Görkezilýän Taýdalyk Çikgi', 'sq': 'Detecting Tweets Reporting Birth Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture', 'af': 'Kies tweets raporteer Vrede Defekte Pregnancy Outcome met 2- View CNN RNN Based Architecture', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': 'Թվիթերի հայտնաբերումը ծննդյան սխալ հղիության արդյունքում օգտագործելով CNN-ի ՌՆԹ հիմնված երկու տեսանկյունից կառուցվածք', 'bn': 'টুইটার সনাক্ত করা হচ্ছে দুই-ভিউ সিএনএন আরএনএন ভিত্তিক আর্কিকেক্ট', 'az': 'Tweets Reporting Bird Defect Pregnancy Output Detected using Two-View CNN RNN Based Architecture', 'bs': 'Otkrivajući rezultat trudnoće na putu Tweets izvještavajući račune s 2-View CNN RNN Based Architecture', 'ca': 'Detecting Tweets Reporting Birth Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture', 'et': 'Sünnihäiretest raseduse tulemustest teatavate tweetide tuvastamine kahe vaatega CNN RNN-põhine arhitektuur', 'cs': 'Detekce tweetů hlášení výsledků těhotenství s použitím dvoupohledové architektury založené na CNN RNN', 'id': 'Detektif Tweets melaporkan hasil kehamilan cacat kelahiran menggunakan arsitektur berdasarkan dua pandangan CNN RNN', 'fi': 'Synnytysvaikutuksista raskaustuloksista raportoivien twiittien tunnistaminen kahden näkymän CNN RNN-pohjaisen arkkitehtuurin avulla', 'he': 'גילוי טוויטים מדווחים על התוצאה של פגיעה בהריון בהולדת באמצעות ארכיטקטורה בסיסית CNN RNN', 'ha': '@ info: status', 'sk': 'Zaznavanje Tweets, ki poročajo o izidu nosečnosti pri rojstnih napakah z dvema pogledom CNN RNN arhitekture', 'jv': 'Perintah Tuwit Tatuhi Njupuk Defectu preggentah Gambar Sugeng Two-view MTN Ngawe Perintah Arkita sing Ngawe', 'bo': 'Tweets Reporting Birth Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture'}
{'en': 'This research work addresses a new multi-class classification task (fifth task) provided at the fifth Social Media Mining for Health Applications (SMM4H) workshop. This automatic tweet classification task involves distinguishing three classes of tweets that mention  birth defects . We propose a novel two view based CNN-BiGRU based architectures for this  task . Experimental evaluation of our proposed  architecture  over the validation set gives encouraging results as it improves by approximately 7 % over our single view model for the fifth task. Code of our proposed  framework  is made available on Github', 'ar': 'يتناول هذا العمل البحثي مهمة تصنيف جديدة متعددة الفئات (المهمة الخامسة) المقدمة في ورشة العمل الخامسة لتعدين الوسائط الاجتماعية للتطبيقات الصحية (SMM4H). تتضمن مهمة تصنيف التغريدات تلقائيًا هذه التمييز بين ثلاث فئات من التغريدات التي تشير إلى عيوب خلقية. نقترح بنية جديدة تستند إلى عرضين تستند إلى CNN-BiGRU لهذه المهمة. يعطي التقييم التجريبي للهندسة المعمارية المقترحة على مجموعة التحقق نتائج مشجعة حيث يتحسن بنسبة 7٪ تقريبًا عن نموذج العرض الفردي الخاص بنا للمهمة الخامسة. رمز إطار العمل المقترح متاح على Github', 'pt': 'Este trabalho de pesquisa aborda uma nova tarefa de classificação multiclasse (quinta tarefa) fornecida no quinto workshop de Mineração de Mídias Sociais para Aplicações em Saúde (SMM4H). Essa tarefa de classificação automática de tweets envolve distinguir três classes de tweets que mencionam defeitos congênitos. Propomos uma nova arquitetura baseada em duas visões baseada em CNN-BiGRU para esta tarefa. A avaliação experimental de nossa arquitetura proposta sobre o conjunto de validação fornece resultados encorajadores, pois melhora em aproximadamente 7% em relação ao nosso modelo de visualização única para a quinta tarefa. O código do nosso framework proposto é disponibilizado no Github', 'es': 'Este trabajo de investigación aborda una nueva tarea de clasificación multiclase (quinta tarea) proporcionada en el quinto taller de Minería de redes sociales para aplicaciones de salud (SMM4H). Esta tarea de clasificación automática de tuits implica distinguir tres clases de tuits que mencionan defectos de nacimiento. Proponemos una novedosa arquitectura basada en dos vistas basadas en CNN-BigRU para esta tarea. La evaluación experimental de nuestra arquitectura propuesta sobre el conjunto de validación arroja resultados alentadores, ya que mejora en aproximadamente un 7% con respecto a nuestro modelo de vista única para la quinta tarea. El código de nuestro marco propuesto está disponible en Github', 'fr': "Ce travail de recherche porte sur une nouvelle tâche de classification multi-classes (cinquième tâche) fournie lors du cinquième atelier Social Media Mining for Health Applications (SMM4H). Cette tâche de classification automatique des tweets consiste à distinguer trois catégories de tweets qui mentionnent des malformations congénitales. Nous proposons une nouvelle architecture basée sur CNN-Bigru basée sur deux vues pour cette tâche. L'évaluation expérimentale de notre architecture proposée par rapport à l'ensemble de validation donne des résultats encourageants car elle s'améliore d'environ 7\xa0% par rapport à notre modèle de vue unique pour la cinquième tâche. Le code de notre framework proposé est disponible sur Github", 'hi': 'यह शोध कार्य स्वास्थ्य अनुप्रयोगों (SMM4H) कार्यशाला के लिए पांचवें सोशल मीडिया माइनिंग में प्रदान किए गए एक नए बहु-श्रेणी वर्गीकरण कार्य (पांचवें कार्य) को संबोधित करता है। इस स्वचालित ट्वीट वर्गीकरण कार्य में ट्वीट्स के तीन वर्गों को अलग करना शामिल है जो जन्म दोषों का उल्लेख करते हैं। हम इस कार्य के लिए एक उपन्यास दो दृश्य आधारित सीएनएन-BiGRU आधारित आर्किटेक्चर का प्रस्ताव करते हैं। सत्यापन सेट पर हमारे प्रस्तावित आर्किटेक्चर का प्रयोगात्मक मूल्यांकन उत्साहजनक परिणाम देता है क्योंकि यह पांचवें कार्य के लिए हमारे एकल दृश्य मॉडल पर लगभग 7% तक सुधार करता है। हमारे प्रस्तावित ढांचे का कोड Github पर उपलब्ध कराया गया है', 'ru': 'Эта исследовательская работа посвящена новой многоклассовой задаче классификации (пятой задаче), которая была представлена на пятом семинаре по использованию социальных сетей в целях применения в здравоохранении (SMM4H). Эта задача автоматической классификации твитов включает в себя выделение трех классов твитов, в которых упоминаются врожденные дефекты. Мы предлагаем романную архитектуру CNN-BiGRU, основанную на двух представлениях, для этой задачи. Экспериментальная оценка предлагаемой нами архитектуры по сравнению с набором валидации дает обнадеживающие результаты, поскольку она улучшается примерно на 7% по сравнению с нашей моделью единого представления для пятой задачи. Код предлагаемой нами структуры доступен на Github', 'ja': 'この研究は、第5回ソーシャルメディアマイニングフォーヘルスアプリケーション（ SMM 4 H ）ワークショップで提供された新しいマルチクラス分類タスク（第5のタスク）に取り組んでいます。この自動ツイート分類タスクでは、出生時の欠陥に言及した3つのクラスのツイートを区別します。このタスクのために、CNN - BiGRUベースの斬新な2ビューアーキテクチャを提案します。検証セットに対する提案されたアーキテクチャの実験的評価は、5番目のタスクの単一ビューモデルよりも約7%改善するため、興味深い結果をもたらします。提案されたフレームワークのコードはGithubで利用可能です', 'zh': '其事涉第五届宜社交媒体掘(SMM4H)研讨会一新多类类(第五项)。 自推文分类及区别三推文。 建一CNN-BiGRU之架构于两视图。 验集上架构之实验性估以令人鼓舞,盖其高于五务者视图形重于7%也。 臣等议框架者代码给于Github', 'ga': 'Tugann an obair thaighde seo aghaidh ar thasc ilrangaithe nua (cúigiú tasc) a cuireadh ar fáil ag an gcúigiú ceardlann ar Mhianadóireacht ar na Meáin Shóisialta le haghaidh Feidhmchláir Sláinte (SMM4H). Is éard atá i gceist leis an tasc aicmithe tweet uathoibríoch seo ná trí aicme tweets a idirdhealú a luann lochtanna breithe. Molaimid ailtireacht nua dhá amharc bunaithe ar CNN-BiGRU don tasc seo. Tugann meastóireacht thurgnamhach ar ár n-ailtireacht bheartaithe thar an tsraith bhailíochtaithe torthaí spreagúla mar go dtagann feabhas air de thart ar 7% thar ár múnla aon-amhairc don chúigiú tasc. Tá cód ár gcreat molta curtha ar fáil ar Github', 'ka': 'ამ შესწავლობის სამუშაო სამუშაო სამუშაო კლასიფიკაციის ახალი სამუშაო კლასიფიკაციის სამუშაო (ხუთი სამუშაო სამუშაო) სამუშაო მედია სამუშ ამ ავტომატიკური ტივის კლასიფიკაციის დავალება სამი კლასის განსხვავება, რომელიც სახელსახლეობის განსხვავება. ჩვენ შეგიძლიათ პრომენტის ორი ხელსაწყობინება CNN-BiGRU-ის ბაზეული აქტიქტიქტურები ამ დავალებისთვის. ჩვენი პროგრამეტური აქტიქტურის გამოსახულება გადაწყვეტილების შესახებ გადაწყვეტილების შესახებ უფრო მხოლოდ 7% გამოსახულება ჩვენი ერთი ხედის მოდელზე პირველი მოდელზე. ჩვენი წარმოიდგინეთ პარამეტრის კოდი Github-ში იქნება', 'el': 'Αυτή η ερευνητική εργασία ασχολείται με μια νέα εργασία ταξινόμησης πολλαπλών κατηγοριών (πέμπτη εργασία) που παρέχεται στο πέμπτο εργαστήριο Εξόρυξης Κοινωνικών Μέσων για Εφαρμογές Υγείας (SMM4H). Αυτή η αυτόματη εργασία ταξινόμησης περιλαμβάνει τη διάκριση τριών κατηγοριών tweets που αναφέρουν γενετικές ανωμαλίες. Προτείνουμε μια νέα αρχιτεκτονική βασισμένη σε δύο απόψεις βασισμένη σε CNN-BiGRU για αυτό το έργο. Η πειραματική αξιολόγηση της προτεινόμενης αρχιτεκτονικής μας πάνω από το σύνολο επικύρωσης δίνει ενθαρρυντικά αποτελέσματα καθώς βελτιώνεται κατά περίπου 7% σε σχέση με το μοντέλο ενιαίας προβολής για την πέμπτη εργασία. Ο κώδικας του προτεινόμενου πλαισίου μας διατίθεται στο Github', 'kk': 'Бұл зерттеу жұмысы бесінші социалдық медиа бағалау қолданбалары (SMM4H) жұмысында берілген жаңа көп класс класс классификациялау тапсырмасын (бесінші тапсырмасы) адресін бер Бұл автоматты tweet классификациясының тапсырмасы төлім қатесін айтқан үш класс tweet класын айыру үшін болады. Бұл тапсырма үшін CNN- BiGRU негіздеген екі қарау архитектураларын қолданамыз. Біздің келтірілген архитектурамызды тексеру бағдарламасының эксперименталдық оценкасы бесінші тапсырманың бір көрініс үлгісінде 7% деп жақсы жасайды. Біздің қолданылатын фреймінің коды Github- та қол жеткізілген', 'hu': 'Ez a kutatás egy új, többosztályú osztályozási feladatot (ötödik feladatot) foglalkozik az ötödik Social Media Mining for Health Applications (SMM4H) workshop keretében. Ez az automatikus tweet osztályozási feladat magában foglalja a születési rendellenességeket említő tweet három osztályát. Ehhez a feladathoz egy új két nézet alapú CNN-BiGRU architektúrát javasolunk. Javasolt architektúránk kísérleti értékelése a validálási készleten keresztül bátorító eredményeket eredményez, mivel az ötödik feladat egységes nézetű modelljénél körülbelül 7%-kal javul. Javasolt keretrendszerünk kódja elérhető a Github-on', 'it': 'Questo lavoro di ricerca affronta un nuovo compito di classificazione multi-classe (quinto compito) fornito nel quinto workshop Social Media Mining for Health Applications (SMM4H). Questo compito automatico di classificazione dei tweet comporta la distinzione di tre classi di tweet che menzionano difetti congeniti. Per questo compito proponiamo una nuova architettura basata su due visualizzazioni CNN-BiGRU. La valutazione sperimentale della nostra architettura proposta sul set di validazione dà risultati incoraggianti in quanto migliora di circa il 7% rispetto al nostro modello di visualizzazione singola per il quinto compito. Il codice del framework proposto è disponibile su Github', 'ms': 'Kerja kajian ini mengarahkan tugas kelas berbilang baru (tugas ke-lima) yang diberikan di workshop lima Media Sosial Perlombongan untuk Aplikasi Kesehatan (SMM4H). Tugas kelasukan tweet automatik ini melibatkan membedakan tiga kelas tweet yang menyebutkan cacat lahir. Kami cadangkan arkitektur berdasarkan CNN-BiGRU untuk tugas ini. Experimental evaluation of our proposed architecture over the validation set gives encouraging results as it improves by approximately 7% over our single view model for the fifth task.  Kod kerangka yang kami cadangkan dibuat tersedia pada Github', 'lt': 'Šie moksliniai tyrimai susiję su nauja daugiakalassine klasifikavimo užduotimi (penkta užduotis), atlikta penktajame socialinių žiniasklaidos kasybos programoms sveikatos srityje seminare (SMM4H). Šis automatinis tweeto klasifikavimo uždavinys apima tris tweet ų klases, kuriose nurodomi gimimo defektai. Siūlome naują CNN-BiGRU grindžiamą architektūrą šiai užduotims atlikti. Mūsų siūlomos architektūros eksperimentinis vertinimas dėl patvirtinimo rinkinio duoda palankių rezultatų, nes jis pagerėja maždaug 7 proc., palyginti su mūsų vieno požiūrio modeliu penktojoje užduotyje. Mūsų siūlomos sistemos kodeksas pateikiamas Github tinklalapyje', 'mk': 'Оваа истражувачка работа се обраќа на нова мултикласификациска задача (пета задача) обезбедена на петата работилница за социјално медиумско минирање за здравствени апликации (SMM4H). Оваа автоматска класификација на твит вклучува разлика на три класи твитови кои споменуваат раѓачки дефекти. Предложуваме нова архитектура базирана на CNN-BiGRU за оваа задача. Experimental evaluation of our proposed architecture over the validation set gives encouraging results as it improves by approximately 7% over our single view model for the fifth task.  Кодексот на нашата предложена рамка е достапен на Гитуб', 'ml': 'ഈ പഠനത്തിന്റെ പണിയില്\u200d അഞ്ചാമത്തെ സോഷ്യല്\u200d മീഡിയ മിനിങ്ങില്\u200d സാമൂഹിക പ്രയോഗങ്ങള്\u200dക്ക് വേണ്ടി നല്\u200dകിയ ഒരു പുതിയ ക്ലാസ് ക്ലാസ്ഫി ഈ ടൂട്ടിക്ലാസ്ഫിക്ഷന്\u200d ജോലി മൂന്നു ക്ലാസുകളെ വ്യത്യസ്തമാക്കുന്നത് പ്രസവിക്കുന്നു ഈ ജോലിയ്ക്ക് വേണ്ടി സിഎന്\u200d -ബിജിറൂ അടിസ്ഥാനമായ ഒരു നോവല്\u200d രണ്ട് കാഴ്ചകള്\u200d ഞങ്ങള്\u200d പ്രൊദാനം ചെയ്യുന്നു. നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട ആര്\u200dക്ടിക്കറ്റിന്\u200dറെ പരീക്ഷണത്തിന്\u200dറെ പരീക്ഷണവിശ്വാസം അഞ്ചാമത്തെ ജോലിക്കുള്ള ഒരു കാഴ്ച മോഡലിന ഞങ്ങളുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട ഫ്രെയിമ്പുകളുടെ കോഡ് ഗിത്തുബില്\u200d ലഭ്യമാക്കുന്നു', 'mt': 'Dan ix-xogħol ta’ riċerka jindirizza kompitu ġdid ta’ klassifikazzjoni ta’ diversi klassijiet (il-ħames kompitu) ipprovdut fil-ħames sessjoni ta’ ħidma tal-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (SMM4H). Dan il-kompitu awtomatiku ta’ klassifikazzjoni tat-tweet jinvolvi d-distinzjoni ta’ tliet klassijiet ta’ tweets li jsemmu difetti tat-twelid. Aħna nipproponu arkitetturi ġodda bbażati fuq żewġ fehmiet tas-CNN-BiGRU għal dan il-kompitu. L-evalwazzjoni sperimentali tal-arkitettura proposta tagħna fuq is-sett ta’ validazzjoni tagħti riżultati inkoraġġanti billi ttejjeb b’madwar 7 % fuq il-mudell ta’ viżjoni unika tagħna għall-ħames kompitu. Code of our proposed framework is made available on Github', 'mn': 'Энэ судалгааны ажил 5-р нийгмийн Media Mining for Health Applications (SMM4H) практикийн шинэ олон-класс ангилалын ажил (таван дахь ажил) юм. Энэ автоматически tweet хуваалтын ажил нь төрсөн алдаа гэдгийг хэлэх гурван хэсэг tweet-г ялгах юм. Бид энэ ажил дээр CNN-BiGRU-н суурилсан архитектуруудыг хоёр шинэ санал дэвшүүлж байна. Бидний санал өгсөн архитектурын туршилтын шалгалт нь таван дахь ажил дээрх ойролцоогоор 7%-аас илүү сайжруулдаг. Бидний санал өгсөн хэлбэрийн код Гитюб дээр', 'pl': 'Niniejsze prace badawcze dotyczą nowego wieloklasowego zadania klasyfikacyjnego (piątego zadania) podczas piątego warsztatu Social Media Mining for Health Applications (SMM4H). To automatyczne zadanie klasyfikacji tweetów polega na wyróżnieniu trzech klas tweetów, które wspominają wady wrodzone. Proponujemy do tego zadania nowe architektury oparte na dwóch widoku oparte na CNN-BiGRU. Eksperymentalna ocena naszej proponowanej architektury w zestawie walidacji daje zachęcające wyniki, ponieważ poprawia się ona o około 7% w porównaniu z naszym modelem pojedynczego widoku dla piątego zadania. Kod proponowanego frameworku jest udostępniony na Github', 'ro': 'Această activitate de cercetare abordează o nouă sarcină de clasificare multiclasă (a cincea sarcină) furnizată în cadrul celui de-al cincilea atelier Social Media Mining for Health Applications (SMM4H). Această sarcină automată de clasificare a tweet-urilor implică distingerea a trei clase de tweet-uri care menționează defectele congenitale. Pentru această sarcină propunem o nouă arhitectură bazată pe două vizualizări bazate pe CNN-BiGRU. Evaluarea experimentală a arhitecturii noastre propuse peste setul de validare dă rezultate încurajatoare, deoarece se îmbunătățește cu aproximativ 7% față de modelul nostru de vizualizare unică pentru a cincea sarcină. Codul cadrului propus este disponibil pe Github', 'si': 'මේ පරීක්ෂණ වැඩේ අළුත් විශාල විශේෂණ වැඩ (පහත්වෙනි වැඩ) පහත්වෙනි සාමාජික මාධ්\u200dයාත්මක විශේෂණ වැඩසටහන්  මේ ස්වයංක්\u200dරීය ට්විට් විශේෂණ කාර්යය සම්බන්ධ විශේෂයෙන් විශේෂ කරන්න තුන් විශේෂ තුන් විශ අපි මේ වැඩේ වෙනුවෙන් CNN-BiGRU අධාරිත ස්ථාපනයක් නිර්මාණය දෙකක් ප්\u200dරයෝජනය කරනවා. අපේ ප්\u200dරශ්ණාත්මක විශ්ලේෂණය ගැන පරීක්ෂණාත්මක විශ්ලේෂණය ප්\u200dරශ්ණාත්මක විශ්ලේෂණය සඳහා විශ්වාස කරන්න ප්\u200dරත අපේ ප්\u200dරශ්නය කරපු සංකේතය ගිතුබ් වලින් ප්\u200dරවේශයක් තියෙනවා', 'so': 'Shaqadan waxbarashadu wuxuu ku magacaabaa shaqada fasalka kala duduwan (shaqada shanaad) ee warqadda shabakadda shanaad ee daryeelka caafimaadka ee macluumaadka bulshada (SM4H). Shaqaddan iskuulka ah ee Tweetka waxaa ka mid ah mid kala soocaya saddex fasaladood oo ah twitter oo ku saabsan dhibaatooyin dhalashada. Waxaynu soo jeedaynaa qoraal labaad oo ku saleysan CNN-BiGRU oo lagu saleynayo qoraalkaas. Qiimeynta baaritaanka dhismaha la soo jeeday ee la xaqiijiyey, wuxuu ka helaa resultiyada dhiirigelinta, sababtoo ah waxay ku kordhisaa qiyaastii 7% oo ka kordhisan qaababka aragtideena ee shaqada shanaad. Codeynta shirkadeena la soo jeeday waxaa laga helaa Github', 'sv': 'Detta forskningsarbete behandlar en ny flerklassklassificeringsuppgift (femte uppgift) som gavs vid den femte workshopen Social Media Mining for Health Applications (SMM4H). Denna automatiska tweet klassificering uppgift innebär att skilja tre klasser av tweets som nämner fosterskador. Vi föreslår en ny CNN-BiGRU-baserad arkitektur för denna uppgift. Experimentell utvärdering av vår föreslagna arkitektur över valideringsuppsättningen ger uppmuntrande resultat eftersom den förbättras med cirka 7% jämfört med vår single view modell för den femte uppgiften. Koden för vårt föreslagna ramverk finns tillgänglig på Github', 'no': 'Dette forskningsarbeidet adresserer eit nytt multiklassesklassifikasjonsverktåk (femte oppgåve) som er tilgjengeleg på den femte sosiale mediamining for helseprogramma (SMM4H) arbeidsområdet. Denne automatisk tweet- klassifikasjonsplassen inneheld å distisera tre klasse tweet som mener fødselsdefektar. Vi foreslår eit roman to vising basert på CNN-BiGRU-basert arkitektur for denne oppgåva. Eksperimentalt evaluering av vårt foreslått arkitektur over valeringsinnstillingane gjev encouraging resultat, sidan han forbetrar med omtrent 7 % over vårt enkelt visningsmodul for femte oppgåva. Kode av vår foreslått rammeverket er tilgjengeleg på Github', 'ta': 'இந்த ஆராய்ச்சி வேலை ஐந்தாம் சமூக ஊடகங்களுக்காக வழங்கப்பட்ட ஒரு புதிய பல வகுப்பு வகுப்பு பணியை (ஐந்தாம் செயல்) இந்த தானியங்கி தொடர் வகுப்பு பணி நாம் இந்த பணிக்கான சிஎன்-பிஜிஆர்யு அடிப்படையிலான புதிய இரண்டு பார்வையை பரிந்துரைக்கிறோம். சரிபார்க்கப்படும் அமைப்பின் மீது எங்கள் பரிந்துரைக்கப்பட்ட கட்டுப்பாட்டை பரிசோதிப்பு முடிவுகளை கொடுக்கிறது ஏனென்றால் அது சுக்க Code of our proposed framework is made available on Github', 'sr': 'Ovaj istraživački rad se bavi novim klasifikacijskim zadatkom (petim zadatkom) koji se predstavlja na petom radionici za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H). Ovaj automatski zadatak klasifikacije tweeta uključuje razliku od tri klase tweeta koji spominju defekte rođenja. Predlažemo novu dva pogleda baziranu na CNN-BiGRU-u arhitekture za ovaj zadatak. Eksperimentalna procjena naše predložene arhitekture o setu validacije daje ohrabrujuće rezultate jer se poboljšava za oko 7% nad našim jedinstvenim modelom pogleda za peti zadatak. Kodeks našeg predloženog okvira je dostupan na Githubu.', 'ur': 'This research work addresses a new multi-class classification task (fifth task) provided at the fifth Social Media Mining for Health Applications (SMM4H) workshop. یہ اتماٹی ٹیوٹ کلاسی ٹائٹ کی تابع میں تین کلاس ٹیوٹ کے متعلق تفریق کرتی ہے جو جنتی ناکام ہیں۔ ہم نے اس کام کے لئے ایک نومین دو نظر کی پیشنهاد کریں جو CNN-BiGRU بنیاد ہے۔ ہمارے مقرر کردہ معماری کی آزمائش کا تحقیق پانچویں کام کے لئے پانچویں نمڈل پر تقریباً 7% سے بہتر ہوتا ہے۔ ہمارے مقرر کردہ فرم کا کوڈ Github پر موجود ہے', 'uz': "Bu taʼminlovchi vazifani 5. Social Media dasturlari (SMM4H) workshopidagi boshqa bir nechta klassifning vazifasi (5- chi vazifasi) yaratadi. Bu avtomatik Twitterning classification vazifasi tug'ilgan uchta sinfni o'zgartirish mumkin. Biz bu vazifani uchun CNN-BiGRU asosida yaratilgan ikki koʻk koʻrinishini tahlil qilamiz. Tasdiqlash tugmasini tasdiqlashni tasdiqlash muvaffaqiyatli natijalariga yetarli natijalarni bajaradi, chunki u 5 ta vazifaning birinchi birinchi koʻrinish modelimizdan 7% bajaradi. Name", 'vi': 'Công trình nghiên cứu này thực hiện một nhiệm vụ phân loại đa hạng mới (nhiệm vụ thứ năm) được tổ chức tại xưởng ứng dụng sức khỏe (SMM4H). Việc phân loại tweet tự động này có nghĩa là phân biệt ba loại tweet mà đề cập đến các khuyết điểm bẩm sinh. Chúng tôi đề nghị một kiến trúc dựa trên kênh CNN-Bicu mới cho nhiệm vụ này. Thí nghiệm đánh giá kiến trúc vốn đã đề nghị của chúng ta trên bộ sửa chữa sẽ có kết quả tích cực khi tiến bộ hơn khoảng 7. Trên mô hình duy nhất của chúng ta cho nhiệm vụ thứ năm. Mã bộ khung đã đề nghị của chúng ta được phát hành ở GitHub.', 'bg': 'Тази изследователска работа разглежда нова многокласна задача за класификация (пета задача), предоставена на петия семинар "Социални медии за минно дело за здравни приложения" (СММ4Х). Тази задача за автоматично класифициране на туитове включва разграничаване на три класа туитове, които споменават вродени дефекти. Предлагаме нова архитектура базирана на два вида за тази задача. Експерименталната оценка на предложената ни архитектура върху набора от валидиране дава окуражаващи резултати, тъй като се подобрява с приблизително 7% спрямо нашия модел за единно виждане за петата задача. Кодът на предложената ни рамка е достъпен в Гитхъб', 'da': 'Dette forskningsarbejde omhandler en ny klassifikationsopgave i flere klasser (femte opgave) leveret på den femte workshop Social Media Mining for Health Applications (SMM4H). Denne automatiske tweet klassifikationsopgave indebærer at skelne mellem tre klasser af tweets, der nævner fødselsdefekter. Vi foreslår en ny to view baserede CNN-BiGRU-baserede arkitekturer til denne opgave. Eksperimentel evaluering af vores foreslåede arkitektur over valideringssættet giver opmuntrende resultater, da den forbedres med ca. 7% i forhold til vores single view model for den femte opgave. Kode for vores foreslåede ramme er gjort tilgængelig på Github', 'nl': 'Dit onderzoek richt zich op een nieuwe multi-class classificatietaak (vijfde taak) die wordt aangeboden tijdens de vijfde Social Media Mining for Health Applications (SMM4H) workshop. Deze automatische tweetclassificatietaak omvat het onderscheiden van drie klassen tweets die geboorteafwijkingen vermelden. Voor deze taak stellen we een nieuwe twee view gebaseerde CNN-BiGRU architectuur voor. Experimentele evaluatie van onze voorgestelde architectuur over de validatieset geeft bemoedigende resultaten, aangezien deze met ongeveer 7% verbetert ten opzichte van ons single view model voor de vijfde taak. Code van ons voorgestelde framework is beschikbaar op Github', 'de': 'Diese Forschungsarbeit befasst sich mit einer neuen Mehrklassenklassifikationsaufgabe (fünfte Aufgabe), die im fünften Workshop Social Media Mining for Health Applications (SMM4H) angeboten wird. Bei dieser automatischen Tweet-Klassifikationsaufgabe werden drei Kategorien von Tweets unterschieden, die Geburtsfehler erwähnen. Für diese Aufgabe schlagen wir eine neuartige zweisichtige CNN-BiGRU basierte Architektur vor. Die experimentelle Bewertung unserer vorgeschlagenen Architektur über den Validierungssatz liefert ermutigende Ergebnisse, da sie sich gegenüber unserem Single View Modell für die fünfte Aufgabe um etwa 7% verbessert. Der Code unseres vorgeschlagenen Frameworks ist auf Github verfügbar', 'hr': 'Ovaj istraživački rad rješava novi zadatak za klasifikaciju višeklase (peti zadatak) koji je određen na petom radionici za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H). Ovaj automatski zadatak klasifikacije tweeta uključuje razliku od tri klase tweeta koji spominju poremećaje rođenja. Predlažemo novu dva pogleda baziranu na CNN-BiGRU-u arhitekture za ovaj zadatak. Eksperimentalna procjena naše predložene arhitekture o setu validacije pruža ohrabrujuće rezultate jer se poboljšava oko 7% nad našim jedinstvenim modelom pogleda za peti zadatak. Kodeks našeg predloženog okvira je dostupan na Githubu', 'id': 'Pekerjaan penelitian ini mengatasi tugas klasifikasi multikelas baru (tugas kelima) yang disediakan di workshop lima Social Media Mining for Health Applications (SMM4H). Tugas klasifikasi tweet otomatis ini melibatkan membedakan tiga kelas tweet yang menyebutkan cacat lahir. Kami mengusulkan sebuah novel dua pandangan berdasarkan arsitektur berdasarkan CNN-BiGRU untuk tugas ini. Evaluasi eksperimental dari arsitektur kami yang diusulkan atas set validasi memberikan hasil yang mendorong karena itu meningkat sekitar 7% atas model pandangan tunggal kami untuk tugas kelima. Kode dari cadangan kami yang diusulkan dibuat tersedia di Github', 'tr': 'Bu araştırma işi beşinji sosyal Media Ködleme Saýlaw Uygulamalary (SMM4H) bellenilýär. Bu otomatik tweet klasifikasiýasy täzelikleriniň doglan maslahatlaryny aýlaýan üç topar tweet täzeliklerini meňzeýär. CNN-BiGRU tabanly arhitektura bu zadyň üçin iki romany teklip edip berýäris. Taýýarlama takmyny barada teklip eden arhitekturymyzyň synanyşdyrylmagynyň üýtgetmesi üçin 5-nji zadyň ýeke görnüş nusgasymyzda 7%-den gowy bolýar. Githubde tapılan teklif edilen çerçewçimiziň kody', 'ko': '이 연구는 제5회 건강 응용 소셜미디어 발굴(SMM4H) 세미나에서 제공된 새로운 다종류 분류 임무(다섯 번째 임무)와 관련된다.이 자동 추문 분류 임무는 출생 결함을 언급한 세 가지 추문을 구분하는 것과 관련된다.이를 위해 우리는 새로운 이중시도 기반의 CNN-BiGRU 체계 구조를 제시했다.검증집에서 우리가 제시한 구조에 대한 실험 평가는 다섯 번째 임무에서 우리의 단시도 모델보다 약 7% 높아진 고무적인 결과를 얻었다.Github에서 사용할 수 있는 프레임워크 코드', 'fa': 'این کار تحقیقات در کارگاه پنجم رسانه رسانه اجتماعی برای کاربردهای سلامتی (SMM4H) یک کار جدید کلاس جدید (کار پنجم) را دریافت می\u200cکند. این وظیفه جدا کردن توئیت اتوماتیک شامل جدا کردن سه کلاس توئیت که در مورد شکست تولد اشاره می\u200cکند. ما پیشنهاد می\u200cکنیم یک رمان دو دید بر اساس معماری بنیاد CNN-BiGRU برای این کار. ارزیابی تجربه\u200cای از معماری پیشنهاد ما بر روی مجموعه تأثیر دادن نتیجه\u200cهای تشویق\u200cکننده را می\u200cدهد چون تقریباً ۷ درصد بر روی مدل نظر تنها ما برای کار پنجم بهتر می\u200cشود. کد چهارچوب پیشنهاد ما در Github موجود است', 'sw': 'This research work addresses a new multi-class classification task (fifth task) provided at the fifth Social Media Mining for Health Applications (SMM4H) workshop.  Kazi hii ya usambazaji wa twita ya kibinafsi inahusisha kutofautisha darasa tatu la twiti ambazo zinaeleza tatu za kuzaliwa. Tupendekeza mtazamo wa riwaya mbili anayeishi CNN-BiGRU kwa ajili ya kazi hii. Tathmini za mazingira yetu ya pendekezo juu ya kituo hiki kinachothibitishwa inaleta matokeo ya kusisimua kwa sababu inaongezeka kwa takriban asilimia 7 juu ya mtindo wetu wa mtazamo wa juhudi la tano. Utawala wa mfumo wetu unapendekezwa umepatikana kwenye Github', 'am': 'ይህ ትምህርት ሥራ በአምስተኛው ማኅበራዊ ሚዲያ ለጤና ፕሮግራሞች (SMM4H) workshop ላይ የተሰኘውን አዲስ ብዙዎች ተለያይነት አድራጊ (አምስተኛ ስራ) አድራጊ ነው፡፡ ይህ ትዊተር መግለጫ ስራ የተወለደውን ስህተት የሚያሳውሱትን ሦስት ደረጃዎች ለመለየት ይገባል፡፡ ለዚህ ስራ የCNN-BiGRU የተመሠረተውን የመረጃ መሠረት ላይ የተመሳሳይ ሁለት የኖሮውን ተመልከት እናሳልቃለን፡፡ በአምስተኛው ስራ ላይ የአንድ መልዕክታችን ምሳሌ በሚያሳድግ 7 በመቶ የሚያሳድገው ፍሬዎችን ያበረታል፡፡ Code of our proposed framework is made available on Github', 'af': "Hierdie ondersoek werk adres 'n nuwe multiklasklasklas klassifikasie taak (vyfde taak) verskaf by die vyfde sosiale media mining vir gesondige toepassings (SMM4H) werkskerm. Hierdie outomatiese tweet klassifikasie taak involveer die uitdeling van drie klasse tweet wat geboorte defekte bepaal. Ons voorstel 'n roman twee besigtig gebaseerde CNN-BiGRU gebaseerde arkitektuur vir hierdie taak. Eksperimentele evaluering van ons voorgestelde arkitektuur oor die geldigheidstel gee encouraging resultate as dit verbeter deur omtrent 7% oor ons enkele aansig model vir die vyfde taak. Kode van ons voorgestelde raamwerk is beskikbaar op Github", 'hy': 'Այս հետազոտությունները վերաբերում են նոր բազմադասարանային դասակարգման խնդիրներին (հինգերորդ խնդիրը), որը տրամադրվել է հինգերորդ աշխատասենյակում "Սոցիալական մեդիայի հանքարում առողջապահության ծրագրերի համար" (SM Այս ավտոմատ թվիթերի դասակարգման խնդիրը ներառում է երեք դասակարգ թվիթերի, որոնք նշում են ծննդյան թերություններ: Մենք առաջարկում ենք CNN-ԲիGRU-ի հիմնված երկու տեսանկյունից հիմնված նոր ճարտարապետություններ այս խնդրի համար: Մեր առաջարկված ճարտարապետության փորձարկման գնահատումը հավասարակշռության ընթացքում խրախուսափելի արդյունքներ է տալիս, քանի որ այն բարելավվում է մոտավորապես 7 տոկոսով հինգերորդ խնդրի ընթացքում: Մեր առաջարկած շրջանակի կոդը հասանելի է Գիթուբի վրա,', 'sq': 'Ky punë kërkimor trajton një detyrë të re klasifikuese shumë-klasësh (detyrë e pestë) të ofruar në seminarin e pestë të Minimit të Mediave Sociale për Aplikacionet Shëndetësore (SMM4H). Kjo detyrë automatike klasifikimi i tweetit përfshin dallimin e tre klasave të tweetit që përmendin defektet e lindjes. Ne propozojmë një novel dy pikëpamje të bazuar në arkitektura bazuar në CNN-BiGRU për këtë detyrë. Vlerësimi eksperimental i arkitekturës sonë të propozuar mbi kompletin e vlerësimit jep rezultate inkurajuese ndërsa përmirësohet me rreth 7% mbi modelin tonë të vetëm të pamjes për detyrën e pestë. Kodi i kuadrit tonë të propozuar është bërë në dispozicion në Github', 'az': 'Bu araştırma işləri beşinci sosyal Media Mining for Health Applications (SMM4H) çalışmalarında təmin edilən yeni çoxlu sınıf klasifikasyon işləri (beşinci görev) ilə müvəffəq edir. Bu avtomatik twet klasifikasiyası işləri doğum günahlarını söyləyən üç sınıf twet tərzlərini ayırmaqdır. Biz bu işin CNN-BiGRU tabanlı iki yeni görünüş arhitektarını təklif edirik. Bizim təklif etdiyimiz arhitektüyün təcrübəsinin təcrübəsinin təcrübəsini təcrübəsinin təcrübəsini verir, çünki o, beşinci iş üçün yalnız görüş modelimizdən 7%-dən artırır. Bizim təbliğ etdiyimiz frameworklərimizin kodu Github üçün faydalanır.', 'bn': 'এই গবেষণার কাজ পাঁচ সোশ্যাল মিডিয়া মিডিয়া মিনিং ফর স্বাস্থ্য অ্যাপ্লিকেশন (এমএম৪H) কর্মশালায় একটি নতুন মাল্টিক শ্রেণীবিভাগ কা এই স্বয়ংক্রিয়ভাবে টুইট বিভাগের কাজের মধ্যে তিন শ্রেণীর টুইট বিচ্ছিন্ন করা হয়েছে যারা জন্মের সমস্যা উল্লেখ কর আমরা এই কাজের জন্য সিএনএন-বিজিআরউ ভিত্তিক কাঠামো ভিত্তিক একটি উপন্যাস প্রস্তাব করি। আমাদের প্রস্তাবিত প্রতিষ্ঠানের পরীক্ষার পরীক্ষার পরীক্ষা প্রদান করা হয়েছে বৈধ সেটের বিষয়টি উৎসাহিত ফলাফল দেয় যেহেতু এটি প্রায় ৭% ব আমাদের প্রস্তাবিত ফ্রেম কোড গিথুবে পাওয়া যায়', 'cs': 'Tato výzkumná práce se zabývá novým vícetřídním klasifikačním úkolem (pátým úkolem) poskytovaným na pátém workshopu Social Media Mining for Health Applications (SMM4H). Tento úkol automatické klasifikace tweetů zahrnuje rozlišení tří tříd tweetů, které zmiňují vrozené vady. Pro tento úkol navrhujeme nové architektury založené na dvou pohledech založené na CNN-BiGRU. Experimentální vyhodnocení naší navrhované architektury v rámci validační sady přináší povzbuzující výsledky, protože se zlepšuje přibližně o 7% oproti našemu modelu jednoho pohledu pro pátý úkol. Kód našeho navrhovaného frameworku je zpřístupněn na Githubu', 'bs': 'Ovaj istraživački rad se bavi novim multiklasičnim klasičnim klasičnim zadatkom (petim zadatkom) koji je predstavljen na petom radionici za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H). Ovaj automatski zadatak klasifikacije tweeta uključuje razliku od tri klase tweeta koji spominju poremećaje rođenja. Predlažemo novu dva pogleda baziranu na CNN-BiGRU-u arhitekture za ovaj zadatak. Eksperimentalna procjena naše predložene arhitekture o setu validacije daje ohrabrujuće rezultate jer se poboljšava za oko 7% nad našim jedinstvenim modelom pogleda za peti zadatak. Kodeks našeg predloženog okvira je dostupan na Githubu', 'et': 'K瓣esolev uurimist繹繹 k瓣sitleb uut mitmeklassilist klassifitseerimis羹lesannet (viies 羹lesanne), mida pakutakse viiendal sotsiaalmeedia kaevandamisel tervise rakenduste jaoks (SMM4H) seminaril. See automaatne s瓣utsu klassifitseerimis羹lesanne h繭lmab kolme klassi s瓣utsu eristamist, mis mainivad s羹nnidefekte. Selle 羹lesande jaoks pakume v瓣lja uudsed kahel vaatel p繭hinevad CNN-BiGRU-p繭hised arhitektuurid. Meie kavandatud arhitektuuri eksperimentaalne hindamine valideerimiskomplekti 羹le annab julgustavaid tulemusi, kuna see paraneb viienda 羹lesande puhul ligikaudu 7%. Meie pakutud raamistiku kood on k瓣ttesaadav Githubis', 'ca': "Aquesta investigació aborda una nova tasca de classificació multiclasse (quinta tasca) proporcionada en el quint taller Social Media Mining for Health Applications (SMM4H). Aquesta tasca automàtica de classificació de tweets implica distingir tres classes de tweets que mencionen defectes de nasciment. Proposem una nova arquitectura basada en CNN-BiGRU per a aquesta tasca. L'evaluació experimental de la nostra arquitectura proposada sobre el conjunt de validació dóna resultats encorajadors mentre millora aproximadament un 7% sobre el nostre model de visió única de la quinta tasca. Code of our proposed framework is made available on Github", 'fi': 'Tﾃ､mﾃ､ tutkimustyﾃｶ kﾃ､sittelee viidennessﾃ､ Social Media Mining for Health Applications (SMM4H) -tyﾃｶpajassa jﾃ､rjestettyﾃ､ uutta moniluokkaista luokittelutehtﾃ､vﾃ､ﾃ､ (viides tehtﾃ､vﾃ､). Tﾃ､ssﾃ､ automaattisessa twiittiluokittelutehtﾃ､vﾃ､ssﾃ､ erotetaan kolme twiittiluokkaa, joissa mainitaan synnynnﾃ､isiﾃ､ vikoja. Tﾃ､hﾃ､n tehtﾃ､vﾃ､ﾃ､n ehdotamme uudenlaista, kahteen nﾃ､kymﾃ､ﾃ､n perustuvaa CNN-BiGRU-pohjaista arkkitehtuuria. Ehdotetun arkkitehtuurin kokeellinen arviointi validoinnin yhteydessﾃ､ antaa rohkaisevia tuloksia, sillﾃ､ se paranee noin 7% viidennen tehtﾃ､vﾃ､n yhden nﾃ､kymﾃ､n malliin verrattuna. Ehdotetun kehyksen koodi on saatavilla Githubissa', 'sk': 'Raziskovalno delo obravnava novo večrazredno klasifikacijsko nalogo (peta naloga), ki je potekala na peti delavnici Družbenih medijev rudarjenje za zdravstvene aplikacije (SMM4H). Ta avtomatska naloga klasifikacije tweetov vključuje razlikovanje treh razredov tweetov, ki omenjajo prirojene napake. Za to nalogo predlagamo nove arhitekture, ki temeljijo na dveh pogledih CNN-BiGRU. Eksperimentalno vrednotenje naše predlagane arhitekture nad naborom validacij daje spodbudne rezultate, saj se izboljša za približno 7% glede na naš model enotnega pogleda za peto nalogo. Koda našega predlaganega okvira je na voljo na Githubu', 'ha': 'Wannan aikin research yana addressa wani new aikin fassarar-multi-daraja (na shan aikin) wanda aka samar da shi a shan-shekara na SMM4H worknin na SMM4H. Wannan aikin classified na Twitter farat ɗaya yana cikin rarraba darafõji uku na Twitter waɗanda ke faɗa mistakardar haihuwa. Tuna goyyar da wani matsayi biyu a kan CNN-BiGRU masu bakin filinaiki na wannan aikin. Kayan karatun matsayinmu da aka buƙata in tsarin da aka gaskata, yana da fassarar mai fari, kamar yana ƙara shi takwai 7% a kan misalin gani guda wa aikin shanbe. Kodi na firam da aka buƙata kan GiThb', 'jv': 'Awakdhéwé nggawe barêng-barêng kuwi wis ana karbot task gawe multi-klase sing dibenalke (tanggal 5) sing nyimpen ning petih Media Minng kanggo Kebebasan Application (SMM4H). Awak dhéwé éntuk sistem sing nyelaranggunaké wis ngerasai tanggal telu kelas nang tuwit sing bisa nyimpen winih. Awak dhéwé nggunakake kuwi nyumbang kelompok durung tapi wis sabanjur online-BigruU architectures kanggo nggawe barang iki. wektu Kod sing dibutuhke rampungan sing dibutuhke nang Gethob', 'he': 'עבודת המחקר הזאת מתייחסת למשימה חדשה של שיעור מסוים רבים (משימה חמישית) שנוספת במסעדה החמישית של מחקר תקשורת בריאות (SMM4H). משימה ההקלטה האוטומטית הזו של טוויט כוללת להבחין שלושה כיסות של טוויטים שמזכירים פגיעות לידה. אנו מציעים ארכיטקטורות בסיסית CNN-BiGRU רומן שניים למשימה זו. Experimental evaluation of our proposed architecture over the validation set gives encouraging results as it improves by approximately 7% over our single view model for the fifth task.  קוד המסגרת המוצעת שלנו מופעל על Github', 'bo': 'འཚོལ་ཞིབ་ཀྱི་ལས་འཚོལ་བ་འདིས་སྒྲུབ་གྲྭར་གྱི་དབྱེ་རིམ་གསར་པ་ཞིག་ལ་འཇུག་བྱེད་ཀྱི་ལས་འཚོལ་ཞིག་གནང་། རང་འགུལ་གྱིས་འགོད་པའི་དྲ་རྒྱའི་དབྱེ་སྟངས་དེ་ལ་བཟོ་བར་མཁན་གྱི་དབྱེ་རིགས་གསུམ་ཡོད། ང་ཚོས་ཀློག་ཚུལ་ལྟ་བུ་གཉིས་པ་རྩིས་གཞི་བྱས་པའི་CNN-BiGRU་གཞི་བཟོ་སྒྲིག་ཆ་རྩིས་འདི་དང་བསམ ང་ཚོའི་དམིགས་འཛུགས་ཀྱི་སྒྲིག་འཛིན་གྱི་གསལ་བཤད་ཀྱི་ལས་རྐྱེན་གྱིས་མཐོང ང་ཚོའི་འཆར་བཀོད་པའི་བཀོད་སྒྲིག་གཞུང་གི་ཨིན་རྟགས་Github ལས་སྤྱོད་ཐུབ་པ་རེད།'}
{'en': 'LITL at SMM4H : An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets LITL  at  SMM 4 H : An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets', 'ar': 'LITL في SMM4H: مُصنِّف قائم على ميزات المدرسة القديمة لتحديد التأثيرات العكسية في التغريدات', 'es': 'LITL en SMM4H: un clasificador basado en funciones de la vieja escuela para identificar los efectos adversos en los tuits', 'fr': "LITL au SMM4H\xa0: un classificateur basé sur des fonctionnalités à l'ancienne pour identifier les effets indésirables dans les tweets", 'pt': 'LITL no SMM4H: um classificador baseado em recursos da velha escola para identificar efeitos adversos em tweets', 'zh': 'SMM4H之LITL:一者,老式类也,所以知推文之不利也', 'ja': 'SMM 4 HのLITL ：ツイートの有害作用を識別するための旧式の機能ベースの分類子', 'hi': 'SMM4H में LITL: Tweets में प्रतिकूल प्रभावों की पहचान करने के लिए एक पुराने स्कूल फीचर-आधारित क्लासिफायर', 'ru': 'LITL на SMM4H: классификатор на основе старой школы для выявления нежелательных эффектов в твитах', 'ga': 'LITL ag SMM4H: Aicmitheoir Gné-Bhunaithe Seanscoile chun Éifeachtaí Díobhálacha a Aithint in Tweets', 'hu': 'LITL az SMM4H-nál: Egy régimódi funkcióalapú hirdető a mellékhatások felismerésére Tweetekben', 'ka': 'Name', 'el': 'Ένας κλασσικός ταξινομητής με βάση χαρακτηριστικά για τον εντοπισμό δυσμενών επιπτώσεων στα tweets', 'it': 'LITL a SMM4H: un annuncio basato su funzionalità old-school per identificare gli effetti avversi nei tweet', 'kk': 'SMM4H: Ескі мектепте қасиеттер негіздеген классификаторыName', 'mk': 'LITL на SMM4H: Класификатор базиран на старо училиште за идентификување на негативни ефекти на твитови', 'ms': 'Name', 'ml': 'SM4H-ലെ ലിറ്റിഎല്\u200d: ടൂട്ടുകളിലെ പ്രഭാവങ്ങള്\u200d തിരിച്ചറിയുന്നതിനുള്ള ഒരു പഴയ സ്കൂളിലെ വിശേഷതകള്\u200d ക്ലാസിഫയര്\u200d', 'mt': 'LITL fl-SMM4H: Klassifikatur ibbażat fuq il-karatteristiċi tal-iskejjel l-qodma għall-identifikazzjoni tal-effetti avversi fit-Tweets', 'mn': 'SMM4H дээр LITL: Хууд сургуулийн Feature-based Classifier for Identifying Adverse Effects in Tweets', 'no': 'Name', 'pl': 'LITL w SMM4H: klasyfikator oparty na starej szkole funkcji do identyfikowania niekorzystnych skutków w tweetach', 'lt': 'LITL SMM4H: Senosios mokyklos savybėmis pagrįstas klasifikatorius, skirtas nustatyti nepageidaujamus poveikius Tweetuose', 'ro': 'LITL la SMM4H: Un clasificator de școală veche bazat pe caracteristici pentru identificarea efectelor adverse în tweets', 'sr': 'LITL na SMM4H: Klasifikator na osnovu stare škole za identifikaciju nuspojava u Tweets-u', 'si': 'LITL at SMM4H: A Old-School Featuration-based ClassiferName', 'so': 'LITL at SMM4H: An old-school Featuritory-based classifier for identifying Adverse Effects in Tweets', 'sv': 'LITL på SMM4H: En gammaldags funktionsbaserad annonsör för att identifiera negativa effekter i tweets', 'ur': 'Name', 'ta': 'SM4H-ல் LITL: குழந்தைய பள்ளிக்கு சார்ந்த வகுப்பாட்டிற்கான முன்னோட்டு விளைவுகளை அடையாளமாக்கு', 'uz': 'Name', 'vi': 'LLOL at SMM4H: Một bộ nhớ đặc trưng theo trường cũ để xác định tác động xấu trong Tweet', 'nl': 'LITL op SMM4H: Een ouderwetse functie-gebaseerde classificator voor het identificeren van negatieve effecten in Tweets', 'da': 'LITL på SMM4H: En gammeldags Feature-baseret Classifier til identificering af negative effekter i tweets', 'hr': 'LITL na SMM4H: Klasifikator za identifikaciju nuspojava na staroj školi u Tweets-u', 'bg': 'Класификатор, базиран на старата школа, за идентифициране на нежелани ефекти в туитове', 'id': 'LITL di SMM4H: A Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets', 'de': 'LITL auf der SMM4H: Ein Old-School Feature-basierter Klassifizierer zur Erkennung unerwünschter Effekte in Tweets', 'ko': 'SMM4H의 LITL: 트윗의 잘못된 영향을 식별하는 데 사용되는 오래된 특징 기반 분류기', 'fa': 'Name', 'af': 'Name', 'sw': 'LITL kwenye SMM4H: Mshitimu anayeishi Shule ya Kizamani kwa Kutambua Matokeo ya Biashara katika Twita', 'sq': 'LITL në SMM4H: Një klasifikues i shkollës së vjetër për identifikimin e efekteve të dëmshme në Tweets', 'am': 'በSM4H ላይ LITL: የሽማግሌ ትምህርት-ትምህርት ፍትሕርት በሚያሳውቅ የሽማግሌ ትዊተሮች ላይ የፊተኝነትን ማወቅ', 'hy': 'ԼիՏԼ SMM4H-ում. Հին դպրոցի ֆունկցիաների հիմնված դասակարգիչ, որը օգտագործում է թվիթերում բացահայտելու համար', 'az': "SMM4H'də LITL: Tweets içində keçmiş məktəb təhsil-tabanlı Klasifəçi", 'bn': 'SM4H-এ লিটিএল: টুইটে পুরোনো স্কুলের বৈশিষ্ট্যাবলী ভিত্তিক ক্লাসিফারের জন্য টুইটারে প্রভাব চিহ্নিত করার জন্য', 'tr': 'LITL at SMM4H: An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets', 'bs': 'LITL na SMM4H: Klasifikator za identifikaciju nuspojava na staroj školi u Tweets-u', 'ca': "LITL a SMM4H: Un classificador basat en les característiques de l'antiga escola per identificar efectes adversos en tweets", 'cs': 'LITL na SMM4H: Old-school klasifikátor založený na funkcích pro identifikaci nežádoucích účinků ve tweetech', 'et': 'LITL SMM4H: Vanakooli funktsioonipõhine klassifikaator kõrvaltoimete tuvastamiseks tweetides', 'fi': 'LITL at SMM4H: Vanhan koulukunnan ominaisuuspohjainen luokitus haitallisten vaikutusten tunnistamiseen tweeteissä', 'ha': 'LITL at SMM4H: An Old-School-based Classifier for Idertain Adverse Effects in Twitter', 'he': 'LITL ב SMM4H: מסווג מבוסס על תכונות בית הספר הישן לזהות השפעות הלא נעימות בטוויטים', 'sk': 'LITL na SMM4H: Old-school Feature-based Classifier za prepoznavanje škodljivih učinkov v tweets', 'bo': 'LITL at SMM4H: An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets', 'jv': 'LITIL nang SMM4H: an older-scale'}
{'en': 'This paper describes our participation to the SMM4H shared task 2. We designed a rule-based classifier that estimates whether a tweet mentions an adverse effect associated to a medication. Our system addresses  English  and  French , and is based on a number of specific word lists and features. These cues were mostly obtained through an extensive corpus analysis of the provided training data. Different  weighting schemes  were tested (manually tuned or based on a logistic regression), the best one achieving a  F1 score  of 0.31 for  English  and 0.15 for  French .', 'ar': 'تصف هذه الورقة مشاركتنا في المهمة المشتركة SMM4H 2. لقد صممنا مصنفًا قائمًا على القواعد لتقدير ما إذا كانت إحدى التغريدات تشير إلى تأثير سلبي مرتبط بأحد الأدوية. يتناول نظامنا اللغتين الإنجليزية والفرنسية ، ويستند إلى عدد من قوائم الكلمات والميزات المحددة. تم الحصول على هذه الإشارات في الغالب من خلال تحليل شامل لمجموعة بيانات التدريب المقدمة. تم اختبار مخططات ترجيح مختلفة (تم ضبطها يدويًا أو بناءً على الانحدار اللوجستي) ، وحقق أفضلها درجة F1 تبلغ 0.31 للغة الإنجليزية و 0.15 للفرنسية.', 'es': 'Este documento describe nuestra participación en la tarea compartida 2 del SMM4H. Diseñamos un clasificador basado en reglas que estima si un tuit menciona un efecto adverso asociado a un medicamento. Nuestro sistema aborda el inglés y el francés, y se basa en una serie de funciones y listas de palabras específicas. Estas señales se obtuvieron principalmente a través de un extenso análisis de corpus de los datos de entrenamiento proporcionados. Se probaron diferentes esquemas de ponderación (ajustados manualmente o basados en una regresión logística), el mejor logró una puntuación F1 de 0.31 para el inglés y 0.15 para el francés.', 'fr': "Cet article décrit notre participation à la tâche partagée 2 du SMM4H. Nous avons conçu un classificateur basé sur des règles qui estime si un tweet mentionne un effet indésirable associé à un médicament. Notre système traite l'anglais et le français et repose sur un certain nombre de listes de mots et de fonctionnalités spécifiques. Ces indices ont été principalement obtenus grâce à une analyse approfondie du corpus des données de formation fournies. Différents schémas de pondération ont été testés (réglés manuellement ou basés sur une régression logistique), le meilleur ayant obtenu un score F1 de 0,31 pour l'anglais et de 0,15 pour le français.", 'pt': 'Este artigo descreve nossa participação na tarefa compartilhada 2 do SMM4H. Criamos um classificador baseado em regras que estima se um tweet menciona um efeito adverso associado a um medicamento. Nosso sistema aborda inglês e francês e é baseado em várias listas de palavras e recursos específicos. Essas pistas foram obtidas principalmente por meio de uma extensa análise de corpus dos dados de treinamento fornecidos. Diferentes esquemas de ponderação foram testados (ajustados manualmente ou com base em uma regressão logística), o melhor alcançando uma pontuação F1 de 0,31 para inglês e 0,15 para francês.', 'ja': '本稿では、SMM 4 H共有タスク2への参加について説明します。私たちは、ルールベースの分類器を設計し、ツイートが薬に関連する有害作用に言及しているかどうかを推定しました。当社のシステムは英語とフランス語に対応しており、いくつかの特定の単語リストと機能に基づいています。これらの手がかりは、提供されたトレーニングデータの膨大なコーパス分析を通じて得られたものがほとんどである。さまざまな重み付けスキームを試験した（手動で調整するか、ロジスティック回帰に基づいて調整した）。最良のものは、英語では0.31、フランス語では0.15のF 1スコアを達成した。', 'zh': '本文述我参SMM4H之共同任务2。 设一法之器,以度推文药之不良反应。 吾之统英语法语,盖众特定之单词表能也。 凡此诸线,广其训练数语料库也。 试异加权方案(手动调或基于逻辑归),最上加权方案于英语中至0.31F1分数,法语至0.15。', 'hi': 'यह पेपर SMM4H साझा कार्य 2 के लिए हमारी भागीदारी का वर्णन करता है। हमने एक नियम-आधारित क्लासिफायर डिज़ाइन किया है जो अनुमान लगाता है कि क्या एक ट्वीट में दवा से जुड़े प्रतिकूल प्रभाव का उल्लेख है। हमारा सिस्टम अंग्रेजी और फ्रेंच को संबोधित करता है, और कई विशिष्ट शब्द सूचियों और सुविधाओं पर आधारित है। इन संकेतों को ज्यादातर प्रदान किए गए प्रशिक्षण डेटा के व्यापक कॉर्पस विश्लेषण के माध्यम से प्राप्त किया गया था। विभिन्न भार योजनाओं का परीक्षण किया गया था (मैन्युअल रूप से ट्यून किया गया या लॉजिस्टिक प्रतिगमन के आधार पर), अंग्रेजी के लिए 0.31 और फ्रेंच के लिए 0.15 का एफ 1 स्कोर प्राप्त करने वाला सबसे अच्छा।', 'ru': 'В этом документе описывается наше участие в совместной задаче 2 SMM4H. Мы разработали основанный на правилах классификатор, который оценивает, упоминает ли твит неблагоприятный эффект, связанный с лекарством. Наша система ориентирована на английский и французский языки и основана на ряде конкретных списков слов и особенностей. Эти подсказки в основном были получены в результате обширного анализа предоставленных учебных данных. Были протестированы различные схемы взвешивания (вручную настроенные или основанные на логистической регрессии), лучшая из которых достигла F1 0,31 для английского языка и 0,15 для французского.', 'ga': 'Déanann an páipéar seo cur síos ar ár rannpháirtíocht i dtasc comhroinnte SMM4H 2. Dhearamar aicmitheoir bunaithe ar rialacha a dhéanann meastachán ar cibé an luann tweet drochthionchar a bhaineann le cógas. Tugann ár gcóras aghaidh ar an mBéarla agus ar an bhFraincis, agus tá sé bunaithe ar roinnt liostaí focal agus gnéithe sonracha. Fuarthas na leideanna seo go príomha trí anailís corpais fhairsing ar na sonraí oiliúna a cuireadh ar fáil. Tástáladh scéimeanna éagsúla ualaithe (de láimh nó bunaithe ar aischéimniú lóistíochta), fuair an ceann ab fhearr scór F1 de 0.31 don Bhéarla agus 0.15 don Fhraincis.', 'ka': 'ამ დოკუმენტი ჩვენი მოწყობილობას SMM4H-ის გაყოფილი საქმე 2-ზე. ჩვენ განაზღვრეთ კლასიფიკაცია, რომელიც განაზღვრება, თუ რაიმე ტვიტი ამბობს განაზღვრებული ეფექტი, რომელიც მედიციაციისთვის დაკავშირებული. ჩვენი სისტემა ინგლისური და ფრანგური მისამართებულია, და რამდენიმე სპექტიფიკური სიტყვების სიტყვების და ფონგური სიტყვების მისა ეს სინაცემები უფრო მეტი იღებულია, რომელსაც უფრო დიდი კორპუსს ანალიზაციით, რომელსაც მომხმარებული განაკლების მონაცემები. განსხვავებული განსაზღვრებული სქემები ტესტირებულია (მანძილურად განსაზღვრებულია ან ლოგისტიკური რეგრესიის დაბაზულია), ყველაზე საუკეთესო სქემები, რომელიც F1 წერტილის 0,31 წერტილი', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή μας στο κοινό έργο 2. Σχεδιάσαμε έναν ταξινομητή βασισμένο σε κανόνες που εκτιμά αν ένα tweet αναφέρει μια ανεπιθύμητη επίδραση που σχετίζεται με ένα φάρμακο. Το σύστημά μας απευθύνεται στα αγγλικά και τα γαλλικά και βασίζεται σε μια σειρά συγκεκριμένων καταλόγων λέξεων και χαρακτηριστικών. Αυτές οι ενδείξεις ελήφθησαν κυρίως μέσω μιας εκτεταμένης ανάλυσης σώματος των παρεχόμενων δεδομένων κατάρτισης. Δοκιμάστηκαν διαφορετικά συστήματα στάθμισης (χειροκίνητα συντονισμένα ή βασισμένα σε λογιστική παλινδρόμηση), το καλύτερο που επιτυγχάνει βαθμολογία F1 0.31 για τα αγγλικά και 0.15 για τα γαλλικά.', 'hu': 'Ez a tanulmány bemutatja, hogy részt vettünk az SMM4H megosztott feladatában 2. Terveztünk egy szabályokon alapuló osztályozót, amely becsüli, hogy egy tweet említ-e egy gyógyszerhez kapcsolódó káros hatást. Rendszerünk angolul és franciával foglalkozik, és számos speciális szólistán és funkción alapul. Ezeket a jeleket leginkább a rendelkezésre bocsátott edzési adatok átfogó korpusz elemzésével szereztük meg. Különböző súlyozási sémákat teszteltünk (manuálisan hangolt vagy logisztikai regresszió alapján), a legjobb F1 pontszámot ért el angolul és 0,15 franciául.', 'it': "Questo articolo descrive la nostra partecipazione al compito condiviso SMM4H 2. Abbiamo progettato un classificatore basato su regole che valuta se un tweet menziona un effetto avverso associato a un farmaco. Il nostro sistema si rivolge all'inglese e al francese e si basa su una serie di elenchi di parole e caratteristiche specifiche. Questi segnali sono stati ottenuti principalmente attraverso un'analisi approfondita del corpus dei dati di allenamento forniti. Sono stati testati diversi schemi di ponderazione (sintonizzati manualmente o basati su una regressione logistica), il migliore ottenendo un punteggio F1 di 0,31 per l'inglese e 0,15 per il francese.", 'kk': 'Бұл қағаз біздің SMM4H ортақ тапсырмасына қатысуымызды 2- ға таңдайды. Біз ережелердің негізгі классификациясын құрастырдық. Бұл tweet медицина қарсы эффектті есептеп береді. Біздің жүйеміз ағылшын және французша тізіміне негізделген, бірнеше сөздер тізіміне негізделген. Бұл белгілер көбінесе келтірілген оқыту деректерінің корпус анализациясы арқылы алды. Басқа тең сұлбалары тексерілді (логистикалық регрессиясына негізделген немесе қолмен түзетілген), ағылшын тілінде 0, 31 деген F1 деңгейінде 0, 15 деңгейінде французша деңгейінде 0, 15 деңгейінде же', 'mk': 'Овој весник го опишува нашето учество во SMM4H заедничката задача 2. Дизајниравме класификатор базиран на правила кој проценува дали на Твитер се споменува негативен ефект поврзан со лекови. Нашиот систем се обраќа на англиски и француски, и се базира на број специфични листи и карактеристики на зборови. These cues were mostly obtained through an extensive corpus analysis of the provided training data.  Различни шеми за тежирање беа тестирани (рачно прилагодени или базирани на логистичка регресија), најдобрата што постигна оценка F1 од 0,31 за англиски и 0,15 за француски.', 'ml': 'ഈ പത്രത്തില്\u200d SM4H പങ്കുചേര്\u200dത്ത പണിയായി നമ്മുടെ പങ്കെടുക്കുന്നത് വിശദീകരിക്കുന്നു. ഞങ്ങള്\u200d ഒരു നിയമത്തില്\u200d അടിസ്ഥാനമായ ഒരു ക്ലാസ്ഫിക്കറിനെ നിര്\u200dമ്മിച്ചു. ഒരു ടൂട്ടിയില്\u200d ഒരു മെഡിക്ടറുമായി ബന്ധപ നമ്മുടെ സിസ്റ്റത്തില്\u200d ഇംഗ്ലീഷും ഫ്രെഞ്ചും വിലാസം ചെയ്യുന്നു. പ്രത്യേക വാക്കുകളുടെ ലിസ്റ്റും വിശ കൂടുതല്\u200d കൂടുതല്\u200d പരിശീലനത്തിന്റെ വിശദീകരണവും കോര്\u200dപ്പുസിന്റെ അന്വേഷണവും കിട്ടിയിരിക്കുന്നു. വ്യത്യസ്ത ഭാരം തൂക്കുന്ന പദ്ധതികള്\u200d പരീക്ഷിക്കപ്പെട്ടിരിക്കുന്നു (കൈയ്യില്\u200d നിര്\u200dമ്മിക്കപ്പെട്ടോ ലോഗിസ്റ്റിക്ക് വീണ്ടെ', 'ms': 'Kertas ini menggambarkan ketertarikan kita pada tugas berkongsi SMM4H 2. Kami merancang pengklasifikasi berdasarkan peraturan yang menghargai sama ada tweet menyebutkan kesan negatif yang berkaitan dengan ubat. Sistem kami alamat Bahasa Inggeris dan Perancis, dan berdasarkan sejumlah senarai perkataan dan ciri-ciri khusus. Tanda-tanda ini kebanyakan mendapat melalui analisis corpus yang luas data latihan yang diberikan. Different weighting schemes were tested (manually tuned or based on a logistic regression), the best one achieving a F1 score of 0.31 for English and 0.15 for French.', 'mt': 'Dan id-dokument jiddeskrivi l-parteċipazzjoni tagħna fil-kompitu kondiviż SMM4H 2. Iddisinjajna klassifikatur ibbażat fuq ir-regoli li jistma jekk tweet isemmix effett negattiv assoċjat ma’ mediċina. Is-sistema tagħna tindirizza l-Ingliż u l-Franċiż, u hija bbażata fuq għadd ta’ listi u karatteristiċi speċifiċi ta’ kliem. Dawn l-indikazzjonijiet inkisbu l-aktar permezz ta’ analiżi corpus estensiva tad-dejta tat-taħriġ ipprovduta. Ġew ittestjati skemi differenti ta’ piż (a ġġustati manwalment jew ibbażati fuq rigressjoni loġistika), l-aħjar waħda li kisbet punteġġ F1 ta’ 0.31 għall-Ingliż u 0.15 għall-Franċiż.', 'mn': 'Энэ цаас SMM4H хуваалцах үйл ажилд бидний оролцоог 2-р тайлбарладаг. Бид хууль дээр суурилсан хэлбэрийг бүтээсэн бөгөөд tweet нь эмчилгээтэй холбоотой эсрэг нөлөөтэй эсрэг нөлөөг хэлж байгааг тооцоолж байна. Бидний систем Англи, Французтай холбоотой. Мөн хэдэн тодорхой үгийн жагсаалт болон чанар дээр суурилсан. Эдгээр нь ихэнхдээ сургалтын өгөгдлийн шинжилгээр корпус шинжилгээс гарсан. Өөр өөр хэмжээний төлөвлөгөө шалгалт хийгдсэн (логистик сэтгэл хөдлөл дээр шалгалт эсвэл суурилсан), хамгийн сайн нь F1 оноо 0.31 болон 0.15 французчуудын төлөвлөгөөнд гарсан.', 'lt': 'Šiame dokumente apibūdinamas mūsų dalyvavimas bendroje SMM4H užduotyje 2. Mes sukūrėme taisyklių pagrindu grindžiamą klasifikatorių, kuris įvertina, ar tweete minimas su vaistais susijęs nepageidaujamas poveikis. Mūsų sistema skirta anglų ir prancūzų kalboms ir grindžiama tam tikrais žodžių sąraša is ir savybėmis. Šie požymiai daugiausia buvo gauti atlikus išsamią pateiktų mokymo duomenų analizę. Buvo išbandytos skirtingos svertinių schemos (rankiniu būdu pritaikytos arba remiantis logistine regresija), geriausia, kad anglų ir prancūzų F1 rezultatas būtų 0,31, o prancūzų – 0,15.', 'no': 'Denne papiret skildrar vår deltakast til delt SMM4H-oppgåva 2. Vi designerte ein regelbasert klassifiserer som vurder om ein tweet mener ein negativ effekt som er tilknytt til eit medikament. Systemet vårt adresser til engelsk og fransk, og er basert på mange spesifikke ordlister og funksjonar. Desse merknadene vart mest henta gjennom eit utvida korpusanalyse av dei oppgjevne treningsdata. Forskjellige vektskjema ble testa (manuelt oppsett eller basert på ein logistisk regresjon), den beste som oppnår eit F1- poeng med 0,31 for engelsk og 0,15 for fransk.', 'pl': 'Niniejszy artykuł opisuje nasz udział w wspólnym zadaniu SMM4H 2. Zaprojektowaliśmy klasyfikator oparty na regułach, który ocenia, czy tweet wspomina niekorzystny efekt związany z lekiem. Nasz system adresowany jest do angielskiego i francuskiego i opiera się na szeregu konkretnych list słów i funkcji. Wskazówki te uzyskano głównie poprzez obszerną analizę korpusu dostarczonych danych treningowych. Przetestowano różne schematy wagowe (ręcznie dostrojone lub oparte na regresji logistycznej), z których najlepszy osiągnął wynik F1 0,31 dla angielskiego i 0,15 dla francuskiego.', 'ro': 'Această lucrare descrie participarea noastră la sarcina comună SMM4H 2. Am proiectat un clasificator bazat pe reguli care estimează dacă un tweet menționează un efect advers asociat unui medicament. Sistemul nostru se adresează limbii engleze și franceze și se bazează pe o serie de liste și caracteristici specifice de cuvinte. Aceste indicii au fost obținute în principal printr-o analiză extinsă a corpului datelor de antrenament furnizate. Au fost testate diferite scheme de ponderare (reglate manual sau pe baza unei regresii logistice), cea mai bună obținând un scor F1 de 0,31 pentru engleză și 0,15 pentru franceză.', 'sr': 'Ovaj papir opisuje naše sudjelovanje na delovanju SMM4H zadatka 2. Mi smo dizajnirali klasifikatora na pravilima koji procenjuje da li tweet spominje negativni efekt povezan s lijekom. Naš sistem adresuje engleski i francuski, i zasnovan je na broju posebnih listi i karakteristika riječi. Ovi znakovi su uglavnom dobili kroz ogromnu korpusnu analizu pruženih podataka o obuci. Istraživali su različite šeme težine (rukopisane ili bazirane na logističkoj regresiji), najbolji koji postigne F1 rezultat 0,31 za engleski i 0,15 za francuski.', 'sv': 'Denna uppsats beskriver vårt deltagande i SMM4H delade uppgift 2. Vi har utformat en regelbaserad klassificering som uppskattar om en tweet nämner en negativ effekt förknippad med en medicin. Vårt system adresserar engelska och franska och bygger på ett antal specifika ordlistor och funktioner. Dessa ledtrådar erhölls mestadels genom en omfattande korpusanalys av de tillhandahållna träningsdata. Olika viktningsscheman testades (manuellt justerade eller baserade på en logistisk regression), den bästa fick F1 poäng på 0,31 för engelska och 0,15 för franska.', 'si': 'මේ පැත්තේ SMM4H කොටස් 2 වෙනුවෙන් අපේ සම්බන්ධතාවක් විස්තර කරනවා. අපි නියෝජනය අධාරිත විශේෂකයෙක් සැකසුම් කරනවා ඒ විශ්වාස කරන්නේ ට්විට් එක්ක විරෝධ ප්\u200dරතිකාරයක අපේ පද්ධතිය ඉංග්\u200dරීසි සහ ෆ්\u200dරෑන්ස් වල ලැයිස්තුවක් සහ විශේෂ වචන ලැයිස්තුවක් අධාරිත මේ සංඥානය ප්\u200dරශ්නයක් ලැබුනා ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විශ්ලේෂනයක් නිසා. වෙනස් බලාපොරොත්තු සැකසුම් පරීක්ෂණය කරලා තියෙන්නේ (පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය කරලා තියෙන්නේ), ඉ', 'so': 'Warqaddan waxaa ku qoran qayb-gelinta shaqada SMM4H oo la qaybsaday 2. Waxaannu qornay fasalka sharciga ku saabsan, kaasoo qiimeynaya in twitterku uu sheego saameyn xun oo ku saabsan daawo. nidaamkayaga wuxuu ku qoran yahay luuqada Ingiriiska iyo Faraansiis, wuxuuna ku saleysan yahay liiska hadalka gaarka ah iyo tababaro. Inta badan waxaa laga helaa baaritaanka korpus oo ballaadhan oo lagu sameynayo macluumaadka waxbarashada. Waxaa la imtixaamay qorshaha miisaanka kala duduwan (gacan loo isticmaalay ama ku saleysay dib u soo celinta jimicsiga), waxaa ugu wanaagsan koox F1 oo af Ingiriis ah 0.31 iyo 0.15.', 'ta': 'இந்த தாள் எஸ்எம்எம்4H பகிர்ந்த பணி 2க்கு எங்கள் பங்கீடு விவரிக்கிறது. நாங்கள் ஒரு விதிமுறையான வகுப்பாளரை வடிவமைத்தோம். ஒரு டுவிட்டர் ஒரு மருத்துவ உடன் தொடர்புடைய எதிர்பார விளைவு என் எங்கள் அமைப்பு ஆங்கிலம் மற்றும் பிரெஞ்சு முகவரிக்கிறது, மற்றும் குறிப்பிட்ட சொல்லு பட்டியல் மற்றும் கு இந்த கூம்புகள் வழங்கப்பட்ட பயிற்சி தரவின் விரிவான கார்ப்ஸ் ஆய்வு மூலம் பெற்றுள்ளன. Different weighting schemes were tested (manually tuned or based on a logistic regression), the best one achieving a F1 score of 0.31 for English and 0.15 for French.', 'ur': 'This paper describes our participation in the SMM4H shared task 2. ہم نے ایک قانون کی بنیادی کلاسیر طراحی کی جو ایک ٹویٹ کے ذریعے ایک مخالف اثر کا ذکر کرتا ہے۔ ہماری سیستم انگلیسی اور فرانسوی کے بارے میں دریافت کرتی ہے، اور بہت سی کلمات لکھنے اور فرصت پر بنی جاتی ہے. یہ نشانیاں اکثریت کے ذریعے پیش کئے گئے ترکینس ڈیٹوں کی ایک بڑی کورپوس تحلیل کے ذریعہ سے ملی گئیں۔ مختلف وزن کی تصویروں کی آزمائش کی گئی تھی (اپنا ذریعہ تغییر کیا گیا تھا یا لوجیسٹیک ریگرس پر بنیاد رکھا گیا تھا) سب سے بہتر جو انگلیسی کے لئے 0.31 اور 0.15 فرانسوی کے لئے F1 سکونٹ پہنچ گیا تھا۔', 'uz': "Bu qogʻoz SMM4H bilan birlashtirilgan vazifaning qismlarimizni anglatadi. Biz qoidagi fasifiyatni yaratdik. Twitterni o'ylab qo'l bilan bog'liq narsa haqida o'ylaymaydi. Bizning tizimmiz ingliz va fransuzcha tilidan boshqaradi, va bir necha so'zlar roʻyxati va hodisalar asosida. These cues were mostly obtained through an extensive corpus analysis of the provided training data.  Har xil oʻlchami qoliplarini sinab ko'rsatildi (qoʻlbola yordamida qoʻllanmagan yoki logistik tiklash asosida) ingliz tilida 0. 31 scorini olish uchun eng yaxshi bir necha F1 scori va 0. 15 fransuzcha uchun 0.", 'vi': 'Tờ giấy này mô tả sự tham gia của chúng ta với nhiệm vụ chia sẻ SMB 2. Chúng tôi thiết kế ra một người phân loại quy định xem trên Twitter có nói về tác động tiêu cực của thuốc không. Hệ thống của chúng tôi đề cập đến Anh Quốc và Pháp, dựa trên một số danh sách từ ngữ và các tính năng cụ thể. Những manh mối này được thu thập chủ yếu bằng một bản phân tích đầy đủ về dữ liệu huấn luyện được cung cấp. Các phương án cân bằng khác nhau được thử nghiệm (chỉnh sửa bằng tay hay dựa trên sự phục hồi tình báo), cách tốt nhất để đạt điểm số F1 của 0.31 cho tiếng Anh và 0.15 cho tiếng Pháp.', 'bg': 'Настоящата статия описва нашето участие в споделената задача 2. Създадохме класификатор, базиран на правила, който оценява дали в туитър се споменава нежелан ефект, свързан с дадено лекарство. Нашата система се отнася до английски и френски език и се основава на редица специфични списъци с думи и функции. Тези знаци са получени предимно чрез обширен корпусен анализ на предоставените данни за обучение. Тествани са различни тегловни схеми (ръчно настроени или базирани на логистична регресия), като най-добрата от тях постига резултат от 0,31 за английски и 0,15 за френски.', 'da': 'Denne artikel beskriver vores deltagelse i SMM4H delte opgave 2. Vi har designet en regelbaseret klassificering, der vurderer, om et tweet nævner en bivirkning forbundet med en medicin. Vores system henvender sig til engelsk og fransk og er baseret på en række specifikke ordlister og funktioner. Disse signaler blev for det meste opnået gennem en omfattende korpusanalyse af de leverede træningsdata. Forskellige vægtningsskemaer blev testet (manuelt tunet eller baseret på en logistisk regression), den bedste opnåede en F1 score på 0,31 for engelsk og 0,15 for fransk.', 'hr': 'Ovaj papir opisuje naše sudjelovanje na zajedničkom zadatku SMM4H 2. Mi smo dizajnirali klasifikatora na temelju pravila koji procjenjuje da li je tweet spomenuo nuspojavu povezan s lijekom. Naš sustav se obraća na engleskom i francuskom, i temeljen je na broju specifičnih listova riječi i karakteristika. Ovi znakovi su uglavnom dobiti kroz ogromnu analizu korpusa pruženih podataka o obuci. Ispitivali su različite težinske shēme (ručno napravljene ili temeljne na logističkoj regresiji), najbolji koji postigne rezultat F1 od 0,31 za engleski i 0,15 za francuski.', 'nl': "Dit artikel beschrijft onze deelname aan de SMM4H gedeelde taak 2. We hebben een rule-based classifier ontworpen die schat of een tweet een nadelig effect van een medicatie vermeldt. Ons systeem richt zich op Engels en Frans en is gebaseerd op een aantal specifieke woordenlijsten en functies. Deze cues werden meestal verkregen door een uitgebreide corpusanalyse van de verstrekte trainingsgegevens. Er werden verschillende wegingsschema's getest (handmatig afgestemd of gebaseerd op een logistieke regressie), waarvan de beste een F1 score behaalde van 0,31 voor Engels en 0,15 voor Frans.", 'fa': 'این کاغذ مشارکت ما را به کار مشترک SMM4H 2 توصیف می\u200cکند. ما یک راهنمایی بر اساس قانون طراحی کردیم که تخمین می\u200cکند که آیا یک تویت اثر مخالف با یک دارو ارتباط دارد یا نه. سیستم ما به انگلیسی و فرانسوی آدرس می\u200cکند، و بر تعدادی از لیست\u200cهای کلمات و ویژه\u200cهای خاص بنیاد می\u200cرسد. این نشانه\u200cها بیشتر از طریق تحلیل زیادی از داده\u200cهای آموزش داده شده\u200cاند. برنامه\u200cهای وزن متفاوت آزمایش شده\u200cاند (به دستی تغییر داده شده یا بر اساس تغییر شناسی) بهترین برنامه\u200cهای F1 از 0.31 برای انگلیسی و 0.15 برای فرانسوی.', 'de': 'Dieses Papier beschreibt unsere Teilnahme an der SMM4H Shared Task 2. Wir haben einen regelbasierten Klassifikator entwickelt, der abschätzt, ob ein Tweet eine negative Wirkung erwähnt, die mit einem Medikament verbunden ist. Unser System richtet sich an Englisch und Französisch und basiert auf einer Reihe spezifischer Wortlisten und Funktionen. Diese Hinweise wurden meist durch eine umfangreiche Korpusanalyse der bereitgestellten Trainingsdaten gewonnen. Verschiedene Gewichtungsschemata wurden getestet (manuell abgestimmt oder basierend auf einer logistischen Regression), wobei das beste eine F1-Punktzahl von 0,31 für Englisch und 0,15 für Französisch erreichte.', 'ko': '이 문서에서는 SMM4H 공유 임무 2에 참여하는 상황을 설명합니다.우리는 약물과 관련된 부작용이 언급되었는지 추측하기 위해 규칙에 기초한 분류기를 설계했다.우리의 시스템은 영어와 프랑스어를 처리하고 특정한 단어 목록과 기능을 바탕으로 한다.이러한 단서는 대부분 제공된 훈련 데이터에 대해 광범위한 어료 라이브러리 분석을 통해 얻어진 것이다.서로 다른 권중 방안에 대해 테스트(수동 조정 또는 논리 기반 회귀)를 실시했는데 그 중에서 가장 좋은 방안의 F1 영어 성적은 0.31, 프랑스어 성적은 0.15였다.', 'id': 'Kertas ini menjelaskan participasi kita pada SMM4H tugas berbagi 2. Kami merancang klasifikasi berdasarkan aturan yang memperkirakan apakah tweet menyebutkan efek negatif yang terkait dengan obat. Sistem kami alamat bahasa Inggris dan Perancis, dan berdasarkan sejumlah daftar kata dan fitur spesifik. Sinyal-sinyal ini terutama diperoleh melalui analisis corpus ekstensif dari data pelatihan yang diberikan. Different weighting schemes were tested (manually tuned or based on a logistic regression), the best one achieving a F1 score of 0.31 for English and 0.15 for French.', 'sw': 'Gazeti hili linaelezea ushiriki wetu kwenye kazi ya SMM4H ilizoshirikishwa na 2. Tuliunda maafisa anayeishi sheria inayokadiria kama twiti inataja athari mbaya inayohusiana na matibabu. Mfumo wetu unaongelea lugha ya Kiingereza na Kifaransa, na unategemea orodha kadhaa ya maneno na tabia. Mifumo hizi zilipatikana zaidi kwa kupitia uchambuzi wa taarifa za mafunzo. Mpango tofauti wa uzito ulijaribiwa (ulitumiwa mkono au kulingana na upinzani wa kisiasa), kipindi bora kabisa cha F1 cha 0.31 kwa Kiingereza na 0.15 kwa Kifaransa.', 'af': "Hierdie papier beskrywe ons deelnimmering na die SMM4H gedeelde taak 2. Ons het 'n reël-gebaseerde klassifiseerder ontwerp wat vurdering of 'n tweet 'n negatiewe effek met 'n medikasie geassosieer het. Ons stelsel adres Engels en Frans, en is gebaseer op 'n aantal spesifieke woorde lyste en funksies. Hierdie tekens is meeste ontvang deur 'n uitbreidige korpusanalisie van die verskaf onderwerp data. Verskillende gewigtige skeme is toets (hand tuned of based on a logistic regression), die beste een wat 'n F1 punt van 0.31 bereik het vir Engels en 0.15 vir Frans.", 'tr': 'Bu kagyz biziň SMM4H we paylaşyklarymyzyň 2-nji zada bölýän zadymyzy tassyklaýar. Biz düzgün derejede taýýarlanan klasifikatçy tasarladyk. Bir tweet derman bilen täsirli täsirli netijesi diýip çaklaýar. Biziň sistemamyz iňlisçe we fransuzça adresini görkeýär we birnäçe wajyp sözler we özelliklere daýanýar. Bu sanatlar köplenç berilen bilim maglumatynyň corpus analyzasyndan berildi. Dähili taýýarlyk taslamalar (el düzenli ýa-da logistiki regresiýa daýanýar), iňlisçe 0,31 we fransuzça 0,15 süýtgedeniň gowy.', 'sq': 'Kjo letër përshkruan pjesëmarrjen tonë në detyrën e përbashkët SMM4H 2. Ne krijuam një klasifikues bazuar në rregulla që vlerëson nëse një tweet përmend një efekt të dëmshëm lidhur me një ilaç. Sistemi ynë drejtohet në anglisht dhe francez dhe bazohet në një numër listash dhe karakteristikë të posaçme fjalësh. Këto shenja u gjetën kryesisht nëpërmjet një analize të gjerë të trupit të të dhënave të trajnimit të dhëna. U testuan skema të ndryshme peshoje (të rregulluara manualisht apo të bazuara në një regresion logjistik), më e mira që arriti një rezultat F1 prej 0.31 për anglishtin dhe 0.15 për francezën.', 'am': 'ይህ ገጽ SM4H የተካፈለውን ስራ 2 እየተካፈለ ተግባራችንን ይናገራል፡፡ የሥርዓት ግንኙነት መፍትር ሀገር ማኅበረሰብ ማነሳሰብ ነው፡፡ ሲስተምረታችን እንግሊዘኛ እና ፈረንሳይኛ እና በተለያዩ ቃላት ዝርዝሮች እና ግንኙነትን ይጨመርበታል፡፡ These cues were mostly obtained through an extensive corpus analysis of the provided training data.  የተለያዩ ሚዛን ፕሮግራም ተፈትኖአል (በእጃቸው ተጠቃሚ ወይም በሎጂክ ክፍል ላይ የተደረገ)፣ ለኢንግሊዝኛ እና ለፈረንሳይኛ የ.', 'hy': 'Այս թղթին նկարագրում է SMM4H-ի ընդհանուր խնդրի 2 մասնակցությունը: Մենք ստեղծեցինք կանոններով հիմնված դասակարգիչ, որը գնահատում է, թե արդյոք թվիթերում նշում է դեղամիջոցների հետ կապված բացասական ազդեցությունը: Մեր համակարգը դիտարկում է անգլերեն և ֆրանսերեն և հիմնված է որոշ հատուկ բառերի ցուցակների և հատկությունների վրա: Այս նշանները հիմնականում ստացվել էին մարմնի բազմազան վերլուծության միջոցով տրամադրված ուսումնասիրության տվյալների: Տարբեր կշռումների ծրագրերը փորձարկվեցին (ձեռքով կազմակերպված կամ լոգոստիկ ռեգրեսիայի վրա հիմնված), լավագույնը, որը հասնում է 0.31-ի F1-ի անգլերենի և 0.15-ի ֆրանսերենի համար:', 'az': 'Bu kağıt bizim SMM4H paylaşılmış işlərimizin paylaşılmasını 2-ini təsdiq edir. Biz qayda-qüvvətli klasifikatçı tasarladıq ki, bir tweet ilaçları ilə əlaqə edilən müsibət etkisini müəyyən edir. Bizim sistemimiz İngilizce və Fransız dilində danışır, və bir neçə növbənöv kelimelər və özelliklərə dayanılır. Bu məlumatlar çox böyük bir korpus analizi ilə verilən təhsil məlumatlarından alındı. Müxtəlif a ğırlıq taslaqları imtahana çəkildi (loģistiki regresiya dayanan və ya tərəfindən qurulmuşdu), İngilizce dilində 0,31 dəqiqəsini və Fransız dilində 0,15 dəqiqəsini qəbul edənlərin ən yaxşısı.', 'bn': 'এই পত্রিকাটি এসএমএফ৪H শেয়ার কর্মসূচির কাছে আমাদের অংশগ্রহণের ব্যাখ্যা করছে। We designed a rule-based classifier that estimates whether a tweet mentions an adverse effect associated to a medication.  আমাদের সিস্টেম ইংরেজি এবং ফরাসী ভিত্তিক কথা এবং বিশেষ কয়েকটি শব্দ তালিকা এবং বৈশিষ্ট্যের উপর ভিত্তিক। প্রশিক্ষণের তথ্যের বিশেষ বিশ্লেষণের মাধ্যমে এই কুইগুলো বেশীরভাগ পেয়েছে। বিভিন্ন ভিন্ন ওজন পরিকল্পনা পরীক্ষা করা হয়েছে (হ্যান্ডামাত্রিক সংক্রান্ত বা বৈশিষ্ট্য পুনরুদ্ধারের ভিত্তিক ভিত্তিক ভিত্তিক ভি', 'ca': "Aquest paper descriu la nostra participació a la tasca compartida SMM4H 2. Vam dissenyar un classificador basat en regles que estima si un tweet menciona un efecte advers associat a un medicament. El nostre sistema s'adressa a l'anglès i al francès, i està basat en una sèrie de llistes i característiques específices de paraules. Aquestes indicacions es van obtenir principalment a través d'una extensa an àlisi corpus de les dades de formació proporcionades. Es van provar diferents esquemes de ponderació (ajustads manualment o basats en una regressió logística), el millor que va aconseguir una puntuació F1 de 0,31 per anglès i 0,15 per francès.", 'cs': 'Tento článek popisuje naši účast na sdíleném úkolu SMM4H 2. Navrhli jsme klasifikátor založený na pravidlech, který odhaduje, zda tweet zmiňuje nežádoucí účinek spojený s lékem. Náš systém řeší angličtinu a francouzštinu a je založen na řadě specifických seznamů slov a funkcí. Tyto nápovědy byly získány převážně prostřednictvím rozsáhlé korpusové analýzy poskytnutých tréninkových dat. Byly testovány různé váhové schémata (ručně laděné nebo na základě logistické regrese), z nichž nejlepší bylo dosaženo F1 skóre 0,31 pro angličtinu a 0,15 pro francouzštinu.', 'bs': 'Ovaj papir opisuje naše sudjelovanje na podijeljenom zadatku SMM4H 2. Mi smo dizajnirali klasifikatora na temelju pravila koji procjenjuje da li tweet spominje negativni učinak povezan s lijekovima. Naš sistem se obraća na engleskom i francuskom jeziku, i zasnovan na broju specifičnih listova riječi i karakteristika. Ovi znakovi su uglavnom dobili kroz ogromnu analizu korpusa pruženih podataka o obuci. Testirani su različiti šeme težine (rukopisane ili temeljne na logističkoj regresiji), najbolji koji postigne rezultat F1 od 0,31 za engleski i 0,15 za francuski.', 'et': 'Käesolevas dokumendis kirjeldatakse meie osalemist SMM4H jagatud ülesandes 2. Me töötasime välja reeglipõhise klassifikaatori, mis hindab, kas säutsis mainitakse ravimiga seotud kõrvaltoimet. Meie süsteem käsitleb inglise ja prantsuse keelt ning põhineb mitmetel konkreetsetel sõnaloenditel ja funktsioonidel. Need vihjed saadakse enamasti esitatud koolitusandmete ulatusliku korpusanalüüsi kaudu. Testiti erinevaid kaalumisskeeme (käsitsi häälestatud või logistilise regressiooni põhjal), parim saavutas F1 skoori 0,31 inglise keeles ja 0,15 prantsuse keeles.', 'fi': 'Tässä artikkelissa kuvataan osallistumistamme SMM4H:n yhteiseen tehtävään 2. Suunnittelimme sääntöpohjaisen luokittelijan, joka arvioi, mainitseeko tweetissä lääkkeeseen liittyvän haittavaikutuksen. Järjestelmämme käsittelee englantia ja ranskaa, ja se perustuu useisiin sanaluetteloihin ja ominaisuuksiin. Nämä vihjeet saatiin enimmäkseen kattavalla koulutusaineiston korpusanalyysillä. Erilaisia painotusjärjestelmiä testattiin (manuaalisesti viritetty tai logistisen regression perusteella), joista paras saavutti F1-pisteet 0,31 englanniksi ja 0,15 ranskaksi.', 'ha': "Wannan takardan na bayyana shirinmu zuwa shirin SMM4H wanda aka raba aiki 2. Ba mu ƙayyade wani mai fassara a kangara, da yana ƙidãya, shin wani na'ura na Twitter yana faɗa wata sharri'a da ke haɗi da dawada. Ana yarda da shiryoyin ayukanmu na da Ingiriya da Faransa, kuma yana baka kan wasu wasu jerin maganar da aka ƙayyade. Waɗannan cutun za'a iya motsa mafiya yawa a kan an yi anayyar nau'i-nau'in da aka ba da data. An jarraba kayan nau'i-nau'i dabam-daban (an yi amfani da hannuwansa ko kuma a kan wata cewa na logistic), mafi kyaun wanda ya sami F1 score 0.31 wa Ingiriya da 0.15 wa faransa.", 'sk': 'Ta prispevek opisuje naše sodelovanje pri skupni nalogi SMM4H 2. Zasnovali smo klasifikator, ki temelji na pravilih, ki ocenjuje, ali tweet omenja neželeni učinek, povezan z zdravilom. Naš sistem obravnava angleščino in francoščino ter temelji na številnih specifičnih seznamih besed in funkcijah. Ti namigi so bili večinoma pridobljeni z obsežno korpusno analizo predloženih podatkov o usposabljanju. Testirane so bile različne tehtalne sheme (ročno nastavljene ali na podlagi logistične regresije), najboljša pa je dosegla rezultat F1 0,31 za angleščino in 0,15 za francoščino.', 'he': 'העיתון הזה מתאר את השתתפות שלנו למשימה המשותפת של SMM4H 2. עיצבנו מסווג מבוסס על חוקים שמעריך אם טוויט מזכיר השפעה שלילית שקשורה לתרופה. המערכת שלנו מתייחסת לאנגלית וצרפתית, ומבוססת על מספר רשימות מילים ופרטים ספציפיים. These cues were mostly obtained through an extensive corpus analysis of the provided training data.  Different weighting schemes were tested (manually tuned or based on a logistic regression), the best one achieving a F1 score of 0.31 for English and 0.15 for French.', 'jv': 'Pesene iki rambarang nggawe ning pating karo SMM4H nang pating 2 Awak dhéwé nggawe barang langgambar luwih banter Sistem dhéwé nganggo Inggris lan Perancis, lan sabên seneng kabèh manut karo nganggo langgambar lan manut. Akus sing dipunangé dipunangé dipunangé kabèh dumadhi kapan banget nggawe dadi nyong nggawe politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་བྱ་འགུལ་འདི་SMM4H སྤྱད་པའི་ལས་ཀ་2 ང་ཚོས་བྱ་ཚིག་དང་འབྲེལ་བའི་ཉེན་ཁ་ཕྱེད་ཀྱི་དབྱེ་བ་ཞིག་གིས་བཟུང་བྱས་མིན། ང་ཚོའི་མ་ལག་གི་དབྱིན་ཡིག་དང་ཕ་རིང་ལ་ཁྱད་ནས་སྐད་ཀྱི་ཁྱད་ཆ་ཁ་ཤས་ཐོ་བཀོད་དང་ཁྱད་ཆོས་ཐོ་བཀོ ཨ་རིགས་འདི་དག་གི་ཆེས་ཡོད་དུས་ངེས་པར་དབྱིབས་ཡོད་པའི་ཆ་འཕྲིན་གྱི་དབུལ་ཞིབ་བྱས་པ་རེད། Different weighting schemes were tested (manually tuned or based on a logistic regression), the best one to achieve a F1 score of 0.31 for English and 0.15 for French.'}
{'en': 'Sentence Classification with Imbalanced Data for Health Applications', 'ar': 'تصنيف الجمل مع البيانات غير المتوازنة للتطبيقات الصحية', 'pt': 'Classificação de sentenças com dados desequilibrados para aplicativos de saúde', 'es': 'Clasificación de sentencias con datos desequilibrados para aplicaciones de salud', 'fr': 'Classification des phrases avec données déséquilibrées pour les applications de santé', 'hi': 'स्वास्थ्य अनुप्रयोगों के लिए असंतुलित डेटा के साथ वाक्य वर्गीकरण', 'ja': '健康応用のための不均衡なデータを伴う文章分類', 'zh': '健用不平数句分', 'ru': 'Классификация предложений с несбалансированными данными для применения в здравоохранении', 'ga': 'Aicmiú Pianbhreithe le Sonraí Éagothroime le haghaidh Feidhmchláir Sláinte', 'ka': 'სიტყვების კლასიფიკაცია განბალისური მონაცემების შესახებ', 'el': 'Ταξινόμηση φράσεων με μη ισορροπημένα δεδομένα για εφαρμογές υγείας', 'hu': 'Az ítélet osztályozása kiegyensúlyozatlan adatokkal egészségügyi alkalmazásokhoz', 'it': 'Classificazione delle sentenze con dati sbilanciati per applicazioni sanitarie', 'kk': 'Сөздік қолданбаларының балансификациялық деректерімен сөз классификациясы', 'mk': 'Sentence Classification with Imbalanced Data for Health Applications', 'lt': 'Sentence Classification with Imbalanced Data for Health Applications', 'ml': 'ആശ്വാസത്തിനുള്ള പ്രയോഗങ്ങള്\u200dക്കുള്ള വിധി ക്ലാസിക്കേഷന്\u200d ഉപയോഗിക്കുക', 'mn': 'Эрүүл мэндийн хэрэглэгчдийн тэнцвэртэй өгөгдлийн хувилбар', 'no': 'Uttrykk- klassifikasjon med ikkje balanserte data for helseprogrammer', 'pl': 'Klasyfikacja zdań z niezrównoważonymi danymi dla zastosowań zdrowotnych', 'ro': 'Clasificarea sentințelor cu date dezechilibrate pentru aplicații de sănătate', 'mt': 'Klassifikazzjoni tas-Sentenza b’Dejta Żbilanċjata għall-Applikazzjonijiet tas-Saħħa', 'sr': 'Klasifikacija kazne sa nepravednom podacima za aplikacije zdravlja', 'so': 'Heshiiska daryeelka ee codsiga caafimaadka', 'si': 'Name', 'sv': 'Domeklassificering med obalanserade data för hälsotillämpningar', 'ta': 'உடல் பயன்பாடுகளுக்கான சரியான தரவுடன் வாக்கியமைப்பு', 'ur': 'سلامتی کاربریوں کے لئے مطابق مطابق ڈاکٹے کے ساتھ سنت کلاسیف کرنا', 'ms': 'Klasifikasi Hukuman dengan Data yang tidak seimbang untuk Aplikasi Kesehatan', 'vi': 'Bản đánh giá với dữ liệu bất ổn về sức khỏe', 'uz': 'Name', 'bg': 'Класификация на изреченията с небалансирани данни за здравни приложения', 'nl': 'Zinnclassificatie met onevenwichtige gegevens voor gezondheidstoepassingen', 'da': 'Sætningsklassificering med ubalancerede data for sundhedsapplikationer', 'hr': 'Klasifikacija kazna sa nepravednom podacima za aplikacije zdravlja', 'de': 'Satzklassifizierung mit ungleichgewichtigen Daten für Gesundheitsanwendungen', 'id': 'Sentence Classification with Imbalanced Data for Health Applications', 'fa': 'کلاسیک مجوز با داده های نابرابری برای کاربردهای سلامتی', 'ko': '불균형 데이터 기반의 문장 분류 위생 분야에서의 응용', 'sw': 'Utoaji wa Hukumu na Taarifa zisizo na usawa kwa matumizi ya Afya', 'tr': 'Saýlaw Programleri üçin nadegalanmış Maglumaty', 'af': 'Soektog Klassifikasie met onbalanseerde data vir gesondige toepassings', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'hy': 'Sentence Classification with Imbalanced Data for Health Applications', 'az': 'Sağlıq Uygulamaları üçün müəyyən edilməmiş Məlumatları ilə Sözü Klasifikası', 'bs': 'Klasifikacija kazna sa nepravednom podacima za aplikacije zdravlja', 'bn': 'স্বাস্থ্য অ্যাপ্লিকেশনের জন্য অমান্য তথ্যের সাথে শ্রেণীবিধান', 'ca': 'Classificació de sentences amb dades desequilibradas per aplicacions sanitàries', 'cs': 'Klasifikace vět s nevyváženými daty pro zdravotní aplikace', 'et': 'Tervisealaste rakenduste lausete klassifitseerimine tasakaalustamata andmetega', 'fi': 'Lausekkeiden luokittelu ja epätasapainoiset tiedot terveyssovelluksissa', 'sq': 'Klasifikimi i dënimeve me të dhëna të paekuilibruara për aplikimet shëndetësore', 'jv': 'iCalImp', 'ha': 'Classification with data na inganci wa Shiryoyin Ayuka na Aiki', 'bo': 'བྱ་ཚིག་ལ་ཉམས་སྐྱོད་ཀྱི་ཉེར་སྤྱོད་ལ་ཆ་མཚོན་པའི་ཆ་འཕྲིན་', 'sk': 'Razvrstitev stavkov z neravnoteženimi podatki za zdravstvene aplikacije', 'he': 'מסווג גזר עם נתונים לא מאוזנים לתוכניות בריאות'}
{'en': 'Identifying and extracting reports of medications, their abuse or adverse effects from  social media  is a challenging task. In  social media , relevant reports are very infrequent, causes imbalanced class distribution for  machine learning algorithms . Learning algorithms typically designed to optimize the overall accuracy without considering the relative distribution of each class. Thus, imbalanced class distribution is problematic as  learning algorithms  have low predictive accuracy for the infrequent class. Moreover,  social media  represents natural linguistic variation in creative language expressions. In this paper, we have used a combination of data balancing and neural language representation techniques to address the challenges. Specifically, we participated the shared tasks 1, 2 (all languages), 4, and 3 (only the span detection, no normalization was attempted) in Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). The results show that with the proposed methodology  recall scores  are better than the precision scores for the shared tasks. The  recall score  is also better compared to the mean score of the total submissions. However, the F1-score is worse than the mean score except for task 2 (French).', 'pt': 'Identificar e extrair relatos de medicamentos, seu abuso ou efeitos adversos das mídias sociais é uma tarefa desafiadora. Nas mídias sociais, relatórios relevantes são muito infrequentes, causando distribuição de classes desequilibrada para algoritmos de aprendizado de máquina. Algoritmos de aprendizado normalmente projetados para otimizar a precisão geral sem considerar a distribuição relativa de cada classe. Assim, a distribuição de classe desequilibrada é problemática, pois os algoritmos de aprendizado têm baixa precisão preditiva para a classe pouco frequente. Além disso, a mídia social representa a variação linguística natural nas expressões da linguagem criativa. Neste artigo, usamos uma combinação de técnicas de balanceamento de dados e representação de linguagem neural para enfrentar os desafios. Especificamente, participamos das tarefas compartilhadas 1, 2 (todos os idiomas), 4 e 3 (apenas a detecção de span, nenhuma normalização foi tentada) em aplicativos de Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Os resultados mostram que com a metodologia proposta as pontuações de recall são melhores que as pontuações de precisão para as tarefas compartilhadas. A pontuação de recall também é melhor em comparação com a pontuação média do total de envios. No entanto, o escore F1 é pior do que o escore médio, exceto para a tarefa 2 (francês).', 'ar': 'يعد تحديد واستخراج التقارير عن الأدوية أو إساءة استخدامها أو الآثار الضارة من وسائل التواصل الاجتماعي مهمة صعبة. في وسائل التواصل الاجتماعي ، التقارير ذات الصلة نادرة للغاية ، مما يؤدي إلى توزيع غير متوازن للفئة لخوارزميات التعلم الآلي. تم تصميم خوارزميات التعلم عادةً لتحسين الدقة الكلية دون مراعاة التوزيع النسبي لكل فئة. وبالتالي ، فإن التوزيع غير المتوازن للفئة يمثل مشكلة لأن خوارزميات التعلم لها دقة تنبؤية منخفضة للفئة النادرة. علاوة على ذلك ، تمثل وسائل التواصل الاجتماعي تباينًا لغويًا طبيعيًا في التعبيرات اللغوية الإبداعية. في هذه الورقة ، استخدمنا مزيجًا من موازنة البيانات وتقنيات تمثيل اللغة العصبية لمواجهة التحديات. على وجه التحديد ، شاركنا في المهام المشتركة 1 و 2 (جميع اللغات) و 4 و 3 (فقط اكتشاف المدى ، ولم تتم محاولة التطبيع) في تعدين الوسائط الاجتماعية للتطبيقات الصحية (SMM4H) 2020 (Klein et al. ، 2020). تظهر النتائج أنه باستخدام المنهجية المقترحة ، تكون درجات الاسترجاع أفضل من درجات الدقة للمهام المشتركة. تعتبر درجة الاستدعاء أفضل أيضًا مقارنة بمتوسط درجة إجمالي عمليات الإرسال. ومع ذلك ، فإن الدرجة F1 أسوأ من متوسط الدرجة باستثناء المهمة 2 (الفرنسية).', 'es': 'Identificar y extraer informes de medicamentos, abuso o efectos adversos de las redes sociales es una tarea difícil. En las redes sociales, los informes relevantes son muy poco frecuentes, lo que provoca una distribución de clases desequilibrada para los algoritmos de aprendizaje automático. Algoritmos de aprendizaje normalmente diseñados para optimizar la precisión general sin tener en cuenta la distribución relativa de cada clase. Por lo tanto, la distribución de clases desequilibrada es problemática, ya que los algoritmos de aprendizaje tienen baja precisión predictiva para la clase poco frecuente Además, las redes sociales representan una variación lingüística natural en las expresiones del lenguaje creativo. En este artículo, hemos utilizado una combinación de técnicas de equilibrio de datos y representación del lenguaje neuronal para abordar los desafíos. Específicamente, participamos en las tareas compartidas 1, 2 (todos los idiomas), 4 y 3 (solo se intentó la detección del intervalo, no se intentó la normalización) en las aplicaciones de Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Los resultados muestran que, con la metodología propuesta, las puntuaciones de recuperación son mejores que las puntuaciones de precisión para las tareas compartidas. La puntuación de retirada también es mejor en comparación con la puntuación media del total de envíos. Sin embargo, la puntuación F1 es peor que la puntuación media, excepto en la tarea 2 (francés).', 'ja': 'ソーシャルメディアから薬物、薬物乱用、または薬物の悪影響の報告を特定し、抽出することは困難な作業です。 ソーシャルメディアでは、関連するレポートは非常に頻繁ではなく、機械学習アルゴリズムのクラス分布の不均衡を引き起こします。 学習アルゴリズムは、通常、各クラスの相対的な分布を考慮することなく、全体的な精度を最適化するように設計されている。 したがって、学習アルゴリズムは頻度の低いクラスの予測精度が低いため、不均衡なクラス分布が問題となる。 さらに、ソーシャルメディアは、創造的な言語表現における自然な言語的変動を表しています。 この論文では、データバランシングとニューラル言語表現技術の組み合わせを用いて課題に対処してきた。 具体的には、ソーシャルメディアマイニングフォーヘルスアプリケーション（ SMM 4 H ） 2020 （ Klein et al., 2020 ）の共有タスク1、2 （すべての言語）、4、3 （スパン検出のみ、正規化は試みられませんでした）に参加しました。 結果は、提案された方法論のリコールスコアが共有されたタスクの精度スコアよりも優れていることを示しています。 総提出物の平均スコアと比較して、リコールスコアも優れています。 ただし、F 1スコアはタスク2 （フランス）を除いて平均スコアよりも悪い。', 'zh': '以社交媒体知药,以不良反应告挑战性。 在社交媒体之上,关报甚少,致机器学算法之类不平。 学算法常指优化体准确性,而不虑每类之对布。 故不平之类有问,学算有不数之占准确性。 社交媒体者,创造性言自然语言变也。 本文合数据平衡神经语以应之。 2020年社交媒体掘应用程序(SMM4H)中与共事1,2(凡语言),4与3(仅跨度检测,未尝试规范化)(Klein等,2020)。 结果表明,用其法,召率得分优于共享之精得分。 视提交总数之均分,召分数亦愈。 然F1 分数差于均分,而任 2 外(法语)。', 'fr': "Identifier et extraire des rapports sur les médicaments, leur abus ou leurs effets indésirables à partir des médias sociaux est une tâche ardue. Dans les médias sociaux, les rapports pertinents sont très peu fréquents, ce qui entraîne une distribution déséquilibrée des classes pour les algorithmes d'apprentissage automatique. Algorithmes d'apprentissage généralement conçus pour optimiser la précision globale sans tenir compte de la distribution relative de chaque classe. Ainsi, la distribution déséquilibrée des classes est problématique car les algorithmes d'apprentissage ont une faible précision prédictive pour les classes peu fréquentes. De plus, les réseaux sociaux représentent une variation linguistique naturelle dans les expressions langagières créatives. Dans cet article, nous avons utilisé une combinaison de techniques d'équilibrage des données et de représentation du langage neuronal pour relever ces défis. Plus précisément, nous avons participé aux tâches partagées 1, 2 (toutes les langues), 4 et 3 (seule la détection de la portée, aucune tentative de normalisation) dans Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). Les résultats montrent qu'avec la méthodologie proposée, les scores de rappel sont meilleurs que les scores de précision pour les tâches partagées. Le score de rappel est également meilleur que le score moyen du total des soumissions. Cependant, le score F1 est inférieur au score moyen sauf pour la tâche 2 (français).", 'hi': 'सोशल मीडिया से दवाओं, उनके दुरुपयोग या प्रतिकूल प्रभावों की रिपोर्टों की पहचान करना और निकालना एक चुनौतीपूर्ण कार्य है। सोशल मीडिया में, प्रासंगिक रिपोर्ट बहुत कम होती हैं, मशीन लर्निंग एल्गोरिदम के लिए असंतुलित वर्ग वितरण का कारण बनती हैं। सीखने के एल्गोरिदम आमतौर पर प्रत्येक वर्ग के सापेक्ष वितरण पर विचार किए बिना समग्र सटीकता को अनुकूलित करने के लिए डिज़ाइन किए गए हैं। इस प्रकार, असंतुलित वर्ग वितरण समस्याग्रस्त है क्योंकि सीखने के एल्गोरिदम में अक्सर वर्ग के लिए कम भविष्यवाणी सटीकता होती है। इसके अलावा, सोशल मीडिया रचनात्मक भाषा अभिव्यक्तियों में प्राकृतिक भाषाई भिन्नता का प्रतिनिधित्व करता है। इस पेपर में, हमने चुनौतियों को संबोधित करने के लिए डेटा संतुलन और तंत्रिका भाषा प्रतिनिधित्व तकनीकों के संयोजन का उपयोग किया है। विशेष रूप से, हमने साझा कार्यों 1, 2 (सभी भाषाओं), 4, और 3 (केवल स्पैन डिटेक्शन, कोई सामान्यीकरण का प्रयास नहीं किया गया था) में सोशल मीडिया माइनिंग फॉर हेल्थ एप्लिकेशन (SMM4H) 2020 (क्लेन एट अल। परिणाम बताते हैं कि प्रस्तावित पद्धति के साथ याद स्कोर साझा कार्यों के लिए सटीक स्कोर से बेहतर हैं। कुल प्रस्तुतियों के औसत स्कोर की तुलना में रिकॉल स्कोर भी बेहतर है। हालांकि, F1-स्कोर कार्य 2 (फ्रेंच) को छोड़कर औसत स्कोर से भी बदतर है।', 'ru': 'Выявление и извлечение сообщений о лекарствах, злоупотреблении ими или неблагоприятных последствиях из социальных сетей является сложной задачей. В социальных сетях соответствующие сообщения встречаются очень редко, что приводит к несбалансированному распределению классов для алгоритмов машинного обучения. Алгоритмы обучения, как правило, предназначены для оптимизации общей точности без учета относительного распределения каждого класса. Таким образом, неравномерное распределение классов является проблематичным, так как обучающие алгоритмы имеют низкую точность прогнозирования для редкого класса. Кроме того, социальные сети представляют собой естественные языковые вариации в выражениях творческого языка. В этой статье мы использовали комбинацию балансировки данных и нейронных методов представления языка для решения проблем. В частности, мы участвовали в совместных задачах 1, 2 (все языки), 4 и 3 (только обнаружение диапазона, попытка нормализации не предпринималась) в приложениях Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Результаты показывают, что с предлагаемой методологией баллы отзыва лучше, чем баллы прецизионности для общих задач. Показатель отзыва также лучше по сравнению со средним показателем общего количества представленных документов. Тем не менее, показатель F1 хуже, чем средний показатель, за исключением задачи 2 (французский).', 'ga': 'Is tasc dúshlánach é tuairiscí ar chógais, a mí-úsáid nó a n-iarmhairtí díobhálacha ó na meáin shóisialta a aithint agus a bhaint astu. Sna meáin shóisialta, tá tuairiscí ábhartha an-annamh, is cúis le dáileadh ranga éagothroime le haghaidh halgartaim meaisínfhoghlama. De ghnáth déantar halgartaim foghlama a dhearadh chun an cruinneas iomlán a bharrfheabhsú gan breithniú a dhéanamh ar dháileadh coibhneasta gach ranga. Mar sin, bíonn fadhbanna le dáileadh éagothroime ranga toisc go bhfuil cruinneas íseal réamh-mheastacháin ag algartaim foghlama don rang neamhmhinic. Ina theannta sin, is ionann na meáin shóisialta agus éagsúlacht nádúrtha teangeolaíoch i nathanna cainte cruthaitheacha. Sa pháipéar seo, d’úsáideamar meascán de theicnící um chothromú sonraí agus de theicnící néar-léirithe teanga chun aghaidh a thabhairt ar na dúshláin. Go sonrach, ghlacamar páirt sna tascanna comhroinnte 1, 2 (gach teanga), 4, agus 3 (ach an braite réise, níor rinneadh iarracht ar normalú) in iarratais Mianadóireacht Meáin Shóisialta le haghaidh Sláinte (SMM4H) 2020 (Klein et al., 2020). Léiríonn na torthaí go bhfuil scóir athghairme leis an modheolaíocht atá beartaithe níos fearr ná na scóir bheachtais do na tascanna comhroinnte. Tá an scór aisghairme níos fearr freisin i gcomparáid le meánscór na n-aighneachtaí iomlána. Mar sin féin, tá an scór F1 níos measa ná an meánscór ach amháin i gcás tasc 2 (Fraincis).', 'el': 'Ο εντοπισμός και η εξαγωγή αναφορών φαρμάκων, της κατάχρησης τους ή των δυσμενών επιπτώσεων από τα μέσα κοινωνικής δικτύωσης είναι ένα δύσκολο έργο. Στα μέσα κοινωνικής δικτύωσης, οι σχετικές αναφορές είναι πολύ σπάνιες, προκαλούν ανισορροπημένη κατανομή τάξεων για αλγόριθμους μηχανικής μάθησης. Οι αλγόριθμοι εκμάθησης συνήθως έχουν σχεδιαστεί για να βελτιστοποιούν τη συνολική ακρίβεια χωρίς να εξετάζουν τη σχετική κατανομή κάθε τάξης. Έτσι, η ανισορροπημένη κατανομή τάξεων είναι προβληματική καθώς οι μαθησιακοί αλγόριθμοι έχουν χαμηλή προγνωστική ακρίβεια για την σπάνια τάξη. Επιπλέον, τα μέσα κοινωνικής δικτύωσης αντιπροσωπεύουν φυσική γλωσσική διακύμανση στις δημιουργικές γλωσσικές εκφράσεις. Στην παρούσα εργασία, έχουμε χρησιμοποιήσει έναν συνδυασμό τεχνικών εξισορρόπησης δεδομένων και αναπαράστασης νευρωνικής γλώσσας για να αντιμετωπίσουμε τις προκλήσεις. Συγκεκριμένα, συμμετείχαμε στις κοινές εργασίες 1, 2 (όλες οι γλώσσες), 4 και 3 (μόνο η ανίχνευση της έκτασης, δεν επιχειρήθηκε ομαλοποίηση) στην εξόρυξη κοινωνικών μέσων για εφαρμογές υγείας (2020). Τα αποτελέσματα δείχνουν ότι με την προτεινόμενη μεθοδολογία οι βαθμολογίες ανάκλησης είναι καλύτερες από τις βαθμολογίες ακρίβειας για τις κοινές εργασίες. Η βαθμολογία ανάκλησης είναι επίσης καλύτερη σε σύγκριση με τη μέση βαθμολογία των συνολικών υποβολών. Ωστόσο, η βαθμολογία F1 είναι χειρότερη από τη μέση βαθμολογία εκτός από την εργασία 2 (γαλλικά).', 'hu': 'A gyógyszerekről, azok visszaéléséről vagy káros hatásairól szóló jelentések azonosítása és kivonása a közösségi médiából kihívást jelentő feladat. A közösségi médiában a releváns jelentések nagyon ritkán fordulnak elő, ami egyensúlytalan osztályelosztást okoz a gépi tanulási algoritmusok számára. Tanulási algoritmusok általában arra tervezték, hogy optimalizálják az általános pontosságot anélkül, hogy figyelembe vennék az egyes osztályok relatív eloszlását. Így az egyensúlytalan osztályeloszlás problémát jelent, mivel a tanulási algoritmusok alacsony prediktív pontossággal rendelkeznek a ritkán előforduló osztályok esetében. Ráadásul a közösségi média a kreatív nyelvi kifejezések természetes nyelvi variációját képviseli. Ebben a tanulmányban adatok kiegyensúlyozásának és neurális nyelvreprezentációs technikáinak kombinációját használtuk a kihívások kezelésére. Konkrétan részt vettünk az 1., 2. (minden nyelven), 4. és 3. feladatokban (csak a span felismerése, normalizáció nem történt) a Social Media Mining for Health alkalmazásokban (SMM4H) 2020 (Klein et al., 2020). Az eredmények azt mutatják, hogy a javasolt módszerrel a visszahívási pontszámok jobb, mint a megosztott feladatok pontossági pontszámai. A visszahívási pontszám is jobb az összes beadvány átlagos pontszámához képest. Azonban az F1 pontszám rosszabb, mint az átlagos pontszám, kivéve a 2. feladatot (francia).', 'ka': 'საზოგადომი მედიაციების განსაცნობა და ექსტრექტირება შესახებ, საზოგადომი მედიაციების განსაზღვრება ან განსაზღვრებული ეფექტი არის შესაძლებელი დავალებ სოციალური მედიაში შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი კლასის გაყოფილი ალგორიტემისთვის. ალგორიტიმები სწავლობა, რომელიც ტიპულად განაზღვრებულია, ყველა კლასის პირობილური გაყოფილი განაზღვრებას უცნობით. ამიტომ, განმავლობული კლასის გაყოფილება პრობლემატიურია, რადგან სწავლების ალგორიტიმები უფრო ცოტა წარმოდგენებული კლასის წარმოდგენება. დამატებით, სოციალური მედიაში ნაირთი ლენგურისტიკური განსხვავება კრეატიური ენის გამოსახულებში. ჩვენ ამ დოკუნეში მონაცემების ბალანსტირების და ნეიროლური ენაზე გამოყენებული ტექნექციების გამოყენება გამოყენებული. განსაკუთრებულად, ჩვენ ერთადერთი საქმედები 1, 2 (ყველა ენები), 4 და 3 (მხოლოდ განსაკუთრება განსაკუთრება, ნორმალიზაცია არ მოცდილობდა) სოციალური მედიაციის მიღება საჯანმრთელო პროგრამებისთვის (SM წარმოდგენები ჩვენებენ, რომ პროგრამა მეტოლოგიის შესახებ წარმოდგენები უკეთესი წარმოდგენებით, ვიდრე წარმოდგენების წარმოდგენები. შემხსენებელი მონაცემები უფრო უკეთესია, როგორც უფრო მეტი მონაცემების მონაცემებით. მაგრამ, F1- წერტილი უკეთესია, ვიდრე საშუალო წერტილი, მაგრამ მეორე წერტილი (ფრანუსი).', 'it': "Identificare ed estrarre segnalazioni di farmaci, loro abusi o effetti avversi dai social media è un compito impegnativo. Nei social media, i rapporti rilevanti sono molto rari, causa una distribuzione di classe sbilanciata per gli algoritmi di machine learning. Algoritmi di apprendimento tipicamente progettati per ottimizzare l'accuratezza complessiva senza considerare la distribuzione relativa di ogni classe. Pertanto, la distribuzione delle classi sbilanciata è problematica in quanto gli algoritmi di apprendimento hanno una bassa precisione predittiva per la classe poco frequente. Inoltre, i social media rappresentano una naturale variazione linguistica nelle espressioni linguistiche creative. In questo articolo, abbiamo utilizzato una combinazione di tecniche di bilanciamento dei dati e rappresentazione del linguaggio neurale per affrontare le sfide. Nello specifico, abbiamo partecipato alle attività condivise 1, 2 (tutte le lingue), 4 e 3 (solo il rilevamento della span, nessuna normalizzazione è stata tentata) in Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). I risultati mostrano che con la metodologia proposta i punteggi di richiamo sono migliori dei punteggi di precisione per le attività condivise. Il punteggio di richiamo è anche migliore rispetto al punteggio medio dei contributi totali. Tuttavia, il punteggio F1 è peggiore del punteggio medio tranne per il compito 2 (francese).", 'kk': 'Дәрігер туралы хабарламаларды анықтау және тарқату, олардың қорқыныштыру немесе социалдық медиақтағы қарсы әсер етпелері - әсер ететін тапсырма. Америкалық медиақта маңызды хабарламаларды қайталанбайды, машиналық оқыту алгоритмдерінің инбалансияланған класс үлестірімін сезіп береді. Әрбір классының қатынасыз үлестірімін түсінбей, жалпы дұрыстығын оптимизациялау үшін құрылған алгоритмдерді үйрену. Бұл үшін дисбалансияланған клас үлестірімі - оқыту алгоритмдерінің тәуелді класының дұрыстығы төмен. Сонымен қатар, әлеуметтік медиақтар жасаушылық тіл өрнектерінің табиғи лингвистикалық айнымалылығын көрсетеді. Бұл қағазда біз мәселелерді өзгерту үшін деректерді балансировау мен невралдық тілдерді көрсету техникаларын қолдандық. Ескерілікті, біз 1, 2 (барлық тілдер), 4 және 3 (тек тегіс анықтау үшін, нормализациялау мүмкін емес) әлемдік медиа бағалау қолданбаларында (SMM4H) 2020 (Klein et al., 2020). Нәтижелер тапсырмалардың дұрыс нәтижелерін тапсырмалардың дұрыс нәтижелерінен жақсы деп көрсетеді. Жалпы жіберушілердің орташа нөмірлеріне салыстырылып жатыр. Бірақ, F1- нөмірі 2- тапсырманың (французша) орташа нөмірінен артық.', 'ms': 'Mengenalpasti dan mengekstrak laporan ubat, penyalahgunaan atau kesan negatif dari media sosial adalah tugas yang mencabar. Dalam media sosial, laporan berkaitan sangat jarang, menyebabkan distribusi kelas tidak seimbang untuk algoritma pembelajaran mesin. Algoritma belajar biasanya dirancang untuk optimumkan ketepatan keseluruhan tanpa mempertimbangkan distribusi relatif setiap kelas. Oleh itu, distribusi kelas yang tidak seimbang adalah masalah kerana algoritma pembelajaran mempunyai ketepatan ramalan rendah untuk kelas jarang. Selain itu, media sosial mewakili variasi bahasa alam dalam ungkapan bahasa kreatif. Dalam kertas ini, kami telah menggunakan kombinasi keseimbangan data dan teknik perwakilan bahasa saraf untuk mengatasi cabaran. Specifically, we participated the shared tasks 1, 2 (all languages), 4, and 3 (only the span detection, no normalization was attempted) in Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020).  Keputusan menunjukkan bahawa dengan metodologi diusulkan skor pemulihan lebih baik daripada skor ketepatan untuk tugas berkongsi. Skor pemulihan juga lebih baik dibandingkan dengan skor rata-rata bagi kumpulan pengiriman. Namun, skor F1 lebih teruk daripada skor rata-rata kecuali tugas 2 (Perancis).', 'ml': 'മരുന്നുകളെപ്പറ്റി തിരിച്ചറിയുന്നതും പുറത്തെടുക്കുന്നതും സാമൂഹിക മീഡിയയില്\u200d നിന്നും അവരുടെ ഉപദ്രവിക്കുന സാമൂഹിക മാധ്യമങ്ങളില്\u200d പ്രധാനപ്പെട്ട റിപ്പോര്\u200dട്ടുകള്\u200d വളരെ അടിസ്ഥാനമാണ്. മെഷീന്\u200d പഠിക്കുന്നതിനുള്ള വിതരണ എല്ലാ ക്ലാസിന്റെയും അടുത്ത വിതരണ വിഭാഗമില്ലാതെ സാധാരണമായി പഠിപ്പിക്കുന്ന ആല്\u200dഗോരിത്മുകള്\u200d ഉപയോഗിക്കാന്\u200d  അതുകൊണ്ട്, അംഗോരിത്മുകള്\u200d പഠിക്കുന്നതിനാല്\u200d ക്ലാസിന്റെ വിതരണ പ്രശ്നങ്ങള്\u200d കുറച്ച് പ്രവചിക്കുന്നു പിന്നെ സാമൂഹ്യ മാധ്യമങ്ങള്\u200d സ്വാഭാവിക ഭാഷ വ്യത്യാസങ്ങളില്\u200d പ്രതിനിധിക്കുന്നു. ഈ പത്രത്തില്\u200d, നമ്മള്\u200d വിലാസങ്ങളെ വിശദീകരിക്കാന്\u200d വേണ്ടി ഒരു ഡേറ്റാ തുല്യമാക്കുന്നതും ന്യൂറല്\u200d ഭാഷ പ്രതിനിധികളു പ്രത്യേകിച്ച്, ഞങ്ങള്\u200d പങ്കെടുത്ത ജോലികളില്\u200d പങ്കുചേര്\u200dത്തിരിക്കുന്നു. 1, 2 (എല്ലാ ഭാഷകള്\u200d, 4, 3 (സ്പാന്\u200d കണ്ടുപിടിക്കുന്നത് മാത്രമാണ്, സാമൂഹിക മീഡിയ മിനിങ്ങില ഭാഗിക്കപ്പെട്ട ജോലികള്\u200dക്കുള്ള സ്കോര്\u200dട്ടിനെക്കാള്\u200d മെച്ചപ്പെട്ട മാറ്റോട്ടോളജി ഓര്\u200dമ്മിക്കുന്നതി The recall score is also better compared to the mean score of the total submissions.  എന്നാലും, എഫ്\u200c1 സ്കോര്\u200d നല്ല സ്കോരിനെക്കാള്\u200d മോശമാണ്. ജോലി 2 (ഫ്രെഞ്ച് 2) ഒഴികെ.', 'mn': 'Нийгмийн мэдээллийн хэрэгцээ, эсвэл эсрэг нөлөө үзүүлэх нь хэцүү ажил юм. Нийгмийн хэвлэлийн мэдээлэл дээр харилцааны мэдээллүүд маш ховорхон байдаг. Машин суралцах алгоритмын төлөвлөгөө маш баланс ангид хуваалцах боломжтой. Алгоритмыг сурах нь ангид бүр харьцаатай хуваарилцааны тухай бодохгүй ерөнхийдөө зөв тодорхойлох зориулагдсан. Тиймээс тэнцвэртэй хичээл хуваалцах нь суралцах алгоритмын тодорхойлолтой бага тодорхойлолтой. Мөн нийгмийн хэвлэл бүтээлч хэл илэрхийллийн байгалийн хэлний өөрчлөлтийг илэрхийлдэг. Энэ цаасан дээр бид өгөгдлийн баланслал болон мэдрэлийн хэл илэрхийлэл технологийг ашиглаж байна. Ялангуяа бид 1, 2 (бүх хэл), 4, 3 (зөвхөн нийгмийн мэдээлэл хөрөнгө оруулалт, эрүүл мэндийн хэрэглээ) 2020 (Klein et al., 2020) дахь хуваалцаагүй ажиллагаанд оролцсон. Үүний үр дүнд санал өгсөн методологийнхээ санах тоо нь хуваалцагдсан ажил дээр тодорхой тоонуудыг илүү сайн гэдгийг харуулж байна. Санах тоо мөн нийт дамжуулалтын дундаж тоонуудыг харьцуулахад илүү сайн байна. Гэхдээ F1 оноо нь 2 ажил (Француз) бусад дундаж оноос илүү муу.', 'lt': 'Sunkus uždavinys – nustatyti ir gauti pranešimus apie vaistus, jų piktnaudžiavimą ar nepageidaujamą poveikį socialinėje žiniasklaidoje. Socialinėje žiniasklaidoje atitinkamos ataskaitos yra labai nedažnos ir sukelia disbalansuotą klasių pasiskirstymą mašinų mokymosi algoritmams. Mokymosi algoritmai, paprastai sukurti siekiant optimizuoti bendrą tikslumą neatsižvelgiant į santykinį kiekvienos klasės pasiskirstymą. Thus, imbalanced class distribution is problematic as learning algorithms have low predictive accuracy for the infrequent class.  Moreover, social media represents natural linguistic variation in creative language expressions.  Šiame dokumente, sprendžiant uždavinius, pasinaudojome duomenų balansavimo ir nervinių kalbų atstovavimo metodų deriniu. Konkrečiai dalyvavome bendrose užduotyse 1, 2 (visos kalbos), 4 ir 3 (tik nustatant intervalą, nebuvo bandoma normalizuoti) Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). Iš rezultatų matyti, kad pasiūlytos metodikos atšaukimo rezultatai yra geresni už tikslius bendrų užduočių rezultatus. Atšaukimo rezultatas taip pat yra geresnis, palyginti su vidutiniu visų paraiškų rezultatu. Tačiau F1 rezultatas yra blogesnis už vidutinį rezultatą, išskyrus 2 užduotį (prancūzų kalba).', 'mt': 'L-identifikazzjoni u l-estrazzjoni ta’ rapporti ta’ mediċini, l-abbuż tagħhom jew l-effetti negattivi mill-midja soċjali hija kompitu ta’ sfida. Fil-midja soċjali, ir-rapporti rilevanti huma rari ħafna, u jikkawżaw distribuzzjoni żbilanċjata tal-klassijiet għall-algoritmi tat-tagħlim tal-magni. Algoritmi tat-tagħlim tipikament iddisinjati biex jottimizzaw il-preċiżjoni globali mingħajr ma jikkunsidraw id-distribuzzjoni relattiva ta’ kull klassi. Għalhekk, id-distribuzzjoni żbilanċjata tal-klassi hija problematika peress li l-algoritmi tat-tagħlim għandhom preċiżjoni prevedibbli baxxa għall-klassi mhux frekwenti. Barra minn hekk, il-midja soċjali tirrappreżenta varjazzjoni lingwistika naturali fl-espressjonijiet tal-lingwi kreattivi. F’dan id-dokument, użajna kombinazzjoni ta’ tekniki ta’ bbilanċjar tad-dejta u rappreżentazzjoni tal-lingwa newrali biex nindirizzaw l-isfidi. B’mod speċifiku, ipparteċipajna fil-kompiti kondiviżi 1, 2 (il-lingwi kollha), 4, u 3 (id-detezzjoni tal-firxa biss, ma ttieħdet l-ebda tentattiv ta’ normalizzazzjoni) fil-Minjieri tal-Midja Soċjali għall-applikazzjonijiet tas-Saħħa (SMM4H) 2020 (Klein et al., 2020). The results show that with the proposed methodology recall scores are better than the precision scores for the shared tasks.  Il-punteġġ tal-ġbir lura huwa wkoll aħjar meta mqabbel mal-punteġġ medju tas-sottomissjonijiet totali. Madankollu, il-punteġġ F1 huwa agħar mill-punteġġ medju ħlief għall-kompitu 2 (Franċiż).', 'pl': 'Identyfikowanie i wyciąganie raportów o lekach, ich nadużyciach lub niepożądanych skutkach z mediów społecznościowych jest trudnym zadaniem. W mediach społecznościowych istotne raporty są bardzo rzadkie, powodują nierównoważony rozkład klas dla algorytmów uczenia maszynowego. Algorytmy uczenia się zazwyczaj zaprojektowane w celu optymalizacji ogólnej dokładności bez uwzględnienia względnego rozkładu każdej klasy. Zatem niezrównoważony rozkład klas jest problematyczny, ponieważ algorytmy uczenia się mają niską dokładność predykcyjną dla rzadkiej klasy. Ponadto media społecznościowe reprezentują naturalną różnicę językową w kreatywnych wyrażaniach językowych. W niniejszym artykule wykorzystaliśmy połączenie technik równoważenia danych i neuronowej reprezentacji języka, aby sprostać wyzwaniom. W szczególności uczestniczyliśmy w wspólnych zadaniach 1, 2 (wszystkie języki), 4 i 3 (tylko wykrywanie rozpiętości, nie próbowano normalizacji) w Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Wyniki pokazują, że przy zaproponowanej metodologii wyniki przywołania są lepsze niż wyniki precyzyjne dla wspólnych zadań. Wynik przywołania jest również lepszy w porównaniu ze średnim wynikiem ogółu zgłoszeń. Jednak wynik F1 jest gorszy od średniego wyniku z wyjątkiem zadania 2 (francuski).', 'ro': 'Identificarea și extragerea rapoartelor de medicamente, abuzul sau efectele adverse ale acestora de pe rețelele sociale este o sarcină dificilă. În rețelele sociale, rapoartele relevante sunt foarte rar frecvente, cauzează distribuția dezechilibrată a claselor pentru algoritmii de învățare automată. Algoritmii de învățare proiectați de obicei pentru a optimiza acuratețea generală fără a lua în considerare distribuția relativă a fiecărei clase. Astfel, distribuția dezechilibrată a claselor este problematică deoarece algoritmii de învățare au o precizie predictivă scăzută pentru clasele rare. Mai mult decât atât, social media reprezintă variația lingvistică naturală în expresiile lingvistice creative. În această lucrare, am folosit o combinație de echilibrare a datelor și tehnici de reprezentare a limbajului neural pentru a aborda provocările. Mai exact, am participat la sarcinile comune 1, 2 (toate limbile), 4 și 3 (doar detectarea intervalului, nu a fost încercată normalizarea) în aplicațiile Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Rezultatele arată că cu metodologia propusă scorurile de rechemare sunt mai bune decât scorurile de precizie pentru sarcinile partajate. Scorul de rechemare este, de asemenea, mai bun în comparație cu scorul mediu al total depunerilor. Cu toate acestea, scorul F1 este mai rău decât scorul mediu, cu excepția sarcinii 2 (franceză).', 'no': 'Identifikasjon og utpakking av rapporter om medikamenter, bruk eller negativ effektar frå sosiale media er ein vanskeleg oppgåve. I sosiale medier er relevante rapporter veldig ofte, fører ulike klassefordeling for maskinelæringsalgoritme. Læring av algoritme som normalt er utforma for å optimalisera overalt nøyaktighet utan å forstå relativt distribusjon av kvar klasse. Derfor er det problematisk å forstå ulike klassefordeling, sidan læringsalgoritme har låg prediktiv nøyaktighet for den frekvens klassen. I tillegg representerer sosialmedia naturlige lingviske variasjonar i kreativ språk-uttrykk. I denne papiret har vi brukt ein kombinasjon av databalansering og neuralspråk-representasjonssteknikk for å handtera utfordringane. Spesielt delta vi delta delta delta oppgåva 1, 2 (alle språk), 4 og 3 (berre spenneoppdaginga, ingen normalisering var prøvd) i sosiale mediaminering for helseprogram (SMM4H) 2020 (Klein et al., 2020). Resultatet viser at med den foreslåde metodologien rekkjer oppføringar er bedre enn nøyaktighetspoeng for delte oppgåver. Påminningspunktet er også bedre samanlikna med gjennomsnittpunktet på totale innsendingar. F1- poengtet er imidlertid verre enn gjennomsnittpunktet unntatt oppgåva 2 (fransk).', 'sr': 'Identifikacija i izvlačenje izveštaja o lijekovima, njihovim zloupotrebima ili nevoljnim efektima iz društvenih medija je izazovan zadatak. U društvenim medijima, relevantni izveštaji su veoma rijetko, uzrokuje nerespoloženu raspodjelu klase za algoritme učenja mašina. Učenje algoritma obično dizajniranih da optimizuje ukupnu tačnost bez razmatranja relativne distribucije svake klase. Dakle, nedalansirana raspodjela klase je problematična jer algoritmi učenja imaju nisku predvidnu tačnost za narednu klasu. Osim toga, društveni mediji predstavljaju prirodnu lingvističku variaciju u kreativnim jezičkim izrazima. U ovom papiru, koristili smo kombinaciju tehnika za balanciranje podataka i predstavljanje neuralnog jezika kako bi se riješili izazovi. Posebno smo učestvovali zajedničke zadatke 1, 2 (svi jezici), 4 i 3 (samo otkrivanje razdoblja, nijedna normalizacija nije pokušala) u prijavama za rudarstvo društvenih medija za zdravlje (SMM4H) 2020 (Klein et al., 2020). Rezultati pokazuju da su rezultati predložene metodologije bolje od preciznih rezultata za zajedničke zadatke. Rezultat podataka je i bolje u usporedbi sa srednjim rezultatima ukupnih podataka. Međutim, rezultat F1 je gore od srednjeg rezultata osim zadatka 2 (francuski).', 'si': 'සාමාජික මාධ්\u200dයමාධ්\u200dයමයෙන් ප්\u200dරතිපත්තියක් අඳුරගන්න සහ ප්\u200dරතිපත්තියක් ප්\u200dරතිපත්ත කරන්න සහ ප්\u200dරතිපත සාමාජික මාධ්\u200dයානයේදී, සම්බන්ධ වාර්තාව ගොඩක් ප්\u200dරශ්නයක් නැති වෙනවා, මෙෂින් ඉගෙනීම් ඇල්ගෝ සාමාන්\u200dයයෙන්ම ඇල්ගෝරිත්ම් ඉගෙන ගන්න සිද්ධ වෙන්නේ හැම ප්\u200dරශ්නයක්ම සම්පූර්ණතාවක්ම සුද්ධ විතර ඉතින්, අන්තිමත් ප්\u200dරශ්න විතරය ප්\u200dරශ්නයක් තියෙන්නේ ඇල්ගෝරිතම්වල් ඉගෙන ගන්න අඩු අනතුරු ප්\u200dරශ්නයක තවත්, සාමාජික භාෂාවික භාෂාවික භාෂාවික වෙනස් ප්\u200dරතිදේශ කරනවා. මේ පත්තරේ අපි දත්ත සැලසුම් සහ න්\u200dයූරාල භාෂාව ප්\u200dරතිනිධාන විද්\u200dයාවක් පාවිච්චි කරලා තියෙනවා. විශේෂයෙන්ම, අපි සාමාජික මාධ්\u200dයාත්මක ප්\u200dරයෝජනය (SMM4H) 2020යි (Klein et al., 2020යි) සමාජික මාධ්\u200dයාත්මක ප්\u200dරයෝජනය සඳහා සාමාජික විශ්වාස කරන ප්\u200dරතිචාරය පෙන්වන්නේ ප්\u200dරතිචාරිත විද්\u200dයාවයෙන් ප්\u200dරතිචාරිත විද්\u200dයාවය මතක කරන්න ප්\u200dරතිචාරය වඩා හො මතක ස්කෝර් එක්ක වඩා හොඳයි සම්පූර්ණ ස්කෝර් එක්ක සම්පූර්ණ ස්කෝර් එක්ක. නමුත්, F1- ස්කෝර් එක අමාරු ස්කෝර් එකට වඩා නරකයි (ෆ්\u200dරෑන්ස්) වැඩක් විතරයි.', 'so': 'Aqoonsashada iyo soo bixinta warbixinta dawooyinka, isticmaalkooda ama saameyaasha caawimaadka ah ee shabakadda bulshada waa arin dhib leh. Macluumaadka bulshada ee ku saabsan macluumaadyadu waa mid aad u caadi ah, sababtoo ah qaybinta fasalka aan la qiimo karin qoraalka waxbarashada machineedka. Waxbarashada algorithamka sida caadiga ah waxaa loo qoray si uu u beddelo saxda dhamaantood iyadoon ka fiirsanayn qaybinta qaraabada ee fasalka walba. Sidaa darteed qaybinta fasalka aan la qiimo karin waa dhibaato, sababtoo ah barashada algorithadu waxay leeyihiin xisaabta la sii sheegayo oo yar fasalka hoose u socda. Sidoo kale shabakadda bulshada ayaa ka muuqata isbedelka luuqadda dabiicadda ah oo ku qoran hadalka afka abuurta. Warqaddan waxaynu ku isticmaalnay isku daro macluumaad la mid ah iyo qaabilaad luqada neurada ah si aan uga sheekeyno dhibaatooyinka. Si gaar ah, waxaynu ka qeybqaadanay shuqullada la qaybsan 1, 2 (dhammaan luqadaha), 4 iyo 3 (oo kaliya baaritaanka spanishka, aan la jarrabin caafimaadka) ee macluumaadka sooshalka (SMM4H) 2020 (Klein et al., 2020). Midhaha la soo jeedo waxay tustaa in goobta lagu soo jeedo kooxda soo xusuusta ay ka wanaagsan yihiin qiimaha saxda ah ee shaqada la qaybsan. Sidoo kale qiimeynta xasuusta waxaa ka wanaagsan in la barbardhigo qiimeynta dhamaanka. Si kastaba ha ahaatee, scorka F1 waa ka sii xumaa scorka caadiga ah shaqo 2 (Faransiis).', 'sv': 'Att identifiera och extrahera rapporter om mediciner, deras missbruk eller negativa effekter från sociala medier är en utmanande uppgift. I sociala medier är relevanta rapporter mycket sällan förekommande, vilket orsakar obalanserad klassfördelning för maskininlärningsalgoritmer. Lärningsalgoritmer som vanligtvis utformats för att optimera den totala noggrannheten utan att beakta den relativa fördelningen av varje klass. Därför är obalanserad klassfördelning problematisk eftersom inlärningsalgoritmer har låg prediktiv noggrannhet för den sällan förekommande klassen. Sociala medier representerar dessutom en naturlig språklig variation i kreativa språkuttryck. I denna uppsats har vi använt en kombination av databalansering och neurala språkrepresentationstekniker för att hantera utmaningarna. Specifikt deltog vi i de delade uppgifterna 1, 2 (alla språk), 4 och 3 (endast span detektering, ingen normalisering försökte) i Social Media Mining for Health applikationer (SMM4H) 2020 (Klein et al., 2020). Resultaten visar att med den föreslagna metoden är återkallelsepoängen bättre än precisionspoängen för de delade uppgifterna. Återkallande poäng är också bättre jämfört med medelpoängen för de totala inlämningarna. F1-poängen är dock sämre än medelpoängen förutom uppgift 2 (franska).', 'ta': 'மருத்துவர்களை அடையாளம் மற்றும் வெளியேற்றுதல் அறிக்கைகள், அவர்களுடைய தீங்கு அல்லது சமூக ஊடகங்களிலிருந்து எதிர்க சமூக ஊடகங்களில் தொடர்புடைய அறிக்கைகள் மிகவும் அடிப்படையாக இருக்கிறது, இயந்திரத்தை கற்றுக்கொள்ள இயந்திரத்திற்கு சம ஒவ்வொரு வகுப்பின் சார்ந்த பங்கீட்டை பரிசோதிக்காமல் மொத்த சரிவுகளை மேம்படுத்த வடிவமைக்கப்பட்டுள்ள ஆல்பரிட்டம் ஆகவே, சமமான வகுப்பு பங்கீடு பிரச்சனையானது, கல்வி படிக்கும் கல்வி வகுப்புகளுக்கு குறைவான முன்வார்வையான துல்லியம். மேலும், சமூக ஊடகங்கள் இயற்கையான மொழி மொழியின் மாறுபாடுகளை குறிப்பிடுகிறது. இந்த காகிதத்தில், நாங்கள் தரவு நிறுவுதல் மற்றும் பாதுகாப்பு மொழி குறிப்பிடும் தொழில்நுட்பம் பயன்படுத்தி சவ குறிப்பிட்டு, நாங்கள் பங்கிடப்பட்ட பணிகளில் பங்கிடப்பட்டது 1, 2 (அனைத்து மொழிகள், 4, மற்றும் 3 (ஸ்பான் கண்டுபிடிப்பு, சாதாரண முயற்சிக்கப்படவில்லை) 2020 (சாலிக ஊடகங்கள முடிவுகள் தெரியும் முறைமையான நினைவு மதிப்புகளுடன் பகிர்ந்த பணிகளுக்கு சரியான மதிப்பெண்களை விட மேலானது. நினைவு மதிப்பெண்கள் மொத்த இஸ்லிம்களின் சராசரியான மதிப்பெண்ணை ஒப்பிடுவதும் சிறந்தது. எப்படியும், F1- மதிப்பெண்கள் செயல் 2 (பிரெஞ்சுக்கு தவிர அதிக மதிப்பெண்ணை விட மோசமாகும்.', 'ur': 'مواد کی راپوروں کی شناسایی اور اضافہ کرنا، سوسیل میڈیا سے ان کی بدکاری یا مخالف اثرات ایک مشکل کام ہے. سوسیل میڈیا میں، معاملہ ریپورٹ بہت غیر عادت ہیں، ماشین یادگاری الگوریتم کے لئے غیر مساوی کلاس تقسیم کا سبب ہے. الگوریتموں کی تعلیم معمولی طور پر طراحی کی جاتی ہے کہ ہر کلاس کی نسبتی تقسیم کو بغیر نظر نہ کریں سب کی دقیقیت کو اچھی طراحی کرنے کے لئے۔ اسی طرح، نابرالنس کلاس تقسیم مشکل ہے جیسے الگوریتموں کی تعلیم کم پیش بینی کی دقیق ہے۔ اور اس کے علاوہ، سوسیل میڈیا، مخلوقات زبان کی تعریف میں طبیعی زبان کی تغییر کی تعریف کرتا ہے. اس کاغذ میں ہم نے ڈیٹا برالنس اور نئورل زبان کی نمایش تکنیک استعمال کی ہے چلنے کے لئے۔ مخصوص طور پر، ہم نے 1, 2 (تمام زبانوں), 4 اور 3 (صرف اسپانیٹ شناسایی، کوئی عاملی کی کوشش نہیں کی) اجتماعی میڈیا مینڈی سلامتی کاریالوں کے لئے (SMM4H) 2020 (Klein et al., 2020) میں شریک کیا۔ نتیجے دکھاتے ہیں کہ پیشنهاد فرضی کے مطالعہ سے ذکر اسکور شریک کاروں کے مطالعہ سے بہتر ہیں. یادآوری اسکور بھی بہتر ہے جتنے کامل مسلمانوں کے متوسط اسکور کے مقابلہ میں۔ However, the F1-score is worse than the mean score except task 2 (French).', 'mk': 'Идентификувањето и извлекувањето извештаи за лековите, нивното злоупотреба или негативните ефекти од социјалните медиуми е предизвикувачка задача. Во социјалните медиуми, релевантните извештаи се многу ретки, предизвикуваат нерамнотежна дистрибуција на класата за алгоритми за машинско учење. Алгоритми за учење обично дизајнирани за оптимизација на целокупната точност без разгледување на релативната дистрибуција на секоја класа. Затоа, нерамнотежната дистрибуција на класата е проблематична бидејќи алгоритмите за учење имаат ниска претпоставувачка точност за нечестото класа. Покрај тоа, социјалните медиуми претставуваат природна јазична варијација во креативните јазички изрази. Во овој документ, користевме комбинација на балансирање на податоци и техники за претставување на нервниот јазик за решавање на предизвиците. Специфично, учествувавме во заедничките задачи 1, 2 (сите јазици), 4 и 3 (само детекција на растојание, не се обиде нормализација) во Социјалните медиуми минирање за здравствени апликации (СММ4Х) 2020 (Klein et al., 2020). Резултатите покажуваат дека со предложената методологија резултатите за повлекување се подобри од прецизните резултати за заедничките задачи. Резултатот за повлекување е, исто така, подобар во споредба со просечниот резултат на вкупните поднесувања. However, the F1-score is worse than the mean score except for task 2 (French).', 'uz': "Davlatlarni aniqlash va olib tashlash haqida qo'shish, ularning isticmaallari yoki shaxsiy effektlarini ajratish va qo'shish muvaffaqiyatli. Мувофиқ маълумотларда, муҳим маълумотлар жуда қизиқроқ, мошининг алгориталарини ўргатиш учун система таркибида тақсимлантирилади. Algoritlarni o'rganish, har bir sinfning qisqa ajratishni tasdiqlash uchun umumiy imkoniyatlarni moslash mumkin. Шундай қилиб, sinf ajratish muammolari, chunki o'rganish algoritlari asosiy darajadagi foydalanuvchi darajaga kamaytirish imkoniyati. Ko'rsatganda, jamiyat mediyati ijodkorlik tilning fikrlarida o'zgarishni o'zgartiradi. Bu qogʻozda, biz muammolarni murakkab qilish uchun ma'lumotni birlashtirish va yaxshi tilni taʼminlashtirish techniqali ishlatdik. Ko'rsatilgan, biz bir, 2 (hamma tillar), 4 va 3 (faqat span aniqlanish, oddiylik tizimini aniqlashni istamaydi) 2020 (Klein et, 2020) sosialom media dasturlari uchun sog'lokal dasturlarni boshqarishga qaramay qildik. @ info: status Qaytarish qiymatlari butun musiqalarning eng kichkina qiymatga ega. Lekin, F1 qiymat 2 vazifa (Fransuzcha) bilan eng qiymatdan ortiq.", 'vi': 'Việc xác định và lấy được báo cáo về các loại thuốc, lạm dụng hay tác động xấu từ các phương tiện xã hội là một thử thách. Trong các phương tiện xã hội, các báo cáo liên quan rất hiếm, gây ra sự phân phối xã hội thiếu cân bằng cho thuật toán học máy. Học thuật to án đặc biệt được thiết kế để tối ưu hóa độ chính xác tổng thể mà không xem xét phân phối tương đối của mỗi lớp. Do đó, phân phối lớp học thiếu cân bằng là vấn đề vì thuật toán học có độ chính xác dự đoán thấp đối với lớp hiếm gặp. Hơn nữa, các phương tiện xã hội đại diện cho sự biến đổi ngôn ngữ tự nhiên. Trong tờ giấy này, chúng tôi đã sử dụng một tổ hợp các công nghệ cân bằng dữ liệu và đại diện ngôn ngữ thần kinh để giải quyết thử thách. Cụ thể, chúng tôi tham gia các công việc chia sẻ 1, 2 (mọi ngôn ngữ), 4, và 3 (chỉ có khả năng tìm ra thời gian, không có sự bình thường) trong dịch vụ Động vật y tế (SMR4H) 2020 (Klein et al., 2020). Kết quả cho thấy rằng với phương pháp triệu tập điểm là tốt hơn điểm chính xác cho các công việc chia sẻ. Điểm thu hồi cũng tốt hơn so với tỉ số trung bình của to àn bộ tài liệu. Tuy nhiên, điểm số F1 còn tệ hơn điểm số trung bình ngoại trừ nhiệm vụ 2 (Pháp).', 'bg': 'Идентифицирането и извличането на доклади за лекарства, тяхното злоупотреба или неблагоприятни ефекти от социалните медии е трудна задача. В социалните медии съответните доклади са много редки, причиняват дисбалансирано разпределение на класовете за алгоритми за машинно обучение. Учебните алгоритми обикновено са предназначени да оптимизират общата точност, без да се отчита относителното разпределение на всеки клас. По този начин дисбалансираното разпределение на класовете е проблематично, тъй като учебните алгоритми имат ниска предсказуема точност за редкия клас. Освен това социалните медии представляват естествена лингвистична вариация в творческите езикови изрази. В тази статия ние използваме комбинация от техники за балансиране на данни и невронно езиково представяне, за да се справим с предизвикателствата. По-конкретно, участвахме в споделените задачи 1, 2 (всички езици), 4 и 3 (само откриване на обхват, не беше направено опит за нормализиране) в Социалните медии Минно дело за здравеопазване (Клейн и др., 2020). Резултатите показват, че с предложената методология резултатите за споменаване са по-добри от прецизните оценки за споделените задачи. Рекламният резултат също е по-добър в сравнение със средния резултат на всички подадени заявки. Въпреки това, резултатът е по-лош от средния резултат, с изключение на задача 2 (френски).', 'nl': 'Het identificeren en extraheren van meldingen van medicijnen, hun misbruik of bijwerkingen van sociale media is een uitdagende taak. In sociale media komen relevante rapporten zeer zelden voor, wat een onevenwichtige klasverdeling voor machine learning algoritmes veroorzaakt. Lerende algoritmen zijn meestal ontworpen om de algehele nauwkeurigheid te optimaliseren zonder rekening te houden met de relatieve verdeling van elke klasse. Zo is een onevenwichtige klasverdeling problematisch omdat leeralgoritmes een lage voorspellende nauwkeurigheid hebben voor de zeldzame klas. Bovendien vertegenwoordigt sociale media natuurlijke taalvariatie in creatieve taaluitingen. In dit artikel hebben we een combinatie van data balancing en neurale taalrepresentatietechnieken gebruikt om de uitdagingen aan te pakken. Specifiek namen we deel aan de gedeelde taken 1, 2 (alle talen), 4 en 3 (alleen de spandetectie, geen normalisatie werd geprobeerd) in Social Media Mining for Health toepassingen (SMM4H) 2020 (Klein et al., 2020). De resultaten tonen aan dat met de voorgestelde methodologie recall scores beter zijn dan de precisiescores voor de gedeelde taken. De recall score is ook beter vergeleken met de gemiddelde score van de totale inzendingen. De F1-score is echter slechter dan de gemiddelde score behalve voor taak 2 (Frans).', 'da': 'At identificere og udtrække rapporter om medicin, deres misbrug eller bivirkninger fra sociale medier er en udfordrende opgave. I sociale medier er relevante rapporter meget sjældne, forårsager ubalanceret klassefordeling for maskinlæringsalgoritmer. Læringsalgoritmer typisk designet til at optimere den samlede nøjagtighed uden at overveje den relative fordeling af hver klasse. Derfor er ubalanceret klassefordeling problematisk, da læringsalgoritmer har lav prædiktiv nøjagtighed for den sjældne klasse. Desuden repræsenterer sociale medier naturlig sproglig variation i kreative sprogudtryk. I denne artikel har vi brugt en kombination af databalancering og neurale sprogrepræsentationsteknikker til at løse udfordringerne. Specielt deltog vi i de delte opgaver 1, 2 (alle sprog), 4 og 3 (kun spændingsdetektion, ingen normalisering blev forsøgt) i Social Media Mining for Health applikationer (SMM4H) 2020 (Klein et al., 2020). Resultaterne viser, at med den foreslåede metode tilbagekaldelse scores er bedre end præcisionsscores for de delte opgaver. Tilbagekaldelsescoren er også bedre sammenlignet med gennemsnitsscoren for de samlede indsendelser. F1-scoren er dog værre end gennemsnitsscoren undtagen for opgave 2 (fransk).', 'hr': 'Otkrivanje i izvlačenje izvješća o lijekovima, njihovim zloupotrebima ili nuspojavama iz društvenih medija je izazovan zadatak. U društvenim medijima, relevantne izvještaje su veoma rijetko, uzrokuju nesporazno distribuciju klase za algoritme učenja strojeva. Učenje algoritma obično dizajniranih kako bi optimiziralo ukupnu preciznost bez razmatranja relativne distribucije svake klase. Dakle, nedalansirana raspodjela klase je problematična jer algoritmi učenja imaju nisku predviđavajuću preciznost za čudno klase. Osim toga, društveni mediji predstavljaju prirodnu jezičku varijaciju u kreativnim jezičkim izrazima. U ovom papiru, koristili smo kombinaciju tehnika za balanciranje podataka i zastupanje neuralnog jezika kako bi se riješili izazovima. Posebno smo učestvovali zajedničke zadatke 1, 2 (svih jezika), 4 i 3 (samo otkrivanje razdoblja, nijedna normalizacija nije pokušala) u prijavama o rudarstvu socijalnih medija za zdravlje (SMM4H) 2020 (Klein et al., 2020). Rezultati pokazuju da su rezultati predložene metodologije bolje od preciznih rezultata za zajedničke zadatke. Rezultat podsjetnika također je bolji u usporedbi s srednjim rezultatima ukupnih podataka. Međutim, rezultat F1-a je gore od srednjeg rezultata osim zadatka 2 (francuski).', 'de': 'Das Erkennen und Extrahieren von Berichten über Medikamente, deren Missbrauch oder negative Auswirkungen aus sozialen Medien ist eine herausfordernde Aufgabe. In sozialen Medien sind relevante Berichte sehr selten, was zu einer ungleichmäßigen Klassenverteilung für Machine Learning Algorithmen führt. Lernalgorithmen wurden typischerweise entwickelt, um die Gesamtgenauigkeit zu optimieren, ohne die relative Verteilung der einzelnen Klassen zu berücksichtigen. Daher ist eine ungleichmäßige Klassenverteilung problematisch, da Lernalgorithmen eine geringe Vorhersagegenauigkeit für die seltene Klasse haben. Darüber hinaus repräsentieren soziale Medien natürliche sprachliche Variationen kreativer Sprachausdrücke. In diesem Beitrag haben wir eine Kombination aus Data Balancing und neuronalen Sprachrepräsentationstechniken verwendet, um die Herausforderungen anzugehen. Konkret beteiligten wir uns an den gemeinsamen Aufgaben 1, 2 (alle Sprachen), 4 und 3 (nur die Span-Erkennung, keine Normalisierung wurde versucht) in Social Media Mining for Health Anwendungen (SMM4H) 2020 (Klein et al., 2020). Die Ergebnisse zeigen, dass mit der vorgeschlagenen Methodik Recall Scores besser sind als die Precision Scores für die geteilten Aufgaben. Der Recall Score ist auch besser als der Mittelwert der gesamten Einreichungen. Allerdings ist die F1-Punktzahl schlechter als die mittlere Punktzahl außer Aufgabe 2 (Französisch).', 'ko': '소셜미디어에서 약물, 약물 남용, 불량반응을 식별하고 추출하는 보고서는 도전적인 과제다.소셜 미디어에서 관련 보도가 매우 적어 기계 학습 알고리즘의 유형 분포가 불균형적이다.학습 알고리즘은 일반적으로 전체 정밀도를 최적화하는 데 목적을 두고 모든 종류의 상대적인 분포를 고려하지 않는다.따라서 불균형적인 클래스 분포는 문제가 있다. 학습 알고리즘이 빈번하지 않은 클래스에 대한 예측 정밀도가 비교적 낮기 때문이다.또 소셜미디어는 창조적 언어 표현에서의 자연적 언어 변이를 대표한다.본고에서 우리는 데이터 균형과 신경 언어 표시 기술을 결합하여 이런 도전에 대응했다.구체적으로 2020년 건강앱 소셜미디어 발굴(SMM4H)에서 공유 임무 1, 2(모든 언어), 4, 3(크로스 테스트만 하고 표준화를 시도하지 않음)에 참여했다.그 결과 공유 임무에 대한 이 방법의 회상 점수는 정확한 점수보다 높았다.모든 제출 평균 점수보다 추억 점수도 좋다.그러나 F1은 미션2(프랑스어)를 제외하고는 평균보다 성적이 좋지 않았다.', 'id': 'Identifikasi dan ekstraksi laporan obat, penyalahgunaan atau efek negatif dari media sosial adalah tugas yang menantang. Dalam media sosial, laporan relevan sangat jarang, menyebabkan distribusi kelas yang tidak seimbang untuk algoritma pembelajaran mesin. Algoritma belajar biasanya dirancang untuk optimisasi akurasi umum tanpa mempertimbangkan distribusi relatif setiap kelas. Jadi, distribusi kelas yang tidak seimbang adalah problematik karena algoritma belajar memiliki akurasi prediksi rendah untuk kelas tidak sering. Selain itu, media sosial mewakili variasi bahasa alam dalam ekspresi bahasa kreatif. Dalam kertas ini, kami telah menggunakan kombinasi keseimbangan data dan teknik representation bahasa saraf untuk mengatasi tantangan. Specifically, we participated the shared tasks 1, 2 (all languages), 4, and 3 (only the span detection, no normalization was attempted) in Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020).  Hasilnya menunjukkan bahwa dengan metodologi yang diusulkan skor kembali lebih baik dari skor presisi untuk tugas yang sama. Skor pengingat juga lebih baik dibandingkan dengan skor rata-rata dari total pengiriman. Namun, skor F1 lebih buruk dari skor rata-rata kecuali untuk tugas 2 (Perancis).', 'fa': 'شناسایی و استخراج گزارش داروها، اثرات مختلف از رسانه های اجتماعی آنها یا استفاده از رسانه های اجتماعی یک کار سخت است. در رسانه\u200cهای اجتماعی، گزارش\u200cهای مربوط به شدت غیر عادی هستند، باعث توزیع کلاس نابرانگیز برای الگوریتم یادگیری ماشین است. الگوریتم یاد گرفتن معمولا طراحی شده تا دقیقات عمومی را بدون توجه به تقسیم نسبتی هر کلاس بهترین سازی کند. بنابراین، تقسیم کلاس نابرابری مشکلی است چون الگوریتم یادگیری دقیق پیش بینی کم برای کلاس نابرابری دارد. علاوه بر این، رسانه\u200cهای اجتماعی تغییرات زبان طبیعی در تعریف زبان خلاقی نشان می\u200cدهد. در این کاغذ، ما از ترکیب داده\u200cها و تکنیک نمایش زبان عصبی برای حل چالش استفاده کردیم. مخصوصاً ما در کارهای مشترک ۱، ۲ (همه زبان\u200cها), ۴ و ۳ (تنها تشخیص طول\u200cکشی، تلاش\u200cهای معمولی\u200cسازی) در کاربرد وزن رسانه\u200cهای اجتماعی برای سلامتی (SMM4H) ۲۰۰۲ (Klein et al., 2020) شرکت کردیم. نتیجه\u200cها نشان می\u200cدهند که با metoدولوژی پیشنهاد امتیاز یاد کردن امتیاز\u200cها بهتر از امتیاز دقیق برای کارهای مشترک هستند. نقاط یادآوری هم بهتر است در مقایسه با نقاط متوسط تحویل عمومی. ولی امتیاز F1 بدتر از امتیاز متوسط جز کار ۲ (فرانسوی) است.', 'sw': 'Kutambua na kutoa taarifa za madawa, unyanyasaji au madhara mbaya kutoka kwenye mitandao ya kijamii ni kazi yenye changamoto. Katika mitandao ya kijamii, taarifa zinazohusiana ni vikali, zinasababisha usambazaji wa darasa lisilo na usawa kwa ajili ya utaratibu wa kujifunza mashine. Kujifunza algorithi kwa kawaida imeundwa kuboresha uhakika wa jumla bila kuzingatia usambazaji wa karibu wa kila darasa. Kwa hiyo, usambazaji wa darasa lisilo na usawa ni tatizo kwani vipengele vya kujifunza vina uhakika mdogo wa kutabiri kwa darasa la msingi. Moreover, social media represents natural linguistic variation in creative language expressions.  Katika gazeti hili, tumetumia muunganiko wa taarifa za usambazaji na mbinu za uwakilizaji wa lugha ya asili ili kutangaza changamoto hizo. Kwa ujumla, tulishiriki kazi za kushirikiana 1, 2 (lugha zote), 4 na 3 (pekee ya kutambua lugha za spania, hakuna utaratibu wa kawaida ulijaribu) katika vyombo vya habari vya kijamii kwa ajili ya matumizi ya afya (SMM4H) 2020 (Klein et, 2020). Matokeo yanaonyesha kwamba kwa njia zilizopendekezwa kukumbuka vipimo vyema ni bora kuliko vipimo vya sahihi kwa kazi zinazoshirikishwa. Matokeo ya kumbukumbu ni bora zaidi kulinganisha na kiwango cha wastani cha ujumbe wa jumla. Hata hivyo, score ya F1 ni mbaya zaidi ya score yenye maana isipokuwa kwa kazi 2 (Kifaransa).', 'sq': 'Identifikimi dhe nxjerrimi i raporteve të ilaçeve, abuzimit të tyre apo efekteve të dëmshme nga media sociale është një detyrë sfiduese. Në mediat shoqërore, raportet e rëndësishme janë shumë të pakta, shkaktojnë shpërndarjen e paekuilibruar të klasave për algoritmet e mësimit të makinave. Algoritmet e mësimit tipikisht të dizajnuara për të optimizuar saktësinë e përgjithshme pa konsideruar shpërndarjen relative të çdo klase. Kështu, shpërndarja e paekuilibruar e klasës është problematike pasi algoritmet e mësimit kanë saktësi të ulët parashikuese për klasën e paprekur. Përveç kësaj, media sociale përfaqëson ndryshimin natyror gjuhësor në shprehjet kreative të gjuhës. Në këtë letër, kemi përdorur një kombinim të ekuilibrimit të të dhënave dhe teknikave të përfaqësimit të gjuhës nervore për të trajtuar sfidat. Veçanërisht, ne morëm pjesë në detyrat e përbashkëta 1, 2 (të gjitha gjuhët), 4 dhe 3 (vetëm zbulimi i zgjatjes, nuk u përpoq normalizimi) në Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). Rezultatet tregojnë se me metodologjinë e propozuar rezultatet e tërheqjes janë më të mira se rezultatet e saktësisë për detyrat e përbashkëta. Rezultati i tërheqjes është gjithashtu më i mirë krahasuar me rezultatin mesatar të paraqitjeve të përgjithshme. Megjithatë, rezultati F1 është më i keq se rezultati mesatar përveç detyrës 2 (franceze).', 'tr': 'Nämedileriň hasaplaryny tanamak we çykarmak, sosyal mediýallarynyň ýüzüniň ýa-da täsirli täsirleri kynçylykdyr. Sosialy medýdançalarda möhüm raporlar gaty zäsirli bolup bilýär, maşynyň öwrenme algoritmalaryny üçin täsirli klas daýlamagyny sebäp edýär. Adatça öwrenmek algoritmalary her synyň relativ daýratyny maslahat etmek üçin düzenlenen. Bu sebäpli, täsirli synp daýlamagynda öwrenme algoritmalarynyň ýakyn synpdaky tapawutlygynyň düşük tapawutlygy bar. Munuň üçin sosyal medýatlar tebigat dil üýtgeşmelerini döredijili dillerde tapawutlandyrýar. Bu kagyzda çözgütleri çözmek üçin maglumatlary balanlama we neural dil temsillemek tekniklerini ulandyk. Adatça, biz 1, 2 (ähli diller), 4 we 3 (diňe gollanyşyk tapylýan zada gollanmaýarys) Sosial Media Taýramçylygy Saglyk Uygulamalarynda (SMM4H) 2020 (Klein et al., 2020). Netijeler teklip eden metodologiýanyň hatlary üçin paylaşyk görenler üçin dogry notlaryň has gowydygyny görkezýär. Hata sanlary hem toplam gönderilen orta sanlary bilen gurlaşýar. Ýöne, F1-noty 2 işiň ýöne orta sanlaryndan erbet.', 'az': 'İlaçların xəbərlərini, sosyal mediyalarından istifadə etmələri və təsirlərini təşkil etmək və çıxartmaq çətin bir işdir. Sosyal media içində məlumatlı raporlar çox sıxıntısızdır, maşın öyrənməsi algoritmi üçün dəyişiklik sınıf dağıtımı olar. Hər sınıfın relativ dağılışını düşünmədən bütün doğruluqları optimizləmək üçün müəyyən edilən algoritmi öyrənmək. Beləliklə, müəyyən dərəcə dağıtımı öyrənmək algoritmlərinin az tədbir dərəcəsinə baxmayaraq problematik idi. Əksinə, sosyal media yaradıcı dil ifadələrində təbiətli dil dəyişikliklərini göstərir. Bu kağızda, çətinliklərə çəkinmək üçün məlumatları balanslama və nöral dil təsirlərinin birləşdirilməsi üçün istifadə etdik. Özellikle, biz 1, 2 (bütün dillər), 4 və 3 (yalnız müxtəlif təşkil edilmək, heç bir normalizasyon quraqlıq edilməyən) vəzifələrə (SMM4H) 2020 (Klein et al., 2020) katıldıq. Sonuçlar təbliğ edilmiş metodolojiyi yada salmaq məqsədilə paylaşılan işlərin məqsədilərin məqsədilə dəyişiklik nöqtələrindən daha yaxşıdır. Seçmə nöqtəsi həmçinin toplam göndərilənlərin orta nöqtəsi ilə daha yaxşıdır. Ancaq, F1-score 2 işdən başqa orta nöqtədən daha pisdir.', 'am': 'ማኅበራዊ ሚዲያ ላይ የሚቆጣጠሩ ማህበራዊ ሚዲያዎች የድካም ጉዳይ ነው፡፡ በማኅበራዊ አውታር ውስጥ ግንኙነት ጉዳይ ብዙ ጥያቄ ነው፡፡ የመኪን ትምህርት አሌጎሪትምን ለማስተማር የክፍል ክፍል የሚያደርጋል፡፡ የአልጎርጂቶች ትምህርት በሁሉም ክፍል የአካባቢ ክፍል ሳይያስተካክሉ የሙሉ እርግጠኝነትን ማምረጥ በተለየ፡፡ ስለዚህም የክፍለ ክፍል ክፍተት መማር ዓልgorithም ለጥያቄው ክፍተት ዝቅተኛ ነው፡፡ እናም ማኅበራዊ ሚዲያዎች ፍጥረት ቋንቋ ቋንቋ መለወጥ ነው፡፡ በዚህ ካላት፣ የዳታ ሚዛን እና የደዌብ ቋንቋ መልዕክት እና ጥቃቄዎችን ለመጠየቅ ጥያቄዎችን ለመጠየቅ ጥያቄዎችን ተጠቅመን ነበር፡፡ በተለይም፣ 1፣ 2 (ሁሉም ቋንቋዎች)፣ 4 እና 3 (ለስፓን ማግኘት ብቻ ነው፣ ማንም የተለመደ ነው) በማኅበራዊ ሚዲያ ለጤና ፕሮግራሞች ማሳየት (SMM4H) 2020 (Klein et al., 2020). ፍጥረቶቹ በተዘጋጀው የሞክራዊ ማስታወስ ቀለበቶች ለታዋቂው ስራዎችን ከመልካም እንዲሻሉ ያሳያል፡፡ ማስታወቂያው ቁጥር በሙሉ አዋቂው ክፍል ይሻላል፡፡ However, the F1-score is worse than the mean score except for task 2 (French).', 'hy': 'Դժվար խնդիր է բացահայտել և դուրս բերել դեղամիջոցների, նրանց չարաշահումը կամ բացասական ազդեցությունները սոցիալական լրատվամիջոցներից: Սոցիալական լրատվամիջոցներում հարկավոր զեկույցները շատ հազվադեպ են, պատճառով է անհավասարակշռություն դասարանի տարածումը մեքենային ուսումնասիրության ալգորիթմների համար: Ալգորիթմներ սովորելու համար, որոնք սովորաբար նախագծված են որպեսզի օպտիմացնեն ընդհանուր ճշգրտությունը առանց հաշվի առնելու յուրաքանչյուր դասարանի հարաբերական բաշխման: Այսպիսով, անհավասարակշռությունը դասարանի բաշխման խնդիր ունի, քանի որ սովորելու ալգորիթմները ցածր կանխատեսողական ճշմարտություն ունեն հազվադեպ դասարանի համար: Ավելին, սոցիալական լրատվամիջոցները ներկայացնում են ստեղծագործական լեզվի արտահայտությունների բնական լեզվաբանական տարբերությունը: Այս թղթի մեջ մենք օգտագործել ենք տվյալների հավասարակշռության և նյարդային լեզուների ներկայացման մեթոդների համակցությունը մարտահրավերների լուծման համար: Մասնավորապես, մենք մասնակցեցինք 1, 2 (բոլոր լեզուները), 4 և 3 (միայն տարածության հայտնաբերումը, նորմալիզացիա չէր փորձել) առողջապահության ծրագրերի սոցիալական լրատվամիջոցներում (SMM4H) 2020 (Կլեյնը և այլն., 2020). Արդյունքները ցույց են տալիս, որ առաջարկված մեթոդոլոգիայի արդյունքները ավելի լավ են, քան ընդհանուր խնդիրների ճշգրիտ արդյունքները: Հաշվի առնելու գնահատականը նաև ավելի լավ է համեմատած ընդհանուր ներկայացումների միջին գնահատականի հետ: Այնուամենայնիվ, F1-գնահատականը ավելի վատ է, քան միջին գնահատականը, բացառությամբ 2-րդ խնդիրը (ֆրանսերեն):', 'bs': 'Identifikacija i izvlačenje izvješća o lijekovima, njihovim zlostavljanjima ili nevoljnim učinama iz društvenih medija je izazovan zadatak. U društvenim medijima, relevantni izvještaji su veoma rijetki, uzrokuju nesporazno distribuciju klase za algoritme učenja mašina. Naučenje algoritma obično dizajniranih da optimizira ukupnu preciznost bez razmatranja relativne distribucije svake klase. Dakle, nedalansirana raspodjela klase je problematična jer algoritmi učenja imaju nisku predvidnu preciznost za narednu klasu. Osim toga, društveni mediji predstavljaju prirodnu lingvističku variaciju u kreativnim jezičkim izrazima. U ovom papiru, koristili smo kombinaciju tehnika za balanciranje podataka i zastupanje neuralnog jezika kako bi se riješili izazovima. Posebno smo sudjelovali u zajedničkim zadatkima 1, 2 (svih jezika), 4 i 3 (samo otkrivanje razdoblja, nije pokušavalo normalizaciju) u prijavama o rudarstvu socijalnih medija za zdravlje (SMM4H) 2020 (Klein et al., 2020). Rezultati pokazuju da su rezultati predložene metodologije bolje od preciznih rezultata za zajedničke zadatke. Početnik podataka je i bolje u usporedbi s srednjim rezultatom ukupnih podataka. Međutim, rezultat F1 je gore od srednjeg rezultata osim zadatka 2 (francuski).', 'bn': 'মেডিকেল, তাদের নির্যাতন অথবা সামাজিক মিডিয়া থেকে বিরুদ্ধে প্রভাবের সংবাদ পরিচিতি এবং বের করার প্রতিবেদন একট In social media, relevant reports are very infrequent, causes imbalanced class distribution for machine learning algorithms.  প্রত্যেক শ্রেণীর আত্মিক বিতরণ বিবেচনা না করার জন্য সাধারণত আলগরিদম শিখার জন্য সাধারণত গঠন করা হয়েছে। তাই, অসম্পূর্ণ শ্রেণীর বিতরণ সমস্যার কারণ শিক্ষা অ্যালগরিদমের ক্লাসের জন্য কম ভবিষ্যৎবাণী সমাধান রয়েছে। এছাড়াও সামাজিক প্রচার মাধ্যম সৃষ্টিশীল ভাষার ভাষায় প্রতিনিধিত্ব করে। এই কাগজটিতে আমরা ডাটা মাত্রা এবং নিউরেল ভাষার প্রতিনিধিত্ব প্রযুক্তি ব্যবহার করেছি চ্যালেঞ্জের কথা বলার জন্য। বিশেষ করে, আমরা ১, ২ (সকল ভাষা), ৪ এবং ৩ (শুধুমাত্র স্প্যান আবিষ্কার, স্বাস্থ্য প্রয়োগের জন্য সামাজিক মিডিয়া মিনিং এর জন্য স্বাস্থ্য অ্যাপ্লিকেশনের জন্য ২০২০০ (ক্ ফলাফল দেখা যাচ্ছে যে প্রস্তাবিত পদ্ধতিগত প্রত্যাখ্যানের স্কোরের সাথে শেয়ার করা কাজের জন্য সঠিক স্কোর থেকে ভ স্কোরের স্কোরের সাথে সম্পূর্ণ আত্মসমর্পণের মানাধিক স্কোরের তুলনায় ভাল। তবে ফ্রেঞ্চ (ফরাসী) কাজ ছাড়া F1-স্কোর মানে স্কোরের চেয়ে খারাপ।', 'af': "Die identifiseer en uitpakking van raporte van medikasie, hulle misbruk of noodsaaklike effekte van sosiale media is 'n pragtige taak. In sosiale media is relevante raporte baie onvolgende, veroorsaak onbalanse klas verspreiding vir masjien leer algoritme. Leer algoritme tipies ontwerp om die hele presisie te optimaliseer sonder om die relatiewe verspreiding van elke klas te onderwerp. Daarom, onbalanse klas verspreiding is problematiek as leer algoritme het lae voorskoude presisie vir die infrekwens klas. Maar sosiale media verteenwoordig natuurlike lingwisiese veranderinge in kreatiewe taal uitdrukkings. In hierdie papier het ons 'n kombinasie van data balansering en neurale taal voorstelling tekens gebruik om die uitdagings te adres. Spesifieke, ons het die gedeelde taak 1, 2 (alle tale), 4 en 3 (slegs die span-opdekking, geen normalisering is probeer) in sosiale media-minning vir gesondige toepassings (SMM4H) 2020 (Klein et al., 2020) gedeel. Die resultate wys dat met die voorgestelde metodologie herhaal telling beter is as die presisie telling vir die gedeelde taak. Die rekenaar telling is ook beter vergelyk met die gemiddelde telling van die totaal onderstellings. Maar, die F1- telling is verder as die gemiddelde telling, behalwe vir taak 2 (Frans).", 'ca': "Identificar i extrair informes de medicaments, dels seus abusos o efectes adversas dels mitjans socials és una tasca desafiadora. Als mitjans socials, els informes pertinents són molt poc freqüents, causen una distribució desequilibrada de classes per algoritmes d'aprenentatge automàtic. Algoritmes d'aprenentatge típicament dissenyats per optimitzar la precisió global sense tenir en compte la distribució relativa de cada classe. Així doncs, la distribució desequilibrada de classes és problemàtica, perquè els algoritmes d'aprenentatge tenen baixa precisió preditiva per a la classe infrequent. A més, els mitjans socials representan variacions lingüístices naturals en expressions de llenguatge creatiu. En aquest paper hem utilitzat una combinació de tècniques d'equilibri de dades i de representació neuronal de llenguatges per abordar els reptes. En concret, vam participar en les tasques compartides 1, 2 (totes les llengües), 4 i 3 (només la detecció d'espai, no es va intentar normalitzar) en Social Media Mining for Health Applications (SMM4H) 2020 (Klein et al., 2020). The results show that with the proposed methodology recall scores are better than the precision scores for the shared tasks.  La puntuació de recuperació també és millor comparada amb la mitjana de les presentacions. Però la puntuació F1 és pitjor que la mitjana excepte la tasca 2 (francès).", 'cs': 'Identifikovat a extrahovat hlášení o lécích, jejich zneužívání nebo nežádoucích účincích ze sociálních médií je náročný úkol. V sociálních médiích jsou relevantní zprávy velmi zřídka, což způsobuje nerovnováženou distribuci tříd pro algoritmy strojového učení. Výukové algoritmy typicky navržené tak, aby optimalizovaly celkovou přesnost bez ohledu na relativní rozložení každé třídy. Proto je nerovnovážené rozdělení tříd problematické, protože učební algoritmy mají nízkou prediktivní přesnost pro vzácnou třídu. Sociální média navíc představují přirozenou jazykovou variaci tvůrčích jazykových projevů. V tomto článku jsme použili kombinaci technik vyrovnávání dat a reprezentace neuronálního jazyka k řešení problémů. Konkrétně jsme se zúčastnili sdílených úkolů 1, 2 (všechny jazyky), 4 a 3 (pouze detekce rozpětí, žádná normalizace nebyla pokusena) v Social Media Mining for Health aplikací (SMM4H) 2020 (Klein et al., 2020). Výsledky ukazují, že při navrhované metodice jsou výsledky vyvolání lepší než přesné výsledky pro sdílené úkoly. Skóre odvolání je také lepší ve srovnání s průměrným skórem celkových příspěvků. Skóre F1 je však horší než průměrné skóre kromě úkolu 2 (francouzsky).', 'et': 'Ravimite, nende kuritarvitamise või kahjulike mõjude teadete tuvastamine ja väljavõtmine sotsiaalmeedias on keeruline ülesanne. Sotsiaalmeedias on asjakohased aruanded väga harva, põhjustades masinõppe algoritmide tasakaalustamatut klassijaotust. Õppealgoritmid on tavaliselt kavandatud üldise täpsuse optimeerimiseks, arvestamata iga klassi suhtelist jaotust. Seega on tasakaalustamatu klassijaotus problemaatiline, sest õppealgoritmide prognoositavus on harvaesineva klassi puhul madal. Lisaks esindab sotsiaalmeedia loominguliste keeleliste väljendite loomulikku keelelist variatsiooni. Käesolevas töös oleme probleemide lahendamiseks kasutanud andmete tasakaalustamise ja närvikeele esindamise tehnikate kombinatsiooni. Täpsemalt osalesime ühistes ülesannetes 1, 2 (kõik keeled), 4 ja 3 (ainult ulatuse tuvastamine, normaliseerimist ei püütud) sotsiaalmeedia kaevandamise rakendustes (SMM4H) 2020 (Klein et al., 2020). Tulemused näitavad, et kavandatud metoodika puhul on tagasikutsumise skoorid paremad kui jagatud ülesannete täpsuskoorid. Samuti on tagasikutsumise skoor parem võrreldes kogu esitatud tulemuste keskmise skooriga. Siiski on F1-skoor halvem kui keskmine skoor, välja arvatud ülesanne 2 (prantsuse).', 'fi': 'Lääkkeitä, niiden väärinkäyttöä tai haittavaikutuksia koskevien raporttien tunnistaminen ja poimiminen sosiaalisesta mediasta on haastava tehtävä. Sosiaalisessa mediassa relevantit raportit ovat hyvin harvinaisia, mikä aiheuttaa epätasapainoista luokkajakaumaa koneoppimisalgoritmeille. Oppimisalgoritmit on tyypillisesti suunniteltu optimoimaan kokonaistarkkuus ottamatta huomioon kunkin luokan suhteellista jakautumista. Näin ollen epätasapainoinen luokkajakauma on ongelmallista, koska oppimisalgoritmit ovat heikosti ennustettavissa harvoin. Lisäksi sosiaalinen media edustaa luontaista kielellistä vaihtelua luovissa kieliilmaisuissa. Tässä artikkelissa olemme käyttäneet datan tasapainotuksen ja neurokielen esittämisen tekniikoiden yhdistelmää haasteiden ratkaisemiseksi. Osallistuimme erityisesti yhteisiin tehtäviin 1, 2 (kaikilla kielillä), 4 ja 3 (vain span detection, normalisointia ei yritetty) Social Media Mining for Health -sovelluksissa (SMM4H) 2020 (Klein et al., 2020). Tulokset osoittavat, että ehdotetulla menetelmällä takaisinkutsupisteet ovat parempia kuin jaettujen tehtävien tarkkuuspisteet. Palautusprosentti on myös parempi verrattuna kaikkien lähetettyjen aineistojen keskiarvoon. F1-pisteet ovat kuitenkin huonompia kuin keskiarvo lukuun ottamatta tehtävää 2 (ranska).', 'jv': 'ra Nang media sothik, raporte sing dikarol akeh tenan nguti, dadi kaé sekolahan kelas denganjut kanggo sekolahan karo Algorithm kuwi apakno. Algorithm Laptop" and "Desktop Labut, media sothik gambar perusahaan anyar luwih basa ning arep kreatif. Nang pewiir iki, kéné wis nggambar kelangan data balanci lan alam kuwi nggambar tarjamahan kanggo urujak obangakke tarjamahan. Me Rejalaké wong mengko karo sistem sing dipunatus bener Perintah sing gak bener Nanging, F1-punti dadi luwih apik kanggo ditambang sandi 2 (Perancis).', 'sk': 'Prepoznavanje in pridobivanje poročil o zdravilih, njihovi zlorabi ali škodljivih učinkih iz družbenih omrežij je zahtevna naloga. V družbenih omrežjih so pomembna poročila zelo redka, kar povzroča neravnoteženo porazdelitev razredov algoritmov strojnega učenja. Učni algoritmi so običajno zasnovani za optimizacijo splošne natančnosti brez upoštevanja relativne porazdelitve posameznega razreda. Tako je neravnotežena porazdelitev razredov problematična, saj imajo učni algoritmi nizko predvidljivo natančnost za redke razrede. Poleg tega družbeni mediji predstavljajo naravno jezikovno variacijo ustvarjalnih jezikovnih izrazov. V tem prispevku smo uporabili kombinacijo tehnik uravnoteženja podatkov in nevronske jezikovne reprezentacije za reševanje izzivov. Natančneje smo sodelovali pri skupnih nalogah 1, 2 (vsi jeziki), 4 in 3 (samo zaznavanje obsega, ni bilo poskusa normalizacije) v programu Social Media Mining for Health (SMM4H) 2020 (Klein et al., 2020). Rezultati kažejo, da so s predlagano metodologijo rezultati odpoklica boljši od natančnih rezultatov za skupna opravila. Rezultat odpoklica je tudi boljši v primerjavi s povprečnim rezultatom vseh prispevkov. Vendar je rezultat F1 slabši od povprečnega rezultata, razen za nalogo 2 (francoščina).', 'he': 'זיהוי ומוציא דיווחים על תרופות, התעללות שלהם או השפעות שליליות ממדיה חברתית היא משימה מאתגרת. בתקשורת החברתית, דיווחים רלוונטיים נדירים מאוד, גורמים לפיתוח לא מאוזן בכיתה לאלגוריתמים ללמד מכונות. אלגוריתמים ללמוד בעיצובים באופטימלי כדי לאופטימליזם את הדיוק הכללי בלי לשקול את ההפצה היחסית של כל כיתה. לכן, פיצוי מעמד לא מאוזן הוא בעייתי כיוון שלאלגוריתמים ללמוד יש מדויקת צפויה נמוכה לכיתה לא נדירה. Moreover, social media represents natural linguistic variation in creative language expressions.  בעיתון הזה השתמשנו בשילוב של שיווי מידע וטכניקות מייצג שפת עצבית כדי להתמודד עם האתגרים. במיוחד, השתתפנו במשימות המשותפות 1, 2 (כל שפות), 4, 3 (רק גילוי המרחב, אין ניסיון נורמליזציה) במכרות מדיה חברתית לתוכניות בריאות (SMM4H) 2020 (Klein et al., 2020). התוצאות מראות שבתוצאה מהמטודולוגיה המוצעת נקודות החזרה טובות יותר מהנקודות הדיקות למשימות המשותפות. The recall score is also better compared to the mean score of the total submissions.  עם זאת, ציון F1 גרוע יותר מהציון הממוצע חוץ מהמשימה 2 (צרפתית).', 'ha': "Ina gane da kuma a fitar da kure na madaidaici, abuse ko haske daga mitandai na jamii, aikin na tsõratar. A cikin mitandai da jamii, suna da jarrabo masu husũma masu bastarwa, kuma yana saba da rabon darafõfi da ba'a daidaita ba dõmin karatun algoritori na mashine. Ana karanta algoritori na ɗabi'a wa'anar da aka ƙayyade wa a ƙayyade tsarin duk gaba bila a kula da rabon rabon nau'in kõwane fasa. Daga haka, rabin fasalar da ba ta balanci ba yana da matsayi, kamar yadda algorituman sun ƙunci tsari mai sauƙi wa fasalar da ke rubutu. Furan haka, mitandai na jami yana mai gauraya cikin linguistic na natsuwa a cikin magana masu halitta. In this paper, we have used a combination of data balancing and neural language representation techniques to address the challenges.  A ƙayyade, mun yi raba da aikin da aka raba shi 1, 2 (dukkan harshen), 4, da 3 (kun gane na span, ba da jarraba normal zartar da shi ba) a cikin shirin Media Mining wa Shiryoyin Ayuka na Afya (SMM4H) 2020 (KIein et al, 2020). Mataimakin ya nuna cewa, idan an gabatar da shiryoyin ayuka da aka buƙata, su fi zama mafiya alhẽri daga score na daidai wa aikin da aka raba shi. Kuma musulunci na musulunci shi ne mafi alhẽri a gare shi. Babu haka, score F1 ce mafi sharri daga naun mai girma fãce ma'anar aikin 2 (French).", 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དུ་བློ་གཏོང་ཚོ་ནི་བརྒྱུད་རྐྱེན་མེད། སྤྱིར་བཏང་གི་སྒྲིག་སྟངས་རྣམས་གྲངས་སྒྲིག་ཆ་རྣམས་ལས་ཆེ་རྐྱེན་ཚད་ལྡན་རེ་རེ་བ་ལ་ཆེ་རུ་གཏོང་བ དེར་བརྟེན། imbalanced class་བགོ་འགྲེལ་བ་དེ་ནི་སློབ་གྲྭར་གྱི་སྔོན་སྒྲིག་གྲངས་རིགས་ཀྱི་གསལ་བཤད་ཚད་ཉུང་བའི་རིང་ལ། ད་དུང་། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནི་གསར་བསྐྲུན་པའི་སྐད་རིགས་ལ་སྐད་རྒྱུན་ལྡན་མཚོན་གྱི་ཡོད། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་བློ་གཏོང་གི་གནས་ཚུལ་ཕྱོགས་དང་མཐུན་རིམ་སྒྲིག་གི་ཐབས་ལམ་ཞིག་བེད་སྤྱོད་ཡོད། དམིགས་འཛུགས་ཀྱིས། ང་ཚོས་སྤྱི་ཚོགས་ཀྱི་བྱ་འགུལ་༡、༢(སྐད་རིགས་ཆ་ཡོངས་) ༤། ༣(span ར་ཞིག་རྟོགས་ན་དང་། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྤྲོད་ཀྱི་ཉེར་སྤྱོད་མ གྲུབ་འབྲས་བ་དེ་ཚོ་ནི་འཆར་བཀོད་ཡོད་པའི་ཐབས་ལམ་ལུགས་ཀྱི་ཨང་གྲངས་ཀ་དེ་ཚོ་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་ཚུ་ལས་མཐོ་རྐྱེན དྲན་སྐུལ་གྲངས་ཀ་དེ་ཚོ་ཡང་བསྡུས་ཡོད་པའི་ཚད་ལྡན་གྲངས་ཀ་དང་མཐུན་འགྱུར་བ་རེད། ཡིན་ནའང་། F1-score་འདི་ལས་ཀ་གཉིས་ཀྱིས་འགྲོ་སྣང་མེད་པའི་ཚད་ལྟར་ཉེན་ཡིན།'}
{'en': 'Sentence Contextual Encoder with BERT and BiLSTM for Automatic Classification with Imbalanced Medication Tweets BERT  and  B i LSTM  for Automatic Classification with Imbalanced Medication Tweets', 'ar': 'التشفير السياقي للجملة مع BERT و BiLSTM للتصنيف التلقائي مع تغريدات الأدوية غير المتوازنة', 'es': 'Codificador contextual de oraciones con BERT y BILSTM para la clasificación automática con tweets de medicamentos desequilibrados', 'pt': 'Codificador contextual de sentença com BERT e BiLSTM para classificação automática com tweets de medicamentos desequilibrados', 'fr': 'Encodeur contextuel de phrase avec BERT et BilsTM pour la classification automatique avec des tweets de médicaments déséquilibrés', 'ja': 'BERTとBiLSTMを備えた文脈エンコーダは、アンバランスな投薬ツイートによる自動分類を可能にします', 'zh': '有BERTBiLSTM之句上下文编码器,施于不平药物推文自分', 'hi': 'असंतुलित दवा Tweets के साथ स्वचालित वर्गीकरण के लिए BERT और BiLSTM के साथ वाक्य प्रासंगिक एन्कोडर', 'ru': 'Контекстный кодировщик предложений с BERT и BiLSTM для автоматической классификации с дисбалансными сообщениями о лекарствах', 'ga': 'Ionchódóir Comhthéacsúil Pianbhreithe le BERT agus BiLSTM le haghaidh Aicmiú Uathoibríoch le Cógas Míchothromaithe', 'el': 'Κωδικοποιητής περιεχομένων φράσεων με BERT και BiLSTM για αυτόματη ταξινόμηση με ανισόρροπα φαρμακευτικά tweets', 'ka': 'Comment', 'hu': 'Ítélet kontextuális kódoló BERT és BiLSTM funkcióval az automatikus osztályozáshoz kiegyensúlyozatlan gyógyszeres tweetekkel', 'mk': 'Контекстен кодер на речениците со BERT и BiLSTM за автоматска класификација со небалансирани медицински твитови', 'it': 'Encoder contestuale di frase con BERT e BiLSTM per la classificazione automatica con tweet di farmaci sbilanciati', 'kk': 'BERT және BiLSTM автоматты түрлендіру үшін сөз контексті кодері', 'lt': 'Nuorodų kontekstinis kodas su BERT ir BiLSTM automatiniam klasifikavimui su disbalansuotais vaistiniais Tweetais', 'ml': 'ബെര്\u200dട്ടിയും ബില്\u200dസ്റ്റിഎമും ഉപയോഗിച്ചുള്ള വിധിക്കുറിപ്പുകള്\u200d', 'mn': 'БЕРТ болон BiLSTM-тэй өгүүлбэрийн контекст коддогч Автоматтын Классификацийн Твиттэй', 'ms': 'Pengekod Konteksual Pengungkapan dengan BERT dan BiLSTM untuk Klasifikasi Automatik dengan Tweet Perubahan yang tidak seimbang', 'ro': 'Encoder contextual pentru sentință cu BERT și BiLSTM pentru clasificarea automată cu Tweetele de medicație dezechilibrate', 'no': 'Comment', 'pl': 'Koder kontekstowy zdań z BERT i BiLSTM do automatycznej klasyfikacji z niezbalansowanymi tweetami leków', 'si': 'BERT සහ BiLSTM සඳහා වාර්තාව සම්බන්ධ සංකේතකය සඳහා ස්වයංක්\u200dරියාත්මක ක්\u200dරියාකරණය සඳහා', 'sr': 'Kontekstualni koder kazne sa BERT i BiLSTM za automatsku klasifikaciju sa nepravednom medikacijskim tweetom', 'mt': 'Kodifikatur Kuntest tas-Sentenza bil-BERT u BiLSTM għall-Klassifikazzjoni Awtomatika bi Tweets tal-Medikazzjoni Żbilanċjata', 'so': 'Qoraalka hoose ee degmada la xiriira BERT iyo BiLSTM ee Automatic Classification with Imbalanced Medicinal Tweets', 'sv': 'Kontextuell meningskoder med BERT och BiLSTM för automatisk klassificering med obalanserade medicintweets', 'ur': 'Name', 'ta': 'BERT மற்றும் பில்ஸ்டிஎம் உடன் வாக்கியம் குறியீட்டாளர் தானியங்கி வகைப்படுத்தலுடன் ஒழுங்கபட்ட மருத்துவ ம் Tweets', 'uz': 'Name', 'vi': 'Câu chuyện Contessa chung kết nối với BERT và BiLSTM for Automatic classification with Imbalat Medication Tweet', 'bg': 'Контекстуален кодер за изречение с автоматична класификация с дисбалансирани медикаменти', 'hr': 'Kontekstualni koder kazne sa BERT i BiLSTM za automatsku klasifikaciju s nepravednom medikacijskim tweetom', 'nl': 'Zinnecontextuele encoder met BERT en BiLSTM voor automatische classificatie met onevenwichtige medicatie tweets', 'da': 'Kontekstuel koder med BERT og BiLSTM til automatisk klassificering med ubalancerede medicintweets', 'de': 'Satzkontextkodierer mit BERT und BiLSTM zur automatischen Klassifizierung mit unausgewogenen Medikamenten-Tweets', 'id': 'Pengekoder Konteksual Sentence dengan BERT dan BiLSTM untuk Klasifikasi Otomatis dengan Tweet Medikasi yang tidak seimbang', 'fa': 'Comment', 'ko': 'BERT와 BilSTM이 있는 문장 상하문 인코더, 불균형 약물 추문 자동 분류에 사용', 'tr': 'BERT we BiLSTM bilen sözlem Kontekst Ködleme', 'sw': 'Kodi la Makala na BERT na BiLSTM kwa ajili ya Kutangaza Huduma na Twiti za Madawa zisizo na usawa', 'af': 'Sentence Konteksual Enkoder met BERT en BiLSTM vir Outomatiese Klassifikasie met Imbalanseerde Medikasie Tweets', 'sq': 'Kodifikuesi Konteksual i Dënimeve me BERT dhe BiLSTM për Klasifikimin Automatik me Tweets të Pabalancuar Mjekimi', 'hy': 'Comment', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'BERT v톛 BiLSTM il톛 S칬z칲 Kontekst Kodlay캼c캼s캼 N톛balan칞캼 Z톛km톛 Tweetl톛ri il톛 Avtomatik Klasifikasyon 칲칞칲n', 'bn': 'বের্ট এবং বিএলস্টিমের স্বয়ংক্রিয়ভাবে স্বাভাবিক ক্লাসিকেশনের জন্য শাস্তি বিষয়বস্তু এনকোডার', 'bs': 'Kontekstualni koder kazne sa BERT i BiLSTM za automatsku klasifikaciju sa nepravednom medikacijskim tweetom', 'cs': 'Kontextový kódér vět s BERT a BiLSTM pro automatickou klasifikaci s nevyváženými medikačními tweety', 'ca': 'Sentence Contextual Encoder with BERT and BiLSTM for Automatic Classification with Imbalanced Medication Tweets', 'et': 'Lause kontekstiktuaalne kodeerija BERT ja BiLSTM automaatseks klassifitseerimiseks tasakaalustamatute ravimite tweetidega', 'fi': 'Lausekkeen kontekstuaalinen kooderi BERT- ja BiLSTM-järjestelmällä automaattiseen luokitteluun epätasapainoisilla lääkkeillä', 'jv': 'Text contextual', 'sk': 'Kontekstualni kodir stavkov z BERT in BiLSTM za samodejno klasifikacijo z neravnoteženimi zdravilnimi tweeti', 'bo': 'Sentence Contextual Encoder with BERT and BiLSTM for Automatic Classification with Imbalanced Medication Tweets', 'ha': 'KCharselect unicode block name', 'he': 'קודד קונטקסטי של משפטים עם BERT ובילסטם לסידור אוטומטי עם טוויטים רפואים לא מאוזנים'}
{'en': 'This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1. Task 1 targets the automatic classification of tweets that mention medication. We adapted the standard BERT pretrain-then-fine-tune approach to include an intermediate training stage with a biLSTM architecture neural network acting as a further fine-tuning stage. We were inspired by the effectiveness of within-task further pre-training and sentence encoders. We show that this approach works well for a highly imbalanced dataset. In this case, the positive class is only 0.2 % of the entire dataset. Our model performed better in both F1 and precision scores compared to the mean score for all participants in the competition and had a competitive recall score.', 'ar': 'توضح هذه الورقة وصف النظام والنهج المستخدم من قبل فريقنا لمسابقة SMM4H 2020 ، المهمة الأولى. تستهدف المهمة الأولى التصنيف التلقائي للتغريدات التي تشير إلى الأدوية. لقد قمنا بتكييف نهج BERT المعياري قبل الاختبار ثم الصقل ليشمل مرحلة تدريب وسيطة مع شبكة عصبية معمارية biLSTM تعمل كمرحلة صقل أخرى. لقد استوحينا الإلهام من فاعلية التدريب المسبق الإضافي وتشفير الجملة داخل المهمة. نظهر أن هذا النهج يعمل بشكل جيد لمجموعة بيانات غير متوازنة للغاية. في هذه الحالة ، تكون الفئة الموجبة 0.2٪ فقط من مجموعة البيانات بأكملها. كان أداء نموذجنا أفضل في كلٍ من F1 ودرجات الدقة مقارنةً بمتوسط النقاط لجميع المشاركين في المسابقة وحصل على درجة استدعاء تنافسية.', 'fr': "Cet article détaille la description du système et l'approche utilisées par notre équipe pour le concours SMM4H 2020, Tâche 1. La tâche 1 vise la classification automatique des tweets qui mentionnent des médicaments. Nous avons adapté l'approche standard de pré-entraînement puis de réglage fin du BERT pour inclure une étape d'entraînement intermédiaire avec un réseau neuronal d'architecture BilsTM agissant comme étape de réglage fin supplémentaire. Nous avons été inspirés par l'efficacité de la pré-formation continue et des encodeurs de phrases au sein des tâches. Nous montrons que cette approche fonctionne bien pour un ensemble de données très déséquilibré. Dans ce cas, la classe positive ne représente que 0,2\xa0% de l'ensemble de données complet. Notre modèle a obtenu de meilleurs résultats en F1 et en précision par rapport au score moyen de tous les participants à la compétition et avait un score de rappel compétitif.", 'es': 'Este documento detalla la descripción del sistema y el enfoque utilizado por nuestro equipo para la competencia SMM4H 2020, Tarea 1. La tarea 1 se centra en la clasificación automática de los tuits que mencionan medicamentos. Adaptamos el enfoque estándar de preentrenamiento y luego ajuste fino de BERT para incluir una etapa de entrenamiento intermedio con una red neuronal de arquitectura BilsTM que actúa como una etapa de ajuste adicional. Nos inspiró la eficacia del preentrenamiento y los codificadores de oraciones adicionales dentro de la tarea. Demostramos que este enfoque funciona bien para un conjunto de datos altamente desequilibrado. En este caso, la clase positiva es solo el 0,2% de todo el conjunto de datos. Nuestro modelo tuvo un mejor rendimiento tanto en F1 como en puntuaciones de precisión en comparación con la puntuación media de todos los participantes en la competencia y tuvo una puntuación de retirada competitiva.', 'pt': 'Este artigo detalha a descrição do sistema e a abordagem usada por nossa equipe para a competição SMM4H 2020, Tarefa 1. A Tarefa 1 visa a classificação automática de tweets que mencionam medicamentos. Adaptamos a abordagem padrão de pré-treinamento e ajuste fino do BERT para incluir um estágio de treinamento intermediário com uma rede neural de arquitetura biLSTM atuando como um estágio de ajuste fino adicional. Fomos inspirados pela eficácia do pré-treinamento adicional e dos codificadores de frases dentro da tarefa. Mostramos que essa abordagem funciona bem para um conjunto de dados altamente desequilibrado. Nesse caso, a classe positiva é apenas 0,2% de todo o conjunto de dados. Nosso modelo teve melhor desempenho tanto na pontuação F1 quanto na precisão em comparação com a pontuação média de todos os participantes da competição e teve uma pontuação competitiva de recordação.', 'ja': '本稿では、SMM 4 H 2020コンペティション、タスク1のために当社チームが使用したシステムの説明とアプローチについて詳述します。タスク1は、投薬について言及したツイートの自動分類を対象としています。我々は、標準的なBERT事前訓練-その後の微調整アプローチを適応させ、さらに微調整段階として機能するbiLSTMアーキテクチャニューラルネットワークを備えた中間訓練段階を含めた。タスク内の事前トレーニングと文章エンコーダーの効果に触発されました。このアプローチは、非常にアンバランスなデータセットに適していることを示しています。この場合、正のクラスはデータセット全体の0.2%にすぎません。私たちのモデルは、競技会のすべての参加者の平均スコアと比較して、F 1と精度スコアの両方で優れたパフォーマンスを発揮し、競争力のあるリコールスコアを持っていました。', 'zh': '本文具言团队在SMM4H 2020竞务1所用系统描述法。 任 1 者,言药之推文自分也。 臣等用格 BERT 预练然后微调,包一中训练,其 biLSTM 架构神经网络充其微调。 更预训句编码器有效性。 吾明用之于高不平之数也。 本例之中,正类仅全数集之 0.2%。 凡参与者之均得分,形于F1精得分,而有竞争性召分数。', 'hi': 'यह पेपर SMM4H 2020 प्रतियोगिता, टास्क 1 के लिए हमारी टीम द्वारा उपयोग किए जाने वाले सिस्टम विवरण और दृष्टिकोण का विवरण देता है। कार्य 1 उन ट्वीट्स के स्वचालित वर्गीकरण को लक्षित करता है जो दवा का उल्लेख करते हैं। हमने मानक BERT pretrain-then-fine-tune approach को अनुकूलित किया ताकि biLSTM आर्किटेक्चर न्यूरल नेटवर्क के साथ एक मध्यवर्ती प्रशिक्षण चरण को शामिल किया जा सके जो एक और ठीक-ट्यूनिंग चरण के रूप में कार्य करता है। हम भीतर-कार्य की प्रभावशीलता से प्रेरित थे आगे पूर्व-प्रशिक्षण और वाक्य एनकोडर। हम दिखाते हैं कि यह दृष्टिकोण अत्यधिक असंतुलित डेटासेट के लिए अच्छी तरह से काम करता है। इस मामले में, सकारात्मक वर्ग पूरे डेटासेट का केवल 0.2% है। हमारे मॉडल ने प्रतियोगिता में सभी प्रतिभागियों के लिए औसत स्कोर की तुलना में एफ 1 और परिशुद्धता स्कोर दोनों में बेहतर प्रदर्शन किया और एक प्रतिस्पर्धी रिकॉल स्कोर था।', 'ru': 'В данном документе подробно описано описание системы и подход, используемый нашей командой для конкурса SMM4H 2020, Задача 1. Задача 1 нацелена на автоматическую классификацию твитов, в которых упоминаются лекарства. Мы адаптировали стандартный подход BERT pretrain-then-fine-tune, включив промежуточный этап обучения с нейронной сетью архитектуры biLSTM, выступающей в качестве дальнейшего этапа тонкой настройки. Мы были вдохновлены эффективностью внутризадачного дальнейшего предварительного обучения и кодировщиков предложений. Мы показываем, что этот подход хорошо работает для сильно несбалансированного набора данных. В этом случае положительный класс составляет лишь 0,2% от всего набора данных. Наша модель показала лучшие результаты как в F1, так и в прецизионности по сравнению со средним баллом для всех участников соревнований и имела конкурентный балл отзыва.', 'ga': "Sonraíonn an páipéar seo an cur síos ar an gcóras agus an cur chuige a d’úsáid ár bhfoireann do chomórtas SMM4H 2020, Tasc 1. Díríonn Tasc 1 ar aicmiú uathoibríoch tweets a luann cógais. D'oiriúnaíomar an cur chuige caighdeánach réamhthraenála-ansin-míntiús BERT chun céim oiliúna idirmheánach a chuimsiú le líonra néarach ailtireachta biLSTM ag feidhmiú mar chéim mhionchoigeartaithe eile. Bhí muid spreagtha ag éifeachtacht na réamh-oiliúna breise laistigh den tasc agus ionchódóirí pianbhreithe. Léirímid go n-oibríonn an cur chuige seo go maith le haghaidh tacar sonraí atá thar a bheith míchothrom. Sa chás seo, níl sa rang dearfach ach 0.2% den tacar sonraí iomlán. D’fheidhmigh ár samhail níos fearr i scóir F1 agus beachtas araon i gcomparáid leis an meánscór do rannpháirtithe uile an chomórtais agus bhí scór iomaíoch aisghairme aige.", 'el': 'Αυτή η εργασία περιγράφει λεπτομερώς το σύστημα και την προσέγγιση που χρησιμοποιήθηκε από την ομάδα μας για τον διαγωνισμό εργασίας 1. Η εργασία 1 στοχεύει στην αυτόματη ταξινόμηση των tweets που αναφέρουν φάρμακα. Προσαρμόσταμε την πρότυπη προσέγγιση προ-ρύθμισης και μετά-ρύθμισης για να συμπεριλάβουμε ένα ενδιάμεσο στάδιο εκπαίδευσης με ένα νευρωνικό δίκτυο αρχιτεκτονικής που λειτουργεί ως περαιτέρω στάδιο συντονισμού. Εμπνευστήκαμε από την αποτελεσματικότητα της περαιτέρω προεκπαίδευσης εντός εργασιών και των κωδικοποιητών προτάσεων. Δείχνουμε ότι αυτή η προσέγγιση λειτουργεί καλά για ένα εξαιρετικά ανισορροπημένο σύνολο δεδομένων. Σε αυτή την περίπτωση, η θετική κατηγορία είναι μόνο 0,2% ολόκληρου του συνόλου δεδομένων. Το μοντέλο μας πέτυχε καλύτερα τόσο σε βαθμολογίες F1 όσο και σε βαθμολογίες ακριβείας σε σύγκριση με το μέσο σκορ για όλους τους συμμετέχοντες στον διαγωνισμό και είχε ανταγωνιστικό σκορ ανάκλησης.', 'hu': 'Ez a tanulmány részletezi a rendszer leírását és megközelítését, amelyet csapatunk alkalmazott az SMM4H 2020 versenyen, 1. feladatban. Az 1. feladat célja a gyógyszereket említő tweetek automatikus osztályozása. A szabványos BERT előzetes-aztán-finomhangolási megközelítést úgy alakítottuk ki, hogy egy közbenső edzési szakaszt is tartalmazzon, amely további finomhangolási szakaszként működik a biLSTM architektúrájú neurális hálózat. A feladaton belüli továbbképzés és mondatkódoló hatékonysága inspirált minket. Megmutatjuk, hogy ez a megközelítés jól működik egy rendkívül kiegyensúlyozatlan adatkészlet esetén. Ebben az esetben a pozitív osztály a teljes adathalmaz 0,2%-a. Modellünk mind F1, mind precíziós pontszámokban jobban teljesített, mint a verseny összes résztvevőjének átlagos pontszáma, és versenyképes visszahívási pontszámot kapott.', 'ka': 'ამ წიგნის განსაზღვრება სისტემის გამოსახულება და მიღება, რომელიც ჩვენი ჯგუფის გამოყენებული SMM4H 2020 კონკრენტებისთვის, დავალება 1. 1. დავალება მიზეზიან თავისუფალური კლასიფიკაციას, რომელიც მედიციაციას ამბობს. ჩვენ სტანდარტური BERT-ის პრერეინ-შემდეგ-სტანტის მიღება, რომელიც უფრო სტანტიური სტანტიკური სტანტიკური ქსელი, რომელიც უფრო სტანტიური სტანტიკური სტანტიკური შემდე ჩვენ დავიწყენეთ ეფექტიურობით სამუშაო სამუშაო სამუშაო მუშაო სამუშაო და სიტყვების კოდერებით. ჩვენ ჩვენ აჩვენებთ, რომ ეს პროგრამა მუშაობა ძალიან განბალიზებული მონაცემების კონფიგურაციისთვის. ამ შემთხვევაში, პოტიფიკაციური კლასი მხოლოდ 0.2% უფრო მონაცემების კონფიკაცია. ჩვენი მოდელი უფრო მეტი გავაკეთეთ F1-ში და წარმოდგენების წარმოდგენებით საშუალო წარმოდგენებისთვის ყველა მოთავსწავლებელი კონკრენტებში და იყო კონკრენტე', 'it': "Questo articolo descrive dettagliatamente la descrizione del sistema e l'approccio utilizzato dal nostro team per il concorso SMM4H 2020, Task 1. Il compito 1 mira alla classificazione automatica dei tweet che menzionano farmaci. Abbiamo adattato l'approccio BERT pretrain-then-fine-tune standard per includere una fase di allenamento intermedia con una rete neurale dell'architettura biLSTM che funge da ulteriore fase di messa a punto. Siamo stati ispirati dall'efficacia dei pre-training e dei codificatori di frasi interni. Dimostriamo che questo approccio funziona bene per un set di dati altamente sbilanciato. In questo caso, la classe positiva è solo lo 0,2% dell'intero set di dati. Il nostro modello ha ottenuto risultati migliori sia in F1 che in precisione rispetto al punteggio medio per tutti i partecipanti alla competizione e ha avuto un punteggio di richiamo competitivo.", 'mk': 'Овој документ го детализира описот на системот и пристапот кој го користи нашиот тим за натпреварот SMM4H 2020, задача 1. Работата 1 е насочена кон автоматска класификација на твитови кои споменуваат лекови. Го адаптиравме стандардниот пристап БЕРТ пре-тренинг-тогаш-фин-тунинг за да вклучиме меѓувремена фаза на тренинг со биLSTM архитектурна нервна мрежа која работи како понатамошна фаза на фино тунинг. Ние бевме инспирирани од ефективноста на понатамошната предобука и кодирање на речениците. Ние покажуваме дека овој пристап функционира добро за многу нерамнотежен податок. Во овој случај, позитивната класа е само 0,2% од целиот податок. Нашиот модел успеа подобро во резултатите на Ф1 и прецизност во споредба со просечниот резултат за сите учесници во натпреварот и имаше резултат за конкурентно повлекување.', 'kk': 'Бұл қағаз SMM4H 2020 бағдарламасының, 1- тапсырма үшін жүйелік сипаттамасын және қасиеттеріміз қолданылатын жағдайды егжей- тегжейлі. 1- тапсырма медицина туралы автоматты түрде тапсырмаларды тапсырмалау. Біз стандартты BERT- тең- кейін- кейін- кейін- кейін- кейін- кейін- кейін- кейін- кейін- кейін- кейінгі бақылау кезегін қолдандық. БиLSTM архитектурасының невралдық желінің бірнеше қарау Біз тапсырмалардың ішіндегі әсер етіліктерінің алдыңғы оқыту және сөйлеме кодерінің әсер етілігін түсіндірдік. Бұл әдістер өте дибалансияланған деректер жиынына жақсы жұмыс істейді. Бұл үшін оң жақсы класы толық деректер жиынының 0, 2% ғана. Біздің үлгіміз F1 және оның дұрыс нәтижелерінде әртүрлі нәтижелерімен салыстырып, әртүрлі қатысушылардың орташа нәтижелерімен жақсы жұмыс істеді.', 'lt': 'Šiame dokumente išsamiai aprašytas sistemos aprašymas ir metodas, kurį mūsų komanda taiko konkurencijai SMM4H 2020, 1 užduotis. 1 užduotis skirta automatiniam vaistų paminėtų tweetų klasifikavimui. Mes pritaikėme standartinį BERT metodą prieš traukimą, po to tiksliai pritaikėme, kad į jį būtų įtrauktas tarpinis mokymo etapas su biLSTM architektūros nerviniu tinklu, veikiančiu kaip tolesnis patobulinimo etapas. Buvome įkvėpti į tolesnio parengimo mokymo ir bausmės kodavimo veiksmingumą. We show that this approach works well for a highly imbalanced dataset.  In this case, the positive class is only 0.2% of the entire dataset.  Mūsų modelis pagerėjo tiek F1, tiek tikslumu, palyginti su vidutiniu visų konkurso dalyvių rezultatu ir turėjo konkurencinį atšaukimo rezultatą.', 'ms': 'Kertas ini menjelaskan keterangan sistem dan pendekatan yang digunakan oleh pasukan kami untuk pertandingan SMM4H 2020, Tugas 1. Tugas 1 sasarkan kelasukan automatik tweet yang menyebutkan ubat. Kami menyesuaikan pendekatan BERT piawai pre-rain-then-fine-tune untuk termasuk tahap latihan sementara dengan rangkaian saraf arkitektur biLSTM bertindak sebagai tahap penyesuaian lebih lanjut. Kami terinspirasi oleh efektivitas dalam tugas lebih lanjut pelatihan dan pengekod kalimat. Kami menunjukkan bahawa pendekatan ini bekerja dengan baik untuk set data yang sangat tidak seimbang. Dalam kes ini, kelas positif hanya 0.2% dari seluruh set data. Model kami berjaya lebih baik dalam kedua-dua skor F1 dan ketepatan dibandingkan dengan skor rata-rata bagi semua peserta dalam pertandingan dan mempunyai skor pemulihan kompetitif.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ ടീമില്\u200d ഉപയോഗിക്കുന്ന സിസ്റ്റം വിശദീകരണം വിശദീകരിക്കുന്നു ടാസ്ക് 1 മെഡിക്കല്\u200d പറഞ്ഞുകൊണ്ടിരിക്കുന്ന ടൂട്ടുകളുടെ സ്വയമായി ക്ലാസ്ഫികേഷന്\u200d ലക്ഷ്യമാണ്. നമ്മള്\u200d സാധാരണ ബെര്\u200dട്ടി പ്രെയിന്\u200d-പിന്നീട് നല്ല പരിശീലന സ്റ്റേജില്\u200d ചേര്\u200dക്കാന്\u200d ഒരു ഇടയിലുള്ള ട്രെയിനിസ്റ്റ് സ്റ്റേജ് ചേര്\u200dക്കാന്\u200d ഒരു  കൂടുതല്\u200d പരിശീലനത്തിനും ശിക്ഷയുടെ കോഡുകളും ഉള്ളിലുള്ള ജോലിയുടെ പ്രവർത്തനവും കൊണ്ട് ഞങ്ങള്\u200dക്ക് ബ നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് ഇതിന്റെ അടുത്തേക്ക് വളരെ നന്നായി പ്രവര്\u200dത്തിക്കുന്നു. ഈ കാരണത്തില്\u200d, മുഴുവന്\u200d ഡാറ്റാസറ്റിന്റെ 0. 2% മാത്രമാണ് പ്രിസ്റ്റീവ് ക്ലാസ്. നമ്മുടെ മോഡല്\u200d എഫ്\u200c1 ലും പ്രിസിഷന്\u200d സ്കോരിലും നല്ലത് പ്രവര്\u200dത്തിച്ചിരുന്നു. മത്സരത്തിലുള്ള എല്ലാ പങ്കാളികള്\u200dക്കും ശരിയായ സ്ക', 'mt': 'Dan id-dokument jiddeskrivi d-deskrizzjoni tas-sistema u l-approċċ użat mit-tim tagħna għall-kompetizzjoni SMM4H 2020, Kompitu 1. Il-kompitu 1 jimmira għall-klassifikazzjoni awtomatika ta’ tweets li jsemmu l-mediċina. Aġġustajna l-approċċ standard BERT ta’ qabel it-taħriġ imbagħad irfinat biex jinkludi stadju intermedju ta’ taħriġ b’netwerk newrali tal-arkitettura biLSTM li jaġixxi bħala stadju ieħor ta’ rfinar. We were inspired by the effectiveness of within-task further pre-training and sentence encoders.  Aħna nuru li dan l-approċċ jaħdem tajjeb għal sett ta’ dejta żbilanċjat ħafna. F’dan il-każ, il-klassi pożittiva hija biss 0.2% tas-sett kollu tad-dejta. Il-mudell tagħna wettaq a ħjar kemm fil-punteġġi F1 kif ukoll fil-punteġġi ta’ preċiżjoni meta mqabbel mal-punteġġ medju għall-parteċipanti kollha fil-kompetizzjoni u kellu punteġġ kompetittiv ta’ ġbir lura.', 'mn': 'Энэ цаас SMM4H 2020 өрсөлдөөнд бидний багийн системийн тодорхойлолт болон арга зам ашигладаг талаар ярьдаг. 1 даалгавар нь эмчилгээ нэрлэж буй tweets-ийн автоматжуулалтыг зориулдаг. Бид стандарт БЕРТ-г дахин сайжруулахын тулд биLSTM архитектурын мэдрэлийн сүлжээнд дундаж суралцах шатан дээр дахин сайжруулахын тулд стандарт BERT-г дахин сайжруулсан. Бид ажлын дотор дасгал хөдөлгөөн болон өгүүлбэрийн коддогчдын үр дүнд урам зориулсан. Бид энэ арга баримт маш сайн ажилладаг гэдгийг харуулж байна. Энэ тохиолдолд эерэг хичээл нь бүх өгөгдлийн сангийн 0.2% юм. Бидний загвар нь F1 болон тодорхой тоонуудын дундаж тоонуудыг харьцуулж, өрсөлдөөнд оролцогчдын дундаж тоонуудыг харьцуулж, өрсөлдөөнтэй санах тоонуудыг илүү сайн хийсэн.', 'pl': 'W artykule przedstawiono opis systemu i podejście stosowane przez nasz zespół do konkursu SMM4H 2020, Zadanie 1. Zadanie 1 dotyczy automatycznej klasyfikacji tweetów, które wspominają o lekach. Dostosowaliśmy standardowe podejście BERT pretrain-then-fine-tune, aby obejmować pośredni etap treningu z architekturą biLSTM sieć neuronową działającą jako kolejny etap dostrajania. Zainspirowaliśmy się skutecznością wewnątrz-task dalszych szkoleń wstępnych i koderów zdań. Pokazujemy, że podejście to działa dobrze w przypadku bardzo niezrównoważonego zbioru danych. W tym przypadku dodatnia klasa to tylko 0,2% całego zbioru danych. Nasz model sprawdził się lepiej zarówno w wynikach F1, jak i precyzyjnych w porównaniu ze średnim wynikiem dla wszystkich uczestników zawodów i miał konkurencyjny wynik odwołania.', 'ro': 'Această lucrare detaliază descrierea sistemului și abordarea utilizată de echipa noastră pentru competiția SMM4H 2020, Sarcina 1. Sarcina 1 vizează clasificarea automată a tweeturilor care menționează medicamentele. Am adaptat abordarea standard BERT pre-train-then-fine-tuning pentru a include o etapă intermediară de antrenament cu o rețea neurală arhitectură biLSTM acționând ca o etapă ulterioară de reglare fină. Am fost inspirați de eficiența pregătirii și a codoarelor de propoziții în cadrul sarcinii. Arătăm că această abordare funcționează bine pentru un set de date extrem de dezechilibrat. În acest caz, clasa pozitivă este de numai 0,2% din întregul set de date. Modelul nostru a performat mai bine atât în F1, cât și în scorurile de precizie comparativ cu scorul mediu pentru toți participanții la competiție și a avut un scor competitiv de rechemare.', 'no': 'Denne papiret detaljerer systembeskrivelsen og tilnærming brukt av gruppa vår for konkurransen SMM4H 2020, oppgåve 1. Oppgåve 1 målar automatisk klassifisering av tweets som mener medikamenter. Vi tilpassa standardinnstillinga BERT-så-fin-tune for å inkludere ein middeløvingsstadium med ein biLSTM-arkitekturkitekturkitekturkitekturkitekturkitekturknetverk som meir finnstillingsstadium. Vi vart inspirert av effektiviteten av inni oppgåve meir føreøving og setkodar. Vi viser at denne tilnærminga fungerer bra for ei veldig imbalansert datasett. I dette tilfellet er positivklassen berre 0,2% av heile datasettet. Modellen vårt utførte bedre i både F1 og nøyaktighetspoeng sammenlignet med gjennomsnittpunktet for alle deltakarane i konkurransen og hadde ein konkurransa rekkelscore.', 'sr': 'Ovaj papir detaljuje opis i pristup sistema koji je koristio naš tim za konkurenciju SMM4H 2020, zadatak 1. Task 1 cilja automatsku klasifikaciju tweets koji spominju lekove. Prilagodili smo standardni pristup BERT-a pretrain-then-fine-tune kako bi uključili prosječnu fazu obuke sa biLSTM arhitekturom neuralnom mrežom koja djeluje kao daljnja faza fino-tuning. inspirisani smo od učinkovitosti daljnjih predobuka i kodera kazne unutar zadatka. Pokazujemo da ovaj pristup dobro funkcioniše za veoma neravnoteženu kompletu podataka. U ovom slučaju, pozitivna klasa je samo 0,2% celog seta podataka. Naš model je bolje izvršio u usporedbi sa srednjim rezultatima svih sudionika u konkurenciji i dobio konkurentni rezultat sjećanja.', 'so': "This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1.  Shaqo 1 wuxuu ku qoran yahay iskuulka dhakhtarka ee tweetka ku saabsan daawooyinka. Waxaannu bedeshay qaababka caadiga ah oo BERT ah oo ah pretrain-then-fine-tune, si a an ugu qorno fasalka dhexe waxbarashada iyo shabakadda dhismaha neurada ee biLSTM ah oo u shaqeynaya sida goob aad u fiican. Waxaannu waxyoonay waxyaabaha shaqada gudahooda ah oo ku qoran waxbarashada hore iyo ciqaabka. Waxan tusnaynaa in qaababkan si wanaagsan u shaqeeyo kooxda macluumaadka ee aan sinnaan lahayn. Markaas fasalka positive ah waa 0.2 % oo ka mid ah dhammaanta macluumaadka. Tusaale'dayada ayaa si wanaagsan u sameeyay F1 iyo scoraha saxda ah oo la barbarto qiimeeya iskaashatada oo dhan, waxayna lahaayeen qiimeeya xasuusta.", 'si': 'මේ පරිස්තමේ පද්ධතිය විස්තර සහ ප්\u200dරවේශනය SMM4H 2020යි ප්\u200dරවේශනය සඳහා භාවිත කණ්ඩායමේ විස්තර විස් ව්\u200dයාපෘති 1 ව්\u200dයාපෘතියේ ස්වයංක්\u200dරීය විශේෂණය සඳහා විශේෂය සඳහා ස්වයංක්\u200dරීය විශේෂ අපි ප්\u200dරමාණය BERT ප්\u200dරීට්\u200dරීන්-ඊට පස්සේ-හොඳින් ටුන් ප්\u200dරවේශනය සම්බන්ධ කරනවා බිල්ස්ටිම් ස්ථාපනය නියුරාල ජාලයෙක් සමඟ අත අපිට ප්\u200dරශ්නයක් තියෙන්නේ වැඩේ ප්\u200dරශ්නයක් තියෙන්නේ තව ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් වලට. අපි පෙන්වන්නේ මේ ප්\u200dරවේශනය හොඳට වැඩ කරන්නේ ගොඩක් නිර්මාණිත දත්ත සෙට් එක්ක. මේ විදියට, සාධාරණ ක්ලාස් 0.2% මුළු දත්ත සෙට් විතරයි. අපේ මොඩල් හොඳයි F1 දෙන්නම් හොඳයි විශේෂතාවක් තියෙන්නේ. සියළුම සාමාන්තාවන්ට සාමාන්තාවක් වෙනුවෙන් සමාන්ති', 'sv': 'Denna uppsats beskriver systembeskrivningen och tillvägagångssättet som vårt team använder för SMM4H 2020 tävlingen, Uppgift 1. Uppgift 1 syftar till automatisk klassificering av tweets som nämner medicinering. Vi har anpassat BERT:s standard pre-then-fine-tune-metod för att inkludera ett mellanliggande träningssteg med ett neuralt biLSTM-arkitektur som fungerar som ytterligare finjusteringsstadium. Vi inspirerades av effektiviteten hos intern-task vidareutbildning och meningskodare. Vi visar att detta tillvägagångssätt fungerar bra för en mycket obalanserad datauppsättning. I detta fall är den positiva klassen bara 0,2% av hela datauppsättningen. Vår modell presterade bättre i både F1 och precisionspoäng jämfört med medelpoängen för alla deltagare i tävlingen och hade en konkurrenskraftig återkallelsepoäng.', 'ta': 'இந்த தாள் எஸ்எம்எம்4H 2020 போட்டிக்கு நம் குழு பயன்படுத்தப்பட்ட அமைப்பு விவரம் மற்றும் முறைமையை விவரமாக்குக பணி 1 மருந்து குறிப்பிடும் தானாகவே வகைப்படுத்தலை தேர்ந்தெடுக்கிறது. நாம் நிலையான பெர்ட் பெர்ட் முன்மழை- பின்னர் நன்றாக-தூண்டு முறைமையாக மாற்றினோம் ஒரு நடுநிலை பயிற்சி நிலையை சேர்க்க ஒரு பில்எஸ்டிஎ மேலும் முன் பயிற்சி மற்றும் வாக்குறியீட்டு குறியீடுகள் உள்ள பணியின் விளைவுகள் மூலம் நாம் தெள We show that this approach works well for a highly imbalanced dataset.  இப்படியில், நேர்மை வகுப்பு முழு தரவுத்தளத்தில் 0. 2% மட்டுமே உள்ளது. எங்கள் மாதிரி F1 மற்றும் துல்லியமான மதிப்பெண்களிலும் சிறந்த செயல்படுத்தப்பட்டது போரிடும் எல்லா பங்குப்பாடுகளுக்கும் சராசர', 'ur': 'This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1. ٹاکس ۱ ڈاکس کے ذریعہ توئیٹوں کی آٹوٹی کلاسیفوں کا موقع دیتا ہے۔ ہم نے استاندارڈ BERT پرٹرین-پھر-ٹھیک-ٹیون طریقہ کو اضافہ کردیا ہے کہ ایک بیلس ٹیم معماری نیورل نیورل نیٹ ورک کے ساتھ ایک دوسرے سیدھی تنظیم سٹیج کے طور پر عمل کرتا ہے۔ اور ہم کو اس کام کے مطابق پہلے کی آموزش اور سفارش کوڈر کی طرف سے الهام دی گئی۔ ہم دکھاتے ہیں کہ یہ طریقہ بہت اچھا کام کرتا ہے ایک بہت نابرانگیز ڈیٹ سٹ کے لئے۔ اس کے مطابق، مثبت کلاس صرف پورے ڈاٹ سٹ کے 0.2%. ہمارا مدل F1 اور دقیق اسکور میں بہتر عمل کرتا تھا جو تمام مشرکوں کے لئے مطابق مطابق سکور کے مقابلہ میں ہے اور ایک مسابقه یاد کرنے کا سکور تھا.', 'uz': "Bu sahifa SM4H 2020 rivojlanishga ishlatilgan guruhimizning tizim taʼrifi va usulini aniqlaydi. Vazifa 1. Task 1 targets the automatic classification of tweets that mention medication.  Biz oddiy BERT'ning andoza prerain-keyin yaxshi usulni o'zgartirib turdik, biLSTM struktur tarmoqni bir yaxshi suhbat holatda bajarish uchun o'rtacha taʼminlovchi darajaga qo'yish. Biz vazifaning vazifaning ichiga kodlash va maxfiy sohasi kodlarining muvaffaqiyatli yordam beradi. Bu usulni ko'rsatishimiz mumkin emas maʼlumot tarkibini juda yaxshi ishlaydi. Bu yerda, yaxshi sinf butun maʼlumot satridagi 0.2% keladi. Bizning modelimiz F1 va aniqlik qiymatlarida yaxshi bajarildi va rivojlanadigan hamma qiymatlarning qismi qiymatiga o'xshash bo'lgan va rivojlanish qiymatiga ega bo'lgan.", 'vi': "Tờ giấy này chi tiết mô tả hệ thống và cách tiếp cận của nhóm chúng ta cho cuộc thi SMM24H 2020, Task 1. Nhiệm vụ 1 nhắm vào việc phân loại các tweet tự động nhắc đến các loại thuốc. Chúng tôi đã thích nghi phương pháp chuẩn trước kết thúc của thiếu sót sót sót sót sót qua một giai đoạn huấn luyện trung cấp với một mạng lưới thần kinh cấu trúc biLSTM hoạt động như một giai đoạn chín. Chúng tôi được truyền cảm hứng bởi hiệu quả của những bộ mã hóa hình thức này. Chúng tôi cho thấy phương pháp này hoạt động tốt cho một bộ dữ liệu thiếu cân bằng. Trong trường hợp này, lớp tích cực chỉ cao 0.2='của toàn bộ bộ bộ dữ liệu. Cách của chúng tôi đã hiểu tốt hơn ở F1 và sự chấp nhận so với số lượng trung hành cho tất cả những người tham gia thi đầu tranh và có được gọc thủ lại", 'bg': 'Настоящата статия подробно описва системата и подхода, използван от нашия екип за състезанието Задача 1. Задача 1 е насочена към автоматичната класификация на туитове, които споменават лекарства. Адаптирахме стандартния подход, който включва междинен етап на обучение с невронна мрежа, действаща като допълнителен етап на фина настройка. Бяхме вдъхновени от ефективността на по-нататъшното предобучение в рамките на задачата и кодиращите изречения. Показваме, че този подход работи добре за силно дисбалансиран набор от данни. В този случай положителният клас е само 0,2% от целия набор от данни. Нашият модел се представи по-добре както във Формула 1, така и по прецизност в сравнение със средния резултат за всички участници в състезанието и имаше конкурентен отзвук.', 'da': "Dette dokument beskriver den systembeskrivelse og tilgang, som vores team bruger til SMM4H 2020 konkurrencen, Opgave 1. Opgave 1 målretter automatisk klassificering af tweets, der nævner medicin. Vi tilpassede BERT's standard pre-then-fine-tune tilgang til at inkludere en mellemliggende træningsfase med et biLSTM arkitektur neuralt netværk, der fungerer som en yderligere finjusteringsfase. Vi blev inspireret af effektiviteten af intern-task videreuddannelse og sætningskodere. Vi viser, at denne tilgang fungerer godt for et stærkt ubalanceret datasæt. I dette tilfælde er den positive klasse kun 0,2% af hele datasættet. Vores model klarede sig bedre i både F1 og præcisionsscore sammenlignet med gennemsnitsscoren for alle deltagere i konkurrencen og havde en konkurrencedygtig tilbagekaldelsescore.", 'hr': 'Ovaj papir detalja opisa i pristupa sustava koji je koristio naš tim za konkurenciju SMM4H 2020, zadatak 1. Task 1 cilja se automatska klasifikacija tweets koji spominju lijekove. Prilagodili smo standardni pristup BERT pretrain-then-fine-tune kako bi uključili prosječnu fazu obuke s neuralnom mrežom biLSTM arhitekture koji djeluje kao daljnja faza fino-tuning. inspirisani su nam učinkovitosti daljnjih kodera predobuke i kazne unutar zadatka. Pokazujemo da ovaj pristup dobro funkcionira za vrlo neravnoteženu kompletu podataka. U ovom slučaju, pozitivna klasa je samo 0,2% cijelog seta podataka. Naš model je bolje izvršio u usporedbi s srednjim rezultatima svih učesnika natjecanja i dobio konkurentni rezultat sjećanja.', 'nl': 'Dit document beschrijft de systeembeschrijving en aanpak die door ons team wordt gebruikt voor de SMM4H 2020 competitie, Taak 1. Taak 1 richt zich op de automatische classificatie van tweets die medicatie vermelden. We hebben de standaard BERT pretrain-then-finetune aanpak aangepast om een tussentijdse trainingsfase te omvatten met een neuraal netwerk van biLSTM architectuur dat fungeert als een verdere finetuning fase. We werden geïnspireerd door de effectiviteit van binnen-task verdere pre-training en zinnencoders. We laten zien dat deze aanpak goed werkt voor een zeer onevenwichtige dataset. In dit geval is de positieve klasse slechts 0,2% van de gehele dataset. Ons model presteerde beter in zowel F1- als precisiescores vergeleken met de gemiddelde score voor alle deelnemers aan de wedstrijd en had een competitieve recall score.', 'de': 'Dieses Papier beschreibt die Systembeschreibung und den Ansatz, den unser Team für den SMM4H 2020 Wettbewerb, Task 1, verwendet hat. Aufgabe 1 zielt auf die automatische Klassifizierung von Tweets ab, die Medikamente erwähnen. Wir haben den Standard-BERT Pretrain-then-Fine-Tune-Ansatz angepasst, um eine Zwischentrainingsstufe mit einem neuronalen Netzwerk der biLSTM-Architektur als weitere Feinabstimmungsstufe einzubeziehen. Inspiriert wurden wir von der Effektivität von innertask-Weiterbildungen und Satzkodierern. Wir zeigen, dass dieser Ansatz gut für einen stark ungleichgewichteten Datensatz funktioniert. In diesem Fall beträgt die positive Klasse nur 0,2% des gesamten Datensatzes. Unser Modell schnitt sowohl in F1- als auch in Präzisionspunkten besser ab als bei allen Teilnehmern des Wettbewerbs und hatte einen wettbewerbsfähigen Rückruf-Score.', 'id': 'Kertas ini menjelaskan deskripsi sistem dan pendekatan yang digunakan oleh tim kami untuk kompetisi SMM4H 2020, Tugas 1. Tugas 1 menargetkan klasifikasi otomatis tweet yang menyebutkan obat. Kami menyesuaikan pendekatan BERT standar pre-rain-then-fine-tune untuk termasuk tahap pelatihan intermedium dengan jaringan saraf arsitektur biLSTM bertindak sebagai tahap penyesuaian lebih lanjut. Kami terinspirasi oleh efektivitas dalam tugas lebih lanjut prapelatihan dan pengkode kalimat. Kami menunjukkan bahwa pendekatan ini bekerja dengan baik untuk set data yang sangat tidak seimbang. Dalam kasus ini, kelas positif hanya 0,2% dari seluruh dataset. Model kami berhasil lebih baik dalam kedua skor F1 dan presisi dibandingkan dengan skor rata-rata bagi semua peserta dalam kompetisi dan memiliki skor recall kompetitif.', 'fa': 'این کاغذ توضیح و دسترسی سیستم را برای مسابقه SMM4H 2020، توضیح داده می\u200cشود. وظیفه ۱ هدف\u200cبندی اتوماتیک توئیت\u200cهایی است که داروها را اشاره می\u200cکنند. ما به طریق پیش رین-بعدش-خوب-تنظیم استاندارد BERT تغییر دادیم تا یک مرحله آموزش بین\u200cالمللی با شبکه عصبی\u200cهای معماری biLSTM که به عنوان مرحله\u200cی تحقیق بیشتری انجام می\u200cدهد. ما توسط فعالیت کارهای پیش آموزش و مجازات بیشتر الهام یافته شدیم. ما نشان می دهیم که این روش برای یک مجموعه داده های بسیار نابرابری خوب کار می کند. در این مورد، کلاس مثبت فقط 0.2% از کل مجموعه داده است. مدل ما بهتر از نقاط ف1 و دقیق در مقایسه با نقاط متوسط برای همه شرکتگران در رقابت انجام داد و یک نقاط یادآوری مسابقه داشت.', 'ko': '이 문서에서는 SMM4H 2020 경쟁 임무 1에서 우리 팀이 사용한 시스템 설명과 방법을 상세히 소개합니다.미션 1의 목표는 약물을 언급한 트윗을 자동으로 분류하는 것이다.우리는 표준적인 BERT pretrain을 채택한 후에 미조정 방법을 채택하여 중간 훈련 단계를biLSTM 구조의 신경 네트워크와 함께 진일보한 미조정 단계로 삼았다.우리는 임무 내에서 더욱 훈련하고 문장 인코딩의 유효성을 계발받았다.우리는 이런 방법이 고도의 불균형 데이터 집합에 적용된다고 밝혔다.이런 상황에서 정류는 전체 데이터 집합의 0.2% 를 차지한다.우리의 모델은 F1과 정확성 득점 방면에서 모든 참가자의 평균 득점보다 더 잘하고 경쟁적인 회상 득점을 가지고 있다.', 'sw': 'Makala hii inaelezea maelezo na mbinu za mfumo uliotumiwa na timu yetu kwa ajili ya mashindano ya SMM4H 2020, Task 1. Kazi 1 inalenga kutangazwa kwa moja kwa moja kwenye twiti zinazotaja madawa. Tumebadilisha mbinu za kawaida za BERT za kutengeneza matumizi mazuri ili kuwaingiza jukwaa la mafunzo ya kati na mitandao ya ujenzi wa biLSTM ikifanya kazi kama jukwaa la kuendelea zaidi. Tulithamishwa na ufanisi wa ndani ya kazi zaidi wa mafunzo na sheria. Tunaonyesha kuwa mbinu hii inafanya kazi vizuri kwa seti za taarifa zisizo na usawa. Katika hali hii, darasa zuri ni asilimia 0.2 tu ya seti zote za data. Mfano wetu ulifanya vizuri katika vipindi vya F1 na vipimo vya sahihi vilivyolinganishwa na kiwango cha wastani kwa washiriki wote katika mashindano hayo na alikuwa na score ya kukumbuka kwa ushindani.', 'tr': 'Bu kagyz sistemiň waspyny we golaýyny SMM4H 2020 duşuşyky üçin ullanýan toparymyzyň çykyşyny we çykyşyny maslahat berýär. 1-nji Görev ilatyny goýýan täzelerin otomatik klasifikasyny hedef edýär. Biz standart BERT önümçilik we önümçilik taýýarlamasyny beýleki biLSTM arhitektura nural şebekesi bilen gollaşdyrdyk. Biz işiň içinde öňünden öňünden öňünden öňünden ve sözleşme kodçylaryň etkinlik tarapyndan ruhlandyrdyk. Biz bu ýagdaýyň örän täsirli bir dataýa düzümlenmesi üçin gowy işleýändigini görkeýäris. Bu ýagdaýda pozitif synp diňe 0.2% bütin veri düzümleriniň. Biziň modelimiz hem F1-de, hem takyk sanlarymyzda has gowy çekdi we ýaryşyklyk hatlarymyz bardy.', 'af': "Hierdie papier beskrywing van die stelsel beskrywing en toegang wat deur ons span gebruik word vir die SMM4H 2020 samekoms, Taak 1. Taak 1 doen die outomatiese klasifikasie van tweets wat medikasie bepaal. Ons het die standaard BERT pretrain-then-fine-tune toegang aangepas om 'n middelste oefening stadium te insluit met 'n biLSTM-arkitektuur neuralnetwerk wat as 'n verdere fin-tuning stadium werk. Ons is inspireer deur die effektiviteit van binne-taak verder voor-oerwinning en setkoders. Ons wys dat hierdie toegang goed werk vir 'n baie onbalanse datastel. In hierdie geval is die positiewe klas slegs 0. 2% van die hele datastel. Ons model het beter uitgevoer in beide F1 en presisiehouers vergelyk met die gemiddelde telling vir alle deelnimmers in die samekoms en het 'n samekomstige rekening telling gehad.", 'sq': 'This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1.  Detyra 1 synon klasifikimin automatik të tweeteve që përmendin ilaçet. Ne e përshtatëm metodën standard BERT para-regjistrimit-pastaj-të-mirënjohur për të përfshirë një fazë trajnimi të ndërmjetësuar me një rrjet nervor arkitekture biLSTM që vepron si një fazë më të mirënjohur. Ne jemi frymëzuar nga efektshmëria e brendshme të detyrës përpara stërvitjes dhe koduesit e dënimeve. Ne tregojmë se kjo qasje funksionon mirë për një grup të dhënash shumë të paekuilibruar. Në këtë rast, klasa pozitive është vetëm 0.2% e të gjitha të dhënave. Modeli ynë përfundoi më mirë si në rezultatet F1 ashtu dhe të saktësisë krahasuar me rezultatin mesatar për të gjithë pjesëmarrësit në konkurs dhe kishte një rezultat konkurrues të tërheqjes.', 'am': 'ይህ ገጽ የድምፅ መግለጫ እና ሥርዓት ለSM4H 2020 ተቃውሞ የተጠቃሚ ስራ 1 ይዘረዝራል፡፡ ስራ 1 መድኃኒት የሚያስታውሱትን በትዊተሮች በራሱ መግለጫ ያሳያል፡፡ የብኤርቴን ብኤርቴን የፊርrain-በኋላ መልካም-ጥያቄን አቀማመጥ፤ በቢልSTM የመሠረታዊ ነጥብ መረብ እንደገና በጥያቄ ተሳታፊ ጥያቄን ለመቀበል ነው፡፡ የስራ ውስጥና የፊደል ትምህርት እና የፍርድ ቀድሞዎች በጥቅምት አወራጅተናል፡፡ ይሄ መግለጫ ለራሱ ስላላደረገው ዳታዎች መልካም እንዲሠራ እናሳያቸዋለን፡፡ በዚህም ጉዳይ፣ የክፍለ ክፍለ ክፍል ከሙሉ ዳታ-setን 0.2 በመቶ ብቻ ነው፡፡ ምሳሌያችን የF1 እና የቁጥጥር ነጥብ እና ለአንዳንዱ ተቃዋሚዎች ሁሉ ትክክል ነጥብ እና ተቃውሞ የተዋጋው የአፍሪካዊ ሁኔታ ነጥብ ነበረች፡፡', 'hy': 'Այս թղթին մանրամասն է ներկայացնում մեր թիմի կողմից օգտագործված համակարգի նկարագրությունը և մոտեցումը SMM4H 2020 մրցակցության համար, առաջին հանձնարարությունը: Առաջին խնդիրը նպատակում է թվիթերի ավտոմատիկ դասակարգումը, որը նշում է դեղամիջոցներ: Մենք հարմարեցրեցինք BER-ի ստանդարտ նախօրինակ-ապա-բարձրացված մոտեցումը, որպեսզի ներառենք միջնակարգ փուլում, որտեղ բիԼՍԹՄ ճարտարապետական նյարդային ցանցը գործում է որպես ավելին բարձրացման փուլում: Մենք ոգեշնչված էինք առաջնապատրաստման և նախադասությունների կոդավորման արդյունավետությամբ: Մենք ցույց ենք տալիս, որ այս մոտեցումը լավ աշխատում է բարձր անհավասարակշռության տվյալների համակարգի համար: Այս դեպքում դրական դասարանը միայն 0.2 տոկոսն է ամբողջ տվյալների համակարգում: Our model performed better in both F1 and precision scores compared to the mean score for all participants in the competition and had a competitive recall score.', 'az': 'Bu kağıt sistem tanımlamasını və metodlarını SMM4H 2020 müqayisədə, Task 1 üçün istifadə edir. İş 1, ilaçları danışan twetlərin avtomatik klasifikasiyasını hedef edir. Biz standart BERT pretrain-then-fine-tune approach, biLSTM arhitektura nöral a ğı ilə daha yaxşı düzəltmə sahəsi olaraq orta təhsil sahəsini daxil etmək üçün uyğunlaşdırdıq. Bizə daha əvvəl təhsil və cümləlik kodlayıcıların etkisiyyətliliği təlqin edildi. Bu tərzim çox müəyyən edilmiş verilənlər üçün yaxşı çalışır. Bu vəziyyətdə pozitif sınıf bütün veri qutusunun 0.2%-idir. Bizim modellərimiz F1 və dəqiqliyyat nöqtələrində müqayisədə olanların orta nöqtəsi ilə daha yaxşı işlədi və müqayisədə çəkilmə nöqtəsi vardı.', 'bn': 'এই কাগজটি আমাদের দলের ব্যবহার কর্তৃক সিস্টেমের বর্ণনা এবং পদক্ষেপ বিস্তারিত বর্ণনা এবং এসএমএফ৪হ ২০ প্রতিযোগি টাস্ক ১ টুইটের স্বয়ংক্রিয়ভাবে বিশ্লেষণের লক্ষ্য হচ্ছে যা মেডিকেশন উল্লেখ করে। আমরা স্ট্যান্ডার্ড বার্টের প্রাণবৃষ্টির প্রতিক্রিয়া পরিবর্তন করেছিলাম, যার মধ্যে একটি প্রশিক্ষণের মাধ্যমে একটি বাইলস্টিম আর্কিটার নিউরেল নেট কাজের মধ্যে আরো প্রশিক্ষণ এবং শাস্তি এনকোডের কার্যক্রমের কার্যক্রমের কারণে আমরা অনুপ্রেরণা প্রদান করেছি। আমরা দেখাচ্ছি যে এই পদক্ষেপ অত্যন্ত অসম্পূর্ণ তথ্য সেটের জন্য ভাল কাজ করছে। এই ক্ষেত্রে পুরো ডাটাসেটের ইতিবাচক ক্লাস শুধুমাত্র 0.2%। প্রতিযোগিতায় অংশগ্রহণকারীদের মানে স্কোরের তুলনায় আমাদের মডেল এফ১ এবং সঠিক স্কোরে ভালো করেছে এবং প্রতিযোগিতায় প্রতিযো', 'bs': 'Ovaj papir detalja opisa i pristupa sustava koji je koristio naš tim za konkurenciju SMM4H 2020, zadatak 1. Task 1 je cilj automatske klasifikacije tweets koji spominju lijekove. Prilagodili smo standardni pristup BERT pretrain-then-fine-tune kako bi uključili posredničku fazu obuke sa neuronskom mrežom biLSTM arhitekture koji djeluje kao daljnja faza fino-tuning. inspirisani su nam učinkovitosti daljnjih predobuka i kodera kazne unutar zadatka. Pokazujemo da ovaj pristup dobro funkcioniše za veoma neravnoteženu kompletu podataka. U ovom slučaju, pozitivna klasa je samo 0,2% cijelog seta podataka. Naš model je bolje izvršio i u rezultatima F1 i preciznosti u usporedbi sa srednjim rezultatima svih učesnika na konkurenciji i imao konkurentni rezultat sjećanja.', 'cs': 'Tento článek podrobně popisuje systém a přístup používaný naším týmem pro soutěž SMM4H 2020, Úkol 1. Úkol 1 se zaměřuje na automatickou klasifikaci tweetů, které zmiňují léky. Přizpůsobili jsme standardní přístup BERT pretrain-then-fine-ladění tak, aby zahrnoval střední tréninkovou fázi s neuronovou sítí architektury biLSTM, která slouží jako další fázi jemného ladění. Inspirovala nás efektivita dalšího předškolení uvnitř úkolů a snímačů vět. Ukazujeme, že tento přístup funguje dobře pro vysoce nevyvážený datový soubor. V tomto případě je kladná třída pouze 0,2% celé datové sady. Náš model si vedl lépe jak v F1, tak v přesném skóre ve srovnání s průměrným skóre pro všechny účastníky soutěže a měl konkurenční skóre odvolání.', 'ca': "Aquest paper detalla la descripció del sistema i l'enfocament que utilitza el nostre equip en la competició SMM4H 2020, tasca 1. La tasca 1 mira a la classificació automàtica dels tweets que mencionen medicaments. Vam adaptar l'enfocament standard BERT de pré-tren-llavors fina per incloure una etapa intermediària d'entrenament amb una xarxa neural arquitectura biLSTM que actua com una etapa més fina. Ens va inspirar l'eficacia dels codificadors de frases i pré-entrenament. Mostrem que aquest enfocament funciona bé per a un conjunt de dades altament desequilibrats. En aquest cas, la classe positiva només és el 0,2% del conjunt de dades. Our model performed better in both F1 and precision scores compared to the mean score for all participants in the competition and had a competitive recall score.", 'et': 'Käesolevas dokumendis kirjeldatakse süsteemi kirjeldust ja lähenemisviisi, mida meie meeskond kasutas SMM4H 2020 konkursil, ülesanne 1. Ülesanne 1 on suunatud ravimeid mainivate säutsude automaatsele klassifitseerimisele. Kohandasime standardset BERT-eeltreeningu-seejärel peenhäälestuse lähenemisviisi, et hõlmata vahepealset treeningut koos biLSTM-arhitektuuriga neurovõrguga, mis toimib täiendava peenhäälestuse etapina. Meid inspireerisid ülesandesisesed täiendavad eelkoolitused ja lausekodeerijad. Näitame, et see lähenemisviis toimib hästi väga tasakaalustamatu andmekogumi puhul. Sel juhul on positiivne klass vaid 0,2% kogu andmekogumist. Meie mudel saavutas parema tulemuse nii F1- kui ka täpsuskoorides võrreldes kõigi võistlusel osalejate keskmise skooriga ning saavutas konkurentsivõimelise tagasikutsumise skoori.', 'fi': 'Tässä artikkelissa kerrotaan järjestelmäkuvauksesta ja lähestymistavasta, jota tiimimme käytti SMM4H 2020 -kilpailussa, Tehtävä 1. Tehtävä 1 kohdistuu lääkitystä mainitsevien twiittien automaattiseen luokitteluun. Mukautimme BERT-standardimallin esikäsittely-then-fine-tune-menetelmän siten, että siihen sisältyy väliaikainen harjoitteluvaihe, jossa biLSTM-arkkitehtuurin neuroverkko toimii edelleen hienosäätövaiheena. Meitä inspiroi tehtävien sisäinen esikoulutus- ja lausekoodaajien tehokkuus. Osoitamme, että tämä lähestymistapa toimii hyvin erittäin epätasapainoisen aineiston kannalta. Tässä tapauksessa positiivinen luokka on vain 0,2% koko aineistosta. Mallimme suoriutui paremmin sekä F1- että tarkkuuspisteissä verrattuna kaikkien kilpailuun osallistuneiden keskiarvoon ja sillä oli kilpailullinen palautuspistemäärä.', 'sk': 'Ta prispevek podrobno opisuje opis sistema in pristop, ki ga uporablja naša ekipa za tekmovanje SMM4H 2020, naloga 1. Naloga 1 je usmerjena v samodejno klasifikacijo tweetov, ki omenjajo zdravila. Standardni pristop BERT predtrening-then-fine-tune smo prilagodili tako, da smo vključili vmesno fazo usposabljanja z živčnim omrežjem arhitekture biLSTM, ki deluje kot nadaljnja faza fine-tune. Navdihnila nas je učinkovitost nadaljnjih predusposabljanj in kodirnikov stavkov znotraj naloge. Pokazali smo, da ta pristop dobro deluje za zelo neravnotežen nabor podatkov. V tem primeru je pozitivni razred le 0,2% celotnega nabora podatkov. Naš model je imel boljši rezultat F1 in natančnosti v primerjavi s povprečnim rezultatom vseh udeležencev tekmovanja in je imel konkurenčno rezultato odpoklica.', 'ha': "Wannan takardan na bayyana salon na'urar system da aka amfani da team wa SMM4H 2020-competitin, Tafiyar 1. Tafiyar 1 na aimar da kure farat ɗaya na rubutu da ake faɗa madaidaici. Mun adayyar da ƙayyadadden BERT prerain-then-fin-tune hanzari zuwa a include an tsakanin mafarin aiki da wata biLStM tsarin neural ke aiki kamar wata daraja ta ƙaranci-tuning. Mun yi wahayi zuwa gare mu da mafiya aikin aiki da ke iya ƙara wa kodi na yin wa'azi. Ko nũna wannan hanyoyin aiki ne mafi alhẽri ga ma'abũcin data da ba ta taƙaita ba. A cikin wannan case, nau'in da za'a zama mai maras amfani kawai na 0.2% cikin tsarin database guda. MisalinMu ya sami mafiya alhẽri a tsakanin F1 da score na daidai sami da nau'i mai nau'i ga duk mãsu tãrayya a cikin competitin kuma ya sami wata rabon da ya yi gauraya.", 'jv': 'Ndeleng iki nang ngerasahan akeh sistem nambah karo akeh dumadhi iki bangsane SMM4H 2020 pating, task 1. 1 Awak dhéwé ngewayakdo Standard BERT Awakdhéwé éntuk dhéwé éntukno-ngéwangi layang-layang lan koder-ingêngêng. Awak dhéwé ngerasakno ngono hal-hal iki dadi iki luwih apik kanggo nguasakno dadi sing seperakan. Nang caz iki, kelas sing wis nong 0.2% kedokan dataset kuwi. model èn dhéwé éntuk luwih-luwih sing luwih nêmêr, dadi F1 lan sing dirampakan kanggo kalah-luwih sing nêmêr terusahaan karo hal-kalah lanjut sing ditambah nêmêr terusahaan karo perusahaan sing wis nguasai', 'bo': 'འོག་གི་ཤོག་བྱང་འདིས་མ་ལག་གི་འགྲེལ་བཤད་དང་གནད་སྡུད་རྣམས་སྤྱོད་པའི་མ་ལག བྱ་འགུལ་༡་གིས་སྨྲ་རྟགས་སྐོར་བའི་Tweets་གི་རང་འགུལ་གྱིས་དབྱེ་རིགས་དམིགས་ཡུལ། We adapted the standard BERT pretrain-then-fine-tune approach to include an intermediate training stage with a biLSTM architecture neural network acting as a further fine-tuning stage. ང་ཚོས་བྱ་ཚིག་དང་སྔོན་གྱི་སྔོན་སྒྲིག་དང་ཚིག་རྟགས་འདིའི་ནང་གི་གྲུབ་འབྲེལ་བ་དེ་ལ་བསྐྱེད་བྱས་པ འུ་ཅག་གིས་ཕལ་ཚེར་སྐྱོན་འདི་རྩ་བ་ལྕགས་ཅན་ཏུ་འགྱུར་ཅན་གྱི་ཆ་འཕྲིན་བརྗོད་ཀྱི་ཐབས་ལམ་ལ་ཕན འོན་ཀྱང་། གྲངས་རིམ་གྱི་དབྱེ་རིམ་འདི་གནད་སྡུད་ཚན་ཡོངས་ཀྱི་ནང་གི་ཚད་0.2%ཁོ་ན་རེད། ང་ཚོའི་མ་དབྱིབས་(F1)ནང་དང་ཚད་ལྡན་གྲངས་ཀ་གཉིས་ལས་མཐུན་རྐྱེན་བྱས་པ་ཡིན། དཔལ་འབྱོར་གྱི་མི་རྣམས་དང་མྱུར་སྤྱོད་མཁན་ཚོ་', 'he': 'This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1.  Task 1 targets the automatic classification of tweets that mention medication.  התאמנו את הגישה הסטנדרטית של BERT לפני גשם-ואז-מתאים כדי לכלול שלב אימון בינוני עם רשת עצבית ארכיטקטורה biLSTM פועלת כשלב מתאים נוסף. השראו אותנו מהיעילות של התאמנות הקדמית והקודדות של משפטים. אנחנו מראים שהגישה הזאת עובדת היטב עבור קבוצת נתונים לא מאוזנת. במקרה הזה, השיעור החיובי הוא רק 0.2% מכל המידע. המודל שלנו הצליח יותר טוב גם בתוצאות F1 וגם בתוצאות מדויקות בהשוואה לתוצאות הממוצעות לכל השתתפים בתחרות ויש לו תוצאות חזרה תחרותיות.'}
