{'en': 'ASR for Non-standardised Languages with Dialectal Variation : the case of ', 'ar': 'ASR للغات غير المعيارية ذات الاختلاف اللهجي: حالة اللغة الألمانية السويسرية', 'fr': 'ASR pour les langues non normalisées avec variation dialectale\xa0: le cas du suisse allemand', 'ja': '方言変異を伴う非標準化言語のASR ：スイスドイツ語の場合', 'pt': 'ASR para línguas não padronizadas com variação dialetal: o caso do suíço-alemão', 'zh': '有方言变者非标准化语ASR:瑞士德语之例', 'es': 'ASR para idiomas no estandarizados con variación dialectal: el caso del alemán suizo', 'hi': 'बोलचाल की भिन्नता के साथ गैर-मानकीकृत भाषाओं के लिए एएसआर: स्विस जर्मन का मामला', 'ru': 'ASR для нестандартизированных языков с диалектными вариациями: случай швейцарского немецкого языка', 'ga': 'ASR do Theangacha Neamhchaighdeánaithe a bhfuil Athrú Canúintí acu: cás Gearmáinis na hEilvéise', 'ka': 'Name', 'el': 'ASR για μη τυποποιημένες γλώσσες με διαλεκτική διακύμανση: η περίπτωση της Ελβετικής Γερμανικής', 'hu': 'ASR nem szabványosított nyelvekre Dialektikus variációval: a svájci német eset', 'it': 'ASR per le lingue non standardizzate con variazione dialettica: il caso del tedesco svizzero', 'mk': 'ASR за нестандардизирани јазици со дијалектална варијација: случајот на швајцарски германски', 'lt': 'ASR standartizuotoms kalboms su dialektine kintamumu: Šveicarijos vokiečių atveju', 'kk': 'ASR диалектикалық айнымалылығымен стандартты емес тілдер үшін: Швейцариялық неміс үшін', 'ms': 'ASR untuk Bahasa Tidak-Standard dengan Variasi Dialektik: kes Jerman Swiss', 'ml': 'ഡയലക്ട്രല്\u200d മാറ്റങ്ങളുമായി സ്വീസ് ജര്\u200dമ്മനിന്റെ കേസ്', 'mt': 'ASR għal Lingwi Mhux Standardizzati b’Varjazzjoni Dijalettwali: il-każ tal-Ġermaniż Svizzeru', 'mn': 'Швейцарийн Германы тохиолдол', 'no': 'ASR for ikkje- standardiserte språk med dialektiske variasjon: the case of Swiss German', 'pl': 'ASR dla języków niestandardowych z wariancją dialektalną: przypadek niemieckiego szwajcarskiego', 'ro': 'ASR pentru limbi nestandardizate cu variație dialectă: cazul germanei elvețiene', 'si': 'Name', 'sr': 'ASR za neostandardizovane jezike sa dijalektnom varijancijom: slučaj švicarskog njemačkog', 'so': 'Jarmalka Iswidish', 'sv': 'ASR för icke-standardiserade språk med dialektisk variation: fallet med schweizisk tyska', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': '(ASR) for Non-chuẩn languages with Diatecl variation: the case of Thụy Sĩ German Name', 'bg': 'АСР за нестандартизирани езици с диалектална вариация: случаят на швейцарски немски', 'da': 'ASR for ikke-standardiserede sprog med dialektisk variation: tilfældet med schweizisk tysk', 'nl': 'ASR voor niet-gestandaardiseerde talen met dialectische variatie: het geval van Zwitsers Duits', 'hr': 'ASR za neostandardizirane jezike s dijalektnom varijancijom: slučaj švicarskog njemačkog', 'de': 'ASR für nicht standardisierte Sprachen mit dialektaler Variation: der Fall des Schweizerdeutschen', 'id': 'ASR untuk Bahasa Tidak Standardisasi dengan Variasi Dialeksi: kasus Jerman Swiss', 'fa': 'Name', 'ko': '사투리의 변이를 띤 비표준화 언어의 ASR: 스위스 독일어의 경우', 'sw': 'ASR kwa lugha zisizo na kiwango cha kurekebisha na mabadiliko ya Kiingereza: kesi ya Ujerumani', 'tr': 'ASR : Şweýsariýa Germaniýanyň kiçi', 'sq': 'ASR për gjuhët jo të standartizuara me variacion dialektal: rasti i gjermanisë zvicerane', 'am': 'ቋንቋዎች', 'hy': 'Սվեյցարական գերմանացի դեպքում', 'af': 'Language', 'az': 'İsviçre Almancı dili ilə standartlaşdırılmış dillər üçün ASR: İsviçə dilləri', 'bn': 'ডায়ালেক্টাল বিভাগের সাথে অসমর্থিত ভাষার জন্য ASR: সুইসি জার্মানের মামলা', 'bs': 'ASR za ne standardizovane jezike sa dijalektnom varijancijom: slučaj švicarskog njemačkog', 'ca': "ASR per llengües no estandaritzats amb variació dialectal: el cas de l'alemanya suïssa", 'cs': 'ASR pro nestandardní jazyky s dialektální variací: případ švýcarské němčiny', 'et': 'Dialektilise variatsiooniga mittestandardsete keelte ASR: Šveitsi saksa juhtum', 'fi': 'ASR ei-standardoiduille kielille, joilla on dialektinen vaihtelu: Sveitsin saksan tapaus', 'jv': 'Language', 'ha': 'KCharselect unicode block name', 'sk': 'ASR za nestandardizirane jezike z dialektno variacijo: primer švicarske nemščine', 'he': 'ASR for Non-Standardized Languages with Dialectal Variation: the case of Swiss German', 'bo': 'ASR for Non-standard Languages with Dialectal Variation: the case of Swiss German'}
{'en': 'Strong regional variation, together with the lack of standard ', 'ar': 'الاختلاف الإقليمي القوي ، جنبًا إلى جنب مع الافتقار إلى قواعد الإملاء القياسية ، يجعل التعرف التلقائي على الكلام السويسري الألماني (ASR) صعبًا بشكل خاص في بيئة متعددة اللهجات. تركز هذه الورقة على أحد التحديات العديدة ، ألا وهو اختيار نص المخرجات لتمثيل الألمانية السويسرية غير الموحدة. نحن نبحث في خيارين محتملين: أ) الكتابة باللهجة - النسخ الصوتية التقريبية التي توفر مراسلات وثيقة بين تسميات حروف الكتابة والإشارة الصوتية ولكنها غير متسقة إلى حد كبير و ب) الكتابة الطبيعية - نسخ تشبه اللغة الألمانية القياسية التي تكون متسقة نسبيًا ولكنها بعيدة عن الإشارة الصوتية. لمعرفة الكتابة التي تسهل استخدام ASR الألماني السويسري ، قمنا ببناء عدة أنظمة باستخدام مجموعة أدوات Kaldi ومجموعة بيانات تغطي 14 نوعًا إقليميًا. تُظهر مقارنة رسمية أن النظام المُدرَّب على النسخ المعيارية يحقق نتائج أفضل في معدل أخطاء الكلمات (WER) (29.39٪) ولكنه أقل أداءً على مستوى الحرف ، مما يشير إلى أن النسخ اللهجة تقدم حلاً قابلاً للتطبيق للتطبيقات النهائية حيث تكون الاختلافات في اللهجات مهمة. لتقييم أداء الكلمات على مستوى الكلمات بشكل أفضل ، نستخدم مقياس WER المرن (FlexWER). عند تقييمه باستخدام هذا المقياس ، يتفوق النظام المُدرَّب على النسخ اللهجة في الأداء الذي تم تدريبه على الكتابة الطبيعية. إلى جانب إنشاء معيار لـ ASR متعدد اللهجات السويسري الألماني ، يمكن أن تكون النتائج التي توصلنا إليها مفيدة في تصميم أنظمة ASR لـ\nلغات أخرى بدون قواعد إملائية.', 'es': 'La fuerte variación regional, junto con la falta de ortografía estándar, hace que el reconocimiento automático de voz (ASR) del alemán suizo sea particularmente difícil en un entorno multidialectal. Este documento se centra en uno de los muchos desafíos, a saber, la elección del texto de salida para representar el alemán suizo no estandarizado. Investigamos dos posibles opciones: a) escritura dialectal, transcripciones fonémicas aproximadas que proporcionan una estrecha correspondencia entre las etiquetas de grafema y la señal acústica, pero son muy inconsistentes, y b) escritura normalizada, transcripciones que se asemejan al alemán estándar que son relativamente consistentes pero distante de la señal acústica. Para averiguar qué escritura facilita el ASR entre Suiza y Alemania, creamos varios sistemas utilizando el kit de herramientas Kaldi y un conjunto de datos que abarca 14 variedades regionales. Una comparación formal muestra que el sistema entrenado en las transcripciones normalizadas logra mejores resultados en la tasa de error de palabras (WER) (29.39%), pero tiene un rendimiento inferior a nivel de caracteres, lo que sugiere que las transcripciones dialectales ofrecen una solución viable para aplicaciones posteriores donde las diferencias dialectales son importantes. Para evaluar mejor el rendimiento a nivel de palabra para las transcripciones dialectales, utilizamos una medida WER flexible (FlexWER). Cuando se evalúa con esta métrica, el sistema entrenado en transcripciones dialectales supera al entrenado en la escritura normalizada. Además de establecer un punto de referencia para ASR multidialectal alemán suizo, nuestros hallazgos pueden ser útiles en el diseño de sistemas ASR para\notros idiomas sin ortografía estándar.', 'pt': 'A forte variação regional, juntamente com a falta de ortografia padrão, torna o reconhecimento automático de fala suíço-alemão (ASR) particularmente difícil em um ambiente multi-dialetal. Este artigo se concentra em um dos muitos desafios, a saber, a escolha do texto de saída para representar o suíço-alemão não padronizado. Investigamos duas opções potenciais: a) escrita dialetal – transcrições fonêmicas aproximadas que fornecem correspondência próxima entre os rótulos do grafema e o sinal acústico, mas são altamente inconsistentes e b) escrita normalizada – transcrições semelhantes ao alemão padrão que são relativamente consistentes, mas distantes do sinal acústico. Para descobrir qual escrita facilita o ASR suíço-alemão, construímos vários sistemas usando o kit de ferramentas Kaldi e um conjunto de dados que abrange 14 variedades regionais. Uma comparação formal mostra que o sistema treinado nas transcrições normalizadas obtém melhores resultados na taxa de erro de palavras (WER) (29,39%), mas apresenta desempenho inferior no nível de caracteres, sugerindo que as transcrições dialetais oferecem uma solução viável para aplicações downstream onde as diferenças dialetais são importantes. Para avaliar melhor o desempenho em nível de palavra para transcrições dialetais, usamos uma medida WER flexível (FlexWER). Quando avaliado com essa métrica, o sistema treinado em transcrições dialetais supera o treinado na escrita normalizada. Além de estabelecer uma referência para o ASR multi-dialetal suíço-alemão, nossas descobertas podem ser úteis no projeto de sistemas ASR para\noutras línguas sem ortografia padrão.', 'fr': "Les fortes variations régionales, associées à l'absence d'orthographe standard, rendent la reconnaissance automatique de la parole (ASR) suisse-allemande particulièrement difficile dans un environnement multidialectal. Cet article se concentre sur l'un des nombreux défis, à savoir le choix du texte de sortie pour représenter le suisse allemand non normalisé. Nous étudions deux options possibles\xa0: a) écriture dialectale — transcriptions phonémiques approximatives qui fournissent une correspondance étroite entre les étiquettes du graphème et le signal acoustique mais qui sont très incohérentes et b) écriture normalisée — transcriptions ressemblant à l'allemand standard qui sont relativement cohérentes mais loin du signal acoustique. Pour savoir quelle écriture facilite l'ASR suisse allemand, nous construisons plusieurs systèmes à l'aide de la boîte à outils Kaldi et d'un ensemble de données couvrant 14 variétés régionales. Une comparaison formelle montre que le système formé sur les transcriptions normalisées obtient de meilleurs résultats en termes de taux d'erreur de mot (WER) (29,39\xa0%) mais qu'il est moins performant au niveau des caractères, ce qui suggère que les transcriptions dialectales offrent une solution viable pour les applications en aval où les différences dialectales sont importantes. Pour mieux évaluer les performances au niveau des mots pour les transcriptions dialectales, nous utilisons une mesure WER flexible (FlexWER). Lorsqu'il est évalué avec cette métrique, le système formé sur les transcriptions dialectales surpasse celui formé sur l'écriture normalisée. Outre l'établissement d'une référence pour l'ASR multi-dialectal suisse allemand, nos résultats peuvent être utiles pour la conception de systèmes ASR pour\nautres langues sans orthographe standard.", 'ja': '強い地域変動と標準的な正書法の欠如は、スイスドイツ語の自動音声認識（ ASR ）を多言語環境で特に困難にします。 本稿では、多くの課題の1つ、すなわち標準化されていないスイスドイツ語を表すための出力テキストの選択に焦点を当てる。 私たちは、次の2つの潜在的なオプションを調査します。a ）方言の書き込み–文法ラベルと音響信号との間に緊密な対応を提供するが、非常に一貫性のない近似的な音声転写、およびb ）正規化された書き込み–比較的一貫しているが音響信号から離れた標準ドイツ語に似た転写。 スイスドイツのASRを容易にする書き込みを見つけるために、Kaldiツールキットと14の地域の品種をカバーするデータセットを使用して、いくつかのシステムを構築しています。 正式な比較は、正規化された文字起こしでトレーニングされたシステムが、単語エラー率（ WER ） （ 29.39 ％ ）でより良い結果を達成するが、文字レベルでは不十分であることを示しており、方言の文字起こしが方言の違いが重要な下流アプリケーションにとって実行可能な解決策を提供することを示唆している。 方言転写の単語レベルのパフォーマンスをよりよく評価するために、柔軟なWERメジャー（ FlexWER ）を使用します。 この指標で評価すると、方言転写に関するトレーニングを受けたシステムは、正規化された書き込みに関するトレーニングを受けたシステムよりも優れています。 スイスドイツ語の多方言ASRのベンチマークを確立することに加えて、私たちの調査結果は、\n標準的な正書法を持たない他の言語.', 'ga': 'Mar gheall ar éagsúlacht réigiúnach láidir, mar aon le heaspa ortagrafaíocht chaighdeánach, tá sé thar a bheith deacair aitheantas cainte uathoibríoch Gearmánach na hEilvéise (ASR) a aithint i suíomh ilchanúnach. Díríonn an páipéar seo ar cheann de na dúshláin iomadúla, eadhon, an téacs aschuir a roghnú chun Gearmáinis Eilvéiseach neamhchaighdeánaithe a léiriú. Déanaimid iniúchadh ar dhá rogha fhéideartha: a) scríbhneoireacht chanúinteach – neas-trascríbhinní fóinéime a sholáthraíonn comhfhreagras dlúth idir lipéid ghraiféime agus an comhartha fuaimiúil ach atá thar a bheith neamh-chomhsheasmhach agus b) scríbhneoireacht normalaithe – tras-scríbhinní cosúil le Gearmáinis chaighdeánach atá réasúnta comhsheasmhach ach i bhfad ón gcomhartha fuaimiúil. Le fáil amach cén scríbhneoireacht a éascaíonn ASR na hEilvéise Gearmáinise, tógaimid roinnt córas ag baint úsáide as foireann uirlisí Kaldi agus tacar sonraí a chlúdaíonn 14 chineál réigiúnach. Léiríonn comparáid fhoirmiúil go mbaineann an córas atá oilte ar na tras-scríbhinní normalaithe torthaí níos fearr amach sa ráta earráide focal (WER) (29.39%) ach go bhfuil tearcfheidhmithe aige ar leibhéal na gcarachtar, ag moladh go dtugann tras-scríbhinní canúinteacha réiteach inmharthana d’fheidhmchláir iartheachtacha ina bhfuil difríochtaí canúinteacha tábhachtach. Chun feidhmíocht leibhéal na bhfocal a mheasúnú níos fearr le haghaidh tras-scríbhinní canúintí, bainimid úsáid as beart WER solúbtha (FlexWER). Nuair a dhéantar measúnú air leis an méadrach seo, sáraíonn an córas atá oilte ar thras-scríbhinní canúintí ná an córas atá oilte ar an scríbhneoireacht normalaithe. Seachas tagarmharc a bhunú le haghaidh ASR ilchanúnach Gearmánach na hEilvéise, is féidir lenár dtorthaí a bheith ina chuidiú le córais ASR a dhearadh do\nteangacha eile gan ortagrafaíocht chaighdeánach.', 'hi': 'मजबूत क्षेत्रीय भिन्नता, मानक ऑर्थोग्राफी की कमी के साथ, स्विस जर्मन स्वचालित भाषण मान्यता (एएसआर) को बहु-बोली सेटिंग में विशेष रूप से मुश्किल बनाती है। यह पेपर कई चुनौतियों में से एक पर केंद्रित है, अर्थात्, गैर-मानकीकृत स्विस जर्मन का प्रतिनिधित्व करने के लिए आउटपुट टेक्स्ट की पसंद। हम दो संभावित विकल्पों की जांच करते हैं: ए) बोलचाल लेखन - अनुमानित फोनिक ट्रांसक्रिप्शन जो ग्राफेम लेबल और ध्वनिक सिग्नल के बीच करीबी पत्राचार प्रदान करते हैं, लेकिन अत्यधिक असंगत हैं और बी) सामान्यीकृत लेखन - मानक जर्मन के समान प्रतिलेखन जो अपेक्षाकृत सुसंगत हैं लेकिन ध्वनिक संकेत से दूर हैं। यह पता लगाने के लिए कि कौन सा लेखन स्विस जर्मन एएसआर की सुविधा प्रदान करता है, हम काल्डी टूलकिट और 14 क्षेत्रीय किस्मों को कवर करने वाले डेटासेट का उपयोग करके कई प्रणालियों का निर्माण करते हैं। एक औपचारिक तुलना से पता चलता है कि सामान्यीकृत प्रतिलेखन पर प्रशिक्षित प्रणाली शब्द त्रुटि दर (डब्ल्यूईआर) (29.39%) में बेहतर परिणाम प्राप्त करती है, लेकिन चरित्र स्तर पर अंडरपरफॉर्म करती है, यह सुझाव देते हुए कि बोलचाल के प्रतिलेखन डाउनस्ट्रीम अनुप्रयोगों के लिए एक व्यवहार्य समाधान प्रदान करते हैं जहां द्वंद्वात्मक अंतर महत्वपूर्ण हैं। बोलचाल प्रतिलेखन के लिए शब्द-स्तर के प्रदर्शन का बेहतर आकलन करने के लिए, हम एक लचीला WER उपाय (FlexWER) का उपयोग करते हैं। जब इस मीट्रिक के साथ मूल्यांकन किया जाता है, तो बोलचाल के प्रतिलेखन पर प्रशिक्षित प्रणाली सामान्यीकृत लेखन पर प्रशिक्षित बेहतर प्रदर्शन करती है। स्विस जर्मन बहु-बोली एएसआर के लिए एक बेंचमार्क स्थापित करने के अलावा, हमारे निष्कर्ष एएसआर सिस्टम को डिजाइन करने में सहायक हो सकते हैं\nमानक ऑर्थोग्राफी के बिना अन्य भाषाओं।', 'zh': '烈域差异,加以阙正字法,使瑞士德语自音识(ASR)多方言境尤难。 本文重点介众挑战之一,即择输出文本示非标准化之瑞士德语。 余论两潜:a)言作 - 近似音素转录,在字素、声学之间,其应甚密,而高不同;b)标准化书 - 类于格德语之转录,相一而远声学。 求何瑞士德语ASR,Kaldi工具包涵盖14数集。 正较明归一化转录训练之统于单词错误率(WER)(29.39%),而于字符之级为不佳,此方言转录为方言差异之要,宜有可行之解决方案。 更评方言转录单词性,用灵活WER度(FlexWER)。 当以此指标质之,方言转录练之统优于标准化。 除瑞士德语多方言ASR建立基准外,犹有助于计ASR系统\n无准正字法他语。', 'ru': 'Сильные региональные вариации, наряду с отсутствием стандартной орфографии, делают автоматическое распознавание швейцарской немецкой речи (ASR) особенно трудным в многодиалектной обстановке. В настоящем документе основное внимание уделяется одной из многочисленных проблем, а именно выбору выходного текста для представления нестандартизированного швейцарского немецкого языка. Мы исследуем два возможных варианта: a) диалектное письмо – приблизительные фонематические транскрипции, которые обеспечивают близкое соответствие между графемными метками и акустическим сигналом, но являются очень непоследовательными, и b) нормализованное письмо – транскрипции, напоминающие стандартный немецкий язык, которые относительно последовательны, но удалены от акустического сигнала. Чтобы выяснить, какое письмо облегчает швейцарский немецкий ASR, мы создаем несколько систем с использованием инструментария Kaldi и набора данных, охватывающего 14 региональных разновидностей. Формальное сравнение показывает, что система, обученная на нормализованных транскрипциях, достигает лучших результатов в частоте ошибок слова (WER) (29,39%), но не выполняет свои функции на уровне символов, что позволяет предположить, что диалектные транскрипции предлагают жизнеспособное решение для последующих приложений, где диалектные различия важны. Чтобы лучше оценить производительность на уровне слов для диалектных транскрипций, мы используем гибкую меру WER (FlexWER). При оценке с помощью этой метрики система, обученная диалектным транскрипциям, превосходит систему, обученную нормализованному письму. Помимо определения эталона для швейцарского немецкого мультидиалектального ASR, наши результаты могут быть полезны при разработке систем ASR для\nдругие языки без стандартной орфографии.', 'ka': 'სხვა ენები სტანდარტური ორტოგრაფიის გარეშე.', 'hu': 'egyéb szabványos ortográfia nélküli nyelvek.', 'it': 'altre lingue senza ortografia standard.', 'el': 'άλλες γλώσσες χωρίς τυπική ορθογραφία.', 'kk': 'стандартты ортографиясыз басқа тілдер.', 'lt': 'kitos kalbos be standartinės ortografijos.', 'mk': 'други јазици без стандардна ортографија.', 'ms': 'bahasa lain tanpa ortografi piawai.', 'ml': 'സാധാരണ ഒറോഗ്രാഫിയില്ലാത്ത മറ്റു ഭാഷകള്\u200d.', 'mt': 'lingwi oħra mingħajr ortografija standard.', 'mn': 'стандарт ортографик байхгүй бусад хэл.', 'no': 'andre språk utan standard ortografi.', 'pl': 'inne języki bez standardowej ortografii.', 'ro': 'alte limbi fără ortografie standard.', 'sr': 'Drugi jezici bez standardne ortografije.', 'si': 'අනිත් භාෂාවල් ස්ථානික වර්තෝග්\u200dරාෆික් නැතුව.', 'so': 'luuqado kale oo aan aqoonta caadi ah ku lahayn', 'sv': 'Andra språk utan standardortografi.', 'ur': 'بغیر استاندارد اورٹوگرافی کے دوسری زبانیں۔', 'ta': 'நிலையான ஒழுங்குநிரல் இல்லாத மற்ற மொழிகள்.', 'uz': 'boshqa tillar andoza ortografiya emas.', 'vi': 'các ngôn ngữ khác mà không chỉnh chuẩn.', 'bg': 'други езици без стандартна ортография.', 'de': 'andere Sprachen ohne Standardorthographie.', 'da': 'andre sprog uden standardortografi.', 'nl': 'andere talen zonder standaardorthografie.', 'hr': 'drugim jezicima bez standardne ortografije.', 'id': 'bahasa lain tanpa ortografi standar.', 'ko': '표준 정자법이 없는 다른 언어.', 'fa': 'زبان های دیگر بدون ورتوگرافی استاندارد.', 'sw': 'lugha nyingine bila orodha ya kawaida.', 'tr': 'standart ortografiýasy bolmadyk başga diller.', 'af': 'ander tale sonder standaard orthografie.', 'sq': 'gjuhë të tjera pa ortografi standard.', 'am': 'ሌሎች ቋንቋዎች በጭምር የኦሮግራፊ ቋንቋዎች ናቸው', 'hy': 'այլ լեզուներ առանց ստանդարտ օրտոգրաֆիայի:', 'az': 'Standart ortografiya olmayan başqa dillər.', 'bn': 'স্ট্যান্ডার্ডার্ড অ্যাটোগ্রাফি ছাড়া অন্যান্য ভাষা।', 'ca': 'altres llengües sense ortografia normal.', 'cs': 'jiné jazyky bez standardní pravopisu.', 'et': 'muud keeled, millel puudub standardne ortograafia.', 'bs': 'Drugi jezici bez standardne ortografije.', 'fi': 'muut kielet, joilla ei ole vakioortografiaa.', 'jv': 'paragraph-styletextattr', 'sk': 'drugi jeziki brez standardne ortografije.', 'ha': 'Da harshe wasu, ba da ortografi na daidaita.', 'he': 'שפות אחרות ללא אורטוגרפיה סטנדרטית.', 'bo': 'སྐད་རིགས་གཞན་མི་མང་གིས་དེ་དག་རྒྱུན་ལྡན་གྱི་ཡིག་རེད།'}
{'en': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks : Comparing the Usefulness of Close and Distant Languages', 'ar': 'تكيف NMT الموجه آليًا لمهام Zero-shot NLP: مقارنة فائدة اللغات القريبة والبعيدة', 'es': 'Adaptación de NMT orientada a máquinas para tareas de PNL de tiro cero: comparación de la utilidad de los lenguajes cercanos y lejanos', 'fr': "Adaptation NMT orientée machine pour les tâches de PNL à tir zéro\xa0: comparaison de l'utilité des langues proches et distantes", 'pt': 'Adaptação NMT orientada a máquina para tarefas NLP Zero-shot: comparando a utilidade de linguagens próximas e distantes', 'ja': 'ゼロショットNLPタスクのための機械指向NMT適応：近距離言語と遠隔言語の有用性の比較', 'zh': '向机器者 NMT 自适零射 NLP 务:近言远言者有用性', 'hi': 'शून्य-शॉट एनएलपी कार्यों के लिए मशीन-उन्मुख एनएमटी अनुकूलन: करीबी और दूर की भाषाओं की उपयोगिता की तुलना करना', 'ru': 'Машиноориентированная адаптация NMT для задач NLP с нулевым выстрелом: сравнение полезности близких и удаленных языков', 'ga': 'Oiriúnú NMT meaisín-dhírithe do thascanna NLP le seatanna nialais: Ag Comparáid a dhéanamh ar Úsáideacht Theangacha Gar- agus Teangacha i gCéin', 'ka': 'Name', 'hu': 'Gép-orientált NMT adaptáció Zero-shot NLP feladatokhoz: Közeli és távoli nyelvek hasznosságának összehasonlítása', 'el': 'Προσαρμογή με προσανατολισμό στη μηχανή για εργασίες μηδενικού πυροβολισμού: σύγκριση της χρησιμότητας κοντινών και απομακρυσμένων γλωσσών', 'it': "Adattamento NMT orientato alla macchina per attività NLP a scatto zero: confronto dell'utilità di lingue vicine e lontane", 'kk': 'NLP тапсырмаларының NMT бағытталған NMT адаптациясы: Жабу мен қашықтағы тілдердің пайдалығын салыстыру', 'mk': 'Адаптација на NMT ориентирана на машина за нула-снимки NLP задачи: Споредување на корисноста на блиски и далечни јазици', 'lt': 'Į mašinas orientuotas NMT pritaikymas nuliniams NLP uždaviniams: artimų ir nuotolinių kalbų naudingumo palyginimas', 'mt': 'Adattament NMT orjentat lejn il-makkinarju għal kompiti NLP b’żero-shot: Tqabbil tal-Utilità ta’ Lingwi mill-qrib u mill-bogħod', 'ms': 'Penyesuaian NMT orient mesin untuk tugas NLP 0-shot: Comparing the Useful of Close and Distant Languages', 'ml': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks: Comparing the Usefulness of Close and Distant Languages', 'no': 'NMT- tilpassing for NLP- oppgåver med maskineorientert NMT- tilpassing for null- shot: Samanliknar nødvendigheten av lukka og avstandsspråk', 'mn': 'НЛП ажлын машины ориентиролт NMT адаптация: Хойд болон хол хэлний хэрэглээ харьцуулах', 'ro': 'Adaptarea NMT orientată spre mașină pentru sarcini PNL zero-shot: Compararea utilizării limbilor apropiate și îndepărtate', 'pl': 'Zorientowana maszynowo adaptacja NMT do zadań zerowo-strzałowych NLP: Porównanie przydatności języków bliskich i odległych', 'sr': 'Mašinski orijentirani NMT adaptacija za zadatak NLP-a sa nulom snimanjem: uspoređivanje korisnosti zatvorenih i dalekih jezika', 'so': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks: Comparinta Useful of Close and Distant Languages', 'si': 'NLP වැඩක් සඳහා මෙෂින් ප්\u200dරමාණය NMT අනතුරු වැඩක්: වහන්න සහ දුරස්ථ භාෂාවගේ ප්\u200dරයෝජනය සම්පූර්ණය', 'sv': 'Maskinorienterad NMT-anpassning för NLP-uppgifter utan skott: Jämförelse av användbarheten hos nära och avlägsna språk', 'ur': 'NLP دنیاوں کے لئے ماشین-oriented NMT اڈپٹیٹ: بند اور دور زبانوں کے فائدہ کے مطابق مقایسہ کرتا ہے', 'ta': 'சூழ்நிலைப்படுத்தப்பட்ட NLP பணிகளுக்கான இயந்திரம் திருப்பி NMT மாற்றுதல்: மூடிய மொழிகளின் பயன்பாட்டை ஒப்பிடுகிறது', 'uz': 'Name', 'vi': 'Công cụ định hướng công nghệ NMT định hướng máy tính cho công việc Không ảnh: So sánh tính hữu ích của ngôn ngữ gần gũi và xa cách', 'nl': 'Machine-georiënteerde NMT Adaptatie voor Zero-shot NLP taken: het vergelijken van de bruikbaarheid van nabije en verre talen', 'bg': 'Машинно ориентирана адаптация за НЛП задачи: Сравняване на полезността на близките и отдалечените езици', 'hr': 'Uspoređivanje korisnosti zatvorenih i dalekih jezika', 'de': 'Maschinenorientierte NMT-Anpassung für Zero-Shot NLP-Aufgaben: Vergleich der Nützlichkeit von Nah- und Fernsprachen', 'da': 'Maskinorienteret NMT-tilpasning til nulskudsNLP-opgaver: Sammenligning af nyttigheden af tæt- og fjernsynssprog', 'sw': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks: Comparing the Usefulness of Close and Distant Languages', 'ko': '시스템을 위한 제로 포 NLP 작업 NMT 적응성: 근거리 언어와 원거리 언어의 유용성 비교', 'id': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks: Comparing the Usefulness of Close and Distant Languages', 'af': 'Masjien-orienteerde NMT-aanpassing vir Nuwe-skoot NLP-opdragte: Vergelyk die gebruikerheid van toemaak en afstand Taal', 'sq': 'Përpërshtatje NMT-orientuar në makinë për detyra zero-shot NLP: Krahasimi i dobësisë së gjuhëve të mbyllura dhe të largëta', 'am': 'አዲስ ዶሴ ፍጠር', 'tr': 'NLP Görniş üçin maşynda görkezilen NMT Görniş Opşenleri: ýap we uzak dilleriniň ullanlygyny karşılaştyrmak', 'az': 'NLP işləri üçün maşın tərəfindən NMT Adaptasyonu: Yaxınlıq və uzaq dillərin faydalanılığını qarşılaşdır', 'fa': 'تغییرات NMT دستگاه برای کارهای NLP صفر تیر: مقایسه کاری زبانهای نزدیک و فاصله', 'ca': "Adaptació NMT orientada a màquines per tasques NLP zero-fotografiades: Comparar l'utilitat de llengües tanques i remotes", 'cs': 'Strojově orientovaná NMT adaptace pro nulové NLP úlohy: Porovnání užitečnosti blízkých a vzdálených jazyků', 'et': 'Masinaorienteeritud NMT kohandumine null-shot NLP ülesannete jaoks: lähedaste ja kaugete keelte kasulikkuse võrdlemine', 'hy': 'Մեքենայի ուղղությամբ NMT-ի հարմարումը զրո-կրակի ՆԼՊ-ի առաջադրանքների համար. Մոտ և հեռավոր լեզուների օգտակարության համեմատությունը', 'fi': 'Konelähtöinen NMT-sopeutuminen nollashotin NLP-tehtäviin: Läheisten ja kaukaisten kielten hyödyllisyyden vertailu', 'bs': 'Uspoređivanje korisnosti zatvorenih i dalekih jezika', 'bn': 'জিরো- শুট এনএলপি কাজের জন্য মেশিন-পরিচিত NMT আড্যাপটেশন: বন্ধ এবং বিদূর ভাষার ব্যবহার তুলনায়', 'ha': '@ action', 'he': 'Machine-oriented NMT Adaptation for Zero-shot NLP tasks: Comparing the Usefulness of Close and Distant Languages', 'sk': 'Strojno usmerjena NMT prilagoditev za naloge NLP brez strela: primerjava uporabnosti jezikov blizu in oddaljenih', 'jv': 'Global', 'bo': 'འདྲ་བཤུ་དང་བར་ཐག་རིང་གི་བྱ་འགུལ་ལ་ལག་སྟར་བྱེད་པའི་NMT བཟོ་སྒྲིག་བཟོ་བྱེད།'}
{'en': 'Neural Machine Translation (NMT) models are typically trained by considering humans as end-users and maximizing human-oriented objectives. However, in some scenarios, their output is consumed by automatic NLP components rather than by humans. In these scenarios, translations’ quality is measured in terms of their fitness for purpose (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency / adequacy criteria. Recently, ', 'ar': 'عادةً ما يتم تدريب نماذج الترجمة الآلية العصبية (NMT) من خلال اعتبار البشر مستخدمين نهائيين وتعظيم الأهداف الموجهة نحو الإنسان. ومع ذلك ، في بعض السيناريوهات ، يتم استهلاك ناتجها بواسطة مكونات البرمجة اللغوية العصبية التلقائية بدلاً من البشر. في هذه السيناريوهات ، تُقاس جودة الترجمات من حيث "ملاءمتها للغرض" (أي تعظيم أداء أدوات البرمجة اللغوية العصبية الخارجية) بدلاً من معايير الطلاقة البشرية / الكفاءة القياسية. في الآونة الأخيرة ، تم اقتراح تقنيات التعلم المعزز التي تستغل التغذية الراجعة من أدوات البرمجة اللغوية العصبية في المراحل النهائية للتكيف مع NMT "الموجه نحو الآلة". في هذا العمل ، نعالج المشكلة في إعداد متعدد اللغات حيث يتم ترجمة نموذج NMT واحد من لغات متعددة للمعالجة التلقائية في المصب في اللغة الهدف. تسمح مشاركة المعرفة عبر اللغات القريبة والبعيدة بتطبيق نهجنا الموجه نحو الآلة في إعداد اللقطة الصفرية حيث لا يتم رؤية بيانات معنونة للغة الاختبار في وقت التدريب. علاوة على ذلك ، نقوم بدمج BERT متعدد اللغات في جانب المصدر لنظام NMT الخاص بنا للاستفادة من المعرفة المضمنة في هذا النموذج. تُظهر تجاربنا مكاسب أداء متماسكة ، لاتجاهات لغوية مختلفة على كل من نماذج NMT "العامة" (المدربة على الاستهلاك البشري) ، و 2) BERT متعدد اللغات الذي تم ضبطه بدقة. يكون هذا الكسب لاتجاهات اللغة ذات اللقطة الصفرية (مثل الإسبانية والإنجليزية) أعلى عندما يتم ضبط النماذج بدقة على لغة مصدر وثيقة الصلة (الإيطالية) من لغة بعيدة (الألمانية).', 'es': 'Los modelos de traducción automática neuronal (NMT) generalmente se entrenan considerando a los humanos como usuarios finales y maximizando los objetivos orientados a los humanos. Sin embargo, en algunos escenarios, su producción es consumida por los componentes automáticos de la PNL en lugar de por los humanos. En estos escenarios, la calidad de las traducciones se mide en términos de su «aptitud para el propósito» (es decir, maximizar el rendimiento de las herramientas externas de PNL) en lugar de en términos de criterios estándar de fluencia/adecuación humana. Recientemente, se han propuesto técnicas de aprendizaje por refuerzo que aprovechan la retroalimentación de las herramientas de PNL posteriores para la adaptación de la NMT «orientada a la máquina». En este trabajo, abordamos el problema en un entorno multilingüe en el que un solo modelo de NMT traduce de varios idiomas para el procesamiento automático posterior en el idioma de destino. El intercambio de conocimientos en idiomas cercanos y lejanos permite aplicar nuestro enfoque orientado a la máquina en la configuración de tiro cero, donde no se ven datos etiquetados para el idioma de prueba durante el entrenamiento. Además, incorporamos BERT multilingüe en el lado fuente de nuestro sistema NMT para beneficiarnos del conocimiento incorporado en este modelo. Nuestros experimentos muestran ganancias de rendimiento coherentes, para diferentes direcciones lingüísticas, tanto en i) modelos NMT «genéricos» (capacitados para el consumo humano) como ii) BERT multilingüe afinado. Esta ganancia para las direcciones lingüísticas cero (por ejemplo, español-inglés) es mayor cuando los modelos se ajustan con precisión en un idioma de origen estrechamente relacionado (italiano) que en uno distante (alemán).', 'fr': "Les modèles de traduction automatique neuronale (NMT) sont généralement formés en considérant les humains comme des utilisateurs finaux et en maximisant les objectifs orientés vers l'humain. Cependant, dans certains scénarios, leur production est consommée par des composants NLP automatiques plutôt que par des humains. Dans ces scénarios, la qualité des traductions est mesurée en fonction de leur «\xa0adéquation à l'objectif\xa0» (c'est-à-dire en maximisant les performances des outils de PNL externes) plutôt qu'en termes de critères standard de fluidité humaine ou d'adéquation. Récemment, des techniques d'apprentissage par renforcement exploitant le feedback des outils de PNL en aval ont été proposées pour une adaptation NMT «\xa0orientée machine\xa0». Dans ce travail, nous abordons le problème dans un environnement multilingue où un seul modèle NMT traduit à partir de plusieurs langues pour un traitement automatique en aval dans la langue cible. Le partage de connaissances dans des langues proches et distantes permet d'appliquer notre approche orientée machine dans le cadre du zéro tir où aucune donnée étiquetée pour la langue du test n'est visible au moment de la formation. De plus, nous intégrons le BERT multilingue dans la partie source de notre système NMT afin de bénéficier des connaissances intégrées dans ce modèle. Nos expériences montrent des gains de performance cohérents, pour différentes directions linguistiques, à la fois sur i) des modèles NMT «\xa0génériques\xa0» (formés pour la consommation humaine) et ii) un BERT multilingue affiné. Ce gain pour les directions de langue zéro plan (par exemple espagnol-anglais) est plus élevé lorsque les modèles sont affinés sur une langue source proche (italien) que sur une langue lointaine (allemand).", 'pt': 'Os modelos de tradução automática neural (NMT) são normalmente treinados considerando humanos como usuários finais e maximizando objetivos orientados para humanos. No entanto, em alguns cenários, sua saída é consumida por componentes automáticos de NLP e não por humanos. Nesses cenários, a qualidade das traduções é medida em termos de sua “adequação ao propósito” (ou seja, maximizar o desempenho de ferramentas externas de PNL) e não em termos de critérios humanos padrão de fluência/adequação. Recentemente, técnicas de aprendizado por reforço que exploram o feedback de ferramentas de PNL a jusante foram propostas para adaptação NMT “orientada por máquina”. Neste trabalho, abordamos o problema em uma configuração multilíngue, onde um único modelo NMT traduz de vários idiomas para processamento automático downstream no idioma de destino. O compartilhamento de conhecimento em linguagens próximas e distantes permite aplicar nossa abordagem orientada a máquina na configuração de tiro zero, onde nenhum dado rotulado para a linguagem de teste é visto no momento do treinamento. Além disso, incorporamos o BERT multilíngue no lado da fonte do nosso sistema NMT para nos beneficiarmos do conhecimento incorporado nesse modelo. Nossos experimentos mostram ganhos de desempenho coerentes, para diferentes direções linguísticas em relação a i) modelos NMT “genéricos” (treinados para consumo humano) e ii) BERT multilíngue ajustado. Esse ganho para direções de idioma de tiro zero (por exemplo, espanhol-inglês) é maior quando os modelos são ajustados em um idioma de origem intimamente relacionado (italiano) do que em um distante (alemão).', 'ja': 'ニューラル・マシン・トランスレーション（ NMT ）モデルは、典型的には、人間をエンドユーザーと見なし、人間指向の目標を最大化することによって訓練される。 しかし、いくつかのシナリオでは、それらの出力は人間ではなく自動NLPコンポーネントによって消費されます。 これらのシナリオでは、翻訳の品質は、標準的な人間の流暢性/妥当性基準ではなく、その「目的への適合性」（すなわち、外部NLPツールのパフォーマンスを最大化すること）の観点から測定されます。 最近、下流のNLPツールからのフィードバックを利用する強化学習技術が、「機械指向」のNMT適応のために提案されている。 この作業では、1つのNMTモデルが複数の言語から翻訳され、ターゲット言語でのダウンストリーム自動処理が可能な多言語環境で問題に取り組みます。 近い言語と遠い言語での知識共有により、トレーニング中にテスト言語のラベル付けされたデータが表示されないゼロショット設定で、機械指向のアプローチを適用できます。 さらに、このモデルに組み込まれた知識の恩恵を受けるために、NMTシステムのソース側に多言語のBERTを組み込んでいます。 当社の実験は、i ）「一般的な」NMTモデル（ヒトの消費のために訓練された）、およびii ）多言語BERTの微調整の両方で異なる言語方向について、一貫したパフォーマンスの向上を示しています。 ゼロショット言語方向（例えば、スペイン語-英語）のこの利得は、モデルが密接に関連するソース言語（イタリア語）で遠隔のもの（ドイツ語）よりも微調整されている場合に高くなります。', 'hi': 'न्यूरल मशीन ट्रांसलेशन (एनएमटी) मॉडल आमतौर पर मनुष्यों को अंतिम उपयोगकर्ताओं के रूप में विचार करके और मानव-उन्मुख उद्देश्यों को अधिकतम करके प्रशिक्षित किए जाते हैं। हालांकि, कुछ परिदृश्यों में, उनके आउटपुट को मनुष्यों के बजाय स्वचालित एनएलपी घटकों द्वारा उपभोग किया जाता है। इन परिदृश्यों में, अनुवाद की गुणवत्ता को मानक मानव प्रवाह / पर्याप्तता मानदंडों के संदर्भ में नहीं बल्कि उनके "उद्देश्य के लिए फिटनेस" (यानी बाहरी एनएलपी उपकरणों के प्रदर्शन को अधिकतम करने) के संदर्भ में मापा जाता है। हाल ही में, डाउनस्ट्रीम एनएलपी उपकरणों से प्रतिक्रिया का शोषण करने वाली सुदृढीकरण सीखने की तकनीकों को "मशीन-उन्मुख" एनएमटी अनुकूलन के लिए प्रस्तावित किया गया है। इस काम में, हम एक बहुभाषी सेटिंग में समस्या से निपटते हैं जहां एक एकल एनएमटी मॉडल लक्ष्य भाषा में डाउनस्ट्रीम स्वचालित प्रसंस्करण के लिए कई भाषाओं से अनुवाद करता है। करीबी और दूर की भाषाओं में ज्ञान साझा करण शून्य-शॉट सेटिंग में हमारे मशीन-उन्मुख दृष्टिकोण को लागू करने की अनुमति देता है जहां प्रशिक्षण के समय परीक्षण भाषा के लिए कोई लेबल डेटा नहीं देखा जाता है। इसके अलावा, हम इस मॉडल में एम्बेडेड ज्ञान से लाभ उठाने के लिए हमारे एनएमटी सिस्टम के स्रोत पक्ष में बहुभाषी BERT को शामिल करते हैं। हमारे प्रयोगों सुसंगत प्रदर्शन लाभ दिखाते हैं, दोनों पर विभिन्न भाषा दिशाओं के लिए i) "जेनेरिक" NMT मॉडल (मानव खपत के लिए प्रशिक्षित), और ii) ठीक ट्यून बहुभाषी BERT. शून्य-शॉट भाषा दिशाओं (जैसे स्पेनिश-अंग्रेजी) के लिए यह लाभ तब अधिक होता है जब मॉडल को दूर के एक (जर्मन) की तुलना में निकटता से संबंधित स्रोत भाषा (इतालवी) पर ठीक-ठाक किया जाता है।', 'zh': '神经机器翻译(NMT)模常以人为最终用户最大化向人而教之。 然其输自NLP组件而非人耗也。 若此者,译者因其适用性(最大化外NLP器之性)量也,非度人之流畅性/充分性量也。 近者,因下流NLP器反馈之强学,施于向机器之NMT。 多言而解之,其NMT多种语言译,以下自处也。 跨近与远言之知共许于零触发设中宜用向机器之法,于训练时不见测试语言标数。 此外NMT系统之源侧整合多言BERT,以从其形中嵌之益也。 吾实验见i)通用NMT(为人消息)与ii)微调者多言BERT异言者连贯而进。 当其源(意大利语)微调,零射语向(如西班牙语 - 英语)增益远语(德语)。', 'ru': 'Модели нейронного машинного перевода (НМП) обычно обучаются, рассматривая людей в качестве конечных пользователей и максимизируя цели, ориентированные на человека. Однако в некоторых сценариях их выход потребляется автоматическими компонентами NLP, а не людьми. В этих сценариях качество переводов измеряется с точки зрения их «пригодности к цели» (т.е. максимизации производительности внешних инструментов NLP), а не с точки зрения стандартных критериев беглости/адекватности персонала. Недавно для «машиноориентированной» адаптации НМТ были предложены методы обучения подкреплению, использующие обратную связь от инструментов NLP, находящихся ниже по потоку. В этой работе мы рассматриваем проблему в многоязычной среде, где одна модель NMT переводит с нескольких языков для последующей автоматической обработки на целевом языке. Обмен знаниями между близкими и удаленными языками позволяет применять наш машинно-ориентированный подход в настройке нулевого снимка, где во время обучения не видны помеченные данные для языка тестирования. Кроме того, мы включаем многоязычный BERT в исходную часть нашей системы NMT, чтобы извлечь выгоду из знаний, встроенных в эту модель. Наши эксперименты показывают согласованное повышение производительности для разных языковых направлений как i) «общих» моделей НМТ (обученных для потребления человеком), так и ii) тонко настроенного многоязычного BERT. Этот прирост для направлений с нулевым выстрелом (например, испанский-английский) выше, когда модели доработаны на близком родственном исходном языке (итальянском), чем на отдаленном (немецком).', 'ga': 'Is gnách go gcuirtear oiliúint ar mhúnlaí Neural Machine Translation (NMT) trí dhaoine a mheas mar úsáideoirí deiridh agus trí chuspóirí atá dírithe ar an duine a uasmhéadú. I gcásanna áirithe, áfach, is iad comhpháirteanna uathoibríocha NLP seachas daoine a ídíonn a n-aschur. Sna cásanna seo, déantar cáilíocht na n-aistriúchán a thomhas i dtéarmaí a “oiriúnachta don fheidhm” (i.e. feidhmíocht uirlisí seachtracha NLP a uasmhéadú) seachas i dtéarmaí critéar caighdeánach líofachta/leorgachta daonna. Le déanaí, moladh teicnící foghlama treisithe a bhaineann leas as aiseolas ó uirlisí NLP iartheachtacha le haghaidh oiriúnú NMT atá “dírithe ar mheaisín”. San obair seo, téimid i ngleic leis an bhfadhb i suíomh ilteangach ina aistrítear samhail NMT amháin ó iltheangacha le haghaidh próiseála uathoibríoch iartheachtacha sa sprioctheanga. Ligeann comhroinnt eolais thar theangacha cóngaracha agus i gcéin ár gcur chuige meaisín-dhírithe a chur i bhfeidhm sa socrú náid lámhaigh nuair nach bhfeictear aon sonraí lipéadaithe don teanga tástála ag am oiliúna. Ina theannta sin, ionchorpraímid BERT ilteangach ar thaobh foinse ár gcóras NMT chun leas a bhaint as an eolas atá leabaithe sa mhúnla seo. Léiríonn ár dturgnaimh gnóthachain chomhleanúnacha feidhmíochta, do threoracha teanga difriúla thar an dá i) samhlacha “cineálacha” NMT (oilte mar bhia don duine), agus ii) BERT ilteangach mionchoigeartaithe. Tá an gnóthachan seo do threoracha teanga nialasacha (m.sh. Spáinnis–Béarla) níos airde nuair a dhéantar mionchoigeartú ar na samhlacha ar theanga fhoinseach a bhfuil dlúthbhaint aici (Iodáilis) ná ar cheann i bhfad i gcéin (Gearmáinis).', 'ka': "ნეიროლური მაქსინის გასაგრძელება (NMT) მოდელები ტიპოლურად იყოს ადამიანებს საკუთარი მომხმარებელი და ადამიანის განსაგრძელებული მიზეზების მაქსიმიზაცია. მაგრამ, რამდენიმე სინარიოში, მათი გამოყენება ავტომატური NLP კომპონენტებით გამოყენება ადამიანებისგან არა. ამ სინარიოში, გადაწყვეტილებების საფუძველი სინარიოში იქნება მისი 'საფუძველი სინართვის' (მაგალითად, გარეშე NLP ხელსაწყოთა სინართვის მაქსიმიკეთება) მაგალითად ადამიანის სინართვის/საკუთარი მიმდინარე, NLP ხელსაწყობილობის გამოყენება განსწავლების ტექნოგიები, რომლებიც გამოიყენებენ გამოყენება NMT მონაცემებისთვის. ამ სამუშაოში, ჩვენ მრავალენგური განსაზღვრებში პრობლემა გადაწყენებთ, სადაც ერთი NMT მოდელი მრავალენ ენებიდან ავტომატიკური პროცესისთვის მიმდინარე ენაში. მეცნიერების გაყოფილი ბრძანებული და გარეშე ენაში შესაძლებელია ჩვენი მანქინის ორიენტირებული პროგრამის გამოყენება ნულ სტატის შესაძლებელად, სადაც ტესტის ენაზე არ მონიშნული მონა დამატებით, ჩვენ მრავალენგური BERT-ს ჩვენი NMT სისტემის მსოფლიო მხარეს დავყენებთ, რომ ამ მოდელში ჩვენი ცნობიდან გამოიყენება. ჩვენი ექსპერიმენტები აჩვენებენ შესაძლებელი პროცემენტები, განსხვავებული ენერგიის მიღებებისთვის i) 'განსხვავებული' NMT მოდელები (ადამიანის გამოყენება) და ii) განსხვავებული მრავალური ბერტი ეს პრობლემა, როდესაც მოდელები მხოლოდ დაკავშირებული მსოფლიო ენაზე (თრალიანური) უფრო მეტია, როდესაც მოდელები უფრო მეტი დაკავშირებული მსოფლიო ენაზე (თრალიანური) უფრო", 'hu': 'A Neural Machine Translation (NMT) modelleket általában úgy képezik, hogy az embereket végfelhasználóként tekintik, és maximalizálják az emberi orientált célokat. Egyes forgatókönyvekben azonban a kibocsátásukat az automatikus NLP komponensek fogyasztják el, nem pedig az emberek. Ezekben a forgatókönyvekben a fordítások minőségét a "célra való alkalmasságuk" (azaz a külső NLP-eszközök teljesítményének maximalizálása) alapján mérik, nem pedig a szokásos emberi folyékonysági/megfelelőségi kritériumok alapján. Az utóbbi időben javasoltak erősítési tanulási technikákat, amelyek kihasználják a downstream NLP eszközök visszajelzéseit a "gépi orientált" NMT adaptációhoz. Ebben a munkában egy többnyelvű környezetben kezeljük a problémát, ahol egyetlen NMT modell több nyelvről fordít le automatikus feldolgozásra a célnyelven. A közeli és távoli nyelveken történő tudásmegosztás lehetővé teszi gépi orientált megközelítésünk alkalmazását a nulla lövés beállításban, ahol a tesztnyelvre vonatkozó címkézett adatok nem láthatók az edzés időpontjában. Ezenkívül NMT rendszerünk forrásoldalába beépítjük a többnyelvű BERT-t, hogy kihasználjuk az ebben a modellben beágyazott ismereteket. Kísérleteink következetes teljesítménynövekedést mutatnak, különböző nyelvi irányok tekintetében mind az i) "általános" NMT modellek (emberi fogyasztásra képzett), mind a ii) finomhangolt többnyelvű BERT modellek esetében. Ez a nyereség a nulla-shot nyelvi irányok (pl. spanyol-angol) esetében nagyobb, ha a modelleket finomhangolják egy szorosan rokon forrásnyelven (olasz), mint egy távoli nyelven (német).', 'el': 'Τα μοντέλα νευρωνικής μηχανικής μετάφρασης (ΜΜΤ) εκπαιδεύονται συνήθως λαμβάνοντας υπόψη τους ανθρώπους ως τελικούς χρήστες και μεγιστοποιώντας τους στόχους προσανατολισμένους στον άνθρωπο. Ωστόσο, σε ορισμένα σενάρια, η παραγωγή τους καταναλώνεται από αυτόματα συστατικά και όχι από ανθρώπους. Σε αυτά τα σενάρια, η ποιότητα των μεταφράσεων μετράται με βάση την "καταλληλότητά τους για τον σκοπό" (δηλαδή τη μεγιστοποίηση της απόδοσης των εξωτερικών εργαλείων NLP) και όχι με βάση τα τυποποιημένα κριτήρια ανθρώπινης ρευστότητας/επάρκειας. Πρόσφατα, έχουν προταθεί τεχνικές ενίσχυσης μάθησης που αξιοποιούν την ανατροφοδότηση από μεταγενέστερα εργαλεία NLP για την προσαρμογή των NMT με προσανατολισμό στη μηχανή. Στην εργασία αυτή, αντιμετωπίζουμε το πρόβλημα σε ένα πολύγλωσσο περιβάλλον όπου ένα μοντέλο μεταφράζεται από πολλές γλώσσες για μεταγενέστερη αυτόματη επεξεργασία στη γλώσσα-στόχο. Η ανταλλαγή γνώσεων σε κοντινές και μακρινές γλώσσες επιτρέπει την εφαρμογή της μηχανολογικής προσέγγισής μας στη ρύθμιση μηδενικού πυροβολισμού, όπου δεν φαίνονται δεδομένα με ετικέτα για τη γλώσσα δοκιμής κατά τη διάρκεια της εκπαίδευσης. Επιπλέον, ενσωματώνουμε την πολυγλωσσική πλευρά του συστήματος μας για να επωφεληθούμε από τη γνώση που ενσωματώνεται σε αυτό το μοντέλο. Τα πειράματά μας δείχνουν συνεκτικά κέρδη απόδοσης, για διαφορετικές γλωσσικές κατευθύνσεις και για τα δύο "γενικά" μοντέλα NMT (εκπαιδευμένα για ανθρώπινη κατανάλωση), και ii) το εκλεπτυσμένο πολυγλωσσικό BERT. Αυτό το κέρδος για γλωσσικές κατευθύνσεις μηδενικής λήψης (π.χ. ισπανικά-αγγλικά) είναι υψηλότερο όταν τα μοντέλα είναι συντονισμένα σε μια στενά συνδεδεμένη γλώσσα προέλευσης (ιταλικά) από μια μακρινή (γερμανικά).', 'it': 'I modelli NMT (Neural Machine Translation) sono tipicamente formati considerando gli esseri umani come utenti finali e massimizzando gli obiettivi orientati all\'uomo. Tuttavia, in alcuni scenari, la loro produzione è consumata da componenti automatici NLP piuttosto che da esseri umani. In questi scenari, la qualità delle traduzioni viene misurata in termini di "idoneità allo scopo" (cioè massimizzando le prestazioni degli strumenti esterni di PNL) piuttosto che in termini di criteri standard di fluidità/adeguatezza umana. Recentemente, sono state proposte tecniche di apprendimento di rinforzo che sfruttano il feedback degli strumenti NLP a valle per l\'adattamento NMT "orientato alle macchine". In questo lavoro affrontiamo il problema in un ambiente multilingue in cui un singolo modello NMT traduce da più lingue per l\'elaborazione automatica a valle nella lingua di destinazione. La condivisione delle conoscenze in lingue vicine e lontane consente di applicare il nostro approccio orientato alla macchina nell\'impostazione zero-shot dove non vengono visualizzati dati etichettati per la lingua di prova durante l\'allenamento. Inoltre, incorporamo BERT multilingue nel lato sorgente del nostro sistema NMT per beneficiare delle conoscenze incorporate in questo modello. I nostri esperimenti mostrano miglioramenti di performance coerenti, per diverse direzioni linguistiche sia su i) modelli NMT "generici" (addestrati per il consumo umano), sia su ii) BERT multilingue perfezionato. Questo guadagno per le direzioni linguistiche zero-shot (ad esempio spagnolo-inglese) è maggiore quando i modelli sono perfezionati su una lingua sorgente strettamente correlata (italiano) rispetto a una lontana (tedesco).', 'kk': "Нейрондық машинаның аударуы (NMT) моделдері адамдарды соңғы пайдаланушылар ретінде және адамдардың бағытталған мақсаттарын кең жаю үшін оқылған. Бірақ кейбір сценарияларда, олардың шығысы адамдардың орнына автоматты NLP компоненттері қолданылады. Бұл сценарияларда, аудармалардың сапасы, стандартты адамдардың жылдамдылығы/адамдық критерияларының қасиетіне (яғни, сыртқы NLP құрылғыларының ықтималдығын шектеу) қасиетінде өлшеміледі. Жуырда NLP құралдарының қайталануын қолданатын үйрену техникаларын жақсарту үшін 'machine-oriented' NMT адаптациясы үшін қолданылады. Бұл жұмыс ішінде, бірнеше тілді NMT үлгісін бірнеше тілден автоматты түрде өзгерту үшін бірнеше тілден аударып жатқан мәселеді бірнеше тілде айналдырамыз. Жақын және қашықтағы тілдерде білім ортақтастыруға мүмкіндік береді. Сынақ тілдерінің жарлық деректері оқыту уақытында көрсетілмеген механизміміздің бағытталған түрімізді нөл- шот Қосымша, біз NMT жүйесіміздің көп тілді BERT-ті бұл үлгінде ендірілген білімдердің көпшілігін қосу үшін бірнеше тілді BERT-ті біріктіреміз. Біздің тәжірибелеріміз көптеген тіл бағыттарына (i) 'generic' NMT моделдері (адам пайдалану үшін оқылған) және ii) көптеген бірнеше тіл бағыттарына сәйкес жеткізу үшін көрсетеді. Бұл нөл түрлі тіл бағыттарының (мысалы, Испан- ағылшын) үлгілері жақын түрлі көзінің тіліне (итальян) қашықтығынан (неміс) қашықтығынан артық түрленгенде жоғары болады.", 'mk': 'Моделите на неврална машина (НМТ) се обично обучени со разгледување на луѓето како крајни корисници и максимализација на човечки ориентирани цели. Сепак, во некои сценарија, нивниот излез е конзумиран од автоматски компоненти на НЛП наместо од луѓе. Во овие сценарија, квалитетот на преведувањата се мери во однос на нивната „способност за цел“ (т.е. максимизирање на резултатите на надворешните НЛП алатки) наместо во однос на стандардните критериуми за човечка течност/соодветност. Неодамна се предложени зајакнувачки техники на учење кои ги искористуваат реакциите од понатамошните алатки на НЛП за „машинско ориентирана“ адаптација на НМТ. Во оваа работа, го решаваме проблемот во мултијазичко поставување каде еден модел на НМТ се преведува од повеќе јазици за автоматско процесирање во потекло на јазикот на целта. Соделувањето на знаење преку блиски и далечни јазици овозможува да се примени нашиот машински ориентиран пристап во поставувањето со нула снимка каде што не се гледаат означени податоци за тестираниот јазик во време на тренингот. Покрај тоа, вклучуваме мултијазичен БЕРТ во изворот на нашиот НМТ систем за да користиме од знаењето вградено во овој модел. Нашите експерименти покажуваат кохерентни постигнувања на резултатите, за различни јазички насоки во однос на и) „генерични“ НМТ модели (обучени за човечка потрошувачка), и i i) фино прилагодени мултијазични БЕРТ. Овој придобивка за нула-снимки јазички насоки (на пример шпанско-англиски) е повисока кога моделите се финетизирани на блиски поврзан извор јазик (италијански) отколку на далечен (германски).', 'ms': "Model Penerjemahan Mesin Neural (NMT) biasanya dilatih dengan mempertimbangkan manusia sebagai pengguna-akhir dan maksimumkan sasaran-orientasi manusia. However, in some scenarios, their output is consumed by automatic NLP components rather than by humans.  Dalam skenario in i, kualiti terjemahan' diukur dalam terma 'fitness for purpose' (i.e. maksimumkan prestasi alat NLP luaran) daripada dalam terma kriteria keseluruhan/keperluan manusia piawai. Baru-baru ini, teknik pembelajaran kuasa yang mengeksploitasi balas balik dari alat NLP turun telah diusulkan untuk penyesuaian NMT 'orientasi mesin'. Dalam kerja ini, kita menangani masalah dalam tetapan berbilang bahasa di mana model NMT tunggal diterjemahkan dari berbilang bahasa untuk pemprosesan automatik turun dalam bahasa sasaran. Perkongsian pengetahuan melalui bahasa yang dekat dan jauh membenarkan untuk melaksanakan pendekatan orientasi mesin kami dalam tetapan tembakan sifar di mana tiada data yang ditanda untuk bahasa ujian dilihat pada masa latihan. Selain itu, kami memasukkan BERT berbilang-bahasa di sisi sumber sistem NMT kami untuk mengambil manfaat dari pengetahuan yang terkandung dalam model ini. Eksperimen kami menunjukkan keuntungan prestasi yang konsisten, untuk arah bahasa yang berbeza atas kedua-dua i) 'generic' model NMT (dilatih untuk konsumsi manusia), dan ii) BERT berbilang bahasa yang sesuai. Gagal ini untuk arah bahasa-tembakan sifar (cth. Bahasa Sepanyol-Inggeris) lebih tinggi bila model disesuaikan dengan baik pada bahasa sumber yang berkaitan rapat (Itali) daripada bahasa yang jauh (Jerman).", 'ml': "ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ (NMT) മോഡലുകള്\u200d സാധാരണ പരിശീലിക്കപ്പെടുന്നു. മനുഷ്യരെ അവസാന ഉപയോക്താക്കളായി വിചാരിക്കുന്നതും മനുഷ്യന് എന്നാലും, ചില സിനേരിയോസില്\u200d അവരുടെ പുറപ്പെട്ട് മനുഷ്യരുടെ കൂട്ടത്തിന് പകരം സ്വയമായി NLP ഘടകങ്ങള്\u200d ഉപയോഗിക് In these scenarios, translations' quality is measured in terms of their 'fitness for purpose' (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency/adequacy criteria.  അടുത്തിടെ NLP ഉപകരണങ്ങളില്\u200d നിന്നുള്ള ഫിബിബ്ബാക്ക് ഉപയോഗിക്കുന്ന പഠിക്കുന്ന സാങ്കേതികവിദ്യകള്\u200d പ്രാവര്\u200dത്തിപ്പിക്കുന്നത് 'എ ഈ ജോലിയില്\u200d നമ്മള്\u200d പല ഭാഷ ക്രമീകരണങ്ങളില്\u200d പ്രശ്നത്തെ പരിഹരിക്കുന്നു. അവിടെ ഒരു NMT മോഡല്\u200d പല ഭാഷകളില്\u200d നിന്നും അധികമായ ഭാഷകളില്\u200d നിന് വിജ്ഞാനം അടുത്തുള്ള ഭാഷകളില്\u200d പങ്കുചേര്\u200dക്കുന്നതും ദൂരെയുള്ള ഭാഷകളില്\u200d പങ്കുചേര്\u200dക്കുന്നതും പരീക്ഷ സമയത്ത് പരീക്ഷ വിവരങ്ങള്\u200dക്ക്  അതുകൊണ്ടും, നമ്മുടെ NMT സിസ്റ്റത്തിന്റെ സ്രോതസ്സിന്റെ സ്രോതസ്സില്\u200d ഞങ്ങള്\u200d പല ഭാഷ ബെര്\u200dട്ടിയില്\u200d ചേര്\u200dക്കുന്നു. ഈ മോഡ നമ്മുടെ പരീക്ഷണങ്ങള്\u200d രണ്ടുപേര്\u200dക്കും വ്യത്യസ്ത ഭാഷയുടെ മാര്\u200dഗങ്ങള്\u200dക്ക് കാണിച്ചുകൊടുക്കുന്നു. സാധാരണമായ NMT മോഡലുകള്\u200dക്ക് (മനുഷ്യര്\u200d ഭക്ഷണ This gain for zero-shot language directions (e.g. Spanish-English) is higher when the models are fine-tuned on a closely-related source language (Italian) than a distant one (German).", 'lt': 'Neural Machine Translation (NMT) models are typically trained by considering humans as end-users and maximizing human-oriented objectives.  Tačiau kai kuriais scenarijais jų produkciją suvartoja ne žmonės, o automatiniai NLP komponentai. Šiais scenarijais vertimo kokybė vertinama atsižvelgiant į „tinkamumą tikslui“ (t. y. i šorinių NLP priemonių veiksmingumo didinimą), o ne į standartinius žmogaus lankstumo ir (arba) tinkamumo kriterijus. Neseniai pasiūlyta stiprinti mokymosi metodus, naudojančius tolesnių NLP priemonių grįžtamąją informaciją, kad būtų galima pritaikyti prie „mašinų orientuoto“ NMT. Šiame darbe sprendžiame problem ą daugiakalbėje aplinkoje, kurioje vienas NMT modelis išverstas iš daugelio kalbų, skirtų tolesniam automatiniam apdorojimui tiksline kalba. Knowledge sharing across close and distant languages allows to apply our machine-oriented approach in the zero-shot setting where no labeled data for the test language is seen at training time.  Be to, į mūsų NMT sistemos šaltinį įtraukiame daugiakalbį BERT, kad gautume naudos iš šiame modelyje įtvirtintų žinių. Mūsų eksperimentai rodo nuoseklų rezultatų pagerėjimą skirtingomis kalbų kryptimis, palyginti su i) "generiniais" NMT modeliais (apmokytais vartoti žmones), ir ii) patobulintais daugiakalbiais BERT. Šis nulinės nuotraukos kalbos krypčių (pvz., ispanų ir anglų kalbos) padidėjimas yra didesnis, kai modeliai yra tiksliai pritaikyti glaudžiai susijusia šaltinio kalba (italų) nei tolima (vokiečių kalba).', 'mt': "Il-mudelli tat-Traduzzjoni tal-Magni Newrali (NMT) huma tipikament imħarrġa billi l-bnedmin jitqiesu bħala utenti finali u jimmassimizzaw l-għanijiet orjentati lejn il-bniedem. Madankollu, f’xi xenarji, il-produzzjoni tagħhom hija kkunsmata minn komponenti awtomatiċi NLP aktar milli mill-bnedmin. F’dawn ix-xenarji, il-kwalità tat-traduzzjonijiet titkejjel f’termini tal-“idoneità għall-iskop” tagħhom (jiġifieri l-massimizzazzjoni tal-prestazzjoni tal-għodod esterni tal-NLP) aktar milli f’termini ta’ kriterji standard ta’ fluwenza/adegwatezza umana. Dan l-aħħar, ġew proposti tekniki ta’ tagħlim ta’ rinfurzar li jisfruttaw ir-reazzjonijiet minn għodod NLP downstream għall-adattament NMT ‘orjentat lejn il-magni’. F’dan ix-xogħol, nindirizzaw il-problem a f’ambjent multilingwi fejn mudell wieħed ta’ NMT jittraduċi minn diversi lingwi għall-ipproċessar awtomatiku downstream fil-lingwa fil-mira. Il-qsim tal-għarfien f’lingwi mill-qrib u distanti jippermetti li jiġi applikat l-approċċ tagħna orjentat lejn il-magna fl-issettjar b’zero shot fejn ma tidher l-ebda dejta ttikkettata għall-lingwa tat-test fil-ħin tat-taħriġ. Barra minn hekk, inkorporajna BERT multilingwi fin-naħa tas-sors tas-sistema NMT tagħna biex nibbenefikaw mill-għarfien inkorporat f’dan il-mudell. Our experiments show coherent performance gains, for different language directions over both i) 'generic' NMT models (trained for human consumption), and ii) fine-tuned multilingual BERT.  Dan il-qligħ g ħal direzzjonijiet lingwistiċi b’zero-shot (pereżempju Spanjol-Ingliż) huwa ogħla meta l-mudelli jkunu rfini fuq lingwa tas-sors relatata mill-qrib (Taljana) minn lingwa distanti (Ġermaniża).", 'mn': "Ньюрал машины хөгжүүлэлт (NMT) загварууд нь хүмүүсийг төгсгөл хэрэглэгчид болон хүн төрөлхтний ориентирогдсон зорилго гэж бодож байдаг. Гэвч зарим хувилбарууд нь хүн төрөлхтний оронд автоматик NLP компонентүүд ашигладаг. Эдгээр хувилбаруудын хувилбарууд нь хүн төрөлхтний шингэнт/адилхан шаардлагатай хувилбаруудыг хамгийн их хэмжээнд хэмжээгддэг. Сүүлийн үед NLP хэрэгслээс хариултыг ашиглан суралцах техникуудыг нэмэгдүүлэх боломжтой болсон. Энэ ажлын тулд бид олон хэл хэлний тодорхойлолтын асуудлыг олон хэлний тодорхойлдог. НMT загвар нь олон хэлээс автоматик үйлдвэрлэлийн тулд зориулагдсан хэлээс орчуулагддаг. Мэдлэгийг ойрхон, холын хэл дээр хуваалцах нь бидний машины ориентирован арга зам нь шалгалтын хэл дээр ямар ч нэрлэгдсэн өгөгдлийг сургалтын цаг үед харагдахгүй байх боломжтой. Мөн бид NMT системийн эх үүсвэрийн талд олон хэлний BERT-г энэ загвар дээр нэмсэн мэдлэгийг ашиглах боломжтой болгодог. Бидний туршилтууд хоёуланг ижил хэлний даалгаврыг харуулж байна. i) 'ерөнхий' NMT загварууд (хүний хэрэглээнд сургалтын тулд сургалтын) болон ii) олон хэлний BERT-г тодорхойлдог. Энэ загвар нь ойролцоогоор харьцуулсан эх үүсвэртэй хэл (Италиан) дээр алсын хэлээс илүү өндөр байдаг.", 'pl': 'Modele neuronowego tłumaczenia maszynowego (NMT) są zazwyczaj trenowane przez uważanie ludzi za użytkowników końcowych i maksymalizację celów zorientowanych na człowieka. Jednak w niektórych scenariuszach ich wyjście jest zużywane przez automatyczne komponenty NLP, a nie przez ludzi. W tych scenariuszach jakość tłumaczeń mierzona jest raczej pod względem ich "przydatności do celu" (tj. maksymalizacji wydajności zewnętrznych narzędzi NLP), a nie pod względem standardowych kryteriów ludzkiej płynności/adekwatności. W ostatnim czasie proponowano techniki uczenia się wzmacniające wykorzystujące informacje zwrotne pochodzące z dalszych narzędzi NLP do adaptacji NMT "zorientowanej maszynowo". W niniejszej pracy podejmujemy problem w otoczeniu wielojęzycznym, w którym pojedynczy model NMT tłumaczy z wielu języków do dalszego automatycznego przetwarzania w języku docelowym. Dzielenie się wiedzą między bliskimi i odległymi językami pozwala na zastosowanie naszego podejścia zorientowanego na maszynę w ustawieniu zero-shot, gdzie nie widać żadnych oznakowanych danych dla języka testowego w czasie szkolenia. Ponadto włączamy wielojęzyczny BERT w stronę źródłową naszego systemu NMT, aby korzystać z wiedzy wbudowanej w ten model. Nasze eksperymenty wykazują spójny wzrost wydajności dla różnych kierunków językowych zarówno w i) "ogólnych" modelach NMT (przeszkolonych do spożycia przez ludzi), jak i ii) dostrojonych wielojęzycznych BERT. Wzrost ten dla kierunków językowych zero-shot (np. hiszpańsko-angielski) jest wyższy, gdy modele są dostrojone na blisko powiązanym języku źródłowym (włoski) niż na odległym (niemieckim).', 'ro': 'Modelele Neural Machine Translation (NMT) sunt de obicei instruite prin considerarea oamenilor ca utilizatori finali și maximizarea obiectivelor orientate spre om. Cu toate acestea, în unele scenarii, producția lor este consumată de componentele automate NLP mai degrabă decât de oameni. În aceste scenarii, calitatea traducerilor este măsurată în termeni de "adecvare pentru scop" (adică maximizarea performanței instrumentelor externe ale PNL) mai degrabă decât în termeni de criterii standard de fluență/adecvare a oamenilor. Recent, au fost propuse tehnici de învățare de consolidare care exploatează feedback-ul de la instrumentele PNL din aval pentru adaptarea NMT "orientată spre mașini". În această lucrare, abordăm problema într-un cadru multilingv în care un singur model NMT traduce din mai multe limbi pentru procesarea automată în aval în limba țintă. Schimbul de cunoștințe în limbi apropiate și îndepărtate permite aplicarea abordării noastre orientate spre mașină în setarea zero-shot, în cazul în care nu sunt văzute date etichetate pentru limba de testare în timpul antrenamentului. Mai mult decât atât, încorporăm BERT multilingv în partea sursă a sistemului nostru NMT pentru a beneficia de cunoștințele încorporate în acest model. Experimentele noastre arată câștiguri coerente de performanță, pentru direcții lingvistice diferite atât în cazul modelelor NMT "generice" (instruite pentru consumul uman), cât și în cazul modelelor BERT multilingve reglate fin. Acest câștig pentru direcțiile lingvistice zero-shot (de exemplu spaniolă-engleză) este mai mare atunci când modelele sunt reglate fin pe o limbă sursă strâns legată (italiană) decât una îndepărtată (germană).', 'no': "Neuralmaskineomsetjingsmodular (NMT) er vanlegvis trent ved å forstå menneske som sluttbrukarar og maksimerer menneskeorienterte mål. I noen scenario vert imidlertid utdata av automatiske NLP-komponentar brukt i staden for menneske. I disse scenarione målar omsetjingskvaliteten i uttrykket av «tilpassende for mål» (t.d. maksimering av uttrykket av eksterne NLP-verktøy) i staden for standardverdigheten for menneske/tilpassende kriterier. Nyleg har det forstått å styrke læringsteknikkar som brukar tilbakemeldingane frå nedtrekksverktøya NLP-verktøya for «maskineorientert» NMT-adaptasjon. I dette arbeidet løyser vi problemet i eit fleirspråk innstilling der ein enkel NMT-modell oversetter frå fleire språk for automatisk nedtrekking i målspråket. Kvitensdeling gjennom nær og distant språk kan bruka maskineorientert tilnærming våre i nullstiltinnstillinga der ingen merkelige data for testspråket vert vist ved treningstid. I tillegg inkluderer vi fleire språk BERT i kjeldesiden av NMT-systemet vår for å få nytte frå kunnskapen innebygd i denne modellen. Eksperimentane våre viser konsekvente utviklingar, for ulike språkkretningar over begge i) 'generic' NMT-modeller (treng for menneskelig bruk), og ii) fint fleirspråk BERT. Dette forståkinga for nullstilte språkkretningar (f.eks. spansk-engelsk) er høg are når modelane er finnstilligere på ein nær relatert kjeldespråk (italiansk) enn ein ekstern (tysk).", 'sr': 'Modeli neurološkog prevoda (NMT) tipično su obučeni smatrajući ljudima krajnjim korisnicima i maksimalizirajući ciljeve na ljudskom orijentaciju. Međutim, u nekim scenarijama, njihov proizvod koristi automatski komponenti NLP umjesto ljudi. U ovim scenarijama, kvalitet prevoda se mjera u smislu njihove "pristojnosti za svrhu" (t.i. maksimaliziranja učinkovitosti vanjskih NLP alata) nego u smislu standardnih kriterija ljudske tečnosti/adekvatnosti. Nedavno je predloženo pojačanje tehnika učenja koja iskorištavaju povratak iz snijeg NLP alata za adaptaciju NMT-a "mašinskom orijentacijom". U ovom poslu, rješavamo problem u multijezičkom postavljanju gde jedan model NMT prevodi iz višestrukih jezika za automatsku obradu na ciljnom jeziku. Podjela znanja na bliskim i daljinskim jezicima omogućava da primjenjuje naš pristup na mašinu u postavljanju nule snimke gde se u treningu ne viđaju nikakvi podaci označene za test jezik. Osim toga, uključujemo višejezičku BERT na izvornu stranu našeg NMT sistema kako bi koristili znanje uključene u ovaj model. Naši eksperimenti pokazuju saslužene dobitke učinkovitosti, za različite jezičke upute nad obje i) \'generične\' NMT modele (obučene za ljudsku potrošnju), i ii) ispravne multijezičke BERT. Ovaj dobitak za uputstvo na jezik bez pucnjave (npr. španjolski-engleski) je veći kada se modeli dobro uključuju na bliski izvorni jezik (italijanski) od udaljenog (njemačkog).', 'si': "මිනිස්සුන්ව අවසාන ප්\u200dරයෝජනය සහ මිනිස්සුන් ප්\u200dරයෝජනය සඳහා අවසාන ප්\u200dරයෝජනය විදියට පරික්ෂා කරනවා. නමුත්, සමහර විදිහට, ඔවුන්ගේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති මේ සීනාරියෝ වලින්, භාවිතය 'ක්\u200dරියාත්මක' ක්\u200dරියාත්මක විශේෂය අවශ්\u200dය වෙනුවෙන් ඔවුන්ගේ 'ක්\u200dරියාත්මක වෙනුවෙන්' (ඉතින්, බාරිය අලුත් වෙලාවෙන්, ප්\u200dරතිචාරය NLP උපකරණයෙන් ප්\u200dරයෝජනය කරලා ඉගෙන ගන්න ප්\u200dරයෝජනය සඳහා උපකරණය සඳහා උපකරණය කරන්න ප්\u200dරය මේ වැඩේ අපි ප්\u200dරශ්නයක් ගොඩක් භාෂාවක් සැකසුම් වලින් ප්\u200dරශ්නයක් හොයාගන්නවා, තියෙන එක NMT මොඩේල් එකක් භාෂාවල් ව Name තවත්, අපි බොහොම භාෂාවක් BERT එකතු කරනවා අපේ NMT පද්ධතියේ මුළු පැත්තේ මේ මොඩේල් එක්ක ඇතුළත් දන්නවට ප්\u200dරයෝජනය අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් සම්බන්ධ වැඩක් පුළුවන් වෙනස් භාෂාවක් විදිහට i) 'generic' NMT මොඩේල්ස් (මිනිස්සු භාවිතාවක්  මේක ශූන්ය-ශෝට් භාෂාව ප්\u200dරතිකාරයක් වෙනුවෙන් ප්\u200dරයෝජනය (ජෙර්මාන්-ඉංග්\u200dරීසියානු වලින්) වඩා වැඩියි, මොඩේල් ලඟ", 'so': "Tilmaamaha tarjumaadda ee Neural Machine (NMT) waxaa sida caadiga ah loo baraa dadka sida isticmaalayaal dhamaadka ah iyo waxyaabaha lagu kordhiyo dadka. Si kastaba ha ahaatee xaaladaha qaarkood waxyaabaha ay soo baxaan waxaa lagu isticmaalaa kooxaha maamaamulka ah ee NLP, taasoo ayan dadka u isticmaalin. Waxyaabahaas waxaa lagu qiyaasaa qiimaha turjumidda (taas oo lagu qiyaasaa qalabka dibadda e e NLP) iyadoo lagu qiyaasaa qiimaha ku habboon saxda ah ee adag/si saxda ah. Dhab ahaantii waxaa loo soo jeeday qalabka barashada oo lagu isticmaalayo dib u celinta qalabka NLP ee hoose laga soo jeedo qalabka 'machine-oriented' NMT. Shaqadan ayaan dhibaatada ku qabsanaynaa qoraalka luuqadaha kala duduwan, kaas oo midowga noocyada NMT ah laga turjumo luuqado kala duduwan oo ay ka baaraandegista iskaa-maamulka hoose ee webiga. Aqoonshaha la xiriira luqadaha dhow iyo meelaha fog waxay ku codsan karaan qaababka lagu hagayo marka lagu qoro qoraalka nooca ah oo aan lagu arag macluumaadka imtixaanka marka lagu tababaro. Moreover, we incorporate multi-lingual BERT in the source side of our NMT system to benefit from the knowledge embedded in this model.  Imtixaanadayada waxay muujiyaan faa'iido la xiriira waxyaabaha la sameeyo oo kala duduwan labada luuqadood ee `AMT' (tababar lagu baray isticmaalka dadka), i i) qaab badan oo luuqado kala duduwan ah BERT. Taasoo faa'iidada ku saabsan hagitaanka luqada nuurka ah (tusaale ahaan Isbanish-Ingiriis) waa ka sarreeyaa marka modellada lagu qoro afka noocyada ku dhow (Talyaani) waa ka fog (Jarmal).", 'sv': 'Neural Machine Translation (NMT) modeller utbildas vanligtvis genom att betrakta människor som slutanvändare och maximera människoorienterade mål. Men i vissa scenarier förbrukas deras produktion av automatiska NLP-komponenter snarare än av människor. I dessa scenarier mäts översättningarnas kvalitet i termer av deras ändamålsenliga lämplighet (dvs. maximera prestanda hos externa NLP-verktyg) snarare än i termer av standardkriterier för mänsklig flytande/tillräcklighet. Nyligen har förstärkningstekniker som utnyttjar återkopplingen från nedströms NLP-verktyg föreslagits för "maskinorienterad" NMT-anpassning. I detta arbete tar vi itu med problemet i en flerspråkig miljö där en enda NMT-modell översätter från flera språk för automatisk efterföljande bearbetning på målspråket. Kunskapsdelning på nära och avlägsna språk gör det möjligt att tillämpa vårt maskinorienterade tillvägagångssätt i nollskottsinställningen där inga märkta data för testspråket syns vid träningstillfället. Dessutom införlivar vi flerspråkig BERT i källsidan av vårt NMT-system för att dra nytta av den kunskap som ingår i denna modell. Våra experiment visar konsekventa prestationsvinster, för olika språkriktningar över både i) generiska NMT-modeller (utbildade för mänsklig konsumtion) och ii) finjusterade flerspråkiga BERT. Denna vinst för noll-shot språkriktningar (t.ex. spanska-engelska) är högre när modellerna är finjusterade på ett närbesläktat källspråk (italienska) än på ett avlägset språk (tyska).', 'ta': "நெருக்கி இயந்திரம் மொழிபெயர்ப்பு (NMT) மாதிரிகள் வழக்கமாக பயிற்சி செய்யப்படுகிறது மனிதர்களை முடிவு பயனராக கருதுவதால் மற்றும் மன ஆனால், சில காட்சிகளில், அவர்களுடைய வெளியீடு மனிதர்களை விட தானியங்கி NLP கூறுகளால் பயன்படுத்தப்படுகிறது. இந்த காட்சியில், மொழிபெயர்ப்பு' தரம் அவர்களுடைய 'விருப்பத்திற்கு' (அதாவது, வெளி NLP கருவிகளின் செயல்பாட்டை அதிகப்படுத்துகிறது) அண்மையில் NLP கருவிகளிலிருந்து பின்பற்றிய செயல்பாட்டை பயன்படுத்தும் படிக்கும் தொழில்நுட்பத்தை வலுப்படுத்தும் 'இயந்திரம் திருப்ப இந்த வேலையில், நாம் பல மொழிக்கு அமைப்பில் பிரச்சனையை நிர்ணயிக்கிறோம். இலக்கு மொழியில் ஒரு NMT மாதிரி மாதிரி பல மொழிகளிலிருந மூடிய மற்றும் தொலைதூர மொழிகளில் பகிர்ந்து அறிவு பயிற்சி நேரத்தில் சோதனை மொழிக்கு எதுவும் குறிப்பிட்ட தகவல்கள் பார்க்கவில்லை மேலும், இந்த மாதிரியில் உள்ள அறிவு பயன்படுத்தப்பட்டுள்ளது என்எம்டி அமைப்பின் மூல பக்கத்தில் நாம் பல மொழி பெர்ட் பிரெட்டை ச நம்முடைய சோதனைகள் சேர்ந்த செயல்பாட்டின் வெற்றியமைப்பை காட்டுகின்றன, இருவருக்கும் வேறு மொழி திசைகளுக்கு 'பொதுவான' NMT மாதிரிகள் (மனித சூழ்நிலைப்படுத்தப்பட்ட மொழி திசைகளுக்கு இந்த பெருக்கம் (உதாரணமாக ஸ்பானிஷ்- ஆங்கிலம்) மாதிரிகள் ஒரு சமீபத்தில் தொடர்புடைய மூல மொழி (இத்தாலி", 'ur': "نیورال ماشین ترجمہ (NMT) موڈل عام طور پر انسان کو آخر کارساز اور انسان کی اصلی موجودات کے مطابق مطابق سمجھنے سے آموزش کی جاتی ہیں. اگرچہ، بعض سیناریوں میں، ان کی آوٹ انسانوں کے بغیر اپنی NLP رقم سے کھایا جاتا ہے. یہ سناریوں میں، ترجمہ کا کیفیت ان کے 'مطابق کے لئے مطابق' کے مطابق اندازہ کیا جاتا ہے (یعنی باہر NLP ابزار کے عملہ کی مطابق مطابق) بغیر منظم انسان کی طبیعت/adequacy کریٹروں کے مطابق۔ اچھا، نیچے سٹریم NLP ابزار کے ذریعہ فیڈبک کے مطابق استعمال کرنے کے لئے استعمال کرنے کی تکنیک استعمال کیا گیا ہے. ہم اس کام میں مشکل کو بہت سی زبان تنظیمات میں حل کرتے ہیں جہاں ایک NMT موڈل بہت سی زبانوں سے ڈونسٹریم کی آٹوٹی پردازی کی زبان میں ترجمہ کرتا ہے۔ علم sharing close and distant languages allows to apply our machine-oriented approach in the zero-shot setting where no labeled data for the test language is seen at training time. اور ہم نے اپنے NMT سیسٹم کے سراسر جانب میں بہت سی زبان BERT کو اس مدل میں داخل ہوئے علم سے فائدہ پہنچایا۔ ہماری آزمائش ان دونوں کی مختلف زبان کی دکھانوں کے لئے ایک مہربانی فائدہ دکھاتی ہے۔ یہ صفر-شٹ کی زبان کی طرف سے فائدہ ہے (جیسے اسپانیایی-انگلیسی) جب مدلز ایک دور (جرمن) سے نزدیک ترین سورج زبان (ایتالیایی) سے بہت زیادہ مناسب ہیں۔", 'uz': 'Name Lekin, bir necha xil aniqlarida, ularning natijalari odamning o\'rniga avtomatik NLP komponentlari tomonidan foydalanadi. Ushbu scenarida, tarjima ma\'lumotlar qiymatini "maqsadga tayyorlash" darajada aniqlanadi. Recently, reinforcement learning techniques exploiting the feedback from downstream NLP tools have been proposed for “machine-oriented” NMT adaptation.  Bu ishda, biz bir necha tilda muammolarni boshqaramiz, bu yerda bir nechta NMT modeli bir nechta tillardan tarjima qiladi, bu tilda foydalanuvchi tilda avtomatik boshqarish uchun. Name Ko\'pchilik, biz bir necha tillar BERT tizimimizning manba tomoniga qo\'yib beramiz. Bu modeldagi ilma foydalanish uchun. Bizning tajribalarimiz bir necha tajriba muvaffaqiyatlarini ko\'rsatadi. Bu ikkita tildagi "generic" modellari (inson foydalanish uchun o\'xshash bo\'lgan va i i) bir necha tillar BERT kabi bir necha tilda. Name', 'vi': 'Mẫu dịch về máy thần kinh (NMB) thường được huấn luyện bằng cách xem con người là người dùng cuối cùng và tăng tối đa các mục tiêu hướng người. Tuy nhiên, trong một số viễn cảnh, kết quả của chúng được sử dụng bởi các thành phần NLP hơn là do con người. Trong các kịch bản này, chất lượng bản dịch được đo bằng độ "82;đủ tiêu chuẩn để đạt mục đích," "892; nói cách đạt tối đa khả năng tiêu chuẩn của công cụ NLP) hơn là dựa trên tiêu chuẩn tính chất lượng người. Gần đây, đã được đề nghị tăng cường kỹ thuật học khai thác các phản hồi từ các công cụ NLP trong nguồn cội. Trong công việc này, chúng ta giải quyết vấn đề trong một môi trường đa dạng, nơi một mô hình NMT độc lập dịch từ nhiều ngôn ngữ để xử lý tự động xuôi dòng trong ngôn ngữ đích. Sự chia sẻ tri thức qua các ngôn ngữ gần và xa cho phép áp dụng phương pháp hướng dẫn máy của chúng ta trong môi trường bắn không, nơi không có dữ liệu được dán nhãn cho ngôn ngữ thử nghiệm vào thời điểm tập luyện. Hơn nữa, chúng tôi đã áp dụng ALT ngôn ngữ rộng trong phần nguồn của hệ thống NMT để tận dụng kiến thức gắn liền với nó. Các thí nghiệm của chúng tôi cho thấy hiệu quả phù hợp, cho các hướng ngôn ngữ khác nhau trên cả 22. Giá trị này cho hướng ngôn ngữ không quay được (ví dụ như Tây Ban Nha).', 'bg': 'Моделите на невронния машинен превод (НМТ) обикновено се обучават, като се разглеждат хората като крайни потребители и се максимизират ориентираните към човека цели. Въпреки това, в някои сценарии тяхната продукция се консумира от автоматични компоненти на НЛП, а не от хора. В тези сценарии качеството на преводите се измерва по отношение на тяхната "годност за целта" (т.е. максимално представяне на външните инструменти за НЛП), а не по отношение на стандартните критерии за гъвкавост/адекватност на човека. Наскоро бяха предложени техники за обучение по укрепване, използващи обратната връзка от инструментите за НЛП надолу по веригата, за адаптиране на НЛП "машинно ориентирани". В тази работа се справяме с проблема в многоезична обстановка, при която един модел превежда от няколко езика за автоматична обработка надолу по веригата на целевия език. Споделянето на знания на близки и отдалечени езици позволява да се приложи нашия машинно ориентиран подход в настройката за нулев изстрел, където не се виждат етикетирани данни за езика на теста по време на обучение. Освен това, ние включваме многоезичен в източника на нашата система НМТ, за да се възползваме от знанията, вградени в този модел. Нашите експерименти показват съгласувано повишаване на производителността за различни езикови направления както при i) "генерични" модели на НМТ (обучени за консумация от човека), така и при фино настроени многоезични BERT. Тази печалба за нулеви езикови посоки (напр. испански-английски) е по-висока, когато моделите са фино настроени на тясно свързан език (италиански), отколкото далечен (немски).', 'nl': 'Neural Machine Translation (NMT) modellen worden meestal getraind door mensen als eindgebruikers te beschouwen en mensgerichte doelstellingen te maximaliseren. In sommige scenario\'s wordt hun output echter verbruikt door automatische NLP-componenten in plaats van door mensen. In deze scenario\'s wordt de kwaliteit van vertalingen gemeten in termen van hun \'geschiktheid voor het doel\' (d.w.z. maximalisering van de prestaties van externe NLP-tools) in plaats van in termen van standaard menselijke vloeibaarheid/adequaatheidscriteria. Onlangs zijn versterkingstechnieken voorgesteld die gebruikmaken van de feedback van downstream NLP-tools voor \'machine-georiënteerde\' NMT-aanpassing. In dit werk pakken we het probleem aan in een meertalige omgeving waar een enkel NMT-model uit meerdere talen vertaalt voor downstream automatische verwerking in de doeltaal. Kennisdeling tussen nabije en verre talen maakt het mogelijk om onze machine-georiënteerde aanpak toe te passen in de zero-shot instelling, waarbij tijdens de training geen gelabelde gegevens voor de testtaal worden gezien. Bovendien integreren we meertalige BERT in de bronzijde van ons NMT-systeem om te profiteren van de kennis die in dit model is ingebed. Onze experimenten tonen coherente prestatiewinsten, voor verschillende taalrichtingen over zowel i) "generieke" NMT-modellen (getraind voor menselijke consumptie), als ii) verfijnde meertalige BERT. Deze winst voor zero-shot taalrichtingen (bv. Spaans-Engels) is hoger wanneer de modellen zijn afgestemd op een nauw verwante brontaal (Italiaans) dan een verre (Duits).', 'hr': 'Modeli neurološkog prevoda (NMT) obično se obučavaju smatrajući ljudima krajnjim korisnicima i maksimalizirajući ciljeve orientirane na ljude. Međutim, u nekim scenarijama, njihov proizvod koristi automatski komponenti NLP umjesto ljudi. U ovim scenarijama kvalitet prevoda se mjera u smislu njihove "pristojnosti za svrhu" (tj. maksimaliziranja učinkovitosti vanjskih NLP alata) umjesto u smislu standardnih kriterija ljudske tečnosti/adekvatnosti. Nedavno je predloženo pojačanje tehnika učenja koja koristi povratak iz sniježnih NLP alata za adaptaciju NMT-a na stroj orientiranu. U ovom poslu rješavamo problem u multijezičkom postavljanju gdje jedan model NMT prevodi iz višestrukih jezika za automatsku obradu na ciljnom jeziku. Dijeljenje znanja na bliskim i daljinskim jezicima omogućava primjenjivati naš pristup na stroj orientiran na nulotvornoj postavci gdje u vrijeme obuke ne vidi označene podatke za test jezik. Osim toga, uključujemo višejezičku BERT na izvornu stranu našeg NMT sustava kako bi koristili znanje uključene u ovaj model. Naši eksperimenti pokazuju pristojne dobitke učinkovitosti, za različite jezičke upute nad obje i) \'generični\' NMT modeli (obučeni za ljudsku potrošnju), i ii) ispravne multijezičke BERT. Ovaj dobitak za uputstvo jezika bez pucnjave (npr. španjolski-engleski) je veći kada se modeli dobro uključuju na bliski izvorni jezik (italijanski) nego udaljeni (njemački).', 'ko': "신경기계번역(NMT) 모델은 보통 인간을 최종 사용자로 보고 인간을 대상으로 하는 목표를 극대화함으로써 훈련한다.그러나 어떤 장면에서는 출력이 인간이 소모하는 것이 아니라 자동 NLP 구성 요소에 의해 소모된다.이러한 장면에서 번역의 질은 그'목적적 적용성'(즉 외부 NLP 도구의 성능을 최대한 향상시키는 것)에 따라 평가되는 것이지 표준에 근거한 인류의 유창성/충분성 기준이 아니다.최근에는 다운스트림 NLP 도구 피드백을 활용한 강화된 학습 기술이'머신지향'NMT 적응에 활용될 것으로 제시됐다.이 작업에서 우리는 다중 언어 환경에서 이 문제를 해결했다. 그 중 하나의 NMT 모델은 여러 언어에서 번역되어 목표 언어에서 하류 자동 처리를 하도록 한다.근거리와 원거리 언어 간의 지식 공유를 통해 우리는 기계를 대상으로 하는 방법을 제로 트리거 설정에 응용할 수 있다. 이 설정에서 훈련할 때 테스트 언어의 표기 데이터를 볼 수 없다.또한 NMT 시스템의 원본에 다양한 언어의 BERT를 추가하여 이 모델에 포함된 지식을 얻을 수 있습니다.우리의 실험은 i)'통용'NMT 모델(인간 소비를 위한 훈련)과 ii)을 미세하게 조정한 다중 언어 BERT에서 서로 다른 언어 방향의 일치 성능이 향상되었다는 것을 나타냈다.이탈리아어의 방향(예:)이 이탈리아어의 방향(예:)보다 가까울 때 독일어의 방향(예:)이 이탈리아어의 방향(예:)보다 더 가깝다.", 'de': 'Neuronale Machine Translation (NMT)-Modelle werden typischerweise trainiert, indem Menschen als Endbenutzer betrachtet und menschenorientierte Ziele maximiert werden. In einigen Szenarien wird ihr Output jedoch von automatischen NLP-Komponenten anstatt von Menschen verbraucht. In diesen Szenarien wird die Qualität der Übersetzungen anhand ihrer Zweckmäßigkeit (d.h. Maximierung der Leistung externer NLP-Tools) gemessen und nicht anhand von Standard-Kriterien für die menschliche Fluency/Angemessenheit. Vor kurzem wurden Verstärkungslerntechniken vorgeschlagen, die das Feedback von nachgelagerten NLP-Werkzeugen nutzen, um eine "maschinenorientierte" NMT-Anpassung zu ermöglichen. In dieser Arbeit behandeln wir das Problem in einem mehrsprachigen Umfeld, in dem ein einziges NMT-Modell aus mehreren Sprachen übersetzt wird, um die automatische Verarbeitung in die Zielsprache zu ermöglichen. Der Wissensaustausch zwischen nahen und fernen Sprachen ermöglicht es, unseren maschinenorientierten Ansatz in der Null-Schuss-Einstellung anzuwenden, bei der zur Trainingszeit keine markierten Daten für die Testsprache angezeigt werden. Darüber hinaus integrieren wir mehrsprachiges BERT in die Quellseite unseres NMT-Systems, um von dem in diesem Modell eingebetteten Wissen zu profitieren. Unsere Experimente zeigen kohärente Leistungszuwächse für verschiedene Sprachrichtungen sowohl über i) "generische" NMT-Modelle (trainiert für den menschlichen Verzehr) als auch über ii) fein abgestimmte mehrsprachige BERT. Dieser Gewinn für Null-Schuss-Sprachrichtungen (z.B. Spanisch-Englisch) ist höher, wenn die Modelle auf eine eng verwandte Quellsprache (Italienisch) fein abgestimmt sind als auf eine entfernte (Deutsch).', 'da': 'Neural Machine Translation (NMT) modeller trænes typisk ved at betragte mennesker som slutbrugere og maksimere menneskeorienterede mål. Men i nogle scenarier forbruges deres output af automatiske NLP komponenter snarere end af mennesker. I disse scenarier måles oversættelseskvaliteten ud fra deres egnethed til formålet (dvs. maksimering af ydeevnen af eksterne NLP-værktøjer) snarere end standardkriterier for menneskelig flydenhed/tilstrækkelighed. For nylig er der foreslået forstærkningsteknikker, der udnytter feedback fra downstream NLP-værktøjer, til "maskinorienteret" NMT-tilpasning. I dette arbejde tackler vi problemet i en flersproget miljø, hvor en enkelt NMT-model oversætter fra flere sprog til downstream automatisk behandling på målsproget. Vidensdeling på tværs af tætte og fjerne sprog gør det muligt at anvende vores maskinorienterede tilgang i nulskudsindstillingen, hvor der ikke ses mærkede data for testsproget på træningstidspunktet. Desuden integrerer vi flersproget BERT i kildesiden af vores NMT-system for at drage fordel af den viden, der er indlejret i denne model. Vores eksperimenter viser sammenhængende præstationsgevinster for forskellige sprogretninger i forhold til både i) generiske NMT-modeller (uddannet til konsum) og ii) finjusteret flersproget BERT. Denne gevinst for nulskudssprogretninger (f.eks. spansk-engelsk) er højere, når modellerne er finjusteret på et nært beslægtet kildesprog (italiensk) end et fjernt sprog (tysk).', 'sw': "Mradi wa Tafsiri ya Mashine ya Kijerumani (NMT) hufundishwa kwa kawaida kwa kuzingatia binadamu kama watumiaji wa mwisho na kuongeza malengo yanayomilikiwa na binadamu. Hata hivyo, katika baadhi ya mitazamo, matokeo yao yanatumiwa na vifaa vya NLP binafsi badala ya binadamu. Katika mitazamo haya, tafsiri' ubora unapunguzwa kwa mujibu wa 'uhalali wa malengo' (yaani ufanisi wa vifaa vya NLP vya nje) badala ya kukingana na vigezo vya usawa wa binadamu. Recently, reinforcement learning techniques exploiting the feedback from downstream NLP tools have been proposed for 'machine-oriented' NMT adaptation.  Katika kazi hii, tunakabiliana na tatizo katika mazingira ya lugha mbalimbali ambapo model moja ya NMT inatafsiri kutoka lugha mbalimbali kwa upasuaji wa kujitegemea katika lugha inayolenga. Kusambaza maarifa katika lugha za karibu na mbali zinaruhusu kutumia mbinu zetu zinazoelekea mashine katika kituo chenye risasi ambapo hakuna taarifa zinazoonyesha kwa lugha ya kujaribu inaonekana wakati wa mafunzo. Moreover, we incorporate multi-lingual BERT in the source side of our NMT system to benefit from the knowledge embedded in this model.  Majaribio yetu yanaonyesha mafanikio ya utendaji wa pamoja, kwa maelekezo tofauti ya lugha mbalimbali kuhusu mifano ya NMT ya kawaida (imefundishwa kwa matumizi ya binadamu), na i i) yenye lugha mbalimbali ya BERT. Matokeo haya kwa maelekezo ya lugha zisizo na sifa (kwa mfano, Kihispania-Kiingereza) ni juu pale mifano inapovutiwa vizuri kwa lugha ya vyanzo vinavyohusiana na karibu zaidi (Kiitalia) kuliko moja ya mbali (Kijerumani).", 'tr': "Niral Makina Çeviri (NMT) modelleri insanları son-kullanıcılar olarak düşünerek ve insan yönündeki hedefleri büyüklenerek eğitiliyor. Ýöne käbir senarylarda, olaryň netijesi adamlaryň ýerine olaryň otomatik NLP komponentleri tarapyndan ullanýar. Bu senaryýalarda, terjime etmekleri 'maksadyň ýeterlirligi' (diýmek bolsa, daşarydaky NLP esbaplarynyň eserlerini) standart adam ýeterlik/ýeterlik kriteriýasynda ölçülýär. Soňky wagtlarda, NLP düşürmek isleýän öwrenmek teknikleri 'maşyny orient' NMT adaptasyonuň üçin ulanylar. Bu işde, bir NMT modeli birnäçe dilden a ňsatly işleýmek üçin mektup dilinde köp dillerde mesele çözýäris. Ýokary we uzak dillerde bilgi bölüşmeleri maşynyň gollanyşymyzy 0-resim düzeninde etmäge mümkin edýär. Bu ýerde test dilinde hiç hili etiket edilen maglumatlar görülmeýär. Mundan soňra, bu nusgada içine bolan bilimden fayda ýetirmek üçin NMT sistemimiziň çeşme tarapynda birnäçe dilli BERT'y birleşdirdik. Biziň deneylerimiz ýerleşýän täsirlerimizi görkezýär, her iki dilde döwletlere görkezýär i) 'jeneral' NMT nusgalary (adam consumek üçin bilinýär), we ii) köp dilli BERT düzümleşýän nusgalary üçin. Bu işi 0-atly dil g örnüşleri üçin (meselâ, espanyol-iňlisçe) örän nusgalar uzak bir dilde (nemesçe) gaty ýakyn bir çe şme dilinde (italiýa) düzülen bolsa ýokary.", 'af': "Neurale Masjien Vertaling (NMT) modele word tipies onderwerp deur mense as einde gebruikers te beskou en die maksimalisering van mensorienteerde objekte. Maar, in sommige scenarios, word hulle uitvoer gebruik deur outomatiese NLP komponente eerder as deur mense. In hierdie scenarios word vertalings 'kwaliteit' gemeet ingevolge van hul 'goederheid vir doel' (bv. maksimalisering van effektiviteit van eksterne NLP-nutsprogramme) eerder as ingevolge van standaard menslike fluiditeit/adekuasie kriteriërs. Onlangs is die versterking van onderstreem NLP-nutsprogramme voorgestel vir 'masjien-orienteerde' NMT-adaptasie. In hierdie werk is ons die probleem in 'n multitaalske opstelling waar 'n enkele NMT model vertaal van veelvuldige tale vir onderstreem automatiese verwerking in die doel taal. Kennis deel oor naby en afstand tale toelaat om ons masjien-orienteerde toegang in die nul-skoot instelling te wend waar geen etiketeerde data vir die toets taal is gesien by onderwerp tyd nie. Ook, ons inkorporeer multi-tale BERT in die bron kant van ons NMT stelsel om voordeel te bring van die kennis in hierdie model ingesluit. Ons eksperimente vertoon koherente prestasie verskaffing, vir verskillende taal rigtings oor beide i) 'generieke' NMT modele (opgelei vir menslike verbruik), en ii) fin-tuned multilinglike BERT. Hierdie verskaf vir nul-skoot taal rigtings (bv. Spaanse-Engels) is hoër wanneer die modele fin-tuned word op 'n naby-verwante bron taal (Italiese) as 'n afgeleë een (Duitse).", 'am': "የኔural Machine ትርጉም (NMT) ሞዴላዎች በጥያቄ ተጠቃሚዎች እና የሰው አቃላቢዎችን በመለጠፍ የተማሩ ናቸው፡፡ ምንም እንኳን በአንዳንዶች ስታይና ውጤታቸው ከሰው ይልቅ በአካባቢ የNLP ሰንሰቦች ይበላል፡፡ In these scenarios, translations' quality is measured in terms of their 'fitness for purpose' (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency/adequacy criteria.  በቅርብ ጊዜ ከNLP መሣሪያዎች የፊደል ጥያቄን በመጠቀም የመማር ተቃውሞ ለNMT ማሻሻሻል ተዘጋጅቷል፡፡ በዚህ ሥራ ውስጥ አንዱ የNMT ሞዴል በብዛት ቋንቋዎች ከታች ወደውኃው ውኃ በራሱ አካባቢ በቋንቋ ለመተላለፍ በሚለይ ቋንቋ እናስፈልጋለን፡፡ እውቀት በአቅራቢያ እና በሩቅ ቋንቋዎች ላይ ማሳየት የሆኑን መሳሪያችንን በ0-shot ማዘጋጀት ይፈቅዳል፡፡ ከዚህም ዓይነት ውስጥ ካደረገ እውቀት ለመጠቀም እናስጠጋለን፡፡ ፈተናዎቻችን ለልዩ ቋንቋዎች ግንኙነት እና ለልዩ ልዩ ቋንቋ ጠቃሚ የNMT ዓይነቶች (ለሰው መጠቀም ማቀናቀል) እና (i i) የተለየ ብልቋ ቋንቋ BERT ነው፡፡ ይህ ጥቅም ከሩቅ (ጀርመን) የተገኘ የቋንቋ ቋንቋ ቋንቋ ቋንቋ (የስፓኒሽ-እንግሊዘኛ) መግለጫ ከፍተኛ ነው፡፡", 'fa': 'مدلهای ترجمه ماشین عصبی (NMT) معمولاً با توجه به انسانها به عنوان کاربر پایان و بزرگترین هدف\u200cهای مستقیم انسان آموزش می\u200cشوند. ولی در بعضی سیناریو، نتیجه آنها توسط بخش\u200cهای NLP خودکار به جای انسان استفاده می\u200cشود. در این سناریو، کیفیت ترجمه\u200cها به عنوان «مناسب برای هدف» اندازه می\u200cگیرند (یعنی عملکرد ابزارهای NLP خارجی) به جای ترجمه\u200cهای سیستم\u200cهای مناسب/مناسب انسان استاندارد. تازگی، تکنیک یادگیری که استفاده می\u200cکند از ابزارهای NLP پایین استفاده می\u200cکند، برای تغییرات NMT «ماشین oriented» پیشنهاد داده شده است. در این کار، ما مشکل را در یک تنظیم بسیاری زبان حل می کنیم که یک مدل NMT از زبان بسیاری برای پرداخت اتوماتیک پایین سیستم در زبان هدف ترجمه می کند. تقسیم علم در زبانهای نزدیک و دور اجازه می دهد که دستور به ماشین oriented ما را در تنظیمات تصویر صفر استفاده کند که در زمان آموزش هیچ اطلاعاتی که برای زبان آزمایش برنامه ریزی شده نیست. علاوه بر این، ما BERT multi lingual را در سمت منبع سیستم NMT برای سودمندی از دانش در این مدل شروع کردیم. آزمایش\u200cهای ما به عنوان پیروزی عملکرد هماهنگ نشان می\u200cدهند، برای جهت\u200cهای زبان\u200cهای مختلف بر هر دو i) مدل NMT ژنرال (آموزش برای مصرف انسان) و (ii) BERT چندین زبان\u200cهای زیادی تنظیم شده. این پیروزی برای مسیرهای زبان صفر (مثال اسپانیایی-انگلیسی) بالاتر است وقتی مدلها به زبان منبع نزدیک (ایتالیایی) از یک زبان دور (آلمان) تنظیم می\u200cشوند.', 'id': "Model Neural Machine Translation (NMT) biasanya dilatih dengan mempertimbangkan manusia sebagai pengguna akhir dan memaksimalkan tujuan orientasi manusia. Namun, dalam beberapa skenario, output mereka dikonsumsi oleh komponen NLP otomatis daripada manusia. Dalam skenario in i, kualitas terjemahan' diukur dalam terma 'fitness for purpose' (i.e. maksimalkan prestasi alat NLP luar) daripada dalam terma standar fluency/adequacy criterion manusia. Baru-baru ini, teknik pembelajaran pemerintahan yang mengeksploitasi feedback dari alat NLP turun telah diusulkan untuk adaptasi NMT 'orient mesin'. In this work, we tackle the problem in a multilingual setting where a single NMT model translates from multiple languages for downstream automatic processing in the target language.  Pembahagian pengetahuan melalui bahasa yang dekat dan jauh memungkinkan untuk menerapkan pendekatan kita yang mengarientasi mesin dalam setting zero-shot dimana tidak ada data yang ditabel untuk bahasa ujian terlihat pada waktu latihan. Selain itu, kami memasukkan BERT berbagai bahasa di sisi sumber dari sistem NMT kami untuk mengambil manfaat dari pengetahuan yang terkandung dalam model ini. Eksperimen kami menunjukkan keuntungan prestasi yang konsisten, untuk arah bahasa yang berbeda di atas keduanya i) 'generic' model NMT (dilatih untuk konsumsi manusia), dan ii) fine-tuned berbeda bahasa BERT. Gagal ini untuk arah bahasa zero-shot (misalnya Bahasa Spanyol-Inggris) lebih tinggi ketika model tersebut disesuaikan dengan baik pada bahasa sumber yang terhubung dekat (Italia) daripada bahasa yang jauh (Jerman).", 'sq': "Modelet e Translacionit të Makinës Neurale (NMT) janë tipikisht të trajnuar duke konsideruar njerëzit si përdoruesit përfundimtarë dhe duke maksimizuar objektivat e orientuara ndaj njerëzve. Megjithatë, në disa skenarë, prodhimi i tyre konsumohet nga komponentet automatike të NLP në vend të njerëzve. In these scenarios, translations' quality is measured in terms of their 'fitness for purpose' (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency/adequacy criteria.  Kohët e fundit, janë propozuar teknikat e forcimit të mësimit që shfrytëzojnë feedback nga mjetet e NLP-së poshtë për përshtatjen 'të orientuar në makinë' në NMT. Në këtë punë, ne trajtojmë problem in në një ambient shumëgjuhës ku një model i vetëm NMT përkthehet nga gjuhë të shumëfishta për përpunimin automatik poshtë në gjuhën e objektivit. Ndryshimi i njohurive nëpërmjet gjuhëve të ngushta dhe të largëta lejon të aplikojë qasjen tonë të orientuar në makinë në rregullimin zero-shot ku nuk shihen të dhëna të etiketuara për gjuhën e testit në kohën e stërvitjes. Përveç kësaj, ne përfshijmë BERT shumëgjuhës në anën burimore të sistemit tonë NMT për të përfituar nga njohuria e përfshirë në këtë model. Eksperimentet tona tregojnë fitime koherente të performancës, për drejtime të ndryshme gjuhësh mbi të dy i) 'generic' modele NMT (të stërvitur për konsumin njerëzor) dhe ii) BERT shumë gjuhësh të përshtatshme. Ky fitim për drejtimet e gjuhës zero-shot (për shembull spanjoll-anglez) është më i lartë kur modelet janë të përshtatshëm në një gjuhë burimi (italiane) të afërt se një gjuhë të largët (gjermane).", 'bn': "নিউরেল মেশিন অনুবাদ (এনএমটি) মডেল সাধারণত মানুষের শেষ ব্যবহারকারীদের হিসেবে বিবেচনা করে এবং মানুষের দিকে সর্বোচ্চ উদ্দেশ্ তবে কিছু দৃশ্যের মধ্যে তাদের আউটপুট মানুষের পরিবর্তে স্বয়ংক্রিয়ভাবে এনএলপি সংক্রান্ত উপাদানের দ্বা এই দৃশ্যগুলোতে অনুবাদের মান পরিমাপ করা হচ্ছে তাদের 'উদ্দেশ্যের জন্য সুবিধা' (যেমন মানুষের স্বাভাবিক ফ্লাইসি/যথাযথ মূল্যের মাধ্যমে বাইরের এনএলপ সম্প্রতি এনএলপি টুল থেকে ফিডিব্যাক ব্যবহার করা শিক্ষা কৌশল বাড়িয়ে দেওয়ার প্রস্তাব প্রদান করা হয়েছে 'মেশিন-দৃষ্টিপূর্ণ' এনএমটি-এর আপল In this work, we tackle the problem in a multilingual setting where a single NMT model translates from multiple languages for downstream automatic processing in the target language.  Knowledge sharing across close and distant languages allows to apply our machine-oriented approach in the zero-shot setting where no labeled data for the test language is seen at training time.  এছাড়াও, আমরা আমাদের এনএমটি সিস্টেমের সূত্রে বহুভাষা বের্টের সাথে যোগাযোগ করি এই মডেলে যে জ্ঞানের সুবিধা থেকে লাভ করা আমাদের পরীক্ষাগুলো দেখাচ্ছে একত্রিত ভাষার অর্জন, দুটির বিভিন্ন ভাষার নির্দেশের জন্য) 'জেনেরিক' এনএমটি মডেল (মানুষের ভোগের প্রশিক্ষণ শূন্য ভাষার নির্দেশ (যেমন স্প্যানিশ-ইংরেজী) এর জন্য এই অর্জন বেশি বেশি যখন মডেলগুলো নিকটবর্তী সোর্স ভাষা (ইতালিয়ান) দূরবর্তী ভাষায় ভাষায়", 'bs': 'Modeli neurološkog prevoda (NMT) tipično se obučavaju smatrajući ljudima krajnjim korisnicima i maksimalizirajući ciljeve orientirane na ljude. Međutim, u nekim scenarijama, njihov proizvod potroši automatski komponenti NLP umjesto ljudi. U ovim scenarijama, kvalitet prevoda se mjera u smislu njihove "pristojnosti za svrhu" (t.i. maksimaliziranja učinkovitosti vanjskih NLP alata) umjesto u smislu standardnih kriterija ljudske tečnosti/adekvatnosti. Nedavno je predloženo pojačanje tehnika učenja koja koristi reakciju iz snižnih NLP alata za adaptaciju NMT-a na mašini orientiranu. U ovom poslu, riješimo problem u multijezičkom postavljanju gdje jedan model NMT prevodi iz višestrukih jezika za automatsku obradu na ciljnom jeziku. Podjela znanja na bliskim i daljinskim jezicima omogućava primjenjivati naš pristup na stroj orijentiran na nulu snimanju gdje se u treningu ne vidi označeni podaci za test jezik. Osim toga, uključujemo višejezičku BERT na izvornu stranu našeg NMT sistema kako bi koristili znanje uključene u ovaj model. Naši eksperimenti pokazuju pristojne dobitke učinka, za različite jezičke upute nad obje i) \'generične\' NMT modele (obučene za ljudsku potrošnju), i ii) ispravne multijezičke BERT. Ovaj dobitak za uputstvo jezika bez pucnjave (npr. španjolski-engleski) je veći kada se modeli dobro uključuju na bliski izvorni jezik (italijanski) nego udaljeni (njemački).', 'cs': 'Modely neuronového strojového překladu (NMT) jsou obvykle trénovány na základě považování člověka za koncové uživatele a maximalizace cílů orientovaných na člověka. Nicméně v některých scénářích je jejich výstup spotřebován automatickými komponenty NLP spíše než lidmi. V těchto scénářích se kvalita překladů měří spíše z hlediska jejich "vhodnosti pro účel" (tj. maximalizace výkonu externích nástrojů NLP) než z hlediska standardních kritérií lidské plynulosti/adekvátnosti. V poslední době byly navrženy techniky posilování učení využívající zpětné vazby z následných NLP nástrojů pro "strojově orientovanou" adaptaci NMT. V této práci řešíme problém v mnohojazyčném prostředí, kde jeden NMT model překládá z více jazyků pro následné automatické zpracování v cílovém jazyce. Sdílení znalostí napříč blízkými a vzdálenými jazyky umožňuje aplikovat náš strojově orientovaný přístup v nastavení nulového záběru, kde v době tréninku nejsou vidět žádná označená data pro testovací jazyk. Navíc do zdrojové strany našeho NMT systému začleníme vícejazyčný BERT, abychom využili znalostí vložených do tohoto modelu. Naše experimenty ukazují koherentní zisky výkonu pro různé jazykové směry u i) "generických" NMT modelů (vycvičených pro lidskou spotřebu) a ii) jemně vyladěných vícejazyčných BERT. Tento zisk pro jazykové směry nulového záběru (např. španělština-angličtina) je vyšší, pokud jsou modely doladěny na úzce příbuzný zdrojový jazyk (italština) než vzdálený (němčina).', 'et': 'Neuraalse masintõlke (NMT) mudelid on tavaliselt koolitatud, arvestades inimesi lõppkasutajatena ja maksimeerides inimesele orienteeritud eesmärke. Mõningatel stsenaariumidel tarbivad nende toodangut aga pigem automaatsed NLP komponendid kui inimesed. Nende stsenaariumide puhul mõõdetakse tõlkete kvaliteeti pigem nende eesmärgile sobivuse (st väliste uue tööprogrammi tööriistade maksimaalse jõudluse) kui tavaliste inimeste sujuvuse/piisavuse kriteeriumide alusel. Hiljuti on tehtud ettepanek tugevdada õppemeetodeid, mis kasutavad uue uue tööprogrammi järgmise etapi tööriistadest saadud tagasisidet, et kohandada masinapõhiselt NMT-d. Selles töös käsitleme probleemi mitmekeelses keskkonnas, kus üks NMT mudel tõlgib mitmest keelest automaatseks töötlemiseks sihtkeeles. Teadmiste jagamine lähedaste ja kaugete keelte vahel võimaldab rakendada meie masinast orienteeritud lähenemisviisi null-shot seadistuses, kus testikeele kohta ei ole koolituse ajal märgistatud andmeid. Lisaks lisame mitmekeelse BERT-i oma NMT-süsteemi allikaküljele, et saada kasu selles mudelis sisalduvatest teadmistest. Meie eksperimendid näitavad sidusat tulemuslikkust erinevates keelesuundades nii i) üldiste NMT mudelite (inimtoiduks koolitatud) kui ka ii) täiustatud mitmekeelsete BERT-mudelite puhul. See kasu nullpildi keele suunas (nt hispaania-inglise keel) on suurem, kui mudelid on täpselt häälestatud tihedalt seotud lähtekeeles (itaalia) kui kaugel (saksa).', 'az': "NMT modelləri insanları son istifadəçilər kimi hesab edir və insanlara tərəf yönəlmiş məqsədləri böyükləndirir. Lakin, bəzi scenariyalarda, onların çıxışları insanların yerinə avtomatik NLP komponentlərindən istifadə edilir. Bu scenariolarda, tercümələrin keyfiyyəti, standart insan sıxınlığı/adekvatlıq kriteriləri üzərində ölçülür. Son zamanlarda NLP vasitələrindən istifadə edilən öyrənmə tekniklərini yeniləşdirmək üçün 'maşın tərəfindən' NMT adaptasiya üçün təklif edildi. Bu işdə, bir NMT modeli müxtəlif dillərdən təkrar təkrar edilən məqsəd dilində avtomatik işləmə üçün problemi çəkirik. Yaxınlıq və uzaq dillərdə bilgi paylaşılması maşına tərəf yönəltmiş tərzimlərimizi sıfır-shot ayarlamasında istifadə edər ki, test dilinin etiketli məlumatları təhsil vaxtında görünməyəcəkdir. Daha sonra, NMT sistemimizin çoxlu dilli BERT'u bu modellərdə olan elmdən faydalanmaq üçün NMT sistemimizin mənbəsi tərəfində birləşdiririk. Bizim təcrübələrimiz müxtəlif dil yönlərinə i) 'generic' NMT modelləri (insanların istifadəsi üçün təhsil edilmiş), və ii) çoxlu dilli BERT üçün müxtəlif təcrübələr göstərir. Sıfır dil tərəfindən (İspanyol-İngilizce kimi), modellərin uzaq dilindən ( Alman dilindən ) yaxın tərəfindən istifadə edilən mənbə dili (İtalyan dilindən ) daha yüksəkdir.", 'fi': 'Neuroiden konekäännösmalleja (NMT) koulutetaan tyypillisesti tarkastelemalla ihmisiä loppukäyttäjinä ja maksimoimalla ihmislähtöiset tavoitteet. Joissakin tilanteissa niiden tuotantoa kuitenkin kuluttavat automaattiset NLP-komponentit ihmisten sijaan. Näissä skenaarioissa käännösten laatua mitataan pikemminkin niiden tarkoituksenmukaisuuden (eli ulkoisten NLP-työkalujen suorituskyvyn maksimoimisen) kuin tavallisten ihmisten sujuvuuden/riittävyyden kriteerien perusteella. Äskettäin on ehdotettu "konesuuntautunutta" NMT-sopeutumista varten vahvistustekniikoita, joissa hyödynnetään jatkojalostuksen työkaluista saatua palautetta. Tässä työssä käsittelemme ongelmaa monikielisessä ympäristössä, jossa yksi NMT-malli kääntää useista kielistä automaattista jatkokäsittelyä kohdekielellä varten. Tietojen jakaminen läheisille ja kaukaisille kielille mahdollistaa konelähtöisen lähestymistapamme soveltamisen nollakuvausasetuksessa, jossa testikielen merkittyjä tietoja ei näy harjoitushetkellä. Lisäksi sisällytämme monikielisen BERT-järjestelmän lähdepuolelle hyötyäksemme tähän malliin sisältyvästä tiedosta. Kokeet osoittavat johdonmukaista suorituskykyä eri kielisuuntiin verrattuna sekä i) "geneerisiin" NMT-malleihin (koulutettu ihmisravinnoksi) että ii) hienoviritettyihin monikielisiin BERT-malleihin. Tämä voitto nolla-shot-kielisuuntiin (esim. espanja-englanti) on suurempi, kun mallit on hienoviritetty läheisesti toisiinsa liittyvällä lähdekielellä (italia) kuin kaukaisella kielellä (saksa).', 'hy': 'Նյարդային մեքենայի թարգմանման (NMT) մոդելները սովորաբար պատրաստվում են մարդկանց վերջնական օգտագործողների համարձակագրելով և մարդկային ուղղությամբ նպատակների մեծացնելով: Այնուամենայնիվ, որոշ սցենարներում նրանց արտադրությունը օգտագործվում է ավտոմատիկ ՆԼՊ-ի բաղադրիչներով, ոչ թե մարդկանց կողմից: In these scenarios, translations\' quality is measured in terms of their \'fitness for purpose\' (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency/adequacy criteria.  Վերջերս նախագծված են "մեքենայի ուղղությամբ" ՆՄԹ-ի ադապտացիայի համար ուժեղացված ուսումնական տեխնիկաներ, որոնք օգտագործում են ՆԼՊ-ի հետագա գործիքների արձագանքը: Այս աշխատանքի ընթացքում մենք լուծում ենք խնդիրը բազլեզու միջավայրում, որտեղ մեկ NMT մոդել թարգմանվում է բազմաթիվ լեզուներից ավտոմատիկ վերամշակում նպատակային լեզվով: Գիտությունների կիսվելը մոտ և հեռավոր լեզուներում թույլ է տալիս կիրառել մեքենայի ուղղությամբ գտնվող մոտեցումը զրոյական նկարների միջոցով, որտեղ փորձարկումների լեզվի համար նշանակված տվյալներ չեն տեսնում: Ավելին, մենք ներառում ենք բազմալեզու BER-ը մեր NMT համակարգի աղբյուրային կողմում, որպեսզի շահույթ ունենանք այս մոդելի ներդրված գիտելիքից: Մեր փորձարկումները ցույց են տալիս համապատասխան արդյունավետության զարգացումներ, տարբեր լեզվի ուղղությունների համար i) \'ընդհանուր\' NMT մոդելների (պատրաստված մարդկային սպառության համար) և II) լավագույն բազլեզու BER-ի համար: This gain for zero-shot language directions (e.g. Spanish-English) is higher when the models are fine-tuned on a closely-related source language (Italian) than a distant one (German).', 'ca': 'Els models de traducció neural de màquines (NMT) es forman típicament considerant els humans com usuaris finals i maximitzant objectius orientats a l\'humà. However, in some scenarios, their output is consumed by automatic NLP components rather than by humans.  En aquests escenaris, la qualitat de les traduccions es mesura en termes de \'aptitud a l\'objectiu\' (i.e. maximitzar el rendiment de les eines externes del NLP) en comptes de criteris standard de fluència/adequació humana. Recentment, s\'han proposat tècniques d\'aprenentatge de reforç que expliquen el feedback de les eines de NLP avall per adaptar-se a la NMT orientada a màquines. En aquesta feina, tractem el problem a en un entorn multillenguatge on un únic model NMT es tradueix de múltiples llengües per al processament automàtic a avall en el llenguatge d\'objectiu. El compartiment de coneixements a llengües estretes i distants permet aplicar el nostre enfocament orientat a la màquina en un entorn de fotografies zero on no es veuen dades etiquetades per al llenguatge de prova en el moment de l\'entrenament. A més, incorporam BERT multilingüe al costat fontdel nostre sistema NMT per beneficiar-nos del coneixement incorporat en aquest model. Els nostres experiments mostran guanys de rendiment coherents, per diferents direccions de llenguatge sobre i) models NMT "genèrics" (entrenats per al consum humà), i ii) BERT multilingüe finat. Aquest guany per direccions de llenguatge amb fotografies zero (per exemple espanyol-anglès) és més gran quan els models estan finament ajustats en un llenguatge de fonts estretament relacionat (italià) que en un llenguatge remot (alemany).', 'ha': "@ info: whatsthis A lokacin da ke cikin wani fili, Outputs za'a ci shi da ƙananan NLP ɗin farat ɗaya ko da mutum. Idan na cikin wannan fasarin, ana ƙayyade nau'in fassarori da aka ƙayyade shi cikin tsarin 'fitarwa ga amfani' (misali, kifi girma da aikin NLP na ƙarƙashin gaba) ko da kuma a ƙayyade kimar gaskiya na mutum na daidaita. A yanzu, ana ƙara mafaniyar kwamfyuta da ake amfani da feedback daga kayan aiki na NLP na ƙarami an buƙata wa adaptation na 'mashine-originated' NMT. Daga wannan aikin, munã haɗa mataimaki a cikin tsarin mulki-lingui, inda wata motel na NMT na fassara daga wasu harshe masu yawa wa shirin jarraba farat ɗaya cikin harshen goan. Sharing da ilmi a kowace lugha na rufe da ke nĩsa yana yarda su shirya mazaɓa masu shiryuwa da shirin mashine-ori cikin tsarin sifiri-shot inda ba'a gane wasu data da aka rubũta wa lugha kan jarraba a lokacin da za'a yi amfani da shi ba. Moreover, we incorporate multi-lingual BERT in the source side of our NMT system to benefit from the knowledge embedded in this model.  Kayan jarrabõyinmu na nuna mafarin aiki da ke samura, ko da shiryoyin harshe dabam-daban a tsakanin 'NMT' misãlai na 'jenarin' da aka sanar wa abincin mutum, da i i) mai kyaun mulki-talli na BERT. Wannan amfani da shiryoyin harshen na sifanci (misali, spanish-Ingiriya) na ɗaukaka idan an nuna misalin misalin su kan harshen maganar da aka kusantar da (Italian) daga wata wuri mai nĩsa (Jarman).", 'he': 'דוגמנים של מכונות עצביות (NMT) מתאמנים בדרך כלל על ידי שיקול בני אדם כמשתמשים סופיים ומקסימום מטרות ממוקצות בני אדם. בכל אופן, במקרים מסוימים, יצרתם נשתמשת על ידי רכיבי NLP אוטומטיים במקום על ידי בני אדם. בתרחישים האלה, איכות התרגשות מתמדדת במונחים של "מתאימה למטרה" שלהם (כלומר המקסימום ביצועים של כלי NLP חיצוניים) במקום במונחים של קריטורי נוזלות/מתאימה אנושית סטנדרטיים. לאחרונה, טכניקות לימוד חיבורי ניצלו את ההחזרה מכלי NLP למטה הציעו להסתגלות NMT "ממוקדת במכונה". בעבודה הזו, אנו מתמודדים עם הבעיה במסגרת רבות שפות שבו מודל NMT אחד מתרגם ממספר שפות עבור עיבוד אוטומטי למטה בשפה המטרה. שיתוף ידע בין שפות קרובות ומרחקות מאפשר להפעיל גישה ממוקדת המכונה שלנו בתערוכת צילום אפס שבו לא נראים נתונים מסוימים לשפה הבדיקה בזמן האימון. חוץ מזה, אנו מכילים BERT רב-שפתי בצד המקור של מערכת NMT שלנו כדי להרוויח מהידע המוקף במודל הזה. הניסויים שלנו מראים זכויות ביצועים קבועות, לכיוונים שפותיים שונים על שניהם i) \'דוגמנים של NMT \'גנריים (מאומנים לצרכת אנושית), ו ii) BERT רבות שפותיים מתאימים. This gain for zero-shot language directions (e.g. Spanish-English) is higher when the models are fine-tuned on a closely-related source language (Italian) than a distant one (German).', 'sk': 'Modeli nevralnega strojnega prevajanja (NMT) se običajno usposabljajo tako, da ljudi obravnavajo kot končne uporabnike in maksimirajo cilje, usmerjene v človeka. Vendar pa v nekaterih scenarijih njihovo proizvodnjo porabijo avtomatske komponente NLP in ne ljudje. V teh scenarijih se kakovost prevodov meri glede na njihovo "primernost za namen" (tj. povečanje učinkovitosti zunanjih orodij NLP) in ne glede na standardna merila tekoče/ustreznosti človeka. Pred kratkim so bile za "strojno usmerjeno" prilagajanje NMT predlagane tehnike učenja okrepitve, ki izkoriščajo povratne informacije iz nadaljnjih orodij NLP. V tem delu rešujemo problem v večjezičnem okolju, kjer enoten model NMT prevaja iz več jezikov za nadaljnjo avtomatsko obdelavo v ciljnem jeziku. Izmenjava znanja v bližnjih in oddaljenih jezikih omogoča uporabo strojno usmerjenega pristopa v nastavitvi ničelnega strela, kjer v času usposabljanja ni vidnih označenih podatkov za testni jezik. Poleg tega večjezični BERT vključujemo v izvorno stran našega sistema NMT, da bi izkoristili znanje, vgrajeno v ta model. Naši poskusi kažejo skladno povečanje učinkovitosti v različnih jezikovnih smereh pri i) "generičnih" modelih NMT (usposobljenih za prehrano ljudi) in ii) natančno nastavljenih večjezičnih BERT. Ta dobiček za ničelne jezikovne smeri (npr. špansko-angleščina) je višji, če so modeli natančno nastavljeni v tesno povezanem izvornem jeziku (italijanščini) kot v oddaljenem jeziku (nemščini).', 'jv': "Maski NMT penting Nanging, nanguwong manggadi bener seneng pisan neng, akeh nggawe wigatiningan NLP ora bisa pertamane uwong. Nanging kadadèhan iki, terjamahan' kaliwat langgambar luwih nggawe 'nggawe kesempatan kanggo nggawe' (th.i. ukuwih bantuan karo alat NLP externe) kayasai adalah sing perusahaan langgambar uwong/adalah. plug-in-action Nang barêng-barêng iki, kéné iso nggawe kesempatan kanggo ngerasakno urip bantêng langgar, ning sekang NMT sing terjamah bantêr lenggal kanggo ngerasakno perusahaan langa bantêr. Bilih nesaturan mruput Nambah, awak dhéwé ngerasakno sistem sing luwih akeh BERT nang sekondirno NMT dumadhi kanggo ngerasakno iki ning model iki. Where's the data ? Punika ingkang nggawe tarjamahan sing nul-shot karo perusahaan (bisa Spanish-englisi) sing luwih apik sapa modelo sing dibutune nggo langut nguasai perusahaan (Itilian) sing sampeyan sak sedhaya.", 'bo': "ནུས་མེད་ལག་འཁྱེར་གྱི་སྤྱི་ཚོལ་གཞུང་ལ་རྒྱུན་ལྡན་མིན་འདུག However, in some scenarios, their output is consumed by automatic NLP components rather than by humans. In these scenarios, translations' quality is measured in terms of their 'fitness for purpose' (i.e. maximizing performance of external NLP tools) rather than in terms of standard human fluency/adequacy criteria. Recently, reinforcement learning techniques exploiting the feedback from downstream NLP tools have been proposed for 'machine-oriented' NMT adaptation. In this work, we tackle the problem in a multilingual setting where a single NMT model translates from multiple languages for downstream automatic processing in the target language. Knowledge sharing across close and distant languages allows to apply our machine-oriented approach in the zero-shot setting where no labeled data for the test language is seen at training time. འོན་ཀྱང་། ང་ཚོས་རང་གི་NMT མ་ལག་གི་ཕྱོགས་སུ་ཡིག་སྐད་ཡིག་ཆ་མང་པོ་ཞིག་བཙུགས་ཏེ། ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་མཐོ་རིམ་གྱི་སྣེ་ཚོགས་ལས་མཐོ་རིམ་མཐུན་བཟོ་བ་ཡིན། འདི་དག་གིས་རྒྱལ་ཁབ་ཀྱི་སྐད་ཡིག་གཟུགས་ཐལ་ཆེ་བ་ལས་མཐོ་རྐྱེན་ཐུབ།"}
{'en': 'Character Alignment in Morphologically Complex Translation Sets for Related Languages', 'ar': 'محاذاة الأحرف في مجموعات الترجمة المعقدة شكليًا للغات ذات الصلة', 'pt': 'Alinhamento de caracteres em conjuntos de tradução morfologicamente complexos para idiomas relacionados', 'fr': 'Alignement des caractères dans les jeux de traduction morphologiquement complexes pour les langues associées', 'es': 'Alineación de caracteres en conjuntos de traducción morfológicamente complejos para idiomas relacionados', 'ja': '関連する言語のための形態学的に複雑な翻訳セットにおける文字の整列', 'zh': '相关语言形态杂译集字符对齐', 'hi': 'संबंधित भाषाओं के लिए रूपात्मक रूप से जटिल अनुवाद सेट में वर्ण संरेखण', 'ru': 'Выравнивание символов в морфологически сложных наборах перевода для родственных языков', 'ga': 'Ailíniú Carachtair i Thacair Aistriúcháin Choimpléasc Moirfeolaíocha do Theangacha Gaolmhara', 'hu': 'Karakterigazítás a kapcsolódó nyelvek morfológiailag összetett fordítási készleteiben', 'ka': 'სიმბოლოების შენახვა Morphologically Complex Translation Sets for Related Languages', 'el': 'Στοίχιση χαρακτήρων σε Μορφολογικά σύνθετα σύνολα μετάφρασης για σχετικές γλώσσες', 'it': 'Allineamento dei caratteri in set di traduzione morfologicamente complessi per lingue correlate', 'lt': 'Simbolių suderinimas morfologiškai sudėtingais vertimo rinkiniais susijusioms kalboms', 'kk': 'Марфологикалық толық түрлі тілдердің таңбаларды түзету', 'mk': 'Израмнување на знаци во морфолошки комплексни преведувања за поврзани јазици', 'ml': 'പരിശോധിച്ച ഭാഷകള്\u200dക്കുവേണ്ടി മൊര്\u200dഫോളോഗിക്കല്\u200d കോമ്പ്ലെക്സ് പരിഭാഷകളിലെ അക്ഷരസജ്ജീകരണം', 'ms': 'Jajaran Aksara dalam Tetapan Terjemahan Mudah Morfologik untuk Bahasa Terhubung', 'mn': 'Марфологикийн төвөгтэй харилцааны тусгаарлалт', 'mt': 'Allinjament tal-Karatteri f’Settijiet ta’ Traduzzjoni Morfoloġikament Kumplessi għal Lingwi Relatati', 'no': 'Teiknsetting i morfologisk kompleks omsetjing for tilhøyrande språk', 'pl': 'Wyrównanie znaków w złożonych morfologicznie zestawach tłumaczeń dla języków pokrewnych', 'ro': 'Alinierea caracterelor în seturi de traduceri morfologic complexe pentru limbi conexe', 'sr': 'Povezanje znakova u morfološki kompleksnim prevodnim setima za povezane jezike', 'so': 'Horizontal in Morphologically Complex Translation Sets for Related Languages', 'ta': 'Name', 'si': 'මොර්ෆෝලිකියෙන් සම්පූර්ණයෙන් අක්ෂර සංවිධානය', 'sv': 'Teckenjustering i morfologiskt komplexa översättningssatser för relaterade språk', 'ur': 'Name', 'uz': 'Name', 'vi': 'Thay đổi ký tự trong bộ trình dịch phức tạp Morphological Componex for Related Ngôn.', 'da': 'Tegnjustering i morfologisk komplekse oversættelsessæt til relaterede sprog', 'hr': 'Postavljanje znakova u morfološki kompleksnom prevodu za povezane jezike', 'nl': 'Tekenauitlijning in morfologisch complexe vertaalsets voor verwante talen', 'bg': 'Подравняване на знаците в морфологически сложни комплекти преводи за сродни езици', 'de': 'Zeichenausrichtung in morphologisch komplexen Übersetzungssätzen für verwandte Sprachen', 'id': 'Penjajaran Karakter dalam Set Translation Morfologis Kompleks untuk Bahasa Terhubung', 'fa': 'تنظیم شخصیت\u200cها در ترجمه\u200cهای ترجمه\u200cهای کامل برای زبانهای ارتباط', 'ko': '관련 언어 형태의 복잡한 번역 집중 문자 정렬', 'sw': 'Kitengezeko cha Character katika Tafsiri ya Kimorphologically Complex Sets for Related Lugha', 'af': 'Karakter Oplyn in Morphologies Kompleks Vertaling Opstellings vir Verwante Taal', 'tr': 'Karkater ködlemeleri baglanyş diller üçin Karkater ködlemeleri', 'sq': 'Rregullimi i karaktereve në përkthimet morfologikisht të kompleksizuara për gjuhët e lidhura', 'am': 'KCharselect unicode block name', 'az': 'Morphologically Complex Translation Sets for Related Languages', 'bn': 'Name', 'hy': 'Սիմպոլոգիապես բարդ թարգմանման համակարգերը կապված լեզուների համար', 'bs': 'Postavljanje znakova u morfološki kompleksnim prevodnim setima za povezane jezike', 'ca': 'Allinjament de Caràcters en Set de Traducció Morfològicament Complex per Llingues Relatades', 'cs': 'Zarovnání znaků v morfologicky složitých překladových sadách pro související jazyky', 'et': 'Sümbolite joondamine seotud keelte morfoloogiliselt keerukates tõlkekomplektides', 'fi': 'Merkkien tasaus morfologisesti monimutkaisissa käännösasioissa samankaltaisille kielille', 'jv': 'Learn Mode', 'ha': 'KCharselect unicode block name', 'he': 'התאמת סמויות בתורמות מורפולוגית מורכבות לשפות הקשורות', 'sk': 'Poravnava znakov v morfološko kompleksnih prevajalskih naborih za sorodne jezike', 'bo': 'མཇལ་རིས་ལྡན་གྱི་ཡིག་འབྲུ་གི་སྒྲིག་འགོད་ཀྱི་ཡིག་རྟགས་ལ་བསྡུ་ཚར་ཡོད་པ'}
{'en': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in ', 'ar': 'بالنسبة للغات ذات التشكل المعقد ، تعد الترجمة من كلمة إلى كلمة مهمة ذات تطبيقات محتملة متنوعة ، على سبيل المثال ، في استرجاع المعلومات ، وتعليم اللغة ، وإنشاء القاموس ، وكذلك في الترجمة الآلية. في هذه الورقة ، نقتصر على المهمة الفرعية لمحاذاة الأحرف للحالة الخاصة لعائلات اللغات ذات الصلة بموارد قليلة جدًا لمعظم الأعضاء أو جميعهم. هناك العديد من هذه العائلات. نحن نركز على مجموعة فرعية من اللغات السامية المنطوقة في إثيوبيا وإريتريا. نبدأ بتكييف خوارزميات المحاذاة المألوفة وراء الترجمة الآلية الإحصائية ، وتعديلها بما يتناسب مع مهمتنا. نوضح كيف يمكن لمحاذاة الأحرف أن تكشف عن المراسلات الصرفية والصوتية والإملائية بين اللغات ذات الصلة.', 'pt': 'Para idiomas com morfologia complexa, a tradução palavra a palavra é uma tarefa com várias aplicações potenciais, por exemplo, na recuperação de informações, instrução de idiomas e criação de dicionários, bem como na tradução automática. Neste artigo, nos limitamos à subtarefa de alinhamento de caracteres para o caso particular de famílias de idiomas relacionados com muito poucos recursos para a maioria ou todos os membros. Existem muitas dessas famílias; nos concentramos no subgrupo de línguas semíticas faladas na Etiópia e na Eritreia. Começamos com uma adaptação dos algoritmos de alinhamento familiares por trás da tradução automática estatística, modificando-os conforme apropriado para nossa tarefa. Mostramos como o alinhamento de caracteres pode revelar correspondências morfológicas, fonológicas e ortográficas entre línguas relacionadas.', 'fr': "Pour les langues dont la morphologie est complexe, la traduction mot à mot est une tâche qui présente diverses applications potentielles, par exemple, dans la recherche d'informations, l'enseignement des langues et la création de dictionnaires, ainsi que dans la traduction automatique. Dans cet article, nous nous limitons à la sous-tâche de l'alignement des caractères pour le cas particulier des familles de langues apparentées avec très peu de ressources pour la plupart ou la totalité des membres. Ces familles sont nombreuses\xa0; nous nous concentrons sur le sous-groupe des langues sémitiques parlées en Éthiopie et en Érythrée. Nous commençons par adapter les algorithmes d'alignement habituels de la traduction automatique statistique, en les modifiant en fonction de notre tâche. Nous montrons comment l'alignement des caractères peut révéler des correspondances morphologiques, phonologiques et orthographiques entre des langues apparentées.", 'es': 'Para los idiomas con morfología compleja, la traducción palabra a palabra es una tarea con varias aplicaciones potenciales, por ejemplo, en la recuperación de información, la enseñanza de idiomas y la creación de diccionarios, así como en la traducción automática. En este artículo, nos limitamos a la subtarea de la alineación de caracteres para el caso particular de familias de idiomas relacionados con muy pocos recursos para la mayoría o todos los miembros. Hay muchas familias de este tipo; nos centramos en el subgrupo de lenguas semíticas que se hablan en Etiopía y Eritrea. Comenzamos con una adaptación de los conocidos algoritmos de alineación detrás de la traducción automática estadística, modificándolos según sea apropiado para nuestra tarea. Mostramos cómo la alineación de caracteres puede revelar correspondencias morfológicas, fonológicas y ortográficas entre idiomas relacionados.', 'ja': '複雑な形態を持つ言語にとって、単語間翻訳は、情報検索、言語指導、辞書作成、および機械翻訳などのさまざまな潜在的なアプリケーションを持つタスクです。本稿では、ほとんどまたはすべてのメンバーのリソースが非常に少ない関連言語のファミリーの特定のケースのための文字整列のサブタスクに限定する。エチオピアとエリトリアで話されているセム語の下位グループに焦点を当てていますまず、統計的機械翻訳の背後にある慣れ親しんだアライメントアルゴリズムの適応から始め、タスクに適したアライメントアルゴリズムを修正します。文字の整列が、関連する言語間の形態学的、音声学的、および正書法的対応を明らかにする方法を示します。', 'zh': '凡杂形之语,单词至单词翻译,一事也;其于信息检索也,言语教字典,创建机器翻译中。 其在本文,自限言语家特定字符对齐子,而于大众及诸成人,资源甚少。 多如此家; 注埃塞俄比亚、厄立特里亚闪米特语子组。 臣等自调机器翻译后所习齐算法,随事修改。 展字符以示形,语正字法相应。', 'hi': 'जटिल आकृति विज्ञान वाली भाषाओं के लिए, शब्द-से-शब्द अनुवाद विभिन्न संभावित अनुप्रयोगों के साथ एक कार्य है, उदाहरण के लिए, सूचना पुनर्प्राप्ति, भाषा निर्देश और शब्दकोश निर्माण में, साथ ही मशीन अनुवाद में। इस पेपर में, हम अपने आप को अधिकांश या सभी सदस्यों के लिए बहुत कम संसाधनों के साथ संबंधित भाषाओं के परिवारों के विशेष मामले के लिए चरित्र संरेखण के उप-कार्य तक सीमित करते हैं। ऐसे कई परिवार हैं; हम इथियोपिया और इरिट्रिया में बोली जाने वाली सेमिटिक भाषाओं के उपसमूह पर ध्यान केंद्रित करते हैं। हम सांख्यिकीय मशीन अनुवाद के पीछे परिचित संरेखण एल्गोरिदम के अनुकूलन के साथ शुरू करते हैं, उन्हें हमारे कार्य के लिए उपयुक्त के रूप में संशोधित करते हैं। हम दिखाते हैं कि चरित्र संरेखण संबंधित भाषाओं के बीच रूपात्मक, ध्वन्यात्मक और ऑर्थोग्राफिक पत्राचार को कैसे प्रकट कर सकता है।', 'ru': 'Для языков со сложной морфологией перевод слов - это задача с различными потенциальными приложениями, например, в поиске информации, языковом обучении и создании словаря, а также в машинном переводе. В этом документе мы ограничиваемся подзадачей выравнивания символов для конкретного случая семей родственных языков с очень ограниченными ресурсами для большинства или всех членов. Таких семей много; мы уделяем особое внимание подгруппе семитских языков, на которых говорят в Эфиопии и Эритрее. Мы начинаем с адаптации знакомых алгоритмов выравнивания за статистическим машинным переводом, изменяя их в соответствии с нашей задачей. Мы показываем, как выравнивание символов может выявлять морфологические, фонологические и орфографические соответствия между родственными языками.', 'ga': 'Maidir le teangacha a bhfuil moirfeolaíocht chasta acu, is tasc é aistriúchán focal-go-focal a bhfuil feidhmeanna féideartha éagsúla ann, mar shampla, in aisghabháil faisnéise, teagasc teanga, agus cruthú foclóir, chomh maith le haistriúchán meaisín. Sa pháipéar seo, ní dhéanaimid ach sinn féin a theorannú don fhothasc a bhaineann le ailíniú carachtair do chás ar leith na dteaghlach de theangacha gaolmhara a bhfuil fíorbheagán acmhainní acu don chuid is mó nó do gach ball. Tá go leor teaghlach den sórt sin; dírímid ar an bhfoghrúpa de theangacha Semitic a labhraítear san Aetóip agus san Eiritré. Tosaímid le hoiriúnú ar na halgartaim ailínithe aithnidiúla taobh thiar de mheaisín-aistriúchán staidrimh, agus iad á mionathrú de réir mar is cuí dár tasc. Léirímid conas is féidir le ailíniú carachtair comhfhreagras moirfeolaíoch, fóineolaíoch agus ortagrafach a nochtadh i measc teangacha gaolmhara.', 'ka': 'კომპლექსიკური მოპოროლოგიის ენათებისთვის, სიტყვებისთვის სიტყვებისთვის გადაწყვეტილება განსხვავებული პოტენციალური პროგრამების რაოდენობა, მაგალითად, ინფორმაციის მიღება,  ამ წიგნაში, ჩვენ ჩვენი სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას სახელმძღვრებას, რომე არსებობს ბევრი ასეთი ოჯახი; ჩვენ კონუქტირებით ექსმიტიკური ენების სამჯგუფში, რომლებიც ექსოპია და ერიტრიაში საუბჯგუფებულია. ჩვენ დავიწყეთ სტატისტიკური მაქანის გადაწყვეტის ალგორტიმების ადატაციას, რომელიც შესაძლებელია ჩვენი დავალებისთვის. ჩვენ ჩვენ აჩვენებთ როგორ შეიძლება მორფოლოგიური, ფონოლოგიური და ორტოგრაფიური კოპორესპერსპერსპერსპერსპერსპერსპერსპერსპერსპ', 'el': 'Για γλώσσες με πολύπλοκη μορφολογία, η μετάφραση λέξης σε λέξης είναι μια εργασία με διάφορες πιθανές εφαρμογές, για παράδειγμα, στην ανάκτηση πληροφοριών, στην εκμάθηση γλωσσών και στη δημιουργία λεξικών, καθώς και στη μηχανική μετάφραση. Στην παρούσα εργασία, περιορίζουμε τους εαυτούς μας στο υποσύστημα της ευθυγράμμισης χαρακτήρων για τη συγκεκριμένη περίπτωση οικογενειών συγγενικών γλωσσών με πολύ λίγους πόρους για τα περισσότερα ή όλα τα μέλη. Υπάρχουν πολλές τέτοιες οικογένειες. εστιάζουμε στην υποομάδα των σημιτικών γλωσσών που ομιλούνται στην Αιθιοπία και την Ερυθραία. Ξεκινάμε με την προσαρμογή των γνωστών αλγορίθμων ευθυγράμμισης πίσω από τη στατιστική μηχανική μετάφραση, τροποποιώντας τους ανάλογα με το έργο μας. Δείχνουμε πώς η ευθυγράμμιση χαρακτήρων μπορεί να αποκαλύψει μορφολογικές, φωνολογικές και ορθογραφικές αντιστοιχίες μεταξύ των σχετικών γλωσσών.', 'hu': 'Az összetett morfológiájú nyelvek esetében a szó-szó fordítás különböző potenciális alkalmazásokkal rendelkező feladat, például információkeresésben, nyelvtanításban, szótárkészítésben, valamint gépi fordításban. Ebben a tanulmányban a karakterek összehangolásának részterületére korlátozódunk a rokon nyelvek családjainak konkrét esetére, amelyek nagyon kevés erőforrással rendelkeznek a legtöbb vagy minden tag számára. Sok ilyen család létezik; Az Etiópiában és Eritreában beszélt szemita nyelvek alcsoportjára összpontosítunk. A statisztikai gépi fordítás mögötti ismert igazítási algoritmusok adaptálásával kezdjük, feladatunknak megfelelően módosítva azokat. Megmutatjuk, hogyan fedheti fel morfológiai, fonológiai és ortográfiai megfelelőségeket a kapcsolódó nyelvek között.', 'it': "Per le lingue con morfologia complessa, la traduzione parola a parola è un compito con varie applicazioni potenziali, ad esempio nel recupero di informazioni, nell'istruzione linguistica e nella creazione di dizionari, nonché nella traduzione automatica. In questo articolo ci limitiamo alla sottomissione dell'allineamento dei caratteri per il caso particolare di famiglie di lingue affini con pochissime risorse per la maggior parte o tutti i membri. Ci sono molte famiglie di questo tipo; Ci concentriamo sul sottogruppo di lingue semitiche parlate in Etiopia ed Eritrea. Iniziamo con un adattamento degli algoritmi di allineamento familiari dietro la traduzione automatica statistica, modificandoli come appropriato per il nostro compito. Mostriamo come l'allineamento dei caratteri possa rivelare corrispondenze morfologiche, fonologiche e ortografiche tra linguaggi correlati.", 'lt': 'Kalbų, turinčių sudėtingą morfologiją, vertimas žodžiu į žodį yra užduotis su įvairiomis galimomis programomis, pavyzdžiui, informacijos gavimo, kalbos mokymo ir žodyno kūrimo, taip pat vertimo mašinomis srityje. Šiame dokumente apsiribojame ypatingu susijusių kalbų šeimų, turinčių labai mažai išteklių daugumai ar visiems nariams, požymių suderinimo klausimu. Yra daug tokių šeimų; daugiausia dėmesio skiriame Etiopijoje ir Eritrėjoje kalbėtų semitinių kalbų pogrupiui. Pradedame pritaikydami žinomus suderinimo algoritmus už statistinių mašinų vertimo, juos atitinkamai pakeičiant mūsų užduotims. Mes parodome, kaip simbolių suderinimas gali atskleisti morfologines, fonologines ir ortografines korespondencijas tarp susijusių kalbų.', 'kk': 'Комплекс морфология тілдері үшін сөз- сөздерді аудару - әртүрлі мүмкіндік қолданбалармен тапсырма, мысалы, мәліметті алу, тіл құқықтауы және сөздік құрылуы және машина аудару үші Бұл қағазда, біз өзімізді көпшілігі не барлық мүшелердің арнаулы тілдердің отбасының қасиеттері үшін таңбалардың түрлендіруіне шектеп тұрамыз. Бұл әлемдердің көпшілігі бар. Эфиопияда және Эритреяда сөйлейтін семитикалық тілдердің субтобына көздейміз. Біз статистикалық компьютердің аудармасының артындағы таңдау алгоритмдерінің адаптациясынан бастап, тапсырмаға керек түрлендіру. Біз таңбаларды қалай морфологиялық, фонологиялық және ортографикалық тілдер арасында қалай көрсетеді.', 'ml': 'സങ്കീര്\u200dണ്ണമായ മോര്\u200dഫോളജിയോടുള്ള ഭാഷകള്\u200dക്ക്, വാക്ക്- to- word- to- word translation is a task with various potential applications such as information retrieval, language instruction, and dictionary creation, as well as machine translation. ഈ പത്രത്തില്\u200d, നമ്മള്\u200d സ്വയം വ്യക്തിപരമാക്കുന്നതിന്\u200dറെ അഭിപ്രായത്തിലേക്കാണ്, ബന്ധപ്പെട്ട ഭാഷകളുടെ കുടുംബങ്ങള്\u200dക്ക് വേ ഇതുപോലുള്ള കുടുംബങ്ങളുണ്ട്; യെഥിഥ്യയിലും എറിത്രിയയിലും സെമിറ്റിക്ക് ഭാഷകളുടെ സബ്ഗ്രൂപ്പില്\u200d ഞങ്ങള്\u200d ശ്രദ്ധിക്കുന്നു. പരിചയപ്പെട്ട ആല്\u200dഗോരിത്മുകളുടെ പിന്നില്\u200d നമ്മള്\u200d തുടങ്ങുന്നത് സ്റ്റാസ്റ്റിക്കല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നത നമ്മള്\u200d കാണിക്കുന്നു എങ്ങനെയാണ് ക്രാഫ്രോളജിക്കല്\u200d, ഫോളോളജിക്കല്\u200d, പ്രോഗ്രാഫിക് ഭാഷകള്\u200dക്കിടയില്\u200d ഉള്\u200dക്കൊള്', 'mn': 'Комплекс өөрчлөлтийн хэл дээр, үг-сөрөг-сөрөг өөрчлөлтийн боломжтой программын ажил, жишээлбэл, мэдээллийг авах, хэл заавал, сөрөг үг бүтээх, мөн машины орчуулалтын ажил юм. Энэ цаасан дээр бид ихэнх эсвэл бүх гишүүдийн хувьд холбоотой хэл гэр бүлийн гэр бүлийн тодорхой тодорхойлолтын тухай өөрсдийгөө багасгадаг. Ийм олон гэр бүл байдаг. Эфиоп болон Эритре дахь хэлний суурь хэл дээр анхаарлаа хандуулдаг. Бид статистикийн машины хөрөнгө оруулах алгоритмыг бидний ажил дээр хэрэгтэй болгон өөрчилж эхэлсэн. Бид харилцааны тэгшитгэл хэрхэн морфологик, фонологик, ортографик харилцааныг харуулж чадна гэдгийг харуулж байна.', 'no': 'For språk med komplekse morfologi er ordomsetjing til ordet eit oppgåve med ulike potensielle program, for eksempel i informasjonshenting, språk- instruksjon og ordbokoppretting, og i maskinsomsetjinga. I denne papiret avgrenserer vi oss til underspørjinga av teikn for det bestemte tilfellet for familiane av tilhøyrande språk med svært få ressursar for dei fleste eller alle medlemmer. Det er mange slike familier. vi fokuserer på undergruppa av semitiske språk som snakker i Etiopia og Eritrea. Vi startar med ein tilpassing av dei kjente justeringsalgoritmene bak statistiske maskinsomsetjinga, og endrar dei som passar for oppgåva vårt. Vi viser korleis teiknstilling kan opna morfologiske, fonologiske og ortografiske korespondencar mellom tilhøyrande språk.', 'ms': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in information retrieval, language instruction, and dictionary creation, as well as in machine translation. Dalam kertas ini, kita sempadan diri kita kepada subtanya penyesuaian aksara untuk kes tertentu keluarga bahasa berkaitan dengan sedikit sumber untuk kebanyakan atau semua ahli. Ada banyak keluarga seperti itu; kita fokus pada subkumpulan bahasa Semitik yang bercakap di Ethiopia dan Eritrea. We begin with an adaptation of the familiar alignment algorithms behind statistical machine translation, modifying them as appropriate for our task.  Kami menunjukkan bagaimana penyesuaian aksara boleh mengungkapkan korespondenci morfologik, fonologik, dan ortografik diantara bahasa yang berkaitan.', 'mt': 'Għall-lingwi b’morfoloġija kumplessa, it-traduzzjoni minn kelma għal kelma hija kompitu b’diversi applikazzjonijiet potenzjali, pereżempju, fil-kisba tal-informazzjoni, l-istruzzjoni tal-lingwa, u l-ħolqien tad-dikjaratur, kif ukoll fit-traduzzjoni bil-magna. F’dan id-dokument, aħna nillimitaw ruħna għas-sottotalba tal-allinjament tal-karattru għall-każ partikolari ta’ familji ta’ lingwi relatati bi ftit riżorsi għall-biċċa l-kbira tal-membri jew għall-membri kollha. Hemm ħafna familji bħal dawn; niffokaw fuq is-sottogrupp tal-lingwi Semitiċi mitkellma fl-Etjopja u l-Eritrea. We begin with an adaptation of the familiar alignment algorithms behind statistical machine translation, modifying them as appropriate for our task.  Aħna nuru kif l-allinjament tal-karattri jista’ jiżvela korrispondenzi morfoloġiċi, fonoloġiċi u ortografiċi fost il-lingwi relatati.', 'pl': 'W przypadku języków o złożonej morfologii tłumaczenie słowo na słowo jest zadaniem o różnych potencjalnych zastosowaniach, na przykład w pozyskiwaniu informacji, instrukcji językowych i tworzeniu słowników, a także w tłumaczeniu maszynowym. W niniejszym artykule ograniczamy się do podzadania osiągania znaków dla konkretnego przypadku rodzin języków pokrewnych z bardzo małą ilością zasobów dla większości lub wszystkich członków. Istnieje wiele takich rodzin; Skupiamy się na podgrupie języków semickich używanych w Etiopii i Erytrei. Zaczynamy od adaptacji znanych algorytmów wyrównania statystycznego tłumaczenia maszynowego, modyfikując je odpowiednio do naszego zadania. Pokazujemy, w jaki sposób wyrównanie znaków może ujawnić korespondencje morfologiczne, fonologiczne i ortograficzne pomiędzy językami pokrewnymi.', 'si': 'භාෂාවට සංශ්\u200dය විද්\u200dයාප්\u200dරවේශය සමග, වචන- වචන පරිවර්තනය විවෘත විද්\u200dයාප්\u200dරවේශය සමග විවෘත විද්\u200dයාප්\u200dරවේශය, උදාහරණය,  මේ පත්තරයේ අපි අපිව ප්\u200dරතිශ්ණාත්මක සම්බන්ධ කරුණාකරණය සඳහා විශේෂ භාෂාවගේ පවුලේ සම්බන්ධ කරුණාකර ඒ වගේම ගොඩක් පවුල තියෙනවා; අපි ඉතියෝපියාවයි එරිට්\u200dරියාවයි කතා කරපු සෙමිටික් භාෂාවල උපකණ්ඩායම් වලට බලන්න. අපි පටන් ගන්නවා සංඛ්\u200dයාත්මක මැෂින් වාර්ථාව පිටිපස්සේ සංවේදනය අල්ගෝරිතම් වල සංවේදනයෙන්, අපේ ව අපි පෙන්වන්නේ කොහොමද අක්ෂර සම්බන්ධ විදියට මොර්ෆෝලෝජික, ෆෝනොලෝජිකාවික, සම්බන්ධ භ', 'mk': 'За јазиците со комплексна морфологија, преводот збор за збор е задача со различни потенцијални апликации, на пример, за преземање информации, инструкции за јазик и создавање на речник, како и за машински превод. Во овој весник, се ограничуваме на подпрашањето на прилагодувањето на карактерите за конкретниот случај на семејствата на поврзани јазици со многу малку ресурси за повеќето или сите членови. Има многу такви семејства; се фокусираме на подгрупата на семитските јазици кои се зборуваат во Етиопија и Еритреа. We begin with an adaptation of the familiar alignment algorithms behind statistical machine translation, modifying them as appropriate for our task.  We show how character alignment can reveal morphological, phonological, and orthographic correspondences among related languages.', 'so': 'Luqadaha ku qoran maamulka muraamka ah, turjumista hadalka-to-word waa shaqo ay ku leedahay codsiyo kala duduwan, tusaale ahaan helitaanka macluumaadka, hagitaanka luqada, iyo abuuridda luqada, sidoo kale turjumidda machine. Qoraalkan waxaynu isugu qoraynaa sameynta qoyska luuqadaha la xiriira oo aad u yar ama xubnaha oo dhan. Qoysaska caynkaas ah waa badan yihiin; waxaynu ku kalsoonaynaa koox luqadaha Semitic oo ku hadla Itoobiya iyo Eritrea. Waxaynu bilownaa in loo beddelo alaabta la isku bedelay oo ku soo wareegsan karo turjumidda takhasuska machine, si loo beddelo shaqadeenna ugu haboon. Waxaynu tusnaynaa sida isbedelka aqoontu u muuqan karto luuqadaha la xiriira oo ay ku qoran karto muuqashada morphologiga, phonolojiga iyo ortografiga.', 'ro': 'Pentru limbile cu morfologie complexă, traducerea cuvânt-la-cuvânt este o sarcină cu diverse aplicații potențiale, de exemplu, în recuperarea informațiilor, instruirea limbii și crearea dicționarului, precum și în traducerea automată. În această lucrare, ne limităm la subsarcina alinierii caracterelor pentru cazul particular al familiilor de limbi conexe cu foarte puține resurse pentru majoritatea sau toți membrii. Există multe astfel de familii; Ne concentrăm asupra subgrupului de limbi semite vorbite în Etiopia și Eritreea. Începem cu o adaptare a algoritmilor de aliniere familiarizați din spatele traducerii automate statistice, modificându-i în funcție de sarcina noastră. Vă arătăm cum alinierea caracterului poate dezvălui corespondențe morfologice, fonologice și ortografice între limbile conexe.', 'sr': 'Za jezike sa kompleksnom morfologijom, prevod riječi na riječ je zadatak sa različitim potencijalnim aplikacijama, na primjer, u prikupljanju informacija, instrukcijama jezika i stvaranju rečnika, kao i u prevodu mašine. U ovom papiru se ograničavamo na podpitanje usklađenja karaktera za posebni slučaj porodice povezanih jezika sa većinom ili svim članovima vrlo malo resursa. Postoji mnogo takvih porodica. fokusiramo se na podskupu semitskih jezika govorenih u Etiopiji i Eritreji. Počeli smo sa adaptacijom poznatih algoritma usklađivanja iza prevoda statističkih mašina, izmijenjenjem ih kao odgovarajuće za naš zadatak. Pokazujemo kako poravnanje karaktera može otkriti morfološke, fonološke i ortografske dopisnice među povezanim jezicima.', 'sv': 'För språk med komplex morfologi är ord-till-ord översättning en uppgift med olika potentiella tillämpningar, till exempel i informationssökning, språkundervisning och ordboksskapande, samt i maskinöversättning. I denna uppsats begränsar vi oss till underuppgiften av karaktärsanpassning för det särskilda fallet av familjer av besläktade språk med mycket få resurser för de flesta eller alla medlemmar. Det finns många sådana familjer. Vi fokuserar på undergruppen av semitiska språk som talas i Etiopien och Eritrea. Vi börjar med en anpassning av de bekanta justeringsalgoritmerna bakom statistisk maskinöversättning och modifierar dem efter behov för vår uppgift. Vi visar hur karaktärsjustering kan avslöja morfologiska, fonologiska och ortografiska korrespondenser mellan besläktade språk.', 'ur': 'زبانوں کے لئے پیچیدہ موفولوژی کے ساتھ، کلمات سے کلمات کی ترجمہ مختلف امکانات کاربریوں کے ساتھ ایک تابع ہے، مثال، معلومات حاصل کرنے، زبان کی تعلیم، اور کلمات پیدا کرنے، اور ماشین ترجمہ میں بھی۔ اس کاغذ میں ہم اپنے آپ کو تعداد کے مطابق تعداد کے مطابق تعداد کے مطابق تعداد کے مطابق تعداد کے مطابق تعداد کے مطابق تعداد کے مطابق بہت کم منابع کے ساتھ محدود کرتے ہیں۔ ایسے بہت سے خاندان ہیں ہم ایٹیوپیا اور ایریتریا میں صحبت کی سیمیٹی زبانوں کے زیر گروپ پر تمرکز کرتے ہیں۔ ہم نے ایسٹیسٹیسی ماشین ترجمہ کے پیچھے پہچان ہونے والی الگوریٹمیوں کی تعمیر سے شروع کیا ہے، ان کو ہمارے کام کے لئے مناسب طور پر بدل دیتے ہیں. ہم نشان دیتے ہیں کہ کس طرح قابل تعمیر قابل تفریق، فرنولوژیکی اور ارٹوگرافیکی زبانوں کے درمیان کس طرح ظاہر کر سکتے ہیں۔', 'ta': 'சிக்கலான மொழிகளுடன் மொழிகளுக்கு, வார்த்தை- to- word மொழிமாற்றியமைப்பு பல்வேறு சாத்தியமான பயன்பாடுகளுடன் மொழிகளுக்கு, மொழி பயிற்சி மற்றும் அ இந்த காகிதத்தில், நாம் எழுத்து ஒழுங்குப்படுத்தும் துணை பணியில் அமைக்கிறோம் சில மொழிகளின் குடும்பத்திற்கு சிறிய இது போன்ற குடும்பங்கள் பல உள்ளன; எதியோபியா மற்றும் எரிட்ரியாவில் பேசிக் கொண்டிருக்கும் செமிடிக் மொழிகளின் துணை குழுவில்  We begin with an adaptation of the familiar alignment algorithms behind statistical machine translation, modifying them as appropriate for our task.  தொடர்புடைய மொழிகளுக்கிடையில் உள்ள எழுத்து ஒழுங்குப்படுத்தல் எப்படி காட்டுகிறது என்பதை நாம் காட்டுகிறோம்.', 'uz': "Name Bu hujjatda biz o'zimizni bir nechta ko'pchilik xususiyatlar uchun qo'llangan tillar oillarga bir xil qoidaga qaramamiz. Bu ko'p qo'llar bor; Biz Ethiopia va Eritreada gapiradigan Semitik tillarining tub guruhini foydalanamiz. Biz statistical mashinaning tarjimasining ортидан аниқланган algorithlarni tahrirlash bilan boshlamiz, ularni vazifa uchun o'zgartirishimiz kerak. Biz oddiy shaklning joylashishini ko'rsatishimiz mumkin, fonologisk va ortografik xizmatlari bilan bogʻ'liq tillarda qanday bogʻ'liq tarkibini koʻrsatish mumkin.", 'vi': 'Đối với ngôn ngữ có độ morphology phức tạp, Từ-to-Từ dịch là một nhiệm vụ với nhiều ứng dụng tiềm năng, ví dụ như, trong việc lấy thông tin, ngôn ngữ, và từ điển sáng tạo, cũng như trong dịch vụ máy. Trong tờ giấy này, chúng tôi chỉ đơn giản là yêu cầu sự phối hợp cá nhân trong trường hợp đặc biệt của các gia đình các ngôn ngữ liên quan với rất ít nguồn lực cho hầu hết hay tất cả các thành viên. Có rất nhiều gia đình như vậy. Chúng tôi tập trung vào nhóm vũ trụ tiếng Á Rập được phát ngôn ở Ethiopia và xoáy. Chúng ta bắt đầu bằng việc thích nghi các thuật toán thẳng hàng quen thuộc đằng sau việc dịch chuyển máy thống kê, sửa đổi chúng nếu thích hợp cho nhiệm vụ của chúng ta. Chúng tôi cho thấy cách việc sắp xếp các ký tự có thể tiết lộ liên kết về lịch sử, âm thanh và cấu hình.', 'bg': 'За езици със сложна морфология преводът от дума на дума е задача с различни потенциални приложения, например в извличането на информация, езиковото обучение и създаването на речници, както и в машинния превод. В тази статия се ограничаваме до подзадачата за подравняване на знаците за конкретния случай на семейства на сродни езици с много малко ресурси за повечето или всички членове. Има много такива семейства; Фокусираме се върху подгрупата семитски езици, говорещи в Етиопия и Еритрея. Започваме с адаптиране на познатите алгоритми за подравняване зад статистическия машинен превод, като ги модифицираме според нашата задача. Показваме как подреждането на знаците може да разкрие морфологични, фонологични и ортографски кореспонденции между сродните езици.', 'nl': 'Voor talen met een complexe morfologie is woord-tot-woord vertaling een taak met verschillende potentiële toepassingen, bijvoorbeeld bij het ophalen van informatie, taalinstructie en woordenboek creatie, evenals bij machinevertaling. In dit artikel beperken we ons tot de subtaak van karakteruitlijning voor het specifieke geval van families van verwante talen met zeer weinig middelen voor de meeste of alle leden. Er zijn veel van zulke families; We richten ons op de subgroep Semitische talen die in Ethiopië en Eritrea gesproken worden. We beginnen met een aanpassing van de bekende uitlijningsalgoritmen achter statistische machinevertaling, die aangepast worden aan onze taak. We laten zien hoe karakteruitlijning morfologische, fonologische en orthografische correspondentie tussen verwante talen kan onthullen.', 'da': 'For sprog med kompleks morfologi er ord-til-ord oversættelse en opgave med forskellige potentielle applikationer, for eksempel i informationssøgning, sprogundervisning og ordbogsoprettelse samt i maskinoversættelse. I denne artikel begrænser vi os til underopgaven af karakter justering for det særlige tilfælde af familier af beslægtede sprog med meget få ressourcer for de fleste eller alle medlemmer. Der er mange sådanne familier. Vi fokuserer på undergruppen af semitiske sprog, der tales i Etiopien og Eritrea. Vi begynder med en tilpasning af de velkendte justeringsalgoritmer bag statistisk maskinoversættelse og ændrer dem efter vores opgave. Vi viser, hvordan karakter justering kan afsløre morfologiske, fonologiske og ortografiske korrespondancer blandt beslægtede sprog.', 'hr': 'Za jezike sa složenom morfologijom, prevod riječi na riječ je zadatak s različitim potencijalnim aplikacijama, na primjer, u prikupljanju informacija, instrukcijama jezika i stvaranju rečnika, kao i u prevodu strojeva. U ovom papiru, mi se ograničavamo na podpitanje usklađenja karaktera za posebni slučaj obitelji povezanih jezika sa većinom ili svim članovima vrlo malo resursa. Postoji mnogo takvih obitelji; fokusiramo se na podskupu semitskih jezika govorenih u Etiopiji i Eritreji. Počinjemo s adaptacijom poznatih algoritma usklađivanja iza prevoda statističkih strojeva, izmijenjenjem ih u odgovarajućem smislu za naš zadatak. Pokazujemo kako poravnanje karaktera može otkriti morfološke, fonološke i ortografske dopisnice među povezanim jezicima.', 'de': 'Für Sprachen mit komplexer Morphologie ist die Wort-zu-Wort-Übersetzung eine Aufgabe mit vielfältigen Anwendungsmöglichkeiten, z.B. im Informationsabruf, Sprachunterricht und Wörterbucherstellung sowie in der maschinellen Übersetzung. In diesem Beitrag beschränken wir uns auf die Teilaufgabe der Zeichenausrichtung für den speziellen Fall von Familien verwandter Sprachen mit sehr wenigen Ressourcen für die meisten oder alle Mitglieder. Es gibt viele solche Familien; Wir konzentrieren uns auf die Untergruppe semitischer Sprachen, die in Äthiopien und Eritrea gesprochen werden. Wir beginnen mit einer Anpassung der bekannten Alignment Algorithmen hinter der statistischen maschinellen Übersetzung und modifizieren sie entsprechend unserer Aufgabe. Wir zeigen, wie die Zeichenausrichtung morphologische, phonologische und orthographische Korrespondenzen zwischen verwandten Sprachen aufzeigen kann.', 'id': 'Untuk bahasa dengan morfologi kompleks, terjemahan kata-kata adalah tugas dengan berbagai aplikasi potensial, misalnya, dalam penerimaan informasi, instruksi bahasa, dan penciptaan kamus, serta dalam terjemahan mesin. Dalam kertas ini, kita membatasi diri kita pada subtask dari penyesuaian karakter untuk kasus tertentu keluarga bahasa yang berhubungan dengan sangat sedikit sumber daya untuk kebanyakan atau semua anggota. There are many such families;  kita fokus pada subkelompok bahasa Semitik yang dibicarakan di Ethiopia dan Eritrea. Kita mulai dengan adaptasi algoritma penyesuaian yang biasa di belakang terjemahan mesin statistik, mengubahnya sesuai dengan tugas kita. Kami menunjukkan bagaimana penyesuaian karakter dapat mengungkapkan korespondensi morfologi, fonologi, dan ortografik antara bahasa yang berhubungan.', 'ko': '복잡한 어법을 가진 언어에 대해 단어부터 단어까지의 번역은 각종 잠재적인 응용을 가진 임무이다. 예를 들어 정보 검색, 언어 교육, 사전 창설과 기계 번역 등이다.본고에서 우리는 문자가 일치하는 하위 임무에 국한되고 관련 어계의 특수한 상황에 대해 대다수 또는 모든 구성원에게 자원이 매우 적다.이런 가정이 많다.우리는 에티오피아와 에리트리아의 샤이족 언어에 주목한다.우리는 먼저 통계기계 번역 뒤에 익숙한 정렬 알고리즘을 조정하고 우리의 임무에 따라 그것들을 적절하게 수정한다.우리는 문자의 정렬이 관련 언어 간의 형태, 음성과 정자법의 대응 관계를 어떻게 보여주는지 보여 주었다.', 'fa': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in information retrieval, language instruction, and dictionary creation, as well as in machine translation. در این کاغذ، ما خودمان را به زیر خواسته\u200cی تعیین شخصیت برای پرونده\u200cهای ویژه خانواده\u200cهای زبان\u200cهای ارتباطی با بسیار کمی منابع برای بیشتر یا همه اعضا محدود می\u200cکنیم. چنین خانواده\u200cهای زیادی هستند. ما روی زیر گروه زبانهای سیمیتی که در اتیوپیا و اریتریا صحبت می کنند تمرکز می کنیم. ما با تغییر دادن الگوریتم های تغییر مشهور پشت ترجمه ماشین آمار شروع می کنیم و آنها را به اندازه مناسب برای کار ما تغییر می دهیم. ما نشان می دهیم که چگونه تنظیم شخصیت می تواند نسبت\u200cهای مورفولژیک، فون\u200cشناسی و ارتوگرافیک بین زبان\u200cهای مربوط به نشان دهد.', 'sw': 'Kwa lugha zenye utafsiri wa maneno yenye utata mkubwa, utafsiri wa maneno na maneno ni kazi yenye matumizi mbalimbali, kwa mfano, katika upatikanaji wa taarifa, elimu ya lugha, na ubunifu wa lugha, pamoja na katika tafsiri ya mashine. Katika karatasi hii, tunajiweka kwenye jukumu la kujipanga kwa ajili ya kesi maalum ya familia za lugha zinazohusiana na rasilimali chache kwa wengi au wanachama wote. Kuna familia nyingi kama hizo; tunajikita kwenye kikundi cha lugha za Semitic zinazozungumzwa nchini Ethiopia na Eritrea. Tunaanza na kubadilisha algorithi zilizofahamika nyuma ya tafsiri ya mashine ya takwimu, kubadilisha kwa ajili ya kazi yetu. Tunaonyesha jinsi ambavyo usambazaji wa tabia unavyoweza kuonyesha mawasiliano ya kifolojia, kifolojia na kiografia kati ya lugha zinazohusiana.', 'af': "Vir tale met kompleks morfologie is 'n taak met verskeie potensiele toepassings, byvoorbeeld, in inligting ontvang, taal instruksie en woordeboek skep, en ook in masjien vertaling. In hierdie papier, ons beperk ons ons aan die ondersteun van karakter-alignering vir die spesifieke geval van geslagte van verwante tale met baie paar hulpbronne vir meeste of alle lede. Daar is baie sodanige geslagte; ons fokus op die subgroep van Semitiese tale wat in Etiopia en Eritrea gespreek is. Ons begin met 'n aanpassing van die gewone uitlyn algoritme agter statistiese masjien vertaling, om hulle as geskikte vir ons taak te verander. Ons wys hoe karakter-lyning morfologiese, fonologiese en ortografiese ooreenstemmings onder verwante tale kan vertoon.", 'tr': 'Karmaşık morfologiýa bilen diller üçin, söz-täze-söz terjime edilen işlemler üçin bir täblidir, meselâ, maglumatlary almak üçin, dil gururum we sözlük bejermek üçin we makine terjime edendir. Bu kagyzda, biz öz-özümizi karakter dilleriniň iň köpüsi ýa-da ähli agzalaryň maşgalalaryň has kiçi çeşmeleri bilen çykarýarys. Şonuň ýaly maşgalasy köp bar; Etiopiýa we Eritreýada gürleýän Semitik dillerin alt grupyna üns berýäris. Biz statistik maşynyň terjimesiniň arkasynda tanyş çyzyglama algoritmalarynyň adaptasyyla başladyk we olaryň işimiz üçin gerekli ýagdaýyny üýtgedik. Biz karakter çyzygynyň morfolojik, fonolojik we ortografiýasy dilleriň arasynda nähili görkezilmesini görkezip bilýäris.', 'sq': 'Për gjuhët me morfologji komplekse, përkthimi fjalë-fjalë është një detyrë me aplikime të ndryshme të mundshme, për shembull, në marrjen e informacionit, mësimin e gjuhës dhe krijimin e fjalorit si dhe në përkthimin e makinave. Në këtë letër, ne kufizojmë veten në nënkërkesën e përshtatjes së karakterit për rastin e veçantë të familjeve të gjuhëve të lidhura me shumë pak burime për shumicën apo të gjithë anëtarët. Ka shumë familje të tilla; ne përqëndrohemi në nëngrupin e gjuhëve semitike të folura në Etiopi dhe Eritrea. Ne fillojmë me një përshtatje të algoritmeve të njohura të përshtatjes pas përkthimit të makinave statistike, duke i modifikuar ato si të përshtatshme për detyrën tonë. Ne tregojmë se si rregullimi i karakterit mund të zbulojë korrespondenca morfologjike, fonologjike dhe ortografike midis gjuhëve të lidhura.', 'am': 'ለቋንቋዎች በተጨማሪው morphology፣ ቃላት-to-word ትርጉም በተለያዩ ፕሮግራሞች ላይ የሚደረገው ስራ ነው፤ ምሳሌ በተለየ መረጃ ማግኘት፣ ቋንቋ ትምህርት እና የመዝገብ ትርጉም እና በመሳሻዊ ትርጉም ነው፡፡ በዚህ ገጽ፣ ለብዙዎቹ ወይም ለሁሉም ብልቶች የተለየ የቋንቋዎች ቤተሰቦች ባለጠቅላላ ሀብት እናስገራለን፡፡ እንደዚህ ብዙ ወገኖች አሉ በኢትዮጵያ እና ኤርትራ በተናገሩት የሴሜቲክ ቋንቋዎች አቅራቢያ ላይ እናስጠጋለን፡፡ በአውቀው መሳሳይ መተርጓሜ በኋላ እናሳውቃለን፡፡ የግንኙነት ቋንቋዎች መካከል የሞሮፎሎጂ፣ ፎሎጂካዊ እና የኦሮግራፍ ግንኙነት እንዴት እንደሚገልጥ እናሳያቸዋለን፡፡', 'az': 'Komplik morfoloji ilə dillər üçün, sözlər-sözlər tercüməsi müxtəlif potensial proqramlar ilə, məsələn, məlumatlar almaq, dil öyrənmək və sözlük yaratmaq və maşın tercüməsi ilə birlikdə işlədir. Bu kağızda, çox ya da bütün üyelər üçün çox az mənfəətlər olan dillərin ailələrinin müəyyən edilməsi üçün özümüzü əlavə etdik. Bütün bu ailələr çox var. Etiopia və Eritreyada danışan Semitik dillərin altqrupuna odaklanırıq. Biz statistik makinatın tercümünün arkasındaki tanıdıqların algoritminin uyğunlaşdırmasıyla başlayırıq, onları bizim işimizə uyğun olaraq dəyişdiririk. Biz karakterlərin tərəflənməsinin, fonolojik və ortografik dillərin arasındakı məlumatları necə göstərə biləcəyini göstəririk.', 'hy': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in information retrieval, language instruction, and dictionary creation, as well as in machine translation.  Այս թղթի մեջ մենք սահմանափակում ենք ինքներս մեզ բնավորության հարմարեցման ենթախնդիրը հարաբերված լեզուների ընտանիքների հատուկ դեպքում, որտեղ շատ քիչ ռեսուրսներ ունեն մեծ մասի կամ բոլոր անդամների համար: Շատ այդպիսի ընտանիքներ կան, մենք կենտրոնանում ենք Սեմիտիկ լեզուների ենթախմբին, որը խոսում է Էթիոպիայում և Էրիտրեայում: Մենք սկսում ենք ծանոթ հարմարեցման ալգորիթմների հարմարեցման հետ վիճակագրական մեքենայի թարգմանման հետևում, փոխելով դրանք համապատասխան մեր խնդրի համար: We show how character alignment can reveal morphological, phonological, and orthographic correspondences among related languages.', 'bn': 'বিভিন্ন সম্ভাব্য অ্যাপ্লিকেশনগুলোর মধ্যে কমপ্লিক্স মোর্ফোলোজির ভাষার জন্য শব্দ-থেকে শব্দ অনুবাদ, যেমন তথ্য পুনরুদ্ধার, ভাষা শিক এই কাগজটিতে আমরা নিজেদের সাবক্রিয় করে রাখি সংস্পর্শের পরিবারের বিশেষ ক্ষেত্রে যারা সংশ্লিষ্ট ভাষার পরিবারের ক্ষে এরকম অনেক পরিবার আছে; আমরা ইথিওপিয়া এবং এরিত্রিয়ায় কথা বলা সেমিটিক ভাষার সাবগ্রুপে মনোযোগ দিচ্ছি। আমরা পরিসংখ্যান মেশিন অনুবাদের পেছনে পরিচিত অ্যালগরিদমের অ্যাডাপেটশন শুরু করি, আমাদের কাজের জন্য যথাযথ পরিবর্তন করি। আমরা দেখাচ্ছি কিভাবে অক্ষরের সাথে মোরফোলিজিক, ফোলোজিক্যাল এবং সংশ্লিষ্ট ভাষার মধ্যে আরোটোগ্রাফিক সংস্ক', 'bs': 'Za jezike sa kompleksnom morfologijom, prevod riječi na riječ je zadatak sa različitim potencijalnim aplikacijama, na primjer, u prikupljanju informacija, instrukcijama jezika i stvaranju rečnika, kao i u prevodu strojeva. U ovom papiru se ograničavamo na podpitanje usklađenja karaktera za posebni slučaj porodice povezanih jezika sa većinom ili svim članovima vrlo malo resursa. Postoji mnogo takvih porodica. fokusiramo se na podskupu semitskih jezika govorenih u Etiopiji i Eritreji. Počinjemo sa adaptacijom poznatih algoritma usklađenja iza prevoda statističkih strojeva, modificiranjem ih u odgovarajućem smislu za naš zadatak. Pokazujemo kako poravnanje karaktera može otkriti morfološke, fonološke i ortografske dopisnice među povezanim jezicima.', 'ca': "Per a les llengües amb morfologia complexa, la traducció de paraules a paraules és una tasca amb diverses aplicacions potencials, per exemple, en la recuperació d'informació, l'instrucció de llengües i la creació de diccionaris, així com en la traducció màquina. En aquest paper, ens limitam a la subtema de l'allinjament de caràcters per al cas concret de famílies de llengües relacionades amb molt pocs recursos per a la majoria o tots els membres. Hi ha moltes d'aquestes famílies; ens centrem en el subgrup de llengües semitiques parlades a Etiòpia i Eritrea. Comencem amb una adaptació dels algoritmes d'alliniament familiar darrere de la traducció estadística de màquines, modificant-los com sigui apropiat per a la nostra tasca. Mostrem com l'allinjament de caràcters pot revelar corresponències morfològiques, fonològiques i ortogràfiques entre les llengües relacionades.", 'cs': 'U jazyků se složitou morfologií je slovo-slovo překlad úkolem s různými potenciálními aplikacemi, například při vyhledávání informací, výuce jazyka a tvorbě slovníků, stejně jako při strojovém překladu. V tomto článku se omezujeme na podúkol zarovnání znaků pro konkrétní případ rodin příbuzných jazyků s velmi málo zdrojů pro většinu či všechny členy. Existuje mnoho takových rodin; Zaměřujeme se na podskupinu semitských jazyků mluvících v Etiopii a Eritreji. Začínáme adaptací známých algoritmů zarovnávání statistického strojového překladu a upravujeme je podle našeho úkolu. Ukážeme, jak zarovnání znaků může odhalit morfologické, fonologické a ortografické korespondence mezi příbuznými jazyky.', 'et': 'Keerulise morfoloogiaga keelte puhul on sõnast sõnasse tõlkimine mitmesuguste potentsiaalsete rakendustega ülesanne, näiteks infohankimises, keeleõppes ja sõnastiku loomises ning masintõlkes. Käesolevas dokumendis piirdume tähemärkide ühtlustamise alamülesandega konkreetsel juhul sugulaskeelte perekondade puhul, kus enamiku või kõigi liikmete jaoks on väga vähe ressursse. Selliseid peresid on palju; Me keskendume Etioopias ja Eritreas räägitavate semiitlike keelte alarühmale. Alustame tuttavate statistilise masintõlke algoritmide kohandamisega, muutes neid vastavalt meie ülesandele. Näitame, kuidas märkide joondamine võib paljastada morfoloogilisi, fonoloogilisi ja ortograafilisi vastavusi seotud keelte vahel.', 'fi': 'Monimutkaisen morfologian kielillä sanakäännös on tehtävä, jolla on erilaisia sovelluksia esimerkiksi tiedonhaussa, kieliopetuksessa ja sanakirjojen luomisessa sekä konekäännöksessä. Tässä artikkelissa rajoitumme alatehtävään, joka koskee merkkien yhdenmukaistamista tietyssä tapauksessa sukulaiskielten perheitä, joilla on hyvin vähän resursseja useimmille tai kaikille jäsenille. Tällaisia perheitä on monia. Keskitymme Etiopiassa ja Eritreassa puhuttujen seemiläisten kielten alaryhmään. Aloitamme tilastollisen konekäännöksen taustalla olevien tuttujen linjausalgoritmien mukauttamisesta ja muokkaamme niitä tehtäväämme sopivasti. Osoitamme, miten merkkien kohdistaminen voi paljastaa morfologisia, fonologisia ja ortografisia vastaavuuksia sukulaiskielten välillä.', 'he': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in information retrieval, language instruction, and dictionary creation, as well as in machine translation.  בעיתון הזה, אנחנו מגבלים את עצמנו לתת-שאלה של התאמה של אופיים למקרה מסוים של משפחות שפות קשורות עם משאבים מעטים מאוד לרוב או לכל חברים. יש הרבה משפחות כאלה; אנחנו מתמקדים בתי-קבוצת שפות סמיטיות שדיברו באתיופיה ואיריטריה. אנו מתחילים עם התאמה של האלגוריתמים המפורסמים מאחורי התרגום של מכונות סטטיסטיות, שינוי אותם כפי שהתאים למשימה שלנו. אנו מראים כיצד התאמת אופיים יכולה לחשוף תואמות מורפולוגיות, פונולוגיות ואורתוגרפיות בין שפות קשורות.', 'ha': "@ info: whatsthis Ga wannan takardan, Munã ɗauki kanmu zuwa masu bin aikin sarrafi na masu hususan da wasu mutane na lugha masu hususan da kuma masu kami kaɗan ko dukansu. Kuna da jama'a mãsu yawa; tuna makini cikin sunayen Semitic da ake faɗa a cikin Ethiopia da Ethiopia. Tuna fara da adaptori na algoritun masu daidaita da aka sani baka fassarar masu ƙarami, kuma za'a gyara su kamar yadda ya kamata wa aikin mu. Tuna nũna jinin juyi na takardar, za'a iya nuna masu mutane na morfologi, folojiki da ortofogi cikin lugha masu husũma.", 'sk': 'Za jezike s kompleksno morfologijo je prevajanje besed v besedo naloga z različnimi potencialnimi aplikacijami, na primer pri pridobivanju informacij, jezikovnem poučevanju in ustvarjanju slovarjev ter strojnem prevajanju. V tem prispevku se omejimo na podnalogo usklajevanja znakov za poseben primer družin sorodnih jezikov z zelo malo virov za večino ali vse člane. Obstaja veliko takih družin; Osredotočamo se na podskupino semitskih jezikov, ki se govorijo v Etiopiji in Eritreji. Začnemo s prilagoditvijo znanih algoritmov poravnave za statističnim strojnim prevajanjem in jih prilagodimo, kot je primerno za našo nalogo. Prikazujemo, kako lahko poravnavanje znakov razkrije morfološke, fonološke in ortografske korespondence med sorodnimi jeziki.', 'jv': 'Tulung langkung karo mpungan no, word-to-word terjamahan kuwi nggawe aplikasi sing paling apik, sampeyan karo informasi nggawe kelas, nggunakake luwih lan kelas nggawe stampen, tambah apik karo terjamahan. Awak dhéwé, ngêpêngé awak dhéwé nggawe gerakan kanggo nggawe cara nggawe kanggo kalah wong liyane wong liyane karo akeh barang pengguna kanggo awak dhéwé, lan akeh wong liyane. Kayané akèh sing sampeyan éwé; kaya kuwi, Awakdhéwé éntukno karo kapan kelas semitik kanggo masalan ning EtiOpi karo Ertriya. Awak dhéwé mulai ngono alamat karo nesaturan alignment Algorithm sing dikutuhke dolanan karo ingkang dolanan popisuk, nggawe ngubah dhéwé nggawe task. Awake tresnaning', 'bo': 'For languages with complex morphology, word-to-word translation is a task with various potential applications, for example, in information retrieval, language instruction, and dictionary creation, as well as in machine translation. ཤོག་བྱང་འདིའི་ནང་དུ། ང་ཚོས་རང་ཉིད་ལ་ཡིག འདི་ལྟ་བུའི་བཟའ་ཚང་མང་པོ་ཡོད། ང་ཚོས་ཨེ་ཐོ་པི་དང་ཨེ་རི་ཊི་རི་ཡ་(Ethiopia)ནང་སྐད་ཆ་མཚོན་པའི་སྐད་ཆ་ཚོའི་གོ་ཁག་གི་གནད་དོན་དག་ལ་བསྟ ང་ཚོས་རྩིས་འཁོར་གྱི་རྗེས་སུ་ཆོས་ཉིད་གྲངས་སྒྲིག་གི་གྲངས་སྒྲིག་ཆ་གྲངས་སྒྲིག ང་ཚོས་ཡིག་འབྲུ་གི་གྲལ་སྒྲིག་མཐོང་ནི་ཇི་ལྟར་ཡག'}
{'en': 'Bilingual Lexicon Induction across Orthographically-distinct Under-Resourced Dravidian Languages', 'ar': 'تحريض المعجم ثنائي اللغة عبر لغات Dravidian المتميزة من الناحية الهجائية قليلة الموارد', 'pt': 'Indução de léxico bilíngue em línguas dravidianas com poucos recursos ortograficamente distintas', 'es': 'Inducción de léxico bilingüe en lenguas dravídicas ortográficamente distintas y con escasos recursos', 'fr': 'Induction du lexique bilingue dans les langues dravidiennes sous-ressources distinctes du point de vue orthographique', 'ja': 'バイリンガルレキシコン誘導-正書法で区別される、資源不足のドラヴィダ語', 'zh': '跨正字法上异资贫乏达罗毗荼语双语词典归', 'hi': 'ऑर्थोग्राफिक रूप से अलग-अलग अंडर-रिसोर्स्ड द्रविड़ भाषाओं में द्विभाषी शब्दकोश प्रेरण', 'ru': 'Индукция двуязычного лексикона для различных ортографически различающихся дравидийских языков с недостаточным объемом ресурсов', 'ga': 'Ionduchtú Foclóir Dátheangach thar Theangacha Dravidian atá ar leith ó thaobh Ortagrafach de Gann-Acmhainní', 'ka': 'ორტოგრაფიკურად განსხვავებული სახელსაწყოთა სახელსაწყოთა სახელსაწყოთა სახელსაწყოთა ელექსიკონის ინდუქცია', 'el': 'Διγλωσσή επαγωγή λεξικού σε ορθογραφικά διακριτές δραβιδικές γλώσσες που δεν διαθέτουν πόρους', 'hu': 'Kétnyelvű lexikon indukció ortográfiailag különböző, alulfeszített dravidi nyelveken', 'it': 'Induzione lessicale bilingue attraverso le lingue dravidiane sottorisorse ortografiche distinte', 'kk': 'Дравидиялық тілдерді ортографикалық түрлендірген екі лексикалық индукциясы', 'lt': 'Dvikalbė leksikono indukcija įvairiose ortografiškai atskirose nepakankamai išteklių dravidinėse kalbose', 'mk': 'Дивјазична индукција на лексикони низ правописно различни дравидски јазици со недоволни ресурси', 'ms': 'Induksi Lexikon Bilingual melintasi Bahasa Dravidian Bawah Sumber yang berbeza secara ortografik', 'mt': 'L-Induzzjoni Bilingwali tal-Lexicon f’Lingwi Dravidi Ortografikament distinti b’Riżorsi Żgħar', 'ml': 'ബില്\u200dലിങ്കുള്ള ലെക്സിക്കോണ്\u200d ഇന്\u200dഡിക്ഷന്\u200d ഓര്\u200dട്ടോഗ്രാഫിക്കല്\u200d വ്യത്യസ്തമായി താഴെ വിഭവങ്ങള്\u200d ഡ്രാവിഡിയന്\u200d ഭ', 'mn': 'Хоёр дахин сэтгэл хөдлөл ортографик өөрчлөгдсөн Дравидийн хэл дээр хоёр дахин сэтгэл хөдлөл', 'no': 'Bildige leksjonske induksjon over ortografisk-skilnande underressurserte dravidianske språk', 'pl': 'Indukcja dwujęzycznego leksykonu w ortograficznie odrębnych językach drawidyjskich', 'ro': 'Inducția bilingvă a lexiconului în limbile dravidiene subrezistente ortografic distincte', 'sr': 'Bilingualna leksička indukcija preko pravografski različitih podresursnih dravidijskih jezika', 'si': 'බිලින්ගුල් ලෙක්සිකෝන් ඉන්ඩුක්ෂන් විශේෂ විශේෂ විශේෂ විශේෂ වලින්', 'so': 'Luqada Bilingual Lexicon Induction across Orthographically-distinct Under-Resourced Dravidian Languages', 'sv': 'Tvåspråkig Lexikon Induktion över ortografiskt distinkta underresourcerade dravidiska språk', 'ta': 'பில்லிங்கல் லெக்சிகோன் செயல்பாடு நிரல்படமாக- வேறுபட்ட கீழ்- மூலமாக்கப்பட்ட ட ட்ராவிடியன் மொழிகள்', 'ur': 'اورٹوگرافیکی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح کی زبانیں', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'bg': 'Двуезична лексиконна индукция в ортографски различни дравидски езици с недостатъчно ресурси', 'hr': 'Bilingualna leksička indukcija na pravoslavnom različitim dreviđanskim jezicima pod resursima', 'da': 'Tosproget Lexikon Induktion på tværs af ortografisk forskellige underresourcerede dravidiske sprog', 'id': 'Induksi Lexikon Bilingual melalui Bahasa Dravidia yang berbeda secara ortografik', 'ko': '자원이 부족한 델라비아어의 이중 언어 어휘 귀납', 'fa': 'زبان\u200cهای درویدیی زیر منبع متفاوت و متفاوت\u200c', 'sw': 'Ujengo wa Lexico wa lugha za Kiasili katika lugha za Ki-Dravidi', 'af': 'Dubbelde Leksiese Induksie oor Ortografiese-ondersteunde Dravidiële Taal', 'nl': 'Tweetalige Lexicon Inductie in Orthografisch onderscheiden Dravidische talen met onvoldoende middelen', 'de': 'Zweisprachige Lexikon-Induktion in orthographisch getrennten dravidischen Sprachen', 'tr': 'Ortografiýan Taýdan Aşary Çykar Leksikaň Induksyzlyky', 'sq': 'Bilingual Lexicon Induction across Orthographically-distinct Under-Resourced Dravidian Languages', 'am': 'ቋንቋ', 'az': 'Ortografik-f…ôrqli D…ôrvid Dill…ôrinin Ortografiki ńįkinci Lexicon Induction', 'hy': 'Երկուլեզու լեքսիկոնի ինդուկցիան առանց ռեսուրսների ունեցող գրաֆիկապես տարբեր գրաֆիկական լեզուներում', 'bn': 'সারা অর্থোগ্রাফিক্যালিক ভাষায় বিলিঙ্গুয়াল লেক্সিকোন নির্মাণ', 'bs': 'Bilingualna leksička indukcija na pravografski različitim dreviđanskim jezicima pod resursima', 'cs': 'Indukce dvojjazyčného slovníku napříč ortograficky odlišnými dravidskými jazyky s nedostatečnými zdroji', 'ca': "L'Inducció Bilingual de Lexicons a través de llengües dravídiques sense recursos ortogràfics distints", 'et': 'Kahekeelse leksikoni induktsioon ortograafiliselt erinevates alaressurssidega dravidia keeltes', 'fi': 'Kaksikielinen leksikonininduktio ortodografisesti erillisillä vajaakäyttöisillä dravidialaisilla kielillä', 'ha': 'KCharselect unicode block name', 'jv': 'structural navigation', 'sk': 'Dvojezična leksikonska indukcija v ortografsko različnih dravidskih jezikih s premalo virov', 'he': 'תוכנית לקסיקון משולשת ברחבי שפות דראבידיות מתחת למשאבים אורתוגרפיים', 'bo': 'རྨང་གཞུང་གི་སྒུལ་རྒྱས་ཐག་གཟུགས་འགྱུར་བའི་སྐད་རིགས་ཀྱི་ནང་ནས་མཐོང་ནུས་པ།'}
{'en': 'Bilingual lexicons are a vital tool for under-resourced languages and recent state-of-the-art approaches to this leverage pretrained monolingual word embeddings using supervised or semi-supervised approaches. However, these approaches require cross-lingual information such as seed dictionaries to train the model and find a ', 'ar': 'تعد المعاجم ثنائية اللغة أداة حيوية للغات قليلة الموارد والأساليب الحديثة الحديثة لهذا النفوذ من عمليات دمج الكلمات أحادية اللغة التي يتم تدريبها مسبقًا باستخدام مناهج خاضعة للإشراف أو شبه خاضعة للإشراف. ومع ذلك ، تتطلب هذه الأساليب معلومات عبر اللغات مثل القواميس الأولية لتدريب النموذج والعثور على تحويل خطي بين كلمة مسافات التضمين. خاصة في حالة اللغات منخفضة الموارد ، لا تتوفر قواميس البذور بسهولة ، وعلى هذا النحو ، تنتج هذه الطرق نتائج ضعيفة للغاية في هذه اللغات. في هذا العمل ، نركز على اللغات Dravidian ، وهي التاميل والتيلوجو والكانادا والمالايالامية ، والتي تعتبر أكثر صعوبة لأنها مكتوبة بنصوص فريدة. للاستفادة من المعلومات الإملائية وما شابهها في هذه اللغات ، نقوم بإحضار اللغات ذات الصلة في نص واحد. استخدمت المناهج السابقة مقاييس غير مثالية لغويًا مثل مسافة تحرير Levenshtein لاكتشاف المتشابهين ، حيث نثبت أن أطول تسلسل فرعي مشترك يكون أكثر منطقية من الناحية اللغوية ويحسن أداء تحريض المعجم ثنائي اللغة. نظهر أن نهجنا يمكن أن يزيد من دقة طرق تحريض المعجم ثنائي اللغة على هذه اللغات عدة مرات ، مما يجعل مناهج تحريض المعجم ثنائي اللغة مجدية لمثل هذه اللغات منخفضة الموارد.', 'fr': "Les lexiques bilingues sont un outil essentiel pour les langues sous-financées et les approches récentes de pointe à cet égard s'appuient sur des intégrations de mots monolingues préentraînées utilisant des approches supervisées ou semi-supervisées. Cependant, ces approches nécessitent des informations multilingues telles que des dictionnaires de base pour entraîner le modèle et trouver une transformation linéaire entre les espaces d'inclusion de mots. En particulier dans le cas de langues à faibles ressources, les dictionnaires de semences ne sont pas facilement disponibles et, en tant que telles, ces méthodes produisent des résultats extrêmement faibles sur ces langues. Dans ce travail, nous nous concentrons sur les langues dravidiennes, à savoir le tamoul, le télougou, le kannada et le malayalam, qui sont encore plus difficiles car elles sont écrites dans des scripts uniques. Pour tirer parti des informations orthographiques et des apparentés dans ces langues, nous regroupons les langues associées dans un script unique. Les approches précédentes utilisaient des mesures linguistiquement sous-optimales telles que la distance d'édition de Levenshtein pour détecter les apparentés, ce qui nous permet de démontrer que la sous-séquence commune la plus longue est linguistiquement plus saine et améliore les performances de l'induction du lexique bilingue. Nous montrons que notre approche peut augmenter la précision des méthodes d'introduction du lexique bilingue sur ces langues à de nombreuses reprises, ce qui rend les approches d'introduction de lexique bilingue réalisables pour ces langues sous-financées.", 'pt': 'Os léxicos bilíngues são uma ferramenta vital para idiomas com poucos recursos e abordagens recentes de última geração para alavancar incorporações de palavras monolíngues pré-treinadas usando abordagens supervisionadas ou semi-supervisionadas. No entanto, essas abordagens exigem informações em vários idiomas, como dicionários de sementes, para treinar o modelo e encontrar uma transformação linear entre os espaços de incorporação de palavras. Especialmente no caso de idiomas com poucos recursos, os dicionários semente não estão prontamente disponíveis e, como tal, esses métodos produzem resultados extremamente fracos nesses idiomas. Neste trabalho, focamos nas línguas dravidianas, nomeadamente tâmil, télugo, canarês e malaiala, que são ainda mais desafiadoras por serem escritas em scripts únicos. Para aproveitar as informações ortográficas e cognatos nesses idiomas, reunimos os idiomas relacionados em um único script. Abordagens anteriores usaram medidas linguisticamente sub-ótimas, como a distância de edição Levenshtein para detectar cognatos, por meio do qual demonstramos que a subsequência comum mais longa é linguisticamente mais sólida e melhora o desempenho da indução de léxico bilíngue. Mostramos que nossa abordagem pode aumentar a precisão dos métodos de indução de léxico bilíngue nessas línguas muitas vezes, tornando as abordagens de indução de léxico bilíngue viáveis para essas línguas com poucos recursos.', 'es': 'Los léxicos bilingües son una herramienta vital para los idiomas con pocos recursos y los enfoques recientes de vanguardia para ello aprovechan la inserción de palabras monolingües preentrenadas mediante enfoques supervisados o semisupervisados. Sin embargo, estos enfoques requieren información multilingüe, como diccionarios de semillas, para entrenar el modelo y encontrar una transformación lineal entre los espacios de incrustación de palabras. Especialmente en el caso de los idiomas con pocos recursos, los diccionarios semilla no están disponibles fácilmente y, como tales, estos métodos producen resultados extremadamente débiles en estos idiomas. En este trabajo, nos centramos en los idiomas dravídicos, a saber, el tamil, el telugu, el kannada y el malayalam, que son aún más desafiantes, ya que están escritos en escrituras únicas. Para aprovechar la información ortográfica y los cognados en estos idiomas, incorporamos los idiomas relacionados en un solo alfabeto. Los enfoques anteriores han utilizado medidas lingüísticamente sub-óptimas, como la distancia de edición de Levenshtein para detectar cognados, por lo que demostramos que la subsecuencia común más larga es lingüísticamente más sólida y mejora el rendimiento de la inducción de léxico bilingüe. Demostramos que nuestro enfoque puede aumentar la precisión de los métodos bilingües de inducción de léxico en estos idiomas muchas veces, lo que hace que los enfoques de inducción de léxico bilingüe sean factibles para idiomas de escasos recursos.', 'ja': 'バイリンガル辞書は、リソース不足の言語にとって重要なツールであり、この事前に訓練された単語埋め込みを利用するための最新のアプローチは、監督されたアプローチまたは半監督されたアプローチを使用します。 しかしながら、これらのアプローチは、モデルを訓練し、単語埋め込み空間間の線形変換を見つけるために、シード辞書などのクロスリンガル情報を必要とする。 特にリソースの少ない言語の場合、シード辞書は容易に入手できないため、これらの方法はこれらの言語に極めて弱い結果をもたらします。 本作では、ドラヴィダ語派の言語、すなわちタミル語、テルグ語、カンナダ語、マラヤーラム語に焦点を当てています。これらの言語は独特の文字で書かれているため、さらに困難です。 これらの言語のオルソグラフィ情報とコグネイトを活用するために、関連する言語を1つのスクリプトにまとめます。 これまでのアプローチは、同族関係を検出するためにLevenshtein編集距離などの言語学的に最適以下の尺度を使用しており、それによって、最も長い一般的なサブシーケンスが言語学的により健全であり、バイリンガル辞書誘導のパフォーマンスを改善することを実証している。 私たちのアプローチは、これらの言語でのバイリンガル辞書帰納法の精度を何度も高めることができ、そのような資源不足の言語でバイリンガル辞書帰納法を実現可能にすることを示しています。', 'zh': '双语词典者,资源贫乏语言之要具,近最先进之法用监督或半监督之法预练单语词嵌。 然须跨语信息(如种子字典)以练模形,寻单词嵌空线性易之。 特于资源匮乏之言,种子词典不易得,故其法极微弱。 注于达罗毗荼语,即泰米尔语,泰卢固语,卡纳达语马拉雅拉姆语,以特脚本编之,故更具挑战性。 因此语中正字法息同源词,整合入一脚本中。 前法用语言前优之量,如Levenshtein辑去以检同源词,以此证最长者公共子序于言,而重双语词典归之性也。 吾法可数增其言语之双语词典归其准确性,使双语词典归之可也。', 'ru': 'Двуязычные лексиконы являются жизненно важным инструментом для языков, не обеспеченных достаточными ресурсами, и последних современных подходов к этому использованию предварительно подготовленных одноязычных вложений слов с использованием контролируемых или полуконтролируемых подходов. Однако эти подходы требуют кросс-лингвистической информации, такой как словари семян, чтобы обучить модель и найти линейное преобразование между пространствами вложения слов. Особенно в случае языков с ограниченными ресурсами, семенные словари не всегда доступны, и поэтому эти методы дают крайне слабые результаты по этим языкам. В этой работе мы фокусируемся на дравидийских языках, а именно тамильском, телугу, каннада и малаялам, которые являются еще более сложными, поскольку они написаны на уникальных письмах. Чтобы воспользоваться орфографической информацией и родственными языками на этих языках, мы объединяем соответствующие языки в единый алфавит. Предыдущие подходы использовали лингвистически неоптимальные меры, такие как расстояние редактирования Левенштейна для обнаружения родственных связей, посредством чего мы демонстрируем, что самая длинная общая подпоследовательность является лингвистически более звучной и улучшает производительность двуязычной индукции лексики. Показано, что наш подход может многократно повысить точность двуязычных методов индукции лексики на этих языках, что делает двуязычные подходы индукции лексики осуществимыми для таких языков с дефицитом ресурсов.', 'hi': 'द्विभाषी शब्दकोश कम संसाधन वाली भाषाओं के लिए एक महत्वपूर्ण उपकरण हैं और हाल ही में पर्यवेक्षित या अर्ध-पर्यवेक्षित दृष्टिकोणों का उपयोग करके इस उत्तोलन के लिए पूर्व-प्रशिक्षित मोनोलिंगुअल शब्द एम्बेडिंग के लिए हाल ही में अत्याधुनिक दृष्टिकोण हैं। हालांकि, इन दृष्टिकोणों को मॉडल को प्रशिक्षित करने और एम्बेडिंग रिक्त स्थान शब्द के बीच एक रैखिक परिवर्तन खोजने के लिए बीज शब्दकोशों जैसी क्रॉस-लिंगुअल जानकारी की आवश्यकता होती है। विशेष रूप से कम संसाधन वाली भाषाओं के मामले में, बीज शब्दकोश आसानी से उपलब्ध नहीं हैं, और इस तरह, ये विधियां इन भाषाओं पर बेहद कमजोर परिणाम उत्पन्न करती हैं। इस काम में, हम द्रविड़ भाषाओं पर ध्यान केंद्रित करते हैं, अर्थात् तमिल, तेलुगु, कन्नड़ और मलयालम, जो और भी अधिक चुनौतीपूर्ण हैं क्योंकि वे अद्वितीय लिपियों में लिखे गए हैं। इन भाषाओं में ऑर्थोग्राफिक जानकारी और कॉग्नेट का लाभ उठाने के लिए, हम संबंधित भाषाओं को एक ही लिपि में लाते हैं। पिछले दृष्टिकोणों ने भाषाई रूप से उप-इष्टतम उपायों का उपयोग किया है जैसे कि कॉग्नेट्स का पता लगाने के लिए लेवेन्सटिन संपादन दूरी, जिससे हम प्रदर्शित करते हैं कि सबसे लंबा आम उप-अनुक्रम भाषाई रूप से अधिक ध्वनि है और द्विभाषी शब्दकोश प्रेरण के प्रदर्शन में सुधार करता है। हम दिखाते हैं कि हमारा दृष्टिकोण इन भाषाओं पर द्विभाषी शब्दकोश प्रेरण विधियों की सटीकता को कई बार बढ़ा सकता है, जिससे द्विभाषी शब्दकोश प्रेरण दृष्टिकोण ऐसी कम संसाधन वाली भाषाओं के लिए संभव हो जाते हैं।', 'ga': 'Uirlis ríthábhachtach is ea foclóirí dátheangacha do theangacha gann-acmhainní agus le cur chuigí úrscothacha le déanaí maidir leis an ngiaráil seo le leabú focal aonteangach réamh-oilte ag baint úsáide as cuir chuige maoirsithe nó leath-mhaoirsithe. Mar sin féin, teastaíonn faisnéis thrastheangach ar nós foclóirí síl leis na cuir chuige seo chun an tsamhail a oiliúint agus claochlú líneach a aimsiú idir na spásanna leabaithe focal. Go háirithe i gcás teangacha íseal-acmhainní, níl fáil go héasca ar fhoclóirí síl, agus mar sin is beag torthaí a bhíonn ar na modhanna seo ar na teangacha sin. Sa saothar seo, dírímid ar na teangacha Dravidian, mar atá Tamil, Teileagúis, Cannadais, agus Mailéalaimis, atá níos dúshlánaí fós mar go bhfuil siad scríofa i scripteanna uathúla. Chun leas a bhaint as eolas ortagrafach agus gaolta sna teangacha seo, tugaimid na teangacha gaolmhara isteach in aon script amháin. Bhain cineálacha cur chuige roimhe seo úsáid as bearta fo-optamacha ó thaobh na teanga de, mar shampla an fad eagarthóireachta Levenshtein chun gaolmhaireachtaí a bhrath, trína léirímid go bhfuil an fho-sheicheamh coitianta is faide níos fónta ó thaobh teanga de agus a fheabhsaíonn feidhmíocht an ionduchtaithe foclóireachta dátheangacha. Léirímid gur féidir lenár gcur chuige cruinneas na modhanna dátheangacha ionduchtaithe foclóireachta ar na teangacha seo a mhéadú go minic, rud a fhágann go bhfuil cur chuige ionduchtaithe foclóireachta dátheangacha indéanta do theangacha tearcacmhainne dá leithéid.', 'hu': 'A kétnyelvű lexikonok létfontosságú eszközt jelentenek az alacsony forrásokkal rendelkező nyelvek számára, és a legújabb, korszerűbb megközelítések ennek a megközelítésnek a felügyelt vagy félig felügyelt megközelítésekkel történő előkészítésére. Ezek a megközelítések azonban többnyelvű információt igényelnek, mint például a vetőszótárak, hogy kiképezzék a modell és lineáris átalakulást találjanak a beágyazott szóközök között. Különösen az alacsony forrású nyelvek esetében a vetőszótárak nem állnak rendelkezésre, és mint ilyen, ezek a módszerek rendkívül gyenge eredményeket eredményeznek ezen nyelveken. Ebben a munkában a dravidi nyelvekre, nevezetesen tamilra, telugu, kannadára és malayalamra összpontosítunk, amelyek még nagyobb kihívást jelentenek, mivel egyedi forgatókönyvekben vannak írva. Ahhoz, hogy kihasználjuk ezeken a nyelveken található ortográfiai információkat és ismereteket, a kapcsolódó nyelveket egyetlen szkriptbe tesszük. Korábbi megközelítések nyelvi szempontból nem optimális méréseket alkalmaztak, mint például a Levenshtein szerkesztési távolság a kognátok felismerésére, amelyekkel bebizonyítjuk, hogy a leghosszabb közös alsekvencia nyelvi szempontból hangosabb és javítja a kétnyelvű lexikon indukció teljesítményét. Megmutatjuk, hogy megközelítésünk sokszor növelheti a kétnyelvű lexikon indukciós módszerek pontosságát ezeken a nyelveken, így a kétnyelvű lexikon indukciós megközelítések megvalósíthatók az ilyen alacsony forrással rendelkező nyelvek esetében.', 'el': 'Τα δίγλωσσα λεξικά είναι ένα ζωτικό εργαλείο για τις γλώσσες που δεν διαθέτουν πόρους και τις πρόσφατες προσεγγίσεις τελευταίας τεχνολογίας σε αυτή τη μόχλευση των προκαθορισμένων μονογλωσσών ενσωμάτωσης λέξεων χρησιμοποιώντας εποπτευμένες ή ημιεποπτικές προσεγγίσεις. Ωστόσο, αυτές οι προσεγγίσεις απαιτούν γλωσσικές πληροφορίες όπως λεξικά σπόρων για να εκπαιδεύσουν το μοντέλο και να βρουν μια γραμμική μετατροπή μεταξύ των χώρων ενσωμάτωσης λέξεων. Ειδικά στην περίπτωση των γλωσσών με χαμηλούς πόρους, τα λεξικά σπόρων δεν είναι άμεσα διαθέσιμα, και ως εκ τούτου, αυτές οι μέθοδοι παράγουν εξαιρετικά αδύναμα αποτελέσματα σε αυτές τις γλώσσες. Σε αυτό το έργο, εστιάζουμε στις δραβιδικές γλώσσες, δηλαδή τα Ταμίλ, τα Τελούγκου, τα Καννάντα και τα Μαλαγιάλαμ, οι οποίες είναι ακόμα πιο δύσκολες καθώς είναι γραμμένες σε μοναδικά σενάρια. Για να επωφεληθούμε από ορθογραφικές πληροφορίες και γνωστές σε αυτές τις γλώσσες, φέρνουμε τις σχετικές γλώσσες σε μια ενιαία γραφή. Οι προηγούμενες προσεγγίσεις έχουν χρησιμοποιήσει γλωσσικά υποβέλτιστα μέτρα όπως η απόσταση επεξεργασίας για την ανίχνευση γνωστών, με την οποία καταδεικνύουμε ότι η μεγαλύτερη κοινή υποακολουθία είναι γλωσσικά πιο ηχητική και βελτιώνει την απόδοση της δίγλωσσης επαγωγής λεξικού. Δείχνουμε ότι η προσέγγισή μας μπορεί να αυξήσει την ακρίβεια των δίγλωσσων μεθόδων επαγωγής λεξικού σε αυτές τις γλώσσες πολλές φορές, καθιστώντας εφικτές τις δίγλωσσες προσεγγίσεις επαγωγής λεξικού για τέτοιες γλώσσες που δεν διαθέτουν πόρους.', 'ka': 'მეორე ლექსიკონები არის მნიშვნელოვანი გამოსახულებელი ხელსაწყოთა ენების და მხოლოდ მნიშვნელოვანი ხელსაწყოთა მონოლენგური სიტყვები, რომელიც გამოყენებული ან მეორე დანარჩენებული გახსნა. მაგრამ, ეს დახმარებები საჭირო მრავალური ინფორმაცია, როგორც შვილის სიტყვების სიტყვები, რომ მოდელის შემწავლობა და ლეინური გარცნობა სიტყვების გარეშე. სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა ენების შესა ამ სამუშაოში ჩვენ ტუკუნსტურებთ დრავიდიური ენაზე, რამილის, ტელუგუ, კანნადის და მალაიალამის, რომლებიც უფრო უფრო შესაძლებელია, როგორც ისინი უნიკალური სკრიპტებში დაწერა ორტოგრაფიკური ინფორმაციის და კონდონტაციის გამოყენება ამ ენაში, ჩვენ ერთი სკრიპტის შესაბამისი ენათების შესაბამისთვის. წინა პროგრამები იყენებენ ენგუქტიკურად სოპტიმალურად, როგორც Levenshtein რედაქტირების განტოლების განტოლების განტოლების განტოლების განტოლება, რომელიც ჩვენ აჩვენებთ, რომ უფრო დიდი საერთო საერთო სოპტიკური განტოლება ენგუქტი ჩვენ გამოჩვენებთ, რომ ჩვენი პროგრამა შეუძლიათ გავაკეთოთ ორიენგური ლექსიკონის ინდექციის მეტოვების წარმოდგენება ამ ენათში მრავალჯერ, რაც ორიენგური ლექსიკონის ინდექციის მიღება', 'it': "I lessici bilingui sono uno strumento vitale per le lingue con scarse risorse e i recenti approcci allo stato dell'arte a questo scopo sfruttano l'incorporazione di parole monolingue pre-addestrate utilizzando approcci supervisionati o semi-supervisionati. Tuttavia, questi approcci richiedono informazioni cross-lingual come dizionari di seme per formare il modello e trovare una trasformazione lineare tra la parola che incorpora spazi. Soprattutto nel caso delle lingue con scarse risorse, i dizionari iniziali non sono facilmente disponibili e, come tali, questi metodi producono risultati estremamente deboli su queste lingue. In questo lavoro, ci concentriamo sulle lingue dravidiane, vale a dire tamil, telugu, kannada e malayalam, che sono ancora più impegnative in quanto sono scritte in script unici. Per sfruttare le informazioni ortografiche e le cognizioni in queste lingue, portiamo le lingue correlate in un unico script. Gli approcci precedenti hanno utilizzato misure linguisticamente sub-ottimali come la distanza di modifica di Levenshtein per rilevare i cognati, per cui dimostriamo che la sub-sequenza comune più lunga è linguisticamente più solida e migliora le prestazioni dell'induzione lessicale bilingue. Mostriamo che il nostro approccio può aumentare l'accuratezza dei metodi di induzione lessicale bilingue su queste lingue molte volte, rendendo possibili approcci di induzione lessicale bilingue per tali lingue poco risorse.", 'lt': 'Dviejų kalbų leksikonai yra gyvybiškai svarbi priemonė nepakankamai išteklių turinčioms kalboms ir naujausiems pažangiausiems požiūriams į šį svertą naudojant priežiūrėtus arba pusiau prižiūrėtus metodus. Tačiau šiems metodams reikalinga tarpkalbinė informacija, pavyzdžiui, sėklos žodynai, siekiant treniruoti model į ir rasti linijinį pakeitimą tarp žodžių įterpimo erdvių. Ypač mažai išteklių turinčių kalbų sėklos žodynai nėra lengvai prieinami, todėl šie metodai šiomis kalbomis duoda labai silpnų rezultatų. Šiame darbe daugiausia dėmesio skiriame dravidiškoms kalboms, t. y. tameliui, telugui, Kanadai ir malajamui, kurios yra dar sudėtingesnės, nes jos yra parašytos unikaliuose scenarijuose. Norėdami pasinaudoti ortografine informacija ir pažįstamomis šiomis kalbomis, mes įtraukiame susijusias kalbas į vieną scenarijų. Previous approaches have used linguistically sub-optimal measures such as the Levenshtein edit distance to detect cognates, whereby we demonstrate that the longest common sub-sequence is linguistically more sound and improves the performance of bilingual lexicon induction.  Mes rodome, kad mūsų požiūris gali dažnai padidinti dvikalbių leksikonų indukcijos metodų tikslumą šiose kalbose, todėl dvikalbių leksikonų indukcijos metodai tokių nepakankamai išteklių turinčių kalbų atžvilgiu gali būti įmanomi.', 'kk': 'Екі лекциялар - ресурс төмен тілдерге және соңғы орындау күйіне қатынау үшін бұл монолингі сөздерді ендіру үшін маңызды құралы. Бақылау немесе жарты бақылау әдістерін қолданады. Бірақ бұл жағдайлар үлгісін оқыту үшін үлгілі сөздердің бірнеше тілді мәліметін талап етеді және сөзді ендіру бос орындар арасындағы сызық түрлендіру керек. Әсіресе, көп ресурстар тілдерінде тарату сөздігі оңай жеткізбейді, сондықтан бұл әдістер бұл тілдерге өте жақсы нәтижелерді жасайды. Бұл жұмыс ішінде, біз дравидеяның тілдеріне назар аударып тұрамыз: Тамил, Телуг, Каннада және Малайям. Олар бірнеше скрипттерде жазылған сияқты көбірек. Ортографиялық мәліметті пайдалану үшін, осы тілдерді тану үшін, сілтейтін тілдерді бір скриптге келтіреміз. Алдыңғы арқылы күндерді табу үшін Левенштейн өңдеу қашықтығын лингвистикалық ішкі оптималдық өлшемдерді қолданады. Бұл арқылы, ең ұзындық ішкі ішкі реттегі лингвистикалық ішкі дыбыс болып, екі тілі лексиканың индукци Біз өзіміздің тәсіліміміз бұл тілдерде екі тіл лексиканың индукциялық әдістерін көптеген және екі тілдерді индукциялық индукциялық индукциялық тілдерге ұқсас етеді.', 'ms': 'Leksikon berbicara adalah alat penting untuk bahasa-sumber-bawah dan pendekatan-state-of-the-art yang baru-baru ini kepada pengaruh penerbangan perkataan monobahasa yang dilatih dahulu menggunakan pendekatan yang diawasi atau semi-mengawasi. Namun, pendekatan ini memerlukan maklumat saling bahasa seperti kamus benih untuk melatih model dan mencari perubahan linear diantara ruang penyampilan perkataan. Terutama dalam kes bahasa sumber rendah, kamus benih tidak mudah tersedia, dan sebagaimana itu, kaedah-kaedah ini menghasilkan keputusan yang sangat lemah pada bahasa-bahasa ini. Dalam kerja ini, kita fokus pada bahasa Dravidia, iaitu Tamil, Telugu, Kannada, dan Malayalam, yang lebih mencabar kerana mereka ditulis dalam skrip unik. Untuk mengambil keuntungan dari maklumat ortografik dan pengetahuan dalam bahasa-bahasa ini, kami membawa bahasa yang berkaitan ke dalam skrip tunggal. pendekatan terdahulu telah menggunakan tindakan sub-optimal secara bahasa seperti jarak edit Levenshtein untuk mengesan kognat, di mana kita menunjukkan bahawa sub-urutan umum paling panjang secara bahasa lebih bunyi dan meningkatkan prestasi induksi leksikon bilingual. Kita menunjukkan bahawa pendekatan kita boleh meningkatkan ketepatan kaedah induksi leksikon bilingual pada bahasa-bahasa ini banyak kali, menjadikan pendekatan induksi leksikon bilingual boleh dilakukan untuk bahasa-bahasa yang tidak berkuasa.', 'ml': 'ബില്\u200dലിങ്കുള്ള ലെക്സിക്ഷന്\u200dമാര്\u200d വിഭവപൂര്\u200dണ്ണമായ ഭാഷകള്\u200d എങ്കിലും ഈ അടുത്തുവരുന്നതിന് വിത്ത നിഘണ്ടികൾ പോലുള്ള വിവരങ്ങൾ ആവശ്യമുണ്ട്, മോഡലിനെ പരിശീലിപ്പിക്കാനും വാക്കിന്റെ ഇടയിലു പ്രത്യേകിച്ച് കുറഞ്ഞ വിഭവങ്ങളുള്ള ഭാഷകളുടെ കാര്യത്തില്\u200d സന്തതികളുടെ നിഘണ്ടാവുകള്\u200d എളുപ്പമായി ലഭ്യമാകുന്നില്ല, അതുപോലെ  ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മള്\u200d ദ്രാവിഡിയന്\u200d ഭാഷകളിലേക്ക് ശ്രദ്ധിക്കുന്നു, താമില്\u200d, ടെലുക്കു, കനാനാദ, മലമാലാലാമിനെക്കുറിച്ച്, അവര്\u200d വ്യത്യ ഈ ഭാഷകളില്\u200d വിവരങ്ങളും കോഗ്രാഫിക് വിവരങ്ങളും ഉപയോഗിക്കാന്\u200d നമ്മള്\u200d ബന്ധപ്പെട്ട ഭാഷകള്\u200d ഒരു സ്ക്രിപ്റ്റിലേക്ക മുമ്പുള്ള വഴികള്\u200d ലെവെന്\u200dഷ്ടെയിന്\u200d എഡിറ്റ് ദൂരം കണ്ടുപിടിക്കാന്\u200d വേണ്ടി ലെവിന്\u200dഷ്ടെയിന്\u200d ഉപയോഗിച്ചിരിക്കുന്നു. അതിനാല്\u200d ഏറ്റവും നീണ്ട സാധാരണ സബ് സെക്കന്\u200dസ് ഭാഷയില്\u200d  ഞങ്ങള്\u200d കാണിക്കുന്നുണ്ടെങ്കില്\u200d ഈ ഭാഷകളില്\u200d രണ്ടു ഭാഷക്ക് ലെക്സിക്ഷന്\u200d നിര്\u200dമ്മിക്കുന്ന രീതികള്\u200dക്ക് കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d വര്\u200dദ', 'mk': 'Дивјазичните лексикони се суштинска алатка за јазиците со недоволни ресурси и неодамнешните најнови пристапи кон ова влијание на претренираните монојазични зборови со користење надгледувани или полунадгледувани пристапи. Сепак, овие пристапи бараат прекујазични информации како што се речниците за семето за обука на моделот и пронаоѓање линијарна трансформација помеѓу зборовите мешани простори. Особено во случајот на јазиците со ниски ресурси, речниците за семето не се лесно достапни, и како такви, овие методи произведуваат екстремно слаби резултати на овие јазици. Во оваа работа, се фокусираме на дравидските јазици, имено Тамил, Телугу, Канада и Малајалам, кои се уште повеќе предизвикувачки бидејќи се напишани во уникатни сценарија. За да ги искористиме ортографските информации и познавањата на овие јазици, ги внесуваме поврзаните јазици во еден скрипт. Претходните пристапи употребија јазички суб-оптимални мерки како што е дистанца на уредување на Левенстин за детектирање на коњати, со која демонстрираме дека најдолгата заедничка суб-секвенца е јазички поголем звук и ја подобрува изведбата на двојјазичната индукција на лексикони. Покажуваме дека нашиот пристап може да ја зголеми прецизноста на методите на индукција на двојјазични лексикони на овие јазици многу пати, правејќи ги приблизите на индукција на двојјазични лексикони можни за вакви јазици со недостаток на ресурси.', 'pl': 'Dwujęzyczne leksykony są kluczowym narzędziem dla niedostatecznie zasobów języków i najnowszych najnowocześniejszych podejść do tego podejścia wykorzystującego wstępnie przeszkolone jednojęzyczne osadzenia słów przy użyciu podejścia nadzorowanego lub pół-nadzorowanego. Jednakże podejścia te wymagają informacji wielojęzycznych, takich jak słowniki seed, aby przeszkolować model i znaleźć liniową transformację między przestrzeniami osadzającymi słowa. Szczególnie w przypadku języków o niskich zasobach słowniki nasion nie są łatwo dostępne, a w związku z tym metody te dają niezwykle słabe rezultaty na tych językach. W tej pracy skupiamy się na językach drawidyjskich, a mianowicie tamilskim, telugu, kannadzie i malajalam, które są jeszcze trudniejsze, ponieważ są pisane w unikalnych scenariuszach. Aby skorzystać z informacji ortograficznych i poznań w tych językach, wprowadzamy powiązane języki w jeden skrypt. Poprzednie podejścia wykorzystują językowo nieoptymalne miary, takie jak odległość edycji Levensteina do wykrywania poznań, dzięki czemu wykazujemy, że najdłuższą wspólną podsekwencją jest językowo bardziej dźwiękowa i poprawia wydajność indukcji dwujęzycznego leksykonu. Pokazujemy, że nasze podejście może wielokrotnie zwiększyć dokładność dwujęzycznych metod indukcji leksykonów na tych językach, dzięki czemu dwujęzyczne metody indukcji leksykonów są możliwe dla takich niewyposażonych języków.', 'mt': 'Il-lexicons bilingwi huma għodda vitali għal lingwi li m’għandhomx riżorsi biżżejjed u approċċi reċenti ta’ l-aktar avvanzati għal dan l-ingranaġġ ta’ inkorporazzjoni ta’ kliem monolingwi mħarrġa minn qabel bl-użu ta’ approċċi sorveljati jew semisorveljati. Madankollu, dawn l-approċċi jeħtieġu informazzjoni translingwistika bħad-dikjararji taż-żerriegħa biex jitħarreġ il-mudell u tinstab trasformazzjoni lineari bejn l-ispazji tal-inkorporazzjoni tal-kelma. Speċjalment fil-każ ta’ lingwi b’riżorsi baxxi, id-dikjararji taż-żerriegħa mhumiex disponibbli faċilment, u bħala tali, dawn il-metodi jipproduċu riżultati estremament dgħajfa fuq dawn il-lingwi. F’din il-ħidma, niffokaw fuq il-lingwi Dravidjani, jiġifieri t-Tamil, it-Telugwu, il-Kannada, u l-Malayalam, li huma saħansitra aktar sfida peress li huma miktuba fi skripti uniċi. Biex niksbu vantaġġ mill-informazzjoni ortografika u l-għarfien f’dawn il-lingwi, a ħna nġibu l-lingwi relatati fi skript wieħed. L-approċċi preċedenti użaw miżuri lingwistikament subottimali bħad-distanza tal-edit Levenshtein biex jinstabu l-kononati, fejn nistgħu nippruvaw li l-itwal sottosekwenza komuni hija lingwistikament aktar soda u ttejjeb il-prestazzjoni tal-induzzjoni tal-lexicon bilingwi. Aħna nuru li l-approċċ tagħna jista’ jżid il-preċiżjoni tal-metodi ta’ induzzjoni tal-lexicon billingwi f’dawn il-lingwi ħafna drabi, u dan jagħmel l-approċċi ta’ induzzjoni tal-lexicon billingwi fattibbli għal tali lingwi li m’għandhomx riżorsi biżżejjed.', 'mn': 'Хоёр хоёр хэлбэрт суурь хэл багасгах болон саяхан урлагийн тусламжтай тусламжтай нэг хэл хэлний тусламжтайгаар дамжуулагдсан, эсвэл хагас дамжуулагдсан арга барилгуудыг ашиглан нэг хэл хэлний тусламжтайгаар нэвтрэх хэрэгсэл юм. Гэхдээ эдгээр арга барилгууд загварыг суралцаж, нэвтрүүлэх орон зайн хоорондын шулуун өөрчлөлт олох хэлний олон хэлний мэдээллийг хэрэгтэй. Ялангуяа бага асуудалтай хэлний тухай тарианы үгийг амархан ашиглаж чадахгүй. Тиймээс эдгээр арга нь эдгээр хэл дээр маш хүчтэй үр дүнг гаргадаг. Энэ ажлын тухай бид Дравидийн хэл дээр анхаарлаа төвлөрүүлдэг. Энэ нь Тамил, Телугу, Каннада, Малайям. Тэд өөр нэг бичсэн бичгийнхээ хувьд илүү хэцүү. Эдгээр хэл дээр ортографик мэдээллийг ашиглахын тулд бид холбоотой хэл нэг скрипт руу оруулдаг. Өмнөх арга баримтууд, Левенштейн зохион байгуулах зай шиг хэлний суб-өөдрөг хэлбэрээр хэрэглэгдсэн. Энэ нь бид хамгийн урт нийтлэг суб-дарааллыг хэлний хэлбэрээр илүү чимээгүй, хоёр хэлний лексикон үйл ажиллагааг сайжруулдаг. Бид эдгээр хэл дээр хоёр хэлний лексикон үйлдвэрлэлийн тодорхойлолтыг ихэвчлэн нэмэгдүүлж, хоёр хэлний лексикон үйлдвэрлэлийн тулд ийм төвөгтэй хэлний тулд ашиглах боломжтой болгодог гэдгийг харуулж байна.', 'no': 'Bilinguelle leksikon er eit viktig verktøy for underressurserte språk og nyleg tilnærmingar av kunsttilstanden til denne leverandøren av foregrensa monospråk-innbygging med oversikte eller semioversikte tilnærmingar. Desse tilnærmingane krev likevel krysspråk informasjon, som frøordboklarar for å trenja modellen og finna ei lineær transformasjon mellom ordinnbyggingsmellomrom. Spesielt i tilfelle for låg ressurserte språk er det ikkje lett tilgjengelege frøordboklarar, og slik er desse metodane utføra ekstremt svake resultat på desse språka. I denne arbeiden fokuserer vi på dravidiske språka, som er Tamil, Telugu, Kannada og Malayalam, som er mer vanskeleg som dei er skriven i unike skript. For å ta fordel av ortografiske informasjon og kjenne på desse språka, vil me føre dei relaterte språka til eit enkelt skript. Førre tilnærmingar har brukt linguisk underoptimalt mål, slik som Levenshtein-redigeringsavstanden for å finna kognittar, der vi viser at den langste felles undersekvensen er linguisk meir lyd og forbedrar utviklinga av bilinguelt leksikonsinduksjon. Vi viser at tilnærminga vårt kan auka nøyaktigheten av bilinguelt leksikoninduksjonsmetoder på desse språka mange gonger, og at induksjonen av bilinguelt leksikon nærar tilgjengeleg for slike underressurserte språk.', 'ro': 'Lexicoanele bilingve reprezintă un instrument vital pentru limbile cu resurse insuficiente și abordările recente de ultimă generație pentru această influență a încorporărilor monolingve pre-instruite folosind abordări supravegheate sau semi-supravegheate. Cu toate acestea, aceste abordări necesită informații cross-lingvistice, cum ar fi dicționare de semințe pentru a instrui modelul și a găsi o transformare liniară între cuvântul care încorporează spații. Mai ales în cazul limbilor cu resurse reduse, dicționarele de semințe nu sunt ușor disponibile și, ca atare, aceste metode produc rezultate extrem de slabe în aceste limbi. În această lucrare, ne concentrăm asupra limbilor dravidiene, și anume Tamil, Telugu, Kannada și Malayalam, care sunt chiar mai provocatoare deoarece sunt scrise în scrieri unice. Pentru a profita de informațiile ortografice și cunoștințele în aceste limbi, aducem limbile conexe într-un singur script. Abordările anterioare au folosit măsuri lingvistice suboptime, cum ar fi distanța de editare Levenshtein pentru a detecta cunoștințele, prin care demonstrăm că cea mai lungă subsecvență comună este lingvistic mai solidă și îmbunătățește performanța inducției lexiconice bilingve. Noi arătăm că abordarea noastră poate crește acuratețea metodelor de inducție a lexiconului bilingv pe aceste limbi de multe ori, făcând abordările bilingve de inducție a lexiconului fezabile pentru astfel de limbi subresursate.', 'sr': 'Bilingualni leksioni su vitalni alat za neposredne jezike i nedavne pristupe umetnosti ovoj primjeni pretrenirane monojezičke reči uključujući nadzorne ili polu nadzorne pristupe. Međutim, ovi pristupi zahtevaju međujezičke informacije kao što su reči semena za treniranje model a i pronalaženje linearne transformacije između reči uključenih prostora. Posebno u slučaju niskog resursa jezika, rečenici semena nisu lako dostupni, i kao takve metode proizvode ekstremno slabe rezultate na ovim jezicima. U ovom poslu, fokusiramo se na dravidski jezik, a to je Tamil, Telugu, Kannada i Malayalam, koji su još izazovniji kao što su napisani u jedinstvenim skriptovima. Da bismo iskoristili ortografsku informaciju i kognirali na ovim jezicima, doveli smo povezane jezike u jednog skripta. Prethodni pristupi su koristili lingvistički suboptimalne mjere kao što je Levenshtein uredna udaljenost za otkrivanje kognija, s kojim pokazujemo da je najduža zajednička podsekvencija jezički više zvuka i poboljšava učinkovitost dvojezičke leksičke indukcije. Pokazujemo da naš pristup može povećati preciznost metoda indukcije dvojezika na ovim jezicima mnogo puta, čineći pristupe indukciji dvojezika leksičkih leksiona mogućim za takve pod resursima jezika.', 'si': 'Bilingual lexicons are a vital toolkit for under-ressursed language and new state-of-the-art approach to this level නමුත්, මේ විදියට විශාල භාෂාවක් තොරතුරු අවශ්\u200dය වෙනවා වගේම සීඩ් භාෂාවක් වලින් මොඩල් ක්\u200dරීයාකරණය කරන්න සහ ලේ විශේෂයෙන්ම ප්\u200dරශ්න භාෂාවල් අඩුම භාෂාවල් වලින්, බීඩ් භාෂාවල් ලේසියෙන් පුළුවන් නෑ, ඒ වගේම, මේ විදිය මේ වැඩේ අපි ඩ්\u200dරාවිඩියාන් භාෂාවට අවධානය කරනවා, තැමිල්, ටෙලුගු, කැන්නාඩ්, සහ මලායාලාම්, ඒ වගේම ඒවා විශේෂ ස්ක්\u200dරිප්ට්  මේ භාෂාවල් වලින් ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය කරන්න, අපි සම්බන්ධ භාෂාවල් එක්ක ස්ක්\u200dරිප්ට් වලට ගෙනි මුලින් අනිවාර්ය භාෂාවික විශ්වාස කරන්න භාෂාවික විශ්වාස කරන්න පුළුවන් වගේ ලෙවෙන්ස්ටීන් සැකසුම් දුර්ගලය හොයාගන්න, ඒ වගේම අපි පෙන්වන්න අපි පෙන්වන්නේ අපේ විදිහට දෙකක් භාෂාවක් විදිහට විශ්වාස කරන්න පුළුවන් කියලා, මේ භාෂාවට වඩා වතාවක් විදිහට, දෙකක් භාෂාව', 'so': 'Luqadaha luqada ah waa qalabka muhiimka ah oo luqadaha hoos-resourceed ku jirta iyo taariikhda-farshaxanka ugu dambeeya ay ku soo bandhigtaan hadalka afka ah oo la soo diro oo lagu isticmaalayo qaabab ilaaliya ama la ilaaliyo. Si kastaba ha ahaatee soo dhowaanshahaas waxay u baahan yihiin macluumaad luuqadaha kala duduwan, sida dictionary farcanka, in lagu tababariyo tusaale ahaan, waxayna heli karaan isbedelka saqafka ah oo u dhexeeya goobaha saqafka. Si gaar ah marka lagu jiro luqadaha hoos-rasmi ah, luuqadaha farcanku si fudud uma helaan, tusaale ahaan qaababkan waxay ku soo saaraan resulto aad u itaal yar oo luuqadahan ku saabsan. Shuqulkaas waxaynu ku kalsoonaynaa luuqadaha Drawiya, kuwaas oo ah Tamil, Telugu, Kannada iyo Malayalam, kuwaas oo aad uga dhibaataysan sida ay ugu qoran karraaniyaha gaarka ah. Si aan ugu isticmaalno macluumaadka ortografiga iyo bandhigyada luuqadahan, waxaynu luuqadaha la xiriiray u keennaa qoraal keliya. Dhaqdooyinkii hore waxay isticmaaleen qiyaastii afka hoos-optimiska ah, tusaale Levenshtein waxay u isticmaaleen sawirida dhererka sawirada si aan u ogaano meelaha ay leedahay, taas oo aannu ku caddaynayno in dhaqdhaqaaqa hoos-hooska ee ugu dheer ay luuqada ugu dhaw tahay cod ka sii fiican, wuxuuna kordhiyaa muuqashada labo luqadood oo leksikan ah. Waxaynu muujinnaa in dhaqdhaqaalahayagu uu kordhi karo saxda dhaqdhaqaalaha labo luqadood ee leksikanka, in luqadahan qaar jeer looga sameeyo dhaqdhaqaalaha leksisinka oo laba luqadood ah oo ay suurtogal u noqon karaan luuqadaha laga hooseeyo.', 'sv': 'Tvåspråkiga lexikon är ett viktigt verktyg för språk med underresurser och de senaste toppmoderna metoderna för detta utnyttjar förkränade enspråkiga ordinbäddningar med hjälp av övervakade eller halvövervakade metoder. Dessa tillvägagångssätt kräver dock flerspråkig information såsom seed ordböcker för att träna modellen och hitta en linjär omvandling mellan ordet inbäddande mellanrum. Särskilt när det gäller språk med låg resurs är det inte lätt att få tillgång till såddlexikon, och därför ger dessa metoder extremt svaga resultat på dessa språk. I detta arbete fokuserar vi på de dravidiska språken, nämligen tamil, telugu, kannada och malayalam, som är ännu mer utmanande eftersom de är skrivna i unika manus. För att dra nytta av ortografisk information och kognitioner på dessa språk, tar vi de relaterade språken i ett enda skript. Tidigare metoder har använt språkligt suboptimala mått såsom Levenshtein redigeringsavstånd för att upptäcka kognitioner, där vi visar att den längsta gemensamma delsekvensen är språkligt mer sund och förbättrar prestandan av tvåspråkig lexikoninduktion. Vi visar att vårt tillvägagångssätt kan öka noggrannheten hos tvåspråkiga lexikoninduktionsmetoder på dessa språk många gånger, vilket gör tvåspråkiga lexikoninduktionsmetoder möjliga för sådana underresurserade språk.', 'ta': 'பில்லிங் லெக்சிக்ஸின்கள் மூலம் மூலம் மற்றும் சமீபத்தில் கலை நிலையின் நிலைமைகளுக்கு ஒரு முக்கியமான கருவி ஆனால், இந்த முன்னேற்றங்கள் மாதிரியை பயிற்சி மற்றும் வார்த்தை இடைவெளிகளுக்கிடையே ஒரு வரிய மாற்றம் கண்டுபிடிக்க வேண்டும்  குறைந்த வளர்ந்த மொழிகள் குறைந்த மொழிகளில், விதிகள் அகராதிகள் எளிதாக கிடைக்கவில்லை, இது போன்று, இந்த முறைகள் இந்த மொழிகளில் மி In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  இந்த மொழிகளில் குறியீடுகள் மற்றும் குறியீடுகளை பயன்படுத்த, நாம் தொடர்புடைய மொழிகளை ஒரு சிறுநிரலில் கொண்ட முந்தைய வழிமுறைகள் மொழியில் துணை உப தேர்வுகளை உபயோகித்துள்ளார்கள் போன்ற லெவன்ஷ்டீன் தொகுப்பு தூரத்தை கண்டுபிடிக்க, அதைக் காண்பிக்க நாம் குறிப்பிடுகிறோம இந்த மொழிகளில் இரு மொழியில் இரு மொழியின் வெளிப்பாட்டு முறையை அதிகரிக்க முடியும் என்று நாம் காண்பிக்கிறோம், இரு மொழியில் லெக்சி', 'ur': 'دوئلینگ لکسونز کمزور کی زبانوں کے لئے ایک ضروری وسیلہ ہے اور اچھی موقعیت آرتی کے لئے اس سطح کے مطابق پہنچنے والے ایک زبانی لکھی لکھی لکھی باتوں کے مطابق موجود ہوئی یا نیچے موجود کی طریقوں کے مطابق موجود ہوتی ہے. لیکن یہ تقریباً کلاس زبان کی اطلاعات کی ضرورت ہے جیسے بذریعہ کے لکھنے کے لئے موڈل کی تعلیم اور لکھنے کی جگہ کے درمیان ایک لینی تغییر پیدا کریں. مخصوصاً کم رسورس زبانوں کی حالت میں، بیٹی لکھائی آسانی سے موجود نہیں ہیں، اور اسی طرح، یہ طریقے ان زبانوں پر بہت کم نتیجے پیدا کرتے ہیں۔ اس کام میں ہم ڈراویڈی زبانوں پر تمرکز کرتے ہیں، یعنی تامیل، ٹولوگو، کانڈا اور مالایالموں، جو ان کے ناموں میں لکھی جاتی ہیں اور ان سے زیادہ مشکل ہیں۔ اورٹوگرافیک معلومات اور ان زبانوں میں پہچان جاننے کے لئے ہم ایک لکھ میں رابطہ دار زبانیں لے آتے ہیں۔ پہلے کی مطابق زبان سے زیادہ اچھی اندازے استعمال کئے گئے ہیں جیسے لوئینسٹین ایڈیٹ دور کی جگہ پہچان جانے کے لئے، جسے ہم دکھاتے ہیں کہ سب سے زیادہ عمده زیادہ آواز ہے اور دوزبان زبان زبان کی ایڈیٹ کی عمدگی کو بہتر کر دیتا ہے. ہم دکھاتے ہیں کہ ہمارا طریقہ ان زبانوں پر دوزخ زبان کی اصلاح کے مطابق اضافہ کر سکتا ہے، اور دوزخ زبان کی اصلاح کے مطابق ایسی زبانوں کے لئے موجود ہوتی ہے۔', 'uz': "Oʻlviy leksikatlar esa murakkablik tillar uchun muhim asbobi va yaqinda ishlab chiqaruvchi sohalar holatiga qarshi mumkin. Bu suhbat soʻzlarni qo'llab qo'llash yoki semi taʼminlovchi soʻzlardan foydalanish mumkin. Lekin, bu murakkablar modelni o'rganish uchun muloqat lugʻatlarga boshqa tillar haqida maʼlumot kerak, va sonlar ichki boʻsh joy orasidagi soʻzning orasidagi oʻzgarishni topish kerak. Especially low-resource tillarida, seed dictionary oddiy emas, va shu usullar bu tillarda juda yomon natijalar yaratadi. Bu ishda, biz Dravidian tillarga, Tamil, Telugu, Kannada va Malayalam tilga qarasamiz. Ular uning o'xshash skriptlarda yozilganda ko'proq qiziqarli. Ushbu tillarda ortografik haqida maʼlumot va kognatlarni foydalanish uchun, biz bogʻ'liq tillarni bir skriptga olimiz. Oldingi usullar Levenshtein soniyalarni aniqlash uchun bir xil tildan sub optimal tilni ishlatish mumkin. Bu yerda biz ko'proq umumiy sub-seksiyatlarning eng umumiy tilidan tovush bo'lgan va ikki tillar leksision induksiyasining natijasini oshirish mumkin. Biz shunday qilamiz, bizning usuli bu tillarda ikkita tillar lekson induksiya usullarini ko'p marta oshirish mumkin, biz ikkita tillarni o'zgartirishimiz mumkin, bu tilning ko'pchilik tillariga imkoniyatli bo'lishi mumkin.", 'vi': 'Sử dụng ngôn ngữ lưỡng là công cụ thiết yếu cho ngôn ngữ thiếu nguồn và cách thức hiện đại mới nhất với đòn bẩy trước khi nhúng từ ngôn ngữ ngữ ngữ ngữ ngầm dưới sự giám sát hoặc giám sát. Tuy nhiên, các phương pháp này yêu cầu thông tin ngôn ngữ khác nhau như từ điển để đào tạo mô hình và tìm thấy một sự chuyển đổi tuyến giữa các khoảng chữ nhúng vào. Đặc biệt trong trường hợp có nguồn lực thấp, các từ điển hạt không dễ dàng sẵn sàng, và như thế, các phương pháp này tạo ra kết quả cực kỳ yếu về những ngôn ngữ này. Trong tác phẩm này, chúng ta tập trung vào những ngôn ngữ của người Drakvidian, đến Tamil, Telui, Kannada, và Malayaham, những ngôn ngữ còn khó khăn hơn những chữ viết trong kịch bản độc đáo. Để sử dụng các thông tin cấu hình và răng nanh ở các ngôn ngữ này, chúng tôi mang các ngôn ngữ liên quan vào một văn lệnh. Những phương pháp trước đã sử dụng ngôn ngữ kém tối ưu như Khoảng cách chỉnh sửa Levenstein để phát hiện các răng nanh, nhờ đó chúng tôi chứng minh rằng tiểu trình phổ biến dài nhất là âm thanh và tăng hiệu quả cho việc tiến hành thư ngôn ngữ. Chúng tôi cho thấy phương pháp này có thể tăng độ chính xác của các phương pháp ngôn ngữ này trên các ngôn ngữ này nhiều lần, làm cho các phương pháp dẫn ứng ngôn ngữ ngữ có đôi có nguồn thức này khả thi.', 'bg': 'Двуезичните лексикони са жизненоважен инструмент за недостиг на ресурси езици и последните най-съвременни подходи към този лост за предварително обучени едноезични вграждания на думи, използващи надзорни или полунадзорни подходи. Въпреки това, тези подходи изискват междуезична информация, като например речници за семена, за да се обучи модела и да се намери линейна трансформация между думата вграждащи пространства. Особено в случая на езици с ниски ресурси речниците за начало не са лесно достъпни и като такива тези методи дават изключително слаби резултати за тези езици. В тази работа се фокусираме върху дравидийските езици, а именно тамилски, телугу, канада и малаялам, които са още по-предизвикателни, тъй като са написани в уникални сценарии. За да се възползваме от ортографската информация и познатите на тези езици, ние привеждаме свързаните езици в един скрипт. Предишните подходи са използвали лингвистично субоптимални мерки като разстоянието за редактиране на Левънщайн за откриване на познати, при което демонстрираме, че най-дългата обща подпоследователност е лингвистично по-звукова и подобрява ефективността на двуезичната индукция на лексикона. Показваме, че нашият подход може да увеличи точността на двуезичните методи за индукция на лексикони на тези езици многократно, което прави двуезичните индукционни подходи осъществими за такива езици с недостатъчно ресурси.', 'hr': 'Bilingualni leksioni su vitalni alat za neposredne jezike i nedavne pristupe stanju umjetnosti ovoj utjecaja pretvorili monojezičke riječi uključujući nadzorne ili polu nadzorne pristupe. Međutim, ovi pristupi zahtijevaju krstojezičke informacije poput riječi semena za obuku model a i pronaći linearnu transformaciju između riječi uključenih prostora. Posebno u slučaju niskog izvođenog jezika, riječi o sjemenju nisu lako dostupni, i kao takve, te metode proizvode ekstremno slabe rezultate na ovim jezicima. U ovom poslu se fokusiramo na dravidski jezik, a to je Tamil, Telugu, Kannada i Malayalam, koji su još izazovniji kao što su napisani u jedinstvenim skriptama. Da bismo iskoristili ortografske informacije i spoznavali se na ovim jezicima, doveli smo povezane jezike u jednog skripta. Prethodni pristupi koristili su jezički podoptimalne mjere kao što je Levenshtein uredna udaljenost za otkrivanje kognija, s kojim pokazujemo da je najduža zajednička podsekvencija jezički više zvuka i poboljšava učinkovitost dvojezičkog indukcije leksikona. Mi pokazujemo da naš pristup može povećati preciznost metoda indukcije dvojezika na ovim jezicima mnogo puta, čineći pristupe indukciji dvojezika leksičkim jezicima mogućim za takve pod resursima.', 'da': 'Tosprogede leksikoner er et vigtigt værktøj til underressourcer sprog og nyere state-of-the-art tilgange til denne udnyttelse af forudtrænede ensprogede ordindlejringer ved hjælp af overvågede eller halvovervågede tilgange. Men disse tilgange kræver tværsprogede oplysninger såsom seed ordbøger for at træne modellen og finde en lineær transformation mellem ordet integrering af mellemrum. Især i tilfælde af sprog med lav ressource er der ikke umiddelbart adgang til sådanne ordbøger, og som sådan giver disse metoder ekstremt svage resultater på disse sprog. I dette arbejde fokuserer vi på de dravidiske sprog, nemlig tamil, telugu, kannada og malayalam, som er endnu mere udfordrende, da de er skrevet i unikke scripts. For at drage fordel af ortografisk information og kognitioner på disse sprog, bringer vi de beslægtede sprog i et enkelt script. Tidligere tilgange har anvendt sprogligt suboptimale målinger såsom Levenshtein redigeringsafstand til at detektere kognitioner, hvor vi demonstrerer, at den længste fælles undersekvens er sprogligt mere sund og forbedrer ydeevnen af tosproget leksikoninduktion. Vi viser, at vores tilgang mange gange kan øge nøjagtigheden af tosprogede leksikoninduktionsmetoder på disse sprog, hvilket gør tosprogede leksikoninduktionsmetoder mulige for sådanne underressourcer sprog.', 'nl': 'Tweetalige lexicons zijn een essentieel hulpmiddel voor te weinig beschikbare talen en recente state-of-the-art benaderingen voor deze toepassing maken gebruik van vooraf getrainde eentalige woordinbeddingen met behulp van begeleide of semi-begeleide benaderingen. Deze benaderingen vereisen echter cross-linguale informatie, zoals zaadwoordenboeken om het model te trainen en een lineaire transformatie te vinden tussen de woordinsluitingsruimtes. Vooral in het geval van talen met lage middelen zijn zaadwoordenboeken niet gemakkelijk beschikbaar, en als zodanig, produceren deze methoden extreem zwakke resultaten op deze talen. In dit werk richten we ons op de Dravidische talen, namelijk Tamil, Telugu, Kannada en Malayalam, die nog uitdagender zijn omdat ze geschreven zijn in unieke scripts. Om gebruik te maken van orthografische informatie en cognaten in deze talen, brengen we de verwante talen in één schrift. Eerdere benaderingen hebben linguïstisch suboptimale metingen gebruikt zoals de Levenstein edit distance om cognaten te detecteren, waarbij we aantonen dat de langste gemeenschappelijke subsequentie taalkundig meer geluid is en de prestaties van tweetalige lexicon inductie verbetert. We laten zien dat onze aanpak de nauwkeurigheid van tweetalige lexicon inductiemethoden op deze talen vele malen kan verhogen, waardoor tweetalige lexicon inductie benaderingen haalbaar zijn voor dergelijke onvoldoende beschikbare talen.', 'de': 'Zweisprachige Lexikone sind ein wichtiges Werkzeug für unzureichend ausgestattete Sprachen und neueste State-of-the-Art Ansätze zu diesem Thema nutzen vortrainierte einsprachige Worteinbettungen unter Verwendung von überwachten oder halbüberwachten Ansätzen. Diese Ansätze erfordern jedoch mehrsprachige Informationen wie Seed-Wörterbücher, um das Modell zu trainieren und eine lineare Transformation zwischen den Wort-Einbettungsräumen zu finden. Vor allem bei Sprachen mit geringen Ressourcen sind Seed-Wörterbücher nicht leicht verfügbar, und als solche produzieren diese Methoden extrem schwache Ergebnisse auf diesen Sprachen. In dieser Arbeit konzentrieren wir uns auf die dravidischen Sprachen Tamil, Telugu, Kannada und Malayalam, die noch anspruchsvoller sind, da sie in einzigartigen Skripten geschrieben sind. Um orthographische Informationen und Cognate in diesen Sprachen zu nutzen, bringen wir die verwandten Sprachen in einer einzigen Schrift zusammen. Bisherige Ansätze haben linguistisch suboptimale Messungen wie die Levenstein-Schnittdistanz zur Erkennung von Kognitionen verwendet, wobei wir zeigen, dass die längste gemeinsame Subsequenz sprachlich mehr Ton ist und die Leistung der zweisprachigen Lexikon-Induktion verbessert. Wir zeigen, dass unser Ansatz die Genauigkeit zweisprachiger Lexikon-Induktionsmethoden auf diesen Sprachen um ein Vielfaches erhöhen kann, wodurch zweisprachige Lexikon-Induktionsansätze für solche unzureichend ausgestatteten Sprachen möglich werden.', 'id': 'Lexikon berbahasa adalah alat penting untuk bahasa yang tidak memiliki sumber daya dan pendekatan terbaru baru-baru ini untuk pengaruh penerbangan kata monobahasa yang dilatih sebelumnya menggunakan pendekatan yang diawasi atau semi-diawasi. However, these approaches require cross-lingual information such as seed dictionaries to train the model and find a linear transformation between the word embedding spaces.  Terutama dalam kasus bahasa dengan sumber daya rendah, kamus benih tidak mudah tersedia, dan sebagai seperti itu, metode ini menghasilkan hasil yang sangat lemah pada bahasa ini. Dalam pekerjaan ini, kami fokus pada bahasa Dravidia, yaitu Tamil, Telugu, Kannada, dan Malayalam, yang bahkan lebih menantang karena mereka ditulis dalam skrip unik. Untuk mengambil keuntungan dari informasi ortografik dan pengetahuan dalam bahasa-bahasa ini, kami membawa bahasa-bahasa yang berhubungan ke dalam skrip tunggal. Previous approaches have used linguistically sub-optimal measures such as the Levenshtein edit distance to detect cognates, whereby we demonstrate that the longest common sub-sequence is linguistically more sound and improves the performance of bilingual lexicon induction.  Kita menunjukkan bahwa pendekatan kita dapat meningkatkan akurasi metode induksi leksikon bilingual pada bahasa-bahasa ini banyak kali, membuat pendekatan induksi leksikon bilingual mudah dilakukan untuk bahasa-bahasa yang tidak memiliki sumber daya.', 'ko': '이중 언어 사전은 자원이 부족한 언어에 있어서 중요한 도구이다. 최근의 최신 연구 방법은 감독이나 반감독의 방법을 이용하여 미리 훈련된 단어를 삽입했다.그러나 이러한 방법은 피드 사전과 같은 다양한 언어 정보를 통해 모델을 훈련시키고 단어가 공간에 삽입되는 사이에 선형 변환을 찾아야 한다.특히 자원이 부족한 언어에서는 씨앗 사전을 쉽게 얻을 수 없기 때문에 이런 방법이 이런 언어에서 발생하는 결과는 매우 미약하다.이 작업에서 우리는 테밀어, 테루고어, 카나다어, 말레이시아어에 중점을 둘 것이다. 왜냐하면 그들은 독특한 각본으로 작성되었기 때문에 더욱 도전적이다.이러한 언어의 정자법 정보와 동원어를 이용하기 위해 우리는 관련 언어를 스크립트에 통합할 것이다.이전의 방법은 언어학에서 가장 긴 공공 서열이 언어학적으로 더욱 합리적이고 이중 언어 어휘의 귀납 성능을 향상시켰다는 것을 증명했다.우리는 우리의 방법이 여러 차례 이중 언어 사전 귀납 방법이 이런 언어에서의 정확성을 높일 수 있고 이중 언어 사전 귀납 방법이 자원이 부족한 언어에서 실행할 수 있음을 나타낸다.', 'fa': 'زبان\u200cهای دوگانه یک ابزار حیاتی برای زبان\u200cهای زیر منابع و نزدیک\u200cهای اولین موقعیت هنر به این تغییر تغییر دادن کلمه\u200cهای یک زبان با استفاده از نزدیک\u200cهای تحت نظر یا نیمه تحت نظر قرار گرفته است. با این حال، این دسترسی\u200cها به اطلاعات متفاوت زبان نیاز دارند، مثل لغو\u200cهای دانه برای آموزش مدل و تغییر خطی بین فضایی\u200cهای متنوع کلمه. مخصوصا در مورد زبانهای کم منابع، لغوی دانه\u200cها به آسانی دسترسی ندارند، و به عنوان این روش، این روش نتایج بسیار ضعیف روی این زبانها تولید می\u200cکند. در این کار، ما روی زبانهای دروادیه تمرکز می کنیم، یعنی تامیل، تلوگو، کاندا و مالایالام، که در نوشته های متفاوتی نوشته شده\u200cاند، بیشتر سخت\u200cتر است. برای استفاده از اطلاعات orthographic و شناختن در این زبانها، زبانهای ارتباطی را به یک نوشته\u200cای وارد می\u200cکنیم. دستورات قبلی از اندازه\u200cهای زیر optimal زبانی مثل فاصله ویرایش Levenshtein برای شناسایی شناسایی استفاده کرده\u200cاند، که به وسیله آن نشان می\u200cدهیم که طولانی\u200cترین زیر دستورات معمولی به زبان\u200cشناسی صدای بیشتر است و فعالیت فعالیت زبان\u200cشناسی دوزبانی را بهتر می\u200cکند ما نشان می دهیم که دسترسی ما می تواند دقیق روش\u200cهای فعالیت زبان دو زبان را بر این زبانها بسیار زیادی افزایش دهد، و این کار را می\u200cتواند به دسترسی زبان دو زبان فعالیت دهد.', 'sw': 'Leksisi za lugha za Kiingereza ni zana muhimu kwa lugha za asili zilizo na mbinu za hivi karibuni za hali ya sanaa za aina hii zinazotumiwa na maneno ya lugha ya kiutamaduni kwa kutumia mbinu za kudhibitiwa au zinazofuatiliwa na nusu. Hata hivyo, mbinu hizi zinahitaji taarifa za lugha za aina mbalimbali kama vile dictionary seed to train model na kutafuta mabadiliko ya msingi kati ya maeneo yanayoingia. Hasa kwa ajili ya lugha zenye rasilimali ndogo, dictionary of seed hazipatikani kwa urahisi, na kwa mfano, njia hizi zinaleta matokeo dhaifu sana katika lugha hizi. In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  Kutumia matumizi ya taarifa za kiorthografia na simu kwa lugha hizi, tunaleta lugha zinazohusiana katika maandiko moja. Hatua zilizopita zimetumia hatua za kutumia lugha zilizo na matumaini kama vile vile Levenshtein kuhariri umbali wa kutambua viungo, ambapo tunaonyesha kuwa muda mrefu zaidi wa mfumo wa lugha ni sauti zaidi na kuboresha utendaji wa sekta ya lexico ya lugha mbili. Tunaonyesha kwamba mbinu yetu inaweza kuongeza ukweli wa njia za viwanda vya lexico viwili kwa lugha hizi mara nyingi, na kuzifanya viwanda vya lexico viwili vinawezekano kwa lugha kama hizi zenye rasilimali.', 'tr': 'Çap sözleri gollanmış diller üçin esasy bir alatdyr we ýakyn-da süzgeýän edilen monodil sözleri gollanmış hereketlerden çykarmak üçin ullanýarlar. Ýöne bu gollaşyklar modelini öwrenmek üçin gaty dilli maglumaty ýaly tarz sözlükleri gerek we sözleriň içindeki seleňleri arasynda çyzgylyk üýtgetmelidir. Özellikle iň az diller bolan ýagdaýda, tarz sözleriň uňsatly meňzeşli däldir we şeýle däldir, bu ýagdaýlar bu dillerde gaty zayıf netijeleri getirilýär. Bu işde biz Drawiýaly dillere - Tamil, Telugu, Kannada we Malayalam dillerine üns berýäris. Olar özleriniň beýleki skriptlerde ýazylan ýaly gaty kynçylykly. Bu dillerde ortografiýa maglumatlary ulanmak we tanyş etmek üçin, gerekli dilleri ýeke bir skript içine alýarys. Öňki golaýarlar bilen bilimsel düzümlerni tapmak üçin Levenshtein düzümlerni üýtgetmek üçin ullanýarlar. Şol sebäbi biziň iň uly sub-sequencesiniň lingwistiki köp ses diýip, we iki dilli leksikon täsirini gowuraýarlar. Biz öz ýaryşymyz bu dillerde iki dil işaretçilikleriniň takyklygyny birnäçe gezek artyp bilýäris we iki dil işaretçiliklerini bu şekilde etmäge mümkin edip bilýäris.', 'af': "Die tweede leksies is 'n vitaal gereedskap vir onder-hulpbronne tale en onlangse staat-van-kunsten toegang tot hierdie leverage aangedraai monolinge woord inbêdings met die gebruik van ondersoekte of semi-ondersoekte toegang. Maar hierdie toegang benodig kruistale inligting soos saad woordeboekvorms om die model te tref en 'n lineêre transformasie tussen die woord ingesluit spasies te vind. Spesiaal in die geval van lae-hulpbronne tale, saadswoordeboeke is nie leeg beskikbaar nie, en soos sodat, hierdie metodes produseer ekstrem swak resultate op hierdie tale. In hierdie werk fokus ons op die Dravidiese tale, dit is Tamil, Telugu, Kannada en Malayalam, wat selfs meer belangrik is soos hulle in unieke skripte geskrywe is. Om voordeel van orthografiese inligting te neem en in hierdie taal konnekteer, bring ons die verwante tale in 'n enkele skrip. Vorige toegang het lingwisiese sub-optimale maat gebruik soos die Levenshtein redigeer afstand om konnekteer te ontdek, waarmee ons wys dat die langste gemeenskaplike sub-sekwensie lingwisiese meer klank is en die prestasie van twee-lingwisse leksikoon induksie verbeter. Ons wys dat ons toegang kan die presisie van twee tale leksikon induksie metodes verhoog op hierdie tale baie maal, maak twee tale leksikon induksie toegang tot toegang tot so onder hulpbronne tale.", 'am': 'የቋንቋ ቋንቋዎች እና የቀድሞው የቋንቋ-ቋንቋ-አካባቢ የደረጃ ግንኙነት አካባቢ ነው፡፡ ነገር ግን ይህ ደረጃዎች የቋንቋ ቋንቋ መረጃዎች እንደ ዘር መዝገብ ቃላትን ለማስተማር እና በንግግር መካከል የደረጃ ለውጥ ማግኘት ያስፈልጋል፡፡ ይልቁንም በተለየ ከታናሹ ቋንቋዎች፣ ዘር መዝገብ መዝገብ ቀላል አይገኙም፣ እንደዚህም፣ እነዚህ ሥርዓቶች በቋንቋዎች ላይ እጅግ ደካማ ፍሬዎችን ያፈራሉ፡፡ In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  እነዚህን ቋንቋዎች የኦሮግራፊ መረጃ እና ቀፎችን ለመጠቀም፣ የተገኘውን ቋንቋዎች በአንድ ጽሑፍ እናመጣለን፡፡ የቀድሞው ደረጃዎች የቋንቋ-ቋንቋ አካባቢ መጠቀሚያ እንደሌvenshtein ማቀናቀፍ ርቀት ለማግኘት ነው፤ ስለዚህም የረጅም ሁኔታ የቋንቋ ቋንቋ ድምፅ እንዲበልጥ እና የሁለት ቋንቋ ሊክሲዮን ክፍተት እንዲያበጃል እናስታውቃለን፡፡ የቋንቋ ቋንቋዎች የሌክሲኮን አካሄዱን እርግጠኛ እንዲያበዛ እናሳየዋለን፡፡', 'sq': 'Lexikonet dygjuhësore janë një mjet thelbësor për gjuhët e mungesës së burimeve dhe qasjet e kohëve të fundit të teknologjisë për këtë vlerësim përfshirje të fjalëve monogjuhësore që përdorin qasje të mbikqyrura apo gjysmë-mbikqyrura. Megjithatë, këto qasje kërkojnë informacion ndërgjuhësor të tillë si fjalorët e frymës për të trajnuar modelin dhe për të gjetur një transformim linear midis fjalës hapësirave të përfshirjes. Especially in the case of low-resourced languages, seed dictionaries are not readily available, and as such, these methods produce extremely weak results on these languages.  Në këtë punë, ne përqëndrohemi në gjuhët dravidiane, veçanërisht Tamil, Telugu, Kannada dhe Malayalam, të cilat janë edhe më sfiduese pasi janë shkruar në skripte unike. Për të përfituar nga informacioni ortografik dhe njohuritë në këto gjuhë, ne sjellim gjuhët e lidhura në një script të vetëm. Përqasjet e mëparshme kanë përdorur masa gjuhësore sub-optimale të tilla si distanca e editimit Levenshtein për të zbuluar njohurit, me të cilat ne demonstrojmë se nënsekuenca më e gjatë e përbashkët është gjuhësore më e tingullueshme dhe përmirëson performancën e induksionit të lexikonëve dygjuhës. Ne tregojmë se qasja jonë mund të rritë saktësinë e metodave të induksionit të lexikonëve dygjuhës në këto gjuhë shumë herë, duke bërë të mundshme qasjet e induksionit të lexikonëve dygjuhës për gjuhë të tilla me pak burime.', 'hy': 'Երկլեզվային լեքսիկոնները կարևոր գործիք են թերռեսուրսների և վերջերս բարձրագույն մոտեցումների համար այս հնարավորության վրա նախկին ուսումնասիրել միալեզվային բառերի ներդրման համար, օգտագործելով վերահսկված կամ կիսավերահսկված մոտեցումներ: Այնուամենայնիվ, այս մոտեցումները պահանջում են երկլեզվային տեղեկատվություն, ինչպիսիք են սերմնային բառարանները, մոդելի վարժեցնելու համար և գտնելու գծային փոխակերպում բառի ներդրող տարածքների միջև: Հատկապես ցածր ռեսուրսներ ունեցող լեզուների դեպքում սերմային բառարանները հեշտությամբ հասանելի չեն, և որպես այդպիսի, այս մեթոդները շատ թույլ արդյունքներ են տալիս այս լեզուների վրա: Այս աշխատանքի ընթացքում մենք կենտրոնանում ենք դրավիդիական լեզուների վրա, հատկապես Թամիլիի, Թելուգու, Կանադայի և Մալալայալամի լեզուների վրա, որոնք ավելի դժվար են, քանի որ դրանք գրված են առանձնահատուկ գրքերում: Օրտոգրաֆիկ ինֆորմացիան և ճանաչությունը օգտագործելու համար այս լեզուներում մենք դրանց հետ կապված լեզուները միայն մեկ գրառում ենք: Անցյալ մոտեցումները օգտագործել են լեզվաբանական ենթաօպտիմալ չափումներ, ինչպիսիք են Լեյվերշտեյնի խմբագրման հեռավորությունը կոգնատների հայտնաբերելու համար, որի միջոցով մենք ցույց ենք տալիս, որ ամենաերկար ընդհանուր ենթահաջորդականությունը լեզվաբանական առումով ավելի ձայն է և բարելավում է երկ Մենք ցույց ենք տալիս, որ մեր մոտեցումը կարող է բարձրացնել երկլեզու լեքսիկոնի ինդուկցիոն մեթոդների ճշգրիտությունը այս լեզուների վրա շատ անգամ, դարձնելով երկլեզու լեքսիկոնի ինդուկցիոն մոտեցումները իրականացնելի նման թերռեսուրսների լեզու', 'az': 'İkinci dillər çox qüvvətli dillər üçün həyat verən və yeni müəllif şəkildə bu tərəfə yaxınlaşan monodil sözlərin istifadə edilməsi və ya yarı-gözləyir tərəflərlə istifadə edilən tərəflərə istifadə edilməsi üçün çox vacib bir vasitədir. Ancaq bu tərzlərin modeli təhsil etmək üçün çox dilli məlumatları lazımdır və səhifələri içərisində yazılmış məlumatlar arasında linear dəyişiklik tapmaq istəyirlər. Özellikle də düşük qüsusiyyətli dillərdə, əkin sözləri asanlıqla mümkün deyildir və buna görə də bu metodlar bu dillərdə çox zəif sonuçlar ürəkləyir. Bu işdə, biz Dravid dillərinə, Tamil, Telugu, Kannada və Malayalam dillərinə odaqlanırıq. Onlar özlərinin bəzi yazılarda yazıldığı kimi daha çətin olanlardır. Bu dillərdə ortografik məlumatlarından faydalanmaq və tanıtmaq üçün, əlaqəli dilləri tək bir skriptə gətiririk. Əvvəlki tərzimlər, Levenshtein düzəltmə məsafəsi kimi dil-optimal ölçülərini istifadə etdilər, bu vasitəsilə ən uzun orta sub-sequence dil dilində daha çox səs və iki dil tərzimlərin tərzimlərini daha yaxşılaşdırır. Bizim tərzimiz bu dillərdə iki dil induksyon metodlarının doğruluğunu çoxlu dəfə artırar, iki dil leksikon induksyonu bu dillərə çoxlu dəfə müvəffəq edər.', 'bn': 'বিলিঙ্গুয়েল লেক্সিকোর একটি গুরুত্বপূর্ণ উপাদান এবং সাম্প্রতিক রাষ্ট্র-শিল্পের ক্ষেত্রে এই লেভারেজের ক্ষেত্রে সাম্প্রতিক ভাষার প্রতিক্রি তবে এই প্রযুক্তিগুলোর ক্ষেত্রে ক্রস-ভাষাভাষী তথ্য প্রয়োজন, যেমন বৃষ্টিশীল অভিভাবক, মডেল প্রশিক্ষণ করার জন্য এবং শব্দের মধ্যে  Especially in the case of low-resourced languages, seed dictionaries are not readily available, and as such, these methods produce extremely weak results on these languages.  এই কাজে আমরা দ্রাভিডিয়ার ভাষার দিকে মনোযোগ দিচ্ছি, যারা তামিল, টেলুগু, কানানাদা এবং মালায়ালাম, যারা আরো চ্যালেঞ্জ করছে যেহেতু তারা ব এই ভাষায় অর্থোগ্রাফিক তথ্য এবং কোক্নেটের সুবিধা ব্যবহার করার জন্য আমরা সংশ্লিষ্ট ভাষাগুলো একটি স্ক্রিপ্টে নি পূর্ববর্তী পদক্ষেপ ভাষাভাষায় সাব-অপারেমিক পদক্ষেপ ব্যবহার করেছে যেমন লেভেনশেইন সম্পাদনার দূরত্ব, যেখানে আমরা দেখাচ্ছি যে সবচেয়ে দীর্ঘ সাধারণ সাব-সেকেন্স ভাষায় আরো  আমরা দেখাচ্ছি যে এই ভাষায় দুই ভাষায় লেক্সিকোন শিল্পের মাধ্যমের সঠিকভাবে বৃদ্ধি করতে পারে, যার ফলে দুই ভাষায় লেক্সিকোর শিল্পের কাছে', 'bs': 'Bilingualni leksikoni su vitalni alat za neposredne jezike i nedavni pristupi stanju umjetnosti ovoj utjecaja pretvorili monojezičke riječi uključujući pristupe nadziranom ili polu nadziranom. Međutim, ovi pristupi zahtijevaju međujezičke informacije kao što su riječi semena za treniranje model a i pronalaženje linearne transformacije između riječi uključenih prostora. Posebno u slučaju niskog resursa jezika, riječi o semenu nisu lako dostupni, i kao takve, ove metode proizvode ekstremno slabe rezultate na ovim jezicima. U ovom poslu, fokusiramo se na dravidski jezik, a to je Tamil, Telugu, Kannada i Malayalam, koji su još izazovniji kao što su napisani u jedinstvenim skriptovima. Da bismo iskoristili ortografsku informaciju i kognirali na ovim jezicima, doveli smo povezane jezike u jednog skripta. Prethodni pristupi su koristili lingvistički sub-optimalne mjere poput Levenshtein uredne udaljenosti za otkrivanje kognija, s kojim pokazujemo da je najduža zajednička podsekvencija jezički više zvuka i poboljšava učinku dvojezičke indukcije leksiona. Pokazujemo da naš pristup može povećati preciznost metoda indukcije dvojezika na ovim jezicima mnogo puta, čineći pristupe indukciji dvojezika leksičkim jezicima mogućim za takve podresursne jezike.', 'ca': "Els lexicòns bilingües són una eina vital per a les llengües amb menys recursos i els enfocaments moderns recents d'aquesta utilització d'incorporacions de paraules monolingües pré-entrenades utilitzant enfocaments supervisats o semi-supervisats. No obstant això, aquests enfocaments requereixen informació translingüística com els diccionaris de semilles per entrenar el model i trobar una transformació linear entre les paraules espais d'incorporació. Especialment en el cas de llengües amb pocs recursos, els diccionaris de semilles no estan disponibles fàcilment, i com a tal, aquests mètodes produeixen resultats extremadament dèbils en aquestes llengües. En aquest treball, ens centrem en les llengües dravídiques, a saber, tamil, Telugu, Kannada i malàyalam, que són encara més desafiables com s'escriuen en escriptures únices. Per aprofitar la informació ortogràfica i els coneixements en aquestes llengües, portem les llengües relacionades en una sola escriptura. Els enfocaments anteriors han utilitzat mesures lingüísticament sub-optimals com la distància d'edició de Levenshtein per detectar cognats, amb la qual demostrem que la subseqüència més llarga comú és lingüísticament més so i millora el rendiment de l'inducció bilingüe del lexicó. Mostrem que el nostre enfocament pot augmentar la precisió dels mètodes d'inducció bilingüe dels lexicons en aquestes llengües moltes vegades, fent possible els enfocaments d'inducció bilingüe dels lexicons per a les llengües tan poc resources.", 'cs': 'Dvoujazyčné slovníky jsou důležitým nástrojem pro nedostatečné zdroje jazyků a nedávné nejmodernější přístupy k tomuto využití předem trénovaných jednojjazyčných slovních vložení pomocí přístupů pod dohledem nebo polovičním dohledem. Tyto přístupy však vyžadují vícejazyčné informace, jako jsou například semenné slovníky, aby trénovaly model a nalezly lineární transformaci mezi vkládacími mezerami slova. Zejména v případě jazyků s nízkými zdroji nejsou semenné slovníky snadno dostupné, a proto tyto metody přinášejí extrémně slabé výsledky na tyto jazyky. V této práci se zaměřujeme na dravidské jazyky, konkrétně tamilštinu, telugu, kannadu a malajálam, které jsou ještě náročnější, protože jsou psány v unikátních skriptech. Pro využití ortografických informací a kognitivních znaků v těchto jazycích přinášíme související jazyky do jednoho písma. Předchozí přístupy používaly lingvisticky suboptimální měřítka, jako je Levensteinova editační vzdálenost k detekci koňátů, přičemž demonstrujeme, že nejdelší běžná podsekvence je lingvisticky větší zvuk a zlepšuje výkon indukce dvojjazyčného lexikonu. Ukazujeme, že náš přístup může mnohokrát zvýšit přesnost dvojjazyčných indukčních metod lexikonu u těchto jazyků, čímž jsou dvojjazyčné indukční přístupy pro takové nedostatečné zdroje.', 'et': 'Kahekeelsed leksikonid on väga olulised vahendid alaressurssidega keelte jaoks ja hiljutised kaasaegsed lähenemisviisid sellele, et võimendada eelnevalt treenitud ühekeelseid sõnade manustamist, kasutades järelevalve all või pooljärelevalve all olevaid lähenemisviise. Sellised lähenemisviisid nõuavad siiski keeleülest teavet, näiteks seemnesõnaraamatuid mudeli koolitamiseks ja lineaarse muundamise leidmiseks sõna manustamisruumide vahel. Eriti vähese ressursiga keelte puhul ei ole algsõnastikud kergesti kättesaadavad ja seetõttu annavad need meetodid nende keelte puhul äärmiselt nõrgad tulemused. Selles töös keskendume dravidia keeltele, nimelt tamil, telugu, kannada ja malajalam, mis on veelgi keerulisemad, kuna need on kirjutatud unikaalsetes skriptides. Selleks et kasutada ära ortograafilist teavet ja kongaate nendes keeltes, toome seotud keeled ühte skripti. Varasemad lähenemised on kasutanud keeleliselt ebaoptimaalseid mõõtmeid, näiteks Levenshteini redigeerimise kaugust kogniatide tuvastamiseks, kusjuures näitame, et pikim levinud alamjada on keeleliselt helisem ja parandab kakskeelse leksikoni induktsiooni jõudlust. Näitame, et meie lähenemisviis võib mitmeid kordi suurendada kakskeelse leksikoni induktsiooni meetodite täpsust nendes keeltes, muutes kakskeelse leksikoni induktsiooni meetodid võimalikuks selliste alaressurssidega keelte puhul.', 'fi': 'Kaksikieliset sanastot ovat elintärkeä työkalu vajaakäyttöisille kielille, ja viimeaikaiset nykyaikaiset lähestymistavat tähän hyödyntävät ennalta harjoitettuja monokielisiä sanaupotuksia valvottuja tai puolivalvottuja lähestymistapoja käyttäen. Nämä lähestymistavat edellyttävät kuitenkin monikielistä tietoa, kuten siemensanakirjoja mallin kouluttamiseksi ja lineaarisen muunnoksen löytämiseksi sanan upotusväliltä. Etenkin vähävaraisten kielten kohdalla siemensanakirjoja ei ole helposti saatavilla, ja näin ollen nämä menetelmät tuottavat erittäin heikkoja tuloksia näillä kielillä. Tässä työssä keskitytään dravidian kieliin eli tamiliin, teluguun, kanadaan ja malayalamiin, jotka ovat vieläkin haastavampia, koska ne on kirjoitettu ainutlaatuisilla käsikirjoituksilla. Hyödyntääksemme ortografista tietoa ja kogniateja näillä kielillä, tuomme niihin liittyvät kielet yhdeksi skriptiksi. Aiemmat lähestymistavat ovat käyttäneet kielellisesti alioptimaalisia mittareita, kuten Levenshteinin editointietäisyyttä kogniattien havaitsemiseen, jolloin osoitamme, että pisin yleinen alasekvenssi on kielellisesti äänekkäämpi ja parantaa kaksikielisen sanaston induktion suorituskykyä. Osoitamme, että lähestymistapamme voi lisätä kaksikielisten sanaston induktiomenetelmien tarkkuutta näillä kielillä useaan otteeseen, mikä tekee kaksikielisten sanaston induktiomenetelmien toteuttamiskelpoisiksi tällaisilla vajaakäyttöisillä kielillä.', 'sk': 'Dvojezični leksikoni so ključno orodje za premalo virov jezikov in nedavne najsodobnejše pristope k temu vzvodu predhodno uveljavljenih enojezičnih besednih vdelav z uporabo nadzorovanih ali polnadzorovanih pristopov. Vendar pa ti pristopi zahtevajo večjezične informacije, kot so semenski slovarji za usposabljanje modela in iskanje linearne transformacije med besedami, ki vsebujejo prostore. Zlasti v primeru jezikov z nizkimi viri semenski slovarji niso takoj na voljo, zato te metode pri teh jezikih prinašajo izjemno slabe rezultate. V tem delu se osredotočamo na dravidske jezike, namreč tamil, telugu, kanada in malajalam, ki so še bolj zahtevni, saj so napisani v edinstvenih scenarijih. Da bi izkoristili ortografske informacije in spoznanja v teh jezikih, povezane jezike združimo v eno samo pisavo. Prejšnji pristopi so uporabili jezikosloško suboptimalne meritve, kot je Levenshstein urejevalna razdalja za zaznavanje kognitov, pri čemer dokazujemo, da je najdaljše skupno podzaporedje jezikosloško bolj zvočno in izboljšuje učinkovitost dvojezične indukcije leksikona. Pokazali smo, da lahko naš pristop večkrat poveča natančnost dvojezičnih metod indukcije leksikona v teh jezikih, kar omogoča izvedbo dvojezičnih indukcijskih pristopov za takšne jezike s premalo virov.', 'ha': "KCharselect unicode block name Haƙĩƙa, waɗannan hanyõyin sun ƙayyade bayani na takardar lugha masu hushi kamar dictionary ɗin zũri dõmin su sanar da shirin motel kuma su sami canza juyin linje tsakanin filayen da ke cikin filayen. @ info: whatsthis In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  To, don ka yi amfani da masu tsari na ortografi da koyi cikin lugha waɗannan, za'a zo da zimannan da aka yi danganta zuwa wani littafi guda. Tsarin da suka riga suka yi amfani da taki masu sub-Optical kamar durowa Lehenshtein dõmin ya gane koki, inda Muke nuna cewa, ƙaranci sauri na zaman shawarar da ke cikin lugha na'ura na ƙaranci aikin leksikon na biyu. Tuna nũna cewa hanyoyinmu yana ƙara tsari na-aikin leksikon da ke cikin lugha biyu sau biyu, kuma za'a sami ƙanshi na lugha biyu na'ura da za'a fasahar da su a ƙari.", 'jv': 'Bilingual politenessoffpolite"), and when there is a change ("assertive Mangkin ngomong kapan langga sing kelas-kelas, diketeksi winih ora ngejarang ngono ngono koyo ngono koyo ngono kuwi, metudhakan iki dadi akeh pebutuha ujaran ning langga iki. Nang gawar iki, kita kang dipun nggo langgambar de Drawian, liyane Tamil, telu, Kanadan lan malayam, sing luwih basa sing ngenakut liyane kudu akeh nyong bisa kelas nang isura winih sing ujaran. Perangkat ingkang sampeyan ortografèk karo akeh sampeyan ingkang iki, kita dadi nggawe langkang sampeyan ing sak saben seneng pisan. Awak dhéwé sing beraksi akeh langgar-sistem sing gambar kelangan podho akeh basa gambar kanggo Ketokan Winih Awak dhéwé ngerasah bener dhéwé iso nggawe akeh akeh basa luwih basa ning arep iki, akeh basa luwih apik dhéwé, akeh akeh akeh basa langgar sapa-apik sing apik dhéwé.', 'he': 'הלקסיקונים מיליונגיים הם כלי חיוני לשפות מתחת למוצאות ומגישות חדשות לאחרונה למציאות מילים מיליונגיות מונושפות שמתאימות מראש באמצעות גישות מפקחות או חצי מפקחות. בכל אופן, גישות אלה דורשות מידע בין שפתיים כמו מילונים זרעים כדי לאמן את המודל ולמצוא שינוי לינרי בין המילה מקומות קישום. במיוחד במקרה של שפות עם משאבים נמוכים, מילונים זרעים לא זמינים בקלות, וככה, השיטות האלה יוצרות תוצאות חלשות מאוד בשפות האלה. In this work, we focus on the Dravidian languages, namely Tamil, Telugu, Kannada, and Malayalam, which are even more challenging as they are written in unique scripts.  To take advantage of orthographic information and cognates in these languages, we bring the related languages into a single script.  הגישות הקודמות השתמשו במדידות לא אופטימיות בשפה, כמו מרחק העורר של Levenshtein כדי לגלות קוגנייטים, שבה אנו מראים כי התת-רצף המשותף הארוך ביותר הוא יותר קול שפתית ומשתפר את ההפעלה של ההפעלה של הלקסיקון השולשי. אנו מראים שהגישה שלנו יכולה להעלות את הדיוקת של שיטות ההדליקה של לקסיקון שתיים-לשונים בשפות אלה פעמים רבות, מה שעושה גישות ההדליקה של לקסיקון שתיים-לשונים אפשריות לשפות כאלה עם פחות משאבים.', 'bo': 'Bilingual lexicons are a vital tool for under-resourced languages and recent state-of-the-art approaches to this leverage pretrained monolingual word embeddings using supervised or semi-supervised approaches. However, these approaches require cross-lingual information such as seed dictionaries to train the model and find a linear transformation between the word embedding spaces. ཁྱད་པར་ན་སྐད་ཡིག་ཆ་ཆ་ཉུང་བའི་ནང་དུ་བྱ་ཚིག་གི་ཐ་སྙད་ཅིག་ཡིན་མེད་པ་དང་། འདི་ལྟ་བུའི་ལམ་ལུགས་འདི་དག་སྐད་ཡིག་ནང་དུ་ འོན་ཀྱང་། ང་ཚོས་དུས་རབ་གྱི་སྐད་ཡིག To take advantage of orthographic information and cognates in these languages, we bring the related languages into a single script. སྔོན་གྱི་ཐབས་ལམ་ལུགས་ནི་སྐད་ཡིག་གཙང་ཆེ་བའི་ཐབས་ལམ་ལ་བེད་སྤྱོད་ཡོད། ང་ཚོས་རང་གི་ཐབས་ལམ་དེ་གཉིས་ཡིག་གཟུགས་ཀྱི་སྐད་རིགས་འདི་དག་གི་ཐོག་ལས་འགྱུར་བའི་ཐབས་ལམ་ལ་ཉར་བཅོས་ན།'}
{'en': 'Recycling and Comparing Morphological Annotation Models for Armenian Diachronic-Variational Corpus Processing', 'ar': 'إعادة التدوير والمقارنة بين نماذج الشرح الصرفي لمعالجة الجسد الأرمني الرقمي المتغير', 'fr': "Recyclage et comparaison de modèles d'annotation morphologique pour le traitement des corpus variationnels diachroniques arméniens", 'pt': 'Reciclando e Comparando Modelos de Anotação Morfológica para Processamento de Corpus Diacrônico-Variacional Armênio', 'es': 'Reciclaje y comparación de modelos de anotación morfológica para el procesamiento de corpus diacrónico-variacionales armenios', 'ja': 'アルメニアのジアクロニック変異体処理のための形態学的注釈モデルのリサイクルと比較', 'hi': 'रीसाइक्लिंग और आर्मेनियाई डायक्रोनिक-परिवर्तनीय कॉर्पस प्रसंस्करण के लिए रूपात्मक एनोटेशन मॉडल की तुलना', 'ru': 'Переработка и сравнение моделей морфологических аннотаций для армянской диахронно-вариационной обработки корпусов', 'zh': '亚美尼亚历变分语料库回收与较形注模', 'ga': 'Múnlaí Anótála Moirfeolaíocha a Athchúrsáil agus a Chomparáid le haghaidh Próiseáil Chorpais Dhiachrónach-Athránaigh Airméinis', 'hu': 'Újrahasznosítás és morfológiai jegyzékmodellek összehasonlítása örmény diakrónikus variációs testfeldolgozáshoz', 'it': "Riciclo e confronto dei modelli di annotazione morfologica per l'elaborazione dei corpi diacronici-variabili armeni", 'lt': 'Perdirbimas ir morfologinių anotacijų modelių palyginimas Armėnijos diachroninio ir kintamojo kūno apdorojimo modeliams', 'ka': 'Name', 'el': 'Ανακύκλωση και σύγκριση μορφολογικών υποδειγμάτων για την Αρμενική Διαχρόνια-Μεταβλητική Επεξεργασία Σώματος', 'ml': 'അര്\u200dമ്മേനിയന്\u200d ഡയറക്രോണിക്- വേറിയേഷന്\u200d കോര്\u200dപ്സ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനായി മോര്\u200dഫോളിക്കല്\u200d ആനോട്ടേഷന്\u200d മോ', 'kk': 'Армениялық диагроникалық- айнымалы корпус процессері үшін морфологикалық жазбалар үлгілерін қайталау және салыстыру', 'mk': 'Рециклирање и споредба на моделите на морфолошка анотација за процес на ерменско дијахронично-варијационален корпус', 'mt': 'Ir-riċiklaġġ u t-tqabbil ta’ Mudelli ta’ Annotazzjoni Morfoloġika għall-Ipproċessar tal-Korpus Dijakroniku-Varjazzjonali Armenjan', 'ms': 'Mengulangi dan membandingkan Model Annotasi Morfologik untuk Pemprosesan Korpus Diakronik-Variasi Armenia', 'mn': 'Арменийн диагроник-өөрчлөлтийн биеийн процессийн морфологик загваруудыг дахин хэрэглэх болон харьцуулах', 'no': 'Rekyclering og sammenlikning av morfologiske notasjonsmodeller for Armensk diakronisk- variasjonal korpushandsaming', 'pl': 'Recykling i porównanie modeli anotacji morfologicznych dla ormiańskiego przetwarzania korpusu diachronicznego', 'ro': 'Reciclarea și compararea modelelor de adnotare morfologică pentru procesarea corpului diacronic-variațional armen', 'sv': 'Återvinning och jämförelse av morfologiska noteringsmodeller för armenisk diakronisk variabel korpusbehandling', 'so': 'Dib-isticmaalidda iyo Comparinta Morphological Annotation Models for Armenian Diakroc-Variable Corpus Processing', 'ur': 'Name', 'si': 'Name', 'ta': 'அர்மெனியாவின் டையாக்ரோனிக்- மாறிகள் செயல்பாடு', 'sr': 'Рециклирање и сравње модела морфологичких нотација за обработку армянских диагронично-вариационних корпуса', 'vi': 'Chế độ lặp lại và so sánh Morphological Chú giải thích Models for Armenia diaChronic-biến Quốc Tập sản', 'uz': 'ArmeniyaName', 'bg': 'Рециклиране и сравняване на морфологични анотационни модели за арменска диахронно-вариационна обработка на корпуса', 'hr': 'Recikliranje i usporedba modela morfoloških oznake za proces Armenskog dijagroničnog i varijantnog korpusa', 'nl': 'Recycling en vergelijking van morfologische annotatiemodellen voor Armeense diachronisch-variantionele korpusverwerking', 'da': 'Genbrug og sammenligning af morfologiske noteringsmodeller til armensk diakronisk variationsbehandling', 'de': 'Recycling und Vergleich morphologischer Annotationsmodelle für die armenische diachronisch-variationelle Korpusverarbeitung', 'ko': '아르메니아어 역시 변분 어료 라이브러리 처리 중 형태 표기 모델의 회수와 비교', 'id': 'Recycling and Comparing Morphological Annotation Models for Armenian Diachronic-Variational Corpus Processing', 'fa': 'بازسازی و مقایسه نمونه\u200cهای نوشته\u200cهای مورفیولوژیکی برای پرداخت کورپوس دیاکرونیک و متغیر ارمنی', 'sw': 'Mradi wa Tamko za Kimorphological Annotation for the Armenian Diakroc-Variable Corpus', 'af': 'Herwerklik en vergelyking van Morphological Annotation Models vir Armeniese Diakronise- Veranderlike Korpus Verwerking', 'tr': 'Ermençe Diachronik-Çeşitli Körpüs işlemleri üçin Morfolojik duýgulama Modelleri', 'sq': 'Riçiklimi dhe krahasimi i modeleve të anotacionit morfologjik për procesimin e korpusit diakronik-variacional armen', 'am': 'ምርጫዎች', 'az': 'Ermenik Diakroniki-Variasiyonlu Cürpüs işləməsi üçün Morphological Annotation Modellərini yenidən istifadə etmək və Comparison', 'hy': 'Հաշվի առնելու և համեմատելու մոդելները', 'bn': 'আর্মেনিয়ান ডায়ারোনিক- ভিয়েয়ারিয়েশন কোর্পাস প্রক্রিয়া', 'bs': 'Recikliranje i usporedba modela morfološke annotacije za proces Armenskog dijagroničnog-varijantnog korpusa', 'et': 'Armeenia diakroonilise variatsiooni korpuse töötlemise morfoloogiliste annotatsioonimudelite ringlussevõtt ja võrdlemine', 'ca': 'Recycling and Comparing Morphological Annotation Models for Armenian Diachronic-Variational Corpus Processing', 'cs': 'Recyklace a srovnání morfologických anotací pro arménské diachronicko-variační zpracování korpusů', 'fi': 'KierrĂ¤tys ja morfologisten huomautusmallien vertailu Armenian diakroonisessa ja variaatiokorpuskĂ¤sittelyssĂ¤', 'jv': 'Reycling and Compring', 'sk': 'Recikliranje in primerjava morfoloških annotacijskih modelov za armensko diakronično-variacijsko obdelavo korpusa', 'he': 'Recycling and Comparing Morphological Annotation Models for Armenian Diachronic-Variational Corpus Processing', 'bo': 'Recycling and Comparing Morphological Annotation Models for Armenian Diachronic-Variational Corpus Processing', 'ha': 'KCharselect unicode block name'}
{'en': 'Armenian is a language with significant variation and unevenly distributed NLP resources for different varieties. An attempt is made to process an ', 'ar': 'الأرمينية هي لغة ذات تباين كبير وموارد البرمجة اللغوية العصبية الموزعة بشكل غير متساو لأنواع مختلفة. جرت محاولة لمعالجة نموذج RNN للتعليق التوضيحي المورفولوجي على أساس بيانات أرمينية مختلفة (مقدمة أو لا مع مجموعة مشروحة شكليًا) ، ولمقارنة نتائج التعليقات التوضيحية لـ RNN والنماذج المستندة إلى القواعد. تم إجراء اختبارات مختلفة لتقييم إعادة استخدام نموذج غير متخصص من اللماتة وعلامات نقاط البيع لأنواع اللغات منخفضة الموارد. ركز البحث على ثلاث لهجات وامتد إلى اللغة الأرمنية الغربية بمتوسط دقة 94،00٪ في lemmatization و 97،02٪ في علامات POS ، بالإضافة إلى إمكانية إعادة استخدام النماذج لتغطية مختلف الأصناف الأرمينية الأخرى. ومن المثير للاهتمام ، أن المقارنة بين نموذج RNN المدرب على الأرمينية الشرقية مع النموذج القائم على قاعدة الجسد القومي الأرمني الشرقي المطبق على الأرمينيين الغربيين أظهر تعزيزًا بنسبة 19 ٪ في الإعراب. يغطي هذا النموذج 88،79٪ من مجموعة بيانات قصيرة غير متجانسة باللغة الأرمينية الغربية ، ويمكن أن يكون أساسًا لتعليق توضيحي ضخم للمجموعة في هذا المعيار. يُقال أن النموذج القائم على RNN يمكن أن يكون بديلاً صالحًا للنموذج القائم على القواعد مع الأخذ في الاعتبار عوامل مثل استهلاك الوقت ، وإعادة الاستخدام لأنواع مختلفة من اللغة المستهدفة والنتائج النوعية المهمة في التعليق التوضيحي الصرفي.', 'fr': "L'arménien est une langue avec des variations importantes et des ressources PNL réparties de manière inégale pour différentes variétés. On essaie de traiter un modèle RNN pour l'annotation morphologique sur la base de différentes données arméniennes (fournies ou non avec des corpus annotés morphologiquement), et de comparer les résultats d'annotation des modèles RNN et basés sur des règles. Différents tests ont été réalisés pour évaluer la réutilisation d'un modèle non spécialisé de lemmatisation et de marquage POS pour les variétés de langues sous-financées. La recherche s'est concentrée sur trois dialectes et s'est étendue à l'arménien occidental avec une précision moyenne de 94,00\xa0% pour la lemmatisation et 97,02\xa0% pour le post-marquage, ainsi qu'une possibilité de réutilisation des modèles pour couvrir différentes autres variétés arméniennes. Il est intéressant de noter que la comparaison d'un modèle RNN formé sur l'arménien oriental avec le modèle basé sur les règles du Corpus national de l'Arménie orientale appliqué à l'arménien occidental a montré une amélioration de 19\xa0% dans l'analyse syntaxique. Ce modèle couvre 88,79\xa0% d'un court jeu de données hétérogène en arménien occidental et pourrait servir de base pour une annotation massive de corpus dans cette norme. Il est avancé qu'un modèle basé sur RNN peut constituer une alternative valide à un modèle basé sur des règles en tenant compte de facteurs tels que la consommation de temps, la réutilisation pour différentes variétés d'une langue cible et des résultats qualitatifs significatifs dans l'annotation morphologique.", 'es': 'El armenio es un idioma con variaciones significativas y recursos de PNL distribuidos de manera desigual para diferentes variedades. Se intenta procesar un modelo RNN para anotación morfológica sobre la base de diferentes datos armenios (proporcionados o no con corpus anotados morfológicamente), y comparar los resultados de anotación de RNN y modelos basados en reglas. Se realizaron diferentes pruebas para evaluar la reutilización de un modelo no especializado de lematización y etiquetado POS para variedades lingüísticas de escasos recursos. La investigación se centró en tres dialectos y se extendió al armenio occidental con una precisión media del 94,00% en la lematización y del 97,02% en el etiquetado POS, así como una posible reutilización de modelos para cubrir otras variedades armenias diferentes. Curiosamente, la comparación de un modelo de RNN entrenado en armenio oriental con el modelo basado en reglas del Corpus Nacional de Armenia Oriental aplicado al armenio occidental mostró una mejora del 19% en el análisis sintáctico. Este modelo cubre el 88,79% de un conjunto de datos heterogéneo corto en armenio occidental, y podría ser una línea de base para una anotación masiva de corpus en ese estándar. Se argumenta que un modelo basado en RNN puede ser una alternativa válida a uno basado en reglas, teniendo en cuenta factores tales como el consumo de tiempo, la reutilización para diferentes variedades de un idioma de destino y los resultados cualitativos significativos en la anotación morfológica.', 'pt': 'O armênio é uma língua com variação significativa e recursos de PNL distribuídos de forma desigual para diferentes variedades. É feita uma tentativa de processar um modelo RNN para anotação morfológica com base em diferentes dados armênios (fornecidos ou não com corpora morfologicamente anotados) e comparar os resultados de anotação de RNN e modelos baseados em regras. Diferentes testes foram realizados para avaliar a reutilização de um modelo não especializado de lematização e POS-tagging para variedades linguísticas com poucos recursos. A pesquisa se concentrou em três dialetos e se estendeu ainda mais ao armênio ocidental com uma precisão média de 94,00% na lematização e 97,02% na marcação POS, bem como uma possível reutilização de modelos para cobrir diferentes outras variedades armênias. Curiosamente, a comparação de um modelo RNN treinado em armênio oriental com o modelo baseado em regras do Corpus Nacional da Armênia Oriental aplicado ao armênio ocidental mostrou um aprimoramento de 19% na análise. Este modelo cobre 88,79% de um conjunto de dados heterogêneo curto em armênio ocidental e pode ser uma linha de base para uma anotação de corpus maciça nesse padrão. Argumenta-se que um modelo baseado em RNN pode ser uma alternativa válida para um modelo baseado em regras, levando em consideração fatores como consumo de tempo, reusabilidade para diferentes variedades de uma língua-alvo e resultados qualitativos significativos na anotação morfológica.', 'hi': 'अर्मेनियाई महत्वपूर्ण भिन्नता के साथ एक भाषा है और विभिन्न किस्मों के लिए असमान रूप से वितरित एनएलपी संसाधन। विभिन्न अर्मेनियाई डेटा (रूपात्मक रूप से एनोटेटेड कॉर्पोरेट के साथ प्रदान किए गए या नहीं) के आधार पर रूपात्मक एनोटेशन के लिए एक आरएनएन मॉडल को संसाधित करने का प्रयास किया जाता है, और आरएनएन और नियम-आधारित मॉडल के एनोटेशन परिणामों की तुलना करने के लिए। कम संसाधन वाली भाषा किस्मों के लिए लेमाटाइजेशन और पीओएस-टैगिंग के एक अनिर्दिष्ट मॉडल के पुन: उपयोग का मूल्यांकन करने के लिए विभिन्न परीक्षण किए गए थे। अनुसंधान ने तीन बोलियों पर ध्यान केंद्रित किया और आगे पश्चिमी अर्मेनियाई तक विस्तारित किया, जिसमें लेमेटाइजेशन में 94,00% और पीओएस-टैगिंग में 97,02% की औसत सटीकता के साथ-साथ विभिन्न अन्य अर्मेनियाई किस्मों को कवर करने के लिए मॉडल की संभावित पुनरावृत्ति भी थी। दिलचस्प बात यह है कि पूर्वी अर्मेनियाई पर प्रशिक्षित एक आरएनएन मॉडल की तुलना पूर्वी अर्मेनियाई राष्ट्रीय कॉर्पस नियम-आधारित मॉडल के साथ पश्चिमी अर्मेनियाई पर लागू की गई थी, जिसमें पार्सिंग में 19% की वृद्धि देखी गई थी। यह मॉडल पश्चिमी अर्मेनियाई में एक छोटे विषम डेटासेट के 88,79% को कवर करता है, और उस मानक में बड़े पैमाने पर कॉर्पस एनोटेशन के लिए एक आधार रेखा हो सकता है। यह तर्क दिया जाता है कि एक आरएनएन-आधारित मॉडल एक नियम-आधारित के लिए एक वैध विकल्प हो सकता है जो समय-खपत, लक्ष्य भाषा की विभिन्न किस्मों के लिए पुन: प्रयोज्य और रूपात्मक एनोटेशन में महत्वपूर्ण गुणात्मक परिणामों जैसे कारकों पर विचार करता है।', 'zh': '亚美尼亚语者,显异NLP资布不均之言,宜于异变体。 尝试以亚美尼亚数(不给形注语料库)RNN模形以注之,较RNN与法注。 异试之试,以估资源贫乏之言变体者非殊词形还原与POS标模形之用。 治侧重于三言,益广西亚美尼亚语,词形还其均准确率为94,00%,POS其平准确率为97,02%其可用者涵盖其他亚美尼亚品。 有趣者,教于东亚美尼亚语RNN与西亚美尼亚语东亚美尼亚国语料库则较著,解析增19%。 盖西亚美尼亚语中短异构数集之88,79%可以为大率语料库注之基线。 或以为RNN可以为法者代方,兼虑日月消耗,语言不同变体者可用性及注释中显者定性素也。', 'ja': 'アルメニア語は顕著なバリエーションを持つ言語であり、さまざまな品種のNLPリソースが不均等に分布しています。 異なるアルメニアのデータに基づいて形態学的注釈のためのRNNモデルを処理し（形態学的に注釈されたコーパスと共に提供されるかどうか）、RNNとルールベースのモデルの注釈結果を比較しようと試みる。 リソース不足の言語変異種に対するレマティゼーション及びＰＯＳタグ付けの非専門化モデルの再利用を評価するために、様々な試験を実施した。 この研究は3つの方言に焦点を当て、さらに西アルメニア語に拡張し、平均精度はレマティゼーションで94,00 ％、POSタグ付けで97,02 ％であり、他の異なるアルメニアの品種をカバーするためのモデルの再利用可能性の可能性もありました。 興味深いことに、東アルメニア語で訓練されたRNNモデルと、西アルメニア語に適用された東アルメニア国立コーパスルールベースのモデルとの比較は、構文解析において19%の増強を示した。 このモデルは、西アルメニア語の短い異種データセットの88,79%をカバーしており、その標準における大規模なコーパスアノテーションのベースラインとなる可能性があります。 RNNベースのモデルは、時間消費、ターゲット言語の異なる変種の再利用可能性、および形態学的注釈における有意な定性的結果などの要因を考慮して、ルールベースのモデルの有効な代替であり得ると主張されている。', 'ru': 'Армянский язык является языком со значительными вариациями и неравномерно распределенными ресурсами NLP для разных сортов. Предпринимается попытка обработки модели RNN для морфологической аннотации на основе различных армянских данных (предоставленных или не предоставленных с морфологически аннотированными телами) и сравнения результатов аннотации RNN и основанных на правилах моделей. Были проведены различные испытания для оценки повторного использования неспециализированной модели лемматизации и маркировки POS для разновидностей языков, не обеспеченных достаточными ресурсами. Исследование было сосредоточено на трех диалектах и далее распространено на западный армянский со средней точностью 94,00% в лемматизации и 97,02% в POS-тегировании, а также возможной возможностью повторного использования моделей для охвата различных других армянских разновидностей. Интересно, что сравнение модели RNN, обученной на восточном армянском языке, с моделью, основанной на правилах Национального корпуса восточного армянского языка, применяемой к западному армянскому языку, показало увеличение на 19% при синтаксическом анализе. Эта модель охватывает 88,79% короткого гетерогенного набора данных на западном армянском языке и может быть основой для массивной аннотации тела в этом стандарте. Утверждается, что модель, основанная на RNN, может быть действительной альтернативой модели, основанной на правилах, с учетом таких факторов, как трудоемкость, возможность повторного использования для различных разновидностей целевого языка и значительные качественные результаты в морфологической аннотации.', 'ga': 'Is teanga í an Airméinis le héagsúlacht shuntasach agus acmhainní NLP dáilte go míchothrom do chineálacha éagsúla. Déantar iarracht samhail RNN a phróiseáil le haghaidh nóta moirfeolaíocha ar bhonn sonraí Airméinis éagsúla (ar fáil nó nach bhfuil le corpora anótáilte de réir moirfeolaíocha), agus comparáid a dhéanamh idir torthaí anótála RNN agus samhlacha bunaithe ar riail. Rinneadh tástálacha éagsúla chun meastóireacht a dhéanamh ar athúsáid samhail neamhspeisialaithe de leamatú agus le clibeáil POS do chineálacha teanga gann-acmhainní. Dhírigh an taighde ar thrí chanúint agus leathnaíodh é go dtí an Airméinis Thiar le cruinneas meánach 94,00 % i leamatúchán agus 97,02 % i gclibeáil POS, chomh maith le hathúsáid féidearthacht samhlacha chun cineálacha éagsúla Airméinis eile a chlúdach. Is díol suntais é gur léiríodh méadú 19% sa pharsáil nuair a cuireadh samhail RNN oilte ar an Airméinis Thoir i gcomparáid le múnla rialacha-bhunaithe Chorpais Náisiúnta Oirthear na hAirméine a cuireadh i bhfeidhm ar Airméinis Thiar. Clúdaíonn an tsamhail seo 88,79% de thacar sonraí gearr ilchineálach san Airméinis Thiar, agus d’fhéadfadh sé a bheith ina bhunlíne d’ollnótáil corpais sa chaighdeán sin. Áitítear gur féidir le samhail atá bunaithe ar RNN a bheith ina rogha bhailí eile seachas samhail atá bunaithe ar rialacha agus aird á tabhairt ar fhachtóirí mar chaitheamh ama, ath-inúsáidteacht do chineálacha éagsúla sprioctheanga agus torthaí cáilíochtúla suntasacha i anótáil mhoirfeolaíoch.', 'ka': 'აპერმიანი არის მნიშვნელოვანი განსხვავებების ენაა და მნიშვნელოვანი NLP რესურსი განსხვავებულ განსხვავებებისთვის. მორპოლოგიური მონაცემებისთვის RNN მოდელის პროცესება განსხვავებული არმენიური მონაცემებისთვის (მომპოროლოგიურად მონაცემებისთვის და არა) და RNN და rule-based მოდელის მონაცემების მონაცემებისთვის შემდგ განსხვავებული ტესტი გავაკეთებულია, რომ ლიმომატიზაციის და POS-მარტიზაციის განსხვავებული ენის განსხვავებებისთვის გამოყენება განსხვავებული მოდელის გამოყენება. პროცემები სამი დიალეკტებზე კონუქტირებულია და უფრო დასავლეთ აპერმენეთის გარეშე 94,00% სიმართლეში და 97,02% სიმართლეში POS-მართლში, და შესაძლებელი მოდელების გამოყენება სხვა აპერმენეთის განსხვავებების გა საინტერესოა, რომელიც დასავლეთ აპერმენეთისთვის პროგორმაცია, რომელიც ინტერესონალური აპერმენეთისთვის გასწავლა პროგორმაციის მოდელის შემდგომარება, რომელიც დასავლეთ აპერმენეთისთ ამ მოდელს 88,79%-ს დასავლეთ აპერმიანეთში ცოტა ჰეტეროგენური მონაცემების შესახებ, და შეიძლება იყოს მასიური კორპუსის ანტოციის ბაზი ხაზი. არგებულია, რომ RNN-დაბათებული მოდელი შეიძლება იყოს საჭირო ალტენტრუმენტი, რომელიც მხოლოდ გამოყენებული ფაქტორები, განსხვავებული სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადას', 'it': "L'armeno è una lingua con variazioni significative e risorse PNL distribuite in modo irregolare per diverse varietà. Si tenta di elaborare un modello RNN per l'annotazione morfologica sulla base di diversi dati armeni (forniti o meno con corpora annotata morfologicamente), e di confrontare i risultati di annotazione di RNN e modelli basati su regole. Sono stati effettuati diversi test per valutare il riutilizzo di un modello non specializzato di lemmatizzazione e POS-tagging per varietà linguistiche con scarse risorse. La ricerca si è concentrata su tre dialetti e si è ulteriormente estesa all'armeno occidentale con una precisione media del 94,00% nella lemmatizzazione e del 97,02% nella marcatura POS, nonché una possibile riutilizzabilità di modelli per coprire diverse altre varietà armene. È interessante notare che il confronto di un modello RNN addestrato sull'armeno orientale con il modello basato sul governo del Corpus nazionale armeno orientale applicato all'armeno occidentale ha mostrato un miglioramento del 19% nel parsing. Questo modello copre l'88,79% di un breve set di dati eterogeneo in armeno occidentale, e potrebbe essere una base di riferimento per una massiccia annotazione del corpus in tale standard. Si sostiene che un modello basato su RNN può essere una valida alternativa a uno basato su regole tenendo conto di fattori quali il consumo di tempo, la riutilizzabilità per diverse varietà di una lingua di destinazione e risultati qualitativi significativi nell'annotazione morfologica.", 'el': 'Τα Αρμενικά είναι μια γλώσσα με σημαντική ποικιλία και άνισα κατανεμημένους πόρους για διαφορετικές ποικιλίες. Γίνεται προσπάθεια επεξεργασίας ενός μοντέλου για μορφολογική παρατήρηση με βάση διάφορα αρμενικά δεδομένα (που παρέχονται ή όχι με μορφολογικά σχολιασμένα σώματα) και σύγκρισης των αποτελεσμάτων σχολιασμού από μοντέλα με βάση κανόνες. Πραγματοποιήθηκαν διάφορες δοκιμές για να αξιολογηθεί η επαναχρησιμοποίηση ενός μη ειδικού μοντέλου λεμματοποίησης και σήμανσης για γλωσσικές ποικιλίες που δεν διαθέτουν επαρκείς πόρους. Η έρευνα επικεντρώθηκε σε τρεις διαλέκτους και επεκτάθηκε περαιτέρω στα Δυτικά Αρμενικά με μια μέση ακρίβεια 94,00% στη λεμματοποίηση και 97,02% στην επισήμανση, καθώς και μια πιθανή επαναχρησιμοποίηση των μοντέλων για να καλύψει διαφορετικές άλλες αρμενικές ποικιλίες. Ενδιαφέρον είναι ότι η σύγκριση ενός μοντέλου RNN εκπαιδευμένου στα Ανατολικά Αρμενικά με το μοντέλο που βασίζεται σε κανόνες του Ανατολικού Αρμενικού Εθνικού Σώματος που εφαρμόστηκε στα Δυτικά Αρμενικά έδειξε αύξηση 19% στην ανάλυση. Το μοντέλο αυτό καλύπτει 88,79% ενός μικρού ετερογενούς συνόλου δεδομένων στα Δυτικά Αρμενικά, και θα μπορούσε να αποτελέσει βάση για μια μαζική επισήμανση σώματος σε αυτό το πρότυπο. Υποστηρίζεται ότι ένα μοντέλο βασισμένο σε RNN μπορεί να αποτελέσει μια έγκυρη εναλλακτική λύση σε ένα μοντέλο βασισμένο σε κανόνες λαμβάνοντας υπόψη παράγοντες όπως η κατανάλωση χρόνου, η επαναχρησιμοποίηση για διαφορετικές ποικιλίες μιας γλώσσας-στόχου και σημαντικά ποιοτικά αποτελέσματα μορφολογικής σχολιασμού.', 'lt': 'Armėnų kalba labai skiriasi ir skirtingų veislių NLP ištekliai paskirstomi nevienodai. Bandoma apdoroti RNN model į, skirtą morfologinei anotacijai, remiantis skirtingais Armėnijos duomenimis (pateikiami arba nenustatyti morfologiškai anotuoti korporai), ir palyginti RNN ir taisyklėmis pagrįstų modelių anotacijos rezultatus. Different tests were carried out to evaluate the reuse of an unspecialized model of lemmatization and POS-tagging for under-resourced language varieties.  Tyrimuose daugiausia dėmesio buvo skiriama trims dialektams ir toliau buvo skiriama Vakarų Armėnijai, vidutiniškai 94,00 % limmatizacijos ir 97,02 % POS žymėjimo tikslumui, taip pat galimam modelių pakartotiniam naudojimui skirtingoms kitoms Armėnijos veislėms. Įdomu, palyginus Rytų Armėnų kalba parengtą RNN model į su Rytų Armėnų nacionalinės korpuso taisyklėmis pagrįstu modeliu, taikytu Vakarų Armėnų kalba, tyrimo rezultatai padidėjo 19 %. Šis modelis apima 88,79 % trumpo heterogeninio duomenų rinkinio Vakarų Armėnijos kalba ir galėtų būti pagrindinis didelio korpuso anotacijos šiame standarte pagrindas. Manoma, kad RNN pagrįstas model is gali būti tinkama alternatyva taisyklėmis pagrįstam modeliui, kuriame atsižvelgiama į tokius veiksnius kaip laiko suvartojimas, pakartotinis naudojimas skirtingoms tikslinės kalbos veislėms ir reikšmingas kokybinis rezultatas – morfologinė anotacija.', 'hu': 'Az örmény nyelv jelentős változatossággal és különböző fajták számára egyenlőtlenül elosztott NLP forrásokkal rendelkezik. Kísérletet teszünk arra, hogy feldolgozzuk az RNN modellt morfológiai jegyzetekhez különböző örmény adatok alapján (morfológiailag jegyzetekkel ellátott korpuszokkal), és összehasonlítsuk az RNN és a szabályalapú modellek jegyzetelési eredményeit. Különböző vizsgálatokat végeztünk a lemmatizáció és POS-címkézés speciális modelljének újrafelhasználásának értékelésére az alacsony forrásokkal rendelkező nyelvfajták esetében. A kutatás három dialektusra összpontosított és tovább terjedt a nyugat-örmény nyelvre, átlagosan 94,00%-os lemmatizációs pontossággal és 97,02%-os POS-címkézéssel, valamint a modellek lehetséges újrafelhasználhatóságával különböző örmény fajtákra. Érdekes módon a Kelet-Örményországon képzett RNN modell összehasonlítása a Kelet-Örményországon alkalmazott Nemzeti Corpus szabályalapú modell és a Nyugat-Örményországon alkalmazott modell 19%-os növekedést mutatott az elemzésben. Ez a modell egy rövid heterogén nyelvű adathalmaz 88,79%-át fedi le Nyugat-Örményországban, és alapjául szolgálhat egy masszív korpuszjegyzéshez ebben a szabványban. Azt állítják, hogy egy RNN-alapú modell érvényes alternatívája lehet egy szabályalapú modell helyett, figyelembe véve olyan tényezőket, mint az időfogyasztás, a célnyelv különböző fajtáinak újrafelhasználhatósága és a morfológiai jegyzetek jelentős minőségi eredményeit.', 'ms': 'Bahasa Armenia adalah bahasa dengan variasi yang signifikan dan sumber NLP yang tidak disebarkan secara sama untuk jenis yang berbeza. Cubaan dibuat untuk memproses model RNN untuk anotasi morfologi berdasarkan data Armenia yang berbeza (disediakan atau tidak dengan korpra yang anotasi morfologi), dan untuk membandingkan hasil anotasi RNN dan model berdasarkan peraturan. Ujian berbeza dilakukan untuk menilai penggunaan semula model lemmatisasi tidak spesialis dan tag POS untuk jenis bahasa yang tidak berkuasa. Penelitian ini fokus pada tiga dialekt dan lebih lanjut dilambangkan ke Armenia Barat dengan ketepatan rata-rata 94,00% dalam lemmatisasi dan 97,02% dalam POS-tagging, serta kemungkinan penggunaan semula model untuk menutupi berbagai jenis Armenia lain. Menarik, perbandingan model RNN yang dilatih di Armenia Timur dengan model yang berdasarkan peraturan Korpus Nasional Armenia Timur yang dilaksanakan pada Armenia Barat menunjukkan peningkatan 19% dalam penghuraian. Model ini meliputi 88,79% dari set data heterogeni pendek di Armenia Barat, dan boleh menjadi dasar untuk anotasi corpus besar dalam piawai itu. Ia disangka bahawa model berasaskan RNN boleh menjadi alternatif yang sah untuk faktor berasaskan peraturan yang mempertimbangkan faktor seperti penggunaan masa, penggunaan semula untuk berbagai jenis bahasa sasaran dan hasil kualitatif yang signifikan dalam anotasi morfologik.', 'ml': 'വ്യത്യസ്ത വ്യത്യാസങ്ങള്\u200dക്ക് വേണ്ടി NLP വിഭവങ്ങള്\u200d വിതരണം ചെയ്യുന്ന അര്\u200dമ്മേനിയന്\u200d ഭാഷയാണ്. വ്യത്യസ്ത ആര്\u200dമേനിയയുടെ ഡാറ്റ അടിസ്ഥാനത്തില്\u200d ഒരു RNN മോഡല്\u200d പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d ശ്രമിച്ചിരിക്കുന്നു (മൊര്\u200dഫോളജിക്കല്\u200d കോര്\u200dപ്പോറയില്\u200d പ്രസ്താവിക് Different tests were carried out to evaluate the reuse of an unspecialized model of lemmatization and POS-tagging for under-resourced language varieties.  ഈ ഗവേഷണം മൂന്നു ഡയലക്കേറ്റുകളിലേക്ക് ശ്രദ്ധിച്ചു വീണ്ടും പടിഞ്ഞാറന്\u200d ആര്\u200dമേനിയയിലേക്ക് വികസിപ്പിക്കുകയും വ്യത്യസ്ത വ്യത്യസ്ത വ്യത്യാസങ്ങള്\u200d മൂടുകയും ചെയ്യ കിഴക്കന്\u200d അര്\u200dമേനിയയില്\u200d പഠിപ്പിക്കപ്പെട്ട ഒരു RNN മോഡലിന്റെ താല്\u200dപര്യം കിഴക്കന്\u200d അര്\u200dമേനിയന്\u200d നാഷണല്\u200d കോര്\u200dപ്പുസിന്റെ നിയമമോഡല്\u200d പ്രയോഗിച്ചു പടിഞ ഈ മോഡല്\u200d പടിഞ്ഞാറന്\u200d അര്\u200dമ്മേനിയനിലെ കുറച്ച് ഹെട്രോജെനിസ് ഡാറ്റാസെറ്റില്\u200d 88,79% പൂര്\u200dണ്ണമാക്കുന്നു. അതിന്റെ ഒരു വലിയ കോര്\u200dപ്പ ഒരു RNN-അടിസ്ഥാനത്തിലുള്ള മോഡല്\u200d ഒരു നിയമത്തിന്റെ അടിസ്ഥാനത്തിലുള്ള ഒരു മാറ്റം ആയിരിക്കാന്\u200d സാധിക്കുന്നു. സമയ-consumption, ലക്ഷ്യഭാഷ വ്യത്യസ്ത വ്യത്യസ്ത ഭാഷയ്ക്ക്', 'kk': 'Армениялық - маңызды айырмашылық тіл және әртүрлі түрлерге NLP ресурстары таратылмаған. Түрлі армян деректерінің негізінде (морфологиялық корпораға келтірілген немесе емес) RNN морфологиялық жазбалардың нәтижесін салыстыру үшін RNN үлгісі жазылады. Төмендегі тіл түрлері үшін ерекшелмеген леммациялау мен POS- тегтерін қайта қолдану үшін әртүрлі сынақтар істелді. Сынақтар үш диалекттерге көздеген және Батыс Арменияның орташа лимматизациялық 94,00 % және POS тегтерінде 97,02 % деген диалекттерге көздеген және басқа армян түрлеріне қайта қолдануға мүмкін үлгілер қолданылады. Бірақ қызықты, Шығыс Армениялық RNN үлгісін Батыс Армениялық үлгілеріне қолданылатын Шығыс Армениялық Құрыптар үлгісімен салыстыру үлгісі, талдау үшін 19% дегенді көрсетті. Бұл үлгі Батыс Арменияндағы қысқа гетероген деректер жиының 88,79% деп жазылады. Осы стандартта маңызды корпус жазбаларының негізгі жолы болуы мүмкін. RNN негіздеген модель ережелердің негіздеген альтернативі болуы мүмкін, уақыт пайдалану, мақсатты тілдің әртүрлі түрлеріне қайта пайдалану мүмкіндігі және морфологиялық жазбаларының маңызды квалификациялық нәтижеле', 'mt': 'L-Armenjan huwa lingwa b’varjazzjoni sinifikanti u riżorsi tal-NLP imqassma b’mod mhux ugwali għal varjetajiet differenti. Sar tentattiv biex jiġi pproċessat mudell ta’ RNN għall-annotazzjoni morfoloġika fuq il-bażi ta’ dejta Armenja differenti (ipprovduta jew le b’korpra morfoloġikament annotata), u biex jitqabblu r-riżultati tal-annotazzjoni ta’ RNN u mudelli bbażati fuq ir-regoli. Saru testijiet differenti biex jiġi evalwat l-użu mill-ġdid ta’ mudell mhux speċjalizzat ta’ limmatizzazzjoni u tikkettar POS għal varjetajiet lingwistiċi b’riżorsi baxxi. Ir-riċerka ffukat fuq tliet dijaletti u estendiet ulterjorment għall-Armenja tal-Punent b’preċiżjoni medja ta’ 94,00 % fil-limmatizzazzjoni u 97,02 % fit-tikkettar tal-POS, kif ukoll użu mill-ġdid possibbli ta’ mudelli biex ikopru varjetajiet Armenji oħra differenti. Interessant, it-tqabbil ta’ mudell ta’ RNN imħarreġ fuq l-Armenja tal-Lvant mal-mudell ibbażat fuq ir-regoli tal-Korp Nazzjonali Armenjan tal-Lvant applikat għall-Armenja tal-Punent wera titjib ta’ 19 % fl-analiżi. Dan il-mudell ikopri 88,79 % ta’ sett ta’ dejta eteroġenu qasir fl-Armenja tal-Punent, u jista’ jkun linja bażi għal annotazzjoni massiva tal-korpus f’dak l-istandard. Huwa argumentat li mudell ibbażat fuq RNN jista’ jkun alternattiva valid a għal waħda bbażata fuq ir-regoli li tikkunsidra fatturi bħal konsum ta’ ħin, użu mill-ġdid għal varjetajiet differenti ta’ lingwa fil-mira u riżultati kwalitattivi sinifikanti f’annotazzjoni morfoloġika.', 'mn': 'Арменийн хэл бол маш чухал өөрчлөлт, өөр төрлийн NLP нөөц бүтээгдэхүүнтэй хэл юм. Өөр Арменийн өгөгдлийн үндсэн (морфологик анзаарагдсан корпора) дээр РНХ загварын морфологик анзаарлын загварыг үйлдвэрлэхэд хичээлдэг. Мөн РНХ болон дүрмийн үндсэн загварын үр дүнг харьцуулахын тулд. Өөр өөр тест хийгдсэн нь хэл төрлийн төрлийн төрлийн lemmatization болон POS-tagging загварыг дахин ашиглахын тулд өөр өөр өөр өөр загварууд. Судалгааны судалгаа 3 диалект дээр төвлөрсөн ба Барууны Армени хүртэл 94,00% лемматизацийн дундаж тодорхойлолтой, POS-тегт 97,02% болон бусад Арменийн төрлийн төрлийн загваруудыг дахин ашиглах боломжтой болсон. Хамгийн сонирхолтой нь зүүн Арменид сургалтын РНХ загварын харьцуулах нь Барууны Арменид хэрэглэгдсэн Барууны Арменийн улс төрийн хууль загвартай харьцуулахад 19%-ын нэмэгдүүлэлт үзүүлсэн. Энэ загвар нь Барууны Арменийн богино гетероген өгөгдлийн хувьд 88.79%-ийг агуулдаг. Энэ стандарт маш олон корпус илтгэлийн суурь шугам байж болно. РНХ-ын суурь загвар нь хууль хэрэглэх, зорилготой хэл төрлийн дахин ашиглах боломжтой болон морфологик анзаарлын үндсэн чадвартай үр дүнг зөвхөн хууль загварын үндсэн загвар юм.', 'no': 'Armensk er eit språk med signifikante variasjonar og ulik distribuert NLP-ressursar for ulike variasjonar. Ein prøv er gjennomført å handsama eit RNN-modell for morfologisk annotasjon på grunn av ulike Armenske data (oppgjeven eller ikkje med morfologisk annotasjon av korpora) og å sammenligna notasjonsresultatene av RNN- og regelbaserte modeller. Dei ulike testane vart gjennomført for å evaluera gjennombruken av eit ikkje spesialisert modell for lemmatisering og POS- merking for underressurserte språk- variasjonar. Forskningen fokuserte på tre dialektar og lenger utvidet til Vest-Armensk med gjennomsnittlig nøyaktighet med 94,00 % i lemmatisasjon og 97,02 % i POS-merking, og eit mulig gjenoppretting av modeller for å dekka ulike andre Armenske variasjonar. Interesantleg viste sammenligninga med eit RNN-modell som treng på øst-Armensk og den øst-Armenske nasjonale korpus-regelsbaserte modellen som er brukt til Vest-Armensk, at det er forbetra 19 % i tolking. Dette modellet dekkar 88,79 % av ein kort heterogenesk dataset i Vest-Armensk, og kan vera ein grunnlinje for ein massiv korpusannotasjon i denne standarden. Det er argumentert at ein RNN-basert modell kan vera ein gyldig alternativ til ein regelbasert, som gjer betre på slike faktorer som tidsbruk, gjenopprettbruk for ulike variasjonar av eit målspråk og signifikante kvalitative resultat i morfologiske annotasjon.', 'pl': 'Ormiański jest językiem o znaczącym zróżnicowaniu i nierównomiernie rozprowadzonych zasobach NLP dla różnych odmian. Podjęto próbę przetworzenia modelu RNN dla adnotacji morfologicznej na podstawie różnych danych ormiańskich (dostarczonych lub nie z korpusami morfologicznymi) oraz porównania wyników adnotacji RNN i modeli opartych na regułach. Przeprowadzono różne testy w celu oceny ponownego wykorzystania niespecjalizowanego modelu lemmatyzacji i POS-tagowania dla niewyposażonych odmian językowych. Badania koncentrowały się na trzech dialektach i dalej rozszerzyły się na zachodnioormiański ze średnią dokładnością 94,00% w lemmatyzacji i 97,02% w tagowaniu POS, a także możliwością ponownego użytkowania modeli do pokrycia różnych innych odmian ormiańskich. Co ciekawe, porównanie modelu RNN trenowanego na Wschodnim Ormianie z modelem opartym na regułach Wschodnioormiańskiego Korpusu Narodowego zastosowanym na Zachodnim Ormianie wykazało wzrost 19% parsowania. Model ten obejmuje 88,79% krótkiego, heterogenicznego zbioru danych w języku zachodnim ormiańskim i mógłby stanowić bazę podstawową dla masywnej adnotacji korpusu w tym standardzie. Argumentuje się, że model oparty na RNN może być ważną alternatywą dla modelu opartego na regułach biorąc pod uwagę takie czynniki jak zużycie czasu, ponowne wykorzystanie dla różnych odmian języka docelowego oraz istotne wyniki jakościowe w adnotacji morfologicznej.', 'sr': 'Armenski je jezik sa značajnim varijacijom i nepravedno raspodijeljenim NLP resursima za različite raznolike. Pokušava se procesirati RNN model morfološke annotacije na osnovu različitih Armenskih podataka (pruženih ili ne morfološki annotiranih korpora) i usporediti rezultate annotacije RNN-a i modela na osnovu pravila. Provedeni su različiti testovi kako bi procenili ponovno upotrebu neprecijalnog modela limmatizacije i označavanja POS-a za neposredne jezičke vrste. Istraživanje se fokusiralo na tri dijalekta i dalje se proširilo na zapadnu Armensku s srednjom preciznošću od 94,00 % limmatizacije i 97,02 % na označavanju POS-a, kao i mogućom ponovnom korištenju modela za pokrivanje različitih Armenskih raznolika. Zanimljivo je da je usporedba modela RNN obučenog na istočnom Armeniju sa model nacionalnog korpusa iz Istoènog Armenskog nacionalnog korpusa koji se primjenjuje na zapadnu Armeniju pokazala povećanje od 19% u analizu. Ovaj model pokriva 88.79% kratkih heterogeneznih podataka u Zapadnoj Armeniji, i može biti osnovna linija za veliku korpusnu annotaciju u tom standardu. Tvrdi se da model na RNN-u može biti validna alternativa na pravilima koja daje obzir na takve faktore kao potrošenje vremena, ponovno korištenje različitih različitih različitih različitih različitih jezika ciljnog jezika i značajnih kvalitativnih rezultata morfološke annotacije.', 'so': 'Armeniyan waa luqad ay leeyihiin isbedelyo faro badan oo ay ku kala qaybsan yihiin raslimo aan u filnayn oo ay kala duduwan noocyo kala duduwan. Jahaadaa waxaa la sameeyaa in lagu sameeyo model RNN oo ku saabsan waraaqo morphological ah oo ku saabsan macluumaad kala duduwan oo Armenian (diyaarin ama aan ku qorin korpora si morphologically annotated), iyo in la barbardhigo midhihiisa xuquuqda ee RNN iyo sameynta sameynta sameynta noocyada xuquuqda. Imtixaano kala duduwan waxaa loo sameeyay in lagu qiimeeyo dib u isticmaalka tusaale aan la aqoonsan jimicsiga iyo POS-tagging oo ku qoran luuqadaha hoose-resourceed. Baaritaanku wuxuu ku kalsoonaaday saddex qalabka oo galbeed ah oo u sii kordhay Armenian, si sax ah looga dhigo 94,00 boqolkiiba barbaarinta iyo 97,02 boqolkiiba POS-tagging, sidoo kalena waxaa suurtagal ah dib u isticmaalka modelalka inay qariyaan kala duduwan Armeniyan oo kale. Si xiiso leh, iftiinkii RNN model lagu barto Bari Armenian iyo model ku saleysan qoraalka bariga Armenian National Corpus ee galbeed Armenian wuxuu tusay kordhis 19% baarlamaanka. Tusaaladan waxay ku daboolan 88,79 % oo ka mid ah macluumaad gaaban oo ay ku qoran yihiin galbeed Armenian, waxaana laga yaabaa inay u noqoto korpus oo aad u weyn. Waxaa loola hadlayaa in muusiko asalka RNN ah uu noqon karo mid suurtagal ah oo ku habboon sharciga, kaas oo ka fiirsan kara arrimaha tusaale ahaan isticmaalka waqtiga, dib u isticmaalidda luuqada kala duduwan ee loogu talagalay iyo waxyaabaha muhiimka ah oo ka soo jeeda suurtogal.', 'sv': 'Armeniska är ett språk med betydande variation och ojämnt fördelade NLP-resurser för olika sorter. Ett försök görs att bearbeta en RNN-modell för morfologisk notering på grundval av olika armeniska data (försedda med eller inte med morfologiskt kommenterade corpora), och att jämföra noteringsresultaten för RNN och regelbaserade modeller. Olika tester genomfördes för att utvärdera återanvändningen av en ospecialiserad modell av lemmatisering och POS-märkning för underresurserade språksorter. Forskningen fokuserade på tre dialekter och utvidgades vidare till västra armeniska med en genomsnittlig noggrannhet på 94,00% i lemmatisering och 97,02% i POS-märkning, samt en möjlig återanvändbarhet av modeller för att täcka olika andra armeniska sorter. Intressant nog visade jämförelsen av en RNN-modell utbildad på östra armeniska med den östra armeniska nationella corpus regelbaserade modellen tillämpad på västra armeniska en förbättring av 19% i tolkning. Denna modell täcker 88,79% av en kort heterogen datamängd på västra armeniska, och kan vara en baslinje för en massiv korpusnotering i den standarden. Det hävdas att en RNN-baserad modell kan vara ett giltigt alternativ till en regelbaserad modell med hänsyn till sådana faktorer som tidsförbrukning, återanvändbarhet för olika sorter av ett målspråk och signifikanta kvalitativa resultat i morfologisk notering.', 'ta': 'அர்மேனியன் மொழியாகும் முக்கியமான மாறிகள் மற்றும் வேறு வித்தியாசமான மூலங்களுக்கு NLP மூலங்கள் வழங்கப் ஆர்மேனிய தகவல்களை அடிப்படையில் ஒரு ஆர்என்னி மாதிரியை செயல்படுத்த முயற்சி செய்யப்பட்டுள்ளது (வழங்கப்பட்டுள்ளது அல்லது குறிப்பிட்ட நிறுவனத்தில் இல்லை), மற்றும்  வேறு சோதனைகள் செய்யப்பட்டுள்ளது மூலத்திற்கு கீழ் வளர்ந்த மொழி மாறுபாடுகளுக்கு தேர்ந்தெடுக்கப்படாத மாதிரி மதிப்பிடும் மற்று இந்த ஆராய்ச்சி மூன்று விளக்கங்கள் மீது கவனம் செலுத்தப்பட்டது மற்றும் மேற்கு அர்மேனியாவிற்கு மேலும் விரிவாக்கப்பட்டது 94,00 சதவிகிதத்தின் சரியான சரித்திரம் மற்று கிழக்கு ஆர்மேனியன் மீது பயிற்சிக்கப்பட்ட ஒரு RNN மாதிரியின் ஒப்பீடு, கிழக்கு அர்மேனியாவின் நாடி கார்ப்ஸ் விதிமுறை மாதிரி மாதிரி முறையி இந்த மாதிரி 88,79% மேற்கு அர்மேனியனில் ஒரு சிறிய வெப்ரீஜன் தகவல் அமைப்பை மறைக்கிறது, மற்றும் அந்த நிலையில் ஒரு பெரிய கார்புஸ் விளக ஒரு RNN-அடிப்படையிலான மாதிரி ஒரு விதிமுறையாக இருக்கலாம் என்று வாக்கியம் செலுத்தப்பட்டுள்ளது, இது நேரம் பயன்படுத்தல், வேறு வித்தியாசமான மொழிக்கு மீண்டும் பயன்படுத', 'mk': 'Ерменецот е јазик со значителна варијација и нееднакво дистрибуирани ресурси на НЛП за различни различности. Се обидува да се процесира РНН модел за морфолошка анотација врз основа на различни ерменски податоци (обезбедени или не со морфолошки анотацирани корпора) и да се споредат резултатите на анотацијата на РНН и модели базирани на правила. Различни тестови беа спроведени за проценка на повторното употреба на неспецијализиран модел на лиматизација и POS-ознака за различни јазички различности. Истражувањата се фокусираа на три дијалекти и понатаму се проширија на Западен Ерменец со просечна точност од 94,00 отсто во лиматизацијата и 97,02 отсто во означувањето на POS, како и можна повторна употреба на моделите за покривање на различни други ерменски разнови. Интересно е што споредбата на РНН модел обучен на Источна Ерменска со моделот заснован на владеењето на Источна Ерменска Национална Корпус кој се применува на Западна Ерменска покажа зголемување од 19 отсто во анализирањето. Овој модел покрива 88,79 отсто од краток хетероген податок на западна Ерменска, и може да биде основа за масовна анотација на корпусот во тој стандард. Се тврди дека моделот базиран на РНН може да биде валидна алтернатива на еден базиран на правила, со оглед на факторите како што се временската потрошувачка, повторното употребливост за различни различности на јазик на целта и значителните квалитетни резултати во морфолошка анотација.', 'ro': 'Armena este o limbă cu variații semnificative și resurse PNL distribuite inegal pentru diferite soiuri. Se încearcă să proceseze un model RNN pentru adnotări morfologice pe baza diferitelor date armene (furnizate sau nu cu corpore adnotate morfologic), și să compare rezultatele adnotării RNN și modelele bazate pe reguli. Au fost efectuate teste diferite pentru a evalua reutilizarea unui model nespecializat de lemmatizare și etichetare POS pentru soiurile lingvistice cu resurse insuficiente. Cercetarea s-a concentrat pe trei dialecte și s-a extins în continuare la armena vestică cu o precizie medie de 94,00% în lemmatizare și 97,02% în etichetarea POS, precum și o posibilă reutilizare a modelelor pentru a acoperi diferite alte soiuri armene. Interesant este faptul că comparația dintre modelul RNN instruit pe armeanul estic și modelul Corpului național al armeanului estic aplicat pe armeanul vestic a arătat o creștere de 19% în analiză. Acest model acoperă 88,79% dintr-un set scurt de date eterogene în limba armenă vestică și ar putea fi o bază de referință pentru o adnotare masivă a corpului în acest standard. Se susține că un model bazat pe RNN poate fi o alternativă validă la unul bazat pe reguli, luând în considerare factori precum consumul de timp, reutilizarea pentru diferite varietăți ale unei limbi țintă și rezultatele calitative semnificative în adnotare morfologică.', 'si': 'අර්මේනියානියාව තරම් විවිධ වර්ගයක් තියෙන භාෂාවක් හා විවිධ වර්ගයක් වෙනුවෙන් නැති විදි Name වෙනස් පරීක්ෂණාවල් පරීක්ෂණය කරලා ලෙම්මේස් සහ POS- ටැග් සඳහා භාෂා වර්ගයක් නොවිශේෂිත නිර්භාවිත විශේෂ කර පරීක්ෂණය තුනක් දායිලක්ට් එක්ක සැකසුම් කරලා පස්සේ අර්මේනියානුවෙන් ඉතිරිපත් කරලා තියෙන්නේ 94,00% විශේෂ සැකසුම් සහ 97,02% විශේෂය POS-ටැග් එක Interested, the comparison of a RNN Model Trained on East Armian with the East Armian National Corpus Rule-based Model Application to Western Armian Show an elevation of 19% in Parsing. මේ මොඩේල් 88,79% පැත්ත අර්මේනියානියාවේ පැත්ත අර්මේනියානියාවේ පොඩි සාමාන්\u200dය දත්ත සූදානයක් ඇතුළු කරනවා, ඒ වගේම ඒක ප්\u200dරශ්නයක් තියෙනවා RNN-අධාරිත මොඩල් එකක් නීති අධාරිත ප්\u200dරශ්නයක් වෙන්න පුළුවන් නීති අධාරිත ප්\u200dරශ්නයක් වෙන්න පුළුවන් විදිහට වි', 'ur': 'آرمنیایی ایک زبان ہے جو بہت اہم تغییرات کے ساتھ ہے اور بغیر طرح طرح طرح طرح کے NLP منبع کے لئے تقسیم کئے گئے ہیں۔ ایک کوشش کی جاتی ہے کہ ایک RNN موڈل کے لئے مختلف ارمنی ڈاکٹوں کے بنیاد پر قائم کرے اور RNN اور قانون کے بنیاد رکھنے والے موڈل کے نتیجے مقایسہ کریں۔ مختلف آزمائش کی گئی تھی کہ لیموماٹیزی اور POS-ٹاگ کی نازل زبان مختلفوں کے لئے دوبارہ استعمال کریں۔ اس تحقیقات نے تین ڈیلکتوں پر تمرکز کیا اور مغرب آرمینی کی طرف مزید مزید لیمٹیزی میں 94,00% اور پوس ٹیگ میں 97,02%، اور دوسری آرمینی مختلف مختلف مختلف مختلف مختلف موجودات کے امکانات کی دوبارہ استعمال کرنے کی امکانات کی۔ غربی آرمینی کے ذریعہ مطابق غربی آرمینی کے ذریعے ایک RNN موڈل کے مقایسے کے طور پر مشرق آرمینی پر آموزش کی گئی تھی۔ یہ مدل مغربی آرمینی میں ایک چھوٹے غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غ اس بات کو جھٹلایا گیا ہے کہ ایک RNN بنیاد موڈل ایک قانون بنیاد رکھنے والے کے لئے ایک معتبر الٹ بن سکتا ہے جس سے زمان مصرف کے ذریعے، ایک موجود زبان کے مختلف مختلف مختلف مختلف مختلف موجود کے لئے دوباره استعمال کرسکتا ہے اور موجود شناسی کے مطابق اضافہ کے', 'uz': "ArmaniyaName Name @ info: whatsthis Taʼminlovchi uchta dialeklarga qaragan va Gʻarbiy Armeniga o'zgarishga qaraydi, o'zgarishga 94,00 foiz haqida, POS tagning 97,02% va boshqa Armaniya turlarini qarish mumkin modellarni qayta ishlatish mumkin. Shunday qiziqarli, Sharqiy Armeniyaga o'rganilgan RNN modeliga o'rganish, Sharqiy Armeniya Tashqi Korpus qoidasi asosiy modeli Gʻarbiy Armeniga qo'llangan modeliga qo'llangan, 19% qo'yishni oshirishni ko'rsatadi. Name Bu qiymatda, RNN asosida yaratilgan model qoidagi boshqaruv bo'lishi mumkin. Vaqt foydalanish, turli tillar uchun qayta ishlatish va murakkab foydalanish natijalariga muhim qiymativ natijalari mumkin.", 'vi': 'Tiếng Armenia là ngôn ngữ có độ khác nhau và Độ phân phối độc lập. Một thử nghiệm xử lý mô hình RNN cho chú thích lịch lịch của chuẩn dựa trên các dữ liệu người Armenia khác nhau (cung cấp hay không có ghi chú lịch lịch lịch âm) và so sánh kết quả chú thích của RNN và các mô hình dựa trên quy định. Các thử nghiệm khác nhau đã được tiến hành để đánh giá lại cách sử dụng một mô hình chưa được công bố về giải thích cho các loại ngôn ngữ thiếu nguồn. Nghiên cứu tập trung vào ba phương ngữ và tiếp tục mở rộng cho miền tây Armenia với tỉ lệ chuẩn hàng đầu của 94,00 và 97,22+ trong kết quả POS-taging, và còn có khả năng tái sử dụng các mô- đun cho các loại khác nhau thuộc chủng tộc Armenia. Thật thú vị, so sánh một mô hình RNN được huấn luyện trên miền Đông Armenia với phương pháp luật của tập đoàn Mỹ phương đông áp dụng cho miền tây Armenia đã cho thấy nâng cao độ khó khó khăn trong việc phân tích. Mô hình này bao gồm 88,99=.=) của một tập tin nhỏ khác nhau ở miền tây Armenia, và có thể là cơ sở thực tế cho ghi chú y tích khổng lồ trong tiêu chuẩn đó. Nó được nói rằng mô hình dựa trên RNN có thể là một thay đổi hợp lệ với mô hình dựa trên quy tắc, dựa vào các yếu tố như tiêu thời gian, tái sử dụng cho các loại khác nhau của ngôn ngữ mục tiêu và kết quả về tiêu chuẩn lịch sử.', 'bg': 'Арменският е език със значителни вариации и неравномерно разпределени ресурси на НЛП за различни сортове. Направен е опит да се обработи модел за морфологична анотация на базата на различни арменски данни (предоставени или не с морфологично анотирани корпуси), както и да се сравнят резултатите от анотацията на RNN и базирани на правила модели. Извършени са различни тестове за оценка на повторното използване на неспециализиран модел на лематизация и ПОС-маркиране за недоресурсни езикови сортове. Проучването се съсредоточи върху три диалекта и допълнително се разшири до Западна Армения със средна точност 94,00% при лематизация и 97,02% при ПОС-маркиране, както и възможна повторна възможност на модели за покриване на различни други арменски сортове. Интересното е, че сравнението на модела на РНН, обучен на Източна Армения, с модела на Източна Армения национален корпус, базиран на правила, приложен към Западна Армения, показва подобрение с 19% в анализирането. Този модел обхваща 88,79% от кратък хетерогенен набор от данни на Западна Армения и може да бъде основна база за масивна корпусна анотация в този стандарт. Твърди се, че базиран на RNN модел може да бъде валидна алтернатива на базиран на правила модел, като се вземат предвид фактори като консумация на време, повторна възможност за различни разновидности на целевия език и значителни качествени резултати в морфологичната анотация.', 'da': 'Armensk er et sprog med betydelig variation og ujævnt fordelt NLP ressourcer for forskellige sorter. Et forsøg er gjort på at behandle en RNN model til morfologisk annotering på grundlag af forskellige armenske data (leveret eller ej med morfologisk annoterede corpora), og at sammenligne annoteringsresultaterne af RNN og regelbaserede modeller. Forskellige tests blev udført for at evaluere genbrug af en uspecialiseret model for lemmatisering og POS-tagging for underressourcer sprogsorter. Forskningen fokuserede på tre dialekter og udvidede yderligere til vestarmensk med en gennemsnitlig nøjagtighed på 94,00% i lemmatisering og 97,02% i POS-mærkning, samt en mulig genanvendelse af modeller til at dække forskellige andre armenske sorter. Interessant nok viste sammenligningen af en RNN model uddannet på østlige armenske med den østlige armenske nationale korpus regelbaserede model anvendt på vestlige armenske en forbedring på 19% i parsing. Denne model dækker 88,79% af et kort heterogent datasæt på vestarmensk, og kunne være en baseline for en massiv corpus annotation i denne standard. Det fremføres, at en RNN-baseret model kan være et gyldigt alternativ til en regelbaseret model under hensyntagen til faktorer som tidsforbrug, genanvendelighed for forskellige sorter af et målsprog og betydelige kvalitative resultater i morfologisk notering.', 'nl': 'Armeens is een taal met aanzienlijke variatie en ongelijk verdeeld NLP bronnen voor verschillende variëteiten. Er wordt geprobeerd om een RNN model te verwerken voor morfologische annotatie op basis van verschillende Armeense gegevens (al dan niet voorzien van morfologisch geanotateerde corpora), en de annotatieresultaten van RNN en op regels gebaseerde modellen te vergelijken. Verschillende tests werden uitgevoerd om het hergebruik van een ongespecialiseerd model van lemmatisatie en POS-tagging te evalueren voor taalvariëteiten met weinig middelen. Het onderzoek richtte zich op drie dialecten en breidde zich verder uit naar West-Armenisch met een gemiddelde nauwkeurigheid van 94,00% in lemmatisatie en 97,02% in POS-tagging, evenals een mogelijke herbruikbaarheid van modellen voor verschillende andere Armeense variëteiten. Interessant is dat de vergelijking van een RNN model getraind op Oost-Armeens met het Oost-Armeens National Corpus rule-based model toegepast op West-Armeens een toename van 19% in parsing toonde. Dit model bestrijkt 88,79% van een korte heterogene dataset in het West-Armenisch, en zou een basis kunnen zijn voor een massale corpusannotatie in die standaard. Er wordt betoogd dat een RNN-gebaseerd model een geldig alternatief kan zijn voor een regel-gebaseerd model waarbij rekening wordt gehouden met factoren als tijdsverbruik, herbruikbaarheid voor verschillende variëteiten van een doeltaal en significante kwalitatieve resultaten in morfologische annotatie.', 'hr': 'Armenski je jezik sa značajnim varijacijom i nepravedno raspodijeljenim NLP resursima za različite razine. Pokušava se obraditi model RNN za morfološku annotaciju na temelju različitih Armenskih podataka (pruženih ili ne morfološki annotiranih tijela) i usporediti rezultate annotacije RNN-a i modela temeljenih na pravilima. Provedeni su različiti testovi kako bi procijenili ponovno primjenu neprecijalnog modela limmatizacije i označavanja POS-a za neposredne jezičke vrste. Istraživanje se fokusiralo na tri dijalekta i dalje se proširilo na zapadni Armenski s srednjom preciznošću od 94,00 % u lematizaciji i 97,02 % u označavanju POS-a, kao i mogućom ponovnom korištenju modela za pokrivanje različitih Armenskih raznolikova. Zanimljivo je, usporedba modela RNN obučenog na istočnom Armeniju s pravilima temeljenim na Istočnom Armenijskom nacionalnom korpusu primjenom na zapadni Armenski pokazala povećanje od 19% u analizu. Ovaj model pokriva 88.79% kratke heterogenezne podatke na zapadnoj Armenskoj, i može biti početna linija za veliku korpusnu annotaciju u tom standardu. Tvrdi se da model na RNN-u može biti validna alternativa na pravilima koja će razmotriti takve faktore kao potrošenje vremena, ponovno iskoristiti različite razine ciljnog jezika i značajne kvalitativne rezultate morfološke annotacije.', 'de': 'Armenisch ist eine Sprache mit erheblichen Variationen und ungleichmäßig verteilten NLP-Ressourcen für verschiedene Sorten. Es wird versucht, ein RNN-Modell für morphologische Annotation auf der Grundlage verschiedener armenischer Daten (bereitgestellt oder nicht mit morphologisch annotierten Korpora) zu verarbeiten und die Annotationsergebnisse von RNN und regelbasierten Modellen zu vergleichen. Verschiedene Tests wurden durchgeführt, um die Wiederverwendung eines unspezialisierten Lemmatisierungs- und POS-Tagging-Modells für unzureichend ausgestattete Sprachvarianten zu evaluieren. Die Forschung konzentrierte sich auf drei Dialekte und erweiterte sich weiter auf Westarmenisch mit einer mittleren Genauigkeit von 94,00% in Lemmatisierung und 97,02% in POS-Tagging, sowie einer möglichen Wiederverwendbarkeit von Modellen für verschiedene andere armenische Sorten. Interessanterweise zeigte der Vergleich eines RNN-Modells, das auf Ostarmenisch trainiert wurde, mit dem Ostarmenischen Nationalkorpus-Regelmodell, das auf Westarmenisch angewendet wurde, eine Steigerung von 19% im Parsing. Dieses Modell deckt 88,79% eines kurzen heterogenen Datensatzes in Westarmenisch ab und könnte eine Grundlage für eine massive Korpusannotation in diesem Standard sein. Es wird argumentiert, dass ein RNN-basiertes Modell eine valide Alternative zu einem regelbasierten Modell sein kann, wobei Faktoren wie Zeitverbrauch, Wiederverwendbarkeit für verschiedene Sorten einer Zielsprache und signifikante qualitative Ergebnisse in morphologischen Annotationen berücksichtigt werden.', 'ko': '아르메니아어는 품종별로 NLP 자원의 분포가 고르지 않은 변이 현저한 언어다.형태 치수화에 사용되는 RNN 모델을 다양한 아르메니아 데이터(형태 치수 자료 라이브러리 제공 또는 미제공)에 따라 처리하고 RNN 모델과 규칙 기반 모델의 치수 결과를 비교하려 한다.자원이 부족한 언어 변체가 비전문화된 레몬화와 어성 표기 모델의 중용을 평가하기 위해 서로 다른 테스트를 실시했다.이 연구는 세 가지 사투리에 중심을 두고 서아메리카어까지 확대했다. 레몬화의 평균 정확도는 94,00%, 어성 표기의 평균 정확도는 97,02%, 그리고 모델의 중용성으로 다른 아르메니아어 품종을 커버했다.흥미로운 것은 동아르메니아어에서 훈련된 RNN 모델을 시아메니아어에 적용한 동아르메니아 국가어료고의 규칙 기반 모델과 비교해보니 해석 능력이 19% 향상된 것으로 나타났다.이 모델은 서아시아어 단이구 데이터 집합의 88.79%를 덮어 이 표준에서 대규모 어료 라이브러리 주석의 기선으로 삼을 수 있다.RNN 기반 모델은 규칙 기반 모델을 효과적으로 대체할 수 있으며, 시간 소모, 목표 언어의 다양한 종류의 중용성, 형태학 주석에서 현저한 정성 결과 등을 고려할 수 있다는 의견도 있다.', 'id': 'Bahasa Armenia adalah bahasa dengan variasi yang signifikan dan sumber daya NLP yang tidak sama untuk berbagai jenis. Sebuah percobaan dibuat untuk memproses model RNN untuk anotasi morfologi berdasarkan data Armenia yang berbeda (disediakan atau tidak dengan korpora yang anotasi morfologi), dan untuk membandingkan hasil anotasi RNN dan model berdasarkan aturan. Ujian yang berbeda dilakukan untuk mengevaluasi penggunaan ulang model lemmatisasi tidak spesialis dan POS-tagging untuk varietas bahasa yang tidak memiliki sumber daya. Penelitian ini fokus pada tiga dialekt dan lebih lanjut memperluas ke Armenia Barat dengan akurasi rata-rata 94,00 % dalam lemmatisasi dan 97,02 % dalam POS-tagging, serta kemungkinan penggunaan ulang model untuk menutupi berbagai jenis Armenia lainnya. Menarik, perbandingan dari model RNN yang dilatih di Armenia Timur dengan model yang berdasarkan peraturan Korpus Nasional Armenia Timur yang dipakai pada Armenia Barat menunjukkan peningkatan 19% dalam penghasilan. This model covers 88,79% of a short heterogeneous dataset in Western Armenian, and could be a baseline for a massive corpus annotation in that standard.  Diduga bahwa model berdasarkan RNN dapat menjadi alternatif yang valid untuk alternatif berdasarkan peraturan yang mempertimbangkan faktor seperti konsumsi waktu, penggunaan ulang untuk berbagai jenis bahasa sasaran dan hasil kualitatif yang signifikan dalam anotasi morfologis.', 'fa': 'ارمنی یک زبان با تغییرات بزرگی و منابع NLP بی\u200cنظیر برای مختلف مختلف است. یک تلاش برای پرداخت یک مدل RNN برای اظهار مورفولوژیکی بر اساس داده های ارمنی متفاوت (به عنوان شرکت مورفولوژیکی مشخص شده یا نه) و برای مقایسه نتیجه اظهار RNN و مدل\u200cهای قانونی است. آزمایش\u200cهای مختلف برای ارزیابی دوباره استفاده از یک مدل غیر ویژه\u200cای از لیماتیزی و نقاشی POS برای مختلف زبانهای زیر منابع انجام شد. تحقیقات روی سه دیالکت تمرکز شده و به ارمنی غربی با دقیقات متوسط 94.00 درصد در لیماتیزی و 97.02 درصد در نقاشی POS، همچنین یک دوباره استفاده از مدل\u200cها برای پوشاندن مختلف گونه\u200cهای ارمنی است. Interestingly, comparison of an RNN model trained on Eastern Armenian with the Eastern Armenian National Corpus rule-based rule applied to Western Armenian showed an improvement of 19% in parsing. این مدل 88.79 درصد از یک مجموعه داده های غربی کوتاه در ارمنیان غربی پوشش می دهد، و می تواند یک خط بنیادی برای یک اظهار بزرگی در آن استاندارد باشد. گفته می\u200cشود که یک مدل بنیاد RNN می\u200cتواند جایگزینی قانونی باشد که به عنوان مصرف زمان، دوباره استفاده می\u200cکند برای مختلف گونه\u200cهای زبان هدف و نتیجه\u200cهای گونه\u200cای بزرگی در نوشته\u200cهای مورفولوژیک.', 'sw': 'Ki-Armenia ni lugha yenye mabadiliko makubwa na kutolewa rasilimali za NLP kwa ajili ya tofauti tofauti. An attempt is made to process an RNN model for morphological annotation on the basis of different Armenian data (provided or not with morphologically annotated corpora), and to compare the annotation results of RNN and rule-based models.  Majaribio mbalimbali yalifanywa ili kutathmini matumizi ya upya ya mifano isiyo na ufanisi wa kutengeneza vifaa vya udhalilishaji na viungo vya POS kwa utofauti wa lugha yenye rasmi. Utafiti huo ulijikita kwenye lugha tatu na kuendelea zaidi nchini Armenia Magharibi kwa kiwango cha sahihi cha asilimia 94,00 katika viumbe vya umeme na asilimia 97,02 katika viungo vya POS, pamoja na uwezekano wa matumizi ya mifano ya kutangaza tofauti mbalimbali za ki-Armenia. Katika hali ya kushangaza, kulinganisha kwa muundo wa RNN ulioelekezwa kutoka Armenia Mashariki na muundo wa utawala wa National Corpus wa Armenia wa Mashariki uliotumika kwa Wa-Armenia wa Magharibi ulionyesha kuongezeka kwa asilimia 19 katika kuiba. Mfano huu unajumuisha asilimia 88,79 ya taarifa fupi za kibiashara nchini Armenia ya Magharibi, na inaweza kuwa msingi wa matangazo makubwa ya makampuni hayo katika hali hiyo. Inahoji kuwa muundo wa msingi wa RNN unaweza kuwa ni mbadala sahihi wa utawala ambao unafikiria kwa sababu kama vile matumizi ya muda, matumizi ya upya kwa lugha tofauti za lengo na matokeo makubwa yanayotokana na matatizo ya kifolojia.', 'tr': 'Ermençe dürli çeşitlerde nLP çeşitleri üçin wajyp üýtgeşikli we daýlanmadyk bir dildir. Farklı Ermenik verilerine dayanarak RNN modelini işlemek için bir dene edildi ve RNN ve kural tabanlı modellerini karşılaştırmak için denedi. Diňe birnäçe testiler lemmatizasyonyň we POS-taglamasynyň düzümleri üçin ýene-de beýleki nusgalary barlamak üçin provelenýär. Araştyrmalar üç dialekte we Batarça Ermenistanyň 94,00 % lemmatizaçy bilen düýbünden geçirildi we POS taglamasynda 97,02% düýbünden başga düýbünden tapawutlygy bilen üýtgedi. Gyzykly bolsa, Gündogar Ermenistan derejesi bilen bilinen RNN nusgasynyň karşılaştyrylygy Gündogar Ermenistan Milli Korpus düzgünlerine daýan ýan nusgasy Batarça Ermenistana üýtgedilýän nusgasynda 19% köprügini görkezildi. Bu nusga Günbatar Ermenistanyň 88.79% köp deňli hasaplançylygyny daýanýar we bu standartda örän köp duýdurma çykyp biler. RNN tabanly bir nusga düzenlenen kural taýýarlanan bir nusga bolup, wagt tüketmesi ýaly faktörlere düşünerek, maksadyň dürli dili üçin ýene-de ulanylygy we morfolojik täzelikde wajyp görnüş netijesi bolup biler diýilýär.', 'af': "Armeniese is 'n taal met betekende veranderinge en onheilig verdeelde NLP hulpbronne vir verskillende veranderinge. 'n Probeer is gemaak om 'n RNN model te proses vir morfologiese annotasie op die basis van verskillende Armeense data (verskaf of nie met morfologiese annotated corpora) en om die annotasie resultate van RNN en reël-gebaseerde modele te vergelyk. Verskillende toets is uitgevoer om die hergebruik van 'n ongespesialiseerde model van lemmatisasie en POS-etiket vir onder-hulpbron taal verskillighede te evalueer. Die ondersoek het op drie dialekte gefokus en verder uitgevoer na Wes-Armeniese met 'n gemiddelde presisie van 94,00 % in lemmatisasie en 97,02 % in POS-etiketing, en ook 'n moontlike hergebruikbaarheid van modele om verskillende Armeniese verskillighede te dekk. Interesantlik het die vergelyking van 'n RNN-model wat op Oosten-Armeniese opgelei is met die Oosten-Armeniese Nasionale Korpus-reël-gebaseerde model wat op Westen-Armeniese toepassing is, die vergelyking van 19% in vergelyking gewys. Hierdie model bedek 88,79% van 'n kort heterogeneese datastel in Wes-Armeniese, en kan 'n basisline wees vir 'n groot korpus annotasie in daardie standaard. Dit is argumenteer dat 'n RNN-gebaseerde model 'n geldige alternatief kan wees vir 'n reël-gebaseerde een wat aandag a an sodanige faktore as tyd-verbruik, hergebruikbaardigheid vir verskillende verskillende verskillende van 'n doel taal en betekende kwaliteit resultate in morfologiese annotasie.", 'sq': 'Armenian është një gjuhë me variacione të rëndësishme dhe burime të shpërndarë në mënyrë të pabarazishme të NLP për varietete të ndryshme. Një përpjekje është bërë për të procesuar një model RNN për anotacion morfologjik në bazë të të dhënave të ndryshme armene (të dhëna apo jo me korpra të anotuar morfologjikisht) dhe për të krahasuar rezultatet e anotacionit të RNN dhe modeleve të bazuar në rregulla. U kryen teste të ndryshme për të vlerësuar përdorimin e përsëritur të një modeli të paspecializuar limmatizimi dhe etiketave POS për varietetet e gjuhës me pak burime. Kërkimi u përqëndrua në tre dialekte dhe u zgjerua më tej në armenin perëndimor me një saktësi mesatare 94,00 % në limmatizim dhe 97,02% në etiketën POS si dhe një përdorueshmëri të mundshme të modeleve për të mbuluar lloje të ndryshme armene të tjera. Interesante, krahasimi i një modeli RNN të stërvitur në armenin lindor me model in bazuar në rregullat e Korpus Kombëtar Armenian Lindor të aplikuar në armenin perëndimor tregoi një përmirësim prej 19% në analizimin. Ky model mbulon 88,79% të një grupi të dhënash të shkurtër heterogjene në armenin perëndimor dhe mund të jetë një bazë për një anotacion masiv të trupit në atë standard. Argumentohet se një model i bazuar në RNN mund të jetë një alternativë e vlefshme për një alternativë të bazuar në rregulla duke i konsideruar faktorë të tillë si konsumi i kohës, ripërdorueshmëria për llojet e ndryshme të një gjuhe objektive dhe rezultate të rëndësishme kualitative në anotacion morfologjik.', 'am': 'አርሜኒያን ልዩ ልዩነት እና የNLP ሀብት ለልዩ ልዩ ልዩነት የተከፈለ ቋንቋ ነው። የRNN ሞዴል በተለዩ አርሜኒያን ዳታ (በሞሮፎሎጂ ወይም በኮርፖርት ላይ ባይታወቀ) እና RNN እና የሥርዓት ሥርዓት ዓይነቶችን ለመተካከል ነው፡፡ በተለየ ቋንቋዎች ውስጥ ያልታወቀ የኢሜያል እና የPOS-tagging ጥያቄ ለመጠቀም የተለያዩ ፈተናዎች ተፈተናል፡፡ ምርመራው የሦስት ዲያብሎክ እና ወደ ምዕራባዊ አርማኔናዊ ተጨማሪ የ94,00 በመቶ እርግጠኛ ማስረጃ እና 97,02 በመቶ በፖስስ ማተሚያ እና ሌሎችን አርሜኒያን ልዩ ልዩ ልዩ ልዩ ልዩነት እንዲሸፍኑ የሚችል ምሳሌዎችን ለመከላከል ይችላል፡፡ በምሥራቅ አርሜኒያን ከምሥራቅ አርሜኒያ የብሔራዊ ኮርፓስ ሥርዓት ሥርዓት የተደረገውን የRNN ሞዴል ምሳሌ በምዕራብ አርሜኒያን በፓርቲው ውስጥ 19 በመቶ ያበረታታል፡፡ ይህ ምሳሌ 88,79 በመቶ ምዕራብ አርሜኒያን የካለ አካባቢ ዳታዎችን ይሸፍናል፡፡ It is argued that an RNN-based model can be a valid alternative to a rule-based one giving consideration to such factors as time-consumption, reusability for different varieties of a target language and significant qualitative results in morphological annotation.', 'hy': 'Armenian is a language with significant variation and unevenly distributed NLP resources for different varieties.  Մորֆոլոգիական annoտացիայի ՌՆԹ-ի մոդելը փորձվում է վերլուծել տարբեր արմենյան տվյալների հիմքում (տրամադրված կամ ոչ մորֆոլոգիապես annoտացված կոպորա) և համեմատել ՌՆԹ-ի և կանոններով հիմնված մոդելների annoտացիայի արդյունքները: Տարբեր թեստեր էին կատարվել, որպեսզի գնահատենք լեմմատիզացիայի և POS-ի անմասնավոր մոդելի կրկին օգտագործումը թերռեսուրսների լեզվի բազմազանությունների համար: Հետազոտությունը կենտրոնացավ երեք դիալեկտների վրա և շարունակեց ընդլայնվել Արևմտյան Էրմենիային, որի միջին ճշգրտությունը 94,00 տոկոս էր լիմմատիզացիայի մեջ և 97,02 տոկոս՝ POS-ի նշանների մեջ, ինչպես նաև մոդելների հնարավոր վերաօգտագործելիությունը,  Հետաքրքիր է, Արևելյան Էրմենիայից վարժեցված ՌՆԹ մոդելի համեմատությունը Արևելյան Էրմենիայի ազգային կորպոսի կանոններով հիմնված մոդելի հետ, որը կիրառվել է Արևելյան Էրմենիայի դեպքում, ցույց տվեց 19 տոկոսո Այս մոդելը ներառում է արևմտյան Էրմենիայի կարճ հետերոգեն տվյալների 88,79 տոկոսը, և կարող է լինել հիմք այդ ստանդարտի մեծ մարմնի նշումների համար: Պարզվում է, որ ՌՆԹ-ով հիմնված մոդելը կարող է լինել օրենքներով հիմնված մի ճշգրիտ այլընտրանք, որը հաշվի առնում է այնպիսի գործոններ, ինչպիսիք են ժամանակի սպառումը, նպատակային լեզու տարբեր տեսակների կրկին օգտագործելիությունը և նշանակալի որակական արդ', 'bn': 'আর্মেনিয়ান একটি ভাষা যাদের গুরুত্বপূর্ণ ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ বিভিন্ন আর্মেনিয়ান ডাটা ভিত্তিক ভিত্তিতে একটি আরএনএন মডেল প্রক্রিয়ার প্রচেষ্টা করা হয়েছে (নৈতিক ভাবে কোর্পোরা প্রদান করা হয় বা না দিয়ে), আর আরএনএন এবং নিয়মিত মডেল Different tests were carried out to evaluate the reuse of an unspecialized model of lemmatization and POS-tagging for under-resourced language varieties.  গবেষণাটি তিনটি ডায়ালগের উপর মনোযোগ দিয়ে পশ্চিম আর্মেনিয়ানের দিকে আরো বাড়িয়ে দিয়েছে যার মানে সঠিকভাবে ৯৪,০০০% লাগবে এবং পোস ট্যাগিং এ ৭,২% এবং অন্য আর্মেনিয়ার মজার ব্যাপারে, পূর্ব আর্মেনিয়ান ন্যাশনাল কোর্পাস নিয়মের মডেলের প্রশিক্ষণ প্রদান করা এক আরএনএন মডেলের তুলনায় পশ্চিম আর্মেনিয়ার প্রতি পার্জিং এ ১৯%  এই মডেলটি পশ্চিম আর্মেনিয়ার সংক্ষিপ্ত বৈশিষ্ট্যাবলী তথ্যের মধ্যে ৮৮,৭৯% কাভার করে থাকে, এবং এই স্ট্যান্ডারে বিশাল কোর্পাসে এটি যুক্তি দেয়া হয়েছে যে একটি RNN ভিত্তিক মডেল একটি বৈধ বিকল্প হতে পারে যেখানে একটি নিয়ম ভিত্তিক বিকল্প হতে পারে যারা টাইমব্যবহার, বিভিন্ন ধরনের লক্ষ্য ভাষার পুনরায় ব্', 'az': 'Ermenik müxtəlif çeşitlər üçün mövcud dəyişiklik və nLP kaynaqları olan dildir. Farklı Erminik məlumatlarının (morphologically annotated corpora təyin edilmiş və ya morfologically annotated corpora təyin edilmiş və ya yox edilmiş) tərzlərinin RNN modelini və hökmlərin təyin edilmiş modellerinin nəticələrini salmaq üçün bir nəsihət olunur. Müxtəlif sınaqlar limmatizasyonun və POS-etiketlərinin çoxluğunun yenidən istifadəsini değerləşdirmək üçün işlədilər. Bu araştırma üç dialektə odaqlandı və daha sonra Batı Ermini tərəfində lemmatizasyonda 94,00 % və POS etiketində 97,02 % tərəfində olan orta dəqiqliyi ilə uzatdı, başqa ərmini müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif modellerin yenidən istifadə edilməsi də İlginç ki, Şərqi Ermeniyyətdə təhsil edilmiş RNN model in in şərqi Ermeniyyətdə təhsil edilən şərqi Ermeniyyətdə Qərqi Ermeniyyətə uyğulanmış qurbanlıq qurbanlıq modeli ilə müqayisədə 19%-dən artırmağını göstərdi. Bu model Batı Ermeniyyadakı qısa heterogenen veri setinin 88.79%-ini örtür və bu standartda böyük korpus annotasyonu olar. RNN-ə dayanan modellərin dəyişiklik alternatifi olaraq, zamanı istifadə etmək, məqsəd dillərinin fərqli cür növbətlərinin yenidən istifadə edilməsi və morfolojik növbətlərinin möhkəm qabiliyyətli sonuçları ilə düşünüb daxil edilən faktörlərə istifadə edilir.', 'bs': 'Armenski je jezik sa značajnim varijacijom i nepravedno raspodijeljenim NLP resursima za različite razine. Pokušava se obraditi model RNN za morfološku annotaciju na temelju različitih Armenskih podataka (pruženih ili ne morfološki annotiranih korpora) i usporediti rezultate annotacije RNN-a i modela baziranih na pravilima. Provedeni su različiti testovi kako bi procijenili ponovno upotrebu neopecijaliziranog modela limmatizacije i označavanja POS-a za neposredne jezičke razine. Istraživanje se fokusiralo na tri dijalekta i dalje se proširilo na zapadnu Armensku s srednjom preciznošću od 94,00 % u lematizaciji i 97,02 % u označavanju POS-a, kao i mogućom ponovnom korištenju modela za pokrivanje različitih Armenskih različitih vrsta. Zanimljivo je da je usporedba modela RNN obučenog na istočnoj Armeniji sa pravilnim modelom na istočnom Armenskom nacionalnom korpusu primjenom na zapadnu Armeniju pokazala poboljšanje od 19% u analizu. Ovaj model pokriva 88.79% kratke heterogenezne podatke na zapadnom Armenskom, i može biti početna linija za veliku korpusnu annotaciju u tom standardu. Tvrdi se da model na RNN-u može biti valjan alternativ na pravilima koji daje razmatranje faktorima poput potrošnje vremena, ponovno korištenja različitih različitih različitih različitih različitih jezika ciljnog jezika i značajnih kvalitativnih rezultata morfološke annotacije.', 'cs': 'Arménština je jazyk s významnou variací a nerovnoměrně rozloženými zdroji NLP pro různé odrůdy. Je zkoušena zpracovat RNN model pro morfologickou anotaci na základě různých arménských dat (poskytnutých či nikoli s morfologicky anotovanými korpusy) a porovnat výsledky anotace RNN a pravidelně založené modely. Byly provedeny různé testy pro vyhodnocení opětovného využití nespecializovaného modelu lemmatizace a POS-tagging pro nedostatečně zdrojové jazykové odrůdy. Výzkum se zaměřil na tři dialekty a dále se rozšířil na západní arménštinu se střední přesností 94,00% v lemmatizaci a 97,02% v POS-tagging, stejně jako možné opakované použitelnosti modelů pro pokrytí různých dalších arménských odrůd. Zajímavé je, že porovnání RNN modelu trénovaného na východní Arménštině s východním arménským národním korpusem založeným na pravidlech aplikovaného na západní arménštině ukázalo zvýšení 19% v parsování. Tento model pokrývá 88,79% krátkého heterogenního datového souboru v západní arménštině a může být základním bodem pro masivní korpusovou anotaci v tomto standardu. Je argumentováno, že model založený na RNN může být platnou alternativou k modelu založenému na pravidlech s ohledem na faktory jako časová spotřeba, opakovaná použitelnost pro různé odrůdy cílového jazyka a významné kvalitativní výsledky morfologické anotace.', 'et': 'Armeenia keel on keel, millel on märkimisväärne varieeruvus ja erinevate sortide jaoks ebaühtlaselt jaotatud NLP ressursid. Püütakse töödelda RNN mudelit morfoloogiliste annotatsioonide jaoks erinevate Armeenia andmete põhjal (morfoloogiliselt annoteeritud korpustega või mitte) ning võrrelda RNN ja reeglipõhiste mudelite annotatsiooni tulemusi. Erinevad testid viidi läbi, et hinnata spetsialiseerimata lemmatiseerimise ja POS-märgistamise mudeli taaskasutamist alaressurssidega keelesortidele. Uuringud keskendusid kolmele dialektile ja laienesid Lääne-Armeeniale keskmise täpsusega 94,00% lemmatiseerimisel ja 97,02% POS-märgistamisel, samuti mudelite võimaliku taaskasutatavusega, et katta erinevad teised Armeenia sortid. Huvitav on, et Ida-Armeenia keelele koolitatud RNN mudeli võrdlemine Ida-Armeenia Rahvuskorpuse reeglitel põhineva mudeliga, mida rakendati Lääne-Armeenia keelele, näitas 19% paremat parsimist. See mudel hõlmab 88,79% Lääne-Armeenia keelsest lühikesest heterogeensest andmekogumist ja võib olla aluseks massiivsele korpuse annotatsioonile selles standardis. Väidetakse, et RNN-il põhinev mudel võib olla õige alternatiiv reeglitel põhinevale mudelile, võttes arvesse selliseid tegureid nagu aja tarbimine, sihtkeele eri sortide korduvkasutatavus ja märkimisväärsed kvalitatiivsed tulemused morfoloogilisel märgistamisel.', 'ca': "L'armeni és un llenguatge amb variació significativa i recursos de NLP distribuïts desigualment per diferents varietats. S'intenta processar un model de RNN per anotació morfològica sobre la base de diferents dades armenes (proporcionades o no amb corpores morfològicament anotats), i comparar els resultats d'anotació dels RNN i dels models basats en regles. Es van fer diferents tests per avaluar la reutilització d'un model no especialitzat de limmatització i etiqueta POS per varietats de llenguatges poc resources. La investigació es va centrar en tres dialectes i s'estendre més a l'armenia occidental amb una mitjana de precisió del 94,00 % en la limmatització i del 97,02 % en l'etiquetage POS, així com una possibilitat de reutilització de models per cobrir diferents altres varietats armenes. Interessant, la comparació d'un model RNN entrenat en armeni oriental amb el model basat en la regla del Corps Nacional de l'Armenia oriental aplicat en armeni occidental va mostrar un increment del 19% en l'analització. Aquest model cobre el 88,79% d'un petit conjunt de dades heterogènes en armenia occidental, i podria ser la base d'una gran anotació de corpus en aquest estàndard. Se argumenta que un model basat en RNN pot ser una alternativa válida a una basada en regles, tenint en compte factors com el consum de temps, la reutilització per diferents varietats d'una llengua d'objectiu i resultats qualitatius significatius en anotació morfològica.", 'fi': 'Armenia on kieli, jolla on merkittäviä vaihteluja ja epätasaisesti jakautuneita NLP-resursseja eri lajikkeille. Pyritään käsittelemään RNN-mallia morfologista annotointia varten erilaisten armenialaisten tietojen perusteella (morfologisesti annotoiduilla korpusilla tai ei) sekä vertailemaan RNN:n ja sääntöpohjaisten mallien annotointituloksia. Eri testejä suoritettiin arvioimaan, miten lemmatisaatio- ja POS-tagging-mallit uusitaan aliresurssoiduille kielilajikkeille. Tutkimuksessa keskityttiin kolmeen murteeseen ja laajennettiin edelleen Länsi-armeniaan keskimäärin 94,00% lemmatisoinnissa ja 97,02% POS-taggingissa sekä mahdollistettiin mallien uudelleenkäytettävyys kattamaan erilaisia armenialaisia lajikkeita. Mielenkiintoista on, että Itä-Armeniaan koulutetun RNN-mallin vertailu Itä-Armenian kansallisen korpusen sääntöpohjaiseen malliin, jota sovellettiin Länsi-Armeniaan, osoitti 19 prosentin parannuksen jäsentämisessä. Tämä malli kattaa 88,79% lyhyestä heterogeenisestä Länsi-armeniankielisestä aineistosta, ja voisi olla perusta massiiviselle korpusmerkinnälle kyseisessä standardissa. Väitetään, että RNN-pohjainen malli voi olla pätevä vaihtoehto sääntöpohjaiselle mallille, jossa otetaan huomioon muun muassa ajankulutus, kohdekielen uudelleenkäytettävyys eri lajikkeille ja merkittävät laadulliset tulokset morfologisessa merkinnässä.', 'jv': "pon Wang text-editor-action Awakdhéwé sing dipolehko nganggo telu dialectu lan nganggo sênêmêr sing katêpakan karo Armani sing basa, dadine kapan kanggo kalagayuté awak dhéwé, awak dhéwé karo 1994,00% lan lemmatirasyon lan 1997,02% lan tambah sing ditawak dhéwé, tambah kayiné ngejaraké model sing bisa ngejaraké koyo ngono ca Kowe isih, sampeyan karo model DNN sing ditambah 'Orient Armian' nganggo perusahaan Rasané Armani sing gawe barang nggawe barang kelas Jejaran Nalikasi model iki wis ngacah-cah bener PIN", 'he': 'Armenian is a language with significant variation and unevenly distributed NLP resources for different varieties.  ניסיון נעשה לעבד דוגמא RNN עבור הערות מורפולוגית על בסיס נתונים ארמנים שונים (שנספקים או לא עם גופורה מורפולוגית מורפולוגית), ולהשוות את תוצאות הערות של RNN ומדוגמנים מבוססים על חוקים. ביצעו בדיקות שונות כדי להעריך את השימוש מחדש של מודל לא מיוחד של לימטיזציה ומתג POS לסוגים שפות מתחת למשאבים. המחקר התמקד בשלושה דיאלקטים וממשיך להתרחב למערב ארמני עם מדויקת ממוצעת של 94,00% בלמטיזציה ו-97,02% בלמטגים POS, כמו גם ניתן להשתמש מחדש של דוגמנים כדי לכסות מגוונים ארמנים אחרים שונים. מעניין, השוואה של דוגמנית RNN מאומנת על ארמני מזרחי עם דוגמנית המבוססת על חוקי הקורפוס הלאומי המזרחי הארמני שמשתמשת על ארמני המערבי הראה שיפור של 19 אחוזים בפרקים. מודל זה מכסה 88,79% מסט נתונים היטרוגני קצר בארמנית המערבית, ויכול להיות בסיס עבור ציון גופוס מסיבי בסטנדרט הזה. טוענים שמודל מבוסס על RNN יכול להיות אלטרנטיבה נכונה לאחרונה מבוססת על חוקים שמשקלת גורמים כאלה הזמן-שימוש, שימוש מחדש למגוונים שונים של שפת המטרה ותוצאות איכותיות משמעותיות בהכתבה מורפולוגית.', 'ha': "@ item Spelling dictionary An jarraba wani misãlin RNN wa mai zartar da shirin morfologi a kan bayan data masu buƙata na armanci (da aka azurta ko kuma ba da marofogi ya yi zartar da Corpo), kuma a sami matsalar fassaran zartarwa na RNN da misãlai masu rubutun. An aiko jarrabo dabam-daban dõmin a evaluate amfani da wata misali na lissafa da ba'a sani ba na salãmar da tagogi na mais-tagning wa wasu nau'i da ke ƙaranci-resource. Research na fokus a kan misalin uku na bayani kuma aka ƙara shi zuwa Tsarama na gabas, yana da ma'aunin taƙaitacce na 94,000% cikin lammasi da 97,01% cikin bastarwa na PoS-tagning, da sami mai yiwuwa ya yi amfani da misãlai dõmin su tsare wasu dabam-aram. Ina sha'anar, kafarin wani misalin RNN wanda aka yi wa tunkuɗe a gabas-arama na armani da misãlin rubutun National Corbus na gabas ya applied to West Aramenan ya nuna wani ƙari da 19% a parse. Wannan misalin na rufe 88,79% daga matsayin mutane na tsohon da aka samu a cikin Tsarama na Tsarama, kuma yana iya kasa wani basalin matsayi mai girma ga nau'in nan. Ana yi jãyayya da cewa wata misalin a kan RNN ya zama wata shida mai inganci wa wata rubutu mai inganci, wanda ya yi bincike da factori kamar matuƙar-amfani da lokaci, kuma yana amfani da nau'in wasu nau'i-harshe na walƙin da aka yi amfani da shi, da matsalar masu muhimmi na mutafalojiki.", 'sk': 'Armenščina je jezik z velikimi variacijami in neenakomerno porazdeljenimi viri NLP za različne sorte. Poskušamo obdelati RNN model za morfološko označevanje na podlagi različnih armenskih podatkov (zagotovljenih ali ne z morfološko označenimi korpusi) in primerjati rezultate označevanja RNN in pravil temelječih modelov. Izvedeni so bili različni testi za oceno ponovne uporabe nespecializiranega modela lemmatizacije in POS-označevanja za premalo virov jezikovnih sort. Raziskava se je osredotočila na tri narečja in se nadalje razširila na zahodno armensko s povprečno natančnostjo 94,00% pri lemmatizaciji in 97,02% pri POS-označevanju ter možnostjo ponovne uporabe modelov za pokrivanje različnih drugih armenskih sort. Zanimivo je, da je primerjava modela RNN, usposobljenega na vzhodnem armenskem jeziku, z modelom vzhodnega armenskega narodnega korpusa, ki temelji na pravilih vzhodnega armenskega narodnega korpusa, ki se uporablja na zahodnem armenskem jeziku, pokazala 19-odstotno povečanje razčlenitve. Ta model zajema 88,79% kratkega heterogenega nabora podatkov v zahodnem armenskem jeziku in bi lahko bil osnova za množično korpusno označevanje v tem standardu. Trdi se, da je model, ki temelji na RNN, lahko veljavna alternativa pravilu in upošteva dejavnike, kot so poraba časa, ponovna uporabnost za različne sorte ciljnega jezika in pomembni kvalitativni rezultati pri morfološkem označevanju.', 'bo': 'ཨར་མི་ནི་ཡིས་སྐད་ཡིག་རྒྱུན་ལྡན་མ་དང་ཐོག་ཁུངས་རྩིས་མེད་པའི་NLP རྒྱུ་དངོས་ཐོག An attempt is made to process an RNN model for morphological annotation on the basis of different Armenian data (provided or not with morphologically annotated corpora), and to compare the annotation results of RNN and rule-based models. སྐད་རིགས་འདིའི་ནང་དུ་དམིགས་འཛུགས་ཀྱི་མིག་གཟུགས་རིས་ལ་རྒྱབ་སྐྱོར་མེད་པའི་རྣམ་པ་ཞིག་ལས་བརྟག་དཔྱད་འགྱུར་བ་ཡིན་པས། འཚོལ་ཞིབ་འདིས་dialects གསུམ་གྱི་ནང་དུ་དམིགས་བསལ་ནུས་པ་ཡིན་མཁན་གྱི་ཨར་མེན་གྱི་ཕྱོགས་འགོད་སུ་ཡོད་པ་ལྟར་ན། དར་མེན་གྱི་རྒྱ་ཆ་ཚན་མ་འདྲ་བ་དང་97,02% Interestingly, the comparison of an RNN model trained on Eastern Armenian with the Eastern Armenian National Corpus rule-based model applied to Western Armenian Armenians showed an enhancement of 19% in parsing. རྣམ་གྲངས་འདིས་ནུབ་ཀྱི་ཨ་རམ་ཡིན་པའི་ཚད་གཞི་ཚོགས་ཀྱི་88.79%སྐོར་ཡོད། It is argued that an RNN-based model can be a valid alternative to a rule-based one giving consideration to such factors as time-consumption, reusability for different varieties of a target language and significant qualitative results in morphological annotation.'}
{'en': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'ar': 'Uralic Language Identification (ULI) 2020 مجموعة بيانات المهام المشتركة ومجموعة Wanca 2017 corpora', 'fr': 'Jeu de données de tâches partagées Uralic Language Identification (ULI) 2020 et corpus Wanca 2017', 'pt': 'Conjunto de dados de tarefas compartilhadas de identificação de idioma urálico (ULI) 2020 e os corpora Wanca 2017', 'es': 'Conjunto de datos de tareas compartidas de identificación del lenguaje urálico (ULI) 2020 y corpora de Wanca 2017', 'ja': 'Uralic Language Identification (ULI) 2020共有タスクデータセットとWanca 2017コーラ', 'hi': 'यूरालिक भाषा पहचान (यूएलआई) 2020 साझा कार्य डेटासेट और वानका 2017 कॉर्पोरेट', 'zh': '乌拉尔语识 (ULI) 2020 共数集 Wanca 2017 语料库', 'ru': 'Набор данных по общим задачам Uralic Language Identification (ULI) 2020 и корпорации Wanca 2017', 'ga': 'Tacar sonraí tasc comhroinnte um Aitheantas Teanga Úralach (ULI) 2020 agus corpora Wanca 2017', 'ka': 'Uralic Language Identification (ULI) 2020 shared task data set and the Wanca 2017 corpora', 'el': 'Καθορισμός της Ουραλικής Γλώσσας (ULI) 2020 κοινόχρηστο σύνολο δεδομένων εργασιών και τα σώματα Wanca 2017', 'hu': 'Urális Nyelvazonosító (ULI) 2020 megosztott feladatadatkészlet és a Wanca 2017 korpus', 'it': 'Uralic Language Identification (ULI) 2020 set di dati condivisi di attività e corpora Wanca 2017', 'kk': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'lt': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'ml': 'ഉരാലിക് ഭാഷ തിരിച്ചറിയുക (ULI) 2020 പങ്കെടുത്ത ജോലി ഡാറ്റാസെറ്റും വാങ്കാ 2017 കോര്\u200dപ്പോറ', 'mn': 'Uralic Language Identification (ULI) 2020 shared task data set and the Wanca 2017 corpora', 'no': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'pl': 'Uralic Language Identification (ULI) 2020 współdzielony zestaw danych zadań i korpusy Wanca 2017', 'mt': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'ro': 'Setul de date pentru activitățile comune de identificare a limbajului Ural (ULI) 2020 și corporele Wanca 2017', 'sr': 'Uralička identifikacija jezika (ULI) 2020. zajednička podataka za zadatke i korporacija Wanca 2017.', 'si': 'Uralc භාෂාව පරිශ්චාපනය (UTI) 2020යි කාර්ය දත්ත සැකයි වන්කා 2017 කෝපෝරා', 'so': 'Aqoonsiga luqada Uralika (ULI) 2020 oo la qaybsaday taarifka shaqada iyo shirkadda Wanca 2017', 'mk': 'Идентификација на ураличкиот јазик (УЛИ) 2020 споделена датотека на задачи и корпората Wanca 2017', 'ms': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'sv': 'Datauppsättningen delade uppgifter för Ural Language Identification (ULI) 2020 och Wanca 2017-korporan', 'ta': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'ur': 'Uralic Language Identification (ULI) 2020 shared task data set and the Wanca 2017 corpora', 'uz': 'Tasdiqlash', 'vi': 'Số dữ liệu chia sẻ ngôn ngữ Ural bây giờ', 'bg': 'Уралска езикова идентификация (УЛИ) за 2020 г. и корпоративните данни на Уанка 2017 г.', 'da': 'Datasættet for delte opgaver i Ural Language Identification (ULI) 2020 og Wanca 2017-korpora', 'nl': 'Uralic Language Identification (ULI) 2020 gedeelde taakgegevenset en het Wanca 2017 corpora', 'hr': 'Uralička identifikacija jezika (ULI) 2020. zajednička podataka za zadatke i korporacija Wanca 2017.', 'de': 'Uralic Language Identification (ULI) 2020 Shared Task Dataset und Wanca 2017 Corpora', 'ko': '우랄어 식별(ULI) 2020 공유 임무 데이터 세트와 Wanca 2017 자료 라이브러리', 'id': 'Identifikasi Bahasa Ural (ULI) 2020 dataset tugas berbagi dan korpora Wanca 2017', 'fa': 'شناسایی زبان Uralic Language Identification (ULI) 2020 shared task data set and the Wanca 2017 corpora', 'sw': 'Utambulisho wa lugha ya Kiurali (ULI) 2020 ulishiriki takwimu za kazi na kampuni ya Wanca 2017', 'tr': 'Uralik Dil Kimligi (ULI) 2020-nji ýygna gören dataseti we Wanca 2017 corpora', 'af': 'Uralic Language Identification (ULI) 2020 deel taakdatasset en die Wanca 2017 korpora', 'sq': 'Identifikimi i gjuhës urale (ULI) 2020 i përbashkët i të dhënave të detyrave dhe korpora Wanca 2017', 'am': 'የኦርላሊክ ቋንቋ ማግኘት (ULI) 2020 የስራ ዳታዎችን እና የዋና 2017 ኮርፖር', 'az': 'Uralic Dil Identification (ULI) 2020 paylaşdırılmış iş veri seti və Wanca 2017 corpora', 'bn': 'উরালিক ভাষা পরিচয় (ULI) ২০২০ শেয়ার কর্মসূচী ডাটাসেট এবং ওয়াঙ্কা ২০১৭ কর্পোরা', 'bs': 'Uralička identifikacija jezika (ULI) 2020. zajednička podataka za zadatke i korporacija Wanca 2017.', 'cs': 'Uralic Language Identification (ULI) 2020 sdílená data úloh a korpusy Wanca 2017', 'et': 'Uuralise keele identifitseerimise (ULI) 2020 jagatud ülesannete andmekogum ja Wanca 2017 korpused', 'fi': 'Uralic Language Identification (ULI) 2020 jaettu tehtäväaineisto ja Wanca 2017 -korpuset', 'hy': 'Ուրալիկ լեզվի հայտնաբերությունը (URI) 2020-ի ընդհանուր խնդիրների տվյալների համակարգը և 2017 թվականի Ուանկա կոպորան', 'ca': 'Identificació Uràlica de Llingua (ULI) 2020 compartia dades de tasques i el corpora Wanca 2017', 'jv': 'Uralic Language ID (UlI) 2020 share task dataset and the Wanca 2020 bodora', 'ha': "Suna'anin Lugha na Uralic (ULI) 2020", 'bo': 'Uralic Language Identification (ULI) 2020 shared task dataset and the Wanca 2017 corpora', 'sk': 'Identifikacija uralskega jezika (ULI) 2020 skupni nabor opravil in korpusi Wanca 2017', 'he': 'זיהוי שפת אוראלית (ULI) 2020 שותף מידע משימות והגופרה של וואנקה 2017'}
{'en': 'This article introduces the Wanca 2017 web corpora from which the sentences written in minor Uralic languages were collected for the test set of the Uralic Language Identification (ULI) 2020 shared task. We describe the ULI shared task and how the ', 'es': 'Este artículo presenta los corpus web de Wanca 2017 de los que se recopilaron las frases escritas en lenguas urálicas menores para el conjunto de pruebas de la tarea compartida de identificación del idioma urálico (ULI) 2020. Describimos la tarea compartida de ULI y cómo se construyó el conjunto de pruebas utilizando los corpus de Wanca 2017 y textos en diferentes idiomas de la colección de corpus de Leipzig. También proporcionamos los resultados de un experimento de identificación del idioma de referencia realizado con el conjunto de datos ULI 2020.', 'ar': 'تقدم هذه المقالة مجموعة Wanca 2017 على الويب التي تم جمع الجمل المكتوبة منها بلغات أورالية ثانوية لمجموعة اختبار مهمة تحديد اللغة الأورالية (ULI) 2020 المشتركة. نصف مهمة ULI المشتركة وكيف تم إنشاء مجموعة الاختبار باستخدام Wanca 2017 corpora والنصوص بلغات مختلفة من مجموعة Leipzig corpora. نقدم أيضًا نتائج تجربة تحديد اللغة الأساسية التي تم إجراؤها باستخدام مجموعة بيانات ULI 2020.', 'pt': 'Este artigo apresenta os corpora da web Wanca 2017, dos quais as frases escritas em idiomas urálicos menores foram coletadas para o conjunto de teste da tarefa compartilhada de identificação de idioma urálico (ULI) 2020. Descrevemos a tarefa compartilhada do ULI e como o conjunto de testes foi construído usando os corpora Wanca 2017 e textos em diferentes idiomas da coleção de corpora Leipzig. Também fornecemos os resultados de um experimento de identificação de idioma de linha de base realizado usando o conjunto de dados ULI 2020.', 'fr': "Cet article présente les corpus Web Wanca 2017 à partir desquels les phrases écrites dans les langues ouraliennes mineures ont été collectées pour le jeu de test de la tâche partagée Uralic Language Identification (ULI) 2020. Nous décrivons la tâche partagée ULI et la façon dont le jeu de tests a été construit à partir des corpus Wanca 2017 et des textes dans différentes langues de la collection de corpus de Leipzig. Nous fournissons également les résultats d'une expérience d'identification linguistique de base menée à l'aide de l'ensemble de données ULI 2020.", 'ru': 'В этой статье представлены веб-корпорации Wanca 2017, из которых были собраны предложения, написанные на второстепенных уральских языках, для тестового набора совместной задачи Uralic Language Identification (ULI) 2020. Мы описываем общую задачу ULI и то, как набор тестов был построен с использованием корпусов Wanca 2017 и текстов на разных языках из коллекции корпусов Leipzig. Мы также предоставляем результаты базового эксперимента по идентификации языка, проведенного с использованием набора данных ULI 2020.', 'zh': '本文介Wanca 2017网络语料库,因集小乌拉尔语句,以乌拉尔语识(ULI)2020年共其集。 述ULI共事,及Wanca 2017语料库与莱比锡语料库合语本构试。 供用ULI 2020数集基线语言识实验。', 'ja': 'この記事では、Uralic Language Identification (ULI) 2020共有タスクのテストセットのために、マイナーなウラル語で書かれた文章を収集したWanca 2017 Webコーパを紹介します。ULI共有タスクと、Wanca 2017コーラを使用したテストセットの構築方法、およびライプツィヒコーラコレクションの異なる言語のテキストについて説明します。また、ＵＬＩ ２ ０ ２ ０データセットを用いて実施したベースライン言語同定実験の結果も提供する。', 'hi': 'यह लेख Wanca 2017 वेब कॉर्पोरेट का परिचय देता है जिसमें से मामूली यूरालिक भाषाओं में लिखे गए वाक्यों को यूरालिक भाषा पहचान (यूएलआई) 2020 साझा कार्य के परीक्षण सेट के लिए एकत्र किया गया था। हम यूएलआई साझा कार्य का वर्णन करते हैं और कैसे परीक्षण सेट का निर्माण वानका 2017 कॉर्पोरेट और लीपज़िग कॉर्पोरेट संग्रह से विभिन्न भाषाओं में ग्रंथों का उपयोग करके किया गया था। हम यूएलआई 2020 डेटासेट का उपयोग करके किए गए बेसलाइन भाषा पहचान प्रयोग के परिणाम भी प्रदान करते हैं।', 'ga': 'Tugann an t-alt seo isteach corpora gréasáin Wanca 2017 ónar bailíodh na habairtí atá scríofa i mionteangacha Úralacha do thacar tástála an taisc chomhroinnte um Aitheantas Teanga Úralach (ULI) 2020. Déanaimid cur síos ar thasc roinnte ULI agus ar an gcaoi ar cuireadh le chéile an fhoireann tástála ag baint úsáide as corpora Wanca 2017 agus as téacsanna i dteangacha éagsúla ó bhailiúchán corpora Leipzig. Soláthraímid freisin torthaí turgnamh sainaitheanta teanga bonnlíne a rinneadh ag baint úsáide as tacar sonraí ULI 2020.', 'ka': 'ამ წესტილის შესახებ ვანკა 2017-ის საბოლო კოპორაზე, რომლიდან ნაკლები სურალიკური ენაში წერტილი წესების შესახებ სურალიკური ენათეტიფიკაციის (ULI) 2020-ის გაყოფილი დავალების ტესტის სე ჩვენ დავწერეთ ULI გაყოფილი პარამეტრის და როგორ ტესტის სექტის შექმნა გამოყენებული 2017 სანუა კოპორაში და ტექსტის განსხვავებული ენაში Leipzig კოპორაზე. ჩვენ ასევე გავაკეთებთ განსაზღვრებული ენის იდენტიფიკაციის ექსპერიმენტის შედეგი, რომელიც გავაკეთებული ULI 2020 მონაცემების კონფიგურაციაში.', 'el': 'Αυτό το άρθρο εισάγει τα διαδικτυακά σώματα από τα οποία συλλέχθηκαν οι προτάσεις γραμμένες σε δευτερεύουσες Ουραλικές γλώσσες για το δοκιμαστικό σύνολο της κοινής εργασίας Ουραλικής Γλώσσας 2020. Περιγράφουμε την κοινή εργασία και πώς κατασκευάστηκε το δοκιμαστικό σύνολο χρησιμοποιώντας τα σώματα Wanca 2017 και κείμενα σε διαφορετικές γλώσσες από τη συλλογή Corpora της Λειψίας. Παρέχουμε επίσης τα αποτελέσματα ενός βασικού πειράματος αναγνώρισης γλώσσας που διεξήχθη χρησιμοποιώντας το σύνολο δεδομένων ULI 2020.', 'hu': 'Ez a cikk bemutatja a Wanca 2017 webes korpuszt, amelyből a kisebb uráli nyelveken írt mondatokat az Uráli Nyelvazonosítás (ULI) 2020 megosztott feladatának tesztsorozatához gyűjtötték össze. Leírjuk az ULI megosztott feladatát, valamint azt, hogy a tesztkészlet hogyan épült fel a Wanca 2017 korpuszaival és a lipcsei korpuszgyűjteményből származó különböző nyelvű szövegekkel. Az ULI 2020 adatkészlet felhasználásával végzett alapvető nyelvazonosítási kísérlet eredményeit is bemutatjuk.', 'it': 'Questo articolo introduce i corpora web Wanca 2017 da cui sono state raccolte le frasi scritte in lingue Urali minori per il set di test del compito condiviso ULI 2020. Descriviamo il compito condiviso da ULI e come il test set è stato costruito utilizzando i corpi Wanca 2017 e testi in diverse lingue della collezione corpora di Lipsia. Forniamo anche i risultati di un esperimento di identificazione linguistica di base condotto utilizzando il set di dati ULI 2020.', 'kk': 'Бұл мақала 2017 жылы Уралик тіл идентификациясының (ULI) 2020 ортақ тапсырманың сынақтарында жазылған сөздер үшін Wanca веб корпорасын таңдайды. Біз ULI ортақтастырған тапсырманы және 2017 жылы Wanca корпорасы мен мәтіндерді басқа тілдерде Лейпциг корпорасының жинағынан қалай құрылғанын анықтадық. Сонымен қатар, ULI 2020 деректер жиынын қолдану үшін негізгі тілді идентификациялау тәжірибесінің нәтижесін береміз.', 'lt': 'Šiame straipsnyje įvedama Wanca 2017 interneto korpora, iš kurios buvo surinkti nedidelėmis uraliniomis kalbomis įrašyti sakiniai bendrai Uralinės kalbos identifikavimo (ULI) 2020 užduoties bandymui atlikti. Mes apibūdiname ULI bendrą užduotį ir kaip bandymų rinkinys buvo sukurtas naudojant Wanca 2017 korprą ir tekstus skirtingomis kalbomis nei Leipcigo korprų rinkinys. Taip pat pateikiame pradinio kalbų identifikavimo eksperimento, atlikto naudojant VRI 2020 duomenų rinkinį, rezultatus.', 'mk': 'This article introduces the Wanca 2017 web corpora from which the sentences written in minor Uralic languages were collected for the test set of the Uralic Language Identification (ULI) 2020 shared task.  Ја опишуваме заедничката задача на УЛИ и како тестот беше изграден користејќи го копилот Ванка 2017 и текстот на различни јазици од колекцијата на лејпциг копилот. Ние, исто така, ги обезбедуваме резултатите од основниот експеримент за идентификација на јазикот спроведен со користење на податоците УЛИ 2020.', 'ms': 'Artikel ini memperkenalkan korpra web Wanca 2017 dari mana kalimat tertulis dalam bahasa Ural kecil dikumpulkan untuk set ujian tugas kongsi Identifikasi Bahasa Ural (ULI) 2020. We describe the ULI shared task and how the test set was constructed using the Wanca 2017 corpora and texts in different languages from the Leipzig corpora collection.  We also provide the results of a baseline language identification experiment conducted using the ULI 2020 dataset.', 'mt': 'This article introduces the Wanca 2017 web corpora from which the sentences written in minor Uralic languages were collected for the test set of the Uralic Language Identification (ULI) 2020 shared task.  Aħna niddeskrivu l-kompitu kondiviż tal-ULI u kif ġie mibni s-sett tat-test bl-użu tal-korpora Wanca 2017 u t-testi f’lingwi differenti mill-ġbir korpora ta’ Leipzig. Aħna nipprovdu wkoll ir-riżultati ta’ esperiment ta’ identifikazzjoni tal-lingwa fil-linja bażi mwettaq bl-użu tad-dejta tal-ULI 2020.', 'mn': 'Энэ баримт 2017 оны Уралик хэл дээр бичигдсэн үгнэлүүдийг Уралик хэлний идентификацийн (ULI) 2020 хуваалтын шалгалтын шалгалтын төлөө цуглуулсан Ванка веб корпора руу илэрхийлж байна. Бид ULI хуваалцах ажлыг, 2017 оны Ванка Корпора болон Лейпцигийн корпора цуглуулалтын өөр хэл дээр хэрхэн бий болсон талаар тайлбарлаж байна. Бид мөн ULI 2020 өгөгдлийн санг ашиглан суурь шугам хэлний идентификацийн туршилтын үр дүнг өгдөг.', 'pl': 'Niniejszy artykuł przedstawia korpusy internetowe Wanca 2017, z których zebrano zdania napisane w mniejszych językach uralskich dla zestawu testowego wspólnego zadania Urlic Language Identification (ULI) 2020. Opisujemy wspólne zadanie ULI i jak zbudowano zestaw testowy z wykorzystaniem korpusów Wanca 2017 oraz tekstów w różnych językach z kolekcji korpusów lipskich. Przedstawiamy również wyniki podstawowego eksperymentu identyfikacji języka przeprowadzonego przy użyciu zbioru danych ULI 2020.', 'ml': 'ഈ ലേഖനം വാങ്കാ 2017 വെബ് കോര്\u200dപ്പോരിയെ പരീക്ഷിക്കുന്നു. അവയില്\u200d നിന്ന് ചെറിയ ഉറാലിക് ഭാഷകളില്\u200d എഴുതിയ വാക്കുകള്\u200d ശേഖരിച്ചിരിക്കുന്നു. യ യുഐ പങ്കെടുത്ത ജോലിയെക്കുറിച്ച് ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു യുലി 2020 ഡാറ്റാസസെറ്റ് ഉപയോഗിച്ച് നടത്തിയ ഒരു ബെസ്ലൈന്\u200d ഭാഷ തിരിച്ചറിയാനുള്ള പരീക്ഷണത്തിന്റെ ഫലങ്ങളും', 'no': 'Denne artikkelen introduserer Wanca 2017 nettkorporen som setningane skrevene i mindre Uraliske språk vart samla for testsettet av den delte oppgåva for Uralic Language Identification (ULI) 2020. Vi beskriver ULI-delt oppgåve og korleis testsettet ble konstruert med korpora og tekstar i Wanca 2017 i ulike språk frå Leipzig-korporsamlinga. Vi tilbyr også resultatet av ein basespråk-identifiseringseksperiment gjennomført med datasettet ULI 2020.', 'ro': 'Acest articol prezintă corpora web Wanca 2017 din care au fost colectate propozițiile scrise în limbi Uralice minore pentru setul de test al misiunii comune de Identificare a Limbii Uralice (ULI) 2020. Descriem sarcina comună ULI și modul în care setul de testare a fost construit folosind corpurile Wanca 2017 și textele în diferite limbi din colecția de corpore Leipzig. De asemenea, furnizăm rezultatele unui experiment de identificare a limbii de bază efectuat folosind setul de date ULI 2020.', 'sr': 'Ovaj članak predstavlja web korporaciju Wanca 2017 iz kojih su prikupljene rečenice napisane na malom Uraličkom jeziku za test seta zajedničkog zadatka Uraličke identifikacije jezika (ULI) 2020. Opišemo zajednički zadatak ULI-a i kako je test postavljen korporacijom Wanca 2017 i tekstima na različitim jezicima iz kolekcije korporacije Leipziga. Takođe pružamo rezultate eksperimenta identifikacije jezika iz početne linije provedenog korištenjem seta podataka ULI 2020.', 'so': 'Maktabadan wuxuu ka soo bandhigaa shirkadda Vanca 2017 oo laga soo qoray erayada lagu qoray luuqadaha yaryar ee Uralika oo laga soo ururiyey si loo sameeyo imtixaanka aqoonsiga luqada Uralika (ULI) 2020 oo loo qeybeeyey. Waxaannu u qoraynaa shaqada ULI ee loo qaybsaday iyo sida loo dhisay imtixaanka oo lagu isticmaalay shirkadaha Wanca 2017 iyo qoraalka luuqadaha kala duduwan ee shirkadda Leipzig. Waxaan sidoo kale siinaynaa arimaha imtixaanka aqoonsiga luqada aasaasiga ah ee lagu sameeyay isticmaalka sawirka macluumaadka ULI 2020.', 'sv': 'Denna artikel introducerar Wanca 2017 webbkorpora från vilka meningarna skrivna på mindre uraliska språk samlades in för testuppsättningen av Ural Language Identification (ULI) 2020 delade uppgift. Vi beskriver ULI:s gemensamma uppgift och hur testuppsättningen konstruerades med Wanca 2017 korpora och texter på olika språk från Leipzig korporasamling. Vi tillhandahåller också resultaten av ett experiment med språkidentifiering som utförts med hjälp av datauppsättningen ULI 2020.', 'ta': '@ info @ info ULI 2020 தகவல் அமைப்பை பயன்படுத்தி செயல்படுத்தப்பட்ட மொழி அடையாளம் சோதனையின் முடிவுகளை நாம் வழங்குகிறோம்.', 'si': 'මේ ලේඛනය වැන්කා 2017 වෙබ් කොර්පෝරාව පෙනුම් කරනවා කියලා පොඩි Uralc භාෂාවට ලියපු වාක්තුවල් සංවේදනය සඳහා යුරාලික් භාෂාව අ අපි ලෙයිප්සිග් කොර්පෝරා සංගීතයෙන් වෙනස් භාෂාවක් වලින් විවිධ භාෂාවක් වලින් පරීක්ෂා සූදානය විදිහට හ අපි අධාරණ භාෂාව පරීක්ෂණයක් පරීක්ෂණය කරන්න පුළුවන් පරීක්ෂණයක් තියෙන්නේ.', 'ur': 'یہ لکھ وانکا ۲۰۱۷ ویب کورپورا کو معرفی کرتا ہے جس سے چھوٹی اورالیک زبانوں میں لکھی ہوئی جماعت Uralic Language Identification (ULI) 2020 کے شریک کار کے لئے جمع کیے گئے ہیں. ہم نے ULI شریک کام کی توصیف کرتی ہے اور جس طرح آزمائش سٹ کی گئی تھی وونکا 2017 کی کورپورا اور پیغام کے مطابق مختلف زبانوں میں Leipzig کورپورا کالکور سے لکھی گئی تھی۔ ہم نے بھی ایک بنیاس لین زبان شناسایی آزمائش کا نتیجہ ادا کیا ہے جو ULI 2020 ڈیٹ سٹ کے مطابق کیا گیا ہے.', 'uz': "Bu maqola Wanca 2017 veb- kompaniyasini ishlatiladi. Bu yerda kichkina Uralik tillarida qoʻllangan so'zlar 2020 bilan birlashtirilgan vazifa (ULI) tizimini sinash uchun qoʻllangan. Biz ULI bilan birlashtirilgan vazifani aytib beramiz va sinov tuzilishini Leipzig kompaniya toʻplamdagi boshqa tillarda va matnlar yordamida qanday yaratiladi. Bu yerda ULI 2020 maʼlumotlar satri yordamida ishga tushirilgan asosiy tilning identification imtiyozlarini beramiz.", 'vi': 'This article giới thiệu the Wanca Thậm chí Ghi sĩ Mạng từ đó câu đã được phát hành bằng tiểu ngôn ngữ Uralic để xem thử nhóm phát minh ngôn ngữ Uralic. Chúng tôi mô tả công việc chung LOL và cách bộ thử nghiệm được xây dựng bằng thông tin đạo lý Wanca và văn bản tại các ngôn ngữ khác nhau từ bộ sưu tập thể xác Leizig. Chúng tôi cung cấp kết quả của thí nghiệm nhận dạng ngôn ngữ cơ bản tiến hành bằng bộ dữ liệu USL 2020.', 'nl': "Dit artikel introduceert het Wanca 2017 web corpora waaruit de zinnen geschreven in kleine Uralische talen werden verzameld voor de testset van de Uralic Language Identification (ULI) 2020 gedeelde taak. We beschrijven de gedeelde taak van ULI en hoe de testset is opgebouwd met behulp van de Wanca 2017 corpora's en teksten in verschillende talen uit de Leipzig corpora collectie. We bieden ook de resultaten van een basistaal identificatie experiment uitgevoerd met behulp van de ULI 2020 dataset.", 'da': "Denne artikel introducerer Wanca 2017 web corpora, hvorfra sætningerne skrevet på mindre Uralske sprog blev indsamlet til testsættet af Uralsk Language Identification (ULI) 2020 delte opgave. Vi beskriver ULI's delte opgave og hvordan testsættet blev konstrueret ved hjælp af Wanca 2017-korpora og tekster på forskellige sprog fra Leipzig-korpora-samlingen. Vi leverer også resultaterne af et baseline sprogidentifikationsforsøg udført ved hjælp af ULI 2020 datasættet.", 'bg': 'Тази статия представя уеб корпусите на Уанка 2017, от които са събрани изреченията, написани на маловажни уралски езици, за теста на споделената задача за уралска идентификация 2020. Описваме споделената задача и как е изграден тестовият комплект, използвайки корпоративните и текстовете на различни езици от колекцията корпоративни корпоративни корпоративни колекции в Лайпциг. Предоставяме и резултатите от експеримент за идентифициране на базовия език, проведен с помощта на набора от данни УЛИ 2020.', 'hr': 'Ovaj članak predstavlja internetsku korporaciju Wanca 2017 iz kojeg su prikupljene rečenice napisane na malom Uraličkom jeziku za test seta zajedničkog zadatka Uraličke identifikacije jezika (ULI) 2020. Opišemo zajednički zadatak ULI-a i kako je test set izgrađen koristeći korporu i tekstove Wanca 2017 na različitim jezicima iz kolekcije korporacije Leipziga. Također pružamo rezultate ispitivanja identifikacije jezika iz početne linije provedenog korištenjem niza podataka ULI 2020.', 'ko': '본고는 Wanca 2017 인터넷 어료 라이브러리를 소개했는데 그 중에서 우랄어 차요언어의 문장을 수집하여 우랄어 식별(ULI) 2020 공유 임무에 사용되는 테스트 집합이다.우리는 ULI 공유 작업과 Wanca 2017 자료 라이브러리와 라이비시 자료 라이브러리에서 서로 다른 언어의 텍스트 구축 테스트 집합을 어떻게 사용하는지 설명했다.ULI2020 데이터 세트를 사용한 베이스라인 언어 식별 실험의 결과도 제공합니다.', 'fa': 'این مقاله، شرکت وب وانکا ۲۰۰۷ را معرفی می\u200cکند که جمله\u200cهای نوشته شده در زبان\u200cهای Uralic کوچک برای امتحان مجموعه شناسایی زبان Uralic (ULI) ۲۰۰۲ کار مشترک جمع می\u200cشوند. ما کار مشترک ULI را توصیف می\u200cکنیم و چگونه مجموعه آزمایش با استفاده از شرکت وانکا ۲۰۱۷ ساخته شده است و متن\u200cها در زبان\u200cهای مختلف از جمله شرکت لیپزیگ. ما همچنین نتیجه\u200cهای یک آزمایش شناسایی زبان\u200cهای بنیادی را با استفاده از مجموعه داده\u200cهای ULI 2020 ارائه می\u200cدهیم.', 'de': 'Dieser Artikel stellt die Wanca 2017 Web-Korpora vor, aus denen die Sätze, die in kleineren uralischen Sprachen geschrieben wurden, für den Testsatz der gemeinsamen Aufgabe Uralic Language Identification (ULI) 2020 gesammelt wurden. Wir beschreiben die gemeinsame Aufgabe des ULI und wie das Testset mit den Wanca 2017 Korpora und Texten in verschiedenen Sprachen aus der Leipziger Korpora-Sammlung aufgebaut wurde. Wir liefern auch die Ergebnisse eines Basisexperiments zur Sprachidentifikation, das mit dem ULI 2020 Datensatz durchgeführt wurde.', 'id': 'Artikel ini memperkenalkan korpra web Wanca 2017 dari mana kalimat tertulis dalam bahasa Ural kecil dikumpulkan untuk set tes dari tugas bersama Identifikasi Bahasa Ural (ULI) 2020. We describe the ULI shared task and how the test set was constructed using the Wanca 2017 corpora and texts in different languages from the Leipzig corpora collection.  Kami juga memberikan hasil dari percobaan identifikasi bahasa dasar yang dilakukan menggunakan set data ULI 2020.', 'tr': 'Bu makala 2017-nji ýylda Uralik dilinde ýazylan sözleriň Uralik dil kimligi (ULI) 2020-nji bölegi üçin jemgylanan web korporatyny çykarýar. Biz ULI paýlaşyp barýan zadyny we testiň 2017-nji ýyldaky Wanca korporatynyň we tekstlerini Leipzig korporatyň düzümlerinden nähili guruldygyny tassyýarlapdyk. Biz hem ULI 2020 veri setirini ulanyp çykan çyzgylyň esasy çyzgylygynyň netijesini bererik.', 'af': "Hierdie artikel introduseer die Wanca 2017 web korpora waarvan die setings geskrywe in klein Uralike tale versamel word vir die toets stel van die Uralike Taal Identifikasie (ULI) 2020 deel taak. Ons beskryf die ULI gedeelde taak en hoe die toets stel gebruik is deur die Wanca 2017 korpora en tekste in verskillende tale van die Leipzig korporasversameling. Ons verskaf ook die resultate van 'n basis taal identifikasie eksperiment wat deur die ULI 2020 datastel gedoen is.", 'sq': 'Ky artikull paraqet korprën e internetit Wanca 2017 nga e cila u mblodhën fjalët e shkruara në gjuhët e vogla urale për grupin e testit të detyrës së përbashkët të Identifikimit të Gjuhave Urale (ULI) 2020. Ne e përshkruajmë detyrën e përbashkët të ULI dhe se si u ndërtua kompleti i testit duke përdorur korprën Wanca 2017 dhe tekstet në gjuhë të ndryshme nga koleksioni i korprës Leipzig. Ne ofrojmë gjithashtu rezultatet e një eksperimenti bazë identifikimi gjuhës kryer duke përdorur dataset ULI 2020.', 'am': 'ይህ ጽሑፍ በዩራሊክ ቋንቋዎች የተጻፈውን የዌብ ኮርፖርት ያሳየዋል፡፡ We describe the ULI shared task and how the test set was constructed using the Wanca 2017 corpora and texts in different languages from the Leipzig corpora collection.  በULI 2020 ዳታ ሰርቨር የተደረገውን የቋንቋ identification ፈተና እናደርጋለን፡፡', 'hy': 'Այս հոդվածը ներկայացնում է Վանկա 2017-ի վեբ-կոպորան, որից հավաքվել են փոքր ուրալիկ լեզուներով գրված նախադասությունները 2020-ի փորձարկումների համար: Մենք նկարագրում ենք ԱՄՆ-ի ընդհանուր խնդիրը և թե ինչպես է փորձարկումները կառուցվել օգտագործելով 2017 թվականի Ուանկա կոպորան և հաղորդագրությունները Լեյփսիգ կոպորային հավաքածուց տարբեր լեզուներով: Մենք նաև տրամադրում ենք հիմնական լեզվի հայտնաբերման փորձի արդյունքները, որոնք կատարվել են օգտագործելով ԱՄՆ 2020 տվյալների համակարգը:', 'az': 'Bu məktub 2017-ci Wanca web korporasını təşkil edir ki, küçük Uralic dillərdə yazılmış cümlələr Uralic Dil Identification (ULI) 2020 paylaşılan işin sınaması üçün toplanıldı. Biz ULI paylaşdığı işləri və sınama setini 2017-ci ilə Wanca korpora və məktubları Leipzig korpora koleksiyonundan müxtəlif dillərdə təşkil edirik. Biz həmçinin ULI 2020 veri qutusu vasitəsilə işlədilən ilk dil kimliğinin sonuçlarını da təmin edirik.', 'sw': 'Makala hii inaonyesha kampuni ya wavuti ya Wanca 2017 ambayo hukumu zilizoandikwa katika lugha ndogo ya Urali zilikusanywa kwa ajili ya mtihani wa kutambua Lugha ya Kiurali (ULI) 2020 zilizosambazwa. Tunaelezea jukumu la ULI lililoshirikishwa na jinsi mjadala wa jaribio lilivyojengwa kwa kutumia kampuni ya Wanca 2017 na ujumbe katika lugha tofauti kutoka kwenye mkusanyiko wa kampuni ya Leipzig. Pia tunatoa matokeo ya jaribio la utambulisho wa lugha za msingi lililofanywa kwa kutumia seti ya data ya ULI 2020.', 'bn': 'এই প্রবন্ধটি ওয়াঙ্কা ২০১৭ সালের ওয়েব কোর্পোরাকে উপস্থাপন করেছে যেখান থেকে সামান্য উরালিক ভাষায় লেখা হয়েছে উরালিক ভাষার পরীক্ষার জন্য বাক্ আমরা ইউআই শেয়ার কর্মসূচি বর্ণনা করি এবং কিভাবে পরীক্ষার সেট নির্মাণ করা হয়েছে ওয়াঙ্কা ২০১৭ সালের কোর্পোরা এবং লেইপ্জিগ কর্পোরা সংগ ইউলি ২০২০০ ডাটাসেট ব্যবহার করে অনুষ্ঠিত একটি বেসেলাইন ভাষার পরিচয় পরীক্ষার ফলাফল আমরা প্রদান করি।', 'cs': 'Tento článek představuje webové korpusy Wanca 2017, ze kterých byly shromážděny věty psané v menších uralských jazycích pro testovací sadu sdíleného úkolu Uralské jazykové identifikace (ULI) 2020. Popisujeme sdílený úkol ULI a jak byla zkušební sada konstruována pomocí korpusů Wanca 2017 a textů v různých jazycích ze sbírky lipských korpusů. Dále poskytujeme výsledky základního jazykového identifikačního experimentu provedeného pomocí datové sady ULI 2020.', 'bs': 'Ovaj članak predstavlja web korporaciju Wanca 2017 iz kojeg su prikupljene rečenice napisane na malom Uraličkom jeziku za test seta zajedničkog zadatka Uraličke identifikacije jezika (ULI) 2020. Opišemo zajednički zadatak ULI-a i kako je test set izgrađen koristeći korporu i tekstove Wanca 2017 na različitim jezicima iz kolekcije korporacije Leipziga. Također pružamo rezultate eksperimenta identifikacije jezika iz početne linije provedenog korištenjem seta podataka ULI 2020.', 'ca': "Aquest article introdueix la web corpora Wanca 2017 de la qual es van recollir frases escrites en llengües uraníques minors per a la tasca compartida d'identificació de llengües uraníques (ULI) 2020. Descrivem la tasca compartida de l'ULI i com es va construir el conjunt d'exàmens fent servir el corpora Wanca 2017 i els textos en diferents llengües de la col·lecció corpora de Leipzig. També proporcionem els resultats d'un experiment de identificació de llenguatges basal fet utilitzant el conjunt de dades ULI 2020.", 'et': 'Käesolevas artiklis tutvustatakse Wanca 2017 veebikorporeid, millest koguti uurali keele identifitseerimise (ULI) 2020 jagatud ülesande testimiseks vähemkeeltes kirjutatud laused. Kirjeldame ULI jagatud ülesannet ja seda, kuidas testikomplekt ehitati, kasutades Wanca 2017 korpuseid ja tekste erinevates keeltes Leipzigi korpuste kollektsioonist. Samuti esitame ULI 2020 andmekogumi abil läbi viidud algkeele identifitseerimise eksperimendi tulemused.', 'fi': 'Tässä artikkelissa esitellään Wanca 2017 -verkkokorpusia, joista on kerätty uraalin sivukielillä kirjoitetut lauseet uralin kielen tunnistus (ULI) 2020 -yhteisen tehtävän testisarjaa varten. Kuvaamme ULI:n yhteistä tehtävää ja miten testisarja rakennettiin käyttäen Wanca 2017 -korpusia ja -tekstejä Leipzigin korpuskokoelmasta eri kielillä. Toimitamme myös tulokset ULI 2020 -aineiston avulla toteutetusta peruskielen tunnistuskokeesta.', 'jv': 'Artik iki ngewehke Wanca 2020 web bodha mengko perusahaan urip nang langa Uralic sing berarti kanggo ngetik nggawe ujian winih Awak dhéwé ngerti nggambar LTI nggawe bener tentang karo ngono hal-hal ujian sing nggawe nguwe Wanca 1997 ora bisa kelas lan seneng nggawe barang-barang kanggo sampek bantuan karo Caipcig Awak dhéwé mulai nggawe barang pancen kanggo ngilanggar urip sisan ingkang éntuk gambar nggawe dataset UlI 2020', 'sk': 'Ta članek predstavlja spletne korpuse Wanca 2017, iz katerih so bili zbrani stavki, napisani v manjših uralskih jezikih, za testiranje skupne naloge uralske identifikacije (ULI) 2020. Opisujemo skupno nalogo ULI in kako je bil testni komplet sestavljen z uporabo korpusov Wanca 2017 in besedil v različnih jezikih iz Leipzigske zbirke korpusov. Predstavljamo tudi rezultate izhodiščnega eksperimenta identifikacije jezika, ki je bil izveden z uporabo nabora podatkov ULI 2020.', 'ha': 'Wannan makala na introduce the Wanca 2017 web Companiya wanda aka samu mummunan cikin harshen ƙarami na Uraliki zuwa jarrabi tsarin shaidar Lugha na Uralic (ULI) 2020 da aka raba shi. Tuna bayyana shirin ULI da aka raba shi kuma yadda aka gina jarrabi a wajen su yi amfani da Wanca 2017 koropa da littattafai cikin harshen daban-daban na Leipzig. Mu ƙarfafa da matsala na jarrabar shaidar lugha baka-layin da aka yi amfani da tsarin maɓallin ULI 2020.', 'bo': 'སྒྲུང་བརྗོད་ཐོག་འདིས་ Wanca 2017་ཡིག་གི་ཝེབ་ཀྱི་སྒེར་གྱི་ནང་དུ་ཚིག་རྐང་ཆ་ཆུང་ཀུ་Uralic Language Identification (ULI) 2020་ཡི་ལས་འཆར་བརྟག་ཞིབ་བྱས་པ་རེད། ང་ཚོས་ULI ཡི་ལས་ཀ་བཤད་པ་དང་བརྟག་ཞིབ་ཀྱི་སྒྲིག ང་ཚོས་ULI 2020་སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་ལེན་པའི་རྨང་གཞིའི་སྐད་བརྟག', 'he': 'המאמר הזה מציג את גופורה האינטרנט של וואנקה 2017, ממנה נאספו המשפטים שנכתבים בשפות אוראליות קטנות עבור קבוצת הבדיקה של זיהוי השפה האוראלית (ULI) 2020 משימה משותפת. אנחנו מתארים את המשימה המשותפת של ULI ואיך התערוכת הבדיקות נבנתה באמצעות הקופורה של וואנקה 2017 והטקסטים בשפות שונות מאסף הקופורה של ליפציג. We also provide the results of a baseline language identification experiment conducted using the ULI 2020 dataset.'}
{'en': 'HeLju@VarDial 2020 : Social Media Variety Geolocation with BERT Models', 'ar': 'HeLju @ VarDial 2020: تحديد الموقع الجغرافي لمجموعة متنوعة من وسائل التواصل الاجتماعي مع نماذج BERT', 'fr': 'HelJu @VarDial 2020\xa0: géolocalisation de variétés sur les réseaux sociaux avec les modèles BERT', 'pt': 'HeLju@VarDial 2020: Geolocalização de variedade de mídia social com modelos BERT', 'es': 'HelJu @VarDial 2020: Geolocalización de variedades de redes sociales con modelos BERT', 'ja': 'HeLju @ VarDial 2020 ： BERTモデルによるソーシャルメディアバラエティジオロケーション', 'zh': '2020 HeLju@VarDial:BERT社交媒体多样性定位', 'hi': 'HeLju@VarDial 2020: BERT मॉडल के साथ सोशल मीडिया वैरायटी जियोलोकेशन', 'ru': 'HeLju@VarDial 2020: Разнообразие социальных сетей Геолокация с моделями BERT', 'ga': 'HeLju@VarDial 2020: Geoshuíomh Éagsúlachta na Meán Sóisialta le Múnlaí BERT', 'ka': 'HeLju@VarDial 2020: სოციალური მედია განსხვავებების геოლოგიაცია BERT მოდელებით', 'hu': 'HeLju@VarDial 2020: A közösségi média változatosságának geolokációja BERT modellekkel', 'el': 'HeLju@VarDial 2020: Γεωεντοπισμός ποικίλων μέσων κοινωνικής δικτύωσης με μοντέλα BERT', 'it': 'HeLju@VarDial 2020: Geolocalizzazione delle varietà dei social media con i modelli BERT', 'lt': 'HeLju@VarDial 2020 m. Socialinės žiniasklaidos įvairovės geografinė padėtis su BERT modeliais', 'mk': 'HeLju@VarDial 2020: Геолокација на различните социјални медиуми со BERT модели', 'kk': 'HeLju@VarDial 2020: BERT үлгілерімен социалдық медиа айнымалылығының географиясы', 'ms': 'HeLju@VarDial - 2020: Geolokasi Variasi Media Sosial dengan Model BERT', 'mt': 'HeLju@VarDial  2020: Social Media Variety Geolocation with BERT Models', 'ml': 'HeLju@VarDial 2020: BERT മോഡലുകളോടൊപ്പം സോഷ്യല്\u200d മീഡിയ വേറിറിറ്റി ജൂലോക്ഷന്\u200d', 'mn': 'HeLju@VarDial 2020: Нийгмийн мэдээллийн олон төрлийн газрын байрлал BERT загвартай', 'pl': 'HeLju@VarDial 2020: Geolokalizacja różnorodności w mediach społecznościowych z modelami BERT', 'no': 'HeLju@VarDial 2020: Geoplassering av sosiale mediavariasjonar med BERT-modeller', 'sr': 'HeLju@VarDial 2020: Geolokacija socijalne medijske varijante sa BERT modelima', 'si': 'HeLju@VarDial 2020යි: සාමාජික මාධ්\u200dයමය වෙනස් භූතික තැනය BERT මොඩල් එක්ක', 'so': 'HeLju@VarDial 2020: Society Variety Geolocation with BERT Models', 'sv': 'HeLju@VarDial 2020: Geolokalisering av olika sociala medier med BERT-modeller', 'ta': 'HeLju@VarDial 2020: பெர்டி மாதிரிகளுடன் சமூக ஊடக மாறிகள்', 'ur': 'HeLju@VarDial 2020: BERT Models کے ساتھ سوسیل میڈیا ویریٹی جئوٹ', 'ro': 'HeLju@VarDial 2020: Geolocalizarea varietăților rețelelor de socializare cu modele BERT', 'uz': 'HeLju@VarDial 2020: BERT modellari bilan jamiyat media kuchi', 'vi': 'HeLju@VarDial 2071: địa hình giao thông xã hội với mẫu giao thông,', 'da': 'HeLju@VarDial 2020: Geoplacering af varierede sociale medier med BERT-modeller', 'hr': 'HeLju@VarDial 2020. godine: Geolokacija socijalnih medija s BERT modelima', 'nl': 'HeLju@VarDial 2020: Social Media Variety Geolocatie met BERT Modellen', 'bg': 'HeLju@VarDial 2020: Геолокация на разнообразието в социалните медии с модели', 'de': 'HeLju@VarDial 2020: Social Media Variety Geolocation mit BERT Modellen', 'id': 'HeLju@VarDial 2020: Geolokasi Variasi Media Sosial dengan Model BERT', 'ko': 'HeLju@VarDial2020년: 소셜 미디어의 다양성 지리적 포지셔닝과 베르토 모델', 'fa': 'HeLju@VarDial ۲۰۰۲: موقعیت گوناگونی رسانه اجتماعی با مدل BERT', 'tr': 'HeLju@VarDial 2020', 'af': 'HeLju@VarDial 2020: Soziale Media Veranderlike Geoligging met BERT Modelle', 'sw': 'HeLju@VarDial 2020: Utamaduni wa Vyombo vya Habari vya kijamii na Modeli za BERT', 'sq': 'HeLju@VarDial 2020: Gjeolokimi i Varietit të Mediave Shoqërore me Modelet BERT', 'am': 'HeLju@VarDial 2020: ማኅበራዊ ሚዲያ ሚዲያዎች በBERT ሞዴል የተደረጉ', 'hy': 'HeLju@VarDial 2020: Սոցիալական լրատվամիջոցների բազմազանությունը BER մոդելների հետ', 'bs': 'HeLju@VarDial 2020. Geolokacija socijalnih medija s modelima BERT', 'cs': 'HeLju@VarDial 2020: Geolokace rozmanitosti sociálních médií s modely BERT', 'az': 'HeLju@VarDial 2020: BERT modell…ôri il…ô sosyal media d…ôyiŇüiklik Geolokasyonu', 'bn': 'HeLju@VarDial ২০২০০: বেরেট মোডেলের সাথে সামাজিক মিডিয়া ভেরিটি গুলোকেশন', 'et': 'HeLju@VarDial 2020: Sotsiaalmeedia mitmekesisuse geolokatsioon BERT mudelitega', 'ca': 'HeLju@VarDial 2020: Geolocalització de varietats de mitjans socials amb models BERT', 'fi': 'HeLju@VarDial 2020: Social Media Variety Geolocation with BERT Models', 'ha': 'HeLju@VarDial 2020: Geolocation with BERT Models', 'sk': 'HeLju@VarDial 2020: Geolokacija raznolikosti družbenih medijev z BERT modeli', 'he': 'HeLju@VarDial 2020: גיאומייקציה של שונים מדיה חברתית עם דוגמנים BERT', 'jv': 'HeLju@VarDial 2020: Digital Media Variance Digital location with BERT model', 'bo': 'HeLju@VarDial སྤྱི་ཚོགས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྟངས་ལ་གནས་ཡུལ་འདུག་ BERT རྣམ་གྲངས་དང་'}
{'en': 'This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation. Our solutions are based on the BERT Transformer models, the constrained versions of our ', 'ar': 'تصف هذه الورقة مساهمة هلسنكي- ليوبليانا في مهمة VarDial المشتركة على تحديد الموقع الجغرافي لمجموعة متنوعة من وسائل التواصل الاجتماعي. تعتمد حلولنا على نماذج BERT Transformer ، حيث تصل الإصدارات المقيدة من نماذجنا إلى المركز الأول في مهمتين فرعيتين والمركز الثالث في مهمة فرعية واحدة ، بينما تتفوق نماذجنا غير المقيدة على جميع الأنظمة المقيدة بهامش كبير. نوضح في تحليلاتنا أن النماذج المستندة إلى Transformer تفوق أداء النماذج التقليدية إلى حد بعيد ، وأن التحسينات التي تم الحصول عليها من خلال نماذج التدريب المسبق على كميات كبيرة من النص (القياسي في الغالب) مهمة ، ولكنها ليست جذرية ، مع تفوق النماذج أحادية اللغة أيضًا على النماذج متعددة اللغات . يُظهر تحليلنا اليدوي أن نوعين من الإشارات هما الأكثر أهمية للتنبؤ (الخاطئ): الكيانات المسماة والميزات اللهجة ، وكلاهما يتم التعامل معه بشكل جيد بواسطة نماذجنا.', 'pt': 'Este artigo descreve a contribuição de Helsinki-Ljubljana para a tarefa compartilhada VarDial na geolocalização de variedade de mídia social. Nossas soluções são baseadas nos modelos BERT Transformer, as versões restritas de nossos modelos alcançando o 1º lugar em duas subtarefas e o 3º lugar em uma subtarefa, enquanto nossos modelos irrestritos superam todos os sistemas restritos por uma grande margem. Mostramos em nossas análises que os modelos baseados em Transformer superam de longe os modelos tradicionais, e que as melhorias obtidas por modelos de pré-treinamento em grandes quantidades de texto (principalmente padrão) são significativas, mas não drásticas, com modelos de idioma único também superando os modelos multilíngues . Nossa análise manual mostra que dois tipos de sinais são os mais cruciais para uma (má) previsão: entidades nomeadas e características dialetais, ambas bem tratadas por nossos modelos.', 'es': 'Este artículo describe la contribución de Helsinki-Ljubljana a la tarea compartida de VarDial sobre la geolocalización de variedades de redes sociales. Nuestras soluciones se basan en los modelos de transformadores BERT, las versiones restringidas de nuestros modelos alcanzan el primer lugar en dos subtareas y el tercer lugar en una subtarea, mientras que nuestros modelos sin restricciones superan a todos los sistemas restringidos por un amplio margen. En nuestros análisis demostramos que los modelos basados en Transformer superan con creces a los modelos tradicionales, y que las mejoras obtenidas por los modelos de preentrenamiento en grandes cantidades de texto (en su mayoría estándar) son significativas, pero no drásticas, y que los modelos de un solo idioma también superan a los modelos multilingües. Nuestro análisis manual muestra que dos tipos de señales son los más cruciales para una (mala) predicción: las entidades nombradas y las características dialectales, ambas manejadas bien por nuestros modelos.', 'fr': "Cet article décrit la contribution d'Helsinki-Ljubljana à la tâche partagée VarDial sur la géolocalisation des variétés sur les réseaux sociaux. Nos solutions sont basées sur les modèles de transformateurs BERT, les versions contraintes de nos modèles atteignant la première place dans deux sous-tâches et la troisième place dans une sous-tâche, tandis que nos modèles sans contrainte surpassent largement tous les systèmes soumis à des contraintes. Nous montrons dans nos analyses que les modèles basés sur Transformer surpassent de loin les modèles traditionnels, et que les améliorations obtenues par les modèles de pré-formation sur de grandes quantités de texte (principalement standard) sont significatives, mais pas drastiques, les modèles unilingues surpassant également les modèles multilingues. Notre analyse manuelle montre que deux types de signaux sont les plus importants pour une (mauvaise) prédiction\xa0: les entités nommées et les caractéristiques dialectales, qui sont toutes deux bien gérées par nos modèles.", 'ja': 'この論文では、ソーシャルメディアの多様な地理的位置に関するVarDial共有タスクへのヘルシンキ-リュブリャナの貢献について説明します。当社のソリューションは、BERTトランスフォーマーモデルに基づいており、2つのサブタスクで1位、1つのサブタスクで3位に達する当社のモデルの制約バージョンは、制約のないモデルは、すべての制約のあるシステムを大幅に上回っています。私たちの分析では、Transformerベースのモデルは、従来のモデルを遥かに上回っており、大量の（主に標準的な）テキストでモデルを事前トレーニングすることによって得られる改善は、単一言語のモデルが多言語のモデルを上回っているため、有意であるが、劇的ではないことが示されています。私たちの手動分析は、2つのタイプの信号が（誤った）予測に最も重要であることを示しています：名前付きエンティティと方言の特徴、どちらも私たちのモデルによって適切に処理されています。', 'zh': '本文述赫尔辛基 - 卢布尔雅VarDial于社交媒体多样性地理定位之献。 吾解决方案基于BERT Transformer,吾道在二,在一在三,在一在三,在性则远过。 故Transformer者,远优于旧,而多(大体)文本预练,而不激切,单言多言。 吾手动分析表明,二者之于(非)占之至要:命之以言,形之以善。', 'hi': 'यह पेपर हेलसिंकी-जुब्लजाना के योगदान का वर्णन करता है जो सोशल मीडिया विविधता जियोलोकेशन पर VarDial साझा कार्य में योगदान करता है। हमारे समाधान BERT ट्रांसफॉर्मर मॉडल पर आधारित हैं, हमारे मॉडल के विवश संस्करण दो subtasks में 1 स्थान पर पहुंचने और एक subtask में 3 स्थान पर पहुंचते हैं, जबकि हमारे अप्रतिबंधित मॉडल एक बड़े मार्जिन से सभी विवश प्रणालियों को मात देते हैं। हम अपने विश्लेषणों में दिखाते हैं कि ट्रांसफॉर्मर-आधारित मॉडल अब तक पारंपरिक मॉडल से आगे निकलते हैं, और यह कि बड़ी मात्रा में (ज्यादातर मानक) पाठ पर पूर्व-प्रशिक्षण मॉडल द्वारा प्राप्त सुधार महत्वपूर्ण हैं, लेकिन कठोर नहीं हैं, एकल-भाषा मॉडल भी बहुभाषी मॉडल से आगे निकलते हैं। हमारे मैनुअल विश्लेषण से पता चलता है कि दो प्रकार के संकेत एक (गलत) भविष्यवाणी के लिए सबसे महत्वपूर्ण हैं: नामित संस्थाएं और बोलचाल की विशेषताएं, जिनमें से दोनों हमारे मॉडल द्वारा अच्छी तरह से संभाली जाती हैं।', 'ru': 'Эта статья описывает вклад Хельсинки-Любляны в разделяемую задачу VarDial по геолокации разнообразия социальных сетей. Наши решения основаны на моделях BERT Transformer, ограниченные версии наших моделей достигают 1-го места в двух подзадачах и 3-го места в одной подзадаче, в то время как наши неограниченные модели превосходят все ограниченные системы с большим запасом. Мы показываем в нашем анализе, что модели на основе трансформаторов намного превосходят традиционные модели, и что улучшения, полученные в результате предварительного обучения моделей на больших количествах (в основном стандартного) текста, являются значительными, но не кардинальными, а одноязычные модели также превосходят многоязычные модели. Наш ручной анализ показывает, что два типа сигналов являются наиболее важными для (неправильного)прогнозирования: именованные сущности и диалектные особенности, оба из которых хорошо обрабатываются нашими моделями.', 'ga': 'Déanann an páipéar seo cur síos ar an méid a chuir Heilsincí-Liúibleána le tasc roinnte VarDial ar gheoláithriú éagsúlachta na meán sóisialta. Tá ár réitigh bunaithe ar mhúnlaí BERT Transformer, na leaganacha srianta dár múnlaí ag baint an 1ú háit amach in dhá fhothasc agus an 3ú háit in aon fhothasc amháin, agus sáraíonn ár múnlaí neamhshrianta na córais shrianta go léir go mór. Léirímid inár n-anailísí go n-éiríonn go mór le samhlacha Trasfhoirmeoirí-bhunaithe ná múnlaí traidisiúnta, agus go bhfuil feabhsuithe a fhaightear trí mhúnlaí réamh-oiliúna ar chainníochtaí móra téacs (caighdeánach den chuid is mó) suntasach, ach nach bhfuil siad thar a bheith suntasach, agus go sáraíonn samhlacha aonteangacha samhlacha ilteangacha freisin. . Léiríonn ár n-anailís láimhe go bhfuil dhá chineál comhartha ar na cinn is ríthábhachtach le haghaidh réamh-mheastacháin: eintitis ainmnithe agus gnéithe canúinteacha, agus láimhseálann ár múnlaí an dá cheann acu go maith.', 'ka': 'ამ დოკუნტის აღწერა ჰელსინკი-ლუბლიანის დამატება VarDial სოციალური მედია განსხვავებული გეოლოკაციაში. ჩვენი პასუხები ბერტი ტრანფორმაციის მოდელზე დაბაზიან, ჩვენი მოდელების დარწმუნებული ვერსიებები ერთი ადგილში ორი საკუთარი და საკუთარი ადგილში ერთი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი მოდელ ჩვენ ჩვენი ანალიზებში ჩვენ აჩვენებთ, რომ ტრანფორმების მოდელები უფრო მეტრაციური მოდელები გავაკეთებენ, და რომ უფრო მეტრაციური მოდელები, რომლებიც უფრო მეტრაციური ტექსტის დიდი (უფრო მეტრანეტური) მნიშვნელობები ჩვენი ხელსაწყოთა ანალიზია, რომ ორი ტიპი სიგნალეები უფრო მნიშვნელოვანია (ცოტა) წარმოდგენისთვის: სახელსაწყოთა ინტერტიები და დიალექტური ფუნქციები, რომელიც ორივე ჩ', 'el': 'Η παρούσα εργασία περιγράφει τη συνεισφορά Ελσίνκι-Λιουμπλιάνα στο κοινό έργο VarDial σχετικά με τη γεωεντοπισμό ποικίλων μέσων κοινωνικής δικτύωσης. Οι λύσεις μας βασίζονται στα μοντέλα Οι περιορισμένες εκδόσεις των μοντέλων μας φτάνουν στην 1η θέση σε δύο δευτερεύουσες εργασίες και στην τρίτη θέση σε μία δευτερεύουσα εργασία, ενώ τα μη περιοριστικά μοντέλα μας ξεπερνούν όλα τα περιορισμένα συστήματα κατά μεγάλο περιθώριο. Στις αναλύσεις μας καταδεικνύουμε ότι τα μοντέλα που βασίζονται στον μετασχηματιστή ξεπερνούν κατά πολύ τα παραδοσιακά μοντέλα και ότι οι βελτιώσεις που επιτυγχάνονται από τα μοντέλα προ-εκπαίδευσης σε μεγάλες ποσότητες (κυρίως τυποποιημένου) κειμένου είναι σημαντικές, αλλά όχι δραστικές, με τα μονογλωσσικά μοντέλα να ξεπερνούν επίσης τα πολυγλωσσικά μοντέλα. Η χειρωνακτική ανάλυση μας δείχνει ότι δύο τύποι σημάτων είναι οι πιο κρίσιμοι για μια (λανθασμένη) πρόβλεψη: ονομαστικές οντότητες και διαλεκτικά χαρακτηριστικά, τα οποία και τα δύο αντιμετωπίζονται καλά από τα μοντέλα μας.', 'hu': 'Ez a tanulmány ismerteti Helsinki-Ljubljana hozzájárulását a VarDial megosztott feladatához a közösségi média változatosságának geolokációjával kapcsolatban. Megoldásaink a BERT Transformer modellekre épülnek, modelleink korlátozott változatai két részfeladatban az első helyet és a harmadik helyet egy részfeladatban, miközben korlátlan modelleink nagy margóval felülmúlják az összes korlátozott rendszert. Elemzéseinkben megmutatjuk, hogy a transzformátor alapú modellek messze felülmúlják a hagyományos modelleket, és hogy a nagy mennyiségű (többnyire szabványos) szöveg előképzési modellek által elért fejlesztések jelentősek, de nem drasztikusak, az egynyelvű modellek is felülmúlják a többnyelvű modelleket. Kézi elemzésünk azt mutatja, hogy két típusú jel a legfontosabb egy (félreértett)előrejelzéshez: a nevezett entitások és a dialektális jellemzők, amelyeket modelleink jól kezelnek.', 'kk': 'Бұл қағаз Хельсинки- Любляна әртүрлі медиақтар географиялық тапсырмасына VarDial ортақ тапсырмасына қатынасын таңдайды. Біздің шешімдеріміз BERT түрлендіруші үлгілеріне негізделген, үлгілеріміздің шектелген нұсқалары бірінші жерде екі төменгі және үшінші жерде бір төменгі сұрақтарда жеткізген, бірақ біздің шектелмеген үлгілеріміз Біз анализияларымызда Трансформация негіздеген үлгілер әдетті үлгілерді көп (көпшілік стандартты) мәтіндердің үлкен (көпшілікті) үлгілерінде алдын- ала алдын- ала оқыту үлгілерінде жақсартылып, бірақ драстикалы Қолмен анализ біздің екі түрлі сигналдардың (тұрақты) таңдау үшін ең маңызды болуын көрсетеді: аталған нысандар мен диалектикалық мүмкіндіктері, екеуі біздің үлгілеріміз дұрыс өзгертілген.', 'lt': 'Šiame dokumente aprašomas Helsinkio ir Ljubljanos indėlis į VarDial bendrą užduotį socialinės žiniasklaidos įvairovės geolokacijos srityje. Our solutions are based on the BERT Transformer models, the constrained versions of our models reaching 1st place in two subtasks and 3rd place in one subtask, while our unconstrained models outperform all the constrained systems by a large margin.  Atliekant analizę parodome, kad Transformų modeliai iki šiol viršija tradicinius modelius ir kad patobulinimai, pasiekti rengimo modeliuose dėl didelių (daugiausia standartinių) tekstų kiekių, yra reikšmingi, bet ne drastiški, o vienos kalbos modeliai taip pat viršija daugiakalbius modelius. Mūsų rankinė analizė rodo, kad dviejų tipų signalai yra svarbiausi (klaidingai) prognozuojant: pavadinti subjektai ir dialektinės savybės, kurių abu gerai tvarko mūsų modeliai.', 'it': 'Questo articolo descrive il contributo Helsinki-Lubiana al compito condiviso VarDial sulla geolocalizzazione delle varietà dei social media. Le nostre soluzioni si basano sui modelli BERT Transformer, le versioni vincolate dei nostri modelli raggiungono il primo posto in due sottoattività e il terzo posto in una sottoattività, mentre i nostri modelli non vincolati superano di gran lunga tutti i sistemi vincolati. Nelle nostre analisi mostriamo che i modelli basati su Transformer superano di gran lunga i modelli tradizionali e che i miglioramenti ottenuti dai modelli di pre-formazione su grandi quantità di testo (per lo più standard) sono significativi, ma non drastici, con modelli monolingua che superano anche i modelli multilingue. La nostra analisi manuale mostra che due tipi di segnali sono i più cruciali per una (mis)previsione: entità denominate e caratteristiche dialettali, entrambi gestiti bene dai nostri modelli.', 'mk': 'Овој весник го опишува придонесот на Хелсинки-Љубљана за заедничката задача на Вардијал за геолокацијата на различните социјални медиуми. Нашите решенија се базирани на моделите BERT Трансформер, ограничените верзии на нашите модели достигнуваат прво место во две потпрашања и трето место во една потпрашања, додека нашите неограничени модели ги надминуваат сите ограничени системи со голема маргина. Во нашите анализи покажуваме дека моделите базирани на Трансформи досега ги надминуваат традиционалните модели и дека подобрувањата постигнати од моделите за предобука на големи количини (претежно стандарден) текст се значителни, но не драстични, со моделите на еднојазик исто така надминуваат мултијази Нашата рачна анализа покажува дека два вида сигнали се најклучни за (погрешно) предвидување: именувани ентитети и дијалектални карактеристики, кои се добро управувани од нашите модели.', 'ms': 'Kertas ini menggambarkan kontribusi Helsinki-Ljubljana kepada tugas berkongsi VarDial pada geolokasi variasi media sosial. Solusi kita berdasarkan pada model BERT Transformer, versi terbatas model kita mencapai tempat pertama dalam dua sub-tanya dan tempat ketiga dalam satu sub-tanya, sementara model kita tidak terbatas melampaui semua sistem terbatas dengan margin besar. Kami menunjukkan dalam analisis kami bahawa model berasaskan Transformer melampaui model tradisional jauh, dan bahawa peningkatan yang dicapai oleh model pralatihan pada kuantiti besar teks (kebanyakan piawai) adalah signifikan, tetapi tidak drastik, dengan model bahasa tunggal juga melampaui model berbilang bahasa. Analisis manual kami menunjukkan bahawa dua jenis isyarat adalah yang paling penting untuk ramalan (salah): entiti bernama dan ciri-ciri dialektal, kedua-dua yang dikendalikan dengan baik oleh model kami.', 'ml': 'This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation.  നമ്മുടെ പരിഹരണങ്ങള്\u200d ബെര്\u200dട്ടി ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റര്\u200d മോഡലുകളുടെ അടിസ്ഥാനത്താണ്, നമ്മുടെ മോഡലുകളുടെ നിര്\u200dബന്ധിതമായ പതിപ്പുകള്\u200d രണ്ടാമത്തെ സ്ഥലത്തേക്കും ഒന്നാമത നമ്മുടെ അന്വേഷണങ്ങളില്\u200d ഞങ്ങള്\u200d കാണിക്കുന്നു, ട്രാന്\u200dസ്ഫോര്\u200dഫ് അടിസ്ഥാനത്തുള്ള മോഡലുകള്\u200d ദൂരെയായി പ്രവര്\u200dത്തിക്കുന്നു. പുന്നിയോഗിക്കുന്ന മോഡലുകള്\u200d മുന്\u200dകൂട്ടിയിട നമ്മുടെ കൈയ്യിലുള്ള അന്യായം കാണിക്കുന്നു രണ്ട് തരം സിഗ്നലുകള്\u200d ഒരു (മിസ്)പ്രവചനത്തിന് ഏറ്റവും പ്രധാനപ്പെട്ടതാണ്: പേരുള്ള വസ്തുക്കളും ഡയ', 'mt': 'Dan id-dokument jiddeskrivi l-kontribut ta’ Helsinki-Ljubljana għall-kompitu kondiviż ta’ VarDial dwar il-ġeolokazzjoni tal-varjetà tal-midja soċjali. Is-soluzzjonijiet tagħna huma bbażati fuq il-mudelli BERT Transformer, il-verżjonijiet ristretti tal-mudelli tagħna li jilħqu l-ewwel post f’żewġ sottomistoqsijiet u t-tielet post f’sottomistoqsija waħda, filwaqt li l-mudelli mhux ristretti tagħna jaqbżu s-sistemi ristretti kollha b’marġini kbir. Fl-analiżi tagħna nuru li l-mudelli bbażati fuq it-Trasformer għadhom lura milli jwettqu mudelli tradizzjonali, u li t-titjib miksub minn mudelli ta’ qabel it-taħriġ dwar kwantitajiet kbar ta’ test (l-aktar standard) huwa sinifikanti, iżda mhux drastiku, b’mudelli b’lingwa waħda wkoll li jwettqu mudelli multilingwi. L-analiżi manwali tagħna turi li żewġ tipi ta’ sinjali huma l-aktar kruċjali għal tbassir (ħa żin): entitajiet imsemmija u karatteristiċi dijalettiċi, li t-tnejn huma mmaniġġjati tajjeb mill-mudelli tagħna.', 'mn': 'Энэ цаас Хельсинки-Любляна нийгмийн мэдээллийн олон янз бүрийн географийн ажил дээр VarDial-ын хуваалцах зориулалтыг тайлбарладаг. Бидний шийдэл нь БЕРТ Трансформаторын загвар дээр суурилсан. Бидний загварын хязгаарлагдсан хувилбарууд нь 1-р доор хоёр доор, 3-р доор нэг доор нэг асуулт дээр хүрэх болно. Гэхдээ бидний хязгаарлагдсан загварууд нь бүх хязгаарлаг Бид өөрсдийн шинжилгээнд Трансфер суурилсан загварууд уламжлалтай загваруудыг урт хугацаанд гаргадаг гэдгийг харуулж байна. Өмнөх (ихэвчлэн стандарт) хэмжээний (ихэвчлэн) хэлбэрээр сургалтын загварууд маш чухал, гэхдээ нэг хэл загварууд ч олон хэл Бидний гарын шинжилгээ нь хоёр төрлийн сигнал нь (буруу) таамаглалтын хамгийн чухал гэдгийг харуулж байна: нэрлэгдсэн биетүүд, диалектикийн чадварууд, хоёр нь бидний загвараар сайн дүрслэгддэг.', 'ro': 'Această lucrare descrie contribuția Helsinki-Ljubljana la sarcina comună VarDial privind geolocalizarea varietății rețelelor de socializare. Soluțiile noastre se bazează pe modelele BERT Transformer, versiunile constrânse ale modelelor noastre ajungând pe locul 1 în două subactivități și pe locul 3 într-o singură subactivitate, în timp ce modelele noastre fără constrângeri depășesc cu o marjă mare toate sistemele constrânse. Analizele noastre arată că modelele bazate pe Transformer depășesc cu mult modelele tradiționale și că îmbunătățirile obținute de modelele de pre-formare pe cantități mari de text (în mare parte standard) sunt semnificative, dar nu drastice, modelele monolingvistice depășesc, de asemenea, modelele multilingve. Analiza noastră manuală arată că două tipuri de semnale sunt cele mai importante pentru o predicție (greșită): entitățile denumite și caracteristicile dialectale, ambele fiind gestionate bine de modelele noastre.', 'pl': 'Niniejszy artykuł opisuje wkład Helsinek-Lublany w wspólne zadanie VarDial w zakresie geolokalizacji różnorodności mediów społecznościowych. Nasze rozwiązania opierają się na modelach BERT Transformer, wersje ograniczone naszych modeli osiągają pierwsze miejsce w dwóch podzadaniach i trzecie miejsce w jednym podzadaniu, natomiast nasze nieograniczone modele znacznie przewyższają wszystkie systemy ograniczone. W naszych analizach pokazujemy, że modele oparte na Transformerze zdecydowanie przewyższają tradycyjne modele oraz że ulepszenia uzyskane przez modele przedtreningowe na dużych ilościach (głównie standardowego) tekstu są znaczące, ale nie drastyczne, a modele jednojęzyczne również przewyższają modele wielojęzyczne. Nasza analiza ręczna pokazuje, że dwa rodzaje sygnałów są najważniejsze dla (błędnej) predykcji: nazwane jednostki i cechy dialektalne, z których oba są dobrze obsługiwane przez nasze modele.', 'no': 'Denne papiret beskriver Helsinki-Ljubljana-bidraga til VarDial-delt oppgåve på geoplassering av sosiale medier. Løysingane våre er basert på BERT-transformeringsmodelane, den begrensede versjonane av modelane våre som når første plass på to underspørsmål og tredje plass på ein underspørsmål, mens våre ukonstrurte modelane utfører alle begrensede systemene med stor margin. Vi viser i våre analyser at Transformeringsbaserte modeller utfører tradisjonelle modeller langt, og at forbetringar som får av føreøvingsmodeller på stor kvantitetar av (mest standard) tekst er signifikant, men ikkje drastiske, med enkelspråksmodeller også utfører fleirspråksmodeller. Manuelle analysen vårt viser at to typar signaler er dei mest viktigste for eit (feil) foregåve: namnet einingar og dialektiske funksjonar, begge som vert handsama godt av våre modeller.', 'sr': 'Ovaj papir opisuje doprinos Helsinki-Ljubljane na podijeljeni zadatak VarDial na geolokaciji društvenih medija. Naše rešenje su temeljene na modelima BERT Transformer a, ograničenim verzijama našeg modela koji stižu do prvog mesta na dva podtačka i trećeg mesta na jednom podpitanju, dok naši bezograničeni modeli izvršavaju sve ograničene sisteme velikom marginom. U našim analizima pokazujemo da su modeli na transformeru do sada iznosili tradicionalne modele i da su poboljšanja dobijena od modela pre obuke na velikim količinama (uglavnom standardnih) teksta značajna, ali ne drastična, sa jednojezičkim modelima takođe iznosili i multijezičke modele. Naša ručna analiza pokazuje da su dve vrste signala najvažnije za predviđanje (pogrešno): imenovane entitate i dijalektne karakteristike, oboje su dobro rješene našim modelima.', 'si': 'මේ පැත්තේ හෙල්සින්කි-ල්ජුබ්ලානා සමාජික මිඩියාව විවිධ ස්ථානයේ වර්ඩියල් කාර්යාලයට සමාජික ව අපේ විශ්වාස අධාරිත BERT ප්\u200dරවර්තනයක් මොඩල් එක්ක, අපේ මොඩල් එක්ක ප්\u200dරවර්තනයක් පළවෙනි ස්ථානයෙන් පළවෙනි ස්ථානයෙන් සහ 3වෙනි ස්ථානයෙන් එක්ක අපි අපේ විශ්ලේෂණයේ පෙන්වන්නේ ප්\u200dරවේශකය අධාරිත මොඩේල් දුරටත් පාරමාන්\u200dය මොඩේල් වලින් ප්\u200dරවේශනය කරන්න පුළුවන් වෙන්න පුළුවන් වෙන්න පුළුවන් විශා අපේ මත්තල විශ්ලේෂණය පෙන්වන්නේ සංඥාවක් වර්ගයක් දෙකක් තමයි (වැරැද්දක්) ප්\u200dරශ්නයක්: නම් කරලා තියෙන අවශ්\u200dයය සහ ඩායිල', 'so': 'Warqaddan waxaa ku qoran warqadda ku saabsan warqadda ku saabsan VarDial ee ku saabsan shabakada shabakada bulshada ee Helsinki-Ljubljana goobo kala duduwan. Xaalkeenu waxay ku saleysan qaababka bedelka ee BERT, qaababka aan ku xaday modelalkayaga ay gaadhaan meel 1st oo ku taal labada shabakad iyo meesha saddexaad oo isku xabsi ah, isla markaasna qaababkayaga aan is-saxeynin waxay ka samaysaa nidaamka aad u qasban oo dhan. Analyadaana waxan ka muuqanaynaa in qaababka qaababka hore ee turjumay ay ay dhaqdhaqaaqaan tusaalooyin caadi ah, iyo in horumarinta lagu soo kordhiyey qaabab badan oo ay ku qoran yihiin qoraal badan (marka badan marka lagu qoro standard), laakiin ma aha mid aad u dhaqdhaqaaq, sidoo kale waxaa lagu sameeyaa modello luuqad kala duduwan. Analyskayaga gacmaha ah waxay muuqataa in laba cayn oo saxiix ah ay ugu muhiimsan yihiin wax la sii sheego (mis)', 'sv': 'Denna uppsats beskriver Helsingfors-Ljubljana bidrag till VarDial delade uppgift om geografisk lokalisering av sociala medier. Våra lösningar bygger på BERT Transformer-modellerna, de begränsade versionerna av våra modeller når 1:a plats i två underuppgifter och 3:e plats i en underuppgift, medan våra obegränsade modeller överträffar alla de begränsade systemen med stor marginal. Vi visar i våra analyser att Transformer-baserade modeller presterar överlägset traditionella modeller, och att förbättringar som erhålls genom pre-training modeller på stora mängder (mestadels standard)  text är betydande, men inte drastiska, med enspråkiga modeller som också presterar bättre än flerspråkiga modeller. Vår manuella analys visar att två typer av signaler är de viktigaste för en (miss)förutsägelse: namngivna entiteter och dialektiska funktioner, som båda hanteras väl av våra modeller.', 'ta': 'இந்த காகிதத்தை குறிப்பிடுகிறது ஹெல்சிங்கி- ல்ஜுப்லாஜானா வார்டியால் பகிர்ந்த பணியை விளக்குகிறது சமூக ஊடகங் எங்கள் தீர்வுகள் BERT மாற்றும் மாதிரிகளை அடிப்படையாக இருக்கிறது, எங்கள் மாதிரிகளின் கட்டுப்படுத்தப்பட்ட பதிப்பு நாம் எங்கள் ஆராய்ச்சிகளில் காட்டுகிறோம் மாற்றம் அடிப்படையான மாதிரிகள் தொலைவில் மாற்றும் பாதிப்பான மாதிரிகளை செயல்படுத்துகின்றன, முன் பயிற்சி மாதிரிகள் பெரி நம்முடைய கைமுறை ஆய்வு காட்டுகிறது இரண்டு வகையான குறிகள் ஒரு (mis)ம் முக்கியமானது: பெயரிடப்பட்ட பொருள்கள் மற்றும் விளக்க க குணங்கள், இவை இரண்டும', 'ur': 'This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation. ہمارے حل BERT تغییرات مدل پر بنے ہوئے ہیں، ہمارے مدل کی محدودہ نسخے ایک مکان پر پہنچ رہے ہیں، دوسری مکان میں اور تیسری مکان میں ایک مکان میں، حالانکہ ہمارے بغیر محدودہ مدل ایک بڑی محدودہ سے تمام محدودہ سیستموں کو کامل کر رہے ہیں۔ ہم اپنے تحلیل میں دکھاتے ہیں کہ ترنسفور کی بنیادی موڈل دور تک سنتی موڈل سے زیادہ اضافہ کرتی ہیں اور یہ کہ بہت سی (بہت سی استاندارڈ) موڈل سے پہلے ترینس موڈل کے ذریعہ سے اضافہ کی جاتی ہیں لیکن ایک زبان موڈل سے بھی زیادہ اضافہ نہیں کرتے۔ ہماری مہمانی تحلیل دکھاتا ہے کہ دو قسم سیگنال ایک (غلط) پیش بینی کے لئے سب سے اچھے ہیں: نام کی اجتماعی اور دیالکتل ویژگی، ان دونوں کو ہماری مدل سے اچھی طرح تحمل کیا جاتا ہے۔', 'uz': "Bu qogʻoz Helsinki-Ljubljana VarDial (VarDial) vazifani ajratishga taʼrifi qiladi. Ushbu qogʻoz jamiyatlar muloqat joylariga qayta ishlash. Bizning qiymatlarimiz BERT Transfer modellari asosida, modellarimizning qisqarli versiyalarimiz ikki vazifalarda birinchi joyga keladi va bir tub vazifani uchinchi joyga yetishadi, va bizning ko'paytirilmagan modellarimiz katta harfga hamma qanday qanday tizimlarni bajaradi. Biz taʼminlovchimizda, Transformer asosiy modellari juda uzoq modellarni bajarayotganda ko'rsatamiz, va o'rganishdan oldin o'rganish modellari katta qiymati (oddiy стандарт) matnning o'zgarishlari muhim, lekin drastik emas, balki bitta tillar modellari bilan bir necha tillar modellarini bajarish mumkin. Bizning qoʻlbola analytikimiz ko'rsatadi, ikkita tur signallar (misol) hisoboti uchun eng muhim: nomli obʼektlar va dialektal xususiyatlar, bu ikkalar modellarimiz bilan yaxshi boshlanadi.", 'vi': 'Tờ giấy này mô tả sự đóng góp của Helsinki-Ljubljana với nhiệm vụ chia sẻ của VarDial về địa vị đa dạng truyền thông xã hội. Các giải pháp của chúng ta dựa trên các mô hình thay đổi BERT, những phiên bản bị hạn của các mô hình mang đến vị trí thứ nhất, gồm hai lớp dưới và vị trí thứ ba trong một lớp phụ đề, trong khi các mô hình chưa được huấn luyện vượt trội tất cả các hệ thống bị hạn với một khối lớn. Chúng tôi cho thấy trong các phân tích, các mô hình biến hình đã áp dụng vượt xa các mô hình truyền thống, và những cải tiến tiến tiến được lấy từ các mô hình trước khi huấn luyện về một lượng lớn văn bản (hầu hết tiêu chuẩn) có ý nghĩa, nhưng không mạnh mẽ, với các mô hình ngôn ngữ đơn cũng vượt trội các mô hình đa dạng. Bài phân tích bằng tay cho thấy hai loại tín hiệu là điều quan trọng nhất cho dự đoán sai: các thực thể tên và các tính năng địa phương, cả hai đều được xử lý tốt bởi các mẫu của chúng ta.', 'da': 'Denne artikel beskriver Helsinki-Ljubljana bidraget til VarDial delte opgave om geografisk lokalisering af sociale medier. Vores løsninger er baseret på BERT Transformer-modellerne, hvor de begrænsede versioner af vores modeller når førstepladsen i to underopgaver og tredjepladsen i én underopgave, mens vores ubegrænsede modeller overstiger alle begrænsede systemer med stor margin. Vi viser i vores analyser, at Transformer-baserede modeller langt overgår traditionelle modeller, og at forbedringer opnået ved pre-training modeller på store mængder (for det meste standard) tekst er betydelige, men ikke drastiske, idet ensprogede modeller også overgår flersprogede modeller. Vores manuelle analyse viser, at to typer signaler er de mest afgørende for en (mis)forudsigelse: navngivne entiteter og dialektiske funktioner, som begge håndteres godt af vores modeller.', 'bg': 'Настоящата статия описва приноса на Хелзинки-Любляна към споделената задача на ВарDial по геолокация на разнообразието в социалните медии. Нашите решения се основават на моделите трансформатори, като ограничените версии на нашите модели достигат първо място в две подзадачи и трето място в една подзадача, докато нашите неограничени модели надминават всички ограничени системи с голям марж. В нашите анализи показваме, че моделите, базирани на трансформатори, далеч превъзхождат традиционните модели и че подобренията, получени от моделите на предобучение върху големи количества (предимно стандартен) текст, са значителни, но не драстични, като едноезичните модели също превъзхождат многоезичните модели. Ръчният ни анализ показва, че два вида сигнали са най-важни за (погрешно)предсказване: наименовани единици и диалектални характеристики, и двете от които се обработват добре от нашите модели.', 'nl': 'Dit artikel beschrijft de bijdrage van Helsinki-Ljubljana aan de gedeelde taak VarDial op de geolocatie van verschillende sociale media. Onze oplossingen zijn gebaseerd op de BERT Transformer modellen, de beperkte versies van onze modellen bereiken de 1e plaats in twee subtaken en de 3e plaats in één subtaak, terwijl onze onbeperkte modellen alle beperkte systemen met een grote marge overtreffen. We laten in onze analyses zien dat Transformer-gebaseerde modellen veel beter presteren dan traditionele modellen, en dat verbeteringen verkregen door pre-training modellen op grote hoeveelheden (meestal standaard) tekst significant, maar niet drastisch zijn, waarbij enkeltalige modellen ook beter presteren dan meertalige modellen. Onze handmatige analyse toont aan dat twee soorten signalen het meest cruciaal zijn voor een (mis)voorspelling: benoemde entiteiten en dialectische kenmerken, die beide goed worden behandeld door onze modellen.', 'de': 'Dieser Beitrag beschreibt den Beitrag Helsinki-Ljubljana zur gemeinsamen Aufgabe VarDial zur Geolokalisierung sozialer Medien. Unsere Lösungen basieren auf den BERT Transformer Modellen. Die eingeschränkten Versionen unserer Modelle erreichen den ersten Platz in zwei Teilaufgaben und den dritten Platz in einer Teilaufgabe, während unsere uneingeschränkten Modelle alle eingeschränkten Systeme deutlich übertreffen. Wir zeigen in unseren Analysen, dass Transformer-basierte Modelle herkömmliche Modelle bei weitem übertreffen und dass Verbesserungen, die durch Vortrainingsmodelle bei großen Mengen an (meist Standard-)Text erzielt werden, signifikant, aber nicht drastisch sind, wobei einsprachige Modelle auch mehrsprachige Modelle übertreffen. Unsere manuelle Analyse zeigt, dass zwei Arten von Signalen für eine (Fehl-)Vorhersage am wichtigsten sind: benannte Entitäten und dialektale Merkmale, die beide von unseren Modellen gut behandelt werden.', 'hr': 'Ovaj papir opisuje doprinos Helsinki-Ljubljane podijeljenom zadatku VarDial na geolokaciji društvenih medija. Naše rješenje su temeljene na modelima BERT transformera, ograničenim verzijama naših modela do prvog mjesta na dvije podstaze i trećem mjestu na jednom podstaženju, dok naši bezograničeni modeli iznose sve ograničene sustave velikom marginom. U našim analizima pokazujemo da su modeli na transformeru do sada iznosili tradicionalne modele i da su poboljšanje koje su dobile modeli predobučenja na velikim količinama (uglavnom standardnih) teksta značajne, ali ne drastične, s jednojezičkim modelima također iznosile multijezičke modele. Naša ručna analiza pokazuje da su dvije vrste signala najvažnije za predviđanje (pogrešno): imenovane entitate i dijalektne funkcije, obje od njih se dobro obrađuju naši modeli.', 'ko': '본고는 헬싱키 루블랴나가 소셜 미디어의 다양성 지리적 포지셔닝에 대한VarDial 공유 임무에 기여한 바를 묘사한다.우리의 해결 방안은 BERT Transformer 모델을 바탕으로 우리 모델의 제약 버전은 두 개의 하위 작업 중 1위를 차지하고 한 개의 하위 작업 중 3위를 얻으며 우리의 무제약 모델은 어느 정도에 모든 제약 시스템보다 우수하다.우리의 분석에 의하면 지금까지 변환기를 바탕으로 한 모델의 성능은 전통 모델보다 우수했고 대량(주로 표준) 텍스트의 예비 훈련 모델을 통해 얻은 개선은 현저하지만 격렬하지 않고 단일 언어 모델의 성능도 다중 언어 모델보다 우수하다는 것을 알 수 있다.우리의 수동 분석에 의하면 두 가지 유형의 신호가 (오류) 예측에 가장 관건적인 것은 명명 실체와 사투리 특징이다. 이 두 가지 신호는 모두 우리의 모델에 의해 잘 처리될 수 있다.', 'fa': 'این کاغذ مشارکت هلسینکی-لجوبلانا را توصیف می\u200cکند که در وضعیت جامعه\u200cهای مختلف رسانه\u200cهای اجتماعی واردیال مشترک شده است. راه حل\u200cهای ما بر روی مدل\u200cهای تبدیل کننده BERT، نسخه\u200cهای محدودیت مدل\u200cهای ما به جای اول رسیدن به جای اول در دو سوت و سوم مکان در یک سوت\u200cپرسی، در حالی که مدل\u200cهای غیرمحدودیت ما از تمام سیستم\u200cهای محدودیت با یک مرز بزرگ بیرون می\u200cآورند. ما در تحلیل\u200cهایمان نشان می\u200cدهیم که مدل\u200cهای بنیاد تغییر\u200cدهنده به مدل\u200cهای سنتی تا الان بیشتر از آن انجام می\u200cدهند، و بهترین\u200cها که توسط مدل\u200cهای پیش\u200cآموزش به اندازه\u200cهای بزرگ (بیشتر استاندارد) متن\u200cهای (استاندارد) معنی دارند، ولی نه دراستیکی، با مدل\u200cهای یک زبان تحلیل دستی ما نشان می دهد که دو نوع سیگنال بزرگترین برای پیش بینی (اشتباه) هستند: entities named and dialectal features, both of which are well handled by models ما.', 'sw': 'Gazeti hili linaelezea mchango wa Helsinki-Ljubljana wa VarDial ulioshirikisha kazi katika maeneo mbalimbali ya mitandao ya kijamii. Mifumbuzi yetu inatokana na mifano ya mabadiliko ya BERT, toleo lililolazimishwa kwa mifano yetu kufikia nafasi ya kwanza katika majukumu mawili na sehemu ya tatu katika juhudi moja, wakati mifano yetu yasiyoeleweka inafanya mifumo yote iliyokuwa imelazimika kwa kiwango kikubwa. Tunaonyesha katika uchambuzi wetu kwamba mifano ya zamani yanafanya mifano ya utamaduni kwa mbali, na kwamba maendeleo yaliyopatikana na mifano ya mafunzo ya zamani yanahusu kiasi kikubwa cha ujumbe (kwa ujumla wa hali ya kawaida) ni muhimu, lakini si vigumu, na pia kwa mifano ya lugha moja pia yanafanya mifano ya lugha mbalimbali. Uchambuzi wetu wa mikononi unaonyesha kuwa aina mbili za ishara ni muhimu zaidi ya utabiri (kwa mfano) unaotajwa: vitu na vipengele vya kidijitali, ambavyo viwili vinavyokabiliwa vizuri na mifano yetu.', 'tr': "Bu kagyz Helsinki-Ljubljana VarDial'yň sosial mediýalaryň beýleki ýerlerinde paýlaşdyrylýar. Çözümlerimiz BERT Transformer modellerine daýanýar, modellerimiziň azalýan versiýalary 1-nji ýere 2 alt we 3-nji ýere ulalýar, ýöne a ýratyn döredilmez modellerimiz bütin bir gabat bilen ähli ýagdaýlanýan sistemalary çykarýarlar. Analyzlarymyzda Transformer tabanly nusgalaryň şu wagt çenli däpli nusgalardan üstün edýändigini we nusgalarymyzda örän uly (köplenç diýmek standart) metinlerin üstünde bolan täzelikleri çykarýar, ýöne drastik däldir, ýeke dil nusgalarynda hem multi dil nusgalarynda çykarýar. Kitap analyzamyz 2 hili sany sinyallaryň bir (ýalňyş) önümlemesi üçin iň owadan möhüm bolandygyny görkezýär: adly zatlar we dialektal özellikleri, ikisi hem de modellerimiz bilen gowy çözilýär.", 'af': "Hierdie papier beskryf die Helsinki-Ljubljana bydraag na die VarDial gedeelde taak op sosiale media verskeie geoligging. Ons oplossing is gebaseer op die BERT Transformer modele, die beperkte weergawe van ons modele wat die 1ste plek bereik in twee subtaske en die 3de plek in een subtaske, terwyl ons ongenstreekte modele uitvoer al die beperkte stelsels deur 'n groot grens. Ons vertoon in ons analiseerdes dat Transformer-gebaseerde modelle tradisionele modele van ver uitvoer, en dat verbeteringe wat deur vooraf-onderwerking modele ontvang word op groot hoeveelheid van (meeste standaard) teks betekeurig is, maar nie drastig nie, met enkel-taal modele ook uitvoer multitaal modele. Ons hand analisie vertoon dat twee tipe signale die mees gekruisigde is vir 'n (mis) voorskou: genaamde entiteite en dialekte funksies, albei van wat goed deur ons modele hanteer word.", 'sq': 'Ky dokument përshkruan kontributin Helsinki-Ljubljana në detyrën e përbashkët të VarDial mbi gjeolokalimin e varietetit të medias sociale. Zgjidhjet tona janë të bazuara në modelet BERT Transformer, versionet e kufizuara të modeleve tona që arrijnë vendin e parë në dy nënpyetje dhe vendin e tretë në një nënpyetje, ndërsa modelet tona të pakufizuara mbizotërojnë të gjitha sistemet e kufizuara me një margin të madh. Ne tregojmë në analizat tona se modelet me qendër në Transformer e tejkalojnë modelet tradicionale deri tani dhe se përmirësimet e arritura nga modelet e paratrajnimit mbi sasi të mëdha teksti (kryesisht standard) janë të rëndësishme, por jo drastike, me modele me gjuhë të vetme gjithashtu të tejkalojnë modelet shumëgjuhësore. Analiza jonë manuale tregon se dy lloje sinjalesh janë më vendimtarët për një parashikim (gabim): njësi të emëruara dhe karakteristika dialektale, të cilat të dy janë trajtuar mirë nga modelet tona.', 'am': 'ይህም ገጽ የኬልስኪን-Ljubljana ማኅበራዊ አውታር ማኅበራዊ አውታር በተለየ ቦታዎች ላይ የተሰራጨውን ሥራ ይናገራል፡፡ መፍትረታችን BERT ትርጉም ሞዴላዎችን በመሠረት ላይ ነው፣ የሞላዎቻችን ግንኙነት በሁለት ደብዳቤዎች በሦስተኛውም ስፍራ በአንድ ትዕዛዝ ውስጥ ወደሚደርስ ደረጃ የተደረገ ነው፡፡ በተመሳሳይነታችን፣ በተለየ የፊደል ዓይነቶች የባሕላዊ ሞዴላዎችን ለሩቅ እንደሚያሳየው እናሳያቸዋለን፤ የፊተኛውም ተማርኮ ሞዴላዎች በብዙ ብዛት (standard) ጽሑፎች በሚያሳየው መጠቀሚያ ግንኙነት ነው፣ ነገር ግን በቋንቋ አይደነቅም፣ በአንድ ቋንቋ ምሳሌዎች ደግሞ ብዙዎችን የቋንቋ ዓይነቶች ማሳየት ነው፡ Our manual analysis shows that two types of signals are the most crucial for a (mis)prediction: named entities and dialectal features, both of which are handled well by our models.', 'bn': 'এই প্রবন্ধে হেল্সিঙ্কি-লুজুব্লজানা ভ্যার্ডিয়াল বিভিন্ন সামাজিক মিডিয়ার বিভিন্ন ভূমিতে ভাগাভাগি করা কা আমাদের সমাধান বিবের্ট ট্রান্সফ্রান্স মডেলের উপর ভিত্তিক, আমাদের মডেলের নিষিদ্ধ সংস্করণ দুই সাবটাস এবং তৃতীয় স্থানে পৌঁছে যাচ্ছে, আর আমাদের অনস্থির মডেল আমরা আমাদের বিশ্লেষণে দেখাচ্ছি যে ট্রান্সফারের ভিত্তিক মডেল অনেক দূরে প্রথাগত মডেল প্রদর্শন করে এবং পূর্ব প্রশিক্ষণের মডেল বিশাল পরিমাণ (বেশীরভাগ স্ট্যান্ডার) টেক্সট আমাদের মানুষের বিশ্লেষণ দেখাচ্ছে যে দুটি ধরনের সিগন্যালের জন্য সবচেয়ে গুরুত্বপূর্ণ ভবিষ্যৎবাণী: নামের বস্তু এবং ডায়ালেক্টাল বৈশি', 'az': 'Bu kağıt, sosyal media müxtəlif geolokasyonda VarDial paylaşdığı işin Helsinki-Ljubljana qismətini təsbit edir. Bizim çətinlərimiz BERT Transformer modellərinə dayandırılır, modellərin müəyyən edilmiş versiyonların birinci yerə iki dəstə və üçüncü yerə bir dəstədə gəlib çatdığı zaman, müəyyən edilməmiş modellərimiz bütün müəyyən edilmiş sistemləri böyük bir dəstə ilə istifadə edirlər. Bizim analizlərimizdə Transformer tabanlı modellərin çox yüksək (çox standart) mətnlərin çoxluğu ilə əvvəl təhsil modellərin üstünlüyünü göstərdiyini göstəririk, lakin təhsil modellərin çoxlu dil modellərinin üstünlüyünü göstərir. Bizim əlavə analizimiz göstərir ki, iki növ sinyal bir (yanlış) tədbir üçün ən çox mövcuddur: adlı növlər və dialektal növləri, ikisi də modellərimiz ilə yaxşı idarə edilir.', 'ca': "Aquest article descriu la contribució Helsinki-Ljubljana a la tasca compartida VarDial sobre la geolocalització de la varietat dels mitjans socials. Les nostres solucions estan basades en els models BERT Transformer, les versions restringides dels nostres models que arriben al primer lloc en dues subterrànies i al tercer lloc en una subterrània, mentre que els nostres models no restringits superen tots els sistemes restringits en gran marge. En les nostres anàlisis demostrem que els models basats en Transformer superen de lluny els models tradicionals, i que les millores obtenides amb els models de pré-formació en grans quantitats de text (majoritàriament estàndard) són significatives, però no dràstics, amb models de llenguatge únic també superant els models multilingües. L'anàlisi manual mostra que dos tipus de senyals són els més crucials per a una predicció (errònia): entitats anomenades i característiques dialectals, ambdós manejades bé pels nostres models.", 'id': 'This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation.  Solusi kita berdasarkan model BERT Transformer, versi terbatas dari model kita mencapai tempat pertama dalam dua subtasks dan tempat ketiga dalam satu subtasks, sementara model kita tidak terbatas melampaui semua sistem terbatas dengan margin besar. Kami menunjukkan dalam analisis kami bahwa model berdasarkan Transformer melebihi model tradisional sejauh ini, dan bahwa peningkatan yang diperoleh oleh model prapelatihan pada jumlah besar teks (kebanyakan standar) adalah signifikan, tetapi tidak drastis, dengan model bahasa tunggal juga melebihi model multibahasa. Analisis manual kami menunjukkan bahwa dua jenis sinyal adalah yang paling penting untuk prediksi (salah): entitas bernama dan fitur dialektal, yang keduanya dikendalikan dengan baik oleh model kami.', 'bs': 'Ovaj papir opisuje doprinos Helsinki-Ljubljane podijeljenom zadatku VarDial na geolokaciji društvenih medija. Naše rješenje su temeljene na modelima BERT Transformer a, ograničenim verzijama naših modela do prvog mjesta na dva podtačka i trećeg mjesta na jednom podpitanju, dok naši bezograničeni modeli izvršavaju sve ograničene sisteme velikom marginom. U našim analizima pokazujemo da su modeli na transformeru do sada iznosili tradicionalne modele i da su poboljšanja dobijena od modela predobuke na velikim količinama (uglavnom standardnih) teksta značajna, ali ne drastična, s jednojezičkim modelima također iznosili i multijezičke modele. Naša ručna analiza pokazuje da su dvije vrste signala najvažnije za predviđanje (pogrešno): imenovane entitate i dijalektne karakteristike, obje od njih se dobro obrađuju naši modeli.', 'hy': 'Այս աշխատանքը նկարագրում է Հելսինկի-Լյուբլիանայի ներդրումը Վարդիալի ընդհանուր խնդիրը սոցիալական լրատվամիջոցների բազմազանության երկրագծի վրա: Մեր լուծումները հիմնված են BER Transforme մոդելների վրա, մեր մոդելների սահմանափակ տարբերակների վրա, որոնք հասնում են առաջին տեղը երկու ենթահարցերով և երրորդ տեղը մեկ ենթահարցերով, մինչդեռ մեր անսահմանափակ մոդելները շատ ավելի լավ են արտադրում բոլոր սահմանափակ համակարգերը: Մենք մեր վերլուծություններում ցույց ենք տալիս, որ տրանֆերմերների հիմնված մոդելները հեռու են գերազանցում ավանդական մոդելները, և որ զարգացումները, որոնք ստացվել են նախ-ուսուցման մոդելների միջոցով մեծ քանակությամբ (հիմնականում ստանդարտ) տեքստի վրա, նշանակալի են Մեր ձեռքի վերլուծությունը ցույց է տալիս, որ երկու տեսակի ազդանշանները ամենակարևոր են (սխալ) կանխատեսման համար. անվանված էակներ և դիալեկտալ հատկություններ, որոնք երկուսն էլ լավ են վարվում մեր մոդելներով:', 'fi': 'Tässä artikkelissa kuvataan Helsingin ja Ljubljanan panosta VarDialin yhteiseen tehtävään sosiaalisen median moninaisuuden geolokaatiossa. Ratkaisumme perustuvat BERT Transformer -malleihin, joiden rajoitetut versiot saavuttavat ensimmäisen sijan kahdessa alitehtävässä ja kolmannen sijan yhdessä alitehtävässä, kun taas rajattomat mallit ylittävät kaikki rajoitetut järjestelmät suurella marginaalilla. Analyysissämme osoitetaan, että Transformer-pohjaiset mallit ylittävät perinteiset mallit selvästi ja että esikoulutusmalleilla saadut parannukset suuriin määriin (enimmäkseen vakiomuotoista) tekstiä ovat merkittäviä, mutta eivät radikaaleja, sillä myös yksikieliset mallit ovat monikielisiä malleja parempia. Manuaalinen analyysimme osoittaa, että kaksi signaalityyppiä ovat ratkaisevimpia (väärin)ennustuksen kannalta: nimetyt entiteetit ja dialektiset piirteet, joita molemmat käsitellään hyvin malleissamme.', 'cs': 'Tento článek popisuje příspěvek Helsinek-Lublaně ke sdílenému úkolu VarDial v oblasti geolokace různých sociálních médií. Naše řešení jsou založena na modelech transformátoru BERT, jejichž verze s omezením dosahují prvního místa ve dvou dílčích úkolech a třetího místa v jednom dílčím úkolu, zatímco naše nekompenzované modely výrazně překonávají všechny omezené systémy. V našich analýzách ukazujeme, že modely založené na Transformeru zdaleka překonávají tradiční modely a že zlepšení dosažená předškolicími modely na velkém množství (většinou standardního) textu jsou významné, ale ne drastické, protože jednojazyčné modely také překonávají vícejazyčné modely. Naše manuální analýza ukazuje, že dva typy signálů jsou pro (chybné) predikci nejdůležitější: jmenované entity a dialektální rysy, které naše modely dobře zvládají.', 'et': 'Käesolevas artiklis kirjeldatakse Helsingi-Ljubljana panust VarDiali jagatud ülesandesse sotsiaalmeedia mitmekesise geolokatsiooni alal. Meie lahendused põhinevad BERT Transformeri mudelitel, meie mudelite piiratud versioonid jõuavad esimesele kohale kahes alamülesandes ja kolmandale kohale ühes alamülesandes, samas kui meie piiramatud mudelid ületavad kõiki piiratud süsteeme suurel hulgal. Analüüsides näitame, et Transformeritel põhinevad mudelid on traditsioonilised mudelid ületavad kaugelt traditsioonilisi mudeleid ning et koolituseelsete mudelitega saavutatud täiustused suurtes kogustes (enamasti standardteksti) on märkimisväärsed, kuid mitte drastilised, sest ühekeelsed mudelid on samuti paremad kui mitmekeelsed mudelid. Meie käsitsi analüüs näitab, et kahte tüüpi signaale on (vale)prognoosimise jaoks kõige olulisemad: nimelised olemid ja dialektilised omadused, mida mõlemat meie mudelid hästi käsitlevad.', 'jv': 'Perintah iki dadi kelalahan nganggo kelamèn helsinaku-LJubalana nang bardial sing dikarolan task nang jeograhan media sotiki. Awakdhéwé tambah kang basa ning model BERT Transformer, versi dadi nggawe model sing bisa basa 1 dumadhi sak 2 Subtitles lan 3 dumadhi sak dadi 1 Awak dhéwé éntuk karo haléné sampek dadi Transformer-basa model sing bisa akeh perusahaan model sing dadi nggawe, lan uga bantuan supaya model sing gawe nguasai perusahaan model sing dituruti (mesthi kuwi padha Standard) sing berarti, macem kuwi model sing berarti, lan model sing berarti kudu nggawe multilenguase model. Awak dhéwé manual dipeneksi iki soko sampeyan sing gak bener nggo ngerasahan (mis)', 'ha': "Wannan karatun na bayyana fassarar al'amarin da aka sanar da shi a cikin ¦akin Jalaliya-Ljublajana. Yauyinmu ne a kan misãlai da BERT ta shige, misalin misalinmu da aka riƙe su zuwa kwance a cikin taskõkin biyu da na uku a cikin wani sub-aikin, kuma da misalinmu wanda ba'a rubutu ba, sai su sami duk na tsarin da aka lazimta shi da margin babba. Tuna nũna cikin anayyanmu cewa misalin Transformer-based zaɓe misãlai na gaba ko baya, kuma musamman da aka samar da su sami masu motsi na zaman shawara a kan tsarin matsayin (maimakon da suka yi tsammani) sun yi muhimmi, kuma amma, bã da sauri, kuma da misãlai masu cikin mulki-lingui. Our manual analysis shows that two types of signals are the most crucial for a (mis)prediction: named entities and dialectal features, both of which are handled well by our models.", 'sk': 'V prispevku je opisan prispevek Helsinkovo-Ljubljane k skupni nalogi VarDial na družbenih omrežjih raznolike geolokacije. Naše rešitve temeljijo na modelih BERT Transformer, omejene različice naših modelov dosegajo 1. mesto v dveh podopravilih in 3. mesto v enem podopravilu, medtem ko naši neomejeni modeli za veliko maržo presegajo vse omejene sisteme. V naših analizah smo pokazali, da so modeli, ki temeljijo na transformatorju, daleč boljši od tradicionalnih modelov in da so izboljšave, dosežene z modeli pred usposabljanjem na velikih količinah (večinoma standardnega) besedila, pomembne, vendar ne drastične, pri čemer so enojezični modeli tudi boljši od večjezičnih modelov. Naša ročna analiza kaže, da sta za (napačno)napovedovanje najpomembnejši dve vrsti signalov: imenovani entiteti in dialektualni značilnosti, ki sta oba dobro obravnavana z našimi modeli.', 'he': 'העיתון הזה מתאר את התרומה של הלסינקי-ליובליאנה למשימה המשותפת של VarDial על מגוון התקשורת החברתית. הפתרונות שלנו מבוססים על דוגמנים BERT Transformer, הגרסאות המוגבלות של הדוגמנים שלנו מגיעים למקום הראשון בשני תת-שאלות ומקום השלישי במקום אחד תת-שאלה, בזמן שהדוגמנים הלא-מוגבלים שלנו מעלים את כל המערכות המוגבלות על ידי גבול גדול. אנו מראים בניתוחים שלנו שמודלים מבוססים על טרנספורס יוצאים מעל מודלים מסורתיים עד רחוק, וששיפורים שנקבלים על ידי מודלים לפני האימון על כמויות גדולות של טקסט (בעיקר סטנדרטי) הם משמעותיים, אבל לא דרסטיים, עם מודלים בשפה אחת גם יוצאים מעל מודלים רבות שפות הניתוח היד שלנו מראה ששני סוגים של אותים הם הכי קריטיים לחזוי (טעות): יחידות בשם וחלקים דיאלקטאליים, שניהם מתמודדים היטב על ידי הדוגמנים שלנו.', 'bo': 'This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation. Our solutions are based on the BERT Transformer models, the constrained versions of our models reaching 1st place in two subtasks and 3rd place in one subtask, while our unconstrained models outperform all the constrained systems by a large margin. The solution is based on the BERT Transformer models. འུ་ཅག་གིས་ང་ཚོའི་དབྱེ་ཞིབ་ནང་དུ་Transformer-based models་ནི་དུས་མཐུན་གྱི་སྔོན་གྲངས་བསྒྱུར་བའི་མིག་ཆས་ལས་ཕར་རྒྱས་སྤྲོད་ཀྱི་ཐབས་ལམ་ནང་ལ་ཕར་རྒྱས་ཁབ་ཀྱི་གྲངས་ཚད་ཆེ་བའི་ཡིག Our manual analysis shows that two types of signals are the most crucial for a (mis)prediction: named entities and dialectal features, both of which are handled well by our models.'}
{'en': 'Experiments in Language Variety Geolocation and Dialect Identification', 'pt': 'Experimentos em variedade de idiomas, geolocalização e identificação de dialetos', 'ar': 'تجارب في تنوع اللغة تحديد الموقع الجغرافي وتحديد اللهجات', 'fr': "Expériences de géolocalisation de variétés de langues et d'identification de dialectes", 'es': 'Experimentos en variedad de idiomas, geolocalización e identificación de dialectos', 'zh': '言语多样性地理定位,方言识实验', 'ja': '言語の多様性の地理的位置と方言の識別における実験', 'hi': 'भाषा विविधता Geolocation और बोली पहचान में प्रयोग', 'ru': 'Эксперименты по геолокации языковых разновидностей и идентификации диалектов', 'ga': 'Turgnaimh i Geoshuíomh Éagsúlacht Teanga agus Sainaithint Canúintí', 'ka': 'Name', 'hu': 'Kísérletek a nyelvváltozatosság geolokációjában és tárcsás azonosításában', 'el': 'Πειράματα στη γεωεντοπισμό γλωσσικών ποικιλιών και τον προσδιορισμό διαλέκτων', 'it': 'Esperimenti in geolocalizzazione delle varietà linguistiche e identificazione dialettica', 'kk': 'Тіл айнымалылығының географиялық орналасуы және таңдау идентификациясының эксперименттері', 'mk': 'Експерименти во геолокација на различните јазици и идентификација на дијалектот', 'lt': 'Kalbų veislių geolokacijos ir dialekto identifikavimo eksperimentai', 'ms': 'Name', 'ml': 'ഭാഷയിലെ പരീക്ഷണങ്ങള്\u200d വേരിറ്റി ജിയോളജേഷനും ഡയലക്ട്രിക്ക് തിരിച്ചറിയുക', 'mt': 'Esperimenti fil-Ġeolokazzjoni tal-Varjetà tal-Lingwi u l-Identifikazzjoni tad-Dijaletti', 'mn': 'Холны өөрчлөлт Geolocation болон Dialect Identification', 'no': 'Comment', 'pl': 'Eksperymenty w geolokalizacji odmian językowych i identyfikacji dialektów', 'ro': 'Experimente în geolocalizarea varietăților lingvistice și identificarea dialectelor', 'sr': 'Eksperimenti u geolokaciji jezika varijanta i identifikaciji dijalekta', 'si': 'භාෂාව වෙනස් භූතිකාරය සහ නිරීක්ෂණය පරීක්ෂණය', 'so': 'Imtixaanka ku saabsan qeybinta iyo aqoonsiga baaritaanka luuqada', 'sv': 'Experiment i geolokalisering av språkvariationer och dialektisk identifiering', 'ta': 'Name', 'ur': 'Language Variety Geolocation اور Dialect Identification', 'uz': 'Name', 'vi': 'Thí nghiệm về ngôn ngữ', 'bg': 'Експерименти в геолокация и идентификация на диалектите', 'nl': 'Experimenten in de geolocatie van taalvariëteiten en dialectidentificatie', 'hr': 'Eksperimenti u geolokaciji jezičkih varijacija i identifikaciji dijalekta', 'da': 'Eksperimenter med geografisk lokalisering af sprogsorter og dialekt identifikation', 'de': 'Experimente zur Geolokalisierung von Sprachenvielfalt und Dialektidentifikation', 'fa': 'تجربه\u200cها در محل جغرافی متفاوت زبان و شناسایی جغرافی', 'ko': '언어 변체 지리적 포지셔닝과 방언 식별 실험', 'sw': 'Tatizo la Utafiti na Utambulisho wa Tambulisho wa Lugha', 'af': 'Name', 'tr': 'Diller Çeşitlik Ýery we Saýlaw Kimligi', 'am': 'Experiments in Language Variety Geolocation and Dialect Identification', 'id': 'Eksperimen dalam Geolokasi Variasi Bahasa dan Identifikasi Dialek', 'sq': 'Eksperimentet në Gjeolokimin e Varitetit të Gjuhave dhe Identifikimin e Dialektit', 'hy': 'Experiments in Language Variety Geolocation and Dialect Identification', 'bs': 'Eksperimenti u geolokaciji jezičkih varijacija i identifikaciji dijalekta', 'ca': 'Experiments in Language Variety Geolocation and Dialect Identification', 'et': 'Eksperimentid keeleliikide geolokatsiooni ja dialekti identifitseerimise alal', 'az': 'Dil √áeŇüitm…ôsi Geolokasyonda v…ô Dialekt Kimlikl…ôrind…ô sńĪnaqlar', 'bn': 'ভাষার ভেরিটি গোলোকশন এবং ডায়ালেক্ট পরীক্ষা', 'fi': 'Kokeet kielilajikkeiden geolokaatiossa ja dialektitunnistuksessa', 'cs': 'Experimenty v geolokaci jazykových odrůd a identifikaci dialektů', 'sk': 'Eksperimenti na področju geolokacije jezikovnih raznolikosti in identifikacije dialektov', 'he': 'ניסויים בגיאומיקציה של שונים שפות ובזיהוי חיבור', 'jv': 'Miscellaneous', 'bo': 'སྐད་ཡིག་རྒྱུན་ལྡན་སྒྲིག་དང་བཀོད་རྟགས་དམིགས་འཛུགས་ནང་གི་བརྟག་དཔྱད་ཞིབ', 'ha': 'KCharselect unicode block name'}
{'en': 'In this paper we describe the systems we used when participating in the VarDial Evaluation Campaign organized as part of the 7th workshop on ', 'ar': 'في هذه الورقة ، نصف الأنظمة التي استخدمناها عند المشاركة في حملة تقييم VarDial التي تم تنظيمها كجزء من ورشة العمل السابعة حول البرمجة اللغوية العصبية للغات وأنواع ولهجات مماثلة. كانت المهام المشتركة التي شاركنا فيها هي الإصدار الثاني من تعريف اللهجة الرومانية (RDI) والإصدار الأول من موقع Social Media Variety Geolocation (SMG). استخدمت الطلبات المقدمة من فريق SUKI لدينا نماذج لغة توليدية تستند إلى Naive Bayes و n-grams.', 'pt': 'Neste artigo descrevemos os sistemas que usamos ao participar da Campanha de Avaliação VarDial organizada como parte do 7º workshop sobre PNL para línguas, variedades e dialetos semelhantes. As tarefas compartilhadas em que participamos foram a segunda edição da Identificação do Dialeto Romeno (RDI) e a primeira edição da Geolocalização de Variedade de Mídia Social (SMG). As submissões de nossa equipe SUKI usaram modelos de linguagem generativa baseados em Naive Bayes e n-grams de caracteres.', 'fr': "Dans cet article, nous décrivons les systèmes que nous avons utilisés lors de notre participation à la campagne d'évaluation VarDial organisée dans le cadre du 7ème atelier sur la PNL pour des langues, des variétés et des dialectes similaires. Les tâches communes auxquelles nous avons participé étaient la deuxième édition du Romanian Dialect Identification (RDI) et la première édition de la Social Media Variety Geolocation (SMG). Les soumissions de notre équipe SUKI ont utilisé des modèles de langage génératifs basés sur le bayésien naïf et les n-grammes de caractères.", 'es': 'En este artículo describimos los sistemas que utilizamos al participar en la Campaña de Evaluación VarDial organizada como parte del 7º taller sobre PNL para idiomas, variedades y dialectos similares. Las tareas compartidas en las que participamos fueron la segunda edición de la Identificación de Dialectos Rumanos (RDI) y la primera edición de Social Media Variety Geolocation (SMG). Las presentaciones de nuestro equipo de SUKI utilizaron modelos de lenguaje generativos basados en Naive Bayes y n-gramas de caracteres.', 'ja': '本稿では、類似の言語、品種、方言のための第7回NLPワークショップの一環として開催されたVarDial評価キャンペーンに参加した際に使用したシステムについて説明します。私たちが参加した共有タスクは、ルーマニア方言識別（ RDI ）の第2版とソーシャルメディアバラエティジオロケーション（ SMG ）の第1版でした。SUKIチームの提出物は、Naive Bayesと文字n - gramsに基づいた生成言語モデルを使用しました。', 'hi': 'इस पेपर में हम उन प्रणालियों का वर्णन करते हैं जिनका उपयोग हमने समान भाषाओं, किस्मों और बोलियों के लिए एनएलपी पर 7 वीं कार्यशाला के हिस्से के रूप में आयोजित VarDial मूल्यांकन अभियान में भाग लेते समय किया था। जिन साझा कार्यों में हमने भाग लिया, वे रोमानियाई बोली पहचान (आरडीआई) के दूसरे संस्करण और सोशल मीडिया वैरायटी जियोलोकेशन (एसएमजी) के पहले संस्करण थे। हमारी SUKI टीम की प्रस्तुतियों ने भोले Bayes और चरित्र n-grams के आधार पर उत्पादक भाषा मॉडल का उपयोग किया।', 'zh': '本文中,述我等VarDial估用之统,当动为第7届类言语,品种与方言NLP研讨会之一体。 所与共同任务者,罗马尼亚方言识(RDI)之第二版,与社交媒体综艺定位(SMG)之第一版。 吾SUKI团队提交,基于朴素贝叶斯与字符n-gram生成语体。', 'ru': 'В этой статье мы описываем системы, которые мы использовали при участии в кампании по оценке VarDial, организованной в рамках 7-го семинара по NLP для аналогичных языков, разновидностей и диалектов. Мы приняли участие во втором издании румынской диалектной идентификации (RDI) и первом издании социологической геолокации в социальных сетях (SMG). В представлениях нашей команды SUKI использовались генеративные языковые модели, основанные на наивных байесовских и символьных n-граммах.', 'ga': 'Sa pháipéar seo déanaimid cur síos ar na córais a d’úsáideamar agus muid rannpháirteach san Fheachtas Measúnaithe VarDial a eagraíodh mar chuid den 7ú ceardlann ar NLP do theangacha, cineálacha agus canúintí comhchosúla. Ba iad na tascanna comhroinnte ar ghlacamar páirt iontu ná an dara eagrán de Shainaithint Canúint na Rómáine (RDI) agus an chéad eagrán de Geolocation Chineálacha na Meán Sóisialta (SMG). Bhain aighneachtaí ár bhfoireann SUKI úsáid as múnlaí teanga giniúna bunaithe ar Naive Bayes agus carachtar n-gram.', 'ka': 'ამ დომენტში ჩვენ გამოიყენეთ სისტემები, როდესაც გარედიალური განსაზღვრება კამპანიაში დავყენებულია, როდესაც NLP-ის 7-ი სამუშაო სამუშაო დაფართებული იგივე ენები, განსხვავებები ჩვენ დავწევეთ სოციალური სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამ ჩვენი SUKI კომპონდის შესახებ გამოიყენება გენერაციური ენის მოდელები Naive Bayes და n-grams.', 'hu': 'Ebben a tanulmányban bemutatjuk azokat a rendszereket, amelyeket használtunk a hasonló nyelvek, fajták és dialektusok NLP-jéről szóló 7. workshop keretében megrendezett VarDial Értékelési Kampányban. A megosztott feladatok között részt vettünk a Román Dialekt Identification (RDI) második kiadása és a Social Media Variety Geolocation (SMG) első kiadása volt. SUKI csapatunk beadványai Naive Bayes és karakter n-grammok alapján generációs nyelvi modelleket használtak.', 'el': 'Στην παρούσα εργασία περιγράφουμε τα συστήματα που χρησιμοποιήσαμε όταν συμμετέχαμε στην καμπάνια αξιολόγησης που διοργανώθηκε στο πλαίσιο του 7ου εργαστηρίου για παρόμοιες γλώσσες, ποικιλίες και διαλέκτους. Τα κοινά καθήκοντα στα οποία συμμετείχαμε ήταν η δεύτερη έκδοση του Ρουμανικού Διαλέκτου Αναγνώρισης (ΠΕΑ) και η πρώτη έκδοση του Γεωεντοπισμού Ποικιλιών Κοινωνικών Μέσων (SMG). Οι υποβολές της ομάδας μας χρησιμοποίησαν παραγωγικά μοντέλα γλώσσας βασισμένα σε αφελές Μπέγιες και γραφήματα χαρακτήρων.', 'it': "In questo articolo descriviamo i sistemi utilizzati durante la partecipazione alla campagna di valutazione VarDial organizzata nell'ambito del 7° workshop sulla PNL per lingue, varietà e dialetti simili. I compiti condivisi a cui abbiamo partecipato sono stati la seconda edizione della Romanian Dialect Identification (RDI) e la prima edizione della Social Media Variety Geolocation (SMG). Le proposte del nostro team SUKI hanno utilizzato modelli di linguaggio generativi basati su Naive Bayes e caratteri n-grammi.", 'mk': 'Во овој весник ги опишуваме системите кои ги користевме кога учествувавме во кампањата за евалуација на Вардијал организирана како дел од седмиот работилник за НЛП за слични јазици, различности и дијалекти. Соделените задачи на кои учествувавме беа второто издание на романската дијалектна идентификација (РДИ) и првото издание на геолокацијата на социјалните медиуми (СМГ). Пренесувањата на нашиот тим СУКИ користеа генеративни јазички модели базирани на Naive Bayes и карактер n-грам.', 'kk': 'Бұл қағазда біз VarDial оқу кампаниясында NLP жұмысының 7- ші жұмысының бөлігіне ұқсас тілдер, түрлі және диалекттер үшін қолданған жүйелерді таңдап көрдік. Біз қатысушыларымызды ортақтастырған тапсырмалар Румындық диалекті идентификациясы (RDI) және социалдық медиа айнымалылық географиясы (SMG) алғашқы шығаруы. SUKI командамыздың жіберілімі Naive Bayes мен n-граммалардың негізінде жалпы тіл моделдерін қолданады.', 'lt': 'Šiame dokumente apibūdinamos sistemos, kurias naudojome dalyvaujant VarDial vertinimo kampanijoje, surengtoje kaip 7-ojo seminaro dėl NLP panašioms kalboms, veislėms ir dialektams dalis. Bendros užduotys, kuriose dalyvavome, buvo antrasis Rumunijos dialekto identifikavimo (RDI) leidimas ir pirmasis socialinių žiniasklaidos veislių geolokacijos (SMG) leidimas. Mūsų SUKI komandos pareiškimai naudojo generacinius kalbų modelius, pagrįstus Naive Bayes ir n-gramais.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഉപയോഗിക്കുന്ന സിസ്റ്റത്തെ വിവരിക്കുന്നു. വാര്\u200dഡിയല്\u200d എവിലൂഷന്\u200d ക്യാമ്പെയിനില്\u200d പങ്കെടുക്കുമ്പോള്\u200d നമ്മള്\u200d എംഎല്\u200dപി ഞങ്ങള്\u200d പങ്കുചേര്\u200dന്ന ജോലികള്\u200d റോമാനിയന്\u200d ഡയലക്ട്രിക്ക് തിരിച്ചറിയുന്നതിന്റെ രണ്ടാമത്തെ എഴുതിയ രണ്ടാമത്തെ എഴുതിയിരുന്നു. സോഷ്യല്\u200d മീ നമ്മുടെ SUKI ടീമിന്റെ കീഴടങ്ങള്\u200d നാവ് ബെയ്സിന്റെ അടിസ്ഥാനമായി ജനററിവ് ഭാഷ മോഡലുകള്\u200d ഉപയോഗിച്ചിരുന്നു.', 'mt': 'F’dan id-dokument niddeskrivu s-sistemi li ntużaw meta pparteċipaw fil-Kampanja ta’ Evalwazzjoni VarDial organizzata bħala parti mis-7 workshop dwar NLP għal lingwi, varjetajiet u dijaletti simili. Il-kompiti kondiviżi li pparteċipawna fihom kienu t-tieni edizzjoni tal-Identifikazzjoni tad-Djalett Rumen (RDI) u l-ewwel edizzjoni tal-Ġeolokazzjoni tal-Varjetà tal-Midja Soċjali (SMG). The submissions of our SUKI team used generative language models based on Naive Bayes and character n-grams.', 'ms': 'Dalam kertas ini kami menggambarkan sistem yang kami gunakan bila berpartisipasi dalam Kampanye Evaluasi VarDial yang dirancang sebagai sebahagian dari workshop ke-7 tentang NLP untuk bahasa, jenis dan dialekt yang sama. Tugas berkongsi yang kami hadapi ialah edisi kedua Identifikasi Dialeksi Romania (RDI) dan edisi pertama Geolokasi Variasi Media Sosial (SMG). The submissions of our SUKI team used generative language models based on Naive Bayes and character n-grams.', 'mn': 'Энэ цаасан дээр бид VarDial Evaluation Campaign-д NLP-ийн 7-р ажлын нэг хэсэг, төрлийн, диалектуудын тулд зохион байгуулагдсан системийг тайлбарлаж байна. Бидний оролцсон ажил нь Румын диалект идентификацийн (RDI) хоёр дахь хувилбар, нийгмийн Media Variety Geolocation (SMG) хоёр дахь хувилбар юм. Бидний СУКИ багийн сургалтын дараа Naive Bayes болон n-грамм дүрслэлүүд дээр бий болгон хэл загварыг ашигладаг.', 'no': 'I denne papiret beskriver vi systemene vi bruka når vi deltar i VarDial Evalueringskampanjen organisert som del av 7. arbeidsområdet på NLP for liknande språk, variasjonar og dialektar. Den delte oppgåva vi delta i var den andre utgåva av Romaniske Dialect Identifikasjonen (RDI) og den første utgåva av den sosiale media variatet Geolocation (SMG). Subduksjonen av SUKI-gruppa vår brukte genererte språk-modeller basert på Naive Bayes og teikn n-gramar.', 'pl': 'W niniejszym artykule opisano systemy, z których korzystaliśmy podczas uczestnictwa w kampanii ewaluacyjnej VarDial organizowanej w ramach siódmego warsztatu NLP dla podobnych języków, odmian i dialektów. Wspólne zadania, w których uczestniczyliśmy, to druga edycja rumuńskiej identyfikacji dialektu (RDI) oraz pierwsza edycja geolokalizacji odmian mediów społecznościowych (SMG). W zgłoszeniach naszego zespołu SUKI wykorzystano generatywne modele językowe oparte na Naive Bayes i n-gramach znaków.', 'ro': 'În această lucrare descriem sistemele pe care le-am folosit atunci când am participat la campania de evaluare VarDial organizată în cadrul celui de-al 7-lea atelier privind PNL pentru limbi, soiuri și dialecte similare. Sarcinile comune la care am participat au fost cea de-a doua ediție a Identificarea Dialectului Românesc (RDI) și prima ediție a Geolocației Varietăților Social Media (SMG). Subscrierile echipei SUKI au folosit modele lingvistice generative bazate pe Naive Bayes și n-grame de caractere.', 'sr': 'U ovom papiru opisujemo sisteme koje smo koristili kada smo sudjelovali u kampanji za evaluaciju VarDial organizovanoj kao deo sedmog radionice na NLP-u za slične jezike, raznolike i dijalekte. Podijeljeni zadatak u kojima smo učestvovali su drugo izdanje Rumunjske identifikacije dijalekta (RDI) i prvo izdanje geolokacije socijalnih medija varijanta (SMG). Podaci našeg SUKI tima koristili su generične jezičke modele na osnovu Naive Bayes i karaktera n-grama.', 'si': 'මේ පත්තරේ අපි භාවිතා කරපු පද්ධතිය ප්\u200dරවේශනය කරනවා වර්ඩියල් විශ්ලේෂණ කැමැන්පේන් වල NLP වල 7වෙනි වැඩසටහනයේ කොටසක් විදිහට ස අපි සම්බන්ධ වැඩක් කරලා තියෙන්නේ රෝමානියාන් ඩායියාලෙක්ට් අඳුරණය (RDI) සහ සාමාජික මාධ්\u200dයාත්මක භූතිකාරණය ( අපේ SUKI කණ්ඩායමේ පිළිගන්න පුළුවන් නේව් බේස් සහ අක්ෂර n-ග්\u200dරාම්ස් අධාරිත භාෂාවක් නිර්මාණය කර', 'so': 'Qoraalkan waxaan ku qornaa nidaamka aan isticmaalnay marka aan ka qeyb galno Campaign Evaluation VarDial (VarDial evaluation campaign) oo loo qabanqaabiyey kamid ah warqadda todobaad ee NLP ku qoran luuqado isku mid ah, kala duwan iyo luuqado kala duduwan. Shaqooyinkii aan ka qeybqaaday waa labaad oo ka mid ah aqoonsiga (RDI) Romanian Dialect (RDI) iyo qeybtii ugu horraysay ee Maamulka sooshaalka ee Variety Geolocation (SMG). Furiinka kooxda SUKI waxay isticmaaleen tusaalooyin afka dhalashada oo ku saleysan Naive Bayes iyo xaraf n-gram.', 'sv': 'I denna uppsats beskriver vi de system vi använde när vi deltog i VarDial Evaluation Campaign som en del av den 7:e workshopen om NLP för liknande språk, sorter och dialekter. De gemensamma uppgifterna vi deltog i var den andra utgåvan av Rumänska Dialect Identification (RDI) och den första utgåvan av Social Media Variety Geolocation (SMG). I inlämningarna från vårt SUKI-team användes generativa språkmodeller baserade på Naive Bayes och tecken n-gram.', 'ta': 'இந்த காகிதத்தில் நாம் பயன்படுத்தும் அமைப்புகளை விவரிக்கிறோம் மற்றும் போன்ற மொழிகள், வேறுபாடுகள் மற்றும் விளக்கும் பொழுது NLP மீது ஏழாவது  நாங்கள் பங்கிட்ட பணிகளில் பங்கிடப்பட்டது ரோமானியன் உரையாடல் அடையாளத்தின் இரண்டாவது தொகுப்பாக இருந்தது மற்றும் சமூக ஊடகங்களின் முதல் பகுதி எங்கள் SUKI குழுவின் கூறுகள் நாவ் பேய்ஸ் மற்றும் எழுத்து n-கிராம் அடிப்படையில் பொதுவான மொழி மாதிரிகளை பயன்பட', 'ur': 'ہم اس کاغذ میں ایسی زبانوں، مختلف اور دیالکسٹوں کے لئے سات ویرڈیل ارکس کمپن میں مشارکت کی حالت میں استعمال کیا کرتے تھے۔ ہم نے مشترک کاموں میں شامل کیا تھا رومانی ڈائیلٹ شناسیٹ (RDI) کے دوسرے ایڈیٹ اور سوسیل میڈیا ویریٹ جئوٹ (SMG) کی پہلی ایڈیٹ۔ ہمارے SUKI ٹیم کی تحویل نے Naive Bayes اور character n-grams پر بنیاد رکھے ہوئے ژنرائیٹ زبان مدل استعمال کیا۔', 'uz': "Bu hujjatda, biz o'xshash tillar, har xil va dialeklar uchun VarDial Evaluation Campaign (VarDial Evaluation Campaign) ta'minlovchi tizimlarni anglatamiz. Biz o'rganilgan vazifalarning birinchi darajasi - Romaniya Dialect Identification (RDI) va Social Media Variety Geolocation (SMG) birinchi taʼminoti. Name", 'vi': 'Trong tờ giấy này, chúng tôi mô tả những hệ thống chúng tôi dùng khi tham gia chiến dịch Đáng giá VarDial, được tổ chức như một phần của hội thảo thứ bảy về ngôn ngữ, biến sắc và phương ngữ tương tự. Các công việc chia sẻ chúng tôi tham gia là phiên bản thứ hai của Thẻ Điện thoại Romani (RDI) và phiên bản đầu tiên của địa điểm địa lý sản sản vật chất Cách mạng xã hội (SMG). Những kiến nghị của đội SUKI đã sử dụng các mô phỏng ngôn ngữ tạo hóa dựa trên Naive Bayes và ký tự n-grams.', 'da': 'I denne artikel beskriver vi de systemer, vi brugte, da vi deltog i VarDial Evaluation Campaign organiseret som en del af den 7. workshop om NLP for lignende sprog, sorter og dialekter. De delte opgaver, vi deltog i, var den anden udgave af den rumænske dialektidentifikation (RDI) og den første udgave af Social Media Variety Geolocation (SMG). Indsendelserne fra vores SUKI team brugte generative sprogmodeller baseret på Naive Bayes og karakter n-grams.', 'bg': 'В настоящата статия описваме системите, които използвахме при участието си в Кампанията за оценка организирана като част от Седмия семинар за НЛП за сходни езици, разновидности и диалекти. Споделените задачи, в които участвахме, бяха второто издание на Румънската диалектна идентификация (ИРДИ) и първото издание на Социалните медии Геолокация на сортовете. Подаванията на нашия екип използваха генеративни езикови модели, базирани на наивния Байес и символ n-грама.', 'hr': 'U ovom papiru opisujemo sustave koje smo koristili kada smo sudjelovali u kampanji za procjenu varDial organiziranoj kao dio sedmog radionice na NLP-u za slične jezike, raznolike i dijalekte. Podjeljeni zadatak u kojima smo učestvovali bili su drugo izdanje Rumunjske identifikacije dijalekta (RDI) i prvo izdanje Geolokacije socijalnih medija varijanta (SMG). Podaci našeg SUKI tima koristili su generične jezičke modele na temelju Naive Bayes i karaktera n-grama.', 'nl': 'In dit artikel beschrijven we de systemen die we gebruikten bij deelname aan de VarDial Evaluatie Campaign georganiseerd als onderdeel van de 7e workshop over NLP voor vergelijkbare talen, variëteiten en dialecten. De gedeelde taken waaraan we deelnamen waren de tweede editie van de Roemeense Dialect Identification (RDI) en de eerste editie van de Social Media Variety Geolocation (SMG). De inzendingen van ons SUKI team gebruikten generatieve taalmodellen gebaseerd op naïeve Bayes en karakter n-grammen.', 'fa': 'در این کاغذ سیستم\u200cهایی را که در زمان شرکت در کمپانی ارزیابی VarDial برای زبان، گونه\u200cها و دیالکت\u200cهای مشابه استفاده کردیم، توصیف می\u200cکنیم. وظیفه\u200cهای مشترک که در آن شرکت کردیم، دومین نسخهٔ شناسایی دایلاکت رومانی (RDI) و اولین نسخهٔ جغرافیت متعدد رسانه\u200cهای اجتماعی (SMG) بود. تحويل تيم SUKI ما از مدل هاي ژنراتي زبان بوسيله بيز نائي و شخصيت n گرم استفاده مي کردند.', 'de': 'In diesem Beitrag beschreiben wir die Systeme, die wir bei der Teilnahme an der VarDial Evaluation Campaign im Rahmen des siebten Workshops zu NLP für ähnliche Sprachen, Sorten und Dialekte verwendet haben. Die gemeinsamen Aufgaben, an denen wir teilgenommen haben, waren die zweite Ausgabe der rumänischen Dialektidentifikation (RDI) und die erste Ausgabe der Social Media Variety Geolocation (SMG). Die Einreichungen unseres SUKI-Teams verwendeten generative Sprachmodelle basierend auf naiven Bayes und Zeichen n-Gramm.', 'sw': 'Katika karatasi hii tunaelezea mifumo tuliyotumia wakati tunashiriki katika kampeni ya Uchunguzi wa VarDial iliyoandaliwa kama sehemu ya warsha ya 7 kwenye NLP kwa lugha hizo, tofauti na lugha hizo. Kazi tulizoshiriki zilikuwa ni toleo la pili la utambulisho wa Dialeka ya Romania (RDI) na toleo la kwanza la Uchaguzi wa Mitandao ya Kijamii (SMG). Mawasiliano ya timu yetu ya SUKI yalitumia mifano ya lugha yenye msingi wa Naive Bayes na wahusika n-gram.', 'id': 'Dalam kertas ini kami menggambarkan sistem yang kami gunakan ketika berpartisipasi dalam Kampanye Evaluasi VarDial yang terorganisir sebagai bagian dari workshop ke-7 tentang NLP untuk bahasa, varietas dan dialekt yang sama. Tugas-tugas yang kami partai adalah edisi kedua Identifikasi Dialek Rumania (RDI) dan edisi pertama dari Geolokasi Varietis Media Sosial (SMG). Pengiriman tim SUKI kami menggunakan model bahasa generatif berdasarkan Naive Bayes dan karakter n-gram.', 'tr': "Bu kagyzda biz VarDial Taýýarlama kampanyasynda NLP'yň 7-nji Workshop bolup meňzeş diller, çeşitler we dialektler üçin ullanýan sistemalary tassyklaýarys. Biziň goşuşymyz ýerleşýän zadlarymyz Rumyniýanyň Dialect Identifikasiýasy (RDI) we Sosial Media Çeşitlikleri Geolocation (SMG) iň birinji basyşymyzdyr. SUKI topamyzyň göndermeleri Naive Bayes we karakter n-gramlaryna daýanýan ýagdaý dil nusgalaryny ulandylar.", 'ko': '본고에서 우리는 VarDial 평가 활동에 참여할 때 사용하는 시스템을 묘사했다. 이 활동은 제7회 NLP 세미나의 일부로 조직된 것으로 이 세미나는 유사한 언어, 변체와 사투리를 대상으로 한다.우리가 참여한 공동 임무는 루마니아 사투리인식(RDI) 2판과 소셜미디어 다양성 지리적 포지셔닝(SMG) 1판이다.우리 슈키팀이 제출한 자료는 박소 베일스와 캐릭터 n-gram을 기반으로 한 생성적 언어 모델을 사용했다.', 'af': 'In hierdie papier beskryf ons die stelsels wat ons gebruik het wanneer gedeeltel word in die VarDial Evaluering Kampanie wat as deel van die 7de werkshop op NLP georganiseer is vir vergelykbare tale, veranderinge en dialekte. Die gedeelde taak in wat ons gedeel het, was die tweede uitgewing van die Romaniese Dialeksie Identifikasie (RDI) en die eerste uitgewing van die Soziale Media Veranderlike Geoligging (SMG). Die onderstellings van ons Suki-team gebruik genereerde taal modele gebaseer op Naive Bayes en karakter n-grame.', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք այն համակարգերը, որոնք մենք օգտագործեցինք, երբ մասնակցեցինք Վարդիալ գնահատման քարոզարշավին, որը կազմակերպել է որպես ՆԼՊ-ի 7-րդ դասընթացի մաս նման լեզուների, բազմազանությունների և դիալեկտների համար Մենք մասնակցում էինք Ռոմանական դիալեկտի ինքնության երկրորդ հրատարակությանը և սոցիալական լրատվամիջոցների բազմազանության երկրորդ հրատարակությանը: The submissions of our SUKI team used generative language models based on Naive Bayes and character n-grams.', 'sq': 'Në këtë letër i përshkruajmë sistemet që përdorëm kur morëm pjesë në kampanjën e vlerësimit të VarDial të organizuar si pjesë e seminarit të shtatë mbi NLP për gjuhë të ngjashme, varietet dhe dialekte. Detyrat e përbashkëta në të cilat morëm pjesë ishin edicioni i dytë i Identifikimit të Dialektit Rumun (RDI) dhe edicioni i parë i Gjeolokacionit të Varietit të Mediave Sociale (SMG). Subjektet e ekipit tonë SUKI përdorën modele gjuhësh gjenerative bazuar n ë Naive Bayes dhe karakter n-gram.', 'bn': 'এই কাগজটিতে আমরা ব্যবহার করা ব্যবস্থাগুলো বর্ণনা করি যখন ভার্ডায়াল ইভায়ালুয়েশন প্রচারাভিযানে অংশগ্রহণ করা হয়, এনএলপির ৭ তম কর্মশালার অংশ হিসেবে এন আমরা যে কাজে অংশগ্রহণ করেছিলাম তা হল রোমানিয়ান ডায়ালেক্ট পরিচয়পত্রের দ্বিতীয় সংস্করণ এবং সামাজিক মিডিয়া ভেরিটি জিওলোকশন (এসএমজি) এর প্র আমাদের SUKI দলের প্রতিবেদন নাইভ বেইস এবং অক্ষর n-গ্রামের ভিত্তিতে জেনারেটিভ ভ ভাষা মডেল ব্যবহার করেছে।', 'bs': 'U ovom papiru opisujemo sisteme koje smo koristili kada smo sudjelovali u kampanji za procjenu varDial organizovanoj kao dio sedmog radionice na NLP-u za slične jezike, raznolike i dijalekte. Podijeljeni zadatak u kojima smo učestvovali su drugo izdanje Rumunjske identifikacije dijalekta (RDI) i prvo izdanje geolokacije socijalnih medija varijanta (SMG). Podaci našeg SUKI tima koristili su generične jezičke modele na osnovu Naive Bayes i karaktera n grama.', 'am': 'In this paper we describe the systems we used when participating in the VarDial Evaluation Campaign organized as part of the 7th workshop on NLP for similar languages, varieties and dialects.  በተካፈሉት ስራዎች የሮማኒያን ዳሌክት (RDI) እና የማኅበራዊ ሚዲያ ሚዲያዎች መጀመሪያ ክፍል (SMG) ነው፡፡ የSUKI ብሔራችንን የናይብ ባይስ እና የ-ግራም ግንኙነት በተመሳሳይ የቋንቋ ምሳሌዎችን ተጠቃሚ፡፡', 'az': "Bu kağıtda, NLP'nin 7-ci çalışmalarının bir parças ı olaraq, bənzər dillər, müxtəlif və dialektlər üçün istifadə etdiyimiz sistemləri təsdiqləyirik. Bizim paylaşdığımız işlər Rumun Dialect Identification (RDI) və Sosyal Media Variety Geolocation (SMG) ilk dəyişikliyinin ikinci dəyişikliyi idi. SUKI ekibimizin təbliğ edilməsi Naive Bayes və karakter n-gramlarına dayanan n ütfə dil modellərini kullandı.", 'et': "Käesolevas töös kirjeldame süsteeme, mida kasutasime osaledes VarDiali hindamiskampaanias, mis korraldati osana seitsmendast NLP-i töötoast sarnastele keeltele, sortidele ja murretele. Ühised ülesanded, milles osalesime, olid Rumeenia dialekti identifitseerimise (RDI) teine väljaanne ja sotsiaalmeedia variety geolokatsiooni (SMG) esimene väljaanne. Meie SUKI meeskonna töös kasutati generatiivseid keelemudeleid, mis põhinevad Naive Bayes'il ja märgi n-grammidel.", 'fi': 'Tässä artikkelissa kuvataan järjestelmiä, joita käytimme osallistuessamme VarDial-arviointikampanjaan, joka järjestettiin osana 7. työpajaa, jossa käsiteltiin samankaltaisia kieliä, lajikkeita ja murteita. Yhteiset tehtävät, joihin osallistuimme, olivat Romanian Dialect Identification (RDI) toinen painos ja Social Media Variety Geolocation (SMG) ensimmäinen painos. SUKI-tiimimme toimituksissa käytettiin generatiivisia kielimalleja, jotka perustuivat Naive Bayesiin ja merkin n-grammiin.', 'ca': 'In this paper we describe the systems we used when participating in the VarDial Evaluation Campaign organized as part of the 7th workshop on NLP for similar languages, varieties and dialects.  Les tasques comunes en les que vam participar eren la segona edició de la Identificació Dialectual Rumena (RDI) i la primera edició de la Geolocalització de la Varietat de Medis Socials (SMG). The submissions of our SUKI team used generative language models based on Naive Bayes and character n-grams.', 'cs': 'V tomto článku popisujeme systémy, které jsme použili při účasti na VarDial Evaluation Campaign organizované v rámci sedmého workshopu NLP pro podobné jazyky, odrůdy a dialekty. Společné úkoly, kterých jsme se podíleli, byly druhé vydání rumunské dialektové identifikace (RDI) a první vydání odrůdy sociálních médií (SMG). Příspěvky našeho SUKI týmu používaly generativní jazykové modely založené na Naivním Bayesovi a znakových n-gramech.', 'jv': 'Nang paper iki kita tasi sistem sing endi nggambar nggawe ngubah candi tanggal gawe ngubah cara-cara sing sampeyan karo sistem 7 ning NLP kanggo langgambar, cah-cah lan dialecta sing ngewehi. Awak dhéwé ngejaraké karo hal sing dirampakan tanggal dhéwé ning daerahé sing wis kelas telu nggawe diuwisan diaelect ID (RDN) lan nambah sing perusahaan ning ndaftar Media Varity General (SMG). Ombudhakan kelompok tarjamahan SUKii iki dadi model anyar nggawe barang-barêng basa kaya Nave bayes karo caratar n-gram', 'ha': "Daga wannan takarda, Munã bayyana wa'ura waɗanda muka yi amfani da su a lokacin da za'a yi shirin karatun na Shaidar Sura'anin NarDial da aka organize kamar rabon na 7 ɗin warsha kan NLP dõmin lugha, masu sãɓãni da diƙaitanci. The share of the tasks that we took part was the other edition of the Romian Dialate Idtion (RD) and the first edition of the Socio Media variariaty Geolocation (SMG). Tsarin da team na SUKI suka yi amfani da misãlai masu motsi na harshen Naive Bayes da karatun n-gram.", 'sk': 'V prispevku opisujemo sisteme, ki smo jih uporabljali pri sodelovanju v Evaluacijski kampanji VarDial, ki je bila organizirana v okviru 7. delavnice o NLP za podobne jezike, sorte in narečja. Skupne naloge, pri katerih smo sodelovali, sta bila druga izdaja romunske identifikacije dialektov (RDI) in prva izdaja geolokacije sort socialnih medijev (SMG). Prispevki naše ekipe SUKI so uporabljali generativne jezikovne modele, ki temeljijo na Naive Bayes in znakov n-gramih.', 'he': 'בעיתון הזה אנחנו מתארים את המערכות שהשתמשנו בהחלטה בקמפיין הערכה VarDial מאורגנת כחלק מהסדן השביעי על NLP לשפות, מגוונים ודיאלקטים דומות. המשימות המשותפות שבהן השתתפנו היו הדורה השנייה של זיהוי הדיאלקט הרומני (RDI) והדורה הראשונה של גיאולוקציה של מגוון מדיה החברתית (SMG). ההעברות של צוות SUKI שלנו השתמשו בדוגמנים שפות יוצרות מבוססים על Naive Bayes ודמות n-גרם.', 'bo': 'In this paper we describe the systems we used when participating in the VarDial Evaluation Campaign organized as part of the 7th workshop on NLP for similar languages, varieties and dialects. The shared tasks we participated in the second edition of the Romanian Dialect Identification (RDI) and the first edition of the Social Media Variety Geolocation (SMG). ང་ཚོའི་SUKI དབང་མཁན་གྱི་མ་དབང་གིས་Naive Bayes་དང་ཁྱད་ཆོས་གྲངས་grams་གཞི་བརྟེན་ནས་སྐྱེས་པའི་སྐད་ཆ་རྣམ་པ་སྤྱོད'}
{'en': 'Exploring the Power of Romanian BERT for Dialect Identification', 'ar': 'استكشاف قوة BERT الرومانية لتحديد اللهجة', 'pt': 'Explorando o poder do BERT romeno para identificação de dialetos', 'es': 'Explorando el poder del BERT rumano para la identificación de dialectos', 'fr': "Explorer le pouvoir du BERT roumain pour l'identification des dialectes", 'ja': '方言識別のためのルーマニア・バート・エスターライヒ州の力の探求', 'hi': 'बोली पहचान के लिए रोमानियाई BERT की शक्ति की खोज', 'zh': '探罗马尼亚语BERT于方言之中', 'ru': 'Изучение силы румынского берта для идентификации диалекта', 'ga': 'Iniúchadh ar Chumhacht na Rómáine BERT um Shainaithint Canúintí', 'ka': 'პრომენური BERT-ის ძალიან დიალექტიკური იდენტიფიკაციისთვის გამოყენება', 'hu': 'A román BERT hatalmának feltárása a dialektus azonosítás terén', 'el': 'Εξερευνώντας τη δύναμη του ρουμανικού BERT για τον προσδιορισμό των διαλεκτών', 'lt': 'Rumunijos BERT įgaliojimų dialektiniam identifikavimui ištirimas', 'kk': 'Диалекті идентификациялау үшін Румыниялық BERT қуатын зерттеу', 'it': "Esplorare il potere del BERT rumeno per l'identificazione dialettica", 'mk': 'Истражувањето на моќта на романскиот БЕРТ за идентификација на дијалектите', 'ml': 'ഡയലക്റ്റ് തിരിച്ചറിയുന്നതിനുള്ള റോമാനിയന്\u200d ബെര്\u200dട്ടിയുടെ ശക്തി പരിശോധിക്കുന്നു', 'ms': 'Menjelaskan Kuasa BERT Romania untuk Pengenalan Dialeksi', 'mt': 'L-esplorazzjoni tas-setgħa tal-BERT Rumen għall-Identifikazzjoni tad-Djalett', 'mn': 'Румын БЕРТ-ын хүч чадварыг шалгах', 'pl': 'Badanie potęgi rumuńskiego BERT w zakresie identyfikacji dialektów', 'ro': 'Explorarea puterii BERT românești pentru identificarea dialectă', 'sr': 'Ispitivanje moći rumunskog BERT za identifikaciju dijalekta', 'no': 'Utforskar kraft på romensk BERT for dialektidentifisering', 'si': 'රෝමානිය BERT ශක්තිය පරීක්ෂණය කරන්න', 'so': 'Exploring the power of Romanian BERT for Dialect Identification', 'sv': 'Utforska kraften hos rumänska BERT för dialektidentifiering', 'ta': 'Name', 'ur': 'رومانی BERT کے طاقت کا تحقیق کرتا ہے', 'uz': 'Name', 'vi': 'Khám phá sức mạnh của cây đỗ nhỏ Romani để xác minh hình.', 'bg': 'Изследване на силата на румънския BERT за идентификация на диалекта', 'da': "Undersøgelse af rumænsk BERT's styrke til dialektidentifikation", 'hr': 'Ispitivanje moći rumunskog BERT za identifikaciju dijalekta', 'nl': 'De kracht van het Roemeense BERT voor dialectidentificatie verkennen', 'de': 'Die Macht des rumänischen BERT für Dialektidentifikation erforschen', 'id': 'Menjelaskan Kekuatan BERT Rumania untuk Identifikasi Dialek', 'ko': '루마니아어 BERT가 사투리 식별에서의 작용을 탐색하다', 'fa': 'تحقیق قدرت برق رومانی BERT برای شناسایی شناسایی', 'sw': 'Kuelezea nguvu ya BERT ya Romania kwa ajili ya kutambua Dialect', 'tr': "Romaniýan BERT'iň güýji sahypalar bejermek üçin", 'af': 'Ondersoek die Krag van Rumuniese BERT vir Dialeksie Identifikasie', 'am': 'የሮማኒያን BERT ኃይል ለDialect Identification', 'hy': 'Ռոմանացի BERT-ի ուժի ուսումնասիրելը', 'sq': 'Shqyrtimi i fuqisë së BERT rumune për identifikimin dialektik', 'az': 'Dialekt Kimlikl톛ri 칲칞칲n Rumun BERT g칲c칲n칲 t톛sdiql톛yici', 'bn': 'ডায়ালেক্ট পরিচয়ের জন্য রোমানিয়ান বার্টের শক্তি বিশ্লেষণ করা হচ্ছে', 'bs': 'Ispitivanje moći rumunskog BERT za identifikaciju dijalekta', 'ca': 'Explorar el poder del BERT rumun per identificar dialectes', 'cs': 'Zkoumání síly rumunského BERT pro identifikaci dialektů', 'et': 'Rumeenia BERTi võimu uurimine dialekti identifitseerimisel', 'fi': 'Romanian BERT:n voiman kartoittaminen dialektien tunnistamisessa', 'sk': 'Raziskovanje moči romunskega BERT za identifikacijo dialektov', 'jv': 'Ngubah Kemerdekaan Power of BERT rumani kanggo diaketahan', 'he': 'לחקור את כוחו של BERT רומני לזהות דיאלקט', 'ha': 'KCharselect unicode block name', 'bo': 'རོ་མ་ཡིན་BERT་གི་ནུས་པ་གནད་དོན་དམ་གསལ་བསལ་བྱེད་བཞིན་པ'}
{'en': 'Dialect identification represents a key aspect for improving a series of tasks, for example, ', 'ar': 'يمثل تحديد اللهجة جانبًا رئيسيًا لتحسين سلسلة من المهام ، على سبيل المثال ، التنقيب عن الرأي ، مع الأخذ في الاعتبار أن موقع المتحدث يمكن أن يؤثر بشكل كبير على الموقف تجاه موضوع ما. في هذا العمل ، نصف الأنظمة التي طورها فريقنا لـ VarDial 2020: تحديد اللهجة الرومانية ، وهي مهمة تم إنشاؤها خصيصًا لتحدي المشاركين لحل المشكلة المذكورة سابقًا. وبشكل أكثر تحديدًا ، نقدم سلسلة من الأنظمة العصبية المبنية على Transformers ، والتي تجمع بين نموذج BERT مدرب مسبقًا حصريًا على اللغة الرومانية مع تقنيات مثل التدريب على الخصومة أو حفلات الزفاف على مستوى الشخصية. باستخدام هذه الأساليب ، تمكنا من الحصول على 0.6475 درجة ماكرو F1 في مجموعة بيانات الاختبار ، مما سمح لنا بالحصول على المرتبة الخامسة من بين 8 فرق مشاركة.', 'pt': 'A identificação dialetal representa um aspecto fundamental para o aprimoramento de uma série de tarefas, por exemplo, mineração de opinião, considerando que a localização do falante pode influenciar muito a atitude em relação a um assunto. Neste trabalho, descrevemos os sistemas desenvolvidos por nossa equipe para o VarDial 2020: Identificação do Dialeto Romeno, uma tarefa criada especificamente para desafiar os participantes a resolver o problema mencionado anteriormente. Mais especificamente, apresentamos uma série de sistemas neurais baseados em Transformers, que combinam um modelo BERT exclusivamente pré-treinado na língua romena com técnicas como treinamento adversário ou embeddings em nível de personagem. Usando essas abordagens, conseguimos obter uma pontuação macro F1 de 0,6475 no conjunto de dados de teste, permitindo assim sermos classificados em 5º entre 8 equipes participantes.', 'es': 'La identificación de dialectos representa un aspecto clave para mejorar una serie de tareas, por ejemplo, la minería de opiniones, teniendo en cuenta que la ubicación del hablante puede influir en gran medida en la actitud hacia un sujeto. En este trabajo, describimos los sistemas desarrollados por nuestro equipo para VarDial 2020: Romanian Dialect Identification, una tarea creada específicamente para desafiar a los participantes a resolver el problema mencionado anteriormente. Más específicamente, presentamos una serie de sistemas neuronales basados en Transformers, que combinan un modelo BERT entrenado previamente exclusivamente en el idioma rumano con técnicas como el entrenamiento contradictorio o la incorporación a nivel de personaje. Al usar estos enfoques, pudimos obtener una puntuación macro F1 de 0.6475 en el conjunto de datos de la prueba, lo que nos permitió ubicarnos en el quinto lugar de los 8 equipos participantes.', 'fr': "L'identification des dialectes représente un aspect clé pour améliorer une série de tâches, par exemple, la recherche d'opinions, étant donné que la localisation du locuteur peut grandement influencer l'attitude envers un sujet. Dans ce travail, nous décrivons les systèmes développés par notre équipe pour VarDial 2020\xa0: identification du dialecte roumain, une tâche spécialement créée pour inciter les participants à résoudre le problème mentionné précédemment. Plus précisément, nous présentons une série de systèmes neuronaux basés sur Transformers, qui combinent un modèle BERT exclusivement pré-entraîné sur la langue roumaine avec des techniques telles que l'entraînement contradictoire ou l'intégration au niveau du personnage. En utilisant ces approches, nous avons pu obtenir un score macro F1 de 0,6475 sur le jeu de données de test, nous permettant ainsi d'être classés 5e sur 8 équipes participantes.", 'ja': '方言の識別は、話者の位置が対象に対する態度に大きく影響を与える可能性があることを考慮して、一連のタスク、例えばオピニオンマイニングを改善するための重要な側面を表しています。この作業では、VarDial 2020のためにチームが開発したシステムについて説明します。VarDial 2020:ルーマニア語の方言識別は、前述の問題を解決するために参加者に挑戦するために特別に作成されたタスクです。より具体的には、ルーマニア語で事前に訓練されたBERTモデルと、対抗訓練や文字レベルの埋め込みなどのテクニックを組み合わせた、Transformersに基づく一連のニューラルシステムを紹介します。これらのアプローチを使用することで、試験データセット上で0.6475のマクロF 1スコアを得ることができたため、8参加チーム中5位にランクインすることができた。', 'hi': 'बोली पहचान कार्यों की एक श्रृंखला में सुधार के लिए एक महत्वपूर्ण पहलू का प्रतिनिधित्व करती है, उदाहरण के लिए, राय खनन, यह देखते हुए कि स्पीकर का स्थान किसी विषय के प्रति दृष्टिकोण को बहुत प्रभावित कर सकता है। इस काम में, हम VarDial 2020 के लिए हमारी टीम द्वारा विकसित प्रणालियों का वर्णन करते हैं: रोमानियाई बोली पहचान, एक कार्य जो विशेष रूप से पहले उल्लिखित मुद्दे को हल करने के लिए प्रतिभागियों को चुनौती देने के लिए बनाया गया है। अधिक विशेष रूप से, हम ट्रांसफॉर्मर पर आधारित तंत्रिका प्रणालियों की एक श्रृंखला पेश करते हैं, जो एक BERT मॉडल को विशेष रूप से रोमानियाई भाषा पर पूर्व-प्रशिक्षित तकनीकों के साथ जोड़ते हैं जैसे कि प्रतिकूल प्रशिक्षण या चरित्र-स्तर के एम्बेडिंग। इन दृष्टिकोणों का उपयोग करके, हम परीक्षण डेटासेट पर 0.6475 मैक्रो एफ 1 स्कोर प्राप्त करने में सक्षम थे, इस प्रकार हमें 8 प्रतिभागी टीमों में से 5 वें स्थान पर रहने की अनुमति मिलती है।', 'zh': '方言识易事之要,如议发掘,虑言者之位可大加于主。 此言吾团队为VarDial 2020统:罗马尼亚方言知,此专为挑战参与者决之也。 更具体地说,引入一系变形金刚神经系统,将专对罗马尼亚语预练者BERT与抗练或字符级嵌入等技术相结合。 用此者,吾得0.6475于测试数据集上之宏观F1数,而使吾得排名第5于8参与者团队之中。', 'ru': 'Идентификация диалекта представляет собой ключевой аспект для улучшения ряда задач, например, интеллектуального анализа мнений, учитывая, что расположение говорящего может в значительной степени повлиять на отношение к субъекту. В этой работе мы описываем системы, разработанные нашей командой для VarDial 2020: Румынская диалектная идентификация, задача, специально созданная для вызова участников для решения ранее упомянутой проблемы. Более конкретно, мы представляем ряд нейронных систем на основе Трансформеров, которые объединяют модель BERT, предварительно подготовленную исключительно на румынском языке, с такими методами, как состязательное обучение или встраивание на уровне символов. Используя эти подходы, мы смогли получить 0,6475 макрос F1 в тестовом наборе данных, что позволило нам занять 5-е место из 8 команд-участников.', 'ga': 'Is príomhghné é sainaithint canúintí chun sraith tascanna a fheabhsú, mar shampla, mianadóireacht tuairimí, ag cur san áireamh gur féidir le suíomh an chainteora tionchar mór a imirt ar an dearcadh i leith ábhar. San obair seo, déanaimid cur síos ar na córais atá forbartha ag ár bhfoireann le haghaidh VarDial 2020: Aithint Canúint na Rómáine, tasc a cruthaíodh go sonrach chun dúshlán a thabhairt do rannpháirtithe an tsaincheist a luadh cheana a réiteach. Go sonrach, tugaimid isteach sraith de chórais néaracha atá bunaithe ar Trasfhoirmeoirí, a chomhcheanglaíonn samhail BERT atá réamh-oilte go heisiach ar an Rómáinis le teicníochtaí ar nós oiliúint sáraíochta nó leabaithe ar leibhéal na gcarachtar. Trí úsáid a bhaint as na cineálacha cur chuige seo, bhíomar in ann scór 0.6475 macra F1 a fháil ar an tacar sonraí tástála, rud a chuir ar ár gcumas a bheith sa 5ú háit as 8 bhfoireann rannpháirtí.', 'ka': 'დიალექტის ინდიდენტიფიკაცია გამოსახულებელია მნიშვნელოვანი აპექტირების გასაკეთებელი რაოდენობების სერიის გასაკეთებლად, მაგალითად, მისახულების გასაკეთებლად, რომლებიც მსოფლიოს ადგილი შე ამ სამუშაოში ჩვენ განვითარებით სისტემები, რომელიც ჩვენი ჯგუფი VarDial 2020-ის განვითარებულია: პომინური დიალექტის ინდიდენტიფიკაცია, რომელიც განსაკუთრებულად განვითარებულია განსაკუთრებული და უფრო განსაკუთრებულია, ჩვენ შევცვალოთ ნეიროლური სისტემებს ტრანფორმეტრების ბაზეულად, რომელიც BERT მოდელის გამოყენება მხოლოდ პრომენური ენაზე პრომენური ენაზე გამოყენებული ტექნექციებით,  გამოყენებით, ჩვენ შეგვიძლია მივიღოთ 0,6475 მაკრო F1 წერტილი ტესტის მონაცემების კონფიგურაციაში, რადგან ჩვენ შეგვიძლია მივიღოთ ხუთი წერტილი 8 მონაცემების კონფიგურაცია.', 'el': 'Ο προσδιορισμός διαλέκτων αντιπροσωπεύει μια βασική πτυχή για τη βελτίωση μιας σειράς καθηκόντων, για παράδειγμα, της εξόρυξης γνώμης, δεδομένου ότι η θέση του ομιλητή μπορεί να επηρεάσει σημαντικά τη στάση απέναντι σε ένα θέμα. Σε αυτή την εργασία, περιγράφουμε τα συστήματα που αναπτύχθηκαν από την ομάδα μας για το ένα έργο που δημιουργήθηκε ειδικά για την πρόκληση των συμμετεχόντων για την επίλυση του προαναφερθέντος ζητήματος. Πιο συγκεκριμένα, εισάγουμε μια σειρά νευρωνικών συστημάτων βασισμένων σε μετασχηματιστές, τα οποία συνδυάζουν ένα μοντέλο που έχει εκπαιδευτεί αποκλειστικά στη ρουμανική γλώσσα με τεχνικές όπως η αντίπαλη εκπαίδευση ή η ενσωμάτωση σε επίπεδο χαρακτήρων. Χρησιμοποιώντας αυτές τις προσεγγίσεις, καταφέραμε να επιτύχουμε μια μακροβαθμολογία 0.6475 στο σύνολο δεδομένων δοκιμών, επιτρέποντας έτσι να κατατάξουμε 5η από τις 8 συμμετεχόμενες ομάδες.', 'hu': 'A dialekt azonosítás kulcsfontosságú szempont egy sor feladat fejlesztéséhez, például a véleménybányászathoz, figyelembe véve, hogy a beszélő helye nagymértékben befolyásolhatja a témához való hozzáállást. Ebben a munkában bemutatjuk a VarDial 2020 csapatunk által kifejlesztett rendszereket: Romániai Dialekt Identification céllal, amelyet kifejezetten a résztvevők számára készítettünk, hogy megoldják a fent említett problémát. Pontosabban olyan transzformátorokon alapuló neurális rendszerek sorozatát mutatjuk be, amelyek egy kizárólag román nyelven képzett BERT modellt kombinálnak olyan technikákkal, mint például az ellenséges tréning vagy karakterszintű beágyazás. Ezekkel a megközelítésekkel 0,6475 makro F1 pontszámot tudtunk elérni a tesztadatokban, így 8 résztvevő csapat közül 5. helyezésre kerülhettünk.', 'it': "L'identificazione dialettica rappresenta un aspetto chiave per migliorare una serie di compiti, ad esempio l'opinion mining, considerando che la posizione dell'oratore può influenzare notevolmente l'atteggiamento verso un soggetto. In questo lavoro, descriviamo i sistemi sviluppati dal nostro team per VarDial 2020: Romanian Dialect Identification, un compito appositamente creato per sfidare i partecipanti a risolvere il problema precedentemente menzionato. In particolare, introduciamo una serie di sistemi neurali basati su Transformers, che combinano un modello BERT esclusivamente pre-addestrato sulla lingua rumena con tecniche come l'allenamento avversario o embedding a livello di carattere. Utilizzando questi approcci, siamo stati in grado di ottenere un punteggio F1 macro 0,6475 sul set di dati del test, permettendoci così di essere al quinto posto su 8 squadre partecipanti.", 'lt': 'Dialeksinis identifikavimas yra pagrindinis aspektas gerinant kelis uždavinius, pavyzdžiui, nuomonės kasybą, atsižvelgiant į tai, kad kalbėjo vieta gali labai paveikti požiūrį į temą. Šiame darbe apibūdinamos sistemos, kurias sukūrė mūsų komanda „VarDial 2020“: Rumunijos dialekto identifikavimas, užduotis, konkrečiai sukurta iššūkiams keliantiems dalyviams spręsti anksčiau minėtą klausimą. Konkrečiau, įvedame įvairias nervų sistemas, grindžiamas Transformers, kurios derina BERT model į, išimtinai iš anksto apmokytą rumunų kalba, su tokiais metodais kaip priešingas mokymas ar charakteristikų įdėjimas. Naudodami šiuos metodus galėjome gauti 0,6475 makro F1 rezultatą bandymų duomenų rinkinyje, taip sudarant galimybę būti 5-oje iš 8 dalyvių komandų.', 'kk': 'Диалекті идентификациясы бірнеше тапсырмаларды жақсарту үшін кілт аспекті, мысалы, сұрақ балауы, сөйлейтінің орналасуы тапсырманың қатынасына көп әсер етеді деп ойлап тұрады. Бұл жұмыс ішінде біз "VarDial 2020" командасының жасалған жүйелерді түсіндіреміз: Румындық диалект идентификациясы, бұрынғы мәселеді шешу үшін қатысушыларды өзгерту үшін жасалған тапсырма. Көбірек түрлендірушерге негізделген невралдық жүйелерді келтіреміз. Бұл BERT үлгісін Румындағы тілде қарсы оқыту немесе таңбалардың деңгейіндегі ендіруі секілді техникаларды біріктіреді. Бұл жағдайларды қолдану үшін біз 0,6475 макро F1 нүктесін сынақтар жиынында алуға мүмкін болдық, сондықтан біз 8 қатысушылардың 5- ші нүктесіне мүмкіндік береміз.', 'ms': 'Pengenalan dialeks mewakili aspek kunci untuk meningkatkan seri tugas, misalnya penambangan pendapat, mengingat lokasi pembicara boleh mempengaruhi sikap terhadap subjek. Dalam kerja ini, kami menggambarkan sistem yang dikembangkan oleh pasukan kami untuk VarDial 2020: Identifikasi Dialek Romania, tugas yang dicipta secara khusus untuk menantang peserta untuk menyelesaikan isu yang disebut sebelumnya. Lebih khususnya, kami memperkenalkan satu siri sistem saraf berdasarkan Transformers, yang menggabungkan model BERT secara eksklusif dilatih pada bahasa Romania dengan teknik seperti latihan lawan lawan atau penerbangan aras aksara. Dengan menggunakan pendekatan ini, kami mampu mendapatkan skor 0.6475 makro F1 pada set data ujian, sehingga membenarkan kami menjadi peringkat ke-5 daripada 8 pasukan peserta.', 'mk': 'Идентификацијата на дијалектот претставува клучен аспект за подобрување на серијата задачи, на пример рудањето на мислењето, со оглед на тоа што локацијата на говорникот може да влијае на ставот кон тема. Во оваа работа ги опишуваме системите развиени од нашиот тим за Вардијал 2020: Романска идентификација на дијалектот, задача специфично создадена за предизвикувањето на учесниците да го решат претходно споменето прашање. Поконкретно, воведуваме серија нервни системи базирани на Трансформери, кои комбинираат модел БЕРТ ексклузивно предобучен на романскиот јазик со техники како што е противна обука или вградување на карактерско ниво. Со користење на овие пристапи, успеавме да добиеме 0,6475 макро Ф1 оценка на тестовите податоци, што ни овозможи да бидеме рангирани на петто место од 8 тимови учесници.', 'ml': 'Dialect identification represents a key aspect for improving a series of tasks, for example, opinion mining, considering that the location of the speaker can greatly influence the attitude towards a subject.  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മുടെ ടീമുകള്\u200d വാര്\u200dഡിയാള്\u200d 2020-ല്\u200d നിര്\u200dമ്മിക്കപ്പെട്ട സിസ്റ്റം വിവരിച്ചുകൊടുക്കുന്നു. റോമാനിയന്\u200d ഡയലേക്ക് തിരി കൂടുതല്\u200d പ്രത്യേകിച്ച്, ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനമായി ഒരു സിസ്റ്റം ന്യൂറല്\u200d സിസ്റ്റമുകളെ പരിചയപ്പെടുത്തുന്നു. അത് ഒരു ബെര്\u200dട്ടി മോഡല്\u200d മാത്രം മുന്\u200dപ്  ഈ വഴികള്\u200d ഉപയോഗിച്ച് ഞങ്ങള്\u200dക്ക് ടെസ്റ്റ് ഡാറ്റാസെറ്റില്\u200d 0.6475 മാക്രോ F1 സ്കോര്\u200d ലഭ്യമാക്കാന്\u200d കഴിഞ്ഞു. അതുകൊണ്ട് 8 പങ്കാളികള്\u200d ടീമ', 'mt': 'L-identifikazzjoni tad-dijalek tirrappreżenta aspett ewlieni għat-titjib ta’ sensiela ta’ kompiti, pereżempju, it-tħaffir tal-opinjonijiet fil-minjieri, meta wieħed iqis li l-post tal-kelliem jista’ jinfluwenza ħafna l-attitudni lejn suġġett. F’dan ix-xogħol, a ħna niddeskrivu s-sistemi żviluppati mit-tim tagħna għal VarDial 2020: Identifikazzjoni tad-Djaletti Rumeni, kompitu maħluq speċifikament għall-parteċipanti li jisfidaw biex isolvu l-kwistjoni msemmija qabel. B’mod aktar speċifiku, a ħna nintroduċu serje ta’ sistemi newrali bbażati fuq it-Transformers, li jikkombinaw mudell BERT esklussivament imħarreġ minn qabel fil-lingwa Rumena ma’ tekniki bħal taħriġ avversarju jew inkorporazzjonijiet fil-livell tal-karattru. Permezz ta’ dawn l-approċċi, inkunu kapaċi niksbu punteġġ ta’ 0.6475 makro F1 fuq is-sett tad-dejta tat-testijiet, u b’hekk ippermettuna li nkunu kklassifikati fil-ħames minn tmien timijiet parteċipanti.', 'pl': 'Identyfikacja dialektu stanowi kluczowy aspekt usprawnienia szeregu zadań, na przykład wydobywania opinii, biorąc pod uwagę, że lokalizacja mówcy może znacznie wpływać na stosunek do tematu. W niniejszej pracy opisujemy systemy opracowane przez nasz zespół dla VarDial 2020: Romanian Dialect Identification, zadanie stworzone specjalnie dla uczestników wymagających rozwiązania wspomnianego wcześniej problemu. W szczególności wprowadzamy serię systemów neuronowych opartych na Transformerach, które łączą model BERT wyłącznie wstępnie przeszkolony na języku rumuńskim z technikami takimi jak trening przeciwny czy osadzenia na poziomie postaci. Wykorzystując te podejścia, udało nam się uzyskać makro F1 0.6475 na zbiorze danych testowych, co pozwoliło nam być piątym miejscem spośród ośmiu zespołów uczestniczących.', 'ro': 'Identificarea dialectă reprezintă un aspect cheie pentru îmbunătățirea unei serii de sarcini, de exemplu, opinie mining, având în vedere că locația vorbitorului poate influența foarte mult atitudinea față de un subiect. În această lucrare, descriem sistemele dezvoltate de echipa noastră pentru VarDial 2020: Identificarea Dialectului Românesc, sarcină creată special pentru a provoca participanții să rezolve problema menționată anterior. Mai precis, introducem o serie de sisteme neuronale bazate pe Transformers, care combină un model BERT exclusiv pre-instruit pe limba română cu tehnici precum antrenamentul adversar sau încorporările la nivel de caracter. Folosind aceste abordări, am reușit să obținem un scor F1 macro de 0,6475 pe setul de date de testare, permițându-ne astfel să fim pe locul 5 din 8 echipe participante.', 'no': 'Dialect-identifikasjon representerer ein nøkkelaspekt for å forbedra ei serie oppgåver, for eksempel, minning av synleg oppgåver, ved å sjå på at staden for taleren kan veldig påvirke oppgåva mot ein emne. I denne arbeiden beskriver vi systemene som er utvikla av gruppa vår for VarDial 2020: Romaniske dialektidentifikasjon, eit oppgåve som er spesielt opprettet for å utfordre deltakarane for å løse det førre oppgåva. Meir spesifikke introduserer vi ei rekkje neuralsystemer basert på Transformerer, som kombinerer ein BERT-modell eksklusivt før-trent på romensk språk med teknikkar som oppositær trening eller innbygging av karakternivå. Ved å bruka desse tilnærmingane, var vi i stand til å få eit 0,6475 makro F1- score på testdatasettet, slik at vi kan bli rankert 5. av 8 deltakarar.', 'sr': 'Identifikacija dijaleta predstavlja ključni aspekt za poboljšanje niz zadataka, na primer, rudarstvo mišljenja, s obzirom da lokacija govornika može veliko uticati na stav prema temu. U ovom poslu opisujemo sisteme koje je razvila naš tim za VarDial 2020: identifikacija rumunskih dijalekata, zadatak posebno stvoren za izazov učesnika da riješe prethodno spomenuto pitanje. Posebnije, predstavljamo niz neuralnih sistema baziranih na transformatorima, koji kombinuju model BERT ekskluzivno predobučen na rumunskom jeziku sa tehnikama poput neprijateljske obuke ili integracije na nivou karaktera. Koristeći te pristupe, uspeli smo da dobijemo 0,6475 makro F1 rezultat na testnom setu podataka, tako da nam omogućava da budemo 5. iz 8 sudionika.', 'si': 'Dialect පරීක්ෂණය ප්\u200dරතිශ්නයක් ප්\u200dරතිශ්නයක් වෙනවා වැඩක් සීරියාවක් වැඩ කරන්න, උදාහරණයෙන්, ප්\u200dරතිශ්නයක් ප්\u200dරතිශ්නයක් විදිහට,  මේ වැඩේ අපි පද්ධතිය වැර්ඩායිල් 2020වෙනුවෙන් විස්තර කළා තියෙන්නේ: රෝමානියාන් ඩායිලෙක්ට් පරික්ෂණය, විශේෂයෙන් විශේෂයෙන විශේෂයෙන්, අපි විශේෂයෙන්, ප්\u200dරවර්තනය කරපු පද්ධතියෙන් අධිරූපයෙන් නිර්මාණය පද්ධතියක් පෙන්වන්න, ඒක BERT මොඩල් එක සම්බන්ධ කරනව අපිට පරීක්ෂණ දත්ත සෙට් එකේ 0.6475 මැක්රෝ F1 ස්කෝර් එකක් ලැබෙන්න පුළුවන්, ඉතින් අපිට පරීක්ෂණ කණ්ඩායම් 8ක් 5වෙනි ස්ථානය කරන', 'so': 'Aqoonsiga dhaqanka waxaa ka mid ah dhinac muhiim ah oo horumarinta shaqaalaha badan, tusaale ahaan kaynta aragtida, isagoo ka fiirsanaya in meeshii uu ku hadlo uu si weyn saameyn ugu yeelan karo qalabka arrimaha la xiriira. Shaqadan waxaynu ku qoraynaa nidaamka kooxdayaga u soo hormariyey VarDial 2020: Identification Romanian Dialect, shaqo gaar ah oo u abuurtay inay ka tacliiyaan wadajirka si ay u xalliyaan arrimaha hore la soo sheegay. Si gaar ah, waxaynu soo bandhignaa nidaam neurada ah oo ku saleysan Transformers, kaas oo ku soo bandhigaa model BERT oo gaar ah ku qoran afka Romaniyanka, waxayna leeyihiin teknikooyin sida tababarida cadaawayaasha ama xarafka. Markaas waxan ku isticmaalnay, waxaan heli karnay koox ka mid ah 5aad oo ka mid ah 8 qayb-qaadayaasha.', 'sv': 'Dialektidentifiering är en viktig aspekt för att förbättra en rad uppgifter, till exempel opinion mining, med tanke på att placeringen av talaren i hög grad kan påverka attityden till ett ämne. I detta arbete beskriver vi de system som utvecklats av vårt team för VarDial 2020: Romanian Dialect Identification, en uppgift speciellt skapad för att utmana deltagarna att lösa det tidigare nämnda problemet. Mer specifikt introducerar vi en serie neurala system baserade på Transformers, som kombinerar en BERT-modell som uteslutande är färdigutbildad på rumänska språket med tekniker som motpartsträning eller karaktärsinbäddningar. Genom att använda dessa metoder kunde vi få en 0,6475 makro F1 poäng på testdatauppsättningen, vilket gjorde att vi kunde rankas 5:e av 8 deltagarlag.', 'ta': 'தொடர்ந்து செயல்களை மேம்படுத்துவதற்கான விசையான விளையாட்டு அடையாளம் குறிப்பிடும். உதாரணமாக, கருத்து குறைந்தது, பேச்சாளரின் இடத்தை பெரும இந்த வேலையில், நாம் எங்கள் குழு 2020 வார்டியால் உருவாக்கப்பட்ட அமைப்புகளை விவரிக்கிறோம்: ரோமானிய விளையாட்டு அடையாளம், முந்தைய குறிப்பி மேலும் குறிப்பிட்டு, இந்த முறைமைகளை பயன்படுத்தி சோதனையின் தரவுத்தளத்தில் 0.6475 மேக்ரோ F1 புள்ளியை பெற முடியும்.', 'ur': 'Dialect identification represents a key aspect for improving a series of tasks, for example, opinion mining, considering that the location of the speaker can greatly affect the attitude of a subject. اس کام میں ہم نے اپنے تیم کے ذریعہ VarDial 2020 کے لئے تولید کی سیستموں کو توصیح دیتے ہیں: رومانی دیالکت شناسایی، ایک کام مخصوص طور پر پیدا ہوا ہے جو پہلے سے موضوع کو حل کرنے کے لئے مشکل کرنے والوں کے لئے پیدا کیا گیا ہے۔ اور زیادہ مخصوص، ہم نے ترنسفور پر بنیاد رکھے ہوئے نئورل سیستموں کی ایک سری پیش آموزش کی ہے جو ایک BERT موڈل کو رومانی زبان پر صرف پہلے آموزش دی گئی ہے اس طرح طریقوں کے ساتھ جس طرح مخالف ترینسی یا شخصیٹ سطح انبودینگ کے ساتھ۔ یہ طریقے استعمال کرتے ہوئے، ہم نے 0.6475 مکرو F1 اسکور کو آزمائش ڈیٹ سٹ پر حاصل کر سکتے تھے، اسی طرح ہم کو 8 مشرکین ٹیموں میں سے پنجم رقم ملنے کی اجازت دی۔', 'mn': 'Диалактын тодорхойлолт нь олон даалгаварын сайжруулах чухал асуудал юм. Жишээлбэл, ойлголтын тодорхойлолт, илтгэгчийн байр сургуульд харилцааны байр сургуульд маш их нөлөөлж чадна. Энэ ажил дээр бид өөрсдийн Баг VarDial 2020-ын хөгжсөн системийг тайлбарлаж байна: Ромын диалект идентификацийн тодорхойлолт, өмнө нь хэлсэн асуудлыг шийдэх шаардлагатай оролцогчдыг зориулсан ажил. Тодорхой хэлбэл, бид Трансформацууд дээр суурилсан мэдрэлийн системүүдийг танилцуулдаг. БЕРТ загварыг Румын хэл дээр зөвхөн өмнө суралцагдсан техникуудтай холбоотой. Эдгээр арга барилгуудыг ашиглан бид 0.6475 макро F1 оноо шалгалтын өгөгдлийн санд гаргаж чадсан. Иймээс бидэнд 8 оролцогчдын 5-р ангид хуваалцах боломжтой болсон.', 'uz': "Koʻrsatish raqamlarni bir necha vazifalarni oshirish uchun muhim aspektlarni koʻrsatish mumkin, masalan, fikrlarni kichiklashtirish mumkin, gapiruvchi manzili mavzuga juda muhimiy influensa beradi. Bu ishda, biz VarDial 2020 uchun guruhmiz yaratilgan tizimlarni anglatamiz: Romaniya Dialect Tasdiqlash, bu muammolarni oldingi talab qilish uchun qo'llanmagan vazifa. Ko'pchilik, biz Transformerlar asosida yaratilgan bir necha neyrol tizimni anglatamiz. Bu BERT modelini faqat Romaniya tilida o'rganish uchun o'rganish tugmalar bilan foydalanishi mumkin. Bu usullar yordamida biz sinov maʼlumotlar sohasida 0.6475 makro F1 scorini olishga imkoniyat berdik. Bunday qilib, bizni 8 participants guruhidagi 5 chi darajaga olishga ruxsat beramiz.", 'vi': 'Nhận diện thoại là một khía cạnh chủ chốt để cải thiện một loạt các nhiệm vụ, ví dụ như việc khai thác ý kiến, vì vị trí của người phát ngôn có thể ảnh hưởng rất lớn đến thái độ đối với một chủ đề. Trong công việc này, chúng tôi mô tả hệ thống phát triển bởi nhóm của chúng tôi đối với VarDial 2020: Rumani, nhiệm vụ đặc biệt được tạo ra cho những người tham dự thử thách để giải quyết vấn đề trước đây. Đặc biệt hơn, chúng tôi giới thiệu một loạt hệ thần kinh dựa trên Transformers để kết hợp một mô hình BERT độc quyền được rèn luyện trên ngôn ngữ Rumani bằng kỹ thuật như huấn luyện ngược thủ hay sự nhúng tay vào các nhân vật. Bằng cách sử dụng các phương pháp này, chúng tôi đã có thể đạt được một số Mac F1 ghi 0.645 trên tập tin thử nghiệm, cho phép chúng tôi được xếp hạng thứ năm ra khỏi 8 các đội tham gia.', 'nl': 'Dialectidentificatie is een belangrijk aspect voor het verbeteren van een reeks taken, bijvoorbeeld opinion mining, aangezien de locatie van de spreker de houding ten opzichte van een onderwerp sterk kan beïnvloeden. In dit werk beschrijven we de systemen die door ons team zijn ontwikkeld voor VarDial 2020: Romanian Dialect Identification, een taak die speciaal is ontworpen voor uitdagende deelnemers om het eerder genoemde probleem op te lossen. Meer specifiek introduceren we een reeks neurale systemen op basis van Transformers, die een BERT model combineren dat exclusief is voorgetraind op de Roemeense taal met technieken zoals adversarial training of personage-level embeddings. Door deze benaderingen te gebruiken, konden we een 0.6475 macro F1 score verkrijgen op de testdataset, waardoor we 5e van de 8 deelnemende teams konden worden.', 'bg': 'Идентификацията на диалекта представлява ключов аспект за подобряване на редица задачи, например извличане на мнение, като се има предвид, че местоположението на говорителя може значително да повлияе на отношението към даден обект. В тази работа описваме системите, разработени от екипа ни за Идентификация на румънски диалект, задача специално създадена, за да предизвика участниците да решат гореспоменатия проблем. По-конкретно, ние въвеждаме серия от невронни системи, базирани на трансформатори, които съчетават модел, изключително предварително обучен на румънски език, с техники като съперническо обучение или вграждане на ниво герои. Използвайки тези подходи, успяхме да получим 0,6475 макро оценка на теста, което ни позволи да бъдем класирани на 5-то място от 8 участници отбора.', 'da': 'Dialekt identifikation repræsenterer et centralt aspekt for at forbedre en række opgaver, f.eks. opinion mining, i betragtning af at placeringen af taleren i høj grad kan påvirke holdningen til et emne. I dette arbejde beskriver vi de systemer, som vores team har udviklet til VarDial 2020: Romanian Dialect Identification, en opgave specifikt skabt til at udfordre deltagerne til at løse det tidligere nævnte problem. Mere specifikt introducerer vi en række neurale systemer baseret på Transformers, der kombinerer en BERT-model, der udelukkende er prætrænet på rumænsk sprog, med teknikker som adversial træning eller karakter-niveau embeddings. Ved at bruge disse tilgange, var vi i stand til at opnå en 0,6475 makro F1 score på testdatasættet, hvilket gav os mulighed for at blive rangeret 5. ud af 8 deltagerhold.', 'hr': 'Identifikacija dijaleta predstavlja ključni aspekt za poboljšanje niz zadataka, na primjer, rudarstvo mišljenja, s obzirom da lokacija govornika može veliko utjecati na stav prema temu. U ovom poslu opisujemo sustave koje je razvila naš tim za VarDial 2020: identifikacija rumunskih dijalekata, zadatak posebno stvoren za izazov učesnika da riješe prethodno spomenuto pitanje. Posebnije, predstavljamo niz neuralnih sustava na temelju transformera, koji kombiniraju model BERT-a izuzetno predobučen na rumunskom jeziku s tehnikama poput neprijateljske obuke ili integracije na nivou karaktera. Koristeći te pristupe, uspjeli smo dobiti rezultat 0,6475 makro F1 na testnom setu podataka, tako omogućavajući nam da budemo 5. iz 8 sudionika.', 'de': 'Dialektidentifikation stellt einen Schlüsselaspekt für die Verbesserung einer Reihe von Aufgaben dar, zum Beispiel Meinungsbildung, da der Standort des Redners die Einstellung zu einem Thema stark beeinflussen kann. In dieser Arbeit beschreiben wir die Systeme, die unser Team für VarDial 2020: Romanian Dialect Identification entwickelt hat, eine Aufgabe, die speziell für anspruchsvolle Teilnehmer entwickelt wurde, um das oben genannte Problem zu lösen. Genauer gesagt stellen wir eine Reihe neuronaler Systeme vor, die auf Transformern basieren, die ein BERT-Modell kombinieren, das ausschließlich auf der rumänischen Sprache vortrainiert ist, mit Techniken wie adversarialem Training oder character-level Embeddings. Mit Hilfe dieser Ansätze konnten wir einen 0,6475 Makro F1 Score auf dem Testdatensatz erhalten, wodurch wir Fünfter von acht Teilnehmerteams werden konnten.', 'fa': 'شناسایی شناسایی دیلاکت نشان می\u200cدهد یک نقطه کلید برای improving a series of tasks, for example, mining opinion, considering that the location of the speaker can greatly influence the attitude towards a subject. در این کار، سیستم\u200cهای توسط تیم ما برای VarDial 2020 توصیف می\u200cکنیم: شناسایی Dialect رومانی، یک وظیفه مخصوصا برای مشکل مشترک برای حل مشکل پیش از این ساخته شده است. دقیقاً ما مجموعه سیستم\u200cهای عصبی را بر اساس تغییر\u200cدهندگان معرفی می\u200cکنیم، که یک مدل BERT را به طور خاص پیش از آموزش بر زبان رومانی با تکنیک\u200cهایی مثل آموزش\u200cهای مخالف یا تغییر سطح شخصیت ترکیب می\u200cکند. با استفاده از این دسترسی، ما توانستیم امتیاز 0.6475 ماکرو F1 را در مجموعه داده\u200cهای آزمایش دریافت کنیم، بنابراین به ما اجازه می\u200cدهد که پنجمین از ۸ تیم مشترک باشیم.', 'id': 'Dialect identification represents a key aspect for improving a series of tasks, for example, opinion mining, considering that the location of the speaker can greatly influence the attitude towards a subject.  Dalam pekerjaan ini, kami menggambarkan sistem yang dikembangkan oleh tim kami untuk VarDial 2020: Identifikasi Dialek Rumania, tugas yang dibuat secara khusus untuk menantang peserta untuk memecahkan masalah yang sebelumnya disebutkan. Lebih spesifik, kami memperkenalkan serangkaian sistem saraf berdasarkan Transformers, yang menggabungkan model BERT eksklusif terlatih di bahasa Rumania dengan teknik seperti pelatihan musuh atau penerbangan karakter. Dengan menggunakan pendekatan ini, kami mampu mendapatkan skor 0,6475 makro F1 pada set data tes, sehingga memungkinkan kami menjadi peringkat ke-5 dari 8 tim peserta.', 'sw': 'Utambulisho wa Dialect unawakilisha mtazamo wa muhimu wa kuboresha mfululizo wa kazi, kwa mfano, uchunguzi wa maoni, ukizingatia kuwa sehemu ya msemaji anaweza kuathiri mtazamo wa mada. Katika kazi hii, tunaelezea mfumo uliotengenezwa na timu yetu kwa ajili ya VarDial 2020: Utambulisho wa Tambulisho la KiRomania, jukumu lililotengenezwa hasa kwa kuwachanganya washiriki kutatua suala hili lililotajwa hapo awali. Zaidi hasa, tunaonyesha mfululizo wa mfumo wa neura unaoanzishwa na Watafsiri, ambao unaunganisha muundo wa BERT pekee wa mafunzo ya awali kwa lugha ya KiRomania na mbinu kama vile mafunzo ya upinzani au viwango vya tabia. Kwa kutumia mbinu hizi, tuliweza kupata kiwango cha takwimu cha takwimu 0.6475 cha ukurasa F1 kwenye seti ya jaribio, kwa hiyo tukaturuhusu kuwa na rangi ya tano kati ya timu 8 za washiriki.', 'tr': 'Sa첵lawy tanamak birn채챌e zady bejermek 체챌in wajyp aspekti, mesel창, d체힊체n첵채nlik ta첵첵arlamak 체챌in, s철zlerini흫 첵erini흫 bir tema tarapyna g철r채 gurlap biljekdigini d체힊체n첵채r. Bu i힊de, bizi흫 toparymyzy흫 VarDial 2020 체챌in geli힊mi힊 sistemalary tassykladyrys: rumyny흫 Dialect kimligi, 철흫ki meseleni 챌철zmek 체챌in 챌철z체mleri 챌철zmek 체챌in bir zady d체zenlen첵채r. A첵ratyn g철r채, transformat챌ylar 체zerine da첵an첵an n채ral sistemalary tany힊dyr첵arys. Bu BERT nusgasyny Roma dilinde t채sirli e휓im 첵a-da karakter derejesi ekle첵채n teknikleri bilen birle힊첵채r. Bu gola첵lary ulanarak 0,6475 makro F1 nokady bardyk we bu 힊ekilde bizi 8-nji go힊ulyk topardan 5-nji derej채 berip bilerdik.', 'af': "Dialeksie-identifikasie verteenwoordig 'n sleutel aspekt vir die verbetering van 'n reeks van taak, byvoorbeeld, opisiemining, met aandag dat die ligging van die spreker groot kan inflyk die aanstand teen 'n onderwerp. In hierdie werk beskrywe ons die stelsels wat deur ons span vir VarDial 2020 ontwikkeld is: Romaniese Dialect Identifikasie, 'n taak spesifieke geskep het vir die aandag van deelnimmers om die voorheen gemerkte probleem te los. Meer spesifieke, ons introduseer 'n reeks neurale stelsels gebaseer op Transformers, wat 'n BERT model uitsluit voor-opgelei word op die Rumäniese taal met teknike soos teëstandige onderwerking of karaktervlak inbettings kombinieer. Deur hierdie toegang te gebruik, was ons in staat om 'n 0,6475 makro F1 punt op die toets datastel te kry, sodat ons toelaat om 5de van 8 deelnaders te wees.", 'am': 'የDialect identification የብዙ ስራዎችን ለማድረግ የቁልፍ ጉዳይ ነው፤ ምሳሌ፣ አስተያየት ግንኙነት እና የአንባቢው ቦታ በጉዳዩ ላይ ጥያቄ እንዲያስቀምጥ ነው፡፡ በዚህ ሥራ፣ የጦማሪያችን 2020 ለVarDial የተደገመውን ድምፅ እናሳውቃለን፤ ሮማኒያን Dialect ማውቀት፣ የቀድሞውን ጉዳይ ለመፍትወት በተለየ ተጋሪዎችን ለመፍታት የተፈጠረውን ስራ እናሳውቃለን፡፡ በተለይም፣ በተለየ በTransformers ላይ የተመሠረቱትን የኒውራዊ ስርዓቶች እናስጠጋለን፣ ይህም BERT ሞዴል በሮማዊ ቋንቋ ላይ የተጠቃሚ የፊደል ትምህርት ወይም የሥርዓት ደረጃን እንደተቃዋሚ ትምህርት ማቀናቀል እናስጠጋለን፡፡ እነዚህን ደረጃዎች በመጠቀም ከ8 ተጋሪዎች ጭፍሮች የ0.6475 ማክሮር F1 score አግኝተን ነበር፡፡', 'az': 'Dialekt identifikassiyası, məsələn, fikirlərin maddiyini yaxşılaşdırmaq üçün, danışmaçının yeri bir məsələnin davranışına çox təsir edə biləcəyini düşünürlər. Bu işdə, müəyyən etdiyimiz sistemləri VarDial 2020 üçün təşkil edirik: Rumun Dialect Identification, keçmişdəkilərin çətinliklərini çəkmək üçün çətinliklərə yaratdığı bir işdir. Daha çox xüsusiyyətli, Transformers üzərində dayanan bir nöral sistemi təşkil edirik ki, BERT modelini Romalı dilində yalnız əvvəl təhsil edilmiş kimi təhsil təhsil və karakter səviyyələri ilə birləşdirir. Bu yaxınlıqları istifadə edərək, sınama verilənlərin dəstəsində 0,6475 makro F1 nöqtəsini elde edə bilərdik. Beləliklə, bizə 8 iştirakçı dəstəsindən 5-ci nöqtəsini verir.', 'ko': '사투리 식별은 일련의 임무(예를 들어 관점 발굴)를 개선하는 관건적인 부분이다. 왜냐하면 말하는 사람의 위치는 주제에 대한 태도에 큰 영향을 줄 수 있기 때문이다.이 작업에서 우리는 우리 팀이VarDial 2020: 루마니아 사투리 식별을 위해 개발한 시스템을 묘사했다. 이것은 도전 참여자를 위해 상술한 문제를 해결하기 위해 만든 임무이다.더욱 구체적으로 말하면, 우리는 트랜스포머를 바탕으로 하는 일련의 신경계를 소개했고, 루마니아 언어에 전문적으로 미리 훈련된 버트 모델과 대항성 훈련이나 문자급 삽입 등 기술을 결합시켰다.이러한 방법을 통해 우리는 테스트 데이터 집합에서 0.6475의 거시적 F1 점수를 얻어 8개 참가팀 중 5위를 차지할 수 있다.', 'bn': 'ডায়ালেক্ট পরিচিতির একটি গুরুত্বপূর্ণ দিকের প্রতিনিধিত্ব করে, যেমন মন মন্তব্য কমানোর জন্য, বিবেচনা করে যে বক্তৃপক্ষের অবস্থান বিষয়টির প্রতি বি এই কাজে আমরা ভ্যার ডায়াল ২০২০ এর জন্য আমাদের টিমের উন্নয়নের ব্যবস্থা বর্ণনা করি: রোমানিয়ান ডায়ালেক্টর পরিচয়, একটি কাজ বিশেষ করে পূর্বে উল্লেখিত ব বিশেষ করে আমরা ট্রান্সফর্মারের উপর ভিত্তিক কিছু নিউরেল সিস্টেমের সাথে পরিচয় করিয়ে দিচ্ছি, যা বিআরটি মডেল একেবারেই রোমানিয়ান ভাষায় প্রশিক্ষণের পূর্বে প্রশ এই পদক্ষেপ ব্যবহার করে আমরা পরীক্ষার ডাটাসেটে ০.6475 ম্যাক্রো এফ১ স্কোর পেতে পারি, যার ফলে আমরা ৮ দলের অংশগ্রহণকারীদের মধ্যে ৫তম রান্না', 'bs': 'Identifikacija dijaleta predstavlja ključni aspekt za poboljšanje niz zadataka, na primjer, rudarstvo mišljenja, s obzirom da lokacija govornika može veliko utjecati na stav prema temu. U ovom poslu opisujemo sisteme koje je razvila naš tim za VarDial 2020: identifikacija rumunskih dijalekta, zadatak posebno stvoren za izazov učesnika da riješe prethodno spomenuto pitanje. Posebnije, predstavljamo niz neuralnih sustava na osnovu Transformera, koji kombinira BERT model ekskluzivno predobučen na rumunskom jeziku sa tehnikama poput neprijateljske obuke ili integracije na nivou karaktera. Koristeći te pristupe, mogli smo dobiti rezultat 0,6475 makro F1 na testnom setu podataka, tako da nam omogućava da budemo 5. iz 8 sudionika.', 'cs': 'Identifikace dialektu představuje klíčový aspekt pro zlepšení řady úkolů, například dolování mínění, vzhledem k tomu, že umístění řečníka může výrazně ovlivnit postoj k tématu. V této práci popisujeme systémy vyvinuté naším týmem pro VarDial 2020: Romanian Dialect Identification, úkol speciálně vytvořený pro výzvu účastníků k řešení výše zmíněného problému. Konkrétněji představujeme řadu neuronových systémů založených na transformátorech, které kombinují BERT model exkluzivně předškolený na rumunském jazyce s technikami jako je adversariální trénink nebo vložení postav. Použitím těchto přístupů jsme byli schopni získat 0,6475 makro F1 skóre na testovacím datovém souboru, což nám umožnilo být páté z osmi účastníků týmů.', 'hy': 'Դիալեկտի հայտնաբերումը ներկայացնում է մի շարք խնդիրների բարելավման կարևոր ասպեկտ, օրինակ, կարծիքի հանքահանումը, հաշվի առնելով, որ խոսնակի տեղադրությունը կարող է մեծ ազդեցություն ունենալ թեմայի նկատմամբ: Այս աշխատանքի ընթացքում մենք նկարագրում ենք մեր թիմի կողմից զարգացած համակարգերը "Վարդիալ 2020"-ի համար. Ռոմանական դիալեկտի ինքնությունը, որն առանձնապես ստեղծվել է մասնակիցների մարտահրավերների համար, որպեսզի լուծեն նախկինում նշ Ավելի հատկապես, մենք ներկայացնում ենք մի շարք նյարդային համակարգեր, որոնք հիմնված են Թերֆորմերների վրա, որոնք միավորում են BER մոդել, որը միայն նախապատրաստված է ռոմանական լեզվով, այնպիսի տեխնիկաների հետ, ինչպիսիք են հակառակորդական վարժանք կամ բնավորության մա Օգտագործելով այս մոտեցումները, մենք կարողացանք ստանալ 0.6475 մակրո F1 գնահատականը թեստի տվյալների համակարգում, ինչը թույլ է տալիս մեզ դասավորել ութ մասնակիցներից հինգերորդը:', 'sq': 'Dialect identification represents a key aspect for improving a series of tasks, for example, opinion mining, considering that the location of the speaker can greatly influence the attitude towards a subject.  Në këtë punë, ne përshkruajmë sistemet e zhvilluar nga ekipi ynë për VarDial 2020: Identifikimi rumun i dialektit, një detyrë e krijuar specifikisht për sfidat e pjesëmarrësve për të zgjidhur çështjen e përmendur më parë. Më specifikisht, ne futim një seri sistemesh nervorë të bazuar në Transformuesit, që kombinojnë një model BERT ekskluzivisht të paratrajnuar në gjuhën rumune me teknika të tilla si trajnimi kundërshtar apo përfshirje në nivelin e karakterit. Duke përdorur këto qasje, ne ishim në gjendje të fitojmë një pikë 0.6475 makro F1 në grupin e të dhënave të testit, duke na lejuar kështu të renditetim të pestën nga 8 ekipet pjesëmarrëse.', 'ca': "L'identificació dialectal representa un aspecte clau per millorar una sèrie de tasques, per exemple, la mineria d'opinió, considerant que la ubicació del parlant pot influir molt en l'actitud cap a un tema. En aquesta feina, descrivim els sistemes desenvolupats pel nostre equip per VarDial 2020: Identificació de diàlectes romena, una tasca específicament creata per als participants desafiant a resoldre el tema anteriorment mencionat. Més específicament, introduïm una sèrie de sistemes neuronals basats en Transformers, que combinan un model BERT exclusivament pré-entrenat en la llengua romena amb tècniques com l'entrenament adversari o incorporació a nivell caràcter. Utilitzant aquests enfocaments, vam aconseguir una puntuació de 0,6475 macro F1 en el conjunt de dades de prova, i així ens va permetre ser classificats en cinc de cada vuit equips participants.", 'et': 'Dialekti identifitseerimine on oluline aspekt rea ülesannete täiustamisel, näiteks arvamuse kaevandamisel, arvestades, et kõneleja asukoht võib oluliselt mõjutada suhtumist teemasse. Käesolevas töös kirjeldame meie meeskonna poolt VarDial 2020 jaoks välja töötatud süsteeme: Rumeenia dialekti identifitseerimine, ülesanne, mis on loodud spetsiaalselt selleks, et osalejad saaksid lahendada eelnevalt nimetatud probleemi. Täpsemalt tutvustame mitmeid Transformeritel põhinevaid närvisüsteeme, mis ühendavad BERT mudeli, mis on üksnes eelõpetatud rumeenia keeles, selliste tehnikatega nagu vastandlik koolitus või iseloomustaseme manustamine. Nende lähenemisviiside abil saime testiandmetest 0,6475 makro F1 skoori, mis võimaldas meil 8 osalejast viiendal kohal olla.', 'fi': 'Dialektitunnistus on keskeinen osa useiden tehtävien, esimerkiksi mielipidevaikunnan parantamista, kun otetaan huomioon, että puhujan sijainti voi vaikuttaa suuresti asenteeseen aihetta kohtaan. Tässä työssä kuvaamme tiimimme VarDial 2020:lle kehittämät järjestelmät: Romanian Dialect Identification, tehtävä, joka on luotu erityisesti haastaville osallistujille ratkaisemaan edellä mainittu ongelma. Tarkemmin sanottuna esittelemme sarjan muuntajiin perustuvia hermojärjestelmiä, joissa yhdistyvät yksinomaan romanian kielellä esikoulutettu BERT-malli tekniikoihin, kuten vastustajakoulutus tai hahmotason upotukset. Näiden lähestymistapojen avulla saimme testiaineistosta 0,6475 makron F1-pisteen, mikä mahdollisti meidät sijoittumaan viidenneksi kahdeksasta osallistujajoukkueesta.', 'sk': 'Identifikacija dialekta predstavlja ključni vidik za izboljšanje vrste nalog, na primer rudarjenje mnenja, saj lahko lokacija govornika močno vpliva na odnos do teme. V tem delu opisujemo sisteme, ki jih je naša ekipa razvila za VarDial 2020: romunska identifikacija dialekta, naloga, ki je bila posebej ustvarjena za izzive udeležencev k reševanju omenjene težave. Natančneje, predstavljamo vrsto nevronskih sistemov, ki temeljijo na transformatorjih, ki združujejo BERT model, ki je izključno vnaprej usposobljen v romunskem jeziku, s tehnikami, kot so konverzalno usposabljanje ali vdelava znakov. Z uporabo teh pristopov smo lahko dobili 0,6475 makro F1 rezultat na testnem naboru podatkov, kar nam je omogočilo uvrstitev 5. od 8 udeleženih ekip.', 'jv': 'diaelect ID Nang iki trabah, kita ngubah sistem sing dumadhakan karo kelompok nggawe Wardial 2020: ngubuturan diaselect Awak dhéwé ngomong nik, kéné mulai akeh sistem Neral sing basa kanggo Transformer, sing ditambah model BERT sing wis luwih apik dhéwé basa luwih apik dhéwé, lan tékno sing ngerasai tékno karo paké, ngono perusahaan langgar -Kemerdekaan karo perangkat caratar langgar. Ngawe ngubah nambah karo hal-nambah iki, dhewe mau iso nggawe punika 0,64 macro F1 mu sekondité perusahaan dataset, dadi iso nggawe barang wis limate sampek ning aytu sekondi 8', 'ha': "Shiryoyin zauren akwatin bayani na ƙayyade mazaɓa wa gyãra masu cikin aikin mãsu yawa, misali, ƙarami masu ƙaranci, kuma, ka yi tunãni, cewa wurin da ake faɗar mai faɗa yana iya yin amfani da mazaɓa zuwa wani matsayi. Daga wannan aikin, Munã bayyana wa'anar na'uranmu wanda aka buɗe na wajen kwamfyutan na'urar Dial 2020: Shirin na'urar-Romian Dialate, wani aikin wanda aka ƙayyade wajen karatu ga masu yin musamman da za'a sole masu da aka faɗa a a gabani. Ko da ƙayyade, Munã ƙara wasu na'urar neural na'urar a kan Transformers, wanda ke haɗa wata misãlai na BERT, yana mai amfani da shi gabã ɗaya a kan harshen Rumoniyan, da kunnufi kamar shirin motsi ko da takardar-daraja. Ina amfani da waɗannan hanyõyin, za'a iya iya samun nau'i 0.6475macro F1 kan danne-jarraba, don haka na yarda a ranar mu 5 daga jama'a 8 mãsu shirin aiki.", 'he': 'זיהוי דיאלקט מייצג אפקט מפתח לשיפור סדרת משימות, לדוגמה, מכרות דעות, בהתחשב במיקום של הרמקול יכול להשפיע על הגישה כלפי נושא. בעבודה הזו, אנחנו מתארים את המערכות שהתפתחו על ידי צוות שלנו עבור VarDial 2020: זיהוי דיאלקט רומני, משימה שנוצרה במיוחד עבור משתתפים מאתגרים לפתור את הנושא הנזכר קודם. יותר במיוחד, אנחנו מכירים סדרה של מערכות עצביות מבוססות על Transformers, שמשולבים מודל BERT בלבד מאומן מראש על השפה הרומנית עם טכניקות כמו אימון יריבי או תוכניות ברמה של אופי. על ידי השימוש באמצעות גישות אלה, הצלחנו להשיג נקודת 0.6475 מקרו F1 על קבוצת הנתונים הבדיקות, כך מאפשר לנו להיות בשורה 5 מתוך 8 קבוצות משתתפות.', 'bo': 'གླེང་མོལ་དཔལ་འཛིན་སྟངས་ནི་བྱ་འགུལ་གྱི་གཙོ་ཆེ་ཆུང་ཅིག་མཚོན་པ་དང་། དཔེར་ན། བསམ་འཆར་ཞབས་ཞུ་བ་ཡིན་པའི་གནས་ཡུལ་འདི་ཁ་གཏད་པ་ཡིན་ནའང ང་ཚོས་རྒྱལ་ཁབ་འདིའི་ནང་གི་དོན་ལྟར་VarDial 2020(VarDial 2020)རྩོམ་པ་ཁག་གི་མ་ལག་གི་ཐོག་ལས་གསར་བསྐྲུན་ཡོད།རོ་མ་ཡིས་བཀོད་སྤྱོད་རྒྱུ་དང་། ང་ཚོས་རང་ཉིད་ཀྱི་ཁྱད་པར་གསལ་བཤད་པ་ཞིག་ལས་དབུལ་རིགས་མ་ལག་ཅིག་སྟོན་གསལ། ཐབས་ལམ་འདི་དག་བེད་སྤྱོད་བཞིན་ཡོད། ང་ཚོས་རྒྱ་ནག'}
{'en': 'Geolocation of Tweets with a BiLSTM Regression Model', 'ar': 'تحديد الموقع الجغرافي للتغريدات باستخدام نموذج الانحدار BiLSTM', 'fr': 'Géolocalisation de Tweets avec un modèle de régression BilsTM', 'es': 'Geolocalización de tuits con un modelo de regresión BilsTM', 'pt': 'Geolocalização de Tweets com um Modelo de Regressão BiLSTM', 'ja': 'BiLSTM回帰モデルを使用したツイートの位置情報', 'zh': '用 BiLSTM 归依推文地理', 'ru': 'Геолокация твитов с помощью регрессионной модели BiLSTM', 'hi': 'एक BiLSTM प्रतिगमन मॉडल के साथ Tweets के Geolocation', 'ga': 'Geolocation of Tweets le Múnla Aischéimnithe BiLSTM', 'ka': 'Name', 'el': 'Γεωεντοπισμός tweets με ένα μοντέλο αναδρομής BiLSTM', 'hu': 'Tweetek geolokációja BiLSTM regressziós modellel', 'it': 'Geolocalizzazione dei Tweet con un modello di regressione BiLSTM', 'kk': 'Name', 'lt': 'Twietų su BiLSTM regresijos modeliu geografinė vieta', 'mk': 'Name', 'ms': 'Geolokasi Tweets dengan Model Regresi BiLSTM', 'mt': 'Ġeolokazzjoni ta’ Tweets b’Mudell ta’ Regressjoni BiLSTM', 'ml': 'ബിഎല്\u200dഎസ്റ്റം റിഗ്രഷന്\u200d മോഡലുമായി ടൂട്ടുകളുടെ ഭൂമിയിലേക്കു്Name', 'mn': 'BiLSTM Регрессийн загвартай Tweets-ын Geolocation', 'pl': 'Geolokalizacja tweetów z modelem regresji BiLSTM', 'no': 'Name', 'ro': 'Geolocalizarea Tweeturilor cu un model de regresie BiLSTM', 'sr': 'Geolokacija Tweets sa model regresije BiLSTM', 'si': 'Name', 'so': 'Geolocation of Tweets with a BiLSTM Regression Model', 'sv': 'Geoplacering av tweets med en BiLSTM regressionsmodell', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Địa điểm của Tweet với mô hình Hồi phục BiLSTM', 'bg': 'Геолокация на туитове с BiLSTM регресионен модел', 'da': 'Geoplacering af tweets med en BiLSTM regressionsmodel', 'hr': 'Geolokacija Tweets sa model regresije BiLSTM', 'nl': 'Geolocatie van Tweets met een BiLSTM regressiemodel', 'de': 'Geolokalisierung von Tweets mit einem BiLSTM Regressionsmodell', 'id': 'Geolokasi Tweets dengan Model Regresi BiLSTM', 'ko': 'BilSTM 회귀 모델로 트윗에 대한 지리적 포지셔닝', 'fa': 'Name', 'sw': 'Utamasishaji wa Twita kwa Utawala wa Udhibiti wa BiLSTM', 'tr': 'BiLSTM Regression Modeli bilen Tweets ýeri', 'af': 'Name', 'sq': 'Gjeolokimi i Tweets me një model Regression BiLSTM', 'am': 'ቦታ', 'bn': 'বিএলস্টিম রেগ্রেশন মডেল দিয়ে টুইটের গোলোকশন', 'hy': 'Comment', 'az': "BiLSTM Regression Modeli ilə Tweets'in Geolocation", 'bs': 'Geolokacija Tweets sa model regresije BiLSTM', 'ca': 'Geolocalització de Tweets amb un model de regressió BiLSTM', 'et': 'BiLSTM regressioonimudeliga tweetide geolokatsioon', 'cs': 'Geolokace tweetů s BiLSTM regresním modelem', 'fi': 'Tweettien geolokaatio BiLSTM-regressiomallilla', 'jv': 'Location, $date', 'ha': 'KCharselect unicode block name', 'sk': 'Geolokacija Tweets z BiLSTM regresijskim modelom', 'he': 'Name', 'bo': 'Geolocation of Tweets with a BiLSTM Regression Model'}
{'en': 'Identifying a user’s location can be useful for ', 'pt': 'Identificar a localização de um usuário pode ser útil para sistemas de recomendação, análises demográficas e monitoramento de surtos de desastres. Embora o Twitter permita que os usuários revelem voluntariamente sua localização, essa informação não está disponível universalmente. A análise de um tweet pode fornecer uma estimativa geral da localização de um tweet, ao mesmo tempo em que fornece informações sobre o dialeto do usuário e outros marcadores linguísticos. Tais atributos linguísticos podem ser usados para fornecer uma aproximação regional das origens dos tweets. Neste artigo, apresentamos um modelo de regressão neural que pode identificar os meandros linguísticos de um tweet para prever a localização do usuário. O modelo final identifica o dialeto embutido no tweet e prevê a localização do tweet.', 'ar': 'يمكن أن يكون تحديد موقع المستخدم مفيدًا لأنظمة التوصية والتحليلات الديموغرافية ومراقبة تفشي الكوارث. على الرغم من أن Twitter يسمح للمستخدمين بالكشف عن مواقعهم طواعية ، فإن هذه المعلومات ليست متاحة عالميًا. يمكن أن يوفر تحليل تغريدة تقديرًا عامًا لموقع تغريدة مع إعطاء نظرة ثاقبة لهجة المستخدم والعلامات اللغوية الأخرى. يمكن استخدام هذه السمات اللغوية لتوفير تقريب إقليمي لأصول التغريدات. في هذه الورقة ، نقدم نموذج الانحدار العصبي الذي يمكنه تحديد التعقيدات اللغوية للتغريدة للتنبؤ بموقع المستخدم. يحدد النموذج النهائي اللهجة المضمنة في التغريدة ويتنبأ بموقع التغريدة.', 'fr': "L'identification de l'emplacement d'un utilisateur peut être utile pour les systèmes de recommandation, les analyses démographiques et la surveillance des épidémies de catastrophes. Bien que Twitter autorise les utilisateurs à révéler volontairement leur position géographique, ces informations ne sont pas universellement disponibles. L'analyse d'un tweet peut fournir une estimation générale de l'emplacement d'un tweet tout en donnant un aperçu du dialecte de l'utilisateur et d'autres marqueurs linguistiques. Ces attributs linguistiques peuvent être utilisés pour fournir une approximation régionale de l'origine des tweets. Dans cet article, nous présentons un modèle de régression neuronale qui permet d'identifier les subtilités linguistiques d'un tweet afin de prédire l'emplacement de l'utilisateur. Le modèle final identifie le dialecte intégré au tweet et prédit l'emplacement du tweet.", 'es': 'Identificar la ubicación de un usuario puede ser útil para sistemas de recomendación, análisis demográficos y monitoreo de brotes de desastres. Aunque Twitter permite a los usuarios revelar voluntariamente su ubicación, dicha información no está disponible de forma universal. El análisis de un tweet puede proporcionar una estimación general de la ubicación de un tweet y, al mismo tiempo, dar una idea del dialecto del usuario y otros marcadores lingüísticos. Estos atributos lingüísticos se pueden utilizar para proporcionar una aproximación regional de los orígenes de los tuits. En este artículo, presentamos un modelo de regresión neuronal que puede identificar las complejidades lingüísticas de un tuit para predecir la ubicación del usuario. El modelo final identifica el dialecto incrustado en el tuit y predice la ubicación del tuit.', 'zh': '定用户位,于建言系统、人口统计分析、灾异监临甚有用。 虽Twitter许用户自露其位,然非遍可用也。 析推文可以供推文位之度,而深知用户之方言及他语言。 此语性可供推文来者近似值。 于本文中,立一神经归模,当识推文语复杂性,以占用户位。 终于模形标识嵌于推文中之方言,而占推文之位。', 'hi': 'उपयोगकर्ता के स्थान की पहचान करना सिफारिश प्रणालियों, जनसांख्यिकीय विश्लेषण और आपदा प्रकोप की निगरानी के लिए उपयोगी हो सकता है। हालांकि ट्विटर उपयोगकर्ताओं को स्वेच्छा से अपने स्थान को प्रकट करने की अनुमति देता है, ऐसी जानकारी सार्वभौमिक रूप से उपलब्ध नहीं है। एक ट्वीट का विश्लेषण उपयोगकर्ता और अन्य भाषाई मार्करों की बोली में अंतर्दृष्टि देते हुए एक ट्वीट स्थान का एक सामान्य अनुमान प्रदान कर सकता है। इस तरह की भाषाई विशेषताओं का उपयोग ट्वीट मूल के क्षेत्रीय सन्निकटन प्रदान करने के लिए किया जा सकता है। इस पेपर में, हम एक तंत्रिका प्रतिगमन मॉडल प्रस्तुत करते हैं जो उपयोगकर्ता के स्थान की भविष्यवाणी करने के लिए एक ट्वीट की भाषाई पेचीदगियों की पहचान कर सकता है। अंतिम मॉडल ट्वीट में एम्बेडेड बोली की पहचान करता है और ट्वीट के स्थान की भविष्यवाणी करता है।', 'ru': 'Идентификация местоположения пользователя может быть полезна для рекомендательных систем, демографических анализов и мониторинга вспышек стихийных бедствий. Хотя Twitter позволяет пользователям добровольно раскрывать свое местоположение, такая информация не является общедоступной. Анализ твита может дать общую оценку местоположения твита, одновременно давая представление о диалекте пользователя и других лингвистических маркерах. Такие лингвистические атрибуты могут использоваться для обеспечения регионального приближения происхождения твитов. В этой статье мы представляем модель нейронной регрессии, которая может идентифицировать лингвистические тонкости твита, чтобы предсказать местоположение пользователя. Окончательная модель определяет диалект, встроенный в твит, и предсказывает местоположение твита.', 'ja': 'ユーザーの場所を特定することは、推奨システム、人口統計分析、および災害発生モニタリングに役立ちます。Twitterではユーザーが自発的に位置を明らかにすることができますが、そのような情報は普遍的に利用できるわけではありません。ツイートを分析することは、ツイートの場所の一般的な推定を提供すると同時に、ユーザ及び他の言語マーカーの方言についての洞察を提供することができる。そのような言語的属性を使用して、ツイートの起源の地域的近似を提供することができる。本稿では、ツイートの言語的な複雑さを特定して、ユーザの位置を予測することができる神経回帰モデルを提示する。最終モデルは、ツイートに埋め込まれた方言を識別し、ツイートの位置を予測する。', 'ga': 'Is féidir suíomh úsáideora a aithint a bheith úsáideach le haghaidh córais mholta, anailísí déimeagrafacha, agus monatóireacht ar ráigeanna tubaiste. Cé go ligeann Twitter d’úsáideoirí a suíomh a nochtadh go deonach, níl an fhaisnéis sin ar fáil go huilíoch. Is féidir le hanailís ar thvuít meastachán ginearálta a sholáthar ar shuíomh tweetanna agus léargas a thabhairt ar chanúint an úsáideora agus ar mharcóirí teanga eile. Is féidir tréithe teangeolaíocha dá leithéid a úsáid chun comhfhogasú réigiúnach a sholáthar ar bhunús na tweetanna. Sa pháipéar seo, cuirimid múnla aischéimniúcháin néarach i láthair ar féidir leis na castaí teanga a bhaineann le tweet a aithint chun suíomh an úsáideora a thuar. Aithníonn an tsamhail dheireanach an chanúint atá leabaithe sa tweet agus déanann sé suíomh an tweet a thuar.', 'hu': 'A felhasználó tartózkodási helyének azonosítása hasznos lehet ajánlási rendszerekhez, demográfiai elemzésekhez és katasztrófajárványok figyelemmel kíséréséhez. Bár a Twitter lehetővé teszi a felhasználók számára, hogy önkéntesen felfedjék tartózkodási helyüket, az ilyen információk nem általánosan elérhetőek. A tweet elemzése általános becslést nyújthat a tweet helyéről, miközben betekintést nyújt a felhasználó dialektusába és más nyelvi markerekbe. Az ilyen nyelvi attribútumok használhatók a tweet eredetének regionális közelítésére. Ebben a tanulmányban bemutatunk egy neurális regressziós modellt, amely képes azonosítani egy tweet nyelvi bonyolultságát, hogy megjósolja a felhasználó helyét. A végső modell azonosítja a tweetbe ágyazott dialektust és előrejelzi a tweet helyét.', 'el': 'Ο εντοπισμός της θέσης ενός χρήστη μπορεί να είναι χρήσιμος για συστήματα συστάσεων, δημογραφικές αναλύσεις και παρακολούθηση επιδημίας καταστροφών. Παρόλο που το Twitter επιτρέπει στους χρήστες να αποκαλύπτουν οικειοθελώς την τοποθεσία τους, τέτοιες πληροφορίες δεν είναι καθολικά διαθέσιμες. Η ανάλυση ενός tweet μπορεί να παρέχει μια γενική εκτίμηση της θέσης ενός tweet, ενώ παράλληλα δίνει εικόνα για τη διάλεκτο του χρήστη και άλλους γλωσσικούς δείκτες. Τέτοια γλωσσικά χαρακτηριστικά μπορούν να χρησιμοποιηθούν για να παρέχουν μια περιφερειακή προσέγγιση της προέλευσης του tweet. Σε αυτή την εργασία, παρουσιάζουμε ένα μοντέλο νευρωνικής παλινδρόμησης που μπορεί να προσδιορίσει τις γλωσσικές πολυπλοκότητες ενός tweet για να προβλέψει την τοποθεσία του χρήστη. Το τελικό μοντέλο προσδιορίζει τη διάλεκτο που ενσωματώνεται στο tweet και προβλέπει τη θέση του tweet.', 'it': "Identificare la posizione di un utente può essere utile per i sistemi di raccomandazione, le analisi demografiche e il monitoraggio delle emergenze. Sebbene Twitter consenta agli utenti di rivelare volontariamente la loro posizione, tali informazioni non sono universalmente disponibili. Analizzare un tweet può fornire una stima generale della posizione di un tweet fornendo allo stesso tempo informazioni sul dialetto dell'utente e altri marcatori linguistici. Tali attributi linguistici possono essere utilizzati per fornire un'approssimazione regionale delle origini dei tweet. In questo articolo, presentiamo un modello di regressione neurale in grado di identificare le complessità linguistiche di un tweet per prevedere la posizione dell'utente. Il modello finale identifica il dialetto incorporato nel tweet e prevede la posizione del tweet.", 'lt': 'Naudotojo vietos nustatymas gali būti naudingas rekomendacijų sistemoms, demografinei analizei ir nelaimių protrūkių stebėsenai. Nors Twitter leidžia naudotojams savanoriškai atskleisti savo vietą, tokia informacija nėra visuotinai prieinama. Analizuojant tweet ą galima apskritai įvertinti tweeto vietą ir kartu sužinoti vartotojo ir kitų kalbinių žymenų dialektą. Tokie kalbiniai požymiai gali būti naudojami regioniniam tweeto kilmės derinimui. Šiame dokumente pristatome nervų regresijos model į, kuris gali nustatyti kalbinius tweeto sudėtingumus, kad būtų galima nuspėti naudotojo vietą. Galutiniame modelyje nurodomas į tweet ą įtrauktas dialektas ir numatoma tweeto vieta.', 'ms': 'Mengenalpasti lokasi pengguna boleh berguna untuk sistem rekomendasi, analisis demografik, dan pengawasan kejadian bencana. Walaupun Twitter membenarkan pengguna untuk mengungkapkan lokasi mereka secara sukarela, maklumat tersebut tidak tersedia secara umum. Menganalisis tweet boleh memberikan penghargaan umum lokasi tweet semasa memberikan pandangan ke dalam dialekt pengguna dan penanda bahasa lain. Atribut bahasa tersebut boleh digunakan untuk menyediakan pendekatan kawasan asal tweet. In this paper, we present a neural regression model that can identify the linguistic intricacies of a tweet to predict the location of the user.  Model terakhir mengenalpasti dialekt yang diletakkan dalam tweet dan meramalkan lokasi tweet.', 'mk': 'Идентификувањето на локацијата на корисникот може да биде корисно за системите за препораки, демографските анализи и мониторингот на појавата на катастрофи. Иако Твитер им овозможува на корисниците доброволно да ја откријат својата локација, ваквата информација не е универзално достапна. Анализирањето на Твитер може да обезбеди генерална проценка на локацијата на Твитерот, додека се дава информација за дијалектот на корисникот и другите јазички маркери. Таквите јазични атрибути може да се користат за да се обезбеди регионална приближување на потеклот на Твитер. Во овој весник претставуваме нервен регресен модел кој може да ги идентификува јазичните сложености на твитот за да ја предвиде локацијата на корисникот. Последниот модел го идентификува дијалектот вклучен во твитот и ја предвидува локацијата на твитот.', 'mt': 'L-identifikazzjoni tal-post tal-utent tista’ tkun utli għa s-sistemi ta’ rakkomandazzjoni, għall-analiżi demografika u għall-monitoraġġ tat-tifqigħa tad-diżastri. Għalkemm Twitter jippermetti lill-utenti jiżvelaw volontarjament il-post tagħhom, tali informazzjoni mhijiex universalment disponibbli. L-analiżi ta’ tweet tista’ tipprovdi stima ġenerali ta’ post ta’ tweet filwaqt li tagħti ħarsa lejn id-dijalekt tal-utent u markaturi lingwistiċi oħra. Attributi lingwistiċi bħal dawn jistgħu jintużaw biex jipprovdu approssimazzjoni reġjonali tal-oriġini tat-tweet. F’dan id-dokument, nippreżentaw mudell ta’ rigressjoni newrali li jista’ jidentifika l-kumplikazzjonijiet lingwistiċi ta’ tweet biex jipprevedi l-post tal-utent. Il-mudell finali jidentifika d-dijalekt inkorporat fit-tweet u jipprevedi l-post tat-tweet.', 'ml': 'ഒരു ഉപയോക്താവിന്റെ സ്ഥാനം തിരിച്ചറിയുവാന്\u200d സുപാര്\u200dശിക്കുന്ന സിസ്റ്റമുകള്\u200dക്ക്, ഡെമോഗ്രാഫിക് അന്യായങ്ങള്\u200d ടൂട്ടര്\u200d ഉപയോക്താക്കള്\u200dക്ക് സ്വാതന്ത്ര്യമായി അവരുടെ സ്ഥാനം വെളിപ്പെടുത്താന്\u200d അനുവദിക്കുന്നുവെങ്കി ഉപയോക്താവിന്റെയും മറ്റുള്ള ഭാഷ മാര്\u200dക്കുകളുടെയും ഡയലിക്കേഷനിലേക്കും കാണിക്കുമ്പോള്\u200d ഒരു ട്വീറ്റ് സ്ഥലത്തിന്റെ ഒരു  ഇങ്ങനെയുള്ള ഭാഷക്കുറിപ്പുകള്\u200d ട്വീറ്റിന്റെ അടുത്ത ട്രീറ്റുകള്\u200d നല്\u200dകുന്നതിനായി ഉപയോഗിക്കാം. In this paper, we present a neural regression model that can identify the linguistic intricacies of a tweet to predict the location of the user.  അവസാനത്തെ മോഡല്\u200d ടൂട്ടിയില്\u200d ചേര്\u200dത്തിരിക്കുന്ന ഡയലക്ട്രേക്ക് തിരിച്ചറിയുന്നു. ടൂട്ടിയിലെ സ്ഥലം പ', 'mn': 'Хэрэглэгчдийн байр сууриллагааг тайлбарлах нь зөвлөгөөний систем, демографик шинжилгээ, гамшгийн үр дүнг удирдах хэрэгтэй. Хэдийгээр Twitter хэрэглэгчид сайн дурын байр суурилуулахад боломж олгодог ч гэсэн ийм мэдээлэл ертөнцөд байхгүй. Твиттийн шинжилгээ нь хэрэглэгч болон бусад хэлний маркертүүдийн диалектын тухай ойлголт өгөх үед туйтын байр сууриллагын ерөнхий дүгнэлт гаргаж чадна. Ийм хэлний харилцаа нь туйтын эх үүсвэрийг ойролцохын тулд ашиглаж болно. Энэ цаасан дээр бид хэрэглэгчийн байр суурь байдлыг таамаглахын тулд tweet-ын хэлний интрикацийг тодорхойлж чадах мэдрэлийн регрессийн загварыг тайлбарлаж байна. Сүүлийн загварын загвар нь tweet-д оршигдсон диалектыг тодорхойлж, tweet-ын газрыг таамагладаг.', 'no': 'Å identifisera plasseringa til ein brukar kan vera nyttig for anbefalingssystemet, demografiske analyser og overvåking av avslutting av katastrof. Selv om Twitter lèt brukarar å opna plasseringa sine voluntarileg, er slike informasjon ikkje universelt tilgjengeleg. Analysering av ein tweet kan gje ein generell estimating av ein tweet- plassering mens du gjer innsikt i dialekten av brukaren og andre lingviske merker. Dei slike lingviske attributtane kan brukast for å gjera ein regional nærming av tweet-opprinnelinjer. I denne papiret presenterer vi eit neuralregresjonsmodul som kan identifisera linguistiske intrikasjon av ein tweet for å foregå plasseringa av brukaren. Den siste modellen identifiserer dialekten innebygd i tweetet og foregår plasseringa på tweetet.', 'pl': 'Identyfikacja lokalizacji użytkownika może być przydatna w systemach rekomendacji, analizach demograficznych i monitorowaniu epidemii katastrof. Chociaż Twitter pozwala użytkownikom dobrowolnie ujawnić swoją lokalizację, informacje te nie są powszechnie dostępne. Analiza tweeta może zapewnić ogólną ocenę lokalizacji tweeta, dając jednocześnie wgląd w dialekt użytkownika i inne znaczniki językowe. Takie atrybuty językowe mogą być wykorzystane do zapewnienia regionalnego przybliżenia pochodzenia tweetów. W artykule przedstawiamy model regresji neuronowej, który może zidentyfikować zawiłości językowe tweeta, aby przewidzieć lokalizację użytkownika. Ostateczny model identyfikuje dialekt osadzony w tweecie i przewiduje lokalizację tweeta.', 'ro': 'Identificarea locației unui utilizator poate fi utilă pentru sistemele de recomandare, analizele demografice și monitorizarea focarelor de dezastre. Deși Twitter permite utilizatorilor să dezvăluie voluntar locația lor, astfel de informații nu sunt disponibile universal. Analiza unui tweet poate oferi o estimare generală a locației tweet, oferind în același timp o perspectivă asupra dialectului utilizatorului și a altor markeri lingvistici. Astfel de atribute lingvistice pot fi utilizate pentru a oferi o aproximare regională a originii tweet-urilor. În această lucrare, prezentăm un model de regresie neurală care poate identifica complexitățile lingvistice ale unui tweet pentru a prezice locația utilizatorului. Modelul final identifică dialectul încorporat în tweet și prezice locația tweet-ului.', 'sr': 'Identifikacija lokacije korisnika može biti korisna za sisteme preporuke, demografske analize i praćenje napada katastrofa. Iako Twitter dozvoljava korisnicima da volontno otkriju svoju lokaciju, takve informacije nisu univerzalno dostupne. Analiziranje tweta može pružiti generalnu procjenu lokacije tweet a dok pruža uvid u dijalekt korisnika i drugih jezičkih markera. Takve lingvističke atribute mogu se koristiti za pružanje regionalnog približavanja porijekla tweet a. U ovom papiru predstavljamo model neuralne regresije koji može identifikovati jezičke intrikacije tweet a kako bi predvidjeli lokaciju korisnika. Posljednji model identifikuje dijalekt uključen u tweet i predviđa lokaciju tweeta.', 'si': 'ප්\u200dරයෝජකයාගේ තැනක් අඳුරගන්න පුළුවන් ප්\u200dරයෝජනය පද්ධතිය, ප්\u200dරයෝජනය විශ්ලේෂණය, සහ ප්\u200dරතිකාරණ ට්විටර් ප්\u200dරයෝජකයන්ට ඔවුන්ගේ තැන පිළිගන්න පුළුවන් වුනොත්, ඒ වගේ තොරතුරු සාමාන්\u200dය විශේෂ ට්විට් එක විශ්ලේෂණය කරන්න පුළුවන් ට්විට් ස්ථානයේ සාමාන්\u200dය විශ්ලේෂණයක් සහ අනිත් භාෂාවික සංකේතකයේ දැන මේ භාෂාවික විශේෂතාව භාවිත කරන්න පුළුවන් විදිහට ටුයිට් ප්\u200dරධානයක් සම්බන්ධ වෙන්න. මේ පත්තරේ අපි පෙන්වන්නේ න්\u200dයූරල් රිග්\u200dරේෂන් මොඩේල් එකක් තියෙන්නේ, ඒ වගේම ප්\u200dරයෝජකයාගේ තැනය පුළුවන් විදිහට ට අන්තිම මොඩේල් එක ට්විට් වල ඇතුළත් ඩායිලක්ට් එක්ක පරීක්ෂණය කරනවා ඒ වගේම ට්විට් වල තැනය ප්\u200dරශ්', 'so': 'Aqoonsashada meesha uu isticmaalayo wuxuu faa’iido u noqon karaa nidaamka talo-bixinta, baaritaanka demographiga iyo socoshada dhibaatada. Inta kastoo Twitter isticmaalayaasha uu si iskaa ah u muujiyo meesha ay joogto, macluumaadkaas oo caalami ah ma heli karo. Inta lagu baaraandegayo Tweetka waxaa laga heli karaa qiimeynta caadiga ah oo ku qoran karo meeshii Twitteet, marka aad aragtida ku qoran karto sawirka isticmaalaha iyo calaamadaha kale oo luqada ah. Waxyaabahaas luuqadaha oo kale waxaa lagu isticmaali karaa in lagu bixiyaa qiyaastii asalka Twitterka. Warqaddan waxan ku qornaa model dib u celinta neurada ah oo aqoonsan karta caadooyinka luuqada ah ee twitterka si loo sii sheego meesha uu isticmaalayo. Tusaale ugu dambeeya ayaa aqoonsanaya lambarka ku qoran Twitteetka, wuxuuna horay u sheegayaa meesha uu ku yaalo Twitteet.', 'ka': 'მომხმარებლის ადგილის განსაცნობა შეიძლება იყოს გამოყენებელი სისტემებისთვის, დემოგრაფიკური ანალიზაციისთვის და შემდეგ შემდეგ მონაცნობისთვის. თუმცა Twitter მოხმარებელი მომხმარებელი თავის ადგილის ადგილის აღმოჩვენება, ეს ინფორმაცია არ არის სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა. Tweet-ის ანალიზაცია შეიძლება გავაკეთოთ სამყარო სისტემისტიკის და სხვა ლუნგური მარკერების დიალექტის განსაზღვრებას. რამდენიმე ლენგურისტიკური ატრიბუტები შეიძლება გამოყენება, რომელიც რეგიონალური გადახლოების მიღება. ამ გვერდიში ჩვენ აჩვენებთ ნეიროლური რეგრესიის მოდელი, რომელიც შეუძლია განვიცნოთ ტვიტის ენტრიკაციის ინტერიკაციას, რომელიც გამოყენებელი ადგილის წინასწორება. საბოლოო მოდელის მოდელის იდენტიფიკაცია დიალექტი, რომელიც გადაწყენებულია ტვირში და გადაწყენებს ტვირის ადგილი.', 'sv': 'Att identifiera en användares plats kan vara användbart för rekommendationssystem, demografiska analyser och övervakning av katastrofutbrott. Även om Twitter tillåter användare att frivilligt avslöja sin plats är sådan information inte allmänt tillgänglig. Analys av en tweet kan ge en allmän uppskattning av en tweetplats samtidigt som det ger insikt i användarens dialekt och andra språkliga markörer. Sådana språkliga attribut kan användas för att ge en regional approximation av tweets ursprung. I denna uppsats presenterar vi en neural regressionsmodell som kan identifiera språkliga komplexiteter i en tweet för att förutsäga användarens position. Den slutliga modellen identifierar dialekten inbäddad i tweeten och förutspår platsen för tweeten.', 'ta': 'ஒரு பயனரின் இடத்தை அடையாளம் பரிந்துரைக்கும் அமைப்புகள், demographic analysis, மற்றும் துன்பங்கள் வெளியேறும் நோட்டம் பயனுள்ளது. ஆயினும் Twitter பயனர்கள் தங்கள் இடத்தை தானாகவே வெளிப்படுத்த அனுமதிக்கிறது, இவ்வாறு தகவல் உலகத்தில் இல்லை. Analyzing a tweet can provide a general estimation of a tweet location while giving insight into the dialect of the user and other linguistic markers.  இத்தகைய மொழிக்குரிய குணங்கள் தொடர்ந்து கொள்ளும் தொடர்பு மூலத்தின் சுழற்சியை வழங்க பயன்படுத்தலாம். இந்த காகிதத்தில், நாம் ஒரு புதிய திருப்ப மாதிரி கொண்டுள்ளோம். இது பயனரின் இடத்தை முன்கூற முடியும். கடைசி மாதிரி தொடர்ச்சியில் உள்ள விளக்கச்சீட்டை கண்டுபிடிக்கும் மற்றும் tweet இடத்தை முன்னோட்டுகிறது.', 'kk': 'Пайдаланушының орналасуын анықтау рекомендациялау жүйелері, демографиялық анализ және бедсендіктерді бақылау үшін пайдалы болады. Твиттер пайдаланушылардың орналасуын көңіл түрде көрсетуге мүмкіндік береді, бұл мәлімет әрқашанда мүмкін емес. Твитті анализациялау пайдаланушының және басқа лингвистикалық маркерлерінің диалектігін көрсету кезінде жалпы tweet орналасуын анықтай алады. Бұл лингвистикалық атрибуттары tweet негізінің жақындау үшін қолданылады. Бұл қағазда, пайдаланушының орналасуын таңдау үшін тілінген интрикациясын анықтай алатын невралдық регрессия үлгісін таңдаймыз. Соңғы үлгі tweet де ендірілген диалектті анықтап, tweetдің орналасуын көрсетеді.', 'ur': 'یوسٹر کی جگہ شناسایی کرنا ضروری ہے کہ سفارش نظام، دموگرافیک تحلیل اور مصیبت آواٹ براک موانٹر کے لئے فائدہ اٹھائے۔ اگرچہ توئیٹر کارساز کو اپنی جگہ سے آزاد کرنا اجازت دیتا ہے، یہ معلومات عمومی طور پر موجود نہیں ہے۔ ٹویٹ کی تحلیل کرنا ایک ٹویٹ کی جگہ کا ایک عمومی ارزش دے سکتا ہے جبکہ کارساز اور دوسرے زبان نشانیوں کے ڈالکت میں نظر آتا ہے۔ یہ زبان انصافیات ٹیوٹ اصل کی تقرب کے لئے استعمال کر سکتے ہیں. اس کاغذ میں، ہم ایک نیورال ریگرس موڈل پیش کریں جو ایک ٹویٹ کی زبان انٹریک کی تعریف کو پہچان سکتا ہے کہ کارساز کی جگہ کی پیش بینی کرے۔ آخری موڈل ٹویٹ میں پیدا ہوا دائیلکسٹ کو پہچان دیتا ہے اور ٹویٹ کی جگہ کی پیش بینی کرتا ہے.', 'vi': 'Việc xác định vị trí của người dùng có thể hữu dụng cho hệ thống đề nghị, phân tích nhân khẩu và giám s át thảm họa. Tuy rằng Twitter cho phép người dùng t ự nguyện tiết lộ vị trí của mình, nhưng thông tin đó chưa sẵn sàng. Phân tích tweet có thể cung cấp một đánh giá phổ biến về địa điểm tweet trong khi cung cấp thông tin về ngôn ngữ của người dùng và các đánh dấu khác. Tài liệu ngôn ngữ này có thể được sử dụng để xác định nguồn gốc của tweet ở khu vực này. Trong tờ giấy này, chúng tôi đưa ra một mô hình hồi phục thần kinh có thể xác định sự phức tạp ngôn ngữ của tweet để dự đoán vị trí của người dùng. Người mẫu cuối cùng xác định vị trí của ngôn ngữ trong tweet và dự đoán vị trí của tweet.', 'uz': "Name @ info Twitterda taʼminlovchi foydalanuvchi va boshqa lingvistik markerlarini dialeklashda foydalanuvchiga ko'rinishi mumkin. Bu tilni taʼminlovchi Twitterning asl asosidagi soʻzni yaratish uchun foydalanish mumkin. Bu hujjatda, biz foydalanuvchining joyini predict qilish uchun neyural boshqaruv modelini aniqlash mumkin. Oxirgi model Twitterda ichki dialekni aniqlaydi va Twitter manzilini koʻrsatish.", 'bg': 'Идентифицирането на местоположението на потребителя може да бъде полезно за системи за препоръки, демографски анализи и мониторинг на епидемии при бедствия. Въпреки че позволява на потребителите доброволно да разкриват местоположението си, такава информация не е всеобщо достъпна. Анализирането на туит може да осигури обща оценка на местоположението на туит, като същевременно дава представа за диалекта на потребителя и други лингвистични маркери. Такива лингвистични атрибути могат да се използват за осигуряване на регионално сближаване на произхода на туит. В тази статия представяме невронен регресионен модел, който може да идентифицира лингвистичните сложности на туит, за да предскаже местоположението на потребителя. Крайният модел идентифицира диалекта, вграден в туита и прогнозира местоположението на туита.', 'hr': 'Identifikacija lokacije korisnika može biti korisna za sustave preporuke, demografske analize i praćenje napada katastrofa. Iako Twitter omogućava korisnicima da dobrovoljno otkriju svoju lokaciju, takve informacije nisu univerzalno dostupne. Analiziranje tweta može pružiti opću procjenu lokacije tweet a dok pruža uvid u dijalekt korisnika i drugih jezičkih znakova. Takve jezičke atribute mogu se koristiti za pružanje regionalnog približavanja porijekla tweet a. U ovom papiru predstavljamo model neuralne regresije koji može identificirati jezičke intrikacije tweet a kako bi predvidjeli lokaciju korisnika. Posljednji model identificira dijalekt uključen u tweet i predviđa lokaciju tweeta.', 'da': 'At identificere en brugers placering kan være nyttigt til anbefalingssystemer, demografiske analyser og overvågning af katastrofeudbrud. Selvom Twitter giver brugerne mulighed for frivilligt at afsløre deres placering, er sådanne oplysninger ikke universelt tilgængelige. Analyse af en tweet kan give en generel vurdering af en tweet placering og samtidig give indsigt i brugerens dialekt og andre sproglige markører. Sådanne sproglige egenskaber kan bruges til at give en regional tilnærmelse af tweets oprindelse. I denne artikel præsenterer vi en neural regressionsmodel, der kan identificere de sproglige kompleksiteter i en tweet for at forudsige placeringen af brugeren. Den endelige model identificerer dialekten indlejret i tweeten og forudsiger placeringen af tweeten.', 'nl': 'Het identificeren van de locatie van een gebruiker kan nuttig zijn voor aanbevelingssystemen, demografische analyses en monitoring van uitbraken van rampen. Hoewel Twitter gebruikers toestaat om vrijwillig hun locatie te onthullen, is dergelijke informatie niet universeel beschikbaar. Het analyseren van een tweet kan een algemene schatting geven van een tweet locatie terwijl het inzicht geeft in het dialect van de gebruiker en andere taalkundige markers. Dergelijke taalkundige kenmerken kunnen worden gebruikt om een regionale benadering van de herkomst van tweets te bieden. In dit artikel presenteren we een neuraal regressiemodel dat de linguïstische complexiteit van een tweet kan identificeren om de locatie van de gebruiker te voorspellen. Het uiteindelijke model identificeert het dialect ingebed in de tweet en voorspelt de locatie van de tweet.', 'de': 'Die Standortbestimmung eines Benutzers kann für Empfehlungssysteme, demografische Analysen und die Überwachung von Katastrophenausbrüchen nützlich sein. Obwohl Twitter Nutzern erlaubt, freiwillig ihren Standort anzugeben, sind solche Informationen nicht allgemein verfügbar. Die Analyse eines Tweets kann eine allgemeine Einschätzung des Tweets-Standorts liefern und gleichzeitig Einblick in den Dialekt des Benutzers und andere linguistische Marker geben. Solche sprachlichen Attribute können verwendet werden, um eine regionale Annäherung der Tweet-Ursprünge zu liefern. In diesem Beitrag stellen wir ein neuronales Regressionsmodell vor, das die sprachlichen Feinheiten eines Tweets identifizieren kann, um den Standort des Nutzers vorherzusagen. Das endgültige Modell identifiziert den im Tweet eingebetteten Dialekt und prognostiziert den Standort des Tweets.', 'fa': 'شناسایی موقعیت یک کاربر می تواند برای سیستم پیشنهاد، تحلیل دموگرافیک و تماشاگر بیماری از فاجعه\u200cها مفید باشد. اگرچه توئیتر به کاربر اجازه می دهد که موقعیت خود را به داوطلب آشکار کنند، این اطلاعات به طور کلی در دسترس نیست. تحلیل یک تویت می\u200cتواند یک مقدار عمومی از موقعیت تویت را در حالی که به دیالکت کاربر و علامت\u200cهای دیگر زبان\u200cشناسی مشاهده می\u200cکند. این ویژگی\u200cهای زبان\u200cشناسی می\u200cتوانند برای تقریبا به منطقه\u200cای از اصل توئیت استفاده شود. در این کاغذ، ما یک مدل بازگشت عصبی را نشان می دهیم که می تواند درگیری زبان\u200cشناسی یک تویت را شناسایی کند تا جایگاه کاربر را پیش بینی کند. مدل نهایی دیالکت را در تویت مشخص می\u200cکند و موقعیت تویت را پیش بینی می\u200cکند.', 'id': 'Identifikasi lokasi pengguna dapat berguna untuk sistem rekomendasi, analisis demografis, dan pengawasan wabah bencana. Walaupun Twitter memungkinkan pengguna untuk secara sukarela mengungkapkan lokasi mereka, informasi tersebut tidak tersedia secara umum. Analisasi tweet dapat memberikan penilaian umum dari lokasi tweet sementara memberikan penglihatan ke dalam dialekt pengguna dan marker bahasa lainnya. Atribut bahasa seperti ini dapat digunakan untuk menyediakan pendekatan regional dari asal tweet. Dalam kertas ini, kami mempersembahkan model regresi saraf yang dapat mengidentifikasi kesulitan bahasa dari tweet untuk memprediksi lokasi pengguna. Model akhir mengidentifikasi dialekt yang terlibat dalam tweet dan memprediksi lokasi tweet.', 'ko': '사용자의 위치를 식별하는 것은 추천 시스템, 인구 통계 분석과 재해 폭발 모니터링에 매우 유용하다.트위터는 사용자가 자신의 위치를 자발적으로 밝힐 수 있도록 허용하지만, 이런 정보는 보편적으로 사용할 수 있는 것이 아니다.추문을 분석하면 추문의 위치에 대한 일반적인 평가를 제공할 수 있고 사용자의 사투리와 다른 언어 표기를 깊이 있게 이해할 수 있다.이러한 언어 속성은 트위터 원본의 지역 근사값을 제공하는 데 사용할 수 있다.본고에서 우리는 추문의 언어 복잡성을 식별하고 사용자의 위치를 예측할 수 있는 신경 회귀 모델을 제시했다.최종 모델은 추문에 박힌 사투리를 식별하고 추문의 위치를 예측한다.', 'sw': 'Kutambua eneo la mtumiaji linaweza kuwa na manufaa kwa mifumo ya mapendekezo, uchambuzi wa demokrasia, na kufuatiliwa kwa majanga yanayotokea. Ingawa Twita inaruhusu watumiaji kuonyesha eneo hilo kwa hiari, taarifa kama hizo hazipatikani duniani. Kuchambua twiti inaweza kutoa estimation ya jumla ya maeneo ya twita wakati akitoa uelewa wa mtazamo wa mtumiaji na alama nyingine za lugha. Such linguistic attributes can be used to provide a regional approximation of tweet origins.  Katika karatasi hii, tunaweka muundo wa kandamizi wa uraia unaoweza kutambua utambulisho wa lugha wa twiti ili kutabiri sehemu ya mtumiaji. Mfano wa mwisho unaonyesha mjadala ulioandikwa kwenye twita na kutabiri sehemu ya twita.', 'tr': 'Ullançylaryň ýerini tanyşdyrmak maslahat sistemleri, demografik analyzlary we daşlaryň täsirleri üçin peýdaly bolar. Twitter Ullançylaryň ýerini meýdança açmaga rugsat bermese de, şol maglumat öňünde hiç hili ýerlerde däl. Tweet çözümlenmek usulçylaryň we başga dil işaretçileriniň dialektine gözleýän ýerini üýtgedip biler. Bärde lingwistiki atributler tweet görnüşiniň ýakynlaşyny üýtgetmek üçin ullanyla bilýär. Bu kagyzda, Ullançynyň ýerini öňden geçirmek üçin tweet lingwistiki intrikatyny tanap biljek nural regressiýa nusgasyny görkezip bileris. Soňky nusga tweetde girdirilen dialektany tanap edýär we tweetniň ýerini çaklaýar.', 'af': "Die identifiseer van 'n gebruiker se ligging kan bruikbaar wees vir aanbevelingsstelsels, demografiese analiserings en afspraak-uitbrekking. Alhoewel Twitter laat gebruikers vrolik hul ligging openbaar, sodanige inligting is nie universele beskikbaar nie. Analisering van 'n tweet kan 'n algemene estimatie van 'n tweet ligging verskaf terwyl gegee insig in die dialekte van die gebruiker en ander lingvisse merkers. Hierdie lingwisiese eienskappe kan gebruik word om 'n regionale toekoms van tweet origins te verskaf. In hierdie papier, voorsien ons 'n neurale regresie model wat die lingvisse intrikasies van 'n tweet kan identifiseer om die ligging van die gebruiker te voorskou. Die eindelike model identifiseer die dialekte in die tweet ingesit en voorskou die ligging van die tweet.", 'sq': 'Identifikimi i vendit të një përdoruesi mund të jetë i dobishëm për sistemet rekomandimi, analizat demografike dhe mbikqyrjen e shpërthimit të katastrofës. Megjithëse Twitter lejon përdoruesit t ë zbulojnë vullnetarisht vendndodhjen e tyre, informacioni i tillë nuk është në dispozicion universal. Analizimi i një tweet mund të sigurojë një vlerësim të përgjithshëm të një lokaliteti të tweetit ndërsa jep kuptim në dialektin e përdoruesit dhe markerëve të tjerë gjuhësor. Të tilla atribute gjuhësore mund të përdoren për të siguruar një përafërsim rajonal të origjinëve të tweetit. In this paper, we present a neural regression model that can identify the linguistic intricacies of a tweet to predict the location of the user.  Modeli përfundimtar identifikon dialektin e përfshirë në tweet dhe parashikon vendndodhjen e tweetit.', 'am': 'የተጠቃሚውን ቦታ ማረጋገጥ ለመስታወቂያ ስርዓቶች፣ demographic analyses እና የጥፋት ውጤት መስኮት የሚጠቅመው ይጠቅማል፡፡ ምንም እንኳን በትዊተር ተጠቃሚዎችን በፈቃድ ቦታዎቻቸውን እንዲገልጹ ይፈልጋል፣ እንደዚህ መረጃዎች በዓለምነት አይገኙም፡፡ በትዊተር መግለጫ በተጠቃሚው እና ሌሎችን ቋንቋዊ ምልክቶች ማሳየት ሲሰጥ የTwitteet ቦታ የጠቅላላ መጠቀሚያ መጠቀም እንዲሰጥ ይችላል፡፡ እንደዚህ የቋንቋዊ ምርጫዎች የአካባቢ አካባቢ ትዊተር አቀማመጥ ለመስጠት ይችላል፡፡ በዚህ ካላት፣ የጠቃሚውን ቦታ ለመግለጽ የሚችሉትን የቋንቋዊ ጥያቄዎችን የሚያሳውቅ የናውሬል አስተዳደር ሞዴል እናቀርባለን፡፡ የመጨረሻው ሞዴል በትዊተር ውስጥ የተደረገውን ቁጥጥር ያሳያል የTwitteet ስፍራውን ያሳያል፡፡', 'hy': 'Օգտագործողի գտնվելու վայրը կարող է օգտակար լինել խորհուրդների համակարգերի, դեմոգրաֆիկ վերլուծումների և աղետի բռնությունների մոնիտորների համար: Չնայած Թվիթերը թույլ է տալիս օգտագործողներին կամավոր բացահայտել իրենց տեղակայությունը, այդ տեղեկատվությունը համաշխարհային հասանելի չէ: Թվիթի վերլուծումը կարող է տալ գլխավոր գնահատականներ թվիթի տեղադրության մասին, միաժամանակ ներկայացնելով օգտագործողի և այլ լեզվաբանական մարկերների դիալեկտը: Այսպիսի լեզվաբանական առանձնահատկությունները կարող են օգտագործվել թվիթի սկզբնական տարածաշրջանի մոտեցման համար: Այս թղթի մեջ մենք ներկայացնում ենք նյարդային ռեգրեսիայի մոդել, որը կարող է բացահայտել թվիթի լեզվաբանական բարդությունները, որպեսզի կանխատեսի օգտագործողի տեղը: Վերջին մոդելը բացահայտում է թվիթերի մեջ ներառված դիալեկտը և կանխատեսում է թվիթերի տեղադրությունը:', 'az': 'İstifadəçilərin yerini təsdiqləməsi, demografik analizi və fəsad döyüşü gözləməsi üçün faydalı olar. Twitter istifadəçilərin yerini gönüllü olaraq göstərməsinə izin verir, amma bu məlumat büt ün məlumatlardan faydalanmaz. Twet analizəsi istifadəçilərin və başqa dil işaretçilərinin dialektlərinə nəzər verən bir twet yerinin genel qiymətini təmin edə bilər. Bütün dil xüsusiyyətlərini tweet kökünün yaxınlaşması üçün istifadə edilə bilər. Bu kağızda, istifadəçinin yerini təsdiqləmək üçün tweet dillərinin intrikatisini tanımlayan nöral regresiya modeli göstəririk. Son modeli twetdə içərilən dialekti tanıyır və twet yerini təmin edir.', 'bn': 'পরামর্শ সিস্টেম, গণগ্রাফিক বিশ্লেষণ এবং দুর্যোগ বিপর্যয় পর্যবেক্ষণের জন্য ব্যবহারকারীর অবস্থান পরিচয় করা যাবে। যদিও টুইটার ব্যবহারকারীদের স্বেচ্ছায় তাদের অবস্থান প্রকাশ করার অনুমতি দেয়, তবে এই তথ্য সার্বভাবে পাওয়া যায় না। টুইট বিশ্লেষণ করে টুইটের একটি সাধারণ হিসেবে একটি টুইট স্থান প্রদান করতে পারে যখন ব্যবহারকারী এবং অন্যান্য ভাষাগত চিহ্নের চিহ্নের বিষয়ট এই ধরনের ভাষার বৈশিষ্ট্য ব্যবহার করা যাবে আঞ্চলিক টুইটের প্রাথমিক ক্ষেত্রে। এই কাগজটিতে আমরা একটি নিউরুল প্রতিরোধ মডেল উপস্থাপন করছি যা ব্যবহারকারীর অবস্থান ভবিষ্যদ্বাণী করার জন্য টুইটের ভাষায় টুইটের ভাষাগত প্রয চূড়ান্ত মডেল টুইটে যে ডায়ালেক্টটি প্রকাশ করা হয়েছে তা চিহ্নিত করেছে এবং টুইটের অবস্থান ভবিষ্যদ্বাণী করেছে।', 'bs': 'Identifikacija lokacije korisnika može biti korisna za sisteme preporuke, demografske analize i praćenje napada katastrofa. Iako Twitter omogućava korisnicima da volontno otkriju svoju lokaciju, takve informacije nisu univerzalno dostupne. Analiziranje tweta može pružiti generalnu procjenu lokacije tweet a dok pruža uvid u dijalekt korisnika i drugih jezičkih markera. Takvi lingvistički atributi se mogu koristiti za pružanje regionalnog približavanja porijekla tweet a. U ovom papiru predstavljamo model neuralne regresije koji može identificirati jezičke intrikacije tweet a kako bi predvidjeli lokaciju korisnika. Posljednji model identificira dijalekt uključen u tweet i predviđa lokaciju tweeta.', 'ca': "Identificar la ubicació d'un usuari pot ser útil per a sistemes de recomanació, anàlisis demogràfics i monitoritzar l'erupció de desastres. Malgrat que Twitter permet als usuaris revelar voluntariament la seva ubicació, aquesta informació no està disponible a nivell universal. Analyzing a tweet can provide a general estimation of a tweet location while giving insight into the dialect of the user and other linguistic markers.  Aquests atributs lingüístics poden ser utilitzats per proporcionar una aproximació regional dels orígens de tweet. En aquest article, presentem un model de regressió neuronal que pot identificar les complicacions lingüístices d'un tweet per predir la ubicació del usuari. El model final identifica el dialecte incorporat en el tweet i prediu la ubicació del tweet.", 'cs': 'Identifikace polohy uživatele může být užitečné pro doporučovací systémy, demografické analýzy a monitorování epidemie katastrof. Přestože Twitter uživatelům umožňuje dobrovolně sdělit svou polohu, takové informace nejsou všeobecně dostupné. Analýza tweetu může poskytnout obecný odhad umístění tweetu a zároveň poskytnout vhled do dialektu uživatele a dalších jazykových značek. Tyto jazykové atributy mohou být použity k poskytnutí regionální aproximace původu tweetů. V tomto článku představujeme neuronový regresní model, který dokáže identifikovat jazykové složitosti tweetu a předpovědět umístění uživatele. Konečný model identifikuje dialekt vložený do tweetu a předpovídá umístění tweetu.', 'et': 'Kasutaja asukoha kindlakstegemine võib olla kasulik soovitussüsteemide, demograafiliste analüüside ja katastroofipuhangute seire jaoks. Kuigi Twitter võimaldab kasutajatel oma asukohta vabatahtlikult avaldada, ei ole selline teave üldiselt kättesaadav. Täitsu analüüsimine võib anda üldise hinnangu säutsu asukohast, andes samas ülevaate kasutaja murdest ja muudest keelelistest markeritest. Selliseid keelelisi atribuute saab kasutada säutsu päritolu piirkondlikuks ühtlustamiseks. Käesolevas töös tutvustame neuroregressiooni mudelit, mis suudab tuvastada säutsu keerukust, et ennustada kasutaja asukohta. Lõplik mudel tuvastab säutsu murde ja prognoosib säutsu asukoha.', 'fi': 'Käyttäjän sijainnin tunnistaminen voi olla hyödyllistä suositusjärjestelmissä, demografisissa analyyseissä ja katastrofiepidemian seurannassa. Vaikka Twitter sallii käyttäjien vapaaehtoisesti paljastaa sijaintinsa, tällaiset tiedot eivät ole yleisesti saatavilla. Twiitin analysointi voi antaa yleisen arvion twiitin sijainnista ja samalla antaa tietoa käyttäjän murteesta ja muista kielimerkeistä. Tällaisia kielellisiä attribuutteja voidaan käyttää tarjoamaan alueellinen lähentäminen tweetin alkuperää. Tässä työssä esitellään neuroregressiomalli, jolla voidaan tunnistaa twiitin kielelliset monimutkaisuudet käyttäjän sijainnin ennustamiseksi. Lopullinen malli tunnistaa tweetiin upotetun murteen ja ennustaa tweetin sijainnin.', 'sk': 'Identifikacija lokacije uporabnika je lahko koristna za sisteme priporočil, demografske analize in spremljanje izbruhov nesreč. Čeprav Twitter uporabnikom omogoča prostovoljno razkritje svoje lokacije, takšne informacije niso splošno dostopne. Analiza tweeta lahko zagotovi splošno oceno lokacije tweeta, hkrati pa daje vpogled v narečje uporabnika in druge jezikovne označevalce. Takšni jezikovni atributi se lahko uporabljajo za zagotavljanje regionalnega približevanja izvora tweetov. V prispevku predstavljamo model nevronske regresije, ki lahko prepozna jezikovne zapletenosti tweeta in napove lokacijo uporabnika. Končni model identificira narečje, vgrajeno v tweet, in napoveduje lokacijo tweet.', 'he': 'זיהוי מיקומו של משתמש יכול להיות שימושי למערכות המלצות, ניתוח דמוגרפי, ומעקב אחר התפרצות אסון. למרות שטוויטר מאפשר למשתמשים לחשוף את המיקום שלהם ברצונות, מידע כזה לא זמין באופן כללי. ניתוח טוויט יכול לספק הערכה כללית של מיקום טוויט בזמן שנותן תובנה לדיאלקט של המשתמש וסימנים לשוניים אחרים. תכונות שפתיים כאלה יכולות להשתמש כדי לספק התקרבות אזורית של מקורי טוויט. בעיתון הזה, אנחנו מציגים מודל גירוס עצבי שיכול לזהות את הסובכים השפתיים של טוויט כדי לחזות את מיקומו של המשתמש. הדוגמנית האחרונה מזהה את הדיאלקט שנמצא בטוויט וחזוי את מיקומו של הטוויט.', 'ha': "Idan ana gane wurin mai amfani da shi, za'a iya amfani da wa'urar shawarar da aka shawara, Ana Ana Anarari da kuma tsarin masu fitarwa na bayani. Kuma kõ da Twitter ya yarda da mãsu amfani da shi, su nuna wurin da ke kanana, ba za'a iya amfani da shi ba. Ana yi anayyar wani Twitter, zai iya bãyar da kima mai ƙidãya wa wuri na Twitter a lokacin da za'a kiyaye gane wa mai amfani da shi da wasu matsayin linguistic. @ info: whatsthis Ga wannan takardan, Munã nuna wata misãlin regression na neura wanda ke iya iya gane wa'anar cikin linguistic na'ura na Twitter dõmin ya yi bayani ga wurin mai amfani da shi. The final model identifies the dialect embedded in the tweet and predicts the location of the tweet.", 'jv': 'I politenessoffpolite"), and when there is a change ("assertivepoliteness Genjer-Genjer Attribute yang dipunangé Nang mapun iki, kita dadi model réaksiyon nêrung kuwi bisa nguasai nggawe barang kelangan anyar kang tuwit kanggo urèhadi nggawe lokasi ning pengguna. Defs', 'bo': 'སྤྱོད་མཁན་གྱི་གནས ཌིས་ཌིར་སྤྱོད་མཁན་གྱིས་རང་ཉིད་ཀྱི་གནས་ཡུལ་མངོན་འཆར་བྱེད་དགོས་ནའང་། དེ་འདྲ་བ་སྤྱིར་བཏང་བ Tweet་ཞིབ་དཔྱད་ཞིབ་ནི་སྤྱོད་མཁན་དང་སྐད་རིགས་བཀོད་པ སྐད་རིགས་འདི་དག་གི་ཁྱད་ཆོས་ཉེར་སྤྱོད་ཐུབ་ཀྱི་འགྱུར་ཁུངས་གཟུགས་འགྲོ་བ་དང་མཉམ་དུ་སྤྱོད་ཐུབ། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རང་ཉིད་ཀྱི་རྒྱུད་ལམ་ལུགས་ཀྱི་དཔེ་གཞི་གཅིག་སྟོན་ཐུབ་ཀྱི་སྐད་རིགས མཐའ་མཇུག་གི་མ་དབྱིབས་དྲ་ཐོག'}
