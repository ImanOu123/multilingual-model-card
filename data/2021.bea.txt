{'en': 'Text Simplification by Tagging T ext  S implification by  T agging', 'es': 'Simplificación del texto mediante el etiquetado', 'fr': 'Simplification du texte par balisage', 'ar': 'تبسيط النص عن طريق وضع العلامات', 'pt': 'Simplificação de texto por marcação', 'ja': 'タグ付けによるテキストの簡略化', 'hi': 'टैगिंग द्वारा पाठ सरलीकरण', 'ru': 'Упрощение текста с помощью тегирования', 'zh': '标简文本', 'ga': 'Téacs a Shimpliú trí Chlibeáil', 'el': 'Απλοποίηση κειμένου με ετικέτα', 'ka': 'ტექსტის განვითარება', 'it': 'Semplificazione del testo mediante etichettatura', 'kk': 'Тегтерді қарапайым мәтін', 'hu': 'Szöveg egyszerűsítése címkézéssel', 'ms': 'Simplifikasi Teks Oleh Tagging', 'lt': 'Teksto supaprastinimas žymėjimu', 'ml': 'ടാഗ്ഗിങ്ങ് കൊണ്ട് പദാവലി ലളിതമാക്കുക', 'mk': 'Text Simplification by Tagging', 'no': 'Enkel tekst ved merking', 'mt': 'Simplifikazzjoni tat-test bit-Tagging', 'pl': 'Uproszczenie tekstu poprzez tagowanie', 'si': 'ටැග් කරලා පාළුව සරලීකරණය', 'mn': 'Текст хялбарчлал', 'sv': 'Textförenkling genom märkning', 'sr': 'Jednostavnost teksta označavanjem', 'ro': 'Simplificarea textului prin etichetare', 'ta': 'அடையாளங்களால் உரை சுலபமாக்கம்', 'so': 'Soo fududeynta qoraalka', 'ur': 'Name', 'uz': '@ info: whatsthis', 'vi': 'Đơn giản bằng cách đánh dấu', 'bg': 'Опростяване на текста чрез маркиране', 'hr': 'Jednostavanje teksta označavanjem', 'da': 'Tekstforenkling ved mærkning', 'nl': 'Tekstvereenvoudiging door labeling', 'ko': '태그를 통한 텍스트 단순화', 'de': 'Textvereinfachung durch Tagging', 'id': 'Simplifikasi Teks Dengan Tagging', 'fa': 'Comment', 'af': 'Teks Vereenvoudiging deur etiket', 'tr': 'Tägleme görä metin Besitlendirmek', 'sq': 'Simplifikimi i tekstit nga etiketa', 'sw': 'Simplified text by Tagging', 'hy': 'Comment', 'am': 'አቀማመጥ', 'az': 'M톛tn Qeyd Et', 'bn': 'ট্যাগিং দ্বারা টেক্সট সাধারণ', 'bs': 'Jednostavnost teksta označavanjem', 'cs': 'Zjednodušení textu označováním', 'ca': 'Simplificació del text per etiquetar', 'et': 'Teksti lihtsustamine sildistamise abil', 'fi': 'Tekstin yksinkertaistaminen merkitsemällä', 'jv': 'tab-style', 'ha': '@ action', 'he': 'Name', 'sk': 'Poenostavitev besedila z označevanjem', 'bo': 'ཤོག་བྱང་ལ་བསྟུན་ནས་ཡི་གེ་སྔོན་སྒྲིག་ཕྱོགས'}
{'en': 'Edit-based approaches have recently shown promising results on multiple monolingual sequence transduction tasks. In contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proven to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. Inspired by these ideas, we present TST, a simple and efficient Text Simplification system based on sequence Tagging, leveraging pre-trained Transformer-based encoders. Our system makes simplistic data augmentations and tweaks in training and  inference  on a pre-existing system, which makes it less reliant on large amounts of parallel training data, provides more control over the outputs and enables faster  inference speeds . Our best  model  achieves near state-of-the-art performance on benchmark test datasets for the  task . Since  it  is fully non-autoregressive,  it  achieves faster inference speeds by over 11 times than the current state-of-the-art text simplification system.', 'es': 'Los enfoques basados en la edición han mostrado recientemente resultados prometedores en múltiples tareas de transducción de secuencias monolingües. A diferencia de los modelos convencionales de secuencia a secuencia (Seq2Seq), que aprenden a generar texto desde cero a medida que se entrenan en cuerpos paralelos, estos métodos han demostrado ser mucho más efectivos, ya que pueden aprender a realizar transformaciones rápidas y precisas al mismo tiempo que aprovechan la potente formación previa modelos lingüísticos. Inspirados en estas ideas, presentamos TST, un sistema de simplificación de textos simple y eficiente basado en el etiquetado de secuencias, que aprovecha codificadores preentrenados basados en Transformer. Nuestro sistema hace aumentos de datos simplistas y ajustes en el entrenamiento y la inferencia en un sistema preexistente, lo que hace que dependa menos de grandes cantidades de datos de entrenamiento paralelos, proporciona más control sobre los resultados y permite velocidades de inferencia más rápidas. Nuestro mejor modelo logra un rendimiento casi vanguardista en los conjuntos de datos de pruebas de referencia para la tarea. Como es totalmente no autorregresivo, logra velocidades de inferencia más de 11 veces más rápidas que el sistema actual de simplificación de textos de última generación.', 'ar': 'أظهرت الأساليب القائمة على التحرير مؤخرًا نتائج واعدة في مهام تحويل التسلسل أحادية اللغة المتعددة. على عكس نماذج التسلسل إلى التسلسل التقليدية (Seq2Seq) ، التي تتعلم إنشاء نص من نقطة الصفر أثناء تدريبها على مجموعات موازية ، فقد أثبتت هذه الأساليب أنها أكثر فاعلية نظرًا لأنها قادرة على تعلم إجراء تحويلات سريعة ودقيقة مع الاستفادة من نماذج اللغة القوية المدربة مسبقًا. مستوحاة من هذه الأفكار ، نقدم TST ، وهو نظام بسيط وفعال لتبسيط النص يعتمد على وضع العلامات المتسلسلة ، والاستفادة من أجهزة التشفير المعتمدة مسبقًا على المحولات. يقوم نظامنا بإجراء عمليات زيادة وتعديل مبسطة للبيانات في التدريب والاستدلال على نظام موجود مسبقًا ، مما يجعله أقل اعتمادًا على كميات كبيرة من بيانات التدريب الموازي ، ويوفر مزيدًا من التحكم في المخرجات ويسمح بسرعات استدلال أسرع. يحقق أفضل نموذج لدينا أداءً قريبًا من أحدث ما توصل إليه العلم في مجموعات بيانات الاختبار المعياري للمهمة. نظرًا لأنه غير متراجع تمامًا ، فإنه يحقق سرعات استدلال أسرع بأكثر من 11 مرة من نظام تبسيط النص الحديث.', 'fr': "Les approches basées sur l'édition ont récemment donné des résultats prometteurs pour de multiples tâches de transduction de séquences monolingues. Contrairement aux modèles classiques de séquence à séquence (Seq2Seq), qui apprennent à générer du texte à partir de zéro lorsqu'ils sont entraînés sur des corpus parallèles, ces méthodes se sont révélées beaucoup plus efficaces car elles sont capables d'apprendre à effectuer des transformations rapides et précises tout en tirant parti de puissants préentraînés modèles linguistiques. Inspirés par ces idées, nous présentons TST, un système de simplification de texte simple et efficace basé sur le marquage de séquences, utilisant des encodeurs pré-entraînés basés sur Transformer. Notre système effectue des augmentations de données et des ajustements simplifiés lors de l'entraînement et de l'inférence sur un système préexistant, ce qui le rend moins dépendant de grandes quantités de données d'entraînement parallèles, fournit un meilleur contrôle sur les sorties et permet des vitesses d'inférence plus rapides. Notre meilleur modèle atteint des performances proches de la pointe de la technologie sur les ensembles de données de test de référence pour la tâche. Comme il n'est pas autorégressif, il atteint des vitesses d'inférence plus de 11 fois supérieures à celles du système de simplification de texte de pointe actuel.", 'pt': 'As abordagens baseadas em edição mostraram recentemente resultados promissores em várias tarefas de transdução de sequência monolíngue. Ao contrário dos modelos sequenciais convencionais (Seq2Seq), que aprendem a gerar texto do zero à medida que são treinados em corpora paralelos, esses métodos se mostraram muito mais eficazes, pois são capazes de aprender a fazer transformações rápidas e precisas enquanto aproveita poderosos modelos de linguagem pré-treinados. Inspirados por essas ideias, apresentamos o TST, um sistema de simplificação de texto simples e eficiente baseado em marcação de sequências, aproveitando codificadores baseados em transformadores pré-treinados. Nosso sistema faz aumentos de dados simplistas e ajustes no treinamento e inferência em um sistema pré-existente, o que o torna menos dependente de grandes quantidades de dados de treinamento paralelo, fornece mais controle sobre as saídas e permite velocidades de inferência mais rápidas. Nosso melhor modelo alcança desempenho próximo do estado da arte em conjuntos de dados de teste de benchmark para a tarefa. Por ser totalmente não autorregressivo, atinge velocidades de inferência mais rápidas em mais de 11 vezes do que o atual sistema de simplificação de texto de última geração.', 'ja': '編集ベースのアプローチは、最近、複数の単一言語配列形質導入タスクで有望な結果を示している。 従来のシーケンスツーシーケンス（ Seq 2 Seq ）モデルは、平行コーパスで訓練されているように、テキストを一から生成することを学習するのとは対照的に、これらの方法は、強力な事前訓練された言語モデルを活用しながら、高速で正確な変換を行うことを学習することができるため、はるかに効果的であることが証明されています。 これらのアイデアに触発されて、事前に訓練されたトランスフォーマーベースのエンコーダを活用したシーケンスタグ付けに基づくシンプルで効率的なテキスト簡素化システムTSTを発表しました。 当社のシステムは、既存のシステムのトレーニングと推論を簡略化したデータ拡張と微調整を行い、大量の並列トレーニングデータへの依存を減らし、出力をより多く制御し、より高速な推論速度を可能にします。 当社の最良のモデルは、タスクのベンチマークテストデータセットでほぼ最先端のパフォーマンスを達成します。 完全に非自動回帰であるため、現在の最先端のテキスト簡略化システムよりも11倍以上高速な推論速度を実現します。', 'hi': 'संपादित करें-आधारित दृष्टिकोण ने हाल ही में कई मोनोलिंगुअल अनुक्रम ट्रांसडक्शन कार्यों पर आशाजनक परिणाम दिखाए हैं। पारंपरिक अनुक्रम-से-अनुक्रम (Seq2Seq) मॉडल के विपरीत, जो स्क्रैच से पाठ उत्पन्न करना सीखते हैं क्योंकि वे समानांतर कॉर्पोरेट पर प्रशिक्षित होते हैं, ये विधियां बहुत अधिक प्रभावी साबित हुई हैं क्योंकि वे शक्तिशाली पूर्व-प्रशिक्षित भाषा मॉडल का लाभ उठाते हुए तेजी से और सटीक परिवर्तन करने में सक्षम हैं। इन विचारों से प्रेरित होकर, हम टीएसटी, अनुक्रम टैगिंग के आधार पर एक सरल और कुशल पाठ सरलीकरण प्रणाली प्रस्तुत करते हैं, पूर्व-प्रशिक्षित ट्रांसफॉर्मर-आधारित एन्कोडर का लाभ उठाते हैं। हमारी प्रणाली एक पूर्व-मौजूदा प्रणाली पर प्रशिक्षण और अनुमान में सरलीकृत डेटा वृद्धि और tweaks बनाती है, जो इसे बड़ी मात्रा में समानांतर प्रशिक्षण डेटा पर कम निर्भर बनाती है, आउटपुट पर अधिक नियंत्रण प्रदान करती है और तेजी से अनुमान गति को सक्षम बनाती है। हमारा सबसे अच्छा मॉडल कार्य के लिए बेंचमार्क परीक्षण डेटासेट पर अत्याधुनिक प्रदर्शन के पास प्राप्त करता है। चूंकि यह पूरी तरह से गैर-ऑटोरिग्रेसिव है, इसलिए यह वर्तमान अत्याधुनिक पाठ सरलीकरण प्रणाली की तुलना में 11 गुना से अधिक तेज अनुमान गति प्राप्त करता है।', 'zh': '盖编辑之法近列于数单语转导见有望焉。 比于旧(Seq2Seq),比于并行语料库上学从头始成文本,其效尤效,以其能习疾速转移,兼以强预训言模也。 感斯启发,推出TST,盖序高效之简统,因豫练之基于Transformer编码器。 吾系统对预存之数,增练推理,以省并行之数,供输者更多控制,而致更快之理速。 吾曹最佳处测试数据集上近得最先进。 以其全非自归,故其推理速倍于前11。', 'ru': 'Подходы, основанные на редактировании, недавно показали многообещающие результаты для множества задач трансдукции одноязычных последовательностей. В отличие от обычных моделей последовательности к последовательности (Seq2Seq), которые учатся генерировать текст с нуля, поскольку они обучены на параллельных телах, эти методы оказались гораздо более эффективными, поскольку они способны научиться делать быстрые и точные преобразования, используя мощные предварительно обученные языковые модели. Вдохновленные этими идеями, мы представляем TST, простую и эффективную систему упрощения текста, основанную на маркировке последовательностей, используя предварительно обученные кодировщики на основе трансформатора. Наша система делает упрощенные дополнения данных и корректировки в обучении и выводах на уже существующей системе, что делает ее менее зависимой от больших объемов параллельных обучающих данных, обеспечивает больший контроль над выводами и позволяет быстрее делать выводы. Наша лучшая модель достигает почти самых современных показателей на контрольных тестовых наборах данных для задачи. Поскольку он полностью не является авторегрессивным, он достигает более высокой скорости вывода более чем в 11 раз, чем современная система упрощения текста.', 'ga': 'Léirigh cur chuige atá bunaithe ar eagarthóireacht le déanaí torthaí gealltanais ar thascanna iolracha aistrithe seicheamh aonteangacha. I gcodarsnacht leis na gnáthmhúnlaí seicheamh-go-seicheamh (Seq2Seq), a fhoghlaimíonn conas téacs a ghiniúint ón tús de réir mar a chuirtear oiliúint orthu ar chorpora comhthreomhara, tá na modhanna seo i bhfad níos éifeachtaí toisc go bhfuil siad in ann claochlú tapa agus cruinn a dhéanamh. agus múnlaí cumhachtacha teanga réamhoilte á n-úsáid. Arna spreagadh ag na smaointe seo, cuirimid i láthair TST, córas Simplithe Téacs atá simplí agus éifeachtach bunaithe ar chlibeáil seicheamh, ag giaráil ionchódóirí Trasfhoirmeoir-bhunaithe réamhoilte. Déanann ár gcóras breisithe sonraí simplíocha agus mionathruithe in oiliúint agus tátal ar chóras a bhí ann cheana, rud a fhágann go mbraitheann sé níos lú ar mhéideanna móra sonraí oiliúna comhthreomhara, a sholáthraíonn níos mó smachta ar na haschuir agus a chumasaíonn luasanna tátail níos tapúla. Baineann ár múnla is fearr amach beagnach feidhmíocht úrscothach ar thacair sonraí tástála tagarmharcála don tasc. Ós rud é go bhfuil sé go hiomlán neamh-uathchéimneach, sroicheann sé luasanna tátail níos tapúla níos mó ná 11 uair ná an córas simplithe téacs úrscothach atá ann faoi láthair.', 'el': 'Οι προσεγγίσεις με βάση την επεξεργασία έχουν πρόσφατα δείξει πολλά υποσχόμενα αποτελέσματα σε πολλαπλές εργασίες μετάφρασης μονογλωσσικών ακολουθιών. Σε αντίθεση με τα συμβατικά μοντέλα αλληλουχίας σε αλληλουχίας (τα οποία μαθαίνουν να παράγουν κείμενο από το μηδέν καθώς εκπαιδεύονται σε παράλληλα σώματα, αυτές οι μέθοδοι έχουν αποδειχθεί πολύ πιο αποτελεσματικές δεδομένου ότι είναι σε θέση να μάθουν να κάνουν γρήγορους και ακριβείς μετασχηματισμούς χρησιμοποιώντας ισχυρά προ-εκπαιδευμένα γλωσσικά μοντέλα. Εμπνευσμένοι από αυτές τις ιδέες, παρουσιάζουμε το ένα απλό και αποτελεσματικό σύστημα απλοποίησης κειμένου βασισμένο στη σήμανση ακολουθίας, αξιοποιώντας προ-εκπαιδευμένους κωδικοποιητές βασισμένους στον μετασχηματιστή. Το σύστημά μας κάνει απλουστευμένες αυξήσεις και βελτιώσεις δεδομένων στην εκπαίδευση και την εξαγωγή συμπερασμάτων σε ένα προϋπάρχον σύστημα, γεγονός που το καθιστά λιγότερο εξαρτημένο σε μεγάλες ποσότητες δεδομένων παράλληλης κατάρτισης, παρέχει μεγαλύτερο έλεγχο των εξόδων και επιτρέπει ταχύτερες ταχύτητες συμπερασμάτων. Το καλύτερο μοντέλο μας επιτυγχάνει σχεδόν υπερσύγχρονη απόδοση σε σύνολα δοκιμών αναφοράς για την εργασία. Δεδομένου ότι είναι πλήρως μη αυτοανακριτική, επιτυγχάνει ταχύτερες ταχύτητες συμπερασμάτων πάνω από 11 φορές από ό, τι το σημερινό σύστημα απλοποίησης κειμένου τελευταίας τεχνολογίας.', 'hu': 'A szerkesztésen alapuló megközelítések a közelmúltban ígéretes eredményeket mutattak több egynyelvű szekvencia átalakítási feladat tekintetében. A hagyományos szekvencia-szekvencia (Seq2Seq) modellekkel ellentétben, amelyek a semmiből tanulnak szöveget generálni a párhuzamos korpuszokon, ezek a módszerek sokkal hatékonyabbak, mivel képesek megtanulni gyors és pontos átalakításokat végrehajtani, miközben erőteljes előképzett nyelvi modelleket használnak. Ezekből az ötletekből inspirálva bemutatjuk a TST-t, egy egyszerű és hatékony szövegegyszerűsítő rendszert, amely sorozatcímkézésen alapul, előre képzett Transformer-alapú kódolókat használ. Rendszerünk egyszerű adatbővítéseket és módosításokat végez az edzés és következtetés során egy már meglévő rendszeren, ami kevésbé függ a nagy mennyiségű párhuzamos edzési adatoktól, nagyobb irányítást biztosít a kimenetek felett és gyorsabb következtetési sebességet tesz lehetővé. Legjobb modellünk közel a legkorszerűbb teljesítményt ér el az adott feladathoz szükséges benchmark tesztadatok tekintetében. Mivel teljesen nem autoregresszív, több mint 11-szer gyorsabb következtetési sebességet ér el, mint a jelenlegi korszerű szövegegyszerűsítő rendszer.', 'it': "Gli approcci basati su modifiche hanno recentemente mostrato risultati promettenti su molteplici attività di trasduzione di sequenze monolingue. A differenza dei modelli convenzionali sequenza-sequenza (Seq2Seq), che imparano a generare testo da zero mentre sono addestrati su corpi paralleli, questi metodi si sono dimostrati molto più efficaci poiché sono in grado di imparare a fare trasformazioni veloci e accurate sfruttando potenti modelli linguistici pre-addestrati. Ispirati da queste idee, presentiamo TST, un sistema di semplificazione del testo semplice ed efficiente basato sulla sequenza Tagging, che sfrutta encoder pre-addestrati basati su Transformer. Il nostro sistema effettua aumenti e modifiche semplificate dei dati nell'allenamento e nell'inferenza su un sistema preesistente, il che lo rende meno dipendente da grandi quantità di dati di allenamento paralleli, fornisce un maggiore controllo sulle uscite e consente velocità di inferenza più elevate. Il nostro modello migliore raggiunge prestazioni quasi all'avanguardia sui set di dati di test benchmark per l'attività. Poiché è completamente non autoregressivo, raggiunge velocità di inferenza più elevate di oltre 11 volte rispetto all'attuale sistema di semplificazione del testo all'avanguardia.", 'ka': 'რედაქტირებული მიღებები ახლა მხოლოდ ჩვენებულია მნიშვნელოვანი მონოლენგური შემდეგების შემდეგებაზე. კონტრანციონალური შედეგების (Seq2Seq) მოდელების კონტრანციონალური შედეგების კონტრანციონალური შედეგებით, რომლებიც შესწავლობენ ტექსტის შექმნა, როგორც ისინი პარალელური კოპორაზე განაცემებულია, ეს მეცემები უფრო ეფექტიურია ამ იდეების გამოყენებული, ჩვენ TST-ს გამოყენებთ, ერთადერთი და ეფექტიური ტექსტის გამოყენება სისტემის სისტემის განვითარება, სისტემის შესაბამისი ტექსემის შესაბამისი ტექსემის დაბა ჩვენი სისტემა უფრო მხოლოდ მონაცემების აგგენტაცია და გაგრძელება სტრინციაში და ინფრენციაში, რომელიც უფრო მხოლოდ იყოს პარალელური განაცემების დიდი რაოდენობაში, უფრო მეტი კონტროლეცია გადა ჩვენი საუკეთესო მოდელი იქნება მონაცემების მონაცემების მონაცემების მონაცემების შემდეგ. იმიტომ, რომ ეს ყველაფერად არ არის ავტორეგრესიური, ის უფრო სიჩქარე ინფრენციის სიჩქარე 11-ჯერ უფრო მეტი გამრავლება, ვიდრე მიმდინარე ტექსტის სისტემის განმავლება.', 'mk': 'Пристапите базирани на уредување неодамна покажаа ветувачки резултати на неколку монојазични трансдукциони задачи. За разлика од конвенционалните модели од секвенца до секвенца (Seq2Seq), кои учат да генерираат текст од нула додека се тренирани на паралелна корпора, овие методи се покажаа дека се многу поефикасни бидејќи се во можност да научат да направат брзи и прецизни трансформации, истовремено користејќи силни предобучени јазички модели. Инспирирано од овие идеи, го претставуваме ТСТ, едноставен и ефикасен систем за поедноставување на текстот базиран на одбележување на секвенца, користење предобучени трансформски кодери. Нашиот систем прави едноставни зголемувања на податоците и промени во обуката и конференцијата на препостоечкиот систем, што го прави помалку зависен од големи количини паралелни податоци за обука, обезбедува поголема контрола над излезите и овозможува побрза брзина на конференција. Our best model achieves near state-of-the-art performance on benchmark test datasets for the task.  Бидејќи е целосно неавторегресивна, таа постигнува побрзи брзини на конференција за повеќе од 11 пати од сегашниот најсовремен систем за едноставување на текстот.', 'kk': 'Өңдеу негіздеген арқылы бірнеше монолингілік ретінде аудару тапсырмаларды жаңа көрсетті. Кәдімгі реттеу мен реттеу (Seq2Seq) үлгілеріне қарамастан, олар параллель корпорада оқылған кезде мәтінді жасау үшін оқылған, бұл әдістер жылдам және дұрыс түрлендіруді үйрене алады, себебі бұл әдістер күшті алдын- оқылған тіл үлгілерін көмект Бұл идеялар бойынша қарапайым және эффективті мәтін бағдарламалау жүйесі реттеу тегтеріне негізделген, алдын- оқылған транформациялау негізделген кодерлерді көмектеседі. Біздің жүйеміз алдындағы жүйеңізге қарапайым деректерді көбейту және қарапайым көбейту жүйесінде қарапайым көбейту және қарапайым көбейту жасайды. Бұл параллель оқыту деректерінің үлкен мөлшерлеріне қатынасы Біздің ең жақсы моделіміз тапсырманың тесті деректер жиындарының күйінде жұмыс істеу жақында жеткізеді. Бұл толық авторегрессиялық емес себебі, оның қазіргі орындағы мәтінді қарапайымдастыру жүйесінен 11 рет артық тез жылдамдығын жеткізеді.', 'lt': 'Edit-based approaches have recently shown promising results on multiple monolingual sequence transduction tasks.  Priešingai nei įprasti sekos-sekos (Seq2Seq) modeliai, kurie mokosi iš nulio gaminti tekstą, nes jie mokomi lygiagrečioje korporoje, šie metodai pasirodė daug veiksmingesni, nes jie gali mokytis greitai ir tiksliai pakeisti, kartu naudojant galingus iš anksto parengtus kalbos modelius. Įkvėpta šiomis idėjomis, mes pristatome TST, paprastą ir veiksmingą teksto supaprastinimo sistemą, grindžiamą sekos ženklinimu ir iš anksto parengtų transformuotojų koduotojų naudojimu. Mūsų sistema paprastai didina duomenis ir koreguoja mokymą ir daro išvadas dėl jau esamos sistemos, todėl ji mažiau priklauso nuo didelių lygiagretaus mokymo duomenų, užtikrina didesnę rezultatų kontrolę ir leidžia greitesnį rezultatų greitį. Mūsų geriausias modelis pasiekia beveik naujausius rezultatus užduoties lyginamųjų bandymų duomenų rinkiniuose. Kadangi ji visiškai neautoregresinė, ji siekia greitesnių išvadų greičių daugiau kaip 11 kartų nei dabartinė naujausia teksto supaprastinimo sistema.', 'ms': 'pendekatan berasaskan-Sunting baru-baru ini telah menunjukkan keputusan yang berjanji pada tugas penjelmaan urutan monobahasa berbilang. Berbeza-beza dengan model urutan-ke-urutan konvensional (Seq2Seq), yang belajar menghasilkan teks dari awal kerana mereka dilatih pada korpra selari, kaedah ini telah terbukti jauh lebih berkesan kerana mereka mampu belajar untuk membuat perubahan yang pantas dan tepat semasa menggunakan model bahasa yang berpelatih berkuasa. Diterinspirasi oleh idea-idea ini, kami memperkenalkan TST, sistem Simplifikasi Teks sederhana dan efisien berdasarkan Tagging urutan, penggunaan pengekod berdasarkan Transformer. Sistem kita membuat peningkatan data sederhana dan penyesuaian dalam latihan dan kesimpulan pada sistem prawujud, yang membuat ia lebih sedikit bergantung pada jumlah besar data latihan selari, menyediakan lebih kawalan atas output dan membolehkan kelajuan kesimpulan yang lebih cepat. Model terbaik kami mencapai hampir prestasi-state-of-the-art pada set data ujian benchmark untuk tugas. Oleh kerana ia tidak secara automatik, ia mencapai kelajuan kesimpulan yang lebih cepat dengan lebih 11 kali daripada sistem kemudahan teks state-of-the-art semasa.', 'ml': 'ചിട്ടപ്പെടുത്താനുള്ള അടിസ്ഥാനത്തിലുള്ള മാറ്റങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു പല മോണോളില്\u200dഗ്ലാന സെക്ക്2സെക്ക് മോഡലുകള്\u200dക്ക് വേര്\u200dതിരിച്ച് പഠിക്കാന്\u200d പഠിക്കുന്നു. പാരാളല്\u200d കോര്\u200dപ്പോരിയില്\u200d പഠിപ്പിക്കപ്പെട്ടിരിക്കുന്നതിനാല്\u200d ഈ രീതികള്\u200d വളരെ പ്രധാനപ്പെടുത്തിയിരിക്ക ഈ ആശയങ്ങള്\u200d കൊണ്ട് ഞങ്ങള്\u200d ടിഎസ്റ്റിനെ കാണിക്കുന്നു. സെക്കന്\u200dസ് ടാഗിങ്ങിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d എളുപ്പമുള്ള ടെക്സ്റ്റ് എളുപ്പമുള് നമ്മുടെ സിസ്റ്റത്തില്\u200d നിലവിലുള്ള ഒരു സിസ്റ്റമില്\u200d പരിശീലനത്തിന്റെയും അപകടത്തിന്റെയും പരിശീലനത്തിന്റെയും പ്രധാനപ്പെടുത്തുന്ന വിവരങ്ങള്\u200d എളുപ്പമായ വിവ ഞങ്ങളുടെ ഏറ്റവും നല്ല മോഡല്\u200d ജോലിക്കുള്ള ബെന്\u200dച്മാര്\u200dക്ക് ടെസ്റ്റ് ഡേറ്റാസ്റ്റ് ഡാറ്റാസറ്റുകളില്\u200d നി ഇത് സ്വയമ്പര്യമില്ലാത്തതിനാല്\u200d, ഇപ്പോഴത്തെ രാജ്യത്തെക്കാള്\u200d നിലവിലുള്ള പദാവലി ലളിതമാക്കുന്നതിനെക്കാള്\u200d 11 തവണ വേഗത്തില്\u200d അത', 'no': 'Redigeringsbaserte tilnærmingar har nyleg viste promiserende resultat på fleire monospråk-sekvensoverføringar. I contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proved to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. Inspirert av desse ideane, presenterer vi TST ein enkel og effektiv tekst- forenklingssystem basert på sekvensmerking, leverar før- trengte transformeringskodar. Sistemet vårt gjer enklare data økning og utviklingar i opplæring og infeksjon på eit føreeksisterande system, som gjer det mindre reliant på store mengdar parallelle opplæringsdata, gjer meir kontroll over utdata og gjer raskare infeksjonssfart. Det beste modellen vårt er nær kunsthandlinga på benchmarktestdatasett for oppgåva. Sidan det er fullstendig ikkje-autoregressivt, oppnår det raskare infeksjonssfart med over 11 ganger enn det gjeldande tekstforenklingssystemet for kunsten.', 'mn': 'Засварлах арга баримтууд саяхан олон хэлний дарааллын дамжуулалтын үр дүнг харуулсан. Энгийн дарааллаас дарааллаар (Seq2Seq) загваруудын эсрэг, тэдгээр загварууд параллел корпора дээр суралцаж суралцаж байгаа үед мөнгө бүтээхийг суралцаж байгаа загварууд нь хурдан, шууд өөрчлөлт хийх боломжтой болсон учраас эдгээр арга нь илүү үр дүнтэй байдаг. Эдгээр санаануудын тулд бид TST-г илүү энгийн, үр дүнтэй Текст хялбарчлалын системийг тагтаж, урд сургалтын Трансфер суурилсан кодеруудыг ашиглаж байна. Бидний систем өмнө сургуульд суралцах болон халдварын тулд энгийн өгөгдлийн нэмэгдүүлэлт болон хөгжүүлэлт хийдэг. Энэ нь их хэмжээний параллел суралцах өгөгдлийг багасгаж, үр дүн дээр илүү хяналт гаргаж, илүү хурдан халдварын хурдыг боломжто Бидний хамгийн шилдэг загвар нь ажлын банкмарк тест өгөгдлийн сангийн ойролцоогоор гарч ирнэ. Энэ нь автоматжуулалт биш болохоор орчин үеийн хурдан хялбарлах системээс 11 дахин хурдан илүү хурдан халдвар авдаг.', 'mt': 'L-approċċi bbażati fuq l-edizzjoni reċentement urew riżultati promettenti dwar kompiti multipli ta’ trasduzzjoni tas-sekwenza monolingwi. B’kuntrast mal-mudelli konvenzjonali ta’ sekwenza għal sekwenza (Seq2Seq), li jitgħallmu jiġġeneraw test mill-bidu billi huma mħarrġa fuq korpra parallela, dawn il-metodi wrew li huma ħafna aktar effettivi billi huma kapaċi jitgħallmu jagħmlu trasformazzjonijiet rapidi u pre ċiżi filwaqt li jinfurzaw mudelli ta’ lingwa mħarrġa minn qabel b’saħħithom. Inspirati minn dawn l-ideat, nippreżentaw it-TST, sistema sempliċi u effiċjenti ta’ Simplifikazzjoni tat-Test ibbażata fuq it-Tagging tas-sekwenzi, l-ingranaġġ ta’ kodifikaturi bbażati fuq it-Trasformer imħarrġa minn qabel. Is-sistema tagħna tagħmel żidiet sempliċi fid-dejta u twettiq fit-taħriġ u l-inferenza fuq sistema preeżistenti, li tagħmilha inqas dipendenti fuq ammonti kbar ta’ dejta parallel a ta’ taħriġ, tipprovdi aktar kontroll fuq ir-riżultati u tippermetti veloċitajiet aktar mgħa ġġla ta’ inferenza. L-aħjar mudell tagħna jikseb prestazzjoni kważi l-aktar avvanzata fuq settijiet ta’ dejta tat-testijiet ta’ referenza għall-kompitu. Peress li mhijiex awtoregressiva għal kollox, tikseb veloċitajiet ta’ inferenza aktar mgħaġġla b’aktar minn 11-il darba mis-sistema attwali ta’ semplifikazzjoni tat-test l-aktar avvanzata.', 'ro': 'Abordările bazate pe editare au arătat recent rezultate promițătoare în mai multe sarcini de traducere a secvențelor monolingve. Spre deosebire de modelele convenționale secvență-la-secvență (Seq2Seq), care învață să genereze text de la zero pe măsură ce sunt instruite pe corpuri paralele, aceste metode s-au dovedit a fi mult mai eficiente deoarece sunt capabile să învețe să facă transformări rapide și precise în timp ce utilizează modele de limbaj puternice pre-instruite. Inspirați de aceste idei, vă prezentăm TST, un sistem simplu și eficient de simplificare a textului bazat pe etichetarea secvențelor, utilizând codificatoare pre-instruite bazate pe Transformer. Sistemul nostru face măriri simpliste a datelor și ajustări în antrenament și inferență pe un sistem preexistent, ceea ce îl face mai puțin dependent de cantități mari de date de antrenament paralel, oferă mai mult control asupra rezultatelor și permite viteze mai mari de inferență. Cel mai bun model al nostru obține performanțe aproape de state-of-the-art pe seturile de date de testare de referință pentru sarcină. Deoarece este complet non-autoregresiv, atinge viteze de inferență mai mari de peste 11 ori decât sistemul actual de simplificare a textului de ultimă generație.', 'pl': 'Podejścia oparte na edycji wykazały ostatnio obiecujące rezultaty w wielu jednojęzycznych zadaniach transdukcji sekwencji. W przeciwieństwie do konwencjonalnych modeli sekwencji-do-sekwencji (Seq2Seq), które uczą się generować tekst od podstaw, gdy są trenowane na równoległych korporach, metody te okazały się znacznie skuteczniejsze, ponieważ są w stanie nauczyć się szybkiego i dokładnego przekształcenia przy jednoczesnym wykorzystaniu potężnych wstępnie przeszkolonych modeli językowych. Zainspirowani tymi pomysłami prezentujemy TST, prosty i wydajny system uproszczenia tekstu oparty na tagowaniu sekwencji, wykorzystujący wstępnie przeszkolone kodery oparte na Transformerze. Nasz system wykonuje uproszczone powiększanie i poprawki danych w treningu i wnioskowaniu na istniejącym już systemie, co sprawia, że jest on mniej zależny od dużych ilości danych treningowych równoległych, zapewnia większą kontrolę nad wyjściami i umożliwia szybsze prędkości wnioskowania. Nasz najlepszy model osiąga niemal najnowocześniejszą wydajność w odniesieniu do zestawów testów referencyjnych do tego zadania. Ponieważ jest on w pełni nieautoregresywny, osiąga szybsze prędkości wnioskowania ponad 11-krotnie niż obecny najnowocześniejszy system uproszczania tekstu.', 'si': 'සංපාදනය සඳහා පරීක්ෂණය සඳහා ප්\u200dරතිචාර ප්\u200dරතිචාර පෙන්වන්න ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරි සාමාන්\u200dය ක්\u200dරමාණික පණිවිඩය (Seq2Seq) මොඩේල්ස් වලට ප්\u200dරතිචාර කරන්න පුළුවන් වෙනස් වෙනුවෙන්, ඒවා සාමාන්\u200dය කොර්පෝරා වලින් පණිවිඩයෙන් පුළුවන් වෙනුවෙන් පුළුවන මේ අදහස් වලින්, අපි TST වෙනුවෙන්, සාමාන්\u200dය හා ප්\u200dරශ්ණ පද්ධතියක් පද්ධතියක් පද්ධතියක් පද්ධතියක් පෙනුවෙන්, පද්ධතිය ටැ අපේ පද්ධතිය සාමාන්\u200dය දත්ත විශාලනය සහ tweaks කරනවා ප්\u200dරධානය සහ පද්ධතියෙන් ඉදිරිපත් පද්ධතියට, ඒකෙන් ඒක විශාල ප්\u200dරධානයක් ලොකු සාමාන්\u200dය ප්\u200dරධා අපේ හොඳම මොඩේල් එක්ක වැඩේ වෙනුවෙන් බෙන්ච්මාර්ක් පරීක්ෂා දත්ත සෙට්ටුවට පරීක්ෂා කරනවා. ඒක සම්පූර්ණයෙන්ම ස්වයංක්\u200dරියාවක් නැති වෙලාවෙන් ඉක්මන් වේගයක් ලැබෙන්නේ පුළුවන් වේගයක් වඩා 11 වතාවක් වඩා වඩා', 'sr': 'Redigerani pristupi nedavno su pokazali obećavajuće rezultate na višestrukim monojezičkim poslovima prevode. Pored konvencionalnih modela sekvencije do sekvence (Seq2Seq), koji nauče da generiraju tekst od ogrebotine dok su obučeni na paralelnoj korpori, te metode su dokazale da su mnogo efikasnije jer su u stanju naučiti da napraviju brze i tačne transformacije dok su uticali na moćne predobučene jezičke modele. Inspirirani ovim idejama, predstavljamo TST, jednostavan i efikasni sistem pojednostavljanja teksta na osnovu oznake sekvence, uključujući predobučene kodere na osnovu transformera. Naš sistem čini jednostavnim povećanjem podataka i preokretanjem treninga i infekcije na pre-postojeći sistem, što ga čini manje pouzdanim na velike količine paralelnih podataka o obuci, pruža više kontrole nad ishodom i omogućava brže infekcije. Naš najbolji model postiže blizu izvršnosti umetnosti na testovima standardnih podataka za zadatak. Pošto je potpuno ne-autoregresivna, postiže brže brzine infekcije više od 11 puta nego trenutni sistem pojednostavljanja teksta umetnosti.', 'ur': 'ویڈیٹ بنیاد کی تقریبیں اچھے سے بہت سی سی زبان کی ترجمہ کے کاموں پر وعدہ دینے والی نتیجے دکھائے گئے ہیں. اس کے مقابلہ میں جہاں سے پیغام جوڑنے کی تعلیم کی جاتی ہے، یہ طریقے بہت اثر ہیں کیونکہ وہ سریع اور دقیق تغییر کرنے کی طاقت رکھتے ہیں اور قوت پیش آموزش کی زبان نمڈلوں کو لذت دیتے ہیں۔ یہ ایڈیوں کے ذریعہ ہم TST کو ایک ساده اور فعال تفسیر سیسٹم کے ذریعہ پیش آموزش کی ترنسفور کی بنیاد پر بنیاد رکھتے ہیں۔ ہمارا سیستم ایک پہلے موجود سیستمے پر سفارشی ڈیٹا اضافہ کرتا ہے اور ٹویک کرتا ہے جو اسے بہت سی ٹرینگ ڈیٹے پر کم اعتماد کرتا ہے، اضافہ پر زیادہ کنترل دیتا ہے اور سریع نازل کی سرعتوں کو فعال کرتا ہے۔ ہمارا بہترین مدل بنچم مارک ٹیسٹ ڈیٹ سٹ کے نزدیک موجود ہوتا ہے۔ کیونکہ یہ کامل غیر اٹوگریسٹ ہے، اس سے 11 بار زیادہ سرعت کے ذریعہ سرعت پہنچ رہا ہے، اس کے ذریعہ یہ موجود موجود موجود موجود آرتی کے متن ساده سازی سیسٹم سے۔', 'so': 'Waxbarashada ku saabsan waxyaabaha lagu soo bandhigay waxay tuseen resultooyin ballan ah oo ku saabsan shaqooyin kala duduwan oo luuqadaha kala duduwan. Iska soojeeda noocyada xiliga ah (Seq2Seq), kaas oo barta in laga sameeyo qoraal laga sameeyo marka lagu baranayo shirkadda lambarka ah, qaababkan waxay u caddaynaysaa inay aad u faa’iido badan tahay, sababtoo ah waxay awoodi karaan in ay bartaan isbedelyo dhaqso iyo si saxda ah, marka ay u dhiibi karaan noocyada afka hore oo tababaray. Fikiradan waxaan soo saaraynaa TST, nidaam fudud oo faa’iido ah oo ku saleysan qoraalka tagging, oo soo diraya codsiga horay loo tababaray. Systemkanagu wuxuu si fudud u sameeyaa koritaanka macluumaadka oo fudud, wuxuuna ku shaqeeyaa waxbarashada iyo dhibaatada ku qoran nidaamka hore, taasoo ka dhigtaa inay ku kalsoonaato tiro badan oo waxbarashada isbarbardhiga ah, wuxuuna bixiyaa maamulka ka badan oo ka maamula bixinta, wuxuuna ka dhigi karaa dhaqsaha dhibaatada dhaqsaha ah. Tusaale ahaan ugu wanaagsan ayaa sameyn kara sameynta xaaladda farshaxanka ee ku qoran sawirada imtixaanka bangiga ee shaqada. Sida darteed waxay si buuxda ah u haysataa mid aan iskumarin, waxay u baahan tahay in aad u dhaqso dhibaato ka badan 11 jeer in ka sii fududaato nidaamka saxda farshaxanka.', 'sv': 'Edit-baserade metoder har nyligen visat lovande resultat på flera enspråkiga sekvenstransduktionsuppgifter. Till skillnad från konventionella sekvens-till-sekvensmodeller (Seq2Seq), som lär sig att generera text från grunden när de tränas på parallella korpora, har dessa metoder visat sig vara mycket effektivare eftersom de kan lära sig att göra snabba och exakta transformationer samtidigt som de utnyttjar kraftfulla förintränade språkmodeller. Inspirerad av dessa idéer presenterar vi TST, ett enkelt och effektivt system för textförenkling baserat på sekvensmärkning, som utnyttjar förintränade transformatorbaserade kodare. Vårt system gör enkla dataökningar och justeringar i träning och inferens på ett befintligt system, vilket gör det mindre beroende av stora mängder parallella träningsdata, ger mer kontroll över utgångarna och möjliggör snabbare inferenshastigheter. Vår bästa modell uppnår nästan toppmoderna prestanda på benchmarks testdataset för uppgiften. Eftersom det är helt icke-autoregressivt uppnår det snabbare inferenshastigheter med över 11 gånger än det nuvarande toppmoderna textförenklingssystemet.', 'ta': 'தொகுப்பு அடிப்படையிலான தொகுப்பான முடிவுகள் பல ஒற்றைமொழி மாற்றும் பணிகளின் மீது வாக்களிக்கப்பட்டுள்ளது. வழக்கமான தொடர்ச்சிக்கு மாதிரியான (Seq2Seq) மாதிரிகளுக்கு எதிராக, அது முன் பயிற்சிக்கப்பட்ட மொழிகளிலிருந்து உரையை உருவாக்க கற்றுக்கொள்ளும் போது, இணைப்பு நிறுவனத்தில் பயிற்சிக்கப இந்த கருத்துக்களால் நாம் TST, ஒரு சுலபமான மற்றும் வேலையான உரை எளிதாக்குதல் அமைப்பு, முன் பயிற்சி மாற்றி அடிப்படையான குறியீடுகளை வழ எங்கள் கணினியில் சுலபமான தரவு அதிகரிப்புகள் மற்றும் முன் இருக்கும் அமைப்பில் பயிற்சி மற்றும் குறைவான தேவைகளை செய்கிறது, அது பெரிய இணைப்பு பயிற்சி தரவை சார்ந் எங்கள் சிறந்த மாதிரி பணிக்கான benchmark சோதனை தரவுத்தளங்களில் நிலையில்-கலை செயல்பாடு நெருங்கி வெற்றுகிறது. இது முழுமையாக தானே கட்டுப்பாடு இல்லாமல் இருந்தால், தற்போதைய நிலையில் உள்ள கலை உரை எளிதாக்குதல் அமைப்பை விட 11 முறை அதிக வேகமான', 'uz': "@ info: whatsthis In contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proven to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models.  Bu g'oyalar bilan imzolangan, biz Transformer-based kodlash asosida yaratilgan oddiy va effektiv matn soddalashtirish tizimini bajaramiz. Bizning tizimimiz oddiy maʼlumot qo'shish va oldingi tizimga taʼminlovchi va taʼminlovchi soʻzni qo'shishga qo'llaydi. Bu tizimning juda katta taʼminlovchi soni ishlatadi, natijalarni boshqarish va tez tezlik tezligini qo'llaydi. Bizning eng yaxshi modelimiz vazifa uchun benchmark sinov maʼlumotlari tugmasining holati holatiga yaxshi bajaradi. Chunki u butunlay avto-regressiv emas, bu joriy matn soʻzligi tizimdan 11 marta yaqinligidan tezlashtirilgan tezligini oshadi.", 'vi': 'Các phương pháp sửa soạn gần đây đã cho thấy kết quả hứa hẹn về việc chuyển tiếp nhiều thứ ngôn ngữ. So với các mô hình lặp lại thông thường (Seq2Seq) học cách tạo văn bản từ đầu khi họ được đào tạo trên vật thể song song song, các phương pháp này đã cho thấy hiệu quả hơn nhiều vì họ có thể học tiến hành biến đổi nhanh và chính xác trong khi sử dụng các mô hình ngôn ngữ được huấn luyện đầy mạnh. Dựa trên những ý tưởng này, chúng tôi giới thiệu TST, một hệ thống đơn giản và hiệu quả Đơn giản văn bản dựa trên nhãn hiệu suất, dùng bộ mã hóa biến hình được rèn luyện trước. Hệ thống của chúng tôi làm tăng cường dữ liệu một cách đơn giản và chỉnh sửa trong huấn luyện và suy đoán dựa trên một hệ thống đã tồn tại, làm cho nó ít dựa vào lượng lớn dữ liệu nghiên cứu song song song song, cung cấp nhiều quyền kiểm soát các kết xuất và cho phép tăng tốc nhận biết nhanh hơn. Người mẫu tốt nhất đạt được thành quả gần như tối tân nhất trên các tập tin mẫu tiêu chuẩn cho nhiệm vụ. Vì nó hoàn toàn không có chế độ cưỡng bức, nên nó đạt tốc độ chịu đựng nhanh hơn cả 11 nhiều lần so với hệ thống cải tiến hiện đại.', 'nl': 'Edit-based benaderingen hebben onlangs veelbelovende resultaten getoond op meerdere monolinguale sequentie transductie taken. In tegenstelling tot conventionele sequence-to-sequence (Seq2Seq) modellen, die leren om tekst vanaf nul te genereren terwijl ze worden getraind op parallelle corpora, zijn deze methoden veel effectiever gebleken omdat ze in staat zijn om snelle en nauwkeurige transformaties te maken terwijl ze gebruik maken van krachtige vooraf getrainde taalmodellen. Geïnspireerd door deze ideeën presenteren we TST, een eenvoudig en efficiënt tekstvereenvoudigingssysteem gebaseerd op sequence tagging, waarbij gebruik wordt gemaakt van vooraf getrainde Transformer-gebaseerde encoders. Ons systeem maakt simplistische gegevensuitbreidingen en tweaks in training en inference op een reeds bestaand systeem, waardoor het minder afhankelijk is van grote hoeveelheden parallelle trainingsgegevens, meer controle over de outputs biedt en snellere inferentiesnelheden mogelijk maakt. Ons beste model bereikt bijna state-of-the-art prestaties op benchmark testdatasets voor de taak. Omdat het volledig niet-autoregressief is, bereikt het sneller inferentiesnelheden met meer dan elf keer dan het huidige state-of-the-art systeem voor tekstvereenvoudiging.', 'hr': 'U redakciji su nedavno pokazali obećavajuće rezultate na višestrukim monojezičkim poslovima prevode. Za suprotnost konvencionalnim modelima sekvencije do sekvence (Seq2Seq), koji nauče proizvesti tekst iz ogrebotine dok su obučeni na paralelnoj korpori, te metode su dokazale da su mnogo učinkovitije jer su u mogućnosti naučiti brže i precizne transformacije dok su utjecali na moćne predobučene jezičke modele. Inspirirani ovim idejama, predstavljamo TST, jednostavan i učinkovit sustav pojednostavljanja teksta na temelju oznake sekvence, uključujući predobučene kodere na osnovu transformera. Naš sustav čini jednostavnim povećanjem podataka i poticanjem treninga i infekcije na prije postojećem sustavu, što je manje pouzdano na velike količine paralelnih podataka o obuci, pruža više kontrole nad ishodom i omogućava brže brzine infekcije. Naš najbolji model postiže blizu postignuća stanja umjetnosti na standardnim testovima podataka za zadatak. Budući da je potpuno ne-autoregresivna, postiže brže brzine infekcije više od 11 puta nego sadašnji sustav pojednostavljanja teksta stanja umjetnosti.', 'bg': 'Подходите, базирани на редактиране наскоро показаха обещаващи резултати при многоезични задачи за трансдукция на последователност. За разлика от конвенционалните модели последователност към последователност (които се научават да генерират текст от нулата, докато се обучават на паралелни корпуси, тези методи се доказват много по-ефективни, тъй като са в състояние да се научат да правят бързи и точни трансформации, като същевременно използват мощни предварително обучени езикови модели. Вдъхновени от тези идеи, представяме проста и ефективна система за опростяване на текста, базирана на последователно етикетиране, използваща предварително обучени кодери, базирани на трансформатори. Нашата система прави опростени увеличения на данните и промени в обучението и изводите на съществуваща система, което я прави по-малко зависима от големи количества паралелни данни за обучение, осигурява повече контрол върху изходите и позволява по-бързи скорости на изводи. Нашият най-добър модел постига почти най-съвременно представяне на базови тестови набори за задачата. Тъй като е напълно неавторегресивен, той постига по-бързи скорости на заключение с над 11 пъти от настоящата система за опростяване на текста.', 'id': 'Pendekatan berdasarkan edit baru-baru ini menunjukkan hasil yang berjanji pada tugas transduksi urutan monobahasa berbilang. Berbeda dengan model sekwensi-ke-sekwensi konvensional (Seq2Seq), yang belajar menghasilkan teks dari nol karena mereka dilatih pada corpora paralel, metode ini telah terbukti jauh lebih efektif karena mereka mampu belajar untuk membuat transformasi cepat dan akurat sementara menggunakan model bahasa yang kuat pra-dilatih. Terinspirasi oleh ide-ide ini, kami mempersembahkan TST, sistem Simplifikasi Teks sederhana dan efisien berdasarkan Tagging urutan, leveraging koder berdasarkan Transformer. Our system makes simplistic data augmentations and tweaks in training and inference on a pre-existing system, which makes it less reliant on large amounts of parallel training data, provides more control over the outputs and enables faster inference speeds.  Model terbaik kita mencapai pertunjukan terbaik di dataset ujian benchmark untuk tugas ini. Since it is fully non-autoregressive, it achieves faster inference speeds by over 11 times than the current state-of-the-art text simplification system.', 'da': 'Redigeringsbaserede tilgange har for nylig vist lovende resultater på flere ensprogede sekvenstransduktionsopgaver. I modsætning til konventionelle sekvens-til-sekvens (Seq2Seq) modeller, der lærer at generere tekst fra bunden, da de er trænet på parallelle korpora, har disse metoder vist sig at være meget mere effektive, da de er i stand til at lære at foretage hurtige og præcise transformationer, samtidig med at de udnytter kraftfulde prætrænede sprogmodeller. Inspireret af disse ideer præsenterer vi TST, et simpelt og effektivt tekstforenklingssystem baseret på sekvensmærkning, der udnytter forududdannede Transformer-baserede encodere. Vores system foretager forenklede dataforøgelser og justeringer i træning og inference på et allerede eksisterende system, hvilket gør det mindre afhængigt af store mængder parallelle træningsdata, giver mere kontrol over output og muliggør hurtigere inference hastigheder. Vores bedste model opnår næsten state-of-the-art ydeevne på benchmark testdatasæt til opgaven. Da det er fuldstændig ikke-autoregressivt, opnår det hurtigere slutningshastigheder med over 11 gange end det nuværende state-of-the-art tekst forenkling system.', 'de': 'Edit-basierte Ansätze haben in jüngster Zeit vielversprechende Ergebnisse bei mehreren monolingualen Sequenztransduktionsaufgaben gezeigt. Im Gegensatz zu herkömmlichen Sequenz-zu-Sequenz (Seq2Seq)-Modellen, die lernen, Text von Grund auf zu generieren, während sie auf parallelen Korpora trainiert werden, haben sich diese Methoden als viel effektiver erwiesen, da sie lernen können, schnelle und genaue Transformationen durchzuführen und gleichzeitig leistungsstarke vortrainierte Sprachmodelle nutzen. Inspiriert von diesen Ideen präsentieren wir TST, ein einfaches und effizientes Text Simplification System basierend auf Sequenz Tagging, das vorgetrainierte Transformer-basierte Encoder einsetzt. Unser System führt vereinfachte Datenerweiterungen und Optimierungen in Training und Inferenz auf einem bereits vorhandenen System durch, wodurch es weniger auf große Mengen an parallelen Trainingsdaten angewiesen ist, mehr Kontrolle über die Outputs bietet und schnellere Inferenzgeschwindigkeiten ermöglicht. Unser bestes Modell erreicht nahezu den neuesten Stand der Technik bei Benchmark-Testdatensätzen für diese Aufgabe. Da es vollständig nicht autoregressiv ist, erreicht es um mehr als 11-mal schnellere Inferenzgeschwindigkeiten als das aktuelle State-of-the-Art Textvereinfachungssystem.', 'fa': 'روش\u200cهای ویرایش\u200cسازی به اخیرا نتیجه\u200cهای قول\u200cدهنده\u200cای بر روی کارهای ترجمه\u200cکردن مجموعه\u200cی یک زبان نشان داده\u200cاند. در مقابل مدل\u200cهای سرعت به سرعت (Seq2Seq) سنتی که یاد می\u200cگیرند که متن را از سرعت آموزش داده می\u200cشوند، در حالی که بر سرعت شرکت پارالی آموزش داده می\u200cشوند، این روش\u200cها ثابت شده\u200cاند که بسیار مثبت\u200cتر است، زیرا آنها می\u200cتوانند یاد بگیرند که تغییرات سریع و دقیق انجام دهند در حالی که مدل\u200cهای ز توسط این ایده\u200cها، ما TST را نشان می\u200cدهیم، یک سیستم ساده\u200cسازی متن ساده و موثر بر اساس برچسب\u200cهای برچسب\u200cها، تغییر\u200cسازی\u200cها بر اساس متن\u200cسازی\u200cهای پیش\u200cآموزش آموزش داده\u200cایم. سیستم ما به افزایش داده\u200cهای ساده\u200cی ساده\u200cای و تغییرات در آموزش و آلودگی در یک سیستم پیش از آنجا می\u200cسازد، که به اندازه\u200cهای زیادی از داده\u200cهای آموزش مشابه کمتر اعتماد می\u200cکند، کنترل بیشتری بر نتیجه\u200cها می\u200cدهد و سرعت آلودگی سریع\u200cتر را می\u200c بهترین مدل ما نزدیک عملکرد موقعیت هنری در مجموعه\u200cهای داده\u200cهای آزمایش ابزار برای این کار می\u200cرسد. با وجود اینکه کاملا غیر خودگریسی است، سرعت آلودگی سریع تر از سیستم ساده\u200cسازی متن فعلی ۱۱ بار به دست می\u200cآید.', 'sw': 'Matokeo ya kuhariri kwa msingi hivi karibuni yameonyesha matokeo ya kuahidini juu ya kazi mbalimbali za usafirishaji wa lugha. Tofauti na mifano ya mfululizo wa kawaida (Seq2Seq), ambayo inajifunza kutengeneza ujumbe wa kuandika kwa sababu wanafundishwa kwenye makampuni yanayofanana, mbinu hizi zimekwisha kuwa na ufanisi zaidi kwa sababu wanaweza kujifunza kufanya mabadiliko ya haraka na sahihi wakati wa kutumia mifano ya lugha zilizofundishwa kabla. Kuhamasishwa na mawazo haya, tunawasilisha TST, mfumo rahisi na ufanisi wa Simulizi wa Mataifa kwa msingi wa mfululizo wa Tagging, kwa kutumia viungo vya mafunzo vya awali. Mfumo wetu unafanya kuongezeka kwa takwimu rahisi na twiti katika mafunzo na kutokuwepo kwa mfumo wa zamani, ambao unafanya kuitegemea kwa kiasi kikubwa cha taarifa za mafunzo tofauti, hutoa udhibiti zaidi juu ya matokeo na inawezesha kasi ya maambukizi. Mfano wetu bora unafanikiwa karibu na hali ya sanaa kwenye seti za taarifa za uchunguzi wa benchmark kwa ajili ya kazi hiyo. Kwa kuwa haina utawala wa kujitegemea kabisa, hupata kasi ya kuongezeka kwa kasi kwa zaidi ya mara 11 kuliko mfumo wa urahisi wa maandishi ya sasa.', 'ko': '편집 방법을 바탕으로 최근 여러 개의 단어 시퀀스 전도 작업에 희망적인 결과를 나타냈다.전통적인 순서부터 순서(Seq2Seq)모델보다 병행 어료 라이브러리에서 훈련할 때 0부터 텍스트를 생성할 수 있다. 강력한 예훈련 언어모델을 활용하면서 신속하고 정확하게 전환하는 것을 배울 수 있기 때문이다.이러한 생각의 계발을 받아 우리는 TST를 제기했다. 이것은 시퀀스 표시를 바탕으로 하는 간단하고 효율적인 텍스트 간소화 시스템으로 미리 훈련된 변환기 기반 인코더를 이용한다.우리의 시스템은 미리 존재하는 시스템에서 훈련과 추리에 대해 간단한 데이터 확장과 조정을 실시하여 대량의 병행 훈련 데이터에 대한 의존을 줄이고 출력에 대한 더 많은 제어를 제공하며 더욱 빠른 추리 속도를 실현했다.우리의 가장 좋은 모델은 임무의 기준 테스트 데이터 집합에서 가장 선진적인 성능에 가깝게 실현되었다.그것은 완전히 비자귀환적이기 때문에 추리 속도가 현재 가장 선진적인 텍스트 간소화 시스템보다 11배 이상 빠르다.', 'af': "Redigeer- gebaseerde toegang het onlangs gewys belofte resultate op veelvuldige monolingse volgorde oordrag opdragte. In contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proven to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. Inspirasie deur hierdie idee, ons stel TST voor 'n eenvoudige en effektief teks Vereenvoudiging stelsel gebaseer op sekwensiemerking, verwysing van vooraf-onderwerp Transformer-gebaseerde koders. Ons stelsel maak eenvoudige data opbreidings en tweaks in optreiding en inferensie op 'n voorafbestaande stelsel, wat dit minder betroubaar maak op groot hoeveelheid parallele optreiding data, verskaf meer kontrole oor die uitvoerdes en laat vinniger inferensie speletjies toe. Ons beste model bereik naby status-of-the-art prestasie op benchmark toets datastel vir die taak. Omdat dit volledig nie-autoregressief is, word dit vinniger inferensie speletjies bereik deur meer 11 maal as die huidige staat-van-die-kunstens teks eenvoudiging stelsel.", 'sq': 'Përqasjet e bazuara në ndryshim kanë treguar kohët e fundit rezultate premtuese mbi detyrat e transdukimit të sekuencës së shumtë monogjuhësore. Në kundërshtim me modelet konvencionale sekuencë-në-sekuencë (Seq2Seq), që mësojnë të gjenerojnë tekst nga zero ndërsa janë trajnuar në korpra paralele, këto metoda kanë provuar të jenë shumë më efektive pasi janë në gjendje të mësojnë të bëjnë transformime të shpejta dhe të sakta ndërsa përdorin modele të fuqishme gjuhësh të paratrajnuara. Inspiruar nga këto ide, ne paraqesim TST, një sistem i thjeshtë dhe efikas të thjeshtësimit të tekstit bazuar në etiketat e sekuencës, duke nxitur koduesit e paratrajnuar me bazë në Transformer. Sistemi ynë bën rritje të të dhënave të thjeshta dhe ndryshime në trainimin dhe përfundimin në një sistem paraekzistues, i cili e bën më pak të varur nga sasi të mëdha të të dhënave paralele të trainimit, ofron më shumë kontrolli mbi rezultatet dhe lejon shpejtësi më të shpejtë të përfundimit. Modeli ynë më i mirë arrin afër shfaqjes më të moderne në bazën e të dhënave të testimit për detyrën. Duke qenë se është plotësisht jo-autoregressive, ajo arrin shpejtësi më të shpejtë përfundimi me mbi 11 herë se sistemi aktual i thjeshtësimit të tekstit.', 'am': 'አካባቢ ደረጃዎች በአሁኑ ጊዜ የተስፋ ውጤቶች በብዙ በሞሎንቋል ስራዎችን የሚያሳዩ ናቸው፡፡ በተቃውሞው የደረጃ ምርጫዎች (Seq2Seq) ምሳሌዎች፣ ጽሑፍን ከክፈት መፍጠር ማድረግ በሚያስተምሩ በፓርላማ ኮርፖራ ላይ ሲያስተማሩ፣ እነዚህ ሥርዓቶች በቶሎ እና እርግጠኛ ለውጦችን ለመማር ሲችሉ፣ ኃይለኛ የፊተኛውን የቋንቋ ምሳሌዎችን በመስጠት ይችላሉ፡፡ እንደዚህ አእምሮዎች የTST እናስገራለን፣ በተቀናቀለ የጽሑፍ ቀላልና የበለጠ የጽሑፍ ቀላል ስርዓት፣ አስቀድሞ ተማርቷል የተለወጠውን የፊደል ኮዶችን በመስጠት እናስጠጋለን፡፡ ሲስተካከላችን ቀላል ዳታዎችን ማድረግ እና ማስጠንቀቂያውን አስቀድሞ ስርዓት ማድረግ እና ማሰቃየትን እና ትዊተር ያደርጋል፡፡ የተሻለ ምሳሌያችን ለስራው የ-የ-አርእስት ግንኙነት አቅራቢያ እንዲደረግ አግኝቷል፡፡ በአሁኑ ሁኔታ-የ-art-ጽሑፍ ቀላል ሲሆን የአንድ ጊዜ በላይ 11 እጥፍ ፈጥኖ ይደረጋል፡፡', 'tr': "Editlenen yaklaýyşlar son zamanlarda birnäçe mono dilli terjime täbliklerinde söz berýän netijesi görkezildi. Däpli görnüş-terjime (Seq2Seq) modelleriň garşy bilen, başlangyçdan metin döretmäge öwrenýän, parallel korporada öwrenmek üçin bu yönler çalt we dogry terjime etmegi öwrenip biljek üçin bu ýoly gaty täsirli bolup, sebäbi çalt we dogry terjime etmegi öwrenip bilýärler. Bu ideýalar tarapyndan isleýän, TST'i basit we etkinlik bir metin bejermeleri sistemasyna görkezýäris. Diňe etitleme sistemi, öňünden täzeden terjime etmäge tabanly ködlemeler üçin süýtgedýäris. Biziň sistemamyz öň bar sistemada basistik maglumatlar ýetişdirilýär we ýetişdirilýär. Bu sistemimiz ön bar sistemde birnäçe maglumatlar barada ýetişdirilýär, netijeleri üstünde köp kontrol edendir we çalt azaltmak hızyny mümkin edýär. Biziň iň gowy nusgamyz görenimiz üçin benchmark testiň durumynda tapylýar. Bu doly otoregressiv däldigine sebäbi ol, şu wagtyň durumynda okan teks bejermeleri sisteminden 11-nji gezek çalt ýigrençä süýtgedýär.", 'bs': 'U redakciji su nedavno pokazali obećavajuće rezultate na višestrukim monojezičkim poslovima prevode. Za suprotnost konvencionalnim modelima sekvencije do sekvence (Seq2Seq), koji nauče da stvore tekst iz ogrebotine dok su obučeni na paralelnoj korpori, te metode su dokazale da su mnogo efikasnije jer su u mogućnosti naučiti da napraviju brze i tačne transformacije, dok se utiču na moćne predobučene jezičke modele. Inspirirani ovim idejama, predstavljamo TST, jednostavan i efikasni sistem pojednostavljanja teksta na osnovu oznake sekvence, uključujući predobučene kodere na osnovu transformera. Naš sistem čini jednostavnim povećanjem podataka i poticanjem treninga i infekcije na pre-postojeći sistem, što ga čini manje pouzdanim na velike količine paralelnih podataka o obuci, pruža više kontrole nad ishodom i omogućava brže brzine infekcije. Naš najbolji model postiže blizu nastave umjetnosti na testovima standardnih podataka za zadatak. Budući da je potpuno ne-autoregresivna, postiže brže brzine infekcije više od 11 puta nego trenutni sistem pojednostavljanja teksta.', 'hy': 'Խմբագրման հիմնված մոտեցումները վերջերս ցույց են տալիս խոստացնող արդյունքներ բազմալեզու հաջորդականության վերաբերյալ: Ի հակադրություն ավանդական հաջորդականության (SeQ2SeQ) մոդելներին, որոնք սովորում են ստեղծել տեքստ զրոյից, երբ նրանք պատրաստվում են զուգահեռ մարմնի վրա, այս մեթոդները ապացուցել են, որ շատ ավելի արդյունավետ են, քանի որ նրանք կարողանում են սովորել արագ և ճշգրիտ փոփոխություններ անել, միաժամանակ օգտագործելով հզոր նախապատրաստ Այս գաղափարներով ոգեշնչված ենք, մենք ներկայացնում ենք ԹՍԹ-ը, մի պարզ և արդյունավետ տեքստի պարզաբանման համակարգ, որը հիմնված է հաջորդականության նշանների վրա, օգտագործելով նախապատրաստված տրանֆորմերի հիմնված կոդերները: Մեր համակարգը պարզ տվյալներ բարձրացնում է և հարմարվում է նախկինում գոյություն ունեցող համակարգի ուսումնասիրության և հետևանքների մեջ, ինչը նվազեցնում է այն կախված մեծ քանակությամբ զուգահեռ ուսումնասիրության տվյալների վրա, ապահովում է ավելի մեծ վերահսկողություն արդյունք Մեր լավագույն մոդելը հասնում է աշխատանքի վերաբերյալ վերջին արդյունքներին: Քանի որ այն ամբողջովին ոչ ինքնագրավիչ է, այն հասնում է ավելի արագ եզրակացության արագություններին 11 անգամ, քան ներկայիս ամենաբարձր տեքստի պարզաբանման համակարգը:', 'az': "Edit-based approaches have recently shown promising results on multiple monolingual sequence transduction tasks. Parallel korpora t…ôhsil edildiyi zaman, bu metodlar tezlikl…ô v…ô d√ľzg√ľn d…ôyiŇüiklikl…ôri √∂yr…ôn…ô bil…ôc…ôkl…ôrind…ôn √∂yr…ôn…ôn, t…ôhsil edilmiŇü dil modellerini t…ôhsil ed…ôrk…ôn d…ôyiŇüiklik v…ô d…ôyiŇüiklik d…ôyiŇüiklikl…ôri √∂yr…ôn…ô bil…ôc…ôkl…ôrin…ô g√∂r…ô daha √ßox etkilidir. Bu fikirl…ôr tarafńĪndan t…ôŇükil edilmiŇüdir, biz TST'i, sńĪralar etiketl…ôm…ôsin…ô dayanan, …ôvv…ôlc…ô t…ôhsil edilmiŇü transformer-tabanlńĪ kodlayńĪcńĪlarńĪ t…ôŇükil edirik. Sistemimiz, …ôvv…ôlki sistemd…ô t…ôhsil v…ô infeksiya i√ßind…ô asanlńĪq veril…ôn m…ôlumatlar artńĪrmańüńĪ v…ô tweaksi yaratdńĪrńĪr, bu da b√∂y√ľk paralel t…ôhsil m…ôlumatlarńĪna daha az g√ľvenilir, √ßńĪxńĪŇülarńĪn √ľst√ľnd…ô daha √ßox kontrol ed…ôr v…ô daha hńĪzlńĪ infeksiya hńĪzlarńĪnńĪ f…ôallaŇüdńĪrńĪr. ∆Źn yaxŇüńĪ modell…ôrimiz bu iŇü √ľ√ß√ľn benchmark sńĪnama veril…ônl…ôrin qurńüularńĪnńĪn yaxńĪnlńĪńüńĪnda √ßalńĪŇüńĪr. Bu tamamil…ô autoregressiv olmayan t…ôrzd…ô, h…ômin m…ôktub oxumasńĪ sistemind…ôn 11 d…ôf…ô daha hńĪzlńĪ infeksyon s√ľr…ôtini art ńĪrar.", 'ca': "Els enfocaments basats en edicions han demostrat recentment resultats prometedors en múltiples tasques de transducció de seqüències monolingües. A diferent dels models convencionals de seqüència a seqüència (Seq2Seq), que aprenen a generar text de zero mentre s'entrenen en corpora parallela, aquests mètodes han demostrat ser molt més efectius, des que poden aprendre a fer transformacions ràpides i exactes mentre utilitzen models de llenguatge avançats poderosos. Inspirat per aquestes idees, presentem TST, un sistema simple i eficient de simplificació del text basat en etiquetar seqüències, aprofitant codificadors pré-entrenats basats en transformadors. Our system makes simplistic data augmentations and tweaks in training and inference on a pre-existing system, which makes it less reliant on large amounts of parallel training data, provides more control over the outputs and enables faster inference speeds.  El nostre millor model aconsegueix un rendiment més avançat en els conjunts de dades de comparació de la tasca. Com que no és totalment autoregressiu, aconsegueix velocitats de inferència més de 11 vegades més ràpids que el sistema actual de simplificació del text més avançat.", 'bn': 'সম্প্রতি ভিত্তিক উপায় সম্পাদনা করা হয়েছে বেশ কয়েকটি মোনোলিভাল সেকেন্স ট্রান্ড্রান্ডকেশন কাজের উপর প্রতিশ্রু প্যারালেল কর্পোরায় তাদের টেক্সট তৈরি করার প্রশিক্ষা প্রদান করা হয়েছে কারণ তারা দ্রুত এবং সঠিকভাবে পরিবর্তন শিখতে পারে যখন ক্ষমতাশালী পূর্ব প্রশিক্ষিত ভাষার মডেল প্রদান করতে পারে। এই চিন্তাগুলো দ্বারা অনুপ্রাণিত, আমরা টিএসটিকে উপস্থাপন করি, সাধারণ এবং কার্যকর টেক্সট সাধারণ ট্যাগিং ব্যবস্থা, পূর্ব প্রশিক্ষণিত ট্রা আমাদের সিস্টেম একটি পূর্বের বিদ্যমান সিস্টেমে প্রশিক্ষণ এবং অস্থিরতার জন্য সহজ তথ্য বাড়িয়ে দেয় এবং টুইট করে, যা বিশাল পরিমাণ প্রশিক্ষণের তথ্যের উপর নির্ভর করে, ফলে আউটপু আমাদের সবচেয়ে ভাল মডেল এই কাজের জন্য বেঞ্চমার্কের পরীক্ষার ডেটাসেটের কাছে রাষ্ট্র-অফ-শিল্পের প্রদর্ যেহেতু এটা পুরোপুরি স্বয়ংক্রিয়ভাবে না নিয়ন্ত্রণের কারণে, বর্তমান রাষ্ট্র-শিল্পের টেক্সট স্বয়ংক্রিয়ভাবে ১১ বারের ব', 'et': 'Redigeerimispõhised lähenemisviisid on hiljuti näidanud paljulubavaid tulemusi mitme ühekeelse järjestuse transduktsiooni ülesannete puhul. Erinevalt tavapärastest järjestusest järjestusse (Seq2Seq) mudelitest, mis õpivad genereerima teksti nullist paralleelsetel korpustel treenides, on need meetodid osutunud palju tõhusamaks, kuna nad suudavad õppida tegema kiireid ja täpseid transformatsioone, kasutades samal ajal võimsaid eeltreenitud keelemudeleid. Nendest ideedest inspireerituna tutvustame TST-d, lihtsat ja tõhusat teksti lihtsustamise süsteemi, mis põhineb järjestuse märgistamisel, kasutades eelnevalt väljaõpetatud Transformer-põhiseid kodeerijaid. Meie süsteem teeb olemasoleva süsteemi koolituses ja järeldustes lihtsustatud andmete täiendamist ja muudatusi, mis muudab selle vähem sõltuvaks suurtest kogustest paralleelsetest treeninguandmetest, annab rohkem kontrolli väljundite üle ja võimaldab kiiremaid järelduste kiirusi. Meie parim mudel saavutab ülesande võrdlustestide andmekogumite peaaegu tipptasemel jõudluse. Kuna see ei ole täielikult autoregressiivne, saavutab see kiirema järelduskiiruse rohkem kui 11 korda kui praegune tipptasemel teksti lihtsustamise süsteem.', 'fi': 'Muokkauspohjaiset lähestymistavat ovat viime aikoina osoittaneet lupaavia tuloksia monikielisessä sekvenssinmuunnuksessa. Toisin kuin perinteiset Seq2Seq-mallit, jotka oppivat tuottamaan tekstiä tyhjästä rinnakkaisilla korpusilla harjoitettaessa, nämä menetelmät ovat osoittautuneet paljon tehokkaampiksi, koska ne pystyvät oppimaan tekemään nopeita ja tarkkoja muunnoksia hyödyntäen tehokkaita esikoulutettuja kielimalleja. Näiden ideoiden innoittamana esittelemme TST:n, yksinkertaisen ja tehokkaan tekstin yksinkertaistamisjärjestelmän, joka perustuu sekvenssimerkkaukseen ja hyödyntää valmiiksi koulutettuja muuntajapohjaisia koodereita. Järjestelmämme tekee yksinkertaisia tietojen lisäyksiä ja säätöjä koulutuksessa ja päättelyssä jo olemassa olevaan järjestelmään, mikä tekee siitä vähemmän riippuvaisen suurista määristä rinnakkaisia harjoitustietoja, antaa enemmän hallintaa tuotoksiin ja mahdollistaa nopeammat päättelynopeudet. Parhaalla mallillamme saavutetaan lähes uusinta suorituskykyä tehtävän vertailutestiaineistoissa. Koska se on täysin ei-autoregressiivinen, se saavuttaa nopeammat päättelynopeudet yli 11 kertaa kuin nykyinen huipputekninen tekstin yksinkertaistamisjärjestelmä.', 'cs': 'Editované přístupy v poslední době ukázaly slibné výsledky na více monojazyčných transdukčních úlohách. Na rozdíl od konvenčních modelů sekvence-to-sekvence (Seq2Seq), které se naučí generovat text od začátku, když jsou trénovány na paralelních korpusech, se tyto metody ukázaly jako mnohem efektivnější, protože jsou schopny se naučit provádět rychlé a přesné transformace při využití výkonných předškolených jazykových modelů. Inspirováni těmito myšlenkami představujeme TST, jednoduchý a efektivní systém zjednodušení textu založený na sekvenčním tagování, využívající předškolené snímače založené na Transformeru. Náš systém provádí zjednodušující rozšíření a vylepšení dat v tréninku a inferenci na již existujícím systému, čímž je méně závislý na velkém množství paralelních tréninkových dat, poskytuje větší kontrolu nad výstupy a umožňuje vyšší rychlost inference. Náš nejlepší model dosahuje téměř nejmodernějšího výkonu na referenčních testovacích sadách pro daný úkol. Vzhledem k tomu, že je plně neautoregresivní, dosahuje rychlejších inferencí více než jedenákrát než současný nejmodernější systém zjednodušení textu.', 'jv': 'section Daerah contrast karo modelo sewendigo-to-sewendigo Yuta-Yuta ngerti ide sing iki, kita sampeyan Sistem awak dhéwé kuwi nggawe sistem sistem sing pertama awak dhéwé karo nggawe barang sistem sing gak adhil, sing teka kuwi nggawe barang sistem sing gak dhéwé, kuwi nggawe sistem sing beraksi kuwi bagian kuwi nggawe data alat, akeh nyong langgar-sistem sing beraksi dadi nggawe barang bakal maneh, iso diang Monday Dino mbok saiki, ora autoréaksi, dadi iso nggawe luwih operas seneng pisan kanggo 11 ulih maneh kaya sistem sing dikarepaké durus-kiper Text.', 'ha': "@ action: button Tsarin motsi da misãlai masu haɗi zuwa-sequence (Seq2Seq), wanda za su iya ƙara matsayi daga tsohon kwanan an da aka sanar su a kan makampuni masu daidaita, za'a jarraba waɗannan hanyoyin yin su kasance mafi mai amfani da ko kuwa, ko da za su iya iya fahimtar su fara ko da taƙaitacce idan an cika misãlai masu ƙarfi da aka yi wa-sha'awa. An yi wahayi da waɗannan idãnun, Munã halatar da TS, a kan system mai sauƙi da mai amfani da matsayin Similarity na daidaita a kan sauri-Tagagi, da mai bãyar da kodi-kodi wanda aka yi wa zaman-yin-sha'a. Ana sami na'asarmu yana ƙara data masu sauƙi kuma yana biyar mafarin da yin shirin da ya sami gaba-gaba, wanda yana kasancewa ta dõgara da yawan mutane na tattalin da fanali, yana da ƙaranci domin matsalan na'ura da kashi fara-kashi. Babu misalinmu ya sami mafiya kusantar halin-sanar kan jarrabar data na bonkimar zuwa aikin. Ki da ya zama mai cikakken-farat-farat, yana sãmu da gaggãwa da maras kafin kasa sauri koda 11 sau ɗaya ko da na tsarin rubutun da ake kai yanzu-rubutun-na-art.", 'sk': 'Pristopi, ki temeljijo na urejanju, so nedavno pokazali obetavne rezultate pri nalogah transdukcije več enojezičnih zaporedj. V nasprotju z običajnimi modeli zaporedja v zaporedje (Seq2Seq), ki se naučijo ustvarjati besedilo iz nič, ko se usposabljajo na vzporednih korpusih, so se te metode izkazale za veliko učinkovitejše, saj se lahko naučijo hitrih in natančnih transformacij, hkrati pa uporabljajo zmogljive predhodno usposobljene jezikovne modele. Na podlagi teh idej predstavljamo TST, preprost in učinkovit sistem za poenostavitev besedila, ki temelji na označevanju zaporedja, ki uporablja vnaprej usposobljene kodirje na podlagi transformatorjev. Naš sistem izvaja poenostavljene povečave podatkov in prilagoditve pri usposabljanju in sklepanju na že obstoječem sistemu, zaradi česar je manj odvisen od velikih količin vzporednih podatkov o usposabljanju, zagotavlja večji nadzor nad izhodi in omogoča hitrejše sklepanje. Naš najboljši model dosega skoraj najsodobnejše zmogljivosti na referenčnih preskusnih naborih podatkov za nalogo. Ker je popolnoma ne-avtoregresiven, doseže hitrejše hitrosti sklepanja za več kot 11-krat od sedanjega najsodobnejšega sistema za poenostavitev besedila.', 'he': '讙讬砖讜转 诪讘讜住住讜转 注诇 注讜专讱 讛专讗讜 诇讗讞专讜谞讛 转讜爪讗讜转 诪讘讟讬讞讜转 注诇 诪砖讬诪讜转 诪注讘专转 专爪祝 诪讜谞讜诇砖讜谞讜转 专讘讜转. 讘谞讬讙讜讚 诇讚讜讙诪谞讬诐 拽讜谞住讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬讜谞爪讬 讘讛砖专讗讛 注诇 讬讚讬 讛专注讬讜谞讜转 讛讗诇讛, 讗谞讜 诪爪讬讙讬诐 TST, 诪注专讻转 驻砖讜讟讛 讜讬讻讜诇转 诇讛驻砖讬讟 讟拽住讟 诪讘讜住住转 注诇 转讜讜讬讜转 专爪祝, 诪砖转诪砖 讘拽讜讚专讬诐 诪讘讜住住讬诐 讘讟专谞住驻讜专专 诪讗讜诪谞讬诐 诪专讗砖. 讛诪注专讻转 砖诇谞讜 注讜砖讛 砖讬谞讜讬讬诐 谞转讜谞讬诐 驻砖讜讟讬诐 讜砖讬谞讜讬讬诐 讘讗讬诪讜谉 讜讛转讜爪讗讛 注诇 诪注专讻转 拽讜讚诪转 拽讬讬诪转, 诪讛 砖注讜砖讛 讗讜转讛 驻讞讜转 转诇讜讬讛 讘讻诪讜转 讙讚讜诇讜转 砖诇 谞转讜谞讬诐 讗讬诪讜谞讬诐 诪拽讘讬诇讬诐, 诪住驻拽 讬讜转专 砖诇讬讟讛 注诇 讛转讜爪讗讜转 讜讗驻砖专 诪讛讬专讜转 讛讛转讜爪讗讛 诪讛讬专讛 讬讜转专. 讛诪讜讚诇 讛讟讜讘 讘讬讜转专 砖诇谞讜 诪砖讬讙 讘讬爪讜注讬诐 拽专讜讘讬诐 诇讗讜专讱 讛诪爪讘 讘诪注专讻转 讛谞转讜谞讬诐 砖诇 讛诪讘讞谉. Since it is fully non-autoregressive, it achieves faster inference speeds by over 11 times than the current state-of-the-art text simplification system.', 'bo': 'བསྒྱུར་བཅོས་ཐབས་ལམ་ལ་བཟོ་བཅོས་ནི་ཉེ་ཆར་ཡིན་ལ་བརྗོད་པའི་གནད་སྡུད་ཆ་རྣམས་མངོན་པ་ཡིན། In contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proven to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. The following methods have proved to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. ངའི་བསམ་ཚུལ་འདི་དག་གིས་ངེད་ཚོས་TST ལྟ་བུའི་སྟབས་བདེ་ནུས་པ་ཡིན་པའི་ཡིག་གེ་སྟབས་དཔྱད་རྟགས་བཀོད་པ་དང་སྔོན་གྱིས་བཟོ་བཅོས་པ་ ང་ཚོའི་མ་ལག་གིས་སྔོན་ཡོད་པའི་སྔོན་ཡོད་པའི་ལག་འཁྱེར་གྱི་ཚད་རྒྱ་བསྐྱེད་སྟངས་དང་བསྐྱེད་སྟངས་ལ་གསལ་བསྐྱེད་པའི་ཚད་གཞི་རྩལ་ཆེ་བ་ཏུ་ཉར་འཇུག་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མ་དབྱིབས་གཟུགས་རིས་བྱུང་བའི་གནས་སྟངས་དེ་ལྟར་བཅས་ཀྱི་ལས་འཆར་བརྟག་དཔྱད་གཞི་རྩལ་བ་དང་། རང་འགུལ་གྱིས་མེད་པ་ལས་དུས་ཡོད་ཚད་ལྡན་མིན་པར། དེ་ལས་རང་འགུལ་གྱི་གནས་སྟངས་གསལ་བཤད་ཀྱི་མ་ལག་ལས་ལྡན་འགྱུར་བའི་མགྱོགས་ལྡན་'}
{'en': 'Broad Linguistic Complexity Analysis for Greek Readability Classification G reek Readability Classification', 'pt': 'Análise de complexidade linguística ampla para classificação de legibilidade em grego', 'fr': 'Analyse globale de la complexité linguistique pour la classification de lisibilité grecque', 'ar': 'تحليل التعقيد اللغوي الواسع لتصنيف المقروئية اليونانية', 'es': 'Análisis amplio de complejidad lingüística para la clasificación de legibilidad griega', 'ja': 'ギリシャ語の読みやすさ分類のための広範な言語的複雑性分析', 'zh': '希腊语可读性类博言复杂性析', 'hi': 'ग्रीक पठनीयता वर्गीकरण के लिए व्यापक भाषाई जटिलता विश्लेषण', 'ru': 'Широкий анализ лингвистической сложности для греческой читабельной классификации', 'ga': "Anailís ar Choimpléasc Teangeolaíoch Leathan d'Aicmiú Inléiteacht na Gréige", 'hu': 'Széles körű nyelvi komplex elemzés a görög olvashatósági osztályozáshoz', 'el': 'Ευρεία Ανάλυση Γλωσσολογικής πολυπλοκότητας για την ταξινόμηση της ελληνικής αναγνωσιμότητας', 'it': 'Ampia analisi della complessità linguistica per la classificazione della leggibilità greca', 'ka': 'უფრო დიდი ლინგუტიკური კომპლექტიკური ანალიზი გრეკური კლასიფიკაციაციისთვის', 'lt': 'Broad Linguistic Complexity Analysis for Greek Readability Classification', 'ms': 'Broad Linguistic Complexity Analysis for Greek Readability Classification', 'mk': 'Анализа на широка јазична комплексност за класификација на грчката читливост', 'mn': 'Грекийн унших чадварын классификацийн шинжилгээ', 'ml': 'ഗ്രീക്കിന്റെ റീഡിബിളിറ്റി ക്ലാസിഷനിലേക്കുള്ള ലിങ്കിസ്റ്റിക്സിക്സിറ്റി പരിശോധന', 'pl': 'Szeroka analiza złożoności językowej dla klasyfikacji czytelności greckiej', 'no': 'Breidde lingskompleksitetsanalyse for gresk klassifisering av lesabilitet', 'sr': 'Brojna lingvistička kompleksnost analiza grčke klasifikacije spremnosti', 'si': 'ග්\u200dරීක් සුදුසුම් විශ්ලේෂණය ගැන විශ්ලේෂණය', 'so': 'Analysis ku saabsan habka luqada ee lagu sameeyo fasaxa aqbalka afka Gariigka', 'mt': 'Broad Linguistic Complexity Analysis for Greek Readability Classification', 'sv': 'Bred sprĂ¥klig komplexitetsanalys fĂ¶r grekisk lĂ¤sbarhetsklassificering', 'ta': 'Name', 'kk': 'Грек оқу мүмкіндігін классификациялау үшін жалпы лингвистикалық толық анализ', 'ro': 'Analiza complexității lingvistice largi pentru clasificarea lizibilității grecești', 'ur': 'یونانی Readability Classification کے لئے براڈ لینگ گیسٹی پیٹکسٹی تحلیل', 'uz': 'Name', 'vi': 'Trình phân tích ngôn ngữ rộng lớn cho mật độ vững mạnh Hy Lạp', 'bg': 'Широк лингвистичен анализ на сложността за класификация на гръцката четливост', 'nl': 'Uitgebreide taalkundige complexiteitsanalyse voor Griekse leesbaarheidsclassificatie', 'hr': 'Analiza široke lingvističke kompleksnosti za klasifikaciju grčke spremnosti', 'da': 'Bred sproglig kompleksitetsanalyse for græsk læsbarhedsklassificering', 'de': 'Umfassende linguistische Komplexitätsanalyse für die Klassifizierung der griechischen Lesbarkeit', 'id': 'Broad Linguistic Complexity Analysis for Greek Readability Classification', 'fa': 'تحلیل پیچیدگی زبان گسترده برای کلاس خواندن قابلیت یونانی', 'ko': '그리스어 가독성 분류의 광의적 언어 복잡성 분석', 'tr': 'Yunaniň okaýanlygy klasifikasy üçin Gatlaýyn Diller', 'sw': 'Uchambuzi wa Ubaguzi wa Kilinguistic kwa Kigiriki', 'am': 'አቀማመጥ', 'sq': 'Analiza e gjerë e kompleksitetit gjuhësor për klasifikimin e lexueshmërisë greke', 'hy': 'Հունաստանի կարդալիության դասակարգման լայն լեզվային բարդությունների վերլուծությունը', 'az': 'Yunanlıq oxuyabiləcəyi Klasifikat üçün genişliyi Linguistik Tamamlama Analizi', 'bn': 'গ্রীকের প্রত্যাবর্তনযোগ্যতার জন্য লিঙ্গিস্টিক কমপ্লেক্সিটি ব্রাড করুন', 'bs': 'Brojna lingvistička kompleksnost analiza grčke klasifikacije spremnosti', 'et': 'Lai keelelise keerukuse analüüs kreeka loetavuse klassifikatsiooni jaoks', 'af': 'Broad Linguistic Kompleksie Analiseer vir Griekse Leesbaardigheid Klassifikasie', 'fi': 'Laaja kielinen monimutkaisuusanalyysi kreikan luettavuusluokitukselle', 'cs': 'Široká analýza jazykové složitosti pro klasifikaci řecké čitelnosti', 'ca': 'Anàlisi ampli de complexitat lingüística per a la classificació grega de llegibilitat', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'Broad Linguistic Complexity Analysis for Greek Readability Classification', 'sk': 'Široka jezikovna analiza kompleksnosti za grško klasifikacijo berljivosti', 'ha': 'Analyza wa KCharselect unicode block name', 'bo': 'Broad Linguistic Complexity Analysis for Greek Readability Classification'}
{'en': 'This paper explores the linguistic complexity of Greek textbooks as a readability classification task. We analyze textbook corpora for different school subjects and textbooks for  Greek  as a Second Language, covering a very wide spectrum of school age groups and proficiency levels. A broad range of quantifiable linguistic complexity features (lexical, morphological and syntactic) are extracted and calculated. Conducting experiments with different  feature subsets , we show that the different linguistic dimensions contribute orthogonal information, each contributing towards the highest result achieved using all linguistic feature subsets. A readability classifier trained on this basis reaches a  classification accuracy  of 88.16 % for the  Greek  as a Second Language corpus. To investigate the generalizability of the  classification models , we also perform cross-corpus evaluations. We show that the  model  trained on the most varied text collection (for  Greek  as a school subject) generalizes best. In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different feature sets and training setups for generalizable readability classification.', 'ar': 'تستكشف هذه الورقة التعقيد اللغوي للكتب المدرسية اليونانية كمهمة تصنيف مقروئية. نقوم بتحليل مجموعات الكتب المدرسية للمواد الدراسية والكتب المدرسية المختلفة للغة اليونانية كلغة ثانية ، والتي تغطي مجموعة واسعة جدًا من الفئات العمرية في المدرسة ومستويات الكفاءة. يتم استخراج وحساب مجموعة واسعة من سمات التعقيد اللغوي القابلة للقياس (المعجمية والصرفية والنحوية). عند إجراء تجارب مع مجموعات فرعية مختلفة من الميزات ، نظهر أن الأبعاد اللغوية المختلفة تساهم في المعلومات المتعامدة ، حيث يساهم كل منها في تحقيق أعلى نتيجة يتم تحقيقها باستخدام جميع مجموعات السمات اللغوية الفرعية. يصل مصنف المقروئية الذي تم تدريبه على هذا الأساس إلى دقة تصنيف تبلغ 88.16٪ لمجموعة اليونانية كلغة ثانية. للتحقيق في قابلية تعميم نماذج التصنيف ، نقوم أيضًا بإجراء تقييمات شاملة للمجموعة. نظهر أن النموذج الذي تم تدريبه على مجموعة النصوص الأكثر تنوعًا (بالنسبة لليونانية كموضوع مدرسي) يتم تعميمه بشكل أفضل. بالإضافة إلى تطوير أحدث التقنيات لتحليل قابلية القراءة اليونانية ، تساهم الورقة أيضًا في رؤى حول دور مجموعات الميزات المختلفة وإعدادات التدريب لتصنيف قابلية القراءة القابلة للتعميم.', 'es': 'Este artículo explora la complejidad lingüística de los libros de texto griegos como una tarea de clasificación de legibilidad. Analizamos corpus de libros de texto para diferentes materias escolares y libros de texto para griego como segundo idioma, que cubren un espectro muy amplio de grupos de edad escolar y niveles de dominio. Se extrae y calcula una amplia gama de características de complejidad lingüística cuantificables (léxicas, morfológicas y sintácticas). Al realizar experimentos con diferentes subconjuntos de características, mostramos que las diferentes dimensiones lingüísticas aportan información ortogonal, cada una de las cuales contribuye al mayor resultado obtenido con todos los subconjuntos de características lingüísticas. Un clasificador de legibilidad entrenado sobre esta base alcanza una precisión de clasificación del 88,16% para el corpus de griego como segundo idioma. Para investigar la generalización de los modelos de clasificación, también realizamos evaluaciones cruzadas de corpus. Demostramos que el modelo entrenado en la colección de textos más variada (para el griego como materia escolar) generaliza mejor. Además de avanzar en el estado del arte del análisis de legibilidad en griego, el documento también aporta información sobre el papel de los diferentes conjuntos de características y configuraciones de entrenamiento para la clasificación de legibilidad generalizable.', 'pt': 'Este artigo explora a complexidade linguística dos livros didáticos de grego como uma tarefa de classificação de legibilidade. Analisamos corpora de livros didáticos para diferentes disciplinas escolares e livros didáticos de grego como segunda língua, cobrindo um espectro muito amplo de faixas etárias escolares e níveis de proficiência. Uma ampla gama de características quantificáveis de complexidade linguística (lexical, morfológica e sintática) são extraídas e calculadas. Conduzindo experimentos com diferentes subconjuntos de traços, mostramos que as diferentes dimensões linguísticas contribuem com informações ortogonais, cada uma contribuindo para o maior resultado alcançado usando todos os subconjuntos de traços linguísticos. Um classificador de legibilidade treinado nesta base atinge uma precisão de classificação de 88,16% para o corpus grego como segunda língua. Para investigar a generalização dos modelos de classificação, também realizamos avaliações entre corpus. Mostramos que o modelo treinado na mais variada coleção de textos (para grego como disciplina escolar) generaliza melhor. Além de avançar no estado da arte para análise de legibilidade grega, o artigo também contribui com insights sobre o papel de diferentes conjuntos de recursos e configurações de treinamento para classificação de legibilidade generalizável.', 'fr': "Cet article explore la complexité linguistique des manuels grecs en tant que tâche de classification de la lisibilité. Nous analysons des corpus de manuels pour différentes matières scolaires et des manuels pour le grec langue seconde, couvrant un très large éventail de groupes d'âge scolaire et de niveaux de compétence. Un large éventail de caractéristiques de complexité linguistique quantifiables (lexicales, morphologiques et syntaxiques) sont extraites et calculées. En menant des expériences avec différents sous-ensembles de caractéristiques, nous montrons que les différentes dimensions linguistiques fournissent des informations orthogonales, chacune contribuant au meilleur résultat obtenu en utilisant tous les sous-ensembles de caractéristiques linguistiques. Un classificateur de lisibilité formé sur cette base atteint une précision de classification de 88,16\xa0% pour le corpus Grec langue seconde. Pour étudier la généralisabilité des modèles de classification, nous effectuons également des évaluations intercorpus. Nous montrons que le modèle formé sur la collection de textes les plus variés (pour le grec en tant que matière scolaire) généralise le mieux. En plus de faire progresser l'état de l'art en matière d'analyse de lisibilité grecque, l'article fournit également des informations sur le rôle des différents ensembles de caractéristiques et configurations de formation pour la classification de lisibilité généralisable.", 'ja': '本論文では、読みやすさの分類課題として、ギリシャ語の教科書の言語的複雑性を探求する。 私たちは、さまざまな学校の教科のための教科書コーパスと、第二言語としてのギリシャ語のための教科書を分析し、非常に幅広い学齢層と習熟度をカバーしています。 広範囲の定量化可能な言語的複雑性の特徴（語彙的、形態的、構文的）が抽出され、計算される。 異なる特徴サブセットの実験を実施することで、異なる言語次元が直交情報に寄与し、すべての言語的特徴サブセットを使用して達成された最高の結果にそれぞれ寄与することを示す。 このベースでトレーニングされた可読性分類子は、第二言語コーパスとしてギリシャ語の分類精度が88.16%に達する。 分類モデルの一般化性を検討するために、クロスコーパス評価も行います。 最も多様なテキストコレクション（学校の教科としてのギリシャ語のため）で訓練されたモデルが最も一般化していることを示しています。 ギリシャ語の可読性分析のための最新技術を進歩させることに加えて、本論文は、一般化可能な可読性分類のための異なる特徴セットの役割とトレーニングのセットアップについての洞察も提供する。', 'zh': '本文讨希腊语教科书为可读性类语复杂性。 析庠序之教科书语料库希腊语以为第二语言教科书,涵盖博学龄组熟练程度。 提算广者量化言语复杂性(词汇,形句法)。 子集实验之,明言语维度献正交息,维度有助于言者。 可读性类器于希腊语为第二语言语料库准确率为88.16%。 为分形之泛化性,行跨语料库之评。 明于最多样化之文本(希腊语为学校科目)训练之形最可概也。 除进希腊语可读性析最新术外,本文供特征集之用,及可泛化可读性分类之教设。', 'ru': 'В этой статье исследуется лингвистическая сложность греческих учебников как задача классификации читаемости. Мы анализируем учебники по различным школьным предметам и учебники по греческому как второму языку, охватывающие очень широкий спектр школьных возрастных групп и уровней владения. Извлекается и рассчитывается широкий спектр количественно определяемых лингвистических признаков сложности (лексических, морфологических и синтаксических). Проводя эксперименты с различными подмножествами признаков, мы показываем, что различные лингвистические измерения вносят вклад в ортогональную информацию, каждая из которых способствует достижению наивысшего результата с использованием всех подмножеств лингвистических признаков. Классификатор удобочитаемости, подготовленный на этой основе, достигает точности классификации 88,16% для греческого языка как второго языка. Чтобы исследовать обобщаемость классификационных моделей, мы также проводим межкорпусные оценки. Показано, что наилучшим образом обобщается модель, обученная на наиболее разнообразной текстовой подборке (для греческого как школьного предмета). В дополнение к продвижению современного уровня для анализа читабельности Греции, документ также вносит вклад в понимание роли различных наборов признаков и учебных установок для обобщаемой классификации читабельности.', 'hi': 'यह पेपर एक पठनीयता वर्गीकरण कार्य के रूप में ग्रीक पाठ्यपुस्तकों की भाषाई जटिलता की पड़ताल करता है। हम एक दूसरी भाषा के रूप में ग्रीक के लिए विभिन्न स्कूल विषयों और पाठ्यपुस्तकों के लिए पाठ्यपुस्तकों का विश्लेषण करते हैं, जो स्कूल आयु समूहों और प्रवीणता स्तरों के एक बहुत व्यापक स्पेक्ट्रम को कवर करते हैं। मात्रात्मक भाषाई जटिलता विशेषताओं (लेक्सिकल, रूपात्मक और वाक्यात्मक) की एक विस्तृत श्रृंखला निकाली और गणना की जाती है। विभिन्न विशेषता उपसमुच्चय के साथ प्रयोगों का संचालन करते हुए, हम दिखाते हैं कि विभिन्न भाषाई आयाम ऑर्थोगोनल जानकारी का योगदान करते हैं, प्रत्येक सभी भाषाई विशेषता सबसेट का उपयोग करके प्राप्त उच्चतम परिणाम की ओर योगदान देता है। इस आधार पर प्रशिक्षित एक पठनीयता क्लासिफायर दूसरी भाषा कॉर्पस के रूप में ग्रीक के लिए 88.16% की वर्गीकरण सटीकता तक पहुंचता है। वर्गीकरण मॉडल की सामान्यता की जांच करने के लिए, हम क्रॉस-कॉर्पस मूल्यांकन भी करते हैं। हम दिखाते हैं कि सबसे विविध पाठ संग्रह (एक स्कूल विषय के रूप में ग्रीक के लिए) पर प्रशिक्षित मॉडल सबसे अच्छा सामान्यीकृत करता है। ग्रीक पठनीयता विश्लेषण के लिए कला की स्थिति को आगे बढ़ाने के अलावा, पेपर सामान्य पठनीयता वर्गीकरण के लिए विभिन्न फीचर सेट और प्रशिक्षण सेटअप की भूमिका पर अंतर्दृष्टि भी योगदान देता है।', 'ga': 'Scrúdaíonn an páipéar seo castacht teanga na dtéacsleabhar Gréigise mar thasc aicmithe inléiteachta. Déanaimid anailís ar chorpas téacsleabhar d’ábhair scoile éagsúla agus ar théacsleabhair don Ghréigis mar Dhara Teanga, a chlúdaíonn speictream an-leathan d’aoisghrúpaí scoile agus leibhéil inniúlachta. Baintear amach agus ríomhtar raon leathan gnéithe inchainníochtaithe castachta teanga (foclóir, moirfeolaíoch agus comhréire). Agus turgnaimh á ndéanamh againn le fo-thacairí gnéithe éagsúla, léirímid go gcuireann na toisí teanga éagsúla le faisnéis orthogonal, gach ceann ag cur leis an toradh is airde a bhaintear amach ag baint úsáide as gach fo-thacar gnéithe teangeolaíocha. Sroicheann aicmitheoir inléiteachta atá oilte ar an mbonn seo cruinneas aicmithe 88.16% don chorpas Gréigis mar Dhara Teanga. Chun ginearálú na múnlaí aicmithe a fhiosrú, déanaimid meastóireachtaí traschorpais freisin. Léirímid gurb é an tsamhail atá oilte ar an mbailiúchán téacs is éagsúla (don Ghréigis mar ábhar scoile) is fearr a ghineann tú. Chomh maith leis an úrscothacht a chur chun cinn maidir le hanailís inléiteacht na Gréige, cuireann an páipéar léargais ar an ról atá ag gnéithe éagsúla agus socruithe oiliúna maidir le haicmiú inléiteachta ginearálaithe.', 'ka': 'ეს წიგნის ინგლისტიკური კომპლექსიტური კომპლექსიტურობა, როგორც კლასიფიკაციის კომპლექსიფიკაცია. ჩვენ განსხვავებული სკოლის სახელსაწყოთან და სკოლის სახელსაწყოთან გერიკის სახელსაწყოთან ანალიზაცით, როგორც მეორე ენაში, სკოლის ასეთი ჯგუფი და პროფიციენტის დონ კვანტიფიკაციური ლენგურისტიკური კომპლექტიკური ფუნქციების (ლექსიკალური, მოპოროლოგიური და სინტაქტიური) დიდი დირეგი ექსტრაქტირებულია და გამო ექსპერიმენტები განსხვავებული ფუნქციების სუბუნტებით გავაკეთებთ, რომ განსხვავებული ენგოგონისტიკური განზომილებები იმუშაობენ ორტოდონალური ინფორმაციას, ყოველთვის მიმართებენ კლასიფიკაციის კლასიფიკაცია, რომელიც ამ ბაზაზე განსწავლა კლასიფიკაცია 88.16%-ის კლასიფიკაციის წარმოდგენა, როგორც მეორე ენის კორპუსს. კლასიფიკაციის მოდელების გენერალიზაციის შესახებ, ჩვენ ასევე გავაკეთებთ კრესიკორპუსის განსაზღვრება. ჩვენ ჩვენ აჩვენებთ, რომ მოდელი ყველაზე განსხვავებული ტექსტის კოლექციაში (როგორც სკოლექტური სახელი) უკეთესი განსხვავებულია. დამატებით განსხვავებული განსხვავებების პროლის და განსხვავებული განსხვავებული კოლეფიკაციის განსხვავებული კოლეფიკაციის კოლეფიკაციისთვის ხელსაწყოთა სახელსაწყოთა ანალიზაციისთვის შესაძლებლო', 'it': "Questo articolo esplora la complessità linguistica dei libri di testo greci come compito di classificazione della leggibilità. Analizziamo corpora di testo per diverse materie scolastiche e libri di testo per il greco come seconda lingua, coprendo uno spettro molto ampio di gruppi di età scolastica e livelli di competenza. Vengono estratte e calcolate una vasta gamma di caratteristiche quantificabili di complessità linguistica (lessicale, morfologico e sintattico). Conducendo esperimenti con diversi sottoinsiemi di funzionalità, mostriamo che le diverse dimensioni linguistiche contribuiscono all'informazione ortogonale, contribuendo ciascuno al massimo risultato ottenuto utilizzando tutti i sottoinsiemi di funzionalità linguistiche. Un classificatore di leggibilità formato su questa base raggiunge una precisione di classificazione dell'88,16% per il corpo greco come seconda lingua. Per indagare la generalizzabilità dei modelli di classificazione, eseguiamo anche valutazioni cross-corpus. Mostriamo che il modello addestrato sulla più varia raccolta di testi (per il greco come materia scolastica) generalizza meglio. Oltre a promuovere lo stato dell'arte per l'analisi della leggibilità greca, il documento fornisce anche approfondimenti sul ruolo dei diversi set di funzionalità e delle impostazioni di formazione per la classificazione della leggibilità generalizzata.", 'el': 'Η παρούσα εργασία διερευνά την γλωσσική πολυπλοκότητα των ελληνικών βιβλίων ως καθήκον ταξινόμησης αναγνωσιμότητας. Αναλύουμε σώματα βιβλίων για διάφορα σχολικά θέματα και βιβλία για την Ελληνική ως Δεύτερη Γλώσσα, καλύπτοντας ένα πολύ ευρύ φάσμα σχολικών ηλικιακών ομάδων και επιπέδων επάρκειας. Ένα ευρύ φάσμα ποσοτικοποιήσιμων γλωσσικών χαρακτηριστικών πολυπλοκότητας (λεξικά, μορφολογικά και συντακτικά) εξάγεται και υπολογίζεται. Διεξάγοντας πειράματα με διαφορετικά υποσύνολα χαρακτηριστικών, δείχνουμε ότι οι διαφορετικές γλωσσικές διαστάσεις συνεισφέρουν ορθογώνιες πληροφορίες, συμβάλλοντας στο υψηλότερο αποτέλεσμα που επιτυγχάνεται χρησιμοποιώντας όλα τα υποσύνολα γλωσσικών χαρακτηριστικών. Ένας ταξινομητής αναγνωσιμότητας εκπαιδευμένος σε αυτή τη βάση επιτυγχάνει ακρίβεια ταξινόμησης 88.16% για το σώμα της Ελληνικής ως Δεύτερης Γλώσσας. Για τη διερεύνηση της γενικιμότητας των μοντέλων ταξινόμησης, διενεργούμε επίσης και διασταυρούμενες αξιολογήσεις. Δείχνουμε ότι το μοντέλο που εκπαιδεύεται στην πιο ποικίλη συλλογή κειμένων (για τα ελληνικά ως σχολικό αντικείμενο) γενικεύει καλύτερα. Εκτός από την προώθηση της κατάστασης της ελληνικής ανάλυσης αναγνωσιμότητας, η εργασία συμβάλλει επίσης στην κατανόηση του ρόλου των διαφορετικών συνόλων χαρακτηριστικών και των εκπαιδευτικών ρυθμίσεων για τη γενικευμένη ταξινόμηση της αναγνωσιμότητας.', 'lt': 'Šiame dokumente nagrinėjamas Graikijos vadovų kalbinis sudėtingumas kaip skaitomumo klasifikavimo užduotis. Analizuojame skirtingų mokyklų dalykų ir graikų kalbų mokyklų vadovų korporas kaip antroji kalba, apimančias labai platų mokyklų amžiaus grupių spektrą ir kvalifikacijos lygį. Ištraukiamos ir apskaičiuojamos įvairios kiekybiškai įvertinamos kalbos sudėtingumo savybės (leksinės, morfologinės ir sintaktinės). Atliekant eksperimentus su skirtingais požymiais, mes parodome, kad skirtingi kalbiniai aspektai prisideda prie ortogoninės informacijos, kiekviena prisideda prie didžiausio rezultato, pasiekto naudojant visus kalbinius požymius. A readability classifier trained on this basis reaches a classification accuracy of 88.16% for the Greek as a Second Language corpus.  To investigate the generalizability of the classification models, we also perform cross-corpus evaluations.  Mes parodome, kad modelis, parengtas įvairiausioje tekstų rinkinyje (graikų kalba kaip mokyklos dalykas), geriausiai apibendrina. Be pažangios Graikijos skaitomumo analizės pažangos, dokumente taip pat pateikiama informacija apie skirtingų charakteristikų rinkinių ir mokymo struktūrų vaidmenį plačiajai skaitomumo klasifikacijai.', 'hu': 'A tanulmány a görög tankönyvek nyelvi összetettségét vizsgálja, mint olvashatósági osztályozási feladatot. Elemezzük a különböző iskolai tantárgyak tankönyveit és a görög mint második nyelv tankönyveit, lefedve az iskolai korcsoportok és a jártassági szintek nagyon széles skáláját. Számos számszerűsíthető nyelvi komplexitási jellemzőt (lexikai, morfológiai és szintaktikai) vonunk ki és számítunk ki. Különböző jellemző részhalmazokkal végzett kísérletek során megmutatjuk, hogy a különböző nyelvi dimenziók hozzájárulnak az ortogonális információkhoz, amelyek mindegyike hozzájárul a legmagasabb eredményhez az összes nyelvi jellemző részhalmaz felhasználásával. Az ilyen alapon képzett olvashatósági osztályozó 88,16%-os osztályozási pontosságot ér el a görög mint másodnyelvű korpusz esetében. Az osztályozási modellek általánosíthatóságának vizsgálatára cross-corpus értékeléseket is végzünk. Megmutatjuk, hogy a legváltozatosabb szöveggyűjteményre (görög mint iskolai tantárgy) képzett modell általánosítja a legjobban. A görög olvashatósági elemzés technológiájának fejlesztése mellett a tanulmány betekintést nyújt a különböző jellemzők és képzési beállítások szerepére az általánosítható olvashatósági osztályozásban.', 'mk': 'Овој весник ја истражува јазичката комплексност на грчките учебници како задача за класификација на читливост. We analyze textbook corpora for different school subjects and textbooks for Greek as a Second Language, covering a very wide spectrum of school age groups and proficiency levels.  Широк опсег квантификувани јазички комплексни карактеристики (лексички, морфолошки и синтактички) се екстрактираат и пресметуваат. Со спроведување експерименти со различни подгрупи на карактеристики, покажуваме дека различните јазички димензии придонесуваат на ортогонски информации, секој придонесувајќи кон највисокиот резултат постигнат користејќи ги сите подгрупи на јазички карактеристики Класификаторот за читливост обучен на оваа основа достигнува класификациска точност од 88,16 отсто за Гркот како корпус на вториот јазик. За да ја испитаме генерализацијата на моделите за класификација, исто така изведуваме крстокорпусни проценки. Ние покажуваме дека моделот обучен на најразличната текстова колекција (за грчки како училишна тема) се генерализира најдобро. Покрај унапредувањето на техничката технологија за анализа на грчката читливост, весникот, исто така, придонесува и информации за улогата на различните набори карактеристики и обуки за генерализирана класификација на читливост.', 'ml': 'ഈ പത്രത്തില്\u200d ഗ്രീക്കിലെ പുസ്തകങ്ങളുടെ ഭാഷ്ടാരത്തിലെ സങ്കീര്\u200dണതയെ വായിക്കാവുവാന്\u200d സാധ്യതയുള്ള ക്ലാസ നമ്മള്\u200d വ്യത്യസ്ത്രീക വിഷയങ്ങള്\u200dക്കും ഗ്രീക്കിന്റെ പുസ്തകങ്ങള്\u200dക്കും വേര്\u200dതിരിക്കുന്ന പുസ്തകങ്ങള്\u200dക്കും പുസ്തകങ്ങള്\u200d വിശദീകരിക്കുന് ഒരു വിശാലമായ പരിഗണനപ്പെടുത്തുവാന്\u200d സാധിക്കുന്ന ഭാഷകങ്ങളുടെ (ലെക്സിക്കല്\u200d, മോര്\u200dഫോളജിക്കല്\u200d സിനിട്ടിക്ക്) പുറത്തെടു വ്യത്യസ്ത ഭാഷകങ്ങളുടെ പരീക്ഷണങ്ങള്\u200d നടത്തുന്ന പരീക്ഷണങ്ങള്\u200d, വ്യത്യസ്ത ഭാഷകങ്ങളുടെ ഭാഷകങ്ങള്\u200d വിവിധ വിവരങ്ങള്\u200dക്കുള്ള വിവരങ്ങള്\u200d ഓര്\u200dട്ടോഗോണ ഈ അടിസ്ഥാനത്ത് പഠിപ്പിക്കുന്ന ഒരു വായിക്കാവുന്ന ക്ലാസ്ഫിക്ഷന്\u200d 88. 16% ഗ്രീക്കിന് ഒരു രണ്ടാമത്തെ ഭാഷ കോര്\u200dപ്പുസ ക്ലാസ്ഫിക്കല്\u200d മോഡലുകളുടെ സാധാരണ പരിശോധിക്കാന്\u200d, നമ്മളും ക്രൂസ് കോര്\u200dപ്പുസിന്\u200dറെ വിലാസങ്ങള്\u200d പ്രവര്\u200dത്തി We show that the model trained on the most varied text collection (for Greek as a school subject) generalizes best.  ഗ്രീക്കിന് വായിക്കാവുന്നതിനുള്ള കലാകാര്യത്തിന്\u200dറെ സ്ഥിതി മുന്\u200dഗണന ചെയ്യുന്നതിന് കൂടാതെ, പേപ്പറും വ്യത്യസ്ത വിഭാഗങ്ങളുടെ പ്രഭാ', 'ms': 'Kertas ini mengeksplorasi kompleksiti bahasa buku teks Yunani sebagai tugas klasifikasi pembacaan. We analyze textbook corpora for different school subjects and textbooks for Greek as a Second Language, covering a very wide spectrum of school age groups and proficiency levels.  A broad range of quantifiable linguistic complexity features (lexical, morphological and syntactic) are extracted and calculated.  Conducting experiments with different feature subsets, we show that the different linguistic dimensions contribute orthogonal information, each contributing towards the highest result achieved using all linguistic feature subsets.  Klasifikasi pembacaan yang dilatih pada as as ini mencapai ketepatan klasifikasi 88.16% untuk Yunani sebagai korpus Bahasa Kedua. Untuk menyelidiki keseluruhan model klasifikasi, kami juga melakukan penilaian cross-corpus. Kami menunjukkan bahawa model yang dilatih pada koleksi teks yang paling beragam (untuk Yunani sebagai subjek sekolah) menyebarkan yang terbaik. Selain meningkatkan kemajuan seni untuk analisis pembacaan Yunani, kertas juga menyumbangkan pandangan mengenai peran set fitur yang berbeza dan tetapan latihan untuk klasifikasi pembacaan yang boleh diseluruhkan.', 'no': 'Denne papiret utforskar den lingviske kompleksiteten av greske tekstbøker som ei klassifikasjonsverktøy. Vi analyserer tekstbokkorpora for ulike skoleetema og tekstbok for gresk som ein andre språk, og dekker ein veldig stor spektrum av skoleegrupper og proficiencnivå. Name Å gjere eksperimenter med ulike funksjonsundergrupper, viser vi at dei ulike lingviske dimensjonane bidra til orthogonale informasjon, kvar som bidra til den høgste resultatet oppnådd med alle undergrupper for lingviske funksjonar. Eit klassifiserer for lesabilitet som treng på denne grunnen når ein klassifiserings- akkurat med 88,16% for gresk som eit andre språkkkorpus. For å undersøke generelliserbarheten av klassifikasjonsmodulane, utfører vi også kryskorpusevalueringar. Vi viser at modellen trent på den mest varierte tekstsamlinga (for gresk som skoleetema) genereliserer best. I tillegg til å forbedra kunstået for gresk lesabilitetsanalyse, bør papiret også bidra til innsyningar om rollen av ulike funksjonssett og oppsett for opplæring for generelt lesabilitetsklassifikasjon.', 'kk': 'Бұл қағаз грек мектептерінің лингвистикалық түрлігін оқуға мүмкіндік тапсырмасы ретінде іздейді. Біз әртүрлі мектепте суреттер мен оқыту кітаптарын грек тілінің екінші тілі ретінде анализ етіп, мектепте жастар топтардың және профессионалық деңгейінің көп бөлігін жасап жаты Көптеген лингвистикалық комплекс мүмкіндіктері (лексикалық, морфологикалық және синтактикалық) көптеген аумағы тарқатып есептеледі. Түрлі мүмкіндіктердің ішінде тәжірибелерін басқа түрлі лингвистикалық өлшемдері ортогоналық мәліметті көмектеседі. Әрбір лингвистикалық мүмкіндіктердің ішінде барлық ең жоғары нәти Бұл негізінде оқу мүмкіндікті классификациясы Грек үшін Екінші тіл корпус ретінде 88,16% деген классификациялық дұрыстығына жеткізеді. Кеңістік үлгілерінің жалпы байланыстығын зерттеу үшін біз көп корпус оқиғаларын де орындаймыз. Біз өзгертілген мәтін жинақтарында оқылған үлгі (мектеп тәсілі ретінде грек үшін) жалпы болады. Грек оқу мүмкіндігін анализиялау үшін суреттің күйін жақсартуға қосымша, қағаз сондай-ақ әдеттегі оқу мүмкіндіктерінің классификациясының түрлі қасиеттерінің және оқу баптауларының', 'ro': 'Această lucrare explorează complexitatea lingvistică a manualelor grecești ca o sarcină de clasificare a lizibilității. Analizăm corpuri de manuale pentru diferite discipline școlare și manuale pentru limba greacă ca a doua limbă, acoperind un spectru foarte larg de grupe de vârstă școlară și niveluri de competență. O gamă largă de caracteristici cuantificabile ale complexității lingvistice (lexicale, morfologice și sintactice) sunt extrase și calculate. Realizând experimente cu diferite subseturi de caracteristici, arătăm că diferitele dimensiuni lingvistice contribuie la informația ortogonală, fiecare contribuind la cel mai înalt rezultat obținut utilizând toate subseturile de caracteristici lingvistice. Un clasificator de lizibilitate instruit pe această bază atinge o acuratețe de clasificare de 88,16% pentru corpul limbii grecești ca a doua limbă. Pentru a investiga generalizarea modelelor de clasificare, efectuăm, de asemenea, evaluări cross-corpus. Aratăm că modelul instruit pe cea mai variată colecție de text (pentru greacă ca subiect școlar) generalizează cel mai bine. Pe lângă avansarea stadiului tehnologiei pentru analiza lizibilității grecești, lucrarea contribuie, de asemenea, la perspectiva rolului diferitelor seturi de caracteristici și setări de instruire pentru clasificarea lizibilității generalizabile.', 'mn': 'Энэ цаас Грекийн сургуулийн номын хэлний цогцыг уншиж чадах боломжтой хуваалцах үйлдлийг судалдаг. Бид өөр сургуулийн сургуулийн сурагчид болон хичээл номуудыг Грекийн Хоёрдугаар хэл болгон шинжилгээ хийж, сургуулийн насны бүлэг болон мэргэжлийн түвшинд маш өргөн хэмжээний хэмжээг харуулсан. Квантификацийн хэлний цогц чанар (лексик, морфологик, синтактик) олон нийтлэг хэлбэрийг татаж, тооцоолж байна. Өөр өөр төрлийн төрлийн хэмжээсүүдтэй туршилт хийх нь бид өөр хэлний хэмжээсүүд нь ортогонол мэдээллийг дэмжиж, хэлний төрлийн хэмжээсүүд бүр хамгийн өндөр үр дүнд нь бүх хэлний төрлийн хэмжээсүүд ашиглаж Үүнээс сургалтын унших чадварын хуваалцагч нь Грекийн хоёр хэл корпус болгон 88.16%-ын хуваалцааны тодорхойлолт хүртдэг. Дасгалын загварын ерөнхийлөгчийн чадварыг судалж, бид мөн гишүүн дүгнэлт хийдэг. Бид хамгийн олон төрлийн текст цуглуулалт дээр сургалтын загвар нь хамгийн сайн байдаг гэдгийг харуулж байна. Грекийн унших чадварын шинжилгээний урлагийн байдлыг дэвшүүлэхээс гадна цаас нь мөн өөр өөр чадваруудын төлөвлөгөө болон унших чадварын түвшинд сургалтын төлөвлөгөө дэвшүүлдэг.', 'sr': 'Ovaj papir istražuje jezičku kompleksnost grčkih udžbenika kao zadatak klasifikacije čitljivosti. Analiziramo školsku korporaciju za različite školske subjekte i školske knjige za grčki kao Drugi jezik, pokrivajući veoma širok spektr školskih grupa i nivoa kvaliteta. Široki raspon kvantificiranog jezičkog kompleksnosti (leksičke, morfološke i sintaktičke) se izvlači i izračunaju. Pokazujemo da različite lingvističke dimenzije doprinose ortogonalnim informacijama, svaki koji doprinosi na najveći rezultat koji je postignut koristeći sve subjekte lingvističkih karakteristika. Klasifikator za čitljivost obučen na ovoj osnovi postiže klasifikacijsku tačnost od 88,16% grčkog kao drugog jezičkog korpusa. Da bismo istražili generalizabilnost klasifikacijskih modela, izvršili smo i krstokorpusne procjene. Pokazujemo da je model obučen na najrazličitijoj kolekciji teksta (za grčku kao školsku temu) najbolji generalizuje. Osim napredovanja stanja umjetnosti za analizu grčke čitljivosti, novine takođe doprinose uvjetima o ulozi različitih setova karakteristika i setova obuke za generalizovanu klasifikaciju čitljivosti.', 'si': 'මේ පැත්තේ ග්\u200dරීක් පාසල් පොත්තුවන්ගේ භාෂාවික සංශ්\u200dයාත්මක විශ්වාස කරනවා කියලා අපි වෙනස් පාසලේ පාසල් පුද්ගලය සහ පාසල් පුද්ගලය විශ්ලේෂණය කරනවා ග්\u200dරීක් වල දෙවෙනි භාෂාවක් වගේ, පාසලේ වයස් කණ් Name වෙනස් භාෂාවික විශේෂතාවක් සමග පරීක්ෂණය සමග, අපි පෙන්වන්නේ වෙනස් භාෂාවික විශේෂතාවක් වර්ත්\u200dරාවික තොරතුරු සම්බන්ධ කියවන්න පුළුවන් විශේෂකයෙක් මේ විදිහට ප්\u200dරශ්නය කරලා තියෙන්නේ විශේෂණය 88.16% ග්\u200dරීකාව දෙවෙනි භාෂාව සාමාන්\u200dය විශේෂණ මොඩේල්ස් ගැන සාමාන්\u200dය විශ්වාස කරන්න, අපි ක්\u200dරිස්කෝපස් විශේෂණය කරනවා. අපි පෙන්වන්නේ හැම වෙනස් පැත්තක් සංග්රහනයේ ප්\u200dරධානය පුළුවන් මොඩල් හොඳයි කියලා. ග්\u200dරීක් කියවන්න පුළුවන් විශ්ලේෂණය සඳහා විශ්ලේෂණයේ ස්ථිතිය අධ්\u200dයානය කරලා තියෙන්නේ, පැත්තේ වෙනස් විශේෂතාවක් සහ', 'so': "Warqaddaas wuxuu ka baaraandegayaa compleximada luuqadda ee buugaagta Gariigka sida shaqada fasaxa kara. Waxaannu shirkadda buugaagta u baaraynaa maadooyinka iskuulka kala duduwan iyo buugaagta afka labaad ee Gariigka, kaas oo ku qoran kooxo da'da iskuulka iyo heerarka aqoonta. Waxaa la soo saaraa oo la xisaabiyaa faro badan oo luuqadaha adag (lexical, morphological and syntactic). Waxyaabaha ku baaraandegista kooxo kala duduwan, waxaynu muujinnaa in qaybaha luuqadaha kala duduwanu ay leeyihiin macluumaad ku saabsan, mid kastana wuxuu ku faa’iidaa ugu sarreeya dhamaantooda isticmaalka kooxo luqada oo dhan. Fasax kara oo lagu baranayo waxyaabaha fasaxa waxay gaadhaa 88.16% oo afka labaad ee Gariigga ah. To investigate the generalizability of the classification models, we also perform cross-corpus evaluations.  Waxan tusnaynaa in qaababka lagu tababariyey waxyaabaha aad u kala duduwan qoraalka (in Gariigka lagu barto maadooyinka iskuulka) uu si wanaagsan u sameeyo. Horumarinta xaalada farshaxanka loo qoro baaritaanka kara ee Gariigka waxaa sidoo kale warqaddu ka faa’iidaa waxyaabaha kala duduwan iyo kooxaha waxbarashada ee fasalka karashada.", 'pl': 'Niniejszy artykuł bada złożoność językową podręczników greckich jako zadanie klasyfikacji czytelności. Analizujemy korpusy podręczników dla różnych przedmiotów szkolnych oraz podręczniki języka greckiego jako drugiego, obejmujące bardzo szerokie spektrum szkolnych grup wiekowych i poziomów biegłości. Wydobywa się i oblicza szeroki zakres wymiernych cech złożoności językowej (leksykalnych, morfologicznych i składniowych). Przeprowadzając eksperymenty z różnymi podzbiorami cech, pokazujemy, że różne wymiary językowe wnoszą informacje ortogonalne, każdy przyczyniając się do najwyższego wyniku osiągniętego przy użyciu wszystkich podzbiorów cech językowych. Przeszkolony na tej podstawie klasyfikator czytelności osiąga dokładność klasyfikacji 88,16% dla korpusu języka greckiego jako drugiego. Aby zbadać uogólnienie modeli klasyfikacyjnych, przeprowadzamy również oceny międzykorpusowe. Pokazujemy, że model trenowany na najbardziej zróżnicowanym zbiorze tekstów (dla greckiego jako przedmiotu szkolnego) najlepiej uogólnia. Oprócz postępu w zakresie analizy czytelności greckiej, artykuł przedstawia również wnioski na temat roli różnych zestawów funkcji i konfiguracji szkoleń dla uogólnionej klasyfikacji czytelności.', 'sv': 'Denna uppsats undersﾃｶker den sprﾃ･kliga komplexiteten hos grekiska lﾃ､robﾃｶcker som en lﾃ､sbarhetsklassificeringsuppgift. Vi analyserar lﾃ､robokskorpor fﾃｶr olika skolﾃ､mnen och lﾃ､robﾃｶcker fﾃｶr grekiska som andrasprﾃ･k, som tﾃ､cker ett mycket brett spektrum av skolﾃ･ldersgrupper och kompetensnivﾃ･er. Ett brett spektrum av kvantifierbara sprﾃ･kliga komplexitetsegenskaper (lexikala, morfologiska och syntaktiska) extraheras och berﾃ､knas. Genom att genomfﾃｶra experiment med olika funktionsdelmﾃ､ngder visar vi att de olika sprﾃ･kliga dimensionerna bidrar med ortogonal information, var och en bidrar till det hﾃｶgsta resultat som uppnﾃ･tts med alla sprﾃ･kliga funktionsdelmﾃ､ngder. En lﾃ､sbarhetsklassificator utbildad pﾃ･ denna grund uppnﾃ･r en klassificeringsnoggrannhet pﾃ･ 88,16% fﾃｶr grekiska som andrasprﾃ･kskorpus. Fﾃｶr att undersﾃｶka generaliseringen av klassificeringsmodellerna utfﾃｶr vi ﾃ､ven tvﾃ､rkorpusutvﾃ､rderingar. Vi visar att modellen trﾃ､nad pﾃ･ den mest varierade textsamlingen (fﾃｶr grekiska som skolﾃ､mne) generaliserar bﾃ､st. Fﾃｶrutom att frﾃ､mja det senaste inom grekisk lﾃ､sbarhetsanalys bidrar uppsatsen ocksﾃ･ med insikter om rollen hos olika funktionsuppsﾃ､ttningar och utbildningsinstﾃ､llningar fﾃｶr generaliserad lﾃ､sbarhetsklassificering.', 'ta': 'இந்த தாள் கிரேக்கு புத்தகங்களின் மொழிய சிக்கல் சிக்கல்களை படிக்கக்கூடிய வகுப்பு பணியாக தேடுகிறது. நாம் வேறு பள்ளிக்கு பொருட்களுக்கான புத்தகக் குறிப்பையும் மற்றும் கிரீக்கு புத்தகங்களுக்கு இரண்டாவது மொழியாக, பள்ளிக்கு வயது க ஒரு விரிவான அளவாக்கக்கூடிய மொழி சிக்கல் குணங்கள் (லெக்சிக்சியல், morphological மற்றும் ஒத்திசைவு) பல்வேறு குணங்கள் குழுக்களுடன் இருந்து சோதனைகளை செய்யும் பொழுது நாம் காண்பிக்கிறோம் வேறு மொழிகளின் பரிமாணங்கள் குறுக்கோடு தகவல்களுக்க இந்த அடிப்படையில் பயிற்சி செய்யப்பட்ட படிப்பியல் வகுப்பாளர் 88. 16% கிரேக்கு ஒரு இரண்டாம் மொழி கார்புஸ் ஆகியவற்றின் வகுப் வகுப்பு வகுப்பு மாதிரிகளின் பொதுவான செயல்பாட்டை ஆய்வு செய்ய, நாம் குறுக்கோர்பாஸ் மதிப்புகளை செய் மிகவும் வேறுபட்ட உரைத் தொகுப்பில் பயிற்சி மாதிரி காட்டுகிறது (ஒரு பள்ளிக்காக கிரீக்கு பொருளாக) சிறந்த கிரீக்காவின் படிக்கக்கூடிய கலைப்பாட்டின் நிலையை மேம்படுத்துவதற்குக் கூட, காகிதத்திற்கும் வேறு பண்புகள் அமைப்புகளின் பொதுவான படி', 'mt': 'This paper explores the linguistic complexity of Greek textbooks as a readability classification task.  Aħna nianalizzaw il-korpra tal-ktieb tat-tagħlim għal suġġetti differenti tal-iskola u l-ktieb tat-tagħlim għall-Grieg bħala t-Tieni Lingwa, li jkopru spettru wiesa’ ħafna ta’ gruppi ta’ età tal-iskola u livelli ta’ profiċjenza. Jiġu estratti u kkalkulati firxa wiesgħa ta’ karatteristiċi kwantifikabbli ta’ kumplessità lingwistika (lexical, morphological and syntactic). It-twettiq ta’ esperimenti b’sottosettijiet ta’ karatteristiċi differenti juri li d-dimensjonijiet lingwistiċi differenti jikkontribwixxu għal informazzjoni ortogonali, kull wieħed jikkontribwixxi lejn l-ogħla riżultat miksub bl-użu tas-sottosettijiet kollha ta’ karatteristiċi lingwistiċi. Klassifikatur tal-leġibbiltà mħarreġ fuq din il-bażi jilħaq preċiżjoni tal-klassifikazzjoni ta’ 88.16% għall-Grieg bħala korpus tat-Tieni Lingwa. To investigate the generalizability of the classification models, we also perform cross-corpus evaluations.  Aħna nuru li l-mudell imħarreġ fuq il-ġbir tat-testi l-aktar varjat (għall-Grieg bħala suġġett tal-iskola) jiġġeneralizza l-a ħjar. Minbarra l-avvanz tal-aħħar avvanz għall-analiżi tal-leġibbiltà Griega, id-dokument jikkontribwixxi wkoll għal għarfien dwar ir-rwol ta’ settijiet differenti ta’ karatteristiċi u strutturi ta’ taħriġ għall-klassifikazzjoni ġeneralizzabbli tal-leġibbiltà.', 'ur': 'یہ کاغذ یونانی پڑھنے والی کتابوں کی زبان کی پیچیدگی کو ایک پڑھنے کے قابل تحریک کے کام کے طور پر تحقیق کرتا ہے. ہم ایک دوسری زبان کے لئے مختلف اسکول کے موضوع اور پڑھنے والی کتاب کے لئے تدریس کتاب کورپورا کو تحقیق کرتے ہیں، اسکول کی عمر گروہوں اور پڑھنے والی سطح کے بہت وسیع طرح پر پورے کرتے ہیں. ایک گھاٹی سینٹریس زبان کی پیچیدگی ویژگی (لکسیکل, مورفولوژیک اور سینٹکتیک) کی گھاٹی سینٹریس اٹھائی جاتی ہے اور شمار کی جاتی ہے۔ مختلف فرصت کے سپٹوں کے ساتھ آزمائش کرنا، ہم دکھاتے ہیں کہ مختلف زبان کی آزمائش اورٹوگونال معلومات کے ساتھ مدد کرتی ہیں، ہر ایک نے سب زبان کی فرصت سپٹوں کے مطابق سب سے بالاترین نتیجے کی مدد کی ہے. اس بنیاد پر آموزش کی پڑھنے والی کلیسٹر یونان کے لئے 88.16% کی قسمت کی دقیق پہنچتی ہے۔ کلاسیفوں کے نمڈلوں کی عمومی قابلیت کی تحقیق کرنے کے لئے ہم بھی کرس کورپوس کی ارزیابی کریں گے۔ ہم دکھاتے ہیں کہ مدل بہترین مختلف ٹیکسٹ کالکتر پر آموزش کی جاتی ہے یونانی پڑھنے کے قابل تحقیقات کے لئے هنر کی موقعیت کو اضافہ کرنے کے علاوہ یہ کاغذ بھی مختلف فائدے سٹ اور تربیت سٹاؤں کے رول کے بارے میں مشورہ کرتا ہے۔', 'uz': "Bu qogʻoz yunoning ingliz tilining murakkablarini o'qib boʻlishi vazifasi deb o'rganadi. Biz har xil maktablar uchun kitob kompaniyalarini o'rganish uchun kitoblar va kitoblarni ikkinchi tili sifatida o'anadi, bu maktab yoshli guruhlari va taxminan darajada juda katta tashkilotni qaraydi. Koʻpaytiriladigan tillar murakkablik xossalari (leksikal, morfologik va syntactik) kengaytiriladi va hisoblanadi. Ko'pchilik tugmalar birikmasi bilan boshqa imtiyozlar bilan boshqa tillardan foydalanish imtiyozlarini ko'rsatishimiz mumkin. Har bir necha lingʻlik imkoniyatlarni hamma tillar imkoniyatlarni ishlatish uchun eng eng yuqori natijaga qoʻllashadi. A readability classifier trained on this basis reaches a classification accuracy of 88.16% for the Greek as a Second Language corpus.  Grafiklash modellarining umumiy aniqlarini qidirish uchun, biz cross-corpus qiymatlarini bajaramiz. Biz bu modelni ko'rsatganimiz, ko'pchilik har hil matn toʻplami (maktab muammosida Greek uchun) eng yaxshi narsa yaratadi. Yunonchaga o'qib boʻladigan sananing holatini taʼminlashni koʻpaytirishdan ham qoʻllash qoʻllanmagan har xil xususiyatlarning xususiyatlarini va ta'lim moslamalarini umumiy oʻqib boʻladigan darajalashga ega.", 'vi': 'Tờ giấy này phân tích về sự phức tạp ngôn ngữ của sách giáo khoa Hy Lạp như một nhiệm vụ phân tích dễ đọc. Chúng tôi phân tích chuyên gia giáo khoa cho các môn học khác nhau và sách giáo khoa cho Hy Lạp như một ngôn ngữ thứ hai, bao gồm cả một phổ biến các nhóm tuổi học và trình độ. Một loạt các tính năng phức tạp ngôn ngữ được định lượng rộng (từ ngữ, morphology và sync) được chiết xuất và tính toán. Tiếp tục thí nghiệm với các nhóm đặc trưng khác nhau, chúng tôi cho thấy các chiều hướng ngôn ngữ khác nhau cung cấp thông tin về khoa học, mỗi chiều hướng tới kết quả cao nhất đạt được nhờ vào tất cả các nhóm đặc trưng ngôn ngữ. Một người phân loại dễ đọc được đào tạo trên cơ sở này đạt độ chính xác phân loại của 88.16=.* cho người Hy Lạp là một tập thể thứ hai. Để nghiên cứu tính tổng thể của các mô hình phân loại, chúng tôi cũng thực hiện đánh giá siêu thể. Chúng tôi cho thấy mẫu được đào tạo trong bộ sưu tập văn bản đa dạng nhất (cho người Hy Lạp làm trường) tổng hợp tốt nhất. Ngoài việc phát triển trạng thái nghệ thuật cho phân tích dễ đọc của người Hy Lạp, nó cũng cung cấp cho anh hiểu về vai trò của các bộ cài đặt đặc trưng khác nhau và cấu hình huấn luyện để phân loại dễ đọc rộng rãi.', 'hr': 'Ovaj papir istražuje jezičku kompleksnost grčkih učionika kao zadatak klasifikacije čitljivosti. Analiziramo školsku korporaciju za različite školske subjekte i školske knjige za grčki kao Drugi jezik, pokrivajući veoma širok spektr školskih dobitnih grupa i razine profila. Široki raspon kvantificiranog jezičkog kompleksnosti (leksičke, morfološke i sintaktičke) se izvlači i izračunaju. Pokazujemo da različite jezičke dimenzije doprinose ortogonalnim informacijama, svaki koji doprinosi na najviši rezultat koji se postigne koristeći sve subjekte jezičke funkcije. Klasifikator za čitljivost obučen na temelju ovog osnova ostvario je klasifikacijsku preciznost od 88,16% grčkog kao drugog jezičkog korpusa. Da bismo istražili generalizabilnost klasifikacijskih modela, izvršili smo i prekorporacije. Pokazujemo da je model obučen na najrazličitijoj kolekciji teksta (za grčku kao školsku temu) najbolji generaliziran. Osim napredovanja stanja umjetnosti za analizu grčke čitljivosti, papir također doprinosi uvjetima o ulozi različitih setova karakteristika i nastavaka obuke za generaliziranu klasifikaciju čitljivosti.', 'nl': 'Dit artikel onderzoekt de linguïstische complexiteit van Griekse leerboeken als een leesbaarheidsclassificatietaak. We analyseren tekstboekcorpora voor verschillende schoolvakken en tekstboeken voor Grieks als tweede taal, die een zeer breed spectrum van schoolleeftijdsgroepen en vaardigheidsniveaus bestrijken. Er wordt een breed scala aan kwantificeerbare linguïstische complexiteitskenmerken (lexicaal, morfologisch en syntactisch) geëxtraheerd en berekend. Door experimenten uit te voeren met verschillende kenmerksubsets, laten we zien dat de verschillende linguïstische dimensies orthogonale informatie bijdragen, elk bijdragen aan het hoogste resultaat dat bereikt wordt met behulp van alle linguïstische kenmerksubsets. Een leesbaarheidsclassificator die op deze basis is getraind, bereikt een classificatienauwkeurigheid van 88,16% voor het Grieks als tweede taal corpus. Om de generaliseerbaarheid van de classificatiemodellen te onderzoeken, voeren we ook corpuscross-corpus evaluaties uit. We laten zien dat het model getraind op de meest uiteenlopende tekstverzameling (voor Grieks als schoolvak) het best generaliseert. Naast het verbeteren van de stand van de techniek voor Griekse leesbaarheidsanalyse, draagt het artikel ook inzichten bij over de rol van verschillende feature sets en trainingsopstellingen voor algemene leesbaarheidsclassificatie.', 'bg': 'Настоящата статия изследва езиковата сложност на гръцките учебници като задача за класификация на четливостта. Анализираме корпоративни учебници за различни учебни предмети и учебници за гръцки като втори език, обхващащи много широк спектър от училищни възрастови групи и нива на владеене. Извличат се и изчисляват широк спектър от количествено измерими лингвистични сложности (лексикални, морфологични и синтактични). Провеждайки експерименти с различни функционални подгрупи, ние показваме, че различните лингвистични измерения допринасят за ортогонална информация, като всяка допринася за най-високия резултат, постигнат чрез всички лингвистични функционални подгрупи. Класификатор за четливост, обучен на тази основа, достига класификационна точност от 88,16% за гръцкия като втори език корпус. За да изследваме обобщаваемостта на класификационните модели, извършваме и кръстосани корпусни оценки. Показваме, че моделът, обучен по най-разнообразната текстова колекция (за гръцки като училищен предмет), обобщава най-добре. В допълнение към напредъка на съвременните технологии в гръцкия анализ на четливостта, статията допринася и за ролята на различните набор от функции и обучителни настройки за обобщена класификация на четливостта.', 'da': 'Denne artikel undersøger den sproglige kompleksitet af græske lærebøger som en læsbarhedsklassificeringsopgave. Vi analyserer lærebøger corpora til forskellige skolefag og lærebøger til græsk som andet sprog, der dækker et meget bredt spektrum af skolealdersgrupper og færdighedsniveauer. En lang række kvantificerbare sproglige kompleksitetstræk (leksikale, morfologiske og syntaktiske) udvindes og beregnes. Ved at udføre eksperimenter med forskellige funktionsmængder viser vi, at de forskellige sproglige dimensioner bidrager med ortogonal information, som hver bidrager til det højeste resultat opnået ved hjælp af alle sproglige funktionsmængder. En læsbarhedsklassificator uddannet på dette grundlag opnår en klassificeringsnøjagtighed på 88,16% for græsk som et andet sprog korpus. For at undersøge generaliseringen af klassifikationsmodellerne udfører vi også cross-corpus evalueringer. Vi viser, at modellen trænet på den mest varierede tekstsamling (for græsk som skolefag) generaliserer bedst. Ud over at fremme den nyeste teknologi inden for græsk læsbarhedsanalyse bidrager artiklen også med indsigt i rollen af forskellige funktionssæt og træningsopsætninger for generaliseret læsbarhedsklassificering.', 'ko': '본고는 그리스 교과서의 언어 복잡성을 탐구하여 가독성 분류 임무로 삼았다.우리는 서로 다른 학교 과목의 교과서 어료고와 그리스어를 제2의 언어로 하는 교과서를 분석해 광범위한 학교 연령대와 숙련도를 포괄했다.대량의 가량화된 언어 복잡성 특징(어휘, 형태와 문법)을 추출하고 계산했다.서로 다른 특징 서브집합에 대한 실험을 통해 우리는 서로 다른 언어 차원이 정교한 정보를 기여하고 각 차원마다 모든 언어 특징 서브집합을 사용하여 가장 높은 결과를 얻는 데 도움이 된다는 것을 발견했다.이를 바탕으로 훈련된 가독성 분류기는 그리스어를 제2의 언어 자료 라이브러리로 분류하는 정확도가 88.16% 에 달한다.분류 모델의 통용성을 연구하기 위해 우리는 크로스 어료 라이브러리 평가도 실시했다.우리는 가장 풍부한 텍스트 집합 (그리스어는 학교 과목으로서) 에서 훈련하는 모델이 가장 잘 요약되었다고 밝혔다.그리스어 가독성 분석의 최신 진전을 추진하는 동시에 본고는 서로 다른 특징집과 훈련 설정이 가독성 분류에 있어서의 역할에 대해 견해를 제시했다.', 'de': 'Dieser Beitrag untersucht die sprachliche Komplexität griechischer Lehrbücher als Aufgabe der Lesbarkeitsklassifikation. Wir analysieren Lehrbuchkorpora für verschiedene Schulfächer und Lehrbücher für Griechisch als Zweitsprache, die ein sehr breites Spektrum von Schulaltersgruppen und Leistungsstufen abdecken. Ein breites Spektrum quantifizierbarer linguistischer Komplexitätsmerkmale (lexikalisch, morphologisch und syntaktisch) wird extrahiert und berechnet. Durch Experimente mit verschiedenen Merkmalssubsätzen zeigen wir, dass die verschiedenen linguistischen Dimensionen orthogonale Informationen beisteuern, die jeweils zum höchsten Ergebnis beitragen, das mit allen linguistischen Merkmalssubsätzen erzielt wird. Ein auf dieser Basis trainierter Lesbarkeitsklassifikator erreicht eine Klassifikationsgenauigkeit von 88,16% für das Griechisch als Zweitsprachenkorpus. Um die Generalisierbarkeit der Klassifikationsmodelle zu untersuchen, führen wir auch korpusübergreifende Auswertungen durch. Wir zeigen, dass das Modell, das auf die unterschiedlichsten Textsammlungen (für Griechisch als Schulfach) trainiert wurde, am besten verallgemeinert. Neben der Weiterentwicklung des Standes der griechischen Lesbarkeitsanalyse liefert der Beitrag auch Einblicke in die Rolle verschiedener Feature-Sets und Trainings-Setups für die generalisierbare Lesbarkeitsklassifizierung.', 'id': 'Kertas ini mengeksplorasi kompleksitas bahasa buku teks Yunani sebagai tugas klasifikasi pembacaan. Kami menganalisis buku belajar corpora untuk subjek sekolah berbeda dan buku belajar untuk Yunani sebagai bahasa kedua, menutupi spektrum yang sangat luas dari kelompok usia sekolah dan tingkat kemampuan. Sebuah jangkauan luas dari ciri-ciri kompleksitas bahasa yang dapat dikwantifikasi (lexik, morfologi dan sintaksi) dikekstraksi dan dihitung. Menjalankan eksperimen dengan subset karakteristik yang berbeda, kami menunjukkan bahwa dimensi bahasa berbeda berkontribusi informasi ortogonal, masing-masing berkontribusi ke hasil tertinggi yang mencapai menggunakan semua subset karakteristik bahasa. Klasifikasi pembacaan yang dilatih pada dasar ini mencapai akurasi klasifikasi 88,16% untuk Yunani sebagai korpus bahasa kedua. Untuk menyelidiki generalisasi model klasifikasi, kami juga melakukan evaluasi cross-corpus. Kami menunjukkan bahwa model yang dilatih pada koleksi teks yang paling beragam (untuk Yunani sebagai subjek sekolah) generalisasi terbaik. Selain meningkatkan state of the art untuk analisis pembacaan Yunani, kertas juga berkontribusikan pengetahuan tentang peran dari set fitur berbeda dan setup latihan untuk klasifikasi pembacaan yang bisa diseluruhkan.', 'sw': 'Gazeti hili linagundua utata wa lugha wa vitabu vya Kigiriki kama kazi ya uandishi wa kusoma. Tunafahamu makampuni ya vitabu kwa ajili ya mada tofauti za shule na vitabu vya Kigiriki kama lugha ya pili, tunaelezea maelezo mengi ya makundi ya umri wa shule na kiwango cha ujuzi. Mpango mkubwa wa utata wa lugha zinazohitajika (lexico, morphological and syntactic) unatolewa na umehisiwa. Vijaribu vya kutengeneza vigogo tofauti, tunaonyesha kuwa tofauti za lugha zinachangia taarifa za upasuaji, kila mmoja anachangia kwenye matokeo ya juu yaliyofanikiwa kwa kutumia vigogo vyote vya lugha. Mfanuzi wa kusoma aliyefundishwa kwa msingi huu unafikia uhakika wa kutangaza asilimia 88.16 kwa Kigiriki kama makampuni ya pili ya lugha. Ili kuchunguza umuhimu wa mifano ya usambazaji, pia tunafanya tafiti za mabadiliko. Tunaonyesha kuwa mtindo wa mafunzo katika mkusanyiko wa maandishi tofauti zaidi (kwa Kigiriki kama mada ya shule) unatengeneza vizuri zaidi. Zaidi ya kukuza hali ya sanaa kwa uchambuzi wa uwezekano wa kusoma nchini Ugiriki, gazeti hilo pia linachangia maoni kuhusu jukumu la vigogo tofauti na vikosi vya mafunzo kwa ajili ya kutangazwa kwa uwezekano wa kusoma.', 'tr': 'Bu kagyz Ýunanyň okuw kitaplarynyň lingwistiki karmaşıklygyny okaýan täblisasy hökmünde gözleýär. Biz okuw kitabyny dürli mekdepler we okuw kitaplary üçin Ýunanyň ikinji dili hökmünde analyzýarys, mekdepler ýa şyndaky toparlaryň we ukyplaryň derejesini örän geniş bir spektrumy. Birnäçe ölçüli lingwistiki karmaşıklyglyklar (leksik, morfologik we sintaktik) hatlary çykylýar we hasaplanýar. Farklı özellikler bilen deneyler çykmak üçin, farklı dil üýtgewleri orthogonal maglumaty kömekleyär, her biri dil üýtgewleri bilen ýene gelen iň ýokary netijede kömekleyär. Ýunança 2-nji dil korpus üçin okamak üçin bilim taýýarlançysyny şu sebäpli bilim taýýarlandyrýar. Klasifikat nusgalarynyň döredilik ukyplaryny barlamak üçin biz çyzyp-corpus çözümlerni hem etýäris. Biz iň çeşitli metin koleksiýasynda bilinmeli nusganyň iň gowydygyny görkeýäris. Ýunança okaylýanlyk analyzasynda sungatyň durumyny bejermek üçin, kagyzyň hem üýtgeşik okaylýanlyk klasifikasy üçin düzümleri we düzümleri barada üns berýär.', 'af': "Hierdie papier ondersoek die lingwisiese kompleksiteit van Griekse teksbokke as 'n leesbaardige klasifikasie taak. Ons analyseer teksbok korpora vir verskillende skoolonderwerpe en teksbokke vir Grieks as 'n Tweede Taal, wat 'n baie wyde spektrum van skoolgroepe en profiesiteitsniveaue oordek. Name Die uitvoer van eksperimente met verskillende funksie subartikels, wys ons dat die verskillende lingwisiese dimensies orthogonale inligting bydra, elkeen bydra tot die hoogste resultaat wat bereik word deur alle lingwisiese funksie subartikels. 'n Leesbehaardige klassifiseerder op hierdie basis bereik 'n klassifiseerde presies van 88.16% vir die Griek as 'n Tweede Taal Korpus. Om die generaliserbaardigheid van die klasifikasie modele te ondersoek, doen ons ook kruiskorpus evaluasies. Ons wys dat die model opgelei op die mees verskillende teks versameling (vir Grieks as 'n skool onderwerp) beste genereer. In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different feature sets and training setups for general readability classification.", 'sq': 'Kjo letër eksploron kompleksitetin gjuhësor të librave grekë si një detyrë klasifikimi i lexueshmërisë. Ne analizojmë korprën e librit mësues për subjekte të ndryshme shkollore dhe libra mësuese për greqisht si gjuhë e dytë, duke mbuluar një spektrum shumë të gjerë të grupeve të moshës shkollore dhe nivelet e aftësisë. Një gamë e gjerë e karakteristikave të kuantifikueshme të kompleksitetit gjuhësor (lexike, morfologjike dhe sintaktike) nxirren dhe llogariten. Duke kryer eksperimente me nëngrupe të ndryshme karakteristike, ne tregojmë se dimensionet e ndryshme gjuhësore kontribuojnë informacion ortogonal, secili kontribuon drejt rezultatit më të lartë të arritur duke përdorur të gjitha nëngrupet e karakteristikave gjuhësore. Një klasifikues i lexueshmërisë i trajnuar në këtë bazë arrin një saktësi klasifikimi prej 88.16% për greqin si një korpus gjuhës së dytë. Për të hetuar gjeneralizueshmërinë e modeleve klasifikuese, ne gjithashtu bëjmë vlerësime ndër-korpus. Ne tregojmë se modeli i trajnuar në koleksionin më të ndryshëm të tekstit (për greqin si një subjekt shkollor) gjeneralizon më mirë. Përveç përparimit të gjendjes së teknologjisë për analizën e lexueshmërisë greke, gazeta kontribuon gjithashtu me kuptime mbi rolin e grupeve të ndryshme të karakteristikave dhe strukturave të trajnimit për klasifikimin e gjeneralizueshëm të lexueshmërisë.', 'am': 'ይህ ገጽ የግሪክ መጻሕፍት የቋንቋዊ ድካምነትን ለመቀበል ትክክል ማድረግ ነው፡፡ የልዩ ትምህርት ደብዳቤዎች እና የግሪክ መጻሕፍት የሁለተኛ ቋንቋ እና የትምህርት ዕድሜ ዕድሜ ክፍል እናስተምር፡፡ ሰፊ የቋንቋ ቋንቋዎች አካውንሲካዊ (lexical, morphological እና Syntactic) ጥያቄ እና የተቆጠሩ ነው፡፡ በተለየ የቋንቋው አካባቢዎች በተለየው ፈተናዎች፣ ልዩ ቋንቋዎች እውቀቶች የፖርቶጎናዊ መረጃዎችን እንዲያሳዩ እናሳየዋለን፡፡ በዚህም መሠረት የተጠቃሚ ትምህርት የሚያስተምር የግሪክ ቋንቋ ቁርጭት 88.16 በመቶ የሚያደርገው ክፍል ነው፡፡ የክፍለ ሥርዓት ምሳሌዎችን ለመመርመርመር፣ የቆርፓስ መስመር እናደርጋለን፡፡ የተለየ የጽሑፍ ጉዳይ (ለግሪክና ለትምህርት ጉዳይ) የተጠቃሚ ሞዴል መሆኑን እናሳያቸዋለን፡፡ የግሪክ አርእስት አካባቢ ትምህርት ማተሚያ ላይ አካባቢ እና የግሪክ አርእስት ግንኙነትን ከመጠቀም በቀር፣ ደብዳቤው በተለየ ልዩ ምርጫዎች ማሰናከል እና ለመጠቀም ለቻይነት ለማስተካከል የሚያስፈልገውን አስተያየት ይጠቅማል፡፡', 'hy': 'Այս աշխատանքը ուսումնասիրում է հունաստանի դասագրքերի լեզվաբանական բարդությունը որպես կարդալի դասակարգման խնդիր: Մենք վերլուծում ենք տարբեր դպրոցական թեմաների դասագիրքը և հունասենի դասագիրքը որպես երկրորդ լեզու, որը ներառում է դպրոցական տարիքային խմբերի շատ լայն սպեկտր և մասնագիտության մակարդակներ: Լեզվաբանական բարդությունը բազմաթիվ հատկություններ (լեքսիկական, մորֆոլոգիական և սինտակտիկ) վերցնում են և հաշվարկում: Փորձեր կատարելով տարբեր հատկանիշների ենթախմբերով, մենք ցույց ենք տալիս, որ տարբեր լեզվաբանական չափությունները ներդրում են օրթոգոնալ տեղեկատվություն, յուրաքանչյուրը ներդրում է ամենաբարձր արդյունքի վրա, որը հասել է բոլոր լեզվաբանական հատկանիշների Այս հիմքում ուսուցանված կարդալիության դասակարգիչը հասնում է հունասենի 88.16 տոկոսի ճշգրիտությանը որպես երկրորդ լեզու կորպուս: Որպեսզի ուսումնասիրենք դասակարգման մոդելների ընդհանուր հասանելիությունը, մենք նաև կատարում ենք միջօրգանական գնահատումներ: Մենք ցույց ենք տալիս, որ ամենատարբեր տեքստի հավաքածուի մոդելը (հունասենի համար որպես դպրոցական թեմա) լավագույնն է ընդհանրացնում: Հունաստանի կարդալիության վերլուծության տեխնոլոգիայի առաջընթացը զարգացնելու համար թղթին նաև ներդրում է բացահայտումներ տարբեր հատկանիշների խաղի և ընդհանուր կարդալիորման ուսումնասիրության կառուցվածքների մասին:', 'az': 'Bu kağıt Yunan öyrənmək kitablarının dil kompleksitəsini oxuyabiləcək qiyməti olaraq keşfetir. Biz öyrəndiyimiz kitab korporasını müxtəlif məktəb məsələləri və öyrəndiyimiz kitabları Yunan üçün ikinci dil olaraq analiz edirik, məktəb qocalarının çox geniş spektrumu və təhsil səviyyələrini örtürük. Qıymetli dil kompleksitəsi (leksik, morfolojik və sintaktik) geniş səviyyəsi çıxarılır və hesablanır. Müxtəlif fərqli fərqli dəyişiklik dəyişiklikləri ilə müxtəlif təcrübələr təşkil edir, hər bir dil fərqli dəyişiklik dəyişiklik dəyişiklikləri ilə ən yüksək nəticəsinə kömək edir. Bu təqdirdə təhsil edilən oxuyabilən klasifikatçı Yunanlılar üçün ikinci dil korpusu olaraq 88.16% dəyişdirir. Klasifikasyon modellərin generalizasizliklərini incitmək üçün, biz də çox korpus değerlendirmələrini təqdim edirik. Biz ən müxtəlif mətn koleksiyonundan təhsil edilmiş modellərin ən yaxşısını göstəririk. Yunan oxuyabiləcəyi analizi üçün sanatın durumunu daha da art ırmaq üçün belə, kağıt həmçinin fərqli təhsil qurğularının və təhsil qurğularının ünvanlı oxuyabiləcəyi klasifikasyonu üçün müxtəlif təhsil qurğularının rolünü daxil edir.', 'bn': 'এই পত্রিকা গ্রীক টেক্সবইয়ের ভাষাগত জটিল বিষয়টি পড়তে পারে ক্লাস্ফিকেশনের কাজ হিসেবে খুঁজে বের করে। আমরা বিভিন্ন স্কুল বিষয়ক এবং গ্রীকের জন্য টেক্সবুক হিসেবে বিশ্লেষণ করি বিভিন্ন বিষয়বস্তুর জন্য বিশ্লেষণ করি, দ্বিতীয় ভাষা হিসেবে, স্কু ব্যাপক পরিমাণ ভাষার জটিল বৈশিষ্ট্যের বৈশিষ্ট্য (লেক্সিক্যাল, মরোফোলিক্যাল এবং সিন্টেক্টিক) ব্যবহার করা হয়েছে এবং হিসাব বিভিন্ন বৈশিষ্ট্য বিভিন্ন ভাষার বিভিন্ন ভাষার বিভিন্ন ভাষায় তথ্য প্রদান করে, প্রত্যেকেই ভাষাগত বৈশিষ্ট্যের বিভিন্ন তথ্য প্রদান করে,  এই ভিত্তিতে প্রশিক্ষক প্রশিক্ষিত এক শ্রেণীবিভাষাকে ৮৮. ১৬% গ্রীকের দ্বিতীয় ভাষা কোর্পাস হিসেবে পৌঁছায়। ক্লাস্ফিকেশন মডেলের সাধারণ পরীক্ষা করার জন্য আমরা ক্রাস কোর্পাসের মূল্য চালাই। আমরা দেখাচ্ছি যে মডেল সবচেয়ে বিভিন্ন ভিন্ন টেক্সট সংগ্রহের (গ্রীকের স্কুল বিষয় হিসেবে গ্রীকের জন্য) সাধা গ্রীকের পাঠকত্ব বিশ্লেষণের জন্য শিল্পের অবস্থা উন্নত করার পরিবর্তে এই কাগজটি বিভিন্ন বৈশিষ্ট্যের ভূমিকা এবং প্রশিক্ষণের বিভিন্ন প্রশিক্ষণ', 'fa': 'این کاغذ پیچیدگی زبان\u200cشناسی کتاب\u200cهای درس یونانی را به عنوان وظیفه\u200cای که قابل خواندن است تحقیق می\u200cکند. ما شرکت کتاب آموزشی را برای موضوع های مدرسه و کتاب های آموزشی مختلف برای یونان به عنوان زبان دوم تحلیل می کنیم، که یک جسم بسیار وسیع از گروه های سن مدرسه و سطح دانشگاهی را پوشش می دهد. یک مجموعه گسترده از ویژه\u200cهای پیچیدگی زبان\u200cشناسی (زبان\u200cشناسی، مورفولوژیک و سنتاکتیک) خارج و محاسبه می\u200cشوند. آزمایشات با زیر ویژه\u200cهای مختلف، نشان می\u200cدهیم که اندازه\u200cهای زبان\u200cشناسی متفاوت اطلاعات orthogonal را تولید می\u200cکنند، هر یک به بهترین نتیجه\u200cای که با استفاده از تمام زیر ویژه\u200cهای زبان\u200cشناسی موفق شده است. یک گروهی که بر اساس این پایه آموزش داده می\u200cشود، دقیقات گروهی 88.16% برای یونان به عنوان یک گروهی دوم زبان می\u200cرسد. برای تحقیق قابلیت ژنرال مدل\u200cهای مختصات، ما هم تحقیقات\u200cهای مختلف کورپوس را انجام می\u200cدهیم. ما نشان می دهیم که مدل آموزش یافته\u200cترین مجموعه متن (برای یونانی به عنوان یک موضوع مدرسه) بهترین ترکیب می\u200cکند. در اضافه به پیشرفت وضعیت هنر برای تحلیل خواندنی یونانی، کاغذ همچنین مشاهده\u200cها در نقش مجموعه\u200cهای ویژه\u200cهای مختلف و تنظیم آموزشی برای گروهی قابل خواندن قابل توجه می\u200cکند.', 'et': 'Käesolev töö uurib kreeka õpikute keelelist keerukust kui loetavuse klassifitseerimise ülesannet. Analüüsime erinevate õppeainete õpikute korpuseid ja kreeka keele kui teise keele õpikuid, mis hõlmavad väga laia spektri kooliealiste ja oskuste tasemeid. Ekstrateeritakse ja arvutatakse lai valik kvantifitseeritavaid keelelise keerukuse tunnuseid (leksikaalsed, morfoloogilised ja süntaktilised). Teostades katseid erinevate funktsioonide alamkogumitega, näitame, et erinevad keelelised mõõtmed annavad ortogonaalset informatsiooni, igaüks aitab kaasa kõigi keeleliste funktsioonide alamkogumite abil saavutatud kõrgeima tulemuse saavutamisele. Sellel alusel koolitatud loetavuse klassifitseerija saavutab kreeka kui teise keele korpuse klassifitseerimistäpsuse 88,16%. Klassifikatsioonimudelite üldistatavuse uurimiseks teostame ka korpusevahelisi hindamisi. Näitame, et kõige mitmekesisema tekstikogu (kreeka kui kooli õppeaine) koolitatud mudel üldistab kõige paremini. Lisaks Kreeka loetavuse analüüsi tehnika arendamisele annab töö ka ülevaate erinevate funktsioonikomplektide ja koolitussüsteemide rollist üldiste loetavuse klassifitseerimisel.', 'bs': 'Ovaj papir istražuje jezičku kompleksnost grčkih učionika kao zadatak klasifikacije čitljivosti. Analiziramo školsku korporaciju za različite školske subjekte i školske knjige za grčki kao Drugi jezik, pokrivajući veoma širok spektr školskih grupa i razine profila. Široki opseg kvantificiranog jezičkog kompleksnosti (leksičke, morfološke i sintaktičke) se izvlače i izračunaju. Pokazujemo da različite lingvističke dimenzije doprinose ortogonalnim informacijama, svaki koji doprinosi na najveći rezultat koji se postigne koristeći sve subjekte lingvističkih karakteristika. Klasifikator za čitljivost obučen na ovoj osnovi ostvario je klasifikacijsku preciznost od 88,16% grčkog kao drugog jezičkog korpusa. Da bismo istražili generalizabilnost klasifikacijskih modela, izvršili smo i prekorpusne procjene. Pokazujemo da je model obučen na najrazličitijoj kolekciji teksta (za grčku kao školsku temu) najbolji generalizuje. Osim napredovanja stanja umjetnosti za analizu grčke čitljivosti, novine također doprinose uvjetima o ulozi različitih setova karakteristika i setova obuke za generalizovanu klasifikaciju čitljivosti.', 'fi': 'Tässä artikkelissa tarkastellaan kreikkalaisten oppikirjojen kielellistä monimutkaisuutta luettavuuden luokittelutehtävänä. Analysoimme oppikirjojen korpusia eri oppiaineille ja kreikan oppikirjoja toisena kielenä, jotka kattavat hyvin laajan kirjon kouluikäisiä ryhmiä ja osaamistasoja. Laaditaan ja lasketaan laaja joukko määrällisiä kielellisiä monimutkaisuuspiirteitä (lexikaaliset, morfologiset ja syntaktiset). Tehdessämme kokeita eri ominaisuuksien alaryhmien kanssa osoitamme, että eri kielelliset ulottuvuudet antavat ortogonaalista tietoa, kukin myötävaikuttaa suurimpaan tulokseen, joka saavutetaan käyttämällä kaikkia kielellisiä ominaisuuksia alaryhmiä. Tältä pohjalta koulutettu luettavuuden luokittelija saavuttaa 88,16 prosentin luokitustarkkuuden kreikan toisena kielenä -korpusessa. Luokitusmallien yleistettävyyden selvittämiseksi suoritamme myös korpusenvälisiä arviointeja. Osoitamme, että kaikkein monipuolisempaan tekstikokoelmaan koulutettu malli yleistää parhaiten. Kreikan luettavuusanalyysin edistyksen lisäksi artikkeli antaa myös tietoa erilaisten ominaisuuksien ja koulutusjärjestelmien roolista yleistettävissä olevan luettavuuden luokittelussa.', 'ca': "Aquest article explora la complexitat lingüística dels llibres de text grecs com a tasca de classificació de llegibilitat. Analitzem la corpora de llibres d'estudi per diferents subjectes escolars i llibres d'estudi per grec com a Segona Llingua, cobrint un gran espectre de grups d'edat escolar i nivells d'aptitud. Es extraeixen i calculen una gran varietat de característiques quantificables de complexitat lingüística (lèxica, morfològica i sinàctica). Realitzant experiments amb diferents subconjunts de característiques, demostram que les diferents dimensions lingüístices aporten informació ortogonal, cada una aportant al resultat més alt aconseguit fent servir tots els subconjunts de característiques lingüístices. Un classificador de llegibilitat entrenat en aquesta base arriba a una precisió de classificació del 88,16% per al grec com a corpus de segona llengua. Per investigar la generalització dels models de classificació, també fem evaluacions intercorporals. Mostrem que el model entrenat en la col·lecció de textos més variada (en grec com a tema escolar) es generalitza millor. A més d'avançar l'avançament de l'anàlisi de llegibilitat grega, el paper també contribueix a la comprensió del paper sobre el paper de diferents conjunts de característiques i configuracions de formació per a la classificació generalitzable de llegibilitat.", 'cs': 'Tento článek zkoumá jazykovou složitost řeckých učebnic jako úlohu klasifikace čitelnosti. Analyzujeme korpusy učebnic pro různé školní předměty a učebnice pro řečtinu jako druhý jazyk, pokrývající velmi široké spektrum školních věkových skupin a úrovní odbornosti. Je extrahována a vypočítána široká škála kvantifikovatelných jazykových složitostí (lexikální, morfologické a syntaktické). Provedením experimentů s různými podmnožinami funkcí ukazujeme, že různé lingvistické dimenze přispívají k ortogonálním informacím, z nichž každá přispívá k nejvyššímu výsledku dosaženému pomocí všech podmnožin lingvistických funkcí. Klasifikátor čitelnosti vyškolený na tomto základě dosahuje klasifikační přesnosti 88,16% pro korpus řečtiny jako druhého jazyka. Pro zkoumání zobecňovatelnosti klasifikačních modelů provádíme také crosskorpusová hodnocení. Ukazujeme, že model trénovaný na nejrůznější sbírce textů (pro řečtinu jako školní předmět) se nejlépe zobecňuje. Kromě pokroku v oblasti analýzy řecké čitelnosti, příspěvek také přináší poznatky o roli různých sad funkcí a nastavení školení pro všeobecnou klasifikaci čitelnosti.', 'jv': 'Gambar iki kelas nyong langkung karbote tindahan kanggo nyuggo bok ning grik kuwi ngupakan seneng nggawe barang seneng pisan. Awak dhéwé énglek perusahaan kelas texture kanggo sekolah-perusahaan karo paké sekolah lan kelas kuwi segala Pak dhéwé, nggawe barang langgar bantuan kelas kuwi mèh karo paké, lan sekolah-langgar kuwi kudu dhéwé. string" in "context_BAR_stringLink Awak dhéwé éntuk éntuk karo paketeng-perusahaan sampeyan karo paketeng langkung gak nggawe barang pengaturan ortoggonal Genjer-Genjer Rasané kapan kelas pangan anyar Awak dhéwé ngerasakno ngono model sing ngwangjelaké gak dhéwé ngerasakno cara-cara sing luwih dumadhiné Genjer-genjer langkung urip kanggo langkung urip kanggo kalagayan urip kanggo ngerasakno Panjenengan langkung urip kuwi tindakan nyong nggawe barang nggawe sistem sing kalagayet terus nggawe aturan tapi ora oleh nggawe winih sing paling apik dhéwé.', 'he': 'העיתון הזה חוקר את המורכבות השפתית של ספרי לימוד יוונים כמשימה קליזציה לקריאה. אנו מנתחים גופורה של ספר לימודים עבור נושאי בית ספר שונים וספרי לימודים ליוני כשפה שנייה, מכסה ספקטר רחב מאוד של קבוצות גיל בית ספר ורמות מומחיות. מגוון רחב של תכונות מורכבות לשוניות (לקסיות, מורפולוגיות וסינטקטיקות) מוצאים ומחשבות. לבצע ניסויים עם תחתיות תכונות שונות, אנו מראים שהמימדים השונים השונים תורמים מידע אורטוגוני, כל אחד תורם אל התוצאה הגבוהה ביותר שנשגה באמצעות כל תחתיות תכונות לשונות. מסגרת היכולת לקרוא מאומנת על בסיס זה מגיעה מדויקת מסגרת של 88.16% עבור היווני כגופוס לשפה שנייה. כדי לחקור את הגנרליזציה של דוגמני ההקלטה, אנחנו גם מבצעים ערכות קרובות. אנחנו מראים שהמודל מאומן על אוסף הטקסט המגווון ביותר (ביווני כנושא בית הספר) מגנרל הכי טוב. In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different feature sets and training setups for generalizable readability classification.', 'sk': 'Ta prispevek raziskuje jezikovno kompleksnost grških učbenikov kot nalogo razvrščanja berljivosti. Analiziramo korpuse učbenikov za različne šolske predmete in učbenike za grščino kot drugi jezik, ki zajemajo zelo širok spekter šolskih starostnih skupin in stopenj strokovnosti. Izvlečemo in izračunamo široko paleto kvantifikacijskih značilnosti jezikovne kompleksnosti (leksikalne, morfološke in sintaktične). Z eksperimenti z različnimi podmnožicami značilnosti smo pokazali, da različne jezikovne dimenzije prispevajo pravokotne informacije, vsaka pa prispeva k najvišjemu rezultatu, doseženemu z uporabo vseh podmnožic jezikovnih značilnosti. Klasifikator berljivosti, usposobljen na tej osnovi, doseže natančnost klasifikacije 88,16% za korpus grškega kot drugega jezika. Za raziskavo splošnosti klasifikacijskih modelov izvajamo tudi medkorpusne vrednotenje. Pokazali smo, da model, usposobljen za najbolj raznoliko zbirko besedil (za grščino kot šolski predmet), najbolje posplošuje. Poleg napredka na področju analize berljivosti v Grčiji prispeva tudi vpogled v vlogo različnih naborov funkcij in nastavitev usposabljanja za splošno razvrščanje berljivosti.', 'ha': "Wannan karatun yana fatan littattafan linguistic cikin littafin Kigiriki kamar wani aikin mai karatun karatun. Ana rarrabe littafin littafin makampuni na masu matsayin da littattafai na alƙaluman da aka rubũta littattafai na Garabci kamar lugha na ƙarami, yana rufe littattafani mai yawa na jama'a da iskomi da daraja na fasafi. Ana nuna da kuma ana ƙayyade wasu fassarai masu iya ƙayyade cikin linguistic da ke iya lissafa (leksi, morfological da syntactic). Ana nuna masu jarraba da jama'a-jama'a daban-daban, ko kuma muna nuna cewa, hanyõyi masu motsi na linguistic, ko kuma, kõwace yana ƙara zuwa mafi ƙaranci matsala da aka samar da su yi amfani da duk jama'a na fassarar linguistic. An sanar da wani mai karatun karatun karatun na karatun a kan wannan, yana zuwa wani tsari na fasalin daraja na 88.6% wa Kigirikin kamar wata Lugha na ƙarshe. To, domin yin ƙidãya ga misãlai na sifilafi, za'a sami karatun sarki-korbas. Tuna nũna cewa misalin an sanar da shi a cikin dukkan matsayin da aka ƙayyade (zuwa Garnish kamar masĩfa da iskooli) ya sami mafi kyaun. Babu ƙaranci halin sanar wa fassarar karatun karatun karatun karatun na alumci, karatun na ƙarfafa da gannai a kan rolin masu daidaita ko kuma tsarin tsarin mafarako wa fasalin karatun mai iya gabatar da karatun karatun.", 'bo': 'ཤོག ང་ཚོས་སློབ་གྲྭའི་ནང་དུ་ཡིག A broad range of quantifiable linguistic complexity features (lexical, morphological and syntactic) are extracted and calculated. Conducting experiments with different feature subsets, we show that the different linguistic dimensions contribute orthogonal information, each contributing towards the highest result achieved using all linguistic feature subsets. དཔེ་བསྐྲུན་བྱས་ཆོག་འཛིན་གྱི་འཛིན་བྱས་པ་ཞིག་གིས་སྐད་ཀྱི་དབྱེ་བ་གཉིས་པ་ཞིག་གིས་དབྱེ་བ་88.16%དང་། དབྱེ་རིམ་དཔེ་དབྱིབས་གྱི་སྤྱིར་བཏུབ་ཀྱི་ཆེད་དུ་ཞིབ་དཔྱད་བྱེད་དགོས་པ་ཡིན། ང་ཚོས་རྣམ་པ་གྲངས་སྒྲིག་མིག་ཡིག་གེ་ཆེས་སྤྲོ་སྣང་ཡོད་ཚད་མང་ཤོས་ཡོད་པ་ཤར་བྱས་ན། In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different features sets and training setups for generalizable readability classification.'}
{'en': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays E nglish-as-Foreign-Language Essays', 'ar': 'تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية', 'fr': 'Analyse De La Structure Argumentative En Anglais Langue Étrangère Essais', 'pt': 'Analisando a estrutura argumentativa em ensaios de inglês como língua estrangeira', 'es': 'Análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera', 'ja': '英語と外国語のエッセイにおける議論構造の解析', 'zh': '解析英语为外语论文证结', 'ru': 'Анализ аргументативной структуры в эссе на английском и иностранном языках', 'ga': 'Struchtúr Argóinteach a Pharsáil i mBéarla-mar-Earrach-Aistí', 'hi': 'पार्सिंग तर्कपूर्ण संरचना में अंग्रेजी के रूप में विदेशी भाषा निबंध', 'ka': 'აპდუმენტეტიური სტრუქტურაცია ანგლისური-as-Foreign-Language Essays', 'hu': 'Argumentatív struktúra értelmezése angol mint idegen nyelvű esszékben', 'el': 'Ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικής ως ξένης γλώσσας', 'it': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'kk': 'Аргументтік құрылғыны ағылшын тілінде талдау', 'lt': 'Argumentacinės struktūros analizavimas anglų kalbos testuose', 'mk': 'Аргументација на аргументативната структура во тестовите на англиски како странски јазик', 'ms': 'Menghurai Struktur Argumentatif dalam Ujian Bahasa Inggeris-sebagai-Luar-Bahasa', 'mt': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'ml': 'ഇംഗ്ലീഷ്- as- വിദേശ- ഭാഷ എസ്സില്\u200d അര്\u200dഗമെന്റിവ് സ്ട്രൂട്ടേറ്റ്', 'mn': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'no': 'Tolking av argumentativ struktur i engelsk-as-Foreign-Language Essays', 'pl': 'Analiza struktury argumentatywnej w esejach o języku angielskim jako obcym', 'sr': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'ro': 'Analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină', 'si': 'ප්\u200dරශ්ණාත්මක සංස්කරණය ඉංග්\u200dරීසිය-as-බාර්ජික-භාෂාවයේ ප්\u200dරශ්ණය', 'so': 'Barsashada jardiinada hagitaanka ku qoran Ingiriis-as-Foreign-language Essays', 'sv': 'Tolkning av argumentativ struktur i engelska-som-främmande-språk essäer', 'ta': 'ஆங்கிலம்- as- Foreign- Language Essays', 'ur': 'انگلیسی-as-Foreign-Language Essays میں آرگومنٹیٹ ساختاری پارسینگ', 'uz': 'Name', 'vi': 'Cấu trúc Argumentive in English-as-Foreign-Language Essays', 'bg': 'Разглеждане на аргументативната структура в английски-чуждоезикови есета', 'hr': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'nl': 'Analyse van argumentatieve structuur in essays over Engels als vreemde taal', 'da': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'de': 'Analyse der argumentativen Struktur in englischsprachigen Essays', 'id': 'Menganalisis Struktur Argumentatif dalam Ujian Bahasa Inggris-sebagai-Bahasa asing', 'ko': '영어 의논문 의논문 구조 해석', 'fa': 'تحلیل ساختار Argumentative in English-as-Foreign-Language Essays', 'sw': 'Mradi wa Kiingereza kwa lugha ya Kigeni na Kigeni Essa', 'tr': 'Argumentatik Structure in English-as-Foreign-Language Essays', 'af': 'Verwerking Argumentatiewe struktuur in Engels-as-Foreign-Language Essays', 'sq': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'hy': 'Արգեմենտատիվ կառուցվածքը վերլուծում անգլերեն-որպես-արտաքին-լեզվի թեսսերում', 'am': 'አርማኔት', 'az': 'İngilizce-as-Foreign-Language Essays olaraq Argumentative Structure analizə edilir', 'bn': 'ইংরেজি- as-পররাষ্ট্র ভাষায় আর্গুমেন্টিভ ক্ষেত্র পার্সিং করা হচ্ছে', 'ca': "Analitzar l'estructura argumentativa en els exàmens anglès-com-estranger", 'cs': 'Analýza argumentativní struktury v esejích angličtiny jako cizího jazyka', 'bs': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays', 'et': 'Argumentatiivse struktuuri parsimine inglise keelena võõrkeelsetes esseetes', 'fi': 'Argumentatiivisen rakenteen jäsentäminen englanninkielisissä esseissä', 'jv': 'Parasing argument structural in French-as-Remote-Language Associations', 'he': 'מעבדת מבנה מסכים במבחנים בשפה זרה אנגלית', 'ha': 'KCharselect unicode block name', 'sk': 'Razdelava argumentativne strukture v angleškem jeziku kot tujem jeziku', 'bo': 'Parsing Argumentative Structure in English-as-Foreign-Language Essays'}
{'en': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The  parsing process  consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each  task  independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts : original noisy EFL essays and those improved by annotators, then evaluate them on the original  essays . The experiment shows that an end-to-end in-domain system achieved an  accuracy  of.341. On the other hand, the cross-domain system achieved 94 % performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.', 'ar': 'تقدم هذه الورقة دراسة حول تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية (EFL) ، والتي هي بطبيعتها صاخبة. تتكون عملية التحليل من خطوتين ، ربط الجمل ذات الصلة ثم تصنيف العلاقات بينهما. نجرب العديد من بنيات التعلم العميق لمعالجة كل مهمة على حدة. في مهمة ربط الجملة ، كان أداء نموذج بيافيني هو الأفضل. في مهمة وضع العلامات على العلاقة ، كان أداء نموذج BERT الدقيق هو الأفضل. يتم استخدام جملتين من التشفير ، ولاحظنا أن النماذج غير الدقيقة كانت تؤدي بشكل عام أداءً أفضل عند استخدام Sentence-BERT بدلاً من مشفر BERT. قمنا بتدريب نماذجنا باستخدام نوعين من النصوص المتوازية: مقالات اللغة الإنجليزية كلغة أجنبية الصاخبة الأصلية وتلك التي تم تحسينها بواسطة المعلقين ، ثم قم بتقييمهم على المقالات الأصلية. تُظهر التجربة أن نظام النطاق الشامل قد حقق دقة 341. من ناحية أخرى ، حقق النظام عبر المجال أداء 94٪ للنظام داخل المجال. يشير هذا إلى أن النصوص المكتوبة جيدًا يمكن أن تكون مفيدة أيضًا في تدريب نظام التنقيب عن الحجج للنصوص المزعجة.', 'es': 'Este artículo presenta un estudio sobre el análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera (EFL), que son inherentemente ruidosos. El proceso de análisis consta de dos pasos, vincular oraciones relacionadas y luego etiquetar sus relaciones. Experimentamos con varias arquitecturas de aprendizaje profundo para abordar cada tarea de forma independiente. En la tarea de vinculación de oraciones, un modelo biafín obtuvo el mejor rendimiento. En la tarea de etiquetado de relaciones, un modelo BERT ajustado fue el que mejor funcionó. Se emplean codificadores de dos oraciones, y observamos que los modelos sin ajuste fino generalmente funcionan mejor cuando se usa el codificador Sentence-BERT en lugar del codificador BERT. Entrenamos nuestros modelos utilizando dos tipos de textos paralelos: ensayos originales de EFL ruidosos y aquellos mejorados por anotadores, y luego los evaluamos en los ensayos originales. El experimento muestra que un sistema de dominio de extremo a extremo logró una precisión de .341. Por otro lado, el sistema entre dominios logró un rendimiento del 94% del sistema dentro del dominio. Esto indica que los textos bien escritos también pueden ser útiles para entrenar el sistema de minería de argumentos para textos ruidosos.', 'fr': "Cet article présente une étude sur l'analyse de la structure argumentative dans les dissertations en anglais langue étrangère (EFL), qui sont intrinsèquement bruyantes. Le processus d'analyse se compose de deux étapes\xa0: relier les phrases associées et étiqueter leurs relations. Nous testons plusieurs architectures de deep learning pour traiter chaque tâche de manière indépendante. Dans la tâche de liaison de phrases, c'est un modèle biaffine qui a donné les meilleurs résultats. Dans la tâche d'étiquetage des relations, c'est un modèle BERT affiné qui a donné les meilleurs résultats. Deux encodeurs de phrases sont utilisés, et nous avons observé que les modèles sans réglage fin donnaient généralement de meilleurs résultats avec l'encodeur Sentence-BERT par opposition au codeur BERT. Nous avons formé nos modèles à l'aide de deux types de textes parallèles\xa0: les essais originaux bruités EFL et ceux améliorés par des annotateurs, puis nous les évaluons sur les dissertations originales. L'expérience montre qu'un système dans le domaine de bout en bout a atteint une précision de 0,341. D'autre part, le système inter-domaines a atteint 94\xa0% de performances du système dans le domaine. Cela indique que des textes bien écrits peuvent également être utiles pour entraîner le système d'exploration d'arguments pour les textes bruyants.", 'pt': 'Este artigo apresenta um estudo sobre a análise da estrutura argumentativa em ensaios de inglês como língua estrangeira (EFL), que são inerentemente barulhentos. O processo de análise sintática consiste em duas etapas, vinculando sentenças relacionadas e, em seguida, rotulando suas relações. Experimentamos várias arquiteturas de aprendizado profundo para abordar cada tarefa de forma independente. Na tarefa de ligação de frases, um modelo biafino teve o melhor desempenho. Na tarefa de rotulagem de relação, um modelo BERT ajustado teve o melhor desempenho. Dois codificadores de sentença são empregados e observamos que os modelos sem ajuste fino geralmente tiveram melhor desempenho ao usar o codificador Sentence-BERT em oposição ao codificador BERT. Treinamos nossos modelos usando dois tipos de textos paralelos: ensaios originais de EFL barulhentos e aqueles aprimorados por anotadores, então os avaliamos nos ensaios originais. O experimento mostra que um sistema no domínio de ponta a ponta alcançou uma precisão de 0,341. Por outro lado, o sistema cross-domain alcançou 94% de desempenho do sistema in-domain. Isso sinaliza que textos bem escritos também podem ser úteis para treinar o sistema de mineração de argumentos para textos ruidosos.', 'ja': '本稿では、本質的に騒がしい英語-外国語（ EFL ）エッセイにおける議論構造の構文解析に関する研究を紹介する。 構文解析プロセスは、関連する文をリンクし、それらの関係をラベル付けする2つのステップで構成されています。 私たちは、それぞれの課題に独立して対処するために、いくつかの深層学習アーキテクチャを実験しています。 文のリンクタスクでは、バイアフィンモデルが最高のパフォーマンスを発揮しました。 関係ラベリングタスクでは、微調整されたBERTモデルが最良のパフォーマンスを発揮しました。 ２つの文章エンコーダが採用されており、非微調整モデルは一般的に、ＢＥＲＴエンコーダとは対照的に、Ｓｅｎｔｅｎｃｅ － ＢＥＲＴを使用する場合により良いパフォーマンスを発揮することが観察された。 私たちは、オリジナルのノイズの多いEFLエッセイと、アノテーターによって改善されたものの2種類のパラレルテキストを使用してモデルをトレーニングし、オリジナルのエッセイで評価しました。 この実験では、エンドツーエンドのドメイン内システムが.341の精度を達成したことが示されています。 一方、クロスドメインシステムは、インドメインシステムの94 ％のパフォーマンスを達成しました。 これは、よく書かれたテキストが、ノイズの多いテキストのための引数マイニングシステムをトレーニングするのにも役立つことを示しています。', 'zh': '本文引解析英语为外语(EFL)论证结构,其质嘈杂。 解析两步驿,链接关句,然后志之。 尝试数深学架构以自立也。 句链接事,字母模形为上。 在於事,微BERT为最。 用二句编码器,吾观之,比于BERT编码器,用句BERT时,非调形常善也。 吾以两体并行本教我模样:原始嘈杂EFL论文及由注者改进论文,然后于原始论文上对其评估。 实验者,端到端域内之0.341精也。 其一,跨域统成域94%之性也。 此明文本亦可用于训练嘈杂文本者参数掘而系之。', 'ru': 'В данной работе представлено исследование по анализу аргументативной структуры в эссе на английском языке как иностранном (EFL), которые по своей сути являются шумными. Процесс синтаксического анализа состоит из двух этапов, соединяющих соответствующие предложения, а затем обозначающих их отношения. Мы экспериментируем с несколькими архитектурами глубокого обучения, чтобы решать каждую задачу самостоятельно. В задаче связывания предложений модель биаффина показала лучшие результаты. В задаче маркировки отношений лучше всего работала тонко настроенная модель BERT. Используются два кодера предложений, и мы заметили, что модели без точной настройки, как правило, работают лучше при использовании Sentence-BERT в отличие от кодера BERT. Мы обучали наши модели, используя два типа параллельных текстов: оригинальные шумные эссе EFL и улучшенные аннотаторами, а затем оценивали их по оригинальным эссе. Эксперимент показывает, что сквозная внутридоменная система достигла точности .341. С другой стороны, междоменная система достигла 94% производительности внутридоменной системы. Это сигнализирует о том, что хорошо написанные тексты также могут быть полезны для обучения системы майнинга аргументов для шумных текстов.', 'hi': 'यह पेपर अंग्रेजी-विदेशी-भाषा (ईएफएल) निबंधों में तर्कसंगत संरचना को पार्स करने पर एक अध्ययन प्रस्तुत करता है, जो स्वाभाविक रूप से शोर कर रहे हैं। पार्सिंग प्रक्रिया में दो चरण होते हैं, संबंधित वाक्यों को जोड़ना और फिर उनके संबंधों को लेबल करना। हम स्वतंत्र रूप से प्रत्येक कार्य को संबोधित करने के लिए कई गहरे सीखने के आर्किटेक्चर के साथ प्रयोग करते हैं। वाक्य जोड़ने के कार्य में, एक biaffine मॉडल ने सबसे अच्छा प्रदर्शन किया। संबंध लेबलिंग कार्य में, एक ठीक-ठाक BERT मॉडल ने सबसे अच्छा प्रदर्शन किया। दो वाक्य एनकोडर नियोजित हैं, और हमने देखा कि गैर-ठीक-ट्यूनिंग मॉडल ने आमतौर पर BERT एन्कोडर के विपरीत वाक्य-BERT का उपयोग करते समय बेहतर प्रदर्शन किया। हमने दो प्रकार के समानांतर ग्रंथों का उपयोग करके अपने मॉडल को प्रशिक्षित किया: मूल शोर ईएफएल निबंध और एनोटेटर द्वारा सुधार किए गए, फिर मूल निबंधों पर उनका मूल्यांकन करें। प्रयोग से पता चलता है कि एक एंड-टू-एंड इन-डोमेन सिस्टम ने .341 की सटीकता हासिल की। दूसरी ओर, क्रॉस-डोमेन सिस्टम ने इन-डोमेन सिस्टम का 94% प्रदर्शन हासिल किया। यह संकेत देता है कि अच्छी तरह से लिखे गए ग्रंथों को शोर ग्रंथों के लिए तर्क खनन प्रणाली को प्रशिक्षित करने के लिए भी उपयोगी हो सकता है।', 'ga': "Cuireann an páipéar seo i láthair staidéar ar an struchtúr argóinteach in aistí Béarla mar theanga iasachta (EFL) a pharsáil, atá fuaimiúil go bunúsach. Tá dhá chéim sa phróiseas parsála, ag nascadh abairtí gaolmhara agus ansin ag lipéadú a gcaidreamh. Bainimid triail as roinnt ailtireachtaí domhainfhoghlama chun tabhairt faoi gach tasc go neamhspleách. Sa tasc nascadh abairtí, samhail biaifín ab fhearr. Maidir leis an tasc maidir le lipéadú an choibhneasa, múnla BERT mionchoigeartaithe ab fhearr. Fostaítear dhá ionchódóir pianbhreithe, agus thugamar faoi deara gur éirigh níos fearr le samhlacha neamh-mhionchoigeartaithe go ginearálta nuair a bhí Pianbhreithe-BERT in úsáid seachas ionchódóir CRET. Chuireamar oiliúint ar ár múnlaí ag baint úsáide as dhá chineál téacs comhthreomhar: bun-aistí torannacha EFL agus iad siúd a d'fheabhsaigh anótálaithe, ansin déan iad a mheas ar na bun-aistí. Léiríonn an turgnamh gur bhain córas in-fhearainn ceann go ceann amach cruinneas .341. Ar an láimh eile, bhain an córas tras-fearainn feidhmíocht 94% den chóras in-fearainn amach. Léiríonn sé seo gur féidir le téacsanna dea-scríofa a bheith úsáideach freisin chun córas mianadóireachta argóintí a oiliúint le haghaidh téacsanna callánacha.", 'hu': 'Ez a tanulmány bemutatja az angol mint idegen nyelvű (EFL) esszék argumentációs struktúrájának elemzését, amelyek eredendően zajosak. Az elemzési folyamat két lépésből áll, összekapcsolja a kapcsolódó mondatokat, majd megjelöli a kapcsolataikat. Számos mélytanulási architektúrával kísérletezünk, hogy minden feladatot önállóan kezeljük. A mondatkötési feladatban a biaffine modell teljesítette a legjobbat. A kapcsolatcímkézési feladat során egy finomhangolt BERT modell teljesített a legjobban. Két mondatkódolót alkalmazunk, és megfigyeltük, hogy a nem finomhangoló modellek általában jobban teljesítenek a Sentence-BERT használatával szemben a BERT kódolóval. Modelljeinket kétféle párhuzamos szövegből készítettük: eredeti zajos EFL esszék és kommentátorok által fejlesztett esszék segítségével, majd értékeltük őket az eredeti esszékben. A kísérlet azt mutatja, hogy egy teljes körű domain rendszer .341 pontosságot ért el. Másrészről a cross-domain rendszer 94%-os teljesítményt ért el az in-domain rendszer. Ez azt jelzi, hogy a jól megírt szövegek hasznosak lehetnek a zajos szövegek argumentumbányászati rendszerének kiképzéséhez.', 'el': 'Η παρούσα εργασία παρουσιάζει μια μελέτη για την ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικά-ως-ξένης γλώσσας (EFL), τα οποία είναι εγγενώς θορυβώδη. Η διαδικασία ανάλυσης αποτελείται από δύο βήματα, που συνδέουν σχετικές προτάσεις και στη συνέχεια επισημαίνουν τις σχέσεις τους. Πειραματιζόμαστε με διάφορες αρχιτεκτονικές βαθιάς μάθησης για να αντιμετωπίσουμε κάθε εργασία ανεξάρτητα. Στην εργασία σύνδεσης της πρότασης, ένα μοντέλο διφίνης πέτυχε το καλύτερο. Στην εργασία επισήμανσης σχέσης, ένα εκλεπτυσμένο μοντέλο πέτυχε καλύτερα. Χρησιμοποιούνται δύο κωδικοποιητές προτάσεων και παρατηρήσαμε ότι τα μοντέλα μη συντονισμού γενικά αποδίδουν καλύτερα όταν χρησιμοποιούν πρόταση-BERT σε αντίθεση με τον κωδικοποιητή BERT. Εκπαιδευτήκαμε τα μοντέλα μας χρησιμοποιώντας δύο τύπους παράλληλων κειμένων: πρωτότυπα θορυβώδη δοκίμια και αυτά που βελτιώθηκαν από σχολιαστές και μετά τα αξιολογήσαμε στα πρωτότυπα δοκίμια. Το πείραμα δείχνει ότι ένα ολοκληρωμένο σύστημα στον τομέα πέτυχε ακρίβεια .341. Από την άλλη πλευρά, το σύστημα μεταξύ τομέων πέτυχε 94% απόδοση του συστήματος εντός τομέα. Αυτό σηματοδοτεί ότι τα καλά γραπτά κείμενα μπορούν επίσης να είναι χρήσιμα για την εκπαίδευση του συστήματος εξόρυξης επιχειρημάτων για θορυβώδη κείμενα.', 'ka': 'ეს დოკუმენტი აჩვენებს აპრინტიგური სტრუქტურის პარასუზაციის შესახებ ინგლისური ენის (EFL) ესესიში, რომლებიც არსებობით ბუნდა. პროცესი განაწერების შეფარდება ორი ნაწილის შეფარდება, შემდეგ შეფარდებული სიტყვების დაკავშირება და შემდეგ მათი შესახებ. ჩვენ ექსპერიმენტირებით რამდენიმე ძალიან სწავლის აქტიქტიკურებით, რომელიც ყოველ რაოდენობას განცემულად გადავუწყ ბიფინის მოდელეში ყველაზე უკეთესი მონაცემები გავაკეთეთ. შესაბამისი მარტიკის დავალებაში, BERT მოდელის შესაბამისი შესაბამისი შესაბამისი შესაბამისი მოდელია. ორი სიტყვების კოდერები მომხმარებულია, და ჩვენ დავხედავთ, რომ არაფერი კოდერების მოდელები უფრო უფრო მუშაობენ, როდესაც გამოყენება ბერტი კოდერების განმავლობაში. ჩვენ ჩვენი მოდელების შესწავლით ორი ტიპის პარალელი ტექსტის გამოყენებით: ორიგინალური ფუნქციური EFL ესეები და ისინი, რომლებიც ანტოტოტორიების შესაძლებელება, შემდეგ დავამუშავ ექსპერიმენტი ჩვენებს, რომ საკუთარი დასრულებული დომინის სისტემა დასრულებულია.341. მეორე მხოლოდ, კრესომინის სისტემა 94% მოქმედება დომინის სისტემას. ეს სიგნალეები, რომლებიც ძალიან წერტილი ტექსტი შეუძლია იყოს საჭირო სისტემის მინდომის სისტემის შესაბამისთვის.', 'it': "Questo articolo presenta uno studio sull'analisi della struttura argomentativa nei saggi inglese come lingua straniera (EFL), che sono intrinsecamente rumorosi. Il processo di analisi consiste in due fasi, collegando frasi correlate e poi etichettando le loro relazioni. Sperimentiamo diverse architetture di deep learning per affrontare ogni compito in modo indipendente. Nell'attività di collegamento delle frasi, un modello biaffine ha eseguito il meglio. Nel compito di etichettatura delle relazioni, un modello BERT perfezionato ha dato il meglio. Vengono impiegati due encoder di frase e abbiamo osservato che i modelli non-fine-tuning generalmente hanno prestazioni migliori quando si utilizza Sentence-BERT rispetto all'encoder BERT. Abbiamo formato i nostri modelli utilizzando due tipi di testi paralleli: saggi EFL originali rumorosi e quelli migliorati dagli annotatori, per poi valutarli sui saggi originali. L'esperimento mostra che un sistema end-to-end in-domain ha raggiunto una precisione di .341. D'altra parte, il sistema cross-domain ha raggiunto il 94% delle prestazioni del sistema in-domain. Questo indica che i testi ben scritti possono anche essere utili per addestrare il sistema di estrazione di argomenti per i testi rumorosi.", 'lt': 'Šiame dokumente pateikiamas tyrimas dėl argumentacinės struktūros analizavimo anglų-kaip-užsienio kalbos (EFL) egzaminuose, kurie iš esmės yra triukšmingi. The parsing process consists of two steps, linking related sentences and then labelling their relations.  Eksperimentuojame su keliomis gilaus mokymosi architektūromis, kad kiekviena užduotis būtų sprendžiama nepriklausomai. Kalbant apie užduotį, susijusią su sakiniu, biffino modelis atliko geriausią rezultatą. In the relation labelling task, a fine-tuned BERT model performed the best.  Naudojami du sakiniai koduojantys kodai ir pastebėjome, kad nereguliuojantys modeliai paprastai geriau veikia naudojant sentence-BERT, o ne BERT koduojantį kodą. Mokėjome savo modelius naudojant dviejų rūšių lygiagrečius tekstus: originalius triukšmingus EFL esejus ir tuos, kuriuos patobulino anotatoriai, tada juos vertiname pagal originalius esejus. Eksperimentas rodo, kad iš vienos srities į kitą sistema pasiekė .341 tikslumą. Kita vertus, tarpdomeninė sistema pasiekė 94 % domeninės sistemos veiklos rezultatų. Tai rodo, kad gerai rašyti tekstai taip pat gali būti naudingi argument ų gavybos sistemai apmokyti triukšmingiems tekstams.', 'kk': 'Бұл қағаз ағылшын тілі (EFL) ретінде аргументациялық құрылғыны талдау туралы зерттеулерді көрсетеді. Бұл аргументалдық құрылғылар әдетте дыбыс болып тұрады. Бұл талдау процесі екі қадам болып, сілтемелерді сілтемелеу және оның қатынасын жарлықтау. Біз әрбір тапсырманы тәуелді өзгерту үшін бірнеше түсінік оқыту архитектураларымен тәжірибедік. Тапсырманы сілтемелеу үшін биафин үлгісі ең жақсы орындалды. Қатысушылық жарлықтау тапсырмасында BERT үлгісін жақсы орындады. Екі сөз кодері жұмыс істейді. Біз BERT кодеріне қарсы сөз- BERT кодеріне қарсы жақсы орындалатын үлгілер үлгілерін көрдік. Біз үлгілерімізді екі түрлі параллель мәтінді қолдануға үйрендік: бастапқы дыбыс EFL ессейлері және жаңартушылары жасалды, содан кейін оларды бастапқы ессейлерде оқу. Тәжірибе домендегі соңындағы соңындағы жүйе .341 деген дұрыстығын жеткізді. Біріншіден, домен жүйесінің 94% жылдамдығын жеткізді. Бұл мәтіндердің жақсы жазылған сигналдары, сондай-ақ, дыбыс мәтіндер үшін аргументтің бағыттау жүйесін оқыту үшін пайдалы болады.', 'ml': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  പാര്\u200dസിംഗ് പ്രക്രിയയില്\u200d രണ്ടു പടികള്\u200d ഉണ്ട്, ബന്ധപ്പെട്ട വാക്കുകള്\u200d ബന്ധപ്പെടുത്തുന്നു, പിന്നെ അവരുടെ ബന എല്ലാ ജോലിയെയും സ്വാതന്ത്ര്യമായി സംസാരിക്കാന്\u200d ആഴമുള്ള പഠിക്കുന്ന ആര്\u200dക്കിട്ടുകള്\u200d കൊണ് വാക്കില്\u200d ബന്ധപ്പെടുത്തുന്ന ജോലിയില്\u200d ഒരു ബിഫിന്\u200d മോഡല്\u200d ഏറ്റവും നല്ലത് പ്രവര്\u200dത്തിച്ചു. ബന്ധപ്പെടുത്തുന്ന ജോലിയില്\u200d, നല്ലൊരു ബെര്\u200dട്ടി മോഡല്\u200d ഏറ്റവും നല്ലത് പ്രവര്\u200dത്തിച്ചു. രണ്ട് വാക്കുകളുടെ കോഡോര്\u200dഡുകള്\u200d ഉപയോഗിച്ചിരിക്കുന്നു, ബെര്\u200dട്ടി കോഡോര്\u200dഡിനെതിരെ ഉപയോഗിക്കുമ്പോള്\u200d സെന്\u200dസ്-ബെര്\u200dട്ടി ഉപയോ നമ്മുടെ മോഡലുകള്\u200d രണ്ടു തരം പാരാലില്\u200d ടെക്സ്റ്റുകള്\u200d ഉപയോഗിച്ച് ഞങ്ങള്\u200d പരിശീലിപ്പിച്ചു: ആദ്യമായ യെഎഫ്എല്\u200d ലേസ്സുകള്\u200d ഉയര്\u200dത്തുന്നതും അ പരീക്ഷണം കാണിച്ചുകൊണ്ടിരിക്കുന്നത് ഡൊമെയിന്\u200d സിസ്റ്റത്തിന്റെ അവസാനത്തിലേക്ക് അവസാനിക്കുന്നതാ മറുവശത്ത്, ക്രിസ്റ്റ് ഡൊമെയിന്\u200d സിസ്റ്റം 94% പ്രവര്\u200dത്തിപ്പിച്ചു. നല്ല എഴുതിയ ടെക്സ്റ്റുകള്\u200d ശബ്ദമുള്ള വാക്കുകള്\u200dക്ക് വേണ്ടി ആര്\u200dഗ്യുമിനിങ്ങ് മൈനിങ്ങ് സിസ്റ്റം പരി', 'ms': 'Kertas ini memperkenalkan kajian mengenai hurai struktur argumensif dalam esei bahasa Inggeris-sebagai-asing (EFL), yang secara nyata bunyi. Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat berkaitan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arkitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam perkataan yang menghubungkan tugas, model biaffin melakukan yang terbaik. Dalam tugas penandaan hubungan, model BERT ditetapkan yang terbaik dilakukan. Dua pengekod kalimat digunakan, dan kami memperhatikan bahawa model bukan-penyesuaian biasanya dilakukan lebih baik bila menggunakan pengekod kalimat-BERT daripada pengekod BERT. Kami melatih model kami menggunakan dua jenis teks selari: esei EFL bunyi asal dan yang diperbaiki oleh annotator, kemudian menilainya pada esei asal. Eksperimen menunjukkan bahawa sistem domain akhir-akhir mencapai ketepatan .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% sistem dalam-domain. Ini memberi isyarat bahawa teks yang ditulis dengan baik juga boleh berguna untuk melatih sistem pertambangan argumen untuk teks bunyi.', 'mk': 'Овој весник претставува студија за анализирање на аргументативната структура на есеите на англиски-како-странски јазик (ЕФЛ), кои се природно гласни. Процесот на анализирање се состои од два чекори, поврзувајќи ги поврзаните реченици и потоа означувајќи ги нивните односи. Експериментираме со неколку архитектури за длабоко учење за да се справиме со секоја задача независно. Во реченицата која ја поврзува задачата, биафинскиот модел беше најдобар. Во врска со задачата за етикетирање на односите, фино прилагоден модел BERT го изврши најдоброто. Употребени се два кодери на реченици, и ние забележавме дека нефинетираните модели генерално работеа подобро кога се користи реченица-BERT во спротивност на BERT кодерот. Ги трениравме нашите модели користејќи два вида паралелни тексти: оригинални бучни есеи ЕФЛ и оние подобрени од анотаторите, потоа ги проценуваме на оригиналните есеи. Експериментот покажува дека системот од крај до крај во домен постигнал точност од .341. Од друга страна, крстодомениот систем постигна 94 отсто од резултатите на системот во домените. Ова сигнализира дека добро напишаните тексти, исто така, можат да бидат корисни за обука на системот за рудање аргументи за бучни тексти.', 'mt': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  Il-proċess ta’ analiżi jikkonsisti f’żewġ passi, li jgħaqqdu sentenzi relatati u mbagħad jikkettaw ir-relazzjonijiet tagħhom. Aħna ninsperimentaw b’diversi arkitetturi ta’ tagħlim profond biex nindirizzaw kull kompitu b’mod indipendenti. Fis-sentenza li tgħaqqad il-kompitu, mudell biffin wettaq l-a ħjar. Fil-kompitu tat-tikkettar tar-relazzjoni, mudell BERT irfinat wettaq l-a ħjar. Jintużaw żewġ kodifikaturi tas-sentenzi, u osservajna li mudelli mhux ta’ rfinar ġeneralment kienu aħjar meta ntużaw Sentenza-BERT minflok l-kodifikatur BERT. Taħriġna l-mudelli tagħna bl-użu ta’ żewġ tipi ta’ testi paralleli: essays oriġinali storbjużi tal-EFL u dawk imtejba mill-annotaturi, imbagħad ivvalutawhom fuq l-essays oriġinali. L-esperiment juri li sistema f’dominju minn tarf sa tarf kisbet preċiżjoni ta’ .341. Min-naħa l-oħra, is-sistema cross-domain kisbet prestazzjoni ta’ 94% tas-sistema in-domain. Dan jindika li testi miktuba sew jistgħu jkunu utli wkoll biex titħarreġ is-sistema tal-minjieri tal-argumenti għal testi storbjużi.', 'pl': 'W artykule przedstawiono badanie analizy struktury argumentatywnej w esejach o języku angielskim jako obcym (EFL), które są z natury hałaśliwe. Proces parsowania składa się z dwóch etapów, łączenia powiązanych zdań, a następnie oznaczania ich relacji. Eksperymentujemy z kilkoma architekturami głębokiego uczenia, aby rozwiązać każde zadanie niezależnie. W zadaniu łączącym zdanie najlepiej sprawdził się model biafinowy. W zadaniu etykietowania relacji najlepiej sprawdził się dopracowany model BERT. Zastosowane są dwa kodery zdań, a my zauważyliśmy, że modele niedostrajające się zazwyczaj sprawdzają się lepiej przy użyciu kodera zdań-BERT w przeciwieństwie do kodera BERT. Szkoliliśmy nasze modele z wykorzystaniem dwóch rodzajów tekstów równoległych: oryginalnych szumownych esejów EFL oraz tych ulepszonych przez adnotatorów, a następnie oceniamy je na oryginalnych esejach. Eksperyment pokazuje, że kompleksowy system w domenie osiągnął dokładność .341. Z drugiej strony system między domenami osiągnął 94% wydajności systemu wewnątrz domeny. Sygnalizuje to, że dobrze napisane teksty mogą być również przydatne do treningu systemu wydobywania argumentów dla głośnych tekstów.', 'ro': 'Lucrarea prezintă un studiu privind analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină (EFL), care sunt inerent zgomotoase. Procesul de analizare constă în două etape, care leagă propozițiile conexe și apoi etichetează relațiile lor. Experimentăm cu mai multe arhitecturi de învățare profundă pentru a aborda fiecare sarcină independent. În sarcina de legătură a propozițiilor, un model de biafine a performat cel mai bine. În sarcina de etichetare a relațiilor, un model BERT reglat fin a performat cel mai bine. Sunt utilizate două codificatoare de propoziții și am observat că modelele non-reglare fină au performat în general mai bine atunci când utilizați Sentence-BERT, spre deosebire de codificatorul BERT. Ne-am instruit modelele folosind două tipuri de texte paralele: eseurile EFL originale zgomotoase și cele îmbunătățite de adnotatori, apoi le-am evaluat pe eseurile originale. Experimentul arată că un sistem end-to-end în domeniu a atins o precizie de .341. Pe de altă parte, sistemul cross-domeniu a obținut o performanță de 94% a sistemului in-domeniu. Acest lucru semnalează că textele bine scrise pot fi, de asemenea, utile pentru instruirea sistemului de mining de argumente pentru texte zgomotoase.', 'mn': 'Энэ цаас Англи хэл болон гадаад хэл (EFL) эссийн аргументын бүтцийг хуваалцах талаар судалж байна. Энэ нь үнэхээр чимээгүй. Тайлбарлах процесс нь хоёр алхам, харилцааны өгүүлбэр холбоотой, дараа нь харилцааныг тэмдэглэдэг. Бид олон гүн гүнзгий суралцах архитектурууддаа ажил бүрийг өөрсдөө зохицуулахын тулд туршилт хийдэг. Үүний дараа ажлыг холбох үед биефин загвар хамгийн сайн хийсэн. Хариулт маркингийн ажил дээр BERT загвар хамгийн сайн хийсэн. Хоёр өгүүлбэр коддогч ажиллаж байгаа. Бид BERT коддогч эсрэгээр Sentence-BERT-ийг ашиглах үед илүү сайн ажиллаж байгааг анзаарсан. Бид моделуудыг хоёр төрлийн параллел текст ашиглан сургалтын загвар өгсөн. Үнэндээ чимээгүй EFL эссийг ашиглаж байлаа. Энэ туршилт нь холбооны төгсгөл-төгсгөл систем нь .341-ийн тодорхойлолтой болсон. Нөгөө талаар, холбоотой систем нь холбоотой системийн 94% ажиллагааг гаргасан. Үнэндээ сайн бичигдсэн бичигдсэн мөн аргументын хөрөнгө оруулах системийг сонсогдож чадна.', 'no': 'Denne papiret viser ein studie om tolking av argumentativ strukturen i engelske som fremst språk (EFL), som er eigentleg støy. Tolkingsprosessen inneheld to steg, lenkjer relaterte setningar og så merker forholdet sine. Vi eksperimenterer med fleire dype læringsarkitektur for å handtera kvar oppgåve uavhengig. I setningen som lenkjer oppgåva, utførte ein biaffinmodell den beste. I forhold til merkelappen utførte ein fint BERT-modell best. To setningskooderar er arbeida, og vi observerte at ikkje-finnstillingsmodeller vanlegvis utførte bedre når sentences-BERT brukar i motsetning til BERT-kodar. Vi treng modellen våre med to typar parallelle tekstar: originale støy EFL-essane og dei forbetra av annotatorar, og deretter evaluer dei på originale essane. Eksperimentet viser at ein ende- til- slutt- domenesystemet oppnådd eit nøyaktig av .341. På den andre siden oppnådd krysdomenesystemet 94% utviklinga i domenesystemet. Dette signaler at skrivne tekstar kan også vera nyttig for å trena argument-miningssystem for støytekstar.', 'sr': 'Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno buke. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se obratimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro napravljeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, i primetili smo da modeli koji nisu ispravni, u običaju su bolje izvršili kada koriste kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dve vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procenili na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem prekršnog domena postigao je 94% učinkovitosti sistema u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sistema argumentacija za bučne tekstove.', 'sv': 'Denna uppsats presenterar en studie om tolkning av argumentationsstrukturen i engelsk-som-främmande-språk (EFL) essäer, som är i sig bullriga. Analysprocessen består av två steg, länka relaterade meningar och sedan märka deras relationer. Vi experimenterar med flera djupinlärningsarkitekturer för att hantera varje uppgift självständigt. I meningssänkningsuppgiften presterade en biaffinmodell bäst. I relationsmärkningsuppgiften presterade en finjusterad BERT-modell bäst. Två meningskoder används, och vi observerade att icke-finjusterande modeller generellt presterade bättre när man använder Sentence-BERT i motsats till BERT-encoder. Vi tränade våra modeller med två typer av parallella texter: original bullriga EFL essäer och de som förbättrats av kommentatorer, och utvärderade dem sedan på de ursprungliga essäerna. Experimentet visar att ett heltäckande domänsystem uppnådde en noggrannhet på .341. Å andra sidan uppnådde det domänöverskridande systemet 94% prestanda jämfört med domänsystemet. Detta signalerar att välskrivna texter också kan vara användbara för att träna argument mining system för bullriga texter.', 'si': 'මේ පත්තු ප්\u200dරදේශයක් ඉංග්\u200dරීසි භාෂාවක් වලින් ප්\u200dරශ්නයක් විශ්ලේෂණය කරනවා, ඒ වගේම ප්\u200dරශ්නයක් විශ්ලේෂණය ක විශ්ලේෂණ ප්\u200dරක්\u200dරියාව සම්බන්ධතාවක් දෙකක් තියෙනවා, සම්බන්ධතාවක් සම්බන්ධතාවක් සම්බන්ධ අපි ගොඩක් ගොඩක් ඉගෙන ගන්න සිද්ධ විද්\u200dයාපාරයෙන් පරීක්ෂණය කරනවා හැම වැඩක්ම ස්වයංක්\u200dර වාක්ය සම්බන්ධ වෙන්න වැඩේ බියාෆින් නිර්මාණයක් හොඳම වැඩ කළා. සම්බන්ධ ලේබිල් කාර්යයෙන්, හොඳම BERT මොඩල් එකක් වැඩ කරනවා. වාක්යෙන් කෝඩාර් දෙකක් වැඩ කරලා තියෙනවා, ඒ වගේම අපි බලාපොරොත්තු කරලා තියෙනවා කියලා කියලා, සමාන්\u200dයයෙන්ම නොවිශ්වාසික අපි අපේ මොඩල් එක්ක ප්\u200dරකාර දෙකක් ප්\u200dරයෝජනය කරන්න පුළුවන් විදිහට ප්\u200dරයෝජනය කරලා තියෙන්නේ: ප්\u200dරධාන ශබ්ද EFL විදිහට සහ අනු පරීක්ෂණය පෙන්වන්නේ අවසානයෙන් අවසානයෙන් අවසානයෙන් ඉවරයි. ඩොමේන් පද්ධතියෙන් හරියට .341 වලින්  අනිත් පැත්තෙන්, ක්\u200dරීස් ඩෝමින් පද්ධතියේ ප්\u200dරවේශ පද්ධතියේ 94% ක්\u200dරියාත්මක පරීක්ෂණය ලබාගත මේ සංඥානය හොඳට ලියපු පාළුවත් ප්\u200dරයෝජනය වෙන්න පුළුවන් විදිහට විශ්වාස කරන්න පුළුවන්', 'so': 'Qoraalkan waxaa lagu qoraa waxbarasho ku saabsan baaritaanka dhismaha arrimaha ku saabsan afka Ingiriiska oo kale oo afka ajnabiga ah (EFL) oo aad u dhawaaqdaan. Baaritaanka baarlamaanka waxaa ka mid ah labo tallaabo, ku xiriira qoraalka la xiriira, markaasna la xiriira xiriirkooda. Waxaynu tijaabinaynaa meelo waxbarasho oo mool dheer ah si aan u sheekeyno shaqa kasta si xor ah. Shaqada isku xiran waxaa lagu sameeyay qaab baabuur ah oo aad ugu wanaagsan. Xiriirka sameynta shaqada, model aad u fiican BERT ayaa sameynaya waxa ugu wanaagsan. Waxaa la isticmaalaa labo qodob ah, waxaana aragnay in tusaalo aan hab-wanaagsanayn lagu sameeyo si ka fiican marka lagu isticmaalo Sentence-BERT si ka gees ah codka BERT. Tusaalooyinkayada waxaan ku tababarinnay laba nooc oo kala duduwan qoraal lambarka ah: qoraalka asalka ah ee EFL iyo kuwa horumariyey oo ka kordhisay qoraalka asalka ah, kadibna waxan ku qiimeynay qoraalka asalka ah. Imtixaanka waxaa muuqda in nidaamka ugu dhammaadka gudaha lagu dhamaado uu gaadhay saxda .341. On the other hand, the cross-domain system achieved 94% performance of the in-domain system.  Xilliyadaasu waxay faa’iido u leedahay in qoraal-qoraal oo wanaagsan ay u faa’iido karto in lagu tababaro nidaamka dayactirka ee qoraalka qaylada ah.', 'ta': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  பாடல் செயல்பாடு இரண்டு படிகளாக இருக்கும், தொடர்புடைய வாக்கியங்களை இணைத்து பின்னர் அவர்களுடைய உறவுகளை குறிப் நாம் ஒவ்வொரு செயலையும் தனித்தனியாக பேசுவதற்கு பல ஆழமான கற்றுக்கொள்ளும் அட்டவணைகளைக் கொண்டு சோ வாக்கியத்தில் இணைக்கப்பட்ட பணியில், ஒரு பிபிபின் மாதிரி சிறந்ததை செய்தார். தொடர்பு அறிவிப்பு பணியில், ஒரு நன்றாக குறிப்பிட்ட பிரெட் மாதிரி சிறந்ததை செய்தார். இரண்டு வாக்கிய குறியீடுகள் பயன்படுத்தப்படுகின்றன, பிரெட் குறியீட்டை எதிர்பார்த்து வாக்கியம்-பிரெட்டை பயன்படுத்தும் போது பொ நாங்கள் இரண்டு வகையான இணைப்பு உரைகளை பயன்படுத்தி எங்கள் மாதிரிகளுக்கு பயிற்சி செய்தோம்: இந்த சோதனையில் உள்ள முடிவு முடிவு கணினியில் சரியான .341 கிடைத்தது என்பதை காட்டுகிறது. மறுபக்கத்தில், குறுக்கும் களம் கணினியில் 94% செயல்படுத்தப்பட்டது. இந்த குறிப்புகள் ஆச்சரியமான உரைகளுக்கு ஆராய்ச்சியின் கட்டுப்பாட்டு மையம் பயிற்சிக்க பயனுள்ளதாக இருக்க', 'ur': 'یہ کاغذ انگلیسی زبان (EFL) کے مطابق بحث کی ساختاری مطالعہ کے بارے میں ایک تحقیق پیش کرتا ہے جو اس میں آواز ہے۔ پارسینگ پرسس دو قدم سے ہے، ارتباط کے کلمات کو متصل کرتا ہے اور پھر ان کے ارتباط کا لیبل کرتا ہے. ہم بہت سی عمیق سیکھنے کی معماری کے ساتھ آزمائش کرتے ہیں ہر کام کو آزاد کے ساتھ استعمال کرنے کے لئے۔ بات کی تعلق میں ایک بیفن مدل بہترین کام کیا گیا۔ رابطہ لیبلینگ کے کام میں ایک ٹھیک تنظیم BERT موڈل بہترین عمل کرتا تھا۔ Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. ہم نے ہمارے مدلکوں کو دو قسم کے متعادل متقابل متقابل استعمال کر دیا تھا: اصلی صدا کی EFL رسی اور ان لوگوں کو جو annotators کے ذریعہ بہتر ہوئے تھے، پھر ان کو اصلی رسی پر ارزش کر لیا تھا. آزمائش دکھاتا ہے کہ ایک ڈومین سیسٹم میں آخر-to-end کے طور پر .341 کی دقیق پہنچ گئی۔ دوسری طرف، کرس ڈومین سیسٹم نے ڈومین سیسٹم کی 94% فعالیت پائی۔ یہ نشانیاں ہیں کہ بہترین لکھی ہوئی پیغام بھی مفید ہو سکتے ہیں کہ آواز کے پیغام کے لئے آواز منڈ سیسٹم کی تعلیم کرنے کے لئے۔', 'uz': "Bu qoʻllar ingliz tilida (EFL) tilida argumentative tizimni ajratish uchun o'qituvchi o'rganishni tahrirlaydi. Bu bizning huddi hamma holatdir. Name Biz har bir vazifani o'xshash o'rganish maktablari bilan o'rganamiz. Bogʻliq vazifani bir so'zda biffin modeli eng yaxshi bajarildi. Maʼlumot bajarayotganda yaxshi BERT modeli eng yaxshi bajarildi. Ikki so'zlar kodlash qoidalari ishlaydi, va biz bir necha bogʻ'liq modellarni BERT kodlash bilan foydalanayotganda umuman yaxshi bajarish mumkin. Biz modellarimizni ikki turli parallel textlardan foydalanib o'rganimiz: asl EFL maslahatlari va taʼminlovchilar orqali o'zgartirdi, keyin ularni asl yozlarida qiymatish mumkin. Imtiyozni koʻrsatish mumkin, domen tizimining oxirigi oxirigi tizimi faqat .341 tizimga yetishdi. Бошқа тарафда, cross-domen tizimi domen tizimning 94% bajarishga erishildi. Name", 'vi': 'Tờ giấy này cung cấp một nghiên cứu về các bài luận văn của ngôn ngữ Anh-như-ngôn ngữ-ngoại-Anh (EFL) mà có âm tính rất ồn ào. Cách phân tích gồm hai bước, nối các câu liên quan và sau đó khắc định quan hệ. Chúng tôi thử vài kiến trúc về học sâu để giải quyết mọi nhiệm vụ một cách độc lập. Trong câu kết nối câu này, mô hình hai cam đã làm tốt nhất. Trong nhiệm vụ gắn kết, mô hình BERT được chỉnh cẩn thận đã làm tốt nhất. Hai câu mã hóa phần tử được sử dụng, và chúng tôi quan sát rằng các mô hình chưa được tinh chỉnh thông thường hoạt động tốt hơn khi sử dụng. Chúng tôi đã đào tạo các mẫu bằng hai loại văn bản song song song: các bài thi EFL nguyên bản và những bài viết được sửa chữa, sau đó đánh giá chúng bằng các bài luận gốc. Thí nghiệm cho thấy rằng hệ thống miền-cuối-tới-kết đã đạt độ chính xác của.341. Mặt khác, hệ thống lãnh thổ đạt được tỉ lệ ứng dụng của hệ thống nội bộ. Đây là tín hiệu cho thấy văn bản viết tốt cũng có ích để đào tạo hệ thống khai thác tranh luận cho các văn bản ồn ào.', 'bg': 'Настоящата статия представя проучване за анализиране на аргументативната структура в есетата на английски като чужд език (ЕФЛ), които по своята същност са шумни. Процесът на анализиране се състои от две стъпки, свързване на свързаните изречения и след това етикетиране на техните взаимоотношения. Експериментираме с няколко архитектури за дълбоко обучение, за да се справим самостоятелно с всяка задача. В задачата за свързване на изречения биафинов модел се представи най-добре. В задачата по отношение на етикетирането най-добре се представи фино настроеният модел BERT. Използват се два кодера на изречения и забелязахме, че моделите с нефина настройка обикновено се представят по-добре при използване на кодера за разлика от кодера за изречение. Обучихме моделите си, използвайки два типа паралелни текстове: оригинални шумни есета и тези подобрени с анотатори, след което ги оценяваме на оригиналните есета. Експериментът показва, че система от край до край е постигнала точност от 0,341. От друга страна, междудомейнната система постига 94% производителност на вътрешната система. Това сигнализира, че добре написаните текстове също могат да бъдат полезни за обучение на система за аргументи за шумни текстове.', 'da': 'Denne artikel præsenterer en undersøgelse af analyse af argumentationsstrukturen i engelsk-som-fremmedsprog (EFL) essays, som i sig selv er støjende. Analyseprocessen består af to trin, der forbinder relaterede sætninger og derefter mærker deres relationer. Vi eksperimenterer med flere deep learning arkitekturer for at løse hver opgave uafhængigt. I sætningsforbindelsesopgaven klarede en biaffine model sig bedst. I forbindelse med mærkning af relationer klarede en finjusteret BERT-model sig bedst. Der anvendes to sætningskodere, og vi bemærkede, at ikke-finjusterende modeller generelt klarede sig bedre ved brug af Sentence-BERT i modsætning til BERT encoder. Vi trænede vores modeller ved hjælp af to typer parallelle tekster: originale støjende EFL essays og dem forbedret af kommentatorer, og derefter evaluere dem på de originale essays. Eksperimentet viser, at et end-to-end in-domain system opnåede en nøjagtighed på .341. På den anden side opnåede systemet på tværs af domæner 94% ydeevne af det in-domæne system. Dette signalerer, at velskrevne tekster også kan være nyttige til at træne argument mining system til støjende tekster.', 'nl': 'Dit artikel presenteert een studie over het parsen van de argumentatieve structuur in Engels-als-vreemde-taal (EFL) essays, die inherent luidruchtig zijn. Het parsing proces bestaat uit twee stappen, het koppelen van verwante zinnen en vervolgens het labelen van hun relaties. We experimenteren met verschillende deep learning architecturen om elke taak onafhankelijk aan te pakken. In de zinskoppelingstaak presteerde een biaffine model het beste. Bij de relatielabelstructuur presteerde een verfijnd BERT-model het beste. Er worden twee zinnencoders gebruikt, en we zagen dat niet-fine-tuning modellen over het algemeen beter presteerden bij het gebruik van Sentence-BERT in tegenstelling tot BERT encoder. We hebben onze modellen getraind met behulp van twee soorten parallelle teksten: originele noise EFL essays en die verbeterd door annotators, en ze vervolgens geëvalueerd op de originele essays. Het experiment toont aan dat een end-to-end in-domein systeem een nauwkeurigheid van .341 bereikte. Aan de andere kant behaalde het domeinoverschrijdende systeem 94% prestaties van het in-domein systeem. Dit geeft aan dat goed geschreven teksten ook nuttig kunnen zijn om argument mining systeem te trainen voor lawaaierige teksten.', 'hr': 'Ovaj papir predstavlja ispitivanje o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces razmatranja sastoji se od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo s nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, najbolje je izvršio dobar model BERT-a. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni prilagođavali općenito ispunjavaju bolje kada koriste kaznu-BERT suprotno koderu BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne eseje EFL-a i one koje su poboljšale annotatori, a onda ih procijeniti na originalnim esejima. Eksperiment pokazuje da je sustav kraja do kraja u domenu postigao to čnost od .341. S druge strane, sustav prekršnog domena postigao je 94% učinkovitosti sustava domena. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sustava argumentacija za bučne tekste.', 'de': 'Diese Arbeit stellt eine Studie zur Analyse der argumentativen Struktur in Englisch-als-Fremdsprache (EFL) Essays vor, die inhärent lauter sind. Der Parsing-Prozess besteht aus zwei Schritten, die verwandte Sätze verknüpfen und dann ihre Beziehungen kennzeichnen. Wir experimentieren mit mehreren Deep Learning Architekturen, um jede Aufgabe unabhängig zu lösen. In der Satzverknüpfungsaufgabe zeigte sich ein Biaffinmodell am besten. Bei der Beziehungsbeschriftung zeigte sich ein fein abgestimmtes BERT-Modell am besten. Es werden zwei Satzkodierer eingesetzt, und wir haben beobachtet, dass nicht-Feinabstimmungsmodelle im Allgemeinen besser abschneiden, wenn SatzBERT verwendet wird als BERT-Kodierer. Wir trainierten unsere Modelle mit zwei Arten von parallelen Texten: Original-geräuschvolle EFL-Essays und diejenigen, die durch Annotatoren verbessert wurden, und evaluieren sie dann auf den Originalessays. Das Experiment zeigt, dass ein End-to-End In-Domain System eine Genauigkeit von .341 erreicht hat. Auf der anderen Seite erzielte das domänenübergreifende System 94% Leistung des Domänensystems. Dies signalisiert, dass gut geschriebene Texte auch nützlich sein können, um Argument Mining System für laute Texte zu trainieren.', 'id': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat yang berhubungan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arsitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam kalimat yang menghubungkan tugas, model biaffine melakukan yang terbaik. Dalam tugas etiket hubungan, model BERT yang disesuaikan lebih baik. Dua pengkode kalimat digunakan, dan kami memperhatikan bahwa model non-fine-tuning biasanya berhasil lebih baik ketika menggunakan Sentence-BERT daripada BERT pengekode. Kami melatih model kami menggunakan dua jenis teks paralel: essai EFL bunyi asli dan yang diperbaiki oleh annotator, kemudian mengevaluasinya pada essai asli. Eksperimen menunjukkan bahwa sistem domain akhir-akhir mencapai akurasi .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% dari sistem in-domain. Sinyal ini bahwa teks yang ditulis dengan baik juga dapat berguna untuk melatih sistem pertambangan argumen untuk teks yang berisik.', 'ko': '본고는 영어가 외국어(EFL)로서의 문장 중의 논문 구조를 분석 연구하였다.해석 과정은 두 가지 절차를 포함하여 관련 문장을 연결한 다음에 그것들의 관계를 표시한다.우리는 각 임무를 독립적으로 해결하기 위해 몇 가지 심도 있는 학습 체계 구조를 시도했다.문장 연결 작업 중 아분 모형보다 표현이 가장 좋다.관계 표기 작업 중 미세한 버트 모형이 가장 잘 나타난다.우리는 두 개의 문장 인코더를 사용했고, 문장 BERT 인코더가 아닌 문장 BERT를 사용할 때, 비미세 모형이 일반적으로 더 잘 표현되는 것을 관찰했다.우리는 두 가지 평행 텍스트를 사용하여 우리의 모델을 훈련시켰다. 그것이 바로 원시 시끄러운 EFL 문장과 주석자가 개선한 문장이다. 그리고 원시 문장에서 그것들을 평가한다.실험에 의하면 끝에서 끝까지 시스템의 정밀도는 0.341에 이르렀다.다른 한편, 도메인 간 시스템의 성능은 도메인 내 시스템의 94%에 달한다.좋은 텍스트를 쓰는 것도 소음 텍스트를 훈련하는 파라미터 발굴 시스템에 사용될 수 있다는 뜻이다.', 'sw': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  mchakato wa wimbo huo unajumuisha hatua mbili, ukiunganisha hukumu zinazohusiana na kisha kuonyesha mahusiano yao. Tunajaribu na majengo kadhaa ya kujifunza yenye muhimu ili kuzungumza kila kazi kwa uhuru. Katika hukumu inayounganisha kazi hiyo, muundo wa upinzani uliofanya vizuri zaidi. Katika jukumu la kutangaza, modeli yenye ujuzi mzuri ya BERT ilifanya vizuri zaidi. Watu wawili wa hukumu wanatumiwa, na tuliona kuwa mifano yasiyo na mafanikio mazuri kwa ujumla ulifanya vizuri wakati wakitumia Hukumu-BERT kinyume na mfumo wa BERT. Tulifunza mifano yetu kwa kutumia aina mbili ya maandishi ya usambazaji: masomo ya asili ya EFL na zile zile zile zilizobadilishwa na wataalamu, kisha kutathmini katika matoleo ya awali. Tatizo hilo linaonyesha kwamba mwisho wa mwisho wa mfumo wa ndani ulipata ukweli wa .341. Kwa upande mwingine, mfumo wa ndani ulipata asilimia 94 ya utendaji wa mfumo wa ndani. Hii inaonyesha kuwa maandishi yaliyoandikwa vizuri yanaweza pia kuwa na manufaa ya kufundisha mfumo wa madini ya uchimbaji wa hoja kwa ajili ya ujumbe wa sauti.', 'fa': 'این کاغذ یک مطالعه در مورد بررسی ساختار مطمئنی در امتحان انگلیسی به عنوان زبان خارجی (EFL) را نشان می دهد که در اصل صدا است. فرایند جدا کردن از دو قدم است که جمله\u200cهای ارتباطی را ارتباط می\u200cدهد و بعدش رابطه\u200cهایشان را برچسب می\u200cکند. ما با چند معماری عمیق یادگیری آزمایش می کنیم تا هر کار را به خصوصی بررسی کنیم. در جمله مرتبط کار، یک مدل طبیعی بهترین عمل کرد. در وظیفه برچسب ارتباط، یک مدل BERT خوب تنظیم شده بهترین عمل کرد. دو تنظیم\u200cکننده\u200cی عبارت استفاده می\u200cشوند، و ما متوجه شدیم که مدل\u200cهای غیر تنظیم\u200cکننده\u200cای عموماً بهتر انجام می\u200cدهند وقتی استفاده از عبارت-BERT در مقابل رمز\u200cکننده BERT انجام می\u200cدهند. ما مدل\u200cهایمان را با استفاده از دو نوع متن parallel آموزش دادیم: رسی\u200cهای صوتی EFL و آن\u200cها که توسط آهنگ\u200cکنندگان بهتر شده\u200cاند، سپس آنها را در رسی\u200cهای اصلی ارزیابی می\u200cکنیم. این آزمایش نشان می دهد که یک سیستم پایان و پایان در دومین دقیقاتی از .341 رسیده است. از طریق دیگر، سیستم\u200cهای مختلف دامنه\u200cای 94 درصد عملکرد سیستم دامنه\u200cای را به دست آورد. این سیگنال\u200cها که متن\u200cهای خوب نوشته می\u200cتوانند برای آموزش سیستم خریدن مدارک برای متن\u200cهای صوتی استفاده کنند.', 'tr': 'Bu kagyz iňlis dilinde (EFL) surat çykyşynyň (argümat) eserlerini çykyp biljek bir arzuw görkezýär. Açmak prosesi iki adımdır, sözleri baglaýar we soňra olaryň ilişkilerini etiketleýändir. Biz her zady özbaşdak çykmak üçin birnäçe derin öwrenme arhitekturmalary bilen synanyşýarys. Sözlemde işi baglaşdyrmak üçin, bir biaffin nusgasy iň gowy etdi. etiket täblisasynda, eňleýin etiket täblisasynda BERT nusgasy iň gowy edipdi. Iki sözlem kodçysy işledildi we biz bejerdik ki, sözlem-BERT kodçysynyň tersine ol işe yaramaz nusgalary gowurak etýändigini görnüşdik. Modellerimizi iki tür paralel metin kullanarak eğitirdik: orijinal ses EFL eserleri ve annotatorlar tarafından geliştirilen eserleri üzerinde değerlendirdik. Denemek bolup domeniň soňunda soňunda bir sistemasyň .341-yň dogrylygyny ýetip bardygyny görkezýär. On the other hand, the cross-domain system achieved 94% performance of the domain system. Bu işaretler, gowy ýazylan metinler goş metinler üçin argüm taýýarlama sistemasyny trenlemek üçin faydaly bolup biler.', 'sq': 'Ky dokument paraqet një studim mbi analizimin e strukturës argumentuese në esejat angleze-si-gjuhë-e huaj (EFL), të cilat janë natyrisht zhurmëshme. Procesi i analizimit përbëhet nga dy hapa, duke lidhur frazat e lidhura dhe pastaj duke etiketuar marrëdhëniet e tyre. Ne eksperimentojmë me disa arkitektura mësimi të thellë për të trajtuar çdo detyrë në mënyrë të pavarur. Në fjalimin që lidh detyrën, një model biffin bëri më të mirën. In the relation labelling task, a fine-tuned BERT model performed the best.  Dy koduesit e fjalëve janë të përdorur dhe ne vëzhguam se modelet jo të rregulluara në përgjithësi funksiononin më mirë kur përdornin Sentence-BERT në vend të koduesit BERT. We trained our models using two types of parallel texts: original noisy EFL essays and those improved by annotators, then evaluate them on the original essays.  Eksperimenti tregon se një sistem në domeni arriti një saktësi prej .341. Nga ana tjetër, sistemi transdomenik arriti 94% performancë të sistemit brenda domenit. Kjo sinjalizon se tekstet e shkruara mirë mund të jenë gjithashtu të dobishme për të trajnuar sistemin e minierave të argumenteve për tekste zhurmëshme.', 'af': "Hierdie papier stel 'n studie op die verwerking van die argumentatiewe struktuur in Engelske as-vreemde-taal (EFL) essays, wat inherent geluid is. Die verwerking proses bestaan van twee stappe, verbind verwante setnings en dan etiket hulle verwante. Ons eksperimenteer met verskeie diep leer arkitektuur om elke taak onveilig te adres. In die seting wat die taak verbind het, het 'n biaffine model die beste uitgevoer. In die verwanting etiketting taak, het 'n fyn- tuned BERT model die beste uitgevoer. Twee setkoders word gebruik, en ons het aanhou dat nie-fin-tuning-modele generelik beter uitgevoer het wanneer Sentence-BERT gebruik word as teen BERT-koder. Ons het ons modele opgelei met twee tipes parallele teks: oorspronklike geluide EFL eseë en die wat deur annotators verbeter is, dan evalueer hulle op die oorspronklike eseë. Die eksperiment vertoon dat 'n end- to- end in- domain stelsel ' n presies van .341 bereik het. Op die ander kant het die kruisdomein stelsel 94% effektuur van die in-domein stelsel bereik. Hierdie signale wat goed geskrywe teks ook nuttig kan wees om argument mining stelsel te tref vir geluide teks.", 'am': 'ይህ ገጽ የኢንጂልኛ-እንደ እንግዳ ቋንቋ (EFL) የግል ቋንቋ-ቋንቋ-የቋንቋ-ቋንቋን የግንኙነት አካባቢ ግንኙነትን ማግኘት የሚያስፈልገውን ትምህርት ያቀርባል፡፡ የፓርላማው ፕሮጀክት ሁለት ደረጃዎች ነው፣ የግንኙነት ቃላትን እና ግንኙነታቸውን በማሳመር ነው፡፡ ለሁሉም ስራ ነፃ ለማነጋገር በብዙ ጥልቅ ትምህርት መሠረታዎችን እናሞክራለን፡፡ በቁጥጥር የሚታያየው ስራ፣ የፊፊን ሞዴል የተሻለ ነው፡፡ በተግባር ስራ ላይ የተሻለ የBERT ሞዴል የተሻለ ነው፡፡ ሁለትም የፍርድ የፊደል ቀለሞች ይሞክራሉ፣ የBERT ኮድ በተቃወመ ጊዜ የፍርድ-BERT ኮድ በተደረገ ጊዜ የተሻለ የፊደል ሞዴል እንደተደረገ አየን፡፡ የሁለት ዓይነት መልዕክቶች በተለያዩ ጽሑፎችን አስተማርነው፤ የኢ.አ.አ.አ.ለ.አ.ለ.አ.አ.ለ.አ.አ.አ.ለ.አ.አ.አ.አ.አ.አ.ለ.አ.አ.አ. The experiment shows that an end-to-end in-domain system achieved an accuracy of .341.  በሌላው ክፍል የዶሜን ስርዓት 94 በመቶ ድምፅ አግኝቷል፡፡ ይህች ሲልክ መልካም የተጻፈ ጽሑፎች እና የድምፅ ጽሑፎችን ለመጠቀም የአጋራጆች ዋና ማጭበር ሲስተም ይጠቅማል፡፡', 'bn': 'এই পত্রিকাটি ইংরেজী হিসেবে বিদেশী ভাষায় যুক্তিগত কাঠামো পার্স করার বিষয়টি একটি গবেষণা উপস্থাপন করেছে, যা অন্তর্ভুক্ত শব্দ। পার্সিং প্রক্রিয়ার মধ্যে দুই পদক্ষেপ রয়েছে, যার সাথে সম্পর্কিত শাস্তি লিঙ্ক করে এবং তারপর তাদের সম্পর্কের আমরা বেশ কয়েকটি গভীর শিক্ষা শিক্ষা প্রতিটি কাজের স্বাধীন ভাবে কথা বলার পরীক্ষা করছি। এই বাক্যে লিঙ্ক করা কাজে একটি বিফিন মডেল সবচেয়ে ভালো করেছে। সম্পর্কের ল্যাবেলিং কাজের মধ্যে একটি ভালো ভালো ভালো ভাবে বেরেট মডেল শুরু করেছে। দুই শাস্তি এনকোডার ব্যবহার করা হয়েছে এবং আমরা দেখেছি যে শাস্তি বিবের্ট এনকোডার বিরুদ্ধে ব্যবহার করার বিরুদ্ধে সাধারণত ভালো কাজ করা ন আমরা আমাদের মডেল দুটি ধরনের প্যারালেল লেখা ব্যবহার করে প্রশিক্ষণ প্রশিক্ষণ দিয়েছি: প্রাথমিক শব্দ ইএফএল প্রসেস এবং যারা শিক্ষার্থীদের এই পরীক্ষাটি দেখাচ্ছে যে ডোমেইনের শেষ পর্যন্ত শেষ ব্যবস্থা সঠিকভাবে পৌঁছেছে। অন্যদিকে, ক্রিস্ট ডোমেইন সিস্টেমের ৯৪% পালন করেছে। এই সিগন্যালটি দেখাচ্ছে যে ভাল লিখিত লেখাগুলো শব্দ লেখার জন্য যুক্ত মিনিং সিস্টেম প্রশিক্ষণের জন্যে উপ', 'az': 'Bu kağıt İngilis dilində-Dışarı dilində (EFL) essaylarında müzakirçi strukturlarını ayırmaq haqqında bir təhsil göstərir. Analizasyon prosesi iki adımdır, əlaqəsiz cümlələri bağlayır və sonra onların əlaqələrini etiketləyir. Biz hər işi təmizlə çəkmək üçün çox derin öyrənmə arhitektarlarıyla imtahana çəkirik. İşləri bağlayıb cümlədə, bir biafin modeli ən yaxşı işlədi. İlişkisi etiketləmə işində, BERT modeli ən yaxşı işlədi. İki cümləlik kodlayıcısı istifadə edilir, və biz BERT kodlayıcısı ilə əlavə etdikdə çox yaxşı işlədiklərini gördük. Biz modellərimizi iki türü paralel metin vasitəsilə təhsil etdik: orijinal səslü EFL essayları və annotatorların təhsil edilənlər, sonra onları orijinal essaylarda təhsil edirik. Bu təcrübə göstərir ki, domeinin sonu-sonu sisteminin .341 dəqiqliyinə nail oldu. Digər tərəfindən, çox domena sistemi domena sisteminin 94% performansını qəbul etdi. Bu sinyallər, yaxşı yazılmış mətnlər də səsl mətnlər üçün arqümət madenci sistemini təhsil etmək üçün faydalı olar.', 'hy': "Այս հոդվածը ներկայացնում է մի ուսումնասիրություն անգլերեն-օտար-լեզու (EFL) էսսեների արտահայտության վերլուծության մասին, որոնք բնական աղմուկ են: Փորձարկման գործընթացը կազմված է երկու քայլ, կապելով կապված նախադասությունները և հետո պիտակելով նրանց հարաբերությունները: Մենք փորձում ենք մի քանի խորը ուսուցման ճարտարապետությունների հետ յուրաքանչյուր խնդիր անկախ լուծելու համար: Արտահայտությունը կապված նախադասության մեջ երկաֆինի մոդելը լավագույնն արեց: Ինչ վերաբերում է պիտակավորման խնդրին, լավագույնը կատարեց բարձրացված BERT մոդելը: Երկու նախադասություն կոդավորիչներ են օգտագործվում, և մենք նկատեցինք, որ ոչ բարձրակարգման մոդելները սովորաբար ավելի լավ են աշխատում օգտագործելով նախադասություն-BER-ը, ի հակադրություն BER-ի կոդավորիչը: Մենք ուսուցանում էինք մեր մոդելները երկու տեսակի զուգահեռ տեքստերի օգտագործելով' սկզբնական աղմկոտ EFL էսսեները, որոնք բարելավվել են annoտորների կողմից, հետո գնահատում ենք դրանք սկզբնական էսսերի վրա: Փորձը ցույց է տալիս, որ տիեզերքի վերջ-վերջ համակարգը հասավ .341 ճշգրիտության: Մյուս կողմից, տիեզերական համակարգը հասավ տիեզերական համակարգի 94 տոկոսի արդյունավետության: Սա ազդանշան է տալիս, որ լավ գրված տեքստերը կարող են օգտակար լինել նաև աղմկոտ տեքստերի համար բանավեճերի հանքային համակարգի ուսումնասիրելու համար:", 'bs': 'Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro određeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni, obično su bolje izvršili kada su koristili kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procjenjivali na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem krstodomena postigao je 94% učinkovitosti sustava u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za treniranje rudarskog sustava argumenta za bučne tekstove.', 'ca': "Aquest paper presenta un estudi sobre l'analització de l'estructura argumentativa en els assats anglès-com-estrangers (EFL), que són inherentment sorollosos. El procés d'analització consisteix en dos passos, enllaçant frases relacionades i etiquetant les seves relacions. Experimentem amb diverses arquitectures d'aprenentatge profund per abordar cada tasca de manera independent. In the sentence linking task, a biaffine model performed the best.  En la tasca d'etiquetar les relacions, un model BERT ajustat va fer el millor. S'utilitzen dos codificadors de frases, i vam observar que els models no fins ajustes generalment van funcionar millor quan utilitzen Sentence-BERT en comptes del codificador BERT. Vam treinar els nostres models fent servir dos tipus de textos parallels: els assaig original sorollós EFL i els millorats pels anotators, i després els vam evaluar en els assaig originals. L'experiment mostra que un sistema de domini final a final va aconseguir una precisió de .341. D'altra banda, el sistema transdomínic va aconseguir un 94% de rendiment del sistema intradomínic. Això indica que els textos ben escrits també poden ser útils per entrenar el sistema de mineria d'arguments per a textos ruidosos.", 'et': 'Käesolevas töös esitatakse uuring inglise kui võõrkeele esseede argumentatiivse struktuuri parsimise kohta, mis on olemuslikult lärmakad. Parsimisprotsess koosneb kahest etapist, sidudes seotud laused ja märgistades seejärel nende suhted. Me eksperimenteerime mitme sügavõppe arhitektuuriga, et iga ülesande lahendada iseseisvalt. Lausete sidumise ülesandes oli parim biafiin mudel. Märgistamisega seotud ülesande puhul oli parim tulemus täpsustatud BERTi mudel. Kasutatakse kahte lausekodeerijat ja täheldasime, et mittepeenhäälestuslikud mudelid toimivad üldiselt paremini Sentence-BERT kasutamisel kui BERT kodeerija. Koolitasime oma mudeleid kahte tüüpi paralleelsete tekstide abil: originaalsed mürakad EFL esseed ja parandatud annotatorid, seejärel hindame neid originaalsete esseede põhjal. Katse näitab, et domeenisisene süsteem saavutas täpsuse 0,341. Teisest küljest saavutas valdkondadevaheline süsteem 94% jõudluse valdkonnasisest süsteemist. See annab märku, et hästi kirjutatud tekstid võivad olla kasulikud ka argumentide kaevandamise süsteemi koolitamiseks mürakate tekstide jaoks.', 'cs': 'Tento článek představuje studii o analýze argumentativní struktury v esejích angličtiny jako cizího jazyka (EFL), které jsou z podstaty hlučné. Proces parsování se skládá ze dvou kroků, propojení souvisejících vět a následně označení jejich vztahů. Experimentujeme s několika architekturami hlubokého učení, abychom řešili každý úkol nezávisle. Ve větě propojující úkol, biafinový model vedl nejlépe. Při úkolu označování vztahů nejlépe fungoval jemně vyladěný model BERT. Používají se dva snímače vět a pozorovali jsme, že modely bez jemného ladění většinou fungují lépe při použití Sentence-BERT než BERT snímač. Naše modely jsme trénovali pomocí dvou typů paralelních textů: originálních hlučných EFL esejí a těch, které vylepšují anotátory, a poté je vyhodnocují na originálních esejích. Experiment ukazuje, že end-to-end in-domain systém dosáhl přesnosti .341. Na druhou stranu, cross-domain systém dosáhl 94% výkonnosti in-domain systému. To signalizuje, že dobře napsané texty mohou být také užitečné pro trénink argument mining systému pro hlučné texty.', 'fi': 'Tämä artikkeli esittelee tutkimuksen argumentatiivisen rakenteen jäsentämisestä englanti vieraana kielenä -esseissä, jotka ovat luonnostaan meluisia. Analysointiprosessi koostuu kahdesta vaiheesta, jotka yhdistävät toisiinsa liittyvät lauseet ja merkitsevät niiden suhteet. Kokeilemme useita syväoppimisen arkkitehtuureja kunkin tehtävän käsittelemiseksi itsenäisesti. Lausekkeen linkitystehtävässä biafiinimalli suoriutui parhaiten. Suhteeseen merkitsemistä koskevassa tehtävässä parhaiten suoriutui hienosäädetty BERT-malli. Käytössä on kaksi lauseenkooderia, ja havaitsimme, että ei-hienosäätömallit suoriutuivat yleensä paremmin Sentence-BERT-kooderilla kuin BERT-kooderilla. Koulutimme mallit kahdentyyppisillä rinnakkaisilla teksteillä: alkuperäisillä noisy EFL esseillä ja kommentaattoreilla parannelluilla esseillä, minkä jälkeen arvioimme niitä alkuperäisillä esseillä. Koe osoittaa, että kokonaisvaltainen verkkotunnusjärjestelmä saavutti tarkkuuden 0,341. Toisaalta toimialojen välinen järjestelmä saavutti 94% suorituskykyä toimialojen sisäisestä järjestelmästä. Tämä osoittaa, että hyvin kirjoitetut tekstit voivat olla hyödyllisiä myös argumenttien louhintajärjestelmän kouluttamisessa meluisille teksteille.', 'ha': "Wannan takardan na bãyar da wani littãfi a kan parse muhimmanci cikin harshen Ingiriya-as-kigenre (EFL), wanda ke cikin sauti. @ action: button We experiment with several deep learning architectures to address each task independently.  A cikin aikin da ke haɗi zuwa maganar, wata misali mai biyafi ya sami mafi kyaun. In the related labelin job, a mai kyau-tuned BERT Model ya samar da mafi kyaun. An yi amfani da kodi biyu na maganar, kuma ba mu gani ba cewa misãlai masu tunkuɗe wa-mai kyau a samu'a da mafiya kyau idan an yi amfani da Cincin-BERT kamar da ya motsa kodi na BERT. Kuma ba mu sanar da misalinmu da misalin misalin misalin biyu masu daidaita: makaranti na farko na EFL da waɗanda aka samar da su, sa'an nan kuma ka ƙaddara su a cikin takardar farko. Tafiyar da ke nuna cewa ƙari zuwa-ƙari cikin-guda ya sami tsari na .341. Ga da hagu, na'urar-ɗamfyuta ta sãmu 94% na'urar tsarin da ke cikin guda. Wannan ayukan ayuka da aka rubũta rubutu masu iya amfani da shi, ya zama mai amfani ga tunkuɗe tsarin sundin da aka yi wa matsayin sauti.", 'sk': 'V prispevku je predstavljena študija razčlenitve argumentativne strukture v esejih angleščine kot tuji jezik (EFL), ki so po sebi hrupni. Postopek razčlenitve je sestavljen iz dveh korakov, povezovanja povezanih stavkov in nato označevanja njihovih odnosov. Eksperimentiramo z več arhitekturami globokega učenja, da bi vsako nalogo obravnavali samostojno. Pri nalogi povezovanja stavkov je bil biafinski model najboljši. Pri nalogi označevanja povezav je bil najboljši prilagojen model BERT. Uporabljena sta dva kodirnika stavkov in opazili smo, da so modeli brez natančnega nastavljanja na splošno boljši pri uporabi kodirnika Sentence-BERT kot BERT. Naše modele smo usposabljali z dvema vrstama vzporednih besedil: originalnimi hrupnimi eseji EFL in tistimi, ki so jih izboljšali z opotatorji, nato pa jih ocenili na originalnih esejih. Poskus je pokazal, da je sistem od konca do konca dosegel natančnost 0,341. Po drugi strani pa je meddomenski sistem dosegel 94% zmogljivosti notranjega sistema. To kaže, da so dobro napisana besedila lahko koristna tudi za usposabljanje sistema rudarjenja argumentov za hrupna besedila.', 'he': 'This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  תהליך המחקר מורכב משני צעדים, הקשר משפטים קשורים ואז סימן את מערכת היחסים שלהם. אנחנו מנסים עם כמה ארכיטקטורות למידה עמוקה כדי להתמודד עם כל משימה באופן עצמאי. במשפט הקשר משימה, דוגמנית ביאפין ביצעה את הטוב ביותר. במשימת התיקון, מודל BERT מעוצבן ביצע את הטוב ביותר. שני קודדים משפטים משתמשים, ואנחנו שמנו לב שדוגמנים לא מתאימים בדרך כלל ביצעו טוב יותר כשהשתמשו בשימוש בשימוש בשימוש בשימוש בשימוש במקום קודד BERT. אימנו את הדוגמנים שלנו באמצעות שני סוגים של טקסטים מקבילים: מאמרים מקוריים רעשים EFL ואלה ששותפים על ידי ציונים, ואז מעריכים אותם על המאמרים המקוריים. הניסוי מראה שמערכת בתחום של סוף אל סוף השיגה מדויקה של .341. מצד שני, מערכת התחום השיגה 94% ביצועים של מערכת התחום. זה מסמן שטקסטים נכתבים היטב יכולים להיות שימושיים גם לאמן מערכת כירות טיעונים לטקסטים רעשים.', 'bo': 'ཤོག་བྱང་འདིས་ཨིན་ཡིག་གི་སྐད་ཡིག་ནང་གི་སྒྲུབ་གཏོང་གི་བཟོ་བསམ་ཞིག་བྱེད་སྐབས་ལྟ་བུ་མངོན་འཆར་ཡོད། དབྱེ་ཞིབ་ཀྱི་ལས་སྦྱོར་དེའི་གྲལ་ཐེངས་གཉིས་ལས་འབྲེལ་བ་ཡིན་པའི་ཚིག་རྟགས་དང་ཁོང་གི་འབྲེལ་བ ང་ཚོས་རེ་བོ་སོ་སོའི་ལས་འགུལ་གྱི་ཁྱད་ཆོས་སོ་སོའི་བཟོ་བརྩིས་གཞི་འདྲ་བྱེད་མ་ཐུབ། ཚིག མཐུན་འབྲེལ་གྱི་ཤོག་བྱང་ཀི་ལས་འགུལ་གྱི་ནང་དུ། ཚད་ལྡན་པའི་BERT མིག་དཔེ་ཞིག་ནི་སྐྱོན་ཤོས་ཡོད། ཚིག ང་ཚོས་མིག་གཟུགས་རིས་འདི་དག་གི་དབྱེ་བ་གཉིས་དབྱེ་བ་གི་ཡིག སྒེར་ཞུ་གིས་domain་ཐོག་མཐའ་མཇུག་གསུམ་དུ་མཐོང་བ་ཡིན།341 On the other hand, the cross-domain system achieved 94% performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.', 'jv': 'Perkara iki nambah urip nggambar kelas pirsak nggawe tarjamahan seneng nggagal-ingkang kaya-nglanggar sapa-kenir (eFL). Genjer Awak dhéwé éntuk karo akeh akeh juter architecture kanggo sabên seneng nggawe gerakan sakjane. Nang papat nggambar task, supoyo biaFin nambah sing luwih apik. Nambah tengahane nggambar nggambar, model BERT wis ngawe barang apik. Yo wis rampung koder sing nggunakake ditambah, lan ampuhi awak dhéwé ngerasah model sing gak bener-ne-tuning nggawe barang luwih dumadhi kanggo nggunakake Sentense-BERT dumadhi karo koder BERT. Awak dhéwé éntuk sistem sing beraksi perusahaan dengané sampeyan kelangan iki: iso nggawe barang kegambar uwong, lan uwong sing nyebutaké awak dhéwé, njuk ujarané awak dhéwé sisayé surat sing uwong. The pilot show that an end-to-end in-domain System success an exact of .34 1. In the second hand, the inter-domain System met 1994% success of the in-domain System. structural navigation'}
{'en': 'Training and Domain Adaptation for Supervised Text Segmentation', 'pt': 'Treinamento e Adaptação de Domínio para Segmentação de Texto Supervisionada', 'es': 'Capacitación y adaptación de dominios para la segmentación de texto supervisada', 'fr': 'Formation et adaptation de domaine pour la segmentation de texte supervisée', 'ja': '監督下のテキストセグメンテーションのためのトレーニングとドメインの適応', 'ar': 'التدريب وتكييف المجال لتجزئة النص تحت الإشراف', 'ru': 'Обучение и адаптация домена для контролируемой сегментации текста', 'zh': '督文本分训练及领域', 'hi': 'पर्यवेक्षित पाठ विभाजन के लिए प्रशिक्षण और डोमेन अनुकूलन', 'ga': 'Oiliúint agus Oiriúnú Fearainn le haghaidh Deighilt Téacs Maoirsithe', 'el': 'Εκπαίδευση και προσαρμογή τομέων για την εποπτευόμενη τμηματοποίηση κειμένου', 'ka': 'შენახვა ტექსტის სეგმენტაციისთვის განათლება და დომენის ადაპტიფიკაცია', 'it': 'Formazione e adattamento del dominio per la segmentazione di testo supervisionata', 'lt': 'Mokymas ir srities pritaikymas prižiūrimam teksto segmentavimui', 'hu': 'Képzés és tartomány-adaptáció a felügyelt szövegszegmentáláshoz', 'ms': 'Pelatihan dan Penyesuaian Domain untuk Segmentasi Teks DiSupervise', 'kk': 'Бақылаған мәтін сегментациясының оқыту мен домен адаптациясы', 'ml': 'സൂപ്പര്\u200dവ്വദര്\u200dശിക്കപ്പെട്ട പദാവലി സജ്ജീകരണത്തിനായുള്ള പരിശീലനവും ഡൊമെയിനും ഉപയോഗിക്കുക', 'no': 'Øvingstilpassing og domene for oversikt tekstsegmentasjon', 'mk': 'Тренинг и адаптација на домен за надгледувана текстова сегментација', 'pl': 'Szkolenia i adaptacja domeny dla nadzorowanej segmentacji tekstu', 'mt': 'Taħriġ u Adattament għall-Dominju għas-Segmentazzjoni tat-Test Sorveljat', 'sr': 'Treniranje i adaptacija domena za nadzornu segmentaciju teksta', 'mn': 'Хэрэглэгдсэн Текст хэлбэрийн суралцах болон домон загварчлал', 'ro': 'Instruire și adaptare domeniu pentru segmentarea textului supravegheat', 'si': 'පරීක්ෂණා කරලා තියෙන පාළුව සෙග්මෙන්ටම් සඳහා ප්\u200dරධානය සහ ඩොමේන් අනුමුණ', 'sv': 'Utbildning och domänanpassning för övervakad textsegmentering', 'ta': 'கண்காணிக்கப்பட்ட உரைப் பிரிவுகளுக்கான பயிற்சி மற்றும் களம் செயல்பாடு', 'ur': 'تحت نظر والی ٹکس سپٹمنٹ کے لئے ترین اور ڈومین اڈپٹیٹ', 'so': 'Waxbarashada iyo Adaptation Domain', 'uz': 'Name', 'vi': 'Đào tạo và sửa mái cho đoạn theo dõi', 'bg': 'Обучение и адаптация на домейна за контролирана текстова сегментация', 'nl': 'Training en domeinaanpassing voor begeleide tekstsegmentatie', 'hr': 'Treniranje i adaptacija domena za nadzornu segmentaciju teksta', 'da': 'Uddannelse og tilpasning af domæne til overvåget tekstsegmentering', 'de': 'Training und Domänenanpassung für überwachte Textsegmentierung', 'ko': '텍스트 분할을 감독하는 훈련과 필드 적응', 'fa': 'آموزش و تغییرات دامنی برای جدول متن تحت نظر', 'id': 'Pelatihan dan Adaptasi Domain untuk Segmentasi Teks Tersupervisi', 'af': 'Oefening en domein aanpassing vir ondersoekte teks segmentasie', 'sw': 'Mafunzo na Mafunzo ya Domain kwa ajili ya Kugawa kwa Makala', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'tr': 'Gözlenýän Metin Segmentasiýasy üçin eğitim we ýer Adaptasy', 'sq': 'Training and Domain Adaptation for Supervised Text Segmentation', 'az': 'Gözlənmiş Metin Segmentasyonu üçün təhsil və Domain Adjustasyonu', 'bn': 'Supervied Text Segmentation এর প্রশিক্ষণ ও ডোমেইন অ্যাডাপ্টেশন', 'hy': 'Հաշվի առկա տեքստի սեգմենցիայի ուսուցման և դաշտային հարմարեցման համար', 'bs': 'Treniranje i adaptacija domena za nadzornu segmentaciju teksta', 'et': 'Koolitus ja domeeni kohandamine kontrollitud teksti segmenteerimiseks', 'ca': 'Formació i adaptació del domini per a la segmentació del text supervisat', 'cs': 'Školení a přizpůsobení domén pro dohledovanou segmentaci textu', 'fi': 'Koulutus ja verkkotunnuksen mukauttaminen valvottuun tekstisegmentointiin', 'jv': 'Learning and domain Adjustment for super Vised Text segmentation', 'he': 'האימונים והשינוי של שטח למחלקת טקסט שמשמרת', 'sk': 'Usposabljanje in prilagajanje domen za nadzorovano segmentacijo besedila', 'bo': 'Training and Domain Adaptation for Supervised Text Segmentation', 'ha': 'KCharselect unicode block name'}
{'en': 'Unlike traditional unsupervised text segmentation methods, recent supervised segmentation models rely on  Wikipedia  as the source of large-scale segmentation supervision. These models have, however, predominantly been evaluated on the in-domain (Wikipedia-based) test sets, preventing conclusions about their general segmentation efficacy. In this work, we focus on the domain transfer performance of supervised neural text segmentation in the educational domain. To this end, we first introduce K12Seg, a new  dataset  for evaluation of supervised segmentation, created from educational reading material for grade-1 to college-level students. We then benchmark a hierarchical text segmentation model (HITS), based on RoBERTa, in both in-domain and domain-transfer segmentation experiments. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting. We identify adapter-based fine-tuning as a remedy that substantially improves transfer performance.', 'pt': 'Ao contrário dos métodos tradicionais de segmentação de texto não supervisionada, os modelos recentes de segmentação supervisionada contam com a Wikipedia como fonte de supervisão de segmentação em larga escala. Esses modelos, no entanto, foram avaliados predominantemente nos conjuntos de testes no domínio (baseados na Wikipédia), impedindo conclusões sobre sua eficácia geral de segmentação. Neste trabalho, focamos no desempenho da transferência de domínio da segmentação de texto neural supervisionada no domínio educacional. Para isso, primeiro apresentamos o K12Seg, um novo conjunto de dados para avaliação da segmentação supervisionada, criado a partir de material didático de leitura para alunos do 1º ano ao ensino superior. Em seguida, comparamos um modelo hierárquico de segmentação de texto (HITS), baseado em RoBERTa, em experimentos de segmentação no domínio e transferência de domínio. Embora o HITS produza desempenho no domínio de última geração (em três conjuntos de testes baseados na Wikipedia), mostramos que, sujeito ao ajuste fino padrão completo, ele é suscetível a overfitting de domínio. Identificamos o ajuste fino baseado em adaptador como uma solução que melhora substancialmente o desempenho da transferência.', 'fr': "Contrairement aux méthodes traditionnelles de segmentation de texte non supervisée, les modèles de segmentation supervisée récents s'appuient sur Wikipédia comme source de supervision de segmentation à grande échelle. Ces modèles ont toutefois été principalement évalués sur des ensembles de tests dans le domaine (basés sur Wikipédia), ce qui a empêché de tirer des conclusions sur leur efficacité générale de segmentation. Dans ce travail, nous nous concentrons sur les performances de transfert de domaine de la segmentation de texte neuronal supervisée dans le domaine éducatif. À cette fin, nous présentons d'abord K12Seg, un nouveau jeu de données pour l'évaluation de la segmentation supervisée, créé à partir de matériel de lecture pédagogique pour les élèves de la première année au niveau collégial. Nous avons ensuite comparé un modèle de segmentation hiérarchique de texte (HITS), basé sur Roberta, à la fois dans des expériences de segmentation dans le domaine et par transfert de domaine. Alors que HITS produit des performances de pointe dans le domaine (sur trois ensembles de tests basés sur Wikipédia), nous montrons que, sous réserve du réglage fin standard complet, il est susceptible de suradapter le domaine. Nous considérons que le réglage fin basé sur l'adaptateur est un remède qui améliore considérablement les performances de transfert.", 'ar': 'على عكس طرق تجزئة النص التقليدية غير الخاضعة للإشراف ، تعتمد نماذج التجزئة الحديثة الخاضعة للإشراف على ويكيبيديا كمصدر للإشراف على التجزئة على نطاق واسع. ومع ذلك ، فقد تم تقييم هذه النماذج في الغالب على مجموعات الاختبار في المجال (المستندة إلى ويكيبيديا) ، مما يمنع الاستنتاجات حول فعالية التجزئة العامة. في هذا العمل ، نركز على أداء نقل المجال لتجزئة النص العصبي الخاضع للإشراف في المجال التعليمي. تحقيقًا لهذه الغاية ، نقدم أولاً K12Seg ، وهي مجموعة بيانات جديدة لتقييم التجزئة الخاضعة للإشراف ، والتي تم إنشاؤها من مواد القراءة التعليمية لطلاب الصف الأول إلى مستوى الكلية. ثم قمنا بعد ذلك بقياس نموذج تجزئة النص الهرمي (HITS) ، استنادًا إلى RoBERTa ، في كل من تجارب التجزئة داخل المجال ونقل المجال. بينما ينتج HITS أداءً متطورًا في المجال (على ثلاث مجموعات اختبار قائمة على ويكيبيديا) ، نوضح أنه ، وفقًا للضبط القياسي الكامل ، يكون عرضة لتركيب المجال. نحدد الضبط الدقيق المستند إلى المحول كعلاج يعمل على تحسين أداء النقل بشكل كبير.', 'es': 'A diferencia de los métodos tradicionales de segmentación de texto sin supervisión, los modelos de segmentación supervisada recientes se basan en Wikipedia como fuente de supervisión de segmentación a gran escala. Sin embargo, estos modelos se han evaluado predominantemente en los conjuntos de pruebas dentro del dominio (basados en Wikipedia), lo que impide sacar conclusiones sobre su eficacia de segmentación general. En este trabajo, nos centramos en el rendimiento de transferencia de dominio de la segmentación de textos neuronales supervisados en el dominio educativo. Con este fin, primero presentamos K12Seg, un nuevo conjunto de datos para la evaluación de la segmentación supervisada, creado a partir de material de lectura educativo para estudiantes de primer grado hasta estudiantes de nivel universitario. Luego comparamos un modelo de segmentación de texto jerárquico (HITS), basado en RobErta, tanto en experimentos de segmentación dentro del dominio como de transferencia de dominio. Si bien HITS produce un rendimiento de dominio de vanguardia (en tres conjuntos de pruebas basados en Wikipedia), demostramos que, sujeto al ajuste completo estándar, es susceptible de sobreajuste del dominio. Identificamos el ajuste fino basado en el adaptador como un remedio que mejora sustancialmente el rendimiento de la transferencia.', 'ja': '従来の無監督テキストセグメンテーション手法とは異なり、最近の監督セグメンテーションモデルは、大規模なセグメンテーション監督のソースとしてウィキペディアに依存しています。 しかしながら、これらのモデルは、主にドメイン内（ウィキペディアベース）の試験セットで評価されており、それらの一般的なセグメンテーションの有効性に関する結論を防いでいる。 この研究では、教育領域における監視下のニューラルテキストセグメンテーションのドメイン転送パフォーマンスに焦点を当てます。 そのために、まず、1年生から大学生までの教育リーディング資料から作成された、監督下セグメンテーションの評価のための新しいデータセットであるK 12 Segを紹介します。 次に、ドメイン内およびドメイン転送セグメンテーション実験の両方で、RoBERTaに基づく階層的テキストセグメンテーションモデル（ HITS ）をベンチマークします。 HITSは最先端のドメイン内パフォーマンスを生み出しますが（ 3つのウィキペディアベースのテストセットで）、標準的なフルブラウンドの微調整の条件下では、ドメインのオーバーフィットの影響を受けやすいことを示しています。 当社は、アダプタベースの微調整を、転送パフォーマンスを大幅に向上させる救済策として特定しています。', 'zh': '与旧无监文本分法不同,近监分模维基百科以为大分。 然要在域内(基于维基百科)试集上,以沮分功之论。 注意教育领域中监督式神经文本分域移。 首言K12Seg,此评督分新数集也,1年级于大学生教阅材创造。 然后域内和域移分实验中于 RoBERTa 分文本(HITS) 准试之。 虽HITS生至先进之域(在三维基百科之试集上),明于准的全调,其易受域过拟合也。 吾将适配器之微定为一补救措施,著传输性能。', 'hi': 'पारंपरिक असुरक्षित पाठ विभाजन विधियों के विपरीत, हाल ही में पर्यवेक्षित विभाजन मॉडल बड़े पैमाने पर विभाजन पर्यवेक्षण के स्रोत के रूप में विकिपीडिया पर भरोसा करते हैं। हालांकि, इन मॉडलों का मुख्य रूप से इन-डोमेन (विकिपीडिया-आधारित) परीक्षण सेट पर मूल्यांकन किया गया है, जो उनकी सामान्य विभाजन प्रभावकारिता के बारे में निष्कर्षों को रोकता है। इस काम में, हम शैक्षिक डोमेन में पर्यवेक्षित तंत्रिका पाठ विभाजन के डोमेन स्थानांतरण प्रदर्शन पर ध्यान केंद्रित करते हैं। इस अंत तक, हम पहले K12Seg, पर्यवेक्षित विभाजन के मूल्यांकन के लिए एक नया डेटासेट पेश करते हैं, जो ग्रेड -1 के लिए कॉलेज स्तर के छात्रों के लिए शैक्षिक पढ़ने की सामग्री से बनाया गया है। फिर हम एक पदानुक्रमित पाठ विभाजन मॉडल (HITS) बेंचमार्क करते हैं, जो RoBERTa पर आधारित है, दोनों इन-डोमेन और डोमेन-ट्रांसफर सेगमेंटेशन प्रयोगों में। जबकि हिट्स अत्याधुनिक इन-डोमेन प्रदर्शन (तीन विकिपीडिया-आधारित परीक्षण सेट पर) का उत्पादन करता है, हम दिखाते हैं कि, मानक पूर्ण विकसित ठीक-ट्यूनिंग के अधीन, यह डोमेन ओवरफिटिंग के लिए अतिसंवेदनशील है। हम एडाप्टर-आधारित ठीक-ट्यूनिंग को एक उपाय के रूप में पहचानते हैं जो स्थानांतरण प्रदर्शन में काफी सुधार करता है।', 'ru': 'В отличие от традиционных неконтролируемых методов сегментации текста, недавние модели сегментации, находящиеся под надзором, полагаются на Википедию как на источник крупномасштабного надзора за сегментацией. Эти модели, однако, преимущественно оценивались на внутридоменных (на основе Википедии) тестовых наборах, предотвращая выводы об их общей эффективности сегментации. В этой работе мы фокусируемся на производительности переноса домена контролируемой нейронной текстовой сегментации в образовательной сфере. С этой целью мы сначала представляем K12Seg, новый набор данных для оценки контролируемой сегментации, созданный из учебного материала для чтения для учащихся 1 класса на уровне колледжа. Затем мы сравниваем иерархическую модель сегментации текста (HITS), основанную на RoBERTa, как в экспериментах по сегментации внутри домена, так и в экспериментах по переносу домена. В то время как HITS производит самые современные внутридоменные характеристики (на трех тестовых наборах на основе Википедии), мы показываем, что, при условии стандартной полной тонкой настройки, он восприимчив к переоборудованию домена. Мы определяем тонкую настройку на основе адаптера как средство, которое значительно улучшает производительность передачи.', 'ga': 'Murab ionann agus modhanna traidisiúnta deighilte téacs gan mhaoirseacht, bíonn samhlacha deighilte maoirsithe le déanaí ag brath ar Vicipéid mar fhoinse maoirseachta deighilte ar scála mór. Mar sin féin, rinneadh na samhlacha seo a mheas go príomha ar na tacair tástála in-fhearainn (bunaithe ar Vicipéid), rud a chuir cosc ar chonclúidí maidir lena n-éifeachtúlacht ghinearálta deighilte. San obair seo, dírímid ar fheidhmíocht aistrithe fearainn na deighilte téacs néaracha maoirsithe sa réimse oideachais. Chuige sin, tugaimid isteach ar dtús K12Seg, tacar sonraí nua chun meastóireacht a dhéanamh ar dheighilt faoi mhaoirseacht, a cruthaíodh as ábhar léitheoireachta oideachais do ghrád 1 go dtí mic léinn ar leibhéal an choláiste. Déanaimid tagarmharcáil ansin ar shamhail deighilte téacs ordlathach (HITS), bunaithe ar RoBERTa, i dturgnaimh deighilte in-fhearainn agus aistrithe fearainn. Cé go ndéanann HITS feidhmíocht den scoth san fhearann (ar thrí thacar tástála bunaithe ar Vicipéid), léirímid, faoi réir an mhionchoigeartaithe chaighdeánaigh lán-séidte, go bhfuil sé so-ghabhálach i leith rófheistithe fearainn. Aithnímid mionchoigeartú atá bunaithe ar oiriúntóirí mar leigheas a fheabhsaíonn feidhmíocht aistrithe go suntasach.', 'el': 'Σε αντίθεση με τις παραδοσιακές μεθόδους τμηματοποίησης κειμένου χωρίς επίβλεψη, τα πρόσφατα εποπτευμένα μοντέλα τμηματοποίησης βασίζονται στη Βικιπαίδεια ως πηγή εποπτείας τμηματοποίησης μεγάλης κλίμακας. Αυτά τα μοντέλα, ωστόσο, έχουν αξιολογηθεί κυρίως στα σύνολα δοκιμών εντός του τομέα (βασισμένα στη Βικιπαίδεια), αποτρέποντας συμπεράσματα σχετικά με τη γενική αποτελεσματοποίηση τους. Στην παρούσα εργασία εστιάζουμε στην απόδοση μεταφοράς τομέων της εποπτευόμενης τμηματοποίησης νευρικού κειμένου στον εκπαιδευτικό τομέα. Για το σκοπό αυτό, εισάγουμε πρώτα το ένα νέο σύνολο δεδομένων για την αξιολόγηση της εποπτευόμενης τμηματοποίησης, το οποίο δημιουργήθηκε από εκπαιδευτικό υλικό ανάγνωσης για μαθητές βαθμού-1 σε κολεγιακό επίπεδο. Στη συνέχεια, αξιολογούμε ένα ιεραρχικό μοντέλο τμηματοποίησης κειμένου (HITS), βασισμένο στο RoBERTa, τόσο σε πειράματα τμηματοποίησης εντός τομέα όσο και μεταφοράς τομέα. Ενώ το HITS παράγει υπερσύγχρονες επιδόσεις στον τομέα (σε τρία δοκιμαστικά σύνολα βασισμένα στη Βικιπαίδεια), αποδεικνύουμε ότι, υπό την προϋπόθεση της τυπικής πλήρους τελειοποίησης, είναι επιρρεπής σε υπερπροσαρμογή του τομέα. Αναγνωρίζουμε τη ρύθμιση που βασίζεται στον προσαρμογέα ως θεραπεία που βελτιώνει σημαντικά την απόδοση μεταφοράς.', 'hu': 'A hagyományos, felügyelet nélküli szövegszegmentációs módszerekkel ellentétben a legutóbbi felügyelt szegmentációs modellek a Wikipédiára támaszkodnak, mint a nagyszabású szegmentációs felügyelet forrására. Ezeket a modelleket azonban elsősorban a domain (Wikipedia alapú) tesztkészleteken értékelték, megakadályozva a következtetéseket az általános szegmentációs hatékonyságukról. Ebben a munkában a felügyelt neurális szövegszegmentáció domain transzfer teljesítményére összpontosítunk az oktatási területen. Ennek érdekében először bemutatjuk a K12Seg-et, a felügyelt szegmentáció értékeléséhez szükséges új adatkészletet, amely az első osztályú hallgatók oktatási olvasóanyagából készült. Ezután összehasonlítjuk a RoBERTa alapján lévő hierarchikus szövegszegmentációs modellt (HITS), mind a domain-transzfer szegmentációs kísérletekben. Míg a HITS a legkorszerűbb domain teljesítményt biztosítja (három Wikipédia alapú tesztkészleten), megmutatjuk, hogy a szabványos finomhangolásnak megfelelően érzékeny a domain túlterhelésére. Az adapter alapú finomhangolást olyan orvosságként határozzuk meg, amely jelentősen javítja az átviteli teljesítményt.', 'ka': 'ტრადიციონალური არსუპერვისტურებული ტექსექმენტის მეტისთან განსხვავებულია, ახალი მონაცემულია სექმენტის მოდელები ვიკიპედიაზე იქნება, როგორც დიდი სიგემ მაგრამ ეს მოდელები უფრო დიომინში (Wikipedia-based) ტესტის კონფიგურაციის კონფიგურაციის შესახებ წარმოდგენების შესახებ. ამ სამუშაოში, ჩვენ კონსტუკურებულია მონაცემული ნეიროლური ტექსექსექსექტის სექსექსექტის მონაცემზე. ამ დასაწყისთვის, ჩვენ პირველად K12Seg-ს, ახალი მონაცემების კონფიგურაციის განსაზღვრებისთვის ახალი მონაცემების კონფიგურაციის შესახებ, რომელიც შექმნა განაზღვრებული კითხვის შემდეგ ჩვენ იერაქტიკალური ტექსემენტის სექმენტის მოდელი (HITS), რობერტაზე ბაზიანდა, რომელიც დიომინში და დიომინის გადატანსტის ექსემენტებში. თუმცა HITS მოქმედება სამყარო სურათის კონფიგურაციას (სამყარო ვიკიპედიაში დაბათებული ტესტის კონფიგურაციას), ჩვენ გამოჩვენებთ, რომ, სტანდარტული სურათების კონფიგურაციას მიხედვით, ეს ჩვენ იდენტიფიკაცით აპეტრუტერის დაფართებული კონფიგურაცია როგორც სწორედ გაუქმედება ტრანფიგურაცია.', 'kk': 'Дәстүрлі мәтін сегментациялау әдістерінің қасиеті, жаңа бақылаған сегментациялау үлгілі сегментациялау үлгісінің көзі ретінде Википедияда тұрады. Бұл үлгілер әдетте доменге (Википедия негізінде) сынақтар бағдарламасында бағалады, олардың жалпы сегментациялық эффективносты туралы шешімдерін сақтауға болады. Бұл жұмыс ішінде білім беру доменіндегі невралдық мәтін сегментациясының доменін аудару әрекетіне көздейміз. Бұл үшін біріншіден біріншіден K12Seg- ді, бақылаған сегментацияны бақылау үшін, 1- сынып колледж деңгейіндегі студенттердің оқу материалынан құрылған жаңа деректер жиынын таныстық. Содан кейін, RoBERTa негізінде, доменге және доменге аудару сегментациялық эксперименттерінде иерархиялық мәтін сегментациялық үлгісін (HITS) белгілейміз. HITS домендегі суреттердің күйін (үш Википедияға негізделген сынақ баптауларында) шығарып жатқанда, біз стандартты толық жақсы баптауға сәйкес келеді дегенді көрсеткіземіз, ол доменге ауыстыруға мүмкін болады. Біз адаптердің негізінде жақсы баптауларын таңдаймыз, көмектесу жұмысын жақсарту үшін.', 'it': "A differenza dei tradizionali metodi di segmentazione del testo non supervisionati, i recenti modelli di segmentazione supervisionata si basano su Wikipedia come fonte di supervisione della segmentazione su larga scala. Questi modelli, tuttavia, sono stati valutati prevalentemente sui set di test in-domain (basati su Wikipedia), impedendo conclusioni sulla loro efficacia generale di segmentazione. In questo lavoro, ci concentriamo sulle prestazioni di trasferimento del dominio della segmentazione neurale supervisionata del testo nel dominio educativo. A tal fine, introduciamo K12Seg, un nuovo dataset per la valutazione della segmentazione supervisionata, creato da materiale didattico di lettura per studenti di grado 1 a livello universitario. Successivamente analizziamo un modello gerarchico di segmentazione del testo (HITS), basato su RoBERTa, sia in esperimenti di segmentazione in-domain che di trasferimento di dominio. Mentre HITS produce prestazioni in-domain all'avanguardia (su tre set di test basati su Wikipedia), mostriamo che, soggetto alla messa a punto standard completa, è suscettibile al sovrafitting del dominio. Identifichiamo la messa a punto basata sull'adattatore come rimedio che migliora notevolmente le prestazioni di trasferimento.", 'ms': 'Tidak seperti kaedah segmentasi teks tradisional tidak diawasi, model segmentasi yang diawasi baru-baru ini bergantung pada Wikipedia sebagai sumber pengawasan segmentasi skala besar. Model ini, bagaimanapun, kebanyakan telah diuji pada set ujian dalam-domain (berdasarkan Wikipedia), mencegah kesimpulan mengenai kegunaan segmen umum mereka. Dalam kerja ini, kita fokus pada prestasi pemindahan domain segmen teks saraf yang dikendalikan dalam domain pendidikan. Untuk tujuan ini, kita pertama kali memperkenalkan K12Seg, set data baru untuk penilaian segmen yang diawasi, dicipta dari bahan pembacaan pendidikan untuk gred-1 ke pelajar-pelajar-tahap kolej. Kemudian kita menandakan model segmen teks hierarkis (HITS), berdasarkan RoBERTa, dalam percubaan segmen dalam domain dan pemindahan domain. Sementara HITS menghasilkan prestasi-state-of-the-art dalam domain (pada tiga set ujian berasaskan Wikipedia), kami menunjukkan bahawa, subjek kepada penyesuaian-sempurna-sempurna piawai, ia susah untuk penyesuaian domain berlebihan. Kami mengenalpasti penyesuaian berasaskan penyesuaian sebagai ubat yang meningkatkan prestasi pemindahan.', 'ml': 'സൂക്ഷിച്ചിട്ടില്ലാത്ത പദാവലി സംരക്ഷണ മാറ്റങ്ങള്\u200dക്ക് വ്യിക്കിപീഡിയയില്\u200d ആശ്രയിക്കുന്നു, അടുത്തുതന്നെ നിരീക്ഷിക്കപ്പെട്ട സ ഈ മോഡലുകള്\u200d പ്രധാനപ്പെട്ടിരിക്കുന്നു (വിക്കിപിഡിയയുടെ അടിസ്ഥാനത്ത്) ടെസ്റ്റ് സജ്ജീകരണങ്ങളില്\u200d (വിക്കിപിഡിയയില്\u200d) നിര്\u200d ഈ ജോലിയില്\u200d, വിദ്യാഭ്യാസത്തിന്റെ ഡൊമെയിനില്\u200d നിരീക്ഷിക്കപ്പെട്ട പാഠങ്ങളുടെ പ്രഭാവം നമ്മള്\u200d ശ്രദ്ധിക്കുന്ന ഈ അവസാനത്തിന് ആദ്യം കെ12സെഗിനെ പരിചയപ്പെടുത്തുന്നു. നിരീക്ഷിക്കപ്പെട്ട വിദ്യാഭാഷ വായിക്കുന്ന വസ്തുക്കളില്\u200d നിന്നും കോളേജ് നില വിദ പിന്നീട് റോബെര്\u200dട്ടാ അടിസ്ഥാനമായ ഒരു ഹീരാര്\u200dച്ചിക്കല്\u200d ടെക്സ്റ്റ് സെഗ്മെന്റേഷന്\u200d മോഡല്\u200d ഞങ്ങള്\u200d ബെന്\u200dച്മാര്\u200dക്ക് ചെയ്യുന്നു. ഡൊ എച്ചിട്സ് ഡൊമെയിനിലെ ആര്\u200dട്ടിന്\u200dറെ സ്റ്റേറ്റ് സ്റ്റേറ്റ് ഓഫ് സ്റ്റേറ്റ് (മൂന്നു വിക്കിപ്പിഡിയയില്\u200d അടിസ്ഥാനമായ പരീക്ഷണസെറ്റുകളില്\u200d) ഉണ്ടാ നമ്മള്\u200d അഡാപ്റ്റര്\u200d അടിസ്ഥാനത്തിലുള്ള സുന്ദരിയുടെ തിരിച്ചറിയുന്നത് മാറ്റങ്ങളുടെ പ്രവര്\u200dത്തനത്തിന് മ', 'lt': 'Priešingai nei tradiciniai nepastebimi teksto segmentacijos metodai, neseniai prižiūrimi segmentacijos modeliai priklauso nuo Wikipedia kaip didelio masto segmentacijos priežiūros šaltinio. Vis dėlto šie modeliai daugiausia buvo įvertinti vietoje (Wikipedia-based) bandymų rinkiniais, užkertant kelią išvadoms dėl bendro jų segmentacijos veiksmingumo. Šiame darbe daugiausia dėmesio skiriame kontroliuojamos nervinių tekstų segmentacijos švietimo srityje srities perdavimo rezultatams. Šiuo tikslu pirmiausia pristatysime K12Seg, naują duomenų rinkinį, skirtą kontroliuojamos segmentacijos vertinimui, sukurtą iš švietimo skaitymo medžiagos pirmojo lygio studentams iki koledžo lygio studentų. Tuomet lyginame hierarchinį teksto segmentacijos model į (HITS), pagrįstą RoBERTa, tiek domeno, tiek domeno perdavimo segmentacijos eksperimentuose. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting.  We identify adapter-based fine-tuning as a remedy that substantially improves transfer performance.', 'no': 'I motsetjing til tradisjonelle ugjennomsiktige tekstsegmentasjonsmetodar, nyleg oversikte segmentasjonsmetodar er på Wikipedia som kjelden for stor skala segmentasjonssovervaking. Desse modelane har imidlertid hovudsakelig evaluert på testsettet i domenet (Wikipedia-basert), og hindrar konklusjonar om det generelle segmenteringseffektiviteten. I denne arbeiden fokuserer vi på domeneoverføringen av oversikt neuraltekstsegmentasjon i utdannelsesdomenet. I denne slutten introdusere vi først K12Seg, eit nytt dataset for evaluering av oversikta segmentasjon, oppretta frå utdannelsesmateriell for studentar i nivå 1 til universitet. Vi benchmarkerer så ein hierarkisk tekstsegmentasjonsmodul (HITS), basert på RoBERTa, i både i domene og domeneoverføringsformer. Mens HITS produksjonar status-of-the-art in-domain performance (på tre Wikipedia-baserte testsett), viser vi at, ved hjelp av standard full-blown fine-tuning, er det viktig til domeneoverfitting. Vi identifiserer adapteringsbasert finnstilling som eit rettaring som forbetrar overføringsfunksjonen.', 'mk': 'За разлика од традиционалните ненадгледувани методи на сегментација на текст, неодамнешните надгледувани модели на сегментација се потпираат на Википедија како извор на големо надгледување на сегментацијата. Сепак, овие модели претежно беа проценети на тестовите во домен (базирани на Википедија), спречувајќи заклучоци за нивната генерална ефективност на сегментацијата. Во оваа работа, се фокусираме на пренесувањето на доменот на надгледуваната сегментација на нервниот текст во образовниот домен. За ова, првпат го воведуваме K12Seg, нов набор на податоци за проценка на надгледуваната сегментација, создаден од образовен материјал за читање за студенти од прво одделение до студенти на колеџ. Потоа го споредуваме хиерархичниот модел на текст сегментација (ХИТС), базиран на RoBERTa, во експериментите за сегментација во домен и во домен-трансфер. И покрај тоа што ХИТС произведува најнови резултати во доменот (на три тестови базирани на Википедија), покажуваме дека, под услов на стандардното целосно финетизирање, е чувствително на преприспособување на доменот. Ние го идентификуваме подобрувањето на адаптерот како лек кој значително ја подобрува перформансата на трансферот.', 'pl': 'W przeciwieństwie do tradycyjnych metod segmentacji tekstu bez nadzoru, najnowsze modele segmentacji nadzorowanej opierają się na Wikipedii jako źródłu nadzoru segmentacji na dużą skalę. Modele te zostały jednak ocenione głównie na zestawach testów w domenie (opartych na Wikipedii), co uniemożliwia wnioski o ich ogólną skuteczność segmentacji. W niniejszej pracy skupiamy się na wydajności transferu domen nadzorowanej segmentacji tekstu neuronowego w domenie edukacyjnej. W tym celu najpierw wprowadzamy K12Seg, nowy zestaw danych służący ocenie nadzorowanej segmentacji, stworzony z materiałów edukacyjnych dla studentów klasy 1 do studiów. Następnie porównujemy hierarchiczny model segmentacji tekstu (HITS), oparty na RoBERTa, zarówno w eksperymentach segmentacji wewnątrz domeny, jak i transferu domeny. Podczas gdy HITS produkuje najnowocześniejszą wydajność w domenie (na trzech zestawach testowych opartych na Wikipedii), pokazujemy, że pod warunkiem standardowego pełnego dostrojenia, jest on podatny na nadmierne dopasowanie domeny. Identyfikujemy dostosowanie oparte na adapterze jako środek zaradczy, który znacznie poprawia wydajność transferu.', 'ro': 'Spre deosebire de metodele tradiționale de segmentare a textului nesupravegheate, modelele recente de segmentare supravegheată se bazează pe Wikipedia ca sursă de supraveghere a segmentării pe scară largă. Cu toate acestea, aceste modele au fost evaluate în principal pe seturile de teste în domeniu (bazate pe Wikipedia), prevenind concluziile cu privire la eficacitatea segmentării lor generale. În această lucrare, ne concentrăm pe performanța transferului domeniului de segmentare a textului neural supravegheat în domeniul educațional. În acest scop, introducem mai întâi K12Seg, un nou set de date pentru evaluarea segmentării supravegheate, creat din materiale educaționale de lectură pentru studenții de clasa 1 la nivel de colegiu. Apoi vom compara un model ierarhic de segmentare a textului (HITS), bazat pe RoBERTa, atât în experimentele de segmentare în domeniu, cât și în experimentele de transfer de domeniu. În timp ce HITS produce performanțe de ultimă generație în domeniu (pe trei seturi de teste bazate pe Wikipedia), arătăm că, sub rezerva reglării fine standard complete, este susceptibil la suprasolicitarea domeniului. Identificam reglarea fină bazată pe adaptor ca un remediu care îmbunătățește în mod substanțial performanța de transfer.', 'mt': 'Għall-kuntrarju tal-metodi tradizzjonali ta’ segmentazzjoni tat-testi mhux sorveljati, mudelli ta’ segmentazzjoni sorveljati reċenti jiddependu fuq Wikipedia bħala s-sors ta’ superviżjoni ta’ segmentazzjoni fuq skala kbira. Madankollu, dawn il-mudelli ġew evalwati fil-biċċa l-kbira fuq is-settijiet tat-testijiet in-domain (ibbażati fuq Wikipedia), li jipprevjenu konklużjonijiet dwar l-effikaċja tas-segmentazzjoni ġenerali tagħhom. In this work, we focus on the domain transfer performance of supervised neural text segmentation in the educational domain.  Għal dan il-għan, l-ewwel a ħna jintroduċu K12Seg, sett ġdid ta’ dejta għall-evalwazzjoni tas-segmentazzjoni sorveljata, maħluq minn materjal edukattiv tal-qari għall-istudenti tal-grad 1 sal-livell tal-kulleġġ. Imbagħad nagħmlu referenza għal mudell ta’ segmentazzjoni tat-test ġerarkiku (HITS), ibbażat fuq RoBERTa, kemm f’esperimenti ta’ segmentazzjoni fid-dominju kif ukoll ta’ trasferiment fid-dominju. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting.  Aħna nidentifikaw l-irfinar ibbażat fuq l-adattaturi bħala rimedju li jtejjeb sostanzjalment il-prestazzjoni tat-trasferiment.', 'si': 'සාමාන්\u200dය විශේෂ නැති පාළුවන් සැකම් විදියට වෙනස් නැති විදියට, අලුත් පරීක්ෂා විදියට සැකම් විදියම් විදියප නමුත්, මේ මොඩේල්ස් වලින් ප්\u200dරධානයෙන් විදිහට පරීක්ෂා සැටීම් වලින් පරීක්ෂා කරලා තියෙනවා, ඔවුන්ගේ සාමාන්\u200dය සැකසුම මේ වැඩේ අපි පරීක්ෂා කරලා තියෙන්නේ න්\u200dයූරාල් පාළුවන්ගේ පරීක්ෂණ පැත්තක් සැකසුම් වලට ප්\u200dරධාන මේ අවසානයට, අපි මුලින්ම K12Sec විදිහට අළුත් දත්ත සෙට් විදිහට පරීක්ෂා කරලා තියෙන්නේ, පරීක්ෂා කරලා තියෙන්නේ අලුත් දත් අපි ඊට පස්සේ බෙන්ච්මාර්ක් කරන්නේ අයිරාක්ෂිකල් පාළුවක් සැකම්පන් මොඩල් (HITS), RoBERTa විසින්, ඩොමේන් වලින් සහ ඩොම HITS නිර්මාණය කරන්නේ විකිපිඩියා තුනක් පරීක්ෂණ සෙට් වලින්, අපි පෙන්වන්නේ ඒක, ප්\u200dරමාණය සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ ස අපි ඇඩාප්ටර් අධිරූපකයෙන් හොඳ සුද්ධියක් හඳුනාගන්නවා ඒක විශේෂයෙන් ප්\u200dරවේශනයක් වැඩ කරනවා.', 'mn': 'Ууламжлалт хэлбэргүй текст хэлбэрийн арга шиг, саяхан удирдагдсан хэлбэрийн загварын загварууд нь том хэмжээний хэлбэрийн удирдах эх үүсвэртэй Wikipedia дээр байдаг. Гэхдээ эдгээр загварууд ихэвчлэн холбоотой (Википедиа-based) шалгалтын хэлбэрээр дүгнэлттэй болсон. Тэдний ерөнхий хэлбэрийн эффективност талаар шийдвэрлэхийг зогсоож байна. Энэ ажлын тухай бид сургууль боловсролын хэлбэрээр удирдлагатай мэдрэлийн текст хэлбэрийг дамжуулах үйл ажиллагаанд анхаарлаа хандуулдаг. Энэ төгсгөлд бид анх K12Seg-г, удирдлагатай загварын үнэлэх шинэ өгөгдлийн санг танилцуулж, 1-р ангид сургуулийн оюутнуудаас боловсрол унших материалээс бүтээсэн. Дараа нь бид RoBERTa-ын үндсэн гиерархик текст загварын загварын загварыг хоёуланг нь хоёуланг болон домжны шилжүүлэх загварын туршилт дээр багтана. ХИТС нь холбоотой урлагийн үйл ажиллагааг (Wikipedia-д 3-р суурилсан шалгалтын багц дээр) бүтээж байхад бид стандарт бүрэн хөгжүүлэх шалгалтын тухай харуулж байна. Энэ нь холбоотой тохиромжтой байх боломжтой. Бид адаптер дээр суурилсан сайжруулах үйл ажиллагааг илүү сайжруулдаг сайжруулах засаг гэж тодорхойлдог.', 'so': 'Isku duwan qaababka kooxaha ah oo aan la ilaalinayn qoraalka qeybinta, qaababka lagu soo ilaaliyey ee ugu dambeeyay kooxaha qeybinta waxay isku halleeyaan Wikipedia, taas oo ah asalka ilaalinta kooxaha waaweyn. Si kastaba ha ahaatee tusaalahan waxaa marka ugu horeysa lagu qiimeeyay kooxda imtixaanka ee gudaha (Wikipedia) oo ka horumarinaya dhamaadka saameyn ku saabsan waxyaabaha guud ee qeybinta. Markaas waxan, waxaynu ku kalsoonaynaa sameynta wareejinta deegaanka ee qeybta qoraalka neurada ah oo lagu ilaaliyey goobta waxbarashada. Tan darteed marka ugu horeysa waxaynu K12Seg ka soo bandhignaynaa sawirada cusub ee lagu qiimeeyo qeybta la ilaaliyey, taas oo laga sameeyaa materialka akhriska waxbarashada fasalka-1 ilaa ardayda heerka jaamacadda. Markaas waxaynu soo bandhignaynaa model xarunta qoraalka (HITS), oo ku saleysan RoBERTA, labada jirrabaadka gudaha iyo wadanka ku wareejinta gudaha. Inta uu HITS sameeyo xaalada farshaxanka ee gudaha (sadex saxanka ee Wikipedia), waxaynu muujinaynaa in lagu hoos dhigo sawir-horumar oo dhan, waxaa shaki looga yaabaa in domain la soo dhaafo. Waxaynu ku garanaynaa hab-bedelka oo ku saleysan hab-bedelka, kaas oo horumarinaya tababarka bedelka.', 'sv': 'Till skillnad från traditionella icke-övervakade textsegmenteringsmetoder förlitar sig nyligen på Wikipedia som källan till storskalig segmenteringsövervakning. Dessa modeller har dock huvudsakligen utvärderats på domänbaserade (Wikipedia-baserade) testuppsättningar, vilket förhindrar slutsatser om deras generella segmenteringseffekt. I detta arbete fokuserar vi på domänöverföringsprestanda för övervakad neural textsegmentering inom utbildningsområdet. För detta ändamål introducerar vi först K12Seg, en ny datauppsättning för utvärdering av övervakad segmentering, skapad från läromedel för årskurs 1 till högskolestudenter. Sedan benchmarkar vi en hierarkisk textsegmenteringsmodell (HITS), baserad på RoBERTa, i både in-domain och domain-transfer segmenteringsexperiment. Även om HITS producerar toppmoderna prestanda inom domänen (på tre Wikipedia-baserade testuppsättningar), visar vi att det, med förbehåll för den vanliga fullblåsta finjusteringen, är känsligt för domänövertillning. Vi identifierar adapterbaserad finjustering som ett botemedel som avsevärt förbättrar överföringsprestanda.', 'sr': 'Za razliku od tradicionalnih neodređenih metoda segmentacije teksta, nedavno nadzirani modeli segmentacije oslanjaju se na Wikipedia kao izvor velike segmentacije nadzora. Međutim, ovi modeli su uglavnom procijenjeni na testovim setima na domenu (na Wikipedia-based), sprečavajući zaključke o njihovoj općej efikasnosti segmentacije. U ovom poslu, fokusiramo se na provedbu prijenosa domena nadzornog segmentacije neuronskog teksta u obrazovnom domenu. Za taj cilj, prvi put predstavljamo K12Seg, novi set podataka za procjenu nadzorne segmentacije, stvoren iz obrazovnog materijala za čitanje studenata nivoa 1. do nivoa fakulteta. Onda smo naveli hijerarhički model segmentacije teksta (HITS), zasnovan na RoBERTi, u eksperimentima u domenu i premeštaju domena. Iako HITS proizvodi stanje umjetnosti u domenu (na tri testa bazirane na Wikipedia), pokazujemo da je pod uslovom standardnog punog ispunjenog fino-tuniranja poduzetni prema domenu. Identificiramo ispravnu prilagodbu na osnovu adapter a kao remeku koja značajno poboljšava izvedbu prijenosa.', 'ta': 'பாரம்பரிய பாதுகாப்பாக்கப்படாத உரை துண்டு முறைகளை மாற்றுகிறது, சமீபத்தில் கண்காணிக்கப்பட்ட துண்டு மாதிரிகள் விகிபிடியாவின் மூலம் பெ இந்த மாதிரிகள் பொதுவான துண்டு விகிபிடியா சோதனையின் அமைப்பில் முக்கியமாக மதிப்பிடப்பட்டுள்ளது, முடிவுகளை தடுக்கிறது. இந்த வேலையில், கல்வி தளத்தில் கண்காணிக்கப்பட்ட புதிய உரை துண்டு பிரிவின் களம் மாற்றும் செயல்பாட்டை நாம் கவனம் செலு இந்த முடிவிற்கு, நாம் முதலில் K12Seg, கண்காணிக்கப்பட்ட துண்டுகளை evaluation புதிய தகவல் அமைப்பை குறிப்பிடுகிறோம், கல்லூரி நிலையில் மாணவர் We then benchmark a hierarchical text segmentation model (HITS), based on RoBERTa, in both in-domain and domain-transfer segmentation experiments.  HITS - டொமைன் செயல்பாட்டின் நிலையை உருவாக்குகிறது (மூன்று விகிபிடியா சோதனைக்கு அடிப்படையில்) நாம் காட்டுகிறோம், நிலையான முழு பறக்கப்பட்ட நன்மைக நாம் அடிப்படையில் அடிப்படையான சரியான தூண்டுதலை கண்டுபிடிக்கிறோம் மாற்றும் செயல்பாட்டை மேம்படுத்து', 'ur': 'غیر منطقی متخصص متخصص متخصص طریقوں کے مطابق، اچھے متخصص متخصص متخصص متخصص ویکیپیڈیا پر بڑی سیگنٹ سپکٹ سپکٹ سپکٹ نظر کے سورج کے طور پر اعتماد رکھتے ہیں لیکن یہ موڈلز ڈومین (ویکیپیڈیا-بنیاد) کی آزمائش سٹیوں پر اکثریت کا ارزش کیا گیا ہے، اور ان کے سارے سٹمنٹ کے اثرات کے بارے میں نتیجے کو روکتے ہیں. اس کام میں ہم ڈومین ترنسیٹ فعالیت پر تمرکز کر رہے ہیں تحصیل ڈومین میں نیورال ٹیکسٹ سکیٹ سیگنٹ کے ذریعہ۔ اس کے لئے ہم پہلی بار K12Seg کو پہنچاتے ہیں، ایک نئی ڈاٹ سٹ، جو نظارت یافتہ سٹمنٹ کی ارزیابی کے لئے ہے، جو کلاس-1 تک کالج سٹمنٹ کے لئے تعلیم پڑھنے کے مواد سے پیدا کیا گیا ہے۔ پھر ہم نے روBERTA پر بنچم لیا ایک ہیراریک ٹیکسٹ سیگنٹ موڈل (HITS) ہے، دونوں دامین میں اور دامین-ترنس سیگنٹ سیگنٹ آزمائش میں۔ While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting. ہم اڈپٹر کی بنیاد پاکیزہ تنظیم کو ایک رسمی کے طور پر پہچان دیتے ہیں جو انتقال کی عملکرد زیادہ بہتر کر دیتا ہے.', 'uz': "@ info: whatsthis Ammo, bu modellar hozirga, vikipedia (Wikipedia) sinov sonlarida qiymat qilingan, ularning umumiy bog'lash effektini oldini oldin. Bu ishda, biz ta'lim domenadagi neyrolik matnning bir qismlarini boshqarish natijasida foydalanamiz. Bu oxiriga, biz birinchi marta K12Seg, birinchi taʼminlovchi qiymatni o'rganish uchun yangi maʼlumotlar tarkibini o'rganamiz, ta'lim o'qish materialini 1 daraja-1 darajaga o'quvchi maktab o'quvchilariga o'rganish. Keyin biz RoBERTA asosida sahierarchik matn qismlash modelini (HITS) yaratdik, domen va domen- transfer qismlarini ajratish imtiyozlarida. HITS hodisa domen sohasida (uchta Wikipedia-asosida) bajarayotganda, biz oddiy soʻzni to ʻxtatish tugmasini ko'rsatganimiz, bu domen ajratishga murakkab bo'ladi. Biz adaptor asosida yaxshi suhbatni ko'rsatuvchimiz, biz o'zgarishning vazifasini katta yaxshi ko'ra oladi.", 'vi': 'Không giống các phương pháp phân chia văn bản truyền thống không được giám sát, các mô hình giám sát gần đây dựa trên Wikipedia là nguồn dẫn chứng phân chia lớn. Những mẫu này, tuy nhiên, đã được đánh giá chủ yếu trên hệ thống thử nghiệm (Wikipedia) để ngăn những kết luận về hiệu quả phân biệt chung. Trong công việc này, chúng tôi tập trung vào khả năng truyền tải miền của phân chia văn bản thần kinh giám sát trong lĩnh vực giáo dục. Để đạt được mục đích đầu tiên, chúng tôi giới thiệu K12Sege, một tập tin mới để đánh giá phân chia giám sát, được tạo ra từ vật liệu đọc giáo dục cho học sinh cấp 1 đến cấp cao. Sau đó, chúng ta tiêu chuẩn mô hình phân chia văn bản cấp bậc phân loại thứ cấp (HITS) dựa trên RoerTa, trong cả hai thí nghiệm phân chia miền và miền-truyền. Trong khi HITS sản xuất xuất xuất xuất trình độ cao nhất trong miền (trong ba bộ thử trên Wikipedia) chúng tôi cho thấy rằng, với sự tinh chỉnh to àn bộ tiêu chuẩn, nó dễ bị quá tải. Chúng tôi nhận diện độ cẩn thận thích ứng, như một phương thuốc cải thiện khả năng chuyển nhượng.', 'nl': 'In tegenstelling tot traditionele niet-begeleide tekstsegmentatiemethoden vertrouwen recente begeleide segmentatiemodellen op Wikipedia als de bron van grootschalige segmentatietoezicht. Deze modellen zijn echter voornamelijk geëvalueerd op de in-domain (Wikipedia-gebaseerde) testsets, waardoor conclusies over hun algemene segmentatieeffectiviteit worden voorkomen. In dit werk richten we ons op de domeintransferprestaties van begeleide neurale tekstsegmentatie in het onderwijsdomein. Hiervoor introduceren we eerst K12Seg, een nieuwe dataset voor de evaluatie van begeleide segmentatie, gemaakt van educatief leesmateriaal voor klas-1 studenten tot college-level studenten. Vervolgens benchmarken we een hiërarchisch tekstsegmentatiemodel (HITS), gebaseerd op RoBERTa, in zowel in-domein als domein-transfer segmentatie experimenten. Hoewel HITS state-of-the-art in-domain prestaties produceert (op drie Wikipedia-gebaseerde testsets), tonen we aan dat, behoudens de standaard full-blown fine-tuning, het gevoelig is voor domein overfitting. We identificeren adaptergebaseerde finetuning als een remedie die de overdrachtsprestaties aanzienlijk verbetert.', 'bg': 'За разлика от традиционните методи за сегментация на текста без надзор, последните модели на надзорна сегментация разчитат на Уикипедия като източник на широкомащабен надзор върху сегментацията. Тези модели обаче са оценени предимно на вътрешните (базирани на Уикипедия) тестови комплекти, предотвратявайки заключенията за тяхната обща ефективност на сегментиране. В тази работа се фокусираме върху изпълнението на трансфера на домейна на контролираната нервна текстова сегментация в образователната област. За тази цел първо въвеждаме нов набор от данни за оценка на контролираната сегментация, създаден от учебни материали за четене за ученици от първи клас до колежански. След това сравняваме йерархичен модел на сегментация на текста (HITS), базиран на РоBERTa, както в експериментите за сегментация в домейн, така и в трансфер на домейн. Докато ХИТС произвежда най-съвременно представяне в областта (на три базирани на Уикипедия тестови комплекта), ние показваме, че при стандартно пълно усъвършенстване, той е податлив на пренасочване на домейна. Ние идентифицираме фината настройка на базата на адаптер като средство за защита, което значително подобрява ефективността на трансфера.', 'de': 'Im Gegensatz zu herkömmlichen Methoden der unbeaufsichtigten Textsegmentierung stützen sich aktuelle überwachte Segmentierungsmodelle auf Wikipedia als Quelle der großflächigen Segmentierungsüberwachung. Diese Modelle wurden jedoch vorwiegend an den in-domain (Wikipedia-basierten) Testsets evaluiert, was Rückschlüsse auf ihre allgemeine Segmentierungswirksamkeit verhindert. In dieser Arbeit konzentrieren wir uns auf die Domänentransferleistung der überwachten neuronalen Textsegmentierung im Bildungsbereich. Zu diesem Zweck stellen wir zuerst K12Seg vor, einen neuen Datensatz zur Bewertung der überwachten Segmentierung, der aus pädagogischem Lesematerial für Schüler der ersten Klasse bis zum College erstellt wurde. Anschließend benchmarken wir ein hierarchisches Textsegmentierungsmodell (HITS), basierend auf RoBERTa, sowohl in Domänen- als auch in Domänen-Transfer-Segmentierungsexperimenten. Während HITS hochmoderne In-Domain-Performance produziert (auf drei Wikipedia-basierten Testsets), zeigen wir, dass es vorbehaltlich der standardmäßigen Full-Blow-Feinabstimmung anfällig für Domain Overfitting ist. Wir identifizieren adapterbasiertes Feintuning als Abhilfe, das die Übertragungsleistung erheblich verbessert.', 'hr': 'Za razliku od tradicionalnih neodređenih metoda segmentacije teksta, nedavno nadzirani modeli segmentacije oslanjaju se na Wikipedia kao izvor velike segmentacije nadzora. Međutim, ovi modeli su uglavnom procijenjeni na testovima na domenu (na Wikipedia-based), sprečavajući zaključke o njihovoj općej djelotvornosti segmentacije. U ovom poslu, fokusiramo se na provedbu prijenosa domena nadziranog segmentacije neuronskog teksta u obrazovnom domenu. Za taj cilj, prvi put predstavljamo K12Seg, novi set podataka za procjenu nadziranog segmentacije, stvoren iz obrazovnog materijala čitanja za studente razine 1. do razine fakulteta. Onda smo navodili hijerarhički model segmentacije teksta (HITS), zasnovan na RoBERTi, u eksperimentima u domenu i premještaju domena. Iako HITS proizvodi postupak umjetnosti u domenu (na tri kompleta ispitivanja na Wikipedia-u), pokazujemo da je pod uslovom standardnog punog punog ispitivanja osjetljiv prema domenu. Identificiramo ispravnu prilagođavanje na temelju adapter a kao lijek koji značajno poboljšava učinkovitost prijenosa.', 'fa': 'برخلاف روش جدا کردن متن غیرقانونی سنتی، مدل جدا کردن نظارت شده اخیر به ویکیپدیا به عنوان منبع نظارت جدا کردن مقیاس بزرگ اعتماد دارد. ولی این مدلها بیشتر در مجموعه\u200cهای آزمایش در دومین (بر ویکیپدیا) ارزیابی می\u200cشوند، که از نتیجه\u200cها در مورد فعالیت بخش عمومی آنها جلوگیری می\u200cکنند. در این کار، ما روی فعالیت انتقال دامنی متن عصبی تحت نظر قرار گرفتیم. برای این پایان، اولین بار K12Seg را معرفی کردیم، یک مجموعه اطلاعات جدید برای ارزیابی از بخش\u200cهای تحقیق شده، از مواد خواندن آموزشی برای دانشجویان درجه ۱ تا سطح دانشجویان ساخته شده است. سپس ما یک مدل جدا کردن متن (HITS) به عنوان روبرتا، در آزمایش\u200cهای جدا کردن دامنی و ترکیب دامنی را ترکیب می\u200cکنیم. در حالی که HITS فعالیت موقعیت هنری در دومین (بر سه مجموعه آزمایش بنیاد ویکیپدیا) تولید می\u200cکند، ما نشان می\u200cدهیم که، در موقعیت آزمایش کامل استاندارد، آن به دومین متفاوت است. ما به عنوان دارویی که عملکرد انتقال را عمده\u200cای بهتر می\u200cکند، تعریف\u200cکننده\u200cای بر اساس adapter-based fine tuning را شناسایی می\u200cکنیم.', 'ko': '전통적인 무감독 텍스트 분할 방법과 달리 최근의 감독 분할 모델은 위키백과에 의존하여 대규모 분할 감독의 원천으로 한다.그러나 이러한 모델은 주로 역내(위키백과 기반) 테스트집에서 평가된 것이기 때문에 일반적인 분할 효과에 대한 결론을 얻을 수 없다.이 업무에서 우리는 교육 분야에서 신경 텍스트의 분할을 감독하는 분야의 전이 성능을 중점적으로 연구했다.이를 위해 먼저 K12Seg을 소개하는데 이것은 감독 분할을 평가하는 데 사용되는 새로운 데이터 집합으로 1학년부터 대학 수준의 학생들까지 교육독해자료로 만들어진 것이다.그런 다음 RoBERTA 기반 계층형 텍스트 분할 모델(HITS)에 대한 벤치마크 테스트를 도메인 내 및 도메인 이동 분할 실험에서 수행했습니다.HITS는 (위키백과 기반의 세 개의 테스트 모음에서) 가장 선진적인 분야 성능을 만들어 냈지만, 표준의 전면적인 미세조정에서 분야의 과도한 의합의 영향을 받기 쉽다는 것을 보여준다.우리는 어댑터를 바탕으로 하는 마이크로스피커는 전송 성능을 현저하게 향상시킬 수 있는 보완 조치라고 생각한다.', 'da': 'I modsætning til traditionelle ikke-overvågede tekstsegmenteringsmetoder er de seneste overvågede segmenteringsmodeller afhængige af Wikipedia som kilde til omfattende segmenteringsovervågning. Disse modeller er imidlertid overvejende blevet evalueret på de in-domæne (Wikipedia-baserede) testsæt, hvilket forhindrer konklusioner om deres generelle segmenteringseffektivitet. I dette arbejde fokuserer vi på domæneoverførsel ydeevne af overvåget neural tekstsegmentering i det uddannelsesmæssige domæne. Til dette formål introducerer vi først K12Seg, et nyt datasæt til evaluering af overvåget segmentering, skabt ud fra undervisningsmateriale til klasse 1 studerende på universitetsniveau. Vi benchmark derefter en hierarkisk tekstsegmenteringsmodel (HITS), baseret på RoBERTa, i både in-domæne og domæne-transfer segmenteringseksperimenter. Mens HITS producerer state-of-the-art inden for domænet ydeevne (på tre Wikipedia-baserede testsæt), viser vi, at det, med forbehold af den standard fuldt udblæste finjustering, er modtageligt for domæne overtilpasning. Vi identificerer adapterbaseret finjustering som et middel, der væsentligt forbedrer overførselsevnen.', 'tr': "D채pli g철zle첵채n metin segmentasy흫 첵체z체ni흫 첵aly, o흫ki g철zle첵채n segmentasy흫 nusgalary Wikipedi첵a be첵ik gabdalyk bejerimini흫 챌e힊mesi bolan 첵aly. 횦철ne bu nusgalar domenyda (Wikipedia-da tabanly) testi d체z체mlerinde de흫lendiril첵채r. 횦철ne bu nusgalar jemi segmentasi첵a etkinlik barada 챌철z체mlerini 챌ykaryp bilme첵채r. Bu i힊de, e휓itim alan캇nda g철zetlenmi힊 n철ral metin segmentasyonu흫 domeny aktarma eserini fokus ediyoruz. 힇onu흫 체챌in ilkinji gezek K12Seg'i, g철zetli segmentasi첵any흫 de흫lenmesi 체챌in t채ze bir datu setirini tany힊dyrdyk. I흫 s캇n캇ftan 1-nji synp okuw챌y okuw챌y okuw챌y 체챌in guruldy. Sonra RoBERTa da첵an첵ar, hem domain-da hem domain-g철챌체rme segmentasy deneylerinde bir hiyerar힊ik metin segmentasy nusgasyny 챌ykar첵arys. HITS domeny흫 durumyny ukyp ba힊ar첵an halkara (체챌 wikipedi첵a da첵an test setirlerinde) ukyp ed첵채n bolsa, biz bu domeny흫 체st체ne m체mkin d채ldigini g철rke첵채ris. Biz adat챌ylary흫 esasy ta첵첵arlanmagyny adat챌ylar ta첵첵arlanmagyny 철z체ne bir tabak bejer첵채ris we bu tabak ta첵첵arlanmagyny 철r채n gowy g철rkez.", 'sw': 'Tofauti na mbinu za kuchaguliwa kwa ujumbe usiohifadhiwa na utamaduni, modeli za vipengele hivi karibuni zinazofuatiliwa zinategemea Wikipedia kama chanzo cha kufuatiliwa kwa makundi makubwa. Hata hivyo, mifano hii imepitiwa kwa kiasi kikubwa kwenye seti za majaribio ya ndani (Wikipedia) na kuzuia matokeo kuhusu ufanisi wao kwa ujumla wa kujitenga. Katika kazi hii, tunajikita kwenye uwezekano wa usafirishaji wa maeneo ya ujumbe wa maandishi ya kijinsia katika maeneo ya elimu. Kwa mwisho huu, tunaanzisha K12Seg, kituo kipya cha takwimu cha kutathmini vipengele vya udhibiti, kilichotengenezwa kutoka vituo vya kusoma vya elimu kwa ajili ya darasa-1 hadi wanafunzi wa darasa la chuo. Kisha tunaweka mfumo wa kujitenga kwa ujumbe wa ujumbe (HITS), kwa kutumia RoBERTa, katika majaribio ya usafirishaji wa ndani na majaribio. Wakati UKIMWI unavyotengeneza hali ya sanaa ya ndani (kwenye seti tatu za majaribio ya Wikipedia), tunaonyesha kwamba, kwa kuzingatia ujumbe mzuri uliotumiwa kwa kiwango kikubwa, haina mashaka kwa kuingia ndani. We identify adapter-based fine-tuning as a remedy that substantially improves transfer performance.', 'sq': 'Ndryshe nga metodat tradicionale të segmentimit të tekstit të pazgjidhur, modelet e segmentimit të mbikqyrur kohët e fundit mbështeten në Wikipedia si burim i mbikqyrjes së segmentimit në shkallë të madhe. Këto modele, megjithatë, janë vlerësuar kryesisht në grupet e testeve në domeni (bazuar në Wikipedia), duke parandaluar përfundimet rreth efektshmërisë së tyre të përgjithshme të segmentimit. Në këtë punë, ne përqëndrohemi në performancën e transferimit të domenit të segmentimit të mbikqyrur të tekstit nervor në domenin arsimor. To this end, we first introduce K12Seg, a new dataset for evaluation of supervised segmentation, created from educational reading material for grade-1 to college-level students.  Ne pastaj përcaktojmë një model hierarkik të segmentimit të tekstit (HITS), bazuar në RoBERTa, në eksperimentet e segmentimit në domeni dhe në transferim në domeni. Ndërsa HITS prodhon shfaqjen më të lartë në domeni (në tre grupe testimi me bazë në Wikipedia), ne tregojmë se, nën përdorimin e rregullimit të plotë të standartit, është e ndjeshme për mbipajtimin e domenit. Ne identifikojmë rregullimin bazuar në adaptues si një mjet që përmirëson thelbësisht performancën e transferit.', 'hy': 'Ի տարբերություն ավանդական անվերահսկված տեքստի սեգմետրացիայի մեթոդներին, վերջերս վերահսկված սեգմետրացիայի մոդելները հիմնված են Վիքիփեդիայում որպես մեծ մասշտաբ սեգմետրացիայի վերահսկողության աղբյու Այնուամենայնիվ, այս մոդելները հիմնականում գնահատվել են տիեզերքում (Վիքիփեդիայում հիմնված) փորձարկումների համակարգերի վրա, կանխում են նրանց ընդհանուր սեգմետրացիայի արդյունավետության մասին եզրակացություններին: Այս աշխատանքում մենք կենտրոնանում ենք ուսուցման ոլորտում վերահսկվող նեյրոնային տեքստի սեգմետրացիայի արդյունքի վրա: Այսպիսով, մենք առաջին անգամ ներկայացնում ենք K12SEG-ը, նոր տվյալների համակարգը վերահսկված սեգմետրացիայի գնահատման համար, որը ստեղծվել է 1-րդ դասարանի ուսումնական կարդալու նյութերից մինչև համալսարանի ուսանողներ: Այնուհետև մենք համեմատում ենք հիերարխիկ տեքստի սեգմետրացիայի մոդելը (ՀիՏՍ), որը հիմնված է ՌոԲԵՌԹայի վրա, և բնագավառի և բնագավառի փոխանցման սեգմետրացիայի փորձերում: While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting.  Մենք սահմանում ենք ադապտերների հիմնված բարելավումը որպես միջոց, որը նշանակաբար բարելավում է փոխանցման արդյունքը:', 'id': 'Tidak seperti metode segmentasi teks tradisional yang tidak diawasi, model segmentasi yang diawasi baru-baru ini bergantung pada Wikipedia sebagai sumber pengawasan segmentasi skala besar. These models have, however, predominantly been evaluated on the in-domain (Wikipedia-based) test sets, preventing conclusions about their general segmentation efficacy.  Dalam pekerjaan ini, kami fokus pada prestasi transfer domain dari segmen teks saraf yang diawasi dalam domain pendidikan. Untuk tujuan ini, kami pertama kali memperkenalkan K12Seg, set data baru untuk evaluasi segmentasi yang diawasi, diciptakan dari bahan pembacaan pendidikan untuk kelas 1 ke siswa tingkat kuliah. Kemudian kita benchmark model segmentasi teks hierarkis (HITS), berdasarkan RoBERTa, dalam percobaan segmentasi dalam domain dan domain-transfer. Sementara HITS menghasilkan prestasi terbaik dalam domain (pada tiga set tes berdasarkan Wikipedia), kami menunjukkan bahwa, subjek untuk penyesuaian standar penuh, susceptible untuk overfitting domain. Kami mengidentifikasi penyesuaian berdasarkan adaptor sebagai obat yang meningkatkan prestasi transfer.', 'af': "Ongelyks van tradisionele ononderwerpende teks segmentasie metodes, het onlangse onderwerpende segmentasie modele op Wikipedia as die bron van groot- skaal segmentasie onderwerp. Hierdie modele het, egter, voordeel geevalueer op die in-domein (Wikipedia-gebaseerde) toets stelle, voorkom die conclusies oor hulle algemene segmentasie effektiviteit. In hierdie werk, ons fokus op die domein oordrag effektuur van superviseerde neurale teks segmentasie in die opvoeding domein. Na hierdie einde, ons introduseer eerste K12Seg, 'n nuwe datastel vir evaluering van ondersoekte segmentasie, geskep van opvoedkundige lees materiel vir grade- 1 tot kolleksievlak studente. Ons benchmark dan 'n hierarkies teks segmentasie model (HITS), gebaseer op RoBERTa, in beide in-domein en domein-oordrag segmentasie eksperimente. Terwyl HITS die staat-van-die-kuns in-domein-prestasie (op drie Wikipedia-gebaseerde toets stelle) produseer, wys ons dat, onderwerp na die standaard vol-blaas fyn-tuning, dit is aanvaardig na domein oorvloedig. Ons identifiseer adapter-gebaseerde fyn-tuning as 'n hersteling wat substantief verbeter oordrag-prestasie.", 'bs': 'Za razliku od tradicionalnih neodređenih metoda segmentacije teksta, nedavno nadzirani modeli segmentacije oslanjaju se na Wikipedia kao izvor velike segmentacije nadzora. Međutim, ovi modeli su uglavnom procijenjeni na testovim setima na domenu (na Wikipedia-based), sprečavajući zaključke o njihovoj općej djelotvornosti segmentacije. U ovom poslu, fokusiramo se na provedbu prijenosa domena nadziranog segmentacije neuronskog teksta u obrazovnom domenu. Za taj cilj, prvi put predstavljamo K12Seg, novi set podataka za procjenu nadzorne segmentacije, stvoren iz obrazovnog materijala čitanja za studente nivoa 1. do nivoa fakulteta. Onda smo navodili hierarhički model segmentacije teksta (HITS), zasnovan na RoBERTi, u eksperimentima u domenu i segmentaciji domena. Iako HITS proizvodi stanje umjetnosti u domenu (na tri kompleta ispitivanja na Wikipedia-u), pokazujemo da je, pod uslovom standardnog punog punog ispitivanja, suosjetljivo prema nadmetanju domena. Identificiramo ispravnu prilagodbu na temelju adapter a kao lijek koji značajno poboljšava izvođenje prijenosa.', 'am': 'በተለየ ባሕላዊ የጽሑፍ ማቀናቀል ሥርዓቶች በተለየ፣ የቀን በተመለከተው የsegmentation ሞዴል በWikipedia ላይ የታመነ ትልቁ የsegmentation ማዕከል ነው፡፡ ምንም እንኳን እነዚህ ምሳሌዎች በዋነኛው ድምፅ ውስጥ (Wikipedia-based) የድምፅ ደረጃዎች ላይ ተካክሎታል፡፡ በዚህ ስራ፣ በተማሩት ድምፅ ውስጥ የተጠበቀውን የነዌብ ጽሑፍ እውቀት የዶሜን ለመለወጥ እናቆማለን፡፡ ስለዚህም መጀመሪያ K12Seg፣ የተጠበቀውን ግንኙነት ለማስተምር አዲስ የዳታተር ማህበረሰብ ማህበረሰብ ከደረጃው-1 ወደ ኮሌጅ ደረጃዎች ተማሪዎችን እናሳውቃለን፡፡ በሮብበርታ የተቀመጠውን የጽሑፍ ማቀናቀል (HITS) ምሳሌ፣ በዶሜን እና የዶሜን መተላለፊያ ፈተና እናደርጋለን፡፡ HITS የድምፅ አካባቢ ድረ ገጽ (በሦስት Wikipedia-based ፈተናዎች ላይ) ሲያሳየው እናሳየዋለን፡፡ በጥያቄ የተመሠረተውን ጥሩ ማድረግ እንደሚያሳየው ፈውስ እናውቃለን፡፡', 'az': "Əlavə edilməmiş mətn segmentasiya metodlarına bənzər, yeni gözlənmiş segmentasiya modelləri böyük ölçülü segmentasiya gözətçisi kimi Wikipediaya təvəkkül edirlər. Bu modellər isə çox domain (Wikipedia-based) sınama qurularında değerlendirilmişdir, onların genel segmentasyon effektivitəsi haqqında sonuçlarını önlədərlər. Bu işdə, təhsil alanında nöral mətn segmentasiyasının domain transfer performansına odaklanırıq. Bu səbəbdə ilk dəfə K12Seg'i, gözləyirli segmentasiya değerlənmək üçün yeni verilən qurğunu tanıdıq, 1. dəfə üniversitə səbəbi öğrencilərə təhsil oxumaq materyalından yaratdıq. Sonra RoBERTa-ya dayanan hiyerarşik metin segmentasiya modeli (HITS) ilə, domain-in və domain-transfer segmentation experimentlərində. HITS domeində sanat performansını (üç Wikipedia tabanlı sınama qurularında) ürəkləndirən halda, biz standart dolu düzəltmə müvəffəqiyyəti ilə göstəririk ki, bu domeinin üstünə uyğunlaşdırılması mümkün deyildir. Biz adapter-based fine-tuning şəkildə təkrar işlətməsini çox yaxşılaşdırır.", 'bn': 'ঐতিহ্যবাহী অসংরক্ষিত টেক্সট বিভাগের মাধ্যমেও, সাম্প্রতিক পর্যবেক্ষিত সিগমেন্টেশন মডেল উইকিপিডিয়ার উপর নির্ভর করে বিশাল স্ক্যালে তবে এই মডেলগুলো প্রাথমিকভাবে ডোমেইন (উইকিপিডিয়ার ভিত্তিক) পরীক্ষার সেটের উপর মূল্যায়ন করা হয়েছে, যার ফলে তাদের সাধারণ বিভাগের কার্ এই কাজে আমরা শিক্ষামূলক ডোমেইনে নিউরেল লেখা বিভাগের উপর নজর রাখার প্রভাব নিয়ে মনোযোগ দিচ্ছি। এই শেষ পর্যন্ত, আমরা প্রথম কে- ১২সেগের সাথে পরিচয় করিয়ে দেব, একটি নতুন ডাটাসেট, যা পর্যবেক্ষণ করা ভাগের মূল্যের জন্য, যা শিক্ষা পড়তে থাকে ১ গ্রেড- তারপর আমরা রোবের্তার ভিত্তিতে একটি হিয়ারেক্যাল টেক্সপেন্টমেন্টেশন মডেল বেনমেন্ট করে দেই ডোমেইন এবং ডোমেইন পরিবর্তনের পরীক্ষায়। যখন এইচটিএস ডোমেইনে শিল্পের রাষ্ট্রের প্রতিষ্ঠান (তিন উইকিপিডিয়ার ভিত্তিক পরীক্ষা সেটে) তৈরি করে, তখন আমরা দেখাচ্ছি যে, স্বাভাবিক ভিত্তিক পুরোপুরি ব আমরা অ্যাডাপ্টার ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক সংস্কারের প্রতিক্রিয়া হিসেবে চিহ্নিত করি যা বাস', 'et': 'Erinevalt traditsioonilistest järelevalveta teksti segmenteerimise meetoditest toetuvad hiljutised järelevalvega segmenteerimise mudelid Vikipeediale kui laiaulatusliku segmenteerimise järelevalve allikale. Neid mudeleid on siiski peamiselt hinnatud domeenisiseste (Wikipedia-põhiste) testide põhjal, vältides järeldusi nende üldise segmenteerimise efektiivsuse kohta. Käesolevas töös keskendume juhendatud neuroteksti segmenteerimise domeeniülekande tulemuslikkusele hariduse valdkonnas. Selleks tutvustame esmalt K12Seg-i, uut andmekogumit järelevalvega segmenteerimise hindamiseks, mis on loodud hariduslikust lugemismaterjalist 1. klassi õpilastele kuni kolledži taseme õpilastele. Seejärel võrdleme RoBERTa-l põhinevat hierarhilist tekstisegmenteerimismudelit nii domeenisiseste kui domeeniülekande segmenteerimise katsetes. Kuigi HITS toodab kaasaegset domeenisisest jõudlust (kolmes Vikipeedia-põhises testikomplektis), näitame, et standardse täieliku peenhäälestuse korral on see vastuvõtlik domeeni ülemäärastamisele. Määratleme adapteripõhise peenhäälestuse abinõuna, mis oluliselt parandab edastusjõudlust.', 'fi': 'Toisin kuin perinteiset valvomattomat tekstisegmentointimenetelmﾃ､t, viimeaikaiset valvotut segmentointimallit luottavat Wikipediaan laajamittaisen segmentoinnin lﾃ､hteenﾃ､. Nﾃ､itﾃ､ malleja on kuitenkin arvioitu pﾃ､ﾃ､asiassa in-domain (Wikipedia-pohjaisilla) testisarjoilla, mikﾃ､ estﾃ､ﾃ､ johtopﾃ､ﾃ､tﾃｶksiﾃ､ niiden yleisestﾃ､ segmentoituvuudesta. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ keskitytﾃ､ﾃ､n ohjatun neurotekstisegmentoinnin toimialueensiirtoon koulutusalalla. Tﾃ､tﾃ､ tarkoitusta varten esittelemme ensin K12Seg-aineiston, joka on uusi ohjatun segmentoinnin arviointiaineisto, joka on luotu opetusmateriaalista 1. luokalle ja korkeakouluille. Tﾃ､mﾃ､n jﾃ､lkeen vertaamme RoBERTa-menetelmﾃ､ﾃ､n perustuvaa hierarkkista tekstisegmentointimallia (HITS) sekﾃ､ toimialueen sisﾃ､isissﾃ､ ettﾃ､ toimialueen siirtosegmentointikokeissa. Vaikka HITS tuottaa huippuluokan verkkotunnuksen suorituskykyﾃ､ (kolmella Wikipedia-pohjaisella testisarjalla), osoitamme, ettﾃ､ standardinmukaisella hienosﾃ､ﾃ､tﾃｶllﾃ､ se on altis verkkotunnuksen ylikuormitukselle. Tunnistamme sovitinpohjaisen hienosﾃ､ﾃ､tﾃｶn korjauskeinoksi, joka parantaa merkittﾃ､vﾃ､sti siirtosuorituskykyﾃ､.', 'cs': 'Na rozdíl od tradičních metod segmentace textu bez dozoru se nedávné modely segmentace pod dohledem spoléhají na Wikipedii jako zdroj dohledu nad segmentací v rozsáhlém měřítku. Tyto modely byly však převážně hodnoceny na in-domain (založených na Wikipedii) testovacích sadách, což zabránilo závěrům o jejich obecné segmentační účinnosti. V této práci se zaměřujeme na výkonnost doménového transferu supervisované segmentace neuronového textu ve vzdělávací doméně. Za tímto účelem nejprve představujeme K12Seg, nový datový soubor pro hodnocení dozorované segmentace, vytvořený ze vzdělávacího čtenářského materiálu pro studenty první třídy až po vysokoškolské úrovně. Následně porovnáme hierarchický model segmentace textu (HITS), založený na RoBERTa, v experimentech segmentace in-domain i domain-transfer. Zatímco HITS produkuje nejmodernější výkon v doméně (na třech testovacích sadách založených na Wikipedii), ukazujeme, že s výhradou standardního plnohodnotného jemného ladění je náchylný k přesahování domén. Identifikujeme jemné ladění založené na adaptéru jako nápravu, která výrazně zlepšuje přenosový výkon.', 'ca': "A diferència dels mètodes tradicionals de segmentació de text no supervisionat, els models de segmentació supervisionats recents confien en Wikipedia com a font de supervisió de segmentació a gran escala. No obstant això, aquests models han estat principalment evaluats en els conjunts d'exàmens en domini (basats en Wikipedia), evitant conclusions sobre la seva eficacia general de segmentació. In this work, we focus on the domain transfer performance of supervised neural text segmentation in the educational domain.  Per això, vam introduir primer K12Seg, un nou conjunt de dades per avaluar la segmentació supervisada, creat de material educatiu de lectura per a estudiants de primer grad a nivell universitari. Llavors comparem un model de segmentació jeràrquica de text (HITS), basat en RoBERTa, en experiments de segmentació en domini i de transfer ència de domini. Mentre que HITS produeix el rendiment en domini més avançat (en tres conjunts de proves basats en Wikipedia), demostram que, sota l'ajustament estàndard complet, és susceptible a l'ajustament excessiv de domini. Identifiquem l'ajustament basat en l'adaptador com un remèdic que millora substancialment el rendiment de la transfer ència.", 'sk': 'Za razliko od tradicionalnih nenadzorovanih metod segmentacije besedila se nedavni modeli nadzorovane segmentacije zanašajo na Wikipedijo kot vir obsežnega nadzora segmentacije. Ti modeli pa so bili predvsem ovrednoteni na domenskih testnih sklopih (ki temeljijo na Wikipediji), kar preprečuje zaključke o njihovi splošni učinkovitosti segmentacije. V tem delu se osredotočamo na uspešnost prenosa domene nadzorovane segmentacije nevronskih besedil v izobraževalni domeni. V ta namen najprej predstavljamo K12Seg, nov nabor podatkov za ocenjevanje nadzorovane segmentacije, ustvarjen iz izobraževalnega branja za študente 1. razreda do študentov. Nato primerjamo hierarhični model segmentacije besedila (HITS), ki temelji na RoBERTa, v poskusih segmentacije v domeni in domeni prenosa. Medtem ko HITS proizvaja najsodobnejše delovanje v domeni (na treh testnih sklopih, ki temeljijo na Wikipediji), pokažemo, da je ob upoštevanju standardnega popolnega finega nastavitve dovzetna za preveliko prilagajanje domene. Določamo natančno nastavitev na podlagi adapterja kot zdravilo, ki bistveno izboljša učinkovitost prenosa.', 'jv': 'taggedtag This modes have, rather, prelomantaly been assertied on the in-domain (http://www.webcam.com/test.png)test set, profing concludes about their General segmentation effectness. In this job, we Focal on the domain transfer output of super Vised Neral text segmentation in the acamera domain. Ngomongke iki, kawula nggawe mbungane soko K12 segment, dadi nggawe data set nggawe geraksi perusahaan sekolahan sing nggawe kudu nggawe barang kelas 1 kuwi cadeh sewulang cara-cara ngono kolèh. We after bench a herearchitecturecal text segmentation model (HITS), supported on RBERT, in all in-domain and domain-transfer segmentation testing. This is a vector graphic tool that can be used to create a single segmentation tool. When HITS generated state-of-the-arts in-domain success Awak dhéwé énhadi alih perusahaan langgar-aké dipunangé diunting nggawe barang langgar tarjamahan kanggo mbatalé nggawe barang nggawe', 'ha': "@ info: whatsthis Haƙĩƙa, waɗannan misalin sun ƙaddara a kan tsarin jarraba (Wikimedia-based) a cikin-Domen, kuma aka kange ƙarshen su a kan fassaran ajiya guda. Daga wannan aikin, munã fokusar da shirin ayuka da aka tsare segment na takardar rubutu a cikin shekaran da aka sani. To this end, we first introduce K12Seg, a new dataset for evaluation of supervised segmentation, created from educational reading material for grade-1 to college-level students.  Sa'an nan kuma muna samar da wata motel na hierrchical matsayin segment (AITS), a kan RoBERTa, cikin jarrabar cire-daban-guda da wanda aka saka cikin-Domen. A lokacin da AITS ke ƙara halin-sanar da ke cikin-guda (a kan jarraba masu sakan Wikimedia) ko, za mu nuna cewa, idan an sami tsarin da aka cika kowantar da aka cika, yana shakka da za'a samu'a guda. Kana gane tamkar mai kyau a kan adaptori kamar wata kafarin wanda ke ƙara gabanin shishi mai girma.", 'he': 'בניגוד לשיטות סגמנציה טקסטית מסורתיות, דוגמני סגמנציה ששולטים לאחרונה תלויים בוויקיפדיה כמקור של פיקוח סגמנציה ברמה גדולה. למרות זאת, הדוגמנים האלה הוערכו בעיקר על קבוצות הבדיקות בתחום (מבוססות בויקיפדיה), ומנעים ממסקנות על יעילות הסגמנציה הכללית שלהם. בעבודה הזו, אנו מתמקדים בהפעלת העברה בתחום של סגמנציה טקסט עצבי מושלמת בתחום החינוך. למטרה זו, אנו מכירים קודם את K12Seg, קבוצת נתונים חדשה להערכה של סגמנציה מופקחת, שנוצרה ממחומר קריאה חינוכי לכיתה 1 לסטודנטים ברמה קולג. ואז נבדוק דוגמא גייררכית של סגמנציה טקסטית (HITS), מבוססת על RoBERTa, בניסויים של סגמנציה בתחום וגם בתחום-העברה. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting.  אנו מזהה את התאמה המבוססת על מתאים כתרופה שמשתפר באופן משמעותי את ההפעלה של העברה.', 'bo': 'Unlike traditional unsupervised text segmentation methods, recent supervised segmentation models rely on Wikipedia as the source of large-scale segmentation supervision. These models have however, predominantly been evaluated on the in-domain (Wikipedia-based) test sets, preventing conclusions about their general segmentation efficacy. In this work, we focus on the domain transfer performance of supervised neural text segmentation in the educational domain. མཐའ་མ་དེར་བརྟེན། ང་ཚོས་དང་པོ་ནས་K12Seg ལ་ངོས་འཛིན་གྱི་ཡིག་ཆ་གསར་བ་ཞིག་གི་རྗེས་སུ་གཏོང་བ། We then benchmark a hierarchical text segmentation model (HITS), based on RoBERTa, in both in-domain and domain-transfer segmentation experiments. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting. ང་ཚོས་འཛིན་སྐྱོང་རྩོམ་བ་དང་མཉམ་དུ་བཟོ་བཅོས་ཀྱི་ཐབས་ལམ་ལྟར་ངོས་འཛིན་བྱེད་ཀྱི་ཡོད།'}
{'en': 'C-Test Collector : A Proficiency Testing Application to Collect Training Data for C-Tests C -Test Collector: A Proficiency Testing Application to Collect Training Data for  C -Tests', 'fr': 'C-Test Collector\xa0: une application de test de compétence pour collecter des données de formation pour les tests C', 'es': 'C-Test Collector: una aplicación de pruebas de aptitud para recopilar datos de entrenamiento para las pruebas C', 'ar': 'جامع اختبار C: تطبيق اختبار الكفاءة لجمع بيانات التدريب لاختبارات C', 'pt': 'C-Test Collector: Um aplicativo de teste de proficiência para coletar dados de treinamento para C-Tests', 'ja': 'C - Test Collector ： C - Testのトレーニングデータを収集するための熟練度テストアプリケーション', 'zh': 'C-Test 收集器:以收 C 试数应用程序', 'hi': 'सी-टेस्ट कलेक्टर: सी-टेस्ट के लिए प्रशिक्षण डेटा एकत्र करने के लिए एक प्रवीणता परीक्षण आवेदन', 'ru': 'Коллектор C-тестов: приложение для проверки квалификации для сбора данных обучения для C-тестов', 'ga': 'Bailitheoir C-Tástáil: Feidhmchlár Tástála Inniúlachta chun Sonraí Oiliúna a Bhailiú le haghaidh Tástálacha C', 'el': 'Συλλέκτης δοκιμής Γ: Μια εφαρμογή δοκιμής δεξιοτήτων για τη συλλογή δεδομένων κατάρτισης για τις δοκιμές Γ', 'hu': 'C-tesztgyűjtő: A készségtesztelő alkalmazás a C-tesztekhez szükséges képzési adatok összegyűjtésére', 'ka': 'C- TestComment', 'it': "C-Test Collector: un'applicazione di test di competenza per raccogliere dati di formazione per C-Test", 'kk': 'Comment', 'lt': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests', 'mk': 'C-Test Collector: Апликација за тестирање на профициеност за собирање податоци за обука за C-Tests', 'ml': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests', 'ms': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests', 'mt': 'Il-Ġbir tat-Testijiet C: Applikazzjoni għall-Ittestjar tal-Profiċjenza biex tinġabar id-dejta dwar it-Taħriġ għat-Testijiet C', 'no': 'Comment', 'mn': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests', 'pl': 'C-Test Collector: Aplikacja do testowania umiejętności do zbierania danych szkoleniowych dla C-Testów', 'ro': 'C-Test Collector: O aplicație de testare a competenței pentru colectarea datelor de instruire pentru C-Tests', 'si': 'Name', 'sr': 'C-Test Collector: Provjera za testiranje stručnosti za kolekciju podataka obuke za C-testove', 'so': 'C-Imtixaanka: Codsiga imtixaanka aqoonta ee u soo bandhiga macluumaadka waxbarashada', 'sv': 'C-Test Collector: En kompetenstest ansökan för att samla in utbildningsdata för C-test', 'ur': 'Name', 'ta': 'C- சோதனை தொகுப்பாளர்:', 'uz': 'Name', 'vi': 'C-Test Collector: Một chương trình thử nghiệm kinh nghiệm để thu thập dữ liệu đào tạo cho C-Tests.', 'bg': 'С-тест колектор: Приложение за тестване на умения за събиране на данни за обучение за С-тестове', 'da': 'C-Test Collector: En færdighedstest ansøgning til at indsamle træningsdata til C-Tests', 'nl': 'C-Test Collector: een vaardigheidstest applicatie om trainingsgegevens voor C-Tests te verzamelen', 'hr': 'C-test kolektor: aplikacija za testiranje povrednosti za skupljanje podataka obuke za C-testove', 'id': 'Pengumpul Tes-C: Aplikasi Pengujian Profikasi untuk mengumpulkan Data Pelatihan untuk Tes-C', 'de': 'C-Test Collector: Eine Anwendung zum Erfassen von Trainingsdaten für C-Tests', 'ko': 'C-Test Collector: C-Test의 교육 데이터를 수집하는 능력 검증 어플리케이션', 'fa': 'گردآورنده آزمایش C: یک کاربرد آزمایش استفاده برای جمع داده\u200cهای آموزش برای آزمایش C', 'sw': 'Mkusanyiko wa Tatibu: Utafiti wa Kujaribu Utafiti wa Kukusanya Data za Ufunzi kwa ajili ya C-Tests', 'tr': 'C-Testler üçin Maglumaty Maglumaty Toplaýyn', 'af': 'Comment', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'C-Test Kollektoru: C-Testl톛r 칲칞칲n t톛hsil m톛lumat캼n캼 toplamaq 칲칞칲n Proficiency Testing Uygulamas캼', 'bs': 'C-test kolektor: aplikacija za testiranje stručnosti za skupljanje podataka obuke za C-testove', 'bn': 'C- পরীক্ষা সংকলন: C- পরীক্ষার জন্য প্রশিক্ষণ তথ্য সংগ্রহের জন্য একটি প্রফেক্স পরীক্ষা করা অ্যাপ্লিকেশন', 'cs': 'C-Test Collector: Aplikace pro testování způsobilosti ke shromažďování tréninkových dat pro C-testy', 'ca': "Recollector de provas C: Una aplicació de prova d'aptitud per recollir dades d'entrenament per a provas C", 'et': 'C-Test Collector: Taskuse testimise rakendus koolitusandmete kogumiseks C-testide jaoks', 'fi': 'C-Test Collector: Proficiency Testing Application harjoitustietojen keräämiseen C-testejä varten', 'sq': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests', 'hy': 'Comment', 'jv': 'C-Test Colector: A Profile testing Application to Compile Learning data for C-Test', 'he': 'אוסף בדיקות C: תכנית בדיקות מומחיות לאסוף נתוני אימונים עבור בדיקות C', 'sk': 'C-Test Collector: Aplikacija za testiranje strokovnosti za zbiranje podatkov o usposabljanju za C-teste', 'ha': 'KCharselect unicode block name', 'bo': 'C-Test Collector: A Proficiency Testing Application to Collect Training Data for C-Tests'}
{'en': 'We present the C-Test Collector, a  web-based tool  that allows  language learners  to test their proficiency level using c-tests. Our tool collects anonymized data on test performance, which allows teachers to gain insights into common error patterns. At the same time, it allows NLP researchers to collect training data for being able to generate c-test variants at the desired difficulty level.', 'ar': 'نقدم أداة C-Test Collector ، وهي أداة قائمة على الويب تتيح لمتعلمي اللغة اختبار مستوى كفاءتهم باستخدام اختبارات c. تقوم أداتنا بجمع بيانات مجهولة المصدر حول أداء الاختبار ، مما يسمح للمعلمين باكتساب رؤى حول أنماط الخطأ الشائعة. في الوقت نفسه ، يسمح للباحثين في البرمجة اللغوية العصبية بجمع بيانات التدريب ليكونوا قادرين على إنشاء متغيرات اختبار c عند مستوى الصعوبة المطلوب.', 'es': 'Presentamos C-Test Collector, una herramienta basada en la web que permite a los estudiantes de idiomas evaluar su nivel de competencia mediante pruebas c. Nuestra herramienta recopila datos anónimos sobre el rendimiento de las pruebas, lo que permite a los profesores obtener información sobre los patrones de error más comunes. Al mismo tiempo, permite a los investigadores de PNL recopilar datos de entrenamiento para poder generar variantes de la prueba c en el nivel de dificultad deseado.', 'pt': 'Apresentamos o C-Test Collector, uma ferramenta baseada na web que permite que alunos de idiomas testem seu nível de proficiência usando c-tests. Nossa ferramenta coleta dados anônimos sobre o desempenho nos testes, o que permite que os professores obtenham informações sobre padrões de erros comuns. Ao mesmo tempo, permite que pesquisadores de PNL coletem dados de treinamento para serem capazes de gerar variantes de c-test no nível de dificuldade desejado.', 'fr': "Nous présentons le C-Test Collector, un outil Web qui permet aux apprenants de langues de tester leur niveau de compétence à l'aide de tests c. Notre outil collecte des données anonymisées sur les performances des tests, ce qui permet aux enseignants de mieux comprendre les modèles d'erreur courants. En même temps, il permet aux chercheurs en PNL de collecter des données de formation pour être en mesure de générer des variants de test c au niveau de difficulté souhaité.", 'ja': 'Cテストコレクターは、言語学習者がCテストを使用して習熟度をテストできるWebベースのツールです。当社のツールは、テストのパフォーマンスに関する匿名化されたデータを収集し、教師が一般的なエラーパターンに関する洞察を得ることができます。同時に、NLP研究者は、所望の難易度レベルでc検定バリアントを生成することができるためのトレーニングデータを収集することができる。', 'zh': '吾言C-Test Collector,此Web之具也,许言学者c-test试其熟练程度。 吾徒收拾试名数,使师深识常见非。 又许NLP人练数,以生c试变体。', 'hi': 'हम सी-टेस्ट कलेक्टर, एक वेब-आधारित उपकरण प्रस्तुत करते हैं जो भाषा सीखने वालों को सी-परीक्षणों का उपयोग करके अपनी प्रवीणता स्तर का परीक्षण करने की अनुमति देता है। हमारा उपकरण परीक्षण प्रदर्शन पर अनाम डेटा एकत्र करता है, जो शिक्षकों को सामान्य त्रुटि पैटर्न में अंतर्दृष्टि प्राप्त करने की अनुमति देता है। उसी समय, यह एनएलपी शोधकर्ताओं को वांछित कठिनाई स्तर पर सी-परीक्षण वेरिएंट उत्पन्न करने में सक्षम होने के लिए प्रशिक्षण डेटा एकत्र करने की अनुमति देता है।', 'ru': 'Мы представляем C-Test Collector, веб-инструмент, который позволяет изучающим язык тестировать свой уровень владения языком с помощью c-tests. Наш инструмент собирает анонимные данные о производительности теста, что позволяет учителям получить представление о распространенных шаблонах ошибок. В то же время, это позволяет исследователям NLP собирать обучающие данные для возможности генерировать c-test варианты на желаемом уровне сложности.', 'ga': 'Cuirimid i láthair an C-Test Collector, uirlis ghréasán-bhunaithe a ligeann d’fhoghlaimeoirí teanga a leibhéal oilteachta a thástáil ag baint úsáide as c-tests. Bailíonn ár n-uirlis sonraí gan ainm ar fheidhmíocht tástála, a ligeann do mhúinteoirí léargais a fháil ar phatrúin earráide coitianta. Ag an am céanna, ceadaíonn sé do thaighdeoirí NLP sonraí oiliúna a bhailiú chun a bheith in ann leagan c-tástála a ghiniúint ag an leibhéal deacrachta atá ag teastáil.', 'ka': 'ჩვენ C-ტესტის კოლექცირების გამოყენება, საბოლო სახელი, რომელსაც ენის სწავლებელების შესაძლებლობა c-ტესტის გამოყენებით შევცვალოთ სახელის პროფიციენტის ჩვენი ხელსაწყოთა ანონიმიზებული მონაცემები ტესტის გამოცემების შესახებ, რომელიც მსწავლებელი შეცდომების სტრუქტურების შესახებ მიიღებს. იგივე დროში, NLP მსწავლობელი შესაძლებელია შეიძლება შეიძლება შეიძლება c-ტესტის განრამეტრებების შექმნა, რომლებიც მინდა განსაზღვრება დონეში.', 'el': 'Παρουσιάζουμε το ένα διαδικτυακό εργαλείο που επιτρέπει στους μαθητές γλωσσών να δοκιμάσουν το επίπεδο επάρκειας τους χρησιμοποιώντας τεστ γ. Το εργαλείο μας συλλέγει ανώνυμα δεδομένα σχετικά με την απόδοση των δοκιμών, τα οποία επιτρέπουν στους εκπαιδευτικούς να αποκτήσουν γνώσεις σχετικά με κοινά μοτίβα σφαλμάτων. Ταυτόχρονα, επιτρέπει στους ερευνητές να συλλέγουν δεδομένα κατάρτισης για να μπορούν να δημιουργήσουν παραλλαγές δοκιμής στο επιθυμητό επίπεδο δυσκολίας.', 'it': 'Vi presentiamo il C-Test Collector, uno strumento basato sul web che consente agli studenti di testare il loro livello di competenza utilizzando i c-test. Il nostro strumento raccoglie dati anonimi sulle prestazioni dei test, che consentono agli insegnanti di acquisire informazioni sui modelli di errore comuni. Allo stesso tempo, consente ai ricercatori PNL di raccogliere dati di formazione per essere in grado di generare varianti di c-test al livello di difficoltà desiderato.', 'kk': 'Біз C- Test жинақтаушысын, c- сынақтар қолданып тілдерді оқытуға мүмкіндік беретін веб- негіздегі құралын көрсетедік. Біздің құралымыз сынақтар әрекетінің анонимді деректерін жинақтайды. Бұл мұғалімдерге жалпы қате үлгілеріне байқау мүмкіндігін береді. Бұл уақытта NLP зерттеушілері c- сынақ айнымалылықтарын қалаған мәселелерде құру үшін оқыту деректерін жинауға мүмкіндік береді.', 'hu': 'Bemutatjuk a C-Test Collectort, egy webalapú eszközt, amely lehetővé teszi a nyelvtanulók számára, hogy c-tesztek segítségével teszteljék jártassági szintjüket. Eszközünk anonimizált adatokat gyűjt a tesztteljesítményről, amelyek lehetővé teszik a tanárok számára, hogy betekintést nyerjenek a gyakori hibamintákba. Ugyanakkor lehetővé teszi az NLP kutatók számára, hogy képzési adatokat gyűjtsenek a kívánt nehézségi szinten elérhető c-tesztváltozatok létrehozásához.', 'lt': 'We present the C-Test Collector, a web-based tool that allows language learners to test their proficiency level using c-tests.  Mūsų priemonė renka anonimizuotus duomenis apie bandymų rezultatus, kurie leidžia mokytojams įgyti supratimą apie bendrus klaidų modelius. Tuo pačiu metu NLP mokslininkai gali rinkti mokymo duomenis, kad galėtų sukurti c bandymų variantus pageidaujamu sunkumų lygiu.', 'mk': 'Го претставуваме Ц-Тест Колекторот, веб-базиран алат кој им овозможува на учениците на јазик да го тестираат нивото на вештина со користење Ц-тестови. Our tool collects anonymized data on test performance, which allows teachers to gain insights into common error patterns.  At the same time, it allows NLP researchers to collect training data for being able to generate c-test variants at the desired difficulty level.', 'ml': 'സി- ടെസ്റ്റ് കോള്\u200dക്ടറിനെ ഞങ്ങള്\u200d കാണിക്കുന്നു. വെബ് അടിസ്ഥാനമായ ഒരു ഉപകരണം അത് ഭാഷ പഠിക്കുന്നവര്\u200dക്ക് സി- ടെസ്റ്റുകള്\u200d  നമ്മുടെ ഉപകരണങ്ങള്\u200d പരീക്ഷ പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനെപ്പറ്റി അപരിചിതമായ വിവരങ്ങള്\u200d സൂക്ഷിക്കുന്നു. അത് അധികാര അതേ സമയത്ത്, ആഗ്രഹിക്കുന്ന ബുദ്ധിമുട്ട നിലയില്\u200d c-പരീക്ഷ വേറെന്റര്\u200d ഉണ്ടാക്കുവാന്\u200d സാധിക്കുന്നതിനായി NLP പരിശീലന്', 'ms': 'Kami memperkenalkan Pengumpul Ujian-C, alat berdasarkan web yang membolehkan pelajar bahasa menguji tahap kemampuan mereka menggunakan ujian-c. Alat kami mengumpulkan data anonim mengenai prestasi ujian, yang membolehkan guru untuk mendapatkan pandangan pada corak ralat umum. Pada masa yang sama, ia membolehkan peneliti NLP mengumpulkan data latihan untuk dapat menghasilkan variasi ujian-c pada tahap kesukaran yang diinginkan.', 'mt': 'Aħna nippreżentaw il-Kollettur tat-Testijiet Ċ, għodda bbażata fuq l-internet li tippermetti lil dawk li jitgħallmu l-lingwi jittestjaw il-livell ta’ profiċjenza tagħhom bl-użu ta’ testijiet Ċ. L-għodda tagħna tiġbor dejta anonimizzata dwar il-prestazzjoni tat-testijiet, li tippermetti lill-għalliema jiksbu fehmiet dwar xejriet komuni ta’ żbalji. At the same time, it allows NLP researchers to collect training data for being able to generate c-test variants at the desired difficulty level.', 'pl': 'Prezentujemy C-Test Collector, internetowe narzędzie, które pozwala uczącym się języków sprawdzić swój poziom biegłości za pomocą c-testów. Nasze narzędzie gromadzi anonimowe dane dotyczące wydajności testów, co pozwala nauczycielom uzyskać wgląd w powszechne wzorce błędów. Jednocześnie umożliwia badaczom NLP zbieranie danych treningowych umożliwiających generowanie wariantów testów c na pożądanym poziomie trudności.', 'mn': 'Бид C-Тест Коллекторыг c-тест ашиглан хэлний сурагчид чадварын түвшинд шалгаж чадна. Бидний хэрэгсэл шалгалтын үйл ажиллагааны хувьд нэр тодорхой мэдээллийг цуглуулдаг. Энэ нь багш нарт нийтлэг алдаа загварын талаар ойлголт авч чадна. Гэвч энэ нь NLP судлаачид хүсэлтэй хэцүү түвшинд c-тест өөрчлөлтийг бүтээж чадах боломжтой боломжтой багш өгөгдлийг цуглуулах боломжтой.', 'no': 'Vi presenterer C-Test-samlinga, eit nettbasert verktøy som tillater språkklærarar å test a kvalitetsnivået sine med c-testar. Verktøyet vårt samler anonymerte data om testutvikling, slik at lærarar kan få innsyning i felles feilmønster. Samtidig kan NLP-forskere samla opplæringsdata for å kunna laga c-testvariantar på det ønskte vanskelighetsfunktet.', 'ro': 'Vă prezentăm C-Test Collector, un instrument bazat pe web care permite cursanților de limbi străine să-și testeze nivelul de competență folosind c-testele. Instrumentul nostru colectează date anonime privind performanța testului, ceea ce permite profesorilor să obțină informații despre tiparele comune de eroare. În același timp, permite cercetătorilor PNL să colecteze date de formare pentru a putea genera variante de test C la nivelul dorit de dificultate.', 'so': 'Waxaynu soo bandhignaynaa kas-tijaabinta C-tijaabada, kaas oo macluumaad ku saabsan karta barashada luqada, si ay u imtixaamaan heerka aqoontooda, si ay u isticmaalaan c-imtixaanka. Qoraalkayagu wuxuu soo ururiyaa macluumaad aan la aqoonin oo ku saabsan sameynta imtixaanka, taas oo ay macallimiinta ka heli karto aragtida qalabka caadiga ah. isla waqtigaas waxaa u fasaxaa baaritaanka NLP inay soo ururiyaan macluumaad waxbarasho si ay u sameyn karto isbedelyada c-test heerka dhibaatada loo baahan yahay.', 'si': 'අපි C- පරීක්ෂණ සංවිධානකය, වෙබ් අධාරිත උපකරණයක් පෙන්වන්නේ භාෂාව ප්\u200dරශ්නයක් C- පරීක්ෂණාවන් ප්\u200d අපේ උපකරණය පරීක්ෂණාව ගැන අනමිකරණ දත්ත සම්බන්ධ කරනවා, ඒකෙන් ගුරුවරුන්ට සාමාන්\u200dය වැරදි ප්\u200dරවේශ එකම වෙලාවෙන්, ඒක NLP පරීක්ෂකයන්ට අවශ්\u200dය අමාරුය ස්ථානයේ c-පරීක්ෂණ වෙනස් විද්\u200dයාපනය කරන්න පුළුවන් දත්ත සම්බන්', 'sv': 'Vi presenterar C-Test Collector, ett webbaserat verktyg som låter språkelever testa sin kunskapsnivå med hjälp av c-test. Vårt verktyg samlar in anonymiserade data om testresultat, vilket gör det möjligt för lärare att få insikt i vanliga felmönster. Samtidigt gör det möjligt för NLP-forskare att samla in träningsdata för att kunna generera c-testvarianter på önskad svårighetsgrad.', 'ta': 'C- சோதனை தொகுப்பாளரை நாம் காண்பிக்கிறோம், ஒரு வலை அடிப்படையில் உள்ள கருவி மொழி படிப்பவர்களை சிசி- சோதனைகளை பயன்படுத்தி சோதி எங்கள் கருவிகள் சோதனையின் செயல்பாட்டின் தகவல்களை சேகரிக்கிறது, அது ஆசிரியர்களை பொதுவான பிழை முறைமைகளாக பெறுவதற்க அதே நேரத்தில், NLP ஆராய்ச்சியாளர்கள் தேவைப்பட்ட கடினமான நிலையில் c- சோதனை மாறிகளை உருவாக்க இயலும் பயிற்சியின் தரவை சே', 'sr': 'Predstavljamo kolektor C-test a, web-bazirani alat koji omogućava učenicima jezika da testiraju svoj nivo profila koristeći c-testove. Naš alat skuplja anonimne podatke o provedbi testa, što omogućava učiteljima da dobiju uvid u zajedničke greške. U isto vreme, omogućava istraživačima NLP da prikupe podatke o obuci kako bi mogli da stvore varijante c-testa na željnoj nivou teškoće.', 'ur': 'ہم نے C-Test Collector کو پیش کیا ہے، ایک ویب بنیادی تولیل جو زبان یادگاروں کو c-tests کے مطابق اپنے پروفسیٹ سطح کا امتحان کرنا اجازت دیتا ہے. ہماری وسیلہ آزمائش کے بارے میں غیر نامی ڈیٹا جمع کرتا ہے، جسے استاد کو معلوم خطا الگوں میں نظر حاصل کرنا اجازت دیتا ہے. اس کے ساتھ یہ NLP تحقیقات کرنے والوں کو امید ہے کہ آرزو کی مشکل سطح میں c-test variants پیدا کرنے کے لئے آموزش دادہ جمع کریں.', 'uz': "Biz C-Test tuzuvchi, veb-asosida asosiy vosita, bu tilni o'rganishlarni C-test tugmasini sinash imkoniyatini beradi. Bizning asboblamiz sinov bajarishi haqida aniqlangan maʼlumotni olib tashlaydi. Bu o'qituvchilarga ko'rinishni umumiy xato shakllarini ko'rsatishga ruxsat beradi. Bu paytda, NLP ta'qituvchilarini taʼminlovchi maʼlumotni olib tashlash imkoniyatini talab qilingan qiyin darajada C- test oʻzgarishlarni yaratish uchun imkoniyat beradi.", 'vi': 'Chúng tôi giới thiệu C-Test Collector, một c ông cụ dựa trên mạng cho phép học viên ngôn ngữ kiểm tra trình độ thành thạo bằng c-thử nghiệm. Công cụ của chúng tôi thu thập dữ liệu nặc danh về kết quả thử nghiệm, cho phép giáo viên nắm được thông tin về các mô hình sai lầm phổ biến. Đồng thời, nó cho phép c ác nhà nghiên cứu tư gia của Đảng NLP thu thập dữ liệu đào tạo để có thể tạo ra biến thể C-thử ở mức độ khó khăn mong đợi.', 'bg': 'Представяме уеб базиран инструмент, който позволява на обучаващите езици да тестват нивото си на владеене чрез тестове. Нашият инструмент събира анонимизирани данни за ефективността на теста, което позволява на учителите да получат представа за често срещаните модели на грешки. В същото време, тя позволява на изследователите от НЛП да събират данни за обучение, за да могат да генерират варианти с-тест на желаното ниво на трудност.', 'hr': 'Predstavljamo kolektor C-Test-a, internetski alat koji omogućava učiteljima jezika da testiraju razinu profila koristeći c-testove. Naš alat skuplja anonimne podatke o provedbi testa, što omogućava učiteljima da dobiju uvid u zajedničke greške. U isto vrijeme, omogućava istraživačima NLP-a da skuplju podatke o obuci kako bi mogli stvoriti varijante c-testa na željenoj razini teškoća.', 'nl': 'We presenteren de C-Test Collector, een webgebaseerde tool waarmee taallerenden hun vaardigheidsniveau kunnen testen met behulp van c-tests. Onze tool verzamelt geanonimiseerde gegevens over testprestaties, waardoor docenten inzicht krijgen in veelvoorkomende foutpatronen. Tegelijkertijd kunnen NLP-onderzoekers trainingsgegevens verzamelen om c-testvarianten op de gewenste moeilijkheidsgraad te kunnen genereren.', 'da': 'Vi præsenterer C-Test Collector, et webbaseret værktøj, der giver sprogelever mulighed for at teste deres færdighedsniveau ved hjælp af c-test. Vores værktøj indsamler anonymiserede data om testresultater, hvilket giver lærere mulighed for at få indsigt i almindelige fejlmønstre. Samtidig giver det NLP-forskere mulighed for at indsamle træningsdata for at kunne generere c-test varianter på det ønskede sværhedsniveau.', 'de': 'Wir stellen den C-Test Collector vor, ein webbasiertes Tool, mit dem Sprachenlerner ihr Sprachniveau mithilfe von c-Tests testen können. Unser Tool sammelt anonymisierte Daten zur Testleistung, die Lehrern Einblicke in gängige Fehlermuster ermöglichen. Gleichzeitig können NLP-Forscher Trainingsdaten sammeln, um c-Test-Varianten im gewünschten Schwierigkeitsgrad generieren zu können.', 'id': 'Kami memperkenalkan C-Test Collector, alat berdasarkan web yang memungkinkan para pelajar bahasa untuk menguji tingkat kemampuan mereka menggunakan c-tests. Alat kami mengumpulkan data anonim tentang prestasi tes, yang memungkinkan guru untuk mendapatkan pandangan pada pola kesalahan umum. Pada saat yang sama, itu memungkinkan para peneliti NLP mengumpulkan data pelatihan untuk dapat menghasilkan varian C-test pada tingkat kesulitan yang diinginkan.', 'ko': '우리는 C-Test Collector를 소개했는데, 이것은 인터넷 기반의 도구로 언어 학습자들이 C-tests를 사용하여 그들의 숙련도를 측정할 수 있도록 한다.우리의 도구는 시험 성적의 익명 데이터를 수집하여 교사들이 흔히 볼 수 있는 오류 패턴을 깊이 있게 이해할 수 있도록 한다.또한 NLP 연구원들이 훈련 데이터를 수집하여 필요한 난이도 수준의 c테스트 변체를 생성할 수 있도록 한다.', 'fa': 'ما مجموعه آزمایشگاهی C-Test را با استفاده از آزمایش c نشان می دهیم، یک ابزار بسیار از وب که اجازه می دهد دانش\u200cآموزان زبان را با استفاده از آزمایش c امتحان کنند. ابزار ما اطلاعات نامیده\u200cای در مورد انجام آزمایش را جمع می\u200cکند که اجازه می\u200cدهد معلم\u200cها در الگوهای خطای مشترک دریافت کنند. در همین زمان، به محققان NLP اجازه می دهد که اطلاعات آموزش را برای توانایی تولید تغییرات c-آزمایش در سطح مشکل خواسته جمع کنند.', 'sw': 'Tunawasilisha mkusanyiko wa jaribio la C-Test, zana yenye mtandao inayoruhusu wanafunzi wa lugha kujaribu kiwango cha ufanisi wao kwa kutumia mtihani wa c-test. Vifaa vyetu vikusanya taarifa zisizoeleweka kuhusu utendaji wa majaribio, ambavyo vinawaruhusu walimu kupata maoni katika mitindo ya makosa ya kawaida. Wakati huo huo, inaruhusu watafiti wa NLP kukusanya takwimu za mafunzo kwa uwezo wa kutengeneza mabadiliko ya mtihani wa c katika kiwango kinachohitajika.', 'tr': 'C-Test Ýygymçysyny, internetde tabanly bir araç görkezýäris ki dil öwrenmeleriň öz ukyplaryny c-testi bilen test etmegini mümkin edýär Biziň esbaplarymyz testler barada anonymyz maglumaty ýygnaýar, bu sebäbi mugallymlaryň orta hata nusgalaryna düşünmesine rugsat berýär. Şol wagtda NLP araştyranlaryň islän kynçylyk derejesinde c-test warianatlaryny üýtgetmegine mümkin edýär.', 'af': "Ons stel die C- Test Versameler,  'n web- gebaseerde hulpmiddel wat toelaat taal leerneerders om hul profiesiteit vlak te toets deur c- toets te gebruik. Ons hulpmiddel versamel anonymiseerde data op toets prestasie, wat toelaat onderwysers inligtings in gemeenskaplike fout patrone te kry. Op dieselfde tyd laat dit toe NLP ondersoekers om onderwerp data te samel om c-toets variante te genereer op die gewende moeilikheid vlak.", 'sq': 'Ne paraqesim C-Test Collector, një mjet në internet që lejon mësuesit e gjuhës të testojnë nivelin e aftësisë së tyre duke përdorur c-tests. Mjet tonë mbledh të dhëna anonime mbi performancën e testit, që lejon mësuesit të fitojnë kuptime në modelet e përbashkëta të gabimeve. Në të njëjtën kohë, ajo lejon kërkuesit e NLP të mbledhin të dhëna treinimi për të qenë në gjendje të gjenerojnë variante c-test në nivelin e dëshiruar të vështirësisë.', 'am': 'የ-ፈተና ኮሌኮር፣ የመረብ መሠረት የቋንቋ ተማሪዎችን በ-ፈተናዎች ይሞክሩ ዘንድ የሚፈቅድ የቋንቋ ጥናት እናቀርባለን፡፡ መሣሪያችን ተማሪዎችን የስህተት ሥርዓት ላይ ያልታወቀ መረጃዎችን ይሰበስባል፤ ይህም አስተማሪዎችን የስህተትን አስተያየት በተለየ ስህተት ምሳሌዎች እንዲያገኙ ይችላል፡፡ በዚያው ሰዓት፣ NLP አስተማሪዎችን የሚያስፈልገውን አስቸጋሪ ደረጃን የc-test variants ማፍጠር እንዲችሉ ይችላል፡፡', 'hy': 'Մենք ներկայացնում ենք C-փորձարկումների հավաքածուն, մի վեբ-հիմնված գործիք, որը թույլ է տալիս լեզվի սովորողներին փորձարկել իրենց հմտությունների մակարդակը c-փորձարկումներով: Մեր գործիքը հավաքում է անհայտ տվյալներ փորձարկումների արտադրության մասին, ինչը թույլ է տալիս ուսուցիչներին հասկանալ ընդհանուր սխալների կաղապարները: Միևնույն ժամանակ, այն թույլ է տալիս ՆԼՊ-ի հետազոտողներին հավաքել ուսուցման տվյալներ, որպեսզի կարողանան ստեղծել c-թեստերի տարբերակներ ցանկացած դժվարության մակարդակում:', 'az': "Biz C-Test Collector'u, web-based bir araç göstəririk ki dil öyrənənənlərin c-test vasitəsilə proqramlarını imtahana çəksinlər. Bizim vasitələrimiz test performansı barəsində anonimlənmiş verilər toplar, bu da müəllimlərə ortaq xəta şartlarına nəzər verə bilər. Aynı zamanda, NLP araştırmacıları istədiyi çətinliklərdə c-test variablarını yaratmaq üçün təhsil məlumatlarını toplamağa imkan verir.", 'bn': 'We present the C-Test Collector, a web-based tool that allows language learners to test their proficiency level using c-tests.  আমাদের টুলটি পরীক্ষা কর্মকাণ্ডের ব্যাপারে অজানা তথ্য সংগ্রহ করে, যা শিক্ষকদের সাধারণ ভুল প্যাটারে দৃষ্টিভঙ একই সাথে এনএলপি গবেষকদের অনুমতি দেয় যাতে প্রযুক্তির তথ্য সংগ্রহ করতে পারে যাতে প্রয়োজনীয় কঠিন পরীক্ষায় c-test ভেরেন্ট তৈর', 'cs': 'Představujeme C-Test Collector, webový nástroj, který umožňuje studentům jazyka otestovat úroveň odborné znalosti pomocí c-testů. Náš nástroj shromažďuje anonymizovaná data o výkonnosti testů, což učitelům umožňuje získat přehled o běžných chybových vzorcích. Zároveň umožňuje výzkumníkům NLP shromažďovat tréninková data, aby mohli generovat varianty c-testu na požadované úrovni obtížnosti.', 'ca': "Presentem el C-Test Collector, una eina basada en la Web que permet als aprenents de llenguatges provar el seu nivell de competencia fent servir c-tests. La nostra eina recol·lecta dades anònims sobre el desempeny de les provas, que permet als professors obtenir insights en patrons d'error comuns. Al mateix temps, permet als investigadors de la NLP recollir dades de formació per poder generar variants de test c al nivell de dificultat desitjat.", 'et': 'Esitleme C-Test Collector, veebipõhine tööriist, mis võimaldab keeleõppijatel testida oma oskuste taset c-testidega. Meie tööriist kogub anonüümseid andmeid testide tulemuslikkuse kohta, mis võimaldab õpetajatel saada ülevaadet tavalistest veamustritest. Samal ajal võimaldab see uue tööprogrammi teadlastel koguda koolitusandmeid, et oleks võimalik luua c-testi variante soovitud raskusastmel.', 'bs': 'Predstavljamo kolektor C-Test-a, web-bazirani alat koji omogućava učiteljima jezika da testiraju svoj nivo profila koristeći c-testove. Naš alat skuplja anonimne podatke o provedbi testa, što omogućava učiteljima da dobiju uvid u zajedničke greške. U isto vrijeme, omogućava istraživačima NLP da skuplju podatke o obuci kako bi mogli stvoriti varijante c-testa na željenim nivou teškoća.', 'fi': 'Esittelemme C-Test Collector -verkkopohjaisen työkalun, jonka avulla kielioppijat voivat testata osaamistasoaan c-testeillä. Työkalumme kerää anonymisoitua tietoa testin suorituskyvystä, jonka avulla opettajat voivat saada tietoa yleisistä virhemalleista. Samalla se antaa NLP:n tutkijoille mahdollisuuden kerätä koulutustietoja c-testin varianttien tuottamiseksi halutulla vaikeustasolla.', 'jv': 'We nyimpen C-Test Awak dhéwé ngregani pernik-pernik kuwi nggawe data nang ujian sisalahan kanggo tukang batal Sampeyan ngono, iso ngebahi nambah NLP luwih akeh operasi dipunangé data kanggo gabung nggawe variante c-test nang sampeyan sing arep kalih apik.', 'sk': 'Predstavljamo vam C-Test Collector, spletno orodje, ki učencem jezikov omogoča, da preizkusijo svojo stopnjo strokovnosti s pomočjo c-testov. Naše orodje zbira anonimizirane podatke o uspešnosti testiranja, kar učiteljem omogoča, da pridobijo vpogled v običajne vzorce napak. Hkrati omogoča raziskovalcem NLP zbiranje podatkov o usposabljanju, da lahko ustvarijo različice c-testov na želeni težavnostni ravni.', 'he': 'אנו מציגים את אוסף בדיקות סי, כלי מבוסס באינטרנט שמאפשר ללמודים לשפה לבדוק את רמת המיומנות שלהם באמצעות בדיקות סי. הכל שלנו אוסף נתונים אנונימיים על ביצועי מבחן, שמאפשר למורים להשיג תובנות לתבנות שגיאות משותפות. באותו הזמן, זה מאפשר למחקרים של NLP לאסוף נתונים אימונים כדי להיות מסוגלים ליצור שונות מבחן c ברמה הקשה הנרצחה.', 'ha': "Tuna halatar da Colayer C-Test, wata zane mai banga-web, wanda ke yarda wa masu lõkaci da harshen su jarraba daraja na tsari da ko kuma don a yi amfani da c-jarraba. Tsarakanmu yana samun data wanda ba'a sani ba na samun aikin jarrabãwa, wanda yana yarda ma'anarnin su sami gannai zuwa misãlai mai karya. A sami wannan, na yarda masu fitina na NLP su sami data masu tsari dõmin a iya iya ƙiƙiro variants na c-jarraba kan zane da za'a buƙata.", 'bo': 'ང་ཚོས་C-Test སྒྲིག་མཁན་འདི་ཝེབ་གཞི་རྟེན་ནས་སྐད་ཡིག ང་ཚོའི་ལག་ཆ་གིས་བརྟག་ཞིབ་བྱས་པའི་ཆ་འཕྲིན་ཡིག་ཆ་སྒྲིག་འཆར་བྱེད་ཀྱི་ཡོད། དུས་གཅིག་མཚུངས་པ་དེ་ནི་NLP འཚོལ་ཞིབ་པས་གནད་དོན་གྱི་ཚད་འཛིན་བྱེད་པའི་དབྱེ་རིམ་གྱི་ཚད་ལྟར་སྒྲིག་འགོད་བྱེད་རྒྱུ་དང་།'}
{'en': 'Sharks are not the threat humans are : Argument Component Segmentation in School Student Essays', 'ar': '"أسماك القرش ليست هي الخطر الذي يمثله البشر": تجزئة مكون الحجة في مقالات طلاب المدارس', 'pt': '“Os tubarões não são a ameaça que os humanos são”: Segmentação de Componentes Argumentativos em Ensaios de Estudantes Escolares', 'fr': "«\xa0Les requins ne sont pas la menace que représentent les humains\xa0»\xa0: segmentation des composantes d'argument dans les essais des élèves", 'es': '«Los tiburones no son la amenaza que representan los humanos»: Segmentación de componentes de argumento en ensayos de estudiantes de escuela', 'zh': '弭鱼非人胁也:中学生论文细分', 'ja': '「サメは人間の脅威ではない」：学校の学生エッセイにおける議論の構成要素セグメンテーション', 'hi': '"शार्क खतरा मनुष्य नहीं हैं": स्कूल के छात्र निबंध में तर्क घटक विभाजन', 'ru': '«Акулы не являются угрозой для людей»: Сегментация компонентов аргументов в очерках для школьников', 'ga': '“Ní siorcanna an bhagairt atá ar dhaoine”: Deighilt Chomhpháirt na Argóine in Aistí Daltaí Scoile', 'ka': "'ახალხი არიან ადამიანების შეცდომა': აპგუმენტის კომპონენტი სკოლური სტუდენტის შეცდომა", 'it': "'Gli squali non sono la minaccia che gli esseri umani sono': Argomento Componente Segmentazione nei saggi degli studenti scolastici", 'kk': "'Жалпы балалар адамдардың қауіпсіздігі емес': Мектептегі студенттер атауындағы Argument Component Segmentation in School Student Essays", 'mk': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'ms': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'ml': "'ഷാര്\u200dക്കുകള്\u200d മനുഷ്യരെ ഭീഷണിപ്പിക്കുന്നത് അല്ല': സ്കൂള്\u200d വിദ്യാര്\u200dത്ഥിക്കുന്ന വിദ്യാര്\u200dത്ഥിയിലെ അര്\u200dഗ", 'mt': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'hu': '"A cápák nem az emberek fenyegetése": Argument Component segmentation in School Student Essays', 'no': '"Sharks are not the threat humans are": Argument Component Segmentation in School Student Essays', 'pl': '"Rekiny nie są zagrożeniem dla ludzi": Segmentacja składników argumentów w esejach uczniów szkolnych', 'el': '"Οι καρχαρίες δεν είναι η απειλή που είναι οι άνθρωποι": Διαμόρφωση Συστατικού επιχειρήματος σε Σχολικά Μαθητικά Δουλειά', 'lt': '„Rykliai nėra grėsmė, kurią kelia žmonės“: Argumento komponento segmentacija mokyklų studentų studijose', 'sr': '"Ajkule nisu prijetnja ljudima: Argument Component Segmentation in School Student Essays', 'mn': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'sv': "'Hajar är inte det hot människor är': Argument Component Segmentering in School Student Essays", 'ro': '"Rechinii nu sunt amenințarea umană": Segmentarea componentei argumentului în eseurile studenților școlari', 'si': "'sharks are not the Threat Human are ': argment component Secmentation in School Stud Associations", 'ur': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'so': "'Shariigyadu ma aha dadka hanjabaad': Heshiiska qeybta arrimaha ee iskuulka ee ardayda Essays", 'ta': "'பங்குகள் மனிதர்களுக்கு அச்சுறுத்தல் அல்ல': பள்ளி மாணவன் எஸ்செல்கிறார்கள்", 'vi': '"Cá mập không phải mối đe dọa của con người\': Số tham khảo phân tích sinh viên tại Học viện Essays.', 'uz': "'Sharqlar odamlar haqida emas': Maktab Student Essa'ning Argument komponent Segmentation", 'nl': "'Haaien zijn niet de bedreiging die mensen zijn': Segmentatie van argumentcomponenten in essays voor schoolstudenten", 'da': "'Hajer er ikke den trussel mennesker er': Argumentkomponent Segmentering i skole Student Essays", 'bg': '"Акулите не са заплахата, която хората са":', 'hr': "'Ajkule nisu prijetnja ljudima: Argument Component Segmentation in School Student Essays", 'id': "'Hiu bukanlah ancaman manusia': Segmentasi Komponen Argumen di Essays mahasiswa sekolah", 'ko': '"상어는 인류의 위협이 아니다": 학생 작문에서의 논점 성분 세분화', 'fa': '"Sharks are not the threat humans are": Argument Component Segmentation in School Student Essays', 'sw': "'Washiriki sio tishio la binadamu ni': Kifungu cha Ugaji Mkuu katika Mwanafunzi wa shule Essays", 'sq': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'de': '"Haie sind nicht die Bedrohung, die Menschen sind": Argument Component Segmentation in Schüleressays', 'tr': "'Sahypalar adamlary tehdit etmezli däl': Argument Component Segmentation in School Student Essays", 'hy': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'af': '"Sharks are not the threat humans are": Argument Component Segmentation in School Student Essays', 'am': "'ጋራዎች ሰዎች የሚያስፈራሩ አይደሉም'፤ በተምህርት ተማሪ ተማሪ Essier", 'ca': '"Els tiburons no són la amenaça que són els humans": Segmentació del component d\'arguments en els exàmens d\'estudiants escolars', 'az': "'K칬p칲kl톛r insanlar캼n t톛hdidl톛ri deyil': Argument Component Segmentation in School Student Essays", 'bn': "'শার্কগুলো মানুষের হুমকি নয়': স্কুল ছাত্রীর আর্গুমেন্ট কম্পোনেন্ট অ্যাগমেন্ট এসজেন্ট বলেছেন", 'bs': "'Ajkule nisu prijetnja ljudima: Argument Component Segmentation in School Student Essays", 'cs': '"Žraloci nejsou hrozbou, kterou lidé jsou": Segmentace komponent argumentů v esejích školních studentů', 'et': '"Haid ei ole oht, mida inimesed on": Argumenti komponentide segmentatsioon kooliõpilaste essees', 'fi': "'Hait eivät ole uhka, jota ihmiset ovat': Argumentti Component Segmentation in School Student Essays", 'he': '"כרישים הם לא האיום שהבני אדם הם": סגרטציה של חלקי הטיעון במבחנים של סטודנטים בבית הספר', 'jv': "'sharks are not the mena Human are': argument Komenta segmentation in Escolar Staten", 'bo': "'Sharks are not the threat humans are': Argument Component Segmentation in School Student Essays", 'sk': '"Morski psi niso grožnja, ki jo ljudje predstavljajo": Segmentacija komponent argumentov v šolskih študentskih esejih', 'ha': "'Sharki ba'a wa'adin mutane ne': Argument Composite Segmentation in Afãrar School Essaye"}
{'en': 'Argument mining is often addressed by a  pipeline method  where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task. In this research, we apply a token-level classification to identify claim and premise tokens from a new corpus of argumentative essays written by middle school students. To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components. We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.', 'pt': 'A mineração de argumentos é frequentemente abordada por um método de pipeline em que a segmentação do texto em unidades argumentativas é conduzida primeiro e seguida por uma tarefa de identificação de componentes de argumento. Nesta pesquisa, aplicamos uma classificação em nível de token para identificar tokens de afirmação e premissa de um novo corpus de ensaios argumentativos escritos por alunos do ensino médio. Para este fim, comparamos uma variedade de modelos de última geração, como recursos discretos e arquiteturas de aprendizado profundo (por exemplo, redes BiLSTM e arquiteturas baseadas em BERT) para identificar os componentes do argumento. Demonstramos que uma arquitetura de aprendizado multitarefa baseada em BERT (ou seja, classificação de nível de token e sentença) pré-treinada de forma adaptativa em um conjunto de dados relevante não rotulado obtém os melhores resultados.', 'es': 'La minería de argumentos a menudo se aborda mediante un método de canalización en el que la segmentación del texto en unidades argumentativas se lleva a cabo primero y procede de una tarea de identificación de componentes de argumento. En esta investigación, aplicamos una clasificación a nivel de token para identificar los tokens de reclamo y premisa de un nuevo corpus de ensayos argumentativos escritos por estudiantes de secundaria. Con este fin, comparamos una variedad de modelos de vanguardia, como características discretas y arquitecturas de aprendizaje profundo (por ejemplo, redes BilsTM y arquitecturas basadas en BERT) para identificar los componentes del argumento. Demostramos que una arquitectura de aprendizaje multitarea basada en BERT (es decir, clasificación de niveles de token y oración) preentrenada de manera adaptativa en un conjunto de datos relevante sin etiqueta obtiene los mejores resultados.', 'fr': "L'exploration d'arguments est souvent abordée par une méthode de pipeline où la segmentation du texte en unités argumentatives est effectuée en premier lieu et suivie d'une tâche d'identification de composant d'argument. Dans cette recherche, nous appliquons une classification au niveau des jetons pour identifier les jetons de revendication et de prémisse à partir d'un nouveau corpus d'essais argumentatifs écrits par des élèves du collège. À cette fin, nous comparons une variété de modèles de pointe tels que des fonctionnalités discrètes et des architectures de deep learning (par exemple, les réseaux BilsTM et les architectures basées sur BERT) afin d'identifier les composants d'argument. Nous démontrons qu'une architecture d'apprentissage multitâche basée sur BERT (c'est-à-dire la classification des niveaux de jeton et de phrase) préentraînée de manière adaptative sur un ensemble de données non étiqueté pertinent permet d'obtenir les meilleurs résultats.", 'ar': 'غالبًا ما يتم التعامل مع تعدين الحجج من خلال طريقة خط الأنابيب حيث يتم إجراء تجزئة النص إلى وحدات جدلية أولاً والمضي قدمًا من خلال مهمة تحديد مكون الوسيطة. في هذا البحث ، نطبق تصنيفًا على مستوى الرمز المميز لتحديد الرموز المميزة للمطالبة والمقدمة من مجموعة جديدة من المقالات الجدلية التي كتبها طلاب المدارس المتوسطة. تحقيقا لهذه الغاية ، نقارن مجموعة متنوعة من أحدث النماذج مثل الميزات المنفصلة وبنى التعلم العميق (على سبيل المثال ، شبكات BiLSTM والبنى القائمة على BERT) لتحديد مكونات الحجة. نوضح أن بنية التعلم متعددة المهام القائمة على BERT (أي التصنيف على مستوى الرمز والجمل) التي تم تدريبها مسبقًا على مجموعة بيانات غير مسماة ذات صلة تحصل على أفضل النتائج.', 'ja': '引数マイニングは、引数単位へのテキストのセグメンテーションが最初に行われ、引数コンポーネント識別タスクによって進行されるパイプライン方法によって対処されることが多い。この研究では、トークンレベルの分類を適用して、中学生が書いた議論的エッセイの新しいコーパスからクレームと前提トークンを識別します。この目的のために、私たちは引数コンポーネントを識別するために、離散的な機能や深層学習アーキテクチャ（ BiLSTMネットワークやBERTベースのアーキテクチャなど）などのさまざまな最先端モデルを比較します。私たちは、BERTベースのマルチタスク学習アーキテクチャ（すなわち、トークンおよび文章レベルの分類）が、関連するラベル付けされていないデータセットで適応的に事前に訓練されていることが、最良の結果を得ることを実証します。', 'zh': '参数掘常道,其先分割文本为证单元,然后参数组件知之。 于是宜用代币级,从中学生所撰新议论文语料库识索赔及前代币。 是以比先进之形,离散架构(学,BiLSTM网络基于BERT之架构),以定参数组件。 余证BERT之多任务学架构(即令牌句之类)于未标数集上自应预训练,可得最佳也。', 'hi': 'तर्क खनन को अक्सर एक पाइपलाइन विधि द्वारा संबोधित किया जाता है जहां तर्कसंगत इकाइयों में पाठ का विभाजन पहले आयोजित किया जाता है और एक तर्क घटक पहचान कार्य द्वारा आगे बढ़ाया जाता है। इस शोध में, हम मध्य विद्यालय के छात्रों द्वारा लिखे गए तर्कसंगत निबंधों के एक नए कॉर्पस से दावे और आधार टोकन की पहचान करने के लिए एक टोकन-स्तर वर्गीकरण लागू करते हैं। इस अंत तक, हम तर्क घटकों की पहचान करने के लिए असतत सुविधाओं और गहरे सीखने के आर्किटेक्चर (जैसे, BiLSTM नेटवर्क और BERT-आधारित आर्किटेक्चर) जैसे विभिन्न प्रकार के अत्याधुनिक मॉडल की तुलना करते हैं। हम प्रदर्शित करते हैं कि एक BERT-आधारित बहु-कार्य सीखने की वास्तुकला (यानी, टोकन और वाक्य स्तर वर्गीकरण) एक प्रासंगिक अनलेबल डेटासेट पर अनुकूली रूप से पूर्वनिर्धारित सर्वोत्तम परिणाम प्राप्त करता है।', 'ru': 'Майнинг аргументов часто рассматривается методом конвейера, где сначала проводится сегментация текста на аргументативные единицы, а затем задача идентификации компонента аргумента. В этом исследовании мы применяем классификацию на уровне токенов для идентификации токенов утверждений и предпосылок из нового корпуса аргументативных эссе, написанных учениками средней школы. С этой целью мы сравниваем различные современные модели, такие как дискретные функции и архитектуры глубокого обучения (например, сети BiLSTM и архитектуры на основе BERT), чтобы идентифицировать компоненты аргументов. Мы демонстрируем, что многозадачная обучающая архитектура на основе BERT (т.е. классификация токенов и уровней предложений), адаптивно предварительно обученная на соответствующем немеченом наборе данных, дает наилучшие результаты.', 'ga': 'Is minic a thugtar aghaidh ar mhianadóireacht argóintí trí mhodh píblíne ina ndéantar an téacs a dheighilt ina aonaid argóinte ar dtús agus ina dhiaidh sin trí thasc aitheantais comhpháirte argóinte. Sa taighde seo, cuirimid i bhfeidhm aicmiú ag leibhéal comharthaí chun comharthaí éilimh agus bonn a aithint ó chorpas nua d’aistí argóinteacha a scríobh daltaí meánscoile. Chuige sin, déanaimid comparáid idir éagsúlacht samhlacha úrscothacha amhail gnéithe scoite agus ailtireachtaí domhainfhoghlama (m.sh., líonraí BiLSTM agus ailtireachtaí bunaithe ar BERT) chun na comhpháirteanna argóinte a shainaithint. Léirímid go bhfaigheann ailtireacht foghlama il-tasc atá bunaithe ar BERT (i.e., aicmiú leibhéal comharthaí agus abairtí) a réamhoilíodh go hoiriúnaitheach ar thacar sonraí ábhartha neamhlipéadaithe na torthaí is fearr.', 'ka': 'არგუმენტების მინდომირება ზოგიერთად მინდომარებულია, რომელიც ტექსტის სეგუმენტიური ერთეულებში გავაკეთება პირველი და გავაკეთება არგუმენტის კომპონენტიფიკაციის ამ შესწავლობში ჩვენ კლასიფიკაციას, რომელიც საშუალო სტუდენტური სტუდენტური სტუდენტურების ახალი კოპუსიდან დავაკეთებთ, დავაკეთებთ კლასიფიკაციას. ამ დასაწყისთვის, ჩვენ განსხვავებთ განსხვავებული მოდელები, როგორც დისკრეტური ფუნქციები და ძალიან სწავლების აქტიქტიკურები (მაგალითად, BiLSTM ქსელები და BERT-დაბათებული აქტიქტიკურები) აღმონიშნ ჩვენ ევმონსტრაცით, რომ ბერტის მრავალური სამუშაო სამუშაო სწავლების აქტიქტიქტურა (მაგალითად, სიტყვის და სიტყვის უფრო კლასიფიკაცია) შესაბამისი უკეთესი სამუშაო მონა', 'hu': 'Az argumentumbányászatot gyakran csővezeték-módszerrel kezelik, ahol először a szöveg argumentatív egységekre történő szegmentálását végzik, majd egy argumentumazonosító feladat folytatja. Ebben a kutatásban token-szintű osztályozást alkalmazunk arra, hogy azonosítsuk a középiskolás diákok által írt vitató esszék új korpuszából származó igény- és premisszjegyeket. Ennek érdekében számos korszerű modellt hasonlítunk össze, például diszkrét funkciókat és mélytanulási architektúrákat (például BiLSTM hálózatokat és BERT alapú architektúrákat), hogy azonosítsuk az argumentum összetevőit. Bemutatjuk, hogy a BERT alapú, többfeladatos tanulási architektúra (azaz token és mondatszint osztályozás) adaptívan előkészített, egy releváns címke nélküli adatkészletre a legjobb eredményeket érheti el.', 'kk': 'Аргументтің балауы көбінде мәтінді аргументтік бірліктерге бөліп, аргументтің компоненттің идентификациялау тапсырмасы аргументтік бірліктеріне сәйкес ретінде адрестіледі. Бұл зерттеулерде біз ортасындағы студенттер жазылған аргументалдық есептердің жаңа корпус аргументалдық есептерін анықтау үшін ток деңгейінің классификациясын қолданамыз. Бұл соңында, біз аргументтің компоненттерін анықтау үшін әртүрлі әртүрлі өзгерістер үлгілерін салыстырамыз. Біз BERT негіздеген көп тапсырмалар оқыту архитектурасы (т.е. белгілер мен сөйлемелер деңгейінің классификациясы) адаптикалық келтірілмеген деректер жинағында жақсы нәтижелерді алады деп көрсетедік', 'el': 'Η εξόρυξη επιχειρημάτων συχνά αντιμετωπίζεται με μια μέθοδο αγωγού όπου η κατάτμηση του κειμένου σε επιχειρηματικές μονάδες διεξάγεται πρώτα και προχωρείται από μια εργασία αναγνώρισης στοιχείων επιχειρήματος. Σε αυτή την έρευνα, εφαρμόζουμε μια ταξινόμηση σε επίπεδο σήματος για να εντοπίσουμε τα σήματα αξιών και προϋποθέσεων από ένα νέο σώμα επιχειρηματολογικών δοκίμων γραμμένων από μαθητές γυμνασίου. Για το σκοπό αυτό, συγκρίνουμε μια ποικιλία μοντέλων τελευταίας τεχνολογίας, όπως διακριτά χαρακτηριστικά και αρχιτεκτονικές βαθιάς μάθησης (π.χ. δίκτυα και αρχιτεκτονικές βασισμένες στο BERT) για να προσδιορίσουμε τα στοιχεία των επιχειρημάτων. Αποδεικνύουμε ότι μια αρχιτεκτονική εκμάθησης πολλαπλών εργασιών βασισμένη στο BERT (δηλ. ταξινόμηση σε επίπεδο συμβολαίου και φράσεων) προσαρμοστικά προσχεδιασμένη σε ένα σχετικό μη επισήμαντο σύνολο δεδομένων επιτυγχάνει τα καλύτερα αποτελέσματα.', 'ms': 'Perlombongan argumen sering didalami oleh kaedah garis paip dimana segmen teks ke unit argumen dilakukan dahulu dan dilakukan oleh tugas pengenalan komponen argumen. Dalam kajian ini, kami melaksanakan klasifikasi aras token untuk mengenalpasti tuntutan dan premis token dari korpus baru essai argumentatif ditulis oleh pelajar sekolah menengah. Untuk tujuan ini, kita membandingkan pelbagai model-state-of-the-art seperti ciri-ciri diskret dan arkitektur belajar dalam (cth., rangkaian BiLSTM dan arkitektur berasaskan BERT) untuk mengenalpasti komponen argumen. Kami menunjukkan bahawa arkitektur pembelajaran berbilang-tugas berasaskan BERT (iaitu klasifikasi aras tanda dan kalimat) dilatih secara adaptif pada set data tidak berlebihan yang relevan mendapatkan keputusan terbaik.', 'it': "Il mining degli argomenti è spesso affrontato da un metodo pipeline in cui la segmentazione del testo in unità argomentative viene condotta prima e seguita da un'attività di identificazione dei componenti degli argomenti. In questa ricerca, applichiamo una classificazione a livello token per identificare i token di rivendicazione e premessa da un nuovo corpus di saggi argomentativi scritti dagli studenti delle scuole medie. A tal fine, confrontiamo una varietà di modelli all'avanguardia come funzionalità discrete e architetture di deep learning (ad esempio reti BiLSTM e architetture basate su BERT) per identificare i componenti degli argomenti. Dimostriamo che un'architettura di apprendimento multi-task basata su BERT (vale a dire classificazione a livello di token e frase) adattatamente pre-addestrata su un set di dati non etichettato pertinente ottiene i migliori risultati.", 'mk': 'Argument mining is often addressed by a pipeline method where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task.  Во ова истражување, применуваме класификација на ниво на знаци за идентификување на тврдења и претпоставување на знаци од нов корпус аргументативни есеји напишани од студентите од средно училиште. To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components.  We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.', 'lt': 'Argument ų gavyba dažnai sprendžiama vamzdyno metodu, kai teksto segmentavimas į argumentinius vienetus atliekamas pirmiausia, o argumento komponento identifikavimo užduotis atliekama. In this research, we apply a token-level classification to identify claim and premise tokens from a new corpus of argumentative essays written by middle school students.  To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components.  We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.', 'mt': 'Il-minjieri tal-argumenti ta’ spiss jiġu indirizzati permezz ta’ metodu ta’ pipeline fejn is-segmentazzjoni tat-test f’unitajiet argumentattivi titwettaq l-ewwel u titwettaq b’kompitu ta’ identifikazzjoni tal-komponent tal-argument. F’din ir-riċerka, nagħmlu klassifikazzjoni fil-livell tat-tokens biex nidentifikaw it-tokens tal-pretensjonijiet u l-premessi minn korp ġdid ta’ essaji argumentattivi miktuba minn studenti tal-iskola medja. Għal dan il-g ħan, a ħna nqabblu varjetà ta’ mudelli moderni bħall-karatteristiċi diskreti u arkitetturi ta’ tagħlim profond (pereżempju n-netwerks BiLSTM u arkitetturi bbażati fuq BERT) biex jiġu identifikati l-komponenti tal-argument. Aħna nippruvaw li arkitettura tat-tagħlim multikompiti bbażata fuq BERT (jiġifieri klassifikazzjoni tal-livell tat-tokens u tas-sentenzi) adattament imħarrġa minn qabel fuq sett ta’ dejta rilevanti mingħajr tikketta tikseb l-a ħjar riżultati.', 'ml': 'ആര്\u200dഗമെന്റ് മീനിംഗ് എപ്പോഴും ഒരു പൈപ്പെലൈന്\u200d രീതിയാല്\u200d വിലാസപ്പെടുത്തുന്നു. വാര്\u200dഗ്യാമെന്റിറ്റീവ് യൂണിറ്റുകളിലേക്ക് വേര ഈ ഗവേഷണത്തില്\u200d, നമ്മള്\u200d ഒരു തെളിവുകള്\u200d പ്രയോഗിക്കുന്നു. അതിന്റെ പുതിയ കോര്\u200dപ്പുസില്\u200d നിന്നും എഴുതിയിരിക്കുന്ന വിദ്യാര്\u200dത്ഥി ഈ അവസാനത്തിനുവേണ്ടി നമ്മള്\u200d വ്യത്യസ്ത വിഭാഗങ്ങളും ആഴത്തെ പഠിപ്പിക്കുന്ന ആര്\u200dക്കിട്ടുകളും (ഉദാഹരണമായ ബില്\u200dസ്റ്റം നെറ്റുകളും ബെര്\u200dട്ടി അടിസ്ഥാനമായ ആര്\u200dക്കി ബെര്\u200dട്ടിന്റെ അടിസ്ഥാനത്തുള്ള പല്ലാ ജോലി പഠിപ്പിക്കുന്ന ആര്\u200dക്കിട്ടറിക്കാനുള്ള സ്ഥാനമാണ് നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത്. അതിനാല്\u200d വിചാരി', 'ro': 'Minerea de argumente este adesea abordată printr-o metodă de pipeline în care segmentarea textului în unități argumentative este efectuată mai întâi și procedată printr-o activitate de identificare a componentei argumentului. În această cercetare, aplicăm o clasificare la nivel de token pentru a identifica jetoanele de pretenție și premisă dintr-un nou corpus de eseuri argumentative scrise de elevii de gimnaziu. În acest scop, comparăm o varietate de modele de ultimă generație, cum ar fi caracteristicile discrete și arhitecturile de învățare profundă (de exemplu, rețelele BiLSTM și arhitecturile bazate pe BERT) pentru a identifica componentele argumentului. Demonstrăm că o arhitectură de învățare multi-sarcină bazată pe BERT (adică clasificarea nivelului de token și frază) preinstruită adaptiv pe un set de date relevant fără etichete obține cele mai bune rezultate.', 'no': 'Argument mining vert ofte adressert av ein røyringsmetode der segmentering av tekst i argumentativ einingar vert først gjennomført og framført av eit argument-komponentsidentifiseringsoppgåve. I denne forskningen bruker vi ein tokennivåklassifikasjon for å identifisera etterspørselen og premisera teikn frå eit nytt korpus av argumentativ essar skriven av midtskole studenter. I denne slutten samanliknar vi ein del av kunstmodeller som diskrete funksjonar og dype læringsarkitekturar (f.eks. BiLSTM-nettverk og BERT-baserte arkitekturar) for å identifisera argumentkomponentane. Vi viser at ein BERT-basert fleire oppgåver-læringsarkitektur (t.d. token og setningsnivå klassifikasjon) tilpassar på eit relevant ubeabelte datasett får dei best e resultatene.', 'mn': 'Аргументийн хөрөнгө оруулалт ихэвчлэн текст аргументийн нэгжүүд руу шилжүүлж, аргументын компонентын идентификацийн ажил дээр ажилладаг хоолойн шугам аргументын аргументын хуваалтын аргументын аргументын аргументын ар Энэ судалгаанд бид дундаж сургуулийн оюутнуудын бичигдсэн аргумент эссийн шинэ корпус дээр хүлээн зөвшөөрөх боломжтой хэмжээний ангилалыг ашигладаг. Энэ төгсгөлд бид аргументын компонентүүдийг тодорхойлдохын тулд олон төрлийн урлагийн загваруудыг харьцуулж байна. Бид БЕРТ-д сургалтын олон ажлын суралцах архитектур (т.е. тэмдэглэл болон өгүүлбэрийн хэмжээний хэмжээний хэмжээний хэмжээний хэмжээнд) хамгийн сайн үр дүнг авдаг гэдгийг харуулж байна.', 'pl': 'Wydobywanie argumentów jest często zajmowane metodą rurociągu, w której segmentacja tekstu na jednostki argumentatywne jest najpierw prowadzona i rozpoczyna się zadaniem identyfikacji składników argumentów. W tym badaniu stosujemy klasyfikację na poziomie tokenów do identyfikacji tokenów roszczeń i założeń z nowego korpusu esejów argumentatywnych napisanych przez uczniów gimnazjum. W tym celu porównujemy różne najnowocześniejsze modele, takie jak funkcje dyskretne i architektury głębokiego uczenia (np. sieci BiLSTM i architektury oparte na BERT), aby zidentyfikować składniki argumentów. Wykazujemy, że wielozadaniowa architektura uczenia się oparta na BERT (tj. klasyfikacja na poziomie tokenów i zdań) adaptacyjnie przeszkolona na odpowiednim nieoznakowanym zbiorze danych uzyskuje najlepsze wyniki.', 'sr': 'Rušenje argument a se često obrađuje metodom naftne linije u kojoj se prvo provede segmentacija teksta u argumentativne jedinice i nastavlja zadatak identifikacije komponenta argumentacija. U ovom istraživanju, primjenjujemo klasifikaciju nivoa znakova za identifikaciju zahtjeva i predstavljanje znakova novog korpusa argumentativnih eseja napisanih od studenata srednje škole. Za taj cilj uspoređujemo razne modele države umjetnosti kao što su diskretne karakteristike i duboke arhitekture učenja (npr. BiLSTM mreže i arhitekture bazirane na BERT) kako bi identifikovali komponente argument a. Pokazujemo da arhitektura za učenje multizadataka na BERT-u (tj. klasifikacija nivoa znakova i rečenica) prilagodno pretvara na relevantni neoznačeni set podataka dobija najbolji rezultat.', 'so': 'Inta badan waxaa lagu magacaabiyaa qoraal baabuur ah, marka lagu sameeyo qeybta qoraalka oo lagu qeybiyo qaybaha wadajirka ah marka hore waxaa lagu sameeyaa shaqada aqoonsashada qiimaha. Waxbarashadan ayaannu sameynaa fasalka heerka calaamada si aan u aqoonsanno codsiga iyo horumarinta calaamadaha cusub oo qoraal-qoraal ah ardayda dugsiga dhexe. Taas darteed waxaynu isbarbardhignaa noocyo kala duduwan xaaladaha farshaxanka, tusaale ahaan qalcadaha kala duwan iyo qalcadaha waxbarashada e e mool dheer (tusaale ahaan shabakado BiLSTM iyo dhismaha buuxa BERT). Waxaynu muujinnaa in dhismaha waxbarashada e e ku saleysan BERT (tusaale ahaan calaamad iyo fasaxa sentence) oo lagu soo bandhigay lagu soo bandhigayo macluumaadka aan la aqoon, wuxuu helaa midhaha ugu wanaagsan.', 'sv': 'Argumentutvinning hanteras ofta med en pipeline-metod där segmentering av text i argumentativa enheter utförs först och fortsätter med en argumentkomponentidentifieringsuppgift. I denna forskning tillämpar vi en token-nivå klassificering för att identifiera anspråk och premises tokens från en ny korpus argumentativa uppsatser skrivna av gymnasieelever. För detta ändamål jämför vi en mängd toppmoderna modeller såsom diskreta funktioner och djupinlärningsarkitekturer (t.ex. BiLSTM-nätverk och BERT-baserade arkitekturer) för att identifiera argumentkomponenterna. Vi visar att en BERT-baserad inlärningsarkitektur för flera uppgifter (dvs. tokens- och meningsnivåklassificering) som är adaptivt förberedd på en relevant omärkt datauppsättning ger bästa resultat.', 'si': 'පායිපලින් විධානයෙන් පායිපලින් විධානයෙන් ලිපින් විධානයෙන් ලිපින් විධානය කරනවා මුලින්ම ප්\u200dරධානය කරලා ති මේ පරීක්ෂණයේ අපි ප්\u200dරයෝජනය කරන්නේ ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය සඳහා අලුත් ප්\u200dරයෝජනයක් තියෙන්නේ අලුත් ප්\u200dරයෝජනයක් පිළ මේ අවසානයෙන්, අපි විවිදියට ස්ථානයේ කාර්යාත්මක විශේෂ විදියට සම්පූර්ණය කරනවා වගේම විශේෂ අවස්ථාවක් සහ ගොඩක් ඉගෙන ගන්න සිද්ධ අපි ප්\u200dරකාශ කරනවා BERT-අධාරිත බොහොම වැඩි වැඩි වැඩක් ඉගෙන ගන්න සිද්ධාව (ඉතින්, ටෝකෙන් සහ වාක්ය ස්ථානයක්) සම්බන්ධ වැඩි නො', 'ur': 'آرمونٹ مینینگ اکثر ایک پائپ لین طریقہ سے پکارا جاتا ہے جہاں متن کی سیگنٹ آرمونٹ یونیٹوں میں پہلے چلتی ہے اور ایک آرمونٹ رقم کی شناسایی ٹاکس کے ذریعہ چلتی ہے. اس تحقیقات میں، ہم ایک ٹوکین سطح کا کلاسیفوں کے لئے استعمال کرتے ہیں کہ ایک نئی جگہ سے مدینہ اسکول دانش آموزوں کی لکھی ہوئی جھگڑنے والی مثالیں معلوم کریں۔ اس کے لئے ہم ایک مختلف موڈل کے مطابق مطابق کرتے ہیں جیسے مختلف فائدے اور عمیق تعلیم معماری (جیسے BiLSTM نیٹورک اور BERT-بنیاد معماری) کو معلوم کرنے کے لئے۔ ہم دکھاتے ہیں کہ ایک BERT-based multi-task learning architecture (یعنی token and sentence level classification) ایک معاملہ غیر معاملہ ڈاٹ سٹ پر اچھے نتائج حاصل کرتا ہے۔', 'ta': 'அருமதி குழந்தைகள் பெரும்பாலாக ஒரு பைப்லைன் முறைமையால் முகவரிக்கப்படுகிறது, அதில் உரையை தர்க்கமான அலகுகளாக பிரித்தல் முதலில் செய்து ஒர இந்த ஆராய்ச்சியில், நாம் ஒரு குறியீடு மட்ட வகுப்பாட்டை பயன்படுத்துகிறோம் நடுநிலை பள்ளி மாணவர்கள் எழுதப்பட்ட ஒரு புதிய வார்த்தை இந்த முடிவிற்கு, நாம் பல்வேறு நிலையில் கலை மாதிரிகளை ஒப்பிடுகிறோம், வேறு வித்தியாசமான குணங்கள் மற்றும் ஆழமான கற்றுக்கொள்ளும் கட்டுரைகள் (உதாரணமாக, பில் நாம் ஒரு BERT-அடிப்படையில் உள்ள பல பணி படிப்பு கற்றுக்கொள்ளும் கட்டுப்பாடு (அதாவது, குறிப்பு மற்றும் வாக்கு வகைப்படுத்தல்) தொடர்பு இல்லாத தகவல் அமைப்பு சிறந்', 'vi': 'Việc khai thác tranh cãi thường được giải quyết bằng một phương pháp dẫn đường nơi việc phân chia văn bản thành các đơn vị cãi vã được thực hiện trước và thực hiện bởi một nhiệm vụ nhận dạng các phần tranh luận. Trong nghiên cứu này, chúng tôi áp dụng một mức độ tượng trưng để xác định các vật thể và tiền tiêu chuẩn của một tập hợp các bài luận tố được viết bởi các học sinh trung học. Với mục đích này, chúng tôi so sánh các mô hình hiện đại, như các tính năng riêng lẻ và các kiến trúc sâu học (v.d. mạng BiLSTM và các kiến trúc dựa trên giao đậu) để xác định các thành phần cãi. Chúng tôi chứng minh rằng một kiến trúc trình học đa nhiệm vụ của BERT (ví dụ, phân loại hình tượng và mức án) thích đáng được sử dụng dựa trên một bộ dữ liệu chưa đóng kín liên quan đạt kết quả tốt nhất.', 'uz': "@ info: whatsthis Bu ta'qituvda, biz o'rta maktab o'quvchilari tomonidan qo'llangan yangi qismlarni aniqlash va o'rganish qoidalarini aniqlash uchun signalni qo'llamiz. Shunday qilib, biz murakkablar komponentlarini aniqlash uchun har xil holatning holatiga bir necha modellarga kamaytamiz. Biz BERT asosida bir necha vazifa o'rganish maktabi (m'anaviy tizim va gapning darajasi) o'xshash ko'rsatuvchimiz. Maʼlumotlar tizimi notoʻgʻri bajarilmagan narsalarning eng yaxshi natijaga ega bo'ladi.", 'bg': 'Изваждането на аргументи често се разглежда чрез метод на тръбопровод, при който сегментирането на текста в аргументативни единици се извършва първо и се извършва от задача за идентифициране на компонента на аргумента. В настоящото изследване прилагаме класификация на ниво символ за идентифициране на твърдения и предпоставки от нов корпус от аргументативни есета, написани от ученици от средното училище. За тази цел сравняваме различни съвременни модели като дискретни функции и архитектури за дълбоко обучение (напр. мрежи БиЛСТМ и архитектури базирани на BERT), за да идентифицираме компонентите на аргументите. Ние демонстрираме, че базираната многозадача архитектура за обучение (т.е. класификация на ниво символ и изречение), адаптивно предварително обучена върху съответна неназначена база данни, получава най-добри резултати.', 'nl': 'Argument mining wordt vaak aangepakt door een pipeline methode waarbij segmentatie van tekst in argumentatieve eenheden eerst wordt uitgevoerd en wordt voortgezet door een argumentcomponent identificatie taak. In dit onderzoek passen we een token-level classificatie toe om claim en premise tokens te identificeren uit een nieuw corpus van argumentatieve essays geschreven door middelbare scholieren. Hiervoor vergelijken we verschillende state-of-the-art modellen zoals discrete features en deep learning architecturen (bijvoorbeeld BiLSTM netwerken en BERT-gebaseerde architecturen) om de argumentcomponenten te identificeren. We tonen aan dat een BERT-gebaseerde multi-task learning architectuur (d.w.z. token- en zinsclassificatie) adaptief vooraf getraind op een relevante niet-gelabelde dataset de beste resultaten oplevert.', 'da': 'Argumentmining behandles ofte ved hjælp af en pipeline metode, hvor segmentering af tekst i argumentative enheder udføres først og fortsættes af en argumentkomponentidentifikationsopgave. I denne forskning anvender vi en tokenniveau klassificering til at identificere krav og præmis tokens fra et nyt korpus af argumentative essays skrevet af mellemskoleelever. Til dette formål sammenligner vi en række avancerede modeller såsom diskrete funktioner og deep learning arkitekturer (f.eks. BiLSTM-netværk og BERT-baserede arkitekturer) for at identificere argumentkomponenterne. Vi demonstrerer, at en BERT-baseret multi-task learning arkitektur (dvs. token- og sætningsniveau klassificering) adaptivt forudtrænet på et relevant mærket datasæt opnår de bedste resultater.', 'id': 'Argument mining is often addressed by a pipeline method where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task.  Dalam penelitian ini, kami menerapkan klasifikasi tingkat token untuk mengidentifikasi klaim dan premise token dari tubuh baru essai argumentatif ditulis oleh siswa sekolah menengah. Untuk tujuan ini, kita membandingkan berbagai jenis model terbaik seperti ciri-ciri diskret dan arsitektur belajar dalam (contohnya jaringan BiLSTM dan arsitektur berdasarkan BERT) untuk mengidentifikasi komponen argumen. Kami menunjukkan bahwa arsitektur pembelajaran berbagai tugas berdasarkan BERT (i.e., klasifikasi tingkat token dan kalimat) yang diadaptasi secara adaptif pada set data tidak berlebihan relevan mendapatkan hasil terbaik.', 'ko': '논거 발굴은 통상적으로 유수선 방법을 채택하여 먼저 텍스트를 논거 단원으로 분할한 다음에 논거 성분 식별 임무를 진행한다.이 연구에서 우리는 표기 단계의 분류를 응용하여 새로운 중학생 의논문 자료 라이브러리에서 주장과 전제 표기를 식별한다.이를 위해 개별 피쳐와 딥러닝 아키텍처(예: BilSTM 네트워크와 BERT 기반 아키텍처)와 같은 다양한 최첨단 모델을 비교하여 패라메트릭 어셈블리를 결정했습니다.우리는 관련 미표기 데이터 집합에서 버트의 다중 임무 학습 구조(즉 표기와 문장급 분류)에 적응하면 최상의 결과를 얻을 수 있음을 증명했다.', 'fa': 'اغلب توسط یک روش لوله دریافت می\u200cشود که جدایی متن به واحدهای دلیل اول انجام می\u200cشود و توسط یک وضعیت شناسایی عناصر اردوмент ادامه می\u200cدهد. در این تحقیقات، ما یک گروهی از سطح معجزه برای شناسایی معجزه\u200cها و نشانه\u200cهایی از یک جسد جدید از رسانه\u200cهای مطمئنی که توسط دانشجویان مدرسه مرکزی نوشته شده\u200cاند استفاده می\u200cکنیم. برای این قسمت، ما متفاوت مدل های موقعیت هنری را مقایسه می کنیم، مانند ویژگی های مختلف و معماری های عمیق یادگیری (مثلا شبکه BiLSTM و معماری های بنیاد BERT) برای شناسایی بخش های حجت. ما نشان می دهیم که یک معماری تعلیم زیادی از کار بر BERT (یعنی توکین و مجازات سطح مجازات) به طور اضافه روی یک مجموعه اطلاعات متعلق به نامزدی متعلق به بهترین نتایج می یابد.', 'de': 'Argument Mining wird oft durch eine Pipeline-Methode adressiert, bei der zuerst die Segmentierung von Text in argumentative Einheiten durchgeführt wird und von einer Argumentkomponente Identifikationsaufgabe fortgesetzt wird. In dieser Forschung wenden wir eine Token-Level-Klassifizierung an, um Claim- und Prämisse-Token aus einem neuen Korpus argumentativer Essays von Mittelschülern zu identifizieren. Dazu vergleichen wir eine Vielzahl von State-of-the-Art Modellen wie diskrete Features und Deep Learning Architekturen (z.B. BiLSTM Netzwerke und BERT-basierte Architekturen), um die Argumentkomponenten zu identifizieren. Wir zeigen, dass eine BERT-basierte Multi-Task-Lernarchitektur (d.h. Token- und Satzebene-Klassifizierung) adaptiv auf einem relevanten, nicht beschrifteten Datensatz vortrainiert, die besten Ergebnisse erzielt.', 'af': "Argument mining is dikwels ingeadres deur 'n pipelyn metode waar segmentasie van teks in argumentatiewe eenhede eerste gedoen word en voortgaan deur 'n argument komponent identifikasie taak. In hierdie ondersoek, het ons 'n token-vlak klasifikasie aangepas om voorsoek en voorsoek tekens te identifiseer van 'n nuwe korpus van argumentatiewe eseye geskrywe deur middelskool studente. Na hierdie einde vergelyk ons 'n verskillende state-of-the-art modele soos diskrete funksies en diep leer arkitektuure (bv. BiLSTM netwerke en BERT-gebaseerde arkitektuure) om die argument komponente te identifiseer. Ons wys dat 'n BERT-gebaseerde multi-taak leer-arkitektuur (bv. token en seënvlak klasifikasie) adaptief op 'n relevant e ongeabelde datastel die beste resultate kry.", 'sq': 'Miniera e argumenteve shpesh trajtohet nga një metodë tubacioni ku segmentimi i tekstit në njësi argumentuese kryehet së pari dhe vazhdon nga një detyrë identifikimi i komponenteve të argumentit. Në këtë kërkim, ne aplikojmë një klasifikim të nivelit të shenjave për të identifikuar pretendimet dhe parashikuar shenjat nga një trup i ri esej argumentuese të shkruara nga studentët e shkollës së mesme. Për këtë qëllim, ne krahasojmë një varietet modelesh të moderne të tilla si karakteristikat diskrete dhe arkitekturat e mësimit të thellë (për shembull rrjetet BiLSTM dhe arkitekturat me bazë në BERT) për të identifikuar komponentet e argumentit. Ne demonstrojmë se një arkitekturë mësimi me shumë detyra bazuar në BERT (pra, klasifikimi i nivelit të shenjave dhe dënimeve) e parastërvitur në mënyrë adaptuese në një grup të dhënash të rëndësishme pa shënuar merr rezultatet më të mira.', 'am': 'የአርጉም ማቀናጃ መቆጣጠሪያ በመጀመሪያ እና በተጨማሪው አካባቢ ስራ የጽሑፉን ማውቀት በተጨማሪው እቅድ በተደረገበት በኪፕላን method ይታሰራል፡፡ In this research, we apply a token-level classification to identify claim and premise tokens from a new corpus of argumentative essays written by middle school students.  ለዚህ ምክንያት፣ ለጥልቅ ምርጫዎች እና ጥልቅ ትምህርት መሠረት (ምሳሌ ቢልSTM መረብ እና BERT-based መሠረት) አካባቢዎችን እናሳውቃለን፡፡ BERT-based ብዙዎችን የስራ ትምህርት መሠረት (ምናልባት እና የቁጥጥር ክፍል) በተለየ ባይታወቀው ዳታ ሳትሰር የተሻለ ፍሬዎችን እንዲያገኝ እናሳየዋለን፡፡', 'hy': 'Արգենտիվ հանքահանումը հաճախ վերաբերվում է խողովակաշարի մեթոդի միջոցով, որտեղ տեքստի սեգմետրացիան արգենտիվ միավորների մեջ առաջինը կատարվում է և շարունակվում է արգենտիվ բաղադրիչների հայտնաբերման գործ Այս ուսումնասիրության մեջ մենք կիրառում ենք նշանների մակարդակի դասակարգման, որպեսզի բացահայտենք և պատկերացնենք նշանները միջնակարգ դպրոցի ուսանողների գրված նոր բանավեճող էսսերի մարմնից: To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components.  We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.', 'sw': 'Ukimwengu wa madini mara nyingi hujadiliwa na njia ya pipeline ambapo kuchaguliwa kwa ujumbe wa maandishi katika vifaa vya hoja vinaendelewa kwanza na kuendelea na jukumu la kutambua hoja. Katika utafiti huu, tunatumia ufafanuzi wa kiwango cha alama ili kutambua madai na kuweka ishara kutoka kwenye makampuni mpya ya masomo ya hoja yaliyoandikwa na wanafunzi wa shule za kati. To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components.  Tunaonyesha kwamba ujenzi wa kujifunza kwa kazi mbalimbali anayeishi BERT (yaani kwa kiwango cha alama na kiwango cha sentenca) unaonyesha kwa utaratibu wa taarifa zisizoeleweka unapata matokeo bora.', 'az': 'Argument mining sık-sık mətn segmentasiyasının argumenti birliklərə ilk dəfə işlədiyi və argumenti komponent təsdiqləmə görevi ilə davam edir. Bu araştırma içində, orta məktəb öğrencilərinin yazıldığı yeni dəyişiklik dəyişikliklərin təsdiqlənməsi və təsdiqlənməsi üçün dəyişiklik səviyyəsini təyin edirik. Bütün bunlara g örə, müxtəlif möcüzələri və dərin öyrənmə arhitektarları (BiLSTM a ğları və BERT-tabanlı arhitektarları) müəyyən etdik. Biz BERT-ə dayanan çoxlu i ş öyrənmə arhitektarının (məsələlər, token və cümlələr səviyyəsi klasifikasyonu) müəyyən edilməmiş veri qutusunun ən yaxşı sonuçlarını qazandığını göstəririk.', 'bn': 'Argument mining is often addressed by a pipeline method where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task.  এই গবেষণায় আমরা একটি চিহ্নিত পর্যায়ের ক্লাসাফিকেশন প্রয়োগ করি মধ্যস্কুলের ছাত্রীদের লেখা একটি নতুন কোর্পাস থেকে দাবি এবং প্রাথমিক চ এই পর্যন্ত আমরা বিভিন্ন ধরনের রাষ্ট্র-শিল্পের মডেলের তুলনা করি যেমন বিভিন্ন বৈশিষ্ট্য এবং গভীর শিক্ষা প্রতিষ্ঠান (যেমন বিএলস্টিম নেটওয়ার্ক এবং বিআরটি ভিত্তি আমরা দেখাচ্ছি যে বেরেট-ভিত্তিক বহুকাজ শিক্ষা কাঠামোর (যেমন চিহ্ন এবং শাস্তি পর্যায়ের ক্লাসাফেশন) সাধারণ মানুষের মাধ্যমে সংশ্লিষ্ট তথ্যের বিষ', 'ca': "La mineria d'arguments sovint es tracta per un mètode de pipeline on la segmentació del text en unitats argumentatives es lleva a cabo primer i es procede per una tasca d'identificació de components argumentativs. En aquesta recerca, aplicam una classificació de nivell de fitxes per identificar les reclamacions i premisar fitxes d'un nou cos d'essais argumentatius escrits pels estudiants de l'institut. A aquest efecte, comparem una varietat de models d'última edat com característiques discretes i arquitectures d'aprenentatge profund (per exemple, xarxes BiLSTM i arquitectures basades en BERT) per identificar els components d'arguments. We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.", 'tr': 'Argument küýşigi köplenç bir pipeline yöntemi tarapyndan berilýar. Bu ýerde metin segmentasiýasyny argüm birine ýöredi we bir argüm komponenti kimligi buýruky tarapyndan geçirilýar. Bu araştırmalarda orta mekdepler tarapyndan ýazylan taryşma eserlerini tanamak üçin token derejesi klasifikasynda uygulaýarys. Şonuň üçin disket karakterleriň we derin öwrenmek arhitektarlaryň (meselâ, BiLSTM şebekeleri we BERT tabanly arhitektarlaryň) düzümlerini tanyşdyrmak üçin bir näçe çe şitli möhümleri karşılaşdyrýarys. BERT-dan daýanýan bir multi-täblik öwrenme arhitektegi (meselâ, token we sözlem derejesi klasifikasyýasy) möhüm baglanmaýan bir dataset i ň üstine iň gowy netijesi bar diýip görkezilýäris.', 'bs': 'Rušenje argument a često se obraća metodom cjevi gdje se segmentacija teksta u argumentativne jedinice prvo vodi i nastavlja zadatak identifikacije komponenta argumentacija. U ovom istraživanju, primjenjujemo klasifikaciju nivoa znakova za identifikaciju zahtjeva i predstavljanje znakova novog korpusa argumentativnih eseja napisanih od studenata srednje škole. Za taj cilj, uspoređujemo razne modele države umjetnosti poput diskretnih karakteristika i duboke arhitekture učenja (npr. BiLSTM mreže i arhitekture bazirane na BERT) kako bi identifikovali komponente argument a. Pokazujemo da arhitektura za učenje multizadataka na BERT-u (tj. klasifikacija nivoa znakova i rečenica) prilagodno pretvara na relevantni neizbiljni komplet podataka dobija najbolji rezultat.', 'hr': 'Rudnja argomenata često se obraća metodom cjevi gdje se prvo provodi segmentacija teksta u argumentativne jedinice i nastavlja zadatak identifikacije komponenta argumentacija. U ovom istraživanju, primjenjujemo klasifikaciju razine znakova za identifikaciju zahtjeva i priznanja znakova novog korpusa argumentativnih eseja napisanih od studenata srednje škole. Za taj cilj uspoređujemo razne modele države umjetnosti poput diskretnih karakteristika i duboke učenje arhitekture (npr. BiLSTM mreže i arhitekture bazirane na BERT) kako bi identifikovali komponente argument a. Pokazujemo da arhitektura multizadataka (tj. klasifikacija znakova i razine kazne) na BERT-u prilagođena prilagodno pretvaranja na relevantni nezabenirani komplet podataka dobija najbolji rezultat.', 'cs': 'Argument mining je často řešen metodou potrubí, kde je nejprve provedena segmentace textu do argumentativních jednotek a postupována úlohou identifikace komponent argumentů. V tomto výzkumu používáme klasifikaci na úrovni tokenů k identifikaci tokenů a předpokladů z nového korpusu argumentativních esejí napsaných studenty středních škol. Za tímto účelem porovnáváme řadu nejmodernějších modelů, jako jsou diskrétní funkce a architektury hlubokého učení (např. BiLSTM sítě a architektury založené na BERT), abychom identifikovali komponenty argumentů. Dokazujeme, že víceúlohová výuková architektura založená na BERT (tj. klasifikace na úrovni tokenů a vět) adaptivně trénovaná na relevantní neoznačené datové sadě dosahuje nejlepších výsledků.', 'fi': 'Argumentin louhintaa kﾃ､sitellﾃ､ﾃ､n usein pipeline-menetelmﾃ､llﾃ､, jossa tekstin segmentointi argumentoiviksi yksikﾃｶiksi suoritetaan ensin ja jatketaan argumenttikomponentin tunnistustehtﾃ､vﾃ､llﾃ､. Tﾃ､ssﾃ､ tutkimuksessa sovellamme token-tason luokitusta tunnistamaan vﾃ､itteet ja lﾃ､htﾃｶkohdat lukiolaisten kirjoittamasta argumentoivasta esseestﾃ､. Tﾃ､tﾃ､ varten vertailemme erilaisia huippuluokan malleja, kuten erillisiﾃ､ ominaisuuksia ja syvﾃ､oppimisarkkitehtuuria (esim. BiLSTM-verkot ja BERT-pohjaiset arkkitehtuurit), argumenttikomponenttien tunnistamiseksi. Osoitamme, ettﾃ､ BERT-pohjainen monitehtﾃ､vﾃ､oppimisarkkitehtuuri (eli token- ja lausetasoluokitus), joka on adaptiivisesti esikoulutettu asiaankuuluvaan merkitsemﾃ､ttﾃｶmﾃ､ﾃ､n aineistoon, tuottaa parhaat tulokset.', 'et': 'Argumentide kaevandamist käsitletakse sageli torujuhtme meetodil, kus teksti segmenteerimine argumentatiivseteks üksusteks viiakse läbi esmalt ja jätkatakse argumentide komponentide identifitseerimise ülesandega. Käesolevas uurimuses rakendame token-taseme klassifikatsiooni, et tuvastada väite- ja eeldusmärke uuest põhikooliõpilaste kirjutatud argumentatiivsete esseede korpusest. Selleks võrdleme erinevaid tipptasemel mudeleid, nagu diskreetsed funktsioonid ja sügavõppe arhitektuurid (nt BiLSTM võrgud ja BERT-põhised arhitektuurid), et tuvastada argumendikomponente. Näitame, et BERT-põhine mitmeülesandeline õppearhitektuur (st märgi- ja lausetaseme klassifikatsioon), mis on adaptiivselt eeltreenitud asjakohasele märgistamata andmekogumile, annab parimad tulemused.', 'sk': 'Argumentno rudarjenje se pogosto obravnava s plinovodno metodo, kjer se segmentacija besedila v argumentativne enote najprej izvede in nadaljuje z opravilom identifikacije komponent argumenta. V raziskavi uporabljamo klasifikacijo na stopnji žetonov za identifikacijo žetonov in predpostavk iz novega korpusa argumentativnih esejev, ki so jih napisali dijaki srednje šole. V ta namen primerjamo različne najsodobnejše modele, kot so diskretne funkcije in arhitekture globokega učenja (npr. omrežja BiLSTM in arhitekture na podlagi BERT), da bi identificirali komponente argumentov. Dokazujemo, da arhitektura večopravil učenja, ki temelji na BERT (tj. klasifikacija na ravni žetonov in stavkov), prilagodljivo predvadljena na ustreznem neoznačenem naboru podatkov, doseže najboljše rezultate.', 'he': 'מכירת הטעות מתייחסת לעתים קרובות על ידי שיטת צינורות שבה החלק של טקסט ליחידות הטעות מתבצע קודם וממשיך על ידי משימה זיהוי רכיב הטעות. במחקר הזה, אנו משתמשים בהקליטה ברמה של סימנים לזהות תביעות ולהעלות סימנים מגופה חדשה של מאמרים מתווכחים שנכתבו על ידי תלמידי בית הספר התיכון. למטרה זו, אנו שווים מגוון של מודלים חדשים כמו תכונות דיסקרטיות וארכיטקטורות למידה עמוקה (למשל רשתות BiLSTM וארכיטקטורות מבוססות על BERT) כדי לזהות את רכיבי הטיעון. אנו מראים כי ארכיטקטורה למידה רבה-משימות מבוססת על BERT (כלומר, סיווג רמת סימנים ומשפטים) מוקדמת בהתאם על קבוצת נתונים רלוונטית ללא סימנים מקבלת את התוצאות הטובות ביותר.', 'ha': "An yi addu'a da kimar argument ko yawa da wata metode na pipe, inda firam-matsayin zuwa sunaye masu husũma ta farko da aka goyi na aikin wani aikin shaidar ɗin argument. Daga wannan littafin, Munã amfani da wata alama-daraja don mu iya gane matsayin su da kuma ko gabatar da alama daga wata sabo na sabo da aka rubũta na karatun iskomin tsakanin. Ga wannan, Munã daidaita misãlai masu cikin-hãlin-sanar kamar masu yin shakka da masu tsari masu ƙaranci (misali, zanen BiLStM da bakin filayenaiki na BERT) dõmin ka gane ƙanshi ɗin. We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.", 'jv': 'Report translation bugs to <\\.\\.\\.> Nang barêng-barêng iki, kita ngubah perusahaan kelas token kanggo nambah winih lan ijolan winih dhéwé kuwi mau Saiki iki, kita nambah akeh model sing sampeyan stêt-sampeyan karo akeh dumaten karo architecture sing ngregani soko ibuot Awak dhéwé éntukno karo BERT-basa akeh multi-task Learn architecture (i.e.g. token lan soko kelompok barang nggambar)', 'bo': 'Argument mining is often addressed by a pipeline method where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task. དབྱེ་ཞིབ་འདིའི་ནང་དུ་ང་ཚོས་རྣམས་ཀྱི་དབྱེ་རིམ་གྱི་རྣམ་པ་ཞིག་དང་མཐུན་ཁག་རྩོམ་པ་ཞིག་གི་ནང་ནས་མཐུན་སྒྲིག་གཏོང་མཁན་གཙ To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components. ང་ཚོས་BERT་ལ་གཞི་རྟེན་ནས་བྱ་འགུལ་གྱི་སྣ་མང་བྱ་འགུལ་གྱི་བཟོ་བཀོད་པ་ཞིག་མངོན་གསལ་བཤད་བྱས།'}
