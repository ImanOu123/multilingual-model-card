{'en': 'Formal Basis of a Language Universal', 'ar': 'الأساس الرسمي للغة عالمي', 'ja': '普遍言語の形式的基礎', 'fr': "Bases formelles d'un universel linguistique", 'pt': 'Base Formal de uma Linguagem Universal', 'es': 'Base formal de un lenguaje universal', 'zh': '通用语言之文', 'hi': 'एक भाषा यूनिवर्सल का औपचारिक आधार', 'ru': 'Формальная основа универсального языка', 'ga': 'Bunús Foirmiúil Teanga Uilíoch', 'ka': 'უნივერსალური ენის ფორმალური ბაზი', 'el': 'Επίσημη βάση μιας καθολικής γλώσσας', 'hu': 'Az univerzális nyelv formális alapja', 'it': 'Base formale di una lingua universale', 'kk': 'Universal тілдің пішімдік негізі', 'lt': 'Universalios kalbos formalus pagrindas', 'ms': 'Asas Formal bagi Bahasa Universal', 'mk': 'Формална база на јазик универзален', 'mt': 'Bażi Formali ta’ Lingwa Universali', 'ml': 'Language Universal', 'no': 'Name', 'mn': 'Дэлхийн хэлний формал суурь', 'ro': 'Baza formală a unei limbi universale', 'pl': 'Formalna podstawa języka uniwersalnego', 'so': 'Formal Basis of a Language Universal', 'si': 'Name', 'sr': 'Formalna osnova univerzalnog jezika', 'sv': 'Formell grund för ett språk universellt', 'ta': 'மொழி பொதுவான அடிப்படை', 'ur': 'Name', 'uz': 'Formal Basis of a Language Universal', 'vi': 'Căn bản chính thức của ngôn ngữ chung', 'bg': 'Официална основа на универсален език', 'hr': 'Formalna osnova univerzalnog jezika', 'nl': 'Formele basis van een universele taal', 'da': 'Formelt grundlag for et sprog universelt', 'id': 'Formal Basis of a Language Universal', 'ko': '통용 언어의 형식적 기초', 'sw': 'Msingi wa awali wa lugha ulimwengu', 'de': 'Formelle Grundlagen einer universellen Sprache', 'fa': 'Basis Formal of a Language Universal', 'af': "Formale Basis van 'n Taal Universele", 'tr': 'Diliň kadroli', 'sq': 'Baza Formale e një Gjuha Universale', 'am': 'ቋንቋ', 'az': 'Universal Dilin Formal Basisi', 'hy': 'Լեզու համաշխարհային ֆորմալ հիմք', 'ca': "Base formal d'una llengua universal", 'bn': 'Formal Basis of a Language Universal', 'cs': 'Formální základ univerzálního jazyka', 'fi': 'Yleisen kielen virallinen perusta', 'bs': 'Formalna osnova univerzalnog jezika', 'et': 'Universaalse keele ametlik alus', 'jv': 'Tampilan Pamisasi Language Universal', 'sk': 'Uradna osnova univerzalnega jezika', 'ha': 'Formal Basis of a Language Universal', 'he': 'בסיס רשמי של שפה Universal', 'bo': 'སྐད་ཡིག་ཆ་སྤྱི་ཚོགས་ཀྱི་རྩ་བའི་གཞི་གཞི་རྟེན'}
{'en': 'Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the separable permutations. This class of permutations is exactly the class that can be expressed in combinatory categorial grammars (CCGs). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions. The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schrder Number Sn1. Because that number grows much more slowly than the n ! number of all permutations, this generalization is also of considerable practical interest for computational applications such as parsing and machine translation. The present article examines the mathematical and computational origins of this restriction, and the reason it is exactly captured in CCG without the imposition of any further constraints.', 'ar': 'يقترح الخلاصة Steedman (2020) كعموم رسمي لقواعد اللغة الطبيعية أن التباديل النحوي من النوع الذي أدى إلى ظهور القواعد التحويلية يقتصر على فئة معروفة لدى علماء الرياضيات وعلماء الكمبيوتر باسم التباديل "القابل للفصل". هذه الفئة من التباديل هي بالضبط الفئة التي يمكن التعبير عنها في قواعد النحو الفئوية التجميعية (CCGs). يبدو أن التبديلات المستبعدة غير القابلة للفصل غائبة في عدد من دراسات التباين اللغوي المتقاطع في ترتيب الكلمات في التراكيب الاسمية واللفظية. ينمو عدد التباديل التي يمكن فصلها في عدد n من العناصر المعجمية في البناء مثل عدد شرودر الكبير Sn − 1. لأن هذا الرقم ينمو بشكل أبطأ بكثير من n! عدد جميع التباديل ، هذا التعميم هو أيضًا ذو أهمية عملية كبيرة للتطبيقات الحسابية مثل التحليل والترجمة الآلية. تبحث هذه المقالة في الأصول الرياضية والحسابية لهذا التقييد ، والسبب في أنه تم تسجيله بالضبط في CCG دون فرض أي قيود أخرى.', 'fr': "Résumé Steedman (2020) propose comme universel formel de la grammaire du langage naturel que les permutations grammaticales du type qui ont donné lieu à des règles transformationnelles soient limitées à une classe connue des mathématiciens et des informaticiens sous le nom de permutations «\xa0séparables\xa0». Cette classe de permutations est exactement la classe qui peut être exprimée dans les grammaires catégorielles combinatoires (CCG). Les permutations non séparables exclues semblent en fait absentes dans un certain nombre d'études sur la variation interlinguistique de l'ordre des mots dans les constructions nominales et verbales. Le nombre de permutations séparables augmente dans le nombre n d'éléments lexicaux dans la construction au fur et à mesure que le grand nombre de Schröder Sn-1. Parce que ce nombre augmente beaucoup plus lentement que le nombre n\xa0! nombre de toutes les permutations, cette généralisation présente également un intérêt pratique considérable pour les applications informatiques telles que l'analyse syntaxique et la traduction automatique. Le présent article examine les origines mathématiques et informatiques de cette restriction, et la raison pour laquelle elle est exactement capturée dans CCG sans imposer d'autres contraintes.", 'es': 'Resumen Steedman (2020) propone como un universal formal de la gramática del lenguaje natural que las permutaciones gramaticales del tipo que han dado lugar a reglas transformacionales se limiten a una clase conocida por los matemáticos y los informáticos como las permutaciones «separables». Esta clase de permutaciones es exactamente la clase que se puede expresar en gramáticas categoriales combinatorias (CCG). De hecho, las permutaciones no separables excluidas parecen estar ausentes en varios estudios de variación interlingüística en el orden de las palabras en construcciones nominales y verbales. El número de permutaciones separables crece en el número n de elementos léxicos de la construcción como el número de Schröder grande Sn-1. Porque ese número crece mucho más lentamente que la n! número de todas las permutaciones, esta generalización también es de considerable interés práctico para aplicaciones computacionales como el análisis y la traducción automática. El presente artículo examina los orígenes matemáticos y computacionales de esta restricción, y la razón por la que se captura exactamente en CCG sin la imposición de ninguna otra restricción.', 'pt': 'Resumo Steedman (2020) propõe como universal formal da gramática da linguagem natural que as permutações gramaticais do tipo que deram origem às regras transformacionais são limitadas a uma classe conhecida por matemáticos e cientistas da computação como as permutações “separáveis”. Esta classe de permutações é exatamente a classe que pode ser expressa em gramáticas categoriais combinatórias (CCGs). As permutações não separáveis excluídas de fato parecem estar ausentes em vários estudos de variação interlinguística na ordem das palavras em construções nominais e verbais. O número de permutações que são separáveis cresce no número n de elementos lexicais na construção como o Grande Número de Schröder Sn−1. Porque esse número cresce muito mais lentamente do que o n! número de todas as permutações, essa generalização também é de considerável interesse prático para aplicações computacionais, como análise sintática e tradução automática. O presente artigo examina as origens matemáticas e computacionais dessa restrição e o motivo pelo qual ela é exatamente capturada no CCG sem a imposição de outras restrições.', 'ja': '抽象的スティードマン（ Abstract Steedman, 2020 ）は、自然言語文法の形式的普遍性として、変換規則を生み出したような文法的順列は、「分離可能な」順列として数学者やコンピュータ科学者に知られているクラスに限定されると提案している。 この置換のクラスは、まさに組み合わせ分類文法（ CCG ）で表現できるクラスです。 除外された分離不可能な順列は、実際には、公称および言語構成における単語順序のクロスリンギスティック変動のいくつかの研究には存在しないように思われる。 分離可能な順列の数は、大シュローダー数Sn − 1として構築された語彙要素の数nで増加する。 この数は、すべての順列のn!数よりもはるかにゆっくりと増加するため、この一般化は、構文解析や機械翻訳などの計算アプリケーションにとってもかなり実用的な関心がある。 本論文は、この制限の数学的および計算的起源、ならびにそれがさらなる制約を課すことなくCCGに正確に捕捉される理由を検討する。', 'zh': '摘要 Steedman(2020)建言,为自然语言语法通用,生转换之法者语法止于数学家计算机科学家谓之可离之类。 此其所以合类 (CCG) 文法也。 事实之上,名动词构中词序跨语变化之中,不可离列若无。 可离者列数在构造中词法元素 n 数中长为大施罗德数 Sn−1。 以其数增长速度多于n慢得! 凡诸排列之数,此泛化于计用(若解析与机器翻译),亦有大实际意义。 本文究其限数学及计算起源,及无所加,于CCG中确获故也。', 'hi': 'सार Steedman (2020) प्राकृतिक भाषा व्याकरण के एक औपचारिक सार्वभौमिक के रूप में प्रस्तावित है कि जिस तरह के व्याकरणिक क्रमपरिवर्तन ने परिवर्तनकारी नियमों को जन्म दिया है, वह गणितज्ञों और कंप्यूटर वैज्ञानिकों को "वियोज्य" क्रमपरिवर्तन के रूप में ज्ञात वर्ग तक सीमित है। क्रमपरिवर्तन का यह वर्ग बिल्कुल वह वर्ग है जिसे संयुक्त श्रेणीबद्ध व्याकरण (CCGs) में व्यक्त किया जा सकता है। बहिष्कृत गैर-वियोज्य क्रमपरिवर्तन वास्तव में नाममात्र और मौखिक निर्माणों में शब्द क्रम में क्रॉसलिंग्विस्टिक भिन्नता के कई अध्ययनों में अनुपस्थित प्रतीत होते हैं। क्रमपरिवर्तनों की संख्या जो वियोज्य हैं, निर्माण में लेक्सिकल तत्वों की संख्या n में बड़े श्रोडर संख्या Sn−1 के रूप में बढ़ती है। क्योंकि यह संख्या एन की तुलना में बहुत धीरे-धीरे बढ़ती है! सभी क्रमपरिवर्तनों की संख्या, यह सामान्यीकरण भी पार्सिंग और मशीन अनुवाद जैसे कम्प्यूटेशनल अनुप्रयोगों के लिए काफी व्यावहारिक रुचि का है। वर्तमान लेख इस प्रतिबंध के गणितीय और कम्प्यूटेशनल मूल की जांच करता है, और इसका कारण यह है कि यह वास्तव में किसी भी आगे की बाधाओं को लागू किए बिना सीसीजी में कब्जा कर लिया गया है।', 'ru': 'Абстрактный Стидман (2020) предлагает в качестве формального универсального понятия грамматики естественного языка, что грамматические перестановки такого рода, которые привели к трансформационным правилам, ограничиваются классом, известным математикам и информатикам как «разделяемые» перестановки. Этот класс перестановок является именно тем классом, который может быть выражен в комбинированных категориальных грамматиках (CCG). Исключенные нераздельные перестановки фактически отсутствуют в ряде исследований перекрестных языковых вариаций в порядке слов в номинальных и словесных конструкциях. Число перестановок, которые являются разделимыми, растет в числе n лексических элементов в конструкции, как большое число Шредера Sn−1. Поскольку это число растет гораздо медленнее, чем n! количество всех перестановок, это обобщение также представляет значительный практический интерес для вычислительных приложений, таких как синтаксический анализ и машинный перевод. В настоящей статье рассматриваются математические и вычислительные истоки этого ограничения и причина, по которой оно точно отражено в CCG без введения каких-либо дополнительных ограничений.', 'ga': 'Molann Abstract Steedman (2020) mar ghramadach teanga nádúrtha uilíoch uilíoch go ndéanfaí iomalartaithe gramadaí den chineál a d’eascair as rialacha bunathraithe a theorannú d’aicme a bhfuil aithne ag matamaiticeoirí agus ríomheolaithe air mar na hathraithe “inscartha”. Is é an aicme seo de iomalartaithe go díreach an rang ar féidir a chur in iúl i ngramadach chatagóireach comhcheangailte (CCGanna). Is cosúil go bhfuil na iomalartaithe neamh-dheighilte eisiata as láthair i roinnt staidéar ar éagsúlacht thrastheangach in ord focal i dtógálacha ainmniúla agus briathartha. Fásann líon na n-athlasadh atá inscartha i líon n na n-eilimintí foclóireachta sa tógáil mar an Uimhir Schröder Mhór Sn−1. Toisc go bhfásann an uimhir sin i bhfad níos moille ná an n! Le líon na n-athruithe ar fad, tá an-suim phraiticiúil ag baint leis an ginearálú seo freisin maidir le feidhmeanna ríomhaireachtúla mar pharsáil agus aistriúchán meaisín. Scrúdaíonn an t-alt seo bunús matamaitice agus ríomhaireachtúil an tsriain seo, agus an fáth go bhfuil sé gafa go beacht sa CCG gan aon srianta breise a chur i bhfeidhm.', 'el': 'Ο Στήντμαν (2020) προτείνει ως τυπικό καθολικό της γραμματικής φυσικής γλώσσας ότι οι γραμματικές αλλοιώσεις του είδους που έχουν προκαλέσει μετασχηματιστικούς κανόνες περιορίζονται σε μια τάξη γνωστή στους μαθηματικούς και τους επιστήμονες υπολογιστών ως "διαχωρίσιμες" αλλοιώσεις. Αυτή η κατηγορία των μεταλλεύσεων είναι ακριβώς η κατηγορία που μπορεί να εκφραστεί σε συνδυασμένες κατηγοριακές γραμματικές (CCG). Οι εξαιρούμενες μη διαχωρίσιμες αλλοιώσεις φαίνεται πράγματι να απουσιάζουν σε μια σειρά μελετών διασταυρούμενης διακύμανσης της τάξης των λέξεων σε ονομαστικές και λεκτικές κατασκευές. Ο αριθμός των διαστάσεων που είναι διαχωρίσιμες αυξάνεται στον αριθμό των λεξικών στοιχείων στην κατασκευή ως ο μεγάλος αριθμός Σρόντερ Σν-1. Γιατί αυτός ο αριθμός μεγαλώνει πολύ πιο αργά από το ν! Η γενικοποίηση αυτή είναι επίσης σημαντικού πρακτικού ενδιαφέροντος για υπολογιστικές εφαρμογές όπως η ανάλυση και η μηχανική μετάφραση. Το παρόν άρθρο εξετάζει τη μαθηματική και υπολογιστική προέλευση αυτού του περιορισμού, καθώς και τον λόγο που αποτυπώνεται ακριβώς στο CCG χωρίς την επιβολή περαιτέρω περιορισμών.', 'hu': 'Összefoglalás Steedman (2020) a természetes nyelvtani formális univerzális nyelvtaniként azt javasolja, hogy a transzformációs szabályokat eredményező nyelvtani permutációk egy olyan osztályra korlátozódnak, amelyet matematikusok és számítógépes tudósok "elválasztható" permutációként ismernek. Ez a permutációs osztály pontosan az az osztály, amely kombinációs kategóriás nyelvtant (CCG-ket) lehet kifejezni. A kizárt, nem szétválasztható permutációk valójában hiányoznak a névleges és verbális konstrukciók szósorrendjének keresztnyelvű variációjának számos tanulmányában. A szétválasztható permutációk száma az építésben szereplő n lexikális elemek számában nő, mint a Nagy Schroder Szám Sn-1. Mert ez a szám sokkal lassabban nő, mint az n! Ez az általánosítás jelentős gyakorlati érdeklődéssel bír a számítástechnikai alkalmazások, mint például az elemzés és a gépi fordítás. A jelen cikk megvizsgálja ennek a korlátozásnak a matematikai és számítástechnikai eredetét, valamint azt, hogy miért rögzítik pontosan a CCG-ben további korlátozások előírása nélkül.', 'it': "Steedman (2020) propone come universale formale della grammatica del linguaggio naturale che permutazioni grammaticali del tipo che hanno dato origine a regole trasformative sono limitate a una classe conosciuta dai matematici e dagli informatici come permutazioni 'separabili'. Questa classe di permutazioni è esattamente la classe che può essere espressa in grammatiche categoriche combinatorie (CCG). Le permutazioni non separabili escluse sembrano infatti assenti in un certo numero di studi di variazione translinguistica nell'ordine delle parole nelle costruzioni nominali e verbali. Il numero di permutazioni separabili cresce nel numero n di elementi lessicali nella costruzione come il grande numero Schroder Sn-1. Perché quel numero cresce molto più lentamente della n! Questa generalizzazione è anche di notevole interesse pratico per applicazioni computazionali come l'analisi e la traduzione automatica. Il presente articolo esamina le origini matematiche e computazionali di questa restrizione, e il motivo per cui è esattamente catturato in CCG senza l'imposizione di ulteriori vincoli.", 'ka': 'აბსტრაქტიკური სტვედემანი (2020) იყველას, როგორც პირველური ენის გრამატიკური უნიველური, რომელიც განვითარებულია ტრანფორმაციული წესების განვითარებულია, მათემატიკური და კომპიუტერის მეცნიერების კლასის გან ეს პერმუტაციების კლასი არის საკუთარი კლასი, რომელიც შეიძლება გამოსახულება კომბინირო კატეგორიალური გრამეტრებში (CCG). მართლაც არ გაყოფილი პერმუტაციები ფაქტიურად იქნება, როგორც კრესილენგურისტიკური განსხვავებების რაოდენობაში არსებობს სიტყვების განსხვავებაში ნომიალური და გერბალური კო პერმუტაციების რაოდენობა, რომლებიც განყოფილებელია, ლექსიკალური ელემენტების n რაოდენობაში იზრდება როგორც დიდი ქროდერის რიცხვი Sn-1. რადგან ეს რიცხვი უფრო ბალმად ვიდრე n! ყველა პერმუტაციების რაოდენობა, ეს ჯერნალიზაცია ასევე მნიშვნელოვანი პრაქტიკური ინტერესტია კომპუტაციალური პროგრაციებისთვის, როგორც პარასი და მა მიმდინარე წესტილის მათემატიკალური და კომპუტაციალური პირობების შესახებ, და მიზეზი, რომ ის კომპუტაციალურად CCG-ში აღმოჩენა უფრო მეტი შესახებ.', 'kk': 'Абстракт Стейдман (2020) табиғи тіл грамматикасы ретінде негізделген грамматикалық аудармалы ережелерді өзгертетін грамматикалық аудармалы түрлерге шектелген математикалар мен компьютер ғылымдарына "бөлек" пермутациялар ретінде белгіленген класқа Бұл пермутациялардың класы - комбинациялық санаттар граммаларында (CCG) көрсетілетін класы. Бөліктірілмеген пермутациялардың бірнеше бір тілді тілді өзгерістерді сөздердің ретінде номиналды және вербалды құрылымдар үшін бірнеше зерттеулерде жоқ сияқты. Үлкен Шродер нөмірі Sn- 1 деп құрылған лексикалық элементтердің n санында бөлек пермутациялардың саны. Өйткені бұл санның көмегімен баяу көмегімен ұстайды! Барлық пермутациялардың саны, бұл жалпы түрлендіру және машинаны аудару секілді компьютерлік қолданбалардың көбірек өсімі. Қазіргі мақала осы шектеулердің математикалық және есептеулердің негізін тексереді, және оның CCG-де бірнеше шектеулердің орналасуы болмай тұрған себебін тексереді.', 'mk': 'Апстракт Стидман (2020) предлага како официјален универзален граматика на природен јазик дека граматичките пермутации на типот што предизвикаа трансформациони правила се ограничени на класа позната за математичарите и компјутерските научници како „разделливи“ пермутации. Оваа класа на пермутации е точно класата која може да се изрази во комбинаторни категоријални граматики (CCG). Изклучените неразделливи пермутации всушност се чини дека се отсутни во голем број студии за крстојазична варијација во редот на зборови во номиналните и вербалните конструкции. Бројот на пермутации кои се разделливи се зголемува во бројот n на лексикални елементи во изградбата како големиот број Шродер Sn-1. Бидејќи тој број расте многу побавно од n! број на сите пермутации, оваа генерализација е исто така од значителен практичен интерес за компјутерски апликации како што се анализирање и машински превод. Сегашната статија ги испитува математичките и компјутерските потекла на оваа рестрикција, и причината поради која е точно фатена во ЦЦГ без наметнување на понатамошни ограничувања.', 'lt': 'Abstract Steedman (2020) siūlo kaip oficialią natūralios kalbos gramatikos universal ą, kad gramatinės permutacijos, kurios sukėlė transformacijos taisykles, apsiribotų klase, kurią matematikai ir kompiuterininkai vadina "atskirtomis" permutacijomis. This class of permutations is exactly the class that can be expressed in combinatory categorial grammars (CCGs).  Atrodo, kad keliuose tarpkalbinių žodžių eilės pokyčių nominaliose ir žodinėse konstrukcijose tyrimuose nėra atskirtų neatskiriamų permutacijų. Atskirų permutacijų skaičius didėja konstrukcijos tekstinių elementų n skaičiuje kaip Didelis Schroder numeris Sn-1. Because that number grows much more slowly than the n!  visų permutacijų skaičius, ši generalizacija taip pat yra labai praktiškai suinteresuota kompiuterinėms reikmėms, pvz., analizavimui ir mašinų vertimui. Šiame straipsnyje nagrinėjama šio apribojimo matematinė ir skaičiavimo kilmė ir priežastis, dėl kurios jis tiksliai įtraukiamas į CCG, nenustatant jokių papildomų apribojimų.', 'ml': 'അബ്സ്ട്രാക്ട്രാക്റ്റ് സ്റ്റീഡ്മാന്\u200d (2020) സ്വാഭാവ ഭാഷ ഗ്രാമാറിന്റെ പ്രധാനപ്രപഞ്ചത്തില്\u200d പ്രാധാനപ്പെടുത്തിയിരിക്കുന്നു. മാറ്റങ്ങളുടെ നിയമങ്ങള്\u200d ഉയര്\u200dത ഈ ക്ലാസ്സിന്റെ അനുവാദങ്ങള്\u200d കൃഷ്ടിയാണ് കൂടുതല്\u200d ക്ലാസില്\u200d പ്രസ്താവിപ്പിക്കാന്\u200d സാധിക്കുന്നതു് (CCGs). വേര്\u200dതിരിച്ചുവെക്കാത്ത അനുവാദങ്ങള്\u200d വാക്കുകളില്\u200d ക്രോസ്ലിഗ്ലിസ്റ്റിക്ക് വ്യത്യാസങ്ങളുടെ പല പഠനങ്ങളില്\u200d അസാധാരണമില്ലെന്ന നിര്\u200dമ്മിതിയിലെ ലെക്സിക്കല്\u200d മൂലകങ്ങളുടെ എണ്ണത്തില്\u200d വേര്\u200dതിരിക്കുന്ന അനുവാദങ്ങളുടെ എണ്ണം വളര്\u200dന്നുവരുന്നു. വലിയ സ്ക്ര Because that number grows much more slowly than the n!  എല്ലാ അനുമതികളുടെയും എണ്ണം, ഈ ജനറലേഷന്\u200d പാര്\u200dസിങ്ങ് ചെയ്യുന്നതും യന്ത്ര പരിഭാഷപ്പെടുത്തുന്നതും പോലെ കണക്കൂട്ടല്\u200d പ ഈ നിയന്ത്രണത്തിന്റെ കണക്കിലുള്ള എണ്ണിക്കണക്കിലുള്ള അടിസ്ഥാനവും പരിശോധിക്കുന്നു. അതിന്റെ കാരണവും കൂടുതല്\u200d നിര്\u200dബന്ധമില്ലാ', 'ms': "Abstract Steedman (2020) mencadangkan sebagai universal formal grammar bahasa semulajadi bahasa bahasa bahasa bahasa bahasa yang permutasi grammatik jenis yang telah memberikan bangunan kepada peraturan pengubahan terhadap kelas yang diketahui oleh ahli matematika dan ilmuwan komputer sebagai permutasi 'terpisah'. Kelas permutasi ini adalah kelas yang boleh diungkapkan dalam grammar kategori kombinatori (CCG). Permutasi yang tidak boleh dipisahkan yang terpisah sebenarnya kelihatan tidak ada dalam beberapa kajian variasi saling bahasa dalam urutan perkataan dalam konstruksi nominal dan verbal. Bilangan permutasi yang boleh dipisahkan tumbuh dalam nombor n unsur leksikal dalam pembangunan sebagai nombor Schroder Besar Sn-1. Kerana nombor itu tumbuh lebih perlahan daripada n! bilangan semua permutasi, generalisasi ini juga berminat praktik yang besar untuk aplikasi komputasi seperti penghuraian dan terjemahan mesin. Artikel ini memeriksa asal matematik dan komputasi terhadap keterangan ini, dan sebab ia benar-benar ditangkap dalam CCG tanpa memaksa sebarang keterangan lebih lanjut.", 'mt': "L-Abstract Steedman (2020) jipproponi bħala universali formali tal-grammar tal-lingwa naturali li permutazzjonijiet grammatiċi tat-tip li wasslu għal regoli trasformazzjonali huma limitati għal klassi magħrufa mill-matematiċi u x-xjentisti tal-kompjuter bħala permutazzjonijiet 'separabbli'. Din il-klassi ta’ permutazzjonijiet hija eżattament il-klassi li tista’ tiġi espressa f’grammi kategorjali kombinatorji (CCGs). Il-permutazzjonijiet mhux separabbli esklużi fil-fatt jidhru assenti f’għadd ta’ studji ta’ varjazzjoni translingwistika fl-ordni tal-kliem f’kostruzzjonijiet nominali u verbali. In-numru ta’ permutazzjonijiet li huma separabbli jikber fin-numru n ta’ elementi lexiċi fil-kostruzzjoni bħala n-numru Schroder Kbar Sn-1. Minħabba li dak in-numru jikber ħafna aktar bil-mod mill-n! in-numru ta’ permutazzjonijiet kollha, din il-ġeneralizzazzjoni hija wkoll ta’ interess prattiku konsiderevoli għall-applikazzjonijiet komputattivi bħall-analizzar u t-traduzzjoni bil-magna. Dan l-artikolu jeżamina l-oriġini matematika u komputattiva ta’ din ir-restrizzjoni, u r-raġuni għaliex hija eżattament maqbuda fis-CCG mingħajr l-impożizzjoni ta’ kwalunkwe restrizzjoni ulterjuri.", 'mn': 'Абстракт Стейдман (2020) нь байгалийн хэл грамматикийн официально универсал хэлний грамматик болгон санал болгодог. Грамматикийн өөрчлөлтийн дүрэм нь математик болон компьютер эрдэмтэд "хуваагдах" пермутацийн хэлбэрээр мэддэг хичээлд хязгаарлаг Энэ пермутацийн класс нь нийлүүлэх категорийн граммаар (CCG) дээр илэрхийлж чадна. Үнэндээ хэл хэлний өөрчлөлтийн олон судалгаагаар нэр болон үгийн баримтуудын дарааллаар хэлбэрийн өөрчлөлт байхгүй мэт санагдаж байна. Том Шродер тоо Sn-1 гэх мэт бүтээгдэхүүн дээрх лексикийн элементүүдийн n тоонд хуваагдах пермутацийн тоо өссөн. Учир нь энэ тоо өссөнээс илүү удаан өсөж байна! Бүх пермутацийн тоо, энэ ерөнхийлөгчийн хувилбар нь мөн машины хувилбар болон тооцоолох хэрэгслүүдэд маш их сонирхолтой юм. Харин одоогийн баримтууд энэ хязгаарлалтын математик болон тооцоололтын эх үүсвэрийг шалгаж байна. Яагаад гэвэл үүнийг CCG-д хамгийн их хязгаарлагүйгээр барьдаг.', 'no': 'Abstrakt Steedman (2020) foreslår som ein formelt universell av naturspråk-grammar som grammatiske permutasjonar av den typen som har gitt opp til transformasjonsregulane er begrenset til ein klasse kjent til matematikare og datavitenskaplege som «separable»-permutasjonar. Denne permutasjonsklassen er nøyaktig klassen som kan uttrykkes i kombinasjonsgramma (CCG). Den ekskluderte ikkje-separerbare permutasjonane synes faktisk å vera absent i mange studiar av krysslingsvariasjonar i ordrekkefølgje i nominale og verbale konstruksjonar. Talet på permutasjonar som er separabelt aukar i talet n på leksiske element i konstruksjonen som stor Schroder nummer Sn- 1. Fordi det tallet vokser mykje langsomt enn den n! Talet på alle permutasjonar, denne generelliseringa er også av mykje praktiske interesse for datamaskiner som tolking og maskineromsetjing. Det gjeldande artikkelen undersøker matematiske og datamaskinelske opprinnelsen av denne avgrensinga, og grunnen til at det er nøyaktig henta i CCG utan å innløysa meir avgrensingar.', 'ro': 'Steedman (2020) propune ca un universal formal al gramaticii limbajului natural că permutările gramaticale de genul care au dat naștere regulilor transformaționale sunt limitate la o clasă cunoscută matematicienilor și oamenilor de știință ca permutările "separabile". Această clasă de permutări este exact clasa care poate fi exprimată în gramatici categorice combinatoare (CCG). Permutările neexprimabile excluse par, de fapt, să fie absente într-un număr de studii de variație translingvistică în ordinea cuvintelor în construcțiile nominale și verbale. Numărul de permutări care sunt separabile crește în numărul n de elemente lexicale în construcție ca număr Schroder mare Sn-1. Pentru că acest număr crește mult mai lent decât n! Numărul tuturor permutărilor, această generalizare este, de asemenea, de interes practic considerabil pentru aplicații computaționale precum parsing și traducerea automată. Prezentul articol examinează originile matematice și computaționale ale acestei restricții și motivul pentru care este capturată exact în CCG fără impunerea oricăror constrângeri suplimentare.', 'pl': 'Streszczenie Steedman (2020) proponuje jako formalny uniwersalny uniwersalny język naturalny, że permutacje gramatyczne tego rodzaju, które doprowadziły do powstania reguł transformacyjnych, ograniczają się do klasy znanej matematykom i informatykom jako "oddzielne" permutacje. Ta klasa permutacji jest dokładnie klasą, którą można wyrażać w gramatykach kategorycznych kombinacyjnych (CCG). Wykluczone nieoddzielne permutacje wydają się faktycznie nieobecne w szeregu badań nad różnicami językowymi w porządku słów w konstrukcjach nominalnych i werbalnych. Liczba permutacji, które są rozdzielalne, rośnie w liczbie n elementów leksykalnych w konstrukcji jako liczba dużych Schrodera Sn-1. Ponieważ ta liczba rośnie o wiele wolniej niż n! Uogólnienie to jest również istotne praktyczne zainteresowanie dla aplikacji obliczeniowych, takich jak parsowanie i tłumaczenie maszynowe. Niniejszy artykuł analizuje matematyczne i obliczeniowe źródła tego ograniczenia oraz przyczyny, dla których jest ono dokładnie uchwycone w CCG bez nakładania dalszych ograniczeń.', 'so': "Abstract Steedman (2020) wuxuu u soo jeedaa caalami rasmi ah oo ku qoran maamulka luqada dabiicadda ah, kaas oo dhamaanka grammatika ah oo ka soo baxay qaynuunnada beddelka waa u xadgudbaan fasalka lagu yaqaan xisaabitaanka iyo cilmiyiinta kambiyuutarka oo u qoran sharciga kala soocan. Fasalkan ogolaanshaha ah waa fasalka lagu soo bandhigi karo qaababka kala duduwan (CCGs). Sida xaqiiqada ah ogolaanshaha aan la kala soocayn waxay u muuqataa inay ka maqnaadaan waxbarasho kala duwan oo ku saabsan beddelka luqada ee hadalka si loo qoro dhismaha magaca iyo qoraalka. The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schroder Number Sn-1.  Maxaa yeelay lambarkaasu aad buu u sii koraa hoos uga sii raadi! Lambaro dhamaan ogolaanshaha, taas oo lagu soo bandhigayo waxay sidoo kale ku leedahay faa'iido faa'iido badan oo ku saabsan codsiga xisaabta, tusaale ahaan baarshaha iyo turjumista machine. Warqadda joogtada ah wuxuu baarayaa asalkii xisaabta iyo xisaabinta, sababtuna waa in CCG lagu qabsadaa iyadoon lagu qasbin qasab kale.", 'si': 'ප්\u200dරශ්න ස්ටීඩ්මන් (2020යි) ප්\u200dරශ්නයක් විදිහට සාමාන්\u200dය භාෂාව විද්\u200dයාපකයෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් විද්\u200dයාපකය නීතියෙ මේ පරිවර්තනයේ පරිවර්තනය හරියටම පරිවර්තනය සම්බන්ධයෙන් ප්\u200dරකාශය (CCGs) වලට ප්\u200dරකාශ කරන්න පුළුවන්. වෙනස් වෙන්න බැරි වෙන්න පුළුවන් වෙනස් වෙන්න පුළුවන් ඇත්තටම වෙනස් වෙන්න පුළුවන් වෙන්නේ ක්\u200dරිස්ටලික වෙනස් විදි වෙනස් කරන්න පුළුවන් වෙනස් වෙන්න පුළුවන් වෙන්න පුළුවන් වෙන්න පුළුවන් සංඛ්\u200dයාවක් නිර්මාණයේ ලොකු SchRoder නො මොකද ඒ අංකය වැඩියෙන් වැඩියෙන් වැඩියෙන්නේ! සියළු පරිවර්තනය, මේ සාමාන්\u200dය පරිවර්තනය සහ පරික්ෂණය සඳහා පරික්ෂණය සහ පරික්ෂණය සඳහා පරික්ෂණය සඳහා පරි මේ ලේඛනය පරීක්ෂා කරනවා මේ පරීක්ෂණයේ ගණාතික සහ පරීක්ෂණාත්මක ප්\u200dරදේශය, ඒ වගේම ඒක ඇත්තටම CCG වලින් අල්ලගන්නේ නැති', 'sr': 'Abstrakt Steedman (2020) predlaže kao formalna univerzalna gramatika prirodnog jezika da su gramatičke permutacije takve vrste koje su dovele do transformacionalnih pravila ograničene na klasu poznatu matematičarima i kompjuterskim naučnicima kao permutacije "odvajajuće". Ova klasa permutacija je tačno klasa koja se može izraziti u kombinacijskim kategorijskim gramima (CCG). Isključene ne-odvajajuće permutacije čine zapravo odsutne u mnogim ispitivanjima krstolingvističkih varijacija u rečnom redu u nominalnim i verbalnim konstrukcijama. Broj permutacija koji su odvojljivi raste u broju n leksičkih elementa u izgradnji kao Veliki Šroder broj Sn-1. Jer taj broj raste mnogo sporije nego n! broj svih permutacija, ova generalizacija takođe ima značajan praktični interes za računalne aplikacije poput analize i prevode strojeva. Sadašnji članak pregleda matematički i računalni porijekl ovog ograničenja, i razlog zbog kojeg se tačno uhvati u CCG bez nametanja bilo kakvih daljnjih ograničenja.', 'sv': 'Sammanfattning Steedman (2020) föreslår som en formell universell naturlig språkgrammatik att grammatiska permutationer av det slag som har gett upphov till transformationsregler begränsas till en klass känd för matematiker och datavetare som "separerbara" permutationer. Denna klass av permutationer är exakt den klass som kan uttryckas i kombinatoriska kategoriska grammater (CCG). De exkluderade icke-separerbara permutationerna tycks faktiskt saknas i ett antal studier av korsspråklig variation i ordordning i nominella och verbala konstruktioner. Antalet permutationer som är separerbara ökar i antalet lexikala element i konstruktionen som Large Schroder Number Sn-1. Eftersom det talet växer mycket långsammare än n! Denna generalisering är också av stort praktiskt intresse för beräkningsapplikationer såsom tolkning och maskinöversättning. Denna artikel undersöker det matematiska och beräkningsmässiga ursprunget till denna begränsning, och anledningen till att den exakt fångas in i CCG utan att ytterligare begränsningar införs.', 'ta': 'எஸ்பிராக்ட் ஸ்டீட்மான் (2020) இயல்பான மொழி வரைப்படத்தின் வடிவமைப்பு பொதுவான பொதுவாக பரிந்துரைக்கிறது. இது மாற்றத்திற்கு கொடுக்கப்பட்ட வகுப்புகளின் அனுமதிகள் மாற்றம்  இந்த வகுப்பு அனுமதிகள் சரியாக வகுப்பாக இருக்கும் வகுப்பாக வகுப்புகளில் (CCGs). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions.  கட்டிடத்தில் உள்ள லெக்சிகிய உறுப்புகளின் எண்ணிக்கையில் பிரிக்கப்பட்ட அனுமதிகளின் எண்ணிக்கை அதிகரிக்கிறது, பெரிய வரிசை எண் Sn-  ஏனென்றால் அந்த எண் n விட மெதுவாக வளருகிறது! அனைத்து அனுமதிகளின் எண்ணிக்கை, இந்த பொதுவாக்கம் பாசிங் மற்றும் இயந்திர மொழிபெயர்ப்பு போன்ற கணக்கீட்டு பயன்பாடுகளுக தற்போதைய கட்டுரையில் கணித மற்றும் கணக்கிட மூலங்களை பரிசோதிக்கிறது, மற்றும் காரணத்தின் மேலும் எந்த கட்டுப்பாடுகளையும் சிசிஜி இல்', 'ur': 'ابسٹرک استئڈمن (2020) ایک طبیعی زبان گراماری کے سامان کے طور پر پیشنهاد کرتا ہے کہ اس طرح کی گراماتیکی تبدیلی قوانین کی وجہ سے پہنچائی گئی ہے جو ریاضیات اور کمپیوٹر دانشمندوں کو معلوم ہوئی کلاس پر محدود ہے۔ This class of permutations is exactly the class that can be expressed in combinatory categorial grammars (CCGs). غیر تقسیم کرنے والے غیر تقسیم پھیر پھیر پھیر پھیر پھیر پھیر رہے ہیں حقیقت یہ ہے کہ بہت سی تحقیقات میں کلمز کی تغییر پھیر پھیر رہے ہیں ساختار میں لکسیکل اتمام کے n شمار میں بڑے Schroder نمبر Sn-1 کے طور پر پھیلا جاتا ہے. کیونکہ یہ شمار ان سے زیادہ آسان ہوتا ہے! تمام پھیر پھیر پھیر پھیر جانے کی تعداد، یہ عمومی پھیر پھیر پھیر جانے کے لئے بھی بہت اچھی کامپیوتر کی علاقه ہے، جیسے پارس اور ماشین ترجمہ. اس محدودیت کی ریاضیات اور کمپیوٹریشن اصل کی تحقیق کرتی ہے، اور اس کی دلیل سی جی میں دقیقا پکڑی جاتی ہے بغیر کسی اور زیادہ محدودیت کے.', 'vi': 'Bản tóm tắt Steedman (2020) đề xuất với tư cách một phổ biến ngôn ngữ tự nhiên ngữ ngữ, rằng các hoán vị theo ngữ pháp kiểu đã tạo ra các quy tắc biến đổi chỉ giới hạn với một lớp học giả và khoa học máy tính được biết như các hoán vị "riêng". This class of hoán vị is chính xác the class that can be description in combinating categoral gramars (CCG). Trong một số nghiên cứu về biến đổi ngôn ngữ, trong trật tự ngôn ngữ ngữ trong cấu trúc ngôn từ và âm bản, các loại không thể phân biệt biệt biệt được. Số lần sắp xếp được phân loại có thể tách ra tăng theo số lượng n của các nguyên tố từ vựng trong cấu trúc là số lượng lớn Schroeder Sn-1. Bởi vì số lượng đó đang lớn dần hơn N! tất cả các hoán vị, cuộc tổng hợp này cũng rất quan trọng với các ứng dụng tính toán như phân tích và dịch chuyển máy. Bài báo này kiểm tra nguồn gốc toán học và tính toán của hạn chế này, và lý do chính xác nó được ghi lại ở CCG mà không cần phải áp dụng bất kỳ ràng buộc nào khác.', 'uz': 'Abstract Steedman (2020) tabiiy tildagi grammatikal universitet sifatida davomiy qiladi. Ularning turlarining grammatikal huquqlarini o\'zgartirish qoidalariga ega bo\'lgan grammatikal huquqlar matematikasi va kompyuterning muammoni "ajratish" huquqlari deb nomli darajaga qaraydi. @ info Bitta ajratilmagan huquqlar qo\'llanmagan so\'zlarning bir nechta qismlarda qoʻllanmagan so\'zlar o\'zgarishlarining ko\'plab o\'zgarishlarida mavjud emas. Hujjatning soni Chunki bu raqam soni o\'zida o\'xshaydi! @ info: whatsthis Joriy maqola bu cheksiz matematik va kompyuterning asosini aniqlanadi, va sababda bu qo\'shilgan qanday qanday qanday qanday qanday qanday qanday qanday qanday qanday qanday qanday qanday qandaydir CCG\'da qabul qilinadi.', 'bg': 'Абстракт Стедман (2020) предлага като формален универсален универсален на естествената езикова граматика граматически пермутации от вида, който е довел до трансформационни правила, да бъдат ограничени до клас, известен на математиците и компютърните учени като "разделими" пермутации. Този клас пермутации е точно този клас, който може да бъде изразен в комбинаторни категорични граматики. Изключените неразделими пермутации всъщност изглежда липсват в редица проучвания на кръстословието вариация в реда на думите в номинални и словесни конструкции. Броят на пермутациите, които са разделими, нараства в броя на лексикалните елементи в конструкцията като Голямото Шродерово число Сн-1. Защото това число расте много по-бавно от n! Това обобщаване също е от значителен практически интерес за изчислителни приложения като анализ и машинен превод. Настоящата статия разглежда математическия и изчислителен произход на това ограничение и причината то да е точно уловено в ЦКГ без налагане на допълнителни ограничения.', 'nl': "Abstract Steedman (2020) stelt voor dat grammaticale permutaties die aanleiding hebben gegeven tot transformatieregels beperkt zijn tot een klasse die wiskundigen en informatici als de 'scheidbare' permutaties kennen. Deze klasse van permutaties is precies de klasse die kan worden uitgedrukt in combinatory categorial grammars (CCG's). De uitgesloten niet-scheidbare permutaties lijken in feite afwezig te zijn in een aantal studies naar crosslinguïstische variatie in woordvolgorde in nominale en verbale constructies. Het aantal permutaties dat scheidbaar is groeit in het aantal n lexicale elementen in de constructie als het Grote Schrodernummer Sn-1. Want dat getal groeit veel langzamer dan de n! Van alle permutaties is deze generalisatie ook van groot praktisch belang voor computertoepassingen zoals parsen en machinevertaling. Dit artikel onderzoekt de wiskundige en computationele oorsprong van deze beperking, en de reden waarom deze precies wordt vastgelegd in CCG zonder verdere beperkingen.", 'da': "Abstract Steedman (2020) foreslår som en formel universel naturlig sproggrammatik, at grammatiske permutationer af den art, der har givet anledning til transformative regler, er begrænset til en klasse kendt af matematikere og dataforskere som de 'adskillelige' permutationer. Denne klasse af permutationer er præcis den klasse, der kan udtrykkes i kombinatoriske kategoriske grammater (CCG). De udelukkede ikke-adskillelige permutationer synes faktisk at være fraværende i en række undersøgelser af tværslingvistisk variation i ordorden i nominelle og verbale konstruktioner. Antallet af permutationer, der kan adskilles, vokser i antallet n af leksikalske elementer i konstruktionen som Stort Schroder Nummer Sn-1. Fordi det tal vokser langsommere end n! Denne generalisering er også af betydelig praktisk interesse for beregningsmæssige applikationer såsom parsing og maskinoversættelse. Denne artikel undersøger den matematiske og beregningsmæssige oprindelse af denne begrænsning, og grunden til, at den er præcis fanget i CCG uden pålæggelse af yderligere begrænsninger.", 'hr': 'Abstrakt Steedman (2020) predlaže kao formalna univerzalna gramatika prirodnog jezika da su gramatičke permutacije takve vrste koje su dovele do transformacijskih pravila ograničene na klasu poznatu matematičarima i kompjuterskim naučnicima kao permutacije "odvojljive". Ova klasa permutacija je točno klasa koja se može izraziti u kombinacijskim kategorijskim gramima (CCG). Isključene ne-odvajajuće permutacije čini se da su u mnogim ispitivanjima krstolingvističkih varijacija u redosljedu riječi u nominalnim i verbalnim konstrukcijama. Broj permutacija koji su odvojljivi raste u broju n leksičkih elementa u izgradnji kao Veliki Schroder broj Sn-1. Jer taj broj raste mnogo sporije nego n! broj svih permutacija, ova generalizacija također ima značajan praktičan interes za računalne aplikacije poput analize i prevoda strojeva. U sadašnjem članku pregledava matematički i računalni porijekl ove ograničenja i razlog zbog kojeg se upravo uhvati u CCG-u bez uvođenja bilo kakvih daljnjih ograničenja.', 'ko': "요약 Steedman(2020)은 자연 언어 문법의 한 형식으로서 통용되고 전환 규칙이 생기는 문법의 교체는 수학자와 컴퓨터 과학자가 알고 있는'분리가능'교체에만 한정된다고 주장했다.이런 종류의 교체는 바로 조합 범주 문법(CCG)으로 표현할 수 있다.사실 많은 명사와 동사 구조에서 어순의 크로스 언어 변이에 대한 연구에서 분리할 수 없는 배열을 배제하지 않은 것 같다.분리 배열 가능한 수량은 구조에서 문법 요소의 수량 n이 증가함에 따라 증가한다. 즉, 대슈라우드 수 Sn-1이다.왜냐하면 이 숫자는 n보다 훨씬 느리기 때문이다!모든 배열에서 이런 보급은 해석과 기계 번역 등 계산 응용에도 상당한 실제적 의미를 가진다.본고는 이러한 제한의 수학과 계산 원천, 그리고 CCG에서 그 어떠한 제한도 가하지 않고 정확하게 포획된 원인을 탐구한다.", 'de': "Abstract Steedman (2020) schlägt als formale Universalität der natürlichen Sprachgrammatik vor, dass grammatische Permutationen der Art, die Anlass zu Transformationsregeln gegeben haben, auf eine Klasse beschränkt sind, die Mathematikern und Informatikern als die 'separable' Permutationen bekannt ist. Diese Klasse von Permutationen ist genau die Klasse, die in kombinatorischen kategorialen Grammatiken (CCGs) ausgedrückt werden kann. Die ausgeschlossenen nicht trennbaren Permutationen scheinen in einer Reihe von Studien zur sprachübergreifenden Variation der Wortreihenfolge in nominalen und verbalen Konstruktionen tatsächlich fehlen. Die Anzahl der trennbaren Permutationen wächst mit der Anzahl n lexikalischer Elemente in der Konstruktion als die Große Schroder Zahl Sn-1. Denn diese Zahl wächst viel langsamer als das n! Neben der Vielzahl aller Permutationen ist diese Verallgemeinerung auch für Rechenanwendungen wie Parsing und maschinelle Übersetzung von erheblichem praktischem Interesse. Der vorliegende Artikel untersucht die mathematischen und rechnerischen Ursprünge dieser Beschränkung und den Grund, warum sie in CCG genau erfasst wird, ohne weitere Einschränkungen aufzuerlegen.", 'sw': 'Abstract Steedman (2020) anapendekeza kama ulimwengu rasmi wa karatasi za lugha za asili ambazo ruhusa za grammati za aina hiyo zimesababisha sheria za mabadiliko kwa darasa linalofahamika na wanasayansi wa hisabati na kompyuta kama ruhusa za ‘kutenganishwa’. Hii darasa la ruhusa ni darasa ambalo linaweza kuonyeshwa kwa vipengele vya pamoja (CCGs). Hukumu zisizo tofauti zinaonekana kutokuwepo katika tafiti kadhaa za mabadiliko ya lugha kwa maneno ili kujenga majengo ya kigeni na ya kawaida. Idadi ya ruhusa zinazotengana inaongezeka katika idadi ya vipengele vya lexico katika ujenzi kama Idadi kubwa ya Msimu Sn-1. Kwa sababu namba hiyo inakua taratibu zaidi ya taratibu! idadi ya ruhusa zote, uzalishaji huu pia una maslahi ya kihalisi kwa matumizi ya kompyuta kama vile parsing na tafsiri ya mashine. Makala ya sasa inachunguza asili ya hisabati na hisabati ya vizuizi hiki, na sababu hiyo imekamatwa kwenye CCG bila kulazimishwa kwa vikwazo vinginevyo.', 'id': "Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the 'separable' permutations.  Kelas permutasi ini adalah persis kelas yang dapat diekspresikan dalam grammar kategori kombinatori (CCG). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions.  The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schroder Number Sn-1.  Because that number grows much more slowly than the n!  number of all permutations, this generalization is also of considerable practical interest for computational applications such as parsing and machine translation.  The present article examines the mathematical and computational origins of this restriction, and the reason it is exactly captured in CCG without the imposition of any further constraints.", 'tr': "Abstrakt Steedman Bu permutasiýanyň klasy kombinator grammarlarda ifade edilebilir klasdyr. Çölüjilik döredilmez permutasylar, aslynda nominal we verbal in şallar bilen kelime düzeninde birnäçe çeşitli işlemlerde ýok görünýär. Bölünebilir permutasyon sayısı in şaat etmekte büyük Schroder Sayısı Sn-1 olarak büyür. Çünkü bu sayı büyüdükten daha yavaş artıyor! Hemme permutasyýalaryň sany, bu generalizasyň hem hesaplamak we maşynyň terjimesi üçin has möhüm praktik gyzyklandyr. Häzirki makala şu çykyşyň matematika we hasaplanjaň başlangyny barýar we ol sebäbi CCG'da gaty bir syýahat bolmadyk sebäbi.", 'af': "Abstrakte Steedman (2020) voorstel as 'n formeel universele van natuurlike taal grammatiek wat grammatiese permutasies van die soort wat opgegee het tot transformasionale reëls is beperk tot 'n klas bekend aan matematiese en rekenaar wetenskappers as die 'skiedenaar' permutasies. Hierdie klas van permutasies is presies die klas wat in kombinasie kategorie gramme (CCG) uitdruk kan word. Die uitgesluitbare nie-skeidige permutasies lyk dat in werklikheid absent is in 'n aantal studie van kruislingwisiese veranderinge in woord volgorde in nominale en verbale konstruksies. Die nommer van permutasies wat skeier is groei in die nommer n van leksiese elemente in die konstruksie as die Groot Schroder Nommer Sn- 1. Omdat daardie nommer baie stadig groei as die n! nommer van alle permutasies, hierdie generalisering is ook van bepaalde praktiese belang vir rekenaar toepassings soos verwerking en masjien vertaling. Die huidige artikel ondersoek die matematiese en rekenaarske oorspronge van hierdie beperking, en die rede wat dit presies in die CCG gevang word sonder die impossie van enige verdere beperking.", 'sq': "Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the 'separable' permutations.  Kjo klasë permutacionesh është saktësisht klasa që mund të shprehet në gramatika kategorike kombinuese (CCG). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions.  The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schroder Number Sn-1.  Sepse ky numër rritet shumë më ngadalë se n! numri i të gjitha permutacioneve, kjo gjeneralizim është gjithashtu me interes të konsiderueshëm praktik për aplikimet kompjuterike të tilla si analizimi dhe përkthimi i makinave. Artikli i tanishëm shqyrton origjinat matematike dhe llogaritare të këtij kufizimi dhe arsyeja pse është kapur saktësisht në CCG pa vënë kufizime të mëtejshme.", 'fa': 'استیدمن (۲۰۰۲) به عنوان یک نقطه\u200cای عمومی از زبان طبیعی پیشنهاد می\u200cکند که تغییرات گراماتیکی از نوع قوانین تغییر تغییر دهنده به کلاس دانشمندان ریاضیان و دانشمندان کامپیوتر به عنوان تغییرات جدا می\u200cشود. این کلاس تغییرات دقیقاً کلاس است که می\u200cتواند در گرم\u200cهای مجموعه\u200cی گرم\u200cهای مجموعه (CCG) بیان شود. تغییرات غیر جدا کننده در حقیقت به نظر می رسد که در تعداد مطالعه های تغییرات کلمه\u200cهای متفاوتی در دستور کلمه\u200cها در ساختار نومیل و زبان غیر جدا می\u200cشوند. تعداد تغییرات که قابل جدا شدن در تعداد n از عناصر زبانی در ساختمان به عنوان شماره\u200cی Schroder بزرگ Sn-1 رشد می\u200cکند. چون اون شماره آروم تر از "ن" رشد ميکنه! تعداد تمام تغییرات، این تغییرات عمومی برای کاربردهای کامپیوتری مثل پردازی و ترجمه ماشین هم بسیار عملی است. مقاله\u200cای در حال حاضر، اصول ریاضی و محاسباتی این محدودیت را تحقیق می\u200cکند، و دلیل آن دقیقا در CCG بدون تنظیم هیچ محدودیت بیشتری گرفته می\u200cشود.', 'hy': "Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the 'separable' permutations.  Այս փոփոխությունների դասարանը ճիշտ այն դասարանն է, որը կարող է արտահայտվել համադրական կատեգորիալ գրամագրերով: Բացառուցված ոչ բաժանվող պարզմունքները փաստորեն թվում են բացակայում բառային կարգով բառային և լեզվաբանական կառուցվածքների խաչլեզվաբանական տարբերությունների մի շարք ուսումնասիրություններում: Կառուցքի մեջ բաժանվող փոփոխությունների թիվը աճում է կառուցվածքի լեքսիկական տարրերի n թվի մեջ, որպես Մեծ Շրոդերի թվի Սն-1: Քանի որ այդ թիվը աճում է շատ ավելի դանդաղ, քան n-ը: այս ընդհանուր տարածումը նաև շատ գործնական հետաքրքրություն ունի համակարգչային ծրագրերի համար, ինչպիսիք են վերլուծությունը և մեքենային թարգմանումը: Այս հոդվածը ուսումնասիրում է այս սահմանափակումների մաթեմատիկական և հաշվարկների ծագումը, և պատճառը, թե ինչու է այն ճիշտ բռնվում ՀԿԳ-ում առանց որևէ այլ սահմանափակումների պարտադրման:", 'az': 'Abstrakt Steedman (2020) t…ôbi…ôtli dil gramatika olaraq t…ôklif edir ki, transformasiya kurallarńĪna s…ôb…ôb olan gramatik permutasiya, matematik√ßil…ôr v…ô kompjuter bilim adamlarńĪna "ayrńĪlabilir" permutasiya olaraq tanńĪnan bir sńĪnńĪfta sńĪnńĪrlandńĪrńĪlńĪr. Bu permutasyon sńĪnńĪfńĪ tam olarak kombinator kategoriyal grammalarda ifad…ô edil…ô bil…ôc…ôk sńĪnńĪfdńĪr. ∆Źslind…ô f…ôrqli olmayan permutasiyalar, nominal v…ô verbal in ŇüallarńĪ il…ô s√∂zl…ôrin sńĪralarńĪnda √ßox d…ôyiŇüiklik d…ôyiŇüiklikl…ôr arasńĪnda yox g√∂r√ľn√ľr. B√∂l√ľnebilir permutasyon sayńĪ, in ŇüaatńĪn n sayńĪsńĪnda B√ľy√ľk Schroder NumarasńĪ Sn-1 olaraq b√∂y√ľkl…ônir. √á√ľnki bu sayńĪ n-d…ôn daha yavaŇü artńĪr! B√ľt√ľn permutasyon sayńĪsńĪ, bu generalizasiya da hesablama v…ô maŇüńĪna √ßevirilm…ôsi kimi bilgisayar uygulamalarńĪ √ľ√ß√ľn √ßox praktik interesdir. Ňěimdiki m…ôktub bu sńĪnńĪrńĪn matematiksel v…ô hesaplamalńĪq m…ônb…ôl…ôrini incidir, v…ô bunun CCG i√ßind…ô h…ôqiq…ôt…ôn d…ô artńĪq m√ľ…ôyy…ôn edilm…ôd…ôn tutulmasńĪnńĪn s…ôb…ôbi.', 'am': 'እስቴድማን (2020) የፍጥረተ ቋንቋ ቋንቋዎች መሠረት ዓለማዊ ብሔርቨርስቲ እንደሚያሳየው፣ የሥርዓት ትምህርት ፍቃድ ለሥልጣናዊዎች እና ኮምፒዩተር አዋቂዎች ‘የተለየ’ ፈቃድ እንደሚታወቁ ቋንቋ ተቃውሞ ነው፡፡ የዚህ ክፍል ፈቃድ በክፍለ አካባቢ ቋንቋ (CCGs) በተለየው ክፍል ነው፡፡ በተለየው ያልተለያዩ ፈቃድ በቋንቋ ቋንቋዊ ክፍተቶችን በንግግር በጥያቄ እና በቋንቋ ግንኙነት ውስጥ የቆየ ይመስላል፡፡ የተለየ ልዩ ፈቃድ ቁጥር እየደረሰ ግንኙነት አካላዊ አካላት ቁጥር ያድጋል፡፡ ምክንያቱም ይህ ቁጥር ከጥንት ይልቅ በዝግታ ያድጋል! የሁሉም ፈቃድ ቁጥር፣ ይህም ማሳሰል እንደማዘጋጀት እና ማሻሻል ትርጓሜ በሚመስል ለመቆጣጠር ፕሮግራሞች የሚያስፈልጋል ተግባር ነው፡፡ የአሁኑ ጽሑፍ የዚህን ግንኙነት የመቆጣጠር እና የቁጥጥር መጀመሪያ ይፈልጋል፣ ከዚህም በላይ ግንኙነት ባይኖር በCCG የተያዙት ምክንያት ነው፡፡', 'bn': 'আবস্ট্র্যাক্ট স্টিডম্যান (২০২০) প্রস্তাব করেছেন প্রাকৃতিক ভাষা গ্রামারের একটি আনুষ্ঠানিক বিশ্ববিদ্যালয় হিসেবে যে গ্রাম্যাটিক্যাল নিয়ম বৃদ্ধি করেছে যা গণত এই ক্লাসের অনুমতি সঠিকভাবে ক্লাস যা মিনিটেরিয়াল গ্রামারে প্রকাশ করা যাবে (সিসিজি)। বিচ্ছিন্ন বিচ্ছিন্ন অনুমতি আসলে মনে হচ্ছে শব্দের নামিক এবং ভার্বাল নির্মাণের ক্ষেত্রে বেশ কয়েকটি গবেষণায় অনুপস্থিত। বিশাল স্ক্রোডার নাম্বার স্ন- ১ হিসেবে নির্মাণের লেক্সিক্যাল উপাদানের সংখ্যার সংখ্যা বৃদ্ধি করে। কারণ সেই নাম্বার ধীরে ধীরে বেড়ে যায়! number of all permutations, this generalization is also of considerable practical interest for computational applications such as parsing and machine translation.  বর্তমান প্রবন্ধটি এই নিষেধাজ্ঞার গণতান্ত্রিক এবং গণতান্ত্রিক উদ্দেশ্য পরীক্ষা করেছে এবং কারণ সিসিজিতে কোনো বাধ্যতা ছাড়াই সেটা', 'bs': 'Abstrakt Steedman (2020) predlaže kao formalnu univerzalnu gramatiku prirodnog jezika da su gramatičke permutacije takve vrste koje su dovele do transformacijskih pravila ograničene na klasu poznatu matematičarima i kompjuterskim naučnicima kao permutacije "odvojljive". Ova klasa permutacija je tačno klasa koja se može izraziti u kombinacijskim kategorijskim gramama (CCG). Isključene ne-odvajajuće permutacije čine zapravo odsutne u broju ispitivanja krstolingvističkih varijacija u redosljedu riječi u nominalnim i verbalnim konstrukcijama. Broj permutacija koji su odvojljivi raste u broju n leksičkih elementa u izgradnji kao Veliki Schroder broj Sn-1. Jer taj broj raste mnogo sporije nego n! broj svih permutacija, ova generalizacija također ima značajan praktični interes za računalne aplikacije poput analize i prevode strojeva. Sadašnji članak pregleda matematički i računalni porijekl ovog ograničenja, i razlog zbog kojeg se upravo uhvata u CCG bez nametanja bilo kakvih daljnjih ograničenja.', 'et': 'Steedman (2020) pakub looduskeele grammatika formaalse universaalina välja, et transformatsioonireeglite tekitanud grammatilised permutatsioonid piirduvad klassiga, mida matemaatikud ja arvutiteadlased tunnevad kui "eraldatavaid" permutatsioone. See permutatsioonide klass on täpselt klass, mida saab väljendada kombinatoorsetes kategooriagrammatikates (CCG). Väljajäetud lahutamatud permutatsioonid tunduvad tegelikult puuduvat mitmetes uuringutes sõnade järjekorra ristkeelelise variatsiooni kohta nominaalsetes ja verbaalsetes konstruktsioonides. Lahutatavate permutatsioonide arv kasvab leksikaalsete elementide arvus n konstruktsioonis kui suur Schroderi number Sn-1. Sest see arv kasvab palju aeglasemalt kui n! Kõigi permutatsioonide arv, see üldistamine on ka märkimisväärne praktiline huvi arvutuslike rakenduste jaoks nagu parsimine ja masintõlge. Käesolevas artiklis uuritakse selle piirangu matemaatilist ja arvutuslikku päritolu ning põhjust, miks see täpselt CCG-s jäädvustatakse ilma täiendavate piirangute kehtestamata.', 'cs': 'Abstrakt Steedman (2020) navrhuje jako formální univerzál gramatiky přirozeného jazyka, že gramatické permutace, které vedly k transformačním pravidlům, jsou omezeny na třídu známou matematikům a informatikům jako "oddělitelné" permutace. Tato třída permutací je přesně třída, kterou lze vyjádřit v kombinačních kategoriálních gramatikách (CCG). Vyloučené nerozdělitelné permutace se ve skutečnosti zdají být chybějící v řadě studií křížových variací pořadí slov v nominálních a verbálních konstrukcích. Počet permutací, které jsou oddělitelné, roste v počtu n lexikálních prvků konstrukce jako Velké Schroderovy číslo Sn-1. Protože to číslo roste mnohem pomaleji než n! Tato zobecnění má velký praktický zájem i pro výpočetní aplikace, jako je parsování a strojový překlad. Tento článek zkoumá matematický a výpočetní původ tohoto omezení a důvod, proč je přesně zachycen v CCG bez uložení dalších omezení.', 'fi': 'Steedman (2020) ehdottaa luonnollisen kielen kieliopin muodolliseksi universaaliksi, että muunnossääntöihin johtaneet kieliopilliset permutaatiot rajoittuvat matemaatikkojen ja tietojenkäsittelytieteilijöiden tuntemaan luokkaan "erotettavina" permutaatioina. Tämä permutaatioiden luokka on juuri se luokka, joka voidaan ilmaista kombinatorisilla kategorisilla grammoilla (CCG). Poistetut erottamattomat permutaatiot näyttävät itse asiassa puuttuvan useista tutkimuksista, jotka koskevat sanajärjestyksen monikielistä vaihtelua nimellisissä ja verbaalisissa rakenteissa. Erotettavien permutaatioiden määrä kasvaa konstruktion leksikaalisten elementtien n lukumäärässä Suurena Schroder-lukuna Sn-1. Koska tuo luku kasvaa paljon hitaammin kuin n! Tällä yleistyksellä on myös huomattava käytännön merkitys laskennallisiin sovelluksiin, kuten parsaukseen ja konekäännökseen. Tässä artikkelissa tarkastellaan tämän rajoituksen matemaattista ja laskennallista alkuperää ja sitä, miksi se on tarkasti taltioitu CCG:ssä ilman lisärajoituksia.', 'ca': "Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the 'separable' permutations.  This class of permutations is exactly the class that can be expressed in combinatory categorial grammars (CCGs).  The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions.  The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schroder Number Sn-1.  Because that number grows much more slowly than the n!  el nombre de permutacions, aquesta generalització també té un interès pràctic considerable per aplicacions computacionals com l'analització i la traducció automàtica. The present article examines the mathematical and computational origins of this restriction, and the reason it is exactly captured in CCG without the imposition of any further constraints.", 'sk': 'Steedman (2020) kot formalni univerzal slovnice naravnega jezika predlaga, da so slovnične permutacije vrste, ki so povzročile transformacijska pravila, omejene na razred, ki ga matematiki in računalniški znanstveniki poznajo kot "ločljive" permutacije. Ta razred permutacij je točno razred, ki ga je mogoče izraziti v kombinacijskih kategorijskih slovnicah (CCG). Izključene neločljive permutacije dejansko niso odsotne v številnih študijah medjezikovne variacije besednega reda v nominalnih in verbalnih konstrukcijah. Število permutacij, ki jih je mogoče ločiti, raste v številu n leksikalnih elementov v konstrukciji kot Velika Schroderjeva številka Sn-1. Ker to število raste veliko počasi kot n! Ta generalizacija je praktično pomembna tudi za računalniške aplikacije, kot sta parsiranje in strojno prevajanje. V prispevku se obravnavajo matematični in računalniški izvor te omejitve ter razlog, zakaj je ta omejitev natančno zajeta v CCG brez uvedbe nadaljnjih omejitev.', 'ha': "@ info: whatsthis Wannan nau'in da za'a ƙayyade nau'in da za'a iya nuna cikin grammar nau'i biyu mai haɗuwa (CCGs). An cire da izinin waɗand a ba su rarraba shi ba, don a bayyana a cikin wasu karatun masu maye wa variant na tsuslinguistic cikin kalma don a sami'a da sunan da rubutu. Kijan rasa da za'a raba su girma cikin yawan ƙanshi na leksisi cikin mazaƙin da ke Large Schruner-1. Saboda wannan namba yana ƙara kasi sauri ko da taran! @ info: tooltip Ga da yanzu, yana jarraba asiyyan matabiki da lissafi na wannan cewa, kuma saban an kãma shi a CCG ko kuma ba da lazimta wani kanuni daban ba.", 'he': "Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the 'separable' permutations.  הכיתה הזו של הפרסומות היא בדיוק הכיתה שאפשר להביע באגרמטיקות הקטגוריות הקבוצותיות (CCG). הפרסומות הלא-נפרדות הנמלאות למעשה נראות נעדרות במספר מחקרים של שווירציה משולשת במסדר מילים בבניינים נומימליים ומיליים. מספר הפרסומות שנפרדות גדל במספר n של אלמנטים לקסיים בבניין כמספר שרודר גדול Sn-1. כי המספר הזה גדל הרבה יותר לאט מאשר n! מספר כל הפרסומות, הגנרליזציה הזאת היא גם מעניינת מעשית משמעותית עבור שימושים מחשביים כמו מעבדה ותרגום מכונות. המאמר הנוכחי בודק את מקורי המתמטיקה והמחשב של ההגבלה הזו, והסיבה שהוא נלכד בדיוק ב CCG ללא ההכרעה של כל מחסומים נוספים.", 'jv': 'absolute steedman Genjer-Genjer iki perMutasyon kuwi dakasakno kanggo kelas sing bisa digasar neng sampeyan kategori Gambar. Awak dhéwé Text Soalé, nomer iki lak tangané luwih apik dhéwé! error message Artik sing nggunakake dipunangé perusahaan mat karo akeh komputasi kanggo nggawe nguasai iki, lan saiki ono dipunangé katon-katon ngguna CG lan ora iso nguasai perusahaan liyane', 'bo': 'ལམ་ལུགས་ཤིང་(2020)དེ་ནི་འཛམ་གླིང་གི་སྤྱིར་བཏང་བའི་སྐད་ཡིག་གི་ཚོགས་རྣམས་ལ། འགྱུར་བརྗོད་ཀྱི་གྲྭར་འདི་གསལ་ནས་བསྡུས་པའི་གྲལ་རིམ་གཟུགས་རིས་ཀྱིས་གསལ་བཤད་ཐུབ་པའི་གྲྭར་ཞིག་ཡིན། ཕན་ཚུན་མེད་པའི་བསྒྱུར་བཅོས་སྣང་མེད་པའི་ཚིག་དག་གནས་ཚུལ་ཁག་ཅིག དབྱེ་རིགས་ཅན་གྱི་རྣམ་གྲངས་ཀྱི་གྲངས་ཚད་གཟུགས་རིས་ཀྱི་རྣམ་གྲངས་ཀ་ནང་དུ་འགྱུར་སྲིད་པའི་བསྒྱུར་བཅོས་ཀྱི་གྲངས་ཁ་ཚད་ཆེ་བའི་Schroder གང་ལེགས་ཞེ་ན། ཨང་གྲངས་འདི་ནར་མོ་ཆེ་བ་ལས་ནག་ཏུ་འགྱོ་བཞིན། གྲངས འདི་ལྟ་བུའི་ཡིག་གཟུགས་འདིས་དེ་གྲངས་རིག་དང་རྩིས་འཁོར་གྱི་འགྱུར་རྐྱེན་དེ་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད། རྒྱུ་མཚན་ནི་འདི་ཚོར་CCG ནང་དུ་གཏ'}
{'en': 'Semantic Data Set Construction from Human Clustering and Spatial Arrangement', 'ar': 'بناء مجموعة البيانات الدلالية من التجمعات البشرية والترتيب المكاني', 'fr': "Construction d'ensembles de données sémantiques à partir d'un regroupement humain et d'un arrangement spatial", 'pt': 'Construção de conjunto de dados semânticos a partir de agrupamento humano e arranjo espacial', 'es': 'Construcción de conjuntos de datos semánticos a partir de agrupamiento humano y disposición espacial', 'hi': 'मानव क्लस्टरिंग और स्थानिक व्यवस्था से सिमेंटिक डेटा सेट निर्माण', 'ja': '人間のクラスタリングと空間配置からのセマンティックデータセット構築', 'zh': '盖聚类空间之语义数集也', 'ru': 'Построение набора семантических данных на основе кластеризации людей и пространственного расположения', 'ga': 'Tógáil Tacar Sonraí Séimeantach ó Chnuasú Daonna agus Socrú Spásúlachta', 'ka': 'სემანტიკური მონაცემების კონფიგურაცია ადამიანის კლასტერინდან და სოციალური განსაზღვრებადან', 'hu': 'Szemantikus adatkészlet építése emberi klaszterekből és térbeli elrendezésből', 'el': 'Κατασκευή συνόλου σημασιολογικών δεδομένων από ανθρώπινη ομαδοποίηση και χωρική διευθέτηση', 'it': 'Costruzione di set di dati semantici da cluster umani e disposizione spaziale', 'lt': 'Semantinių duomenų rinkinio konstrukcija iš žmogaus grupavimo ir erdvinio susitarimo', 'kk': 'Адам кластері мен бос орындарынан Semantic Data Set құрылымы', 'mk': 'Конструкција на семантичкиот набор податоци од човечкиот кластерирање и просторно организирање', 'ms': 'Pembangunan Set Data Semantik dari Pemkumpulan Manusia dan Peraturan Ruang', 'ml': 'മനുഷ്യന്\u200d ക്ലൌസ്റ്റിങ്ങില്\u200d നിന്നും സ്പാസ്റ്റിയേല്\u200d ആഘോഷത്തില്\u200d നിന്നും സെമാന്റിക് ഡേറ്റ', 'mt': 'Il-Kostruzzjoni tas-Sett Semantiku ta’ Dejta minn Raggruppament tal-Bniedem u Arranġament Spazjali', 'mn': 'Хүмүүсийн кластеринг болон огторгуйн зохион байгуулалтын Semantic Data Set Construction from Human Clustering and Spatial Arrangement', 'no': 'Semantisk datasett- konstruksjon frå menneskelige klassering og mellomromsett', 'pl': 'Konstrukcja zestawu danych semantycznych z klastrowania ludzkiego i aranżacji przestrzennej', 'ro': 'Construcția seturilor de date semantice din gruparea umană și amenajarea spațială', 'sr': 'Semantička konstrukcija podataka iz ljudskog klusteringa i svemirskog dogovora', 'si': 'මිනිස්සු ක්\u200dලාස්ටරින් සහ ස්පේසියාල් සැකසුම් නිර්මාණය', 'so': 'Semantic Data Set Construction from Human Clusting and Spatial Arrangement', 'sv': 'Semantic Data Set Construction from Human Clustering and Spatial Arrangement', 'ta': 'Name', 'ur': 'انسان کلسٹرینگ اور فضائی ترکیب سے سیمنٹی ڈاٹ سٹ بنانے', 'uz': 'Name', 'vi': 'Bộ xây dựng bộ khung dữ liệu truyền kỳ', 'bg': 'Изграждане на семантичен набор от данни от човешки клъстери и пространствено подреждане', 'da': 'Semantic Data Set Construction from Human Clustering and Spatial Arrangement', 'nl': 'Semantische dataset constructie vanuit menselijke clustering en ruimtelijke ordening', 'hr': 'Semantička konstrukcija podataka iz ljudskih klusteringa i prostornog dogovora', 'de': 'Semantische Datensatzkonstruktion aus menschlicher Clusterung und räumlicher Anordnung', 'ko': '인류 집합과 공간 배열을 바탕으로 하는 의미 데이터 집합 구축', 'fa': 'ساختن مجموعه داده\u200cهای سیم\u200cمانتیک از گروه\u200cهای انسان و ترکیب فضایی', 'id': 'Pembangunan Set Data Semantik dari Pengkumpulan Manusia dan Peraturan Ruang', 'sw': 'Mjengo wa Taarifa za Semantic Data kutoka kwenye Maandamano ya Binadamu na Hispania', 'tr': 'Adam Clustering we Spasiýal Teşkilatı', 'sq': 'Ndërtimi i Set Semantik të të dhënave nga grupimi njerëzor dhe rregullimi hapësiror', 'af': 'Name', 'hy': 'Comment', 'bn': 'মানব ক্লাস্টিং এবং স্প্যান্টিয়াল অ্যারেঞ্জেন্ট থেকে সেম্যান্টিক ডাটা নির্মাণ', 'az': "İnsan Clustering və Space Arrangement'dan Semantik Data Set inşaat", 'am': 'የስሜናክኛ ዳታ መሠረት ከሰው Clusting እና Spatial Arrangement', 'bs': 'Semantička konstrukcija podataka iz ljudskog klusteringa i prostornog dogovora', 'cs': 'Konstrukce sémantických datových souborů z lidského shlukování a prostorového uspořádání', 'ca': "Construcció de conjunt de dades Semàtics a partir de la agrupació humana i l'organització espacial", 'et': 'Semantilise andmekogumi ehitus inimklastritest ja ruumilisest paigutusest', 'fi': 'Semanttisen tietojoukon rakentaminen ihmisen klusteroinnista ja paikkakunnasta', 'jv': 'Samanti data Set', 'he': 'קבוצת נתונים סמנטית בנייה ממערכת האנושיות ומסדר חללית', 'sk': 'Konstrukcija semantičnega nabora podatkov iz človeškega grozdja in prostorske ureditve', 'ha': 'KCharselect unicode block name', 'bo': 'Semantic Data Set Construction from Human Clustering and Spatial Arrangement'}
{'en': 'Abstract Research into representation learning models of lexical semantics usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments. Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that can not then be used to generate a larger lexical resource. Furthermore, similarity between more than two items is not considered. We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase. The methodology uses a spatial multi-arrangement approach proposed in the field of cognitive neuroscience for capturing multi-way similarity judgments of visual stimuli. We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work. We specifically target verbs, but the method can equally be applied to other parts of speech. We perform cluster analysis on the data from the first phase and demonstrate how this might be useful in the construction of a comprehensive verb resource. We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity. We demonstrate how the resultant data set can be used for fine-grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and semantic similarity. In particular, we find that stronger static word embedding methods still outperform lexical representations emerging from more recent pre-training methods, both on word-level similarity and clustering. Moreover, thanks to the data set’s vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as Heat or Motion.', 'ar': 'يستخدم البحث المجرد في نماذج التعلم التمثيلية للدلالات المعجمية عادةً شكلاً من أشكال التقييم الجوهري للتأكد من أن التمثيلات المكتسبة تعكس الأحكام الدلالية البشرية. تقدير التشابه الدلالي المعجمي هو طريقة تقييم مستخدمة على نطاق واسع ، لكن الجهود تركزت عادةً على الأحكام الزوجية للكلمات في عزلة ، أو تقتصر على سياقات محددة ومحفزات معجمية. هناك قيود مع هذه الأساليب التي إما لا توفر أي سياق للأحكام ، وبالتالي تتجاهل الغموض ، أو توفر سياقات محددة للغاية لا يمكن استخدامها بعد ذلك لتوليد مورد معجمي أكبر. علاوة على ذلك ، لا يؤخذ في الاعتبار التشابه بين أكثر من عنصرين. نحن نقدم وصفًا وتحليلاً كاملين لمنهجيتنا المقترحة مؤخرًا لبناء مجموعة بيانات واسعة النطاق والتي تنتج تصنيفًا دلاليًا لعينة كبيرة من الأفعال في المرحلة الأولى ، بالإضافة إلى أحكام تشابه متعددة الطرق تم إجراؤها ضمن الفئات الدلالية الناتجة في المرحلة الثانية. تستخدم المنهجية نهجًا متعدد الترتيب المكاني المقترح في مجال علم الأعصاب الإدراكي لالتقاط أحكام تشابه متعددة الاتجاهات للمحفزات البصرية. لقد قمنا بتكييف هذه الطريقة للتعامل مع المحفزات اللغوية متعددة المعاني وعينات أكبر بكثير من الأعمال السابقة. نحن نستهدف الأفعال على وجه التحديد ، ولكن يمكن تطبيق الطريقة بالتساوي على أجزاء أخرى من الكلام. نقوم بإجراء تحليل عنقودي على البيانات من المرحلة الأولى ونوضح كيف يتم ذلك\nقد يكون مفيدًا في بناء مورد فعل شامل. نقوم أيضًا بتحليل المعلومات الدلالية التي تم التقاطها بواسطة المرحلة الثانية ونناقش إمكانات أحكام التشابه المستحثة مكانيًا لتعكس بشكل أفضل المفاهيم البشرية عن تشابه الكلمات. نوضح كيف يمكن استخدام مجموعة البيانات الناتجة للتحليلات الدقيقة وتقييم نماذج التعلم التمثيلي في المهام الجوهرية للتجميع الدلالي والتشابه الدلالي. على وجه الخصوص ، وجدنا أن أساليب تضمين الكلمة الثابتة الأقوى لا تزال تتفوق على التمثيلات المعجمية الناشئة عن طرق التدريب السابقة الأكثر حداثة ، سواء على مستوى التشابه على مستوى الكلمات أو التجميع. علاوة على ذلك ، بفضل التغطية الواسعة لمجموعة البيانات ، نحن قادرون على مقارنة فوائد التمثيلات الموجهة المتخصصة لنوع معين من المعرفة الخارجية من خلال تقييم نماذج FrameNet و VerbNet المعدلة في مجالات دلالية محددة مثل "الحرارة" أو "الحركة". "', 'fr': "Résumé La recherche sur les modèles d'apprentissage des représentations de la sémantique lexicale utilise généralement une forme d'évaluation intrinsèque pour s'assurer que les représentations apprises reflètent des jugements sémantiques humains. L'estimation de similarité sémantique lexicale est une méthode d'évaluation largement utilisée, mais les efforts se sont généralement concentrés sur des jugements par paires de mots isolés, ou se limitent à des contextes spécifiques et à des stimuli lexicaux. Ces approches présentent des limites qui ne fournissent aucun contexte pour les jugements, ignorant ainsi l'ambiguïté, ou fournissent des contextes sententiels très spécifiques qui ne peuvent ensuite pas être utilisés pour générer une ressource lexicale plus importante. De plus, la similitude entre plus de deux éléments n'est pas prise en compte. Nous fournissons une description complète et une analyse de notre méthodologie récemment proposée pour la construction d'ensembles de données à grande échelle qui produit une classification sémantique d'un large échantillon de verbes dans la première phase, ainsi que des jugements de similarité multidirectionnelle effectués dans les classes sémantiques résultantes dans la seconde phase. La méthodologie utilise une approche spatiale multi-arrangements proposée dans le domaine des neurosciences cognitives pour saisir des jugements de similitude multidirectionnels de stimuli visuels. Nous avons adapté cette méthode pour gérer des stimuli linguistiques polysémiques et des échantillons beaucoup plus importants que les travaux précédents. Nous ciblons spécifiquement les verbes, mais la méthode peut également être appliquée à d'autres parties du discours. Nous effectuons une analyse de cluster sur les données de la première phase et montrons comment cela\npeut être utile dans la construction d'une ressource complète sur les verbes. Nous analysons également les informations sémantiques capturées par la deuxième phase et discutons du potentiel des jugements de similitude induits spatialement pour mieux refléter les notions humaines de similitude des mots. Nous montrons comment l'ensemble de données résultant peut être utilisé pour des analyses précises et l'évaluation de modèles d'apprentissage de représentation sur les tâches intrinsèques de regroupement sémantique et de similarité sémantique. En particulier, nous constatons que les méthodes d'intégration de mots statiques plus fortes continuent de surpasser les représentations lexicales issues des méthodes de pré-apprentissage plus récentes, à la fois en termes de similitude au niveau des mots et de regroupement. De plus, grâce à la vaste couverture de l'ensemble de données, nous sommes en mesure de comparer les avantages de la spécialisation des représentations vectorielles pour un type particulier de connaissances externes en évaluant des modèles adaptés à FrameNet et VerbNet sur des domaines sémantiques spécifiques tels que «\xa0Heat\xa0» ou «\xa0Motion\xa0».", 'pt': 'Resumo A pesquisa em modelos de aprendizagem de representação de semântica lexical geralmente utiliza alguma forma de avaliação intrínseca para garantir que as representações aprendidas reflitam julgamentos semânticos humanos. A estimativa de similaridade semântica lexical é um método de avaliação amplamente utilizado, mas os esforços geralmente se concentram em julgamentos de palavras em pares de forma isolada ou são limitados a contextos e estímulos lexicais específicos. Existem limitações com essas abordagens que não fornecem nenhum contexto para julgamentos e, portanto, ignoram a ambiguidade, ou fornecem contextos sentenciais muito específicos que não podem ser usados para gerar um recurso lexical maior. Além disso, a semelhança entre mais de dois itens não é considerada. Fornecemos uma descrição e análise completas de nossa metodologia recentemente proposta para construção de conjuntos de dados em larga escala que produz uma classificação semântica de uma grande amostra de verbos na primeira fase, bem como julgamentos de similaridade multifacetados feitos dentro das classes semânticas resultantes em a segunda fase. A metodologia utiliza uma abordagem de multi-arranjo espacial proposta no campo da neurociência cognitiva para capturar julgamentos de similaridade de múltiplas vias de estímulos visuais. Adaptamos esse método para lidar com estímulos linguísticos polissêmicos e amostras muito maiores do que trabalhos anteriores. Nós direcionamos especificamente os verbos, mas o método também pode ser aplicado a outras partes do discurso. Realizamos análise de cluster nos dados da primeira fase e demonstramos como isso\npode ser útil na construção de um recurso verbal abrangente. Também analisamos as informações semânticas capturadas pela segunda fase e discutimos o potencial dos julgamentos de similaridade induzidos espacialmente para melhor refletir as noções humanas de similaridade de palavras. Demonstramos como o conjunto de dados resultante pode ser usado para análises refinadas e avaliação de modelos de aprendizagem de representação nas tarefas intrínsecas de agrupamento semântico e similaridade semântica. Em particular, descobrimos que métodos de incorporação de palavras estáticas mais fortes ainda superam as representações lexicais emergentes de métodos de pré-treinamento mais recentes, tanto na similaridade no nível da palavra quanto no agrupamento. Além disso, graças à vasta cobertura do conjunto de dados, podemos comparar os benefícios de se especializar em representações vetoriais para um tipo específico de conhecimento externo, avaliando modelos adaptados de FrameNet e VerbNet em domínios semânticos específicos, como “Heat” ou “Motion. ”', 'es': 'Resumen La investigación sobre los modelos de aprendizaje de representación de la semántica léxica generalmente utiliza alguna forma de evaluación intrínseca para garantizar que las representaciones aprendidas reflejen los juicios semánticos humanos. La estimación de similitud semántica léxica es un método de evaluación ampliamente utilizado, pero los esfuerzos se han centrado típicamente en juicios por pares de palabras aisladas, o se limitan a contextos específicos y estímulos léxicos. Existen limitaciones con estos enfoques que no proporcionan ningún contexto para los juicios y, por lo tanto, ignoran la ambigüedad, o proporcionan contextos de oración muy específicos que no pueden usarse para generar un recurso léxico más amplio. Además, no se tiene en cuenta la similitud entre más de dos elementos. Proporcionamos una descripción completa y un análisis de nuestra metodología recientemente propuesta para la construcción de conjuntos de datos a gran escala que produce una clasificación semántica de una gran muestra de verbos en la primera fase, así como juicios de similitud multidireccional realizados dentro de las clases semánticas resultantes en la segunda fase. La metodología utiliza un enfoque de múltiples arreglos espaciales propuesto en el campo de la neurociencia cognitiva para capturar juicios de similitud multidireccional de los estímulos visuales. Hemos adaptado este método para manejar estímulos lingüísticos polisémicos y muestras mucho más grandes que en trabajos anteriores. Nos enfocamos específicamente en los verbos, pero el método se puede aplicar igualmente a otras partes del discurso. Realizamos análisis de conglomerados en los datos de la primera fase y demostramos cómo esto\npodría ser útil en la construcción de un recurso verbo completo. También analizamos la información semántica capturada por la segunda fase y discutimos el potencial de los juicios de similitud inducidos espacialmente para reflejar mejor las nociones humanas de similitud de palabras. Demostramos cómo el conjunto de datos resultante se puede utilizar para análisis detallados y la evaluación de modelos de aprendizaje de representación en las tareas intrínsecas de la agrupación semántica y la similitud semántica. En particular, encontramos que los métodos de incrustación de palabras estáticas más fuertes aún superan a las representaciones léxicas que surgen de los métodos de preentrenamiento más recientes, tanto en la similitud a nivel de palabras como en la agrupación. Además, gracias a la amplia cobertura del conjunto de datos, podemos comparar los beneficios de las representaciones vectoriales especializadas para un tipo particular de conocimiento externo mediante la evaluación de modelos actualizados de FrameNet y VerbNet en dominios semánticos específicos como «Calor» o «Movimiento».', 'ja': '抽象的語彙意味論の表現学習モデルに関する研究は、通常、学習された表現が人間の意味論的判断を反映することを保証するために、何らかの形の本質的評価を利用する。 語義的意味論的類似性の推定は、広く使用されている評価方法であるが、通常、孤立した単語の対の判断に焦点を当ててきたか、特定の文脈や語彙的刺激に限定されてきた。 これらのアプローチには、判断のためのいかなる文脈も提供せず、それによって曖昧さを無視するか、または次いで、より大きな語彙リソースを生成するために使用することができない非常に特定の意味的文脈を提供するかのいずれかの制限がある。 また、2項目以上の類似性は考慮しない。 私たちは、大規模なデータセット構築のために最近提案された方法論の完全な説明と分析を提供します。この方法論は、第1段階の動詞の大規模なサンプルの意味論的分類、ならびに第2段階の結果として生じる意味論的クラス内で行われた多方向の類似性判断を生成します。 この方法論は、視覚刺激の多方向類似性判断を捕捉するために、認知神経科学の分野で提案された空間多重配置アプローチを使用する。 私たちは、この方法を多義的な言語刺激と以前の仕事よりもはるかに大きなサンプルを扱うように適応させました。 特に動詞をターゲットにしていますが、この方法は音声の他の部分にも同様に適用できます。 最初の段階からのデータに対してクラスター分析を行い、これがどのように\n総合的な動詞リソースの構築に役立つかもしれません。また、第２の位相によって取り込まれた意味情報を分析し、人間の言葉の類似性の概念をよりよく反映するために、空間的に誘導された類似性判断の可能性について議論する。結果として得られるデータセットが、意味的クラスタリングと意味的類似性の本質的なタスクに関する表現学習モデルの細かい分析と評価にどのように使用できるかを実証する。特に、より強力な静的な単語埋め込み方法は、単語レベルの類似性とクラスタリングの両方で、より最近の事前トレーニング方法から生まれた語彙表現よりも優れていることがわかります。さらに、データセットの膨大なカバレッジのおかげで、「熱」や「動き」などの特定のセマンティックドメインでFrameNetおよびVerbNet改造モデルを評価することによって、特定のタイプの外部知識のためにベクトル表現を専門化する利点を比較することができます。', 'ru': 'Абстрактное исследование моделей обучения репрезентации лексической семантики обычно использует ту или иную форму внутренней оценки, чтобы убедиться, что изученные репрезентации отражают семантические суждения человека. Лексическая оценка семантического сходства является широко используемым методом оценки, но усилия, как правило, сосредоточены на парных суждениях о словах в изоляции или ограничены конкретными контекстами и лексическими стимулами. Существуют ограничения с этими подходами, которые либо не обеспечивают какого-либо контекста для суждений, и, таким образом, игнорируют двусмысленность, или обеспечивают очень конкретные контексты, которые затем не могут быть использованы для генерации большего лексического ресурса. Кроме того, не учитывается сходство между более чем двумя пунктами. Мы предоставляем полное описание и анализ нашей недавно предложенной методологии построения крупномасштабного набора данных, которая производит семантическую классификацию большой выборки глаголов на первом этапе, а также многофакторные оценки сходства, сделанные в рамках результирующих семантических классов на втором этапе. Методология использует предложенный в области когнитивной нейробиологии пространственный многоаспектный подход для захвата многофакторных оценок сходства зрительных стимулов. Мы адаптировали этот метод для обработки полисемантических лингвистических стимулов и гораздо больших образцов, чем предыдущая работа. Мы специально нацелены на глаголы, но метод в равной степени может быть применен и к другим частям речи. Мы проводим кластерный анализ по данным первого этапа и демонстрируем, как это\nможет быть полезно при построении всеобъемлющего глагольного ресурса. Мы также анализируем семантическую информацию, полученную на втором этапе, и обсуждаем потенциал пространственно индуцированных суждений о сходстве, чтобы лучше отразить человеческие понятия о сходстве слов. Показано, как результирующий набор данных может быть использован для мелкозернистых анализов и оценки репрезентативных моделей обучения по имманентным задачам семантической кластеризации и семантического сходства. В частности, мы обнаружили, что более сильные статические методы встраивания слов все еще превосходят лексические представления, возникающие из более поздних методов предварительного обучения, как на уровне сходства слов, так и кластеризации. Кроме того, благодаря обширному охвату набора данных, мы можем сравнить преимущества специализированных векторных представлений для определенного типа внешних знаний, оценивая модели FrameNet- и VerbNet-переоснащенные на конкретных семантических областях, таких как «Тепло» или «Движение».', 'ga': 'Coimrithe De ghnáth úsáidtear taighde ar shamhlacha foghlama ionadaíochta de shéimeantaic léacsach de chineál éigin meastóireachta intreach chun a chinntiú go léiríonn na huiríll foghlamtha breithiúnais shéimeantacha daonna. Is modh meastóireachta a úsáidtear go forleathan é meastachán cosúlachta shéimeantach foclóireachta, ach is iondúil go ndírítear iarrachtaí ar bhreithiúnais péire ar fhocail ina n-aonar, nó tá siad teoranta do chomhthéacsanna sonracha agus spreagthaí foclóireachta. Tá teorainneacha leis na cineálacha cur chuige seo nach dtugann comhthéacs ar bith do bhreithiúnais, agus dá réir sin neamhaird a dhéanamh ar athbhrí, nó a sholáthraíonn comhthéacsanna sainiúla tuairimí nach féidir a úsáid ansin chun acmhainn foclóireachta níos mó a chruthú. Ina theannta sin, ní mheastar cosúlachtaí idir níos mó ná dhá mhír. Cuirimid cur síos agus anailís iomlán ar an modheolaíocht atá molta againn le déanaí maidir le tógáil tacair sonraí ar mhórscála a tháirgeann aicmiú séimeantach ar shampla mór de na briathra sa chéad chéim, chomh maith le breithiúnais chosúlachta ilbhealaigh a dhéantar laistigh de na haicmí shéimeantacha iarmhartacha i. an dara céim. Úsáideann an mhodheolaíocht cur chuige spásúil il-socruithe atá molta i réimse na néareolaíochta cognaíocha chun breithiúnais chosúlachta ilbhealaigh i spreagthaigh amhairc a ghabháil. Tá an modh seo curtha in oiriúint againn chun spreagthaí teanga ilghnéitheacha a láimhseáil agus samplaí i bhfad níos mó ná mar a rinneadh roimhe seo. Dírímid go sonrach ar bhriathra, ach is féidir an modh a chur i bhfeidhm go cothrom ar chodanna eile den chaint. Déanaimid anailís bhraisle ar na sonraí ón gcéad chéim agus léirímid conas mar a dhéantar é seo\nd’fhéadfadh sé a bheith úsáideach chun acmhainn chuimsitheach briathra a chur le chéile. Déanaimid anailís freisin ar an bhfaisnéis shéimeantach a gabhadh ag an dara céim agus pléimid an poitéinseal atá ag na breithiúnais chosúlachta a tharlódh ó thaobh spáis de chun tuairimí daonna cosúlachta focal a léiriú níos fearr. Léirímid conas is féidir an tacar sonraí dá bharr a úsáid le haghaidh anailísí míne agus meastóireachta ar shamhlacha foghlama ionadaíochta ar thascanna intreacha cnuasaigh shéimeantaigh agus cosúlachta shéimeantach. Go háirithe, feicimid go sáraíonn modhanna leabú focal statacha níos láidre fós na huiríll foclóireachta a tháinig chun cinn ó mhodhanna réamhoiliúna níos déanaí, ar chosúlacht agus ar chnuasú focal. Ina theannta sin, a bhuí le clúdach ollmhór na tacair sonraí, is féidir linn comparáid a dhéanamh idir na buntáistí a bhaineann le sainléiriú veicteora do chineál áirithe eolais sheachtraigh trí mhúnlaí FrameNet- agus VerbNet-ais-fheistithe a mheas ar shainréimsí shéimeantacha mar “Teas” nó “Motion. ”', 'zh': '摘要词汇语义学者,所以质学语义也。 词汇语义相似性度博用之评,而事集孤立之单词,或止于特定上下文词汇。 此术有局限性,或不为决一上下文,而忽歧义,或为非常之句上下文,然后不可以成大词汇之资。 此外,不计两项目之相似性。 供吾近者大集构法之全析,当于第一阶段生大动词样本之语义,及于第二阶段中语义类中多向相似性决之。 其法用知神经科学领域空间多排法,所以获视激刺者多决于相似性。 吾辈既调此术以处之多义语言激刺,大于前样本。 专于动词,同用于词性。 聚类析第一阶段之数,以示何如?\n或助构全动词之资。 论第二阶段获之语义息,论空诱相似性之力,以见人之单词相似性名。 以数集语义聚类语义相似性者,细粒度量也。 特见词级相似性聚类,静态犹优于近预训练方法词汇。 凡此诸覆盖范围,特定语义域(如Heat、Motion、评FrameNet与VerbNet更造模形以较之特定外知专向量之利也。', 'hi': 'लेक्सिकल शब्दार्थ के प्रतिनिधित्व सीखने के मॉडल में अमूर्त अनुसंधान आमतौर पर यह सुनिश्चित करने के लिए आंतरिक मूल्यांकन के कुछ रूपों का उपयोग करता है कि सीखा प्रतिनिधित्व मानव शब्दार्थ निर्णयों को प्रतिबिंबित करता है। लेक्सिकल शब्दार्थ समानता अनुमान एक व्यापक रूप से उपयोग की जाने वाली मूल्यांकन विधि है, लेकिन प्रयासों ने आमतौर पर अलगाव में शब्दों के युग्मवार निर्णयों पर ध्यान केंद्रित किया है, या विशिष्ट संदर्भों और लेक्सिकल उत्तेजनाओं तक सीमित हैं। इन दृष्टिकोणों के साथ सीमाएं हैं जो या तो निर्णय के लिए कोई संदर्भ प्रदान नहीं करती हैं, और इस प्रकार अस्पष्टता को अनदेखा करती हैं, या बहुत विशिष्ट संवेदनशील संदर्भ प्रदान करती हैं जिनका उपयोग तब एक बड़े लेक्सिकल संसाधन उत्पन्न करने के लिए नहीं किया जा सकता है। इसके अलावा, दो से अधिक वस्तुओं के बीच समानता पर विचार नहीं किया जाता है। हम बड़े पैमाने पर डेटा सेट निर्माण के लिए हमारी हाल ही में प्रस्तावित पद्धति का पूर्ण विवरण और विश्लेषण प्रदान करते हैं जो पहले चरण में क्रियाओं के एक बड़े नमूने का शब्दार्थ वर्गीकरण पैदा करता है, साथ ही साथ दूसरे चरण में परिणामी शब्दार्थ वर्गों के भीतर किए गए बहु-तरफ़ा समानता निर्णय भी। पद्धति दृश्य उत्तेजनाओं के बहु-तरफ़ा समानता निर्णयों को कैप्चर करने के लिए संज्ञानात्मक तंत्रिका विज्ञान के क्षेत्र में प्रस्तावित एक स्थानिक बहु-व्यवस्था दृष्टिकोण का उपयोग करती है। हमने इस विधि को पॉलीसेमस भाषाई उत्तेजनाओं और पिछले काम की तुलना में बहुत बड़े नमूनों को संभालने के लिए अनुकूलित किया है। हम विशेष रूप से क्रियाओं को लक्षित करते हैं, लेकिन विधि को समान रूप से भाषण के अन्य हिस्सों पर लागू किया जा सकता है। हम पहले चरण से डेटा पर क्लस्टर विश्लेषण करते हैं और प्रदर्शित करते हैं कि यह कैसे\nएक व्यापक क्रिया संसाधन के निर्माण में उपयोगी हो सकता है। हम दूसरे चरण द्वारा कैप्चर की गई शब्दार्थ जानकारी का भी विश्लेषण करते हैं और शब्द समानता की मानवीय धारणाओं को बेहतर ढंग से प्रतिबिंबित करने के लिए स्थानिक रूप से प्रेरित समानता निर्णयकी क्षमता पर चर्चा करते हैं। हम प्रदर्शित करते हैं कि कैसे परिणामी डेटा सेट का उपयोग शब्दार्थ क्लस्टरिंग और शब्दार्थ समानता के आंतरिक कार्यों पर ठीक-ठाक विश्लेषण और प्रतिनिधित्व सीखने के मॉडल के मूल्यांकन के लिए किया जा सकता है। विशेष रूप से, हम पाते हैं कि मजबूत स्थैतिक शब्द एम्बेडिंग विधियां अभी भी शब्द-स्तर की समानता और क्लस्टरिंग दोनों पर हाल ही में पूर्व-प्रशिक्षण विधियों से उभरने वाले लेक्सिकल अभ्यावेदनों से बेहतर प्रदर्शन करती हैं। इसके अलावा, डेटा सेट के विशाल कवरेज के लिए धन्यवाद, हम "हीट" या "मोशन" जैसे विशिष्ट शब्दार्थ डोमेन पर FrameNet- और VerbNet-retrofitted मॉडल का मूल्यांकन करके एक विशेष प्रकार के बाहरी ज्ञान के लिए वेक्टर प्रतिनिधित्व को विशेषज्ञता देने के लाभों की तुलना करने में सक्षम हैं।', 'ka': 'აბსტრაქტური განსხვავება ლექსიკალური სმენტიკის მოდელების გამოყენებაში გამოიყენება ინტერნექტური განსხვავებაზე, რომ დარწმუნოთ, რომ მეცნიერებული გამოყენებები განსხვავებენ Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. არსებობს განზომილებები, რომლებიც ანუ არსებობს კონტექსტის განზომილებებისთვის, და ამიტომ არსებობს არსებობას, ანუ ძალიან განსაკუთრებული კონტექსტის განზომილება, რომელიც შემდეგ არ შეიძლება გამ დამატებით, უფრო მეტი ორივე ელემენტების განსხვავება არ იყოს. ჩვენ უკვე მხოლოდ ჩვენი მოგვეყენებული მეტოლოგიის უფრო გამოსახულება და ანალიზაცია, რომელიც მეორე ფაზაში უფრო დიდი გერბების სიმპანტიკური კლასიფიკაცია გამოვიყენებს, და მრავალური განსხვავება, რომელიც გავაკეთებული შემდეგ სმენტიკ მეტოდოლოგია გამოყენება სისტემალური მრავალური განზომილებების მიღება, რომელიც კონციონიტური ნეირომეცნიერების პანელში გამოყენება ვიზუალური სტიმულის მრავალური განზომილებების გა ჩვენ ამ პროცემის შესაძლებლობად პოლისემისტიკური სტიმულები და უფრო დიდი მონაცემები წინა მუშაობით. ჩვენ განსაკუთრებულად გვერბების მიღება, მაგრამ მეტი შეიძლება იგივე განსაკუთრებულად გადაყენება სხვა ნაწილაზე. ჩვენ კლასტერის ანალიზაციას პირველი ფაზის მონაცემების შესახებ და გამოჩვენებთ როგორ ეს', 'el': 'Η έρευνα σε μοντέλα εκμάθησης αναπαράστασης της λεξικής σημασιολογίας συνήθως χρησιμοποιεί κάποια μορφή εγγενής αξιολόγησης για να διασφαλίσει ότι οι διδασκόμενες αναπαραστάσεις αντικατοπτρίζουν ανθρώπινες σημασιολογικές κρίσεις. Η Λεξική σημασιολογική εκτίμηση ομοιότητας είναι μια ευρέως χρησιμοποιούμενη μέθοδος αξιολόγησης, αλλά οι προσπάθειες έχουν συνήθως επικεντρωθεί σε ζεύγη κρίσεις λέξεων μεμονωμένα, ή περιορίζονται σε συγκεκριμένα πλαίσια και λεξικά ερεθίσματα. Υπάρχουν περιορισμοί με αυτές τις προσεγγίσεις που είτε δεν παρέχουν κανένα πλαίσιο για τις κρίσεις, και έτσι αγνοούν την ασάφεια, είτε παρέχουν πολύ συγκεκριμένα νοητικά πλαίσια που δεν μπορούν στη συνέχεια να χρησιμοποιηθούν για τη δημιουργία ενός μεγαλύτερου λεξικού πόρου. Επιπλέον, δεν λαμβάνεται υπόψη η ομοιότητα μεταξύ περισσότερων από δύο στοιχείων. Παρέχουμε μια πλήρη περιγραφή και ανάλυση της πρόσφατα προτεινόμενης μεθοδολογίας κατασκευής συνόλων δεδομένων μεγάλης κλίμακας που παράγει μια σημασιολογική ταξινόμηση ενός μεγάλου δείγματος ρήμων στην πρώτη φάση, καθώς και πολλαπλές εκτιμήσεις ομοιότητας που γίνονται μέσα στις προκύπτουσες σημασιολογικές τάξεις στη δεύτερη φάση. Η μεθοδολογία χρησιμοποιεί μια χωρική προσέγγιση πολλαπλών ρυθμίσεων που προτείνεται στον τομέα της γνωστικής νευροεπιστήμης για την καταγραφή πολλαπλών κριτηρίων ομοιότητας οπτικών ερεθίσεων. Έχουμε προσαρμόσει αυτή τη μέθοδο για να χειριστούμε πολυσυναισθηματικά γλωσσικά ερεθίσματα και πολύ μεγαλύτερα δείγματα από προηγούμενες εργασίες. Στοχεύουμε συγκεκριμένα ρήματα, αλλά η μέθοδος μπορεί εξίσου να εφαρμοστεί και σε άλλα μέρη της ομιλίας. Πραγματοποιούμε ανάλυση συστοιχιών στα δεδομένα από την πρώτη φάση και καταδεικνύουμε πώς αυτό', 'it': "La ricerca sui modelli di apprendimento della rappresentazione della semantica lessicale utilizza solitamente una qualche forma di valutazione intrinseca per garantire che le rappresentazioni apprese riflettano giudizi semantici umani. La stima della somiglianza semantica lessicale è un metodo di valutazione ampiamente utilizzato, ma gli sforzi si sono tipicamente concentrati su giudizi a coppie di parole isolate, o sono limitati a contesti specifici e stimoli lessicali. Ci sono limitazioni con questi approcci che o non forniscono alcun contesto per i giudizi, e quindi ignorano l'ambiguità, o forniscono contesti sentimentali molto specifici che non possono quindi essere utilizzati per generare una risorsa lessicale più ampia. Inoltre, la somiglianza tra più di due elementi non è considerata. Forniamo una descrizione completa e un'analisi della nostra metodologia recentemente proposta per la costruzione di set di dati su larga scala che produce una classificazione semantica di un grande campione di verbi nella prima fase, così come giudizi di somiglianza multi-way effettuati all'interno delle classi semantiche risultanti nella seconda fase. La metodologia utilizza un approccio spaziale multi-arrangiamento proposto nel campo delle neuroscienze cognitive per catturare giudizi di somiglianza multi-way degli stimoli visivi. Abbiamo adattato questo metodo per gestire stimoli linguistici polisemosi e campioni molto più grandi rispetto ai lavori precedenti. Ci rivolgiamo specificamente ai verbi, ma il metodo può essere applicato anche ad altre parti del discorso. Eseguiamo analisi cluster sui dati della prima fase e dimostriamo come questo", 'hu': 'Absztrakt A lexikai szemantika reprezentációs tanulási modelljeinek kutatása általában a belső értékelés valamilyen formáját használja annak biztosítására, hogy a tanult reprezentációk tükrözzék az emberi szemantikai ítéleteket. A lexikai szemantikai hasonlóság becslése széles körben használt értékelési módszer, de az erőfeszítések jellemzően az elszigetelt szavak páros megítélésére összpontosítanak, vagy konkrét kontextusokra és lexikai ingerekre korlátozódnak. Ezeknek a megközelítéseknek vannak olyan korlátai, amelyek vagy nem biztosítanak kontextust az ítéletek számára, és ezáltal figyelmen kívül hagyják a kétértelműséget, vagy nagyon speciális értelmi kontextusokat biztosítanak, amelyek ekkor nem használhatók fel nagyobb lexikai erőforrás létrehozására. Továbbá nem veszik figyelembe kétnél több tétel közötti hasonlóságot. Teljes körű leírást és elemzést nyújtunk a közelmúltban javasolt módszertanunkról a nagyszabású adatkészlet építésére, amely az első fázisban nagy igék mintájának szemantikai osztályozását eredményezi, valamint a második fázisban az eredményező szemantikai osztályokon belül hozott többirányú hasonlósági ítéleteket. A módszertan a kognitív idegtudomány területén javasolt térbeli, többszörös elrendezésű megközelítést alkalmaz a vizuális ingerek többirányú hasonlósági ítéleteinek rögzítésére. Ezt a módszert a korábbi munkáknál sokkal nagyobb minták kezelésére adaptáltuk. Kifejezetten az igéket célozzuk meg, de a módszer a beszéd más részeire is alkalmazható. Az első fázisból származó adatokon klaszterelemzést végzünk, és bemutatjuk, hogyan', 'kk': 'Лексикалық семантикалық оқыту үлгілерінің абстракты зерттеулері кәдімгі, білім тәсілдердің адамдардың семантикалық тәжірибелерін көрсету үшін кейбір түрлі интринзикалық оқи Лексикалық семантикалық ұқсас бағалау - көп қолданылатын бағалау әдісі, бірақ әдетте бұл сөздердің екі жағдай бөліміне назар аударылды, немесе осы жағдай жағдай мен лексикалық стимулдарға шектелген. Бұл жағдайлардың шектеулері бар. Бұл үлкен шектеулерге контекст бермейді. Сондай-ақ бұл шектеулерді елемейді, немесе оның үлкен лексикалық ресурсты құру үшін қолданылмайтын мәліметтерді өзгерту үші Қосымша, екеуден артық нысандар арасындағы ұқсас болмайды. Біз жуырдағы кеңейтілген деректер жинағының үлкен масштабының методологиясын толық сипаттамасын және анализ береміз. Бұл бірінші фазейдегі үлкен вербалардың семантикалық классификациясын жасайды, сондай-ақ екінші фазейдегі семантикалық классында Бұл методология көптеген көптеген жергілікті көптеген тәсілдерді көптеген неврологиялық өрісінде көрінетін көптеген стимулдардың сәйкестіктерін алу үшін қолданылады. Біз бұл әдістерді полиземді лингвистикалық стимулдарды және алдыңғы жұмыстардан артық үлкен үлкен үлгілерді өзгертдік. Біз тіпті вербаларды мақсат етіп, бірақ әдіс басқа сөйлеу бөлігіне тең қолданылады. Біз бірінші этаптағы деректер туралы кластер анализациясын жасап,', 'lt': 'Abstraktiniai moksliniai tyrimai, susiję su lexinės semantikos mokymosi reprezentaciniais modeliais, paprastai naudoja tam tikrą savarankiško vertinimo form ą, kad būtų užtikrinta, jog išmoktos reprezentacijos atspindėtų žmogaus semantinius sprendimus. Leksinis semantinis panašumo vertinimas yra plačiai naudojamas vertinimo metodas, tačiau pastangos paprastai buvo sutelktos į dviejų žodžių sprendimus atskirai arba apsiriboja konkrečiomis aplinkybėmis ir leksiniais stimuli a is. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that cannot then be used to generate a larger lexical resource.  Be to, neatsižvelgiama į panašumą tarp daugiau kaip dviejų straipsnių. Mes pateikiame išsamų mūsų neseniai pasiūlytos didelio masto duomenų rinkinio kūrimo metodikos aprašymą ir analizę, pagal kurią pirmajame etape semantiškai klasifikuojamas didelis žodžių ėminys, taip pat kelių krypčių panašumo sprendimai, priimti pagal gautas semantines klases antrajame etape. Metodikoje naudojamas erdvinis daugiasluoksnis metodas, pasiūlytas kognityvinio neuromokslinio tyrimo srityje, siekiant priimti daugiasluoksnius vizualinių stimuli ų panašumo sprendimus. Mes pritaikėme šį metodą, kad būtų galima tvarkyti polizieminius kalbinius stimulius ir daug didesnius mėginius nei ankstesnis darbas. Mes konkrečiai nukreipiame į žodžius, bet metodas gali būti taikomas ir kitoms kalbos dalims. Atliekame pirmojo etapo duomenų grupių analizę ir parodysime, kaip tai', 'ms': 'kajian abstrak ke dalam model pembelajaran mewakili semantik leksikal biasanya menggunakan beberapa bentuk penilaian dalaman untuk memastikan mewakili belajar mencerminkan penilaian semantik manusia. Perkiraan persamaan semantik leksikal adalah kaedah penilaian yang digunakan secara luas, tetapi usaha biasanya telah fokus pada penilaian perkataan pasangan dalam pengasingan, atau terhad kepada konteks khusus dan istimuli leksikal. Terdapat keterangan dengan pendekatan ini yang sama ada tidak menyediakan sebarang konteks untuk penghakiman, dan dengan itu mengabaikan ambiguiti, atau menyediakan konteks kalimat yang sangat spesifik yang tidak boleh digunakan untuk menghasilkan sumber leksikal yang lebih besar. Lagipun, persamaan antara lebih dari dua item tidak dianggap. Kami menyediakan keterangan penuh dan analisis metodologi kami yang diusulkan baru-baru ini untuk pembangunan set data skala besar yang menghasilkan klasifikasi semantik sampel besar verb dalam fasa pertama, serta penilaian perbandingan berbilang arah yang dibuat dalam kelas semantik hasil dalam fasa kedua. Metodologi menggunakan pendekatan berbilang-pengaturan ruang yang diusulkan dalam medan sains neurologi kognitif untuk menangkap penilaian kesamaan berbilang-cara stimuli visual. Kami telah menyesuaikan kaedah ini untuk mengendalikan stimul bahasa polisemus dan sampel yang lebih besar daripada kerja sebelumnya. Kami secara khusus sasaran verb, tetapi kaedah boleh sama-sama dilaksanakan pada bahagian lain ucapan. Kami melakukan analisis kumpulan pada data dari fasa pertama dan menunjukkan bagaimana ini', 'ml': 'ലെക്സിക്സിക്കല്\u200d സെമാന്റിക്സിന്റെ പ്രതിനിധിയില്\u200d പഠിക്കുന്ന മോഡലുകളിലേക്ക് അസ്ട്രാക്രേക്റ്റ് ചെയ്യുക. പഠിച്ച പ്രതിന ലെക്സിക്സിക്കല്\u200d സെമാന്റിക് സമമാക്രമണത്തിന്റെ അസാധാരണയാണ് ഒരു വിശ്വാസത്തിന്റെ മാര്\u200dഗമാണ്. പക്ഷെ പ്രശ്നങ്ങള്\u200d സാധാരണ വാക്കുകളുടെ രണ്ട് വിധികളെ  There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that cannot then be used to generate a larger lexical resource.  അതിനുശേഷം, രണ്ടു വസ്തുക്കള്\u200dക്കിടയില്\u200d കൂടുതല്\u200d സമമാണെന്ന് വിചാരിക്കുന്നില്ല. നമ്മള്\u200d നമ്മുടെ അടുത്തുള്ള പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്\u200d ഒരു പൂര്\u200dണ്ണമായ വിശദീകരണവും വിശദീകരണവും നല്\u200dകുന്നു. അത് ആദ്യത്തെ ക്ലാസില്\u200d ഒരു മഹാമാന്റിക് ക്ലാസ്ഫിക്ക് സൃഷ്ടി ഈ രീതിയില്\u200d ഒരു സ്പെസ്റ്റിയേല്\u200d അധികമായി സംഘടനയുടെ നടപടി ഉപയോഗിക്കുന്നു. കോഗ്നിയറ്റ് ന്യൂറസിന്റെ പാലത്തില്\u200d പ്രായശ്ചിത്തമായ ഒരു  ഞങ്ങള്\u200d പോളിസിമിസ് ഭാഷകങ്ങളുടെ സ്റ്റിമുലില്\u200d കൈകാര്യം ചെയ്യാന്\u200d ഈ രീതിയില്\u200d മാറ്റിയിട്ടുണ്ട്. മുമ്പ് പണ നമ്മള്\u200d പ്രത്യേകിച്ച് വാര്\u200dഡുകളെ ലക്ഷ്യം ചെയ്യുന്നു, പക്ഷെ പ്രസംഗിക്കുന്ന മറ്റു ഭാഗങ്ങളിലേക്ക് ഒര നമ്മള്\u200d ആദ്യത്തെ അവസ്ഥയില്\u200d നിന്നുള്ള വിവരങ്ങളെക്കുറിച്ച് ക്ലാസ്റ്റര്\u200d അന്വേഷണം നടത്തുന്നു.', 'mt': 'Ir-riċerka astratta dwar mudelli ta’ tagħlim ta’ rappreżentazzjoni tas-semantika lexika normalment tuża xi forma ta’ evalwazzjoni intrinsika biex tiżgura li r-rappreżentazzjonijiet imgħallma jirriflettu sentenzi semantiċi umani. L-istima ta’ similarità semantika lexika hija metodu ta’ evalwazzjoni użat ħafna, iżda l-isforzi tipikament iffukaw fuq sentenzi bejn il-pari ta’ kliem iżolati, jew huma limitati għal kuntesti speċifiċi u stimuli lexiċi. Hemm limitazzjonijiet b’dawn l-approċċi li jew ma jipprovdu l-ebda kuntest għal sentenzi, u b’hekk jinjoraw l-ambigwità, jew jipprovdu kuntesti sentenzjali speċifiċi ħafna li mbagħad ma jistgħux jintużaw biex jiġġeneraw riżorsa lexika akbar. Barra minn hekk, mhijiex ikkunsidrata similarità bejn aktar minn żewġ elementi. We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase.  Il-metodoloġija tuża approċċ ta’ arranġament multiplu ġeografiku propost fil-qasam tan-newroxjenza konjittiva biex jinkisbu sentenzi ta’ similarità multidirezzjonali ta’ stimuli viżivi. Aġġustajna dan il-metodu biex nimmaniġġjaw stimuli lingwistiċi poliżimali u kampjuni ħafna akbar minn xogħol preċedenti. Nimmiraw b’mod speċifiku l-verbs, iżda l-metodu jista’ jiġi applikat b’mod ugwali għal partijiet oħra tad-diskors. Aħna nagħmlu analiżi ta’ raggruppament dwar id-dejta mill-ewwel fażi u nuru kif dan', 'mk': 'Апстрактно истражување за репрезентациски модели на учење на лексикалната семантика обично користи некоја форма на внатрешна оценка за да се осигури дека научените репрезентации ги одразуваат човечките семантични пресуди. Лексикалната семантична проценка на сличност е широко употребен метод на проценка, но напорите обично се фокусираат на двојни пресуди на зборови во изолација, или се ограничени на специфични контексти и лексикални стимули. Постојат ограничувања со овие пристапи кои или не обезбедуваат никаков контекст за пресудите, и со тоа игнорираат нејасност, или обезбедуваат многу специфични реченствени контексти кои тогаш не можат да се користат за генерирање поголем лексикален ресурс. Покрај тоа, сличноста помеѓу повеќе од два предмети не се разгледува. Ние обезбедуваме целосен опис и анализа на нашата неодамна предложена методологија за изградба на голем набор податоци кој произведува семантична класификација на голем примерок на јазици во првата фаза, како и мултипатични пресуди за сличност направени во резултатните семантични класи во втората фаза. Метологијата користи просторски пристап со мултиаранжмани предложен во областа на когнитивната невронаука за заземање мултипатични пресуди за сличност на визуелни стимули. Го адаптиравме овој метод за да се справиме со полисемски јазички стимули и многу поголеми примероци од претходната работа. We specifically target verbs, but the method can equally be applied to other parts of speech.  Правиме анализа на групи на податоците од првата фаза и демонстрираме како ова', 'pl': 'Badania nad modelami uczenia się reprezentacji semantyki leksykalnej zazwyczaj wykorzystują pewną formę wewnętrznej oceny, aby zapewnić, że nauczone reprezentacje odzwierciedlają ludzkie osądy semantyczne. Leksykalna ocena podobieństwa semantycznego jest szeroko stosowaną metodą oceny, ale wysiłki koncentrowały się zazwyczaj na parowych ocenach słów w izolacji lub ograniczają się do konkretnych kontekstów i bodźców leksykalnych. Istnieją ograniczenia w tych podejściach, które albo nie zapewniają żadnego kontekstu dla osądów, a tym samym ignorują dwuznaczność, albo zapewniają bardzo specyficzne konteksty sensentialne, które nie mogą być następnie wykorzystane do generowania większego zasobu leksykalicznego. Ponadto nie uwzględnia się podobieństwa więcej niż dwóch pozycji. Zapewniamy pełny opis i analizę naszej ostatnio proponowanej metodologii budowy zbiorów danych na dużą skalę, która generuje klasyfikację semantyczną dużej próby czasowników w pierwszej fazie, a także wielokierunkowe oceny podobieństwa dokonywane w ramach wynikających z nich klas semantycznych w drugiej fazie. Metodologia wykorzystuje przestrzenne podejście multi-aranżacyjne proponowane w dziedzinie neuronauki poznawczej do przechwytywania wielokierunkowych ocen podobieństwa bodźców wzrokowych. Dostosowaliśmy tę metodę do obsługi wielosemicznych bodźców językowych i znacznie większych próbek niż poprzednie prace. Szczególnie kierujemy się do czasowników, ale metoda ta może być również stosowana do innych części mowy. Przeprowadzamy analizę klastrową na danych z pierwszej fazy i pokazujemy, w jaki sposób to możliwe', 'ro': 'Cercetarea modelelor de învățare a reprezentării semanticii lexicale utilizează de obicei o formă de evaluare intrinsecă pentru a se asigura că reprezentările învățate reflectă judecățile semantice umane. Estimarea similarității semantice lexicale este o metodă de evaluare utilizată pe scară largă, dar eforturile s-au concentrat în mod obișnuit pe judecăți pereche ale cuvintelor izolate sau sunt limitate la contexte specifice și stimuli lexicali. Există limitări în aceste abordări care fie nu oferă nici un context pentru judecăți și, prin urmare, ignoră ambiguitatea, fie oferă contexte sentimentale foarte specifice, care nu pot fi apoi folosite pentru a genera o resursă lexicală mai mare. În plus, nu se ia în considerare asemănarea dintre mai mult de două elemente. Oferim o descriere completă și o analiză a metodologiei noastre recent propuse pentru construirea seturilor de date la scară largă, care produce o clasificare semantică a unui eșantion mare de verbe în prima fază, precum și judecăți de similitudine multidirecțională făcute în cadrul claselor semantice rezultate în a doua fază. Metodologia utilizează o abordare spațială multi-aranjament propusă în domeniul neuroștiințelor cognitive pentru captarea judecăților de similitudine multidirecțională a stimulilor vizuali. Am adaptat această metodă pentru a gestiona stimuli lingvistici polisemoși și mostre mult mai mari decât lucrările anterioare. Obiectivăm în mod specific verbele, dar metoda poate fi aplicată și altor părți ale vorbirii. Efectuăm analize cluster pe datele din prima fază și demonstrăm modul în care acestea sunt', 'mn': 'Экстрактикийн суралцах суралцах загваруудын загваруудыг харуулахын тулд суралцан үзүүлэлтийн загварууд нь хүн төрөлхтний шийдвэрлэлтийг харуулахын тулд зарим төрлийн дүгнэлтийг ашигладаг. Lexical semantic equality estimation is a widely used evaluation method, but efforts have typically focused on two words in isolation, or are limited to specific contexts and lexical stimulation. Эдгээр арга баримт хязгаарлалт байдаг. Шүүмжлэх үед ямар ч нөхцөл байдлыг хандуулж чадахгүй. Үүнээс гайхалтай байдлыг эсвэл маш тодорхой мэдрэмжлэх нөхцөл байдлыг хандуулж чадахгүй. Дараа нь, хоёр асуудлын хоорондох төстэй адилтгал ойлгомжгүй. Бид саяхан том хэмжээний өгөгдлийн бүтээгдэхүүний шинжлэх ухаан болон шинжлэх ухаан өгөгдлийн хэмжээний шинжлэх ухааны тухай бүрэн тодорхойлдог. Энэ нь анхны хэмжээнд ихэнх хэмжээний жишээг бий болгодог. Энэ методологийг харааны сэтгэл хөдлөлийн олон төрлийн загварын арга зам ашигладаг. Бид энэ аргыг өмнөх ажлаас илүү олон хэлний сэтгэл хөдлөлийг зохицуулахын тулд зохицуулсан. Бид илтгэлийг тодорхой зориулсан, гэхдээ арга нь бусад хэсэгт адилхан хэрэглэгдэж болно. Бид анхны этапаас өгөгдлийн талаар кластер шинжилгээ хийж,', 'no': 'Abstrakt forskning i læringsmodeller på leksiske semantikk brukar vanlegvis nokre form av intrinsiske evaluering for å sikre at dei lærte representasjonane reflekterer menneske semantiske sprøytebrukar. Leksiske semantiske tilsvarende estimation er ein vast brukt evalueringsmetode, men forsøk har vanlegvis fokusert på pare sprøytebrukar av ord i isolation, eller er begrenset til spesifikke kontekstar og leksisk stimuler. Det finst begrensningar med desse tilnærmingane som anten ikkje gjev nokon kontekst for sprøytebrukar, og derfor ignorerer ambiguity, eller gjev veldig spesifikke sentensjonal kontekstar som ikkje kan derfor brukast til å laga eit større leksisk ressurs. I tillegg vert ikkje tilsvara similaritet mellom fleire enn to element. Vi gjev ein fullstendig skildring og analyse av vår nyleg foreslått metodologi for storskala datasett-konstruksjon som produserer ein semantisk klassifikasjon av eit stor prøve av verbar i den første fasen, og fleire måtar tilsvarande uttrykk i resultatet av semantiske klasser i den andre fasen. Metodologien brukar eit område fleire arrangeringslinjer som foreslått i feltet kognitivt neurovitenskap for å henta fleire måtar liknande sprøytebrukar av visuell stimuler. Vi har tilpassa denne metoden for å handtera polysemiske lingvisk stimuler og mykje større prøver enn tidlegare arbeid. Vi har spesifikke mål for verber, men metoden kan også brukast til andre taledeler. Vi utfører klasteranalysen på data frå den første fasen og viser korleis dette er', 'si': 'නිර්මාණය පරීක්ෂණය සඳහා ලෙක්සිකල් සෙමැන්ටික්ස් වලින් ඉගෙන ගන්න ප්\u200dරමාණය සඳහා සාමාන්\u200dය විශ්වාස කරන්න පුළුවන් විදිහ ලෙක්සිකාල් සෙමාන්ටික් සැමාන්තික විශ්වාසයක් විශ්වාසයෙන් භාවිත විශ්වාස කරන විධානයක්, නමුත් උත්සහ සාමාන්\u200dය විශ්වාසයෙන්  මේ විධානය සමඟ සීමාවල් තියෙනවා මේ විධානය සඳහා කිසිම සංවේදනය සඳහා කිසිම සංවේදනය සඳහා සඳහා කිසිම සංවේදනය සඳහා සිද්ධ වෙන්නේ න ඉතින්, අයිති දෙකක් වඩා වඩා අයිති වගේ සාමාන්\u200dයතාවක් හිතන්නේ නැහැ. අපි පුරුදු විස්තර සහ විශ්ලේෂණයක් දෙන්නේ අපේ අලුත් විස්තර සඳහා විශ්ලේෂණය ගැන ලොකු ස්කල් දත්ත සැට් නිර්මාණය සඳහා විස්තර සඳහා විශේෂණය සඳහා විස්තර කරනවා ම විද්\u200dයාත්මක භාවිතා කරනවා විද්\u200dයාත්මක විද්\u200dයාත්මක විද්\u200dයාත්මක විද්\u200dයාත්මක විද්\u200dයාත්මක විද්\u200dයාත්මක විද්\u200dයාපයක් අල්ලන අපි මේ විධානය සම්බන්ධ කරලා තියෙන්නේ පොලිසිම් භාෂාවික සුදුසුම් සහ කලින් වැඩිය වඩා ගොඩක් ලො අපි විශේෂයෙන් විශේෂයෙන් වාර්තාවක් ලක්ෂණය කරනවා, ඒත් වාර්තාවක් අනිත් කොටස් වලට සමාන්\u200dය ව අපි පළමුවෙනි පරීක්ෂණයෙන් තොරතුරු විශ්ලේෂණය කරනවා මේක කොහොමද පෙන්වන්නේ.', 'so': 'Baaritaanka ka qeybqaadashada tusaalaha waxbarashada leksikada waxaa inta badan isticmaala qaab ka mid ah qiimeynta gudaha si loo xaqiijiyo in qofka lagu bartay ay ka fiiriyaan xukummada dadka. Qiimeynta isku mid ah ee Leksikal waa qaab aad u badan oo loo isticmaalay qiimeynta, laakiin hawshooyinku waxay si caadiga ah ugu fiirsan yihiin labada xil oo xafiiska ah ee hadalka gooni ahaanshaha, ama waxay ku xadgudbaan qoraalo gaar ah iyo dhaqaale. Waxaa jira xadooyin ay leedahay qaababkan aan marnaba xukun u siin, markaasna aan ka jeedin dhaqdhaqaalaha, ama ay keeni karaan xeelad gaar ah oo aan markaas loo isticmaali karin in lagu sameeyo hanti aad u weyn. Furthermore, sinnaanta u dhexeeya laba wax ka badan lama tiriyo. Waxaannu sameynaa sawir buuxda iyo baaritaanka qaababkayaga la soo jeeday ee dhismaha danbiyada ee waaweyn, taasoo soo saara fasalka labaad oo kala duduwan samooyin badan oo hadal ah, sidoo kale xukummada isku mid ah ee fasalka labaad lagu sameeyo. Iswidishku wuxuu isticmaalaa qaabab kala duduwan oo lagu soo jeedo beerta cilmiga neuro-cilmiga ah oo loo soo jeedo si uu u qabsado xukummo isku mid ah oo aragga. We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work.  Waxaan si gaar ah u baahan nahay hadallada, laakiin qaababka waxaa si siman looga codsan karaa qeybo kale oo hadal ah. Ana sameynaa baaritaanka sawirada ee fasalka ugu horeeyay waxaana tusinaynaa sidan', 'sv': 'Abstract Forskning om representationsinlﾃ､rningsmodeller av lexikal semantik anvﾃ､nder vanligtvis nﾃ･gon form av inneboende utvﾃ､rdering fﾃｶr att sﾃ､kerstﾃ､lla att de lﾃ､rda representationerna ﾃ･terspeglar mﾃ､nskliga semantiska bedﾃｶmningar. Lexisk semantisk likhetsbedﾃｶmning ﾃ､r en allmﾃ､nt anvﾃ､nd utvﾃ､rderingsmetod, men anstrﾃ､ngningarna har vanligtvis fokuserat pﾃ･ parvisa bedﾃｶmningar av ord i isolering, eller ﾃ､r begrﾃ､nsade till specifika sammanhang och lexikala stimuli. Det finns begrﾃ､nsningar med dessa tillvﾃ､gagﾃ･ngssﾃ､tt som antingen inte ger nﾃ･gon kontext fﾃｶr bedﾃｶmningar, och dﾃ､rmed ignorerar tvetydighet, eller ger mycket specifika kﾃ､nslosammanhang som sedan inte kan anvﾃ､ndas fﾃｶr att generera en stﾃｶrre lexikal resurs. Dessutom beaktas inte likheter mellan mer ﾃ､n tvﾃ･ poster. Vi ger en fullstﾃ､ndig beskrivning och analys av vﾃ･r nyligen fﾃｶreslagna metod fﾃｶr storskalig datauppsﾃ､ttningskonstruktion som ger en semantisk klassificering av ett stort urval verb i den fﾃｶrsta fasen, samt flervﾃ､gs likhetsbedﾃｶmningar gjorda inom de resulterande semantiska klasserna i den andra fasen. Metoden anvﾃ､nder en spatial multi-arrangement approach fﾃｶreslagen inom omrﾃ･det kognitiv neurovetenskap fﾃｶr att fﾃ･nga multi-way likhet bedﾃｶmningar av visuella stimuli. Vi har anpassat denna metod fﾃｶr att hantera polyemoﾃｶsa sprﾃ･kliga stimuli och mycket stﾃｶrre prover ﾃ､n tidigare arbete. Vi riktar oss specifikt mot verb, men metoden kan ocksﾃ･ tillﾃ､mpas pﾃ･ andra delar av talet. Vi utfﾃｶr klusteranalys pﾃ･ data frﾃ･n fﾃｶrsta fasen och visar hur detta', 'sr': 'Abstrakt istraživanja u modelima učenja leksičkih semantika obično koristi neku vrstu unutrašnje procjene kako bi se osigurala da naučene predstave odražavaju ljudske semantičke osude. Procjenjivanje leksičke semantičke sličnosti je široko korišćena metoda procjene, ali napori su se obično fokusirali na pare osuđenja reči u izolaciji ili ograničeni na specifične kontekste i leksičke stimule. Postoje ograničenja sa ovim pristupima koje ili ne pružaju nikakav kontekst za osude, i tako ignoriraju ambiguitet, ili pružaju vrlo specifične sentencijalne kontekste koje se onda ne mogu koristiti za stvaranje većeg leksičkog resursa. Osim toga, ne smatra se sličnosti između više od dve stvari. Mi pružamo potpuni opis i analizu naše nedavno predložene metodologije za izgradnju velike skale podataka koji proizvodi semantičku klasifikaciju velikog uzoraka verba u prvoj fazi, kao i mnogim osuđivanjima sličnosti koji su doneli u rezultativnim semantičkim klasama u drugoj fazi. Metodologija koristi prostorni pristup višearanžmana koji je predložen u oblasti kognitivne neuronauke za uhvativanje suđenja višestranih sličnosti vizuelnog stimula. Prilagodili smo ovu metodu da se bavimo polizemnim jezičkim stimulima i mnogo većim uzorcima od prethodnog rada. Posebno ciljamo verbe, ali metod se može jednako primjenjivati na druge dijelove govora. Izvodimo klasterijsku analizu podataka iz prve faze i pokazujemo kako je ovo', 'ta': 'Abstract Research into representation learning models of lexical semantics usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments.  Lexical semantic similarity estimation is a widely used evaluation method, but efforts have normally focused on two wise words in isolation, or limited to specific contexts and lexical stimuli. விதிகளுக்கு எந்த சூழலும் வழங்கவில்லை என்று இந்த செயல்பாடுகளுக்கு எல்லைகள் இருக்கின்றன, அதனால் விருப்பங்களை தவிர்க்கவும், அல்லது மிகவும் குறிப்ப அதற்கு மேலும், இரண்டுக்கும் மேற்பட்ட உருப்படிகளுக்கும் இடையில் சமம் என கருதப்படாது. நாம் எங்கள் சமீபத்தில் திருந்திய முறைமையின் முழு விளக்கம் மற்றும் ஆய்வு வழங்குகிறோம் பெரிய அளவு தரவு அமைப்பு கட்டமைப்பிற்கு, அது முதல் நிலையில் ஒரு பெரிய மாதிரி சொல்லும்  இந்த முறைமையில் பார்வையின் ஒத்த தீர்ப்புகளை பெறுவதற்காக குறிப்பிடும் புலத்தில் பரிந்துரைக்கப்பட்ட பல அமைப்புகளை பயன்படுத்தும். முந்தைய வேலையை விட பெரிய மொழிகளை கையாள இந்த முறையை மாற்றி வைத்துள்ளோம். நாம் குறிப்பிட்ட சொற்களை குறிப்பிடுகிறோம், ஆனால் முறைமையில் பேச்சின் மற்ற பகுதிகளுக்கு சமமாக பயன நாம் முதல் நிலையில் இருந்து தகவல்களை செயல்படுத்தி எப்படி இதை காண்பிக்கிறோம்', 'ur': 'لکسیکل سیمانٹیکس کی تعلیم کی نمونڈل کے معاملہ میں مفصل تحقیق کے ذریعہ مفصل کے ذریعہ کچھ اندازے کی تحقیق کا استعمال کرتا ہے تاکہ علم کی تعلیم انسان کی سیمانٹی فیصلہ کرتی ہے. Lexical semantic similarity estimation is a widely used evaluation method, but efforts are typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. ان طریقوں کے ساتھ محدودیت ہیں جو فیصلے کے لئے کوئی کنترکس نہیں دیتے، اور اس کے ذریعہ غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غ اور اس کے علاوہ، دو سے زیادہ چیزوں کے درمیان برابر نظر نہیں آتا۔ ہم نے اپنا اخیرا پیشنهاد کیا ہوا مٹولوژی کی پوری توصیف اور تحلیل دیتے ہیں جو بڑے اسکیل ڈیٹ سٹ بنانے کے لئے ایک بڑے نمونے کے نمونے کی سیمنٹی کلاسیفوں کو پہلی مرحلہ میں پیدا کرتا ہے، اور دوسرے مرحلہ میں بہت سی طرح کے مطابق مشابہ کا فیصلہ کرتا ہے۔ اس طریقہ کا استعمال کرتا ہے ایک جگہ مختلف طریقے کے مطابق جہالت نیروسائنس کے منطقه میں پیشنهاد کی جاتی ہے کہ مجھے طریقے کے مطابق مشابہ نظریات کے مطابق مشابہ کریں۔ ہم نے اس طریقہ کو اس طریقہ سے اگلے کاموں سے بہت بڑے نمونے کے ساتھ تحمل کرنے کے لئے اضافہ کیا ہے۔ ہم مخصوص باتوں کا موقع لگاتے ہیں، لیکن یہ طریقہ برابر باتوں کے دوسرے قسموں پر لازم کر سکتا ہے. ہم پہلی مرحلہ سے ڈیٹوں پر کلسٹر تحلیل کرتے ہیں اور دکھاتے ہیں کہ یہ کس طرح ہے', 'uz': "Name Leksikal semantik huddi qiymatlik juda qulay foydalanuvchi usuli, ammo huddi bir xil so'zlarning ikkita xil qo'llanmalarini o'zgartiradi, yoki tayyorlik qiymatlar va leksikal stimuliyasiga chegara. Bu usullarda hech qanday qo'llanmalar qo'llanmagan holatlar mavjud emas, va shunday qilib qo'shish imkoniyatini eʼtibor berilmagan, yoki keyin katta leksikal Resource yaratish uchun juda foydalanish mumkin. Koʻrsatilgan, ikkita narsalar orasidagi teng oʻxshash emas. Biz yaqinda ilova qilingan foydalanuvchimizni butun taʼrif qilamiz. Bu birinchi darajadagi katta taʼminlovchi maʼlumot tuzuvlari uchun semantik darajasini yaratish va birinchi darajadagi katta misol uchun bir kichkina narsalarning ajratuvchisi va ikkinchi darajadagi semantik sinfdagi bir necha yo'l bir xil bir necha darajada bir xil bir xil Name Biz bu usulni o'zgartirish uchun polysemik tilni stimulik va oldingi ishdan ko'proq misollarni boshqarish uchun qo'llab keldik. Biz hodisa so'zlarni foydalanamiz, lekin usul boshqa bir qismlarga ishlatishi mumkin. We perform cluster analysis on the data from the first phase and demonstrate how this\njuda umumiy verb manbani yaratishda foydalanishi mumkin. Biz ikkinchi darajada olingan semantik maʼlumotini analyzmaymiz va spatiay ishga tushunadigan huddi xukunalarning imkoniyatlarini yaxshi fikrlash uchun gapiramiz. Biz natijada ma'lumotlar tarkibini aniqlash va o'rganish modellarini tasavvur qilishini ko'rsatdik, semantik bir xil va semantik bir xil vazifalarning ichki vazifalarini o'rganish mumkin. Ko'pchilik, biz ko'proq static so'zlar ichki cheksiz usullarning eng yaqin o'rganishdan oldin o'rganish usullarini ko'proq o'xshash va bir so'zlar va bir qanchalik o'xshash usullardan o'zgartiradi. Moreover, thanks to the data set's vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as 'Heat' or 'Motion.'", 'vi': "Việc nghiên cứu về các mô hình văn hoá học về ngữ pháp văn học thường sử dụng một số hình thức đánh giá nội bộ để đảm bảo các biểu hiện học phản ánh những phán xét theo ngữ nghĩa con người. Xét nghiệm nét phân biệt mẫu giáo là một phương pháp đánh giá phổ biến, nhưng các nỗ lực thường được tập trung vào các phán đoán kép của từ cách cô lập, hoặc giới hạn với các ngữ cảnh cụ thể và các kích thích từ học. Có những giới hạn với các phương pháp này, hoặc không cung cấp bất cứ ngữ cảnh nào cho phán quyết, và do đó phớt lờ sự mơ hồ, hoặc cung cấp các ngữ cảnh án đặc biệt không thể dùng để tạo ra một nguồn ngôn ngữ văn bản lớn hơn. Hơn nữa, sự giống nhau giữa hơn hai mục không được xem xét. Chúng tôi cung cấp một mô tả đầy đủ và phân tích về phương pháp gần đây được đề xuất cho việc xây dựng các tập tin mẫu dữ liệu trên diện rộng mà tạo ra một phân loại theo ngữ động rộng lớn trong giai đoạn đầu tiên, cũng như các phán xét về nét giống nhau nhiều chiều được đưa ra trong lớp ngữ pháp theo đây trong giai đoạn thứ hai. Phương pháp này sử dụng một phương pháp đa sắp xếp không gian được đề xuất trong lĩnh vực thần kinh nhận thức để chụp được các hiệu ứng đa chiều của các kích thích ảnh hưởng. Chúng tôi đã thích nghi phương pháp này để xử lý các chất kích thích ngôn ngữ đa dạng và các mẫu lớn hơn nhiều so với công việc trước. Chúng tôi đặc biệt nhắm vào động từ, nhưng phương pháp có thể cũng áp dụng cho các phần khác của ngôn ngữ. Chúng tôi thực hiện phân tích cụm các dữ liệu từ giai đoạn đầu tiên và chứng minh cách\ncó thể hữu dụng trong việc xây dựng một nguồn từ toàn diện. Chúng tôi cũng phân tích các thông tin ngữ pháp bắt được từ giai đoạn thứ hai và thảo luận về khả năng khả năng của các phán quyết giống nhau lây lan vũ trụ nhằm phù hợp với khái niệm giống nhau từ của con người. Chúng tôi chứng minh cách mà bộ dữ liệu kết quả có thể được dùng cho các phân tích kỹ lưỡng và đánh giá các mô hình học đại diện về các công việc cơ bản của gắn kết theo ngữ nghĩa. Đặc biệt, chúng tôi thấy các phương pháp che đậy chữ còn mạnh hơn thực hiện các biểu hiện ngôn ngữ xuất phát từ các phương pháp trước-huấn luyện gần đây, cả về nét giống nhau trên từ và tụ tập. Hơn nữa, nhờ s ự bao quát bao quát của bộ dữ liệu, chúng ta có thể so sánh lợi ích của việc đặc biệt các biểu tượng vector cho một dạng kiến thức đặc biệt bên ngoài, bằng cách đánh giá gương cấu hình của Bộ khung và Verbit về lĩnh vực ngữ pháp cụ thể như'Heat'hay'Vũ điệu'.", 'nl': 'Abstract Onderzoek naar representatie leermodellen van lexicale semantiek maakt meestal gebruik van een vorm van intrinsieke evaluatie om ervoor te zorgen dat de aangeleerde representaties menselijke semantische oordelen weerspiegelen. Lexische semantische gelijkenisschatting is een veel gebruikte beoordelingsmethode, maar de inspanningen zijn meestal gericht op parenwise oordelen van woorden afzonderlijk, of zijn beperkt tot specifieke contexten en lexicale stimuli. Er zijn beperkingen met deze benaderingen die ofwel geen context bieden voor oordelen, en daardoor dubbelzinnigheid negeren, ofwel zeer specifieke sententiële contexten bieden die dan niet kunnen worden gebruikt om een grotere lexicale bron te genereren. Bovendien wordt de gelijkenis tussen meer dan twee items niet in aanmerking genomen. We bieden een volledige beschrijving en analyse van onze recent voorgestelde methodologie voor grootschalige dataset constructie die een semantische classificatie van een groot steekproef werkwoorden in de eerste fase produceert, evenals multi-way overeenkomsten oordelen gemaakt binnen de resulterende semantische klassen in de tweede fase. De methodologie maakt gebruik van een ruimtelijke multi-arrangement benadering die wordt voorgesteld op het gebied van cognitieve neurowetenschappen voor het vastleggen van multi-way overeenkomsten oordelen van visuele stimuli. We hebben deze methode aangepast om polyemotionele linguïstische stimuli en veel grotere samples aan te pakken dan eerder werk. We richten ons specifiek op werkwoorden, maar de methode kan ook worden toegepast op andere delen van spraak. We voeren clusteranalyse uit op de data uit de eerste fase en tonen aan hoe dit', 'de': 'Die Erforschung von Repr채sentationslernmodellen der lexikalischen Semantik nutzt in der Regel eine Form der intrinsischen Evaluation, um sicherzustellen, dass die erlernten Repr채sentationen menschliche semantische Urteile widerspiegeln. Lexikale semantische 횆hnlichkeitssch채tzung ist eine weit verbreitete Bewertungsmethode, aber die Bem체hungen konzentrierten sich typischerweise auf paarweise getrennte Urteile von W철rtern oder beschr채nken sich auf spezifische Kontexte und lexikalische Reize. Es gibt Einschr채nkungen bei diesen Ans채tzen, die entweder keinen Kontext f체r Urteile bieten und dadurch Ambiguit채t ignorieren, oder sehr spezifische sententiale Kontexte bieten, die dann nicht verwendet werden k철nnen, um eine gr철횩ere lexikalische Ressource zu generieren. Dar체ber hinaus wird die 횆hnlichkeit von mehr als zwei Posten nicht ber체cksichtigt. Wir bieten eine vollst채ndige Beschreibung und Analyse unserer k체rzlich vorgeschlagenen Methodik f체r die Konstruktion von gro횩en Datens채tzen, die eine semantische Klassifizierung einer gro횩en Stichprobe von Verben in der ersten Phase erzeugt, sowie Multi-Way 횆hnlichkeitsbeurteilungen innerhalb der resultierenden semantischen Klassen in der zweiten Phase. Die Methodik verwendet einen r채umlichen Multi-Arrangement-Ansatz, der im Bereich der kognitiven Neurowissenschaften vorgeschlagen wird, um Mehrwege-횆hnlichkeitsbeurteilungen visueller Reize zu erfassen. Wir haben diese Methode angepasst, um polyemotionale linguistische Reize und viel gr철횩ere Stichproben als fr체here Arbeiten zu handhaben. Wir richten uns gezielt auf Verben, aber die Methode kann auch auf andere Teile der Sprache angewendet werden. Wir f체hren Clusteranalysen an den Daten aus der ersten Phase durch und demonstrieren, wie diese', 'hr': 'Abstraktno istraživanje u modelima učenja leksičkih semantika obično koristi neku vrstu unutrašnje procjene kako bi se osiguralo da naučene predstave odražavaju ljudske semantičke osude. Procjenjivanje leksičke semantičke sličnosti je široko korišteni metod procjene, ali napori su se obično fokusirali na pare osuđenja riječi u izolaciji ili ograničeni na specifične kontekste i leksičke stimule. Postoje ograničenja s ovim pristupima koji niti ne pružaju nikakav kontekst za osuđenje, te tako ignoriraju ambiguitet ili pružaju vrlo specifične osjećajne kontekste koje se onda ne mogu koristiti za stvaranje većeg leksičkog resursa. Osim toga, ne smatra se sličnost između više od dvije stvari. Predstavljamo potpuni opis i analizu naše nedavno predložene metodologije za izgradnju velike skale podataka koji proizvodi semantičku klasifikaciju velikog uzoraka verba u prvoj fazi, kao i više način a osuđenja sličnosti koje su donijele u rezultativnim semantičkim klasama u drugoj fazi. Metodologija koristi prostorni multiorganizacijski pristup koji je predložen u oblasti kognitivne neuronauke za uhvativanje suđenja višestruke sličnosti vizuelnog stimula. Prilagodili smo ovu metodu kako bi se bavili polizemnim jezičkim stimulima i mnogo većim uzorcima od prethodnog rada. Posebno ciljamo verbe, ali metod se može jednako primjenjivati na druge dijelove govora. Izvodimo klasterijsku analizu podataka iz prve faze i pokazujemo kako to', 'bg': 'Резюме Изследванията на моделите за изучаване на представителството на лексикалната семантика обикновено използват някаква форма на вътрешна оценка, за да се гарантира, че научените представи отразяват човешките семантични преценки. Лексикалната семантична прилика е широко използван метод за оценка, но усилията обикновено са фокусирани върху двойки преценки на думите изолирано или са ограничени до специфични контексти и лексикални стимули. Съществуват ограничения при тези подходи, които или не осигуряват контекст за преценки и по този начин пренебрегват двусмислеността, или осигуряват много специфични контексти, които не могат да бъдат използвани за генериране на по-голям лексикален ресурс. Освен това не се разглежда сходство между повече от две позиции. Предоставяме пълно описание и анализ на нашата наскоро предложена методология за изграждане на мащабни масиви от данни, която произвежда семантична класификация на голяма извадка глаголи в първата фаза, както и многопосочни решения за сходство, направени в рамките на получените семантични класове във втората фаза. Методологията използва пространствен мулти-аранжиментен подход, предложен в областта на когнитивната неврология за улавяне на многопосочни преценки за сходство на визуалните стимули. Адаптирали сме този метод, за да се справят с многообразни лингвистични стимули и много по-големи проби от предишната работа. Ние конкретно насочваме глаголите, но методът може да се приложи еднакво и към други части на речта. Извършваме клъстерен анализ на данните от първата фаза и демонстрираме как това', 'ko': '어휘의 의미 표징 학습 모델에 대한 연구는 일반적으로 어떤 형식의 내재적인 평가를 채택하여 학습된 표징이 인류의 의미 판단을 반영하도록 확보한다.어휘의 의미 유사도 평가는 광범위하게 사용되는 평가 방법이지만 연구는 고립된 어휘의 대조 판단에 집중되거나 특정한 언어 환경과 어휘 자극에 국한된다.이러한 방법의 한계는 판단어경을 제공하지 않고 잘못된 뜻을 무시하거나 매우 구체적인 문장어경을 제공하지 않으면 더 큰 어휘 자원을 생성하는 데 사용할 수 없다는 데 있다.이 밖에 두 항목 간의 유사성을 고려하지 않는다.우리는 우리가 최근에 제기한 대규모 데이터 집합 구축 방법의 완전한 묘사와 분석을 제공했다. 이 방법은 1단계에서 대량의 동사 견본을 생성하는 의미 분류와 2단계에서 생성된 의미류에서 이루어진 다방면의 유사성 판단을 제공한다.이 방법은 인지신경과학 분야에서 제기한 공간 다중 배열 방법을 이용하여 시각 자극의 다방면 유사성 판단을 포착한다.우리는 이런 방법을 채택하여 다의적 언어의 자극과 이전보다 훨씬 큰 견본을 처리했다.우리는 전문적으로 동사를 겨냥하지만, 이런 방법은 다른 어류에도 적용된다.우리는 1단계의 데이터에 대해 분류 분석을 하고 어떻게', 'id': 'Penelitian Abstrakt ke dalam model pembelajaran representation semantik lexik biasanya menggunakan beberapa bentuk evaluasi intrinsik untuk memastikan bahwa representation belajar merefleksikan penilaian semantik manusia. Perkiraan kesempatan semantis Lexik adalah metode evaluasi yang sering digunakan, tetapi usaha biasanya telah fokus pada penilaian sepasang kata dalam isolasi, atau terbatas pada konteks spesifik dan stimul lexik. Ada batasan dengan pendekatan ini yang sama ada tidak menyediakan konteks apapun untuk penghakiman, dan dengan itu mengabaikan ambigusi, atau menyediakan konteks kalimat yang sangat spesifik yang tidak dapat digunakan untuk menghasilkan sumber daya lexik yang lebih besar. Selain itu, persamaan antara lebih dari dua item tidak dianggap. Kami menyediakan deskripsi penuh dan analisis metodologi kami yang baru-baru ini diusulkan untuk konstruksi set data skala besar yang memproduksi klasifikasi semantis dari sampel besar verb dalam fase pertama, serta penilaian perbedaan berbilang cara yang dibuat dalam kelas semantis hasil dalam fase kedua. Metodologi menggunakan pendekatan multiarranjemen ruang yang diusulkan dalam bidang ilmu saraf kognitif untuk menangkap penilaian kelihatan persamaan stimuli visual. We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work.  Kami secara khusus menargetkan verb, tapi metode dapat sama-sama diterapkan pada bagian lain dari pidato. Kami melakukan analisis kelompok pada data dari fase pertama dan menunjukkan bagaimana ini', 'sw': 'Utafiti utafiti wa kuwakilisha mifano ya kujifunza semantika za lexico mara nyingi hutumia namna fulani ya uchunguzi wa ndani ili kuhakikisha kuwa maoni ya wanafunza yanaonyesha hukumu za kimapenzi za binadamu. Takwimu za simu za Lexico ni njia inayotumiwa sana ya uchunguzi, lakini jitihada za kawaida zimefikia maamuzi mawili ya maneno yanayojitenga, au ni vizuizi vya utafiti maalum na msisimko wa kisaikolojia. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that cannot then be used to generate a larger lexical resource.  Zaidi ya hayo, usawa kati ya vitu viwili vinavyofanana. Tunatoa maelezo kamili na uchambuzi wa mbinu zetu zilizopendekezwa hivi karibuni kwa ajili ya ujenzi wa data makubwa unaotengeneza mchanganyiko wa sekunde wa mifano makubwa ya maneno katika hatua ya kwanza, pamoja na maamuzi yanayofanana na namna mbalimbali yaliyofanywa katika darasa la sekunde la pili. Utawala huu unatumia mbinu za mikakati ya kuandaliwa kwa kiasi kikubwa zilizopendekezwa katika uwanja wa sayansi ya ubongo wa kisasa kwa ajili ya kuchukua maamuzi yanayofanana kwa njia mbalimbali ya msimamo wa kuona. Tumebadilisha mbinu hii ya kukabiliana na mifano makubwa ya lugha mbalimbali kuliko kazi iliyopita. Tunalenga kazi hasa, lakini njia hii inaweza kutumika kwa upande mwingine wa hotuba. Tunafanya uchambuzi wa ubunifu wa taarifa kutoka hatua ya kwanza na kuonyesha jinsi hii', 'da': 'Abstract Forskning i repræsentationslæringsmodeller af leksikalsk semantik bruger normalt en form for iboende evaluering for at sikre, at de lærte repræsentationer afspejler menneskelige semantiske vurderinger. Lexisk semantisk lighedsestimering er en meget udbredt evalueringsmetode, men indsatsen har typisk fokuseret på parvise vurderinger af ord isoleret, eller er begrænset til specifikke sammenhænge og leksikske stimuli. Der er begrænsninger med disse tilgange, der enten ikke giver nogen kontekst for domme og dermed ignorerer tvetydighed, eller giver meget specifikke følelsesmæssige sammenhænge, der ikke kan bruges til at generere en større leksikalsk ressource. Desuden tages der ikke hensyn til lighed mellem mere end to punkter. Vi giver en fuldstændig beskrivelse og analyse af vores nyligt foreslåede metode til konstruktion af store datasæt, der producerer en semantisk klassificering af et stort udvalg af verber i første fase, samt flervejs lighedsvurderinger foretaget inden for de resulterende semantiske klasser i anden fase. Metoden anvender en rumlig multi-arrangement tilgang foreslået inden for kognitiv neurovidenskab til at fange multi-vejs lighedsvurderinger af visuelle stimuli. Vi har tilpasset denne metode til at håndtere polystemøse sproglige stimuli og meget større prøver end tidligere arbejde. Vi målretter specifikt verber, men metoden kan også anvendes på andre dele af talen. Vi udfører klyngeanalyse på data fra første fase og demonstrerer, hvordan dette', 'fa': 'تحقیقات مثبت به مدل یادگیری یادگیری از سیمانتیک\u200cهای زبانی معمولاً برخی از شکل ارزیابی داخلی را استفاده می\u200cکند تا مطمئن شود که نمایش\u200cدهندگان یاد گرفته\u200cاند، قضاوت\u200cهای سیمانتیک انسان را تفسیر می\u200c ارزیابی شبیه\u200cسازی لکسیکی یک روش ارزیابی وسیع استفاده می\u200cشود، ولی تلاش معمولاً بر قضاوت کلمات در تنهایی جفت تمرکز می\u200cکنند، یا محدود به موقعیت\u200cهای ویژه و تحریک\u200cسازی زبانی هستند. محدودیت با این روش\u200cها وجود دارد که یا هیچ محدودیت برای قضاوت را نمی\u200cدهد، و بدین\u200cسان غیر قابلیت را نادیده بگیرد، یا محدودیت\u200cهای محدودیت بسیار خاصی را پیشنهاد می\u200cدهد که بعد از آن نمی\u200cتواند برای تولید یک منبع زبان بزرگ استفاده شود. علاوه بر این، شبیه بین بیش از دو عنصر به نظر نمی رسد. ما یک توضیح کامل و تحلیل از روش پیشنهاد اخیرا برای ساختن مجموعه داده های مقیاس بزرگ که یک نمونه semantic از نمونه های بزرگ کلمات در مرحله اول تولید می\u200cکند، همچنین تصمیم\u200cهای شباهت بیشتری در درجه کلمات semantic در مرحله دوم انجام می\u200cشود. روش\u200cشناسی از طریق بسیاری از ترتیب\u200cهای فضایی که در زمینه علم عصبی شناخته\u200cای پیشنهاد شده است استفاده می\u200cکند برای گرفتن قضاوت\u200cهای شبیه\u200cانگیز چندین طریق از ترتیب\u200cهای بینایی. ما این روش را برای حل تحریک زبان\u200cشناسی و نمونه\u200cهای بسیار بزرگتر از کارهای قبلی تغییر دادیم. ما مخصوصاً کلمات را هدف می\u200cدهیم، ولی این روش می\u200cتواند برابر به بخش\u200cهای دیگر سخنرانی کاربرد شود. ما تحلیل کلاستر روی داده های اولین مرحله انجام می دهیم و نشان می دهیم که چگونه این', 'tr': 'Lektikler semantiklerin öğrenme modellerine karşı abstrakt araştırmalar genelde insan semantik hükümlerini garanti etmek için bazı şekilde içeri girişimleri kullanır. Leksik semantik meňzeşlikler deňlenme yöntemi örän ullanýar, ýöne çabalar adatça ýekeje sözlerniň judgamalarynda üns berilýär ýa-da spesifikleriň we leksiýalyň durumlaryna süýtgedilýär. Şu ýagdaýlar bilen hat-laýyşlar üçin hiç hili kontekst saýlamaýan nusgalar bar we şol sebäpli görkezilmez bolsa, ýada uly bir lingwisiň çeşmesini döretmek üçin ullanyp bilmeýän sözleriň şartlaýyşlary bar. Mundan hem, iki zadan köpüsi arasynda meňzeşlik duýulmaýar. Ýakynda golaý golaý maglumat taýýarlanmasy üçin biziň iň golaý maglumat taýýarlanmasymyzyň doly waspyny we analýşiny berip otyrdyk. Bu ýerde ilkinji fazda semantik sanlaryň uly nusgasyny döretýär, we ikinji fazda multi-ýoly ýaly çykyşlyklar bilen netijeli semantik klaslaryň içine çykyş edilen Bu metodoloji görsel stimüllerin çoklu şekilde meñzeşlikler çözmesi üçin bilinçli nörव bilimi alanında teklif edilen uzay bir çoklu düzenleme metodlarını kullanır. Biz bu yöntemi polizem dil stimullaryny we öňki işden köp örän uly nusgalary çykarmak üçin üýtgedik. Biz hakykatdanam sözleri hedef edip bilýäris, ýöne çykyş başga parçalaryna deňe uygulanabilir. Biz ilkinji fazdan berilen maglumatlar barada cluster analizi çykýarys we muny nädip görkezilýäni görkez', 'hy': 'Լեքսիկական սեմանտիկայի ուսումնասիրության ներկայացման մոդելների վերացական հետազոտությունը սովորաբար օգտագործում է որոշ տեսակի ներքին գնահատականներ, որպեսզի վստահվի, որ սովոր ներկայացումները արտացոլում են մարդկային սեմանտիկ Լեքսիկական սեմանտիկ նմանության գնահատումը լայնորեն օգտագործված գնահատման մեթոդ է, բայց փորձերը սովորաբար կենտրոնացել են բառերի զույգ դատողությունների վրա, կամ սահմանափակվում են որոշակի կոնտեքստների և լեքսիկական խթանների վրա: Այս մոտեցումներում սահմանափակումներ կան, որոնք կամ չեն տրամադրում որևէ կոնտեքստ դատողությունների համար, և դրանով անտեսում են անորոշակիությունը, կամ տրամադրում են շատ հատուկ դատական կոնտեքստներ, որոնք հետո չեն կարող օգտագործվել ավելի մեծ լեքսիկական ռեսուրս Ավելին, երկու առարկաների միջև նմանությունը չհամարվում է: We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase.  Մեթոդոլոգիան օգտագործում է ճանաչողական նյարդաբանության ոլորտում առաջարկված տարածական բազմակառուցման մոտեցումը տեսողական խթանների բազմաուղիղ նման դատողությունների վերցնելու համար: Մենք հարմարեցրել ենք այս մեթոդը, որպեսզի վերահսկենք պոլիսեմային լեզվաբանական խթանները և շատ ավելի մեծ նմուշներ, քան նախորդ աշխատանքը: Մենք հատկապես նշանակում ենք բայերը, բայց մեթոդը նույնպես կարող է կիրառվել խոսքի այլ մասերի վրա: Մենք կատարում ենք խմբերի վերլուծություն առաջին փուլում տեղեկատվության վրա և ցույց ենք տալիս, թե ինչպես է սա', 'af': "Abstrakte Verondersoek binne verteenwoordigheidsverdigheidmodele van leksiese semantieke gebruik gewoonlik sommige vorm van intrinsiese evaluering om te verseker dat die geleerde verteenwoordigheidsverdigheidsverdighede menslike semantiese oordelings reflekteer. Leksiese semantiese gelykheidsestimatie is 'n vaste gebruikte evalueringsmetode, maar versoekte het tipies gefokus op parewyse oordelings van woorde in isolatie, of is beperk na spesifieke kontekste en leksiese stimule. Daar is beperkinge met hierdie toegange wat of nie enige konteks vir oordelings verskaf nie, en daarom ignoreer onbeperheid of verskaf baie spesifieke sentenciele konteks wat dan nie gebruik word om 'n groter leksielike hulpbron te genereer nie. Verder word gelykenis tussen meer as twee items nie aangeneem nie. Ons verskaf 'n volledige beskrywing en analisie van ons onlangs voorgestelde metodologie vir groot-skaal data stel konstruksie wat produseer 'n semantiese klasifikasie van' n groot voorbeeld van verbe in die eerste fase, asook multiweë gelykenigheidsprooiings gemaak binne die resultate semantiese klasse in die tweede fase. Die metodologie gebruik 'n spasielike multi-arrangement toegang wat in die veld van kognitiewe neurosciensie voorgestel is om multiveise gelykenigheidsprooiings van visuele stimule te vang. Ons het hierdie metode aanpas om polisemus lingvisse stimuleer en baie groter voorbeelde te hanteer as vorige werk. Ons spesifieke doel verbe, maar die metode kan gelyk aanwend word na ander dele van spreek. Ons uitvoer klaster analisie op die data van die eerste fase en wys hoe hierdie", 'am': 'ምርመራ ለሌክሲካዊ ስሜንቲካ ማስተማር ምሳሌዎችን በመጠቀም የሚተማሩት መልዕክቶች በሰው የsemantic ፍርድ እንዲያረጋግጡ የሚጠይቅ የውይይት ውይይት ይጠቅማል፡፡ ሌክሲካዊ የsemantic ብጤት መጠቀሚያ በተለይ የተጠቃሚ ማስታወሻ ማድረግ ነው፤ ነገር ግን ተግባራት በተለየ ሁለት ጥበብ ቃላት በተለየ ወይም በተለያዩ ጽሑፎች እና ለሌክሲካዊ ጉዳይ ላይ አካባቢ ነው፡፡ እነዚህ መግለጫ ላይ ግንኙነት አለባቸው ለፍርድ ማድረግ ማድረግ ማድረግ ማድረግ አይችሉም፣ በዚህም ምክንያት ፍላጎታቸውን አይዋሹም፣ ወይም በዚያን ጊዜ የበለጠ የሊክሲካዊ ክፍል ለመፍጠር የማይችል እጅግ የተለየ አስተያየት ውይይቶች አሉ፡፡ ከዚህም በላይ በሁለት ዕቃ መካከል የሚበልጥ ብጤ አይደለም፡፡ የአሁኑን ደረጃ ውስጥ በሁለተኛው ክፍል ውስጥ ለትልቁ ዳታዎች የቃላትን ትልቅ ምሳሌ በሚያሳየው እና በሁለተኛው ክፍል ውስጥ በብዙ መንገዶች የሚመስል ፍርድ እናሳውቃለን፡፡ የባሕላዊ የነዌብ ኢንተርሲ እርሻ ውስጥ ለመዘጋጀት የስፋትያ ብዙዎችን ድርጅት ለመቀበል የሚጠቅመውን የዓይኖችን ብጤት ፍርድ ለመያዝ ነው፡፡ የፖሊስ ቋንቋ ጥምቀት እና የቀድሞው ሥራ የሚበልጠውን ትልቅ ምሳሌዎችን ለመቀበል ይህንን ሥርዓት ሰጥተናል፡፡ በተለየን ቃላት እናስመክራለን፣ የሥርዓት ግን ለሌሎች ንግግር ለመጠቀም ይችላል፡፡ የመጀመሪያው ደረጃዎች ያሉትን ዳራዎችን እናሳየዋለን እንደዚህም እንዴት እንደሆነ እናሳያቸዋለን', 'bs': 'Abstraktno istraživanje u modeli učenja leksičkih semantika obično koristi neku vrstu unutrašnje procjene kako bi se osiguralo da naučene predstave odražavaju ljudske semantičke osude. Procjenjivanje leksičke semantičke sličnosti je široko korišteni metod procjene, ali napori su se obično fokusirali na pare osuđenja riječi u izolaciji, ili su ograničeni na specifične kontekste i leksičke stimule. Postoje ograničenja s ovim pristupima koje ili ne pružaju nikakav kontekst za osude, i tako ignoriraju nesposobnost ili pružaju vrlo specifične sentencijalne kontekste koje se onda ne mogu koristiti za stvaranje većeg leksičkog resursa. Osim toga, ne razmatra se sličnost između više od dvije stvari. Mi pružamo potpuni opis i analizu naše nedavno predložene metodologije za izgradnju velike skale podataka koji proizvodi semantičku klasifikaciju velikog uzoraka verba u prvoj fazi, kao i multicestovnih osuđivanja sličnosti donijenih u rezultativnim semantičkim klasama u drugoj fazi. Metodologija koristi prostorni multiorganizacijski pristup koji je predložen u oblasti kognitivne neuronauke za uhvativanje suđenja sa višestrukim sličnostima vizuelnog stimula. Prilagodili smo ovu metodu da se bavimo polizemnim jezičkim stimulima i mnogo većim uzorcima od prethodnog rada. Posebno ciljamo verbe, ali metod se može jednako primjenjivati na druge dijelove govora. Izvodimo klasterijsku analizu podataka iz prve faze i pokazujemo kako ovo', 'az': 'Leksik semantik öyrənmə modellərinin abstraktlı araştırmaları insanların semantik hökmlərini təsdiqləməsini təsdiqləmək üçün çox istifadə edir. Leksik semantik oxuması geniş istifadə edilən değerlendirmə metodumudur, amma çabalar genellikle isolat sözlərin cüt yargılamalarına odaqlanır, ya da müəyyən müxtəliflərə və leksik stimularına sınırlanır. Bu tərzlərin müəyyən edilməsi üçün heç bir məlumat verməyən və bu tərzlərin məlumatlarını görməyən və ya böyük bir dil ressamı yaratmaq üçün istifadə edilməyən tərzlərin müəyyən edilməsi üçün istifadə edilməyən məlumatları var. Daha sonra, iki nəfərdən daha çox olanların arasındakı bənzəri düşünülməz. Biz son zamanlarda təklif edilmiş çox ölçülü verilən quruluş in şaatının metodolojisinin tamamlanmasını və analizisini təmin edirik ki, ilk fərzində böyük bir verb örneğin in semantik klasifikasyonu və ikinci fərzində müxtəlif semantik sınıfların içində yapılmış çoxlu yollarla bənzər hökmləri təyin edir. Bu metodoloji, görsel stimulunun çoxlu yollarla bənzər şəkillərini tutmaq üçün kognitiv nöroloji sahəsində təklif edilən çoxlu münasibət tərzini istifadə edir. Biz bu metodları çoxlu dil stimuli və əvvəlki işlərdən daha böyük nümunələri idarə etmək üçün uyğunlaşdırdıq. Biz həqiqətən fərqlərə məcburiyyət edirik, amma metod başqa sözlərin başqa parçalarına eyni olaraq istifadə edilə bilər. Biz ilk fəzindən verilənlər barəsində cluster analizi təyin edirik və bunun necə olduğunu göstəririk.', 'sq': 'Kërkimi abstrakt në modelet e përfaqësimit të mësimit të semantikës lexike zakonisht përdorë një form ë vlerësimi brendshëm për të siguruar që përfaqësimet e mësuara të pasqyrojnë gjykimet semantike njerëzore. Vlerësimi i ngjashmërisë lexike semantike është një metodë vlerësimi i përdorur gjerësisht, por përpjekjet tipikisht janë përqëndruar në gjykimet e palëve të fjalëve në izolim, ose janë të kufizuar në kontekste specifike dhe stimule lexike. Ka kufizime me këto qasje që ose nuk ofrojnë asnjë kontekst për gjykimet, dhe kështu injorojnë paqartësinë, ose ofrojnë kontekste shumë të posaçme dënimi që pastaj nuk mund të përdoren për të gjeneruar një burim më të madh lexik. Përveç kësaj, ngjashmëria midis më shumë se dy objekteve nuk konsiderohet. Ne japim një përshkrim të plotë dhe analizë të metodologjisë tonë të propozuar kohët e fundit për ndërtimin e një grupi të dhënash në shkallë të madhe që prodhon një klasifikim semantik të një kampioni të madh verbësh në fazën e parë, si dhe gjykime të ngjashmërisë shumë-drejtore të bërë brenda klasave rezultuese semantike në fazën e dytë. Metodologjia përdor një qasje hapësire me shumërregullime propozuar në fushën e neuroshkencës kognitive për të kapur gjykime të ngjashmërisë shumëdrejtore të stimujve vizualë. Kemi përshtatur këtë metodë për të trajtuar stimulet gjuhësore polisemore dhe mostra më të mëdha se punët e mëparshme. Ne specifikisht synojmë verbët, por metoda mund të aplikohet në mënyrë të barabartë në pjesë të tjera të fjalimit. Ne kryejmë analizën e grupeve mbi të dhënat nga faza e parë dhe demonstrojmë se si kjo', 'et': 'Leksikaalsemantika representatsiooniõppe mudelite uurimine kasutab tavaliselt mingit sisemise hindamise vormi, et tagada, et õppitud representatsioonid peegeldavad inimese semantilisi otsuseid. Lexikaalse semantilise sarnasuse hindamine on laialdaselt kasutatav hindamismeetod, kuid jõupingutused on tavaliselt keskendunud sõnade paarihinnangule eraldi või piirduvad konkreetsete kontekstide ja leksikaalsete stiimulitega. Nende lähenemisviiside puhul on piiranguid, mis kas ei paku kohtuotsustele konteksti ja seega eiravad ebaselgust või pakuvad väga spetsiifilisi sentimentaalseid kontekste, mida ei saa kasutada suurema leksikaalse ressursi loomiseks. Lisaks ei võeta arvesse enam kui kahe kirje sarnasust. Anname täieliku kirjelduse ja analüüsi meie hiljuti väljapakutud metoodikast suuremahuliseks andmekogumikuks, mis annab esimeses etapis suure tegusõnade valimi semantilise klassifikatsiooni ning teises etapis saadud semantilistes klassides tehtud mitmesuunalise sarnasuse otsused. Metoodikas kasutatakse kognitiivse neuroteaduse valdkonnas pakutud ruumilist multipaigutuslikku lähenemisviisi visuaalsete stiimulite mitmesuunaliste sarnasuse hinnangute jäädvustamiseks. Oleme kohandanud seda meetodit, et käsitleda polüseemseid keelelisi stiimuleid ja palju suuremaid proove kui varasemad tööd. Me suuname spetsiaalselt tegusõnadele, kuid meetodit saab võrdselt rakendada ka teistele kõneosadele. Teeme klastrianalüüsi esimese etapi andmete põhjal ja näitame, kuidas', 'fi': 'Leksikaalisen semantiikan representaatiooppimismallien tutkimus käyttää yleensä jonkinlaista sisäistä arviointia varmistaakseen, että opitut representaatiot heijastavat ihmisen semanttisia arvioita. Lexical semantic similarity estimointi on laajalti käytetty arviointimenetelmä, mutta pyrkimykset ovat tyypillisesti keskittyneet sanojen pareittain arviointiin yksinään tai rajoittuneet tiettyihin konteksteihin ja leksikaalisiin ärsykkeisiin. Näillä lähestymistavoilla on rajoituksia, jotka joko eivät tarjoa mitään kontekstia tuomioille ja siten sivuuttavat epäselvyyttä tai tarjoavat hyvin erityisiä sententiaalisia konteksteja, joita ei sitten voida käyttää suuremman sanaston luomiseen. Lisäksi ei oteta huomioon useamman kuin kahden erän samankaltaisuutta. Tarjoamme kattavan kuvauksen ja analyysin hiljattain ehdotetusta menetelmästämme laajamittaiseen tietoaineiston rakentamiseen, joka tuottaa semanttisen luokituksen suuresta verbinäytteestä ensimmäisessä vaiheessa sekä monisuuntaisia samankaltaisuusarviointeja, jotka on tehty tuloksena olevien semanttisten luokkien sisällä toisessa vaiheessa. Menetelmässä hyödynnetään kognitiivisen neurotieteen alalla ehdotettua spatiaalista monimuotoista lähestymistapaa visuaalisten ärsykkeiden monisuuntaisen samankaltaisuuden arviointien kuvaamiseen. Olemme mukauttaneet tätä menetelmää käsittelemään monikielisiä kielellisiä ärsykkeitä ja paljon suurempia näytteitä kuin aikaisempi työ. Kohdistamme erityisesti verbejä, mutta menetelmää voidaan soveltaa myös muihin puheen osiin. Teemme klusterianalyysin ensimmäisestä vaiheesta lähtien ja osoitamme, miten tämä', 'ca': "La investigació abstracta sobre els models d'aprenentatge de representació de la semàntica lèxica normalment utilitza alguna forma d'evaluació intrínseca per assegurar que les representacions aprengutes reflexionin els judicis semàntics humans. L'estimació de la similitud semàntica lèxica és un mètode d'evaluació generalment utilitzat, però els esforços s'han centrat típicament en judicis parells de paraules en a ïllament, o estan limitats a contextes específics i estímuls lexics. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that cannot then be used to generate a larger lexical resource.  A més, no es considera la similitud entre més de dos objectes. Oferecem una descripció i anàlisi completas de la nostra metodologia proposada recentment per a la construcció de conjunts de dades a gran escala que produeix una classificació semàntica d'una gran mostra de verbs en la primera fase, així com els judicis de similitud multidireccionals fets en les classes semàntiques resultants en la segona fase. La metodologia utilitza un enfocament de multiarreglament espacial proposat en el camp de la neurociència cognitiva per capturar judicis de similitud multidireccionals d'estímuls visuals. Hem adaptat aquest mètode per gestionar estímuls lingüístics polisemosos i mostres molt més grans que la feina anterior. Mirem específicament els verbs, però el mètode pot ser aplicat igualment a altres parts de la fala. Fem una anàlisi de grups sobre les dades de la primera fase i demostrem com això", 'bn': 'লেক্সিক্সিক্যাল সেম্যান্টিক্সের প্রতিনিধিত্ব শিক্ষা মডেলে গবেষণা ব্যবহার করে যাতে শিক্ষিত প্রতিনিধিত্বের প্রতিনিধিত্বের কি লেক্সিক্সিক্যাল সেম্যান্টিক সমতুল্য হিসাব ব্যবহার করা একটি ব্যাপক মুল্যায়ন পদ্ধতি, কিন্তু প্রচেষ্টা সাধারণত বিচারের প্রতি প্রচেষ্টা সাধারণত একাক্ এই পদ্ধতিগুলোর মধ্যে সীমাবদ্ধ রয়েছে যারা বিচারের কোন প্রতিক্রিয়া প্রদান করে না এবং এর ফলে তাদের বিচার উপেক্ষা করে না অথবা অনেক বিশেষ প্রতিক্রিয়া প্রদা তাছাড়াও, দুই জিনিসের মধ্যে একই রকম বিবেচনা করা যায় না। আমরা সম্প্রতি আমাদের প্রস্তাবিত পদ্ধতির সম্পূর্ণ বর্ণনা এবং বিশ্লেষণ দিয়েছি বিশাল তথ্য নির্মাণের জন্য যা প্রথম ক্ষেত্রে একটি বিশাল কার্যকলাপের সামান্য ক্লাস তৈরি করে, আর দ্বিত এই পদ্ধতিটি দৃশ্য উৎসাহের অনুরূপ বিচারের জন্য প্রস্তাবিত একটি স্পেসিয়াল বহুবিধান প্রযুক্তি ব্যবহার করে। আমরা পূর্ববর্তী কাজের চেয়ে বহুসাধারণ ভাষার উৎসাহ এবং অনেক বড় ধরনের উদাহরণ প্রদান করেছি। আমরা বিশেষ করে শব্দগুলোকে লক্ষ্য করি, কিন্তু এই পদ্ধতি বাক্যের অন্যান্য অংশে প্রয়োগ করতে পারে। আমরা প্রথম পর্যায়ের তথ্য সম্পর্কে ক্লাস্টার বিশ্লেষণ করি এবং প্রদর্শন করি কিভাবে', 'cs': 'Abstrakt Výzkum reprezentačních učebních modelů lexikální sémantiky obvykle využívá určitou formu vnitřního hodnocení, aby se zajistilo, že učené reprezentace odrážejí lidské sémantické úsudky. Lexický odhad sémantické podobnosti je široce používaná hodnotící metoda, ale úsilí se obvykle zaměřuje na párové posuzování slov izolovaně, nebo je omezeno na specifické kontexty a lexikální stimuly. Existují omezení těchto přístupů, které buď neposkytují žádný kontext pro úsudky, a tím ignorují nejednoznačnost, nebo poskytují velmi specifické sententiální kontexty, které pak nelze použít k vytvoření většího lexikálního zdroje. Kromě toho se nezvažuje podobnost více než dvou položek. Poskytujeme kompletní popis a analýzu naší nedávno navržené metodiky pro konstrukci rozsáhlých datových sad, která vytváří sémantickou klasifikaci velkého vzorku slovesa v první fázi, stejně jako vícesměrné posouzení podobnosti provedené v rámci výsledných sémantických tříd ve druhé fázi. Metodika využívá prostorový multi-uspořádání přístupu navržený v oblasti kognitivní neurovědy pro zachycení multi-cestných hodnocení podobnosti vizuálních stimulů. Tuto metodu jsme přizpůsobili tak, aby zvládli polyemozní jazykové stimuly a mnohem větší vzorky než předchozí práce. Konkrétně se zaměřujeme na slovesa, ale metodu lze aplikovat i na jiné části řeči. Provádíme klastrovou analýzu dat z první fáze a ukážeme, jak to', 'jv': 'absolute Search text-tool-action error-console-action politenessoffpolite"), and when there is a change ("assertivepolite"), and when there is a change ("assertivepolite"), there is a change ("assertive Awak dhéwé nggawe akeh perusahaan karo haléné sampek karo hal-hal ngono nggawe sistem sing gawe nggawe sistem podhak dhéwé kuwi nggawe sistem kaya sistem sing gawe lanjut sematik pentar nggawe sistem sing dibenalke perusahaan anyar sampek bantuan, lan akeh podhake multi-wegian sampek deweke nggawe diuwisan sematik iki bakal mr Metotologi gambar sistem kawit perusahaan langgar sampek multi-arangan sing jewis biasane nêmên ning kaya pating denis-jinês kuwi nggawe geraksi perusahaan langgar sampek multi-maneh sing apik têmên. Awak dhéwé éntuk nggunaké iki dadi kanggo ngerasakno polisemus neng sampuran sing luwih apik karo nggawe layanan. section Awak dhéwé ngerti dadi perusahaan karo akeh basa sak ngono bisalahan piye cara ngono iki\npodho iso ngawe barang nggawe winih sing perbudhakan winih akeh dumadhi Awak dhéwé énêmên ngerasakno perusahaan semanti kartané karo hal iki dadi, nik nggawe perusahaan kowé nggawe geraksé perusahaan karo hal-kara yênêmêr iki luwih apik dhéwé. Awak dhéwé éntuk pisan kelas kuwi nggawe dadi wis nggawe kanggo nyebuté nggawe jiné-jiné karo cara-jiné nggawe model kuwi nggawe barang kelas kuwi duluran semantar clustering lan semantar sampeyan winih. Awak dhéwé, kita nglanggar pada akeh statik saben nggambar pada basa luwih panelusuran Nambah, misara data set\'s basa Coverage, kita iso nggawe nyimpen perusahaan bener de vector nggawe layakno sing perusahaan winih dhéwé nggawe layakno sing nyimpen karo nggawe frame net- lan Verbnet-retofferte model nang semanti dumain sing dibuté kaya \'Hot\' lan \'Moton\'', 'ha': "Yana amfani da wasu irin haƙƙin a cikin littafin da aka sanar da shi, kuma ana yi amfani da shi a cikin muhimmada, dõmin ya yi amfani da cewa masu fassarar da aka sanar su su yi fassarar da hukuncin mutane. Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli.  Kuna ƙunsa da waɗannan hanyõyin su ko kuwa ba su ga wani muhimma wa masu yin hukunci ba, kuma sai su ƙẽtare damu da shi, ko kuma su gaura muhimmada masu ƙayyade matsayin da ba za'a iya amfani da shi ba dõmin a ƙara wata resource mai kifi. Furan, ba'a ƙaddara daidaita tsakanin abun biyu ba. Mu bãyar da rabo cikakken, da Anarari na hanyoyinmu na da aka buƙata, a cikin shirin tsarin data masu girma, wanda ke iya samar da shi na semantic-sami mai girma na verbs cikin fasa na farko, da kuma masu yin hukunci masu daidaita da multi-hanya da aka aikata a cikin fassaran semantic na ƙarami. Taimaki yana amfani da wata hanyoyi mai multi-juyi wanda aka buƙata a cikin field da kan neuro na kognitive dõmin ka kãma hukuncin masu daidaita na masu gani. Mun sami wannan hanyon da za'a yi amfani da misãlai masu ƙaranci na misãlai na zaman aikin. Tuna ƙayyade kunnufi masu amfani da, kuma amma, metoden za'a iya amfani da shi daidai zuwa masu sunan faɗi. Munã samar anayyar ƙareta kan data daga fasa na farko kuma ke nuna jinin wannan\nIna kasa da amfani a cikin kuɓutar da wani rayi na kamwai. Ana yi anayyar da laban lãbãri na sambawa da aka kãma fasa na ƙara na biyu kuma Muke yi jayayya da mataimaki ga masu iya gabatar da gareshi masu daidaita da takarda da spatse dõmin su yi mafiya fassarar fanikin mutum da kalmar da ke daidaita. Tuna nũna yadda za'a iya amfani da fassarar data a kan Analai mai kyau-grafi da evaluation da misãlai masu motsi da aka sanar da su a kan aikin da ke cikin na ƙari na ƙaranci da kamata. Kayyai, munã gane, lalle ne mafi tsananin kalma mai embedded metode sun fi ƙaranci masu motsi na leksisi wanda ke fita daga metoden mafunci na farko, duka kan magana-leveli daidaita kuma ta ƙare. Za kuma, game da tsarin bayani na tsarin data, za mu iya daidaita amfani da masu tsari na masu ƙayyade masu shiryuwa na shiryarwa wa masu ƙayyade wa masu husika wa masu sani na masu tsari wa masu tsakanin shiryarwa don a ƙayyade nau'in da za'a iya ƙayyade misãlai na FrameNet- da VerbNet-retrofitted misãlai masu hushi, kamar 'Kifi' ko 'Motion'.", 'sk': 'Raziskave modelov reprezentacijskega učenja leksikalne semantike običajno uporabljajo neko obliko notranje vrednotenje, da se zagotovi, da učene reprezentacije odražajo človeške semantične presoje. Vrednotenje lexikalne semantične podobnosti je pogosto uporabljena metoda vrednotenja, vendar se prizadevanja običajno osredotočajo na pare presoje besed ločeno ali so omejene na določene kontekste in leksikalne dražljaje. Pri teh pristopih obstajajo omejitve, ki bodisi ne zagotavljajo nobenega konteksta za sodbe in s tem ignorirajo dvoumnost ali pa zagotavljajo zelo specifične kontekste sententiala, ki jih nato ni mogoče uporabiti za ustvarjanje večjega leksikalnega vira. Poleg tega se podobnost med več kot dvema postavkama ne upošteva. Predstavljamo popoln opis in analizo naše nedavno predlagane metodologije za gradnjo obsežnih podatkovnih nizov, ki proizvaja semantično klasifikacijo velikega vzorca glagolov v prvi fazi, kot tudi večsmernih podobnih sodb znotraj nastalih semantičnih razredov v drugi fazi. Metodologija uporablja prostorski multi-ureditveni pristop, predlagan na področju kognitivne nevroznanosti za zajemanje večsmernih podobnosti vizualnih dražljajev. To metodo smo prilagodili ravnanju s poličnimi jezikovnimi dražljaji in veliko večjimi vzorci kot prejšnje delo. Posebej ciljamo glagole, vendar se metoda lahko uporablja tudi za druge dele govora. Izvajamo analizo grozdov na podatkih iz prve faze in prikazujemo, kako\nLahko bi bila koristna pri gradnji celovitega glagolnega vira. Analiziramo tudi semantične informacije, zajete v drugi fazi, in razpravljamo o možnostih prostorsko induciranih sodb o podobnosti, da bolje odražajo človeške pojme podobnosti besed. Prikazujemo, kako je mogoče rezultatni nabor podatkov uporabiti za natančne analize in vrednotenje modelov reprezentacijskega učenja o intrinzičnih nalogah semantičnega grozdja in semantične podobnosti. Zlasti ugotavljamo, da močnejše statične metode vključevanja besed še vedno presegajo leksikalne reprezentacije, ki se pojavljajo iz novejših metod pred usposabljanjem, tako pri podobnosti na ravni besed kot gručenju. Poleg tega lahko zaradi obsežne pokritosti nabora podatkov primerjamo prednosti specializiranih vektorskih predstavitev za določeno vrsto zunanjega znanja z ocenjevanjem modelov FrameNet in VerbNet, naknadno opremljenih na specifičnih semantičnih področjih, kot sta "Heat" ali "Motion".', 'he': "מחקר אוסטרקטי בנוגע למדלים לימודים מייצגים של סמנטיקה לקסיקה בדרך כלל משתמש בצורה מסוימת של עריכה פנימית כדי להבטיח שהמייצגים הלמדים משקפים שיפוטים סמנטיים אנושיים. הערכת דמיון סמנטית לקסית היא שיטת הערכה משתמשת רחבה, אך המאמצים התמקדו בדרך כלל על שיפוטים בין זוגות של מילים בבודדות, או מוגבלות לתקשרים ספציפים וגרימים לקסיים. ישנם מגבלות עם גישות אלה שאולי לא מספקים שום קשר לשיפוטים, ולכן מתעלמים מאין ספציפיות, או מספקים קשרים משפטיים מאוד ספציפים שאי אפשר להשתמש בהם כדי ליצור משאב לקסיקלי גדול יותר. חוץ מזה, דמיון בין יותר משני פריטים לא נחשב. אנו מספקים תיאור מלא ונבחן של המתודליות המוצעת לאחרונה שלנו לבניית קבוצת נתונים בקנה מידה גדולה שמוצרת שיעור סמנטי של דגימה גדולה של פעולים בשלב הראשון, כמו גם שיפוטים דומים רבים שנעשו בתוך השיעורים הסמנטיים הנוצאים בשלב השני. המטדולוגיה משתמשת בגישה מרובה-ארגון שטחי שהצעה בשטח הנוירומדעים הקיוניטיביים כדי לתפוס שיפוטים דומים מרובים של גירוי ויזואלי. התאמנו את השיטה הזאת כדי לטפל בזריעות שפתיים פוליזמיות ודגימות הרבה יותר גדולות מהעבודה הקודמת. אנו במיוחד מטרידים אלברים, אבל השיטה יכולה להיות משוממת לחלקים אחרים של דיבור. אנחנו מבצעים ניתוח קבוצה על הנתונים מהשלב הראשון ולהראות איך זה\nעשויים להיות שימושיים בבניית משאב מלא מילים. We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity.  We demonstrate how the resultant data set can be used for fine-grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and semantic similarity.  במיוחד, אנו מוצאים ששיטות קישום מילים סטטיות חזקות עדיין מעליות מייצגות לקסיות שמוצאות משיטות קודמות לאימונים האחרונות יותר, גם על דמיון רמה מילים וגם על התעסקות. חוץ מזה, תודות לכיסוי העצום של קבוצת הנתונים, אנחנו מסוגלים לשוות את היתרונות של ייצוגי ווקטורים מיוחדים לסוג מסוים של ידע חיצוני על ידי הערכה של דוגמנים מוצפנים של FrameNet ו VerbNet על שטחים סמנטיים מסוימים כמו 'חום' או 'תנועה'.", 'bo': "ལག་ལེན་པའི་སྔོན་ལྟའི་རྣམ་པ་སྟོན་པའི་མིག་གཟུགས་རིས་ཀྱི་དཔེ་གཞི་ཚོགས་ཀྱི་ནང་འཁོད་གྱི་དཔེ་གཞི་ལྟར་བྱེད་ཀྱི་ལས་འཆར་བརྗོད་བྱེད་ན་ཕལ་ འདྲ་རྒྱ་ལྟར་མཉམ་དུ་ཕལ་ཆེར་རྩིས་བ་ནི་ཕལ་ཆེར་ཐབས་ཤིག་རེད། ཕན་ཚུལ་འདི་དག ད་དུང་། རྣམ་གྲངས་གཉིས་ལས་བར་དོན་གཉིས་དབར་གྱི་ལྟ་བུ་མི་རེད། We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase. ཐབས་ལམ་ལུགས་དེ་ལ་སྤྱོད་པའི་བར་སྟོང་ཆེ་བའི་ཐབས་ལམ་སྤྱོད་མཁན་གྱི་གནས་སྟངས་སྣ་ཚོགས་ཀྱི་མཐུན་རྐྱེན་གྱིས་དམིགས་བསལ་བ་སྤྱོད་ཡོད། We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work. ང་ཚོས་དམིགས་འབེབས་ཀྱི་བྱ་ཚིག་དམིགས་ཡུལ་བྱས་པ་ཡིན་ནའང་ཕྱོགས་ཀྱི་ཆ་ཤས་གཞན་ཞིག་ལ ང་ཚོས་དང་པོའི་གོ་རིམ་ནང་ནས་གནད་མེད་པའི་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡིག་ཆ་ནང་ནས་\nལྟ་བུའི་ཐོག་ཁུངས་ཤིག་ཡོད་པའི་བཟོ་བརྩིས་ཡོད་སྟོན་པ་ཞིག་ཡིན་སྲིད། ང་ཚོས་ཀྱང་རང་ཉིད་ཀྱི་ཕྱོགས་གཉིས་པ་དེ་གིས་བགོ་སྐབས་ཆའི་ཆ་འཕྲིན་དེ་ཞིབ་དཔྱད་བྱས་ནས། འཛམ་གླིང་ནང་གི་གོ་སྐབས་འགའ་བ་གཉིས་པ་དེ་ ང་ཚོས་གནད་ཅིག་ཞིབ་བཤེར་བྱེད་པའི་ནང་འཁོད་བྱས་པའི་ཆ་འཕྲིན་གྱི་གནད་སྡུད་ཚན་དག་གི་ལག་ལེན་འཐབ ང་ཚོས་ཁྱད་པར་དུ་མཐོང་ཐུབ་པའི་བརྡ་སྟོན་པ་ཁག་གི་ཐ་སྙད་ནང་ལས་གནས་ཚུལ་མཐུན་གྱི་ཐབས་ལམ་དང་མཐུན་སྣེ་ཚོགས་ལས་མཐོང་བ་རེད། Moreover, thanks to the data set's vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as 'Heat' or 'Motion'."}
{'en': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'ar': 'المناهج العصبية الخاضعة للإشراف وغير الخاضعة للإشراف لقراءة النص', 'fr': 'Approches neuronales supervisées et non supervisées de la lisibilité', 'pt': 'Abordagens neurais supervisionadas e não supervisionadas para legibilidade de texto', 'es': 'Enfoques neuronales supervisados y no supervisados para la legibilidad del texto', 'ja': 'テキストの読みやすさに対する監督された、監督されていないニューラルアプローチ', 'zh': '文本可读性监无监神经法', 'hi': 'पाठ पठनीयता के लिए पर्यवेक्षित और असुरक्षित तंत्रिका दृष्टिकोण', 'ru': 'Контролируемые и неконтролируемые нейронные подходы к читаемости текста', 'ga': 'Cur Chuige Néaracha Maoirsithe agus Neamhmhaoirsithe maidir le hInléiteacht Téacs', 'ka': 'ტექსტის კითხვა შესაძლებლობა', 'el': 'Εποπτευόμενες και μη εποπτευόμενες Νευρικές Προσεγγίσεις στην αναγνωσιμότητα Κειμένου', 'hu': 'A szöveg olvashatóságának felügyelet nélküli és felügyelet nélküli idegi megközelítései', 'it': 'Approcci neurali supervisionati e non supervisionati alla leggibilità dei testi', 'lt': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'kk': 'Мәтінді оқу мүмкіндігіне бақылау және сақталмаған нейрондық қатынау', 'ms': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'mk': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'ml': 'പദാവലിയുടെ സാഹചര്യത്തിലേക്കുള്ള നെയുറല്\u200d സമീപത്തിലേക്ക് പ്രത്യേകിച്ചും നിരീക്ഷിക്കപ്പെ', 'mt': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'mn': 'Текст унших боломжтой мэдрэлийн ойлголт', 'no': 'Overvakt og usikkert neuraltilnærmingar til lesabilitet for tekst', 'pl': 'Nadzorowane i nienadzorowane neuronowe podejście do czytelności tekstu', 'ro': 'Abordări neurale supravegheate și nesupravegheate în ceea ce privește lizibilitatea textelor', 'sr': 'Nadzoreni i neodređeni neiralni pristup čitljivosti teksta', 'so': 'Dhacdooyinka Neural ee la ilaaliyo iyo maamulka', 'si': 'පරීක්ෂණා කරලා පාළුවට පාළුවන් කියවන්න පුළුවන් සහ නිර්භාවිත නිර්භාවිතය', 'sv': 'Övervakade och icke övervakade neurala tillvägagångssätt för textläsbarhet', 'ur': 'متن پڑھنے کے قابل تحقیق اور غیرقابل تحقیق', 'ta': 'கண்காணிக்கப்படாத மற்றும் கண்காணிக்கப்படாத நெயுரல் உரை சாத்தியமுள்ளது', 'uz': 'Comment', 'vi': 'Tiếp cận thần kinh giám sát và không giám sát', 'nl': 'Toezichthoudende en niet-begeleide neurale benaderingen van tekstleesbaarheid', 'hr': 'Nadzirani i neodržani neurološki pristup čitljivosti teksta', 'bg': 'Наблюдавани и неконтролирани неврални подходи към четливостта на текста', 'da': 'Overvågede og ukontrollerede neurale tilgange til tekstlæsbarhed', 'id': 'Pendekatan Neural yang Diperhatikan dan Tidak Diperhatikan Keadaan Teks', 'de': 'Überwachte und unbeaufsichtigte neuronale Ansätze zur Lesbarkeit von Texten', 'ko': '텍스트 가독성 감독과 비감독 신경 방법', 'fa': 'دسترسی عصبی تحت نظر و حفاظت غیرقابل خواندن متن', 'sq': 'Përqafimet neuronale të mbikqyrura dhe të pazgjidhura ndaj lexueshmërisë së tekstit', 'tr': 'Gözlemýän we gaýd etmeýän neiral arkalanmalar', 'sw': 'Imetolewa na zisizothibitishwa na Neural Kuelekea Huduma ya Maandishi', 'af': 'Besigtig en Ononderwerpende Neurale toegang na Teks Leesbaarde', 'hy': 'Նյարդային մոտեցումները տեքստի կարելի է դիտարկել', 'am': 'Supervised and Unsupervised Neural Approaches to Text Readability', 'az': 'M톛tn oxuya bil톛c톛yi n칬ral Yax캼nl캼qlar캼n캼 g칬zl톛yir v톛 g칬zl톛m톛y톛n N칬ral Yax캼nl캼qlar캼', 'bn': 'টেক্সট প্রত্যাবর্তনযোগ্যতার সাথে সার্ভারভিস্ট এবং অনভারল নিউরাল প্রাকদর্শন', 'bs': 'Nadzoreni i neodržani neuroni pristupi čitljivosti teksta', 'et': 'Järelevalve all olevad ja järelevalveta neuroalsed lähenemisviisid teksti loetavusele', 'ca': 'Pròpies neuronals supervisats i no supervisats a la llegibilitat del text', 'cs': 'Dohlížené a nekontrolované neuronové přístupy k čitelnosti textu', 'fi': 'Valvottu ja valvomaton tekstin luettavuuteen liittyvä hermolähestymistapa', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Nadzorovani in nenadzorovani živčni pristopi k berljivosti besedila', 'ha': 'KCharselect unicode block name', 'he': 'גישות נוירוליות מושגת ולא מושגת לקריאות טקסט', 'bo': 'ལྟ་རྟོག་པ་དང་སྲུང་སྐྱོད་མེད་པའི་Neural Approach'}
{'en': 'Abstract We present a set of novel neural supervised and unsupervised approaches for determining the readability of documents. In the unsupervised setting, we leverage neural language models, whereas in the supervised setting, three different neural classification architectures are tested. We show that the proposed neural unsupervised approach is robust, transferable across languages, and allows adaptation to a specific readability task and data set. By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to readability, which in most cases still rely on extensive feature engineering, and propose possibilities for improvements.', 'ar': 'الملخص نقدم مجموعة من الأساليب العصبية الجديدة الخاضعة للإشراف وغير الخاضعة للإشراف لتحديد قابلية قراءة المستندات. في الإعداد غير الخاضع للإشراف ، نستفيد من نماذج اللغة العصبية ، بينما في الإعداد الخاضع للإشراف ، يتم اختبار ثلاثة هياكل تصنيف عصبية مختلفة. نظهر أن النهج العصبي المقترح غير الخاضع للإشراف قوي ، ويمكن نقله عبر اللغات ، ويسمح بالتكيف مع مهمة قراءة ومجموعة بيانات محددة. من خلال المقارنة المنهجية للعديد من البنى العصبية على عدد من المعايير القياسية ومجموعات بيانات قابلية القراءة ذات العلامات الجديدة بلغتين ، تقدم هذه الدراسة أيضًا تحليلًا شاملاً للنهج العصبية المختلفة لتصنيف قابلية القراءة. نكشف عن نقاط قوتهم وضعفهم ، ونقارن أداءهم بأحدث مناهج التصنيف الحالية لقابلية القراءة ، والتي لا تزال تعتمد في معظم الحالات على هندسة الميزات الشاملة ، ونقترح إمكانيات للتحسين.', 'pt': 'Resumo Apresentamos um conjunto de novas abordagens neurais supervisionadas e não supervisionadas para determinar a legibilidade de documentos. Na configuração não supervisionada, aproveitamos os modelos de linguagem neural, enquanto na configuração supervisionada, três arquiteturas de classificação neural diferentes são testadas. Mostramos que a abordagem neural não supervisionada proposta é robusta, transferível entre linguagens e permite adaptação a uma tarefa específica de legibilidade e conjunto de dados. Pela comparação sistemática de várias arquiteturas neurais em vários conjuntos de dados de legibilidade de referência e novos rotulados em duas linguagens, este estudo também oferece uma análise abrangente de diferentes abordagens neurais para classificação de legibilidade. Expomos seus pontos fortes e fracos, comparamos seu desempenho com as atuais abordagens de classificação de última geração para legibilidade, que na maioria dos casos ainda dependem de extensa engenharia de recursos e propomos possibilidades de melhorias.', 'es': 'Resumen Presentamos un conjunto de novedosos enfoques neuronales supervisados y no supervisados para determinar la legibilidad de los documentos. En el entorno no supervisado, aprovechamos los modelos de lenguaje neuronal, mientras que en el entorno supervisado, se prueban tres arquitecturas de clasificación neuronal diferentes. Demostramos que el enfoque neuronal no supervisado propuesto es sólido, transferible entre idiomas y permite la adaptación a una tarea de legibilidad y un conjunto de datos específicos. Mediante la comparación sistemática de varias arquitecturas neuronales en una serie de datos de referencia y nuevos conjuntos de datos de legibilidad etiquetados en dos idiomas, este estudio también ofrece un análisis integral de diferentes enfoques neuronales para la clasificación de la legibilidad. Exponemos sus fortalezas y debilidades, comparamos su rendimiento con los enfoques actuales de clasificación de vanguardia para la legibilidad, que en la mayoría de los casos todavía se basan en una amplia ingeniería de funciones, y proponemos posibilidades de mejora.', 'fr': "Résumé Nous présentons un ensemble de nouvelles approches neuronales supervisées et non supervisées pour déterminer la lisibilité des documents. Dans le cadre non supervisé, nous exploitons des modèles de langage neuronal, tandis que dans le cadre supervisé, trois architectures de classification neuronale différentes sont testées. Nous montrons que l'approche neuronale non supervisée proposée est robuste, transférable entre les langues et permet une adaptation à une tâche de lisibilité et à un ensemble de données spécifiques. En comparant systématiquement plusieurs architectures neuronales sur un certain nombre d'ensembles de données de référence et de nouveaux ensembles de données de lisibilité étiquetés en deux langues, cette étude propose également une analyse complète des différentes approches neuronales de la classification de lisibilité. Nous exposons leurs forces et leurs faiblesses, comparons leurs performances aux approches de classification de pointe actuelles en matière de lisibilité, qui dans la plupart des cas reposent encore sur une ingénierie complète des fonctionnalités, et proposons des possibilités d'amélioration.", 'ja': '要約私たちは、文書の可読性を決定するための新規のニューラル監視および監視されていないアプローチのセットを提示します。監督されていない場面では、私たちは神経言語モデルを活用しますが、監督されている場面では、3つの異なる神経分類アーキテクチャがテストされます。提案されているニューラル・アプローチは、堅牢であり、言語間で転送可能であり、特定の可読性タスクとデータセットへの適応を可能にすることを示しています。この研究は、2つの言語のいくつかのベンチマークおよび新しいラベル付けされた可読性データセットに関するいくつかのニューラルアーキテクチャの体系的な比較を行うことにより、可読性分類へのさまざまなニューラルアプローチの包括的な分析も提供する。私たちは、それらの長所と短所を明らかにし、それらのパフォーマンスを、ほとんどの場合まだ広範な機能工学に依存している可読性に対する現在の最先端の分類アプローチと比較し、改善の可能性を提案します。', 'zh': '摘要建定文档可读性新型神经督无监督之法。 于无监之中,因神经言模形,而于监境之中,试三神经之类架构。 臣等明神经无监督之法为健,可跨语移,并许应特定可读性数集。 两言多准可读性数集上之神经架构,本究可读性类之异神经备矣。 表其善恶,校其先进可读性类,犹赖广功,而更进其能。', 'hi': 'सार हम दस्तावेजों की पठनीयता को निर्धारित करने के लिए उपन्यास तंत्रिका पर्यवेक्षित और असुरक्षित दृष्टिकोणों का एक सेट प्रस्तुत करते हैं। असुरक्षित सेटिंग में, हम तंत्रिका भाषा मॉडल का लाभ उठाते हैं, जबकि पर्यवेक्षित सेटिंग में, तीन अलग-अलग तंत्रिका वर्गीकरण आर्किटेक्चर का परीक्षण किया जाता है। हम दिखाते हैं कि प्रस्तावित तंत्रिका असुरक्षित दृष्टिकोण मजबूत है, भाषाओं में हस्तांतरणीय है, और एक विशिष्ट पठनीयता कार्य और डेटा सेट के अनुकूलन की अनुमति देता है। दो भाषाओं में कई बेंचमार्क और नए लेबल पठनीयता डेटा सेट पर कई तंत्रिका आर्किटेक्चर की व्यवस्थित तुलना करके, यह अध्ययन पठनीयता वर्गीकरण के लिए विभिन्न तंत्रिका दृष्टिकोणों का एक व्यापक विश्लेषण भी प्रदान करता है। हम उनकी ताकत और कमजोरियों को उजागर करते हैं, पठनीयता के लिए वर्तमान अत्याधुनिक वर्गीकरण दृष्टिकोणों से उनके प्रदर्शन की तुलना करते हैं, जो ज्यादातर मामलों में अभी भी व्यापक सुविधा इंजीनियरिंग पर भरोसा करते हैं, और सुधार के लिए संभावनाओं का प्रस्ताव करते हैं।', 'ru': 'Аннотация Представляем набор новых нейронных контролируемых и неконтролируемых подходов к определению читабельности документов. В неконтролируемой обстановке мы используем нейронные языковые модели, в то время как в контролируемой обстановке тестируются три различные архитектуры нейронной классификации. Показано, что предлагаемый нейронный неконтролируемый подход является надежным, переносимым между языками и позволяет адаптироваться к конкретной задаче читаемости и набору данных. Путем систематического сравнения нескольких нейронных архитектур на ряде эталонных и новых маркированных наборов данных о читаемости на двух языках, это исследование также предлагает всесторонний анализ различных нейронных подходов к классификации читаемости. Мы раскрываем их сильные и слабые стороны, сравниваем их эффективность с современными классификационными подходами к удобочитаемости, которые в большинстве случаев по-прежнему опираются на обширную функциональную инженерию, и предлагаем возможности для улучшений.', 'ga': 'Coimriú Cuirimid i láthair sraith de chuir chuige núíosacha faoi mhaoirseacht agus faoi mhaoirseacht chun inléiteacht doiciméad a chinneadh. Sa suíomh gan mhaoirseacht, déanaimid giaráil ar shamhlacha néartheanga, ach sa suíomh maoirsithe, déantar tástáil ar thrí ailtireacht néar-aicmiúcháin éagsúla. Léirímid go bhfuil an cur chuige néarach neamh-mhaoirsithe atá beartaithe láidir, inaistrithe trasna teangacha, agus go gceadaíonn sé oiriúnú do thasc inléiteacht sonrach agus do thacar sonraí. Trí chomparáid chórasach a dhéanamh ar roinnt ailtireachtaí néaracha ar roinnt tacair sonraí inléiteachta tagarmharcála agus lipéadaithe nua in dhá theanga, tairgeann an staidéar seo freisin anailís chuimsitheach ar chuir chuige néarúla éagsúla maidir le haicmiú inléiteachta. Nochtaimid a láidreachtaí agus a laigí, cuirimid a bhfeidhmíocht i gcomparáid le cineálacha cur chuige aicmithe úrscothacha maidir le hinléiteacht, atá ag brath go fóill ar ghné-innealtóireacht fhairsing i bhformhór na gcásanna, agus molaimid féidearthachtaí le haghaidh feabhsúcháin.', 'ka': 'აბსტრაქტიკური ჩვენ აჩვენებთ ნეიროლური დანარწმუნებული და არაფერიზებული პროგრამების განსაზღვრებისთვის. ჩვენ ვიყენებთ ნეირალური ენის მოდელების შესახებ, მაგრამ შესახებ შესახებ, სამი განსხვავებული ნეირალური კლასიფიკაციის არქტიქტურების შესახებ. ჩვენ ჩვენ აჩვენებთ, რომ პროგრამა ნეიროლური არსუპერიზებული პროგრამა უფრო ძალიან, გადატანიზებელია ენაში, და შეუძლებელია განსაკუთრებული კითხვადასხვა სა რამდენიმე ნეიროლური აქტიქტიკურების სისტემატიკური შემდგომარებით, რამდენიმე ბენქმარკური და ახალი მარტიკური მონაცემების შემდგომარებით ორი ენაში, ეს სწავლება ასევე განსხვავებული ნეირ ჩვენ ისინი ძალიან ძალიან და ცოტაციების გამოყენება, ისინი გამოყენება მიმდინარე კლასიფიკაციის კლასიფიკაციის მიზეზებისთვის, რომელიც უფრო მეტი შემთხვევაში უფრო დიდი ფუნქციების ინეზინერიზიან და', 'el': 'Παρουσιάζουμε ένα σύνολο νέων νευρολογικών εποπτευόμενων και χωρίς επίβλεψη προσεγγίσεων για τον προσδιορισμό της αναγνωσιμότητας των εγγράφων. Στο περιβάλλον χωρίς επίβλεψη, χρησιμοποιούμε μοντέλα νευρωνικής γλώσσας, ενώ στο εποπτευόμενο περιβάλλον δοκιμάζονται τρεις διαφορετικές αρχιτεκτονικές νευρωνικής ταξινόμησης. Αποδεικνύουμε ότι η προτεινόμενη νευρική προσέγγιση χωρίς επίβλεψη είναι ισχυρή, μεταβιβάσιμη σε όλες τις γλώσσες και επιτρέπει την προσαρμογή σε μια συγκεκριμένη εργασία αναγνωσιμότητας και σύνολο δεδομένων. Με τη συστηματική σύγκριση πολλών νευρωνικών αρχιτεκτονικών σε μια σειρά σημείων αναφοράς και νέων ετικετών συνόλων δεδομένων αναγνωσιμότητας σε δύο γλώσσες, η παρούσα μελέτη προσφέρει επίσης μια ολοκληρωμένη ανάλυση διαφορετικών νευρωνικών προσεγγίσεων για την ταξινόμηση αναγνωσιμότητας. Εκθέτουμε τα δυνατά και αδύνατα σημεία τους, συγκρίνουμε την απόδοσή τους με τις τρέχουσες προσεγγίσεις ταξινόμησης στην αναγνωσιμότητα, οι οποίες στις περισσότερες περιπτώσεις εξακολουθούν να βασίζονται σε εκτεταμένη μηχανική χαρακτηριστικών, και προτείνουμε δυνατότητες βελτίωσης.', 'hu': 'Összefoglalás A dokumentumok olvashatóságának meghatározására szolgáló új idegi felügyelet nélküli és felügyelet nélküli megközelítéseket mutatunk be. Felügyelet nélküli környezetben neurális nyelvi modelleket használunk, míg a felügyelt környezetben három különböző neurális osztályozási architektúrát tesztelünk. Megmutatjuk, hogy a javasolt felügyelet nélküli neurális megközelítés robusztus, nyelvek között átvihető, és lehetővé teszi az alkalmazkodást egy adott olvashatósági feladathoz és adatkészlethez. Több neurális architektúra szisztematikus összehasonlításával számos referenciaértéken és új feliratozott olvashatósági adatkészleten két nyelven, ez a tanulmány átfogó elemzést kínál a különböző neurális megközelítések olvashatósági osztályozására. Feltárjuk erősségeiket és gyengeségeiket, összehasonlítjuk teljesítményüket a legkorszerűbb olvashatósági osztályozási megközelítésekkel, amelyek a legtöbb esetben még mindig kiterjedt funkciótervezésre támaszkodnak, és javaslatokat teszünk a fejlesztésre.', 'kk': 'Абстракты Біз құжаттардың оқуға мүмкіндігін анықтау үшін романдық невралды бақылау және қолданылмаған әдістер жиынын көрсетедік. Қолданбаған параметрлерде, біз невралдық тіл үлгілерін қолданамыз, бірақ қарау параметрлерінде үш түрлі невралдық классификациялау архитектурасы тексеріледі. Біз ұсынылған невралдық өзгертілмеген тәсілі дұрыс, тілдерді аударуға мүмкіндік береді. Оқуға мүмкіндік беретін тапсырмалар мен деректер жиынына адаптациялауға мү Бұл зерттеулер оқу мүмкіндіктерінің бірнеше невралдық архитектураларын жүйелік түрде салыстырып, екі тілде жаңа жарлық оқу мүмкіндіктерінің деректер жиындары жүйелік түрде салыстырылады. Біз олардың күштігін және қауіпсіздіктерін көрсеткіземіз, олардың әрекеттерін оқу мүмкіндігіне салыстырып, көпшілігінде әлі қауіпсіздік инженеріне тәуелді және жақсарту мүмкіндіктерін ұсынам', 'it': "Presentiamo una serie di nuovi approcci neurali supervisionati e non supervisionati per determinare la leggibilità dei documenti. Nell'ambiente non supervisionato, utilizziamo modelli di linguaggio neurale, mentre nell'ambiente supervisionato vengono testate tre diverse architetture di classificazione neurale. Mostriamo che l'approccio neurale non supervisionato proposto è robusto, trasferibile tra le lingue e consente l'adattamento a un compito specifico di leggibilità e a un set di dati. Confrontando sistematicamente diverse architetture neurali su un certo numero di benchmark e nuovi set di dati di leggibilità etichettati in due lingue, questo studio offre anche un'analisi completa dei diversi approcci neurali alla classificazione della leggibilità. Esponiamo i loro punti di forza e di debolezza, confrontiamo le loro prestazioni con gli attuali approcci di classificazione all'avanguardia per la leggibilità, che nella maggior parte dei casi si basano ancora su un'ampia funzionalità ingegneristica, e proponiamo possibilità di miglioramento.", 'ms': 'Abstract Kami perkenalkan set pendekatan saraf yang baru yang diawasi dan tidak diawasi untuk menentukan pembacaan dokumen. Dalam tetapan yang tidak diawasi, kita menggunakan model bahasa saraf, sementara di tetapan yang diawasi, tiga arkitektur klasifikasi saraf yang berbeza diuji. Kami menunjukkan bahawa pendekatan saraf yang diusulkan tidak diawasi adalah kuat, boleh dipindahkan melalui bahasa, dan membolehkan penyesuaian kepada tugas pembacaan dan set data khusus. Dengan perbandingan sistemik beberapa arkitektur saraf pada sejumlah tanda referensi dan set data pembacaan baru yang ditabel dalam dua bahasa, kajian ini juga menawarkan analisis komprensif pendekatan saraf yang berbeza untuk klasifikasi pembacaan. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to readability, which in most cases still rely on extensive feature engineering, and propose possibilities for improvements.', 'lt': 'Abstract We present a set of new neural supervised and unsupervised approaches to determine readability of documents. Neprižiūrimose aplinkybėse naudojame nervų kalbos modelius, o prižiūrimose aplinkybėse bandomos trys skirtingos nervų klasifikacijos architektūros. Mes rodome, kad siūlomas neuralinis nepastebimas metodas yra patikimas, perduodamas įvairiomis kalbomis ir leidžia prisitaikyti prie konkrečios skaitomumo užduoties ir duomenų rinkinio. Sistemingai palyginant keletą nervų architektūrų su lyginamuoju lyginamuoju rodikliu ir naujais pažymėtais skaitomumo duomenų rinkiniais dviem kalbomis, šiame tyrime taip pat pateikiama išsami įvairių nervų metodų analizė skaitomumo klasifikacijai. Mes atskleidžiame jų stiprumus ir trūkumus, palyginame jų rezultatus su dabartiniais pažangiausiais klasifikavimo metodais skaitomumui, kurie daugeliu atvejų vis dar priklauso nuo plataus masto charakteristikų in žinerijos, ir siūlome galimybes patobulinti.', 'mk': 'Апстрактен Презентираме нови нервни надгледувани и ненадгледувани пристапи за одредување на читливоста на документите. Во ненадгледуваното поставување, ги користиме моделите на нервниот јазик, додека во надгледуваното поставување, се тестираат три различни архитектури на нервната класификација. Покажуваме дека предложениот неурален ненадгледуван пристап е robust, префрлив преку јазици и овозможува адаптација на специфична задача за читање и податоци. By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification.  Ние ги изложуваме нивните сили и слабости, ги споредуваме нивните резултати со сегашните најсовремени класификациски пристапи кон читателноста, кои во повеќето случаи сé уште се потпираат на екстремна инженерска карактеристика, и предложуваме можности за подобрувања.', 'ml': 'രേഖകളുടെ വായിക്കുന്നത് നിര്\u200dണ്ണയിക്കാനും സൂക്ഷ്മമില്ലാത്ത സാധനങ്ങളുടെ അടുത്ത് നില്\u200dക്കുന്ന ഒരു നോവല്\u200d ന്യൂറ സൂക്ഷിച്ചില്ലാത്ത ക്രമീകരണങ്ങളില്\u200d, നമ്മള്\u200d ന്യൂറല്\u200d ഭാഷ മോഡലുകള്\u200d ഉപയോഗിക്കുന്നു. നിരീക്ഷിക്കപ്പെട്ട സെറ്റില്\u200d മൂന്നു  നിര്\u200dദ്ദേശിക്കപ്പെടാത്ത ന്യൂറല്\u200d സംരക്ഷിക്കപ്പെടാത്ത പ്രായോഗ്യം നിര്\u200dബന്ധിതമാക്കുന്നത് ഭാഷകളില്\u200d മാറ്റുന്നതും, വിശിഷ കുറച്ചു ബെന്\u200dച്മാര്\u200dക്കും പുതിയ വായിക്കാവുന്ന വിവരങ്ങളുടെ ഡേറ്റാ സജ്ജീകരണങ്ങള്\u200d രണ്ടു ഭാഷകളില്\u200d സിസ്റ്റമിക്കായി നെറുറല്\u200d ആര്\u200dക്ടിക്കറ്റുകളുടെ  നമ്മള്\u200d അവരുടെ ശക്തികളെയും ദുര്\u200dബലങ്ങളെയും വെളിപ്പെടുത്തുന്നു, അവരുടെ പ്രവര്\u200dത്തനങ്ങളെയും ഇപ്പോഴത്തെ കലാകാര്യത്തിന്റെ സ്ഥിതിയോട് താല്\u200dപര്യമാക്കുന്ന', 'pl': 'Streszczenie Przedstawiamy zestaw nowych neuronowych nadzorowanych i bez nadzoru podejść do określania czytelności dokumentów. W otoczeniu bez nadzoru wykorzystujemy modele języka neuronowego, natomiast w otoczeniu nadzorowanym testowane są trzy różne architektury klasyfikacji neuronowej. Pokazujemy, że proponowane podejście neuronowe bez nadzoru jest solidne, możliwe do przenoszenia między językami i pozwala na adaptację do konkretnego zadania czytelności i zbioru danych. Poprzez systematyczne porównanie kilku architektur neuronowych na szeregu referencyjnych i nowych znakowanych zbiorach danych dotyczących czytelności w dwóch językach, niniejsze opracowanie oferuje również kompleksową analizę różnych neuronowych podejść do klasyfikacji czytelności. Ujawniamy ich mocne i słabe strony, porównujemy ich wydajność z aktualnymi najnowocześniejszymi podejściami klasyfikacyjnymi do czytelności, które w większości przypadków nadal opierają się na rozbudowanej inżynierii funkcji oraz proponujemy możliwości ulepszeń.', 'no': 'Abstrakt Vi viser eit sett av nyraloversikte og usikkerte tilnærmingar for å bestemme lesabilitet for dokument. I den usikkerte innstillinga leverer vi neuralspråk-modeller, mens i den oversikte innstillinga tester tre ulike neuralklassifikasjonske arkitekturar. Vi viser at den foreslåde neuralforsterte tilnærminga er sterkt, overførbar på språk, og tillater tilpassing til ei spesielt lesabilitet oppgåve og datasett. Etter systematisk samanlikning av fleire neuralarkitekturar på mange benchmarker og nye merkelige lesabilitetsdatasett i to språk, tilbyr denne studien også ein komplett analyse av ulike neuraltilnærmingar til lesabilitetsklassifikasjon. Vi eksponerer sine sterke og tyrke, samanliknar sine utviklinga med den gjeldande klassifikasjonen av kunstklassifikasjonen tilnærmer lesabiliteten, som i dei fleste tilfellene fortsatt rely på utvida funksjonsengineering, og foreslår muligheter for forbedringar.', 'ro': 'Rezumat Prezentăm un set de abordări noi supravegheate neurale și nesupravegheate pentru determinarea lizibilității documentelor. În cadrul nesupravegheat, utilizăm modele de limbaj neural, în timp ce în cadrul supravegheat, trei arhitecturi de clasificare neurală diferite sunt testate. Noi arătăm că abordarea neurală nesupravegheată propusă este robustă, transferabilă între limbi și permite adaptarea la o sarcină specifică de lizibilitate și setul de date. Prin compararea sistematică a mai multor arhitecturi neurale pe un număr de referințe și noile seturi de date etichetate de lizibilitate în două limbi, acest studiu oferă, de asemenea, o analiză cuprinzătoare a diferitelor abordări neurale pentru clasificarea lizibilității. Expunem punctele forte și punctele slabe ale acestora, le comparăm performanțele cu abordările actuale de clasificare de ultimă generație a lizibilității, care în majoritatea cazurilor se bazează încă pe ingineria extinsă a caracteristicilor și propunem posibilități de îmbunătățire.', 'sr': 'Abstrakt predstavljamo niz novog neuralnog nadzora i neodređenih pristupa za određivanje čitljivosti dokumenta. U neodređenom stanju, mi utiču na neuralne jezičke modele, dok se u nadzornom stanju testiraju tri različite neuroklasifikacijske arhitekture. Pokazujemo da je predloženi neuralni neodređeni pristup roban, prebacivan na jezike i omogućava adaptaciju na određeni zadatak čitljivosti i set podataka. Sistemalnim usporedbom nekoliko neuralnih arhitektura o broju kriterija i novih kompleta podataka o čitljivosti na dva jezika, ova studija takođe nudi komplektivnu analizu različitih neuralnih pristupa klasifikaciji čitljivosti. Mi izlažemo njihove snage i slabosti, uspoređujemo njihovu provedbu sa trenutnim pristupima klasifikacije stanja umjetnosti na čitljivost, koje u većini slučajeva još uvijek oslanjaju na ogromne in ženjerstvo karakteristike, i predlažemo mogućnosti za poboljšanje.', 'si': 'අපි පිළිබඳින්න පුළුවන් න්\u200dයූරාල් නිරීක්ෂණය සහ නිරීක්ෂණ විදියට පිළිබඳ විදියට පිළිබඳ විදිය අපි නිර්භාවිත භාෂා මොඩේල් කරනවා, ඒත් බලන්න සැකසුම් තුනක් වෙනස් නිර්භාවිත විශේෂ ස්ථාපනය පරීක්ෂා කරනවා. අපි පෙන්වන්නේ ප්\u200dරතිචාරයක් නිර්භාවිත විදිහට ප්\u200dරතිචාරයක් නැති විදිහට නිර්භාවිත විදිහට, භාෂාවට ප බෙන්ච්මාර්ක් සහ අළුත් ලෙබෙල් කියවන්න පුළුවන් දත්ත සෙට් වල භාෂාවක් දෙකක් තියෙන ස්ථාපනය සඳහා සංවිධානය සම්බන්ධ විශේ අපි ඔවුන්ගේ ශක්තිමත්වය හා දුර්වලය ප්\u200dරවේශනය කරනවා, ඔවුන්ගේ ප්\u200dරවේශනය ප්\u200dරවේශනය කියලා කියවන්න පුළුවන් වෙනුවෙන් ප්\u200dරවේශනය සඳහා ප්\u200dරවේ', 'mn': 'Абстракт Бид баримтуудын унших чадварыг тодорхойлох шинэ сэтгэл хөдлөл, сэтгэл хөдлөл байгуулагдсан шинэ арга баримтуудыг тайлбарлаж байна. Гэвч бид мэдрэлийн хэл загварыг дамжуулж чадахгүй байдалд 3 төрлийн мэдрэлийн хуваариллагааны барилгуудыг шалгаж байна. Бид санал дэвшүүлэгдэхгүй мэдрэлийн ойлголт нь хүчтэй, хэл дээр шилжүүлж чадна гэдгийг харуулж, уншиж чадах үйл ажиллагаа болон өгөгдлийн бүтээгдэхүүнд адилтгаж чадна. Хоёр хэл дээр олон мэдрэлийн архитектуруудын систематикийн харьцуулахад энэ судалгаа унших боломжтой хуваалцах боломжтой шинэ өгөгдлийн сангуудын олон мэдрэлийн архитектуруудын шинжлэх ухаан өгдөг. Бид тэдний хүчтэй, хүчтэй байдлыг илэрхийлж, үйл ажиллагааг унших чадвартай харьцуулж, ихэнх тохиолдолд энэ нь маш том инженерчлэлтэй хамаарч, сайжруулах боломжтой боломжтой байдаг.', 'mt': 'Abstrat Aħna nippreżentaw sett ta’ approċċi newrali ġodda sorveljati u mhux sorveljati biex tiġi ddeterminata l-leġibbiltà tad-dokumenti. In the unsupervised setting, we leverage neural language models, whereas in the supervised setting, three different neural classification architectures are tested.  Aħna nuru li l-approċċ newrali mhux sorveljat propost huwa robust, trasferibbli bejn il-lingwi, u jippermetti l-adattament għal kompitu speċifiku ta’ leġibbiltà u sett ta’ dejta. Permezz ta’ tqabbil sistematiku ta’ diversi arkitetturi newrali fuq għadd ta’ punti ta’ riferiment u settijiet ġodda ta’ dejta ta’ leġibbiltà ttikkettati f’żewġ lingwi, dan l-istudju joffri wkoll analiżi komprensiva ta’ approċċi newrali differenti għall-klassifikazzjoni tal-leġibbiltà. Aħna niżżlu l-qawwiet u d-dgħufijiet tagħhom, inqabblu l-prestazzjoni tagħhom mal-approċċi attwali tal-klassifikazzjoni l-aktar avvanzati għall-leġibbiltà, li fil-biċċa l-kbira tal-każijiet għadhom jiddependu fuq in ġinerija b’karatteristiċi estensivi, u nipproponu possibbiltajiet għal titjib.', 'ta': 'ஆவணங்களின் படிப்பை தீர்மானிக்க ஒரு புதிய புதிய பாதுகாப்பு மற்றும் பாதுகாப்பாக்கப்படாத வழிகளை நாம் கழிக்கிறோம பாதுகாப்பாக்கப்படாத அமைப்பில், நாம் புதிய மொழி மாதிரிகளை ஒப்புக்கொள்கிறோம், ஆனால் கண்காணிக்கப்பட்ட அமைப்பில், மூன்று வ நாம் நிர்ணயிக்கப்பட்ட புதிய பாதுகாப்பாக்கப்படாத முறைமை மொழிகளில் மாற்றப்பட்டது, மாற்றப்படுகிறது மற்றும் ஒரு குறிப்பிட்ட பென்க்மார்க் மற்றும் புதிய குறிப்பிட்ட படிக்கும் தகவல் அமைப்புகளை இரண்டு மொழிகளில் ஒப்பிடுவதால், இந்த ஆய்வு வேறு புதிய புதிய முறைமையை படிக்கும்  நாம் அவர்களுடைய சக்திகளையும் பலஹீனப்படையையும் வெளிப்படுத்துகிறோம், அவர்கள் செயல்பாட்டையும் தற்போதைய கலை வகைப்பாட்டிற்கு ஒப்பிடுகிறோம், அது படிக்', 'sv': 'Sammanfattning Vi presenterar en uppsättning nya neurala övervakade och oövervakade metoder för att fastställa läsbarheten hos dokument. I den obevakade miljön utnyttjar vi neurala språkmodeller, medan i den övervakade miljön testas tre olika neurala klassificeringsarkitekturer. Vi visar att den föreslagna neurala obevakade metoden är robust, överförbar över språk och möjliggör anpassning till en specifik läsbarhetsuppgift och datamängd. Genom systematisk jämförelse av flera neurala arkitekturer på ett antal benchmark och nya märkta läsbarhetsdata på två språk erbjuder denna studie också en omfattande analys av olika neurala tillvägagångssätt för läsbarhetsklassificering. Vi avslöjar deras styrkor och svagheter, jämför deras prestanda med nuvarande toppmoderna klassificeringsmetoder för läsbarhet, som i de flesta fall fortfarande förlitar sig på omfattande feature engineering, och föreslår möjligheter till förbättringar.', 'so': 'Waxaannu soo saarnaa koox dareemo ah oo ilaalinaya oo aan la ilaalin karin si aan u xaqiijinno qoraalka akhriska. Xafiiska aan la ilaalinayn, waxaynu soo bandhignaa modelal afka neurada, marka la ilaaliyo, waxaa la imtixaamaa saddex meelood oo kala duduwan qaabka neurada. We show that the proposed neural unsupervised approach is robust, transferable across languages, and allows adaptation to a specific readability task and data set.  Waxbarashadan wuxuu sidoo kale bixiyaa baaritaanka kooxa ah oo ku qoran meelo neurada ah oo ku qoran qaar ka mid ah benchmarkga iyo qoraalka macluumaadka akhriska ee cusub oo labo luqadood ah. Waxaannu muujinnaa xooggooda iyo itaaldarradooda, Isbarbardhigno tababaridooda xaaladda farshaxanka ah, taasoo marka badan waxay ku xiran yihiin wax akhrin kara, waxayna soo jeedi karaan suurtogal horumar ah.', 'ur': 'ہم نے ایک مجموعہ نورال کی نظارت کی اور غیر قابل تحقیق کی طریقے کی تصدیق کی غیر قابل تعمیر کی جگہ، ہم نئورل زبان کی نمونڈلوں کو لذت دیتے ہیں، حالانکہ تحت نظر کی جگہ، تین مختلف نئورل کلاسیفوں کی معماری آزمائش کی جاتی ہیں. ہم نشان دیتے ہیں کہ پیشنهاد نائورل غیر قابل تحقیق قوت ہے، زبانوں میں انتقال قابل ہے، اور ایک خاص پڑھنے کے قابل تحقیق اور ڈیٹا سٹ کے لئے اضافہ کرنے کی اجازت دیتے ہیں. چند نورول معماروں کی سیستماتیک مقایسہ کے ذریعہ سے جنچم مارک اور نئی لکھی ہوئی پڑھنے کے قابل ذریعہ ڈیٹ سٹ دو زبانوں میں، یہ تحقیق بھی پڑھنے کے لئے مختلف نورول طریقے کے تحقیق کا تحقیق کرتا ہے. ہم ان کی قوت اور ضعیفوں کو کھول دیتے ہیں، ان کی پرورش کو سنائی کے قابلیت کے مطابق سنائی کے قابلیت کے مطابق مقایسہ کر دیتے ہیں، جو اکثر موقعیفوں میں یہاں تک بھی بڑی فعالیت انجینری پر بھروسہ رکھتے ہیں، اور ان کی اصلاح کے امکانات کا پیشنهاد کرتے ہیں', 'vi': 'Trừu tượng Chúng tôi giới thiệu một loạt các tiếp cận thần kinh mới giám sát và không giám sát để xác định sự dễ đọc của tài liệu. Trong môi trường không được giám sát, ta sử dụng các mô hình ngôn ngữ thần kinh, trong khi trong môi trường được giám sát, ba kiến trúc phân loại thần kinh khác nhau được thử nghiệm. Chúng tôi cho thấy phương pháp dây thần kinh không giám sát được đề xuất mạnh mẽ, dễ lây nhiễm qua các ngôn ngữ, và cho phép thích nghi với một nhiệm vụ và bộ dữ liệu có thể đọc được. Bằng cách so sánh mô phỏng các kiến trúc thần kinh trên một số điểm chuẩn và các bộ dữ liệu mới có thể đọc mới bằng hai ngôn ngữ, nghiên cứu này cũng cung cấp một phân tích to àn diện về các phương pháp thần kinh khác nhau đến mức độ dễ đọc. Chúng ta bộc lộ điểm mạnh và yếu của họ, so sánh khả năng của họ với các phương pháp phân loại hiện đại về độ đọc, mà hầu hết vẫn dựa vào kỹ thuật đặc trưng rộng, và đề xuất khả năng cải tiến.', 'uz': "Ҳужжатларни ўқиш учун сақланган ва сақланмаган манбага тўпланган даража ҳосилларини чиқардик. Koʻrsatilmagan moslamada, biz neyrolik tilning modellarini yozib qo'llayapmiz. Va taʼminlovchi moslamada, uchta boshqa neyrol classification architektlari imtiyozmaydi. Biz tasavvur qilingan neyrolik himoyalangan usulni ko'rsatishimiz mumkin, tillar tilida o'zgartirib boʻladi, va uning taymaviy oʻqish vazifasini va maʼlumot moslamasini oʻzgartirishga ruxsat beradi. Bir necha necha neyrolik maktablarning bir necha kompyuterga o'xshash qilingan va yangi oddiy oʻquvchi maʼlumot tarkibini ikkita tillarda o'rganish bilan bir necha neyrolik muammolari bilan birlashtirish mumkin. Bu o'qituvchi darajalashtirish uchun boshqa neyrol tarjimalarni o'rganish mumkin. Biz ularning ko'plamlarini ko'rsamiz, ularning joriy sananing darajasining xususiyatini o'qituvchi holatiga kamaytamiz, va ko'pchilik holatda ham ko'proq imkoniyatlarni ajratishga ishlatamiz va yaxshilash imkoniyatlarini rivojlanadi.", 'nl': 'Abstract We presenteren een reeks nieuwe neurale begeleide en niet-begeleide benaderingen voor het bepalen van de leesbaarheid van documenten. In de onbeheerde setting maken we gebruik van neurale taalmodellen, terwijl in de begeleide setting drie verschillende neurale classificatiearchitecturen worden getest. We tonen aan dat de voorgestelde neurale onbeheerde aanpak robuust is, overdraagbaar is over talen en aanpassing mogelijk maakt aan een specifieke leesbaarheidstaak en dataset. Door systematische vergelijking van verschillende neurale architecturen op een aantal benchmark en nieuwe gelabelde leesbaarheidsdatasets in twee talen, biedt deze studie ook een uitgebreide analyse van verschillende neurale benaderingen voor leesbaarheidsclassificatie. We brengen hun sterke en zwakke punten bloot, vergelijken hun prestaties met de huidige state-of-the-art classificatiebenaderingen voor leesbaarheid, die in de meeste gevallen nog steeds berusten op uitgebreide feature engineering, en stellen verbetermogelijkheden voor.', 'bg': 'Представяме набор от нови невронни надзорни и ненадзорни подходи за определяне на четливостта на документи. В неконтролирана обстановка ние използваме невронните езикови модели, докато в контролираната обстановка се тестват три различни архитектури за невронна класификация. Показваме, че предложеният невронен подход без надзор е здрав, преносим между езици и позволява адаптация към конкретна задача за четливост и набор от данни. Чрез систематично сравняване на няколко неврални архитектури върху редица референтни и нови маркирани набори от данни за четливост на два езика, това изследване предлага и изчерпателен анализ на различни неврални подходи към класификацията на четливостта. Излагаме техните силни и слаби страни, сравняваме тяхното представяне с съвременните класификационни подходи за четливост, които в повечето случаи все още разчитат на обширно инженерство на функциите, и предлагаме възможности за подобрения.', 'hr': 'Abstrakt Mi predstavljamo skup novog neuralnog nadzora i neodređenog pristupa za utvrđivanje čitljivosti dokumenta. U neodređenom stanju, mi primjenjujemo neuralne jezičke modele, dok se u nadzornom stanju testiraju tri različite arhitekture neuroklasifikacije. Pokazujemo da je predloženi neuralni neodređeni pristup jak, prebacivan na jezike i omogućava prilagodbu određenom zadatku čitljivosti i postavku podataka. Sistemično usporedbom nekoliko neuralnih arhitektura o broju kriterija i novih označenih kompleta podataka o čitljivosti na dva jezika, u ovom ispitivanju također nudi sveobuhvatnu analizu različitih neuralnih pristupa klasifikaciji čitljivosti. Mi izlažemo njihove snage i slabosti, uspoređujemo njihovu učinku sa trenutnim pristupima klasifikacije stanja umjetnosti na čitljivost, koje u većini slučajeva još uvijek oslanjaju na veliki in ženjering karakteristika, i predlažemo mogućnosti za poboljšanje.', 'de': 'Wir präsentieren eine Reihe neuartiger neural überwachter und unüberwachter Ansätze zur Bestimmung der Lesbarkeit von Dokumenten. Im unbeaufsichtigten Setting nutzen wir neuronale Sprachmodelle, während im überwachten Setting drei verschiedene neuronale Klassifikationsarchitekturen getestet werden. Wir zeigen, dass der vorgeschlagene neuronale unüberwachte Ansatz robust, sprachübergreifend übertragbar ist und eine Anpassung an eine bestimmte Lesbarkeitsaufgabe und einen Datensatz ermöglicht. Durch den systematischen Vergleich mehrerer neuronaler Architekturen auf einer Reihe von Benchmark- und neu markierten Lesbarkeitsdatensätzen in zwei Sprachen bietet diese Studie auch eine umfassende Analyse verschiedener neuronaler Ansätze zur Lesbarkeitsklassifizierung. Wir zeigen ihre Stärken und Schwächen auf, vergleichen ihre Performance mit aktuellen Klassifikationsansätzen zur Lesbarkeit, die in den meisten Fällen noch auf umfangreichem Feature Engineering beruhen, und schlagen Verbesserungsmöglichkeiten vor.', 'id': 'Abstrakt Kami memperlihatkan set novel neural supervised and unsupervised approaches for determining the readability of documents. Dalam setting yang tidak diawasi, kita menggunakan model bahasa saraf, sementara di setting yang diawasi, tiga arkitektur klasifikasi saraf yang berbeda diuji. Kami menunjukkan bahwa pendekatan saraf yang diusulkan tidak diawasi adalah kuat, dapat dipindahkan melalui bahasa, dan memungkinkan adaptasi ke tugas pembacaan spesifik dan set data. Dengan perbandingan sistematis dari beberapa arsitektur saraf pada sejumlah benchmark dan set data pembacaan baru yang ditabel dalam dua bahasa, penelitian ini juga menawarkan analisis komprensif dari pendekatan saraf yang berbeda untuk klasifikasi pembacaan. Kami mengungkapkan kekuatan dan kelemahan mereka, membandingkan prestasi mereka dengan pendekatan klasifikasi terbaik saat ini untuk pembacaan, yang dalam kebanyakan kasus masih bergantung pada teknik karakteristik ekstensif, dan mengusulkan kemungkinan untuk peningkatan.', 'ko': '요약 우리는 문서의 가독성을 확인하기 위해 새로운 신경 감독과 비감독 방법을 제시했다.비감독 환경에서 우리는 신경 언어 모델을 이용하고 감독 환경에서 우리는 세 가지 서로 다른 신경 분류 구조를 테스트했다.우리는 제시된 신경 무감독 방법이 건장하고 언어를 뛰어넘을 수 있으며 특정한 가독성 임무와 데이터 집합에 적응할 수 있음을 증명했다.두 언어 중 대량의 기준 데이터 집합과 새로운 표기 가독성 데이터 집합의 몇 가지 신경 구조를 체계적으로 비교함으로써 본 연구는 서로 다른 가독성 분류 신경 방법을 전면적으로 분석했다.우리는 그들의 장단점을 제시하고 그들의 성능을 현재 가장 선진적인 가독성 분류 방법과 비교했으며 대다수 상황에서 광범위한 특징 공정에 의존하고 개선 가능성을 제기했다.', 'da': 'Abstract Vi præsenterer en række nye neurale overvågede og uopvågede tilgange til bestemmelse af dokumenters læsbarhed. I den ubevågede indstilling udnytter vi neurale sprogmodeller, mens i den overvågede indstilling testes tre forskellige neurale klassifikationsarkitekturer. Vi viser, at den foreslåede neurale tilgang uden opsyn er robust, kan overføres på tværs af sprog og muliggør tilpasning til en specifik læsbarhedsopgave og datasæt. Ved systematisk sammenligning af flere neurale arkitekturer på en række benchmark og nye mærkede læsbarhedsdatasæt på to sprog tilbyder denne undersøgelse også en omfattende analyse af forskellige neurale tilgange til læsbarhedsklassificering. Vi afslører deres styrker og svagheder, sammenligner deres ydeevne med nuværende state-of-the-art klassifikationsmetoder til læsbarhed, som i de fleste tilfælde stadig er afhængige af omfattende feature engineering, og foreslår muligheder for forbedringer.', 'sw': 'Tuliondoa hatua za kisasa zinazolindwa na zisizo na uhakika kwa ajili ya kuamua kusoma nyaraka. Katika mazingira yasiyoelewekwa, tunatumia mifano ya lugha ya kisasa, wakati katika mazingira ya utangalizi, majengo matatu tofauti ya usambazaji wa neura yanajaribiwa. Tunaonyesha kwamba mbinu zilizopendekezwa na ubongo usio na uhakika wa neura ni kutengenezwa, kubadilishwa katika lugha mbalimbali, na inaruhusu kuboresha kazi maalum ya kusoma na seti ya data. Kwa kulinganisha na majengo kadhaa ya ubongo katika maeneo kadhaa ya bendera na taarifa mpya za kusoma zilizoandikwa kwa kwa lugha mbili, utafiti huu pia unatoa uchambuzi wa kina wa njia mbalimbali za ubongo za kusoma. Tunaonyesha nguvu zao na udhaifu wao, ukilinganisha na utendaji wao wa hali ya sasa ya usambazaji wa sanaa unakaribia kusoma, ambapo kwa matukio mengi bado tunategemea ubunifu mkubwa, na tunapendekeza uwezekano wa maboresho.', 'fa': 'ما مجموعه\u200cای از روان\u200cهای عصبی را برای تعیین خواندن سند را نشان می\u200cدهیم. در تنظیمات غیرقابل تحقیق، ما مدل زبان عصبی را تحقیق می کنیم، در حالی که در تنظیمات تحقیق، سه معماری مختلف تنظیمات عصبی آزمایش می شوند. ما نشان می دهیم که دستور پیشنهاد غیرقابل تحمل عصبی قوی است، قابل تحویل از زبانها است، و اجازه می دهد که به یک کار خواندنی ویژه و مجموعه داده باشد. با مقایسه سیستماتی از چند معماری عصبی در تعداد برچسب و مجموعه داده های خواندنی جدید در دو زبان، این مطالعه همچنین یک تحلیل کامل از دسترسی عصبی مختلف برای برچسب خواندن قابلیت پیشنهاد می کند. ما قوت و ضعیفه\u200cهایشان را نشان می\u200cدهیم، عملکرد\u200cهایشان را با نزدیک\u200cهای مختصات هنری به خواندگی مقایسه می\u200cکنیم، که در اکثر موارد هنوز بر مهندسی ویژه\u200cهای وسیع اعتماد دارند، و فرصت\u200cهایشان را برای بهتر کردن پیشنهاد می\u200cدهیم.', 'tr': 'Abstrakt Biz senediň okaýanlygyny bejermek üçin romanlary bejerýäris. Taýýarlanmadyk düzümlerde, biz näyral dil nusgalaryny çykarýarys, ýöne gözetli düzümlerde üç farklı näyral klasifikasyýa arhitekturlary bardyr. Biz nuýral taýýarlanmadyk nuýral ýazşynyň güýçli we dillerde göçürilebilir bolandygyny görkezip berýäris we munyň belli okaýanlyg täblisasyna we maglumatlaryň düzümlerini üýtgetmegine mümkin edýäris. Birnäçe benchmark we täze etiket edilen okanlyk data setirleriniň sistemiýa karşılaşlygyna görä, bu araşdyrma okuwçylyk klasifikasyýasy üçin beýleki näural yaklaşyklaryň we daşary çykyşlygyny barlaýar. Biz olaryň güýçlerini we zaçyrlyklaryny açýarys, ukyplaryny häzirki möhüm möhüm döwletlere golaýlaşdyrýarys. Köp wagtlarda henizem uly möhüm enjiniýetçiliklere ynanýarlar we gelişmeler üçin mümkinçiliklere karşılaştyrýarys.', 'sq': 'Abstrakt Ne paraqesim një sërë afrimesh të reja nervore të mbikqyrura dhe të pazgjidhura për të përcaktuar lexueshmërinë e dokumenteve. Në vendosjen e pa mbikqyrur, ne përdorim modelet e gjuhës nervore, ndërsa në vendosjen e mbikqyrur, janë testuar tre arkitektura të ndryshme klasifikimi nervor. Ne tregojmë se qasja e propozuar neurale e pa mbikqyrur është e fortë, e transferueshme nëpër gjuhë dhe lejon përshtatjen në një detyrë të veçantë lexueshmërie dhe të dhënave. Nga krahasimi sistematik i disa arkitekturave neurale në një numër referencimi dhe të dhënave të reja të etiketuara të lexueshmërisë në dy gjuhë, ky studim ofron gjithashtu një analizë tërësore të qasjeve të ndryshme neurale për klasifikimin e lexueshmërisë. Ne ekspozojmë fuqitë dhe dobësitë e tyre, krahasojmë shfaqjen e tyre me qasjet e klasifikimit aktual të lartë të klasifikimit të lexueshmërisë, të cilat në shumicën e rasteve ende mbështeten në inxhinierinë e gjerë të karakteristikave dhe propozojmë mundësi për përmirësime.', 'am': 'ሰነዱን ማነብ ለመጠበቅ እና የማይጠበቀውን የደብዳቤዎችን መቃኛ እናስቀምጣለን፡፡ በተጠበቀው ባሕላዊ ቋንቋ ምሳሌዎችን እናስገድዳለን፣ በተጠበቀው ሥርዓት ውስጥ ሦስት የተለየ የደዌብ መዝገብ መሠረቶች ይፈተናል፡፡ በቋንቋዎች ላይ የተዘጋጀው የሆኑት የነዌብ ሥርዓት፣ የሚለወጥ፣ የተለወጠውን እና በተለየ የአብያዊ ስራ እና ዳታ ማሰናከል እንዲፈቅድ እናደርጋለን፡፡ በሁለት ቋንቋዎች ላይ በብዛት የደዌብ አካባቢዎች እና አዲስ የቻለ የአንባቢው ዳታ በተያያያየ ብጤት በተስተያየት፣ ይህ ትምህርት ደግሞ ለልዩ ልዩ ልዩ የደዌብ ግንኙነት ለማንበብ ማስተያየትን ያቀርባል፡፡ ኃይላቸውን እና ድካማቸውን እናሳውቃለን፣ የአሁኑ የart-ክፍል ግንኙነታቸውን ለመቀበል እናስተያየዋለን፡፡', 'af': "Abstrak Ons stel 'n stel van nuwe neurale ondersoekte en onondersoekte toegange voor die besluit van die leesbaarheid van dokumente. In die onversoekte instelling, laat ons neurale taal modele leverer, terwyl in die ondersoekte instelling, drie verskillende neuralklasifikasie-arkitektuure is toets. Ons wys dat die voorgestelde neurale onverondersteunde toegang is sterk, oordragbare oor tale en toelaat toepassing na 'n spesifieke leesbaardige taak en data stel. Deur sistematiese vergelyking van verskeie neurale arkitekturke op 'n aantal benchmarke en nuwe gemerkbare readability data stel in twee tale, hierdie studie gee ook 'n kompensieële analisie van verskillende neurale toegange aan lesabiliteit klasifikasie. Ons expose hulle sterkte en swakhede, vergelyk hulle prestasie met huidige staat van die kuns klassifikasie toegang tot leesbaardigheid, wat in meeste gevalle nog op uitbreidige funksie in ženiering vertrou en voorstel moontlikhede vir verbeteringe.", 'az': 'Əksinə, belələrin oxuyabiləcəyini müəyyən etmək üçün yeni nöral təhlükəsizlik və təhlükəsizlik edilməmiş tərzlərini göstəririk. Nəyral dil modellərini istifadə edirik, amma gözləyirləndiriləndə üç müxtəlif nəyral klasifikasiya arhitektürlərini sınayırıq. Biz göstəririk ki, təbliğ edilməmiş nöral təsiri güclüdür, dillərdə daşınabilir, və müəyyən oxuyabiləcək işlərə və məlumatlara uyğunlaşdırmağa imkan verir. Bir neçə benchmark və iki dildə yeni etiket edilən oxuyabilən verilənlər tərəfindən sistematik nöral arhitektarların qarşılaşdırması ilə bu təhsil oxuyabiləcək klasifikasiya üçün müxtəlif nöral tərəfindən müxtəlif analizi təklif edir. Biz onların qüvvətlərini və zəifliklərini göstəririk, onların performanslarını oxuyabiləcəyi tərzlərinə qarşılaşdırırıq, çoxlarında hələ də böyük tərzlərin mühendisiyyətinə təvəkkül edir və yaxşılıqların mümkünlüklərinə təklif edirik.', 'hy': 'Աբստրակտ Մենք ներկայացնում ենք մի շարք նոր նյարդային վերահսկվող և անվերահսկվող մոտեցումներ փաստաթղթերի կարելի է որոշել: Ոչ վերահսկվող միջավայրում մենք օգտագործում ենք նյարդային լեզվի մոդելները, մինչդեռ վերահսկվող միջավայրում փորձվում են երեք տարբեր նյարդային դասակարգման ճարտարապետություններ: Մենք ցույց ենք տալիս, որ առաջարկված նյարդային անվերահսկված մոտեցումը կայուն է, փոխանցելի է լեզուների միջև և հնարավորություն է տալիս հարմարվել որոշակի կարդալիության խնդիրներին և տվյալների համակարգին: Ստոմատիկ համեմատությամբ որոշ նյարդային ճարտարապետությունների վերաբերյալ երկու լեզուներով և նոր նյարդային կարդալիության տվյալների համակարգերի վրա, այս ուսումնասիրությունը նաև ընդհանուր վերլուծություն է առաջարկում կարդալիորման տարբեր նյարդային Մենք բացահայտում ենք նրանց ուժեղությունները և թույլությունները, համեմատում ենք նրանց արտադրողականությունը ներկայիս լավագույն դասակարգման մոտեցումների հետ կարելի է կարդալ, որոնք մեծ մասում դեռ հիմնված են էքսպանցիոն հատկությունների ճարտարագիտության վրա և առաջարկում են բարել', 'bs': 'Abstrakt Mi predstavljamo niz novog neuralnog nadzora i neodređenih pristupa za određivanje čitljivosti dokumenta. U neodređenom stanju, mi primjenjujemo neuralne jezičke modele, dok se u nadzornom stanju testiraju tri različite arhitekture neuroklasifikacije. Pokazujemo da je predloženi neuralni neodređeni pristup jak, prebacivan na jezike i omogućava adaptaciju na određeni zadatak čitljivosti i set podataka. Sistemično usporedbom nekoliko neuralnih arhitektura o broju kriterija i novih kompleta podataka o čitljivosti na dva jezika, ova studija također nudi komplektivnu analizu različitih neuralnih pristupa klasifikaciji čitljivosti. Mi izlažemo njihove snage i slabosti, uspoređujemo njihovu učinku sa trenutnim pristupima klasifikacije stanja umjetnosti na čitljivost, koje u većini slučajeva još uvijek oslanjaju na veliki in ženjering karakteristika, i predlažemo mogućnosti za poboljšanje.', 'ca': "Abstract Presentam un conjunt d'enfocaments neurals noves supervisats i no supervisats per determinar la llegibilitat dels documents. En un entorn no supervisat, utilitzem models de llenguatge neural, mentre que en un entorn supervisat, es testen tres arquitectures diferents de classificació neural. Mostrem que l'enfocament neuronal no supervisat proposat és robust, transferible a través de llengües i permet adaptar-se a una tasca específica de llegibilitat i a un conjunt de dades. A través de la comparació sistemàtica de diverses arquitectures neuronals en una sèrie de punts de referència i nous conjunts de dades de llegibilitat etiquetats en dues llengües, aquest estudi també ofereix una anàlisi completa de diferents enfocaments neuronals a la classificació de llegibilitat. Exposem les seves forces i debilitats, comparam el seu rendiment amb els enfocaments actuals d'última classificació de la llegibilitat, que en la majoria dels casos encara confien en enginyeria extensa de característiques, i proposem possibilitats d'millors.", 'cs': 'Abstrakt Představujeme soubor nových neuronově dohlížených a bez dozoru přístupů pro stanovení čitelnosti dokumentů. V bez dozoru využíváme neuronové jazykové modely, zatímco v dozorovaném prostředí jsou testovány tři různé neuronové klasifikační architektury. Ukazujeme, že navržený neuronový bez dozoru přístup je robustní, přenositelný napříč jazyky a umožňuje adaptaci na konkrétní úlohu čitelnosti a datovou sadu. Systematickým srovnáním několika neuronových architektur na řadě benchmarkových a nových značených datových sad čitelnosti ve dvou jazycích nabízí tato studie také komplexní analýzu různých neuronových přístupů k klasifikaci čitelnosti. Odhalujeme jejich silné a slabé stránky, porovnáváme jejich výkon se současnými klasifikačními přístupy k čitelnosti, které ve většině případů stále spoléhají na rozsáhlé funkční inženýrství, a navrhujeme možnosti zlepšení.', 'bn': 'ডকুমেন্টের পাঠক নির্ধারণের জন্য আমরা একটি সেট নিউরেল পর্যবেক্ষণ এবং সংরক্ষিত উপায় উপস্থাপন করি। অরক্ষিত সেটিংসে আমরা নিউরেল ভাষার মডেল লাভ করি, যদিও পর্যবেক্ষিত সেটে তিনটি ভিন্ন নিউরেল ক্লাসাফিকেশন আর্কিটেক্টার পরীক্ষা কর আমরা দেখাচ্ছি যে প্রস্তাবিত নিউরাল অরক্ষিত পদ্ধতি হচ্ছে সারা ভাষায় পরিবর্তনযোগ্য, এবং একটি নির্দিষ্ট পাঠযোগ্য কাজ এবং তথ্য সে বেনম্যার্ক এবং দুই ভাষায় নতুন লেবেল পাঠযোগ্য তথ্য সংক্রান্ত বেশ কিছু নিউরাল কাঠামোর তুলনায় এই গবেষণাটি বিভিন্ন নিউরেল ক্লাস্ফিকেশনের জন্য বিভ আমরা তাদের শক্তি এবং দুর্বলতা প্রকাশ করি, বর্তমান-শিল্প পরিস্থিতির সাথে তাদের প্রভাবের তুলনা করি, যা পড়তে পারে তাদের পাঠতে পারে, যা বেশীরভাগ ক্ষেত্রে বিশা', 'et': 'Esitleme uudseid neurokontrollitud ja järelevalveta lähenemisviise dokumentide loetavuse määramiseks. Järelevalveta keskkonnas kasutame neurokeele mudeleid, samas kui järelevalveta keskkonnas testitakse kolme erinevat neuroklassifikatsiooni arhitektuuri. Näitame, et kavandatud järelevalveta närvilähenemine on tugev, ülekantav keelte vahel ning võimaldab kohaneda konkreetse loetavuse ülesande ja andmekogumiga. Mitmete neuraalarhitektuuride süstemaatilise võrdluse kaudu mitmete võrdlusaluste ja uute märgistatud loetavuse andmekogumitega kahes keeles pakub see uuring ka põhjalikku analüüsi erinevatest neuraalsetest lähenemisviisidest loetavuse klassifitseerimisele. Avastame nende tugevad ja nõrgad küljed, võrdleme nende tulemuslikkust praeguste tipptasemel loetavuse klassifitseerimise lähenemisviisidega, mis enamikul juhtudel tuginevad endiselt ulatuslikule funktsioonitehnoloogiale, ning pakume välja võimalusi parandusteks.', 'fi': 'Esittelemme joukon uusia neurovalvottuja ja valvomattomia lähestymistapoja asiakirjojen luettavuuden määrittämiseen. Valvonnattomassa ympäristössä hyödynnämme neurokielimalleja, kun taas valvotussa ympäristössä testataan kolmea erilaista neuroluokitusarkkitehtuuria. Osoitamme, että ehdotettu kontrolloimaton neurolähestymistapa on vankka, siirrettävissä eri kielillä ja mahdollistaa mukautumisen tiettyyn luettavuuden tehtävään ja tietoaineistoon. Vertailemalla systemaattisesti useita neuroarkkitehtuureja useista vertailuarvoista ja uusista merkityistä luettavuustietoaineistoista kahdella kielellä tämä tutkimus tarjoaa myös kattavan analyysin eri neurolähestymistavoista luettavuuden luokitteluun. Paljastamme niiden vahvuudet ja heikkoudet, vertaamme niiden suorituskykyä nykyisiin, viimeisimpiin luettavuuden luokittelumenetelmiin, jotka useimmissa tapauksissa edelleen perustuvat laajaan ominaisuussuunnitteluun, ja ehdotamme parannusmahdollisuuksia.', 'sk': 'Predstavljamo nabor novih nevronsko nadzorovanih in nenadzorovanih pristopov za določanje berljivosti dokumentov. V neobzorovanem okolju uporabljamo modele nevronskega jezika, v nadzorovanem okolju pa testiramo tri različne nevronske klasifikacijske arhitekture. Pokazali smo, da je predlagani nevrološki pristop robusten, prenosljiv v vseh jezikih in omogoča prilagajanje določenemu opravilu berljivosti in naboru podatkov. S sistematično primerjavo več nevralnih arhitektur na številnih referenčnih in novih označenih naborih podatkov o berljivosti v dveh jezikih, ta študija ponuja tudi celovito analizo različnih nevralnih pristopov k klasifikaciji berljivosti. Razkrivamo njihove prednosti in slabosti, primerjamo njihovo uspešnost z najsodobnejšimi klasifikacijskimi pristopi k berljivosti, ki se v večini primerov še vedno zanašajo na obsežen inženiring funkcij, in predlagamo možnosti za izboljšave.', 'he': 'אסטרקט אנחנו מציגים קבוצה של גישות חדשות עצביות ששולטות ולא שולטות לקבוע את היכולת לקרוא את המסמכים. במסגרת ללא השגחה, אנו משתמשים בדוגמנים בשפה העצבית, בעוד במסגרת השגחה, שלושה ארכיטקטורות מסווג העצבי שונות נבחנות. אנו מראים שהגישה העצבית המוצעת ללא השגחה היא חזקה, מועברה דרך שפות, ומאפשרת להתאים למשימת קריאות ומערכת נתונים ספציפית. על ידי השוואה שיטתית של מספר ארכיטקטורות עצביות על מספר נקודות רמז וקוראים נתונים חדשים בקריאות בשתי שפות, המחקר הזה גם מציע ניתוח מורכב של גישות עצביות שונות לקריאות. אנו חושפים את כוחותיהם וחלשותיהם, משוואים את ביצועיהם עם גישות מסווג המיוחדות הנוכחיות לקריאה, אשר ברוב המקרים עדיין תלויים בהנדסה מיוחדת, ומצייעים אפשרויות לשיפורים.', 'bo': 'ལམ་ལུགས་གསར་གཏོང་ཞིག་ལ་སྒྲིག་ཡིག་ཆའི་ལྟ་རྟོག་པ་དང་ལྟ་བུའི་བཟོ་བཅོས་སྟངས་མེད་པའི་བཟོ་བཅོས་ཚུ་སྟོན་ཡོད། སྒྲིག་འཛུགས་མེད་པའི་སྒྲིག་སྟངས་ནང་དུ་ང་ཚོའི་ནུས་བྱུང་བའི་སྒེར་གྱི་སྒྲིག་འགོད་ལ་ལག་ལེན་འཐབ་ཀྱི་ཡོད། ང་ཚོས་སྔོན་འཛུགས་བྱས་པའི་དྲ་རྒྱ་སྟངས་ལ་བཟོ་བཅོས་མེད་པའི་ཐབས་ལམ་ནི་སྟབས་བདེ་ཞིག་ཡིན་པ་དང་། སྐད་ཡིག་ཆ་ལ་བསྐྱེད་ཆ By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to readability, which in most cases still rely on extensive feature engineering, and propose possibilities for improvements.', 'ha': "Lalle ne, Mun zo da wani matsayi na amintacce dõmin a ƙaddara karatun takardu. In the tsari da ba'a tsare ba, za'a jarraba misãlai na lugha neural, da kuma a cikin tsarin da aka tsare, an jarraba layin turura uku daban-daban. Tuna nũna cewa da aka buƙata hanyarwa na neural wanda ba'a tsare shi ba ta zama an riƙe, an shige shi a cikin harshen, kuma yana yarda in adadi zuwa wani aikin karatun mai ƙayyade karatun da tsarin data. @ item: inmenu Munã fizge ƙarfinsu da rauni, kuma Muke samfanar da aikin su zuwa halin-danne-sanar na yanzu zuwa karatun, wanda ko da yawa yana dõgara ga masu amfani da muhimmin muhimmi, kuma Munã shawarar da muhimmada masu kyautatawa.", 'jv': 'absolute Nang halaman sing gak nggawe, kéné iso nggawe model luwih-luwih ngono nggawe gerakan, sampeyan karo aturan sing kalah-kalah basan seneng pisan Neral Awak dhéwé ngerasakno ngono hal-hal sing gak bener nggawe gerakan luwih-luwih apik lan ijol-ijol kuwi nggawe gerakan kanggo ngerasakno dadi kejahatan. Daerah sistematik karo sistem sing dibenaanye karo akeh liyane nan karo bench (bench) lan bagian sing dibenalke pergambar data sing dibenalke dhéwé, akeh basa iki dadi wis ngerasakno akeh sampeyan karo akeh nyong langgar sampeyan sing dibenalke kapan neral Awak dhéwé éngak nglanggar nggawe lan ujak-ujak, nggawe gerarangko cara nggawe stad-of-the-arts Sadurunggawe barang nggawe readable, sing ngomong sak basa luwih-ujak sak wis dianggawe lan akeh perusahaan kanggo dianggap'}
{'en': 'Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition', 'ar': 'تحريض PCFG الإحصائي على العمق كنموذج لاكتساب القواعد النحوية البشرية', 'es': 'Inducción estadística de PCFG con límites de profundidad como modelo de adquisición de gramática humana', 'fr': "Induction statistique de PCFG limitée en profondeur comme modèle d'acquisition de la grammaire humaine", 'pt': 'Indução Estatística PCFG Limitada em Profundidade como Modelo de Aquisição de Gramática Humana', 'ja': '人間の文法獲得のモデルとしての深さ制限された統計的PCFG誘導', 'zh': '深度有界计PCFG归为人语法习得模', 'ru': 'Статистическая индукция PCFG с глубинными границами в качестве модели грамматики человека', 'hi': 'मानव व्याकरण अधिग्रहण के एक मॉडल के रूप में गहराई से घिरा सांख्यिकीय PCFG प्रेरण', 'ga': "Ionduchtú PCFG Staidrimh le Doimhneacht mar Mhúnla d'Fháil Gramadaí Daonna", 'hu': 'Mélységkorlátozott statisztikai PCFG indukció mint az emberi nyelvtani beszerzés modellje', 'ka': 'დიბოლოდ დაბრუნებული სტატისტიული PCFG ინდექცია როგორც ადამიანის გრამარის მიღება მოდელი', 'el': 'Στατιστική επαγωγή σε βάθος ως μοντέλο απόκτησης ανθρώπινης γραμματικής', 'it': 'Induzione statistica PCFG legata alla profondità come modello di acquisizione grammaticale umana', 'lt': 'Iš gilumo pagrįsta statistinė PCFG indukcija kaip žmogaus gramos įgijimo pavyzdys', 'kk': 'Адам грамма қабылдау үлгісі ретінде тереңдік шектелген статистикалық PCFG индукциясы', 'mk': 'Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition', 'ml': 'ആഴത്തില്\u200d പരിശോധിക്കപ്പെട്ട പിസിഎഫിജി നിര്\u200dമ്മാണം മനുഷ്യര്\u200d ഗ്രാമാര്\u200d വിവേകത്തിന്റെ മോഡലായിരിക്കും', 'ms': 'Induksi PCFG Statistik Berbatas Kedalaman sebagai Model Akquisition Grammar Manusia', 'mt': 'Induzzjoni tal-PCFG Statistika Konfinata mal-Fond bħala Mudell tal-Akkwist tal-Grammar Uman', 'no': 'Djupnavgrensa statistisk PCFG- induksjon som modell for oppteken av menneskelige grammar', 'ro': 'Inducția statistică PCFG legată de adâncime ca model de achiziție a gramaticii umane', 'pl': 'Indukcja statystyczna PCFG o ograniczonej głębokości jako model pozyskiwania gramatyki ludzkiej', 'mn': 'Гүн гүнзгий хязгаарлагдсан статистикийн PCFG индукцийг хүн төрөлхтний гүнзгий хүлээн авах загвар болгон', 'so': 'Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition', 'si': 'ගොඩක් සීමාවිත සංඛ්\u200dයාත්මක PCFG සීමාව මිනිස්සු ග්\u200dරාම්මාර් ග්\u200dරාම්මාර් අල්ලගන්න මොඩේල් වලින්', 'sv': 'Djupbunden statistisk PCFG induktion som modell för mänsklig grammatik förvärv', 'sr': 'Dubina ograničena statistička indukcija PCFG kao model prihvaćanja ljudskih grama', 'ta': 'ஆழம்- Bounded Statistical PCFG காட்சியின் மாதிரியாக மனித Grammar பெறுதல்', 'ur': 'گھاٹ بوند ڈیٹ سٹیسٹیکل PCFG انڈاکٹ انسان کے گرمار حاصل کی مدل کے طور پر', 'uz': 'Comment', 'vi': 'Trình đầu kết cấu kết gen theo giới hạn của Kết cấu Kết cấu Kết gốc', 'bg': 'Дълбоко-ограничена статистическа индукция като модел на придобиване на човешка граматика', 'nl': 'Dieptebonden Statistische PCFG Inductie als Model van Menselijke Grammaticaverwerving', 'hr': 'Djuboko ograničena statistička indukcija PCFG kao model prikupljanja ljudskih Grammar a', 'de': 'Tiefengebundene statistische PCFG Induktion als Modell der menschlichen Grammatik', 'ko': '심도 있는 유계 통계 PCFG 귀납법은 인류 문법 습득 모델로 삼는다', 'da': 'Dybdebundet statistisk PCFG induktion som model for erhvervelse af human grammatik', 'fa': 'فشار عمیق محدود آمار PCFG به عنوان مدل پذیرش گرم انسان', 'sw': 'Ujenzi wa Takwimu wa Takwimu ya Kiasili ya PCFG kama Model of Upatikanaji wa Kitabu cha Binadamu', 'id': 'Induksi PCFG Statistik Berbatas Kedalaman sebagai Model Acquisition Grammar Manusia', 'tr': 'Gijäniň Taýýarlygy Statistik PCFG Indukçy İnsan Grammar Mazmunlaryň Modeli', 'af': "Djipte- gebreekte Statistiese PCFG Induksie as 'n Model van menslike Grammar Inkrywing", 'sq': 'Indukcioni i PCFG-së Statistike me Kufizim të thellësisë si Model i Akvizionit të Gramave Njerëzore', 'hy': 'Խաղրության սահմանափակված վիճակագրական պոֆԳ ինդուկցիան որպես Մարդկային գրամամային հաղթանակի մոդել', 'az': 'İnsan Grammar Qazanması Modeli kimi, Derinçək Sınır Statistik PCFG Induksyonu', 'bs': 'Duboko ograničena statistička indukcija PCFG kao model prihvaćanja ljudskih Grammar a', 'ca': "Inducció estadística PCFG basada en la profunditat com a model d'adquisició de grama humana", 'am': 'የመስኮት ምርጫዎች', 'et': 'Sügavusega piiratud statistiline PCFG induktsioon kui inimgrammatika omandamise mudel', 'bn': 'গভীর-সীমাবদ্ধ পরিসংখ্যান পিসিএফজি নির্মাণ হিসেবে মানুষ গ্রামার প্রতিক্রিয়ার মডেল হিসেবে', 'fi': 'Syvyys-sidottu tilastollinen PCFG-induktio ihmisen kieliopin hankinnan mallina', 'cs': 'Hloubkově vázaná statistická indukce PCFG jako model akvizice lidské gramatiky', 'jv': 'Attribute', 'sk': 'Globinsko omejena statistična indukcija PCFG kot model pridobivanja človeške slovnice', 'he': 'מערכת PCFG סטטיסטית מוגבלת עמוקה כדוגמא להשיגת גרמה אנושית', 'ha': 'KCharselect unicode block name', 'bo': 'Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition'}
{'en': 'Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech. The article then explores the idea that the difference between simple grammars exhibited by child learners and fully recursive grammars exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the recursive grammars. An implementation of these memory bounds as limits on center embedding in a depth-specific transform of a recursive grammar yields a significant improvement over an equivalent but unbounded baseline, suggesting that this arrangement may indeed confer a learning advantage.', 'ar': 'الخلاصة توضح هذه المقالة نموذجًا بسيطًا لتحريض PCFG مع مجال فئة ثابت يتنبأ بأغلبية كبيرة من حدود المكونات الموثقة ، ويتوقع تسميات تتفق مع ما يقرب من نصف العلامات المكونة المعتمدة على مجموعة بيانات تقييم قياسية للكلام الموجه للأطفال. يستكشف المقال بعد ذلك فكرة أن الاختلاف بين القواعد النحوية البسيطة التي يعرضها المتعلمون الأطفال والقواعد النحوية التكرارية تمامًا التي يعرضها المتعلمون البالغون قد يكون تأثيرًا على زيادة سعة الذاكرة العاملة ، حيث تكون القواعد النحوية الضحلة صورًا مقيدة للقواعد النحوية العودية. يؤدي تنفيذ حدود الذاكرة هذه كحدود على التضمين المركزي في تحويل خاص بعمق لقواعد تكرارية إلى تحسن كبير على خط أساسي مكافئ ولكن غير محدود ، مما يشير إلى أن هذا الترتيب قد يمنح بالفعل ميزة تعليمية.', 'pt': 'Resumo Este artigo descreve um modelo de indução PCFG simples com um domínio de categoria fixo que prevê uma grande maioria de limites de constituintes atestados e prevê rótulos consistentes com quase metade dos rótulos constituintes atestados em um conjunto de dados de avaliação padrão de fala dirigida a crianças. O artigo então explora a ideia de que a diferença entre gramáticas simples exibidas por aprendizes crianças e gramáticas totalmente recursivas exibidas por aprendizes adultos pode ser um efeito do aumento da capacidade de memória de trabalho, onde as gramáticas superficiais são imagens restritas das gramáticas recursivas. Uma implementação desses limites de memória como limites na incorporação do centro em uma transformação específica de profundidade de uma gramática recursiva produz uma melhoria significativa em relação a uma linha de base equivalente, mas ilimitada, sugerindo que esse arranjo pode de fato conferir uma vantagem de aprendizado.', 'es': 'Resumen Este artículo describe un modelo de inducción de PCFG simple con un dominio de categoría fija que predice una gran mayoría de los límites constituyentes atestiguados, y predice etiquetas consistentes con casi la mitad de las etiquetas constituyentes certificadas en un conjunto de datos de evaluación estándar del habla dirigida a niños. El artículo luego explora la idea de que la diferencia entre las gramáticas simples exhibidas por los niños que aprenden y las gramáticas totalmente recursivas exhibidas por los estudiantes adultos puede ser un efecto del aumento de la capacidad de memoria de trabajo, donde las gramáticas superficiales son imágenes restringidas de las gramáticas recursivas. Una implementación de estos límites de memoria como límites en la incrustación central en una transformación específica de profundidad de una gramática recursiva produce una mejora significativa con respecto a una línea de base equivalente pero ilimitada, lo que sugiere que esta disposición puede conferir una ventaja de aprendizaje.', 'fr': "Résumé Cet article décrit un modèle d'induction PCFG simple avec un domaine de catégorie fixe qui prédit une grande majorité des limites de constituants attestées, et prédit des étiquettes cohérentes avec près de la moitié des étiquettes constituantes attestées sur un ensemble de données d'évaluation standard de la parole dirigée par l'enfant. L'article explore ensuite l'idée que la différence entre les grammaires simples présentées par les enfants apprenants et les grammaires entièrement récursives présentées par les apprenants adultes peut être un effet de l'augmentation de la capacité de mémoire de travail, les grammaires superficielles étant des images contraintes des grammaires récursives. Une implémentation de ces limites de mémoire en tant que limites de l'intégration centrale dans une transformation spécifique à la profondeur d'une grammaire récursive produit une amélioration significative par rapport à une base équivalente mais illimitée, suggérant que cet arrangement peut effectivement conférer un avantage d'apprentissage.", 'ja': '要約この記事では、認証された構成要素の境界の大部分を予測し、子供向けスピーチの標準評価データセット上の認証された構成要素のラベルのほぼ半数と一致するラベルを予測する、固定カテゴリドメインを有する単純なPCFG誘導モデルについて説明します。その後、この記事では、児童学習者によって示される単純な文法と、成人学習者によって示される完全再帰文法の違いは、浅い文法が再帰文法の制約されたイメージである作業記憶容量の増加の効果である可能性があるという考えを探求する。再帰的な文法の深さ固有の変換への中心埋め込みの制限としてのこれらのメモリ境界の実装は、同等であるが境界のないベースラインよりも有意な改善をもたらし、この配置が実際に学習の利点を与え得ることを示唆する。', 'hi': 'सार यह आलेख एक निश्चित श्रेणी डोमेन के साथ एक साधारण PCFG प्रेरण मॉडल का वर्णन करता है जो सत्यापित घटक सीमाओं के एक बड़े बहुमत की भविष्यवाणी करता है, और बच्चे-निर्देशित भाषण के मानक मूल्यांकन डेटा सेट पर लगभग आधे सत्यापित घटक लेबल के अनुरूप लेबल की भविष्यवाणी करता है। लेख तब इस विचार की पड़ताल करता है कि बाल शिक्षार्थियों द्वारा प्रदर्शित सरल व्याकरणों और वयस्क शिक्षार्थियों द्वारा प्रदर्शित पूरी तरह से पुनरावर्ती व्याकरणों के बीच का अंतर कार्यशील स्मृति क्षमता को बढ़ाने का प्रभाव हो सकता है, जहां उथले व्याकरण पुनरावर्ती व्याकरणों की सीमित छवियां हैं। पुनरावर्ती व्याकरण के गहराई-विशिष्ट रूपांतरण में केंद्र एम्बेडिंग पर सीमा के रूप में इन स्मृति सीमाओं का कार्यान्वयन एक समकक्ष लेकिन असीमित आधार रेखा पर एक महत्वपूर्ण सुधार पैदा करता है, यह सुझाव देता है कि यह व्यवस्था वास्तव में एक सीखने का लाभ प्रदान कर सकती है।', 'zh': '摘要本言简PCFG归模,有定域,可测绝大多数已成分界,并占与童子导向语音准估数集上近一半已分标签一般。 然后讨论此说,童子之学者简语法与成人学者全递归语法之间,或增记能之化,其浅语法递归语法之约束图像也。 以记界为递归语法之深特定变中嵌之限,比于等效而无界之基线,显而改之,明其可赋也。', 'ru': 'Реферат Эта статья описывает простую модель индукции PCFG с фиксированной областью категории, которая предсказывает подавляющее большинство заверенных границ составляющих и предсказывает метки, соответствующие почти половине заверенных меток составляющих на стандартном наборе данных оценки речи, направленной на ребенка. Затем в статье исследуется идея о том, что разница между простыми грамматиками, демонстрируемыми детьми-учащимися, и полностью рекурсивными грамматиками, демонстрируемыми взрослыми учащимися, может быть следствием увеличения рабочей емкости памяти, где неглубокие грамматики являются ограниченными изображениями рекурсивных грамматик. Реализация этих ограничений памяти в качестве ограничений на встраивание центра в специфическое для глубины преобразование рекурсивной грамматики дает значительное улучшение по сравнению с эквивалентной, но неограниченной базовой линией, предполагая, что это расположение действительно может дать преимущество в обучении.', 'ga': 'Coimriú Déanann an t-alt seo cur síos ar shamhail ionduchtaithe PCFG simplí le fearann catagóir seasta a thuar tromlach mór de theorainneacha na gcomhábhar deimhnithe, agus a thuar lipéid atá comhsheasmhach le beagnach leath de na lipéid comhábhar deimhnithe ar thacar caighdeánach sonraí meastóireachta de chaint leanaí-dhírithe. Scrúdaíonn an t-alt ansin an smaoineamh go bhféadfadh an difríocht idir gramadach shimplí a thaispeánann foghlaimeoirí leanaí agus gramadach lánathfhillteach a thaispeánann foghlaimeoirí fásta a bheith ina éifeacht ar mhéadú cumas cuimhne oibre, áit a bhfuil na gramadach éadomhain ina n-íomhánna srianta de na gramadach athchúrsach. Má chuirtear na teorainneacha cuimhne seo i bhfeidhm mar theorainneacha ar neadú lárionad i gclaochlú doimhneacht-shonrach ar ghramadach athfhillteach tagann feabhas suntasach ar bhunlíne choibhéiseach ach gan teorainn, rud a thugann le tuiscint go bhféadfadh buntáiste foghlama a bheith ag an socrú seo.', 'ka': 'აბსტრაქტიკური ამ წესტილის გამოსახულება მარტივი PCFG ინდიქციის მოდელი, რომელიც განსახულებელია მნიშვნელოვანი კოსტუტენტის უფრო დიდი ფართობის ზომის, და განსახულებელია მარტივი კოსტუტენტის ნახევარი მონიშვნელოვ მაგალითად მისი აღმოჩენა იდეა, რომ ბავშვების სწავლებელი და უფრო რეკურსიური გრამის განსხვავება, რომელიც განსხვავებულია, შეიძლება იყოს მუშაობის მეხსიერების განსხვავება, სადაც ცოტა გრამიმარები რეკურსიური გრამიმარების გამოსახ ამ მეხსიერის განმავლობა როგორც ცენტრის განმავლობაში, როგორც განმავლობაში განმავლობაში განმავლობაში განმავლობაში განმავლობაში განმავლობაში განმავლობაში, განმავლობაში მნიშვნელოვანი განმავლობაში, მაგრამ განმავლობაში განმავლობაში არ განმა', 'hu': 'Absztrakt Ez a cikk egy egyszerű PCFG indukciós modellt ír le rögzített kategóriás tartománnyal, amely a tanúsított alkotóelemek határainak nagy többségét előrejelzi, és a tanúsított alkotóelemek közel felének megfelelő címkéket előrejelzi a gyermek-irányított beszéd standard értékelési adatkészletén. A cikk azt a gondolatot vizsgálja fel, hogy a gyermek tanulók által kiállított egyszerű nyelvtanfolyamok és a felnőtt tanulók által kiállított teljesen rekurzív nyelvtanfolyamok közötti különbség hatással lehet a munkamemória kapacitásának növelésére, ahol a sekély nyelvtanfolyamok korlátozott képek a rekurzív nyelvtanfolyamokról. Ezeknek a memóriakorlátoknak a rekurzív nyelvtan mélységspecifikus átalakításába történő középső beágyazásának korlátaiként való megvalósítása jelentős javulást eredményez az egyenértékű, de korlátlan alaphoz képest, ami arra utal, hogy ez az elrendezés valóban tanulási előnyt biztosíthat.', 'el': 'Περίληψη Αυτό το άρθρο περιγράφει ένα απλό μοντέλο επαγωγής με έναν σταθερό τομέα κατηγοριών που προβλέπει τη μεγάλη πλειοψηφία των επιβεβαιωμένων ορίων συστατικών, και προβλέπει ετικέτες συμβατές με σχεδόν τις μισές πιστοποιημένες ετικέτες συστατικών σε ένα τυποποιημένο σύνολο δεδομένων αξιολόγησης της ομιλίας κατευθυνόμενης από παιδιά. Στη συνέχεια, το άρθρο διερευνά την ιδέα ότι η διαφορά μεταξύ απλών γραμματικών που εκτίθενται από παιδιά μαθητές και πλήρως αναδρομικών γραμματικών που εκτίθενται από ενήλικες μαθητές μπορεί να είναι αποτέλεσμα αύξησης της ικανότητας μνήμης εργασίας, όπου οι ρηχές γραμματικές είναι περιορισμένες εικόνες των αναδρομικών γραμματικών. Μια εφαρμογή αυτών των ορίων μνήμης ως ορίων για την κεντρική ενσωμάτωση σε έναν μετασχηματισμό ειδικής στο βάθος μιας αναδρομικής γραμματικής δίνει μια σημαντική βελτίωση σε σχέση με μια ισοδύναμη αλλά απεριόριστη βάση, υποδηλώνοντας ότι αυτή η ρύθμιση μπορεί πράγματι να δώσει ένα μαθησιακό πλεονέκτημα.', 'it': "Questo articolo descrive un semplice modello di induzione PCFG con un dominio di categoria fissa che prevede una grande maggioranza dei confini costituenti attestati e prevede etichette coerenti con quasi la metà delle etichette costituenti attestate su un set di dati di valutazione standard del discorso diretto da bambino. L'articolo esplora poi l'idea che la differenza tra grammatiche semplici esposte da studenti bambini e grammatiche completamente ricorsive esposte da studenti adulti può essere un effetto di aumento della capacità di memoria di lavoro, dove le grammatiche superficiali sono immagini vincolate delle grammatiche ricorsive. L'implementazione di questi limiti di memoria come limiti all'incorporamento centrale in una trasformazione specifica della profondità di una grammatica ricorsiva produce un miglioramento significativo rispetto a una linea di base equivalente ma illimitata, suggerendo che questa disposizione può effettivamente conferire un vantaggio di apprendimento.", 'lt': 'Abstraktas Šiame straipsnyje aprašomas paprastas PCFG indukcijos modelis su fiksuotos kategorijos domenu, kuris numato didelę daugumą patvirtintų sudedamųjų dalių ribų ir numato etiketes, atitinkančias beveik pusę patvirtintų sudedamųjų dalių etiketių standartiniame vaikų orientuotos kalbos vertinimo duomenų rinkinyje. Šiame straipsnyje nagrinėjama idėja, kad skirtumas tarp paprastų gramatikų, kurias parodo vaikai, ir visiškai rekursyvių gramatikų, kurias parodo suaugusieji, gali turėti įtakos didinant darbo atminties pajėgumus, kai plokščios gramatikos yra ribotos rekursyvių gramatikų vaizdais. Įgyvendinant šias atminties ribas kaip centro ribas, įterpiamas į konkrečią grąžą keičiančią atkuriamąją gramatiką, gerokai pagerėja lygiavertė, bet neribota bazė, ir tai rodo, kad šis susitarimas gali iš tikrųjų suteikti mokymosi pranašumą.', 'kk': 'Абстракты Бұл мақала қарапайым PCFG индукциялық моделін бағытталған санаттар доменіне таңдайды. Оның көпшілігінің көпшілігін таңдайды, және белгілері бағытталған сөздердің стандартты оқу деректер жиынында бар жартынан жартынан келеді. Мақаланың содан кейін балалар оқытушыларының кәдімгі граммалардың арасындағы айырмашылығын жұмыс істеу мүмкіндігі болуы мүмкін, қайталанатын граммалардың кескіндерін шектеу мүмкін. Бұл жады шектерін ортасында қайталанатын грамматиканың түрлі түрлі түрлендіру үшін шектері ретінде іске асыру керек, бірақ шектелмеген негізгі сызықтың шектері болады. Бұл түрлендірімі оқыту мүмкіндігін көрсетеді.', 'ms': 'Abstrakt Artikel ini menggambarkan model induksi PCFG sederhana dengan domain kategori tetap yang meramalkan kebanyakan sempadan konstitusi yang disahkan, dan meramalkan label yang konsisten dengan hampir separuh label konstitusi yang disahkan pada set data penilaian piawai bagi ucapan yang direka kanak-kanak. Artikel kemudian mengeksplorasi idea bahawa perbezaan antara grammar sederhana yang dipaparkan oleh pelajar kanak-kanak dan grammar yang sepenuhnya rekursif yang dipaparkan oleh pelajar-pelajar dewasa mungkin merupakan kesan untuk meningkatkan kapasitas memori kerja, di mana grammar rendah adalah imej yang dikuasai bagi grammar rekursif. Pelaksanaan sempadan memori ini sebagai had pada penyembelihan tengah dalam perubahan khusus kedalaman grammar rekursif memberikan peningkatan yang signifikan atas dasar yang sama tetapi tidak terbatas, menyarankan bahawa perjanjian ini mungkin memberikan keuntungan pembelajaran.', 'mk': 'Апстракт Оваа статија опишува едноставен модел на индукција на PCFG со домен на фиксна категорија кој предвидува големо мнозинство од потврдените граници на конститунтите, и предвидува етикети којашто се совпаѓаат со скоро половина од потврдените етикети на конститунтите на стандардниот набор на податоци за проценка на говор Во статијата потоа се истражува идејата дека разликата помеѓу едноставните граматки изложени од учениците на деца и целосно рекурсивните граматки изложени од возрасните ученици може да биде ефект на зголемување на капацитетот на работна меморија, каде што плошките граматки се ограничени слики од рекурсивните граматки Имплементацијата на овие мемориски граници како граници на центарот вграден во длабочина специфична трансформација на рекурсивна граматика предизвика значително подобрување во однос на еквивалентна, но неограничена основа, што сугерира дека овој аранжман може навистина да даде предност за учење', 'ml': 'അസ്ട്രാക്റ്റ് ചെയ്യുക ഈ ലേഖനം ഒരു നിശ്ചയിച്ച വിഭാഗത്തിന്റെ ഡൊമെയിനുമായി എളുപ്പമായ പിസിഎഫ്ജി ഇന്\u200dഡര്\u200dഷന്\u200d മോഡല്\u200d വിശദീകരിക്കുന്നു. കുട്ടികള്\u200d നേര്\u200dവഴിയില്\u200d സംസാരിക്കുന് പിന്നെ ആ രേഖയില്\u200d പരിശോധിക്കുന്നത് കുട്ടികള്\u200d പഠിക്കുന്ന കുട്ടികള്\u200d കാണിക്കുന്ന വ്യത്യാസവും പൂര്\u200dണ്ണമായ വിവരങ്ങള്\u200d കാണിക്കുന്ന മുതിര്\u200dന്നിരിക്കുന്ന ഗ്രാമാര്\u200d ഈ മെമ്മറിയുടെ അതിരുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത് ഒരു റിസ്റ്റര്\u200dച്ചിവ് ഗ്രാമാറ്ററിന്റെ ആഴത്തില്\u200d പ്രത്യേകിച്ച് മാറ്റുന്നതിന്റെ കേന്ദ്രത്തിലെ അതിരുകളായി അത', 'mt': 'Abstrat Dan l-artikolu jiddeskrivi mudell sempliċi ta’ induzzjoni tal-PCFG b’dominju ta’ kategorija fissa li jipprevedi maġġoranza kbira ta’ konfini kostitwenti attestati, u jipprevedi tikketti konsistenti ma’ kważi nofs it-tikketti kostitwenti attestati fuq sett standard ta’ dejta ta’ evalwazzjoni ta’ diskors dirett mit-tfal. L-artikolu mbagħad jesplora l-idea li d-differenza bejn grammi sempliċi esposti minn tfal li qed jitgħallmu u grammi kompletament rikorrenti esposti minn studenti adulti tista’ tkun effett ta’ żieda fil-kapaċità tal-memorja tax-xogħol, fejn il-grammi baxxi huma stampi ristretti tal-grammi rikorrenti. Implimentazzjoni ta’ dawn il-limiti tal-memorja bħala limiti fuq l-inkorporazzjoni taċ-ċentru fi trasformazzjoni speċifika għall-fond ta’ grammar rikorrenti twassal għal titjib sinifikanti fuq linja bażi ekwivalenti iżda mhux limitata, li jissuġġerixxi li dan l-arranġament jista’ tabilħaqq jagħti vantaġġ ta’ tagħlim.', 'mn': 'Абсолют Энэ баримт энгийн PCFG үйлдвэрлэлийн загварыг хүүхдүүд рүү дамжуулагдсан хэлбэрийн мэдээлэл дээр бараг хагас баталсан байгуулагдсан загвартай тайлбарладаг. Үүний дараа нь хүүхдийн сурагчид харуулсан энгийн граммарын ялгаа, насанд сурагчид харуулсан бүрэн дахин дахин дахин давтагдсан граммарын ялгаа нь ажиллах санамжийн чадварыг нэмэгдүүлэх нөлөө байж болно. Граммар нь дахин давтагдсан граммарын зураг хязгаарлагддаг. Эдгээр санамжийн хязгаарын хэрэглээ төвд гүн гүнзгий тодорхойлолтой грамматикийн өөрчлөлт гэх мэт хязгаарын хэмжээсүүд нь тэнцүү гэхдээ хязгааргүй суурь шугам дээр маш чухал сайжруулах боломжтой болгодог.', 'no': 'Abstrakt Denne artikkelen beskriver ein enkel PCFG- induksjonsmodul med ein fast kategoridomene som foregår ein stor fleire av atteste konstitusjonsgrenser, og foregår merkelappar som er konsistent med nesten halvparten av atteste konstitusjonsmerkelappar på ein standardvalgeringsdata sett av barneskeførte tale. Artikkelen så utforskar ideen at forskjellen mellom enkle grammar som vert viste av barna lærarar og fullstendig rekursiv grammar som vert viste av voksne lærarar kan vera ein effekt av å økja arbeidspapørsmålet, der dei fleire grammare er begrenset av dei rekursivne grammarene. Ein implementasjon av desse minningsgrensene som grenser på sentrum som innebygger i ein dybspesifikk transformasjon av eit rekursivt grammar fører til ein betydelig forbedring over eit ekvivalent, men ugjennomsiktig grunnlinje, som tyder på at denne arrangeasjonen kan vere verkeleg gjennomsikt på læring.', 'pl': 'Streszczenie Niniejszy artykuł opisuje prosty model indukcji PCFG ze stałą domeną kategorii, która przewiduje znaczną większość zaświadczonych granic składników oraz przewiduje etykiety zgodne z prawie połową zaświadczonych etykiet składników na standardowym zbiorze danych oceny mowy kierowanej dzieckiem. Następnie artykuł bada ideę, że różnica między gramatykami prostymi wykazywanymi przez uczniów dzieci a gramatykami w pełni rekursywnymi wykazywanymi przez dorosłych uczniów może być efektem zwiększenia pojemności pamięci roboczej, gdzie gramatyki płytkie są ograniczone obrazy gramatyki rekursywnych. Implementacja tych granic pamięci jako ograniczeń osadzenia centralnego w specyficznej głębokości transformacji gramatyki rekursywnej daje znaczącą poprawę nad równoważną, ale nieograniczoną bazą podstawową, sugerując, że układ ten może rzeczywiście przynieść korzyść uczenia się.', 'ro': 'Acest articol descrie un model simplu de inducție PCFG cu un domeniu de categorie fixă care prezice o mare majoritate a limitelor constitutive atestate și prezice etichete compatibile cu aproape jumătate din etichetele constitutive atestate pe un set standard de date de evaluare a discursului orientat spre copii. Articolul explorează apoi ideea că diferența dintre gramaticile simple expuse de elevii copii și gramaticile complet recursive expuse de elevii adulți poate fi un efect de creștere a capacității memoriei de lucru, în cazul în care gramaticile superficiale sunt imagini constrânse ale gramaticilor recursive. Implementarea acestor limite de memorie ca limite pentru încorporarea centrului într-o transformare specifică adâncimii a unei gramatici recursive produce o îmbunătățire semnificativă față de o bază echivalentă, dar nelimitată, sugerând că acest aranjament poate conferi într-adevăr un avantaj de învățare.', 'sr': 'Apstrakt Ovaj članak opisuje jednostavan model indukcije PCFG sa fiksnim domenom kategorije koja predviđa većinu potvrđenih granica sastavnih sastavnika i predviđa etikete koje su u skladu sa skoro polovinom potvrđenih etiketa sastavnih sastavnika na standardnom setu podataka za procjenu reči na djecu. Članak onda istražuje ideju da razlika između jednostavnih gramara koje pokazuju učitelji deteta i potpuno rekursivnih gramara koje pokazuju odrasli učitelji može biti uticaj povećanja kapaciteta rada, gde su plitke gramare ograničene slike rekursivnih gramara. Implementacija tih granica pamćenja kao ograničenja centra ugrađenog u dubinu specifičnoj transformaciji rekursivne gramatike pruža značajno poboljšanje nad ekvivalentnim ali neograničenim početnim linijama, ukazujući na to da ovaj aranžman može zaista da pruži prednost učenja.', 'sv': 'Sammanfattning Denna artikel beskriver en enkel PCFG induktionsmodell med en fast kategoridomän som förutspår en stor majoritet av bestyrkade beståndsdelsgränser, och förutspår etiketter som överensstämmer med nästan hälften av bestyrkade beståndsdelar på en standardutvärderingsdata för barnriktat tal. Artikeln undersöker sedan idén att skillnaden mellan enkla grammater som visas av barn elever och fullt rekursiva grammater som visas av vuxna elever kan vara en effekt av att öka arbetsminneskapaciteten, där de ytliga grammaterna är begränsade bilder av rekursiva grammater. En implementering av dessa minnesgränser som gränser för centrerad inbäddning i en djupspecifik transformation av en rekursiv grammatik ger en betydande förbättring jämfört med en motsvarande men obegränsad baslinje, vilket tyder på att detta arrangemang verkligen kan ge en inlärningsförmåga.', 'si': 'අවස්ථාවක් මේ ලේඛනය විස්තර කරනවා සාමාන්\u200dය PCFG විස්තර ප්\u200dරමාණය සඳහා ස්ථිර ප්\u200dරමාණයක් තියෙන්නේ, ඒ වගේම ලේබල් ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහ The letter then Explores the idea that the Diffection of Easy Grammmars exhibited by baby learnrs and fully reclaimed Grammmars exhibited by grew learnrs may be an Impact of Incompressing Working Note Captivity, where the shallow Grammmars are Restrained Pictures of the Redosive Grammmars. මේ මතක සීමාවක් සීමාවක් සීමාවක් විදියට සීමාවක් වෙනුවෙන් සීමාවක් වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක ව්\u200dයාපෘතියක් ගොඩක් විශේෂ ව්\u200dයාපෘතියක් වල', 'so': "Qabsi Qoraalka kadibna wuxuu ka baaraandegaa fikrada in kala duwanaanshaha barbaarinta carruurta iyo barbaarinta si buuxda ah lagu tuso ardayda qaangaarka ah ay saameyn u yeelan karto kordhidda awoodda xasuusta shaqada, taas oo ay ku qoran karto sawirro sawir lagu soo celiyo. Si loo sameeyo xuduudahan xasuusta sida xadhig ku qoran xarunta hoose-gaar ah oo lagu beddelayo grammar dib u soo celinta ayaa ka soo bixinaya hagaajin aad u weyn, si isku mid ah laakiin a an xad lahayn, waxaana looga jeedinayaa in heshiiskaas hubaal u yeelan karo faa'iido waxbarasho.", 'ta': 'நீக்கு பின்னர் இந்த கட்டுரை தெரிந்து கொள்ளும் நினைவில் வேலை செய்யும் சிறுவர்கள் காட்டப்பட்டுள்ள மாறுபாடுகள் மற்றும் முழுமையான மாணவர்கள் காட்டப்பட்டுள்ள மாறுபாடுகளுக் இந்த நினைவகத்தின் எல்லைகள் செயல்படுத்தப்படும் ஆழம்- குறிப்பிட்ட மாற்றம் ஒரு திரும்ப வரிசையில் உள்ள மையத்தில் உள்ள வரம்பு ஆகும் ஆனால் வரம்பில்லாத அடிப்படைக்கோட்டி', 'ur': 'یہ لکھا ایک ساده PCFG اینڈیکشن موڈل کو ایک ثابت کاٹی ڈومین کے ساتھ بیان کرتا ہے جو ایک بڑی گواہی دینے والی محدودیت کی زیادہ زیادہ محدودیت کی پیش بینی کرتا ہے اور لیبل کی پیش بینی کرتا ہے کہ شامل آدھی گواہی دینے والی محدودیت لابل کے مطابق ایک استاندارڈیٹ ار اس کے بعد لکھا ہوا یہ خیال دیکھتا ہے کہ بچوں کی تعلیم کرنے والوں کے ذریعہ ساده گرامر کے درمیان تفاوت اور بالکل تکرار کی گرامر کے ذریعہ سے نمایش کی جاتی ہے وہ کامیابی قابلیت بڑھنے کا اثر ہے جہاں کم گرامر دوبارہ گرامر کی تصاویر محدود ہوتی ہیں۔ یہ یادگاری حدود کی تعمیر کے مطابق مرکز کے اندر سے محدودیت ہیں جو ایک دوبارہ مطابق گراماری کی عمیق تغییر میں داخل ہوتی ہیں، ایک برابر لیکن غیر محدودیت بنیس لین کے ذریعے ایک بڑی زیادتی تغییر دیتی ہے، اس کی پیش کرتی ہے کہ یہ تعمیر یقیناً ایک سیکھنے', 'vi': 'Trừu tượng Bài này mô tả một mô hình cảm ứng PCFG đơn giản với một miền phân loại cố định, nó dự đoán đa số các ranh giới cấu tạo đã được xác thực, và nó dự đoán các nhãn tương ứng với gần nửa các nhãn ký tự đã được xác thực trên một tập tin dữ liệu tiêu chuẩn của ngôn ngữ hướng trẻ em. Bài báo nghiên cứu ý tưởng rằng sự khác biệt giữa các tạp chí đơn giản được trưng bày bởi những đứa học trò trẻ và các tạp chí thư lưu động đầy đủ của những đứa học giả người lớn có thể gây ra hiệu quả của việc tăng cường bộ nhớ hoạt động, nơi các tạp chí nông cạn bị giới hạn ảnh của các tạp âm. Một sự hiện hiện được những hành trí tượng này với những được chỉ dẫn đến một cách thay đổi chính xác của một cháo lễ vẫn còn có một điểm khác tương tự nhưng chưa được đượ', 'uz': "@ info: whatsthis Keyin maqola oddiy grammatika o'rganish va o'smirlar o'rganishlar bilan o'rganilgan o'zgarishlar orasidagi o'zgarishlar orasidagi o'zgarishni o'rganish mumkin, xotira qobiliyatni ko'payishini xotiraga oshirish mumkin. Bu yerda kichkina grammatikalar qayta grammatika rasmlarni qanday tartib beradi. Ushbu xotira chegaralarini qaytarish grammatika qo'shimcha qo'shimcha chegaralarda ishga tushirish imkoniyatini o'zgartirish mumkin, lekin chegara boʻlmaydi, bu amalni o'rganish imkoniyatini bajarishi mumkin.", 'bg': 'Резюме Тази статия описва прост индукционен модел с фиксирана категория домейн, който прогнозира голяма част от утвърдените граници на съставните елементи и прогнозира етикети, съответстващи на почти половината утвърдени съставни етикети върху стандартен набор от данни за оценка на речта, насочена към деца. След това статията изследва идеята, че разликата между простите граматики, показани от деца, и напълно рекурсивните граматики, показани от възрастни, може да бъде ефект от увеличаването на капацитета на работната памет, където плитките граматики са ограничени изображения на рекурсивните граматики. Прилагането на тези граници на паметта като ограничения за вграждане на центъра в специфично за дълбочина трансформация на рекурсивна граматика води до значително подобрение спрямо еквивалентна, но неограничена базова линия, което предполага, че това подреждане наистина може да даде предимство за учене.', 'da': 'Denne artikel beskriver en simpel PCFG induktionsmodel med et fast kategoridomæne, der forudsiger et stort flertal af attesterede bestanddele grænser, og forudsiger etiketter, der svarer til næsten halvdelen af attesterede bestanddele etiketter på et standardevalueringsdatasæt af børnerettet tale. Artiklen undersøger derefter tanken om, at forskellen mellem enkle grammatier udstillet af børneelever og fuldt rekursive grammatier udstillet af voksne elever kan være en effekt af at øge arbejdshukommelseskapaciteten, hvor de overfladiske grammatier er begrænsede billeder af rekursive grammatier. En implementering af disse hukommelsesgrænser som grænser for midterindlejring i en dybdespecifik transformation af en rekursiv grammatik giver en betydelig forbedring i forhold til en tilsvarende, men ubegrænset baseline, hvilket tyder på, at dette arrangement faktisk kan give en læringsfordel.', 'nl': "Abstract Dit artikel beschrijft een eenvoudig PCFG inductiemodel met een vast categoriedoomein dat een grote meerderheid van de geteste constitutionsgrenzen voorspelt, en labels voorspelt die consistent zijn met bijna de helft van de geteste constitution labels op een standaard evaluatie dataset van kindergerichte spraak. Het artikel onderzoekt vervolgens het idee dat het verschil tussen eenvoudige grammatica's tentoongesteld door kinderen en volledig recursieve grammatica's tentoongesteld door volwassenen een effect kan zijn van het verhogen van het werkgeheugen capaciteit, waarbij de ondiepe grammatica's beperkte afbeeldingen van de recursieve grammatica's zijn. Een implementatie van deze geheugengrenzen als limieten voor centruminbedding in een dieptespecifieke transformatie van een recursieve grammatica levert een significante verbetering op ten opzichte van een equivalente maar onbeperkte baseline, wat suggereert dat deze regeling inderdaad een leervoordeel kan opleveren.", 'hr': 'Abstrakt Ovaj članak opisuje jednostavan model indukcije PCFG-a s domenom određene kategorije koji predviđa većinu potvrđenih ograničenja sastojaka i predviđa etikete koje odgovaraju skoro pola potvrđenih etiketa sastojaka na standardnom setu podataka za procjenu dječjeg govora. Članak onda istražuje ideju da razlika između jednostavnih gramara izloženog učiteljima djece i potpuno rekursivnih gramara izloženog odraslim učiteljima može biti učinka povećanja kapaciteta rada, gdje plitke gramare ograničavaju slike rekursivnih gramara. Implementacija tih granica sjećanja kao ograničenja središta ugrađenog u duboko specifičnom transformaciji rekursivne gramatike pruža značajno poboljšanje nad ekvivalentnim ali neograničenim početnim linijom, ukazujući na to da ovaj dogovor može zaista pružiti prednost učenja.', 'de': 'Dieser Artikel beschreibt ein einfaches PCFG-Induktionsmodell mit einer festen Kategoriedomäne, das eine große Mehrheit der attestierten Komponentengrenzen vorhersagt und Etiketten vorhersagt, die mit fast der Hälfte der attestierten Komponentenbeschriftungen auf einem Standard-Auswertungsdatensatz kindgesteuerter Sprache übereinstimmen. Der Artikel untersucht dann die Idee, dass der Unterschied zwischen einfachen Grammatiken, die von Kindern gezeigt werden, und vollständig rekursiven Grammatiken, die von erwachsenen Lernenden gezeigt werden, ein Effekt der Erhöhung der Arbeitsgedächtniskapazität sein kann, wobei die flachen Grammatiken eingeschränkte Bilder der rekursiven Grammatiken sind. Eine Implementierung dieser Speichergrenzen als Begrenzung der Center-Einbettung in eine tiefenspezifische Transformation einer rekursiven Grammatik führt zu einer signifikanten Verbesserung gegenüber einer äquivalenten, aber unbegrenzten Baseline, was darauf hindeutet, dass diese Anordnung tatsächlich einen Lernvorteil verschaffen kann.', 'fa': 'این مقاله یک مدل ساده تولید PCFG را با یک دامنه\u200cی مقاله ثابت می\u200cکند که بسیاری از محدوده\u200cهای ثابت شده را پیش\u200cبینی می\u200cکند، و برچسب\u200cها را پیش\u200cبینی می\u200cکند که با تقریباً نصف برچسب\u200cهای مقاله ثابت شده در یک مجموعه داده\u200cهای ارزیابی استاندارد از سخنرانی که به کود بعد این مقاله ایده را تحقیق می\u200cکند که تفاوت بین گرامرات ساده\u200cای که توسط دانش\u200cآموزان کودک و گرامرات کاملاً تکرار کننده\u200cای که توسط دانش\u200cآموزان بزرگسالان نشان داده می\u200cشود ممکن است اثر افزایش توانایی حافظه کار باشد، جایی که گرامرات کوچک تصاویر گرامرات تکرار کننده عملکرد این محدودیت حافظه به عنوان محدودیت مرکزی که در یک تغییر عمیق ویژه\u200cای از یک گرامی تکرار می\u200cکند، بهترین بزرگی بر یک خط بنیادی مشابه می\u200cکند ولی غیرمحدودیت می\u200cکند، پیشنهاد می\u200cدهد که این ترتیب واقعاً ممکن است فایده یادگیری را ارائه', 'id': 'Abstrakt Artikel ini menjelaskan model induksi PCFG sederhana dengan domain kategori tetap yang memprediksi kebanyakan batas konstitusi yang disahkan, dan memprediksi label konsisten dengan hampir setengah dari label konstitusi yang disahkan pada set data evaluasi standar dari pidato yang direksi anak. Artikel kemudian mengeksplorasi ide bahwa perbedaan antara gramatika sederhana yang diungkapkan oleh pelajar-pelajar anak dan gramatika yang sepenuhnya rekursif yang diungkapkan oleh pelajar-pelajar dewasa mungkin merupakan efek dari meningkatkan kapasitas memori kerja, di mana gramatika rendah adalah gambar-gambar gramatika rekursif. Sebuah implementasi batas memori ini sebagai batas pada pusat memasukkan dalam transformasi kedalaman-spesifik grammar rekursif memberikan peningkatan yang signifikan atas dasar yang sama tetapi tidak terbatas, menyarankan bahwa perjanjian ini mungkin benar-benar memberikan keuntungan belajar.', 'sw': 'Makala hii inaelezea modeli rahisi ya uzalishaji wa PCFG yenye kiwango maalumu ambacho kinatabiri idadi kubwa ya mipaka ya kikao, na inatabiri alama zinazomilikiwa na takribani nusu ya mabango ya vigogo vinavyothibitishwa kwenye seti ya taarifa za uchunguzi wa takwimu zinazoongozwa na watoto. Makala hiyo baadae inagundua wazo kwamba tofauti kati ya gramma rahisi zilizoonyeshwa na wanafunzi wa watoto na vipiga vya vifaa vya kuwasha wanafunzi wazima vinaweza kuwa athari ya kuongezeka kwa uwezo wa kumbukumbu za kazi, ambapo gramma hizo zenye vibaya vimewekwa vizuizini picha za gramma zinazojifunza. Kutekelezwa kwa mipaka ya kumbukumbu hizi kama mipaka ya kituo kinachoingia katika mabadiliko ya kina mahususi ya gramu ya kurejesha yanaleta maendeleo makubwa zaidi ya msingi wa kisasa lakini hauna mipaka, ikionyesha kwamba mkutano huu unaweza kuleta faida ya kujifunza.', 'tr': 'Abstrakt Bu makala sabit kategori domeny ile basit bir PCFG indüksiýa modelini tanaýar ve etiketleri çagalar yönünde durumly değerlendirilen hasaplar takmynanyr. Soňra makala çykarýar, çaga öwrenmegi tarapyndan görkezilen basit grammarlaryň tapawudyny we uly öwrenmegi tarapyndan görkezilen grammarlaryň üýtgeýän ýagdaýynyň ukybyny artmagyň täsiri bolup biler. Garyp grammarlaryň(grammarlaryň) gaýtalanany suratlaryna sykylan bolup biler. Bu hafıza sınırlarının derinliklerinde belli bir gramatik düzenlemesinin orta sınırları olarak sürdürmesi ekvivalent ve sınırlı bir tabanlı üzerinde önemli bir gelişme yaratır. Bu düzenleme aslında öğrenme avantajını sağlayabilir.', 'ko': '요약 본고는 간단한 PCFG 귀납 모델을 묘사했다. 이 모델은 고정된 유형역을 가지고 절대 다수의 인증 성분의 경계를 예측할 수 있으며 어린이가 음성으로 향하는 표준 평가 데이터 집합에서 인증 성분의 절반에 가까운 라벨과 일치하는 라벨을 예측할 수 있다.이어서 어린이 학습자가 나타내는 간단한 문법과 성인 학습자가 나타내는 완전한 귀속문법 간의 차이는 업무 기억 용량이 증가한 결과일 수 있다. 그 중에서 얕은 문법은 귀속문법의 제한된 이미지이다.귀속문법의 깊이 있는 특정 변환에서 이러한 기억 경계를 중심으로 제한을 삽입하는 실현은 효과가 있지만 경계가 없는 기선에 비해 현저한 개선이 생겼다. 이것은 이러한 안배가 확실히 학습 우위를 가진다는 것을 나타낸다.', 'af': "Abstrak Hierdie artikel beskrywe 'n eenvoudige PCFG induksie model met' n vaste kategorie domein wat voorskou 'n groot meeste van bevestige konstituïngsgrense, en voorskou etikette wat bestaan met byna helfte van bevestige konstituïngsetikette op 'n standaard evalueringsdata stel van kindergreedspraat. Die artikel ondersoek dan die idee dat die verskil tussen eenvoudige gramme wat deur kinders onderwerp word en volledig rekursiewe gramme wat deur voksners onderwerp word, dalk mag 'n effek wees van vergroot werk geheue kapasiteit, waar die klein gramme onderwerp word beelde van die rekursiewe gramme. 'n Implementasie van hierdie geheue grense as grense op sentrum inbêring in 'n dieptespesifieke transformasie van 'n rekursiewe grammatiek gee 'n betaling verbetering oor' n gelykivalente maar onbegrense basisline, wat voorstel dat hierdie aanpassing sekerlik 'n onderwerp voordeel kan aangee.", 'hy': 'Աբլակտրական Այս հոդվածը նկարագրում է պարզ պոֆԳ ինդուկցիոն մոդելը, որն ունի ֆիքսավորված կատեգորիայի ոլորտ, որը կանխատեսում է հավասարված բաղադրիչների մեծ մասը և կանխատեսում է պիտակներ, որոնք համապատասխանում են երեխաների ուղղությամբ խոսքի ստանդարտ գնահատման տվ Հետո հոդվածը ուսումնասիրում է այն գաղափարը, որ երեխաների ուսանողների ցուցադրված պարզ գրամագրությունների և չափահասների ուսանողների ցուցադրված ամբողջովին կրկնօրինակ գրամագրությունների տարբերությունը կարող է աճել աշխատանքային հիշողության ունակությունը, որտեղ մակերեսային գրամագրությունները սահմանափակ Այս հիշողության սահմանների իրականացումը, որպես կենտրոնի սահմանները, որոնք ներառվում են կրկնօրինակ գրամագրության խորության մասնավոր փոխակերպման մեջ, նշանակալի բարելավում է համարժեք, բայց անսահմանափակ հիմքի համեմատ, և առաջարկում է, որ այս կազմակերպությունը կարող', 'az': 'Bu məktub çoxluğunu təsdiqləyən mövcud sınırlarının çoxluğunu təsdiqləyən PCFG induksyon modelini təsdiqləyir və çoxluğunu təsdiqləyən çoxluğunu təsdiqləyir, çoxluğun təsdiqlənmiş mövcud etiketlərinin yaxın yarısını təsdiqlənir. Sonra məktəbə təhsil edir ki, çocuk öyrənənənlərin və yetişkin öyrənənənlərin göstərilən çox asan grammaların arasındakı fərqli olaraq işləmə kapasitəsini artırmaq təsiri olar, orada küçük grammaların yenidən cürbəcür grammaların görüntüləri məcbur edilir. Bu hafıza sınırlarının mərkəzində xüsusiyyətli bir grammatik dəyişəcəyi qədər xüsusiyyətli bir dəyişəcəyi qədər çox yaxşılaşdırılmasını təsdiqləyən mərkəzin mərkəzində olan sınırları olaraq təmin edir.', 'bn': 'Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech.  তারপর এই প্রবন্ধে এই ধারণা খুঁজে পাচ্ছে যে শিশুদের শিক্ষার্থীদের দ্বারা প্রদর্শন করা সহজ গ্রামের মধ্যে পার্থক্য এবং বয়স্ক শিক্ষার্থীদের দ্বারা পুরোপুরি রিসারিভার্সি এই স্মৃতির সীমানা বাস্তবায়নের সীমাবদ্ধতা হিসেবে পুনরুদ্ধারিত গ্রামের গভীর-নির্দিষ্ট গভীর পরিবর্তনের কেন্দ্রে ব্যবস্থা করা হয়েছে সমতুল্য কিন্তু সীমাবদ্', 'sq': 'Abstrakt Ky artikull përshkruan një model të thjeshtë induksioni PCFG me një domain të kategorisë fikse që parashikon një shumicë të madhe të kufijve të konfiguruara përbërëse dhe parashikon etiketa të konsistente me pothuajse gjysmën e etiketave të konfiguruara përbërëse në një sërë të dhënash standard të vlerësimit të fjalimit të drejtuar nga fëmijët. Artikli pastaj eksploron idenë se dallimi midis gramatikave të thjeshta të shfaqura nga nxënësit e fëmijëve dhe gramatikave plotësisht rekursive të shfaqura nga nxënësit e rritur mund të jetë një efekt i rritjes së kapacitetit të kujtesës së punës, ku gramatikave të thella janë imazhe të kufizuara të gramatikave rekursive. Një zbatim i këtyre kufijve të kujtesës si kufij në qendër të përfshirjes në një transformim të thellë-specifik të një gramatike rekursive sjell një përmirësim të rëndësishëm mbi një bazë ekvivalente por jo të kufizuar, duke sugjeruar se ky marrëveshje mund të japë në të vërtetë një avantazh mësimi.', 'am': 'ይህ ጽሑፍ አቀማመጥ የPCFG ተግባር ሞዴል በሚያሳየው የኮምፒዩተር ኮምፒዩተር እና የተመሳሳይ ብዙዎቹ ከተሰበሰቡ ዳርቻዎች የሚታወቁ እና ምልክቶችን በቁጥር እኩሌታው የተደገመ የአካባቢ ምልክቶች በተመሳሳይ የሕፃን-ተመራሳይ ንግግር ማተሚያ ላይ የተመሳሳይ ማተሚያ ይናገራል፡፡ ከዚህም በኋላ ሕግጋቱ የሕፃናት ተማሪዎች እና ሙሉ ተማሪዎችን የሚያሳየው የቀላል grammar መፍትወት፣ የሥራ ማስታወቂያውን ማድረግ ማስታወቂያውን የሚያበዛ ጥያቄ እንዲሆን ይችላል፡፡ የዚህ ማስታሰቢያ ድንበር በጥልቅ-በተለየ ቀለም ለውጥ በመስመር ላይ እንደተደረገ ግንኙነት በሚያስተካክለው ነገር ግን በሌላው መሠረት ላይ የተደረገ ጥቅምት እንዲያስፈልጋል፡፡', 'cs': 'Abstrakt Tento článek popisuje jednoduchý indukční model PCFG s pevnou kategorií domény, která předpovídá velkou většinu ověřených hranic složek, a předpovídá štítky shodné s téměř polovinou ověřených složek na standardní hodnotící sadě dat řeči řízené dětmi. Článek pak zkoumá myšlenku, že rozdíl mezi jednoduchými gramatikami vystavenými dětskými žáky a plně rekurzivními gramatikami vystavenými dospělými žáky může být efektem zvýšení kapacity pracovní paměti, kde mělké gramatiky jsou omezené obrazy rekurzivních gramatik. Implementace těchto paměťových hranic jako limitů pro centrální vkládání do hloubkově specifické transformace rekurzivní gramatiky přináší významné zlepšení oproti ekvivalentní, ale neomezené základní linie, což naznačuje, že toto uspořádání může skutečně poskytnout učební výhodu.', 'fi': 'Tässä artikkelissa kuvataan yksinkertainen PCFG-induktiomalli, jossa on kiinteäluokkainen verkkotunnus, joka ennustaa suuren osan todistetuista ainesosien rajoista ja ennustaa merkinnät, jotka vastaavat lähes puolta todistetuista ainesosista lapsiohjatun puheen arviointiaineistossa. Artikkelissa tarkastellaan ajatusta siitä, että lapsioppijoiden esittämien yksinkertaisten kielioppimien ja aikuisten esittämien täysin rekursiivisten kielioppimien välinen ero saattaa johtua työmuistikapasiteetin kasvusta, jossa matalat kieliopit ovat rekursiivisten kielioppimien rajoitettuja kuvia. Näiden muistirajojen toteuttaminen rajoituksina keskustan upottamiselle rekursiivisen kieliopin syvyyskohtaiseen muunnokseen tuottaa merkittävän parannuksen vastaavaan mutta rajattomaan perusaikatauluun verrattuna, mikä viittaa siihen, että tämä järjestely voi todellakin antaa oppimisetua.', 'bs': 'Apstraktirajući ovaj članak opisuje jednostavan model indukcije PCFG sa fiksnim domenom kategorije koja predviđa većinu potvrđenih ograničenja sastavnika i predviđa etikete koje odgovaraju skoro pola potvrđenih etiketi sastavnika na standardnom setu podataka za procjenu djeteta. Članak onda istražuje ideju da razlika između jednostavnih gramara izloženog učenicima djece i potpuno rekursivnih gramara izloženog odraslim učenicima može biti učinka povećanja kapaciteta rada, gdje plitke gramare ograničavaju slike rekursivnih gramara. Implementacija tih granica sjećanja kao ograničenja centra ugrađenog u duboko specifičnom transformaciji rekursivne gramatike pruža značajno poboljšanje nad ekvivalentnim ali neograničenim početnim linijama, ukazujući na to da ovaj dogovor može zaista pružiti prednost učenja.', 'ca': "Abstract Aquest article descriu un simple model d'inducció de PCFG amb un domini de categoria fixa que prediu una gran majoria dels límits de components atestats i prediu etiquetes consistents amb gairebé la meitat d'etiquetes de components atestats en un conjunt de dades d'evaluació estándar de discurs dirigits pel nen. L'article explora llavors la idea que la diferència entre les gramàtiques simples mostrades pels alumnes infantils i les gramàtiques completament recursives mostrades pels alumnes adults pot ser un efecte d'augmentar la capacitat de memòria operativa, on les gramàtiques superficials són imatges restringides de les gramàtiques recursives. Una implementació d'aquests límits de memòria com límits en el centre incorporat en una transformació específica de profunditat d'una gramàtica recursiva produeix una millora significativa sobre una base equivalent però sense límits, suggerent que aquest acord pot donar un avantatge d'aprenentatge.", 'et': 'Käesolevas artiklis kirjeldatakse lihtsat PCFG induktsioonimudelit fikseeritud kategooria domeeniga, mis prognoosib suuremat osa tõestatud koostisosade piiridest ja prognoosib peaaegu poolte tõendatud koostisosade märgistustega lapsepõhise kõne standardses hindamisandmekogumis. Artiklis uuritakse seejärel ideed, et erinevus lapsõppijate ja täiskasvanute eksponeeritud täielikult rekursiivsete grammatikate vahel võib olla mõju töömälu suurendamisele, kus madalad grammatikad on rekursiivsete grammatikate piiratud kujutised. Nende mälupiiride rakendamine rekursiivse grammatika sügavuspetsiifilise muunduse keskpunkti piiramisena annab märkimisväärse paranemise võrreldes samaväärse, kuid piiramatu lähtejoonega, mis viitab sellele, et see korraldus võib tõepoolest anda õppimise eelise.', 'jv': 'absolute This section description s a Simple PFG ndution model with a fixed category domain that Previews a big plural of Attested concituent limits, and preview Lables coherent with about polar of Attested concituent label on a Standard assertion data set of little-directited language. Inggal kuwi nggawe akeh luwih akeh dumadhi iki sampeyan anyar sampeyan anyar tentang kanggo nguasai supoyo urip nggawe barang kelas nang sampeyan cilas nggawe barang kelas nggawe barang alah luhur Global', 'ha': '@ info: whatsthis The article then explores the idea that the difference between simple grammars exhibited by child learners and fully recursive grammars exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the recursive grammars.  Juyin waɗannan iyãkõkin kumbar ta zama ƙetare a tsakiyar da ke haɗa cikin wata shifo-bayani na cikakken grammati, yana fitar da mai kyau mai daidaita kuma ba da bango ba, kuma yana son cẽwa wannan shirin zai iya ƙara wani amfani na karanta.', 'bo': 'Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech. The article then explores the idea that the difference between simple grammars exhibited by child learners and fully recursive grammars exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the recursive grammars. The article then explores the idea that the difference between simple grammars An implementation of these memory bounds as limits on center embedding in a depth-specific transform of a recursive grammar yields a significant improvement over an equivalent but unbounded baseline, suggesting that this arrangement may indeed confer a learning advantage.', 'sk': 'V tem članku je opisan preprost model indukcije PCFG z domeno fiksne kategorije, ki napoveduje veliko večino potrjenih meja sestavnih delov in napoveduje oznake, ki so skladne s skoraj polovico potrjenih sestavnih delov na standardnem naboru podatkov ocenjevanja otrokovega govora. Članek nato raziskuje idejo, da je razlika med preprostimi slovnicami, ki jih prikazujejo otroški učenci, in popolnoma rekurzivnimi slovnicami, ki jih prikazujejo odrasli učenci, lahko učinek povečanja zmogljivosti delovnega spomina, kjer so plitve slovnice omejene slike rekurzivnih slovnic. Izvedba teh pomnilniških omejitev kot omejitev za vgradnjo središča v globinsko specifično transformacijo rekurzivne slovnice prinaša znatno izboljšanje v primerjavi z enakovrednim, a neomejenim osnovnim osnovnim začetkom, kar kaže, da lahko ta ureditev dejansko prinese učno prednost.', 'he': 'המאמר הזה מתאר מודל דלקת PCFG פשוטה עם שטח קטגוריה קבועה שמחזה רוב גדול של גבולות המרכיבים מאושרים, וחזוי תוויות מתאימות כמעט חצי מהתוויות המרכיבים מאושרות על קבוצת נתוני עריכה סטנדרטית של נאום ממוקד הילדים. המאמר חוקר את הרעיון שההבדל בין גרמטיקות פשוטות המוצגות על ידי לומדים ילדים וגרמטיקות חדשות לחלוטין המוצגות על ידי לומדים מבוגרים יכול להיות השפעה של גידול יכולת זיכרון עבודה, שבו גרמטיקות שטחיות הן תמונות מוגבלות של גרמטיקות חדשות. ההפעלה של הגבולות הזיכרון האלה כגבולות על המרכז התכנית בתנועה עמוקה ספציפית של גרמטיקה חוזרת מובילה שיפור משמעותי מעל בסיס שווה אבל ללא גבולות, המציע שהסדר הזה עשוי למעשה להעניק יתרון למידה.'}
{'en': 'Approximating Probabilistic Models as Weighted Finite Automata', 'fr': "Approximation de modèles probabilistes sous forme d'automates finis pondérés", 'ar': 'تقريب النماذج الاحتمالية كأوتوماتا محدودة مرجحة', 'es': 'Aproximación de modelos probabilísticos como autómatas finitos ponderados', 'pt': 'Aproximando Modelos Probabilísticos como Autômatos Finitos Ponderados', 'ja': '加重有限オートマタとしての確率モデルの近似', 'zh': '将概率模形近似为加权有限自动机', 'hi': 'भारित परिमित Automata के रूप में संभावित मॉडल approximating', 'ru': 'Приближение вероятностных моделей к взвешенным конечным автоматам', 'ga': 'Samhlacha Dóchúla a Chomhfhogasú mar Uathmata Deiridh Ualaithe', 'ka': 'შესაბამისი მოდელი, როგორც უფრო მნიშვნელოვანი ფინიტის ავტომატიკა', 'el': 'Προσέγγιση των πιθανών μοντέλων ως σταθμισμένα τελικά αυτόματα', 'hu': 'Valószínűsített modellek közelítése súlyozott véges automata formájában', 'it': 'Approssimazione dei modelli probabilistici come automatico finito ponderato', 'kk': 'Маңызды финит автоматты ретінде маңызды үлгілер', 'lt': 'Tikėtinų modelių apytikrinimas kaip svertinių finitų automatų', 'mk': 'Приближување на веројатните модели како тешки финитни автомати', 'ms': 'Approximating Probabilistic Models as Weighted Finite Automata', 'mn': 'Магадгүй хэмжээтэй финит автомат гэх мэт', 'ml': 'സാധ്യതയുള്ള മോഡലുകള്\u200d വൈറ്റ് ഫൈറ്റ് സ്റ്റോമാറ്റായി പ്രാവര്\u200dത്തികമാക്കുന്നു', 'mt': 'L-approssimazzjoni tal-Mudelli Probabilistiċi bħala Awtomati Finiti Piżati', 'pl': 'Zbliżenie modeli prawdopodobnych jako ważonych automatów końcowych', 'ro': 'Apropierea modelelor probabilistice ca automat finit ponderat', 'no': 'Nærmest sannsynlige modeller som vekt fint automatisk', 'si': 'සම්බන්ධ විශ්වාසික මොඩේල්ස් විශ්වාසික ස්වයංක්\u200dරීය විදියට', 'sr': 'Približavajući verovatne modele kao masna finita automatska', 'so': 'Horumarinta qaababka suurtagalka ah sida Weighted Finite Automata', 'sv': 'Tillnärmning av sannolika modeller som viktad finit automata', 'ta': 'வெளிப்படையான கண்டுபிடிப்பு தானியங்கி', 'ur': 'اٹوٹ فینیٹ اتوماٹا کی طرح احتمالات موڈل کی تقریباً کرتا ہے', 'uz': 'Name', 'vi': 'Đối tượng ổn định dạng như Weight Finite Automate', 'bg': 'Приближаване на вероятните модели като претеглена фина автоматика', 'da': 'Tilnærmelse af sandsynlige modeller som vægtet finite automata', 'hr': 'Približavajući vjerojatni modeli kao težina Finite Automata', 'nl': 'Het benaderen van probabilistische modellen als gewogen eindige automaten', 'de': 'Näherung probabilistischer Modelle als gewichtete finite Automaten', 'fa': 'تقریباً مدل احتمالاتی به عنوان اتوماتیکا فنایتی وزن', 'id': 'Mendekatkan Model Kemungkinan sebagai Automata Finit Berberat', 'ko': '확률 모형을 가중 유한 자동기와 근사하게 하다', 'sw': 'Akionyesha Modela Inawezekana kama Tamko la Automata', 'tr': 'Ýagtylamak Faýllary Aýratýan Mümkin Modeller', 'af': 'Omtrent waarskynlik waarskynlik Modelle as gewigte Finite Automata', 'sq': 'Përafërsisja e modeleve të mundshëm si Automat Finite të Peshuara', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Մոտավորելով հավանական մոդելները՝ որպես կեշտրված ֆինիտային ավտոմատա', 'az': 'Ölçülü Finite Automata kimi Muxluqat Modelləri', 'bs': 'Približavajući vjerojatni modeli kao težina Finite Automata', 'bn': 'সম্ভাব্য মোডেল উইটল ফিনিট স্বয়ংক্রিয়ভাবে উপস্থিত করা হচ্ছে', 'ca': 'Aproximar els Models Probabilistes com a Automates Finites Pesades', 'cs': 'Přibližování pravděpodobnostních modelů jako vážených konečných automatů', 'et': 'Tõenäoliste mudelite lähendamine kaalutud finiitautomaadina', 'fi': 'Probabilististen mallien lähentäminen painotettuna finiittiautomaattina', 'jv': 'Sumbersane Validity', 'sk': 'Približevanje verjetnih modelov kot tehtanega finitnega avtomata', 'ha': 'Approximating Probabilistic Models as Weighted Finite Automata', 'he': 'מתקרבים מודלים סבירים כאוטומטה סופית משקלת', 'bo': 'རྒྱ་ཆེ་བའི་ཆེད་དུ་རང་འགུལ་གྱིས་ཉེར་སྤྱོད་བྱས་པའི་རྣམ་གྲངས་སྒྲིག་འགོད་འདོད་པ'}
{'en': 'Abstract Weighted finite automata (WFAs) are often used to represent probabilistic models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space. The probabilistic source to be represented as a WFA, however, may come in many forms. Given a generic probabilistic model over sequences, we propose an algorithm to approximate it as a WFA such that the Kullback-Leibler divergence between the source model and the WFA target model is minimized. The proposed algorithm involves a counting step and a difference of convex optimization step, both of which can be performed efficiently. We demonstrate the usefulness of our approach on various tasks, including distilling n-gram models from neural models, building compact language models, and building open-vocabulary character models. The algorithms used for these experiments are available in an open-source software library.', 'ar': 'غالبًا ما تُستخدم الأوتوماتا المحدودة الموزونة (WFA) المجردة لتمثيل النماذج الاحتمالية ، مثل نماذج اللغة n-gram ، لأنها ، من بين أشياء أخرى ، فعالة في مهام التعرف في الزمان والمكان. ومع ذلك ، قد يأتي المصدر الاحتمالي الذي سيتم تمثيله على أنه WFA في أشكال عديدة. بالنظر إلى نموذج احتمالي عام على التسلسلات ، نقترح خوارزمية لتقريبها على أنها WFA بحيث يتم تقليل تباعد Kullback-Leibler بين نموذج المصدر والنموذج المستهدف WFA. تتضمن الخوارزمية المقترحة خطوة عد واختلاف خطوة التحسين المحدبة ، وكلاهما يمكن تنفيذه بكفاءة. نوضح فائدة نهجنا في المهام المختلفة ، بما في ذلك استخلاص نماذج n-gram من النماذج العصبية ، وبناء نماذج لغة مضغوطة ، وبناء نماذج شخصية مفتوحة المفردات. الخوارزميات المستخدمة لهذه التجارب متوفرة في مكتبة برمجيات مفتوحة المصدر.', 'es': 'Resumen Los autómatas finitos ponderados (WFA) se utilizan a menudo para representar modelos probabilísticos, como los modelos de lenguaje n-gram, porque, entre otras cosas, son eficientes para las tareas de reconocimiento en el tiempo y el espacio. Sin embargo, la fuente probabilística para ser representada como una WFA puede presentarse de muchas formas. Dado un modelo probabilístico genérico sobre secuencias, proponemos un algoritmo para aproximarlo como un WFA de manera que se minimice la divergencia de Kullback-Leibler entre el modelo fuente y el modelo objetivo WFA. El algoritmo propuesto implica una etapa de conteo y una diferencia de etapa de optimización convexa, las cuales se pueden realizar de manera eficiente. Demostramos la utilidad de nuestro enfoque en varias tareas, incluida la destilación de modelos de n-gramas a partir de modelos neuronales, la creación de modelos de lenguaje compactos y la creación de modelos de caracteres de vocabulario abierto. Los algoritmos utilizados para estos experimentos están disponibles en una biblioteca de software de código abierto.', 'pt': 'Resumo Os autômatos finitos ponderados (WFAs) são frequentemente usados para representar modelos probabilísticos, como os modelos de linguagem n-gram, porque, entre outras coisas, são eficientes para tarefas de reconhecimento no tempo e no espaço. A fonte probabilística a ser representada como um WFA, no entanto, pode vir de várias formas. Dado um modelo probabilístico genérico sobre sequências, propomos um algoritmo para aproximá-lo como um WFA tal que a divergência de Kullback-Leibler entre o modelo fonte e o modelo WFA alvo seja minimizada. O algoritmo proposto envolve uma etapa de contagem e uma etapa de otimização convexa de diferença, sendo que ambas podem ser realizadas de forma eficiente. Demonstramos a utilidade de nossa abordagem em várias tarefas, incluindo destilar modelos n-gram de modelos neurais, construir modelos de linguagem compactos e construir modelos de caracteres de vocabulário aberto. Os algoritmos usados para esses experimentos estão disponíveis em uma biblioteca de software de código aberto.', 'fr': "Les automates finis pondérés (WFA) sont souvent utilisés pour représenter des modèles probabilistes, tels que les modèles de langage n-gram, parce qu'ils sont notamment efficaces pour les tâches de reconnaissance dans le temps et l'espace. La source probabiliste à représenter comme une DPA peut toutefois prendre de nombreuses formes. Étant donné un modèle probabiliste générique sur les séquences, nous proposons un algorithme pour l'approximer en tant que WFA de telle sorte que la divergence de Kullback-Leibler entre le modèle source et le modèle cible WFA soit minimisée. L'algorithme proposé implique une étape de comptage et une étape d'optimisation différentielle convexe, qui peuvent toutes deux être effectuées efficacement. Nous démontrons l'utilité de notre approche sur diverses tâches, y compris la distillation de modèles n-grammes à partir de modèles neuronaux, la création de modèles de langage compacts et la création de modèles de caractères à vocabulaire ouvert. Les algorithmes utilisés pour ces expériences sont disponibles dans une bibliothèque de logiciels open source.", 'ja': '抽象加重有限オートマタ（ ＷＦＡ ）は、とりわけ、時間と空間における認識タスクに効率的であるため、ｎグラム言語モデルなどの確率モデルを表すためによく使用される。しかしながら、Ｗｆａとして表される確率的ソースは、多くの形態であり得る。配列にわたる一般的な確率モデルを考えると、ソースモデルとＷｆａターゲットモデルとの間のクルバック・ライブラー発散が最小化されるように、それをＷｆａとして近似するアルゴリズムを提案する。提案されたアルゴリズムは、カウントステップと凸最適化ステップの差を含み、両方とも効率的に実行することができる。ニューラルモデルからn - gramモデルを抽出し、コンパクトな言語モデルを構築し、オープンボキャブラリーキャラクターモデルを構築するなど、さまざまなタスクに対するアプローチの有用性を示しています。これらの実験に使用されるアルゴリズムは、オープンソースのソフトウェアライブラリで利用可能である。', 'zh': '摘要 加权有限自动机(WFAs)常以表概率,如n-gram言模形者,以其有效于时空也。 然示 WFA 概率源或有多种形式。 为定序通用概率模形,设一算法以近似为WFA,使源WFA之间Kullback-Leibler散最小化。 其算法涉数步、凸优化步骤之差,两者皆有效。 吾示我以有用之性,取我神经之n-gram,急凑之言,开词汇字符。 用此实验算法于开源软件库中得之。', 'ru': 'Абстрактные взвешенные конечные автомати (WFA) часто используются для представления вероятностных моделей, таких как n-граммовые языковые модели, потому что, среди прочего, они эффективны для задач распознавания во времени и пространстве. Однако вероятностный источник, который должен быть представлен в виде WFA, может иметь различные формы. Учитывая общую вероятностную модель последовательностей, мы предлагаем алгоритм, чтобы аппроксимировать ее как Wfa ТАКИМ образом, чтобы свести к минимуму расхождение Куллбека-Лейблера между исходной моделью и целевой моделью Wfa. Предложенный алгоритм включает в себя этап подсчета и разность выпуклых этапов оптимизации, оба из которых могут быть выполнены эффективно. Мы демонстрируем полезность нашего подхода к различным задачам, включая дистилляцию n-граммных моделей из нейронных моделей, построение компактных языковых моделей и построение открытых лексических моделей символов. Алгоритмы, используемые для этих экспериментов, доступны в библиотеке программного обеспечения с открытым исходным кодом.', 'hi': 'सार भारित परिमित ऑटोमेटा (डब्ल्यूएफए) का उपयोग अक्सर संभाव्य मॉडल का प्रतिनिधित्व करने के लिए किया जाता है, जैसे कि एन-ग्राम भाषा मॉडल, क्योंकि अन्य चीजों के अलावा, वे समय और स्थान में मान्यता कार्यों के लिए कुशल होते हैं। डब्ल्यूएफए के रूप में प्रतिनिधित्व करने के लिए संभाव्य स्रोत, हालांकि, कई रूपों में आ सकता है। अनुक्रमों पर एक सामान्य संभाव्य मॉडल को देखते हुए, हम एक एल्गोरिथ्म का प्रस्ताव करते हैं ताकि इसे डब्ल्यूएफए के रूप में अनुमानित किया जा सके जैसे कि स्रोत मॉडल और डब्ल्यूएफए लक्ष्य मॉडल के बीच कुलबैक-लीबलर विचलन को कम से कम किया जाए। प्रस्तावित एल्गोरिथ्म में एक गिनती चरण और उत्तल अनुकूलन चरण का अंतर शामिल है, जिनमें से दोनों को कुशलतापूर्वक निष्पादित किया जा सकता है। हम विभिन्न कार्यों पर हमारे दृष्टिकोण की उपयोगिता का प्रदर्शन करते हैं, जिसमें तंत्रिका मॉडल से एन-ग्राम मॉडल को डिस्टिल करना, कॉम्पैक्ट भाषा मॉडल का निर्माण करना और खुले-शब्दावली चरित्र मॉडल का निर्माण शामिल है। इन प्रयोगों के लिए उपयोग किए जाने वाले एल्गोरिदम एक ओपन-सोर्स सॉफ़्टवेयर लाइब्रेरी में उपलब्ध हैं।', 'ga': 'Abstract Is minic a úsáidtear uathmata teoranta ualaithe (WFAanna) chun samhlacha dóchúlachta a léiriú, mar mhúnlaí teanga n-gram, mar go bhfuil siad éifeachtach i measc rudaí eile le haghaidh tascanna aitheantais in am agus sa spás. D’fhéadfadh go mbeadh an fhoinse dhóchúil le léiriú mar WFA, áfach, i bhfoirmeacha go leor. I bhfianaise múnla cineálach dóchúlachta thar sheichimh, molaimid algartam chun é a chomhfhogasú mar WFA ionas go laghdófar an éagsúlacht Kullback-Leibler idir an tsamhail fhoinseach agus an tsamhail sprice WFA. Is éard atá i gceist leis an algartam atá beartaithe ná céim chomhairimh agus difríocht chéim optamaithe dronnach, agus is féidir an dá cheann a dhéanamh go héifeachtach. Léirímid úsáideacht ár gcur chuige ar thascanna éagsúla, lena n-áirítear samhlacha n-gram a dhriogadh ó mhúnlaí néaracha, mionsamhlacha teanga dlútha a thógáil, agus samhlacha carachtair stór focal oscailte a thógáil. Tá na halgartaim a úsáidtear do na turgnaimh seo ar fáil i leabharlann bogearraí foinse oscailte.', 'hu': 'Absztrakt A súlyozott véges automatákat (WFA-k) gyakran használják valószínűsíthető modellek, mint például n-gramm nyelvi modellek, mert többek között hatékonyak az időben és térben történő felismerési feladatokhoz. A valószínűsíthető forrás, amelyet WFA-ként kell képviselni, azonban számos formában előfordulhat. Egy általános valószínűségi modell alapján a szekvenciák felett javasoltunk egy algoritmust, amely közelíti azt WFA-ként, hogy minimalizálja a Kullback-Leibler eltérést a forrás modell és a WFA célmodell között. A javasolt algoritmus magában foglalja a számlálási lépést és a konvex optimalizálási lépések különbségét, amelyek mindkettő hatékonyan végrehajtható. Különböző feladatokban bemutatjuk megközelítésünk hasznosságát, beleértve az n-gram modelleket neurális modellekből történő desztillálását, kompakt nyelvi modelleket építését és nyitott szókincsű karaktermodelleket. Az ezekhez a kísérletekhez használt algoritmusok egy nyílt forráskódú szoftverkönyvtárban érhetők el.', 'el': 'Τα σταθμισμένα πεπερασμένα αυτόματα χρησιμοποιούνται συχνά για την αναπαράσταση πιθανών μοντέλων, όπως τα γλωσσικά μοντέλα γραμμάτων, επειδή μεταξύ άλλων, είναι αποτελεσματικά για εργασίες αναγνώρισης σε χρόνο και χώρο. Ωστόσο, η πιθανολογική πηγή που εκπροσωπείται ως WFA μπορεί να έρθει σε πολλές μορφές. Δεδομένου ενός γενικού πιθανολογικού μοντέλου πάνω από ακολουθίες, προτείνουμε έναν αλγόριθμο για την προσέγγιση του ως WFA, έτσι ώστε η απόκλιση Kullback-Leibler μεταξύ του μοντέλου προέλευσης και του μοντέλου στόχου WFA να ελαχιστοποιηθεί. Ο προτεινόμενος αλγόριθμος περιλαμβάνει ένα βήμα μέτρησης και μια διαφορά του κυρτού βήματος βελτιστοποίησης, τα οποία μπορούν να εκτελεστούν αποτελεσματικά. Επιδεικνύουμε τη χρησιμότητα της προσέγγισής μας σε διάφορες εργασίες, συμπεριλαμβανομένης της απόσταξης μοντέλων γραμμάτων από νευρωνικά μοντέλα, της οικοδόμησης μοντέλων συμπαγών γλωσσών και της δημιουργίας μοντέλων χαρακτήρων ανοιχτού λεξιλογίου. Οι αλγόριθμοι που χρησιμοποιούνται για αυτά τα πειράματα είναι διαθέσιμοι σε μια βιβλιοθήκη λογισμικού ανοικτού κώδικα.', 'it': "Gli automi finiti ponderati (WFA) sono spesso usati per rappresentare modelli probabilistici, come i modelli di linguaggio n-gram, perché, tra le altre cose, sono efficienti per le attività di riconoscimento nel tempo e nello spazio. La fonte probabilistica da rappresentare come WFA, tuttavia, può venire in molte forme. Dato un modello probabilistico generico su sequenze, proponiamo un algoritmo per approssimarlo come WFA in modo che la divergenza Kullback-Leibler tra il modello sorgente e il modello target WFA sia minimizzata. L'algoritmo proposto prevede una fase di conteggio e una differenza di fase di ottimizzazione convessa, entrambi possono essere eseguiti in modo efficiente. Dimostriamo l'utilità del nostro approccio su vari compiti, tra cui la distillazione di modelli n-gram da modelli neurali, la costruzione di modelli di linguaggio compatti e la costruzione di modelli di caratteri open-vocabulary. Gli algoritmi utilizzati per questi esperimenti sono disponibili in una libreria software open source.", 'kk': 'Абстрактық тең аяқталған автоматты (WFA) көбінесе n- грамм тіл үлгілері секілді ықтималдық үлгілерді көрсету үшін қолданылады, себебі басқа нәрселердің арасында, олар уақыт мен бос орында тапсырмаларды анықтау ү Бірақ WFA ретінде таңдалатын ықтималдық көзі көп пішінде болуы мүмкін. Келесі реттер бойынша жалпы ықтималдық үлгісін көрсету үшін біз оны WFA ретінде көздегі үлгісі мен WFA мақсатты үлгісінің арасындағы Kullback- Leibler диверензиясының түсіндігін түсіндіру алгоритмін ұсындық. Келтірілген алгоритм санау қадамын және конвекстің оптимизациялау қадамының айырмашылығы болады, екеуі ең жақсы жұмыс істеуге болады. Біз әртүрлі тапсырмалардың қасиеттерінің пайдалығын көрсетедік, n- грамм моделдерін невралдық моделдерден бөліп, комплекттік тіл үлгілерін құру және ашық сөздер үлгілерін құру. Бұл эксперименттер үшін қолданылатын алгоритмдер ашық көзі бағдарлама жиынында бар.', 'lt': 'Abstraktiniai svertiniai galutiniai automatai (WFA) dažnai naudojami, kad būtų galima atspindėti probabilistinius modelius, pvz., n gram ų kalbos modelius, nes, be kita ko, jie yra veiksmingi laiko ir erdvės atpažinimo užduotims atlikti. Vis dėlto tikimybės šaltinis, kuris turi būti laikomas WFA, gali būti įvairus. Atsižvelgdami į bendrą probabilistinį sekų model į, siūlome algoritmą, kuris jį apytikriai apytikriai įvertintų kaip WFA, kad būtų kuo labiau sumažintas Kullback-Leibler skirtumas tarp šaltinio modelio ir WFA tikslinio modelio. Siūlomas algoritmas apima skaičiavimo etapą ir konvekso optimizavimo etapo skirtumą, kurie abu gali būti veiksmingai atliekami. Mes įrodome savo požiūrio naudingumą įvairioms užduotims, įskaitant n-gram ų modelių distiliavimą iš nervinių modelių, kompaktinių kalbų modelių kūrimą ir atviro žodyno simbolių modelių kūrimą. Šiems eksperimentams naudojami algoritmai pateikiami atvirojo kodo programinės įrangos bibliotekoje.', 'mk': 'Апстрактни тешки крајни автоматики (WFAs) честопати се користат за да претставуваат веројатни модели, како што се n-грамските јазички модели, бидејќи меѓу другите работи, тие се ефикасни за задачи за препознавање во времето и просторот. Сепак, веројатниот извор кој ќе биде претставен како ВФА може да дојде во многу форми. Со оглед на генералниот веројатен модел во текот на секвенциите, предложуваме алгоритм кој ќе го приближи како WFA така што дивергенцијата Кулбак-Лејблер помеѓу изворниот модел и метниот модел на WFA е минимизирана. Предложениот алгоритм вклучува чекор на броење и разлика во чекорот на конвексна оптимизација, кои двата може да се извршат ефикасно. Ние ја демонстрираме корисноста на нашиот пристап на различни задачи, вклучително и дестилирање на n-грамски модели од невровните модели, изградба на компактни јазички модели и изградба на модели на отворен речник. Алгоритмите кои се користат за овие експерименти се достапни во отворена софтверска библиотека.', 'ms': 'Automa Tertib Berberat Abstrakt (WFAs) sering digunakan untuk mewakili model kemungkinan, seperti model bahasa n-gram, kerana di antara perkara lain, ia berkesan untuk tugas pengenalan dalam masa dan ruang. Sumber kemungkinan untuk diwakili sebagai WFA, bagaimanapun, mungkin datang dalam banyak bentuk. Berdasarkan model kemungkinan generik melalui jujukan, kita cadangkan algoritma untuk mengharapkannya sebagai WFA sehingga pelbagai Kullback-Leibler diantara model sumber dan model sasaran WFA dikurangkan. Algoritma yang diusulkan melibatkan langkah penghitungan dan perbezaan langkah optimasi konveks, yang keduanya boleh dilakukan dengan efektif. Kami menunjukkan penggunaan pendekatan kami pada berbagai tugas, termasuk membersihkan model n-gram dari model saraf, membina model bahasa kompat, dan membina model aksara vocabulari terbuka. Algoritma yang digunakan untuk eksperimen ini tersedia dalam perpustakaan perisian sumber terbuka.', 'ml': 'അസ്ട്രാക്ട്രാക്റ്റ് വൈറ്റ് ഫൈനിറ്റ് ഫൈനിറ്റ് ഓട്ടോമാറ്റ (WFA) ഉപയോഗിക്കുന്നത് സാധ്യതയുള്ള മോഡലുകളെ പ്രതിനിധിയ്ക്കാനാണ്. ഗ്രാം ഭാഷ മോ ഒരു WFA എന്ന പ്രതിനിധിയില്\u200d പ്രതിനിധിയിക്കുന്ന സ്രോതസ്സിന്റെ സ്രോതസ്സ്, ഒരുപാട് രൂപങ്ങളില്\u200d വരാം. സെക്കന്റുകള്\u200dക്ക് മുകളില്\u200d സാധാരണമായ ഒരു മോഡല്\u200d കൊണ്ട് ഞങ്ങള്\u200d ഒരു ആല്\u200dഗോരിതം പ്രായശ്ചിത്തം ചെയ്യുന്നു. ഒരു WFA പോലെ കൂല്\u200dബാക്ക്-ലീബ്ലര്\u200d സോര്\u200dസ്സ് മോഡലിന്\u200dറെ  പ്രൊദ്ദേശിക്കപ്പെട്ട ആല്\u200dഗോരിതം എണ്ണുന്ന പടിയും കോണ്\u200dക്സിന്റെ ഐക്യോമിഷഷന്\u200d പടിയുടെ വ്യത്യാസവും ഉള്ളതാണ്. അതിന് We demonstrate the usefulness of our approach on various tasks, including distilling n-gram models from neural models, building compact language models, and building open-vocabulary character models.  ഈ പരീക്ഷണങ്ങള്\u200dക്കായി ഉപയോഗിക്കുന്ന ആല്\u200dഗോരിത്മുകള്\u200d ഒരു തുറന്ന സോഴ്സ് വെയര്\u200d ലൈബ്രറിയില്\u200d ലഭ്യമാ', 'mt': 'Abstract Weighted finite automata (WFAs) are often used to represent probabilistic models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space.  Madankollu, is-sors probabilistiku li għandu jiġi rrappreżentat bħala WFA jista’ jiġi f’ħafna forom. Minħabba mudell ġeneriku probabilistiku fuq sekwenzi, qed nipproponu algoritmu biex jiġi approssimat bħala WFA b’tali mod li d-diverġenza ta’ Kullback-Leibler bejn il-mudell tas-sors u l-mudell fil-mira tad-WFA tiġi minimizzata. L-algoritmu propost jinvolvi pass ta’ għadd u differenza ta’ pass ta’ ottimizzazzjoni konvessa, li t-tnejn jistgħu jitwettqu b’mod effiċjenti. Aħna nuru l-utilità tal-approċċ tagħna fuq diversi kompiti, inkluż id-distillazzjoni ta’ mudelli n-gram minn mudelli newrali, il-bini ta’ mudelli lingwistiċi kompatti, u l-bini ta’ mudelli ta’ karattru vokabulari miftuħa. L-algoritmi użati għal dawn l-esperimenti huma disponibbli f’librerija tas-softwer open-source.', 'mn': 'Абстрактикийн хэмжээний төгсгөл автомат (WFAs) ихэвчлэн n-грамм хэл загваруудыг илэрхийлэх магадлал загваруудыг ашигладаг. Учир нь бусад зүйлсийн дотор, тэд цаг, орон зайд ажиллагааг хүлээн зөвшөөрөхөд үр Гэхдээ ВФА гэж үзүүлэх магадлалын эх үүсвэр олон хэлбэрүүд байж болно. Дараагийн ерөнхий магадлалын загварын тулд бид үүнийг WFA гэж ойролцох алгоритмыг санал болгож, эх үүсвэрийн загвар болон WFA зорилго загварын хооронд Kullback-Leibler-ын ялгаа багасгаж байна. Энэ алгоритм нь тооцооллын алхам болон конвексын эерэг үзүүлэлтийн алхам хоёулаа үр дүнтэй ажиллаж болно. Бид өөр олон даалгаварын арга загварын хэрэгцээг үзүүлдэг. Н-грамм загваруудыг мэдрэлийн загвараас ялгах, компакт хэл загваруудыг бүтээж, нээлттэй үгийн загваруудыг бүтээж байна. Эдгээр туршилтуудын тулд хэрэглэгдсэн алгоритм нь нээлттэй эх програм хангамжийн номын санд байдаг.', 'ka': 'აბსტრაქტიკური განსაზღვრებული განსაზღვრებული ავტომატი (WFAs) ზოგიერთად გამოყენება პრობალისტიკური მოდელების გამოსაყენებლად, როგორც n-გრამის ენის მოდელები, რადგან სხვა რამ განსაზღვრებით, ისინი მაგრამ შეიძლება მრავალური ფორმებში გაჩვენება როგორც WFA. ჩვენ მივიღეთ ალგორიტიმ, როგორც WFA-ის გადარჩენა, რომ Kullback-Leibler განსხვავება მხოლოდ მოდელის შორის და WFA მისაღების მოდელის შორის. პროგრამებული ალგორიტიმის შესაძლებელია წერილება და კონგექსის ოპტიმიზაციის განსხვავება, რომელიც ორივე შეიძლება ეფექტიურად გავაკეთოთ. ჩვენ ჩვენი პროგრამის გამოსაყენებელობა განსხვავებული დავალებისთვის, ან-გრამის მოდელების განსხვავება ნეიროლური მოდელებიდან, კომპექტური ენის მოდელების შექმნა და გახსნილი სიტყვებული ამ ექსპერიმენტებისთვის გამოიყენებული ალგორიტიმები გახსნა პროგრამეტური ლიბილოტში.', 'pl': 'Ważone automaty skończone (WFA) są często wykorzystywane do reprezentowania modeli probabilistycznych, takich jak n-gram modele językowe, ponieważ między innymi są skuteczne do rozpoznawania zadań w czasie i przestrzeni. Źródło prawdopodobieństwa, które ma być reprezentowane jako WFA, może jednak pojawić się w wielu formach. Biorąc pod uwagę ogólny model prawdopodobieństwa nad sekwencjami, proponujemy algorytm przybliżenia go jako WFA w taki sposób, aby zminimalizować rozbieżność Kullbacka-Leiblera między modelem źródłowym a modelem docelowym WFA. Proponowany algorytm obejmuje krok liczenia i różnicę kroku optymalizacji wypukłej, które oba mogą być wykonywane efektywnie. Pokazujemy przydatność naszego podejścia do różnych zadań, w tym destylowania modeli n-gramowych z modeli neuronowych, budowania kompaktowych modeli językowych oraz budowania modeli postaci otwartego słownictwa. Algorytmy wykorzystywane do tych eksperymentów są dostępne w bibliotece oprogramowania open source.', 'ro': 'Automatele finite ponderate (WFA) sunt adesea folosite pentru a reprezenta modele probabilistice, cum ar fi modelele de limbaj n-gram, deoarece, printre altele, ele sunt eficiente pentru sarcini de recunoaștere în timp și spațiu. Sursa probabilistică care urmează să fie reprezentată ca APA, cu toate acestea, poate veni în multe forme. Având în vedere un model probabilistic generic asupra secvențelor, propunem un algoritm pentru a-l aproxima ca un WFA astfel încât divergența Kullback-Leibler dintre modelul sursă și modelul țintă WFA să fie minimizată. Algoritmul propus implică un pas de numărare și o diferență de etapă de optimizare convexă, ambele fiind efectuate eficient. Demonstrăm utilitatea abordării noastre în diverse sarcini, inclusiv distilarea modelelor n-gram din modele neurale, construirea modelelor de limbaj compact și construirea modelelor de caractere cu vocabular deschis. Algoritmii utilizați pentru aceste experimente sunt disponibili într-o bibliotecă de software open-source.', 'so': "Sida badan waxaa loo isticmaalaa tusaalaha suurtagalka ah, tusaale ahaan noocyada afka n-gram, sababtoo ah waxyaabaha kale waxey ku faa’iido badan yihiin shaqooyinka aqoonsashada waqtiga iyo wakhtiga. Wixii suurtagalka ah oo looga soo jeedo WFA waxay noqon kartaa noocyo badan. Sida uu sameynayo qaab dabiicadeed oo ka badan xilliyada, waxaynu soo jeedaynaa algoritm si a an u dhigno WFA, sida kaleback-Leibler kala duwanaanshaha noocyada iyo modelka waxqabadka WFA. Algorithm la soo jeeday wuxuu ku qoran yahay tallaabo xisaabta iyo kala duwan tallaabo qaabilaad, kaas oo labadoodaba si fiican loo sameeyo. Waxaynu muujinnaa faa'iidada qaababkayaga ku saabsan shaqaalaha kala duduwan, tusaalayaasha naxaadka, dhismada qaababka afka isku xiran, sameyna qaababka muuqashada aqoonta ee furan. Algorityada lagu isticmaalay imtixaankan waxaa laga helaa maktabadda software oo furan.", 'si': 'ප්\u200dරශ්න විශ්ණාත්මක සම්පූර්ණ සාමාන්\u200dය ස්වයංග්\u200dරහය (WFAs) සාමාන්\u200dය විදියට ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා, n-ග්\u200dරාම් භාෂාව මො ඒත් WFA වලින් ප්\u200dරතිනිධානය කරන්න පුළුවන් ප්\u200dරමාණයක් වෙන්න පුළුවන්. සාමාන්\u200dය සංභාවිත ප්\u200dරමාණයක් විදිහට, අපි ඒක WFA වලින් අල්ගෝරිතමයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා, ඒ වගේම මුළු මෝඩේල් සහ WFA ලක්ෂණ ප්\u200dරශ්නය කරපු ඇල්ගෝරිතම් එක්ක ගණන්න පැත්තක් සහ ප්\u200dරශ්නයක් තියෙනවා කොන්වෙක්ස් විශ්වාස කරන්න පුළුවන් ද අපි වෙනස් වැඩක් වෙනුවෙන් අපේ විදියට ප්\u200dරයෝජනයක් පෙන්වන්නේ, n-ග්\u200dරාම් මෝඩේල් විස්තර කරනවා න්\u200dයූරාල් මෝඩේල් වලින්, සම්ප මේ පරීක්ෂණ සඳහා භාවිත කරන්න ඇල්ගෝරිතම්ස් තියෙන්නේ විවෘත ප්\u200dරවෘත සොෆ්ටවේර් ලායිබර', 'sr': 'Apstraktički ograničeni automat (WFA) često se koristi za predstavljanje verovatnih modela, poput n-gramnih jezičkih modela, jer među ostalim stvarima, oni su efikasni za prepoznavanje zadataka u vremenu i svemiru. Verovatan izvor koji će biti predstavljen kao WFA, međutim, može doći u mnoge oblike. S obzirom na generički verovatni model preko sekvencija, predlažemo algoritam da ga približi kao WFA, tako da je razlika Kullback-Leibler a između izvornog modela i ciljnog modela WFA minimizirana. Predloženi algoritam uključuje korak brojanja i razliku koraka optimizacije konveksa, koji se oboje mogu efikasno provesti. Pokazujemo korisnost našeg pristupa na različitim zadacima, uključujući destilaciju n-gramnih modela iz neuralnih modela, izgradnju kompaktnih jezičkih modela i izgradnju otvorenih rečeničkih modela. Algoritmi koji se koriste za te eksperimente dostupni su u biblioteci otvorenog izvora softvera.', 'sv': 'Abstract Viktade finita automater (WFA) används ofta för att representera sannolikhetsmodeller, såsom n-gramsspråkmodeller, eftersom de bland annat är effektiva för identifieringsuppgifter i tid och rum. Den sannolika källan som ska representeras som ett WFA kan dock komma i många former. Med tanke på en generisk sannolikhetsmodell över sekvenser föreslår vi en algoritm för att ungefära den som en WFA så att Kullback-Leibler avvikelsen mellan källmodellen och WFA-målmodellen minimeras. Den föreslagna algoritmen innebär ett räkningsteg och en skillnad i konvex optimeringssteg, som båda kan utföras effektivt. Vi demonstrerar användbarheten av vårt tillvägagångssätt på olika uppgifter, inklusive destillering av n-grammomodeller från neurala modeller, byggande av kompakta språkmodeller och byggande av öppna ordförrådsmodeller. Algoritmerna som används för dessa experiment finns tillgängliga i ett programvarubibliotek med öppen källkod.', 'ta': 'சாத்தியமான மாதிரிகளை போன்ற n- gram மொழி மாதிரிகளை குறிப்பிட பயன்படுத்தப்படும். ஏனென்றால் வேறு விஷயங்களில், நேரத்திலும் இடைவெளியிலும் அடையாளம் செய்ய WFA என்று குறிப்பிடப்படும் சாத்தியமான மூலம் பல வடிவங்களில் வரும். பொதுவான சாத்தியமான மாதிரி கொடுத்தால், நாம் ஒரு WFA க்கு சுற்றியமாக அதை விரும்புகிறோம். மூலத்தின் மாதிரி மற்றும் WFA இலக்கு மாதிரி இடையேயுள்ள வேறுபாடு க பரிந்துரைக்கப்பட்ட ஆல்பரிதம் எண்ணிக்கையில் உள்ள படி மற்றும் கான்க்ஸ் மேம்படுத்தல் படியின் வேறுபாடு, அவைகள் இருவரும் வெ நாம் வேறு பணிகளில் எங்கள் செயல்பாடுகளின் பயன்பாட்டை காட்டுகிறோம், புதிய மாதிரிகளில் இருந்து n-gram மாதிரிகளை வேறுபடுத்தும், ஒப்பிட்ட ம இந்த சோதனைகளுக்கான பயன்படுத்தப்பட்ட ஆல்பரிட்டம் திறந்த மூல மென்பொருள் நூலகத்தில் கிடைக்கும்.', 'no': 'Abstrakt Vekt avslutta automat (WFA) er ofte brukt for å representera sannsynlige modeller, som n-gram språk-modeller, fordi dei er effektiv for gjenkjenning av oppgåver i tid og plass. Den sannsynlige kjelden som skal representerast som ein WFA kan likevel komme i mange skjemar. Given eit generiskt sannsynlig modell over sekvensar, fører vi ein algoritme for å omtrenga det som eit WFA slik at divergensen Kullback-Leibler mellom kjeldemodellen og målmodellen WFA er minimert. Det foreslått algoritmen involverer ein teljingsteg og ein forskjell av konveks optimaliseringssteg, begge av dei kan utførast effektivt. Vi demonstrerer n ødvendigheten av tilnærminga vårt på ulike oppgåver, inkludert distillering n-gram-modeller frå neuralmodeller, bygging av kompakte språk-modeller og bygging av opne-ordbokstav-modeller. Algoritmen som brukar for desse eksperimentane er tilgjengelege i ein opna kjeldeprogramvarbibliotek.', 'ur': 'ابسٹرک وایٹ فینی آٹوماٹ (WFAS) اکثر وقت اور فضا میں شائستہ کاروبار کی تصدیق کرنے کے لئے استعمال کئے جاتے ہیں۔ امید ہے کہ WFA کے طور پر نمایش کی جاتی ہے، مگر بہت سی فرموں میں آ سکتی ہے. ہم نے اس کو WFA کے مطابق تقریبا کرنے کے لئے ایک آلگوریتم کی امکانات موڈل کے ذریعہ سے پیش کیا ہے جس طرح کولباک-لیبلر موڈل اور WFA موڈل کے درمیان مختلف ہے۔ پیشنهاد الگوریتم میں ایک شمار سپے اور ایک تفاوت کی ہے، جسے دونوں مفید طور پر عمل کر سکتے ہیں. ہم طرح طرح کے کاموں پر اپنے طریقے کا فائدہ دکھاتے ہیں، ن-گرم موڈل کو نئورل موڈل سے جدا کرنے کے شامل ہے، کمپیٹ زبان موڈل بناتے ہیں، اور کھولے لکھے لکھے لکھے لکھنے والے موڈل بناتے ہیں. یہ آزمائش کے لئے استعمال ہوئے الگوریتم ایک آپن سورٹ سورٹ لئبری میں موجود ہیں.', 'uz': "Name @ info: whatsthis Ko'pchilik tugmalar birikmasi modeli bilan, biz uni WFA sifatida qisqarish uchun algoritni tahlil qilamiz. Bu yerda, Kullback-Leibler manba modeli orasidagi ajratish va WFA target modeli minimal qilinadi. Aniqlanadigan algoritm hisoblash va konveks optimiz darajasining o'zgarishlari, bu ikkita qanday foydalanishi mumkin. Biz har xil vazifalarda qancha ishlatimizning foydalanishimizni ko'rsatdik, neyrol modellaridan n gram modellarini ajratish, qisqa tilning modellarini yaratish va ochiq vositalar modellarini yaratish. Ushbu eksport uchun ishlatilgan algoritlar ochiq- manba dastur kutubxonasida mavjud.", 'vi': 'Thường sử dụng hệ thống đo lường giới hạn (WFA) để đại diện cho mô hình thể xác, như mô hình ngôn ngữ n-gram, bởi vì trong không gian và thời gian chúng có hiệu quả để nhận dạng. Tuy nhiên, các nguồn tin xác suất được đại diện làm Cơ đốc cầu có thể xuất hiện theo nhiều dạng. Dựa vào một mô hình xác suất chung trên dãy số, chúng tôi đề xuất một thuật to án để mô phỏng nó như một tổ chức QKK để sự khác biệt Kullback-Leibler giữa mẫu nguồn và mẫu mục tiêu của WFA được thu nhỏ nhất. Theo thuật toán được đề nghị thì phải tính từng bước và phân biệt các bước tăng trưởng theo giao thức. Cả hai đều có thể được thực hiện một cách hiệu quả. Chúng tôi chứng minh sự hữu ích của cách tiếp cận với các công việc khác nhau, bao gồm việc chưng cất các mô hình n-gram từ các mô hình thần kinh, xây dựng các mô hình ngôn ngữ gọn, và tạo ra các mô hình chữ mở từ. Những thuật toán được dùng cho các thí nghiệm này có trong thư viện phần mềm mở nguồn.', 'bg': 'Претеглените крайни автомати (УФА) често се използват за представяне на вероятностни модели, като например н-грамови езикови модели, тъй като наред с други неща те са ефективни за разпознаване на задачи във времето и пространството. Вероятният източник да бъде представен като WFA обаче може да дойде в много форми. Предвид генеричен вероятностен модел върху последователности, ние предлагаме алгоритъм, който да го приближи като ДФА, така че да се сведе до минимум отклонението между модела източник и целевия модел на ДФА. Предложеният алгоритъм включва стъпка на броене и разлика на изпъкналата стъпка на оптимизация, които могат да бъдат изпълнени ефективно. Ние демонстрираме полезността на нашия подход при различни задачи, включително дестилиране на н-грамови модели от невронни модели, изграждане на компактни езикови модели и изграждане на отворени модели на знаци. Алгоритмите, използвани за тези експерименти, са достъпни в софтуерна библиотека с отворен код.', 'nl': "Abstract Gewigde eindige automaten (WFA's) worden vaak gebruikt om probabilistische modellen weer te geven, zoals n-gram taalmodellen, omdat ze onder andere efficiënt zijn voor herkenningstaken in tijd en ruimte. De probabilistische bron die als WFA moet worden vertegenwoordigd, kan echter in vele vormen komen. Gezien een generiek probabilistisch model over sequenties, stellen we een algoritme voor om het te benaderen als een WFA, zodat de Kullback-Leibler divergentie tussen het bronmodel en het WFA doelmodel wordt geminimaliseerd. Het voorgestelde algoritme omvat een telstap en een verschil van convexe optimalisatiestap, die beide efficiënt kunnen worden uitgevoerd. We demonstreren het nut van onze aanpak voor verschillende taken, waaronder het distilleren van n-gram modellen uit neurale modellen, het bouwen van compacte taalmodellen en het bouwen van open vocabulaire karaktermodellen. De algoritmen die voor deze experimenten worden gebruikt, zijn beschikbaar in een open-source softwarebibliotheek.", 'da': "Vægtede finite automater (WFA'er) bruges ofte til at repræsentere sandsynlige modeller, såsom n-gram sprogmodeller, fordi de blandt andet er effektive til genkendelse opgaver i tid og rum. Den sandsynlige kilde, der skal repræsenteres som en WFA, kan imidlertid komme i mange former. Givet en generisk sandsynlighedsmodel over sekvenser, foreslår vi en algoritme til at tilnærme den som en WFA, således at Kullback-Leibler divergensen mellem kildemadellen og WFA målmodellen minimeres. Den foreslåede algoritme indebærer et tælletrin og en forskel i konveks optimeringstrin, som begge kan udføres effektivt. Vi demonstrerer nytten af vores tilgang til forskellige opgaver, herunder destillering af n-gram modeller fra neurale modeller, opbygning af kompakte sprogmodeller og opbygning af åbne ordforråd tegn modeller. De algoritmer, der anvendes til disse eksperimenter, er tilgængelige i et open source softwarebibliotek.", 'de': 'Abstract Gewichtete finite Automaten (WFA) werden häufig verwendet, um probabilistische Modelle, wie z.B. n-gram Sprachmodelle, darzustellen, weil sie unter anderem effizient für Erkennungsaufgaben in Zeit und Raum sind. Die probabilistische Quelle, die als WFA dargestellt werden soll, kann jedoch in vielen Formen vorliegen. Angesichts eines generischen probabilistischen Modells über Sequenzen schlagen wir einen Algorithmus vor, um es als WFA so zu approximieren, dass die Kullback-Leibler-Divergenz zwischen dem Quellmodell und dem WFA-Zielmodell minimiert wird. Der vorgeschlagene Algorithmus beinhaltet einen Zählschritt und eine Differenz des konvexen Optimierungsschritts, die beide effizient durchgeführt werden können. Wir demonstrieren die Nützlichkeit unseres Ansatzes für verschiedene Aufgaben, einschließlich der Destillation von n-Gramm-Modellen aus neuronalen Modellen, des Aufbaus kompakter Sprachmodelle und des Aufbaus offener Vokabeln Charaktermodelle. Die für diese Experimente verwendeten Algorithmen stehen in einer Open-Source-Softwarebibliothek zur Verfügung.', 'hr': 'Abstraktički ograničeni automat (WFAs) često se koristi za predstavljanje vjerojatnih modela, poput n-gramnih jezičkih modela, jer među drugim stvarima, oni su učinkoviti za prepoznavanje zadataka u vremenu i svemiru. Vjerojatni izvor koji će biti predstavljen kao WFA, međutim, može doći u mnoge oblike. S obzirom na generični vjerojatni model preko sekvencija, predlažemo algoritam da ga približi kao WFA, tako da se razlika Kullback-Leibler a između izvornog modela i ciljnog modela WFA minimizira. Predloženi algoritam uključuje korak brojanja i razliku koraka optimizacije konveksa, koji se oboje mogu učinkovito provesti. Mi pokazujemo korisnost našeg pristupa na različitim zadacima, uključujući destilaciju n-grama modela iz neuralnih modela, izgradnju kompaktnih jezičkih modela i izgradnju otvorenih rečeničkih modela. Algoritmi koji se koriste za te eksperimente dostupni su u biblioteci otvorenog izvora softvera.', 'ko': '추상 가중치 유한 자동기(WFA)는 일반적으로 확률 모델, 예를 들어 n-gram 언어 모델을 표시하는데 다른 것을 제외하고는 시간과 공간에서 식별 임무에 효과적이기 때문이다.그러나 WFA로 표시된 확률원은 여러 형태가 있을 수 있다.서열상의 일반 확률 모델을 제시하고 우리는 이를 WFA와 비슷하게 하는 알고리즘을 제시하여 원본 모델과 WFA 목표 모델 사이의 Kullback-Leibler 산도를 최소화시켰다.이 알고리즘은 하나의 계수보와 하나의 차분철 최적화보를 포함하는데 이 두 단계는 모두 효과적으로 집행할 수 있다.우리는 신경 모델에서 n-gram 모델을 추출하고 치밀한 언어 모델을 구축하며 개방된 어휘표 문자 모델을 구축하는 등 다양한 임무의 유용성을 보여 주었다.이러한 실험에 사용되는 알고리즘은 소스 소프트웨어 라이브러리에서 찾을 수 있다.', 'id': 'Abstrakt Weighted finite automata (WFAs) sering digunakan untuk mewakili model probabilis, seperti model bahasa n-gram, karena diantara hal lain, mereka efisien untuk tugas pengenalan dalam waktu dan ruang. Sumber kemungkinan untuk dipilih sebagai WFA, bagaimanapun, mungkin datang dalam banyak bentuk. Berdasarkan model probabilis generik melalui urutan, kami mengusulkan algoritma untuk mendekatinya sebagai WFA sehingga divergensi Kullback-Leibler antara model sumber dan model sasaran WFA diminumkan. Algoritma yang diusulkan melibatkan langkah penghitungan dan perbedaan langkah optimisasi konveks, yang keduanya dapat dilakukan secara efisien. We demonstrate the usefulness of our approach on various tasks, including distilling n-gram models from neural models, building compact language models, and building open-vocabulary character models.  Algoritma yang digunakan untuk eksperimen ini tersedia di perpustakaan perisian sumber terbuka.', 'sw': 'Huduma za kujitegemea kwa ndege (WFA) mara nyingi hutumiwa kuwakilisha mifano ya uwezekano, kama vile mifano ya lugha ya gram, kwa sababu pamoja na mambo mengine, wanakuwa na ufanisi wa kutambua kazi wakati na anga. Chanzo cha uwezekano kinachoonekana kama WFA, hata hivyo, inaweza kuja kwa namna nyingi. Kutokana na mtindo wa uwezekano wa kawaida zaidi ya mfululizo, tunapendekeza utambulisho wa kuikaribia kama WFA kama vile tofauti ya Kullback-Leibler kati ya muundo wa chanzo na modeli ya lengo la WFA ni chini kabisa. The proposed algorithm involves a counting step and a difference of convex optimization step, both of which can be performed efficiently.  Tunaonyesha matumizi ya mitazamo yetu katika kazi mbalimbali, ikiwa ni pamoja na kutofautisha mifano ya gram kutoka kwenye mifano ya ubongo, kujenga mifano ya lugha yenye ushirikiano, na kujenga mifano ya uwazi wa lugha. Makala yanayotumiwa kwa majaribio haya yanapatikana katika maktaba ya programu huru.', 'tr': "Abstrakt Ýagtymly Boýyn Otomaty (WFAs) köplenç sanal nusgalary, mysal n-gram dil nusgalary görkezmek üçin ullanýar, sebäbi başga zatlaryň arasynda wagt we seleňde tanamak üçin etkinlik bar. Ýöne WFA'da görkezilmeli mümkin çeşme köpüsi şeklinde bolup biler. Umumy mümkin bir nusga görä, bu nusga üçin WFA hasaplamak üçin bir algoritm teklip edip görýäris Önerlenen algoritm sanlama adımy we konveks optimizasyň adımynyň farklygyny bar. Bu ikisi hem faydaly edip bilýär. Biz öz ýaryşymyzyň n ähili işlerde ulanylygyny görkeýäris, näral modellerinden n n-gram modellerini çykarmak, kompakt dil modellerini gurmak we aç-sözli karakter modellerinden gurmak üçin. Bu deneyler üçin ullanýan algoritmalar açyk-çeşme softwär kitaphanesinde bar.", 'fa': 'اغلب برای نمایش مدلهای احتمالاتی مانند مدلهای زبان n گرم استفاده می\u200cشوند، زیرا در بین چیزهای دیگر، آنها برای کارهای شناسایی در زمان و فضا موثر هستند. ولی منبع احتمالی که به عنوان یک WFA نمایش داده شود، ممکن است در بسیاری فرم بیاید. با توجه به یک مدل احتمالی ژنرالی بر روی ترکیب ها، ما یک الگوریتم را پیشنهاد می کنیم که آن را به عنوان یک WFA تقریبا کند، که اختلاف Kullback-Leibler بین مدل منبع و مدل هدف WFA minimized می شود. الگوریتم پیشنهاد با یک قدم شمارش و یک تفاوت از قدم optimization convex است که هر دو می توانند به طور موثر انجام دهند. ما استفاده از دسترسی خود را بر کار های مختلف نشان می دهیم، شامل جدا کردن مدلهای n-گرم از مدلهای عصبی، ساختن مدلهای زبان پیچیده و ساختن مدلهای شخصیت باز و آشکار. الگوریتم\u200cها که برای این آزمایشات استفاده می\u200cشوند در کتابخانه\u200cی نرم\u200cافزار منبع باز موجود می\u200cشوند.', 'af': "Abstrakte Gewigte eindige outomata (WFAs) word dikwels gebruik om waarskynlike modele te verteenwoordig, soos n-gram taal modele, omdat onder ander dinge hulle effektief is vir herken opdragte in tyd en spasie. Die waarskynlik bron wat as 'n WFA verteenwoordig word, kan egter in baie vorms kom. Gien 'n generieke waarskynlike model oor sekwensies, voorstel ons 'n algoritme om dit as 'n WFA te beskou sodat die Kullback-Leibler afwyking tussen die bron model en die WFA doel model is minimiseer. Die voorgestelde algoritme involveer 'n tel stap en 'n verskil van konvex optimaliseeringstap, albei van wat effektief kan uitgevoer word. Ons wys die bruikbaarheid van ons toegang op verskeie taak, insluitend afdeling van n-gram modele van neurale modele, bou kompakte taal modele en bou oop-woordeboek karaktermodele. Die algoritme wat vir hierdie eksperimente gebruik word, is beskikbaar in 'n open-bron sagteware biblioteek.", 'sq': 'Automatika Abstract Weighted finite (WFAs) shpesh përdoret për të përfaqësuar modele probabiliste, të tilla si modelet e gjuhës n-gram, sepse midis gjërave të tjera, ato janë të efektshme për detyrat e njohjes n ë kohë dhe hapësirë. Burimi probabilist që do të përfaqësohet si një WFA, megjithatë, mund të vijë në shumë forme. Duke pasur parasysh një model gjeneral probabilist mbi sekuencat, ne propozojmë një algoritëm për ta përafërsuar atë si një WFA në mënyrë që dallimi Kullback-Leibler midis model it burimi dhe modelit objektiv WFA të minimizohet. Algoritmi i propozuar përfshin një hap numërimi dhe një ndryshim në hapin e optimizimit të konveksit, të dy të cilat mund të kryehen me efektshmëri. Ne demonstrojmë dobinë e qasjes sonë n ë detyra të ndryshme, duke përfshirë distilimin e modeleve n-gram nga modelet neurale, ndërtimin e modeleve të gjuhës kompakte dhe ndërtimin e modeleve të karakterit të fjalëkalimit të hapur. Algoritmet e përdorura për këto eksperimente janë në dispozicion në një bibliotekë softueresh me burim të hapur.', 'am': 'የ-ግራም ቋንቋ ምሳሌዎች፣ ምክንያቱም ሌሎች ነገሮች በጊዜና በስፍራው ለማወቅ ስራዎችን በጥቅም ይችላሉ፡፡ ምንም እንኳን የሚቻለው የWFA መልዕክት በብዙ ፎርማቶች ሊመጣ ይችላል፡፡ የውጤት ምሳሌ በተደረገ ቁጥር ላይ በተደረገ ጊዜ፣ የኩልቡክ-ሊባር በኩል ሞዴል እና የWFA አካል ሞዴል መቆጣጠር እንደሚያሳየው አሌጎሪትምን እናሳውቃለን፡፡ በተዘጋጀው አልጎሪም የቁጥጥር እርምጃና የኮንክስ ምርጫዎች እርምጃን ያስተካክላል፣ ሁለቱም በጥቅም ይደረጋሉ፡፡ የ-ግራም ዓይነቶች ከናውሮል ሞዴላዎች፣ የቋንቋ ምሳሌዎች መሥራት እናስቀምጣለን፣ የተከፈተ የግልፅ ቃላት ምሳሌ እናደርጋለን፡፡ እነዚህን ፈተናዎች የሚጠቀሙት አልጎርጂቶች በተከፈተ ሶፍትዌር መብረክ ውስጥ ይገኛሉ።', 'hy': 'Աբստրակտ Կարժեցված սահմանափակ ավտոմատները հաճախ օգտագործվում են հավանական մոդելների ներկայացնելու համար, ինչպիսիք են n-գրամ լեզվի մոդելները, որովհետև, մյուս դեպքում, դրանք արդյունավետ են ժամանակի և տարածության ճանաչողական գործերի համար: Այնուամենայնիվ, հավանական աղբյուրը, որը ներկայացված է որպես ՎԱՀ, կարող է բազմաթիվ ձևերով գալ: Հաշվի առնելով հաջորդականությունների ընդհանուր հավանական մոդելը, մենք առաջարկում ենք ալգորիթմ, որպեսզի այն մոտավորվի որպես ՎԱՀ, այնպես, որ կոլբաքս-Լեյբլերի տարբերությունը աղբյուր մոդելի և ՎԱՀ նպատակային մոդելի միջև նվազեցվի Անհրաժեշտ ալգորիթմը ներառում է հաշվարկի քայլ և կոնֆեքսիվ օպտիմացման քայլի տարբերություն, որոնք երկուսն էլ կարող են արդյունավետ կատարվել: Մենք ցույց ենք տալիս մեր մոտեցումների օգտակարությունը տարբեր խնդիրների վրա, ներառյալ n-գրամ մոդելների բաժանելը նյարդային մոդելներից, կառուցվածքը խիստ լեզվի մոդելների և բաց բառերի հիմքերի մոդելների կառուցված Այս փորձարկումների համար օգտագործված ալգորիթմները հասանելի են բաց կոդֆորմային ծրագրային գրադարանում:', 'az': 'Abstrakt Ölçülü sonlu automata (WFAs) çox zaman və uzayda mümkünlü modelləri, n-gram dil modelləri kimi göstərmək üçün istifadə edilir, çünki digər şeylərdən başqa şeylər arasında, onlar vaxtda və uzayda tanıma işləri üçün faydalanırlar. Lakin WFA olaraq göstəriləcək mümkün olaraq çoxlu formlarda olar. Sıradan çox olaraq mümkün bir modeli olaraq, biz onu WFA kimi yaxınlaşdırmaq üçün bir algoritm təklif edirik ki, Kullback-Leibler mənbə modeli və WFA məqsəd modeli arasındakı dəyişiklik düşürülmüşdür. Öndərilən algoritm sayma adımı və konveks optimizasyonu adımının fərqli olması ilə birlikdə hər ikisinin effektiv olar. Biz n öral modellərdən n-gram modellərini ayırmaq, kompakt dil modellərini inşa etmək və açıq-sözlü karakter modellərini inşa edirik. Bu təcrübələr üçün istifadə edilən algoritmi açıq-kaynak yazılım kitabısında faydalanır.', 'bn': 'স্বয়ংক্রিয়ভাষার মডেল, যেমন n-গ্রাম ভাষার মডেল, প্রায়শই ব্যবহার করা হয়, কারণ অন্যান্য কাজের মধ্যে তারা সময় ও স্থানে স্বীকৃতির কাজের জন্য কার্যকর। তবে উইএফএ হিসেবে প্রতিনিধিত্ব করা সম্ভাব্য উৎস অনেক ফর্মে আসতে পারে। সেকেন্দ্রের বিভিন্ন সাধারণ সম্ভাব্য মডেল দিয়ে আমরা একটি অ্যালগরিদম প্রস্তাব করছি যেমন উৎস মডেল এবং উইএফএ টার্গ মডেলের মধ্যে কুল্লব্যাক-লেইব্লারের বিভেদ কমিয়ে দ প্রস্তাবিত অ্যালগরিদম একটি গণনা পদক্ষেপ এবং কনকল্যাক্স অপারেশন পদক্ষেপের পার্থক্যের মধ্যে রয়েছে, যাদের উভয়কে কার্ আমরা বিভিন্ন কাজের উপর আমাদের পদক্ষেপ প্রদর্শন করি, যার মধ্যে নিউরেল মডেল থেকে এন-গ্রাম মডেল বিচ্ছিন্ন করা, প্রতিষ্ঠানের ভাষার মডেল তৈরি করা এব এই পরীক্ষার জন্য ব্যবহৃত অ্যালগরিদম একটি উন্মুক্ত সোর্স সফটওয়্যার লাইব্রেরীতে পাওয়া যাচ্ছে।', 'bs': 'Abstraktički ograničeni automat (WFAs) često se koristi za predstavljanje verovatnih modela, poput n-gramnih jezičkih modela, jer među ostalim stvarima, oni su učinkoviti za prepoznavanje zadataka u vremenu i svemiru. Verovatan izvor koji će biti predstavljen kao WFA, međutim, može doći u mnoge oblike. S obzirom na generični vjerojatni model preko sekvencija, predlažemo algoritam da ga približi kao WFA tako da se razlika Kullback-Leibler a između izvornog modela i ciljnog modela WFA minimizira. Predloženi algoritam uključuje korak brojanja i razliku koraka optimizacije konveksa, koji se oboje mogu učinkovito provesti. Pokazujemo korisnost našeg pristupa na različitim zadacima, uključujući destilaciju n-gramnih modela iz neuralnih modela, izgradnju kompaktnih jezičkih modela i izgradnju otvorenih rečeničkih modela. Algoritmi koji se koriste za te eksperimente dostupni su u biblioteci otvorenog izvora softvera.', 'cs': 'Abstrakt Vážené konečné automaty (WFA) se často používají k reprezentaci pravděpodobnostních modelů, například n-gramových jazykových modelů, protože jsou mimo jiné efektivní pro rozpoznávací úlohy v čase a prostoru. Pravděpodobnostní zdroj, který má být reprezentován jako WFA, však může přijít v mnoha formách. Vzhledem k generickému pravděpodobnostnímu modelu nad sekvencemi navrhujeme algoritmus pro aproximaci jako WFA tak, aby byla minimalizována Kullback-Leiblerova divergence mezi zdrojovým modelem a cílovým modelem WFA. Navržený algoritmus zahrnuje krok počítání a rozdíl konvexního optimalizačního kroku, které lze provádět efektivně. Demonstrujeme užitečnost našeho přístupu při různých úkolech, včetně destilace n-gramových modelů z neuronových modelů, budování kompaktních jazykových modelů a budování znakových modelů s otevřenou slovní zásobou. Algoritmy použité pro tyto experimenty jsou k dispozici v open-source softwarové knihovně.', 'ca': "Automàtics finits pesats abstracts (WFAs) sovint s'utilitzen per representar models probabilistes, com els models de llenguatge n-gram, perquè, entre altres coses, són eficients per a tasques de reconeixement en el temps i l'espai. Però la font probabilista que es representi com a WFA pot venir en moltes formes. Tenint en compte un model probabilista genèric sobre seqüències, proposem un algoritme per aproximar-lo com a WFA de tal manera que la divergència Kullback-Leibler entre el model d'origen i el model d'objectiu WFA es minimitzi. L'algoritme proposat implica un pas de comptació i una diferència de pas d'optimització convex, ambdós poden ser executats eficientment. Demonstrem l'utilitat del nostre enfocament en diverses tasques, com la distillació de models n-gram a partir de models neurals, la construcció de models de llenguatge compactes i la construcció de models de caràcter de vocabulari obert. Els algoritmes utilitzats per aquests experiments estan disponibles en una biblioteca de software de codi obert.", 'et': 'Kaalutud piiratud automaate (WFA) kasutatakse sageli tõenäosusmudelite, näiteks n-grammi keelemudelite esindamiseks, sest muuhulgas on need tõhusad aja ja ruumi tuvastamise ülesannete jaoks. Tõenäosuslik allikas, mida esitatakse WFA-na, võib siiski olla mitmes vormis. Arvestades üldist tõenäosusmudelit järjestuste üle, pakume välja algoritmi, mis lähendaks seda WFA-na selliselt, et Kullback-Leibleri erinevus lähtemudeli ja WFA sihtmudeli vahel oleks minimeeritud. Kavandatud algoritm hõlmab loendamise etappi ja kumera optimeerimise etapi erinevust, mida mõlemat saab efektiivselt teostada. Näitame oma lähenemisviisi kasulikkust erinevates ülesannetes, sealhulgas n-grammi mudelite destilleerimisel närvimudelitest, kompaktsete keelemudelite ehitamisel ja avatud sõnavara märkmudelite ehitamisel. Nende katsete algoritmid on kättesaadavad avatud lähtekoodiga tarkvara teegis.', 'fi': 'Painotettuja äärellisiä automaatteja (WFA) käytetään usein todennäköisyysmallien, kuten n-gramman kielimallien, esittämiseen, koska ne ovat tehokkaita muun muassa tunnistamistehtävissä ajassa ja tilassa. Todennäköinen lähde, joka esitetään WFA:na, voi kuitenkin olla monissa muodoissa. Kun otetaan huomioon yleinen todennäköisyysmalli sekvenssien yli, ehdotamme algoritmia sen likimäärittämiseksi WFA:na siten, että Kullback-Leibler-poikkeama lähdemallin ja WFA:n kohdemallin välillä minimoidaan. Ehdotettu algoritmi sisältää laskentavaiheen ja kuperan optimointivaiheen eron, jotka molemmat voidaan suorittaa tehokkaasti. Osoitamme lähestymistapamme hyödyllisyyden erilaisissa tehtävissä, kuten n-gramman mallien tislauksessa neuromalleista, kompaktien kielimallien rakentamisessa ja avoimen sanaston merkkimallien rakentamisessa. Näissä kokeissa käytetyt algoritmit ovat saatavilla avoimen lähdekoodin ohjelmistokirjastossa.', 'jv': 'All Suoro perbudhakan kelompok dianggo WFD, nguasai, iso dianggo akeh akeh Format. Nyong ngowe sistem sing paling-perusahaan sistem sing wis an a dadi, kita supoyo Algorithm kanggo kelas kotak sing nyimpen NVO karo model Kullback-Lebler Algorithm Awak dhéwé éntuk kesempatan ngéwé kesempatan ning sami tasks, gambar nggambar model n-gram karo model alat, nggawe kompct language model, lan nggawe open-Vocaturé model. Algorithm sing dikenabah kanggo nyusun iki ning sampeyan pakan kelompok Open-source', 'sk': 'Uteženi končni avtomati (WFA) se pogosto uporabljajo za predstavitev verjetnostnih modelov, kot so n-gramski jezikovni modeli, saj so med drugim učinkoviti pri prepoznavanju nalog v času in prostoru. Verjetnostni vir, ki ga je treba predstaviti kot WFA, pa je lahko v več oblikah. Glede na generični verjetnostni model nad zaporedji predlagamo algoritem za približevanje kot WFA tako, da je Kullback-Leiblerjeva divergenca med izvornim modelom in ciljnim modelom WFA čim manjša. Predlagani algoritem vključuje korak štetja in razliko konveksne optimizacije, ki ju je mogoče izvesti učinkovito. Prikazujemo uporabnost našega pristopa pri različnih nalogah, vključno z destiliranjem n-gramskih modelov iz nevronskih modelov, gradnjo kompaktnih jezikovnih modelov in gradnjo modelov znakov odprtega besedišča. Algoritmi, ki se uporabljajo za te poskuse, so na voljo v odprtokodni knjižnici programske opreme.', 'ha': "Ana amfani da maras a ƙayyade masu yiwuwa, kamar misãlai na-gram, don haka, dõmin da wasu abu, sun fi amfani da masu gane aikin bayani a lokaci da fili. Kizarar da ake iya nuna kamar WFA, kuma amma, za ya iya zo cikin wasu former. Gida wata motsi mai yiwuwa a kan sauri masu sakan, sai mu buƙata algoritm don a sami shi kamar WFA, cewa diffanin Kullback-Leibler tsakanin maɓallin komai da motel na WFA za'a ƙaranci. Algoritm da aka goyyade shi yana ƙunsa da wata ƙyama mai ƙidãya da wani daban na cire kwamfyutan teburi, wanda za'a iya cika su da kafi. Tuna nuna amfani da aikin mu kan aikin dabam-daban, kamar rarrabe misãlai na n-gram daga misãlai na ƙarura, da za'a sami misãlai da ke samu'in da za'a samu'a cikin misalin ayuka da ake buɗe. Algorituman da ake amfani da wa wannan jarraba za'a iya cikin littãfin kwamfyuta mai buɗewa.", 'he': 'אוטומטיקה מוגבלת משקלת אוסטרקטית (WFAs - Abstract Weighted Limited Automatic Automatics, WFAs - WFAs - Abstract Weighted Limited Automatic Automatic Automatic Automatic Automatics, WFAs - WFAs - Abstract Weighted Limited Automatic Automatic Automatics, WFAs - WFAs המקור הסביר לייצג כWFA, עם זאת, יכול לבוא בצורות רבות. בהתחשב במודל סיכוי גנרלי במהלך רצפים, אנו מציעים אלגוריתם כדי להתקרב לזה כWFA כך שהדיווג קולבק-לייבלר בין מודל המקור למודל המטרה של WFA נמנע. האלגוריתם המוצע כולל צעד ספירה והשונה של צעד אופטימיזציה קונבקס, שניהם יכולים להיבצע בצורה יעילה. אנו מראים את שימושי הגישה שלנו על משימות שונות, כולל למחוק דוגמנים n-גרם מדוגמנים עצביים, לבנות דוגמנים שפתיים חדים, ולבנות דוגמנים אופי מילים פתוחים. האלגוריתמים המשתמשים בניסויים האלה זמינים בספריית תוכנה מקור פתוח.', 'bo': 'ལམ་ལུགས་ཀྱི་ཕྱིར་ཉིད་མཐའ་འགྱུར་བའི་རང་འགུལ་གྱི་རྣམ་པ(WFAs)འདི་རྒྱུན་དུ་ནུས་པ་གནོད་སྐྱེན་པའི་མ་དཔེ་དཔེར་ན(n-gram)སྐད་རིགས་དཔེ་རིགས་དང་། གང་ལགས་གཞན ཡིན་ནའང་། དཔལ་ཆེན་གྱི་འབྱུང་རྐྱེན་དེ་WFA ཞིག་མཚོན་དགོས་པ་ཡིན་ནའང་དབྱིབས་མང་པོ་ཞིག་ཡོད་ཐུབ། Given a generic probabilistic model over sequences, we propose an algorithm to approximate it as a WFA such that the Kullback-Leibler divergence between the source model and the WFA target model is minimized. This is the driving force and the WFA target model. གྲོས་འཆར་བཀོད་པའི་ས Algorithm་དེ་འདིས་རྩིས་ཀྱི་གྲལ་རིམ་དང་མཐའ་ཕན་ཚུན་གྱི་ཁྱད་པར་གཅིག་མཚུངས་ཡིན། We demonstrate the usefulness of our approach on various tasks, including distilling n-gram models from neural models, building compact language models, and building open-vocabulary character models. experiment with these experiments are available in an open-source software library.'}
{'en': 'RYANSQL : Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases', 'ar': 'RYANSQL: تطبيق متكرر لحشوات الفتحات المستندة إلى Sketch للنص المعقد إلى SQL في قواعد البيانات عبر المجالات', 'fr': "RYANSQL\xa0: Application récursive de remplissages d'emplacements basés sur des croquis pour des textes complexes en SQL dans des bases de données interdomaines", 'pt': 'RYANSQL: Aplicando recursivamente preenchimentos de slot baseados em esboço para texto para SQL complexo em bancos de dados entre domínios', 'es': 'RYANSQL: Aplicación recursiva de rellenos de ranuras basados en bocetos para texto a SQL complejo en bases de datos entre dominios', 'ja': 'RYANSQL ：クロスドメインデータベースの複雑なテキストからSQLへのスケッチベースのスロット充填を再帰的に適用する', 'zh': 'RYANSQL曰:递归填 Sketch 槽于跨域数据库,杂文本于 SQL', 'hi': 'RYANSQL: पुनरावर्ती रूप से क्रॉस-डोमेन डेटाबेस में जटिल पाठ-से-SQL के लिए स्केच-आधारित स्लॉट फिलिंग्स लागू करना', 'ru': 'RYANSQL: Рекурсивно применяя заполнение слотов на основе эскизов для сложных текстовых файлов в междоменных базах данных', 'ga': 'RYANSQL: Líontaí Sliotán Sceitseáil-bhunaithe a Chur i bhFeidhm Athchúrsach ar Téacs-go-SQL Coimpléascach i mBunachar Sonraí Tras Fearainn', 'hu': 'RYANSQL: Folyamatosan alkalmazható vázlat alapú slot töltések komplex szöveg-SQL-hez tartományközi adatbázisokban', 'el': 'Επαναστατική εφαρμογή συμπληρωμάτων αυλακώσεων με βάση το σκίτσο για σύνθετο κείμενο-σε-SQL σε βάσεις δεδομένων μεταξύ τομέων', 'ka': 'QUnicodeControlCharacterMenu', 'it': 'RYANSQL: Applicazione ricorsiva di riempimenti di slot basati su schizzi per complessi da testo a SQL in database cross-domain', 'kk': 'RYANSQL: Қос- домен деректер қорларында комплекс мәтін- мен SQL- тің слотты толтыру үшін Sketch- негіздеген қайтарап қолданылады', 'mk': 'РИАНСКЛ: Рекурсивно применување на полнење на слотови на скетки за комплексен текст до SQL во базите на податоци на крстодомените', 'lt': 'RYANSQL: kompleksinio teksto į SQL kompleksinių duomenų bazių tarpdomeninėse duomenų bazėse rekursyviai taikomi skeetch grindžiami laiko tarpsniai', 'ms': 'RYANSQL: Menggunakan Penisi Slot berdasarkan Sket secara rekursif untuk Teks-ke-SQL kompleks dalam Pangkalan Data Salib Domain', 'ml': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'mt': 'RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases', 'mn': 'RYANSQL: Төрөгдлийн өгөгдлийн сан дээр комплекс текст-ээс SQL-ээр Скетт-ээр суурилсан слот дүүрэлтүүдийг дахин ашиглах', 'pl': 'RYANSQL: Rekursywne stosowanie wypełnień gniazd opartych na szkicu dla złożonego tekstu do SQL w bazach danych między domenami', 'ro': 'RYANSQL: Aplicarea recursivă a umpluturilor de sloturi bazate pe schițe pentru complexe text-to-SQL în bazele de date cross-domain', 'no': 'RYANSQL: Rekursivt brukar Sketch- basert slot- fylling for kompleks tekst- til- SQL i krysdomenedatabaser', 'sr': 'RYANSQL: Rekursivno primjenjivanje slota na osnovu Sketka za kompleksni tekst na SQL u bazi podataka preko domena', 'so': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'sv': 'RYANSQL: Rekursivt tillämpa skissbaserade kortfyllningar för komplexa text-till-SQL i databaser över domäner', 'ta': 'RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases', 'si': '@ info: whatsthis', 'ur': 'RYANSQL: Cross- Domain Databases میں مکمل متن- to- SQL کے لئے اسکیٹ بنیاد اسلوٹ پر لٹ بھرنے کے لئے دوبارہ استعمال کیا جا رہا ہے', 'uz': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'vi': 'Bộ vẽ dốc có tính dụng lại cho nhiều văn bản tới SQL phức tạp trong nhà dữ liệu chéo miền', 'bg': 'Рекурсивно прилагане на слотове базирани на скици запълвания за комплексни текстове в бази данни с междудомейни', 'da': 'RYANSQL: Rekursivt anvendelse af skitsebaserede slot fyldninger til komplekse tekst-til-SQL i databaser på tværs af domæner', 'hr': 'RYANSQL: Rekursivno primjenjivanje slota na osnovu Sketcha za kompleksni tekst do SQL u bazi podataka preko domena', 'nl': 'RYANSQL: Recursief toepassen van schetsgebaseerde sleuvenvullingen voor complexe tekst-naar-SQL in domeinoverschrijdende databases', 'de': 'RYANSQL: Rekursives Anwenden skizzenbasierter Slot-Füllungen für komplexe Text-to-SQL in domänenübergreifenden Datenbanken', 'id': 'RYANSQL: Mengaplikasikan secara rekursif Penisi Slot berdasarkan Sketch untuk Teks-ke-SQL kompleks dalam Pangkalan Data Cross-Domain', 'fa': 'RYANSQL: استفاده کردن پر کردن Slot based on Sketch برای متن kompleks- to- SQL در داده\u200cهای داده\u200cهای Cross- Domain', 'ko': 'RYANSQL: SQL에 복잡한 텍스트의 초안 기반 슬롯 채우기 반복 적용', 'tr': 'RYANSQL: Çoklu alan veritabanlarında Complex Metin-dan SQL için Sket tabanlı Slot dolumları tekrardan uygulama', 'af': 'QUnicodeControlCharacterMenu', 'sw': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'sq': 'RYANSQL: Aplikimi rekursiv i plotësimeve të intervaleve bazuar në sketch për tekstin kompleks në SQL në bazat e të dhënave transdomenale', 'hy': 'RYATSQL: Կարգավորապես օգտագործելով Sketch-ի հիմնված ընթացքի լրացումները բարդ տեքստի-սQL-ի համար միջբեռի տվյալների բազաներում', 'am': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'az': 'RYANSQL: Üstüsüz Domena Verici Bağlarında kompleks Metin-to-SQL üçün Süt-tabanlarını rekursiv uyğula bilər', 'bn': 'Please see http: // europa. eu. int/ eur- lex/ LexUriServ/ LexUriServ/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'bs': 'RYANSQL: Rekursivno primjenjivanje slota na osnovu Sketcha za kompleksni tekst na SQL u bazi podataka preko domena', 'ca': "RYANSQL: Aplicar recursivament llençaments d'intervals basats en esquets per a un text complexe a un SQL en bases de dades transdomàniques", 'cs': 'RYANSQL: Rekurzivní aplikace výplní slotů založených na skecích pro komplexní text-to-SQL v databázích mezi doménami', 'et': 'RYANSQL: Sketch-põhiste pesade täitmise rekursiivne rakendamine keerulistele tekstist SQL-i-le domeenidevahelistes andmebaasides', 'fi': 'RYANSQL: Sketch-pohjaisten korttipaikkojen rekursiivinen soveltaminen monimutkaisiin tekstiin SQL-tiedostoiksi toimialueiden välisissä tietokannoissa', 'jv': 'Relative', 'he': 'RYANSQL: שימוש מחדש במילוי סגרות מבוססים על סגרות עבור מסובך טקסט-ל-SQL בבסיסיסי נתונים', 'ha': 'RYANSQL: Applied Recursive Applied Fillingues based on Setch for Complex Text- to-SQL in KCharselect unicode block name', 'sk': 'RYANSQL: Rekursivna uporaba polnil rež na osnovi skic za kompleksno besedilo v SQL v meddomenskih zbirkah podatkov', 'bo': 'RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases'}
{'en': 'Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given. In this article, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested SELECT statements ; a sketch-based slot-filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further. RYANSQL achieved competitive result of 58.2 % accuracy on the challenging Spider benchmark. At the time of submission (April 2020), RYANSQL v2, a variant of original RYANSQL, is positioned at 3rd place among all systems and 1st place among the systems not using database content with 60.6 % exact matching accuracy. The source code is available at https://github.com/kakaoenterprise/RYANSQL.', 'ar': 'Abstract Text-to-SQL هي مشكلة تحويل سؤال المستخدم إلى استعلام SQL ، عند طرح السؤال وقاعدة البيانات. في هذه المقالة ، نقدم نهج شبكة عصبية يسمى RYANSQL (شبكة التعليق التوضيحي المتواترة لـ SQL) لحل مهام تحويل النص إلى SQL المعقدة لقواعد البيانات عبر المجالات. يتم تعريف رمز موضع العبارة (SPC) لتحويل استعلام SQL متداخل إلى مجموعة من عبارات SELECT غير المتداخلة ؛ يُقترح نهج ملء الفتحات المستند إلى الرسم التخطيطي لتجميع كل عبارة SELECT الخاصة ببطاقة SPC المقابلة لها. بالإضافة إلى ذلك ، يتم تقديم طريقتين لمعالجة المدخلات لتحسين أداء التوليد بشكل أكبر. حققت RYANSQL نتيجة تنافسية بلغت 58.2٪ من الدقة في اختبار Spider المعياري. في وقت التقديم (أبريل 2020) ، تم وضع RYANSQL v2 ، وهو متغير من RYANSQL الأصلي ، في المركز الثالث بين جميع الأنظمة والمركز الأول بين الأنظمة التي لا تستخدم محتوى قاعدة البيانات بدقة مطابقة 60.6٪. شفرة المصدر متاحة على https://github.com/kakaoenterprise/RYANSQL.', 'es': 'Resumen Text-to-SQL es el problema de convertir una pregunta de usuario en una consulta SQL, cuando se dan la pregunta y la base de datos. En este artículo, presentamos un enfoque de red neuronal llamado RYANSQL (Red de anotación de rendimiento recursivo para SQL) para resolver tareas complejas de texto a SQL para bases de datos entre dominios. El código de posición de sentencia (SPC) se define para transformar una consulta SQL anidada en un conjunto de instrucciones SELECT no anidadas; se propone un enfoque de relleno de ranuras basado en bocetos para sintetizar cada sentencia SELECT para su SPC correspondiente. Además, se presentan dos métodos de manipulación de entrada para mejorar aún más el rendimiento de la generación. RYANSQL logró un resultado competitivo de 58,2% de precisión en el desafiante punto de referencia Spider. En el momento de la presentación (abril de 2020), RYANSQL v2, una variante de RYANSQL original, ocupa el tercer lugar entre todos los sistemas y el primer lugar entre los sistemas que no utilizan contenido de base de datos con una precisión de coincidencia exacta del 60,6%. El código fuente está disponible en https://github.com/kakaoenterprise/RYANSQL.', 'fr': "Résumé Text-to-SQL est le problème de la conversion d'une question utilisateur en requête SQL, lorsque la question et la base de données sont fournies. Dans cet article, nous présentons une approche de réseau de neurones appelée RYANSQL (Recursively Yielding Annotation Network for SQL) pour résoudre des tâches text-to-SQL complexes pour des bases de données interdomaines. Le code de position d'instruction (SPC) est défini pour transformer une requête SQL imbriquée en un ensemble d'instructions SELECT non imbriquées\xa0; une approche de remplissage d'emplacements basée sur des croquis est proposée pour synthétiser chaque instruction SELECT pour son SPC correspondant. En outre, deux méthodes de manipulation d'entrée sont présentées pour améliorer encore les performances de génération. RYANSQL a obtenu un résultat compétitif avec une précision de 58,2\xa0% sur le banc d'essai difficile Spider. Au moment de la soumission (avril 2020), RYANSQL v2, une variante de RYANSQL original, se positionne à la 3e place parmi tous les systèmes et à la 1ère place parmi les systèmes n'utilisant pas de contenu de base de données avec une précision de correspondance exacte de 60,6\xa0%. Le code source est disponible sur https://github.com/kakaoenterprise/RYANSQL.", 'pt': 'Resumo Text-to-SQL é o problema de converter uma pergunta do usuário em uma consulta SQL, quando a pergunta e o banco de dados são fornecidos. Neste artigo, apresentamos uma abordagem de rede neural chamada RYANSQL (Recursively Yielding Annotation Network for SQL) para resolver tarefas complexas de Text-to-SQL para bancos de dados de domínio cruzado. O Statement Position Code (SPC) é definido para transformar uma consulta SQL aninhada em um conjunto de instruções SELECT não aninhadas; uma abordagem de preenchimento de slot baseada em sketch é proposta para sintetizar cada instrução SELECT para seu SPC correspondente. Além disso, dois métodos de manipulação de entrada são apresentados para melhorar ainda mais o desempenho da geração. O RYANSQL alcançou um resultado competitivo de 58,2% de precisão no desafiador benchmark Spider. No momento da submissão (abril de 2020), o RYANSQL v2, uma variante do RYANSQL original, está posicionado em 3º lugar entre todos os sistemas e 1º lugar entre os sistemas que não usam conteúdo de banco de dados com precisão de correspondência exata de 60,6%. O código-fonte está disponível em https://github.com/kakaoenterprise/RYANSQL.', 'ja': 'Abstract Text - to - SQLは、ユーザーの質問とデータベースが与えられたときに、ユーザーの質問をSQLクエリに変換する問題です。 この記事では、クロスドメインデータベースの複雑なText - to - SQLタスクを解決するためのRYANSQL (Recursively Yielding Annotation Network for SQL)と呼ばれるニューラルネットワークアプローチを紹介します。 ステートメント位置コード（ SPC ）は、ネストされたSQLクエリをネストされていないSELECTステートメントのセットに変換するために定義されています。スケッチベースのスロット充填アプローチは、対応するSPCの各SELECTステートメントを合成するために提案されています。 さらに、生成性能をさらに向上させるために、２つの入力操作方法を提示する。 RYANSQLは、挑戦的なSpiderベンチマークで58.2 ％の精度という競争力のある結果を達成しました。 提出時（ 2020年4月）、元のRYANSQLのバリアントであるRYANSQL v 2は、正確なマッチング精度が60.6 ％のデータベースコンテンツを使用していないシステムの中で、全システムの中で3位、1位に位置付けられています。 ソースコードはhttps://github.com/kakaoenterprise/RYANSQLから入手できます。', 'ru': 'Abstract Text-to-SQL - задача преобразования вопроса пользователя в SQL-запрос, когда задаются вопрос и база данных. В этой статье мы представляем нейросетевой подход под названием RYANSQL (Recursively Yielding Annotation Network for SQL) для решения сложных задач Text-to-SQL для междоменных баз данных. Код позиции оператора (SPC) определяется для преобразования вложенного SQL-запроса в набор невложенных инструкций SELECT; для синтеза каждого инструкции SELECT для соответствующего SPC предлагается подход на основе эскизов. Кроме того, представлены два способа манипулирования вводом для дальнейшего улучшения производительности генерации. RYANSQL добился конкурентного результата - 58,2% точности по сложному эталону Spider. На момент подачи заявки (апрель 2020) RYANSQL v2, вариант оригинального RYANSQL, занимает 3-е место среди всех систем и 1-е место среди систем, не использующих контент базы данных с точностью согласования 60,6%. Исходный код доступен по адресу https://github.com/kakaoenterprise/RYANSQL.', 'zh': '摘要 文本至SQL给定与数据库转用户为SQL所问。 本文有RYANSQL(RECURSIVE YIELD Annotation Network for SQL)神经网络之法,以决跨域数据库杂文本SQL务。 语句代码 (SPC) 用将嵌套 SQL 询转换为非嵌套 SELECT 语句。 立草图槽填法,以成SELECT语及其SPC。 供二输操作方法,以进一步提高生性。 RYANSQL于有挑战性之Spider,准试而得58.2%准确率之争。 提交时(2020 年 4 月),RYANSQL v2 为始 RYANSQL 之变体,凡统中第三,不用数据库者第一,准确率为 60.6%。 源代码在 https://github.com/kakaoenterprise/RYANSQL。', 'hi': 'Abstract Text-to-SQL एक उपयोगकर्ता प्रश्न को SQL क्वेरी में कनवर्ट करने की समस्या है, जब प्रश्न और डेटाबेस दिए जाते हैं। इस लेख में, हम क्रॉस-डोमेन डेटाबेस के लिए जटिल टेक्स्ट-टू-एसक्यूएल कार्यों को हल करने के लिए रयानएसक्यूएल (एसक्यूएल के लिए पुनरावर्ती रूप से उपज एनोटेशन नेटवर्क) नामक एक तंत्रिका नेटवर्क दृष्टिकोण प्रस्तुत करते हैं। कथन स्थिति कोड (SPC) एक नेस्टेड SQL क्वेरी को गैर-नेस्टेड SELECT कथनों के सेट में परिवर्तित करने के लिए परिभाषित किया गया है; एक स्केच-आधारित स्लॉट-भरने के दृष्टिकोण को इसके संबंधित एसपीसी के लिए प्रत्येक SELECT कथन को संश्लेषित करने का प्रस्ताव है। साथ ही, दो इनपुट हेरफेर विधियों को पीढ़ी के प्रदर्शन को और बेहतर बनाने के लिए प्रस्तुत किए जाते हैं। RYANSQL ने चुनौतीपूर्ण स्पाइडर बेंचमार्क पर 58.2% सटीकता का प्रतिस्पर्धी परिणाम प्राप्त किया। सबमिशन के समय (अप्रैल 2020), RYANSQL v2, मूल RYANSQL का एक संस्करण, सभी प्रणालियों के बीच तीसरे स्थान पर स्थित है और 60.6% सटीक मिलान सटीकता के साथ डेटाबेस सामग्री का उपयोग नहीं करने वाले सिस्टम के बीच पहला स्थान है। स्रोत कोड https://github.com/kakaoenterprise/RYANSQL पर उपलब्ध है।', 'ga': 'Teibí Téacs-go-SQL is ea an fhadhb a bhaineann le ceist úsáideora a thiontú ina ceist SQL, nuair a thugtar an cheist agus an bunachar sonraí. San Airteagal seo, cuirimid i láthair cur chuige líonra néaraigh ar a dtugtar RYANSQL (Líonra Anótála Atá Toradh Athchúrsach do SQL) chun tascanna casta Téacs-go-SQL a réiteach do bhunachair shonraí tras-fearainn. Sainmhínítear Cód Seasaimh Ráitis (SPC) chun ceist neadaithe SQL a athrú ina thacar de ráitis SELECT neamhneadaithe; moltar cur chuige líonta sliotán atá bunaithe ar sceitsí chun gach ráiteas SELECT a shintéisiú dá CPS comhfhreagrach. Ina theannta sin, cuirtear dhá mhodh láimhsithe ionchuir i láthair chun feidhmíocht ghiniúna a fheabhsú tuilleadh. Bhain RYANSQL toradh iomaíoch cruinnis 58.2% amach ar thagarmharc dúshlánach Spider. Tráth na haighneachta (Aibreán 2020), tá RYANSQL v2, leagan den RYANSQL bunaidh, sa 3ú háit i measc na gcóras go léir agus sa 1ú háit i measc na gcóras nach n-úsáideann ábhar bunachair shonraí le cruinneas meaitseála 60.6%. Tá an cód foinse ar fáil ag https://github.com/kakaoenterprise/RYANSQL.', 'hu': 'Absztrakt Text-to-SQL a felhasználói kérdések SQL lekérdezéssé alakításának problémája, amikor a kérdés és az adatbázis megadásra kerül. Ebben a cikkben bemutatjuk a RYANSQL (Recursively Yielding Annotation Network for SQL) nevű neurális hálózati megközelítést, amely komplex szöveg-SQL feladatok megoldásához tartományok közötti adatbázisokhoz. Az SPC (Statement Position Code) a beágyazott SQL-lekérdezések beágyazott SELECT utasítások halmazává alakítására szolgál; Az egyes SELECT utasítások szintetizálására a megfelelő SPC-hez egy vázlaton alapuló slot-töltési megközelítést javasoltunk, továbbá két bemeneti manipulációs módszert is bemutatunk a generációs teljesítmény további javítása érdekében. A RYANSQL 58,2%-os pontossággal versenyező eredményt ért el a kihívást jelentő Spider referenciaértéken. A benyújtás időpontjában (2020. április) a RYANSQL v2, az eredeti RYANSQL változata, az összes rendszer között harmadik helyen, az adatbázis tartalmát nem használó rendszerek között pedig az első helyen áll, 60,6%-os pontos pontossággal. A forráskód a következő címen érhető el: https://github.com/kakaoenterprise/RYANSQL.', 'el': 'Περίληψη Κείμενο-σε-είναι το πρόβλημα της μετατροπής μιας ερώτησης χρήστη σε ερώτημα όταν δίνεται η ερώτηση και η βάση δεδομένων. Σε αυτό το άρθρο, παρουσιάζουμε μια προσέγγιση νευρωνικού δικτύου που ονομάζεται για την επίλυση σύνθετων εργασιών κειμένου-σε-SQL για βάσεις δεδομένων μεταξύ τομέων. Ο κωδικός θέσης δήλωσης ορίζεται για να μετατρέψει ένα ένθετο ερώτημα σε ένα σύνολο μη ένθετων δηλώσεων. προτείνεται μια προσέγγιση πλήρωσης αυλακώσεων με βάση το σκίτσο για τη σύνθεση κάθε δήλωσης για την αντίστοιχη Επιπλέον, παρουσιάζονται δύο μέθοδοι χειρισμού εισόδου για τη βελτίωση της απόδοσης παραγωγής περαιτέρω. Η εταιρεία πέτυχε ανταγωνιστικό αποτέλεσμα ακρίβειας 58.2% στο απαιτητικό σημείο αναφοράς Σπάιντερ. Κατά τη στιγμή της υποβολής (Απρίλιο 2020), το είναι μια παραλλαγή του αρχικού βρίσκεται στην τρίτη θέση μεταξύ όλων των συστημάτων και στην 1η θέση μεταξύ των συστημάτων που δεν χρησιμοποιούν περιεχόμενο βάσης δεδομένων με ακρίβεια 60,6% ακριβούς αντιστοίχισης. Ο πηγαίος κώδικας διατίθεται στη διεύθυνση https://github.com/kakaoenterprise/RYANSQL.', 'lt': 'Abstract Text- to- SQL yra vartotojo klausimo perskaičiavimo į SQL klausimą problem a, kai pateikiamas klausimas ir duomenų bazė. Šiame straipsnyje pateikiamas neurologinio tinklo metodas, vadinamas RYANSQL (rekursyviai teikiančių pranešimų tinklas SQL), siekiant išspręsti sudėtingas teksto–SQL užduotis įvairių domenų duomenų bazėse. Pareiškimo pozicijos kodas (SPC) apibrėžiamas, siekiant paversti nested SQL klausimą nested SELECT pareiškimų rinkiniu; siūlomas schemų pagrindu pagrįstas laiko tarpsnių užpildymo metodas, kad kiekvienas SELECT pareiškimas būtų sintetizuotas pagal atitinkamą SPC. Be to, pateikiami du įvesties manipuliavimo metodai, siekiant toliau gerinti gamybos veiksmingumą. RYANSQL achieved competitive result of 58.2% accuracy on the challenging Spider benchmark.  Pateikimo metu (2020 m. balandžio mėn.), RYANSQL v2, originalaus RYANSQL variantas, yra trečioje vietoje tarp visų sistemų ir pirmoje vietoje tarp sistemų, kuriose duomenų bazės turinys nenaudojamas tiksliai atitinkant 60,6 %. The source code is available at  https://github.com/kakaoenterprise/RYANSQL.', 'it': "Abstract Text-to-SQL è il problema di convertire una domanda utente in una query SQL, quando la domanda e il database sono forniti. In questo articolo, presentiamo un approccio di rete neurale chiamato RYANSQL (Recursively Yielding Annotation Network for SQL) per risolvere complesse attività Text-to-SQL per database cross-domain. Il codice di posizione delle dichiarazioni (SPC) è definito per trasformare una query SQL nidificata in un insieme di istruzioni SELECT non nidificate; Viene proposto un approccio di riempimento slot basato su schizzi per sintetizzare ogni istruzione SELECT per il relativo SPC corrispondente. Inoltre, vengono presentati due metodi di manipolazione degli input per migliorare ulteriormente le prestazioni di generazione. RYANSQL ha ottenuto un risultato competitivo del 58,2% di precisione sul benchmark Spider impegnativo. Al momento della presentazione (aprile 2020), RYANSQL v2, una variante di RYANSQL originale, si posiziona al 3 ° posto tra tutti i sistemi e al 1 ° posto tra i sistemi che non utilizzano contenuti di database con una precisione di corrispondenza esatta del 60,6%. Il codice sorgente è disponibile all'indirizzo https://github.com/kakaoenterprise/RYANSQL.", 'ka': 'აბსტრაქტიკური ტექსტი- დან SQL- სკითხვისთვის გამოყენებელი კითხვა SQL- სკითხვისთვის პრობლემა, როდესაც კითხვა და ბაზატური დააყენება. ამ არქეში ჩვენ მივიღეთ ნეიროლური ქსელის პროგრამა, რომელიც სახელია RYANSQL (რეკურსიურად მივიღეთ SQL- სთვის ნოტაციის ქსელი) კომპლექსი ტექსტი- სა- SQL მონაცემების გარეშე Statement Position Code სკექტის დაფართებული სლოტის დაფართლების პროგრამა უნდა ყველა SELECT განახლების სინტეზიზაცია თავის შესაბამისი SPC-ის შესაბამისი. დამატებით, ორი შესაბამისი მანუპულაციის მეტი მომხმა RYANSQL წარმოდგენა კონსპექტიური წარმოდგენა 58.2% წარმოდგენების წარმოდგენების წარმოდგენება. პროგრამის განსაზღვრების დროში (აპრილი2020) RYANSQL v2, პირველ RYANSQL-ის განსაზღვრება, სამუშაო ადგილში ყველა სისტემის და სამუშაო ადგილი სისტემის შორის და სამუშაო ადგილი სისტემის შორის, რომელიც მიმდინარე კოდის შესაძლებელია https://github.com/kakaoenterprise/RYANSQL.', 'kk': 'Сұрақ мен деректер қоры берілген кезде пайдаланушының сұранысын SQL сұраныста аудару мәселесі. Бұл мақалада, біз RYANSQL деп аталатын невралдық желінің қасиетін (SQL үшін рекурсиялық түсіндіру желі) комплексті мәтін- мен SQL деректер қорларының біріктірілген мәтін- мен SQL тапсырмаларын шешу үшін Күнтізбенің орналасуы коды (SPC) жүгіртілген SQL сұранысын жүгіртілмеген SELECT мәліметтерінің жиынына аудару үшін анықталды. sketch-негіздеген слотты толтыру тәсілі әрбір SELECT мәліметін сәйкес SPC үшін синтезализациялау үшін ұсынылады. Сонымен қатар, екі кіріс манипулациялау тәсілі жалғастыру үшін қосылады. RYANSQL жағдайда 58,2% деңгейіндегі тәртіпсіздік нәтижесін жеткізді. Жіберу кезінде (2020 жылдың сәуірінде) RYANSQL v2, бастапқы RYANSQL- нің айнымалысы, барлық жүйелер мен бірінші орында 60, 6% деген деректер қорының мазмұнын қолдамайтын жүйелер арасында 3- ші орында орнатылады. Бастапқы код бар https://github.com/kakaoenterprise/RYANSQL.', 'mk': 'Апстрактен текст- во- SQL е проблемот со претворањето на прашањето на корисникот во SQL- прашање, кога ќе се даде прашањето и базата на податоци. Во оваа статија, претставуваме пристап на нервната мрежа наречен RYANSQL (Рекурсивно испраќање на анатациска мрежа за SQL) за решавање на комплексни задачи текст до SQL за крстодомени бази на податоци. Кодот за позиција на изјавата (SPC) е дефиниран за трансформирање на гнезденото SQL прашање во набор негнездени SELECT изјави; се предложува пристап на полнување на слотови базиран на скици за синтезирање на секоја изјава на SELECT за својата соодветна СПЦ. Покрај тоа, се претставени два методи на манипулација на внесување за понатамошно подобрување на генерацијата. РИАНСКЛ постигна конкурентни резултати од точност од 58,2 отсто на предизвикувачкиот спојдерски резултат. Во времето на поднесувањето (април 2020), РИАНСКЛ v2, варијант на оригиналниот РИАНСКЛ, е позициониран на трето место меѓу сите системи и на првото место меѓу системите кои не користат содржина на база на податоци со точна точност од 60,6 отсто. The source code is available at  https://github.com/kakaoenterprise/RYANSQL.', 'ms': 'Teks- ke- SQL Abstrakt adalah masalah menukar soalan pengguna ke pertanyaan SQL, apabila soalan dan pangkalan data diberikan. Dalam artikel ini, kami memperkenalkan pendekatan rangkaian saraf bernama RYANSQL (Recursively Yielding Annotation Network for SQL) untuk menyelesaikan tugas Teks-ke-SQL kompleks untuk pangkalan data melintasi-domain. Kod Posisi Pernyataan (SPC) ditakrif untuk mengubah pertanyaan SQL tersarang ke set pernyataan SELECT yang tidak tersarang; a sketch-based slot-filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further.  RYANSQL mencapai keputusan kompetitif akurasi 58.2% pada tanda benchmark Spider yang menantang. Pada masa penghantaran (April 2020), RYANSQL v2, varian RYANSQL asal, ditempatkan di tempat ketiga diantara semua sistem dan tempat pertama diantara sistem yang tidak menggunakan kandungan pangkalan data dengan keputusan persamaan 60.6%. Kod sumber tersedia di https://github.com/kakaoenterprise/RYANSQL.', 'ml': 'ഉപയോക്താവിന്റെ ചോദ്യത്തെ SQL ചോദ്യത്തിലേക്ക് മാറ്റുന്നതിനുള്ള പ്രശ്നമാണു്. ചോദ്യം, ഡാറ്റാബേസും കൊടുക്കുമ് ഈ ലേഖനത്തില്\u200d, റിയാന്\u200dസ്ക്യൂള്\u200d എന്ന പേരുള്ള നെയൂറല്\u200d നെറ്റ്റര്\u200d നെറ്റര്\u200d നെറ്റോര്\u200dക്ക് സാധ്യതയുണ്ടാക്കുന്നു. ക്രിസ്റ്റോമെന്\u200d ഡാറ്റാബേസുകള പ്രസ്താന സ്ഥാനത്തിന്റെ കോഡ് (എസ്പിസി) നിര്\u200dണ്ണയിച്ചിരിക്കുന്നു. ഒരു കൂട്ടത്തിലെ SQL കോരിയിലേക്ക് ഒരു കൂട്ടം സെലിക് സ്കേച്ച് അടിസ്ഥാനത്തുള്ള സ്ലോട്ട് നിറയ്ക്കുന്ന പ്രായോഗ്യം സങ്കീര്\u200dണ്ണമാക്കുവാന്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. അതിന്റെ പൊരുത്തപ്പെട്ട സ RYANSQL ചോദ്യം ചെയ്യുന്ന സ്പൈഡര്\u200d ബെന്\u200dച്മാര്\u200dക്കിന്\u200dറെ വിശദീകരണത്തിന്\u200dറെ 58. 2% ശ്രേഷ്ഠതയുടെ ഫലം എത്ത മിസ്റ്റര്\u200d ചെയ്യുന്ന സമയത്തു് (എപ്രില്\u200d 2020), RYANSQL v2, യഥാര്\u200dത്ഥ RYANSQL-ന്റെ മാറ്റമാണു്, എല്ലാ സിസ്റ്റത്തിലും ആദ്യ സ്ഥാനത്തും 60. 6% കൃത്യമായി പൊരുത്തുന ഉറവിട കോഡ് ലഭ്യമാണു് https://github.com/kakaoenterprise/RYANSQL.', 'mt': 'It-Test Asstrat għal-SQL huwa l-problem a tal-konverżjoni ta’ mistoqsija tal-utent f’mistoqsija SQL, meta tingħata l-mistoqsija u d-database. F’dan l-artikolu, qed nippreżentaw approċċ tan-netwerk newrali msejjaħ RYANSQL (Recursively Yielding Annotation Network for SQL) biex jissolvew kompiti kumplessi Test-to-SQL għal bażijiet tad-dejta transdomestiċi. Il-Kodiċi tal-Pożizzjoni tad-Dikjarazzjoni (SPC) huwa ddefinit biex jittrasforma mistoqsija SQL mibnija f’sett ta’ dikjarazzjonijiet SELECT mhux mibnija; jiġi propost approċċ ibbażat fuq sketch-based slot-filling biex tiġi sintetizzata kull dikjarazzjoni SELECT għall-SPC korrispondenti tagħha. Barra minn hekk, żewġ metodi ta’ manipulazzjoni tal-input huma ppreżentati biex itejbu aktar il-prestazzjoni tal-ġenerazzjoni. RYANSQL kisbet riżultat kompetittiv ta’ eżattezza ta’ 58.2% fuq il-punt ta’ riferiment sfidanti Spider. Fiż-żmien tas-sottomissjoni (April 2020), RYANSQL v2, varjant tar-RYANSQL oriġinali, huwa pożizzjonat fit-tielet post fost is-sistemi kollha u l-ewwel post fost is-sistemi li ma jużawx kontenut ta’ bażi tad-dejta b’preċiżjoni eżatta ta’ tqabbil ta’ 60,6 %. Il-kodiċi tas-sors huwa disponibbli fuq https://github.com/kakaoenterprise/RYANSQL.', 'pl': 'Abstract Text-to-SQL to problem konwersji pytania użytkownika na zapytanie SQL, gdy podane są pytanie i baza danych. W tym artykule przedstawiamy podejście sieci neuronowej o nazwie RYANSQL (Recursively Yielding Annotation Network for SQL) do rozwiązywania złożonych zadań Text-to-SQL dla baz danych między domenami. Kod pozycji instrukcji (SPC) jest zdefiniowany w celu przekształcenia zagnieżdżonego zapytania SQL w zestaw niezagnieżdżonych instrukcji SELECT; Proponuje się podejście oparte na szkicu do wypełniania slotów w celu syntezy każdej instrukcji SELECT dla odpowiedniego SPC. Dodatkowo przedstawiono dwie metody manipulacji wejściowej w celu dalszej poprawy wydajności generowania. RYANSQL osiągnął konkurencyjny wynik o dokładności 58,2% w wymagającym porównaniu Spider. W momencie składania (kwietniu 2020) RYANSQL v2, wariant oryginalnego RYANSQL, znajduje się na trzecim miejscu wśród wszystkich systemów i pierwszym miejscu wśród systemów niewykorzystujących treści bazy danych o dokładności 60,6% dokładności dopasowania. Kod źródłowy dostępny jest na stronie internetowej https://github.com/kakaoenterprise/RYANSQL.', 'ro': 'Text-to-SQL este problema conversiei unei întrebări de utilizator într-o interogare SQL, atunci când întrebarea și baza de date sunt date. În acest articol, prezentăm o abordare de rețea neurală numită RYANSQL (Recursively Yielding Annotation Network for SQL) pentru a rezolva sarcini complexe Text-to-SQL pentru bazele de date cross-domenii. Codul de poziție a declarației (SPC) este definit pentru a transforma o interogare SQL cuibărită într-un set de declarații SELECT neîmbrăcate; Se propune o abordare bazată pe schiță de umplere a sloturilor pentru sintetizarea fiecărei declarații SELECT pentru SPC corespunzătoare. În plus, sunt prezentate două metode de manipulare a intrărilor pentru a îmbunătăți performanța generației în continuare. RYANSQL a obținut un rezultat competitiv de 58,2% precizie pe criteriul provocator Spider. La momentul depunerii (aprilie 2020), RYANSQL v2, o variantă a RYANSQL original, se poziționează pe locul 3 în rândul tuturor sistemelor și pe locul 1 în rândul sistemelor care nu utilizează conținutul bazei de date cu o precizie de potrivire exactă de 60,6%. Codul sursă este disponibil la adresa https://github.com/kakaoenterprise/RYANSQL.', 'mn': 'Abstract Text-to-SQL бол хэрэглэгчийн асуултыг SQL квадрат рүү шилжүүлэх асуудал юм. Энэ бичлэгт бид RYANSQL гэдэг мэдрэлийн сүлжээний арга зам (Recursively Yielding Annotation Network for SQL) олон домгийн өгөгдлийн сангийн комплекс Text-to-SQL даалгаваруудыг шийдэх боломжтой. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested SELECT statements; Слот дүүргэх арга зам нь SELECT-ын харьцангуй SPC-ын тухай ярилцлага бүрийг нэгтгэхэд санал болгож байна. Үүнээс хоёр орлуулах манипулацийн арга зам нь үеийн үр дүнг илүү сайжруулахын тулд илэрхийлэгддэг. RYANSQL нь шаардлагатай Суйдер багц дээрх зөв байдлын үр дүнд 58.2% гарсан. 2020 оны сарын дөрөв сарын дараа RYANSQL v2-ын эхний RYANSQL-ийн хувилбар нь 3-р байрлалд бүх систем болон 1-р байрлалд өгөгдлийн сангийн contentsыг 60.6% тохиромжтой тохиромжтой тохиромжтой байрлалтай ашиглахгүй байдаг. Гэхдээ эх үүсвэрийн код https://github.com/kakaoenterprise/RYANSQL.', 'no': 'Abstrakt tekst- til- SQL er problem med å konvertera eit brukarspørsmål til ein SQL- spørsmål når spørsmålet og databasen vert oppgjeven. I denne artikkelen presenterer vi eit neuralnettverkstilnærming kalla RYANSQL (rekursivt gjeldande notasjonsnettverk for SQL) for å løysa komplekse tekst- til- SQL- oppgåver for cross- domain databaser. Statusplasseringskode (SPC) er definert for å transformera eit nestert SQL- spørjing til eit sett av ikkje- nesterte SELECT- uttrykk. Ein tilnærming på plassbasert plassbasert er foreslått for å syntisera kvar SELECT- uttrykk for den tilsvarande SPC- en. I tillegg vert to inndatamanipulasjonsmetodar vist for å forbetra produksjonen. RYANSQL oppnådd konkurentivt resultat av 58,2% nøyaktig på den vanskelege Spider-benchmarken. På tidspunksjonen (april 2020) er RYANSQL v2 ein variant av opphavleg RYANSQL plassert på tredje plass blant alle systema og første plass blant systema som ikkje brukar databaseinnhaldet med 60,6% nøyaktig nøyaktig nøyaktig. Kjeldekode er tilgjengeleg på https://github.com/kakaoenterprise/RYANSQL.', 'sr': 'Abstraktivni tekst na SQL je problem preobraćanja pitanja korisnika u SQL pitanje, kada se postavlja pitanje i baza podataka. U ovom članku predstavljamo neuronski pristup mreže koja se zove RYANSQL (rekursivno dajuća mreža Annotacija za SQL) kako bi rešili kompleksne zadatke teksta do SQL za prekršne domene baze podataka. Kod pozicije izjave (SPC) definisan je kako bi transformisao gnjezdo SQL zahtev u setu neogniženih izjava SELECT-a; Predložen je pristup ispunjavanja slot a na skeču da sintezira svaku izjavu SELECT za njegovu odgovarajuću SPC. Osim toga, predstavljaju se dve metode manipulacije ulaznih uloga kako bi dalje poboljšala učinkovitost generacije. RYANSQL je postigao konkurentni rezultat tačnosti 58,2% na izazovnoj mjeri pauka. U vreme podnošenja (april 2020), RYANSQL v2, variant originalnog RYANSQL, postavlja se na trećem mjestu među svim sistemima i prvim mjestom među sistemima koji ne koriste sadržaj baze podataka sa tačnom točnošću 60,6%. Izvorni kod je dostupan na https://github.com/kakaoenterprise/RYANSQL.', 'so': "QL waa dhibaatada ku wareejinta su'aalaha isticmaalaha SQL marka la siiyo su'aalaha iyo basaaska macluumaadka. Markaas waxan warqaddan ku qoran, waxaynu soo bandhignaynaa qaab shabakad neural ah oo la yidhaahdo RYANSQL (Recursively Yielding Annotation Network for SQL) si aan u xallino shaqooyin complex Text-to-SQL oo lagu sameeyo macluumaad-databases. Aqoonta heerka (SPC) waxaa loo qoray in lagu beddelo qoraal la qoray SQL oo loo beddelo qoraal kamid ah oo aan aheyn SELECT; waxaa lagu talo galaa qalabka ku buuxinta sawir-sawir-buuxinta, si uu u dhigo qalab kasta oo SELECT ku habboon SPC. RYANSQL wuxuu helay fasax tartanka ah 58.2% sax ah oo ku saabsan dhibaatada Spider benchmark. Waqtiga la soo dhiibo (april 2020), RYANSQL v2, oo ka bedela asalka RYANSQL, wuxuu dhigaa meel saddexaad oo ka mid ah nidaamka oo dhan iyo meesha ugu horeysa ee aan isticmaalin kooxaha kooxaha database oo ku qoran 60.6% si sax ah oo u eg. Kaarka asalka ah waxaa laga helaa https://github.com/kakaoenterprise/RYANSQL.", 'sv': 'Abstract Text-to-SQL är problemet med att konvertera en användarfråga till en SQL-fråga, när frågan och databasen ges. I den här artikeln presenterar vi ett neuralt nätverkstillvägagångssätt som kallas RYANSQL (Recursively Yielding Annotation Network for SQL) för att lösa komplexa text-till-SQL-uppgifter för domänöverskridande databaser. Statement Position Code (SPC) definieras för att omvandla en kapslad SQL-fråga till en uppsättning icke-kapslade SELECT-satser. En skissbaserad metod för fyllning av spår föreslås för att syntetisera varje SELECT-sats för motsvarande SPC. Dessutom presenteras två metoder för inmatning för att förbättra produktionsprestanda ytterligare. RYANSQL uppnådde ett konkurrenskraftigt resultat på 58,2% noggrannhet på det utmanande Spider-riktmärket. Vid inlämningstillfället (april 2020) ligger RYANSQL v2, en variant av original RYANSQL, på 3:e plats bland alla system och 1:a plats bland system som inte använder databasinnehåll med 60,6% exakt matchningsnoggrannhet. Källkoden finns tillgänglig på https://github.com/kakaoenterprise/RYANSQL.', 'ta': 'கேள்வி மற்றும் தரவுத்தளத்தை கொடுக்கும்போது பயனர் கேள்வியை SQL கேள்விக்கு மாற்றுவது பிரச்சனையாகும். இந்த கட்டுரையில், நாம் ஒரு புதிய வலைப்பின்னல் செயல்பாட்டை காண்பிக்கிறோம் RYANSQL (SQL க்கான மீண்டும் வயது அறிவிப்பு வலைப்பின்னல்) சிக்கலான உரை முன்னிருப்பு நிலை குறியீடு (SPC) ஒரு கூட்டு SQL கேள்வியை மாற்ற விவரிக்கப்பட்டுள்ளது ஒரு அமைப்பு SELECT கூற்றுகளாக மாற்று மேலும் உருவாக்கும் செயல்பாட்டை மேம்படுத்துவதற்கு ஒவ்வொரு SELECT கூற்றையும் SPC க்கு ஒத்திசைப்படுத்த பரிந்துரைக்கப்படுகிறது. RYANSQL சவாலிக்கும் சிப்பெயர் பென்மார்க்கு 58. 2% சரியான முடிவு அடைந்தது. முகவரிக்கும் போது (ஏப்ரில் 2020), RYANSQL v2, மூல RYANSQL மாறியில், அனைத்து கணினிகளுக்கும் மூன்றாம் இடத்திலும் முதல் இடத்திலும் 60. 6% சரியாக பொருத்தும் சரியாக மூல குறியீடு கிடைக்கும் https://github.com/kakaoenterprise/RYANSQL.', 'si': 'ප්\u200dරශ්නය සහ දත්තසංකේත දෙන්න ප්\u200dරශ්නයක් SQL ප්\u200dරශ්නයක් වෙනස් කරන්න ප්\u200dරශ්නය. මේ ලේඛනයේදී, අපි RYANSQL කියල නියුරාල ජාතික විධානයක් පෙන්වන්නේ (SQL වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක ජාතිකාව) ක්\u200d ප්\u200dරවේශනය ස්ථානය කෝඩ (SPC) විශ්වාස කරලා නැති SQL ප්\u200dරවේශනයක් නැති SELECT ප්\u200dරවේශනයක් සූදානයකට වෙනස් කරන්න; ස්කෙච් අධාරිත ස්ලෝට් පුරවන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා හැම SELECT ප්\u200dරශ්නයක්ම සංවිධානය සඳහා සංවිධානය කරන්න. තවත RYANSQL සම්පූර්ණයෙන් ස්පයිඩර් බෙන්ච්මාර්ක් එක්ක 58.2% විශිෂ්ට විදියට පටන් ගත්තා. අපරිල් 2020යි, RYANSQL v2, ප්\u200dරධාන RYANSQL වර්ගයක් තුන්වෙනි ස්ථානයේ තුන්වෙනි ස්ථානය සහ පද්ධතියේ පද්ධතියෙන් ස්ථානයේ තුන්වෙනි ස්ථානයේ ත මූල කෝඩ ප්\u200dරවේශය https://github.com/kakaoenterprise/RYANSQL.', 'ur': 'Abstract Text to SQL is the problem of converting a user question into an SQL query, when the question and database are given. اس مقالہ میں ہم ایک نئورل نیٹ ورک طریقہ پیش کرتے ہیں جن کا نام RYANSQL (SQL کے لئے دوبارہ پیدا کرنے والی آنٹ ورک نیٹ ورک) کرس-ڈومین ڈیٹ بیس کے لئے پیچیدہ ٹکس-ٹ-سی-ٹ-سی ٹکس ٹکس کو حل کرنے کے لئے۔ Statement Position Code (SPC) کے لئے نائستہ SQL کیوری کو نائستہ SELECT سٹیٹمنٹوں کے ساتھ تبدیل کرنے کے لئے مقرر کیا گیا ہے; ایک اسکیچ بنیاد اسلوٹ پر ڈالنے کے طریقے کی پیشنهاد کی جاتی ہے ہر SELECT سٹیٹن کو اس کے مطابق SPC کے لئے سنٹیز کرنے کے لئے. اور اضافہ بھی، دو اینپیٹ منپیلوٹ طریقے پیشنهاد کیے جاتے ہیں جن کی عملکرد اضافہ کرنے کے لئے۔ RYANSQL نے 58.2% دقیقہ پر مسابقه کا نتیجہ پہنچایا ہے۔ آئپریل 2020 کی مدت میں RYANSQL v2، اصلی RYANSQL کی بدلنی ہے، سب سیستموں میں تیسری جگہ اور اولین جگہ ہے جو سیستموں میں 60.6% کے مطابق مطابق مطابق مطابق نہیں رکھتے۔ سورس کوڈ اس میں موجود ہے https://github.com/kakaoenterprise/RYANSQL.', 'vi': 'Tóm tắt Văn bản tới SQL là vấn đề chuyển đổi câu hỏi người dùng thành yêu cầu SQL, khi câu hỏi và cơ sở dữ liệu được đưa ra. Trong bài báo này, chúng tôi giới thiệu một phương pháp mạng thần kinh gọi là RYANSQL (trả tự động dịch chuyển thời chú chú cho SQL) để giải quyết các công việc văn bản đến SQL phức tạp cho dữ liệu chéo miền. Mật mã Vị trí Chứng bố trí (SPC) được định nghĩa để chuyển đổi một câu hỏi SQL đã ấp lại thành một nhóm các phát biểu SelECT không được ấp. một phương pháp vẽ phác thảo chứa đầy đủ thời gian được đề nghị tổng hợp mỗi phát biểu SelECT cho mô tả tương ứng của nó. Thêm vào đó, hai phương pháp thao túng nhập được trình nâng cao khả năng sản xuất hơn. RYANSQL đạt được kết quả cạnh tranh của bộ số 58.2 cao độ chính xác trên tiêu chuẩn Con nhện thử thách. Vào thời điểm đăng ký (April 2020), RYANSQL v2, một biến thể của Máy phát âm nguyên, được đặt ở vị trí thứ ba giữa tất cả hệ thống và vị trí thứ nhất trong hệ thống không sử dụng nội dung cơ sở dữ liệu với độ chính xác Y.66. Mã nguồn có sẵn ở https://github.com/kakaoenterprise/RYANSQL.', 'uz': 'Name Bu maqolada, biz kr- domen maʼlumotlar bazalari uchun murakkab matn- to-SQL vazifalarini aniqlash uchun RYANSQL (qayta yillangan tarmoq tarmoq tarmoqni koʻrsatimiz. @ info: whatsthis Name Name @ info Manba kodi mavjud emas https://github.com/kakaoenterprise/RYANSQL.', 'bg': 'Резюме Текст-към-е проблем при преобразуването на потребителски въпрос в заявка, когато въпросът и базата данни са дадени. В тази статия представяме подход на невронната мрежа, наречен Рекурсивно извеждаща анотационна мрежа за решаване на сложни задачи от текст към SQL за междудомейнни бази данни. Кодът на позицията на изявлението (се дефинира за трансформиране на вложена заявка в набор от невложени изявления; Предлага се подход за запълване на слотове, базиран на скици, за да се синтезира всяко изявление за съответната му характеристика Допълнително са представени два метода за манипулиране на входа, за да се подобри производителността на генерирането допълнително. РЯНСКЛ постигна конкурентен резултат от 58.2% точност на предизвикателния бенчмарк Спайдър. Към момента на подаване (април 2020 г.), вариант на оригиналния е позициониран на трето място сред всички системи и на първо място сред системите, които не използват съдържание на база данни с точност на съвпадение 60,6%. Изходният код е достъпен на адрес: https://github.com/kakaoenterprise/RYANSQL.', 'da': 'Abstract Text-to-SQL er problemet med at konvertere et brugerspørgsmål til en SQL-forespørgsel, når spørgsmålet og databasen er givet. I denne artikel præsenterer vi en neural netværkstilgang kaldet RYANSQL (Recursively Yielding Annotation Network for SQL) til at løse komplekse tekst-til-SQL opgaver for tværs af domæner databaser. Statement Position Code (SPC) er defineret til at omdanne en indlejret SQL-forespørgsel til et sæt ikke-indlejrede SELECT-sætninger. En skitsebaseret slot-fyldning tilgang foreslås for at syntetisere hver SELECT-sætning for den tilsvarende SPC. Desuden præsenteres to input manipulationsmetoder for at forbedre generationens ydeevne yderligere. RYANSQL opnåede et konkurrencedygtigt resultat på 58,2% nøjagtighed på det udfordrende Spider benchmark. På tidspunktet for indsendelse (april 2020) er RYANSQL v2, en variant af original RYANSQL, placeret på 3. plads blandt alle systemer og 1. plads blandt systemer, der ikke bruger databaseindhold med 60,6% nøjagtig matching nøjagtighed. Kildekoden er tilgængelig på https://github.com/kakaoenterprise/RYANSQL.', 'nl': 'Abstract Text-to-SQL is het probleem van het omzetten van een gebruikersvraag in een SQL query, wanneer de vraag en de database worden gegeven. In dit artikel presenteren we een neurale netwerkbenadering genaamd RYANSQL (Recursively Yielding Annotation Network for SQL) om complexe Text-to-SQL taken voor domeinoverschrijdende databases op te lossen. Statement Positie Code (SPC) is gedefinieerd om een geneste SQL-query om te zetten in een set niet-geneste SELECT-opdrachten; Er wordt een sketch-based slot-filling benadering voorgesteld om elke SELECT-instructie voor de overeenkomstige SPC te synthetiseren. Daarnaast worden twee invoermanipulatiemethoden gepresenteerd om de generatieprestaties verder te verbeteren. RYANSQL behaalde een concurrerend resultaat van 58,2% nauwkeurigheid op de uitdagende Spider benchmark. Op het moment van indiening (april 2020) staat RYANSQL v2, een variant van originele RYANSQL, op de 3e plaats onder alle systemen en 1e plaats onder de systemen die geen database-inhoud gebruiken met 60,6% exacte matching nauwkeurigheid. De broncode is beschikbaar op: https://github.com/kakaoenterprise/RYANSQL.', 'de': 'Text-to-SQL ist das Problem der Umwandlung einer Benutzerfrage in eine SQL-Abfrage, wenn die Frage und die Datenbank gegeben sind. In diesem Artikel stellen wir einen neuronalen Netzwerkansatz namens RYANSQL (Recursively Yielding Annotation Network for SQL) vor, um komplexe Text-to-SQL-Aufgaben für domänenübergreifende Datenbanken zu lösen. Der Statement Position Code (SPC) wird definiert, um eine verschachtelte SQL-Abfrage in einen Satz nicht verschachtelter SELECT-Anweisungen zu verwandeln. Ein sketch-basierter Slot-Filling-Ansatz wird vorgeschlagen, um jede SELECT-Anweisung für ihren entsprechenden SPC zu synthetisieren. Zusätzlich werden zwei Eingabemanipulationsmethoden vorgestellt, um die Erzeugungsleistung weiter zu verbessern. RYANSQL erzielte wettbewerbsfähige Ergebnisse mit 58,2% Genauigkeit auf dem anspruchsvollen Spider Benchmark. Zum Zeitpunkt der Einreichung (April 2020) befindet sich RYANSQL v2, eine Variante des ursprünglichen RYANSQL, auf dem dritten Platz unter allen Systemen und auf dem ersten Platz unter den Systemen, die keine Datenbankinhalte verwenden, mit 60,6% exakter Übereinstimmung. Der Quellcode ist verfügbar unter https://github.com/kakaoenterprise/RYANSQL.', 'hr': 'Abstrakt tekst- na- SQL je problem preobraćanja pitanja korisnika u SQL pitanje, kada se postavlja pitanje i baza podataka. U ovom članku predstavljamo neuronski pristup mreže koja se zove RYANSQL (rekursivno objavljiva mreža Annotacija za SQL) kako bi riješili kompleksne zadatke teksta do SQL za prekršne baze podataka. Kod položaja izjave (SPC) definiran je kako bi transformirao gnjezdo SQL zahtjev u set neognijeznih izjava SELECT-a; Predložen je pristup ispunjavanja slot a na skeču kako bi sintezirala svaku izjavu SELECT-a za odgovarajući SPC-u. Osim toga, predstavljaju se dvije metode manipulacije ulaza kako bi se dalje poboljšala učinkovitost generacije. RYANSQL je postigao konkurentni rezultat tačnosti 58,2% na izazovnoj mjeri pauka. U vrijeme podnošenja (travnja 2020), RYANSQL v2, variant originalnog RYANSQL, postavlja se na trećem mjestu među svim sustavima i prvim mjestom među sustavima koji ne koriste sadržaj baze podataka s tačnom točnošću odgovarajućeg preciznosti 60,6%. Izvorni kod je dostupan na https://github.com/kakaoenterprise/RYANSQL.', 'ko': '추상적인 텍스트를 SQL로 바꾸는 것은 주어진 문제와 데이터베이스에서 사용자 문제를 SQL 조회로 바꾸는 문제입니다.본고에서 우리는 RYANSQL(귀속 생성 SQL 주석 네트워크)이라는 신경 네트워크 방법을 제시하여 전역 데이터베이스의 복잡한 텍스트부터 SQL 임무까지 해결하는 데 사용한다.문장 위치코드(SPC)는 끼워 넣은 SQL 조회를 끼워 넣지 않은 SELECT 문장으로 변환하는 것으로 정의한다.스케치 기반의 틈새 충전 방법을 제시하여 각각의 SELECT 문장을 종합하여 해당하는 SPC를 얻었다. 또한 두 가지 입력 조작 방법을 제시하여 생성 성능을 더욱 향상시켰다.RYANSQL은 도전적인 스파이더 벤치마크 테스트에서 58.2%의 정확도를 얻었다.제출 시(2020년 4월) RYANSQL v2는 원시 RYANSQL의 변형으로 모든 시스템 중 3위, 데이터베이스 콘텐츠를 사용하지 않는 시스템 중 1위, 정밀일치 정밀도는 60.6%였다.소스 코드는https://github.com/kakaoenterprise/RYANSQL.', 'fa': 'مسئله تبدیل کردن سؤال کاربر به یک سوال SQL است، وقتی سؤال و دادگاه داده می شود. در این مقاله، ما یک روش شبکه عصبی به نام RYANSQL (شبکه یادآوری برای SQL) را برای حل کار پیچیده\u200cای متن به SQL برای پایگاه\u200cهای داده\u200cهای متوسط دامنه\u200cای نشان می\u200cدهیم. رمز موقعیت اعلام (SPC) برای تغییر یک سؤال SQL نازل شده به مجموعه اعلام SELECT غیر نازل شده تعریف شده است. یک روش پر کردن slot بر اساس sketch پیشنهاد می\u200cشود که هر گزارش SELECT را برای SPC مربوط به آن متصل کند. به اضافه، دو روش تغییر ورودی برای بهتر فعالیت نسل پیشنهاد می\u200cشود. RYANSQL به نتیجه رقابت با دقیق 58.2% روی صندوق عنکبوت مشکل رسید. در زمان تحویل (آپریل ۲۰۰۲) RYANSQL v2، یک تغییر اصلی RYANSQL، در جای سوم در میان تمام سیستم\u200cها و جای اول در میان سیستم\u200cها که از محتوای داده\u200cهای داده\u200cگاه با دقیق هماهنگی دقیق ۶۰.۶ درصد استفاده نمی\u200cکنند. کد منبع در دسترسی است https://github.com/kakaoenterprise/RYANSQL.', 'id': 'Teks-ke-SQL abstrak adalah masalah konversi pertanyaan pengguna ke pertanyaan SQL, ketika pertanyaan dan database diberikan. Dalam artikel ini, kami mempersembahkan pendekatan jaringan saraf bernama RYANSQL (Recursively Yielding Annotation Network for SQL) untuk memecahkan tugas teks-ke-SQL kompleks untuk pangkalan data cross-domain. Kode Posisi Pernyataan (SPC) didefinisikan untuk mengubah pertanyaan SQL tersarang menjadi set pernyataan SELECT yang tidak tersarang; pendekatan penuhian slot berdasarkan sketsa diusulkan untuk sintesis setiap pernyataan SELECT untuk SPC yang sesuai. Lagipula, dua metode manipulasi masukan ditetapkan untuk meningkatkan prestasi generasi lebih lanjut. RYANSQL achieved competitive result of 58.2% accuracy on the challenging Spider benchmark.  Pada saat pengiriman (April 2020), RYANSQL v2, varian dari RYANSQL asli, ditempatkan di tempat ketiga diantara semua sistem dan tempat pertama diantara sistem yang tidak menggunakan konten pangkalan data dengan akurasi persis yang cocok 60,6%. Kode sumber tersedia di https://github.com/kakaoenterprise/RYANSQL.', 'af': "Abstrak Teks- na- SQL is die probleem van omskakeling van 'n gebruiker vraag in' n SQL navraag, wanneer die vraag en databasis is gegee. In hierdie artikel, voorsien ons 'n neurale netwerk toegang wat genoem word RYANSQL (Rekursief uitgeleide Notasie Netwerk vir SQL) om kompleks Teks- na- SQL taak te los vir kruis- domein databasis. Statement Posisie Kode 'n sketch-gebaseerde slot-opvulling toegang is voorgestel om elke SELECT-opdrag te sintetiseer vir sy ooreenstemmende SPC. Additionally, twee invoer manipulasie metodes word voorgestel om verder generasie-prestasie te verbeter. RYANSQL het mededingsresultaat van 58. 2% waarskynlik op die speler benchmark bereik. Op die tyd van onderskrywing (April 2020), is RYANSQL v2, 'n variant van oorspronklike RYANSQL, op die 3de plek onder alle stelsels en 1st plek onder die stelsels nie gebruik databasis inhoud met 60.6% presies ooreenstemmende presies. Die bronkode is beskikbaar by https://github.com/kakaoenterprise/RYANSQL.", 'sq': 'Teksti abstrakt në SQL është problemi i konvertimit të pyetjes së përdoruesit në një pyetje SQL, kur jepen pyetjet dhe bazat e dhënave. Në këtë artikull, ne paraqesim një qasje rrjeti nervor të quajtur RYANSQL (RYANSQL Recursively Yielding Annotation Network for SQL) për të zgjidhur detyrat komplekse Text-to-SQL për bazat e të dhënave transdomenale. Kodi i pozicionit të deklaratës (SPC) është përcaktuar për të transformuar një pyetje të folur SQL në një sërë deklaratash SELECT jo të folura; është propozuar një qasje për mbushjen e slots me bazë sketch për të sintetizuar çdo deklaratë SELECT për SPC korrespondente të saj. Përveç kësaj, dy metoda manipulimi i hyrjes janë paraqitur për të përmirësuar performancën e gjeneratës më tej. RYANSQL arriti rezultatin konkurrues të saktësisë 58.2% në referencën sfiduese të Merimangës. Në kohën e paraqitjes (prill 2020), RYANSQL v2, një variant i RYANSQL origjinal, është vendosur në vendin e tretë midis të gjitha sistemeve dhe vendin e parë midis sistemeve që nuk përdorin përmbajtjen e bazës së dhënave me 60.6% saktësi të përshtatshme. Kodi burimi është në dispozicion në https://github.com/kakaoenterprise/RYANSQL.', 'sw': 'Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given.  Katika makala hii, tunaweka mbinu za mtandao wa neura zinazoitwa RYANSQL (Mtandao wa Kutangaza Uzazi wa Mara kwa ajili ya SQL) ili kutatua kazi tata za maandishi kwa ajili ya takwimu za ndani. Sheria ya Position (SPC) imeelezwa kubadilisha utafiti wa SQL uliokuwa umezungumzwa katika mfululizo wa matamko ya SELECT isiyo na makosa; mbinu za kutuliza sawia zinazotumiwa na michoro inapendekezwa kuunganisha tamko la kila SELECT kwa ajili ya tamko lake linalomilikiwa na SPC. Zaidi yake, mbinu mbili za utekelezaji wa input zinaonyesha kuboresha utendaji wa kizazi zaidi. RYANSQL ilifanikiwa matokeo ya ushindani yaliyotokana na asilimia 58.2 ya uhakika juu ya bendera ya Spider. Wakati wa kujisilisha (Aprili 2020), RYANSQL v2, tofauti ya asili ya RYANSQL, inawekwa katika nafasi ya tatu kati ya mifumo yote na nafasi ya kwanza kati ya mifumo ambayo haitumii maudhui ya taarifa yenye asilimia 60.6 yenye uhakika sahihi. Kifungu cha chanzo kinapatikana katika https://github.com/kakaoenterprise/RYANSQL.', 'tr': "Abstrakt Metin-we SQL isleýän soragy SQL soragyna üýtgetmekde mesele bar. Bu makalede, biz RYANSQL (Rekursively Yielding Annotation Network for SQL) çoklu domain veritabanları için kompleks Metin-to-SQL görevlerini çözmek için nöral a ğ yaklaşımı sunuyoruz. Beýik ýeriniň Kody (SPC) ýakyn SQL soragyny ýygnamaýan SELECT deklarlarynyň bir takmyna terjime edildi; sketch tabanly slot doldurulýan öňki, her SELECT deklarasyny täsirli SPC üçin syntetize etmek üçin teklip edildi. Beýlenen, iki girdi işleme yöntemi döwletlere bejermek üçin önüne getirilýär. RYANSQL 58.2% ýüzdeki örümdeki düzgün çekici netijede ýetdi. Teslimat wagty (Aprel 2020), RYANSQL v2, orijinal RYANSQL'iň üýtgeşigi 3-nji ýerde, hemme sistemleriň arasynda 1-nji ýerinde 60.6% edil dogry metini ulanmaýar. %s halta bar. https://github.com/kakaoenterprise/RYANSQL.", 'az': "Abstrakt Metin-to-SQL istifadəçi sualını SQL sualına döndərmək problemidir, sual və verilən verilənlərdə. Bu məlumatda, çox domain veri bazları üçün kompleks Metin-to-SQL işləri çəkmək üçün RYANSQL adlı nöral a ğ tərzini göstəririk. Statement Position Kodu (SPC) qurulmuş SQL sualını qurulmayan SELECT ifadələrinin qurulması üçün tanımlanır; sketch-based slot-filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance. RYANSQL müqayisədə 58.2% dəyişiklik dəyişiklik dəyişiklik göstərildi. YANSQL v2, orijinal RYANSQL'in dəyişikliyi, bütün sistemlər arasında üçüncü yerdə və sistemlərin birinci yerdə 60.6% ilə istifadə edilməyən veritabanın məlumatını istifadə etməyən sistemlərin arasında yerləşdirilir. Kaynak kodu faydalanır https://github.com/kakaoenterprise/RYANSQL.", 'am': 'text-to-SQL በዚህ ጽሑፍ ውስጥ RYANSQL (RYANSQL ለመቀበል የኢትዮጵያ አቀማመጥ የመረጃ መረብ) ለመፍታት የጽሑፍ-ወደ-SQL አድራጊዎችን ለመፍታት የደብዳቤ ዳታቤቶችን ለመፍታት የኔትዎራል መረብ መግለጫ እናቀርባለን፡፡ የመስመር ቦታ ኮድ (SPC) የደረጃ SQL ምርጫዎችን ለመለወጥ ተገልጦአል፡፡ የስኮት ደረጃዎች የሞላው ስልክ ሁሉንም የSELECT ድምፅ ለመቀናቀል ይገልጻል። በተጨማሪም፣ ሁለት የኢንተርኔት ማቀናጃ ሥርዓቶች ለትውልድ ትክክል እንዲያሳድጉ ይገናኛሉ፡፡ RYANSQL በጥላቻው Spider benchmark ላይ 58.2 በመቶ እርግጠኛ ፍሬ አግኝቷል፡፡ RYANSQL v2 (አፕሪል 2020) በተለየ ጊዜ፣ ዋና የተለየ RYANSQL v2፣ በሥርዓት ሁሉ መካከል በሦስተኛ ቦታ እና በመጀመሪያ ስርዓቶች መካከል 60.6 በመቶ እርግጠኛ ክፍል በማይተካክሉ የዳታ መቀመጫውን በመጠቀም ስርዓት ነው፡፡ The source code is available at  https://github.com/kakaoenterprise/RYANSQL.', 'bs': 'Abstraktivni tekst na SQL je problem preobraćanja pitanja korisnika u SQL pitanje, kada se postavlja pitanje i baza podataka. U ovom članku predstavljamo neuronski pristup mreže koja se zove RYANSQL (rekursivno objavljiva mreža Annotacija za SQL) kako bi riješili kompleksne zadatke teksta do SQL za preko domena baze podataka. Kod pozicije za izjave (SPC) definisan je kako bi transformirao gnjezdo SQL zahtjev u set neognijeznih izjava SELECT-a; Predložen je pristup napunjenja slot a na skeču da sintezira svaku izjavu SELECT za njegovu odgovarajuću SPC-u. Osim toga, predstavljaju se dva metoda manipulacije ulaza kako bi dalje poboljšala učinkovitost generacije. RYANSQL je postigao konkurentni rezultat tačnosti 58,2% na izazovnoj mjeri pauka. U vrijeme podnošenja (april 2020), RYANSQL v2, variant originalnog RYANSQL, postavlja se na trećem mjestu među svim sistemima i prvim mjestom među sistemima koji ne koriste sadržaj baze podataka sa tačnom točnošću 60,6%. Izvorni kod je dostupan na https://github.com/kakaoenterprise/RYANSQL.', 'ca': "Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given.  In this article, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases.  El codi de posició de la declaració (SPC) es defineix per transformar una consulta de SQL ninjada en un conjunt de declaracions SELECT no ninjades; es propone un enfocament basat en esboços de rellenç de slots per sintetitzar cada declaració SELECT per a la seva SPC correspondent. A més, s'introdueixen dos mètodes de manipulació d'entrada per millorar el rendiment de la generació. RYANSQL va aconseguir un resultat competitiu de la precisió del 58,2% en el punt de referència desafiant Spider. En el moment de la presentació (abril 2020), RYANSQL v2, una variant de RYANSQL original, es posiciona al tercer lloc entre tots els sistemes i al primer lloc entre els sistemes que no utilitzen continguts de base de dades amb una precisió exact a del 60,6%. El codi d'origen està disponible en https://github.com/kakaoenterprise/RYANSQL.", 'hy': 'Աբստրակտ տեքստ-ի-SQL խնդիրն է օգտագործողի հարցը SQL հարցում փոխարինել, երբ հարցը և բազան տվյալները տրվում են: Այս հոդվածի մեջ մենք ներկայացնում ենք նյարդային ցանցի մոտեցում, որը կոչվում է RYATSQL (Reursive Yyiyiling annoannoannotion net for SQL), որպեսզի լուծենք բարդ տեքստի-SQL գործողությունները միջոցային տվյալների համար: Առաջնական դիրքի կոդը (SP C) սահմանվում է, որպեսզի թաքնված SQL հարցը վերածվի ոչ թաքնված SELECT նախադասությունների մի շարք: Ավելին, ներկայացվում են երկու մուտքագրման մեթոդ, որպեսզի զարգացվի սերնդի արդյունքը: ՌԻԱՆՍՔԼ-ը ստացավ 58.2 տոկոսի ճշգրիտության մրցակցության արդյունքը մարտահրավերվող Spider-ի հարաբերականի վրա: Հաշվի ներկայացման ժամանակ (2020 թ. ապրիլ), RYATSQL v2-ը, որը օրիգինալ RYATSQL-ի տարբերակն է, տեղադրվում է 3-րդ տեղում բոլոր համակարգերի միջև և 1-րդ տեղում համակարգերի միջև, որոնք չեն օգտագործում բազայի պարունակությունը 60.6 տոկոսով ճշգրիտ համապատասխան Առաջին կոդը հասանելի է https://github.com/kakaoenterprise/RYANSQL.', 'cs': 'Abstrakt Text-to-SQL je problém převodu uživatelské otázky na SQL dotaz, kdy je daná otázka a databáze. V tomto článku představujeme přístup neuronové sítě s názvem RYANSQL (Recursively Yielding Annotation Network for SQL) pro řešení složitých Text-to-SQL úloh pro cross-doménové databáze. Kód pozice příkazu (SPC) je definován pro transformaci vnořeného SQL dotazu na sadu nevnořených příkazů SELECT; Pro syntetizaci každého SELECT příkazu pro jeho odpovídající SPC jsou navrženy náčrtně založené slotové plnění. Dále jsou prezentovány dvě metody manipulace se vstupem pro další zlepšení výkonu generace. RYANSQL dosáhl konkurenčního výsledku s 58,2% přesností na náročném Spider benchmarku. V době odeslání (duben 2020) je RYANSQL v2, varianta původního RYANSQL, umístěna na třetím místě mezi všemi systémy a prvním místě mezi systémy, které nepoužívají obsah databáze s 60,6% přesnou přesností shody. Zdrojový kód je k dispozici na adrese https://github.com/kakaoenterprise/RYANSQL.', 'et': 'Tekst SQL-iks on probleem, mis tekitab kasutaja küsimuse teisendamise SQL-päringuks, kui esitatakse küsimus ja andmebaas. Selles artiklis tutvustame neurovõrgu lähenemisviisi nimega RYANSQL (Recursively Yielding Annotation Network for SQL), et lahendada keerukaid tekstist SQL ülesandeid domeenidevaheliste andmebaaside jaoks. Statement Position Code (SPC) on määratletud pesastatud SQL-päringu teisendamiseks pesastamata SELECT-lausete komplektiks; Iga SELECTi lause sünteesimiseks vastava omaduste kokkuvõtte jaoks pakutakse välja visandipõhine teenindusaegade täitmise meetod. Lisaks esitatakse kaks sisendi manipulatsioonimeetodit, et parandada tootmise jõudlust veelgi. RYANSQL saavutas konkurentsivõimelise tulemuse 58,2% täpsusega Spider võrdlusalusel. Esitamise ajal (aprill 2020) on RYANSQL v2, originaalse RYANSQL variant, kolmandal kohal kõigi süsteemide hulgas ja 1. kohal süsteemide hulgas, mis ei kasuta andmebaasi sisu 60,6% täpse vastavuse täpsusega. Lähtekood on kättesaadav aadressil https://github.com/kakaoenterprise/RYANSQL.', 'bn': 'Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given.  এই প্রবন্ধটিতে আমরা একটি নিউরেল নেটওয়ার্ক উপায় উপস্থাপন করছি যার নাম RYANSQL (পুনরাবৃত্তিকভাবে প্রাক্তন ডাটাবেজের জন্য প্রযুক্তিক লেখা থেকে SQL-এর জন্য বিবৃতির অবস্থান কোড (এসপিসি) নির্ধারণ করা হয়েছে একটি নেস্টেড এসকিউএল অনুসন্ধানের একটি সেকেলিক্ট বিবৃতি পরিবর্তন করার জন্য; স্ক্যাচ-ভিত্তিক স্লোটফিলিং পদ্ধতি প্রস্তাব করা হয়েছে প্রত্যেকটি সেলিকেট বিবৃতি সংশ্লিষ্ট করার জন্য প্রস্তাব করা হয়েছে এসপিসির সাথে সংশ্লি RYANSQL প্রতিযোগিতার ফলাফল ৫৮. ২% স্পাইডার বেনম্যার্কে সঠিকভাবে অর্জন করেছে। জমা দেয়ার সময় (এপ্রিল ২০২০), RYANSQL ভি২, মূল রায়ান্সকিউলের একটি ভেরিয়েন্ট, সকল সিস্টেমের মধ্যে তৃতীয় স্থান এবং প্রথম স্থানে সিস্টেমের মধ্যে ৬০. ৬% ঠিক ঠি উৎস কোড পাওয়া যাচ্ছে https://github.com/kakaoenterprise/RYANSQL.', 'fi': 'Teksti SQL-muotoon on ongelma muuntaa käyttäjäkysymys SQL-kyselyksi, kun kysymys ja tietokanta annetaan. Tässä artikkelissa esittelemme neuroverkkoa koskevan lähestymistavan nimeltä RYANSQL (Recursively Yielding Annotation Network for SQL) monimutkaisten Text-to-SQL-tehtävien ratkaisemiseksi toimialueiden välisissä tietokannoissa. Statement Position Code (SPC) on määritetty muuttamaan sisäkkäisen SQL-kyselyn sisäkkäisiksi SELECT-lausekkeiksi. Jokaisen SELECT-lausekkeen syntetisoimiseksi ehdotetaan luonnokseen perustuvaa slot-filling-menetelmää vastaavaan SPC:hen. Lisäksi esitellään kaksi syöttömanipulaatiomenetelmää generaation suorituskyvyn parantamiseksi edelleen. RYANSQL saavutti kilpailukykyisen tuloksen 58,2% tarkkuudella haastavassa Spider-vertailussa. Toimituksen yhteydessä (huhtikuu 2020) alkuperäisen RYANSQL-version RYANSQL v2 sijoittuu kolmannelle sijalle kaikista järjestelmistä ja ensimmäiselle sijalle järjestelmistä, jotka eivät käytä tietokantasisältöä 60,6%:n tarkkuudella. Lähdekoodi on saatavilla osoitteessa https://github.com/kakaoenterprise/RYANSQL.', 'ha': "@ info: tooltip Daga wannan makala, Munã halatar da wani mataimaki na tarayya na neural wanda ke kiran RYANSQL (Shirin YYYANSQL na SQL) dõmin yin solar aikin matsayin-zuwa-SQL wa danne-danne-danne guda. Ana bayyana kodi na Wurin Size (SPC) dõmin a canza canza wata tambayar SQL na ƙaranci zuwa wani daidaita statements na kasa-ƙaranci; An buƙata hanyoyin filin slot-fili wanda ke asansa don a haɗa duk faɗa ɗar na SPC. Kuma da wancan, za'a motsa shiryoyin ayuka biyu cikin shirin ayuka dõmin a ƙara tsarin mai nuna aiki. RYANSQL ya sami fassarar ta wajen competitive matsalar 58.2% na tsari a kan tsãwarwa na tsãwarwa. A lokacin da aka shigar da shirin bayani (April 2020), RYANSQL v2, wata variant na farko na RYANSQL, ana zama wurin na uku cikin duk na'ura da na farko na cikin tsari don ya yi amfani da maɓallin database da asilimin 60.6% da ke daidaita tsarin da ke daidaita. Kodi ɗin maɓalli na da https://github.com/kakaoenterprise/RYANSQL.", 'jv': 'Sampeyan Nang artiklé iki, kita nambah tanggal sistem sing nambah RYANsL (recurrsvely Yieling Anntative Network for sql) kanggo Resolve komplikasi Text-to-sqL tasks for interdomain databazs. structural navigation slot-filling method L deep Sumber kode kang sampeyan ing https://github.com/kakaoenterprise/RYANSQL.', 'sk': 'Besedilo v SQL je problem pretvorbe uporabniškega vprašanja v SQL poizvedbo, ko sta podana vprašanje in zbirka podatkov. V tem članku predstavljamo pristop nevronskega omrežja RYANSQL (Recursively Yielding Annotation Network for SQL) za reševanje kompleksnih opravil besedila v SQL za meddomenske zbirke podatkov. Koda položaja izjave (SPC) je določena za pretvorbo ugnezdene poizvedbe SQL v niz nestnezdenih izjav SELECT; Za sintetizacijo vsake izjave SELECT za ustrezni SPC je predlagan pristop zapolnjevanja rež, ki temelji na skicah. Poleg tega sta predstavljeni dve metodi vhodne manipulacije za nadaljnje izboljšanje zmogljivosti generacije. RYANSQL je dosegel konkurenčni rezultat 58,2% natančnosti pri zahtevnem merilu Spider. V času oddaje (april 2020) je RYANSQL v2, različica originalnega RYANSQL, uvrščena na 3. mesto med vsemi sistemi in 1. mesto med sistemi, ki ne uporabljajo vsebine baze podatkov z natančno natančnostjo ujemanja 60,6%. Izvorna koda je na voljo na spletni strani https://github.com/kakaoenterprise/RYANSQL.', 'bo': 'Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given. Abstract Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given. In this article, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested SELECT statements; and sketch་ལ་གཞི་བརྟེན་པའི་slot-filling approach་སྔོན་སྒྲིག་ནི་SELECT་རེ་རེར་སྤྱོད་ཀྱི་SPC་དང་མཐུན་སྒྲིག RYANSQL དཀའ་ངལ་ཆེ་བའི་Spider benchmark ཐོག་ལས་58.2% accuracy ཐོག་ལས་རྒྱལ་ཁབ་ཕྱོགས་འགྱུར་བ་རེད། At the time of submission (April 2020), RYANSQL v2, a variant of original RYANSQL, is positioned at 3rd place among all systems and 1st place among the systems not using database content with 60.6% exact matching accuracy. ཐོག་མའི་ཨང་རྟགས་སྤྱོད་ཚར་བ https://github.com/kakaoenterprise/RYANSQL.', 'he': 'טקסט אסטרקט ל- SQL היא הבעיה של להפוך שאלה משתמשת לתוך שאלה SQL, כאשר נותנים שאלה ומאגר הנתונים. במאמר הזה, אנו מציגים גישה לרשת עצבית שנקראת RYANSQL (Recursively Yielding Annotation Network for SQL) כדי לפתור משימות מסובכות טקסט-ל-SQL לבסיסי נתונים מעבר לתחום. קוד עמדת הצהרה (SPC) מוגדר כדי לשנות בקשה SQL קבועה לתוך קבוצה של הצהרות SELECT לא קבועות; מציעה גישה ממלאת קופסאות מבוססת על סקיצים כדי לסינטזיה כל הצהרה SELECT עבור SPC המתאים שלה. בנוסף, שני שיטות מניפולציה כניסה מוצגות כדי לשפר את ההפעה של הדור הלאה. RYANSQL השיג תוצאה תחרותית של מדויקת 58.2% על המיקום המתאגר של ספיידר. בזמן ההעברה (באפריל 2020), RYANSQL v2, שונה של RYANSQL המקורי, נמצאת במקום השלישי בין כל המערכות והמקום הראשון בין המערכות שלא משתמשים בתוכן נתוני הנתונים עם מדויקת תואמת מדויקת של 60.6%. קוד המקור זמין ב https://github.com/kakaoenterprise/RYANSQL.'}
{'en': 'CausaLM : Causal Model Explanation Through Counterfactual Language Models', 'ar': 'CausaLM: شرح النموذج السببي من خلال نماذج اللغة المضادة', 'es': 'CausalM: Explicación del modelo causal a través de modelos de lenguaje contrafactual', 'fr': 'CausalM\xa0: Explication du modèle causal par des modèles de langage contrefactuels', 'pt': 'CausaLM: explicação do modelo causal por meio de modelos de linguagem contrafactuais', 'ja': 'CausaLM ：反事実的言語モデルを通じた因果モデルの説明', 'zh': 'CausaLM:反语说因果', 'ru': 'CausaLM: Объяснение Причинной Модели Через Контрафактуальные Модели Языка', 'hi': 'CausaLM: कारण मॉडल स्पष्टीकरण के माध्यम से प्रतिवादी भाषा मॉडल मॉडल', 'ga': 'CausaLM: Míniú ar an tSamhail Cúiseach Trí Mhúnlaí Teanga Frithfhíorasacha', 'el': 'Αιτιολογική εξήγηση μοντέλου μέσω πλαστών γλωσσικών μοντέλων', 'hu': 'CausaLM: Okozati modell magyarázata hamis nyelvi modelleken keresztül', 'it': 'CausaLM: Spiegazione del modello causale attraverso modelli linguistici contraffatti', 'lt': 'priežastis', 'mk': 'ПричинаLM: Causal Model Explanation Through Counterfactual Language Models', 'ka': 'CausaLM: მოდელის გამოყენება კონტრექტურალური ენის მოდელების გარეშე', 'ms': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'ml': 'കസാസല്\u200d: കണക്ടെര്\u200dഫാക്കല്\u200d ഭാഷ മോഡലുകളിലൂടെ ക്യൂസല്\u200d മോഡല്\u200d എക്സ്പ്ലാനേഷന്\u200d', 'mt': 'KawżaLM: Spjegazzjoni tal-Mudell Kawżali Permezz ta’ Mudelli tal-Lingwa Falsifikati', 'mn': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'no': 'CausaLM: forklaring av avbrytingsmodell gjennom tilfeldige språk- modeller', 'pl': 'CausaLM: Wyjaśnienie modelu przyczynowego za pomocą fałszywych modeli językowych', 'ro': 'CausaLM: Explicarea modelului cauzal prin modele lingvistice contrafăcute', 'sr': 'CausaLM: Objašnjenje modela optužbe kroz proizvodnje jezičkih modela', 'so': 'CausaLM: Tilmaamaha muusikada ee caawimaadda', 'sv': 'CausaLM: Förklaring av orsaksmodeller genom förfalskade språkmodeller', 'ta': 'CausaLM: Counterfactual Language Models', 'si': 'CausLM: ප්\u200dරතිචාර භාෂා මොඩේල් ප්\u200dරශ්න', 'ur': 'CausaLM: کنٹرفارفیل زبان موڈلوں کے ذریعہ کائوسل موڈل پتفصیل', 'kk': 'CausaLM: қарсы тіл үлгілерімен шешу үлгісін түсіндіру', 'uz': 'Foydalanuvchi modeli', 'vi': 'Nguyên nhân viên: Mô tả nguyên nhân qua mô tả ngữ văn', 'bg': 'Обяснение на причинния модел чрез фалшиви езикови модели', 'nl': 'CausaLM: Causale Model Verklaring door middel van namaaktaalmodellen', 'hr': 'CausaLM: Objašnjenje model optužnice kroz proizvodnje jezičkih modela', 'id': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'de': 'CausaLM: Erklärung des kausalen Modells durch gefälschte Sprachmodelle', 'da': 'CausaLM: Årsagsmodellforklaring gennem forfalskede sprogmodeller', 'sw': 'CausaLM: Utelelezaji wa Model wa Kausali kupitia Modeli za Lugha', 'tr': 'CausaLM: Gaýratyn Diller modinden Wasp', 'ko': '인과 모델: 반사실 언어 모델을 통해 인과 모델을 해석한다', 'fa': 'CausaLM: توضیح Model Causal Through Counterfactual Language Models', 'am': 'factual language Models', 'az': 'CausaLM: Counterfactual Dil Modelləri ilə Causal Model Explanation', 'bn': 'ক্যাসাএলএম: কাউন্টারফ্যাক্যালেট ভাষা মোডেলের মাধ্যমে ক্যাসাল মডেল এক্সপ্লেনেশন', 'af': 'CausaLM: Oplossing Model Verduideling deur Teikerfeel Taal Modelle', 'sq': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'cs': 'CausaLM: Vysvětlení příčinného modelu pomocí padělaných jazykových modelů', 'bs': 'CausaLM: Objašnjenje modela optužnice kroz proizvodnje jezičkih modela', 'et': 'CausaLM: põhjusliku mudeli selgitus võltsitud keelemudelite kaudu', 'fi': 'CausaLM: Syysmallin selitys väärennettyjen kielimallien kautta', 'ca': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'hy': 'LM: Պատճառների մոդելի բացատրությունը կեղծ լեզվի մոդելների միջոցով', 'jv': 'CausaLM: Cause model Expression throughout Counter Language model', 'sk': 'CausaLM: Razlaganje vzročnega modela skozi ponarejene jezikovne modele', 'he': 'סיבה', 'bo': 'CausaLM: Causal Model Explanation Through Counterfactual Language Models', 'ha': 'KCharselect unicode block name'}
{'en': 'Abstract Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination. As all machine learningbased methods, they are as good as their training data, and can also capture unwanted biases. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology. To bridge that gap, we propose CausaLM, a framework for producing causal model explanations using counterfactual language representation models. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data.1', 'ar': 'الملخص يعتبر فهم التنبؤات التي تقوم بها الشبكات العصبية العميقة أمرًا صعبًا للغاية ، ولكنه أيضًا مهم لنشرها. مثل جميع الأساليب القائمة على التعلم الآلي ، فهي جيدة مثل بيانات التدريب الخاصة بها ، ويمكنها أيضًا التقاط التحيزات غير المرغوب فيها. في حين أن هناك أدوات يمكن أن تساعد في فهم ما إذا كانت مثل هذه التحيزات موجودة ، إلا أنها لا تميز بين الارتباط والسببية ، وقد تكون غير مناسبة للنماذج القائمة على النص وللتفكير حول مفاهيم اللغة عالية المستوى. تتمثل المشكلة الرئيسية لتقدير التأثير السببي لمفهوم الاهتمام على نموذج معين في أن هذا التقدير يتطلب توليد أمثلة معاكسة ، وهو ما يمثل تحديًا مع تقنية التوليد الحالية. لسد هذه الفجوة ، نقترح CausaLM ، إطار عمل لإنتاج تفسيرات نموذجية سببية باستخدام نماذج تمثيل اللغة المضادة للواقع. يعتمد نهجنا على ضبط دقيق لنماذج التضمين السياقية العميقة مع مهام خصم مساعدة مستمدة من الرسم البياني السببي للمشكلة. بشكل ملموس ، نظهر أنه من خلال الاختيار الدقيق لمهام ما قبل التدريب للخصم المساعدة ، يمكن لنماذج تمثيل اللغة مثل BERT أن تتعلم بشكل فعال تمثيلًا مضادًا للواقع لمفهوم معين من الاهتمام ، ويمكن استخدامها لتقدير تأثيرها السببي الحقيقي على أداء النموذج. النتيجة الثانوية لطريقتنا هي نموذج تمثيل اللغة الذي لا يتأثر بالمفهوم الذي تم اختباره ، والذي يمكن أن يكون مفيدًا في التخفيف من التحيز غير المرغوب فيه المتأصل في البيانات.', 'fr': "Résumé Comprendre les prédictions faites par les réseaux de neurones profonds est notoirement difficile, mais également crucial pour leur diffusion. Comme toutes les méthodes basées sur l'apprentissage automatique, elles sont aussi performantes que leurs données d'entraînement et peuvent également détecter des biais indésirables. Bien qu'il existe des outils qui peuvent aider à comprendre si de tels biais existent, ils ne font pas de distinction entre corrélation et causalité et peuvent ne pas être adaptés aux modèles textuels et au raisonnement sur des concepts linguistiques de haut niveau. L'un des principaux problèmes de l'estimation de l'effet causal d'un concept d'intérêt sur un modèle donné est que cette estimation nécessite la génération d'exemples contrefactuels, ce qui est difficile avec la technologie de production existante. Pour combler cette lacune, nous proposons CausalM, un cadre permettant de produire des explications de modèles causaux à l'aide de modèles de représentation linguistique contrefactuels. Notre approche est basée sur le réglage fin de modèles d'intégration contextualisés profonds avec des tâches contradictoires auxiliaires dérivées du graphique causal du problème. Concrètement, nous montrons qu'en choisissant soigneusement les tâches auxiliaires de pré-formation contradictoire, les modèles de représentation linguistique tels que BERT peuvent apprendre efficacement une représentation contrefactuelle pour un concept d'intérêt donné, et être utilisés pour estimer son véritable effet causal sur les performances du modèle. Un sous-produit de notre méthode est un modèle de représentation de la langue qui n'est pas affecté par le concept testé, ce qui peut être utile pour atténuer les biais indésirables enracinés dans les données.1", 'es': 'Resumen Comprender las predicciones realizadas por las redes neuronales profundas es notoriamente difícil, pero también crucial para su difusión. Como todos los métodos basados en el aprendizaje automático, son tan buenos como sus datos de entrenamiento y también pueden capturar sesgos no deseados. Si bien existen herramientas que pueden ayudar a entender si existen tales sesgos, no distinguen entre correlación y causalidad, y podrían ser inadecuadas para los modelos basados en texto y para razonar sobre conceptos lingüísticos de alto nivel. Un problema clave para estimar el efecto causal de un concepto de interés en un modelo dado es que esta estimación requiere la generación de ejemplos contrafácticos, lo que supone un desafío con la tecnología de generación existente. Para cerrar esa brecha, proponemos CausalM, un marco para producir explicaciones de modelos causales utilizando modelos de representación de lenguaje contrafácticos. Nuestro enfoque se basa en el ajuste fino de modelos de incrustación contextualizados profundos con tareas contradictorias auxiliares derivadas del gráfico causal del problema. Concretamente, mostramos que al elegir cuidadosamente las tareas auxiliares de preentrenamiento contradictorio, los modelos de representación del lenguaje como BERT pueden aprender efectivamente una representación contrafáctica para un concepto de interés dado y usarse para estimar su verdadero efecto causal en el rendimiento del modelo. Un subproducto de nuestro método es un modelo de representación del lenguaje que no se ve afectado por el concepto probado, lo que puede ser útil para mitigar el sesgo no deseado arraigado en los datos.1', 'pt': 'Resumo Compreender as previsões feitas por redes neurais profundas é notoriamente difícil, mas também crucial para sua disseminação. Como todos os métodos baseados em aprendizado de máquina, eles são tão bons quanto seus dados de treinamento e também podem capturar vieses indesejados. Embora existam ferramentas que podem ajudar a entender se tais vieses existem, elas não distinguem entre correlação e causação e podem ser inadequadas para modelos baseados em texto e para raciocinar sobre conceitos de linguagem de alto nível. Um problema-chave de estimar o efeito causal de um conceito de interesse em um determinado modelo é que essa estimativa requer a geração de exemplos contrafactuais, o que é desafiador com a tecnologia de geração existente. Para preencher essa lacuna, propomos o CausaLM, uma estrutura para produzir explicações de modelos causais usando modelos de representação de linguagem contrafactuais. Nossa abordagem é baseada no ajuste fino de modelos de incorporação contextualizados profundos com tarefas adversárias auxiliares derivadas do gráfico causal do problema. Concretamente, mostramos que, escolhendo cuidadosamente as tarefas de pré-treinamento adversárias auxiliares, os modelos de representação de linguagem, como o BERT, podem efetivamente aprender uma representação contrafactual para um determinado conceito de interesse e ser usados para estimar seu verdadeiro efeito causal no desempenho do modelo. Um subproduto de nosso método é um modelo de representação de linguagem que não é afetado pelo conceito testado, que pode ser útil para mitigar vieses indesejados enraizados nos dados.1', 'ja': '抽象的深層ニューラルネットワークによる予測を理解することは非常に困難であるが、その普及にも重要である。 すべての機械学習ベースの方法と同様に、それらはトレーニングデータと同じくらい優れており、望ましくないバイアスを取り込むこともできます。 そのようなバイアスが存在するかどうかを理解するのに役立つツールがあるが、それらは相関関係と因果関係を区別せず、テキストベースのモデルや高水準言語の概念に関する推論には不適切かもしれない。 関心の概念が与えられたモデルに与える因果効果を推定する際の重要な問題は、この推定には反事実的な例の生成が必要であり、既存の生成技術では難しいことである。 そのギャップを埋めるために、私たちはCausaLMを提案します。CausaLMは、反事実的な言語表現モデルを使用して因果モデルの説明を生成するためのフレームワークです。 私たちのアプローチは、問題の因果グラフから導出された補助的な対抗タスクを伴う深い文脈化された埋め込みモデルの微調整に基づいています。 具体的には、BERTのような言語表現モデルは、補助的な対立事前訓練タスクを慎重に選択することで、与えられた関心の概念に対する反事実表現を効果的に学習し、モデルのパフォーマンスに対する真の因果効果を推定するために使用できることを示している。 私たちの方法の副産物は、テストされた概念の影響を受けない言語表現モデルであり、データに根付いている不要なバイアスを軽減するのに役立ちます。1', 'hi': 'गहरे तंत्रिका नेटवर्क द्वारा की गई भविष्यवाणियों को समझने के लिए अमूर्त समझना कुख्यात रूप से कठिन है, लेकिन उनके प्रसार के लिए भी महत्वपूर्ण है। सभी मशीन लर्निंग-आधारित तरीकों के रूप में, वे अपने प्रशिक्षण डेटा के रूप में अच्छे हैं, और अवांछित पूर्वाग्रहों को भी कैप्चर कर सकते हैं। जबकि ऐसे उपकरण हैं जो यह समझने में मदद कर सकते हैं कि क्या इस तरह के पूर्वाग्रह मौजूद हैं, वे सहसंबंध और कारण के बीच अंतर नहीं करते हैं, और पाठ-आधारित मॉडल के लिए और उच्च-स्तरीय भाषा अवधारणाओं के बारे में तर्क करने के लिए बीमार-अनुकूल हो सकते हैं। किसी दिए गए मॉडल पर ब्याज की अवधारणा के कारण प्रभाव का अनुमान लगाने की एक महत्वपूर्ण समस्या यह है कि इस अनुमान के लिए प्रतिवादी उदाहरणों की पीढ़ी की आवश्यकता होती है, जो मौजूदा पीढ़ी की तकनीक के साथ चुनौतीपूर्ण है। उस अंतर को पाटने के लिए, हम CausaLM का प्रस्ताव करते हैं, जो कि प्रतिवादी भाषा प्रतिनिधित्व मॉडल का उपयोग करके कारण मॉडल स्पष्टीकरण के उत्पादन के लिए एक रूपरेखा है। हमारा दृष्टिकोण समस्या के कारण ग्राफ से व्युत्पन्न सहायक प्रतिकूल कार्यों के साथ गहरे प्रासंगिक एम्बेडिंग मॉडल की ठीक-ट्यूनिंग पर आधारित है। ठोस रूप से, हम दिखाते हैं कि सहायक प्रतिकूल पूर्व-प्रशिक्षण कार्यों को ध्यान से चुनकर, BERT जैसे भाषा प्रतिनिधित्व मॉडल प्रभावी रूप से ब्याज की किसी दी गई अवधारणा के लिए एक प्रतिवादी प्रतिनिधित्व सीख सकते हैं, और मॉडल प्रदर्शन पर इसके वास्तविक कारण प्रभाव का अनुमान लगाने के लिए उपयोग किया जा सकता है। हमारी विधि का एक उपोत्पाद एक भाषा प्रतिनिधित्व मॉडल है जो परीक्षण की गई अवधारणा से अप्रभावित है, जो डेटा में निहित अवांछित पूर्वाग्रह को कम करने में उपयोगी हो सकता है।', 'ru': 'Абстрактное Понимание предсказаний, сделанных глубокими нейронными сетями, является печально известным сложностью, но также имеет решающее значение для их распространения. Как и все методы, основанные на машинном обучении, они так же хороши, как и их обучающие данные, а также могут фиксировать нежелательные ошибки. Хотя существуют инструменты, которые могут помочь понять, существуют ли такие предвзятости, они не проводят различия между корреляцией и причинной обусловленностью и, возможно, не подходят для текстовых моделей и для рассуждений о концепциях языка высокого уровня. Ключевая проблема оценки причинно-следственной связи представляющей интерес концепции с данной моделью заключается в том, что эта оценка требует генерации контрафактных примеров, что сопряжено с трудностями с существующей технологией генерации. Чтобы восполнить этот пробел, мы предлагаем CausaLM, структуру для создания объяснений причинно-следственных моделей с использованием контрафактных моделей языкового представления. Наш подход основан на тонкой настройке глубинных контекстуализированных моделей встраивания со вспомогательными соперническими задачами, полученными из причинно-следственного графа задачи. Конкретно, мы показываем, что, тщательно подбирая вспомогательные состязательные предварительные обучающие задачи, такие языковые модели, как BERT, могут эффективно выучить контрафактное представление для данной концепции интереса и быть использованы для оценки ее истинного причинно-следственного влияния на эффективность модели. Побочным продуктом нашего метода является языковая модель представления, на которую не влияет тестируемая концепция, которая может быть полезна для смягчения нежелательной предвзятости, укоренившейся в данных .1', 'zh': '摘要知深神经网络之占为名难,而深神经网络之传亦至重。 与凡学机器同,与练数同,而可得不需之差也。 虽有器可以助知偏见,而不可以别相关性因果关系,而不可以形于文本、推于言名。 计其对给定效者一关键问题,此度须生反事示例,于今有挑战性。 为弥合之差,吾等发CausaLM,此反事语言之框架也。 吾道基于深情之微,及从果之佐对抗性。 细择对抗性预训练任务,BERT言有效给定反其实,以度其对模型之实。 吾法之副产品,不试其概,所以缓数根深蒂之差也。', 'ga': 'Tá sé thar a bheith deacair tuartha a dhéanann líonraí néaracha doimhne a thuiscint, ach tá sé ríthábhachtach freisin chun iad a scaipeadh. Cosúil le gach modh meaisínfhoghlama, tá siad chomh maith lena sonraí oiliúna, agus féadann siad laofachtaí nach dteastaíonn a ghabháil freisin. Cé go bhfuil uirlisí ann a chabhróidh le tuiscint an bhfuil a leithéid de laofachtaí ann, ní dhéanann siad idirdhealú idir comhghaolú agus cúisíocht, agus d’fhéadfadh siad a bheith mí-oiriúnach do mhúnlaí téacsbhunaithe agus do réasúnaíocht faoi choincheapa teanga ardleibhéil. Príomhfhadhb a bhaineann le meastachán a dhéanamh ar an éifeacht chúise atá ag coincheap spéise ar mhúnla ar leith ná go n-éilíonn an meastachán seo samplaí frithfhíorasacha a ghiniúint, rud atá dúshlánach le teicneolaíocht giniúna reatha. Chun an bhearna sin a líonadh, molaimid CausaLM, creat chun míniúcháin ar mhúnlaí cúiseacha a tháirgeadh ag baint úsáide as samhlacha ionadaíochta teanga frithfhíorasach. Tá ár gcur chuige bunaithe ar mhionchoigeartú ar shamhlacha leabaithe comhthéacsúla domhain le tascanna sáraíochta cúnta a dhíorthaítear ó ghraf cúiseach na faidhbe. Go nithiúil, léirímid, trí thascanna réamhoiliúna sáraíochta cúnta a roghnú go cúramach, gur féidir le samhlacha ionadaíochta teanga ar nós BERT léiriú frithfhíorasach a fhoghlaim go héifeachtach do choincheap áirithe spéise, agus iad a úsáid chun a fhíoréifeacht cúisíoch ar fheidhmíocht na samhla a mheas. Fotháirge dár modh is ea samhail ionadaíochta teanga nach bhfuil aon tionchar ag an gcoincheap a tástáladh uirthi, a d’fhéadfadh a bheith úsáideach chun laofacht nach dteastaíonn atá fite fuaite sna sonraí a mhaolú.1', 'ka': 'აბსტრაქტიკური განსხვავების წარმოდგენები, რომლებიც ძალიან ნეიროლური ქსელებიდან გავაკეთებული, არამედ მნიშვნელოვანია ისინი განსხვავებას. როგორც ყველა მაქსინური სწავლების მეტი, ისინი იგივეა კარგი, როგორც მათი სწავლების მონაცემები, და შეიძლება ასევე გააკვიროთ უნდა იყოს. თუმცა არსებობს ხელსაწყობილობი, რომელიც შეუძლია გავიგოთ თუ არა ასეთი წინაწყობილობები არსებობს კორელაცია და მიზეზების შორის, და შეიძლია არსებობს ტექსტური მოდელებისთვის და რაზეზების მნიშვნელოვანი პრობლემა, რომელიც მინდომის მოდელზე ინტერესტის წარმოდგენის მიზეზი ეფექტის განსაზღვრება იყო, რომ ეს განსაზღვრება იჭირდება განსაზღვრებული მაგალითების შემდეგ, რომელი ჩვენ CausaLM-ს, რომელიც გამოიყენება მიზეზი მოდელური განახლებების გამოყენებას გამოიყენებული მსოფლიო ენის გამოსახულებელი მოდელების გამოყენება. ჩვენი პროგრამა იგივეა, რომელიც პრობლემის მიზეზი გრაფიდან გამოვიყენებული დახმარებელი განსაზღვრებული მოდელების კონტექსტუალურად დაყენებულია. მართლაც, ჩვენ ჩვენ აჩვენებთ, რომ აღმოჩნეთ დახმარებელი განსაკუთრებულ პრეტაციალური სამუშაო სამუშაო სამუშაო სამუშაო მოდელები, როგორც BERT, შეგვიძლია ეფექტურად ვისწავლოთ განსაკუთრებული ინტე ჩვენი მედიოდის ბიპროდისტი არის ენის გამოსახულების მოდელი, რომელიც ტესტირებული კონცექტის გამოსახულებელია, რომელიც შეიძლება გამოსახულებელია მონაცემებში, რომელიც არ უნდა და 1', 'hu': 'Absztrakt A mély neurális hálózatok előrejelzéseinek megértése közismerten nehéz, de a terjesztésük szempontjából is döntő fontosságú. Mint minden gépi tanuláson alapuló módszer, ugyanolyan jók, mint az edzési adataik, és nem kívánt elfogultságokat is rögzíthetnek. Bár vannak eszközök, amelyek segítenek megérteni, hogy léteznek-e ilyen előítéletek, azok nem tesznek különbséget a korreláció és az okozati összefüggés között, és nem alkalmasak lehetnek a szövegalapú modellek és a magas szintű nyelvi fogalmak érvelésére. Egy adott modellre gyakorolt érdeklődési fogalom okozati hatásának becslésének kulcsfontosságú problémája, hogy ez a becslés ellentétes példák generálását igényli, ami kihívást jelent a meglévő termelési technológiával szemben. A szakadék áthidalása érdekében a CausaLM-et javasoljuk, amely egy olyan keretrendszert, amely az okozati modell magyarázatait ellentényes nyelvi reprezentációs modellek felhasználásával lehet előállítani. Megközelítésünk a mély kontextuális beágyazási modellek finomhangolásán alapul, kiegészítő ellenséges feladatokkal, amelyek a probléma okozati grafikonjából származnak. Konkrétan megmutatjuk, hogy a kiegészítő ellentétes előképzési feladatok gondos kiválasztásával az olyan nyelvi reprezentációs modellek, mint a BERT, hatékonyan tanulhatnak ellentétes reprezentációt egy adott érdeklődési fogalomhoz, és felhasználhatók arra, hogy megbecsüljék a modell teljesítményére gyakorolt valódi okozati hatását. Módszerünk mellékterméke egy olyan nyelvi reprezentációs modell, amelyet a tesztelt koncepció nem befolyásol, és amely hasznos lehet az adatokban beépült nemkívánatos elfogultságok enyhítésében. 1', 'el': 'Η κατανόηση των προβλέψεων που γίνονται από βαθιά νευρωνικά δίκτυα είναι διαβόητη δύσκολη, αλλά και κρίσιμη για τη διάδοση τους. Όπως όλες οι μέθοδοι που βασίζονται στη μηχανική μάθηση, είναι τόσο καλές όσο τα δεδομένα κατάρτισης τους και μπορούν επίσης να συλλάβουν ανεπιθύμητες προκαταλήψεις. Ενώ υπάρχουν εργαλεία που μπορούν να βοηθήσουν στην κατανόηση του αν υπάρχουν τέτοιες προκαταλήψεις, δεν διακρίνουν μεταξύ συσχέτισης και αιτιώδους συσχέτισης, και μπορεί να είναι ακατάλληλα για μοντέλα βασισμένα στο κείμενο και για τη συλλογιστική σχετικά με γλωσσικές έννοιες υψηλού επιπέδου. Ένα βασικό πρόβλημα της εκτίμησης της αιτιώδους επίδρασης μιας έννοιας ενδιαφέροντος σε ένα δεδομένο μοντέλο είναι ότι αυτή η εκτίμηση απαιτεί τη δημιουργία αντιπραγματικών παραδειγμάτων, γεγονός που αποτελεί πρόκληση με την υπάρχουσα τεχνολογία παραγωγής. Για να γεφυρώσουμε αυτό το χάσμα, προτείνουμε ένα πλαίσιο για την παραγωγή αιτιώδους επεξηγήσεων μοντέλων χρησιμοποιώντας αντιπραγματικά μοντέλα γλωσσικής αναπαράστασης. Η προσέγγισή μας βασίζεται στον συντονισμό των βαθύτατων πλαισιωμένων μοντέλων ενσωμάτωσης με βοηθητικές αντιφατικές εργασίες που προέρχονται από το αιτιολογικό γράφημα του προβλήματος. Συγκεκριμένα, καταδεικνύουμε ότι επιλέγοντας προσεκτικά βοηθητικές αντιθετικές εργασίες προεκπαίδευσης, τα μοντέλα γλωσσικής αναπαράστασης όπως το μπορούν να μάθουν αποτελεσματικά μια αντιπαραγωγική αναπαράσταση για μια δεδομένη έννοια ενδιαφέροντος και να χρησιμοποιηθούν για την εκτίμηση της πραγματικής αιτιώδους επίδρασής του στην απόδοση του μοντέλου. Ένα υποπροϊόν της μεθόδου μας είναι ένα μοντέλο γλωσσικής αναπαράστασης που δεν επηρεάζεται από την δοκιμασμένη έννοια, το οποίο μπορεί να είναι χρήσιμο για τον μετριασμό της ανεπιθύμητης προκατάληψης που είναι ριζωμένη στα δεδομένα. 1', 'kk': 'Абстрактикалық түсініктерді түсініктеу үшін түсінікті невралдық желілерден жасалған бағдарламаларды білмейді, сондай-ақ олардың тарату үшін маңызды. Барлық компьютердің оқыту әдістері ретінде олар өзінің оқыту деректері сияқты жақсы, сондай-ақ қаламаған тұрақты түсіндіре алады. Бұл өзгерістерді түсінуге көмектесетін құралдар бар, олар мәтін негіздеген моделдерге және жоғары деңгейіндегі тіл концепцияларының айырмашылығын түсінбейді. Келтірілген үлгіге қызықтық концепциясының негізгі нәтижесін оқу үшін негізгі мәселесі - бұл оқиға бар жалпы мәселелерді құру керек, ол бар жалпы құру технологиясында қиын Бұл бос аралығын көшірмелеу үшін CausaLM- ды, тілдерді көрсету үлгілерін қолдану үшін, негізгі үлгілерді түсініктемелерді жасау үшін қолданамыз. Біздің тәсіліміз мәселедің негізгі графикадан шыққан көмекші негізгі қарсы тапсырмаларды түзету үлгілеріне негізделген. Сонымен біз, BERT секілді тілдерді таңдау үлгілерін көмектесіп таңдап, келтірілген қызықтық концепциясы үшін жалғыз мәліметті үйрене аламыз, мәліметтің шындық себептерін бағалау үшін қолданылады. Біздің әдіміміздің айырмалы продукты - тілдерді көрсету үлгісі, тексерілмеген концепциясы арқылы әсер етпейді. Бұл деректерге қаламаған қарамастыру үшін пайдалы болуы мүмкін. 1', 'it': "Comprendere le previsioni fatte dalle reti neurali profonde è notoriamente difficile, ma anche cruciale per la loro diffusione. Come tutti i metodi basati sull'apprendimento automatico, sono validi quanto i loro dati di allenamento e possono anche catturare pregiudizi indesiderati. Anche se esistono strumenti che possono aiutare a capire se esistono tali pregiudizi, essi non distinguono tra correlazione e causalità e potrebbero non essere adatti per modelli basati sul testo e per ragionare su concetti linguistici di alto livello. Un problema chiave per stimare l'effetto causale di un concetto di interesse su un dato modello è che questa stima richiede la generazione di esempi controfattuali, che è difficile con la tecnologia di generazione esistente. Per colmare questo divario, proponiamo CausaLM, un framework per produrre spiegazioni di modelli causali utilizzando modelli di rappresentazione linguistica controfattuali. Il nostro approccio si basa sulla messa a punto di modelli di incorporazione contestualizzati profondi con compiti avversi ausiliari derivati dal grafico causale del problema. In concreto, dimostriamo che, scegliendo con attenzione i compiti ausiliari di pre-formazione avversaria, modelli di rappresentazione linguistica come BERT possono imparare efficacemente una rappresentazione controfattuale per un dato concetto di interesse e essere utilizzati per stimare il suo vero effetto causale sulle prestazioni del modello. Un sottoprodotto del nostro metodo è un modello di rappresentazione linguistica che non è influenzato dal concetto testato, che può essere utile per mitigare i bias indesiderati radicati nei dati. 1", 'ms': 'Ramalan pemahaman abstrak yang dibuat oleh rangkaian saraf dalam sangat sukar, tetapi juga penting untuk penyebaran mereka. As all machine learning-based methods, they are as good as their training data, and can also capture unwanted biases.  While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts.  Masalah utama penghargaan kesan penyebab konsep kepentingan pada model tertentu ialah penghargaan ini memerlukan generasi contoh kontrafaktual, yang mencabar dengan teknologi generasi yang wujud. Untuk menyelesaikan ruang tersebut, kami cadangkan CausaLM, kerangka untuk menghasilkan penjelasan model penyebab menggunakan model perwakilan bahasa kontrafaktual. pendekatan kita berdasarkan penyesuaian model penyembedding kontekstualisasi dalam dengan tugas musuh bantuan yang berasal dari graf penyebab masalah. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance.  Sebuah produk sampingan kaedah kami adalah model perwakilan bahasa yang tidak diserang oleh konsep yang diuji, yang boleh berguna untuk mengurangi bias yang tidak diinginkan terlibat dalam data. 1', 'ml': 'ആഴത്തെ ന്യൂറല്\u200d നെറ്റര്\u200d വര്\u200dക്കുകള്\u200d ഉണ്ടാക്കിയ പ്രവചനങ്ങള്\u200d അസ്ട്രാക്ട് ചെയ്യുന്നത് വളരെ ബുദ്ധിമുട്ടാണ്, പക്ഷെ  എല്ലാ യന്ത്രങ്ങളും പഠിക്കുന്നതിന്റെ അടിസ്ഥാനമായ രീതികളാണ് അവയുടെ പരിശീലനത്തിന്റെ വിവരങ്ങളെപ്പോലെയാണ് നല്ലത്,  ഇത്തരം തെറ്റുകള്\u200d നിലനില്\u200dക്കുന്നോ എന്ന് മനസ്സിലാക്കാന്\u200d സാധ്യതയുള്ള ഉപകരണങ്ങളുണ്ടെങ്കില്\u200d, അവര്\u200d ബന്ധവും കാരണവും തമ്മില്\u200d വേര്\u200dപിരിക്കുന്നില്ല, പ കൊടുക്കപ്പെട്ട ഒരു മോഡലിന്റെ ആവശ്യത്തിന്റെ കാരണ പ്രഭാവം കണക്കാക്കാനുള്ള ഒരു പ്രശ്നമായ പ്രശ്നം എന്താണെന്നാല്\u200d ഈ കണക്കിന് നിലവ ആ വേര്\u200dപെടുത്താന്\u200d ഞങ്ങള്\u200d കായുസെല്\u200dഎമിനെ പ്രൊജക്കെടുക്കുന്നു, കാരണമായ മോഡല്\u200d വിശദീകരിക്കുന്നതിനുള്ള ഫ്രെയിമെയ പ്രശ്നത്തിന്റെ കാരണ ഗ്രാഫ്റ്റില്\u200d നിന്നും കൊണ്ടുവന്ന ആഴത്തില്\u200d നിന്നും കൂടുതല്\u200d വിരോധമായ പ്രവര്\u200dത്തനങ്ങളുടെ കൂട്ടത്തില്\u200d നമ് തീര്\u200dച്ചയായും, നമ്മള്\u200d കാണിച്ചു കൊടുക്കുന്നത് ശ്രദ്ധിച്ച് കൊണ്ട് തന്നിട്ടുള്ള താല്\u200dക്കാലിക പ്രവർത്തിക്കുന്നതിന് മുമ്പ് പരിശീലിക്കുന്ന ജോലികള്\u200d തിരഞ്ഞെടുക നമ്മുടെ രീതിയിലുള്ള ഒരു ഭാഷ പ്രദര്\u200dശിപ്പിക്കുന്ന മോഡലാണ് പരീക്ഷിക്കപ്പെട്ട ആശയം കൊണ്ട് പ്രയോജനപ്പെടാത്തത്. അത് ഡേറ്റായില്\u200d ഉ 1', 'mn': 'Гүн гүнзгий мэдрэлийн сүлжээгээр хийсэн абстрактикийн ойлголтын таамаглал нь маш хэцүү, мөн тэдний тархалтад чухал. Бүх машины суралцах сургалтын аргын төлөө тэд суралцах өгөгдлийн төлөвлөгөөтэй адилхан, мөн хүсэхгүй байдал барьж чадна. Ийм байдал байдаг эсэхийг ойлгох боломжтой хэрэгсэл байдаг ч тэд харилцаа болон шалтгааны хоорондоо ялгаагүй, мөн текст суурилсан загварууд болон өндөр төвшин хэлний ойлголтын тухай бодох боломжтой байж магадгүй. Өөр загвар дээр сонирхолтой ойлголтын үр дүнг тооцоолох чухал асуудал бол энэ тооцоололт нь суурь үеийн технологи дээр шаардлагатай хуурамч жишээн хэрэгтэй. Бид CausaLM-г тодруулахын тулд буруу хэлний төсөөлөлтийн загварыг ашиглан шалтгаан загварын тодорхойлолтуудыг бүтээх үйл ажиллагаа өгдөг. Бидний арга зам нь асуудлын шалтгаан графикийн тусламжтай тусламжтай өрсөлдөг загваруудын гүн гүнзгий байдлын загваруудыг тодорхойлж байдаг. Эцэст нь бид анхаарлын өмнө сургалтын тусламжтайгаар тусламжтайгаар сонгож, BERT шиг хэлний үзүүлэлтийн загварууд үнэхээр сонирхолтой ойлголтыг сурах боломжтой болно. Бидний арга замын биеийн бүтээгдэхүүн бол хэлний үзүүлэлтийн загвар юм. Энэ нь шалгалтанд нөлөөлөхгүй байдаг. Энэ нь мэдээллээр хүсэхгүй байдлыг багасгах хэрэгтэй. 1', 'no': 'Avstrakt forståking av dype neuralnettverk er vanskeleg, men også viktig for disseminasjonen. Som alle maskinelæringsmetodane er dei så gode som opplæringsdata, og kan også henta ugjennomsiktige forsikt. Selv om det finst verktøy som kan hjelpa å forstå om slike forskjeller finst, forskjeller dei ikkje mellom korrelasjon og for årsaken, og kanskje vera ugyldig for tekstbaserte modeller og for rasjon om språk med høg nivå. Ein nøkkelproblem med å estimere grunnleggjande effekt av ein konsept av interesse på eit oppgjeven modell er at denne estimeren krev generasjon av vilkårlege eksemplar, som er vanskeleg med eksisterande generasjonsteknologi. For å bryta dette mellomrommet, foreslår vi CausaLM, eit rammeverk for å produsera grunnleggjande modelleforklaringar ved hjelp av vilkårlege språk- representasjonsmodular. Tilnærminga vårt er basert på finnstilling av dype kontekstualiserte innbyggingsmodeller med hjelpelige adversariale oppgåver som er oppretta frå den grunnleggjande grafen av problemet. Dette viser vi at ved å velja forsiktig hjelpevekslingsoppgåver for å trekke opp, språk-representasjonsmodular som BERT kan lære eit vilkårleg representasjon for eit gitt interesse, og blir brukt for å estimere sin sann årsakel effekt på utviklinga av modellen. Eit byprodukt av metoden vårt er eit språk-representasjonsmodul som ikkje er påvirka av den testerte konsepten, som kan vera nyttig i å minne ugjennomsiktige bias som inneheld i data. 1', 'pl': 'Zrozumienie prognoz dokonywanych przez głębokie sieci neuronowe jest notorycznie trudne, ale również kluczowe dla ich rozpowszechniania. Jak wszystkie metody oparte na uczeniu maszynowym, są tak dobre jak ich dane treningowe, a także mogą wychwytywać niechciane uprzedzenia. Chociaż istnieją narzędzia, które mogą pomóc zrozumieć, czy takie uprzedzenia istnieją, nie rozróżniają one korelacji i związku przyczynowego i mogą być nieodpowiednie dla modeli tekstowych i do rozumowania na temat koncepcji językowych wysokiego poziomu. Kluczowym problemem oszacowania efektu przyczynowego koncepcji zainteresowania na dany model jest fakt, że szacunek ten wymaga generowania przykładów kontrfaktycznych, co stanowi wyzwanie dla istniejącej technologii generacji. Aby wypełnić tę lukę, proponujemy CausaLM, ramy służące do tworzenia wyjaśnień modeli przyczynowych przy użyciu modeli reprezentacji językowej przeciwfaktycznych. Nasze podejście opiera się na dopracowaniu głęboko kontekstualizowanych modeli osadzania z dodatkowymi zadaniami przeciwnymi wywodzącymi się z wykresu przyczynowego problemu. Konkretnie pokazujemy, że starannie dobierając pomocnicze zadania przedszkoleniowe, modele reprezentacji językowej, takie jak BERT, mogą skutecznie nauczyć się reprezentacji przeciwfaktycznej dla danej koncepcji zainteresowania i być wykorzystane do oszacowania jej prawdziwego wpływu przyczynowego na wydajność modelu. Produktem ubocznym naszej metody jest model reprezentacji języka, który nie jest naruszony przez testowaną koncepcję, co może być przydatne w łagodzeniu niechcianych stronnic zakorzenionych w danych. 1', 'lt': 'Abstract Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination.  Kaip ir visi su mašinų mokymu pagrįsti metodai, jie yra tokie pat geri kaip ir jų mokymo duomenys, ir taip pat gali nustatyti nepageidaujamus nukrypimus. Nors yra priemonių, kurios gali padėti suprasti, ar tokių pusiausvyrų egzistuoja, jos neatskiria koreliacijos ir priežastinio ryšio ir gali būti netinkamos tekstiniams modeliams ir aukšto lygio kalbų koncepcijoms pagrįsti. Pagrindinė problem a, susijusi su intereso koncepcijos priežastiniu poveikiu tam tikram modeliui, yra ta, kad šiam vertinimui reikia sukurti priešingus pavyzdžius, kurie kelia sunkumų esamoms gamybos technologijoms. Siekiant pašalinti šią spragą, siūlome CausaLM, pagrindą, pagal kurį būtų galima pateikti priežastinio modelio paaiškinimus naudojant priešingus kalbų atstovavimo modelius. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem.  Konkrečiai rodome, kad atidžiai pasirinkdami papildomas priešingas priešingas parengiamojo mokymo užduotis kalbų atstovavimo modeliai, pavyzdžiui, BERT, gali veiksmingai išmokti priešingą atstovavimą tam tikrai interesų koncepcijai ir būti naudojami vertinant jo tikrą priežastinį poveikį modelio veiklos rezultatams. Mūsų metodo šalutinis produktas yra kalbos reprezentacijos model is, kuris neturi įtakos bandomai koncepcijai, kuri gali būti naudinga mažinant nepageidaujamą pusę, įtraukiamą į duomenis. 1', 'mk': 'Abstract Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination.  Како и сите методи засновани на машинско учење, тие се добри како и нивните податоци за обука, и исто така можат да фатат нежелни предрасуди. Иако постојат алатки кои можат да помогнат да разберат дали вакви предрасуди постојат, тие не разликуваат помеѓу корелацијата и причината и можеби не се соодветни за текстовите модели и за размислување за јазичките концепти на високо ниво. Клучен проблем со проценката на причинниот ефект на концептот на интерес на одреден модел е тоа што оваа проценка бара генерација на контрафактни примери, кои се предизвикуваат со постоечката генерациска технологија. За да ја преминеме таа празнина, предлагаме CausaLM, рамка за производство на причински модели објаснувања користејќи контрафактични модели за претставување на јазикот. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem.  Конкретно, покажуваме дека со внимателно избирање на помошните непријателски предобукни задачи, моделите за претставување на јазикот како што е БЕРТ можат ефикасно да научат контрафактично претставување на одреден концепт на интерес и да се користат за проценка на неговиот вистински причинен ефект на моделот. Бипроизвод од нашиот метод е модел за претставување на јазикот кој не е влијаен на тестираниот концепт, кој може да биде корисен за олеснување на нежелената предрасуда вклучена во податоците. 1', 'sr': 'Apstraktivno razumevanje predviđanja koje su napravljene dubokim neuralnim mrežama je poznato teško, ali takođe je ključno i za njihovu disseminaciju. Kao i svi metodi na osnovu učenja mašine, oni su dobri kao i podaci o obuci, i mogu takođe uhvatiti neželjene predrasude. Iako postoje alati koji mogu da pomognu da shvate postoje li takve predrasude, ne razlikuju se između korelacije i uzrokovanja, i možda bi bili loše odgovarajući za modele na tekstu i za razmišljanje o konceptima jezika na visokom nivou. Ključni problem procjene uzrokovanog učinka koncepta interesa na određeni model je da ova procjena zahteva generaciju lažnih primjera, koje je izazovno sa postojećim tehnologijom generacije. Da bismo predložili taj praznik, predlažemo CausaLM, okvir za proizvodnju uzrokovanih model a objašnjenja koristeći lažne modele predstavljanja jezika. Naš pristup je baziran na finom prilagodbi dubokih kontekstualiziranih modela ugrađenih sa pomoænim neprijateljskim zadatkama iz uzrokovanog grafika problema. Konačno, pokazujemo da pažljivo izabereći pomoćne neprijateljske zadatke pre obuke, modeli predstavljanja jezika kao što je BERT mogli učiti lažnu predstavu za određeni koncept interesa i koristiti se kako bi procenili svoj pravi uzrok na provedbu model a. Pojavljeni proizvod naše metode je model predstavljanja jezika koji ne utiče na testovani koncept, koji može biti korisan u smanjenju neželjene pristrasnosti koje se ugrizaju u podacima. 1', 'mt': 'Il-previżjonijiet ta’ fehim astratt magħmula minn netwerks newrali profondi huma magħrufa bħala diffiċli, iżda wkoll kruċjali għat-tixrid tagħhom. As all machine learning-based methods, they are as good as their training data, and can also capture unwanted biases.  Filwaqt li hemm għodod li jistgħu jgħinu biex jifhmu jekk tali preġudizzji jeżistux, ma jiddistingwux bejn il-korrelazzjoni u l-kawżalità, u jistgħu ma jkunux adattati għal mudelli bbażati fuq it-test u għar-raġunament dwar kunċetti lingwistiċi ta’ livell għoli. Problema ewlenija tal-istima tal-effett kawżali ta’ kunċett ta’ interess fuq mudell partikolari hija li din l-istima teħtieġ il-ġenerazzjoni ta’ eżempji kontrofattwali, li hija sfida għat-teknoloġija tal-ġenerazzjoni eżistenti. Biex nindirizzaw din id-distakk, nipproponu CausaLM, qafas għall-produzzjoni ta’ spjegazzjonijiet ta’ mudell kawżali bl-użu ta’ mudelli ta’ rappreżentazzjoni tal-lingwi kontrofattwali. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem.  B’mod konkret, nuru li billi nagħżlu b’attenzjoni kompiti awżiljarji avversarji ta’ qabel it-taħriġ, mudelli ta’ rappreżentanza lingwistika bħall-BERT jistgħu effettivament jitgħallmu rappreżentanza kontrofattwali għal kunċett partikolari ta’ interess, u jintużaw biex jistmaw l-effett kawżali veru tiegħu fuq il-prestazzjoni tal-mudell. Prodott sekondarju tal-metodu tagħna huwa mudell ta’ rappreżentazzjoni lingwistika li mhuwiex affettwat mill-kunċett ittestjat, li jista’ jkun utli biex jittaffa l-preġudizzju mhux mixtieq imdaħħal fid-dejta. 1', 'ro': 'Înțelegerea predicțiilor făcute de rețelele neuronale profunde este notoriu dificilă, dar și crucială pentru diseminarea lor. Ca toate metodele bazate pe învățare automată, acestea sunt la fel de bune ca datele lor de antrenament și pot capta, de asemenea, prejudecăți nedorite. Deși există instrumente care pot ajuta la înțelegerea existenței unor astfel de prejudecăți, ele nu fac distincția între corelație și cauzalitate și ar putea fi necorespunzătoare pentru modelele bazate pe text și pentru raționamentul cu privire la conceptele lingvistice de nivel înalt. O problemă cheie de estimare a efectului cauzal al unui concept de interes asupra unui anumit model este faptul că această estimare necesită generarea de exemple contrafactuale, ceea ce reprezintă o provocare pentru tehnologia de generare existentă. Pentru a depăși acest decalaj, propunem CausaLM, un cadru pentru producerea de explicații ale modelului cauzal folosind modele de reprezentare a limbajului contrafactual. Abordarea noastră se bazează pe reglarea fină a modelelor de încorporare contextualizate profund cu sarcini adversare auxiliare derivate din graficul cauzal al problemei. În mod concret, arătăm că, prin alegerea atentă a sarcinilor de pre-formare adversară auxiliară, modelele de reprezentare lingvistică precum BERT pot învăța efectiv o reprezentare contrafactuală pentru un anumit concept de interes și pot fi utilizate pentru a estima efectul cauzal real asupra performanței modelului. Un produs secundar al metodei noastre este un model de reprezentare lingvistică care nu este afectat de conceptul testat, care poate fi util în atenuarea prejudecăților nedorite înrădăcinate în date. 1', 'sv': 'Att förstå förutsägelser gjorda av djupa neurala nätverk är notoriskt svårt, men också avgörande för deras spridning. Som alla maskininlärningsbaserade metoder är de lika bra som deras träningsdata och kan också fånga oönskade fördomar. Även om det finns verktyg som kan hjälpa till att förstå om sådana fördomar finns, skiljer de inte mellan korrelation och orsakssamband, och kan vara olämpliga för textbaserade modeller och för resonemang om språkbegrepp på hög nivå. Ett centralt problem för att uppskatta orsakseffekten av ett intressebegrepp på en given modell är att denna uppskattning kräver att man genererar kontrafaktiska exempel, vilket är utmanande med befintlig produktionsteknik. För att överbrygga detta gap föreslår vi CausaLM, ett ramverk för att producera orsaksmodellförklaringar med hjälp av kontrafaktiska språkrepresentationsmodeller. Vårt tillvägagångssätt är baserat på finjustering av djupkontextualiserade inbäddningsmodeller med extra motstridiga uppgifter härledda från orsaksgruppen av problemet. Konkret visar vi att språkrepresentationsmodeller som BERT kan lära sig en kontrafaktisk representation för ett givet intressebegrepp och användas för att uppskatta dess verkliga orsakseffekt på modellens prestanda genom att noggrant välja hjälpuppgifter. En biprodukt av vår metod är en språkrepresentationsmodell som inte påverkas av det testade konceptet, vilket kan vara användbart för att mildra oönskade bias som är inbyggda i data. 1', 'si': 'ගොඩක් න්යුරෝල් ජාලයෙන් කරපු අවශ්\u200dය තේරුම්ගන්න අවශ්\u200dයයි, ඒත් ඔවුන්ගේ විස්තරයෙන් ප්\u200dරශ්නය වෙ ඔක්කොම මැෂින් ඉගෙන ගන්න ප්\u200dරමාණය විදිහට, ඔවුන් ඔවුන්ගේ ප්\u200dරධාන දත්ත වගේ හොඳයි, ඒ වගේම අවශ්\u200dය න ඒ වගේම උපකරණය තේරුම් ගන්න පුළුවන් උපකරණය තේරුම් ගන්න, ඔවුන් සම්බන්ධතාවය සහ කාරණය සඳහා වෙනස් කරන්නේ නැති කියලා, සමහරවිට පාළුව දෙන්න ප්\u200dරමාණයක් වෙනුවෙන් සැලසුම් ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරශ්නයක් තමයි මේ විශ්වාස අවශ්\u200dය වෙනුවෙන් ප්\u200dරශ්නයක් වි අපි CausLM විශ්වාස කරනවා, ඒ විශ්වාස විශ්වාස කරන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරනවා කියලා. අපේ ප්\u200dරවේශනය සඳහා ගොඩක් සංවේශනය සම්පූර්ණය සම්පූර්ණයේ හොඳ සංවේශනය සම්පූර්ණය සඳහා සාධාරණ විරෝධ වැඩක විශේෂයෙන්, අපි පෙන්වන්නේ ඒක අවධානයෙන් ප්\u200dරශ්නයක් නිර්භාවිත විරෝධක වැඩ කරන්න, භාෂාව ප්\u200dරශ්නයක් නිර්භාවිත විදිහට BERT වගේ ප්\u200dරශ්නයක් ප්\u200dර අපේ පරීක්ෂණයේ බායිප්\u200dරදේශයක් තමයි භාෂාව ප්\u200dරතිනිධානයක් විදිහට පරීක්ෂණය කරලා නැති පරීක්ෂණය, ඒක ප්\u200dරයෝජනය වෙන් 1', 'so': 'Waxyaabaha waxgarashada la qabo oo shabakado daboolka ah lagu sameeyo waa ku adag tahay, laakiin waxaa kaloo muhiim u ah inay kala firdhiyaan. Sida caadooyinka waxbarashada ee machadka ah oo dhan waxay u wanaagsan yihiin sida macluumaadkooda waxbarashada, sidoo kale waxay qabsan karaan tababar aan la filayn. Intii ay jirto qalabka caawimaad ah oo garan kara in caynkaas ah ay jiraan, ma kala duwanaayaan xiriirka iyo sababaha, waxaana laga yaabaa in lagu habboon tusaalaha qoraalka ku saleysan iyo ka fikirrada dhanka luuqada sare. Dhibaato muhiim ah oo ku qiimeynaya saameynta ku saabsan qaababka danaha la siiyey waa in qiimeyntu ay u baahan tahay abuuridda tusaalooyin kala duduwan, kaas oo ku qasbaya teknolojiga farsamada. Si aan u qaliinno burburkaas, waxaynu u soo jeedaynaa CausaLM, kaas oo ah koob u sameynta fasirada noocyada sababta ah oo lagu isticmaalayo noocyada qaabilaadda luuqada ka geesta ah. Dhaqdhaqaalkayagu waxay ku saleysan tahay samooyin aad u dheer oo daboolan oo ay ku jiraan shaqooyin cadaawayaal ah oo ka soo baxay aragtida dhibaatada. Si taxadar ah, waxaynu tusnaynaa in si taxadar leh u doorasho shaqaalaha ka hor-waxbarashada, tusaale ahaan noocyada qaabilaadda luuqadda sida BERT waxay si effective ah u baran karaan aragtida dib u dhigashada, waxaana loo isticmaali karaa inuu ku qiimeeyo saameyntiisa dhabta ah ee sameynta modellka. Dhaqaalaha noocyadana waa model u dhigista luuqada oo aan saameyn ku lahayn fikrada imtixaanka, kaas oo faa’iido u leh in la koobi karo baaritaanka aan la filin ee macluumaadka lagu soo qoray. 1', 'ta': 'ஆழமான புதிய வலைப்பின்னல்களால் செய்யப்பட்டுள்ள புரிந்து புரிந்து கொள்ளும் முக்கியமாக உள்ளது, ஆனால் அவர்கள் பரப் அனைத்து இயந்திரத்திலும் கற்றுக்கொள்ள முறைகளாக, அவர்கள் பயிற்சி தகவல்களைப் போல நல்ல, மற்றும் எதிர்பாராத பாதிக் இது போன்ற பிரச்சனைகள் இருக்கிறதா என்று புரிந்து கொள்ளும் கருவிகள் இருக்கும் போது, அவர்கள் இணைப்புகள் மற்றும் காரணத்திற்கும் இடையே பிரிப்பது அல்ல கொடுக்கப்பட்ட மாதிரியின் காரணத்தின் விளைவை மதிப்பிடுவதற்கு ஒரு முக்கிய பிரச்சினை இந்த இடைவெளியை பிரிண்ட் செய்ய, நாம் CausaLM, ஒரு சட்டத்தை உருவாக்குவதற்கு காரணத்தின் மாதிரி விளக்கங்களை எதிர்மறை மொழி பி எங்கள் வழிமுறை பிரச்சனையின் காரணமான வரைப்படத்திலிருந்து வரையப்பட்ட மாதிரிகளின் மூலம் சரியான சரியான தூண்டுதல் அடிப்படையில் உள்ளத நாம் கவனமாக தேர்ந்தெடுத்து முன் பயிற்சி பணிகளை தேர்ந்தெடுத்து, பிரெட் போன்ற மொழி பிரதிநிர்வாக மாதிரிகளை தேர்ந்தெடுத்து கொடுக்கப்பட்ட வட்டியின் உண்மையான கா எங்கள் முறையில் ஒரு பைப் பொருள் ஒரு மொழி குறிப்பிடும் மாதிரி அது சோதிக்கப்பட்ட கருத்தால் பாதிக்கப்படவில்லை, அது தரவுகளில் உள்ளடக்கப் 1', 'ur': 'عمیق نیورل نیورل نیٹورک کے ذریعے مطلق سمجھنے کی پیش بینی بہت مشکل نہیں ہے، بلکہ ان کے پھیلانے کے لئے بھی ضروری ہے. تمام ماشین کی تعلیم کی بنیاد کی طریقے کے طور پر، وہ اپنے تربین ڈیٹے جیسے اچھے ہیں، اور وہ بھی غیر خواہش کی بحث کو پکڑ سکتے ہیں۔ اگرچہ ایسے ابزار ہیں جو سمجھ سکتے ہیں کہ ایسی بغیرات موجود ہیں، وہ تعلق اور دلیل کے درمیان تفریق نہیں کرتے، اور شاید ان کے لئے متن بنیاد مدلکوں اور بلند سطح کی زبان عقیدوں کے بارے میں بغیر مناسب ہیں. ایک مقررہ موڈل پر علاقه کا دلیل اثر مقرر کرنے کی ایک کلی مسئلہ یہ ہے کہ یہ مطالبہ مختلف مثال کی نسل کی ضرورت ہے جو موجود نسل تکنولوژی کے ساتھ مشکل ہے اس جگہ کے لئے ہم CausaLM کی پیشنهاد کریں گے، ایک فرمود ہے کہ منصفال موڈل کی توضیح کے مطابق مختلف زبان کی نمونڈل کے مطابق پیدا کریں۔ ہمارا طریقہ مسئلہ کے دلیل گراف سے پیدا ہوا ہے جو عمیق کنٹکسٹیولیز مڈیلڈ مڈیلڈ کے مطابق اضافہ کرنے والے کاموں کے ذریعے بنیاد ہے. بالکل، ہم دکھاتے ہیں کہ مشکل طریقے سے مشکل طریقے کے مقابلہ پیش ترینس کے کاموں کو انتخاب کریں، زبان نمونے نمونے جیسے BERT کے ذریعہ ایک معلوم نظریہ کے لئے ایک فارغ حقیقی نمونے کی تعلیم سکتا ہے، اور مدل کے کامیابی پر اس کا حقیقی دلیل اثر کا اندازہ لینے کے لئے استعم ہمارے طریقے کا ایک بائیپروڈکٹ ایک زبان نمونٹ موڈل ہے جو آزمائش کی نظریہ سے غیر اثر ہے، جو ڈاکٹوں میں غیر خواہش کی بصیرت کو کمزور کرنے کے لئے فائدہ دے سکتا ہے. 1" (msgctxt: "panel:showusername") to "1', 'vi': 'Rõ ràng dự đoán về hiểu biết về sâu thần kinh từ mạng thần kinh rất khó, nhưng cũng rất quan trọng cho sự phát triển của chúng. Như tất cả các phương pháp dựa trên việc học máy, chúng cũng tốt như dữ liệu huấn luyện của chúng, và có thể ghi lại các tật xấu không mong đợi. Trong khi có những công cụ có thể giúp hiểu được sự tồn tại của các thói giả lập này, chúng không phân biệt được mối tương quan và nguyên nhân, và có thể không phù hợp với các mô hình văn bản và lý luận về các khái niệm ngôn ngữ cấp cao. Một vấn đề quan trọng trong việc ước tính hiệu quả của một khái niệm lợi nhuận trên một mô hình đã được xác định là nó yêu cầu tạo ra những ví dụ ngược điểm, thách thức với công nghệ sản sinh đã có. Để vượt qua khoảng cách đó, chúng tôi đề nghị CaucasLM, một cơ sở để sản xuất giải thích hệ thống, dựa trên mô tả ngôn ngữ ngược điểm. Cách tiếp cận của chúng tôi dựa trên độ chỉnh sửa sâu các mô hình tình hình ghép với các công việc phụ kết hợp kết hợp từ nguyên nhân của vấn đề. Trên thực tế, chúng tôi cho thấy rằng, chọn cẩn thận các công việc bổ trợ huấn luyện trước đối thủ, các mô hình đại diện ngôn ngữ như BERT có thể thực sự học đại diện ngược về một khái niệm về lợi ích cụ thể, và được sử dụng để ước lượng nguyên nhân thật sự của nó trên khả năng mô hình. Một thứ thừa hưởng của phương pháp là một mô hình ngôn ngữ không bị ảnh hưởng bởi khái niệm được thử nghiệm, có thể có ích để giảm bớt các khuynh hướng không mong muốn được gắn vào dữ liệu. L', 'uz': "Name Barcha mashinalar o'rganish usullari sifatida, ular ularning taʼminlovchi maʼlumotlari kabi juda yaxshi narsa, va hamma narsalarni qo'shish mumkin. Шунингдек, ушбу баҳслар мавжуд бўлса ҳам, улар алоқалар ва сабаблари орасида ажратилмаган, ва matn asosiy modellari учун нотўғри мувофиқ бўлиши мумкин ва олий тил фикрларини тўғрилаш учун баҳс қиладиган асбоблар мавжуд. Ko'rsatilgan modelga qiziqarish natijasining sabablarini qiymatish uchun muhim muammolar, bu qiymatning qiymati, bu tashkilotni tasavvur qilish kerak, bu mavjud foydalanuvchi texnologiya bilan murakkab qiladi. Bu gap tasavvur qilish uchun CausaLM, biz sabablar modeli rivojlanish uchun foydalanuvchi modelni foydalanish uchun foydalanamiz. Bizning fikrimiz muammolar sababining sabablarga ko'rsatilgan juda ko'p qismi modellari bilan ajoyib chiqarishga asosidir. Biz tashkilotni tajribadan oldin foydalanish vazifalarini aniqlashimiz mumkin, BERT kabi tilni taʼminlovchi modellarni foydalanishimiz mumkin, bir xil qiziqni anglatadigan g'oyalarning foydalanishi mumkin, va model ishoniga haqiqiqiy sabablar effektini qiymatlashdan foydalanamiz. Bizning usulidagi baytiyot taʼminlovchi tilning taʼminlovchi modeli, bu tizimni tasdiqlash imkoniyati yordamida ishlatilmaydi, bu maʼlumotlar tarkibini olib tashlashda foydalanishi mumkin. 1", 'bg': 'Разбирането на прогнозите, направени от дълбоки невронни мрежи, е известно като трудно, но също така от решаващо значение за тяхното разпространение. Както всички методи, базирани на машинно обучение, те са толкова добри, колкото техните данни за обучение и могат да улавят нежелани пристрастия. Въпреки че съществуват инструменти, които могат да помогнат да се разбере дали съществуват такива пристрастия, те не правят разлика между корелация и причинно-следствена връзка и може да не са подходящи за текстови модели и за разсъждения за езикови концепции на високо ниво. Ключов проблем при оценката на причинно-следствения ефект на концепция за интерес върху даден модел е, че тази оценка изисква генерирането на контрафактически примери, което е предизвикателство при съществуващите технологии за производство. За да преодолеем тази пропаст, предлагаме рамка за създаване на обяснения на причинно-следствения модел, използвайки контрафактически езикови модели за представяне. Нашият подход се основава на фина настройка на дълбоко контекстуализирани вградени модели с помощни противоречиви задачи, получени от причинно-следствената графика на проблема. Конкретно, ние показваме, че чрез внимателно подбор на допълнителни задачи за предобучение, моделите на езиково представяне като BERT могат ефективно да научат контрафактическо представяне за дадена концепция за интерес и да бъдат използвани за оценка на истинския причинно-следствен ефект върху производителността на модела. Страничен продукт на нашия метод е езиков модел на представяне, който не се влияе от тестваната концепция, която може да бъде полезна за смекчаване на нежеланите пристрастия, вкоренени в данните. 1', 'da': 'Forståelse af forudsigelser lavet af dybe neurale netværk er notorisk vanskeligt, men også afgørende for deres formidling. Som alle maskinlæringsbaserede metoder er de lige så gode som deres træningsdata og kan også fange uønskede fordomme. Mens der er værktøjer, der kan hjælpe med at forstå, om sådanne fordomme eksisterer, skelner de ikke mellem korrelation og årsagssammenhæng, og de kan være dårligt egnede til tekstbaserede modeller og til at ræsonnere om sprogbegreber på højt niveau. Et centralt problem ved vurderingen af årsagseffekten af et interessekoncept på en given model er, at dette skøn kræver generering af kontrafaktiske eksempler, hvilket er en udfordring med eksisterende produktionsteknologi. For at bygge bro over denne kløft foreslår vi CausaLM, en ramme for fremstilling af årsagsmodelforklaringer ved hjælp af kontrafaktiske sprogrepræsentationsmodeller. Vores tilgang er baseret på finjustering af dybe kontekstualiserede indlejringsmodeller med hjælpeforstyrrende opgaver afledt af årsagsgrafen over problemet. Konkret viser vi, at sprogrepræsentationsmodeller som BERT effektivt kan lære en kontrafaktisk repræsentation af et givet interessekoncept ved omhyggeligt at vælge hjælpeopgaver til adversielle forberedelsesopgaver og bruges til at vurdere dens sande årsagsvirkning på modellens præstation. Et biprodukt af vores metode er en sprogrepræsentationsmodel, der ikke påvirkes af det testede koncept, hvilket kan være nyttigt til at afbøde uønskede bias indgroet i dataene. 1', 'hr': 'Apstraktivno razumijevanje predviđanja dubokih neuronskih mreža je poznato teško, ali također je ključno za njihovu rasprostranost. Kao i svi metodi na osnovu učenja strojeva, oni su dobri kao i podaci o obuci, te mogu također uhvatiti nepotrebne predrasude. Iako postoje alati koji mogu pomoći razumjeti postoje li takve predrasude, ne razlikuju se između korelacije i uzrokovanja, te mogu biti loše odgovarajući za modele na tekstu i razumjeti o konceptima jezika na visokoj razini. Ključni problem procjene uzročnog učinka koncepta interesa na određeni model je da ova procjena zahtijeva generaciju lažnih primjera, koji je izazovan sa postojećim tehnologijom generacije. Da bismo predložili taj praznik, predlažemo CausaLM, okvir za proizvodnju uzročnih model a objašnjenja koristeći lažne modele predstavljanja jezika. Naš pristup je temeljen na finom prilagodbi dubokih kontekstualiziranih modela ugrađenih s pomoćnim neprijateljskim zadatkama iz uzrokovanog grafika problema. Konačno, pokazujemo da pažljivo izabereći pomoćne adversarne zadatke prije obuke, modeli predstavljanja jezika poput BERT mogu učiti lažno faktičnu predstavu određenog koncepta interesa i koristiti se za procjenu njegovog pravog uzrokovanog učinka na provedbu model a. Pojavljeni proizvod naše metode je model zastupanja jezika koji ne utječe na testirani koncept, koji može biti korisan u smanjenju neželjene pristrasnosti ugrizane u podacima. 1', 'nl': 'Abstract Het begrijpen van voorspellingen gemaakt door diepe neurale netwerken is notorisch moeilijk, maar ook cruciaal voor hun verspreiding. Zoals alle op machine learning gebaseerde methoden zijn ze net zo goed als hun trainingsgegevens en kunnen ze ook ongewenste vooroordelen vastleggen. Hoewel er tools zijn die kunnen helpen begrijpen of dergelijke vooroordelen bestaan, maken ze geen onderscheid tussen correlatie en causatie, en kunnen ze slecht geschikt zijn voor tekstgebaseerde modellen en voor redenering over taalconcepten op hoog niveau. Een belangrijk probleem bij het inschatten van het causale effect van een concept of interest op een bepaald model is dat deze schatting het genereren van contrafactische voorbeelden vereist, wat uitdagend is met bestaande generatietechnologie. Om die kloof te overbruggen, stellen we CausaLM voor, een raamwerk voor het produceren van causale modellverklaringen met behulp van contrafactische taalrepresentatiemodellen. Onze aanpak is gebaseerd op fine-tuning van diepe contextualiseerde embedding modellen met bijkomende tegenstrijdige taken afgeleid van de causale grafiek van het probleem. Concreet laten we zien dat taalrepresentatiemodellen zoals BERT, door zorgvuldig te kiezen voor ondersteunende adversaire pre-training taken, effectief een contrafactische representatie kunnen leren voor een bepaald concept van interesse, en kunnen worden gebruikt om het werkelijke causale effect ervan op de prestaties van het model te schatten. Een bijproduct van onze methode is een taalrepresentatiemodel dat niet wordt beïnvloed door het geteste concept, wat nuttig kan zijn bij het verminderen van ongewenste bias in de gegevens. 1', 'de': 'Das Verständnis von Vorhersagen tiefer neuronaler Netze ist notorisch schwierig, aber auch entscheidend für ihre Verbreitung. Wie alle auf maschinellem Lernen basierenden Methoden sind sie so gut wie ihre Trainingsdaten und können auch unerwünschte Vorurteile erfassen. Es gibt zwar Werkzeuge, die helfen können, zu verstehen, ob solche Verzerrungen existieren, aber sie unterscheiden nicht zwischen Korrelation und Kausalität und sind möglicherweise nicht geeignet für textbasierte Modelle und für die Argumentation über hochrangige Sprachkonzepte. Ein zentrales Problem bei der Abschätzung des kausalen Effekts eines Interessenskonzeptes auf ein gegebenes Modell besteht darin, dass diese Schätzung die Generierung kontrafaktischer Beispiele erfordert, was mit der bestehenden Erzeugungstechnologie eine Herausforderung darstellt. Um diese Lücke zu überbrücken, schlagen wir CausaLM vor, ein Framework zur Erzeugung kausaler Modellerklärungen unter Verwendung kontrafaktischer Sprachrepräsentationsmodelle. Unser Ansatz basiert auf der Feinabstimmung von tief kontextualisierten Einbettungsmodellen mit Hilfsaufgaben, die aus dem kausalen Graphen des Problems abgeleitet werden. Konkret zeigen wir, dass Sprachrepräsentationsmodelle wie BERT durch die sorgfältige Auswahl von Hilfsaufgaben im adversarialen Vortraining effektiv eine kontrafaktische Repräsentation für ein bestimmtes Interessenskonzept erlernen und deren tatsächliche kausale Wirkung auf die Modellleistung abschätzen können. Ein Nebenprodukt unserer Methode ist ein Sprachrepräsentationsmodell, das vom getesteten Konzept nicht beeinflusst wird, was nützlich sein kann, um unerwünschte Verzerrungen in den Daten abzumildern. 1', 'fa': 'پیش\u200cبینی\u200cهای مطلق درک کردن که توسط شبکه\u200cهای عصبی عمیق ساخته شده\u200cاند خیلی سخت است، ولی همچنین برای پراکنده\u200cشان مهم است. همانطور که همه روش\u200cهای یادگیری بر اساس ماشین، آنها به اندازه داده\u200cهای آموزش خود خوب هستند، و می\u200cتوانند همچنین روش\u200cهای ناخواسته را بگیرند. در حالی که ابزارهای وجود دارند که می توانند کمک کنند بفهمند که آیا این فرضیه وجود دارند، آنها بین ارتباط و دلایل تفاوت نمی کنند، و ممکن است برای مدل\u200cهای متن و مفهوم\u200cهای زبان\u200cهای بالا متناسب باشند. مشکل کلیدی برای ارزیابی اثر باعث دلیل یک مفهوم علاقه بر یک مدل داده این است که این ارزیابی نیاز به نسل مثالهای دروغگویی است که با تکنولوژی نسل موجود مشکل دارد. برای پول این فاصله، ما به CausaLM پیشنهاد می\u200cکنیم، یک چهارچوب برای توضیح\u200cهای مدل\u200cهای سبک با استفاده از مدل\u200cهای نمایش\u200cدهنده\u200cی زبان\u200cهای مخالف. دستور ما بر اساس تنظیم کردن مدل\u200cهای عمیق در موقعیت\u200cهایی که با وظیفه\u200cهای دشمنی کمک\u200cکننده\u200cای از گراف دلیل مشکل می\u200cگیرند، پایه\u200cای است. دقیقاً ما نشان می دهیم که با دقت انتخاب کار های مخالفت پیش آموزش، مدلهای نمایش زبانی مثل BERT می تواند به طور تاثیر نمایش حقیقی را برای یک مفهوم علاقه داده یاد بگیرد، و برای ارزیابی اثر واقعی دلیل خود را بر انجام مدل استفاده می شود. یک تولید سایر روش ما یک مدل نمایش زبانی است که توسط مفهوم آزمایش تأثیر داده نشده است، که می تواند در کمینگی از نحوه\u200cهای ناخواسته در داده\u200cها مفید باشد. ۱', 'sw': 'Tabiri za kuelewa vizuri zilizotengenezwa na mitandao ya ndani ya ubongo ni vigumu sana, lakini pia ni muhimu kwa kusambaza kwao. Kama njia zote za kujifunza kwa msingi, ni vizuri kama taarifa za mafunzo, na pia wanaweza kuchukua upendeleo usiotarajiwa. Wakati kuna vifaa ambavyo vinaweza kusaidia kuelewa kama upendeleo huu unakuwepo, hawatofauti kati ya uhusiano na sababu, na wanaweza kuwa vibaya kwa mifano ya maandishi na kwa kujadili kuhusu dhana za lugha ya juu. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology.  Ili kuunganisha mpango huo, tunapendekeza CausaLM, mfumo wa kutengeneza maelezo yanayosababishwa kwa kutumia mifano ya uwakilishi wa lugha tofauti. Hatua yetu inatokana na misimamo ya vizuri yenye mifano yenye utaratibu mkubwa na kazi za upinzani zilizotokana na matokeo ya tatizo. Bila shaka, tunaonyesha kwamba kwa kuchagua kazi za upinzani wa mafunzo ya kabla ya kujifunza kwa makini, mifano ya uwakilishi wa lugha kama vile BERT inaweza kujifunza uwakilishi wa moja kwa moja kwa dhana inayopewa ya maslahi, na inatumika kuchagua madhara yake ya kweli kwa ufanisi wa model. Utengenezaji wa njia yetu ni muundo wa uwakilizaji wa lugha ambao hauathiriki na dhana ya jaribio, ambayo inaweza kuwa na manufaa katika kupunguza upendeleo usiotarajiwa kuwekwa kwenye taarifa. 1', 'af': "Abstrakte verstaan voorskoude wat deur diep neuralnetwerke gemaak is, is nooit moeilik, maar ook cruciaal vir hulle verspreiding. Soos alle masjien leer-gebaseerde metodes, is hulle so goed as hul onderwerp data, en kan ook onverwagte voorwerp aanvang. Alhoewel daar is nutsprogramme wat kan help verstaan of sodanige voorspoedies bestaan, het hulle nie tussen korrelasie en veroorspoediging verskillig nie, en dalk is sleg geskik vir teksbaseerde modele en vir redering oor hoë vlak taal konsepte. 'n Sleutel probleem om die oorsaaklike effek van 'n konsepte van belang op 'n gegewe model te estimeer is dat hierdie estimeering benodig die generasie van vilkfeilike voorbeelde, wat is vanskerp met bestaande generasie teknologie. Om daardie gap te brei, voorstel ons CausaLM, 'n raamwerk vir die produksie van oorsaaklike modelle uitduidelings met die gebruik van teen-feilike taal verteenwoordigheidmodele. Ons toegang is gebaseer op fyn-tuning van diep kontekstualiseerde inbêde modele met hulpbrukbare teenstandaaries opdragte wat van die oorsaaklike graaf van die probleem afgelei is. Ons wys daarvan dat deur versigtig te kies hulpbrekende teenstandaaries voor-onderwerp opdragte, taal-voorstellingsmodele soos BERT kan effektief 'n teenwerklike voorstelling leer vir 'n gegewe konsepte van belang, en gebruik word om sy waarde oorsaaklike effekte op model prestasie te vure. 'n Byprodukt van ons metode is 'n taal voorstelling model wat nie deur die testeerde konsepte geïffekteer word nie, wat kan bruikbaar wees in die gemeindiging van onvolgende bias wat in die data ingegrawe is nie. 1", 'ko': '심층신경망의 예측을 이해하는 것은 어렵지만 그 전파도 중요하다는 것은 잘 알려져 있다.기계 학습을 기반으로 하는 모든 방법과 마찬가지로 훈련 데이터와 마찬가지로 좋고 불필요한 편차를 포착할 수 있다.일부 도구는 이러한 편견이 존재하는지 이해하는 데 도움을 줄 수 있지만 관련성과 인과관계를 구분하지 않기 때문에 텍스트를 바탕으로 하는 모델과 고급 언어 개념에 대한 추리에 적합하지 않을 수 있다.취미 개념이 주어진 모델의 인과에 미치는 영향을 평가하는 관건적인 문제는 이런 평가는 반사실적인 예를 만들어야 한다는 것이다. 이것은 기존의 생성 기술에 있어 도전이다.이 차이를 보완하기 위해 우리는 카사LM을 제기했는데 이것은 반사실적 언어 표현 모델을 사용하여 인과모델 해석을 생성하는 틀이다.우리의 방법은 심층 상황화 삽입 모델에 대한 미세한 조정과 문제 인과도에서 파생된 보조 대항적 임무를 바탕으로 한다.구체적으로 말하면 보조 대항성 훈련 전 임무를 꼼꼼히 선택함으로써 언어표징모델(예를 들어 버트)은 관심 개념에 대한 반사실표징을 효과적으로 학습하고 모델 성능에 대한 진정한 인과적 영향을 평가하는 데 사용될 수 있음을 나타낸다.우리의 방법의 부산물 중 하나는 테스트 개념의 영향을 받지 않는 언어 표시 모델로 데이터의 뿌리 깊은 불필요한 편견을 줄이는 데 도움이 된다.1', 'id': 'Pemahaman Abstrakt prediksi yang dibuat oleh jaringan saraf dalam sangat sulit, tapi juga penting untuk penyebaran mereka. Sebagai semua metode pembelajaran berbasis mesin, mereka sama baik dengan data pelatihan mereka, dan juga dapat menangkap biases yang tidak diinginkan. Meskipun ada alat yang dapat membantu memahami apakah biases tersebut ada, mereka tidak membedakan antara korelasi dan penyebab, dan mungkin tidak cocok untuk model berdasarkan teks dan untuk alasan tentang konsep bahasa tinggi. Sebuah masalah kunci untuk memperkirakan efek penyebab konsep kepentingan pada model tertentu adalah bahwa penilaian ini memerlukan generasi controfaksi controfaksi, yang menantang dengan teknologi generasi yang ada. Untuk memecahkan ruang tersebut, kami mengusulkan CausaLM, sebuah rangkaian untuk memproduksi penjelasan model penyebab menggunakan model representation bahasa kontrafaktual. pendekatan kita berdasarkan penyesuaian model embedding kontekstualisasi dalam dengan tugas bantuan musuh yang berasal dari grafik penyebab masalah. Secara konkret, kami menunjukkan bahwa dengan hati-hati memilih tugas bantuan musuh pra-pelatihan, model perwakilan bahasa seperti BERT dapat secara efektif belajar perwakilan kontrofaksi untuk konsep tertentu kepentingan, dan digunakan untuk memperkirakan efek penyebabnya pada prestasi model. Sebuah produk sampingan dari metode kita adalah model representation bahasa yang tidak terpengaruh oleh konsep yang diuji, yang dapat berguna untuk mengurangi bias yang tidak diinginkan terlibat dalam data. 1', 'am': 'የጥልቅ የደዌብ መረብ የተደረገውን ትንቢት ማስተዋል ግን በማፍረሳቸው ላይ አስቸጋሪ ነው፡፡ መሣሪያዎች ሁሉ እንደተማርኩ ሥርዓቶች፣ እንደ ማስተማርናቸው ዳታዎች መልካም ናቸው፣ ያልተፈቀደውንም ድጋፍ ይያዛሉ፡፡ ምንም እንኳን እንደነዚህ ልዩ ልውስና ቢኖር የሚያስተውሉ መሣሪያዎች ቢኖሩ፣ ግንኙነት እና ጉዳይ መካከል አይለዩም፣ የጽሑፍ ምሳሌዎች እና ከፍተኛ ቋንቋ ምሳሌዎች ማሰናከል አይጠቅሙም፡፡ የውጤት አካባቢ ጥያቄን በመቆጣጠር የጠቅላላ ጉዳይ ነው፡፡ ይህንን ክፍል ለመቀላቀል፣ CausaLM፣ የውይይት ዓይነት የቋንቋ መልዕክት ምሳሌዎችን ለመፍጠር የፍሬም ትርጉም እናደርጋለን፡፡ የችግረታችን ጥልቅ የውይይት ተቃውሞ በተቃዋሚ ስራዎችን በመሠረት ነው፡፡ እርግጠኛ፣ በጥንቃቄ አስቀድሞ ትምህርት አድራጊዎችን በመመርጥ፣ እንደBERT የሚመስሉ የቋንቋ መልዕክት ምሳሌዎች በተስፋው ውጤት ለጥያቄ ጥያቄ ለመማር ይችላል፡፡ የሥርዓታችን ብጤት የቋንቋ መልዕክት ምሳሌ ነው፤ በተፈተናው አእምሮው ያልተገኘ ነው፤ ከዳራዎች ውስጥ የተዘጋጀውን ፍላጎት በመጠቀም ይጠቅማል፡፡ 1', 'az': 'Nəyral ağları tarafından yapılmış abstraktik anlama tədbirləri çox çətin deyildir, lakin onların yayılması üçün də çox möcüzdür. Bütün makinelərin öyrənməsi tərzlərinə görə, onlar təhsil məlumatları kimi yaxşı və istəməyən tərzlərini də yakalaya bilərlər. Bütün bu tərzlərin olmadığını anlamağa kömək edə bilən vasitələr varsa da, onlar bağlılıq və səbəb arasında fərqlənməzlər və metin-tabanlı modellərə və yüksək səbəb dil fikirləri haqqında mübahisə edə bilərlər. Verilən modellərdə maraqlıq təsirinin nəticəsini hesablamaq üçün ən çox problemi var ki, bu hesablama, həmin nəsil teknolojisi ilə çətin olanların nəsillərinin nəsillərini lazım edir. Bu boşluğu körpüşdürmək üçün CausaLM\'i təbliğ edirik, çünki həqiqətən dil göstəricisi modellərini istifadə edərək causal modellər təbliğ etmək üçün. Bizim yaxınlığımız problemin sebebi grafından gələn müdafiə edən çətin müxtəlif modellərin düzəltməsinə dayanılır. Beləliklə, biz göstərdik ki, BERT kimi dil göstəricisi modelləri təhsil edilən təhsil müəyyən edilməsi üçün çox təsirli təhsil seçərək və modeli təhsil etkisini təmin etmək üçün istifadə edilir. Bizim metodumuzun uyğunluğu sınağa çəkilməmiş bir dil göstəricisi modeli idi. Bu, məlumatlarda sınağa çəkilməyən təsirləri azaltmaq üçün faydalı olar. 1" (msgctxt: "panel:showusername") to "1', 'bn': 'গভীর নিউরেল নেটওয়ার্ক দ্বারা যে ভবিষ্যদ্বাণী বুঝতে পারে তা খুব কঠিন, কিন্তু তাদের প্রচারণার জন্য গুরুত্বপূ সব মেশিন ভিত্তিক পদ্ধতি হিসেবে তারা তাদের প্রশিক্ষণের তথ্যের মতো ভালো এবং তারা অসন্তুষ্ট বিভেদের ধরে নিতে পার যেখানে কিছু টুল আছে যা বুঝতে পারে যে এই ধরনের বৈষম্য আছে কি না, তারা সংশ্লিষ্ট এবং কারণের মধ্যে আলাদা করে না, এবং লেখা ভিত্তিক মডেলের জন্য অনুমোদন করে এবং উচ্ একটি মডেলের প্রতি আগ্রহের কারণের প্রভাব হিসেবে হিসেব করার একটি গুরুত্বপূর্ণ সমস্যা হচ্ছে এই হিসাবের প্রয়োজন হচ্ছে প্রজন্মের প্রযুক্তির প্রয এই বিভ্রান্ত ব্রিজ করার জন্য আমরা কাউসালএমকে প্রস্তাব করি যে কারণের মডেল তৈরি করার জন্য একটি ফ্রেক্রেক্কারের প্রস্তাব করেছি  আমাদের প্রতিযোগিতা ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিতে রয়েছে যা সমস্যার কারণের গ্রাফ থেকে প্রাপ্ত বিরোধী কাজের সা নিশ্চিতভাবে আমরা দেখাচ্ছি যে পূর্ব প্রশিক্ষণের বিরোধী বিরোধী কাজ নির্বাচন করে ভাষার প্রতিনিধিত্ব মডেল, যেমন বিআরটি-এর মতো কার্যকর ভাষার প্রতিনিধিত্ব শিখতে পারে একটি প আমাদের পদ্ধতির একটি বাই পণ্য হচ্ছে ভাষার প্রতিনিধিত্ব মডেল যা পরীক্ষা করা ধারণা দ্বারা প্রভাবিত নয়, যা তথ্যে উৎপাদন করা অসন্তুষ্ট বিয়ার 1', 'bs': 'Apstraktivno razumijevanje predviđanja koje su napravljene dubokim nervnim mrežama je poznato teško, ali također je ključno za njihovu disseminaciju. Kao i svi metodi na osnovu učenja strojeva, oni su dobri kao i podaci o obuci, i mogu također uhvatiti neželjene predrasude. Iako postoje alati koji mogu pomoći da shvate postoje li takve predrasude, ne razlikuju se između korelacije i uzrokovanja, i mogu biti loše odgovarajući za modele na tekstu i za razmišljanje o konceptima jezika na visokom nivou. Ključni problem procjene uzročnog učinka koncepta interesa na određeni model je da ova procjena zahtijeva generaciju lažnih primjera, koji je izazovan sa postojećom tehnologijom generacije. Da bismo predložili taj praznik, predlažemo CausaLM, okvir za proizvodnju uzročnih model a objašnjenja koristeći lažne modele predstavljanja jezika. Naš pristup je baziran na finom prilagodbi dubokih kontekstualiziranih modela ugrađenih s pomoćnim neprijateljskim zadacima iz uzrokovanog grafika problema. Konačno, pokazujemo da pažljivo izabereći pomoćne neprijateljske zadatke prije obuke, modeli predstavljanja jezika poput BERT mogu učiti lažno faktičnu predstavu za određeni koncept interesa i koristiti se za procjenu njegovog pravog uzrokovanog učinka na provedbu model a. Povratni proizvod naše metode je model predstavljanja jezika koji ne utječe na testovani koncept, koji može biti korisan u smanjenju neželjene pristrasnosti ugrizane u podacima. 1', 'hy': 'Աբստրակտ հասկանալը խորը նյարդային ցանցերի կողմից արված կանխատեսումները հայտնի է, բայց նաև կարևոր է նրանց տարածման համար: Ինչպես բոլոր մեքենայի ուսուցման հիմնված մեթոդները, դրանք նույնքան լավ են, ինչքան իրենց ուսուցման տվյալները, և կարող են նաև ընկալել անցանկանալի կողմնականություններ: Մինչդեռ կան գործիքներ, որոնք կարող են օգնել հասկանալ, թե արդյոք այդպիսի կողմնականություններ գոյություն ունեն, դրանք չեն տարբերակում հարաբերակցության և պատճառի միջև, և կարող են չհամապատասխանել տեքստի հիմնված մոդելներին և բարձր մակարդակի լեզվի գաղափա A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology.  Այս տարբերությունը հաղթահարելու համար մենք առաջարկում ենք "Կոսալ Մ"-ը, պատճառական մոդելի բացատրություններ ստեղծելու հիմք, օգտագործելով հակափաստական լեզվի ներկայացման մոդելներ: Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem.  Իրականում, մենք ցույց ենք տալիս, որ ուշադիր ընտրելով օգնական հակառակորդական նախավարժական գործերը, լեզվի ներկայացման մոդելները, ինչպիսիք են BER-ը, կարող են արդյունավետ սովորել հակափաստական ներկայացումը որոշ հետաքրքրության գաղափարների համար և օգտագործվել մոդելի արտադրողության վրա դրված իրական պատճառի Մեր մեթոդի կողմնակի արդյունքը լեզվի ներկայացման մոդել է, որը չի ազդում փորձարկված գաղափարի վրա, ինչը կարող է օգտակար լինել անցանկալի կողմնականության նվազեցնելիս, որը ներառված է տվյալներում: 1', 'cs': 'Porozumění predikcím hlubokých neuronových sítí je notoricky obtížné, ale také klíčové pro jejich šíření. Stejně jako všechny metody založené na strojovém učení jsou stejně dobré jako jejich tréninková data a mohou také zachytit nežádoucí zaujatosti. I když existují nástroje, které mohou pomoci pochopit, zda takové předsudky existují, nerozlišují mezi korelací a příčinou souvislostí a mohou být nevhodné pro textové modely a pro uvažování o jazykových konceptech na vysoké úrovni. Klíčovým problémem odhadu příčinného účinku konceptu zájmu na daný model je, že tento odhad vyžaduje generování kontrafactických příkladů, což je u stávající generační technologie náročné. Abychom tuto mezeru překlenuli, navrhujeme CausaLM, rámec pro tvorbu vysvětlení kauzálních modelů pomocí kontrafaktuálních jazykových reprezentačních modelů. Náš přístup je založen na jemném ladění hlubokých kontextualizovaných modelů vkládání s pomocnými adversariálními úlohami odvozenými z kauzálního grafu problému. Konkrétně ukazujeme, že pečlivým výběrem pomocných adversariálních předškolicích úkolů se modely jazykové reprezentace, jako je BERT, mohou efektivně naučit kontrafactickou reprezentaci pro daný koncept zájmu a být použity k odhadu jejího skutečného příčinného vlivu na výkonnost modelu. Vedlejším produktem naší metody je model jazykové reprezentace, který není ovlivněn testovaným konceptem, což může být užitečné při zmírňování nežádoucích zaujatostí zakořeněných v datech. 1', 'et': 'Sügavate närvivõrkude prognooside mõistmine on tuntud raske, kuid ka nende leviku seisukohalt oluline. Nagu kõik masinõppel põhinevad meetodid, on need sama head kui nende koolitusandmed ja võivad jäädvustada ka soovimatuid kallakusi. Kuigi on olemas vahendeid, mis aitavad mõista, kas sellised eelarvamused eksisteerivad, ei erista need korrelatsiooni ja põhjuslikku seost ning võivad olla ebasobivad tekstipõhiste mudelite ja kõrgetasemeliste keelekontseptsioonide arutlemiseks. Põhiprobleem huvikontseptsiooni põhjusliku mõju hindamisel konkreetsele mudelile on see, et see hinnang nõuab vastufaktuaalsete näidete loomist, mis on olemasoleva tootmistehnoloogia puhul keeruline. Selle lõhe ületamiseks pakume välja CausaLM, raamistiku põhjuslike mudelite selgituste tootmiseks, kasutades vastufaktuaalseid keeleesitusmudeleid. Meie lähenemisviis põhineb sügavate kontekstualiseeritud manustamismudelite täpsustamisel koos abiülesannetega, mis tulenevad probleemi põhjuslikust graafikust. Konkreetselt näitame, et ettevaatlikult valides konkurentsieelseid lisaülesandeid, võivad keeleesindusmudelid, nagu BERT, tõhusalt õppida konkreetse huvikontseptsiooni vastufaktuaalset esindust ning neid kasutada selle tõelise põhjusliku mõju hindamiseks mudeli jõudlusele. Meie meetodi kõrvalsaaduseks on keeleesituse mudel, mida testitud kontseptsioon ei mõjuta, mis võib olla kasulik andmetesse juurdunud soovimatute eelarvamuste leevendamisel. 1', 'tr': "Ger챌ek neural 힊ebekelerinden eden abstrakt d체힊체nme 철흫체nleri hi챌 hili kyn d채ldir, 첵철ne olary흫 a챌ylygyna 철r채n m철h체m. Hemme ma힊yny흫 철wrenmegi ta첵첵arlanan y철ntemleri 첵aly, olar 철z okuw챌ylary maglumatlary 첵aly gowy we isleme첵채n biasleri hem 챌ekip bilerler. 횦철ne 힊ol 첵erleri d체힊체nmek 체챌in k철mek edip biljek esbaplar bar. Olar correlisi첵a we seb채bi arasynda tapawutlanma첵ar we metin tabanly nusgalar 체챌in 첵al흫y힊 d채l we 첵okary derejesi barada d체힊체nmek 체챌in. Berilen nusga 체챌in gyzyklan첵an d체힊체njelerini흫 seb채bi hasaplamak kyn챌ylykly mesele bolup bu hasaplamak 체챌in hasaplany힊y흫 d철wletlerini흫 d철wletlerini gerek bolar. Bu bo힊luky k철plitmek 체챌in CausaLM'i, seb채bi 철r채n nusgalary 체챌in fa첵ly dil t채sirleme modellerini ulanan bir 챌er챌eve teklif edip g철r첵채ris. Bizi흫 첵ary힊ymyz derin contextualizal첵an da힊ary nusgalary mesel채흫 seb채bi grafisinden 챌ykan k철mek eden nusgalarymyz 체챌in fin d체zenlemelidir. Munu흫 체챌in, biz BERT 첵aly s철zleri n채hili gyzyklandyrmak 체챌in k철meklik t채siri 철n-bilim t채sirlerini gowy g철rke첵채n 힊eklinde g철rke첵채ris we muny흫 dogry seb채bi t채sirini nusgamak 체챌in ullan첵ar. Bizi흫 첵체regimizi흫 byprodukty - test edilen d체힊체nj체mizden etm채n dil temsilleme nusgasy. Bu data i챌inde isleme첵채n biasleri azaltmak 체챌in kyn챌ylykly bolar. 1", 'fi': 'Syvien hermoverkkojen ennusteiden ymmärtäminen on tunnetusti vaikeaa, mutta myös ratkaisevaa niiden leviämisen kannalta. Kuten kaikki koneoppimiseen perustuvat menetelmät, ne ovat yhtä hyviä kuin niiden harjoitustiedot, ja voivat myös tallentaa ei-toivottuja ennakkoluuloja. Vaikka on olemassa työkaluja, jotka voivat auttaa ymmärtämään, onko tällaisia ennakkoluuloja olemassa, ne eivät erota korrelaatiota ja syy-yhteyttä, ja ne saattavat olla sopimattomia tekstipohjaisiin malleihin ja korkean tason kielikäsitteiden päättelyyn. Keskeinen ongelma kiinnostuksen käsitteen syy-seurauksen arvioimisessa tiettyyn malliin on se, että tämä arvio edellyttää vastakohtaisten esimerkkien luomista, mikä on haastavaa olemassa olevalla tuotantotekniikalla. Tämän aukon korjaamiseksi ehdotamme CausaLM:tä, viitekehystä kausaalisten mallien selitysten tuottamiseen kontrafaktuaalisilla kieliesitysmalleilla. Lähestymistapamme perustuu syvällisten kontekstualisoitujen upotusmallien hienosäätöön ongelman syy-kaaviosta johdetuilla lisäkontekstuaalisilla tehtävillä. Konkreettisesti osoitamme, että BERT:n kaltaiset kieliedustusmallit voivat huolellisesti valita kontradiktorisia esikoulutustehtäviä ja oppia tehokkaasti vastakohtaisen edustuksen tietylle kiinnostuksen käsitteelle ja arvioida sen todellista kausaalista vaikutusta mallin suorituskykyyn. Menetelmämme sivutuote on kieliesitysmalli, johon testattu konsepti ei vaikuta, ja se voi olla hyödyllinen aineistoon juurtuneiden ei-toivottujen ennakkoluulojen lieventämisessä. 1', 'ca': "La comprensió abstracta de les prediccions fetes per les xarxes neuronals profundes és notoriament difícil, però també crucial per a la seva disseminació. Com tots els mètodes basats en l'aprenentatge màquinari, són tan bons com les seves dades d'entrenament, i també poden capturar biases no desitjats. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts.  A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology.  Per superar aquest buit, proposem CausaLM, un marc per a produir explicacions de model causal utilitzant models de representació de llenguatges contrafets. El nostre enfocament es basa en ajustar els models d'incorporació contextualitzats profunds amb tasques adversaries auxiliars derivades del gràfic causal del problema. Concretament, demostram que seleccionant cuidadosament tasques adversaries auxiliars de pré-entrenament, models de representació lingüística com BERT poden aprendre efectivament una representació contrafeta d'un concepte d'interès determinat i ser utilitzats per estimar el seu efecte real causal en el rendiment del model. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data. 1", 'sq': 'Abstract Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination.  As all machine learning-based methods, they are as good as their training data, and can also capture unwanted biases.  While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts.  A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology.  Për të mbushur këtë boshllëk, ne propozojmë CausaLM, një kuadër për prodhimin e shpjegimeve të modelit shkak duke përdorur modele të përfaqësimit të gjuhës kundërfaktore. Përqasja jonë është e bazuar në rregullimin e modeleve të thella kontekstualizuar të përfshirjes me detyra ndihmëse kundërshtare të nxjerra nga grafiku shkak i problemit. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance.  Një subprodukt i metodës sonë është një model përfaqësimi gjuhësor i cili nuk është i prekur nga koncepti i testuar, i cili mund të jetë i dobishëm në lehtësimin e paragjykimit të padëshiruar të përfshirë në të dhënat. 1', 'sk': 'Razumevanje napovedi globokih nevronskih omrežij je znano težko, vendar je ključnega pomena tudi za njihovo razširjanje. Kot vse metode, ki temeljijo na strojnem učenju, so enako dobre kot njihovi podatki o usposabljanju in lahko zajamejo tudi neželene pristranskosti. Medtem ko obstajajo orodja, ki lahko pomagajo razumeti, ali takšne pristranskosti obstajajo, pa ne razlikujejo med korelacijo in vzročno zvezo in so morda neustrezna za besedilne modele in razmišljanje o jezikovnih konceptih na visoki ravni. Ključni problem ocenjevanja vzročnega učinka koncepta zanimanja na določen model je, da ta ocena zahteva ustvarjanje kontrafaktualnih primerov, kar je izziv pri obstoječi generacijski tehnologiji. Za premostitev te vrzeli predlagamo CausaLM, okvir za izdelavo razlag vzročnega modela z uporabo kontrafaktualnih jezikovnih reprezentacijskih modelov. Naš pristop temelji na finem nastavitvi globoko kontekstualiziranih modelov vgradnje s pomožnimi kontekstualnimi nalogami, izpeljanimi iz vzročnega grafa problema. Konkretno pokažemo, da se lahko s skrbno izbiro pomožnih kontradiktorskih nalog pred usposabljanjem modeli jezikovne reprezentacije, kot je BERT, učinkovito naučijo kontradiktorske reprezentacije za določen koncept interesa in se uporabljajo za oceno njegovega resničnega vzročnega učinka na uspešnost modela. Stranski produkt naše metode je jezikovni model reprezentacije, na katerega testirani koncept ne vpliva, kar je lahko koristno pri ublažitvi neželenih pristranskosti, vgrajenih v podatke. 1', 'jv': 'Awak dhéwé Tambah kabeh kelas sistem sing basa-sistem, dadi iki luwih apik lan data takar-takar, lan iso nggawe biasa layang-layang. Sing sing ono alat sing bisa ngrembug nungse kapan biasane iki, dhewe ora bisa ngrebut waenganggo perusahaan karo perusahaan lan kelangan, lan supoyo iso dianggap kanggo model sing basa teks lan ngregani uwong sing bisa teka luwih dumadhi kapan kelangan langkung sampek luwih. Mbok Asmaci bener Mbok kuwi nggawe gap kuwi, kita ngomong gunakake CausaLM, akeh dumadhi kanggo ngilangno sistem anyar modèl pakan Njaring Saiki, kéné iso nglanggar nganggep nglanggar kelangan langgar-nglanggar tasks wis nguasai, iso nggambar tarjamahan kanggo BERT iso nggambar cara nggawe barang kelangan kanggo ngerasai winih dhéwé, lan iso nggunakake sing berarti iso nggawe barang pengguna emperara awak dhéwé. Nalika penting dhéwé kuwi model sing perusahaan anyar tentang gak nggawe gerakan oleh tentang, iki iso nggawe barang nggawe bias sing bisa nggawe data. 1', 'he': 'ההבנה המוחלטת צפויות שעשויות על ידי רשתות עצביות עמוקות היא קשה במידע ידוע, אבל גם קריטית להפיצה שלהם. ככל שיטות למידה המכונית, הן טובות כמו נתוני האימונים שלהן, וגם יכולות לתפוס תמונות בלתי רצויות. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts.  בעיה מפתחת של הערכה של השפעה הסיבית של מושג של עניין על מודל מסוים היא שההערכה הזו דורשת את הדור של דוגמאות נגד עובדות, אשר מאתגר עם טכנולוגיה של דור קיימת. כדי לשבור את הפער הזה, אנו מציעים CausaLM, מסגרת לייצור הסברים דוגמני סיבה בשימוש דוגמני מייצג שפה נגד עובדות. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem.  במיוחד, אנו מראים שבבחירה בזהירות משימות נוגדיות נוגדיות לפני האימון, מודלים מייצג שפת כמו BERT יכולים ללמוד באופן יעיל מייצג נגד עובדות עבור מושג מסוים של עניין, ולהשתמש כדי להעריך את השפעה הסיבית האמיתית שלו על ביצוע מודל. תוצר הלוואי של השיטה שלנו הוא דוגמא מייצג שפה שלא משפיע על ידי המושג הנבחן, שיכול להיות שימושי בהקלה של ההתמחות הלא רצויה שנמצאת במידע. 1', 'ha': "Abtract Under Abutar da aka aikata ko da mitandan neura na ƙari, yana da muhimu ga fassararsu. Kama duk shiryoyin ayuka da aka sanar da shi, sun zama mafiya alhẽri kamar data na amfani da su, kuma suna iya sami karɓi karkacin da ba'a so. Akwai da waɗansu zanen za'a iya amfani da su fahimta, ko da za'a ƙudura wannan, bã su rarraba tsakanin tsakanin tsakiya da shawara, kuma don a yiwu su daidai wa misãlai masu rubutun matsayi kuma don su yi jãyayya a kan fassaran harshen sarrafa. Wata masĩfa na ƙayyade matsayin a kan sha'anin wani zaɓen marubuci kan wata misali da aka bai wa shi, shine cewa wannan qiymani yana da muhimmin ƙiƙiro misãlai biyu masu motsi, wanda yana tsõratar da shi a kan technical mai kizata wanda ke iya gaba. Ga mu sami wannan gaura, za'a buƙata CausaLM, wani firam na samun ta samu'ar da misalin misãlai masu motsi da ke samun motsi masu motsi da baka-harshe. Mataimakinmu ne a kan samar-tunkuɗe masu cikin misalin da aka samu da taskõki masu ƙaranci daga matsayin mataimaki. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance.  Wata bazawa na hanyoyinmu shi ne misalin mai tsari da harshen wanda bai yi amfani ba da shi daga zato mai jarraba, wanda zai iya amfani da shi a cire sigarin da ba'a so da aka shigar da shi cikin data. 1", 'bo': 'ལམ་སྤྲོད་ཀྱི་གསལ་བཤད་ཀྱི་སྔོན་ཚུལ་འདྲ་རྒྱ་ལས་བཟོ་བཅོས་པ་མེད། དེ་དག་གི་གསལ་བཤད་དུ་བཅུག་པར་གལ་ཆེན་དགོས། མ་ལག་གི་ཁྱད་པར་གཞི་རྟེན་ནས་གཙོ་བྱེད་ཀྱི་ཐབས་ལམ་ལྟར། དེ་དག་ཚོ་ནི་ཁོང་ཚོའི་གཙོ་སློང་གི་ཆ་འཕྲིན་དང་། དེ་དག་གི་མཐུན་རིམ་དང་རྒྱུ་མཚན་གཉིས་ཀྱི་སྒྲིག་ཆ་ཡོད་མིན་འདུག དམིགས་འཛུགས་ཀྱི་རྐྱེན་ཚུལ་དང་འབྲེལ་བ་འདིས་དམིགས་ཡུལ་ལས་མཐུན་རྐྱེན་གྱི་དཀའ་ངལ་ཅིག་ཡིན་ན། བར་སྟོང་འདི་དག་ལྷག་སོང་དང་། ང་ཚོས་CausaLM་ལ་མཐུན་བཟོ་བྱེད་པར་མཐུན་གཞུང་ཞིག་ཡིན་པ་ལས་ རྒྱུ་མཚན་གྱི་མིང་དཔེ་གཏོང་སྟོན Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem. འུ་ཅག་གིས་གནད་དོན་གཅིག་ཁར་ལྡན་བྱེད་པའི་གྲོགས་རམ་གཟུགས་བྱ་བ་དག་གིས་གནད་དོན་གནང་བ་དང་། སྐད་ཡིག ང་ཚོའི་ཐབས་ལམ་གྱི་bay བ་བུ་ཅིག་ནི་སྐད་ཡིག་གི་འཆར་བརྟན་པའི་ཆ་ཚིག་ལས་གནོད་འགྱུར་བའི་རྣམ་པ་ཞིག་ཡིན་པས། 1'}
{'en': 'Analysis and Evaluation of Language Models for Word Sense Disambiguation', 'ar': 'تحليل وتقييم النماذج اللغوية لتوضيح معنى الكلمات', 'fr': 'Analyse et évaluation de modèles linguistiques pour la désambiguïsation des sens des mots', 'pt': 'Análise e Avaliação de Modelos de Linguagem para Desambiguação de Sentido de Palavras', 'es': 'Análisis y evaluación de modelos de lenguaje para la desambiguación del sentido de las palabras', 'ja': '単語センスの曖昧さ解消のための言語モデルの分析と評価', 'zh': '词义消歧语体析论', 'hi': 'विश्लेषण और Word भावना disambiguation के लिए भाषा मॉडल का मूल्यांकन', 'ru': 'Анализ и оценка языковых моделей для размывания смысла слова', 'ga': 'Anailís agus Measúnú ar Mhúnlaí Teanga le hAghaidh Dhíathbhrí ar Bhriathra Focal', 'ka': 'სიტყვის სიტყვის განსხვავებისთვის ენის მოდელების ანალიზაცია და განსაზღვრება', 'it': 'Analisi e valutazione dei modelli linguistici per la disambiguazione del senso di parola', 'kk': 'Сөзді сезімді өшіру үшін тіл үлгілерін анализ және бағалау', 'lt': 'Kalbos modelių, skirtų žodžių jausmui išspręsti, analizė ir vertinimas', 'mk': 'Анализа и евалуација на јазичките модели за раздвојување на зборовите', 'ms': 'Analisis dan penilaian Model Bahasa untuk Nyahambiguasi Sensa Perkataan', 'hu': 'Nyelvi modellek elemzése és értékelése a Word Sense szétbontásához', 'el': 'Ανάλυση και αξιολόγηση γλωσσικών μοντέλων για την αποσαφήνιση της λογικής λέξης', 'ml': 'വാക്കിന്റെ സെന്\u200dസ് അസംഭാഷണത്തിനുള്ള ഭാഷ മോഡലുകളുടെ അന്വേഷണവും പരിശോധിക്കുക', 'mt': 'Analiżi u Evalwazzjoni tal-Mudelli tal-Lingwa għad-Diżambigwazzjoni tas-Sens tal-Kliem', 'mn': 'Үүний мэдрэмжгүй байдлын хэл загварын шинжилгээ болон үнэлгээ', 'no': 'Analyser og evaluering av språk- modeller for utstyring av ordførsel', 'pl': 'Analiza i ocena modeli językowych dla rozjasnienia zmysłu słowa', 'ro': 'Analiza și evaluarea modelelor lingvistice pentru dezambiguizarea sensului Word', 'sr': 'Analiza i procjena jezičkih modela za disambigaciju osjećaja reči', 'si': 'විශ්ලේෂණය සඳහා භාෂා මොඩේල්ස් විශ්ලේෂණය සහ විශ්ලේෂණය', 'so': 'Analysis iyo Qiimeynta Modelooyinka Luqada', 'sv': 'Analys och utvärdering av språkmodeller för Word Sense Disambiguation', 'ta': 'வார்த்தை உணர்வு தடைப்புக்கான மொழி மாதிரிகளின் ஆராய்வு மற்றும் மதிப்பிடுதல்', 'ur': 'Word Sense Disambiguation کے لئے زبان موڈل کا تحلیل اور ارزش', 'vi': 'Kết quả phân tích ngôn ngữ cho biến mất cảm xúc từ', 'uz': 'Name', 'nl': 'Analyse en Evaluatie van Taalmodellen voor Word Sense Disambiguatie', 'da': 'Analyse og evaluering af sprogmodeller til Word Sense Disambiguation', 'bg': 'Анализ и оценка на езикови модели за разграничаване на чувството на словото', 'hr': 'Analiza i procjena jezičkih modela za disambigaciju osjećaja riječi', 'id': 'Analisi dan Evaluasi Model Bahasa untuk Pengambiguasi Sensi Perkataan', 'de': 'Analyse und Evaluation von Sprachmodellen zur Wortsinnentscheidung', 'ko': '어의 변조 언어 모델의 분석과 평가', 'fa': 'تحلیل و ارزیابی مدل زبان برای ناپدید کردن حس کلمه', 'sw': 'Anachambua na Uthibitisho wa Modeli za Lugha kwa Kupuuzwa kwa maneno', 'af': 'Analiseer en Evaluering van Taal Modelle vir WoordSense Ontbreking', 'tr': 'Sened Gaýşartmaky üçin Dil Modelleriniň Taýýarlama we Taýýarlama', 'sq': 'Analiza dhe vlerësimi i modeleve gjuhësore për zhdukjen e kuptimit të fjalëve', 'am': 'መግለጫ', 'az': '參뙺泃밠䓉饳瓉饬즙얟淉饳椠쎼쎧쎼渠䑩氠䵯摥汬즙物湩渠慮慬楺椠盉餠䕶慬畡獹潮甊', 'hy': 'Լեզվային մոդելների վերլուծությունը և գնահատումը', 'ca': 'Anàlisi i Evaluació de Models de Llingua per a desambiguar el sentit de paraules', 'bs': 'Analiza i procjena jezičkih modela za disambigaciju osjećaja riječi', 'bn': 'শব্দের সেন্স বিচ্ছিন্ন করার জন্য ভাষা মডেলের বিশ্লেষণ এবং মূল্যায়ন', 'cs': 'Analýza a hodnocení jazykových modelů pro disambiguaci slovního smyslu', 'et': 'Keelemudelite analüüs ja hindamine sõnatunde disambiguatsiooni jaoks', 'fi': 'Sanaaistin hajottamisen kielimallien analysointi ja arviointi', 'he': 'ניתוח והעריכה של דוגמני שפת עבור ניתוח משמעות מילים', 'jv': 'Ngalesi karo Validity model Language', 'sk': 'Analiza in vrednotenje jezikovnih modelov za razočaranje besednega smisla', 'ha': 'Ana yi Ana da Bayani ga Modellun Harshen wa Cire Bayanta Kalmar', 'bo': 'ཡིག་ཆ་ལྟ་བྱེད་ཀྱི་སྐད་རིགས་མ་དབྱེ་ཞིབ་དང་ཚད་ལྟར་ཞིབ་བྱེད་པ'}
{'en': 'Abstract Transformer-based language models have taken many fields in NLP by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. One of the main conclusions of our analysis is that BERT can accurately capture high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense, with minimal improvements obtained by increasing the size of this training data.', 'ar': 'لقد اتخذت النماذج اللغوية المستندة إلى المحولات العديد من المجالات في البرمجة اللغوية العصبية عن طريق العاصفة. تهيمن BERT ومشتقاته على معظم معايير التقييم الحالية ، بما في ذلك تلك الخاصة بإزالة الغموض عن Word Sense (WSD) ، وذلك بفضل قدرتها على التقاط الفروق الدلالية الحساسة للسياق. ومع ذلك ، لا يزال هناك القليل من المعرفة حول قدراتها والقيود المحتملة في ترميز واستعادة حواس الكلمات. في هذه المقالة ، نقدم تحليلًا كميًا ونوعيًا متعمقًا لنموذج BERT الشهير فيما يتعلق بالغموض المعجمي. تتمثل إحدى الاستنتاجات الرئيسية لتحليلنا في أنه يمكن لـ BERT أن تلتقط بدقة تمييزات ذات مستوى عالٍ من الإحساس ، حتى عندما يتوفر عدد محدود من الأمثلة لكل معنى كلمة. يكشف تحليلنا أيضًا أنه في بعض الحالات ، تقترب نماذج اللغة من حل مشكلة إزالة غموض الأسماء في ظل ظروف مثالية من حيث توافر بيانات التدريب وموارد الحوسبة. ومع ذلك ، نادرًا ما يحدث هذا السيناريو في ظروف العالم الحقيقي ، وبالتالي ، لا تزال هناك العديد من التحديات العملية حتى في الأماكن الخشنة. نقوم أيضًا بإجراء مقارنة متعمقة بين إستراتيجيات WSD القائمة على نموذج لغتين رئيسيتين ، وهما الضبط الدقيق واستخراج الميزات ، ووجدنا أن النهج الأخير أكثر قوة فيما يتعلق بتحيز الحس ويمكنه استغلال بيانات التدريب المحدودة المتاحة بشكل أفضل . في الواقع ، أثبتت استراتيجية الاستخراج البسيطة المتمثلة في حساب متوسط الزخارف السياقية أنها قوية حتى باستخدام ثلاثة تدريبات فقط\nجمل لكل معنى الكلمة ، مع الحد الأدنى من التحسينات التي تم الحصول عليها من خلال زيادة حجم بيانات التدريب هذه.', 'ja': '抽象変換器ベースの言語モデルは、ストームによってNLPで多くの分野を取り上げてきた。 BERTとその派生物は、文脈に応じた意味的ニュアンスを取り込む能力のおかげで、Word Sense Disambiguation （ WSD ）を含む既存の評価ベンチマークのほとんどを支配しています。 しかし、単語の感覚を符号化し回復する能力と潜在的な制限については、まだほとんど知識がありません。 この記事では、語彙の曖昧さに関して有名なBERTモデルの深い定量的および定性的分析を提供します。 私たちの分析の主な結論の1つは、BERTは、各単語の意味で利用可能な例が限られている場合でも、高レベルの意味の区別を正確に取り込むことができるということです。 我々の分析はまた、場合によっては、言語モデルが、トレーニングデータとコンピューティングリソースの可用性の観点から理想的な条件下で粗粒名詞の曖昧さを解消することに近いことを明らかにします。 しかし、このシナリオは現実世界の場面ではほとんど発生しないため、粗粒化した場面でも多くの実用的な課題が残されている。 また、2つの主要な言語モデルベースのWSD戦略、すなわち微調整と機能抽出の深い比較を行い、後者のアプローチは、感覚バイアスに関してより堅牢であり、利用可能な限られたトレーニングデータをよりよく利用できることを発見しました。 実際、コンテキスト化された埋め込みを平均化する単純なフィーチャー抽出戦略は、3つのトレーニングのみを使用しても堅牢であることが証明されています\nこのトレーニングデータのサイズを大きくすることで最小限の改善が得られます。', 'pt': 'Resumo Modelos de linguagem baseados em transformadores conquistaram muitos campos da PNL. BERT e seus derivados dominam a maioria dos benchmarks de avaliação existentes, incluindo aqueles para Word Sense Disambiguation (WSD), graças à sua capacidade de capturar nuances semânticas sensíveis ao contexto. No entanto, ainda há pouco conhecimento sobre suas capacidades e potenciais limitações na codificação e recuperação dos sentidos das palavras. Neste artigo, fornecemos uma análise quantitativa e qualitativa aprofundada do célebre modelo BERT no que diz respeito à ambiguidade lexical. Uma das principais conclusões de nossa análise é que o BERT pode capturar com precisão as distinções de sentido de alto nível, mesmo quando um número limitado de exemplos está disponível para cada sentido de palavra. Nossa análise também revela que, em alguns casos, os modelos de linguagem chegam perto de resolver a desambiguação de substantivos de granulação grossa sob condições ideais em termos de disponibilidade de dados de treinamento e recursos computacionais. No entanto, esse cenário raramente ocorre em ambientes do mundo real e, portanto, muitos desafios práticos permanecem mesmo em ambientes de granulação grosseira. Também realizamos uma comparação aprofundada das duas principais estratégias de WSD baseadas em modelo de linguagem, a saber, ajuste fino e extração de recursos, descobrindo que a última abordagem é mais robusta em relação ao viés de sentido e pode explorar melhor os dados de treinamento disponíveis limitados . Na verdade, a estratégia simples de extração de recursos de média de embeddings contextualizados se mostra robusta mesmo usando apenas três treinamentos\nsentenças por sentido de palavra, com melhorias mínimas obtidas pelo aumento do tamanho desses dados de treinamento.', 'es': 'Resumen Los modelos lingüísticos basados en Transformer han arrasado en muchos campos de la PNL. BERT y sus derivados dominan la mayoría de los puntos de referencia de evaluación existentes, incluidos los de la desambiguación del sentido de las palabras (WSD), gracias a su capacidad para capturar matices semánticos sensibles al contexto. Sin embargo, todavía hay poco conocimiento sobre sus capacidades y posibles limitaciones en la codificación y recuperación de los sentidos de las palabras. En este artículo, ofrecemos un análisis cuantitativo y cualitativo en profundidad del célebre modelo BERT con respecto a la ambigüedad léxica. Una de las principales conclusiones de nuestro análisis es que BERT puede captar con precisión distinciones sensoriales de alto nivel, incluso cuando hay un número limitado de ejemplos disponibles para cada sentido de palabra. Nuestro análisis también revela que, en algunos casos, los modelos lingüísticos se acercan a resolver la desambiguación de sustantivos groseros en condiciones ideales en términos de disponibilidad de datos de entrenamiento y recursos informáticos. Sin embargo, este escenario rara vez ocurre en entornos del mundo real y, por lo tanto, quedan muchos desafíos prácticos incluso en el entorno de grano grueso. También realizamos una comparación en profundidad de las dos estrategias principales de WSD basadas en modelos del lenguaje, a saber, el ajuste fino y la extracción de características, encontrando que este último enfoque es más sólido con respecto al sesgo sensorial y puede aprovechar mejor los limitados datos de entrenamiento disponibles. De hecho, la estrategia simple de extracción de características de promediar las incrustaciones contextualizadas demuestra ser sólida incluso con solo tres capacitaciones\nfrases por sentido de palabra, con mejoras mínimas que se obtienen al aumentar el tamaño de estos datos de entrenamiento.', 'fr': "Les modèles de langage basés sur Transformer ont pris d'assaut de nombreux domaines de la PNL. BERT et ses dérivés dominent la plupart des critères d'évaluation existants, y compris ceux de Word Sense Disambiguation (WSD), grâce à leur capacité à saisir des nuances sémantiques contextuelles. Cependant, il existe encore peu de connaissances sur leurs capacités et leurs limites potentielles en matière d'encodage et de récupération des sens des mots. Dans cet article, nous proposons une analyse quantitative et qualitative approfondie du célèbre modèle BERT en ce qui concerne l'ambiguïté lexicale. L'une des principales conclusions de notre analyse est que le BERT peut saisir avec précision des distinctions de sens de haut niveau, même lorsqu'un nombre limité d'exemples est disponible pour chaque sens du mot. Notre analyse révèle également que, dans certains cas, les modèles linguistiques sont presque capables de résoudre la question de la désambiguïsation grossière des noms dans des conditions idéales en termes de disponibilité des données de formation et des ressources informatiques. Cependant, ce scénario se produit rarement dans des contextes réels et, par conséquent, de nombreux défis pratiques demeurent, même dans le contexte grossier. Nous effectuons également une comparaison approfondie des deux principales stratégies WSD basées sur des modèles de langage, à savoir le réglage fin et l'extraction de caractéristiques, constatant que cette dernière approche est plus robuste en ce qui concerne le biais de sens et qu'elle peut mieux exploiter les données d'entraînement disponibles limitées. En fait, la stratégie simple d'extraction de caractéristiques consistant à établir la moyenne des intégrations contextualisées s'avère robuste, même en utilisant seulement trois formations\nphrases par mot, avec des améliorations minimes obtenues en augmentant la taille de ces données d'entraînement.", 'zh': '摘要于Transformer言,风靡于NLP。 BERT 及衍生品物主见料基准,包 Word Sense 消歧义 (WSD) 之准,归功于获上下文语义细微差别之能也。 然其编码复词义,潜于局限性,犹知之甚少。 本文供词汇歧义名BERT深入定量定性分析。 论大要之一,BERT可得高义异,虽词义示例数有限。 语形于练数计算资源可用性近于理粗粒度名词消歧。 然少于现实世界,故虽在粗粒度中,犹多其实。 又二要言之WSD(即微调和特征取)深较之,一法偏差,而益用有限者训练数。 事实上,均上下文化之简特征提取之策虽仅用三练亦证健壮。\n每单词句义,以增练数之大小为最小。', 'hi': 'सार ट्रांसफॉर्मर आधारित भाषा मॉडल तूफान से एनएलपी में कई क्षेत्रों ले लिया है. BERT और इसके डेरिवेटिव मौजूदा मूल्यांकन बेंचमार्क के अधिकांश पर हावी हैं, जिसमें वर्ड सेंस डिसकम्पिगेशन (WSD) के लिए भी शामिल हैं, संदर्भ-संवेदनशील शब्दार्थ बारीकियों को कैप्चर करने में उनकी क्षमता के लिए धन्यवाद। हालांकि, शब्द इंद्रियों को एन्कोडिंग और पुनर्प्राप्त करने में उनकी क्षमताओं और संभावित सीमाओं के बारे में अभी भी बहुत कम ज्ञान है। इस लेख में, हम लेक्सिकल अस्पष्टता के संबंध में प्रसिद्ध BERT मॉडल का एक गहन मात्रात्मक और गुणात्मक विश्लेषण प्रदान करते हैं। हमारे विश्लेषण के मुख्य निष्कर्षों में से एक यह है कि BERT सटीक रूप से उच्च-स्तरीय अर्थ भेदों को कैप्चर कर सकता है, भले ही प्रत्येक शब्द अर्थ के लिए सीमित संख्या में उदाहरण उपलब्ध हों। हमारे विश्लेषण से यह भी पता चलता है कि कुछ मामलों में भाषा मॉडल प्रशिक्षण डेटा और कंप्यूटिंग संसाधनों की उपलब्धता के संदर्भ में आदर्श परिस्थितियों में मोटे-दाने वाले संज्ञा बहुविकल्पी को हल करने के करीब आते हैं। हालांकि, यह परिदृश्य शायद ही कभी वास्तविक दुनिया की सेटिंग्स में होता है और इसलिए, कई व्यावहारिक चुनौतियां मोटे-दाने वाली सेटिंग में भी रहती हैं। हम दो मुख्य भाषा मॉडल-आधारित डब्ल्यूएसडी रणनीतियों की गहराई से तुलना भी करते हैं, अर्थात्, ठीक-ट्यूनिंग और फीचर निष्कर्षण, यह पाते हुए कि बाद का दृष्टिकोण पूर्वाग्रह को समझने के संबंध में अधिक मजबूत है और यह सीमित उपलब्ध प्रशिक्षण डेटा का बेहतर शोषण कर सकता है। वास्तव में, संदर्भित एम्बेडिंग के औसत की सरल सुविधा निष्कर्षण रणनीति केवल तीन प्रशिक्षण का उपयोग करके भी मजबूत साबित होती है\nइस प्रशिक्षण डेटा के आकार को बढ़ाकर प्राप्त न्यूनतम सुधारों के साथ प्रति शब्द भावना वाक्य।', 'ru': 'Абстрактные языковые модели, основанные на трансформаторах, штурмом заняли много полей в NLP. BERT и его производные доминируют в большинстве существующих критериев оценки, в том числе для Word Sense Disambiguation (WSD), благодаря их способности фиксировать чувствительные к контексту семантические нюансы. Тем не менее, все еще мало знаний об их возможностях и потенциальных ограничениях в кодировании и восстановлении словесных органов чувств. В данной статье мы приводим углубленный количественный и качественный анализ знаменитой модели BERT в отношении лексической неоднозначности. Один из главных выводов нашего анализа заключается в том, что БЕРТ может точно фиксировать высокоуровневые смысловые различия, даже если для каждого слова имеется ограниченное количество примеров. Наш анализ также показывает, что в некоторых случаях языковые модели приближаются к решению грубозернистой дезамбигментации существительных в идеальных условиях с точки зрения доступности обучающих данных и вычислительных ресурсов. Однако этот сценарий редко встречается в реальных условиях, и, следовательно, многие практические проблемы остаются даже в весьма сложной обстановке. Мы также проводим углубленное сравнение двух основных стратегий WSD на основе языковой модели, а именно тонкой настройки и извлечения признаков, обнаруживая, что последний подход является более надежным в отношении предвзятости восприятия и может лучше использовать ограниченные доступные учебные данные. На самом деле, простая стратегия извлечения признаков усреднения контекстуализированных вложений оказывается надежной даже при использовании только трех тренингов\nпредложения по смыслу слов, с минимальными улучшениями, полученными за счет увеличения размера этих обучающих данных.', 'ga': 'Teibí Tá go leor réimsí san NLP tar éis stoirme a chur ar mhúnlaí teanga atá bunaithe ar chlaochladán. Is iad BERT agus a dhíorthaigh atá chun tosaigh sa chuid is mó de na tagarmharcanna meastóireachta atá ann cheana féin, lena n-áirítear iad siúd le haghaidh Disathbhríocht Word Sense (WSD), a bhuí lena gcumas chun nuances séimeantach comhthéacs-íogair a ghabháil. Mar sin féin, is beag eolas atá fós ar a gcumas agus ar na srianta a d’fhéadfadh a bheith orthu maidir le céadfaí focal a ionchódú agus a aisghabháil. San Airteagal seo, cuirimid mionanailís chainníochtúil agus cháilíochtúil ar fáil ar mhúnla clúiteach BERT maidir le débhríocht fhoclóra. Ceann de phríomhchonclúidí ár n-anailíse is ea gur féidir le CRET idirdhealú cruinn a dhéanamh ar chiall ardleibhéil, fiú nuair a bhíonn líon teoranta samplaí ar fáil do gach ciall focal. Léiríonn ár n-anailís freisin go mbíonn múnlaí teanga i gcásanna áirithe gar do dhifríocht garbh ainmfhocail a réiteach faoi choinníollacha idéalacha maidir le hinfhaighteacht sonraí oiliúna agus acmhainní ríomhaireachta. Mar sin féin, is annamh a tharlaíonn an cás seo i suíomhanna fíorshaoil agus, mar sin, tá go leor dúshlán praiticiúla fós ann fiú sa suíomh garbh. Déanaimid comparáid dhomhain freisin ar an dá phríomhstraitéis WSD atá bunaithe ar mhúnla teanga, eadhon, mionchoigeartú agus asbhaint gnéithe, ag fáil amach go bhfuil an cur chuige deiridh sin níos láidre maidir le claonadh braite agus gur féidir leis leas níos fearr a bhaint as sonraí teoranta oiliúna atá ar fáil. . Déanta na fírinne, tá an straitéis eastósctha gnéithe simplí maidir le meánú leabaithe comhthéacsúla láidir fiú gan úsáid a bhaint as ach trí oiliúint.\nabairtí in aghaidh an fhocail, le feabhsuithe íosta faighte trí mhéid na sonraí oiliúna seo a mhéadú.', 'it': "I modelli linguistici basati su trasformatori hanno preso molti campi in NLP. BERT e i suoi derivati dominano la maggior parte dei benchmark di valutazione esistenti, compresi quelli per Word Sense Disambiguation (WSD), grazie alla loro capacità di catturare sfumature semantiche sensibili al contesto. Tuttavia, ci sono ancora poche conoscenze sulle loro capacità e potenziali limitazioni nella codifica e nel recupero dei sensi delle parole. In questo articolo forniamo un'analisi quantitativa e qualitativa approfondita del celebre modello BERT rispetto all'ambiguità lessicale. Una delle principali conclusioni della nostra analisi è che BERT può catturare con precisione distinzioni sensoriali di alto livello, anche quando un numero limitato di esempi è disponibile per ogni senso di parola. La nostra analisi rivela anche che in alcuni casi i modelli linguistici si avvicinano a risolvere la disambiguazione dei sostantivi a grana grossa in condizioni ideali in termini di disponibilità dei dati formativi e delle risorse informatiche. Tuttavia, questo scenario si verifica raramente in contesti reali e, quindi, molte sfide pratiche rimangono anche in ambienti a grana grossa. Eseguiamo anche un confronto approfondito delle due principali strategie WSD basate sul modello linguistico, vale a dire la messa a punto e l'estrazione delle funzionalità, scoprendo che quest'ultimo approccio è più robusto rispetto al bias dei sensi e può sfruttare al meglio i dati di formazione disponibili limitati. Infatti, la semplice strategia di estrazione delle funzionalità di medie incorporazioni contestualizzate si dimostra robusta anche utilizzando solo tre allenamenti\nfrasi per parola senso, con miglioramenti minimi ottenuti aumentando la dimensione di questi dati di allenamento.", 'ka': 'Name BERT და მისი განსხვავებული განსხვავებები დომინტურებენ უფრო მეტის განსხვავებული განსხვავებული ბენქმარი, რომელიც სიტყვის განსხვავებული განსხვავებას (WSD), მადლობად მათი შესაძლებლობა კონტექსტური მაგრამ, ისინი არსებობს პატარა უცნობა მათი შესაძლებლობა და შესაძლებელი ზომილებების შესაძლებლობა კოდირებაში და სიტყვის სიტყვის შესაძლებლობაზე. ამ პექტიკში ჩვენ კოლექსიკალური ანალიზაციის კოლექტიური და კოლექტიური ანალიზაციას გვეყენებთ. ჩვენი ანალიზის ერთი უფრო მნიშვნელოვანი შესაძლებელია, რომ BERT შეუძლია წარმოდგენოთ უფრო მარტივი სიგრძე განსხვავებები, მაგრამ როცა ყველა სიტყვის შესაძლებელია მაგალით ჩვენი ანალიზია ასევე აღმოჩნდა, რომ რამდენიმე შემთხვევაში ენის მოდელები დაახლოებით, რომლებიც აღმოჩნეთ საკუთარი საკუთარი საკუთარი საკუთარი განსხვავება იდეალური შემთხვევაში იდეალური მაგრამ ეს სინარიო არაფერად მოხდება რეალური მსოფლიოში და ამიტომ, ბევრი პრაქტიკური გამოცდილებები უკვე დარჩენა კონტაქტიური განსაზღვრებში. ჩვენ ასევე გავაკეთებთ ორი მნიშვნელოვანი ენის მოდელის სტრატიგიების დამატებული WSD სტრატიგიების განმავლობაში, ანუ, სტრუქტირება და სტრუქტირება განმავლობაში, რომლებიც აღმოჩნეთ, რომ ბოლო პროგრამა უფრო ძალ სინამდვილეში, განსხვავებული კონტექსტუალურებული ინტექსტუალურებული ინტექსტუალურებების უფრო ძალიან გამოყენება მხოლოდ სამი განსხვავება\nსიტყვების სიტყვების სიტყვებით, მინიმალური დამატებით, რომლებიც მიიღებულია ამ განსწავლების მონაცემების ზომა.', 'el': 'Τα μοντέλα γλωσσών που βασίζονται στον μετασχηματιστή έχουν πάρει πολλά πεδία στην καταιγίδα. Το BERT και τα παράγωγά του κυριαρχούν στα περισσότερα από τα υπάρχοντα κριτήρια αξιολόγησης, συμπεριλαμβανομένων εκείνων για την Αποκατάσταση της Λογικής Λογικής (WSD), χάρη στην ικανότητά τους να συλλαμβάνουν ευαίσθητες σημασιολογικές αποχρώσεις στο πλαίσιο. Ωστόσο, εξακολουθούν να υπάρχουν ελάχιστες γνώσεις σχετικά με τις δυνατότητες και τους πιθανούς περιορισμούς τους στην κωδικοποίηση και ανάκτηση των αισθήσεων λέξεων. Σε αυτό το άρθρο, παρέχουμε μια σε βάθος ποσοτική και ποιοτική ανάλυση του διάσημου μοντέλου σε σχέση με τη λεξική ασάφεια. Ένα από τα κύρια συμπεράσματα της ανάλυσης μας είναι ότι ο BERT μπορεί να καταγράψει με ακρίβεια τις διακρίσεις αισθήσεων υψηλού επιπέδου, ακόμα και όταν υπάρχει περιορισμένος αριθμός παραδειγμάτων για κάθε λέξη έννοια. Η ανάλυση μας αποκαλύπτει επίσης ότι σε ορισμένες περιπτώσεις τα γλωσσικά μοντέλα πλησιάζουν στην επίλυση χονδροειδούς διαχωρισμού ουσιαστικών υπό ιδανικές συνθήκες όσον αφορά τη διαθεσιμότητα δεδομένων κατάρτισης και υπολογιστικών πόρων. Ωστόσο, αυτό το σενάριο σπάνια εμφανίζεται σε πραγματικές συνθήκες και, ως εκ τούτου, πολλές πρακτικές προκλήσεις παραμένουν ακόμη και στο χονδροειδές περιβάλλον. Πραγματοποιούμε επίσης μια σε βάθος σύγκριση των δύο βασικών στρατηγικών που βασίζονται στο μοντέλο γλωσσών, δηλαδή της λεπτομέρειας και της εξαγωγής χαρακτηριστικών, διαπιστώνοντας ότι η τελευταία προσέγγιση είναι πιο ισχυρή σε σχέση με την προκατάληψη των αισθήσεων και μπορεί καλύτερα να εκμεταλλευτεί τα περιορισμένα διαθέσιμα δεδομένα κατάρτισης. Στην πραγματικότητα, η απλή στρατηγική εξαγωγής χαρακτηριστικών του μέσου όρου ενσωμάτωσης σε πλαίσιο αποδεικνύεται ισχυρή ακόμη και χρησιμοποιώντας μόνο τρεις προπονήσεις\nπροτάσεις ανά λέξη νόημα, με ελάχιστες βελτιώσεις που επιτυγχάνονται με την αύξηση του μεγέθους αυτών των δεδομένων κατάρτισης.', 'kk': 'Абстракты түрлендіруші тіл үлгілері NLP- де бірнеше өрістер алды. BERT және оның дерективтері бар оқиғалардың көпшілігін бастайды, сондай-ақ Word Sense Disambiguation (WSD) деген сөздерінің көпшілігін бастайды, контексті семантикалық нюанс түсіндіру мүмкіндіктеріне көме Бірақ олардың кодтамасы және сөздің сезімдерін қайта алу мүмкіндіктері мен мүмкіндік шектеулері туралы әлі білім жоқ. Бұл мақалада, біз Лексикалық амбикциялық қатынасы туралы беRT үлгісінің көпшілігін және квалификациялық анализ береміз. Біздің анализиямыздың негізгі нәтижесінің бірі - BERT әрбір сөз сезімі үшін шектелген мәселелерді дұрыс түсіндіре алады. Біздің анализиямыз кейбір жағдайда тіл үлгілері идеалдық шарттарында деректерді және есептеу ресурстарының жеткізілікті арқылы бір-бірінші тіл үлгілерін шешуге жақын болады. Бірақ бұл сценарий шын әлемдік параметрлерінде қарапайды, сондықтан көптеген практикалық өзгерістер қарапайды. Сонымен қатар, біз басқа тіл үлгісінде негізгі WSD стратегиясының түсіндігін салыстырып, мәселе, қарау және таңдау мүмкіндіктерін салыстырып, соңғы тәсілдігі көзгертілікті сезімге қарай көзгертілген ж Шынымен, орташа контекстуалды ендіру стратегиясының қарапайым қасиеттері тек үш оқыту арқылы\nСөздердің түсініктері, бұл оқыту деректерінің өлшемін көбейту арқылы кеміндетті жақсартулары бар.', 'lt': 'Abstraktiniai kalbų modeliai, pagrįsti transformatoriais, per audrą užėmė daugelį NLP laukų. BERT ir jo išvestinės finansinės priemonės dominuoja dauguma esamų vertinimo lyginamųjų rodiklių, įskaitant tuos, kurie susiję su žodžių jautrumo nedviprasmiškumu (angl. Word Sense Disambiguation, WSD), dėl jų gebėjimo surinkti kontekstui jautrius semantinius nuancijas. Tačiau vis dar yra mažai žinių apie jų gebėjimus ir galimus žodžio jutimų kodavimo ir atgavimo apribojimus. Šiame straipsnyje teikiame išsamią žymėto BERT modelio kiekybinę ir kokybinę analizę, susijusią su leksiniu dviprasmiškumu. Viena iš pagrindinių mūsų analizės išvadų yra ta, kad BERT gali tiksliai atspindėti aukšto lygio jutimo skirtumus, net jei kiekvienam žodžio jutimui galima rasti ribotą skaičių pavyzdžių. Mūsų analizė taip pat atskleidžia, kad kai kuriais atvejais kalbos modeliai yra artimi didelių grūdų pavadinimų skirtumui išspręsti idealiomis sąlygomis, atsižvelgiant į galimybę gauti mokymo duomenis ir skaičiavimo išteklius. Tačiau šis scenarijus retai atsiranda realiame pasaulyje, todėl daugelis praktinių iššūkių tebėra netgi didelio grūdo aplinkoje. Taip pat nuodugniai palyginame dvi pagrindines kalbų modeliu pagrįstas VSD strategijas, būtent patobulinimą ir savybių išgavimą, nustatydami, kad pastarasis požiūris yra tvirtesnis, atsižvelgiant į sąmoningumą ir kad jis gali geriau išnaudoti ribotus turimus mokymo duomenis. Tiesą sakant, paprasta kontekstinės integracijos vidurkio gavimo strategija yra patikima net ir naudojant tik tris mokymus.\nsakiniai žodžio prasme, minimaliai patobulinant šiuos mokymo duomenis.', 'mk': 'Апстрактни јазички модели базирани на трансформи заземаа многу полиња во НЛП од бура. БЕРТ и нејзините деривативи доминираат во поголемиот дел од постоечките проценки, вклучувајќи ги и оние за раздвојување на зборовите чувства (WSD), благодарение на нивната способност за заземање семантични нијанси чувствителни контекст. Сепак, сé уште има мало знаење за нивните способности и потенцијалните ограничувања во кодирањето и обновувањето на зборните сетила. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity.  Еден од главните заклучоци од нашата анализа е дека БЕРТ може точно да прифати разлики на високо ниво на чувство, дури и кога е достапен ограничен број примери за секоја зборна смисла. Нашата анализа, исто така, открива дека во некои случаи јазичките модели се блиску до решавање на дејамбигуацијата со грубо населено името под идеални услови во поглед на достапноста на податоци за обука и компјутерски ресурси. Сепак, ова сценарио ретко се случува во реалните услови и, со тоа, многу практични предизвици и понатаму остануваат дури и во сиромашните услови. Исто така, спроведуваме длабока споредба на двете стратегии на СДД базирани на главниот јазички модел, имено, финетизирање и екстракција на карактеристики, откривајќи дека последниот пристап е посилен во однос на чувствителната предрасуда и дека може подобро да ги искористи ограничените достапни Всушност, едноставната стратегија за извлекување на карактеристики на просечното контекстуално вложување се покажува силна дури и користејќи само три обуки\nреченици по збор смисла, со минимални подобрувања постигнати со зголемување на големината на овие податоци за обука.', 'ms': 'Model bahasa berasaskan Transformer Abstract telah mengambil banyak medan di NLP oleh ribut. BERT dan derivatnya menguasai kebanyakan tanda referensi penilaian yang ada, termasuk tanda referensi untuk Lumpuhkan Perasaan Perkataan (WSD), berkat kemampuan mereka dalam menangkap nuansi semantik sensitif-konteks. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses.  Dalam artikel ini, kami menyediakan analisis kuantitatif dan kualitatif dalam model BERT yang terkenal berkaitan dengan ambiguiti lexik. Salah satu kesimpulan utama dari analisis kami adalah bahawa BERT boleh menangkap dengan tepat perbezaan sensasi tahap tinggi, walaupun bilangan contoh terbatas tersedia untuk setiap sensasi perkataan. Analisis kami juga menunjukkan bahawa dalam beberapa kes model bahasa datang dekat dengan memecahkan penyelesaian tidak ambiguasi nama berlebihan dalam keadaan ideal dalam terma kemampuan data latihan dan sumber komputer. Namun, skenario ini jarang berlaku dalam tetapan dunia nyata dan, sebab itu, banyak cabaran praktik tetap berada walaupun dalam tetapan terbuka. Kami juga melakukan perbandingan dalam-dalam dua strategi WSD berdasarkan model bahasa utama, iaitu, penyesuaian dan ekstraksi ciri-ciri, mencari bahawa pendekatan terakhir lebih kuat terhadap bias perasaan dan ia boleh mengeksploitasi lebih baik data latihan tersedia yang terbatas. Malah, strategi ekstraksi ciri-ciri sederhana untuk mewakili penyambungan kontekstual membuktikan kuat walaupun menggunakan hanya tiga latihan\nkalimat per perkataan, dengan peningkatan minimal yang diperoleh dengan meningkatkan saiz data latihan ini.', 'ml': 'ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനത്തുള്ള ഭാഷ മോഡലുകള്\u200d NLP-ല്\u200d പല പ്രദേശങ്ങളും കൊടുക്കുന്നു ബെര്\u200dട്ടിയും അതിന്റെ പ്രവർത്തകങ്ങളും നിലവിലുള്ള വിലാസങ്ങളുടെ മിക്കവേറെ മാറ്റങ്ങളിലേക്കാണ് നിയന്ത്രിക്കുന്നത്. വാക്കിന്റെ സെന്\u200dസ് ഡിസ്പ എന്നാലും, അവരുടെ കഴിവും സാധ്യതയുമുള്ള പരിധികളും എന്\u200dകോഡിങ്ങ് ചെയ്യുന്നതും വാക്കുകളുടെ സെന്\u200dസിന്\u200dസ് വീണ്ടും തിര ഈ ലേഖനത്തില്\u200d, നമ്മള്\u200d ആഴത്തിലുള്ള വിവിധ വിശദീകരിക്കുന്നു ബെര്\u200dട്ടി മോഡലിനെക്കുറിച്ച്, ലെക്സിക്കല്\u200d ആഗ്രഹിക്കുന്ന ഒര നമ്മുടെ അന്വേഷണത്തിന്റെ പ്രധാനപ്പെട്ട അവസാനത്തില്\u200d ഒന്നാണ് ബെര്\u200dട്ടി ഉയര്\u200dന്ന നില വ്യത്യാസങ്ങള്\u200d ശരിക്കും പിടിക്കാന്\u200d സാധിക നമ്മുടെ അന്യായോജ്യം വ്യക്തമാക്കുന്നു, ചില കാര്യങ്ങളില്\u200d ഭാഷ മോഡലുകള്\u200d പരിശീലനത്തിന്റെയും പരിശീലനത്തിന്റെയും വിഭവങ്ങള്\u200d കണക്കുകൂട്ടു എന്നാലും ഈ കാഴ്ചപ്പെടുന്നത് യഥാര്\u200dത്ഥ ലോകത്തിലെ സജ്ജീകരണങ്ങളില്\u200d കുറച്ച് പ്രധാനപ്പെട്ടിരിക്കുന്നു. അതുകൊണ്ട്, ക രണ്ട് പ്രധാനഭാഷയുടെ മോഡല്\u200d അടിസ്ഥാനമായ വിഎസ്ഡി സ്ട്രായ്ട്രീജികളുടെയും ആഴത്തില്\u200d നമ്മള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അതായത് നല്ല തിരഞ്ഞെടുക്കുന്നതും വിശേഷത് സത്യത്തില്\u200d മൂന്നു ട്രെയിനിങ്ങള്\u200d ഉപയോഗിച്ച് കൊണ്ട് മൂന്ന് പരിശീലനം ഉപയോഗിക്കുന്നത് മാത്രം കൊണ്ട് മാത്രം ക\nഈ ട്രെയിനിങ്ങളുടെ വലിപ്പം വര്\u200dദ്ധിപ്പിക്കുന്നതിനാല്\u200d കുറച്ച് മെച്ചപ്പെട്ട വാക്കുകള്\u200dക്ക് വാ', 'mt': 'Il-mudelli lingwistiċi astratti bbażati fuq it-Transformer ħadu ħafna oqsma f’NLP b’maltempata. Il-BERT u d-derivattivi tiegħu jiddominaw il-biċċa l-kbira tal-parametri ta’ referenza eżistenti ta’ evalwazzjoni, inklużi dawk għad-Diżambigwarazzjoni tas-Sens tal-Kliem (WSD), bis-saħħa tal-kapaċità tagħhom fil-kisba ta’ nuanzi semantiċi sensittivi għall-kuntest. Madankollu, għad hemm ftit għarfien dwar il-kapaċitajiet u l-limitazzjonijiet potenzjali tagħhom fl-ikkodifikar u l-irkupru tas-sensi tal-kelma. F’dan l-artikolu, nagħtu analiżi kwantitattiva u kwalitattiva fil-fond tal-mudell BERT iċċelebrat fir-rigward tal-ambigwità lexika. Waħda mill-konklużjonijiet ewlenin tal-analiżi tagħna hija li l-BERT jista’ jaqbad b’mod preċiż distinzjonijiet ta’ sens ta’ livell għoli, anki meta numru limitat ta’ eżempji jkun disponibbli għal kull sens tal-kelma. L-analiżi tagħna turi wkoll li f’xi każijiet il-mudelli lingwistiċi jmorru qrib is-soluzzjoni tad-diżambigwazzjoni tan-nomi b’għeneb kbir taħt kundizzjonijiet ideali f’termini tad-disponibbiltà tad-dejta tat-taħriġ u r-riżorsi tal-kompjuter. Madankollu, dan ix-xenarju rarament iseħħ f’ambjenti tad-dinja reali u, għalhekk, ħafna sfidi prattiċi jibqgħu anke f’ambjent ta’ ħbub grossi. Għandna nagħmlu wkoll paragun fil-fond taż-żewġ strateġiji ewlenin tad-DEM ibbażati fuq mudell lingwistiku, jiġifieri l-aġġustament u l-estrazzjoni tal-karatteristiċi, li jsibu li l-approċċ tal-aħħar huwa aktar robust fir-rigward tal-preġudizzju tas-sens u jista’ jisfrutta aħjar id-dejta limitata disponibbli dwar it-taħriġ. Fil-fatt, l-istrateġija sempliċi għall-estrazzjoni tal-karatteristiċi tal-medja tal-inkorporazzjonijiet kuntestwalizzati turi li hija robusta anke bl-użu ta’ tliet taħriġ biss\nsentenzi għal kull sens ta’ kelma, b’titjib minimu miksub billi jiżdied id-daqs ta’ din id-dejta ta’ taħriġ.', 'mn': 'Абстракт Трансформер-ын үндсэн хэл загварууд NLP-д маш олон салбарыг шатаар авсан. БЕРТ болон түүний төрөлхтнүүд оршиж буй оюутнуудын ихэнх хэмжээсүүдийг давамгайлдаг, мөн Word Sense Disambiguation (WSD) гэх мэт хэмжээсүүдийг ашиглаж байхад баярлалаа. Гэхдээ тэдний чадвар, боломжтой хязгаарлалтын тухай бага мэдлэг байдаг. Энэ баримтуудад бид Лексийн хэмжээсгүй байдлын тухай баярласан BERT загварын хэмжээсүүдийг гүн гүнзгий, квалифицийн шинжилгээ өгдөг. Бидний шинжилгээний үндсэн нэг нь БЕРТ хэмжээний мэдрэмжийн ялгааг тодорхой ойлгох боломжтой гэсэн үг бүрт хязгаарлагдсан жишээний тоо байхдаа ч гэсэн. Бидний анализ мөн зарим тохиолдолд хэл загварууд нь давсаг давсаг, тооцоолох боломжтой боломжтой боломжтой байдлын үндсэн нөхцөл байдлын дотор шийдвэрлэх боломжтой болно. Гэвч энэ хувилбар жинхэнэ дэлхийн төвшинд ховор тохиолддог. Иймээс олон практикийн сорилтууд давхар тарианы хэмжээнд ч байдаг. Мөн бид хоёр үндсэн хэл загварын үндсэн WSD стратегийг гүн гүнзгий харьцуулж, тэгэхээр сайн тохиромжтой болон шинжлэх ухаан, дараагийн арга загвар нь ойлголтын тухай илүү хүчтэй гэдгийг олж мэднэ. Үнэндээ, орчин үеийн дунджаар дамжуулагдсан байгууллагуудын хялбар шинжлэх ухааны стратеги нь зөвхөн гурван сургалтыг ашиглан\nЭнэ сургалтын өгөгдлийн хэмжээг нэмэгдүүлснээр хамгийн бага сайжруулалт гаргасан үг.', 'pl': 'Modele językowe oparte na transformatorach przejęły wiele dziedzin w NLP przez burzę. BERT i jego pochodne dominują w większości istniejących punktów odniesienia do oceny, w tym dotyczących rozproszeń Word Sense Disambiguation (WSD), dzięki ich zdolności do przechwytywania kontekstowych niuansów semantycznych. Jednak wciąż jest niewiele wiedzy na temat ich możliwości i potencjalnych ograniczeń w zakresie kodowania i odzyskiwania zmysłów słowowych. W tym artykule przedstawiamy dogłębną analizę ilościową i jakościową sławnego modelu BERT pod kątem dwuznaczności leksykalnej. Jednym z głównych wniosków naszej analizy jest to, że BERT może dokładnie uchwycić wysokie rozróżnienia zmysłów, nawet jeśli dla każdego znaczenia słowa dostępna jest ograniczona liczba przykładów. Nasza analiza ujawnia również, że w niektórych przypadkach modele językowe zbliżają się do rozwiązywania gruboziarnistej dyjednoznaczności rzeczowników w idealnych warunkach pod względem dostępności danych treningowych i zasobów obliczeniowych. Jednakże scenariusz ten rzadko występuje w świecie rzeczywistym, dlatego wiele praktycznych wyzwań pozostaje nawet w warunkach gruboziarnistych. Przeprowadzamy również dogłębne porównanie dwóch głównych strategii WSD opartych na modelu językowym, a mianowicie precyzyjnego dostrajania i ekstrakcji cech, stwierdzając, że ostatnie podejście jest bardziej solidne w odniesieniu do tendencji zmysłowych i może lepiej wykorzystać ograniczone dostępne dane treningowe. W rzeczywistości prosta strategia ekstrakcji cech polegająca na uśrednianiu kontekstowych osadzeń okazuje się solidna nawet przy użyciu tylko trzech szkoleń\nzdania na słowo sens, z minimalnymi ulepszeniami uzyskanymi poprzez zwiększenie wielkości tych danych treningowych.', 'no': 'Name BERT og deres deriverte dominerer dei fleste av dei eksisterande evalueringsbenchmarkene, inkludert dei for Word Sense Disambiguation (WSD), takk på at dei kan henta i henting av kontekstsensitiv semantiske nuans. Men det er likevel lite kunnskap om dei kapasitetene og potensielle grenser i koding og gjenoppretting av ordsensar. I denne artikkelen gir vi ein kvantitativ og kvalitativ analyse av den gjennomførte BERT-modellen med respekt til leksiske ambiguitet. Ein av dei viktigste konklusjonane i analysen vår er at BERT kan nøyaktig henta forskjellingar på høg nivå, sjølv når eit begrenset tal eksemplar er tilgjengeleg for kvar ordfølelse. Analysen vårt viser også at i enkelte tilfeller språk-modeller kommer nær til å løyse uttrykk-kornerte substitusjonsdisambiguasjon under ideale vilkår med tilgjengelighet av opplæringsdata og dataressursar. Dette scenarioen gjer imidlertid ofte i verdensinnstillingane, og derfor blir mange praktiske utfordringar sjølv i innstillinga med kortskorn. Vi utfører også ein i dybde sammenlikning av de to hovudspråk-modellene baserte WSD-strategiene, som er, finnstillingsog utpakking av funksjonar, og finn at den siste tilnærminga er meir sterkt med hensyn til følelsesforsikt og kan bedre bruka begrensede tilgjengelege treningsdata. Faktisk, den enkle funksjonsekstraheringsstrategien for gjennomsnittleg kontekstualiserte innbygging viser at berre tre opplæring er sterkt.\nsetningar per ordfølelse, med minimale forbetringar som er henta ved å auka storleiken på denne treningsdata.', 'ro': 'Modelele lingvistice bazate pe transformatori au luat multe domenii în PNL cu furtună. BERT și derivatele sale domină majoritatea criteriilor de evaluare existente, inclusiv cele pentru dezambiguizarea sensului Word (WSD), datorită capacității lor de a capta nuanțe semantice sensibile la context. Cu toate acestea, există încă puține cunoștințe despre capacitățile lor și potențialele limitări în codificarea și recuperarea simțurilor cuvintelor. În acest articol, oferim o analiză cantitativă și calitativă aprofundată a celebrului model BERT în ceea ce privește ambiguitatea lexicală. Una dintre principalele concluzii ale analizei noastre este că BERT poate capta cu precizie distincții de simțuri la nivel înalt, chiar și atunci când un număr limitat de exemple este disponibil pentru fiecare sens de cuvânt. Analiza noastră arată, de asemenea, că, în unele cazuri, modelele lingvistice sunt aproape de rezolvarea dezambiguizării substantivelor cu granule grosiere în condiții ideale în ceea ce privește disponibilitatea datelor de formare și a resurselor de calcul. Cu toate acestea, acest scenariu apare rar în mediul real și, prin urmare, multe provocări practice rămân chiar și în mediul cu granule grosiere. De asemenea, efectuăm o comparație aprofundată a celor două strategii WSD bazate pe modelul lingvistic principal, și anume, reglarea fină și extragerea caracteristicilor, constatând că această abordare din urmă este mai robustă în ceea ce privește părtinirea simțurilor și poate exploata mai bine datele limitate disponibile de formare. De fapt, strategia simplă de extragere a caracteristicilor de mediere a încorporărilor contextualizate se dovedește robustă chiar și utilizând doar trei instruiri\npropoziții pe sens cuvânt, cu îmbunătățiri minime obținute prin creșterea dimensiunii acestor date de antrenament.', 'sr': 'Apstraktički jezički modeli na transformeri uzeli su mnoge polja u NLP olujom. BERT i njegovi derivati dominiraju većinu postojećih kriterija procjene, uključujući one za Disambiguaciju osjetljivog reči (WSD), zahvaljujući njihovoj sposobnosti u uhvativanju semantičnih nuanca u kontekstu. Međutim, još uvek postoji malo znanja o njihovim sposobnostima i potencijalnim ograničenjima u kodiranju i oporavljanju čula riječi. U ovom članku pružamo duboku kvantitativnu i kvalitativnu analizu proslavljenog model BERT-a u vezi leksičke ambiguitete. Jedan od glavnih zaključaka naše analize je da BERT može precizno uhvatiti razlike osjećaja visokog nivoa, čak i kad je dostupno ograničen broj primjera za svaki smisao reči. Naša analiza takođe pokazuje da u nekim slučajevima jezički modeli se približavaju rješavanju disambiguacije pod idealnim uvjetima u smislu dostupnosti podataka i računalnih resursa. Međutim, ovaj scenario se rijetko dešava u stvarnom svijetu i stoga mnogi praktični izazovi ostaju čak i u području određenog zrnca. Također radimo dublje usporedbu dve glavne strategije na jezičkim modelima bazirane na WSD-u, što je to, izvlačenje i izvlačenje funkcija, otkrivanje da je poslednji pristup jači u odnosu na pristrasnost osjećaja i može bolje iskoristiti ograničene dostupne podatke o obuci. Zapravo, jednostavna strategija izvlačenja karakteristika prosječne kontekstualizacije dokazuje da je snažna čak i koristeći samo tri obuke.\nrečenice po smislu riječi, sa minimalnim poboljšanjima koje su dobile povećanjem veličine ovih podataka o obuci.', 'so': "Tusaale ahaan luuqada afka laguu soo wareejiyo waxay ku qaateen duufaan badan oo NLP ku yaal. BERT iyo derivateedu waxay xukuntaan qiimeynta marka badan ee joogta, kuwaas oo ka mid ah waxyaabaha loo qoray qalabka Sense (WSD), waxaana mahad ku leh awooddooda ay qabsadaan nuurada hoose-sensitive. Si kastaba ha ahaatee, weli aqoon yar oo ku saabsan awooddooda iyo xaduudaha suurtagalka ah ee codsiga iyo bogsashada sanooyinka hadalka. Qoraalkan waxan ku qornaa baaritaan aad u dheer oo qiyaas ah oo qiimeyn ah, tusaalka la xumeeyey BERT ee ku saabsan faa'iidada leksikada. Mid ka mid ah dhamaadka ugu muhiimsan baaritaankeenna waa in BERT si saxda ah u qabsan karo kala duwan waxyaabaha heerka sare, xataa haddii lagu helo tusaalooyin aad u xad badan oo hadal kasta ah. Analyskayaguna wuxuu sidoo kale muuqanayaa in marka qaarkood qaababka luuqada ah ay u dhowdahay inay u xafidaan baahida kooxaha aan wax ka qabanayn oo ku jirta shuruudaha fikrada, si ay u helaan macluumaadka waxbarashada iyo hantida xisaabinta. Si kastaba ha ahaatee muuqashadan wax yar ayaa ku dhaca xaaladaha caalamiga ah, sababtaas darteed dhibaatooyin badan oo caadiga ah waxay ku jiraan xittaa barta kooxaha. Sidoo kale waxaynu sameynaa wax hoos u dhigi karnaa labada qoraal oo qoraal ah oo hoose u qoran qoraalka WSD, tusaale ahaan qalabka wanaagga iyo baxsashada gaarka ah, waxaynu ogaanaynaa in qaabka dambe aad looga fududeeyo fikrada dhimiska ah, waxaana ka wanaagsan in lagu isticmaalo macluumaadka waxbarashada ee xadidan ah. Xaqiiqdii, qalabka soo saarista ee ugu fudud waxyaabaha lagu sameeyo ee lagu soo daabacay ayaa caddaynayaa in lagu isticmaalo saddex waxbarasho oo kaliya\nimtixaanka hadalka oo dhan, iyo hagaajinta ugu yaraan marka lagu kordhiyo tirada macluumaadkan waxbarashada.", 'sv': 'Transformerbaserade språkmodeller har tagit många områden i NLP med storm. BERT och dess derivat dominerar de flesta av de befintliga utvärderingsgränserna, inklusive dem för Word Sense Disambiguation (WSD), tack vare deras förmåga att fånga kontextkänsliga semantiska nyanser. Det finns dock fortfarande lite kunskap om deras förmåga och potentiella begränsningar i kodning och återställning av ordsinnen. I den här artikeln ger vi en djupgående kvantitativ och kvalitativ analys av den hyllade BERT-modellen med avseende på lexikal tvetydighet. En av de viktigaste slutsatserna i vår analys är att BERT kan fånga upp sinnesskillnader på hög nivå, även när ett begränsat antal exempel finns tillgängliga för varje ordmening. Vår analys visar också att språkmodeller i vissa fall är nära att lösa grovkorniga substantivskillnader under idealiska förhållanden när det gäller tillgång till utbildningsdata och datorresurser. Detta scenario förekommer dock sällan i verkligheten och därför kvarstår många praktiska utmaningar även i den grovkorniga miljön. Vi gör också en djupgående jämförelse av de två huvudsakliga språkmodellbaserade WSD-strategierna, nämligen finjustering och funktionsutvinning, där vi konstaterar att det senare tillvägagångssättet är mer robust med avseende på sansbias och att det bättre kan utnyttja begränsade tillgängliga träningsdata. Faktum är att den enkla strategin för extraktion av funktioner för att beräkna kontextualiserade inbäddningar visar sig vara robust även med endast tre övningar\nmeningar per ord mening, med minimala förbättringar erhållna genom att öka storleken på dessa träningsdata.', 'si': 'Name BERT සහ එයාගේ විශේෂතාවන් විශේෂ විශේෂ බෙන්ච්මාර්ක් වලින් ප්\u200dරධානය කරනවා, වචන විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ වි නමුත්, ඔවුන්ගේ ක්\u200dරියාත්මක සහ ප්\u200dරතිශ්ණ සීමාවන් ගැන තවමත් පොඩි දන්නවක් තියෙනවා වචන සංවේදනය ස මේ ලේඛනයේදී, අපි ලෙක්සිකල් අවශ්\u200dයතාවක් ගැන ගොඩක් ගොඩක් අවශ්\u200dයය සහ ප්\u200dරශ්නය විශ්ලේෂනයක් දෙනවා. අපේ විශ්ලේෂණයේ ප්\u200dරධාන අවස්ථාවෙන් එක්කෙනෙක් තමයි BERT පුළුවන් විශේෂ අවස්ථාවක් විශේෂ අවස්ථාවක් අල්ලගන් අපේ විශ්ලේෂණය ප්\u200dරකාශ කරනවා කිසිම විදිහට භාෂා මොඩේල් වලින් කෝර්ස් ග්\u200dරේන්ඩ් විශ්ලේෂණය සහ පරීක්ෂණාව සම්බන්ධ විදි නමුත්, මේ සිනාරියෝ ඇත්ත ලෝකයේ සැකසුම් වලින් සිද්ධ වෙන්නේ නැහැ ඒ නිසා සිද්ධ විශ්වාසික ප්\u200dරශ්නයක් ඉන අපි තමයි ප්\u200dරධාන භාෂා මොඩේල් අධාරිත WSD සංයෝජනය දෙන්නේ ගොඩක් ගොඩක් සම්බන්ධතාවක් කරනවා, ඒක තමයි, හොඳ සංයෝජනය සහ සංයෝජනය සඳහා අන්ති ඇත්තටම, සාමාන්\u200dය විශේෂතාවක් නිර්මාණය කරන්නේ සාමාන්\u200dය විශේෂතාවක් සම්බන්ධ විශේෂතාවක් ප්\u200dරයෝජන\nවචන අවශ්\u200dය වචන වචන, අඩුම විශ්වාසයෙන් ලැබෙන අඩුම විශ්වාසයෙන් මේ ප්\u200dරේක්ෂණ දත්ත වැඩ කරන්න.', 'hu': 'Absztrakt Transzformátor alapú nyelvi modellek sok területet vettek át az NLP-ben. A BERT és származékai dominálják a meglévő értékelési referenciaértékek többségét, beleértve a Word Sense Disambiguation (WSD) referenciaértékeit is, köszönhetően a kontextusérzékeny szemantikai árnyalatok rögzítésére képes képességüknek. Azonban még mindig kevés tudás áll rendelkezésre a kódolásban és a szóérzékek visszaállításában rejlő képességeikről és potenciális korlátaikról. Ebben a cikkben mélyreható mennyiségi és minőségi elemzést nyújtunk be az ünnepelt BERT modellről a lexikai kétértelműség tekintetében. Elemzésünk egyik legfontosabb következtetése, hogy a BERT pontosan meg tudja ragadni a magas szintű érzékelési megkülönböztetéseket, még akkor is, ha korlátozott számú példa áll rendelkezésre minden szóérzékre. Elemzésünk azt is feltárja, hogy bizonyos esetekben a nyelvi modellek közel kerülnek a durva szemű főnév egyértelműségének megoldásához, ideális körülmények között a képzési adatok és a számítástechnikai erőforrások rendelkezésre állása szempontjából. Ez a forgatókönyv azonban ritkán fordul elő a valós környezetben, ezért számos gyakorlati kihívás marad még a durva szemcsés környezetben is. Mélyreható összehasonlítást végzünk a két fő nyelvi modell alapú WSD stratégiával, nevezetesen a finomhangolással és a funkciókivonással, megállapítva, hogy ez utóbbi megközelítés erőteljesebb az érzékelési elfogultság tekintetében, és jobban ki tudja használni a korlátozott képzési adatokat. Valójában a kontextuális beágyazások átlagosításának egyszerű funkciókivonási stratégiája robusztusnak bizonyul még csak három tréning használatával is.\nSzónkénti mondatok, minimális fejlesztésekkel, amelyeket az edzési adatok méretének növelésével érhetünk el.', 'ta': 'மாற்று மொழி மாற்று மாதிரி மாதிரிகள் NLP யில் பல புலங்களை புயல் மூலம் எடுத்துள்ளார்கள். BERT மற்றும் அதன் derivatives அதிக மதிப்புகளில் இருக்கும் பெரும்பாலான மதிப்புருக்களை கட்டுப்படுத்துகிறது, வார்த்தை உணர்வு உணர்வுடைய அணுகுகளை பிடித்து அவர However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses.  இந்த கட்டுரையில், நாம் ஒரு ஆழமான அளவு மற்றும் பிரெட்டி மாதிரியை பார்க்கப்பட்டுள்ளோம் லெக்சிக்ஸியான உச்சரிப்பு பற்றி ஒரு  எங்கள் ஆய்வு முக்கிய முடிவு எங்கள் ஆராய்ச்சி சில நிலைகளில் மொழி மாதிரிகள் மாதிரிகளுக்கு நெருங்கி தீர்க்க முடியும் நிலையில் பயிற்சி தரவுகள் மற்றும் கணிப்பு  ஆனால், இந்த காட்சியோ உண்மையான உலக அமைப்புகளில் குறைவாகவே நடக்கும் மற்றும், அதனால், பல செயல்பாடு சவால்கள் தெற்கையான சிகிச்ச இரண்டு மொழி மாதிரி மாதிரி விட்சிடி முறைமையை ஒப்பிடும் ஆழமாக நாம் செயல்படுத்துகிறோம், அதாவது, நன்றாக உபயோகிக்கும் மற்றும் குணங்கள் வெளியேறுதல், புரிந்த உண்மையில், சுலபமான குணங்கள் பிரிப்பு வெளியேற்றும் திட்டம் சராசரியான பொருள்களின் செயல்பாடு மூன்று பயிற்சிய\nஇந்த பயிற்சி தரவின் அளவை அதிகப்படுத்தினால் குறைந்தபட்ச மேம்படுத்தப்பட்ட வாக்கியங்களுக்கு ஒரு வார்த்', 'ur': 'Name BERT اور اس کے ڈریویٹیوں کی اکثریت موجود موجود ارزیابی بنچمبارک کی حکومت کرتی ہیں، یہاں تک کہ کلمات Sense Disambiguation (WSD) کے لئے، ان کی قابلیت کے شکریہ کہ ان کے کنٹنس-حساس سیمنٹی نونس کو پکڑ لیتے ہیں. لیکن ان کے قابلیت اور امکانات حدود کے بارے میں بھی بہت ہی کم علم ہے کہ ان کا کوڈینڈ اور لفظ سنس کے بارے میں۔ اس مقالہ میں ہم ایک گہرے اندھیرے اندھیرے اندھیرے اور کیلوٹیٹی تحلیل دیتے ہیں جن کی جشن کے BERT موڈل کے معاملہ میں لکھی جاتی ہے۔ ہمارے تحلیل کی ایک اصلی نتیجہ یہ ہے کہ BERT بالا سطح سمجھ کے اختلاف کو دقیق پکڑ سکتا ہے، اگرچہ ہر کلمات سمجھ کے لئے ایک تعداد کی مثال موجود ہوتی ہے۔ ہماری تحلیل بھی ظاہر کرتا ہے کہ بعض موقع میں زبان کی نمائندلیاں کورس کے دانے کے ذریعے مغلوب کرنے کے قریب آتے ہیں، یعنی ایڈال شرایط کے اندر، ڈیٹا اور کمپیوٹر کے رسولوں کے موجود ہونے کے مطابق. لیکن یہ سناریو بہت ہی کم دنیا کی تنظیم میں ہوتا ہے اور اسی وجہ سے بہت سی کامل چالیاں اگرچہ کڑی دانے کے تنظیم میں بھی رہتے ہیں۔ ہم نے ان دو اصلی زبان مدل پر بنیاد رکھے ہوئے WSD استراتژی کے مطابق ایک عمیق مقایسہ کر رہے ہیں، یعنی پاکیزہ تنظیم اور فرصت اضافہ کرنا، دیکھ رہے ہیں کہ آخری طریقہ اس طریقہ سے زیادہ مضبوط ہے اور یہ بہتر استراتژی کے مطابق محدود کر سکتا ہے. حقیقت میں، آسان فرصت اٹھانے کا استراتژی متوسط متوسط انڈینگ کے مطابق ثابت ہوتا ہے کہ صرف تین تطابق کے مطابق بھی مضبوط ہے\nکلمات پر احساس، اس ترینس ڈیٹ کی اندازہ بڑھنے کے ذریعہ سے کم ترین سوداگری کے ساتھ۔', 'uz': "Name BERT va uning taʼminlovchilari mavjud qiymatlarni boshqaradi. Bu so'zlar o'zgarishga (WSD) qo'llaniladi. Lekin, ularning imkoniyatlarini kodlash va so'zlar sensorini qayta olish uchun juda qismi yoʻq. Bu maqolada, biz BERT modelini hech qanday qiymati va qualitativ analyzerni anglatamiz. Analysimizning eng asosiy murakkablarimizdan biri BERT haqida o'xshash darajada o'zgarishga ega bo'ladi. Agar har bir so'zlar uchun juda chegara misollar mavjud boʻlsa. Bizning analytikimizni ko'rsatadi, bir necha holatda tilning modellari o'zgarishga qaraydi, ma'lumot va kompyuterning murakkablarini saqlash imkoniyatlarida qo'llanmagan holatlarni o'zgartirib keladi. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting.  Biz bu ikki asosiy tilning asosiy WSD-asosiy modeli strategiyasiga o'xshash o'xshash qilamiz, mana yaxshi suhbat va tayyorlash imkoniyatlarini bajaramiz va keyingi usul bizning tizimi haqida ko'proq o'xshash va bu juda qisqa taʼminlovchi maʼlumotni foydalanishi mumkin. Aslida, oddiy tashkilotni ajratish strategiya o'rtasida o'rtacha o'zgarishlar faqat uchta ta ta'limdan foydalanishini ko'rsatadi.\nso'zlar bir so'zlar ma'lumotning oʻlchamini ko'paytirish mumkin.", 'vi': 'Bản dịch biến hình, hình biến hình, đã có nhiều lĩnh vực trong giải độc tố. BERT và các dẫn xuất của nó thống trị hầu hết các tiêu chuẩn đánh giá tồn tại, bao gồm cả các tiêu chuẩn biến đổi cảm xúc từ từ từ "Thời Báo chí Thời Báo". Tuy nhiên, vẫn có rất ít kiến thức về khả năng và giới hạn tiềm năng của họ trong việc mã hóa và khôi phục các giác quan từ. Trong bài báo này, chúng tôi cung cấp một cuộc phân tích về chất lượng và chất lượng sâu sắc về mô hình cây Berlin nổi tiếng về sự tối đa ngôn ngữ. Một trong những kết luận quan trọng nhất của chúng ta là BERT có thể nắm bắt chính xác những sự khác biệt cấp cao, thậm chí khi có một số ví dụ giới hạn cho mỗi từ có ý nghĩa. Phân tích của chúng tôi cũng cho thấy rằng trong một số trường hợp các mô hình ngôn ngữ gần như giải quyết sai lệch danh từ sâu sắc dưới những điều kiện lý tưởng về nguồn cung cấp dữ liệu huấn luyện và phương tiện tính to án. Tuy nhiên, viễn cảnh này hiếm khi xảy ra trong thế giới thực và do đó, vẫn còn nhiều thử thách thực tế ngay cả trong môi trường sắc đoạn. Chúng tôi cũng tiến hành một cuộc so sánh sâu với hai chiến lược lớn theo kiểu ngôn ngữ, dựa trên, cụ thể là, độ chỉnh sửa và khai thác các nét đặc trưng, phát hiện rằng phương pháp này vững chắc hơn về khuynh hướng cảm xúc và nó có thể khai thác tốt hơn các dữ liệu tập luyện có hạn chế. Thực tế, chiến lược khai thác các đặc trưng đơn giản hơn việc nhận giá định các tình huống có vẻ vững chắc thậm chí chỉ bằng ba huấn luyện\ncâu cho từng chữ một, với những cải tiến tối thiểu được xác định bằng cách tăng kích thước của dữ liệu đào tạo này.', 'bg': 'Абстрактни трансформаторни езикови модели са завзели много области в НЛП от буря. BERT и неговите производни доминират по-голямата част от съществуващите референтни показатели за оценка, включително тези за дисамбигиране на чувството на думи (WSD), благодарение на способността им да улавят чувствителни към контекста семантични нюанси. Все още има малко познания за техните възможности и потенциални ограничения при кодиране и възстановяване на думите сетива. В тази статия предлагаме задълбочен количествен и качествен анализ на прочутия модел по отношение на лексикалната двусмисленост. Едно от основните заключения от нашия анализ е, че може точно да улови различия от смисъла на високо ниво, дори когато има ограничен брой примери за всяко значение на думата. Анализът ни показва също, че в някои случаи езиковите модели са близо до решаването на грубозърнестото разграничаване на съществителното при идеални условия по отношение на наличието на данни за обучение и изчислителни ресурси. Този сценарий обаче рядко се случва в реални условия и следователно много практически предизвикателства остават дори в грубозърнестата обстановка. Също така извършваме задълбочено сравнение на двете основни стратегии на езиковия модел, а именно фина настройка и извличане на функции, като установим, че последният подход е по-стабилен по отношение на предразсъдъка на сетивата и може по-добре да използва ограничените налични данни за обучение. Всъщност, простата стратегия за извличане на функции за усредняване на контекстуализираните вграждания се оказва стабилна дори при използване само на три обучения\nизречения на дума смисъл, с минимални подобрения, получени чрез увеличаване на размера на тези данни за обучение.', 'hr': 'Uzeli su mnoge polja u NLP-u olujom na osnovu transformera. BERT i njegovi derivati dominiraju većinu postojećih kriterija procjene, uključujući one za Disambiguaciju osjećaja riječi (WSD), zahvaljujući njihovoj sposobnosti u uhvaćenju semantičnih nuanca konteksta. Međutim, još uvijek postoji malo znanja o njihovim sposobnostima i potencijalnim ograničenjima u kodiranju i oporavljanju čula riječi. U ovom članku pružamo duboku kvantitativnu i kvalitativnu analizu proslavljenog modela BERT-a u pogledu leksičke ambiguitete. Jedan od glavnih zaključaka naše analize je da BERT može precizno uhvatiti razlike osjećaja visokog razina, čak i kada je dostupno ograničen broj primjera za svaki osjećaj riječi. Naša analiza također pokazuje da se u nekim slučajevima jezički modeli približavaju rješavanju disambiguacije pod idealnim uvjetima u smislu dostupnosti podataka i računalnih resursa. Međutim, ovaj scenarij se rijetko pojavljuje u stvarnom svijetu i stoga mnogi praktični izazovi ostaju čak i u području zrnca. Također provodimo dublje usporedbu dvije glavne strategije WSD-a na temelju jezika, a to je, izvlačenje i izvlačenje funkcija, otkrivajući da je posljednji pristup jači u odnosu na pristrasnost osjećaja i može bolje iskoristiti ograničene dostupne podatke o obuci. Zapravo, jednostavna strategija izvlačenja karakteristika prosječne kontekstualizacije dokazuje da je snažna čak i koristeći samo tri obuke\nrečenice po smislu riječi, s minimalnim poboljšanjima koje su dobile povećanjem veličine podataka o obuci.', 'nl': 'Abstract Transformer-gebaseerde taalmodellen hebben veel gebieden in NLP door storm ingenomen. BERT en zijn derivaten domineren de meeste bestaande evaluatiebenchmarks, waaronder die voor Word Sense Disambiguation (WSD), dankzij hun vermogen om contextgevoelige semantische nuances vast te leggen. Er is echter nog weinig kennis over hun mogelijkheden en mogelijke beperkingen in het coderen en herstellen van woordzintuigen. In dit artikel geven we een diepgaande kwantitatieve en kwalitatieve analyse van het gevierde BERT-model met betrekking tot lexicale ambiguïteit. Een van de belangrijkste conclusies van onze analyse is dat BERT onderscheidingen op hoog niveau nauwkeurig kan vastleggen, zelfs als er voor elke woordzin een beperkt aantal voorbeelden beschikbaar is. Onze analyse toont ook aan dat in sommige gevallen taalmodellen dicht bij het oplossen van grove naamwoorden-discambiguatie onder ideale omstandigheden in termen van beschikbaarheid van trainingsgegevens en rekenmiddelen komen. Dit scenario komt echter zelden voor in de echte wereld en daarom blijven er ook in de grove omgeving veel praktische uitdagingen bestaan. We voeren ook een diepgaande vergelijking uit van de twee belangrijkste taal model gebaseerde WSD strategieën, namelijk fine-tuning en feature extraction, waarbij we vaststellen dat de laatste aanpak robuuster is met betrekking tot sense bias en het beter kan profiteren van beperkte beschikbare trainingsgegevens. Sterker nog, de eenvoudige feature extraction strategie van het gemiddelde van contextualiseerde embeddings blijkt robuust zelfs met slechts drie trainingen\nzinnen per woordzin, met minimale verbeteringen verkregen door de grootte van deze trainingsgegevens te vergroten.', 'de': 'Abstract Transformer-basierte Sprachmodelle haben viele Felder in NLP im Sturm erobert. BERT und seine Derivate dominieren die meisten existierenden Bewertungsbenchmarks, auch für Word Sense Disambiguation (WSD), dank ihrer Fähigkeit kontextsensitive semantische Nuancen zu erfassen. Allerdings gibt es noch wenig Wissen über ihre Fähigkeiten und potenziellen Einschränkungen bei der Kodierung und Wiederherstellung von Wortsinnen. In diesem Artikel liefern wir eine eingehende quantitative und qualitative Analyse des gefeierten BERT-Modells hinsichtlich lexikalischer Ambiguität. Eine der wichtigsten Schlussfolgerungen unserer Analyse ist, dass BERT hochrangige Sinnesunterschiede präzise erfassen kann, auch wenn für jeden Wortsinn eine begrenzte Anzahl von Beispielen verfügbar ist. Unsere Analyse zeigt auch, dass Sprachmodelle in einigen Fällen der Lösung grobkörniger Substantivdisambiguation unter idealen Bedingungen in Bezug auf die Verfügbarkeit von Trainingsdaten und Rechenressourcen nahe kommen. Dieses Szenario tritt jedoch selten in realen Umgebungen auf und so bleiben auch im grobkörnigen Setting viele praktische Herausforderungen bestehen. Wir führen auch einen detaillierten Vergleich der beiden Hauptsprachenmodell-basierten WSD-Strategien durch, nämlich Feinabstimmung und Feature-Extraktion, wobei festgestellt wird, dass letzterer Ansatz robuster in Bezug auf Sinnesbias ist und begrenzte verfügbare Trainingsdaten besser nutzen kann. Tatsächlich erweist sich die einfache Feature-Extraktion-Strategie der Mittelung kontextualisierter Einbettungen auch bei nur drei Trainings als robust\nSätze pro Wortsinn, mit minimalen Verbesserungen durch Vergrößerung der Größe dieser Trainingsdaten.', 'da': 'Transformer-baserede sprogmodeller har taget mange områder i NLP med storm. BERT og dets derivater dominerer de fleste af de eksisterende evalueringsbenchmarks, herunder dem for Word Sense Disambiguation (WSD), takket være deres evne til at fange kontekstfølsomme semantiske nuancer. Der er dog stadig lidt viden om deres evner og potentielle begrænsninger i kodning og gendannelse af ord sanser. I denne artikel giver vi en dybdegående kvantitativ og kvalitativ analyse af den berømte BERT-model med hensyn til leksiksk tvetydighed. En af de vigtigste konklusioner af vores analyse er, at BERT nøjagtigt kan fange sanseforskelle på højt niveau, selv når der er et begrænset antal eksempler til rådighed for hvert ord sans. Vores analyse afslører også, at sprogmodeller i nogle tilfælde er tæt på at løse grovkornede substantivforskelle under ideelle betingelser med hensyn til tilgængelighed af uddannelsesdata og computerressourcer. Dette scenarie forekommer dog sjældent i den virkelige verden, og derfor er der mange praktiske udfordringer, selv i de grovkornede omgivelser. Vi udfører også en dybdegående sammenligning af de to hovedsprogsmodellbaserede WSD-strategier, nemlig finjustering og feature extraction, idet vi konstaterer, at sidstnævnte tilgang er mere robust med hensyn til sanselighed og bedre kan udnytte begrænsede tilgængelige træningsdata. Faktisk viser den enkle strategi for udtrækning af funktioner med gennemsnitlig kontekstualiserede indlejringer sig robust selv ved hjælp af kun tre træninger\nSætninger pr. ordsans, med minimale forbedringer opnået ved at øge størrelsen af disse træningsdata.', 'id': 'Model bahasa berasaskan Transformer Abstract telah mengambil banyak bidang di NLP oleh badai. BERT dan derivatnya mendominasi kebanyakan benchmarks evaluasi yang ada, termasuk benchmarks untuk Word Sense Disambiguation (WSD), berkat kemampuan mereka dalam menangkap nuansi semantis sensitif konteks. Namun, masih sedikit pengetahuan tentang kemampuan mereka dan batasan potensial dalam pengekodan dan pemulihan sensor kata. Dalam artikel ini, kami menyediakan analisis kuantitatif dan kualitatif yang mendalam dari model BERT yang dirayakan terhadap ambiguitas lexik. Salah satu kesimpulan utama dari analisis kami adalah bahwa BERT dapat menangkap dengan akurat perbedaan sensor tinggi, bahkan ketika jumlah terbatas contoh tersedia untuk setiap sensor kata. Analisis kami juga mengungkapkan bahwa dalam beberapa kasus model bahasa mendekati penyelesaian ketidakambiguasi nama-nama besar dalam kondisi ideal dalam termasuk disponibilitas data pelatihan dan sumber daya komputer. Namun, skenario ini jarang terjadi dalam pengaturan dunia nyata dan, oleh itu, banyak tantangan praktis bahkan tetap dalam pengaturan yang kasar. Kami juga melakukan perbandingan dalam-dalam dari dua strategi WSD berdasarkan model bahasa utama, yaitu, penyesuaian dan ekstraksi fitur, menemukan bahwa pendekatan terakhir lebih kuat terhadap bias perasaan dan dapat lebih baik mengeksploitasi data pelatihan tersedia terbatas. Sebenarnya, strategi ekstraksi karakteristik sederhana dari rata-rata penerbangan kontekstualisasi membuktikan kuat bahkan menggunakan hanya tiga pelatihan\nkalimat per kata, dengan peningkatan minimal yang diperoleh dengan meningkatkan ukuran data latihan ini.', 'sw': 'Mfano wa lugha yenye asili ya zamani umechukua maeneo mengi katika NLP kwa dhoruba. BERT na vifaa vyake vinavyoongoza misingi mengi ya tathmini zilizopo, ikiwa ni pamoja na wale ambao ni kwa ajili ya uchochezi wa Sensi (WSD), shukrani kwa uwezo wao katika kuchukua mabomu ya kimataifa yenye hisia. Hata hivyo, bado hakuna maarifa kidogo kuhusu uwezo wao na vizuizi vya uwezekano katika kupunguza na kutambua hisia za maneno. Katika makala hii, tunatoa uchambuzi wa kina kiasi cha kina na kina cha uchambuzi wa modeli ya BERT inayosherehekea kuhusu uchochezi wa kimapenzi. Moja ya matokeo muhimu ya uchambuzi wetu ni kwamba BERT anaweza kupata tofauti za kiwango kikubwa, hata kama mifano mipango mingi yanapatikana kwa kila neno. Uchambuzi wetu pia unaonyesha kuwa katika baadhi ya matukio mengine ya lugha hukaribia kutatua hali ya kutokuwepo kwa maendeleo yasiyo na mipango ya bara katika mazingira ya mawazo yanayohusu upatikanaji wa taarifa za mafunzo na rasilimali za kompyuta. Hata hivyo, tukio hili linatokea nadra katika mazingira ya dunia halisi na hivyo, changamoto nyingi za kihalisi bado zinabaki katika mazingira ya bara. Pia tunafanya mbinu mbili za mitindo ya lugha yenye msingi wa mtandao wa WSD, namely, mafunzo mazuri na utoaji wa tabia, tunagundua kuwa mbinu za mwisho ni dhahiri zaidi kuhusu upendeleo wa maana na inaweza kutumia zaidi taarifa za mafunzo. Kiukweli, mkakati rahisi wa utekelezaji wa wastani wa maeneo yanayoendelea unaonyesha ubakaji hata kwa kutumia mafunzo matatu tu tu\nsentensi kwa maneno yenye maana, na maendeleo madogo yaliyopata kwa kuongeza ukubwa wa takwimu hizi za mafunzo.', 'ko': '추상 변환기를 기반으로 한 언어 모델은 이미 NLP의 많은 영역을 휩쓸었다.위아래 문장의 민감한 의미의 미세한 차이를 포착할 수 있기 때문에 BERT와 그 파생물은 단어의 의미 분리(WSD) 기준을 포함한 대부분의 기존 평가 기준을 주도했다.그러나 그것들의 인코딩과 의미 회복 능력과 잠재적 한계에 대해 사람들은 아직 잘 모른다.이 글에서 우리는 유명한 BERT 모델에 대해 심도 있는 정량과 정성 분석을 진행하였다.우리가 분석한 주요 결론은 단어마다 의미가 유한한 예만 있어도 버트는 고급 의미의 차이를 정확하게 포착할 수 있다는 것이다.우리의 분석에 의하면 어떤 상황에서 훈련 데이터와 계산 자원의 가용성을 보면 언어 모델은 이상적인 조건에서 굵은 입도 명사의 분열 문제를 해결하는 데 가깝다.그러나 이런 상황은 현실 환경에서 매우 드물기 때문에 굵은 입도 환경에서도 여전히 많은 실제 도전이 존재한다.우리는 또한 두 가지 주요 언어 모델을 바탕으로 하는 WSD 전략, 즉 마이크로스피커와 특징 추출을 깊이 비교한 결과 감지 편차가 더욱 안정적이고 유한한 사용 가능한 훈련 데이터를 더욱 잘 활용할 수 있음을 발견했다.사실상 세 번의 훈련만 사용해도 평균 상하문에 박힌 간단한 특징 추출 전략은 노봉성을 증명했다\n모든 단어의 문장 의미는 훈련 데이터의 크기를 늘려 최소한의 개선을 얻을 수 있다.', 'fa': 'مدل\u200cهای زبانی که بر اساس تبدیل\u200cکننده\u200cی تبدیل\u200cکننده\u200cها ساخته شده\u200cاند، به طوفان بسیاری از زمینه\u200cها در NLP گرفته\u200cاند. BERT و تولید\u200cهایش بیشترین مقدار ارزیابی موجود را تسلیم می\u200cکنند، شامل آن\u200cها برای ناپدید کردن کلمه Sense Disambiguation (WSD) به سزای توانایی\u200cهایشان در دستگیر نونس\u200cهای semantic-sensitive محیط. ولی هنوز دانش کمی در مورد توانایی\u200cهایشان و محدودیت\u200cهای پتانسیل در رمزبندی و بازیابی احساسات کلمه وجود دارد. در این مقاله، ما یک تحلیل تعدادی و کیفیت عمیق از مدل BERT جشن گرفته را در مورد غیرقابلیت زبانی پیشنهاد می کنیم. یکی از نتیجه\u200cهای اصلی تحلیل ما این است که BERT می\u200cتواند دقیقا تفاوت\u200cهای حس بالا را بگیرد، حتی هنگامی که تعداد محدودیت مثال برای هر احساس کلمه موجود باشد. تحلیل ما همچنین نشان می دهد که در بعضی موارد مدلهای زبان نزدیک است به حل نامبوغگویی از اسم\u200cهای غذایی که به عنوان شرایط ایده\u200cای در مورد دسترسی داده\u200cهای آموزش و منابع محاسبات است. ولی این سناریو کم کم در تنظیمات دنیای واقعی اتفاق می افتد و بنابراین چالش های عملی بیشتر حتی در تنظیمات غذای غذایی باقی ماند. ما همچنین یک مقایسه عمیق از دو استراتژی\u200cهای WSD بر اساس مدل زبان اصلی انجام می\u200cدهیم، که یعنی استراتژی\u200cهای خوب تنظیم و ویژه\u200cهای ویژه\u200cای، و می\u200cفهمیم که این دستور آخرین با احساس ضعیفه\u200cای قوی\u200cتر است و می\u200cتواند اطلاعات آموزش محدودیت را استفاده کند در حقیقت، استراتژی ساده\u200cی استراتژی استراتژی\u200cهای استراتژی\u200cهای متوسط\u200cسازی\u200cها ثابت می\u200cکند که حتی با استفاده از فقط سه تمرین استراتژی ثابت می\u200cکند\nجمله\u200cها به عنوان احساس کلمه، با بهترین کمی که با افزایش اندازه این داده\u200cهای آموزش به دست آورده می\u200cشوند.', 'tr': "Abstrakt terjime edilen dil nusgalary NLP'da puruslyk bilen köp sahypa alyp gitdiler. BERT we onuň çözümleri bar değerlendirmeleriň köp bölegi, Word Sense Disambiguation (WSD) karakterlerine dahil edilen çözümlerden dolayı, kontekst hassasiyetli bir semantik nuans yakalamak üçin ukyplaryna teşekkürler. Ýöne, söz duýgulary hakynda ýene-de olaryň ukyplary we potensial çykyşlary hakynda biraz bilim bar. Bu makalasda, leksiýa ýok bolmagy barada bellenilýän BERT nusgynyň derinlikli we kwalitet çözümlerini temin edip otyrýarys. Biziň analizimiziň esasy çözümlerinden biri BERT-iň ýokary dereje duýgylyk tapawutlaryny düzgün almak üçin, hatda her söz duýgylygy üçin az sany örnekler bar. Biziň analýusymyz käbir wagtlarda dil modelleriň, daýlary we hasaplamak resurslaryň bar bolmagy üçin ideal şertlerde çözmesini ýakynlaşýar. Ýöne bu senaryň dünýä gurultaýlarynda käwagt görünýär. Şonuň üçin birnäçe praktik kynçylyklar ýok çykyşlyklarda hem galýar. Biz hem esasy dil modinde WSD stratejiýasynyň derinliklerini daşyrýarys, diýmek bolsa, iňki taýýarlama we özellikleri çykarmak üçin, soňky approach duýgulama tertibine gelmegi barada has güýçli däldir we bu durum ulaganyň bar maglumatlaryny gowy ulanyp biler. Aslyna seretseň, senediň önümlerini golaýlaşdyrmak üçin esasy çykyş strategiýasy diňe üç okuwçylygy ulanyp robustydyr.\nsözler söz duýguny bilen, bu okuw maglumatynyň ölçüsini artdyrmak bilen azajyk gelişmeleri bilen.", 'af': "Name BERT en sy afgeleide domineer die meeste van die bestaande evalueringsbenchmarke, insluitend die vir Woord Sense Disambiguation (WSD), dankie aan hulle moontlikheid in die opvang van konteks-sensitief semantiese nuans. Maar daar is nog klein kennis oor hul kapasiteite en potensiele beperking in enkodering en herstelling van woorde senses. In hierdie artikel verskaf ons 'n in-diepte kvantitatiewe en kwalitatiewe analisie van die gesnede BERT-model met betrekking tot leksiese onbedienheid. Een van die hoofde conclusies van ons analisie is dat BERT kan presies hoë vlak sin verskilte opneem, selfs wanneer 'n beperkte aantal voorbeelde beskikbaar is vir elke woord sin. Ons analisie verduidelik ook dat in sommige gevalle taal-modele naby kom om die oplossing van kors-graan-nuwe-ontsammings onder ideele voorwaardes in terms van beskikbaarheid van onderwerp data en rekenaar hulpbronne te verlos. Maar hierdie scenario is selfs gereeld in werklike wêreld instellings, en daarom bly baie praktiese uitdagings selfs in die kruipende instelling. Ons doen ook 'n in-diepte vergelyking van die twee hoofde taal model-gebaseerde WSD strategies, bedoel, fyn-tuning en funksie uittrekking, te vind dat die laaste toegang meer kragtiger is met betrekking na sens bias en dit kan beter gebruik beperk beskikbare optrekking data. In werklikheid, die eenvoudige funksie uittrekking strategie van gemiddelde kontekstualiseerde inbettings bevestig sterk selfs om slegs drie optrekking te gebruik\nvoorwerpe per woord sin, met minimale verbeteringe wat deur die grootte van hierdie onderwerp data te vergroot word.", 'am': 'የፊደል ቋንቋ ምሳሌዎች በNLP በዐውሎ ነፋስ ብዙ እርሻዎችን ወሰዱ። BERT እና ዋነቶች የአሁኑን ማስታወቂያ አካባቢዎች፣ ለቃላት የሲኒስ አፍላጎት (WSD) እና የአካባቢው ሰነፎችን በመያዝ መብት አመሰግናለሁ፡፡ ነገር ግን ምንም እንኳ የቃላትን ድምፅ ማድረግ እና የችሎታቸውን እና የቻልነታቸውን ግንኙነት ጥቂት እውቀት አለ፡፡ በዚህ ጽሑፍ ውስጥ የBERT ሞዴል በሚታወቀው የልስክሲካዊ ጉዳይ ላይ በሚያስፈልገው የጥልቅ እና በተመሳሳይ እናሳውቃለን፡፡ በአስተማርነታችን መጀመሪያ ፍጻሜዎች አንዱ BERT የደረጃ ልዩ ልዩነትን ያስተካክላል፡፡ ምንም እንኳ ለሁሉም ቃላት የተደረገ ምሳሌዎች ቢገኙ እንኳን፡፡ Analysያችን ደግሞ የሚያሳየው የቋንቋ ምሳሌዎች በአሳብ አካባቢ ክፍል እና የመጠቀም ዳራዎችን እና የቁጥጥር ሀብትን ለማግኘት ሲቀርቡ ነው፡፡ ምንም እንኳን ይህ ስዕይት በሀይማዊ ዓለም አካባቢዎች ውስጥ ጥቂት ነው፣ ስለዚህም፣ ብዙ የውጤት ጥያቄዎች በኮርማዊ አካባቢ ውስጥ ይኖራሉ፡፡ በሁለቱ መጀመሪያ ቋንቋዎች የWSD ተቃውሞ፣ ጥሩ ማቀናቀል እና ምርጫዎችን ማሳየት እና ጥልቅ ጥልቅ እናደርጋለን፡፡ እውነቱም፣ ቀላል የአፍሪካ ውጤት ማውጣት ተቃውሞ የሚቆጠሩ አካባቢዎች በሦስት ትምህርት ብቻ ሲጠቀም ይታያል፡፡\nየንግግር ቃላት በማስተካከል፣ የዚህን ትምህርት ዳታ መጠን በመጨመር በሚያበዛ ትንሽ ትክክለኛ ማድረግ ነው፡፡', 'sq': 'Modelet e gjuhës abstrakte me bazë në Transformer kanë marrë shumë fusha në NLP me stuhi. BERT dhe derivatet e saj mbizotërojnë shumicën e niveleve ekzistuese të vlerësimit, duke përfshirë ato për zhdukjen e kuptimit të fjalëve (WSD), falë aftësisë së tyre në kapjen e nuances semantike të ndjeshme nga konteksti. Megjithatë, ka ende pak njohuri rreth aftësive të tyre dhe kufizimeve të mundshme në kodimin dhe rimëkëmbjen e ndjenjave të fjalës. Në këtë artikull, ne ofrojmë një analizë të thellë kuantitative dhe kualitative të modelit të famshëm BERT lidhur me dyshimin lexik. Një nga përfundimet kryesore të analizës sonë është se BERT mund të kapë saktësisht dallime të sensit të nivelit të lartë, edhe kur një numër i kufizuar shembuj është në dispozicion për çdo kuptim fjalësh. Analiza jonë zbulon gjithashtu se në disa raste modelet gjuhësore vijnë pranë zgjidhjes së çambiguarisë së emrave të grumbulluara nën kushte ideale lidhur me dispozicionin e të dhënave të trajnimit dhe burimeve kompjuterike. Megjithatë, ky skenar rrallë ndodh në ambientet e botës reale dhe kështu, shumë sfida praktike mbeten edhe në ambientet e grumbulluara. Ne kryejmë gjithashtu një krahasim të thellë të dy strategjive të WSD-së bazuar në model in kryesor të gjuhës, veçan ërisht, rregullimin dhe nxjerrjen e karakteristikave, duke gjetur se qasja e fundit është më e fortë lidhur me paragjykimin e ndjenjave dhe mund të shfrytëzojë më mirë të dhënat e kufizuara të trajnimit në dispozicion. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training\nme përmirësime minimale të arritura duke rritur madhësinë e këtyre të dhënave të trainimit.', 'hy': 'Աբստրակտ տրանսֆերմերների հիմնված լեզվի մոդելները շատ դաշտեր են վերցրել ՆԼՊ-ում փոթորիկի պատճառով: BERT-ը և դրա արտադրյալները գերիշխում են գոյություն ունեցող գնահատման համեմատական նշանների մեծամասնությամբ, ներառյալ Word Sense Discount (Word Sense Discount) նշանները, շնորհիվ նրանց հնարավորության վերցնել կոնտեքստի զգայուն սեմանտիկ Այնուամենայնիվ, դեռևս քիչ գիտելիք կա նրանց ունակությունների և պոտենցիալ սահմանափակումների մասին բառերի զգայարանների կոդավորման և վերականգնման մեջ: Այս հոդվածի մեջ մենք ներկայացնում ենք հայտնի BER մոդելի խորը քանակական և որակային վերլուծություն լեքսիկական անորոշակիության հետ կապված: Մեր վերլուծության հիմնական եզրակացություններից մեկն այն է, որ BER-ը կարող է ճշգրիտ ընկալել բարձր մակարդակի զգայարանների տարբերակներ, նույնիսկ երբ բառերի զգայարանների համար հասանելի է սահմանափակ քանակ օրինակներ: Մեր վերլուծությունը նաև ցույց է տալիս, որ որոշ դեպքերում լեզվի մոդելները մոտ են լուծելու խրթին հատուկ անվանումների բացահայտությունը իդեալական պայմաններում՝ վերապատրաստության տվյալների և համակարգչային ռեսուրսների առումով: Այնուամենայնիվ, այս սցենարիան հազվադեպ է տեղի ունենում իրական աշխարհի միջավայրում, և հետևաբար շատ գործնական մարտահրավերներ դեռևս գոյություն ունեն նույնիսկ դաժան հատուկ միջավայրում: Մենք նաև խորը համեմատություն ենք կատարում երկու հիմնական լեզվի մոդելներից հիմնված աշխարհային զարգացման տեխնոլոգիաների հետ, հատկապես, բարելավման և առանձնահատկությունների վերացման, հայտնաբերելով, որ վերջին մոտեցումը ավելի ուժեղ է զգայական կողմնականության հարցում, և այն ավելի Իրականում, ընդհանուր կոնտեքստոլիզացված ներդրումների պարզ առանձնահատկությունների վերացման ռազմավարությունը պարզվում է, որ հզոր է նույնիսկ օգտագործելով միայն երեք ուսուցման\nբառի իմաստը բառի մեջ բացատրված նախադասություններով, որոնք ստացվում են նվազագույն բարելավումներով՝ աճելով այս ուսումնասիրության տվյալների չափը:', 'az': 'Abstrakt Transformer-tabanlı dil modelləri NLP içində fırtına vasitəsilə çox sahələr alırlar. BERT və onun tükənmələri mevcut değerlendirmələrin çoxunu, Word Sense Disambiguation (WSD) ilə birlikdə yazılmış kəlmələrin çoxuna hökmranlıq edirlər. Ancaq onların kodlama və söz duyguları barəsində daha az bilgi var. Bu məlumatda, leksik qüvvəti haqqında qeyd edilmiş BERT model in in çətinlikli kvantitatlı və kvalitatlı analizi təmin edirik. Bizim analizimizin ən böyük sonuçlarından biri, BERT hər kəlmə hissəsi üçün çox sınırlı nümunələr mümkün olmasına rağmen yüksək seviyyətli hiss fərqliyini tutub saxlayar. Bizim analizimiz də belə göstərir ki, bəzi vaxtlarda dil modelləri ideal şərtlərin təhsil və hesaplama resurslarının faydalanması haqqında çox çəkilməyə yaxınlaşır. Ancaq bu scenario həqiqət dünya tərzlərində az qalır və buna görə də çoxlu praktik çətinliklərdə hətta çəkilir. Biz həmçin in iki ana dil modeli olan WSD stratejilərinin derinlikləri ilə qarşılaşdırırıq, yani, gözəl düzəltmə və özellikləri çıxartma, sonuncusu tərzim hiss tərzlərinə qarşı daha qüvvətli olduğunu və bu, mümkün tərzim məlumatlarını daha yaxşı istifadə edə bilər. Əslində, hətta üç təhsil istifadə etmək üçün çox asan təhsil çıxarma stratejisi\nbu təhsil məlumatının böyüklüyünü artırmaq üçün az təhsil edilən cümlələr ilə söz anlayışında.', 'cs': 'Abstrakt Jazykové modely založené na transformátorech zabraly mnoho oblastí NLP bouřkou. BERT a jeho deriváty dominují většině stávajících hodnotících benchmarků, včetně těch pro Word Sense Disambiguation (WSD), díky jejich schopnosti zachytit kontextově citlivé sémantické nuance. Nicméně stále existuje málo znalostí o jejich schopnostech a potenciálních omezeních v kódování a obnově slovních smyslů. V tomto článku podáváme hloubkovou kvantitativní a kvalitativní analýzu slavného modelu BERT s ohledem na lexikální nejednoznačnost. Jedním z hlavních závěrů naší analýzy je, že BERT dokáže přesně zachytit rozlišení smyslů na vysoké úrovni, i když je k dispozici omezený počet příkladů pro každý slovní smysl. Naše analýza také ukazuje, že jazykové modely se v některých případech blíží řešení hrubozrnného podstatného rozjasnění za ideálních podmínek z hlediska dostupnosti tréninkových dat a výpočetních zdrojů. Tento scénář se však v reálném prostředí vyskytuje zřídka, a proto mnoho praktických výzev zůstává i v hrubozrnném prostředí. Dále provádíme hloubkové srovnání dvou hlavních jazykových modelových strategií WSD, konkrétně jemného ladění a extrakce funkcí, zjišťujeme, že tento druhý přístup je robustnější s ohledem na smyslové zaujatosti a může lépe využít omezené dostupné tréninková data. Jednoduchá strategie extrakce funkcí průměru kontextualizovaných vložení je ve skutečnosti robustní i při použití pouze tří školení\nvěty na slovní smysl, s minimálními zlepšeními získanými zvětšením velikosti těchto tréninkových dat.', 'bn': 'ভিত্তিক ভিত্তিক ভাষার মডেল এনএলপিতে অনেক ক্ষেত্র গ্রহণ করেছে। বের্ট এবং এর অভিভাবকরা বিদ্যমান মূল্যের বেশীরভাগ মূল্যবোধের মাধ্যমে ক্ষমতা প্রদান করেছে, যাদের মধ্যে রয়েছে শব্দ সেন্স বিভ্রান্তিকর বিভ্রান্তিকর বিভ তবে তাদের ক্ষমতা এবং সম্ভাব্য সীমাবদ্ধতা সম্পর্কে এখনও কিছুটা জানা যাচ্ছে না শব্দের সংক্রান্ত সংক্রান এই প্রবন্ধে আমরা গভীর গভীর পরিমাণ এবং পরিমাণ বিবের্টি মডেলের বিশ্লেষণ প্রদান করি লেক্সিক্সিয়াল গুরুত্বের ব্যাপারে। আমাদের বিশ্লেষণের একটি প্রধান সমাপ্তি হচ্ছে যে বিরেটি সঠিকভাবে উচ্চস্তরের মানসিক বৈষম্যের পার্থক্য গ্রহণ করতে পারে, এমনকি যদি প্রত্ আমাদের বিশ্লেষণ প্রকাশ করেছে যে কিছু কিছু ক্ষেত্রে ভাষার মডেল কাছে কোর্স-গ্রেফতার নির্দিষ্ট বিভ্রান্তির সমাধানের কাছে এসেছে যে  তবে এই দৃশ্য বাস্তবতায় খুব কম ঘটছে এবং এর ফলে অনেক বাস্তবতার চ্যালেঞ্জ এমনকি সার্ক গ্রেফতারের সেটেও বেশী চ্যালেঞ্জ আছে। আমরা এই দুই প্রধান ভাষার মডেল ভিত্তিক উইএসডি কৌশলের তুলনায় গভীরভাবে তুলনা করি, যেখানে আমরা আবিষ্কার করি যে পরবর্তী পদক্ষেপ অনুভূতির ব্যাপারে আরো বেশী ধারাবাহিক এবং  বাস্তবতা হচ্ছে, গড়ে প্রতিযোগিতায় প্রবেশ করার সাধারণ বৈশিষ্ট্য নির্বাচন কৌশল প্রমাণ করে, এমনকি তিনটি প্রশিক্ষণ ব্যবহার\nএই প্রশিক্ষণের তথ্যের আকার বৃদ্ধি করার মাধ্যমে প্রতি শব্দের প্রতিটি বাক্যের মাধ্যমে নিম্ন উন্নতির মাধ', 'bs': 'Apstraktički jezički modeli na transformeru uzeli su mnoge polja u NLP olujom. BERT i njegovi derivati dominiraju većinu postojećih kriterija procjene, uključujući one za Disambiguaciju osjećaja riječi (WSD), zahvaljujući svojoj sposobnosti u uhvativanju semantičnih nuanca konteksta. Međutim, još uvijek nema znanja o njihovim sposobnostima i potencijalnim ograničenjima u kodiranju i oporavljanju čula riječi. U ovom članku pružamo duboku kvantitativnu i kvalitativnu analizu proslavljenog modela BERT-a u pogledu leksičke ambiguitete. Jedan od glavnih zaključaka naše analize je da BERT može precizno uhvatiti razlike osjećaja visokog nivoa, čak i kad je dostupno ograničen broj primjera za svaki osjećaj riječi. Naša analiza također pokazuje da se u nekim slučajevima jezički modeli približavaju rješavanju disambiguacije pod idealnim uvjetima u smislu dostupnosti podataka i računalnih resursa. Međutim, ovaj scenarij se rijetko pojavljuje u stvarnom svijetu i stoga mnogi praktični izazovi ostaju čak i u okruženju zrnca. Također provodimo dublje usporedbu dvije glavne strategije WSD-a na jezičkom modelu, a to je, izvlačenje i izvlačenje funkcija, otkrivajući da je poslednji pristup jači u vezi s osjećajnim predrasudama i da može bolje iskoristiti ograničene dostupne podatke o obuci. Zapravo, jednostavna strategija izvlačenja karakteristika prosječne kontekstualizacije dokazuje da je snažna čak i koristeći samo tri obuke.\nrečenice po smislu riječi, s minimalnim poboljšanjima koje su dobile povećanjem veličine podataka o obuci.', 'et': 'Transformeritel põhinevad keelemudelid on NLP-s tormiga võtnud palju valdkondi. BERT ja selle tuletised domineerivad enamikku olemasolevatest hindamiskritest, sealhulgas WordSense Disambiguation (WSD) võrdlusalustest tänu nende võimele jäädvustada kontekstitundlikke semantilisi nüansse. Siiski on veel vähe teadmisi nende võimete ja võimalike piirangute kohta sõnameelte kodeerimisel ja taastamisel. Käesolevas artiklis anname põhjaliku kvantitatiivse ja kvalitatiivse analüüsi tuntud BERT mudeli kohta seoses leksikaalse ebamäärasusega. Meie analüüsi üks peamisi järeldusi on see, et BERT suudab täpselt jäädvustada kõrgetasemelised tähendused isegi siis, kui iga sõna tähenduse kohta on saadaval piiratud arv näiteid. Meie analüüs näitab ka, et mõnel juhul on keelemudelid lähedal jämedate substantiivide eristamisele ideaalsetes tingimustes koolitusandmete ja arvutiressursside kättesaadavuse osas. Sellist stsenaariumi esineb aga harva reaalses maailmas ja seetõttu jäävad paljud praktilised väljakutsed isegi jämedamateralistes tingimustes. Samuti võrdleme põhjalikult kahte peamist keelemudelil põhinevat WSD strateegiat, nimelt peenhäälestust ja funktsioonide ekstraheerimist, leides, et viimane lähenemisviis on tugevam meelelahutuse suhtes ja võib paremini ära kasutada piiratud olemasolevaid koolitusandmeid. Tegelikult osutub lihtne funktsioonide eraldamise strateegia kontekstipõhiste manustamiste keskmiseks tugevaks isegi, kui kasutatakse ainult kolme koolitust\nlaused sõna kohta tähenduses, minimaalsed parandused saavutatakse nende koolitusandmete suuruse suurendamisega.', 'fi': 'Muuntajapohjaiset kielimallit ovat vallanneet NLP:ssä myrskyssä monia aloja. BERT ja sen johdannaiset hallitsevat useimpia nykyisiä arviointiperusteita, mukaan lukien Word Sense Disambiguation (WSD) -vertailuarvot, koska ne pystyvät kuvaamaan kontekstiin liittyviä semanttisia vivahteita. Niiden kyvyistä ja mahdollisista rajoituksista sanaaistien koodauksessa ja palauttamisessa on kuitenkin vielä vähän tietoa. Tässä artikkelissa teemme perusteellisen kvantitatiivisen ja laadullisen analyysin tunnetusta BERT-mallista sanaston epäselvyydestä. Yksi analyysimme tärkeimmistä johtopäätöksistä on, että BERT pystyy kuvaamaan tarkasti korkeatasoisia aistieroja, vaikka kullekin sanalle olisi saatavilla rajoitettu määrä esimerkkejä. Analyysimme osoittaa myös, että joissakin tapauksissa kielimallit ovat lähellä karkean substantiivin erottelua ihanteellisissa olosuhteissa koulutustiedon ja laskentaresurssien saatavuuden kannalta. Tätä skenaariota esiintyy kuitenkin harvoin reaalimaailmassa, ja siksi monet käytännön haasteet jäävät vielä karkeassakin ympäristössä. Lisäksi vertailemme perusteellisesti kahta keskeistä kielimallipohjaista WSD-strategiaa, eli hienosäätöä ja ominaisuuksien uuttamista, ja toteamme, että jälkimmäinen lähestymistapa on vankempi aistiharhan suhteen ja pystyy hyödyntämään paremmin rajallista käytettävissä olevaa koulutustietoa. Itse asiassa kontekstualisoitujen upotusten keskiarvojen yksinkertainen ominaisuuspoimintastrategia osoittautuu vankaksi jopa kolmessa harjoittelussa.\nlauseita sanaa kohti merkityksessä, minimaaliset parannukset saadaan kasvattamalla tämän harjoitusdatan kokoa.', 'ca': "Els models de llenguatge abstracts basats en Transformes han pres molts camps en NLP per tempesta. BERT i els seus derivats dominan la majoria dels punts de referència existents d'evaluació, inclosos els de desambiguació del sentit de les paraules, gràcies a la seva habilitat de capturar nuances semàntiques sensibles al contexte. Però encara hi ha poc coneixement sobre les seves capacitats i limitacions potencials en codificar i recuperar sentits de paraules. En aquest article proporcionem una an àlisi quantitativa i qualitativa en profunditat del famós model BERT en relació a l'ambigüitat lexical. Una de les principals conclusions de la nostra anàlisi és que el BERT pot capturar amb precisió distincions de sentit d'alt nivell, fins i tot quan hi ha un nombre limitat d'exemples disponibles per cada sentit de paraula. La nostra anàlisi també revela que en alguns casos els models lingüístics s'apropen a resoldre la desambiguació de noms grossos en condicions ideals en termes de disponibilitat de dades de formació i recursos informàtics. No obstant això, aquest escenari rarament apareix en entorns del món real i, per tant, molts reptes pràctics encara són en entorns grossos. També fem una comparació en profunditat de les dues estratègies principals de DEM basades en el model de llenguatge, a saber, l'ajustament i l'extracció de característiques, trobant que aquest últim enfocament és més robust en relació al bias sensorial i pot aprofitar millor les dades limitades d'entrenament disponibles. De fet, l'estratègia d'extracció de característiques senzilla de mitjana d'integracions contextualitzades es demostra robusta fins i tot fent servir només tres entrenaments\nfrases per sentit de paraula, amb millores mínimas obtenides augmentant la mida d'aquestes dades d'entrenament.", 'ha': '@ info: whatsthis BERT da masu ƙaranci domin mafiya yawansu da ke cikin evaluation, kamar waɗanda aka yi wa "Disambition of Size (WSD"), na gõde wa awon su sami ƙari na muhimman na-muhimmi. Kayya, bã da da wani ilmi sai game da awoninsu da ma\'abũcin muhimmada ga kodi da kuɓutar da sanyin magana. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity.  Babu ɗayan ƙarshen ƙarshen bayãni na yi anayya cẽwa BERT zai iya sami rarrabai masu da daraja na sarki, kuma kõ dã kuna da wasu misãlai masu ƙayyade wa kõwane magana. AnayyayinMu na bayyana cẽwa, cikin wani abu akwai misãlai na harshen su kusa su nẽmi rabo da wanda aka bai wa coare da shi ba, a cikin sharrin fikanci da za\'a sami tsarin data da lissafi. A lokacin da wannan idãnun na ci kaɗan a cikin kayan daidaita-duniya masu gaskiya, kuma daga wannan, sai masu yawa masu jiyya sun baka cikin kayan taƙaita. Tuna sami kowace misalin misalin biyu masu bascan na WSD, ko kuma misalin misalin na farko, ko kuma za mu sami tsarin da ake samar da shi, ko kuma za\'a iya amfani da data wanda ke iya ƙayyade. Na gaskata, masu sauƙi na samurar taskõki na tsakanin taƙaitacce\ndictionary variant', 'jv': 'Name BERT karo perusahaan omat sing dumadhi bukane kabeh wektu preiane nggawe bendhurikan sing dumadhi, gambar nggo Word Sense disabled mbiguation (WSD), nggawe akeh sabên kanggo ngerasakno nyong apa sematik sematik maneh Nanging, ditambah, durung tengah bantuan kancah sabanjuré kapasituran karo perusahaan kanggo ngkoding lan ngregani kelas kuwi seneng pisan. Nanging artiklo iki, awake dhéwé ngomong nik nggambar luwih-luwih karo kalitatif antaraning nggawe modèl BERT nggawe barang langgar sampeyan luwih dumadhi. BERT iso nggawe akeh sampeyan luwih dumadhi iki, nik sampeyan perusahaan sampeyan luwih dumadhi, nek sampeyan perusahaan seneng sampeyan kanggo sabên gambar Ananali dhéwé éntuk mungkin ngerti apakno dadi, dadi model anyar tentang kanggo ngilangno nggawe barang nggawe gerakan kelangan podho ndelok sistem sing berarti perusahaan podho nggunaken data lan tambah. Nanging, akeh bener iki dadi bareng-bareng nêmên iki dadi aturan anyar tentang kanggo nik, dadi, akeh waé pratike kang isih durung nêmên negoro sisan nguasah tarjamahan. Awak dhéwé éntuk nggambar luwih-luwih nggawe gerarané karo model sing wis dipunangé WSD kuwi, nambah, dibiné-tuning lan extraksi perusahaan, ngregani dianggap sing luwih apik dhéwé, akeh iso nggawe nguasai perusahaan anyar biasane sak lan iso nggawe bebasané perusahaan data terus nggawe. lah\nechoH e l l o space w o r l d periodHelloworldHello world', 'sk': 'Abstraktni jezikovni modeli, ki temeljijo na transformatorjih, so zavzeli številna področja v NLP. BERT in njegovi derivati prevladujejo večino obstoječih referenčnih vrednosti ocenjevanja, vključno s tistimi za Word Sense Disambiguation (WSD), zahvaljujoč njihovi sposobnosti zajemanja semantičnih odtenkov, občutljivih na kontekst. Vendar pa je še vedno malo znanja o njihovih zmožnostih in potencialnih omejitvah pri kodiranju in obnovitvi besednih čutov. V tem članku predstavljamo poglobljeno kvantitativno in kvalitativno analizo znanega BERT modela glede na leksikalno dvoumnost. Eden od glavnih zaključkov naše analize je, da lahko BERT natančno zajame razlike med pomeni na visoki ravni, tudi če je za vsak pomen besede na voljo omejeno število primerov. Naša analiza prav tako pokaže, da so v nekaterih primerih jezikovni modeli blizu reševanja grobozrnatega samostalnika v idealnih pogojih glede razpoložljivosti podatkov o usposabljanju in računalniških virov. Vendar pa se ta scenarij redko pojavlja v realnih okoljih, zato ostajajo številni praktični izzivi tudi v grobozrnatem okolju. Izvedli smo tudi poglobljeno primerjavo dveh glavnih strategij WSD na podlagi jezikovnega modela, in sicer finega nastavitve in ekstrakcije funkcij, ugotovili, da je slednji pristop robustnejši glede na pristranskost občutkov in da lahko bolje izkoristi omejene razpoložljive podatke o usposabljanju. Pravzaprav se preprosta strategija ekstrakcije funkcij povprečja kontekstualiziranih vdelav izkaže za robustna tudi z uporabo samo treh usposabljanj.\nstavki na besedni pomen, z minimalnimi izboljšavami, ki jih dosežemo s povečanjem velikosti teh podatkov o usposabljanju.', 'he': 'דוגמני שפת מבוססים בטרנספורטר לקחו שדות רבים ב-NLP בסערה. BERT והנוצרים שלה שולטים ברוב נקודות ההערכה הנוכחיות, כולל אלה עבור ניאונסים סמנטיים רגישים לקונקסט. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses.  במאמר הזה, אנו מספקים ניתוח כמוני ואיכותי עמוק של המודל BERT המחוגג בנוגע לאמבטיות לקסיקה. אחת המסקנות העיקריות של הניתוח שלנו היא שBERT יכול לתפוס בדיוק הבדיקות הגיוניים ברמה גבוהה, אפילו כאשר מספר מוגבל של דוגמאות זמין לכל תחושת מילה. הניתוח שלנו גם מגלה שבמקרים מסוימים דוגמני שפת מתקרבים לפתור אי-ספרות בשמות עצומות בתנאים אידיאליים במונחים של זמינות נתוני אימון ומשאבים מחשבים. בכל אופן, התרחיש הזה לעיתים נדירות מתרחש במסגרות בעולם האמיתי, ולכן, אתגרים מעשיים רבים נשארים אפילו במסגרת עצומה. אנחנו גם מבצעים שיוון עמוק של שני אסטרטגיות WSD המבוססות על מודל השפה הראשי, כלומר, התאים ומוציאת תכונות, למצוא שהגישה האחרונה היא חזקה יותר בנוגע לחוש ההתמחות והיא יכולה לנצל טוב יותר נתוני אימון מוגבל זמינים. למעשה, האסטרטגיה הפשוטה להוציא תכונות של הממוצע של תוכניות קונטוקטוליזציות מוכיחה חזקה אפילו בשימוש רק שלושה אימונים\nמשפטים לכל חוש מילה, עם שיפורים מינימליים שנקבלו על ידי הגדילה של מידע האימון הזה.', 'bo': 'Abstract Transformer-based language models have taken many fields in NLP by storm. BERT ། derivatives derive dominate the most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. ཡིན་ནའང་། ཁོང་ཚོའི་ཆེད་དུ་ནུས་པ་སྐོར་དང་རྒྱབ་སྐྱོར་ཀྱི་ཆེད་དུ་ཉར་encoding་དང་ཐོག་འཕྲད་ཀྱི་ཚིག་རྟོགས་ཀ In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. BERT ཡི་སྐོར་ཚད་ལྟར་བཀོད་ཐུབ་པའི་རྩ་བའི་མཇུག་གི་མཐུན་སྣེ་ཚོགས་གཅིག་ནི་BERT རྣམས་accurately capture high-level sense distinctions,even when a limited number of examples is available for each word sense. ང་ཚོའི་དབྱེ་ཞིབ་ཀྱང་ལས་སྐད་ལ་ཤས་བའི་སྐད་ཡིག However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. དངོས་གནས་བྱས་ན། མཐའ་འཁོར་གྱི་སྔོན་སྒྲིག་གནས་ཚུལ་རྒྱ་བསྐྱེད་ཀྱི་ཐབས་ལམ་སྟབས་བདེ་བ་སྤྱོད་ཐབས་འཇུག་བྱེད་རྒྱུ་མཚན་ན\nཚིག་སྒྲུབ་ཚིག་ལྟར་མང་ཆེ་ཤོས་རྐྱེན་བྱས་ན། པར་རྩིས་གཏོང་ཆེ་ཆུང་དེ་མང་ཆེ་རུ་གཏོང་ཡོད།'}
{'en': 'The Taxonomy of Writing Systems : How to Measure How Logographic a System Is', 'fr': "La taxonomie des systèmes d'écriture\xa0: comment mesurer la logographie d'un système", 'es': 'La taxonomía de los sistemas de escritura: cómo medir qué tan logográfico es un sistema', 'ar': 'تصنيف أنظمة الكتابة: كيفية قياس مدى وجود نظام لوغرافيك', 'pt': 'A Taxonomia dos Sistemas de Escrita: Como Medir Quão Logográfico é um Sistema', 'ja': 'ライティングシステムの分類法：ロゴグラフィックシステムがどのように機能しているかを測定する方法', 'zh': '书系统之类:何以测其逻辑性?', 'hi': 'लेखन प्रणालियों का वर्गीकरण: कैसे मापने के लिए कैसे एक प्रणाली Logographic है', 'ru': 'Таксономия письменных систем: как измерить, как логографическая система', 'ga': 'Tacsanomaíocht na gCóras Scríbhneoireachta: Conas Cé chomh Logagrafach atá Córas a Thomhas', 'ka': 'Name', 'hu': 'Az írási rendszerek taxonómiája: Hogyan mérjük meg, hogyan van Logográfiai rendszer', 'it': 'La tassonomia dei sistemi di scrittura: come misurare il logografico di un sistema', 'el': 'Η Ταξινομία των Συστημάτων Γραψίας: Πώς να μετρήσετε πώς είναι Λογογραφικό ένα Σύστημα', 'mk': 'Таксономијата на пишувачките системи: Како да се мери колку е лоографски систем', 'kk': 'Жазу жүйелерінің таксониясы: Жүйенің логографиялық қалай өлшемі', 'ms': 'Taxonomi Sistem Penulisan: Bagaimana Mengukur Seberapa Logografik Sistem', 'lt': 'Rašymo sistemų taksonomija: kaip išmatuoti sistemos logografiją', 'no': 'Taksonomien for skrivesystemet: Korleis å måla korleis ein systemet er logografisk', 'pl': 'Taksonomia systemów pisania: Jak mierzyć, jak logograficzny jest system', 'ro': 'Taxonomia sistemelor de scriere: Cum se măsoară modul în care este logografic un sistem', 'sr': 'Taksonomija pismenih sustava: kako da izmjerimo kako je logografijski sistem', 'mn': 'Бичилгээний системийн таксономик: Систем хэрхэн логографик байдгийг хэрхэн хэмжих вэ?', 'si': 'Name', 'ml': 'എഴുതുന്ന സിസ്റ്റത്തിന്റെ ടാക്സോനോമി: ഒരു സിസ്റ്റം എങ്ങനെയാണ് ലോഗ്രാഫിക്ക് അളവ് വരുത്തുക', 'mt': 'It-Taxonomija tas-Sistemi tal-kitba: Kif titkejjel Kif Logografika Sistema hija', 'sv': 'Taxonomi av skrivsystem: Hur man mäter hur logografiskt ett system är', 'so': 'Xafiiska qoritaanka nidaamka', 'ta': 'எழுதும் அமைப்புகளின் Taxonomy: கணினியின் பதிவுக்குறிப்பு எப்படி அளவு செய்யவேண்டும்', 'ur': 'لیکن سیسٹم کی تاکسونمی: سیسٹم کیسے لوگوگرافیک ہے؟', 'uz': 'Comment', 'vi': 'The Taxonomy of Writing Systems: How to đo How Logography a Systems is', 'bg': 'Таксономията на системите за писане: Как да измерим логографската система', 'da': 'Taxonomi af skrivesystemer: Sådan måler du, hvordan logografisk et system er', 'hr': 'Taksonomija pismenih sustava: Kako mjeriti kako je logografijski sustav', 'nl': 'De taxonomie van schrijfsystemen: Hoe meet je hoe logografisch een systeem is', 'de': 'Die Taxonomie von Schreibsystemen: Wie man misst, wie logographisch ein System ist', 'ko': '쓰기 시스템의 분류: 하나의 시스템의 표지를 어떻게 평가하는가', 'fa': 'تاکسون سیستم نوشتن: چگونه به اندازه\u200cگیری چگونه یک سیستم لوگوگرافیک است', 'sw': 'Taxonomy of Writing Systems: Namna Kupima namna ya Uandishi wa Logographic ni', 'tr': 'Yazım sistemlerinin taksonomisi:Bir sistemin nasıl Logografi olduğunu nasıl ölebilir?', 'af': 'Name', 'id': 'The Taxonomy of Writing Systems: How to Measure How Logographic a System Is', 'sq': 'Taksonomia e Sistemeve të Shkrimit: Si të matni si është logografik një sistem', 'am': 'The Taxonomy of Writing Systems: How to Measure How Logographic a System Is', 'hy': 'Գրության համակարգերի տաքսոնոմիան. Ինչպե՞ս չափել, թե ինչպես է համակարգը լոգոգրաֆիկ', 'az': 'Yazım Sistemlərin Taksoni: Sistemin necə Logografi olduğunu necə ölçürmək', 'bn': 'লেখা সিস্টেমের ট্যাক্সোনোমি: কিভাবে লোগোগ্রাফিক কি ভাবে পরিমাপ করা হবে', 'bs': 'Taksonomija pismenih sustava: kako se mjeriti kako je logografijski sistem', 'ca': 'The Taxonomy of Writing Systems: How to Measure How Logographic a System Is', 'cs': 'Taxonomie psacích systémů: Jak měřit, jak je logografický systém', 'et': 'Kirjutamissüsteemide taksonoomia: kuidas mõõta, kuidas süsteemi logograafiline on', 'fi': 'Kirjoitusjärjestelmien taksonomia: Kuinka mitata järjestelmän logiikkaa', 'he': 'טקסונומיה של מערכות כתיבה: איך למדוד איך המערכת לוגוגרפית', 'ha': 'KCharselect unicode block name', 'sk': 'Taksonomija pisalnih sistemov: Kako meriti, kako je logografski sistem', 'jv': 'TaXOmy nang Sistem sing ditambah: piye soko soko soko sistem log ografi sing apik', 'bo': 'རྩིས་འབྲི་མ་ལག་གི་Taxonomy ། མ་ལག་གི་དོན་རིས་ཇི་ལྟར་ཞིབ་གམ།'}
{'en': 'Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent : if they represent words or morphemes, they are logographic ; if syllables, syllabic ; if segments, alphabetic ; and so forth. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction. A system could be syllabic, and highly logographic ; or alphabetic, and mostly non-logographic. This accords better with how writing systems actually work, but neither author proposed a method for measuring logography. In this article we propose a novel measure of the degree of logography that uses an attention-based sequence-to-sequence model trained to predict the spelling of a token from its pronunciation in context. In an ideal phonographic system, the model should need to attend to only the current token in order to compute how to spell it, and this would show in the attention matrix activations. In contrast, with a logographic system, where a given pronunciation might correspond to several different spellings, the model would need to attend to a broader context. The ratio of the activation outside the token and the total activation forms the basis of our measure. We compare this with a simple lexical measure, and an entropic measure, as well as several other neural models, and argue that on balance our attention-based measure accords best with intuition about how logographic various systems are.', 'ar': 'صنفت تصنيفات أنظمة الكتابة منذ Gelb (1952) أنظمة تعتمد على ما تمثله الرموز المكتوبة: إذا كانت تمثل كلمات أو أشكالًا ، فهي منطقية ؛ إذا كانت المقاطع المقطعية. إذا كانت المقاطع أبجدية ؛ وهكذا دواليك. كسر سبروت (2000) وروجرز (2005) التقاليد من خلال تقسيم الجوانب اللوجغرافية والفونوغرافية إلى بعدين ، مع تصنيف السجل بدلاً من التمييز القاطع. يمكن أن يكون النظام مقطعيًا ولوجغرافيًا بدرجة عالية ؛ أو أبجديًا ، وفي الغالب غير منطقي. يتوافق هذا بشكل أفضل مع كيفية عمل أنظمة الكتابة فعليًا ، لكن لم يقترح أي من المؤلفين طريقة لقياس اللوغرافيا. في هذه المقالة نقترح مقياسًا جديدًا لدرجة السجل الذي يستخدم نموذج تسلسل إلى تسلسل قائم على الانتباه تم تدريبه للتنبؤ بهجاء رمز من نطقه في السياق. في نظام تسجيل صوتي مثالي ، يجب أن يحتاج النموذج إلى الاهتمام بالرمز المميز الحالي فقط من أجل حساب كيفية تهجئته ، وسيظهر ذلك في عمليات تنشيط مصفوفة الانتباه. على النقيض من ذلك ، مع نظام لوغرافي ، حيث قد يتوافق نطق معين مع عدة تهجئات مختلفة ، سيحتاج النموذج إلى الالتحاق بسياق أوسع. تشكل نسبة التنشيط خارج الرمز المميز وإجمالي التنشيط أساس قياسنا. نقارن هذا بمقياس معجمي بسيط ، ومقياس إنتروبيا ، بالإضافة إلى العديد من النماذج العصبية الأخرى ، ونجادل بأن مقياسنا القائم على الانتباه يتوافق بشكل أفضل مع التوازن.\nمع الحدس حول كيفية وجود أنظمة مختلفة لوجوغرافيك. يوفر عملنا أول مقياس قابل للقياس الكمي لمفهوم اللوجغرافيا الذي يتوافق مع الحدس اللغوي ، ونعتقد أنه يوفر رؤية أفضل لما تعنيه هذه الفكرة.', 'ja': 'Gelb （ 1952 ）以降の書き込みシステムの分類は、書き込まれた記号が何を表すかに基づいてシステムを分類してきた。それらが単語またはモルフェームを表す場合、それらはロゴグラフィックであり、音節が音節である場合、セグメントがアルファベットである場合などである。 Sproat （ 2000 ）とRogers （ 2005 ）は、ロゴグラフィーと音声学の側面を2つの次元に分割し、ロゴグラフィーはカテゴリ別ではなくグレーディングされることで、伝統と決別した。 システムは、音節的で高度にロゴグラフィックな場合もあれば、アルファベット的でほとんどが非ロゴグラフィックな場合もあります。 これは、実際の書き込みシステムの仕組みとよりよく一致しますが、ロゴグラフィーを測定する方法を提案した著者もいません。 この記事では、文脈での発音からトークンのスペルを予測するためにトレーニングされたアテンションベースのシーケンス間モデルを使用するロゴグラフィーの度合いの新しい尺度を提案します。 理想的なフォノグラフィックシステムでは、スペルを計算するために、モデルは現在のトークンのみに注意する必要があり、これは注意行列のアクティベーションに表示されます。 対照的に、所与の発音がいくつかの異なる綴りに対応し得るロゴシステムでは、モデルはより広い文脈に注意する必要がある。 トークンの外部でのアクティベーションと総アクティベーションの比率は、当社の測定の基礎を形成します。 これを単純な単語論的尺度、エントロピー的尺度、および他のいくつかのニューラルモデルと比較し、バランスをとる上で、私たちのアテンションベースの尺度が最良であると主張します。\nさまざまなロジックシステムがどのように組み込まれているかについての直感で説明します。私たちの研究は、言語学的直感に合致するロゴグラフィーの概念の最初の定量化可能な尺度を提供し、この概念が意味するものについてのより良い洞察を提供すると主張しています。', 'fr': "Les taxonomies des systèmes d'écriture depuis Gelb (1952) ont classifié les systèmes en fonction de ce que représentent les symboles écrits\xa0: s'ils représentent des mots ou des morphèmes, ils sont logographiques\xa0; s'il s'agit de syllabes, de syllabes, de syllabes\xa0; s'il s'agit de segments, alphabétiques\xa0; et ainsi de suite. Sproat (2000) et Rogers (2005) ont rompu avec la tradition en divisant les aspects logographiques et phonographiques en deux dimensions, la logographie étant graduée plutôt qu'une distinction catégorique. Un système peut être syllabique et hautement logographique\xa0; ou alphabétique, et la plupart du temps non logographique. Cela correspond mieux au fonctionnement réel des systèmes d'écriture, mais aucun des deux auteurs n'a proposé de méthode de mesure de la logographie. Dans cet article, nous proposons une nouvelle mesure du degré de logographie qui utilise un modèle séquence-séquence basé sur l'attention, entraîné pour prédire l'orthographe d'un jeton à partir de sa prononciation en contexte. Dans un système phonographique idéal, le modèle devrait s'occuper uniquement du jeton actuel afin de calculer comment l'épeler, et cela se manifesterait dans les activations de la matrice d'attention. En revanche, avec un système logographique, où une prononciation donnée peut correspondre à plusieurs orthographes différentes, le modèle devrait tenir compte d'un contexte plus large. Le ratio entre l'activation en dehors du jeton et l'activation totale constitue la base de notre mesure. Nous comparons cela avec une mesure lexicale simple et une mesure entropique, ainsi qu'avec plusieurs autres modèles neuronaux, et soutenons que, dans l'ensemble, notre mesure basée sur l'attention est la meilleure\navec intuition sur la façon dont les différents systèmes sont logographiques. Notre travail fournit la première mesure quantifiable de la notion de logographie qui correspond à l'intuition linguistique et, selon nous, fournit un meilleur aperçu de ce que cette notion signifie.", 'es': 'Las taxonomías de los sistemas de escritura desde Gelb (1952) tienen sistemas clasificados según lo que representan los símbolos escritos: si representan palabras o morfemas, son logográficos; si son sílabas, silábicas; si son segmentos, alfabéticos; etc. Sproat (2000) y Rogers (2005) rompieron con la tradición al dividir los aspectos logográfico y fonográfico en dos dimensiones, clasificando la logografía en lugar de una distinción categórica. Un sistema puede ser silábico y altamente logográfico; o alfabético, y en su mayoría no logográfico. Esto concuerda mejor con cómo funcionan realmente los sistemas de escritura, pero ninguno de los autores propuso un método para medir la logografía. En este artículo proponemos una medida novedosa del grado de logografía que utiliza un modelo de secuencia a secuencia basado en la atención entrenado para predecir la ortografía de un token a partir de su pronunciación en contexto. En un sistema fonográfico ideal, el modelo debería tener en cuenta solo el token actual para calcular cómo deletrearlo, y esto se mostraría en las activaciones de la matriz de atención. Por el contrario, con un sistema logográfico, en el que una pronunciación dada podría corresponder a varias ortografías diferentes, el modelo tendría que atender a un contexto más amplio. La proporción de la activación fuera del token y la activación total forman la base de nuestra medida. Comparamos esto con una medida léxica simple y una medida entrópica, así como con varios otros modelos neuronales, y argumentamos que, en conjunto, nuestra medida basada en la atención es la mejor\ncon intuición sobre cómo son los distintos sistemas logográficos. Nuestro trabajo proporciona la primera medida cuantificable de la noción de logografía que concuerda con la intuición lingüística y, argumentamos, proporciona una mejor comprensión de lo que significa esta noción.', 'pt': 'Taxonomias de sistemas de escrita desde Gelb (1952) classificaram os sistemas com base no que os símbolos escritos representam: se representam palavras ou morfemas, são logográficos; se sílabas, silábicas; se segmentos, alfabético; e assim por diante. Sproat (2000) e Rogers (2005) romperam com a tradição ao dividir os aspectos logográfico e fonográfico em duas dimensões, com a logografia sendo graduada ao invés de uma distinção categórica. Um sistema pode ser silábico e altamente logográfico; ou alfabética, e principalmente não-logográfica. Isso concorda melhor com a forma como os sistemas de escrita realmente funcionam, mas nenhum dos autores propôs um método para medir a logografia. Neste artigo, propomos uma nova medida do grau de logografia que usa um modelo de sequência a sequência baseado em atenção treinado para prever a grafia de um token a partir de sua pronúncia no contexto. Em um sistema fonográfico ideal, o modelo deveria atender apenas ao token atual para poder computar a forma de soletrar, e isso se mostraria nas ativações da matriz de atenção. Em contraste, com um sistema logográfico, onde uma determinada pronúncia pode corresponder a várias grafias diferentes, o modelo precisaria atender a um contexto mais amplo. A proporção da ativação fora do token e a ativação total forma a base de nossa medida. Comparamos isso com uma medida lexical simples e uma medida entrópica, bem como vários outros modelos neurais, e argumentamos que, em geral, nossa medida baseada na atenção combina melhor\ncom intuição sobre como vários sistemas logográficos são. Nosso trabalho fornece a primeira medida quantificável da noção de logografia que está de acordo com a intuição linguística e, argumentamos, fornece uma melhor compreensão do que essa noção significa.', 'hi': 'गेलब (1952) के बाद से लेखन प्रणालियों के वर्गीकरण ने लिखित प्रतीकों का प्रतिनिधित्व करने के आधार पर प्रणालियों को वर्गीकृत किया है: यदि वे शब्दों या मॉर्फेम्स का प्रतिनिधित्व करते हैं, तो वे लॉगोग्राफिक हैं; यदि शब्दांश, सिलेबिक; यदि खंड, वर्णमाला; और आगे भी। स्प्रोट (2000) और रोजर्स (2005) ने लॉगोग्राफिक और फोनोग्राफिक पहलुओं को दो आयामों में विभाजित करके परंपरा के साथ तोड़ दिया, जिसमें लॉगोग्राफी को एक स्पष्ट अंतर के बजाय वर्गीकृत किया गया था। एक प्रणाली सिलेबिक हो सकती है, और अत्यधिक लॉगोग्राफिक हो सकती है; या वर्णमाला, और ज्यादातर गैर-लॉगोग्राफिक। यह बेहतर है कि लेखन प्रणाली वास्तव में कैसे काम करती है, लेकिन न तो लेखक ने लॉगोग्राफी को मापने के लिए एक विधि प्रस्तावित की। इस लेख में हम लॉगोग्राफी की डिग्री का एक उपन्यास उपाय प्रस्तावित करते हैं जो संदर्भ में इसके उच्चारण से टोकन की वर्तनी की भविष्यवाणी करने के लिए प्रशिक्षित एक ध्यान-आधारित अनुक्रम-से-अनुक्रम मॉडल का उपयोग करता है। एक आदर्श फोनोग्राफिक सिस्टम में, मॉडल को केवल वर्तमान टोकन में भाग लेने की आवश्यकता होनी चाहिए ताकि यह गणना की जा सके कि इसे कैसे वर्तनी किया जाए, और यह ध्यान मैट्रिक्स सक्रियणों में दिखाएगा। इसके विपरीत, एक लॉगोग्राफिक सिस्टम के साथ, जहां एक दिया गया उच्चारण कई अलग-अलग वर्तनी के अनुरूप हो सकता है, मॉडल को एक व्यापक संदर्भ में भाग लेने की आवश्यकता होगी। टोकन के बाहर सक्रियण का अनुपात और कुल सक्रियण हमारे माप का आधार बनाता है। हम इसकी तुलना एक साधारण लेक्सिकल उपाय, और एक एन्ट्रोपिक उपाय, साथ ही साथ कई अन्य तंत्रिका मॉडल के साथ करते हैं, और तर्क देते हैं कि संतुलन पर हमारे ध्यान-आधारित उपाय सबसे अच्छा है\nकैसे logographic विभिन्न प्रणालियों रहे हैं के बारे में अंतर्ज्ञान के साथ. हमारा काम लॉगोग्राफी की धारणा का पहला मात्रात्मक उपाय प्रदान करता है जो भाषाई अंतर्ज्ञान के अनुरूप है और, हम तर्क देते हैं, इस धारणा का क्या मतलब है, इस बारे में बेहतर अंतर्दृष्टि प्रदान करता है।', 'zh': '自Gelb(1952)以来分类学已随书符对系统分:其为单词语素,则其书也; 若音节,音节; 如段,字母次也。 云云。 Sproat(2000)、Rogers(2005)破故事,分逻辑学、唱片学为二维度,分于逻辑学分级非绝分也。 统者,音之节也,而高有逻辑性。 或以字母次第,多是非数。 此又书统之实事,而二作者未有测逻辑学之术也。 于本文之中,设一新测逻辑学,当量用注意之序,以从上下文中之令牌拼写。 凡语音系统,唯须关令牌,以计拼写之,示在矩阵激活中。 比之日志统,给定音应拼写,形须广上下文。 令牌外之激活,与总激活之率,为我之基。 以此比于词汇度量熵度量,与其数神经相较,以为总者,于意度为最合。\n直觉知诸统所记。 吾事为言直觉者逻辑学一可量化之衡量,而吾以为有二焉。', 'ru': 'Таксономии систем письма, начиная с Gelb (1952), классифицируют системы, основанные на том, что представляют собой письменные символы: если они представляют слова или морфемы, они являются логографическими; если слоги, слоговые; если сегменты, алфавитные; и так далее. Sproat (2000) и Rogers (2005) порвали с традицией, разделив логографические и фонографические аспекты на два измерения, при этом логография была оценена, а не категоризировано различие. Система может быть слогографической и сильно логографической; или алфавитной, и в основном нелогографической. Это лучше согласуется с тем, как на самом деле работают системы письма, но ни один из авторов не предложил метод измерения логографии. В этой статье мы предлагаем новую меру степени логографии, которая использует модель последовательности, основанную на внимании, обученную предсказывать орфографию токена от его произношения в контексте. В идеальной фонографической системе модель должна учитывать только текущий токен, чтобы вычислить, как он пишется, и это будет отображаться в активациях матрицы внимания. В отличие от логографической системы, в которой конкретное произношение может соответствовать нескольким различным написаниям, модель должна учитывать более широкий контекст. Отношение активации вне токена к общей активации составляет основу нашей меры. Мы сравниваем это с простой лексической мерой и энтропийной мерой, а также с несколькими другими нейронными моделями, и утверждаем, что в итоге наша мера, основанная на внимании, наилучшим образом согласуется\nс интуицией о том, как логографические различные системы. Наша работа обеспечивает первую количественную меру понятия логографии, которая согласуется с лингвистической интуицией и, как мы утверждаем, обеспечивает лучшее понимание того, что означает это понятие.', 'ga': 'Tá córais rangaithe ag tacsanomaíochtaí na gcóras scríbhneoireachta ó Gelb (1952) bunaithe ar a seasann na siombailí scríofa: má seasann siad do fhocail nó do mhoirfimí, is córais logagrafacha iad; más siollaí, siolla; más deighleoga, aibítre; agus mar sin de. Bhris Sproat (2000) agus Rogers (2005) leis an traidisiún trí na gnéithe logagrafacha agus fónagrafacha a roinnt ina dhá thoise, agus an logagrafaíocht á grádú seachas ina hidirdhealú catagóiriúil. D’fhéadfadh córas a bheith siollabach, agus an-lógagrafaíochta; nó aibítre, agus neamh-lógagrafaíochta den chuid is mó. Tagann sé seo níos fearr leis an gcaoi a n-oibríonn córais scríbhneoireachta i ndáiríre, ach mhol ceachtar den dá údar modh chun an logagrafaíocht a thomhas. San Airteagal seo molaimid tomhas nua ar mhéid na logagrafaíochta a úsáideann samhail seicheamh-go-seicheamh atá bunaithe ar aird agus atá oilte chun litriú comhartha a thuar óna fhuaimniú i gcomhthéacs. I gcóras fónagrafach idéalach, níor cheart go gcaithfeadh an tsamhail ach freastal ar an comhartha reatha chun é a ríomh conas é a litriú, agus thaispeánfadh sé seo i ngníomhartha aire maitrís. I gcodarsnacht leis sin, le córas logagrafach, ina mbeadh fuaimniú tugtha ag teacht le roinnt litrithe éagsúla, bheadh ar an tsamhail díriú ar chomhthéacs níos leithne. Tá an cóimheas idir an gníomhachtú lasmuigh den chomhartha agus an gníomhachtú iomlán mar bhunús lenár mbeart. Déanaimid é seo a chur i gcomparáid le tomhas foclóireachta simplí, agus le beart eantrópach, chomh maith le go leor samhlacha néaracha eile, agus áitímid gurb é an beart is fearr a thugann ár mbeart aird-bhunaithe.\nle hintiúlacht faoi conas atá córais éagsúla logagrafacha. Soláthraíonn ár gcuid oibre an chéad tomhas inchainníochtaithe ar choincheap na logagrafaíochta a thagann le hintiúlacht theangeolaíoch agus, áitímid, a thugann léargas níos fearr ar cad is brí leis an nóisean seo.', 'ka': 'დაწერის სისტემის რაკონომიები, როდესაც Gelb (1952) კლასიფიკაციული სისტემები იყო, რომელიც წერილი სიმბოლოების გამოსახულება: თუ ისინი წერილის სიტყვები ან მორფემების გამოსახ თუ სილაბი, სილაბი; თუ სექმენტები, ალტაბეტიკი; და ასე. Sproat (2000) და Rogers (2005) ტრადიციას გაყოფილი, როცა ლოგრაფიური და ფონოგრაფიური აპექტირები ორი განზომილებში გაყოფილი, როცა ლოგრაფია კოტეგრაფიური განსხვავება არა. სისტემა შეიძლება იყოს სილაბური და ძალიან ლოგრაფიური; ან ალტაბეტური და უფრო მეტი ლოგრაფიური. ეს უკეთესია, როგორ წერილის სისტემები მუშაობს, მაგრამ არც ავტორი მინდა ლოგრაფიის განზომილების მეტი. ამ წიგნაში ჩვენ მინდა ლოგრაფიის პრომენტის ზომა, რომელიც ახლა აღმოჩენებული მოდელს, რომელიც აღმოჩენებული მოდელს, რომელიც აღმოჩენებულია მოდელს, რომელიც მისი წიგნაზე გამოყენებული წიგნა იდეალური ფონოგრაფიური სისტემაში, მოდელი უნდა მხოლოდ მიმდინარე სისტემაში დაწყება, როგორ მას წერტილის შესაძლებელად დაწყება, და ეს იქნება დაახლოების მარტიკის აკეთეციაში. კონტრასტურად, ლოგორფიკური სისტემით, სადაც მონიშნული გამოსახულება შეიძლება მრავალ განსხვავებული სისტემის შესაძლებელია, მოდელი უფრო დიდ კონტექსტში მოსწავლა. აქტივაციის გარეშე და საერთო აქტივაციის განმავლობა ჩვენი ზომის ბაზია. ჩვენ ამას მარტივი ლექსიკალური ზომით და ენტროპური ზომით, და რამდენიმე სხვა ნეიროლური მოდელებით შემდგენებთ, რომ ჩვენი აღმოჩენების ბალანზაციაში ჩვენი აღმოჩენების ნაი\nინტეუცია როგორ არის ლოგრაფიური განსხვავებული სისტემები. ჩვენი სამუშაო პირველი კვანტიფიკაციური განზომილება ლოგრაფიის წარმოდგენისთვის, რომელიც ლუგრაფიკური ინტივიციის შესახებ და, ვთქვათ, უფრო უკეთესი ინტევიციის შესახებ, რას ნი', 'el': 'Οι ταξινομήσεις των συστημάτων γραφής από το Gelb (1952) έχουν ταξινομήσει συστήματα με βάση το τι αντιπροσωπεύουν τα γραπτά σύμβολα: εάν αντιπροσωπεύουν λέξεις ή μορφώματα, είναι λογογραφικά. εάν συλλαβές, συλλαβική· εάν τμήματα, αλφαβητικά· και ούτω καθεξής. Οι Σπρόατ (2000) και Ρότζερς (2005) έσπασαν με την παράδοση χωρίζοντας τις λογογραφικές και φωνογραφικές πτυχές σε δύο διαστάσεις, με τη λογογραφία να βαθμολογείται και όχι κατηγορηματική διάκριση. Ένα σύστημα θα μπορούσε να είναι συλλαβητικό και ιδιαίτερα λογογραφικό. ή αλφαβητικά, και κυρίως μη λογογραφικά. Αυτό συμφωνεί καλύτερα με το πώς λειτουργούν πραγματικά τα συστήματα γραφής, αλλά κανένας από τους συγγραφείς δεν πρότεινε μέθοδο μέτρησης της λογογραφίας. Σε αυτό το άρθρο προτείνουμε ένα νέο μέτρο του βαθμού λογογραφίας που χρησιμοποιεί ένα μοντέλο ακολουθίας-ακολουθίας βασισμένο στην προσοχή εκπαιδευμένο για να προβλέψει την ορθογραφία ενός σήματος από την προφορά του στο πλαίσιο. Σε ένα ιδανικό φωνογραφικό σύστημα, το μοντέλο θα πρέπει να παρακολουθεί μόνο το τρέχον σύμβολο για να υπολογίσει πώς να το συλλαβίσει, και αυτό θα φανεί στις ενεργοποίησες του πίνακα προσοχής. Αντίθετα, με ένα λογογραφικό σύστημα, όπου μια συγκεκριμένη προφορά μπορεί να αντιστοιχεί σε πολλές διαφορετικές ορθογραφίες, το μοντέλο θα πρέπει να προσέχει ένα ευρύτερο πλαίσιο. Η αναλογία της ενεργοποίησης εκτός του σήματος και της συνολικής ενεργοποίησης αποτελεί τη βάση του μέτρου μας. Συγκρίνουμε αυτό με ένα απλό λεξικό μέτρο, και ένα εντροπικό μέτρο, καθώς και πολλά άλλα νευρικά μοντέλα, και υποστηρίζουμε ότι σε ισορροπία το μέτρο που βασίζεται στην προσοχή μας συμφωνεί καλύτερα\nμε διαίσθηση για το πόσο λογογραφικά είναι τα διάφορα συστήματα. Η εργασία μας παρέχει το πρώτο ποσοτικό μέτρο της έννοιας της λογογραφίας που συμφωνεί με τη γλωσσική διαίσθηση και, υποστηρίζουμε, παρέχει καλύτερη κατανόηση του τι σημαίνει αυτή η έννοια.', 'hu': 'Az írási rendszerek taxonómiái Gelb (1952) óta osztályozták a rendszereket az írott szimbólumok képviselete alapján: ha szavakat vagy morfémákat képviselnek, akkor logográfiai; ha szótagok, szótagok; ha szegmensek, betűrendben; és így tovább. Sproat (2000) és Rogers (2005) megszakították a hagyományt azzal, hogy két dimenzióra bontották a logográfiai és fonográfiai vonatkozásokat, a logográfiát inkább kategorikus megkülönböztetés helyett osztályozták. Egy rendszer lehet szótagos, és nagyon logográfias; vagy betűrendben, és többnyire nem logográfiai. Ez jobban illeszkedik az írási rendszerek tényleges működéséhez, de egyik szerző sem javasolt módszert a logógráfia mérésére. Ebben a cikkben a logógráfia mértékének új mérését javasoljuk, amely egy figyelem-alapú szekvencia-szekvencia modellt használ arra, hogy megjósolja a tokenek helyesírását a kontextusban. Egy ideális hangfelvételi rendszerben a modellnek csak az aktuális tokennel kell foglalkoznia ahhoz, hogy kiszámítsa, hogyan kell betűzni, és ez megmutatná a figyelemmátrix aktiválásaiban. Ezzel szemben egy logográfiai rendszerrel, ahol egy adott kiejtés több különböző helyesírásnak felel meg, a modellnek egy tágabb kontextust kell figyelembe vennie. A tokenen kívüli aktiválás és a teljes aktiválás aránya képezi az intézkedésünk alapját. Ezt összehasonlítjuk egy egyszerű lexikális mértékkel, egy entrópikus mértékkel, valamint több más neurális modellekkel, és azzal érvelünk, hogy egyensúlyban a figyelem-alapú mértékünk megfelel a legjobban\nmegérzéssel arról, hogy mennyire logográfiai a különböző rendszerek. Munkánk a logográfia fogalmának első számszerűsíthető mértékét nyújtja, amely összhangban van a nyelvi intuícióval, és érvelünk, jobb betekintést nyújt arra, hogy ez mit jelent.', 'it': "Le tassonomie dei sistemi di scrittura a partire da Gelb (1952) hanno classificato sistemi basati su ciò che i simboli scritti rappresentano: se rappresentano parole o morfemi, sono logografici; se sillabe, sillabe; se segmenti, alfabetico; e così via. Sproat (2000) e Rogers (2005) hanno rotto con la tradizione dividendo gli aspetti logografici e fonografici in due dimensioni, con la logografia classificata piuttosto che una distinzione categorica. Un sistema potrebbe essere sillabico e altamente logografico; o alfabetico, e per lo più non logografico. Questo si accorda meglio con come funzionano i sistemi di scrittura, ma nessuno degli autori ha proposto un metodo per misurare la logografia. In questo articolo proponiamo una nuova misura del grado di logografia che utilizza un modello sequenza-sequenza basato sull'attenzione addestrato a prevedere l'ortografia di un token dalla sua pronuncia nel contesto. In un sistema fonografico ideale, il modello dovrebbe avere bisogno di occuparsi solo del token corrente per calcolare come si scrive, e questo mostrerebbe nelle attivazioni della matrice di attenzione. Al contrario, con un sistema logografico, dove una data pronuncia potrebbe corrispondere a più ortografie diverse, il modello avrebbe bisogno di occuparsi di un contesto più ampio. Il rapporto tra l'attivazione esterna al token e l'attivazione totale costituisce la base della nostra misura. Confrontiamo questo con una semplice misura lessicale, e una misura entropica, così come molti altri modelli neurali, e sosteniamo che in equilibrio la nostra misura basata sull'attenzione accorda meglio\ncon intuizione su come sono logografici i vari sistemi. Il nostro lavoro fornisce la prima misura quantificabile della nozione di logografia che si accorda con l'intuizione linguistica e, diciamo, fornisce una migliore comprensione di ciò che questa nozione significa.", 'lt': 'rašymo sistemų taksonomijos nuo Gelb (1952 m.) turi klasifikuotas sistemas, grindžiamas rašytiniais simboliais: jei jos yra žodžiai arba morfomai, jos yra logografinės; jei silabos, silabos; jei segmentai, raidiniai; and so forth.  Sproat (2000) ir Rogers (2005) sutriko su tradicija padalijant logografinius ir fonografinius aspektus į du matmenis, o logografija buvo klasifikuojama, o ne kategorijinis skirtumas. Sistema gali būti silabinė ir labai logografinė; arba alfabetiškai ir daugiausia ne logografiškai. Tai geriau sutampa su tuo, kaip rašymo sistemos iš tikrųjų veikia, bet nė vienas autorius nepasiūlė metodo logografijai matuoti. Šiame straipsnyje siūlome naują logografijos laipsnio matavimą, pagal kurį naudojamas dėmesiu grindžiamas sekos po sekos modelis, parengtas prognozuoti ženklo rašymą iš jo išraiškos kontekste. Idealioje fonografinėje sistemoje modelis turėtų būti naudojamas tik dabartiniam ženklui, kad būtų galima apskaičiuoti, kaip jį rašyti, ir tai parodytų dėmesio matricos aktyvavimuose. Priešingai, naudojant logografinę sistemą, kurioje tam tikras išraiškas gali atitikti kelis skirtingus raštus, modelis turėtų atsižvelgti į platesnį kontekstą. Aktyvavimo už ženklo ribų ir bendro aktyvavimo santykis yra mūsų matavimo pagrindas. Palyginame tai su paprasta leksikine priemone, entropine priemone, taip pat su keliais kitais nerviniais modeliais, ir tvirtiname, kad mūsų dėmesiu pagrįsta priemonė geriausiai atitinka\nsu intuicija apie įvairių sistemų logografiką. Mūsų darbas suteikia pirmą kiekybiškai įvertinamą logografijos sąvokos, atitinkančios kalbinę intuiciją, ir, mūsų teigimu, suteikia geresnį supratimą apie tai, ką reiškia ši sąvoka.', 'mk': 'Таксономиите на системите за пишување откако Гелб (1952) имаат класифицирани системи базирани на она што пишуваните симболи го претставуваат: ако тие претставуваат зборови или морфеми, тие се лоографски; ако слободи, слободни; if segments, alphabetic; if segments, alphabetic; if segments, alphabetic и така натаму. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction.  A system could be syllabic, and highly logographic;  или алфабетски, и претежно нелоографски. Ова се совпаѓа подобро со тоа како системите за пишување всушност функционираат, но ниту авторот не предложи метод за мерење на лоографијата. Во оваа статија предложуваме нова мерка на степенот на лоографија која користи модел од секвенца до секвенца базиран на внимание, трениран за предвидување на правописот на знак од неговата изјава во контекст. Во идеален фонографски систем, моделот треба да присуствува само на тековниот знак за да се пресмета како да го пишува, а ова ќе се покаже во активацијата на матрицата на вниманието. За разлика од тоа, со лоографскиот систем, каде што дадена изјава може да одговара на неколку различни правописи, моделот ќе мора да присуствува на поширок контекст. Односот на активацијата надвор од знакот и вкупната активација ја формира основата на нашата мерка. We compare this with a simple lexical measure, and an entropic measure, as well as several other neural models, and argue that on balance our attention-based measure accords best\nсо интуиција за тоа колку лоографски се различните системи. Нашата работа обезбедува прва квантификабилна мерка на концепцијата на лоографија која се согласува со јазичката интуиција и, тврдиме, обезбедува подобар поглед на тоа што значи оваа концепција.', 'kk': 'Желб (1952) дегеннен кейін жазу жүйелерінің таксономиялары жазылған символдарына негізделген жүйелерді салыстырып тұрады: егер олар сөздерді не морфемдерді көрсетеді, олар логографикалық; егер олар шаблондар, шаблондар; шаблондар; шаблондар; шаблондар; шаблондар; шаблондар; шаблондар; шаблондар; шаблондар егер сегменттер, альфавиттік; amount in units (real) және басқа. Sproat (2000) және Rogers (2005) дәстүрлі және логографикалық және фонографикалық аспекттерді екі өлшемге бөліп, логография категориялық түрлендіру орнына бағалады. Жүйе сөздік және логографикалық болуы мүмкін; жүйе немесе алфавиттік, көбінесе логографикалық емес. Бұл жазу жүйелерін қалай жұмыс істеу үшін жақсы болады, бірақ авторы логография өлшемінің әдісін таңдамады. Бұл мақалада біз логография градусының романдық өлшемін таңдаймыз. Бұл мақалада оның сөздерінен мәліметті көрсету үшін бағытталған тәртіпке тәртіпке негізделген реттеу үлгісін қолданады. Идеалдық фонографикалық жүйеде үлгі тек назардағы белгілеріне қатынау үшін оны қалай мәтінді есептеу үшін қатынау керек. Бұл матрица белсенділіктерінде көрсетіледі. Әйтпесе, логографикалық жүйесі, келтірілген сөйлеме бірнеше бірнеше мәліметтерге сәйкес болуы мүмкін, үлгі көтерілген контекстке қатынау керек. Белсендіру қатынасы белгісінің сыртында және жалпы белсендіру қатынасы біздің өлшеміміздің негізінде тұрады. Бұны қарапайым лексикалық өлшемімен, энтропикалық өлшемімен және басқа невралдық моделдерімен салыстырып, біздің назарымыз негізделген өлшеміміздің балансында\nжүйелер логографикалық түрлі жүйелерді қалай түсінуге болады. Біздің жұмысымыз, лингвистикалық интузиясына сәйкес келетін логографияның бірінші санаттық өлшемін береді. Бұл ойымыздың мәліметінің жақсы түсініктерін көрсетеді.', 'ml': 'ഗെബ്(1952) മുതല്\u200d എഴുതുന്ന സിസ്റ്റത്തിന്റെ ടാക്സോണിമിസ്റ്റുകള്\u200d എഴുതിയ ചിഹ്നങ്ങള്\u200dക്ക് അടിസ്ഥാനമായി വിശദീകരിച്ചിരിക്കുന്നു സിലാബിക്ക്, സിലാബിക്ക്; ഭാഗങ്ങള്\u200d, ആല്\u200dഫാബെറ്റിക്; and so forth.  ലോഗോഗ്രാഫിക്കും ഫോണോഗ്രാഫിക്കും ഭാഗങ്ങളും രണ്ടു ഭാഗങ്ങളിലേക്ക് വേര്\u200dപെടുത്തുന്നതിനാല്\u200d സ്പ്രൂവ് (2000) റോജെര്\u200dസും (2005) പാരമ്പര്യം തകര്\u200dത്തു. ലോഗ ഒരു സിസ്റ്റം സിലാബിക്ക് ആയിരിക്കാം, വളരെ ലോഗോഗ്രാഫിക്കും; അല്\u200dഫാബെറ്റിക്ക് അല്ലെങ്കില്\u200d പ്രധാനപ്പെട്ട ലോഗ്രാഫിക്ക് അല്ലെങ്കില്\u200d എഴുതുന്ന സിസ്റ്റം എങ്ങനെയാണ് പ്രവര്\u200dത്തിക്കുന്നതെന്ന് ഇത് നന്നായി സമ്മതിക്കുന്നു. പക്ഷെ ലോഗോഗ്രാഫി അളക്കു ഈ ലോഗോഗ്രാഫിയുടെ ലോഗ്രാഫിയുടെ ഡിഗ്രിയില്\u200d നമ്മള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. അത് ശ്രദ്ധയോടെ അടിസ്ഥാനപ്പെടുത്തിയ സെക്കന്റ് മോഡല്\u200d ഉപയോഗിക്കു ഒരു ആശയിക ഫോണോഗ്രാഫിക് സിസ്റ്റത്തില്\u200d, നിലവിലുള്ള അടയാളം മാത്രമേ ഉള്ളുള്ളൂ. വ്യത്യസ്തമായി, ഒരു ലോഗോഗ്രാഫിക്ക് സിസ്റ്റത്തില്\u200d, കൊടുത്തിരിക്കുന്ന പ്രസംഗം പല വ്യത്യസ്തംഭാഷണങ്ങള്\u200dക്കും സമ്മതിക്കുന്നുവ അടയാളങ്ങളുടെ പുറത്തുള്ള പ്രവര്\u200dത്തനത്തിന്റെ വിഭാഗവും മൊത്തം പ്രവര്\u200dത്തനവും നമ്മുടെ അളവിലെ അടിസ്ഥാനത്തി നമ്മള്\u200d ഇതിനെ ഒരു ലളിതമായ ലെക്സിക്കൽ അളവും ഒരു എൻട്രോപ്പിക്ക് അളവും മറ്റൊരു പ്രവർത്തക മോഡലുമായി താല്പര്യമാക്കുന്നു. നമ്മുടെ\nലോഗോഗ്രാഫിക് വ്യത്യസ്തംഭങ്ങള്\u200d എങ്ങനെയാണെന്ന് മനസ്സിലാക്കുന്നു. നമ്മുടെ ജോലി ലോഗോഗ്രാഫിയുടെ ആദ്യത്തെ പരിപാടിയുള്ള അളവ് നല്\u200dകുന്നു. അത് ഭാഷ കാര്യത്തില്\u200d സമ്മതിക്കുന്നു. നമ്മള്\u200d തര്\u200dക്കിക്കുന്നു,', 'mt': 'It-tassonomiji tas-sistemi tal-kitba sa mill-Gelb (1952) għandhom sistemi klassifikati bbażati fuq dak li s-simboli miktuba jirrappreżentaw: jekk jirrappreżentaw kliem jew morfi, huma logografiċi; jekk sillabi, sillabiċi; jekk segmenti, alfabetiċi; eċċ. Sproat (2000) u Rogers (2005) kisru bit-tradizzjoni billi qasmu l-aspetti logografiċi u fonografiċi f’żewġ dimensjonijiet, bil-logografija tiġi kklassifikata aktar milli distinzjoni kategorika. Sistema tista’ tkun silabika, u logografika ħafna; jew alfabetiċi, u l-aktar mhux logografiċi. Dan jaqbel a ħjar ma’ kif jaħdmu s-sistemi tal-kitba fil-fatt, iżda l-ebda awtur ma ppropona metodu għall-kejl tal-logografija. F’dan l-artikolu nipproponu miżura ġdida tal-grad ta’ logografija li tuża mudell ta’ sekwenza għal sekwenza bbażat fuq l-attenzjoni mħarreġ biex jipprevedi l-ortografija ta’ token mill-pronunzja tiegħu fil-kuntest. F’sistema fonografika ideali, il-mudell għandu jkollu bżonn jattendi biss għat-token kurrenti sabiex jikkalkula kif isir l-ortografija, u dan juri fl-attivazzjonijiet tal-matriċi tal-attenzjoni. B’kuntrast ma’ sistema logografika, fejn pronunzja partikolari tista’ tikkorrispondi għal diversi ortografiji differenti, il-mudell ikollu jattendi għal kuntest usa’. The ratio of the activation outside the token and the total activation forms the basis of our measure.  Aħna nqabblu dan ma’ miżura lexika sempliċi, u miżura entropika, kif ukoll diversi mudelli newrali oħra, u jargumentaw li fuq bilanċ il-miżura bbażata fuq l-attenzjoni tagħna taqbel bl-a ħjar mod\nb’intwizzjoni dwar kif huma sistemi logografiċi varji. Ix-xogħol tagħna jipprovdi l-ewwel miżura kwantifikabbli tal-kunċett ta’ logografija li jaqbel mal-intwizzjoni lingwistika u, aħna jargumentaw, jipprovdi għarfien aħjar dwar x’tfisser din il-kunċett.', 'mn': '1952 оны Гельб (Гельб) гэхээс хойш бичих системийн таксоном нь бичих тэмдэгт юу гэсэн үг вэ гэвэл тэд үг эсвэл морфом гэдэг бол логографик байдаг. хэрвээ тэмдэглэгдэх үг бол тэмдэглэгдэх үг юм. хэлбэрийн хэмжээсүүд бол Ингээд л. Пророат (2000) болон Рогерс (2005) нь логографик болон фонографик хэмжээсүүдийг хоёр хэмжээсүүдэд хувааж, логографийг категорийн ялгаанаас илүү ангилалдаг. Систем илэрхийлэл болон маш логографик байж болно. эсвэл алфавит, ихэнхдээ логографик биш. Энэ нь бичих системүүд хэрхэн ажилладаг талаар илүү сайн ойлгомжтой. Гэхдээ зохиолч ч логографийг хэмжих арга санал өгч чадахгүй. Энэ баримтуудад бид анхаарлын дарааллаас дарааллаар дамжуулагдсан загварыг ашигладаг логографийн хэмжээний шинэ хэмжээг сануулдаг. Идеал фонографик системд загвар нь зөвхөн одоогийн тодорхойлолтыг тооцоолох ёстой. Энэ нь анхаарлын матриц идэвхтэй болно. Харамсалтай нь, логографик системтэй холбогдолтой, хэдэн өөр хэлбэртэй холбогдолтой байж болно. Загвар нь илүү өргөн нөхцөлд орох хэрэгтэй. Хүчирхийллийн харьцаа нь бидний хэмжээний суурь юм. Бид үүнийг энгийн хэмжээтэй, энтропик хэмжээтэй харьцуулж, бусад олон мэдрэлийн загвартай харьцуулж, анхаарлын үндсэн хэмжээг баланслахад\nЛогографийн төрлийн системийн тухай ойлголт авч үздэг. Бидний ажлын анхны тоо хэмжээтэй хэмжээний логографикийн ойлголтыг дамжуулдаг. Энэ ойлголтын юу гэсэн үг вэ гэдгийг бид хэлж байна.', 'ms': 'Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent: if they represent words or morphemes, they are logographic;  jika silabel, silabel; jika segmen, alfabet; dan sebagainya. Sproat (2000) dan Rogers (2005) rosak dengan tradisi dengan membahagi aspek logografik dan fonografik ke dua dimensi, dengan logografi ditandai daripada perbezaan kategori. A system could be syllabic, and highly logographic;  atau alfabet, dan kebanyakan bukan-logografik. Ini lebih sesuai dengan bagaimana sistem penulisan sebenarnya berfungsi, tetapi tiada penulis melamar kaedah untuk mengukur logografi. Dalam artikel ini kami cadangkan ukuran baru darjah logografi yang menggunakan model urutan-ke-urutan berdasarkan perhatian dilatih untuk meramalkan ejaan token dari ungkapannya dalam konteks. Dalam sistem fonografik ideal, model perlu menghadiri hanya token semasa untuk menghitung bagaimana mengeja ia, dan ini akan menunjukkan dalam aktivasi matriks perhatian. Sebaliknya, dengan sistem logografik, di mana ungkapan yang diberi mungkin sepadan dengan beberapa ejaan yang berbeza, model perlu menghadiri konteks yang lebih luas. Nisbah aktivasi diluar token dan total aktivasi membentuk dasar ukuran kita. Kita membandingkan ini dengan ukuran leksikal sederhana, dan ukuran entropik, serta beberapa model saraf lain, dan membantah bahawa pada keseimbangan ukuran berdasarkan perhatian kita menyesuaikan yang terbaik\nwith intuition about how logographic various systems are.  Kerja kami menyediakan ukuran kuantifikasi pertama bagi gagasan logografi yang sesuai dengan intuisi bahasa dan, kita berdebat, menyediakan pandangan yang lebih baik kepada apa maknanya gagasan ini.', 'pl': 'Taksonomie systemów pisania od Gelb (1952) posiadają systemy klasyfikowane na podstawie tego, co symbole pisane reprezentują: jeśli reprezentują słowa lub morfemy, są one logograficzne; jeśli sylaby, sylaby; jeśli segmenty, alfabetyczne; i tak dalej. Sproat (2000) i Rogers (2005) zerwali z tradycją dzieląc aspekty logograficzne i fonograficzne na dwa wymiary, przy czym logografia była klasyfikowana raczej niż kategoryczna. System mógłby być sylabiczny i wysoce logograficzny; albo alfabetyczne, i głównie nie logograficzne. Lepiej zgadza się to z tym, jak rzeczywiście działają systemy pisania, ale żaden z autorów nie zaproponował metody pomiaru logografii. W niniejszym artykule proponujemy nowatorską miarę stopnia logografii, która wykorzystuje oparty na uwadze model sekwencji-sekwencji przeszkolony do przewidywania pisowni tokenu z jego wymowy w kontekście. W idealnym systemie fonograficznym model powinien zajmować się tylko bieżącym tokenem, aby obliczyć, jak go pisać, a to pokazałoby się w aktywacjach macierzy uwagi. W przeciwieństwie do systemu logograficznego, gdzie dana wymowa może odpowiadać kilku różnym pisowniom, model musiałby uwzględniać szerszy kontekst. Stosunek aktywacji poza tokenem i całkowitej aktywacji stanowi podstawę naszej miary. Porównujemy to z prostą miarą leksykalną i miarą entropiczną, a także kilkoma innymi modelami neuronowymi i twierdzimy, że w równowadze nasza miara oparta na uwadze najlepiej zgadza się\nZ intuicją na temat tego, jak logograficzne są różne systemy. Nasza praca stanowi pierwszą ilościową miarę pojęcia logografii zgodną z intuicją językową i, jak twierdzimy, zapewnia lepszy wgląd w to, co to pojęcie oznacza.', 'ro': 'Taxonomiile sistemelor de scriere de la Gelb (1952) au clasificat sisteme bazate pe ceea ce reprezintă simbolurile scrise: dacă reprezintă cuvinte sau morfeme, ele sunt logografice; dacă silabe, silabice; dacă segmente, alfabetice; şi aşa mai departe. Sproat (2000) și Rogers (2005) au rupt tradiția împărțind aspectele logografice și fonografice în două dimensiuni, logografia fiind clasificată mai degrabă decât o distincție categorică. Un sistem ar putea fi silabic, și foarte logografic; sau alfabetic, și mai ales non-logografic. Acest lucru se potrivește mai bine cu modul în care sistemele de scriere funcționează de fapt, dar nici un autor nu a propus o metodă de măsurare a logografiei. În acest articol propunem o nouă măsură a gradului de logografie care utilizează un model secvență-la-secvență bazat pe atenție instruit pentru a prezice ortografia unui token din pronunția sa în context. Într-un sistem fonografic ideal, modelul ar trebui să aibă grijă doar de token-ul curent pentru a calcula modul în care se scrie, iar acest lucru ar arăta în activările matricei de atenție. Spre deosebire de un sistem logografic, unde o pronunție dată ar putea corespunde mai multor ortografii diferite, modelul ar trebui să participe la un context mai larg. Raportul dintre activarea din afara token-ului și activarea totală formează baza măsurii noastre. Comparăm acest lucru cu o măsură lexicală simplă și o măsură entropică, precum și cu mai multe alte modele neuronale, și susținem că, în echilibru, măsura noastră bazată pe atenție acordă cel mai bine\ncu intuiție despre modul în care logografice diferite sisteme sunt. Lucrarea noastră oferă prima măsură cuantificabilă a noțiunii de logografie care corespunde intuiției lingvistice și, argumentăm, oferă o mai bună perspectivă asupra ceea ce înseamnă această noțiune.', 'sr': 'Taksonomije pisaćeg sistema od Gelba (1952) imaju klasifikovane sisteme na osnovu onoga što napisani simboli predstavljaju: ako predstavljaju riječi ili morfije, oni su logografični; ako su silabe, silabe; ako segmenti, alfabetski; i tako dalje. Sproat (2000) i Rogers (2005) prekinuli su tradiciju razdvajanjem logografskih i fonografskih aspekta u dve dimenzije, a logografija se ocjenjuje umjesto kategorijske razlike. Sistem bi mogao biti silabetski i jako logografski; ili alfabetski, i uglavnom ne-logografski. Ovo se bolje slaže kako napisani sistemi zapravo rade, ali ni autor nije predložio metodu za mjerenje logografije. U ovom članku predlažemo novu mjeru stupnja logografije koja koristi model koji je osnovan na pažnji sekvenci na sekvenci obučen kako bi predvidjela pisanje znaka iz njegovog proglašavanja u kontekstu. U idealnom fonografskom sistemu, model bi trebao prisustvovati samo trenutnom znaku da bi računalo kako ga pisati, a to bi pokazalo u aktivaciji pažnje matrice. Za suprotno, sa logografskim sistemom, gde bi dati proglašenje moglo odgovarati nekoliko različitih pisanja, model bi trebao prisustvovati širom kontekstu. Razmjer aktivacije izvan znaka i ukupne aktivacije formira osnovu naše mjere. Uspoređujemo ovo jednostavnom leksičkom mjerom i entropičnom mjerom, kao i nekoliko drugih neuralnih modela, i tvrdimo da na ravnoteži naše mjere na temelju pažnje najbolje odgovara\nsa intuicijom o tome kako su logografski različiti sistemi. Naš rad pruža prvu kvantificiranu mjeru pojma logografije koja se uklapa sa jezičkom intuicijom i, svađamo se, pruža bolji uvid u ono što ova pojma znači.', 'so': 'Xirfaha qoraalka marka laga bilaabo Gelb (1952) waxay ku qoran yihiin nidaamka qoraalka oo ay ku qoran yihiin waxa ay ku qoran yihiin: haddii ay ka representaan hadal ama morpheem, waa qoraal; haday leeyihiin biil, dhaqan; haddii qeybo, alphabetic; sidaa darteed Sproat (2000) iyo Rogers (2005) waxay ku burbureen cilmiga sida ay u kala qeybiyeen logografiga iyo afafka dhinacyada labada dhinac, taasoo lagu daray qorografiga si aan loo kala soocayn. nidaam wuxuu noqon karaa mid dhaqdhaqaaq ah oo aad u sawiraan; ama alphabetic, sida badan logografi aan aheyn. Taasi si wanaagsan ayuu u oggolaadaa sida qoraalku u shaqeeyo, laakiin qofka qoraya horay uma uu soo jeedin karo qaab qiyaasta logografiga. Qoraalkan waxaan soo jeedaynaa qiyaastii sawir ah ee shahaadada logografiga, kaas oo isticmaalaya tusaale hoos-u-jeeda oo loo baray si loo sii sheego sawirka calaamada laga soo bandhigo. Isticmaalka fikrada ee fikradda ah waxaa u baahan in modelku uu tago calaamada joogtada oo kaliya si uu u xisaabo sida loo sawiro, taasuna waxay ku muuqan doontaa waxqabadka kaleemeysiga. Iska duwan, marka lagu jiro nidaamka logografiga, meesha lagu ogeysiiyo uu ku habboon karo warqado kala duduwan, waxaa loo baahan yahay in modellka ku jirto hoos aad u ballaadhan. Qiimaha waxqabadka ka baxsan calaamada iyo waxqabadka oo dhamaantiisu waxay sameeyaa aasaaska qiyaastayada. Waxan waxaynu isbarbardhignaa qiyaas fudud oo lexic ah iyo qiyaastii hore iyo sidoo kale tusaalayaal kale oo neurada ah, waxaynu ka fekernaa in ku saabsan qiyaasta aad u taxadar karto\niyo fikr ku saabsan nidaamka logografiga kala duduwan Shaqo-keentayadu wuxuu bixiyaa fikrada logografiga ee ugu horeeyay oo qiyaas ah, kaas oo ku saabsan fikrada luuqadda, waxaynu ka doodaynaa inay ka fiirsato waxa fikradan looga jeedo.', 'si': 'ගෙල්බ් (1952) පස්සේ ලියුම් පද්ධතියේ තැක්සොනෝමිස් ලියුම් සංඥාවට පද්ධතිය තියෙනවා: ඔවුන් වචන නැත්නම් මොර්ෆීම් වලි සිල්බල්, සිල්බික්; භාගයක්, ඇල්ෆේබටික්; ඒ වගේම. Name පද්ධතියක් සිල්ලාබික් වෙන්න පුළුවන්, ගොඩක් ලොග්\u200dරාෆික් වෙන්න පුළුවන්; නැත්තම් ලොග්\u200dරාෆික් නැත්තම්. මේක හොඳයි ලියන පද්ධතිය ඇත්තටම කොහොමද වැඩ කරන්නේ කියලා, නමුත් ලේඛකයා ලොග්\u200dරාෆික් වැඩ කරන්න විදිහක මේ ලිපිනයේ අපි ලොග්\u200dරාෆිකාවේ ප්\u200dරමාණයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා මේ ලොග්රාෆිකාවේ අවධානයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය ක අදහස් ෆෝනෝග්\u200dරාෆික් පද්ධතියෙන්, මොඩේල් එක ප්\u200dරස්ථිත ටෝකෙන් විතරයි ඒක කොහොමද බලන්නේ කියලා ගණන් කරන්න, ඒ වගේම මේක අ ප්\u200dරතික්\u200dරමයෙන්, ලොග්\u200dරාෆික් පද්ධතියෙන්, දෙන්න ප්\u200dරතික්\u200dරමයක් වෙනස් වර්තනයකට සම්බන්ධ වෙන්න පුළුවන්, මොඩේල්  සක්\u200dරීය සහ සම්පූර්ණ සක්\u200dරීය සම්පූර්ණ සක්\u200dරීය සම්පූර්ණය අපේ මාපයේ අධාරණය. අපි මේක සාමාන්\u200dය ලෙක්සිකල් මාර්ගයක් සමග සම්පූර්ණය කරනවා, එන්ට්\u200dරොපික් මාර්ගයක් සමග අනිත් න්\u200dයූරාල් මාර්ගයක් සමග සම\nලෝග්\u200dරාෆික් විවිධ පද්ධතිය කොහොමද කියලා බලන්නේ. අපේ වැඩේ පළමු විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් ලොග්\u200dරාෆික් අ', 'sv': 'Taxonomier för skrivsystem sedan Gelb (1952) har klassificerat system baserat på vad de skrivna symbolerna representerar: om de representerar ord eller morfemer, är de logografiska; Om stavelser, stavelser. Om segment, alfabetiskt. och så vidare. Sproat (2000) och Rogers (2005) bröt med traditionen genom att dela upp logografiska och fonografiska aspekter i två dimensioner, där logografin graderades snarare än kategoriskt. Ett system kan vara stavelsemässigt och mycket logografiskt. eller alfabetisk, och mestadels icke-logografisk. Detta överensstämmer bättre med hur skrivsystem faktiskt fungerar, men ingen av författarna föreslog en metod för mätning av logografi. I den här artikeln föreslår vi ett nytt mått på graden av logografi som använder en uppmärksamhetsbaserad sekvens-till-sekvensmodell utbildad för att förutsäga stavningen av en token från dess uttal i sammanhang. I ett idealiskt fonografiskt system bör modellen endast behöva ägna sig åt den aktuella token för att beräkna hur man stavar den, och detta skulle visa sig i uppmärksamhetsmatriskaktiveringar. Däremot, med ett logografiskt system, där ett visst uttal kan motsvara flera olika stavningar, skulle modellen behöva ägna sig åt ett bredare sammanhang. Förhållandet mellan aktiveringen utanför token och den totala aktiveringen utgör grunden för vår åtgärd. Vi jämför detta med ett enkelt lexikalt mått, och ett entropiskt mått, samt flera andra neurala modeller, och hävdar att vår uppmärksamhetsbaserade mått på det hela taget överensstämmer bäst\nmed intuition om hur logografiska olika system är. Vårt arbete ger det första kvantifierbara måttet på begreppet logografi som överensstämmer med språklig intuition och ger, menar vi, bättre insikt i vad detta begrepp innebär.', 'ur': 'گلب (1952) کے بعد لکھنے کی سیستم کی تاکسونومیز لکھنے والی سیستم کے ذریعے لکھی ہوئی سیستموں کو لکھی ہوئی سیستموں پر بنیاد رکھتا ہے: اگر وہ لکھی ہوئی نشانیوں کی تعریف کرتی ہیں، تو یہ لگوگرافی ہیں، اگر کلاب، کلاب، اگر قسمت، الفبابتی، اور اسی طرح۔ اسپروٹ (2000) اور راجرز (2005) لوگوگرافیک اور فونوگرافیک الگوں کو دو اندازے میں تقسیم کرنے کے ذریعہ سند کے ساتھ ٹکڑے ہوئے، اور لوگوگرافی کو تقسیم کے بغیر گرافی کی جاتی ہے۔ ایک سیسٹم کلابیک اور بہت لوگوگرافیک ہو سکتا ہے۔ یا الفابتیک، اور اکثر غیر لوگوگرافیک۔ یہ بہتر بات ہے کہ لکھنے کی سیستموں کو کس طرح کام کرتی ہے، لیکن نہ لکھنے والے لگوگرافی کا اندازہ کرنے کے لئے ایک طریقہ پیش کیا کرتے ہیں. اس مقالہ میں ہم لوگوگرافی کے درجے کا ایک نو اندازہ پیشنهاد کرتے ہیں جو توجه کے ذریعے ایک نظر اندازے کی طریقہ کی طریقہ کی طریقہ سے استعمال کرتا ہے ایک ایڈیل فونوگرافیک سیسٹم میں، موڈل کو صرف موجود ٹوکنے پر حاضر ہونا چاہیے تاکہ اسے کس طرح سمجھنے کا شمار کرے، اور یہ اظہار ماٹریکس فعالیت میں دکھائے گا. مخالف، ایک لوگوگرافیک سیسٹم کے ساتھ، جہاں ایک عطا کی تعریف چند مختلف باتوں کے ساتھ مل سکتی ہے، اس مدل کو زیادہ وسیع سیسٹم کے ساتھ ملنے کی ضرورت ہے. ٹوکین کے باہر فعالیت کی نسبت اور کامل فعالیت ہمارے اندازے کی بنیاد بناتی ہے. ہم اسے ایک ساده لکھی ناپ سے اور ایک انٹروپیک ناپ سے مقایسہ کرتے ہیں، اور بہت سے اور نئورل موڈل سے، اور جھگڑتے ہیں کہ ہماری توجه کی ناپ کی توازن پر اچھی طرح ہے\nلوگوگرافیک مختلف سیستموں کے بارے میں نظر سے۔ ہمارا کام لوگوگرافی کے منظور کی پہلی مقدار قابل اندازہ دیتا ہے جو زبان کی نظر سے مطابق ہے اور ہم جھگڑتے ہیں، اس کا اچھا اندازہ دیتا ہے کہ اس کا معنی کیا ہے۔', 'ta': 'ஜெல்ப் (1952) முதலில் எழுதும் முறைமைகளின் படிப்பெண்கள் எழுதும் அமைப்புகள் எழுதும் குறியீடுகளை என்ன குறிப்பிடும் என்பதை அடிப்படையாக வகுப் சில்லாபிக் என்றால் துண்டுகள், ஆல்பாபெட்டி and so forth.  ஸ்ப்ரூவாட் (2000) மற்றும் ரோஜெர்ஸ் (2005) புகுநிரல் மற்றும் போனோகிராபிக் பகுதிகளை இரண்டு பரிமாணத்தில் பிரித்து, வகுப்பு வேறுபாட்டை விட தரப்படுத்து ஒரு அமைப்பு சில்லாபிக் மற்றும் மிகவும் உயர்ந்த நுட்பத்தியலாக இருக்கலாம். அல்லது ஆல்பாபெட்டிக்கு, பெரும்பாலாக பதிவு இல்லாத இது எப்படி எழுதும் அமைப்புகள் வேலை செய்யும் என்பதை நல்ல அனுமதிக்கிறது, ஆனால் ஆசிரியர் எந்த முறையிலும் பதிவுரையை அளவிட இந்த கட்டுரை ஒரு சிந்தனையான போனோக்கிராபிக் அமைப்பில், தற்போதைய குறியீட்டை மட்டும் சேர்க்க வேண்டும், இதை எப்படி சொல்ல வேண்டும் என்று கணக்கிட, இது  மாறாக, கொடுக்கப்பட்ட முறைமையுடன், பல வித்தியாசமான சொற்களுக்கு பொருத்தமாக இருக்கலாம், மாதிரியில் ஒரு விரிவான சூழலுக்கு செல் குறியீட்டிற்கு வெளியே செயல்பாட்டின் விகிதம் மற்றும் மொத்த செயல்பாடு எங்கள் அளவின் அடிப்படையை வடிவமைக் நாம் இதை எளிய லெக்சிக்சியல் அளவுடன் ஒப்பிடுகிறோம் மற்றும் சில புதிய மாதிரிகளுடனும் ஒப்பிடுகிறோம்.\nமுறைமைகள் எப்படி இருக்கிறது என்பதை பற்றி புரிந்து கொள்ளும். எங்கள் வேலையில் முதல் அளவு நிறைவேற்றும் கருத்து கொடுக்கிறது அது மொழியான உணர்வுடன் ஒப்புக்கொள்கிறது மற்றும் நாம் வாதம் செய்து, இந்த', 'no': 'Taksonomiar av skrivesystemet sidan Gelb (1952) har klassifiserte systemer basert på kva skrivesymbolet representerer. Dersom dei representerer ord eller morferar, er dei logografiske. viss syllabler, syllabic; viss syllabler, syllabic; og om segment, alfabetisk; om segment, alfabetisk; og og så framover. Sproat (2000) og Rogers (2005) breide med tradisjonen ved å dele logografiske og fonografiske aspektane til to dimensjonar, med logografi blir gradert i staden for ein kategorisk skildring. Name eller alfabetisk, og hovudsakelig ikkje-logografisk. Dette tilpassar bedre korleis skrivesystemet faktisk fungerer, men ingen forfattar foreslått ein metode for å måla logografi. I denne artikkelen foreslår vi eit romant mål på logografi som brukar ein oppmerksbasert sekvens- til- sekvensmodell treng for å foreslå stavinga av eit teikn frå sin uttale i kontekst. I eit ideell fonografisk systemet må modellen berre delta på den gjeldande tegnet for å rekna ut korleis det skal skrivast, og dette vil visa i oppmerksmatrisen. I contrast, with a logographic system, where a given pronunciation might correspond to several different spellings, the model would need to attend to a broader context. Forholdet til aktiveringa utenfor teiknet og totalaktiveringa er grunnlag av målet vår. Vi samanliknar dette med ein enkel leksisk mål, og ein entropisk mål, og fleire andre neuralmodeller, og argumenterer at på balansering av merksomhetsbaserte mål våre beste tilhøyrer\nmed intuisjon om korleis loggografiske ulike systemar er. Arbeidet vårt tilbyr den første kvantifiserte målene på noen av logografi som tilsvarar linguistiske intuisjon og, vi argumenterer, tilbyr betre innsyning i kva denne noen betyr.', 'vi': 'Thuế về các hệ thống chữ viết kể từ thời Gelb (1952) đã phân loại hệ thống dựa trên các biểu tượng chữ viết: nếu chúng đại diện từ ngữ hay morphine, chúng là biểu tượng. nếu âm tiết. nếu đoạn, theo thứ tự; và vân vân. Sprate (2000) và Rogers (200Rs) đã phá vỡ truyền thống bằng cách chia các khía cạnh biểu tượng và vẽ thành hai chiều, chứ không phải là phân biệt dứt khoát. Một hệ thống có thể được âm tiết, và được đăng ký cao. hoặc theo vần, và hầu hết không biểu tượng. Điều này phù hợp với cách viết hệ thống thực sự hoạt động, nhưng không có tác giả nào đề xuất phương pháp đo biểu tượng. Trong bài báo này, chúng tôi đề xuất một thước đo mới về mức độ đăng ký sử dụng một mô hình dãy-tới-trình-lập tập trung được huấn luyện để dự đoán chính tả của biểu tượng từ phát âm trong ngữ cảnh. Trong một hệ đài phát âm lý tưởng, người mẫu cần phải chú ý chỉ tới vật lưu động hiện thời để tính to án cách đánh vần nó, và nó sẽ hiển thị trong kích hoạt ma trận chú ý. Tuy nhiên, với hệ thống logo, nơi phát âm được phát âm tương ứng với nhiều phát âm khác nhau, mô hình sẽ cần phải quan tâm tới một ngữ cảnh rộng hơn. Tỷ lệ kích hoạt ngoài biểu tượng và kích hoạt tổng thể là căn cứ của dự án của chúng ta. Chúng tôi so sánh nó với một thước đo ngôn ngữ đơn giản, và một thước đo cánh tả, cũng như nhiều loại thần kinh khác, và tranh luận rằng trên cân bằng, biện pháp tập trung của chúng tôi phù hợp tốt nhất.\nvới trực giác về cách sử dụng các hệ thống logo. Công việc của chúng tôi cung cấp một thước đo định lượng đầu tiên của khái niệm "logo" theo trực giác ngôn ngữ và, chúng tôi tranh luận, cung cấp tầm nhìn tốt hơn về ý nghĩa của khái niệm này.', 'uz': "(1952) yildan, Gelb (1952) bilan yozish tizimlarining taxonomlari yozish tizimlari yozib qo'llangan tizimlarni qo'llangan: agar ularning so'zlar yoki morphemlarni tashqarishga ega bo'lsa, ular logografik; va agar rasmlar, katak; agar belgilar, alfabetik; va shunday qilib. Name Tizim syllab va juda katta logografik bo'lishi mumkin; yoki alfabetik va ko'pchilik logografik emas. This accords better with how writing systems actually work, but neither author proposed a method for measuring logography.  Bu maqolada, biz logografiya darajasining novel oʻlchamini talab qilamiz. Bu foydalanuvchi qismni tahrirlash uchun foydalanadigan qiymatning imkoniyatini tahrirlash mumkin. Tanlangan fikrlar fonografik tizimda, model uni qanday tekislash uchun faqat joriy belgini qidirish uchun foydalanishi kerak. Bu matrix aktivlarida koʻrsatiladi. Ikkinchi tomonda, logografik tizimi bilan, xususiyatli bir necha hil imkoniyatlarning bir xil imkoniyatlariga bog'liq boʻlishi mumkin, model kengaytirish kerak. Amalning chegarasining chegarasi va hamma aktiv amalning asosimizni yaratadi. Biz bu narsalarni oddiy leksik tartibi va eng narsa va boshqa neyron modellar bilan kamaytamiz va bizning tasavvur bilan o'xshash mumkin, bizning tasavvur o'zgarishga qaramaymiz mumkin.\nlogografik har xil tizimlar qanday bo'lishini anglatadi. Bizning ishimiz logografiya fikrlarining birinchi qiymatiga ega bo'ladi va biz murakkab qilamiz, bu fikrlarning ma'nosini nima qilishiga yaxshi ko'rinishimiz mumkin.", 'de': 'Taxonomien von Schreibsystemen seit Gelb (1952) haben klassifizierte Systeme basierend auf dem, was die geschriebenen Symbole repräsentieren: wenn sie Wörter oder Morpheme darstellen, sind sie logographisch; wenn Silben, Silben; wenn Segmente alphabetisch sind; und so weiter. Sproat (2000) und Rogers (2005) brachen mit der Tradition, indem sie die logographischen und phonographischen Aspekte in zwei Dimensionen aufteilten, wobei die Logographie eher abgestuft als kategorisch unterschieden wurde. Ein System könnte syllabisch und in hohem Maße logographisch sein; oder alphabetisch und meist nicht logographisch. Dies stimmt besser mit der Funktionsweise von Schreibsystemen überein, aber keiner der Autoren schlug eine Methode zur Messung der Logographie vor. In diesem Artikel schlagen wir ein neuartiges Maß für den Grad der Logographie vor, das ein aufmerksamkeitsbasiertes Sequenzmodell verwendet, das trainiert ist, die Schreibweise eines Tokens aus seiner Aussprache im Kontext vorherzusagen. In einem idealen phonographischen System sollte das Modell nur auf das aktuelle Token achten müssen, um zu berechnen, wie es geschrieben wird, und dies würde in den Aufmerksamkeitsmatrix-Aktivierungen zeigen. Im Gegensatz dazu müsste das Modell bei einem logographischen System, bei dem eine bestimmte Aussprache mehreren verschiedenen Schreibweisen entsprechen könnte, einem breiteren Kontext Rechnung tragen. Das Verhältnis der Aktivierung außerhalb des Tokens und der Gesamtaktivierung bildet die Grundlage unserer Maßnahme. Wir vergleichen dies mit einem einfachen lexikalischen Maß und einem entropischen Maß sowie mehreren anderen neuronalen Modellen und argumentieren, dass unser aufmerksamkeitsbasiertes Maß im Gleichgewicht am besten übereinstimmt.\nMit Intuition darüber, wie logographisch verschiedene Systeme sind. Unsere Arbeit liefert das erste quantifizierbare Maß für den Begriff der Logographie, das der linguistischen Intuition entspricht und, so argumentieren wir, einen besseren Einblick in das, was dieser Begriff bedeutet.', 'da': 'Taxonomier af skrivesystemer siden Gelb (1952) har klassificeret systemer baseret på, hvad de skrevne symboler repræsenterer: Hvis de repræsenterer ord eller morfemer, er de logografiske; hvis stavelser, stavelser hvis segmenter, alfabetisk og så videre. Sproat (2000) og Rogers (2005) brød med traditionen ved at opdele logografiske og fonografiske aspekter i to dimensioner, hvor logografien blev klassificeret snarere end en kategorisk skelnen. Et system kunne være sygebeligt og meget logografisk; eller alfabetisk, og for det meste ikke-logografisk. Dette stemmer bedre overens med, hvordan skrivesystemer rent faktisk fungerer, men ingen af forfatterne foreslog en metode til måling af logografi. I denne artikel foreslår vi et nyt mål for graden af logografi, der bruger en opmærksomhedsbaseret sekvens-til-sekvensmodel uddannet til at forudsige stavningen af et token ud fra dets udtale i kontekst. I et ideelt fonografisk system bør modellen kun behøve at tage sig af den nuværende token for at beregne, hvordan man staver det, og dette ville vise sig i opmærksomheds matrix aktiveringer. I modsætning til, at med et logografisk system, hvor en given udtale kan svare til flere forskellige stavemåder, ville modellen skulle tage sig af en bredere kontekst. Forholdet mellem aktiveringen uden for token og den samlede aktivering danner grundlaget for vores foranstaltning. Vi sammenligner dette med en simpel leksikalsk måling, og en entropisk måling, samt flere andre neurale modeller, og argumenterer for, at vores opmærksomhedsbaserede måling i balance passer bedst\nmed intuition om, hvordan logografiske forskellige systemer er. Vores arbejde giver det første kvantificerbare mål for begrebet logografi, der er i overensstemmelse med sproglig intuition, og vi argumenterer for, giver bedre indsigt i, hvad dette begreb betyder.', 'hr': 'Taksonomije pisaćeg sustava od Gelba (1952) imaju klasifikirane sustave na temelju onoga što napisani simboli predstavljaju: ako predstavljaju riječi ili morfije, logografični su; ako špiljarke, silabac; ako segmenti, alfabetički; i tako dalje. Sproat (2000) i Rogers (2005) prekinuli su tradicijom razdvajanjem logografskih i fonografskih aspekta u dvije dimenzije, s ocjenom logografije umjesto kategorijskih razlika. Sistem bi mogao biti silabetski i jako logografski; ili alfabetično, i uglavnom ne-logografično. To se bolje dogovara kako napisani sustavi zapravo funkcioniraju, ali ni autor nije predložio metodu za mjerenje logografije. U ovom članku predlažemo novu mjeru stupnja logografije koja koristi model koji je osnovan na pažnji sekvenciji na sekvenciji obučen kako bi predvidjela pisanje znaka iz njegove izjave u kontekstu. U idealnom fonografskom sustavu, model bi trebao prisustvovati samo trenutnom znaku kako bi računalo kako ga pisati, a to bi pokazalo u aktivaciji pažnje matrice. Za suprotno, sa logografskim sustavom, gdje bi dati proglašenje moglo odgovarati nekoliko različitih pisanja, model bi trebao prisustvovati širem kontekstu. Razmjer aktivacije izvan znaka i ukupne aktivacije formira temelj naše mjere. Uspoređujemo ovo jednostavnom leksičkom mjerom i entropičnom mjerom, kao i nekoliko drugih neuronskih modela, i tvrdimo da na ravnoteži naše mjere na temelju pažnje najbolje odgovara\nsa intuicijom o tome kako su logografski različiti sustavi. Naš rad pruža prvu kvantificiranu mjeru pojma logografije koja odgovara jezičkoj intuiciji i, tvrdimo, pruža bolji uvid u ono što ova pojma znači.', 'bg': 'Таксономиите на системите за писане от Гелб (1952 г.) имат класифицирани системи въз основа на това, което представляват писмените символи: ако представляват думи или морфеми, те са логографски; ако срички - срички; ако сегменти - азбучен; и така нататък. Спроат (2000) и Роджърс (2005) прекъсват традицията, като разделят логографските и фонографските аспекти на две измерения, като логографията се оценява по-скоро, отколкото категорично разграничаване. Системата може да бъде сричка и силно логографска; или азбучен, и най-вече нелогографски. Това съответства по-добре на начина, по който всъщност работят системите за писане, но нито един от авторите не предлага метод за измерване на логографията. В тази статия предлагаме нова мярка за степента на логография, която използва модел, базиран на вниманието последователност към последователност, обучен да предвижда правописа на символ от произношението му в контекста. В идеалната фонографска система моделът трябва да се грижи само за текущия символ, за да изчисли как да го произнесе, и това ще се покаже в активиранията на матрицата на вниманието. За разлика от това, при логографската система, където дадено произношение може да съответства на няколко различни правописи, моделът трябва да се съобрази с по-широк контекст. Съотношението на активирането извън токена и общото активиране формира основата на нашата мярка. Сравняваме това с проста лексикална мярка и ентропична мярка, както и с няколко други невронни модела и твърдим, че в баланс нашата мярка, базирана на вниманието, отговаря най-добре\nс интуиция за това колко логографски са различните системи. Нашата работа осигурява първата количествено измерима мярка на понятието логография, която съответства на лингвистичната интуиция и, твърдим, дава по-добра представа за това какво означава това понятие.', 'nl': 'Taxonomieën van schrijfsystemen sinds Gelb (1952) hebben geclassificeerde systemen gebaseerd op wat de geschreven symbolen vertegenwoordigen: als ze woorden of morfemen vertegenwoordigen, zijn ze logografisch; indien lettergrepen, lettergrepen; indien segmenten, alfabetisch; en ga zo maar door. Sproat (2000) en Rogers (2005) braken met de traditie door de logografische en fonografische aspecten in twee dimensies te splitsen, waarbij logografie eerder werd gegradeerd dan een categorisch onderscheid. Een systeem kan syllabisch en zeer logografisch zijn; of alfabetisch, en meestal niet-logografisch. Dit komt beter overeen met hoe schrijfsystemen eigenlijk werken, maar geen van de auteurs stelde een methode voor om logografie te meten. In dit artikel stellen we een nieuwe maat voor de mate van logografie voor die gebruikmaakt van een attentie-based sequence-to-sequence model getraind om de spelling van een token te voorspellen vanuit zijn uitspraak in context. In een ideaal fonografisch systeem moet het model alleen aandacht besteden aan de huidige token om te berekenen hoe het moet worden gespeld, en dit zou zichtbaar zijn in de attentiematrix activaties. In tegenstelling tot een logografisch systeem, waarbij een bepaalde uitspraak kan overeenkomen met verschillende spellingen, zou het model rekening moeten houden met een bredere context. De verhouding tussen de activering buiten de token en de totale activering vormt de basis van onze maatregel. We vergelijken dit met een eenvoudige lexicale maatstaf, en een entropische maatstaf, evenals verschillende andere neurale modellen, en stellen dat in balans onze aandacht gebaseerde maatstaf het beste overeenkomt\nMet intuïtie over hoe logografisch verschillende systemen zijn. Ons werk biedt de eerste kwantificeerbare maatstaf van het begrip logografie die overeenkomt met de linguïstische intuïtie en, volgens ons, een beter inzicht geeft in wat dit begrip betekent.', 'id': 'Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent: if they represent words or morphemes, they are logographic;  jika silabel, silabel; jika segmen, alfabet; dan sebagainya. Sproat (2000) dan Rogers (2005) pecah dengan tradisi dengan membagi aspek logografis dan fonografik ke dua dimensi, dengan logografi ditandai daripada perbedaan kategoris. Sebuah sistem bisa menjadi silabis, dan sangat logografis; atau alfabet, dan kebanyakan bukan logografis. Ini lebih cocok dengan bagaimana sistem menulis benar-benar bekerja, tetapi tidak seorang penulis mengusulkan metode untuk mengukur logografi. Dalam artikel ini kami mengusulkan ukuran baru dari tingkat logografi yang menggunakan model urutan-urutan berdasarkan perhatian yang dilatih untuk memprediksi ejaan token dari pronunciasinya dalam konteks. Dalam sistem fonografik ideal, model harus menghadiri hanya token saat ini untuk menghitung bagaimana mengeja itu, dan ini akan menunjukkan dalam aktivasi matriks perhatian. Sebaliknya, dengan sistem logografis, di mana pronunciasi tertentu mungkin berkorresponsi dengan beberapa ejaan yang berbeda, model akan perlu menghadiri konteks yang lebih luas. Rasio aktivasi diluar token dan total aktivasi membentuk dasar ukuran kita. Kita membandingkan ini dengan ukuran lexik sederhana, dan ukuran entropik, serta beberapa model saraf lainnya, dan berdebat bahwa pada keseimbangan ukuran berdasarkan perhatian kita sesuai dengan yang terbaik\ndengan intuisi tentang bagaimana berbagai sistem logografis. Pekerjaan kami menyediakan ukuran kuantifikasi pertama dari gagasan logografi yang sesuai dengan intuisi bahasa dan, kami berdebat, menyediakan pengetahuan yang lebih baik tentang apa gagasan ini berarti.', 'fa': 'تاکسونومی از سیستم نوشتن از زمانی که گلب (۱۹۵۲) سیستم\u200cهای مختصری بر اساس نشانه\u200cهای نوشته\u200cها معرفی می\u200cکنند، دارند: اگر آنها کلمات یا مورفی را معرفی می\u200cکنند، آنها لوگوگرافی هستند. اگر کلابها، کلابی است؛ اگر بخش\u200cها، الفبابتی\u200cها، و همچنین. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction. سیستم می\u200cتواند کلابی باشد و بسیار لوگوگرافیک باشد. یا الفبا و بیشتر غیر لوگوگرافیک. این بهتر با چگونه سیستم نوشتن در واقع کار می کند، اما هیچ نویسنده\u200cای برای اندازه\u200cگیری لاگوگرافی پیشنهاد نمی\u200cکند. در این مقاله ما یک اندازه رمانی از درجه لوگوگرافی پیشنهاد می\u200cکنیم که از یک مدل توجه به رده\u200cای آموزش داده شده برای پیش\u200cبینی کردن نوشته\u200cای از نوشته\u200cاش در محیط استفاده می\u200cکند. در یک سیستم فونوگرافی ایده، مدل باید تنها به نشان فعلی حاضر باشد تا محاسبه چگونه نوشته شود، و این در فعالیت ماتریکس توجه نشان دهد. بر خلاف این، با یک سیستم لوگوگرافیک، جایی که یک گزارش داده می\u200cتواند با چند نوشته\u200cهای مختلف مرتبط باشد، مدل باید به یک محیط گسترده\u200cتر حاضر شود. نسبت فعالیت بیرون علامت و فعالیت کامل بنیاد اندازه ما را شکل می دهد. ما این را با یک اندازه زبانی ساده مقایسه می کنیم، و یک اندازه انتروپیک، و چند مدل عصبی دیگر، و بحث می کنیم که بر مقایسه اندازه\u200cهای توجه ما بهترین ترتیب دارد\nبا توجه به نظر چگونه سیستم های مختلف لوگوگرافیک هستند. کار ما اولین اندازه قابل تعداد اندازه\u200cای از نظر لاگوگرافی که با نظر زبان\u200cشناسی مشترک است، و ما بحث می\u200cکنیم، به نظر بهتر این نظر را به معنی چی می\u200cدهد، می\u200cرسد.', 'sw': 'Taxonomia za mfumo wa kuandika tangu Gelb (1952) wamekuwa na mifumo ya kutangaza kwa msingi wa kile ambacho ishara za maandishi zinaonyesha: kama wanawakilisha maneno au maneno ya kifo, hizo ni logografia; kama misitu, utambulisho; kama sehemu, alfafabeti; na mpaka sasa. Mapinduzi (2000) na Rogers (2005) yalivunja kwa utamaduni kwa kugawanya vipande vya logographic na simu viwili, na kwa ajili ya logography kuendelea daraja kuliko tofauti ya makundi. Mfumo unaweza kuwa utaratibu wa kijinsia na utambulisho mkubwa; au alfafabeti, na zaidi sio logografia. Hii inaruhusu vizuri kwa jinsi mifumo ya kuandika inavyofanya kazi, lakini wala mwandishi hakupendekeza njia ya kupunguza logografia. Katika makala hii tunapendekeza hatua ya riwaya ya kiwango cha logografia ambacho kinatumia mtindo wa mfululizo wa mfululizo wa mfululizo wa ufuatiliaji wa kutabiri ujumbe wa alama kutoka kwenye matangazo yake. Katika mfumo wa picha za kiitikadi, muundo unapaswa kuhudhuria alama ya sasa pekee ili kuhesabu namna ya kutafsiri, na hii itaonyesha katika shughuli za kisasa. Tofauti na hilo, kwa mfumo wa logografia, ambapo utangazaji unaweza kulingana na maneno kadhaa tofauti, mtindo huo unatakiwa kuhudhuria mazingira mengi. Kiwango cha shughuli nje ya alama na shughuli zote kinatengeneza msingi wa hatua yetu. Tunawalinganisha hili kwa hatua rahisi za lexico, na hatua ya mtazamo, pamoja na mifano mingine ya neurali, na tunahoji kwamba kwa usawa wa hatua za kusikiliza inakubalika vizuri zaidi\nna ufahamu kuhusu mifumo mbalimbali ya logografia. Kazi yetu inatoa hatua ya kwanza ya kufikiri ya logografia inayompa mtazamo wa lugha na, tunahoji, inatoa uelewa mzuri wa kile kinachomaanisha dhana hii.', 'ko': 'Gelb(1952) 이후 쓰기 시스템의 분류법은 쓰기 기호가 대표하는 내용에 따라 시스템을 분류했다. 만약에 단어나 어소를 대표한다면 이것은 표지이다.만약 음절이라면 음절이다.세그먼트의 경우 알파벳순으로 정렬합니다.잠깐만요.Sproat(2000)과 Rogers(2005)는 전통을 깨고 표지와 음상을 두 차원으로 나누어 표지를 분류하고 구분하는 것이 아니라 등급을 나눈다.하나의 시스템은 음절의 고도로 기호화될 수 있다.혹은 자모순으로 배열되어 있고 대부분 표지가 없다.이것은 쓰기 시스템의 실제 작업 방식에 더욱 부합되지만 두 작가 모두 기호를 측정하는 방법을 제시하지 않았다.이 글에서 우리는 새로운 표지도 도량 방법을 제시했다. 이것은 주의를 바탕으로 하는 서열부터 서열 모델까지 사용했다. 이 모델은 훈련을 통해 상하 문장의 발음에 따라 표기된 맞춤법을 예측할 수 있다.이상적인 유성기 시스템에서 모형은 맞춤법을 계산하기 위해 현재 표시만 주목해야 한다. 이것은 주의 행렬의 활성화에 나타날 것이다.그에 비해 logographic 시스템에 대해 주어진 발음은 몇 가지 다른 맞춤법에 대응할 수 있기 때문에 모델은 더욱 광범위한 상하문에 주목해야 한다.기호화폐 밖의 활성화와 총 활성화의 비율은 우리가 평가하는 기초를 이루고 있다.우리는 이를 간단한 어휘 측정, 엔트로피 측정 및 기타 몇 가지 신경 모델과 비교하였으며, 전반적으로 말하면 우리가 주의력을 바탕으로 하는 측정이 가장 잘 부합된다고 여겼다\n직감으로 각종 시스템의 표지를 이해하다.우리의 업무는 첫 번째 언어 직감에 부합되는 기호학 개념의 가량화 도량을 제공했고 이 개념의 의미에 대한 더 좋은 이해를 제공했다고 생각한다.', 'tr': 'Gelb (1952) tarafından bu yana yazma sistemlerinin taksiyonları yazılan sembollerin ne ifade edildiğine dayanan sıralar sistemleri vardır: eğer kelimeler ya da morfomlar ifade etseler, logografiklerdir; unit synonym for matching user input bölekler, elipbi;  We şeýle däl. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded instead of a categorical distinction. Bir sistem sözleşik we ýokary logografiýa bolup biler; ýene-de bir syýasy bolup biler. ýa-da alfabetik we köplenç logografi bolmadyr. Bu ýazma sistemalaryň aslynda nähili işe yarandygyny gowylaşdyrýar, ýöne awtor hem logografiýany ölçüsi üçin bir yöntemi teklip etmedi. Bu makala biz üns berilýän tagrafiýanyň derejesini önlemek üçin bilinmeli terjime-terjime modelini ullanýan logografiýanyň derejesini teklip edip görýäris. ideal fonografik sistemde modeli häzirki token üçin nädip ymlany hasaplamak üçin bu şekilde matriks aktivasynda gösterilir. Mazmunla, logografiň sistemi bilen, bir sözlem birnäçe dürli sözlemlere meňzeş bolmagy mümkin edýär. Modeliň gaty bir kontekste meňzeş bolmaly bolar. Etkinleşik gapysynyň daşynda we jemi faýllaryň ölçümiziň esasyny bejerýär. Muny basit bir leksiýa ölçüsi we entropik ölçüsi bilen karşılaştyrýarys. Diňe nähili nähili nural modelleri we dikkatimiz tabanly ölçümiziň iň gowy pikirlerimizi çykýarys.\nlogografiýanyň nähili üýtgeşikleri barada düşünmek bilen. Çalışmalarymyz ilkinji ýagtylyk düzgünlerine golografiýanyň pikirini saýlaýar we bu pikirin näme diýjek bolsa gowy pikirini saýlaýar.', 'af': "Taxonomies van skryfstelsels vanaf Gelb (1952) het klassifiseerde stelsels gebaseer op wat die skryfe simbole verteenwoordig word: as hulle woorde of morfome verteenwoordig, is hulle logografiese; en amount in units (real) as segmente, alfabetiese; en so. Sproat (2000) en Rogers (2005) het met tradisie gebreek deur die logografiese en fonografiese aspekte in twee dimensies te deel, met logografie gegradeer word eerder as 'n kategoriese verskil. Name of alfabetiese, en meeste nie-logografiese. Dit is beter met hoe skryfstelsels eintlik werk, maar geen outeur het 'n metode voorgestel om logografie te maak nie. In hierdie artikel voorstel ons 'n roman maat van die grad van logografie wat gebruik 'n aandag-gebaseerde sekvensie-na-sekvensie model wat opgelei is om die spel van 'n teken van sy uitsprekking in konteks te voorskou. In 'n ideële fonografiese stelsel moet die model by slegs die huidige teken aangaan om dit te bereken hoe te spel, en hierdie sal in die aandag matriks aktivasies vertoon. In contrast, met 'n logografiese stelsel, waar 'n gegewe uitdrukking dalk mag ooreenstem met verskeie verskeie speletjies, moet die model by 'n breideer konteks aangaan. Die verhouding van die aktivasie buite die token en die totaal aktivasie vorm die basis van ons maat. Ons vergelyk dit met 'n eenvoudige leksiese maat en 'n entropiese maat, en ook verskeie ander neurale modele, en argueer dat op die balans ons aandag-gebaseerde maat die beste ooreenstem\nmet intuisie oor hoe logografiese verskillende stelsels is. Ons werk verskaf die eerste quantifiseerbare maat van die nodiging van logografie wat met lingwisiese intuisie ooreenkomstig en, ons arguseer, verskaf beter inligting in wat hierdie nodiging beteken.", 'sq': 'Taksonomitë e sistemeve të shkrimit që nga Gelb (1952) kanë sisteme të klasifikuar bazuar në atë që simbolet e shkruara përfaqësojnë: nëse përfaqësojnë fjalë apo morfema, ato janë logografike; nëse sillabet, sillabet; nëse segmentet, alfabetike; dhe kështu me radhë. Sproat (2000) dhe Rogers (2005) u thyen me traditën duke ndarë aspektet logografike dhe fonografike në dy dimensione, me logografinë të renditur në vend të një dallim kategorik. Një sistem mund të jetë silabik dhe mjaft logografik; apo alfabetike, dhe kryesisht jo-logografike. Kjo përshtatet më mirë me mënyrën se si funksionojnë sistemet e shkrimit, por asnjë autor nuk propozoi një metodë për matjen e logografisë. Në këtë artikull propozojmë një masë të re të gradës së logografisë që përdorë një model sekuencë-në-sekuencë të bazuar në vëmendje të trajnuar për të parashikuar shkrimin e një shenjë nga shprehja e saj në kontekst. Në një sistem fonografik ideal, modeli duhet të ndjekë vetëm token aktuale me qëllim që të llogarisë si ta shkruajë atë, dhe kjo do të tregohet në aktivitetet e matricës së vëmendjes. Në ndryshim, me një sistem logografik, ku një shprehje e caktuar mund të korrespondojë me disa ortografi të ndryshme, modeli do të duhet të ndjekë një kontekst më të gjerë. Raporti i aktivizimit jashtë token dhe aktivizimit total formon bazën e masave tona. Ne e krahasojmë këtë me një masë të thjeshtë lexike, dhe një masë entropike, si dhe disa modele të tjera neuronale, dhe argumentojmë se në balancë masa jonë bazuar në vëmendje përshtatet më mirë\nme intuicion se si janë sistemet e ndryshme logografike. Puna jonë ofron masën e parë kuantifikuese të konceptit të logografisë që përputhet me intuicionin gjuhësor dhe, argumentojmë, ofron një kuptim më të mirë në se çfarë do të thotë ky koncept.', 'am': 'ከጌልብ (1952) ጀምሮ የጽሑፍ ድምፅ ስርዓቶች የጽሕፈት ምልክቶች ምን እንደምታሳዩ የተመሳሳይ ሲስተካከሉ፤ ቃላት ወይም ሞክራፊም ቢሆን ሎographic ናቸው፡ ባርቢክ ክፍሎች ከዚህም በኋላ የሎographic እና የፎኖግራፊ ጉዳዮችን ለሁለት ምዕራፍት በመለየ (2000) እና ሮጋርስ (2005) በተለየ ወግ አፈረሱ፡፡ ሲስተም በሙሉ፣ እና ብዙ ሎographic ሊሆን ይችላል:: ወይም አልፋብቲክ፣ አብዛኛውም የሎographic ይህ የጽሕፈት ስርዓት እንዴት እንደሚሠራ ይሻላል፤ ነገር ግን የጦማሪው የሎography ማሰናከል ልማድ የለውም፡፡ በዚህ ጽሑፍ ውስጥ የባሕላዊ የጦography አካባቢ እናሳውቃለን፡፡ በአሳባቢው ፎኖግራፊ ስርዓት፣ ሞዴል እንዴት እንደሚቃወም ይቆጠር ዘንድ ብቻ ያስፈልጋል፡፡ በተለይ፣ የሎographic ስርዓት፣ የተሰጠ አዋጅ በተለየ ቋንቋዎች ይደሰታል፡፡ የአካባቢው ክፍል ውጭ እና ሙሉ ተግባር የስፍርነታችንን መሠረት ይሠራል፡፡ ይህንን ቀላል ልስክሲካዊ መስኮት እና አካባቢ መስኮት እናስተያየዋለን፣ እናም ሌሎችን የነጥብ ዓይነቶች እናዋርዳለን፡፡\nየሎographic ብዛት እንዴት እንደሆኑ Our work provides the first quantifiable measure of the notion of logography that accords with linguistic intuition and, we argue, provides better insight into what this notion means.', 'hy': 'Գրացման համակարգերի տաքսոնամիաները 1952 թ.-ից սկսած Գելբի (Գելբ) համակարգերը դասակարգված են, հիմնված այն բանի վրա, ինչ գրված խորհրդանիշները ներկայացնում են. եթե նրանք ներկայացնում են բառեր կամ մորֆեմներ, դրանք լո եթե խոսքերը, խոսքերը, եթե բաժինները` ալֆետիկ, և այլն: Spread (2000) և Ռոջերսը (2005) խախտեցին ավանդույթների հետ՝ բաժանելով լոգոգրաֆիկ և ֆոնոգրաֆիկ ասպեկտները երկու չափով, որտեղ լոգոգրաֆիան դասակարգում է, ոչ թե կատեգորիկական տարբերակ: Համակարգը կարող է լինել սիլաբիկ և շատ լոգոգրաֆիկ, or alphabetic, and mostly non-logographic.  Սա ավելի լավ համապատասխանում է գրողական համակարգերի աշխատանքին, բայց ոչ մի հեղինակ չի առաջարկել լոգոգրաֆիայի չափման մեթոդ: Այս հոդվածի մեջ մենք առաջարկում ենք լոգոգրաֆիայի աստիճանի նոր չափումներ, որոնք օգտագործում են ուշադրության հիմնված հաջորդականության մոդել, որը պատրաստված է կանխագուշակել նշանի գրությունը դրա արտահայտությունից կոնտեքստում: Իդեալական ֆոնոգրաֆիկ համակարգում մոդելը պետք է օգտագործի միայն ներկայիս նշանը, որպեսզի հաշվարկի, թե ինչպես գրել այն, և սա ցույց կտա ուշադրության մատրիքսի ակտիվացման մեջ: Ի հակադրություն դրան, լոգոգրաֆիկ համակարգի հետ, որտեղ տվյալ արտահայտությունը կարող է համապատասխանել մի քանի տարբեր արտահայտումներին, մոդելը պետք է զբաղվի ավելի լայն կոնտեքստով: Ակտիվացման հարաբերությունը նշանի դուրս և ամբողջ ակտիվացման հիմքում է մեր չափումը: Մենք համեմատում ենք սա պարզ լեքսիկական չափով, էնտրոպիկ չափով, ինչպես նաև մի քանի այլ նյարդային մոդելների հետ, և փաստարկում ենք, որ ուշադրության վրա հիմնված չափով հավասարակշռության վրա լավագույնը համապատասխանում է\nմտածելով, թե ինչպես են տարբեր համակարգերը լոգոգրաֆիկ: Մեր աշխատանքը տրամադրում է լոգոգրաֆիայի գաղափարի առաջին չափը, որը համապատասխանում է լեզվաբանական ինտուիցիային և, մենք պնդում ենք, ավելի լավ ընկալում է, թե ինչ է նշանակում այս գաղափարը:', 'az': 'Gelb (1952) tərəfindən bu yana yazma sistemlərinin taksonları yazılmış sembollərin göstərilməsinə dayanan sırlaşdırılmış sistemlərdir: əgər onlar sözləri və morfomları göstərirlərsə, onlar logografikdirlər; sözlər, sözlər; seçmək, alfabetik; Və belə. Sproat (2000) və Rogers (2005), logografi və fonografi aspektlərini iki ölçüyə bölüşdürən, logografi kategorikalı fərqləndirməkdən əvvəl dəyişdirilmiş olaraq yayılmışdır. Sistem silabik və çox logografik olar. və çox logografi deyil. Bu, yazma sistemlərinin əslində işlədikləri kimi daha yaxşıdır, amma yazar da logografi ölçülərinin bir yolunu təbliğ etmədi. Bu mətnədə, bir möcüzə yazmağını təmin etmək üçün təhsil edilmiş, təhsil edilmiş bir möcüzə yazmağın dərəcəsinin yeni ölçüsünü təklif edirik. İddial fonografik sistemində modeli sadəcə ağımdaki token ilə birlikdə olmalıdır ki, bunu nasıl yazılacağını hesablamaq üçün, bu da matriks aktivasiyonlarında göstərilir. Əksinə, bir logografik sistemi ilə, verilən sözlər bir neçə-neçə fərqli sözlərə uyğun ola bilər, modeli daha geniş bir məlumatlara istifadə etmək lazımdır. İşaret dışında fəallaşdırma və tamamlama fəallaşdırma bizim ölçümüzə dayanır. Biz bunu basit bir leksik ölçüsü ilə, entropik ölçüsü ilə, başqa bir neçə nöral modelləri ilə qarşılaşdırırıq, və bu, dikkatimiz tabanlı ölçülərimizin ən yaxşı fikirləşdirir.\nlogografi müxtəlif sistemlərin necə olduğunu düşünürlər. Bizim işimiz ilk qiymətli ölçüyə malik olaraq, dillərin intuiyası ilə uyğunlaşan logografi fikrinin və, mübahisə edirik, bu fikrinin nə anlama gələcəyini daha yaxşı fikirləşdirir.', 'bn': 'গেলব (১৯৫২) থেকে লেখার সিস্টেমের ট্যাক্সোনিমিজরা লিখেছেন কি প্রতিনিধিত্ব করেছেন তা ভিত্তিক সিস্টেম: তারা যদি শব্দ বা মর্ফিমের যদি সিলাবিক, সিলাবিক যদি অংশ, আলফাবেটিক; এবং এভাবেই। স্প্রোয়াট (২০০০) এবং রজার্স (২০০৫) ঐতিহ্যবাহী ভেঙ্গে পড়েছে লোগোগ্রাফিক এবং ফোনোগ্রাফিক প্রাক্ষাপগুলো দুটি মাত্রায় ভেঙ্গে দেয়ার মাধ্যমে, য একটি সিস্টেম সিলাবিক এবং অত্যন্ত লোগোগ্রাফিক হতে পারে; অথবা আলফাবেটিক, আর বেশীরভাগ লোগোগ্রাফিক। কিন্তু লেখকেও লোগোগ্রাফি মাপের জন্য কোন উপায় প্রস্তাব করেন না। এই প্রবন্ধটিতে আমরা লোগোগ্রাফির ডিগ্রি পরিমাপ প্রস্তাব করি যা মনোযোগের ভিত্তিক সেকেন্স-থেকে সেকেন্সেকেন্স মোডেল ব্যবহার করে প্রশিক্ষণ করা হয়েছে য কিভাবে বানানোর জন্য মডেলের কেবল বর্তমান চিহ্নের সাথে যোগ দিতে হবে এবং এটি মনোযোগ ম্যাট্রিক্স সক্রিয় কার্যকলাপে দেখা যাবে। বিপরীতে, একটি লোগোগ্রাফিক সিস্টেমের সাথে যেখানে একটি প্রকাশিত বিভিন্ন ভাষার সাথে সমান হতে পারে, মডেলটি ব্যাপক প্রসঙ্গে অংশ নিতে হব The ratio of the activation outside the token and the total activation forms the basis of our measure.  আমরা এটাকে সাধারণ লেক্সিক্সিক মাপের সাথে তুলনা করি এবং একটি এন্ট্রোপিক মাপের সাথে এবং অন্যান্য নিউরেল মডেলের সাথে তুলনা করি, আর যুক্তি\nযেখানে লোগোগ্রাফিক বিভিন্ন সিস্টেম কিভাবে আছে তা নিয়ে বুঝতে পারে। আমাদের কাজ লোগোগ্রাফির ধারণার প্রথম পরিমাপ প্রদান করে যা ভাষার ভাষার অনুভূতির সাথে সমর্থন করে এবং আমরা যুক্তি দিচ্ছি যে এই ধারণার মানে ক', 'bs': 'Taksonomije pisaćeg sustava od Gelba (1952) imaju klasifikovane sisteme na temelju onoga što napisani simboli predstavljaju: ako predstavljaju riječi ili morfije, logografični su; ako su silabe, silabe; ako segmenti, alfabetički; I tako dalje. Sproat (2000) i Rogers (2005) prekinuli su tradiciju razdvajanjem logografskih i fonografskih aspekta u dvije dimenzije, s ocjenom logografije umjesto kategorijske razlike. Sistem bi mogao biti silabetski i jako logografski; ili alfabetično, i uglavnom ne-logografično. To se bolje dogovara kako napisani sistemi zapravo rade, ali ni autor nije predložio metodu za mjerenje logografije. U ovom članku predlažemo novu mjeru stupnja logografije koja koristi model koji se osnova pažnje na sekvenciji obučen za predviđanje napisa znaka iz njegovog proglašavanja u kontekstu. U idealnom fonografskom sistemu, model bi trebao prisustvovati samo trenutnom znaku kako bi računalo kako ga pisati, a to bi pokazalo u aktivaciji pažnje matrice. Za suprotno, sa logografskim sistemom, gdje bi dati proglašenje moglo odgovarati nekoliko različitih pisanja, model bi trebao prisustvovati širem kontekstu. Razmjer aktivacije izvan znaka i ukupne aktivacije formira temelj naše mjere. To uspoređujemo jednostavnom leksičkom mjerom i entropičnom mjerom, kao i nekoliko drugih neuronskih modela, i tvrdimo da na ravnoteži naše mjere na temelju pažnje najbolje odgovara\nsa intuicijom o tome kako su logografski različiti sistemi. Naš rad pruža prvu kvantificirajuću mjeru pojma logografije koja odgovara jezičkoj intuiciji i, tvrdimo, pruža bolji uvid u ono što ova pojma znači.', 'ca': "Les taxonomies dels sistemes d'escriptura des de Gelb (1952) tenen sistemes classificats basats en el que representan els símbols escrits: si representen paraules o morfes, són logogràfics; si sílabes, sílabes; si segments, alfabètics; i així endavant. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction.  Un sistema podria ser sílabic i molt logogràfic; o alfabètic, i sobretot no logogràfic. Això està millor d'acord amb com funcionan els sistemes d'escriptura, però cap autor no va proposar un mètode de mesura de la logografia. En aquest article proposem una nova mesura del grau de logografia que utilitza un model de seqüència a seqüència basat en l'atenció entrenat per predir l'ortografia d'una fitxa de la seva pronunciació en context. En un sistema fonogràfic ideal, el model només hauria d'atendre a la fitxa actual per calcular com ortografar-la, i això mostraria en l'activació de la matriu d'atenció. En canvi, amb un sistema logogràfic, on una determinada pronunciació podria correspondir a diverses ortografies diferents, el model hauria d'atendre a un context més ampli. La proporció de l'activació fora de la fitxa i l'activació total formen la base de la nostra mesura. We compare this with a simple lexical measure, and an entropic measure, as well as several other neural models, and argue that on balance our attention-based measure accords best\nwith intuition about how logographic various systems are.  La nostra feina proporciona la primera mesura quantificable de la noció de logografia que s'ajusta a la intuïció lingüística i, argumentem, proporciona una millor comprensió del que significa aquesta noció.", 'cs': 'Taxonomie psacích systémů od Gelb (1952) mají klasifikované systémy založené na tom, co písemné symboly představují: pokud představují slova nebo morfémy, jsou logografické; pokud slabiky, slabiky; pokud segmenty, abecedně; a tak dále. Sproat (2000) a Rogers (2005) porušili tradici tím, že rozdělili logografické a fonografické aspekty do dvou dimenzí, přičemž logografie byla spíše stupňována než kategorické rozlišení. Systém by mohl být slabikový a vysoce logografický; nebo abecedně a většinou nelogograficky. To lépe odpovídá tomu, jak vlastně fungují psací systémy, ale ani jeden z autorů nenavrhl metodu měření logografie. V tomto článku navrhujeme nové měřítko stupně logografie, které využívá pozornostní model sekvence-sekvence vycvičený k předpovědi pravopisu tokenu z jeho výslovnosti v kontextu. V ideálním fonografickém systému by se model měl věnovat pouze aktuálnímu tokenu, aby mohl vypočítat, jak ho hláskovat, což by se ukázalo v aktivacích matice pozornosti. Naproti tomu u logografického systému, kde daná výslovnost může odpovídat několika různým pravopisům, by se model musel věnovat širšímu kontextu. Poměr aktivace mimo token a celkové aktivace tvoří základ našeho opatření. Porovnáváme to s jednoduchým lexikálním měřítkem a entropickým měřítkem, stejně jako s několika dalšími neuronovými modely, a argumentujeme, že v rovnováze naše pozornost založená měřítka nejlépe odpovídá míře\ns intuicí o tom, jak logografické jsou různé systémy. Naše práce poskytuje první kvantifikovatelné měřítko pojmu logografie, které odpovídá lingvistické intuici a podle nás poskytuje lepší pohled na to, co tento pojem znamená.', 'et': 'Kirjutamissüsteemide taksonoomiad alates Gelbist (1952) on klassifitseerinud süsteeme, mis põhinevad kirjalikel sümbolitel: kui need esindavad sõnu või morfeeme, on need logograafilised; kui silbid, silbid; kui segmendid, tähestikuliselt; ja nii edasi. Sproat (2000) ja Rogers (2005) lõhkusid traditsioonist, jagades logograafilised ja fonograafilised aspektid kaheks dimensiooniks, kusjuures logograafiat liigitati pigem kui kategoorialist eristamist. Süsteem võib olla silbiline ja väga logograafiline; või tähestikuliselt ja enamasti mittelogograafiliselt. See sobib paremini sellega, kuidas kirjutamissüsteemid tegelikult töötavad, kuid kumbki autor ei pakkunud välja logigraafia mõõtmise meetodit. Käesolevas artiklis pakume välja uudse logograafia taseme mõõtmise, mis kasutab tähelepanupõhist jadast järjestusse mudelit, mis on koolitatud ennustama märgi õigekirja selle häälduse kontekstis. Ideaalses fonograafilises süsteemis peaks mudel tähelepanu pöörama ainult praegusele märgile, et arvutada, kuidas seda kirjutada, ja see näitaks tähelepanu maatriksi aktiveerimisel. Seevastu logograafilise süsteemi puhul, kus antud hääldus võib vastada mitmele erinevale õigekirjale, peaks mudel vastama laiemale kontekstile. Meie mõõtme aluseks on väljaspool tokeni aktiveerimise ja kogu aktiveerimise suhe. Me võrdleme seda lihtsa leksikaalse ja entroopse mõõtmega, samuti mitmete teiste närvimudelitega ning väidame, et tasakaalus on meie tähelepanupõhine mõõtmine kõige parem\nintuitsiooniga, kuidas logograafilised erinevad süsteemid on. Meie töö annab esimese mõõdetava mõõtme logograafia, mis on kooskõlas keelelise intuitsiooniga ja, me väidame, annab parema ülevaate, mida see mõiste tähendab.', 'fi': 'Kirjoitusjärjestelmien taksonomiat Gelbin (1952) jälkeen ovat luokitelleet järjestelmiä sen perusteella, mitä kirjoitetut symbolit edustavat: jos ne edustavat sanoja tai morfeemeja, ne ovat logografisia; jos tavut, tavut; jos segmentit, aakkosjärjestyksessä; Ja niin edelleen. Sproat (2000) ja Rogers (2005) rikkoivat perinteen jakamalla logografiset ja fonografiset näkökohdat kahteen ulottuvuuteen, jossa logografia luokiteltiin pikemminkin kuin kategorinen ero. Järjestelmä voi olla tavumainen ja erittäin logografinen. tai aakkosellisesti, ja enimmäkseen ei-logografisesti. Tämä sopii paremmin kirjoitusjärjestelmien toimintaan, mutta kumpikaan kirjoittaja ei ehdottanut logografian mittausmenetelmää. Tässä artikkelissa ehdotamme uudenlaista logografian asteiden mittausta, joka käyttää huomiota perustuvaa sekvenssimallia, joka on koulutettu ennustamaan merkin oikeinkirjoitusta sen ääntämisestä kontekstissa. Ihanteellisessa fonografisessa järjestelmässä mallin tulisi kiinnittää huomiota vain nykyiseen merkkiin, jotta se voidaan laskea, miten se kirjoitetaan, ja tämä näkyisi huomiomatriisin aktivoitumissa. Sen sijaan logografisessa järjestelmässä, jossa tietty ääntäminen voi vastata useita eri kirjoitusmuotoja, mallin olisi otettava huomioon laajempi konteksti. Mittauksemme perustana on tokenin ulkopuolisen aktivoinnin ja kokonaisaktivoinnin suhde. Vertaamme tätä yksinkertaiseen sanastoon ja entrooppiseen mittaan sekä useisiin muihin neuromalleihin ja väitämme, että tasapainossa huomiopohjainen mittamme sopii parhaiten yhteen.\nintuitiolla siitä, miten logografiset eri järjestelmät ovat. Työmme tarjoaa ensimmäisen määrällisen mittakaavan logografian käsitteestä, joka on sopusoinnussa kielellisen intuition kanssa, ja väitämme, antaa paremman käsityksen siitä, mitä tämä käsite tarkoittaa.', 'sk': 'Taksonomije pisalnih sistemov že od Gelba (1952) razvrščajo sisteme, ki temeljijo na tem, kaj predstavljajo pisani simboli: če predstavljajo besede ali morfeme, so logografski; če so zlogi, zlogi; če so segmenti, abecedno; in tako naprej. Sproat (2000) in Rogers (2005) sta prekinila tradicijo z razdelitvijo logografskih in fonografskih vidikov na dve dimenziji, pri čemer je logografija bolj razvrščena kot kategorično razlikovanje. Sistem je lahko zlobni in zelo logografski; ali abecedno in večinoma nelogografsko. To se bolje ujema s tem, kako sistemi pisanja dejansko delujejo, vendar noben avtor ni predlagal metode merjenja logografije. V tem članku predlagamo novo merilo stopnje logografije, ki uporablja model, ki temelji na pozornosti, ki je usposobljen za napovedovanje črkovanja žetona iz njegove izgovorjave v kontekstu. V idealnem fonografskem sistemu bi moral model upoštevati samo trenutni žeton, da bi izračunal, kako ga črkovati, kar bi se pokazalo v aktivacijah matrice pozornosti. V nasprotju z logografskim sistemom, kjer bi določena izgovorjava lahko ustrezala več različnim črkovanjem, bi moral model upoštevati širši kontekst. Razmerje med aktivacijo zunaj žetona in skupno aktivacijo je osnova našega merila. Primerjamo to s preprostim leksikalnim merilom in entropskim merilom ter z več drugimi nevronskimi modeli in trdimo, da je naša merila, ki temelji na pozornosti, najboljša.\nz intuicijo o tem, kako so logografski različni sistemi. Naše delo zagotavlja prvo merljivo merilo pojma logografije, ki je v skladu z jezikovno intuicijo in zagotavlja boljši vpogled v to, kaj ta pojem pomeni.', 'he': "Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent: if they represent words or morphemes, they are logographic;  אם מילים, מילים; אם חלקים, אלפביטיים; וכן הלאה. Sproat (2000) ו רוג'רס (2005) שברו עם מסורת על ידי החלק היבטים הלוגוגרפיים ופונוגרפיים לשני מימדים, עם לוגוגרפיה מוצבת במקום הבדיקה קטגורית. מערכת יכולה להיות סילבית, ולוגרפית מאוד; או אלפביטית, וברוב לא לוגוגרפית. זה מתאים יותר לאיך מערכות כתיבה למעשה עובדות, אבל אף אחד מהסופרים לא הציע שיטה למדוד לוגוגרפיה. במאמר הזה אנו מציעים מדידה חדשה של התואר של לוגוגרפיה שמשתמשת במודל מבוסס על תשומת לב רצף לרצף מאומן לחזות את האיתוף של סימן מהביטוי שלו בקשר. במערכת פונוגרפית אידיאלית, המודל צריך להשתתף רק בסימן הנוכחי כדי לחשב איך לאיית אותו, וזה יראה בפעילות המטריקס של תשומת לב. בניגוד לזה, עם מערכת לוגוגרפית, שבה ביטוי מסוים יכול להתאים לכמה איפוסים שונים, המודל צריך להשתתף בקשר רחב יותר. יחס ההפעלה מחוץ לסימן והפעלה הכוללת יוצר את בסיס המידד שלנו. אנחנו משוותים את זה עם מדידת לקסיקה פשוטה, ומדידת אנטרופית, כמו גם כמה דוגמנים נוירואלים אחרים, ותווכחים שבמשקל המדידה המבוססת על תשומת לב שלנו מתאימה הכי טוב\nעם אינטואיציה על איך מערכות שונות לוגוגרפיות. העבודה שלנו מספקת את המידד הראשון המקביל של הרעיון של לוגוגרפיה שמתאים לאינטואיציה לשונית, ואנחנו מתווכחים, מספקת תובנה טובה יותר למה הרעיון הזה אומר.", 'ha': "Taksonomies of writing system since Gelb (1952) have classified system based on what the typical symbol is wakin: if they are wakin words or morfemes, then they are logoggraphic; Idan zakata da aka cika; Idan rabo, alfabeteki; Dakata. @ info: whatsthis An iya iya kasa zama mai salo, da matsayi mai girma; ko alfabeteki, kuma mafi yawansu bã logografi ba. Wannan yana yarda da mafi kyautar da jinsi tsarin rubutu suke aiki, kuma amma ma'abũcin marubuci ba ya buƙata wani metode wa haƙunsa logografi. A cikin wannan makala, Munã buɗa wani matsayi na tsari ga daraja na logografi da ke amfani da wani misali mai bincike-zuwa-sequence wanda aka yi wa lũra wa fassarar wata ãya daga bayani da ke bayyana shi. Idan wani na'urar fonografi na zato, an kamata shi ya zama mai haɗi zuwa alama na yanzu kawai, dõmin ya yi ƙidãya yadda za'a lissafa shi, kuma wannan yana nuna cikin alama masu kiyãta. In da tsakanin, da wani tsari na logografi, inda kunyar da aka yi nuna, za'a iya daidai da wasu misalin dabam-daban, ya kamata misalin ya sami zuwa wani mazaɓa mai shimfiɗa. Tsarawa na aikin bayan alama da cikakken aikin yana danne a kan haske. Munã samfani wannan da ke da ma'aunin littãfi mai sauƙi, da ma'aunin littafi da wasu misãlai na neura, kuma Munã yi jayayya da cẽwa, a kan daidaita ma'auni masu bincike, yana da mafi kyaun\nsuna da kashi a kan jinsi na'urar logografi ko. Kaimakanmu yana samar da ma'aunin na farko ma'auni na logografi wanda yana yarda da hisia'a na harshen, kuma, Munã yi jayayya, yana ƙarami da kashi mafi alhẽri ga ma'anar wannan zato.", 'jv': 'Language marking textattr lan aku mulai Language Sistem iso dianggo kelalabiya karo log-togografi; akeh Gak Aljebetar, karo akeh tenan-log saiki. Iki barêng-barêng langkung apik sing nêmên patingé karo sistem sing paling nêmên, ngusaté autor siwehe nggawe sistem kanggo nggawe log ografi. Nang artikl iki, kita unduh kuwi nyumbang kelompok nggawe digaturan log ografi sing isin gambar nggawe sekonduran-to-sekondirne sing nyimpen kanggo ngerayakno gerusahaan token kanggo ngerayakno Jejaring politenessoffpolite"), and when there is a change ("assertivepoliteness Relative Awak dhéwé nggilalahan iki ngono sistem sing sampeyan luwih, lan input, sampeyan karo model sing itérung, lan uwong nggawe barang sampeyan tambah kuwat titimbang awak dhéwé\ngagal Awak dhéwé nggawe mbéwé éntuk kuwi kesempatan kanggo ngerasakno karo nggawe gerakan ning tarjamahan ingkang. Awak dhéwé, awak dhéwé, gawe ngerasakno luwih apik sing apik dhéwé.', 'bo': 'Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent: if they represent words or morphemes, they are logographic;  གལ་སྲིད་འདི་ལྕགས་རིམ་དང་། གལ་སྲིད་དེ་རྣམ་གྲངས་ཡིན་ཚེ། དུས་མེད། Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with logography being graded rather than a categorical distinction. མ་ལག་ཅིག་དེ་སྒྲ་ཚིགས་རམ་དང་ཐིག་རིང་གི་འགྱུར་བ་ཞིག་ཡིན་པ་རེད། ཡིག་འབྲུ་བ་ཡིན་མིན་དེ་ལས་དུས་རབས་ཀྱི་མིན་དེ་རེད། འདིས་འབྲི་ནུས་མ་ལག་གིས་དངོས་ཡིག In this article we propose a novel measure of the degree of logography that uses an attention-based sequence-to-sequence model trained to predict the spelling of a token from its pronunciation in context. ideal phonographic system་ནང་དུ་མ་དཔེ་དབྱིབས་ད་ལྟོའི་ཁྱད་ཆོས དེ་ལྟ་བུའི་རིམ་པ་ཞིག་དང་མཉམ་དུ་དམིགས་ཡུལ་གྱི་ཡིག་གཟུགས་རིས ལྟག་ཕྱི་ཁར་གྱི་བྱ་སྤྱོད་ཀྱི་ཆེ་རྐྱེན་ཚད་དང་བསྡུས་བཟོ་རུང་འདིས་ང་ཚོའི་ཚད་གཞི་རྩི་གཞི་བཟོས་ཡོད། We compare this with a simple lexical measure, and an entropic measure, as well as several other neural models. And argue that on balance our attention-based measure accords best\nདྲ་རིས་ལག་མ་འདྲ་བའི་སྐོར་གྱི་ཐད་ནས་ཐད་ཚོར་བ་རེད། ང་ཚོའི་ལས་འགན་གྱི་དྲན་རིམ་གྱི་སྐོར་དང་པོ་སྣང་ཚུལ་གྲངས་རིམ་དང་མཉམ་དུ་མཐུན་གྱི་རྣམ་པ་དང་མཐུན་ཚད་ལྡན་གྱི་ཐབས་ཤེས་དང་ང་ཚོས'}
{'en': 'Decoding Word Embeddings with Brain-Based Semantic Features', 'ar': 'فك ترميز كلمة التعارف مع الميزات الدلالية المستندة إلى الدماغ', 'es': 'Decodificación de incrustaciones de palabras con funciones semánticas basadas en cerebro', 'fr': 'Décodage des intégrations de mots avec des fonctionnalités sémantiques basées sur le cerveau', 'pt': 'Decodificando Word Embeddings com Recursos Semânticos Baseados no Cérebro', 'ja': '脳ベースのセマンティック機能を使用した単語埋め込みのデコード', 'zh': '用大脑者语义特徵解码词嵌', 'hi': 'मस्तिष्क-आधारित शब्दार्थ सुविधाओं के साथ शब्द एम्बेडिंग डिकोडिंग', 'ru': 'Декодирование вложений слов с помощью семантических функций на основе мозга', 'ga': 'Leabú Focal a Dhíchódú le Gnéithe Séimeantacha Brain-Bhunaithe', 'ka': 'Name', 'el': 'Αποκωδικοποίηση Ενσωματώσεων λέξεων με σημαντικά χαρακτηριστικά βασισμένα στον εγκέφαλο', 'hu': 'Szóbeágyazások dekódolása agyalapú szemantikus funkciókkal', 'it': 'Decodifica incorporazioni di parole con funzionalità semantiche basate sul cervello', 'mk': 'Name', 'kk': 'Меңзен негіздеген семантикалық мүмкіндіктерімен сөз ендіру', 'lt': 'Name', 'mt': 'L-inkorporazzjonijiet tal-kliem li jiddikodifikaw b’Karatteristiċi Semantiċi bbażati fuq il-Moħħ', 'ms': 'Decoding Word Embeddings with Brain-Based Semantic Features', 'mn': 'Тархины суурь Semantic Features', 'ml': 'ബ്രെയിന്\u200d അടിസ്ഥാനമായ സെമാന്റിക് വിശേഷതകളുമായി വാക്ക് എംബെഡിങ്ങുകള്\u200d കോഡിങ് ചെയ്യുന്ന', 'no': 'Dekodering av ord med semiantiske funksjonar med hjernebasert', 'pl': 'Dekodowanie osadzeń słowa z funkcjami semantycznymi opartymi na mózgu', 'sr': 'Dekodiranje reèi sa semantičnim karakterima na mozgu', 'ro': 'Decodarea încorporărilor de cuvinte cu caracteristici semantice bazate pe creier', 'si': 'Name', 'sv': 'Avkoda ordinbäddningar med hjärnbaserade semantiska funktioner', 'so': 'Xafiisyada codsiga ee qoraalka ku jira', 'ur': 'Name', 'ta': 'Name', 'uz': 'Name', 'vi': 'Thiết lập chữ cáiName', 'bg': 'Декодиране на словни вграждания с мозъчно базирани семантични функции', 'da': 'Afkodning af ordindlejringer med hjernebaserede semantiske funktioner', 'nl': 'Het decoderen van woordinsluitingen met hersengebaseerde semantische functies', 'hr': 'Dekodiranje riječi sa semantičnim funkcijama na mozgu', 'de': 'Dekodierung von Wort-Einbettungen mit hirnbasierten semantischen Funktionen', 'ko': '대뇌의 의미 특징을 바탕으로 한 단어 삽입 디코딩', 'fa': 'Name', 'id': 'Mendekodifikasi Penciptaan Kata dengan Karakteristik Semantik Berdasarkan Otak', 'tr': 'Beýnin Etkilendirilen Semantik özellikleri bilen Ködleme', 'sw': 'Imekodiwa kwa neno linalohusu Tamko za Kisemantiki', 'af': 'Name', 'sq': 'Duke dekodifikuar përfshirjet e fjalëve me funksione Semantike të bazuara në tru', 'hy': 'Comment', 'az': 'Beynin 칖st칲nd톛ki Semantik 칐zellikl톛ri il톛 Dekodlay캼r', 'bn': 'Name', 'am': 'አዲስ ዶሴ ፍጠር', 'cs': 'Dekodování vložení slov se sémantickými funkcemi založenými na mozku', 'et': 'Sõnade dekodeerimine ajupõhiste semantiliste funktsioonidega', 'fi': 'Sanaupotusten dekoodaaminen aivopohjaisilla semanttisilla ominaisuuksilla', 'bs': 'Dekodiranje reči sa semantičnim karakterima na mozgu', 'ca': 'Incorporacions de paraules decodificadores amb característiques Semàtiques basades en el cervell', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'מפענח פיצוי מילים עם תכונות סמנטיות מבוססות על מוח', 'sk': 'Dekodiranje besednih vdelav s semantičnimi funkcijami na podlagi možganov', 'ha': 'KCharselect unicode block name', 'bo': 'ལྟ་བུའི་རྩིས་གཞི་བརྟེན་པའི་ཆ་མཚུངས་རྟགས་ཀྱི་ཡིག་ཚན་མཚོན་འགྲོ་བ་ཀྱི་ཡིག་གཟུགས་རྟགས་'}
{'en': 'Word embeddings are vectorial semantic representations built with either counting or predicting techniques aimed at capturing shades of meaning from word co-occurrences. Since their introduction, these representations have been criticized for lacking interpretable dimensions. This property of word embeddings limits our understanding of the semantic features they actually encode. Moreover, it contributes to the black box nature of the tasks in which they are used, since the reasons for word embedding performance often remain opaque to humans. In this contribution, we explore the semantic properties encoded in word embeddings by mapping them onto interpretable vectors, consisting of explicit and neurobiologically motivated semantic features (Binder et al. Our exploration takes into account different types of embeddings, including factorized count vectors and predict models (Skip-Gram, GloVe, etc.), as well as the most recent contextualized representations (i.e., ELMo and BERT). In our analysis, we first evaluate the quality of the mapping in a retrieval task, then we shed light on the semantic features that are better encoded in each embedding type. A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories. For each probing task, we identify the most relevant semantic features and we show that there is a correlation between the embedding performance and how they encode those features. This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.', 'ar': 'تضمين الكلمات عبارة عن تمثيلات دلالية متجهة مبنية إما باستخدام تقنيات العد أو التنبؤ التي تهدف إلى التقاط ظلال المعنى من التكرارات المشتركة للكلمات. منذ تقديمها ، تم انتقاد هذه التمثيلات لافتقارها إلى أبعاد قابلة للتفسير. تحد خاصية تضمين الكلمة هذه من فهمنا للسمات الدلالية التي يشفرونها بالفعل. علاوة على ذلك ، فإنه يساهم في طبيعة "الصندوق الأسود" للمهام التي يتم استخدامها فيها ، نظرًا لأن أسباب أداء تضمين الكلمات غالبًا ما تظل غامضة بالنسبة للبشر. في هذه المساهمة ، نستكشف الخصائص الدلالية المشفرة في تضمين الكلمة عن طريق تعيينها على نواقل قابلة للتفسير ، تتكون من سمات دلالية صريحة وذات دوافع بيولوجية عصبية (Binder et al. 2016). يأخذ استكشافنا في الاعتبار أنواعًا مختلفة من عمليات الزفاف ، بما في ذلك متجهات التعداد المحسوب ونماذج التنبؤ (Skip-Gram و GloVe وما إلى ذلك) ، بالإضافة إلى أحدث التمثيلات السياقية (مثل ELMo و BERT). في تحليلنا ، نقوم أولاً بتقييم جودة التعيين في مهمة استرجاع ، ثم نلقي الضوء على الميزات الدلالية التي يتم تشفيرها بشكل أفضل في كل نوع من أنواع التضمين. تم أخيرًا تعيين عدد كبير من مهام الفحص لتقييم كيفية أداء الزخارف الأصلية والمعينة في الفئات الدلالية التمييزية. لكل مهمة استقصاء ، نحدد الميزات الدلالية الأكثر صلة ونبين أن هناك ارتباطًا بين أداء التضمين وكيفية تشفيرها\nالميزات. تضع هذه الدراسة نفسها كخطوة للأمام في فهم جوانب المعنى التي تلتقطها مساحات المتجهات ، من خلال اقتراح طريقة جديدة وبسيطة لنحت التمثيلات الدلالية التي يمكن تفسيرها من قبل الإنسان من نواقل التوزيع.', 'fr': "Les intégrations de mots sont des représentations sémantiques vectorielles créées à l'aide de techniques de comptage ou de prédiction visant à saisir les nuances de sens des cooccurrences de mots. Depuis leur introduction, ces représentations ont été critiquées pour leur manque de dimensions interprétables. Cette propriété des intégrations de mots limite notre compréhension des caractéristiques sémantiques qu'ils encodent réellement. De plus, cela contribue à la nature «\xa0boîte noire\xa0» des tâches dans lesquelles ils sont utilisés, car les raisons de la performance de l'intégration de mots restent souvent obscures pour les humains. Dans cette contribution, nous explorons les propriétés sémantiques codées dans les intégrations de mots en les cartographiant sur des vecteurs interprétables, constitués de caractéristiques sémantiques explicites et motivées par la neurobiologie (Binder et al. 2016). Notre exploration prend en compte différents types d'intégrations, y compris les vecteurs de dénombrement factorisés et les modèles de prévision (Skip-Gram, Glove, etc.), ainsi que les représentations contextualisées les plus récentes (ElMo et BERT). Dans notre analyse, nous évaluons d'abord la qualité du mappage dans une tâche de récupération, puis nous mettons en lumière les caractéristiques sémantiques qui sont mieux codées dans chaque type d'intégration. Un grand nombre de tâches de sondage sont finalement définies pour évaluer comment les intégrations d'origine et mappées se comportent dans des catégories sémantiques discriminantes. Pour chaque tâche de sondage, nous identifions les caractéristiques sémantiques les plus pertinentes et nous montrons qu'il existe une corrélation entre les performances d'intégration et la façon dont elles les encodent\nfonctionnalités. Cette étude constitue un pas en avant dans la compréhension des aspects de la signification capturés par les espaces vectoriels, en proposant une nouvelle méthode simple pour découper des représentations sémantiques interprétables par l'homme à partir de vecteurs de distribution.", 'pt': 'Embeddings de palavras são representações semânticas vetoriais construídas com técnicas de contagem ou previsão destinadas a capturar tons de significado de co-ocorrências de palavras. Desde a sua introdução, essas representações têm sido criticadas por não terem dimensões interpretáveis. Essa propriedade de incorporação de palavras limita nossa compreensão das características semânticas que elas realmente codificam. Além disso, contribui para a natureza de “caixa preta” das tarefas em que são usadas, uma vez que as razões para o desempenho da incorporação de palavras muitas vezes permanecem opacas para os seres humanos. Nesta contribuição, exploramos as propriedades semânticas codificadas em embeddings de palavras mapeando-as em vetores interpretáveis, consistindo em características semânticas explícitas e neurobiologicamente motivadas (Binder et al. 2016). Nossa exploração leva em consideração diferentes tipos de embeddings, incluindo vetores de contagem fatorados e modelos de previsão (Skip-Gram, GloVe, etc.), bem como as representações contextualizadas mais recentes (ou seja, ELMo e BERT). Em nossa análise, primeiro avaliamos a qualidade do mapeamento em uma tarefa de recuperação, depois esclarecemos os recursos semânticos que são melhor codificados em cada tipo de incorporação. Um grande número de tarefas de sondagem é finalmente definido para avaliar como os embeddings originais e mapeados se comportam em categorias semânticas discriminantes. Para cada tarefa de sondagem, identificamos as características semânticas mais relevantes e mostramos que existe uma correlação entre o desempenho da incorporação e como eles codificam essas características.\nrecursos. Este estudo se coloca como um passo à frente na compreensão de quais aspectos de significado são capturados por espaços vetoriais, ao propor um método novo e simples para esculpir representações semânticas interpretáveis por humanos a partir de vetores distributivos.', 'ja': '単語埋め込みは、単語の共起から意味の色合いを取り込むことを目的としたカウントまたは予測技術のいずれかで構築されたベクトル意味表現です。 導入以来、これらの表現は解釈可能な次元を欠いていると批判されてきた。 このワード埋め込みのプロパティは、実際にエンコードするセマンティック機能の理解を制限します。 さらに、単語埋め込みパフォーマンスの理由は人間にとって不透明なままであることが多いため、それらが使用されるタスクの「ブラックボックス」の性質に寄与します。 この寄稿では、明示的かつ神経生物学的に動機付けられた意味的特徴からなる解釈可能なベクトルにそれらをマッピングすることによって、単語埋め込みにエンコードされる意味的特性を探求する（ Binder et al. 2016 ）。 当社の調査では、因数分解されたカウントベクトルと予測モデル（ Skip - Gram、GloVeなど）、および最新のコンテキスト化された表現（ ELMoとBERTなど）を含む、さまざまなタイプの埋め込みを考慮しています。 分析では、まず検索タスクのマッピングの品質を評価し、次に各埋め込みタイプでより良くエンコードされるセマンティック機能を明らかにします。 多数のプロービングタスクが最終的に設定され、元の埋め込みとマッピングされた埋め込みが区別されるセマンティックカテゴリでどのように実行されるかを評価します。 各プロービングタスクについて、最も関連性の高いセマンティック機能を特定し、埋め込みパフォーマンスとそれらをエンコードする方法との間に相関関係があることを示します。\n特徴。この研究は、分布ベクトルから人間が解釈可能な意味表現を刻む新しい単純な方法を提案することによって、意味のどの側面がベクトル空間によって取り込まれるかを理解するための一歩として位置づけている。', 'es': 'Las incrustaciones de palabras son representaciones semánticas vectoriales construidas con técnicas de conteo o predicción destinadas a capturar matices de significado de la ocurrencia conjunta de palabras. Desde su introducción, estas representaciones han sido criticadas por carecer de dimensiones interpretables. Esta propiedad de la incrustación de palabras limita nuestra comprensión de las características semánticas que realmente codifican. Además, contribuye a la naturaleza de «caja negra» de las tareas en las que se utilizan, ya que las razones del rendimiento de incrustación de palabras a menudo siguen siendo opacas para los humanos. En esta contribución, exploramos las propiedades semánticas codificadas en las incrustaciones de palabras mapeándolas en vectores interpretables, que consisten en características semánticas explícitas y motivadas neurobiológicamente (Binder et al., 2016). Nuestra exploración tiene en cuenta diferentes tipos de incrustaciones, incluidos los vectores de recuento factorizados y los modelos de predicción (Skip-Gram, GloE, etc.), así como las representaciones contextualizadas más recientes (es decir, eLMO y BERT). En nuestro análisis, primero evaluamos la calidad del mapeo en una tarea de recuperación, luego arrojamos luz sobre las características semánticas que están mejor codificadas en cada tipo de incrustación. Finalmente se establece un gran número de tareas de sondeo para evaluar cómo funcionan las incrustaciones originales y mapeadas en categorías semánticas discriminatorias. Para cada tarea de sondeo, identificamos las características semánticas más relevantes y mostramos que hay una correlación entre el rendimiento de incrustación y la forma en que las codifican.\ncaracterísticas. Este estudio se establece como un paso adelante en la comprensión de qué aspectos del significado son capturados por los espacios vectoriales, al proponer un método nuevo y simple para tallar representaciones semánticas interpretables por humanos a partir de vectores distribucionales.', 'zh': '词嵌者,用数测术之矢量语义,指于单词共现中获其阴景也。 自引入以来,以阙解维度见讥。 词销此性限,实编码语义特征。 此外有助于用其任者,黑匣子其所以然者也。 此篇之中,嵌映可解者向量探其编码语义属性,向量以显式神经生物学动机之语义为(Binder et al. 2016)。 寻思异类嵌入,因式解数向量与占(Skip-Gram,GloVe等),及最新上下文化(即ELMoBERT)也。 先料其质,次明其编码语义。 终置探测以质本末,与映嵌语义类。 凡探事,定至语义,明其性与编码有相关性也。\n特征。 此论新简之法,雕镂向量人之语义,以定位为解向量空获何义而前。', 'hi': 'शब्द एम्बेडिंग वेक्टरीय शब्दार्थ प्रतिनिधित्व हैं जो या तो गिनती या भविष्यवाणी करने वाली तकनीकों के साथ निर्मित होते हैं, जिसका उद्देश्य शब्द सह-घटनाओं से अर्थ के रंगों को कैप्चर करना है। उनके परिचय के बाद से, इन अभ्यावेदनों की व्याख्या योग्य आयामों की कमी के लिए आलोचना की गई है। शब्द एम्बेडिंग की यह संपत्ति उन शब्दार्थ विशेषताओं की हमारी समझ को सीमित करती है जिन्हें वे वास्तव में एन्कोड करते हैं। इसके अलावा, यह उन कार्यों की "ब्लैक बॉक्स" प्रकृति में योगदान देता है जिसमें उनका उपयोग किया जाता है, क्योंकि शब्द एम्बेडिंग प्रदर्शन के कारण अक्सर मनुष्यों के लिए अपारदर्शी रहते हैं। इस योगदान में, हम शब्द एम्बेडिंग में एन्कोडेड शब्दार्थ गुणों का पता लगाते हैं, उन्हें व्याख्यायोग्य वैक्टर पर मैप करके, जिसमें स्पष्ट और न्यूरोबायोलॉजिकल रूप से प्रेरित शब्दार्थ विशेषताएं शामिल हैं (बाइंडर एट अल। हमारी खोज विभिन्न प्रकार के एम्बेडिंग को ध्यान में रखती है, जिसमें फैक्टराइज्ड काउंट वैक्टर और भविष्यवाणी मॉडल (स्किप-ग्राम, ग्लोवे, आदि) के साथ-साथ सबसे हाल ही में प्रासंगिक प्रतिनिधित्व (यानी, ELMo और BERT) शामिल हैं। हमारे विश्लेषण में, हम पहले एक पुनर्प्राप्ति कार्य में मानचित्रण की गुणवत्ता का मूल्यांकन करते हैं, फिर हम उन शब्दार्थ विशेषताओं पर प्रकाश डालते हैं जो प्रत्येक एम्बेडिंग प्रकार में बेहतर एन्कोडेड होते हैं। बड़ी संख्या में जांच कार्यों को अंततः यह आकलन करने के लिए सेट किया गया है कि मूल और मैप किए गए एम्बेडिंग शब्दार्थ श्रेणियों में भेदभावपूर्ण प्रदर्शन कैसे करते हैं। प्रत्येक जांच कार्य के लिए, हम सबसे प्रासंगिक शब्दार्थ विशेषताओं की पहचान करते हैं और हम दिखाते हैं कि एम्बेडिंग प्रदर्शन के बीच एक सहसंबंध है और वे उन लोगों को कैसे एन्कोड करते हैं\nसुविधाऐं। यह अध्ययन खुद को यह समझने में एक कदम के रूप में सेट करता है कि अर्थ के किन पहलुओं को वेक्टर रिक्त स्थान द्वारा कब्जा कर लिया जाता है, वितरण वैक्टर से मानव-व्याख्यायोग्य शब्दार्थ प्रतिनिधित्व को तराशने के लिए एक नई और सरल विधि का प्रस्ताव करके।', 'ru': 'Вложения слов - это векторные семантические представления, построенные с помощью методов подсчета или предсказания, направленных на захват оттенков смысла от совмещения слов. С момента их введения эти представления подвергались критике за отсутствие интерпретируемых аспектов. Это свойство вложений слов ограничивает наше понимание семантических особенностей, которые они на самом деле кодируют. Кроме того, это способствует «черному ящику» в характере задач, в которых они используются, поскольку причины производительности встраивания слов часто остаются непрозрачными для человека. В этом вкладе мы исследуем семантические свойства, закодированные во вложениях слов, путем отображения их на интерпретируемые векторы, состоящие из явных и нейробиологически мотивированных семантических особенностей (Binder et al. 2016). Наше исследование учитывает различные типы вложений, включая факторизованные векторы подсчета и модели прогнозирования (Skip-Gram, GloVe и т.д.), а также самые последние контекстуализированные представления (т.е. ELMo и BERT). В нашем анализе мы сначала оцениваем качество отображения в задаче поиска, затем проливаем свет на семантические особенности, которые лучше закодированы в каждом типе вложения. Большое количество задач зондирования, наконец, устанавливается, чтобы оценить, как оригинальные и отображенные вложения работают в разграничивающих семантических категориях. Для каждой задачи зондирования мы определяем наиболее релевантные семантические признаки и показываем, что существует корреляция между производительностью встраивания и тем, как они их кодируют\nэто исследование представляет собой шаг вперед в понимании того, какие аспекты смысла захватываются векторными пространствами, предлагая новый и простой метод для создания интерпретируемых человеком семантических представлений из векторов распределения.', 'ga': 'Léiriúcháin shéimeantacha veicteora is ea leabaithe focal a tógadh le teicnící comhairimh nó tuar atá dírithe ar shades brí a ghabháil ó chomhtharluithe focal. Ó tugadh isteach iad, tá na huiríll seo cáinte mar gheall ar easpa toisí inmhínithe. Cuireann an airí seo de leabú focal teorainn lenár dtuiscint ar na gnéithe shéimeantacha a ionchódaíonn siad i ndáiríre. Ina theannta sin, cuireann sé le nádúr “bosca dubh” na dtascanna ina n-úsáidtear iad, mar is minic a bhíonn na cúiseanna le feidhmíocht leabaithe focal teimhneach don duine. Sa rannchuidiú seo, déanaimid iniúchadh ar na hairíonna shéimeantacha atá ionchódaithe i leabaithe focal trí iad a mhapáil ar veicteoirí inmhínithe, comhdhéanta de ghnéithe séimeantacha follasacha agus néarbhitheolaíocha (Binder et al. 2016). Cuireann ár dtaiscéalaíocht san áireamh cineálacha éagsúla leabaithe, lena n-áirítear veicteoirí comhairimh fachtóirithe agus samhlacha tuar (Skip-Gram, GloVe, etc.), chomh maith leis na huiríll comhthéacsúla is déanaí (i.e., ELMo agus BERT). In ár n-anailís, déanaimid meastóireacht ar cháilíocht na mapála ar dtús i dtasc aisghabhála, ansin cuirimid solas ar na gnéithe séimeantacha atá ionchódaithe níos fearr i ngach cineál leabaithe. Socraítear líon mór tascanna iniúchta ar deireadh chun measúnú a dhéanamh ar an gcaoi a bhfeidhmíonn an bunleabú agus an leabaithe léarscáilithe i gcatagóirí séimeantacha idirdhealaitheacha. I gcás gach tasc iniúchta, sainaithnímid na gnéithe shéimeantacha is ábhartha agus léirímid go bhfuil comhghaol idir an fheidhmíocht leabaithe agus conas a ionchódaíonn siad iad sin.\ngnéithe. Leagann an staidéar seo amach mar chéim chun tosaigh chun tuiscint a fháil ar na gnéithe den bhrí a shealbhaíonn spásanna veicteora, trí mhodh nua agus simplí a mholadh chun léiriúcháin shéimeantacha daonna-léirmhínithe a shnoí ó veicteoirí dáileacháin.', 'hu': 'A szóbeágyazások vektoriális szemantikai reprezentációk, amelyeket számlálási vagy előrejelzési technikákkal építenek, és amelyek célja a szótárs-előfordulásokból származó jelentési árnyalatok rögzítése. Bevezetésük óta ezeket az ábrázolásokat kritizálták, mert hiányoznak értelmezhető dimenziók. A szóbeágyazások ezen tulajdonsága korlátozza az általuk ténylegesen kódolt szemantikai jellemzők megértését. Ezenkívül hozzájárul az alkalmazott feladatok "fekete doboz" jellegéhez, mivel a szó beágyazásának okai gyakran átláthatatlanok maradnak az emberek számára. Ebben a közreműködésben a szóbeágyazásokban kódolt szemantikai tulajdonságokat vizsgáljuk fel úgy, hogy azokat értelmezhető vektorokra tárjuk fel, amelyek explicit és neurobiológiailag motivált szemantikai jellemzőkből állnak (Binder et al. 2016). Kutatásunk során figyelembe vesszük a különböző típusú beágyazásokat, beleértve a faktorizált számvektorokat és előrejelzési modelleket (Skip-Gram, GloVe stb.), valamint a legfrissebb kontextuális reprezentációkat (ELMo és BERT). Elemzésünk során először egy visszakeresési feladatban értékeljük a térképezés minőségét, majd rávilágítunk azokra a szemantikai jellemzőkre, amelyek jobban kódolhatók az egyes beágyazási típusokban. Végül számos vizsgálati feladatot állítottunk be annak értékelésére, hogy az eredeti és a leképezett beágyazások hogyan teljesítenek diszkrimináló szemantikai kategóriákban. Minden egyes vizsgálati feladathoz azonosítjuk a legrelevánsabb szemantikai jellemzőket, és megmutatjuk, hogy korreláció van a beágyazási teljesítmény és azok kódolásának módja között.\njellemzők. Ez a tanulmány előrelépésként állítja fel magát annak megértésében, hogy a jelentés mely aspektusait ragadják meg a vektorterek, egy új és egyszerű módszert javasol az emberi-értelmezhető szemantikai reprezentációk eloszlási vektorokból történő faragására.', 'el': 'Οι ενσωματώσεις λέξεων είναι διανυσματικές σημασιολογικές αναπαραστάσεις που κατασκευάζονται είτε με τεχνικές μέτρησης είτε πρόβλεψης που στοχεύουν στην καταγραφή των αποχρώσεων νοήματος από τις συνυπάρξεις λέξεων. Από την εισαγωγή τους, αυτές οι αναπαραστάσεις έχουν επικριθεί για την έλλειψη ερμηνευτών διαστάσεων. Αυτή η ιδιότητα των ενσωμάτωσης λέξεων περιορίζει την κατανόηση των σημασιολογικών χαρακτηριστικών που πραγματικά κωδικοποιούν. Επιπλέον, συμβάλλει στη φύση του "μαύρου κουτιού" των εργασιών στις οποίες χρησιμοποιούνται, δεδομένου ότι οι λόγοι για την ενσωμάτωση της απόδοσης λέξεων συχνά παραμένουν αδιαφανείς για τους ανθρώπους. Στην παρούσα συνεισφορά, εξερευνούμε τις σημασιολογικές ιδιότητες που κωδικοποιούνται στις ενσωμάτωση λέξεων χαρτογραφώντας τις σε ερμηνευτά διανύσματα, που αποτελούνται από ρητά και νευροβιολογικά υποκινούμενα σημασιολογικά χαρακτηριστικά (κ. 2016). Η έρευνά μας λαμβάνει υπόψη διαφορετικούς τύπους ενσωμάτωσης, συμπεριλαμβανομένων των παραγόμενων διανυσμάτων καταμέτρησης και των προβλέψεων μοντέλων (κ.λπ.), καθώς και των πιο πρόσφατων πλαισιωμένων αναπαραστάσεων (π.χ. ELMo και BERT). Στην ανάλυσή μας, αξιολογούμε πρώτα την ποιότητα της χαρτογράφησης σε μια εργασία ανάκτησης και στη συνέχεια ρίχνουμε φως στα σημασιολογικά χαρακτηριστικά που κωδικοποιούνται καλύτερα σε κάθε τύπο ενσωμάτωσης. Ένας μεγάλος αριθμός εργασιών ανίχνευσης τίθεται τελικά για να αξιολογήσει πώς η αρχική και η χαρτογραφημένη ενσωμάτωση αποδίδουν σε διακριτικές σημασιολογικές κατηγορίες. Για κάθε εργασία ανίχνευσης, προσδιορίζουμε τα πιο συναφή σημασιολογικά χαρακτηριστικά και δείχνουμε ότι υπάρχει συσχέτιση μεταξύ της απόδοσης ενσωμάτωσης και του τρόπου που κωδικοποιούν αυτά\nχαρακτηριστικά. Η μελέτη αυτή θέτει τον εαυτό της ως ένα βήμα μπροστά στην κατανόηση των πτυχών της έννοιας που συλλαμβάνονται από τους διανυσματικούς χώρους, προτείνοντας μια νέα και απλή μέθοδο για τη χάραξη ανθρώπινων ερμηνευτών σημασιολογικών αναπαραστάσεων από διανεμητικά διανύσματα.', 'it': 'Le incorporazioni di parole sono rappresentazioni semantiche vettoriali costruite con tecniche di conteggio o previsione volte a catturare sfumature di significato dalle co-occorrenze di parole. Fin dalla loro introduzione, queste rappresentazioni sono state criticate per mancanza di dimensioni interpretabili. Questa proprietà delle incorporazioni di parole limita la nostra comprensione delle caratteristiche semantiche che effettivamente codificano. Inoltre, contribuisce alla natura "scatola nera" dei compiti in cui vengono utilizzati, poiché le ragioni per le prestazioni di incorporazione delle parole rimangono spesso opache per gli esseri umani. In questo contributo, esploriamo le proprietà semantiche codificate negli embedding di parole mappandole su vettori interpretabili, costituiti da caratteristiche semantiche esplicite e neurobiologicamente motivate (Binder et al. 2016). La nostra esplorazione prende in considerazione diversi tipi di embedding, inclusi vettori di conteggio fattorizzati e modelli predittivi (Skip-Gram, GloVe, ecc.), così come le più recenti rappresentazioni contestualizzate (es., ELMo e BERT). Nella nostra analisi, valutiamo prima la qualità della mappatura in un compito di recupero, poi facciamo luce sulle caratteristiche semantiche che sono meglio codificate in ogni tipo di embedding. Un gran numero di attività di probing è infine impostato per valutare come le incorporazioni originali e mappate si comportano in categorie semantiche discriminatorie. Per ogni compito di probing, identifichiamo le caratteristiche semantiche più rilevanti e mostriamo che c\'è una correlazione tra le prestazioni di embedding e il modo in cui queste codificano\ncaratteristiche. Questo studio si pone come un passo avanti nella comprensione di quali aspetti del significato sono catturati dagli spazi vettoriali, proponendo un nuovo e semplice metodo per intagliare rappresentazioni semantiche umana-interpretabili dai vettori distributivi.', 'ka': "სიტყვების შეყვარება არის გვქტორიალური სმენტიკური გამოსახულებები, რომლებიც შეყვარებულია ან გამოსახულებულია ტექნოგიები, რომლებიც უნდა შეიყვარებულია სიტყვების შესა მათი შეცდომის შემდეგ, ეს გამოსახულებები კრიტიკურებულია განსხვავებელი განზომილებებისთვის. ეს სიტყვების შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესახებ ჩვენი სემონტიკური შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამი დამატებით, ეს მოხმარება საქმედების 'შავი კოსტი' სათვის, რომლებიც ისინი გამოყენება, რადგან სიტყვის შემდეგ საქმედებო სიტყვის შემდეგ ადამიანებისთვის უცნობი ამ დამატებით, ჩვენ ვაკეთებთ სიმბოლოგიური განსაზღვრებები, რომლებიც სიმბოლოგიური განსაზღვრებულებაში კოდირებულია სიმბოლოგიური განსაზღვრებით, რომლებიც განსაზღვრებული გვექტორებში, რომლებიც გამო ჩვენი განსხვავება აღმოჩენა განსხვავებული ტიპები ინტებიზიციების შესახებ, რომლებიც ფაქტორიზებული გვექტორები და წინასწორებული მოდელები (Skip-Gram, Glove, etc.), და აღმოჩენა ყველაზე ახალი კონტექსტუალური გამოსა ჩვენი ანალიზაციაში, ჩვენ პირველი გავამუშავებთ მაპრაფიკაციის საფუძველი დავაკეთება, და შემდეგ ჩვენ გავამუშავეთ სიმპანტიკური ფუძვებები, რომელიც უფრო უფრო კოდირებ უფრო დიდ რაოდენობა პრობენტიკური დავალებები დასაწყებულია, როგორ ორიგიალური და კაპონტიკური კოტეგორიზები გავაკეთებენ დისკრიმინტიკური კატეგორიაში. ყოველ პრობენტიური დავალებისთვის, ჩვენ განვიცნობით ყველაზე მნიშვნელოვანი სემონტიური განსაზღვრებები და ჩვენ ჩვენ გამოჩვენებთ, რომ არსებობს კორელექცია საშუალებო\nშესახებ. ეს სწავლება იგივე ნაწილად გავაგრძნოთ, რომელიც განსაზღვრების განსაზღვრების აპექტები გვეკტორის სივრცეებიდან დაატვირდება, რომელიც განსაზღვრებით ახალი და განსაზღვრებული მეთოდი, რომ გადა", 'lt': "žodžių įterpimas – tai vektoriniai semantiniai atvaizdai, sukurti skaičiavimo arba prognozavimo metodais, kuriais siekiama surinkti reikšmės šešėlius iš žodžių bendrų įvykių. Nuo jų įvedimo kritikuota, kad trūksta aiškinamų matmenų. Ši žodžių įterpimo savybė apriboja mūsų supratimą apie semantines savybes, kurias jos iš tikrųjų koduoja. Moreover, it contributes to the 'black box' nature of the tasks in which they are used, since the reasons for word embedding performance often remain opaque to humans.  Šiuo įnašu mes tiriame semantines savybes, koduotas žodžių įterpimuose, juos paveikslėliant į aiškinamuosius vektorius, sudarytus iš aiškių ir neurobiologiškai motyvuotų semantinių savybių (Binder et al. 2016). Mūsų tyrime atsižvelgiama į įvairių tipų įterpimus, įskaitant faktorizuotus vektorius ir prognozuojamus modelius (Skip-Gram, GloVe ir t. t.), taip pat į naujausius kontekstinius rodmenis (t. y. ELMo ir BERT). Mūsų analizėje pirmiausia vertiname žemėlapių kokybę atliekant atkūrimo užduotį, o vėliau atskleidžiame semantines savybes, kurios yra geriau koduojamos kiekvieno įterpimo tipo atžvilgiu. Galiausiai nustatomas didelis tyrimo uždavinių skaičius, siekiant įvertinti, kaip pradiniai ir žemėlapiai naudojami diskriminuojant semantines kategorijas. Kiekvienai bandymo uždavinei nustatome svarbiausius semantinius požymius ir parodome, kad yra koreliacija tarp įterpimo rezultatų ir jų kodavimo būdų.\nsavybės. Šis tyrimas yra žingsnis į priekį, siekiant suprasti, kurie reikšmės aspektai aptinkami užkrato pernešėjų erdvėse, pasiūlant naują ir paprastą metodą išskirti žmogaus aiškinamus semantinius rodmenis iš paskirstymo pernešėjų.", 'ms': "Penampilan perkataan adalah perwakilan semantik vektorial dibina sama ada dengan teknik penghitungan atau ramalan yang bertujuan untuk menangkap bayangan makna dari kejadian sambungan perkataan. Sejak perkenalan mereka, perwakilan ini telah dikritik kerana kekurangan dimensi yang boleh diterangkan. Ciri-ciri ini dalam perkataan membatasi pemahaman kita tentang ciri-ciri semantik yang sebenarnya mereka kodkan. Moreover, it contributes to the 'black box' nature of the tasks in which they are used, since the reasons for word embedding performance often remain opaque to humans.  In this contribution, we explore the semantic properties encoded in word embeddings by mapping them onto interpretable vectors, consisting of explicit and neurobiologically motivated semantic features (Binder et al. 2016).  Penjelajahan kami mempertimbangkan jenis-jenis pembangunan yang berbeza, termasuk vektor kiraan faktor dan model ramalan (Skip-Gram, GloVe, dll.), serta perwakilan kontekstual yang terbaru (iaitu ELMo dan BERT). Dalam analisis kita, kita pertama-tama menilai kualiti peta dalam tugas pengumpulan, kemudian kita memberi cahaya kepada ciri-ciri semantik yang lebih dikekodkan dalam setiap jenis penyembedding. Bilangan besar tugas penyiasatan akhirnya ditetapkan untuk menilai bagaimana penyembahan asal dan peta dilakukan dalam kategori semantik diskriminasi. Untuk setiap tugas penyelidikan, kita mengenalpasti ciri-ciri semantik yang paling relevan dan kita menunjukkan bahawa terdapat korelasi antara prestasi penyembedding dan bagaimana mereka mengekodkan\nciri- ciri. Ujian ini menetapkan dirinya sebagai langkah ke hadapan dalam memahami mana aspek makna ditangkap oleh ruang vektor, dengan melaporkan kaedah baru dan sederhana untuk mengukir perwakilan semantik yang boleh diinterpretasi manusia dari vektor distribusi.", 'kk': "Сөздерді ендіру - сөздердің көлеңкелерін сөздердің көлеңкелерін алу үшін құрылған векториялық семантикалық кескіндер. Олардың көрінісінен кейін, бұл таңбалар аудармалы өлшемдерінің жоқ болуы үшін қиындықталды. Бұл сөздерді ендіру қасиеті біздің семантикалық қасиеттерімізді шектеп береді. Сонымен қатар, олар қолданылатын тапсырмалардың 'қара қоршау' қасиетіне көмектеседі, себебі сөздерді ендіру үшін адамдарға көбірек мөлдірлік болады. Бұл көмектесімізде, сөздерді ендіру үшін, оларды толықтай алатын векторларға сәйкес келтіріп, нейробиологиялық симантикалық қасиеттерді зерттеп көрдік (Binder et al. 2016). Біздің зерттеулеріміз, факторизацияланған вектор саны және үлгілерді алдын алатын түрлері (Skip-Gram, Glove, т. б.), және ең жаңа контекстуалды түрлері (т. б. ELMo және BERT). Біздің анализиямызда, біріншіден қалпына келтіру тапсырмасының сапатын бағалап, кейін әрбір ендіру түрінде жақсы кодталатын семантикалық қасиеттерге жарықты жарықты түсіндік. Бірнеше теңдеу тапсырмаларының көпшілігі соңында негізгі және карталанған ендірудің қалай істейтінін бақылау үшін орнатылады. Әрбір тексеру тапсырмасы үшін ең маңызды семантикалық мүмкіндіктерді анықтаймыз. Біз ендіру әрекеттерінің арасында және оларды қалай кодтамыз деп көрсетеді.\nқасиеттері. Бұл зерттеулер өзінің бірінші қадам болып, таратылған векторлардан кейінгі мәліметтің қандай аспекттерін түсіндіру үшін, адамдарды аударуға мүмкіндік беретін семантикалық түсініктерді түсіндіру үшін жа", 'mk': 'Вклучувањата на зборовите се векторијални семантични претставувања изградени со техники на броење или предвидување кои имаат за цел фаќање сенки од значење од зборовите коопозиции. Од нивното воведување, овие претставувања се критикувани поради недостатокот на интерпретабилни димензии. Оваа сопственост на вложување на зборови го ограничува нашето разбирање на семантичните карактеристики кои всушност ги кодираат. Покрај тоа, тој придонесува за природата на „црната кутија“ на задачите во кои се користат, бидејќи причините за вградување на зборовите честопати остануваат непријатни за луѓето. Во овој придонес, ги истражуваме семантичките сопствености кодирани во зборовите вградени со мапирање на нив на интерпретабилни вектори, кои се состојат од експлицитни и невробиолошки мотивирани семантични карактеристики (Binder et al. 2016). Our exploration takes into account different types of embeddings, including factorized count vectors and predict models (Skip-Gram, GloVe, etc.), as well as the most recent contextualized representations (i.e., ELMo and BERT).  Во нашата анализа, прво го проценуваме квалитетот на мапирањето во задачата за преземање, потоа ги објаснуваме семантичните карактеристики кои се подобро кодирани во секој тип на вградување. Голем број истражувачки задачи конечно се поставуваат за да се процени како оригиналните и мапираните вложувања функционираат во дискриминативните семантични категории. За секоја истражувачка задача, ги идентификуваме најрелевантните семантични карактеристики и покажуваме дека постои корелација помеѓу вградената изведба и како тие ги кодираат\nкарактеристики. Оваа студија се поставува себеси како чекор напред во разбирањето кои аспекти на значењето се зафатени од векторните простори, предлагајќи нов и едноставен метод за исечување на човековите семантични претставувања од дистрибутивните вектори.', 'ml': "വാക്കുകള്\u200d വെക്റ്ററിയല്\u200d സെമാന്റിക് പ്രതിനിധികളാണ്, എണ്ണുകയോ പ്രവചിക്കുകയോ ചെയ്തിരിക്കുന്ന സാങ്കേതികവിദ്യകള്\u200d വാക്കില അവരെ പരിചയപ്പെടുത്തിയതിനു ശേഷം, ഈ പ്രതിനിധികള്\u200d പരാജയപ്പെടുത്തിയിരിക്കുന്നു. വ്യക്തമാക്കാന്\u200d കഴിയുന ഈ വാക്കിന്റെ സ്വത്തുക്കള്\u200d അവയുടെ സെമാന്റിക്കിന്റെ ഗുണഗണങ്ങളെ കുറിച്ച് മനസ്സിലാക്കുന്നു. അതുകൊണ്ടും, അത് ഉപയോഗിക്കുന്ന ജോലികളുടെ 'കറുത്ത പെട്ടി' സ്വഭാവം ചെയ്യുന്നു. വാക്കിന്റെ പ്രവര്\u200dത്തനത്തിന്റെ കാരണങ്ങള്\u200d മ ഈ ഭാഗത്തില്\u200d, വാക്കുകളില്\u200d എഴുതിയിരിക്കുന്ന സെമാന്റിക് ഗുണഗണങ്ങള്\u200d ഞങ്ങള്\u200d പരിശോധിക്കുന്നു. വ്യക്തമായ വെക്റ്ററുകളിലേക്ക് മാപ്പ് ചെയ്യുന്നു. പ്രത്യക്ഷമ നമ്മുടെ പരിശോധന വ്യത്യസ്ത തരത്തിലുള്ള വ്യത്യസ്ത തരത്തില്\u200d കണക്ക് ചെയ്യുന്നതും, ഫാക്ട്രിക്റ്റര്\u200d വെക്റ്റരും പ്രവചിക്കുന്ന മോഡലുകളും (സ്കിപ്പ്-ഗ്ലോവിയും etc.) പി നമ്മുടെ അന്വേഷണത്തില്\u200d, നമ്മള്\u200d ആദ്യം വീണ്ടെടുക്കുന്ന ജോലിയില്\u200d മാപ്പിങ്ങിന്റെ ഗുണത്തെ വിലാസപ്രകാരം ചെയ്യുന്നു. പിന്നീട്  ഒരുപാട് പരീക്ഷിക്കുന്ന ജോലികള്\u200d അവസാനം സൂക്ഷിച്ചിരിക്കുന്നു. സെമാന്റിക് വിഭാഗങ്ങളെ വ്യത്യസ്തമാക്കുന്നതില്\u200d ആദ്യഭ ഓരോ പരീക്ഷിക്കുന്ന ജോലിക്കും നമ്മള്\u200d ഏറ്റവും പ്രധാനപ്പെട്ട സെമാന്റിക് വിശേഷങ്ങള്\u200d തിരിച്ചറിയുന്നു. നമ്മള്\u200d കാണിക്കുന്നു\nപ്രത്യേകങ്ങള്\u200d. ഈ പഠനത്തിന്റെ സ്വന്തം മുന്നോട്ട് നിര്\u200dത്തുന്നു. വെക്റ്റര്\u200d സ്പെയിസ്റ്റുകളാല്\u200d പിടികൂടുന്നത് എന്താണെന്ന് മനസ്സിലാക്കുന്നതെന്ന് മനസ്സി", 'pl': 'Wkładania słów to wektorowe reprezentacje semantyczne zbudowane przy użyciu technik liczenia lub przewidywania mających na celu uchwycenie odcieni znaczenia ze współwystępowania słów. Od czasu ich wprowadzenia reprezentacje te były krytykowane za brak interpretowalnych wymiarów. Ta właściwość osadzeń słów ogranicza nasze zrozumienie cech semantycznych, które faktycznie kodują. Ponadto przyczynia się do "czarnej skrzynki" zadań, w których są one wykorzystywane, ponieważ powody osadzania słów często pozostają nieprzejrzyste dla ludzi. W niniejszym artykule badamy właściwości semantyczne zakodowane w osadzeniach słów poprzez mapowanie ich na wektory interpretowalne, składające się z wyraźnych i neurobiologicznie motywowanych cech semantycznych (Binder et al. 2016). Nasze badania uwzględniają różne rodzaje osadzeń, w tym faktoryzowane wektory liczby i modele predykcyjne (Skip-Gram, GloVe itp.), a także najnowsze kontekstualizowane reprezentacje (tj. ELMo i BERT). W naszej analizie najpierw oceniamy jakość mapowania w zadaniu odzyskiwania, a następnie rzucamy światło na cechy semantyczne, które są lepiej zakodowane w każdym typie osadzenia. W końcu ustawiono dużą liczbę zadań sondujących, aby ocenić, jak oryginalne i mapowane osadzenia działają w rozróżniających kategoriach semantycznych. Dla każdego zadania sondującego identyfikujemy najbardziej istotne cechy semantyczne i pokazujemy, że istnieje korelacja między wydajnością osadzania a tym, jak je kodują.\ncechy. Badanie to stawia się jako krok naprzód w zrozumieniu, które aspekty znaczenia są uchwycone przez przestrzenie wektorowe, proponując nową i prostą metodę wyrzeźbienia interpretowalnych przez człowieka reprezentacji semantycznych z wektorów dystrybucyjnych.', 'no': 'Ordinnbygging er vektorielle semantiske representasjonar bygde med anten telling eller forventing teknikk som er målt på å henta skygge av meningsverdiar frå ordsammenhendingar. Siden innføring av dei har desse representasjonane blitt kritisert for mangling av tolkbare dimensjonar. Denne eigenskapen av ordinnbygging avgrenserer vår forståelse av semantiske funksjonane dei faktisk kodar. Det bør også bidra til den «svarte boksen» egenskapen av oppgåva som dei vert brukte, sidan grunnene for ordinnbygging er ofte ugjennomsiktige for menneske. I denne bidraga utforskar vi semantiske eigenskapane koda i ordinnbygging ved å kartera dei til tolkbare vektorar, som inneheld eksplisitt og neurobiologisk motivert semantiske funksjonar (Binder et al. 2016). Utforskinga vårt gjer i bruk forskjellige typar innbygging, inkludert faktoriserte tal vektorar og forhåndsvising av modeller (Hopp-Gram, Glove osv.), og de siste kontekstualiserte representasjonane (t.d. ELMo og BERT). I analysen vår er vi først evaluert kvaliteten til kartet i ei henting oppgåve, og så blei vi lys på de semantiske funksjonane som er bedre koda i kvar innbyggingstype. Ein stor tal proberingsoppgåver er sett til slutt for å vurdere korleis originalene og mapperingsinnbygginga utfører i diskriminasjonskkategoriar. For kvar proberingsoppgåve identifiserer vi dei mest relevante semantiske funksjonane, og vi viser at det er ein korrelasjon mellom innbyggingsoppgåva og korleis dei kodar dei\nfunksjonar. Denne studien sett seg fram som eit steg for å forstå kva aspekt av betydning vert henta av vektormellomrom ved å foreslå eit nytt og enkelt metode for å lage semantiske representasjonar frå distribusjonelle vektorar som kan interpreterast menneske.', 'mt': 'L-inkorporazzjonijiet tal-kliem huma rappreżentazzjonijiet semantiċi vektorjali mibnija jew b’tekniki ta’ għadd jew ta’ tbassir immirati lejn il-qbid ta’ ombri ta’ tifsira minn ko-okkorrenzi tal-kliem. Mill-introduzzjoni tagħhom, dawn ir-rappreżentazzjonijiet ġew ikkritikati minħabba nuqqas ta’ dimensjonijiet interpretabbli. Din il-proprjetà tal-inkorporazzjoni tal-kliem tillimita l-fehim tagħna tal-karatteristiċi semantiċi li fil-fatt jikkodifikaw. Barra minn hekk, tikkontribwixxi għan-natura tal-“kaxxa sewda” tal-kompiti li fihom jintużaw, peress li r-raġunijiet għall-prestazzjoni tal-inkorporazzjoni tal-kliem spiss jibqgħu opaki għall-bnedmin. F’din il-kontribuzzjoni, nesploraw il-karatteristiċi semantiċi kkodifikati fl-inkorporazzjonijiet tal-kliem billi nimmappjawhom fuq vetturi interpretabbli, li jikkonsistu f’karatteristiċi semantiċi espliċiti u newrobijoloġikament motivati (Binder et al. 2016). L-esplorazzjoni tagħna tikkunsidra tipi different i ta’ inkorporazzjonijiet, inklużi l-vetturi tal-għadd fatturizzat u mudelli ta’ tbassir (Skip-Gram, GloVe, e ċċ.), kif ukoll ir-rappreżentazzjonijiet l-aktar reċenti kuntestwalizzati (jiġifieri ELMo u BERT). Fl-analiżi tagħna, l-ewwel ivvalutaw il-kwalità tal-immappjar f’kompitu ta’ rkupru, imbagħad nieħdu dawl fuq il-karatteristiċi semantiċi li huma kkodifikati a ħjar f’kull tip ta’ inkorporazzjoni. Fl-aħħar nett, għadd kbir ta’ kompiti ta’ sondaġġ huma stabbiliti biex jivvalutaw kif l-inkorporazzjonijiet oriġinali u mmappjati jwettqu f’kategoriji semantiċi diskriminatorji. Għal kull kompitu ta’ sondaġġ, nidentifikaw l-aktar karatteristiċi semantiċi rilevanti u nuru li hemm korrelazzjoni bejn il-prestazzjoni ta’ inkorporazzjoni u kif dawn jikkodifikaw dawk\nkaratteristiċi. This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.', 'si': "වචන සම්බන්ධ වෙක්ටරිය සෙමැන්ටික් ප්\u200dරතිනිශ්ණත්වය නිර්මාණය කරලා තියෙන්නේ වචන සම්බන්ධතාවයෙන් වචන සම්බන්ධ ව ඔවුන්ගේ පරීක්ෂණයෙන් පස්සේ, මේ ප්\u200dරතිනිධාන ප්\u200dරතිනිධාන විශ්වාස කරන්න පුළුවන් විශ් මේ වචන සම්බන්ධ විශේෂතාවය අපේ සෙමැන්ටික් අවස්ථාවක් ගැන තේරුම් සීමාන්තික විශේෂතාවක් ස ඒවගේම, ඒක ප්\u200dරයෝජනය කළු බොක්ස් 'ස්වභාවිතයි' ක්\u200dරියාවට ප්\u200dරයෝජනය කරනවා, මිනිස්සුන්ට ප්\u200dරයෝජනය වෙනුවෙන්  In this part, we find the semantic genscripts coded in word Embdings by map them to interpolable Vectors, composing of Explistic and neurobiologisically Motified semantic Featurals (Binder et al. 2016). අපේ පරීක්ෂණය විවිධ වර්ගයක් ගණන් කරනවා වෙක්ටර් ගණන් වෙක්ටර් වලින් සම්බන්ධ කරනවා (Skip-Gram, Glove, etc.), ඒ වගේම අලුත් පරීක්ෂණ වර්ගයක් වලින්. අපේ විශ්ලේෂණයේදී, අපි පළමු විශ්ලේෂණයේදී ප්\u200dරතිලේෂණයේ ක්\u200dරියාත්මක ක්\u200dරියාත්මක විශේෂ කරනවා, ඊට පස්සේ අපි සෙමැන්ටි අවසානයෙන් ප්\u200dරශ්න වැඩක් ලොකු සංකේතයක් සැකසුම් කරලා තියෙන්නේ ප්\u200dරධාන සහ සංකේතනය කොහොමද ප්\u200dරශ්න විදිහ හැම ප්\u200dරශ්න වැඩක්ම විතරයි, අපි හොඳම සම්බන්ධ සෙමාන්ටික් අවස්ථාවක් පරීක්ෂා කරනවා, අපි පෙන්වන්නේ ඒ වගේම සම්\nවිශේෂතාවක්. මේ පරීක්ෂණය තමයි වෙක්ටර් ස්ථානයෙන් අදහස් වෙනුවෙන් තේරුම් ගන්න පුළුවන් පැත්තක් වෙනුවෙන් වෙක්ටර් ස්ථානයෙන් අලුත් සහ සර", 'mn': 'Хүмүүс нь тооцоолж буй эсвэл тооцоолж буй техникуудыг тооцоолж буй векториал semantic илэрхийллүүд юм. Тэдний танилцуулалтаас хойш эдгээр үзүүлэлтийг илэрхийлж чадахгүй хэмжээсүүдийг алдагдахаас шүүмжлэгдсэн. Энэ үгний жишээ нь бидний шинжлэх ухааныг хязгаарладаг. Үүний дараа нь хар хайрцаг нь хүмүүст хэрэглэгддэг үйл ажиллагааны хайрцаг байдлаар нөлөөлдөг. Үүний тусламжтайгаар бид хэлбэрээр дүгнэх хэлбэрээр шинэчлэгдсэн semantic properties-ыг судалж үзнэ. Энэ нь тодорхой, мэдрэлийн сэтгэл хөдлөл болон сэтгэл хөдлөл хийгдсэн semantic features (Binder et al. 2016). Бидний судалгаанд олон төрлийн загваруудыг тооцоолж, загваруудыг тооцоолж (Skip-Gram, Glove, т.д.), хамгийн сүүлийн туршлагатай үзүүлэлт (т.е. ELMo болон BERT). Бидний шинжилгээнд эхлээд газрын зураг авах ажил дээрх чанарыг үнэлдэг, дараа нь бид бүх төрлийн илүү шинжлэх ухааны шинжлэх ухаан дээр гэрэл гаргасан. Ихэнх судалгааны ажлыг эцэст нь анхны болон газрын зурагт хэрхэн үржүүлэхийг тодорхойлж байдаг талаар тодорхойлдог. Судалгааны даалгаврын тулд бид хамгийн холбогдолтой семантик хэмжээсүүдийг тодорхойлдог. Бид үүнийг хэрхэн холбогдолтой байдгийг харуулж байна.\nчанар. Энэ судалгаа өөрийгөө хуваарилцааны вектор орон зайд ямар хэмжээсүүдийг ойлгохын тулд аль хэмжээсүүдийг шинэ, энгийн арга зам болгож, хүн төрөлхтний хэлбэрээр дүрслэлтэй семантик хэмжээсүүдийг хуваарил', 'so': 'Qoraalka warqada ku qoran waa qaabab ka mid ah oo la dhisay tirada ama wax ka sii sheego, kaas oo loogu talo galay in lagu soo qabsado hooska waxyaabaha micneheedu ay ka soo jeedaan hadal isku mid ah. Tan iyo waqtigii ay soo bandhigteen, waxaa lagu qiimeeyey noocyo turjuman darteed. hantidan hadalka ayaa ku xadgudba waxyaabaha ay ku qoran yihiin Waxaa sidoo kale ku faa’iidaa dabiicadda shaqada lagu isticmaalo madow, sababaha hadalka lagu sameeyo waxyaabaha ku saabsan waxyaabaha ay marar badan u baahan yihiin dadka. Markaas waxan waxaynu baaraynaa hantidiisa semantika ah oo ku qoran hadalka ku qoran, waxaana ku sawirannaa waddooyinka lagu turjumayo, kaas oo ka mid ah qaab cad iyo waxyaabaha neurobiological ku hagaajiya semantic (Binder et al. 2016). Baaritaankeennu waxay ku xisaabsan yihiin noocyo kala duduwan oo ka mid ah wadooyinka tirada iyo qaababka horumarinta (Skip-Gram, GloVe, etc.) iyo noocyadii ugu dambeeyey e e la soo jeeday (ELMo iyo BERT). Analyskayaga, marka ugu horeysa waxaynu qiimeynaynaa qiimeynta sawirada shaqada la heli karo, kadibna waxaynu ku shubnay iftiinka sawirada ah oo ugu wanaagsan kooban cayn kasta. A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories.  Shaqo kasta oo baaritaanka ah, waxaynu aqoonsanaynaa waxyaabaha ugu muhiimsan ee jimicsiga, waxaynu muujinnaa inay haystaan xiriir u dhexeeya sameynta sameynta iyo sida ay u kooban yihiin\nqalab. Waxbarashadan wuxuu isu dhigaa qaab horumar ah si ay u fahamaan waxyaabaha ay micneheedu leedahay meelaha vector lagu qabsado, taasoo lagu soo jeedo qaab cusub oo fudud oo lagu qorayo noocyada dadka lagu turjumayo semantika oo kala duduwan.', 'ro': 'Încorporările de cuvinte sunt reprezentări semantice vectoriale construite cu tehnici de numărare sau predicție care vizează captarea nuanțelor de semnificație din co-evenimente cuvinte. De la introducerea lor, aceste reprezentări au fost criticate pentru lipsa dimensiunilor interpretabile. Această proprietate a încorporărilor de cuvinte limitează înțelegerea caracteristicilor semantice pe care le codează de fapt. Mai mult decât atât, contribuie la natura "cutiei negre" a sarcinilor în care sunt utilizate, deoarece motivele pentru încorporarea cuvintelor rămân adesea opace pentru oameni. În această contribuție, explorăm proprietățile semantice codificate în încorporările de cuvinte prin maparea lor pe vectori interpretabili, constând în trăsături semantice explicite și motivate neurobiologic (Binder et al. 2016). Explorarea noastră ia în considerare diferite tipuri de încorporări, inclusiv vectori factorizați și modele de predicție (Skip-Gram, GloVe, etc.), precum și cele mai recente reprezentări contextualizate (ex., ELMo și BERT). În analiza noastră, evaluăm mai întâi calitatea cartografierii într-o sarcină de recuperare, apoi punem lumină asupra caracteristicilor semantice care sunt mai bine codificate în fiecare tip de încorporare. Un număr mare de sarcini de sondare este setat în cele din urmă pentru a evalua modul în care încorporările originale și mapate funcționează în categorii semantice discriminatorii. Pentru fiecare sarcină de sondare, identificăm cele mai relevante caracteristici semantice și arătăm că există o corelație între performanța de încorporare și modul în care acestea codează aceste caracteristici\ncaracteristici. Acest studiu se prezintă ca un pas înainte în înțelegerea aspectelor semnificației captate de spațiile vectoriale, propunând o metodă nouă și simplă de sculptare a reprezentărilor semantice uman-interpretabile din vectorii distribuționali.', 'sr': 'Uključenje reči su vektorijske semantičke predstave izgrađene sa brojanjem ili predviđanjem tehnika ciljanih na uhvativanje senki znaèaja iz saradnje reèi. Od njihovog uvođenja, ove predstave su kritizirane zbog nedostatka interpretabilnih dimenzija. Ova imovina reèi ugraðenja ogranièava naše razumevanje semantièkih karakteristika koje su zapravo kodirane. Osim toga, to doprinosi prirodi "crne kutije" zadataka u kojima se koriste, jer razlozi za uključenje reči često ostaju opasni za ljude. U ovom doprinosu, istražujemo semantičke vlasništvo kodirane u rečima ugrađenja mapirajući ih na interpretabilne vektore, sastavljajući od eksplicitih i neurobiološki motiviranih semantičkih karakteristika (Binder et al. 2016). Naše istraživanje uzima u obzir različite vrste ugrađenja, uključujući faktorizirane vektore broja i predviđanje modela (Skip-Gram, Glove, itd.), kao i najnovije kontekstualizirane predstave (tj. ELMo i BERT). U našoj analizi, prvo procjenjujemo kvalitet mapiranja u povratnom zadatku, a onda smo proširili svjetlo na semantičke karakteristike koje su bolje kodirane u svakom vrstu uključenja. Veliki broj ispitivanja je konačno postavljen da proceni kako originalni i mapirani integraciji izvode u diskriminacijskim semantičkim kategorijama. Za svaki probni zadatak, identifikujemo najvažnije semantičke karakteristike i pokazujemo da postoji korelacija između uključujuće učinke i kako oni kodiraju one\nkarakteristike. Ova studija se postavlja kao korak napred u razumijevanju koji aspekti značenja su uhvaćeni vektorskim prostorijama, predlažeći novu i jednostavnu metodu da se izvuče semantične predstave sa distribucijskih vektora koji mogu pretumačiti ljudima.', 'sv': 'Ordinbäddningar är vektoriella semantiska representationer byggda med antingen räknings- eller förutsägelsetekniker som syftar till att fånga nyanser av mening från ordsamvaror. Sedan de introducerades har dessa framställningar kritiserats för att de saknar tolkningsbara dimensioner. Denna egenskap av ord inbäddningar begränsar vår förståelse av de semantiska funktioner de faktiskt kodar. Dessutom bidrar det till den "svarta lådan" karaktären hos de uppgifter som de används i, eftersom orsakerna till att ord inbäddas ofta förblir ogenomskinliga för människor. I detta bidrag utforskar vi de semantiska egenskaperna kodade i ordinbäddningar genom att kartlägga dem på tolkade vektorer, bestående av explicita och neurobiologiskt motiverade semantiska drag (Binder et al. 2016). Vår utforskning tar hänsyn till olika typer av inbäddningar, inklusive faktoriserade räknevektorer och förutsägelsemodeller (Skip-Gram, GloVe, etc.), samt de senaste kontextualiserade representationerna (dvs ELMo och BERT). I vår analys utvärderar vi först kvaliteten på kartläggningen i en hämtningsuppgift, sedan belyser vi de semantiska funktioner som är bättre kodade i varje inbäddningstyp. Ett stort antal undersökningsuppgifter ställs slutligen in för att bedöma hur original- och mappade inbäddningar presterar i diskriminerande semantiska kategorier. För varje probningsuppgift identifierar vi de mest relevanta semantiska funktionerna och visar att det finns ett samband mellan inbäddningsprestandan och hur de kodar dessa\negenskaper. Denna studie sätter sig själv som ett steg framåt för att förstå vilka aspekter av mening som fångas av vektorrum, genom att föreslå en ny och enkel metod för att skära mänskligt tolkade semantiska representationer från distributionsvektorer.', 'ta': "வார்த்தை உள்ளீடுகள் வெக்டாரியல் பெம்பென்டிக் குறிப்புகள் எண்ணிக்கையில் உள்ளது அல்லது முன்வார்த்தை நிழலில் இருந்து சொல்ல அவர்கள் தொடர்பு கொண்டிருந்தால், இந்த புதிய குறிப்பிடப்பட்டுள்ள பகுதிகள் முடிவுபடுத்தப்பட்டுள்ளது. இந்த வார்த்தையின் குறியீட்டின் குணங்களை புரிந்து கொள்ளும். மேலும், அது பயன்படுத்தப்படும் பணிகளின் 'கருப்பெட்டி' இயல்பிற்கு செலவு செய்கிறது, ஏனெனில் வார்த்தை உள்ளிடும் செயல்பாட்டின்  இந்த செயல்பாட்டில், நாம் வார்த்தையில் குறியிடப்பட்ட பென்மான்டிக் குணங்களை பார்க்கிறோம். வெளிப்படையாக மற்றும் நரம்பியல் ஊக்கும் பெம்பாண்டிக் குண எங்கள் கண்டறிதல் வெக்டார் மற்றும் முன்காட்சி மாதிரிகளைச் சேர்த்துள்ள வேறு வகையான உள்ளீடுகளை எடுத்துக் கொள்ளும், மற்றும் அண்மையில் சமீபத்தில் பாதிக்கப்பட்ட பிரத எங்கள் ஆராய்ச்சியில், முதலில் நாம் மீண்டும் வரைப்படத்தின் தரமை மதிப்பினை மதிப்பிடுகிறோம், பின்னர் நாம் ஒவ்வொரு குறியீட்டு வகைய A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories.  ஒவ்வொரு பரிசோதனைக்கும் செயல்\nகுணங்கள். இந்த ஆராய்ச்சி தன்னை ஒரு படி முன்னோக்கி அமைக்கிறது புரிந்து வெக்டார் இடைவெளிகளால் பிடிக்கப்பட்டுள்ளது என்பதை புரிந்து கொள்ளும், புதிய மற்ற", 'ur': "Word embedding are vectorial semantic representations built with either counting or predicting techniques aimed at capturing shades of meaning from word co-occurrences. ان کے معلوم ہونے کے بعد، یہ معلومات تفصیل کے لائق ہونے کے لئے منکر ہیں. یہ کلمات کے اموال ہمارے سمنتی ویژے کے بارے میں محدود ہوتی ہے جو وہ حقیقت میں کوڈ کر رہے ہیں۔ اس کے علاوہ، یہ کاموں کے 'سیاه باکس' کی تعبیر میں اضافہ کرتا ہے جن میں وہ استعمال کئے جاتے ہیں، کیونکہ کلمات کے مطابق اضافہ کرنے کے سبب اضافہ ہوتے ہیں، اضافہ ہوتے ہیں کہ انسانوں کے لئے اضافہ کئے جاتے ہم اسے مفصل پڑھنے کے ذریعے لفظوں میں سیمنٹی ویکتروں پر مکاپیٹ کریں گے، جو صریح اور نیروبیولوژیکی طریقے سے سیمنٹی ویکتروں میں موجود ہیں (Binder et al. 2016). ہماری تحقیقات مختلف طریقوں کے مطابق انبودینگ کا ذریعہ لیتی ہے، فکتوری کی شمار ویکتوروں کے شامل اور نمڈلوں کی پیش بینی کرتی ہے (Skip-Gram, Glove, etc.)، اور اگلوں سے اگلوں سے اگلوں سے متوجہ ہوئی نمائش (یعنی ELMo اور BERT). ہمارے تحلیل میں، ہم پہلی بار ایک اٹھانے کے کام میں نقشه کی کیفیت کا ارزش کریں، پھر ہم نے سیمنٹی ویٹیوں پر نور ڈال دیا جو ہر انڈینگ ٹائپ میں بہتر سی کوڈ کیے جاتے ہیں. ایک بڑی تعداد پرڈینگ کے کام آخر میں مقرر کیے گئے ہیں کہ آغاز اور نقشه مہینڈینگ کس طرح کام کریں جن کی مختلف سیمنٹی کاٹیوں میں۔ ہر امتحان کام کے لئے، ہم سب سے اچھے سمantic features کو پہچان لیتے ہیں اور ہم نشان دیتے ہیں کہ انڈینگ کامل کے درمیان ایک تعلق ہے اور وہ کس طرح ان کو کڑتے ہیں\nفرصت. This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.", 'uz': 'Name Tashqi qilinganda, bu tashkilotlar tarjima qiladigan holatlar sababda qisqarli bo\'lgan. Bu so\'zning xossalari bizning semantik imkoniyatlarimizni o\'rganish mumkin. Ko\'rib, bu ishlatiladigan vazifalar "qora qutisi" tarkibini qo\'llaydi, chunki so\'z ichki vazifalarning sabablari odamlarga yetarli emas. Bu paytda, biz ularni tarjima qiladigan vektorlarga qarashtirish uchun semantik xossalarini ko\'rib chiqaramiz, xususiyatli va neyrologik bilan harakat qiladigan semantik xususiyatlarini (Binder et al. 2016). Bizning qidirish turlarimiz, faqatgina qismi vectorlari va oldinga modellar (Skip-Gram, GloVe va va eng yaqinda taʼminlovchi tashkilotlar (m. ELMo va BERT) kabi. Analyzerimizda, biz birinchi marta raqamli tashkilotning сифатini qiymatimiz, keyin biz har bir qanchalik turida yaxshi kodlash mumkin. Name For each probing task, we identify the most relevant semantic features and we show that there is a correlation between the embedding performance and how they encode those\nxususiyatlar. Bu o\'qituvni o\'zini o\'rganishni o\'rganishni o\'rganish uchun, vektor boʻsh joylarining qanday qismi bilan qabul qilishni o\'rganish uchun yangi va oddiy usulni o\'rganish va tarjima vektorlardan foydalaniladigan semantik tashkilotlarini yaratish mumkin.', 'vi': 'Sự nhúng vào từ là các biểu tượng theo giao thức cơ quan được xây dựng bằng cách đếm hoặc dự đoán các kỹ thuật nhằm nhằm nhằm chộp lấy các sắc thái ý nghĩa từ các lần này xảy ra. Kể từ khi họ giới thiệu, các biểu tượng này đã bị phê bình vì thiếu các kích thước giải thích. Tài sản này của sự gắn ghép từ giới hạn sự hiểu biết về các tính năng ngữ pháp mà chúng thực sự mã hóa. Hơn nữa, nó có tác dụng với "hộp đen" của các nhiệm vụ mà nó được sử dụng, vì lý do tạo ra hiệu quả từ đính kèm thường là mờ ám đối với con người. Trong sự đóng góp này, chúng ta khám phá các tính chất theo ngữ pháp được mã hóa trong sự gắn ghép từ bằng cách vẽ chúng vào các sinh vật có thể hiểu được, gồm các tính chất theo ngữ pháp rõ ràng và sinh lý theo logic (Binder et al. 206). Trong cuộc thám hiểm của chúng tôi được tính toán các kiểu nối bộ, bao gồm các sinh tố đếm đúng số và các mô hình dự đoán (Skip-Gram, GloVe, v., cũng như các biểu tượng tình hình gần đây (ví dụ, ElMo và BERT). Theo phân tích của chúng tôi, trước tiên chúng tôi đánh giá chất lượng của bản đồ trong một nhiệm vụ tìm kiếm, sau đó chúng tôi soi sáng các tính chất ngữ pháp tốt hơn được mã hóa trong mỗi loại nhúng. Một số công việc thăm dò lớn được đặt ra để đánh giá cách sự nhúng mũi gốc và bản đồ thực hiện trong phân biệt ngữ pháp phân biệt. Với mỗi nhiệm vụ thăm dò, chúng tôi xác định các tính năng ngữ pháp quan trọng nhất và chúng tôi cho thấy có sự tương quan giữa khả năng lắp ghép và cách chúng mã hóa chúng\nnét. Nghiên cứu này đặt mình như một bước tiến trong việc hiểu biết các khía cạnh ý nghĩa nào được ghi lại bởi các chi tiết vector, bằng cách đề xuất một phương pháp mới và đơn giản để khắc các biểu tượng chữ nghĩa\'Người\'.', 'bg': 'черти. Това изследване се поставя като стъпка напред в разбирането кои аспекти на значението са уловени от векторните пространства, като предлага нов и прост метод за издълбане на човешко-интерпретативни семантични представи от разпределителни вектори.', 'de': 'Funktionen. Diese Studie stellt einen Schritt nach vorn dar, um zu verstehen, welche Bedeutungsaspekte von Vektorräumen erfasst werden, indem sie eine neue und einfache Methode vorschlägt, um menschlich interpretierbare semantische Repräsentationen aus Verteilungsvektoren zu schnitzen.', 'da': 'træk. Denne undersøgelse sætter sig selv som et skridt fremad i forståelsen af, hvilke aspekter af betydning der fanges af vektorrum, ved at foreslå en ny og enkel metode til at udskære menneskelig-fortolkende semantiske repræsentationer fra distributionsvektorer.', 'nl': 'kenmerken. Deze studie zet zichzelf als een stap voorwaarts in het begrijpen van welke aspecten van betekenis worden vastgelegd door vectorruimten, door een nieuwe en eenvoudige methode voor te stellen om mens-interpreteerbare semantische representaties uit distributievectoren te snijden.', 'fa': 'ویژگی\u200cها. این مطالعه خودش را به عنوان یک قدم جلوتر برای فهمیدن که کدام منظوری از معنی توسط فضای ویکتور گرفته می شود، با پیشنهاد یک روش جدید و ساده برای ترکیب نمایش\u200cهای semantic قابل تعبیر انسان از ویکتورهای تقسیم.', 'sw': 'tabia. Utafiti huu unajiweka kama hatua ya mbele kuelewa ni vipi maana vinavyomaanisha vilikamatwa na maeneo ya vector, kwa kupendekeza njia mpya na rahisi ya kutengeneza uwakilishi wa sekunde yanayotafsiriwa binadamu kutoka kwenye vectors.', 'hr': 'karakteristike. U ovom ispitivanju se predstavlja korak naprijed u razumijevanju koji aspekti značenja uhvaćeni vektorskim prostorijama, predlažeći novi i jednostavan način za odvajanje semantičkih predstavljanja ljudskih interpretacija iz distribucijskih vektora.', 'id': 'ciri-ciri. Studi ini mengatur dirinya sebagai langkah maju dalam memahami aspek arti mana yang ditangkap oleh ruang vektor, dengan mengusulkan metode baru dan sederhana untuk memotong represensi semantis manusia-interpretable dari vektor distribusi.', 'af': "funksies. Hierdie studie stel homself as 'n stap voort in verstaan wat aspekte van betekenis word deur vektorspasies gevang deur 'n nuwe en eenvoudige metode te stel om menslike-uittelbare semantiese voorstellings van verspreidingsvektore te skep.", 'ko': '특징.이 연구는 분포 벡터에서 인류가 해석할 수 있는 의미 표시를 절단하여 벡터 공간이 의미를 포착하는 어떤 부분을 이해하는 데 한 걸음 나아갔다.', 'tr': 'üýtgewler. Bu çalışma, mantıklı ifadelerin vektör uzayları tarafından kapıldığını anlamak için kendini bir adım önüne koyuyor.', 'sq': 'karakteristika. Ky studim vendos veten si një hap përpara në kuptimin se cilat aspekte të kuptimit kapen nga hapësirat vektorë, duke propozuar një metodë të re dhe të thjeshtë për të shkurtuar përfaqësime semantike të interpretueshme nga vektorët shpërndarës.', 'am': 'ምርጫዎች ይህም ትምህርት ራሱን በአካባቢው ቦታዎች የሚያዙትን አዲስ እና ቀላል የህዝብ ትርጉም የሚተረጉትን የsemantic መልዕክቶችን ከክፍል vector መቆጣጠር በማስተዋል እንደምታስተውል አቅራቢያ ነው፡፡', 'bn': 'বৈশিষ্ট্য। এই গবেষণা নিজেকে একটি পদক্ষেপ হিসেবে স্থাপন করে বুঝতে পারে যে ভেক্টরের স্পেস দ্বারা গ্রেফতার করা হচ্ছে, বিতরণের ভেক্টর থেকে মানুষ-ব্যাখ্যা', 'cs': 'vlastnosti. Tato studie se stanoví jako krok vpřed v pochopení, které aspekty významu jsou zachyceny vektorovými prostory, navrhnutím nové a jednoduché metody vyřezávání lidsky interpretovatelných sémantických reprezentací z distribučních vektorů.', 'ca': 'característiques. Aquest estudi es posa un pas cap endavant en entendre quins aspectes del sentit capturan els espais vectoris, proposant un mètode nou i senzill per tallar representacions semàntiques interpretables per humans dels vectors distribuïbles.', 'hy': 'հատկություններ: Այս ուսումնասիրությունը ձևավորում է ինքն իրեն որպես քայլ առաջ հասկանալու համար, թե որն է իմաստի ասպեկտները գրանցվում վեկտորային տարածքներով, առաջարկելով նոր և պարզ մեթոդ մարդկային մեկնաբանելի սեմանտիկ ներկայացումներ բաշխման վեկտորներից:', 'az': 'xüsusiyyətlər. Bu təhsil özünü bir adım öyrənir ki, bəzi vektör uzaqlarından hansı anlama aspektlərinin alındığını anlamaq üçün, insan yorumlayıcı semantik göstəricilərini dağıtmaq üçün yeni və basit bir yol təklif edir.', 'et': 'omadused. Käesolev uuring seab ennast sammuks edasi mõistmisel, milliseid tähenduse aspekte vektoriruumid kajastavad, pakkudes välja uue ja lihtsa meetodi jaotusvektoritest inimese tõlgendatavate semantiliste representatsioonide nikerdamiseks.', 'bs': 'karakteristike. U ovom ispitivanju se predstavlja korak naprijed u razumijevanju koje aspekte značenja uhvate vektorskim prostorijama, predlažeći novi i jednostavan metod kako bi uništili ljudske semantičke predstave iz distribucijskih vektora.', 'fi': 'ominaisuudet. Tämä tutkimus asettaa itsensä askeleena eteenpäin ymmärtämisessä, mitkä merkityksen osa-alueet ovat vektoriavaruudessa, ehdottamalla uutta ja yksinkertaista menetelmää ihmisen tulkittavissa olevien semanttisten representaatioiden veistämiseksi jakeluvektoreista.', 'jv': 'embedding depiction Punika ingkang kelas embedding Label In this collation, we istrage the semanti layers koded in word embedding by maping it to interable vectors, forming of explicitic and Nerbiylogically mobiled semanti settings (Binder et al. 16). Iserting Dino haléné, awak dhéwé nggawe perusahaan kowé nggawe karting ing ing ing nggawe gerakan ing nggawe winih, podho kita isih dolanan cara semanti karo perusahaan langgar-sistem sing luwih apik yang cukup. Learn Mode Sampeyan kanggo saben nggunggo bukal, kita nguasai perusahaan semanti sing bebasan lho. Awak dhéwé mungkin bakal terus nggawe gerakan kelas karo akeh operasi ingkang dipun-ingkang karo koyo kode kuwi tindakan\nperingatan.  This tutorial Sets it as a phase forward in compromise whose Aspects of means are Capted by vector space, by proposal a new and simply method to carve Human-readable semanti representations from Distribubutionvectors.', 'ha': "@ info: whatsthis Tana da ya fara, waɗannan mataimaka sun yi zargi dõmin ba da wani girmamo mai fassarawa ba. This property of word embeddings limits our understanding of the semantic features they actually encode.  Kayya, yana ƙara zuwa halin aikin 'botsun haske' da ake yi musu amfani da shi, saboda haka, sababin saurin da ake shiga maganar ta yi daidai a kan mutum ko da yawa. Ga wannan da ke ƙara, za mu yi amfani da sifatin semantiki wanda aka kodi cikin maganar da aka gudãna da su a kan hanyoyi masu fassarawa, masu sami da shiryoyi masu fassarawa (Binder et al. 2016). Bayanmu yana da nau'i-nau'i daban-daban da aka lissafa, kamar shiryoyi na ƙidãyar matsayin da aka ƙayyade shi (skiip-Gram, GloV, etc), da kuma masu ƙarshe da aka haɗa (misali, ELMo da BERT). Daga anayyarmu, sai mu ƙaddara sifar kartonmu a cikin wani aikin da za'a samu, sa'an nan kuma muka yi haske a kan haske na semantiki waɗanda ke fi kyau kodi cikin kõwace irin na fitarwa. An ƙayyade wasu aikin mai jarraba zuwa ƙara don a iya ƙayyade yadda kwanan da aka cika cikin hanyon da aka saka cikin tsarin categories na semantic. Ga kõwane aikin jarraba, Munã gane mafiya muhimmi na semanti kuma tuna nuna kuwa akwai wata mazauni a tsakanin aikin da za'a fito da su kodi\nKCharselect unicode block name This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.", 'he': 'תוכניות מילים הן תמונות סמנטיות ויקטוריות בנויות עם טכניקות ספירה או חזיקה שמכוונות לתפוס צללים של משמעות מתרחשות יחד מילים. מאז ההציגה שלהם, היציגות האלה נבקרו על חסר מימדים אפשריים להפריע. רכוש זה של קישור מילים מגביל את הבנה שלנו של התכונות הסמנטיות שהם למעשה קודים. חוץ מזה, הוא תורם לטבע "קופסה שחורה" של המשימות שבהן הם משתמשים, מאחר שהסיבות להכניסת מילים ביצועים לעתים קרובות נשארות חסרות ערך עבור בני אדם. בתרומה הזו, אנו חוקרים את הנכונות הסמנטיות מוצפנות במילים באמצעות מפת אותן על ווקטורים אפשריים לפרשנות, המתכתבים בתכונות סמנטיות מוציאות באופן ברור ונוירוביולוגי (Binder et al. 2016). החקירה שלנו לוקחת בחשבון סוגים שונים של תוכניות, כולל ווקטורי ספירת מפורקים ומודלים צפויים (Skip-Gram, GloVe, jne.), כמו גם היציגות הקונקסטולוגיות האחרונות (כלומר ELMo ובRT). בניתוח שלנו, אנו קודם מעריכים את איכות המפה בתפקיד חיפוש, ואז אנו משקיעים אור על המאפיינים הסמנטיים שמקודדים יותר טוב בכל סוג של חיפוש. מספר גדול של משימות חקירה מונחים סוף סוף כדי להעריך איך המקורי והתוספות המפוכות מבצעים בקטגוריות סמנטיות המדחיקות. לכל משימה של חקירה, אנו מזהה את התכונות הסמנטיות הרלוונטיות ביותר ואנחנו מראים שיש קשר בין ביצועי ההכניסה\nתכונות. המחקר הזה מציג את עצמו כצעד קדימה בהבנה איזה היבטים של המשמעות נלכדו על ידי חללים ווקטורים, על ידי הצעה שיטה חדשה ופשוטה לגלוש מייצגים סמנטיים אנושיים אפשריים לפרשנות מהווקטורים פיצועים.', 'sk': 'Vgradnje besed so vektorske semantične reprezentacije, zgrajene s tehnikami štetja ali napovedovanja, katerih cilj je zajemati odtenke pomena iz sočasnih besed. Od uvedbe so te reprezentacije kritizirale zaradi pomanjkanja razložljivih dimenzij. Ta lastnost besednih vdelav omejuje naše razumevanje semantičnih značilnosti, ki jih dejansko kodirajo. Poleg tega prispeva k naravi "črne škatle" nalog, pri katerih se uporabljajo, saj razlogi za učinkovitost vključevanja besed pogosto ostajajo nepregledni za ljudi. V prispevku raziskujemo semantične lastnosti, kodirane v besednih vdelavah, tako da jih preslikamo na razložljive vektorje, sestavljene iz eksplicitnih in nevrobiološko motiviranih semantičnih značilnosti (Binder et al. 2016). Naše raziskovanje upošteva različne vrste vdelav, vključno s faktoriziranimi številnimi vektorji in napovednimi modeli (Skip-Gram, GloVe itd.), kot tudi najnovejše kontekstualizirane predstavitve (tj. ELMo in BERT). V naši analizi najprej ocenimo kakovost kartiranja v opravilu iskanja, nato pa osvetlimo semantične značilnosti, ki so bolje kodirane v vsaki vrsti vdelave. Končno je nastavljeno veliko število opravil preiskovanja, da bi ocenili, kako izvirna in preslikana vdelava delujejo v različnih semantičnih kategorijah. Za vsako opravilo preiskovanja določimo najpomembnejše semantične značilnosti in pokažemo, da obstaja korelacija med učinkovitostjo vdelave in njihovim kodiranjem\nznačilnosti. Ta študija se postavlja kot korak naprej pri razumevanju, katere vidike pomena zajemajo vektorski prostori, s predlogom nove in enostavne metode za izklesanje človeško razložljivih semantičnih reprezentacij iz distribucijskih vektorjev.', 'bo': 'Word embeddings are vectorial semantic representations built with either counting or predicting techniques aimed at capturing shades of meaning from word co-occurrences. ཁོང་ཚོའི་སྔོན་སྤྲོད་ཀྱི་གསལ་བཤད་འདི་དག་གི་གྲངས་རིམ་གང་ཞིག་ཡོད་པ་ལས་ངོས་འཛིན་བྱེད་སྲིད་ ཐ་སྙད་ཀྱི་རྒྱུ་དངོས་ཀྱི་ཁྱད་ཆོས་ཀྱིས་ང་ཚོའི་རྣམ་པ་དེ་དག་དངོས་ཡོད་ཐོག འདི་ཡང་བེད་སྤྱོད་པའི་བྱ་འགུལ་གྱི་རང་བཞིན་གནད་གནད་པོའི་རང་བཞིན་ལ་རྒྱབ་སྐྱོར་བྱེད་ཀྱི་ཡོད། In this contribution, we explore the semantic properties encoded in word embeddings by mapping them onto interpretable vectors, consisting of explicit and neurobiologically motivated semantic features (Binder et al. 2016). Our exploration takes into account different types of embeddings, including factorized count vectors and predict models (Skip-Gram, Glove, etc.), as well as the most recent contextualized representations (i.e., ELMo and BERT). The examples include: ང་ཚོའི་དབྱེ་ཞིབ A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories. ལྟ་བུ་རེ་རེད་ཀྱི་ལས་འཚོལ་ཞིབ་བྱས་ན། ང་ཚོས་རང་ཉིད་ཀྱི་ཆ་རྐྱེན་ཆེན་ཤོས་གསལ་བ་འདི་རྟོགས་བྱས་ན་འོང་ནི་\nfeatures. This study sets itself as a step forward in understanding which aspects of meaning are captured by vector spaces, by proposing a new and simple method to carve human-interpretable semantic representations from distributional vectors.'}
{'en': 'Abstractive Text Summarization : Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization', 'es': 'Resumen de texto abstracto: mejora de los modelos secuencia a secuencia mediante la desambiguación del sentido de las palabras y la generalización de contenido semántico', 'ar': 'تلخيص النص التجريدي: تعزيز نماذج التسلسل إلى التسلسل باستخدام توضيح معنى الكلمات وتعميم المحتوى الدلالي', 'pt': 'Resumo Abstrativo de Texto: Aprimorando Modelos de Sequência a Sequência Usando Desambiguação de Sentido de Palavras e Generalização de Conteúdo Semântico', 'fr': "Résumé de texte abstrait\xa0: amélioration des modèles séquence à séquence à l'aide de la désambiguïsation du sens des mots et de la généralisation de contenu sémantique", 'ja': '抽象的テキストの要約：単語センスの曖昧さ解消とセマンティックコンテンツの一般化を使用したシーケンス間モデルの強化', 'zh': '抽象文本摘要:用字感消歧义语义泛化增序至序', 'ru': 'Абстрактное текстовое обобщение: совершенствование моделей последовательности в последовательности с использованием словосочетания смысла и семантического контента', 'hi': 'Abstractive Text Summarization: Word Sense Disambiguation और Semantic Content Generalization का उपयोग करके अनुक्रम-से-अनुक्रम मॉडल को बढ़ाना', 'ga': 'Achoimriú Téacs Teibí: Samhlacha Seicheamh-go-Seicheamh a Fheabhsú Ag Úsáid Dídhébhríocht Focal Sense agus Ginearálú Séimeantach Ábhar', 'ka': 'აბსტრაქტიური ტექსტის კომპანიზაცია: შემდეგ- შემდეგ- შემდეგ მოდელების უფრო მეტირება გამოყენება სიტყვის სიტყვის გამოყენება', 'el': 'Περίληψη κειμένου: Ενίσχυση μοντέλων αλληλουχίας σε αλληλουχίας χρησιμοποιώντας την αποσαφήνιση και τη γενίκευση σημασιολογικού περιεχομένου', 'hu': 'Absztraktív szövegösszefoglalás: A szekvencia-szekvencia modellek javítása a Word Sense szétérthetőségével és a szemantikus tartalom általánosításával', 'it': 'Sintesi astratta del testo: miglioramento dei modelli sequenziali utilizzando la disambiguazione del senso delle parole e la generalizzazione dei contenuti semantici', 'lt': 'Abstraktyvi teksto santrauka: iš eilės į eilę modelių tobulinimas, naudojant žodžio jausmą ir semantinio turinio generalizaciją', 'kk': 'Абстрактивті мәтін тұжырымдамасы: Сөздердің сезімін бұғаттауын және бөлшектердің мазмұнын жасау үлгілерін көтеру', 'ms': 'Penapisan Teks Abstraktif: Menyukur Model Sejukan-ke-Sejukan Mengguna Pengesahan Sensa Perkataan dan Penjanaan Kandungan Semantik', 'ml': 'അബ്ട്രാക്ട്രേക്ഷന്\u200d വാക്ക് സെന്\u200dസിന്റെ അസംഭാഷണം ഉപയോഗിക്കുന്ന സെക്കന്\u200dസ് മോഡലുകള്\u200d കൂടുതല്\u200d വര്\u200dദ്ധിപ്പിക്കുക', 'mk': 'Апстрактивна резултатација на текстот: подобрување на моделите од секвенција до секвенција со користење на раздвојување на зборовите и генерализација на семантичната содржина', 'mt': 'Sommarju tat-Test Abstrattiv: It-Titjib tal-Mudelli Sekwenti-Sekwenti bl-Użu tad-Diżambiguazzjoni tas-Sens tal-kliem u l-Ġeneralizzazzjoni tal-Kontenut Semantiku', 'pl': 'Abstrakcyjne podsumowanie tekstu: ulepszanie modeli sekwencji do sekwencji przy użyciu rozjasnienia tekstu Word Sense i uogólniania treści semantycznych', 'mn': 'Абстрактив текст цуглуулга: Дараагийн-дараагийн загваруудыг нэмэгдүүлэх', 'ro': 'Rezumat text abstract: îmbunătățirea modelelor secvență-secvență folosind dezambiguizarea sensului Word și generalizarea conținutului semantic', 'no': 'Abstraktiv tekstsamandrag: Forstørring av sekvens- til- sekvens- modeller ved bruk av forstørring av tekstfølelser og generering av semiantisk innhald', 'sr': 'Abstraktivna sažetka teksta: Povećavanje modela sekvence do sekvence koristeći dezambigaciju osjećaja riječi i generalizaciju semantičnog sadržaja', 'so': 'Highlighting: Enhancing Sequence-to-Sequence Models Using Word Sense Disambition and Semantic Content General', 'si': 'ප්\u200dරතික්\u200dරීය පාළුව සංශ්\u200dය: ප්\u200dරතික්\u200dරීය- වල සංශ්\u200dය සංශ්\u200dය සංශ්\u200dය සංශ්\u200dය භාවිත කරනවා වචන සංශ්\u200dය සහ සංශ්\u200d', 'ta': 'சுருக்கம்:', 'ur': 'Abstractive Text Summarization: Enhancing Sequence- to- Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization', 'sv': 'Abstraktiv textsammanfattning: Förbättra sekvens-till-sekvensmodeller med hjälp av ordsinnesdistribution och semantisk innehållsgenerering', 'uz': 'Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization', 'vi': 'Tóm tắt tập tin âm bản: Chế độ lặp lặp nhanh/ nhanh', 'hr': 'Abstraktivna sažetka teksta: poboljšanje modela sekvence do sekvence koristeći disambigaciju osjećaja riječi i generalizaciju semantičkog sadržaja', 'da': 'Abstraktiv tekst summering: Forbedring af sekvens-til-sekvensmodeller ved hjælp af Word Sense Disambiguation og semantisk indholdsgeneralisering', 'bg': 'Обобщение на абстрактния текст: Подобряване на моделите последователност към последователност, използвайки дисамбигуация на чувството на словото и генериране на семантично съдържание', 'nl': 'Abstracte samenvatting van tekst: Verbetering van sequentiemodellen met behulp van Word Sense Disambiguation en semantische inhoudsverzameling', 'id': 'Persingkatan Teks Abstraktif: meningkatkan Model Sekuensi-ke-Sekuensi Menggunakan Pengambiguasi Sensi Kata dan Generalisasi Konten Semantik', 'de': 'Abstraktive Textzusammenfassung: Verbesserung von Sequenz-zu-Sequenz-Modellen mithilfe von Word Sense Disambiguation und semantischer Inhaltsverallgemeinerung', 'fa': 'جمع کردن متن abstractive: افزایش مدل\u200cهای سعادت به سعادت', 'ko': '추상적 텍스트 요약: 단어의 의미 변조와 의미 내용의 범용화 강화 서열을 서열 모델로 사용', 'sw': 'Ujumbe wa maandishi ya kusitisha: Kuongezea Mitandao ya Kuzungumzwa kwa mara kwa mara kwa kutumia Utoaji wa Sensi na Ujumbe wa Maudhui', 'tr': 'Abstraktif Metin Toplaýyşy: Diňe-tä-sıralama Modelleri Keçirmek ve Orta Mazmunlar Üzerinde Ullanýar', 'af': 'Abstraktiewe Teks Opsomming: Verbeter Sequence- to- Sequence Models gebruik word Sense Ontbreking en Semantiese Inhoud Generalisering', 'sq': 'Përshkrimi abstraktiv i tekstit: përmirësimi i modeleve nga sekuenca në sekuencë duke përdorur çambiguacionin e ndjerjes së fjalës dhe gjeneralizimin e përmbajtjes Semantike', 'hy': 'Աբստրակտիվ տեքստի համառոտագրություն. բարելավել հաջորդականություն հաջորդականության մոդելները՝ օգտագործելով բառերի զգացմունքի անբացատրությունը և սեմանտիկ պարունակության ընդհանուր ընդհանուր ընդլայնումը', 'bn': 'আবত্ত্রিক টেক্সট সামারিজেশন: শব্দের সেন্স বিচ্ছিন্ন এবং সেম্যান্টিক বিষয়বস্তু সাধারণ', 'az': 'Abstraktiv Metin Toplaşdırılması: Sözlük Duyurulması və Semantik Məzmun Generalizasyonu Əlavə Et', 'am': 'ማጠቃለያ', 'bs': 'Abstraktivna sažetka teksta: poboljšanje modela sekvence do sekvence koristeći disambigaciju osjećaja riječi i generalizaciju semantičnog sadržaja', 'ca': 'Resumen abstractiu del text: millorar els models de seqüència a seqüència utilitzant desambiguació de sentit de paraula i generalització de continguts Semàtics', 'cs': 'Abstraktivní shrnutí textu: zlepšení modelů sekvence na sekvenci pomocí disambiguace Word Sense a zobecnění sémantického obsahu', 'et': 'Kokkuvõtlik teksti kokkuvõte: järjestuse mudelite tõhustamine, kasutades sõnatunne disambigeerimist ja semantilist sisu generaliseerimist', 'fi': 'Abstrakti tekstin yhteenveto: sekvenssimallien tehostaminen sekvenssimallien avulla sanaaistin hajottamisen ja semanttisen sisällön generoinnin avulla', 'jv': 'Samurasi tèks apasitsi: Inchanging Seyense-to-Seyense Modes Using Word Sense disabled mbiguation and semanti Content Generalization', 'he': 'סאמר טקסט אסטרקטיבי: שיפור מודלים רצף-לרצף באמצעות ניתוח משמעות מילים וגנרליזציה של תוכן סמנטי', 'ha': '@ action', 'sk': 'Povzetek besedila: izboljšanje modelov zaporedja v zaporedje z razjasnitvijo besednega smisla in generalizacijo semantične vsebine', 'bo': 'Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization'}
{'en': 'Abstract Nowadays, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. In this direction, this work presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies. The proposed framework is capable of dealing with the problem of out-of-vocabulary or rare words, improving the performance of the deep learning models. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries. The framework is composed of three key elements : (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task. The pre-processing task is a knowledge-based approach, based on ontological knowledge resources, word sense disambiguation, and named entity recognition, along with content generalization, that transforms ordinary text into a generalized form. A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form. The post-processing task utilizes knowledge resources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form.', 'ar': 'الملخص في الوقت الحاضر ، تركز معظم الأبحاث التي أجريت في مجال تلخيص النص التجريدي على النماذج القائمة على العصبية وحدها ، دون النظر إلى دمجها مع الأساليب القائمة على المعرفة التي يمكن أن تعزز كفاءتها. في هذا الاتجاه ، يقدم هذا العمل إطارًا جديدًا يجمع بين تلخيص النص المعتمد على التسلسل العصبي جنبًا إلى جنب مع الهيكل والمنهجيات القائمة على الدلالات. إن الإطار المقترح قادر على التعامل مع مشكلة الكلمات غير المطابقة للمفردات أو الكلمات النادرة ، وتحسين أداء نماذج التعلم العميق. تعتمد المنهجية الشاملة على نموذج نظري محدد جيدًا لتعميم المحتوى القائم على المعرفة وتنبؤات التعلم العميق لتوليد ملخصات تجريدية. يتكون إطار العمل من ثلاثة عناصر رئيسية: (1) مهمة ما قبل المعالجة ، (2) منهجية التعلم الآلي ، و (3) مهمة ما بعد المعالجة. مهمة ما قبل المعالجة هي نهج قائم على المعرفة ، يعتمد على موارد المعرفة الأنطولوجية ، وتوضيح معنى الكلمة ، والتعرف على الكيان المسمى ، إلى جانب تعميم المحتوى ، الذي يحول النص العادي إلى نموذج معمم. يتم تدريب نموذج التعلم العميق لمعمارية وحدة فك التشفير اليقظة ، والتي يتم توسيعها لتمكين آلية المواجهة والتغطية ، بالإضافة إلى التعلم المعزز والبنى القائمة على المحولات ، على نسخة معممة من أزواج ملخص النص ، وتعلم التنبؤ بالملخصات في شكل معمم. مهمة ما بعد المعالجة تستخدم المعرفة\nالموارد ، وتضمينات الكلمات ، وتوضيح معنى الكلمة ، وخوارزميات الكشف عن مجريات الأمور على أساس طرق تشابه النص من أجل تحويل النسخة المعممة من الملخص المتوقع إلى شكل نهائي يمكن قراءته من قبل الإنسان. يقوم إجراء تجريبي مكثف على ثلاث مجموعات بيانات شائعة بتقييم الجوانب الرئيسية للإطار المقترح ، بينما تُظهر النتائج التي تم الحصول عليها أداءً واعدًا ، مما يؤكد قوة النهج المقترح.', 'es': 'Resumen Hoy en día, la mayoría de las investigaciones realizadas en el campo de la síntesis de textos abstractivos se centran únicamente en modelos neuronales, sin considerar su combinación con enfoques basados en el conocimiento que podrían mejorar aún más su eficiencia. En esta dirección, este trabajo presenta un marco novedoso que combina la sumarización de texto basada en neuronas de secuencia a secuencia junto con metodologías basadas en la estructura y la semántica. El marco propuesto es capaz de abordar el problema de las palabras raras o fuera de vocabulario, mejorando el rendimiento de los modelos de aprendizaje profundo. La metodología general se basa en un modelo teórico bien definido de generalización de contenido basada en el conocimiento y predicciones de aprendizaje profundo para generar resúmenes abstractivos. El marco se compone de tres elementos clave: (i) una tarea de preprocesamiento, (ii) una metodología de aprendizaje automático y (iii) una tarea de posprocesamiento. La tarea de preprocesamiento es un enfoque basado en el conocimiento, basado en recursos de conocimiento ontológico, desambiguación del sentido de las palabras y reconocimiento de entidades nombradas, junto con la generalización de contenido, que transforma el texto ordinario en una forma generalizada. Un modelo de aprendizaje profundo de arquitectura de codificador-decodificador atento, que se amplía para permitir un mecanismo de afrontamiento y cobertura, así como arquitecturas basadas en transformadores y aprendizaje de refuerzo, se entrena en una versión generalizada de pares de resumen de texto, aprendiendo a predecir resúmenes de forma generalizada. La tarea de posprocesamiento utiliza el conocimiento\nrecursos, incrustaciones de palabras, desambiguación del sentido de las palabras y algoritmos heurísticos basados en métodos de similitud de texto para transformar la versión generalizada de un resumen predicho en una forma final legible por humanos. Un extenso procedimiento experimental en tres conjuntos de datos populares evalúa los aspectos clave del marco propuesto, mientras que los resultados obtenidos muestran un rendimiento prometedor, lo que valida la solidez del enfoque propuesto.', 'fr': "Résumé De nos jours, la plupart des recherches menées dans le domaine de la synthèse de textes abstraits se concentrent uniquement sur les modèles neuronaux, sans tenir compte de leur combinaison avec des approches fondées sur la connaissance qui pourraient améliorer encore leur efficacité. Dans cette direction, ce travail présente un nouveau cadre qui combine la synthèse de textes neuronaux séquence-à-séquence avec des méthodologies basées sur la structure et la sémantique. Le cadre proposé est capable de traiter le problème du hors vocabulaire ou des mots rares, améliorant ainsi les performances des modèles d'apprentissage profond. La méthodologie globale est basée sur un modèle théorique bien défini de généralisation de contenu basé sur les connaissances et de prédictions d'apprentissage profond pour générer des résumés abstraits. Le cadre est composé de trois éléments clés\xa0: (i) une tâche de pré-traitement, (ii) une méthodologie d'apprentissage automatique et (iii) une tâche de post-traitement. La tâche de prétraitement est une approche basée sur les connaissances, basée sur des ressources de connaissances ontologiques, la désambiguïsation du sens des mots et la reconnaissance d'entités nommées, ainsi que la généralisation du contenu, qui transforme le texte ordinaire en une forme généralisée. Un modèle d'apprentissage profond d'architecture codeur-décodeur attentif, qui est étendu pour permettre un mécanisme d'adaptation et de couverture, ainsi que des architectures d'apprentissage par renforcement et basées sur des transformateurs, est entraîné sur une version généralisée de paires texte-résumé, apprenant à prédire des résumés sous une forme généralisée. La tâche de post-traitement utilise les connaissances\nressources, intégrations de mots, désambiguïsation des sens des mots et algorithmes heuristiques basés sur des méthodes de similarité de texte afin de transformer la version généralisée d'un résumé prédit en une forme finale lisible par l'homme. Une procédure expérimentale approfondie sur trois ensembles de données populaires évalue les aspects clés du cadre proposé, tandis que les résultats obtenus présentent des performances prometteuses, validant la robustesse de l'approche proposée.", 'zh': '摘要今于抽象摘要领域者多究其神经形,而不虑其合进一步提高效率可知也。 于是建一新框架,框架合神经文本摘要及构语义之法。 所建框架能处词汇量不足罕见之单词,以崇深学模范之性。 体法基于知识泛化深学明义,以成抽象摘要。 其框架三要:(i)预处理任,(ii)机器学术,及(iii)后处理务。 预处理务者,知识之术也,本体论知识之资,词义消歧义名实识泛化,转为广义之文。 细心编码器-解码器架构之深,学以广之,应对覆盖,及化学基于转换器架构,练之以文本摘要练之以广义,习之以广义占摘要。 后处理任以知\n资源、词销、词义消歧义与文本相似性法之启发式算法,以转占摘要广义版本为人可读之终文。 三行数集上博实验程评所发框架要,而得所望,验其所鲁棒性。', 'pt': 'Resumo Atualmente, a maioria das pesquisas realizadas na área de sumarização de texto abstrativa concentra-se apenas em modelos baseados em neurônios, sem considerar sua combinação com abordagens baseadas em conhecimento que poderiam aumentar ainda mais sua eficiência. Nessa direção, este trabalho apresenta um novo framework que combina sumarização de texto baseado em neurais sequência-a-sequência juntamente com metodologias baseadas em estrutura e semântica. O framework proposto é capaz de lidar com o problema de falta de vocabulário ou palavras raras, melhorando o desempenho dos modelos de deep learning. A metodologia geral é baseada em um modelo teórico bem definido de generalização de conteúdo baseado em conhecimento e previsões de aprendizado profundo para gerar resumos abstratos. A estrutura é composta por três elementos principais: (i) uma tarefa de pré-processamento, (ii) uma metodologia de aprendizado de máquina e (iii) uma tarefa de pós-processamento. A tarefa de pré-processamento é uma abordagem baseada em conhecimento, baseada em recursos de conhecimento ontológico, desambiguação de sentido de palavra e reconhecimento de entidade nomeada, juntamente com generalização de conteúdo, que transforma o texto comum em uma forma generalizada. Um modelo de aprendizado profundo de arquitetura de codificador-decodificador atento, que é expandido para permitir um mecanismo de enfrentamento e cobertura, bem como aprendizado de reforço e arquiteturas baseadas em transformador, é treinado em uma versão generalizada de pares de resumo de texto, aprendendo a prever resumos em uma forma generalizada. A tarefa de pós-processamento utiliza o conhecimento\nrecursos, incorporação de palavras, desambiguação de sentido de palavra e algoritmos heurísticos baseados em métodos de similaridade de texto para transformar a versão generalizada de um resumo previsto em uma forma final legível por humanos. Um extenso procedimento experimental em três conjuntos de dados populares avalia aspectos-chave do framework proposto, enquanto os resultados obtidos apresentam desempenho promissor, validando a robustez da abordagem proposta.', 'hi': 'सार आजकल, अमूर्त पाठ सारांशीकरण के क्षेत्र में किए गए अधिकांश शोध अकेले तंत्रिका-आधारित मॉडल पर केंद्रित हैं, ज्ञान-आधारित दृष्टिकोणों के साथ उनके संयोजन पर विचार किए बिना जो उनकी दक्षता को और बढ़ा सकते हैं। इस दिशा में, यह काम एक उपन्यास रूपरेखा प्रस्तुत करता है जो संरचना और शब्दार्थ-आधारित तरीकों के साथ अनुक्रम-से-अनुक्रम तंत्रिका-आधारित पाठ सारांशीकरण को जोड़ता है। प्रस्तावित ढांचा आउट-ऑफ-शब्दावली या दुर्लभ शब्दों की समस्या से निपटने में सक्षम है, जिससे गहरे सीखने के मॉडल के प्रदर्शन में सुधार होता है। समग्र पद्धति अमूर्त सारांश उत्पन्न करने के लिए ज्ञान-आधारित सामग्री सामान्यीकरण और गहरी सीखने की भविष्यवाणियों के एक अच्छी तरह से परिभाषित सैद्धांतिक मॉडल पर आधारित है। फ्रेमवर्क तीन प्रमुख तत्वों से बना है: (i) एक पूर्व-प्रसंस्करण कार्य, (ii) एक मशीन सीखने की पद्धति, और (iii) एक पोस्ट-प्रोसेसिंग कार्य। प्री-प्रोसेसिंग कार्य एक ज्ञान-आधारित दृष्टिकोण है, जो ontological ज्ञान संसाधनों, शब्द भावना disambiguation, और नामित इकाई मान्यता पर आधारित है, सामग्री सामान्यीकरण के साथ, जो सामान्य पाठ को एक सामान्यीकृत रूप में परिवर्तित करता है। चौकस एनकोडर-डिकोडर आर्किटेक्चर का एक गहरा सीखने का मॉडल, जिसे एक मुकाबला और कवरेज तंत्र, साथ ही सुदृढीकरण सीखने और ट्रांसफॉर्मर-आधारित आर्किटेक्चर को सक्षम करने के लिए विस्तारित किया जाता है, पाठ-सारांश जोड़े के एक सामान्यीकृत संस्करण पर प्रशिक्षित किया जाता है, जो एक सामान्यीकृत रूप में सारांश की भविष्यवाणी करना सीखता है। पोस्ट-प्रोसेसिंग कार्य ज्ञान का उपयोग करता है\nसंसाधनों, शब्द एम्बेडिंग, शब्द भावना disambiguation, और heuristic एल्गोरिदम पाठ समानता विधियों पर आधारित क्रम में एक अंतिम, मानव पठनीय रूप के लिए एक अनुमानित सारांश के सामान्यीकृत संस्करण को बदलने के लिए। तीन लोकप्रिय डेटा सेटों पर एक व्यापक प्रयोगात्मक प्रक्रिया प्रस्तावित ढांचे के प्रमुख पहलुओं का मूल्यांकन करती है, जबकि प्राप्त परिणाम प्रस्तावित दृष्टिकोण की मजबूती को मान्य करते हुए आशाजनक प्रदर्शन प्रदर्शित करते हैं।', 'ja': '今日、抽象的なテキスト要約の分野で行われているほとんどの研究は、ニューラルベースのモデルだけに焦点を当てており、それらと効率をさらに向上させることができる知識ベースのアプローチとの組み合わせを考慮することはありません。 この方向性では、この研究は、構造と意味ベースの方法論とともに、シーケンス間ニューラルベースのテキスト要約を組み合わせた斬新なフレームワークを提示する。 提案されたフレームワークは、語彙外または希少な単語の問題に対処し、ディープラーニングモデルのパフォーマンスを向上させることができる。 全体的な方法論は、抽象的な要約を生成するための知識ベースのコンテンツの一般化と深層学習予測の十分に定義された理論モデルに基づいている。 フレームワークは、（ ｉ ）前処理タスク、（ ｉ ｉ ）機械学習方法論、及び（ ｉｉｉ ）後処理タスクの３つの主要な要素から構成される。 前処理タスクは、オントロジー知識リソース、単語センスの曖昧さ解消、およびコンテンツの一般化とともに、通常のテキストを一般化された形式に変換する名前付きエンティティ認識に基づく知識ベースのアプローチである。 注意深いエンコーダデコーダアーキテクチャのディープラーニングモデルは、対応とカバレッジのメカニズム、ならびに強化学習とトランスベースのアーキテクチャを可能にするように拡張され、テキストサマリーペアの一般化されたバージョンで訓練され、一般化された形式で要約を予測することを学習します。後処理タスクは、知識を利用します\nリソース、ワード埋め込み、ワードセンスの曖昧さ解消、およびテキスト類似性メソッドに基づくヒューリスティックアルゴリズムを使用して、予測された要約の一般化されたバージョンを最終的な人間が読み取り可能な形式に変換します。3つの人気のあるデータセットに関する広範な実験手順は、提案されたフレームワークの主要な側面を評価し、取得された結果は有望なパフォーマンスを示し、提案されたアプローチの堅牢性を検証する。', 'ru': 'В настоящее время большинство исследований, проводимых в области абстрактного обобщения текста, фокусируется только на нейронных моделях, не рассматривая их сочетание с наукоемкими подходами, которые могли бы еще больше повысить их эффективность. В этом направлении данная работа представляет собой новую структуру, которая сочетает в себе последовательность за последовательностью нейронное обобщение текста наряду со структурой и семантическими методологиями. Предлагаемая система способна решить проблему внесловных или редких слов, повышая эффективность моделей глубокого обучения. Общая методология основана на четко определенной теоретической модели обобщения контента на основе знаний и прогнозов глубокого обучения для генерирования абстрактных сводок. Эта система состоит из трех ключевых элементов: i) задачи предварительной обработки, ii) методологии машинного обучения и iii) задачи последующей обработки. Задача предварительной обработки - это основанный на знаниях подход, основанный на онтологических ресурсах знаний, дезагрегировании смысла слова и распознавании именованных сущностей, наряду с обобщением содержания, который преобразует обычный текст в обобщенную форму. Модель глубокого обучения внимательной архитектуры кодер-декодер, которая расширяется, чтобы обеспечить механизм совмещения и охвата, а также обучение подкреплению и архитектуры на основе трансформаторов, обучается на обобщенной версии пар текст-суммирование, обучаясь предсказывать сводки в обобщенной форме. Задача постобработки использует знания\nресурсы, вложения слов, дезагрегирование смысла слов и эвристические алгоритмы, основанные на методах текстового сходства, чтобы преобразовать обобщенную версию прогнозируемого резюме в окончательную, читаемую человеком форму. Обширная экспериментальная процедура по трем популярным наборам данных оценивает ключевые аспекты предлагаемой основы, а полученные результаты демонстрируют многообещающие результаты, подтверждая надежность предлагаемого подхода.', 'ga': "Abstract Sa lá atá inniu ann, díríonn an chuid is mó den taighde a dhéantar i réimse an achoimrithe téacs teibí ar mhúnlaí néarbhunaithe amháin, gan smaoineamh ar a dteaglaim le cineálacha cur chuige eolas-bhunaithe a d'fhéadfadh a n-éifeachtúlacht a fheabhsú tuilleadh. Sa treo seo, cuireann an saothar seo creat nua i láthair a chomhcheanglaíonn achoimriú téacs néarbhunaithe ó sheicheamh go seicheamh agus le modheolaíochtaí struchtúrtha agus shéimeantacha. Tá an creat atá beartaithe in ann déileáil le fadhb na bhfoclóra as-focal nó na bhfocal neamhchoitianta, ag feabhsú feidhmíocht na múnlaí domhainfhoghlama. Tá an mhodheolaíocht fhoriomlán bunaithe ar mhúnla teoiriciúil dea-shainithe maidir le ginearálú ábhair eolas-bhunaithe agus tuar domhainfhoghlama chun achoimrí teibí a ghiniúint. Tá trí phríomhghné sa chreat: (i) tasc réamhphróiseála, (ii) modheolaíocht mheaisínfhoghlama, agus (iii) tasc iar-phróiseála. Is cur chuige eolasbhunaithe é an tasc réamhphróiseála, bunaithe ar acmhainní eolais ontological, dí-athbhrí ar chiall na bhfocal, agus ar aithint aonáin ainmnithe, mar aon le ginearálú ábhair, a athraíonn gnáth-théacs ina fhoirm ghinearálaithe. Déantar samhail foghlama domhain d’ailtireacht ionchódóra-díchódóra aireach, a leathnaítear chun meicníocht dhéileála agus chumhdaigh a chumasú, chomh maith le foghlaim athneartaithe agus ailtireachtaí bunaithe ar chlaochladán, a oiliúint ar leagan ginearálaithe de phéirí téacs-achoimre, ag foghlaim conas achoimrí a thuar i. foirm ghinearálaithe. Úsáideann an tasc iar-phróiseála eolas\nacmhainní, neadú focal, dí-athbhrí ar chiall na bhfocal, agus algartaim heorastúla bunaithe ar mhodhanna cosúlachta téacs chun an leagan ginearálaithe den achoimre réamh-mheasta a athrú go foirm dheiridh, inléite ag an duine. Déanann nós imeachta turgnamhach fairsing ar thrí thacar sonraí móréilimh meastóireacht ar phríomhghnéithe an chreata atá beartaithe, agus léiríonn na torthaí a fuarthas feidhmíocht mhaith, ag bailíochtú stóinseacht an chur chuige atá beartaithe.", 'it': "Oggi, la maggior parte delle ricerche condotte nel campo della sintesi astratta del testo si concentra solo su modelli basati su neurali, senza considerare la loro combinazione con approcci basati sulla conoscenza che potrebbero migliorare ulteriormente la loro efficienza. In questa direzione, questo lavoro presenta un nuovo framework che combina la sintesi del testo neurale sequenziale-sequenziale insieme a strutture e metodologie semantiche-based. Il quadro proposto è in grado di affrontare il problema dell'out-of-vocabulary o delle parole rare, migliorando le prestazioni dei modelli di deep learning. La metodologia complessiva si basa su un modello teorico ben definito di generalizzazione dei contenuti basati sulla conoscenza e previsioni di deep learning per generare riassunti astratti. Il quadro è composto da tre elementi chiave: (i) un compito di pre-elaborazione, (ii) una metodologia di apprendimento automatico e (iii) un compito di post-elaborazione. Il compito di pre-elaborazione è un approccio basato sulla conoscenza, basato sulle risorse di conoscenza ontologica, sulla disambiguazione del senso delle parole e sul riconoscimento delle entità denominate, insieme alla generalizzazione dei contenuti, che trasforma il testo ordinario in una forma generalizzata. Un modello di deep learning di attenta architettura encoder-decoder, che è ampliato per consentire un meccanismo di coping e copertura, così come l'apprendimento di rinforzo e architetture basate su trasformatori, è formato su una versione generalizzata di coppie testo-riepilogo, imparando a prevedere i riassunti in forma generalizzata. Il compito di post-elaborazione utilizza conoscenze\nRisorse, incorporazioni di parole, disambiguazione del senso delle parole e algoritmi euristici basati su metodi di somiglianza del testo al fine di trasformare la versione generalizzata di un riassunto previsto in una forma finale, leggibile dall'uomo. Un'ampia procedura sperimentale su tre set di dati popolari valuta gli aspetti chiave del framework proposto, mentre i risultati ottenuti mostrano prestazioni promettenti, convalidando la robustezza dell'approccio proposto.", 'ka': 'აბსტრაქტიკური დღეში, ბევრად აბსტრაქტიური ტექსტის კუნძრაციაციის პანელში გავაკეთებულია მხოლოდ ნეიროლური მოდელზე, რომლებიც უფრო მეტად შეიძლება იმ ეფექტიკურობას გააკეთებო ამ მხარეს, ეს სამუშაო ახალგაზრდება პრომენტიკური ფრამეტრი, რომელიც კომბიუნციაცია ნეიროლური დაბათი ტექსტის კომბიზაცია სტრუქტურა და სმენტიკური მეტოლო პროგრამეტრები შეუძლებელია გარეშე სიტყვებლის ან რეტალური სიტყვების პრობლემების შესახებ, გარეშე ძალიან ძალიან სწავლის მოდელების შესახებ. ყველა მეტოლოგია ძალიან განსაზღვრებულია ცნობიერების გენერალზაციის შესახებ და ძალიან სწავლების განსაზღვრებების განსაზღვრებისთვის თეორეტიკური მოდელზე. პარამეტრის შექმნა სამი გასაღების ელემენტებით: i) პროცესირების დავალება, ii) მაქინის სწავლების მეტოლოგია და iii) პროცესირების დავალება. ოპვეპროცესი დავალება არის ცნობიერების მიზეზი, რომელიც კონტოლოგიური ცნობიერების რესურსებზე, სიტყვის განსხვავება, და სახელი ინტერტის განაცნობა, რომელიც განსხვავებული ინტერტის გენერალიზაციათან მნიშვნელოვანი სწავლების მოდელი, რომელიც გაფართებულია კოდირების და კოდირების მექანიზმის შესაძლებლობად, და სწავლების და ტრანფორმების განმავლობაზე აღმოჩენა ტექსტური კოდირების გერძალური ვერტიქტიფიკაში, რომელიც სწავლობულია, რომელიც სწ პროცესის შემდეგ დავალება უცნობის გამოყენება\nრესურსები, სიტყვების შებრუნება, სიტყვების სიტყვების განსხვავება, და ჰეურისტიური ალგორიტიმები ტექსტის სხვადასხვა მეტოვების დაბაზეული ტექსტის სხვადასხვა მეტოვების განსხვავება, რომ გადაწყვეტილი სი სამი პოლუბური მონაცემების კონფიგური პროცემები განსაზღვრებას გასაკეთება საკუთარ პოლუბური მონაცემების გასაკეთებელი აპექტები, მაგრამ მიღებული შედეგი გამოიყენება გვ', 'hu': 'Absztrakt Napjainkban az absztraktív szövegösszefoglalás területén végzett kutatások többsége önmagában a neurális modellekre összpontosít, anélkül, hogy figyelembe vennék azokat a tudásalapú megközelítésekkel való kombinációjukat, amelyek tovább növelhetik hatékonyságukat. Ebben az irányban a munka olyan új keretrendszert mutat be, amely ötvözi a szekvencia-szekvencia neurális szövegösszefoglalást a szerkezet és a szemantikai módszerek mellett. A javasolt keret képes kezelni a szókincsen kívüli vagy ritka szavak problémáját, javítva a mélytanulási modellek teljesítményét. Az általános módszertan a tudásalapú tartalom általánosításának jól meghatározott elméleti modelljén és az absztraktív összefoglalók készítésére szolgáló mélytanulási előrejelzéseken alapul. A keretrendszer három kulcsfontosságú elemből áll: (i) előfeldolgozási feladat, (ii) gépi tanulási módszertan és (iii) utófeldolgozási feladat. Az előfeldolgozási feladat egy olyan tudásalapú megközelítés, amely ontológiai tudás erőforrásokon, szóérzékek egyértelműsítésén és nevezett entitás felismerésén alapul, valamint a tartalom általánosításán alapul, amely a hétköznapi szöveget általánosított formává alakítja. A figyelmes kódoló-dekóder architektúra mélytanulási modelljét, amely kiterjesztett, hogy lehetővé tegye a leküzdési és lefedettségi mechanizmust, valamint a megerősítő tanulás és transzformátor alapú architektúrák, a szöveg-összefoglaló párok általános verziójára képezik, megtanulva az összefoglalókat általános formában megjósolni. Az utófeldolgozási feladat ismereteket használ fel\nAz előrejelzett összefoglaló általánosított változatát végleges, emberi olvasható formává alakítják. Három népszerű adatkészleten végzett kiterjedt kísérleti eljárás értékeli a javasolt keretrendszer kulcsfontosságú aspektusait, míg az elért eredmények ígéretes teljesítményt mutatnak, igazolva a javasolt megközelítés robusztusságát.', 'el': 'Σήμερα, η περισσότερη έρευνα που διεξάγεται στον τομέα της αφηρημένης σύνοψης κειμένου επικεντρώνεται μόνο σε νευρωνικά μοντέλα, χωρίς να εξετάζεται ο συνδυασμός τους με προσεγγίσεις βασισμένες στη γνώση που θα μπορούσαν να βελτιώσουν περαιτέρω την αποτελεσματικότητά τους. Προς αυτή την κατεύθυνση, η παρούσα εργασία παρουσιάζει ένα νέο πλαίσιο που συνδυάζει την αλληλουχία-σε-αλληλουχία σύνοψη κειμένου με βάση τη δομή και τις σημασιολογικές μεθοδολογίες. Το προτεινόμενο πλαίσιο είναι ικανό να αντιμετωπίσει το πρόβλημα των μη λεξιλογίων ή σπάνιων λέξεων, βελτιώνοντας την απόδοση των μοντέλων βαθιάς μάθησης. Η συνολική μεθοδολογία βασίζεται σε ένα καλά καθορισμένο θεωρητικό μοντέλο γενικοποίησης περιεχομένου βασισμένου στη γνώση και προβλέψεων βαθιάς μάθησης για τη δημιουργία αφηρημένων περιλήψεων. Το πλαίσιο αποτελείται από τρία βασικά στοιχεία: (i) μια εργασία προεπεξεργασίας, (ii) μια μεθοδολογία μηχανικής μάθησης και (iii) μια εργασία μετεπεξεργασίας. Η εργασία προεπεξεργασίας είναι μια προσέγγιση βασισμένη στη γνώση, βασισμένη σε οντολογικούς πόρους γνώσης, αποσαφήνιση λέξεων και αναγνώριση ονομαστικών οντοτήτων, μαζί με τη γενίκευση περιεχομένου, που μετατρέπει το συνηθισμένο κείμενο σε μια γενικευμένη μορφή. Ένα μοντέλο βαθιάς μάθησης με προσεκτική αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή, το οποίο επεκτείνεται για να επιτρέψει έναν μηχανισμό αντιμετώπισης και κάλυψης, καθώς και ενισχυτική μάθηση και αρχιτεκτονικές βασισμένες σε μετασχηματιστές, εκπαιδεύεται σε μια γενικευμένη έκδοση ζευγαριών κειμένου-σύνοψης, μαθαίνοντας να προβλέπουν περιλήψεις σε μια γενικευμένη μορφή. Η εργασία μετεπεξεργασίας χρησιμοποιεί γνώση\nπόρους, ενσωμάτωση λέξεων, αποσαφήνιση λέξεων και heuristικοί αλγόριθμοι βασισμένοι σε μεθόδους ομοιότητας κειμένου προκειμένου να μετατραπεί η γενικευμένη έκδοση μιας προβλεπόμενης περίληψης σε μια τελική, αναγνώσιμη από τον άνθρωπο μορφή. Μια εκτεταμένη πειραματική διαδικασία σε τρία δημοφιλή σύνολα δεδομένων αξιολογεί βασικές πτυχές του προτεινόμενου πλαισίου, ενώ τα αποτελέσματα που προκύπτουν παρουσιάζουν ελπιδοφόρα απόδοση, επικυρώνοντας την ανθεκτικότητα της προτεινόμενης προσέγγισης.', 'kk': 'Қазіргі абстракты, абстрактивті мәтін тұжырымдамасындағы зерттеулердің көпшілігі невралдық негізделген моделдеріне жалғыз көмектеседі, білім негізделген тұжырымдамасымен біріктіріп, олардың ефективті Осы бағытта, бұл жұмыс құрылғы мен семантикалық методологияларды бірге реттеу мен реттеу негіздеген мәтінді жинақтау ретінде жазылады. Келтірілген қоршауы сөздердің немесе сөздердің тығыс мәселелерін өзгертуге болады, терең оқыту үлгілерін жақсартуға болады. Барлық методология білім негіздеген мазмұның жалпы теоретикалық моделіне негізделген және абстрактивтік тұжырымдамасын құру үшін түсінікті оқыту үшін түсінікті түсінікті. Бұл қоршауы үш кілт элементінен құрылады: i) алдын- ала өңдеу тапсырмасы, ii) машиналық оқыту методологиясы және iii) өңдеу тапсырмасы. Алдын- ала өңдеу тапсырмасы - онтологиялық білім ресурстарына негізделген білім негізделген тәсілдік, сөздердің сезімі бұғаттауына негізделген, мәтінді жалпы пішімге аударады. Ақырымды кодер- декодер архитектурасының түсінікті оқыту үлгісі. Бұл көшірмелеу мен мәтін- тұжырымдамасының механизмін рұқсат ету үшін, оқыту мен түрлендіру архитектурасының жалпы нұсқасында, жалпы түрлендіру үшін оқыту үшін көтері Орындау кейін тапсырмасы білімдерді қолдану\nресурстар, сөздерді ендіру, сөздердің сезімін өзгерту және мәтін ұқсас тәсілдеріне негізделген хиуристік алгоритмдері, мәтін ұқсас тәсілдерінің жалпы нұсқасын соңғы, адамды оқу мүмкіндігіне Үш мәліметтік деректер бағдарламасындағы эксперименталдық процедурасы ұсынылған қоршау бағдарламасының негізгі аспекттерін бағалады. Алған нәтижелері ұсынылған әрекеттерді көрсетеді, ұсынылған тәсілдің құндыл', 'lt': 'Abstract Today, most research conducted in the field of abstract text summary focuses on neural-based models alone, not considering their combination with knowledge-based approaches that could further enhance their efficiency. Šiuo požiūriu šiame darbe pateikiama nauja sistema, kuria sujungiama iš eilės į eilę pagrįsta teksto santrauka su struktūra ir semantine metodika. Siūloma sistema gali spręsti ne žodyno ar retų žodžių problem ą ir pagerinti gilaus mokymosi modelių veiksmingumą. Bendroji metodika grindžiama gerai apibrėžtu teoriniu turinio generalizacijos, pagrįstos žiniomis, modeliu ir išsamaus mokymosi prognozėmis, kad būtų galima parengti abstraktines santraukas. Ši ą sistemą sudaro trys pagrindiniai elementai: i) išankstinio apdorojimo užduotis, ii) mašininio mokymosi metodika ir iii) išankstinio apdorojimo užduotis. Išankstinio apdorojimo užduotis – žiniomis pagrįstas metodas, grindžiamas ontologiniais žinių ištekliais, žodžių supratimo nesuderinimu ir pavadinimu subjekto pripažinimu kartu su turinio generalizacija, kuris paprastąjį tekstą paverčia bendra form a. Atidžiaus kodavimo ir dekoderių architektūros mokymosi model is, kuris išplėstas siekiant sudaryti galimybę įveikti ir aprėpti priemones, taip pat stiprinti mokymąsi ir transformatoriais grindžiamas architektūras, mokomas bendra teksto santraukų porų versija, mokomas prognozuoti santraukas bendra form a. Po perdirbimo atliekama užduotis naudoja žinias\ništekliai, žodžių įdėjimai, žodžių supratimo išaiškinimas ir heuristiniai algoritmai, pagrįsti teksto panašumo metodais, siekiant paversti bendrą numatomos santraukos versiją galutine, žmogui skaitoma form a. Išsami eksperimentinė trijų populiarių duomenų rinkinių procedūra vertina pagrindinius siūlomos sistemos aspektus, o gauti rezultatai rodo žadančius rezultatus ir patvirtina siūlomo metodo patikimumą.', 'ms': 'Hari ini, kebanyakan kajian yang dilakukan dalam bidang penghuraian teks abstraktif fokus pada model berdasarkan saraf sahaja, tanpa mempertimbangkan kombinasi mereka dengan pendekatan berdasarkan pengetahuan yang boleh meningkatkan efisiensi mereka lebih lanjut. Dalam arah ini, kerja ini menghasilkan kerangka baru yang menggabungkan penghuraian teks berasaskan saraf turutan ke turutan bersama dengan struktur dan metodologi berasaskan semantik. Bingkai cadangan yang direncanakan mampu menghadapi masalah luar-vocabulari atau perkataan langka, meningkatkan prestasi model belajar dalam. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries.  kerangka ini terdiri dari tiga unsur kunci: (i) tugas pra-proses, (ii) metodologi pembelajaran mesin, dan (iii) tugas pos-proses. Tugas pra-pemprosesan adalah pendekatan berdasarkan pengetahuan, berdasarkan sumber pengetahuan ontologi, penyelesaian perasaan perkataan, dan pengenalan entiti bernama, bersama dengan pengenalisan kandungan, yang mengubah teks biasa menjadi bentuk yang terkalahkan. Model pembelajaran dalam arkitektur pengekod-dekoder perhatian, yang dikembangkan untuk memungkinkan mekanisme pengendalian dan penyamaran, serta pembelajaran kuasa dan arkitektur berasaskan pengubah, dilatih pada versi umum pasangan teks-ringkasan, belajar untuk meramalkan ringkasan dalam bentuk umum. Tugas selepas pemprosesan menggunakan pengetahuan\nsumber, penyambungan perkataan, penyelesaian perasaan perkataan, dan algoritma heuristik berdasarkan kaedah persamaan teks untuk mengubah versi umum ringkasan dijangka ke bentuk terakhir yang boleh dibaca oleh manusia. Prosedur percubaan ekstensif pada tiga set data populer menilai aspek utama kerangka yang direncanakan, sementara keputusan yang diperoleh menunjukkan prestasi yang berjanji, mengesahkan kepekatan pendekatan yang direncanakan.', 'ml': 'ഇപ്പോള്\u200d അസ്ട്രാക്ട്രാക്ക് ചെയ്യുന്നതില്\u200d ഏറ്റവും പ്രധാനപ്പെട്ട പദാവലിയുടെ കാലത്ത് നിര്\u200dമ്മിക്കപ്പെട്ട നെയൂറല്\u200d അടിസ്ഥാനമായ മോഡലുകളില്\u200d മാത് ഈ വഴിയില്\u200d, ഈ പ്രവര്\u200dത്തിപ്പിക്കുന്ന ഒരു നോവല്\u200d ഫ്രെയിമാര്\u200dക്ക് കാണിക്കുന്നു. അതിന്റെ സെക്കന്\u200dസ്-മുതല്\u200d സെക്കന്\u200dസ് അടിസ്ഥാനമായ നെയുറല്\u200d  പ്രൊദ്ദേശിക്കപ്പെട്ട ഫ്രെയിമെക്ക് വാക്കുകളുടെ പ്രശ്നത്തെക്കുറിച്ച് കൈകാര്യം ചെയ്യാന്\u200d കഴിയും, ആഴത്തെ പഠിക്കുന മൊത്തം രീതിയില്\u200d നിര്\u200dണ്ണയിക്കപ്പെട്ട വിജ്ഞാനത്തിലുള്ള വസ്തുക്കളുടെ ജനറലേഷനും ആഴത്തെ പഠിപ്പിക്കുന്ന പ്രവചനങ്ങളും അടിസ്ഥാ ഫ്രെയിമെന്\u200dറ് മൂന്ന് മൂന്ന് മൂലകങ്ങളില്\u200d ഉണ്ടാക്കിയിരിക്കുന്നു: (i) മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിക്കുന്ന ജോലി, (ii) ഒരു യന്ത്ര പഠ മുമ്പ് പ്രവര്\u200dത്തിപ്പിക്കുന്ന ജ്ഞാനത്തിന്റെ അടിസ്ഥാനത്തിലായ ഒരു പരിജ്ഞാനവും വാക്കിന്റെ വിഭവങ്ങള്\u200d അടിസ്ഥാനത്തിലാണ്, വാക്കിന്റെ മനസ്സില്\u200d വി ഒരു കോപ്പിങ്ങ് ചെയ്യുന്നതിനും കറയ്ക്കുന്നതിനും പ്രാവര്\u200dത്തികമാക്കാനും ഒരു ആഴത്തില്\u200d പഠിക്കുന്ന ഒരു കോഡെര്\u200d ഡെക്കോഡേര്\u200d ആര്\u200dക്കിട്ടറിന്റെ മാതൃകയും, പഠിപ്പിക്കുന്നതിനും അടിസ്ഥാനമാക്ക The post-processing task utilizes knowledge\nവിഭവങ്ങള്\u200d, വാക്കുകള്\u200d അകത്തേക്ക് ചേര്\u200dക്കുന്നത്, വാക്കിന്റെ മനസ്സിന്റെ അസംബന്ധം, വാക്കുകളുടെ ആല്\u200dഗോരിത്രത്തിന്റെ മാര്\u200dഗങ്ങളില്\u200d അടിസ്ഥാനമാക്കിയ ആ മൂന്നു പ്രിയപ്പെട്ട ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d ഒരു വിശാലമായ പരീക്ഷണപ്രക്രിയയുണ്ട്, പ്രൊദ്ദേശിച്ച ഫ്രെയിമ്പിന്റെ താക്കോലുകള്\u200d പരിശോധി', 'mk': 'Апстрактни денови, повеќето истражувања спроведени во областа на апстрактивната резултатација на текстот се фокусираат само на модели на нервна основа, без да се разгледува нивната комбинација со пристапи на основа на знаење кои би можеле понатаму да ја зголемат нивната ефи Во оваа насока, оваа работа претставува нова рамка која ја комбинира резултатацијата на текстот базиран на нерви од секвенца до секвенца заедно со структурата и семантичките методологии. Предложената рамка е способна да се справи со проблемот на надворешниот речник или ретките зборови, подобрувајќи ја изведбата на моделите на длабоко учење. Целокупната методологија се базира на добро дефиниран теоретски модел на генерализација на содржината базирана на знаење и предвидувања за длабоко учење за генерирање апстрактивни резултати. Рамката се состои од три клучни елементи: (i) задача за преобработување, (ii) методологија за машинско учење и (iii) задача за постобработување. Препроцесорската задача е пристап базиран на знаење, базиран на онтологичките ресурси на знаење, раздвојување на зборовите чувства и препознавање на именуваните ентитети, заедно со генерализацијата на содржината, кој го трансформира обичниот текст во генерализирана форма Модел на длабоко учење на внимателна архитектура на кодер-декодер, која е проширена за да овозможи механизам за справување и покривање, како и зајакнување на учењето и архитектурите базирани на трансформатори, е обучен на генерализирана верзија на парови текст-резултат, учејќи се да предвидат резултат Оваа задача користи знаење\nресурси, вложувања на зборови, раздвојување на зборовите, и хеористички алгоритми базирани на методи на сличност на текст со цел да ја трансформираат генерализираната верзија на предвидено резултат во финална, човечки читлива форма. Експерименталната процедура на три популарни податоци ги проценува клучните аспекти на предложената рамка, додека добиените резултати покажуваат ветувачки перформанси, потврдувајќи ја силноста на предложениот пристап.', 'mt': 'Illum il-ġurnata, il-biċċa l-kbira tar-riċerka mwettqa fil-qasam tas-sommarju tat-test astrattiv tiffoka fuq mudelli bbażati fuq in-newrali waħedhom, mingħajr ma tikkunsidra l-kombinazzjoni tagħhom ma’ approċċi bbażati fuq l-għarfien li jistgħu jkomplu jtejbu l-effiċjenza tagħhom. F’din id-direzzjoni, dan ix-xogħol jippreżenta qafas ġdid li jikkombina sommarju tat-test ibbażat fuq it-testi newrali minn sekwenza għal sekwenza flimkien ma’ metodoloġiji bbażati fuq l-istruttura u s-semantika. Il-qafas propost huwa kapaċi jindirizza l-problema ta’ kliem barra mill-vokabulari jew rari, u jtejjeb il-prestazzjoni tal-mudelli ta’ tagħlim profond. Il-metodoloġija globali hija bbażata fuq mudell teoretiku definit sew ta’ ġeneralizzazzjoni tal-kontenut ibbażat fuq l-għarfien u tbassir ta’ tagħlim profond għall-ġenerazzjoni ta’ sommarji astratti. The framework is composed of three key elements: (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task.  The pre-processing task is a knowledge-based approach, based on ontological knowledge resources, word sense disambiguation, and named entity recognition, along with content generalization, that transforms ordinary text into a generalized form.  Mudell ta’ tagħlim profond ta’ arkitettura attenta ta’ kodifikatur-dekoder, li huwa estiż biex jippermetti mekkaniżmu ta’ coping u kopertura, kif ukoll tagħlim rinfurzat u arkitetturi bbażati fuq trasformaturi, huwa mħarreġ fuq verżjoni ġeneralizzata ta’ pari ta’ sommarju tat-test, li jitgħallem jipprevedi sommarji f’form a ġeneralizzata. Il-kompitu ta’ wara l-ipproċessar juża l-għarfien\nriżorsi, inkorporazzjonijiet tal-kliem, diżambiguazzjoni tas-sens tal-kliem, u algoritmi ħewristiċi bbażati fuq metodi ta’ similarità tat-test sabiex tittrasforma l-verżjoni ġeneralizzata ta’ sommarju mbassar f’form a finali, li tinqara mill-bniedem. Proċedura esperimentali estensiva fuq tliet settijiet ta’ dejta popolari tevalwa aspetti ewlenin tal-qafas propost, filwaqt li r-riżultati miksuba juru prestazzjoni promettenti, li tivvalida r-robustezza tal-approċċ propost.', 'pl': 'W dzisiejszych czasach większość badań prowadzonych w dziedzinie abstrakcyjnej streszczenia tekstu koncentruje się na modelach neuronowych, bez uwzględnienia ich połączenia z podejściami opartymi na wiedzy, które mogłyby jeszcze bardziej zwiększyć ich efektywność. W tym kierunku praca przedstawia nowe ramy łączące podsumowanie tekstu opartego na sekwencji sekwencji neuronowej wraz z metodologią struktury i semantyczną. Proponowane ramy są w stanie poradzić sobie z problemem poza słownictwem lub rzadkimi słowami, poprawiając wydajność modeli głębokiego uczenia się. Ogólna metodologia opiera się na dobrze zdefiniowanym modelu teoretycznym uogólniania treści opartych na wiedzy oraz prognozach głębokiego uczenia w celu generowania abstrakcyjnych streszczeń. Ramy składają się z trzech kluczowych elementów: (i) zadania wstępnego przetwarzania, (ii) metodologii uczenia maszynowego oraz (iii) zadania po przetwarzaniu. Zadaniem przetwarzania wstępnego jest podejście oparte na wiedzy, oparte na ontologicznych zasobach wiedzy, rozpoznawaniu sensu słowa i rozpoznawaniu nazwanych jednostek wraz z uogólnieniem treści, które przekształca zwykły tekst w uogólnioną formę. Model głębokiego uczenia uważnej architektury kodera-dekodera, który został rozbudowany w celu umożliwienia mechanizmu radzenia sobie i pokrycia, a także uczenia się wzmacniającego i architektur opartych na transformatorach, jest trenowany na uogólnionej wersji par tekstowo-podsumowujących, ucząc się przewidywać podsumowania w postaci uogólnionej. Zadanie po przetwarzaniu wykorzystuje wiedzę\nZasoby, osadzenia słów, dyscyplinacja sensu słowa oraz algorytmy heurystyczne oparte na metodach podobieństwa tekstowego w celu przekształcenia uogólnionej wersji przewidywanego podsumowania w ostateczną, czytelną dla człowieka formę. Obszerna procedura eksperymentalna na trzech popularnych zbiorach danych ocenia kluczowe aspekty proponowanego frameworku, natomiast uzyskane wyniki wykazują obiecującą skuteczność, potwierdzając solidność proponowanego podejścia.', 'ro': 'În zilele noastre, majoritatea cercetărilor efectuate în domeniul rezumatului abstractiv al textului se concentrează numai pe modele bazate pe neural, fără a lua în considerare combinația lor cu abordări bazate pe cunoaștere care ar putea spori și mai mult eficiența lor. În această direcție, această lucrare prezintă un cadru nou care combină rezumarea textului neural secvență-la-secvență împreună cu structura și metodologiile semantice. Cadrul propus este capabil să abordeze problema cuvintelor în afara vocabularului sau a cuvintelor rare, îmbunătățind performanța modelelor de învățare profundă. Metodologia generală se bazează pe un model teoretic bine definit de generalizare a conținutului bazat pe cunoaștere și predicții de învățare profundă pentru generarea rezumatelor abstractive. Cadrul este compus din trei elemente cheie: (i) o sarcină de pre-procesare, (ii) o metodologie de învățare automată și (iii) o sarcină de post-procesare. Sarcina de pre-procesare este o abordare bazată pe cunoaștere, bazată pe resurse de cunoaștere ontologică, dezambiguizarea sensului cuvântului și recunoașterea entităților denumite, împreună cu generalizarea conținutului, care transformă textul obișnuit într-o formă generalizată. Un model de învățare profundă a arhitecturii encoder-decoder atente, care este extins pentru a permite un mecanism de coping și acoperire, precum și învățare de armare și arhitecturi bazate pe transformator, este instruit pe o versiune generalizată a perechilor text-sumar, învățând să prezică rezumatele într-o formă generalizată. Sarcina de post-procesare utilizează cunoștințe\nResurse, încorporări de cuvinte, dezambiguizarea sensului cuvântului și algoritmi euristici bazați pe metode de similitudine a textului pentru a transforma versiunea generalizată a unui rezumat anticipat într-o formă finală, lizibilă de om. O procedură experimentală amplă pe trei seturi de date populare evaluează aspectele cheie ale cadrului propus, în timp ce rezultatele obținute prezintă performanțe promițătoare, validând robustețea abordării propuse.', 'so': 'Maalmahaas, wax badan oo baaritaanka la sameeyay beerta qoraalka waxyaabaha la’aanta ah ayaa ku focus ah modelalka neurada oo keliya, iyadoon ka fiirsanaynin inay ku xiriiraan qaababka aqoonta ee awoodkooda sii kordhin karo. Xaggan, shuqulkaasu wuxuu soo bandhigaa saxda, kaas oo ku soo ururiya qoraal qoraal ah oo ku qoran xilli-ilaa-xilliga neurada oo ku qoran dhismaha iyo qaababka semantika. Qoraalka la soo jeeday wuxuu awoodaa in uu ka macaamilo karo dhibaatada hadallada aan qoraalka ahayn ama hadallada gaaban, inuu horumariyo tababarka muusikada waxbarashada moolka dheer. Iskuulka dhamaanka waxaa lagu saleeyaa tusaale aad u yaqaan tioretik oo ku qoran qoraalka waxyaabaha aqoonta ku saleysan oo la soo hormariyo horumarinta waxbarashada mool dheer oo la soo saaro xiliga diidmada ah. Qoraalka waxaa lagu sameeyaa saddex element oo muhiim ah: (i) shaqo ka hor baaraandegista, (ii) qaababka waxbarashada machine, iyo (iii) shaqo ka dib baaraandegista. Shaqada horay u baaraandegista waa qaab aqoonta lagu saleeyo asalka aqoonta aqoonta, kala baaraandegista hadalka, aqoonsashada aqoonta, iyo waxyaabaha la magacaabay, kaas oo ku beddelinaya qoraalka caadiga ah oo u beddelaya foom generalis. Tusaale waxbarasho dheer oo ah dhismaha qodeynta, kaas oo loo ballaadhiyay inuu awoodo koordinta iyo daboolidda, sidoo kale in lagu kordhiyo dhismaha barashada iyo beddelinta, waxaa lagu baraa qoraal la qoray labada noocyo oo qoraal ah, taasoo lagu barto in lagu hor dhigo qoraalka lagu qoray. Shaqada ka baaraandegista ayaa isticmaalaya aqoonta\nFursadaha, qeybaha hadalka, kala soocsiga maanka, iyo qoraalka heuristiga oo ku saleysan qoraalka isku mid ah si uu ugu beddelo warqada la soo hormariyey oo ugu horrayay qoraalka ugu dambeeya oo dadka akhrisan. Shahaadada baaritaanka oo ballaadhan oo ku qoran saddexda data oo popular ah ayaa qiimeynaya dhinacyada ugu muhiimsan ee laga soo jeeday frameerka, marka laga soo helayna waxay muujiyaan muuqashada ballan ah, si loo xaqiijiyo dharka qaababka lagu soo jeedo.', 'si': 'අවස්ථාවයි, අවස්ථාවයි, බොහෝම පරීක්ෂණය කරලා තියෙන්නේ අවස්ථාවක් පැත්තක් සුම්පර්ණයේ ප්\u200dරදේශයේ සුම්පර්ණය ප්\u200dරදේශයෙන් නිර්ම මේ පැත්තේදී, මේ වැඩ ප්\u200dරදේශයක් ප්\u200dරදේශයක් තියෙනවා ක්\u200dරියාත්මක ප්\u200dරදේශයක් සම්බන්ධ කරනවා ක්\u200dරියාත්මක ප්\u200dරදේශයක් සමග සං ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් විදිහට ප්\u200dරශ්නයක් නැති වචන වචන වගේ ප්\u200dරශ්නයක් වෙන්න, ගොඩක් ඉගෙන ගන සම්පූර්ණ විද්\u200dයාවය හොඳ විශ්වාසිත විද්\u200dයාත්මක සාමාන්\u200dය සාමාන්\u200dය විද්\u200dයාපනය සහ ගොඩක් ඉගෙන ගන්න ප්\u200dරශ්නයක් නි ප්\u200dරවේශය තුනක් යතුරු අවශ්\u200dය තුනක් නිර්මාණය කරලා තියෙනවා: i) ප්\u200dරවේශනයක් ප්\u200dරවේශනයක්, (i) පරීක්ෂණයක් ප්\u200dරවේශනයක් (machine The pre-processing job is a Known-based approach, based on ontology Known Systems, word sensation disombguation, and Named Unity Known, accompanied with the contingent General lization, that transcends the standard text to a generic form. A depth learning Model of Attensive Encoder-decoder Architectura, that is breed to make a coping and Coveage mekanizer, as well as consolidation learnt and changeover-based Architecturas, is Trained on a genelized Version of text-summy pares, learnt to forecast summits in a genelized form. පස්සේ ප්\u200dරක්\u200dරියාස කරණාව දන්නවක් භාවිත කරනවා\nසම්බන්ධතාවය, වචන සම්බන්ධතාවය, වචන සම්බන්ධතාවය, හෙයුරිස්ටික ඇල්ගෝරිත්මය, පාළුවන් සම්බන්ධතාවය විදියට ආධාරිත විදියට පරික ප්\u200dරශ්නයක් පරීක්ෂණයක් තුනක් ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්න', 'sv': 'Abstract Nuförtiden fokuserar den mesta forskningen inom området abstraktiv textsammanfattning enbart på neuralbaserade modeller, utan att överväga deras kombination med kunskapsbaserade tillvägagångssätt som ytterligare skulle kunna förbättra deras effektivitet. I den riktningen presenterar detta arbete ett nytt ramverk som kombinerar sekvens-till-sekvens neuralbaserad textsammanfattning tillsammans med struktur och semantiska metoder. Den föreslagna ramen kan hantera problemet med outvokabulära eller sällsynta ord, vilket förbättrar djupinlärningsmodellernas prestanda. Den övergripande metoden bygger på en väl definierad teoretisk modell av kunskapsbaserad innehållsgeneralisering och djupinlärningsförutsägelser för att generera abstrakta sammanfattningar. Ramverket består av tre nyckelelement: i) en förbehandling, ii) en maskininlärningsmetod och iii) en efterbehandling. Förbehandlingsuppgiften är ett kunskapsbaserat tillvägagångssätt, baserat på ontologiska kunskapsresurser, ordsinnesdeklaration och namngiven entitetsigenkänning, tillsammans med innehållsgeneralisering, som omvandlar vanlig text till en generaliserad form. En djupinlärningsmodell av uppmärksam encoder-avkodararkitektur, som utökas för att möjliggöra en coping- och täckningsmekanism, samt förstärkningsinlärning och transformatorbaserade arkitekturer, utbildas på en generaliserad version av text-sammanfattning par, lära sig att förutsäga sammanfattningar i en generaliserad form. Efterbehandlingsuppgiften utnyttjar kunskap\nFör att omvandla den generella versionen av en förutsagd sammanfattning till en slutlig, mänsklig läsbar form. Ett omfattande experimentförfarande på tre populära datauppsättningar utvärderar centrala aspekter av det föreslagna ramverket, medan de erhållna resultaten uppvisar lovande prestanda, vilket bekräftar robustheten i det föreslagna tillvägagångssättet.', 'mn': 'Харин одоогийн абстракт, ихэнх судалгаа abstractive text жинхэнэ хэмжээсүүд нь мэдлэг суурилсан арга барилгуудтай холбоотой, тэдний үр дүнг нэмэгдүүлж чадна. Энэ хэсэгт, энэ ажил дарааллаар дарааллаар дарааллаар дарааллаар дарааллаар суурилсан мэдрэлийн хэмжээсүүдийг бүтэц болон семантик суурилсан методологийг нэгтгэдэг шинэ хэлбэрийг харуулдаг. Шинэ санал болгон суралцах загварын үйл ажиллагааг сайжруулах боломжтой. Ихэнх методологи нь мэдлэг дээр суурилсан материалуудын ерөнхийлөгч, гүн гүнзгий суралцах тодорхойлолтуудын теоретик загвар дээр суурилсан. Фреймер нь гурван түлхүүр элементүүдийн бүтэц: i) урд үйлдвэрлэлтийн ажил, ii) машин суралцах методологи, iii) дараа үйлдвэрлэлтийн ажил. Өмнөх үйл ажиллагаа нь мэдлэг дээр суурилсан арга юм. Онтологийн мэдлэг боловсролын баялаг, үг мэдрэмжтэй байдал, нэрлэгдсэн бүтээлүүдийн хүлээн зөвшөөрөл, бүтээлүүдийн ерөнхийлөгч байдалтай хамт энгийн текст ерөнхийлөгч хэлбэр Харин сонирхолтой коддогч архитектурын гүн гүнзгий суралцах загвар, хуваалцах механизм болон суралцах, өөрчлөгч суралцах, өөрчлөгч суралцах архитектуруудын ерөнхийлөгчийн хувилбар дээр суралцагдаж байна. Дараагийн үйл ажиллагаа мэдлэг ашиглан\nБайгаль, үг нэвтрүүлэх, үг мэдрэмжгүй байдал, хэлбэрийн алгоритм, мөн хэлбэрийн тэнцүү арга дээр суурилсан хэлбэрүүдийг төгсгөл, хүний унших боломжтой хэлбэртэй хувилбарыг өөрчлөхийн тулд. Гурван хүн төрөлхтний мэдээллийн багц дээрх шинэ туршилтын процедур санал өгсөн хэлбэрийн чухал асуудлыг үнэлдэг. Гэхдээ олсон үр дүн нь амлалтай үйл ажиллагааг харуулж, санал өгсөн арга барилгын чадварыг ба', 'ta': 'இந்த நேரத்தில் செயல்படுத்தப்பட்ட புலத்தில் பெரும்பாலான ஆராய்ச்சி சுருக்கம் செய்யப்பட்டது, புதிய மாதிரிகளை மட்டுமே கவனம் செலுத்துகிறது, அறிவு அடிப்பட In this direction, this work presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies.  பரிந்துரைக்கப்பட்ட சட்டத்தில் சொல்லத்திலிருந்து அல்லது சிறிய வார்த்தைகளின் பிரச்சினையைக் கொண்டு பாதிக்க முடியும்,  மொத்த முறைமையில் அறிவிப்பு அடிப்படையில் உள்ளடக்கங்களை உருவாக்குதல் மற்றும் ஆழமான கற்றுக்கொள்ள முன்னோட்டங்களை உருவாக்குவதற்கான சட்டத்தின் மூன்று முக்கிய உறுப்புகளில் உருவாக்கப்பட்டுள்ளது: (i) முன் செயல்படுத்தும் செயல் முன் செயல்படுத்தல் செயல் ஒரு அறிவு அடிப்படையான செயல்பாடு, அடிப்படையிலான நொடியல் அறிவு மூலம், வார்த்தை உணர்வு பிரிவு, பெயரிடப்பட்ட பொருள் குறிப்பிடு, ப A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form.  பின்செயல்படுத்தல் செயல் அறிவை பயன்படுத்துகிறது\nமூலங்கள், வார்த்தை பொருத்துதல், வார்த்தை உணர்வு பிரிவுகள் மற்றும் உரை ஒத்த முறைகளை அடிப்படையில் மாற்றுவதற்கு, முன்னோக்கப்பட்ட சுருக்கம், மனித படிக்க ம மூன்று பெரிய தகவல் அமைப்புகளில் ஒரு விரிவான சோதனை செயல்பாடு முன்நிர்ணயிக்கப்பட்ட சட்டத்தின் முக்கிய விளைவுகளை மதிப்பிடுகிறது, பெற்றுள்', 'ur': 'اکثر تحقیقات جو آب تراکیٹی ٹیکسٹ کے مکان میں کیا گیا ہے صرف نئورل بنیادی موڈل پر تمرکز کرتی ہے، بغیر علم بنیادی طریقوں کے ساتھ ان کی ترکیب کی توقع کرتی ہے جو ان کے کامیابی میں اضافہ کرسکتی ہے. اس طریقے میں، یہ کام ایک نئی فرم پیش کرتا ہے جو سطح سے اورال بنیاد رکھے ہوئے پیغام کی تعریف کے ساتھ اور سیمانٹی بنیاد رکھے ہوئے مڈولوژوں کے ساتھ جمع کرتا ہے. پیشنهاد کی فرمود بات یا نادر کلمات کے مسئلہ سے بحث کرنے کے قابل ہے، اور عمیق سیکھنے کی مدل کی عمدت کو بہتر کر سکتا ہے. یہ سب طریقے معلوم ہوتے ہیں کہ علم کی بنیاد رکھی ہوئی منصوبات کی عمومی تعلیم اور عمیق تعلیم کی پیش بینی کی وجہ سے بہتر تعریف کی نظریات کی مدل پر ہے۔ چوکاٹ تین کلی عناصر سے پیدا کیا گیا ہے: i) ایک پیش پردازی کا کام، ii) ایک ماشین سیکھنے کا مطالعہ، اور iii) ایک پوسٹ پردازی کا کام۔ پیش پردازی کا کام ایک علم کی بنیادی طریقہ ہے، اس طریقہ پر متولوژیکی علم کے منبع پر بنیاد ہے، کلمات کا احساس غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر ایک عمدہ سیکھنے کی موڈل ہے جو متوجہ Encoder-Decoder معماری ہے، جو ایک کاپینگ اور کاوٹ مکانیزم کو فعال کرنے کے لئے پھیلائی جاتی ہے، اور اس کے ساتھ زیادہ سیکھنے اور تبدیل کرنے کی معماری ہے، ایک متوجہ جڑوں کی جرائم کی جرائم پر آموزش کی جاتی ہے، جرائم فرم میں سراسر کی پیش بینی کرنے کی تعلیم کی جاتی پوسٹ پرسس کی تابع علم کا استعمال کرتا ہے\nسراسر، لفظ انڈینگ، لفظ سمجھ غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر تین محبوب ڈاٹ سٹ پر ایک بڑی آزمائش پردازی پیشنهاد فرمود کی کلی اثرات کا ارزش کرتا ہے، حالانکہ پالیا گیا نتیجے وعدہ کے کامیابی کو دکھاتے ہیں، اور پیشنهاد کی طریقے کی طاقت کا ارزش کرتا ہے.', 'sr': 'U današnje vrijeme, većina istraživanja provedena u oblasti sažetanja abstraktivnog teksta fokusira se na neuralne modele sami, bez obzira na njihovu kombinaciju sa pristupima na znanju koje bi mogle da povećaju njihovu efikasnost. U ovom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno sa strukturom i semantičkim metodama. Predloženi okvir je sposoban da riješi problem izvan rečenika ili rijetkih reči, poboljšava učenje dubokih modela učenja. Обща методологија је базирана на добро определеном теоретичном моделу генерализације sadržaja базираног на знањима и прогнозирања глубоких учења за производство абстрактивних резюме. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja mašine, i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na znanju, baziran na ontološkim resursima znanja, disambiguaciji riječi i priznanju entiteta, zajedno sa generalizacijom sadržaja, koji transformiše obični tekst u generalizovani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji sažetnih parova teksta, učenje da predvidi sažetke u generalizovanom obliku. Poslije obrade zadatak koristi znanje\nresursi, uključenje riječi, disambiguacija riječi, i heuristički algoritmi bazirani na metodi sličnosti teksta kako bi transformisali generaliziranu verziju predviđenog sažetka u konačni, ljudski čitljivi oblik. Ogromna eksperimentalna procedura na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobijeni rezultati pokazuju obećavajuću funkciju, potvrđujući robotu predloženog pristupa.', 'no': 'Abstrakte dagar, dei fleste forskningar gjennomførte i feltet abstraktive tekstsamansering fokuserer på enkelte neuralbaserte modeller utan å tenke på sine kombinasjon med kunnskapsbaserte tilnærmingar som kan forbetra effektiviteten. I denne retninga viser dette arbeidet eit nytt rammeverk som kombinerer sammendraging av tekst med sekvens-til-sekvens saman med strukturbaserte og semantiske metodar. Det foreslåde rammeverket er i stand til å handtera problemet med utrykke ordet eller sjeldre ord, forbetra utviklinga av dei dype læringsmodelane. Den generelle metodologien er basert på ein godt definert teoretisk modell for generellisering av kunnskapsbasert innhald og dype læringsforensingar for å laga abstraktive samandrag. Rammeverket er lagt av tre nøkkelelementa: i) ei førehandsamingsoppgåve, ii) ein maskinelæringsmetodologi, og iii) ei post- handsamingsoppgåve. Forhandteringsoppgåva er ein kunnskapsbasert tilnærming, basert på ontologiske kunnskapsressursar, disambiguasjon av ordfølelse, og gjenkjenning av namnet entitet, saman med innhaldet generellisering, som transformerer vanleg tekst til eit generelt form. Ein dyp læringsmodell av attentive kodingsdekoderarkitektur, som er utvida for å slå på ein koplingsmekanismekanismen og dekningsmekanismen, og styrkering av læring og transformeringsbasert arkitektur, er trent på ein generelt versjon av tekstsamandringspar, læring for å forventa samandringar i eit generelt form. Oppgåva etter prosessering brukar kunnskap\nressursar, ordinnbygging, ord-sens-disambiguasjon, og heuristiske algoritme basert på tekstliknande metodar for å transformera den generelle versjonen av eit forventa sammendrag til ein sist, menneskelig lesbar form. Eit utvida eksperimentelt prosedyr på tre populære datasett evaluerer nøkkelaspektar av den foreslåde rammeverket, mens dei oppnådd resultatene viser promiserende utviklingar, og kan validera kraftigheten av den foreslåde tilnærminga.', 'vi': 'Bản tóm tắt hiện nay, hầu hết các nghiên cứu thực hiện trong lĩnh vực tổng kết văn bản trừu tượng tập trung vào các mô hình dựa trên thần kinh, mà không cân nhắc sự kết hợp của chúng với các phương pháp dựa trên kiến thức có thể tăng hiệu quả hơn. Trong hướng này, dự án này mang đến một bộ khung mới kết hợp các bản tóm tắt dựa trên chuỗi-tới-số dựa trên-thần kinh cùng với cấu trúc và các phương pháp theo ngữ pháp. Cơ chế được đề xuất có khả năng giải quyết vấn đề về ngôn ngữ ngoài giới hạn, hay những từ hiếm, cải thiện khả năng của các mô hình học sâu. Phương pháp tổng hợp dựa trên một mô hình lý thuyết xác định rõ ràng về tổng hợp nội dung dựa trên kiến thức và dự đoán về học sâu để tạo ra các bản tóm tắt trừu tượng. The frame is composed of three main elements: i) a pre-treatment task, ii) a máy leaving methods, and III a posttreatment task. The pre-treatment task là một phương pháp dựa trên kiến thức, based on ontological knowledge Resources, Từ sensiting dismbiation, and named Enteprise, cùng với phần nội dung rộng, that transforms common text into the general form. Một mô hình học sâu về kiến trúc có mã hóa dữ dội có chú ý, được mở rộng để mở rộng khả năng giải mã, cũng như tăng cường học tập và kiến trúc dựa vào máy biến hình, được rèn luyện trên một phiên bản tổng hợp văn bản, học dự đoán các bản tổng quát. Nhiệm vụ nối tiếp lợi dụng kiến thức\nnguồn lực, sự tác ghép nối từ, phân dạng cảm nhận từ, và thuật to án thần kinh dựa trên phương pháp tương tự văn bản, để biến phiên bản phổ biến của một bản tổng hợp được dự đoán thành hình thức đọc cuối cùng. Một thủ tục thử nghiệm rộng rãi trên ba bộ dữ liệu phổ biến đánh giá các khía cạnh chủ chốt của bộ khung đã đề nghị, trong khi kết quả có triển vọng tốt, xác nhận độ bền vững của phương pháp được đề nghị.', 'uz': "Bugun hozirda ko'pchilik o'rganish matn muhim sohalarida ishga tushirilgan o'rganishlar faqat neyron asosida modellarni o'rganish mumkin. Ularning ilmiy asosiy usullar bilan birlashtirish mumkin, ularning effektligini oshirish mumkin. Ushbu oynada, bu ishni qoʻllash va semantik asosida qoʻllanilgan matn muhitizasini bir nechta- to- seksirlik darajasi bilan birlashtirish mumkin. Aniqlanadigan freym soʻzlar yoki chegara so'zlarning muammolarini boshqarish mumkin, eng yuqori o'rganish modellarini bajarish mumkin. Umumiy metodologi, ilmiy tarkibi yaratish va eng o'rganish muvaffaqiyatlarini yaratish uchun yaxshi aniqlangan teoretikal modeliga asoslangan. Freym uchta kalit elementlaridan yaratiladi: (i) pre-processing vazifa, (ii) mashinani o'rganish usuli va (iii) keyingi vazifa. Birinchi harakat vazifa, ontologik илм манзилларi asosida, so'z ma'lumotni qismlashtirish va ma'lumotni tasdiqlash va mavzu yaratish bilan ishlatish mumkin, bu oddiy matnni umumiy shaklni o'zgartiradi. Name Keyingi vazifa\n@ info: whatsthis Name", 'bg': 'В днешно време повечето изследвания, проведени в областта на абстрактното обобщаване на текста, се фокусират само върху невронно-базираните модели, без да се има предвид тяхната комбинация с базирани на знание подходи, които биха могли допълнително да повишат тяхната ефективност. В тази посока тази работа представя нова рамка, която съчетава последователност към последователност невронно базирана текстова обобщаване заедно със структурно и семантично базирани методологии. Предложената рамка е в състояние да се справи с проблема с нелексиката или редките думи, подобрявайки ефективността на моделите за дълбоко обучение. Цялостната методология се основава на добре дефиниран теоретичен модел на обобщаване на съдържанието, основано на знанието, и прогнози за дълбоко обучение за генериране на абстрактни резюмета. Рамката се състои от три ключови елемента: i) задача за предварителна обработка, ii) методология за машинно обучение и iii) задача за следобработка. Задачата за предварителна обработка е базиран на знанието подход, базиран на онтологични ресурси на знанието, разграничаване на смисъла на думата и разпознаване на наименовани обекти, заедно с обобщаване на съдържанието, което превръща обикновения текст в обобщена форма. Модел на дълбоко обучение на внимателна архитектура на кодер-декодер, който е разширен, за да позволи механизъм за справяне и покриване, както и укрепване на обучението и трансформаторната архитектура, се обучава на обобщена версия на двойки текст-резюме, научавайки се да предвижда резюмета в обобщена форма. Задачата за последваща обработка използва знания\nресурси, вграждане на думи, разграничаване на смисъла на думата и евристични алгоритми, базирани на методи за сходство на текста, за да се трансформира обобщената версия на предсказаното резюме в окончателна, четлива за човека форма. Обширна експериментална процедура върху три популярни набора от данни оценява ключовите аспекти на предложената рамка, докато получените резултати показват обещаващи резултати, валидиращи здравината на предложения подход.', 'hr': 'U današnje vrijeme, većina istraživanja provedena u području sažetanja abstraktivnog teksta fokusirala se na samo neurološke modele, bez obzira na njihovu kombinaciju s pristupima na temelju znanja koje bi mogle povećati njihovu učinkovitost. U tom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno s strukturom i semantičkim metodama. Predloženi okvir je sposoban rješavati problem izvan riječi ili rijetkih riječi, poboljšati učinkovitost dubokih modela učenja. Općenita metodika temeljena je na dobro definiranom teorijskom modelu generalizacije sadržaja na znanju i predviđanja dubokog učenja za stvaranje abstraktivnih sažetaka. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja strojeva i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na temelju znanja, temeljen na ontološkim resursima znanja, disambiguaciji riječi osjećaja i priznanju imena entiteta, zajedno s generalizacijom sadržaja, koji transformira obični tekst u generalizirani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji sažetnih parova teksta, učenje predvidjeti sažetke u generaliziranom obliku. Poslije obrade zadatak koristi znanje\nresursi, uključuvanje riječi, disambiguacija riječi, i heuristički algoritmi na temelju metoda sličnosti tekstu kako bi se transformirala generalizirana verzija predviđenog sažetka u konačni, ljudski čitljivi oblik. Veliki eksperimentalni postupak na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobiveni rezultati pokazuju obećavajuću učinkovitost, potvrđujući robotu predloženog pristupa.', 'da': 'I dag fokuserer de fleste forskning inden for abstraktiv tekst resuméering alene på neurale-baserede modeller, uden at overveje deres kombination med videnbaserede tilgange, der yderligere kan forbedre deres effektivitet. I denne retning præsenterer dette arbejde en ny ramme, der kombinerer sekvens-til-sekvens neural-baseret tekst sammenfatning sammen med struktur og semantisk baserede metoder. Den foreslåede ramme er i stand til at håndtere problemet med uden for ordforråd eller sjældne ord og forbedre effektiviteten af deep learning-modellerne. Den overordnede metode er baseret på en veldefineret teoretisk model for videnbaseret indhold generalisering og dyb læring forudsigelser til generering af abstrakte resuméer. Rammen består af tre nøgleelementer: i) en forberedelsesopgave, ii) en maskinlæringsmetode og iii) en efterbehandlingsopgave. Forbearbejdningsopgaven er en videnbaseret tilgang, baseret på ontologiske videnressourcer, ordsanseforståelse og navngivet entitetsgenkendelse, sammen med indholdsgeneralisering, der omdanner almindelig tekst til en generaliseret form. En dyb læringsmodel af opmærksom encoder-dekoder arkitektur, som er udvidet til at muliggøre en coping- og dækningsmekanisme, samt forstærkning læring og transformer-baserede arkitekturer, er trænet på en generaliseret version af tekst-resumé par, der lærer at forudsige resuméer i en generaliseret form. Efterbehandlingsopgaven udnytter viden\nRessourcer, ordindlejringer, ordforståelse og heuristiske algoritmer baseret på tekstligningsmetoder for at omdanne den generaliserede version af et forudsiget resumé til en endelig, menneskelæsbar form. En omfattende eksperimentel procedure på tre populære datasæt evaluerer centrale aspekter af den foreslåede ramme, mens de opnåede resultater viser lovende resultater, hvilket validerer robustheden af den foreslåede tilgang.', 'nl': 'Abstract Tegenwoordig concentreert het meeste onderzoek op het gebied van abstracte tekstsamenvatting zich alleen op neurale modellen, zonder rekening te houden met hun combinatie met kennisgebaseerde benaderingen die hun efficiëntie verder zouden kunnen verbeteren. In deze richting presenteert dit werk een nieuw raamwerk dat sequentie-to-sequence neural-based tekst samenvatting combineert samen met structuur en semantisch gebaseerde methodologieën. Het voorgestelde kader is in staat om het probleem van niet-woordenschat of zeldzame woorden aan te pakken, waardoor de prestaties van de deep learning modellen worden verbeterd. De algemene methodologie is gebaseerd op een goed gedefinieerd theoretisch model van kennisgebaseerde contentgeneralisatie en deep learning voorspellingen voor het genereren van abstracte samenvattingen. Het raamwerk bestaat uit drie kernelementen: (i) een pre-processing taak, (ii) een machine learning methodologie en (iii) een post-processing taak. De pre-processing taak is een op kennis gebaseerde benadering, gebaseerd op ontologische kennisbronnen, woordzinnendiambiguatie en naamsbekendheid, samen met contentgeneralisatie, die gewone tekst transformeert in een algemene vorm. Een deep learning model van attente encoder-decoder architectuur, dat is uitgebreid om een coping- en dekkingsmechanisme mogelijk te maken, evenals versterking learning en transformator-gebaseerde architecturen, wordt getraind op een algemene versie van tekst-samenvattingsparen, waarbij wordt geleerd samenvattingen in een algemene vorm te voorspellen. De post-processing taak maakt gebruik van kennis\nDe algemene versie van een voorspelde samenvatting wordt omgezet in een definitieve, menselijke leesbare vorm. Een uitgebreide experimentele procedure op drie populaire datasets evalueert belangrijke aspecten van het voorgestelde framework, terwijl de verkregen resultaten veelbelovende prestaties vertonen en de robuustheid van de voorgestelde aanpak valideren.', 'de': 'Abstract Heutzutage konzentriert sich die meiste Forschung im Bereich der abstraktiven Textzusammenfassung auf neuronale Modelle allein, ohne deren Kombination mit wissensbasierten Ansätzen zu berücksichtigen, die ihre Effizienz weiter steigern könnten. In dieser Richtung präsentiert diese Arbeit ein neuartiges Framework, das sequenzbasierte neuronale Textzusammenfassungen mit Struktur- und semantisch-basierten Methoden kombiniert. Der vorgeschlagene Rahmen ist in der Lage, das Problem von Fremdwörtern oder seltenen Wörtern zu lösen und die Leistung der Deep Learning Modelle zu verbessern. Die Methodik basiert auf einem klar definierten theoretischen Modell der wissensbasierten Inhaltsverallgemeinerung und Deep Learning Vorhersagen zur Generierung abstrakter Zusammenfassungen. Das Framework besteht aus drei Schlüsselelementen: (i) einer Vorverarbeitungsaufgabe, (ii) einer Methodik des maschinellen Lernens und (iii) einer Nachverarbeitungsaufgabe. Die Vorbearbeitungsaufgabe ist ein wissensbasierter Ansatz, der auf ontologischen Wissensressourcen, Wortsinn-Begriffsklärung und Namenserkennung sowie Inhaltsverallgemeinerung basiert, der gewöhnlichen Text in eine verallgemeinerte Form verwandelt. Ein Deep-Learning-Modell der aufmerksamen Encoder-Decoder-Architektur, das erweitert wurde, um einen Coping- und Coverage-Mechanismus sowie Verstärkungslernen und transformatorbasierte Architekturen zu ermöglichen, wird auf einer verallgemeinerten Version von Text-Summary-Paaren trainiert und lernt Zusammenfassungen in verallgemeinerter Form vorherzusagen. Die Nachbearbeitungsaufgabe nutzt Wissen\nUm die verallgemeinerte Version einer vorhergesagten Zusammenfassung in eine endgültige, menschenlesbare Form zu verwandeln, werden Ressourcen, Worteinbettungen, Wortsinn-Disambiguation und heuristische Algorithmen basierend auf Textähnlichkeitsmethoden verwendet. Ein umfangreiches experimentelles Verfahren an drei populären Datensätzen evaluiert Schlüsselaspekte des vorgeschlagenen Frameworks, während die erhaltenen Ergebnisse vielversprechende Leistung aufweisen und die Robustheit des vorgeschlagenen Ansatzes bestätigen.', 'id': 'Abstrakt Saat ini, kebanyakan penelitian yang dilakukan dalam bidang penelitian teks abstraktif fokus pada model berbasis saraf sendirian, tanpa mempertimbangkan kombinasi mereka dengan pendekatan berbasis pengetahuan yang dapat meningkatkan lebih lanjut efisiensi mereka. Dalam arah ini, pekerjaan ini mempersembahkan cadangan baru yang menggabungkan persendirian-ke-persendirian teks berasaskan saraf bersama struktur dan metodologi berasaskan semantis. Cadangan yang diusulkan mampu menghadapi masalah dari luar vokbulari atau kata langka, meningkatkan prestasi model belajar dalam. Metodologi umum berdasarkan model teori yang terdefinisikan dengan baik dari generalisasi konten berdasarkan pengetahuan dan prediksi belajar dalam untuk menghasilkan ringkasan abstraktif. Rambutnya terdiri dari tiga elemen kunci: (i) tugas pra-proses, (ii) metodologi belajar mesin, dan (iii) tugas pos-proses. Tugas pra-proyeksi adalah pendekatan berdasarkan pengetahuan, berdasarkan sumber pengetahuan ontologi, penyelesaian perasaan kata, dan pengakuan entitas bernama, bersama dengan generalisasi isi, yang mengubah teks biasa menjadi bentuk generalisasi. Model belajar mendalam arsitektur pengekode-dekoder perhatian, yang diperbesar untuk memungkinkan mekanisme penghadapan dan penyamaran, serta pemerintahan belajar dan arsitektur berdasarkan transformer, dilatih pada versi umum pasangan teks-ringkasan, belajar untuk memprediksi ringkasan dalam bentuk umum. Tugas pos-proses menggunakan pengetahuan\nsumber daya, pembangunan kata, penyelesaian perasaan kata, dan algoritma heuristik berdasarkan metode persamaan teks untuk mengubah versi generalisasi dari ringkasan yang diprediksi menjadi bentuk akhir yang dapat dibaca oleh manusia. Sebuah prosedur eksperimen ekstensif pada tiga set data populer mengevaluasi aspek kunci dari cadangan yang diusulkan, sementara hasil yang diperoleh menunjukkan prestasi yang berjanji, mengevalifikasi kepekatan pendekatan yang diusulkan.', 'fa': 'امروز، اکثر تحقیقات انجام شده در زمینه تعداد متن abstractive تنها روی مدل\u200cهای عصبی تمرکز می\u200cکند، بدون توجه به ترکیب آنها با روش\u200cهای علمی که می\u200cتوانند عملکرد آنها را بیشتر افزایش دهند. در این مسیر، این کار یک چهارچوب نویسی را نشان می دهد که جمع کردن متن بنیاد عصبی را با ساختار و روش\u200cهای بنیاد semantic را ترکیب می\u200cکند. این چهارچوب پیشنهاد قادر است که با مشکل بیرون کلمات یا کلمات نادر حل کند، و عملکرد مدل یادگیری عمیق را بهتر کند. این روش\u200cشناسی عمومی بر روی یک مدل نظریه\u200cای خوب تعریف شده از محتوای ژنرال\u200cسازی بر اساس علم و پیش\u200cبینی\u200cهای یادگیری عمیق برای تولید جمعیت\u200cهای abstractive است. چهارچوب از سه عنصر کلیدی ساخته شده است: i) یک کار پیش\u200cپردازی، ii) روش یادگیری ماشین، و iii) یک کار بعد از پردازی. وظیفه پیش\u200cپردازی یک روش بر اساس علم است که بر اساس منابع علم\u200cشناسی\u200cشناسی\u200cشناسی\u200cهای کلمه\u200cشناسی و شناختن عنوان\u200cشناسی\u200cهای عنوان\u200cشناسی است که متن معمولی را تبدیل می\u200cکند به یک فرم ژنرال\u200cشناسی. یک مدل یادگیری عمیق از معماری آهنگ\u200cبندی\u200cکننده\u200cی رمزبندی\u200cکننده\u200cای که برای فعال کردن یک مکانیسم پوشش و پوشش، و یادگیری و معماری\u200cهای بنیاد تغییر\u200cدهنده، روی نسخه\u200cی جفت\u200cهای جمع\u200cآوری متن آموزش می\u200cشود، یاد گرفتن برای پیش\u200cبینی جمع\u200cآوری در یک شکل عمومی. کار بعد از پرداخت از دانش استفاده می\u200cکند\nمنابع، جمع کردن کلمات، غیرقابل تغییر حس کلمات و الگوریتم های حوریستی بر روش شبیه\u200cسازی متن برای تغییر نسخه\u200cی عمومی یک جمع پیش\u200cبینی به یک فرم نهایی، قابل خواندن بشر. یک روش آزمایشی بسیار گسترده در سه مجموعه داده\u200cهای محبوب ارزش می\u200cدهد نقطه\u200cهای کلیدی از چهارچوب پیشنهاد، در حالی که نتیجه\u200cهای پیدا شده\u200cاند اجرای قول\u200cدهنده را نشان می\u200cدهند، و ثابت کردن قوی\u200cای از روش', 'sw': 'Kwa siku hizi, utafiti mkubwa uliofanywa katika uwanja wa muhtasari wa maandishi yasiyo na maandishi ya ubora unajikita kwenye mifano yenye msingi wa neura peke yake, bila kuzingatia muunganiko wao na mbinu za kisayansi ambazo zinaweza kuongeza ufanisi wao. Kwa mwelekeo huu, kazi hii inaonyesha mfumo wa riwaya unaoanganisha muhtasari wa maandishi yanayotumika kwa mfululizo wa mfululizo na mbinu za kisasa. Mfumo huu unapendekezwa una uwezo wa kushughulikia tatizo la maneno yasiyo ya lugha au maneno nadra, na kuimarisha utendaji wa mifano ya kujifunza kwa kina. Utawala wa jumla unajikita na mifano ya nadharia yenye ufafanuzi wa maudhui yenye msingi wa maarifa na utabiri wa kujifunza kwa ajili ya kutengeneza muhtasari wa kutosha. Mfumo huu umetengenezwa na vipengele vitatu vya muhimu: (i) kazi ya kabla ya kufanya kazi, (ii) mbinu za kujifunza mashine, na (iii) kazi ya baada ya kuchukua hatua. Kazi ya upasuaji wa awali ni mbinu yenye ufahamu, kwa kutumia rasilimali za maarifa za kiutaalamu, uvumbuzi wa maneno, na utambulisho wa entity, pamoja na uzalishaji wa maudhui, ambayo hubadilisha ujumla kuwa namna ya ujumla. Mfano wa kujifunza kwa kina wa ujenzi wa ubunifu wa kodi unaoaminika, ambao unaongezeka ili kuwezesha ubunifu na taarifa za habari, pamoja na kuboresha majengo ya kujifunza na mabadiliko yenye msingi wa muhtasari, unafundishwa kwa toleo la jumla la la ndoa za muhtasari, kujifunza kutabiri muhtasari katika mfumo wa jumla. Kazi ya baada ya upasuaji inatumia maarifa\nrasilimali, maeneo ya maneno, uvunjifu wa maana, na vipimo vya heuristi vilivyo kwa njia sawa na maandishi ili kubadilisha toleo la jumla la la muhtasari lililotabiliwa hadi a in a ya mwisho, inayosomeka kwa binadamu. Utaratibu mkubwa wa majaribio kwenye seti ya data maarufu tatu unatathmini vipengele muhimu vya mfumo wa pendekezo, wakati matokeo yaliyopata yanaonyesha ufanisi wa kuahidini, ukithibitisha ubora wa mbinu hiyo ya pendekezo.', 'sq': 'Abstrakt Today, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. Në këtë drejtim, ky punë paraqet një kuadër të ri që kombinon përmbledhjen e tekstit nga sekuenca në sekuencë me bazë nervore së bashku me strukturën dhe metodologjitë me bazë semantike. Korniza e propozuar është e aftë të trajtojë problemin e fjalëve jashtë fjalorit apo të rralla, duke përmirësuar performancën e modeleve të mësimit të thellë. Metodologjia e përgjithshme bazohet në një model teorik të përcaktuar mirë të gjeneralizimit të përmbajtjes bazuar në njohuri dhe parashikimeve të mësimit të thellë për gjenerimin e përmbledhjeve abstraktive. Korniza përbëhet nga tre elementë kyçe: (i) një detyrë paraprocesuese, (ii) një metodologji mësimi i makinave dhe (iii) një detyrë pas procesimit. Detyra paraprocesuese është një qasje bazuar në njohuri, bazuar në burimet ontologjike të njohurive, çambiguacionin e kuptimit të fjalës dhe njohjen e emëruar të njësisë së bashku me gjeneralizimin e përmbajtjeve, që transformon tekstin e zakonshëm në një form ë të gjeneralizuar. Një model mësimi i thellë i arkitekturës së koduesit-dekoderit të vëmendshëm, i cili zgjerohet për të mundësuar një mekanizëm përballimi dhe mbulimi, si dhe forcimi i mësimit dhe arkitekturës bazuar në transformues, është trajnuar në një version të gjeneralizuar të çifteve tekst-përmbledhje, duke mësuar të parashikojë përmbledhjet në një form ë të gjeneralizuar. The post-processing task utilizes knowledge\nburimet, përfshirjet e fjalëve, çambiguacioni i kuptimit të fjalëve dhe algoritmet heuristikë bazuar në metodat e ngjashmërisë së tekstit me qëllim që të transformojë version in e gjeneralizuar të një përmbledhjeje të parashikuar në një form ë përfundimtare të lexueshme nga njerëzit. Një procedurë eksperimentale të gjerë mbi tre grupe të dhënash popullore vlerëson aspektet kyçe të kuadrit të propozuar ndërsa rezultatet e fituara ekspozojnë performancë premtuese, duke validuar fuqinë e qasjes së propozuar.', 'tr': 'Abstrakt Köp sany abstraktiw metin toplamynyň sahypasynda işlenýän araştyrmalar neural tabanly modellere ýeke özüne üns berilýär, bilim tabanly hereketleriyle birleşişmäge özleriniň etkinliýetini artdyryp biler üýtgetmeýän şeklinde üns berilýär. Bu görnöşinde, bu işe tertibe-tä-dizirli näyral tabanly metin hulatyny struktur we semantik tabanly metinleri bilen birleştirilýär. Mazmunlar sistemasy sözleriň daşyndaky ýa-da nadir sözleriň meselesini çözmek, derin öwrenmek nusgalarynyň täzeliklerini gowylaşdyryp biler. Hemme methodologiýa bilgi tabanly maglumat döredilmesiniň we çukur öwrenmek üçin gowy tanyş teoriýalygyna daýanýar. Bu çerçew üç a çyk elementlerden oluşulýar: i) öňünden i şleýän zady, (ii) maşynyň öwrenmesi methodologiýasy we (iii) öňünden soňra işleýän zady. Öňki işleýän zady bilim tabanly bir ýazşydyr, ontolojik bilim çeşmelerine daýanýar, söz duýguny çykarmak we adly zatlary tanamak bilen daýanýar, bu da adatça metin döredilmiş bir şekilde üýtgedir. Dykgat ködleme-dekoder arhitekteginiň derin öwrenmek nusgasy, kop we örgüt mekanizmasyny mümkin etmek üçin genişletilýär we öwrenmek we üýtgetmek üçin gurultatyny daýatmak üçin, metin-sumy çiftleriň umumy tarapynda öwrenmeli, toparyny döredilen nusgasynda öwrenmek üçin öwrenmeli. Edilmek üçin işlemden soňra bilgi ullanýar\nResuller, söz gaýşartmaky, söz duýguny çykarmak we heuristik algoritmalar metin benzeri yöntemlerine dayanan metin ýagdaýynda önlenen toparyň döredilmiş sürümini iň soňky, adam okalabilir bir şekilde üýtgetmek üçin üýtgetmek üçin. Üç meýdança maglumat düzümlerinde örän bir deneysel prosedür teklip eden frameýäniň aç aspektlerini deňleýär, we netijeler netijeleri söz berýän zady görkeýär, teklip eden golaýyň güýçligini taýýarlaýar.', 'af': "Abstrakte Vandag, die meeste ondersoek wat in die veld van abstraktiewe teks opsomming gedoen is, fokus alleen op neuralgebaseerde modele, sonder om hulle kombinasie met kennis-gebaseerde toegange te onderwerp wat hulle effektiviteit verder kan verbeter. In hierdie rigting, hierdie werk voorsien 'n nuwe raamwerk wat sekwensie-na-sekwensie neurale-gebaseerde teks opsomming kombinieer saam met struktuur en semantiese-gebaseerde metodes. Die voorgestelde raamwerk is in staat om met die probleem van uit-woordeboek of selfde woorde te behandel, die prestasie van die diep leer modele te verbeter. Die algemene metodologie is gebaseer op 'n goed gedefinieerde teorieese model van kennis-gebaseerde inhoud generalisering en diep leer voorskou vir die genereer van abstraktiewe opsommings. Die raamwerk is gemaak van drie sleutel elemente: i) â\x80\x99n voorafverwerking taak, (ii) â\x80\x99n masjien leer metodologie en (iii) â\x80\x99n post-verwerking taak. Die voorafverwerking opdrag is 'n kennis-gebaseerde toegang, gebaseer op ontologiese kennis hulpbronne, woord sens ontsamminging en genoem entiteiterkenning, saam met inhoud generellisering, wat gewone teks verander in 'n genereliseerde vorm. 'n Deep leer model van aandaglike enkoder-dekoder-arkitektuur, wat uitgevou word om 'n kopering en dekkeningsmekanisme te aktiveer, en ook versterking leer en transformeer-gebaseerde arkitektuure, is opgelei op 'n generelse weergawe van teks-opsommingspaar, leer om opsommings in 'n generelliseerde vorm te voorskou. Die post-verwerking taak gebruik kennis\nhulpbronne, woord inbettings, woord sens ontsammings en heuristiese algoritme gebaseer op teks gelykenis metodes om die generaliseerde weergawe van 'n voorskoude opsomming te transformeer na 'n finale, menslike-leesbaarde vorm. 'n Uitbreidige eksperimentale prosedure op drie populêre data stelle evalueer sleutel aspekte van die voorgestelde raamwerk, terwyl die ontvangde resultate die beloftende effektiviteit vertoon, die kragtigheid van die voorgestelde toegang bekend.", 'ko': '현재 추상적인 텍스트 요약 분야에서 진행된 대부분의 연구는 신경 네트워크를 바탕으로 하는 모델에만 주목하고 지식을 바탕으로 하는 방법과 결합하는 것을 고려하지 않아 효율을 한층 높였다.이 방향에서 이 작업은 서열을 바탕으로 서열 신경 네트워크에 이르는 텍스트 요약과 구조와 의미를 바탕으로 하는 방법을 결합한 새로운 구조를 제시했다.이 프레임워크는 어휘량이 부족하거나 희귀어를 해결할 수 있어 딥러닝 모델의 성능을 높일 수 있다.전체적인 방법은 정의가 좋은 이론 모델, 즉 지식을 바탕으로 하는 내용 개괄과 추상적 요약을 생성하는 깊이 있는 학습 예측을 바탕으로 한다.이 프레임워크는 세 가지 관건적인 요소로 구성되어 있는데 그것이 바로 (i)예처리 임무, (ii)기계 학습 방법, 그리고 (iii)후처리 임무이다.예처리 임무는 지식을 바탕으로 하는 방법으로 본체의 지식 자원, 단어의 의미 소멸, 명명 실체 식별과 내용 범화를 바탕으로 일반 텍스트를 광의적인 형식으로 전환한다.인코더-디코더 체계 구조에 전념하는 깊이 있는 학습 모델은 텍스트 요약에 대한 광의적인 버전에서 훈련을 하고 광의적인 형식으로 요약을 예측하는 학습을 한다. 이 모델은 대응과 커버 메커니즘을 실현하고 학습과 변환기를 바탕으로 하는 체계 구조를 강화한다.후처리 임무 활용 지식\n자원, 단어 삽입, 의미 변조, 텍스트 유사성 방법을 바탕으로 하는 계발식 알고리즘으로 요약을 예측하는 광의적인 버전을 최종 인류가 읽을 수 있는 형식으로 전환시킨다.세 개의 유행 데이터 집합에서 광범위한 실험을 실시하여 이 프레임워크의 관건적인 부분을 평가했고 얻은 결과는 좋은 성능을 보여 이 방법의 노봉성을 검증했다.', 'am': 'ዛሬ፣ ብዙዎቹ የጽሑፍ ቁጥጥር በሚደረጉት እርሻ ላይ ተማርከዋል፣ ብቻውን በናውራዊ አካባቢ ምሳሌዎች ላይ ብቻ ነው፡፡ ወደዚህ ቦታ፣ ይህ ሥራ የነጥብ ፍሬም በሥርዓት እና በsemantic-based ሥርዓት የተደረገውን የነጥብ የጽሑፍ ቁጥጥር የሚያሳስብ ነው፡፡ በተዘጋጀው ፍሬም የጠልቅ ትምህርት ምሳሌዎችን ማሳየት የሚችል የቋንቋ ወይም የግልፅ ቃላትን መቆጣጠር ይችላል፡፡ የጠቅላላ ሞዴology እውቀት-based የውይይት ማቀናቀል እና የጥልቅ ትምህርት ማቀናኘት ጥልቅ ትምህርት ላይ የተመሳሳይ ተቃውሞ ነው፡፡ የፍሬም ቁልፎች በሦስት ቁልፎች ውስጥ ነው:(i) የፕሮግራም ስራ:(ii) የመኪን ትምህርት methodology እና (iii) የፖለቲካ ስራ ነው፡፡ የቀድሞው የሥርዓት ሥራ የኦቶሎጂ እውቀት ሀብት፣ የቃላት ማስተዋል ውቀት፣ የተባለው አካባቢ ማውቀት፣ በተባለው ማቀናቀል እና የጽሑፉን ማቀናቀል በመጠቀም የተጠቃሚ ጽሑፍ አቀማመጥ እንዲለውጥ ነው፡፡ የጽሑፍ አቀማመጥ እና የድጋፍ አካባቢ መሠረት ማድረግ የጥልቅ ትምህርት ሞዴል፣ ማስተማርና ማተማር እና የመለወጥ መሠረት፣ የጽሑፍ አነስተኛ ሁለትን በመጠቀም የተማረ ነው፡፡ የፖስታ ስራ እውቀትን ይጠቅማል\nሀብት፣ ቃላት ግንኙነት፣ የቃላት አስተያየት እና የኦርቲክ አሌጎርቲም በጽሑፍ መሰላቸውን ሥርዓት ለመለወጥ የተቀረበ የውጤት ክፍል ወደ መጨረሻ የሰው ተቃውሞ የሚነበበውን መልዕክት ለመለወጥ ነው፡፡ በተፈተናው የሦስት የድምፅ ፈተና ሥርዓት በተፈተናው የፍሬም ቁልፎችን ያስተካክላል፡፡ ፍሬዎቹም በተገኘው ጊዜ የተስፋ የሥርዓት ውጤት ያሳያል፡፡', 'az': 'Abstrakt Günlərdə, abstraktiv mətn toplaması sahəsində təkcə nöral tabanlı modellərə tərəfindən təklif edilmiş araştırmalar, elm tabanlı təklifələrlə birləşdirilməsini daha da artıra bilər. Bu tərəfdə, bu işin bir yeni framework ü göstərir ki, sequence-to-sequence-based mətn quruluşu və semantik metodları ilə birləşdirir. Bu tədbir qurğusu sözlərin və ya nadir sözlərin problemlərini çəkməyə qadir deyildir, böyük öyrənmə modellərinin performansını yaxşılaşdırmağa qadir deyildir. Bu bütün metodoloji elm-tabanlı məlumatların generalizasyonu və abstraktiv toplantıları yaratmaq üçün çox müəyyən edilmiş teoriki modellərə dayanılır. Çerçive üç anahtar elementindən oluşur: i) əvvəlcə i şləmə işləri, ii) makina öyrənmə metodolojisi və iii) post işləmə işləri. Əvvəlcə işləmə işləri bilgi-tabanlı tərzidir, ontolojik elm kaynaqlarına dayanan, sözlərin sağlamlığı dəyişməsi və adı ilə ünvanlıq tanıması ilə birlikdə sıradan metinləri generalizasyona çevirir. Dinli koder-dekoder arhitektarının derin öyrənmə modeli, kopyalama və örtük mehanizmisini fəallaşdırmaq üçün genişlənir, həmçin in öyrənməyi və transformer-tabanlı arhitektarları daha qüvvətli təhsil edirlər, ünvanlı bir şəkildə təhsil etməyi öyrənir. Sonra işləmə işləri bilgi istifadə edir\nMətn similaritə metodlarına dayandırılmaq üçün tədbir edilmiş təsbit verzijünü son, insan oxuyabilən formaya çevirmək üçün mənbəni, sözlər içərisində yazılmış yazılı hisslər, və heuristik algoritmi. Üç popüler veri qurularında böyük bir təcrübə prosedüsü təklif edilmiş quruluşun açarlı aspektlərini değerləşdirir. Yaxılmış sonuçlar təklif edilən təcrübəsinin güclülüyünü təsdiqləyir.', 'bn': 'বর্তমানে বিচ্ছিন্ন করুন, বেশীরভাগ গবেষণা আত্মসংক্ষেপের ক্ষেত্রে নিউরুল ভিত্তিক মডেলের উপর মনোযোগ প্রদান করেছে, তাদের জ্ঞান-ভিত্তিক উপায়ের সাথে  এই দিকে এই কাজ একটি নভেল ফ্রেম্যাক্টর উপস্থাপন করে যা সেকেন্স-থেকে সেকেন্স-ভিত্তিক নিউরাল-ভিত্তিক টেক্সট সংক্রান্ত সংক্ষেপের প্রস্তাবিত ফ্রেমের কাঠামোটি শব্দভাণ্ডার বা দুর্লভ শব্দের সমস্যার সাথে মিলিয়ে নিতে সক্ষম, গভীর শিক্ষা মডেলের প্রদর্শনের সাধারণত পদ্ধতির ভিত্তিক ততিত্তিগত মডেলের উপর ভিত্তিক রয়েছে জ্ঞান-ভিত্তিক বিষয়বস্তু জেনারেলেশন এবং গভীর শিক্ষার ভবিষ্যৎবাণ ফ্রেমের কাঠামো তিনটি গুরুত্বপূর্ণ উপাদানের মধ্যে তৈরি করা হয়েছে: (i) পূর্ব প্রক্রিয়ার কাজ, (ii) একটি মেশিন শিক্ষা পদ্ধতি এবং (আই) একট পূর্ব প্রক্রিয়ার কাজ হচ্ছে একটি জ্ঞান-ভিত্তিক পদ্ধতি, শব্দের মানসিক বিভ্রান্তির ভিত্তিতে, এবং নামে বস্তুর স্বীকৃতি এবং বিষয়বস্তু সংস্কারের স কোডার-ডেকোডার কাঠামোর গভীর শিক্ষার মডেল, যা কপিং এবং কাভারেজ ব্যবস্থা করার জন্য বিস্তৃত হয়েছে এবং সাথে শিক্ষা এবং পরিবর্তনের ভিত্তিক ক কাঠামোগুলোর সাধারণ সংক্রান্ত জোড়ার সংস্করণে শিক্ পরিচালনা করার কাজ জ্ঞান ব্যবহার করে\nসম্পদ, শব্দ প্রবাহিত, শব্দের মানসিক বিভ্রান্তি এবং হারিস্টিক অ্যালগরিদম, টেক্সটের সমতুল্য পদ্ধতি ভিত্তিতে ভিত্তি করেছে যাতে ভবিষ্যতের সার্সা প্রস্তাবিত ফ্রেমের কাঠামোর একটি বিস্তারিত পরীক্ষার প্রক্রিয়া তিনটি জনপ্রিয় তথ্য সেটে প্রস্তাবিত পরীক্ষার প্রক্রিয়া মূল্যায়ন করে, আর ফলাফল প্রত', 'bs': 'U današnje vrijeme, većina istraživanja provedena u oblasti sažetanja abstraktivnog teksta fokusirala se na samo neurološke modele, bez obzira na njihovu kombinaciju sa pristupima na temelju znanja koje bi mogle povećati njihovu učinkovitost. U ovom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno sa strukturom i semantičkim metodama. Predloženi okvir je sposoban rješavati problem izvan rečenika ili rijetkih riječi, poboljšavajući učenje dubokih modela učenja. Općenita metodika se temelji na dobro definiranom teorijskom modelu generalizacije sadržaja na znanju i predviđanja dubokog učenja za stvaranje abstraktivnih sažetaka. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja mašine i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na znanju, baziran na ontološkim resursima znanja, disambiguaciji riječi, i priznanje entiteta po imenu, zajedno s generalizacijom sadržaja, koji pretvara obični tekst u generalizirani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji rezumnih parova teksta, učenje predvidjeti sažetke u generaliziranom obliku. Poslije obrade zadatak koristi znanje\nresursi, uključenje riječi, disambiguacija riječi, i heuristički algoritmi bazirani na metodi sličnosti teksta kako bi transformirali generaliziranu verziju predviđenog sažetka u konačni, ljudski čitljivi oblik. Ogromna eksperimentalna procedura na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobijeni rezultati pokazuju obećavajuću učinkovitost, potvrđujući robotu predloženog pristupa.', 'ca': "Avui en dia, la majoria de les investigacions fetes en el camp de la resumització abstracta del text es centren només en models basats en neurones, sense considerar la seva combinació amb enfocaments basats en el coneixement que podrien millorar més la seva eficiència. En aquesta direcció, aquesta feina presenta un nou marc que combina una resumida de text basada en seqüència a seqüència neuronal juntament amb estructura i metodologies basades en semàntica. El marc proposat és capaç de tractar el problema de paraules fora de vocabulari o rares, millorant el rendiment dels models d'aprenentatge profund. La metodologia global es basa en un model teòric ben definit de generalització del contingut basat en el coneixement i prediccions profundes d'aprenentatge per generar resumes abstracts. El marc està compost de tres elements clau: i) una tasca de pré-processament, ii) una metodologia d'aprenentatge de màquines i iii) una tasca de post-processament. La tasca de pré-processament és un enfocament basat en el coneixement, basat en recursos ontològics de coneixement, desambiguació del sentit de paraula i reconeixement de l'entitat anomenat, juntament amb la generalització del contingut, que transforma el text normal en una form a generalitzada. Un model d'aprenentatge profund d'arquitectura atenta de codificadors-decoders, que s'expandeix per permetre un mecanisme de copia i cobertura, com també l'aprenentatge de reforç i arquitectures basades en transformadors, està entrenat en una versió generalitzada de parelles de resum de text, aprenent a predir resums en una forma generalitzada. La tasca de postprocessament utilitza el coneixement\nrecursos, incorporacions de paraules, desambiguació del sentit de paraules i algoritmes heurístics basats en mètodes de similitud de text per transformar la versió generalitzada d'un resum predit en una form a final llegible per a l'humà. An extensive experimental procedure on three popular data sets evaluates key aspects of the proposed framework, while the obtained results exhibit promising performance, validating the robustness of the proposed approach.", 'hy': 'Այսօր վերացական, վերացական տեքստի համառոտագրման ոլորտում կատարված հետազոտությունների մեծ մասը կենտրոնանում է միայն նեյրոնային հիմնված մոդելների վրա, առանց հաշվի առնելու նրանց համադրումը գիտելիքի հիմնված մոտեցումների հետ, որոնք կարող են ավելի բարելավել իրենց արդ Այս ուղղությամբ, այս աշխատանքը ներկայացնում է նոր շրջանակ, որը համադրում է նյարդային հաջորդականությամբ հիմնված տեքստի համառոտագրությունը, ինչպես նաև կառուցվածքը և սեմանտիկ հիմնված մեթոդոլոգիաները: Առաջարկված շրջանակը կարողանում է լուծել ոչ բառարանի կամ հազվադեպ բառերի խնդիրը, բարելավելով խորը սովորելու մոդելների արդյունքը: Ընդհանուր մեթոդոլոգիան հիմնված է գիտելիքի հիմնված պարունակության ընդհանուր ընդհանուր ընդհանուր տեսական մոդելի վրա և խորը ուսումնասիրության կանխատեսումների վրա վերացրական համառոտագրություններ ստեղծելու համար: Համակարգը կազմված է երեք կարևոր տարրերից: i) նախավերամշակման առաջադրանք, i) մեքենային ուսումնասիրության մեթոդոլոգիա և i) նախավերամշակման առաջադրանք: Նախավերամշակման գործընթացը գիտելիքների հիմնված մոտեցում է, որը հիմնված է օնտոլոգիական գիտելիքների ռեսուրսների վրա, բառերի զգացմունքի անբացատրություն և անվանված էության ճանաչելու վրա, միասին պարունակության ընդհանուր ընդհանուր ընթացքում, որը վերածում է Ուշադիր կոդեր-կոդեր ճարտարապետության խորը ուսումնասիրության մոդելը, որը ընդլայնվում է, որպեսզի հնարավորություն տա հաղթահարելու և ծածկության մեխանիզմներին, ինչպես նաև ուժեղացման ուսումնասիրության և վերափոխման հիմնված ճարտարապետություններին, ուսուցվում է տեքստի համառոտագրական զույգերի ընդհանուր տար Հաջորդ գործընթացը օգտագործում է գիտելիքը\nresources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form.  Երեք հայտնի տվյալների համակարգերի ընդլայնված փորձարկման գործընթացը գնահատում է առաջարկած շրջանակի հիմնական ասպեկտները, մինչդեռ ստացված արդյունքները ցույց են տալիս խոստացնող արդյունքներ, ստուգելով առաջարկած մոտեցության կայուն', 'fi': 'Nykyään suurin osa abstraktiivisen tekstiyhteenvedon alalla tehdyistä tutkimuksista keskittyy pelkästään neuropohjaisiin malleihin ottamatta huomioon niiden yhdistämistä tietoon perustuviin lähestymistapoihin, jotka voisivat parantaa niiden tehokkuutta entisestään. Tähän suuntaan tässä työssä esitellään uusi viitekehys, joka yhdistää sekvenssi-sekvenssiin neuropohjaisen tekstin yhteenvedon rakenne- ja semanttisiin menetelmiin. Ehdotetulla kehyksellä pystytään käsittelemään sanaston ulkopuolisia tai harvinaisia sanoja koskevaa ongelmaa ja parantamaan syväoppimisen mallien suorituskykyä. Kokonaismenetelmä perustuu hyvin määriteltyyn teoreettiseen malliin tietopohjaisesta sisällönyleistämisestä ja syväoppimisen ennusteista abstraktien yhteenvetojen tuottamiseksi. Kehys koostuu kolmesta avaintekijästä: i) esikäsittelytehtävästä, ii) koneoppimismenetelmästä ja iii) jälkikäsittelytehtävästä. Esiprosessointitehtävä on tietopohjainen lähestymistapa, joka perustuu ontologisiin tietoresursseihin, sanaaistin erotteluun ja nimettyjen entiteettien tunnistamiseen sekä sisällön yleistämiseen, joka muuttaa tavallisen tekstin yleiseksi muotoksi. Tarkkaan koodaaja-dekooderiarkkitehtuurin syväoppimismalli, jota laajennetaan mahdollistamaan selviytymis- ja peittomekanismi sekä vahvistus- ja muuntajapohjaiset arkkitehtuurit, on koulutettu teksti-yhteenvetoparien yleiseen versioon, joka oppii ennustamaan tiivistelmiä yleistetyssä muodossa. Jälkikäsittelytehtävässä hyödynnetään tietoa\nTekstin samankaltaisuusmenetelmiin perustuvat heuristiset algoritmit, joilla ennustetun yhteenvedon yleistetty versio muunnetaan lopulliseksi, ihmisluettavaksi muotoon. Laaja kokeellinen menettely kolmella suositulla aineistolla arvioi ehdotetun viitekehyksen keskeisiä näkökohtia, kun taas saadut tulokset osoittavat lupaavaa suorituskykyä vahvistaen ehdotetun lähestymistavan kestävyyden.', 'et': 'Tänapäeval keskendub enamik abstraktse teksti kokkuvõtte valdkonnas tehtud uuringutest üksnes neuraalsetele mudelitele, kaalumata nende kombinatsiooni teadmistepõhiste lähenemisviisidega, mis võiksid nende tõhusust veelgi suurendada. Selles suunas esitatakse käesolev töö uudset raamistikku, mis ühendab järjestusest järjestuseni neuropõhise teksti kokkuvõtliku koostamise struktuuri ja semantika meetoditega. Kavandatud raamistik on võimeline tegelema sõnavara või haruldaste sõnade probleemiga, parandades sügavõppe mudelite tulemuslikkust. Üldine metoodika põhineb hästi määratletud teoreetilisel mudelil teadmistepõhise sisu üldistamise ja sügavõppe prognooside kohta abstraktsete kokkuvõtete koostamiseks. Raamistik koosneb kolmest põhielementist: i) eeltöötlusülesanne, ii) masinõppe metoodika ja iii) järeltöötlusülesanne. Eeltöötlusülesanne on teadmistepõhine lähenemisviis, mis põhineb ontoloogilistel teadmiste ressurssidel, sõnatähenduse eristamisel ja nimetatud olemi tuvastamisel koos sisu üldistamisega, mis muudab tavalise teksti üldistatud vormiks. Tähelepanu kodeerija-dekooderi arhitektuuri sügavõppemudel, mida laiendatakse, et võimaldada toimetuleku- ja katvusmehhanismi, samuti tugevdusõppe ja transformaatoripõhiseid arhitektuure, on koolitatud teksti-kokkuvõtte paaride üldistatud versioonil, õppides prognoosima kokkuvõtteid üldises vormis. Järeltöötlusülesanne kasutab teadmisi\nTeksti sarnasuse meetoditel põhinevad heuristilised algoritmid, et muuta prognoositud kokkuvõtte üldine versioon lõplikuks inimloetavaks vormiks. Laiaulatuslik eksperimentaalne protseduur kolmel populaarsel andmekogumil hindab kavandatud raamistiku põhiaspekte, samas kui saadud tulemused näitavad paljulubavat tulemust, kinnitades kavandatud lähenemisviisi tugevust.', 'cs': 'Abstrakt V současné době se většina výzkumů prováděných v oblasti abstraktivního textového shrnutí zaměřuje pouze na neuronové modely, aniž bychom zvážili jejich kombinaci s přístupy založenými na znalostech, které by mohly dále zvýšit jejich efektivitu. V tomto směru práce představuje nový rámec, který kombinuje sekvenci-to-sekvence neuronově založené textové shrnutí spolu se strukturou a sémanticky založenými metodikami. Navržený rámec je schopen řešit problém mimo slovní zásobu nebo vzácných slov a zlepšit výkon modelů hlubokého učení. Celková metodika je založena na dobře definovaném teoretickém modelu zobecnění obsahu založeném na znalostech a predikcích hlubokého učení pro generování abstraktivních souhrnů. Rámec se skládá ze tří klíčových prvků: (i) úkolu předzpracování, (ii) metodiky strojového učení a (iii) úkolu po zpracování. Úkolem předzpracování je přístup založený na znalostech, založený na ontologických znalostních zdrojích, rozšiřování slovních smyslů a rozpoznávání pojmenovaných entit spolu s zobecněním obsahu, který transformuje běžný text do zobecněné formy. Model hlubokého učení s pozornou architekturou kodéru-dekodéru, který je rozšířen tak, aby umožnil zvládnutí a pokrytí mechanismu, stejně jako posílení učení a transformátorové architektury, je trénován na zobecněné verzi text-souhrnných párů, které se učí předpovídat souhrnné souhrny v obecné podobě. Úkol po zpracování využívá znalostí\nZdroje, vkládání slov, rozšíření slovních smyslů a heuristické algoritmy založené na metodách podobnosti textu s cílem transformovat zobecněnou verzi předpokládaného souhrnu do konečné, člověkem čitelné podoby. Rozsáhlý experimentální postup na třech populárních datových sadách hodnotí klíčové aspekty navrhovaného rámce, zatímco získané výsledky vykazují slibný výkon, což ověřuje robustnost navrhovaného přístupu.', 'jv': 'absolute Noudays, dibutuhé perusahaan sing dumadhi nèng kapan karo resampungan teks absolute Nang direction wiir, lan uwis menehi un barêng dumaten sing isin secanse-to-sekanse sener resumen ning sampeyan karo structural lan semanti-basa method. Laptop" and "Desktop Laptop" and "Desktop structural navigation Awak-procasa saiki wis diangkat-diangkat sing basa awak-dhuwi, sing basa supoyo ontrologke awak dhéwé, nglanggar kuwi tindakan untarané awak dhéwé, lan nganggo kesempatan sampeyan, lan nganggo perusahaan kuwi nggawe nguasakno deep Laptop\ngambar Punika sing perusahaan anyar tentang kanggo telu populer dadi sing rumangsa Aspek Where\'s the larang pangan', 'ha': "Ga baya a yanzu, mafi yawansu da aka aiko a cikin field masu ƙararin matsayin na kanrakati, yana fokus kan misãlai masu baka neura kawai, kuma bã da kula da komowarsu da hanyoyin da zane-ba'a, wanda zai iya ƙara fikancinsu. Daga wannan gefen, wannan aikin yana gaya wani firam na nowaya wanda ke haɗa masu saka-dubi'a-sequence na rubutun neural sami da metodi na rubutu da bakin semantic. An karɓi firam da aka faɗa yana iya iya iya shawara wa matsalar masu yin magana ba'a-magana ko da sauri, kuma yana ƙaranci aikin misalin da aka sanar da masu ƙari. Sura'a ɗabi'a ne a kan wata misãlin da aka ƙayyade mai kyau-defined theoretiske na ƙididdige cikin tsarin da aka danne shi a kan ilmi da kuma babu wani abu mai ƙaranci da za'a sami ƙararin da ba'a sani ba. An samo firam daga ƙanshi uku masu maɓalli:(i) wani aikin aiki mai gabatar da shirin aiki, (ii) wani metode mai amfani da mashine, da (i) wani aikin aiki mai bayan-aiki. Kayan aiki na gabatar da shirin aiki yana da wata hanyoyi a kan saniya, a kan asansa da maɓallin ilmi, yin rarrabẽwa ga magana, da kuma an ambaci sunan ganin shaidar abun, da kuma da mai ƙiƙiro maɓalli, yana musanya matsayin na ɗabi'a zuwa wani tsari mai gabatar da shi. An sanar da wani motsi na matsayin kode-kode-na'urar, wanda za'a faɗa ɗa shi dõmin ya iya amfani da kofi da tsari, da kuma a ƙarfafa wasu matsayin da aka sanar da shi da aka shige shi, an sanar da shi a wani version na jumla'ar nau'in rubutu-nau'in rubutu, kuma an sanar da ɗabi'a cikin tsarin mai jumla. Suna amfani da ilmi\nQXml Rukacin jarrabi mai shimfiɗawa a kan data ta sami uku, yana ƙaddara masu key aspects of firam ɗin da aka buƙata, kuma a lokacin da matsala suka nuna performance mai yiwuwa da ake yi wa'adi, yana gaskata tufãfin na hanyarwa da ake faɗi.", 'sk': 'Danes se večina raziskav na področju abstraktivnega povzetka besedila osredotoča samo na živčno osnovane modele, ne da bi upoštevali njihovo kombinacijo s pristopi na znanju, ki bi lahko še bolj izboljšali njihovo učinkovitost. V tej smeri je v tem delu predstavljen nov okvir, ki združuje povzetek besedila iz zaporedja do zaporedja, ki temelji na nevralni osnovi, skupaj s strukturo in semantično osnovanimi metodologijami. Predlagani okvir je sposoben obravnavati problem izven besedišča ali redkih besed in izboljšati učinkovitost modelov globokega učenja. Celotna metodologija temelji na dobro opredeljenem teoretičnem modelu generalizacije vsebin na znanju in napovedih globokega učenja za ustvarjanje abstraktivnih povzetkov. Okvir je sestavljen iz treh ključnih elementov: (i) naloge predobdelave, (ii) metodologije strojnega učenja in (iii) naloge po obdelavi. Predobdelava je na znanju temelječi pristop, ki temelji na ontoloških virih znanja, razjasnitvi besednega pomena in prepoznavanju imenovanih entitet, skupaj s posploševanjem vsebine, ki navadno besedilo pretvori v posplošeno obliko. Model globokega učenja pozorne arhitekture kodirnika-dekodirnika, ki je razširjen tako, da omogoča mehanizem obvladovanja in pokritosti, kot tudi ojačitveno učenje in arhitekture na podlagi transformatorjev, je usposobljen na splošni različici parov besedilo-povzetek, ki se uči napovedovati povzetke v splošni obliki. Naloga po obdelavi uporablja znanje\nVključevanje besed, razjasnitev besednega pomena in heuristični algoritmi, ki temeljijo na metodah podobnosti besedila, da bi posplošeno različico predvidenega povzetka pretvorili v končno, človeško berljivo obliko. Obsežen eksperimentalni postopek na treh priljubljenih podatkovnih nizih ocenjuje ključne vidike predlaganega okvira, pridobljeni rezultati pa kažejo obetavno delovanje, kar potrjuje robustnost predlaganega pristopa.', 'he': 'בימים אלה, רוב המחקרים שנערכו בשטח הסיכוי טקסט אסטרקטיבי מתמקדים בדוגמנים מבוססים על עצבים בלבד, מבלי לשקול את שילוב שלהם עם גישות מבוססים על ידע שיכולות לשפר עוד את היעילות שלהם. בכיוון הזה, העבודה הזו מציגה מסגרת חדשה שמשולבת מסגרת טקסט מבוססת ברצף לרצף לרצף המסגרת המוצעת מסוגלת להתמודד עם הבעיה של מילים מחוץ למילים או מילים נדירות, לשפר את ההופעה של דוגמני הלימוד העמוקים. המטדולוגיה הכללית מבוססת על מודל תיאורטי מוגדר היטב של הגנרליזציה של תוכן מבוסס על ידע וחזויות למידה עמוקה לייצור סדרות אסטרקטיביות. The framework is composed of three key elements: (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task.  המשימה הקדמית לעבודה היא גישה מבוססת על ידע, מבוססת על משאבי ידע אונטולוגיים, חוסר ביטוי מילים, והזיהוי של ישות בשם, יחד עם הגנרליזציה של תוכן, שמהפך טקסט רגיל לצורה כללית. מודל למידה עמוק של ארכיטקטורת קודד-פיקוד תשומת לב, שמרוחב כדי לאפשר מנגנון התמודדות וכיסוי כיסוי, כמו גם למידה תגבורת וארכיטקטורות מבוססת מעבר, מאומנת על גרסה כללית של זוגות קודם-טקסט, ללמוד לצפות בקיצורים בצורה כללית. המשימה לאחר העבודה משתמשת בידע\nמשאבים, תוספות מילים, ניתוח חוש מילים, ואלגוריטמים היוריסטיים מבוססים על שיטות דומות טקסט כדי לשנות את הגרסה המפורסמת של סכם צפוי לצורה סופית, אפשרית לקרוא אנושית. תהליך ניסוי רחב על שלושה קבוצות נתונים פופולריים מעריך היבטים המרכזים של המסגר המוצע, בעוד התוצאות המקבלות מראות ביצועים מבטיחים, מאשרים את החזקה של הגישה המוצעת.', 'bo': 'abstract Nowadays, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. འདིའི་གནས་སྟངས་འདིའི་ནང་དུ་ལས་ཀ་འདི་ལྟ་བུའི་གསར་བ་གྲངས་ཀ་ཞིག་སྟོན་པ་ཡིན་པས། The proposed framework is capable of dealing with the problem of out-of-vocabulary or rare words, improving the performance of the deep learning models. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries. ཝེབ་གཞུང་དེ་གཙོ་ཆེ་རྣམ་གྲངས་གསུམ་ལས་སྔོན་ལས་སྦྱོར་བྱ་རིམ་ཞིག་ཆགས་འདུག: (i)མ་ལག སྔོན་གྱིས་ལས་སྦྱོར་བྱས་པའི་བྱ A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form. Post-processing task utilizes knowledge\nresources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form. སྐད་ཆེན་གྱི་ཆ་འཕྲིན་ཡིག་ཆ་གསུམ་གྱི་ལག་ལེན་གྱི་སྒྲིག'}
{'en': 'The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification', 'ar': '(عدم) ملاءمة مقاييس التقييم التلقائي لتبسيط النص', 'pt': 'A (in)adequação das métricas de avaliação automática para simplificação de texto', 'es': 'La (in) idoneidad de las métricas de evaluación automática para la simplificación de textos', 'fr': "L'inadéquation des mesures d'évaluation automatique pour la simplification de texte", 'ja': 'テキスト簡略化のための自動評価指標の（非）適合性', 'zh': '自评指标简文本者(不)适用性', 'hi': 'पाठ सरलीकरण के लिए स्वत: मूल्यांकन मैट्रिक्स की (Un) उपयुक्तता', 'ru': '(Не)Пригодность метрик автоматической оценки для упрощения текста', 'ga': 'Oiriúnacht (Neamh)Méadracht Meastóireachta Uathoibríoch do Shimpliú Téacs', 'ka': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'it': "L'idoneità (Un)delle metriche di valutazione automatiche per la semplificazione del testo", 'hu': 'Az automatikus értékelési mércék (Un)alkalmassága a szöveg egyszerűsítésére', 'el': 'Η (μη)καταλληλότητα των μετρικών αυτόματης αξιολόγησης για απλοποίηση κειμένου', 'mk': 'Автоматска метрика за проценка на текстот', 'ml': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'ms': 'Kesesuaian Metrik Evaluasi Automatik untuk Simplifikasi Teks', 'kk': 'Мәтінді қарапайымдастыру (Қосымша)Suitability of Automatic Evaluation Metrics for Text Simplification', 'lt': 'Automatinio vertinimo metrikų tinkamumas tekstui supaprastinti', 'no': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'pl': 'Przydatność automatycznych metryków oceny do uproszczenia tekstu', 'ro': '(Un)Adecvarea parametrilor de evaluare automată pentru simplificarea textului', 'mn': 'Текст хялбарчлалын автоматтын үнэлэх метрик', 'sr': 'Допустимост метрика автоматичне оценке за једностављење текста', 'si': 'Suitability of Auto evalution Metrics for Text Simplication', 'so': 'The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification', 'ta': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'mt': 'L-adegwatezza tal-Metriċi tal-Evalwazzjoni Awtomatika għas-Simplifikazzjoni tat-Test', 'sv': '(Un)Lämpligheten hos automatiska utvärderingsmetoder för textförenkling', 'ur': 'The (Un) Suitability of Automatic Evaluation Metrics for Text Simplification', 'vi': '(Một)Đối chiếu với đo tốc độ đánh giá tự động cho việc làm đơn giản văn bản', 'uz': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'bg': 'Пригодността на измервателните показатели за автоматична оценка за опростяване на текста', 'hr': 'Prikladnost automatske mjere procjene za pojednostavljenje teksta', 'da': '(Un)egnetheden af automatiske evalueringsmålinger til tekstforenkling', 'nl': 'De (on)geschiktheid van automatische evaluatiestatistieken voor tekstvereenvoudiging', 'fa': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'de': 'Die (Un)Eignung von automatischen Auswertungskennzahlen zur Textvereinfachung', 'id': 'Kecocokan Metrik Evaluasi Otomatis untuk Simplifikasi Teks', 'ko': '텍스트 단순화에 대한 지표의 적용성 자동 평가', 'sw': 'Suability of Automatic Evaluation Metrics for Simplification Text', 'af': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'sq': 'Përshtatshmëria e Metrikës Automatike të Vlerësimit për Simplifikimin e Tekstit', 'tr': 'Metin Basitlendirmek üçin (Un)Suitability of Automatic Evaluation Metrics for Text Simplification', 'hy': 'Comment', 'am': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'bs': 'Sposobnost automatske mjere procjene za pojednostavljenje teksta', 'az': 'Suitability of Automatic Evaluation Metrics for Text Simplification', 'bn': 'স্বয়ংক্রিয়ভাবে Evaluation Metrics for Text Simplication', 'ca': "L'adequació dels mètrics d'evaluació automàtica per a simplificar el text", 'cs': 'Vhodnost metrik automatického vyhodnocování pro zjednodušení textu', 'et': 'Automaatsete hindamismeetrite (mitte)sobivus teksti lihtsustamiseks', 'fi': 'Automaattisten arviointimetrien (ei)soveltuvuus tekstin yksinkertaistamiseen', 'he': 'התאימות של מטריקת הערכה אוטומטית לפשטות טקסט', 'sk': 'Ustreznost meril avtomatskega ocenjevanja za poenostavitev besedila', 'ha': 'Suitabilities of Authematic evaluation Metrics for Text Similarity', 'bo': 'The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification', 'jv': 'Suitness of Automatically Validity Metric for Text Simplification'}
{'en': 'Abstract In order to simplify sentences, several rewriting operations can be performed, such as replacing complex words per simpler synonyms, deleting unnecessary information, and splitting long sentences. Despite this multi-operation nature, evaluation of automatic simplification systems relies on metrics that moderately correlate with human judgments on the simplicity achieved by executing specific operations (e.g., simplicity gain based on lexical replacements). In this article, we investigate how well existing metrics can assess sentence-level simplifications where multiple operations may have been applied and which, therefore, require more general simplicity judgments. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity. Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics’ scores and human judgments across three dimensions : the perceived simplicity level, the system type, and the set of references used for computation. We show that these three aspects affect the correlations and, in particular, highlight the limitations of commonly used operation-specific metrics. Finally, based on our findings, we propose a set of recommendations for automatic evaluation of multi-operation simplifications, suggesting which metrics to compute and how to interpret their scores.', 'ar': 'الخلاصة من أجل تبسيط الجمل ، يمكن إجراء العديد من عمليات إعادة الكتابة ، مثل استبدال الكلمات المعقدة لكل مرادفات أبسط ، وحذف المعلومات غير الضرورية ، وتقسيم الجمل الطويلة. على الرغم من هذه الطبيعة متعددة العمليات ، يعتمد تقييم أنظمة التبسيط التلقائي على المقاييس التي ترتبط بشكل معتدل بالأحكام البشرية على البساطة التي يتم تحقيقها من خلال تنفيذ عمليات محددة (على سبيل المثال ، اكتساب البساطة على أساس الاستبدالات المعجمية). في هذه المقالة ، نحقق في مدى جودة المقاييس الحالية في تقييم التبسيط على مستوى الجملة حيث قد يتم تطبيق عمليات متعددة ، وبالتالي ، تتطلب أحكامًا أكثر بساطة عامة. لذلك ، نقوم أولاً بجمع مجموعة بيانات جديدة وأكثر موثوقية لتقييم ارتباط المقاييس والأحكام البشرية للبساطة الكلية. ثانيًا ، نجري أول تقييم تلوي للمقاييس التلقائية في تبسيط النص ، باستخدام مجموعة بياناتنا الجديدة (وغيرها من البيانات الموجودة) لتحليل تباين الارتباط بين درجات المقاييس والأحكام البشرية عبر ثلاثة أبعاد: مستوى البساطة المدركة ، نوع النظام ومجموعة المراجع المستخدمة في الحساب. نوضح أن هذه الجوانب الثلاثة تؤثر على الارتباطات ، وعلى وجه الخصوص ، نسلط الضوء على قيود المقاييس الشائعة الاستخدام الخاصة بالعملية. أخيرًا ، بناءً على النتائج التي توصلنا إليها ، نقترح مجموعة من التوصيات للتقييم التلقائي لتبسيط العمليات المتعددة ، مع اقتراح المقاييس التي يجب حسابها وكيف\nلتفسير درجاتهم.', 'fr': "Résumé Afin de simplifier les phrases, plusieurs opérations de réécriture peuvent être effectuées, telles que le remplacement de mots complexes par des synonymes plus simples, la suppression d'informations inutiles et la division de phrases longues. Malgré cette nature multi-opérations, l'évaluation des systèmes de simplification automatique repose sur des mesures qui sont modérément corrélées avec les jugements humains sur la simplicité obtenue par l'exécution d'opérations spécifiques (par exemple, gain de simplicité basé sur des remplacements lexicaux). Dans cet article, nous examinons dans quelle mesure les mesures existantes peuvent évaluer les simplifications au niveau de la phrase lorsque plusieurs opérations peuvent avoir été appliquées et qui, par conséquent, nécessitent des jugements de simplicité plus généraux. Pour cela, nous collectons d'abord un nouvel ensemble de données plus fiables pour évaluer la corrélation entre les métriques et les jugements humains d'une simplicité globale. Ensuite, nous effectuons la première méta-évaluation des mesures automatiques dans la simplification de texte, en utilisant notre nouvel ensemble de données (et d'autres données existantes) pour analyser la variation de la corrélation entre les scores des métriques et les jugements humains à travers trois dimensions\xa0: le niveau de simplicité perçu, le type de système et l'ensemble des références utilisées pour le calcul. Nous montrons que ces trois aspects affectent les corrélations et, en particulier, soulignons les limites des métriques spécifiques aux opérations couramment utilisées. Enfin, sur la base de nos résultats, nous proposons un ensemble de recommandations pour l'évaluation automatique des simplifications multi-opérations, suggérant quelles métriques calculer et comment\npour interpréter leurs scores.", 'ja': '要約文を簡略化するために、より単純な代名詞ごとに複雑な単語を置き換えたり、不要な情報を削除したり、長い文を分割したりするなど、いくつかの書き換え操作を行うことができます。 このような多動作性にもかかわらず、自動簡素化システムの評価は、特定の動作を実行することによって達成される簡素化（例えば、語彙置換に基づく簡素化ゲイン）に関する人間の判断と適度に相関するメトリクスに依存する。 この記事では、複数の操作が適用された可能性があり、したがってより一般的な簡易性の判断を必要とする文レベルの簡易化を、既存の指標がどの程度うまく評価できるかを調査します。 そのために、私たちはまず、総合的な単純さの指標と人間の判断の相関関係を評価するための、より信頼性の高い新しいデータセットを収集します。 第二に、テキスト簡略化における自動指標の最初のメタ評価を行い、新しいデータセット（および他の既存のデータ）を使用して、指標のスコアと人間の判断との間の相関関係の変動を分析します。これは、認識された単純化レベル、システムタイプ、および計算に使用される参照のセットです。 これらの3つの側面が相関関係に影響を与え、特に一般的に使用されるオペレーション固有の指標の制限を強調することを示しています。 最後に、調査結果に基づいて、マルチオペレーションの簡素化の自動評価のための一連の推奨事項を提案し、どの指標を計算するか、どのように計算するかを提案します。\n彼らのスコアを解釈することができます。', 'pt': 'Resumo Para simplificar frases, várias operações de reescrita podem ser realizadas, como substituir palavras complexas por sinônimos mais simples, excluir informações desnecessárias e dividir frases longas. Apesar dessa natureza multioperacional, a avaliação de sistemas de simplificação automática depende de métricas que se correlacionam moderadamente com julgamentos humanos sobre a simplicidade alcançada pela execução de operações específicas (por exemplo, ganho de simplicidade com base em substituições lexicais). Neste artigo, investigamos quão bem as métricas existentes podem avaliar simplificações em nível de sentença onde várias operações podem ter sido aplicadas e que, portanto, exigem julgamentos de simplicidade mais gerais. Para isso, primeiro coletamos um conjunto de dados novo e mais confiável para avaliar a correlação de métricas e julgamentos humanos de simplicidade geral. Em segundo lugar, realizamos a primeira meta-avaliação de métricas automáticas no Text Simplification, usando nosso novo conjunto de dados (e outros dados existentes) para analisar a variação da correlação entre as pontuações das métricas e os julgamentos humanos em três dimensões: o nível de simplicidade percebido, o tipo de sistema e o conjunto de referências usadas para computação. Mostramos que esses três aspectos afetam as correlações e, em particular, destacam as limitações das métricas específicas de operação comumente usadas. Por fim, com base em nossas descobertas, propomos um conjunto de recomendações para avaliação automática de simplificações multioperacionais, sugerindo quais métricas computar e como\ninterpretar suas pontuações.', 'es': 'Resumen Para simplificar las oraciones, se pueden realizar varias operaciones de reescritura, como reemplazar palabras complejas por sinónimos más simples, eliminar información innecesaria y dividir oraciones largas. A pesar de esta naturaleza multioperativa, la evaluación de los sistemas de simplificación automática se basa en métricas que se correlacionan moderadamente con los juicios humanos sobre la simplicidad lograda al ejecutar operaciones específicas (por ejemplo, la ganancia de simplicidad basada en reemplazos léxicos). En este artículo, investigamos qué tan bien las métricas existentes pueden evaluar las simplificaciones a nivel de oración en las que se pueden haber aplicado múltiples operaciones y que, por lo tanto, requieren juicios de simplicidad más generales. Para ello, primero recopilamos un conjunto de datos nuevo y más fiable para evaluar la correlación de las métricas y los juicios humanos de una simplicidad general. En segundo lugar, realizamos la primera metaevaluación de métricas automáticas en Simplificación de textos, utilizando nuestro nuevo conjunto de datos (y otros datos existentes) para analizar la variación de la correlación entre las puntuaciones de las métricas y los juicios humanos en tres dimensiones: el nivel de simplicidad percibido, el tipo de sistema y el conjunto de referencias utilizadas para el cálculo. Mostramos que estos tres aspectos afectan a las correlaciones y, en particular, destacamos las limitaciones de las métricas específicas de la operación comúnmente utilizadas. Finalmente, en función de nuestros hallazgos, proponemos un conjunto de recomendaciones para la evaluación automática de las simplificaciones de múltiples operaciones, que sugieren qué métricas calcular y cómo\npara interpretar sus partituras.', 'zh': '摘要为简句,可行数重写,如将杂单词代为更简之同义词,删去浮息及拆分长句。 虽有此多操,而自简之评赖于人特定操作之指标(,盖词法易性之益)。 本文之中,考今指标评句简化,其间可应用数操作,故须更简断。 先收一新之数集,以料指标人之简相关性。 其次,于文本简化中自指标为首元评估,用我新数集(及他见数)以析之指标分数与人伦断三维度之相关性变:知者简性水平,系统类型用算之参考集。 此三者相关性,特为常用特定于操指标之局限性。 最后,据我们的发现,我们发出了一朋自己评料多操作简化的建议,建议计算哪些指标及如何计算。\n以解其分数。', 'hi': 'वाक्यों को सरल बनाने के लिए, कई पुनर्लेखन संचालन किए जा सकते हैं, जैसे कि जटिल शब्दों को प्रति सरल पर्यायवाची शब्द ों को बदलना, अनावश्यक जानकारी को हटाना और लंबे वाक्यों को विभाजित करना। इस बहु-संचालन प्रकृति के बावजूद, स्वचालित सरलीकरण प्रणालियों का मूल्यांकन मैट्रिक्स पर निर्भर करता है जो विशिष्ट संचालन (जैसे, लेक्सिकल प्रतिस्थापन के आधार पर सादगी लाभ) को निष्पादित करके प्राप्त सादगी पर मानव निर्णयों के साथ मामूली रूप से सहसंबंधित है। इस लेख में, हम जांच करते हैं कि मौजूदा मीट्रिक कितनी अच्छी तरह से वाक्य-स्तर के सरलीकरण का आकलन कर सकते हैं जहां कई संचालन लागू किए जा सकते हैं और इसलिए, अधिक सामान्य सादगी निर्णयों की आवश्यकता होती है। इसके लिए, हम पहले समग्र सादगी के मीट्रिक और मानव निर्णयों के सहसंबंध का मूल्यांकन करने के लिए एक नया और अधिक विश्वसनीय डेटा सेट एकत्र करते हैं। दूसरा, हम तीन आयामों में मैट्रिक्स के स्कोर और मानव निर्णयों के बीच सहसंबंध की भिन्नता का विश्लेषण करने के लिए हमारे नए डेटा सेट (और अन्य मौजूदा डेटा) का उपयोग करके पाठ सरलीकरण में स्वचालित मीट्रिक का पहला मेटा-मूल्यांकन करते हैं: कथित सादगी स्तर, सिस्टम प्रकार, और गणना के लिए उपयोग किए जाने वाले संदर्भों का सेट। हम दिखाते हैं कि ये तीन पहलू सहसंबंधों को प्रभावित करते हैं और विशेष रूप से, आमतौर पर उपयोग किए जाने वाले ऑपरेशन-विशिष्ट मीट्रिक की सीमाओं को उजागर करते हैं। अंत में, हमारे निष्कर्षों के आधार पर, हम बहु-संचालन सरलीकरण के स्वचालित मूल्यांकन के लिए सिफारिशों का एक सेट प्रस्तावित करते हैं, यह सुझाव देते हुए कि कौन से मीट्रिक की गणना की जाए और कैसे\nउनके स्कोर की व्याख्या करने के लिए।', 'ru': 'Реферат Чтобы упростить предложения, можно выполнить несколько операций перезаписи, таких как замена сложных слов более простыми синонимами, удаление ненужной информации и разделение длинных предложений. Несмотря на такой многофункциональный характер, оценка автоматических систем упрощения основана на показателях, которые умеренно коррелируют с человеческими суждениями, на простоте, достигаемой путем выполнения конкретных операций (например, повышение простоты на основе лексических замен). В этой статье мы исследуем, насколько хорошо существующие метрики могут оценивать упрощения на уровне предложений, где может быть применено несколько операций, и которые, следовательно, требуют более общих оценок простоты. Для этого мы сначала собираем новый и более надежный набор данных для оценки корреляции метрик и человеческих суждений общей простоты. Во-вторых, мы проводим первую метаоценку автоматических метрик в Text Simplification, используя наш новый набор данных (и другие существующие данные) для анализа вариации корреляции между оценками метрик и человеческими суждениями по трем измерениям: воспринимаемый уровень простоты, тип системы и набор ссылок, используемых для расчета. Мы показываем, что эти три аспекта влияют на корреляции и, в частности, подчеркиваем ограничения широко используемых метрик, специфичных для конкретной операции. Наконец, основываясь на наших выводах, мы предлагаем набор рекомендаций для автоматической оценки мультиоперационных упрощений, предлагая, какие метрики вычислять и как\nинтерпретировать свои оценки.', 'ga': 'Coimriú Chun abairtí a shimpliú, is féidir roinnt oibríochtaí athscríobh a dhéanamh, mar shampla focail chasta a ionadú de réir comhchiallaigh níos simplí, faisnéis nach bhfuil gá léi a scriosadh, agus abairtí fada a roinnt. In ainneoin an chineál iloibríochta seo, braitheann meastóireacht ar chórais uathshimplithe ar mhéadracht a bhfuil comhghaolmhaireacht measartha acu le breithiúnais dhaonna ar an tsimplíocht a baineadh amach trí oibríochtaí sonracha a chur i gcrích (m.sh. gnóthachan simplíochta bunaithe ar athchur foclóireachta). San Airteagal seo, déanaimid imscrúdú ar cé chomh maith agus is féidir le méadracht atá ann cheana simplithe ar leibhéal na pianbhreithe a mheas nuair a d’fhéadfaí iloibríochtaí a bheith curtha i bhfeidhm agus a dteastaíonn, mar sin, breithiúnais simplíochta níos ginearálta. Chuige sin, bailímid ar dtús tacar sonraí nua agus níos iontaofa chun measúnú a dhéanamh ar chomhghaolmhaireacht méadrachta agus breithiúnais dhaonna ar shimplíocht fhoriomlán. Ar an dara dul síos, déanaimid an chéad mheit-mheastóireacht ar mhéadracht uathoibríoch i Simpliú Téacs, ag baint úsáide as ár dtacar sonraí nua (agus sonraí eile atá ann cheana) chun anailís a dhéanamh ar éagsúlacht na comhghaolmhaireachta idir scóir méadrachta agus breithiúnais dhaonna thar thrí thoise: an leibhéal simplíochta a bhraitear, an cineál córais, agus an tsraith tagairtí a úsáidtear don ríomh. Léirímid go mbíonn tionchar ag na trí ghné seo ar na comhghaolta agus, go háirithe, leagtar béim ar na teorainneacha a bhaineann le méadracht a bhaineann go sonrach le hoibríocht go minic. Ar deireadh, bunaithe ar ár dtorthaí, molaimid sraith moltaí le haghaidh meastóireachta uathoibríoch ar shimplithe iloibríochta, ag moladh cé na méadrachtaí atá le ríomh agus conas\na gcuid scóir a léirmhíniú.', 'el': 'Περίληψη Προκειμένου να απλοποιηθούν οι προτάσεις, μπορούν να εκτελεστούν διάφορες λειτουργίες επαναγραφής, όπως η αντικατάσταση σύνθετων λέξεων ανά απλούστερα συνώνυμα, η διαγραφή περιττών πληροφοριών και ο διαχωρισμός μεγάλων προτάσεων. Παρά την πολυλειτουργική αυτή φύση, η αξιολόγηση των συστημάτων αυτόματης απλοποίησης βασίζεται σε μετρήσεις που συσχετίζονται μετρίως με τις ανθρώπινες κρίσεις σχετικά με την απλότητα που επιτυγχάνεται με την εκτέλεση συγκεκριμένων λειτουργιών (π.χ. κέρδος απλότητας με βάση λεξικές αντικαταστάσεις). Σε αυτό το άρθρο, διερευνούμε πόσο καλά οι υπάρχουσες μετρήσεις μπορούν να αξιολογήσουν απλοποιήσεις σε επίπεδο πρότασης όπου μπορεί να έχουν εφαρμοστεί πολλαπλές λειτουργίες και οι οποίες, ως εκ τούτου, απαιτούν πιο γενικές εκτιμήσεις απλότητας. Για αυτό, συλλέγουμε πρώτα ένα νέο και πιο αξιόπιστο σύνολο δεδομένων για την αξιολόγηση της συσχέτισης των μετρήσεων και των ανθρώπινων κρίσεων συνολικής απλότητας. Δεύτερον, διεξάγουμε την πρώτη μετα-αξιολόγηση των αυτόματων μετρήσεων στην απλοποίηση κειμένου, χρησιμοποιώντας το νέο μας σύνολο δεδομένων (και άλλα υπάρχοντα δεδομένα) για να αναλύσουμε την διακύμανση της συσχέτισης μεταξύ των βαθμολογιών των μετρήσεων και των ανθρώπινων κρίσεων σε τρεις διαστάσεις: το αντιληπτό επίπεδο απλότητας, τον τύπο συστήματος και το σύνολο των αναφορών που χρησιμοποιούνται για τον υπολογισμό. Δείχνουμε ότι αυτές οι τρεις πτυχές επηρεάζουν τους συσχετισμούς και, ειδικότερα, αναδεικνύουν τους περιορισμούς των κοινώς χρησιμοποιούμενων μετρήσεων συγκεκριμένων λειτουργιών. Τέλος, με βάση τα πορίσματά μας, προτείνουμε ένα σύνολο συστάσεων για την αυτόματη αξιολόγηση των απλουστεύσεων πολλαπλών λειτουργιών, προτείνοντας ποιες μετρήσεις πρέπει να υπολογιστούν και πώς\nνα ερμηνεύουν τα σκορ τους.', 'it': "Per semplificare le frasi, è possibile eseguire diverse operazioni di riscrittura, come la sostituzione di parole complesse per sinonimi più semplici, l'eliminazione di informazioni inutili e la divisione di frasi lunghe. Nonostante questa natura multi-operativa, la valutazione dei sistemi di semplificazione automatica si basa su metriche moderatamente correlate ai giudizi umani sulla semplicità raggiunta dall'esecuzione di operazioni specifiche (ad esempio, guadagno di semplicità basato su sostituzioni lessicali). In questo articolo, analizziamo come le metriche esistenti possano valutare le semplificazioni a livello di frase in cui possono essere state applicate più operazioni e che, quindi, richiedono giudizi di semplicità più generali. Per questo, raccogliamo innanzitutto un nuovo e più affidabile set di dati per valutare la correlazione tra metriche e giudizi umani di semplicità generale. In secondo luogo, conduciamo la prima meta-valutazione delle metriche automatiche in Text Simplification, utilizzando il nostro nuovo set di dati (e altri dati esistenti) per analizzare la variazione della correlazione tra punteggi delle metriche e giudizi umani in tre dimensioni: il livello di semplicità percepito, il tipo di sistema e l'insieme di riferimenti utilizzati per il calcolo. Mostriamo che questi tre aspetti influenzano le correlazioni e, in particolare, evidenziano i limiti delle metriche specifiche delle operazioni comunemente utilizzate. Infine, sulla base dei nostri risultati, proponiamo una serie di raccomandazioni per la valutazione automatica delle semplificazioni multi-operazione, suggerendo quali metriche calcolare e come\nper interpretare i loro punteggi.", 'ka': 'აბსტრაქტიკის გამოსახულებლად, რამდენიმე მონაცემები შეიძლება გავაკეთოთ, როგორც კომპლექტური სიტყვების შეცვლა უფრო სუნონიმე სინონიმში, უნდა უნდა ინფორმაციას წაშლა ამ მრავალ პროგრამის სისტემის ავტომატური გამოყენების განსაზღვრება იქნება მეტრიკაზე, რომელიც მეტრიკაში ადამიანის განსაზღვრებით, რომელიც განსაზღვრებული განსაზღვრებით განსაზღვრებული პროგრამის გამოყენებაში (მაგალითად, ლექ ამ წილაკში, ჩვენ შევხედავთ თუ რამდენიმე საკმაოდ მსგავსი მეტრიკის შესაძლებელია გაუმუშაოთ სიტყვების განხორცილება, სადაც მრავალი операциები შესაძლებელია მომხმარება და რა ამისთვის, ჩვენ პირველად შევქმნით ახალი და უფრო დარწმუნებელი მონაცემები, რომელსაც მეტრიკის და ადამიანის საუკეთესებების კორელაციას გავამუშავებთ. მეორე, ჩვენ ტექსტის გამოყენებაში ავტომატური მეტრიკის პირველი მეტარა გავაკეთებთ, ჩვენი ახალი მონაცემები (და სხვა მონაცემები) გამოყენებთ, რომ გავაკეთებთ მეტრიკის მონაცემების და ადამიანის გავაკეთებების განსხვავების განსხვავების განსხვავება სამი განსხვავებ ჩვენ ჩვენ აჩვენებთ, რომ ეს სამი აპექტირები კორელაციების შესახებ და, განსაკუთრებით, განსაკუთრებით, გამოყენებული პერაციის განსაკუთრებული მეტრიკის ზომილებები საბოლოოდ, ჩვენი შესაძლებლობის ბაზაზე, ჩვენ მინდომენეთ მრავალური პროგრამის ავტომატური განსაზღვრებისთვის შესაძლებლობა, რომელსაც მეტრიკის გამომუშავება და როგორ გამო\nმათი შედეგების გარგება.', 'hu': 'Absztrakt A mondatok egyszerűsítése érdekében több újraírási műveletet is végezhetünk, mint például komplex szavak egyszerűbb szinonimákra történő cseréje, felesleges információk törlése és hosszú mondatok felosztása. Ennek ellenére az automatikus egyszerűsítési rendszerek értékelése olyan mérőszámokon alapul, amelyek mérsékelten korrelálnak az egyes műveletek végrehajtásával elért egyszerűségre vonatkozó emberi ítéletekkel (pl. egyszerűsítés lexikális helyettesítéseken alapuló). Ebben a cikkben azt vizsgáljuk, hogy a meglévő mutatók milyen jól értékelik a mondatszintű egyszerűsítéseket, amikor több műveletet alkalmaztak, és amelyek ezért általánosabb egyszerűségi ítéletet igényelnek. Ehhez először egy új és megbízhatóbb adatkészletet gyűjtünk össze a mutatók és az emberi megítélések összefüggésének értékeléséhez. Másodszor, elvégezzük az automatikus mutatók első metaértékelését a Text Simplification alkalmazásban, az új adatkészletünk (és más meglévő adatok) felhasználásával elemezzük a mutatók pontszáma és az emberi ítéletek közötti korreláció változását három dimenzióban: az észlelt egyszerűségi szint, a rendszertípus és a számításhoz használt referenciakészlet. Megmutatjuk, hogy ez a három szempont befolyásolja a korrelációkat, és különösen kiemeljük a gyakran használt műveletspecifikus mutatók korlátait. Végezetül, megállapításaink alapján javaslatokat teszünk a többműveleti egyszerűsítések automatikus értékelésére, javaslatokat adva, hogy mely mutatókat számítsunk és hogyan\nhogy értelmezzék a pontszámaikat.', 'ms': 'Abstrakt Untuk mempermudahkan kalimat, beberapa operasi tulisan semula boleh dilakukan, seperti menggantikan perkataan kompleks per sinonim sederhana, menghapuskan maklumat tidak diperlukan, dan membahagi kalimat panjang. Walaupun sifat berbilang-operasi ini, penilaian sistem pemadaman automatik bergantung pada metrik yang secara moderat berkorrelasi dengan penilaian manusia tentang kemudahan yang dicapai dengan melaksanakan operasi khusus (cth., penilaian kemudahan berdasarkan penggantian leksikal). Dalam artikel ini, kami menyelidiki betapa baik metrik yang wujud boleh menilai pemudahan tahap kalimat di mana operasi berbilang mungkin telah dilaksanakan dan yang, oleh itu, memerlukan penilaian kemudahan yang lebih umum. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity.  Kedua, kami melakukan meta-penilaian pertama metrik automatik dalam Simplifikasi Teks, menggunakan set data baru kami (dan data yang ada lain) untuk menganalisis variasi korelasi antara skor metrik dan penilaian manusia melalui tiga dimensi: aras kesederhanaan yang diduga, jenis sistem, dan set rujukan yang digunakan untuk pengiraan. Kami menunjukkan bahawa tiga aspek ini mempengaruhi korelasi dan, terutama, menyatakan keterangan metrik yang biasa digunakan secara spesifik operasi. Akhirnya, berdasarkan penemuan kami, kami cadangkan set cadangan untuk penilaian automatik pemudahan operasi berbilang, menyarankan metrik mana untuk dikira dan bagaimana\nuntuk menerangkan skor mereka.', 'kk': 'Сөздерді қарапайым көшірмелеу үшін бірнеше қайта жазу әрекеттері орындалады, мысалы, қарапайым синонимдерде комплекс сөздерді алмастыру, керек мәліметті өшіру және ұзын сөздерді бөлу үшін. Бұл көп операциялық табиғатқа қарамастан, автоматты қарапайым жүйелердің оқиғаларын бағалау керек метрикаларына тәуелді, адамдардың оқиғаларының қарапайымдылығын орындау үшін қарапайым түсініктеріне сәйкес келеді (мысалы,  Бұл мақалада, біз бірнеше әрекеттерді қолдану үшін бірнеше әрекеттер қолданылатын және олардың жалпы қарапайым қарапайым түсініктерін қанша жақсы метрикалық түсініктерді тексеруге болады. Бұл үшін біріншіден біріншіден метрикалық және адамдардың жалпы қарапайымдылығын бағалау үшін жаңа және сенімді деректерді жинақтаймыз. Екіншіден, біз мәтінді қарапайым көмегімен, жаңа деректер жиынымыз (және басқа бар деректер) менен, метрикалық нөмірлері мен адамдардың шешімдері арасындағы айырмашылығын анализ үш өлшемі бойынша, қарапайым деңгейі, жүйе түрі мен есептеу үшін қолданылатын сілт Біз бұл үш аспекттердің көмегімен қолданылған әрекеттердің шектеулерін көрсетеді. Соңында, біздің табуымыздың негізінде біз көптеген операциялық қарапайымдарын автоматты түрде оқиға алу үшін бірнеше рекомендацияларды ұсынамыз, қандай метрикалық есептеу және қалай о\nолардың нәтижелерін түсіндіру үшін.', 'lt': "Abstraktas Siekiant supaprastinti sakinius, galima atlikti keletą perskaičiavimo operacijų, pavyzdžiui, pakeisti sudėtingus žodžius paprastesniais sinonimiais, išbraukti nereikalingą informaciją ir padalyti ilgus sakinius. Nepaisant šio daugiafunkcinio pobūdžio, automatinio supaprastinimo sistemų vertinimas grindžiamas metriniais rodikliais, kurie vidutiniškai koreliuoja su žmogaus sprendimais dėl paprastumo, pasiekto vykdant konkrečias operacijas (pvz., paprastumo didinimas, pagrįstas leksiniais pakeitimais). Šiame straipsnyje tiriame, kaip gerai esami rodikliai gali įvertinti bausmės supaprastinimą, kai galėjo būti taikomos kelios operacijos ir todėl reikalingi bendresni paprastesni sprendimai. Todėl pirmiausia renkame naują ir patikimesnį duomenų rinkinį, skirtą įvertinti metrinių ir žmogiškųjų sprendimų bendram paprastumui koreliaciją. Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics' scores and human judgments across three dimensions: the perceived simplicity level, the system type, and the set of references used for computation.  Mes rodome, kad šie trys aspektai daro įtaką koreliacijoms ir ypač pabrėžia dažnai naudojamų konkrečiai veiklai skirtų metrinių rodiklių apribojimus. Galiausiai, remdamiesi savo išvadomis, siūlome rekomendacijas automatiškai įvertinti įvairių operacijų supaprastinimus, kuriose siūloma, kokius rodiklius apskaičiuoti ir kaip\naiškinti savo rezultatus.", 'no': 'Abstrakt For å forenkla setningar kan fleire omskrivingsoperasjonar utførast, slik som byt ut komplekse ord per enklare synonym, sletta unnecessare informasjon og dele lang setningar. Til tross av denne fleire operasjonsnaturen, evalueringa av automatiske forenklingssystemet er avhengig av metrikar som modert korrelatert med menneske sprøytebrukar på enkeltet som er oppretta ved køyring av spesifikke operasjonar (f.eks. enkeltvaring basert på leksiske erstatningar). I denne artikkelen undersøker vi kor godt eksisterande metrikar kan vurdere forenklingar for setningsnivå der fleire operasjonar kan ha brukt, og derfor krev meir generelle enkelte uttrykk. For det samler vi først eit nytt og meir tiltruleg data set for å evaluera korrelasjonen av metrikar og menneske sprøytebrukar av overalt enkelt. Andre, vi gjer den første metaevalueringa av automatiske metrikar i tekst-eininga, ved hjelp av våre nye datasett (og andre eksisterande data) for å analysera variasjonen av korrelasjonen mellom metriske poeng og menneske sprøytebrukar over tre dimensjonar: den oppfatte enkelhetsnivå, systemtypen og settet referanser som vert brukt for rekninga. Vi viser at desse tre aspektene påvirkar korrelasjonane og spesielt markerer grensene for vanleg brukte operasjonsspesifikke metrikar. Etter slutt, basert på oppdagingane våre, foreslår vi eit sett anbefalingar for automatisk evaluering av fleire operasjonar-forenklingar, som foreslår kva metrikn skal rekna ut og korleis\nfor å tolka scorene sine.', 'ml': 'വാക്കുകള്\u200d എളുപ്പമാക്കുവാന്\u200d വേണ്ടി അസ്ട്രാക്റ്റ് ചെയ്യുക, പല പുനരേഖകളും പ്രവര്\u200dത്തിപ്പിക്കുവാന്\u200d സാധിക്കുന്നു, എളുപ്പമുള്ള വാക് ഈ പല പ്രവര്\u200dത്തനങ്ങളുടെ പ്രകൃതിയാണെങ്കിലും, സ്വയം എളുപ്പമുള്ള സിസ്റ്റമുള്ള മെട്രിക്കങ്ങളുടെ വിശദീകരണങ്ങള്\u200d ആശ്രയിച്ചിരിക്കുന്നു. പ്രത്യേക പ്രവര്\u200dത്തനങ്ങള്\u200d നടത് ഈ ലിപ്പോര്\u200dട്ടില്\u200d, നിലവിലുള്ള മെട്രിക്കുകള്\u200d എത്ര നന്നായി വിധിക്കുന്നുവെന്ന് ഞങ്ങള്\u200d അന്വേഷിക്കുന്നു. പല പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രയോഗിക അതിനു വേണ്ടി, നമ്മള്\u200d ആദ്യം ഒരു പുതിയ വിശ്വസ്തനായ ഡേറ്റാ സെറ്റ് ചേര്\u200dക്കുന്നു. മെട്രിക്കുകളുടെയും മനുഷ്യരുടെയും ബന്ധങ് രണ്ടാമതായി, നമ്മുടെ പുതിയ വിവരങ്ങളുടെ (മറ്റുള്ള ഡേറ്റാ സജ്ജീകരണങ്ങളും) ഉപയോഗിച്ച് മെട്രിക്സിന്റെ സ്കോര്\u200dസിന്റെയും മനുഷ്യരുടെയും വിധികള്\u200dക്കുമിടയിലുള്ള ബന്ധം വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d ആദ് We show that these three aspects affect the correlations and, in particular, highlight the limitations of commonly used operation-specific metrics.  അവസാനം, നമ്മുടെ കണ്ടുപിടികള്\u200d അടിസ്ഥാനത്തില്\u200d നമ്മള്\u200d ഒരു കൂട്ടം പരാമര്\u200dശിക്കുന്നു പല പ്രവര്\u200dത്തനങ്ങളുടെ സ്വയമായി പരിഗണിക്കുന്നതിന്\nto interpret their scores.', 'mt': 'Abstrat Sabiex jiġu ssimplifikati s-sentenzi, jistgħu jitwettqu diversi operazzjonijiet ta’ miktub mill-ġdid, bħalma huma s-sostituzzjoni ta’ kliem kumpless għal kull sinonimu sempliċi, it-tħassir ta’ informazzjoni mhux meħtieġa, u l-qsim ta’ sentenzi twal. Minkejja din in-natura ta’ diversi operazzjonijiet, l-evalwazzjoni tas-sistemi ta’ simplifikazzjoni awtomatika tiddependi fuq il-metriċi li jikkorrelataw moderatament mas-sentenzi umani dwar is-sempliċità miksuba bl-e żekuzzjoni ta’ operazzjonijiet speċifiċi (pereżempju, il-qligħ tas-sempliċità bbażat fuq sostituzzjonijiet lexiċi). F’dan l-artikolu, ninvestigaw kemm metriċi eżistenti tajjeb jistgħu jivvalutaw is-simplifikazzjonijiet fil-livell tas-sentenza fejn jistgħu jkunu applikati operazzjonijiet multipli u li, għalhekk, jeħtieġu sentenzi ta’ sempliċità aktar ġenerali. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity.  It-tieni nett, nagħmlu l-ewwel meta-evalwazzjoni tal-metriċi awtomatiċi fis-Simplifikazzjoni tat-Test, bl-użu tas-sett tad-dejta l-ġdid tagħna (u dejta eżistenti oħra) biex tanalizza l-varjazzjoni tal-korrelazzjoni bejn il-punteġġi tal-metriċi u s-sentenzi umani fi tliet dimensjonijiet: il-livell perċepitu tas-sempliċità, it-tip tas-sistema, u s-sett ta’ referenzi użati għall-komputazzjoni. Aħna nuru li dawn it-tliet aspetti jaffettwaw il-korrelazzjonijiet u, b’mod partikolari, jenfasizzaw il-limitazzjonijiet ta’ metriċi speċifiċi għall-operazzjoni użati b’mod komuni. Fl-a ħħar nett, abbażi tas-sejbiet tagħna, qed nipproponu sett ta’ rakkomandazzjonijiet għall-evalwazzjoni awtomatika tas-simplifikazzjonijiet ta’ diversi operazzjonijiet, li jissuġġerixxu liema metriċi għandhom jiġu kkalkulati u kif\nbiex jinterpretaw il-punteġġi tagħhom.', 'ro': 'Pentru a simplifica propozițiile, pot fi efectuate mai multe operațiuni de rescriere, cum ar fi înlocuirea cuvintelor complexe pe sinonime mai simple, ștergerea informațiilor inutile și divizarea propozițiilor lungi. În ciuda caracterului multioperațional, evaluarea sistemelor de simplificare automată se bazează pe valori care corelează moderat cu judecățile umane privind simplitatea obținută prin executarea unor operațiuni specifice (de exemplu, câștigul de simplitate bazat pe înlocuiri lexicale). În acest articol, investigăm cât de bine valorile existente pot evalua simplificările la nivel de frază în cazul în care s-ar putea aplica mai multe operațiuni și care, prin urmare, necesită judecăți mai generale de simplitate. Pentru aceasta, colectăm mai întâi un set de date nou și mai fiabil pentru evaluarea corelației măsurătorilor și a judecăților umane de simplitate generală. În al doilea rând, efectuăm prima meta-evaluare a măsurătorilor automate în Text Simplification, folosind noul set de date (și alte date existente) pentru a analiza variația corelației dintre scorurile măsurătorilor și judecățile umane în trei dimensiuni: nivelul de simplitate perceput, tipul de sistem și setul de referințe utilizate pentru calcul. Aratăm că aceste trei aspecte afectează corelațiile și, în special, evidențiază limitările măsurătorilor specifice operațiunii utilizate în mod obișnuit. În cele din urmă, pe baza constatărilor noastre, propunem un set de recomandări pentru evaluarea automată a simplificărilor multioperaționale, sugerând ce valori să calculeze și cum\nsă interpreteze scorurile lor.', 'mn': 'Үүнийг хялбарчлахын тулд хэд хэдэн дахин бичиж буй үйл ажиллагааг хийж болно. Жишээлбэл илүү хялбар хэлбэрүүдийг орлуулж, хэрэггүй мэдээллийг устгаж, урт өгүүлбэрүүдийг хувааж болно. Энэ олон үйл ажиллагааны байгаль ч, автоматжуулалтын хялбарчлалын системийн үнэлгээ нь хүний хувьд тодорхой үйл ажиллагааны дасгал хялбарчлалтай холбоотой хэмжээсүүдтэй холбоотой метриктикүүд байдаг. Энэ хэвлэлд бид хэр сайн суурилсан метрик хэмжээний хэмжээний хялбарчлалыг шалгаж, олон үйл ажиллагаа хэрэгжүүлж болох бөгөөд энэ нь илүү энгийн шийдвэр хэрэгтэй. Үүний тулд бид эхлээд метрик болон хүн төрөлхтний шийдвэрлэлтийг үнэлэхэд шинэ, итгэлтэй мэдээллийг цуглуулдаг. Хоёр дахь, бид Текст Багшилдэг автоматическийн метрикийн анхны мета-оюун шалгалтыг хийж, бидний шинэ өгөгдлийн бүтээгдэхүүнийг (мөн бусад оршин байгаа өгөгдлийн тоо баримт) ашиглаж, метрикийн тоо болон хүн төрөлхтний шийдвэрлэлтийн өөрчлөлтийг 3 хэмжээсүүд дотор шинжилгээ Бид эдгээр гурван асуудлыг харилцааны нөлөөлдөг гэдгийг харуулж байна. Ялангуяа ихэвчлэн хэрэглэгддэг үйл ажиллагааны тодорхой метриктикийн хязгаарыг тодорхойлж байна. Эцэст нь, бидний олон үйл ажиллагааны хялбарчлалын автоматжуулалтын тооцоолж, хэрхэн тооцоолж, хэрхэн тооцоолж, хэрхэн тооцоолж, хэрхэн тооцоолж буй хэмжээний зөвлөмжүүдийг\nтоонуудыг илэрхийлж чадна.', 'sr': 'Da bi se pojednostavili rečenice, može se izvršiti nekoliko operacija prepisanja, kao što je zamjena složenih reči po jednostavnijim sinonima, izbrisanje nepotrebnih informacija i razdvajanje dugih rečenica. Uprkos ovoj višeoperacijskoj prirodi, procjena automatskih pojednostavljanja oslanja se na metrike koje moderno povezuju sa ljudskim osuđivanjima o jednostavnošću postignutom izvršavanjem specifičnih operacija (npr. dobitak jednostavnosti na osnovu leksičkih zamjena). U ovom članku istražujemo koliko dobro postojeće metrike mogu procijeniti pojednostavljenje na nivou rečenica u kojima se mogu primjenjivati višestruke operacije i što stoga zahtijevaju vise opće jednostavnosti osude. Za to, prvo sakupljamo novi i pouzdaniji podaci za procjenu korelacije metrika i ljudskih osuda o ukupnoj jednostavnosti. Drugo, mi vodimo prvu metaprocjenu automatske metrike u tekstu Jednostavnosti, koristeći naš novi set podataka (i drugi postojeći podaci) kako bi analizirali varijaciju korelacije između rezultata metrika i ljudskih osuđivanja na tri dimenzije: razina pojednostavnosti, tip sistema i seta referencija korištenih za računalo. Pokazujemo da ovi tri aspekta utiču na korelaciju i posebno naglašavaju ograničenja često korištenih metrika za specifičnu operaciju. Konačno, na temelju naših nalaza, predlažemo niz preporuka za automatsku procjenu pojednostavljanja multioperacija, predlažeći koji metrik da računate i kako\nda interpretiraju njihove rezultate.', 'so': 'Si aad u fududaato hadallada, waxaa la sameyn karaa shaqooyin badan oo la qorayo, tusaale ahaan in lagu beddelo hadallo qallafsan si fudud u qorayo islamarkaasna la deleto macluumaad aan u baahnayn iyo kala qeybinayo erayo dheer. Despite this multi-operation nature, evaluation of automatic simplification systems relies on metrics that moderately correlate with human judgments on the simplicity achieved by executing specific operations (e.g., simplicity gain based on lexical replacements).  Qoraalkan waxaynu baaraynaa siduu si wanaagsan u qiimeyn karo fududaadka heerka, meesha lagu codsan karo shuqullo badan, taas darteed waxay u baahan tahay xukun fudud oo fudud. Taas darteed, marka ugu horeysa waxaynu soo ururinnaa koob cusub oo la aamin karo si aan ugu qiimeyno xiriirka ku xiriirka metriciga iyo xukunka biniaadamka ee fudud. Second, waxaynu sameynnaa qiimeynta ugu horraysa meta-qiimeynta hore ee qoraalka Simplification, waxaynu isticmaalnaa sawirkayada cusub (iyo data kale) si aan u analysno isbedelka xiriirka u dhexeeya qiimaha metrikada iyo xukummada dadka saddex meelood oo dhan: heerka sahliga la gartay, nooca nidaamka iyo kooxda loo isticmaalay xisaabitaanka. Waxaynu muujinnaa in saddexdan dhinac ay saameyn ku leedahay xiriirka, gaar ahaantiina waxaa ku qoran xadhigga qaababka caadiga ah ee lagu isticmaalayo. Ugu dambaysta, waxaynu soo jeedaynaa arimo badan oo lagu talo saaran karo qiimeynta fududaadka shaqooyinka badan, waxaana soo jeedinaya metriciyada aan xisaabinno iyo sida\nsi ay u fasiraan scorahooda.', 'sv': 'Sammanfattning För att förenkla meningar kan flera omskrivningsåtgärder utföras, till exempel ersätta komplexa ord per enklare synonymer, ta bort onödig information och dela upp långa meningar. Trots denna multi-operation karaktär förlitar sig utvärderingen av automatiska förenklingssystem på mätvärden som måttligt korrelerar med mänskliga bedömningar av enkelheten som uppnås genom att utföra specifika operationer (t.ex. enkelhetsvinst baserad på lexikala ersättningar). I den här artikeln undersöker vi hur väl befintliga mätvärden kan bedöma förenklingar på meningsnivå där flera operationer kan ha tillämpats och som därför kräver mer allmänna enkelhetsbedömningar. För det samlar vi först in en ny och mer tillförlitlig datauppsättning för att utvärdera korrelationen mellan mätvärden och mänskliga bedömningar av övergripande enkelhet. För det andra genomför vi den första metautvärderingen av automatiska mätvärden i Text Simplification, med hjälp av vår nya datauppsättning (och andra befintliga data) för att analysera variationen i korrelationen mellan mätvärden och mänskliga bedömningar över tre dimensioner: upplevd enkelhetsnivå, systemtyp och uppsättningen referenser som används för beräkning. Vi visar att dessa tre aspekter påverkar korrelationerna och i synnerhet belyser begränsningarna för vanliga verksamhetsspecifika mätvärden. Slutligen, baserat på våra resultat, föreslår vi en uppsättning rekommendationer för automatisk utvärdering av fleroperations förenklingar, vilket föreslår vilka mätvärden som ska beräknas och hur\natt tolka sina poäng.', 'mk': 'Апстрактен За да се поедностават речениците, може да се извршат неколку операции за препишување, како што е замената на сложени зборови на едноставни синоними, избришувањето на непотребни информации и поделбата на долги реченици. И покрај оваа мултиоперациона природа, евалуацијата на автоматски системи за едноставување се потпира на метрики кои се модерно корелираат со човечките пресуди за едноставноста постигната со спроведување на специфични операции (на пример, добивањето на едноставноста базирано на лексични зам Во овој статија, истражуваме колку добро постојните метрики можат да проценат поедноставувања на нивото на речениците каде што можеби биле применети повеќе операции и кои, затоа, бараат поопшта пресуди за едноставност. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity.  Второ, ја спроведуваме првата мета-евалуација на автоматската метрика во Текст-едноставувањето, користејќи го нашиот нов набор податоци (и други постоечки податоци) за анализирање на варијацијата на корелацијата помеѓу оценките на метриката и човечките пресуди во три димензии: перцепираното ниво на едноставност, системскиот тип и наборот на рефе Ние покажуваме дека овие три аспекти влијаат на корелациите и, особено, ги истакнуваме ограничувањата на обично употребени метрики специфични за операција. Finally, based on our findings, we propose a set of recommendations for automatic evaluation of multi-operation simplifications, suggesting which metrics to compute and how\nза да ги интерпретираат нивните резултати.', 'ur': 'جماعتوں کو سادھا کرنے کے لئے بہت سی دوبارہ لیٹ کرنے کی عملیات کر سکتے ہیں، جیسے پیچیدہ کلمات کو سادھے سینونیم پر بدل سکتے ہیں، غیر ضروری معلومات کو مٹا سکتے ہیں اور طویل کلمات کو تقسیم کرتے ہیں. یہ بہت سی عملیات کی تعبیر کے بغیر، اتوماتیک سادگی سیسٹم کی ارزیابی متریک پر ہے جو انسان کے فیصلے کے ساتھ آسانی کے ساتھ متصل ہوتے ہیں (جیسے لکسیکل بدلنے پر بنیاد سادگی کے ذریعے) کامیاب ہونے کے ذریعے پہنچ گئے ہیں۔ اس مقالہ میں ہم تحقیق کرتے ہیں کہ کس طرح بہتر موجود متریک سفارش کرسکتے ہیں جہاں بہت سی عملیات لازم ہو سکتے ہیں اور اسی وجہ سے یہ بہت سادگی فیصلے کی ضرورت ہے۔ اس کے لئے ہم پہلے ایک نئی اور زیادہ قابل اطمینان جمع کریں گے کہ متریک اور انسان کے تمام سادگی کے فیصلے کا ارزش کریں۔ دوسرا، ہم متریک کے اسکوروں اور انسانوں کے فیصلے کے درمیان تغییرات کی تغییرات کے مطابق تین اندازے سے پہلے متریک کی آزمائش کررہے ہیں: سمجھا ہوا سادگی سطح، سیسٹم کیپ اور کمپیوٹر کے لئے استعمال کیا جاتا ہے. ہم دکھاتے ہیں کہ یہ تین قسمیں تعلقات پر اثر دیتی ہیں اور مخصوصاً معمولی طور پر استعمال کی عملیات کی تعلقات کی محدودیت کو اثر دیتی ہیں۔ آخر میں، ہمارے نتیجے پر بنیاد ہے، ہم ایک مجموعہ آزمائش سادھائی کے ساتھ ایک مجموعہ سفارش کریں گے، جو متریک کمپیوٹر کریں اور کیسے کریں،\nان کے امتیاز کی تعبیر کرنے کے لئے۔', 'pl': 'Streszczenie W celu uproszczenia zdań można wykonać kilka operacji przepisywania, takich jak zastępowanie złożonych słów na prostsze synonimy, usuwanie niepotrzebnych informacji i dzielenie długich zdań. Pomimo tego wielofunkcyjnego charakteru, ocena systemów automatycznego uproszczenia opiera się na wskaźnikach umiarkowanie korelujących z ludzkimi osądami dotyczącymi prostoty osiągniętej poprzez wykonywanie określonych operacji (np. zysk prostoty oparty na zastępstwach leksykalnych). W tym artykule zbadamy, jak dobrze istniejące wskaźniki mogą ocenić uproszczenia na poziomie zdań, w których zastosowano wiele operacji i które w związku z tym wymagają bardziej ogólnych ocen prostoty. W tym celu najpierw zbieramy nowy i bardziej wiarygodny zestaw danych do oceny korelacji wskaźników i osądów ludzkich o ogólnej prostocie. Po drugie, przeprowadzamy pierwszą meta-ocenę automatycznych metryk w programie Text Simplification, wykorzystując nasz nowy zestaw danych (i inne istniejące dane) do analizy zmienności korelacji między wynikami metryki a ocenami ludzkimi w trzech wymiarach: postrzeganego poziomu prostoty, typu systemu i zestawu referencji wykorzystywanych do obliczeń. Pokazujemy, że te trzy aspekty wpływają na korelacje, a w szczególności podkreślają ograniczenia powszechnie stosowanych wskaźników operacyjnych. Wreszcie, na podstawie naszych ustaleń, proponujemy zestaw zaleceń dotyczących automatycznej oceny uproszczeń wielooperacyjnych, sugerując, jakie wskaźniki należy obliczyć i jak\ninterpretować ich wyniki.', 'ta': "வாக்கியங்களை எளிதாக்குவதற்காக பிரித்துவிடு இந்த பல செயல்பாட்டு இயற்கையை போன்றாலும், தானாகவே எளிதாக்கும் அமைப்புகளை மதிப்பிடும் மெட்ரிக்களை நம்புகிறது இது மனித த தீர்ப்புகளை செயல்படுத்தும் சுலபமான செயல்களை  இந்த கட்டுரையில், நாம் எவ்வளவு நன்றாக இருக்கும் மெட்ரிக்கள் வாக்கு-மட்டத்திற்கு எளிதாக்கத்தை மதிப்பிட முடியும் என்பதை ஆராய்க்கிற மெட்ரிக்கள் மற்றும் மனித த தீர்ப்புகளை மதிப்பதற்கு, முதலில் நாம் ஒரு புதிய மற்றும் மேலும் நம்பிக்கை கொள்ளும் தகவல் அமைப்ப Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics' scores and human judgments across three dimensions: the perceived simplicity level, the system type, and the set of references used for computation.  இந்த மூன்று பக்கங்கள் இணைப்புகளை பாதிக்கும் மற்றும், குறிப்பாக, பொதுவாக பயன்படுத்தப்பட்ட செயல்பாடு குறிப்பிட்ட மெட இறுதியாக, எங்கள் கண்டுபிடிப்புகளை அடிப்படையில், நாம் தானாகவே பல செயல்பாடு எளிதாக்கத்தை பரிந்துரைக்க ஒரு சில பரிந்துரைகளை பரிந்த\nஅவர்களுடைய மதிப்பெண்களை விளக்க வேண்டும்.", 'si': 'සම්පූර්ණයෙන් වාක්ය සංවේදනය කරන්න, වෙනස් ප්\u200dරවේශනය කරන්න පුළුවන්, වගේම සංවේදනය වෙනුවෙන් සම්පූර්ණ වචන සංවේදනය වෙනුවෙන ස්වයංක්\u200dරීය ස්වභාවිතයෙන්, ස්වයංක්\u200dරීය සංක්\u200dරීය පද්ධතිය පද්ධතියේ පරීක්ෂණය මෙට්\u200dරික්ස් එක්ක මිනිස්සු විධානයෙන් සමාන්\u200dය විධානයෙන් සම් මේ ලේඛනයේ අපි පරීක්ෂණය කරනවා කොච්චර හොඳයි තියෙන්නේ මෙට්\u200dරික්ස් එක්ක වාර්තාවක් විශ්වාස කරන්න පුළුවන් කියලා වචන සරල ව ඒකට, අපි මුලින්ම අලුත් සහ විශ්වාසිත දත්ත සැකසුම් කරනවා මෙට්\u200dරික්ස් සහ මිනිස්සුන්ගේ සාමාන්\u200dය සාමාන්\u200dය විධානය දෙවෙනි වෙනුවෙන්, අපි පළමු මෙටා-විශ්ලේෂණයේ ස්වයංක්\u200dරීය මෙට්\u200dරික්ස් වලට පරීක්ෂණය කරන්න, අපේ අලුත් දත්ත සැට (සහ අනිත් තියෙන දත්ත) භාවිත කරන්න, මෙට්\u200dරික්ස් ස්කෝර්ස් සහ අපි පෙන්වන්නේ මේ විශේෂ තුනක් සම්බන්ධතාවට ප්\u200dරතිකාර කරනවා ඒ වගේම, විශේෂයෙන්ම, සාමාන්\u200dය විශේෂ විශ අන්තිමේදී, අපේ හොයාගන්න අධික, අපි ස්වයංක්\u200dරීය විශේෂණය සඳහා ස්වයංක්\u200dරීය විශේෂණය සඳහා ප්\u200dරතිචාරයක් ප්\u200dරතිචා\nඔවුන්ගේ අංක ගණන්න.', 'uz': "@ info: whatsthis Bu ko'plab amalning tayyorlarida avtomatik soddalashtirish tizimini qiymatish oddiy amallarni bajarish uchun oddiy amalni bajarish (масалан, leksikal almashtirishlar asosida oddiy narsalar bilan bog'lash mumkin) metriklarga ishlatadi. Bu maqolada biz murakkab mavjud metriklarni qanday yaxshi ko'proq amallar qo'llanilga oshiriladi va shunday qilib ko'proq amallar qo'llanmagan oddiylik xususiyatlarini qidirish kerak. Shunday qilib, biz birinchi oddiylikning metrik va inson xususiyatlarini qidirish uchun yangi va yaxshi ishlayotgan maʼlumotlarni olib tashlamiz. Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics' scores and human judgments across three dimensions: the perceived simplicity level, the system type, and the set of references used for computation.  Biz bu uchta aspektlar aloqalarni ko'rsatamiz va hususiyat, oddiy ishlatilgan operatsiya-specific metriklarning chegaralarini koʻrsatish. Endi, biz murakkablarimiz asosida, biz ko'plab amalning soddalarini avtomatik o'qidirish uchun bir necha talab qilamiz, va qanday qilish va qanday qilish metriklarini\nularni o'rganish uchun.", 'vi': 'Trừu tượng Để đơn giản hóa câu, có thể thực hiện nhiều thao tác bổ trở lại, như thay thế từ phức tạp cho đồng xu đơn giản, xóa bỏ thông tin không cần thiết và chia câu dài. Mặc dù tính chất đa thao tác này, đánh giá hệ thống ứng biến tự động phụ thuộc vào các âm tiết có mối liên hệ tạm thời với các phán quyết con người về sự đơn giản đạt được khi thực hiện các thao tác cụ thể (v.d., sự đơn giản nhờ vào thay thế từ vựng). Trong bài báo này, chúng tôi tìm hiểu khả năng đo tử cung có thể đánh giá sự đơn giản của mức án khi có nhiều thao tác có thể được thực hiện và yêu cầu đánh giá đơn giản hơn. Để đạt được mục đích đầu tiên, chúng tôi thu thập một bộ dữ liệu mới và đáng tin cậy hơn để đánh giá mối tương quan của đo lường và phán xét con người về sự đơn giản chung. Cách thứ hai, chúng tôi tiến hành phân tích meta-Administration of Automatic metrics in Textsimplicition, bằng cách dùng bộ dữ liệu mới (và các dữ liệu tồn tại khác) để phân tích sự khác nhau giữa điểm đo lường và các phán quyết con người qua ba chiều: the Nhận thức sơ sài, the system type, và the set of references used to computetion. Chúng tôi cho thấy ba khía cạnh này ảnh hưởng tới các mối tương quan và, đặc biệt, nhấn mạnh giới hạn của các âm lượng đặc trưng cho hoạt động. Cuối cùng, dựa trên những kết quả của chúng tôi, chúng tôi đề xuất một loạt những lời khuyên về việc đánh giá tự động các hệ thống đa năng, đề xuất các đo lường để tính to án và cách\nđể giải đoán điểm số.', 'nl': 'Abstract Om zinnen te vereenvoudigen kunnen verschillende herschrijvingsoperaties worden uitgevoerd, zoals het vervangen van complexe woorden per eenvoudigere synoniemen, het verwijderen van onnodige informatie en het splitsen van lange zinnen. Ondanks deze multi-operatie aard, is de evaluatie van automatische vereenvoudigingssystemen gebaseerd op statistieken die matig correleren met menselijke oordelen over de eenvoud die wordt bereikt door het uitvoeren van specifieke bewerkingen (bijvoorbeeld eenvoudwinst op basis van lexicale vervangingen). In dit artikel onderzoeken we hoe goed bestaande metrics vereenvoudigingen op zinsniveau kunnen beoordelen waar meerdere bewerkingen mogelijk zijn toegepast en die daarom meer algemene eenvoudoordelen vereisen. Hiervoor verzamelen we eerst een nieuwe en betrouwbaardere dataset voor het evalueren van de correlatie van metrics en menselijke beoordelingen van algehele eenvoud. Ten tweede voeren we de eerste meta-evaluatie uit van automatische metrics in Textvereenvoudiging, waarbij we onze nieuwe dataset (en andere bestaande gegevens) gebruiken om de variatie van de correlatie tussen de scores van metrics en menselijke oordelen te analyseren in drie dimensies: het waargenomen eenvoudsniveau, het systeemtype en de set referenties die worden gebruikt voor berekening. We laten zien dat deze drie aspecten van invloed zijn op de correlaties en benadrukken in het bijzonder de beperkingen van veelgebruikte operationele specifieke metrics. Tot slot stellen we op basis van onze bevindingen een reeks aanbevelingen voor automatische evaluatie van multi-operation vereenvoudigingen voor, waarbij we voorstellen welke statistieken moeten worden berekend en hoe\nom hun scores te interpreteren.', 'hr': 'Apstrakt kako bi se pojednostavila rečenica, može se izvršiti nekoliko operacija za prepisanje, poput zamjene složenih riječi po jednostavnijim sinonima, izbrisanje nepotrebnih informacija i razdvajanje dugih rečenica. Unatoč ovoj višeoperacijskoj prirodi, procjena automatskih sustava pojednostavljanja oslanja se na metrike koje umjerno povezuju s ljudskim osuđivanjima o jednostavnosti postignutom izvršavanjem specifičnih operacija (npr. dobitak jednostavnosti na temelju leksičkih zamjena). U ovom članku istražujemo koliko dobro postojeće metrike mogu procijeniti pojednostavljenje razine rečenica u kojima se mogu primjenjivati višestruke operacije i što stoga zahtijevaju opće jednostavnije sudjenje. Za to prvo skupljamo novi i pouzdaniji podaci za procjenu korelacije metrika i ljudskih osuđenja o ukupnoj jednostavnosti. Drugo, provodimo prvu metaprocjenu automatskih metrika u tekstu Jednostavnosti, koristeći naš novi komplet podataka (i drugi postojeći podaci) kako bi analizirali varijaciju korelacije između rezultata metrika i ljudskih osuđivanja na tri dimenzije: razina pojednostavnosti, tipa sustava i komplet referencija korištenih za računalo. Pokazujemo da ovi tri aspekta utječu na korelacije i posebno na ograničenje često korištenih mjerila za specifičnu operaciju. Konačno, na temelju naših nalaza, predlažemo skup preporuka za automatsku procjenu pojednostavljanja multioperacija, predlažeći koje metrike za računalo i kako\nda interpretiraju njihove rezultate.', 'bg': 'За да се опростят изреченията, могат да се извършват няколко операции за пренаписване, като например замяна на сложни думи с по-прости синоними, изтриване на ненужна информация и разделяне на дълги изречения. Въпреки този многооперативен характер, оценката на системите за автоматично опростяване разчита на показатели, които умерено корелират с човешките преценки за простотата, постигната чрез изпълнение на конкретни операции (напр. увеличение на простотата въз основа на лексикални замествания). В тази статия изследваме колко добре съществуващите показатели могат да оценят опростяванията на ниво изречение, където може да са приложени множество операции и които следователно изискват по-общи преценки за простота. За това първо събираме нов и по-надежден набор от данни за оценка на корелацията на показателите и човешките преценки за цялостна простота. Второ, провеждаме първата мета-оценка на автоматичните показатели в текстовото опростяване, като използваме нашия нов набор от данни (и други съществуващи данни), за да анализираме вариацията на корелацията между оценките на показателите и човешките преценки в три измерения: нивото на възприемана простота, типа на системата и набор от референции, използвани за изчисляване. Показваме, че тези три аспекта влияят на корелациите и по-специално подчертаваме ограниченията на често използваните специфични за операцията показатели. И накрая, въз основа на нашите констатации, предлагаме набор от препоръки за автоматична оценка на многооперационните опростявания, предлагащи кои показатели да се изчислят и как\nда интерпретират резултатите си.', 'da': 'For at forenkle sætninger kan flere omskrivninger udføres, såsom erstatning af komplekse ord pr. enklere synonymer, sletning af unødvendige oplysninger og opdeling af lange sætninger. På trods af denne multi-operation karakter er evaluering af automatiske forenklingssystemer afhængig af metrics, der moderat korrelerer med menneskelige vurderinger af den enkelhed, der opnås ved at udføre specifikke operationer (f.eks. simplify gain baseret på leksikalske erstatninger). I denne artikel undersøger vi, hvordan eksisterende målinger kan vurdere forenklinger på sætningsniveau, hvor flere operationer kan være anvendt, og som derfor kræver mere generelle enkelhedsvurderinger. Til dette formål indsamler vi først et nyt og mere pålideligt datasæt til evaluering af korrelationen mellem metrics og menneskelige vurderinger af overordnet enkelhed. For det andet gennemfører vi den første metaevaluering af automatiske målinger i Tekstforenkling ved hjælp af vores nye datasæt (og andre eksisterende data) til at analysere variationen i korrelationen mellem målingers scorer og menneskelige bedømmelser på tværs af tre dimensioner: det opfattede enkelhedsniveau, systemtypen og det sæt referencer, der anvendes til beregning. Vi viser, at disse tre aspekter påvirker korrelationerne og fremhæver især begrænsningerne i almindeligt anvendte operationsspecifikke metrics. Endelig, baseret på vores resultater, foreslår vi et sæt anbefalinger til automatisk evaluering af multi-operation forenklinger, hvilke metrics der skal beregnes, og hvordan\nat fortolke deres score.', 'de': 'Um Sätze zu vereinfachen, können mehrere Umschreibungen durchgeführt werden, wie das Ersetzen komplexer Wörter durch einfachere Synonyme, das Löschen unnötiger Informationen und das Aufteilen langer Sätze. Trotz dieser Multi-Operations-Natur stützt sich die Bewertung von automatischen Vereinfachungssystemen auf Metriken, die moderat mit menschlichen Urteilen über die Einfachheit korrelieren, die durch die Ausführung bestimmter Operationen erreicht wird (z.B. Einfachheitsgewinn basierend auf lexikalischen Ersetzungen). In diesem Artikel untersuchen wir, wie gut vorhandene Metriken Vereinfachungen auf Satzebene bewerten können, bei denen mehrere Operationen angewendet wurden und die daher allgemeinere Einschätzungen erfordern. Dazu sammeln wir zunächst einen neuen und zuverlässigeren Datensatz zur Bewertung der Korrelation von Metriken und menschlichen Einschätzungen der allgemeinen Einfachheit. Zweitens führen wir die erste Meta-Auswertung automatischer Metriken in Textvereinfachung durch, indem wir unseren neuen Datensatz (und andere vorhandene Daten) verwenden, um die Variation der Korrelation zwischen Metriken-Scores und menschlichen Urteilen über drei Dimensionen zu analysieren: die wahrgenommene Einfachheitsstufe, den Systemtyp und den Satz von Referenzen, die für die Berechnung verwendet werden. Wir zeigen, dass sich diese drei Aspekte auf die Korrelationen auswirken und zeigen insbesondere die Grenzen gängiger betriebsspezifischer Metriken auf. Schließlich schlagen wir basierend auf unseren Ergebnissen eine Reihe von Empfehlungen für die automatische Bewertung von Vereinfachungen mit mehreren Operationen vor, die vorschlagen, welche Metriken berechnet werden sollen und wie\nihre Partituren zu interpretieren.', 'id': "Abstrakt Untuk menyederhanakan kalimat, beberapa operasi menulis ulang dapat dilakukan, seperti menggantikan kata kompleks per sinonym sederhana, menghapus informasi yang tidak diperlukan, dan membagi kalimat panjang. Meskipun alam multi-operasi ini, evaluasi sistem penyimplifikasi otomatis bergantung pada metrik yang secara moderat berkorelasi dengan penilaian manusia tentang kesederhanaan yang dicapai dengan melakukan operasi spesifik (contohnya, keuntungan kesederhanaan berdasarkan penggantian leksik). Dalam artikel ini, kami menyelidiki seberapa baik metrik yang ada dapat menilai kesederhanaan tingkat kalimat di mana banyak operasi mungkin telah diterapkan dan yang, oleh itu, membutuhkan penilaian kesederhanaan umum. Untuk itu, kita pertama-tama mengumpulkan set data yang baru dan lebih dipercaya untuk mengevaluasi korelasi metrik dan penilaian manusia kesederhanaan umum. Kedua, kami melakukan meta-evaluasi pertama dari metrik otomatis dalam Simplifikasi Teks, menggunakan set data baru kami (dan data yang ada) untuk menganalisis variasi korelasi antara skor metrik 'dan penilaian manusia melalui tiga dimensi: tingkat kesederhanaan yang didapati, tipe sistem, dan set referensi yang digunakan untuk komputasi. Kami menunjukkan bahwa tiga aspek ini mempengaruhi korelasi dan, terutama, menyatakan batasan dari metrik spesifik operasi yang biasa digunakan. Akhirnya, berdasarkan penemuan kami, kami mengusulkan sebuah set rekomendasi untuk evaluasi otomatis penyimplifikasi multi-operasi, menyarankan metrik mana untuk dikomputerkan dan bagaimana\nto interpret their scores.", 'fa': 'برای ساده کردن جمله\u200cها، چند عملیات دوباره نوشتن می\u200cتوانند انجام دهند، مانند جایگزینش کلمه\u200cهای پیچیده\u200cتر به عنوان سنونیم\u200cهای ساده\u200cتر، حذف اطلاعات لازم نیست و جدا کردن جمله\u200cهای طولانی. با وجود این طبیعت چندین عملیات، ارزیابی سیستم\u200cهای ساده\u200cسازی اتوماتیک بر متریک\u200cها بستگی دارد که به وسیله\u200cی مدرسه با تصمیم\u200cهای انسان بر ساده\u200cساده\u200cای که با اجرای عملیات خاص به دست آورده\u200cاند (مثلاً پیروزی ساده\u200cساده بر اساس جایگزینش\u200cهای زبانی) ارتباط در این مقاله، ما تحقیق می\u200cکنیم که چقدر متریک\u200cهای موجود هستند می\u200cتوانند ساده\u200cسازی\u200cهای سطح جمله\u200cها را ارزیابی کند که ممکن است عملیات چندین مورد کاربرد قرار داده شود، و به این دلیل، به قضاوت ساده\u200cای بیشتری نی برای این، اولین بار یک مجموعه اطلاعات جدید و قابل اطمینان بیشتری برای ارزیابی ارزیابی متریک و قضاوت انسانی از همه سادگی جمع می کنیم. دوم، ما اولین ارزیابی مته\u200cای از متری\u200cهای خودکار در ساده\u200cسازی متن را انجام می\u200cدهیم، با استفاده از مجموعه داده\u200cهای جدید ما (و دیگر داده\u200cهای موجود) برای تحلیل تغییرات ارتباط بین نمونه\u200cهای متریک و داده\u200cهای انسان در سه بعدی: سطح ساده\u200cای که مشاهده شده، نوع سیستم و مجموعه\u200cی ارتباطات برای محاسبات استفاده ما نشان می دهیم که این سه نقطه بر ارتباطات تاثیر می دهد و مخصوصاً محدودیت متریک\u200cهای معمولاً استفاده می\u200cشود. بالاخره، بر اساس نتیجه\u200cهایمان، ما پیشنهاد می\u200cکنیم مجموعه پیشنهاد برای ارزیابی خودکار ساده\u200cهای چندین عملیات، پیشنهاد می\u200cدهیم که کدام متریک برای محاسبه و چگونه\nتا نتیجه\u200cهایشان را تعبیر کنند.', 'ko': '요약은 문장을 간소화하기 위해 복잡한 단어를 간단한 동의어로 교체하고 불필요한 정보를 삭제하며 긴 문장을 나누는 등 몇 가지 재작성 작업을 수행할 수 있다.비록 이런 다중 조작 성질이 존재하지만 자동 간소화 시스템의 평가는 특정한 조작을 통해 실현되는 단순성에 대한 인류의 판단(예를 들어 어휘 교체를 바탕으로 하는 단순성 이득)과 적당한 관련 지표에 의존한다.본고에서 우리는 기존 지표가 여러 조작을 응용할 수 있는 문장급 간소화를 어떻게 평가하는지 연구할 것이기 때문에 더욱 전면적인 간소화 판단이 필요하다.이를 위해 우리는 먼저 새로운 믿을 만한 데이터 집합을 수집하여 지표 간의 관련성과 인류가 전체적인 단순성에 대한 판단을 평가하는 데 사용했다.그 다음에 우리는 텍스트 간소화에서의 자동 도량에 대해 제1차원 평가를 실시했다. 우리의 새로운 데이터 집합(기타 기존 데이터)을 이용하여 도량 점수와 인류 판단 간의 관련성이 세 가지 차원에서 변화하는 것을 분석했다. 감지의 단순도, 시스템 유형과 계산에 사용되는 참고 집합이다.우리는 이 세 가지 측면이 관련성에 미치는 영향을 보여주었고 특히 특정 지표를 자주 사용하는 한계성을 강조했다.마지막으로 Dell의 발견을 바탕으로 Dell은 멀티태스킹을 단순화하는 자동 평가를 위한 권장 사항을 제시하여 어떤 지표를 계산하고 어떻게 계산하는지를 제안했습니다.\n그들의 점수를 설명하다.', 'sw': 'Ili kuondoa hukumu rahisi, shughuli kadhaa za kuandika upya zinaweza kutekelezwa, kama vile kubadilisha maneno magumu kwa ajili ya synonyesho rahisi, kufuta taarifa zisizo lazima, na kutoa hukumu ndefu. Pamoja na utaratibu huu wa upasuaji wa aina mbalimbali, uchunguzi wa mfumo wa urahisi unategemea mbinu ambazo kwa sasa zinaunganisha na maamuzi ya binadamu kuhusu urahisi uliotekelezwa kwa kutekeleza operesheni maalum (kwa mfano, upatikanaji unaotegemea mabadiliko ya lexico). Katika makala hii, tunachunguza namna mbinu zilizopo vizuri zinavyoweza kutathmini urahisi wa kiwango cha hukumu ambapo shughuli nyingi zinaweza kutumika na hivyo, inahitaji maamuzi ya urahisi zaidi. Kwa hilo, kwanza tunakusanya taarifa mpya na yenye kuaminika zaidi ili kutathmini uhusiano wa mitindo na hukumu za binadamu kwa urahisi kabisa. Pili, tunafanya uchunguzi wa kwanza wa mbinu za kujitegemea katika Uwekezaji wa Mataifa, kwa kutumia seti zetu mpya ya data (na data nyingine zilizopo) ili kuchambua mabadiliko ya uhusiano kati ya vipindi vya metric na hukumu za binadamu katika vipengele tatu: kiwango cha urahisi, aina ya mfumo, na seti ya maoni yanayotumiwa kwa ajili ya hisabati. Tunaonyesha kwamba vipande vitatu vinathiri uhusiano na hususani, hususani kuonyesha vizuizi vya njia maalum za operesheni. Mwisho, kwa mujibu wa matokeo yetu, tunapendekeza baadhi ya mapendekezo kwa ajili ya kutathmini utafiti wa urahisi wa operesheni nyingi, tunapendekeza njia gani ya kuhesabu na jinsi gani\nkutafsiri vipimo vyao.', 'tr': 'sözleri ýeňil etmek üçin, birnäçe faýly ýazma işlemleri çykaryp bilýär, birnäçe esasy synonymlara karmaşık sözleri almak üçin, gerekli maglumatlary pozmak we uzak sözleri bölmek üçin eser goýup biler. Bu köp işleýän tebigata rağmen, awtomatik ýe ňlemek sistemleriniň deňlemesi metriklere g örä, adamlaryň häsiýetleri spesifikal işleýän ýerleşdirilip ýeňildirilen ýeňildirim barada (meselâ, esasy bir ýeňilik ýeňleme sistemalaryna daýanýar). Bu makaleda, biz esasy metrikleriň nähili gowy bolan esasy düzedilerini esaslaşdyrylyp biljek bolandygyny soruşýarys. Bu sebäpli, esasy düzedileriniň esasy düzedilerini çaklayp biljek bolýar. Şol sebäpli, esasy düzedileriniň esasy Şonuň üçin ilkinji gezek metrikler we adamlaryň hemme basit çözümlerini deňlemek üçin täze we ynamly bir maglumat toplaýarız. Ikinjisi, metrileriň अंश we adamlaryň häsiýetleriniň 3 boyutlarda işlenýän ilkinji meta-deňlemesini Metin Basitleşdirmek üçin, täze maglumatlarymyzyň (we beýleki maglumatlarymyzyň) üýtgeşişini çözmek üçin çykyp etdik: hasaplanýan basitlerlik derejesi, sistem hili we hasaplamak üçin ullanýan Referanslar takmyny çykyp Biz bu üç aspektler correliklere täsir edýändigini görkeýäris we özellikle, köplenç işleýän metrikleriň sınırlaryny ýagtylaşýarys. Soňunda tapylyklarymyza daýanýar, biz multi-operasyon basitleriniň otomatik deňlemesi üçin bir taksa maslahatlary teklip edip, nähili metrikleriň hasaplamagyny we nähili maslahat etmegini maslahat berýäris.\ndüzümlerini ýaryşdyrmak üçin.', 'hy': "Աբլակտրական Որպեսզի պարզեցնենք նախադասությունները, կարելի է կատարել մի քանի վերագրման գործողություններ, ինչպիսիք են բարդ բառերի փոխարինելը պարզ սինոնիմերի վրա, անհրաժեշտ տեղեկություն վերացնելը և երկար նախադասություններ բաժանելը: Չնայած այս բազմագործման բնույթին, ավտոմատիկ պարզեցման համակարգերի գնահատումը հիմնված է մետրիկների վրա, որոնք մեծապես կապված են մարդկային դատողությունների հետ պարզության վրա, որը հասնում է հատուկ գործողությունների կատարման միջոցով (օրինակ, պարզության շահույթը՝ հիմնված Այս հոդվածի մեջ մենք ուսումնասիրում ենք, թե ինչպես կարող են գոյություն ունեցող մետրիկները գնահատել նախադասության մակարդակի պարզաբանությունները, որտեղ կարող են կիրառվել բազմաթիվ գործողություններ և որոնք, հետևաբար, պահանջում են ավելի ընդհանուր Սկզբում մենք հավաքում ենք նոր և ավելի վստահելի տվյալների համակարգը, որպեսզի գնահատենք մետրիկների և մարդկային դատողությունների կապը ընդհանուր պարզ լինելու համար: Երկրորդ, մենք կատարում ենք տեքստի պարզաբանության մետագնահատման առաջին մետագնահատումը, օգտագործելով մեր նոր տվյալների համակարգը (և այլ գոյություն ունեցող տվյալները) մետրիկայի գնահատականների և մարդկային դատողությունների միջև կապվածության տարբերությունը վերլուծելու համար երեք չափով' ընկած պարզության մակարդակը, համակարգը և հաշվարկների համար օգ Մենք ցույց ենք տալիս, որ այս երեք ասպեկտները ազդում են հարաբերությունների վրա և հատկապես շեշտում են ընդհանրապես օգտագործված գործողության կոնկրետ չափումների սահմանափակումները: Վերջապես, հիմնվելով մեր հայտնաբերությունների վրա, մենք առաջարկում ենք մի շարք խորհուրդներ բազմագործման պարզաբանությունների ավտոմատիկ գնահատման համար, առաջարկում, թե ինչ մետրիկ հաշվարկելու և ինչպես\nիրենց գնահատականները մեկնաբանելու համար:", 'am': 'ቦታ ምንም እንኳ ይህ ብዙዎች የሥራ ሥርዓት ቢሆንም፣ የራሱ ቀላል ስርዓት ስርዓቶች በማድረግ ቀላል ስርዓት በሚያገኘው በሚያስተካክሉ ምትርኮች ላይ ነው፡፡ በዚህ ጽሑፍ ውስጥ ብዙዎች ተግባሮች የተጠቀሙበት የፍርድ ደረጃ ቀላል መሆኑን እናሳውቃለን፡፡ For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity.  Second, the first meta-assessment of the text Simplification using the new data set (and other existing data) to analyse the difference between metrics scores and human ፈራጆች ፍርድ በሦስት dimensions: the simplicity level, the system type and the set of references for computation used. እነዚህም ሦስት ጉዳዮች ግንኙነታቸውን እንዲያካክሉ እና በተለየ ጊዜ የተጠቃሚ የስርዓት-ምርጫዎች ግንኙነቶችን እናሳየዋለን፡፡ በመጨረሻው፣ ፍላጎታችንን በመሠረት፣ የትኛውን ማህበረሰብ እና እንዴት እንዲቆጠር እናስታውቃለን፡፡\nነፃዎቻቸውን ለመተረጉም', 'af': "Abstrak Om teikens te eenvoudig, kan verskeie herskryf operasies uitgevoer word, soos komplekse woorde per eenvoudiger sinonime vervang, onnoordelike inligting verwyder en lanke teikens verdeel. Onthou hierdie veelvuldige operasie-natuur, evaluering van outomatiese eenvoudiging-stelsels is op metries wat middelik verbind met menslike oordelings op die eenvoudigheid wat bereik word deur spesifieke operasies uit te voer (bv. eenvoudigheid verskaf gebaseer op leksiese vervangings). In hierdie artikel, ons ondersoek hoe goed bestaande metries kan assers sentence-level eenvoudiginge waar veelvuldige operasies dalk aangepas is en wat daarom meer algemene eenvoudige oordelinge benodig. Daarom versamel ons eerste 'n nuwe en meer betroubare data stel om die korrelasie van metries en menslike oordelinge van die hele eenvoudigheid te evalueer. Tweede, ons doen die eerste meta-evaluasie van outomatiese metries in Teks Vereenvoudiging, gebruik ons nuwe data stel (en ander bestaande data) om die verandering van die koreluasie tussen metries se telling en menslike oordelings oor drie dimensies te analyseer: die aangeneem eenvoudigheid vlak, die stelsel tipe en die stel van verwysings gebruik word vir rekenaar. Ons wys dat hierdie drie aspekte effekteer die korrelasies en, in particular, verlig die beperkings van algemeen gebruikte operasie-spesifieke metries. Eindelik, gebaseer op ons gevinde, voorstel ons 'n stel aanbevelings vir outomatiese evaluering van veelvuldige operasie eenvoudiginge, voorstel wat metries om te bereken en hoe\nom hul punte te interpreteer.", 'sq': 'Abstrakt Për të thjeshtuar fjalët, mund të kryehen disa operacione rishkrimi, të tilla si zëvendësimi i fjalëve komplekse për sinonime të thjeshta, fshirja e informacionit të panevojshëm dhe ndarja e fjalëve të gjata. Megjithë këtë natyrë shumë-operacionale, vlerësimi i sistemeve automatike të thjeshtësimit mbështetet në metrika që korrelohen moderatamente me gjykimet njerëzore mbi thjeshtësinë e arritur duke ekzekutuar operacione të posaçme (për shembull, fitimin e thjeshtësisë bazuar në zëvendësimet lexike). Në këtë artikull, ne hetojmë se sa mirë metrikat ekzistuese mund të vlerësojnë thjeshtimin e nivelit të dënimeve ku operacionet e shumta mund të kenë qenë aplikuar dhe të cilat, prandaj, kërkojnë gjykime më të përgjithshme të thjeshtësisë. Për këtë, ne së pari mbledhim një grup të ri dhe më të besueshëm të të dhënash për vlerësimin e korrelacionit të metrikave dhe gjykimeve njerëzore të thjeshtësisë së përgjithshme. Së dyti, ne kryejmë meta-vlerësimin e parë të metrikave automatike në Simplifikimin e Tekstit, duke përdorur grupin tonë të ri të të dhënave (dhe të dhënat ekzistuese të tjera) për të analizuar variacionin e korrelacionit midis rezultateve të metrikave dhe gjykimeve njerëzore në tre dimensione: nivelin e perceptuar të thjeshtësisë, tipin e sistemit dhe grupin e referimeve të përdorura për llogaritjen. Ne tregojmë se këto tre aspekte ndikojnë në korrelacionet dhe, veçanërisht, theksojnë kufizimet e metrikave të përdorura në mënyrë të zakonshme specifike operacionit. Më në fund, bazuar në gjetjet tona, ne propozojmë një sërë rekomandimesh për vlerësimin automatik të thjeshtësimeve të shumëoperacioneve, duke sugjeruar se cilat metrika për të llogaritur dhe si\nto interpret their scores.', 'bn': "বাক্য সুস্পষ্ট করার জন্য বেশ কিছু পুনরায় লেখা অপারেশন করা যাবে, যেমন সহজ সিনোনিমের প্রতি জটিল শব্দ প্রতিস্থাপন করা, প্রয়োজনীয় তথ্য মুছে ফেলা এবং দ এই বহু অপারেশন প্রকৃতি সত্ত্বেও স্বয়ংক্রিয় সিস্টেমের স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয় সংক্রান্ত মেটিকের উপর নির্ভর করে যা মানুষের বিচারের সাথে মিলিয়ে রাখে সুন এই প্রবন্ধে আমরা অনুসন্ধান করি কিভাবে বিদ্যমান মেট্রিকেরা শাস্তি স্তরের সাধারণ সুস্পষ্ট বিষয়গুলো মূল্যায়ন করতে পারে যেখানে বেশ কিছু কা এর জন্য আমরা প্রথমে একটি নতুন এবং আরো বিশ্বস্ত তথ্য সংগ্রহ করি মেট্রিক এবং মানবিক বিচারের সম্পর্ক মূল্যায়নের জন্য। Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics' scores and human judgments across three dimensions: the perceived simplicity level, the system type, and the set of references used for computation.  আমরা দেখাচ্ছি যে এই তিনটি প্রাপ্ত সম্পর্কের উপর প্রভাব ফেলে এবং বিশেষ করে সাধারণ ব্যবহার করা অপারেশন-নির্দিষ্ট মেট্রিকের সী অবশেষে, আমাদের আবিস্কারের ভিত্তিতে, আমরা স্বয়ংক্রিয়ভাবে বহুক্ষেত্রের স্বয়ংক্রিয়ভাবে পরামর্শ প্রস্তাব করি, যার পরামর্শ দেয়া হচ্ছ\nতাদের স্কোর ব্যাখ্যা করার জন্য।", 'az': 'Sözümləri asanlaşdırmaq üçün, bir neçə yeni yazma işləri işlədilir, bəlkə daha asanlaşdırılmış sinonimlərə kompleks sözləri əvəz etmək, fərqli məlumatları silmək və uzun cümlələri bölüşdirmək üçün. Bu çoxlu operasyon təbiətinə rağmen, avtomatik təmizləmə sistemlərinin değerlendirməsi məsələlərə bağlı olan metriklərə bağlı olar ki, insanların hökmləri müəyyən edilən müəyyən işləri yerinə yetirməklə nəticə edilən basitlıqla bağlı olar (məsələn, leksik əvəzinə dayanan basitlıq kazanması). Bu məlumatda, biz həmin metriklərin cümlədən səviyyədə təkrarlaşdırılması üçün nə qədər yaxşı təkrarlaşdırılmasını təsdiqləyirik ki, çoxlu işlər istifadə edilmiş və buna görə də daha çox asanlıq yargılaması lazımdır. Buna görə biz ilk dəfə metriklərin və insanların bütün basit hökmlərinin bağlılığını değerləşdirmək üçün yeni və daha güvenilir məlumatları toplayırıq. İkincisi, metriklərin qiymətlərinin və insan hökmünün dəyişikliyini üç ölçüdə analiz etmək üçün, məlumatlarımızın yeni məlumatlarımızı və başqa məlumatlarımızı istifadə etmək üçün, məlumatların dəyişikliyini və insanların hökmünün dəyişikliyini məlumatların ilk meta-değerləndirməsini təşkil edirik: məlumatların basit seviyyəti, sistem türü və Biz bu üç aspektlərin bağlantılara təsir etdiyini göstəririk və özlərinə də çox istifadə edilən işləmə müəyyən metriklərinin sınırlarını işıqlandırır. Sonunda, bizim tapındıqlarımıza dayanan, çoxlu operasyon basitlarının avtomatik değerlənməsi üçün tədbirləri təklif edirik, hangi metrikləri hesablamaq və nasıl hesablamaq üçün tədbirləri təklif edirik.\nnəticələrini təfsil etmək üçün.', 'ca': "Abstract Per simplificar les frases, es poden fer diverses operacions de reescriptura, com per exemple substituir paraules complexes per sinònims simples, eliminar informació innecessària i dividir frases llargues. Malgrat aquesta naturalesa multioperativa, l'evaluació dels sistemes de simplificació automàtica es basa en mètriques que correlacionen moderadament amb els judicis humans sobre la simplicitat aconseguida executant operacions específices (per exemple, el guany de simplicitat basat en substitucions lècsiques). En aquest article, investigam com de bé les mètriques existents poden evaluar les simplificacions del nivell de frases on es poden haver aplicat múltiples operacions i que, per tant, requereixen judicis de simplicitat més generals. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity.  Segon, fem la primera meta-evaluació de les mètriques automàtiques en la Simplificació del Texte, utilitzant el nostre nou conjunt de dades (i altres dades existents) per analitzar la variació de la correlació entre les puntuacions de les mètriques i els judicis humans en tres dimensions: el nivell perceptiu de simplicitat, el tipus de sistema i el conjunt de referències utilitzats per al calcul. Mostrem que aquests tres aspectes afecten les correlacions i, en particular, destaquen les limitacions de les mètriques comunament utilitzades específicament per a l'operació. Finalment, basant-nos en els nostres descobriments, proposem un conjunt de recomanacions per a una evaluació automàtica de simplificacions multioperatives, suggerint quines mètriques calcular i com\nper interpretar les seves puntuacions.", 'bs': 'Apstrakt kako bi se pojednostavila rečenica, može se izvršiti nekoliko operacija prepisanja, poput zamjene složenih riječi po jednostavnijim sinonima, izbrisanje nepotrebnih informacija i razdvajanje dugih rečenica. Uprkos ovoj prirodi višeoperacije, procjena automatskih pojednostavljanja oslanja se na metrike koje moderno povezuju sa ljudskim osuđivanjima o jednostavnošću postignutom izvršavanjem specifičnih operacija (npr. dobitak jednostavnosti na temelju leksičkih zamjena). U ovom članku istražujemo koliko dobro postoje metrike mogu procijeniti pojednostavljenje na razini rečenica u kojima se mogu primjenjivati višestruke operacije i što stoga zahtijevaju opće jednostavne osude. Za to prvo sakupljamo novi i pouzdaniji podaci za procjenu korelacije metrika i ljudskih osuđenja o ukupnoj jednostavnosti. Drugo, mi vodimo prvu metaprocjenu automatske metrike u tekstu Jednostavnosti, koristeći naš novi set podataka (i drugi postojeći podaci) kako bi analizirali varijaciju korelacije između rezultata metrika i ljudskih osuđivanja na tri dimenzije: razina pojednostavnosti, tip sistema i seta referencija korištenih za računalo. Pokazujemo da ovi tri aspekta utiču na korelaciju i posebno naglašavaju ograničenja često korištenih metrika za specifičnu operaciju. Konačno, na temelju naših nalaza, predlažemo niz preporuka za automatsku procjenu pojednostavljanja multioperacija, predlažeći koje metrike za računalo i kako\nda interpretiraju njihove rezultate.', 'cs': 'Abstrakt Pro zjednodušení vět lze provést několik operací přepisu, jako je nahrazení složitých slov za jednodušší synonyma, odstranění zbytečných informací a rozdělení dlouhých vět. Navzdory této multioperační povaze se hodnocení automatických zjednodušovacích systémů opírá o metriky, které středně korelují s lidskými úsudky o jednoduchosti dosažené prováděním konkrétních operací (např. zisk jednoduchosti založený na lexikálních nahrazeních). V tomto článku zkoumáme, jak dobře existující metriky mohou hodnotit zjednodušení na úrovni věty, kde mohlo být použito více operací a které proto vyžadují obecnější posouzení jednoduchosti. Za tímto účelem nejprve shromažďujeme novou a spolehlivější sadu dat pro hodnocení korelace metrik a lidských hodnocení celkové jednoduchosti. Za druhé provádíme první meta-hodnocení automatických metrik v textové zjednodušení s využitím naší nové datové sady (a dalších existujících dat) k analýze odchylky korelace mezi skóremi metrik a lidskými úsudky napříč třemi dimenzemi: vnímanou úrovní jednoduchosti, typem systému a sadou referencí použitých pro výpočet. Ukazujeme, že tyto tři aspekty ovlivňují korelace a zejména zdůrazňujeme omezení běžně používaných metrik specifických pro operaci. Na základě našich zjištění navrhujeme soubor doporučení pro automatické vyhodnocení zjednodušení víceoperačních operací, navrhujeme, které metriky vypočítat a jak\ninterpretovat jejich skóre.', 'fi': 'Lausekkeiden yksinkertaistamiseksi voidaan suorittaa useita uudelleenkirjoittamistoimia, kuten monimutkaisten sanojen korvaaminen yksinkertaisemmilla synonyymeillä, tarpeettoman tiedon poistaminen ja pitkien lauseiden jakaminen. Monitoimisesta luonteesta huolimatta automaattisten yksinkertaistamisjärjestelmien arviointi perustuu mittareihin, jotka korreloivat kohtalaisesti ihmisten arvioihin tiettyjen toimintojen suorittamisen yksinkertaisuudesta (esim. yksinkertaisuusvahvistus, joka perustuu leksikaalisiin korvauksiin). Tässä artikkelissa selvitämme, miten hyvin olemassa olevat mittarit voivat arvioida lausetason yksinkertaistuksia, joissa on voitu soveltaa useita toimintoja ja jotka vaativat siksi yleisempiä yksinkertaisuusarvioita. Tätä varten keräämme ensin uuden ja luotettavamman datakokonaisuuden mittaamaan mittarien korrelaatiota ja inhimillisten arviointien yleistä yksinkertaisuutta. Toiseksi suoritamme ensimmäisen metaarvioinnin automaattisista mittareista Tekstin yksinkertaistamisessa käyttäen uutta datajoukkoamme (ja muuta olemassa olevaa dataa) analysoidaksemme mittareiden pisteiden ja inhimillisten arviointien välisen korrelaation vaihtelua kolmella ulottuvuudella: koetun yksinkertaisuuden tasolla, järjestelmätyypissä ja laskennassa käytettyjen viitearvojen joukossa. Osoitamme, että nämä kolme näkökohtaa vaikuttavat korrelaatioihin ja korostamme erityisesti yleisesti käytettyjen operatiivisten mittareiden rajoituksia. Lopuksi esitämme havaintojemme perusteella joukon suosituksia useiden toimintojen yksinkertaistamisten automaattiseen arviointiin, joissa ehdotetaan, mitä mittareita lasketaan ja miten\ntulkita pisteitään.', 'et': 'Lausete lihtsustamiseks on v繭imalik teha mitmeid 羹mberkirjutamistoiminguid, n瓣iteks keerukate s繭nade asendamine lihtsamate s羹non羹羹midega, tarbetu info kustutamine ja pikkade lausete jagamine. Vaatamata sellele mitmeoperatsioonilisele olemusele tugineb automaatsete lihtsustamiss羹steemide hindamine m繭繭dukalt m繭繭dikutele, mis vastavad inimese otsustele konkreetsete toimingute l瓣biviimise lihtsuse kohta (nt lihtsuse kasv leksikaalsetel asendustel). Selles artiklis uurime, kui h瓣sti on olemasolevad m繭繭dikud v繭imalik hinnata lausetaseme lihtsustamist, kus v繭ib olla rakendatud mitu toimingut ja mis seet繭ttu n繭uavad 羹ldisemat lihtsustatud otsuseid. Selleks kogume esmalt uut ja usaldusv瓣瓣rsemat andmekogumit, et hinnata m繭繭dikute korrelatsiooni ja inimeste 羹ldise lihtsuse hinnangu korrelatsiooni. Teiseks teostame tekstilihtsustamises automaatsete m繭繭dikute esimese metahindamise, kasutades oma uut andmekogumit (ja muid olemasolevaid andmeid), et anal羹羹sida m繭繭dikute skooride ja inimotsuste vahelise korrelatsiooni varieerumist kolmes m繭繭tmes: tajutav lihtsustase tase, s羹steemi t羹羹p ja arvutamiseks kasutatavate viitete kogum. N瓣itame, et need kolm aspekti m繭jutavad korrelatsioone ja r繭hutavad eelk繭ige tavaliselt kasutatavate operatsioonispetsiifiliste m繭繭dikute piiranguid. L繭puks pakume oma tulemuste p繭hjal v瓣lja soovitused mitme toimingu lihtsustamise automaatseks hindamiseks, soovitades v瓣lja, milliseid m繭繭dikuid arvutada ja kuidas\net t繭lgendada oma tulemusi.', 'ha': "@ action: button Bayan ƙanãnan aiki masu yawa, evaluation na'urar masu sauƙi farat ɗaya yana dõgara a kan metric waɗanda ke yin husũma da hukuncin mutãne a kan sauti da aka samar da amfani masu ƙayyade (misali, amfani da muhimmi a kan shige masu leksikal). Daga wannan makala, Munã tambaya cewa masu da ma'anar metric masu jira zai iya ƙaddara saurin-daraja a inda an tambayi wasu aikin aiki mãsu yawa, kuma don haka, ana buƙata umarni mai saukarwa. Daga wannan, tuna samun wani danne na daban da ake iya amintarwa domin ka yi jãyayya a tsakanin metric da hukuncin mutane na rubuci. Piki, za mu yi amfani da farkon meta-evaluation na mitrics farat ɗaya cikin Kibainishi na Kibaini, don ka yi amfani da tsarin danne-yanzu (da wasu data wanda ke jira) dõmin ya yi analyi ga sãɓãnin da ke tsakanin da nau'in metrics da hukuncin mutãne a cikin hanyoyi uku: zane da na gane, nau'in na'ura, da daidaita misãlai wanda za'a yi amfani da wa lissafi. Tuna nũna cewa waɗannan sau biyu suna yi wa'azi ga mazaunin, kuma, haske, za'a nuna tsarin da ake yi amfani da shi da kawaici-misãlai. Gani, a kan da aka sami fassararmu, muna buƙata masu shauri farat ɗaya ga tunkuɗe masu aikin mutane, kuma tuna shawarar da wanne metric za'a lissafa ko da\nto interpret their scores.", 'he': 'Abstract למרות הטבע הרב-פעולה הזה, הערכה של מערכות הפשטות אוטומטיות תלויה במטריקות שמתואמות במידה עם השיפוטים האנושיים על הפשטות שנוצאות על ידי ביצוע פעולות מסוימות (למשל הרווח הפשטות מבוסס על החליפות לקסיות). במאמר הזה, אנו חוקרים עד כמה מטריות קיימות יכולות להעריך היטב את הפשטות ברמה של גזר המשפט איפה אפשרי שימוש במבצעים רבים ולכן דורשים שיפוטים פשוטים יותר כלליים. למען זה, קודם נאסוף קבוצת נתונים חדשה ויותר אמינה כדי להעריך את הקשר של מטריקה ושיפוטים אנושיים של פשטות כללית. שנית, אנו מבצעים את המטה-הערכה הראשונה של מטריקה אוטומטית בפשטות טקסט, באמצעות קבוצת הנתונים החדשה שלנו (ועוד נתונים קיימים) כדי לנתח את ההערכת של הקשר בין נקודות המטריקה לשיפוטים האנושיים בשלושה מימדים: רמת הפשוטה הנחשפת, סוג המערכת, וסוג התייחסות השתמשות לחישוב. אנחנו מראים ששלושת היבטים האלה משפיעות על הקשר ובמיוחד, מדגישים את הגבלות של מטריות ספציפיות לפעולה. סוף סוף, בהתבסס על הממצאים שלנו, אנו מציעים קבוצה ממלצות להערכה אוטומטית של הפשטות במבצעים רבים\nכדי לפרש את הציונים שלהם.', 'sk': 'Povzetek Za poenostavitev stavkov je mogoče izvesti več operacij prenovitve, kot so zamenjava kompleksnih besed za preprostejše sinonime, brisanje nepotrebnih informacij in razdelitev dolgih stavkov. Kljub tej večoperacijski naravi se vrednotenje sistemov avtomatske poenostavitve opira na meritve, ki zmerno povezujejo s človeškimi presojami o preprostosti, doseženi z izvajanjem določenih operacij (npr. pridobitev enostavnosti na podlagi leksikalnih nadomestil). V tem članku raziskujemo, kako dobro obstoječe meritve lahko ocenijo poenostavitve na ravni stavka, kjer je morda bilo uporabljenih več operacij in ki zato zahtevajo bolj splošne preproste presoje. Za to najprej zberemo nov in zanesljivejši nabor podatkov za ocenjevanje korelacije meritev in človeških presoj splošne preprostosti. Drugič, izvedli smo prvo metaevalvacijo avtomatskih meritev v programu Poenostavitev besedila z uporabo novega nabora podatkov (in drugih obstoječih podatkov) za analizo variacije korelacije med rezultati meritev in človeškimi presojami v treh dimenzijah: stopnji zaznane preprostosti, vrsti sistema in sklopa referenc, ki se uporabljajo za izračun. Pokazali smo, da ti trije vidiki vplivajo na korelacije in predvsem poudarjamo omejitve običajno uporabljenih meritev specifičnih operacij. Na podlagi naših ugotovitev predlagamo niz priporočil za samodejno ocenjevanje večoperacijskih poenostavitev, ki predlagajo, katere meritve je treba izračunati in kako\nda razlagajo svoje rezultate.', 'jv': 'Subtraction Nanging kabèh akeh operasi sistem multi-operasi iki, akeh lanian sistem semplikasi sistem sistem sistem sing dinopakan karo Metiks sing digawes-perusahaan karo hukum sistem sing dipun ciptaaken winih dhéwé, lan akeh dumadhi uwong sing nguasai perusahaan kanggo ngerasai operasi sing beraksi (isul prelimun akeh dumadhi podho akeh luwih nar Nang artiklo iki, kita sissisalakno piye soko akeh metika sing bisa tekan kelas Simplification barang nggawe barang nggawe operasi sing bisa aplikasi karo akeh operasi layang, dadi, njuk dianggap hukum sing sampeyan akeh akeh perusahaan. Saiki iki, awak dhéwé beraksi perusahaan langkung akeh data sing beraksi barêng-barêng nggawe gerakan kanggo kuwi nggawe gerakan kanggo Kemerdekaan karo dolanan sing beraksi barêng-barêng kanggo didasakno sing luwih apik dhéwé. Digawe, awak dhéwé beraksi perusahaan meta-assertisi sistem sing otomatik Metika kanggo Ketoken Simplification , nambah dhéwé data sistem gak dhéwé (barêng data sing beraksi barêng) kanggo nyelarasi perusahaan karo perusahaan karo dolar-dolar sing katêpakan karo dolar-dolar sing nganggep hukum sing telu dimensi: kedanungsak perusahaan seneng sampek, kalih sistem lan ake Awak dhéwé éntukno karo tanggal karo perusahaan mralaman karo nggawe, ngono nggawe barang nggawe barang nggawe operasi wis dipenekno operasi wis dipenekno. Tulung, digawe akham mulasai nggawe bukun\nDurangmu ngertuakaké xrané.', 'bo': "ལམ་ལུགས་འདི་ཆ་ཚིག་སྔོན་འཕགས་བྱེད་དགོས་ན། བསྐྱར་འབྲི་བཞིན་པའི་བཀོལ་སྤྱོད་འདི་དག་སྒྲུབ་པ་ཡིན། Despite this multi-operation nature, evaluation of automatic simplification systems relies on metrics that moderately correlate with human judgments on the simplicity achieved by executing specific operations (e.g., simplicity gain based on lexical replacements). In this article, we investigate how well existing metrics can assess sentence-level simplifications where multiple operations may have been applied and which, therefore, require more general simplicity judgments. For that, we first collect a new and more reliable data set for evaluating the correlation of metrics and human judgments of overall simplicity. Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics' scores and human judgments across three dimensions: the perceived simplicity level, the system type, and the set of references used for computation. We show that these three aspects affect the correlations and, in particular, highlight the limitations of commonly used operation-specific metrics. Finally, based on our findings, we propose a set of recommendations for automatic evaluation of multi-operation simplifications, suggesting which metrics to compute and how\nཁོང་ཚོའི་ཚད་རིས་གཞན་གཏོང་བ་དེ་རེད།"}
{'en': 'Are Ellipses Important for Machine Translation?', 'pt': 'As elipses são importantes para a tradução automática?', 'ar': 'هل القطع الناقص مهمة للترجمة الآلية؟', 'fr': 'Les points de suspension sont-ils importants pour la traduction automatique\xa0?', 'es': '¿Son importantes las elipses para la traducción automática?', 'ja': '楕円は機械翻訳にとって重要ですか？', 'zh': '省略号于机器翻译重乎?', 'hi': 'क्या दीर्घवृत्त मशीन अनुवाद के लिए महत्वपूर्ण हैं?', 'ru': 'Важны ли эллипсы для машинного перевода?', 'ga': 'An bhfuil Éilips Tábhachtach maidir le hAistriúchán Meaisín?', 'hu': 'Fontosak az ellipszisek a gépi fordítás szempontjából?', 'el': 'Είναι σημαντικές οι Ellipses για τη μηχανική μετάφραση;', 'lt': 'Are Ellipses Important for Machine Translation?', 'it': 'Le ellissi sono importanti per la traduzione automatica?', 'kk': 'Машин аудару үшін Ellipses маңызды ма?', 'ka': 'ვლთოჟთრვ ლთ ჟა გაზნთ ჱა მაქთნ ოპვგყპქგანვ?', 'ml': 'മെഷീന്\u200d പരിഭാഷക്കായി എലിപ്പിസുകള്\u200d പ്രധാനപ്പെട്ടതാണോ?', 'mt': 'L-Ellipses huma importanti għat-Traduzzjoni tal-Magni?', 'ms': 'Are Ellipses Important for Machine Translation?', 'no': 'Er Ellipser viktig for maskinsomsetjing?', 'mn': 'Дэлхийн зураг Машин хөрөнгө оруулахад чухал юу?', 'ro': 'Ellipsele sunt importante pentru traducerea automată?', 'pl': 'Czy elipsy są ważne dla tłumaczenia maszynowego?', 'sr': 'Da li je Elipse važna za prevod mašine?', 'so': 'Ellipses ma muhiim u yahay turjumaadda mashiinka?', 'si': 'එලිප්ස් වලට යන්ත්\u200dරය වාර්ථාව සඳහා වැදගත්වද?', 'sv': 'Är ellipser viktiga för maskinöversättning?', 'ta': 'இயந்திரத்தின் மொழிபெயர்ப்புக்கான Ellipses முக்கியமானதா?', 'ur': 'کیا الیپس ماشین ترجمہ کے لئے اہم ہیں؟', 'mk': 'Дали Елипсите се важни за машински превед?', 'uz': 'Ellips tarjima uchun muhim?', 'vi': 'Liệu Ellipses có quan trọng với việc dịch cỗ máy?', 'bg': 'Елипсите важни ли са за машинния превод?', 'hr': 'Da li je Ellipse važna za prevod stroja?', 'nl': 'Zijn Ellipsen belangrijk voor machinevertaling?', 'de': 'Sind Ellipsen wichtig für die maschinelle Übersetzung?', 'id': 'Apa Ellipses penting untuk Translation Mesin?', 'da': 'Er ellipser vigtige for maskinoversættelse?', 'fa': 'الیپز برای ترجمه ماشین مهم هستن؟', 'sw': 'Je Ellips ni muhimu kwa Tafsiri ya Mashine?', 'ko': '생략 번호는 기계 번역에 중요합니까?', 'tr': 'Ýylpikler maşynyň terjime üçin wajyp barmy?', 'af': 'Is Elipse belangrik vir Masjien Vertaling?', 'sq': 'A janë Elipset të rëndësishme për përkthimin e makinave?', 'am': 'undo-type', 'hy': 'Արդյո՞ք Էլիպսը մեքենայի թարգմանման համար կարևոր է:', 'bn': 'মেশিন অনুবাদের জন্য Ellipses কি গুরুত্বপূর্ণ?', 'az': 'Makin Çeviri üçün Elipsi möcüzdür?', 'et': 'Kas Ellipsid on masintõlke jaoks olulised?', 'ca': 'Elípsis són importants per a la traducció de màquines?', 'fi': 'Ovatko ellipsit tärkeitä konekäännöksen kannalta?', 'cs': 'Jsou elipsy důležité pro strojový překlad?', 'bs': 'Da li je Elipse važna za prevod mašine?', 'sk': 'Ali so elipse pomembne za strojni prevod?', 'jv': 'Kowe Perintah sing dikarepaké karo Manus Terjamahan?', 'he': 'האם אליפסים חשובים לתרגום מכונות?', 'ha': 'Shin, KCharselect unicode block name', 'bo': 'འཛིན་གྲངས་ནང་དུ་འདྲ་མིན་གཏོང་བར་གལ་ཆེན་ཡིན་ནམ།'}
{'en': 'Abstract This article describes an experiment to evaluate the impact of different types of ellipses discussed in theoretical linguistics on Neural Machine Translation (NMT), using English to Hindi / Telugu as source and target languages. Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the ellipsis, the frequency of such errors is slightly more in Telugu than Hindi, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents. These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target. We also observe that not all ellipses are translated poorly and benefit from reconstruction, advocating for a disparate treatment of different ellipses in MT research.', 'ar': 'الخلاصة توضح هذه المقالة تجربة لتقييم تأثير الأنواع المختلفة من الأشكال البيضوية التي نوقشت في علم اللغة النظري على الترجمة الآلية العصبية (NMT) ، باستخدام الإنجليزية إلى الهندية / التيلجو كلغات المصدر والهدف. يُظهر التقييم بالطرق اليدوية أن معظم الأخطاء التي ارتكبها Google NMT تقع في الجملة التي تحتوي على علامة القطع ، وأن تكرار مثل هذه الأخطاء في التيلوجو أكثر بقليل من اللغة الهندية ، وتظهر كفاية الترجمة تحسنًا عند إعادة بناء القطع الناقصة مع سوابقها. هذه النتائج لا تؤكد فقط أهمية العلامات الناقصة ودقتها في الترجمة الآلية ، ولكنها تشير أيضًا إلى وجود ارتباط محتمل بين ترجمة أجهزة الخطاب مثل القطع الناقص مع التناقض المورفولوجي للمصدر والهدف. نلاحظ أيضًا أنه لا تتم ترجمة جميع علامات الحذف بشكل سيئ وتستفيد من إعادة البناء ، والدعوة إلى معالجة متباينة للأشكال المختلفة في أبحاث الترجمة الآلية.', 'pt': 'Resumo Este artigo descreve um experimento para avaliar o impacto de diferentes tipos de elipses discutidos em linguística teórica na tradução automática neural (TNM), usando inglês para hindi/télugo como idiomas de origem e destino. A avaliação com métodos manuais mostra que a maioria dos erros cometidos pelo Google NMT estão localizados na oração que contém as reticências, a frequência desses erros é um pouco maior em Telugu do que em Hindi, e a adequação da tradução mostra melhora quando as elipses são reconstruídas com seus antecedentes. Esses achados não apenas confirmam a importância das elipses e sua resolução para a TM, mas também apontam para uma possível correlação entre a tradução de dispositivos discursivos como elipses com a incongruência morfológica da fonte e do alvo. Observamos também que nem todas as elipses são mal traduzidas e se beneficiam da reconstrução, defendendo um tratamento díspar de diferentes elipses na pesquisa de MT.', 'es': 'Resumen Este artículo describe un experimento para evaluar el impacto de diferentes tipos de elipses discutidos en lingüística teórica sobre la traducción automática neuronal (NMT), utilizando del inglés al hindi/telugu como idiomas de origen y de destino. La evaluación con métodos manuales muestra que la mayoría de los errores cometidos por Google NMT se encuentran en la cláusula que contiene los puntos suspensivos, la frecuencia de dichos errores es ligeramente mayor en telugu que en hindi, y la adecuación de la traducción mejora cuando las elipses se reconstruyen con sus antecedentes. Estos hallazgos no solo confirman la importancia de las elipses y su resolución para la MT, sino que también sugieren una posible correlación entre la traducción de los dispositivos del discurso como las elipses con la incongruencia morfológica de la fuente y el objetivo. También observamos que no todas las elipses se traducen mal y se benefician de la reconstrucción, lo que aboga por un tratamiento dispar de las diferentes elipses en la investigación de MT.', 'fr': "Résumé Cet article décrit une expérience visant à évaluer l'impact de différents types d'ellipses discutés en linguistique théorique sur la traduction automatique neuronale (NMT), en utilisant l'anglais vers l'hindi/telugu comme langues source et cible. L'évaluation avec des méthodes manuelles montre que la plupart des erreurs commises par Google NMT se situent dans la clause contenant les points de suspension, que la fréquence de ces erreurs est légèrement plus élevée en télougou qu'en hindi, et que l'adéquation de la traduction montre une amélioration lorsque les ellipses sont reconstruites avec leurs antécédents. Ces résultats confirment non seulement l'importance des ellipses et de leur résolution pour la TA, mais suggèrent également une corrélation possible entre la traduction de dispositifs de discours tels que les ellipses et l'incongruité morphologique de la source et de la cible. Nous observons également que toutes les ellipses ne sont pas mal traduites et ne bénéficient pas de la reconstruction, ce qui plaide pour un traitement disparate des différentes ellipses dans la recherche sur la magnétoscopie.", 'hi': 'सार यह लेख न्यूरल मशीन ट्रांसलेशन (एनएमटी) पर सैद्धांतिक भाषाविज्ञान में चर्चा किए गए विभिन्न प्रकार के दीर्घवृत्तों के प्रभाव का मूल्यांकन करने के लिए एक प्रयोग का वर्णन करता है, जो स्रोत और लक्षित भाषाओं के रूप में अंग्रेजी से हिंदी / तेलुगु का उपयोग करता है। मैनुअल विधियों के साथ मूल्यांकन से पता चलता है कि Google NMT द्वारा की गई अधिकांश त्रुटियां एलिप्सिस वाले खंड में स्थित हैं, ऐसी त्रुटियों की आवृत्ति हिंदी की तुलना में तेलुगु में थोड़ी अधिक है, और अनुवाद पर्याप्तता में सुधार दिखाता है जब दीर्घवृत्तों को उनके पूर्ववर्तियों के साथ पुनर्निर्मित किया जाता है। ये निष्कर्ष न केवल दीर्घवृत्त के महत्व और एमटी के लिए उनके संकल्प की पुष्टि करते हैं, बल्कि स्रोत और लक्ष्य की रूपात्मक असंगतता के साथ दीर्घवृत्त जैसे प्रवचन उपकरणों के अनुवाद के बीच एक संभावित सहसंबंध की ओर भी संकेत देते हैं। हम यह भी देखते हैं कि सभी दीर्घवृत्तों का खराब अनुवाद नहीं किया जाता है और पुनर्निर्माण से लाभ होता है, एमटी अनुसंधान में विभिन्न दीर्घवृत्तों के असमान उपचार की वकालत करते हैं।', 'zh': '摘要本文引一实验,以英语至印地语/泰卢固语为源言语,评论语言学异类者省略号神经机器翻译(NMT)之。 用手动之评,Google NMT所犯多谬在含省略号子句中,此谬频率略高于印地语于泰卢固语,并当省略号与前身重建,译充分性显改。 非唯效搏之大要,及其MT分辨率也,而示之以译与源与趣之形异者相关性。 观其所至,非所有之译皆差也,且有益于重建,故主MT论不同者。', 'ja': '要約この記事では、ヒンディー語/テルグ語への英語をソースおよびターゲット言語として、理論言語学で議論されている異なるタイプの楕円がニューラル・マシン・トランスレーション（ NMT ）に与える影響を評価するための実験について説明します。手動法による評価では、Google NMTによるエラーのほとんどが省略記号を含む節に位置しており、そのようなエラーの頻度はヒンディー語よりもテルグ語の方がわずかに多く、楕円体をその前段階で再構築すると翻訳の妥当性が改善されることが示されている。これらの知見は、楕円の重要性とMTに対するそれらの解像度を確認するだけでなく、楕円のような言説装置の翻訳とソースとターゲットの形態的不整合との間の相関の可能性を示唆しています。また、すべての楕円が不十分に翻訳され、再建の恩恵を受けるわけではないことを観察し、MT研究における異なる楕円の異なった扱いを提唱しています。', 'ru': 'Реферат Эта статья описывает эксперимент по оценке влияния различных типов эллипсов, обсуждаемых в теоретической лингвистике, на нейронный машинный перевод (НМП) с использованием английского языка для хинди/телугу в качестве исходного и целевого языков. Оценка ручными методами показывает, что большинство ошибок, сделанных Google NMT, находятся в положении, содержащем многоточие, частота таких ошибок в телугу немного больше, чем в хинди, а адекватность перевода показывает улучшение при реконструкции многоточий с их предшественниками. Эти выводы не только подтверждают важность эллипсов и их разрешение для MT, но также намекают на возможную корреляцию между переводом устройств дискурса, таких как эллипсы, с морфологической несогласованностью источника и цели. Мы также наблюдаем, что не все эллипсы плохо переведены и получают выгоду от реконструкции, выступая за различное обращение с различными эллипсами в исследованиях MT.', 'ga': 'Coimriú Déanann an t-alt seo cur síos ar thurgnamh chun meastóireacht a dhéanamh ar thionchar cineálacha éagsúla éilipsí a pléadh sa teangeolaíocht theoiriciúil ar Neural Machine Translation (NMT), ag baint úsáide as Béarla go Hiondúis / Teileagúis mar fhoinse agus mar sprioctheangacha. Léiríonn meastóireacht le modhanna láimhe go bhfuil an chuid is mó de na hearráidí a rinne Google NMT suite sa chlásal ina bhfuil an éilips, tá minicíocht earráidí den sórt sin beagán níos mó i Teileagúis ná i Hiondúis, agus léiríonn leordhóthanacht an aistriúcháin feabhas nuair a athchruthaítear éilipsí lena réamhchinneadh. Ní hamháin go ndeimhníonn na torthaí seo an tábhacht a bhaineann le héilipsí agus a réitigh do MT, ach tugann siad leid freisin i dtreo comhghaol féideartha idir aistriú gléasanna dioscúrsa cosúil le héilipsí agus neamhréireacht moirfeolaíoch na foinse agus na sprice. Tugaimid faoi deara freisin nach n-aistrítear gach éilips go dona agus go mbaineann siad leas as atógáil, rud a mholann cóireáil dhifriúil ar éilipsí éagsúla i dtaighde MT.', 'ka': 'აბსტრაქტიკური ამ წესტილის აღწერა ექსპერიმენტი, რომელიც განსხვავებული ტიპების ელიპსების ექსპერიმენტის შესახებ, რომელიც ტეორეტიკური ლუნგლისტიკში განსხვავებულია ნუპალური მაქსინის გან მანძილური მეტისთან განსაზღვრება ჩვენებს, რომ Google NMT-ის უფრო მეტი შეცდომები კლასოზაში, რომლებიც ელიპსისთან შექმნა, ასეთი შეცდომების სიგრძნობა ტელუგიში უფრო მეტია ჰინდისთან, და განსაზღვრების შესაძლებლობა ჩვენებს, როც ეს მონაცემები არა მხოლოდ ელიპსის და მისი გარეშექმნის მნიშვნელობას MT-სთვის, მაგრამ შესაძლებელი კოლექციის გარეშექმნის შორის, როგორც ელიპსის მოპოროლოგიური კონგულობას და მიზეზის. ჩვენ ასევე დავხედავთ, რომ არა ყველა ელიპსები ცოტა და გამოიყენება განსხვავებული ელიპსების განსხვავება MT სწავლებაში.', 'el': 'Περίληψη Αυτό το άρθρο περιγράφει ένα πείραμα για την αξιολόγηση της επίδρασης διαφορετικών τύπων ελλείψεων που συζητούνται στη θεωρητική γλωσσολογία στη Νευρική Μηχανική Μετάφραση (χρησιμοποιώντας τα Αγγλικά στα Χίντι/Τελούγκου ως γλώσσες προέλευσης και στόχου. Η αξιολόγηση με χειροκίνητες μεθόδους δείχνει ότι τα περισσότερα από τα σφάλματα που γίνονται από το Google NMT βρίσκονται στη ρήτρα που περιέχει την ελλείψεις, η συχνότητα τέτοιων σφαλμάτων είναι ελαφρώς μεγαλύτερη στα Τελούγκου παρά στα Χίντι, και η επάρκεια μετάφρασης δείχνει βελτίωση όταν οι ελλείψεις ανασχηματίζονται με τις προηγούμενες τους. Τα ευρήματα αυτά όχι μόνο επιβεβαιώνουν τη σημασία των ελλείψεων και την επίλυσή τους για τη ΜΤ, αλλά επίσης υποδηλώνουν μια πιθανή συσχέτιση μεταξύ της μετάφρασης συσκευών λόγου όπως οι ελλείψεις με τη μορφολογική ασυμφωνία της πηγής και του στόχου. Παρατηρούμε επίσης ότι δεν μεταφράζονται όλες οι ελλείψεις κακώς και επωφελούνται από την ανασυγκρότηση, υποστηρίζοντας μια διαφορετική αντιμετώπιση των διαφορετικών ελλείψεων στην έρευνα ΜΤ.', 'kk': 'Абстракты Бұл мақала теоретикалық тілдерде (NMT) аудару үшін, ағылшын тілдеріне инду/ Телуго тілдеріне көзі мен мақсатты тілдер ретінде талқылатын әртүрлі эллипс түрлерінің нәтижесін бағалау үшін тәжірибе Қолмен баптау әдістерімен Google NMT жасалған қателердің көпшілігі эллипсиясы бар клаузында, бұл қателердің жиілігі Телуго хиндидан артық, аудармалардың адекциясы өзінің аллипсиясынан қайта құрылғанда жақсартылығын көрсетеді. Бұл тапсырмалар тек элипс пен MT үшін айырмашылығының маңыздылығын тексермейді, сонымен қатар, көзі мен мақсаттың морфологиялық конгрессиялығы секілді дискурс құрылғыларының аудармасының арасындағы көмегі Біз сондай-ақ бүкіл елипс қайта аударылмайды және қайта құрылғанда, MT зерттеулерінде әртүрлі элипс лекцияларының әртүрлі лекцияларына қолдау үшін қолданылады.', 'lt': 'Abstraktas Šis straipsnis aprašo eksperimentą, skirtą įvertinti skirtingų elipsų tipų, aptartų teorinėje kalboje, poveikį neuroninių mašin ų vertimui (NMT), anglų kalba į Hindi/Telugą kaip šaltinis ir tikslinė kalba. Vertinimas naudojant rankinius metodus rodo, kad dauguma Google NMT padarytų klaidų yra pateiktoje skiltyje su elipsija, tokių klaidų dažnis Telugėje šiek tiek didesnis nei Hindi, o vertimo tinkamumas rodo pagerėjimą, kai elipsijos atkuriamos su jų antecedentais. Šie duomenys ne tik patvirtina elipsų svarbą ir jų rezoliuciją MT atžvilgiu, bet ir rodo galimą koreliaciją tarp diskursinių įtaisų, pvz., elipsų, vertimo su morfologiniu šaltinio ir tikslo neatitikimu. Taip pat pastebime, kad ne visos elipsės yra prastai išverstos ir gauna naudos iš atstatymo, skatinant skirtingą įvairių elipsų apdorojimą MT moksliniuose tyrimuose.', 'mk': 'Апстракт Оваа статија опишува експеримент за проценка на влијанието на различните типови на елипси дискутирани во теоретска лингвистика на преведувањето на невралните машини (НМТ), користејќи англиски на хинди/телугу како извор и метен јазик. Евалуацијата со рачни методи покажува дека повеќето грешки направени од Google NMT се лоцирани во клаузулата која ја содржи елипсата, фреквенцијата на ваквите грешки е малку поголема во Телугу отколку во Хиндија, а апсолутноста на преводот покажува подобрување кога елипсите се реконструирани со нивните претходни. Овие откритија не само што ја потврдуваат важноста на елипсите и нивната резолуција за МТ, туку и укажуваат на можна корелација помеѓу преводот на дискурсни уреди како елипсите и морфолошката несогласност на изворот и метата. Исто така, набљудуваме дека не сите елипси се лошо преведени и имаат корист од реконструкцијата, застапувајќи различен третман на различни елипси во истражувањето на МТ.', 'hu': 'Absztrakt Ez a cikk egy kísérletet ír le annak értékelésére, hogy az elméleti nyelvészetben tárgyalt ellipszisek különböző típusai milyen hatással vannak a neurális gépi fordításra (NMT). A kézi módszerekkel történő értékelés azt mutatja, hogy a Google NMT által elkövetett hibák többsége az ellipszist tartalmazó záradékban található, az ilyen hibák gyakorisága valamivel nagyobb telugu, mint hindi, és a fordítási megfelelőség javulást mutat, ha ellipsziseket rekonstruálnak az előzményeikkel. Ezek az eredmények nemcsak megerősítik az ellipszisek fontosságát és azok felbontását MT szempontjából, hanem arra is utalnak, hogy lehetséges korrelációt mutatnak a diskurzus eszközök, mint például az ellipszisek fordítása és a forrás és a cél morfológiai inkgruitása között. Azt is megfigyeljük, hogy nem minden ellipszis fordítása rosszul történik, és nem hasznos a rekonstrukcióból, amely a különböző ellipszisek eltérő kezelését javasolja az MT kutatásban.', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷകളില്\u200d സംസാരിക്കപ്പെട്ട എലിലിപ്പുകളുടെ പ്രഭാവം നിരീക്ഷിക്കാനുള്ള പരീക്ഷണത്തിനുള്ള പരീക്ഷണം ഈ ലേഖനം വിവരിക്കുന്നു. കൈകൊണ്ടുള്ള രീതികളുമായി പരിശോധിക്കുന്നത് കാണിക്കുന്നു ഗൂഗില്\u200d NMT ചെയ്ത പിശകുകളില്\u200d ഏറെയും പിശകുകള്\u200d എലിപ്സികള്\u200d ഉള്\u200dപ്പെടുത്തിയിരിക്കുന്ന ക്ലാസില്\u200d സ്ഥാപിക്കുന്നു.  These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target.  എല്ലാ എലിലിപ്പുകളും ദുര്\u200dബലമായി പരിഭാഷപ്പെടുത്തുന്നില്ലെന്നും, എംടിയിലെ വ്യത്യസ്ത പരിശോധനത്തില്\u200d വ്യത്യസ്ത പരിശോധനയു', 'ms': 'Abstract This article describes an experiment to evaluate the impact of different types of ellipses discussed in theoretical linguistics on Neural Machine Translation (NMT), using English to Hindi/Telugu as source and target languages.  Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the ellipsis, the frequency of such errors is slightly more in Telugu than Hindi, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents.  These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target.  We also observe that not all ellipses are translated poorly and benefit from reconstruction, advocating for a disparate treatment of different ellipses in MT research.', 'mt': 'Abstrat Dan l-artikolu jiddeskrivi esperiment biex jevalwa l-impatt ta’ tipi differenti ta’ elipsi diskussi f’lingwistika teoretika fuq it-Traduzzjoni ta’ Makkinarju Newrali (NMT), bl-użu tal-Ingliż għal Indjan/Telugwu bħala lingwi ta’ sors u fil-mira. Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the ellipsis, the frequency of such errors is slightly more in Telugu than Hindi, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents.  Dawn is-sejbiet mhux biss jikkonfermaw l-importanza tal-elipsi u r-riżoluzzjoni tagħhom għall-MT, iżda wkoll jindikaw korrelazzjoni possibbli bejn it-traduzzjoni ta’ apparat ta’ diskors bħal elipsi mal-inkogrunità morfoloġika tas-sors u l-mira. Aħna nnotaw ukoll li mhux l-elipsi kollha huma tradotti ħa żin u jibbenefikaw mir-rikostruzzjoni, filwaqt li nappoġġjaw trattament differenti ta’ elipsi differenti fir-riċerka MT.', 'no': 'Abstrakt Denne artikkelen beskriver ein eksperiment for å evaluera effekten av ulike typar ellipse som er diskutert i teoretisk språk på Neuralmaskinsomsetjing (NMT), med engelsk til Hindi/Telugu som kjeldespråk og målspråk. Evalueringa med manuelle metodar viser at dei fleste feilene Google NMT gjer i klausen som inneheld ellipser, frekvensen av desse feilene er litt meir i Telugu enn Hindi, og omsetjingsbehandlinga viser forbetringa når ellipser vert rekonstruert med antecedentene sine. Desse finningane stadfestar ikkje berre viktigheten for ellipser og oppløysinga for MT, men også hint til ein mogleg korrelasjon mellom omsetjinga av diskurseiningar som ellipser med morfologisk inkruitet av kjelden og målet. Vi observerer også at ikkje alle ellipser vert omsett slik dårlig og nyttig frå rekonstruksjon, som advokerer for ein forskjellig behandling av ulike ellipser i MT-forskning.', 'mn': 'Абстракт Энэ баримт мэдрэлийн машин хөрөнгө оруулах (NMT) теоретик хэл дээр ярилцсан олон төрлийн зуйвануудын нөлөөг үнэлэх туршилтыг илэрхийлж байна. Гарилгаан арга барилгаар дүгнэлт нь Google NMT-ын хийсэн алдаа ихэнх нь зуйвангуудыг дүгнэж байдаг гэдгийг харуулж байна. Тэдгээр алдааны давхар хэмжээ нь Хиндуудаас бага зэрэг илүү Телугуд байдаг. Эдгээр ололтууд зөвхөн зуйвангуудын чухал болон MT-ийн шийдвэрлэлийг баталдаг биш, гэхдээ зуйвангуудын төлөвлөгөө болон зорилготой морфологик бус байдлын харилцааны холбоотой байдлыг баталдаг. Мөн бид бүх зуйвангуудыг зөвхөн хөгжүүлж, сэтгэл хөдлөлөөс ашигтай болохгүй гэдгийг анзаарлаа. MT судалгаанд өөр төрлийн зуйвангуудын эмчилгээ дэмжиж байна.', 'it': "Questo articolo descrive un esperimento per valutare l'impatto di diversi tipi di ellissi discussi nella linguistica teorica sulla traduzione automatica neurale (NMT), utilizzando l'inglese all'hindi/telugu come lingue di origine e di destinazione. La valutazione con metodi manuali mostra che la maggior parte degli errori commessi da Google NMT si trovano nella clausola contenente le ellissi, la frequenza di tali errori è leggermente più in Telugu che in Hindi, e l'adeguatezza della traduzione mostra un miglioramento quando le ellissi vengono ricostruite con i loro antecedenti. Questi risultati non solo confermano l'importanza delle ellissi e la loro risoluzione per MT, ma suggeriscono anche una possibile correlazione tra la traduzione di dispositivi di discorso come le ellissi con l'incongruenza morfologica della fonte e del bersaglio. Osserviamo anche che non tutte le ellissi sono tradotte male e beneficiano della ricostruzione, sostenendo un trattamento disparato di diverse ellissi nella ricerca MT.", 'pl': 'Streszczenie Niniejszy artykuł opisuje eksperyment mający na celu ocenę wpływu różnych rodzajów elipsów omawianych w językoznawstwie teoretycznym na neuronalne tłumaczenie maszynowe (NMT), wykorzystując język angielski na hindi/telugu jako język źródłowy i docelowy. Ocena metodami ręcznymi pokazuje, że większość błędów popełnionych przez Google NMT znajduje się w punkcie zawierającym elipsę, częstotliwość takich błędów jest nieco większa w telugu niż w hindi, a adekwatność tłumaczenia pokazuje poprawę, gdy elipsy są rekonstruowane wraz z ich poprzednimi. Wyniki te nie tylko potwierdzają znaczenie elipsów i ich rozdzielczość dla MT, ale również wskazują na możliwą korelację między tłumaczeniem urządzeń dyskursujących, takich jak elipsy, a morfologiczną niezgodnością źródła i celu. Obserwujemy również, że nie wszystkie elipsy są słabo tłumaczone i korzystają z rekonstrukcji, opowiadając się za różnym traktowaniem różnych elipsów w badaniach MT.', 'sr': 'Abstrakt Ovaj članak opisuje eksperiment za procjenu utjecaja različitih vrsta elipse koji su razgovarali teorijskim jezicima na Neuralnu mašinu prevodu (NMT), koristeći engleski na Hindi/Telugu kao izvor i ciljni jezik. Evaluacija ručnim metodama pokazuje da većina grešaka koje je napravio Google NMT nalazi se u klauzuli koja sadrži elipse, frekvencija takvih grešaka je malo više u Telugu nego Hindiju, a adekvatnost prevoda pokazuje poboljšanje kada se elipse rekonstruiraju sa svojim predsednicima. Ovi nalazi ne samo potvrđuju važnost elipse i njihove rezolucije za MT-a, nego takođe ukazuju na moguću korelaciju između prevoda uređaja diskursa poput elipse sa morfološkom neskladnošću izvora i cilja. Takoðe posmatramo da ne svi elipse nisu loše prevedeni i koristi od rekonstrukcije, advokacije za različite tretmane različitih elipse u istraživanju MT-a.', 'si': 'මේ ලිපිනය ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරයෝජනයක් වෙනස් වර්ගයක් ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ න්\u200dයුරාල්  අවශ්\u200dය විධානය සමඟ ප්\u200dරවේශනය පෙන්වන්නේ ගුගුල් NMT වලින් කරපු වැරැද්දක් ගොඩක් ගොඩක් වැරැද්දක් ඉලිපිස් වලින් තියෙනවා කියලා, මේ වැරැද්දක් ප්\u200dරවේශනය තෙලුග මේ හොයාගන්නේ එලිප්ස් සහ MT විශේෂය සඳහා ඔවුන්ගේ විශේෂතාවක් විතරයි නෙවෙයි, නමුත් පුළුවන් සම්බන්ධ උපකරණය වගේ භාවිතාවක් සමඟ අපි පරික්ෂා කරනවා හැම දෙයක්ම බොරු විදියට පරික්ෂා කරන්නේ නැහැ කියලා, MT පරික්ෂණයේ වෙනස් දෙයක් වෙනස් දෙයක් විදියට', 'so': "Abstract Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the ellipsis, the frequency of such errors is slightly more in Telugu than Hindi, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents.  Helitaankaasu waxay ku xaqiijiyaan muhiimka jiilaalka iyo go'aankooda ee MT oo keliya, laakiin waxay sidoo kale ku hindisaan xiriir suurtagal ah oo u dhexeeya turjumidda qalabka hadalka, sida ellipses la xiriira dhamaanta dhaqaalaha iyo waxyaabaha ay ku jiraan. Sidoo kale waxaynu aragnaa in aysan dhamaan waxyaabaha lagu turjumo si xun iyo faa’iido looga baahan yahay dhisidda, taasoo looga talin karo daryeel kala duduwan baaritaanka baaritaanka MT.", 'sv': 'Sammanfattning Denna artikel beskriver ett experiment för att utvärdera effekten av olika typer av ellipser diskuterade i teoretisk lingvistik på neural maskinöversättning (NMT), med hjälp av engelska till hindi/telugu som källa- och målspråk. Utvärdering med manuella metoder visar att de flesta av felen som gjorts av Google NMT finns i satsen som innehåller ellipsen, frekvensen av sådana fel är något mer på telugu än hindi, och översättningen visar förbättring när ellipser rekonstrueras med sina företeelser. Dessa fynd bekräftar inte bara betydelsen av ellipser och deras upplösning för MT, utan antyder också en möjlig korrelation mellan översättning av diskursanordningar som ellipser med den morfologiska inkonsekvensen hos källan och målet. Vi konstaterar också att inte alla ellipser översätts dåligt och gynnas av rekonstruktion, vilket förespråkar en olikartad behandling av olika ellipser i MT forskning.', 'ro': 'Acest articol descrie un experiment de evaluare a impactului diferitelor tipuri de elipse discutate în lingvistica teoretică asupra traducerii automate neurale (NMT), folosind limba engleză în hindi/telugu ca limbi sursă și țintă. Evaluarea cu metode manuale arată că majoritatea erorilor făcute de Google NMT se află în clauza care conține elipsa, frecvența acestor erori este puțin mai mare în telugu decât în hindi, iar caracterul adecvat al traducerii arată o îmbunătățire atunci când elipsele sunt reconstruite cu antecedentele lor. Aceste constatări nu numai că confirmă importanța elipselor și rezoluția lor pentru MT, ci și sugerează că există o posibilă corelație între traducerea dispozitivelor de discurs precum elipsele și incongruența morfologică a sursei și țintei. Observăm, de asemenea, că nu toate elipsele sunt traduse slab și beneficiază de reconstrucție, pledând pentru un tratament disparat al diferitelor elipse în cercetarea MT.', 'ur': 'یہ لکھا ایک آزمائش کا مطابق بیان کرتا ہے کہ انگلیسی کو ہینڈی/ٹیلوگو کے ساتھ سورج اور موجود زبانوں کے طور پر بحث کی تئوریٹی زبان شناسی میں مشورہ کیا گیا ہے۔ مہمانی طریقے کے مطابق ارزیابی دکھاتی ہے کہ گوگل NMT کی اکثریت خطاؤں میں الیپیس کے ساتھ موجود ہیں، یہ خطاؤں کا فرکانس ہندی سے بہت کم زیادہ ہے، اور ترجمہ adequacy دکھاتی ہے جب الیپیس ان کی آنٹیسڈینٹوں کے ساتھ دوبارہ ساختہ کیے جاتے ہیں۔ یہ نتیجے صرف الیوپز اور ان کی روشنی MT کے لئے مطمئن نہیں کرتے، بلکہ یہ بھی موجود بات دستگاه کی ترجمہ کے درمیان ایک قابل تعلق کی طرف نشان دیتے ہیں جیسے الیوپز کے ساتھ سورج اور موجود کے موجود غیرقابل تعلق کے ساتھ. ہم نے بھی دیکھا ہے کہ تمام الیوپز بد ترجمہ نہیں کیا جاتا اور دوبارہ ساختہ کرنے سے فائدہ اٹھائے جاتے ہیں، MT تحقیق میں مختلف الیوپز کے معاملہ کے لئے پکارتے ہیں.', 'ta': 'இந்த கட்டுரையை விளக்கும் ஒரு பரிசோதனையை குறிப்பிடுகிறது மூலம் மற்றும் சேர்க்கும் மொழிகளாக மூலம் மற்றும் இலக்கு மொழிகளை பயன்படுத்தி வித்திய வித்தியாசமான ம கைமுறைமைகளுடன் பார்க்கப்படும் பொழுது கூகுல் NMT செய்த பெரும்பாலான பிழைகள் எலிப்ஸில் உள்ள குறிப்பில் உள்ளன, இது பிழைகளின் frequency குறைந்தது ஹின்டிவை விட ட ட டெல்குவில் அதிகமாக இந்த கண்டுபிடிப்புகள் எம்டி க்கான முக்கியத்தையும் தெளிவுத்திறனையும் மட்டும் உறுதி செய்ய முடியாது, மூலம் மற்றும் இலக்குகளுடன் மொழிபெயர்ப்பு மொ மேலும் நாம் அனைத்து எலிலப்புகளும் மாற்றப்படுகிறது என்பதை பார்க்கிறோம். மீண்டும் உருவாக்கத்திலிருந்து நன்மையாக மாற்றப்', 'vi': 'Bản tóm tắt Bài viết này mô tả một thử nghiệm để đánh giá tác động của các loại hình êlíp được thảo luận trong ngôn ngữ học thuyết về dịch lắp máy thần kinh (NMB), sử dụng tiếng Anh với tiếng Hindi/Tiếng Anh làm nguồn và ngôn ngữ đích. Bài đánh giá bằng các phương pháp bằng tay cho thấy hầu hết lỗi của Google NMT nằm trong điều khoản có hình vệ tinh, tần số của những lỗi này ở Telug còn hơn cả tiếng Ấn, và độ chuẩn dịch cho thấy khả năng phục hồi hình êlíp bằng tiền trước. Những kết quả này không chỉ xác nhận tầm quan trọng của các hình êlíp và giải quyết của chúng cho MTV, mà còn gợi ý tới một mối tương quan có thể giữa dịch các thiết bị ngôn luận như hình êlíp với sự bất đồng lịch sự của nguồn và mục tiêu. Chúng tôi cũng nhận thấy rằng không phải tất cả hình êlíp đều được dịch sai và lợi ích từ sự tái tạo, ủng hộ cho một sự phân biệt về hình êlíp trong nghiên cứu MTV.', 'uz': "Name Qoʻlbola usullar bilan tasdiqlash imkoniyatini koʻrsatish mumkin, Google NMT'ning ko'pchiligi xatolar ellipsis bilan boshlanadigan boshqa soʻzda joylashadi, bu xatolarning freymi Hindidan ham qisqa ko'proq, va tarjima qilish qisqacha o'zgarishlarni tasdiqlashda o'zgartiradi. Bu natijalar faqat ellipslar va MT uchun ularning muhimligini тасдиқлай emas, balki suhbat uskunalarning o'rganish imkoniyatlariga o'rganish mumkin, balki suhbat uskunalarning o'rganish mumkin. Ko'rib chiqqamiz, hamma ellipselar yomon tarjima qilinadi, MT ta'minlovchisidan boshqa shakllarni ajratish uchun foydalanadi.", 'bg': 'Резюме Настоящата статия описва експеримент за оценка на въздействието на различните видове елипси, обсъдени в теоретичната лингвистика върху невралния машинен превод (НМТ), използвайки английски на хинди/телугу като изходни и целеви езици. Оценката с ръчни методи показва, че повечето грешки, допуснати от Гугъл НМТ, се намират в клаузата, съдържаща елипсите, честотата на такива грешки е малко по-голяма в телугу, отколкото в хинди, а адекватността на превода показва подобрение при реконструкция на елипсите с техните предшественици. Тези находки не само потвърждават значението на елипсите и тяхната резолюция за МТ, но и намекват за възможна корелация между превода на дискурсни устройства като елипсите с морфологичната несъответствия на източника и целта. Също така отбелязваме, че не всички елипси се превеждат лошо и се възползват от реконструкцията, като се застъпва за различно лечение на различните елипси в изследванията на МТ.', 'da': 'Denne artikel beskriver et eksperiment med henblik på at evaluere effekten af forskellige typer ellipser diskuteret i teoretisk lingvistik på Neural Machine Translation (NMT) ved hjælp af engelsk til hindi/telugu som kilde- og målsprog. Evaluering med manuelle metoder viser, at de fleste fejl begået af Google NMT er placeret i sætningen indeholdende ellipsen, hyppigheden af sådanne fejl er lidt mere i telugu end hindi, og oversættelsesmæssigheden viser en forbedring, når ellipser rekonstrueres med deres forudgående. Disse fund bekræfter ikke blot betydningen af ellipser og deres opløsning for MT, men antyder også en mulig sammenhæng mellem oversættelsen af diskursenheder som ellipser med kildens og målets morfologiske inkorenhed. Vi bemærker også, at ikke alle ellipser oversættes dårligt og drager fordel af rekonstruktion, hvilket går ind for en forskellig behandling af forskellige ellipser i MT forskning.', 'de': 'Abstract Dieser Artikel beschreibt ein Experiment zur Evaluierung des Einflusses verschiedener Ellipsentypen, die in der theoretischen Linguistik diskutiert werden, auf die neuronale maschinelle Übersetzung (NMT) unter Verwendung von Englisch zu Hindi/Telugu als Ausgangs- und Zielsprache. Die Auswertung mit manuellen Methoden zeigt, dass sich die meisten Fehler von Google NMT in dem Satz befinden, der die Ellipse enthält, die Häufigkeit solcher Fehler ist etwas häufiger in Telugu als in Hindi, und die Übersetzungsaadäquanz zeigt eine Verbesserung, wenn Ellipsen mit ihren Vorgängern rekonstruiert werden. Diese Ergebnisse bestätigen nicht nur die Bedeutung von Ellipsen und deren Auflösung für MT, sondern deuten auch auf eine mögliche Korrelation zwischen der Übersetzung von Diskurseinrichtungen wie Ellipsen mit der morphologischen Inkongruenz von Quelle und Ziel hin. Wir beobachten auch, dass nicht alle Ellipsen schlecht übersetzt werden und von Rekonstruktionen profitieren, was für eine unterschiedliche Behandlung verschiedener Ellipsen in der MT-Forschung spricht.', 'id': 'Abstrakt Artikel ini menggambarkan eksperimen untuk mengevaluasi dampak dari jenis elips yang berbeda yang didiskusikan dalam bahasa teori pada Translation Neural Machine (NMT), menggunakan bahasa Inggris ke Hindi/Telugu sebagai sumber dan bahasa sasaran. Evaluasi dengan metode manual menunjukkan bahwa kebanyakan kesalahan yang dibuat oleh Google NMT terletak dalam klausul yang mengandung elipsi, frekuensi kesalahan tersebut sedikit lebih dalam Telugu daripada Hindi, dan adekwatesi terjemahan menunjukkan peningkatan ketika elipsi dibangun kembali dengan anteceden mereka. Penemuan ini tidak hanya mengkonfirmasi penting elips dan resolusi mereka untuk MT, tetapi juga menunjukkan ke sebuah korelasi mungkin antara terjemahan perangkat diskors seperti elips dengan ketidaksamaan morfologi sumber dan sasaran. Kami juga memperhatikan bahwa tidak semua elips diterjemahkan buruk dan berguna dari rekonstruksi, mendukung untuk perawatan yang tidak sama dari elips yang berbeda dalam penelitian MT.', 'ko': '본고는 영어부터 인디언/테루고어를 원어와 목표어로 하고 이론언어학에서 논의된 다양한 유형의 생략호가 신경기계번역(NMT)에 미친 영향을 평가하는 실험을 요약한다.인공 평가에 따르면 Google NMT의 대부분 오류는 줄임말이 포함된 종문에 있는데, 이러한 오류는 타이루고어에서 인디언보다 발생률이 약간 높고, 줄임말이 그들의 선행어와 함께 재구성될 때 번역의 충분성이 개선된 것으로 나타났다.이러한 발견은 생략과 기계 번역에 대한 중요성을 증명할 뿐만 아니라 생략 등 문장 수단의 번역이 원어와 목표어의 형태 불일치성과 관련이 있음을 암시한다.우리는 또한 모든 생략호가 잘 번역되지 않고 재건에서 이익을 얻는 것은 아니기 때문에 기계 번역 연구에서 서로 다른 생략호에 대해 서로 다른 처리를 제창한다.', 'sw': 'Abstract This article describes an experiment to evaluate the impact of different types of ellipses discussed in theoretical linguistics on Neural Machine Translation (NMT), using English to Hindi/Telugu as source and target languages.  Uchunguzi wa njia za mkono unaonyesha kwamba makosa mengi yaliyofanywa na Google NMT yanawekwa katika makala yenye maelezo hayo, kiwango cha makosa haya ni kidogo zaidi katika Telugu kuliko Hindi, na tafsiri inaonyesha kuboreshwa pale mafua yanapojengwa tena kwa matukio yao. Matokeo haya siyo tu yanathibitisha umuhimu wa mafanikio na suluhisho lao kwa ajili ya MT, bali pia huzungumzia uhusiano wa uwezekano kati ya kutafsiri vifaa vya mazungumzo kama vile vifaa vya mazungumzo vinavyotokana na ukosefu wa kifolojia wa chanzo na lengo hilo. Pia tunaona kwamba sio maeneo yote yanatafsiriwa vibaya na faida mbaya kutoka kwa ujenzi, wakitetea matibabu tofauti ya maarifa katika utafiti wa MT.', 'nl': 'Abstract Dit artikel beschrijft een experiment om de impact te evalueren van verschillende soorten ellipsen die in de theoretische taalkunde worden besproken op Neural Machine Translation (NMT), waarbij Engels naar Hindi/Telugu wordt gebruikt als bron- en doeltaal. Evaluatie met handmatige methoden toont aan dat de meeste fouten gemaakt door Google NMT zich bevinden in de clausule met de ellipsis, de frequentie van dergelijke fouten is iets meer in het Telugu dan Hindi, en de vertaaltoereikendheid toont verbetering wanneer ellipsen worden gereconstrueerd met hun voorouders. Deze bevindingen bevestigen niet alleen het belang van ellipsen en hun resolutie voor MT, maar wijzen ook op een mogelijke correlatie tussen de vertaling van discoursapparaten zoals ellipsen met de morfologische incongruïteit van bron en doelwit. We zien ook dat niet alle ellipsen slecht vertaald zijn en profiteren van reconstructie, wat pleit voor een ongelijke behandeling van verschillende ellipsen in MT-onderzoek.', 'hr': 'Abstrakt Ovaj članak opisuje eksperiment za procjenu utjecaja različitih vrsta elipse raspravljenih u teorijskom jeziku na neurološki prevod strojeva (NMT), koristeći engleski na Hindi/Telugu kao izvor i ciljni jezik. Procjenjivanje ručnim metodama pokazuje da se većina grešaka koje je napravio Google NMT nalazi u klauzuli koja sadrži ellipse, učestalost takvih grešaka je malo više u Telugu nego Hindiju, a adekvatnost prevoda pokazuje poboljšanje kada se ellipse rekonstruiraju s njihovim predsednicima. Ovi nalazi ne samo potvrđuju važnost elipse i njihove rezolucije za MT, nego također ukazuju na moguću korelaciju između prevoda diskursnih uređaja poput elipse sa morfološkom neskladnošću izvora i cilja. Također primjećujemo da nisu svi elipse loše prevedeni i koristi od rekonstrukcije, koji se obraćaju za različito liječenje različitih elipse u istraživanju MT-a.', 'tr': 'Abstrakt Bu makala nähili milletler Jewral Maşynyň terjime (NMT), Iňlisçe Hindi/Telugu dilinde görnüş we maksat dilinde gürrüňleýän ellipseleriň netijesini çözmek üçin bir denedi tassyklaýar. El ýagdaýy bilen deňlenme ýagdaýynda Google NMT tarapyndan eden ýalňyşlaryň köpüsi ellipsi bilen ýene-de bolup barýandygyny görkezýär, ýaly ýalňyşlaryň frekansyny Hindi ň ýüzünde Teluguda biraz köp däldir we terjime etmek isleýänligini görkezýär. Bu tapmalar diňe elipseleriň we çözümleriniň wajyplygyny takyklaýar, ýöne çeşme we maksadyň morfolojik döwürmegi bilen elipseler ýaly gürrüňleriň terjime edilmesine kömek edip biler. Biz hemme elipseler ýaman terjime edilmedigini we ýene-de ýene-de bir nusga alyp bilýäris, MT araştyrmalarynda farklı elipseler üçin üýtgeşik.', 'fa': 'این مقاله یک آزمایش را برای ارزیابی تاثیر نوع الیپس مختلف در زبان تئوریسی بر ترجمه ماشین عصبی (NMT) توصیف می\u200cکند، از انگلیسی به هندی/تلوگو به عنوان زبان منبع و هدف استفاده می\u200cکند. ارزیابی با روش\u200cهای دستی نشان می\u200cدهد که بیشتر اشتباهی که توسط گوگل NMT ساخته شده\u200cاند در قطعه\u200cای که شامل الیپیس است، فرکانس چنین اشتباهی کمی بیشتر از هندی است، و فرکانس\u200cهای چنین اشتباهی در تلوگو بیشتر از هندی است، و فرکانس\u200cهای ترجمه\u200cای بهتری را نشان می\u200cدهد وقتی الیپیس این نتیجه\u200cها نه تنها اهمیت الیپس\u200cها و حل\u200cسازی\u200cهایشان برای MT تایید می\u200cکنند، بلکه همچنین نشان می\u200cدهند به رابطه ممکن بین ترجمه\u200cسازی دستگاه\u200cهای صحبت مانند الیپس\u200cها با غیرقابلیت مورفولوژیک منبع و هدف. ما همچنین مشاهده می\u200cکنیم که همه الیپس\u200cها بد ترجمه نمی\u200cشوند و سود از بازسازی می\u200cشوند، برای درمان مختلف الیپس\u200cهای مختلف در تحقیقات MT پژوهش می\u200cکنند.', 'sq': 'Abstrakt Ky artikull përshkruan një eksperiment për të vlerësuar ndikimin e llojeve të ndryshme elipsesh diskutuar në gjuhën teorike në Translacionin e Makinës Neurale (NMT), duke përdorur anglisht në Hindi/Telugu si burim dhe gjuhë objektiv. Vlerësimi me metodat manuale tregon se shumica e gabimeve të bëra nga Google NMT janë vendosur në klauzulën që përmban elipsin, frekuenca e gabimeve të tilla është paksa më e madhe në Telugu se në Hindi dhe përshtatja e përkthimit tregon përmirësimin kur elipset rindërtohen me antecedentet e tyre. Këto gjetje jo vetëm konfirmojnë rëndësinë e elipseve dhe rezolutën e tyre për MT, por gjithashtu tregojnë drejt një korrelacioni të mundshëm midis përkthimit të pajisjeve diskursore si elipset me mospërputhjen morfologjike të burimit dhe objektivit. Ne gjithashtu vëzhgojmë se jo të gjitha elipset përkthehen keq dhe përfitojnë nga rindërtimi, duke mbrojtur për një trajtim të pabarazishëm të elipseve të ndryshme në kërkimin e MT.', 'af': "Abstrak Hierdie artikel beskrywe 'n eksperiment om die effekt van verskillende tipes elipse te evalueer wat in teorieese lingwisies gespreek is op Neurale Masjien Vertaling (NMT), gebruik Engels na Hindi/Telugu as bron en doel tale. Evaluasie met manuele metodes vertoon dat die meeste van die foute gemaak deur Google NMT in die klause wat die elipse bevat, die frekwensie van sodanige foute is bietjie meer in Telugu as Hindi, en die vertaling adekuasie vertoon verbetering wanneer elipse herstel word met hul antecedentes. Hierdie vindings bevestig nie slegs die belangrikheid van elipse en hulle resolusie vir MT nie, maar ook vir 'n moontlike korrelasie tussen die vertaling van diskurstoestelle soos ellipse met die morfologiese inkonruiteit van die bron en doel. Ons het ook aanmerk dat nie alle elipse verkeerd vertaal word en voordeel van rekonstruksie, wat vir 'n verskillende behandeling van verskillende elipse in MT-ondersoek bevestig word nie.", 'am': 'ይህ ጽሑፍ የኢንጂንድ/ቴልጉን ምዕራፍ እና የዕድሜ ቋንቋ በመጠቀም በኔural Machine ትርጓሜ ላይ የተነጋገረውን የኢንሊፕቶችን ቋንቋዎች የልዩ ዓይነት የኢሊፕዮጵያዎች ግንኙነትን ለማረጋገጥ ፈተና ይናገራል፡፡ በኃይል ሥርዓቶች ላይ የተመሳሳይ የጎግል NMT የተደረገውን ብዙዎቹ ስህተቶች ኤሊፕሲሲን በተያዙ ክፍል ውስጥ ናቸው፣ የዚህ ስህተቶች ቁጥር ከኪንዲ ይልቅ በቴልጉግ ይበዛል፡፡ እነዚህ ፍጥረቶች የኤሊፕሎጂዎች እና የልዩነታቸውን ማስታወቂያ ብቻ አይደለም፣ ነገር ግን በመድረክ እና በተቃውሞው የሞፎሎጂ ክፍል በተደረገ የንግግር አካባቢዎች መካከል ግንኙነት እንዲያረጋግጡ ይቻላል፡፡ እናም የኤሊፕላን ሁሉ ድህነት እንዳይተረጉም እና ጥቅም እንዳይሆን እናየዋለን፡፡', 'hy': 'Աբստրակտ Այս հոդվածը նկարագրում է փորձ, որպեսզի գնահատենք տարբեր տեսակի էլիպսիների ազդեցությունը, որը քննարկվում է տեսական լեզվաբանության մեջ նյարդային մեքենայի թարգմանման վրա (NMT), օգտագործելով անգլերեն Հինդի և Թելուգու որպես Գրային մեթոդների օգնությամբ գնահատումը ցույց է տալիս, որ Google NMT-ի կողմից կատարված սխալների մեծ մասը գտնվում է էլիպսի պարագայում, այսպիսի սխալների հաճախականությունը թեկուզ ավելի շատ է Թելուգում, քան Հինդին, և թարգմանման համապատասխանությունը ցույց է տալիս զարգացում, երբ էլիպսիները վեր These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target.  Մենք նաև նկատում ենք, որ ոչ բոլոր էլիպսերը վատ են թարգմանվում և օգտակար են վերականգնումից, պաշտպանելով ՄԹ ուսումնասիրության մեջ տարբեր էլիպսերի անհավասար բուժումը:', 'bn': 'এই প্রবন্ধে বিভিন্ন ধরনের ইলিপের প্রভাব মূল্যায়নের একটি পরীক্ষা বর্ণনা করে নিউরাল মেশিন অনুবাদ (এনএমটি) ব্যবহার করে ইংরেজী থেকে হিন্দি/টেলুগুয়া থেকে সোর্স এব হিন্দির চেয়ে বেশীরভাগ গুগল এনএমটি দ্বারা ত্রুটির প্রমাণ প্রদর্শন করেছে যে এলিপসিসের মধ্যে রয়েছে তাদের বেশীরভাগ ভুলের মধ্যে রয়েছে, এই সমস্ত ভুলের ফ্রেন্স হিন্দির চেয়ে তেলুগুতে বেশ এগুলো খুঁজে পাওয়া যাচ্ছে না শুধু এমটির গুরুত্বপূর্ণ এবং তাদের সিদ্ধান্ত নিশ্চিত করা যায় না, বরং উৎস এবং লক্ষ্যবস্তুর মাধ্যমে যে সমস্ত বাক্য যন্ত্র অনু এমটিটি গবেষণায় বিভিন্ন এলিপিসের বিভিন্ন চিকিৎসার জন্য আমরা দেখি যে সকল এলিপিস দুর্বল এবং পুনঃনির্মাণ থেকে লাভ করা হয় না।', 'az': "Bu məlumat nöral Makin Çevirməsi (NMT) və Hindi/Telugu dillərinin mənbəzi və məqsəd dillərinə mübahisə edilən teoretik dillərin təsirini değerləşdirmək üçün bir təcrübə təcrübə edir. Əlavə metodları ilə müəyyən edilmə göstərir ki, Google NMT ilə etdiyi hataların çoxu ellipsi içərisində bulunduğu clauzun içində, bu hataların frequenci Hindistan'dan biraz daha çox Telugu'da, və çevirim adeqliyyatı ellipsilərin öndəlikləri ilə yenidən in şa edildikdə yaxşılıqlarını göstərir. Bu tapılar ancaq ellipsilərin və MT üçün çözünürlüklərinin vacibətini təsdiqləməsini təsdiqləyir, ancaq mənbəsinin və məqsədinin morfolojik müəyyən edilməsi ilə ellipsi kimi söhbət cihazlarının çevirilməsi barəsində mümkün bir bağlantılıq təsdiqləyir. Biz də gözləyirik ki, bütün ellipsilər kötü bir dəyişiklik və yenidən in şall a şdırılmaqdan fayda vermir, MT araştırmalarında fərqli ellipsi təhsil etmək üçün müxtəlif təhsil edirlər.", 'ca': "Abstract Aquest article descriu un experiment per avaluar l'impacte de diferents tipus d'elipses discutidas en la lingüística teòrica sobre la traducció neuronal de màquines (NMT), utilitzant anglès a hindí/telugu com a llengües de font i alvo. L'evaluació amb mètodes manuals mostra que la majoria dels errors fets per Google NMT es troben en la clàusula que conté l'elipsi, la freqüència d'aquests errors és una mica més a Telugu que a Hindi, i la adequació de traducció mostra millor quan les elipsis es reconstruiuen amb els seus antecedents. Aquests descobriments no només confirman l'importància de les elipses i la seva resolució per a MT, sinó també indican una possible correlació entre la traducció de dispositius de discurs com les elipses amb la incongruència morfològica de la font i l'alv. També observem que no totes les elipses són mal traduïdes i beneficien de la reconstrucció, defensant un tractament desigual de diferents elipses en la recerca MT.", 'cs': 'Abstrakt Tento článek popisuje experiment pro hodnocení vlivu různých typů elips diskutovaných v teoretické lingvistice na neuronový strojový překlad (NMT) s využitím angličtiny do hindštiny/telugu jako zdrojových a cílových jazyků. Vyhodnocení ručními metodami ukazuje, že většina chyb Google NMT se nachází v klauzuli obsahující elipsy, četnost takových chyb je v telugu o něco větší než v hindštině a adekvátnost překladu ukazuje zlepšení při rekonstrukci elipsy s jejich předchůdci. Tyto zjištění nejen potvrzují význam elips a jejich rozlišení pro MT, ale také naznačují možnou korelaci mezi překladem diskurzních zařízení, jako jsou elipsy, s morfologickou nesouladou zdroje a cíle. Dále pozorujeme, že ne všechny elipsy jsou špatně přeloženy a mají prospěch z rekonstrukce, což obhajuje rozdílné zacházení s různými elipsy ve výzkumu MT.', 'et': 'Käesolevas artiklis kirjeldatakse eksperimenti, mille eesmärk on hinnata teoreetilises lingvistikas käsitletud ellipside mõju neuromasintõlkele (NMT), kasutades lähte- ja sihtkeelena inglise keelest hindi/telugu keelde. Manuaalsete meetoditega hindamine näitab, et enamik Google NMT tehtud vigadest asub ellipsi sisaldavas lauses, selliste vigade sagedus on telugu keeles veidi rohkem kui hindi keeles ning tõlke adekvaatsus näitab paranemist ellipside rekonstrueerimisel nende eelkäikudega. Need leiud ei kinnita mitte ainult ellipside tähtsust ja nende resolutsiooni MT jaoks, vaid viitavad ka võimalikule seosele diskursusseadmete, nagu ellipsid, tõlkimise vahel allika ja sihtmärgi morfoloogilise vastuolu vahel. Samuti täheldame, et mitte kõik ellipsid ei ole halvasti tõlgitud ega kasu rekonstrueerimisest, toetades erinevate ellipside erinevat ravi MT uuringutes.', 'fi': 'Tässä artikkelissa kuvataan kokeilua, jonka tarkoituksena on arvioida teoreettisessa lingvistiikassa käsiteltyjen ellipsien vaikutusta neurokonekäännökseen (NMT), käyttäen englannin kielestä hindiin/teluguun lähtö- ja kohdekielinä. Manuaalisten menetelmien arviointi osoittaa, että suurin osa Google NMT:n virheistä sijaitsee ellipsit sisältävässä lauseessa, tällaisten virheiden esiintymistiheys on hieman enemmän telugussa kuin hindissa ja käännöksen riittävyys paranee, kun ellipsit rekonstruoidaan niiden edeltäjillä. Nämä löydökset eivät ainoastaan vahvista ellipsien merkitystä ja niiden resoluutiota MT:lle, vaan myös viittaavat mahdolliseen korrelaatioon diskurssilaitteiden kuten ellipsien kääntämisen ja lähteen ja kohteen morfologisen epäjohdonmukaisuuden välillä. Havaitsemme myös, että kaikki ellipsit eivät ole käännettyjä huonosti ja hyötyvät rekonstruktiosta, joten MT-tutkimuksessa kannatetaan eri ellipsien erilaista käsittelyä.', 'bs': 'Abstrakt Ovaj članak opisuje eksperiment za procjenu utjecaja različitih vrsta elipse koji su razgovarali teorijskim jezicima na neurološki prevod mašine (NMT), koristeći engleski na Hindi/Telugu kao izvor i ciljni jezik. Procjenjivanje ručnim metodama pokazuje da su većina grešaka koje je napravio Google NMT nalazila u klauzuli koja sadrži ellipse, frekvencija takvih grešaka malo više u Telugu nego Hindiju, a adekvatnost prevoda pokazuje poboljšanje kada se elipse rekonstruiraju sa svojim predsednicima. Ovi nalazi ne samo potvrđuju važnost elipse i njihove rezolucije za MT, nego također ukazuju na moguću korelaciju između prevoda uređaja diskusija poput elipse sa morfološkom neskladnošću izvora i cilja. Također posmatramo da nisu svi elipse loše prevedeni i koristi od rekonstrukcije, advokacija za različite liječenje različitih elipse u istraživanju MT-a.', 'jv': 'absolute Tatanan karo maneh sing manut songane kuwi nggawe akeh akeh error ning Google NMT dumateng sak kelas nang kelas nang kelas sing alipse, dadi kapan kanggo ndelok perusahaan karo telu luwih terakhi liyane ing hinti, lan akeh perusahaan kanggo ndelok oleh nuné kapan kelas nggawe winih dhéwé. Ndheke kuwi nggawe barang nggunakake wigatasahan kelas nggawe Alipse karo nggawe MT, dadi, akhire supoyo karo perusahaan babagan kelas perangkat wigatasahan kelas perangkat alamat surat kanggo kelas karo nggawe tarjamahan karo perusahaan lan tarjamahan Awak dhéwé éntuk ngerasah karo hal akeh stirip dadi, lan bantuan ngono nggawe nguasai perusahaan kanggo langgar alih luwih-luwih sabanjuré MT.', 'ha': "@ info: whatsthis Ana gaskata da shiryoyin manual na nuna cewa mafi yawansu masu ɓarna da Google NMT ke cikin ƙayyade wanda ke ƙunsa da elipti, ko kuma ruwan makorarin waɗannan yana da abu kaɗan a cikin teleugu mafi ƙaranci daga Hindi, kuma fassarar fassarar gaskiyar ya nuna mafiya kyau idan an canza shirin ayuka da ake baka su. Wannan gannaiki ba ta gaskata muhimmin elipti kawai da buƙatan su wa MT, kuma amma yana ƙara zuwa wata muhimma da muhimmanci a tsakanin fassarar kayan faɗa ɗar da shirin ayuka kamar elipti da tsarin morfologi na source da goal. Tuna ganin kuma ba a fassara kulli ɗin misalin misahan da amfani daga rekodi, kuma ana yi wa shari'a wa'anar abubuwa na dabam-dabam cikin research na MT.", 'he': 'המאמר הזה מתאר ניסוי כדי להעריך את ההשפעה של סוגים שונים של אליפסים ששוחחים בתיאורית שפתיים על תרגום מכונות נוירואליות (NMT), בשימוש באנגלית להינדי/טלוגו כמקור שפות ומטרה. הערכה עם שיטות ידנית מראה שרוב הטעויות שעשויות על ידי Google NMT נמצאות בתנאי המכיל את האליפסיה, התדירות של טעויות כאלה היא מעט יותר בטלוגו מאשר הינדי, וההתרגום מתאים מראה שיפור כאשר האליפסים מתבנים מחדש עם הקודמים שלהם. הממצאים האלה לא רק מאשרים את חשיבות האליפסים והפתרון שלהם למטה"ט, אלא גם רמזים לקשר אפשרי בין התרגום של מכשירי דיבור כמו אליפסים עם אי-תואמות מורפולוגית של המקור והמטרה. אנחנו גם רואים שלא כל אליפסות מתרגמות בצורה גרועה ותרווחות מהבנייה מחדש, המגנים לטיפול שונה של אליפסות שונות במחקר MT.', 'sk': 'V članku je opisan eksperiment za oceno vpliva različnih vrst elipsov, obravnavanih v teoretičnem jezikoslovju, na nevralno strojno prevajanje (NMT), pri čemer se kot izvorni in ciljni jezik uporablja angleščina v hindujščino/telugu. Vrednotenje z ročnimi metodami kaže, da je večina napak, ki jih naredi Google NMT, v klavzuli, ki vsebuje elipse, pogostost takih napak je nekoliko večja v telugu kot v hindujščini, ustreznost prevoda pa kaže izboljšanje, ko se elipse rekonstruirajo s svojimi predhodniki. Te ugotovitve ne potrjujejo le pomena elipse in njihove ločljivosti za MT, temveč namigujejo tudi na možno korelacijo med prevajanjem diskurznih naprav, kot so elipse, z morfološko neskladnostjo vira in cilja. Ugotavljamo tudi, da niso vse elipse slabo prevedene in koristijo od rekonstrukcije, kar se zavzema za različno zdravljenje različnih elipse v raziskavah MT.', 'bo': 'Abstract This article describes an experiment to evaluate the impact of different types of ellipses discussed in theoretical linguistics on Neural Machine Translation (NMT), using English to Hindi/Telugu as source and target languages. ལག་བཟོས་གྱི་ལམ་ལུགས་དང་བསྡུས་ནི་Google NMT་གིས་བཟོ་བའི་ནོར་འཁྲུལ་ཆེ་ཤོས་ཀྱི་ནང་དུ་བསྡུར་ཚར་ཡོད་པ་ལྟར་ན། These findings not only confirm the importance of ellipses and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like ellipses with the morphological incongruity of the source and target. ང་ཚོས་ཀྱང་མཐོང་སྣང་གསལ་པོ་ཡོད་མིན་འདུག་ལས་བཟོ་བཅོས་ཕྱོགས་ལས་ཕན་ཚུལ་ཞིབ་མེད་པར། རྒྱལ་སྐྱོར་ལུགས་ཕྱོགས་གཞན་དང་མཉམ་ད'}
{'en': 'LFG Generation from Acyclic F-Structures is NP-Hard', 'ar': 'جيل LFG من هياكل F Acyclic صعب NP', 'pt': 'A geração de LFG a partir de estruturas F acíclicas é NP-Hard', 'es': 'La generación LFG a partir de estructuras F acíclicas es NP-dura', 'fr': 'La génération de LFG à partir de structures F acycliques est dure au NP', 'zh': 'č‡Şć—\xa0çŽŻFç»“ćž„č€…LFGNP-Hardäąź', 'hi': 'Acyclic F-Structures से LFG Generation NP-Hard है', 'ja': '非環状Ｆ構造からのＬＦＧ生成はＮＰ －ハードである。', 'ru': 'Производство LFG из ациклических F-структур является NP-твердым', 'ga': 'Tá Giniúint LFG ó Struchtúir F Aicmileach NP-Chrua', 'hu': 'LFG generáció aciklikus F-struktúrákból NP-kemény', 'el': 'Η παραγωγή από ακυκλικές δομές Φ είναι NP-σκληρή', 'ka': 'Name', 'kk': 'Name', 'it': 'La generazione di LFG da strutture acicliche F è NP-Hard', 'lt': 'LFG gamyba iš Acyclic F-Structures yra NP-Hard', 'mk': 'Генерацијата на LFG од акцикличките F- структури е NP- Hard', 'mt': 'Il-Ġenerazzjoni tal-LFG minn Strutturi F Aċikliċi hija NP-Hard', 'mn': 'Цөмийн F-структуруудын LFG төрөл нь NP-Хатуу', 'no': 'Name', 'pl': 'Generacja LFG z Acyklic F-Structures jest NP-twarda', 'ro': 'Generarea LFG din structuri F aciclice este NP-Hard', 'ml': 'എക്സിക്ലിക് എഫ്- സ്ട്രാക്ട്രാക്ടറുകളില്\u200d നിന്നുള്ള LFG ജനിപ്പിയാണ് NP- ഹാര്\u200dഡ്', 'si': 'Name', 'ms': 'Jenerasi LFG dari Struktur-F Akisiklik adalah NP-Hard', 'ta': 'Name', 'sr': 'Generacija LFG iz acikličkih F-struktura je NP-Hard', 'ur': 'Name', 'so': 'LFG Generation from Acyclic F-Structures is NP-Hard', 'sv': 'LFG Generation från Acykliska F-Structures är NP-Hard', 'uz': 'Name', 'vi': 'Máy tạo LFG từ Ayclic F-structures is NPR-Hard', 'bg': 'Генерирането на LFG от ациклични F-структури е NP-твърдо', 'nl': 'LFG Generatie van Acyclische F-Structuren is NP-Hard', 'hr': 'Generacija LFG iz acikličkih F-struktura je NP-Hard', 'da': 'LFG Generation fra Acykliske F-Structures er NP-Hard', 'ko': '비순환 F 구조에서 LFG를 생성하는 것은 NP가 어렵다', 'sw': 'Uzalishaji wa LFG kutoka Miundombinu ya Acyclic ni NP-Harufu', 'de': 'LFG-Erzeugung aus Acyclischen F-Strukturen ist NP-hart', 'id': 'Generasi LFG dari Struktur F Akisiklik adalah NP-Hard', 'fa': 'نسل LFG از ساختارهای آسیکلیک F-ساختاری NP-Hard است', 'tr': "Aksilik F-Structures'den LFG Gurama NP-Zor", 'af': 'Name', 'sq': 'LFG Generation from Acyclic F-Structures is NP-Hard', 'hy': 'LFG-ի ստեղծումը Ացիկլիկ F-կառուցվածքներից է', 'am': 'LFG Generation from Acyclic F-Structures is NP-Hard', 'bn': 'Name', 'bs': 'Generacija LFG iz acikličkih F-struktura je NP-Hard', 'az': "Acyclic F-Structures'dən LFG Generation NP-Hard", 'ca': "La generació de LFG a partir d'estructures F acícliques és NP-Hard", 'fi': 'LFG Generation from Acyclic F-Structures is NP-Hard', 'cs': 'LFG generace z Acyklických F-Structures je NP-Hard', 'et': 'LFG generatsioon atsüklilistest F-struktuuridest on NP-Hard', 'ha': 'KCharselect unicode block name', 'jv': 'LFG Generation from aceyclik F-structural is NP-Hard', 'he': 'LFG יצירת מבנה F אוציקלי הוא NP-Hard', 'sk': 'Generacija LFG iz acikličnih F-struktur je NP-Hard', 'bo': 'LFG Generation from Acyclic F-Structures is NP-Hard'}
{'en': 'Abstract The universal generation problem for LFG grammars is the problem of determining whether a given grammar derives any terminal string with a given f-structure. It is known that this problem is decidable for acyclic f-structures. In this brief note, we show that for those f-structures the problem is nonetheless intractable. This holds even for grammars that are off-line parsable.', 'fr': 'Résumé Le problème de génération universel pour les grammaires LFG est le problème de déterminer si une grammaire donnée dérive une chaîne terminale avec une structure f donnée. On sait que ce problème est décidable pour les structures f acycliques. Dans cette brève note, nous montrons que pour ces structures f, le problème est néanmoins insoluble. Cela vaut même pour les grammaires qui sont analysables hors ligne.', 'pt': 'Resumo O problema de geração universal para gramáticas LFG é o problema de determinar se uma dada gramática deriva qualquer string terminal com uma dada estrutura f. Sabe-se que este problema é decidível para estruturas f acíclicas. Nesta breve nota, mostramos que para essas estruturas-f o problema é intratável. Isso vale mesmo para gramáticas que são analisáveis off-line.', 'es': 'Resumen El problema de generación universal para las gramáticas LFG es el problema de determinar si una gramática dada deriva alguna cadena terminal con una estructura f dada. Se sabe que este problema es decidible para las estructuras f acíclicas. En esta breve nota, mostramos que, para esas estructuras f, el problema es, no obstante, intratable. Esto es válido incluso para gramáticas que son analizables fuera de línea.', 'ar': 'الملخص إن مشكلة التوليد الشاملة لقواعد LFG هي مشكلة تحديد ما إذا كانت قواعد معينة تستمد أي سلسلة طرفية ببنية f معينة. من المعروف أن هذه المشكلة قابلة للفصل في الهياكل f غير الحلقية. في هذه المذكرة الموجزة ، نوضح أنه بالنسبة لتلك الهياكل ، فإن المشكلة مع ذلك مستعصية على الحل. هذا ينطبق حتى على القواعد النحوية التي يمكن تحليلها خارج الخط.', 'ja': '抽象LFG文法の普遍生成問題は、与えられた文法が与えられたf構造を持つ任意の終端文字列を導出するかどうかを判断する問題である。この問題は、非環式ｆ構造に対して決定可能であることが知られている。この簡単なメモでは、これらのf構造にとって、問題はそれでも難解であることを示しています。これは、オフラインで構文解析可能な文法であっても当てはまります。', 'hi': 'सार LFG व्याकरण के लिए सार्वभौमिक पीढ़ी की समस्या यह निर्धारित करने की समस्या है कि क्या कोई दिया गया व्याकरण किसी दिए गए एफ-संरचना के साथ किसी भी टर्मिनल स्ट्रिंग को प्राप्त करता है। यह ज्ञात है कि यह समस्या एसाइक्लिक एफ-संरचनाओं के लिए निर्णायक है। इस संक्षिप्त नोट में, हम दिखाते हैं कि उन एफ-संरचनाओं के लिए समस्या फिर भी असभ्य है। यह उन व्याकरणों के लिए भी रखता है जो ऑफ-लाइन पार्सेबल हैं।', 'zh': '摘要 LFG语法之通用,定给定语法有给定f终端字符串也。 众所周知,于非环f可定。 以此言之,吾明f构,犹棘手也。 至于用离线可解析之语法。', 'ru': 'Аннотация Задача универсальной генерации для грамматик LFG заключается в определении того, является ли данная грамматика производной какой-либо терминальной строки с данной f-структурой. Известно, что эта задача является решаемой для ациклических f-структур. В этой краткой записке мы показываем, что для этих f-структур проблема, тем не менее, неразрешима. Это относится даже к грамматикам, которые являются автономными парсами.', 'ga': 'Coimriú Is í an fhadhb ghiniúna uilíoch do ghramadach LFG an fhadhb a bhaineann le cinneadh a dhéanamh an dtagann aon teaghrán teirminéil le f-struchtúr ar leith ó ghramadach ar leith. Tá sé ar eolas go bhfuil an fhadhb seo indecidable do struchtúir f-aicrileach. Sa nóta gairid seo, léirímid go bhfuil an fhadhb dosháraithe mar sin féin do na f-struchtúir sin. Coinníonn sé seo fiú i gcás gramadaí atá inbhraite as líne.', 'el': 'Περίληψη Το καθολικό πρόβλημα δημιουργίας για γραμματικές είναι το πρόβλημα του προσδιορισμού αν μια δεδομένη γραμματική αντλεί οποιαδήποτε τελική συμβολοσειρά με δεδομένη δομή. Είναι γνωστό ότι αυτό το πρόβλημα είναι αποφασιστικό για τις ακυκλικές δομές φ. Σε αυτή τη σύντομη σημείωση, καταδεικνύουμε ότι για αυτές τις δομές το πρόβλημα είναι ωστόσο επιλεκτικό. Αυτό ισχύει ακόμη και για γραμματικές που είναι εκτός σύνδεσης αναλύσιμες.', 'it': 'Il problema di generazione universale per le grammatiche LFG è il problema di determinare se una data grammatica derivi una stringa terminale con una data struttura f. È noto che questo problema è risolvibile per le f-strutture acicliche. In questa breve nota, mostriamo che per quelle strutture il problema è comunque intrattabile. Questo vale anche per grammatiche che sono parsabili off-line.', 'hu': 'Absztrakt Az LFG nyelvtanfolyamok univerzális generációs problémája annak meghatározása, hogy egy adott nyelvtan származik-e egy adott f-struktúrával rendelkező terminál karakterláncot. Ismeretes, hogy ez a probléma megoldható az aciklikus f-struktúrák esetében. Ebben a rövid megjegyzésben megmutatjuk, hogy ezeknek az f-struktúráknak a probléma mégis megoldhatatlan. Ez vonatkozik még a nyelvtani, amelyek offline értelmezhetők.', 'kk': 'Абстракты LFG граммаларының әлемдік құрылу мәселесі - келтірілген грамматиканың f- структурасындағы терминал жолын түсіргенін анықтау мәселесі. Бұл мәселе асцикликалық f- құрылғыларға бөлшекті деп біледі. Бұл қысқа жазбанда, бұл f- құрылымдар үшін мәселе біздің интерактивдігін көрсетеді. Бұл сызықтағы талдау мүмкін граммалар үшін де бар.', 'lt': 'Abstraktas Universalios kartos problem a LFG gramatikams yra problema nustatyti, ar tam tikra gramatika gauna bet kokią galutinę eilutę su tam tikra f struktūra. Žinoma, kad ši problema yra sprendžiama ciklinių f-struktūrų atžvilgiu. Šioje trumpojoje pastaboje parodomi, kad šioms f struktūroms problema vis dėlto neįmanoma išspręsti. Tai pasakytina net apie gramatikas, kurios yra netiesioginės analizuojamos.', 'mk': 'Апстрактен Проблемот на универзалната генерација за граматичките LFG е проблемот со одредувањето дали дадена граматичка изведува било кој терминален рядок со дадена f- структура. It is known that this problem is decidable for acyclic f-structures.  In this brief note, we show that for those f-structures the problem is nonetheless intractable.  This holds even for grammars that are off-line parsable.', 'ml': 'LFG ഗ്രാമാര്\u200dക്കുള്ള പ്രശ്നം അസ്ട്രാക്രാക്ട് ചെയ്യുക ഈ പ്രശ്നം എക്സിക്ലിക്ക് ഫ് സ്ട്രൈക്കുകള്\u200dക്ക് വേണ്ടി തീരുമാനിക്കുന്നതാണെന്ന് അറിയുന് ഈ ചെറിയ കുറിപ്പില്\u200d നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നു, ആ ഫ് സ്ട്രൂട്ടിങുകള്\u200dക്ക് വേണ്ടി പ്രശ്നം ആവശ്യമ ഈ ഗ്രാമ്മാര്\u200dക്ക് വേണ്ടിയുള്ള പാര്\u200dസാബില്\u200d പോലുമുണ്ട്.', 'ka': 'Name ეს პრობლემა აციკლიკური f-სტრუქტურებისთვის გადაწყვეტილებელია. ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ამ f-სტრუქტურაციისთვის პრობლემა არამედ ინტერექტიურია. რჲგა ეყპზა ეჲპთ ჱა დპამაპთ, კჲთრჲ ჟა თჱლთჱანთ.', 'mn': 'Абстракт LFG грамматуудын универсал үеийн асуудал бол өгөгдсөн граммат нь өгөгдсөн f-бүтэцтэй терминал стринг гаргадаг эсэхийг тодорхойлох асуудал юм. Энэ асуудал нь цикл f-бүтээгдэхүүнд шийдвэрлэх боломжтой гэдгийг мэднэ. Энэ тохиолдолд бид f-бүтээгдэхүүнд асуудлыг харуулж байна. Энэ нь шулуун бусад хэлбэртэй грамм хүртэл байдаг.', 'no': 'Abstrakt Den universelle genereringsproblemet for LFG- grammar er problemet med å avgjera om ein gitt grammar avgjer ein terminalstreng med ein gitt f- struktur. Det er kjent at dette problemet er desikable for aksikliske f- strukturer. I denne korte notaten viser vi at for desse f-strukturene er problemet likevel intraktibel. Dette holdt til og med grammer som er off line tolkbar.', 'ms': 'Abstrakt Masalah generasi universal untuk gramatik LFG adalah masalah menentukan sama ada gramatik diberi berasal dari mana-mana rentetan terminal dengan struktur f diberi. It is known that this problem is decidable for acyclic f-structures.  In this brief note, we show that for those f-structures the problem is nonetheless intractable.  This holds even for grammars that are off-line parsable.', 'ro': 'Problema de generare universală a gramaticilor LFG este problema determinării dacă o gramatică dată derivă orice șir terminal cu o anumită structură f. Este cunoscut faptul că această problemă este decisivă pentru f-structurile aciclice. În această scurtă notă, arătăm că pentru aceste f-structuri problema este totuși imposibilă. Acest lucru este valabil chiar și pentru gramaticile care sunt off-line parsable.', 'mt': 'Abstrat Il-problem a tal-ġenerazzjoni universali għall-grammi LFG hija l-problema tad-determinazzjoni ta’ jekk gramma partikolari tirriżultax minn xi string terminali bi struttura f partikolari. It is known that this problem is decidable for acyclic f-structures.  In this brief note, we show that for those f-structures the problem is nonetheless intractable.  This holds even for grammars that are off-line parsable.', 'so': "Qabsi dhibaatada qaranka caalamiga ah ee grammarka LFG waa dhibaatada ku saabsan in grammar la siiyo uu helo xadhig kasta oo ku qoran f-structure. Waxaa la ogaanayaa in dhibaatadan ay go'aan u tahay dhismaha afka ee akykliska. Warqadan fudud, waxan tusaynaa in dhibaatadu ay tahay mid aan suurtagal ahayn. Tan waxay sidoo kale u qabanqaabisaa qofka lagu baaraandegayo.", 'pl': 'Uniwersalnym problemem generowania gramatyki LFG jest określenie, czy dana gramatyka pochodzi z jakiegokolwiek ciągu końcowego o danej strukturze f. Wiadomo, że problem ten jest możliwy do rozstrzygnięcia dla acyklicznych struktur f. W tej krótkiej notatce pokazujemy, że dla tych struktur f problem jest jednak nierozwiązany. Dotyczy to nawet gramatyki, które są off-line analizowalne.', 'sv': 'Sammanfattning Det universella genereringsproblemet för LFG-grammatik är problemet att avgöra om en given grammatik härleder någon slutsträng med en given f-struktur. Det är känt att detta problem är avgörande för acykliska f-strukturer. I denna korta anmärkning visar vi att problemet ändå är svårhanterligt för dessa f-strukturer. Detta gäller även för grammatik som är off-line tolkningsbara.', 'sr': 'Abstrakt Problem univerzalne generacije za grame LFG je problem određivanja da li predavana gramatika proizvodi bilo kakvu terminalnu žicu sa određenom f-strukturom. Poznato je da je ovaj problem odlučivan za akcikličke f-strukture. U ovoj kratkoj poruci pokazujemo da je problem za te f-strukture ipak intraktivan. Ovo se drži čak i za grame koji su izvan linije analizirani.', 'ta': 'கொடுக்கப்பட்ட குறிப்பிட்ட முனைய சரம் கொண்டு இருக்குமா என்பதை தீர்மானிக்க பிரச்சினை இந்த பிரச்சினையை எக்சைக்லிக் f-அமைப்புகளுக்கு தீர்மானிக்கும் என்பது தெரியும். இந்த குறிப்பிட்ட குறிப்பில், நாம் அந்த f-கட்டங்களுக்கு காண்பிக்கிறோம் என்றாலும் இந்த பிரச்சினையை  இந்த கூட வரிசையில் பார்சாப்பில் இருக்கும் வரைப்படங்களுக்கு கூட.', 'ur': 'الفجی گراماروں کے لکھنے کی عمومی نسل مسئلہ یہ مسئلہ ہے کہ مقرر کرنا چاہیے کہ ایک دیئے گراماری کس ترمینلی استرینگ کو ایک دیئے f- ساختار کے ساتھ پیدا کرتا ہے. اسے معلوم ہے کہ یہ مسئلہ آسیکلیک f-ساختاروں کے لئے فیصلہ کرنے والا ہے۔ اس تھوڑے نمونٹ میں، ہم دکھاتے ہیں کہ ان f-ساختاروں کے لئے مشکل ہے، بجز اس کے کہ مشکل نہیں ہے۔ یہ گرامر کے لئے بھی ہے جو غیر لین پارس قابل ہیں۔', 'si': 'LFG ග්\u200dරාමාර්ස් වලට සාමාන්\u200dය ප්\u200dරශ්නයක් තියෙන්න ප්\u200dරශ්නයක් තීර්ණය කරන්න ප්\u200dරශ්නයක් තීර්ණය කරන්න ප්\u200dරශ්නයක් ද ඒක දන්නවා මේ ප්\u200dරශ්නය අයිසික්ලික් f-නිර්මාණය වෙනුවෙන් ප්\u200dරශ්නයක් වෙන්න පුළුවන් කි අපි පෙන්වන්නම් ඒ f-ස්ථාපනයට ප්\u200dරශ්නයක් තියෙන්නේ නැහැ කියලා. මේක නිර්මාණය කරන්න පුළුවන් ග්\u200dරාමාර්මාර් වලත් තියෙනවා.', 'uz': "Abstract The universal generation problem for LFG grammars is the problem of determining whether a given grammar derives any terminal string with a given f-structure.  Bu muammo acyklik f-structurlari uchun xususiyatli bo'ladi. Bu kichkina yozda, biz bu f-structural uchun muammolar kerak emas. Bu faqatgina barsablar uchun grammatika bo'ladi.", 'vi': 'Bản tóm tắt Vấn đề phát sinh chung cho các Hệ thống LFG là vấn đề quyết định nếu ngữ pháp nào bắt đầu các chuỗi thiết bị cuối với cấu trúc đặc biệt. Nó được biết rằng vấn đề này có thể quyết định với cấu trúc gương ngoại. Trong lá thư ngắn ngủi này, chúng ta cho thấy rằng vấn đề trong các cấu trúc đó vẫn rất khó giải quyết. Cái này còn giữ được cho các tạp chí khác được phân tích.', 'bg': 'Абстракт Универсалният проблем за генериране на граматики е проблемът да се определи дали дадена граматика извлича терминален низ с дадена f-структура. Известно е, че този проблем е решаващ за ациклични f-структури. В тази кратка бележка показваме, че за тези структури проблемът все пак е неразрешим. Това важи дори за граматики, които са офлайн анализируеми.', 'nl': "Abstract Het universele generatieprobleem voor LFG grammatica is het probleem van het bepalen of een gegeven grammatica een eindstring afleidt met een gegeven f-structuur. Het is bekend dat dit probleem beslissend is voor acyclische f-structuren. In deze korte nota laten we zien dat voor die f-structuren het probleem niettemin onlosmakelijk is. Dit geldt zelfs voor grammatica's die offline parseerbaar zijn.", 'da': 'Det universelle generationsproblem for LFG grammatik er problemet med at bestemme, om en given grammatik stammer fra en terminal streng med en given f-struktur. Det er kendt, at dette problem er afgørende for acykliske f-strukturer. I denne korte bemærkning viser vi, at problemet for disse f-strukturer ikke desto mindre er uløseligt. Dette gælder selv for grammatier, der er off-line fortolkbare.', 'id': 'Abstrakt Masalah generasi universal untuk gramatika LFG adalah masalah untuk menentukan apakah gramatika tertentu berasal dari string terminal dengan struktur f tertentu. Diketahui bahwa masalah ini dapat ditentukan untuk struktur f aksiklik. Dalam catatan singkat ini, kami menunjukkan bahwa bagi f-struktur tersebut masalah masih tidak dapat diterima. Ini bahkan berlaku untuk grammar yang tidak dapat dihapus.', 'hr': 'Abstraktiraj problem univerzalne generacije za grame LFG-a je problem utvrđivanja da li predstavljena gramatika proizvodi bilo kakvu terminalnu žicu s određenom f-strukturom. Poznato je da je ovaj problem odlučivan za akcikličke f-strukture. U ovoj kratkoj poruci pokazujemo da je problem za te f-strukture ipak intraktivan. Ovo se drži čak i za grame koji su izvan linije analizirani.', 'fa': 'مشکل نسل عمومی برای گرامرات LFG مشکل تعیین کردن آیا گرامرات داده شده هر string ترمینال با یک ساختار f داده می\u200cشود. می داند که این مشکل برای ساختارهای آسیکلیک f قابل تصمیم گیری است. در این یادداشت کوتاه، ما نشان می دهیم که برای این ساختارهای f مشکل با وجود این است که مشکل قابل توجه است. این حتی برای گرامبر های غیر خط قابل تولید است.', 'sw': 'Tatizo la kizazi cha kimataifa kwa wachambuzi wa LFG ni tatizo la kuamua kama programu iliyotolewa inapata mfumo wowote wa kivitano na muundo fulani wa f. Inajulikana kuwa tatizo hili linaweza kuamua kwa miundombinu ya afya ya uchunguzi. Katika ujumbe huu mfupi, tunaonyesha kwamba kwa ajili ya miundombinu hizo tatizo hilo ni jambo lisiloeleweka. Hii inafanikiwa hata kwa ajili ya gramma ambazo hazina mabomu.', 'de': 'Abstract Das universelle Generationsproblem für LFG-Grammatiken ist das Problem zu bestimmen, ob eine gegebene Grammatik irgendeinen Endstring mit einer gegebenen f-Struktur ableitet. Es ist bekannt, dass dieses Problem für azyklische F-Strukturen entscheidbar ist. In dieser kurzen Anmerkung zeigen wir, dass für diese f-Strukturen das Problem dennoch unlösbar ist. Dies gilt auch für Grammatiken, die offline parsbar sind.', 'ko': 'LFG 문법의 일반적인 생성 문제는 주어진 문법이 주어진 f 구조를 가진 단말기 문자열을 파생시키는지 확인하는 문제입니다.모두가 알다시피 이 문제는 비순환 f-구조에 대해 판정할 수 있다.이 짧은 노트에서 우리는 이러한 f 구조에 대해 말하자면 이 문제는 여전히 까다롭다는 것을 나타낸다.이것은 심지어 오프라인에서 분석할 수 있는 문법에도 적용된다.', 'af': "Abstrak Die universele generasie probleem vir LFG gramme is die probleem van bepaal of 'n gegewe grammar enige terminaal string met' n gegewe f- struktuur afgelei word. Dit is bekend dat hierdie probleem is desikable vir aksikliske f-strukture. In hierdie kort nota, wys ons dat vir dié f-strukture die probleem is tog intrakbaar. Hierdie hou selfs vir gramme wat aflyn verwerkbaar is.", 'sq': 'Abstrakt Problemi i gjeneratës universale për gramatikat LFG është problemi i përcaktimit nëse një gramatik i caktuar merr ndonjë string terminal me një f-strukturë të caktuar. Është e njohur se ky problem është vendimtar për strukturat acyclic f. Në këtë shënim të shkurtër, ne tregojmë se për këto f-struktura problemi është megjithatë i papërshtatshëm. Kjo mban edhe për gramatikat që janë të analizueshme jashtë linje.', 'am': 'አቀማመጥ ይህ ጉዳዩ የኢካክሊክ f-አካውንትርክቶችን እንደተፈጸመ ይታወቃል፡፡ በዚህ አነስተኛ ቦታዎች፣ ስለነዚህ f-አካውንቶቹ ጉዳዩ ምንም እንኳ አይቻልም፡፡ ይሄ በቋንቋ ሳንቋ ለቋንቋዎች እንኳ ይኖራል፡፡', 'tr': 'Abstrakt Bu mesele welosikli f-strukturlar üçin çözümlidir. Bu gysga ýagdaýda, bu f-strukturlaryň soragynyň ýöne çözümli bolmagyny görkezýäris. Bu hatta çizgi ayırılabilir gramlar için hatta.', 'hy': 'Աբլաստրատ ԼՖԳ գրամագրությունների համընդհանուր սերնդի խնդիրն այն է, թե արդյոք տվյալ գրամագրությունը հանում է որոշակի f-կառուցվածքի տերմինալ լար: Գիտնի է, որ այս խնդիրը որոշումներ կարելի է անել f-կառուցվածքների համար: Այս կարճ նկարում մենք ցույց ենք տալիս, որ այս f-կառուցվածքների համար խնդիրն այնուամենայնիվ անհասկանալի է: Սա նույնիսկ տեղի է ունենում գրամագրությունների համար, որոնք անլայն կարելի է վերլուծել:', 'bn': 'LFG গ্রামারের জন্য বৈশ্বিক প্রজন্ম সমস্যা হচ্ছে একটি নির্দিষ্ট গ্রামার কোন টার্মিনাল স্ট্রিঙ্কের প্রাপ্ত ফ- কাঠামোর সা এটা জানা যায় যে এই সমস্যা একাইক্লিক ফ-কাঠামোর জন্য সিদ্ধান্ত। এই সংক্ষিপ্ত নোটে আমরা দেখাচ্ছি যে এই ফ-কাঠামোর জন্য সমস্যা ব্যবস্থায়ত। এমনকি গ্রামারগুলোর জন্য যারা অলাইনের পার্সাবেল।', 'az': 'Abstrakt LFG qrammaları üçün universel nəsil problemi verilən qrammaların verilən f-strukturları ilə bir terminal dəyişdirilməsini müəyyən etmək problemidir. Bu problemin aciklik f-strukturları üçün çəkilir. Bu qısa nöqtədə, biz bu f-strukturların problemi olaraq intraktif olduğunu göstəririk. Bu, hətta səhifədən ayırılabilir gramlar üçün hazırlanır.', 'ca': 'Abstract El problem a de la generació universal per a les gramàtiques LFG és el de determinar si una gramàtica determinada deriva qualsevol cadena terminal amb una estructura f determinada. És conegut que aquest problema és decisible per a les estructures f acícliques. En aquesta breu nota, demostram que per a aquestes estructures f el problema no obstant això és intractable. This holds even for grammars that are off-line parsable.', 'bs': 'Abstrakt Problem univerzalne generacije za grame LFG je problem utvrđivanja da li određena gramatika proizvodi bilo kakvu terminalnu žicu s određenom f-strukturom. Poznato je da je ovaj problem odlučivan za akcikličke f-strukture. U ovoj kratkoj poruci pokazujemo da je problem za te f-strukture ipak intraktivan. Ovo se drži čak i za grame koji su izvan linije analizirani.', 'cs': 'Univerzální generační problém LFG gramatiky je problém určení, zda daná gramatika odvozuje nějaký koncový řetězec s danou f-strukturou. Je známo, že tento problém je rozhodný pro acyklické f-struktury. V této stručné poznámce ukazujeme, že u těchto f-struktur je problém nicméně řešitelný. To platí i pro gramatiky, které jsou off-line analyzovatelné.', 'et': 'Universaalne generatsiooniprobleem LFG grammatikate jaoks on probleem määrata, kas antud grammatika tuletab mõne konkreetse f-struktuuriga terminalstringi. On teada, et see probleem on otsustatav atsükliliste f-struktuuride puhul. Selles lühikeses märkuses näitame, et nende f-struktuuride puhul on probleem siiski lahendamatu. See kehtib isegi grammatika kohta, mis on off-line parsitav.', 'fi': 'LFG-kielioppien yleisluonti-ongelma on se, ett채 m채채ritet채채n, johtaako tietty kielioppi mit채채n p채채temerkkijonoa tietyll채 f-rakenteella. Tiedet채채n, ett채 t채m채 ongelma on ratkaistavissa asyklisten f-rakenteiden osalta. T채ss채 lyhyess채 huomautuksessa osoitamme, ett채 n채iden f-rakenteiden ongelma on kuitenkin ratkaisematon. T채m채 p채tee jopa kielioppiin, jotka ovat off-line j채sennett채viss채.', 'jv': 'absolute Punika dipun ngomongke boten iki dadi kanggo sampeyan operasi f-bisa. Nang liyane iki dadi, kita ngomong nik nggawe kanggo sampeyan f-sampeyan kuwi bisa pasar iki dadi apik sing apik. Genjer-Genjer', 'he': 'אבסטרט הבעיה של הדור האוניברסלי עבור גרמטיקות LFG היא הבעיה של לקבוע אם גרמטיקה מסוימת משיגה כל רצועה סופית עם מבנה f מסוים. ידוע כי הבעיה הזו נחליטה עבור מבנים f אקסיקליים. בפתק הקצר הזה, אנו מראים שבשביל המבנים האלה, הבעיה עדיין בלתי ניתנת לעבור. זה מתאים אפילו לתרמטיקות שאפשר להעביר מחוץ לרשת.', 'ha': "@ item: inmenu Text Completion Ana sani cewa wannan matalauci ne mai iya zartar da kan akyclisin f-tsari. Ina cikin wannan littãfin nan kaɗan, Munã nũna cewa, wa waɗannan f-bakarãri masu bukãta ne da amfani ba. Wannan yana ƙunsa ga grammati waɗanda ba'a samu'i ba-line.", 'sk': 'Povzetek Problem univerzalne generacije slovnic LFG je problem ugotavljanja, ali določena slovnica izpelje kateri koli terminalni niz z določeno strukturo f. Znano je, da je ta problem odločljiv za aciklične f-strukture. V tej kratki opombi pokažemo, da je problem za te f-strukture kljub temu nepremagljiv. To velja celo za slovnice, ki so off-line razčlenljive.', 'bo': 'Abstract The universal generation problem for LFG grammars is the problem of determining whether a given grammar derives any terminal string with a given f-structure. ཚོར་བ་འདི་ཚོར་བ་སྤྱོད་གྱིས་པ་གྲངས་སྤྱོད་ཆེན་པོ་ཞིག་རེད། འུ་ཅག་གི་དྲན་འཛིན་གསལ་པོ་འདིའི་ནང་དུ་f-བཟོ་བཀོད་ཡོད་པ་དེ་ཚོའི་དཀའ་ངལ་བ་བཏུབ་མིན་པར། འདིས་བྲལ་ནས་འབྲེལ་མེད་པའི་ཚིག་གྲངས་ཀ་ཞིབ་འཇུག་པར་བྱེད་ཀྱི་ཡོད།'}
