{'en': 'ConTest : A Unit Test Completion Benchmark featuring Context C on T est: A Unit Test Completion Benchmark featuring Context', 'ar': 'ConTest: معيار إكمال اختبار الوحدة الذي يعرض السياق', 'pt': 'ConTest: um benchmark de conclusão de teste de unidade com contexto', 'fr': "ConTest\xa0: un banc d'essai unitaire avec contexte", 'es': 'ConTest: Un punto de referencia para la finalización de pruebas unitarias', 'ja': 'ConTest ：コンテキストを特徴とするユニットテスト完了ベンチマーク', 'zh': 'ConTest:以上下文为单元试成', 'hi': 'ConTest: एक इकाई परीक्षण पूरा बेंचमार्क संदर्भ की विशेषता', 'ru': 'ConTest: контрольный параметр завершения модульного теста, включающий контекст', 'ga': 'Comórtas: Tagarmharc Críochnaithe an Triail Aonaid le Comhthéacs', 'ka': 'ContestComment', 'hu': 'ConTest: A Unit Test Completion Benchmark with Context', 'lt': 'ConTest: Vieneto bandymų užbaigimo lyginamasis ženklas su kontekstu', 'kk': 'Контест: Бірікті толтыру белгісін тексеру контексті', 'ms': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'el': 'Ένας δείκτης αναφοράς ολοκλήρωσης δοκιμής μονάδας που χαρακτηρίζει το πλαίσιο', 'it': 'ConTest: un benchmark di completamento del test di unità con contesto', 'mk': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'mn': 'Контест: Нэгдсэн туршилтын төгсгөл банкметр', 'no': 'ConTest: Eit einingstestfullføringsbenchmark som inneheld kontekst', 'ro': 'ConTest: Un benchmark de finalizare a testului unitar cu context', 'pl': 'ConTest: A Unit Test Completion Benchmark obejmujący kontekst', 'ml': 'പരീക്ഷിക്കുക: ഉള്ളിലുള്ള ഒരു യൂണിറ്റ് പരീക്ഷ പൂര്\u200dത്തിയാക്കുന്ന ബെന്\u200dച്മാര്\u200dക്കിന്\u200d', 'mt': 'ConTest: Benchmark ta’ Tlestija tat-Test ta’ Unit à li jkollha Kuntest', 'si': 'ContestComment', 'sr': 'Контест: контекст контекста', 'so': 'Imtixaanka:', 'sv': 'ConTest: Ett riktmärke för slutförande av enhetstest med kontext', 'ta': 'சோதனை', 'ur': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'uz': 'Test: Context boĘ»yicha toĘ»ldirish', 'vi': 'Kiểm tra kết quả đơn vị hiển thị Khung', 'bg': 'КонТест: сравнителен показател за завършване на единичен тест, включващ контекст', 'nl': 'ConTest: Een Unit Test Voltooiing Benchmark met Context', 'hr': 'ConTest: Kontekst za završavanje testova jedinica', 'da': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'de': 'ConTest: Ein Unit Test Completion Benchmark mit Kontext', 'id': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'fa': 'آزمایش: یک آزمایش آزمایش کامل نمونه\u200cای که شامل آزمایش می\u200cباشد', 'ko': '경쟁: 컨텍스트를 특징으로 하는 단원 테스트 완성 기준', 'sw': 'Hijaribu: Kitizo cha Kutimiza Benchmark kinachoonyesha Context', 'tr': 'Test', 'af': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'hy': 'Comment', 'bs': 'ConTest: Kontekst za završavanje testova jedinica', 'bn': 'পরীক্ষা', 'ca': "ConTest: Un punt de referència de completació d'una unitat amb context", 'cs': 'ConTest: Benchmark pro dokončení testů jednotky s kontextem', 'et': 'ConTest: ühikutesti lõpuleviimise võrdlusnäitaja, mis sisaldab konteksti', 'fi': 'ConTest: Yksikkötestin loppuun saattamisen vertailuarvo, jossa on konteksti', 'sq': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'he': 'ConTest: A Unit Test Completion Benchmark with Context', 'ha': 'KCharselect unicode block name', 'sk': 'ConTest: merilo za dokončanje enotnega preskusa s kontekstom', 'bo': 'ConTest: A Unit Test Completion Benchmark featuring Context', 'jv': 'conTest: A Unit Test Completetion Bench funning context'}
{'en': 'We introduce CONTEST, a  benchmark  for NLP-based unit test completion, the task of predicting a test’s assert statements given its setup and focal method, i.e. the  method  to be tested. ConTest is large-scale (with 365k datapoints). Besides the test code and tested code,  it  also features context code called by either. We found  context  to be crucial for accurately predicting assertions. We also introduce baselines based on transformer encoder-decoders, and study the effects of including  syntactic information  and  context . Overall, our  models  achieve a BLEU score of 38.2, while only generating unparsable code in 1.92 % of cases.', 'ar': 'نقدم CONTEST ، وهو معيار لإكمال اختبار الوحدة القائم على البرمجة اللغوية العصبية ، ومهمة التنبؤ ببيانات تأكيد الاختبار نظرًا لإعداده وطريقته البؤرية ، أي الطريقة التي سيتم اختبارها. ConTest واسع النطاق (مع 365 ألف نقطة بيانات). إلى جانب رمز الاختبار والكود الذي تم اختباره ، فإنه يتميز أيضًا برمز السياق الذي تم استدعاؤه بواسطة أي منهما. لقد وجدنا أن السياق أمر بالغ الأهمية للتنبؤ الدقيق بالتأكيدات. نقدم أيضًا خطوط أساس تستند إلى أجهزة فك ترميز المحولات ، وندرس تأثيرات تضمين المعلومات النحوية والسياق. بشكل عام ، تحقق نماذجنا درجة BLEU 38.2 ، مع إنشاء رمز غير قابل للتحليل فقط في 1.92٪ من الحالات.', 'pt': 'Apresentamos o CONTEST, um benchmark para a conclusão de testes unitários baseados em PNL, a tarefa de prever as declarações assert de um teste de acordo com sua configuração e método focal, ou seja, o método a ser testado. O ConTest é em larga escala (com 365k pontos de dados). Além do código de teste e do código testado, ele também apresenta o código de contexto chamado por ambos. Descobrimos que o contexto é crucial para prever asserções com precisão. Também introduzimos linhas de base baseadas em codificadores-decodificadores de transformadores e estudamos os efeitos da inclusão de informações sintáticas e contexto. No geral, nossos modelos atingem uma pontuação BLEU de 38,2, enquanto geram apenas código não analisável em 1,92% dos casos.', 'es': 'Presentamos CONTEST, un punto de referencia para la realización de pruebas unitarias basadas en PNL, la tarea de predecir las declaraciones de afirmación de una prueba dada su configuración y método focal, es decir, el método que se probará. ConTest es a gran escala (con 365 000 puntos de datos). Además del código de prueba y el código probado, también incluye código de contexto llamado por cualquiera de los dos. Descubrimos que el contexto es crucial para predecir con precisión las afirmaciones. También introducimos líneas de base basadas en codificadores-decodificadores de transformadores y estudiamos los efectos de incluir información sintáctica y contexto. En general, nuestros modelos alcanzan una puntuación BLEU de 38,2, mientras que solo generan código imanalizable en el 1,92% de los casos.', 'fr': "Nous introduisons CONTEST, une référence pour la réalisation de tests unitaires basés sur la PNL, la tâche de prédire les affirmations d'un test compte tenu de sa configuration et de sa méthode focale, c'est-à-dire la méthode à tester. Contest est une entreprise à grande échelle (avec 365 000 points de données). Outre le code de test et le code testé, il comporte également un code contextuel appelé par l'un ou l'autre. Nous avons constaté que le contexte était crucial pour prédire avec précision les assertions. Nous introduisons également des lignes de base basées sur des encodeurs-décodeurs de transformateurs et étudions les effets de l'inclusion d'informations syntaxiques et de contexte. Dans l'ensemble, nos modèles obtiennent un score BLEU de 38,2, tout en ne générant du code non analysable que dans 1,92\xa0% des cas.", 'ja': '私たちは、NLPベースの単位テスト完了のベンチマークであるコンテストを導入し、その設定と焦点法、すなわちテストされる方法でテストのアサートステートメントを予測するタスクを導入します。ConTestは大規模なものである（ 365,000個のデータポイントがある）。テストコードとテストコードに加えて、どちらかによって呼び出されるコンテキストコードも備えています。私たちは、アサーションを正確に予測するためにコンテキストが重要であることを発見しました。また、変圧器エンコーダデコーダをベースとしたベースラインを導入し、構文情報や文脈を含むことによる効果を研究している。全体として、当社のモデルは38.2のBLEUスコアを達成しますが、1.92%のケースでは解析不可能なコードしか生成しません。', 'zh': '引入 CONTEST,盖 NLP 之单元试成之准,据试设焦点之法(即试之法)占试之断言句也。 ConTest 大(有 365k 数)。 自代码、代码之外,有一调之上下文代码。 臣等见上下文于确占断言至重。 又言变压器编码器-解码器之基线,究句法息上下文之化。 总体而言,BLEU分为38.2,而仅于1.92%生不可解析之代码。', 'hi': 'हम प्रतियोगिता, एनएलपी-आधारित इकाई परीक्षण पूरा होने के लिए एक बेंचमार्क पेश करते हैं, जो इसके सेटअप और फोकल विधि को देखते हुए एक परीक्षण के दावे वाले बयानों की भविष्यवाणी करने का कार्य है, यानी परीक्षण की जाने वाली विधि। ConTest बड़े पैमाने पर (365k datapoints के साथ) है। परीक्षण कोड और परीक्षण किए गए कोड के अलावा, इसमें संदर्भ कोड भी शामिल है जिसे या तो कहा जाता है। हमने संदर्भ को सटीक रूप से दावों की भविष्यवाणी करने के लिए महत्वपूर्ण पाया। हम ट्रांसफॉर्मर एनकोडर-डिकोडर के आधार पर बेसलाइन भी पेश करते हैं, और वाक्यात्मक जानकारी और संदर्भ को शामिल करने के प्रभावों का अध्ययन करते हैं। कुल मिलाकर, हमारे मॉडल 38.2 का BLEU स्कोर प्राप्त करते हैं, जबकि केवल 1.92% मामलों में अपार्सेबल कोड उत्पन्न करते हैं।', 'ru': 'Мы вводим КОНКУРС, эталон для завершения теста на основе NLP, задачу прогнозирования утверждений теста с учетом его настройки и фокального метода, то есть метода, который должен быть протестирован. ConTest является крупномасштабным (с 365 тыс. точек данных). Помимо тестового кода и тестового кода, он также имеет контекстный код, вызываемый одним из них. Мы считаем, что контекст имеет решающее значение для точного предсказания утверждений. Мы также вводим базовые линии, основанные на кодерах-декодерах трансформаторов, и изучаем эффекты включения синтаксической информации и контекста. В целом, наши модели достигают балла BLEU 38,2, при этом генерируя непарсируемый код только в 1,92% случаев.', 'ga': 'Tugaimid isteach CONTEST, tagarmharc le haghaidh críochnú na dtrialacha aonaid atá bunaithe ar NLP, an tasc chun ráitis dhearbhaithe tástála a thuar i bhfianaise a socraithe agus a modh fócasach, i.e. an modh atá le tástáil. Tá ConTest ar scála mór (le 365k pointe sonraí). Seachas an cód tástála agus an cód tástáladh, gnéithe sé freisin cód comhthéacs a dtugtar ag ceachtar. Fuaireamar amach go raibh comhthéacs ríthábhachtach chun dearbhuithe a thuar go beacht. Tugaimid isteach freisin bonnlínte bunaithe ar ionchódóirí claochladáin, agus déanaimid staidéar ar na héifeachtaí a bhaineann le faisnéis chomhréire agus comhthéacs a áireamh. Tríd is tríd, baineann ár múnlaí scór BLEU de 38.2 amach, agus ní ghintear cód do-chosanta ach i 1.92% de chásanna.', 'hu': 'Bemutatjuk a CONTEST-t, amely az NLP-alapú egységteszt befejezésének referenciaértékét, a teszt állítási állításainak előrejelzését a beállítási és fókusz módszere, azaz a tesztelendő módszer alapján. A ConTest nagyszabású (365 kilométeres adatpontokkal). A tesztkód és a tesztelt kód mellett tartalmazza a környezeti kódot, amelyet bármelyik nevezett. Úgy találtuk, hogy a kontextus kulcsfontosságú az állítások pontos előrejelzéséhez. Bevezetjük a transzformátor kódoló-dekódereken alapuló alapvonalakat, és tanulmányozzuk a szintaktikus információk és kontextusok bevonásának hatásait. Összességében modelleink 38,2 BLEU pontszámot érnek el, miközben csak az esetek 1,92%-ában generálnak feldolgozhatatlan kódot.', 'el': 'Παρουσιάζουμε ένα σημείο αναφοράς για την ολοκλήρωση της μονάδας δοκιμής με βάση το έργο της πρόβλεψης των δηλώσεων διαβεβαίωσης μιας δοκιμής δεδομένης της ρύθμισης και της εστιακής μεθόδου, δηλαδή της μεθόδου που πρέπει να δοκιμαστεί. Ο ConTest είναι μεγάλης κλίμακας (με σημεία δεδομένων 365k). Εκτός από τον κώδικα δοκιμής και τον δοκιμασμένο κώδικα, διαθέτει επίσης κώδικα περιβάλλοντος που καλείται από οποιοδήποτε. Διαπιστώσαμε ότι το πλαίσιο είναι κρίσιμο για την ακριβή πρόβλεψη των ισχυρισμών. Επίσης εισάγουμε γραμμές βάσης βασισμένες σε κωδικοποιητές-αποκωδικοποιητές μετασχηματιστών, και μελετάμε τα αποτελέσματα της συμπερίληψης συντακτικών πληροφοριών και περιβάλλοντος. Συνολικά, τα μοντέλα μας επιτυγχάνουν βαθμολογία 38.2, ενώ παράγουν μη μεταγραφή κώδικα μόνο σε 1.92% των περιπτώσεων.', 'it': "Introducemo CONTEST, un benchmark per il completamento del test di unità basato su PNL, il compito di prevedere le dichiarazioni assert di un test dato il suo setup e il metodo focale, cioè il metodo da testare. ConTest è su larga scala (con 365k datapoint). Oltre al codice di prova e al codice testato, dispone anche di codice contestuale chiamato da entrambi. Abbiamo trovato il contesto cruciale per prevedere con precisione le asserzioni. Introduciamo anche linee di base basate su encoder-decoder trasformatori e studiamo gli effetti dell'inclusione di informazioni sintattiche e contesto. Nel complesso, i nostri modelli raggiungono un punteggio BLEU di 38,2, mentre generano codice non riproducibile solo nell'1,92% dei casi.", 'kk': 'CONTEST- ті, NLP- негіздеген бірлік сынақтарын толтыру үшін бағыттау белгісін келтіріп, сынақтарының артық мәліметтерін баптау және тоғыс тәсілі, т. е. тексеру тәсілі. ConTest үлкен масштабы (365k деректер нүктелерімен). Сынақ кодын басқа, сынаған кодын басқа, сонымен қатар қолданылатын контексті кодын таңдайды. Біз тұрақты таңдау үшін контекст маңызды деп таптық. Сонымен қатар, түрлендіруші кодерлердің негізгі сызықтарын таңдап, синтактикалық мәліметтер мен контексті қоса алатын эффекттерді зерттейміз. Барлық үлгілеріміз 38,2 BLEU нәтижесін жеткізеді, бірақ тек 1,92% жағдайда жазылмайтын код құрылады.', 'mk': 'Ние го воведуваме КонтЕСТ, benchmark за завршување на тестот на единица базиран на НЛП, задачата да се предвидат изјавите на тестот со оглед на неговото поставување и фокалниот метод, т.е. методот кој треба да се тестира. ConTest е на голема skalа (со 365k точки на податоци). Освен тестовиот код и тестовиот код, исто така има контекстен код наречен или од. We found context to be crucial for accurately predicting assertions.  Ние, исто така, воведуваме основни линии базирани на трансформаторите кодери и ги проучуваме ефектите на вклучувањето на синтактичките информации и контекст. Вкупно, нашите модели достигнуваат БЛЕУ оценка од 38,2, додека генерираат незапаллив код само во 1,92 отсто од случаите.', 'ka': 'ჩვენ შევცვალობთ CONTEST, NLP-based ერთეულის ტესტის დასრულებაზე, ტესტის აცენტური გამოსახულებების დაწყენება, რომლებიც ტესტის გადასრულება და ფოკალური მეტი, მაგალითად ტესტის მეტი. ConTest არის დიდი მაგალითი (365k მონაცემებით). ტესტის კოდის დამატებით და ტესტიული კოდის დამატებით, ეს კონტექსტის კოდის შესახებ. ჩვენ მივიღეთ კონტექსტური გასანიშვნელოვანი, რომელიც წარმოდგენით აუცირებისთვის. ჩვენ ასევე განვითავსებთ ფესტრუქტურის კოდერების ბაზეზე და სინტაქტიური ინფორმაცია და კონტექსტის ეფექტის შესახებ. ჩვენი მოდელები 38,2 წერტილის ბლესონის წერტილი მივიღებთ, მაგრამ მხოლოდ 1,92% ფასების შექმნა უკეთესი კოდის შექმნა.', 'ml': 'നമ്മള്\u200d കോണ്\u200dടെസ്റ്റിനെ പരീക്ഷിക്കുന്ന ഒരു ബെങ്ക്മാര്\u200dക്ക് പരീക്ഷിക്കുന്നതിനായി പരീക്ഷിക്കുന്ന രീതി കോണ്\u200dടെസ്റ്റ് വലുതായിരിക്കുന്നു (365k ഡാറ്റാപ്പിന്റുകളുമായി) പരീക്ഷ കോഡും പരീക്ഷിക്കപ്പെട്ട കോഡും കൂടാതെ, അതും വിളിച്ചിരിക്കുന്ന കോഡുകളും കൂടിയാണ്. We found context to be crucial for accurately predicting assertions.  മാറ്റം മാറ്റുന്നതിന്റെ കോഡോര്\u200d അടിസ്ഥാനത്തില്\u200d നാം ബെസ്റ്റേലൈനുകളെ പരിചയപ്പെടുത്തുകയും സിനിട്ടാക്ടിക് വിവ മൊത്തത്തില്\u200d, ഞങ്ങളുടെ മോഡലുകള്\u200d 38.2 സ്കോര്\u200d പ്രാപിക്കുന്നു. കേസുകളില്\u200d 1.92% മാത്രമേ പാര്\u200dസബില്\u200d കോഡ് ഉണ്ടാക്കുന്നു.', 'ms': 'Kami memperkenalkan CONTEST, tanda rujukan untuk selesaikan ujian unit berasaskan NLP, tugas untuk meramalkan pernyataan pastikan ujian diberi pengaturan dan kaedah fokus, iaitu kaedah yang hendak diuji. ConTest skala besar (dengan 365k titik data). Selain kod ujian dan kod ujian, ia juga berkaitan kod konteks dipanggil oleh sama ada. Kami mendapati konteks yang penting untuk meramalkan saksi yang tepat. Kami juga memperkenalkan garis dasar berdasarkan pengekod pengubah, dan mempelajari kesan termasuk maklumat sintaktik dan konteks. Secara keseluruhan, model kita mencapai skor BLEU 38.2, sementara hanya menghasilkan kod yang tidak boleh dibakar dalam 1.92% kes.', 'lt': 'Įvedame CONTEST, NLP pagrįs to vieneto bandymų užbaigimo lyginamąjį tašką, užduotį numatyti bandymo tvirtinamuosius pareiškimus atsižvelgiant į jo nustatymą ir židininį metodą, t. y. bandomą metodą. ConTest yra didelis (su 365k duomenų taškais). Be bandomojo kodo ir bandomojo kodo, jame taip pat nurodomas kontekstinis kodas, kurį vadina. Mes nusprendėme, kad aplinkybės yra labai svarbios tiksliai prognozuojant teiginius. Taip pat įvedame bazines linijas, grindžiamas transformatoriaus kodatoriumi, ir tiriame sintaksinės informacijos ir konteksto įtraukimo poveikį. Apskritai, mūsų modeliai pasiekia 38,2 BLEU rezultatą, tuo pačiu metu tik 1,92 proc. atvejų sukuriamas neišdeginamas kodas.', 'no': 'Vi introduserer CONTEST, eit benchmarkt for fullføring av NLP-basert einingstesten, oppgåva for å foregå forsikninga av asserterte uttrykk i testen gitt oppsettmetoden og fokalmetoden, dvs. metoden som skal testast. ConTest er stor skala (med 365k datapunkt). I staden for testkoden og testkoden, kan det også bruka kontekstkoden som vert kalla av anten. Vi fann konteksten som er viktig for å spesifisera assertingar. Vi introduserer også baselinjer basert på transformeringskoder, og studerer effektane for å inkludere syntaksiske informasjon og kontekst. Generelt, våre modeller oppnår ein BLEU-score på 38,2, mens berre genererar utforskende kode i 1,92 % av tilfeller.', 'mn': 'CONTEST-г, NLP-д суурилсан нэгжүүдийн туршилтын төгсгөлийн багц, шалгалтын эсрэг тодорхойлолтын таамаглалтыг таамаглах үйл ажиллагааг илтгэнэ. Яг л шалгалтын арга. Контест бол том хэмжээтэй (365k өгөгдлийн цэгтэй). Тест кодын дотор мөн тест кодын дотор мөн агуулсан контекст кодын дотор мөн адилхан байдаг. Бид тодорхой таамаглах үед нөхцөл байдал чухал гэж олж мэдсэн. Мөн бид өөрчлөгч кодлогч дээр суурь шулуунуудыг тайлбарлаж, синтактик мэдээлэл болон нөхцөл байдлын үр дүнг судлах болно. Бидний загвар нь 38.2 тооны БЛЕУ-ын оноо гарч ирдэг. Гэвч зөвхөн хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэзээ ч хэ', 'mt': 'Aħna nintroduċu CONTEST, punt ta’ riferiment għat-tlestija tat-test tal-unit à bbażat fuq NLP, il-kompitu li nipprojbixxu d-dikjarazzjonijiet assertivi ta’ test fid-dawl tal-istruttura u l-metodu fokali tiegħu, jiġifieri l-metodu li għandu jiġi ttestjat. ConTest huwa fuq skala kbira (b’365k punti tad-dejta). Minbarra l-kodiċi tat-test u l-kodiċi ttestjat, għandu wkoll kodiċi ta’ kuntest imsejjaħ jew minn. Instabna li l-kuntest huwa kruċjali għat-tbassir preċiż tal-affermazzjonijiet. Inintroduċu wkoll linji bażi bbażati fuq id-dekodituri tal-kodifikaturi tat-trasformaturi, u nistudjaw l-effetti tal-inklużjoni tal-informazzjoni u l-kuntest sintattiċi. B’mod ġenerali, il-mudelli tagħna jiksbu punteġġ BLEU ta’ 38.2, filwaqt li jiġġeneraw kodiċi li ma jistax jitħares biss f’1.92% tal-każijiet.', 'pl': 'Wprowadzamy CONTEST, referencję dla ukończenia testów jednostkowych opartych na NLP, zadanie przewidywania stwierdzeń egzekwowania testu biorąc pod uwagę jego konfigurację i metodę fokalną, czyli metodę, która ma być testowana. ConTest jest dużą skalą (z 365k punktów danych). Oprócz kodu testowego i testowanego kodu, zawiera również kod kontekstowy wywołany przez jedną z nich. Uznaliśmy, że kontekst jest kluczowy dla dokładnego przewidywania twierdzeń. Wprowadzamy również linie bazowe oparte na koderze-dekoderach transformatorowych oraz badamy efekty włączenia informacji składniowych i kontekstu. Ogólnie rzecz biorąc, nasze modele osiągają wynik BLEU 38.2, generując jedynie niekompilacyjny kod w 1,92% przypadków.', 'ro': 'Introducem CONTEST, un punct de referință pentru finalizarea testului unitar bazat pe PNL, sarcina de a anticipa declarațiile de afirmare ale unui test având în vedere configurarea și metoda focală, adică metoda care urmează să fie testată. ConTest este la scară largă (cu 365k de puncte de date). Pe lângă codul de testare și codul testat, acesta dispune, de asemenea, de cod context numit de fiecare. Am considerat că contextul este crucial pentru prezicerea exactă a afirmaţiilor. Introducem, de asemenea, linii de referință bazate pe transformatoare codificatoare și studiem efectele includerii informațiilor sintactice și contextului. În general, modelele noastre obțin un scor BLEU de 38,2, în timp ce generează cod de neîmpărțit doar în 1,92% din cazuri.', 'sr': 'Predstavljamo CONTEST, kritiku za završavanje testova na osnovu NLP-a, zadatak predviđanja izjava uvjerenja testa s obzirom na svoj uspostav i fokalni metod, to je metod koji treba testirati. ConTest je velika skala (sa 365k bodova podataka). Osim testnog koda i testovanog koda, takoðe ukljuèuje i kontekstni kod koji se zove. Pronašli smo kontekst za tačno predviđanje tvrdnja. Takođe predstavljamo osnovne linije na osnovu transformacijskog kodera i proučavamo učinke uključujući sintaktičku informaciju i kontekst. U ukupnom slučaju, naši modeli postižu rezultat BLEU od 38,2, dok samo stvaraju nepromišljiv kodeks u 1,92% slučajeva.', 'sv': 'Vi introducerar CONTEST, ett riktmärke för NLP-baserad enhetstest slutförande, uppgiften att förutsäga ett test påstående med tanke på dess setup och fokal metod, dvs metoden som ska testas. ConTest är storskalig (med 365k datapunkter). Förutom testkoden och testad kod har den också kontextkod som kallas av endera. Vi fann att sammanhanget var avgörande för korrekt förutsägelse av påståenden. Vi introducerar även baslinjer baserade på transformatorkodare-dekodrar, och studerar effekterna av att inkludera syntaktisk information och sammanhang. Sammantaget uppnår våra modeller en BLEU-poäng på 38,2, samtidigt som de genererar oöverkomlig kod endast i 1,92% av fallen.', 'si': 'අපි CONTEST විශ්වාස කරනවා, NLP-ආධාරිත යුනිත් පරීක්ෂණය සම්පූර්ණය සඳහා බෙන්ච්මාර්ක්, පරීක්ෂණයේ පරීක්ෂණයේ අවස්ථාවක් සහ කෝෂාල Contesting is Large- scaled (with 365k data Points). පරීක්ෂණ කෝඩ් සහ පරීක්ෂණා කෝඩ් එක්ක, ඒක තියෙන්නේ පරීක්ෂණ කෝඩ් එක්ක වගේම කියලා. අපි හොයාගත්තා සංවේදනය සම්පූර්ණයෙන් ප්\u200dරශ්නයක් වෙන්න පුළුවන් කියලා. අපි මූලික තොරතුරු සංවිධානය කරන්නේ සංවිධානය කොඩර් ඩිකොඩර් වලට අධාරණය කරනවා, සහ සංවිධානය සහ සං සම්පූර්ණයෙන්, අපේ මොඩල් එක්ක බ්ලූයුස් අංකයක් 38.2 වෙනුවෙන් ලැබෙනවා, ඒ වගේම ප්\u200dරශ්නයක් විතරක් 1.92% ව', 'so': 'Waxaynu soo bandhignaynaa CONTEST, baaritaanka imtixaanka kooxa e e NLP-ku saleysan, shaqada ku saabsan ka hor dhigidda imtixaanka ee uu soo bandhigay iyo habka midowga, waa qaabka la imtixaamo. Imtixaanka waa mid aad u weyn (waxaa ku yaala 365k barxado macluumaad). Qorada imtixaanka iyo codka imtixaanka waxaa sidoo kale ku jira kooxda imtixaanka ee lagu magacaabay. Waxaynu helnay dabool muhiim ah si saxda ah u sii sheegidda hadallada. Sidoo kale waxaynu soo bandhignaa aasaasyo ku saleysan codsiga beddelinta, waxaana baranaynaa saamaynta ku saabsan macluumaadka iyo kooxda. Sida caadiga ah modelalkayagu waxay gaadhaan koox BLEU oo ah 38.2, xittaa waxaa keliyahoo soo saara koox aan la sameyn karin boqolkiiba 1.92.', 'ta': 'நாம் CONTEST, NLP-அடிப்படையில் உள்ள அலகு சோதனை முடிவுக்கு ஒரு பென்க்மார்க் குறிப்பு, சோதனையின் கூற்று வார்த்தைகள் கொடுத்துள்ளது என்பதை முன்வார கான்ட்செஸ் பெரிய அளவு (365k தரவுப் புள்ளிகளுடன்) சோதனை குறியீடு மற்றும் சோதிக்கப்பட்ட குறியீடு We found context to be crucial for accurately predicting assertions.  நாம் மாற்றி குறியீடுகளை அடிப்படையில் அடிப்படையான கோடுகளை குறிப்பிடுகிறோம் மற்றும் ஒத்திசைவு தகவல் மற்றும் ச மொத்தமாக, எங்கள் மாதிரிகள் 38.2 பிலியு புள்ளி பெறுகிறது, ஆனால் 1.92% விஷயங்களில் மட்டும் குறியீட்டை உருவாக்குகிறது.', 'ur': 'ہم CONTEST کو معلوم کرتے ہیں، NLP بنیادی یونیٹ کی آزمائش پوری کرنے کے لئے ایک بنچم مارک، ایک آزمائش کی آزمائش کی آزمائش کا کام ہے جو اس کے سٹاپ اور فوکال طریقے سے دیا گیا ہے، یعنی آزمائش کا طریقہ۔ ConTest is large-scale (with 365k datapoints). آزمائش کا کوڈ اور آزمائش کا کوڈ کے علاوہ، یہ بھی کنٹکس کوڈ کو پکارتا ہے۔ ہم نے سمجھ لیا کہ دقیق پیش بینی کے لئے ضروری ہے۔ ہم نے ابس لائن کو بھی تغییر قائم کرنے والے کوڈر-ڈیکوڈر پر بنیاد رکھا ہے اور سینٹکتیک معلومات اور کنٹکس کے شامل ہونے کے اثرات کی تحقیق کریں۔ بالکل، ہمارے مدلکوں 38.2 کی BLEU اسکور پہنچ رہے ہیں، حالانکہ صرف 1.92% کیس میں ناپذیر کوڈ پیدا کر رہے ہیں.', 'vi': 'Chúng ta s ẽ đưa ra liên bang, một tiêu chuẩn cho việc hoàn thành đơn vị dựa trên lập trình độc lập lập lập, nhiệm vụ dự đoán những phát biểu của thử nghiệm dựa trên thiết lập và phương pháp tiêu cự, tức là phương pháp thử nghiệm. Xét nghiệm nằm trên diện rộng (với các điểm dữ liệu 365k). Bên cạnh mã kiểm tra và mã đã thử, nó cũng có mã ngữ cảnh được gọi bởi một trong hai. Chúng tôi tìm thấy bối cảnh quan trọng để dự đoán chính xác. Chúng tôi cũng giới thiệu những đường cơ bản dựa trên bộ mã hóa máy biến đổi, và nghiên cứu kết quả của việc cung cấp thông tin cú pháp và ngữ cảnh. Trong tổng hợp, các mô-đun của chúng ta đạt được một lượng đứng của hợp-38.2, trong khi đó chỉ phát ra mã không đối thủ trong phạm vi 1.992.', 'uz': "Биз CONTEST, NLP asosida bir sinov tizimni tugatish uchun benchmark, tasdiqlash imkoniyatini koʻrsatish imkoniyatlarini tasdiqlash imkoniyatini koʻrsatish imkoniyatini, balki sinab qilish usuli. Name Besides the test code and tested code, it also features context code called by either.  Biz tashkilotlarni tasavvur qilish muhim bo'lganligini topdik. Biz boshqa shaxsiy kodlash kodlash qoidalari asosida asosiy sonlarni ko'rib chiqaramiz va syntactik maʼlumot va tarkibini o'rganamiz. Umumiy, modellarimiz 38.2 pochta BLEU bo'ladi, ammo faqat xabarlarning 1.92% davomida notoʻgʻri kodi yaratish mumkin.", 'bg': 'Представяме КОНТЕСТ, еталон за завършване на единичен тест, базиран на НЛП, задачата за предсказване на твърденията на теста предвид неговата настройка и фокусния метод, т.е. метода, който ще бъде тестван. КонТест е мащабен (с 365км точки данни). Освен тестовия код и тествания код, той също разполага с контекстен код, наречен от двете. Намерихме контекста за решаващ за точното предсказване на твърденията. Също така въвеждаме базови линии, базирани на трансформаторни кодери-декодери, и изучаваме ефектите от включването на синтактична информация и контекст. Като цяло нашите модели постигат резултат от 38.2, като същевременно генерират неперсиаем код само в 1.92% от случаите.', 'nl': 'We introduceren CONTEST, een benchmark voor NLP-gebaseerde unit test voltooiing, de taak om de bewering verklaringen van een test te voorspellen gezien de opstelling en focusmethode, d.w.z. de te testen methode. ConTest is grootschalig (met 365k datapoints). Naast de testcode en de geteste code bevat het ook contextcode die door beide wordt aangeroepen. We vonden context cruciaal voor het nauwkeurig voorspellen van beweringen. We introduceren ook baselines gebaseerd op transformator encoder-decoders, en bestuderen de effecten van het opnemen van syntactische informatie en context. Over het algemeen bereiken onze modellen een BLEU score van 38.2, terwijl ze slechts onverslaanbare code genereren in 1,92% van de gevallen.', 'da': "Vi introducerer CONTEST, et benchmark for NLP-baseret enhedstest fuldførelse, opgaven med at forudsige en test's påstand erklæringer i betragtning af dens setup og fokal metode, dvs. den metode, der skal testes. ConTest er storstilet (med 365k datapunkter). Udover testkoden og testet kode har den også kontekstkode, der kaldes af begge. Vi fandt kontekst for at være afgørende for præcist at forudsige påstande. Vi introducerer også baselines baseret på transformer encoder-dekodere, og undersøger virkningerne af at inkludere syntaktisk information og kontekst. Samlet set opnår vores modeller en BLEU score på 38,2, mens de kun genererer uoverskuelig kode i 1,92% af tilfældene.", 'hr': 'Predstavljamo CONTEST, kritiku za završavanje testova na osnovu NLP-a, zadatak predviđanja izjava uvjerenja testa s obzirom na svoj način uspostavljanja i fokusiranja, tj. metodu koji treba testirati. ConTest je velika skala (s 365k podataka). Osim testnog koda i testiranog koda, također se uključuje i kontekstni kod koji se zove. Našli smo da je kontekst ključni za precizno predviđanje uvjeta. Također predstavljamo osnovne linije na temelju kodera transformera i proučavamo učinke uključujući sintaktičke informacije i kontekst. U ukupnom slučaju, naši modeli postignu rezultat BLEU-a od 38,2, dok samo stvaraju nepromišljiv kod u 1,92% slučajeva.', 'id': "We introduce CONTEST, a benchmark for NLP-based unit test completion, the task of predicting a test's assert statements given its setup and focal method, i.e. the method to be tested.  ConTest skala besar (dengan 365k poin data). Selain kode ujian dan kode ujian, juga memiliki kode konteks yang disebut oleh keduanya. Kami menemukan konteks yang penting untuk memprediksi dengan akurat pernyataan. Kami juga memperkenalkan garis dasar berdasarkan koder-dekoder transformer, dan mempelajari efek dari termasuk informasi sintaksi dan konteks. Secara keseluruhan, model kita mencapai nilai BLEU 38,2, sementara hanya menghasilkan kode yang tidak terbakar dalam 1,92% kasus.", 'de': 'Wir stellen CONTEST vor, einen Benchmark für die NLP-basierte Unit Test Completion, die Aufgabe, die Assert Statements eines Tests aufgrund seines Setups und der Fokusmethode, also der zu testenden Methode, vorherzusagen. ConTest ist groß (mit 365k Datenpunkten). Neben dem Testcode und dem getesteten Code enthält es auch Kontextcode, der von beiden aufgerufen wird. Wir fanden den Kontext als entscheidend für die genaue Vorhersage von Behauptungen. Wir stellen auch Baselines vor, die auf Transformator Encoder-Decodern basieren und untersuchen die Auswirkungen der Einbeziehung syntaktischer Informationen und Kontext. Insgesamt erreichen unsere Modelle einen BLEU-Score von 38.2, während sie nur in 1,92% der Fälle unverspielbaren Code generieren.', 'ko': '우리는 NLP의 단원 테스트를 바탕으로 완성된 기준을 바탕으로 테스트의 설정과 초점 방법(즉 테스트를 기다리는 방법)에 따라 테스트의 단언문을 예측하는 임무를 소개했다.경기 규모가 매우 크다.테스트 코드와 테스트 코드를 제외하고는 어느 한 측이 호출하는 상하문 코드도 가지고 있다.우리는 상하문이 정확한 예측 단언에 매우 중요하다는 것을 발견했다.transformer 인코더-디코더를 기반으로 한 기선을 소개하고 문법 정보와 상하문을 포함하는 효과도 연구했다.전반적으로 말하면 우리 모델의 BLEU 점수는 38.2이고 1.92%의 경우 해석할 수 없는 코드만 생성된다.', 'fa': 'ما CONTEST را معرفی می\u200cکنیم، یک نقشه برای تموم آزمایش واحد بنیاد NLP، وظیفه پیش\u200cبینی گزارش\u200cهای ثابت\u200cکننده\u200cی یک آزمایش به عنوان روش\u200cسازی و تمرکز آن، یعنی روش\u200cسازی که باید آزمایش شود. ConTest مقیاس بزرگی است (با نقطه داده\u200cهای 365k). غیر از کد آزمایش و کد آزمایش، همچنین کد آزمایش را به عنوان کد آزمایش مشخص می\u200cکند. ما متصل را برای پیش بینی دقیقا مهم یافتیم. ما همچنین خطوط بنیادی را بر اساس تغییر\u200cدهنده\u200cی رمزگار\u200cدهنده\u200cها معرفی می\u200cکنیم، و اثرات تغییر\u200cدهنده\u200cی اطلاعات سنتاکتیک و محیط را مطالعه می\u200cکنیم. در کل، مدل\u200cهای ما یک امتیاز BLEU از 38.2 می\u200cرسد، در حالی که تنها در ۱.92% از پرونده\u200cها کد غیرقابل تغییر قابل تغییر قابل تغییر قابل تولید می\u200cکند.', 'sw': 'Tunawasilisha CONTEST, benchmark for completion of test unit s based in NLP, jukumu la kutabiri matamko ya utaratibu wa jaribio lililosababisha setup and methods of focal, yaani njia ya kujaribu. ConTest ni kiwango kikubwa (na vituo 365k vya takwimu). Zaidi ya kodi ya jaribio na kodi ya jaribio, pia inaonyesha kodi la muktadha linaloitwa pia. Tumegundua muktadha wa muhimu wa kutabiri ukweli matamko. Tunaweza pia kutambua misingi inayohusiana na decodi za mabadiliko, na kutafiti madhara ya pamoja na taarifa na muktadha. Kwa ujumla, mifano yetu inafanikiwa score ya BLEU ya 38.2, wakati tu hutengeneza sheria isiyo na mabaya katika asilimia 1.92 ya kesi.', 'tr': "CONTEST'i, NLP tabanly birim barlamasynyň tamamlamasynyň bir benchmark taýýarlapdyr,diýmek üçin test i ň durum we fokus metodasyny berilýän durumlaryny tahmin etmek üçin täblisaň. ConTest uly ölçekli (365k veri nokatlar bilen). Testler ködlerinde we testiler ködlerinde munuň hem diýilip atlanýan konteks ködleri hem karakterlerdir. Biz özümizi düzgün çaklamak üçin daýyn bir kontekst tapdyk. Biz de sintaktik bilgi ve kontekste dahil olmak üzere tabanlı tabanlı tabanlı çizgileri tanıtıyoruz. Munuň ýagdaýynda, nusgalarymyz 38.2 ýagdaýynda BLEU ködlerini ýetip bilýär, diňe 1.92% ýagdaýda ýazmaz ködleri döreýär.", 'af': "Ons introduseer CONTEST, 'n benchmark vir NLP-gebaseerde eenheid toets voltooiing, die taak van voorskou van 'n toets s e asserte uitdrukkings gegee sy opstelling en fokale metode, bv. die metode om te testeer. ConTest is groot- scale (met 365k datapunte). Buitend die toets kode en toets kode, is dit ook die kontekskode wat deur enige genoem word. Ons het konteks gevind om gekruisig te wees vir presies voorskou aanbevestings. Ons introduseer ook basisline gebaseer op transformeerder enkoder-dekodere en ondersoek die effekte van insluitend sintaktieke inligting en konteks. Op die hele maniere, ons modele het 'n BLEU-telling van 38.2 bereik, terwyl slegs onverwerkbare kode genereer in 1.92% van gevalle.", 'sq': 'Ne prezantojmë CONTEST, një referencë për kompletimin e testit të njës i s ë me bazë në NLP, detyrën e parashikimit të deklaratave të një test i duke marrë parasysh konfigurimin e tij dhe metodën fokale, që do të thotë metodën që do të testohet. ConTest është në shkallë të madhe (me 365k pikë të dhënash). Përveç kodit të testuar dhe kodit të testuar, ai ka gjithashtu kod konteksti të quajtur nga ose. We found context to be crucial for accurately predicting assertions.  We also introduce baselines based on transformer encoder-decoders, and study the effects of including syntactic information and context.  Në përgjithësi, modelet tona arrijnë një rezultat BLEU prej 38.2, ndërsa gjenerojnë vetëm kod të papërshtatshëm në 1.92% të rasteve.', 'am': 'CONTEST፣ NLP-based የክፍተት ተፈተና ፍጻሜውን ለመጠየቅ የፈተናውን ጉዳይ እና የክፍለ ሥርዓት ማሰናከል እና የመፈተን ሥርዓት ነው፡፡ Contest is large-scale (with 365k ዳታ points). ከፈተናው ኮድ እና ፈተናው ኮድ ሌላ፣ የኮድ ኮድ እና በጥቅምት ይጠቅማል፡፡ አካባቢ መሆኑን ለመፍጠር አስቸጋሪ ሆነን አግኝተናል፡፡ እንደዚህም በመለወጥ የኮድ ኮድዶችን በመሠረት መሳሪያ እናገልጣለን እና የሲንተቲክ መረጃ እና ግንኙነትን እናስተምር፡፡ በጠቅላላ፣ ሞዴላዎቻችን የቢሊዩን ደረጃ 38.2 አግኝቷል፣ ከ1.92 በመቶ በጉዳዮች ውስጥ ብቻ ያልተፈላጊ ኮድ አግኝቷል፡፡', 'az': "Biz CONTEST'i, NLP tabanlı birim test tamamlaması üçün bir benchmark təyin edirik, testlərin təsdiqlənməsi və təsdiqlənməsi üçün təsdiqlənməsi və təsdiqlənməsi üçün təsdiqlənməsi üçün təsdiqləyirik. ConTest böyük ölçüdür (365k veri nöqtələri ilə). Sınama kodu və sınama kodu istisna edilməsindən başqa, bu da tərəfindən nazil edilən kontekst kodu təsdiqləyir. Biz müəyyən edilməsi üçün məlumat çox mövcuddur. Biz həmçinin transformer kodlayıcılarına dayanan baz çətinləri təşkil edirik və sintaktik məlumatların və məlumatların etkisini təşkil edirik. Əlbəttə, modellərimiz 38,2 BLEU nöqtəsinə nail oldu, lakin yalnız 1,92% vəziyyətdə təkrar edilməz kodu yaradılır.", 'bn': 'এনএলপি-ভিত্তিক ইউনিট পরীক্ষা সম্পূর্ণের জন্য আমরা কোন্টেস্ট পরীক্ষার বেনম্যার্ক পরীক্ষা করে দেখাচ্ছি, যেমন পরীক্ষার পদ্ধতি পরীক্ষা করা হবে। কন্টেস বিশাল স্কেল (৩৬৫ কিছু ডাটাবেন্ট দিয়ে)। পরীক্ষার কোড এবং পরীক্ষা করা কোড ছাড়াও, এটিও প্রাপ্ত কন্টেক্সটেক্সট কোড দ্বারা ডাকা হয়। We found context to be crucial for accurately predicting assertions.  আমরা পরিবর্তনের কোডারের উপর ভিত্তিক ভিত্তিক বেসেলাইন পরিচয় করিয়ে দেই এবং সিন্ট্যাকটিক তথ্য এবং প্রেক্ষাপটের প্রভাব পড়ি। সাধারণত, আমাদের মডেলগুলো ৩৮.', 'ca': "Introduïm CONTEST, un punt de referència per la completació de les proves unit àries basades en NLP, la tasca de predir les afirmacions d'una prova amb la seva configuració i el mètode focal, és a dir, el mètode a provar. ConTest és a gran escala (amb 365k punts de dades). A part del codi de prova i el codi de prova, també té codi contextual anomenat tampoc. Vam trobar que el context era crucial per predir exactament les afirmacions. També introduïm línies de base basades en codificadors de transformador, i estudiem els efectes d'incloure informació sinàctica i context. En general, els nostres models aconsegueixen una puntuació BLEU de 38,2, mentre només generant codi inestimable en 1,92% dels casos.", 'cs': 'Představujeme CONTEST, srovnávací měřítko pro ukončení jednotkových testů založených na NLP, úkol předpovídat výkazy prosazování testu s ohledem na jeho nastavení a fokusní metodu, tedy metodu, která má být testována. ConTest je rozsáhlý (s 365k datovými body). Kromě testovacího kódu a testovaného kódu obsahuje také kontextový kód volaný oběma. Zjistili jsme, že kontext je klíčový pro přesné předpovědi tvrzení. Dále představujeme základní linky založené na transformátorových kodérech a zkoumáme efekty zahrnutí syntaktických informací a kontextu. Celkově dosahují naše modely BLEU skóre 38,2, přičemž generují nepřepisovatelný kód pouze v 1,92% případů.', 'et': 'Tutvustame CONTESTi, NLP-põhise ühikutesti lõpuleviimise võrdlusalust, mille eesmärk on prognoosida testi kinnitusväärtusi, arvestades selle seadistust ja fokusmeetodit ehk katsetatavat meetodit. ConTest on ulatuslik (365 km andmepunktiga). Lisaks testikoodile ja testitud koodile sisaldab see ka kontekstikoodi, mida nimetab kumbki. Leidsime, et kontekst on väidete täpseks prognoosimiseks väga oluline. Tutvustame ka trafo kodeerijatel põhinevaid lähtejooni ning uurime süntaktilise informatsiooni ja konteksti kaasamise mõju. Kokkuvõttes saavutavad meie mudelid BLEU skoori 38,2, samal ajal kui tekitavad pakkimata koodi ainult 1,92% juhtudest.', 'hy': 'Մենք ներկայացնում ենք ԿոնտեՍթ-ը, ՆԼՊ-ի հիմնված միավորի փորձարկումների ավարտին համեմատական նպատակը, փորձարկումների ճշգրիտ հայտարարությունների կանխատեսման խնդիրը, հաշվի առնելով դրա կառուցվածքը և ֆոկալ մեթոդը, այսինք ConTEst-ը մեծ մասշտաբ է (365k տվյալների կետերով): Besides the test code and tested code, it also features context code called by either.  Մենք կարծում էինք, որ կոնտեքստը կարևոր է ճշգրիտ կանխատեսելու համար: Մենք նաև ներկայացնում ենք հիմնական գծեր, հիմնված վերափոխողների կոդերների վրա, և ուսումնասիրում ենք սինտակտիկ ինֆորմացիայի և կոնտեքստի ներառման ազդեցությունները: Ընդհանուր առմամբ, մեր մոդելները հասնում են 38.2 բԼԵՎ-ի գնահատականի, մինչդեռ միայն 1.92 տոկոսի անհրաժեշտ կոդ են ստեղծում:', 'bs': 'Predstavljamo CONTEST, kritiku za završavanje testova na osnovu NLP-a, zadatak predviđanja izjava uvjerenja testa s obzirom na njen način uspostavljanja i fokalnog metoda, to je metod koji treba testirati. ConTest je velika skala (sa 365k bodova podataka). Osim testnog koda i testnog koda, također uključuje i kontekstni kod koji se zove. Pronašli smo kontekst za tačno predviđanje tvrdnji. Također predstavljamo osnovne linije na temelju transformatorskih kodera i proučavamo učinke uključujući sintaktičke informacije i kontekst. U ukupnom slučaju, naši modeli postignu rezultat BLEU-a od 38,2, dok samo stvaraju nepromišljiv kod u 1,92% slučajeva.', 'fi': 'Esittelemme CONTESTin, vertailuarvon NLP-pohjaiselle yksikkötestin suorittamiselle, jonka tehtävänä on ennustaa testin assert statement -lauseet ottaen huomioon sen kokoonpanon ja fokusmenetelmän eli testattavan menetelmän. ConTest on laajamittainen (365 km datapistettä). Testikoodin ja testatun koodin lisäksi siinä on myös kontekstikoodi, jota kutsutaan jompikumpi. Pidimme kontekstia ratkaisevana väitteiden tarkan ennustamisen kannalta. Esittelemme myös muuntajakooderiin perustuvia lähtölinjoja ja tutkimme syntaktisen tiedon ja kontekstin sisällyttämisen vaikutuksia. Kaiken kaikkiaan mallimme saavuttavat BLEU-pisteen 38,2 ja tuottavat korvaamatonta koodia vain 1,92 prosentissa tapauksista.', 'he': 'אנחנו מציגים את CONTEST, נקודת רמז עבור השלמת מבחן יחידה מבוססת על NLP, המשימה של לחזות הצהרות של מבחן בהתחשב בשיטת ההגדרה והשיטה המרכזית שלה, כלומר השיטה שנבדקה. ConTest הוא בקנה מידה גדולה (עם 365k נקודות נתונים). חוץ מהקוד המבחן וקוד המבחן, הוא גם מכיל קוד הקשר שנקרא גם על ידי. We found context to be crucial for accurately predicting assertions.  אנחנו גם מציגים קווי בסיס מבוססים על מערכת מערכת קודד, ולחקר את ההשפעות של כולל מידע סינטאקטי וקונקסט. באופן כללי, הדוגמנים שלנו משיגים נקודת BLEU של 38.2, בעוד יוצרים קוד בלתי ניתן לשרוף רק ב-1.92% מהמקרים.', 'sk': 'Predstavljamo CONTEST, referenčno merilo za dokončanje enotnega preskusa na osnovi NLP, nalogo napovedovanja trditev preskusa glede na njegovo nastavitev in fokusno metodo, tj. metodo, ki jo je treba preskusiti. ConTest je obsežen (s 365 km podatkovnimi točkami). Poleg testne kode in testirane kode ima tudi kontekstno kodo, ki jo imenuje katera koli. Ugotovili smo, da je kontekst ključnega pomena za natančno napovedovanje trditev. Predstavljamo tudi osnovne linije, ki temeljijo na transformatorskih kodirnih dekoderjih, in preučujemo učinke vključevanja sintaktičnih informacij in konteksta. Na splošno naši modeli dosežejo rezultat BLEU 38,2, medtem ko ustvarjajo neplačljivo kodo le v 1,92% primerov.', 'ha': "Tuna ƙara CONTEST, wani bangon wa cikakken jarraba cikin shirin NLP-based, aikin wanda za'a gabatar da bayani na jarraba cewa da tsarin da kuma hanyon focal, misali da za'a jarraba shi. KCharselect unicode block name Babu kodi na jarraba ko da aka jarraba shi, yana da amfani da kodi ɗin kode na'ura ko. Mun sãmu muhimu da za'a yi bayani ga kalmõmi. Tuna nuna kayan-kode-kode-kodi, kuma munã karatun ayukan ayuka, da kuma masu haɗi da shirin-takis. Gansa da kammala, misalinmu za'a sami matsayin BLEU na 38.2, kuma a sami kodi kawai wanda ba'a samu ba cikin asilimin 1.92.", 'jv': 'We first insert undo-type Mungkin kabeh ujian kode lan ujian kode, dadi nyimpen kode kontèks seneng dadi. Awak dhéwé éntuk sistem sing klêrung kanggo nggawe ujian Awak dhéwé nglebokake sistem sing basa kanggo koder-koder, lan uga njaluk efek ngono informasi sistem sing nyelarane Lakok, model sing sampeyan ngerasai blok sing katok 3.2, sampeyan ngilangno kode sing ora bisa perusahaan kanggo kowé 1.2% sakjane sakjane.', 'bo': 'ང་ཚོས་CONTEST དང་། NLP ལ་གཞི་རྟེན་པའི་ཆ་འཕྲིན་ལྟར་བརྟག་དཔྱད་བྱེད་པའི་བྱ་ཚུལ་གསལ་བཤད་པ་ཞིག་ལ་སྔོན་སྒྲིག ཚད་བརྟག་ཞིབ་ཚད་ཆེ་བ་ཞིག་ཡིན། དེ་ལས་བརྟག་ཞིབ་བཤེར་ཨང་དང་བརྟག་ཞིབ་བྱས་པའི་ཁོར་ཡིག་ཨང་ཡང་ཆ་མཚོན་པ ང་ཚོས་ཁོར་ཡུག་བྱེད་པར་གལ་ཆེན་རྐྱེན་ཏུ་རྟོགས་པ་ཡིན། ང་ཚོས་དུས་མཐུན་བཟོ་བྱེད་པའི་རྨང་གཞིའི་ཕྱོགས་ཀྱི་ཨིན་ཀོ་ཌི་ཨང་ཀོ་ལ་གཞི་རྟེན་ནས་ངོས་འཛིན་བྱེད་ཀྱི་ཡོད། ཡིན་ཡང་། ང་ཚོའི་མིག་དཔེ་གཞུང་གིས་སྐྱེལ་ཆེན་38.2 ཡི་ཚད་ལྡན་རྐྱེན་བྱེད་ཀྱི་ཡོད།'}
{'en': 'CommitBERT : Commit Message Generation Using Pre-Trained Programming Language Model C ommit BERT : Commit Message Generation Using Pre-Trained Programming Language Model', 'fr': 'CommitBert\xa0: Génération de messages de validation en utilisant un modèle de langage de programmation', 'ar': 'CommitBERT: الالتزام بإنشاء الرسائل باستخدام نموذج لغة البرمجة المدربين مسبقًا', 'es': 'CommitBert: CommitBert: Comprometer la generación de mensajes utilizando', 'pt': 'CommitBERT: Geração de Mensagem de Confirmação Usando Modelo de Linguagem de Programação Pré-treinada', 'ja': 'CommitBERT ：事前にトレーニングされたプログラミング言語モデルを使用したメッセージ生成のコミット', 'hi': 'CommitBERT: पूर्व प्रशिक्षित प्रोग्रामिंग भाषा मॉडल का उपयोग कर संदेश जनरेशन कमिट', 'zh': 'CommitBERT:豫训编程语言范', 'ru': 'CommitBERT: Генерация сообщений фиксации с использованием предварительно обученной модели языка программирования', 'ga': 'CommitBERT: Tiomantas Giniúint Teachtaireachta Ag Úsáid Samhail Teanga Ríomhchlárúcháin Réamhoilte', 'hu': 'CommitBERT: Előképzett programozási nyelvi modell segítségével üzenetek generálása', 'ka': 'CommitBERT: Commit Message Generation', 'el': 'Δεσμεύστε τη δημιουργία μηνυμάτων χρησιμοποιώντας το προ-εκπαιδευμένο μοντέλο γλώσσας προγραμματισμού', 'kk': 'CommitBERT: Алдын- оқылған бағдарламаның тіл үлгісін қолданатын хатты құру', 'it': 'CommitBERT: Generazione di messaggi di commit utilizzando il modello di linguaggio di programmazione pre-addestrato', 'lt': 'Įsipareigojimas', 'mk': 'BERT: Генерација на пораки за комуникација користејќи предобучен јазик модел за програмирање', 'ml': 'കമ്മിറ്റ്ബെര്\u200dട്ട്: മുമ്പ് പരിശീലന പ്രോഗ്രാമിങ്ങിന്റെ ഭാഷ മോഡല്\u200d ഉപയോഗിക്കുന്ന കമ്മിറ്റ് സന', 'mn': 'CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model', 'ms': 'CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model', 'mt': 'CommitBERT: Ġenerazzjoni ta’ Messaġġi ta’ Kummissjoni bl-użu ta’ mudell lingwistiku ta’ programmazzjoni mħarreġ minn qabel', 'no': 'CommitBERT: Lag meldingar ved bruk av føreøvinga språk- modell', 'pl': 'CommitBERT: Generowanie wiadomości CommitBERT za pomocą wstępnie przeszkolonego modelu języka programowania', 'sr': 'CommitBERT: Generacija poruke koja koristi predobučeni jezik programiranja', 'ro': 'CommitBERT: Generarea mesajelor de comitere folosind modelul de limbaj de programare pre-instruit', 'si': 'Comment', 'so': 'CommitBERT: Commit Message Generation using pre-trained programming Model', 'sv': 'CommitBERT: Skapa meddelanden med hjälp av förklädd programmeringsspråksmodell', 'ta': 'குறிப்பு: முன் பயிற்சி நிரல் மொழி மாதிரியை பயன்படுத்தி குறிப்பு செய்தி உருவாக்கம்', 'ur': 'کمیٹ برٹ: پیغام پیدا کرنا کمیٹ کرنا', 'uz': 'Comment', 'vi': 'Ghi nhận: tạo tin nhắn bằng cách dùng ngôn ngữ lập trình sẵn sàng', 'bg': 'Изпращане на съобщение чрез предварително обучен езиков модел за програмиране', 'da': 'CommitBERT: Commit-generering af meddelelser ved hjælp af forududdannet programmeringssprogsmodel', 'nl': 'CommitBERT: Berichten genereren met behulp van vooraf getraind programmeertaalmodel', 'de': 'CommitBERT: Commit Message Generierung mithilfe eines vortrainierten Programmiersprachenmodells', 'hr': 'CommitBERT: Generacija poruke poruke koristeći predobučeni model jezika programiranja', 'id': 'CommitBERT: Commit Message Generation Menggunakan Model Bahasa Programasi Terlatih', 'fa': 'CommitBERT: تولید پیام را با استفاده از مدل برنامه\u200cبندی زبان پیش آموزش', 'ko': 'CommitBERT: 미리 훈련된 프로그래밍 언어 모델로 제출 메시지 생성', 'sw': 'Comments', 'af': 'Opdrag', 'sq': 'CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model', 'tr': 'Hat', 'hy': 'BER: Commit հաղորդագրության ստեղծման օգտագործելով նախապատրաստված ծրագրավորման լեզվի մոդել', 'az': 'CommitBERT: √Ėn t…ôhsil edilmiŇü Proqramma Dili Modelind…ôn istifad…ô edil…ôn ńįsmarńĪŇü √úretimi', 'bn': 'মন্তব্য: পূর্ববর্তী প্রোগ্রামিং ভাষা মডেল ব্যবহার করে কমিট বার্তা জেনারেশন', 'am': 'ምስሉን በሌላ ስም አስቀምጥ', 'cs': 'CommitBERT: Generování zpráv s využitím předškoleného programovacího jazykového modelu', 'ca': 'CommitBERT: Generació de missatges de comunicació utilitzant un model de llenguatge de programació pré-capacitat', 'bs': 'CommitBERT: Generacija poruke koja koristi predobučeni jezik programiranja', 'et': 'CommitBERT: Commit Message Generation, kasutades eelõpetatud programmeerimiskeele mudelit', 'fi': 'CommitBERT: Commit Message Generation käyttäen esikoulutettua ohjelmointikielimallia', 'ha': 'KCharselect unicode block name', 'he': 'CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model', 'sk': 'CommitBERT: Objava sporočil z uporabo vnaprej usposobljenega programskega jezikovnega modela', 'bo': 'CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model', 'jv': 'KomitBERT: Komit Message Generation Using Preview-Learned Program Language model'}
{'en': 'Commit message is a document that summarizes source code changes in  natural language . A good commit message clearly shows the source code changes, so this enhances collaboration between developers. Therefore, our work is to develop a  model  that automatically writes the commit message. To this end, we release 345 K datasets consisting of code modification and commit messages in six programming languages (Python, PHP,  Go ,  Java ,  JavaScript , and Ruby). Similar to the neural machine translation (NMT) model, using our dataset, we feed the code modification to the encoder input and the commit message to the decoder input and measure the result of the generated commit message with BLEU-4. Also, we propose the following two training methods to improve the result of generating the commit message : (1) A method of preprocessing the input to feed the code modification to the encoder input. (2) A method that uses an initial weight suitable for the code domain to reduce the gap in contextual representation between programming language (PL) and natural language (NL).', 'ar': 'رسالة الالتزام هي مستند يلخص تغييرات التعليمات البرمجية المصدر في اللغة الطبيعية. تُظهر رسالة الالتزام الجيدة بوضوح تغييرات كود المصدر ، لذا فإن هذا يعزز التعاون بين المطورين. لذلك ، فإن عملنا هو تطوير نموذج يقوم تلقائيًا بكتابة رسالة الالتزام. تحقيقا لهذه الغاية ، قمنا بإصدار 345K مجموعة بيانات تتكون من تعديل التعليمات البرمجية وإلزام الرسائل بست لغات برمجة (Python و PHP و Go و Java و JavaScript و Ruby). على غرار نموذج الترجمة الآلية العصبية (NMT) ، باستخدام مجموعة البيانات الخاصة بنا ، نقوم بتغذية تعديل الكود بإدخال المشفر ورسالة الالتزام بإدخال وحدة فك التشفير وقياس نتيجة رسالة الالتزام التي تم إنشاؤها باستخدام BLEU-4. أيضًا ، نقترح طريقتين للتدريب التاليتين لتحسين نتيجة إنشاء رسالة الالتزام: (1) طريقة للمعالجة المسبقة للإدخال لتغذية تعديل الكود إلى إدخال المشفر. (2) طريقة تستخدم وزنًا أوليًا مناسبًا لمجال الكود لتقليل الفجوة في التمثيل السياقي بين لغة البرمجة (PL) واللغة الطبيعية (NL).', 'pt': 'A mensagem de confirmação é um documento que resume as alterações do código-fonte em linguagem natural. Uma boa mensagem de confirmação mostra claramente as alterações no código-fonte, o que melhora a colaboração entre os desenvolvedores. Portanto, nosso trabalho é desenvolver um modelo que escreva automaticamente a mensagem de confirmação. Para isso, lançamos 345 mil conjuntos de dados que consistem em modificações de código e mensagens de confirmação em seis linguagens de programação (Python, PHP, Go, Java, JavaScript e Ruby). Semelhante ao modelo de tradução automática neural (NMT), usando nosso conjunto de dados, alimentamos a modificação do código na entrada do codificador e a mensagem de confirmação na entrada do decodificador e medimos o resultado da mensagem de confirmação gerada com BLEU-4. Além disso, propomos os dois métodos de treinamento a seguir para melhorar o resultado da geração da mensagem de confirmação: (1) Um método de pré-processamento da entrada para alimentar a modificação do código na entrada do codificador. (2) Um método que usa um peso inicial adequado ao domínio do código para reduzir a lacuna na representação contextual entre linguagem de programação (PL) e linguagem natural (NL).', 'zh': '提交者,总结自然语言中源代码改易之文档。 消息明源代码改,增开发人员协和。 是以我们的事务是开发一个自己写入提交消息的模样。 为此发345K数集,其六编程语言(PythonPHP,Go,JavaJavaScriptRuby)代码改通消息。 与神经机器翻译(NMT)模形相类,用我数集,改代码给编码器输,并给解码器,用BLEU-4量生。 又条上二训练方法以成消息:(1)预处理输以代码改给编码器输之法。 (2) 一法,用适代码域初重以缩小编程语言 (PL) 与自然语言 (NL) 上下文相去也。', 'es': 'El mensaje de confirmación es un documento que resume los cambios en el código fuente en lenguaje natural. Un buen mensaje de confirmación muestra claramente los cambios en el código fuente, por lo que mejora la colaboración entre los desarrolladores. Por lo tanto, nuestro trabajo consiste en desarrollar un modelo que escriba automáticamente el mensaje de confirmación. Con este fin, publicamos 345K conjuntos de datos que consisten en mensajes de modificación y confirmación de código en seis lenguajes de programación (Python, PHP, Go, Java, JavaScript y Ruby). De manera similar al modelo de traducción automática neuronal (NMT), con nuestro conjunto de datos, alimentamos la modificación del código a la entrada del codificador y el mensaje de confirmación a la entrada del decodificador y medimos el resultado del mensaje de confirmación generado con BLEU-4. Además, proponemos los siguientes dos métodos de entrenamiento para mejorar el resultado de generar el mensaje de confirmación: (1) Un método de preprocesamiento de la entrada para alimentar la modificación del código a la entrada del codificador. (2) Un método que utiliza un peso inicial adecuado para el dominio del código para reducir la brecha en el contexto representación entre lenguaje de programación (PL) y lenguaje natural (NL).', 'fr': "Le message de validation est un document qui résume les modifications apportées au code source en langage naturel. Un bon message de validation indique clairement les modifications apportées au code source, ce qui améliore la collaboration entre les développeurs. Par conséquent, notre travail consiste à développer un modèle qui écrit automatiquement le message de validation. À cette fin, nous publions 345 000 ensembles de données comprenant des modifications de code et des messages de validation dans six langages de programmation (Python, PHP, Go, Java, JavaScript et Ruby). Comme pour le modèle de traduction automatique neuronale (NMT), à l'aide de notre ensemble de données, nous alimentons la modification du code à l'entrée du codeur et le message de validation à l'entrée du décodeur et mesurons le résultat du message de validation généré avec BLEU-4. Nous proposons également les deux méthodes d'apprentissage suivantes pour améliorer le résultat de la génération du message de validation\xa0: (1) Une méthode de prétraitement de l'entrée pour alimenter la modification de code à l'entrée de l'encodeur. (2) Une méthode qui utilise un poids initial adapté au domaine de code pour réduire l'écart dans le contexte représentation entre langage de programmation (PL) et langage naturel (NL).", 'hi': 'कमिट संदेश एक दस्तावेज़ है जो प्राकृतिक भाषा में स्रोत कोड परिवर्तनों को सारांशित करता है। एक अच्छा कमिट संदेश स्पष्ट रूप से स्रोत कोड परिवर्तन दिखाता है, इसलिए यह डेवलपर्स के बीच सहयोग को बढ़ाता है। इसलिए, हमारा काम एक मॉडल विकसित करना है जो स्वचालित रूप से कमिट संदेश लिखता है। इस अंत में, हम कोड संशोधन से मिलकर 345K डेटासेट जारी करते हैं और छह प्रोग्रामिंग भाषाओं (पायथन, PHP, Go, जावा, जावास्क्रिप्ट और रूबी) में संदेश ों को प्रतिबद्ध करते हैं। तंत्रिका मशीन अनुवाद (NMT) मॉडल के समान, हमारे डेटासेट का उपयोग करके, हम कोड संशोधन को एन्कोडर इनपुट और डिकोडर इनपुट के लिए कमिट संदेश खिलाते हैं और BLEU-4 के साथ उत्पन्न कमिट संदेश के परिणाम को मापते हैं। इसके अलावा, हम कमिट संदेश उत्पन्न करने के परिणाम को बेहतर बनाने के लिए निम्नलिखित दो प्रशिक्षण विधियों का प्रस्ताव करते हैं: (1) एन्कोडर इनपुट को कोड संशोधन को खिलाने के लिए इनपुट को प्रीप्रोसेस करने की एक विधि। (2) एक विधि जो प्रोग्रामिंग भाषा (पीएल) और प्राकृतिक भाषा (एनएल) के बीच प्रासंगिक प्रतिनिधित्व में अंतर को कम करने के लिए कोड डोमेन के लिए उपयुक्त प्रारंभिक वजन का उपयोग करती है।', 'ru': 'Commit message - это документ, в котором обобщаются изменения исходного кода на естественном языке. Хорошее сообщение о фиксации четко показывает изменения в исходном коде, поэтому это улучшает сотрудничество между разработчиками. Поэтому наша работа заключается в разработке модели, которая автоматически записывает сообщение Commit. Для этого мы выпускаем 345K датасетов, состоящих из модификации кода и фиксирования сообщений на шести языках программирования (Python, PHP, Go, Java, JavaScript, Ruby). Подобно модели нейронного машинного перевода (NMT), используя наш набор данных, мы подаем модификацию кода на вход кодера и сообщение фиксации на вход декодера и измеряем результат сгенерированного сообщения фиксации с помощью BLEU-4. Также мы предлагаем следующие два метода обучения для улучшения результата генерации сообщения фиксации: (1) метод предварительной обработки входного сигнала для подачи модификации кода на вход кодировщика. (2) метод, который использует начальный вес, подходящий для области кода, чтобы уменьшить разрыв в контекстуальном представлении между языком программирования (PL) и естественным языком (NL).', 'ja': 'コミットメッセージは、自然言語のソースコードの変更を要約した文書です。 優れたコミットメッセージは、ソースコードの変更を明確に示しているため、開発者間のコラボレーションを強化します。 したがって、コミットメッセージを自動的に書き込むモデルの開発に取り組んでいます。 そのために、コードの変更とコミットメッセージからなる345 Kデータセットを6つのプログラミング言語（ Python、PHP、Go、Java、JavaScript、Ruby ）でリリースします。 ニューラルマシン変換（ ＮＭＴ ）モデルと同様に、データセットを使用して、コード修正をエンコーダ入力にフィードし、コミットメッセージをデコーダ入力にフィードし、生成されたコミットメッセージの結果をＢＬＥＵ － ４で測定する。 また、コミットメッセージの生成結果を改善するために、次の2つの訓練方法を提案します。（ 1 ）コード修正をエンコーダ入力にフィードするために入力を前処理する方法。（ 2 ）プログラミング言語（ PL ）と自然言語（ NL ）の文脈表現のギャップを減らすために、コードドメインに適した初期重みを使用する方法。', 'ga': 'Is doiciméad é Commit message a dhéanann achoimre ar athruithe ar an gcód foinse i dteanga nádúrtha. Léiríonn teachtaireacht tiomantas maith go soiléir na hathruithe ar an gcód foinseach, mar sin cuireann sé seo le comhoibriú idir forbróirí. Mar sin, is é ár gcuid oibre múnla a fhorbairt a scríobhann an teachtaireacht tiomantais go huathoibríoch. Chuige sin, scaoilimid tacair sonraí 345K ina bhfuil modhnú cód agus tiomaimid teachtaireachtaí i sé theanga ríomhchlárúcháin (Python, PHP, Go, Java, JavaScript, agus Ruby). Cosúil leis an tsamhail néar-aistriúcháin meaisín (NMT), ag baint úsáide as ár tacar sonraí, cuirimid an modhnú cód le hionchur an ionchódóra agus an teachtaireacht tiomantais chuig an ionchur díchódóra agus tomhaisimid toradh na teachtaireachta gealltanais a ghintear le BLEU-4. Chomh maith leis sin, molaimid an dá mhodh oiliúna seo a leanas chun feabhas a chur ar thoradh giniúna na teachtaireachta tiomanta: (1) Modh chun an t-ionchur a réamhphróiseáil chun an modhnú cód a bheathú chuig an ionchur ionchódóra. (2) Modh a úsáideann meáchan tosaigh atá oiriúnach d’fhearann an chóid chun an bhearna san léiriú comhthéacsúil idir teanga ríomhchlárúcháin (PL) agus teanga nádúrtha (NL) a laghdú.', 'el': 'Το μήνυμα υποβολής είναι ένα έγγραφο που συνοψίζει τις αλλαγές πηγαίου κώδικα στη φυσική γλώσσα. Ένα καλό μήνυμα υποβολής δείχνει σαφώς τις αλλαγές του πηγαίου κώδικα, έτσι αυτό ενισχύει τη συνεργασία μεταξύ των προγραμματιστών. Ως εκ τούτου, η δουλειά μας είναι να αναπτύξουμε ένα μοντέλο που γράφει αυτόματα το μήνυμα υποβολής. Για το σκοπό αυτό, απελευθερώνουμε σύνολα δεδομένων 345Κ που αποτελούνται από τροποποίηση κώδικα και μηνύματα υποβολής σε έξι γλώσσες προγραμματισμού (Python, PHP, Go, Java, JavaScript και Ruby). Παρόμοια με το μοντέλο νευρωνικής μηχανικής μετάφρασης (NMT), χρησιμοποιώντας το σύνολο δεδομένων μας, τροφοδοτούμε την τροποποίηση κώδικα στην είσοδο κωδικοποιητή και το μήνυμα υποβολής στην είσοδο αποκωδικοποιητή και μετράμε το αποτέλεσμα του παραγόμενου μηνύματος υποβολής με BLEU-4. Επίσης, προτείνουμε τις ακόλουθες δύο μεθόδους εκπαίδευσης για τη βελτίωση του αποτελέσματος της δημιουργίας του μηνύματος υποβολής: (1) Μια μέθοδος προεπεξεργασίας της εισόδου για να τροφοδοτήσει την τροποποίηση κώδικα στην είσοδο κωδικοποιητή. (2) Μέθοδος που χρησιμοποιεί αρχικό βάρος κατάλληλο για τον τομέα κώδικα για να μειώσει το χάσμα στην αναπαράσταση του περιβάλλοντος μεταξύ γλώσσας προγραμματισμού (PL) και φυσικής γλώσσας (NL).', 'hu': 'A commit üzenet egy olyan dokumentum, amely természetes nyelven összefoglalja a forráskód változásait. Egy jó commit üzenet egyértelműen megmutatja a forráskód változásait, így ez fokozza a fejlesztők közötti együttműködést. Ezért munkánk egy olyan modell kidolgozása, amely automatikusan írja a commit üzenetet. Ebből a célból 345K adatkészletet bocsátunk ki, amely kódmódosításból és üzenetekből áll hat programozási nyelven (Python, PHP, Go, Java, JavaScript és Ruby). A neurális gépi fordítás (NMT) modellhez hasonlóan adatkészletünk segítségével a kódmódosítást a kódoló bemenetére és a commit üzenetet a dekódoló bemenetére továbbítjuk, és a generált commit üzenet eredményét a BLEU-4 segítségével mérjük. Továbbá a következő két oktatási módszert javasoljuk a commit üzenet létrehozásának eredményének javítására: (1) A bemenet előfeldolgozásának módszere, hogy a kód módosítását a kódoló bemenet táplálja. (2) Egy olyan módszer, amely a programozási nyelv (PL) és a természetes nyelv (NL) közötti kontextuális reprezentációs szakadék csökkentésére a kódtartománynak megfelelő kezdeti súlyt használ.', 'ka': 'Commit შეტყობინება არის დოკუმენტი, რომელიც სახელსაწყოთა ენის შეცვლების შეცვლების შესაბამისათვის. კარგი შეტყობინებების შეტყობინება წარმოადგილად ჩვენებს წიგნის კოდის ცვლილება, ამიტომ ეს განვითარების შორის მუშაობა. ამიტომ, ჩვენი სამუშაო არის მოდელის განვითარება, რომელიც ავტომატურად დაწერს შეტყობინება. ამ შემთხვევაში, 345K მონაცემების კოდის რედაქტირების შესახებ და 6 პროგრამის ენაში შეტყობინება (Python, PHP, Go, Java, JavaScript, და Ruby). ჩვენი მონაცემების კოდენტის შეცვლის მოდულისთვის, როგორც ჩვენი მონაცემების შეცვლის გამოყენება, ჩვენ კოდენტის შეცვლის შეცვლის კოდენტის შეცვლისთვის და შეცვლის შეცვლისთვის დეკოდენტის შეცვლისთვის და შექ ჩვენ შეგიძლიათ შემდეგი ორი განაკეთებული მეტი, რომელიც კოდირების შეცვლის შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი: (2) პროგრამის ენის (PL) და ნახვა ენის (NL) შორის განსხვავებაში, რომელიც კოდენსტური დემომინის მისამართლად საჭირო სიმართლის გამოყენება.', 'it': "Commit message è un documento che riassume le modifiche del codice sorgente in linguaggio naturale. Un buon messaggio di commit mostra chiaramente le modifiche del codice sorgente, in modo da migliorare la collaborazione tra sviluppatori. Pertanto, il nostro lavoro è quello di sviluppare un modello che scrive automaticamente il messaggio di commit. A tal fine, rilasciamo 345K dataset costituiti da modifiche del codice e messaggi di commit in sei linguaggi di programmazione (Python, PHP, Go, Java, JavaScript e Ruby). Simile al modello NMT (neural machine translation), utilizzando il nostro dataset, inseriamo la modifica del codice all'ingresso dell'encoder e il messaggio di commit all'ingresso del decoder e misuriamo il risultato del messaggio di commit generato con BLEU-4. Inoltre, proponiamo i seguenti due metodi di formazione per migliorare il risultato della generazione del messaggio di commit: (1) Un metodo di preelaborazione dell'input per alimentare la modifica del codice all'input dell'encoder. (2) Un metodo che utilizza un peso iniziale adatto al dominio di codice per ridurre il divario nella rappresentazione contestuale tra linguaggio di programmazione (PL) e linguaggio naturale (NL).", 'kk': 'Хатты жіберу - табиғи тілде көзгертілген құжат. Жақсы жұмыс хабарламасы көзгертілген код өзгерістерін көрсетеді, сондықтан бұл жасаушылар арасындағы жұмыс істеуді көтереді. Сондықтан, біздің жұмысымыз - автоматты түрде жұмыс хабарламасын жазу үлгісін жасау. Бұл үшін 345K деректер қорларын алты бағдарламалар тілдерінде (Python, PHP, Go, Java, JavaScript және Ruby) кодты өзгерту және хаттарды жасап береміз. Деректер жиынымыз қолданатын невралдық компьютердің аудармасының (NMT) моделіне сияқты, кодты кодтардың келтіріміне өзгерту және декодтардың келтіріміне көмектесу және BLEU- 4 дегенмен жасалған комитет хабарының нәти Сонымен қатар, біз келесі екі оқыту әдістерін жұмыс істеудің нәтижесін жасау үшін келесі екі оқыту әдістерін таңдаймыз: (1) Кодты өзгерту әдістерін кодтардың келтірілген енгіз (2) Программа тілі (PL) мен табиғи тілі (NL) арасындағы тәртіпсіздік кеңейту үшін код доменіне қолданылатын бастапқы жиілігін қолданатын әдіс.', 'lt': 'Perduoti pranešimas yra dokumentas, kuriame apibendrinami šaltinio kodo pokyčiai natūralioje kalboje. Geras įsipareigojimo pranešimas aiškiai rodo šaltinio kodo pokyčius, taigi tai sustiprina vystytojų bendradarbiavimą. Todėl mūsų darbas yra sukurti model į, kuris automatiškai rašytų įsipareigojimo pranešimą. Šiuo tikslu paskelbiame 345K duomenų rinkinius, sudarytus iš kodų keitimo ir perduodame pranešimus šešiomis programavimo kalbomis (Python, PHP, Go, Java, JavaScript ir Ruby). Panašus į neurologinio mašinos vertimo (NMT) model į, naudojant mūsų duomenų rinkinį, mes perduodame kodo pakeitimą kodo įvedimui ir perduodame pranešimą dekoderio įvedimui ir išmatuojame sukaupto perdavimo pranešimo rezultatus naudojant BLEU-4. Be to, siūlome šiuos du mokymo metodus, kuriais siekiama pagerinti įsipareigojimo pranešimo sukūrimo rezultatus: 1) metodą, kuriuo iš anksto apdorojama įranga, kad kodo keitimas būtų naudojamas koduotojo įrangai. (2) Metodas, kuriuo naudojamas pradinis svoris, tinkamas kodų srities atžvilgiu, siekiant sumažinti atotrūkį tarp programavimo kalbos (PL) ir natūralios kalbos (NL) kontekstinio atstovavimo.', 'mk': 'Пораката за пренесување е документ кој ги сумира промените на изворниот код на природниот јазик. A good commit message clearly shows the source code changes, so this enhances collaboration between developers.  Затоа, нашата работа е да развиеме модел кој автоматски ја пишува пораката. За оваа цел, објавуваме 345K податоци составени од модификација на кодот и испраќаме пораки на шест програмни јазици (Python, PHP, Go, Java, JavaScript и Ruby). Слична на моделот на нервен машински превод (NMT), користејќи го нашиот податок, ја даваме модификацијата на кодот на внесувањето на кодерот и ја пренесуваме пораката на внесувањето на декодерот и го мериме резултатот на генерираната порака со BLEU-4. Исто така, ги предложуваме следните два методи на обука за подобрување на резултатот од генерирањето на пораката за команда: (1) Метод за препроцесирање на влогот за внесување на модификацијата на кодот на влогот на кодерот. (2) Метод кој користи иницијална тежина соодветна за кодовиот домен за намалување на празнината во контекстуалното претставување помеѓу јазикот на програмирање (PL) и природниот јазик (NL).', 'ml': 'സ്വാഭാവികമായ ഭാഷയില്\u200d ഉറവിട കോഡ് മാറ്റുന്നതിനെ ചുരുക്കിക്കൊണ്ടുള്ള ഒരു രേഖയാണ് കമ്മിറ് A good commit message clearly shows the source code changes, so this enhances collaboration between developers.  അതുകൊണ്ട്, നമ്മുടെ ജോലി ഒരു മോഡല്\u200d നിര്\u200dമ്മിക്കാനാണ് നമ്മുടെ പ്രവര്\u200dത്തിക്കുന്നത്, അത് സ്വയം പ്രതികര ഈ അവസാനത്തിനുള്ളില്\u200d, നമ്മള്\u200d കോഡ് മാറ്റം വരുത്തുന്നതിനുള്ള 345K ഡാറ്റാസറ്റേറ്റുകള്\u200d വിടുന്നു. ആറു പ്രോഗ്രാമിങ്ങ് ഭാഷകളില്\u200d സന്ദേശങ നമ്മുടെ ഡാറ്റാസെറ്റ് ഉപയോഗിച്ച് ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ (NMT) മോഡലിന് അതുപോലെയാണ് ഞങ്ങള്\u200d കോഡോര്\u200d ഇന്\u200dപുട്ടിലേക്ക് കോഡ് മാറ്റം നല്\u200dകുന്നതും, ഡികോഡെര്\u200d  കോഡ് മാറ്റം വരുത്തുന്നതിന്റെ ഫലം മെച്ചപ്പെടുത്താനുള്ള രണ്ട് ട്രെയിനിങ്ങളുടെ പിന്നിലുള്ള രണ്ട് ട്രെയിനിങ്ങളുടെ രീതികളും ഞങ (2) പ്രോഗ്രാംമിങ്ങ് ഭാഷയും സ്വാഭാവികമായ ഭാഷയും തമ്മിലുള്ള പ്രതിനിധിയിലുള്ള പ്രതിനിധിയിലുള്ള വ്യത്യാസം കുറവ് ചെയ്യാന്\u200d ആദ്യമ', 'mn': 'Commit message is a document that summarizes source code changes in natural language. Сайн хамтын санаа нь эх үүсвэрийн кодын өөрчлөлтийг тодорхой харуулж байна. Иймээс үүнийг хөгжүүлэгчдийн хамтын ажиллагааг нэмэгдүүлнэ. Тиймээс бидний ажил бол автоматаар загварыг бичдэг загвар хөгжүүлэх юм. Энэ төгсгөлд бид 345K өгөгдлийн сангуудыг 6 програмчлалын хэл дээр кодын өөрчлөлт болон хувилбар бүрдүүлдэг (Python, PHP, Go, Java, JavaScript, Ruby). Ньюрал машины хөрөнгө (NMT) загвартай адилхан, өгөгдлийн санг ашиглаж, бид кодын орлуулалтын өөрчлөлтийг кодлогчийн орлуулалтын хувьд хангаж, кодлогчийн орлуулалтын хувьд харуулж, үүсгэсэн commit message-ын үр дүнг BLEU Мөн бид эдгээр хоёр дасгал сургалтын аргыг шинэчлэх боломжтой аргыг санал болгож байна: (1) Кодлогийн өөрчлөлтийг кодлогч орлуулах аргыг дахин ажиллах арга юм. (2) Програмчлалын хэл (PL) болон байгалийн хэл (NL) хоорондын орчин үеийн ялгааг багасгах зорилготой кодын домгийн эхний жингийг ашигладаг арга.', 'pl': 'Komunikat Commit to dokument, który podsumowuje zmiany kodu źródłowego w języku naturalnym. Dobra wiadomość o commitach wyraźnie pokazuje zmiany kodu źródłowego, co zwiększa współpracę między programistami. Dlatego naszą pracą jest opracowanie modelu, który automatycznie pisze komunikat commit. W tym celu udostępniamy zestawy danych 345K składające się z modyfikacji kodu i komunikatów commitujących w sześciu językach programowania (Python, PHP, Go, Java, JavaScript i Ruby). Podobnie jak w modelu neuronowego tłumaczenia maszynowego (NMT), wykorzystując nasz zestaw danych, przekazujemy modyfikację kodu do wejścia kodera i komunikat commitu do wejścia dekodera i mierzymy wynik wygenerowanego komunikatu commitu za pomocą BLEU-4. Proponujemy również dwie następujące metody szkoleniowe w celu poprawy wyniku generowania komunikatu commit: (1) Metodę wstępnego przetwarzania wejścia w celu podania modyfikacji kodu do wejścia kodera. (2) Metoda wykorzystująca wagę początkową odpowiednią dla domeny kodu w celu zmniejszenia luki w reprezentacji kontekstowej między językiem programowania (PL) a językiem naturalnym (NL).', 'ms': 'Commit message is a document that summarizes source code changes in natural language.  Mesej commit yang baik menunjukkan dengan jelas perubahan kod sumber, jadi ini meningkatkan kerjasama antara pembangun. Oleh itu, kerja kita adalah untuk mengembangkan model yang menulis mesej commit secara automatik. Untuk tujuan ini, kami melepaskan set data 345K yang mengandungi pengubahsuaian kod dan Commit mesej dalam enam bahasa pemrograman (Python, PHP, Go, Java, JavaScript, dan Ruby). Sama seperti model terjemahan mesin saraf (NMT), menggunakan set data kami, kami memberi makan pengubahsuaian kod kepada input pengekod dan mengirim mesej ke input pengekod dan mengukur keputusan mesej mengirim yang dijana dengan BLEU-4. Juga, kami cadangkan dua kaedah latihan berikut untuk meningkatkan keputusan menghasilkan mesej komitmen: (1) Kaedah untuk memproses input untuk mengisi pengubahsuaian kod ke input pengekod. (2) Kaedah yang menggunakan berat awal yang sesuai untuk domain kod untuk mengurangi ruang dalam perwakilan kontekstual antara bahasa pemrograman (PL) dan bahasa semulajadi (NL).', 'no': 'Kommando er eit dokument som samanserer kjeldekodendringar i naturspråk. Eit godt kommunikasjonsmelding viser klart kjeldekoden endringar, så dette forbetrar samarbeid mellom utviklarane. Derfor er arbeidet vårt å utvikla eit modell som automatisk skriv kommunikasjonsmeldinga. Til denne slutten vert vi løyst 345K datasett som inneheld kodendringar og kommuniserer meldingar i seks programspråk (Python, PHP, Go, Java, JavaScript og Ruby). Lik som modellen for neuralmaskinsomsetjing (NMT), brukar datasettet vårt, kjem vi kodendringen til koderinga og kommunikasjonsmeldinga til dekoderinndata og målar resultatet av den genererte kommunikasjonsmeldinga med BLEU-4. I tillegg foreslår vi desse to øvingsmetodane for å forbetra resultatet av oppretting av kommunikasjonsmeldinga: (1) Eit metode for å forhandtere inndata for å køyra kodendringane til kodeininga. (2) Eit metode som brukar ein startvekt som passar for koddomenet for å redusera mellomrommet i kontekstalt representasjon mellom programmeringspråk (PL) og naturspråk (NL).', 'mt': 'Il-messaġġ ta’ impenn huwa dokument li jagħti sommarju tal-bidliet fil-kodiċi tas-sors fil-lingwa naturali. Messaġġ ta’ impenn tajjeb juri b’mod ċar il-bidliet fil-kodiċi tas-sors, għalhekk dan itejjeb il-kollaborazzjoni bejn l-iżviluppaturi. Għalhekk, ix-xogħol tagħna huwa li niżviluppaw mudell li awtomatikament jikteb il-messaġġ ta’ impenn. Għal dan il-għan, nirrilaxxaw settijiet ta’ dejta 345K li jikkonsistu f’modifika tal-kodiċi u nimpenjaw messaġġi f’sitt lingwi ta’ programmazzjoni (Python, PHP, Go, Java, JavaScript, u Ruby). Similar to the neural machine translation (NMT) model, using our dataset, we feed the code modification to the encoder input and the commit message to the decoder input and measure the result of the generated commit message with BLEU-4.  Barra minn hekk, qed nipproponu ż-żewġ metodi ta’ taħriġ li ġejjin biex jittejjeb ir-riżultat tal-ġenerazzjoni tal-messaġġ ta’ impenn: (1) Metodu ta’ pproċessar minn qabel tal-input biex tiġi alimentata l-modifika tal-kodiċi għall-input tal-kodifikatur. (2) Metodu li juża piż inizjali adattat għad-dominju tal-kodiċi biex jitnaqqas id-distakk fir-rappreżentanza kuntestwali bejn il-lingwa tal-ipprogrammar (PL) u l-lingwa naturali (NL).', 'ro': 'Mesajul Commit este un document care rezumă modificările codului sursă în limbaj natural. Un mesaj bun de comitere arată clar modificările codului sursă, astfel încât acest lucru îmbunătățește colaborarea între dezvoltatori. Prin urmare, munca noastră este de a dezvolta un model care scrie automat mesajul de comitere. În acest scop, lansăm 345K seturi de date constând în modificarea codului și mesaje de comitere în șase limbaje de programare (Python, PHP, Go, Java, JavaScript și Ruby). Similar modelului de traducere automată neurală (NMT), folosind setul nostru de date, introducem modificarea codului la intrarea codificatorului și mesajul de comitere la intrarea decodorului și măsurăm rezultatul mesajului de comitere generat cu BLEU-4. De asemenea, propunem următoarele două metode de instruire pentru a îmbunătăți rezultatul generarii mesajului de comitere: (1) O metodă de pre-procesare a intrării pentru a alimenta modificarea codului la intrarea codificatorului. (2) O metodă care utilizează o greutate inițială adecvată domeniului de cod pentru a reduce decalajul în reprezentarea contextuală dintre limbajul de programare (PL) și limbajul natural (NL).', 'so': 'Wargelinta heshiiska waa dukumenti ku qoran qoraalka kooxda noocyada ah oo ku beddelaya luuqada asalka ah. Hadal wanaagsan oo sameynta ayaa bayaan u muujiya isbeddelka kooxda, sidaa darteed taasu waxay kordhisaa iskaashiis u dhexeeya kuwa wax dhisaya. Sidaa darteed shaqadayadu waa inuu horumariyo model oo si automatic ah u qoro warqada sameynta. Taas darteed waxaan u bixinaynaa 345K macluumaadyo oo ku jira beddelinta codsiga iyo soo dirnaa warqado ku qoran lix luuqadood (Python, PHP, Go, Java, JavaScript iyo Ruby). Tusaale u eg tarjumaadka maskinenta neural (NMT), waxaynu quudinnaa beddelinta codsiga input iyo macluumaadka ku sameynaya input-koodkarada iyo qiyaaseynaa dhamaadka soo saaray buuxinta budgeyska BLEU-4. Sidoo kale waxaan horumarinaynaa laba qaabab waxbarasho oo soo socda si uu u hagaajiyo dhamaadka soo saarashada warqada sameynta: (1) Midabka ka hor baaraandegista input in lagu quudiyo beddelinta codsiga laguu sameeyo input. (2) Midabka ku isticmaalaya miisaan asalka ah oo ugu haboon gudaha codsiga inuu hoos u dhigo kala duwanaanshaha ku qoran luqada programka (PL) iyo luqada asalka ah (NL).', 'si': 'Commit පණිවිඩය තමයි ප්\u200dරාකෘතික භාෂාවේ මූලික කෝඩ වෙනස් සම්පූර්ණය කරපු දස්ත. හොඳ කම්පිට් පණිවිඩයක් පැහැදිලියට ප්\u200dරදේශ කෝඩ වෙනස් වෙන්න පෙන්වනවා, ඉතින් මේක විකාසකර ඉතින්, අපේ වැඩේ තමයි ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරමාණයක් ලියනවා. මේ අවසානයෙන්, අපි 345K දත්ත සෙට් ප්\u200dරකාශ කරනවා කෝඩ් වෙනස් කරන්න සහ පණිවිඩයක් පණිවිඩය හතර භාෂාවයෙන් (Python, PHP, Go, Java, JavaScript,  අපේ දත්ත සැට භාවිතා කරන්න, අපි කෝඩ් වෙනස් වෙනුවෙන් කෝඩ් වෙනස් වෙනුවෙන් කෝඩ් වෙනස් වෙනුවෙන් කෝඩ් වෙනස් වෙනුවෙන් කෝඩ් වෙනුවෙන් සහ කෝ ඒවගේම, අපි පස්සෙන් ප්\u200dරශ්නය දෙකක් ප්\u200dරශ්නය කරන්න පුළුවන් විදිහට කම්පිට් පණිවිඩය නිර්මාණය කරන්න: (1) කෝඩ් පණිවිඩය සඳහ (2) කෝඩ් ඩෝමින් වලට ප්\u200dරමාණය භාෂාවක් සහ ස්වභාවික භාෂාවක් අතර ප්\u200dරමාණය කරන්න ප්\u200dරමාණය භාෂාවක් සඳහා ප්\u200dරමාණය වි', 'ta': 'பொதுவான செய்தி என்பது மூல குறியீடு மாற்றங்களை இயல்பான மொழியில் சுருக்கும் ஆவணம். நல்ல செய்தி Therefore, our work is to develop a model that automatically writes the commit message.  இந்த முடிவிற்கு, நாம் குறிமுறைமாற்றம் மற்றும் ஆறு நிரல் மொழிகளில் செய்திகளை சேர்க்கும் 345K தகவல் அமைப்புகளை விடுவோம் (பைதான், PHP, Go புதிய இயந்திர மொழிபெயர்ப்பு (NMT) மாதிரி, எங்கள் தரவு அமைப்பை பயன்படுத்தி, நாம் குறியீட்டு உள்ளீட்டிற்கு குறியீட்டு மாற்றியை வழங்குகிறோம் மற்றும் க மேலும், நாம் பின்வரும் இரண்டு பயிற்சி முறைமைகளை மேம்படுத்த முடிவு செய்தி உருவாக்குவதற்கு பரிந்துரைக்கிறோம்: (1) குறியீட்டு மா (2) நிரல் மொழி (PL) மற்றும் இயல்பான மொழி( NL) இடையே உள்ள தற்போதைய குறிப்பிட்ட இடைவெளியை குறைக்க ஒரு துவக்க எடை பொருத்தமான முறையில', 'sr': 'Poslanja poruka je dokument koji sažeta izmjene izvornog koda na prirodnom jeziku. Dobra poruka za obavezu jasno pokazuje promjene izvornog koda, pa to povećava saradnju između programera. Stoga, naš posao je da razvijemo model koji automatski piše poruku o obavezi. Do ovog cilja, oslobađamo 345K podataka koje se sastoje od modifikacije koda i prenose poruke na šest programiranih jezika (Python, PHP, Go, Java, JavaScript i Ruby). Slični modelu neuronskog prevoda mašine (NMT), koristeći našu kompetu podataka, hranimo modifikaciju koda kod kodera i posvećujemo poruku ulazu dekodera i mjerimo rezultat proizvedene poruke za obvezivanje BLEU-4. Takođe, predlažemo sljedeće dve metode obuke kako bi poboljšali rezultat stvaranja poruke obveznika: (1) metoda preobrađivanja ulaza kako bi nahranila modifikaciju koda za ulaz kodera. (2) Metod koji koristi početnu težinu odgovarajuću za domenu koda da smanji prazninu u kontekstualnom predstavljanju između jezika programiranja (PL) i prirodnog jezika (NL).', 'sv': 'Commit meddelande är ett dokument som sammanfattar källkodsändringar i naturligt språk. Ett bra commit-meddelande visar tydligt källkodsändringarna, vilket förbättrar samarbetet mellan utvecklare. Därför är vårt arbete att utveckla en modell som automatiskt skriver commit-meddelandet. För detta ändamål släpper vi 345K dataset bestående av kodmodifiering och commit meddelanden i sex programmeringsspråk (Python, PHP, Go, Java, JavaScript och Ruby). På samma sätt som NMT-modellen (neural machine translation) matar vi med hjälp av vår dataset kodmodifieringen till kodinmatningen och commit-meddelandet till dekodinmatningen och mäter resultatet av det genererade commit-meddelandet med BLEU-4. Vi föreslår också följande två utbildningsmetoder för att förbättra resultatet av att generera commit meddelande: (1) En metod för förbehandling av indata för att mata kodändringen till kodinmatningen. (2) En metod som använder en initial vikt som är lämplig för koddomänen för att minska klyftan i kontextuell representation mellan programmeringsspråk (PL) och naturligt språk (NL).', 'ur': 'Commit message is a document that summarizes source code changes in natural language. ایک اچھی کمیٹ پیغام واضح طور پر سورس کوڈ بدلنے کو دکھاتا ہے، تو یہ ڈولوپٹر کے درمیان collaboration بڑھاتا ہے۔ تو ہمارا کام یہ ہے کہ ایک موڈل ایجاد کریں جو اپنے ساتھ کام پیغام لکھتا ہے۔ اس کے لئے ہم 345K ڈاٹ سٹ کو آزاد کریں جو کوڈ بدلنے کے ساتھ ہے اور چھ پروگرامینگ زبانوں میں پیغام کریں (Python, PHP, Go, Java, JavaScript, اور Ruby). نوئرل ماشین ترجمہ (NMT) موڈل کے مطابق، ہمارے ڈاٹ سٹ کے استعمال سے، ہم کوڈر اینٹ پیغام کے لئے کوڈ بدلنے کی کوڈ بدلنے کی کوڈ پیغام اور دکوڈر اینٹ پیغام کی کمپیٹ پیغام کے مطابق اور BLEU-4 کے ساتھ پیدا کئے ہوئے کم اور ہم نیچے دو تدریس طریقوں کو پیشنهاد کرتے ہیں کہ کمپیٹ پیغام پیدا کرنے کے نتیجہ کو بہتر کریں: (1) کوڈر اپنا پیغام پیدا کرنے کے لئے کوڈ بدلنے کے لئے ایک طریقہ ہے۔ (2) ایک طریقہ جس نے کوڈ ڈومین کے لئے مناسب پیغام وزن کا استعمال کرتا ہے کہ پروگرامینگ زبان (PL) اور طبیعی زبان (NL) کے درمیان تفاوت کم کرے۔', 'uz': 'Izohlar Bu yaxshi harakat xabar manbasi manba kodi oʻzgarishlarini koʻrsatiladi, shunday qilib bu tuzuvchilar orasidagi qoʻllanmalarni oshirish mumkin. Shunday qilib, bizning ishimizni avtomatik avtomatik yozib olish modelini yaratish. Bu yerda, biz kodlash oʻzgarishlari uchun 345K maʼlumotlar tarkibini chiqaramiz va 6 dastur tilida xabarlarni amalga oshamiz (Python, PHP, Go, Java, JavaScript va Ruby). Name Also, we propose the following two training methods to improve the result of generating the commit message: (1) A method of preprocessing the input to feed the code modification to the encoder input.  Name', 'vi': 'Ghi chú là một tài liệu tổng hợp các thay đổi mã nguồn trong ngôn ngữ tự nhiên. Một thông điệp cam kết tốt hiển thị rõ ràng các thay đổi mã nguồn, vì vậy nó tăng cường sự hợp tác giữa các nhà phát triển. Do đó, công việc của chúng ta là phát triển một mô hình viết tự động thông điệp ràng buộc. Chúng tôi phát hành tập tin 345K gồm sự sửa đổi mật mã và ủy thác thông điệp trong sáu ngôn ngữ lập trình (Python, PHP, Go, Java, JavaScript, và Ruby). Giống như hệ thống dịch cỗ máy thần kinh (NMB) dùng bộ dữ liệu của chúng tôi, chúng tôi cung cấp mã hóa bằng cách nhập bộ mã hóa và thông điệp ủy thác cho bộ giải mã và đo kết quả của sứ mạng ủy thác do chính tạo bằng tiếng bíp-4. Chúng tôi cũng đề xuất hai phương pháp huấn luyện theo đây để cải thiện kết quả phát ra thông điệp cam kết: 1) Một phương pháp xử lý nội dung để cung cấp mã hóa cho người nhập mã hóa. (2) Một phương pháp sử dụng trọng lượng đầu tiên phù hợp với miền mật mã để giảm khoảng cách phân biệt ngữ cảnh giữa ngôn ngữ lập trình (lời hứa) và ngôn ngữ tự nhiên (nhu cầu quốc gia).', 'bg': 'Съобщението за изпращане е документ, който обобщава промените в изходния код на естествен език. Доброто съобщение за къмит ясно показва промените в изходния код, така че това подобрява сътрудничеството между разработчиците. Затова нашата работа е да разработим модел, който автоматично записва съобщението за къмит. За тази цел пускаме 345К набори от данни, състоящи се от модификация на кода и изпращане на съобщения на шест езика за програмиране (Питон, PHP, Go, Java, JavaScript и Ruby). Подобно на модела на невронен машинен превод (НМТ), използвайки нашия набор от данни, ние подаваме модификацията на кода към входа на кодера и съобщението за къмит към входа на декодера и измерваме резултата от генерираното съобщение за къмит с Блю-4. Също така предлагаме следните два метода за обучение за подобряване на резултата от генерирането на съобщението за къмит: (1) Метод за предварителна обработка на входа за подаване на модификацията на кода към входа на кодера. (2) Метод, който използва първоначално тегло, подходящо за областта на кода, за да намали разликата в контекстното представяне между езика за програмиране (PL) и естествения език (NL).', 'nl': 'Commit bericht is een document dat broncode wijzigingen in natuurlijke taal samenvat. Een goed commit bericht toont duidelijk de broncode wijzigingen, zodat dit de samenwerking tussen ontwikkelaars verbetert. Daarom is ons werk om een model te ontwikkelen dat automatisch de commit boodschap schrijft. Hiervoor brengen we 345K datasets uit bestaande uit code modificatie en commit berichten in zes programmeertalen (Python, PHP, Go, Java, JavaScript en Ruby). Net als bij het neurale machine translation (NMT) model voeren we met behulp van onze dataset de code modificatie naar de encoder ingang en het commit bericht naar de decoder ingang en meten we het resultaat van het gegenereerde commit bericht met BLEU-4. Ook stellen we de volgende twee trainingsmethoden voor om het resultaat van het genereren van het commit bericht te verbeteren: (1) Een methode om de invoer vooraf te verwerken om de codewijziging aan de encoder ingang te voeren. (2) Een methode die gebruikmaakt van een initieel gewicht dat geschikt is voor het codedomein om de kloof in contextuele representatie tussen programmeertaal (PL) en natuurlijke taal (NL) te verkleinen.', 'da': 'Commit meddelelse er et dokument, der opsummerer kildekodeændringer i naturligt sprog. En god commit-meddelelse viser tydeligt kildekodeændringerne, så det forbedrer samarbejdet mellem udviklere. Derfor er vores arbejde at udvikle en model, der automatisk skriver commit-beskeden. Til dette formål udgiver vi 345K datasæt bestående af kodeændring og commit meddelelser i seks programmeringssprog (Python, PHP, Go, Java, JavaScript og Ruby). Ligesom den neurale maskine oversættelse (NMT) model, ved hjælp af vores datasæt, fodrer vi kode ændring til encoder input og commit meddelelse til dekoder input og måler resultatet af den genererede commit meddelelse med BLEU-4. Vi foreslår også følgende to træningsmetoder for at forbedre resultatet af genereringen af commit-meddelelsen: (1) En metode til forbearbejdning af input til at fodre kodemændringen til encoder input. (2) En metode, der anvender en indledende vægt, der er egnet til koddomænet, til at mindske kløften i kontekstuel repræsentation mellem programmeringssprog (PL) og naturligt sprog (NL).', 'id': 'Pesan Commit adalah dokumen yang mengagumkan perubahan kode sumber dalam bahasa alami. Sebuah pesan Commit yang baik jelas menunjukkan perubahan kode sumber, jadi ini meningkatkan kolaborasi antara pengembang. Therefore, our work is to develop a model that automatically writes the commit message.  Untuk tujuan ini, kami melepaskan set data 345K yang terdiri dari modifikasi kode dan mengirim pesan dalam enam bahasa pemrograman (Python, PHP, Go, Java, JavaScript, dan Ruby). Sama seperti model terjemahan mesin saraf (NMT), menggunakan set data kami, kami memberi makan modifikasi kode ke input pengakod dan mengirim pesan ke input pengakod dan mengukur hasil dari pesan pengakod yang dihasilkan dengan BLEU-4. Juga, kami mengusulkan dua metode latihan berikut untuk meningkatkan hasil dari menghasilkan pesan komitmen: (1) metode untuk memproses input untuk memberi makan modifikasi kode ke input pengekode. (2) Metode yang menggunakan berat awal yang cocok untuk domain kode untuk mengurangi ruang dalam representation kontekstual antara bahasa pemrograman (PL) dan bahasa alam (NL).', 'de': 'Commit-Nachricht ist ein Dokument, das Quellcode-Änderungen in natürlicher Sprache zusammenfasst. Eine gute Commit-Nachricht zeigt deutlich die Änderungen des Quellcodes an, was die Zusammenarbeit zwischen den Entwicklern verbessert. Daher ist es unsere Arbeit, ein Modell zu entwickeln, das automatisch die Commit-Nachricht schreibt. Zu diesem Zweck veröffentlichen wir 345K Datensätze bestehend aus Code Modifikation und Commit Nachrichten in sechs Programmiersprachen (Python, PHP, Go, Java, JavaScript und Ruby). Ähnlich wie beim NMT-Modell speisen wir mit unserem Datensatz die Code-Modifikation an den Encoder-Eingang und die Commit-Nachricht an den Decoder-Eingang und messen das Ergebnis der generierten Commit-Nachricht mit BLEU-4. Außerdem schlagen wir die folgenden zwei Trainingsmethoden vor, um das Ergebnis der Erzeugung der Commit-Nachricht zu verbessern: (1) Eine Methode zur Vorverarbeitung der Eingabe, um die Codeänderung an den Encoder-Eingang zu übertragen. (2) Eine Methode, die ein für die Codedomäne geeignetes Anfangsgewicht verwendet, um die Lücke in der kontextuellen Darstellung zwischen Programmiersprache (PL) und natürlicher Sprache (NL) zu verringern.', 'hr': 'Poslata poruka je dokument koji sažeta izmjene izvornog koda na prirodnom jeziku. Dobra poruka o obavljanju jasno pokazuje promjene izvornog koda, tako da se to povećava suradnja između programera. Stoga, naš rad je razvoj model a koji automatski piše poruku o obavezi. Za taj cilj oslobađamo 345K podataka koji se sastoje od modifikacije koda i prenose poruke na šest programiranih jezika (Python, PHP, Go, Java, JavaScript i Ruby). Slični modelu prevoda neuralnih strojeva (NMT), koristeći našu kompletu podataka, hranimo modifikaciju koda kod kodera i posvećujemo poruku ulazu dekodera i mjerimo rezultat proizvedene poruke s BLEU-4. Također predlažemo sljedeće dvije metode obuke kako bi poboljšali rezultat stvaranja poruke obveznika: (1) metoda preobrađivanja ulaza kako bi nahranila modifikaciju koda u ulaz kodera. (2) Metod koji koristi početnu težinu odgovarajuću za domenu kodova kako bi smanjila prazninu u kontekstualnom predstavljanju između jezika programiranja (PL) i prirodnog jezika (NL).', 'sw': 'Ujumbe wa ujumbe unaoandikwa ni nyaraka ambalo linahitimisha mabadiliko ya kanuni za asili kwa lugha ya asili. Ujumbe mzuri wa kufanya kazi unaonyesha mabadiliko ya kanuni ya chanzo, kwa hiyo hii inaongeza ushirikiano kati ya waandalizi. Kwa hiyo, kazi yetu ni kutengeneza muundo unaoandika kwa manufaa ujumbe huo. Kwa mwisho huu, tunatoa taarifa za takwimu 345K zinazojumuisha mabadiliko ya kodi na kutuma ujumbe katika lugha sita za programu (Python, PHP, Go, Java, JavaScript, na Ruby). Kama ilivyo kwa mtindo wa kutafsiri mashine ya kidini (NMT), kwa kutumia seti yetu ya taarifa, tunaruzuku mabadiliko ya kodi na ujumbe unaoendelea kwenye tarakimu hiyo na kupima matokeo ya ujumbe uliotengenezwa na BLEU-4. Pia, tunapendekeza njia mbili zifuatazo za mafunzo ili kuboresha matokeo ya kutengeneza ujumbe wa kuandaa ujumbe huo: (1) njia ya kabla ya kuchukua input ili kulisha mabadiliko ya kodi kwa ajili ya kuweka ujumbe wa kodi. (2) Utawala unaotumia uzito wa mwanzo unaohitaji kwa ajili ya kupunguza gaidi katika uwakilishi wa kisasa kati ya lugha ya programu (PL) na lugha ya asili (NL).', 'fa': 'پیام ارسال یک سند است که تغییرات کد منبع در زبان طبیعی را جمع می\u200cکند. پیام بسیار خوب به طور واضح تغییرات کد منبع را نشان می دهد، بنابراین این همکاری بین توسعه\u200cکنندگان را افزایش می\u200cدهد. بنابراین، کار ما این است که یک مدل توسعه کنیم که پیام ارتباط را خودکار می نویسه. برای این پایان، ما مجموعه داده\u200cهای 345K را آزاد می\u200cکنیم که از تغییر کد و پیغام\u200cها در شش زبان برنامه\u200cبندی (Python, PHP, Go, Java, JavaScript و Ruby) وجود دارند. شبیه به مدل ترجمه ماشین عصبی (NMT) با استفاده از مجموعه داده\u200cهای ما، ما تغییر کد را به ورودش کودها تغییر می\u200cدهیم و پیام ارتباط به ورودش دکودها تغییر می\u200cدهیم و نتیجه پیام ارتباط تولید شده با BLEU-4 را اندازه می\u200cدهیم همچنین، ما این دو روش آموزش را پیشنهاد می\u200cکنیم تا نتیجه تولید پیام کمیت را بهتر کنیم: (۱) روش پیش پرداخت ورودی برای تغییر کد به ورودی رمز\u200cدهنده را تغییر دهیم. (۲) روش که از وزن اولیه مناسب برای دامنۀ کد استفاده می\u200cکند تا فاصله\u200cای در نمایش موضوع بین زبان برنامه\u200cریزی (PL) و زبان طبیعی (NL) کاهش دهد.', 'ko': '메시지를 제출하는 것은 원본 코드 변경을 자연 언어로 정리한 문서입니다.좋은 제출 메시지가 원본 코드의 변경을 명확하게 보여 주기 때문에 개발자 간의 협력을 강화시켰다.따라서, 우리의 업무는 제출 메시지를 자동으로 기록하는 모델을 개발하는 것이다.이를 위해 우리는 6가지 프로그래밍 언어(Python, PHP, Go, Java, JavaScript, Ruby)로 코드 수정과 메시지 제출을 포함한 345K개의 데이터 집합을 발표했다.신경기계번역(NMT) 모델과 유사하게 우리의 데이터 세트를 사용하여 코드를 인코더 입력에 피드백하고, 제출 메시지를 디코더 입력에 피드백하며, BLEU-4 측정을 사용하여 생성된 제출 메시지의 결과를 생성합니다.그 밖에 우리는 다음과 같은 두 가지 훈련 방법을 제시하여 제출 메시지를 생성하는 결과를 향상시켰다. (1) 입력을 미리 처리하고 코드 수정을 인코더에 피드백한다.(2) 코드 영역에 적합한 초기 권한을 사용하여 프로그래밍 언어(PL)와 자연 언어(NL) 사이의 상하문 차이를 축소하는 방법.', 'tr': 'Maglumat sözbaşy täbiň dilinde kellesi üýtgeden senedir. Gowy komite mesajy kellesiniň üýtgewlerini belli edip görkezýär, şonuň üçin bu östirişçiler arasynda işbirliğini azaltýar. Şonuň üçin biziň işimiz, komite mesajyny otomatik ýazýan bir nusgany bejermek. Bu üçin 345K veri setirlerini 6 programlama dilinde çykarýan we mesajlaryň barlygyny boşadyrys (Python, PHP, Go, Java, JavaScript, we Ruby). Munuň neural maşynyň terjimesine (NMT) nusgasyna görä, veri setegimizi ulanýarys, kodeçi girişinde ködleme üýtgewini we kodeçi girişine komit hat we BLEU-4 bilen üretilen komit mesajynyň netijesini ölçüp berýäris. Munuň üçin biz aşağıdaki iki okuw metodlaryny komit mesajyny bejermek üçin teklip edip teklip edip görýäris: (1) Ködler kodyň girişi üýtgetmek üçin girişi öňden proces etmek üçin bir metody. (2) Programlama dili (PL) we tebigy dili (NL) arasynda gaplary azaltmak üçin köd domynyň başyndaky kilo ulanan bir yöntem.', 'am': 'ምስሉን በሌላ ስም አስቀምጥ መልካም የሥርዓት መልእክት የsource code ለውጦችን ያሳያል፤ ስለዚህ ይህ በአካባቢዎች መካከል ትክክል ይጨምርበታል፡፡ ስለዚህ ሥራችን የሙሉ መልእክትን በራስነት የሚጻፈውን ምሳሌ ለመፍጠር ነው፡፡ ወደዚህ ምክንያት፣ የኮድ ማሻሻያ እና መልዕክቶችን በስድስት ፕሮግራም ቋንቋዎች (Python፣ PHP፣ ሂድ፣ ያva፣ ያvaScript እና ሩby) እናስወግዳለን፡፡ እንደገና በኮድ መሣሪያው ማተርጓም (NMT) ሞዴል፣ ዳራሲ set የተጠቀምን የኮድ ማቀናጃ ማቀናጃ እና የመልእክትን መልእክት ለdecoder input እናስቀምጣለን፡፡ ደግሞም የሆኑት መልዕክት መፍጠርን ለማሻሻል የሚከተሉትን ሁለት ተማሪዎች ዘዴዎች እናሳስባታለን:(1) የሆዶ ሆኗን ለመጠቀም የኮድ ማሻሻሻል ለencoder input ለመጠቀም የሚችል የሆኑን ማቀናጃ ዓይነት ነው፡፡ (2) የፊደል ሚዛን ለኮድ ዶሜን የሚጠቅመው የፊደል ሚዛን በፕሮግራም ቋንቋ (PL) እና ፍጥረት ቋንቋ (NL) መካከለኛ ክፍተቱን ለማጎድል የሚጠቅመው የሆኑን ዓይነት (PL)', 'sq': 'Mesazhi Commit është një dokument që përmbledh ndryshimet e kodit burimor në gjuhën natyrore. Një mesazh i mirë commit tregon qartë ndryshimet e kodit burimor, kështu që kjo përmirëson bashkëpunimin midis zhvilluesve. Pra, puna jonë është të zhvillojmë një model që automatikisht shkruan mesazhin e kryerjes. To this end, we release 345K datasets consisting of code modification and commit messages in six programming languages (Python, PHP, Go, Java, JavaScript, and Ruby).  Të ngjashme me modelin e përkthimit të makinës nervore (NMT), duke përdorur grupin tonë të dhënash, ne ushqejmë modifikimin e kodit në hyrjen e koduesit dhe dërgojmë mesazhin në hyrjen e dekoderit dhe matni rezultatin e mesazhit të gjeneruar të dërgimit me BLEU-4. Gjithashtu, ne propozojmë dy metodat e trajnimit të ardhshëm për të përmirësuar rezultatin e gjenerimit të mesazhit të angazhimit: (1) Një metodë për të përgatitur hyrjen për të ushqyer modifikimin e kodit në hyrjen e koduesit. (2) Një metodë që përdor një peshë fillestare të përshtatshme për domenin e kodit për të reduktuar çarjen në përfaqësimin kontekstual midis gjuhës së programimit (PL) dhe gjuhës natyrore (NL).', 'af': "Verwyder boodskap is 'n dokument wat opsomming bronkode verander in natuurlike taal. 'n Goeie aanvoer boodskap duidelik vertoon die bronkode veranderinge, sodat hierdie verbeter samarbeid tussen ontwikkelaars. Daarom, ons werk is om 'n model te ontwikkel wat outomaties die aansluit boodskap skryf. Na hierdie einde, ons verlos 345K datastelle wat bestaan van kode verandering en opvoer boodskappe in ses programme tales (Python, PHP, Go, Java, JavaScript, en Ruby). Lik soos die neurale masjien vertaling (NMT) model, gebruik ons datastel, voer ons die kode verandering na die enkoder invoer en die opvoer boodskap na die dekoder invoer en maat die resultaat van die genereerde opvoer boodskap met BLEU- 4. Ook, ons voorstel die volgende twee onderwerp metodes om die resultaat van die genereer van die opvoer boodskap te verbeter: (1) ' n metode van voorafverandering van die invoer om die kode verandering na die enkoder invoer te voer. (2) â\x80\x99n metode wat â\x80\x99n aanvanklike gewig gebruik het wat geskik is vir die kode domein om die spasie in contextual verskyning tussen programming taal (PL) en natuurlike taal (NL) te verminder.", 'bn': 'কমিট বার্তা একটি নথি একটি ভাল কাজের বার্তা পরিষ্কারভাবে উৎস কোড পরিবর্তন দেখাচ্ছে, তাই এটি ডেভেলপারদের মধ্যে সহযোগিতা বৃদ্ধ তাই, আমাদের কাজ হচ্ছে একটি মডেল তৈরি করতে যা স্বয়ংক্রিয়ভাবে এই প্রতিষ্ঠান বার্তা লিখেছে। এই পর্যন্ত আমরা কোড পরিবর্তন এবং ছয় প্রোগ্রামিং ভাষায় বার্তা প্রদান করি (পাইথন, পিএইচপি, গো, জাভা, জাভাস্ক্রিপ্ট এবং রুবি) ৩৪৫০০০ ডাটাসেট মুক আমাদের ডাটাসেট ব্যবহার করে নিউরেল মেশিন অনুবাদ (NMT) মডেলের সমতুল্য, আমরা এনকোডার ইনপুটের কোড পরিবর্তন এবং ডিকোডার ইনপুটের ক্ষেত্রে বার্তা পরিমাপ করি এবং বি এছাড়াও, আমরা নিম্নলিখিত দুটি প্রশিক্ষণ পদ্ধতি প্রস্তাব করছি যাতে এই প্রযুক্তি বার্তা তৈরি করার ফলাফল উন্নতি প্রদান করা: (1) এনকোডার ইনপুটের (2) প্রোগ্রামিং ভাষা (পিএল) এবং প্রাকৃতিক ভাষা (এনএল) মধ্যে প্রোগ্রামিং ভাষার মধ্যে প্রতিনিধিত্বের মধ্যে প্রাথমিক ভাষার জন্য', 'bs': 'Poslata poruka je dokument koji sumira izmjene izvornog koda na prirodnom jeziku. Dobra poruka o obavljanju jasno pokazuje promjene izvornog koda, pa to povećava saradnju između programera. Stoga, naš rad je da razvijemo model koji automatski piše poruku o obavezi. Za taj cilj, otpuštamo 345K podataka, sastojeći se od modifikacije koda i prenosimo poruke na šest programiranih jezika (Python, PHP, Go, Java, JavaScript i Ruby). Slični modelu neuronskog prevoda stroja (NMT), koristeći našu kompetu podataka, hranimo modifikaciju koda za ulaz kodera i obvezujemo poruku za ulaz dekodera i mjerimo rezultat proizvedene poruke obveze sa BLEU-4. Također predlažemo sljedeće dvije metode obuke kako bi poboljšali rezultat stvaranja poruke obveznika: (1) metoda preobrađivanja ulaza kako bi nahranila modifikaciju koda za ulaz kodera. (2) Metod koji koristi početnu težinu odgovarajuću za domenu koda da smanji prazninu u kontekstualnom predstavljanju između jezika programiranja (PL) i prirodnog jezika (NL).', 'az': 'İsmarış təbiətli dildə mənbə kodu dəyişikliklərini qeyd edən bir dökümdür. İyi iş ismarışı açıq-aydın mənbə kodu dəyişikliklərini göstərir, böylece bu müvəffəqilər arasında işbirliği artırar. Beləliklə, işimiz, commit mesajını avtomatik yazan bir modeli təhsil etməkdir. Bu səbəbdə 345K veri qurğuları, kodu dəyişdirmək və altı proqramma dilində ismarışları təyin edirik (Python, PHP, Go, Java, JavaScript və Ruby). NMT modeli kimi, verilən qurğumuzu istifadə edərək kodu dəyişikliyini kodlayıcının girişinə və dekoder girişinə bağlı ismarışlarını və yaratdığı commit ismarışı BLEU-4 ilə ölçürək. Ayrıca, biz bu iki təhsil metodlarını kodlama girişinə dəyişdirmək üçün commit mesajını yaratmaq üçün təhsil edirik: (2) Proqramma dili (PL) və təbiətli dili (NL) arasındakı məsafəni azaltmaq üçün Kod domeini üçün uyğun ilk ağırlığı istifadə edən bir metod.', 'hy': 'Commit հաղորդագրությունը մի փաստաթղթի է, որը համառոտագրում է բնական լեզվի աղբյուր կոդի փոփոխությունները: Լավ հաղորդագրություն պարզապես ցույց է տալիս աղբյուր կոդի փոփոխությունները, այսպիսով դա բարելավում է զարգացողների միջև համագործակցությունը: Այսպիսով, մեր աշխատանքն այն է, որ ստեղծենք մոդել, որը ինքնաբերաբար գրում է հաղորդագրությունը: Այս նպատակով մենք հրապարակում ենք 345K տվյալների համակարգեր, որոնք կազմված են կոդի փոփոխության և հաղորդագրություններ ուղարկում վեց ծրագրավորման լեզուներով (Պատոն, PHP, Go, Java, JavaSc և Rub). Նմանատիպ է նյարդային մեքենայի թարգմանման (NMT) մոդելին, օգտագործելով մեր տվյալների համակարգը, մենք կերակրում ենք կոդի փոփոխությունը կոդերի ներմուծի և հաղորդագրությունը կոդերի ներմուծի վրա հաղորդագրությունը և չափում ենք ստեղծված հաղորդագրության արդյունքը՝  Մենք նաև առաջարկում ենք հետևյալ երկու ուսումնասիրության մեթոդը, որպեսզի բարելավենք հաղորդագրության ստեղծման արդյունքը: (1) Ինձ նախագործելու մեթոդը, որպեսզի կոդի փոփոխությունը տեղադրվի կոդերի ինֆորմացիայի մեջ: (2) Մեթոդ, որը օգտագործում է սկզբնական կշիռը, որը համապատասխանում է կոդի տիեզերքի համար, որպեսզի նվազեցվի կոնտեքստային ներկայացման տարբերությունը ծրագրավորման լեզուների (PL) և բնական լեզուների (ՆԼ)', 'cs': 'Zpráva odevzdání je dokument, který shrnuje změny zdrojového kódu v přirozeném jazyce. Dobrá zpráva revize jasně ukazuje změny zdrojového kódu, což zlepšuje spolupráci mezi vývojáři. Naší prácí je proto vyvinout model, který automaticky zapisuje zprávu commitu. Za tímto účelem vydáváme 345K datové sady sestávající z modifikace kódu a revizních zpráv v šesti programovacích jazycích (Python, PHP, Go, Java, JavaScript a Ruby). Podobně jako u modelu neuronového strojového překladu (NMT), pomocí našeho datového setu přivádíme modifikaci kódu do vstupu kodéru a zprávu commitu do vstupu dekodéru a měříme výsledek generované revizní zprávy pomocí BLEU-4. Navrhujeme také následující dvě tréninkové metody pro zlepšení výsledku generování commit zprávy: (1) Metodu předzpracování vstupu tak, aby byla změna kódu naplněna vstupem kodéru. (2) Metoda, která používá počáteční váhu vhodnou pro kódovou doménu ke snížení mezery v kontextové reprezentaci mezi programovacím jazykem (PL) a přirozeným jazykem (NL).', 'ca': "El missatge d'entrega és un document que resume els canvis de codi fonten el llenguatge natural. A good commit message clearly shows the source code changes, so this enhances collaboration between developers.  Per tant, la nostra feina és desenvolupar un model que escriu automàticament el missatge de compromís. Per això, alliberam 345K conjunts de dades que consisteixen en modificar el codi i entreguem missatges en sis llengües de programació (Python, PHP, Go, Java, JavaScript i Ruby). Semellant al model de traducció neural de màquina (NMT), utilitzant el nostre conjunt de dades, alimentam la modificació del codi a la entrada del codificador i enviem el missatge a la entrada del decodificador i mesurem el resultat del missatge d'entrega generat amb BLEU-4. També proposem els següents dos mètodes d'entrenament per millorar el resultat de la generació del missatge de compromís: (1) Un mètode de preprocessió de la entrada per alimentar la modificació del codi a la entrada del codificador. (2) Un mètode que utilitza un pes inicial adequat per al domini de codi per reduir la diferència en la representació contextual entre el llenguatge de programació (PL) i el llenguatge natural (NL).", 'et': 'Kommunikatsioonisõnum on dokument, mis võtab kokku lähtekoodi muutused looduskeeles. Hea sissekandmise teade näitab selgelt lähtekoodi muutusi, nii et see parandab arendajate koostööd. Seetõttu on meie töö välja töötada mudel, mis kirjutab automaatselt sissekande sõnumi. Selleks anname välja 345K andmekogumi, mis koosnevad koodi modifitseerimisest ja edastamisest kuues programmeerimiskeeles (Python, PHP, Go, Java, JavaScript ja Ruby). Sarnaselt neuraalse masintõlke (NMT) mudelile toidame oma andmekogumi abil koodi modifikatsiooni kodeerija sisendisse ja sissekandmise teate dekoodrisisendisse ning mõõdame genereeritud sissekandmise teate tulemust BLEU-4-ga. Lisaks pakume välja järgmised kaks koolitusmeetodit, et parandada sissekandesõnumi genereerimise tulemust: (1) sisendi eeltöötlemise meetod koodi muutmise edastamiseks kodeerija sisendisse. (2) Meetod, mis kasutab koodidomeenile sobivat algkaalu, et vähendada programmeerimiskeele (PL) ja looduskeele (NL) kontekstilises esituses esindatud lõhet.', 'fi': 'Toimitusviesti on asiakirja, jossa esitetään yhteenveto lähdekoodin muutoksista luonnollisella kielellä. Hyvä toimitusviesti näyttää selvästi lähdekoodin muutokset, joten tämä parantaa kehittäjien välistä yhteistyötä. Siksi työmme on kehittää malli, joka kirjoittaa automaattisesti commit-viestin. Tätä varten julkaisemme 345K datajoukkoa, jotka koostuvat koodin muokkauksesta ja toimitusviesteistä kuudella ohjelmointikielellä (Python, PHP, Go, Java, JavaScript ja Ruby). Neuronen konekäännösmallin (NMT) tavoin syötämme datajoukkoamme käyttäen koodinmuodostuksen kooderin syötteeseen ja toimitusviestin dekooderisyötteeseen ja mittaamme luodun toimitusviestin tuloksen BLEU-4:llä. Lisäksi ehdotamme seuraavia kahta harjoitusmenetelmää toimitusviestin tuottamisen tuloksen parantamiseksi: (1) Menetelmä syötteen esikäsittelyyn koodinmuodostuksen syöttämiseksi kooderin syötteeseen. (2) Menetelmä, jossa käytetään kooditoimialueelle sopivaa alkupainoa ohjelmointikielen (PL) ja luonnollisen kielen (NL) kontekstuaalisen esittämisen välisen kuilun pienentämiseksi.', 'jv': 'buddy buddy Yo wis rampung, awak dhéwé iso nggawe model sing otomatik ngetik berkas karo ibutan. Sampeyan iki, kita mbukak 34 5 K dataset sing ngubah perusahaan kode lan akeh berkas ning suxtang langang program Simulate politenessoffpolite"), and when there is a change ("assertivepoliteness (2) A method that use an first pound valid for the source domain to minimate the gap in contextual representation amongst program language (PL) and normal language (NL).', 'sk': 'Sporočilo za objavo je dokument, ki povzema spremembe izvorne kode v naravnem jeziku. Dobro sporočilo pošiljanja jasno prikazuje spremembe izvorne kode, zato to izboljša sodelovanje med razvijalci. Zato je naše delo razviti model, ki samodejno zapiše sporočilo pošiljanja. V ta namen izdajamo 345K naborov podatkov, sestavljenih iz spremembe kode in pošiljanja sporočil v šestih programskih jezikih (Python, PHP, Go, Java, JavaScript in Ruby). Podobno kot model nevronskega strojnega prevajanja (NMT) z uporabo našega nabora podatkov podajamo modifikacijo kode na vhod kodirja in sporočilo pošiljanja na vhod dekodirja ter merimo rezultat ustvarjenega sporočila pošiljanja z BLEU-4. Prav tako predlagamo naslednji dve metodi usposabljanja za izboljšanje rezultata ustvarjanja sporočila pošiljanja: (1) Metoda predobdelave vhoda za podajanje spremembe kode v vhod kodirnika. (2) Metoda, ki uporablja začetno težo, primerno za domeno kode, za zmanjšanje vrzeli v kontekstni predstavitvi med programskim jezikom (PL) in naravnim jezikom (NL).', 'ha': "Commit message is a document that summarizes source code changes in natural language.  Salon aiki mai kyau na nuna kodi na ƙari, don haka yana ƙara samaki tsakanin developers. Saboda haka, aikinmu yana ƙara wata misali wanda ke rubũtar da takarda farat ɗaya. Ga wannan, Munã saka kodi 345K na cikin shiryoyin ayuka 6 (Python, PHP, Go, Java, Java, da Ruby). Kamar misalin translation na maɓallin neural (NMT), za'a yi amfani da shiryoyin ayuka na danne-danne, muna ciyar da shirin ayuka wa gyare-gyare zuwa tsarin koden kuma da daman gaske zuwa tsarin na koda kuma mu ƙayyade ƙarshen jumar da aka ƙara wajen gaske da BLEU-4. Kayya, muna goyya da shiryoyin mafarin biyu masu motsi da za'a kyautata matsalar da za'a iya ƙara matsalar da ake ƙara: (1) Shirin na'urar da za'a kiyaye injistan da za'a ciyar da canza kodi zuwa tsarin kode. (2) Taurar da ke amfani da nau'in farko mai daidai wa koden don ya ƙara gap cikin mai nuna wa wanda ke daidai a tsakanin harshen shiryoyin ayuka (PL) da harshen asili (NL).", 'he': 'מסר העברה הוא מסמך שמסכם שינויים מקורי בשפה טבעית. מסר התחייבות טוב מראה בבירור את קוד המקור משתנה, כך שזה משפר את שיתוף פעולה בין מפתחים. Therefore, our work is to develop a model that automatically writes the commit message.  למטרה זו, אנחנו משחררים קבוצות מידע 345K שמכילות משינוי קוד ומעבירים הודעות בשש שפות תוכנית (Python, PHP, Go, Java, JavaScript, ורובי). דומה לדוגמא של התרגום המכונה העצבית (NMT), באמצעות קבוצת הנתונים שלנו, אנו מאכילים את שינוי הקוד לתכנית הקודן והמסר להעביר לתכנית הקודר ומדוד את תוצאה של מסר ההעברה שנוצר עם BLEU-4. Also, we propose the following two training methods to improve the result of generating the commit message: (1) A method of preprocessing the input to feed the code modification to the encoder input.  (2) שיטה שמשתמשת במשקל ראשון מתאים לתחום הקוד כדי להפחית את הפער בין שפת תוכנית (PL) לשפה טבעית (NL).', 'bo': 'Commit message is a document that summarizes the source code changes in natural language. ཆ་འཕྲིན་གསར་བ་སྐྱོན་པོ་ཞིག་ནི་ཐོག་མའི་ཨང་རྩིས་བཟོ་བཅོས་མངོན དེར་བརྟེན། ང་ཚོའི་ལས་ཀ་ནི་རང་འགུལ་གྱིས་བརྗོད་བྱེད་པའི་མིག་དཔེ་ཞིག་གསར་འཛུགས་བྱེད་དགོས། To this end, we release 345K datasets consisting of code modification and commit messages in six programming languages (Python, PHP, Go, Java, JavaScript, and Ruby). Similar to the neural machine translation (NMT) model, using our dataset, we feed the code modification to the encoder input and the commit message to the decoder input and measure the result of the generated commit message with BLEU-4. འུ་ཅག་གིས་གཤམ་གྱི་གཙོ་རིམ་ལམ་ལུགས་གཉིས་ཀྱིས་རྒྱས་ཁབ་ཀྱི་འབྲེལ་བ་ཡི་གེ་ཡར་རྒྱས་གཏོང་འཕྲིན་གསར་བསྐྲུན་གཏོང་ཐབས་ལམ་ཞིག་ཏེ: (1) འ (2) བྱ་རིམ་འདིའི་ནང་དུ་འགོ་འཛུགས་ཀྱི་ཞེང་ཚད་གཅིག་པ་ཞིག་འཇུག་བྱེད་སྐབས་ཡིག་གཟུགས་རིས་བྱ་རིམ(PL) དང་རང་རུང་བའི་སྐད'}
{'en': 'Time-Efficient Code Completion Model for the  R Programming Language R  Programming Language', 'fr': 'Modèle de complétion de code rapide pour le langage de programmation R', 'ar': 'نموذج إتمام الكود الموفر للوقت للغة برمجة R', 'pt': 'Modelo de conclusão de código com eficiência de tempo para a linguagem de programação R', 'es': 'Modelo de finalización de código eficiente en tiempo para el lenguaje de programación R', 'ru': 'Эффективная во времени модель завершения кода для языка программирования R', 'ja': 'Rプログラミング言語の時間効率コード補完モデル', 'hi': 'R प्रोग्रामिंग भाषा के लिए समय-कुशल कोड पूर्णता मॉडल', 'zh': 'R 编程语言之省时代码成式', 'ga': 'Samhail Chríochnaithe Chód Tíosach Ama don Teanga Ríomhchlárúcháin R', 'el': 'Χρονικό-αποδοτικό μοντέλο ολοκλήρωσης κώδικα για τη γλώσσα προγραμματισμού R', 'hu': 'Időhatékony kódfejlesztési modell az R programozási nyelvhez', 'ka': 'Name', 'it': 'Modello di completamento del codice efficiente nel tempo per il linguaggio di programmazione R', 'kk': 'R бағдарлама тілінің уақыт- эффективні код толтыру үлгісі', 'ms': 'Model Penyempurnaan Kod Efisien Masa untuk Bahasa Perprogram R', 'ml': 'R പ്രോഗ്രാംമിങ്ങിങ്ങിനുള്ള സമയ- ഫാക്റ്റിഫൈറ്റ് കോഡ് പൂര്\u200dത്തിയാക്കുന്ന മോഡല്\u200d', 'mk': 'Time-Efficient Code Completion Model for the R Programming Language', 'mt': 'Mudell ta’ Tlestija tal-Kodiċi Effiċjenti fil-Ħin għall-Lingwa tal-Programmazzjoni R', 'mn': 'R Програмчлалын хэл дээр цаг-үр дүнтэй код дуусгах загвар', 'no': 'Name', 'pl': 'Efektywny w czasie model uzupełniania kodu dla języka programowania R', 'ro': 'Model eficient de completare a codului pentru limbajul de programare R', 'sr': 'Model završetka vremenskih kodova za R programiranje jezika', 'lt': 'R programavimo kalbos kodo užbaigimo modelis, efektyviai naudojantis laiku', 'si': 'R ව්\u200dයාපෘති භාෂාව සඳහා වෙලාව- සක්\u200dරීය කෝඩ් සම්පූර්ණ මොඩල්', 'so': 'Qoraalka R-Programming', 'sv': 'Tidseffektiv kodkompletteringsmodell för R-programmeringsspråket', 'ta': 'R நிரல் மொழிக்கான நேரத்திற்கான குறியீடு முடிவு மாதிரி', 'ur': 'Name', 'uz': 'R dastur uchun vaqt- effektiv kodlash usuli', 'vi': 'Mô hình hoàn chỉnh mã hiệu quả thời gian cho ngôn ngữ chương trình R', 'da': 'Tidseffektiv kodefærdighedsmodel for R-programmeringssproget', 'hr': 'Model Završenja vremenskih kodova za R programiranje jezika', 'de': 'Zeiteffizientes Code VervollstĂ¤ndigungsmodell fĂ¼r die R Programmiersprache', 'id': 'Model Penyelesaian Kode Efisien Waktu untuk Bahasa Programmasi R', 'fa': 'مدل کامل کد زمان- تاثیر برای زبان برنامه\u200cبندی R', 'bg': 'Ефективен във времето модел за завършване на кодове за програмния език Р', 'nl': 'Tijdbesparend Code Voltooiingsmodel voor de R-programmeertaal', 'tr': 'R Programlamak Dili üçin Wagtlaýyn Ködleme Tamamlama Modeli', 'af': 'Name', 'sw': 'Modeli ya Kutimiza Sheria ya Time-Effective kwa Lugha ya Programu ya R', 'sq': 'Modeli i kompletimit të kodit me efektshmëri kohore për gjuhën e programimit R', 'ko': 'R 언어의 시간 효율 코드 완성 모델', 'am': 'ቋንቋ', 'az': 'R Programlama Dili üçün vaxt-effektiv Kod Tamamlama Modeli', 'ca': 'Model de completació del codi eficient en temps per al llenguatge de programació R', 'cs': 'Časově efektivní model dokončování kódu pro programovací jazyk R', 'hy': 'R ծրագրավորության լեզու համար ժամանակի արդյունավետ կոդի ավարտական մոդել', 'bn': 'R প্রোগ্রামিং এর জন্য সময়- কার্যকর কোড সম্পূর্ণ মডেল', 'et': 'Ajasäästlik koodilõpetamise mudel R programmeerimiskeele', 'bs': 'Model Završenja vremenskih kodova za R programiranje jezika', 'fi': 'Aikatehokas koodinpäätösmalli R-ohjelmointikielelle', 'sk': 'Časovno učinkovit model zaključevanja kode za programski jezik R', 'ha': '@ action', 'he': 'מודל סיום קוד יעיל בזמן לשפה התכנית R', 'jv': 'string" in "context_BAR_stringLink', 'bo': 'R བྱ་རིམ་བྱེད་སྐད་ཡིག་ཆ་ལ་དུས་འཚམ་བའི་མ་དཔེ་རིགས'}
{'en': 'In this paper we present a deep learning code completion model for the  R language . We introduce several  techniques  to utilize  language modeling based architecture  in the  code completion task . With these techniques, the  model  requires low resources, but still achieves high quality. We also present an evaluation dataset for the  R language completion task . Our  dataset  contains multiple autocompletion usage contexts that provides robust validation results. The  dataset  is publicly available.', 'es': 'En este artículo presentamos un modelo de finalización de código de aprendizaje profundo para el lenguaje R. Presentamos varias técnicas para utilizar la arquitectura basada en el modelado del lenguaje en la tarea de finalización de código. Con estas técnicas, el modelo requiere pocos recursos, pero aun así logra una alta calidad. También presentamos un conjunto de datos de evaluación para la tarea de completar el lenguaje R. Nuestro conjunto de datos contiene múltiples contextos de uso de autocompletado que proporcionan resultados de validación sólidos. El conjunto de datos está disponible públicamente.', 'fr': "Dans cet article, nous présentons un modèle de complétion de code d'apprentissage profond pour le langage R. Nous introduisons plusieurs techniques pour utiliser l'architecture basée sur la modélisation du langage dans la tâche de complétion de code. Avec ces techniques, le modèle nécessite peu de ressources, mais atteint toujours une qualité élevée. Nous présentons également un ensemble de données d'évaluation pour la tâche d'achèvement du langage R. Notre ensemble de données contient plusieurs contextes d'utilisation de la saisie semi-automatique qui fournissent des résultats de validation robustes. L'ensemble de données est accessible au public.", 'pt': 'Neste artigo, apresentamos um modelo de preenchimento de código de aprendizado profundo para a linguagem R. Apresentamos várias técnicas para utilizar a arquitetura baseada em modelagem de linguagem na tarefa de conclusão de código. Com essas técnicas, o modelo requer poucos recursos, mas ainda alcança alta qualidade. Também apresentamos um conjunto de dados de avaliação para a tarefa de conclusão da linguagem R. Nosso conjunto de dados contém vários contextos de uso de preenchimento automático que fornecem resultados de validação robustos. O conjunto de dados está disponível publicamente.', 'ar': 'نقدم في هذه الورقة نموذجًا لإكمال كود التعلم العميق للغة R. نقدم العديد من التقنيات لاستخدام العمارة القائمة على نمذجة اللغة في مهمة إكمال التعليمات البرمجية. باستخدام هذه التقنيات ، يتطلب النموذج موارد منخفضة ، لكنه لا يزال يحقق جودة عالية. نقدم أيضًا مجموعة بيانات تقييم لمهمة إكمال لغة R. تحتوي مجموعة البيانات الخاصة بنا على سياقات استخدام متعددة للإكمال التلقائي توفر نتائج تحقق قوية. مجموعة البيانات متاحة للجمهور.', 'ja': '本稿では， R言語のディープラーニングコード完了モデルを提示する．コード完了タスクで言語モデリングベースのアーキテクチャを利用するためのいくつかのテクニックを紹介します。これらの技術により、モデルは低いリソースを必要としますが、依然として高品質を実現します。また、R言語完了タスクの評価データセットも提示します。当社のデータセットには、堅牢な検証結果を提供する複数のオートコンプリート使用コンテキストが含まれています。データセットは一般公開されています。', 'zh': '本文中,言 R 语之深代码成模样。 余言数术,以代码成事,用其言建模之体系结构。 用此术者,模形之资少,而犹得高质量。 给 R 语成者数集。 吾数集包数自成用上下文,可验也。 数集是明可用也。', 'hi': 'इस पेपर में हम आर भाषा के लिए एक गहरी सीखने कोड पूर्णता मॉडल प्रस्तुत करते हैं। हम कोड पूरा करने के कार्य में भाषा मॉडलिंग आधारित वास्तुकला का उपयोग करने के लिए कई तकनीकों का परिचय देते हैं। इन तकनीकों के साथ, मॉडल को कम संसाधनों की आवश्यकता होती है, लेकिन फिर भी उच्च गुणवत्ता प्राप्त होती है। हम आर भाषा पूर्णता कार्य के लिए एक मूल्यांकन डेटासेट भी प्रस्तुत करते हैं। हमारे डेटासेट में कई स्वत: पूर्णता उपयोग संदर्भ होते हैं जो मजबूत सत्यापन परिणाम प्रदान करते हैं। डेटासेट सार्वजनिक रूप से उपलब्ध है।', 'ru': 'В этой статье мы представляем модель завершения кода глубокого обучения для языка R. Мы вводим несколько методов для использования архитектуры на основе языкового моделирования в задаче завершения кода. С этими методами, модель требует низких ресурсов, но все же достигает высокого качества. Мы также представляем набор оценочных данных для задачи завершения языка R. Наш набор данных содержит несколько контекстов использования автозавершения, которые обеспечивают надежные результаты проверки. Набор данных является общедоступным.', 'ga': 'Sa pháipéar seo cuirimid i láthair samhail críochnú cód foghlama domhain don teanga R. Tugaimid isteach roinnt teicníochtaí chun úsáid a bhaint as ailtireacht atá bunaithe ar shamhaltú teanga sa tasc críochnaithe cód. Leis na teicnící seo, éilíonn an tsamhail acmhainní íseal, ach fós tá ardchaighdeán á bhaint amach. Cuirimid i láthair freisin tacar sonraí meastóireachta don tasc críochnaithe teanga R. Cuimsíonn ár dtacar sonraí comhthéacsanna úsáide uathchríochnaithe iolracha a sholáthraíonn torthaí bailíochtaithe láidre. Tá an tacar sonraí ar fáil go poiblí.', 'ka': 'ამ წიგნაში ჩვენ მივიღეთ დიდი სწავლის კოდის დასრულების მოდელი R ენაზე. ჩვენ ვიყენებთ რამდენიმე ტექნოგიები, რომლებიც ენის მოდელების გამოყენებაში იყენებთ კოდის დასრულება. ამ ტექნექციების შესახებ, მოდელი უნდა დაბალი რესურსები, მაგრამ უფრო დიდი კალექტის მიღება. ჩვენ ასევე R ენის დასრულება დავამუშაოთ მონაცემების შესახებ. ჩვენი მონაცემების კონტექსტი აქვს მრავალ ავტოდასრულების გამოყენების კონტექსტი, რომელიც ძალიან გადასრულების შედეგი. მონაცემების კონფიგურაცია ადგილურად ხელსახულია.', 'hu': 'Ebben a tanulmányban bemutatjuk az R nyelv mélytanulási kódfejlesztési modelljét. Számos technikát vezetünk be a nyelvmodellezési alapú architektúra használatára a kódfejlesztési feladatban. Ezekkel a technikákkal a modell alacsony erőforrásokat igényel, de még mindig magas minőséget ér el. Bemutatunk egy értékelő adatkészletet az R nyelv kiegészítéséhez. Adatkészletünk több automatikus kiegészítési felhasználási környezetet tartalmaz, amelyek robusztus érvényesítési eredményeket biztosítanak. Az adatkészlet nyilvánosan hozzáférhető.', 'el': 'Στην παρούσα εργασία παρουσιάζουμε ένα μοντέλο ολοκλήρωσης κώδικα βαθιάς μάθησης για τη γλώσσα Ρ. Εισάγουμε διάφορες τεχνικές για να χρησιμοποιήσουμε αρχιτεκτονική βασισμένη στη μοντελοποίηση γλωσσών στην εργασία ολοκλήρωσης κώδικα. Με αυτές τις τεχνικές, το μοντέλο απαιτεί χαμηλούς πόρους, αλλά εξακολουθεί να επιτυγχάνει υψηλή ποιότητα. Παρουσιάζουμε επίσης ένα σύνολο δεδομένων αξιολόγησης για την εργασία ολοκλήρωσης της γλώσσας R. Το σύνολο δεδομένων μας περιέχει πολλαπλά πλαίσια χρήσης αυτόματης συμπλήρωσης που παρέχουν ισχυρά αποτελέσματα επικύρωσης. Το σύνολο δεδομένων είναι διαθέσιμο στο κοινό.', 'it': "In questo articolo presentiamo un modello di completamento del codice di deep learning per la lingua R. Introduciamo diverse tecniche per utilizzare l'architettura basata sulla modellazione del linguaggio nel compito di completamento del codice. Con queste tecniche, il modello richiede poche risorse, ma raggiunge comunque alta qualità. Presentiamo anche un set di dati di valutazione per il compito di completamento del linguaggio R. Il nostro set di dati contiene molteplici contesti di utilizzo di completamento automatico che forniscono risultati di convalida affidabili. Il set di dati è disponibile al pubblico.", 'kk': 'Бұл қағазда R тілінің түсті оқыту кодын толтыру үлгісін таңдаймыз. Біз тілді моделдеу архитектурасын код толтыру тапсырмасында қолдану үшін бірнеше техникаларды келтіреміз. Бұл технологиялар үлгісінде төмен ресурстар керек, бірақ әлі жоғары сапатты жеткізеді. Біз сондай-ақ R тілді толтыру тапсырмасының бағалау деректерін таңдаймыз. Деректер жиынымыздың бірнеше автотолтыру контексті бар, бұл құпты тексеру нәтижесін жеткізеді. Деректер жиыны көпшілікті қол жеткізеді.', 'lt': 'Šiame dokumente pristatome gilaus mokymosi kodų užbaigimo model į R kalbai. Įdiegiame kelis metodus, kaip naudoti kalbų modeliavimo architektūrą kodų užbaigimo užduotyje. Taikant šiuos metodus modeliui reikalingi maži ištekliai, tačiau jis vis dar užtikrina aukštą kokybę. Mes taip pat pateikiame R kalbos užbaigimo užduoties vertinimo duomenų rinkinį. Mūsų duomenų rinkinyje yra keletas automatinio užbaigimo kontekstų, kurie suteikia patikimus patvirtinimo rezultatus. Duomenų rinkinys yra viešas.', 'ms': 'Dalam kertas ini, kami memperkenalkan model penyelesaian kod belajar dalam untuk bahasa R. Kami memperkenalkan beberapa teknik untuk menggunakan arkitektur berdasarkan pemodelan bahasa dalam tugas penyelesaian kod. Dengan teknik ini, model memerlukan sumber rendah, tetapi masih mencapai kualiti tinggi. Kami juga memperkenalkan set data penilaian untuk tugas pelengkapan bahasa R. Set data kami mengandungi konteks penggunaan pelengkapan automatik yang menyediakan keputusan pengesahihan yang kuat. Set data tersedia secara awam.', 'ml': 'ഈ പേപ്പറില്\u200d നമ്മള്\u200d R ഭാഷയ്ക്ക് ആഴത്തെ പഠിക്കുന്ന കോഡ് പൂര്\u200dത്തീകരണ മോഡല്\u200d കൊണ്ടുവരുന്നു. കോഡ് പൂര്\u200dത്തിയാക്കുന്ന ജോലിയില്\u200d ഭാഷ മോഡലിങ്ങിനെ ഉപയോഗിക്കാന്\u200d നമുക്ക് പല സാങ്കേതികവിദ്യകള്\u200d പരി ഈ സാങ്കേതികവിദ്യ കൊണ്ട്, മോഡലിന് കുറഞ്ഞ വിഭവങ്ങള്\u200d ആവശ്യമുണ്ട്, പക്ഷെ ഇപ്പോഴും ഉയര്\u200dന്ന സ്വാതന്ത നമ്മളും R ഭാഷ പൂര്\u200dത്തിയാക്കുന്നതിനുള്ള ഒരു വിലാസവിവരങ്ങള്\u200d കൊണ്ടുവരുന്നു. നമ്മുടെ ഡാറ്റാസെറ്റില്\u200d ഒരുപാട് സ്വയം പൂര്\u200dത്തിയാക്കുന്ന ഉപയോഗിക്കുന്നതിനുള്ള പരിപാടികളുണ്ട്.  ഡാറ്റാസെറ്റ് പ്രസിദ്ധമാണ്.', 'mk': 'In this paper we present a deep learning code completion model for the R language.  We introduce several techniques to utilize language modeling based architecture in the code completion task.  Со овие техники, моделот бара ниски ресурси, но сепак постигнува висок квалитет. Ние, исто така, претставуваме сет на податоци за евалуација за задачата за завршување на јазикот R. Нашиот набор на податоци содржи повеќе контексти за автокомплетирање кои обезбедуваат силни резултати за валидација. Податоците се јавно достапни.', 'pl': 'W niniejszym artykule przedstawiamy model kompletacji kodu głębokiego uczenia dla języka R. Wprowadzamy kilka technik wykorzystania architektury opartej na modelowaniu językowym w zadaniu uzupełniania kodu. Dzięki tym technikom model wymaga niskich zasobów, ale nadal osiąga wysoką jakość. Przedstawiamy również zestaw danych oceniających zadanie uzupełniania języka R. Nasz zestaw danych zawiera wiele kontekstów użytkowania automatycznego uzupełniania, które zapewniają solidne wyniki walidacji. Zestaw danych jest publicznie dostępny.', 'mt': 'F’dan id-dokument nippreżentaw mudell ta’ tlestija tal-kodiċi ta’ tagħlim profond għall-lingwa R. We introduce several techniques to utilize language modeling based architecture in the code completion task.  B’dawn it-tekniki, il-mudell jeħtieġ riżorsi baxxi, iżda xorta jikseb kwalità għolja. Aħna nippreżentaw ukoll sett ta’ dejta ta’ evalwazzjoni għall-kompitu tat-tlestija tal-lingwa R. Is-sett tad-dejta tagħna fih diversi kuntesti ta’ użu awtokompletat li jipprovdu riżultati sodi ta’ validazzjoni. Is-sett tad-dejta huwa disponibbli għall-pubbliku.', 'no': 'I denne papiret viser vi ein dyp læringskode-fullføringsmodell for R-språket. Vi introduserer fleire teknikk for å bruka språk- modelleringa basert arkitektur i kodfullføringsoppgåva. Med desse teknikkene krev modellen låge ressursar, men framleis oppnår høg kvalitet. Vi presenterer også ein evalueringsdataset for R- språk- fullføringsoppgåva. Datasettet vårt inneheld fleire autofullføringskontekstar som tilbyr robust valideringsresultat. Datasettet er tilgjengeleg offentlig.', 'ro': 'În această lucrare prezentăm un model de completare a codului de învățare profundă pentru limba R. Introducem mai multe tehnici pentru a utiliza arhitectura bazată pe modelarea limbii în sarcina de completare a codului. Cu aceste tehnici, modelul necesită resurse reduse, dar încă atinge o calitate ridicată. De asemenea, prezentăm un set de date de evaluare pentru sarcina de completare a limbii R. Setul nostru de date conține mai multe contexte de utilizare a completării automate care oferă rezultate solide de validare. Setul de date este disponibil publicului.', 'sr': 'U ovom papiru predstavljamo model završetka koda za R jezik. Predstavljamo nekoliko tehnika za upotrebu arhitekture bazirane na jeziku u zadatku završetka koda. Uz ove tehnike, model zahteva niske resurse, ali još uvek postiže visoke kvalitete. Takoðe predstavljamo podatke za procjenu zadataka za završavanje jezika R. Naša kompleta podataka sadrži višestruke kontekste za upotrebu autokompleta koji pružaju robne rezultate validacije. Podaci su javno dostupni.', 'so': 'Qoraalkan waxan ku qornaa model aad u dheer oo waxbarashada kaararka ah ee luqada R. Waxaynu soo bandhignaynaa qaabab badan oo lagu isticmaalayo tusaale ahaan dhismaha ku saleysan luuqada ee shaqada dhamaystirka. Teqooyinkan, modeligu wuxuu u baahan yahay hanti yar, laakiin weli wuxuu gaadhaa qiimo sare. Waxaynu sidoo kale keennaa kooban macluumaadka qiimeynta ee shaqada dhamaadka luqada R. Taariikhdayada waxaa ku jira isticmaalka isticmaalka iskuulka ah oo kala duduwan, kaas oo bixiya resultada xaqiijinta robotiga. Rugta macluumaadku wuxuu si bayaan ah u helaa.', 'mn': 'Энэ цаасан дээр бид R хэлний гүн гүнзгий суралцах кодын бүтээлтийн загварыг үзүүлнэ. Бид хэл загварын загварын архитектурыг кодын бүтээлтийн ажил дээр ашиглах олон техникуудыг танилцуулдаг. Эдгээр техникуудын хувьд загвар нь бага боловсрол хэрэгтэй, гэхдээ өндөр сайн чанартай байдаг. Мөн бид R хэл дуусгах үйлдлийн үнэлгээ өгөгдлийн санг тайлбарлаж байна. Бидний өгөгдлийн сангууд маш олон автоматжуулалтын хэрэглээ нөхцөл байдлыг агуулдаг. Өгөгдлийн санг олон нийтэд хэрэглэгддэг.', 'ta': 'In this paper we present a deep learning code completion model for the R language.  நாம் மொழி மாதிரி உருவமைப்பு அடிப்படையான அடிப்படையாளரை பயன்படுத்த பல தொழில்நுட்பத்தை அறிவிக்கிறோம் குறிய இந்த தொழில்நுட்பத்தைக் கொண்டு, மாதிரியில் குறைந்த வளங்கள் தேவைப்படுகிறது, ஆனால் இன்னும் அதிக தரம R மொழி முடிப்பு பணிக்கு ஒரு மதிப்பிடும் தகவல் அமைப்பை கொண்டு வருகிறோம். எங்கள் தரவுத்தளத்தில் பல தானியங்கி முடிப்பு பயன்பாட்டு முறைமைகள் உள்ளது, இது ரோப்ட் செலுத்தும் முடிவு தகவல் அமைப்பு பொதுவாக கிடைக்கும்.', 'sv': 'I denna uppsats presenterar vi en modell för djupinlärningskod för R-språket. Vi introducerar flera tekniker för att använda språkmodelleringsbaserad arkitektur i kodkompletteringsuppgiften. Med dessa tekniker kräver modellen låga resurser, men uppnår fortfarande hög kvalitet. Vi presenterar också en utvärderingsdata för uppgiften R språkkomplettering. Vårt dataset innehåller flera användningskontexter för automatisk komplettering som ger robusta valideringsresultat. Datauppsättningen är allmänt tillgänglig.', 'si': 'මේ පත්තරේ අපි R භාෂාව සඳහා ගොඩක් ඉගෙනගන්න කෝඩ් සම්පූර්ණයක් තියෙනවා. අපි භාෂාව ප්\u200dරමාණය කරන්න භාෂාව ප්\u200dරමාණය කරන්න අධාරිත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dය මේ තාක්ෂණය සමග, මොඩල් එකට අඩුම උපකරණය අවශ්\u200dයයි, නමුත් තවමත් උපකරණ ප්\u200dරතිශේෂතාවට අවශ අපි R භාෂාව සම්පූර්ණ වැඩ සඳහා විශ්ලේෂණ දත්ත සූදානයක් තියෙනවා. අපේ දත්ත සෙට්ටුව ස්වයංක්\u200dරිය ප්\u200dරයෝජනය සම්බන්ධතාවක් තියෙනවා ඒ වගේම ශක්තිමත් විශ්වාසය දත්ත සෙට් සාමාන්\u200dයයෙන් ප්\u200dරවේශයෙන්.', 'ur': 'اس کاغذ میں ہم ایک عمیق سیکھنے کی کوڈ کامل کی مدل کو آر زبان کے لئے پیش کرتے ہیں۔ ہم بہت سی تکنیک پیش کرتے ہیں کہ زبان موڈلینگ کی بنیادی معماری کا استعمال کریں ان تکنیک کے ساتھ مدل کم سرمایہ کی ضرورت ہے، لیکن اب تک اچھی کیفیت پہنچتی ہے۔ ہم نے بھی آر زبان کامل کا کام کے لئے ایک ارزیابی ڈیٹ سٹ کو پیش کیا ہے. ہمارے ڈاکٹ سٹ میں بہت سی آٹوٹ کامل استعمال کی کنٹکسٹس لگتی ہے جو مضبوط validation نتیجے پیش کرتا ہے. ڈاٹ سٹ عمومی طور پر موجود ہے.', 'vi': 'Trong tờ giấy này chúng tôi có một mô hình hoàn thành mã để học sâu cho ngôn ngữ R. Chúng tôi giới thiệu vài kỹ thuật để sử dụng kiến trúc văn bản từ ngữ trong nhiệm vụ hoàn thành mã. Với những kỹ thuật này, mẫu cần ít nguồn tài nguyên, nhưng vẫn đạt được chất lượng cao. Chúng tôi cũng đưa ra một tập tin đánh giá cho nhiệm vụ hoàn thành ngôn ngữ R. Bộ dữ liệu của chúng tôi chứa nhiều trường hợp sử dụng tự hoàn thiện, cung cấp kết quả xác thực. Bộ dữ liệu có công khai.', 'uz': "Bu qogʻozda R tilning juda qiyin o'rganish kodi tuzilishi modelini hozir qilamiz. Biz bir necha teknologizni kodlash vazifasida tilning asosiy mualliflarni ishlatish uchun foydalanamiz. Ushbu teknologiya bilan model qo'shimcha rasmlar kerak, ammo o o'zida yuqori sifatga erishadi. Biz R tilni tuzish vazifasini qiymatlashni hozirganamiz. Maʼlumotlar soni bir nechta avtomatik toʻldirish muvaffaqiyatlari mavjud. robot haqiqiqiylik natijalarini yaratadi. Maʼlumotlar bazasini ochib boʻlmadi.", 'bg': 'В настоящата статия представяме модел за задълбочено обучение на код за езика. Въвеждаме няколко техники за използване на архитектура базирана на езиково моделиране в задачата за завършване на кода. С тези техники моделът изисква ниски ресурси, но все пак постига високо качество. Представяме и набор от данни за оценка на задачата за завършване на езика. Нашият набор от данни съдържа множество контексти за използване на автоматично завършване, които осигуряват надеждни резултати от валидиране. Наборът от данни е публично достъпен.', 'hr': 'U ovom papiru predstavljamo model završetka koda za R jezik. Predstavljamo nekoliko tehnika za upotrebu arhitekture na temelju modela jezika u zadatku završetka kodova. Uz te tehnike, model zahtijeva niske resurse, ali još uvijek postiže visoke kvalitete. Također predstavljamo podatke za procjenu zadataka za završavanje jezika R. Naša kompleta podataka sadrži višestruke kontekste za upotrebu autokompleta koji pružaju robne rezultate potvrde. Podaci su javno dostupni.', 'nl': 'In dit artikel presenteren we een deep learning code completion model voor de R taal. We introduceren verschillende technieken om taalmodellering gebaseerde architectuur te gebruiken in de code voltooiing taak. Met deze technieken vergt het model weinig middelen, maar bereikt het toch een hoge kwaliteit. We presenteren ook een evaluatie dataset voor de R taal voltooiing taak. Onze dataset bevat meerdere gebruikscontexten voor automatische aanvulling die robuuste validatieresultaten opleveren. De dataset is openbaar beschikbaar.', 'da': 'I denne artikel præsenterer vi en dyb læring kode fuldførelse model for R sproget. Vi introducerer flere teknikker til at udnytte sprogmodellering baseret arkitektur i kodefærdiggørelsesopgaven. Med disse teknikker kræver modellen lave ressourcer, men opnår stadig høj kvalitet. Vi præsenterer også et evalueringsdatasæt til R sprogfærdiggørelsesopgaven. Vores datasæt indeholder flere autokompletteringssammenhænge, der giver robuste valideringsresultater. Datasættet er offentligt tilgængeligt.', 'ko': '본고에서 우리는 R 언어의 심도 있는 학습 코드 완성 모델을 제시했다.우리는 코드 완성 임무에서 언어 모델링을 바탕으로 하는 체계 구조를 활용한 몇 가지 기술을 소개했다.이런 기술이 있으면 모델이 필요로 하는 자원은 매우 낮지만 여전히 높은 품질을 실현할 수 있다.우리는 또한 R 언어로 임무를 완성하기 위해 평가 데이터 집합을 제공했다.우리의 데이터 집합은 여러 개의 자동 사용 상하문을 포함하여 신뢰할 수 있는 검증 결과를 제공합니다.이 데이터 세트는 공개된 것이다.', 'de': 'In diesem Beitrag stellen wir ein Deep Learning Code Completion Modell für die R Sprache vor. Wir führen verschiedene Techniken ein, um sprachmodellbasierte Architektur in der Code-Vervollständigung Task zu verwenden. Mit diesen Techniken erfordert das Modell geringe Ressourcen, erreicht aber dennoch eine hohe Qualität. Außerdem stellen wir einen Auswertungsdatensatz für die R-Sprachvervollständigungsaufgabe vor. Unser Datensatz enthält mehrere Nutzungskontexte zur automatischen Vervollständigung, die robuste Validierungsergebnisse liefern. Der Datensatz ist öffentlich zugänglich.', 'id': 'Dalam kertas ini kami mempersembahkan model penyelesaian kode belajar dalam untuk bahasa R. Kami memperkenalkan beberapa teknik untuk menggunakan arsitektur berdasarkan model bahasa dalam tugas penyelesaian kode. Dengan teknik ini, model membutuhkan sumber daya rendah, tapi masih mencapai kualitas tinggi. Kami juga mempersembahkan set data evaluasi untuk tugas penyelesaian bahasa R. Set data kami mengandung konteks penggunaan pelengkapan otomatis yang menyediakan hasil validasi yang kuat. Set data tersedia publik.', 'tr': 'Bu kagyzda R dili üçin derin öwrenme kody tamamlama nusgasyny görkezýäris Biz dilleriň modelleýän arhitektura köd tamamlama işinde ullanmak üçin birnäçe teknikleri taýýarlapdyk. Bu teknikler bilen nusga düşük çeşmeler gerek, ýöne henizem ýokary howpsuzlyk bilen ýetişir. Biz hem R dili tamamlama täblisasynyň barlama maglumaty çykarýarys. Maglumatymyz sistemimizde gaty awtomatik taýýarlama netijesini temin eden senediler bar. Maglumat setirini publika meýilleşdirýär.', 'af': "In hierdie papier vertoon ons 'n diep leer kode voltooiing model vir die R taal. Ons introduseer verskeie teknike om taal modellering gebruik te maak gebaseerde arkitektuur in die kode voltooiing taak. Met hierdie teknike, die model benodig lae hulpbronne, maar nog hoë kwaliteit bereik. Ons stel ook 'n evaluasie datastel vir die R taal voltooiing taak. Ons datastel bevat veelvuldige outomatiese volledige gebruik konteks wat kragtige geldigheidresultate verskaf. Die datastel is openlik beskikbaar.", 'sq': 'Në këtë letër prezantojmë një model të kompletimit të kodit të mësimit të thellë për gjuhën R. Ne futim disa teknika për të përdorur arkitekturën e modelimit gjuhësor në detyrën e kompletimit të kodit. Me këto teknika, modeli kërkon burime të ulta, por ende arrin cilësi të lartë. Ne prezantojmë gjithashtu një grup të dhënash vlerësimi për detyrën e kompletimit të gjuhës R. Të dhënat tona përmbajnë shumë kontekste të përdorimit të autokompletimit që ofrojnë rezultate të fuqishme të vlerësimit. Të dhënat janë në dispozicion publik.', 'hy': 'In this paper we present a deep learning code completion model for the R language.  Մենք ներկայացնում ենք բազմաթիվ մեթոդներ, որոնք օգտագործում են լեզվի մոդելավորման հիմնված ճարտարապետությունը կոդի ավարտացման գործում: Այս մեթոդների միջոցով մոդելը պահանջում է ցածր ռեսուրսներ, բայց դեռևս հասնում է բարձր որակի: Մենք նաև ներկայացնում ենք R լեզվի ավարտացման խնդիր գնահատման տվյալների համակարգ: Մեր տվյալների համակարգը պարունակում է բազմաթիվ ինքնալրացման կոնտեքստներ, որոնք ապահովում են ուժեղ հավասարման արդյունքներ: Տվյալների համակարգը հասանելի է:', 'fa': 'در این کاغذ ما یک مدل کامل کد یادگیری عمیق برای زبان R را نشان می دهیم. ما چند تکنیک را معرفی می کنیم که برای استفاده از معماری بنیاد زبانی در کار کامل کد استفاده کنیم. با این تکنیک، مدل نیاز به منابع کم دارد، اما هنوز به کیفیت بالا رسیده است. ما همچنین یک مجموعه داده\u200cهای ارزیابی برای کار کامل زبان R را پیشنهاد می\u200cکنیم. مجموعه داده\u200cهای ما شامل موقعیت\u200cهای استفاده از کامل خودکار چندین موقعیت است که نتیجه\u200cهای تایید شدیدی را پیشنهاد می\u200cدهد. مجموعه داده ها به طور عمومی در دسترس هستند.', 'az': 'Bu kağızda R dilinin derin öyrənmə kodu tamamlama modelini göstəririk. Biz còd tamamlama işində dil modellərini istifadə etmək üçün çoxlu teknikləri təşkil edirik. Bu tekniklərlə modeli düşük kaynaqlar lazımdır, amma hələ də yüksək keyfiyyət yetirir. Biz həmçinin R dili tamamlama işləri üçün değerlendirmə verilən verilən qurğunu göstəririk. Bizim verilən qurğumuz çoxlu avtomatik işləmə müxtəlifləri barəsində möhkəm təsdiqləmə sonuçlarını verir. Veri qurğuları açıq-aşkar mövcuddur.', 'sw': 'Katika karatasi hii tunaweka modeli ya kujifunza kwa ujuzi wa kodi kwa lugha ya R. Tunaonyesha mbinu kadhaa za kutumia muundo wa lugha katika kazi ya kuuliza sheria. Kwa mbinu hizi, muundo unahitaji rasilimali chini, lakini bado unapata kiwango kikubwa. Pia tunaweka taarifa za uchunguzi kwa ajili ya kazi ya kutimiza lugha ya R. Taarifa zetu zina mikakati mbalimbali ya matumizi ya kujitegemea inayotoa matokeo ya uhakika wa robo. Taasisi ya taarifa zinapatikana hadharani.', 'bn': 'এই কাগজটিতে আমরা আর ভাষার জন্য গভীর শিক্ষা কোড সম্পূর্ণ মডেল উপস্থাপন করি। কোড সম্পূর্ণ কাজে ভাষার মডেলিং ভিত্তিক কাঠামো ব্যবহার করার জন্য আমরা বেশ কিছু প্রযুক্তি চিহ্নিত করি। এই প্রযুক্তিগুলোর মাধ্যমে মডেল কম সম্পদ দরকার, কিন্তু এখনও উচ্চমান অর্জন করে। আমরা আরভাষা সম্পূর্ণ কাজের জন্য একটি মূল্যায়নের ডাটাসেট উপস্থাপন করি। আমাদের ডাটাসেটের মধ্যে বেশ কয়েকটি স্বয়ংক্রিয়ভাবে পূর্ণ ব্যবহারের প্রতিযোগিতা আছে যা রোবটস্ট বৈধ ফল ডাটাসেট প্রকাশ্যে পাওয়া যাচ্ছে।', 'bs': 'U ovom papiru predstavljamo model završetka koda za R jezik. Predstavljamo nekoliko tehnika za upotrebu arhitekture na temelju modela jezika u zadatku završetka kodova. Uz te tehnike, model zahtijeva niske resurse, ali još uvijek postiže visoke kvalitete. Također predstavljamo podatke za procjenu zadataka za završavanje jezika R. Naša kompleta podataka sadrži višestruke kontekste za upotrebu autokompleta koji pružaju robne rezultate potvrde. Podaci su javno dostupni.', 'cs': 'V tomto článku představujeme model kompletace kódu hlubokého učení pro jazyk R. Představujeme několik technik pro využití architektury založené na jazykovém modelování v úloze dokončování kódu. S těmito technikami vyžaduje model nízké zdroje, ale přesto dosahuje vysoké kvality. Představujeme také hodnotící sadu dat pro úlohu dokončení jazyka R. Naše datová sada obsahuje několik kontextů použití automatického dokončování, které poskytují robustní výsledky ověřování. Soubor dat je veřejně dostupný.', 'fi': 'Tässä työssä esitellään R-kielen syväoppimisen koodin täydennysmalli. Esittelemme useita tekniikoita kielimallinnukseen perustuvan arkkitehtuurin hyödyntämiseksi koodin täydennystehtävässä. Näiden tekniikoiden avulla malli vaatii vähän resursseja, mutta saavuttaa silti korkean laadun. Esitämme myös arviointiaineiston R-kielen täydennystehtävään. Aineistomme sisältää useita automaattisen täydennyksen käyttökonteksteja, jotka tarjoavat vankkoja validointituloksia. Aineisto on julkisesti saatavilla.', 'et': 'Käesolevas töös tutvustame R keele sügavõppe koodi lõpetamise mudelit. Tutvustame mitmeid meetodeid, et kasutada keele modelleerimisel põhinevat arhitektuuri koodi täitmise ülesandes. Nende tehnikatega nõuab mudel madalaid ressursse, kuid saavutab siiski kõrge kvaliteedi. Samuti esitame hindamisandmekogumi R keele lõpetamise ülesandeks. Meie andmekogum sisaldab mitut automaatse lõpetamise kasutuskonteksti, mis pakub tugevaid valideerimistulemusi. Andmekogum on avalikult kättesaadav.', 'am': 'በዚህ ፕሮግራም ለR ቋንቋ ጥልቅ ትምህርት የኮድ ሙላት model እናቀርባለን፡፡ የቋንቋን ምሳሌ መሠረት መሠረትን ለመጠቀም ብዙዎችን ጥቃቄዎች እናስታውቃለን፡፡ እነዚህን ስልጣናዎች፣ ሞዴል የቅርብ ሀብት ያስፈልጋል ነገር ግን ገና ከፍተኛ ጥሩ ያገኛል፡፡ እና ለR ቋንቋ ማድረግ ማድረግ ዳታዎችን እናቀርባለን፡፡ የዳውሬታችን ማረጋገጫ የሮቦት አረጋጋጭ ፍሬዎችን የሚያደርግ ብዙዎችን አውቶማቲካዊ መጠቀም ይኖራል፡፡ የዳታ ሳጥን ግልፅ ነው', 'ca': "En aquest article presentem un model de completació del codi d'aprenentatge profund del llenguatge R. Introduïm diverses tècniques per utilitzar arquitectura basada en la modelació lingüística en la tasca de completament del codi. Amb aquestes tècniques, el model necessita baixos recursos, però encara té alta qualitat. També presentem un conjunt de dades d'evaluació per a la tasca de completament del llenguatge R. El nostre conjunt de dades conté múltiples contextos d'ús autocompletat que proporcionen resultats de validació robustos. El conjunt de dades està disponible al públic.", 'he': 'בעיתון הזה אנו מציגים מודל סיום קוד למידה עמוק לשפה R. אנחנו מציגים כמה טכניקות להשתמש בארכיטקטורה מבוססת על דגמניות שפות במשימת השלמת הקוד. עם הטכניקות האלה, המודל דורש משאבים נמוכים, אבל עדיין משיג איכות גבוהה. אנחנו גם מציגים קבוצת מידע הערכה למשימת השפה R. קונטקסט המידע שלנו מכיל תקשורת שימוש אוטומטית רבה שמספקת תוצאות אישור חזקות. The dataset is publicly available.', 'sk': 'V prispevku predstavljamo model zaključevanja kode za globoko učenje jezika R. Predstavljamo več tehnik za uporabo arhitekture, ki temelji na jezikovnem modeliranju, v opravilu dokončanja kode. S temi tehnikami model zahteva nizke vire, vendar še vedno dosega visoko kakovost. Predstavljamo tudi vrednotenjski nabor podatkov za nalogo dokončanja jezika R. Naš nabor podatkov vsebuje več kontekstov uporabe samodokončanja, ki zagotavljajo robustne rezultate preverjanja. Zbirka podatkov je javno dostopna.', 'jv': 'Nang pepul iki, kita mudheng model kang sampeyan nggo barang R Awak dhéwé nggawe sistem sing sampeyan kanggo nggambar aturan anyar nggawe Gambar teknik-teknik iki, model tenong keamanan akeh perusahaan, dadi iso diangkat luwih apik. Same here data set string" in "context_BAR_stringLink dataset kang dipuluhayo', 'ha': "Ga wannan takardan da Muke halatar da wata masana mai cikakken kodi wa harshen R. Tuna fara masu amfani da misalin ayuka da aka baka cikin aikin kodi da za'a cika. Ga wannan zanen, misalin yana da amfani kaɗan, kuma amma yana da girma. Kayya, Munã halatar da an ƙidãya danne ga cikakken aikin R-harshen. QXml An sami tsarin bayani.", 'bo': 'ཤོག ང་ཚོས་སྐད་ཡིག་རྩལ་གཞི་རྩིས་གཞི་བརྗོད་ཀྱི་ཐབས་ལམ་འདྲ་ཞིག་སྟོན་བྱེད་ཀྱི་ཡོད། ཐབས་ལམ་འདི་དག་དང་། མིག་ལམ་ལ་རྒྱ་ཆུང་ཉུང་བའི་རྒྱུ་ཆས་དགོས་རེད། ཡིན་ནའང་དེ་ཡང་རང་ཉིད་ཀྱི་ཁྱད་ཚད་མཐ འུ་ཚོས་R སྐད་རིགས་ཁ་སྡུག་གི་བྱ་འགུལ་ལ་ཉེན་ཁ་འབྱེད་ཀྱི་ཡིག་ཆ་མཚོན་ན། ང་ཚོའི་གནད་སྡུད་ཆ་ཚན་ཡི་གེ སྒྲིག་ཆ་སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་སྤྱད་ཚར་བ'}
{'en': 'Shellcode_IA32 : A Dataset for Automatic Shellcode Generation S hellcode_ IA 32: A Dataset for Automatic Shellcode Generation', 'pt': 'Shellcode_IA32: um conjunto de dados para geração automática de shellcode', 'ar': 'Shellcode_IA32: مجموعة بيانات لإنشاء أكواد القشرة تلقائيًا', 'fr': 'ShellCode_IA32\xa0: un ensemble de données pour la génération automatique de Shellcode', 'es': 'ShellCode_IA32: Un conjunto de datos para la generación automática de código', 'hi': 'Shellcode_IA32: स्वचालित शेलकोड जनरेशन के लिए एक डेटासेट', 'ja': 'Shellcode_IA 32:自動シェルコード生成のためのデータセット', 'ru': 'Shellcode_IA32: Набор данных для автоматической генерации Shellcode', 'zh': 'Shellcode_IA32:以生壳代码数集', 'ga': 'Shellcode_IA32: Tacar Sonraí le haghaidh Giniúint Uathoibríoch Cóid Shell', 'hu': 'Shellcode_IA32: Adatkészlet az automatikus Shellcode generáláshoz', 'el': 'Ένα σύνολο δεδομένων για την αυτόματη παραγωγή κελιών', 'it': 'Shellcode_IA32: un set di dati per la generazione automatica di Shellcode', 'kk': 'Shellcode_ IA32: Автоматты қоршау- орта коды құру үшін деректер қоры', 'lt': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'ms': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'ml': 'ഷെല്\u200dകോഡ് IA32: സ്വയം ഷെല്\u200dകോഡ് ജനിപ്പിക്കുന്നതിനുള്ള ഡേറ്റാസെറ്റ്', 'ka': 'Shellcode_ IA32: მონაცემები ავტომატური Shellcode- ის შექმნა', 'no': 'Shellcode_ IA32: Eit databaset for automatisk skalkoding', 'mk': 'Shellcode_IA32: Податоци за генерација автоматски Shellcode', 'mt': 'Shellcode_IA32: Sett ta’ Dejta għall-Ġenerazzjoni Awtomatika tal-Shellcode', 'ro': 'Shellcode_IA32: Un set de date pentru generarea automată de Shellcode', 'pl': 'Shellcode_IA32: Zestaw danych do automatycznego generowania kodów shellcode', 'sr': 'Shellcode_ IA32: Databanka za automatsku generaciju Shellcode', 'so': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'mn': 'Shellcode_IA32: Автоматик Shellcode үүсгэх өгөгдлийн сан', 'sv': 'Shellcode_IA32: Ett dataset för automatisk Shellcode generering', 'ta': 'Shellcode_ IA32: தானியங்கி Shellcode உருவாக்கத்திற்கு தகவல் அமைப்பு', 'si': 'ශෙල්කෝඩ_ IA32: ස්වයංක්\u200dරිය ශෙල්කෝඩ් නිර්මාණය සඳහා දත්ත සැකසුම්', 'ur': 'Shellcode_ IA32: Automatic Shellcode Generation for A Dataset', 'uz': 'Shellcode_ IA32: Avtomatik Shellcode Generation uchun maʼlumot set', 'vi': 'Chế độ sò còn tự động tạo mã tự động.', 'bg': 'Shellcode_IA32: Набор от данни за автоматично генериране на Shellcode', 'hr': 'Shellcode_IA32: Databanka za automatičku Generaciju Shellcode', 'nl': 'Shellcode_IA32: Een dataset voor automatische shellcode generatie', 'da': 'Shellcode_IA32: Et datasæt til automatisk generering af Shellcode', 'fa': 'Shellcode_ IA32: یک تنظیم اطلاعات برای تولید شیلکود خودکار', 'id': 'Shellcode_IA32: Satu Set Data untuk Generasi Automatik Shellcode', 'de': 'Shellcode_IA32: Ein Datensatz zur automatischen Shellcode-Generierung', 'ko': '셸 코드 IA32: 자동 셸 코드 생성을 위한 데이터 세트', 'sq': 'Shellcode_IA32: Një bazë të dhënash për Gjenerimin Automatik të Shellcode', 'sw': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'tr': 'Shellcode_IA32: Otomatik Kabuk Ködleme Bejer', 'af': "Shellcode_ IA32: ' n Dataset vir Outomatiese Shellcode Generasie", 'am': 'የዶሴ ስም፦', 'hy': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'bn': 'শেলকোড_ IA32: স্বয়ংক্রিয়ভাবে শেলকোড জেনারেশনের জন্য একটি ডাটাসেট', 'cs': 'Shellcode_IA32: Datová sada pro automatické generování shellcode', 'az': 'Shellcode_IA32: Avtomatik Shell Kodu Ünvanı', 'bs': 'Shellcode_IA32: Databanka za automatičku Generaciju Shellcode', 'ca': 'Shellcode_IA32: Un conjunt de dades per a la generació automàtica de codis Shellcode', 'et': 'Shellcode_IA32: automaatse Shellcode genereerimise andmekogum', 'fi': 'Shellcode_IA32: Tietokanta automaattista Shellcode Generation', 'jv': 'Language', 'ha': 'KCharselect unicode block name', 'sk': 'Shellcode_IA32: Zbirka podatkov za samodejno ustvarjanje Shellcode', 'he': 'Shellcode_IA32: A Dataset for Automatic Shellcode Generation', 'bo': 'Shellcode_IA32:རང་འགུལ་གྱིས་Shellcode སྒྲིག་འཛུགས་ཡིག་སྣོད'}
{'en': 'We take the first step to address the task of  automatically generating shellcodes , i.e., small pieces of code used as a payload in the exploitation of a  software vulnerability , starting from  natural language comments . We assemble and release a novel dataset (Shellcode_IA32), consisting of challenging but common assembly instructions with their natural language descriptions. We experiment with standard methods in neural machine translation (NMT) to establish baseline performance levels on this task.', 'pt': 'Damos o primeiro passo para abordar a tarefa de gerar automaticamente shellcodes, ou seja, pequenos pedaços de código usados como carga útil na exploração de uma vulnerabilidade de software, a partir de comentários em linguagem natural. Montamos e lançamos um novo conjunto de dados (Shellcode_IA32), que consiste em instruções de montagem desafiadoras, mas comuns, com suas descrições em linguagem natural. Experimentamos métodos padrão em tradução automática neural (NMT) para estabelecer níveis de desempenho de linha de base nessa tarefa.', 'fr': "Nous faisons le premier pas vers la génération automatique de codes shell, c'est-à-dire de petits morceaux de code utilisés comme charge utile dans l'exploitation d'une vulnérabilité logicielle, à partir de commentaires en langage naturel. Nous assemblons et publions un nouveau jeu de données (ShellCode_IA32), composé d'instructions d'assemblage complexes mais communes avec leurs descriptions en langage naturel. Nous expérimentons des méthodes standard de traduction automatique neuronale (NMT) afin d'établir des niveaux de performance de base pour cette tâche.", 'ar': 'نتخذ الخطوة الأولى لمعالجة مهمة إنشاء أكواد القشرة تلقائيًا ، أي أجزاء صغيرة من التعليمات البرمجية تُستخدم كحمولة في استغلال ثغرة في البرنامج ، بدءًا من التعليقات اللغوية الطبيعية. نقوم بتجميع وإصدار مجموعة بيانات جديدة (Shellcode_IA32) ، تتكون من إرشادات تجميع صعبة ولكنها شائعة مع أوصاف لغتها الطبيعية. نجرب الطرق القياسية في الترجمة الآلية العصبية (NMT) لتحديد مستويات الأداء الأساسية في هذه المهمة.', 'es': 'Damos el primer paso para abordar la tarea de generar automáticamente códigos shell, es decir, pequeños fragmentos de código utilizados como carga útil en la explotación de una vulnerabilidad de software, a partir de comentarios en lenguaje natural. Reunimos y publicamos un conjunto de datos novedoso (ShellCode_IA32), que consiste en instrucciones de ensamblaje desafiantes pero comunes con sus descripciones en lenguaje natural. Experimentamos con métodos estándar de traducción automática neuronal (NMT) para establecer niveles de rendimiento de referencia en esta tarea.', 'hi': 'हम स्वचालित रूप से शेलकोड उत्पन्न करने के कार्य को संबोधित करने के लिए पहला कदम उठाते हैं, यानी, प्राकृतिक भाषा टिप्पणियों से शुरू होने वाले सॉफ़्टवेयर भेद्यता के शोषण में पेलोड के रूप में उपयोग किए जाने वाले कोड के छोटे टुकड़े। हम एक उपन्यास डेटासेट (Shellcode_IA32) को इकट्ठा और जारी करते हैं, जिसमें उनके प्राकृतिक भाषा विवरणों के साथ चुनौतीपूर्ण लेकिन सामान्य असेंबली निर्देश शामिल हैं। हम इस कार्य पर आधारभूत प्रदर्शन स्तर स्थापित करने के लिए तंत्रिका मशीन अनुवाद (एनएमटी) में मानक तरीकों के साथ प्रयोग करते हैं।', 'ja': '最初のステップは、シェルコードを自動的に生成する作業に取り組むことです。つまり、自然言語のコメントから始まり、ソフトウェアの脆弱性を利用する際のペイロードとして使用される小さなコードです。私たちは、新しいデータセット（ Shellcode_IA 32 ）を組み立ててリリースします。これは、難しいが一般的な組み立て命令と、それらの自然言語の記述で構成されています。私たちは、このタスクのベースラインパフォーマンスレベルを確立するために、神経機械翻訳（ NMT ）における標準的な方法を実験しました。', 'ru': 'Мы делаем первый шаг для решения задачи автоматического генерирования шелл-кодов, то есть небольших фрагментов кода, используемых в качестве полезной нагрузки при эксплуатации уязвимости программного обеспечения, начиная с комментариев на естественном языке. Мы собираем и выпускаем новый набор данных (Shellcode_IA32), состоящий из сложных, но распространенных инструкций по сборке с их описаниями на естественном языке. Мы экспериментируем со стандартными методами нейронного машинного перевода (НМП), чтобы установить базовые уровни производительности по этой задаче.', 'ga': 'Déanaimid an chéad chéim chun aghaidh a thabhairt ar an tasc a bhaineann le sliogchóid a ghiniúint go huathoibríoch, i.e. píosaí beaga cód a úsáidtear mar phálasta chun leochaileacht bogearraí a shaothrú, ag tosú ó thuairimí teanga nádúrtha. Cruinnímid agus scaoilimid tacar sonraí úrnua (Shellcode_IA32), ina bhfuil treoracha casta ach coitianta lena gcur síos ar theanga nádúrtha. Déanaimid tástáil le modhanna caighdeánacha in aistriúchán meaisín néarach (NMT) chun bunleibhéil feidhmíochta a bhunú ar an tasc seo.', 'zh': '第一步以决自生shellcode之务,即自自然语言注始,于利用软件漏时以为有效载荷小段代码。 组装发新数集(Shellcode_IA32),以挑战性见汇编指自然语言成之。 试用神经机器翻译(NMT)中法,以立基线性平。', 'hu': 'Az első lépést megtesszük annak a feladatnak a kezelésére, hogy automatikusan generáljuk shellkódokat, azaz a szoftver sebezhetőségének hasznos terheléseként használt kis kódokat, a természetes nyelvi megjegyzésektől kezdve. Összeállítunk és kiadunk egy új adatkészletet (Shellcode_IA32), amely kihívást jelentő, de közös összeszerelési utasításokat tartalmaz természetes nyelvi leírásokkal. A neurális gépi fordítás (NMT) szabványos módszereivel kísérletezünk a feladat alapvető teljesítményszintjének meghatározására.', 'it': 'Facciamo il primo passo per affrontare il compito di generare automaticamente shellcode, cioè piccoli pezzi di codice utilizzati come payload nello sfruttamento di una vulnerabilità software, partendo dai commenti del linguaggio naturale. Assembliamo e rilasciamo un nuovo dataset (Shellcode_IA32), composto da istruzioni di assemblaggio impegnative ma comuni con le loro descrizioni del linguaggio naturale. Sperimentiamo metodi standard nella traduzione automatica neurale (NMT) per stabilire i livelli di prestazioni di base su questo compito.', 'ka': 'ჩვენ ვაკეთებთ პირველი ნაწილი, რომ ავტომატურად ქოლკოდის შექმნის დასაწყებას, მაგალითად პატარა კოდის ნაწილი ნაწილი, როგორც გამოყენებული როგორც პროგრამეტური დაავადება პროგრამეტურის გამ ჩვენ შეიყვანეთ და გახსნა ნომალური მონაცემების კონფიგურაცია (Shellcode_IA32), რომელიც შესაძლებელია, მაგრამ საერთო კონფიგურაციის ინსტრუქციები, რომელიც მათი ნა ჩვენ ექსპერიმენტირებით ნეიროლური მანქანის გარგულისხმებით (NMT) სტანდარტური პროცემენტებით ამ რაოდენობაზე დავიყენებთ.', 'el': 'Κάνουμε το πρώτο βήμα για να αντιμετωπίσουμε το έργο της αυτόματης δημιουργίας κωδικών, δηλαδή μικρών κομματιών κώδικα που χρησιμοποιούνται ως ωφέλιμο φορτίο στην εκμετάλλευση μιας τρωτότητας λογισμικού, ξεκινώντας από σχόλια φυσικής γλώσσας. Συγκεντρώνουμε και απελευθερώνουμε ένα νέο σύνολο δεδομένων (που αποτελείται από δύσκολες αλλά κοινές οδηγίες συναρμολόγησης με τις περιγραφές της φυσικής γλώσσας τους. Πειραματιζόμαστε με τυποποιημένες μεθόδους στη νευρωνική μηχανική μετάφραση (NMT) για να καθορίσουμε βασικά επίπεδα απόδοσης σε αυτό το έργο.', 'lt': 'Pirmasis žingsnis sprendžiamas uždavinys automatiškai generuoti kompiuterinius kodus, t. y. mažus kodus, naudojamus kaip naudingą apkrovą naudojant programinės įrangos pažeidžiamumą, pradedant natūraliomis kalbos komentarais. We assemble and release a novel dataset (Shellcode_IA32), consisting of challenging but common assembly instructions with their natural language descriptions.  Eksperimentuojame naudojant standartinius metodus nervinių mašin ų vertimui (NMT), kad nustatytume pradinius veiksmingumo lygius šioje užduotyje.', 'kk': 'Біз қоршау кодын автоматты түрде құру тапсырмасын бірінші қадамды, яғни, бағдарламаның өзгерістерін қолдану үшін жүктеу үшін қолданылатын кішкентай кодының тапсырмасын жасау үшін бірінші қадамд Біз романдық деректер жинақтарын (Shellcode_ IA32) жинақтаймыз. Бірақ олардың тәуелді тілдерінің сипаттамасының жалпы мәліметтері болады. Біз бұл тапсырманың негізгі жұмыс деңгейін орнату үшін невралдық машинаның аудару (NMT) стандартты әдістерімен тәжірибелеміз.', 'ml': 'സ്വാഭാവികമായ ഭാഷയുടെ വിവരങ്ങളില്\u200d നിന്നും തുടങ്ങുന്നതില്\u200d നിന്നും സ്വാഭാവികമായ ഭാഷയുടെ വിവരങ്ങളില്\u200d നിന്നും സ്വാഭാവികമായ ഭാഷയുടെ വിവരങ്ങളില്\u200d  നമ്മള്\u200d ഒരു നോവല്\u200d ഡാറ്റാസേറ്റ് സംഘടിപ്പിക്കുകയും, അവരുടെ സ്വാഭാവ ഭാഷയുടെ വിവരണങ്ങള്\u200d കൊണ്ട് സാധാരണമായ സഭയുടെ ഉപദേശങ്ങള്\u200d  ഈ ജോലിയില്\u200d ബെസ്റ്റലൈന്\u200d പ്രവര്\u200dത്തനങ്ങള്\u200d നിര്\u200dമ്മിക്കുന്നതിനുള്ള നെയുറല്\u200d യന്ത്രത്തിന്\u200dറെ പരിഭാഷകളില്\u200d സ്ഥാനമ', 'mk': 'Ние го преземаме првиот чекор за да ја решиме задачата на автоматско генерирање на shellcodes, т.е. мали парчиња код кои се користат како корисно товарување во експлоатацијата на софтверската ранливост, почнувајќи од природните јазични коментари. We assemble and release a novel dataset (Shellcode_IA32), consisting of challenging but common assembly instructions with their natural language descriptions.  We experiment with standard methods in neural machine translation (NMT) to establish baseline performance levels on this task.', 'mn': 'Бид анхны алхмыг автоматжуулахын тулд шалтгаан кодыг автоматжуулахын тулд хэрэглэгддэг жижиг хэсгүүдийг програм хангамжийн эмзэг байдлаас эхлээд хэрэглэгддэг. Бид шинэ өгөгдлийн санг (Shellcode_IA32) цуглуулж, гаргаж өгдөг. Бид энэ ажил дээр суурь шугам үйл ажиллагааны түвшин байгуулахын тулд мэдрэлийн машин хөгжүүлэх (NMT) стандарт аргыг туршиж үздэг.', 'no': 'Vi tar den første stegen til å adressa oppgåva for automatisk laging av skalkodar, dvs. små deler av kode som vert brukt som opplasting i ekspluatasjonen av eit programvare sårbarhet, som startar frå naturlege språk-kommentarar. Vi samler og slettar ei roman dataset (Shellcode_IA32), som inneheld vanskeleg, men felles samlingsinstruksjonar med naturspråkkskildringar. Vi eksperimenterer med standardmetodar i neuralmaskinsomsetjinga (NMT) for å setja opp baseline effektivå på denne oppgåva.', 'ms': 'We take the first step to address the task of automatically generating shellcodes, i.e., small pieces of code used as a payload in the exploitation of a software vulnerability, starting from natural language comments.  Kami mengumpulkan dan melepaskan set data baru (Shellcode_IA32), yang terdiri dari arahan mengumpulkan yang mencabar tetapi biasa dengan deskripsi bahasa alami mereka. Kami eksperimen dengan kaedah piawai dalam terjemahan mesin saraf (NMT) untuk menetapkan aras prestasi asas dalam tugas ini.', 'ro': 'Facem primul pas pentru a aborda sarcina de a genera automat shellcode, adică bucăți mici de cod folosite ca sarcină utilă în exploatarea unei vulnerabilități software, pornind de la comentariile limbajului natural. Asamblăm și lansăm un nou set de date (Shellcode_IA32), constând în instrucțiuni de asamblare dificile, dar comune, cu descrierile limbajului lor natural. Experimentăm metode standard în traducerea automată neurală (NMT) pentru a stabili nivelurile de performanță de bază pentru această sarcină.', 'mt': 'Aħna nieħdu l-ewwel pass biex nindirizzaw il-kompitu li jiġġeneraw awtomatikament il-shellcodes, jiġifieri biċċiet żgħar ta’ kodiċi użati bħala tagħbija ta’ użu fl-isfruttament ta’ vulnerabbiltà tas-softwer, li jibdew mill-kummenti tal-lingwa naturali. Aħna nġabru u nħarġu sett ta’ dejta ġdid (Shellcode_IA32), li jikkonsisti f’struzzjonijiet ta’ assemblaġġ komuni iżda ta’ sfida bid-deskrizzjonijiet tal-lingwa naturali tagħhom. Aħna ninsperimentaw b’metodi standard fit-traduzzjoni tal-magni newrali (NMT) biex nistabbilixxu livelli ta’ prestazzjoni fil-linja bażi fuq dan il-kompitu.', 'sr': 'Prvi korak da se obratimo zadatku automatskog generiranja šelskih kodova, tj. malih komada koda koji se koristi kao opterećenje u ekspluataciji softvera ranjivosti, počevši od prirodnih jezičkih komentara. Skupljamo i oslobodimo novi set podataka (Shellcode_IA32), sastavljajući od izazovnih, ali zajedničkih instrukcija skupljanja sa njihovim prirodnim jezikom opisivanjem. Eksperimentiramo sa standardnim metodama u prevodu neuralne mašine (NMT) kako bi uspostavili nivo izvođenja početne linije na ovom zadatku.', 'so': 'Waxaynu qaadannaa tallaabo ugu horeysa si aan u sheekeyno shaqada si aan automatic ahaanshaha u sameeyo codsiga, tusaale ahaan qeybo yar oo qodob ah oo loogu isticmaalay isticmaalka dhibaatada dhaqaalaha software, waxaana ka bilaabaynaa commentarka afka asalka ah. Waxaannu soo ururinaynaa oo soo bixinaynaa taariikhda warqada qoyska (Shellcode_IA32), kaas oo ka mid ah dhibaatooyin, laakiin waxaa lagu hagaa hagitaanka ururka ee caadiga ah oo ku qoran qoraalka afkooda asalka ah. Waxaan ku imtixaamaynaa qaabab caadi ah oo ku qoran tarjumaadda maskaxda neurada (NMT) si aan u sameyno heerarka sameynta heerarka bandhigyada hoose-line.', 'si': 'අපි ස්වයංක්\u200dරියාවිතයෙන් ශෙල්කෝඩ් නිර්මාණය කරපු වැඩේ පළමු පැත්ත ගමන් කරනවා, ඉතින්, ප්\u200dරතිභාවිත භාෂාව ප්\u200dරකාරයක් වලින්  අපි සම්බන්ධ කරනවා ඒ වගේම ප්\u200dරතිභාවිත භාෂාව විස්තරයක් සමග සාමාන්\u200dය සම්බන්ධ කරනවා. අපි පරීක්ෂණය කරන්නේ න්\u200dයූරල් යන්ත්\u200dරය භාවිතාන (NMT) වල ස්ථානය ප්\u200dරමාණය සඳහා මේ වැඩේ පරීක්ෂණයේ ප්\u200dර', 'sv': 'Vi tar det första steget för att ta itu med uppgiften att automatiskt generera skalkoder, dvs. små bitar av kod som används som nyttolast vid utnyttjandet av en mjukvarusäkerhet, med utgångspunkt i naturliga språkkommentarer. Vi sammanställer och släpper ett nytt dataset (Shellcode_IA32), som består av utmanande men vanliga monteringsanvisningar med deras naturliga språkbeskrivningar. Vi experimenterar med standardmetoder inom neural machine translation (NMT) för att fastställa baseline prestandanivåer för denna uppgift.', 'ur': 'ہم نخستین قدم کو چلتے ہیں کہ شیلکوڈ کے پیدا کرنے کے کام کو اپنا کام کریں، یعنی سیلکوڈ کے چھوٹے ٹکڑے جو ایک سوفٹیور آسیب کی استعمال میں استعمال کئے جاتے ہیں، طبیعی زبان کی کمانٹوں سے شروع ہوتے ہیں. ہم ایک نئی ڈیٹ سٹ (Shellcode_IA32) کو جمع کریں اور آزاد کریں، جو ان کی طبیعی زبان کی توصیف کے ساتھ مشکل لیکن مشترک جماعت کی تعلیمات ہے۔ ہم نے نیورل ماشین ترجمہ (NMT) میں استاندارڈ طریقے کے ساتھ آزمائش کی کہ اس کام پر بنیس لین پرورش سطح قائم کریں.', 'pl': 'Podejmujemy pierwszy krok, aby rozwiązać zadanie automatycznego generowania shellodów, czyli małych kawałków kodu wykorzystywanych jako ładunek w eksploatacji luki oprogramowania, począwszy od komentarzy językowych naturalnych. Składamy i wydajemy nowatorski zestaw danych (Shellcode_IA32), składający się z trudnych, ale powszechnych instrukcji montażu wraz z ich opisami językowymi naturalnymi. Eksperymentujemy ze standardowymi metodami neuronowego tłumaczenia maszynowego (NMT), aby ustalić podstawowe poziomy wydajności w tym zadaniu.', 'ta': 'மென்பொருள் பாதுகாப்பில் பயன்படுத்தப்பட்ட மென்பொருள் தானாகவே குறியீடுகளை உருவாக்கும் சிறிய குறியீட்டு துண்டுகளை பயன்படுத்தப்பட்டுள்ளது,  நாம் ஒரு புதிய தரவுத்தளத்தை சேகரித்து வெளியேற்றுகிறோம் (Shellcode_ IA32), சவால் செய்யும் ஆனால் அவர்களுடைய இயற்கைய மொழி விவரி நாம் புதிய இயந்திரத்தின் மொழிபெயர்ப்பில் நிலையான முறைமைகளை சோதிக்கிறோம் இந்த பணியில் அடிப்படைக்கோடு செயல', 'vi': 'Chúng tôi có một bước đầu tiên để giải quyết nhiệm vụ tự động tạo ra các chiến trường (xem nhẹ) bằng các đoạn mã nhỏ được sử dụng để khai thác các lỗ hổng của phần mềm, bắt đầu từ các bình luận ngôn ngữ tự nhiên. Chúng tôi lắp ráp và phát hành một bộ dữ liệu mới (SỔ-ma), gồm những chỉ dẫn tập hợp đầy đủ với mô tả ngôn ngữ tự nhiên của chúng. Chúng tôi thử nghiệm với các phương pháp tiêu chuẩn trong dịch chuyển máy thần kinh (NMB) để thiết lập mức độ hiệu suất cơ bản trong nhiệm vụ này.', 'uz': "Biz avtomatik ishlab chiqarish vazifasini avtomatik yaratish uchun birinchi qadam qabul qilamiz. Masalan, dastur shaxsiyatlarini foydalanish uchun ishlatiladigan kichkina kodlash qismlari, asl tilni izohlashdan boshlanadi. Biz murakkab qiladigan va umumiy tilning taʼriflari bilan bog'liq maʼlumotlar tartibi (Shellcode_IA32) bilan birlashtiramiz. Biz bu vazifaning asosiy bajarish darajasini o'rnatish uchun neyrolik tarjima (NMT) bilan standard usullarni sinab qilamiz.", 'bg': 'Ние правим първата стъпка, за да се справим със задачата за автоматично генериране на шелкодове, т.е. малки парчета код, използвани като полезен товар при експлоатацията на софтуерна уязвимост, започвайки от коментари на естествен език. Събираме и пускаме нов набор от данни (състоящ се от предизвикателни, но общи инструкции за сглобяване с описанията на естествения език. Експериментираме със стандартни методи в невронния машинен превод (НМТ), за да установим базови нива на производителност по тази задача.', 'da': 'Vi tager det første skridt til at løse opgaven med automatisk generering af shellkoder, dvs. små stykker kode, der bruges som nyttelast i udnyttelsen af en software sårbarhed, med udgangspunkt i naturligt sprog kommentarer. Vi samler og udgiver et nyt datasæt (Shellcode_IA32), der består af udfordrende, men almindelige monteringsvejledninger med deres naturlige sprogbeskrivelser. Vi eksperimenterer med standardmetoder i neural machine translation (NMT) for at fastlægge baseline performance niveauer på denne opgave.', 'nl': 'We zetten de eerste stap om de taak aan te pakken om automatisch shellcodes te genereren, d.w.z. kleine stukjes code die worden gebruikt als payload bij het uitbuiten van een software kwetsbaarheid, te beginnen met opmerkingen in natuurlijke taal. We assembleren en brengen een nieuwe dataset (Shellcode_IA32) uit, bestaande uit uitdagende maar gangbare assemblage instructies met hun natuurlijke taalbeschrijvingen. We experimenteren met standaardmethoden in neural machine translation (NMT) om basisprestatieniveaus voor deze taak vast te stellen.', 'hr': 'Prvi korak radimo na rješavanju zadatka automatskog proizvodnje shellkoda, tj. malih komada koda koji se koristi kao opterećenje u ekspluataciji softvera ranjivosti, počevši od prirodnih jezičkih komentara. Skupljamo i objavljujemo novu kompletu podataka (Shellcode_IA32), koja se sastoji od izazovnih, ali zajedničkih uputa o skupštini s njihovim prirodnim jezikom opisima. Eksperimentiramo standardne metode u prevodu neuralnih strojeva (NMT) kako bi uspostavili početne razine učinka na ovom zadatku.', 'ko': '우리는 첫 번째 단계로 케이스 코드를 자동으로 생성하는 임무를 해결한다. 즉, 자연 언어 주석부터 소프트웨어의 빈틈을 이용할 때 유효한 하중으로 사용하는 작은 블록 코드를 사용한다.우리는 도전적이지만 흔히 볼 수 있는 어셈블리 명령과 자연 언어 설명으로 구성된 새로운 데이터 세트 (Shellcode IA32) 를 조립하고 발표했다.우리는 이 임무의 기본 성능 수준을 구축하기 위해 신경기계번역(NMT)의 표준 방법으로 실험을 진행했다.', 'de': 'Wir machen den ersten Schritt, um die Aufgabe der automatischen Erzeugung von Shellcodes, d.h. kleinen Codestücken, die als Payload bei der Ausnutzung einer Software-Schwachstelle verwendet werden, anzugehen, ausgehend von natursprachlichen Kommentaren. Wir bauen und veröffentlichen einen neuartigen Datensatz (Shellcode_IA32), bestehend aus anspruchsvollen, aber gängigen Montageanweisungen mit ihren natürlichen Sprachbeschreibungen. Wir experimentieren mit Standardmethoden in der neuronalen maschinellen Übersetzung (NMT), um Basisleistungsniveaus für diese Aufgabe festzulegen.', 'id': 'Kita mengambil langkah pertama untuk mengatasi tugas untuk secara otomatis menghasilkan shellcode, i.e., potongan kecil kode yang digunakan sebagai muatan payload dalam eksploitasi kecemasan perangkat lunak, dimulai dari komentar bahasa alam. Kami mengumpulkan dan melepaskan set data baru (Shellcode_IA32), yang terdiri dari instruksi pengumpulan yang menantang tetapi umum dengan deskripsi bahasa alami mereka. Kami eksperimen dengan metode standar dalam terjemahan mesin saraf (NMT) untuk menentukan tingkat prestasi dasar dalam tugas ini.', 'sw': 'Tunachukua hatua ya kwanza kujadili jukumu la kutengeneza sheria za mkononi, yaani vipande vidogo vya sheria vilivyotumiwa kama malipo katika matumizi ya hali ya hatari ya programu, kuanzia kutoka kwenye maoni ya lugha za asili. Tunakusanya na kuachia seti ya taarifa za riwaya (Shellcode_IA32), yenye changamoto lakini maelekezo ya mkusanyiko wa kawaida kwa maelezo yao ya lugha ya asili. Tunajaribu kwa njia za kawaida katika tafsiri ya mashine ya ubongo (NMT) ili kuanzisha kiwango cha utendaji wa msingi katika kazi hii.', 'fa': 'ما اولین قدم را برای رسیدن به وظیفه تولید شیلکودهای خودکار انجام می دهیم، یعنی قطعات کوچک کد که به عنوان یک بار پرداخت در استفاده از یک نرم\u200cافزار آسیب\u200cآسیب است، از توضیح زبان طبیعی شروع می\u200cشود. ما یک مجموعه داده\u200cهای نویسی (Shellcode_IA32) را جمع می\u200cکنیم و آزاد می\u200cکنیم که از دستورات مشکل ولی مجموعه\u200cهای مشترک با توصیف زبان طبیعی آنها است. ما با روش\u200cهای استاندارد در ترجمه ماشین عصبی (NMT) آزمایش می\u200cکنیم تا سطح عملکرد پایین\u200cخط روی این کار را ثابت کنیم.', 'af': "Ons neem die eerste stap om die taak te adres van automaties genereer shellkodes, i.e. klein stukke kode wat gebruik word as 'n gelaai laai in die ekspluatasie van 'n sagteware vulnerabiliteit, begin van natuurlike taal kommentaar. Ons versamel en verlos 'n romaniese datastel (Shellcode_IA32), wat bestaan van pragtige, maar gemeenskaplike versameling instruksies met hul natuurlike taal beskrywings. Ons eksperimenteer met standaard metodes in neurale masjien vertaling (NMT) om basisline prestasie vlakke op hierdie taak te stel.", 'am': 'የሶፍትዌር ቋንቋ አካሄዱን በመጠቀም የሶፍትዌር ደካማነት ለመጠቀም የሚጠቀሙትን ስራዎችን በራስነት ለመፍጠር የመጀመሪያ ደረጃን እንወስዳለን፡፡ አዲስ የጉዳዩ ጉዳይ ግን በተፈጠረው ቋንቋቸው ጽሑፎች የተጠቃሚ የጉባኤ ትምህርት ትምህርት እናሰብስባቸዋለን፡፡ በዚህ ስራ ላይ የጥያቄ የድምፅ ደረጃዎችን ለመሠረት የናውሬል መሣሪያን ትርጉም (NMT) እናሞክራለን፡፡', 'tr': 'Biz öz-özüne shellkoda döretmäge ilkinji adım çykýarys, diýipdir kiçi köd bölekleri saýlamak üçin bir softwaryň hasaplanyşlygyny ulanmak üçin, tebigy dilden terjimelerden başlaýarys. Biz bir roman sanatyny (Shellcode_IA32) çykyş we çykyş edip, tebigy dilleriniň tassymlaryny bilen birleşdirdik. Biz neural maşynyň terjimesinde (NMT) standart metodlary bilen bu işiň üstünde esasy çykyş derejesini çykarmak üçin synanyşýarys.', 'bn': 'আমরা স্বয়ংক্রিয়ভাবে শেল কোড তৈরি করার কাজ নিয়ে প্রথম পদক্ষেপ নেই, যেমন স্বাভাবিক ভাষা মন্তব্য থেকে প্রাকৃতিক মন্তব্য থেকে শুরু করা ছোট কোডে আমরা একটি উপন্যাসের তথ্য সংগ্রহ করি এবং মুক্তি দেই (শেলকোড_ আইএ৩২), যার মধ্যে চ্যালেঞ্জের কিন্তু তাদের প্রাকৃতিক ভাষার আমরা নিউরুল মেশিন অনুবাদের (এনএমটি) মাধ্যমে নির্ধারিত পদ্ধতি দিয়ে পরীক্ষা করছি এই কাজে বেসালাইনের প্রদর্শনীর স্তর স', 'hy': 'Մենք առաջին քայլն ենք անում, որպեսզի լուծենք խնդիրը, որն այն է, որ ինքնաբերաբար ստեղծենք կեղծ կոդներ, այսինքն՝ փոքրիկ կոդներ, որոնք օգտագործվում են որպես օգտակար բեռ բեռ ծրագրային խոցելիության օգտագործման մեջ, սկսած Մենք հավաքում և հրապարակում ենք նոր տվյալների համակարգ (Շելկոդ_ԻԱ32), որը կազմում է մարտահրավերներ, բայց ընդհանուր համակարգչային հրահանգներ իրենց բնական լեզվի նկարագրություններով: Մենք փորձում ենք ստանդարտ մեթոդներով նյարդային մեքենայի թարգմանման (NMT) միջոցով, որպեսզի սահմանենք այս խնդրի հիմնական արդյունավետության մակարդակը:', 'az': 'Biz ilk adımı sürükləyirik ki, təbiətli dil şəkillərindən başlayıb, proqramların zəifliklərinin istifadəsində istifadə edilən küçük kodun parçalarını təkrar-təkrar yaratmaq üçün istifadə edirik. Biz yeni verilən quruluşu (Shellcode_IA32) yığırıq və yayınlıq edirik. Bu, təbiətli dillərinin yazılımları ilə çətinlikləyici, müxtəlif but common assembly instructions. Biz bu işin əsas səviyyələrini təyin etmək üçün nöral maşına çevirilməsi (NMT) standart metodları ilə təcrübə edirik.', 'sq': 'Ne marrim hapin e parë për të trajtuar detyrën e krijimit automatik të kodeve shell, i.e., copa të vogla kodesh të përdorura si një ngarkesë të dobishme në shfrytëzimin e vulnerabilitetit të programit, duke filluar nga komentet natyrore të gjuhës. Ne mbledhim dhe lëshojmë një set të dhënash të reja (Shellcode_IA32), që përbëhet nga udhëzime të vështira por të përbashkëta të mbledhjes me përshkrimin e tyre natyror të gjuhës. Ne eksperimentojmë me metoda standarde në përkthimin e makinave nervore (NMT) për të vendosur nivelet bazë të performancës në këtë detyrë.', 'bs': 'Prvi korak da se obratimo zadatku automatskog proizvodnje šelskih kodova, tj. malih komadića koda koji se koristi kao opterećenje u ekspluataciji softvera ranjivosti, počevši od prirodnih jezičkih komentara. Skupljamo i objavljujemo novu kompletu podataka (Shellcode_IA32), koja se sastoji od izazovnih ali zajedničkih instrukcija skupljanja sa njihovim prirodnim jezikom opisima. Eksperimentiramo sa standardnim metodama u prevodu neuralne mašine (NMT) kako bi uspostavili nivo izvođenja početne linije na ovom zadatku.', 'ca': "Prenem el primer pas per abordar la tasca de generar automàticament codis shell, és a dir, petites peces de codi utilitzades com a càrrega útil en l'explotació d'una vulnerabilitat del software, començant dels comentaris del llenguatge natural. Recopilem i publicam un nou conjunt de dades (Shellcode_IA32), que consisteix en instruccions de montatge difícils però comunes amb les seves descripcions de llenguatge natural. Experimentem amb mètodes estàndard en la traducció neural de màquines (NMT) per establir nivells de rendiment basals en aquesta tasca.", 'et': 'Alustades looduskeelsetest kommentaaridest, astume esimese sammu, et tegeleda automaatselt shellkoodide genereerimisega, st väikeste kooditükkide genereerimisega, mida kasulikuks koormuseks kasutatakse tarkvara haavatavuse kasutamisel. Koostame ja avaldame uudse andmekogumi (Shellcode_IA32), mis koosneb keerulistest, kuid ühistest koostamisjuhistest koos looduskeele kirjeldustega. Eksperimenteerime standardmeetoditega neuro masintõlkes (NMT), et määrata selle ülesande algtasemed.', 'fi': 'Otamme ensimmäisen askeleen vastataksemme tehtävään luoda automaattisesti shellkodeja eli pieniä koodinpaloja, joita käytetään hyötykuormana ohjelmistohaavoittuvuuden hyödyntämisessä, alkaen luonnollisen kielen kommenteista. Kokoamme ja julkaisemme uuden aineiston (Shellcode_IA32), joka koostuu haastavista mutta yhteisistä kokoonpanoohjeista ja niiden luonnollisen kielen kuvauksista. Kokeilemme standardimenetelmiä neurokonekäännöksessä (NMT) määrittääksemme lähtötason suorituskykytasot tässä tehtävässä.', 'cs': 'Prvním krokem je řešit úkol automatického generování shellkódů, tedy malých kousků kódu používaných jako užitečné zatížení při využití softwarové zranitelnosti, počínaje přirozenými jazykovými komentáři. Sestavujeme a uvolňujeme novou datovou sadu (Shellcode_IA32), sestávající z náročných, ale běžných montážních instrukcí s jejich popisem přirozeného jazyka. Experimentujeme se standardními metodami neuronového strojového překladu (NMT) pro stanovení základních úrovní výkonnosti pro tento úkol.', 'jv': 'Awak dhéwé éntuk perusahaan tanggal nggambar aturan kanggo nggawe shell-kode, dadi bener, sing uwis kuwi nggawe nguasakno karo perusahaan kanggo nguasakno perusahaan perangkat sing apik dhéwé, sampek tanggal nggo kuwi perusahaan anyar Awak dhéwé ngêmên lan mbukaké batir dataset (shell kode_IB32), sing berarti karo nggawe barang ngêmên, kuwi ngêmên sesuk sabên langgar sapa adalah. Awak dhéwé éntuk saalan karo sistem sing dibenalke kapan ning tarjamahan (NMT) kanggo nggawe barang nggawe barang pengguna nggawe barang iki.', 'sk': 'Naredimo prvi korak, da se lotimo naloge samodejnega generiranja shellkodes, tj. majhnih kosov kode, ki se uporabljajo kot koristni obremenitev pri izkoriščanju ranljivosti programske opreme, začenši s komentarji naravnega jezika. Sestavljamo in izdajamo nov nabor podatkov (Shellcode_IA32), ki je sestavljen iz zahtevnih, vendar skupnih navodil za sestavljanje z opisi naravnega jezika. Eksperimentiramo s standardnimi metodami v nevronskem strojnem prevajanju (NMT), da bi določili osnovne ravni učinkovitosti pri tej nalogi.', 'ha': 'We take the first step to address the task of automatically generating shellcodes, i.e., small pieces of code used as a payload in the exploitation of a software vulnerability, starting from natural language comments.  Munã tãra kuma Muke sakar da wani tsari na takardar aiki (Shellcode_IA32), mai ƙiyayya da kuma masu shiryarwa na haɗuwa da kuma da tsarin sunayen zaman rubutu. Tuna jarraba da metode na daidaita cikin fassarar maɓallin neura (NMT) dõmin a tabbatar da daraja na gyaran aiki a kan wannan aikin.', 'he': 'אנחנו לוקחים את הצעד הראשון כדי להתמודד עם המשימה של ליצור אוטומטי קודים מוצפים, כלומר, חתיכות קטנות של קוד שמשתמשים כעומס משימוש בניצחון של פגיעות תוכנה, מתחילה מהתגובות טבעיות לשפה. אנו מאסיפים ופרסמים קבוצת נתונים חדשה (Shellcode_IA32), שמכילה בהוראות האיסוף המתאימה אבל משותפת עם תיאור השפה הטבעי שלהם. We experiment with standard methods in neural machine translation (NMT) to establish baseline performance levels on this task.', 'bo': 'ང་ཚོས་རང་འགུལ་གྱིས་སྦྱར་ཡིག་གཟུགས་རིས་གསར་འཛུགས་པའི་ལས་འགུལ་གྱི་ཐེངས་དང་པོ་ཞིག་ལ་བགོ་སྤྱད་ནས། ང་ཚོས་གསར་གཏོད་ཀྱི་ཆ་འཕྲིན་ཡིག་ཆ་ཞིག་བསྡད་བྱེད་ཀྱི་རྒྱུ་དངོས་འཛིན་བྱེད་ཀྱི་ཡོད། ང་ཚོས་རང་ཉིད་ཀྱི་མི་རྩིས་འཁོར་གྱི་འགྲེལ་བཤད་ཀྱི་ཚད་རྩིས་བྱས་ནས་གནད་གཤིས་འགྲུལ་སྐྱོད་ཚད་འདི་དང་མཐུན་བཟ'}
{'en': 'Reading StackOverflow Encourages Cheating : Adding Question Text Improves Extractive Code Generation S tack O verflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation', 'ar': 'تشجع القراءة StackOverflow الغش: تؤدي إضافة نص السؤال إلى تحسين إنشاء الشفرة الاستخراجية', 'es': 'Leer StackOverflow fomenta las trampas: agregar texto de pregunta mejora la generación de código extractivo', 'pt': 'Ler o StackOverflow incentiva a trapaça: adicionar texto de pergunta melhora a geração de código extrativo', 'fr': "Lire StackOverflow encourage la triche\xa0: l'ajout de texte de question améliore la génération de code extractif", 'ja': 'StackOverflowの読み取りで不正行為が奨励される:質問テキストを追加すると、抽出コードの生成が改善されます', 'zh': '读堆栈溢劝作弊:添问文本可改进提取代码生', 'hi': 'StackOverflow पढ़ना धोखा देने को प्रोत्साहित करता है: प्रश्न पाठ जोड़ने से निष्कर्षण कोड जनरेशन में सुधार होता है', 'ru': 'Чтение StackOverflow поощряет обман: добавление текста вопроса улучшает генерацию кода извлечения', 'ga': 'Spreagann Léitheoireacht StackOverflow Caimiléireacht: Má chuirtear Téacs Ceist Leis Feabhsaíonn Giniúint Cód Eastóscach', 'ka': 'კითხვის ტექსტის დამატება ექსტრაქტური კოდის შექმნა', 'hu': 'Az olvasás StackOverflow ösztönzi a csalást: a kérdésszöveg hozzáadása javítja a kivonatos kód generálását', 'el': 'Η ανάγνωση ενθαρρύνει την απάτη: Η προσθήκη κειμένου ερωτήσεων βελτιώνει την παραγωγή αποσπαστικού κώδικα', 'it': "Reading StackOverflow incoraggia l'inganno: l'aggiunta di testo delle domande migliora la generazione di codice estrattivo", 'kk': 'Сұрақ мәтіні қосу - тарқату кодын құру', 'lt': 'Skaitymas „StackOverflow“ skatina sukčiavimą: klausimo teksto papildymas gerina ekstraktyvių kodų kūrimą', 'mk': 'Читањето на табелата ги охрабрува мамењето: Додавањето на текст на прашања ја подобрува генерацијата на екстрактивен код', 'ms': 'Membaca StackOverflow Encouragement Penipuan: Menambah Teks soalan meningkatkan Penjanaan Kod Ekstraktif', 'ml': 'സ്റ്റാക്ക് വായിക്കുന്നുOverflow Encourages Cheating: ചോദ്യം ചേര്\u200dക്കുന്ന പദാവലി കോഡ് പ്രാവര്\u200dത്തികമാക്കുന്നു', 'mt': 'Il-qari ta’ StackOverflow jinkoraġġixxi l-ingaġġ: iż-żieda tat-test tal-mistoqsija ttejjeb il-ġenerazzjoni tal-Kodiċi Estrattiv', 'mn': 'StackOverflow-ын унших хөгжлийн шалтгаан: асуулт бичсэн нэмэх нь нэмэгдүүлэх кодыг бүтээх', 'no': 'Les StackOverflow-kodingar Cheating: Legg til spørsmåltekst forbetrar utpakkende kode', 'pl': 'Czytanie StackOverflow zachęca do oszustwa: dodawanie tekstu pytania usprawnia generowanie kodu ekstrakcyjnego', 'ro': 'Citirea StackOverflow încurajează înșelăciunea: adăugarea textului întrebărilor îmbunătățește generarea de coduri extractive', 'sr': 'Čitanje StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation', 'so': 'Reading StackOverflow Encourages Cheating: Additing Question Text Improves Extractive Code Generation', 'ta': 'கேள்வி உரையை சேர்த்து வெளியேற்ற குறியீடு உருவாக்கத்தை மாற்றுகிறது', 'sv': 'Reading StackOverflow uppmuntrar fusk: Lägga till frågetext förbättrar extraktiv kodgenerering', 'ur': 'StackOverflow Encourages Cheating پڑھا جاتا ہے: سوال کے متن زیادہ کرنا اضافہ کی کوڈ پیدا کرتا ہے', 'si': 'ස්ටැක්වර්ෆලෝව් සංකේතනය කියනවා චීට්: ප්\u200dරශ්න පාළුව සම්පූර්ණය කරන්න ප්\u200dරශ්න පාළුවට ප්\u200dරශ', 'vi': 'Đọc dãy nhà quá trình Điều khiển: Thêm văn bản câu hỏi cải thiện tạo mật mã', 'uz': 'Overflow Encourages Cheating: Add Query Text Improves Extractive Code Generation', 'bg': 'Четенето насърчава измамата: добавянето на текст на въпроси подобрява генерирането на извличащ код', 'hr': 'Čitanje StackOverflow poticaja prevara: dodavanje pitanja teksta poboljšava proizvodnju kodova', 'id': 'Membaca StackOverflow Encourages Penipuan: Menambah Teks Pertanyaan meningkatkan Generasi Kode Ekstraktif', 'de': 'Lesen von StackOverflow fördert Betrug: Hinzufügen von Fragentext verbessert die extraktive Codegenerierung', 'fa': 'خواندن سقف\u200cگریز انگیزه\u200cهای خیانت: اضافه کردن متن سوال، تولید کد خارجی را بهتر می\u200cکند', 'sw': 'Kusoma Msimamo', 'nl': 'Het lezen van StackOverflow moedigt fraude aan: het toevoegen van vraagtekst verbetert het genereren van extractieve code', 'da': 'Læsning StackOverflow opfordrer til snyd: Tilføjelse af spørgsmålstekst forbedrer genereringen af ekstrakt kode', 'sq': 'Leximi i StackOverflow inkurajon mashtrimin: shtimi i tekstit të pyetjes përmirëson gjenerimin e kodit ekstraktiv', 'tr': 'StackOverflow Ködlemeler Saýlaw: Sorag Metini Eklemek Iňleýär Açmak Ködleme', 'am': 'Overflow Encourages Cheating: Adding Question Text Improves Extract Code Generation', 'ko': 'StackOverflow 읽기 부정행위 권장: 질문 텍스트를 추가하면 추출 코드 생성 향상', 'hy': 'Կարելով StackoverFlow խրախուսում է խաբել. Հարցման տեքստի ավելացումը բարելավում է արտադրողական կոդի ստեղծումը', 'bn': 'প্রশ্ন টেক্সট যোগ করা হচ্ছে এক্সট্র্যাক্ট কোড জেনারেশন', 'az': 'StackOverflow Encourages Cheating: sual metini əlavə etmək ekstraktif kodu yaratmasını yaxşılaşdırır', 'ca': 'Llegir StackOverflow alenta a enganyar: afegir text de pregunta millora la generació de codi extractiv', 'af': 'Lees StackOverflow Encourages Cheating: Voeg by Vrag Teks Verbeter Ekstraktiewe Kode Generasie', 'et': 'Lugemine StackOverflow ergutab petmist: küsimusteksti lisamine parandab ekstraktiivse koodi genereerimist', 'bs': 'Čitanje StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation', 'fi': 'Lukeminen StackOverflow kannustaa huijaamaan: Kysymystekstin lisääminen parantaa ekstraktiivisen koodin luomista', 'cs': 'Čtení StackOverflow podporuje podvádění: Přidání textu otázky zlepšuje generování extraktivního kódu', 'jv': 'Ngawe StackOF10 Walian Senegal Kebebasan: nambah Panguna Kemerdekaan Seng Buk Ketok', 'ha': 'Surcurrent', 'sk': 'Branje StackOverflow spodbuja goljufanje: dodajanje besedila vprašanj izboljša ustvarjanje ekstraktivne kode', 'bo': 'StackOverflow སྒྲིག་འགོད་ཀློག་འཇུག་སྟངས་འདྲི་ཞིབ་བྱེད། དྲི་ཚིག་ཡིག་གེ་ཁ་སྣོན་བྱེད་བཞིན་པའི་འཕགས', 'he': 'קריאת עודדות מעל שלב בגידה: הוספת טקסט שאלות משפר את יצירת קוד חיצוני'}
{'en': 'Answering a programming question with only its title is difficult as salient contextual information is left out. To address this, we present a  corpus  of over 40,000 StackOverflow question texts to be used in conjunction with the corresponding intents from the CoNaLa dataset (Yin et al., 2018). Using both the  intent  and the question body, we use  BART  to establish a baseline BLEU score of 34.35 for this new task. We then find further improvements of 2.8 % by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score. We then evaluate the prior state-of-the-art CoNaLa models with this additional  data . We find that our proposed  method  of using the body and mined data beats that of the previous  state-of-the-art  by a 71.96 % BLEU score. Finally, we perform ablations that prove that BART is an unsupervised multimodal learner and examine its extractive behavior.', 'ar': 'من الصعب الإجابة على سؤال برمجي بعنوانه فقط حيث يتم استبعاد المعلومات السياقية البارزة. لمعالجة هذا الأمر ، نقدم مجموعة تضم أكثر من 40000 نص من أسئلة StackOverflow لاستخدامها مع المقاصد المقابلة من مجموعة بيانات CoNaLa (Yin et al. ، 2018). باستخدام كل من النية وهيئة السؤال ، نستخدم BART لإنشاء درجة BLEU الأساسية 34.35 لهذه المهمة الجديدة. وجدنا بعد ذلك تحسينات إضافية بنسبة 2.8٪ من خلال دمج بيانات CoNaLa الملغومة مع البيانات المصنفة لتحقيق درجة 35.32 BLEU. نقوم بعد ذلك بتقييم نماذج CoNaLa الحديثة السابقة بهذه البيانات الإضافية. وجدنا أن طريقتنا المقترحة لاستخدام الجسم والبيانات المستخرجة تتفوق على الأسلوب الحديث السابق بنسبة 71.96٪ BLEU. أخيرًا ، نجري عمليات استئصال تثبت أن BART هو متعلم متعدد الوسائط غير خاضع للإشراف ونفحص سلوكه الاستخراجي.', 'fr': "Il est difficile de répondre à une question de programmation uniquement avec son titre, car les informations contextuelles importantes sont omises. Pour y remédier, nous présentons un corpus de plus de 40 000 textes de questions StackOverflow à utiliser conjointement avec les intentions correspondantes du jeu de données ConALA (Yin et al., 2018). En utilisant à la fois l'intention et le corps de la question, nous utilisons BART pour établir un score de base de 34,35 pour cette nouvelle tâche. Nous constatons ensuite d'autres améliorations de 2,8\xa0% en combinant les données extraites du ConALA avec les données marquées pour obtenir un score BLEU de 35,32. Nous évaluons ensuite les modèles ConALA de pointe antérieurs à l'aide de ces données supplémentaires. Nous constatons que la méthode que nous proposons d'utiliser le corps et les données extraites surpasse celle de la technologie précédente d'un score BLEU de 71,96\xa0%. Enfin, nous effectuons des ablations qui prouvent que BART est un apprenant multimodal non supervisé et examinons son comportement extractif.", 'es': 'Responder a una pregunta de programación solo con su título es difícil, ya que la información contextual más destacada queda fuera. Para abordar esto, presentamos un corpus de más de 40.000 textos de preguntas de StackOverflow que se utilizarán junto con las intenciones correspondientes del conjunto de datos de ConAla (Yin et al., 2018). Utilizando tanto la intención como el cuerpo de la pregunta, utilizamos BART para establecer una puntuación BLEU de referencia de 34,35 para esta nueva tarea. Luego encontramos mejoras adicionales del 2.8% al combinar los datos extraídos de ConAla con los datos etiquetados para lograr una puntuación BLEU de 35.32. A continuación, evaluamos los modelos CoNala de última generación anteriores con estos datos adicionales. Descubrimos que nuestro método propuesto para usar el cuerpo y los datos minados supera al del estado de la técnica anterior en una puntuación BLEU del 71,96%. Finalmente, realizamos ablaciones que demuestran que BART es un estudiante multimodal no supervisado y examinamos su comportamiento extractivo.', 'pt': 'Responder a uma pergunta de programação apenas com seu título é difícil, pois informações contextuais importantes são deixadas de fora. Para resolver isso, apresentamos um corpus de mais de 40.000 textos de perguntas do StackOverflow para serem usados em conjunto com as intenções correspondentes do conjunto de dados CoNaLa (Yin et al., 2018). Usando a intenção e o corpo da pergunta, usamos o BART para estabelecer uma pontuação BLEU de linha de base de 34,35 para essa nova tarefa. Em seguida, encontramos melhorias adicionais de 2,8%, combinando os dados CoNaLa extraídos com os dados rotulados para obter uma pontuação BLEU de 35,32. Em seguida, avaliamos os modelos CoNaLa de última geração com esses dados adicionais. Descobrimos que nosso método proposto de usar o corpo e os dados extraídos supera o do estado da arte anterior por uma pontuação BLEU de 71,96%. Finalmente, realizamos ablações que comprovam que BART é um aprendiz multimodal não supervisionado e examinamos seu comportamento extrativo.', 'ja': '顕著な文脈情報が省略されているため、タイトルだけでプログラミングの質問に答えるのは難しい。これに対処するために、私たちは、CoNaLaデータセットからの対応するインテントと組み合わせて使用される40,000を超えるStackOverflow質問テキストのコーパスを提示します（ Yin et al., 2018 ）。意図と質問の本文の両方を使用して、BARTを使用して、この新しいタスクのベースラインBLEUスコア34.35を確立します。次に、採掘されたCoNaLaデータとラベル付けされたデータを組み合わせて、35.32 BLEUスコアを達成することによって、2.8%のさらなる改善を見出す。次に、この追加データを使用して、従来の最先端のCoNaLaモデルを評価します。私たちは、本体と採掘データを使用するための提案された方法が、71.96 ％のBLEUスコアで以前の最先端のものを上回っていることを発見しました。最後に、BARTが監督されていないマルチモーダル学習者であることを証明するアブレーションを行い、その抽出行動を検討します。', 'zh': '答曰:唯题编程为难,略省上下文信也。 为此者,举一过40,000StackOverflow问文本之语料库,与CoNaLa数合用(Yin等,2018)。 用意向正文,我用 BART 为之基线BLEU分 34.35。 然后CoNaLa数合于标数,更进为2.8%,至于35.32 BLEU分。 然后以此数质先进之CoNaLa。 臣等见用身掘数,视前最先进71.96%BLEU分。 最后行消释,证BART无监督多模态学器,并检其提取。', 'ru': 'Ответить на вопрос программирования только с его названием сложно, поскольку важная контекстуальная информация остается в стороне. Для решения этой проблемы мы представляем корпус из более чем 40 000 текстов вопросов StackOverflow, которые будут использоваться в сочетании с соответствующими намерениями из набора данных CoNaLa (Yin et al., 2018). Используя как цель, так и тело вопроса, мы используем БАРТА, чтобы установить исходный балл BLEU 34,35 для этой новой задачи. Затем мы находим дальнейшие улучшения на 2,8%, объединив добытые данные CoNaLa с маркированными данными, чтобы достичь 35,32 балла BLEU. Затем мы оцениваем предыдущие современные модели CoNaLa с помощью этих дополнительных данных. Мы обнаружили, что предлагаемый нами метод использования данных об организме и добыче превосходит предыдущий по уровню развития на 71,96% BLEU. Наконец, мы выполняем абляции, которые доказывают, что БАРТ является неконтролируемым мультимодальным учеником, и исследуем его экстрактивное поведение.', 'hi': 'केवल इसके शीर्षक के साथ एक प्रोग्रामिंग प्रश्न का उत्तर देना मुश्किल है क्योंकि मुख्य प्रासंगिक जानकारी छोड़ दी जाती है। इसे संबोधित करने के लिए, हम 40,000 से अधिक स्टैकओवरफ्लो प्रश्न ग्रंथों का एक कॉर्पस प्रस्तुत करते हैं, जिसका उपयोग CoNaLa डेटासेट (यिन एट अल। इरादा और प्रश्न निकाय दोनों का उपयोग करते हुए, हम इस नए कार्य के लिए 34.35 के बेसलाइन BLEU स्कोर को स्थापित करने के लिए BART का उपयोग करते हैं। फिर हम 35.32 BLEU स्कोर प्राप्त करने के लिए लेबल किए गए डेटा के साथ खनन किए गए CoNaLa डेटा के संयोजन से 2.8% के आगे सुधार पाते हैं। फिर हम इस अतिरिक्त डेटा के साथ पूर्व अत्याधुनिक CoNaLa मॉडल का मूल्यांकन करते हैं। हम पाते हैं कि शरीर और खनन किए गए डेटा का उपयोग करने की हमारी प्रस्तावित विधि 71.96% BLEU स्कोर द्वारा पिछले राज्य-कला की धड़कन है। अंत में, हम एब्लेशन करते हैं जो साबित करते हैं कि BART एक असुरक्षित बहुआयामी शिक्षार्थी है और इसके निष्कर्षण व्यवहार की जांच करता है।', 'ga': 'Tá sé deacair ceist ríomhchlárúcháin a bhfuil an teideal uirthi amháin a fhreagairt mar fágtar eolas comhthéacsúil suntasach as. Chun aghaidh a thabhairt air seo, cuirimid corpas os cionn 40,000 téacs ceiste StackOverflow i láthair le húsáid in éineacht leis na hintinn chomhfhreagracha ó thacar sonraí CoNaLa (Yin et al., 2018). Agus an rún agus an comhlacht ceisteanna á úsáid againn, bainimid úsáid as BART chun scór BLEU bonnlíne de 34.35 a bhunú don tasc nua seo. Ansin aimsímid tuilleadh feabhsuithe de 2.8% trí shonraí CoNaLa a mhianaíodh a chomhcheangal leis na sonraí lipéadaithe chun scór 35.32 BLEU a bhaint amach. Déanaimid measúnú ansin ar na múnlaí CoNaLa den scoth roimhe seo leis na sonraí breise seo. Feictear dúinn go sáraíonn an modh atá molta againn chun an corp agus sonraí mionnaithe a úsáid scór BLEU 71.96% a bhí ann roimhe seo. Mar fhocal scoir, déanaimid díbleachtaí a chruthaíonn gur foghlaimeoir ilmhódúil gan mhaoirseacht é BART agus scrúdaítear a iompar eastóscach.', 'ka': 'პროგრამების კითხვის გასაღება მხოლოდ მისი სათაური შესახებ ძალიან რთულია, რადგან კონტექსტური ინფორმაცია გადარჩენა. ამის შესახებ, ჩვენ აჩვენებთ 40 000 StackOverflow კითხვის ტექსტის კოპორსს, რომელიც გამოიყენება შესახებ CoNala მონაცემების კონფიგურაციის შესახებ (Yin et al., 2018). გამოყენებული საზოგადოება და კითხვის სხეულის გამოყენება, ჩვენ გამოყენებთ BART-ს, რომ ამ ახალი საზოგადოებისთვის მუშაობა BLEU-ს 34.35 წერტილი დავიყენოთ. შემდეგ ჩვენ მოვიძლიათ 2,8% უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო შემდეგ ჩვენ უნდა გავამუშავოთ პირველი მოდელების CoNala მოდელები ამ დამატებული მონაცემებით. ჩვენ აღმოჩნეთ, რომ ჩვენი წარმოადგილი მეტი, რომელიც სახელის და მინდომის მონაცემების გამოყენება, უფრო წინა წარმოადგილა წარმოადგილა წარმოადგილად 71,96% BLEU წარმო საბოლოოდ, ჩვენ ვაკეთებთ შესაძლებლობები, რომელიც გამოწვება, რომ BART არის მულტიმოდიალური სწავლებელი და გამოწმება მისი ექსტრაქტიური ქცევა.', 'hu': 'Egy programozási kérdésre kizárólag a címmel válaszolni nehéz, mivel a kiemelkedő kontextuális információk kimaradnak. Ennek megoldására több mint 40 000 StackOverflow kérdésszövegből álló korpuszt mutatunk be, amelyet a CoNaLa adatkészlet megfelelő szándékaival együtt használunk (Yin et al., 2018). Mind a szándék, mind a kérdés testét használva a BART segítségével állapíthatjuk meg az új feladat 34,35-ös alapszintű BLEU pontszámát. Ezt követően további 2,8%-os javulást találunk azzal, hogy kombináljuk a kibányászott CoNaLa adatokat a címkézett adatokkal, hogy elérjük a 35,32 BLEU pontszámot. Ezt követően értékeljük a korábbi, korszerű CoNaLa modelleket ezekkel a kiegészítő adatokkal. Úgy találjuk, hogy a test és a bányászati adatok felhasználásának javasolt módszere 71,96%-os BLEU pontszámmal meghaladja a korábbi korszerűségét. Végezetül olyan ablációkat végezünk, amelyek bizonyítják, hogy a BART felügyelet nélküli multimodális tanuló, és megvizsgáljuk annak extraktív viselkedését.', 'el': 'Η απάντηση σε μια ερώτηση προγραμματισμού με μόνο τον τίτλο της είναι δύσκολη καθώς οι σημαντικές πληροφορίες του περιβάλλοντος παραλείπονται. Για να αντιμετωπιστεί αυτό, παρουσιάζουμε ένα σώμα από πάνω από 40.000 ερωτικά κείμενα που θα χρησιμοποιηθούν σε συνδυασμό με τις αντίστοιχες προθέσεις από το σύνολο δεδομένων (Γιν κ.α., 2018). Χρησιμοποιώντας τόσο την πρόθεση όσο και το σώμα ερωτήσεων, χρησιμοποιούμε το BART για να καθορίσουμε μια βασική βαθμολογία BLEU 34.35 για αυτή τη νέα εργασία. Στη συνέχεια, βρίσκουμε περαιτέρω βελτιώσεις 2,8% συνδυάζοντας τα εξορυγμένα δεδομένα CoNaLa με τα επισημασμένα δεδομένα για να επιτύχουμε μια βαθμολογία 35.32 BLEU. Στη συνέχεια αξιολογούμε τα προηγούμενα μοντέλα τελευταίας τεχνολογίας με αυτά τα πρόσθετα δεδομένα. Διαπιστώνουμε ότι η προτεινόμενη μέθοδος χρήσης του σώματος και των εξορυκτικών δεδομένων ξεπερνά αυτή της προηγούμενης τελευταίας τεχνολογίας κατά 71,96% βαθμολογία BLEU. Τέλος, διεξάγουμε απολύσεις που αποδεικνύουν ότι το BART είναι ένας ασυνεπόπτης πολυμορφικός μαθητής και εξετάζουμε την εκχυλιστική του συμπεριφορά.', 'it': "Rispondere a una domanda di programmazione con solo il titolo è difficile in quanto le informazioni contestuali salienti vengono omesse. Per affrontare questo problema, presentiamo un corpus di oltre 40.000 testi di domande StackOverflow da utilizzare in combinazione con gli intenti corrispondenti dal dataset CoNaLa (Yin et al., 2018). Utilizzando sia l'intento che il corpo delle domande, usiamo BART per stabilire un punteggio BLEU di base di 34,35 per questa nuova attività. Troviamo quindi ulteriori miglioramenti del 2,8% combinando i dati CoNaLa estratti con i dati etichettati per ottenere un punteggio BLEU 35,32. Valutiamo quindi i precedenti modelli CoNaLa all'avanguardia con questi dati aggiuntivi. Troviamo che il nostro metodo proposto per utilizzare il corpo e i dati estratti batte quello del precedente stato dell'arte con un punteggio BLEU del 71,96%. Infine, eseguiamo ablazioni che dimostrano che BART è uno studente multimodale non supervisionato ed esaminiamo il suo comportamento estrattivo.", 'kk': 'Бағдарлама сұрағына тек айдарына жауап беру үшін тәуелсіздік мәліметі қалды. Бұл көмектесу үшін, CoNaLa деректер жиынының (Yin et al., 2018) қатынасыз керек мақсаттарымен қолданылатын 40 000 көп StackOverflow сұрақ мәтіндерін келтіреміз. Бұл жаңа тапсырма үшін негізгі BLEU нөмірін 34.35 деп қолданатын BART дегенді қолданамыз. Содан кейін 2,8% деген жақсы жақсартулар табылады. Коналаларды 35,32 BLEU нәтижесін жеткізу үшін мәліметтермен біріктіріп. Содан кейін біз CoNaLa моделдерін қосымша мәліметтермен оқу үшін оқу үшін. Біз денесі және материаларды қолдану әдісіміздің алдыңғы орындағы мәліметті 71,96% BLEU нөміріне жетілдіреді. Соңында, БАРТ көптеген көптеген бірнеше оқытушы болып, оның шығыс әрекетін тексеру үшін бағдарламаларды орындаймыз.', 'lt': 'Atsakyti į programavimo klausimą tik pavadinimu yra sunku, nes nepateikiama svarbi kontekstinė informacija. Siekdami išspręsti šį klausimą, pateiksime daugiau kaip 40 000 StackOverflow klausimų tekstų, kurie turi būti naudojami kartu su atitinkamais CoNaLa duomenų rinkinio tikslais (Yin et al., 2018 m.). Naudodamiesi ir ketinimu, ir klausimu grindžiamu organu, mes naudojame BART nustatydami bazinį BLEU 34,35 tašką šiai naujai užduotims. Tada ieškome papildomų 2,8 proc. patobulinimų, sujungdami minuojamus CoNaLa duomenis su pažymėtais duomenimis, kad būtų pasiektas 35,32 BLEU rezultatas. Tada vertiname ankstesnius pažangiausius CoNaLa modelius su šiais papildomais duomenimis. Mes manome, kad mūsų siūlomas kūno ir minų duomenų naudojimo metodas viršija ankstesnės pažangos metodą 71,96 proc. BLEU rezultatu. Galiausiai mes atliekame abliacijas, įrodančias, kad BART yra nepastebimas daugiarūšio mokymasis ir išnagrinėjame jo išgaunamąjį elgesį.', 'mk': 'Одговорот на прашањето за програмирање со само нејзината титула е тежок бидејќи истакнатите контекстни информации се оставени надвор. За да се реши ова, претставуваме корпус од повеќе од 40.000 тексти за прашања StackOverflow кои ќе бидат употребени заедно со соодветните намери од податоците на CoNaLa (Yin et al., 2018). Користејќи ја намерата и телото за прашање, користиме Барт за да поставиме основна оценка БЛЕУ од 34,35 за оваа нова задача. Потоа ќе најдеме понатамошни подобрувања од 2,8 отсто преку комбинација на минираните податоци од CoNaLa со обележаните податоци за да постигнеме 35,32 БЛЕУ резултат. Потоа ги проценуваме претходните најнови модели на Конала со овие дополнителни податоци. Најдовме дека нашиот предложен метод за употреба на телото и минираните податоци го претепува она од претходната најнова состојба со 71,96 отсто од БЛЕУ. Конечно, изведуваме аблации кои докажуваат дека БАРТ е ненадгледуван мултимодилен ученик и го испитуваме неговото извлекувачко однесување.', 'ms': 'Jawaban soalan pemrograman hanya dengan tajuk adalah sukar kerana maklumat kontekstual yang penting ditinggalkan. Untuk mengatasinya, kami memperkenalkan lebih dari 40,000 teks soalan StackOverflow yang akan digunakan bersama dengan niat yang sepadan dari set data CoNaLa (Yin et al., 2018). Menggunakan kedua-dua niat dan badan soalan, kita gunakan BART untuk menetapkan nilai BLEU dasar 34.35 untuk tugas baru ini. Kemudian kita jumpa peningkatan tambahan 2.8% dengan menggabungkan data CoNaLa yang dicampur dengan data yang ditabel untuk mencapai skor BLEU 35.32. Kemudian kita menilai model CoNaLa yang paling terakhir dengan data tambahan ini. Kami mendapati bahawa kaedah kami yang diusulkan untuk menggunakan tubuh dan data tambang mengalahkan bahawa keadaan-state-of-the-art terdahulu dengan skor BLEU 71.96%. Akhirnya, kami melakukan ablasi yang membuktikan bahawa BART adalah pelajar multimodal yang tidak diawasi dan memeriksa perilaku ekstraktifnya.', 'ml': 'ഒരു പ്രോഗ്രാമിങ്ങ് ചോദ്യം ഉത്തരം നല്\u200dകുന്നത് അതിന്\u200dറെ തലക്കെട്ട് മാത്രമാണെന്ന് മാത്രം ബുദ്ധിമുട് ഇതിനെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d, കോനാലാ ഡാറ്റാസേറ്റില്\u200d നിന്നുള്ള ഉത്തരവാദിത്വത്തോടൊപ്പം ഉപയോഗിക്കാന്\u200d 40,000 കോര്\u200dപ്പസ് സ്റ്റാ ഈ പുതിയ ജോലിക്കുള്ള ബെല്ലു ലൈന്\u200d സ്കോര്\u200d സ്ഥാപിക്കാന്\u200d ബാര്\u200dട്ടിനെ ഉപയോഗിക്കുന്നു. We then find further improvements of 2.8% by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score.  പിന്നെ നമ്മള്\u200d കൂടുതല്\u200d വിവരങ്ങളുമായി കോനാലാ മോഡലുകളെ വിലാസപ്പെടുത്തുന്നു. ഞങ്ങള്\u200d കണ്ടെത്തുന്നു ശരീരത്തിന്റെ പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയും മൈന്\u200d ഡേറ്റാ ഉപയോഗിക്കുന്നതും മുമ്പുള്ള സ്ഥാനത്തിന്റെ മ അവസാനം, ബാര്\u200dട്ട് സംരക്ഷിക്കപ്പെടാത്ത പല്ലിമോഡല്\u200d പഠിപ്പിക്കുന്നവനാണെന്ന് തെളിയിക്കുന്ന അഗ്നികങ്ങള്\u200d ഞങ്ങള്\u200d', 'mt': "It-tweġiba għal mistoqsija ta’ programmazzjoni bit-titolu tagħha biss hija diffiċli peress li l-informazzjoni kuntestwali essenzjali titħalla barra. Biex nindirizzaw dan, nippreżentaw korpus ta’ aktar minn 40,000 test ta’ mistoqsija StackOverflow li għandhom jintużaw flimkien mal-intenzjonijiet korrispondenti mis-sett tad-dejta CoNaLa (Yin et al., 2018). Bl-użu kemm tal-intenzjoni kif ukoll tal-korp tal-mistoqsijiet, a ħna nużaw il-BART biex nistabbilixxu punteġġ BLEU ta’ linja bażi ta’ 34.35 għal dan il-kompitu l-ġdid. Imbagħad isibu titjib ulterjuri ta' 2.8% billi ngħaqdu d-dejta mħawla ta' CoNaLa mad-dejta ttikkettata biex jinkiseb punteġġ BLEU ta' 35.32. Imbagħad jivvalutaw il-mudelli CoNaLa l-aktar avvanzati minn qabel b’din id-dejta addizzjonali. Aħna nsibu li l-metodu propost tagħna għall-użu tal-ġisem u d-dejta minjiera jegħleb dak tal-a ħħar avvanzat b’punteġġ BLEU ta’ 71,96 %. Finally, we perform ablations that prove that BART is an unsupervised multimodal learner and examine its extractive behavior.", 'mn': 'Програмчлалын асуултыг зөвхөн нэртэй хариулт өгөх нь хэцүү, яагаад гэвэл сайхан орчин үлдсэн мэдээлэл. Энэ талаар бодохын тулд бид CoNala өгөгдлийн сангийн холбоотой холбоотой холбоотой 40,000 гаруй StackOverflow асуултын текстүүдийн корпус илэрхийлдэг. Хоёр зорилго болон асуулт биеийг ашиглан бид БАРТ-г ашиглаж энэ шинэ ажил дээр суурь шугам BLEU 34.35 тоо байгуулахын тулд ашиглаж байна. Тэгээд бид хоосон CoNaLa өгөгдлийг 35.32 BLEU оноо гаргах үед нэмэгдсэн өгөгдлийн хувьд 2.8% улам сайжруулсан байна. Дараа нь бид өмнөх урлагийн CoNaLa загварыг нэмэлт мэдээллээр дүгнэж байна. Бид бие болон сүүрсэн өгөгдлийн хэрэглээ бидний санал болгосон арга нь өмнөх урлагийн үйл явдал 71.96% BLEU оноос ялгадаг. Эцэст нь, бид Барт бол олон төрлийн сурагч гэдгийг баталж, нэмэгдүүлэх үйл явцыг шалгана.', 'no': 'Svar eit program- spørsmål med berre tittelen er vanskeleg, sidan kontekstinformasjon er lagra ut. For å handtera dette, presenterer vi ei korpus med over 40 000 StackOverflow spørsmåltekst som skal brukast i samsvar med dei tilsvarande utformingane frå CoNaLa-datasettet (Yin et al., 2018). Når vi bruker både målet og spørsmålskroppen, bruker vi BART for å oppretta ein grunnlinje BLEU-score på 34,35 for denne nye oppgåva. Vi finn så fleire forbedringar av 2,8 % ved å kombinere minerte CoNaLa-data med dei merkelige data for å oppnå eit 35,32 BLEU-poeng. Vi evaluerer så den førre modellen CoNaLa-kunsten med denne ekstra data. Vi finn at vårt foreslått metode for å bruka kroppen og minerte data slår det av den førre kunsttilstanden med ein 71,96% BLEU-score. I slutt utfører vi tillegg som bevise at BART er ein ukjend multimodal lærar og undersøker ekstraktivt atferd.', 'ro': 'Răspunsul la o întrebare de programare numai cu titlul său este dificil, deoarece informațiile contextuale saliente sunt omise. Pentru a aborda acest lucru, prezentăm un corpus de peste 40.000 de texte de întrebări StackOverflow care vor fi utilizate împreună cu intențiile corespunzătoare din setul de date CoNaLa (Yin et al., 2018). Folosind atât intenția, cât și corpul de întrebare, folosim BART pentru a stabili un scor BLEU de bază de 34,35 pentru această nouă sarcină. Apoi găsim îmbunătățiri suplimentare de 2,8% prin combinarea datelor CoNaLa minate cu datele etichetate pentru a obține un scor BLEU 35,32. Apoi evaluăm modelele CoNaLa de ultimă oră cu aceste date suplimentare. Considerăm că metoda noastră propusă de utilizare a corpului și a datelor extrase depășește cea a ultimei state-of-the-art cu un scor BLEU de 71,96%. În cele din urmă, efectuăm ablații care dovedesc că BART este un elev multimodal nesupravegheat și examinăm comportamentul său extractiv.', 'pl': 'Odpowiedź na pytanie programowe tylko z jego tytułem jest trudna, ponieważ pominęto istotne informacje kontekstowe. Aby temu rozwiązać, przedstawiamy korpus ponad 40.000 tekstów pytań StackOverflow do wykorzystania w połączeniu z odpowiednimi intencjami ze zbioru danych CoNaLa (Yin et al., 2018). Wykorzystując zarówno intencję, jak i ciało pytania, używamy BART do ustalenia wyniku BLEU wynoszącego 34.35 dla tego nowego zadania. Następnie znajdujemy dalsze ulepszenia 2,8% poprzez połączenie wydobytych danych CoNaLa z oznaczonymi danymi, aby uzyskać wynik 35.32 BLEU. Następnie oceniamy poprzednie najnowocześniejsze modele CoNaLa z tymi dodatkowymi danymi. Stwierdzamy, że proponowana przez nas metoda wykorzystania ciała i wydobytych danych jest lepsza od poprzedniego stanu techniki o wynik 71,96% BLEU. Wreszcie wykonujemy ablacje, które udowadniają, że BART jest nienadzorowanym uczniem multimodalnym i badamy jego ekstrakcyjne zachowanie.', 'si': 'වැඩසටහන් ප්\u200dරශ්නයක් ප්\u200dරතික්\u200dරියා කරන්න එයාගේ ලිපිනය විතරයි ප්\u200dරශ්නයක් ප්\u200dරතික්\u200dරියා කරන්න අමාරු මේක සම්බන්ධ කරන්න, අපි ස්ටැක්වර්ෆල් ප්\u200dරශ්ණ ප්\u200dරශ්නය 40,000 වඩා ප්\u200dරශ්නයක් තියෙන්නේ CoNala දත්ත සෙට්ටුවෙන් සම්බන්ධ උදව්වක් ස අදහස් සහ ප්\u200dරශ්න ශරීරය දෙන්නම පාවිච්චි කරනවා, අපි BART වැඩකරනවා මේ අළුත් වැඩක් වෙනුවෙන් මූලික BLUE ප්\u200dරමා ඊට පස්සේ අපිට 2.8% වැඩි වැඩිය හොයාගන්න පුළුවන් තියෙනවා මයින් කොනාලා තොරතුරු සම්බන්ධ කරලා තියෙන්න පුළුවන් තො අපි ඊට පස්සේ මුලින්ම ස්ථානයේ CoNaLa මොඩේල් එක්ක මුලින්ම ස්ථානය විශ්වාස කරන්නේ. අපිට හොයාගන්න පුළුවන් විදියට අපේ ශරීරය සහ මයින් තොරතුරු පාවිච්චි කරන්න පුළුවන් විදියට පසුගිය ස්ථානයේ ඉන්න අන්තිමට, අපි ප්\u200dරශ්නයක් කරනවා ඒ වගේම බාර්ට් එක ප්\u200dරශ්නයක් තියෙනවා කියලා ප්\u200dරශ්නයක් වෙන්නේ බාර්ට් එක ගොඩ', 'sr': 'Odgovor na pitanje programiranja sa samo njegovim naslovom je teško, jer je ostavljena slobodna kontekstualna informacija. Da bi se ovo riješili, predstavljamo korpus od preko 40.000 teksta StackOverflow pitanja koji se koristi u vezi sa odgovarajućim namerama iz CoNala dataset (Yin et al., 2018). Koristeći i namjeru i telo pitanja, koristimo BART kako bi uspostavili početni BLEU rezultat od 34,35 za ovaj novi zadatak. Onda pronađemo daljnje poboljšanje od 2,8% kombinirajući rudene podatke CoNala sa označenim podacima kako bi postigli rezultat BLEU 35,32. Onda procjenjujemo prethodne modele "CoNala" sa ovim dodatnim podacima. Naša predložena metoda korištenja tijela i rudnih podataka pretvara prethodnog stanja umjetnosti 71,96% rezultata BLEU-a. Konačno, izvršavamo aktivnosti koje dokazuju da je BART neodređen multimodalni učenik i pregledamo njegovo ekstraktivno ponašanje.', 'so': "Answering a programming question with only its title is difficult as salient contextual information is left out.  To address this, we present a corpus of over 40,000 StackOverflow question texts to be used in conjunction with the corresponding intents from the CoNaLa dataset (Yin et al., 2018).  Isku isticmaalayno ujeedka iyo jidhka su'aalka, waxaynu isticmaalnaa BART si aan u sameyno kooxda hoose ee BLEU oo ah 34.35 shaqo cusub. Markaas waxaan helaynaa horumarinta ugu badnaanta 2.8 boqolkiiba marka lagu soo wadayo macluumaadka koonaLa ee la qoray si loo helo scorada 35.32 BLEU. Markaas waxaynu qiimeynaynaa xaalada hore ee CoNala's sameynaya macluumaadkan dheeraad ah. Waxaynu helnaa in qaababka loo soo jeeday isticmaalidda jidhka iyo macluumaadka lagu kaydiyey ay ku dhuftaa xaaladdii hore ee xaaladdii hore ee sanada ah 71.96% BLEU score. Ugu dambaysta, waxaynu sameynaa qalab, taas oo caddaynaya in BART uu yahay waxbarasho aan la ilaalin karo oo kala duduwan, waxaana baaritaan dabeecadiisa la soo saaro.", 'ta': 'ஒரு நிரல் கேள்விக்கு பதில் அதன் தலைப்பு இதை முகவரிக்க, நாம் 40,000 க்கு மேற்பட்ட StackOverflow கேள்வி உரைகளை கொண்டு பயன்படுத்த வேண்டும் கோனாலா தரவுத்தளத்திலிருந்து ஒத்திசைப்படுத்தும்  இந்த புதிய செயலுக்காக பிலூ புள்ளி புள்ளி புள்ளி புள்ளி புள்ளி மதிப்பை உருவாக்க BART யை பயன்படுத்துகிறோம். 2.8% மேலும் முன்னேற்றம் கண்டுபிடிப்போம் கோனாலா தரவை குறிக்கப்பட்ட தரவுடன் சேர்த்து 35.32 பிலியு மதிப்பு பெறுவதற்கு. இந்த கூடுதல் தரவுடன் முந்தைய நிலையின் மாதிரி கோனாலா மாதிரிகளை மதிப்பிடுகிறோம். நாங்கள் கண்டுபிடிக்கும் எங்கள் உறுப்பை பயன்படுத்த முறையில் மற்றும் குறைந்த தகவல்கள் முந்தைய நிலையில் உள்ளது என்று 71.96% பிலி இறுதியில், BART ஒரு பாதுகாப்பாக்கப்படாத பல முறை கற்றியவர் என்று தெரியும் பொருள்களை நாம் செயல்படுத்துகிறோம் அதன் வெளியே', 'sv': 'Att svara på en programmeringsfråga med bara dess titel är svårt eftersom viktig kontextuell information utelämnas. För att ta itu med detta presenterar vi en korpus med över 40 000 StackOverflow frågetexter som ska användas tillsammans med motsvarande avsikter från CoNaLa dataset (Yin et al., 2018). Med hjälp av både avsikt och frågetext använder vi BART för att fastställa en baslinje BLEU poäng på 34,35 för den nya uppgiften. Vi hittar sedan ytterligare förbättringar på 2,8% genom att kombinera de minerade CoNaLa-data med de märkta data för att uppnå en 35,32 BLEU-poäng. Vi utvärderar sedan tidigare state-of-the-art CoNaLa modeller med dessa ytterligare data. Vi finner att vår föreslagna metod för att använda kroppen och utvinna data slår den tidigare state-of-the-art med 71,96% BLEU poäng. Slutligen utför vi ablationer som bevisar att BART är en oövervakad multimodal elev och undersöker dess extraherande beteende.', 'ur': 'ایک پروگرامینگ سؤال کے ساتھ جواب دینا صرف اس کے تائیٹل کے ساتھ مشکل ہے کیونکہ سائل کنٹکسٹیل معلومات باہر چھوڑ دی جاتی ہے. اس کے بارے میں ہم نے 40,000 سے زیادہ استاک اوورلف سؤال کے متعلق ایک کورپوس کو پیش کیا ہے جو CoNala dataset (Yin et al., 2018) کے متعلق مطابق مطابق کے ساتھ استعمال کیا جائے گا۔ اور سوال جسم کے دونوں مطابق بورٹ کو استعمال کرتے ہیں کہ اس نوی کام کے لئے بنیس لین بلیوس کا اسکور 34.35 بنائیں۔ پھر ہم 2.8% کے زیادہ سوداگری پائیں گے، مٹی کی CoNaLa ڈیٹا کو لابلیٹ ڈیٹا کے ساتھ ملا کر 35.32 BLEU اسکور کو پہنچانے کے لئے۔ پھر ہم اس اضافہ دکھانے کے ساتھ پہلے کی حالت کی تصویر کریں گے. ہمیں معلوم ہے کہ ہماری پیشنهاد کی طریقہ جسم اور ماینڈ ڈیٹا کا استعمال کرنا 71.96% BLEU اسکور کے ذریعہ اس سے ضرب کرتا ہے۔ بالآخر، ہم آزمائش کر رہے ہیں جو ثابت کرتی ہے کہ BART ایک غیر قابل تعلیم دینے والی multimodal learner ہے اور اس کے اضافہ رفتار کی تحقیق کرتی ہے.', 'uz': "@ info Buni tasavvur qilish uchun, biz CoNaLa maʼlumotlar satrining qisqa qandaydir bo'lgan 40 000 dan ortiq StackOverflow savol matnlarini ishlatish uchun qo'shish mumkin. Bu yangi vazifa uchun 34.35 asosiy BLEU scorini ishlatish uchun BART'ni ishlatamiz. Keyin biz bir necha CoNala maʼlumotni 35.32 BLEU qiymatiga birlashtirish uchun qo'shimcha maʼlumot bilan birlashtirish mumkin. Keyin biz birinchi marta ko'proq CoNala modellarini qiymatimiz va bu qoʻshimcha maʼlumot bilan. Biz o'ylaymiz, tanamiz va kichkina maʼlumotlarni ishlatish usuli oldingi holatda 71.96% BLEU qiymatiga o'zgartiradi. Endi biz BART'ning ko'plab o'qituvchi o'quvchilarini bajaramiz va ularning cheksiz xuddi o'tibor beramiz.", 'vi': 'Trả lời một câu hỏi lập trình chỉ với tựa đề là khó khăn vì thông tin ngữ cảnh nổi bật bị bỏ ra. Để giải quyết chuyện này, chúng tôi giới thiệu một tập thể đầy đủ các văn bản Câu hỏi kiểu Stacket et et al., 208 để được sử dụng liên kết với ý định tương ứng từ bộ dữ liệu CO2 La. Sử dụng cả mục đích và cơ quan hỏi, chúng tôi dùng BART để thiết lập số lượng LEU tại 34.35 cho nhiệm vụ mới này. Chúng tôi tìm thấy nhiều cải tiến hơn trong 2.8=. bằng cách kết hợp các dữ liệu CO2 khai quật với các dữ liệu ghi nhãn để đạt được một số chẵn.32.bleU. Sau đó, chúng tôi đánh giá các mô hình Colt La tân tiến với những dữ liệu này. Chúng tôi thấy cách dùng cơ thể và đóng tính dữ liệu trước hiện bằng ghi lại 71.97.96 không đầu máy. Cuối cùng, chúng ta làm việc cắt bỏ khả năng chứng minh rằng BART là một người học hành không giám sát nhiều phương tiện và kiểm tra hành vi khai thác.', 'hr': 'Odgovor na pitanje programiranja sa samo njegovim naslovom je teško jer je ostavljeno slobodne contextualne informacije. Za rješavanje ovoga predstavljamo korpus od preko 40.000 teksta o pitanju StackOverflow koji se koristi zajedno s odgovarajućim namjerama iz kompeta podataka CoNala (Yin et al., 2018). Koristeći i namjeru i tijelo pitanja, koristimo BART kako bi uspostavili početni BLEU rezultat 34,35 za ovaj novi zadatak. Onda nađemo daljnje poboljšanje od 2,8% kombiniranjem rudenih podataka CoNala s označenim podacima kako bi postigli rezultat BLEU-a 35,32%. Onda procjenjujemo prethodne modele stanja umjetnosti CoNala s ovim dodatnim podacima. Naša predložena metoda korištenja tijela i mineralnih podataka pretjeruje prethodnu stanju umjetnosti 71,96% rezultata BLEU-a. Konačno, izvršavamo aktivnosti koje dokazuju da je BART neodređen multimodalni učitelj i pregledamo njegovo ekstraktivno ponašanje.', 'nl': 'Het beantwoorden van een programmeervraag met alleen de titel is moeilijk omdat opvallende contextuele informatie wordt weggelaten. Om dit aan te pakken presenteren we een corpus van meer dan 40.000 StackOverflow vraagteksten die gebruikt kunnen worden in combinatie met de overeenkomstige intenties uit de CoNaLa dataset (Yin et al., 2018). Met behulp van zowel de intentie als het vragenlichaam, gebruiken we BART om een baseline BLEU score van 34.35 voor deze nieuwe taak vast te stellen. Vervolgens vinden we verdere verbeteringen van 2,8% door de gemine CoNaLa data te combineren met de gelabelde data om een 35.32 BLEU score te bereiken. Vervolgens evalueren we de eerdere state-of-the-art CoNaLa modellen met deze aanvullende gegevens. We constateren dat onze voorgestelde methode om het lichaam en de gemine gegevens te gebruiken die van de vorige state-of-the-art met een 71,96% BLEU score overtreft. Tot slot voeren we ablaties uit die aantonen dat BART een niet-begeleide multimodale leerling is en onderzoeken we het extractieve gedrag ervan.', 'de': 'Eine Programmierfrage nur mit ihrem Titel zu beantworten, ist schwierig, da aussagekräftige Kontextinformationen weggelassen werden. Dazu stellen wir einen Korpus aus über 40.000 StackOverflow Fragentexten vor, der in Verbindung mit den entsprechenden Intents aus dem CoNaLa Datensatz verwendet werden soll (Yin et al., 2018). Wir verwenden BART, um einen BLEU-Wert von 34.35 für diese neue Aufgabe zu ermitteln. Wir finden dann weitere Verbesserungen von 2,8% durch die Kombination der abgebauten CoNaLa-Daten mit den markierten Daten, um einen 35,32 BLEU-Score zu erzielen. Anschließend werten wir die bisherigen CoNaLa-Modelle mit diesen zusätzlichen Daten aus. Wir stellen fest, dass unsere vorgeschlagene Methode zur Verwendung des Körpers und der ermittelten Daten die des vorherigen State-of-the-Art um einen 71,96% BLEU-Score übertrifft. Abschließend führen wir Ablationen durch, die belegen, dass BART ein unbeaufsichtigter multimodaler Lerner ist und untersuchen sein extraktives Verhalten.', 'bg': 'Отговарянето на въпрос за програмиране само със заглавието му е трудно, тъй като очевидната контекстуална информация е пропусната. За да се справим с това, представяме корпус от над 40 000 въпроса текста, които ще бъдат използвани във връзка със съответните намерения от набора от данни (Ин и др., 2018). Използвайки както намерението, така и тялото на въпроса, ние използваме БАРТ, за да установим базов резултат от 34,35 за тази нова задача. След това откриваме допълнителни подобрения от 2,8%, като комбинираме добитите данни с етикетираните данни, за да постигнем 35,32 резултат. След това оценяваме предишните съвременни модели с тези допълнителни данни. Намираме, че предложеният ни метод за използване на тялото и добитите данни бие този на предишните най-съвременни с 71,96% резултат. И накрая, извършваме аблации, които доказват, че БАРТ е ненадзорен мултимодален учащ се и изследваме неговото извличащо поведение.', 'da': 'Det er svært at besvare et programmeringsspørgsmål med kun titlen, da fremtrædende kontekstuelle oplysninger udelades. For at løse dette præsenterer vi et korpus på over 40.000 StackOverflow spørgsmålstekster, der skal bruges sammen med de tilsvarende hensigter fra CoNaLa datasættet (Yin et al., 2018). Ved hjælp af både hensigten og spørgsmålstegn bruger vi BART til at fastsætte en baseline BLEU score på 34,35 for denne nye opgave. Vi finder derefter yderligere forbedringer på 2,8% ved at kombinere de minerede CoNaLa data med de mærkede data for at opnå en 35,32 BLEU score. Vi evaluerer derefter de tidligere state-of-the-art CoNaLa modeller med disse yderligere data. Vi finder ud af, at vores foreslåede metode til at bruge kroppen og udvundet data slår den tidligere state-of-the-art med en BLEU score på 71,96%. Endelig udfører vi ablationer, der beviser, at BART er en uautoriseret multimodal elev og undersøger dens ekstraktive adfærd.', 'fa': 'پاسخ دادن یک سوال برنامه\u200cریزی با فقط عنوان آن سخت است، زیرا اطلاعات موقعیتی بی\u200cنیاز است. برای حل این کار، ما یک کورپوس از بیش از ۴۰ هزار متن سوال StackOverflow را پیشنهاد می\u200cکنیم که با هدف متفاوت از مجموعه داده\u200cهای CoNala (Yin et al., 2018) استفاده می\u200cشود. با استفاده از هدف و جسد سوال، ما از BART استفاده می کنیم تا یک امتیاز پایین BLEU از 34.35 برای این کار جدید ایجاد کنیم. سپس بهترین ترکیب بیشتری از 2.8 درصد با ترکیب داده های معدنی CoNala با داده های معدنی برای رسیدن امتیاز BLEU ۳۵.۳۲ پیدا کردیم. بعدش ما مدل های پیشینیان هنری CoNala را با این داده های اضافه ارزیابی می کنیم. ما فهمیدیم که روش پیشنهاد ما از استفاده از بدن و داده های معدنی به عنوان یک امتیاز BLEU 71.96 درصد از اولین حالت هنر شکست می دهد. بالاخره، ما قابلیت\u200cها را انجام می\u200cدهیم که ثابت می\u200cکند که BART یک دانش\u200cآموز چندین مدل غیرقابل تحقیق است و رفتار خارجی آن را تحقیق می\u200cکنیم.', 'ko': '제목만 있는 프로그래밍 문제에 대답하는 것은 어려운 일이다. 왜냐하면 두드러진 상하문 정보가 무시되기 때문이다.이 문제를 해결하기 위해 우리는 4만 개의 문제 텍스트를 포함하는 어료 라이브러리를 제공하여 코나라라 데이터 집합의 상응하는 의도와 결합하여 사용한다(Yin 등, 2018).의도와 문제 바디를 사용하여 BART를 사용하여 새 임무에 34.35의 BLEU 베이스라인 점수를 설정했습니다.그리고 발굴한 코나라 데이터를 태그 데이터와 결합해 35.32 BLEU 점수를 받아 2.8% 더 높일 예정이다.그런 다음 이러한 추가 데이터를 사용하여 이전에 가장 진보된 CoNaLa 모델을 평가합니다.우리가 제시한 신체 사용과 데이터 발굴 방법은 이전 최첨단 BLEU 점수보다 71.96% 높은 것으로 나타났다.마지막으로 우리는 융해 실험을 실시하여 BART가 감독이 없는 다중모드 학습자임을 증명하고 추출 행위를 검사했다.', 'id': 'Jawab pertanyaan pemrograman dengan hanya judulnya sulit karena informasi kontekstual yang saling ditinggalkan. Untuk mengatasi hal ini, kami mempersembahkan lebih dari 40.000 teks pertanyaan StackOverflow yang akan digunakan bersama dengan tujuan yang sesuai dari dataset CoNaLa (Yin et al., 2018). Menggunakan tujuan dan tubuh pertanyaan, kami menggunakan BART untuk menentukan nilai BLEU dasar 34,35 untuk tugas baru ini. Kemudian kita menemukan peningkatan lebih lanjut dari 2,8% dengan menggabungkan data CoNaLa tambang dengan data labeled untuk mencapai skor BLEU 35,32. Kemudian kita mengevaluasi model CoNaLa terbaik sebelumnya dengan data tambahan ini. Kami menemukan bahwa metode kami yang diusulkan untuk menggunakan tubuh dan data tambang mengalahkan yang dari state-of-the-art sebelumnya dengan skor BLEU 71,96%. Akhirnya, kami melakukan ablasi yang membuktikan bahwa BART adalah pelajar multimodal yang tidak diawasi dan memeriksa perilaku ekstraktif.', 'tr': "Programlamak soragyny diňe onuň sözbaşyny bilen jogap bermek kyn, näçe salient contextual maglumat taşlanmak kyn. Bunu çözmek üçin 40,000 üzerinden fazla StackOverflow soragy metinlerini CoNaLa veri setinden (Yin et al., 2018-nji ýyldan) gollanan maksadlaryla birleşdirdik. Hem maksady hem soragy bedenini ulanarak BART'y bu täze işiň üçin baseline BLEU 34.35 sanyny gurmak üçin ulanýarys. Sonra, mayın CoNaLa verisini 35,32 BLEU noktasını elde etmek için 2.8% daha gelişmeleri bulduk. Soňra öňki CoNaLa nusgalaryny şu ekleme hasaplamada çykýarys. Beden we miner berüvlerini ulanmak üçin teklip edilen yönümimiz 71.96% BLEU ýagdaýynda ýeňdi. Soňunda, BART'iň suytalanmaýan bir multimodal öwrenmeýändigini kanıtlayan ýagdaýlary çykaryp barýarys we özüniň daşary hereketini barlap çykaryp barýarys.", 'sw': 'Kujibu swali la programu yenye kichwa chake pekee ni vigumu kwa kuwa taarifa za kisasa zinaondoka. Ili kuonyesha hili, tunaweka makampuni ya zaidi ya ujumbe wa maswali ya StackOverflow 40,000 yanayotumiwa kwa ushirikiano na malengo yanayofanana kutoka kwenye seti ya data ya CoNaLa (Yin et al, 2018). Kwa kutumia nia zote na mwili wa swali, tunatumia BART kuanzisha vipimo vya msingi vya BLEU cha 34.35 kwa kazi hii mpya. Kisha tunagundua maendeleo zaidi ya asilimia 2.8 kwa kuunganisha takwimu za madini za CoNala pamoja na takwimu zilizoonyeshwa ili kufikia score 35.32 BLEU. Kisha tunatathmini mifano ya zamani ya hali ya sanaa ya CoNaLa kwa takwimu hii zaidi. Tunapata kwamba mbinu yetu ya kutumia mwili na taarifa za madini inapiga kipindi cha hali ya sanaa iliyopita kwa kiwango cha 71.96% BLEU. Mwisho, tunafanya mabomu yanayothibitisha kuwa BART ni mwanafunzi wa lugha mbalimbali aliyejihifadhiwa na kuchunguza tabia zake zisizo nje.', 'af': "Die antwoord van 'n program vraag met slegs sy titel is moeilik as salient contextual inligting verlaat word. Om hierdie adres te stel, stel ons 'n korpus van meer 40,000 StackOverflow vraagteks wat gebruik word in saam met die ooreenstemmende doels van die CoNaLa datastel (Yin et al., 2018). By die gebruik van beide die doel en die vraagliggaam, gebruik ons BART om 'n basisline BLEU aantal te stel van 34.35 vir hierdie nuwe taak. Ons vind dan verdere verbeteringe van 2.8% deur die mineerde CoNaLa data met die merkteerde data te kombinieer om 'n 35.32 BLEU-punt te bereik. Ons evalueer dan die voorste staat van die kuns CoNaLa modele met hierdie addisionele data. Ons vind dat ons voorgestelde metode om die liggaam en mineerde data te gebruik slaan wat van die vorige state-of-the-art deur 'n 71,96% BLEU-score. Eindelik, ons uitvoer ablasies wat bevestig dat BART 'n ononderwerp multimodaal leerder is en ondersoek sy ekstraktiewe gedrag.", 'am': 'የፕሮግራም ጥያቄ በመመልስ ላይ አርእስት ብቻ ነው፡፡ ለዚህ ለማስታወቂያ፣ ከኮንናላ ዳታተር (Yin et al, 2018) የተባለው የፍላጎት ጽሑፎች የሚጠቀሙትን የ40,000 በላይ የStackOverflow ጥያቄ ጽሑፎችን እናቀርባታለን፡፡ በአጠቃላይ እና የጥያቄውን አካል በመጠቀም፣ ለዚህ አዲስ ስራ የBLEU score እንዲመሠረት BART እንጠይቃለን፡፡ ከዚህም በኋላ የኮናላ ዳታዎችን ለ35.32 ቢልዩን score ለማግኘት የቆጠረውን ዳታ በመጠቀም 2.8 በመቶ የበለጠ ማስታወቂያውን እናገኛለን፡፡ ከዚህ በኋላ የቀድሞው የኮናላ አካባቢ አካባቢ ዳታዎችን እናሳውቃለን፡፡ አካል እና አካላዊ ዳታዎችን በመቀበል የፊተኛውን የልዩ ትውልድ ሀብት 71.96 በመቶ BLEU score እንደተደገፈ እናገኛለን፡፡ Finally, we perform ablations that prove that BART is an unsupervised multimodal learner and examine its extractive behavior.', 'hy': 'Պարզարագրման հարցի պատասխանը միայն դրա անվանությամբ դժվար է, քանի որ կարևոր կոնտեքստալ ինֆորմացիան դուրս է մնում: Սա լուծելու համար մենք ներկայացնում ենք ավելի քան 40,000 StackoverFlow հարցի տեքստ, որը պետք է օգտագործվի միասին Կոնալա տվյալների համակարգի (Yin et al., 2018) համապատասխան նպատակների հետ: Օգտագործելով նաև մտադրությունը, նաև հարցի մարմնը, մենք օգտագործում ենք BAR-ը, որպեսզի ստանանք այս նոր խնդրի համար 34.35-ի հիմնական ԲԼԵՎ գնահատականը: We then find further improvements of 2.8% by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score.  Այնուհետև մենք գնահատում ենք նախկինում ամենաբարձր Կոնալա մոդելները այս ավելացյալ տվյալներով: Մենք հայտնաբերում ենք, որ մարմնի և հանքային տվյալների օգտագործման մեր առաջարկած մեթոդը հաղթահարում է նախորդ տեխնոլոգիայի մեթոդը 71.96 տոկոսով ԲԼԵՎ գնահատականով: Վերջապես, մենք կատարում ենք ընդունակություններ, որոնք ապացուցում են, որ Բարթը անվերահսկված բազմամոդալ սովորող է և ուսումնասիրում է դրա արտադրողական վարքագիծը:', 'az': 'Proqramma sualına cavab vermək yalnız onun başlığı ilə çətin müxtəlif məlumatlar istifadə edilməsi çətin. Bunu çəkmək üçün, CoNala veri qutusu (Yin et al., 2018). İstədiyimiz və sual vücudun hər ikisini də istifadə edərək, bu yeni işin üçün BART istifadə edərik. Sonra minik CoNala verilərini 35,32 BLEU nöqtəsinə yetirmək üçün etiketli məlumatlarla birləşdirən 2,8%-in daha yaxşılıqlarını tapırıq. Sonra əvvəlki məlumatların CoNala modellərini bu əlavə məlumatlarla değerləşdiririk. Vəsir və minik məlumatlarını istifadə etmək təklif etdiyimiz metodumuz əvvəlki məlumatların 71,96% BLEU nöqtəsinə qədər döyüşər. Sonunda, BART çoxlu modal öyrənməyən bir çoxlu öyrənmək olduğunu kanıtlayan fəaliyyətlər təyin edirik.', 'sq': 'Përgjigja në një pyetje programimi me vetëm titullin e saj është e vështirë pasi informacioni kontekstual i rëndësishëm është lënë jashtë. Për të trajtuar këtë, ne paraqesim një korpus prej mbi 40,000 teksteve të pyetjeve StackOverflow që do të përdoren në lidhje me qëllimet korrespondente nga dataset CoNaLa (Yin et al., 2018). Duke përdorur qëllimin dhe trupin e pyetjes, ne përdorim BART për të vendosur një pikë bazë BLEU prej 34.35 për këtë detyrë të re. We then find further improvements of 2.8% by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score.  Pastaj vlerësojmë modelet e mëparshëm të CoNaLa me këto të dhëna shtesë. Ne zbulojmë se metoda jonë e propozuar për përdorimin e trupit dhe të dhënat e minave mundet atë të gjendjes së mëparshme të artit me një rezultat BLEU 71.96%. Më në fund, ne bëjmë ablacione që vërtetojnë se BART është një mësues multimodal i pa mbikqyrur dhe shqyrtojmë sjelljen e tij ekstraktive.', 'bs': 'Odgovor na pitanje programiranja sa samo njegovim naslovom je teško, jer je ostavljena slobodna kontekstualna informacija. Da bi se ovo riješili, predstavljamo korpus od preko 40.000 teksta o pitanju StackOverflow koji se koristi zajedno sa odgovarajućim namjerama CoNaLa dataset (Yin et al., 2018). Koristeći i namjeru i tijelo pitanja, koristimo BART kako bi uspostavili početni BLEU rezultat od 34,35 za ovaj novi zadatak. Onda pronađemo daljnje poboljšanje od 2,8% kombiniranjem rudenih podataka CoNala sa označenim podacima kako bi postigli rezultat BLEU 35,32. Onda procjenjujemo prethodne modele umjetnosti CoNala sa ovim dodatnim podacima. Naša predložena metoda korištenja tijela i mineralnih podataka pretvara prethodnog stanja umjetnosti 71,96% rezultata BLEU-a. Napokon, izvršavamo aktivnosti koje dokazuju da je BART neodređen multimodalni učenik i pregledamo njegovo ekstraktivno ponašanje.', 'cs': 'Odpovědět na programovací otázku pouze s názvem je obtížné, protože významné kontextové informace jsou vynechány. Pro řešení této problematiky představujeme korpus více než 40.000 StackOverflow otázek textů, které mají být použity ve spojení s odpovídajícími záměry z datové sady CoNaLa (Yin et al., 2018). Použitím záměru i otázkového těla používáme BART k určení základního skóre BLEU 34.35 pro tento nový úkol. Následně nalezneme další zlepšení 2,8% kombinací vytěžených dat CoNaLa s označenými daty, abychom dosáhli 35,32 BLEU skóre. S těmito dodatečnými daty pak vyhodnocujeme předchozí nejmodernější modely CoNaLa. Zjišťujeme, že náš navržený způsob využití těla a těžených dat překonává předchozí stav techniky o 71,96% BLEU skóre. Nakonec provádíme ablace, které dokazují, že BART je multimodální žák bez dozoru a zkoumáme jeho extraktivní chování.', 'bn': 'একটি প্রোগ্রামিং প্রশ্নের উত্তর শুধুমাত্র তার শিরোনামের শিরোনাম কঠিন যেহেতু বিক্রিয়ানের প্রোগ্ এই বিষয়টিকে ঠিক করার জন্য আমরা ৪০,০০০ জনের বেশী স্ট্যাক ওভারপ্ল্যান্ড প্রশ্নের লেখাগুলো উপস্থাপন করি যা কোনো নালা ডাটাসেটের সাথে সংশ্লি উদ্দেশ্য এবং প্রশ্নের দেহ ব্যবহার করে আমরা বার্ট ব্যবহার করি এই নতুন কাজের জন্য বেসেলাইন বিলু স্কোর তৈরি করার জন্য। তারপর আমরা মিনিট কোনালা তথ্য সংযুক্ত করে ২. We then evaluate the prior state-of-the-art CoNaLa models with this additional data.  আমরা খুঁজে পাচ্ছি যে আমাদের প্রস্তাবিত পদ্ধতি দেহ ব্যবহার করা এবং খনির তথ্য ব্যবহার করার মাধ্যমে পূর্ববর্তী রাষ্ট্র-অফ-শিল্পের প শেষ পর্যন্ত আমরা আগুন প্রমাণ করি যে বার্ট একটি অরক্ষিত বহুটিমোডাল শিক্ষক এবং তার আচরণ পরীক্ষা করি।', 'ca': "Respondre a una qüestió de programació amb només el seu títol és difícil, ja que la informació contextual salient es deixa fora. Per abordar això, presentem un corpus de més de 40.000 textos de preguntes StackOverflow que s'utilitzen conjuntament amb les intencions correspondents del conjunt de dades CoNaLa (Yin et al., 2018). Utilitzant tant la intenció com el cos de pregunta, utilitzem BART per establir una puntuació BLEU de 34,35 per aquesta nova tasca. Després trobem millores adicionals del 2,8% combinant les dades minerades de CoNaLa amb les dades etiquetades per aconseguir una puntuació BLEU de 35,32%. Després evaluem els models CoNaLa més avançats amb aquestes dades adicionals. Trobem que el nostre mètode proposat d'utilitzar el cos i les dades mines supera l'última puntuació del 71,96% BLEU. Finalment, fem ablacions que demostren que BART és un aprenent multimodal sense supervisió i examinem el seu comportament extractiu.", 'et': 'Programmeerimisk羹simusele vastamine ainult selle pealkirjaga on keeruline, sest oluline kontekstiteave j瓣etakse v瓣lja. Selle lahendamiseks esitame 羹le 40 000 StackOverflow k羹simusteksti korpuse, mida kasutatakse koos CoNaLa andmekogumi vastavate kavatsustega (Yin et al., 2018). Kasutades nii kavatsust kui ka k羹simuse sisu, kasutame BART-i, et m瓣瓣rata BLEU baaskoor 34,35 selle uue 羹lesande jaoks. Seej瓣rel leiame 2,8% v繭rra t瓣iendavaid parandusi, kombineerides kaevandatud CoNaLa andmed m瓣rgistatud andmetega, et saavutada 35,32 BLEU skoor. Seej瓣rel hindame eelnevaid kaasaegseid CoNaLa mudeleid nende lisaandmetega. Leiame, et meie pakutud keha ja kaevandatud andmete kasutamise meetod v繭idab eelmise tehnika taseme meetodit 71,96% BLEU skoori v繭rra. L繭puks teeme ablatsioone, mis t繭estavad, et BART on j瓣relevalveta multimodaalne 繭ppija ja uurime selle ekstraktiivset k瓣itumist.', 'fi': 'Ohjelmointikysymykseen vastaaminen vain otsikolla on vaikeaa, koska oleellista asiayhteyteen liittyvää tietoa jätetään pois. Tämän ratkaisemiseksi esittelemme yli 40 000 StackOverflow-kysymystekstiä, joita käytetään yhdessä CoNaLa-aineiston vastaavien tarkoitusten kanssa (Yin et al., 2018). Käyttämällä sekä aikomusta että kysymyskohtaa, määritämme BART:n avulla BLEU-lähtöpisteen 34,35 tälle uudelle tehtävälle. Tämän jälkeen löydämme 2,8 prosentin parannuksia yhdistämällä louhitut CoNaLa-tiedot merkittyihin tietoihin 35,32 BLEU-pisteen saavuttamiseksi. Tämän jälkeen arvioimme viimeisimmät CoNaLa-mallit näiden lisätietojen avulla. Havaitsemme, että ehdotettu menetelmä kehon ja louhittujen tietojen käyttämiseksi voittaa edellisen huipputekniikan 71,96% BLEU-pisteellä. Lopuksi suoritamme ablaatioita, jotka todistavat, että BART on valvomaton multimodaalinen oppija ja tutkimme sen ekstraktivista käyttäytymistä.', 'jv': 'Ngubah werong program sing nganggo titla kuwi susah-susahe durung malay Ngawe ngendalikne iki, kita nyimpen carapa kanggo teka witan luwih cara-cara sing seperakan kanggo kelas telu wae coNala dumateng (Yin et al, 2008). Ngawe ngubah nambah karo perbudhakan kanggo masa, awak dhéwé nggunakake LPRT kanggo nggawe roti sing paling blo 34. Defs We tambah assertive the first state-of-the-arts CoNala model with this additional data. Awak dhéwé nglanggar aturan nyengkuyé nggambar barang sampeyan karo perusahaan dadi sing nggawe barang nggawe barang-barêng kanggo ngerayakno kotak sing nêmên karo perusahaan lan oleh-barêng sampeyan ingkang 75.60% sing nyengkuyé Lha wih-wih, awak dhéwé ngerti perusahaan kanggo ngerasakno Balt iki dadi mlaku multimodal gak enyong, lan ujian sisan pancene ora iso nggawe barang apik dhéwé.', 'ha': "Answering a programming question with only its title is difficult as salient contextual information is left out.  To, za mu gabatar da wata makaranta na over 40,000 StackSurflor masu tambayar ta wanda za a yi amfani da shi sami da kashi mai inganci daga the CoNaLa dataset (Yin et al., 2018). Yi amfani da aikin suna da amfani da aikin tambayi, ko kuma za mu yi amfani da BART dõmin ka daidaita wani nau'i na Baselin BLEU na 34.35 wa wannan aikin sãbuwa. Sa'an nan kuma za mu sami koNala data da aka rubũta shi zuwa wani score 35.32BLEU. Sa'an nan kuma Muke ƙayyade misalin-na-kunyar CoNala da wannan zaɓata. Tuna gane cewa hanyoyinmu da za'a yi amfani da jikin da ke ƙaranci data banke abin da na gaba na halin-sanar da aka rubũta shi na 71.96% BLEU score. Gani, za mu sami karatun karatun da za'a gaskata BANT ta zama wani mai tsaro na multi'in da ba'a tsare shi ba, kuma ke jarrabi aikin mataimarsa.", 'he': 'Answering a programming question with only its title is difficult as salient contextual information is left out.  כדי להתמודד עם זה, אנו מציגים קורפוס של מעל 40,000 טקסטים של שאלות StackOverflow לשימוש ביחד עם הכוונות המתאימות מסט הנתונים של CoNala (Yin et al., 2018). בשימוש בכוונה וגוף השאלות, אנו משתמשים בארט כדי לקבוע נקודת BLEU בסיסית של 34.35 למשימה החדשה הזאת. ואז נמצא שיפורים נוספים של 2.8% על ידי שילוב את נתוני CoNala מוכרים עם נתונים מוכרים כדי להשיג נקודת BLEU 35.32. ואז אנו מעריכים את דוגמני קונאלה המאוחרים הקודמים עם הנתונים הנוספים האלה. אנחנו מוצאים שהשיטה המוצעת שלנו להשתמש בגוף ומידע מוכר מכה את שיטת המצב הקודם על ידי נקודת BLEU 71.96%. סוף סוף, אנו מבצעים איברים שמוכיחים שבארט הוא לומד multimodal ללא השגחה ולבדוק את התנהגותו החולף.', 'sk': 'Odgovor na programsko vprašanje samo z naslovom je težko, saj so izpuščene kontekstne informacije. Za obravnavo tega predstavljamo korpus več kot 40.000 vprašanj StackOverflow besedil, ki jih je treba uporabiti v povezavi z ustreznimi nameni iz nabora podatkov CoNaLa (Yin et al., 2018). Z uporabo namena in telesa vprašanja uporabljamo BART za določitev osnovne ocene BLEU 34,35 za to novo nalogo. Nato najdemo nadaljnje izboljšave za 2,8% s kombinacijo kopanih podatkov CoNaLa z označenimi podatki, da dosežemo rezultat 35,32 BLEU. Nato s temi dodatnimi podatki ocenimo najsodobnejše modele CoNaLa. Ugotavljamo, da naša predlagana metoda uporabe telesa in rudiranih podatkov presega najsodobnejšo metodo za 71,96% BLEU rezultat. Nazadnje opravimo ablacije, ki dokazujejo, da je BART nenadzorovan multimodalni učenec in preučujemo njegovo ekstraktivno vedenje.', 'bo': 'བྱ་རིམ་འདྲི་ཞིག་ལ་ལན་མི་ཐུབ་པ། དེའི་མགོ་མིང་ཡིན་པའི་མགོ་མིང་ཡིན་པས་salient contextual information is left out. འདི་ལྟར་བཤད་ན། ང་ཚོའི་རྣམ་པ་འདི་གསལ་བཤད་ཀྱི་ཡིག་གཟུགས་སྐོར་ལས་ཕར་མེད་སྟོན་པའི་མིང་༡༤༠༠་ཙམ་སྟོན་གྱི་ཡོད་པ་རེད། དམིགས་ཡུལ་དང་འདྲི་ཞིབ་ཀྱི་སྒེར་གྱི་ཐབས་ལམ་གཉིས་པོ་ཞིག་སྤྱོད་བཞིན་པའི་ང་ཚོས་BART་སྤྱད་ནས་ལས་ཀ་གསར་པ་ལ་ཉིད་མཇུག་ We then find further improvements of 2.8% by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score. འོན་ཀྱང་། ང་ཚོས་རང་གི་འཆར་བཀོད་པའི་ཐབས་ལམ་ལ་སྤྱོད་ཀྱི་རྩིས་པ་དང་ནང་གི་ཕྱིར མཐའ་མཇུག་དུ། འུ་ཅག་གིས་BART ནི་རྒྱུན་ལྡན་མེད་པའི་སྣ་མང་ཆེ་མཐོང་བ་ཞིག་ཡིན་པའི་ལག་ལེན་འཐབ་རྩོལ་བ་ཞིག་བྱེ'}
{'en': 'Text-to-SQL in the Wild : A Naturally-Occurring Dataset Based on Stack Exchange Data SQL  in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data', 'ar': 'Text-to-SQL in the Wild: مجموعة بيانات تظهر بشكل طبيعي بناءً على بيانات تبادل مكدس', 'pt': 'Text-to-SQL em estado selvagem: um conjunto de dados de ocorrência natural baseado em dados do Stack Exchange', 'es': 'Texto a SQL en estado salvaje: un conjunto de datos natural basado en datos de Stack Exchange', 'fr': "Text-to-SQL in the Wild\xa0: un jeu de données naturel basé sur des données d'échange de pile", 'ja': 'ワイルドなテキスト- to - SQL:スタックエクスチェンジデータに基づく自然発生的なデータセット', 'zh': '野外文本至SQL:基于堆栈易数者自集', 'hi': 'वाइल्ड में पाठ-से-SQL: स्टैक एक्सचेंज डेटा पर आधारित एक स्वाभाविक रूप से होने वाला डेटासेट', 'ru': 'Text-to-SQL in the Wild: набор данных с естественным расположением символов на основе данных обмена стеком', 'ga': 'Téacs-go-SQL san Fhiáin: Tacar Sonraí a Tharlaíonn go Nádúrtha Bunaithe ar Shonraí Stocmhalartaithe', 'hu': 'Text-to-SQL in the Wild: Egy természetesen előforduló adatkészlet Stack Exchange adatokon alapul', 'el': 'Ένα φυσικό σύνολο δεδομένων βασισμένο σε δεδομένα ανταλλαγής στοίβας', 'it': 'Text-to-SQL in the Wild: un set di dati naturali basato su Stack Exchange Data', 'lt': 'Tekstas į SQL laukiniuose gyvūnuose: natūralus duomenų rinkinys, pagrįstas keitimosi duomenimis', 'kk': 'Жұлдыз мәтіннен SQL: Қалқан ауыстыру деректеріне негізделген табиғалау деректер бағдарламасы', 'ml': 'വയലിലെ പദാവലി', 'ka': 'Text- to- SQL in the Wild: A Naturally- Occurring Data Database Based on Stack Exchange Data', 'mn': 'Дөрвөлжингийн Текст-ээс SQL: Түүний мэдээлэл дээр байгалийн сайжруулах өгөгдлийн сан', 'mt': 'Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data', 'no': 'Tekst- til- SQL i Wild: Ein naturleg- okkurring- databasert basert på Stack Exchange- data', 'pl': 'Text-to-SQL na wolności: naturalny zestaw danych oparty na danych Stack Exchange', 'ro': 'Text-to-SQL în sălbăticie: un set de date natural bazat pe date de schimb de stive', 'sr': 'Text-to-SQL u divljini: Prirodno-okvirujući datum podataka na temelju podataka o razmjeni ulozi', 'mk': 'Текст-во-SQL во дивината: Состав на природни податоци базиран на податоци за размена на стапки', 'ms': 'Teks-ke-SQL dalam Wild: Satu Set Data yang berlaku secara alami berdasarkan Data Tukar', 'si': 'ස්ටැක් එක්ස්චේන්ජ් දත්ත අධාරිත පාළුවෙන් SQL: ස්ටැක් එක්ස්චේන්ජ් දත්ත', 'so': 'QL-text-to-SQL in the Wild: A Natural-Occurring Dataset based on Stack Exchange Data', 'ta': 'விளையாட்டில் உள்ள உரை- to- SQL: அடுக்கு மாற்று தகவல் அடிப்படையில் ஒரு இயல்பான- ஒழுங்கு தகவல் அமைப்பு', 'ur': 'وایلڈ میں متن-سے-SQL: سٹاک اکسچینڈ ڈاٹ پر بنیاد رکھی ایک طبیعی-اوکرینڈ ڈاٹیس', 'sv': 'Text-till-SQL i det vilda: Ett naturligt förekommande dataset baserat på Stack Exchange Data', 'uz': 'Name', 'vi': 'Văn bản tới SQL ở hoang dã: Một dữ liệu hiện thời tự nhiên dựa trên dữ liệu trao đổi Stacks', 'hr': 'Text-to-SQL u divljini: Datacija prirodno-okruženja temeljena na podacima razmjene uloga', 'nl': 'Text-to-SQL in het wild: een natuurlijk voorkomende dataset gebaseerd op Stack Exchange Data', 'da': 'Tekst-til-SQL i naturen: Et naturligt forekommende datasæt baseret på Stack Exchange Data', 'bg': 'Текст в дивата природа: естествено срещащ се набор от данни, базиран на данни за обмен на стекове', 'id': 'Teks-ke-SQL di Wild: Sebuah Set Data yang terjadi secara alami berdasarkan Data Tukar Tukar', 'fa': 'متن به SQL در وحشی: یک داده\u200cای طبیعی بسته بر روی داده\u200cهای تبدیل استک', 'sw': 'Mjumbe wa maandishi kwa-SQL katika jangwa: Mpango wa data ya asili ya kujifunza kwa msingi wa mabadiliko ya data', 'tr': 'Wild-de metin-tä-SQL', 'de': 'Text-to-SQL in freier Wildbahn: Ein natürlich vorkommender Datensatz auf Basis von Stack Exchange Daten', 'ko': 'SQL에 텍스트: 스택에서 데이터를 교환하는 자연 생성된 데이터 세트', 'sq': 'Tekst-në-SQL në të egër: Një bazë të dhënash që ndodhin natyralisht bazuar në të dhënat e shkëmbimit të kopave', 'hy': 'Տեքստ-մինչև-SQL վայրի մեջ. բնական տեղի ունեցող տվյալների համակարգ, որը հիմնված է Stack', 'af': "Teks- na- SQL in die Wild: ' n Natuurlik- Okkurring Databasis Baseer op Stack Exchange Data", 'am': 'Text-to-SQL in the Wild: A Natural-Occurring Dataset based on Stack Exchange Data', 'az': 'Wild-to-SQL: Stack Exchange Data Based on A Naturally-Occurring Data Database', 'bs': 'Text-to-SQL u divljini: Prirodno-okvirujući datum na temelju podataka o razmjeni uloga', 'bn': 'বন্যায় টেক্সট- থেকে SQL: স্বাভাবিক-অকার্রিং তথ্যের উপর ভিত্তিক তথ্য', 'ca': "Text-to-SQL en el salvatge: Un conjunt de dades naturals basat en dades d'intercanvi de piles", 'fi': 'Teksti SQL:ksi luonnossa: Luonnollisesti esiintyvä tietojoukko, joka perustuu Stack Exchange -tietoihin', 'cs': 'Text-to-SQL ve volné přírodě: Přirozeně se vyskytující datová sada založená na datech Stack Exchange', 'et': 'Text-to-SQL looduses: loomulikult esinev andmekogum, mis põhineb Stack Exchange andmetel', 'jv': 'Text-to-KSL in the Wild', 'sk': 'Besedilo v SQL v naravi: naravno nastajajoči nabor podatkov, ki temelji na podatkih Stack Exchange', 'he': 'טקסט-ל-SQL בפרא: קבוצת נתונים מתרחשת טבעית', 'ha': 'KCharselect unicode block name', 'bo': 'Wild ནང་གི་ཡིག་གེ SQL : སྤྱིར་བཏང་བའི་ཟུར་བ་ཡིག་གཟུགས་རིས'}
{'en': 'Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of  natural language understanding systems . As a result, they do not contain any of the richness and variety of natural-occurring utterances, where humans ask about data they need or are curious about. In this work, we release  SEDE , a  dataset  with 12,023 pairs of utterances and  SQL queries  collected from real usage on the  Stack Exchange website . We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.', 'ar': 'تم جمع معظم مجموعات بيانات التحليل الدلالي المتاحة ، والتي تتكون من أزواج من الكلام الطبيعي والأشكال المنطقية ، فقط لغرض التدريب وتقييم أنظمة فهم اللغة الطبيعية. نتيجة لذلك ، فهي لا تحتوي على أي ثراء وتنوع للألفاظ الطبيعية ، حيث يسأل البشر عن البيانات التي يحتاجون إليها أو يثيرون فضولهم. في هذا العمل ، قمنا بإصدار SEDE ، وهي مجموعة بيانات تحتوي على 12023 زوجًا من الكلمات المنطوقة واستعلامات SQL التي تم جمعها من الاستخدام الحقيقي على موقع Stack Exchange. نوضح أن هذه الأزواج تحتوي على مجموعة متنوعة من تحديات العالم الحقيقي التي نادرًا ما تنعكس حتى الآن في أي مجموعة بيانات تحليل دلالي أخرى ، ونقترح مقياس تقييم يعتمد على مقارنة عبارات الاستعلام الجزئية الأكثر ملاءمة لاستعلامات العالم الحقيقي ، وإجراء التجارب مع خطوط أساس قوية ، تظهر فجوة كبيرة بين الأداء على SEDE مقارنة بمجموعات البيانات الشائعة الأخرى.', 'fr': "La plupart des ensembles de données d'analyse sémantique disponibles, comprenant des paires d'énoncés naturels et de formes logiques, ont été collectés uniquement à des fins de formation et d'évaluation des systèmes de compréhension du langage naturel. Par conséquent, ils ne contiennent aucune de la richesse et de la variété des énoncés naturels, dans lesquels les humains s'interrogent sur les données dont ils ont besoin ou sont curieux. Dans ce travail, nous publions SEDE, un ensemble de données contenant 12 023 paires d'énoncés et de requêtes SQL collectées à partir d'une utilisation réelle sur le site Web de Stack Exchange. Nous montrons que ces paires présentent une variété de défis du monde réel qui étaient rarement reflétés jusqu'à présent dans aucun autre jeu de données d'analyse sémantique, proposons une métrique d'évaluation basée sur la comparaison de clauses de requête partielles plus adaptées aux requêtes du monde réel, et menons des expériences avec des bases de référence solides, ce qui montre un écart important entre les performances de SEDE par rapport aux autres ensembles de données courants.", 'pt': 'A maioria dos conjuntos de dados de análise semântica disponíveis, compostos de pares de enunciados naturais e formas lógicas, foram coletados exclusivamente para fins de treinamento e avaliação de sistemas de compreensão de linguagem natural. Como resultado, eles não contêm nenhuma riqueza e variedade de enunciados de ocorrência natural, onde os humanos perguntam sobre os dados de que precisam ou sobre os quais estão curiosos. Neste trabalho, lançamos o SEDE, um conjunto de dados com 12.023 pares de enunciados e consultas SQL coletados de uso real no site do Stack Exchange. Mostramos que esses pares contêm uma variedade de desafios do mundo real que raramente foram refletidos até agora em qualquer outro conjunto de dados de análise semântica, propomos uma métrica de avaliação baseada na comparação de cláusulas de consulta parciais que é mais adequada para consultas do mundo real e conduzimos experimentos com linhas de base fortes, mostrando uma grande lacuna entre o desempenho na SEDE em comparação com outros conjuntos de dados comuns.', 'es': 'La mayoría de los conjuntos de datos de análisis semántico disponibles, que comprenden pares de enunciados naturales y formas lógicas, se recopilaron únicamente con el propósito de entrenar y evaluar los sistemas de comprensión del lenguaje natural. Como resultado, no contienen nada de la riqueza y variedad de expresiones naturales, en las que los humanos preguntan por los datos que necesitan o por los que sienten curiosidad. En este trabajo, publicamos SEDE, un conjunto de datos con 12,023 pares de enunciados y consultas SQL recopiladas del uso real en el sitio web de Stack Exchange. Mostramos que estos pares contienen una variedad de desafíos del mundo real que rara vez se reflejaban hasta ahora en ningún otro conjunto de datos de análisis semántico, proponemos una métrica de evaluación basada en la comparación de cláusulas de consulta parcial que es más adecuada para consultas del mundo real, y realizamos experimentos con líneas de base sólidas. lo que muestra una gran brecha entre el rendimiento de SEDE en comparación con otros conjuntos de datos comunes.', 'zh': '大抵可用者语义解析据集,兼自然语及逻辑对,惟以训练评估自然语言解系统。 是以不含自然之语,人问其所须好奇之数。 于是发 SEDE,此一数集,其实 Stack Exchange 网站用 12,023 问 SQL 。 此诸现实世界挑战,此等挑战迄今为止少于一切语义解析数集,立一根查子句较量指标,更宜世界询问,并有强基线之实验,明SEDE性与他常数集相去甚大。', 'ja': '自然発話と論理形式のペアで構成される、利用可能なほとんどのセマンティック構文解析データセットは、自然言語理解システムの訓練と評価の目的でのみ収集された。その結果、人間が必要としている、または興味を持っているデータについて尋ねる自然発生的な発言の豊かさと多様性は含まれていません。この作業では、Stack Exchange Webサイトの実際の使用から収集された12,023ペアの発話とSQLクエリを含むデータセットであるSEDEをリリースします。これらのペアには、他のセマンティック解析データセットにはほとんど反映されていない様々な現実の課題が含まれており、現実のクエリに適した部分的なクエリ条項の比較に基づいた評価指標を提案し、強力なベースラインを使用して実験を行い、他の一般的なデータセットと比較してSEDEのパフォーマンスに大きなギャップを示しています。', 'hi': 'अधिकांश उपलब्ध शब्दार्थ पार्सिंग डेटासेट, जिसमें प्राकृतिक उच्चारण और तार्किक रूपों के जोड़े शामिल हैं, को पूरी तरह से प्राकृतिक भाषा समझने वाली प्रणालियों के प्रशिक्षण और मूल्यांकन के उद्देश्य से एकत्र किया गया था। नतीजतन, उनमें प्राकृतिक रूप से होने वाले कथनों की समृद्धि और विविधता में से कोई भी शामिल नहीं है, जहां मनुष्य उन आंकड़ों के बारे में पूछते हैं जिनकी उन्हें आवश्यकता होती है या उनके बारे में उत्सुक होते हैं। इस काम में, हम SEDE, स्टैक एक्सचेंज वेबसाइट पर वास्तविक उपयोग से एकत्र किए गए कथनों और SQL क्वेरीज़ के 12,023 जोड़े के साथ एक डेटासेट जारी करते हैं। हम दिखाते हैं कि इन जोड़ों में विभिन्न प्रकार की वास्तविक दुनिया की चुनौतियां होती हैं जो शायद ही कभी किसी अन्य शब्दार्थ पार्सिंग डेटासेट में अब तक परिलक्षित होती हैं, आंशिक क्वेरी खंडों की तुलना के आधार पर एक मूल्यांकन मीट्रिक का प्रस्ताव करती हैं जो वास्तविक दुनिया के प्रश्नों के लिए अधिक उपयुक्त है, और मजबूत बेसलाइन के साथ प्रयोगों का संचालन करती है, जो अन्य सामान्य डेटासेट की तुलना में SEDE पर प्रदर्शन के बीच एक बड़ा अंतर दिखाती है।', 'ru': 'Большинство доступных наборов данных семантического анализа, состоящих из пар естественных высказываний и логических форм, были собраны исключительно с целью обучения и оценки систем понимания естественного языка. В результате, они не содержат никакого богатства и разнообразия естественных высказываний, где люди спрашивают о данных, которые им нужны, или интересуются ими. В этой работе мы выпускаем SEDE - датасет с 12 023 парами фраз и запросов SQL, собранных из реального использования на сайте Stack Exchange. Мы показываем, что эти пары содержат множество реальных задач, которые редко отражались до сих пор в любом другом наборе данных семантического анализа, предлагаем оценочную метрику, основанную на сравнении частичных запросов, которая больше подходит для реальных запросов, и проводим эксперименты с сильными базовыми линиями, показывая большой разрыв между производительностью на SEDE по сравнению с другими общими наборами данных.', 'ga': 'Bailíodh an chuid is mó de na tacair sonraí parsála shéimeantacha a bhí ar fáil, comhdhéanta de phéirí de chaint nádúrtha agus d’fhoirmeacha loighciúla, chun críche oiliúna agus measúnaithe ar chórais nádúrtha tuisceana teanga amháin. Mar thoradh air sin, níl aon shaibhreas agus éagsúlacht iontu de chainteanna nádúrtha a tharlaíonn, ina bhfiafraíonn daoine faoi na sonraí a bhfuil gá acu leo nó ina bhfuil siad fiosrach. San obair seo, scaoilimid SEDE, tacar sonraí ina bhfuil 12,023 péire cainte agus fiosruithe SQL a bhailítear ó fhíorúsáid ar shuíomh Gréasáin na Stack Exchange. Léirímid go bhfuil éagsúlacht de dhúshláin fhíorshaolacha sna péirí seo nár léiríodh ach go hannamh go dtí seo in aon tacar sonraí parsála shéimeantach eile, molaimid méadrach meastóireachta bunaithe ar chomparáid idir clásail pháirtigh fiosrúcháin atá níos oiriúnaí do cheisteanna ón bhfíorshaol, agus déan turgnaimh. le bonnlínte láidre, rud a léiríonn bearna mhór idir an fheidhmíocht ar SEDE i gcomparáid le tacair shonraí coitianta eile.', 'hu': 'A legtöbb rendelkezésre álló, természetes kifejezések és logikai formák párjaiból álló szemantikai elemzési adatkészletet kizárólag a természetes nyelvértési rendszerek képzésére és értékelésére gyűjtötték. Ennek eredményeképpen nem tartalmazzák a természetes kifejezések gazdagságát és változatosságát, ahol az emberek olyan adatokat kérdeznek, amelyekre szükségük van vagy kíváncsiak. Ebben a munkában kiadjuk a SEDE adatkészletet, amely 12 023 pár kimondást és SQL lekérdezést tartalmaz a Stack Exchange weboldalon valós használatból. Megmutatjuk, hogy ezek a párok különböző valós kihívásokat tartalmaznak, amelyek eddig ritkán tükröződtek más szemantikai elemzési adatkészletben, javasoljuk a részleges lekérdezési záradékok összehasonlításán alapuló értékelési metrikát, amely jobban alkalmas valós lekérdezésekhez, és erős alapvonalakkal végezzünk kísérleteket, amelyek nagy rést mutatnak a SEDE teljesítménye között más közös adatkészletekhez képest.', 'el': 'Τα περισσότερα διαθέσιμα σύνολα σημασιολογικών αναλύσεων, που αποτελούνται από ζεύγη φυσικών εκφρασμάτων και λογικών μορφών, συλλέχθηκαν αποκλειστικά με σκοπό την εκπαίδευση και αξιολόγηση συστημάτων κατανόησης φυσικής γλώσσας. Ως αποτέλεσμα, δεν περιέχουν τίποτα από τον πλούτο και την ποικιλία των φυσικών εκφράσεων, όπου οι άνθρωποι ρωτούν για δεδομένα που χρειάζονται ή είναι περίεργοι. Σε αυτή την εργασία, απελευθερώνουμε ένα σύνολο δεδομένων με 12,023 ζεύγη προφορών και ερωτήματα που συλλέγονται από πραγματική χρήση στην ιστοσελίδα του. Δείχνουμε ότι αυτά τα ζεύγη περιέχουν μια ποικιλία πραγματικών προκλήσεων που σπάνια αντικατοπτρίζονται μέχρι στιγμής σε οποιοδήποτε άλλο σύνολο σημασιολογικών δεδομένων ανάλυσης, προτείνουμε μια μετρική αξιολόγηση βασισμένη στη σύγκριση μερικών ρητρών ερωτήματος που είναι πιο κατάλληλη για ερωτήματα πραγματικού κόσμου, και διεξάγουμε πειράματα με ισχυρές γραμμές βάσης, δείχνοντας ένα μεγάλο χάσμα μεταξύ της απόδοσης στο SEDE σε σύγκριση με άλλα κοινά σύνολα δεδομένων.', 'ka': 'უფრო მეტი ხელმისაწარმოდგენებული სემონტიკური განაცემება, რომელიც ფართოლური სიტყვების და ლოგიკური ფორმების ზოგიდან იყო, ყველაფერი იყენებულია ერთადერთი საზოგადო შემდეგ, ისინი არ აქვს ბედნიერება და განსხვავებული სახელსაწყოთა სიტყვების განსხვავება, სადაც ადამიანები მონაცემების შესახებ, რომელიც საჭირო მონაცემების შესახებ ამ სამუშაოში, ჩვენ SEDE-ს გახსნა, მონაცემების სექტი 12 023 კოსტრის და SQL კითხვების სამუშაო გამოყენებიდან სექტირებულია. ჩვენ ჩვენ გამოჩვენებთ, რომ ეს ზოგები აქვს განსხვავებული რეალური მსოფლიოს გამოცდილებების განსხვავება, რომლებიც ახლა უფრო ცოტა განსხვავებული სემონტიკური განსხვავება მონაცემების კლასების შესაბამისად მეტრიკური განსხვავება, რომლებიც რეალური მსოფლიოს კითხვებისთვი', 'it': "La maggior parte dei dataset di analisi semantica disponibili, costituiti da coppie di espressioni naturali e forme logiche, sono stati raccolti esclusivamente allo scopo di formare e valutare sistemi di comprensione del linguaggio naturale. Di conseguenza, non contengono alcuna ricchezza e varietà di espressioni naturali, in cui gli esseri umani chiedono informazioni di cui hanno bisogno o sono curiosi. In questo lavoro, rilasciamo SEDE, un set di dati con 12.023 coppie di parole e query SQL raccolte dall'uso reale sul sito Stack Exchange. Mostriamo che queste coppie contengono una varietà di sfide del mondo reale che sono state raramente riflesse finora in qualsiasi altro set di dati di analisi semantica, proponiamo una metrica di valutazione basata sul confronto di clausole di query parziali più adatte alle query del mondo reale, e conduciamo esperimenti con linee di base forti, mostrando un grande divario tra le prestazioni su SEDE rispetto ad altri set di dati comuni.", 'lt': 'Dauguma turimų semantinio analizavimo duomenų rinkinių, sudarytų iš natūralių žodžių ir logiškų formų poros, buvo surinkti tik gamtinių kalbų supratimo sistemų mokymo ir vertinimo tikslais. Todėl jose nėra jokių turtingų ir įvairių gamtos išraiškų, kuriose žmonės klausia apie duomenis, kurių jiems reikia arba kurie yra įdomūs. Šiame darbe išleidžiame SEDE, duomenų rinkinį su 12 023 poromis žodžių ir SQL klausimų, surinktų iš tikro naudojimo Stack Exchange interneto svetainėje. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.', 'kk': 'Қолданатын семантикалық талдау деректер жиындары, табиғи сөйлемелер мен логикалық пішімдері, табиғи тілдерді түсініктіру жүйелерінің оқыту мен оқыту үшін ғана жинақталды. Сонымен, адамдар өзінің қажетті деректер және қызығушылық туралы мәліметтерді сұрайды. Бұл жұмыс ішінде, біз SEDE- ді 12 023 қос сөз мен SQL сұрақтарымен шын қолдану вебсайтынан алып тастадық. Біз бұл екеуінің бірнеше семантикалық талдау деректер жиынында әлемдік әлемдік мәселелерді салыстырып, шын әлемдік сұрақтардың бөлігін салыстыруға негізделген метрикалық мәселелерді ұсынып, күшті негізгі сызықтарды тәжірибелерді тәжірибелерді көрсетеді, SEDE-дағы', 'ms': 'Kebanyakan set data penghuraian semantik yang tersedia, yang mengandungi pasangan ungkapan alami dan bentuk logik, dikumpulkan hanya untuk tujuan latihan dan penilaian sistem pemahaman bahasa alami. Sebagai hasilnya, mereka tidak mengandungi sebarang kekayaan dan pelbagai perkataan yang berlaku secara alami, di mana manusia bertanya tentang data yang mereka perlukan atau yang mereka ingin tahu. Dalam kerja ini, kami melepaskan SEDE, set data dengan 12,023 pasangan ucapan dan pertanyaan SQL yang dikumpulkan dari penggunaan sebenar di laman web Stack Exchange. Kami menunjukkan bahawa pasangan ini mengandungi pelbagai cabaran dunia nyata yang jarang dicerminkan sejauh ini dalam mana-mana set data penghuraian semantik lain, melaporkan metrik penilaian berdasarkan perbandingan klawsul pertanyaan sebahagian yang lebih sesuai untuk pertanyaan dunia nyata, dan melakukan eksperimen dengan garis dasar yang kuat, menunjukkan ruang besar antara prestasi pada SEDE dibandingkan dengan set data biasa lain.', 'ml': 'സ്വാഭാവിക വാക്കുകളും ലോഗിക്കല്\u200d രൂപങ്ങളും ചേര്\u200dത്തിരിക്കുന്ന സെമാന്\u200dറിക് പാര്\u200dസിങ്ങ് ഡാറ്റാസറ്റുകളില്\u200d ഏറ്റവും ലഭ്യമായ സെമാന അതിന്റെ ഫലമായി മനുഷ്യര്\u200dക്ക് ആവശ്യമുള്ള വിവരങ്ങളെക്കുറിച്ചോ ആശ്ചര്യപ്പെടുന്നതിനെക്കുറിച്ചോ അവര്\u200d ചോദിക്കുന്നു. ഈ പ്രവര്\u200dത്തനത്തില്\u200d ഞങ്ങള്\u200d സെഡിയെ വിടുന്നു, 12,023 വാക്കുകളുള്ള ഒരു ഡാറ്റാസസെറ്റ്, SQL വാക്കുകളുടെ സ്റ്റാക്ക് എക്സ്ചാങ്ങ് വെ നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നു ഈ ഇണകളില്\u200d യഥാര്\u200dത്ഥ ലോകത്തിലെ വ്യത്യാസങ്ങളുണ്ട്. മറ്റൊരു സെമാന്റിക് പാര്\u200dസിങ്ങ് ഡാറ്റാസെറ്റിലും പ്രത്യേകിക്കപ്പെട്ടിട്ടില്ലാത്ത വിലാസങ്ങളില്\u200d പ്രത്യേകിക്കപ', 'mk': 'Повеќето достапни семантични податоци за анализирање, кои се состојат од парови природни изрази и логични форми, беа собрани само со цел обука и проценка на природните системи за разбирање на јазикот. Како резултат на тоа, тие не содржат богатство и различност на природни изрази, каде луѓето прашуваат за податоците кои им се потребни или се љубопитни за. Во оваа работа, го објавуваме SEDE, компјутер на податоци со 12.023 пари изрази и SQL прашања собрани од вистинска употреба на веб-страницата Stack Exchange. Ние покажуваме дека овие парови содржат различни предизвици во реалниот свет кои досега ретко беа рефлектирани во било кој друг семантички податок за анализирање, предложуваме метрика за проценка базирана на споредба на клаузулите за делумно прашање кои се посоодветни за реалните прашања, и спроведуваме експерименти со силни бази линии, покажувајќи голема празнина поме', 'no': 'Dei fleste tilgjengelege semantiske tolking av datasett, som inneheld par av naturlige uttrykk og logiske formar, ble samla berre for opplæring og evaluering av naturlige språksforståkingssystemer. I resultatet inneheld dei ingen av riktigheten og variasjonen av naturlige uttrykk, der mennesker spør om data dei treng eller er nysgjerrige om. I denne arbeida løyser vi SEDE, eit dataset med 12 023 par uttaler og SQL-spørjingar samla frå verkeleg bruk på Stack Exchange-nettstaden. Vi viser at desse parene inneheld mange verdsutfordringar som rart vart reflektert så langt i alle andre semantiske analyseringsdatasett, foreslår ein evalueringsmetrisk basert på sammenligning av delvis spørjingsklassar som er meir passande for verdspørjingar, og gjer eksperimenter med sterke baselinjer, viser ein stor mellom utviklinga på SEDE i sammenligning med andre felles datasett.', 'mn': 'Байгалийн хэл болон логикийн хэлбэрээр байгалийн хэлбэрүүдийн хэлбэрүүдийн ихэнх semantic хуваалцах өгөгдлийн сангууд нь байгалийн хэл ойлголтын системийн сургалтын болон үнэлэх зорилгоор цорын ганц ц Үүний үр дүнд хүмүүс хэрэгтэй эсвэл сонирхолтой мэдээллийн талаар асуудаг байгалийн байгалийн баян, төрлийн хэлбэрүүд байхгүй. Энэ ажлын хувьд бид SEDE-г гаргаж өгөгдлийн санг 12.023 хэлбэрээр, SQL квери нь Stack Exchange вебсайт дээр жинхэнэ хэрэглээнээс цуглуулсан. Бид эдгээр хоёр хоёр нь жинхэнэ дэлхийн сорилтуудыг харуулж байна. Өөр хэдэн семантик хуваалцах өгөгдлийн санд ховорхон харагдаж буй хэсэг хэсэг хэсэг хэсэг хэсэг хэсгүүдийг харьцуулахад бага зэрэг тохиромжтой хэсгүүдийн тохиромжтой төлөвлөгдөж, хүчтэй суурь шугамны туршилтууд хийж, SEDE', 'pl': 'Większość dostępnych zbiorów danych analizy semantycznej, składających się z par wypowiedzi naturalnych i form logicznych, zebrano wyłącznie w celu szkolenia i oceny systemów rozumienia języka naturalnego. W rezultacie nie zawierają one żadnego bogactwa i różnorodności naturalnych wypowiedzi, w których ludzie pytają o dane, których potrzebują lub których są ciekawi. W tej pracy wydajemy SEDE, zbiór danych z 12,023 parami wypowiedzi i zapytań SQL zebranych z rzeczywistego użytkowania na stronie Stack Exchange. Pokazujemy, że pary te zawierają różnorodne wyzwania w świecie rzeczywistym, które rzadko były odzwierciedlone dotychczas w jakimkolwiek innym zbiorze danych analizowania semantycznego, proponujemy metrykę oceny opartą na porównaniu klauzul zapytań częściowych, która jest bardziej odpowiednia dla zapytań świata rzeczywistego oraz przeprowadzamy eksperymenty z silnymi liniami bazowymi, pokazując dużą lukę między wydajnością w SEDE w porównaniu z innymi powszechnymi zbiorami danych.', 'ro': 'Cele mai multe seturi de date de analizare semantică disponibile, cuprinzând perechi de expresii naturale și forme logice, au fost colectate exclusiv în scopul instruirii și evaluării sistemelor de înțelegere a limbajului natural. Ca urmare, ele nu conțin nici o bogăție și varietate de expresii naturale, în cazul în care oamenii întreabă despre datele de care au nevoie sau sunt curioși. În această lucrare, lansăm SEDE, un set de date cu 12.023 perechi de pronunțări și interogări SQL colectate din utilizare reală pe site-ul Stack Exchange. Aratăm că aceste perechi conțin o varietate de provocări din lumea reală care rareori au fost reflectate până în prezent în orice alt set de date de analizare semantică, propunem o metrică de evaluare bazată pe comparația clauzelor parțiale de interogare care este mai potrivită pentru interogările din lumea reală și efectuează experimente cu linii de bază puternice, arătând un decalaj mare între performanța pe SEDE comparativ cu alte seturi de date comune.', 'sr': 'Većina dostupnih semantičkih analiza podataka, uključujući parove prirodnih govora i logičkih oblika, bila je skupljena samo za svrhu obuke i procjene sustava prirodnog razumevanja jezika. Kao rezultat toga, oni ne sadrže nikakvu bogatstvo i raznolikost prirodnih izraza, gde ljudi pitaju o podacima o kojima im je potrebno ili znatiželjno. U ovom poslu, oslobodimo SEDE, kompletu podataka sa 12.023 par reči i ispitivanja SQL prikupljenih sa pravog korištenja na sajtu Stack Exchange. Pokazujemo da ovi par sadrže razne izazove na stvarnom svijetu koji su do sada rijetko odraženi u bilo kojoj drugoj semantičkoj analizi podataka, predlažemo metričku procjenu koja se temelji na usporedbi delovih klauzula za ispitivanje zahteva koji je prikladniji za stvarne svetske ispitivanja, i provodimo eksperimente sa jakim osnovnim linijama, pokazujući veliku prazninu između izvedbe na SEDE u usporedbi sa drugim zajedn', 'si': 'ගොඩක් පුළුවන් සෙමාන්ටික් විශ්ලේෂණ දත්ත සේට්, සම්පූර්ණ ස්වභාවික කිරීම සහ ලෝජික විශ්ලේෂණ වර්තනය සඳහා  ප්\u200dරතිචාරයෙන්, ඔවුන්ට ප්\u200dරශ්නයක් නැහැ ස්වාභාවික විදියට ප්\u200dරශ්නයක් නැහැ, මිනිස්සු ඔවුන්ට ඕනි දත්ත ගැන මේ වැඩේ අපි SEDE විස්තර කරනවා, දත්ත සෙට් 12,023 කුණු වචනයක් සහ SQL ප්\u200dරශ්නයක් ඇත්ත භාවිතාවයෙන් ස්ටැක් එකක්ෂන් වැබැයිට්  අපි පෙන්වන්නේ මේ ජෝඩු වලින් ඇත්ත ලෝක ප්\u200dරශ්නයක් තියෙනවා කියලා දැනටමත් අනුවෙන් ප්\u200dරශ්නයක් තියෙන්නේ අනුවෙන් සෙමැන්ටික් පරීක්ෂණ දත්ත සෙට් වලින්, අනුවෙන් අනුවෙන් අනුවෙන්', 'so': "Inta badan macluumaadka baaritaanka ee semantika ah, kuwaas oo ka mid ah hadal dabiicadda ah iyo noocyo caadiga ah, waxaa loo soo ururiyey si kaliya ah waxbarashada iyo qiimeynta nidaamka waxgarashada afka dabiicadda ah. Sababtaas darteed waxey ku haystaan hadallo hodantinimada ah oo kala duduwan oo dabiicadda ah, taas oo ay dadku weydiinayaan macluumaad ay u baahan yihiin ama ay ka fikiraan. Shaqadan ayaannu SEDE ka bixinaynaa, sawir macluumaad ah oo ku qoran 12,023 nooc oo hadal ah iyo su'aalo SQL ah oo laga soo ururiyey isticmaalka runta ah bogagga Stack Exchange. Waxaynu muujinnaa in labadaas ay ku jiraan dhibaatooyin kala duduwan ee caalamiga ah, kuwaas oo a an si yar u fiirsanayn dhamaan taariikhda baaritaanka kale ee semantik, waxay soo jeedinayaan qiimeynta metric oo ku saleysan qoraalada qeybta ah oo ugu haboon qoraalaha caalamka ah, waxaana sameynaya jirrabooyin aad u adag, waxayna muujinayaan muuqashada sameynta SEDE oo isbarbarbarbardhigta kaloo macluumaad ah.", 'sv': 'De flesta tillg채ngliga semantiska parsningsdataupps채ttningar, best책ende av par naturliga uttryck och logiska former, samlades enbart in i syfte att utbilda och utv채rdera system f철r f철rst책else av naturligt spr책k. Som ett resultat inneh책ller de inte n책gon av de rikedomar och variationer av naturligt f철rekommande yttranden, d채r m채nniskor fr책gar om data de beh철ver eller 채r nyfikna p책. I detta arbete sl채pper vi SEDE, en dataupps채ttning med 12 023 par yttranden och SQL-fr책gor insamlade fr책n verklig anv채ndning p책 Stack Exchange webbplats. Vi visar att dessa par inneh책ller en m채ngd olika verkliga utmaningar som s채llan reflekterats hittills i n책gon annan semantisk tolkningsdata, f철resl책r en utv채rderingsmetod baserad p책 j채mf철relse av partiella fr책gesatser som 채r mer l채mpade f철r verkliga fr책gor, och genomf철r experiment med starka baslinjer, vilket visar ett stort gap mellan prestanda p책 SEDE j채mf철rt med andra vanliga dataupps채ttningar.', 'mt': 'Il-biċċa l-kbira tas-settijiet ta’ dejta tal-analizzazzjoni semantika disponibbli, li jinkludu par ta’ dikjarazzjonijiet naturali u forom loġiċi, inġabru biss għall-finijiet tat-taħriġ u l-evalwazzjoni tas-sistemi ta’ fehim tal-lingwi naturali. B’riżultat ta’ dan, ma fihom l-ebda rikkezza u varjetà ta’ dikjarazzjonijiet naturali, fejn il-bnedmin jistaqsu dwar id-dejta li jeħtieġu jew huma kurjużi dwarha. In this work, we release SEDE, a dataset with 12,023 pairs of utterances and SQL queries collected from real usage on the Stack Exchange website.  Aħna nuru li dawn il-pari fihom varjetà ta’ sfidi tad-dinja reali li s’issa rarament kienu riflessi fi kwalunkwe sett ta’ dejta semantiku ieħor tal-analizzazzjoni, nipproponu metrika ta’ evalwazzjoni bbażata fuq paragun ta’ klawżoli ta’ mistoqsijiet parzjali li huma aktar adattati għal mistoqsijiet tad-dinja reali, u nieħdu esperimenti b’linji bażi b’saħħithom, li juru lakuna kbira bejn il-prestazzjoni fuq is-SEDE meta mqabbla ma', 'ta': 'கிடைக்கும் பெரும்பாலான பாடல் தகவல் அமைப்புகள், இயற்கையான வார்த்தைகள் மற்றும் தொழில்நுட்ப வடிவங்கள் சேர்க்கப்பட்டுள்ளன, இயற்கைய முடிவில், அவர்கள் எந்த பணக்கத்தையும் மற்றும் பல்வேறு இயற்கையான வார்த்தைகளையும் கொண்டிருக்கவில்லை, அங்கு மனிதர் இந்த வேலையில், நாம் SEDE, 12,023 ஜோடி வார்த்தைகள் மற்றும் SQL கேள்விகள் உண்மையான பயன்பாட்டில் இருந்து சேகரிக்கப்பட்டுள்ளது தள்ளி  இந்த ஜோடிகளில் இருக்கும் பல்வேறு உண்மையான உலக சவால்கள் இருக்கிறது இது பிரதிபலிக்கப்பட்ட எந்த வேறு பெமான்டிக் காட்சி தரவுத்தளத்திலும், பிரிவு கேள்வி குறிப்புகளை ஒப்பிட மெட்ரிக் சொல்லும் பொதுவான உலக', 'ur': 'زیادہ موجود سیمنٹی پارسینگ ڈیٹ سٹ، جسے طبیعی کلمات اور منطقی فرموں کے جوڑے ہیں، صرف طبیعی زبان سمجھنے کی سیستموں کی تعلیم اور ارزش کے لئے جمع کئے گئے۔ اس کے نتیجے میں ان کے پاس کوئی مالداری اور مختلف طبیعی کلمات نہیں ہے جہاں انسان ان ان کی نیاز ہے یا کنجکاوی کے بارے میں سوال کرتے ہیں۔ اس کام میں ہم SEDE کو آزاد کرتے ہیں، ایک ڈیٹ سٹ جو 12 023 کلمات اور SQL کوریس کے ساتھ استاک اکسچینچ ویٹ ویٹ ویٹ میں واقعی استعمال سے جمع کیے گئے ہیں۔ ہم دکھاتے ہیں کہ یہ جوڑے ایک مختلف حقیقی دنیاوی چالوں میں لگتے ہیں جو یہاں تک کسی دوسرے سیمنٹی پارسینگ ڈیٹ سٹ میں کم دکھائے جاتے ہیں، ایک منٹریک کا ارزش کرتا ہے جو اصل دنیاوی سوالوں کے لئے زیادہ مناسب ہے اور مضبوط بنسٹ لینوں کے ساتھ آزمائش کرتا ہے، SEDE کے عملکرد کے درمیان دوسرے مشترک ڈیٹ سٹ کے مقاب', 'uz': "Ko'pchilik maʼlumotlar tarkibidagi semantik parsing tarkibi, tabiiy so'zlarning ikkita so'zlari va logical formatlarida qo'llangan, faqat o'rganish va asl tilni o'qiymatish uchun bir xil tilni o'rganish va qiymatish uchun. Va natijada, ular hozir va tabiiy bo'lgan so'zlarning bir xil so'zlarida mavjud emas. Bu yerda odamlar kerakli maʼlumot haqida soʻrayapti yoki eng g'oyalar haqida o'ylaydi. Bu ishda, biz SEDE, 12,023 ikkita so'zlar va SQL soʻzlari haqiqiqiy foydalanuvchidan olingan soʻzlarni boshqaramiz. Biz shu ikkita qoʻllarda har xil dunyoning boshqa semantik parsing maʼlumotlarida ko'p qancha qiymatlar bor. Boshqa so ʻrov soʻrov soʻrovlariga qiymati kerak bo'lgan soʻrov soʻrovlariga qiymatlashni anglatmoqchimiz. Bu xavfsiz dunyo soʻrovlari uchun juda qiymatlashtirish mumkin.", 'vi': 'Phần lớn dữ liệu phân tích theo ngữ pháp có sẵn, gồm các cặp từ ngữ tự nhiên và các dạng logic, được thu thập chỉ để đào tạo và đánh giá các hệ thống hiểu biết ngôn ngữ tự nhiên. Kết quả là, chúng không chứa bất kỳ sự giàu có và phong phú của những phát ngôn tự nhiên hiện ra, nơi con người hỏi về dữ liệu mà họ cần hay tò mò muốn biết. Trong công việc này, chúng tôi công bố SEde, một bộ dữ liệu với 12,23 các cặp lời nhắn và mã SQL. Được lấy từ dữ liệu sử dụng thực sự trên trang web Stacks Exchange. Chúng tôi cho thấy những cặp này chứa nhiều thách thức thế giới thực mà hiếm khi được phản ánh trong bất kỳ bộ dữ liệu phân tích theo ngữ pháp nào khác, đề xuất một thước đo đánh giá dựa trên so sánh các hợp lệ truy vấn phần thích hợp hơn cho các câu hỏi trên thế giới thực, và thực hiện các thí nghiệm với các nền tảng mạnh, cho thấy một khoảng cách lớn giữa các hiệu suất trên SEE so với các tập tin dữ liệu chung.', 'bg': 'Повечето налични семантични анализиращи набори от данни, състоящи се от двойки естествени изказвания и логически форми, са събрани единствено с цел обучение и оценка на системите за разбиране на естествения език. В резултат на това те не съдържат нито едно от богатството и разнообразието на природни изказвания, където хората питат за данни, от които се нуждаят или са любопитни. В тази работа публикуваме набор от данни с 12 023 двойки изказвания и заявки, събрани от реална употреба на сайта. Показваме, че тези двойки съдържат различни предизвикателства от реалния свят, които рядко са били отразени досега в други семантични анализиращи набори от данни, предлагаме метрична оценка, базирана на сравнение на клаузи за частични заявки, която е по-подходяща за заявки от реалния свят, и провеждаме експерименти със силни базови линии, показвайки голяма разлика между производителността на SEDE в сравнение с други общи набори от данни.', 'da': 'De fleste tilgængelige semantiske fortolkningsdatasæt, bestående af par af naturlige udtalelser og logiske former, blev udelukkende indsamlet med henblik på uddannelse og evaluering af natursprogforståelsessystemer. Som følge heraf indeholder de ikke nogen af de rigdom og mangfoldighed af naturligt forekommende udtalelser, hvor mennesker spørger om data, de har brug for eller er nysgerrige på. I dette arbejde frigiver vi SEDE, et datasæt med 12.023 par udtalelser og SQL-forespørgsler indsamlet fra reel brug på Stack Exchange hjemmesiden. Vi viser, at disse par indeholder en række udfordringer i den virkelige verden, som sjældent har været afspejlet indtil videre i noget andet semantisk parsing datasæt, foreslår en evalueringsmetric baseret på sammenligning af partielle forespørgselssætninger, der er mere egnet til den virkelige verden forespørgsler, og udfører eksperimenter med stærke baselines, der viser en stor kløft mellem ydeevnen på SEDE sammenlignet med andre almindelige datasæt.', 'nl': "De meeste beschikbare semantische parsing datasets, bestaande uit paren van natuurlijke uitingen en logische vormen, werden uitsluitend verzameld met het oog op training en evaluatie van systemen voor het begrijpen van natuurlijke taal. Hierdoor bevatten ze niets van de rijkdom en verscheidenheid van natuurlijke uitingen, waar mensen vragen naar gegevens die ze nodig hebben of waar ze nieuwsgierig naar zijn. In dit werk brengen we SEDE uit, een dataset met 12,023 paren van uitspraken en SQL query's verzameld van echt gebruik op de Stack Exchange website. We tonen aan dat deze paren een verscheidenheid aan uitdagingen in de echte wereld bevatten die tot nu toe zelden werden weerspiegeld in een andere semantische parsing dataset, stellen een evaluatiemetriek voor gebaseerd op vergelijking van partiële query clausules die geschikter is voor real-world query's, en voeren experimenten uit met sterke baselines, die een grote kloof tonen tussen de prestaties op SEDE in vergelijking met andere gemeenschappelijke datasets.", 'hr': 'Većina dostupnih semantičkih analiza podataka, uključujući par prirodnih govora i logičkih oblika, bila je skupljena samo za svrhu obuke i procjene sustava prirodnog razumijevanja jezika. Kao rezultat toga, oni ne sadrže nikakvu bogatstvu i raznolikost prirodnih izraza, gdje ljudi pitaju o podacima o kojima su potrebni ili znatiželjni. U ovom poslu oslobađamo SEDE, kompletu podataka sa 12.023 par izraza i SQL ispitivanja prikupljenih iz prave korištenja na internetskoj stranici Stack Exchange. Mi pokazujemo da te pare sadrže razne izazove na stvarnom svijetu koji su do sada rijetko odraženi u bilo kojem drugom semantičkom razmatranju podataka, predlažemo metričku procjenu temeljnu na usporedbi djelomičnih klauzula za pitanje ispitivanja na stvarnom svijetu, i provoditi eksperimente s jakim osnovnim linijama, pokazujući veliku razliku između učinka na SEDE u usporedbi s drugim zajedničkim podacima.', 'ko': '대부분의 사용 가능한 의미 분석 데이터 집합은 쌍을 이루는 자연 언어와 논리 형식을 포함하여 모두 자연 언어 이해 시스템을 훈련하고 평가하기 위해 수집된 것이다.따라서 자연적으로 발생하는 다양한 말은 포함되지 않는다. 인간은 이 말에서 그들이 필요로 하거나 궁금해하는 데이터를 묻는다.이 작업에서 우리는 12023개의 대화어와 SQL 조회를 포함하는 데이터 집합을 발표했고 Stack Exchange 사이트의 실제 사용에서 수집했다.우리는 이러한 다양한 현실 세계를 포함하는 도전에 대해 증명했다. 이런 도전은 지금까지 다른 의미 분석 데이터에 집중적으로 반영되지 않았다. 우리는 일부 조회 자구를 비교하는 평가 지표를 제시했다. 이 지표는 현실 세계의 조회에 더욱 적합하고 강력한 기준을 사용하여 실험을 실시한 결과 SEDE의 성능은 다른 흔히 볼 수 있는 데이터 집합에 비해 큰 차이가 있음을 나타냈다.', 'id': 'Kebanyakan dataset penghuraian semantis yang tersedia, terdiri dari pasangan ucapan alami dan bentuk logis, dikumpulkan hanya untuk tujuan latihan dan evaluasi sistem pemahaman bahasa alami. Sebagai hasilnya, mereka tidak mengandung kekayaan dan berbagai macam perkataan yang terjadi secara alami, di mana manusia bertanya tentang data yang mereka butuhkan atau ingin tahu. Dalam pekerjaan ini, kami melepaskan SEDE, sebuah set data dengan 12.023 pasangan ucapan dan pertanyaan SQL yang dikumpulkan dari penggunaan nyata di situs Stack Exchange. Kami menunjukkan bahwa pasangan-pasangan ini mengandung berbagai tantangan dunia nyata yang jarang terrefleksi sejauh ini dalam sett data penghuraian semantis lainnya, melaporkan metrik evaluasi berdasarkan perbandingan dari klawsul pertanyaan parsial yang lebih cocok untuk pertanyaan dunia nyata, dan melakukan eksperimen dengan garis dasar yang kuat, menunjukkan ruang besar antara prestasi di SEDE dibandingkan dengan sett data umum lainnya.', 'fa': 'بیشترین مجموعه\u200cهای تجزیه داده\u200cهای semantic در دسترسی از جفت کلمات طبیعی و فرم\u200cهای منطقی تنها برای تمرین و ارزیابی سیستم\u200cهای درک زبان طبیعی جمع می\u200cشوند. به نتیجه، آنها هیچ گونه ثروتمندی و مختلف کلمات طبیعی وجود ندارند، جایی که مردم درباره اطلاعات می پرسند که آنها نیاز دارند یا کنجکاو هستند. در این کار، ما SEDE را آزاد می کنیم، یک مجموعه اطلاعات با 12.023 جفت سخنرانی و سوال SQL که از استفاده واقعی در وبسایت استاک Exchange جمع شده است. ما نشان می دهیم که این جفت ها مختلف چالش دنیای واقعی را دارند که به این حال در هر مجموعه\u200cی تجزیه داده\u200cهای semantic نشان داده می\u200cشوند، یک متریک ارزیابی را پیشنهاد می\u200cدهیم که بر مقایسه از مجموعه\u200cهای پاره\u200cای درخواست\u200cهای دنیای واقعی مناسب\u200cتر است، و آزمایش\u200cهای با خطوط\u200cهای بنیادی قوی\u200cتر است، که در مقایسه با مجموعه\u200cهای داده\u200cهای معمولی', 'tr': "I흫 k철p me흫ze힊 semantik anal첵힊im veri setirleri, tebigy s철zleri we logik bi챌imleri bolan, tebigy dilleri흫 d체힊체nme sistemlerini흫 bilim we 챌철z체mlenmegi 체챌in birle힊ildi. Sonu챌 olarak insan gerekli veriler hakk캇nda bilgi soruyor ya da merak ediyor. Bu i힊de, SEDE'i 12.023 sany s철z we SQL soraglary hakyky ulanmakdan 챌yk첵an bir veri setini 챌ykardyk. Biz bu 챌iftlerde d체n첵채de birn채챌e 챌철z체mler bar. 힇u wagt hem be첵leki semantik anal첵힊im sisteminde g철r체l첵채r. Ger챌ek d체n첵채de soraglary흫 we g체첵챌li bazarlar bilen de흫le첵채n 챌철z체mler 체챌in bir metrik de흫le첵채n 챌철z체mlerini tassyklap ed첵채ris. SEDE 체첵tgetmesi 체챌in be첵leki data첵atlar bilen de흫le첵채n 챌철z체mlerini g철r첵채n.", 'de': 'Die meisten verfügbaren semantischen Parsing-Datensätze, bestehend aus Paaren natürlicher Äußerungen und logischer Formen, wurden ausschließlich zum Zweck des Trainings und der Evaluation natürlicher Sprachverständnissysteme gesammelt. Infolgedessen enthalten sie nichts von dem Reichtum und der Vielfalt natürlicher Äußerungen, bei denen Menschen nach Daten fragen, die sie benötigen oder auf die sie neugierig sind. In dieser Arbeit veröffentlichen wir SEDE, einen Datensatz mit 12,023 Paaren von Äußerungen und SQL Abfragen, die aus der realen Nutzung auf der Stack Exchange Website gesammelt wurden. Wir zeigen, dass diese Paare eine Vielzahl von realen Herausforderungen enthalten, die bisher in keinem anderen semantischen Parsing-Datensatz widergespiegelt wurden, schlagen eine Auswertungsmetrik vor, die auf dem Vergleich von Teilabfrageklauseln basiert, die besser für reale Abfragen geeignet ist, und führen Experimente mit starken Baselines durch, die eine große Lücke zwischen der Leistung auf SEDE im Vergleich zu anderen gängigen Datensätzen zeigen.', 'sq': 'Shumica e të dhënave të analizimit semantik të disponueshme, të përbërë nga çifte shprehjesh natyrore dhe forme logjike, u mblodhën vetëm për qëllim trajnimit dhe vlerësimit të sistemeve natyrore të kuptimit të gjuhës. Si rezultat, ata nuk përmbajnë asnjë nga pasuria dhe shumëllojshmëria e shprehjeve natyrore që ndodhin, ku njerëzit pyesin për të dhënat për të cilat kanë nevojë ose janë kuriozë. Në këtë punë, ne lëshojmë SEDE, një set të dhënash me 12,023 palë shprehje dhe pyetje SQL të mbledhura nga përdorimi i vërtetë në uebsajtin Stack Exchange. Ne tregojmë se këto çifte përmbajnë një shumëllojshmëri sfidash të botës reale që rrallë u pasqyruan deri tani në ndonjë set tjetër të dhënash të analizimit semantik, propozojnë një metrik vlerësimi bazuar në krahasimin e klauzulave të pyetjeve të pjesshme që janë më të përshtatshme për pyetjet e botës reale dhe kryejnë eksperimente me linja bazë të forta, duke treguar një dallim të madh midis performancës në SEDE krahasuar me të tjera', 'sw': 'Takwimu nyingi zinazopatikana kwa ajili ya mafunzo na kutathmini mifumo ya kuelewa lugha ya asili. Matokeo yake, hawana utajiri wowote wa maneno yanayotokea asilia, ambapo binadamu wanauliza kuhusu data wanazohitaji au wanajiuliza. Katika kazi hii, tunatoa SEDE, seti ya taarifa yenye hotuba 12,023 na maswali ya SQL yalikusanywa kutoka matumizi halisi katika tovuti ya Stack Exchange. Tunaonyesha kuwa hawa ndoa zina changamoto mbalimbali za kimataifa ambazo zilionekana vibaya mpaka sasa katika seti nyingine za mabadiliko ya semantic, pendekeza uchunguzi wa mbinu kwa kulinganisha vipengele vya utafiti ambavyo ni muhimu zaidi kwa maswali ya kimataifa, na kutekeleza majaribio yenye misingi imara, kuonyesha tofauti kubwa kati ya utendaji wa SEDE ukilinganishwa na seti nyingine za data za kawaida.', 'am': 'ብዙዎቹ የፍጥረት ቃላት እና የሎጂ ፎርማቶች የሚቆጠሩ የsemantic ማኅበረሰብ ዳታዎችን ለፍጥረት ቋንቋ ማስተዋል ስርዓቶች ማስተምርና ማስተምር ብቻ ተሰብስባቸዋል፡፡ ይሄንን ምክንያት ሰዎች የሚያስፈልጉትን ወይም የሚያስደነግጡትን ዳታ የሚጠይቁበት ባለጠግነት እና የተለያዩ የፍጥረታዊ ቃላት ምንም አይገኙም፡፡ በዚህ ሥራ የSEDE፣ 12,023 ዓይነቶች የንግግር እና SQL ጉዳዮች በStack Exchange ድረ ገጽ ላይ የተሰበሰቡ የዳታ ሰርቨርስቲ እናስቀራለን፡፡ እናሳያቸዋለን፣ እነዚህ ሁለንተናዎች እስከ ዛሬ ድረስ በሌሎች የsemantic parsing ዳታ ማዕከላዊ ጥያቄዎች ላይ የተለያዩ የዓለም ጥያቄ ጥያቄዎች የሚኖሩትን እና ከሌሎቹ ትልቅ ዳታተሮች ጋር በሚያሳየው የክፍል ጥያቄዎችን በመተካከል የተመሳሳይ ሚትሪክ እና በብርቱ መሳሪያ ተፈተናዎችን እና በSEDE ላይ ትልቅ ክፍል የሚያሳየው ነው፡፡', 'af': "Die meeste beskikbaar semantiese verwerking van datastelle, bevat van paar van natuurlike uitspraak en logiese vorms, is slegs versamel vir die doel van onderwerp en evaluering van natuurlike taalsverstandingsstelsels. As 'n resultaat, bevat hulle nie enige van die rykdom en verskilligheid van natuurlike voordeel nie, waar mense vra oor die data wat hulle nodig of is nuuskierig oor. In hierdie werk verlos ons SEDE, 'n datastel met 12.023 paar uitspraak en SQL vrae versamel van regte gebruik op die Stack Exchange webwerp. Ons wys dat hierdie paar bevat 'n verskilligheid van reël-wêreld uitdrukkings wat eers in enige ander semantiese verwerking datastel tot ver reflekteer is, voorstel 'n evaluering metriek gebaseer op vergelyking van gedeeltelike navraag klauses wat meer geskikbaar is vir reël-wêreld navraag, en uitvoer eksperimente met sterke basisline, wys 'n groot spasie tussen die uitdrukking op SEDE vergelyk met", 'hy': 'Ամենաշատ հասանելի սեմանտիկ վերլուծության տվյալների համակարգեր, որոնք կազմված են բնական արտահայտությունների և տրամաբանական ձևերի զույգերից, հավաքվեցին միայն բնական լեզվի հասկացման համակարգերի ուսուցման և գնահատման նպատակով: Արդյունքում դրանք չեն պարունակում բնական արտահայտությունների հարստությունը և բազմազանությունը, որտեղ մարդիկ հարցնում են տվյալների մասին, որոնց մասին նրանք կարիք ունեն կամ հետաքրքիր են: Այս աշխատանքի ընթացքում մենք հրապարակում ենք SEDE ը, 12,053 զույգ արտահայտությունների և SQL հարցերի տվյալներ, որոնք հավաքվել են Stack Trade կայքում իրական օգտագործման արդյունքում: Մենք ցույց ենք տալիս, որ այս զույգերը պարունակում են բազմաթիվ իրական աշխարհի մարտահրավերներ, որոնք մինչ այժմ հազվադեպ են արտացոլում ցանկացած այլ սեմանտիկ վերլուծության տվյալների համակարգում, առաջարկում են գնահատման մետրիկ, հիմնված մասամբ հարցերի համեմատության վրա, որը ավելի համապատասխան է իրական աշխարհի հարցերի համար, և կատարում են փորձեր ուժ', 'bs': 'Većina dostupnih semantičkih analiza podataka, uključujući par prirodnih govora i logičkih oblika, bila je skupljena samo za cilj obuke i procjene sustava prirodnog razumijevanja jezika. Kao rezultat toga, oni ne sadrže nikakvu bogatstvo i raznolikost prirodnih izraza, gdje ljudi pitaju o podacima o kojima trebaju ili su znatiželjni. U ovom poslu, oslobodimo SEDE, kompletu podataka sa 12.023 par govora i SQL ispitivanja prikupljenih iz prave korištenja na sajtu Stack Exchange. Pokazujemo da ovi par sadrže razne izazove na stvarnom svijetu koji su do sada rijetko odraženi u bilo kojoj drugoj semantičkoj analizaciji podataka, predlažemo metričku procjenu na osnovu usporedbe djelomičnih klauzula za pitanje pitanja koja je prikladnija za ispitivanje realnog svijeta, i provoditi eksperimente sa jakim osnovnim linijama, pokazujući veliku prazninu između učinka na SEDE u usporedbi s drugim zajednič', 'az': "Təbiətli sözlər və lojik formlardan olan ən çox semantik analizə verilən qurular təbiətli dil anlama sistemlərinin təhsil və təhsil etmək üçün təhsil edilmişdir. Buna görə də insanların ehtiyacı olduğu və ya meraklı məlumatları haqqında soruşduqları təbiətli və təbiətli sözlərdən heç bir şey yoxdur. Bu işdə SEDE'i, Stack Exchange sitəsində gerçek istifadədən toplanmış 12.023 sözlər və SQL soruşmaları olan veri qurğuları yayındırırıq. Biz bu cütlər həqiqət dünyanın müxtəlif çətinliklərini göstəririk ki, bu cütlər həyata qədər çox semantik ayırma verilər qutusu içində, həyat dünyanın soruşmalarına daha uyğun və güclü baz çətinlikləri ilə müxtəlif təcrübələrini təşkil edir, SEDE'nin başqa ortaq verilər qutusu ilə dəyişdirilməsi ilə çox böyük səbəb göstərir.", 'ca': "La majoria de conjunts de dades d'analització semàntica disponibles, composts de parells de expressions naturals i formes lògiques, es van recollir només per a formar i evaluar els sistemes naturals de comprensió del llenguatge. Com a resultat, no contenen cap de les riqueses i varietats d'expressions naturals, on els humans pregunten sobre les dades que necessiten o són curioses. En aquest treball, vam publicar SEDE, un conjunt de dades amb 12.023 parelles de frases i preguntes SQL recollides a partir d'un ús real a la pàgina web Stack Exchange. Mostrem que aquests parells contenen una varietat de reptes del món real que tan poc s'han reflexionat fins ara en qualsevol altre conjunt de dades semàntiques d'analització, proposem una mesura d'evaluació basada en la comparació de clàusules de consulta parcial més apropiades per a consultas del món real, i condueixen experiments amb línies de base fortes, mostrant una gran diferència entre el rendiment de SEDE en comparació amb altres conjunts de dades comuns.", 'bn': 'বেশীরভাগ প্রাকৃতিক বক্তব্য এবং লজিক ফর্মের মধ্যে বিভিন্ন সেমেন্টিক পার্সিং ডাটাসেট, প্রাকৃতিক ভাষা বোঝার উদ্দেশ্যে শুধু এর ফলে তাদের কোন সমৃদ্ধ এবং বিভিন্ন প্রাকৃতিক ভাষার মধ্যে নেই, যেখানে মানুষ তাদের প্রয়োজনীয় তথ্য সম্পর্কে জিজ্ঞেস করে অথবা তা এই কাজে আমরা সেডিকে মুক্তি দিচ্ছি, যার সাথে ১২,০২৩ জোড়া ভাষা এবং এসকিউএল প্রশ্নের একটি ডাটাসেট, যা স্ট্যাক এক্সচেঞ্জ ওয়েবসাইটে সং আমরা দেখাচ্ছি যে এই জোড়ার মধ্যে বিভিন্ন বিভিন্ন বিশ্বের চ্যালেঞ্জ রয়েছে যা এতদিন পর্যন্ত অন্যান্য সেম্পেন্টিক পার্সিং ডাটাসেটে প্রতিক্রিয়া প্রদর্শন করা হয়েছে, যা পার্টিক ক ক্লাসের তুলনায় ভিত্তিক মেট', 'fi': 'Suurin osa saatavilla olevista luonnollisista lauseista ja loogisista muodoista koostuvista semanttisista jäsennysaineistoista kerättiin yksinomaan luonnollisen kielen ymmärtämisjärjestelmien koulutusta ja arviointia varten. Näin ollen ne eivät sisällä luonnon ilmaisujen rikkautta ja monipuolisuutta, jossa ihmiset kysyvät tarvitsemaansa dataa tai ovat uteliaita. Tässä työssä julkaisemme SEDE-aineiston, joka sisältää 12 023 lauseparia ja SQL-kyselyjä, jotka on kerätty Stack Exchange -sivuston todellisesta käytöstä. Osoitamme, että nämä parit sisältävät erilaisia reaalimaailman haasteita, jotka ovat tähän mennessä harvoin heijastuneet mihinkään muuhun semanttiseen jäsennysaineistoon, ehdotamme osittaisten kyselylauseiden vertailuun perustuvaa arviointimetriikkaa, joka sopii paremmin reaalimaailman kyselyihin, ja teemme kokeita vahvoilla perusviivoilla, mikä osoittaa, että SEDE:n suorituskyvyn välillä on suuri ero muihin yleisiin tietoaineistoihin verrattuna.', 'cs': 'Většina dostupných sémantických parsovacích datových sad, sestávajících z párů přirozených výroků a logických forem, byla shromážděna výhradně za účelem výcviku a hodnocení systémů porozumění přirozenému jazyku. V důsledku toho neobsahují žádnou z bohatství a rozmanitosti přirozeně se vyskytujících výroků, kde se lidé ptají na data, která potřebují nebo jsou zvědaví. V této práci vydáváme SEDE, datovou sadu s 12,023 páry výroků a SQL dotazů shromážděných z reálného použití na webových stránkách Stack Exchange. Ukazujeme, že tyto páry obsahují celou řadu výzev v reálném světě, které byly zatím zřídka reflektovány v jakékoli jiné sémantické parsovací datové sadě, navrhujeme hodnotící metriku založenou na srovnání dílčích dotazových klauzul, která je vhodnější pro reálné dotazy, a provádíme experimenty se silnými základními liniemi, ukazující velkou mezeru mezi výkonem SEDE ve srovnání s ostatními běžnými datovými sadami.', 'et': "Enamik olemasolevaid semantilisi parsimisandmekogumeid, mis koosnevad looduslike väljendite ja loogiliste vormide paaridest, koguti üksnes looduskeele mõistmise süsteemide koolitamiseks ja hindamiseks. Selle tulemusena ei sisalda need looduslike väljendite rikkalikkust ja mitmekesisust, kus inimesed küsivad andmeid, mida nad vajavad või mida huvitavad. Selles töös avaldame andmekogumi SEDE, mis sisaldab 12 023 paari väljendeid ja SQL-päringuid, mis on kogutud Stack Exchange'i veebisaidil reaalse kasutamise käigus. Näitame, et need paarid sisaldavad mitmesuguseid reaalmaailma väljakutseid, mida seni harva peegeldati üheski teises semantilises parsimisandmekogumis, pakume välja hindamismeetodika, mis põhineb osalise päringu klauslite võrdlemisel, mis sobib reaalmaailma päringute jaoks paremini, ning teostame katseid tugevate lähtejoontega, näidates suurt lõhet SEDE jõudluse vahel võrreldes teiste tavaliste andmekogumitega.", 'sk': 'Večina razpoložljivih semantičnih zbirk podatkov razčlenitve, ki so sestavljeni iz parov naravnih izgovorov in logičnih oblik, je bila zbrana izključno za namene usposabljanja in vrednotenja sistemov razumevanja naravnega jezika. Posledično ne vsebujejo bogastva in raznolikosti naravnih izgovorov, kjer ljudje sprašujejo o podatkih, ki jih potrebujejo ali zanimajo. V tem delu objavljamo SEDE, nabor podatkov z 12.023 parov izjav in SQL poizvedb, zbranih iz resnične uporabe na spletni strani Stack Exchange. Pokazali smo, da ti pari vsebujejo različne resnične izzive, ki so se doslej redko odražali v katerem koli drugem semantičnem razčlenjevanju podatkov, predlagali ocenjevalno metriko, ki temelji na primerjavi delnih poizvedbenih klavzul, ki je bolj primerna za resnične poizvedbe, in izvedli poskuse z močnimi osnovnimi črtami, kar kaže veliko vrzel med učinkovitostjo na SEDE v primerjavi z drugimi skupnimi nabori podatkov.', 'ha': "Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of natural language understanding systems.  Saboda haka, ba su ƙunsa da wasu matajiri da wasu kalmõmi masu cikin kashfa, inda mutane ke tambayar data da ake bukãta ko suna tambayar su. Daga wannan aikin, Muke saka DA, wani tsarin da aka samu 12,23-nau'i na magana da SQL masu samun su daga amfani da gaskiya a kan Stack Exphange website. Tuna nũna wa waɗannan nau'a suna da wasu masu cikin duniya masu cikin gaskiya waɗanda aka yi wa muhimma ko da yaushe na cikin wasu danne-parse na semantic, sai ka buƙata an evaluci metric a kan daidaita ga fasalin rabo-tambayar musamman wanda yake mafi daidai ga masu tambayar duniya da gaskiyar, kuma ana sami jarrabori da baƙa ƙo masu ƙarfi, sunã nuna gaɓanci mai girma a tsakanin mafarin tsakanin na CEDA da sami da waɗansu danasõn da suka zama daidaita.", 'jv': 'Daftar semanti dipunanggé dataset, ditawakdhéwé, sampeyan tanggal pawarang pribadhakan lan logik, iki bakal ngregani dipunanggé kanggo nggawe sistem sing apik dhéwé. Yo wis dipoleh, wong kuwi or a nesatur perbudhakan liyane lan nganggo perbudhakan kanggo langgar-langgar, lan uwis seneng pisan barang data dhéwé kudu dhéwé ngerasakno. Nang barêng-barêng iki, kita mbukak SEDES, dadi nggawe 12.02 3 pating kelengatan perusahaan lan kelas Awak dhéwé éntuk sistem iki ngono perusahaan akeh perusahaan anyar-perusahaan sing dibutungan winih sing dibutungane kuwi tindakan semantar dataset sing wis dipatensi, supoyo perusahaan meta sing basa gambar nggawe perusahaan winih sing dibutungan winih-perusahaan sing luwih nggawe gerakan kanggo dianggap sing dianggap luwih dumadhi iki banget nggawe dataset sing berarti.', 'he': 'רוב המערכות הנתונים הסמנטיות הנוכחות, המכילות מזוגים של מילים טבעיים וצורות הגיוניים, נאספו רק למטרה האימון והעריכה של מערכות הבנה טבעית לשפה. כתוצאה מכך, הם לא מכילים שום דבר מהעשירה ומגוון של מילים טבעיים מתרחשים, שבו בני אדם שואל על נתונים שהם צריכים או סקרנים עליהם. בעבודה הזו, אנחנו משחררים את SEDE, קבוצת נתונים עם 12,023 זוגות מבטות וביקשות SQL שנאספו משימוש אמיתי באתר Stack Exchange. אנו מראים שהזוגות האלה מכילות מגוון של אתגרים בעולם האמיתי שבלעיתים נדירות השקפו עד כה בכל קבוצת נתונים של בדיקת סמנטית אחרת, מציעים מטריקה עריכה מבוססת על השוואה של פסקי חקירה חלקית שמתאימים יותר לשאלות בעולם האמיתי, ומבצעים ניסויים עם קווי בסיס חזקים, מראים פער גדול בין ההופעה על SEDE בהשוואה לקבו', 'bo': 'སྔོན་ཤུགས་ཀྱི་ལྟ་བུའི་ཆེས་ཉིད་མཁན་གྱི་དབྱེ་སྟངས་བཅས་ཀྱི་མཐུན་རིམ་དང་མིང་རྩལ་ཆུང་ལ་བསྡད་ཡོད། དབྱིབས་འབྲས་དུ་མི་མཐུན་པ་དང་མཐུན་རྐྱེན་པའི་ཐ་སྙད་ཚུལ་གང་ཡང་མིན་འདུག In this work, we release SEDE, a data set with 12,023 pairs of utterances and SQL queries collected from real usage on the Stack Exchange website. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.'}
{'en': 'Bag-of-Words Baselines for Semantic Code Search', 'ar': 'حقيبة من الكلمات الأساسية للبحث عن الشفرة الدلالية', 'fr': 'Lignes de base de sacs de mots pour la recherche de code sémantique', 'pt': 'Linhas de base do saco de palavras para pesquisa de código semântico', 'es': 'Líneas base de bolsa de palabras para la búsqueda de código semántico', 'ja': 'セマンティックコード検索のための言葉のバッグベースライン', 'ru': 'Базовые линии Bag-of-Sords для поиска семантического кода', 'zh': '以语义代码索词袋基线', 'hi': 'सिमेंटिक कोड खोज के लिए बैग-ऑफ-वर्ड्स बेसलाइन', 'ga': 'Bunlínte Bag-of-Ford le haghaidh Cuardach Cód Séimeantach', 'el': 'Γραμμές βάσης λέξεων για την αναζήτηση σημασιολογικού κώδικα', 'hu': 'A szemantikus kód keresésének alapjai', 'kk': 'Semantic код іздеу үшін сөздер негізгі сызықтары', 'it': 'Base Bag-of-Words per la ricerca di codice semantico', 'lt': 'Semantinio kodo paieškos žodžių maišelio bazės', 'mk': 'Базични линии за семантично пребарување на кодот', 'ms': 'Baris asas beg-perkataan untuk Carian Kod Semantik', 'mt': 'Linji bażi tal-borża tal-kliem għat-tiftix tal-Kodiċi Semantiku', 'ml': 'സെമാന്റിക് കോഡിനുള്ള വാക്കുകളുടെ അടിസ്ഥാനങ്ങള്\u200d', 'mn': 'Semantic Code Search', 'pl': 'Podstawy worka słów dla wyszukiwania kodu semantycznego', 'ro': 'Pungă de cuvinte de referință pentru căutarea codului semantic', 'si': 'Name', 'ka': 'სიტყვების ბაზი ხაზები სემანტიკური კოდის ძებნა', 'no': 'Ordbaselinjer for semiantisk kodsøk', 'so': 'Qoraalka codsiga Semantic', 'sv': 'Baslinjer för ordsäck för semantisk kod Sök', 'ta': 'Name', 'ur': 'سیمنٹی کوڈ تلاش کے لئے بات-of-Words Baselines', 'sr': 'Prazne linije za semantički pretragu kodova', 'uz': 'Name', 'vi': 'Tìm kiếm mật mã trung thành', 'hr': 'Pravne linije za pretragu semantičkog koda', 'bg': 'Базови линии за търсене на семантичен код', 'da': 'Bag-of-Words basislinjer for semantisk kodesøgning', 'nl': 'Basislijnen voor semantische code zoeken', 'de': 'Wortbeutel-Baselines für die Suche nach semantischem Code', 'ko': '의미 코드 검색에 사용되는 단어 패키지 기선', 'id': 'Garis dasar tas-kata untuk Pencarian Kode Semantik', 'sw': 'Maelezo ya maneno kwa ajili ya kutafuta Sheria ya Semantic', 'fa': 'خطوط بنیادی کلمات برای جستجوی کد سیمانتیک', 'sq': 'Bag-of-Words Baselines for Semantic Code Search', 'hy': 'Comment', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bn': 'Name', 'tr': 'Semantik Kod Arama üçin sözleriň esasy hatlary', 'af': 'Name', 'cs': 'Sáček slov Základní linie pro vyhledávání sémantického kódu', 'az': 'Semantik Kod Araması', 'ca': 'Llinies de base de la borsa de paraules per a la búsqueda de codi semàntic', 'et': 'Semantilise koodi otsingu sõnadekott', 'fi': 'Laukku-of-Words Baselines for Semantic Code Search', 'bs': 'Prtljažne linije za pretragu semantičkog koda', 'jv': 'Vag-of-words', 'ha': 'Bag-of-Words Baselines for Semantic Code Search', 'sk': 'Izhodišča vrečke besed za iskanje semantičnih kod', 'bo': 'སྔོན་འཛུགས་ཀྱི་གསལ་འཚོལ་བཤེར་ལ་བརྗོད་ཐོག་གི་གནད་དོན་གཞི་རྟེན་འབྲི་བ', 'he': 'קווי התיק של מילים לחפש קוד סמנטי'}
{'en': 'The task of semantic code search is to retrieve  code snippets  from a  source code corpus  based on an information need expressed in  natural language . The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. It is a common assumption that traditional bag-of-words IR methods are poorly suited for semantic code search : our work empirically investigates this assumption. Specifically, we examine the effectiveness of two traditional IR methods, namely  BM25  and  RM3 , on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets. We find that the two keyword-based methods outperform several pre-BERT neural models. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.', 'ar': 'تتمثل مهمة البحث عن الشفرة الدلالية في استرداد مقتطفات التعليمات البرمجية من مجموعة التعليمات البرمجية المصدر بناءً على الحاجة إلى المعلومات التي يتم التعبير عنها بلغة طبيعية. لطالما اعتبرت الفجوة الدلالية بين اللغة الطبيعية ولغات البرمجة واحدة من أهم العقبات التي تحول دون فعالية طرق استرجاع المعلومات (IR) القائمة على الكلمات الرئيسية. من الافتراض الشائع أن أساليب IR "التقليدية" لأكياس الكلمات ليست مناسبة تمامًا للبحث عن الكود الدلالي: يقوم عملنا بالتحقيق في هذا الافتراض تجريبيًا. على وجه التحديد ، نحن ندرس فعالية طريقتين تقليديتين للأشعة تحت الحمراء ، وهما BM25 و RM3 ، على CodeSearchNet Corpus ، والتي تتكون من استعلامات لغة طبيعية مقترنة بمقتطفات التعليمات البرمجية ذات الصلة. نجد أن الطريقتين المستندة إلى الكلمات الرئيسية تتفوقان على العديد من النماذج العصبية قبل BERT. نقوم أيضًا بمقارنة العديد من استراتيجيات المعالجة المسبقة للبيانات الخاصة بالشفرة ووجدنا أن الترميز المتخصص يحسن الفعالية.', 'fr': "La tâche de la recherche de code sémantique est de récupérer des extraits de code à partir d'un corpus de code source en fonction d'un besoin d'information exprimé en langage naturel. L'écart sémantique entre le langage naturel et les langages de programmation a longtemps été considéré comme l'un des obstacles les plus importants à l'efficacité des méthodes de récupération d'informations basées sur des mots clés (IR). Il est courant de penser que les méthodes IR «\xa0traditionnelles\xa0» de sacs de mots sont mal adaptées à la recherche de code sémantique\xa0: notre travail étudie empiriquement cette hypothèse. Plus précisément, nous examinons l'efficacité de deux méthodes IR traditionnelles, à savoir BM25 et RM3, sur le Corpus CodeSearchNet, qui consiste en des requêtes en langage naturel associées à des extraits de code pertinents. Nous trouvons que les deux méthodes basées sur des mots clés surpassent plusieurs modèles neuronaux pré-BERT. Nous comparons également plusieurs stratégies de prétraitement de données spécifiques au code et constatons que la tokenisation spécialisée améliore l'efficacité.", 'pt': 'A tarefa da pesquisa de código semântico é recuperar trechos de código de um corpus de código-fonte com base em uma necessidade de informação expressa em linguagem natural. A lacuna semântica entre linguagem natural e linguagens de programação tem sido considerada por muito tempo como um dos obstáculos mais significativos para a eficácia dos métodos de recuperação de informações (IR) baseados em palavras-chave. É uma suposição comum que os métodos de RI “tradicionais” de saco de palavras são pouco adequados para busca de código semântico: nosso trabalho investiga empiricamente essa suposição. Especificamente, examinamos a eficácia de dois métodos tradicionais de RI, a saber, BM25 e RM3, no CodeSearchNet Corpus, que consiste em consultas em linguagem natural emparelhadas com trechos de código relevantes. Descobrimos que os dois métodos baseados em palavras-chave superam vários modelos neurais pré-BERT. Também comparamos várias estratégias de pré-processamento de dados específicos de código e descobrimos que a tokenização especializada melhora a eficácia.', 'es': 'La tarea de la búsqueda semántica de código es recuperar fragmentos de código de un corpus de código fuente basándose en una necesidad de información expresada en lenguaje natural. La brecha semántica entre el lenguaje natural y los lenguajes de programación se ha considerado durante mucho tiempo como uno de los obstáculos más importantes para la eficacia de los métodos de recuperación de información (IR) basados en palabras clave. Es una suposición común que los métodos «tradicionales» de IR de bolsa de palabras no son adecuados para la búsqueda de código semántico: nuestro trabajo investiga empíricamente esta suposición. Específicamente, examinamos la eficacia de dos métodos de IR tradicionales, a saber, BM25 y RM3, en el Corpus CodeSearchNet, que consiste en consultas de lenguaje natural combinadas con fragmentos de código relevantes. Encontramos que los dos métodos basados en palabras clave superan a varios modelos neuronales anteriores a BERT. También comparamos varias estrategias de preprocesamiento de datos de código específico y descubrimos que la tokenización especializada mejora la eficacia.', 'zh': '语义代码搜索者,以自然语言言求源代码语料库索代码片段。 久之,自然语言、编程语言之间语义相去直以为关键字信息检索(IR)法有效性之大障也。 常设者,古法也词袋IR法非其宜语义代码搜之:吾事究之。 具体来说于CodeSearchNet语料库上究二旧IR法(即BM25、RM3)之有效性,当语料库自然语言询代码片段配对成。 二者关键字优于前BERT神经。 又校数特定于代码之数预处理策,见专记可提高效率。', 'ja': 'セマンティックコード検索のタスクは、自然言語で表現された情報ニーズに基づいてソースコードコーパスからコードスニペットを取得することです。自然言語とプログラミング言語との間の意味的ギャップは、キーワードベースの情報検索（ IR ）方法の有効性に対する最も重大な障害の1つと長い間見なされてきた。「従来の」言葉のIR方法がセマンティックコード検索に適していないというのが一般的な仮定です。私たちの研究はこの仮定を実証的に調査します。具体的には、関連するコードスニペットとペアリングされた自然言語クエリで構成されるCodeSearchNet Corpus上の2つの従来のIR方法、すなわちBM 25とRM 3の有効性を検討します。2つのキーワードベースの方法は、いくつかのBERT前のニューラルモデルよりも優れていることがわかりました。また、いくつかのコード固有のデータ前処理戦略を比較すると、特殊なトークン化が有効性を向上させることがわかります。', 'hi': 'शब्दार्थ कोड खोज का कार्य प्राकृतिक भाषा में व्यक्त की गई जानकारी की आवश्यकता के आधार पर स्रोत कोड कॉर्पस से कोड स्निपेट को पुनः प्राप्त करना है। प्राकृतिक भाषा और प्रोग्रामिंग भाषाओं के बीच शब्दार्थ अंतर को लंबे समय से कीवर्ड-आधारित सूचना पुनर्प्राप्ति (आईआर) विधियों की प्रभावशीलता के लिए सबसे महत्वपूर्ण बाधाओं में से एक माना जाता है। यह एक आम धारणा है कि "पारंपरिक" बैग-ऑफ-वर्ड्स आईआर विधियां शब्दार्थ कोड खोज के लिए खराब रूप से अनुकूल हैं: हमारा काम अनुभवजन्य रूप से इस धारणा की जांच करता है। विशेष रूप से, हम CodeSearchNet Corpus पर दो पारंपरिक IR विधियों, अर्थात् BM25 और RM3 की प्रभावशीलता की जांच करते हैं, जिसमें प्रासंगिक कोड स्निपेट के साथ युग्मित प्राकृतिक भाषा क्वेरी शामिल हैं। हम पाते हैं कि दो कीवर्ड-आधारित तरीके कई पूर्व-BERT तंत्रिका मॉडल से आगे निकल जाते हैं। हम कई कोड-विशिष्ट डेटा पूर्व-प्रसंस्करण रणनीतियों की भी तुलना करते हैं और पाते हैं कि विशेष टोकनीकरण प्रभावशीलता में सुधार करता है।', 'ru': 'Задача поиска семантического кода заключается в извлечении фрагментов кода из корпуса исходного кода на основе информационной потребности, выраженной на естественном языке. Семантический разрыв между естественным языком и языками программирования уже давно рассматривается как одно из наиболее существенных препятствий для эффективности методов поиска информации по ключевым словам (IR). Общепринято предположение, что «традиционные» методы ИК-мешков плохо подходят для семантического поиска кода: наша работа эмпирически исследует это предположение. В частности, мы изучаем эффективность двух традиционных методов ИК, а именно BM25 и RM3, на корпусе CodeSearchNet, который состоит из запросов на естественном языке в паре с соответствующими фрагментами кода. Мы обнаружили, что два метода, основанные на ключевых словах, превосходят несколько нейронных моделей до BERT. Мы также сравниваем несколько кодовых стратегий предварительной обработки данных и обнаруживаем, что специализированная токенизация повышает эффективность.', 'ga': "Is é an tasc a bhaineann le cuardach cód séimeantach ná gearrthóga cód a aisghabháil ó chorpas cód foinse bunaithe ar riachtanas faisnéise a chuirtear in iúl i dteanga nádúrtha. Breathnaíodh le fada ar an mbearna shéimeantach idir teanga nádúrtha agus teangacha ríomhchlárúcháin mar cheann de na constaicí is suntasaí ar éifeachtacht modhanna aisghabhála faisnéise eochairfhocal-bhunaithe (IR). Is toimhde coitianta é nach bhfuil modhanna IR mála focal “traidisiúnta” oiriúnach go dona do chuardach cód shéimeantach: déanann ár gcuid oibre imscrúdú eimpíreach ar an mbonn tuisceana seo. Go sonrach, scrúdaímid éifeachtacht dhá mhodh IR thraidisiúnta, eadhon BM25 agus RM3, ar an CodeSearchNet Corpus, atá comhdhéanta d'fhiosrúcháin teanga nádúrtha atá péireáilte le gearrthóga cód ábhartha. Faighimid amach go sáraíonn an dá mhodh eochairfhocal-bhunaithe roinnt samhlacha néaracha réamh-BERT. Déanaimid comparáid freisin idir roinnt straitéisí réamhphróiseála sonraí a bhaineann go sonrach le cód agus faighimid go bhfeabhsaítear éifeachtúlacht sainchomharthaíochta.", 'ka': 'სიმენტიკური კოდის ძიება არის კოდის სნეპტების კოპორსდან მიღება ინფორმაციის საჭიროა, რომელიც ნაირადი ენაში გამოსახულებული ინფორმაცია. სიმენტიკური სიტყვის და პროგრამის ენების შორის განსხვავება ძალიან განმავლებული იყო, როგორც ერთი უფრო მნიშვნელოვანი განსხვავებაში გასაღების ინფორმაციის მიღება (IR) მეტოვების ეფექტიურობ ჩვენი სამუშაო მუშაობა იქნება, რომ სამუშაო სიტყვების შესაძლებლობისთვის, რომელიც IR სიტყვების შესაძლებლობისთვის ძალიან ძალიან მუშაობელია: ჩვენი სამუშაო ე განსაკუთრებულია, ჩვენ შევხედავთ ორი ტრადიციონალური IR მეტოვების ეფექტიურობა, რომელიც BM25 და RM3, CodeSearchNet კორპოსში, რომელიც შექმნის ნაირადი ენის კითხვების შესახებ, რომელიც შესახებ შესა ჩვენ აღმოჩნეთ, რომ ორი კლავიტური სიტყვების გარეშე მეტივები უფრო მეტი BERT ნეირალური მოდელების გარეშე. ჩვენ ასევე კოდის სპექტიფიკური მონაცემების პრესპროცესის სტრატიგიების შემდგენება და აღმოჩნეთ, რომ სპექციალური ტოკენიზაცია უფრო მეტი', 'hu': 'A szemantikus kódkeresés feladata a természetes nyelven kifejezett információigény alapján egy forráskód korpuszból történő lekérdezése. A természetes nyelv és a programozási nyelvek közötti szemantikai szakadékot már régóta a kulcsszóalapú információvisszakeresési (IR) módszerek hatékonyságának egyik legjelentősebb akadályának tekintik. Gyakori feltételezés, hogy a "hagyományos" szavazsákos IR módszerek nem alkalmasak a szemantikai kódkeresésre: munkánk empirikusan vizsgálja ezt a feltételezést. Konkrétan két hagyományos IR módszer, nevezetesen a BM25 és RM3 hatékonyságát vizsgáljuk meg a CodeSearchNet Corpus-on, amely természetes nyelvű lekérdezésekből áll és releváns kódrészletekből áll. Úgy találtuk, hogy a két kulcsszó alapú módszer több BERT előtti neurális modellt felülmúl. Számos kódspecifikus adatfeldolgozási stratégiát is összehasonlítunk, és úgy találjuk, hogy a speciális tokenizáció javítja a hatékonyságot.', 'el': 'Το καθήκον της αναζήτησης σημασιολογικού κώδικα είναι να ανακτήσει αποσπάσματα κώδικα από ένα σώμα πηγαίου κώδικα με βάση μια ανάγκη πληροφοριών που εκφράζεται σε φυσική γλώσσα. Το σημασιολογικό χάσμα μεταξύ της φυσικής γλώσσας και των γλωσσών προγραμματισμού θεωρείται εδώ και καιρό ένα από τα σημαντικότερα εμπόδια στην αποτελεσματικότητα των μεθόδων ανάκτησης πληροφοριών βάσει λέξεων-κλειδιών. Είναι κοινή υπόθεση ότι οι "παραδοσιακές" μέθοδοι υπέρυθρων λέξεων δεν είναι κατάλληλα για την αναζήτηση σημασιολογικού κώδικα: η εργασία μας διερευνά εμπειρικά αυτή την υπόθεση. Συγκεκριμένα, εξετάζουμε την αποτελεσματικότητα δύο παραδοσιακών μεθόδων IR, δηλαδή BM25 και RM3, στο Σώμα το οποίο αποτελείται από ερωτήματα φυσικής γλώσσας σε συνδυασμό με σχετικά αποσπάσματα κώδικα. Διαπιστώνουμε ότι οι δύο μέθοδοι που βασίζονται σε λέξεις-κλειδιά ξεπερνούν αρκετά νευρικά μοντέλα προ-BERT. Συγκρίνουμε επίσης διάφορες στρατηγικές προεπεξεργασίας δεδομένων ειδικά για κώδικα και διαπιστώνουμε ότι η εξειδικευμένη επισήμανση βελτιώνει την αποτελεσματικότητα.', 'it': 'Il compito della ricerca semantica del codice è quello di recuperare frammenti di codice da un corpus di codice sorgente basato su un bisogno di informazioni espresso in linguaggio naturale. Il divario semantico tra linguaggio naturale e linguaggi di programmazione è stato a lungo considerato uno degli ostacoli più significativi all\'efficacia dei metodi di recupero delle informazioni basati su parole chiave (IR). È un presupposto comune che i metodi IR "tradizionali" siano poco adatti alla ricerca semantica del codice: il nostro lavoro indaga empiricamente questa ipotesi. Nello specifico, esaminiamo l\'efficacia di due metodi IR tradizionali, vale a dire BM25 e RM3, sul CodeSearchNet Corpus, che consiste in query in linguaggio naturale accoppiate con frammenti di codice pertinenti. Troviamo che i due metodi basati su parole chiave superano diversi modelli neurali pre-BERT. Confrontiamo anche diverse strategie di pre-elaborazione dei dati specifiche per codice e scopriamo che la tokenizzazione specializzata migliora l\'efficacia.', 'lt': 'Semantinio kodo paieškos užduotis – paimti kodo fragmentus iš išorinio kodo korpuso, pagrįstus natūralia kalba išreikštu informacijos poreikiu. Semantinis natūralios kalbos ir programavimo kalbų skirtumas ilgai buvo laikomas viena svarbiausių kliūčių pagrindiniais žodžiais pagrįstų informacijos gavimo (IR) metodų veiksmingumui. Bendra prielaida, kad "tradiciniai" žodžių maišelio IR metodai netinka semantiniam kodų paieškai: mūsų darbas empiriniu būdu tiria šią prielaidą. Konkrečiai, mes nagrinėjame dviejų tradicinių IR metodų, būtent BM25 ir RM3, veiksmingumą CodeSearchNet Corpus, kurį sudaro natūralūs kalbos klausimai, susiję su atitinkamomis kodo pjūklėmis. Matome, kad du pagrindiniais žodžiais pagrįsti metodai viršija keletą prieš BERT nervų modelių. Taip pat palyginame keletą kodui būdingų duomenų išankstinio apdorojimo strategijų ir nustatome, kad specializuota tokenizacija pagerina veiksmingumą.', 'mk': 'The task of semantic code search is to retrieve code snippets from a source code corpus based on an information need expressed in natural language.  Семантичката разлика помеѓу природниот јазик и програмирачките јазици долго време се смета за една од најзначајните пречки за ефикасноста на методите на преземање информации базирани на клучните зборови (IR). Тоа е заедничка претпоставка дека „традиционалните“ методи на ИР-вреќа се лошо соодветни за семантичко пребарување на кодот: нашата работа емпирички ја истражува оваа претпоставка. Специфично, ја испитуваме ефективноста на двата традиционални ИР методи, имено БМ25 и РМ3, на CodeSearchNet Corpus, кој се состои од природни јазички прашања парирани со релевантни кодови. Најдовме дека двата методи базирани на клучни зборови надминуваат неколку нервни модели пред BERT. Исто така, споредуваме неколку стратегии за преобработување на податоци специфични за код и откриваме дека специјализираната токенизација ја подобрува ефективноста.', 'ms': "Tugas pencarian kod semantik adalah untuk mendapatkan snippets kod dari korpus kod sumber berdasarkan keperluan maklumat yang diungkapkan dalam bahasa semulajadi. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods.  Ia adalah asumsi umum bahawa kaedah IR 'tradisional' beg-of-words tidak sesuai untuk mencari kod semantik: kerja kita secara empirik menyelidiki asumsi ini. Secara khusus, kami memeriksa keefektivitas dua kaedah IR tradisional, iaitu BM25 dan RM3, pada CodeSearchNet Corpus, yang terdiri dari pertanyaan bahasa semulajadi berpasangan dengan snippets kod berkaitan. Kami mendapati bahawa dua kaedah berdasarkan kata kunci melebihi beberapa model saraf pre-BERT. Kami juga membandingkan beberapa strategi pra-proses data khusus kod dan mencari bahawa tokenization khusus meningkatkan keefektivitas.", 'ml': 'The task of semantic code search is to retrieve code snippets from a source code corpus based on an information need expressed in natural language.  സ്വാഭാവ ഭാഷകള്\u200dക്കും പ്രോഗ്രാമിങ്ങ് ഭാഷകള്\u200dക്കും തമ്മിലുള്ള സെമാന്റിക്ക് വേര്\u200dപ്പെട്ടിരിക്കുന്നു. കീവോര്\u200dഡ് അടിസ്ഥാനമായ വിവരങ് സെമാന്റിക് കോഡ് തെരയുന്നതിനായി നമ്മുടെ പ്രവര്\u200dത്തിക്കുന്നത് സാമ്പത്തികമായി അന്വേഷിക്കുന്നതാണെന്ന് കരുതുന്നു. പ്രത്യേകിച്ച്, നമ്മള്\u200d രണ്ട് പാരമ്പര്യമായ ഐആര്\u200d രീതികളുടെ പ്രകൃതിയെ പരിശോധിക്കുന്നു, BM25, RM3, കോഡ് തെരച്ചിലെ നെറ്റ് കോര്\u200dപ്സില്\u200d, സ്വാഭാവിക ഭാഷ ക നമുക്ക് കണ്ടെത്തുന്നത് കീവോര്\u200dഡ് അടിസ്ഥാനത്തിലുള്ള രണ്ട് രീതികളാണെന്നാണ്. നമ്മള്\u200d കുറച്ചു കോഡ് പ്രത്യേക വിവരങ്ങള്\u200dക്കും മുമ്പ് പ്രവര്\u200dത്തിപ്പിക്കുന്ന ക്രായേജ്യം തുല്യമാക്കുകയും പ്രത്', 'mt': 'Il-kompitu tat-tiftix semantiku tal-kodiċi huwa li jinkisbu snippets tal-kodiċi minn korpus tal-kodiċi tas-sors ibbażat fuq ħtieġa ta’ informazzjoni espressa f’lingwa naturali. Id-distakk semantiku bejn il-lingwa naturali u l-lingwi ta’ programmazzjoni ilu meqjus għal żmien twil bħala wieħed mill-aktar ostakli sinifikanti għall-effettività tal-metodi ta’ ġbir ta’ informazzjoni bbażata fuq il-kliem ewlieni (IR). Huwa suppożizzjoni komuni li l-metodi tal-IR “tradizzjonali” tal-borża tal-kliem mhumiex adattati sew għat-tiftix tal-kodiċi semantiku: ix-xogħol tagħna jinvestiga din is-suppożizzjoni b’mod empiriku. Specifically, we examine the effectiveness of two traditional IR methods, namely BM25 and RM3, on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets.  Issibu li ż-żewġ metodi bbażati fuq kliem ewlieni jaqbżu diversi mudelli newrali ta’ qabel BERT. Aħna nqabblu wkoll diversi strateġiji speċifiċi għall-ipproċessar minn qabel tad-dejta skont il-kodiċi u nsibu li t-tokenizzazzjoni speċjalizzata ttejjeb l-effettività.', 'kk': "Семантикалық код іздеудің тапсырмасы - көздегі код корпусынан кодты түрде белгіленген мәліметтің негізінде алу. Табиғи тіл мен бағдарлама тілдерінің арасындағы семантикалық қашықтығы ұзындық уақытта перне сөздерді негіздеген мәліметті (IR) алу әдістерінің ең маңызды бұл болып қалады. Бұл 'әдетті' сөздердің IR әдістері семантикалық код іздеу үшін жалпы сәйкес келеді деп ойлаймыз: жұмыс мұны империялық түрде зерттейді. Ескерілі, біз екі әдімгі IR әдістерінің эффектілігін, мысалы BM25 және RM3 кодтамасындағы CodeSearchNet корпусында тексереміз. Бұл табиғи тіл сұрауларының қатынасы бар. Біз екі кілттің сөздерді негіздеген әдістер бірнеше BERT невралдық моделдерінің өзгертілген. Біз сондай-ақ бірнеше код арқылы деректерді алдын- ала өңдеу стратегияларын салыстырып, специализиялық токенизацияның эффективнілігін жақсартады.", 'ro': 'Sarcina căutării de coduri semantice este de a recupera fragmente de cod dintr-un corpus de cod sursă bazate pe o nevoie de informații exprimată în limbaj natural. Diferența semantică dintre limbajul natural și limbajele de programare a fost considerată de mult timp ca fiind unul dintre cele mai semnificative obstacole în calea eficacității metodelor de recuperare a informațiilor bazate pe cuvinte cheie (IR). Este o presupunere comună că metodele IR "tradiționale" sunt slab potrivite pentru căutarea codurilor semantice: munca noastră investighează empiric această presupunere. Mai exact, examinăm eficacitatea a două metode IR tradiționale, și anume BM25 și RM3, pe CodeSearchNet Corpus, care constă în interogări în limbaj natural asociate cu fragmente de cod relevante. Considerăm că cele două metode bazate pe cuvinte cheie depășesc mai multe modele neurale pre-BERT. De asemenea, comparăm mai multe strategii de pre-procesare a datelor specifice codului și constatăm că tokenizarea specializată îmbunătățește eficiența.', 'pl': 'Zadaniem wyszukiwania kodu semantycznego jest pobieranie fragmentów kodu źródłowego z korpusu kodu źródłowego w oparciu o potrzebę informacyjną wyrażoną w języku naturalnym. Przepaść semantyczna między językiem naturalnym a językami programowania od dawna uważana jest za jedną z najważniejszych przeszkód w skuteczności metod odzyskiwania informacji opartych na słowach kluczowych (IR). Powszechne jest założenie, że "tradycyjne" metody IR źle nadają się do wyszukiwania kodu semantycznego: nasza praca bada to założenie empirycznie. W szczególności badamy skuteczność dwóch tradycyjnych metod IR, a mianowicie BM25 i RM3, w korpusie CodeSearchNet, który składa się z zapytań językowych naturalnych połączonych z odpowiednimi fragmentami kodu. Odkrywamy, że te dwie metody oparte na słowach kluczowych przewyższają kilka modeli neuronowych pre-BERT. Porównujemy również kilka strategii wstępnego przetwarzania danych specyficznych dla kodu i stwierdzamy, że specjalistyczna tokenizacja poprawia skuteczność.', 'mn': 'Земантик код хайлтын ажил бол байгалийн хэл дээр илэрхийлэгдсэн мэдээлэл дээр эх үүсвэрийн код корпус-аас код снип авах юм. Байгалийн хэл болон програмчлалын хэл хоорондын семантик ялгаа урт хугацаанд хамгийн чухал бэрхшээл гэсэн үг дээр суурилсан мэдээлэл авах (IR) аргын үр дүнтэй байдал гэж үздэг. Энэ бол уламжлалт үгний IR арга баримтууд шийдвэрлэхэд зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөв Ялангуяа бид хоёр уламжлалтай IR аргын үр дүнг, мөн BM25 болон RM3, CodeSearchNet Corpus дээр шалгаж үздэг. Энэ нь байгалийн хэлний кверитүүд нь холбоотой кодын хэлбэртэй холбоотой. Бид хоёр түлхүүр үг суурилсан арга нь хэдэн өмнө БЕРТ-ын мэдрэлийн загваруудыг хийдэг. Мөн бид хэдэн кодын тодорхойлолтой мэдээллийн өмнө үйлдвэрлэх стратегийг харьцуулж, мэргэжлийн тодорхойлолтын үр дүнг сайжруулдаг.', 'no': 'Oppgåva til semantisk kode- søk er å henta kode- snippet frå ei kjeldekode- korpus basert på ei informasjon som treng uttrykt i naturspråk. Det semantiske avstanden mellom naturspråk og programmeringspråk er for lang kalla til ein av dei viktigste hindringane til effektiviteten av nøkkelordbaserte informasjonshenting (IR) metodar. Det er ein vanleg antar at «tradisjonelle» søk av ord IR-metodar er slik passande for semantisk søk: arbeidet vårt er empirisk undersøkt denne antasen. Spesielt er vi undersøk effektiviteten av to tradisjonelle IR-metodar, dvs. BM25 og RM3, på kodeSearchNet-korpusen, som inneheld av naturspråksspørjingar som er saman med relevante kodsnippet. Vi finn at dei to nøkkelordbaserte metodane utfører fleire før BERT-neuralmodeller. Vi sammenliknar også fleire dataspesifikke forehandlingsstrategiar og finn at spesialiserte tokenisering forbetrar effektivitet.', 'sv': 'Uppgiften med semantisk kodsökning är att hämta kodutdrag från en källkodskorpus baserat på ett informationsbehov uttryckt i naturligt språk. Den semantiska klyftan mellan naturligt språk och programmeringsspråk har länge ansetts vara ett av de viktigaste hindren för effektiviteten av nyckelordsbaserade informationsinsamlingsmetoder. Det är ett vanligt antagande att "traditionella" IR-metoder är dåligt lämpade för semantisk kodsökning: vårt arbete undersöker empiriskt detta antagande. Specifikt undersöker vi effektiviteten av två traditionella IR-metoder, nämligen BM25 och RM3, på CodeSearchNet Corpus, som består av naturliga språkfrågor ihopkopplade med relevanta kodutdrag. Vi finner att de två sökordsbaserade metoderna överträffar flera pre-BERT neurala modeller. Vi jämför också flera kodspecifika databehandlingsstrategier och finner att specialiserad tokenisering förbättrar effektiviteten.', 'so': "Shaqada raadinta kooxda ah waa in laga soo celiyo kooxda codsiga ee asalka ah oo lagu saleynayo macluumaad looga baahan yahay luqada asalka ah. Dhaqdhaqaaqa afka asalka ah iyo afka programka waxaa wakhti dheer looga tiriyey mid ka mid ah dhibaatooyinka ugu muhiimsan qaababka helitaanka macluumaadka ee keyword-based (IR). Waa sida caadiga ah in qaababka caadiga ah oo ay u habboon yihiin hababka IR in loo baahdo raadinta kooxda ah: shaqadayadu si fiican ayuu u baaraandegaa malayaashan. Si gaar ah, waxaynu baaritaan waxqabadka labada qaababka caadiga ah ee IR, tusaale ahaan BM25 iyo RM3, taas oo ka mid ah koodeSearchNet Corpus, kaas oo ku qoran qoraalo luuqadaha dabiiciga ah oo la xiriira kooxda codsiga. We find that the two keyword-based methods outperform several pre-BERT neural models.  Sidoo kale waxaynu isbarbardhignaa qalabka kooban ee macluumaadka ka hor baaraandegista, waxaana ognahay in calaamad gaar ah uu hagaajiyo faa'iido.", 'ta': "பெமான்டிக் குறியீடு தேடும் செயல் இயல்பான மொழியில் தெரியும் தகவல் தேவை இயல்பான மொழி மற்றும் நிரல் மொழிகளுக்கிடையிலுள்ள பெரிய இடைவெளிப்பாடு விசைவார்த்தை தகவல் மீட்டெடுப்பு (IR) முறைமைகளின் விளைவுகள இது ஒரு பொது யூகமாக இருக்கிறது என்றால் 'மரபாரமான' சொற்களின் பாக்-வார்த்தைகள் ஐஆர் முறைமைகள் பொருத்தமாக தேடுவதற்கு பொருத்தமானது: எங குறிப்பிட்டு, நாம் இரண்டு மரபார்ந்த IR முறைமைகளின் விளைவை பரிசோதிக்க வேண்டும், பிஎம்25 மற்றும் RM3, கோடு தேடும் வலை கோர்புஸ் மீது, அது இயல்பான மொ இரண்டு விசைவார்த்தை அடிப்படையான முறைமை BERT புதிய மாதிரிகளை செயல்படுத்தும் என்பதை நாம் கண்டுபிடிக்கி We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.", 'sr': 'Zadatak semantičkog pretraživanja koda je da uzmete snippet koda iz izvornog koda korpusa na osnovu informacijske potrebe izražene na prirodnom jeziku. Semantički praznik između prirodnog jezika i jezika programiranja dugo se smatra jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" reèi IR metode loše odgovarajuće za pretragu semantičkih kodova: naš rad empirièki istražuje ovu pretpostavku. Posebno, istražujemo učinkovitost dva tradicionalna IR metoda, a to je BM25 i RM3, na kodesetarchNet korpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih sa relevantnim kodskim snippetama. Nalazimo da dve metode na temelju ključnih reči iznose nekoliko pre-BERT neuralnih modela. Takođe uspoređujemo nekoliko strategija predobrađivanja podataka specifičnih kodova i saznamo da specijalizovana tokenizacija poboljšava učinkovitost.', 'si': "සෙමැන්ටික් කෝඩ් හොයාගැනීමේ වැඩය තමයි ප්\u200dරාකෘතික භාෂාවට ප්\u200dරතිකෘති තොරතුරු අවශ්\u200dය භාෂාවක් නිසා  ස්වභාවික භාෂාවය සහ ව්\u200dයාප්තිකරණය භාෂාවය අතර සිමාන්තික අවශ්\u200dය විදිහට පරීක්ෂා කරලා තියෙන්නේ ලොකු වචන පරීක්ෂණය සඳ ඒක සාමාන්\u200dය විශ්වාස කරනවා කියලා 'පාරමාන්\u200dය' බෑග් වචන IR විධානයක් සෙමාන්ටික කෝඩ් සොයාගන්න වැරදියි: අපේ වැඩේ සාමාන විශේෂයෙන්, අපි පරාධික IR පද්ධතිය දෙකක් ගැන පරීක්ෂණය කරනවා, මේකයි BM25 සහ RM3, CodeSearchNet Corpus වල, ඒක සම්බන්ධ කෝඩ ස්නිපෙට්ට් එක්ක සම්බ අපිට හොයාගන්න පුළුවන් වචන දෙකක් විදිහට පරිස්සම් BERT න්\u200dයූරල් මොඩේල් වලින් විදිහට ප්\u200dරතිකා අපි කෝඩ් විශේෂ දත්ත ප්\u200dරතික්\u200dරියාත්මක විදිහට සම්බන්ධ කරනවා ඒ වගේම විශේෂ විදිහට ප්\u200dරතික්\u200dරියා", 'ur': "سیمنٹی کوڈ تلاش کا کام یہ ہے کہ ایک سورس کوڈ کورپوس سے کوڈ اسنیپٹوں کو اٹھانے کی ضرورت طبیعی زبان میں واضح کیا جاتا ہے. طبیعی زبان اور پروگرامینگ زبانوں کے درمیان سیمنٹی فاصلہ بہت مدت تک ایک بڑی مضبوط روش کے ساتھ سمجھا گیا ہے کہ کلیدر کی بنیادی معلومات (IR) حاصل کرنے کے مطابقت کے مطابقت کے لئے۔ یہ ایک معمولی فرض ہے کہ 'سنتی' کلمات کے بغل IR طریقے سیمنٹی کوڈ تلاش کے لئے برابر مطابق ہیں: ہمارا کام اس فرض کو مطابق تحقیق کرتا ہے۔ ویسے ہی ہے کہ ہم دو سنتی IR طریقے کے مطابق تحقیق کرتے ہیں، یعنی BM25 اور RM3، CodeSearchNet Corpus پر، جو متعلق کیڈ سنپیٹوں کے ساتھ جوڑے ہوئے طبیعی زبان کے سوال میں سے ہے. ہم کو معلوم ہے کہ دو کلیدر بنیادی طریقے بہت سے پہلے BERT نیورال موڈل سے کام لیتے ہیں۔ ہم نے بہت سی کوڈ مخصوص ڈیٹا پرپروسیس کے استراتژیکوں کے مطابق مقایسہ کر دیا ہے اور دیکھتے ہیں کہ مخصوص ٹوکنیزی کے مطابق اثرات کو اثر دیتی ہے.", 'uz': 'Seymantik kodi qidirish vazifasi asl tilda koʻrsatilgan maʼlumot uchun manba kodi kodlash usulini aniqlash. Oddiy tillar va dastur qilish uchun semantik gap uzoqda, kalit asosida maʼlumot olish (IR) usullarining foydalanishiga eng muhim hammasidan deb hisoblanadi. Bu umumiy g\'oyalar, oddiy "traditional" so\'zlar sohasi IR usullari semantik kod qidirish uchun juda yetarli qiymatdir: bizning ishimiz bu g\'oyatni qidirishda juda qidiriladi. Kodlash tarkibida biz ikkita traditional IR metodlarining effektligini tekshirishingiz mumkin, BM25 va RM3, kodSearchNet Korpusida, bu tilning asl soʻrovlari bilan bog\'liq kodlash qoidalari bilan bog\'liq qoʻllangan. Biz o\'rganamiz, ikkita tugmalar asosida bir necha BERT neyrol modellarini bajaradi. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.', 'vi': "Nhiệm vụ của việc tìm kiếm mật mã ngữ nghĩa là lấy đoạn mã từ một tập thể chứa mật mã gốc dựa trên nhu cầu thông tin được bày tỏ bằng ngôn ngữ tự nhiên. Khoảng cách ngữ pháp giữa ngôn ngữ tự nhiên và ngôn ngữ lập trình đã được coi là một trong những trở ngại quan trọng nhất với hiệu quả của các phương pháp truy tìm thông tin từ khoá (IR). Đó là một giả thuyết phổ biến rằng phương pháp IR'truyền thống'không phù hợp với việc tìm kiếm theo bí mật ngữ nghĩa. Công việc của chúng ta nghiên cứu cơ bản này. Chúng tôi đặc biệt nghiên cứu tính hiệu quả của hai phương pháp IR truyền thống, cả BM25 và RM3, trên the CodeinNet Corpus, which consists of natural language queries ghép với các đoạn mã liên quan. Chúng tôi thấy rằng hai phương pháp từ khoá đạt giới hạn sử dụng nhiều mô hình thần kinh trước BERT. Chúng tôi cũng so sánh các chiến lược xử lý dữ liệu đặc biệt và phát hiện ra hiệu quả cải tiến.", 'bg': 'Задачата на семантичното търсене на код е да извлича откъси от код от корпус на изходен код въз основа на информационна нужда, изразена на естествен език. Сентичната пропаст между естествения език и програмните езици отдавна се разглежда като една от най-значимите пречки за ефективността на методите за извличане на информация, базирани на ключови думи. Често срещано е предположението, че "традиционните" методи за ИР с торба с думи са слабо подходящи за семантично търсене на кодове: нашата работа емпирично изследва това предположение. По-конкретно, изследваме ефективността на два традиционни IR метода, а именно БМ25 и РМ3, върху Корпуса който се състои от заявки за естествен език, съчетани със съответните кодови фрагменти. Откриваме, че двата метода, базирани на ключови думи, превъзхождат няколко невронни модела преди BERT. Също така сравняваме няколко специфични за кода стратегии за предварителна обработка на данни и откриваме, че специализираната токенизация подобрява ефективността.', 'da': "Opgaven med semantisk kodesøgning er at hente kodeudstryk fra et kildekodekorpus baseret på et informationsbehov udtrykt i naturligt sprog. Den semantiske kløft mellem naturligt sprog og programmeringssprog har længe været betragtet som en af de væsentligste hindringer for effektiviteten af søgeordsbaserede informationssøgningsmetoder (IR). Det er en almindelig antagelse, at 'traditionelle' taske-of-word IR metoder er dårligt egnede til semantisk kodesøgning: vores arbejde undersøger empirisk denne antagelse. Specielt undersøger vi effektiviteten af to traditionelle IR metoder, nemlig BM25 og RM3, på CodeSearchNet Corpus, som består af natursprogforespørgsler parret med relevante kodeudstryk. Vi finder ud af, at de to søgeordsbaserede metoder overgår flere pre-BERT neurale modeller. Vi sammenligner også flere kodespecifikke databehandlingsstrategier og finder ud af, at specialiseret tokenisering forbedrer effektiviteten.", 'hr': 'Zadatak pretraživanja semantičkog koda je uzeti snippet koda iz izvornog koda korpusa na temelju informacijske potrebe izražene na prirodnom jeziku. Semantički razmak između prirodnog jezika i programiranja jezika dugo se smatra jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" vrećice riječi IR metode loše odgovarajuće za pretragu semantičkih kodova: naš rad empirički istražuje ovu pretpostavku. Posebno, pregledamo učinkovitost dvije tradicionalne IR metode, a to je BM25 i RM3, na KodeSearchNet Corpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih s relevantnim kodskim snippetama. Nalazimo da su dva metoda temeljena na ključnim riječima iznosila nekoliko pre-BERT neuralnih modela. Također uspoređujemo nekoliko strategija predobrađivanja podataka o specifičnim kodovima i otkrijemo da je specijalizovana tokenizacija poboljšala učinkovitost.', 'nl': "De taak van semantische codezoeken is om codefragmenten uit een broncodecorpus op te halen op basis van een informatiebehoefte uitgedrukt in natuurlijke taal. De semantische kloof tussen natuurlijke taal en programmeertalen wordt al lang beschouwd als een van de belangrijkste obstakels voor de effectiviteit van keyword-based information retrieval (IR)-methoden. Het is een algemene veronderstelling dat 'traditionele' zak-met-woorden IR methoden slecht geschikt zijn voor semantische code zoeken: ons werk onderzoekt deze veronderstelling empirisch. In het bijzonder onderzoeken we de effectiviteit van twee traditionele IR-methoden, namelijk BM25 en RM3, op het CodeSearchNet Corpus, dat bestaat uit natuurlijke taalqueries gekoppeld aan relevante codefragmenten. We vinden dat de twee op trefwoorden gebaseerde methoden beter presteren dan verschillende pre-BERT neurale modellen. We vergelijken ook verschillende code-specifieke data pre-processing strategieën en vinden dat gespecialiseerde tokenizatie de effectiviteit verbetert.", 'de': 'Die Aufgabe der semantischen Codesuche besteht darin, Codeschnipsel aus einem Quellcodekorpus abzurufen, basierend auf einem Informationsbedarf, der in natürlicher Sprache ausgedrückt wird. Die semantische Lücke zwischen natürlicher Sprache und Programmiersprachen gilt seit langem als eines der größten Hindernisse für die Effektivität keyword-based information retrieval (IR)-Methoden. Es ist eine gängige Annahme, dass "traditionelle" Bag-of-Words-IR-Methoden für die semantische Codesuche schlecht geeignet sind: Unsere Arbeit untersucht diese Annahme empirisch. Konkret untersuchen wir die Wirksamkeit zweier traditioneller IR-Methoden, nämlich BM25 und RM3, auf dem CodeSearchNet Corpus, das aus natursprachlichen Abfragen gepaart mit relevanten Code-Snippets besteht. Wir stellen fest, dass die beiden keywordbasierten Methoden mehrere neuronale Modelle vor BERT übertreffen. Wir vergleichen auch mehrere code-spezifische Daten-Vorverarbeitungsstrategien und stellen fest, dass spezialisierte Tokenisierung die Effektivität verbessert.', 'id': "Tugas pencarian kode semantis adalah untuk mendapatkan snippets kode dari kode sumber corpus berdasarkan kebutuhan informasi yang diungkapkan dalam bahasa alam. Lubang semantis antara bahasa alam dan bahasa pemrograman telah lama dianggap sebagai salah satu halangan yang paling signifikan untuk efektivitas metode pengembalian informasi berdasarkan kata kunci (IR). Ini adalah asumsi umum bahwa 'tradisional' tas-kata IR metode tidak cocok untuk pencarian kode semantis: pekerjaan kita secara empiris menyelidiki asumsi ini. Secara spesifik, kami memeriksa efektivitas dua metode IR tradisional, yaitu BM25 dan RM3, pada CodeSearchNet Corpus, yang terdiri dari pertanyaan bahasa alami berpasangan dengan snippets kode relevan. Kami menemukan bahwa dua metode berdasarkan kata kunci melebihi beberapa model saraf pre-BERT. Kami juga membandingkan beberapa strategi pre-proses data khusus kode dan menemukan bahwa tokenisasi khusus meningkatkan efektivitas.", 'ko': "의미 코드 검색의 임무는 자연 언어가 표현하는 정보 수요에 따라 원본 코드 라이브러리에서 코드 세션을 검색하는 것이다.오랫동안 자연 언어와 프로그래밍 언어 간의 의미 갭은 키워드 기반의 정보 검색(IR) 방법의 유효성에 영향을 주는 가장 중요한 장애 중 하나로 여겨져 왔다.흔히 볼 수 있는 가설은'전통적인'패키지 IR 방법이 의미 코드 검색에 적합하지 않다는 것이다. 우리의 작업은 이 가설을 실증적으로 연구했다.구체적으로 말하자면 우리는 CodeSearchNet 자료 라이브러리에서 두 가지 전통적인 IR 방법, 즉 BM25와 RM3의 유효성을 검증했다. 이 자료 라이브러리는 자연 언어 조회와 관련 코드 세션으로 구성되어 있다.우리는 이 두 가지 키워드를 바탕으로 하는 방법이 몇 가지 전버트 신경 모델보다 우수하다는 것을 발견했다.우리는 코드에 특정된 몇 가지 데이터 예처리 전략을 비교한 결과 전문적인 표기화가 효율을 높인 것을 발견했다.", 'sw': "Kazi ya kutafuta mfumo wa kanuni za kimapenzi ni kupata vifaa vya kodi kutoka kwenye makampuni ya kanuni yenye msingi wa mahitaji ya taarifa yanayoelezwa kwa lugha ya asili. Ugaji wa kimapenzi kati ya lugha za asili na lugha za programu kwa muda mrefu umechukuliwa kama moja ya vikwazo muhimu zaidi katika ufanisi wa upatikanaji wa taarifa za muhimu (IR). It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  Kwa hakika, tunachunguza ufanisi wa mbinu mbili za utamaduni wa IR, yaani BM25 na RM3, kwenye Corpus ya CodeSearchNet, ambayo ni pamoja na maswali ya lugha ya asili yanayohusiana na vikosi vinavyohusiana. Tunapata kwamba mbinu mbili za msingi za neno zinazotumia mifano kadhaa ya ubongo wa BERT. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.", 'sq': "Detyra e kërkimit të kodit semantik është të marrësh copat e kodit nga një kod burimi korpus bazuar në një nevojë informacioni të shprehur në gjuhën natyrore. Ndryshimi semantik midis gjuhës natyrore dhe gjuhëve të programimit është konsideruar për një kohë të gjatë si një nga pengesat më të rëndësishme në efektshmërinë e metodave të marrjes së informacionit bazuar në fjalë kyçe (IR). Është një supozim i përbashkët se metodat 'tradicionale' të çantës së fjalëve IR janë keq të përshtatshme për kërkimin e kodit semantik: puna jonë empirikisht heton këtë supozim. Veçanërisht, ne e shqyrtojmë efektshmërinë e dy metodave tradicionale të IR, në emër BM25 dhe RM3, në CodeSearchNet Corpus, i cili përbëhet nga pyetje natyrore gjuhësh të paluara me copa kodi të duhura. Ne zbulojmë se dy metodat bazuar në fjalë kyçe kalojnë disa modele neuronale para-BERT. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.", 'am': "የsemantic code search job is to retrieve the code code from a source code corpus based on an information that is useful in natural language. በአፍሪካዊ ቋንቋ እና በፕሮግራም ቋንቋዎች መካከል የsemantic ውጤት ከረጅም ዘመን ጀምሮ የቁልፍ ቃላት ማግኘት (IR) ዓይነት አካባቢ መሆኑን (IR) ማግኘት ከሚያሰኘው ትልቅ ግንኙነት አንዱ ነው፡፡ የ'ትምህርት' የኢ.ஆர ቃላት አካባቢ ቃላት የሆኑት አካባቢ ማድረግ የተጠቃሚ ነው፤ ሥራችን በትክክል ይሞክራል፡፡ በተለያይነት፣ የሁለት ባሕላዊ IR ሥርዓት፣ BM25 እና RM3፣ በኮዲስመር ኔት ኮርፓስ ላይ ጥያቄን እናመርምረዋለን፡፡ የሁለት የቁልፎች ቃላት-መሠረቶች ብዙዎችን የBERT የነጥብ ዓይነቶች የሚያደርጉትን እናገኛለን፡፡ እና ብዙ የሥርዓት ዳታዎችን አስቀድሞ ለመሥራት strategieን እናስተያየዋለን፣ የግንኙነት ማስታወቂያው ፍጥረትን ያሻላል፡፡", 'fa': 'وظیفه جستجوی کد سیمانتیک این است که اسنکت\u200cهای کد را از یک کورپوس منبع بر اساس یک نیاز اطلاعاتی که در زبان طبیعی توضیح داده می\u200cشود برگیرد. فاصله semantic بین زبان طبیعی و برنامه\u200cریزی زبان\u200cهای برنامه\u200cریزی برای مدت طولانی به عنوان یکی از مهمترین مانع\u200cهای فعالیت روش\u200cهای بازیابی اطلاعات (IR) بر اساس کلید به نظر گرفته شده است. این فرض معمولی است که روش\u200cهای کلمه\u200cهای "سنتی" IR برای جستجوی کد\u200cهای semantic به بدی مناسب می\u200cشوند: کار ما به طور عمومی این فرض را تحقیق می\u200cکند. به طور خاص، ما فعالیت دو روش IR سنتی را تحقیق می\u200cکنیم، یعنی BM25 و RM3، روی Corpus CodeSearchNet، که از سوالات زبان طبیعی که با اسنیپت\u200cهای کد مربوط به هم جور شده است. ما فهمیدیم که دو روش کلیدی بر اساس کلید چند مدل عصبی قبل از BERT را انجام می دهند. ما همچنین چندین استراتژی پیش\u200cپردازش داده\u200cهای مخصوص کد را مقایسه می\u200cکنیم و پیدا می\u200cکنیم که توکینز مخصوص فعالیت را بهتر می\u200cکند.', 'hy': 'Սեմանտիկ կոդի որոնման խնդիրն է վերցնել կոդի կտորները աղբյուր կոդի կոդի կորպուսից, հիմնված բնական լեզվով արտահայտված ինֆորմացիայի կարիքի վրա: Բնական լեզուների և ծրագրավորման լեզուների միջև սեմանտիկ տարբերությունը երկար ժամանակ համարվում է ամենակարևոր խոչընդոտներից մեկը, որոնք առաջացնում են ստեղծաբառերով հիմնված տեղեկատվության վերադարձման (RI) մեթոդների արդյունավետության վրա: Սա ընդհանուր ենթադրություն է, որ "ավանդական" բառերի արտահայտության մեթոդները վատ համապատասխանում են սեմանտիկ կոդի որոնման համար: Մեր աշխատանքը էմպրիկապես ուսումնասիրում է այս ենթադրությունը: Հատկապես, մենք ուսումնասիրում ենք երկու ավանդական ԻՌ մեթոդի արդյունավետությունը, այն է\' BM25 և ՌՄ3-ը, ԿոդեՍերքNet Կորպուսի վրա, որը կազմված է բնական լեզվի հարցերից, որոնք զույգված են համապատասխանատու կոդի կտորների հետ Մենք հայտնաբերեցինք, որ երկու հիմնական բառերով հիմնված մեթոդները գերազանցում են BER նախաբեռ նյարդային մոդելներին: Մենք նաև համեմատում ենք մի քանի կոդի-հատուկ տվյալների նախավերաբերյալ ռազմավարություններ և հայտնաբերում ենք, որ հատուկ թոկենիզացիան բարելավում է արդյունավետությունը:', 'tr': "Semantik köd araştyrmasynyň göresi tebigy dilde ifade edilen maglumaty üçin köd köd ködlemelerini a çmak. Doýal diller we programlemek diller arasyndaky semantik gaplaryň (IR) täsirli sözler üçin iň möhüm engellerden biri diýip kabul edildi. Däpli sanat eserleşmek üçin 'dünýäpli' sözleri IR metodlaryň semantik ködleme gözlemesi üçin ýeterli däl. Biziň işimiz bu pikirlemi empiriýaly barýar. Adatça, biz 2 däpli IR metodlaryň, ady BM25 we RM3, KodeSearchNet Korpusynda, tebigy dil soraglarynyň barlygyny barlaýarys. Biz iki aç kelime tabanly yöntemler BERT öňünden näral nusgalaryny çykarýar. Biz hem birnäçe köd taýýarlanmaky önünde işleýän maglumaty karşılaştyrýarys we özellikle tokenizaçy etkinlik täsirini gowylaşdyrýar.", 'bn': "সেমেন্টিক কোড অনুসন্ধানের কাজ হচ্ছে প্রাকৃতিক ভাষায় প্রকাশিত তথ্য প্রকাশিত একটি সোর্স কোড কোর্পাস থেকে কোড স্নি প্রাকৃতিক ভাষা এবং প্রোগ্রামিং ভাষার মধ্যে সেমেন্টিক বিভ্রান্তিক বিভ্রান্তি অনেক দীর্ঘদিন ধরে বিবেচনা করা হয়েছে কীওয়ার্ড ভিত্তিক এটা একটা সাধারণ ধারণা যে 'ঐতিহ্যবাহী' ব্যাগ-অফ-শব্দের আইআর-এর পদ্ধতি সেমেন্টিক কোড অনুসন্ধানের জন্য খুব খারাপ: আমাদের কাজ এই ধারণার জন্ বিশেষ করে আমরা দুই ঐতিহ্যবাহী আইআর পদ্ধতির কার্যক্রম পরীক্ষা করি, যেমন বিএম২৫ এবং আরএম৩, কোড সার্চ নেট কোর্পাসে যা প্রাকৃতিক ভাষার অনুসন্ধানের প্রশ্নের আমরা খুঁজে পাচ্ছি যে বিবের্টের পূর্বে নিউরেল মডেলের দুটি কীওয়ার্ড ভিত্তিক পদ্ধতিগুলো বেশ কয়েকটি প্ We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.", 'ca': "La tasca de la búsqueda de codi semàntic és recuperar fragments de codi d'un corpus de codi font basat en una necessitat d'informació expressada en llenguatge natural. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods.  It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  En concret, examinem l'eficacia de dos mètodes tradicionals de IR, a saber, BM25 i RM3, al CodeSearchNet Corpus, que consisteix en preguntes de llenguatge natural parellades amb fragments de codi pertinents. Trobem que els dos mètodes basats en paraules clau superen varis models neurals pre-BERT. També comparem diverses estratègies de pré-processament de dades específices per codi i descobrim que la tecenització especialitzada millora l'eficacia.", 'az': "Semantik kodu araştırmasının görevi, doğal dildə ifadə edilən məlumatlar üçün mənbə kodu korpusundan kodu snippet almaqdır. Təbiətli dil və programlama dillərin arasındakı semantik boşluğu uzun zamandır anahtar sözlərinə dayanan məlumat alma (IR) metodlarının ən möhkəm səbəbi kimi hesab edildi. Həmçinin 'tradicional' sözlərin IR metodları semantik kodu araması üçün pis uyğun deyildir: işimiz bu iddiayı imkansız olaraq araşdırır. Özellikle, biz iki nəticə IR metodlarının, həmçinin BM25 və RM3, KodeSearchNet Corpus üzerində olan təbiətli dil soruşmalarından olub. İki anahtar sözlərə dayanan metodların BERT-dən əvvəl nöral modellərini təqdim edir. Biz həmçinin çoxlu kodu müəyyən məlumatları ön işləmə stratejiləri ilə qarşılaşdırırıq və təhsil edilmiş tokenizasyon efektivitəti daha yaxşılaşdırır.", 'cs': 'Úkolem vyhledávání sémantického kódu je získat úryvky kódu ze zdrojového kódu na základě informační potřeby vyjádřené v přirozeném jazyce. Sémantická propast mezi přirozeným jazykem a programovacími jazyky je dlouho považována za jednu z nejvýznamnějších překážek efektivity metod vyhledávání informací založených na klíčových slovech (IR). Je běžným předpokladem, že "tradiční" sáčkové IR metody jsou špatně vhodné pro vyhledávání sémantického kódu: naše práce empiricky zkoumá tento předpoklad. Konkrétně zkoumáme efektivitu dvou tradičních IR metod, jmenovitě BM25 a RM3, na CodeSearchNet Corpus, který se skládá z dotazů přirozeného jazyka spárovaných s relevantními úryvky kódu. Zjistili jsme, že tyto dvě metody založené na klíčových slovech překonávají několik pre-BERT neuronových modelů. Porovnáváme také několik strategií předzpracování dat specifických pro kód a zjišťujeme, že specializovaná tokenizace zlepšuje efektivitu.', 'bs': 'Zadatak pretraživanja semantičkog koda je da uzmete snippet koda iz izvornog koda korpusa na temelju informacijske potrebe izražene na prirodnom jeziku. Semantički praznik između prirodnog jezika i jezika programiranja dugo je smatrao jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" metode riječi IR loše odgovarajuće za pretragu semantičkih kodova: naš posao empirički istražuje ovu pretpostavku. Posebno, pregledamo učinkovitost dvije tradicionalne IR metode, a to je BM25 i RM3, na KodeSearchNet korpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih sa relevantnim kodskim snippetama. Nalazimo da su dva metoda temeljena na ključnim riječima iznosila nekoliko pre-BERT neuralnih modela. Također uspoređujemo nekoliko strategija predobrađivanja podataka specifičnih kodova i saznamo da specijalizovana tokenizacija poboljšava učinkovitost.', 'fi': "Semanttisen koodihaun tehtävänä on hakea koodinpätkyjä lähdekoodikorpusta luonnollisella kielellä ilmaistun tietotarpeen pohjalta. Luonnonkielen ja ohjelmointikielten semanttista kuilua on pitkään pidetty yhtenä avainsanoihin perustuvien tiedonhakumenetelmien tehokkuuden suurimmista esteistä. On yleistä olettamusta, että 'perinteiset' sana-pussi IR-menetelmät eivät sovellu semanttiseen koodihakuun: tutkimuksemme tutkii tätä olettamusta empiirisesti. Tarkastelemme erityisesti kahden perinteisen IR-menetelmän, BM25:n ja RM3:n, tehokkuutta CodeSearchNet Corpus -järjestelmässä, joka koostuu luonnollisista kielikyselyistä ja asiaankuuluvista koodinpätköistä. Havaitsemme, että nämä kaksi avainsanapohjaista menetelmää ovat parempia kuin useat BERT-neuromallit. Vertaamme myös useita koodikohtaisia tietojen esikäsittelyn strategioita ja huomaamme, että erikoistunut tokenisointi parantaa tehokkuutta.", 'et': 'Semantilise koodiotsingu ülesanne on hankida koodilõiked lähtekoodikorpusest looduskeeles väljendatud infovajaduse põhjal. Looduskeele ja programmeerimiskeelte semantilist lõhet on pikka aega peetud üheks olulisemaks takistuseks märksõnapõhise teabehankimise (IR) meetodite tõhususele. Tavaline eeldus on, et traditsioonilised IR-meetodid sobivad semantilise koodi otsinguks halvasti: meie töö uurib seda eeldust empiiriliselt. Konkreetselt uurime kahe traditsioonilise IR meetodi, nimelt BM25 ja RM3 efektiivsust CodeSearchNet Corpuses, mis koosneb looduskeelsetest päringutest, mis on seotud asjakohaste koodilõigetega. Leiame, et kaks märksõnapõhist meetodit ületavad mitmeid BERT-eelseid närvimudeleid. Võrdleme ka mitmeid koodipõhiseid andmete eeltöötlusstrateegiaid ja leiame, et spetsiaalne tokeniseerimine parandab efektiivsust.', 'af': "Die taak van semantiese kode soek is om kode snippets uit 'n bronkode korpus te ontvang wat op 'n inligting nodig in natuurlike taal uitgevoer word. Die semantiese spans tussen natuurlike taal en programma tale is vir lank aangesien as een van die mees betekende hinders tot die effektiviteit van sleutelwoord-gebaseerde inligting ontvang (IR) metodes. Dit is 'n gemeenskaplike aanvaar dat 'tradisionele' sak van woorde IR metodes verkeerd geskik is vir semantiese kode soek: ons werk empiriese hierdie aanvaar ondersoek. Spesifieke, ons ondersoek die effektiviteit van twee tradisionele IR metodes, bedoel BM25 en RM3, op die CodeSearchNet Corpus, wat bestaan van natuurlike taal vrae wat met relevante kode snippets paar is. Ons vind dat die twee sleutelwoord-gebaseerde metodes verskeie voor-BERT neurale modele uitvoer. Ons vergelyk ook verskeie kode-spesifieke data-voorafverwerking strategies en vind dat spesialiseerde tokenisasie effektiviteit verbeter.", 'jv': "Sampeyan kelas sematik bukane dadi nggawe kelas kode seneng pisan kelas nang kode perbudhakan Tarjamahan sematik langkung banjur idiomat lan program sing dumadhi iki bakal terusah bantuan ing ngupakan karo perbudhakan sing apik bantuan kanggo nggawe informasi sing basa gambar na kelas Mungkin ngerti, nggunakake 'Traditional' bags-of-words IR kuwi ngerasah kanggo nguasai kode sematik: lan barang awak dhéwé empires menehi kuwi. Kowe nguasai, awak dhéwé ngerasakno efek karo hal-hal ngerasakno IR sing wis ambang, nambah EM5 lan Rm3, lan kode-suarangknet Awak dhéwé ngerti, kuwi gambarang langgar sampek dadi sing bisa model sing bisa BERT nggawe Awak dhéwé pisan karo paketen nggambar akeh operasi layang-pakan karo perusahaan gambar nggawe barang nggawe aturan tokenisaan sing bisa nguasai efek.", 'ha': "Kayan aikin search na kodi na semantic is to retrieve kode ɗin kodi daga wata kode na source based on wani maɓalli wanda aka buɗe da shi cikin harshen asimi. Kifin sakanti da ke tsakanin harshen asimi da shiryoyin ayukan ayuka da aka ƙayyade wa zaman zuwa aka ƙaddara shi kamar ɗayan hanyõyin mafi girma wa amfani da motsar masu tsari ga maɓallin maganar (IR). Wannan yana da ɗabi'a da za'a buƙata-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane A ƙayyade, tuna ƙidãya masu amfani da shiryoyin IR biyu na zamani, kamar BM25 da RM3, a kan KCode SearchNet, wanda ke ƙunsa da askari na cikin harshen asili wanda aka haɗa da kodi masu husũma. Tuna gane cewa hanyõyin biyu masu sala ga maɓallin ayuka da ke samar wasu misãlai masu gaba-BERT. Kayya, Munã daidaita ko da wasu taki masu ƙayyade kodi masu cikin takilaikin da ke gabatar da aiki, kuma Munã gane cewa alama masu ƙayyade, yana ƙara mafiya amfani.", 'sk': 'Naloga semantičnega iskanja kode je pridobiti delčke kode iz korpusa izvorne kode na podlagi informacijske potrebe, izražene v naravnem jeziku. Semantična vrzel med naravnim jezikom in programskimi jeziki je že dolgo veljala za eno najpomembnejših ovir za učinkovitost metod pridobivanja informacij na podlagi ključnih besed (IR). Pogosta domneva je, da so "tradicionalne" metode IR vrečke besed slabo primerne za semantično iskanje kod: naše delo empirično raziskuje to domnevo. Natančneje preučujemo učinkovitost dveh tradicionalnih IR metod, in sicer BM25 in RM3, na CodeSearchNet Corpus, ki je sestavljen iz poizvedb v naravnem jeziku, povezanih z ustreznimi delčki kode. Ugotovili smo, da sta obe metodi, ki temeljita na ključnih besedah, boljši od več pred-BERT nevronskih modelov. Primerjamo tudi več strategij predobdelave podatkov, specifičnih za kodo, in ugotavljamo, da specializirana žetonizacija izboljšuje učinkovitost.', 'bo': 'སྔོན་ལྟར་ཞིབ་ཀྱི་འཚོལ་བཤེར་ཀྱི་བྱ་འགུལ་ནི་རང་བཞིན་སྐད་ནང་གསལ་བཤད་ཀྱི་ཆ་འཕྲིན་ཡིག The semantic gap between natural language and programming languages has been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. འདི་ལྟ་བུའི་མཐུན་ལམ་ལུགས་ཀྱི་གནད་སྡུད་གནད་མིན་ཡོད་པའི་ཐབས་ལམ་ཞིག་ཉེན་པ་ཞིག་ཡིན། དམིགས་འཛུགས་ཀྱིས། ང་ཚོའི་རྒྱུན་སྲོལ་གྱི་IR ཐབས་ལམ་གཉིས་ཀྱི་ལྟ་བུ་ཞིབ་དཔྱད་དགོས་པ་དེ་མིན BM25 དང་RM3(CodeSearchNet Corpus)ནང་དུ་ཡོད། དེ་ནི་སྤྱིར་བཏང་བའི་སྐད ང་ཚོས་བྱ་ཚིག་དང་གཙོ་ཚིག་གཞི་རྟེན་པའི་ཐབས་ལམ་གཉིས་ཀྱིས་BERT སྔོན་གྱི་དཔེ་དབྱིབས་མང་པོ་ཞིག ང་ཚོས་ཀྱང་གསལ་བཤད་ཀྱི་སྔོན་སྒྲིག་འགོད་བྱེད་པའི་གནས་ཚུལ་གསལ་བཀལ་བ་མང་ཙམ་བཟོ་བྱེད་ཀྱི་ཡོད།', 'he': "המשימה של חיפוש קוד סמנטי היא להשיג חתיכות קוד ממקור קוד קורפוס מבוסס על צורך מידע מוביע בשפה טבעית. הפער הסמנטי בין שפת טבעית לשפת תוכנית כבר זמן רב נחשב כאחד המעכבים הכי משמעותיים ביותר לעובדות שיטות השיג מידע מבוסס על מילים מפתחות (IR). It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  במיוחד, אנחנו בודקים את היעילות של שתי שיטות IR מסורתיות, כלומר BM25 ו-RM3, על CodeSearchNet Corpus, אשר מורכבת משאלות שפות טבעיות זוגות עם חתיכות קוד רלוונטיות. אנחנו מוצאים ששתי השיטות המבוססות על מילים מפתחות מעליפות מספר דוגמנים עצביים לפני BERT. אנחנו משוותים גם מספר אסטרטגיות מעבדה מוקדמת של נתונים מסויימים לקוד ומצאים שטוקניזציה מומחית משפר את היעילות."}
