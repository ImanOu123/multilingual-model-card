{'en': 'SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task', 'ar': 'نظام SRPOL لمهمة ترجمة الكلام من البداية إلى النهاية IWSLT 2020', 'fr': 'Le système de SRPOL pour la tâche de traduction vocale de bout en bout IWSLT 2020', 'pt': 'Sistema do SRPOL para a tarefa de tradução de fala de ponta a ponta do IWSLT 2020', 'es': 'Sistema de SRPOL para la tarea de traducción de voz de extremo a extremo de IWSLT 2020', 'zh': 'SRPOL 用 IWSLT 2020 端到端语音译职之统', 'hi': 'IWSLT 2020 एंड-टू-एंड वाक् अनुवाद कार्य के लिए SRPOL की प्रणाली', 'ja': 'IWSLT 2020エンドツーエンドの音声翻訳タスクのためのSRPOLのシステム', 'ru': "SRPOL 's System for the IWSLT 2020 End-to-End Speech Translation Task (Система SRPOL для задачи комплексного перевода речи IWSLT 2020)", 'ga': 'Córas SRPOL do Thasc Aistriúcháin Ó Dheireadh go Deireadh IWSLT 2020', 'ka': 'SRPOL- ის სისტემა IWSLT 2020 ბოლოდან ბოლოდან დასრულებული სიტყვების გასაგრძელება', 'el': 'Το σύστημα της SRPOL για το έργο ολοκληρωμένης μετάφρασης ομιλίας του IWSLT 2020', 'hu': 'Az SRPOL rendszere az IWSLT 2020 teljes beszédfordítási feladatához', 'it': 'Sistema SRPOL per la traduzione vocale end-to-end di IWSLT 2020', 'kk': 'SRPOL жүйесі IWSLT 2020 End- to End Speech Translation Task', 'ms': "SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task", 'ml': 'IWSLT 2020 അവസാനിക്കുന്നതിനുള്ള SRPOL സിസ്റ്റം', 'mt': 'Is-Sistema tal-SRPOL għall-kompitu tat-traduzzjoni tal-kelma mill-aħħar sal-aħħar tal-IWSLT 2020', 'lt': 'SRPOL strategijos „IWSLT 2020“ vertimo žodžiu užduotis', 'mn': "SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task", 'no': 'SRPOL- systemet for IWSLT 2020 End- to- End Speech Translation Task', 'mk': 'Системот на СРПОЛ за задачата за преведување на говорот од крај до крај на IWSLT 2020', 'pl': 'System SRPOL do kompleksowego tłumaczenia mowy IWSLT 2020', 'ro': 'Sistemul SRPOL pentru sarcina de traducere vocală finală IWSLT 2020', 'sr': 'SRPOL-ov sistem za IWSLT 2020. zadatak za kraj do kraja prevoda govora', 'si': "SRPOL' s System for the IWSLT 2020End- to- End Talk translation Job", 'so': "SRPOL's system for the IWSLT 2020 End-to-End Speech Translation Task", 'ta': 'IWSLT 2020 முடிவு- முடிவு பேச்சு மொழிபெயர்ப்பு பணிக்கான SRPOL அமைப்பு', 'sv': 'SRPOL:s system för IWSLT 2020 End-to-End Speech Translation Task', 'ur': 'IWSLT 2020 End-to-End Speech Translation Task کے لئے SRPOL سیسٹم', 'uz': '@ info: whatsthis', 'vi': 'Hệ thống âm thanh AROL for the IWSLT 2020 End-to-End chuyện Translation Task', 'bg': 'Системата на СРПОЛ за задачата за превод на реч от край до край', 'da': "SRPOL's system til IWSLT 2020 End-to-End Tale Oversættelse Opgave", 'nl': "SRPOL's systeem voor de IWSLT 2020 End-to-End spraakvertaaltaak", 'hr': 'SRPOL-ov sustav za IWSLT 2020. zadatak za kraj do kraja prevoda govora', 'de': "SRPOL's System für die IWSLT 2020 End-to-End Sprachübersetzung", 'ko': 'SRPOL의 IWSLT 2020 엔드-투-엔드 음성 번역 임무 시스템', 'fa': 'سیستم SRPOL برای تاریخ ترجمه سخنرانی IWSLT 2020', 'sw': 'Mfumo wa SRPOL kwa ajili ya Task la Tafsiri ya Utafiti', 'tr': "SRPOL'iň IWSLT 2020'iň End-to-End Sözi Terjime Görevi", 'am': "SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task", 'af': 'SRPOL se Stelsel vir die IWSLT 2020 End- to- End Speech Translation Task', 'sq': 'Sistemi i SRPOL për IWSLT 2020', 'az': "SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task", 'bn': 'IWSLT ২০২০ শেষ- থেকে শেষ- পর্যন্ত ভাষণ অনুবাদের কাজের জন্য SRPOL সিস্টেম', 'hy': 'IwPLT 2020 թվականի վերջ-վերջ խոսքի թարգմանման հանձնարարությունը', 'bs': 'SRPOL-ov sustav za zadatak prevoda govora IWSLT 2020.', 'cs': 'Systém SRPOL pro komplexní překlad řeči IWSLT 2020', 'et': 'SRPOLi süsteem IWSLT 2020 lõppkõne tõlke ülesandeks', 'fi': 'SRPOL:n järjestelmä IWSLT 2020:n puhekääntämistehtävään', 'id': 'Sistem SRPOL untuk Tugas Terjemahan Bicara Akhir-Akhir IWSLT 2020', 'ca': 'El Sistema SRPOL per a la tasca de traducció de la llengua final a final IWSLT 2020', 'ha': '@ action', 'jv': 'paper size', 'sk': 'Sistem SRPOL za nalogo prevajanja govora od konca do konca IWSLT 2020', 'he': 'מערכת SRPOL למשימה של IWSLT 2020', 'bo': "SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task"}
{'en': 'We took part in the offline End-to-End English to German TED lectures translation task. We based our solution on our last year’s submission. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. To improve the model’s quality of translation we introduced two regularization techniques and trained on machine translated Librispeech corpus in addition to iwslt-corpus, TEDLIUM2 andMust_C corpora. Our best model scored almost 3 BLEU higher than last year’s model. To segment 2020 test set we used exactly the same procedure as last year.', 'ar': 'شاركنا في مهمة ترجمة محاضرات TED من الإنجليزية إلى الألمانية من البداية إلى النهاية. لقد استندنا في حلنا إلى تقديمنا العام الماضي. استخدمنا بنية محول معدلة قليلاً مع طبقة تلافيفية تشبه ResNet لتحضير إدخال الصوت إلى ترميز المحولات. لتحسين جودة الترجمة في النموذج ، أدخلنا تقنيتين للتنظيم ودربنا على مجموعة Librispeech المترجمة آليًا بالإضافة إلى iwslt-corpus و TEDLIUM2 و Must_C corpora. أفضل طراز لدينا سجل 3 BLEU أعلى من طراز العام الماضي. لتقسيم مجموعة الاختبار لعام 2020 ، استخدمنا نفس الإجراء تمامًا كما في العام الماضي.', 'es': 'Participamos en la tarea de traducción de conferencias TED de inglés a alemán de principio a fin fuera de línea. Basamos nuestra solución en la presentación del año pasado. Utilizamos una arquitectura Transformer ligeramente alterada con una capa convolucional similar a Resnet que prepara la entrada de audio al codificador Transformer. Para mejorar la calidad de la traducción del modelo, introdujimos dos técnicas de regularización y nos capacitamos en corpus Librispeech traducidos automáticamente, además de los corpora iwslt-corpus, TEDLIUM2 y MUST_C. Nuestro mejor modelo obtuvo casi 3 BLEU más que el modelo del año pasado. Para segmentar el conjunto de pruebas de 2020 utilizamos exactamente el mismo procedimiento que el año pasado.', 'pt': 'Participamos da tarefa de tradução de palestras TED de inglês para alemão de ponta a ponta offline. Baseamos nossa solução na apresentação do ano passado. Usamos uma arquitetura Transformer ligeiramente alterada com camada convolucional do tipo ResNet preparando a entrada de áudio para o codificador Transformer. Para melhorar a qualidade da tradução do modelo, introduzimos duas técnicas de regularização e treinamos em Librispeech corpus traduzido por máquina, além de iwslt-corpus, TEDLIUM2 e Must_C corpora. Nosso melhor modelo obteve quase 3 BLEU a mais do que o modelo do ano passado. Para segmentar o conjunto de testes de 2020, usamos exatamente o mesmo procedimento do ano passado.', 'fr': "Nous avons participé à la tâche de traduction hors ligne de bout en bout des conférences TED de l'anglais vers l'allemand. Nous avons basé notre solution sur la base de notre soumission de l'année dernière. Nous avons utilisé une architecture Transformer légèrement modifiée avec une couche convolutionnelle de type Resnet préparant l'entrée audio de l'encodeur Transformer. Pour améliorer la qualité de traduction du modèle, nous avons introduit deux techniques de régularisation et nous nous sommes formés au corpus Librispeech traduit automatiquement en plus des corpus iwslt-corpus, TEDLIUM2 et MUST_C. Notre meilleur modèle a obtenu près de 3 points de plus que le modèle de l'année dernière. Pour segmenter le jeu de test 2020, nous avons utilisé exactement la même procédure que l'année dernière.", 'ja': 'オフラインのエンドツーエンドの英語からドイツ語へのTED講義翻訳タスクに参加しました。昨年の提出書類に基づいてソリューションを作成しました。私たちは、ResNetのような畳み込みレイヤーを備えた少し変更されたトランスフォーマーアーキテクチャを使用して、トランスフォーマーエンコーダへのオーディオ入力を準備しました。モデルの翻訳品質を向上させるために、2つの正規化技術を導入し、iwslt - corpus、TEDLIUM 2、およびMust_C corporaに加えて機械翻訳Librispeechコーパスのトレーニングを行いました。当社の最高のモデルは、昨年のモデルよりもほぼ3 BLEUのスコアを獲得しました。2020年のテストセットをセグメント化するために、昨年とまったく同じ手順を使用しました。', 'zh': '与离线端到端英语德语TED讲座译事。 我们的解决方案基于去年提交的文件。 吾用少变之 Transformer 架构,有类 ResNet 之卷积层,以备 Transformer 编码器之音频输。 为重译质,引入二正则化,教习于机器翻译之Librispeech语料库及iwslt-corpus,TEDLIUM2 andMust_C语料库。 最佳得分比去年模出近3 BLEU。 为分2020年试集,用与去年同。', 'ru': 'Мы приняли участие в офлайн-задаче по переводу с английского на немецкий лекций TED. Наше решение было основано на нашем прошлогоднем представлении. Мы использовали слегка измененную архитектуру Трансформатора со сверточным слоем, подобным ResNet, подготавливающим аудио вход для кодировщика Трансформатора. Для улучшения качества перевода модели мы внедрили две методики регуляризации и обучили машинному переводу Librispeech corpus в дополнение к iwslt-corpus, TEDLIUM2 иMust_C corpa. Наша лучшая модель набрала почти на 3 БЛЮ больше, чем модель прошлого года. Для сегментации тестового набора 2020 года мы использовали точно такую же процедуру, как и в прошлом году.', 'hi': 'हमने ऑफ़लाइन एंड-टू-एंड अंग्रेजी से जर्मन टेड व्याख्यान अनुवाद कार्य में भाग लिया। हम अपने पिछले साल के सबमिशन पर हमारे समाधान के आधार पर. हम ResNet के साथ एक थोड़ा बदल ट्रांसफॉर्मर वास्तुकला का इस्तेमाल किया-जैसे convolutional परत ट्रांसफॉर्मर एन्कोडर के लिए ऑडियो इनपुट तैयार. अनुवाद के मॉडल की गुणवत्ता में सुधार करने के लिए हमने दो नियमितीकरण तकनीकों को पेश किया और मशीन अनुवादित लिब्रिसपीच कॉर्पस पर प्रशिक्षित किया, इसके अलावा iwslt-corpus, TEDLIUM2 andMust_C corpora। हमारे सबसे अच्छे मॉडल ने पिछले साल के मॉडल की तुलना में लगभग 3 BLEU अधिक स्कोर किया। सेगमेंट 2020 परीक्षण सेट के लिए हमने पिछले साल की तरह ही प्रक्रिया का उपयोग किया।', 'ga': "Ghlacamar páirt i dtasc aistriúcháin léachtaí TED ó Bhéarla go Gearmáinis ó cheann go ceann as líne. Bhunaíomar ár réiteach ar ár n-aighneacht anuraidh. D'úsáideamar ailtireacht Trasfhoirmeora a athraíodh de bheagán agus ciseal conbhlóideach cosúil le ResNet ag ullmhú an ionchur fuaime chuig an ionchódóir Transformer. Chun cáilíocht aistriúcháin an mhúnla a fheabhsú thugamar isteach dhá theicníc rialtachta agus chuireamar oiliúint ar corpas meaisín-aistrithe Librispeech chomh maith le iwslt-corpus, TEDLIUM2 agus Must_C corpora. Scóráil ár múnla is fearr beagnach 3 BLEU níos airde ná samhail na bliana seo caite. Chun tacair tástála 2020 a dheighilt, d'úsáideamar go díreach an nós imeachta céanna agus a bhí anuraidh.", 'hu': 'Részt vettünk az offline End-to-End angol-német TED előadások fordítási feladatában. Megoldásunkat a tavalyi beadványunkra alapoztuk. Egy kissé módosított Transformer architektúrát használtunk ResNet-szerű konvolúciós réteggel, amely előkészítette az audio bemenetet a Transformer kódolóhoz. A modell fordítási minőségének javítása érdekében két szabályozási technikát vezettünk be, és az iwslt-corpus, a TEDLIUM2 és a Must_C corpora mellett gépi lefordítású Librispeech corpus képzésére készültünk. A legjobb modellünk majdnem 3 BLEU-t ért el a tavalyi modellnél. A 2020-as tesztkészlethez pontosan ugyanazt az eljárást használtuk, mint tavaly.', 'el': 'Πήραμε μέρος στο έργο μετάφρασης διαλέξεων από αγγλικά σε γερμανικά. Βασίσαμε τη λύση μας στην περσινή υποβολή μας. Χρησιμοποιήσαμε μια ελαφρώς τροποποιημένη αρχιτεκτονική μετασχηματιστή με ένα στρώμα που μοιάζει με ResNet προετοιμάζοντας την είσοδο ήχου στον κωδικοποιητή μετασχηματιστή. Για να βελτιώσουμε την ποιότητα της μετάφρασης του μοντέλου εισαγάγαμε δύο τεχνικές κανονικοποίησης και εκπαιδεύσαμε σε μηχανικά μεταφρασμένο σώμα εκτός από τα σώματα iwslt-corpus, TEDLIUM2 και Must_C. Το καλύτερό μας μοντέλο πέτυχε σχεδόν τρία υψηλότερα από το περσινό μοντέλο. Για το τμήμα 2020 σετ δοκιμών χρησιμοποιήσαμε ακριβώς την ίδια διαδικασία με πέρυσι.', 'ka': 'ჩვენ დავიწყეთ "End-to-End" ინგლისური დაწყვეტილების დაწყვეტილებელი TED ლექციების დაწყვეტილებელი საქმე. ჩვენ წინა წლის შემდეგ ჩვენი გარეშე დავიბაზეთ. ჩვენ გამოყენეთ ცოტა შეცვლელი ტრანფორმების აქტიქტიქტიკური რესნეტების მსგავსი კონტროლუციონალური ჩატვირთვის, როგორც რესნეტების მსგავ ჩვენ მოდელის გასაგრძელებლად ორი რეგილარიზაციის ტექნოგიების გასაგრძელებლად შევცვალოთ და მაქინის გასაგრძელებლად Librispeech corpus-ს დამატებით iwslt-corpus, TEDLIUM2 და Must_C corpora-ს დამატებით. ჩვენი ყველაზე საუკეთესო მოდელი დაიწყო დამატებით 3 BLEU-ს უფრო მეტი წლის მოდელზე. 2020 წლის სეგენტის ტესტისთვის ჩვენ გამოყენეთ ისეთი პროცესია როგორც წინა.', 'it': "Abbiamo preso parte al compito offline di traduzione delle lezioni TED dall'inglese al tedesco. Abbiamo basato la nostra soluzione sulla presentazione dell'ultimo anno. Abbiamo usato un'architettura Transformer leggermente modificata con un livello convoluzionale simile a ResNet per preparare l'ingresso audio al codificatore Transformer. Per migliorare la qualità della traduzione del modello abbiamo introdotto due tecniche di regolarizzazione e addestrato sul corpus Librispeech tradotto automaticamente oltre a iwslt-corpus, TEDLIUM2 e Must_C corpora. Il nostro miglior modello ha ottenuto quasi 3 BLEU in più rispetto al modello dello scorso anno. Per segmentare il set di test 2020 abbiamo utilizzato esattamente la stessa procedura dell'anno scorso.", 'kk': 'Біз "End-to-End" ағылшыншасына неміс TED лекцияларының аудару тапсырмасына бөлікті. Біз соңғы жылдың келтірімізге шешімізді негіздеп тұрмыз. Біз ResNet секілді конверсиялық қабатты аудио енгізуін түрлендіру кодеріне дайындау үшін бірнеше өзгертілген түрлендіру архитектурасын қолдандық. Үлгінің аудармасының сапатын жақсарту үшін, біз екі үлгі түрлендіру техникасын және компьютердің аудармағындағы Librispeech корпус iwslt-corpus, TEDLIUM2 және Must_C корпорасына қосымша үйрендік. Біздің ең жақсы моделіміз өткен жылдың үлгісінен артық 3 BLEU болды. 2020 жыл сегментінің сынақтарына біз өткен жылдың бір процедурасын қолдандық.', 'lt': 'Mes dalyvavome anglų kalbos vertimo darbe iš eilės į vokiečių TED pamokas. Mūs ų sprendimas grindžiamas praėjusių metų pareiškimu. Naudojome šiek tiek pakeistą Transformer architektūrą su panašu į ResNet konvoliuciniu sluoksniu, ruošiant garso įvedimą į Transformer kodatorių. Siekdami pagerinti modelio vertimo kokybę, įdiegėme du reguliarizavimo metodus ir apmokėme mašin ų vertimo Librispeech corpus, be iwslt-corpus, TEDLIUM2 ir Must_C corpora. Mūs ų geriausias modelis buvo beveik 3 BLEU didesnis už praėjusių metų model į. To segment 2020 test set we used exactly the same procedure as last year.', 'mk': 'We took part in the offline End-to-End English to German TED lectures translation task.  Го базиравме нашето решение на минатата година. Користевме малку променета трансформарна архитектура со конволуционален слој како Ресенет кој го подготвува аудио внесот во трансформарниот кодер. За да го подобриме квалитетот на преводот на моделот, воведовме две техники за регуларизација и трениравме на машински превод Librispeech corpus, покрај iwslt-corpus, TEDLIUM2 и Must_C corpora. Нашиот најдобар модел постигна скоро 3 БЛЕ повисоки од минатогодишниот модел. To segment 2020 test set we used exactly the same procedure as last year.', 'ms': "We took part in the offline End-to-End English to German TED lectures translation task.  Kita berdasarkan penyelesaian kita pada penghantaran tahun lepas. Kami menggunakan arkitektur Transformer yang sedikit diubah dengan lapisan konvolusi seperti ResNet menyediakan input audio ke pengekod Transformer. Untuk meningkatkan kualiti terjemahan model kami memperkenalkan dua teknik pengaturan dan dilatih pada Librispeech corpus terjemahan mesin selain iwslt-corpus, TEDLIUM2 dan Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model.  Untuk set ujian segmen 2020 kami menggunakan prosedur yang sama dengan tahun lepas.", 'ml': 'ഞങ്ങള്\u200d ഓഫ്\u200cലൈന്\u200d ആന്\u200dഡ് മുഴുവന്\u200d ഇംഗ്ലീഷില്\u200d പങ്കുചേര്\u200dത്ത് ജര്\u200dമ്മന്\u200d ടെഡി ലേക്ഷര്\u200d പരിഭാഷണത്തിന്\u200dറെ  നമ്മുടെ കഴിഞ്ഞ വര്\u200dഷത്തെ കീഴ്പ്പെടുത്തിയിട്ട് നമ്മുടെ പരിഹാരം അടിസ്ഥാനമാക്കി. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder.  ഈ മോഡലിന്റെ വിഭാഷത്തിന്റെ ഗുണപൂര്\u200dണ്ണമാക്കാന്\u200d ഞങ്ങള്\u200d രണ്ടു നിയന്ത്രണത്തിന്റെ സാങ്കേതികവിദ്യകളെ പരിശീലിപ്പിച്ച് ലിബ്രിസ്പീച് കോര്\u200dപ്പുസിനെ  നമ്മുടെ ഏറ്റവും നല്ല മോഡല്\u200d കഴിഞ്ഞ വര്\u200dഷത്തെ മോഡലിനെക്കാള്\u200d മൂന്നു ബിലിയുവിനെക്കാള്\u200d ഉയര്\u200dത്തി. 2020 ടെസ്റ്റ് സെറ്റ് ചെയ്യാന്\u200d കഴിഞ്ഞ വര്\u200dഷം നമ്മള്\u200d അതേ പ്രക്രിയയാണ് ഉപയോഗിച്ചത്.', 'mt': "We took part in the offline End-to-End English to German TED lectures translation task.  We based our solution on our last year's submission.  Użajna arkitettura Transformer kemmxejn mibdula b’saff konvoluzzjonali simili għal ResNet li jipprepara l-input awdjo għall-kodifikatur Transformer. Biex tittejjeb il-kwalità tat-traduzzjoni tal-mudell introduċejna żewġ tekniki ta’ regolarizzazzjoni u mħarrġa fuq Librispeech corpus tradott bil-magna flimkien ma’ iwslt-corpus, TEDLIUM2 u Must_C corpora. L-aħjar mudell tagħna kellu kważi 3 BLEU ogħla mill-mudell tas-sena l-oħra. Għas-sett tat-test tas-segment 2020 użajna eżattament l-istess proċedura bħas-sena l-oħra.", 'no': 'Vi har delt i den fråkopla ende-til-slutt engelsk til tysk TED-leksjonsoppgåva. Vi baserer løsningen vårt på løsningen vårt siste år. Vi brukte ein liten endra transformeringsarkitektur med konvolusjonell lag som ResNet-liknar som forbereder lyd-inndata til Transformeringskodar. For å forbetra omsetjingskvaliteten til modellen, introdusere vi to reguleringsteknikk og trenga på maskina omsette Librispeech corpus i tillegg til iwslt-corpus, TEDLIUM2 og Must_C corpora. Det beste modellet vårt oppretta nesten 3 BLEU høgare enn siste årsmodellen. For segment 2020-testen brukte vi nøyaktig det samme prosedyren som siste år.', 'pl': 'Braliśmy udział w zadaniu tłumaczenia wykładów TED z języka angielskiego na niemiecki offline. Nasze rozwiązanie opieraliśmy na zeszłorocznej zgłoszeniu. Zastosowaliśmy nieco zmienioną architekturę Transformera z warstwą konwolucyjną ResNet przygotowującą wejście audio do kodera Transformera. Aby poprawić jakość tłumaczenia modelu, wprowadziliśmy dwie techniki regularyzacji oraz trenowaliśmy korpus Librispeech przetłumaczony maszynowo oprócz korpusów iwslt-corpus, TEDLIUM2 i Must_C. Nasz najlepszy model zdobył niemal 3-BLEU wyższy niż ubiegłoroczny model. Do segmentu zestawu testowego 2020 zastosowaliśmy dokładnie taką samą procedurę jak w zeszłym roku.', 'mn': 'Бид "End-to-End" хэлний англи хэлний төгсгөлд Германы TED лекцийн хөгжлийн даалгавраанд оролцсон. Өнгөрсөн жилийн дараа бидний шийдвэрийг үндсэн. Бид ResNet шиг бага зэрэг өөрчлөгдсөн Трансфер архитектурыг ашигласан. Аудио орлуудыг Трансфер кодер руу бэлдэж байна. Тиймээс бид загварын хөгжүүлэх чадварыг сайжруулахын тулд хоёр шууд шинжлэх ухааны техник, машины хөгжүүлэх Librispeech корпус болон iwslt-corpus, TEDLIUM2 болон Must_C корпора дамжуулагдсан. Бидний хамгийн сайн загвар өнгөрсөн жилийн загвараас бараг 3 БЛУ өндөр байсан. 2020 оны шалгалтын хувьд бид өнгөрсөн жилтэй адилхан процедурыг ашигласан.', 'ro': 'Am luat parte la sarcina offline de traducere a prelegerilor TED din engleză în germană. Am bazat soluția noastră pe depunerea noastră de anul trecut. Am folosit o arhitectură Transformer ușor modificată cu strat convoluțional asemănător ResNet pregătind intrarea audio la encoder Transformer. Pentru a îmbunătăți calitatea traducerii modelului am introdus două tehnici de regularizare și am instruit pe corpus Librispeech tradus automat în plus față de iwslt-corpus, TEDLIUM2 și Must_C corpora. Cel mai bun model al nostru a obținut aproape 3 BLEU mai mult decât modelul de anul trecut. Pentru segmentarea setului de testare 2020 am folosit exact aceeași procedură ca și anul trecut.', 'sr': 'Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Na osnovu našeg rješenja na poslednjoj predanosti. Koristili smo malu izmjenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a, pripremajući audio unos za koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dve regularizacijske tehnike i obučene na mašini prevedeno Librispeech corpus, osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model je dobio skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa 2020. koristili smo tačno iste procedure kao i prošle godine.', 'so': "Waxaannu ka qeybqaadanay shabakadda End-to-End Ingiriis-da German TED lectures translation mission. waxaynu ku aasaasnay xalaalka dhamaadka sanadkii. Waxaynu isticmaalnay dhismaha turjumista ee wax yar oo beddelan oo la mid ah ResNet darajada adag oo u diyaarinaya sawirka codka ee turjumista. Si loo hagaajiyo takhasuska turjumista, waxaan soo bandhigay laba qaabilaad oo la soodajiyo oo lagu tababariyey mashiinka lagu turjumay librispeech korpus ka sokow iwslt-corpus, TEDLIUM2 iyo Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model.  qeybinta 2020 ee baaritaanka waxaynu u isticmaalnay si isku mid ah xiliga sanadkii hore.", 'si': 'අපි ඉංග්\u200dරීසියට අන්තිම විදියට ජර්මන් TED ප්\u200dරශ්න විදියට භාවිතා කරනවා. අපි අන්තිම අවුරුද්දේ පිළිගන්නේ අපේ විසරණය. අපි ResNet-වගේ සම්පූර්ණ ස්ථානයක් සමග වෙනස් වෙන්න වෙනස් වෙන්න ස්ථානයක් පාවිච්චි කරනවා අඩියෝජිත ඇත මොඩල් එකේ වාර්ථාවේ කුළුවත් වැඩි කරන්න අපි නියමික විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත ව අපේ හොඳම මෝඩේල් එක ගිය අවුරුද්දේ මෝඩේල් එකට වඩා බ්ලෝයුස් 3ක් වඩා වැඩියි. අපි පරීක්ෂණාවට පරීක්ෂණාවට පස්සේ අවුරුද්දේ වගේ සිද්ධ විධානය පාවිච්චි කරනවා.', 'sv': 'Vi deltog i översättningsuppgiften offline från engelska till tyska TED-föreläsningar. Vi baserade vår lösning på vårt förra års inlämning. Vi använde en något förändrad Transformer arkitektur med ResNet-liknande konvulutionslager för att förbereda ljudingången till Transformer encoder. För att förbättra modellens kvalitet på översättning introducerade vi två regulariseringstekniker och tränade på maskinöversatt Librispeech corpus utöver iwslt-corpus, TEDLIUM2 och Must_C corpora. Vår bästa modell fick nästan 3 BLEU högre än förra årets modell. För att segmentera 2020 testset använde vi exakt samma procedur som förra året.', 'ta': 'We took part in the offline End-to-End English to German TED lectures translation task.  நாங்கள் கடந்த வருடத்தின் கட்டளையை அடிப்படையாக எங்கள் தீர்வு. நாங்கள் ஒரு சிறிய மாற்றப்பட்ட மாற்று அமைப்பை பயன்படுத்தினோம் ரெஸ்நெட் போன்ற சாதாரண அடுக்கு மாற்றும் குறியீட்டிற்க மாதிரியின் மொழிபெயர்ப்பின் தரம் மாற்ற நாங்கள் இரண்டு கட்டுப்பாட்டு தொழில்நுட்பத்தை முன்னேற்றி இயந்திரத்தில் பயிற்சி மொழிபெயர்ப்பு லிப்ரிச்ப எங்கள் சிறந்த மாதிரி கடந்த வருடத்தின் மாதிரியை விட மூன்று பிலியு உயர்ந்தது. 2020 சோதனையை பிரிக்க நாம் கடந்த வருடத்தில் அதே செயல்பாட்டை பயன்படுத்தினோம்.', 'ur': 'ہم نے آف لین End-to-End انگلیسی میں جرمانی TED لکتروں کی ترجمہ کا کام بنایا۔ ہم نے اگلے سال کے مسلمانوں پر ہمارا حل بنیاد رکھا ہے۔ ہم نے ایک تھوڑا بدل تغییر تغییر تغییر دینے والے معماری استعمال کیا ہے جو رس نیٹ جیسی کنوولیوشن لائر کے ساتھ آڈیو اپن ایمپ ترنسفور کوڈر کے لئے تیار کر رہے ہیں. ہم نے مدل کی تعلیم کی کیفیت کو اچھی طرح پہنچایا اور ماشین کی تعلیم لیبرائیسپیچ کورپوس کے علاوہ دوسری قانونی تکنیک کو پہنچایا۔ ہمارے سب سے بہترین نمونڈل گئی سال کی نمونڈل سے تقریباً تین بلیوس سے بلند تھا۔ سال ۲۰۰۲ کے سپٹ ٹیسٹ کے لئے ہم نے پچھلی سال کے مطابق اسی طرح استعمال کیا۔', 'uz': "Biz ofline End to- End ingliz tilidagi ingliz tilida o'rganishni Olmoncha TED tahrirlash vazifasiga ega qildik. Biz yetgi yil qanday qilishga qaror qilamiz. Biz ResNet sifatida bir qisqa o'zgarishga o'zgarishga ishlatdik va Transformer kodlash uchun audio input tayyorligini tayyorlash. @ info Bizning eng yaxshi modelimiz past yil modelidagi 3 BLEU ko'p edi. 2020 ta'limni ajratish uchun biz past yil huddi bir xil vazifalarni ishlatdik.", 'vi': 'Chúng tôi tham gia vào cuộc dịch thuật bằng tiếng Anh giữa kết thúc và cuối cùng của Đức. Chúng ta đã dựa trên giải pháp của mình từ năm ngoái. Chúng tôi sử dụng một cấu trúc biến hình có chút thay đổi với lớp xoắn ốc giống hệt ResNet để chuẩn bị âm thanh nhập vào bộ mã hóa biến hình. Để nâng cao chất lượng bản dịch của mô hình chúng tôi đã nhập vào hai kỹ thuật hoá học và được đào tạo trên tập đoàn LibRispeech (Văn bản) được dịch ra trên máy tính, thêm cả hợp chất lỏng lẻo, định vị và phải hạ C. Mô hình tốt nhất của chúng ta đã đạt đến ba nguyên tắc cao hơn mẫu năm ngoái. Về phần kiểm tra 2020 chúng tôi đã dùng đúng thủ tục y chang năm ngoái.', 'bg': 'Участвахме в офлайн задачата за превод на лекции от английски до немски език. Основахме решението си на представянето от последната година. Използвахме леко променена архитектура на трансформатора с конволюционен слой, подобен на ResNet, подготвящ аудио входа към трансформатора. За да подобрим качеството на превода на модела, въведохме две техники за регулировка и обучихме машинно преведен корпус в допълнение към корпусите. Най-добрият ни модел отбеляза почти 3 по-висока оценка от миналата година. За сегмент 2020 тест комплект използвахме точно същата процедура като миналата година.', 'da': 'Vi deltog i offline end-to-end engelsk til tysk TED foredrag oversættelse opgave. Vi baserede vores løsning på vores sidste års indsendelse. Vi brugte en lidt ændret Transformer arkitektur med ResNet-lignende konvulutionslag forberedelse af lydindgangen til Transformer encoder. For at forbedre modellens oversættelseskvalitet introducerede vi to reguleringsteknikker og trænede i maskinoversat Librispeech corpus ud over iwslt-corpus, TEDLIUM2 og Must_C corpora. Vores bedste model scorede næsten 3 BLEU højere end sidste års model. For at segmentere 2020 testsæt brugte vi nøjagtig samme procedure som sidste år.', 'nl': 'We namen deel aan de offline End-to-End Engels naar Duits TED lezingen vertaaltaak. We baseerden onze oplossing op onze inzending van vorig jaar. We gebruikten een licht gewijzigde Transformer architectuur met ResNet-achtige convolutionele laag die de audio-ingang naar Transformer encoder voorbereidde. Om de kwaliteit van de vertaling van het model te verbeteren hebben we twee regularisatietechnieken geïntroduceerd en getraind op machinaal vertaalde Librispeech corpus naast iwslt-corpus, TEDLIUM2 en Must_C corpora. Ons beste model scoorde bijna drie BLEU hoger dan vorig jaar. Voor het segmenteren van 2020 testset hebben we exact dezelfde procedure gebruikt als vorig jaar.', 'hr': 'Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Započeli smo našu rješenje na podnošenju prošle godine. Koristili smo malu izmijenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a pripremajući audio ulaz za koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dvije regularizacijske tehnike i obučene na strojevima prevedeno Librispeech corpus, osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model rezultirao je skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa za segment 2020, koristili smo tačno isti postupak kao i prošle godine.', 'de': 'Wir haben an der Offline-End-Übersetzungsaufgabe für TED-Vorträge teilgenommen. Unsere Lösung stützten wir auf die Vorlage des Vorjahres. Wir verwendeten eine leicht veränderte Transformer-Architektur mit ResNet-ähnlicher Faltungsschicht, die den Audioeingang zum Transformer-Encoder vorbereitete. Um die Übersetzungsqualität des Modells zu verbessern, führten wir zwei Regularisierungstechniken ein und trainierten zusätzlich zu iwslt-corpus, TEDLIUM2 und Must_C Korpora am maschinell übersetzten Librispeech Korpus. Unser bestes Modell erzielte fast drei BLEU höher als das Vorjahresmodell. Für das Segment 2020-Testset haben wir genau das gleiche Verfahren wie im Vorjahr verwendet.', 'ko': '우리는 오프라인에서 끝까지 영어부터 독일어 TED 강좌 번역 임무에 참가했다.우리는 작년에 제출한 해결 방안을 바탕으로 한다.우리는 ResNet과 비슷한 볼륨층을 가지고 변환기 인코더를 위해 오디오 입력을 준비하는 약간 바뀐 변환기 구조를 사용했다.모델의 번역 품질을 향상시키기 위해 iwslt 자료 라이브러리, TEDLIUM2와Must C 자료 라이브러리 외에 두 가지 정규화 기술을 도입하고 기계 번역의Librispeech 자료 라이브러리에서 훈련을 실시했다.우리의 가장 좋은 차종의 득점은 작년 차종보다 3개의 BLEU 가까이 높다.2020 테스트집을 분할하기 위해 작년과 똑같은 프로그램을 사용했다.', 'sw': "Tumeshiriki katika kazi ya tafsiri ya TED katika mtandao wa mwisho-to-End English hadi Ujerumani. We based our solution on our last year's submission.  Tulitumia jengo lililobadilishwa kidogo la Transformer na kiwango kinachofanana na ResNet ambacho kiliandaa matokeo ya sauti kwenye kodi la Transformer. Kuboresha ubora wa utafsiri wa mifano tulianzisha mbinu mbili za kudhibiti na kufundishwa kwenye mashine yanayotafsiriwa Librispeech pamoja na iwslt-corpus, TEDLIUM2 na Must_C. Mfano wetu bora uliorodhesha takribani BLEU 3 zaidi ya mtindo wa mwaka jana. Katika sehemu ya jaribio la 2020 tulitumia utaratibu huo sawa kama mwaka jana.", 'fa': 'ما در کار ترجمه\u200cهای TED به انگلیسی End-to-End شرکت کردیم. ما راه حل خود را بر اساس تسلیم سال گذشته\u200cمان بنیاد می\u200cدهیم. ما از یک معماری تغییر تبدیل کننده کوچک استفاده کردیم با طبقه متغییر مانند ResNet برای آماده کردن ورودهای صوتی به رمندۀ تغییر دهنده. برای بهتر کردن کیفیت ترجمه مدل، دو تکنیک قانونی را معرفی کردیم و بر ماشین ترجمه شده\u200cایم Librispeech corpus در addition to iwslt-corpus, TEDLIUM2 و Must_C corpora. بهترین مدل ما تقریباً سه بلوپ بالاتر از مدل سال گذشته بود. برای برقطه آزمایش ۲۰۰۲، ما دقیقاً همان روش را با سال گذشته استفاده کردیم.', 'af': "Ons het deel in die offline End-to-End Engels na Duitse TED-leksies vertaling taak geneem. Ons gebaseer on s oplossing op ons laaste jaar se onderwerp. Ons gebruik 'n bietjie verander Transformer Arkitektuur met ResNet- like konvolusionele laag wat die oudio invoer na Transformer enkoder berei het. Om die model se kwaliteit van vertaling te verbeter, het on s twee regularisasie teknike ingevoer en op masjien vertaling Librispeech corpus in byvoeg by iwslt-corpus, TEDLIUM2 en Must_C corpora. Ons beste model het amper 3 BLES hoër as die laaste jaar se model getel. To segment 2020 test set we used exactly the same procedure as last year.", 'sq': "Ne morëm pjesë në detyrën e përkthimit të lezioneve të TED-it nga fundi në fund. Ne bazuam zgjidhjen tonë në dorëzimin tonë të vitit të kaluar. Ne përdorëm një arkitekturë pak të ndryshuar Transformer me shtresë konvolutive si ResNet duke përgatitur hyrjen audio në koduesin Transformer. Për të përmirësuar cilës in ë e përkthimit të modelit ne futëm dy teknika rregulluese dhe stërvitëm në Librispeech corpus përkthyer nga makina përveç iwslt-corpus, TEDLIUM2 dhe Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model.  Për testin e segmentit 2020 kemi përdorur saktësisht të njëjtën procedurë si vitin e kaluar.", 'tr': "Biz offline End-to-End Iňlisçe nemesçe TED sanlarynyň terjime täbligine böldik. Biz geçen ýylymyzyň teslim etmäge çözümüzü daýadyk. ResNet'e görkezilen bir şekilde üýtgeden bir Transformer arhitektegi ullandık. Ses girişini Transformer ködere taýýarlanýar. Modeliniň terjime kalitesini geliştirmek üçin biz 2 düzenlemek tekniklerini we makine terjime edilen Librispeech corpus iwslt-corpus, TEDLIUM2 we Must_C corpora dahil edildi. Biziň iň gowy nusgymyz geçen ýylyň nusgasyndan 3 BLEU köp sany boldy. 2020-nji ýyl barlamak üçin biz geçen ýyl ýaly edil bir prosedyny ulandyk.", 'am': 'ወደ አርንሳይ የመጨረሻ-ወደ-መጨረሻ እንግሊዘኛ ወደ ጀርመን ቴድ ትርጓሜዎችን ትርጉም አድራሻ ተጋርተናል፡፡ የቀድሞው ዓመታት ስልጣን ላይ መፍትረታችንን አቀረብን፡፡ የድምፅ ድምፅ አቀማመጥ ወደ ተርጓሚው ኮድ ማዘጋጀት በResNet የሚመስል አካውንት የተለወጠውን የፍጥረት መሠረት አቀራጠልን፡፡ በይslt-corpus፣ TEDLIUM2 እና ሙሉ_C ኮፖርት በቀር ሁለት የሥርዓት አስተዳደር ቴክኖቶችን እና በመሣሪያዎች ላይ የተዘጋጀን የሊብሪፓክ ኮፕስ እና የተማረርን የሞዴል ጥያቄን ለማድረግ ነው፡፡ የቀድሞው ዓመት በ3 ቢልዩን የበለጠ ሞዴል ተቃውሞ ነበር፡፡ በ2020 ፈተና ለመክፈት እንደገና ባለፈው ዓመታት አንድ ሥርዓት ተጠቃሚ ነበር፡፡', 'az': 'Biz "End-to-End" İngilizce dilində Almanca TED leksiyalarının çevirilməsinə bölüşdük. Biz s on il müs əlmanlarımızın çətinliklərinə dayandıq. Biz ResNet kimi konvolucional səviyyə ilə biraz dəyişdirilmiş Transformer arhitektarını kullandıq. Transformer kodlayıcısına audio girişini hazırlamaq üçün. Modelin tərcümünün keyfiyyətini yaxşılaşdırmaq üçün iki düzgünlük tekniklərini təyin etdik və maşına Librispeech korpusu iwslt-corpus, TEDLIUM2 və Must_C korporasını təhsil etdik. Bizim ən yaxşı modellərimiz son il modelindən az qala 3 BLEU yüksək dəyişdi. 2020-ci segment test təyin etdik ki, biz dünən il ilə həqiqətən də eyni proqramı kullandıq.', 'hy': 'Մենք մասնակցեցինք անգլերենի վերջ-վերջ անգլերենի և գերմանացի TED-ի դասընթացների թարգմանման գործին: Մենք հիմնեցինք մեր լուծումը անցյալ տարվա ներկայացման վրա: We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder.  Մոդելի թարգմանման որակը բարելավելու համար մենք ներկայացրեցինք երկու ռեգուլարիզացիոն տեխնիկա և ուսուցանում էինք մեքենայի թարգմանված գրադարձ կորպոս, ավելացնելով iսթ-կորպոս, TEDլիում2 և Մուստ_C կորպորա Մեր լավագույն մոդելը գնահատել է մոտ երեք բլեուզ ավելի բարձր, քան անցյալ տարվա մոդելը: To segment 2020 test set we used exactly the same procedure as last year.', 'ca': "Vam participar en la tasca de traducció del final al final de l'anglès a les conferències alemanes TED. Vam basar la nostra solució en la presentació de l'any passat. Vam utilitzar una arquitectura Transformer una mica canviada amb capa convolucionada com ResNet preparant l'entrada d'àudio al codificador Transformer. Per millorar la qualitat de la traducció del model vam introduir dues tècniques de regularizació i vam entrenar en Librispeech corpus traduit per màquina a més d'iwslt-corpus, TEDLIUM2 i Must_C corpora. El nostre millor model va marcar gairebé 3 BLEU més alts que el model de l'any passat. Per al conjunt de tests del segment 2020 vam utilitzar exactament el mateix procediment que l'any passat.", 'bn': 'আমরা অফ-লাইন শেষ-থেকে ইংরেজিতে জার্মান টেড ভাষণের অনুবাদ কাজে অংশ নিয়েছি। আমরা গত বছরের আত্মসমর্পণের উপর আমাদের সমাধান ভিত্তি করেছি। আমরা রেসেন্টের মতো বিশ্বাসী স্তরের সাথে একটি সামান্য পরিবর্তনের পরিবর্তন কাঠামো ব্যবহার করেছি ট্রান্সফার্নার এনকোডারে অডিও এই মডেলের অনুবাদের মান উন্নত করার জন্য আমরা দুটি নিয়ন্ত্রণ প্রযুক্তি তুলে ধরেছি এবং ইইজসল-কোর্পাস, টেডিলিউম্২ এবং মেশিন অনুবাদ করা লিব্রিস্পেচ কোর্পাসের আমাদের সর্বোচ্চ মডেল গত বছরের মডেল থেকে প্রায় ৩ বিলিউ বেশি। ২০২০ পরীক্ষা বিভাগের জন্য আমরা গত বছর পর্যন্ত একই প্রক্রিয়া ব্যবহার করেছিলাম।', 'cs': 'Zúčastnili jsme se offline překladu TED přednášek z angličtiny do němčiny End-to-End. Naše řešení jsme založili na loňském předložení. Použili jsme mírně změněnou architekturu Transformeru s konvoluční vrstvou podobnou ResNet připravující zvukový vstup do snímače Transformeru. Pro zlepšení kvality překladu modelu jsme představili dvě regularizační techniky a trénovali na strojově přeloženém korpusu Librispeech kromě korpusů iwslt-corpus, TEDLIUM2 a Must_C. Náš nejlepší model dosáhl téměř o tři BLEU vyšší než loňský model. Pro segment 2020 testovací sady jsme použili přesně stejný postup jako loni.', 'bs': 'Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Na osnovu našeg rješenja na posljednjoj godini podnošenja. Koristili smo malu izmjenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a, pripremajući audio ulaz u koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dvije regularizacijske tehnike i obučene na mašini prevedeno Librispeech corpus osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model je skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa za segment 2020, koristili smo tačno iste procedure kao i prošle godine.', 'fi': 'Osallistuimme offline End-to-End English to German TED luentojen kääntämiseen. Perustimme ratkaisumme viime vuoden toimitukseen. Käytimme hieman muunneltua Transformer-arkkitehtuuria ResNetin kaltaisella konvolutionaalisella kerroksella, joka valmisti äänituloa Transformer-kooderiin. Mallin kääntämisen laadun parantamiseksi otimme käyttöön kaksi laillistustekniikkaa ja koulutimme konekäännettyä Librispeech-korpusta iwslt-korpusen, TEDLIUM2- ja Must_C-korpusten lisäksi. Paras mallimme sai lähes 3 BLEU enemmän kuin viime vuoden malli. Segmentin 2020 testisarjaan käytimme täsmälleen samaa menettelyä kuin viime vuonna.', 'id': 'Kami mengambil bagian dalam tugas terjemahan dari Bahasa Inggris akhir ke akhir ke kursus TED Jerman. Kami mendasarkan solusi kami pada penyerahan tahun lalu kami. Kami menggunakan arsitektur Transformer yang sedikit berubah dengan lapisan konvolusi seperti ResNet mempersiapkan input audio ke pengekode Transformer. Untuk meningkatkan kualitas terjemahan model kami memperkenalkan dua teknik regularisasi dan dilatih di mesin terjemahan Librispeech corpus tambah iwslt-corpus, TEDLIUM2 dan Must_C corpora. Model terbaik kami skor hampir 3 BLEU lebih tinggi dari model tahun lalu. Untuk set tes segmen 2020 kami menggunakan prosedur yang sama seperti tahun lalu.', 'et': 'Osalesime võrguühenduseta inglise keele-saksa TED loengute tõlkimise ülesandes. Me põhinesime oma lahendusel eelmisel aastal esitatud pakkumisel. Kasutasime veidi muudetud Transformeri arhitektuuri ResNeti sarnase konvolutsioonikihiga, mis valmistas helisisendi Transformeri kodeerijaks ette. Mudeli tõlkekvaliteedi parandamiseks tutvustasime lisaks iwslt-korpusele, TEDLIUM2 ja Must_C korpusele ka masintõlgitud Librispeech korpusega. Meie parim mudel sai peaaegu 3 BLEU kõrgema kui eelmisel aastal. Segmendi 2020 testikomplekti jaoks kasutasime täpselt sama protseduuri kui eelmisel aastal.', 'ha': "@ info: whatsthis Mun ƙaddara suluyinmu a kan Musuluncin shekara ta shida. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder.  To improve tsarin motel'in fassarar, we introduce technical biyu masu tsaro kuma an sanar da shi a kan mashine ta fassar Librispech Cornas, addition to iwslt-Corbas, TeDLIUM2 and Must_C Corpo. Babu misalinmu na ƙari takin BLEU ya fi girma daga misalin shekara ta shida. Ga rabin jarrabi 2020, mun yi amfani da daidai jarrabo kamar shekara ta shida.", 'sk': 'Sodelovali smo pri prevajanju TED predavanj iz angleščine do nemščine brez povezave. Našo rešitev smo temeljili na lanskem predložitvi. Uporabili smo rahlo spremenjeno arhitekturo transformatorjev s konvolucijskim slojem, podobnim ResNetu, ki je pripravil avdio vhod v kodirnik transformatorjev. Za izboljšanje kakovosti prevajanja modela smo poleg iwslt-korpusa, TEDLIUM2 in Must_C korpusa uvedli dve tehniki regularizacije in usposabljali strojno prevedenega Librispeech korpusa. Naš najboljši model je ocenil skoraj 3 BLEU višje od lanskega modela. Za segment test set 2020 smo uporabili popolnoma enak postopek kot lani.', 'jv': 'Awak dh챕w챕 wis ak챔h n챗m챗n ning "End-to-End" -Inggris kanggo nganggo barang alaman kanggo tarjamahan "Tom". Awakdh챕w챕 ngerti perusahaan dh챕w챕 nang kana dh챕w챕 We used a little change Transformer architecture with Resnet-like convolution layer Reading the sound input to Transformer koder. Mbak penting nggawe kalitas model kebebasan itoleh dumadhi, awak dh챕w챕 ngerasai t챕kno sing berarti ujak karo perusahaan dibutuhke "Library" sing berarti itoleh bantuan, lan ujak-ujak i "Iwakken telu" lan "Must_C" Rasan챕 sing paling dh챕w챕, ditambah sing kator 3 BEL kuwi model sing paling tau. Genjer-genjer saiki gerang t챔st 2020 sampeyan, kita ngaweh penggunan ngono cah-cah dumadhi tau.', 'bo': 'ང་ཚོས་དྲ་རྒྱའི་ནང་དུ་End-to-End དབྱིན་ཡིག ང་ཚོས་རྗེས་མའི་ལོ་ངོ་མའི་བསམ་བློ་གཏོང་བའི་ཐབས་ཤེས་དེ་གཞི་རྟེན་བྱེད་ཀྱི་ཡོད། We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. ང་ཚོའི་མ་དབྱིབས་གྱི་དཔེ་དབྱིབས་ལ་སྒྲིག་འགོད་ཀྱི་རིམ་པ་སྒྲིག ང་ཚོའི་མ་དབྱིབས་འདས་པའི་ལོ་རྣམ་གྲངས་སྔོན་གྱི་མ་དབྱིབས་ཉུང་བའི་ཚད་ལྡན་གྲངས་ཀ་འདི་ཉེ་བར་གསུ ལོ་གྲངས་སྔོན་2020་ཡི་བརྟག་ཞིབ་ཚད་ལ་རྗེས་སུ་ང་ཚོས་དུས་མཐུན་གྱི་ཐབས་ལམ་ལ་མཚུངས་པ་ཡིན།', 'he': 'השתתפנו בתפקיד התרגום של "סוף עד סוף" לאנגלית לרצאות TED הגרמניות. הבססנו את הפתרון שלנו על ההכנעה שלנו בשנה שעברה. השתמשנו בארכיטקטורה מעט משתנה עם שכבה משתנה דומה לרסנט שמכינה את הכניסה של הקולנוע לקודר. כדי לשפר את איכות התרגום של המודל הכרנו שתי טכניקות רגילות ואימנו על מכונת התרגם Librispeech corpus בנוסף ל iwslt-corpus, TEDLIUM2 ו Must_C corpora. המודל הטוב ביותר שלנו קיבל כמעט 3 BLEU גבוה יותר מהמודל של שנה שעברה. To segment 2020 test set we used exactly the same procedure as last year.'}
{'en': 'The University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task', 'ar': 'تقديم جامعة هلسنكي إلى مهمة IWSLT2020 Offline SpeechTranslation', 'pt': 'Apresentação da Universidade de Helsinque para a Tarefa de Tradução de Fala Offline IWSLT2020', 'es': 'Presentación de la Universidad de Helsinki a la tarea de traducción de voz fuera de línea IWSLT2020', 'fr': "Soumission de l'Université d'Helsinki à la tâche de traduction vocale hors ligne IWSLT2020", 'ja': 'IWSLT 2020オフラインスピーチ翻訳タスクへのヘルシンキ大学の提出', 'zh': '赫尔辛基大学为 IWSLT2020 离线音译', 'ru': 'Заявка Хельсинкского университета на участие в задаче офлайн-перевода речи IWSLT2020', 'hi': 'IWSLT2020 ऑफ़लाइन SpeechTranslation कार्य के लिए हेलसिंकी प्रस्तुत विश्वविद्यालय', 'ga': 'Ollscoil Heilsincí Aighneacht chuig Tasc Aistriúcháin Óráid As Líne IWSLT2020', 'hu': 'A Helsinki Egyetem benyújtása az IWSLT2020 Offline SpeechTranslation Task részére', 'ka': 'ჰელსინკის სუნივერსი სამუშაო IWSLT2020-ის გარეშე საუბრო საუბრო', 'it': "La presentazione dell'Università di Helsinki al compito Offline SpeechTranslation di IWSLT2020", 'lt': 'Helsinkio universitetas pristato užduotį „IWSLT2020“ ne interneto kalbų vertimo darbui', 'kk': 'Хельсинки университетінің IWSLT2020 сыртқы сөздерді аудару тапсырмасы', 'el': 'Υποβολή του Πανεπιστημίου του Ελσίνκι στο έργο μετάφρασης ομιλίας χωρίς σύνδεση', 'ml': 'Translation Task', 'ms': 'Submission University of Helsinki to the IWSLT2020 Offline SpeechTranslation Task', 'mn': 'Хельсинкийн Их Сургууль IWSLT2020 онлайн ярианы хөгжлийн ажил', 'no': 'University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task', 'pl': 'Zgłoszenie przez Uniwersytet Helsiński do IWSLT2020 Offline SpeechTranslation Task', 'mk': 'The University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task', 'ro': 'Depunerea Universității din Helsinki la misiunea IWSLT2020 Offline SpeechTranslation', 'si': 'හෙල්සින්කි විශ්වාසිත්තාව IWSLT202 අෆ්ලායින් වාර්තාවන් වැඩක්', 'mt': 'Is-Sottomissjoni tal-Università ta’ Ħelsinki għall-Kompitu ta’ Traduzzjoni Speech Offline tal-IWSLT2020', 'so': 'Maamulka jaamacadda Helsinki ee IWSLT2020 Offline SpeechTranslation Task', 'ta': 'IWSLT2020 ஆஃப்லைன் பேச்சு மொழிபெயர்ப்புTranslation Task', 'sr': 'Univerzitet Helsinki podmisija na zadatak IWSLT2020 Offline SpeechTranslation Task', 'ur': 'Helsinki University of Submission to the IWSLT2020 Offline SpeechTranslation Task', 'sv': 'Helsingfors universitet Bidrag till IWSLT2020 Offline SpeechĂ–versĂ¤ttningsuppgift', 'uz': 'Translation Task', 'vi': 'Đệ Nhất của Helsinki... Phục vụ cho tổ chức IWmảnh-2... Tác phẩm thuyết giáo.', 'bg': 'Предложение на Университета в Хелзинки за задачата за превод на офлайн речи', 'nl': 'De Universiteit van Helsinki inzending aan de IWSLT2020 Offline SpeechTranslation Task', 'da': 'University of Helsinki Indsendelse til IWSLT2020 Offline SpeechTranslation Opgave', 'hr': 'Univerzitet Helsinki podmission na zadatak IWSLT2020 Offline SpeechTranslation', 'de': 'Einreichung der Universität Helsinki beim IWSLT2020 Offline SpeechTranslation Task', 'fa': 'دانشگاه هلسینکی به وظیفه\u200cی گفتگوی بیرون\u200cخط IWSLT2020', 'sw': 'The University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task', 'ko': '헬싱키 대학, IWSLT2020 오프라인 강연 통역 임무 제출', 'tr': 'Helsinki Uniwersitetiň IWSLT2020-nyň offline söz bellenişi', 'id': 'University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task', 'af': 'Die Universiteit van Helsinki Submission na die IWSLT2020 Aflyn Spraak Taak', 'sq': 'Përdorimi i Universitetit të Helsinkit në detyrën IWSLT2020 Offline SpeechTranslation', 'am': 'Translation Task', 'hy': 'Հելսինկի համալսարանը ներկայացնում է IwSLT2020-ի անլայն խոսքի թարգմանման խնդիրը', 'az': 'Helsinki Üniversitesi IWSLT2020 Offline Speech Taski', 'bn': 'বিশ্ববিদ্যালয়ের হেলসিঙ্কি সাবমিশন IWSLT2020 অফ-লাইন বক্তব্যের কাজ', 'bs': 'Univerzitet Helsinki podmission na zadatak IWSLT2020 Offline SpeechTranslation Task', 'cs': 'Univerzita v Helsinkách Předložení IWSLT2020 Offline projevůPřeklad úkolu', 'et': 'Helsingi Ülikooli avaldus IWSLT2020 Offline SpeechTranslation Task', 'fi': 'Helsingin yliopiston hakemus IWSLT2020 Offline SpeechTranslation Task -ohjelmaan', 'ca': 'La Submissió de la Universitat de Helsinki a la tasca IWSLT2020 Offline SpeechTranslation', 'jv': 'Submisi Universite de helsinaki kanggo kelas IWSLT2020 Walian Perancis', 'ha': 'Translate Tasks', 'bo': 'IWSLT2020 དྲ་བ་ནས་ཡོད་པའི་སྐད་ཡིག་ཆ་ལོག་བློ་གཏད་ཀྱི་ལས་འགུལ་ལ།', 'sk': 'Prijava Univerze v Helsinkih na nalogo IWSLT2020 Offline SpeechTranslation', 'he': 'אוניברסיטת הלסינקי הועברה למשימה של IWSLT2020 Offline SpeechTranslation'}
{'en': 'This paper describes the University of Helsinki Language Technology group’s participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text. In line with this year’s task objective, we train both cascade and end-to-end systems for spoken language translation. We opt for an end-to-end multitasking architecture with shared internal representations and a cascade approach that follows a standard procedure consisting of ASR, correction, and MT stages. We also describe the experiments that served as a basis for the submitted systems. Our experiments reveal that multitasking training with shared internal representations is not only possible but allows for knowledge-transfer across modalities.', 'ar': 'تصف هذه الورقة مشاركة مجموعة تكنولوجيا اللغة بجامعة هلسنكي في مهمة ترجمة الكلام دون اتصال بالإنترنت IWSLT 2020 ، وتتناول ترجمة الصوت الإنجليزي إلى نص ألماني. تماشياً مع هدف مهمة هذا العام ، نقوم بتدريب كل من الأنظمة المتتالية والشاملة لترجمة اللغة المنطوقة. نختار بنية متعددة المهام من طرف إلى طرف مع تمثيلات داخلية مشتركة ونهج تسلسلي يتبع إجراءً قياسيًا يتكون من ASR والتصحيح ومراحل MT. نصف أيضًا التجارب التي كانت بمثابة أساس للأنظمة المرسلة. تكشف تجاربنا أن التدريب على المهام المتعددة مع التمثيلات الداخلية المشتركة ليس ممكنًا فحسب ، بل يسمح بنقل المعرفة عبر الأساليب.', 'pt': 'Este artigo descreve a participação do grupo de Tecnologia da Linguagem da Universidade de Helsinque na tarefa de tradução de fala offline do IWSLT 2020, abordando a tradução de áudio em inglês para texto em alemão. De acordo com o objetivo da tarefa deste ano, treinamos sistemas em cascata e de ponta a ponta para tradução de idiomas falados. Optamos por uma arquitetura multitarefa de ponta a ponta com representações internas compartilhadas e uma abordagem em cascata que segue um procedimento padrão composto por estágios ASR, correção e MT. Também descrevemos os experimentos que serviram de base para os sistemas apresentados. Nossos experimentos revelam que o treinamento multitarefa com representações internas compartilhadas não é apenas possível, mas permite a transferência de conhecimento entre as modalidades.', 'es': 'Este artículo describe la participación del grupo de Tecnología del Lenguaje de la Universidad de Helsinki en la tarea de traducción de voz fuera de línea IWSLT 2020, que aborda la traducción de audio en inglés a texto alemán. De acuerdo con el objetivo de la tarea de este año, capacitamos sistemas en cascada y de principio a fin para la traducción del idioma hablado. Optamos por una arquitectura multitarea de extremo a extremo con representaciones internas compartidas y un enfoque en cascada que sigue un procedimiento estándar que consiste en etapas de ASR, corrección y MT. También describimos los experimentos que sirvieron de base para los sistemas presentados. Nuestros experimentos revelan que la capacitación multitarea con representaciones internas compartidas no solo es posible, sino que permite la transferencia de conocimientos entre modalidades.', 'fr': "Cet article décrit la participation du groupe de technologie linguistique de l'Université d'Helsinki à la tâche de traduction vocale hors ligne IWSLT 2020, portant sur la traduction de l'audio anglais en texte allemand. Conformément à l'objectif de la tâche de cette année, nous formons des systèmes en cascade et de bout en bout pour la traduction en langue parlée. Nous optons pour une architecture multitâche de bout en bout avec des représentations internes partagées et une approche en cascade qui suit une procédure standard comprenant des étapes ASR, correction et TA. Nous décrivons également les expériences qui ont servi de base aux systèmes soumis. Nos expériences révèlent que la formation multitâche avec des représentations internes partagées est non seulement possible mais permet également le transfert de connaissances entre les différentes modalités.", 'ja': '本稿では、ヘルシンキ大学言語技術グループがIWSLT 2020オフライン音声翻訳タスクに参加し、英語音声のドイツ語テキストへの翻訳に取り組んでいることについて説明します。今年のタスク目標に沿って、口語翻訳のためのカスケードとエンドツーエンドの両方のシステムをトレーニングしています。私たちは、内部表現を共有するエンドツーエンドのマルチタスクアーキテクチャと、ASR、修正、およびMT段階からなる標準的な手順に従うカスケードアプローチを選択します。提出されたシステムの基礎となった実験についても述べる。私たちの実験は、内部表現を共有するマルチタスクトレーニングが可能であるだけでなく、さまざまな方法で知識を伝達することができることを明らかにしています。', 'zh': '本文引赫尔辛基大学语术小组参 IWSLT 2020 离线音译,决英语音频翻译成德语文本。 以今年之事,习于口译之级联,与端到端系统。 择有共内之端到端多任务处理架构,循 ASR、校 MT 之级联法。 又述系统之实验。 臣等实验明,有共享内表多任务训练不惟可也,且许跨模态之知移。', 'hi': 'यह पेपर आईडब्ल्यूएसएलटी 2020 ऑफ़लाइन भाषण अनुवाद कार्य में हेलसिंकी भाषा प्रौद्योगिकी समूह की भागीदारी का वर्णन करता है, जो जर्मन पाठ में अंग्रेजी ऑडियो के अनुवाद को संबोधित करता है। इस वर्ष के कार्य उद्देश्य के अनुरूप, हम बोली जाने वाली भाषा अनुवाद के लिए कैस्केड और एंड-टू-एंड सिस्टम दोनों को प्रशिक्षित करते हैं। हम साझा आंतरिक अभ्यावेदन और एक कैस्केड दृष्टिकोण के साथ एक एंड-टू-एंड मल्टीटास्किंग आर्किटेक्चर का विकल्प चुनते हैं जो एएसआर, सुधार और एमटी चरणों से मिलकर एक मानक प्रक्रिया का पालन करता है। हम उन प्रयोगों का भी वर्णन करते हैं जो प्रस्तुत प्रणालियों के लिए एक आधार के रूप में कार्य करते हैं। हमारे प्रयोगों से पता चलता है कि साझा आंतरिक अभ्यावेदन के साथ मल्टीटास्किंग प्रशिक्षण न केवल संभव है, बल्कि तौर-तरीकों में ज्ञान-हस्तांतरण की अनुमति देता है।', 'ru': 'В этой статье описывается участие группы языковых технологий Университета Хельсинки в задаче офлайн-перевода речи IWSLT 2020, посвященной переводу английского аудио на немецкий текст. В соответствии с задачей этого года, мы обучаем как каскадные, так и сквозные системы для перевода разговорного языка. Мы выбираем сквозную многозадачную архитектуру с общими внутренними представлениями и каскадным подходом, который следует стандартной процедуре, состоящей из этапов ASR, коррекции и MT. Описаны также эксперименты, послужившие основой для представленных систем. Наши эксперименты показывают, что многозадачное обучение с общими внутренними представлениями не только возможно, но и позволяет передавать знания по всем формам.', 'ga': 'Déanann an páipéar seo cur síos ar rannpháirtíocht ghrúpa Teicneolaíochta Teanga Ollscoil Heilsincí i dtasc aistriúcháin cainte as líne IWSLT 2020, ag tabhairt aghaidh ar aistriú fuaime Béarla go téacs Gearmáinise. Ag teacht le tascchuspóir na bliana seo, cuirimid oiliúint ar chórais cascáideacha agus ceann go ceann le haghaidh aistriúchán teanga labhartha. Roghnaímid ailtireacht iltascála ceann go ceann le huiríll inmheánacha roinnte agus cur chuige easghluaiseachta a leanann nós imeachta caighdeánach comhdhéanta de chéimeanna ASR, ceartúcháin agus MT. Déanaimid cur síos freisin ar na turgnaimh a bhí mar bhonn do na córais a cuireadh isteach. Nochtann ár dturgnaimh go bhfuil oiliúint ilchascála le huiríll inmheánacha roinnte indéanta ní amháin ach go gceadaíonn sé aistriú eolais trasna módúlachtaí.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή της ομάδας γλωσσικής τεχνολογίας του Πανεπιστημίου του Ελσίνκι στο έργο μετάφρασης ομιλίας εκτός σύνδεσης, με στόχο τη μετάφραση του αγγλικού ήχου σε γερμανικό κείμενο. Σύμφωνα με τον φετινό στόχο εργασίας, εκπαιδεύουμε τόσο συστήματα καταρράκτων όσο και ολοκληρωμένα για τη μετάφραση προφορικής γλώσσας. Επιλέγουμε μια ολοκληρωμένη αρχιτεκτονική πολλαπλών εργασιών με κοινές εσωτερικές αναπαραστάσεις και μια προσέγγιση που ακολουθεί μια τυποποιημένη διαδικασία που αποτελείται από στάδια διόρθωσης, διόρθωσης και ΜΤ. Περιγράφουμε επίσης τα πειράματα που χρησιμοποίησαν ως βάση για τα υποβαλλόμενα συστήματα. Τα πειράματά μας αποκαλύπτουν ότι η εκπαίδευση πολλαπλών εργασιών με κοινές εσωτερικές αναπαραστάσεις δεν είναι μόνο δυνατή, αλλά επιτρέπει τη μεταφορά γνώσης μεταξύ των μορφών.', 'hu': 'Ez a tanulmány bemutatja a Helsinki Egyetem Nyelvtechnológiai Csoportjának részvételét az IWSLT 2020 offline beszédfordítási feladatban, amely az angol hang német szövegre történő fordításával foglalkozik. Az idei feladatcélkitűzésnek megfelelően a beszélt nyelvű fordításra vonatkozó kaszkád- és end-to-end rendszereket is képzünk. Olyan end-to-end multitasking architektúrát választunk, amely megosztott belső reprezentációkkal és kaszkád megközelítéssel rendelkezik, amely az ASR, a korrekció és az MT szakaszokból álló standard eljárást követi. Leírjuk azokat a kísérleteket is, amelyek a benyújtott rendszerek alapjául szolgáltak. Kísérleteink azt mutatják, hogy a közös belső reprezentációkkal ellátott multitasking tréning nemcsak lehetséges, hanem lehetővé teszi a tudás átadását a módszerek között.', 'ka': 'ამ წიგნის განახსოვრება ჰელსინკის ენის ტექნოლოგიის სამუშაო გუნივერტის გადაწყვეტილება IWSLT 2020-ში, რომელიც სამუშაო სიტყვების გადაწყვეტილება და ინგლისური ауდიოს ამ წლის სამუშაო მიზეზი მიზეზით, ჩვენ კაკადის და საკუთარი სისტემების გადაწყვეტის სისტემების გადაწყვეტის მიზეზით. ჩვენ მონიშნეთ მულტი რაქტიკური აქტიქტიკური გადასრულებას, რომელიც გადასრულებული ინტერესტიკური გამოსახულებებით და კასკადის გადასრულებას, რომელიც სტანდარტული პროცექტის შემდეგ ჩვენ ასევე აღწერეთ ექსპერიმენტები, რომლებიც იმუშაობენ სისტემისთვის ბაზი. ჩვენი ექსპერიმენტები აღმოჩნენ, რომ მრავალტუქციების განაკეთება საერთო ინტერესტრაციებით არა მხოლოდ შესაძლებელია, მაგრამ შესაძლებელია ცნობიერ', 'kk': 'Бұл қағаз Helsinki тіл технологиялық тобының университетінің IWSLT 2020 жылы онлайн сөздердің аудармалы тапсырмасына қатысуын, ағылшын аудио аудармаларын неміс мәтініне аудару үшін таңдайды Бұл жылдың тапсырманың мақсатына сәйкес келгенде, біз сөйлейтін тілдерді аудару үшін каскад мен аяқтау жүйелерін үйренеміз. Біз бірнеше тапсырманың соңындағы көп тапсырмалар архитектурасын ортақтастырып, ішкі түрінде ортақтастырылған, және ASR, түзету және MT қадамдарының стандартты процедурына келеді. Біз сондай-ақ жүйелердің негізгі тәжірибелерін таңдаймыз. Біздің тәжірибеміз бірнеше тапсырмаларды ортақ ішкі тапсырмалардың оқытуы мүмкін емес, бірақ білім беру үшін көп тапсырмаларды өзгертуге мүмкін.', 'it': "Questo articolo descrive la partecipazione del gruppo University of Helsinki Language Technology al compito di traduzione vocale offline IWSLT 2020, affrontando la traduzione dell'audio inglese in testo tedesco. In linea con l'obiettivo di quest'anno, addestriamo sistemi a cascata e end-to-end per la traduzione della lingua parlata. Optiamo per un'architettura multitasking end-to-end con rappresentazioni interne condivise e un approccio a cascata che segue una procedura standard composta da fasi ASR, correzione e MT. Descriviamo anche gli esperimenti che hanno servito come base per i sistemi presentati. I nostri esperimenti rivelano che la formazione multitasking con rappresentazioni interne condivise non solo è possibile, ma consente il trasferimento di conoscenze attraverso modalità.", 'ml': 'ഈ പത്രത്തില്\u200d ഹെല്\u200dസിങ്കി ഭാഷ ടെക്നോളജി ഗ്രൂപ്പിന്റെ പങ്കെടുക്കുന്നതിനെ വിവരിച്ചുകൊടുക്കുന്നു. ഇംഗ്ലീഷ് ഓഡിയോയിയുടെ പരി ഈ വര്\u200dഷത്തിന്റെ ജോലിയുടെ ലക്ഷ്യം കൊണ്ട്, സംസാരിക്കുന്ന ഭാഷ പരിഭാഷയ്ക്കുള്ള കാസ്കേഡും അവസാന സിസ്റ്റം വേണ അവസാനം അവസാനിപ്പിക്കുന്നതിനായി നമ്മള്\u200d പ്രതിനിധികളോടൊപ്പം പങ്കെടുത്ത അകത്തുള്ള പ്രതിനിധികളോടൊപ്പം പല്ലിത്തിരിക്കുന്ന സ്ഥാനം തെ സിസ്റ്റത്തിന്റെ അടിസ്ഥാനമായി സേവിച്ച പരീക്ഷണങ്ങളെപ്പറ്റി ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. നമ്മുടെ പരീക്ഷണങ്ങള്\u200d വെളിപ്പെടുത്തുന്നു, പങ്കുചേര്\u200dത്തിരിക്കുന്ന ആന്തരീക പ്രതിനിധികളോടൊപ്പം പങ്കുചേര്\u200d', 'mk': "This paper describes the University of Helsinki Language Technology group's participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text.  In line with this year's task objective, we train both cascade and end-to-end systems for spoken language translation.  We opt for an end-to-end multitasking architecture with shared internal representations and a cascade approach that follows a standard procedure consisting of ASR, correction, and MT stages.  We also describe the experiments that served as a basis for the submitted systems.  Нашите експерименти откриваат дека мултизадачна обука со заеднички внатрешни претставувања не е само можна, туку и овозможува трансфер на знаење преку модијалитети.", 'ms': "Kertas ini menggambarkan kelompok Teknologi Bahasa Universiti Helsinki berpartisipasi dalam tugas terjemahan ucapan luar talian IWSLT 2020, mengarahkan terjemahan audio Inggeris ke teks Jerman. In line with this year's task objective, we train both cascade and end-to-end systems for spoken language translation.  Kami memilih arkitektur multitugas akhir-akhir dengan perwakilan dalaman berkongsi dan pendekatan kaskad yang mengikut prosedur piawai yang terdiri dari ASR, pembetulan, dan tahap MT. We also describe the experiments that served as a basis for the submitted systems.  Our experiments reveal that multitasking training with shared internal representations is not only possible but allows for knowledge-transfer across modalities.", 'lt': 'Šiame dokumente aprašomas Helsinkio universiteto kalbos technologijų grupės dalyvavimas užduotyje „IWSLT 2020“ išversti kalbas be interneto, kurioje kalbama apie anglų garso vertimą į vokiečių tekstą. Atsižvelgdami į šių metų uždavinių tikslą, rengiame kaskadines ir pabaigos kalbos vertimo sistemas. Mes pasirinkiame įvairių užduočių tarpusavio architektūrą su bendrais vidiniais atstovais ir kaskadinį požiūrį, kuris būtų vykdomas pagal standartinę procedūrą, kurią sudaro ASR, koregavimo ir MT etapai. Taip pat apibūdiname eksperimentus, kurie buvo pateiktų sistemų pagrindas. Mūsų eksperimentai atskleidžia, kad mokymas įvairiomis užduotimis su bendra vidaus atstovavimu yra ne tik įmanomas, bet ir leidžia keistis žiniomis įvairiomis priemonėmis.', 'pl': 'Niniejszy artykuł opisuje udział grupy Uniwersytetu Helsińskiego w zadaniu tłumaczenia mowy offline IWSLT 2020, zajmującym się tłumaczeniem angielskiego dźwięku na tekst niemiecki. Zgodnie z tegorocznym celem zadania szkolimy zarówno systemy kaskadowe, jak i kompleksowe do tłumaczenia języka mówionego. Wybieramy kompleksową architekturę wielozadaniową ze wspólnymi wewnętrznymi reprezentacjami i podejściem kaskadowym, które stosuje standardową procedurę składającą się z etapów ASR, korekcji i MT. Opisujemy również eksperymenty, które służyły jako podstawa dla przesłanych systemów. Nasze eksperymenty ujawniają, że szkolenie wielozadaniowe ze wspólnymi reprezentacjami wewnętrznymi jest nie tylko możliwe, ale pozwala na transfer wiedzy między modalnościami.', 'mt': "This paper describes the University of Helsinki Language Technology group's participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text.  In line with this year's task objective, we train both cascade and end-to-end systems for spoken language translation.  Aħżel arkitettura multikompiti minn tarf sa tarf b’rappreżentazzjonijiet interni kondiviżi u approċċ kaskat li jsegwi proċedura standard li tikkonsisti minn stadji ASR, korrezzjoni, u MT. We also describe the experiments that served as a basis for the submitted systems.  Our experiments reveal that multitasking training with shared internal representations is not only possible but allows for knowledge-transfer across modalities.", 'ro': 'Această lucrare descrie participarea grupului de tehnologie lingvistică al Universității din Helsinki la sarcina de traducere offline a vorbirii IWSLT 2020, abordând traducerea audio engleză în text german. În conformitate cu obiectivul de sarcină din acest an, instruim atât sisteme cascade, cât și sisteme end-to-end pentru traducerea limbii vorbite. Optăm pentru o arhitectură multitasking end-to-end cu reprezentări interne partajate și o abordare în cascadă care urmează o procedură standard constând în etape ASR, corecție și MT. De asemenea, descriem experimentele care au servit ca bază pentru sistemele depuse. Experimentele noastre arată că instruirea multitasking cu reprezentări interne comune nu este doar posibilă, ci permite transferul de cunoștințe între modalități.', 'mn': 'Энэ цаас Хельсинки хэлний технологийн сургуулиудын IWSLT 2020 оны илтгэл хөрөнгө хөрөнгө оруулах ажил дээр оролцож, Англи хэлний аудио хэлний Германы текст руу оролцож байна. Энэ жилийн ажлын зорилго дээр бид хэлний хөрөнгө оруулахын тулд каскад болон төгсгөл системийг суралцах болно. Бид олон үйл ажиллагааны төгсгөлийн архитектурыг хуваалцах дотоод харилцааны төгсгөлийн архитектур болон ASR, засах, MT хэмжээний стандарт процедурыг дагах каскад архитектурыг сонгосон. Мөн бид дамжуулагдсан системийн үндсэн туршилтуудыг тайлбарладаг. Бидний туршилтууд олон ажлын дасгал хөдөлгөөн нь зөвхөн боломжгүй гэдгийг харуулдаг. Мэдлэг болон мэдлэг дасгал хөдөлгөөнийг арга хэмжээнд хүргэж чадна.', 'so': 'Warqadan waxaa ku qoran qayb ka mid ah kooxda Teknolojiga Luqada Helsinki ee IWSLT 2020, oo ku qoran turjumista afka Ingiriiska ee Jarmalka. Ugu sameynayo dhamaadka arimaha shaqada sanadkan, waxaynu ku tababarinnaa nidaamka cascade iyo dhammaadka ugu dambeeya si loo turjumo luqada lagu hadlo. Waxaynu u dooranaynaa dhismo badan oo ku saabsan wadajirka gudaha ah iyo qaab kaskad ah oo ku socda xiliga caadiga ah oo ka mid ah ASR, hagaajinta, iyo MT fasalka. Sidoo kale waxaynu u qornaa imtixaanka lagu sameeyo nidaamka la soo dhiibay. Imtixaanadayada ayaa muuqanaya in waxbarasho badan oo la xiriiray noocyada internetka oo kala duduwan ma suurtowdo oo kaliya, laakiin waxaa suurtagal in aqoonta loo wareejiyo qaabab kala duduwan.', 'si': 'මේ පැත්තේ හෙල්සින්කි භාෂාවිද්\u200dයාලයේ විශ්වාසික විශ්වාසයේ භාෂාවිද්\u200dයාලයේ කණ්ඩායම IWSLT 202 වෙනුවෙන් කිරීම මේ අවුරුද්දේ වැඩේ අරමුණ සමග, අපි කැස්කේඩ් සහ අන්තිම පද්ධතියට කතා කරනවා භාෂාව අවරංචාවට. අපි අවසානයෙන් ඉවරයි අවසානයෙන් ඉවරයි ගොඩක් වැඩි වැඩි වැඩි විද්\u200dයාපෘතියක් තෝරාගන්නේ අන්තිම අංශ්\u200dය ස්ථානය සහ කැස්කේ අපි පරීක්ෂණය විස්තර කරන්නේ පුළුවන් පද්ධතියට පරීක්ෂණයක් විදියට. අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් වෙනවා කියලා විශේෂ ක්\u200dරියාකාරීය සාමාන්\u200dය ඇතුළු ප්\u200dරතිචාරයක් සමග වි', 'no': 'Denne papiret beskriver deltakaren av Universiteten av Helsinki Språk Teknologi i IWSLT 2020 fråkopla taleomsetjinga, og adresserer omsetjinga av engelsk lyd til tysk tekst. I tillegg til oppgåvemålet i denne året treng vi både kaskade og sluttsystem for språket omsetjing. Vi veljer ein fleire oppgåver- arkitektur med delte interne representasjonar og ein kaskadtilnærming som følgjer ein standard prosedyr som inneheld ASR, korrigering og MT- stader. Vi beskriver også eksperimentene som kalla som grunnlag for dei sendte systema. Eksperimentane våre viser at fleire oppgåver trening med delte interne representasjonar er ikkje berre mulig, men tillater kunnskap-overføring over modular.', 'sv': 'Denna uppsats beskriver Helsingfors universitets språkteknikgrupps deltagande i IWSLT 2020 offline talöversättning, som behandlar översättning av engelskt ljud till tysk text. I linje med årets uppgiftsmål utbildar vi både kaskadsystem och heltäckande system för språköversättning. Vi väljer en end-to-end multitasking arkitektur med delade interna representationer och en kaskadmetod som följer ett standardförfarande bestående av ASR, korrigering och MT steg. Vi beskriver också de experiment som fungerade som grund för de inlämnade systemen. Våra experiment visar att multitasking träning med delade interna representationer inte bara är möjligt utan möjliggör kunskapsöverföring över olika modaliteter.', 'sr': 'Ovaj papir opisuje sudjelovanje Univerziteta Helsinkijske jezičke tehnologije u zadatku IWSLT 2020 za offline govorni prevod, s obzirom na prevod engleskog zvuka na njemački tekst. U skladu sa zadatkom ove godine, treniramo i kaskadne i konačne sisteme za prevod govornog jezika. Izabrali smo multitasking arhitekturu sa zajedničkim unutrašnjim predstavljanjima i pristupom kaskade koji prati standardnu proceduru koja se sastoji od ASR, korekcije i MT faza. Takoðe opisujemo eksperimente koji su služili kao osnovu predanih sustava. Naši eksperimenti otkrivaju da multitasking obuka sa zajedničkim unutrašnjim predstavljanjima nije samo moguća, nego omogućava da prebacimo znanje u međuvremenu.', 'ta': "This paper describes the University of Helsinki Language Technology group's participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text.  இந்த வரிசையில் இந்த வரிசையில் பேசும் மொழிமொழிபெயர்ப்பிற்கான காஸ்கேட் மற்றும் முடிவு அமைப்புகளை பயிற்சி  நாம் முடிவில் முடிவில் பெரிய பல்தலைப்பு உருவாக்கியத்தை தேர்ந்தெடுக்கிறோம் பங்கிடப்பட்ட உள்ளார்ந்த குறிப்புகளுடன் மற்றும் காஸ்கேட நாம் கொடுக்கப்பட்ட கணினிகளுக்கு அடிப்படையாக சேவைத்த சோதனைகளை விவரிக்கிறோம். எங்கள் பரிசோதனைகள் பங்கிடப்பட்ட உள்ளார்ந்த பங்கிட்ட பயிற்சி மட்டுமே சாத்தியமானது என்பதை குறிப்பிடுகிறது ஆனால் அறி", 'ur': "This paper describes the University of Helsinki Language Technology group's participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text. اس سال کے تابع موضوع کے ساتھ ہم کاسکے اور آخر و آخر سیستموں کو زبان کی ترجمہ کے لئے آموزش دیتے ہیں۔ ہم نے ایک مثال آخر تک متلوٹ ٹاکسینگ معماری کے لئے انتخاب کیا ہے جو مشترک داخلی نمونات کے ساتھ ہے اور ایک کاسکے طریقہ کے ساتھ ہے جو ASR، اصلاح اور MT مرحلے کے ساتھ ایک استاندارڈ پردازش کے پیچھے چلتی ہے. ہم نے بھی ان تجربیات کی توصیف کرتی ہیں جن کو مستقیم سیستموں کے لئے بنیاد بنایا تھا۔ ہماری آزمائش ظاہر کرتی ہے کہ مشترک داخلی نمونات کے ساتھ ملتی تاسکینگ کی آموزش صرف ممکن نہیں ہے بلکہ علم-Transfer کی اجازت دیتی ہے", 'vi': 'Bài viết này mô tả s ự tham gia của Hội đồng Công nghệ Ngôn ngữ Helsinki... Trong nhiệm vụ dịch chuyển thuyết ngoài dòng I.WSLT 2020... nhằm giải quyết việc dịch âm thanh tiếng Anh thành văn bản Đức. Theo mục tiêu nhiệm vụ của năm nay, chúng tôi huấn luyện cả hai hệ thống dây chuyền và kết thúc để dịch ngôn ngữ ngôn ngữ. Chúng tôi chọn một kiến trúc đa nhiệm cuối cùng cùng với các biểu đồ nội bộ chia sẻ và một phương pháp ha-đoàn theo một thủ tục tiêu chuẩn gồm các giai đoạn ASR, sửa chữa và MTV. Chúng tôi cũng mô tả các thí nghiệm đã tạo ra cơ sở cho hệ thống được gửi đi. Những thí nghiệm của chúng ta cho thấy huấn luyện đa nhiệm với các biểu hiện nội bộ chia sẻ không chỉ là khả thi mà còn cho phép truyền tri thức qua các phương thức.', 'uz': "Bu gaz Helsinki tillar Teknolojiy guruhi IWSLT 2020'ning IWSLT 2020'ning o'zgarishni anglatadi. Ingliz audio tarjimasini Olmoncha matnning tarjima qilishini anglatadi. @ info Biz internal representations bilan bir necha multitasking maktablarni tugatamiz va ASR, to ʻgʻrilash va MT darajasidagi standard vazifalarga qo'shiladi. Biz quyidagi tizim asosida ishlatilgan imtiyozlarni anglatamiz. Bizning imtiyozlarimizning ko'plab-bir xil taʼminlov ichki tajribalar bilan bog'liq o'rganishlar faqat mavjud emas, balki ma'lumotni o'zgartirishga ruxsat beradi.", 'da': 'Denne artikel beskriver University of Helsinki Language Technology gruppes deltagelse i IWSLT 2020 offline tale oversættelse opgave, der omhandler oversættelse af engelsk lyd til tysk tekst. I overensstemmelse med dette års opgavemål træner vi både kaskade- og end-to-end-systemer til talesprogoversættelse. Vi vælger en end-to-end multitasking arkitektur med delte interne repræsentationer og en kaskade tilgang, der følger en standardprocedure bestående af ASR, korrektion og MT faser. Vi beskriver også de eksperimenter, der tjente som grundlag for de indsendte systemer. Vores eksperimenter afslører, at multitasking træning med fælles interne repræsentationer ikke kun er mulig, men muliggør vidensoverførsel på tværs af modaliteter.', 'bg': 'Настоящата статия описва участието на групата по езикови технологии на Университета в Хелзинкския университет в задачата за офлайн превод на реч, насочена към превода на английски аудио на немски текст. В съответствие с тазгодишната задача ние обучаваме както каскадни, така и системи от край до край за превод на говорен език. Избираме цялостна архитектура с общи вътрешни представяния и каскаден подход, който следва стандартна процедура, състояща се от етапи на АСР, корекция и МТ. Описваме и експериментите, които служат като основа за представените системи. Нашите експерименти разкриват, че многофункционалното обучение с споделени вътрешни представи не само е възможно, но и позволява трансфер на знания между модалите.', 'nl': 'Dit artikel beschrijft de deelname van de groep Taaltechnologie van de Universiteit van Helsinki aan de IWSLT 2020 offline spraakvertaaltaak, gericht op de vertaling van Engelse audio naar Duitse tekst. In lijn met de taakdoelstelling van dit jaar trainen we zowel cascade- als end-to-end systemen voor gesproken taalvertaling. We kiezen voor een end-to-end multitasking architectuur met gedeelde interne representaties en een cascade aanpak die een standaard procedure volgt bestaande uit ASR-, correctie- en MT-fasen. We beschrijven ook de experimenten die als basis dienden voor de ingediende systemen. Onze experimenten tonen aan dat multitasking training met gedeelde interne representaties niet alleen mogelijk is, maar ook kennisoverdracht mogelijk maakt tussen modaliteiten.', 'hr': 'Ovaj papir opisuje učestvovanje Univerziteta Helsinkijske jezičke tehnologije u zadatku IWSLT 2020-a o offline govornom prevodu, s obzirom na prevod engleskog zvuka na njemački tekst. U skladu s zadatkom ove godine, treniramo i kaskadne i konačne sustave za prevod govornog jezika. Izabrali smo multitasking arhitekturu sa zajedničkim unutrašnjim predstavljanjem i pristupom kaskade koji prati standardnu proceduru koja se sastoji od ASR, isprave i MT faza. Također opisujemo eksperimente koji su služili kao osnovu podanih sustava. Naši eksperimenti otkrivaju da je multitasking obuka s zajedničkim unutrašnjim predstavljanjima ne samo moguća, nego omogućava prijenos znanja preko načina.', 'de': 'Dieser Beitrag beschreibt die Beteiligung der Gruppe Sprachtechnologie der Universität Helsinki an der Offline-Sprachübersetzungsaufgabe IWSLT 2020, die sich mit der Übersetzung von englischem Audio in deutschen Text befasst. Entsprechend dem diesjährigen Aufgabenziel schulen wir sowohl Kaskaden- als auch End-to-End-Systeme für gesprochene Übersetzungen. Wir entscheiden uns für eine End-to-End-Multitasking-Architektur mit gemeinsamen internen Repräsentationen und einem Kaskadenansatz, der einem Standardverfahren folgt, das aus ASR-, Korrektur- und MT-Stufen besteht. Wir beschreiben auch die Experimente, die als Grundlage für die eingereichten Systeme dienten. Unsere Experimente zeigen, dass Multitasking-Training mit gemeinsamen internen Repräsentationen nicht nur möglich ist, sondern auch einen modalitätsübergreifenden Wissenstransfer ermöglicht.', 'id': 'Kertas ini menjelaskan kelompok Teknologi Bahasa Universitas Helsinki berpartisipasi dalam tugas terjemahan pidato luar talian IWSLT 2020, mengarahkan terjemahan audio Inggris ke teks Jerman. Berdasarkan dengan tujuan tugas tahun ini, kita melatih sistem kaskade dan sistem akhir-akhir untuk terjemahan bahasa berbicara. Kami memilih arkitektur multitasking akhir-akhir dengan persembahan internal bersama dan pendekatan kaskade yang mengikuti prosedur standar yang terdiri dari ASR, koreksi, dan tahap MT. Kami juga menggambarkan eksperimen yang layak sebagai dasar bagi sistem yang diserahkan. Eksperimen kami mengungkapkan bahwa pelatihan multitasking dengan representation interna berbagi tidak hanya mungkin tetapi memungkinkan untuk transfer pengetahuan melalui modalitas.', 'ko': '본고는 헬싱키대학 언어기술그룹이 IWSLT 2020 오프라인 음성 번역 임무에 참여하여 영어 오디오에서 독일어 텍스트까지의 번역 문제를 해결하였다.올해의 임무 목표에 따라 우리는 구어 번역 교육을 위해 단계별 연결과 단계별 시스템을 갖추고 있다.우리는 ASR, 교정 및 MT 단계로 구성된 표준 프로그램을 따르는 공유된 내부 표시 및 종속 연결 방법을 갖춘 종단간 멀티태스킹 아키텍처를 선택했습니다.우리는 또한 제출 시스템의 기초로 하는 실험을 묘사했다.우리의 실험에 따르면 내부 표징을 공유하는 다중 임무 훈련은 가능할 뿐만 아니라 크로스 모드의 지식 이동도 허용한다.', 'sw': 'Gazeti hili linaelezea ushiriki wa kikundi cha Teknolojia cha Kikuu cha Lugha cha Helsinki katika kazi ya tafsiri ya lugha ya IWSLT 2020, ikielezea tafsiri ya sauti ya Kiingereza katika maandishi ya Kijerumani. Kwa mujibu wa lengo la kazi la mwaka huu, tunafundisha mifumo ya kaskade na mwisho kwa ajili ya kutafsiri lugha inayozungumzwa. Tunachagua ujenzi wa mwisho wa mwisho wa matokeo mengi yenye uwakilishi wa ndani na mbinu za kaskaza zinazofuata mchakato wa kawaida wa ASR, uharibifu, na vituo vya MT. Tunaweza pia kuelezea majaribio yaliyotumikia kama msingi wa mifumo yaliyotolewa. Majaribio yetu yanaonyesha kuwa mafunzo mengi yanayoshirikiana na uwakilizaji wa ndani haiwezekani pekee bali yanaruhusu kusambaza maarifa kwa namna mbalimbali.', 'tr': 'Bu kagyz Helsinki Dil Tehnologiýasynyň IWSLT 2020-nji ýylda offline s öz terjime täbligini barýar we iňlisçe ses täbligini Almança metine çykarýar. Bu ýylyň görevleriniň maksadyna görä, biz hem kascada hem soňra-soňra s öz dillerini terjime etmek üçin sistemalary öwredýäris. Biz, ASR, düzeltmek, MT taýýarlanan standart prosedürüne uyan bir multitasking arhitektegi we paylaşın içeri temsilleri bilen seçýäris. Biz hem gönderilen sistemalar üçin üýtgedilen deneyleri tassykladyk. Biziň deneylerimiz birnäçe taýýarlap daşary daşary täzelikleri bilen bilim-terjimesine mümkin däldir, ýöne bilim-terjimesine modalaryň daşary mümkin däldir.', 'af': "Hierdie papier beskrywe die Universiteit van Helsinki Taal Tegnologie se deelnadering in die IWSLT 2020 aflyn sprekkoorvalingstaak, om die vertaling van Engelse oudio in Duitse teks te beskrywe. In lyn met hierdie jaar se taak doel, tref ons beide kaskade en end-to-end stelsels vir praat taal vertaling. Ons kies vir 'n einde-tot-einde multitaak-arkitektuur met gedeelde interne verteenwoordings en 'n kaskade toegang wat volg 'n standaard prosedure wat bestaan van ASR, korreksie en MT stadige. Ons beskrywe ook die eksperimente wat as 'n basis gedien het vir die onderdra stelsels. Ons eksperimente vertoon dat multitasking onderwerp met gedeelde interne verteenwoordings nie alleen moontlik is nie, maar toelaat vir kennis-oordrag oor modaliteite.", 'fa': 'این روزنامه، گروه تکنولوژی دانشگاه هلسینکی زبان را توصیف می\u200cکند که مشارکت گروه تکنولوژی زبان IWSLT 2020 در وظیفه ترجمه\u200cی صحبت غیر خطی است، با توصیف ترجمه صدای انگلیسی به متن آلمانی با هدف وظیفه امسال، ما سیستم\u200cهای کاسکید و پایان و پایان را برای ترجمه زبان صحبت می\u200cکنیم. ما برای یک معماری بسیاری از کار های پایان و پایان با نمایش های داخلی مشترک انتخاب می کنیم و یک طریق کاسکید که از طریق استاندارد پیروی می کند که از مرحله های ASR، اصلاح و MT است. ما همچنین آزمایشات را توصیف می\u200cکنیم که به عنوان بنیادی برای سیستم\u200cهای تحویل داده می\u200cشوند. آزمایش\u200cهای ما نشان می\u200cدهند که آموزش تعلیم\u200cهای زیادی با نمایش\u200cهای داخلی مشترک ممکن نیست، بلکه اجازه می\u200cدهد برای انتقال علم در طول modalities.', 'am': 'ይህ ገጽ የኢንጂንግል ድምፅ ቴክኖሎጂ ዩንቨርስቲ በጀርመን ጽሑፍ ለመግለጽ በIWSLT 2020 የንግግር ትርጓሜ አድራሻ ላይ ተርጓሚዎችን የሚያሳውቃል፡፡ የዓመቱ ስራ አቃራቢ በመስመር፣ ለንግግር ቋንቋ ትርጓሜ እና መጨረሻ ሲስተማርን እናስተምራለን፡፡ በአውራዊ ግንኙነት መልዕክቶች እና የአስር፣ ማስታወስ እና የMT ደረጃዎች የሚቆጠሩ የድጋፍ ሥርዓት የሚከተለውን የአካባቢ ሥርዓት ለመጨረሻ አካባቢ መሠረት እና ለመቆጣጠር እናደርጋለን፡፡ We also describe the experiments that served as a basis for the submitted systems.  ፈተናዎቻችን የውይይት ግንኙነት በተካፈሉት የውይይት ግንኙነት ብቻ አይደለም ነገር ግን እውቀትን በመለስ ይችላል፡፡', 'bn': 'এই পত্রিকাটি বিশ্ববিদ্যালয়ের হেলসিঙ্কি ভাষা প্রযুক্তিগত প্রযুক্তি গ্রুপের অংশগ্রহণকারী আইউএসএলটি ২০২০ অফ-লাইন ভাষণ অনুবাদ করা এই বছরের কাজের লক্ষ্যের সাথে আমরা ভাষাভাষার অনুবাদের জন্য ক্যাস্কেড এবং শেষ পর্যন্ত ব্যবস্থা প্রশিক্ষণ করি। আমরা শেয়ার করা আভ্যন্তরীণ প্রতিনিধিদের সাথে মাল্টিটাইটিং কাঠামোর শেষ পর্যন্ত প্রতিষ্ঠানের জন্য পছন্দ করি এবং একটি ক্যাসেড প্রক্রিয়া যা এসআর, সংশো আমরা যে পরীক্ষাগুলোকে জমা দিয়েছিলাম সিস্টেমের ভিত্তিক হিসেবে কাজ করেছিলাম তা বর্ণনা করি। আমাদের পরীক্ষাগুলো দেখাচ্ছে যে ভাগাভাগি ভাগাভাগি প্রতিনিধিত্বের সাথে বহুভাষী প্রশিক্ষণ কেবল সম্ভব নয়, কিন্ত', 'az': 'Bu kağıt Helsinki Dil Tehnologiyanın Üniversitesinin IWSLT 2020-nin offline s öz çeviri işini, İngilizə audisinin çevirisini Alman metinə çevirir. Bu il işin məqsədilə, danışan dil tercüməsi üçün kascada və sona-sona sistemləri təhsil edirik. Biz bir çoxlu iş bitirmək arhitektarını paylaşdırırıq. İçəri göstəricilər və ASR, düzəltmək və MT fərzində olan standart prosedürlərin ardınca gedən kaskadın tərzini seçirik. Biz də müəyyən edilmiş sistemlər üçün istifadə edilən eksperimentləri təsbit edirik. Bizim təcrübələrimiz ortaq içəri təcrübələr ilə çoxlu işlər təcrübəsi mümkün deyil, ancaq elm təcrübəsini modüllərdə təhrif edə bilər.', 'ca': "Aquest article descriu la participació del grup de tecnologia del llenguatge de la Universitat d'Helsinki en la tasca de traducció del discurs offline IWSLT 2020, dirigint la traducció de l'àudio anglès al text alemany. De acord amb l'objectiu de la tasca d'aquest any, entrenem sistemes cascade s i de final a final per a la traducció del llenguatge parlat. Optem una arquitectura multitasca de final a final amb representacions internes compartides i un enfocament cascat que segueix un procediment estàndard compost d'etapes ASR, correcció i MT. També descrivim els experiments que van servir com a base dels sistemes submetits. Els nostres experiments revelen que la capacitat multitasca amb representacions internes compartides no només és possible, sinó permet la transfer ència de coneixements a través de modalitats.", 'bs': 'Ovaj papir opisuje sudjelovanje Univerziteta Helsinkijskih jezičkih tehnologija u zadatku IWSLT 2020 za offline govorni prevod, s obzirom na prevod engleskog zvuka na njemački tekst. U skladu sa zadatkom ove godine, treniramo i kaskadne i konačne sisteme za prevod govornog jezika. Izabrali smo multitasking arhitekturu sa zajedničkim unutrašnjim predstavljanjima i pristupom kaskade koji prati standardnu proceduru koja se sastoji od ASR, korekcije i MT faza. Također opisujemo eksperimente koji su služili kao osnovu predanih sustava. Naši eksperimenti otkrivaju da je multitasking obuka sa zajedničkim unutrašnjim predstavljanjima ne samo moguća, nego omogućava prenošenje znanja preko načina.', 'cs': 'Tento článek popisuje účast skupiny University of Helsinki Language Technology na úkolu IWSLT 2020 offline překladu řeči, který se zabývá překladem anglického zvuku do německého textu. V souladu s letošním cílem úkolu trénujeme kaskádové i end-to-end systémy pro překlad mluveného jazyka. Rozhodli jsme se pro komplexní multitaskingovou architekturu se sdílenými interními reprezentacemi a kaskádovým přístupem, který se řídí standardním postupem sestávajícím ze stupňů ASR, korekce a MT. Dále popisujeme experimenty, které sloužily jako základ pro předložené systémy. Naše experimenty ukazují, že multitasking trénink se sdílenými interními reprezentacemi je nejen možný, ale umožňuje přenos znalostí napříč modalitami.', 'et': 'Käesolevas artiklis kirjeldatakse Helsingi Ülikooli keeltehnoloogia rühma osalemist IWSLT 2020 võrguühenduseta kõnetõlke ülesandes, mis käsitleb inglise heli tõlkimist saksa keelde. Kooskõlas käesoleva aasta ülesande eesmärgiga koolitame nii kaskaadi- kui ka otsast-otsa süsteeme kõnelevate keelte tõlkimiseks. Valime otsast otsani mitmeülesandearhitektuuri, millel on ühised sisemised esindused ja kaskaadne lähenemisviis, mis järgib standardmenetlust, mis koosneb ASR, parandus ja MT etappidest. Samuti kirjeldame katseid, mis olid esitatud süsteemide aluseks. Meie eksperimendid näitavad, et mitmeülesandeline koolitus koos ühiste sisemiste esindustega ei ole mitte ainult võimalik, vaid võimaldab teadmiste edastamist eri viiside vahel.', 'fi': 'Tässä artikkelissa kuvataan Helsingin yliopiston kieliteknologiaryhmän osallistumista IWSLT 2020 -offline-puhekäännöstyöhön, jossa käsitellään englanninkielisen äänen kääntämistä saksaksi. Tämän vuoden tehtävätavoitteen mukaisesti koulutamme sekä kaskadi- että end-to-end-järjestelmiä puhuttujen kielten kääntämiseen. Valitsemme kokonaisvaltaisen monitehtäväarkkitehtuurin, jossa on yhteiset sisäiset esitykset ja kaskadi-lähestymistavan, joka noudattaa standardimenettelyä, joka koostuu ASR-, korjaus- ja MT-vaiheista. Kuvailemme myös kokeita, jotka toimivat pohjana toimitetuille järjestelmille. Kokemuksemme osoittavat, että monikoulutus yhteisillä sisäisillä edustustoilla ei ole vain mahdollista, vaan mahdollistaa tiedonsiirron eri muodoissa.', 'hy': 'Այս աշխատանքը նկարագրում է Հելսինկի լեզվի տեխնոլոգիաների համալսարանի խումբի մասնակցությունը IW-Սլեթ 2020-ի անլայն լեզվի թարգմանման խնդիրների մեջ, որոնք վերաբերվում են անգլերենի ձայնի թարգմանմանմանը գեր Այս տարվա խնդիրների հետ կապված, մենք վարժեցնում ենք խոսված լեզվի թարգմանման կասկադի և վերջ-վերջ համակարգերը: Մենք ընտրում ենք ավարտ-ավարտ բազմախնդիր ճարտարապետություն, որն ունի ընդհանուր ներքին ներկայացումներ և կասկադի մոտեցում, որը հետևում է ստանդարտ գործընթացին, որը կազմված է ASR-ից, ուղղումներից և MT-ից: Մենք նաև նկարագրում ենք փորձերը, որոնք օգտագործում էին որպես հիմք ներկայացված համակարգերի համար: Մեր փորձարկումները բացահայտում են, որ բազմապատասխանատվությունը ընդհանուր ներքին ներկայացուցիչների հետ ոչ միայն հնարավոր է, այլ նաև հնարավոր է գիտելիքների փոխանցումը տարբեր միջոցների միջև:', 'sq': 'Ky dokument përshkruan pjesëmarrjen e grupit të Teknologjisë s ë Gjuhave të Universitetit të Helsinkit në detyrën e përkthimit të fjalës jashtë linje IWSLT 2020, duke trajtuar përkthimin e audio anglez në tekstin gjerman. Në përputhje me objektivin e detyrës të këtij viti, ne trajnojmë si kaskadë, ashtu edhe sisteme nga fundi në fund për përkthimin e gjuhës s ë folur. Ne zgjedhim një arkitekturë shumë-detyrash nga fundi në fund me përfaqësime të përbashkëta të brendshme dhe një qasje kaskade që pason një procedurë standarte që përbëhet nga ASR, korrigjim dhe faza MT. We also describe the experiments that served as a basis for the submitted systems.  Our experiments reveal that multitasking training with shared internal representations is not only possible but allows for knowledge-transfer across modalities.', 'jv': 'Perintah iki rambarang nggawe kelompok Universite ning kelompok Teknêngkno ning IWSLT 2020 kuwi nggawe tarjamahan sing wis intang, nambah tarjamahan kanggo kelompok Inggris kanggo teks ning alam. line We opt for an end-to-end multitasking architecture with a sharing intermediate representations and a kascade method that would be ardong with a Standard Procedure that would include ASR, rection, and MT phases. Awak dhéwé pisan karo éntuk sing paling nggawe ngupakan karo sistem sing nyimpen. Awakdhéwé éntuk ngertukno karo akeh multitasking nggawe gerakan kelamèh karo repréntasi winih sing ora bisa diagonalan tambah kuwi nggawe kesempatan karo modalité.', 'ha': "Wannan karatun na bayyana fassarar fassarar sauti na Ingiriya zuwa littãfin Jarman. @ action: button Mu zãɓi bakar arziki mai ƙaranci na multi-multitori da ake haɗa masu cikin rubutun da ke guda da wata hanyor kaskada wanda ke biyar wata takarda na daidaita ta ƙara ta haɗi da shirin AR, sahifa da MT. Kayya, Munã bayyana jarrabai waɗanda suka yi aiki kamar ba'a ba da tsarin da aka samu Kayan jarrabõyinmu sun bayyana cẽwa, ma'anar multi-multi da ake yi wa rabo masu cikin rubutun na guda bai zama kawai ba, kuma yana yarda in shige da ilmi a kan kowace misãlai.", 'sk': 'V prispevku je opisano sodelovanje skupine Univerze v Helsinkih za jezikovno tehnologijo v nalogi prevajanja govora brez povezave IWSLT 2020, ki obravnava prevajanje angleškega zvoka v nemško besedilo. V skladu z letošnjim ciljem naloge usposabljamo tako kaskadne kot celovite sisteme prevajanja govorjenega jezika. Odločimo se za celovito večopravilno arhitekturo s skupnimi notranjimi predstavitvami in kaskadnim pristopom, ki sledi standardnemu postopku, sestavljenem iz stopenj ASR, popravka in MT. Opisujemo tudi poskuse, ki so služili kot osnova za predložene sisteme. Naši eksperimenti kažejo, da večopravilno usposabljanje s skupnimi notranjimi predstavitvami ni le mogoče, ampak omogoča prenos znanja med načini.', 'bo': "This paper describes the University of Helsinki Language Technology group's participation in the IWSLT 2020 offline speech translation task, addressing the translation of the English audio to German text. ལོ་གཅིག་གི་བྱ་འགུལ་གྱི་དམིགས་ཡུལ་དང་བསྟུན་ནས་སྨུག་ཅིག་དང་འཕྲིན་རྗེས་སུ་གཏོང་བྱེད་པའི་སྐད་ཡིག་ལ་འགྲོ་སྐ We opt for an end-to-end multitasking architecture with shared internal representations and a cascade approach that follows a standard procedure consisting of ASR, correction, and MT stages. ང་ཚོས་དུས་ཡོད་པའི་ལག་ལེན་འཐབ་རྩིས་ལག་ལ་གྱི་རྨས་གཞི་བྱས་པ་ཡིན་པས་ ང་ཚོའི་བརྟག་ཞིག་གིས་དབྱིབས་སྤྱད་ནས་འཇུག་སྣེ་མང་བྱེད་པའི་གྲ་སྒྲིག་འགོད་རྩལ་གསུམ་སྟོན་རྒྱུ་ལས་ནའང་གནས་སྟངས་འད", 'he': 'העיתון הזה מתאר את השתתפות של קבוצת טכנולוגיה השפה של אוניברסיטת הלסינקי במשימת התרגום הנאום מחוץ לשידור IWSLT 2020. בהתאם למטרת המשימה של השנה, אנו מאמן גם מערכות קסקאדה וגם מערכות סוף-סוף לתרגום שפה מדברת. אנו בוחרים בארכיטקטורה מסוף-לסוף עם משימות רבות עם מייצגים פנימיים משותפים וגישה קסקודית שמעקבת אחרי הליך סטנדרטי שמכיל בשלבים ASR, תיקון, ו-MT. We also describe the experiments that served as a basis for the submitted systems.  הניסויים שלנו מראים שאימונים רבים עם מייצגים פנימיים משותפים הם לא רק אפשריים, אלא מאפשרים לעבור ידע דרך דרכים.'}
{'en': 'The AFRL IWSLT 2020 Systems : Work-From-Home Edition', 'ar': 'أنظمة AFRL IWSLT 2020: إصدار العمل من المنزل', 'fr': 'Les systèmes AFRL IWSLT 2020\xa0: édition travail à domicile', 'es': 'Los sistemas AFRL IWSLT 2020: Edición para trabajar desde casa', 'pt': 'Os sistemas AFRL IWSLT 2020: edição Work-From-Home', 'ja': 'AFRL IWSLT 2020システム：在宅勤務版', 'hi': 'AFRL IWSLT 2020 सिस्टम: वर्क-फ्रॉम-होम संस्करण', 'zh': 'AFRL IWSLT 2020 系统:在家办公版', 'ru': 'Системы AFRL IWSLT 2020: Work-From-Home Edition', 'ga': 'Córais AFRL IWSLT 2020: Eagrán Obair Ón Baile', 'hu': 'Az AFRL IWSLT 2020 rendszerek: Work-From-Home Edition', 'el': 'Τα συστήματα του AFRL IWSLT 2020: έκδοση εργασίας από το σπίτι', 'ka': 'AFRL IWSLT 2020 სისტემები: სახლიდან მუშაობა', 'lt': 'AFRL IWSLT 2020 sistemos: darbas iš namų', 'kk': 'AFRL IWSLT 2020 жүйелері: Work-From-Home Edition', 'it': 'I sistemi AFRL IWSLT 2020: Work-From-Home Edition', 'mt': 'Is-Sistemi AFRL IWSLT 2020: Edizzjoni tax-Xogħol-Minn-Id', 'mk': 'АФРЛ IWSLT 2020 системи: Едиција за работа од дома', 'mn': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'ms': 'Sistem AFRL IWSLT 2020: Edition Kerja Dari Rumah', 'ml': 'AFRL IWSLT 2020 സിസ്റ്റമുകള്\u200d: വീട്ടില്\u200d നിന്നും എഡിറ്റര്\u200d', 'pl': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'ro': 'Sistemele AFRL IWSLT 2020: Ediția Work-From-Home', 'no': 'AFRL IWSLT 2020 Systema: Work-From-Home Edition', 'si': 'AFRL IWSLT 2020යි පද්ධතිය: වැඩ-ඉඳන් ගෙදර ප්\u200dරකාශනය', 'so': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'sv': 'AFRL IWSLT 2020 System: Work-From-Home Edition', 'sr': 'AFRL IWSLT 2020 sistemi: Izdaj posla iz kuće', 'ta': 'AFRL IWSLT 2020 அமைப்புகள்: வேலை - வீட்டிலிருந்து திருத்துதல்', 'ur': 'AFRL IWSLT 2020 سیسٹم: Work-From-Home Edition', 'uz': 'AFRL IWSLT 2020 tizim: Ish- dan Uy tahrirchi', 'vi': 'Các hệ thống AFRL IWSLT 2020: Work-From-Home Edition', 'nl': 'De AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'da': 'Den AFRL IWSLT 2020 systemer: Work-From-Home Edition', 'bg': 'Системите на AFRL IWSLT 2020: Работа от дома издание', 'hr': 'Sistemi AFRL IWSLT 2020: Izdavanje posla iz kuće', 'de': 'Die AFRL IWSLT 2020 Systeme: Work-From-Home Edition', 'id': 'The AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'ko': 'AFRL IWSLT 2020 시스템: Home Edition', 'fa': 'The AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'sw': 'Mfumo wa 2020 AFRL IWSLT: Mhariri wa kazi-From-Home', 'tr': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'sq': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'af': 'Die AFRL IWSLT 2020-stelsels: Werk-Van-Huis', 'am': 'የAFRL IWSLT 2020 Systems: Work-From-Home Edition', 'hy': 'ԱֆՌL IW-ՍԼT 2020 համակարգերը՝ աշխատանքի-տնային խմբագրություն', 'bn': 'AFRL IWSLT ২০২০ সিস্টেম: কাজ থেকে বাড়ির সম্পাদক', 'az': 'AFRL IWSLT 2020 Sistemləri: Work-From-Home Edition', 'bs': 'AFRL IWSLT 2020. sistemi: Izdavanje posla iz kuće', 'ca': 'The AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'cs': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'et': 'AFRL IWSLT 2020 süsteemid: töö kodust väljaanne', 'fi': 'AFRL IWSLT 2020 Systems: Work-From-Home Edition', 'jv': 'The AfRL IWSLT 2020 System: Works-from-Beginning Edit', 'ha': 'KCharselect unicode block name', 'sk': 'Sistemi AFRL IWSLT 2020: Delo od doma Edition', 'he': 'מערכות AFRL IWSLT 2020: עורך עבודה מהבית', 'bo': 'The AFRL IWSLT 2020 Systems: Work-From-Home Edition'}
{'en': 'This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. As in previous years, we chose to adopt the cascade approach of using separate systems to perform speech activity detection, automatic speech recognition, sentence segmentation, and machine translation. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation. Our primary submission yielded BLEU scores of 21.28 on tst2019 and 23.33 on tst2020.', 'es': 'Este informe resume la presentación del Laboratorio de Investigación de la Fuerza Aérea (AFRL) a la tarea de traducción del idioma hablado (SLT) fuera de línea como parte de la campaña de evaluación IWSLT 2020. Como en años anteriores, decidimos adoptar el enfoque en cascada de usar sistemas separados para realizar la detección de la actividad del habla, el reconocimiento automático del habla, la segmentación de oraciones y la traducción automática. Todos los sistemas estaban basados en neuronas, incluida una red neuronal totalmente conectada para la detección de la actividad del habla, una red neuronal factorizada con retardo de tiempo Kaldi con recuperación del modelo de lenguaje de red neuronal recurrente (RNN) para el reconocimiento de voz, una RNN bidireccional con mecanismo de atención para la segmentación de oraciones, y redes de transformadores capacitadas con OpenNMT y Marian para la traducción automática. Nuestra presentación principal arrojó puntuaciones BLEU de 21.28 en tst2019 y 23.33 en tst2020.', 'ar': 'يلخص هذا التقرير تقديم مختبر أبحاث القوات الجوية (AFRL) إلى مهمة ترجمة اللغة المنطوقة دون اتصال بالإنترنت (SLT) كجزء من حملة تقييم IWSLT 2020. كما في السنوات السابقة ، اخترنا اعتماد نهج التسلسل باستخدام أنظمة منفصلة لأداء اكتشاف نشاط الكلام ، والتعرف التلقائي على الكلام ، وتجزئة الجملة ، والترجمة الآلية. كانت جميع الأنظمة قائمة على أساس عصبي ، بما في ذلك شبكة عصبية متصلة بالكامل للكشف عن نشاط الكلام ، وشبكة عصبية لتأخير الوقت المعامل من Kaldi مع نموذج لغة الشبكة العصبية المتكررة (RNN) لإعادة التعرف على الكلام ، و RNN ثنائي الاتجاه مع آلية الانتباه لتجزئة الجملة ، و شبكات المحولات المدربة مع OpenNMT و Marian للترجمة الآلية. أسفر تقديمنا الأساسي عن درجات 21.28 في tst2019 و 23.33 في tst2020.', 'fr': "Ce rapport résume la soumission du Laboratoire de recherche de l'armée de l'air (AFRL) à la tâche de traduction en langue parlée hors ligne (SLT) dans le cadre de la campagne d'évaluation IWSLT 2020. Comme les années précédentes, nous avons choisi d'adopter l'approche en cascade qui consiste à utiliser des systèmes distincts pour la détection de l'activité vocale, la reconnaissance vocale automatique, la segmentation des phrases et la traduction automatique. Tous les systèmes étaient basés sur des neurones, y compris un réseau neuronal entièrement connecté pour la détection de l'activité vocale, un réseau neuronal temporisé factorisé Kaldi avec un modèle de langage de réseau neuronal récurrent (RNN) enregistrant la reconnaissance vocale, un RNN bidirectionnel avec mécanisme d'attention pour la segmentation des phrases, et réseaux de transformateurs formés avec OpenNMT et Marian pour la traduction automatique. Notre soumission principale a donné des scores UEBL de 21,28 au tst2019 et de 23,33 au tst2020.", 'pt': 'Este relatório resume o envio do Laboratório de Pesquisa da Força Aérea (AFRL) para a tarefa de tradução de linguagem falada offline (SLT) como parte da campanha de avaliação do IWSLT 2020. Como nos anos anteriores, optamos por adotar a abordagem em cascata de usar sistemas separados para realizar detecção de atividade de fala, reconhecimento automático de fala, segmentação de frases e tradução automática. Todos os sistemas eram baseados em neurônios, incluindo uma rede neural totalmente conectada para detecção de atividade de fala, uma rede neural de atraso de tempo fatorada Kaldi com rescore de modelo de linguagem de rede neural recorrente (RNN) para reconhecimento de fala, uma RNN bidirecional com mecanismo de atenção para segmentação de frases e redes de transformadores treinadas com OpenNMT e Marian para tradução automática. Nossa submissão primária rendeu pontuações BLEU de 21,28 no tst2019 e 23,33 no tst2020.', 'zh': '本告总结空军研究实验室(AFRL)向离线口语译(SLT)事务提交之文,以为IWSLT 2020估动之一。 与往年同,择级联法,用独统以行语检,自语音别,句分机器翻译。 凡统皆神经也,音检相连神经网络,有递归神经网络(RNN)言重评分之Kaldi分时滞神经网络,句分之有机双向RNN,及用OpenNMTMarian练于机器翻译转换器网络。 大要在tst2019上得21.28分,在tst2020上得23.33分BLEU分。', 'ja': 'このレポートは、IWSLT 2020評価キャンペーンの一環として、オフライン口語翻訳（ SLT ）タスクに空軍研究ラボ（ AFRL ）が提出したものをまとめたものです。前年と同様に、音声アクティビティ検出、自動音声認識、文セグメンテーション、機械翻訳を別々のシステムで行うカスケードアプローチを採用しました。すべてのシステムは、音声アクティビティ検出のための完全に接続されたニューラルネットワーク、音声認識のための再帰ニューラルネットワーク（ ＲＮＮ ）言語モデルを有するＫａｌｄｉ因子化時間遅延ニューラルネットワーク、文セグメンテーションのための注意メカニズムを有する双方向ＲＮＮ、及び機械翻訳のためのＯｐｅｎＮＭＴ及びＭａｒｉａｎで訓練された変圧器ネットワークを含む、ニューラルベースであった。私たちの主要な提出物は、TST 2019で21.28、TST 2020で23.33のBLEUスコアを得た。', 'hi': 'यह रिपोर्ट IWSLT 2020 मूल्यांकन अभियान के हिस्से के रूप में ऑफ़लाइन बोली जाने वाली भाषा अनुवाद (SLT) कार्य के लिए वायु सेना अनुसंधान प्रयोगशाला (AFRL) सबमिशन को सारांशित करती है। पिछले वर्षों की तरह, हमने भाषण गतिविधि का पता लगाने, स्वचालित भाषण मान्यता, वाक्य विभाजन और मशीन अनुवाद करने के लिए अलग-अलग प्रणालियों का उपयोग करने के कैस्केड दृष्टिकोण को अपनाने का फैसला किया। सभी प्रणालियां तंत्रिका आधारित थीं, जिसमें भाषण गतिविधि का पता लगाने के लिए एक पूरी तरह से जुड़े तंत्रिका नेटवर्क, आवर्तक तंत्रिका नेटवर्क (आरएनएन) भाषा मॉडल के साथ एक कालडी फैक्टराइज्ड समय देरी तंत्रिका नेटवर्क भाषण मान्यता के लिए पुनरावृत्ति, वाक्य विभाजन के लिए ध्यान तंत्र के साथ एक द्विदिश आरएनएन, और मशीन अनुवाद के लिए ओपनएनएमटी और मैरियन के साथ प्रशिक्षित ट्रांसफॉर्मर नेटवर्क शामिल थे। हमारे प्राथमिक सबमिशन ने tst2019 पर 21.28 और tst2020 पर 23.33 के BLEU स्कोर प्राप्त किए।', 'ru': 'В этом отчете обобщается информация, представленная Исследовательской лабораторией Военно-воздушных сил (AFRL) для выполнения задачи по автономному переводу на разговорный язык (SLT) в рамках кампании по оценке IWSLT 2020. Как и в предыдущие годы, мы выбрали каскадный подход использования отдельных систем для обнаружения речевой активности, автоматического распознавания речи, сегментации предложений и машинного перевода. Все системы были основаны на нейронах, включая полностью подключенную нейронную сеть для обнаружения речевой активности, факторизованную нейронную сеть с задержкой по времени Калди с рекуррентной моделью языка нейронной сети (RNN), восстанавливающую речевое распознавание, двунаправленную RNN с механизмом внимания для сегментации предложений и трансформаторные сети, обученные с OpenNMT и Marian для машинного перевода. Наша первичная заявка дала баллы BLEU 21,28 на tst2019 и 23,33 на tst2020.', 'ga': 'Déanann an tuarascáil seo achoimre ar aighneacht na Saotharlainne Taighde Aerfhórsa (AFRL) don tasc aistriúcháin teanga labhartha as líne (SLT) mar chuid d’fheachtas meastóireachta IWSLT 2020. Mar a tharla sna blianta roimhe seo, roghnaigh muid an cur chuige cascáideach a ghlacadh maidir le córais ar leith a úsáid chun gníomhaíocht cainte a bhrath, aithint uathoibríoch urlabhra, deighilt abairtí, agus aistriúchán meaisín a dhéanamh. Bhí na córais go léir bunaithe ar néarchóras, lena n-áirítear líonra néarúil lán-nasctha le haghaidh braite gníomhaíochta cainte, líonra néaraíoch moille ama fachtóirithe Kaldi le samhail teanga líonra néarach athfhillteach (RNN) le hathchóiriú cainte le haghaidh aitheantais cainte, RNN déthreoch le meicníocht aird le haghaidh deighilt phianbhreithe, agus oiliúint ar líonraí claochladán le OpenNMT agus Marian le haghaidh aistriúchán meaisín. Fuarthas scóir BLEU de 21.28 ar tst2019 agus 23.33 ar tst2020 mar thoradh ar ár bpríomhaighneacht.', 'hu': 'Ez a jelentés összefoglalja a Légierő Kutatólaboratóriumának (AFRL) az IWSLT 2020 értékelési kampány részeként az offline beszélt nyelvű fordítási feladatra (SLT) való benyújtását. Az előző évekhez hasonlóan úgy döntöttünk, hogy a kaszkádos megközelítést alkalmazzuk, hogy külön rendszereket használjunk a beszédaktivitás felismerésére, az automatikus beszédfelismerésre, a mondatszegmentálásra és a gépi fordításra. Minden rendszer neurális alapú volt, beleértve egy teljesen összekapcsolt neurális hálózatot a beszédaktivitás felismerésére, egy Kaldi faktorizált időkésleltető neurális hálózatot a beszédfelismerésre (RNN) visszatérő neurális hálózattal, egy kétirányú RNN-t a mondatszegmentációs mechanizmussal, valamint az OpenNMT és Marian által képzett transzformátor hálózatokat a gépi fordításra. Elsődleges beadványunk 21,28 BLEU pontszámot eredményezett a tst2019-en és 23,33-at a tst2020-on.', 'ka': 'ამ შეტყობინებაში გამოსახულებულია "Air Force Research Laboratory" (AFRL)-ს გამოსახულებას "offline language translation" (SLT) საქმე, რომელიც IWSLT 2020-ის გამოსახულება. როგორც წინა წლის განმავლობაში, ჩვენ ამორჩევეთ კასკადის პროგრამის გამოყენება განსაკუთრებული სისტემის განსაკუთრებისთვის, სიტყვების განსაკუთრებისთვის, სიტყვების განსაკუთრე ყველა სისტემები ნეიროლური დაბათებულია, რომელიც მუშაობით დაკავშირებული ნეიროლური ქსელი სისტემებისთვის განახლებისთვის, Kaldi ფაქტორიზებული დროის განახლებისთვის ნეიროლური ქსელი, რომელიც განახლებისთვის მუშაობის მოდელის განახლებისთვის, ბიდე ჩვენი პირველური მისამართლად ბლესო წერტილები 21.28 წერტილებია 2019-ში და 23.33 წერტილებში tst2020-ში.', 'it': "Questo rapporto riassume la presentazione del Laboratorio di Ricerca dell'Aeronautica Militare (AFRL) al compito di traduzione offline della lingua parlata (SLT) nell'ambito della campagna di valutazione IWSLT 2020. Come negli anni precedenti, abbiamo scelto di adottare l'approccio a cascata di utilizzare sistemi separati per eseguire il rilevamento delle attività vocali, il riconoscimento automatico del parlato, la segmentazione delle frasi e la traduzione automatica. Tutti i sistemi erano basati su neurali, tra cui una rete neurale completamente connessa per il rilevamento dell'attività vocale, una rete neurale con ritardo temporale fattorizzato Kaldi con modello di linguaggio di rete neurale ricorrente (RNN) per il riconoscimento vocale, un RNN bidirezionale con meccanismo di attenzione per la segmentazione delle frasi e reti di trasformatori addestrate con OpenNMT e Marian per la traduzione automatica. La nostra presentazione primaria ha ottenuto punteggi BLEU di 21,28 su tst2019 e 23,33 su tst2020.", 'el': 'Η παρούσα έκθεση συνοψίζει την υποβολή του εργαστηρίου έρευνας της Αεροπορίας (AFRL) στο έργο μετάφρασης προφορικής γλώσσας εκτός σύνδεσης (SLT) ως μέρος της εκστρατείας αξιολόγησης IWSLT 2020. Όπως και τα προηγούμενα χρόνια, επιλέξαμε να υιοθετήσουμε την προσέγγιση της χρήσης ξεχωριστών συστημάτων για την ανίχνευση δραστηριότητας ομιλίας, την αυτόματη αναγνώριση ομιλίας, τον κατακερματισμό προτάσεων και τη μηχανική μετάφραση. Όλα τα συστήματα ήταν νευρωνικά βασισμένα, συμπεριλαμβανομένου ενός πλήρως συνδεδεμένου νευρωνικού δικτύου για την ανίχνευση δραστηριότητας ομιλίας, ενός νευρωνικού δικτύου χρονικής καθυστέρησης με μοντέλο γλώσσας επαναλαμβανόμενου νευρωνικού δικτύου (RNN) για αναγνώριση ομιλίας, ενός αμφίδρομου με μηχανισμό προσοχής για την τμηματοποίηση προτάσεων, και δικτύων μετασχηματιστών εκπαιδευμένων με OpenNMT και Marian για μηχανική μετάφραση. Η αρχική μας υποβολή απέδωσε βαθμολογίες 21.28 στο tst2019 και 23.33 στο tst2020.', 'ms': 'Laporan ini singkatkan penghantaran Laboratori Penelitian Pasukan Udara (AFRL) kepada tugas terjemahan bahasa bercakap (SLT) luar talian sebagai sebahagian daripada kampanye penilaian IWSLT 2020. Seperti pada tahun-tahun terdahulu, kami memilih untuk mengadopsi pendekatan kaskad menggunakan sistem terpisah untuk melakukan pengesan aktiviti ucapan, pengenalan ucapan automatik, segmen kalimat, dan terjemahan mesin. Semua sistem berdasarkan saraf, termasuk rangkaian saraf yang tersambung sepenuhnya untuk pengesan aktiviti bercakap, rangkaian saraf yang diberikan faktor Kaldi melambat masa dengan model bahasa rangkaian saraf (RNN) berulang-ulang menyalin semula untuk pengenalan bercakap, RNN bidireksi dengan mekanisme perhatian untuk segmen kalimat, dan rangkaian pengubah dilatih dengan OpenNMT dan Marian untuk terjemahan mesin. Pemberian utama kami memberikan skor BLEU 21.28 pada tst2019 dan 23.33 pada tst2020.', 'kk': 'Бұл хабарлама "Air Force Research Laboratory" (AFRL) IWSLT 2020 бағалау кампаниясының бір бөлігі ретінде онлайн тілді аудару (SLT) тапсырмасына жіберіледі. Алдыңғы жылдар бойынша, сөздерді анықтау, автоматты сөздерді анықтау, сөздерді сегментация және машина аудару үшін бөлек жүйелерді қолданатын каскад қасиетін қолдануды таңдадық. Барлық жүйелер невралды негіздеген, сөйлеу белсенділігін анықтау үшін толық қосылған невралды желі, Kaldi факторизацияланған уақытты невралдық желі қайталанатын невралдық желі (RNN) тіл үлгісін қайталау үшін, сөйлеу сегментациялау механизмі мен OpenNMT және Мариан аудару үшін Біздің негізгі жіберіміз, т2020 жылы 21.28 және 23.33 жылы БЛЕС нәтижелері болды.', 'lt': 'Šioje ataskaitoje apibendrinamas oro pajėgų mokslinių tyrimų laboratorijos (AFRL) pateiktas žodžio vertimo kalba (SLT) uždavinys ne internete kaip IWSLT 2020 vertinimo kampanijos dalis. Kaip ir ankstesniais metais, nusprendėme taikyti kaskadinį požiūrį į atskirų sistemų naudojimą kalbos veiklos aptikimui, automatiniam kalbos pripažinimui, sakinių segmentavimui ir mašin ų vertimui atlikti. Visos sistemos buvo pagrįstos nervais, įskaitant visiškai prijungtą nervinį tinklą kalbos aktyvumui aptikti, Kaldi faktorizuotą laiko vėlavimo nervinį tinklą su pakartotiniu nervinio tinklo (RNN) kalbos modeliu, kuriame buvo atkurtas kalbos pripažinimas, dvikrypčių RNN su dėmesio mechanizmu sakinių segmentacijai ir transformatorių tinklus, apmokytus su OpenNMT ir Marian mašininiam vertimui. Mūsų pirminio pranešimo rezultatai buvo 21,28 T2019 m., o 2020 m. – 23,33 T2020 m.', 'mk': 'Овој извештај ја резимира поднесувањето на Лабораторијата за истражување на воздушните сили (АФРЛ) на задачата за превод на говорен јазик (СЛТ) преку интернет како дел од кампањата за проценка на ИВСЛТ 2020. Како и во претходните години, одбравме да го усвоиме каскадниот пристап на користење на одделни системи за извршување на детекција на говорната активност, автоматско препознавање на говорот, сегментација на речениците и машински превод. Сите системи беа неурални, вклучувајќи целосно поврзана неурална мрежа за детекција на говорната активност, факторизирана Калди неурална мрежа за одложување на времето со рецидентна неурална мрежа (РНН) јазички модел за препознавање на говорот, дворечна РНН со механизам за внимание за сегментација на речениците, и транс Нашата примарна поднесувачка даде оценки БЛЕУ од 21,28 на ТС2019 година и 23,33 на ТС2020 година.', 'mn': 'Энэ мэдээллийг IWSLT 2020-ын оюутнуудын нэг хэсэг болгон ярилцсан хэл хөрөнгө оруулах (SLT) даалгаврын судалгааны лаборатор (AFRL) дээр нэмэгдүүлдэг. Өнгөрсөн жилийн хугацаанд бид ярианы үйл ажиллагааг олох, автоматик ярианы хүлээн зөвшөөрөх, өгүүлбөр хэмжээний хэлбэрийг болон машины хөрөнгө оруулахын тулд каскад арга замыг ашиглах болсон Бүх системүүд ярианы үйл ажиллагаанд бүрэн холбогдсон мэдрэлийн сүлжээ, Kaldi-г дахин дахин сэтгэл сүлжээ (RNN) гэх мэт мэдрэлийн сүлжээний загвартай ярианы танихын тулд дахин сэргээгдсэн мэдрэлийн сүлжээ, өгүүлийн хэлбэртэй анхаарлын механизм, OpenNMT болон Мариан-тай сургалтын сүлжээ Бидний анхны даалгавар нь 2019 онд 21.28, tst2020 онд 23.33 болсон.', 'ml': '@ info കഴിഞ്ഞ വര്\u200dഷങ്ങള്\u200dക്ക് മുമ്പ് സംസാരിക്കുന്ന സിസ്റ്റങ്ങള്\u200d ഉപയോഗിക്കുന്നതിന്റെ കാസ്കേഡിന്റെ നടപടികള്\u200d നമ്മള്\u200d തെരഞ്ഞെടുത്തു. സം എല്ലാ സിസ്റ്റങ്ങളും ന്യൂറല്\u200d അടിസ്ഥാനമായിരുന്നു, സംസാരിക്കുന്നതിനുള്ള പൂര്\u200dണ്ണമായി ബന്ധപ്പെട്ട നെയൂറല്\u200d ശൃംഖലം ലഭ്യമാക്കിയിരുന്നു, വാക്ക് സംഘത്തിനുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d കണ്ടുപിടിക്കുന്നതിനുള്ള കാള നമ്മുടെ പ്രധാനപ്പെട്ട സന്ദേശങ്ങള്\u200d ടെസ്റ്റ് 2019-ല്\u200d 21. 28 സ്കോര്\u200d ബിലിയു കൊടുത്തു. ടെസ്റ്റി2020-ല്\u200d 23. 33.', 'pl': 'Raport ten podsumowuje zgłoszenie Laboratorium Badań Sił Powietrznych (AFRL) do zadania tłumaczenia języka mówionego offline (SLT) w ramach kampanii ewaluacyjnej IWSLT 2020. Podobnie jak w poprzednich latach postanowiliśmy przyjąć podejście kaskadowe polegające na wykorzystaniu oddzielnych systemów do wykrywania aktywności mowy, automatycznego rozpoznawania mowy, segmentacji zdań i tłumaczenia maszynowego. Wszystkie systemy były oparte na neuronach, w tym w pełni połączona sieć neuronowa do wykrywania aktywności mowy, czynnikowo opóźniona sieć neuronowa Kaldiego z modelem językowym powtarzającej się sieci neuronowej (RNN) do rozpoznawania mowy, dwukierunkowy RNN z mechanizmem uwagi na segmentację zdań oraz sieci transformatorowe przeszkolone OpenNMT i Marian do tłumaczenia maszynowego. Nasze główne zgłoszenie przyniosło wyniki BLEU 21.28 na tst2019 i 23.33 na tst2020.', 'mt': 'Dan ir-rapport jagħti sommarju tal-preżentazzjoni tal-Laboratorju tar-Riċerka tal-Forza tal-Ajru (AFRL) lill-kompitu tat-traduzzjoni tal-lingwa mitkellma offline (SLT) bħala parti mill-kampanja ta’ evalwazzjoni tal-IWSLT 2020. As in previous years, we chose to adopt the cascade approach of using separate systems to perform speech activity detection, automatic speech recognition, sentence segmentation, and machine translation.  Is-sistemi kollha kienu bbażati fuq in-newrali, inkluż netwerk newrali kompletament konness għad-detezzjoni tal-attività tad-diskors, netwerk newrali ta’ dewmien fil-ħin iffatturat Kaldi b’mudell lingwistiku rikorrenti tan-netwerk newrali (RNN) li jiskoraġġixxi għar-rikonoxximent tad-diskors, RNN bidirezzjonali b’mekkaniżmu ta’ attenzjoni għas-segmentazzjoni tas-sentenzi, u netwerks ta’ trasformaturi mħarrġa b’OpenNMT u Is-sottomissjoni primarja tagħna tat punteġġi BLEU ta’ 21.28 fuq tst2019 u 23.33 fuq tst2020.', 'sr': 'Ovaj izveštaj sažetuje predavanje istraživačke laboratorije zračne snage (AFRL) na zadatak offline govornog prevoda jezika (SLT) kao deo procjene kampanje IWSLT 2020. Kao i u prethodnim godinama, odlučili smo usvojiti pristup kaskade korištenja odvojenih sustava za otkrivanje govornih aktivnosti, priznanje automatskih govora, segmentaciju rečenica i prevod strojeva. Svi sustavi su bili neuralni bazirani, uključujući potpuno povezanu neuralnu mrežu za otkrivanje govorne aktivnosti, Kaldi faktorizirao vremensku odlaganju neuralne mreže sa rekonstruiranim neuralnim mrežom (RNN) jezičkim modelom za prepoznavanje govora, bidirekcionalnim RNN sa pažnjom mehanizma za segmentaciju rečenica, i transformacijskim mrežama obučenim sa OpenNMT i Marijanom za prevod mašine Naša primarna predstava donela je rezultate BLEU od 21,28 na tst2019 i 23,33 na tst2020.', 'no': 'Denne rapporten samanserer at luftforskningslaboratorien (AFRL) er tilgjengeleg til den offline praktiske omsetjinga (SLT) som del av evalueringskampanjen IWSLT 2020. Som i tidlegare år, har vi valt å adoptera kaskadtilnærminga ved å bruka separe systemar for å utføra oppdaging av taleaktivitet, automatisk oppkjenning av tale, setningsegmentasjon og maskinsomsetjing. Alle systema vart neuralbasert, inkludert eit fullstendig tilkopla neuralnettverk for oppdaging av taleaktivitet, ein Kaldi faktorisert tidspunkt på neuralnettverk med rekursært neuralnettverk (RNN) språk-modell som gjenoppretter for tale-gjenkjenning, ein bidireksjonal RNN med oppmerksmekanisme for setningsssegmentasjon, og transformerer nettverk som treng med OpenNMT og Marian for maskineomsetjing. Vårt primærsubmisasjon gjev BLEU-poeng på 21,28 på tst2019 og 23,33 på tst2020.', 'si': 'මේ වාර්තාව සම්පූර්ණයෙන් ගුවන් බලය පරීක්ෂණ ප්\u200dරශ්නය (AFRL) ප්\u200dරශ්නය සම්පූර්ණය කරනවා IWSLT 2020යි විශ්නය සම්පූර මුලින් අවුරුද්දු වලින්, අපි වෙනස් පද්ධතිය භාවිත කරන්න කැස්කේඩ් විදිහට ප්\u200dරවේශනය කරගන්න, ස්වයංක්\u200dරිය භාවිතාවක්  සියළු පද්ධතිය න්\u200dයුරාල් අධාරණය කරනවා, සියළුම සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් න්\u200dයුරාල් ජාලය හොයාගන්න, කාල්ඩි ප්\u200dරතිකාරණය කරපු වෙලාවක් න්\u200dයුරාල ජා අපේ ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන විශ්වාස කරලා බ්ලෝයුස් අං', 'ro': 'Acest raport rezumă prezentarea laboratorului de cercetare a forțelor aeriene (AFRL) la sarcina de traducere offline în limba vorbită (SLT), ca parte a campaniei de evaluare IWSLT 2020. Ca și în anii precedenți, am ales să adoptăm abordarea în cascadă a utilizării sistemelor separate pentru detectarea activității vorbirii, recunoașterea automată a vorbirii, segmentarea frazelor și traducerea automată. Toate sistemele au fost bazate pe neuroni, inclusiv o rețea neuronală complet conectată pentru detectarea activității vorbirii, o rețea neuronală cu întârziere în timp factorizată Kaldi cu modelul limbajului de rețea neurală recurentă (RNN) pentru recunoașterea vorbirii, un RNN bidirecțional cu mecanism de atenție pentru segmentarea frazelor și rețele de transformare instruite cu OpenNMT și Marian pentru traducerea automată. Prezentarea noastră primară a obținut scoruri BLEU de 21,28 pe tst2019 și 23,33 pe tst2020.', 'sv': 'Denna rapport sammanfattar Air Force Research Laboratory (AFRL) inlämnade till uppdraget offline spoken language translation (SLT) som en del av utvärderingskampanjen IWSLT 2020. Liksom tidigare år valde vi att använda kaskadmetoden att använda separata system för att utföra talaktivitetsdetektering, automatisk taligenkänning, meningssegmentering och maskinöversättning. Alla system var neurala, inklusive ett fullt uppkopplat neuralt nätverk för detektering av talaktivitet, ett Kaldi-faktoriserat tidsfördröjningsneuralt nätverk med återkommande neuralt nätverk (RNN) språkmodell som återskapar taligenkänning, ett dubbelriktat RNN med uppmärksamhetsmekanism för meningssegmentering och transformatornätverk utbildade med OpenNMT och Marian för maskinöversättning. Vår primära inlämning gav BLEU poäng på 21,28 på tst2019 och 23,33 på tst2020.', 'so': 'Reportan summarizes the Air Force Research Laboratory (AFRL) submission to the offline language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. Sidii sannadihii hore, waxaynu dooranaynay inaannu isticmaalno nidaam gooni ah si aan u sameynno aqoonsashada waxqabadka hadalka, aqoonsashada hadalka bilowga ah, qeybinta ereyga iyo turjumidda mashiinka. Sirtii oo dhan waxay ku saleysan jireen neural, including a fully-linked neural network for hadal detection, a Kaldi factorized time delay neural network with recurrent network of neural neural (RNN) model rescoring for recognition of speech, a bidirectional RNN with attention mechanism for sentence segmentation, and transforming networks trained with OpenNMT and Marian for machine translation. Sujumaadkeenii ugu horeeyay waxay soo saaray BLEU scoro 21.28 oo ku qoran tst2019 iyo 23.33 oo ku qoran tst2020.', 'ta': '@ info முந்தைய வருடங்களில், நாங்கள் பேச்சு செயல்பாடு கண்டுபிடிப்பதற்கு, தானாகவே பேச்சு குறிப்பு, வாக்கிய பிரிவு, இயந்திரம் மொழிபெயர்ப்ப அனைத்து அமைப்புகளும் பேச்சு செயல்பாடு கண்டுபிடிப்பதற்கான முழுமையாக இணைக்கப்பட்ட புதிய வலைப்பின்னல், ஒரு கால்டி தாமதமாக்கப்பட்ட நேரம் தாமதம் பின்னணி வலைப்பின்னல் இருந்தது, பேச்சு ஒதுக்கொள்வதற்கான மொழி மாதி எங்கள் முதல் பரிமாற்றத்திற்கு BLEU மதிப்புகள் வழங்கப்பட்டது tst2019 மற்றும் tst2020 மீது 23. 33.', 'ur': 'اس راپورت نے هوائی فورس تحقیقات لابراتور (AFRL) کو آفولاین کی زبان ترجمہ (SLT) کی تابع کے لئے IWSLT 2020 ارزیابی کمپین کی حصہ کے طور پر جمع کردیا ہے. جیسا پہلے سالوں میں ہم نے کاسکے کا طریقہ قبول کرنے کا انتخاب کیا تھا کہ بات فعالیت شناسایی کرنے کے لئے مختلف سیستموں کے استعمال کرنے کے لئے کاسکے کا طریقہ قبول کریں۔ تمام سیسٹم نیورال بنیاد ہیں، کلام فعالیت شناسایی کے لئے ایک پوری نئورل نیورل نیٹ ورک شامل ہوتے تھے، ایک Kaldi فاکتوری کی زمانہ دیر نیورل نیورل نیٹ ورک (RNN) کی زبان کی موڈل کی بات شناسایی کے لئے ریسکوری کرتی تھی، ایک دوسری طریقہ RNN کی جگہ مکانیسم کے ساتھ سوگنے کے مکانیسم کے ساتھ، اور مکانین ہماری اولین مسلمانی مسلمانوں نے ٹیٹ ۲۰۱۹ اور ٹیٹ ۲۰۰۲ میں ۲۱.۲۸ اور ۲۳.۳۳ مسلمانوں میں بلیوس سکور کی۔', 'uz': "@ info: status Oldingi yillarda biz gapirish harakatini aniqlash, avtomatik gapirish, bir so'zni ajratish, va mashina tarjima qilish uchun bir xil tizimlarni ishlatish uchun bir xil tizimlarni ishlatishni tanlashni tanlashni istaysiz. Name Bizning asosiy joʻnatuvchimiz tst2019 bilan 21.28 darajaga BLEU scorlarini va tst2020 bilan 23.33.", 'vi': 'Bản báo cáo này tổng hợp phòng nghiên cứu không quân (AFRL) đệ trình cho nhiệm vụ dịch ngôn ngữ ngoại tuyến (SLT) trong chiến dịch đánh giá IWSLT 2020. Như những năm trước, chúng tôi chọn cách sử dụng dây chuyền sử dụng các hệ thống khác nhau để thực hiện việc phát hiện hoạt động ngôn ngữ, nhận diện ngôn ngữ tự động, phân đoạn câu và dịch thuật máy. Tất cả hệ thống thần kinh là dựa trên hệ thần kinh, bao gồm một mạng thần kinh kết nối hoàn toàn cho việc phát hiện hoạt động ngôn ngữ, một mạng lưới thần kinh của Kaldi phân giải thời gian với hệ thống dây thần kinh thần kinh liên tục (RNN) tái tạo mô hình ngôn ngữ cho nhận dạng ngôn ngữ, một RNN phân biệt ngôn ngữ có ý nghĩa, và mạng chuyển đổi được huấn luyện với OpenNMT và Marian để dịch thiết bị máy. Việc đệ trình đầu tiên của chúng tôi đã cho thấy Vé hạng 21.8 trên tsT99 và 23.33 trên tst2020.', 'nl': 'Dit rapport vat de inzending van het Air Force Research Laboratory (AFRL) voor de offline gesproken taal vertaling (SLT) taak samen als onderdeel van de IWSLT 2020 evaluatiecampagne. Net als in voorgaande jaren hebben we gekozen voor de cascade-benadering van het gebruik van afzonderlijke systemen om spraakactiviteit detectie, automatische spraakherkenning, zinssegmentatie en machinevertaling uit te voeren. Alle systemen waren gebaseerd op neurale systemen, waaronder een volledig verbonden neuraal netwerk voor spraakactiviteit detectie, een Kaldi gefactoriseerd tijdvertragingsnetwerk met recidivierend neuraal netwerk (RNN) taalmodel voor spraakherkenning, een bidirectioneel RNN met aandachtsmechanisme voor zinssegmentatie en transformatornetwerken getraind met OpenNMT en Marian voor machinevertaling. Onze primaire inzending leverde BLEU scores op van 21.28 op tst2019 en 23.33 op tst2020.', 'bg': 'Този доклад обобщава представянето на изследователската лаборатория на ВВС в задачата за офлайн превод на говорен език (СЛТ) като част от кампанията за оценка на Международния транспорт 2020. Както и в предишните години, ние избрахме каскадния подход за използване на отделни системи за откриване на речна активност, автоматично разпознаване на речта, сегментация на изреченията и машинен превод. Всички системи са на невронна основа, включително напълно свързана невронна мрежа за откриване на речна активност, невронна мрежа Калди факторизирана с времево забавяне с повтаряща се невронна мрежа (РНН) езиков модел за разпознаване на реч, двупосочна РНН с механизъм на внимание за сегментация на изреченията и трансформаторни мрежи, обучени с OpenNMT и Мариан за машинен превод. Нашето първично представяне даде резултати от 21.28 за tst2019 и 23.33 за tst2020.', 'hr': 'Ovaj izvještaj sažetuje prijedlog istraživačke laboratorije zračne snage (AFRL) na zadatak offline govornog prevoda jezika (SLT) kao dio procjene kampanje IWSLT 2020. Kao i u prethodnim godinama, odlučili smo usvojiti pristup kaskade korištenja odvojenih sustava za otkrivanje govorne aktivnosti, priznanje automatskih govora, segmentaciju kazne i prevod strojeva. Svi sustavi su bili na neuralnoj bazi, uključujući potpuno povezanu neuralnu mrežu za otkrivanje govorne aktivnosti, Kaldi faktorizirano vrijeme odlaganja neuralne mreže sa rekonstruiranim neuralnim mrežom (RNN) jezičkim modelom za prepoznavanje govora, bidirectional RNN s pažnjom mehanizma za segmentaciju rečenica, i transformacijske mreže obučene s OpenNMT i Marian za prevod strojeva. Naša primarna predstava donijela je rezultate BLEU od 21,28 na tst2019 i 23,33 na tst2020.', 'da': 'Denne rapport opsummerer Air Force Research Laboratory (AFRL) indsendelse til opgaven offline talesprog oversættelse (SLT) som en del af IWSLT 2020 evalueringskampagnen. Som i tidligere år valgte vi at anvende kaskadetilgangen ved at bruge separate systemer til at udføre taleaktivitetsregistrering, automatisk talegenkendelse, sætningssegmentering og maskinoversættelse. Alle systemer var neurale baserede, herunder et fuldt forbundet neuralt netværk til detektering af taleaktivitet, et Kaldi factoriseret time delay neuralt netværk med tilbagevendende neuralt netværk (RNN) sprogmodel rescoring til talegenkendelse, et bidirektionelt RNN med opmærksomhedsmekanisme til sætningssegmentering, og transformer netværk uddannet med OpenNMT og Marian til maskinoversættelse. Vores primære indsendelse gav BLEU score på 21,28 på tst2019 og 23,33 på tst2020.', 'de': 'Dieser Bericht fasst die Einreichung des Air Force Research Laboratory (AFRL) zur Offline-Sprachübersetzung (SLT) im Rahmen der IWSLT 2020-Evaluierungskampagne zusammen. Wie in den Vorjahren haben wir uns für den Kaskadenansatz entschieden, getrennte Systeme zur Erkennung von Sprachaktivitäten, automatischer Spracherkennung, Satzsegmentierung und maschineller Übersetzung einzusetzen. Alle Systeme waren neuronal basiert, einschließlich eines vollständig vernetzten neuronalen Netzwerks zur Erkennung von Sprachaktivität, eines Kaldi faktorierten neuronalen Netzes mit Zeitverzögerung mit wiederkehrendem neuronalem Netzwerk (RNN) Sprachmodell für Spracherkennung, eines bidirektionalen RNN mit Aufmerksamkeitsmechanismus für Satzsegmentierung und Transformatornetze, die mit OpenNMT und Marian für maschinelle Übersetzung trainiert wurden. Unsere primäre Einreichung ergab BLEU-Scores von 21.28 am tst2019 und 23.33 am tst2020.', 'id': 'This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign.  Seperti tahun-tahun sebelumnya, kami memilih untuk mengadopsi pendekatan kaskade menggunakan sistem terpisah untuk melakukan deteksi aktivitas pidato, pengakuan pidato otomatis, segmentasi kalimat, dan terjemahan mesin. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation.  Pemberian utama kami memberikan nilai BLEU 21,28 pada tst2019 dan 23,33 pada tst2020.', 'tr': 'Bu rapor Air Force Research Laboratory (AFRL) IWSLT 2020 duýgulama kampanyasynyň bir parçasynda çykyş edilen dil terjimesine (SLT) görkezilýär. Öňki ýyllarda bolsa, biz çykyş etkinleşenleri tanamak, sözlemler segmentasy we maşynyň terjimesini ýerine ýetirmek üçin kazad metodasyny üýtgetmegi seçdik. Hemme sistemler neural netijelidir, çykyş etkinlik detectasy üçin doly baglanyşyk netral şebekesi, Kaldi faýldan geçirmek üçin zamany gollanyşyk netijeli netral şebekesi (RNN) düzümlenmek üçin gollanyşyk bilen, sözleşme segmentasiýasy üçin bir bidirektiwni RNN we maşynyň terjime etmek üçin bilim mekanizmasy bilen birleşdirdi. Biziň ilkinji teslimanymyz bolan BLEU sanlarynyň 21.28 sany 2019 we 23.33 sany t2020-de geçirdi.', 'sw': 'Ripoti hii ina muhtasari wa Laboratori ya Utafiti wa Jeshi la Ndege (AFRL) inayowasilisha tafsiri ya lugha inayozungumzwa mtandaoni (SLT) kama sehemu ya kampeni ya uchunguzi wa IWSLT 2020. Kama ilivyopita miaka iliyopita, tulichagua kuchagua mbinu za kutumia mifumo tofauti ili kutekeleza uchunguzi wa harakati za hotuba, kutambua hotuba binafsi, kutengwa kwa hukumu, na tafsiri ya mashine. Mifumo yote yalikuwa na msingi, ikiwa ni pamoja na mtandao wa neura uliohusishwa kwa ajili ya kutambua shughuli za mazungumzo, Mtandao wa muda wa muda unaotegezeka kwa muda mrefu wa neura wa Kaldi ukiwa na mtindo wa lugha unaoendelea kuboresha kutambuliwa kwa hotuba (RNN), mfumo wa kiserikali wa RNN ikiwa na mfumo wa kutoa hisia kwa ajili ya kutengwa hukumu, na kubadilisha mitandao yanayofundishwa na OpenNMT na Marian kwa ajili ya kutafsiri mashine. Ujumbe wetu wa msingi ulitoa vipimo vya BLEU 21.28 kwenye tst2019 na 23.33 kwenye tst2020.', 'ko': '이 보고서는 공군연구실(AFRL)이 제출한 오프라인 구어번역(SLT) 임무를 총괄하여 IWSLT 2020 평가 활동의 일부로 삼았다.몇 년 전과 마찬가지로 우리는 등급 연결 방법을 채택하여 단독 시스템을 이용하여 음성 활동 검측, 자동 음성 식별, 문장 분할과 기계 번역을 집행하기로 선택했다.모든 시스템은 신경 기반으로, 음성 활동 감지를 위한 전체 연결 신경 네트워크, 음성 인식을 위한 역귀환 신경 네트워크(RNN) 언어 모델을 재분류한 칼디 분해 시연 신경 네트워크, 문장 분할을 위한 주의 메커니즘을 위한 양방향 RNN 및 OpenNMT와 Marian 트레이닝을 이용한 기계 번역용 변압기 네트워크를 포함한다.우리의 초보 제출 결과에 따르면 tst2019와 tst2020에서 BLEU 점수는 각각 21.28과 23.33이었다.', 'fa': 'این گزارش آزمایشگاه تحقیقات نیروی هوایی (AFRL) را به عنوان بخشی از کمپین ارزیابی IWSLT 2020 جمع می\u200cکند. همانطور که در سال های گذشته، ما انتخاب کردیم که روش کاسکید را از استفاده از سیستم\u200cهای جدا برای انجام کشف فعالیت سخنرانی، شناسایی سخنرانی خودکار، جدایی جمله\u200cها و ترجمه\u200cهای ماشین بپذیریم. تمام سیستم\u200cها بر اساس عصبی بودند، شامل یک شبکه عصبی کاملاً متصل شده برای شناسایی فعالیت سخنرانی، شبکه عصبی را با شبکه عصبی (RNN) بازسازی مدل عصبی برای شناسایی سخنرانی، یک RNN دوره\u200cای با مکانیسم توجه برای جدا کردن جمله، و شبکه\u200cهای تغییر\u200cدهنده با OpenNMT و Marian برای ترجمه\u200cهای ماشین آموزش داده شده تحویل اولیه ما در سال ۲۰۱۹ و ۲۳.۳۳ در سال ۲۰۰۲ امتیاز BLEU را به دست آورد.', 'af': "Hierdie raporteer versamel die Air Force Research Laboratory (AFRL) onderskrywing na die offline praat taal vertaling (SLT) taak as deel van die IWSLT 2020 evalueringskampanje. Soos in vorige jaar, het ons gekies om die kaskade toegang te aanvaar om aparte stelsels te gebruik om spraak aktiviteit opskrif te doen, outomatiese spraak herken, teikenssegmentasie en masjien vertaling te doen. Alle stelsels was neurale gebaseer, insluitend 'n volledige verbinding neuralnetwerk vir spraak aktiviteit beskrywing, 'n Kaldi faktoriseer tyd vertraging neuralnetwerk met rekursieerde neuralnetwerk (RNN) taal model herkoring vir spraak herkenning, 'n bidireksjonale RNN met aandag mekanisme vir setsegmentasie, en transformeernetwerke wat met OpenNMT en Marian onderwerp is vir masjien vertaling. Ons primêre onderwerp het BLEU-rekening van 21.28 op tst2019 en 23.33 op tst2020 gegee.", 'sq': 'Ky raport përmbledh paraqitjen e Laboratorit të Kërkimit të Forcave Ajrore (AFRL) në detyrën e përkthimit të gjuhës së folur (SLT) jashtë linje si pjesë e fushatës së vlerësimit të IWSLT 2020. Si në vitet e mëparshme, ne zgjodhëm të miratojmë qasjen kaskade të përdorimit të sistemeve të veçanta për të kryer zbulimin e veprimtarisë së fjalimit, njohjen automatike të fjalimit, segmentimin e fjalëve dhe përkthimin e makinave. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation.  Paraqitja jonë kryesore dha rezultate BLEU prej 21.28 në tst2019 dhe 23.33 në tst2020.', 'am': 'ይህ ሪፖርት የአየር ኃይል ምርምርመራ ማህበረሰብ (AFRL) የድምፅ ቋንቋ ትርጓሜ (SLT) ስራ እንደ IWSLT 2020 ማስታወቂያ ዘመቻ ክፍል እንዲሰጥ ያሳያል፡፡ ባለፉት ዓመታት፣ የንግግር ተግባር ማግኘት፣ የንግግር ማስታወቂያ፣ የፍርድ ግንኙነት እና የመሳሳይ ትርጓሜ ለማድረግ የተለየውን የስርዓት ግንኙነት በመጠቀም እና የመሳሳይ ትርጉም ለመጠቀም መረጥነው፡፡ የድምፅ ስርዓቶች ሁሉ በሙሉ ግንኙነት የተጠቃሚ የኔural መረብ፣ ለንግግር ተግባር ማግኘት የተጠቃሚ የቁጥጥር ዘገየር የኔural መረብ (RNN) የሚቀጥለውን የቋንቋ ሞዴል ለንግግር ማስታወቂያውን የሚያሳድግ፣ አዳዲስ RNN በሥርዓት segmentation እና ማርያን የተጠቃሚ መረብ እንዲለውጥ እና ማርያን ለመmachine ትርጉም የተማረ መረብ ነው። Our primary submission yielded BLEU scores of 21.28 on tst2019 and 23.33 on tst2020.', 'hy': 'This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign.  Ինչպես նախորդ տարիների ընթացքում, մենք որոշեցինք օգտագործել առանձին համակարգերի օգտագործումը խոսքի ակտիվության հայտնաբերման, խոսքի ավտոմատիկ ճանաչելու, նախադասությունների սեգմետրացիայի և մեքենային թարգմանման համար: Բոլոր համակարգերը նյարդային հիմքով էին, ներառյալ խոսքի ակտիվության հայտնաբերելու ամբողջովին կապված նյարդային ցանց, Կալդի գործոնավորված ժամանակային ուշացումների նյարդային ցանց, որը կրկնվող նյարդային ցանց (ՌՆՆ) լեզվի մոդելն էր, որը վերագրում էր խոսքի ճանաչման համար, երկու ուղղությամբ ՌՆ- Մեր հիմնական ներկայացումը 2019 թ․-ի և 2020 թ․-ի ընթացքում 23.33 թ․-ի համար ստացավ ԲԼԵՎ գնահատականներ։', 'az': 'Bu xəbər Air Force Research Laboratoriyanın (AFRL) IWSLT 2020 değerlendirmə kampanyasının bir parças ı olaraq offline dil tercüməsinə (SLT) vəzifəsini yazır. Biz əvvəlki illərdə ayrı sistemləri istifadə etmək üçün kaskadın tərzini seçdik, sözlərin fəaliyyəti keşfetmək, otomatik sözlərin tanıması, cümlələrin segmentasiyası və maşına çevirilməsi üçün istifadə etmək üçün. Tüm sistemlər, sözlər fəaliyyəti keşfetmək üçün tamamilə bağlı nöral şəbəkəsi, Kaldi fəaliyyətləndirilmiş zaman gecikdirməsi nöral şəbəkəsi (RNN) dil modeli sözləri tanımlamaq üçün yenidən korumaq, cümlələr segmentasiyası üçün gözləmə mehānismi ilə müddətli RNN və maşın tercüməsi üçün OpenNMT və Marian təhsil edilən nöral şəbəkələri ilə transform Bizim ilk təklifimiz TT2019-də və TT2020-də 23.33-də BLEU müəyyən etdi.', 'bn': 'এই রিপোর্টটি বিমান বাহিনীর গবেষণা ল্যাব্রেটরির (এএএফআরএল) অফ-লাইন ভাষার অনুবাদ (এসএলটি) কাজের সারসংক্ষিপ্ত করেছে আইডউএসএলটি ২০২০ এর মূল্ পূর্ববর্তী বছরের মত, আমরা বিভিন্ন ব্যবস্থা ব্যবহার করার জন্য বিভিন্ন সিস্টেম ব্যবহারের ক্যাস্কেড পদ্ধতি গ্রহণ করতে বেছে নিলাম, কথা স্বয়ংক্ সকল সিস্টেম নিউরেল ভিত্তিক ছিল, যার মধ্যে একটি ভাষণ কার্যক্রম আবিষ্কারের জন্য পুরোপুরি সংযুক্ত নিউরেল নেটওয়ার্ক, একটি কাল্ডি ক্যাক্টরিয়েশনের সময়ের দেরি নিউরেল নেটওয়ার্কের নেটওয়ার্ক (RNN) বাক স্বীকারের জন্য আমাদের প্রাথমিক প্রদান করা টিট২০২০৯ এবং ২৩.', 'bs': 'Ovaj izvještaj sažetuje prijedlog istraživačke laboratorije zračne snage (AFRL) na temelj offline govornog prevoda jezika (SLT) kao dio procjene kampanje IWSLT 2020. Kao i u prethodnim godinama, odlučili smo usvojiti pristup kaskade korištenja odvojenih sustava za otkrivanje govorne aktivnosti, priznanje automatskog govora, segmentaciju kazne i prevod strojeva. Svi sustavi su bili neuralni bazirani, uključujući potpuno povezanu neuralnu mrežu za otkrivanje govorne aktivnosti, Kaldi faktorizirao vremensku odlaganju neuralne mreže sa rekonstruiranim neuralnim mrežom (RNN) jezičkim modelom za prepoznavanje govora, bidirectional RNN sa mehanizam pažnje za segmentaciju rečenica, i transformacijskim mrežama obučenim s OpenNMT i Marianom za prevod mašine. Naša primarna predstava donela je rezultate BLEU od 21,28 na tst2019 i 23,33 na tst2020.', 'ca': "Aquest informe resume la presentació del Laboratori d'Investigació de la Força Aérea (AFRL) a la tasca de traducció de llenguatges parlats offline (SLT) com part de la campanya d'evaluació IWSLT 2020. Com en anys anteriors, vam escollir adoptar l'enfocament cascat d'utilitzar sistemes separats per a fer detecció d'activitat de parla, reconeixement automàtic de parla, segmentació de frases i traducció màquina. Tots els sistemes estaven basats en neurones, incloent una xarxa neural plenament conectada per la detecció de l'activitat fonamental, una xarxa neural de retard temporal factoritzada en Kaldi amb un model de llenguatge de xarxa neural recurrent (RNN), un RNN bidireccional amb mecanisme d'atenció per la segmentació de frases, i xarxes de transformadors entrenats amb OpenNMT i Marian per traducció màquina. La nostra presentació primària va aportar puntuacions BLEU de 21,28 en tst2019 i 23,33 en tst2020.", 'cs': 'Tato zpráva shrnuje podání výzkumné laboratoře letectva (AFRL) k úkolu offline překladu mluveného jazyka (SLT) v rámci hodnotící kampaně IWSLT 2020. Stejně jako v předchozích letech jsme se rozhodli přijmout kaskádový přístup využívající samostatné systémy pro detekci řečové aktivity, automatické rozpoznávání řeči, segmentaci vět a strojový překlad. Všechny systémy byly založeny na neuronálech, včetně plně připojené neuronové sítě pro detekci řečové aktivity, Kaldi faktorizované neuronové sítě s recidivním neuronovým modelem (RNN) jazykového modelu pro rozpoznávání řeči, obousměrné RNN s mechanismem pozornosti pro segmentaci vět a transformátorové sítě trénované OpenNMT a Marian pro strojový překlad. Náš primární příspěvek přinesl BLEU skóre 21.28 na tst2019 a 23.33 na tst2020.', 'et': 'Käesolevas aruandes esitatakse kokkuvõte õhujõudude uuringute laboratooriumi (AFRL) esitamisest võrguühenduseta kõneleva keele tõlke ülesandele IWSLT 2020 hindamiskampaania raames. Nagu eelmistel aastatel, otsustasime kaskaadse lähenemisviisi kasutada eraldi süsteeme kõnetegevuse tuvastamiseks, automaatseks kõnetuvastuseks, lausete segmenteerimiseks ja masintõlkeks. Kõik süsteemid olid neuropõhised, sealhulgas täielikult ühendatud neuravõrk kõneaktiivsuse tuvastamiseks, Kaldi faktoriseeritud ajaviivituse neuravõrk korduva neuravõrgu (RNN) keelemudeli ümberkorraldamiseks kõnetuvastuseks, kahesuunaline RNN tähelepanumehhanismiga lausete segmenteerimiseks ning OpenNMT ja Mariani masintõlkeks koolitatud trafovõrgud. Meie esmane esitus andis BLEU tulemused tst2019. aastal 21,28 ja tst2020. aastal 23,33.', 'fi': 'Tässä raportissa esitetään yhteenveto ilmavoimien tutkimuslaboratorion (AFRL) lähettämisestä offline-puheen kielen kääntämiseen osana IWSLT 2020 -arviointikampanjaa. Edellisten vuosien tapaan valitsimme kaskadimenetelmän, jossa käytetään erillisiä järjestelmiä puheentunnistuksen, automaattisen puheentunnistuksen, lausesegmentoinnin ja konekäännöksen suorittamiseen. Kaikki järjestelmät olivat neuropohjaisia, mukaan lukien täysin yhdistetty neuroverkko puheen aktiivisuuden havaitsemiseen, Kaldi faktorisoitu aikaviive-neuroverkko toistuvilla neuraaliverkoilla (RNN) kielimallinnuksella puheentunnistukseen, kaksisuuntainen RNN lausesegmentoinnilla ja OpenNMT:llä ja Marianilla konekääntämiseen koulutetut muuntajaverkot. Ensisijainen julkaisumme tuotti BLEU-pisteet 21,28 tst2019 ja 23,33 tst2020.', 'jv': 'Ngubah iki menehi nggawe Tarjamahan Laborari (AfRL) sing berarti kanggo ngilangno urip offline (SLT) nganggo akèh ning kampanya IWSLT 2020. Taning kanggo lah sing dumadhi, kéné milih kanggo nyenggap dadi kapan kanggo ngubah sistem separahan kanggo nggawe aksi watesan, sesuk sabanjuré automatik, nggawe gerarané kapan kanggo kelas. Lair sisteme buku kelompok nggambar, misale kang sampeyan online, nggo Kemerdekaan aku Rasané sing prawih dumadhi sing paling dhéwé sawetara Balik, sing paling dhéwé paling nggawe sapa tarjamahan, sing paling dhéwé maburé, sing paling dhéwé maburé, sing paling dhéwé maburé, sing paling dhéwé mab', 'sk': 'To poročilo povzema predložitev letalskega raziskovalnega laboratorija (AFRL) v nalogo prevajanja govorjenega jezika brez povezave v okviru ocenjevalne kampanje IWSLT 2020. Tako kot v preteklih letih smo se odločili za kaskadni pristop uporabe ločenih sistemov za zaznavanje govorne aktivnosti, avtomatsko prepoznavanje govora, segmentacijo stavkov in strojno prevajanje. Vsi sistemi so bili nevronsko osnovani, vključno s popolnoma povezanim nevronskim omrežjem za zaznavanje govorne aktivnosti, Kaldijevim faktoriziranim nevronskim omrežjem za prepoznavanje govora, dvosmernim RNN z mehanizmom pozornosti za segmentacijo stavkov in transformatorskim omrežjem, usposobljenim z OpenNMT in Marian za strojno prevajanje. Naš primarni prispevek je dosegel rezultate BLEU 21,28 na tst2019 in 23,33 na tst2020.', 'ha': "@ info: status Kaman da na farko, muka zãɓi kafada ya yi amfani da shiryoyin ayuka daban-daban dõmin a yi amfani da zane-zane-zane-zane, zane gane-zane farat ɗaya, segment-salon, kuma fassarar-zane. Kulma na'urar da aka ɗauki, tare da zanen da aka haɗa shi cikakken neural wa gannaiki, wato na kaldi mai jinkiri wa lokacin da aka factori tsakanin neural da shiryarwa na daura (RNN) da misalin harshen na'ura mai maras da gyare wa gannaiki na magana, wani sauri RNN da muhalli wa muhalli wa maganar segmentation, kuma ta transform tarayya waɗanda aka yi wa shirin da Open NMT da Marian wa fassarar mashine. Our primary submission yielded BLEU scores of 21.28 on tst2019 and 23.33 on tst2020.", 'bo': 'This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. ང་ཚོས་དུས་འདི་ལྟ་བུའི་རིང་ལ། All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation. ང་ཚོའི་རྨང་ཐོག', 'he': 'הדו"ח הזה מסכם את ההעברה של מעבדת מחקר חיל האוויר (AFRL) לתרגום השפה המפורסמת מחוץ לאינטרנט (SLT) בתור חלק מהקמפיין הערכה IWSLT 2020. כמו בשנים הקודמות, בחרנו לאמץ את הגישה הקסקודית של השימוש במערכות נפרדות כדי לבצע זיהוי פעילות נאום, זיהוי נאום אוטומטי, סגמלציה משפטים, ותרגום מכונות. כל המערכות היו מבוססות על עצבים, כולל רשת עצבית מחוברת לחלוטין לזהות פעילות הנאום, רשת עצבית שעכבה זמן מופעל על ידי Kaldi עם דוגמאל שפת רשת עצבית (RNN) מתחזר להזיהוי הנאום, RNN bidirectional עם מנגנון תשומת לב לגזרת משפטים, ורשתות משתנות מאומנות עם OpenNMT ומריאן לתרגום מכונות. ההצגה העיקרית שלנו הביאה נקודות BLEU של 21.28 ב-2019 ו-23.33 ב-2020.'}
{'en': 'OPPO’s Machine Translation System for the IWSLT 2020 Open Domain Translation Task', 'ar': 'نظام الترجمة الآلية من OPPO لمهمة ترجمة المجال المفتوح IWSLT 2020', 'pt': 'Sistema de tradução automática da OPPO para a tarefa de tradução de domínio aberto IWSLT 2020', 'fr': "Le système de traduction automatique d'OPPO pour la tâche de traduction de domaine ouvert IWSLT 2020", 'es': 'Sistema de traducción automática de OPPO para la tarea de traducción de dominio abierto IWSLT 2020', 'ja': 'IWSLT 2020オープンドメイン翻訳タスクのためのOPPOの機械翻訳システム', 'ru': "OPPO 's Machine Translation System for the IWSLT 2020 Open Domain Translation Task (Система машинного перевода для задачи перевода открытых доменов IWSLT 2020)", 'hi': 'IWSLT 2020 ओपन डोमेन अनुवाद कार्य के लिए ओप्पो की मशीन अनुवाद प्रणाली', 'zh': 'OPPO 以 IWSLT 2020 开域译者机器翻译统', 'ga': 'Córas Aistriúcháin Meaisín OPPO do Thasc Aistriú Fearainn Oscailte IWSLT 2020', 'hu': 'Az OPPO gépi fordítási rendszere az IWSLT 2020 nyílt domain fordítási feladathoz', 'el': 'Το σύστημα μηχανικής μετάφρασης του ΟΠΠΑ για το έργο μετάφρασης ανοικτού τομέα', 'ka': 'OPPO-ის მაქსინური გადაწყვეტის სისტემა IWSLT 2020 გახსნა დიომინური გადაწყვეტის საქაღალდე', 'kk': 'OPPO- тың IWSLT 2020 Open Domain аудару тапсырмасының машинаны аудару жүйесі', 'it': 'Il sistema di traduzione automatica di OPPO per il compito di traduzione a dominio aperto IWSLT 2020', 'ms': 'Sistem Terjemahan Mesin OPPO untuk Tugas Terjemahan Domain Buka IWSLT 2020', 'ml': 'IWSLT 2020 തുറക്കുന്നതിനുവേണ്ടി ഓപ്പോയുടെ മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം തുറക്കുക', 'mn': 'OPPO-ын IWSLT 2020 Open Domain Translation Task', 'lt': 'OPPO mašinų vertimo sistema IWSLT 2020 atvirojo domeno vertimo užduotims', 'mk': 'Системот на машински превод на ОППО за задачата за отворен домен превод IWSLT 2020', 'pl': 'System tłumaczeń maszynowych OPPO dla zadania tłumaczenia otwartej domeny IWSLT 2020', 'ro': 'Sistemul de traducere automată al OPPO pentru sarcina de traducere a domeniului deschis IWSLT 2020', 'mt': 'Is-Sistema tat-Traduzzjoni tal-Makkinarju tal-OPPO għall-kompitu tat-Traduzzjoni Domenika Miftuħa tal-IWSLT 2020', 'no': 'OPPO sin maskineoversettelsystem for IWSLT 2020 Open Domain Translation Task', 'sr': 'OPPO-ov sistem za prevod mašine za IWSLT 2020. zadatak za prevod domena', 'si': "OPPO's machine translation system for the IWSLT 2020Open Domain translation Job", 'so': "OPPO's Machine Translation System for the IWSLT 2020 Open Domain Translation Task", 'sv': 'OPPO:s maskin철vers채ttningssystem f철r IWSLT 2020 Open Domain 횜vers채ttningsuppgift', 'ta': 'IWSLT 2020 டொமைன் மொழிபெயர்ப்பு மொழிபெயர்ப்பு அமைப்பு', 'ur': "OPPO's Machine Translation System for the IWSLT 2020 Open Domain Translation Task", 'uz': '@ info: whatsthis', 'vi': 'Hệ thống dịch cỗ máy của OPPO cho Nhiệm vụ IWSLT 2020 Open miền', 'bg': 'Системата за машинен превод на ОППО за задачата за превод с отворен домейн', 'nl': "OPPO's Machine Translation System voor de IWSLT 2020 Open Domain Translation Task", 'da': "OPPO's maskinoversættelsessystem til IWSLT 2020 Open Domain Oversættelsesopgave", 'hr': 'OPPO-ov sustav za prevod strojeva za IWSLT 2020. zadatak za prevod otvorenog domena', 'de': "OPPO's Machine Translation System für die IWSLT 2020 Open Domain Translation Task", 'id': 'Sistem Terjemahan Mesin OPPO untuk Tugas Terjemahan Domain Buka IWSLT 2020', 'ko': 'IWSLT 2020 오픈 도메인 번역 임무를 위한 OPPPO 기계 번역 시스템', 'sw': 'Mfumo wa Tafsiri wa Mashine wa OPPO kwa ajili ya IWSLT 2020 Open Translation Domain', 'tr': "OPPO'yň IWSLT 2020 Aç Saýlaw Terjime Görevi üçin Ullançy Terjime Sistemi", 'sq': 'Sistemi i përkthimit të makinave i OPPO për detyrën e përkthimit të dominit të hapur IWSLT 2020', 'am': 'የOPPO Machine Translation System for the IWSLT 2020 Open Domain Translation Task', 'af': 'OPPO se Masjien Vertaling stelsel vir die IWSLT 2020 Open Domein Vertaling Taak', 'hy': 'ՕպՕ-ի մեքենային թարգմանման համակարգը IwSLT 2020-ի բաց վայրի թարգմանման գործի համար', 'az': "IWSLT 2020 Açıq Domain Çeviri Gözməsi üçün OPPO'nun Makine Çeviri Sistemi", 'bn': "IWSLT 2020 খোলা ডোমেন অনুবাদ করার জন্য OPPO'র মেশিন অনুবাদ সিস্টেম", 'bs': 'OPPO-ov sistem za prevod mašine za zadatak IWSLT 2020 otvorenog domena', 'ca': "Sistema de traducció màquina de l'OPPO per a la tasca de traducció de domini obert IWSLT 2020", 'cs': 'Strojový překlad systém OPPO pro IWSLT 2020 Open Domain Translation Task', 'et': 'OPPO masintõlke süsteem IWSLT 2020 avatud domeeni tõlke ülesandeks', 'fi': 'OPPO:n konekäännösjärjestelmä IWSLT 2020 Open Domain Translation -tehtävään', 'fa': 'سیستم ترجمه ماشین OPPO برای تابع ترجمه دامنی باز IWSLT 2020', 'jv': "OPpo's Manual translation System for the IWSLT 2020 Open domain translation task", 'ha': '@ info: whatsthis', 'sk': 'OPPO sistem strojnega prevajanja za nalogo prevajanja odprtih domen IWSLT 2020', 'he': 'מערכת התרגום מכונות של OPPO עבור משימה התרגום הפתוח של IWSLT 2020', 'bo': "OPPO's Machine Translation System for the IWSLT 2020 Open Domain Translation Task"}
{'en': 'In this paper, we demonstrate our machine translation system applied for the Chinese-Japanese bidirectional translation task (aka. open domain translation task) for the IWSLT 2020. Our model is based on Transformer (Vaswani et al., 2017), with the help of many popular, widely proved effective data preprocessing and augmentation methods. Experiments show that these methods can improve the baseline model steadily and significantly.', 'ar': 'في هذه الورقة ، نوضح نظام الترجمة الآلية المطبق لمهمة الترجمة الصينية اليابانية ثنائية الاتجاه (المعروفة أيضًا باسم مهمة ترجمة المجال المفتوح) لـ IWSLT 2020. يعتمد نموذجنا على Transformer (Vaswani et al. ، 2017) ، بمساعدة للعديد من طرق المعالجة المسبقة وزيادة البيانات الشائعة والمثبتة على نطاق واسع. تظهر التجارب أن هذه الأساليب يمكن أن تحسن النموذج الأساسي بشكل مطرد وكبير.', 'pt': 'Neste artigo, demonstramos nosso sistema de tradução automática aplicado à tarefa de tradução bidirecional chinês-japonês (também conhecida como tarefa de tradução de domínio aberto) para o IWSLT 2020. Nosso modelo é baseado no Transformer (Vaswani et al., 2017), com a ajuda de muitos métodos de pré-processamento e aumento de dados populares e amplamente comprovados. Experimentos mostram que esses métodos podem melhorar o modelo de linha de base de forma constante e significativa.', 'fr': "Dans cet article, nous présentons notre système de traduction automatique appliqué à la tâche de traduction bidirectionnelle chinois-japonais (également appelé tâche de traduction de domaine ouvert) pour l'IWSLT 2020. Notre modèle est basé sur Transformer (Vaswani et al., 2017), à l'aide de nombreuses méthodes de prétraitement et d'augmentation de données efficaces et largement éprouvées. Les expériences montrent que ces méthodes peuvent améliorer le modèle de base de façon constante et significative.", 'es': 'En este artículo, demostramos nuestro sistema de traducción automática aplicado a la tarea de traducción bidireccional chino-japonés (también conocida como tarea de traducción de dominio abierto) para el IWSLT 2020. Nuestro modelo se basa en Transformer (Vaswani et al., 2017), con la ayuda de muchos métodos de preprocesamiento y aumento de datos populares y ampliamente probados. Los experimentos muestran que estos métodos pueden mejorar el modelo de referencia de manera constante y significativa.', 'zh': '本文者,演我机器翻译统,宜用 IWSLT 2020 中日双向翻译务(亦谓之开域译)。 吾法基于Transformer(Vaswani等,2017)假众流行,博证有效之数预处理增益之法。 实验明,可以定而著基线。', 'ja': '本稿では， IWSLT 2020の中日双方向翻訳タスク（別名，オープンドメイン翻訳タスク）に応用した機械翻訳システムを実証する．当社のモデルは、多くの人気のある、広く実証された効果的なデータ前処理および拡張方法の助けを借りて、Transformer （ Vaswani et al., 2017 ）に基づいています。実験は、これらの方法がベースラインモデルを安定して有意に改善することができることを示している。', 'hi': 'इस पेपर में, हम IWSLT 2020 के लिए चीनी-जापानी द्विदिश अनुवाद कार्य (उर्फ ओपन डोमेन अनुवाद कार्य) के लिए लागू हमारी मशीन अनुवाद प्रणाली का प्रदर्शन करते हैं। हमारा मॉडल ट्रांसफॉर्मर (वासवानी एट अल. 2017) पर आधारित है, जिसमें कई लोकप्रिय, व्यापक रूप से साबित हुए प्रभावी डेटा प्रीप्रोसेसिंग और वृद्धि के तरीकों की मदद से। प्रयोगों से पता चलता है कि ये विधियां बेसलाइन मॉडल को लगातार और महत्वपूर्ण रूप से सुधार सकती हैं।', 'ru': 'В этой статье мы демонстрируем нашу систему машинного перевода, применяемую для китайско-японской двунаправленной задачи перевода (также известной как задача перевода в открытом домене) для IWSLT 2020. Наша модель основана на Transformer (Vaswani et al., 2017), с помощью многих популярных, широко зарекомендовавших себя эффективных методов предварительной обработки и дополнения данных. Эксперименты показывают, что эти методы могут постоянно и значительно улучшать базовую модель.', 'ga': 'Sa pháipéar seo, léirímid ár gcóras aistriúcháin meaisín a cuireadh i bhfeidhm ar an tasc aistriúcháin déthreorach Síneach-Seapánach (aka. tasc aistriúcháin fearann oscailte) don IWSLT 2020. Tá ár múnla bunaithe ar Transformer (Vaswani et al., 2017), le cabhair as go leor modhanna éifeachtacha réamhphróiseála agus méadaithe sonraí a bhfuil tóir orthu, cruthaithe go forleathan. Léiríonn turgnaimh gur féidir leis na modhanna seo an múnla bunlíne a fheabhsú go seasta agus go suntasach.', 'hu': 'Ebben a tanulmányban bemutatjuk a kínai-japán kétirányú fordítási feladatra (azaz nyílt domain fordítási feladatra) alkalmazott gépi fordítási rendszerünket az IWSLT 2020-ra. Modellünk a Transformeren alapul (Vaswani et al., 2017), számos népszerű, széles körben bizonyított hatékony adatfeldolgozási és kiterjesztési módszer segítségével. A kísérletek azt mutatják, hogy ezek a módszerek folyamatosan és jelentősen javíthatják az alapmodellt.', 'it': "In questo articolo, mostriamo il nostro sistema di traduzione automatica applicato per l'attività di traduzione bidirezionale cinese-giapponese (aka attività di traduzione a dominio aperto) per l'IWSLT 2020. Il nostro modello si basa su Transformer (Vaswani et al., 2017), con l'aiuto di molti metodi popolari e ampiamente dimostrati efficaci di pre-elaborazione e aumento dei dati. Gli esperimenti dimostrano che questi metodi possono migliorare il modello di base in modo costante e significativo.", 'el': 'Σε αυτή την εργασία, παρουσιάζουμε το σύστημα μηχανικής μετάφρασης που εφαρμόστηκε για την εργασία κινεζικής-ιαπωνικής αμφίδρομης μετάφρασης (γνωστή και ως εργασία μετάφρασης ανοικτού τομέα) για το IWSLT 2020. Το μοντέλο μας βασίζεται στον μετασχηματιστή (Βασουάνι κ.α., 2017), με τη βοήθεια πολλών γνωστών, ευρέως αποδεδειγμένων αποτελεσματικών μεθόδων προεπεξεργασίας και αύξησης δεδομένων. Τα πειράματα δείχνουν ότι αυτές οι μέθοδοι μπορούν να βελτιώσουν σταθερά και σημαντικά το μοντέλο βάσης.', 'ka': 'ჩვენ ჩვენი მანქანის გაგრძელების სისტემა ჩინეთ-იაპონური გაგრძელების რაოდენობისთვის გამოყენებული ჩინეთ-იაპონური გაგრძელების რაოდენობისთვის გამოყენება (ან ჩვენი მოდელი ტრანსპერსერის (Vaswani et al., 2017) დაბაზიან, რამდენიმე პოლიპური, ძალიან გამოწმებული ეფექტიური მონაცემების პრეპროცესი და აგგენტაციის მეტოდე ექსპერიმენტები ჩვენებს, რომ ეს მეტები შეუძლებელია გასაკეთებლად და მნიშვნელოვანი მოდელს.', 'mk': 'Во овој весник, ние го демонстрираме нашиот систем на машински превод аплициран за кинеско-јапонското дводречен превод задача (alias open domain translation task) за IWSLT 2020. Нашиот модел е базиран на Трансформер (Васани и други, 2017), со помош на многу популарни, широко докажани ефикасни методи за препроцес и зголемување на податоците. Експериментите покажуваат дека овие методи можат постојано и значително да го подобрат основниот модел.', 'kk': 'Бұл қағазда, IWSLT 2020 үшін Қытай- Жапон қолданылатын компьютерді аудару жүйесімізді көрсетедік. Біздің үлгіміз Трансферлерге (Vaswani et al., 2017) негізделген, көпшілікті, көпшілікті, көпшілікті деректерді преprocessing және augmentation әдістерінің көмегімен қолданылады. Тәжірибелер бұл әдістер негізгі үлгісін дұрыс және маңызды жасай алады.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ യന്ത്രത്തിന്റെ പരിഭാഷ സിസ്റ്റം ചൈനീസ്-ജപ്പാനികളുടെ ബിഡിയര്\u200dട്ടിഷന്\u200d പരിഭാഷണ ജോലിക്കായി പ്രയോഗിച്ചിരിക ഞങ്ങളുടെ മോഡല്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200dസ്\u200c (വാസ്വാനി എറ്റ് അല്\u200d 2017) അടിസ്ഥാനത്താണ്, വളരെ പ്രധാനപ്പെട്ടവരുടെ സഹായത്തില്\u200d, വ്യാപ്തരായ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ഈ രീതികള്\u200dക്ക് ബെസ്ലൈന്\u200d മോഡല്\u200d സ്ഥിരമായും പ്രാധാനപ്പെ', 'lt': 'Šiame dokumente parodome savo mašininio vertimo sistemą, kuri buvo taikoma dvikryptiniam vertimo darbui Kinijos ir Japonijos kalbomis (taip pat atviro domeno vertimo darbui) pagal IWSLT 2020. Mūsų model is grindžiamas Transformer (Vaswani et al., 2017), padedant daugeliui populiarių, plačiai įrodytų veiksmingų duomenų apdorojimo ir didinimo metodų. Eksperimentai rodo, kad šie metodai gali nuolat ir reikšmingai pagerinti pradinį model į.', 'ms': 'Dalam kertas ini, kami menunjukkan sistem terjemahan mesin kami yang dipakai untuk tugas terjemahan bidireksi Cina-Jepun (alias tugas terjemahan domain terbuka) untuk IWSLT 2020. Model kami berdasarkan Transformer (Vaswani et al., 2017), dengan bantuan ramai rakyat, terbukti secara luas berkesan cara pemprosesan data dan peningkatan. Eksperimen menunjukkan bahawa kaedah ini boleh meningkatkan model dasar secara terus-menerus dan secara signifikan.', 'mt': 'F’dan id-dokument, qed nippruvaw is-sistema tagħna ta’ traduzzjoni bil-magni applikata għall-kompitu ta’ traduzzjoni bidirezzjonali Ċiniż-Ġappuniż (magħruf ukoll bħala kompitu ta’ traduzzjoni b’dominju miftuħ) għall-IWSLT 2020. Il-mudell tagħna huwa bbażat fuq it-Transformer (Vaswani et al., 2017), bl-għajnuna ta’ ħafna metodi popolari, li ġew ippruvati b’mod wiesa’ effettivi ta’ pproċessar ta’ data minn qabel u ta’ żieda. L-esperimenti juru li dawn il-metodi jistgħu jtejbu l-mudell tal-linja bażi b’mod stabbli u sinifikanti.', 'no': 'I denne papiret viser vi maskinsomsetjingssystemet vårt som er brukt for det kinesiske-japanske bidireksjonale omsetjingssoppgåva (t.d. open domain translation task) for IWSLT 2020. Modellen vårt er basert på Transformer (Vaswani et al., 2017), med hjelp av mange populære, breidde viste effektive dataforhandlingsmetoder og augmentasjon. Eksperiment viser at desse metodane kan forbetra baseline-modellen stabil og betydelig.', 'pl': 'W niniejszym artykule przedstawiamy nasz system tłumaczeń maszynowych stosowany do zadania tłumaczenia dwukierunkowego chińsko-japońskiego (tzw. zadania tłumaczenia otwartej domeny) dla IWSLT 2020. Nasz model oparty jest na Transformerze (Vaswani et al., 2017), z pomocą wielu popularnych, powszechnie sprawdzonych metod wstępnego przetwarzania i rozszerzania danych. Eksperymenty pokazują, że metody te mogą stale i znacząco ulepszać model bazowy.', 'ro': 'În această lucrare, demonstrăm sistemul nostru de traducere automată aplicat pentru sarcina de traducere bidirecțională chineză-japoneză (alias sarcina de traducere a domeniului deschis) pentru IWSLT 2020. Modelul nostru se bazează pe Transformer (Vaswani et al., 2017), cu ajutorul multor metode populare, dovedite pe scară largă eficiente de prelucrare și augmentare a datelor. Experimentele arată că aceste metode pot îmbunătăți modelul de bază constant și semnificativ.', 'si': 'මේ පත්තරේ අපි පෙන්වන්නේ අපේ මැෂින් වාර්තාව පද්ධතිය IWSLT 2020ට චීනි-ජාපානි වාර්තාවික වැඩ සඳහා ප්\u200dරයෝජනය කරනවා. අපේ මෝඩල් අධාරිත වැස්වානී ට්රාන්ෆර් එක්ක (වාස්වානී ට් ල්., 2017) වෙනුවෙන්, ප්\u200dරජාතිකාරයෝ ගොඩක් උදව් සමග පරීක්ෂණය පෙන්වන්න පුළුවන් මේ විදියට මූලික මොඩේල් එක ස්ථිර විශේෂය සහ විශේෂයෙන් ව', 'so': 'Qoraalkan waxaynu muujinnaa nidaamka turjumista machine-machine ee loo codsaday shaqada tarjumaadda Chinese-Japanese bidirectional translation (aka. open domain translation mission) for the IWSLT 2020. Tusaalkayagu wuxuu ku saleysan yahay turjumista (Vaswani et al., 2017), iyadoo caawiya qaababka dadka badan oo aad u maamulan, waxaa lagu xaqiijiyey qaabab faa’iido ah oo ka horumarinta macluumaadka iyo horumarinta. Imtixaanka waxaa muujin kara in qaababkan lagu hagi karo qaababka aasaasiga ah si joogto ah iyo si muhiim ah.', 'sr': 'U ovom papiru pokazujemo naš sistem prevoda mašine koji se prijavio za zadatak kineskog-japanskog dvoričnog prevoda (takođe otvoren zadatak prevoda domena) za IWSLT 2020. Naš model je baziran na Transformeru (Vaswani et al., 2017), uz pomoć mnogih popularnih, široko dokazanih efikasnih metoda preobrade i povećanja podataka. Eksperimenti pokazuju da ove metode mogu stabilno i značajno poboljšati početni model.', 'mn': 'Энэ цаасан дээр бид машин орчуулах системийг IWSLT 2020-д Хятад-Японы хоёр дахь орчуулах үйлдлийг ашиглаж байгааг харуулж байна. Бидний загвар бол Трансформер (Васвани и аль., 2017) дээр суурилсан. Манай олон алдарт хүмүүсийн тусламжтайгаар маш их үр дүнтэй мэдээллийн өмнө үйлдвэрлэх болон нэмэгдүүлэх арга замыг батал Эдгээр арга нь суурь шугам загварыг тогтмол, чухал сайжруулж чадна гэдгийг харуулж байна.', 'sv': 'I den h채r uppsatsen visar vi v책rt maskin철vers채ttningssystem som till채mpats f철r den kinesiska-japanska tv책riktade 철vers채ttningsuppgiften (채ven kallad 철ppen dom채n철vers채ttning) f철r IWSLT 2020. V책r modell 채r baserad p책 Transformer (Vaswani et al., 2017), med hj채lp av m책nga popul채ra, bepr철vade effektiva databehandlings- och f철rst채rkningsmetoder. Experiment visar att dessa metoder kan f철rb채ttra baslinjen stadigt och avsev채rt.', 'ta': 'இந்த காகிதத்தில், IWSLT 2020 க்கு எங்கள் இயந்திர மொழிபெயர்ப்பு அமைப்பை காட்டுகிறது சீன- ஜப்பானிய மொழிபெயர்ப்பு பணிக்கு (aka. திறந்த ட எங்கள் மாதிரி மாற்றும் அடிப்படையில் உள்ளது (வாஸ்வானி மற்றும் அல்., 2017) பல பிரபலமாக, விரிவாக தெளிவாக்கப்பட்டுள்ள தகவல் முன்செயல் இந்த முறைகள் அடிப்படைக்கோட்டின் மாதிரியை மேம்படுத்த முடியும் என்பதை காட்டுகிறது.', 'ur': 'اس کاغذ میں، ہم نے اپنے ماشین ترجمہ سیسٹم کو IWSLT 2020 کے لئے چانین-جاپانی دومین ترجمہ کا تابع (یعنی دومین ترجمہ تابع) کے لئے پکارا تھا۔ ہماری مدل تغییر پھیلانے والے (Vaswani et al., 2017) پر بنیاد ہے، بہت سی جماعت کی مدد کے ساتھ، بہت زیادہ اثر دکھانے والی دکھانے والی پیش پردازی اور افزایش طریقوں کے مطابق۔ تجربے دکھاتے ہیں کہ یہ طریقے بنیاد لین موڈل کو ثابت قدم اور اہم طریقے سے بہتر کر سکتے ہیں۔', 'uz': "Bu qogʻozda, biz IWSLT 2020 uchun Xitoycha- Yapon bilan bir xitoycha tarjima vazifasi (aka. open domain translation vazifasi) uchun qoʻllanmizni ko'rsatdik. Bizning modelmiz Vaswani et al 2017 (Vaswani et al., 2017) asosida, ko'pchilik, ko'pchilik maʼlumotni koʻchirish va qoʻshish usullarini yordam bilan juda katta ishlaydi. Tajribalar bu usullar asboblar modelini steady va muhim oshirish mumkin.", 'vi': 'Trong tờ giấy này, chúng tôi chứng minh hệ thống dịch chuyển máy của chúng tôi được áp dụng cho nhiệm vụ dịch chuyển tức thời Trung Quốc và Nhật Bản (tức thời dịch vụ miền mở) cho IWSLT 2020. The model of Our model is based on transformer (vaswani et al., 2007), with the help of many popular, widely produced effectively data pre treatment and Augmention methods. Thí nghiệm cho thấy những phương pháp này có thể cải thiện mô hình cơ bản một cách chắc chắn và đáng kể.', 'bg': 'В настоящата статия демонстрираме нашата система за машинен превод, приложена за задачата Китайско-японски двупосочен превод (позната още като задача за превод с отворен домейн) за Международния транспорт 2020. Нашият модел е базиран на Трансформатор (Васвани и др., 2017), с помощта на много популярни, широко доказани ефективни методи за предварителна обработка и увеличаване на данни. Експериментите показват, че тези методи могат да подобрят базовия модел постоянно и значително.', 'nl': 'In dit artikel demonstreren we ons machinevertaalsysteem toegepast voor de Chinees-Japanse bidirectionele vertaaltaak (ook bekend als open domein vertaaltaak) voor de IWSLT 2020. Ons model is gebaseerd op Transformer (Vaswani et al., 2017), met behulp van vele populaire, wijd bewezen effectieve data preprocessing en augmentatie methoden. Uit experimenten blijkt dat deze methoden het basismodel gestaag en significant kunnen verbeteren.', 'da': 'I denne artikel demonstrerer vi vores maskinoversættelsessystem, der er anvendt til den kinesisk-japanske bidirektionelle oversættelsesopgave (alias open domain oversættelsesopgave) for IWSLT 2020. Vores model er baseret på Transformer (Vaswani et al., 2017), ved hjælp af mange populære, bredt beviste effektive data forbehandling og augmentation metoder. Eksperimenter viser, at disse metoder kan forbedre baseline modellen støt og betydeligt.', 'hr': 'U ovom papiru pokazujemo naš sustav prevoda mašine prijavljen za zadatak kineskog-japanskog dvoričnog prevoda (također otvoren zadatak prevoda domena) za IWSLT 2020. Naš model je baziran na transformeru (Vaswani et al., 2017), uz pomoć mnogih popularnih, široko dokazanih učinkovitih metoda preobrade i povećanja podataka. Eksperimenti pokazuju da te metode mogu stabilno i značajno poboljšati početni model.', 'de': 'In diesem Beitrag demonstrieren wir unser maschinelles Übersetzungssystem für die bidirektionale Übersetzungsaufgabe Chinesisch-Japanisch (auch Open Domain Translation Task genannt) für die IWSLT 2020. Unser Modell basiert auf Transformer (Vaswani et al., 2017), mit Hilfe vieler beliebter, weithin bewährter Methoden zur Datenvorverarbeitung und -augmentation. Experimente zeigen, dass diese Methoden das Basismodell stetig und signifikant verbessern können.', 'fa': 'در این کاغذ، ما سیستم ترجمه ماشین خود را نشان می دهیم که برای کار ترجمه دومین چینی-ژاپنی (به عنوان وظیفه ترجمه دومین باز) برای IWSLT 2020 درخواست شده است. مدل ما بر اساس تغییر دهنده (Vaswani et al., 2017) است، با کمک بسیاری از روش\u200cهای پیش\u200cپردازی و افزایش داده\u200cهای محبوب و عمومی ثابت شده است. تجربه\u200cها نشان می\u200cدهند که این روش\u200cها می\u200cتوانند مدل پایین و معمولاً بهتر شود.', 'id': 'Dalam kertas ini, kami menunjukkan sistem terjemahan mesin kami yang dipakai untuk tugas terjemahan bidireksi Cina-Jepang (alias tugas terjemahan domain terbuka) untuk IWSLT 2020. Model kami berdasarkan Transformer (Vaswani et al., 2017), dengan bantuan dari banyak popular, terbukti secara luas efektif metode pemprosesan dan peningkatan data. Eksperimen menunjukkan bahwa metode ini dapat meningkatkan model dasar secara konstan dan signifikan.', 'ko': '본고에서 우리는 IWSLT2020 중일 양방향 번역 임무(또는 개방역 번역 임무)에 응용되는 기계 번역 시스템을 보여 주었다.우리의 모델은 Transformer(Vaswani et al., 2017)를 바탕으로 많은 유행하고 효과적인 데이터의 사전 처리와 증강 방법을 빌렸다.실험에 의하면 이러한 방법은 안정적이고 현저하게 기선 모델을 개선할 수 있다.', 'sw': 'Katika gazeti hili, tunaonyesha mfumo wetu wa kutafsiri mashine uliotumika kwa ajili ya kazi ya tafsiri ya Kichina na Japani (kwa mujibu wa utafsiri wa domain) kwa ajili ya IWSLT 2020. Mradi wetu una msingi wa Transformer (Vaswani et al., 2017), kwa msaada wa watu wengi maarufu, ulithibitishwa kuwa na ufanisi wa upasuaji wa data na kuongeza njia za kuongeza. Majaribio yanaonyesha kuwa mbinu hizi zinaweza kuboresha muundo wa msingi kwa nguvu na kwa kiasi kikubwa.', 'tr': 'Bu kagyzda, IWSLT 2020 üçin hytaý-japonça terjime täblisasyna uygulanan maşynlarymyzy görkezilýäris. Biziň modelimiz Transformer(Vaswani et al., 2017), köp populer adamlaryň kömegi bilen täsirli maglumaty önlemek we önlemek taryşlaryna dayandyrylýar. Experiimentler bu metodlaryň esasy çyzgylyň nusgasyny daýardan we möhüm şekilde gowurap biljekdigini görkezýär.', 'sq': 'Në këtë letër, ne demonstrojmë sistemin tonë të përkthimit të makinës aplikuar për detyrën kinez-japoneze të përkthimit dy-drejtues (alias open domain translation task) për IWSLT 2020. Modeli ynë është bazuar në Transformer (Vasvani et al., 2017), me ndihmën e shumë metodave të popullore, të vërtetuara gjerësisht efektive të përdorimit dhe rritjes së të dhënave. Eksperimentet tregojnë se këto metoda mund të përmirësojnë modelin bazë në mënyrë të qëndrueshme dhe të konsiderueshme.', 'am': 'በዚህ ካላት፣ ለIWSLT 2020 የቻይና-ጃፓን-የጃፓን ባለሥልጣዊ ትርጉም ማድረግ የተጠቀመውን የmachine ትርጉም ስርዓታችንን እናሳያቸዋለን፡፡ ሞዴሌያችን በተለየ (Vaswani et al., 2017) በብዙዎች ሰዎች እርዳታ የዳታ መዘርጋት እና የአደጋጋጋጀት ሥርዓት በማድረግ የተመሠረተ ነው፡፡ ፈተናዎች እነዚህ ሥርዓቶች በጥጋት እና በጥቅልቅ ማሻሻል እንዲችሉ ያሳያል፡፡', 'af': 'In hierdie papier wys ons masjien vertaling stelsel toegewend vir die Sjinese-Japaanse bidireksjonale vertaling taak (dus. open domein vertaling taak) vir die IWSLT 2020. Ons model is gebaseer op Transformer (Vaswani et al., 2017), met die hulp van baie populêre, vaste effektiewe data voorbereiding en augmentasie metodes. Eksperimente wys dat hierdie metodes die basis model stadig en betekeurig kan verbeter.', 'hy': 'Այս աշխատանքում մենք ցույց ենք տալիս մեր մեքենային թարգմանման համակարգը, որը կիրառվել է Չինաստանի-Ճապոնիայի երկու ուղղությամբ թարգմանման խնդրի համար (հայտնի է որպես բաց տիեզերքի թարգմանման խնդիր) IW-2020-ի համար: Մեր մոդելը հիմնված է Transforme-ի վրա (Վասվանին և այլն., 2017), օգնելով շատ հայտնի, լայնորեն ապացուցել արդյունավետ տվյալների նախամշակման և աճի մեթոդներին: Փորձարկումները ցույց են տալիս, որ այս մեթոդները կարող են կայուն և նշանակալի բարելավել հիմնական մոդելը:', 'bn': 'এই কাগজটিতে আমরা আমাদের মেশিন অনুবাদ সিস্টেম প্রদর্শন করছি যা চীন-জাপানী বিদ্যুৎ অনুবাদের কাজের জন্য প্রয়োগ করা হয়েছে (যা খোলা ডোমেইন অনুব আমাদের মডেল ট্রান্সফ্রান্সফারের ভিত্তিতে রয়েছে (ভাসুয়ানি এন্ট আল ২০১৭), অনেক জনপ্রিয়, ব্যাপক প্রমাণিত তথ্য প্রক্রিয়া এবং ব পরীক্ষাগুলো দেখাচ্ছে যে এই পদ্ধতি স্থায়ীভাবে আর গুরুত্বপূর্ণ ভাবে উন্নত করতে পারে।', 'bs': 'U ovom papiru pokazujemo naš sistem prevoda mašine koji se prijavio za zadatak kineskog-japanskog dvodirektivnog prevoda (također otvoren zadatak prevoda domena) za IWSLT 2020. Naš model je baziran na Transformeru (Vaswani et al., 2017), uz pomoć mnogih popularnih, široko dokazanih učinkovitih metoda preobrade i povećanja podataka. Eksperimenti pokazuju da te metode mogu stabilno i značajno poboljšati početni model.', 'az': 'Bu kağızda, maşınımızın çevirim sistemini IWSLT 2020 üçün Çin-Japon iki dərəcəli çevirim işi üçün istifadə edirik. Bizim modelimiz Transformer (Vaswani et al., 2017) ilə dayanılır, çoxlu məşhur, çoxlu faydalı məlumatların əvvəlcə işləməsi və artırma metodlarının yardımıyla. Həqiqətən, təcrübələr bu metodların temel modelini möhkəm və möhkəm təmizləyə biləcəyini göstərir.', 'ca': "En aquest article demostram el nostre sistema de traducció màquina aplicat a la tasca de traducció bidireccional xinès-japonès (anomenada tasca de traducció de domini obert) de l'IWSLT 2020. El nostre model es basa en Transformer (Vaswani et al., 2017), amb l'ajuda de molts mètodes populars i eficaces de preprocessió i augmentació de dades. Experiments show that these methods can improve the baseline model steadily and significantly.", 'et': 'Käesolevas töös tutvustame meie masintõlkesüsteemi, mida rakendatakse IWSLT 2020. aasta Hiina-Jaapani kahesuunalise tõlke ülesandele (ehk avatud domeeni tõlke ülesandele). Meie mudel põhineb Transformeril (Vaswani et al., 2017) paljude populaarsete, laialdaselt tõestatud tõhusate andmete eeltöötlus- ja suurendamismeetodite abil. Katsed näitavad, et need meetodid võivad baasmudelit pidevalt ja oluliselt parandada.', 'cs': 'V tomto článku demonstrujeme náš systém strojového překladu aplikovaný pro čínsko-japonský obousměrný překlad (tzv. open domain translation úloha) pro IWSLT 2020. Náš model je založen na Transformeru (Vaswani et al., 2017), s pomocí mnoha populárních, široce osvědčených metod předzpracování a rozšíření dat. Experimenty ukazují, že tyto metody mohou trvale a výrazně zlepšovat základní model.', 'fi': 'T채ss채 artikkelissa esittelemme konek채채nn철sj채rjestelm채채mme, jota on sovellettu kiina-japani-kaksisuuntaiseen k채채nn철steht채v채채n (eli avoimen verkkotunnuksen k채채nn철steht채v채채n) IWSLT 2020 -ohjelmassa. Mallimme perustuu Transformeriin (Vaswani et al., 2017) monien suosittujen, laajalti todistettujen tehokkaiden tietojen esik채sittely- ja augmentaatiomenetelmien avulla. Kokeet osoittavat, ett채 n채m채 menetelm채t voivat parantaa perusmallia tasaisesti ja merkitt채v채sti.', 'ha': "@ info: whatsthis @ info: whatsthis Kayan jarrabai sun nuna cewa, waɗannan hanyoyin za'a iya kyautata misalin layin basuɗan daidai da mai girma.", 'he': 'בעיתון הזה, אנו מציגים את מערכת התרגום המכונית שלנו שהופעלה לתפקיד התרגום השני-יפני (alias open domain translation task) של IWSLT 2020. המודל שלנו מבוסס על Transformer (Vaswani et al., 2017), עם עזרה של הרבה פופולריים, מוכיחים באופן רחב שיטות התמודדות נתונים יעילות. ניסויים מראים שהשיטות האלה יכולות לשפר את הדוגמא הבסיסית באופן קבוע ובמשמעותי.', 'sk': 'V prispevku predstavljamo naš sistem strojnega prevajanja, ki je bil prijavljen za kitajsko-japonsko dvosmerno prevajalsko nalogo (oziroma prevajalsko nalogo odprte domene) za IWSLT 2020. Naš model temelji na Transformerju (Vaswani et al., 2017), s pomočjo številnih priljubljenih, široko dokazanih učinkovitih metod predobdelave in povečevanja podatkov. Poskusi kažejo, da lahko te metode stalno in znatno izboljšajo osnovni model.', 'jv': 'Nan pepulan iki, kita mulai sistem tarjamahan kanggo nyengkuyung kanggo kelas Jepang-Jepang Biireksyonal terjamahan (akha. open domain translation task) kanggo IWSLT 2020. Awakdhéwé model kang basa karo Transformer (VaSwai et al), lan bantuan akeh populer, dadi wis babagan barang pengguna-pengguna ngon sistem yang cukup bantuan. Isopo sing ngomong nik kuwi method sing isa nggawe model sing bisa diagonan lan akeh liyane', 'bo': 'In this paper, we demonstrate our machine translation system applied for the Chinese-Japanese bidirectional translation task (aka. open domain translation task) for the IWSLT 2020. ང་ཚོའི་མ་དབྱིབས་འདིས་བཟོ་བརྒྱུད་པ་ཞིག་དང་། ལག་ལེན་བྱེད་དགོས་མིན་འདི་དག་གི་རྨན་གཞི་འདིས་སྟངས་བདེ་འཇགས་ངང་ཞིག་ཏུ་ཡར་རྒྱས་གཏོང་།'}
{'en': 'Character Mapping and Ad-hoc Adaptation : Edinburgh’s IWSLT 2020 Open Domain Translation System', 'ar': 'رسم الخرائط والتكيف المخصص: نظام ترجمة المجال المفتوح IWSLT 2020 في إدنبرة', 'pt': 'Mapeamento de Caracteres e Adaptação Ad-hoc: Sistema de Tradução de Domínio Aberto IWSLT 2020 de Edimburgo', 'es': 'Mapeo de caracteres y adaptación ad hoc: el sistema de traducción de dominio abierto IWSLT 2020 de Edimburgo', 'fr': "Cartographie des caractères et adaptation ad hoc\xa0: le système de traduction de domaine ouvert IWSLT 2020 d'Édimbourg", 'ja': 'キャラクターマッピングとアドホックアダプテーション：エディンバラのIWSLT 2020オープンドメイン翻訳システム', 'zh': '角色映临时改编:爱丁堡IWSLT 2020开放域译系统', 'hi': 'चरित्र मानचित्रण और तदर्थ अनुकूलन: एडिनबर्ग के IWSLT 2020 ओपन डोमेन अनुवाद प्रणाली', 'ru': 'Картографирование персонажей и специальная адаптация: система перевода открытых доменов IWSLT 2020 в Эдинбурге', 'ga': 'Mapáil Carachtair agus Oiriúnú Ad-hoc: Córas Aistriúcháin Fearainn Oscailte IWSLT 2020 Dhún Éideann', 'ka': "Character Mapping and Ad- hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'el': 'Χαρτογράφηση χαρακτήρων και προσαρμογή ad hoc: Το σύστημα μετάφρασης ανοικτού τομέα του Εδιμβούργου', 'hu': 'Karaktertérkép és ad-hoc adaptáció: Edinburgh IWSLT 2020 nyílt domain fordítási rendszere', 'it': 'Mappatura dei caratteri e adattamento ad hoc: il sistema di traduzione a dominio aperto IWSLT 2020 di Edimburgo', 'lt': "Character Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'kk': 'Таңбалар картасын және Ad- hoc адаптациясы: Эдинбург IWSLT 2020 Open Domain Translation System', 'mk': 'Мапирање на знаци и адхок адаптација: Единбуршкиот IWSLT 2020 отворен домен преведувачки систем', 'ms': 'Penapisan Aksara dan Penyesuaian Ad-hoc: Sistem Terjemahan Domain Buka IWSLT 2020 Edinburgh', 'mt': 'IWSLT 2020 Open Domain Translation System', 'ml': 'എഡിന്\u200dബര്\u200dഗിന്\u200dറെ IWSLT 2020 തുറക്കുന്ന ഡൊമെയിന്\u200d പരിഭാഷ സിസ്റ്റം തുറക്കുക', 'pl': 'Mapowanie znaków i adaptacja ad hoc: Edynburgski system tłumaczeń otwartych domen IWSLT 2020', 'mn': 'Хэрэглэгчийн газрын зураг болон Ad-hoc адаптация: Эдинбургийн IWSLT 2020 Open Domain Translation System', 'no': 'Teikn- karting og ad- hoc- adaptasjon: Edinburgh sin IWSLT 2020 Open Domain Translation System', 'sr': 'Mapiranje karaktera i ad-hoc adaptacija: Edinburgov IWSLT 2020. sustav otvorenog domena prevoda', 'ro': 'Maparea caracterelor și adaptarea ad-hoc: sistemul de traducere a domeniului deschis IWSLT 2020 din Edinburgh', 'si': 'අක්ෂර මැප්පින් සහ අඩ්- හෝක් අනුවිධානය: එඩිබර්න්ගුන්ගේ IWSLT 202 විවෘත ඩොමේන් අවවාද පද්ධති', 'so': "Shirkad Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'sv': 'Teckenkartläggning och ad hoc-anpassning: Edinburghs IWSLT 2020 Open Domain Translation System', 'ta': "எழுத்து வரைப்படம் மற்றும் அட்- ஹோக் மாற்றம்: Edinburgh's IWSLT 2020 திறந்த டொமைன் மொழிபெயர்ப்பு அமைப்பு", 'ur': "Character Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'uz': 'KChart tahrirchi va Adaptasi: Edinburgh IWSLT 2020 Ochiq Domen tarjima tizimi', 'vi': 'Bản đồ ký tự và s ửa đổi đặc biệt: Hệ thống dịch nội thất Open Domain của Edinburgh', 'bg': 'Картография на знаците и адаптация: Единбургската система за превод с отворен домейн', 'da': 'Tegnkortlægning og ad-hoc tilpasning: Edinburghs IWSLT 2020 Open Domain Oversættelsessystem', 'nl': 'Character Mapping en Ad-hoc aanpassing: Edinburghs IWSLT 2020 Open Domain Translation System', 'hr': 'Mapiranje karaktera i Ad-hoc Adaptacija: Edinburgov IWSLT 2020 Otvoreni sustav prevoda domena', 'de': 'Character Mapping und Ad-hoc-Anpassung: Edinburghs Open Domain Translation System IWSLT 2020', 'ko': '문자 매핑 및 특수 적응: 에든버러 IWSLT 2020 오픈 도메인 번역 시스템', 'id': 'Peta Karakter dan Adaptasi Ad-hoc: Sistem Translation Domain Buka IWSLT 2020 Edinburgh', 'fa': 'نقشه\u200cسازی و تغییرات عادت هوک: سیستم ترجمه\u200cسازی دامین باز IWSLT ۲۰۰۲ ادینبورگ', 'sw': "Character Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'af': 'Karakter Kaart en Ad- hoc Adaptasie: Edinburgh se IWSLT 2020 Open Domein Vertaling System', 'sq': 'hartimi i karaktereve dhe përshtatja ad hoc: Sistemi i Traktatimit të Domenit të Hapur IWSLT 2020 i Edinburgut', 'am': 'አዲስ ዶሜን ትርጉም', 'hy': 'Սեմպերի քարտեզագրությունը և հատուկ ադապտացիան. Էդինբուրգի IwPLT 2020 բաց դաշտային թարգմանման համակարգը', 'az': "Karakter Mapping və Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System", 'bn': 'অক্ষর ম্যাপিং এবং আদ-হোক পরিচালনা: এডিনবার্গের IWSLT ২০২০ খোলা ডোমেইন অনুবাদ সিস্টেম', 'cs': 'Mapování znaků a Ad-hoc adaptace: Edinburghský překladatelský systém IWSLT 2020 Open Domain', 'tr': "Karakter Mapping we Ad-hoc Görniş Opşenleri: Edinburgh's IWSLT 2020 Open Domain Translation System", 'et': 'Märkide kaardistamine ja ajutine kohandamine: Edinburghi avatud domeeni tõlkesüsteem IWSLT 2020', 'fi': 'Merkkien kartoitus ja tapauskohtainen mukauttaminen: Edinburghin IWSLT 2020 Open Domain -käännösjärjestelmä', 'ca': "Mapa de caràcters i adaptació ad hoc: Sistema de traducció de domini obert IWSLT 2020 d'Edimburgu", 'bs': 'Mapiranje karaktera i Ad-hoc Adaptacija: Edinburgov IWSLT 2020. sustav otvorenog domena prevoda', 'jv': "Karakter Mapping lan ads-Hoc Adjustation: Edgin's IWSLT 2020 Open domain translation System", 'sk': 'Kartiranje znakov in ad hoc prilagoditev: edinburški prevajalski sistem IWSLT 2020', 'ha': 'KCharselect unicode block name', 'he': 'המפתח של אותים והשינוי ad hoc: מערכת התרגום הפתוחה של אדינבורג IWSLT 2020', 'bo': "Character Mapping and Ad-hoc Adaptation: Edinburgh's IWSLT 2020 Open Domain Translation System"}
{'en': 'This paper describes the University of Edinburgh’s neural machine translation systems submitted to the IWSLT 2020 open domain JapaneseChinese translation task. On top of commonplace techniques like tokenisation and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.\\leftrightarrowChinese translation task. On top of commonplace techniques like tokenisation and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.', 'ar': 'تصف هذه الورقة أنظمة الترجمة الآلية العصبية بجامعة إدنبرة المقدمة إلى مهمة الترجمة اليابانية الصينية ذات المجال المفتوح IWSLT 2020. علاوة على التقنيات الشائعة مثل الترميز وتنظيف الجسم ، نستكشف رسم الخرائط والتكيف مع وقت فك التشفير بدون إشراف. تركز تقنياتنا على الاستفادة من البيانات المقدمة ، ونظهر التأثير الإيجابي لكل تقنية من خلال التحسين التدريجي لـ BLEU.', 'es': 'Este artículo describe los sistemas de traducción automática neuronal de la Universidad de Edimburgo presentados a la tarea de traducción de japonés ↔ chino de dominio abierto IWSLT 2020. Además de técnicas comunes como la tokenización y la limpieza de corpus, exploramos el mapeo de caracteres y la adaptación del tiempo de decodificación sin supervisión. Nuestras técnicas se centran en aprovechar los datos proporcionados y mostramos el impacto positivo de cada técnica a través de la mejora gradual de BLEU.', 'fr': "Cet article décrit les systèmes de traduction automatique neuronale de l'Université d'Édimbourg soumis à la tâche de traduction japonaise ↔ chinois dans le domaine ouvert IWSLT 2020. En plus des techniques courantes telles que la tokenisation et le nettoyage de corpus, nous explorons la cartographie des personnages et l'adaptation non supervisée du temps de décodage. Nos techniques se concentrent sur l'exploitation des données fournies, et nous montrons l'impact positif de chaque technique grâce à l'amélioration progressive de l'UEBL.", 'pt': 'Este artigo descreve os sistemas de tradução automática neural da Universidade de Edimburgo submetidos à tarefa de tradução japonês↔chinês de domínio aberto IWSLT 2020. Além de técnicas comuns, como tokenização e limpeza de corpus, exploramos o mapeamento de caracteres e a adaptação não supervisionada do tempo de decodificação. Nossas técnicas se concentram em alavancar os dados fornecidos e mostramos o impacto positivo de cada técnica por meio do aprimoramento gradual do BLEU.', 'ja': '本稿では、IWSLT 2020オープンドメイン日本語↔中国語翻訳タスクに提出されたエディンバラ大学のニューラル機械翻訳システムについて説明する。トークン化やコーパスクリーニングなどの一般的なテクニックに加えて、キャラクターマッピングと監視されていないデコード時間の適応を探ります。当社の技術は提供されたデータを活用することに焦点を当てており、BLEUの段階的な改善を通じて各技術のプラスの影響を示しています。', 'ru': 'В этой статье описываются системы нейронного машинного перевода Эдинбургского университета, представленные для выполнения задачи открытого домена IWSLT 2020 по переводу с японского на↔ китайский язык. В дополнение к обычным методам, таким как токенизация и очистка корпуса, мы исследуем отображение символов и неконтролируемую адаптацию декодирования во времени. Наши методы сосредоточены на использовании предоставленных данных, и мы показываем положительное влияние каждого метода посредством постепенного улучшения BLEU.', 'zh': '本文介爱丁堡大学提付IWSLT 2020开域日语↔中文翻译任神经机器翻译系统。 除标记化和语料库清理等常见技术之外,我们还探索了字符映射和无监督解码时间。 吾术侧重于用其数,以渐进BLEU,以见其极。', 'hi': 'यह पेपर एडिनबर्ग विश्वविद्यालय के तंत्रिका मशीन अनुवाद प्रणालियों का वर्णन करता है जो IWSLT 2020 ओपन डोमेन जापानीचीनी↔अनुवाद कार्य में प्रस्तुत किया गया है। टोकनाइजेशन और कॉर्पस सफाई जैसी सामान्य तकनीकों के शीर्ष पर, हम चरित्र मानचित्रण और असुरक्षित डिकोडिंग-समय अनुकूलन का पता लगाते हैं। हमारी तकनीकें प्रदान किए गए डेटा का लाभ उठाने पर ध्यान केंद्रित करती हैं, और हम BLEU के क्रमिक सुधार के माध्यम से प्रत्येक तकनीक का सकारात्मक प्रभाव दिखाते हैं।', 'ga': 'Déanann an páipéar seo cur síos ar chórais néar-aistriúcháin meaisín de chuid Ollscoil Dhún Éideann a cuireadh faoi bhráid thasc aistriúcháin Seapáinise↔Síneach oscailte IWSLT 2020. Anuas ar theicníochtaí coitianta ar nós comharthaíocht agus glanadh corpais, déanaimid iniúchadh ar mhapáil carachtair agus ar oiriúnú ama díchódaithe gan maoirsiú. Díríonn ár dteicníochtaí ar na sonraí a chuirtear ar fáil a ghiaráil, agus léirímid tionchar dearfach gach teicníc trí fheabhsú de réir a chéile ar BLEU.', 'hu': 'Ez a tanulmány bemutatja az Edinburgh-i Egyetem idegi gépi fordító rendszereit, amelyeket az IWSLT 2020 nyílt domain japán kínai fordítási feladat keretében nyújtottak be. A hétköznapi technikák mellett, mint például a tokenizáció és a corpus tisztítás, feltárjuk a karakterek feltérképezését és a felügyelet nélküli dekódolási idő adaptációját. Technikáink a rendelkezésre bocsátott adatok kihasználására összpontosítanak, és a BLEU fokozatos fejlesztésén keresztül bemutatjuk az egyes technikák pozitív hatását.', 'ka': 'ეს დომენტი აღწერს ვებინდონის ნეიროლური მაქანის გარგულისხმების სისტემებს, რომელიც IWSLT 2020-ში გახსნა დიომინის წონური ჩინეთის გარგულისხმების როგორც ტოკენიზაცია და კორპუსს წაშლა, ჩვენ განვიკეთებთ კარიქტურის მაპრაფიკაცია და არ განსხვავებული განსხვავებული განსხვავება. ჩვენი ტექნექციები კონუქტირებულია მონაცემულების მონაცემულებაზე და ჩვენ ჩვენ ყველა ტექნექტიკის პოციტური შედეგებას გამოჩვენებთ ბლესექტის ს', 'el': 'Η παρούσα εργασία περιγράφει τα νευρωνικά συστήματα μηχανικής μετάφρασης του Πανεπιστημίου του Εδιμβούργου που υποβλήθηκαν στην εργασία ιαπωνικής κινεζικής μετάφρασης ανοικτού τομέα. Εκτός από κοινές τεχνικές όπως η επισήμανση και ο καθαρισμός σωμάτων, εξερευνούμε τη χαρτογράφηση χαρακτήρων και την προσαρμογή χωρίς επίβλεψη χρόνου αποκωδικοποίησης. Οι τεχνικές μας εστιάζουν στην αξιοποίηση των παρεχόμενων δεδομένων και αναδεικνύουμε τον θετικό αντίκτυπο κάθε τεχνικής μέσα από τη σταδιακή βελτίωση της BLEU.', 'kk': 'Бұл қағаз Эдинбург университетінің невралдық компьютердің аудару жүйелерін IWSLT 2020 дегенге ашылған доменді жапон қытайша аудару тапсырмасына таңдайды. Токенизация және корпус тазалау сияқты көпшілікті техникалардың жоғарында, біз таңбалар картасын және оны баптау уақыттың адаптациясын зерттейміз. Біздің технологиямыз келтірілген деректерді көмектесу үшін көмектеседі, және біз әрбір технологияның оң жақсы нәтижесін BLEU бағдарламалы жасау арқылы көрсетеді.', 'ms': 'Kertas ini menggambarkan sistem terjemahan mesin saraf Universiti Edinburgh dihantar ke tugas terjemahan bahasa Jepun domain terbuka IWSLT 2020. Di atas teknik biasa seperti tokenisation dan pembersihan corpus, kami mengeksplorasi peta aksara dan penyesuaian masa-penyesuaian tanpa pengawasan. Teknik kita fokus pada penggunaan data yang diberikan, dan kita menunjukkan kesan positif setiap teknik melalui peningkatan secara perlahan-lahan BLEU.', 'mk': 'Овој весник ги опишува системите на превод на невропските машини на Универзитетот во Единбург пренесени на IWSLT 2020 отворен домен Јапонски кинески превод. Покрај обичните техники како што се токенизацијата и чистењето на корпусот, истражуваме мапирање на карактерите и ненадгледувана адаптација на декодирањето на времето. Нашите техники се фокусираат на искористувањето на обезбедените податоци и го покажуваме позитивното влијание на секоја техника преку постепено подобрување на БЛЕУ.', 'lt': 'Šiame dokumente aprašomos Edinburgo universiteto nervinių mašinų vertimo sistemos, pateiktos IWSLT 2020 atvirojo domeno Japonijos kinų vertimo užduotims. Be įprastų metodų, pavyzdžiui, tokenizacijos ir korpuso valymo, mes tiriame charakterų žemėlapių nustatymą ir nepastebimą dekodizavimo laiko pritaikymą. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.', 'it': "Questo articolo descrive i sistemi neurali di traduzione automatica dell'Università di Edimburgo sottoposti al compito di traduzione giapponese cinese a dominio aperto IWSLT 2020. Oltre alle tecniche comuni come la tokenizzazione e la pulizia del corpo, esploriamo la mappatura dei caratteri e l'adattamento non supervisionato del tempo di decodifica. Le nostre tecniche si concentrano sull'utilizzo dei dati forniti e mostriamo l'impatto positivo di ogni tecnica attraverso il graduale miglioramento della BLEU.", 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tat-traduzzjoni tal-magni newrali tal-Università ta’ Edinburgh sottomessi lill-kompitu tat-traduzzjoni Ċiniża b’dominju miftuħ IWSLT 2020. Minbarra tekniki komuni bħat-tokenizzazzjoni u t-tindif tal-korpus, nistudjaw l-immappjar tal-karattri u l-adattament mhux sorveljat għad-dekodifikazzjoni tal-ħin. It-tekniki tagħna jiffukaw fuq l-ingranaġġ tad-dejta pprovduta, u nagħmlu l-impatt pożittiv ta’ kull teknika permezz tat-titjib gradwali tal-BLEU.', 'no': 'Denne papiret beskriver Universiteten av Edimburg sine neuralmaskinsomsetjingssystemet som er sendt til den opne domeneomsetjingssystemet i IWSLT 2020. På toppen av vanlege teknikk som tokenisering og opprydding av korpus utforskar vi teiknkarparting og ikkje-oppretta dekodingstidspunkt. Teknikkene våre fokuserer på å levera dei oppgjevne data, og vi viser positivt effekt av kvar teknikk gjennom gradiske forbetringa av BLEU.', 'ro': 'Această lucrare descrie sistemele neuronale de traducere automată ale Universității din Edinburgh prezentate la sarcina IWSLT 2020 de traducere japoneză chineză. Pe lângă tehnicile obișnuite, cum ar fi tokenizarea și curățarea corpurilor, explorăm cartografierea caracterului și adaptarea nesupravegheată a timpului de decodare. Tehnicile noastre se concentrează pe valorificarea datelor furnizate și arătăm impactul pozitiv al fiecărei tehnici prin îmbunătățirea treptată a BLEU.', 'ml': 'ഈ പത്രത്തില്\u200d എഡിന്\u200dബര്\u200dഗിന്\u200dറെ ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റത്തെ വിവരിച്ചുകൊടുക്കുന്നു. IWSLT 2020 തുറന്ന ഡൊമെയിന്\u200d ജാ സാങ്കേതികമായ സാങ്കേതികവിദ്യകളുടെയും കോര്\u200dപ്പുസ് വൃത്തിയാക്കുന്നതിനെപ്പോലെയുള്ള സാങ്കേതികവിദ്യകളുടെയും മുകളില നമ്മുടെ സാങ്കേതികവിദ്യയുടെ വിവരങ്ങള്\u200d കൊടുക്കുന്നതിനെക്കുറിച്ച് ശ്രദ്ധിക്കുന്നു. എല്ലാ സാങ്കേതികവിദ്യയുട', 'mn': 'Энэ цаас Эдинбургийн Их Сургуулийн мэдрэлийн машины хөгжүүлэх системийг IWSLT 2020-д Хятад хэлний хөгжүүлэх үйлдлийг нээлттэй болгон тайлбарладаг. Тодорхойлолт болон корпус цэвэрлэх мэт ерөнхий газрын техникуудын дээд бид харьцааны зураг зураг, цаг хугацааны загварыг судалж байна. Бидний техникууд хангалттай өгөгдлийг ашиглах, техник бүрт эерэг нөлөө үзүүлэхэд бид БЛЕУ-ын хурдан сайжруулах боломжтой.', 'pl': 'Niniejszy artykuł opisuje neuronowe systemy tłumaczenia maszynowego Uniwersytetu Edynburga przesłane do otwartej domeny zadania tłumaczenia japońskiego chińskiego IWSLT 2020. Oprócz powszechnych technik, takich jak tokenizacja i czyszczenie korpusów, badamy mapowanie znaków i adaptację czasu dekodowania bez nadzoru. Nasze techniki koncentrują się na wykorzystaniu dostarczonych danych i pokazujemy pozytywny wpływ każdej techniki poprzez stopniowe doskonalenie BLEU.', 'so': 'Warqadan wuxuu ku qoran Jaamacadda Edinburgh nidaamka neural machine translation systems oo loo soo dhiibay IWSLT 2020 oo furan domain oo ah fasalinta Shiinaha. Dhakhtarka caadiga ah, sida calaamadda iyo nadiifsashada naafada, waxaynu baaraynaa kartooyinka xarafka ah iyo habboonaan bedelka xiliga. Teqooyiyadayada waxay ku kalsoonaan yihiin in la soo diro macluumaadka la soo daahiriyey, waxaynu tusnaa saamaynta suurtagalka ah ee teknikada kasta ee horumarinta BLEU.', 'si': 'මේ පත්තුරේ ඉඩින්බ්\u200dරින්ගුන් විශ්වාසයේ න්\u200dයූරාල් මැෂින් වාර්තාව පද්ධතියට පිළිගන්නවා IWSLT 2020ට ජ සාමාන්\u200dය තාක්ෂණික විද්\u200dයාවයේ ඉහළට ටොකෙනිස් සහ කොර්පුස් සුද්ධිකරණය වගේ, අපි ප්\u200dරකාරය සැකසුම් කරනවා සහ ප්\u200dර අපේ තාක්ෂිකාවල් දෙන්න පුළුවන් දත්ත ප්\u200dරශ්නය කරනවා, අපි හැම තාක්ෂිකාවක්ම ප්\u200dරශ්නයක්ම පෙන්වන්නේ BLUE', 'sr': 'Ovaj papir opisuje sisteme prevoda neuroloških strojeva Univerziteta Edinburga predate zadatku za prevod japanskih kineskih domena IWSLT 2020. Na vrhu zajedničkih tehnika kao što su tokenizacija i čišćenje korpusa, istražujemo mapiranje karaktera i nepotrebnu adaptaciju vremena dekodiranja. Naše tehnike se fokusiraju na primjenu pruženih podataka, i pokazujemo pozitivan uticaj svake tehnike kroz postupno poboljšanje BLEU-a.', 'sv': 'Denna uppsats beskriver universitetets neurala maskinﾃｶversﾃ､ttningssystem som lﾃ､mnats in till IWSLT 2020 ﾃｶppen domﾃ､n japansk kinesisk ﾃｶversﾃ､ttning uppgift. Utﾃｶver vanliga tekniker som tokenisering och korpusrengﾃｶring utforskar vi karaktﾃ､rskartlﾃ､ggning och oﾃｶvervakad avkodningstidsanpassning. Vﾃ･ra tekniker fokuserar pﾃ･ att utnyttja de data som tillhandahﾃ･lls, och vi visar den positiva effekten av varje teknik genom gradvis fﾃｶrbﾃ､ttring av BLEU.', 'ta': 'இந்த காகிதத்தில் எடின்பர்க்கின் புதிய இயந்திரம் மொழிபெயர்ப்பு அமைப்புகளை குறிப்பிடுகிறது IWSLT 2020 திறந்த டொமைன் திறந் பொதுவான இடத்தில் தொழில்நுட்ப தொழில்நுட்ப மேல் குறிப்பிடுதல் மற்றும் குறும்பு சுத்தம் போன்ற, நாம் எழுத்து வரைபடம் மற்ற எங்கள் தொழில்நுட்பம் கொடுக்கப்பட்ட தரவை அனுப்புவதை கவனம் செலுத்துகிறது, ஒவ்வொரு தொழில்நுட்பத்தின் நேர்ம விளைவுகளை பி', 'ur': 'یہ کاغذ ادینڈینبور کی یونیوریس کی نیورال ماشین ترجمہ سیسٹم کی توصیف کرتی ہے جو IWSLT 2020 میں کھولی جاپانی چین ترجمہ کا کام ہے۔ ٹوکنیزی اور کورپوس پاک کرنے کی طرح عام مکان تکنیک کے اوپر، ہم شخص نقشه مکانپٹ اور غیر قابل دکھانے کی سامان دیکھتے ہیں. ہماری تکنیک دیئے گئے ڈیٹا کے ذریعے مضبوط کرنا ہے اور ہم ہر تکنیک کے مثبت اثر دکھاتے ہیں بلیوس کی تدریج اثر کے ذریعے۔', 'uz': "Бу саҳифа Edinburgh universitetet IWSLT 2020 open domain xitoycha tarjima vazifasi brauzeri tizimini anglatadi. Ushbu hodisa ko'pchilik soniyalarning eng yuqoridagi teknologizda, ko'paytirish va kodlash vaqt tahrirchini ko'rib chiqaramiz. Maʼlumotlarni yozib olish uchun foydalanamiz va biz har bir teknologizning yaxshi effektini BLEU yaxshi o'zgartirish orqali ko'rsamiz.", 'vi': 'Bài viết này mô tả hệ thống dịch chuyển máy thần kinh của Đại học Edinburgh được gửi cho the IWSLT 2020 công việc dịch chuyển quân Nhật Bản Bản. Ngoài những kỹ thuật phổ biến như điều hòa và dọn dẹp vật thể, chúng ta khám phá bản đồ nhân vật và bắt cóc thời gian không giám sát. Kỹ thuật của chúng tôi hướng tới việc nhờ cậy nguồn dữ liệu cung cấp, và chúng tôi cho thấy tác động tích cực của mỗi kỹ thuật qua sự cải tiến chậm chạp của Hệ thống.', 'bg': 'Настоящата статия описва невронните системи за машинен превод на Университета в Единбург, подадени на задачата за превод на японски китайски език с отворен домейн. В допълнение към обичайните техники като токенизация и почистване на корпуси, ние изследваме картографиране на знаците и ненадзорна адаптация за декодиране във времето. Техниките ни се фокусират върху използването на предоставените данни, а ние показваме положителното въздействие на всяка техника чрез постепенното подобряване на БЮ.', 'nl': 'Dit artikel beschrijft de neurale machinevertaalsystemen van de Universiteit van Edinburgh die zijn ingediend bij de IWSLT 2020 open domein Japans Chinese vertaaltaak. Naast gangbare technieken zoals tokenisering en corpusreiniging onderzoeken we karaktermapping en onbeheerde decoderingstijd aanpassing. Onze technieken richten zich op het benutten van de verstrekte gegevens, en we laten de positieve impact van elke techniek zien door de geleidelijke verbetering van BLEU.', 'da': "Denne artikel beskriver University of Edinburgh's neurale maskinoversættelsessystemer, der er indsendt til IWSLT 2020 open domain japansk kinesisk oversættelsesopgave. Ud over almindelige teknikker som tokenisering og korpusrengøring undersøger vi karakterkortlægning og uopvåget afkodningstidstilpasning. Vores teknikker fokuserer på at udnytte de leverede data, og vi viser den positive effekt af hver enkelt teknik gennem den gradvise forbedring af BLEU.", 'de': 'Diese Arbeit beschreibt die neuronalen maschinellen Übersetzungssysteme der Universität Edinburgh, die der Open Domain Japanisch Chinesisch Übersetzungsaufgabe IWSLT 2020 unterzogen wurden. Neben gängigen Techniken wie Tokenisierung und Korpusreinigung untersuchen wir Charakterzuordnung und unbeaufsichtigte Dekodierzeitanpassung. Unsere Techniken konzentrieren sich auf die Nutzung der bereitgestellten Daten, und wir zeigen die positiven Auswirkungen jeder Technik durch die schrittweise Verbesserung der BLEU.', 'id': 'Kertas ini menjelaskan sistem terjemahan mesin saraf Universitas Edinburgh yang dikirim ke tugas terjemahan bahasa Jepang IWSLT 2020 domain terbuka. Di atas teknik biasa seperti tokenisation dan pembersihan corpus, kami mengeksplorasi peta karakter dan adaptasi decoding-waktu tidak diawasi. Teknik kami fokus pada penggunaan data yang diberikan, dan kami menunjukkan dampak positif setiap teknik melalui peningkatan secara bertahap dari BLEU.', 'ko': '본고는 에든버러대학이 IWSLT2020 개방역 일한 번역 임무에 제출한 신경기계 번역 시스템을 묘사한다.표기화와 자료 라이브러리 정리 등 흔히 볼 수 있는 기술을 토대로 우리는 문자영사와 무감독 디코딩 시간의 적응을 탐색했다.우리의 기술은 제공된 데이터를 이용하는 데 중심을 두었고 BLEU의 점진적인 개선을 통해 각 기술의 긍정적인 영향을 보여 주었다.', 'sw': "This paper describes the University of Edinburgh's neural machine translation systems submitted to the IWSLT 2020 open domain Japanese Chinese translation task.  Kwa upande wa mbinu za kawaida kama alama na usafi wa barafu, tunachunguza ramani za tabia na kuboreshwa kwa muda usio na uhakika. Teknolojia zetu zinalenga kutumia taarifa zilizotolewa, na tunaonyesha athari chanya za kila teknolojia kupitia maendeleo ya pole ya BLEU.", 'af': 'Hierdie papier beskrywe die Universiteit van Edimburg se neurale masjien vertalingsstelsels wat aan die IWSLT 2020 oop domein Japaanse vertalingstaak voorgeskryf is. Op bo van gemeenskaplike teknike soos tokenisasie en korpus skoonmaak, ondersoek ons karakter-mapering en onveronderwerp-tyd-aanpassing. Ons teknike fokus op die verskaffinge data te verwyder, en ons wys die positiewe effekt van elke tekniks deur die graduulle verbetering van BLEU.', 'tr': "Bu kagyz Edimburgyň Uniwersitetiniň näral maşynyň terjime sistemalaryny IWSLT 2020'a göndərilýär. Iň köp ýerlerde tokenizat we korpus temizlemek ýaly teknikleriň üstünde karakter maplemesini we gaýd etmedik zaman adaptasiýasyny gözləýäris. Biziň tekniklerimiz berilen maglumatlary etmäge üns berýäris we biz her teknikiýanyň ýokary düzeltmegini BLEU ýüzerinden döwletli täsirini görkeýäris.", 'am': 'ይህ ፕሮግራም የኤዲንቡር ዩንቨርስቲ የናቡራል መሣሪያን ትርጉም ሲስተም በIWSLT 2020 የተከፈተ ጃፓን የቻይና ትርጉም ስርዓት የተዘጋጀውን ይናገራል፡፡ በአካባቢው ስልጣናዎች ላይ እንደምናደርገው ማነጻ እና የኮርፕስ ማነጻት፣ የጽሑፍ ማረፊያ እና የማይጠበቀው የጊዜው ማቀናቀል እናፈልጋለን፡፡ የመስኮታችን ስህተታችን የዳራዎችን በመስጠት ላይ እናሳየዋለን፣ የሁሉንም ቴክኖክና በቢሌዩን ቀላል ማሳየት እናሳየዋለን፡፡', 'hr': 'Ovaj papir opisuje sustave prevoda neuroloških strojeva Univerziteta Edinburga predate zadatku za prevod japanskih kineskih domena IWSLT 2020. Na vrhu zajedničkih tehnika poput tokenizacije i čišćenja korpusa istražujemo mapiranje karaktera i nepotrebnu adaptaciju vremena dekodiranja. Naše tehnike su usredotočene na primjenu pruženih podataka i pokazujemo pozitivan utjecaj svake tehnike kroz postupno poboljšanje BLEU-a.', 'az': "Bu kağıt Edinburgin Universitetinin nöral maşın çeviri sistemlərini IWSLT 2020-ə açıq domani Çin çeviri işini təsdiq edir. Tokenizasyon və korpus təmizlənməsi kimi ortaq tehniklərin üstündə karakterlərin haritasını keşfetmişik və dəyişiklik vaxtı uyğunlamasını keşfetmişik. Tehniklərimiz təmin verilən məlumatları istifadə etməyə odaqlanır və hər tehniklərin pozitiv təsirini BLEU'nin tələb edilməsi vasitəsilə göstəririk.", 'fa': 'این کاغذ سیستم ترجمه\u200cهای ماشین عصبی دانشگاه ادینبورگ را توصیف می\u200cکند که به وظیفه ترجمه\u200cهای ژاپنی ژاپنی باز شده است. بالای تکنیک\u200cهای معمولی مثل تمیز توکین و پاک کردن کورپوس، ما نقشه\u200cسازی شخصیت\u200cها و تغییر تغییر مدت\u200cسازی را تحقیق می\u200cکنیم. تکنیک\u200cهای ما روی تأثیر داده\u200cهای پیشنهاد تمرکز می\u200cکنیم، و تاثیر مثبت هر تکنیک را از طریق تأثیر تأثیر BLEU نشان می\u200cدهیم.', 'bn': "This paper describes the University of Edinburgh's neural machine translation systems submitted to the IWSLT 2020 open domain Japanese Chinese translation task.  সামাজিক জায়গার প্রযুক্তির উপরে আমরা চিত্র ম্যাপিং এবং অরক্ষণশীল সময় পরিষ্কার করি। আমাদের প্রযুক্তিগুলো প্রদান করা তথ্য প্রদান করার প্রতি মনোযোগ দিয়ে মনোযোগ দিচ্ছে এবং আমরা প্রত্যেক প্রযুক্তির ইতিবাচক প্", 'ca': "Aquest article descriu els sistemes neuromàtics de traducció de la Universitat d'Edimburgh submetits a la tasca de traducció xinesa japonesa de domini obert IWSLT 2020. A més de les tècniques comunes com la tocenització i la netejació de corpus, explorem el mapatge de caràcters i l'adaptació sense supervisió al temps de decodificació. Les nostres tècniques es centren en aprofitar les dades proporcionades, i demostram l'impacte positiu de cada tècnica a través de l'millora gradual de la BLEU.", 'hy': 'Այս հոդվածը նկարագրում է Էդինբուրգի համալսարանի նյարդային մեքենային թարգմանման համակարգերը, որոնք ներկայացվել են IwPLT 2020-ի բաց բնագավառի ճապոնական թարգմանման խնդիրը: Ավելին այն սովորական տեխնիկաներին, ինչպիսիք են թոկենիզացիան և մարմնի մաքրումը, մենք ուսումնասիրում ենք հիերոգլիֆների քարտեզագրությունը և անվերահսկված անկոդավորման ժամանակի ադապտացիան: Մեր տեխնոլոգիաները կենտրոնանում են տրամադրված տվյալների օգտագործման վրա, և մենք ցույց ենք տալիս յուրաքանչյուր տեխնոլոգիայի դրական ազդեցությունը ԲԼԵՎ-ի աստիճանաբար զարգացման միջոցով:', 'bs': 'Ovaj papir opisuje sisteme prevođenja neuroloških strojeva Univerziteta Edinburga podignute na zadatak prevođenja japanskih kineskih domena IWSLT 2020. Na vrhu zajedničkih tehnika poput tokenizacije i čišćenja korpusa istražujemo mapiranje karaktera i nepotrebnu adaptaciju dekodiranja vremena. Naše tehnike se fokusiraju na primjenu pruženih podataka, i pokazujemo pozitivan utjecaj svake tehnike kroz postupno poboljšanje BLEU-a.', 'cs': 'Tento článek popisuje neuronové strojové překladové systémy Univerzity v Edinburghu předložené k otevřené doméně japonské čínštiny IWSLT 2020. Kromě běžných technik, jako je tokenizace a čištění korpusů, zkoumáme mapování znaků a adaptaci dekódování bez dohledu. Naše techniky se zaměřují na využití poskytnutých dat a ukazujeme pozitivní dopad každé techniky postupným zlepšováním BLEU.', 'et': 'Käesolevas töös kirjeldatakse Edinburghi Ülikooli neuromasintõlkesüsteeme, mis on esitatud IWSLT 2020 avatud domeeniga Jaapani Hiina tõlketööle. Lisaks tavalistele tehnikatele, nagu tokeniseerimine ja korpuse puhastamine, uurime märkide kaardistamist ja järelevalveta dekodeerimisaja kohandamist. Meie tehnikad keskenduvad esitatud andmete kasutamisele ja näitame iga tehnika positiivset mõju BLEU järkjärgulise täiustamise kaudu.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan Edinburghin yliopiston neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmiﾃ､, jotka on lﾃ､hetetty IWSLT 2020 avoimen verkkotunnuksen japanikinkiinan kﾃ､ﾃ､nnﾃｶstehtﾃ､vﾃ､ﾃ､n. Tavallisten tekniikoiden, kuten tokenisaation ja korpuspuhdistuksen, lisﾃ､ksi tutkimme hahmojen kartoitusta ja valvomatonta dekoodausaikaa. Tekniikamme keskittyvﾃ､t toimitettujen tietojen hyﾃｶdyntﾃ､miseen, ja osoitamme jokaisen tekniikan myﾃｶnteisen vaikutuksen BLEU:n asteittaisen parantamisen kautta.', 'sq': 'Ky dokument përshkruan sistemet e përkthimit nervor të makinave të Universitetit të Edinburgut të dërguar në detyrën e përkthimit japonez të domenit të hapur IWSLT 2020. Në krye të teknikave të zakonshme si tokenizimi dhe pastrimi i trupit, ne eksplorojmë hartimin e karaktereve dhe përshtatjen e pazgjidhur të kohës së dekodimit. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.', 'sk': 'V prispevku so opisani nevronski strojni prevajalski sistemi Univerze v Edinburgu, ki so bili predloženi prevajanju japonske kitajske jezike IWSLT 2020. Poleg običajnih tehnik, kot sta žetonizacija in čiščenje korpusov, raziskujemo kartiranje znakov in nenadzorovano dekodiranje časa. Naše tehnike se osredotočajo na izkoriščanje predloženih podatkov, pozitiven učinek vsake tehnike pa pokažemo s postopnim izboljšanjem BLEU.', 'he': 'העיתון הזה מתאר את מערכות התרגום המכונית העצבית של אוניברסיטת אדינבורג שנשלחו לתפקיד הפתוח IWSLT 2020 של התרגום הסיני היפני. בנוסף לטכניקות רגילות כמו טוקניזציה וניקוי הקורפוס, אנו חוקרים מפת אופיים ולהתאמה ללא שיקול. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.', 'ha': "Wannan avir describes the University of edinburg' s neural translation system sent to the IWSLT 2020 opened Domen and China translation job. On top of commonplace techniques like tokenisation and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation.  Tekinyinmu na muhalli da za'a samar da data da aka ba shi, kuma tuna nuna matsayin mai kyau ga kowane technki a tsakanin gyarata na BLEU.", 'bo': "ཤོག་བྱང་འདིས་Edimburg's University of Edinburgh's neural machine translation system་ལ་བཤད་ཀྱི་ཡོད་པ་དེ་ནི་IWSLT 2020་ལ་ཁ་ཕྱེས་པའི་དུས་མཚམས་རྒྱ་ནག་གི་སྤྱི་ཚོགས དེ་ལས་ཕལ་ཆེན་དང་སྒྲིག་གཙང་གཅད་ཀྱི་ཐབས་ལམ་ལ་མཐུན་པར། ང་ཚོས་ཡིག་འབྲུ་ཀྱི་རྣམ་པ་ཞིག་དང་ལྡན་སྒྲིག་འགོད་མེད་པའི་ད ང་ཚོའི་ཐབས་ལམ་ལ་སྤྲོད་ཡོད་པའི་གནས་ཚུལ་འདིས་མཐར་བསྐྱུར་བྱེད་ཀྱི་ཡོད།", 'jv': "This paper describes the University of Edgin's Neral device translation sistems sent to the IWSLT 2020 open domain Chinese translation task. Tulung bon didhak teknik karo tokenisaan lan karo perusahaan Teknik awak dhéwé dipundukne ngengambar nggawe data nyengkuyé, lan kéné iso ngomong nik nggawe barang nggawe teknik sing bisa nyengkuyé nggawe barang kelas barang nggawe barang nggawe gerakan oleh dumadhi luwih dumadhi"}
{'en': 'CASIA’s System for IWSLT 2020 Open Domain Translation', 'ar': 'نظام CASIA لترجمة المجال المفتوح IWSLT 2020', 'fr': 'Système CASIA pour la traduction de domaines ouverts IWSLT 2020', 'pt': 'Sistema da CASIA para tradução de domínio aberto IWSLT 2020', 'es': 'Sistema de CASIA para la traducción de dominio abierto IWSLT 2020', 'ja': 'CASIAのIWSLT 2020オープンドメイン翻訳システム', 'zh': 'CASIAIWSLT 2020开域名译系统', 'hi': 'IWSLT 2020 ओपन डोमेन अनुवाद के लिए CASIA की प्रणाली', 'ru': 'Система CASIA для перевода открытых доменов IWSLT 2020', 'ga': 'Córas CASIA le haghaidh Aistriú Fearainn Oscailte IWSLT 2020', 'ka': 'CASIA- ის სისტემა IWSLT 2020- ის გახსნა დომენის გასაგულისხმებისთვის', 'hu': 'A CASIA rendszere IWSLT 2020 nyílt domain fordításhoz', 'el': 'Το σύστημα της CASIA για τη μετάφραση ανοιχτού τομέα', 'lt': 'CASIA IWSLT 2020 atviro domeno vertimo sistema', 'it': 'Il sistema CASIA per IWSLT 2020 Open Domain Translation', 'kk': "CASIA's System for IWSLT 2020 Open Domain Translation", 'ml': 'IWSLT 2020- നുള്ള CASIA സിസ്റ്റം ഡൊമൈന്\u200d പരിഭാഷപ്പെടുത്തുക', 'mt': 'Is-Sistema CASIA għat-Traduzzjoni tad-Dominju Miftuħ IWSLT 2020', 'mk': 'Системот на CASIA за IWSLT 2020 отворен домен превод', 'ms': 'Sistem CASIA untuk Terjemahan Domain Buka IWSLT 2020', 'mn': "CASIA's System for IWSLT 2020 Open Domain Translation", 'no': 'CASIA- systemet for IWSLT 2020 Open Domain Translation', 'si': "CASIA's System for IWSLT 2020Open Domain translation", 'ro': 'Sistemul CASIA pentru traducerea domeniului deschis IWSLT 2020', 'pl': 'System CASIA dla tłumaczeń otwartych domen IWSLT 2020', 'sr': 'CASIA-ov sistem za IWSLT 2020. prevod otvorenog domena', 'sv': 'CASIAs system för IWSLT 2020 Open Domain Översättning', 'so': 'CASIA System for IWSLT 2020 Open Domain Translation', 'ta': "CASIA' s system for IWSLT 2020 Open Domain Translation", 'ur': "CASIA's System for IWSLT 2020 Open Domain Translation", 'uz': 'IWSLT 2020 uchun CASIA tizimi ochish Domen tarjima', 'vi': 'Hệ thống CASIA cho IWSLT 2020 Dịch miền rộng mở', 'da': "CASIA's system til IWSLT 2020 Open Domain Oversættelse", 'bg': 'Системата на КАСИА за превод на отворен домейн', 'de': 'CASIAs System für IWSLT 2020 Open Domain Translation', 'nl': "CASIA's systeem voor IWSLT 2020 Open Domain Translation", 'id': "CASIA's System for IWSLT 2020 Open Domain Translation", 'sw': 'Mfumo wa CASIA wa IWSLT 2020 Open Domain Translation', 'fa': 'سیستم CASIA برای ترجمه دامنی باز IWSLT 2020', 'tr': "CASIA's System for IWSLT 2020 Open Domain Translation", 'sq': 'Sistemi i CASIA për IWSLT 2020', 'hr': 'CASIA sustav za IWSLT 2020. prevod otvorenog domena', 'ko': 'CASIA용 IWSLT 2020 오픈 도메인 번역 시스템', 'az': "CASIA's System for IWSLT 2020 Open Domain Translation", 'bn': 'IWSLT ২০২০ এর জন্য ক্যাসিয়ার সিস্টেম খোলা ডোমেন অনুবাদ', 'af': 'CASIA se Stelsel vir IWSLT 2020 Open Domein Vertaling', 'am': '瘠ｨCASIA 瘉ｵ瘉ｭ瘠乍卸 瘉喆WSLT 2020 瘧ｭ瘢違卸 瘠ｶ瘉憮兜 瘟ｵ瘉ｭ瘡蚊嬥', 'cs': 'Systém CASIA pro IWSLT 2020 Open Domain Translation', 'hy': 'ԿԱՍԻԱյի IwPLT 2020-ի բաց բնագավառի թարգմանման համակարգը', 'bs': 'CASIA-ov sustav za IWSLT 2020. Otvoreni prevod domena', 'ca': "CASIA's System for IWSLT 2020 Open Domain Translation", 'et': 'CASIA süsteem IWSLT 2020 avatud domeeni tõlkimiseks', 'fi': 'CASIAn järjestelmä IWSLT 2020 avoimen verkkotunnuksen kääntämiseen', 'sk': 'Sistem CASIA za prevajanje odprtih domen IWSLT 2020', 'he': 'מערכת CASIA IWSLT 2020 תורגם תואר פתוח', 'ha': 'KCharselect unicode block name', 'jv': "CaSiA's System for IWSLT 2020 Open domain translation", 'bo': "CASIA's System for IWSLT 2020 Open Domain Translation"}
{'en': 'This paper describes the CASIA’s system for the IWSLT 2020 open domain translation task. This year we participate in both ChineseJapanese and JapaneseChinese translation tasks. Our system is neural machine translation system based on Transformer model. We augment the training data with knowledge distillation and back translation to improve the translation performance. Domain data classification and weighted domain model ensemble are introduced to generate the final translation result. We compare and analyze the performance on development data with different model settings and different data processing techniques.', 'ar': 'تصف هذه الورقة نظام CASIA لمهمة ترجمة المجال المفتوح IWSLT 2020. نشارك هذا العام في مهام الترجمة الصينية - اليابانية واليابانية - → الصينية. نظامنا هو نظام ترجمة آلي عصبي يعتمد على نموذج المحولات. نقوم بزيادة بيانات التدريب عن طريق تقطير المعرفة والترجمة الخلفية لتحسين أداء الترجمة. يتم تقديم تصنيف بيانات المجال ومجموعة نموذج المجال الموزون لتوليد نتيجة الترجمة النهائية. نقوم بمقارنة وتحليل الأداء على بيانات التطوير بإعدادات نموذجية مختلفة وتقنيات معالجة بيانات مختلفة.', 'fr': "Cet article dÃĐcrit le systÃĻme de CASIA pour la tÃĒche de traduction de domaine ouvert IWSLT 2020. Cette annÃĐe, nous participons Ã\xa0 des tÃĒches de traduction chinoisâ\x86\x92japonais et japonaisâ\x86\x92chinois. Notre systÃĻme est un systÃĻme de traduction automatique neuronale basÃĐ sur le modÃĻle Transformer. Nous augmentons les donnÃĐes de formation par la distillation des connaissances et la rÃĐtro-traduction afin d'amÃĐliorer les performances de traduction. La classification des donnÃĐes de domaine et l'ensemble de modÃĻles de domaine pondÃĐrÃĐ sont introduits pour gÃĐnÃĐrer le rÃĐsultat final de la traduction. Nous comparons et analysons les performances des donnÃĐes de dÃĐveloppement avec diffÃĐrents paramÃĻtres de modÃĻle et diffÃĐrentes techniques de traitement des donnÃĐes.", 'es': 'Este artículo describe el sistema de CASIA para la tarea de traducción de dominio abierto IWSLT 2020. Este año participamos en tareas de traducción de chino → japonés y japonés → chino. Nuestro sistema es un sistema de traducción automática neuronal basado en el modelo Transformer. Aumentamos los datos de formación con la destilación de conocimientos y la traducción inversa para mejorar el rendimiento de la traducción. Se introducen la clasificación de datos de dominio y el conjunto de modelos de dominio ponderado para generar el resultado final de la traducción Comparamos y analizamos el rendimiento de los datos de desarrollo con diferentes configuraciones de modelos y diferentes técnicas de procesamiento de datos.', 'pt': 'Este artigo descreve o sistema da CASIA para a tarefa de tradução de domínio aberto IWSLT 2020. Este ano, participamos de tarefas de tradução de chinês→japonês e japonês→chinês. Nosso sistema é um sistema de tradução automática neural baseado no modelo Transformer. Aumentamos os dados de treinamento com destilação de conhecimento e tradução reversa para melhorar o desempenho da tradução. A classificação de dados de domínio e o conjunto de modelo de domínio ponderado são introduzidos para gerar o resultado final da tradução. Comparamos e analisamos o desempenho dos dados de desenvolvimento com diferentes configurações de modelo e diferentes técnicas de processamento de dados.', 'zh': '本文言CASIA用于IWSLT 2020开域译之统。 今年中文→日语日语→中文翻译。 吾统者,变形金刚之神经机器翻译统也。 因知蒸馏回译以增培训数,以重译性。 引入域数分加权域模形融合以成终译。 吾校析有不同数据处理术者开数之性也。', 'ja': '本稿では、IWSLT 2020オープンドメイン翻訳タスクのためのCASIAのシステムについて説明する。今年は、中国語の日本語翻訳と→日本語の中国語翻訳→の両方に参加しています。当社のシステムは、トランスフォーマーモデルに基づくニューラル機械翻訳システムです。トレーニングデータをナレッジ蒸留とバック翻訳で拡張し、翻訳パフォーマンスを向上させます。ドメインデータ分類と加重ドメインモデルアンサンブルを導入して、最終的な翻訳結果を生成します。さまざまなモデル設定とさまざまなデータ処理技術を使用して、開発データのパフォーマンスを比較および分析します。', 'ru': 'В этой статье описывается система CASIA для задачи перевода открытого домена IWSLT 2020. В этом году мы участвуем как в китайском→японском, так и в японском→китайском переводе. Наша система представляет собой систему нейронного машинного перевода, основанную на модели Трансформатора. Мы дополняем обучающие данные дистилляцией знаний и обратным переводом для улучшения производительности перевода. Для получения конечного результата трансляции вводятся классификация данных домена и ансамбль взвешенной модели домена. Мы сравниваем и анализируем эффективность данных разработки с различными настройками модели и различными методами обработки данных.', 'hi': 'यह पेपर IWSLT 2020 ओपन डोमेन अनुवाद कार्य के लिए CASIA के सिस्टम का वर्णन करता है। इस साल हम चीनी→जापानी और जापानी→चीनी अनुवाद कार्यों दोनों में भाग लेते हैं। हमारी प्रणाली ट्रांसफॉर्मर मॉडल पर आधारित तंत्रिका मशीन अनुवाद प्रणाली है। हम अनुवाद प्रदर्शन में सुधार करने के लिए ज्ञान आसवन और वापस अनुवाद के साथ प्रशिक्षण डेटा को बढ़ाते हैं। डोमेन डेटा वर्गीकरण और भारित डोमेन मॉडल ensemble अंतिम अनुवाद परिणाम उत्पन्न करने के लिए पेश कर रहे हैं। हम विभिन्न मॉडल सेटिंग्स और विभिन्न डेटा प्रोसेसिंग तकनीकों के साथ विकास डेटा पर प्रदर्शन की तुलना और विश्लेषण करते हैं।', 'ga': 'Déanann an páipéar seo cur síos ar chóras CASIA do thasc aistriúcháin fearainn oscailte IWSLT 2020. I mbliana glacaimid páirt i dtascanna aistriúcháin Sínis → Seapáinis agus Seapáinis → Sínis. Córas néar-aistriúcháin meaisín é ár gcóras bunaithe ar mhúnla Trasfhoirmeora. Méadaimid na sonraí oiliúna le driogadh eolais agus aisaistriúchán chun feidhmíocht an aistriúcháin a fheabhsú. Tugtar isteach aicmiú sonraí fearainn agus ensemble de shamhlacha fearainn ualaithe chun an toradh aistriúcháin deiridh a ghiniúint. Déanaimid comparáid agus anailís ar fheidhmíocht sonraí forbartha le socruithe múnla éagsúla agus teicnící próiseála sonraí éagsúla.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα της CASIA για την εργασία μετάφρασης ανοικτού τομέα. Φέτος συμμετέχουμε τόσο στα κινεζικά ιαπωνικά όσο και στα ιαπωνικά κινεζικά μεταφραστικά καθήκοντα. Το σύστημά μας είναι νευρικό σύστημα μηχανικής μετάφρασης βασισμένο στο μοντέλο μετασχηματιστή. Συμπληρώνουμε τα δεδομένα εκπαίδευσης με απόσταξη γνώσεων και μεταγραφή για να βελτιώσουμε την απόδοση της μετάφρασης. Η ταξινόμηση δεδομένων τομέα και το σύνολο σταθμισμένων μοντέλων τομέα εισάγονται για την παραγωγή του τελικού αποτελέσματος μετάφρασης. Συγκρίνουμε και αναλύουμε την απόδοση σε δεδομένα ανάπτυξης με διαφορετικές ρυθμίσεις μοντέλου και διαφορετικές τεχνικές επεξεργασίας δεδομένων.', 'hu': 'Ez a tanulmány bemutatja a CASIA rendszerét az IWSLT 2020 nyílt domain fordítási feladathoz. Idén részt veszünk kínai japán és japán kínai fordítási feladatokban is. Rendszerünk egy transzformátor modellre épülő neurális gépi fordító rendszer. A képzési adatokat ismeretlepárlással és visszafordítással bővítjük a fordítási teljesítmény javítása érdekében. A végleges fordítási eredmény előállítása érdekében a domain adatok osztályozása és a súlyozott domain modell együttese kerül bevezetésre. A fejlesztési adatok teljesítményét különböző modellbeállításokkal és adatfeldolgozási technikákkal hasonlítjuk össze és elemezzük.', 'it': "Questo articolo descrive il sistema CASIA per il compito di traduzione a dominio aperto IWSLT 2020. Quest'anno partecipiamo sia alle attività di traduzione cinese giapponese che giapponese cinese. Il nostro sistema è un sistema di traduzione automatica neurale basato sul modello Transformer. Aumentiamo i dati di formazione con distillazione della conoscenza e traduzione posteriore per migliorare le prestazioni di traduzione. La classificazione dei dati di dominio e l'insieme ponderato dei modelli di dominio vengono introdotti per generare il risultato finale della traduzione. Confrontiamo e analizziamo le prestazioni sui dati di sviluppo con diverse impostazioni del modello e diverse tecniche di elaborazione dei dati.", 'ka': 'ამ დომენტის შესახებ CASIA სისტემის IWSLT 2020 დიომენის გასაგრძელება. ამ წლის ჩვენ ჩვენ ჩინეთი იაპონური და იაპონური ჩინეთის გაგრძელების საქმებში დავათავსებთ. ჩვენი სისტემა ნეიროლური მანქანის გადაწყვეტილების სისტემა ტრანფორმეტრის მოდელზე ბაზეულია. ჩვენ განვითარებით მონაცემების დისტლიაცია და განვითარებით განვითარებით განვითარებით. დემომინის მონაცემების კლასიფიკაცია და გაზრულებული დემომინის მოდელის მოდულია შეიყვანა, რომ დასაწყისი გაგრძელება შექმნა. ჩვენ განვითარების მონაცემების გამოყენებას და ანალიზებას განსხვავებული მოდელური პარამეტრებით და განსხვავებული მონაცემების გამოყენება ტექნოგიები', 'kk': 'Бұл қағаз IWSLT 2020 доменді аудару тапсырмасының CASIA жүйесін анықтайды. Бұл жыл біз қытап және япон және жапон қытап аудармалардың тапсырмаларына қатынасыз. Біздің жүйеміз түрлендіруші үлгісіне негізделген невралдық компьютерді аудару жүйесі. Біз мәліметтің дистилациясы мен аудармаларды жақсарту үшін оқыту деректерін көтереміз. Соңғы аудармалардың нәтижесін құру үшін доменнің деректерінің классификациясы мен тең доменнің үлгісі келтіріледі. Біз жасау деректерінің әртүрлі модель параметрлері мен әртүрлі деректерді өңдеу техникаларымен салыстырып анализ.', 'ms': 'Kertas ini menggambarkan sistem CASIA untuk tugas terjemahan domain terbuka IWSLT 2020. Tahun ini kita berpartisipasi dalam tugas terjemahan bahasa Jepun dan bahasa Jepun. Our system is neural machine translation system based on Transformer model.  Kami menambah data latihan dengan pengusiran pengetahuan dan terjemahan belakang untuk meningkatkan prestasi terjemahan. Domain data classification and weighted domain model ensemble are introduced to generate the final translation result.  Kami membandingkan dan menganalisis prestasi pada data pembangunan dengan tetapan model yang berbeza dan teknik pemprosesan data yang berbeza.', 'ml': 'IWSLT 2020 തുറക്കുന്ന ഡൊമെയിന്\u200d പരിഭാഷണ ജോലിക്കുള്ള കാസിയുടെ സിസ്റ്റം വിശദീകരിക്കുന്ന ഈ പത്രിയില ഈ വര്\u200dഷം ഞങ്ങള്\u200d ചൈനീസ് ജാപ്പനീസും ജപ്പാനീസ് പരിഭാഷകങ്ങളും പങ്കുചേര്\u200dക്കുന്നു. Our system is neural machine translation system based on Transformer model.  പരിശീലനത്തിന്റെ പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുന്നു. പരിഭാഷയുടെ പ്രകടനം മുന്\u200dകൂട്ടുവ ഡൊമെയിന്\u200d ഡേറ്റാ വിവരങ്ങള്\u200d ക്ലാസ്ഫിക്ഷനും ഭാരം ഡൊമെയിന്\u200d മോഡല്\u200d എന്\u200dസ്പെബിലും പരിചയപ്പെടുത്തുന്നു. അവസ വ്യത്യസ്ത മോഡല്\u200d സജ്ജീകരണങ്ങളും വ്യത്യസ്ത ഡേറ്റാ പ്രവര്\u200dത്തിപ്പിക്കുന്ന സാങ്കേതികങ്ങളും കൊണ്ട് നമ്മള്\u200d', 'mk': 'Овој весник го опишува системот на КАСИА за задачата за отворен превод на домен IWSLT 2020. This year we participate in both Chinese Japanese and Japanese Chinese translation tasks.  Нашиот систем е нервен машински преведувачки систем базиран на трансформскиот модел. Ги зголемуваме податоците за обука со дистилација на знаење и превод за подобрување на преводот. Класификација на податоци за домен и тежиран модел на домен се воведени за генерирање на крајниот резултат на преводот. We compare and analyze the performance on development data with different model settings and different data processing techniques.', 'lt': 'Šiame dokumente aprašoma CASIA sistema, skirta IWSLT 2020 atviro domeno vertimo užduotims. Šiais metais dalyvaujame Kinijos japonų ir japonų kinų vertimo užduotyse. Mūsų sistema yra nervinės mašinos vertimo sistema, pagrįsta Transformer modeliu. Siekdami pagerinti vertimo rezultatus, didiname mokymo duomenis, naudojant žinių distiliavimą ir grįžtamąjį vertimą. Siekiant gauti galutinį vertimo rezultatą, įvedamas domeno duomenų klasifikavimas ir svertinis domeno modelio rinkinys. Palyginame ir analizuojame vystymo duomenų rezultatus su skirtingais modelių nustatymais ir skirtingais duomenų apdorojimo metodais.', 'mt': 'Dan id-dokument jiddeskrivi s-sistema tal-CASIA għall-kompitu tat-traduzzjoni tad-dominju miftuħ IWSLT 2020. Din is-sena qed jipparteċipaw kemm fil-kompiti tat-traduzzjoni Ċiniża Ġappuniża kif ukoll fil-Ġappuniża Ċiniża. Is-sistema tagħna hija sistema tat-traduzzjoni tal-magni newrali bbażata fuq il-mudell Transformer. Aħna nżidu d-dejta tat-taħriġ bid-distillazzjoni tal-għarfien u t-traduzzjoni lura biex itejbu l-prestazzjoni tat-traduzzjoni. Il-klassifikazzjoni tad-dejta tad-dominju u l-ensemble tal-mudell tad-dominju ppeżat huma introdotti biex jiġġeneraw ir-riżultat finali tat-traduzzjoni. Aħna nqabblu u nanalizzaw il-prestazzjoni dwar id-dejta tal-iżvilupp ma’ konfigurazzjonijiet mudell differenti u tekniki differenti tal-ipproċessar tad-dejta.', 'mn': 'Энэ цаас IWSLT 2020 оны нээлттэй зохиолын даалгаварын CASIA системийг тайлбарладаг. Энэ жил бид Хятадын Япон болон Япон улсын орчуулалтын ажилд оролцсон. Бидний систем бол Трансфер загварын үндсэн мэдрэлийн машин орчуулах систем юм. Бид мэдлэгийг сайжруулахын тулд сургалтын өгөгдлийг нэмэгдүүлнэ. Домены өгөгдлийн хуваарилалт болон жингийн домены загвар хамгийн сүүлийн орчуулалтын үр дүнг үүсгэхийн тулд танилцуулагддаг. Бид хөгжлийн өгөгдлийн үйл ажиллагааг өөр загварын тодорхойлолт болон өөр өөр өгөгдлийн үйлдвэрлэлийн техникуудыг харьцуулж, шинжилгээ хийдэг.', 'ro': 'Această lucrare descrie sistemul CASIA pentru sarcina de traducere a domeniului deschis IWSLT 2020. Anul acesta participăm atât la sarcini de traducere chineză japoneză cât și japoneză chineză. Sistemul nostru este un sistem de traducere automată neurală bazat pe modelul Transformer. Îmbunătățim datele de instruire cu distilarea cunoștințelor și traducerea înapoi pentru a îmbunătăți performanța traducerii. Clasificarea datelor de domeniu și ansamblul modelului ponderat de domeniu sunt introduse pentru a genera rezultatul final al traducerii. Comparăm și analizăm performanța datelor de dezvoltare cu diferite setări de model și diferite tehnici de procesare a datelor.', 'pl': 'Niniejszy artykuł opisuje system CASIA dla zadania tłumaczenia otwartej domeny IWSLT 2020. W tym roku uczestniczymy zarówno w zadaniach tłumaczeniowych chińskiego japońskiego, jak i japońskiego chińskiego. Naszym systemem jest neuronowy system tłumaczenia maszynowego oparty na modelu Transformera. Dane szkoleniowe uzupełniamy o destylację wiedzy i tłumaczenie wsteczne, aby poprawić wydajność tłumaczenia. W celu wygenerowania końcowego wyniku tłumaczenia wprowadzono klasyfikację danych domenowych oraz zespół ważonych modeli domenowych. Porównujemy i analizujemy wydajność danych rozwojowych z różnymi ustawieniami modelu i różnymi technikami przetwarzania danych.', 'so': 'Kanu wuxuu ku qoran yahay nidaamka CASIA ee IWSLT 2020 oo furan turjumista domain. Sannadan waxaynu ka qeybqaadanaynaa shaqooyinka turjumaadda Shiino iyo Japoniya. nidaamkayagu waa nidaamka turjumista maskinada asalka ah oo ku saleysan qaababka turjumista. Waxaannu ku dareynaa macluumaadka waxbarashada ku saabsan aqoonta iyo turjumidda dib si aan u beddelno tababarka turjumaadda. Tilmaamaha macluumaadka ee Domain waxaa lagu soo bandhigaa sameynta model domain oo miisaamay si uu u sameeyo fasirada ugu dambeeya. Waxaannu isbarbardhignaa oo baaritaannaa tababarka macluumaadka horumarinta iyo qaabab kala duduwan iyo teknolojiyo kala duduwan baaritaanka macluumaadka.', 'sr': 'Ovaj papir opisuje CASIA sistem za zadatak prevoda domena IWSLT 2020. Ove godine smo učestvovali na kineskim i japanskim prevodnim zadacima. Naš sistem je neuralni sistem prevoda na osnovu transformera. Povećavamo podatke o obuci sa destilacijom znanja i prevodom natrag kako bi poboljšali provedbu prevoda. Klasifikacija podataka domena i model težine domena se uvede kako bi stvorili konačni rezultat prevoda. Uspoređujemo i analiziramo provedbu podataka o razvoju sa različitim modelima i različitim tehnikama obrade podataka.', 'si': 'මේ පැත්තේ කාසියාගේ පද්ධතිය IWSLT 2020ට විවෘත විවෘත වැඩේ විවෘත කරනවා. මේ අවුරුද්දේ අපි චීනි ජාපානි සහ ජාපානි චීනි වාර්ථාවක් දෙන්නම් සම්බන්ධ වෙනවා. අපේ පද්ධතිය න්\u200dයූරාල් මැෂින් වාර්ථාව පද්ධතිය විදිහට පද්ධතිය. අපි දැනගන්න දත්ත විශ්වාසය සහ ආපහු වාර්ථාව සඳහා ප්\u200dරධාන දත්ත විශ්වාසය කරනවා. ඩොමේන් දත්ත විශේෂණය සහ විශේෂ ප්\u200dරමාණය අන්තිම වාර්ථාව නිර්මාණය කරන්න ප්\u200dරමාණය කරන්න. අපි විකාශ දත්තේ ප්\u200dරවේශනය සහ වෙනස් මොඩේල් සැකසුම සඳහා වෙනස් දත්ත ප්\u200dරවේශනය සඳහා පරික්ෂණය සඳහ', 'sv': 'Denna uppsats beskriver CASIA:s system för IWSLT 2020 open domain översättningsuppgifter. I år deltar vi i både kinesiska japanska och japanska kinesiska översättningsuppgifter. Vårt system är neuralt maskinöversättningssystem baserat på Transformer modell. Vi utökar utbildningsdata med kunskapsdestillation och bakåtöversättning för att förbättra översättningens prestanda. Domändataklassificering och viktad domänmodellensemble introduceras för att generera det slutliga översättningsresultatet. Vi jämför och analyserar prestandan på utvecklingsdata med olika modellinställningar och olika databehandlingstekniker.', 'ta': 'IWSLT 2020 திறந்த டொமைன் மொழிபெயர்ப்பு பணிக்கான CASIA அமைப்பை இந்த தாள் விளக்குகிறது. இந்த வருடத்தில் நாம் சீன ஜாப்பானிய மற்றும் ஜப்பானிய சீன மொழிபெயர்ப்பு பணிகளில் பகிர்ந்து கொள எங்கள் அமைப்பு மாற்றும் மாதிரியை அடிப்படையில் புதிய இயந்திரம் மொழிபெயர்ப்பு அமைப்பு. அறிவு பிரிப்பு மற்றும் திரும்ப மொழிபெயர்ப்பு மொழிபெயர்ப்பை மேம்படுத்துவதற்காக பயிற்சி தகவல்களை  Domain data classification and weighed domain model ensemble are introduced to generate the final translation results. நாம் வேறு மாதிரி அமைப்புகள் மற்றும் வேறு தரவு செயல்படுத்தல் தொழில்நுட்பத்தை ஒப்பிடுகிறோம் மற்றும் ஆரா', 'ur': "This paper describes the CASIA's system for the IWSLT 2020 open domain translation task. آج سال ہم چینی جیاپنی اور جیاپنی چینی ترجمہ کے کاموں میں شریک ہوتے ہیں۔ ہمارا سیسٹم نئورل ماشین ترجمہ سیسٹم ہے ترفنسر موڈل پر بنیاد ہے۔ ہم تعلیم دادہ کو علم کے تفریق کے ساتھ اور پیچھے ترجمہ کے ساتھ زیادہ کر رہے ہیں تاکہ ترجمہ کرے ڈومین ڈاٹ کا کلیسپیشن اور وزن ڈومین موڈل آنسمبل کے لئے آخری ترجمہ نتیجہ پیدا کرنے کے لئے پیش کیے جاتے ہیں. ہم طرح طرح کے اندازے اور مختلف ڈیٹا پرسس ٹیکنیک کے ساتھ طرح طرح طرح کے ڈیٹا ڈیٹا کے ذریعے عمل کو مقایسہ کرتے ہیں اور تحقیق کرتے ہیں.", 'no': 'Denne papiret beskriver CASIA- systemet for oppgåva for omsetjinga av domenet IWSLT 2020. I denne året deltar vi både kinesiske og japanske omsetjingsprogrammer. Systemet vårt er neuralmaskinsomsetjingssystem basert på transformeringsmodell. Vi aukar opplæringsdata med kunnskapsdistillasjon og tilbakeomsetjing for å forbetra omsetjinga. Domenedata- klassifikasjon og vektsmodell for domenet er introdusert for å laga resultatet av det siste omsetjinga. Vi sammenliknar og analyserer utviklingsdata med ulike modellinstillingar og ulike datahandlingstekningar.', 'vi': 'Tờ giấy này mô tả hệ thống Caspian về công việc dịch chuyển miền trống cho IWSLT 2020. Năm nay chúng tôi tham gia dịch vụ Trung Quốc và Nhật Bản. Hệ thống của chúng tôi là hệ thống dịch chuyển máy thần kinh dựa trên mô hình transformer. Chúng tôi tăng cường dữ liệu đào tạo bằng việc chưng cất kiến thức và dịch chuyển lại để cải tiến tiến tiến tiến tiến độ dịch chuyển. Phân loại dữ liệu miền và mô hình miền cân bằng được nhập để tạo ra kết quả dịch chuyển cuối cùng. Chúng tôi so sánh và phân tích các dữ liệu phát triển với thiết lập mô hình khác nhau và các kỹ thuật xử lý dữ liệu khác nhau.', 'uz': 'Bu qogʻoz IWSLT 2020 ochiq domen tarjima vazifasi CASIA tizimini anglatadi. Bu yil xitoycha va Japoniya xitoycha tarjima vazifalarini bajaramiz. Bizning tizimmiz Transformer modelga asosida neyrol tarjima tizimi. @ info @ info: whatsthis Biz taʼminlovchi maʼlumot bazasining natijasini boshqa model moslamalari va boshqa maʼlumot boshqarish tugmalari bilan kamaytamiz va analyzeriz.', 'bg': 'Настоящата статия описва системата на КАСИА за задачата за превод с отворен домейн по международен транспорт 2020. Тази година участваме в преводачески задачи както на китайски японски, така и на японски. Нашата система е невронна система за машинен превод базирана на модела на трансформатор. Увеличаваме данните за обучението с дестилация на знания и обратен превод, за да подобрим ефективността на превода. Класификация на домейнните данни и претеглен домейн модел ансамбъл са въведени за генериране на крайния резултат от превода. Сравняваме и анализираме ефективността на разработените данни с различни настройки на модела и различни техники за обработка на данни.', 'nl': 'Dit document beschrijft het CASIA-systeem voor de IWSLT 2020 open domein vertaaltaak. Dit jaar nemen we deel aan zowel Chinese Japans als Japans Chinese vertaaltaken. Ons systeem is neuraal machine translation systeem gebaseerd op Transformer model. We breiden de trainingsgegevens uit met kennisdestillatie en back translation om de vertaalprestaties te verbeteren. Domein data classificatie en gewogen domein model ensemble worden geïntroduceerd om het uiteindelijke vertaalresultaat te genereren. We vergelijken en analyseren de prestaties op ontwikkelingsdata met verschillende modelinstellingen en verschillende gegevensverwerkingstechnieken.', 'da': "Denne artikel beskriver CASIA's system til IWSLT 2020 open domain oversættelse opgave. I år deltager vi i både kinesisk japansk og japansk kinesisk oversættelsesopgaver. Vores system er neural maskinoversættelse system baseret på Transformer model. Vi udvider træningsdataene med videndedestillation og back-oversættelse for at forbedre oversættelsesevnen. Domænedataklassifikation og vægtet domænemodel ensemble introduceres for at generere det endelige oversættelsesresultat. Vi sammenligner og analyserer ydeevnen på udviklingsdata med forskellige modelindstillinger og forskellige databehandlingsteknikker.", 'de': 'Dieser Beitrag beschreibt das CASIA-System für die Open Domain Translation Task IWSLT 2020. In diesem Jahr nehmen wir sowohl an Übersetzungsaufgaben für Chinesisch Japanisch als auch Japanisch Chinesisch teil. Unser System ist neuronales maschinelles Übersetzungssystem basierend auf Transformer-Modell. Wir ergänzen die Trainingsdaten mit Wissensdestillation und Rückübersetzung, um die Übersetzungsleistung zu verbessern. Die Klassifizierung von Domänendaten und das gewichtete Domänenmodell-Ensemble werden eingeführt, um das endgültige Übersetzungsergebnis zu generieren. Wir vergleichen und analysieren die Performance von Entwicklungsdaten mit verschiedenen Modelleinstellungen und verschiedenen Datenverarbeitungstechniken.', 'hr': 'Ovaj papir opisuje CASIA sustav za zadatak prevoda domena IWSLT 2020. Ove godine učestvujemo u kineskim i japanskim prevodnim zadacima. Naš sustav je sustav prevoda neuralnih strojeva temeljen na modelu transformera. Povećavamo podatke o obuci s destilacijom znanja i prevodom natrag kako bi poboljšali učinkovitost prevoda. Klasifikacija podataka domena i model težine domena se uvodi kako bi stvorili konačni rezultat prevoda. Uspoređujemo i analiziramo učinkovitost podataka o razvoju s različitim modelima i različitim tehnikama obrade podataka.', 'id': 'Kertas ini menjelaskan sistem CASIA untuk tugas terjemahan domain terbuka IWSLT 2020. This year we participate in both Chinese Japanese and Japanese Chinese translation tasks.  Our system is neural machine translation system based on Transformer model.  Kami menambah data latihan dengan distillasi pengetahuan dan terjemahan kembali untuk meningkatkan prestasi terjemahan. Klasifikasi data domain dan ensemble model domain berat diperkenalkan untuk menghasilkan hasil terjemahan akhir. Kami membandingkan dan menganalisis prestasi pada data pengembangan dengan pengaturan model yang berbeda dan teknik pemroses data yang berbeda.', 'tr': "Bu kagyz IWSLT 2020'yň açyk domena terjime täblisasynyň CASIA sistemini tassyklaýar. Bu ýyl biz hem Hytaý, hem Japonça terjime etmäge rugsat berdik. Biziň sistemimiz Nural Makine terjime sistemidir Transformer nusgasyna daýanýar. Biz bilim taýýarlanmasy bilen bilim maglumatyny we yzyna terjime etmek üçin terjime etmek maglumatyny artýarys. domain data classification and weighted domain model ensemble are introduced to generate the final translation result. Biz gelişme maglumatynda farklı nusgala düzümleri we farklı maglumat işlemegi teknikleri bilen eserleşdirip çykýarys.", 'af': 'Hierdie papier beskryf die Casia se stelsel vir die IWSLT 2020 oop domein vertaling taak. Hierdie jaar het ons gedeel in Sjinese japanse en japanse vertalingstaak. Ons stelsel is neurale masjien vertaling stelsel gebaseer op Transformer model. Ons verbeter die onderwerp data met kennis-destilasie en terugvertaling om die vertaling-prestasie te verbeter. Domein data klasifikasie en gegewigte domein model ensemble word ingevoer om die eindelike vertaling resultaat te genereer. Ons vergelyk en analiseer die prestasie op ontwikkelingsdata met verskillende modelle instellings en verskillende data-verwerking tekniks.', 'fa': 'این کاغذ سیستم CASIA را برای تکلیف ترجمه دومین باز IWSLT 2020 توصیف می\u200cکند. امسال ما در وظیفه ترجمه چینی و ژاپنی شرکت می کنیم. سیستم ما سیستم ترجمه ماشین عصبی بر اساس مدل ترجمه کننده است. ما اطلاعات آموزش را با جدا کردن دانش و ترجمه برگشتیم تا عملکرد ترجمه را بهتر کنیم. ویرایش داده\u200cهای دامنی و مدل وزن دامنی برای تولید نتیجه نهایی ترجمه وارد می\u200cشوند. ما عملکرد روی داده های توسعه با تنظیمات مدل مختلف و تکنیک پردازش داده های مختلف را مقایسه می کنیم و تحلیل می کنیم.', 'sq': "This paper describes the CASIA's system for the IWSLT 2020 open domain translation task.  Këtë vit marrim pjesë në detyrat e përkthimit kinez japonez dhe japonez kinez. Sistemi ynë është sistemi nervor i përkthimit të makinave bazuar në modelin Transformer. Ne shtojmë të dhënat e trajnimit me distillacionin e njohurive dhe përkthimin prapa për të përmirësuar performancën e përkthimit. Klasifikimi i të dhënave të dominit dhe kompleti i modelit të peshuar të dominit janë futur për të gjeneruar rezultatin përfundimtar të përkthimit. Ne krahasojmë dhe analizojmë performancën në të dhënat e zhvillimit me rregullime të ndryshme modeli dhe teknika të ndryshme të procesimit të të dhënave.", 'hy': 'Այս աշխատանքը նկարագրում է ԿԱՍԻԱյի համակարգը IwPLT 2020-ի բաց բնագավառի թարգմանման գործի համար: This year we participate in both Chinese Japanese and Japanese Chinese translation tasks.  Մեր համակարգը նյարդային մեքենայի թարգմանման համակարգ է, որը հիմնված է Transforme մոդելի վրա: Մենք ավելացնում ենք կրթության տվյալները գիտելիքների դիսլիլացիայի և վերադարձ թարգմանման միջոցով, որպեսզի բարելավենք թարգմանման արդյունքները: Դոմենի տվյալների դասակարգման և դասակարգված տիեզերքի մոդելի համակարգը ներկայացվում են վերջնական թարգմանման արդյունքի ստեղծման համար: Մենք համեմատում ենք և վերլուծում ենք զարգացման տվյալների արդյունքները տարբեր մոդելների միջոցների և տարբեր տվյալների վերամշակման մեթոդների հետ:', 'ko': '본고는 CASIA의 IWSLT2020 개방역 번역 임무 시스템을 소개한다.올해 우리는 중일과 일중 번역 임무에 참가했다.우리의 시스템은 변압기 모형을 바탕으로 하는 신경 기계 번역 시스템이다.우리는 지식 추출과 역방향 번역을 통해 훈련 데이터를 강화하여 번역 성능을 향상시킨다.영역 데이터 분류와 가중 영역 모델 통합을 도입하여 최종 번역 결과를 생성한다.우리는 서로 다른 모델 설정과 서로 다른 데이터 처리 기술에서 개발된 데이터의 성능을 비교 분석했다.', 'sw': 'Gazeti hili linaelezea mfumo wa CASIA kwa ajili ya kazi ya tafsiri ya domain ya IWSLT 2020. Mwaka huu tunashiriki kazi za utafsiri wa Kijapani na Kijapani. Mfumo wetu ni mfumo wa utafsiri wa mashine ya asili unaofanywa na mtindo wa Transformer. We augment the training data with knowledge distillation and back translation to improve the translation performance.  Usambazaji wa taarifa za ndani na mifano yenye uzito wa domain unaanzishwa ili kutengeneza matokeo ya tafsiri ya mwisho. Tunawalinganisha na uchambuzi ufanisi wa taarifa za maendeleo na mazingira tofauti ya mifano na teknolojia tofauti za upasuaji wa data.', 'bn': 'IWSLT ২০২০ খোলা ডোমেইন অনুবাদ কাজের জন্য ক্যাসিয়ার সিস্টেম বর্ণনা করা হয়েছে। This year we participate in both Chinese Japanese and Japanese Chinese translation tasks.  আমাদের সিস্টেম ট্রান্সফ্রান্সফার মডেলের ভিত্তিতে নিউরুল মেশিন অনুবাদ সিস্টেম। আমরা জ্ঞান বিচ্ছিন্ন এবং পেছনের অনুবাদের সাথে প্রশিক্ষণের তথ্য যোগ করি অনুবাদের প্রদর্শনের উন্নতির জন্য। ডোমেইন ডাটা ক্লাসাফিকেশন এবং ওজন ডোমেইন মডেল এনসেম্বেল চিহ্নিত করা হয়েছে শেষ অনুবাদের ফলাফল তৈরি করার জন্য। আমরা বিভিন্ন মডেল বৈশিষ্ট্য এবং বিভিন্ন তথ্য প্রক্রিয়ার প্রযুক্তির সাথে উন্নয়নের তথ্যের প্রদর্শনের তুলনা', 'am': "This paper describes the CASIA's system for the IWSLT 2020 open domain translation task.  በዚህ ዓመት ቻይንኛ እና ጃፓንኛ ቻይንኛ ትርጉም ሥራ እናጋራለን፡፡ ስብስነታችን የሆኑት የፖስታ መሣሪያን ትርጉም ሲስተም በተመሳሳይ ሞዴል ላይ ነው፡፡ እውቀት ማብራራትን እና ትርጓሜውን ለማሻሻል እናስጠጋለን፡፡ የዶሜን ዳታ መግለጫ እና ሚዛን ዶሜን ሞዴል ምሳሌ ለመፍጠር የመጨረሻውን ትርጉም ፍጻሜ ለመግለጥ ይገልጣል። የድምፅ ዳራዎችን በተለየ የሞዴል አካላት እና ልዩ የዳታ ማቀናጃ ቴክኖችንን እናስተያይዛለን እናስተዋልናለን፡፡", 'ca': "Aquest article descriu el sistema de CASIA per la tasca de traducció de domini obert IWSLT 2020. Aquest any participem en tasques de traducció xinesa i japonesa. El nostre sistema és un sistema de traducció neural basat en el model Transformer. augmentem les dades d'entrenament amb distillació del coneixement i traducció per millorar el rendiment de la traducció. Domain data classification and weighted domain model ensemble are introduced to generate the final translation result.  Comparem i analitzem el rendiment de les dades de desenvolupament amb diferents configuracions models i tècniques de processament de dades.", 'et': 'Käesolevas dokumendis kirjeldatakse CASIA süsteemi IWSLT 2020 avatud domeeni tõlkimise ülesandeks. Sel aastal osaleme nii hiina jaapani kui ka jaapani hiina tõlkeülesannetes. Meie süsteem on Transformeri mudelil põhinev neurotõlkesüsteem. Täiendame koolitusandmeid teadmiste destilleerimise ja tagasitõlkimise abil, et parandada tõlketõhusust. Lõpliku tõlketulemuse genereerimiseks tutvustatakse domeeniandmete klassifitseerimist ja kaalutud domeenimudeli ansamblit. Võrdleme ja analüüsime arendusandmete tulemuslikkust erinevate mudeliseadmete ja erinevate andmetöötlustehnikatega.', 'cs': 'Tento článek popisuje systém CASIA pro úlohu překladu otevřené domény IWSLT 2020. Letos se účastníme jak čínštiny japonštiny, tak japonštiny čínštiny. Náš systém je neuronový strojový překlad založený na modelu transformátoru. Data školení rozšiřujeme o destilaci znalostí a zpětný překlad, abychom zlepšili výkon překladu. Pro generování konečného výsledku překladu jsou uvedeny klasifikace doménových dat a soubor vážených doménových modelů. Porovnáváme a analyzujeme výkonnost vývojových dat s různými nastaveními modelu a různými technikami zpracování dat.', 'fi': 'T채ss채 artikkelissa kuvataan CASIAn j채rjestelm채채 IWSLT 2020 avoimen verkkotunnuksen k채채nt채miseen. T채n채 vuonna osallistumme sek채 kiinan ett채 japanin k채채nt채miseen. J채rjestelm채mme on Transformer-malliin perustuva neurokonek채채nn철sj채rjestelm채. Lis채채mme koulutustietoa tiet채myksen tislauksella ja takaisink채채nt채misell채 k채채nn철ksen suorituskyvyn parantamiseksi. Lopullisen k채채nn철stuloksen tuottamiseksi esitell채채n verkkotunnustietojen luokittelu ja painotettu verkkotunnusmallin kokonaisuus. Vertailemme ja analysoimme kehitysdatan suorituskyky채 erilaisilla malliasetuksilla ja erilaisilla tietojenk채sittelytekniikoilla.', 'bs': 'Ovaj papir opisuje CASIA-ov sistem za zadatak prevoda domena IWSLT 2020. Ove godine učestvujemo u kineskim i japanskim prevodnim zadacima. Naš sistem je sistem za prevod neuralne mašine baziran na modelu transformera. Povećavamo podatke o obuci sa destilacijom znanja i prevodom natrag kako bi poboljšali izvođenje prevoda. Uključuju se klasifikacija podataka domena i model težine domena za proizvedenje konačnog rezultata prevoda. Upoređujemo i analiziramo učinkovitost podataka o razvoju sa različitim modelima i različitim tehnikama obrade podataka.', 'az': 'Bu kağıt IWSLT 2020 açıq domena qurğulaması üçün CASIA sistemini təsbiq edir. Bu il biz Çin, Japon və Çin çeviriş işlərində iştirak edirik. Sistemimiz Transformer modelinin dayanan nöral mašin tərcümə sistemidir. Biz təhsil məlumatlarını elm destilasyonu ilə artırırıq və təhsil etmək üçün geri çeviririk. Domena məlumatı klasifikasiyası və ağırlı domena modeli ensemble sonuncu çevirin nəticəsini yaratmaq üçün daxil edilir. Biz müxtəlif modellər və müxtəlif məlumatlar işləmə teknikləri ilə müxtəlif tədbirlərin performansını və analizə edirik.', 'jv': "This paper describes the LASS's System for the IWSLT 2020 open domain translation task. Tahun iki awak dhéwé ngertukang cara sing Jepang lan Jepang kuwi tarjamahan surat Jepang Sistem awak dhéwé iku sistem itolekak perintah karo Transformer. Awak dhéwé éntuk dadi nggawe barang kelas alam lan mbukak tarjamahan kanggo nggawe tarjamahan. domain data Awak dhéwé ngpisan karo alèhku nggawe akeh nggambar dadi nggawe model karo perusahaan dadi sampeyan karo teknik sing ngewehi operasi dadi.", 'he': 'העיתון הזה מתאר את המערכת של קאסיה למשימת התרגום הפתוחה של IWSLT 2020. השנה אנחנו משתתפים בתפקידים של התרגום הסיני והיפני. המערכת שלנו היא מערכת התרגום של מכונות עצביות מבוססת על מודל טרנספורר. אנחנו מגדילים את נתוני האימונים עם משקה ידע ותרגום אחורה כדי לשפר את ביצועי התרגום. מסווג נתונים של דומין ומזוג מודל דומין משקל מוצג כדי ליצור את תוצאת התרגום הסופית. We compare and analyze the performance on development data with different model settings and different data processing techniques.', 'sk': 'V prispevku je opisan sistem CASIA za nalogo prevajanja odprte domene IWSLT 2020. Letos sodelujemo pri prevajalskih nalogah kitajske japonščine in japonščine kitajske kitajske. Naš sistem je nevronski strojni prevajalni sistem, ki temelji na modelu Transformer. Podatke o usposabljanju dopolnjujemo z destilacijo znanja in prevajanjem nazaj za izboljšanje učinkovitosti prevajanja. Za ustvarjanje končnega rezultata prevoda sta uvedena klasifikacija domenskih podatkov in komplet ponderiranih domenskih modelov. Primerjamo in analiziramo učinkovitost razvojnih podatkov z različnimi nastavitvami modela in različnimi tehnikami obdelave podatkov.', 'ha': "Wannan takardan na faﾉ預ﾉ預'ar CASA na'urar wa IWSLT 2020 buﾉ容 aikin translation. @ item Text character set @ info: whatsthis Munﾃ｣ ﾆ兮ra data na ﾆ冓dﾃ｣ya da fassarar da ilmi da kuma bakin tarjibu dﾃｵmin ya kyautata fassarar fassarar. Domain data classification and weighted domain model ensemble are introduced to generate the final translation result.  Munﾃ｣ samfani da kuma Muke anaﾆ兮yyade fassarar data na danne da tsari masu motsi daban-dabam da zane-zane masu shirya data.", 'bo': 'ཤོག་བྱང་འདིས་CASIA་གི་མ་ལག་དེ་IWSLT 2020་ལ་ཁ་ཕྱེ་ན་ཡོད་པའི་དུས་ཡུལ་སྤྱོད་ཀྱི་འགོད་སྐྱོང་། ད་ལོ་ངོ་ངེད་གཉིས་ཀྱིས་རྒྱ་ནག་དང་ཇུང་རིག་གི་སྤྱི་ཚོགས་ལས་འགུལ་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མ་ལག་ནི་གསར་བསྒྱུར་མ་དབྱིབས་གཞུང་གི་ལག་འཁྱེར་གྱི་མ་ལག་ལུགས་སྒྱུར་མ་ལག་རེད། ང་ཚོས་ཤེས་པའི་དབྱིབས་གྱི་གནས་ཚུལ་གསལ་བཤད་དང་ལོག་བསྒྱུར་བཅོས་ཕྱིར་མཐོང་བྱེད་ཀྱི་ཡོད། Domain data classification and weighted domain model ensemble are introduced to generate the final translation result. ང་ཚོས་དབྱིབས་སྒྲིག་ཆ་མ་འདྲ་བ་དང་ལས་སྦྱོར་བའི་གྲ་སྒྲིག་འགོད་བྱེད་པའི་གྲ་སྒྲིག་འགོད་དང་ལས'}
{'en': 'Deep Blue Sonics’ Submission to IWSLT 2020 Open Domain Translation Task', 'ar': 'تقديم Deep Blue Sonics إلى مهمة ترجمة المجال المفتوح IWSLT 2020', 'fr': 'Soumission de Deep Blue Sonics à la tâche de traduction Open Domain IWSLT 2020', 'es': 'Presentación de Deep Blue Sonic a la tarea de traducción de dominio abierto de IWSLT 2020', 'pt': 'Submissão da Deep Blue Sonics para a tarefa de tradução de domínio aberto IWSLT 2020', 'ja': 'Deep Blue SonicsのIWSLT 2020オープンドメイン翻訳タスクへの提出', 'zh': '深蓝索尼克为 IWSLT 2020 开域译事', 'ru': 'Представление Deep Blue Sonics на IWSLT 2020 Open Domain Translation Task', 'hi': "डीप ब्लू Sonics 'IWSLT 2020 ओपन डोमेन अनुवाद कार्य के लिए प्रस्तुत", 'ga': 'Aighneacht Deep Blue Sonics chuig Tasc Aistriú Fearainn Oscailte IWSLT 2020', 'ka': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'hu': 'Deep Blue Sonics beküldése az IWSLT 2020 Domain megnyitása Fordítási feladat', 'el': 'Υποβολή της στο έργο μετάφρασης ανοικτού τομέα του IWSLT 2020', 'it': 'Presentazione di Deep Blue Sonics al compito di traduzione di un dominio aperto IWSLT 2020', 'lt': 'Giliai mėlynų dainų pristatymas į IWSLT 2020 atviro domeno vertimo užduotį', 'mk': 'Предавање на длабоко сини соници на IWSLT 2020 отворена задача за преведување на домен', 'kk': 'IWSLT 2020 Open Domain Translation Task', 'ms': "Submission Blue Deep Sonics' to IWSLT 2020 Open Domain Translation Task", 'ml': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'mt': "Sottomissjoni ta' Sonics Blu fil-fond għal kompitu ta' traduzzjoni tad-dominju miftuħ IWSLT 2020", 'mn': 'IWSLT 2020 Open Domain Translation Task', 'no': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'pl': 'Zgłoszenie Deep Blue Sonics do IWSLT 2020 Open Domain Translation Task', 'ro': 'Depunerea Deep Blue Sonics la IWSLT 2020 Activitatea de traducere a domeniului deschis', 'sr': 'Duboka podrška plavog sonika na IWSLT 2020 Otvoren domen prevod zadatak', 'si': "Deep Blue Sonics' Subaction to IWSLT 202 Open Domain translation Job", 'sv': 'Deep Blue Sonics inlämning till IWSLT 2020 Översättningsuppgift för öppen domän', 'so': 'Submission to IWSLT 2020 Open Domain Translation Task', 'ta': 'IWSLT 2020 க்கு ஆழமான நீலப் பானிக்குகளின் ஒப்பீடு', 'ur': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'uz': 'Comment', 'vi': 'Liên kết sâu Blue Sonics cho IWSLT 2020 Mở Nhiệm vụ dịch miền miền rộng', 'bg': 'Дийп Блу Соникс представя задачата за превод с отворен домейн', 'da': "Deep Blue Sonics' indsendelse til IWSLT 2020 Åbn domæne Oversættelsesopgave", 'nl': 'Indiening van Deep Blue Sonics aan IWSLT 2020 Open Domain Translation Task', 'hr': 'Duboka plava sonika podnosi na IWSLT 2020 Otvoreni domeni prevod zadatak', 'id': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'de': "Deep Blue Sonics' Einreichung bei IWSLT 2020 Open Domain Translation Task", 'ko': '짙은 남색 초음속 IWSLT 2020 개방역 번역 퀘스트 제출', 'fa': 'Submission of Blue Sonics deep to IWSLT 2020 Open Domain Translation Task', 'af': 'Deep Blue Sonics se Submission na IWSLT 2020 Open Domain Translation Task', 'tr': 'IWSLT 2020 Aç Saýlaw Terjime Görevi', 'sw': 'Tamko la Wasafiri wa Kikundi cha Blue kwa IWSLT 2020 Open Translation Task', 'sq': 'Dërgimi i Sonikeve Blu të thella në IWSLT 2020', 'am': 'ወደ IWSLT 2020 ክፈት ዶሜን ትርጉም ስራ', 'az': 'IWSLT 2020 Open Domain Translation Task', 'hy': 'Deep Blue Sonics-ի ներկայացումը IwPLT 2020-ի բաց բնագավառի թարգմանման գործին', 'bn': 'IWSLT ২০২০ এ গভীর নীল সোনিকের সাবমিশন খোলা ডোমেন অনুবাদ কাজ', 'bs': 'Submission dubokog plavog sonika na IWSLT 2020 Otvoren domeni prevod zadatak', 'ca': 'Submissió de Sonics Blaus Profunds a la tasca de traducció del domini obert IWSLT 2020', 'cs': 'Podání Deep Blue Sonics do IWSLT 2020 Open Domain Translation Task', 'fi': 'Deep Blue Sonicsin julkaisu IWSLT 2020 Open Domain Translation Tehtävä', 'et': 'Deep Blue Sonicsi esitamine IWSLT 2020 avatud domeeni tõlkimise ülesandele', 'jv': "deep blossom Soiks' Submis to IWSLT 2020 Open domain translation task", 'ha': 'Submit to IWSLT 2020 Open Domen Translate Tasks', 'he': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task", 'sk': 'Deep Blue Sonics predloži prevajalsko nalogo odprte domene IWSLT 2020', 'bo': "Deep Blue Sonics' Submission to IWSLT 2020 Open Domain Translation Task"}
{'en': 'We present in this report our submission to IWSLT 2020 Open Domain Translation Task. We built a data pre-processing pipeline to efficiently handle large noisy web-crawled corpora, which boosts the BLEU score of a widely used transformer model in this translation task. To tackle the open-domain nature of this task, back- translation is applied to further improve the translation performance.', 'fr': "Nous présentons dans ce rapport notre soumission à la tâche de traduction Open Domain IWSLT 2020. Nous avons créé un pipeline de prétraitement des données pour gérer efficacement les grands corpus analysés sur le Web, ce qui augmente le score BLEU d'un modèle de transformateur largement utilisé dans cette tâche de traduction. Pour faire face à la nature ouverte de cette tâche, la rétro-traduction est appliquée afin d'améliorer encore les performances de traduction.", 'ar': 'نقدم في هذا التقرير تقديمنا إلى IWSLT 2020 Open Domain Translation Task. لقد قمنا ببناء خط أنابيب للمعالجة المسبقة للبيانات للتعامل بكفاءة مع مجموعات كبيرة مزعجة على شبكة الإنترنت ، مما يعزز درجة BLEU لنموذج محول مستخدم على نطاق واسع في مهمة الترجمة هذه. لمعالجة طبيعة المجال المفتوح لهذه المهمة ، يتم تطبيق الترجمة العكسية لتحسين أداء الترجمة.', 'pt': 'Apresentamos neste relatório nossa submissão à Tarefa de Tradução de Domínio Aberto do IWSLT 2020. Construímos um pipeline de pré-processamento de dados para lidar eficientemente com grandes corpora ruidosos rastreados na web, o que aumenta a pontuação BLEU de um modelo de transformador amplamente utilizado nesta tarefa de tradução. Para lidar com a natureza de domínio aberto dessa tarefa, a retrotradução é aplicada para melhorar ainda mais o desempenho da tradução.', 'es': 'Presentamos en este informe nuestra presentación a IWSLT 2020 Open Domain Translation Task. Creamos un canal de preprocesamiento de datos para manejar de manera eficiente grandes y ruidosos corpus rastreados por la web, lo que aumenta la puntuación BLEU de un modelo de transformador ampliamente utilizado en esta tarea de traducción. Para abordar la naturaleza de dominio abierto de esta tarea, se aplica la traducción inversa para mejorar aún más el rendimiento de la traducción.', 'hi': 'हम इस रिपोर्ट में IWSLT 2020 ओपन डोमेन अनुवाद कार्य के लिए हमारे सबमिशन प्रस्तुत करते हैं। हमने बड़े शोर वेब-क्रॉल किए गए कॉर्पोरेट को कुशलतापूर्वक संभालने के लिए एक डेटा प्री-प्रोसेसिंग पाइपलाइन का निर्माण किया, जो इस अनुवाद कार्य में व्यापक रूप से उपयोग किए जाने वाले ट्रांसफॉर्मर मॉडल के BLEU स्कोर को बढ़ाता है। इस कार्य की ओपन-डोमेन प्रकृति से निपटने के लिए, अनुवाद प्रदर्शन को और बेहतर बनाने के लिए बैक-ट्रांसलेशन लागू किया जाता है।', 'ja': 'このレポートでは、IWSLT 2020 Open Domain Translation Taskへの提出を紹介しています。私たちは、この翻訳タスクで広く使用されている変圧器モデルのBLEUスコアを向上させる、大きなノイズの多いウェブクロールされたコーラを効率的に処理するためのデータ前処理パイプラインを構築しました。このタスクのオープンドメイン性に対処するために、翻訳パフォーマンスをさらに向上させるためにバック翻訳が適用されます。', 'zh': '我们在本报中介介了我们提交给IWSLT 2020开域译职的申请。 为数预处理管,以治大 Web 爬网语料库,以重转换器BLEU之分。 为开域性,宜反译进一步提高之。', 'ru': 'В настоящем отчете мы представляем нашу заявку на выполнение задачи по переводу открытых доменов IWSLT 2020. Мы построили трубопровод предварительной обработки данных для эффективной обработки больших шумных обтекаемых веб-корпусов, что повышает оценку BLEU широко используемой трансформаторной модели в этой задаче перевода. Чтобы решить открытый характер этой задачи, бэк-перевод применяется для дальнейшего улучшения производительности перевода.', 'ga': 'Cuirimid i láthair sa tuarascáil seo ár n-aighneacht do Thasc Aistriú Fearainn Oscailte IWSLT 2020. Chuireamar píblíne réamhphróiseála sonraí le chéile chun corpora mór torannacha cráite ar an ngréasán a láimhseáil go héifeachtach, rud a ardaíonn an scór BLEU ar shamhail claochladáin a úsáidtear go forleathan sa tasc aistriúcháin seo. Chun dul i ngleic le nádúr oscailte an taisc seo, cuirtear cúlaistriúchán i bhfeidhm chun feidhmíocht an aistriúcháin a fheabhsú tuilleadh.', 'el': 'Παρουσιάζουμε στην παρούσα έκθεση την υποβολή μας στο έργο μετάφρασης ανοικτού τομέα. Κατασκευάσαμε έναν αγωγό προεπεξεργασίας δεδομένων για την αποτελεσματική διαχείριση μεγάλων θορυβωδών σωμάτων μέσω διαδικτύου, το οποίο αυξάνει την βαθμολογία ενός ευρέως χρησιμοποιούμενου μοντέλου μετασχηματιστή σε αυτήν την εργασία μετάφρασης. Για να αντιμετωπιστεί ο ανοιχτός χαρακτήρας αυτού του έργου, εφαρμόζεται η οπισθοδρομική μετάφραση για να βελτιωθεί περαιτέρω η απόδοση της μετάφρασης.', 'hu': 'Ebben a jelentésben bemutatjuk benyújtásunkat az IWSLT 2020 Open Domain Fordítási feladatra. Adatfeldolgozó csővezetéket építettünk a nagy zajos webes feltérképezésű corporák hatékony kezelésére, ami növeli egy széles körben használt transzformátormodell BLEU pontszámát ebben a fordítási feladatban. A feladat nyílt területű jellegének kezelése érdekében a fordítási teljesítmény további javítása érdekében visszafordítást alkalmaznak.', 'ka': 'ჩვენ ამ შეტყობინებში ჩვენი გადაწყენება IWSLT 2020-ში გახსნა დემონის გადაწყენება. ჩვენ დავყენეთ მონაცემების წინაპროცესების გარემოქმედებით, რომელიც ძალიან გამოყენებული ტრანფორმაციის მოდელის გარემოქმედებით, რომელიც ამ გარემოქმედებით გარემოქმედებით გარემოქმედებით ამ დავალების გახსნა დიომინის სახელსაწყოთა სახელსაწყოთა სახელსაწყოთა სახელსაწყოთა სახელსაწყოთა სახელსაწყოთან დააყენება.', 'it': "Presentiamo in questo rapporto la nostra presentazione all'Open Domain Translation Task IWSLT 2020. Abbiamo costruito una pipeline di pre-elaborazione dei dati per gestire in modo efficiente grandi corpora web-crawled rumorosi, che aumenta il punteggio BLEU di un modello di trasformatore ampiamente utilizzato in questo compito di traduzione. Per affrontare la natura open-domain di questo compito, viene applicata la traduzione posteriore per migliorare ulteriormente le prestazioni di traduzione.", 'kk': 'Біз осы хабарламада IWSLT 2020 дегенді ашу доменді аудару тапсырмасына жібереміз. Біз бұл аудармалы тапсырманың көп қолданылған транформациялық моделінің BLEU нәтижесін өзгерту үшін деректерді алдын- өзгерту жолын құрдық. Бұл тапсырманың ашық домен қасиетін өзгерту үшін, аудармаларды жақсарту үшін қайта аудармалы қолданылады.', 'mk': 'Во овој извештај го претставуваме нашето поднесување на IWSLT 2020 отворена задача за преведување на домен. We built a data pre-processing pipeline to efficiently handle large noisy web-crawled corpora, which boosts the BLEU score of a widely used transformer model in this translation task.  За да се реши природата на отворениот домен на оваа задача, назад- преводот се применува за понатамошно подобрување на преводот.', 'ms': 'Kami memperkenalkan dalam laporan ini penghantaran kami kepada Tugas Terjemahan Domain Buka IWSLT 2020. Kami bina saluran paip-pemprosesan data untuk mengendalikan secara efisien korpra web-crawled yang berbunyi besar, yang meningkatkan skor BLEU bagi model pengubah yang digunakan secara luas dalam tugas terjemahan ini. Untuk menangani sifat domain terbuka tugas ini, terjemahan-belakang dilaksanakan untuk meningkatkan prestasi terjemahan lebih lanjut.', 'ml': 'ഈ റിപ്പോര്\u200dട്ടില്\u200d ഞങ്ങള്\u200d നമ്മുടെ കീഴ്പെടുത്തിയിരിക്കുന്നു IWSLT 2020 തുറക്കുന്ന ഡൊമെയിന്\u200d പരിഭ ഞങ്ങള്\u200d ഒരു ഡേറ്റാ പ്രോസിക്ക് പൈപ്പെലിന്\u200d നിര്\u200dമ്മിച്ചിരിക്കുന്നു. ഒരു വലിയ ശബ്ദം വെബ്- ക്രൌള്\u200d കോര്\u200dപ്പോരാ കൈകാര്യം ചെയ്യാന്\u200d വേണ്ടി. ഈ ഈ ജോലിയുടെ തുറന്ന ഡൊമെയിന്\u200d സ്വഭാവം നേരിടാന്\u200d പ്രയോഗിക്കുന്നു, പരിഭാഷപ്രഭാഷണം കൂടുതല്\u200d മെച്ചപ്പെടു', 'mn': 'Бид энэ мэдээллээр IWSLT 2020 оны Open Domain Translation Task-д өгсөн. Бид өгөгдлийн урд үйлдвэрлэх хоолойн шугам бүтээсэн бөгөөд энэ хөрөнгө дамжуулагч үйлдвэрлэхэд маш том чимээгүй веб-шүлэгдсэн корпора ашиглаж байдаг. Энэ нь БЛЕУ-ын тоо хэмжээний ашиглаж Энэ ажлын нээлттэй хэмжээний байдлыг зохицуулахын тулд эргээд орчуулах үйл ажиллагааг илүү сайжруулахын тулд хэрэглэгддэг.', 'mt': 'F’dan ir-rapport qed nippreżentaw is-sottomissjoni tagħna lill-IWSLT 2020 Open Domain Translation Task. Bniejna pipeline ta’ qabel l-ipproċessar tad-dejta biex inmaniġġjaw b’mod effiċjenti korpra kbira storbjuża bl-internet imbuzzata, li ssaħħa ħ il-punteġġ BLEU ta’ mudell trasformatur użat ħafna f’dan il-kompitu ta’ traduzzjoni. Biex tiġi indirizzata n-natura open-domain ta’ dan il-kompitu, tiġi applikata t-traduzzjoni lura biex tkompli tittejjeb il-prestazzjoni tat-traduzzjoni.', 'pl': 'W niniejszym raporcie przedstawiamy naszą zgłoszenie do IWSLT 2020 Open Domain Translation Task. Zbudowaliśmy rurociąg wstępnego przetwarzania danych, aby skutecznie obsługiwać duże hałaśliwe korpusy internetowe, co zwiększa wynik BLEU szeroko stosowanego modelu transformatora w tym zadaniu tłumaczenia. Aby rozwiązać otwarty charakter tego zadania, stosuje się tłumaczenie wsteczne w celu dalszej poprawy wydajności tłumaczenia.', 'no': 'Vi presenterer i denne rapporten vår oppføring til IWSLT 2020 Open Domain Translation Task. Vi bygge eit dataforhandteringsrøyr for å handtere stor støy nettkrawled korpora, som styrer BLEU- poeng av eit breidde brukt transformeringsmodell i denne omsetjinga. For å løysa den opne domenenaturen av denne oppgåva, vert tilbakeomsetjinga brukt for å forbetra omsetjinga.', 'ro': 'Prezentăm în acest raport depunerea noastră la IWSLT 2020 Open Domain Translation Task. Am construit o conductă de pre-procesare a datelor pentru a gestiona în mod eficient corporele mari zgomotoase cu crawlere web, ceea ce sporește scorul BLEU al unui model de transformator utilizat pe scară largă în această sarcină de traducere. Pentru a aborda natura de domeniu deschis a acestei sarcini, se aplică traducerea înapoi pentru a îmbunătăți în continuare performanța traducerii.', 'lt': 'Šiame pranešime pristatome savo pasiūlymą „IWSLT 2020“ atvirojo domeno vertimo uždaviniui. Mes sukūrėme duomenų išankstinio apdorojimo vamzdyną, kad veiksmingai valdytume didelę triukšmingą tinklinę korporą, kuri padidina plačiai naudojamo transformatoriaus modelio BLEU rezultatą šioje vertimo užduotyje. Siekiant išspręsti šios užduoties atviros srities pobūdį, vertimas atgal taikomas tolesniam vertimo rezultatų gerinimui.', 'sr': 'Predstavljamo u ovom izveštaju našu predanost zadatku za prevod domena IWSLT 2020. Napravili smo preobrađivanje podataka cijevi za efikasno rješavanje velike bučne mrežne korporacije, koja povećava BLEU rezultat široko korištenog model a transformacije u ovom prevodnom zadatku. Da bi se riješila priroda otvorenog domena ovog zadatka, prevod se primjenjuje da bi se dalje poboljšao izvođenje prevoda.', 'so': 'Waxaannu warqadan ku soo bandhignaa cashuurta aan u soo dirno IWSLT 2020 oo furan Domain turjumista. Waxaannu dhisnay baabuur baaritaanka ka hor-baaraandegista, si aad u faa’iido u qabsato shirkad aad u weyn oo web-crawled ah, kaasoo boosteraya kooxda BLEU oo ah model aad u isticmaalaya beddelasho oo ku saabsan waxbarashadan. Si loo qabsado dabeecadda furan ee shaqadan waxaa loo codsadaa turjumista dib-u-dib si loo sii kordhiyo sameynta turjumista.', 'si': 'අපි මේ වාර්තාවේ අපේ පිළිගන්න IWSLT 2020ට දාන්නේ ඩොමේන් වාර්තාව වැඩක් විවෘත කරන්න. අපි දත්ත ප්\u200dරක්\u200dරියාස කරපු පායිප්ලින් එකක් හදන්නේ ලොකු ශබ්ද වෙබ් ක්\u200dරායුල් කරපු කොර්පෝරාව හැකිරීමට, ඒකෙන් මේ වාර්ථාපන මේ වැඩේ විවෘත ස්වභාවිතාව සටන් කරන්න, පස්සේ- වාර්ථාව අවශ්\u200dය වෙනුවෙන් වාර්ථාව වැඩ කරන්න.', 'sv': 'Vi presenterar i denna rapport vårt bidrag till IWSLT 2020 Open Domain Translation Task. Vi byggde en databehandlingspipeline för att effektivt hantera stora bullriga webbgenomsökta korporar, vilket ökar BLEU-poängen för en allmänt använd transformatormodell i denna översättningsuppgift. För att ta itu med uppgiftens öppna domänkaraktär används backöversättning för att ytterligare förbättra översättningens prestanda.', 'ta': '@ info: whatsthis மொழிபெயர்ப்பு மாற்று மாற்றும் மாதிரியின் பெரிய சப்தமான முன் செயல்பாட்டு பைப்லைனை வெளிப்படையாக கையாள ஒரு தகவலை உருவாக்கினோம். இந்த பணியின் திறந்த களத்தின் இயற்கையை பொருத்த, மொழிபெயர்ப்பு மொழிபெயர்ப்பு மேலும் மொழிபெயர்ப்பு செய்', 'ur': 'ہم اس راپورٹ میں اپنا ادعا کرنا IWSLT 2020 کھول دیمین ترجمہ ٹاکس میں پیش کرتے ہیں۔ ہم نے ایک ڈاکٹی پیش پرسس پئیپ لین بنائی ہے جو اس ترجمہ کے کام میں بہت بڑی آواز ویب کرولے کی کوروں کو اثبات کے ساتھ تحمل کرنے کے لئے ہے، جو BLEU اسکور کو بڑھاتا ہے۔ اس کام کے کھلے ڈومین کی طبیعت کے ساتھ حل کرنے کے لئے، پیچھے ترجمہ کے لئے زیادہ ترجمہ کرنا کے لئے لازم کیا جاتا ہے.', 'uz': '@ info Bu tarjima vazifani katta ishlab chiqarish uchun bir maʼlumot pipelini ishlab chiqardik. Bu tarjima qilish vazifasida katta ishlatilgan shaxsiy tarjima modelini BLEU qiymatini oshirish mumkin. @ info: whatsthis', 'vi': 'Chúng tôi giới thiệu trong báo cáo này đơn xin được giao dịch cho IWSLT 2020 Open Domain Task. Chúng tôi đã xây dựng một đường ống xử lý dữ liệu để xử lý hiệu quả các hạ sĩ quan bò qua mạng ồn ào, giúp tăng số lượng nguyên vẹn của một mô hình biến đổi được sử dụng rộng rãi trong nhiệm vụ dịch chuyển này. Để giải quyết vấn đề công việc này, dịch lại được áp dụng để cải thiện hiệu suất dịch chuyển.', 'bg': 'В този доклад представяме нашето представяне на задачата за превод с отворен домейн. Изградихме тръбопровод за предварителна обработка на данни, за да се справим ефективно с големи шумни корпуси, обхождани в мрежата, което увеличава резултата на широко използван трансформаторен модел в тази задача за превод. За да се справи с отворения характер на тази задача, се прилага обратен превод за допълнително подобряване на ефективността на превода.', 'nl': 'We presenteren in dit rapport onze inzending aan IWSLT 2020 Open Domain Translation Task. We hebben een data-pre-processing pipeline gebouwd om grote noise web-crawled corpora efficiënt te verwerken, wat de BLEU score van een veel gebruikt transformatormodel in deze vertaaltaak verhoogt. Om het open-domein karakter van deze taak aan te pakken, wordt back-translation toegepast om de vertaalprestaties verder te verbeteren.', 'da': 'Vi præsenterer i denne rapport vores indsendelse til IWSLT 2020 Open Domain Translation Task. Vi har bygget en dataforhåndsbehandling pipeline til effektivt at håndtere store støjende web-crawlede corpora, hvilket øger BLEU scoren for en meget udbredt transformermodel i denne oversættelsesopgave. For at tackle opgavens åbne domæne anvendes back-oversættelse for yderligere at forbedre oversættelsesevnen.', 'hr': 'Predstavljamo u ovom izvještaju našu prijavu zadatku otvorenog domena za prevod IWSLT 2020. Napravili smo preobrađujući cijev podataka kako bi učinkovito riješili veliku bučnu mrežnu korporaciju, koja povećava BLEU rezultat široko korištenog model a transformacije u ovom prevodnom zadatku. Za rješavanje prirode otvorenog domena ovog zadatka, prevod se primjenjuje za daljnje poboljšavanje učinka prevoda.', 'de': 'Wir stellen in diesem Bericht unsere Einreichung an IWSLT 2020 Open Domain Translation Task vor. Wir haben eine Datenvorverarbeitungs-Pipeline aufgebaut, um große rauschende Web-Crawling-Korpora effizient zu handhaben, was den BLEU-Score eines weit verbreiteten Transformatormodells in dieser Übersetzungsaufgabe erhöht. Um die Open-Domain-Natur dieser Aufgabe anzugehen, wird Back-Translation angewendet, um die Übersetzungsleistung weiter zu verbessern.', 'ko': '이 보고서에서는 IWSLT 2020 개방형 도메인 번역 임무를 제공합니다.우리는 대형 소음 네트워크 파충류 자료 라이브러리를 효과적으로 처리하기 위해 데이터 예처리 파이프를 구축했는데, 이것은 이 번역 임무에서 광범위하게 사용되는 변환기 모델의 BLEU 점수를 높였다.이 임무의 개방적 성격을 해결하기 위해 역방향 번역을 채택하여 번역 성능을 더욱 향상시켰다.', 'fa': 'ما در این گزارش تسلیم کردن ما به کار ترجمه دامنی باز IWSLT 2020 را پیشنهاد می کنیم. ما یک لوله پیش از پردازش داده ساختیم تا کارسازی بزرگ\u200cتر از وب\u200cکراول\u200cهای صوتی را حل کند، که امتیاز BLEU از یک مدل تغییر\u200cدهنده\u200cی وسیع استفاده شده در این کار ترجمه را افزایش دهد. برای حل طبیعت دامنه باز این کار، ترجمه پشتی برای بهتر کردن عملکرد ترجمه استفاده می\u200cشود.', 'id': 'Kami mempersembahkan dalam laporan ini pengiriman kami ke IWSLT 2020 Open Domain Translation Task. Kami membangun pipeline pre-proses data untuk mengendalikan secara efisien besar keributan web-crawled corpora, yang meningkatkan skor BLEU dari model transformer yang sangat digunakan dalam tugas terjemahan ini. Untuk mengatasi sifat domain terbuka tugas ini, terjemahan kembali diaplikasikan untuk meningkatkan prestasi terjemahan lebih lanjut.', 'sw': 'Tunatoa kwenye ripoti hii ya ujumbe wetu wa IWSLT 2020 Mfungu wa Tafsiri ya Domain. Tumetengeneza pipeline ya data kabla ya kuchukua hatua kwa ufanisi kukabiliana na kampuni kubwa yenye kelele ya mtandaoni, ambayo inaongeza vipimo vya BLEU vya mtindo wa mabadiliko kwa kiasi kikubwa uliotumika katika kazi hii ya tafsiri. Ili kukabiliana na asili ya wazi ya kazi hii, tafsiri ya nyuma inatumika kuboresha ufanisi wa tafsiri.', 'tr': 'Biz bu raporda IWSLT 2020-nji 첵ylda A챌 Domain Terjime G철revimizi g철rke첵채ris Biz esasy g체rr체흫li web-g체rr체흫li korporasyny etkinlik 체챌in data 철흫체nden i힊le첵채n pipelini in 힊a etdik. Bu terjime g철revinde BLEU sanyny 체첵tged첵채r. Bu zady흫 a챌yk-domeny tebli휓ini 챌철zmek 체챌in, terjime etkinli휓ini daha da geli힊tirmek 체챌in yada terjime edilir.', 'af': "Ons voorsien in hierdie raporteer ons onderskrywing na IWSLT 2020 Open Domein Vertaling Taak. Ons het 'n data voor-verwerking pyplyn gebou om effektief groot ruis web-krawled korpora te hanteer, wat die BLES-telling van 'n vaste gebruik transformer model in hierdie vertaling taak boonstem. Om die open-domein-natuur van hierdie taak te trek, word terug-vertaling aangepas om die vertaling uitvoerings verder te verbeter.", 'am': 'በዚህ ሪፖርት ውስጥ ወደIWSLT 2020 የዶሜን ትርጉም ማድረግ እናቀርባለን፡፡ በዚህ ትርጓሜ ውስጥ የተጠቃሚ ለውጥ ሞዴል የBLEU ደረጃውን በጥቅልቅ የሚጠቅመውን የድምፅ ድምፅ አዋቂ ኮርፖርት ለመቀበል አግኝተናል፡፡ የዚህን ስራ የክፈት ዶሜን ሥርዓት ለመቀናቀል፣ የኋላ-ትርጉም ትርጓሜውን ለመጠቀም ይግባራል፡፡', 'sq': 'We present in this report our submission to IWSLT 2020 Open Domain Translation Task.  Ne ndërtuam një tubacion paraprocesimi të të dhënave për të trajtuar efektivisht trupin e madh të zhurmshëm në internet, i cili rrit rezultatin BLEU të një modeli transformues të përdorur gjerësisht në këtë detyrë përkthimi. Për të trajtuar natyrën e domenit të hapur të kësaj detyre, përkthimi mbrapsht aplikohet për të përmirësuar më tej performancën e përkthimit.', 'bn': 'আমরা এই রিপোর্টে উপস্থাপন করেছি আমাদের ইউএসএলটি ২০২০ সালের প্রতি আমাদের জমা দিয়েছি ডোমেন অনুবাদ করার কাজ আমরা একটি ডাটা প্রক্রিয়ার পূর্ব পাইপেলিন নির্মাণ করেছি কার্যকর কর্পোরার জন্য, যা এই অনুবাদের কাজে ব্যাপকভাবে ব্যবহৃত পরিবর্তন মডেল বাড়িয়ে দেয়। এই কাজের উন্মুক্ত ডোমেইন প্রকৃতির সাথে যুক্ত করার জন্য, অনুবাদের অনুবাদ আরো উন্নত করার জন্য প্রয়োগ করা হয়েছে।', 'az': "Biz bu raporda IWSLT 2020'in açıq Domain Çeviri Göndərməyimizi göstəririk. Biz böyük səslənmiş web-crawled korporasını müvəffəqiyyətlə idarə etmək üçün məlumatları ön işləmə pipeline in şa etdik. Bu, bu çeviri işində çox kullanılan transformer model in in BLEU nöqtəsini artırar. Bu işin açıq-domenin təbiətini çəkmək üçün, geri-tercümə təbiətini daha yaxşılaşdırmaq üçün istifadə edilir.", 'ca': "En aquest informe presentem la nostra presentació a la IWSLT 2020 Open Domain Translation Task. Vam construir un pipeline de preprocessament de dades per manejar eficientment grans corpores ruidosos a la web, que augmenta la puntuació BLEU d'un model de transformador amplament utilitzat en aquesta tasca de traducció. To tackle the open-domain nature of this task, back- translation is applied to further improve the translation performance.", 'cs': 'V této zprávě představujeme naše podání IWSLT 2020 Open Domain Translation Task. Postavili jsme potrubí pro předzpracování dat pro efektivní zpracování velkých hlučných webových korpusů, což zvyšuje BLEU skóre široce používaného transformátorového modelu v tomto překladu. Pro řešení otevřené domény tohoto úkolu se používá zpětný překlad pro další zlepšení výkonnosti překladu.', 'et': 'Käesolevas aruandes esitame oma esituse IWSLT 2020 avatud domeeni tõlke ülesandele. Ehitasime andmete eeltöötlusjuhtme, et tõhusalt käsitleda suuri mürakaid veebi-roomitavaid korpuseid, mis suurendab laialdaselt kasutatava trafomodeli BLEU skoori selles tõlketöös. Selle ülesande avatud olemusega tegelemiseks rakendatakse tagantõlkimist, et tõlketõhusust veelgi parandada.', 'fi': 'T채ss채 raportissa esittelemme julkaisumme IWSLT 2020 Open Domain Translation Task -ohjelmaan. Rakensimme datan esik채sittelyputken suurten meluisten verkkory철mittyjen korpusten tehokkaaseen k채sittelyyn, mik채 parantaa laajasti k채ytetyn muuntajamallin BLEU-pistem채채r채채 t채ss채 k채채nn철sty철ss채. Teht채v채n avoimeen luonteeseen vastaamiseksi k채ytet채채n j채lkik채채nt채mist채 k채채nn철ksen suorituskyvyn parantamiseksi entisest채채n.', 'bs': 'Predstavljamo u ovom izvješću naše podatke IWSLT 2020. otvorenom domenu prevodnom zadatku. Napravili smo preobrađujući cijev podataka kako bi učinkovito riješili veliku bučnu mrežnu korporaciju, koja povećava BLEU rezultat široko korištenog model a transformera u ovom prevodnom zadatku. Da bi se riješila priroda otvorenog domena ovog zadatka, primjena se za daljnje poboljšavanje učinka prevođenja.', 'hy': 'Այս զեկույցում մենք ներկայացնում ենք մեր ներկայացումը IwPLT 2020-ի բաց բնագավառի թարգմանման գործին: Մենք կառուցեցինք տվյալների նախավերաշարժման խողովակաշար, որպեսզի արդյունավետ վերահսկենք մեծ աղմկոտ վեբ-թափված կոպորան, որը բարձրացնում է բլեուզ գնահատականը լայնորեն օգտագործված վերափոխող մոդելի այս թարգմանման գործում Այս խնդրի բաց բնույթին լուծելու համար հետադարձ թարգմանությունը կիրառվում է թարգմանության արդյունքների շարունակելու համար:', 'jv': "Awak dhéwé nggawe barang iki dadi kanggo IWSLT 2020 Open domain translation task. Awak dhéwé ngrebut sistem data-wis mulasar tentang kanggo ngilanggar banter perusahaan web-kedhalan sing nggawe barang dumadhi, sing sumungane dhéwé Where's the BIESpun sing ditawak dhéwé model sing paling nggawe tarjamahan iki. Mbok tanggal kanggo kowe jenengan token open-domain ning task iki, mbok- terjamahan kanggo ngubah banter kanggo tukang tarjamahan.", 'ha': '@ info: whatsthis Mun gina wani pilin da aka yi amfani da shi gaba-aiki don ka yi amfani da shi game da shirin sauti mai girma na web-cracracrash, wanda ke ƙarfafa musamman BLEU mai amfani da shi mai yawa a cikin wannan aikin fassarar. @ action: button', 'sk': 'V tem poročilu predstavljamo našo predložitev na nalogo prevajanja odprtih domen IWSLT 2020. Zgradili smo cevovod za predhodno obdelavo podatkov za učinkovito ravnanje z velikimi hrupnimi spletnimi korpusi, kar povečuje rezultat BLEU široko uporabljenega transformatorskega modela v tej prevajalski nalogi. Za reševanje odprte narave te naloge se uporablja nazaj prevajanje za nadaljnje izboljšanje učinkovitosti prevajanja.', 'he': 'אנחנו מציגים בדו"ח הזה את ההעברה שלנו למשימת התרגום הפתוחה של IWSLT 2020. We built a data pre-processing pipeline to efficiently handle large noisy web-crawled corpora, which boosts the BLEU score of a widely used transformer model in this translation task.  כדי להתמודד עם טבע התרשמה הפתוח של המשימה הזאת, התרגום מאחור מתפקד כדי לשפר את ביצועי התרגום.', 'bo': 'ང་ཚོས་IWSLT 2020་ལ་སྙན་ཞུ་འདི་ནང་དུ་ཚོར་འདྲ་བཤུ་བྱེད་པ་ཡིན། We built a data pre-processing pipeline to efficiently handle large noisy web-crawled corpora, which boosts the BLEU score of a widely used transformer model in this translation task. བྱ་འགུལ་འདིའི་ཁ་ཕྱེས་པའི་དྲ་ཁྱབ་ཀྱི་རང་བཞིན་སྤྲོ་སྟངས་ལ་རྒྱབ་སྐྱོར་བྱེད་ན་ཕར་སྤྲོད་ཀྱི་ཡོད།'}
{'en': 'ISTIC’s Neural Machine Translation System for IWSLT’2020', 'ar': "نظام الترجمة الآلية العصبية ISTIC لـ IWSLT'2020", 'fr': "Système de traduction automatique neuronale d'ISTIC pour IWSLT'2020", 'es': "Sistema de traducción automática neuronal de ISTIC para IWSLT'2020", 'pt': "Sistema de tradução automática neural do ISTIC para IWSLT'2020", 'zh': 'ISTIC 之神经机器翻译统,施于 IWSLT2020', 'ja': "ISTIC 's Neural Machine Translation System for IWSLT' 2020", 'hi': "IWSLT'2020 के लिए ISTIC की तंत्रिका मशीन अनुवाद प्रणाली", 'ru': "Система нейронного машинного перевода Istic для IWSLT'2020", 'ga': "Córas Néar-Aistrithe Meaisín ISTIC do IWSLT'2020", 'el': "Το Νευρικό Σύστημα Μηχανικής Μετάφρασης του ISTIC για την IWSLT'2020", 'ka': "ISTIC- ის ნეირალური მაქინის განსაგულისხმების სისტემა IWSLT'2020", 'hu': "Az ISTIC idegi gépi fordító rendszere az IWSLT'2020 számára", 'it': "Sistema di traduzione automatica neurale ISTIC per IWSLT'2020", 'kk': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'lt': 'ISTIC „IWSLT 2020“ neurologinių mašinų vertimo sistema', 'mk': 'Системот за преведување на неврални машини на ISTIC за IWSLT 2020', 'ms': "Sistem Terjemahan Mesin Neural ISTIC untuk IWSLT'2020", 'ml': "IWSLT' 2020- നുള്ള ISTIC നെയുറല്\u200d യന്ത്രം പരിഭാഷപ്പെടുത്തുന്ന സിസ്റ്റം", 'no': "ISTIC sin Neural Machine Translation System for IWSLT' 2020", 'mn': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'pl': "System neuronowego tłumaczenia maszynowego ISTIC dla IWSLT'2020", 'ro': "Sistemul de traducere automată neurală ISTIC pentru IWSLT'2020", 'sr': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'si': "ISTIC's neural machine translation system for IWSLT'2020Name", 'so': "ISTIC's Neural machine Translation System for IWSLT'2020", 'sv': "ISTICs Neural Machine Translation System för IWSLT'2020", 'ta': "ISTIC' s Neural Machine Translation System for IWSLT' 2020", 'ur': "IWSLT'2020 کے لئے ISTIC کے نیورال ماشین ترجمہ سیسٹم", 'mt': "Sistema ta' Traduzzjoni ta' Magni Newrali tal-ISTIC għall-IWSLT'2020", 'uz': "IWSLT' 2020 uchun ISTIC' ning tarjima tizimi", 'vi': "Dịch về máy thần kinh học cổ học cho IWSLT'2020", 'bg': "Системата за неврален машинен превод на ИСТИК за ИВСЛТ'2020", 'hr': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'da': "ISTIC's Neural Machine Translation System til IWSLT'2020", 'nl': "ISTIC's Neural Machine Translation System voor IWSLT'2020", 'ko': 'IWSLT 2020을 위한 ISIC 신경 기계 번역 시스템', 'id': "Sistem Translation Mesin Neural ISTIC untuk IWSLT'2020", 'fa': "سیستم ترجمه ماشین عصبی ISTIC برای IWSLT'2020", 'de': "ISTICs neurales maschinelles Übersetzungssystem für IWSLT'2020", 'tr': "IWSLT'2020 üçin ISTIC'iň näral Maşynyň terjime sistemi", 'sw': "Mfumo wa Tafsiri wa Mashine ya Kifaransa wa ISTIC kwa ajili ya IWSLT'2020", 'af': "ISTIC se Neural Masjien Vertaling Stelsel vir IWSLT' 2020", 'sq': "Sistemi i Translacionit të Makinës Neurale të ISTIC për IWSLT'2020", 'am': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'hy': 'ԻՍՏԻԿ-ի Նյարդային մեքենայի թարգմանման համակարգը IW-ՍԼT 2020-ի համար', 'az': "IWSLT'2020 üçün ISTIC'in Nöral Makina Çeviri Sistemi", 'bn': "IWSLT'2020 এর জন্য ISTIC'র নিউরাল মেশিন অনুবাদ সিস্টেম", 'ca': "Sistema de traducció de màquines neuronals de ISTIC per IWSLT'2020", 'bs': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'et': "ISTICi neuroaalne masintõlke süsteem IWSLT'2020 jaoks", 'cs': "Neurální strojový překlad ISTIC pro IWSLT'2020", 'fi': "ISTICin neuroaalinen konekäännösjärjestelmä IWSLT'2020:lle", 'jv': "System kanggo IWSLT'2020", 'ha': '@ info: whatsthis', 'bo': "ISTIC's Neural Machine Translation System for IWSLT'2020", 'sk': "Sistem nevralnega strojnega prevajanja ISTIC za IWSLT'2020", 'he': "מערכת תרגום מכונות נוירות של ISTIC עבור IWSLT '2020"}
{'en': 'This paper introduces technical details of machine translation system of Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020). ISTIC participated in both translation tasks of the Open Domain Translation track : Japanese-to-Chinese MT task and Chinese-to-Japanese MT task. The paper mainly elaborates on the model framework, data preprocessing methods and decoding strategies adopted in our system. In addition, the system performance on the development set are given under different settings.', 'ar': 'تقدم هذه الورقة تفاصيل فنية لنظام الترجمة الآلية لمعهد المعلومات العلمية والتقنية في الصين (ISTIC) للمؤتمر الدولي السابع عشر حول ترجمة اللغة المنطوقة (IWSLT 2020). شارك ISTIC في مهمتي الترجمة لمسار ترجمة المجال المفتوح: مهمة الترجمة الآلية من اليابانية إلى الصينية ومهمة الترجمة الآلية من الصينية إلى اليابانية. تتناول الورقة بشكل أساسي إطار النموذج وطرق المعالجة المسبقة للبيانات واستراتيجيات فك التشفير المعتمدة في نظامنا. بالإضافة إلى ذلك ، يتم تقديم أداء النظام في مجموعة التطوير ضمن إعدادات مختلفة.', 'pt': 'Este artigo apresenta detalhes técnicos do sistema de tradução automática do Instituto de Informações Científicas e Técnicas da China (ISTIC) para a 17ª Conferência Internacional sobre Tradução de Línguas Faladas (IWSLT 2020). O ISTIC participou de ambas as tarefas de tradução da trilha de Tradução de Domínio Aberto: tarefa de TA de japonês para chinês e tarefa de TA de chinês para japonês. O artigo trata principalmente da estrutura do modelo, métodos de pré-processamento de dados e estratégias de decodificação adotadas em nosso sistema. Além disso, o desempenho do sistema no conjunto de desenvolvimento é fornecido em diferentes configurações.', 'es': 'Este artículo presenta los detalles técnicos del sistema de traducción automática del Instituto de Información Científica y Técnica de China (ISTIC) para la 17ª Conferencia Internacional sobre Traducción en Lenguaje Hablado (IWSLT 2020). ISTIC participó en las dos tareas de traducción de la sección Traducción de dominio abierto: la tarea MT del japonés al chino y la tarea MT del chino al japonés. El documento se centra principalmente en el marco del modelo, los métodos de preprocesamiento de datos y las estrategias de decodificación adoptadas en nuestro sistema. Además, el rendimiento del sistema en el conjunto de desarrollo se da en diferentes configuraciones.', 'fr': "Cet article présente les détails techniques du système de traduction automatique de l'Institute of Scientific and Technical Information of China (ISTIC) pour la 17e Conférence internationale sur la traduction en langue parlée (IWSLT 2020). ISTIC a participé aux deux tâches de traduction de la filière Traduction Open Domain\xa0: tâche de traduction automatique du japonais vers le chinois et tâche de traduction automatique du chinois vers le japonais. L'article développe principalement le cadre du modèle, les méthodes de prétraitement des données et les stratégies de décodage adoptées dans notre système. De plus, les performances du système sur le jeu de développement sont données sous différents paramètres.", 'ja': '本稿では、第17回国際口語翻訳会議（ IWSLT 2020 ）のための中国科学技術情報院（ ISTIC ）の機械翻訳システムの技術的詳細を紹介する。ISTICは、オープンドメイン翻訳トラックの両方の翻訳タスクに参加しました：日本語から中国語へのMTタスクと中国語から日本語へのMTタスク。本稿では、主に当社システムで採用されているモデルフレームワーク、データ前処理方法、デコード戦略について詳述する。また、開発セット上のシステム性能は異なる設定で与えられている。', 'zh': '本文介第十七届中国科学技术信息研究所(ISTIC)第十七届口语译国际会议(IWSLT 2020)机器翻译系统之技术细节。 ISTIC与开域译分会场二译:日文至中文机器翻译及中文至日本机器翻译。 本文主言系统中模框架、数据预处理法、解码策。 此外,开发集上的系统性能在不同的设置下来。', 'hi': 'यह पेपर बोली जाने वाली भाषा अनुवाद (IWSLT 2020) पर 17 वें अंतर्राष्ट्रीय सम्मेलन के लिए चीन के वैज्ञानिक और तकनीकी सूचना संस्थान (ISTIC) की मशीन अनुवाद प्रणाली के तकनीकी विवरण का परिचय देता है। ISTIC ने ओपन डोमेन अनुवाद ट्रैक के दोनों अनुवाद कार्यों में भाग लिया: जापानी-से-चीनी MT कार्य और चीनी-से-जापानी MT कार्य। पेपर मुख्य रूप से मॉडल ढांचे, डेटा प्रीप्रोसेसिंग विधियों और हमारे सिस्टम में अपनाई गई डिकोडिंग रणनीतियों पर विस्तृत है। इसके अलावा, विकास सेट पर सिस्टम प्रदर्शन विभिन्न सेटिंग्स के तहत दिए जाते हैं।', 'ru': 'В данной работе представлены технические детали системы машинного перевода Института научно-технической информации Китая (ИСТИК) ДЛЯ 17-й Международной конференции по переводу на разговорный язык (IWSLT 2020). ISTIC участвовал в обоих задачах перевода трека Open Domain Translation: задача японского-китайского MT и задача китайско-японского MT. В документе в основном рассматриваются модельные рамки, методы предварительной обработки данных и стратегии декодирования, принятые в нашей системе. Кроме того, производительность системы на наборе разработок приведена под разными настройками.', 'ga': 'Tugann an páipéar seo isteach sonraí teicniúla maidir le córas meaisín-aistriúcháin Institiúid Faisnéise Eolaíoch agus Teicniúil na Síne (ISTIC) don 17ú Comhdháil Idirnáisiúnta ar Aistriúchán Teanga Labhartha (IWSLT 2020). Ghlac ISTIC páirt sa dá thasc aistriúcháin den rian Aistriúcháin Fearainn Oscailte: tasc MT Seapáinis go Sínis agus tasc MT Sínis-go-Seapánach. Déanann an páipéar mionsaothrú go príomha ar an gcreat eiseamláireach, ar na modhanna réamhphróiseála sonraí agus ar na straitéisí díchódaithe a nglactar leo inár gcóras. Ina theannta sin, tá feidhmíocht an chórais ar an sraith forbartha tugtha faoi shocruithe éagsúla.', 'ka': 'ჩინეთის მეცნიერო და ტექნიკალური ინფორმაციის ინსტიუტის (ISTIC) 17მე ინტერნეციონალური კონფიგურაციისთვის მუშაობელი ენათა გასაგრძელებაზე (IWSLT 2020) ტექნიკალური განა ISTIC მოთავსდება ორივე გაგრძელებული დემოინის გაგრძელება: იაპონი-დან-ჩინეთი MT დავალება და ჩინეთი-დან-იაპონი MT დავალება. ჩვენი სისტემაში მოდელური პარამეტრების, მონაცემების წინაპროცესების მეტოვების და სტრაფიკაციის რეკოდირების შესახებ განახლება. დამატებით, განვითარების კონფიგურაციის სისტემის გამოსახულება განსხვავებული პარამეტრებში იყოს.', 'el': 'Η παρούσα εργασία εισάγει τεχνικές λεπτομέρειες του συστήματος μηχανικής μετάφρασης του Ινστιτούτου Επιστημονικών και Τεχνικών Πληροφοριών της Κίνας (ISTIC) για το 17ο Διεθνές Συνέδριο για τη Μετάφραση Μιλημένης Γλώσσας (IWSLT 2020). Το ISTIC συμμετείχε και στις δύο εργασίες μετάφρασης του τμήματος μετάφρασης ανοικτού τομέα: εργασία ιαπωνικού-κινεζικού ΜΤ και εργασία κινεζικού-ιαπωνικού ΜΤ. Η εργασία αναλύει κυρίως το πλαίσιο μοντέλου, τις μεθόδους προεπεξεργασίας δεδομένων και τις στρατηγικές αποκωδικοποίησης που υιοθετούνται στο σύστημά μας. Επιπλέον, οι επιδόσεις του συστήματος στο σύνολο ανάπτυξης δίνονται κάτω από διαφορετικές ρυθμίσεις.', 'hu': 'Ez a tanulmány bemutatja a Kínai Tudományos és Műszaki Információs Intézet (ISTIC) gépi fordítási rendszerének technikai részleteit a beszélt nyelvi fordításról szóló 17. nemzetközi konferencia (IWSLT 2020). Az ISTIC részt vett az Open Domain Translation sáv fordítási feladataiban: japán-kínai MT feladatban és kínai-japán MT feladatban. A tanulmány elsősorban a rendszerünkben alkalmazott modellkeretrendszerrel, adatfeldolgozási módszerekkel és dekódolási stratégiákkal foglalkozik. Ezenkívül a rendszer teljesítménye a fejlesztőkészleten különböző beállítások mellett kerül megadásra.', 'it': "Questo articolo introduce i dettagli tecnici del sistema di traduzione automatica dell'Istituto di Informazione Scientifica e Tecnica della Cina (ISTIC) per la 17a Conferenza Internazionale sulla Traduzione Linguistica Parlata (IWSLT 2020). ISTIC ha partecipato a entrambe le attività di traduzione della traccia Open Domain Translation: attività MT giapponese-cinese e attività MT cinese-giapponese. Il documento si occupa principalmente del modello framework, dei metodi di pre-elaborazione dei dati e delle strategie di decodifica adottate nel nostro sistema. Inoltre, le prestazioni del sistema sul set di sviluppo sono fornite in diverse impostazioni.", 'kk': 'Бұл қағаз 17- ші халықаралық тіл аудармасының (IWSLT 2020) аудармасының Қытай ғылыми және техникалық мәліметтің институты (ISTIC) машинаның аудармау жүйесінің техникалық егжей- тегжейін таңдайды ISTIC Open Domain аудару жолындағы екі аудару тапсырмаларында қатысу: Japanese-to-Chinese MT тапсырмасы және Chinese-to-Japanese MT тапсырмасы. Бұл қағаз негізінде біздің жүйеңізде қолданылатын үлгі қоршау, деректерді алдын- ала өңдеу әдістерін жасайды. Қосымша, жүйелік жасау баптауларының әртүрлі баптауларында жұмыс істеу әрекеттері көрсетіледі.', 'lt': 'Šiame dokumente pateikiama techninė informacija apie Kinijos mokslinės ir techninės informacijos instituto (ISTIC) vertimo raštu sistemą 17-ajai tarptautinei konferencijai kalbos vertimo raštu klausimais (IWSLT 2020). ISTIC dalyvavo abiejose atviro domeno vertimo takelio vertimo užduotyse: MT užduotis iš Japonijos į Kiniją ir MT užduotis iš Kinijos į Japoniją. Dokumente daugiausia išdėstomi modelių sistemos, duomenų apdorojimo metodai ir mūsų sistemoje priimtos dekodinimo strategijos. Be to, sistemos eksploataciniai rodikliai rengimo rinkinyje pateikiami skirtingais nustatymais.', 'mk': 'Овој весник претставува технички детали за системот на машински превод на Институтот за научна и техничка информација на Кина (ИСТИК) за 17-тата меѓународна конференција за превод на зборен јазик (ИВСЛТ 2020). ИСТИК учествуваше во двете преводни задачи на транслекцијата на Отворениот домен: задача од јапонски на кинески на МТ и задача од кинески на јапонски на МТ. Документот главно лаборира за моделната рамка, методите за препроцес на податоци и стратегиите за декодирање усвоени во нашиот систем. Покрај тоа, системските резултати на наборот за развој се дадени под различни поставувања.', 'mn': 'Энэ цаас Хятад Шинжлэх ухааны болон Техникийн мэдээллийн Институт (ISTIC) дээрх машины хөгжүүлэх системийн техник нарийвчлалыг 17-р Олон улсын Конференция (IWSLT 2020) дээр тайлбарладаг. ISTIC Open Domain Translation track-ийн хоёр дахь орчуулалтын даалгаврын даалгаврын ажилд оролцсон: Япон-аас Хятад-аас хамт Хятад-аас-Япон MT ажилд оролцсон. Энэ цаас ихэвчлэн бидний системд хэрэглэгдсэн загварын хэлбэрээр, өгөгдлийн аль боловсруулах арга загварын талаар тодорхойлж байна. Үүнээс гадна хөгжлийн хэмжээний системийн үйл ажиллагааг өөр өөр тохиолдолд өгдөг.', 'no': 'Denne papiret introduserer tekniske detaljar om maskinsomsetjingssystemet for Institute of Scientific and Technical Information of China (ISTIC) for den 17. internasjonale konferansen om språk omsetjinga (IWSLT 2020). ISTIC delta på begge omsetjingsverkingar av den opne domene omsetjingspunktet: Japanese-to-Chinese MT-oppgåva og kinesisk-to-Japanese MT-oppgåva. Papiret utviklar hovudsakelig på modellerammeverket, dataforhandlingsmetoder og dekoderingsstrategiar som er godtatt i systemet vår. I tillegg vert systemutviklinga i utviklingsettet gitt under ulike innstillingar.', 'ms': 'This paper introduces technical details of machine translation system of Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020).  ISTIC berpartisipasi dalam kedua-dua tugas terjemahan trek Terjemahan Domain terbuka: tugas MT Jepun-ke-Cina dan tugas MT Cina-ke-Jepun. Kertas ini terutama mengeksploitasi kerangka model, kaedah pemprosesan data dan strategi penyahkodan yang diterima dalam sistem kita. Selain itu, prestasi sistem pada set pembangunan diberi di bawah tetapan yang berbeza.', 'pl': 'W artykule przedstawiono szczegóły techniczne systemu tłumaczenia maszynowego Instytutu Informacji Naukowo-Technicznej Chin (ISTIC) na XVII Międzynarodowej Konferencji Tłumaczenia Języka Mówionego (IWSLT 2020). ISTIC uczestniczył w obu zadaniach tłumaczeniowych ścieżki tłumaczeniowej Open Domain Translation: zadaniu MT japońsko-chiński oraz zadaniu MT chińsko-japoński. W artykule omówiono głównie ramy modelu, metody wstępnego przetwarzania danych oraz strategie dekodowania przyjęte w naszym systemie. Ponadto wydajność systemu w zestawie deweloperskim podana jest w różnych ustawieniach.', 'ml': 'ഈ പത്രത്തില്\u200d സംസാരിക്കുന്ന ഭാഷ പരിഭാഷയിലെ 17 ആന്\u200dഡാരാഷ്ട്രാന്തി പരിഭാഷയുടെ പരിഭാഷയുടെ സിസ്റ്റിറ്റിയില്\u200d സാങ്കേതിക വിവരങ്ങള്\u200d സംബന്ധിച്ച് യന് തുറന്ന ഡൊമെയിന്\u200d ട്രാക്കിന്റെ ട്രാക്കിന്റെ പരിഭാഷകങ്ങള്\u200d രണ്ടും ISTIC പങ്കുചേര്\u200dന്നു. ജാപ്പനീസ്- മുതല്\u200d- ചൈനീസ് എംടി ജോ പ്രധാനപ്പെട്ട പത്രത്തില്\u200d മോഡല്\u200d ഫ്രെയിമ്പില്\u200d, ഡേറ്റാ പ്രെസിക്രേഷന്\u200d രീതികള്\u200d, നമ്മുടെ സിസ്റ്റത്തില്\u200d നിര്\u200dത കൂടാതെ വ്യത്യസ്ത സജ്ജീകരണങ്ങളില്\u200d സിസ്റ്റം പ്രകടനം നല്\u200dകുന്നു.', 'mt': 'Dan id-dokument jintroduċi dettalji tekniċi tas-sistema tat-traduzzjoni bil-magna tal-Istitut tal-Informazzjoni Xjentifika u Teknika taċ-Ċina (ISTIC) għas-17-il Konferenza Internazzjonali dwar it-Traduzzjoni tal-Lingwa Kkellma (IWSLT 2020). L-ISTIC ipparteċipa fiż-żewġ kompiti ta’ traduzzjoni tal-binarju tat-traduzzjoni tad-dominju miftuħ: kompitu MT Ġappuniż-Ċiniż u kompitu MT Ċiniż-Ġappuniż. Id-dokument prinċipalment jelabora dwar il-qafas mudell, il-metodi ta’ preproċessar tad-dejta u l-istrateġiji ta’ dekodifikazzjoni adottati fis-sistema tagħna. Barra minn hekk, il-prestazzjoni tas-sistema fuq is-sett tal-iżvilupp tingħata taħt ambjenti differenti.', 'ro': 'Această lucrare prezintă detalii tehnice ale sistemului de traducere automată al Institutului de Informații Științifice și Tehnice din China (ISTIC) pentru cea de-a 17-a Conferință Internațională privind Traducerea Limbilor Vorbite (IWSLT 2020). ISTIC a participat la ambele sarcini de traducere ale pistei Open Domain Translation: sarcina MT japoneză-chineză și sarcina MT chineză-chineză. Lucrarea elaborează în principal cadrul modelului, metodele de pre-procesare a datelor și strategiile de decodare adoptate în sistemul nostru. În plus, performanța sistemului pe setul de dezvoltare este dată în setări diferite.', 'sr': 'Ovaj papir predstavlja tehničke detalje o sistemu prevoda mašine Instituta naučnih i tehničkih informacija Kine (ISTIC) za 17. Međunarodnu konferenciju o prevodu govornog jezika (IWSLT 2020). ISTIC je sudjelovao u obe prevodne zadatke otvorene lokalne prevode: zadatak japanskog na kineskom MT-u i zadatak kineskog na japanskog MT-a. U novinama se uglavnom pojavljuje o modelu okvira, metodi preobrade podataka i strategije za dekodiranje usvojene u našem sistemu. Osim toga, provedba sustava na setu razvoja daje se pod različitim nastavama.', 'so': 'Kanu warqaddan wuxuu soo bandhigayaa taariikhda turjumista machine system of Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Talk Language Translation (IWSLT 2020). ISTIC waxay ka qeybqaadatay labada shaqaalooyin turjuman oo ku qoran garta furan Domain: Japanese-to-Chinese MT shaqo iyo Chinese-to-Japanese MT. Qoraalka waxaa ugu horeyn qoraalka ku qoran qoraalka modellka, qaababka lagala baaraandegayo macluumaadka iyo qoraalka koordiyeynta ee nidaamka lagu sameeyo. Intaas waxaa dheer oo la siiyaa sameynta nidaamka ee horumarinta lagu sameynayo xarumaha kala duduwan.', 'sv': 'Denna uppsats introducerar tekniska detaljer om maskinﾃｶversﾃ､ttningssystemet vid Institutet fﾃｶr vetenskaplig och teknisk information i Kina (ISTIC) fﾃｶr den 17:e internationella konferensen om sprﾃ･kﾃｶversﾃ､ttning (IWSLT 2020). ISTIC deltog i bﾃ･da ﾃｶversﾃ､ttningsuppgifterna fﾃｶr spﾃ･ret Open Domain Translation: japansk-till-kinesisk MT-uppgift och kinesisk-till-japansk MT-uppgift. Uppsatsen behandlar frﾃ､mst modellramverket, databehandlingsmetoder och avkodningsstrategier som antagits i vﾃ･rt system. Dessutom anges systemets prestanda pﾃ･ utvecklingsuppsﾃ､ttningen under olika instﾃ､llningar.', 'ta': 'இந்த தாள் பேசும் மொழி மொழிபெயர்ப்பு மொழியை மொழிபெயர்ப்பு மொழியின் 17வது ஆற்றல் மொழிமாற்றியமைப்பிற்கு இயந்திர மொழிமாற்ற முறைமாற்று அமைப ISTIC திறந்த டொமைன் மொழிபெயர்ப்பு தடத்தின் மொழிபெயர்ப்பு பணிகளில் இருவரும் பகிர்ந்தது: ஜப்பானிஸ்- முதல்- சீனிய MT பணியும் ச முக்கியமாக தாள் மாதிரி சட்டத்தில், தரவு முன் செயல்படுத்தல் முறைமைகள் மற்றும் எங்கள் கணினியில் பொறுத்தப்பட்ட திட் மேலும், முன்னேற்ற அமைப்புகளின் கணினி செயல்பாடு வேறு அமைப்புகளின் கீழ் கொடுக்கப்படுகிறது.', 'si': 'මේ පැත්තේ පරීක්ෂක විස්තර පද්ධතියේ පද්ධතියේ විද්\u200dයාණික සහ තාක්ෂණික තොරතුරු සංවිධානය (ISTIC) සඳහා පරීක්ෂක භාෂා ISTIC විවාදයේ විවාදය සහ ජාපානිය MT වැඩේ විවාදයෙන් විවාදය කරන දෙන්නම් ක්\u200dරියාත්මක වෙලා තියෙන්නේ. මේ පත්තේ ප්\u200dරධාන විශේෂයෙන් අපේ පද්ධතියේ ප්\u200dරවෘතිකරණය, දත්ත ප්\u200dරවෘතිකරණය සහ ප්\u200dරවෘතිකරණය සඳහ ඒ වගේම, විකාශය සම්පූර්ණයේ පද්ධතිය ප්\u200dරමාණය වෙනස් සැකසුම් සඳහා දෙන්නේ.', 'ur': 'This paper introduces technical details of machine translation system of Institute of Science and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020) for the 17th International Conference on Spoken Language Translation (IWSLT 2020). ISTIC Open Domain Translation Track کے دونوں ترکیب میں شریک ہوا: Japanese-to-Chinese MT task اور Chinese-to-Japanese MT task. یہ کاغذ عمدہ طور پر ہمارے سیستم میں پکڑے ہوئے موڈل فرمیٹ، ڈیٹا پرپرینسس طریقے اور ڈیکوڈ استراتژیکوں کے بارے میں تفصیل کرتا ہے. اور اس کے علاوہ، ڈولیٹ سٹ پر سیستم کی عملکرد مختلف تنظیمات کے اندر دی جاتی ہے.', 'uz': 'Bu gaz Xitoycha Ilmiy va Technical Information Institute (ISTIC) haqida qidirish tilni tarjima qilish uchun 17- chi International Conference (IWSLT 2020) uchun Mashine tarjima tizimini tanlang. @ info: whatsthis Qogʻoz asosiy model freymi, maʼlumot boshqarish usullari va tizimmizdagi ishlab chiqarish strategiyasini aniqlaydi. Qoʻshimcha, taʼminlovchi tizim tugmasi boshqa moslamalarda koʻrsatiladi.', 'vi': 'Tờ giấy này đưa ra chi tiết kỹ thuật về hệ thống dịch chuyển máy của Institute of Scientific và Technical Information of China (ISTIC) for the 17ing International Confession spoken Language Translation (IWSLT 2020). ISIC đã tham gia cả hai công việc dịch thuật của đường dịch vụ Miền Mới mở: giao thức đường mạng từ Nhật sang Trung Quốc và Giao thức MTV của Trung Quốc. Tờ giấy đề cập chủ yếu về khung hình mẫu, phương pháp xử lý dữ liệu và giải mã chiến lược được áp dụng trong hệ thống. Hệ thống của bộ phát triển được cung cấp dưới các thiết lập khác nhau.', 'bg': 'Настоящата статия представя техническите детайли на системата за машинен превод на Института за научно-техническа информация на Китай (ИСТИК) за 17-та международна конференция по езиков превод (ИСТИК 2020). ИСТИК участва и в двете преводни задачи на пистата "Отворен домейн превод": задача "Японско-китайски МТ" и задача "Китайско-японски МТ". В статията са разработени предимно моделната рамка, методите за предварителна обработка на данни и стратегиите за декодиране, приети в нашата система. В допълнение, производителността на системата на комплекта за разработка се дава под различни настройки.', 'nl': 'Dit artikel introduceert technische details van machine translation systeem van Institute of Scientific and Technical Information of China (ISTIC) voor de 17e Internationale Conferentie over gesproken taal vertaling (IWSLT 2020). ISTIC nam deel aan beide vertaaltaken van de Open Domain Translation track: Japans-to-Chinese MT taak en Chinees-to-Japans MT taak. In het artikel wordt voornamelijk ingegaan op het modelkraamwerk, data preprocessing methodes en decoderingsstrategieën die in ons systeem worden toegepast. Daarnaast worden de systeemprestaties op de ontwikkelset gegeven onder verschillende instellingen.', 'da': 'Denne artikel introducerer tekniske detaljer i maskinoversættelsessystemet ved Institut for Videnskabelig og Teknisk Information i Kina (ISTIC) til den 17. internationale konference om talt sprog oversættelse (IWSLT 2020). ISTIC deltog i begge oversættelsesopgaver på sporet Open Domain Translation: japansk-til-kinesisk MT-opgave og kinesisk-til-japansk MT-opgave. Dokumentet behandler hovedsageligt modelrammen, dataforbearbejdningsmetoder og afkodningsstrategier, der anvendes i vores system. Derudover er systemets ydeevne på udviklingssættet angivet under forskellige indstillinger.', 'hr': 'Ovaj papir predstavlja tehničke detalje o sustavu prevoda strojeva Instituta znanstvenih i tehničkih informacija Kine (ISTIC) za 17. Međunarodnu konferenciju o prevodu govornog jezika (IWSLT 2020). ISTIC je sudjelovao u obe prevodne zadatke otvorenog lokalnog praćenja: zadatak japanskog-na-kineskog MT-a i zadatak kineskog-na-japanskog MT-a. U novinama se uglavnom razvija o modelnom okviru, metodi preobrađivanja podataka i strategiji za dekodiranje usvojene u našem sustavu. Osim toga, učinkovitost sustava na setu razvoja daje se u različitim nastavama.', 'de': 'Dieser Beitrag stellt technische Details des maschinellen Übersetzungssystems des Instituts für Wissenschaftliche und Technische Information Chinas (ISTIC) für die 17th International Conference on Spoken Language Translation (IWSLT 2020) vor. ISTIC nahm an beiden Übersetzungsaufgaben des Open Domain Translation Tracks teil: Japanisch-Chinesisch MT Task und Chinesisch-Japanisch MT Task. Die Arbeit beschäftigt sich hauptsächlich mit dem Modellframework, den Methoden der Datenvorverarbeitung und den Decodierungsstrategien unseres Systems. Zusätzlich wird die Systemleistung auf dem Entwicklungsset unter verschiedenen Einstellungen angegeben.', 'id': 'This paper introduces technical details of machine translation system of Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020).  ISTIC berpartisipasi dalam kedua tugas terjemahan dari trek Terjemahan Domain terbuka: tugas MT Jepang-ke-Cina dan tugas MT Cina-ke-Jepang. Kertas ini terutama menjelaskan tentang struktur model, metode pemroses data dan strategi dekoding yang diadopsi dalam sistem kita. Selain itu, prestasi sistem pada set pengembangan diberikan di bawah pengaturan yang berbeda.', 'ko': '본고는 제17회 국제구어번역대회(IWSLT 2020) 중국과학기술정보연구소(ISIC) 기계번역시스템의 기술 세부 사항을 소개한다.ISIC는 개방 영역 번역 궤도의 두 가지 번역 임무인 일한기계번역임무와 중일기계번역임무에 참여했다.본고는 주로 시스템이 채택한 모델 구조, 데이터 예처리 방법과 디코딩 전략을 논술했다.이 밖에 서로 다른 설정에서 개발집의 시스템 성능을 제시했다.', 'tr': 'Bu kagyz Hytaý Ilmi we Tekniki Maglumaty Enstitüsüniň (ISTIC) 17nji Halkara Konfersiýasy çykyş dili terjime etmek üçin maşynyň terjime sistemasyny (IWSLT 2020) taýýarlaýar. ISTIC Aç Saýlaw Terjimesiniň ikisi täblisasynda dahyl boldy: Japonça-tä-Çin çe MT täblisasynda we Çinçe-tä-Japonça MT täblisasynda. Bu kagyz sistemimizde kabul edilen nusgala çerýädä, maglumatyň öňünden işlemek we taýýarlanmak strategiýalary barada düşünýär. Munuň üstine, gelişmek düzümlerinde sistem başarylyklary üýtgeden düzümler astynda berilýär.', 'fa': 'این کاغذ جزئیات تکنیکی از سیستم ترجمه ماشین از موسسه اطلاعات علمی و تکنیکی چین (ISTIC) برای کنفرانس ۱۷م بین المللی در مورد ترجمه زبان زبان Spoken (IWSLT 2020) را معرفی می\u200cکند. ISTIC در هر دو کار ترجمه کردن ترجمه دامین باز شرکت کرد: کار MT ژاپنی-به چینی و کار MT چینی-به ژاپنی. این کاغذ در اصل در مورد چهارچوب مدل، روش پیش پرداخت داده ها و استراتژی\u200cهای دکوندی که در سیستم ما قبول شده است توضیح می\u200cدهد. علاوه بر این، عملکرد سیستم روی مجموعه توسعه تحت تنظیمات مختلف داده می شود.', 'sw': 'Makala hii inaonyesha maelezo ya kiufundi ya mfumo wa kutafsiri mashine wa Taasisi ya Sayansi na Teknolojia ya China (ISTIC) kwa Mkutano wa Kimataifa wa 17 kuhusu Tafsiri ya Lugha ya Utetezi (IWSLT 2020). ISTIC ilishiriki kazi zote za tafsiri za ufuatiliaji wa tafsiri ya wazi Domain: kazi ya MT ya Kijapani-hadi-China na MT ya Kichina-hadi Japani. Gazeti hilo linaelezea zaidi katika mfumo wa mifano, mbinu za upasuaji wa data na mikakati ya kupunguza mipango ilizochukuliwa katika mfumo wetu. Zaidi ya hayo, utendaji wa mfumo wa maendeleo unapewa chini ya mazingira tofauti.', 'af': 'Hierdie papier introduseer tegniese besonderhede van masjien vertalingsstelsel van Institute of Scientific and Technical Information of China (ISTIC) vir die 17de Internasionale Konferencie oor Spoken Taal Vertaling (IWSLT 2020). ISTIC het gedeel in beide vertaling opdragte van die Open Domein Vertaling snit: Japanese- to- Chinese MT taak en Chinese- to- Japanese MT taak. Die papier vertel hoofsaaklik op die model raamwerk, data voorsoek metodes en dekodering strategies wat in ons stelsel aangeneem is. In addition, the system performance on the development set is given under different settings.', 'sq': 'Ky dokument paraqet detaje teknike të sistemit të përkthimit të makinave të Institutit të Informacionit Shkencësor dhe Teknik të Kinës (ISTIC) për Konferencën e 17-të Ndërkombëtare mbi Përkthimin e Gjuhave të Folura (IWSLT 2020). ISTIC mori pjesë në të dy detyrat e përkthimit të gjurmës së Përkthimit të Domenit të Hapur: detyrën japoneze-kineze MT dhe detyrën kineze-japoneze MT. Gazeta kryesisht elaboraton mbi kuadrin e modelit, metodat e përgatitjes së të dhënave dhe strategjitë e dekodimit të miratuara në sistemin tonë. Përveç kësaj, performanca e sistemit në sistemin e zhvillimit jepet nën rregullime të ndryshme.', 'hy': 'Այս աշխատանքը ներկայացնում է Չինաստանի գիտական և տեխնիկական տեղեկատվության ինստիտուտի (ԻՍՏԻԿ) մեքենային թարգմանման համակարգի տեխնիկական մանրամասները խոսքի լեզվի թարգմանման 17-րդ միջազգային կոնֆերանսի համար (IwSLT 2020- ԻՍՏԻԿ-ը մասնակցել է բաց դաշտի թարգմանման երկու խնդիրներին՝ ճապոնական-չինական MT խնդիրներին և չինական-ճապոնական MT խնդիրներին: Այս թղթին հիմնականում վերլուծում է մոդելների շրջանակը, տվյալների նախամշակման մեթոդները և մեր համակարգում ընդունված կոդավորման ռազմավարությունները: In addition, the system performance on the development set are given under different settings.', 'am': 'ይህ ፕሮግራም የቻይና የሳይንቨርሲና የቴክኖክቲክ መረጃ ኢንተটিቲ (ISTIC) ለ17ኛ ዓለምአቀፍ መንግስና የቋንቋ ትርጉም ጉዳይ (IWSLT 2020) የመረጃ ትርጉም የmachine ትርጉም ስርዓት ያሳያል፡፡ ISTIC የክፈት ዶሜን ትርጉም መግለጫ ስራዎችን በሁለቱም ተርጓሚዎች ላይ ተጋጠመ፤ ጃፓንኛ-ወደ-ቻይንኛ MT ስራ እና ቻይንኛ-ወደ-ጃፓን MT ስራ ተጋርቷል። የፕሮግራሙ ወረቀት በሞዴል ፍሬም፣ የዳታ ቅድሚያ ሥርዓት እና በሥርዓታችን የተወሰደውን የስርዓት መጠቀሚያ ይዘረዝራል፡፡ በተጨማሪም፣ የግንኙነቱ ሥርዓት በተለየ ግንኙነቶች ውስጥ ነው፡፡', 'az': 'Bu kağıt, XVIII İnstitüsü Bilimli və Tehnik Malümatı Institute of China (ISTIC) ilə birləşdirilmiş dil çevirilməsi barəsində maşın çevirilməsi sisteminin teknik detaylarını təşkil edir. ISTIC Açıq Domain Çeviri Çincə MT işləri və Çincə-Japon MT işləri ilə birlikdə yer aldı. Bu kağıt sistemimizdə götürülmüş model framework ü, məlumatlar ön işləmə metodları və stratejilərimizi kodlamaq haqqında təsbiq edir. Əvvəlcə, təhsil quruluğunda sistem performansı müxtəlif quruluğu altında verilir.', 'bn': 'এই পত্রিকাটি চীনের বিজ্ঞান ও প্রযুক্তিগত তথ্য ইনস্টিটিউট অফ আইএসটিসি (আইএসটিসি) নিয়ে প্রযুক্তিগত বিস্তারিত বিস্তারিত বিবরণ উপস্থাপন করেছে য ISTIC participated in both translation tasks of the Open Domain Translation track: Japanese-to-Chinese MT task and Chinese-to-Japanese MT task.  কাগজটি মূলধারণত মডেল ফ্রেম, ডাটা প্রক্রিয়ার পদ্ধতি এবং আমাদের সিস্টেমে গ্রহণ করা কৌশল নিয়ে ব্যাখ্যা করেছে। এছাড়াও উন্নয়ন সেটের ব্যবস্থা বিভিন্ন বৈশিষ্ট্যের অধীনে দেয়া হয়।', 'bs': 'Ovaj papir predstavlja tehničke detalje o sistemu prevoda mašine Instituta naučne i tehničke informacije Kine (ISTIC) za 17. Međunarodnu konferenciju o prevodu govornog jezika (IWSLT 2020). ISTIC je sudjelovao u obe prevodne zadatke otvorenog lokalnog praćenja: zadatak japanskog-na-kineskog MT-a i zadatak kineskog-na-japanskog MT-a. U novinama se uglavnom razvija o modelnom okviru, metodi preobrade podataka i strategije za dekodiranje usvojene u našem sustavu. Osim toga, provedba sustava na setu razvoja daje se pod različitim postavkama.', 'cs': 'Tento článek představuje technické podrobnosti systému strojového překladu Ústavu vědecko-technických informací Číny (ISTIC) na 17th Mezinárodní konferenci o překladu mluvených jazyků (IWSLT 2020). Společnost ISTIC se podílela na obou překladatelských úkolech Open Domain Translation Track: japonsko-čínsko MT úlohy a čínsko-japonsko MT úlohy. Příspěvek se zabývá především modelovým rámcem, metodami předzpracování dat a dekódovacími strategiemi přijatými v našem systému. Kromě toho je výkon systému na vývojové sadě uveden v různých nastaveních.', 'fi': 'Tässä artikkelissa esitellään Kiinan tieteellisen ja teknisen tiedon instituutin (ISTIC) konekäännösjärjestelmän teknisiä yksityiskohtia 17. kansainvälisessä puhutun kielen kääntämisen konferenssissa (IWSLT 2020). ISTIC osallistui Open Domain Translation -radan molempiin käännöstehtäviin: japani-kiina MT -tehtävään ja kiina-japani MT -tehtävään. Työssä käsitellään pääasiassa järjestelmässämme käytössä olevia mallikehyksiä, tietojen esikäsittelymenetelmiä ja dekoodatusstrategioita. Lisäksi järjestelmän suorituskyky kehityssarjassa annetaan eri asetuksissa.', 'et': 'Käesolevas dokumendis tutvustatakse Hiina Teadus- ja Tehnilise Informatsiooni Instituudi (ISTIC) masintõlke süsteemi tehnilisi üksikasju 17. rahvusvahelisel rääkimiskeelse tõlke konverentsil (IWSLT 2020). ISTIC osales avatud domeeni tõlke raja mõlemas tõlketöös: jaapani-hiina MT ülesandes ja hiina-jaapani MT ülesandes. Töös käsitletakse peamiselt meie süsteemis kasutusele võetud mudeliraamistikku, andmete eeltöötlusmeetodeid ja dekodeerimisstrateegiaid. Lisaks on süsteemi jõudlus arenduskomplektis esitatud erinevates seadistustes.', 'ca': "Aquest paper introdueix detalls tècnics del sistema de traducció màquina de l'Institut d'Informació Científica i Técnica de la Xina (ISTIC) per la 17ª Conferència Internacional sobre la Traducció del Llingüe Spoken (IWSLT 2020). ISTIC va participar en les dues tasques de traducció de la pista de traducció de domini obert: tasca de MT japonès a xinès i tasca de MT xinès a japonès. El paper elabora principalment el marc model, els mètodes de preprocessió de dades i les estratègies de decodificació adoptades al nostre sistema. In addition, the system performance on the development set are given under different settings.", 'jv': 'Pesene iki nggawe informasi teknik karo sistem penterjamahan ing Sistem Pengaturan Cine lan Teknik Informasi Siji (IsTIC) kanggo nggawe Kasemperasi tanggal Pasang kanggo Terjamahan Ing Jagat (IWSLT 2020). IsTIC wis gampang ning arep terjamahan ning Open domain translation track: task japoni-to-Chinese MT lan task Chinese-to-japoni MT . Perintah sing mbutalog-mbutalog barang nggawe sistem model, dadi sing bisa nguasai perusahaan karo sistem sing dino. Nambah, akeh sistem kanggo nggawe aturan kanggo nggawe aturan kapan kanggo sampek', 'sk': 'Ta prispevek predstavlja tehnične podrobnosti sistema strojnega prevajanja Inštituta za znanstvene in tehnične informacije Kitajske (ISTIC) za 17. mednarodno konferenco o govornem jeziku prevajanja (IWSLT 2020). ISTIC je sodeloval pri obeh prevajalskih nalogah sledi prevajanja odprte domene: naloga japonsko-kitajsko MT in naloga kitajsko-japonsko MT. Prispevek predvsem obravnava modelni okvir, metode predobdelave podatkov in strategije dekodiranja, sprejete v našem sistemu. Poleg tega so učinkovitost sistema na razvojnem naboru podane v različnih nastavitvah.', 'ha': "Wannan karatun na introduce technical description of the system of the Installation of Asian and Technical information of China (ICTIC) for the 17th International Conference on Talk language Translate (IWSLT 2020). @ item license (short name) Kayan takardar ta ƙayyade mainli a kan firam-firam, metoden pre-aiki da taki-tarakin da aka karɓi cikin tsarin mu. Da wannan, za'a ba da cikakken halin na'ura a kan kowandon kayan motsi.", 'he': 'העבודה הזו מציגה פרטים טכניים של מערכת התרגום מכונתית של המכון המידע המדעי והטכני של סין (ISTIC) למועדון הבינלאומי ה-17 על התרגום לשפה מדברת (IWSLT 2020). ISTIC participated in both translation tasks of the Open Domain Translation track: Japanese-to-Chinese MT task and Chinese-to-Japanese MT task.  העיתון מפרסם בעיקר על המסגרת המודל, שיטות מעבדת נתונים וסטרטגיות פיתוח מאושפות במערכת שלנו. בנוסף, ביצועי המערכת על קבוצת הפיתוח נותנים תחת סדרות שונות.', 'bo': 'This paper introduces technical details of machine translation system of Institute of Science and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020). ISTIC ཡིས་ཁ་ཕྱེ་བའི་དཔེ་གཞུང་གི་རྗེས་སྤྱོད་ཀྱི་བྱ་འགུལ་གཉིས་ཀྱི་ནང་དུ་ཞུགས་བྱས་པ། དེའི་ཤོག་བུ་འདིས་ང་ཚོའི་མ་ལག་གི་སྔོན་སྒྲིག་ཐབས་ལམ་ལུགས་དང་ཕྱོགས་སྐྱོད་ཐབས་ལམ་ལུགས་དང་འཆར་བཤེར་ཐབས་ལམ་ལ ད་དུང་། འཕེལ་རིམ་གྱི་སྒྲིག་འཛུགས་གྱི་མ་ལག་གི་སྒྲུབ་སྟངས་སྒྲིག་སྟངས་སོ་སོའི་ནང་དུ་བྱིན་ཡོད།'}
{'en': 'The HW-TSC Video Speech Translation System at IWSLT 2020', 'es': 'El sistema de traducción de voz por vídeo HW-TSC en IWSLT 2020', 'fr': "Le système de traduction vocale vidéo HW-TSC à l'IWSLT 2020", 'pt': 'O sistema de tradução de fala de vídeo HW-TSC na IWSLT 2020', 'ar': 'نظام ترجمة كلام الفيديو HW-TSC في IWSLT 2020', 'hi': 'IWSLT 2020 में HW-TSC वीडियो स्पीच ट्रांसलेशन सिस्टम', 'zh': 'HW-TSC 视频音译系统亮相 IWSLT 2020', 'ja': 'IWSLT 2020のHW - TSCビデオ音声翻訳システム', 'ga': 'An Córas Físe Aistriúcháin Urlabhra HW-TSC ag IWSLT 2020', 'ru': 'Система перевода видеоречи HW-TSC на IWSLT 2020', 'ka': 'HW-TSC ვიდეო სიტყვის განსაგულისხმების სისტემა IWSLT 2020-ში', 'el': 'Το σύστημα μετάφρασης ομιλίας βίντεο στο IWSLT 2020', 'hu': 'A HW-TSC videobeszédfordító rendszer az IWSLT 2020-on', 'it': 'Il sistema di traduzione vocale video HW-TSC a IWSLT 2020', 'lt': 'HW-TSC vaizdo kalbos vertimo sistema IWSLT 2020 m.', 'mk': 'Системот за преведување на видео говор на HW-TSC на IWSLT 2020', 'ms': 'Sistem Terjemahan Ucapan Video HW-TSC pada IWSLT 2020', 'ml': 'IWSLT 2020-ലെ HW-TSC വീഡിയോ സ്പീക് പരിഭാഷ സിസ്റ്റം', 'mn': 'IWSLT 2020 оны HW-TSC Видео ярианы хөгжлийн хөгжлийн систем', 'mt': 'Is-Sistema tat-Traduzzjoni tal-Vidjo Speech tal-HW-TSC fl-IWSLT 2020', 'pl': 'System tłumaczenia mowy wideo HW-TSC na IWSLT 2020', 'no': 'HW-TSC video-taleomsetjingssystemet på IWSLT 2020', 'ro': 'Sistemul de traducere video HW-TSC la IWSLT 2020', 'kk': 'HW- TSC видео сөйлеу аудару жүйесі IWSLT 2020 жылы', 'sr': 'HW-TSC Video Speech Translation System na IWSLT 2020.', 'si': 'HW-TSC වීඩියෝ කතා පද්ධතිය IWSLT 2020දී පද්ධතිය', 'so': 'HW-TSC Video Speech System Translation System at IWSLT 2020', 'sv': 'HW-TSC Video Speech Översättningssystem på IWSLT 2020', 'ta': 'IWSLT 2020 இல் HW- TSC வீடியோ பேச்சு மொழிபெயர்ப்பு அமைப்பு', 'ur': 'IWSLT 2020 میں HW-TSC ویڈیو بات ترجمہ سیسٹم', 'vi': 'Hệ thống dịch chuyển động HW-TSC tại IWSLT 2020', 'uz': 'Name', 'bg': 'Системата за превод на видео реч на ИВСЛТ 2020', 'hr': 'HW-TSC video govorni sustav prevoda na IWSLT 2020.', 'da': 'HW-TSC Video Speech Oversættelse System på IWSLT 2020', 'nl': 'Het HW-TSC Video Speech Translation System op IWSLT 2020', 'de': 'Das HW-TSC Video Speech Translation System auf der IWSLT 2020', 'id': 'The HW-TSC Video Speech Translation System at IWSLT 2020', 'ko': 'IWSLT 2020의 HW-TSC 비디오 음성 번역 시스템', 'fa': 'سیستم ترجمه سخنرانی ویدئو HW-TSC در IWSLT 2020', 'sw': 'Mfumo wa Tafsiri ya Hotuba ya Video ya HW-TSC katika IWSLT 2020', 'af': 'Die HW- TSC Video Speech Translation System by IWSLT 2020', 'tr': "HW-TSC wideo sözleri IWSLT 2020'de terjime sistemi", 'sq': 'Sistemi i Translacionit të Fjalës Video HW-TSC në IWSLT 2020', 'am': 'የHW-TSC ቪዲዮ የንግግር ትርጉም ሲስተም በIWSLT 2020', 'hy': 'The HW-TSC Video Speech Translation System at IWSLT 2020', 'az': 'HW-TSC Video S칬z T톛rc칲m톛 Sistemi IWSLT 2020-d톛', 'bn': 'IWSLT ২০২০ এ এইচডি-টিএসসি ভিডিও ভাষা ভাষণ অনুবাদ সিস্টেম', 'bs': 'HW-TSC Video Speech Translation System na IWSLT 2020.', 'ca': 'El sistema de traducció de vídeo-voz HW-TSC a IWSLT 2020', 'et': 'HW-TSC videokõne tõlkesüsteem IWSLT 2020', 'cs': 'HW-TSC Video Speech Translation System na IWSLT 2020', 'fi': 'HW-TSC Video Speech Translation System IWSLT 2020 -messuilla', 'he': 'מערכת התרגום של שיחות וידאו HW-TSC ב IWSLT 2020', 'sk': 'Sistem prevajanja videogovora HW-TSC na IWSLT 2020', 'jv': 'HWSLT 2020', 'ha': 'Translate system of the HW-TSC video Spelling at IWSLT 2020', 'bo': 'HW-TSC བརྙན་རིས་འདིའི་སྐད་བསྒྱུར་གྱི་མ་ལག་IWSLT 2020'}
{'en': 'The paper presents details of our system in the IWSLT Video Speech Translation evaluation. The system works in a cascade form, which contains three modules : 1) A proprietary ASR system. 2) A disfluency correction system aims to remove interregnums or other disfluent expressions with a fine-tuned BERT and a series of rule-based algorithms. 3) An NMT System based on the Transformer and trained with massive publicly available corpus.', 'es': 'El documento presenta detalles de nuestro sistema en la evaluación de la traducción de voz en video de IWSLT. El sistema funciona en forma de cascada, que contiene tres módulos: 1) Un sistema ASR patentado. 2) Un sistema de corrección de disfluencia tiene como objetivo eliminar los interregnos u otras expresiones disfluentes con un BERT ajustado y una serie de algoritmos basados en reglas. 3) Un sistema NMT basado en el Transformer y entrenado con corpus masivo disponible públicamente.', 'fr': "L'article présente les détails de notre système dans l'évaluation de la traduction vocale vidéo IWSLT. Le système fonctionne en cascade, qui contient trois modules\xa0: 1) Un système ASR propriétaire. 2) Un système de correction de disfluence vise à supprimer les interrègnes ou d'autres expressions disfluentes avec un BERT affiné et une série d'algorithmes basés sur des règles. 3) Un système NMT basé sur le Transformer et entraîné avec corpus massif accessible au public.", 'ar': 'تقدم الورقة تفاصيل نظامنا في تقييم IWSLT لترجمة الكلام بالفيديو. يعمل النظام في شكل تسلسلي ، والذي يحتوي على ثلاث وحدات: 1) نظام ASR خاص. 2) يهدف نظام تصحيح عدم الطلاقة إلى إزالة interregnums أو غيرها من التعبيرات غير الملائمة باستخدام BERT مضبوط وسلسلة من الخوارزميات المستندة إلى القواعد. 3) نظام NMT قائم على المحول ومدرب بمجموعة ضخمة متاحة للجمهور.', 'ja': 'IWSLTビデオ音声翻訳評価では、当社のシステムの詳細を紹介しています。このシステムは、1)独自のASRシステム、2)細かく調整されたBERTと一連のルールベースのアルゴリズムを使用して、インターレグナムやその他の不流動的な表現を除去することを目的とした不流動性補正システム、3)トランスフォーマーをベースに、大規模な公開コーパスを使用してトレーニングされたNMTシステムの3つのモジュールを含むカスケード形式で動作します。', 'pt': 'O artigo apresenta detalhes do nosso sistema na avaliação do IWSLT Video Speech Translation. O sistema funciona em forma de cascata, que contém três módulos: 1) Um sistema ASR proprietário. 2) Um sistema de correção de disfluência visa remover interregnos ou outras expressões disfluentes com um BERT ajustado e uma série de algoritmos baseados em regras. 3) Um Sistema NMT baseado no Transformer e treinado com corpus massivo disponível publicamente.', 'zh': '本文引我等于 IWSLT 视频语音译评估中系统之详细信息。 统以级联事,三模块:1)有ASR统。 2) 不畅校正统旨在微BERT,与一系法删除间歇期或余不畅之表达式。 3)者,变压器之NMT统也,大用公言之语料库也。', 'hi': 'पेपर IWSLT वीडियो स्पीच अनुवाद मूल्यांकन में हमारी प्रणाली का विवरण प्रस्तुत करता है। सिस्टम एक कैस्केड रूप में काम करता है, जिसमें तीन मॉड्यूल होते हैं: 1) एक मालिकाना एएसआर सिस्टम। 2) एक disfluency सुधार प्रणाली का उद्देश्य एक ठीक ट्यून BERT और नियम आधारित एल्गोरिदम की एक श्रृंखला के साथ interregnums या अन्य disfluent अभिव्यक्तियों को हटाने के लिए है। 3) ट्रांसफॉर्मर पर आधारित एक एनएमटी सिस्टम और बड़े पैमाने पर सार्वजनिक रूप से उपलब्ध कॉर्पस के साथ प्रशिक्षित।', 'ru': 'В статье представлена подробная информация о нашей системе в оценке перевода видеоречи IWSLT. Система работает в каскадном виде, который состоит из трех модулей: 1) Собственная система ASR. 2) Система коррекции оттока предназначена для удаления межрежимных или других отходящих выражений с доработанным BERT и серией алгоритмов на основе правил. 3) Система NMT на основе Трансформатора и обучена с массовым общедоступным корпусом.', 'ga': 'Cuireann an páipéar i láthair sonraí ár gcóras i meastóireacht IWSLT Aistriúchán Cainte Físe. Oibríonn an córas i bhfoirm cascáideach, ina bhfuil trí mhodúl: 1) Córas ASR dílseánaigh. 2) Tá sé mar aidhm ag córas ceartúcháin eislíofachta idirrialacha nó sloinn easaontacha eile a bhaint le CRET mionchoigeartaithe agus sraith algartam bunaithe ar rialacha. 3) Córas NMT bunaithe ar an Trasfhoirmeoir agus oilte le corpas ollmhór atá ar fáil go poiblí.', 'el': 'Η εργασία παρουσιάζει λεπτομέρειες του συστήματός μας στην αξιολόγηση της μετάφρασης βίντεο ομιλίας. Το σύστημα λειτουργεί σε μορφή καταρράκτη, η οποία περιέχει τρεις ενότητες: 1) Ένα ιδιόκτητο σύστημα ASR. 2) Ένα σύστημα διόρθωσης ακαμψίας στοχεύει στην απομάκρυνση των διαγραμμάτων ή άλλων ακαμψίων εκφράσεων με ένα συντονισμένο BERT και μια σειρά αλγορίθμων βασισμένων σε κανόνες. 3) Ένα σύστημα βασισμένο στον μετασχηματιστή και εκπαιδευμένο με μαζικό κοινό διαθέσιμο σώμα.', 'ka': 'ჩვენი სისტემის შესახებ IWSLT ვიდეო სიტყვების გასაგულისხმების განსაგულისხმების განსაგულისხმებით. Name 2) განსხვავებული რექტირების სისტემის მიზეზი ინტერეგნომის ან სხვა განსხვავებული გამოსახულებების გადასხვა BERT და სხვა რექტირებული ალგორიტემის სერიო. 3) NMT-ის სისტემა, რომელიც ტრანფორმენსერის ბაზეზიან და განსწავლა მასიური ადამიანურად ხელხილი კორპუსით.', 'it': 'Il documento presenta i dettagli del nostro sistema nella valutazione IWSLT Video Speech Translation. Il sistema funziona in una forma a cascata, che contiene tre moduli: 1) Un sistema ASR proprietario. 2) Un sistema di correzione della disfluenza mira a rimuovere interregni o altre espressioni disfluenti con un BERT ottimizzato e una serie di algoritmi basati su regole. 3) Un sistema NMT basato sul Transformer e addestrato con corpus massiccio pubblicamente disponibile.', 'kk': 'Қағаз жүйеміздің егжей- тегжейін IWSLT видео сөйлеу аудармасында көрсетеді. Жүйелік үш модуль бар каскад пішінде жұмыс істейді: 1) Сіздің ASR жүйесі. 2) Айнымалықты түзету жүйесі керек нөмірлерді немесе басқа белгілі өрнектерді өшіруге мақсатты BERT және ережелерді негізделген алгоритмдерді. 3) Трансформация жүйесіне негізделген және көпшілік қол жеткізетін корпус арқылы оқылған NMT жүйесі.', 'mk': 'Документот претставува детали за нашиот систем во проценката на IWSLT видео превод на говорот. Системот работи во каскадна форма, која содржи три модули: 1) сопствен систем ASR. 2) Целта на системот за корекција на расипаноста е отстранување на интерегниумите или другите изрази на расипаноста со фино прилагодени БЕРТ и серија алгоритми базирани на правила. 3) НМТ систем базиран на Трансформерот и обучен со масовен јавно достапен корпус.', 'lt': 'Dokumente pateikiama informacija apie mūsų sistemą IWSLT vaizdo kalbos vertimo vertinime. Sistema veikia kaskadine form a, kurioje yra trys moduliai: 1) savarankiška ASR sistema. 2) Nuotekų koregavimo sistema siekiama pašalinti interregnumus arba kitas nuotekų išraiškas su tiksliai pritaikytais BERT ir daugeliu taisyklėmis pagrįstų algoritmų. 3) NMT sistema, pagrįsta transformatoriumi ir apmokyta su masiniu visuomenei prieinamu korpusu.', 'ml': 'ഈ പത്രത്തില്\u200d IWSLT വീഡിയോ സംസാര വിവരങ്ങളുടെ വിശദീകരണങ്ങള്\u200d കാണിക്കുന്നു. ഈ സിസ്റ്റത്തില്\u200d മൂന്നു ഘടകങ്ങള്\u200d ഉള്ള ഒരു കാസ്കേഡ് രൂപത്തില്\u200d പ്രവര്\u200dത്തിക്കുന്നു. 1) ASR സിസ്റ്റത്തില്\u200d ഒര 2) A disfluency correction system aims to remove interregnums or other disfluent expressions with a fine-tuned BERT and a series of rule-based algorithms.  3) ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനമായി നിര്\u200dമ്മിക്കുന്ന ഒരു എംഎംടി സിസ്റ്റത്തിന്\u200dറെ ഒരു പരിശീലനം വളരെ', 'ms': 'Kertas ini memperkenalkan perincian sistem kita dalam penilaian Penerjemahan Video Ucapan IWSLT. The system works in a cascade form, which contains three modules: 1) A proprietary ASR system.  2) Sistem penyelesaian kelemahan bertujuan untuk menghapuskan interegnum atau ungkapan kelemahan lain dengan BERT yang ditetapkan dan siri algoritma berdasarkan peraturan. 3) Sistem NMT berdasarkan Transformer dan dilatih dengan korpus masyarakat yang tersedia.', 'mt': 'The paper presents details of our system in the IWSLT Video Speech Translation evaluation.  Is-sistema taħdem f’form a ta’ kaskata, li fiha tliet moduli: 1) Sistema ASR proprjetarja. 2) Sistema ta’ korrezzjoni tad-disfluwenza għandha l-għan li tneħħi l-interregnums jew espressjonijiet oħra tad-disfluwenza b’BERT irfinat u serje ta’ algoritmi bbażati fuq ir-regoli. 3) Sistema NMT ibbażata fuq it-Transformer u mħarrġa b’korpus massiv disponibbli għall-pubbliku.', 'hu': 'A tanulmány bemutatja rendszerünk részleteit az IWSLT Video Speech Translation értékelésében. A rendszer kaszkád formában működik, amely három modult tartalmaz: 1) Egy saját ASR rendszer. 2) A diszfluencia korrekciós rendszer célja, hogy eltávolítsa az interregnumokat vagy más diszfluencia kifejezéseket finomhangolt BERT-vel és szabályalapú algoritmusokkal. 3) Egy transzformátoron alapuló NMT rendszer, amelyet masszív nyilvánosan hozzáférhető korpuszokkal képeztek.', 'mn': 'Энэ цаас бидний системийг IWSLT бичлэгийн ярианы хөгжлийн дүгнэлт дэвшүүлдэг. Энэ систем 3 модуль агуулдаг каскад хэлбэрээр ажилладаг: 1) АСР систем. 2) Бүртгэл сайжруулах систем нь интеррегентом эсвэл бусад алгоритмыг сайжруулахад зориулагддаг. 3) Трансформацын үндсэн, олон нийтэд ашиглах корпус болон сургалтын NMT систем.', 'pl': 'W artykule przedstawiono szczegóły naszego systemu w ocenie IWSLT Video Speech Translation. System działa w formie kaskadowej, która zawiera trzy moduły: 1) autorski system ASR. 2) System korekcji niepłynności ma na celu usunięcie interregnów lub innych niepłynnych wyrażeń za pomocą dostrojonego BERT i serii algorytmów opartych na regułach. 3) System NMT oparty na Transformerze i przeszkolony z ogromnym publicznie dostępnym korpusem.', 'ro': 'Lucrarea prezintă detalii ale sistemului nostru în evaluarea IWSLT Video Speech Translation. Sistemul funcționează în cascadă, care conține trei module: 1) Un sistem ASR proprietar. 2) Un sistem de corecție a disfluenței își propune să elimine interregnumurile sau alte expresii disfluente cu ajutorul unui BERT reglat fin și o serie de algoritmi bazați pe reguli. 3) Un sistem NMT bazat pe Transformer și instruit cu corpuri masive disponibile publicului.', 'no': 'Papiret viser detaljar om systemet vårt i evalueringa av videotaleomsetjinga IWSLT. Name 2) Eit forskjellingskorrigeringssystem mål å fjerna interregnummer eller andre forskjellige uttrykk med ein finnstillingsBERT og ein serie reglamentserte algoritmer. 3) Eit NMT- systemet basert på Transformeren og trent med massivt offentlig tilgjengeleg korpus.', 'sr': 'Novinar predstavlja detalje našeg sistema u procjeni prevoda video govora IWSLT. Sistem radi u kaskadnom obliku, koji sadrži tri modula: 1) vlasnički ASR sistem. 2) Sistem korištenja nestabilnosti cilja je ukloniti interregnume ili druge nestabilne izraze sa fino korištenim BERT-om i serijom algoritma na pravilima. 3) NMT sistem baziran na transformatoru i obučen sa velikim javno dostupnim korpusom.', 'si': 'The papers presents Details of our system in the IWSLT Video Talk translation unit. පද්ධතිය කැස්කේඩ් වර්ගයක් වැඩ කරනවා, මොඩියෝල් තුනක් තියෙනවා: 1) ප්\u200dරධාන ASR පද්ධතියක්. 2) ප්\u200dරශ්නයක් නිරීක්ෂණ විධාන පද්ධතියක් අරමුණ වෙන්නේ ප්\u200dරශ්නයක් හෝ අනිත් ප්\u200dරශ්නයක් හෝ විශ්නයක් සමග BERT සහ නී 3) NMT පද්ධතියක් ත්\u200dරාණ්පර්තකයෙන් අධිරූපය කරලා ලොකු සාමාජිකව ප්\u200dරවේශනය කරලා තියෙනවා.', 'so': 'Qoraalka waxaa lagu qoraa macluumaad ku saabsan nidaamka IWSLT kaartaynta tarjumaadka fiidiyowga. Sirku wuxuu ku shaqeeyaa foomka cashuurta, kaasoo ku jira saddex module: 1) nidaamka ASR ee ku shaqeeya. 2) nidaamka hagaajinta waxaa loola jeedaa inuu dhaqaajiyo nidaamka kala duduwan ama hadal kale oo qalloocan ah oo ku qoran BERT iyo koox algoriim ah oo sharciga ku qoran. 3) An NMT System based on the Transformer and trained with massive publicly available corpus.', 'sv': 'Artikeln presenterar detaljer om vårt system i utvärderingen av IWSLT Video Speech Translation. Systemet fungerar i kaskadform, som innehåller tre moduler: 1) Ett egenutvecklat ASR-system. 2) Ett system för diskretionskorrigering syftar till att ta bort interregnum eller andra flytande uttryck med en finjusterad BERT och en serie regelbaserade algoritmer. 3) Ett NMT-system baserat på Transformern och tränat med massiv offentligt tillgänglig korpus.', 'ta': 'இந்த தாள் IWSLT வீடியோ பேச்சு மொழிபெயர்ப்பு மதிப்பில் எங்கள் கணினியின் விவரங்களை கூறுகிறது. இந்த அமைப்பு மூன்று பகுதிகள் உள்ளது, ஒரு காஸ்கேட் வடிவத்தில் வேலை செய்கிறது, அதில் ASR முறைமையை கொண்டுள்ளது. 2) ஒரு திருத்தமான திருத்தம் அமைப்பு உள்ளடக்கம் அல்லது மற்றும் வேறு திருத்தமான தொடர்களை நீக்க வேண்டும் பிரெட் மற்றும் ஒரு தொடர் விதிமு 3) மாற்றும் மற்றும் பயிற்சி செய்யும் ஒரு NMT அமைப்பு', 'ur': 'The paper presents detail of our system in the IWSLT Video Speech Translation evaluation. سیسٹم ایک کاسکیڈ فرم میں کام کرتا ہے جس میں تین موڈولے ہیں: 1) ایک صاحب ASR سیسٹم۔ 2) ایک غلطینس اصلاح سیسٹم کا ارادہ ہے کہ ایک پاکیزہ تنظیم BERT اور ایک سری قانون بنیاد الگوریٹم کے ساتھ انٹریگنامز یا دوسرے غلطینے الگوریٹم کو ہٹا دیں. 3) ایک NMT سیسٹم ترنسفور پر بنیاد ہے اور بہت زیادہ ظاہر موجود کرپوس کے ساتھ آموزش کی جاتی ہے.', 'uz': 'Qogʻoz IWSLT Video Talab tarjima qiymatida tizimmizning detalchamini koʻrsatiladi. Name 2) Tasdiqlik tizimi, interregnum yoki boshqa murakkab ifodalarni BERT va bir necha qoidagi algoritlar bilan olib tashlashni istaydi. Name', 'vi': 'Tờ giấy đưa ra chi tiết về hệ thống của chúng tôi trong bản đánh giá kênh Dịch qua video IWSLT. Hệ thống hoạt động theo dạng dây chuyền, gồm ba mô- đun: 1) Hệ thống ASR độc quyền. 2) Một hệ thống sửa chữa thói quen không lưu nhằm mục đích loại bỏ nội dung hay các biểu thức không thông thạo với hỗn hợp BERT và một loạt các thuật to án dựa vào quy luật. Một hệ thống NMT dựa trên Transformer và được đào tạo với tập đoàn khổng lồ công cộng.', 'bg': 'Статията представя подробности за нашата система в оценката на видео речен превод. Системата работи в каскадна форма, която съдържа три модула: 1) Собствена система. 2) Системата за корекция на дисфлуънтността има за цел премахване на интергнуми или други дисфлуънтни изрази с фина настройка и серия от алгоритми, базирани на правила. 3) Система на НМТ базирана на трансформатора и обучена с масивен публично достъпен корпус.', 'da': 'Artiklen præsenterer detaljer om vores system i IWSLT Video Speech Translation evaluering. Systemet fungerer i kaskadeform, som indeholder tre moduler: 1) Et proprietært ASR-system. 2) Et system til korrektion af diskløshed har til formål at fjerne interregnummer eller andre diskløse udtryk med en finjusteret BERT og en række regelbaserede algoritmer. 3) Et NMT-system baseret på Transformeren og trænet med massiv offentligt tilgængelig korpus.', 'hr': 'Novinar pokazuje detalje našeg sustava u procjeni prevoda video govora IWSLT. Sistem radi u obliku kaskade, koji sadrži tri modula: 1) vlasnički ASR sustav. 2) Sistem korištenja nestabilnosti cilja je ukloniti interregnume ili druge nestabilne izraze s fino korištenim BERT-om i niz algoritma na pravilima. 3) NMT sustav baziran na transformatoru i obučen s velikim javno dostupnim korpusom.', 'nl': 'De paper presenteert details van ons systeem in de IWSLT Video Speech Translation evaluatie. Het systeem werkt in een cascadevorm, die drie modules bevat: 1) Een eigen ASR-systeem. 2) Een disfluency correctie systeem heeft tot doel interregnums of andere disfluency expressies te verwijderen met een verfijnde BERT en een reeks regels gebaseerde algoritmen. 3) Een NMT-systeem gebaseerd op de Transformer en getraind met een enorm publiek beschikbaar corpus.', 'de': 'Der Beitrag stellt Details unseres Systems in der IWSLT Video Speech Translation Evaluation vor. Das System arbeitet in Kaskadenform, die drei Module enthält: 1) Ein proprietäres ASR-System. 2) Ein Disfluenzkorrektursystem zielt darauf ab, Interregnum oder andere disfluente Ausdrücke mit einem fein abgestimmten BERT und einer Reihe regelbasierter Algorithmen zu entfernen. 3) Ein NMT-System basierend auf dem Transformer und trainiert mit massivem öffentlich zugänglichen Korpus.', 'id': 'Kertas ini memperlihatkan rincian sistem kita dalam evaluasi Video Speech Translation IWSLT. Sistem bekerja dalam bentuk kaskade, yang mengandung tiga modul: 1) Sebuah sistem ASR properti. 2) Sebuah sistem koreksi penyesalan bertujuan untuk menghapus interegnum atau ekspresi penyesalan lainnya dengan BERT yang ditetapkan dan seri algoritma berdasarkan aturan. 3) Sistem NMT berdasarkan Transformer dan dilatih dengan korpus masyarakat yang tersedia publik.', 'ko': '본고는 우리 시스템이 IWSLT 영상 음성 번역 평가에서의 응용을 상세하게 소개한다.이 시스템은 3개의 모듈로 구성된 다중 구간(Cascaded) 방식으로 작동합니다. 1) 독점 ASR 시스템입니다.2) 매끄럽지 않은 교정 시스템은 BERT를 미세하게 조정하고 일련의 규칙 기반 알고리즘을 통해 인터럽트나 기타 매끄럽지 않은 표현식을 없애기 위한 것이다.3) Transformer 기반의 NMT 시스템으로 대량의 공개적으로 사용할 수 있는 자료 라이브러리를 사용하여 훈련한다.', 'fa': 'این کاغذ جزئیات سیستم ما را در ارزیابی ترجمه سخنرانی ویدئو IWSLT نشان می دهد. سیستم در یک شکل کاسکد کار می\u200cکند که شامل سه مدول است: ۱) سیستم ASR ویژگی. 2) یک سیستم اصلاح ناپذیری هدف دارد که با یک BERT و یک سری الگوریتم بر اساس قانون برطرف کند. 3) سیستم NMT بر اساس تغییر دهنده و آموزش داده شده با قالب عمومی در دسترس است.', 'sw': 'The paper presents details of our system in the IWSLT Video Speech Translation evaluation.  Mfumo unafanya kazi katika mfumo wa mabomu, ambao una vifaa vitatu: 1) mfumo wa kutangaza ASR. 2) Mfumo wa uharibifu wa usawa unalenga kuondoa utaratibu au maoni mengine yasiyo na maana yenye utaratibu mzuri wa BERT na mfululizo wa vipengele vya sheria. 3) Mfumo wa NMT unaoingia na Mfumo wa Transfer na umefundishwa na makampuni makubwa yanayopatikana hadharani.', 'tr': 'Kagyzyň biziň sistemimiziň IWSLT wideo söz terjimelerinde maglumaty görkezýär. Sistem 3 modüli içinde işleýär: 1) Bir ASR sistemi. 2) Azizlik düzeltme sistemi bir şekilde düzeltmeli BERT ve kural tabanlı algoritmalarla birleştirmek amaçlı. 3) Transformer üzerinde bir NMT sistemi we halkara mejbur korpus bilen bilinmiş.', 'af': "Die papier stel besonderhede van ons stelsel in die IWSLT Video Spraak Vertaling evaluering. Die stelsel werk in 'n kaskade vorm, wat bevat drie modules: 1) ' n eienaar ASR stelsel. 2) 芒聙聶n Verskeidingskorreksie stelsel bepaal om interregnumme of ander verskeidingsuitdrukkings met 芒聙聶n fyn-ge茂nstalleerde BERT en 芒聙聶n reel-gebaseerde algoritme te verwyder. 3) 芒聙聶n NMT Stelsel gebaseer op die Transformer en onderrig met massief openbaar beskikbaar corpus.", 'am': 'የፕሬዝዳንቱ የስርዓታችንን ዝርዝሮች IWSLT የቪዲዮ ቋንቋ ትርጉም ማሳየት ነው፡፡ ሲስተም ሦስት ሰንዱን የሚያስፈልግ ሆኖ በካስኮድ ፎርማት ውስጥ ይሠራል፡፡ 2) የጥላቻ አስተካክል ስርዓት በጥሩ BERT እና በተለያዩ የሥርዓት አሌጎርቲም በተደረገ መልዕክቶች እንዲያስወግድ ነው፡፡ 3) በተመሳሳይ እና በተገኘው የህዝብ ብዛት የተገኘ ኮፕስ የተሰኘ የNMT ስርዓት ነው፡፡', 'hy': 'Այս հոդվածը ներկայացնում է մեր համակարգի մանրամասները IW-ՍԼT տեսախօսքի թարգմանման գնահատման մեջ: Համակարգը աշխատում է կասկադի ձևով, որը պարունակում է երեք մոդուլներ. 1) Պրոպենտեր ASR համակարգ: 2) Խեղճի ուղղության համակարգը նպատակն է վերացնել ինտերենիումները կամ այլ խեղճի արտահայտությունները բարձրացված BER-ով և մի շարք կանոններով հիմնված ալգորիթմներով: 3) ՆՄԹ համակարգ, որը հիմնված է Թանֆերմերների վրա և մարզիչված է հսկայական հանրային հասանելի կորպուսով:', 'az': 'Kağıt sistemimizin ayrıntılarını IWSLT Video Sözü Çeviri Qərcləməsində göstərir. Sistem üç modul içində Cascade formasında çalışır: 1) Özünün ASR sistemi. 2) Köpüklük düzəltmə sistemi müəyyən edilmiş BERT və qüdrətli algoritmi ilə müxtəlif nömrələri və başqa fərqli ifadələri silmək məqsədilə məcbur edir. 3) Transformer üzərində dayanan NMT sistemi və çox açıq-aşkar mövcud korpus ilə təhsil edilmişdir.', 'bn': 'এই পত্রিকাটি আইউএসএলটি ভিডিও ভিডিও ভাষা অনুবাদের বিস্তারিত বিস্তারিত বিবরণ উপস্থাপন করেছে। সিস্টেম ক্যাসেড ফর্মে কাজ করে, যার মধ্যে তিনটি মডিউল রয়েছে: ১) একটি প্রার্থনারী ASR সিস্টেম। ২) একটি অস্পষ্ট সংশোধনী সিস্টেমের লক্ষ্য হচ্ছে ইন্টার্জাম বা অন্যান্য অস্বস্তিত্ব প্রকাশের মাধ্যমে ভালো ভিত্তিক বিবেরেট এবং শাসনের ৩) ট্রান্সফ্রান্সফারের উপর ভিত্তিক এক এনএমটি সিস্টেম এবং ব্যাপক প্রকাশ্যে প্রশিক্ষণ প্রদান করা হয়েছে।', 'ca': "El paper presenta detalls del nostre sistema a l'evaluació de la traducció de la voz de vídeo IWSLT. El sistema funciona en form a cascada, que conté tres móduls: 1) Un sistema ASR propietari. 2) Un sistema de correcció de la disfluència té l'objectiu de eliminar interregnums o altres expressions de disfluència amb un BERT finament ajustad i una sèrie d'algoritmes basats en les regles. 3) An NMT System based on the Transformer and trained with massive publicly available corpus.", 'cs': 'Příspěvek prezentuje detaily našeho systému v hodnocení IWSLT Video Speech Translation. Systém funguje v kaskádové podobě, která obsahuje tři moduly: 1) Proprietární ASR systém. 2) Systém korekce neslušnosti má za cíl odstranit interregnia nebo jiné neslušnostní výrazy pomocí vyladěného BERT a řady algoritmů založených na pravidlech. 3) NMT systém založený na transformátoru a trénovaný s masivním veřejně dostupným korpusem.', 'bs': 'Papir predstavlja detalje našeg sistema u procjeni prevoda video govora IWSLT. Sistem radi u formi kaskade, koji sadrži tri modula: 1) vlasnički ASR sistem. 2) Sistem korištenja nestabilnosti cilja je ukloniti interregnume ili druge nestabilne izraze sa fino korištenim BERT-om i niz algoritma baziranih na pravilima. 3) NMT sistem baziran na transformatoru i obučen s velikim javno dostupnim korpusom.', 'et': 'Töös esitatakse meie süsteemi üksikasjad IWSLT Video Speech Translation hindamisel. Süsteem töötab kaskaadvormis, mis sisaldab kolme moodulit: 1) patenteeritud ASR süsteem. 2) Disfluentsuse korrigeerimise süsteemi eesmärk on eemaldada intergnumid või muud disfluentsid väljendid täpsustatud BERT-i ja reeglipõhiste algoritmide seeria abil. 3) Transformeril põhinev NMT-süsteem, mis on koolitatud massiivse avalikult kättesaadava korpusega.', 'fi': 'Tyﾃｶssﾃ､ esitellﾃ､ﾃ､n jﾃ､rjestelmﾃ､mme yksityiskohtia IWSLT Video Speech Translation -arvioinnissa. Jﾃ､rjestelmﾃ､ toimii kaskadimuodossa, joka sisﾃ､ltﾃ､ﾃ､ kolme moduulia: 1) Omistettu ASR-jﾃ､rjestelmﾃ､. 2) Disfluenssikorjausjﾃ､rjestelmﾃ､llﾃ､ pyritﾃ､ﾃ､n poistamaan interregnaaleja tai muita disfluentteja ilmaisuja hienoviritetyllﾃ､ BERT-jﾃ､rjestelmﾃ､llﾃ､ ja sﾃ､ﾃ､ntﾃｶpohjaisilla algoritmeilla. 3) Muuntajaan perustuva NMT-jﾃ､rjestelmﾃ､, joka on koulutettu massiivisella julkisesti saatavilla olevalla korpusella.', 'sq': 'The paper presents details of our system in the IWSLT Video Speech Translation evaluation.  Sistemi punon në një form ë kaskade, e cila përmban tre module: 1) një sistem ASR pronar. 2) Një sistem korrigjimi i disfluencës synon të heqë interregnum apo shprehje të tjera disfluent me një BERT të rregulluar dhe një seri algoritmesh bazuar në rregulla. 3) An NMT System based on the Transformer and trained with massive publicly available corpus.', 'he': 'The paper presents details of our system in the IWSLT Video Speech Translation evaluation.  The system works in a cascade form, which contains three modules: 1) A proprietary ASR system.  2) מערכת תיקון חסר הכוח מטורפת להסיר את התפרצות או ביטויים חסרי הכוח אחרים עם BERT מעוצבן וסדרה של אלגוריתמים מבוססים על חוקים. 3) מערכת NMT המבוססת על הטרנספורטר ומאמנת עם קורפוס מסיבי פנוי לציבור.', 'jv': 'Perintah sing nyimpen manèh ning sistem awak dhéwé ning tarjamahan IWSLT Video Sistem kang akeh basa ing rak dadi kapan, sing nduwe telu modul: 1) Sistem ASR sing apik. 2) A disflority justification sistem goal to remove interRegnums or additional disfloent Expressions with a Fintuned BERT and a string of rule-supported Algorithms. 3) Sistem NMT sing bisire ditambah kanggo Transformer sadurungé karo perusahaan populer', 'ha': "Kanjanas na ƙunsa da tsari na'urarmu cikin shirin Fassarori na IWSLT na Fassarar Farawa. @ action: button 2) Sistemi na shawara na'urar gaske don ya yi amfani da tafiyar da wasu magana masu saka da BERT da wani salon algoritori na rubutu. QShortcut", 'sk': 'V prispevku so predstavljene podrobnosti o našem sistemu v oceni IWSLT Video Speech Translation. Sistem deluje v kaskadni obliki, ki vsebuje tri module: 1) lastniški ASR sistem. 2) Cilj sistema popravljanja disfluentnosti je odstranitev intergnumov ali drugih disfluentnih izrazov z natančno nastavljenim BERT-om in vrsto algoritmov, ki temeljijo na pravilih. 3) NMT sistem, ki temelji na transformatorju in se usposablja z ogromnim javno dostopnim korpusom.', 'bo': 'འོག་གི་ཤོག་བྱང་དེས་ང་ཚོའི་མ་ལག་གི་གསལ་བཤད་མང་ཙམ་སྟོན་པ་དེའི་ནང་དུ་IWSLT བརྙན་ཐོག་གཏམ་གླེ མ་ལག་གི་སྒྲིག་རིགས་ཀྱི་ཚེག 2) A disfluency correction system aims to remove interregnums or other disfluent expressions with a fine-tuned BERT and a series of rule-based algorithms. 3) བཟོ་བཅོས་པ་ལྟ་བུའི་དོན་ལག་ཅིག་གཙོ་རིམ་པ་ཞིག་དང་མཐུན་སྣེ་མང་ཆེ་བའི་མཐུན་འབྲེལ་བ་ཡིན་པ་དང་།'}
{'en': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for ~ Non-Native ~ SLT at IWSLT 2020', 'ar': 'CUNI Neural ASR مع خطوة متوسطة المستوى الصوتي لـ ~ غير الأصلي ~ SLT في IWSLT 2020', 'es': 'CUNI Neural ASR con paso intermedio a nivel de fonema para ~ no nativos ~ SLT en IWSLT 2020', 'pt': 'CUNI Neural ASR com Etapa Intermediária de Nível de Fonema para ~ Não Nativo ~ SLT no IWSLT 2020', 'fr': "ASR neuronal CUNI avec étape intermédiaire au niveau du phonème pour ~non-native~SLT à l'IWSLT 2020", 'ja': 'IWSLT 2020での~非ネイティブ~ SLTのための音素レベルの中間ステップを備えたCuNiニューラルASR', 'hi': 'IWSLT 2020 में ~ गैर-मूल ~ SLT के लिए Phoneme-Level Intermediate Step के साथ CUNI तंत्रिका ASR', 'zh': 'CUNI神经ASR与音素水平中步驿,用于~非原生~SLT在IWSLT 2020', 'ru': 'CUNI Neural ASR с промежуточным этапом уровня фонемы для~ненативного ~SLT на IWSLT 2020', 'ga': 'CUNI Neural ASR le Céim Mheánach Leibhéal Fónaim do~Neamhdhúchasacha~SLT ag IWSLT 2020', 'ka': 'CUNI ნეირალური ASR- ი, ფონემი- დონეზე ინტერემედიატიური სექტი ~Non- Native~SLT IWSLT 2020- ში', 'hu': 'CUNI Neurális ASR Phoneme szintű közepes lépéssel ~ nem natív ~ SLT-hez az IWSLT 2020-on', 'el': 'Νευρικό ASR με ενδιάμεσο βήμα επιπέδου φωνών για~μη-εγγενή~SLT στο IWSLT 2020', 'it': 'CUNI Neural ASR con Phoneme-Level Intermediate Step per ~ Non-Native ~ SLT a IWSLT 2020', 'mk': 'КУНИ неврален АСР со интермедијален чекор на фономско ниво за~Нероден~СЛТ на IWSLT 2020', 'ms': 'CUNI Neural ASR dengan Langkah Pertengahan Aras-Phoneme untuk~Non-Native~SLT pada IWSLT 2020', 'ml': 'ഫോണിമെ- നില-ഇടത്തിനുള്ള ഇടപാടിനുള്ള സിയുണി നെയുറല്\u200d ആസ്റ്റര്\u200d ~നേതാവില്ലാത്ത ~SLT-ല്\u200d IWSLT 2020-ല്\u200d', 'lt': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for~Non-Native~SLT at IWSLT 2020', 'kk': 'Телефон- деңгейіндегі ~Жүйелік емес ~SLT- ге IWSLT 2020 жылы CUNI негізгі ASR', 'no': 'CUNI Neural ASR med mellomsnittsteg for ~Non-Native ~SLT på IWSLT 2020', 'mt': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for~Non-Native~SLT at IWSLT 2020', 'mn': 'CUNI мэдрэлийн ASR нь IWSLT 2020 онд', 'sr': 'CUNI Neuralni ASR sa prosječnim koracima na nivou telefone za ~Ne-roditeljski ~SLT na IWSLT 2020.', 'pl': 'CUNI Neuronalny ASR z poziomem Phoneme pośredni krok dla~Non-Native~SLT na IWSLT 2020', 'ro': 'CUNI Neural ASR cu Phoneme-Level Intermediar Pas pentru ~ Non-Native ~ SLT la IWSLT 2020', 'si': 'CUNI නිර්මාත්මක ASR සමඟ ෆෝනේම්-ලේවල් ඉන්ධාරණ පැත්ත ~Non-Native~SLT IWSLT 2020ට', 'sv': 'CUNI Neural ASR med Phoneme-nivå mellansteg för ~ Non-Native ~ SLT på IWSLT 2020', 'ta': 'IWSLT 2020-ல் CUNI புகைப்படம்- நிலை இடைவெளி படியுடன் சியுனி நெருக்கமான ASR', 'ur': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for ~Non-Native~SLT at IWSLT 2020', 'so': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for~Non-Native~SLT at IWSLT 2020', 'uz': 'Name', 'vi': 'U.P.U.C.U.A.R. với Không phải là trường nội bộ (trường hợp gốc) ở IWSLT 2020', 'hr': 'CUNI Neuralni ASR s prosječnim korakom na nivou telefoneme za ~Ne-roditeljski ~SLT na IWSLT 2020.', 'da': 'CUNI Neural ASR med Phoneme-niveau mellemliggende trin til ~ Non-Native ~ SLT på IWSLT 2020', 'de': 'CUNI Neural ASR mit Phoneme-Level Zwischenschritt fﾃｼr‾Non-Native‾SLT bei IWSLT 2020', 'id': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for‾Non-Native‾SLT at IWSLT 2020', 'bg': 'Невроден АСР с междинна стъпка на телефонно ниво за ~ не-роден ~ СЛТ в 2020', 'nl': 'CUNI Neural ASR met Phoneme-Niveau Tussenstap voor‾Niet-Native‾SLT bij IWSLT 2020', 'ko': 'IWSLT 2020 중 비로컬 SLT 음소급 중간 단계의 CUNI 신경 ASR', 'fa': 'CUNI Neural ASR با قدم میانگین سطح تلفنی برای ~Non-Native~SLT در IWSLT 2020', 'sw': 'ASR ya asili ya CUNI yenye hatua ya kati ya Picha kwa ‾Siyo-Native‾SLT kwenye IWSLT 2020', 'tr': "IWSLT 2020'de ýerlik bölegi üçin CUNI Neural ASR", 'af': 'Kuni Neurale ASR met Phoneme- Vlak Intermediate Step vir ‾Non- Native‾SLT op IWSLT 2020', 'sq': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for‾Non-Native‾SLT at IWSLT 2020', 'am': 'በፎቶ-ደረጃ Intermediate Step for ~Non-Native~SLT at IWSLT 2020', 'hy': 'CuNice Նեյրալ ASR ֆոնեմային մակարդակի միջին քայլը', 'az': 'IWSLT 2020-d蓹 ~Non-Native~SLT 眉莽眉n Phoneme-Level Intermediate Step il蓹 CUNI Neural ASR', 'bn': 'ইউএসএলটি ২০২০-এ ফটোমেম- স্তরের মধ্যের মধ্যে সিউনি-নেউরেল আসার সাথে ~নাগরিক~এসএলটির জন্য', 'ca': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for‾Non-Native‾SLT at IWSLT 2020', 'cs': 'CUNI Neurální ASR s Phoneme-úrovní střední krok pro~Non-Native~SLT na IWSLT 2020', 'et': 'CUNI neuraalne ASR koos telefonitaseme tasandi vahetasemega ~ mitte-Native ~ SLT ajal IWSLT 2020', 'bs': 'CUNI Neuralni ASR sa prosječnim koracima na nivou telefoneme za ~Ne-roditeljski ~SLT na IWSLT 2020.', 'fi': 'CUNI Neuraalinen ASR Phoneme-tason välivaihe ~ ei-natiiville ~ SLT: lle IWSLT 2020', 'jv': 'CUNI Njuaral ASR karo Meksi Normal', 'ha': 'KCharselect unicode block name', 'sk': 'CUNI nevralni ASR z vmesnim korakom na telefonski ravni za ~ ne-native ~ SLT na IWSLT 2020', 'he': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for‾Non-Native‾SLT at IWSLT 2020', 'bo': 'CUNI Neural ASR with Phoneme-Level Intermediate Step for‾Non-Native‾SLT at IWSLT 2020'}
{'en': 'In this paper, we present our submission to the Non-Native Speech Translation Task for IWSLT 2020. Our main contribution is a proposed speech recognition pipeline that consists of an acoustic model and a phoneme-to-grapheme model. As an intermediate representation, we utilize phonemes. We demonstrate that the proposed pipeline surpasses commercially used automatic speech recognition (ASR) and submit it into the ASR track. We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track.', 'ar': 'في هذه الورقة ، نقدم تقديمنا إلى مهمة ترجمة الكلام غير الأصلية لـ IWSLT 2020. مساهمتنا الرئيسية هي خط أنابيب مقترح للتعرف على الكلام يتكون من نموذج صوتي ونموذج صوتي إلى حروف. كتمثيل وسيط ، نستخدم الصوتيات. نوضح أن خط الأنابيب المقترح يتجاوز التعرف التلقائي على الكلام المستخدم تجاريًا (ASR) وإرساله إلى مسار ASR. نحن نكمل ASR بأنظمة الترجمة الآلية الجاهزة للمشاركة أيضًا في مسار ترجمة الكلام.', 'es': 'En este artículo, presentamos nuestra presentación a la Tarea de traducción de voz no nativa para IWSLT 2020. Nuestra principal contribución es una propuesta de canalización de reconocimiento de voz que consiste en un modelo acústico y un modelo de fonema a grafema. Como representación intermedia, utilizamos fonemas. Demostramos que la canalización propuesta supera el reconocimiento automático de voz (ASR) de uso comercial y la enviamos a la vía ASR. Complementamos este ASR con sistemas de MT estándar para participar también en la vía de traducción de voz.', 'pt': 'Neste artigo, apresentamos nossa submissão ao Non-Native Speech Translation Task for IWSLT 2020. Nossa principal contribuição é uma proposta de pipeline de reconhecimento de fala que consiste em um modelo acústico e um modelo fonema-grafema. Como representação intermediária, utilizamos fonemas. Demonstramos que o pipeline proposto supera o reconhecimento automático de fala (ASR) usado comercialmente e o submete à trilha ASR. Complementamos este ASR com sistemas MT de prateleira para participar também da trilha de tradução de fala.', 'fr': "Dans cet article, nous présentons notre soumission à la tâche de traduction vocale non native pour IWSLT 2020. Notre principale contribution est une proposition de pipeline de reconnaissance vocale qui consiste en un modèle acoustique et un modèle phonème en graphème. En tant que représentation intermédiaire, nous utilisons des phonèmes. Nous démontrons que le pipeline proposé surpasse la reconnaissance vocale automatique (ASR) utilisée dans le commerce et le soumettons à la piste ASR. Nous complétons cette ASR par des systèmes de magnétoscopie prêts à l'emploi afin de participer également au suivi de la traduction vocale.", 'ja': '本稿では、IWSLT 2020の非ネイティブスピーチ翻訳タスクへの提出を紹介します。私たちの主な貢献は、音響モデルと音素対グラフモデルからなる音声認識パイプラインの提案です。中間表現として、音素を利用している。提案されたパイプラインが市販されている自動音声認識（ ＡＳＲ ）を上回ることを実証し、ＡＳＲトラックに提出する。私たちは、音声翻訳トラックにも参加するために、このASRを既製のMTシステムで補完します。', 'zh': '本文中,将IWSLT 2020非母语语音译事。 凡我一音别管道,声学管音素字素模形。 以为中表,吾用音素。 臣等证管道越商自音识(ASR),并提付ASR道中。 因成机器翻译以补其 ASR,以参音译。', 'hi': 'इस पेपर में, हम IWSLT 2020 के लिए गैर-मूल भाषण अनुवाद कार्य के लिए अपना सबमिशन प्रस्तुत करते हैं। हमारा मुख्य योगदान एक प्रस्तावित भाषण पहचान पाइपलाइन है जिसमें एक ध्वनिक मॉडल और एक फोनम-टू-ग्राफेम मॉडल शामिल है। एक मध्यवर्ती प्रतिनिधित्व के रूप में, हम phonemes का उपयोग करें। हम प्रदर्शित करते हैं कि प्रस्तावित पाइपलाइन व्यावसायिक रूप से उपयोग की जाने वाली स्वचालित भाषण पहचान (एएसआर) को पार करती है और इसे एएसआर ट्रैक में सबमिट करती है। हम भाषण अनुवाद ट्रैक में भी भाग लेने के लिए ऑफ-द-शेल्फ एमटी सिस्टम के साथ इस एएसआर के पूरक हैं।', 'ru': 'В этой статье мы представляем нашу заявку на задание по переводу неродной речи для IWSLT 2020. Нашим основным вкладом является предлагаемый конвейер распознавания речи, который состоит из акустической модели и модели фонемы-графемы. В качестве промежуточного представления мы используем фонемы. Мы демонстрируем, что предлагаемый трубопровод превосходит коммерчески используемое автоматическое распознавание речи (ASR) и передаем его в трек ASR. Мы дополняем этот ASR готовыми системами MT, чтобы принять участие также в речевом переводе.', 'ga': 'Sa pháipéar seo, cuirimid ár n-aighneacht i láthair don Tasc Aistriúcháin Urlabhra Neamhdhúchasach do IWSLT 2020. Is é an príomh-ranníocaíocht atá againn ná píblíne aitheanta cainte atá comhdhéanta de shamhail fhuaimiúil agus de shamhail fóinéim-go-graifim. Mar léiriú idirmheánach, bainimid úsáid as fóinéimí. Léirímid go sáraíonn an píblíne atá beartaithe aitheantas uathoibríoch cainte a úsáidtear ar bhonn tráchtála (ASR) agus cuirimid isteach sa rian ASR é. Comhlánaimid an ASR seo le córais MT as an tseilf chun páirt a ghlacadh freisin sa rian aistriúcháin cainte.', 'ka': 'ამ დოკუნეში ჩვენ ჩვენი წარმოდგენება IWSLT 2020-ის სამუშაო სამუშაო წარმოდგენებაში. ჩვენი მნიშვნელოვანი დამატება არის საუკეთესო საუკეთესო მოდელზე, რომელიც არსებობს აკსტიული მოდელზე და ფონემის გრაფიმე მოდელზე. როგორც საშუალო გამოყენება, ჩვენ გამოყენებთ ტონემები. ჩვენ გამოჩვენებთ, რომ საზოგადომის ფეხლინი კომპორციალურად გამოიყენებული ავტომატიკური სიტყვების განახლება (ASR) და ამას ASR სიტყვებში გადატანა. ჩვენ დავაკეთებთ ამ ASR-ს MT სისტემაში, რომელიც დავაკეთებთ სიტყვების გადაწყვეტილება.', 'el': 'Σε αυτή την εργασία, παρουσιάζουμε την υποβολή μας στο έργο μετάφρασης μη μητρικής ομιλίας για το IWSLT 2020. Η κύρια συνεισφορά μας είναι ένας προτεινόμενος αγωγός αναγνώρισης ομιλίας που αποτελείται από ένα ακουστικό μοντέλο και ένα μοντέλο φωνής-γραφεμού. Ως ενδιάμεση αναπαράσταση, χρησιμοποιούμε φωνήματα. Αποδεικνύουμε ότι ο προτεινόμενος αγωγός ξεπερνά την εμπορικά χρησιμοποιούμενη αυτόματη αναγνώριση ομιλίας και την υποβάλλει στο κομμάτι ASR. Συμπληρώνουμε αυτό το σύστημα με έτοιμα συστήματα ΜΤ για να συμμετέχουμε και στο κομμάτι μετάφρασης ομιλίας.', 'kk': 'Бұл қағазда, біз IWSLT 2020 жылы үшін балалардың аудармаларының тапсырмасына жібереміз. Біздің негізгі қатынасыз - акустикалық моделі мен фонемде графимде қатынау үлгісі болатын сөздерді анықтау құралы. Орташа таңдау ретінде, телефонын қолданамыз. Біз келтірілген конвейер коммерциялық сөздерді автоматты түрде анықтау (ASR) және ASR жолына жібереді дегенді көрсетедік. Біз осы ASR-ді MT жүйелеріне қосып, сөздерді аудару жолында қосылу үшін.', 'hu': 'Ebben a tanulmányban bemutatjuk benyújtásunkat az IWSLT 2020 nem őshonos beszédfordítási feladataira. Fő hozzájárulásunk egy akusztikus modellből és egy fonema-graféma modellből álló beszédfelismerő pipeline. Közbenső ábrázolásként fonémákat használunk. Bemutatjuk, hogy a javasolt csővezeték meghaladja a kereskedelmi forgalomban használt automatikus beszédfelismerést (ASR) és benyújtjuk az ASR sávba. A beszédfordítási pályán való részvétel érdekében ezt az ASR-t egyszerűen használható MT rendszerekkel egészítjük ki.', 'ms': 'Dalam kertas ini, kami memperkenalkan penghantaran kami kepada Tugas Terjemahan Cahaya Bukan-asli untuk IWSLT 2020. Kontribusi utama kami adalah saluran paip pengenalan ucapan yang direncanakan yang terdiri dari model akustik dan model phoneme-to-grapheme. Sebagai perwakilan sementara, kami menggunakan fonem. Kami menunjukkan bahawa saluran paip yang diusulkan melebihi pengenalan pidato automatik (ASR) yang digunakan secara komersial dan menghantarnya ke trek ASR. Kami tambahkan ASR ini dengan sistem MT off-the-shelf untuk mengambil bahagian juga dalam trek terjemahan ucapan.', 'mk': 'Во овој документ, го претставуваме нашето поднесување на Неродната задача за преведување на говор за IWSLT 2020. Нашиот главен придонес е предложен гасовод за препознавање на говорот кој се состои од акустички модел и модел од фонет до графем. Како посредна претстава, користиме телефони. Демонстрираме дека предложениот гасовод го надминува комерцијално искористеното автоматско препознавање на говорот (АСР) и го пренесува на АСР трага. Ние го комплиментираме овој АСР со системи на МТ надвор од полицата за да учествуваме, исто така, во трансформацијата за превод на говорот.', 'it': 'In questo articolo, presentiamo la nostra presentazione al Non-Native Speech Translation Task per IWSLT 2020. Il nostro contributo principale è una pipeline di riconoscimento vocale proposta che consiste in un modello acustico e un modello fonema-grafema. Come rappresentazione intermedia, utilizziamo i fonemi. Dimostriamo che la pipeline proposta supera il riconoscimento vocale automatico utilizzato commercialmente (ASR) e lo sottoponiamo nella traccia ASR. Completiamo questo ASR con sistemi MT off-the-shelf per partecipare anche alla traccia di traduzione vocale.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d നമ്മുടെ കീഴ്പെടുത്തിക്കൊടുക്കുന്നത് നാഷണവിഭാഷയില്ലാത്ത സംസാരത്തിന്റെ പരിഭാഷണ കാര് നമ്മുടെ പ്രധാനപ്പെട്ട വാക്ക് തിരിച്ചറിയാനുള്ള പൈപ്പെലിനാണ് പ്രൊദ്ദേശിക്കപ്പെട്ടിരിക്കുന്നത്. അത് ഒരു ആക്സ തമ്മിലുള്ള പ്രതിനിധിയായി ഞങ്ങള്\u200d ഫോണികള്\u200d ഉപയോഗിക്കുന്നു. പ്രൊദ്ദേശിക്കപ്പെട്ട പൈപ്പൈലൈന്\u200d സ്വയമായി സംസാരിക്കുന്ന സ്വഭാഷണത്തിന്റെ തിരിച്ചറിയുന്നതിന് മുന്\u200dപ് കടന്നു  സംസാരം പരിഭാഷണത്തിന്റെ ട്രാക്കിലും പങ്കെടുക്കാനുള്ള എസ്ആര്\u200d പൂര്\u200dത്തീകരിക്കുന്നു.', 'mt': 'F’dan id-dokument, qed nippreżentaw is-sottomissjoni tagħna lill-Kompitu tat-Traduzzjoni tal-Ilmijiet Mhux Nazzjonali għall-IWSLT 2020. Il-kontribut ewlieni tagħna huwa pipeline propost għar-rikonoxximent tad-diskors li jikkonsisti f’mudell akustiku u mudell foneme-to-grapheme. As an intermediate representation, we utilize phonemes.  Aħna nuru li l-pipeline propost jaqbeż ir-rikonoxximent awtomatiku tad-diskors (ASR) użat kummerċjalment u jissottomettiha fil-binarju ASR. Aħna nikkumplimentaw din l-ASR b’sistemi MT li ma jidhrux fuq l-ixkaffa biex jieħdu sehem ukoll fil-binarju tat-traduzzjoni tad-diskors.', 'no': 'I denne papiret presenterer vi søknaden vårt til oppgåva for IWSLT 2020 som ikkje er i staden for taleomsetjing. Vårt hovudbidrag er ein foreslått tale-gjenkjenning-røyr som inneheld av ein akustisk modell og ein fonemodus til grafikk. Som mellombels representasjon bruker vi telefonar. Vi demonstrerer at den foreslåde røyrlinja overstyrer komercialt brukt automatisk opplesing (ASR) og sender den til ASR- sporet. Vi complementerer denne ASR med off-shelf MT-systemet for å ta del også i taleoversettelssporet.', 'pl': 'W niniejszym artykule przedstawiamy naszą zgłoszenie do Zadania Tłumaczenia Mowy Non-Native Speech Task dla IWSLT 2020. Naszym głównym wkładem jest proponowany rurociąg rozpoznawania mowy, który składa się z modelu akustycznego i modelu fonem-grafem. Jako pośrednia reprezentacja używamy fonemów. Pokazujemy, że proponowany rurociąg przewyższa komercyjnie stosowane automatyczne rozpoznawanie mowy (ASR) i przesyła go do ścieżki ASR. Uzupełniamy ten ASR o gotowe systemy MT, aby uczestniczyć również w ścieżce tłumaczenia mowy.', 'ro': 'În această lucrare, vă prezentăm prezentarea noastră la sarcina de traducere a vorbirii non-native pentru IWSLT 2020. Contribuția noastră principală este o conductă propusă de recunoaștere a vorbirii, care constă dintr-un model acustic și un model fonem-graf. Ca reprezentare intermediară, folosim foneme. Demonstrăm că conducta propusă depășește recunoașterea automată a vorbirii (ASR) utilizată comercial și o transmitem în pista ASR. Completăm această ASR cu sisteme MT de pe raft pentru a lua parte și la traseul de traducere vocală.', 'mn': 'Энэ цаасан дээр бид IWSLT 2020-ийн төлөө үндэслэлгүй ярианы хөрөнгө хөрөнгө оруулах үйлдлийг дамжуулж байна. Бидний гол зорилго бол ярианы хүлээн зөвшөөрөл хоолойн шугам юм. Энэ нь акустик загвар, фонем-т графим загвар юм. Бид дундаж үзүүлэлтийн хувьд утаснуудыг хэрэглэдэг. Бид санал өгсөн хоолойн шугам нь худалдааны автоматик ярианы хүлээн зөвхөн ашиглаж, ASR шугам руу дамжуулдаг гэдгийг харуулж байна. Бид энэ АСР-г илтгэл хөрөнгө оруулах боломжтой MT системээр нэмэгдүүлнэ.', 'si': 'මේ පත්තරේ අපි අපේ පිළිබඳින්නේ නොනැති වචන වාර්තාවක් වැඩේ IWSLT 2020ට. අපේ ප්\u200dරධාන ප්\u200dරයෝජනයක් තමයි කතාව අඳුරගන්න පායිප්ලින් එකක් තියෙන්නේ, ඒ වගේම අකුස්ටික් මොඩේල් එකක් සහ අතරමාධික ප්\u200dරතිනිධානයක් විදිහට, අපි ෆෝන්ම් එක පාවිච්චි කරනවා. අපි පැහැදිලි කරනවා කියලා පායිප්ලින් එක ස්වයංක්\u200dරමයෙන් ස්වයංක්\u200dරීය කතා පරීක්ෂණය කරන්න පුළුවන් කියලා ASR ට්\u200dර අපි මේ ASR එක සම්පූර්ණ කරනවා MT පද්ධතියෙන් කොටස් කරන්න.', 'so': 'Warqadan, waxaynu u soo dhiibnaa cashuurta tarjumaadda ee IWSLT 2020. Kharashadanada ugu horeeya waa sawir lagu soo jeeday aqoonsashada hadalka, kaasoo ka mid ah model cajiibsan iyo muusiko sawir ah. Midowga dhexe, waxaynu isticmaalnaa telefoonno. Waxaynu muujinnaa in heerka la soo jeeday ay uu kor u dhaafo aqoonsiga hadalka asalka ah oo lagu isticmaalay aqoonsiga hadalka (ASR) oo uu ku diro wadada ASR. Waxaynu ku dhamaynaynaa ASR-da nidaamka MT-ka-shelf-shelf si aan uga qeybqaadano sidoo kale wadooyinka turjumaadda.', 'ta': 'இந்த காகிதத்தில், நாங்கள் எங்கள் கூறுதலை IWSLT 2020 இல் இல்லாத பேச்சு மொழிபெயர்ப்பு பணிக்கு கொடுக்கிறோம். எங்கள் முக்கிய ஒப்பந்தம் ஒரு பேச்சு குறிப்பிடும் பைப்பையாள் என்பது ஒரு முன்னிருந்த பேச்சு ஒப்புக்கொண்ட மாதிரி மற ஒரு நடுநிலை பிரதிநிதியாக, நாம் தொலைபேசிகளை பயன்படுத்துகிறோம். நாம் திருப்பப்பட்ட பைப்லைன் வியாபாரத்தில் தானாகவே பேச்சு அடையாளம் பயன்படுத்தப்படுகிறது மற்றும் ASR தடத்தில் கொடுக்கு பேச்சு மொழிபெயர்ப்பு தடத்தில் பகிர்ந்து கொள்ள இந்த ASR மூலம் நிறைவேற்றுகிறோம்.', 'sr': 'U ovom papiru predstavljamo svoju predanost zadatku za prevod neodređenih govora za IWSLT 2020. Naš glavni doprinos je predložen cjevovod za priznanje govora koji se sastoji od akustičkog model a i telefonskog modela. Kao međuvremena predstavljanja, koristimo telefone. Pokazujemo da je predložena naftna linija prelazi komercijalno korišćena automatska priznanja govora (ASR) i podiže ga na ASR stazu. Mi dopunjavamo ovaj ASR sa off-shelf MT sistemima da bi se uključili i u pratnju prevoda govora.', 'ur': 'اس کاغذ میں، ہم نے اپنا اطاعت کو IWSLT 2020 کے لئے غیر ملتی بول کی ترجمہ ٹاکس کے لئے پیش کیا ہے. ہمارا اصلی حصہ یہ ایک پیشنهاد ہے کہ کلام کی شناسایی پائیپ لین ہے جو ایک آکوستیکی موڈل اور ایک فونیم پر گرافیم موڈل ہے۔ ایک میانہ نمایش کے طور پر ہم فونیموں کو استعمال کرتے ہیں۔ ہم نشان دیتے ہیں کہ پیشنهاد پائپ لین تجارت سے اضافہ ہوتا ہے اور اسے ASR ٹریک میں ڈال دیتا ہے۔ ہم اس آس آس آر کو شلف MT سیسٹم کے ساتھ اضافہ کرتے ہیں کہ زبان ترک میں بھی حصہ حاصل کریں۔', 'lt': 'Šiame dokumente pristatome savo pasiūlymą nemokamų kalbų vertimo darbui „IWSLT 2020“. Pagrindinis mūsų indėlis yra siūlomas kalbos pripažinimo vamzdynas, kurį sudaro akustinis model is ir fonemo-grafimo modelis. Kaip tarpinis atstovavimas, mes naudojame telefonemes. Mes įrodome, kad siūlomas vamzdynas viršija komerciniu būdu naudojamą automatinį kalbos atpažinimą (ASR) ir pateikia jį į ASR kelią. Mes papildysime šį ASR išorinėmis MT sistemomis, kad taip pat dalyvautume kalbos vertimo take.', 'sv': 'I denna uppsats presenterar vi vårt bidrag till Non-Native Speech Translation Task för IWSLT 2020. Vårt huvudsakliga bidrag är en föreslagen taligenkänning pipeline som består av en akustisk modell och en fonem-till-grafem modell. Som en mellanliggande representation använder vi fonemer. Vi visar att den föreslagna pipeline överträffar kommersiellt använt automatisk taligenkänning (ASR) och skickar in den i ASR-spåret. Vi kompletterar denna ASR med färdiga MT-system för att även delta i talöversättningsspåret.', 'uz': "Bu qogʻozda biz IWSLT 2020 uchun mahalliy tilning tarjima vazifasini namoyish qilamiz. Bizning asosiy qiziqaruvchimiz, gapiruvchi tashqi soʻzni tasdiqlash pipelining asoslangan modeli va foydalanuvchi modeli. Intermediate represent sifatida, biz foydalanamiz. Ko'rib chizilgan pipelining bir xil tilni avtomatik foydalanish (ASR) bilan ishlatiladi va buni ASR yoʻlakiga qo'yish mumkin. Biz bu ASR'ni MT tizimlarini yozib qo'yish va gapirish tarjimasini o'rganish uchun bajaramiz.", 'vi': 'Trong tờ giấy này, chúng tôi xin giới thiệu sự phục tùng của mình cho Công tác Dịch Ngôn ngữ Không Native cho IWSLT 2020. Phần quan trọng của chúng tôi là một ống dẫn nhận dạng giọng đề xuất gồm một mô hình âm thanh và một mô hình ghép-đến-graphheme. Chúng tôi sử dụng các đường điện thoại. Chúng tôi chứng minh rằng đường ống dự kiến vượt qua khả năng nhận dạng ngôn ngữ tự động được sử dụng thương mại (ASR) và gửi nó vào đường ray ASR. Chúng tôi bổ sung ASR với các hệ thống MT loại không hạn để tham gia cũng trong bài dịch thuyết.', 'bg': 'В настоящата статия представяме нашето представяне на Задачата за превод на чуждоземен речен превод за международен транспорт 2020. Нашият основен принос е предложен тръбопровод за разпознаване на речта, който се състои от акустичен модел и модел фонем-графем. Като междинно представяне използваме фонеми. Ние демонстрираме, че предложеният тръбопровод надминава търговско използваното автоматично разпознаване на речта (АСР) и го изпращаме в пистата на АСР. Ние допълваме този АСР с готови МТ системи, за да участваме и в речния превод.', 'nl': 'In dit artikel presenteren we onze inzending aan de Non-Native Speech Translation Task voor IWSLT 2020. Onze belangrijkste bijdrage is een voorgestelde spraakherkenningspipeline die bestaat uit een akoestisch model en een foneem-naar-grafeemmodel. Als tussenrepresentatie gebruiken we fonemen. We tonen aan dat de voorgestelde pijplijn de commercieel gebruikte automatische spraakherkenning (ASR) overtreft en verzenden deze in het ASR-spoor. We vullen deze ASR aan met kant-en-klare MT-systemen om ook deel te nemen aan het spraakvertaalspoor.', 'hr': 'U ovom papiru predstavljamo svoju predanost zadatku za prevod neodređenog govora za IWSLT 2020. Naš glavni doprinos je predložen cjevovod za prepoznavanje govora koji se sastoji od akustičkog model a i telefonskog modela. Kao prosječna predstavljanja, koristimo telefone. Pokazujemo da predložena cijevina prelazi komercijalno korišteno priznanje automatskog govora (ASR) i predaje ga na stazu ASR. Mi dopunjavamo ovaj ASR sa off-shelf MT sustavima kako bi se uključili i u pratnju prevoda govora.', 'da': 'I denne artikel præsenterer vi vores indsendelse til Non-Native Speech Translation Task for IWSLT 2020. Vores vigtigste bidrag er en foreslået talegenkendelse pipeline, der består af en akustisk model og en fonem-til-grafem model. Som en mellemliggende repræsentation bruger vi fonemer. Vi demonstrerer, at den foreslåede pipeline overgår kommercielt anvendt automatisk talegenkendelse (ASR) og sender den ind i ASR sporet. Vi supplerer denne ASR med færdige MT-systemer for også at deltage i taleoversættelsesspørgsmålet.', 'id': 'In this paper, we present our submission to the Non-Native Speech Translation Task for IWSLT 2020.  Kontribusi utama kami adalah pipa pengakuan pidato yang direncanakan yang terdiri dari model akustik dan model phoneme-to-grapheme. Sebagai representation intermediate, kami menggunakan telepon. Kami menunjukkan bahwa saluran pipa yang diusulkan melebihi pengkenalan pidato otomatis yang digunakan secara komersial (ASR) dan mengirimkannya ke jalur ASR. We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track.', 'fa': 'در این کاغذ، ما تحویل خود را به تابع ژباب غیر طبیعی برای IWSLT 2020 پیشنهاد می کنیم. کمک اصلی ما یک لوله شناسایی سخنرانی است که از یک مدل آکوستیک و یک مدل تلفن به گرافیم است. به عنوان نمایش بین\u200cالمللی، ما تلفن\u200cها را استفاده می\u200cکنیم. ما نشان می دهیم که خط لوله پیشنهاد به طور تجارتی از شناسایی سخنرانی خودکار (ASR) استفاده می\u200cشود و آن را به راه ASR می\u200cفرستیم. ما این ASR را با سیستم\u200cهای MT خارج از پناهگاه اطلاع می\u200cکنیم تا در ترک ترجمه سخنرانی هم بخشید.', 'de': 'In diesem Beitrag stellen wir unseren Beitrag zur Non-Native Speech Translation Task für IWSLT 2020 vor. Unser Hauptbeitrag ist eine vorgeschlagene Spracherkennungs-Pipeline, die aus einem akustischen Modell und einem Phonem-zu-Graphem-Modell besteht. Als Zwischendarstellung verwenden wir Phoneme. Wir zeigen, dass die vorgeschlagene Pipeline die kommerziell genutzte automatische Spracherkennung (ASR) übertrifft und in die ASR-Spur einreicht. Wir ergänzen diesen ASR mit gebrauchsfertigen MT-Systemen, um auch am Sprachübersetzungsspur teilzunehmen.', 'sw': 'Katika gazeti hili, tunatoa ujumbe wetu kwenye kazi ya Tafsiri ya Utamaduni wa Kiraia kwa ajili ya IWSLT 2020. Mchango wetu mkuu ni pipeline inayopendekezwa kutambua hotuba inayojumuisha muundo wa kifahari na modeli ya simu kwa picha. Kama uwakilishi wa kati, tunatumia simu. Tunaonyesha kwamba pipeli inayopendekezwa inapitia utambulisho wa kujieleza kwa kibiashara (ASR) na kuitumia katika njia ya ASR. Tunajamilisha ASR kwa mifumo ya MT ya kutoa huduma hiyo ili pia kushiriki katika mfumo wa kutafsiri hotuba.', 'ko': '이 논문에서 우리는 IWSLT2020 비모국어 음성 번역 임무에 제출했다.우리의 주요 공헌은 음성인식 파이프를 제시한 것이다. 이 파이프는 음성학 모델과 음소부터 자형 모델로 구성된다.중간 표시로서 우리는 음소를 사용한다.상용 자동 음성인식(ASR)보다 파이프라인이 우수하다는 것을 입증하고 ASR 트랙에 제출했습니다.우리는 기존의 기계 번역 시스템으로 ASR을 보충하여 음성 번역에 참여한다.', 'tr': "Bu kagyzda IWSLT 2020-nji ýylyň IWSLT üçin beýleki çykyşymyzy görkezýäris. Biziň esasy gaýşartymyz, akustik nusga we foneme-tä-grafime nusga içerilýän çykyş tanamak pipetdir. Orta temsil olarak telefonları kullanırız. Biz teklip eden pipeline commercially ulanan otomatik çykyş tanyşyny (ASR) geçýändigini we muny ASR şäherine gönderýäris. Biz bu ASR'i satyn sistemasynda çykmak üçin çykyş terjime çykmak üçin basýarys.", 'af': "In hierdie papier, ons voorsien ons ondersteuning aan die Nie-Natiewe Spraak Vertaling Opdrag vir IWSLT 2020. Ons hoofbydrang is 'n voorgestelde spraak herken pyplyn wat bestaan van 'n akustiese model en 'n foneme-na-grafémodel. As 'n middelste voorstelling, gebruik ons fonemes. Ons wys dat die voorgestelde pyplyn oortgaan commercially gebruik outomatiese woorde herken (ASR) en dit in die ASR snit stuur. Ons complementeer hierdie ASR met af-die-shelf MT stelsels om deel te neem ook in die spraak vertaling snit.", 'sq': 'Në këtë letër, ne paraqesim paraqitjen tonë në Detyrën e Trakthimit të Fjalës jo-vendase për IWSLT 2020. Kontributi ynë kryesor është një tubacion i propozuar për njohjen e fjalimit që përbëhet nga një model akustik dhe një model telefonim-në-grafim. Si përfaqësim i mesëm, ne përdorim telefonema. We demonstrate that the proposed pipeline surpasses commercially used automatic speech recognition (ASR) and submit it into the ASR track.  Ne komplementojmë këtë ASR me sisteme MT jashtë raftit për të marrë pjesë gjithashtu në gjurmën e përkthimit të fjalës.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք մեր ներկայացումը ոչ բնիկ լեզվի թարգմանման խնդիրներին IwPLT 2020-ի համար: Մեր հիմնական ներդրումը խոսքի ճանաչման խողովակաշար է, որը կազմված է ձայնային մոդելի և հեռախոս-գրաֆեմի մոդելի հետ: Որպես միջնական ներկայացում, մենք օգտագործում ենք հեռախոսներ: Մենք ցույց ենք տալիս, որ առաջարկված խողովակաշարը գերազանցում է առևտրային առումով օգտագործված ավտոմատիկ խոսքի ճանաչման (ASR) և ներկայացնում այն ASR-ի ճանապարհին: We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track.', 'bn': 'এই কাগজটিতে আমরা আমাদের আত্মসমর্পণ করছি না জাতীয় ভাষা অনুবাদের কাজের জন্য ইউএসএলটি ২০২০। আমাদের প্রধান অবদান হচ্ছে প্রস্তাবিত বক্তৃতা স্বীকারের পাইপেলাইন যা একাস্টিক মডেল এবং ফোন-থেকে গ্রাফেম মডেল। মাঝামাঝি প্রতিনিধিত্ব হিসেবে আমরা ফোন ব্যবহার করি। আমরা প্রস্তাবিত পাইপেলাইন বাণিজ্যিক ভাষণ স্বীকৃতি ব্যবহার করেছে এবং এটি ASR ট্র্যাকে প্রবেশ করেছি। ভাষণ অনুবাদের ট্র্যাকে অংশগ্রহণের জন্য আমরা এসআরকে অফ-শেল্ফ এমটি সিস্টেম দ্বারা সম্পূর্ণ করি।', 'am': 'በዚህ ገጾች ውስጥ ለIWSLT 2020 የኖረ አካባቢ ንግግር ትርጉም ስራችን እናቀርባለን፡፡ የዋነታችን አካባቢ የንግግር ማስታወቂያው ፕላይንስ ነው፤ በቁጥጥር ሞዴል እና የፎልፎ-ለግራሜ ሞዴል የሚኖር ነው፡፡ የመካከለኛ መልዕክት፣ ፎፎፎችን እናስቀምጣለን፡፡ የተዘጋጀው ፖሊስ በንግግር የራሱ ንግግር ማስታወቂያውን (ASR) እንዲሻል እናሳየዋለን፡፡ ይህንን ASR በንግግር ትርጉም ግንኙነት እናጋራለን፡፡', 'az': 'Bu kağızda, biz müsəlmanızı IWSLT 2020 üçün nazil olmayan sözlərin tercümə işinə göstəririk. Bizim ən böyük qismətimiz, akustik modellərdən və fonema-to-grafik modellərdən olub təbliğ edilən sözlərin tanıması pipeline idi. Aralıq göstəricisi kimi, telefonları istifadə edirik. Biz göstəririk ki, təbliğ edilmiş boru alışverişli olaraq istifadə edilən otomatik söz tanıması (ASR) və onu ASR yoluna göndərir. Biz bu ASR-i sözlərin çevirilməsi yolunda da bölmək üçün istifadə edərik.', 'ca': "En aquest article, presentem la nostra subministració a la tasca de traducció de la llengua no indígena per IWSLT 2020. Our main contribution is a proposed speech recognition pipeline that consists of an acoustic model and a phoneme-to-grapheme model.  Com a representació intermediària, utilitzem telèmens. Demonstrem que el pipeline proposat supera el reconeixement automàtic de la fala (ASR) utilitzat comercialment i l'envia a la pista ASR. We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track.", 'cs': 'V tomto článku představujeme náš příspěvek k úkolu překladu nativní řeči pro IWSLT 2020. Naším hlavním příspěvkem je navržená potrubí rozpoznávání řeči, která se skládá z akustického modelu a fonému-grafémového modelu. Jako zprostředkovatel používáme fonémy. Dokazujeme, že navržené potrubí překonává komerčně používané automatické rozpoznávání řeči (ASR) a předává ho do ASR stopy. Tento ASR doplňujeme standardními MT systémy, abychom se podíleli i na stopě překladu řeči.', 'bs': 'U ovom papiru predstavljamo svoju predanost zadatku za prevod neodređenog govora za IWSLT 2020. Naš glavni doprinos je predložen cjevovod za prepoznavanje govora koji se sastoji od akustičkog model a i telefonskog modela. Kao prosječna predstavljanja, koristimo telefone. Pokazujemo da predložena cijevina prelazi komercijalno korišteno priznanje automatskog govora (ASR) i predaje ga na stazu ASR. Dodajemo ovaj ASR sa off-shelf MT-ovim sistemima da bi se uključili i u pratnju prevoda govora.', 'et': 'Käesolevas dokumendis esitame oma ettepanekut mittekõlise kõne tõlke ülesandele IWSLT 2020. Meie peamine panus on kavandatud kõnetuvastustoru, mis koosneb akustilisest mudelist ja foneem-grafeem mudelist. Vahe esindusena kasutame foneeme. Näitame, et kavandatud torujuhe ületab kaubanduslikult kasutatud automaatse kõnetuvastuse (ASR) ja esitame selle ASR rajale. Täiendame seda ASR-i riiulipõhiste MT-süsteemidega, et osaleda ka kõnetõlke rajal.', 'fi': 'Tässä artikkelissa esittelemme artikkelimme IWSLT 2020:n Non-Native Speech Translation Task -hankkeeseen. Pääasiallinen panos on ehdotettu puheentunnistusputki, joka koostuu akustisesta mallista ja foneemi-grafeemi-mallista. Väliesityksenä käytämme foneemeja. Osoitamme, että ehdotettu putkisto ylittää kaupallisesti käytetyn automaattisen puheentunnistuksen (ASR) ja lähetämme sen ASR-radalle. Täydennämme tätä ASR:ää valmiilla MT-järjestelmillä, jotta voimme osallistua myös puhekäännösradalle.', 'jv': 'Nang maper iki, kita mulai nggawe tresenaké kanggo Terjamahan kanggo IWSLT 2020 Awakdhéwé éntuk pergunaké panelangno sawar nggambar aturan tapi model akustik lan model model telempen karo graphem Tambah kang intermediate, kita ngubah telepongan Awak dhéwé éntuk ngéwangaké nyeangké éntuk gak nyeangke tarjamahan kanggo nyeangke tarjamahan (ASR) lan uga ngewehi nang ASR track Awak dhéwé nambah ASR iki ngono sistem MT liyane ora ono nggawe ngulinakake tarjamahan kanggo langgar.', 'ha': 'Ga wannan takardan, Munã halatar da injinmu zuwa Tafiyar da Tarjifanmu na Non-Native Spelling wa IWSLT 2020. Bayanin da ke ƙaranci shi ne wata pilin da aka buƙata tabbatarwa ga magana wanda ke ƙunsa da wani misalin akosati da wani motel na-fomat zuwa-grapheme. Kama mataimaki mai tsakiya, za mu yi amfani da fomat. Tuna nũna cewa piilen da aka buƙata ta kafin bayani da aka yi amfani da mataimaki farat ɗaya (ATR) kuma Mu saka shi a cikin hanyari na ATR. Munã cika wannan SSR da shirin-shelf-shelf-MT-na don mu yi rabo da shi also cikin jerin fassarar magana.', 'sk': 'V tem prispevku predstavljamo našo predstavitev za nalogo prevajanja govora nedomorodcev za IWSLT 2020. Naš glavni prispevek je predlagan cevovod za prepoznavanje govora, ki je sestavljen iz akustičnega modela in modela fonema-grafema. Kot vmesna reprezentacija uporabljamo foneme. Dokazujemo, da predlagani cevovod presega komercialno uporabljeno samodejno prepoznavanje govora (ASR) in ga predložimo v ASR sled. Ta ASR dopolnjujemo s pripravljenimi MT sistemi, da sodelujemo tudi pri prevajanju govora.', 'he': 'בעיתון הזה, אנחנו מציגים את ההעברה שלנו למשימת התרגום של דיבורים לא מקומית עבור IWSLT 2020. התרומה העיקרית שלנו היא צינור זיהוי נאום מוצע שמכיל מודל אקוסטי ומודל טלפונים לגרפים. As an intermediate representation, we utilize phonemes.  אנו מראים שהצינור המוצע עובר את זיהוי הנאום האוטומטי (ASR) שמשתמש באופן מסחרי ושלח אותו למסלול ASR. אנו משלים את ASR הזה במערכות MT מחוץ למדף כדי לקחת חלק גם במסלול התרגום הנאום.', 'bo': 'ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྣམས་མེད་པའི་སྐད་བརྗོད་ཀྱི་མིང་ཚོའི་ནང་དུ་འཇུག་སྣོད་IWSLT 2020་ལ་ཡོད། ང་ཚོའི་རྩ་བའི་གོ་སྤྲོད་དེ་སྒྲུང་བརྗོད་ཀྱི་གཟུགས་རིས་མངོན་འཆར་བ་ཞིག་རེད། རྒྱ་ནག་མི་མང་གི་གསལ་བཤད་པ་ལ་ང་ཚོས་ཁ་པར་ལག་ལེན་འཐབ་ཐུབ། We demonstrate that the proposed pipeline surpasses commercially used automatic speech recognition (ASR) and submit it into the ASR track. ང་ཚོས་ASR་འདི་ལ་དུས་shelf MT systems་ཕྱི་ཁར་ནས་བསྡུར་ན་ཁ་བརྗོད་ཀྱི་གླེང་སྒྲོམ་ནང་དུ་ཆ་ཤས་ཞིག་བྱེད་དགོས་པ'}
{'en': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'ar': 'ترجمة ELITR للكلام غير الأصلي في IWSLT 2020', 'pt': 'Tradução de fala não nativa ELITR no IWSLT 2020', 'es': 'Traducción de voz no nativa de ELITR en IWSLT 2020', 'fr': "Traduction vocale non native ELITR à l'IWSLT 2020", 'ja': 'IWSLT 2020でのELITR非ネイティブスピーチ翻訳', 'zh': 'ELITR非母语语音译在IWSLT 2020', 'ru': 'ELITR Non-Native Speech Translation at IWSLT 2020 (Перевод неродной речи ELITR на IWSLT 2020)', 'hi': 'IWSLT 2020 में ELITR गैर-मूल भाषण अनुवाद', 'ga': 'Aistriúchán Urlabhra Neamhdhúchasach ELITR ag IWSLT 2020', 'ka': 'ELITR ბვჱ ნავრთგნარა დჲგჲპნა ოპვგყპლწმა ნა IWSLT 2020', 'hu': 'ELITR nem natív beszédfordítás az IWSLT 2020-on', 'el': 'Μετάφραση μη εγγενής ομιλίας ELITR στο IWSLT 2020', 'it': 'ELITR Traduzione vocale non nativa a IWSLT 2020', 'lt': 'ELITR ne gimtosios kalbos vertimas 2020 m. IWSLT', 'kk': 'ELITR жұмыс емес сөз аудармасы IWSLT 2020 жылы', 'mk': 'ЕЛИТР Нероден превод на говор на IWSLT 2020', 'ml': 'IWSLT 2020-ല്\u200d ELITR നാതീവികമായ സ്പീക്ക് പരിഭാഷ', 'mt': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'ms': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'mn': 'IWSLT 2020 онд ELITR хэл биш орон төрөлхтний хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийг', 'pl': 'ELITR tłumaczenie mowy nienatywnej na IWSLT 2020', 'no': 'ELITR ikkje- nativt taleomsetjing på IWSLT 2020', 'sr': 'ELITR Nenacionalni prevod govora na IWSLT 2020.', 'ro': 'ELITR Non-Native Speech Traducere la IWSLT 2020', 'so': 'Translation at IWSLT 2020', 'si': 'ELITR Non-Native Word translation at IWSLT 2020Query', 'ur': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'sv': 'ELITR Icke-Native Speech Översättning på IWSLT 2020', 'ta': 'IWSLT 2020-ல் ELITR நாடியல் பேச்சு இல்லாத மொழிபெயர்ப்பு', 'uz': 'Name', 'vi': '[ELITA Non-Native Speech Translation at IWSLT 2020]', 'bg': 'ЕЛИТР Нероден превод на реч в ИВСЛТ 2020', 'da': 'ELITR Non-Native Tale Oversættelse på IWSLT 2020', 'nl': 'ELITR Non-Native Speech Translation op IWSLT 2020', 'hr': 'ELITR Neproditeljski prevod govora na IWSLT 2020.', 'de': 'ELITR Non-Native Speech Translation auf der IWSLT 2020', 'id': 'ELITR Non-Native Speech Translation di IWSLT 2020', 'ko': 'IWSLT 2020의 ELITR 비모국어 음성 번역', 'fa': 'ترجمه سخنرانی غیر طبیعی ELITR در IWSLT 2020', 'sw': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'tr': "ELITR IWSLT 2020'de ýerli söz terjime edilmez", 'af': 'ELITR Non- Native Speech Translation at IWSLT 2020', 'sq': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'am': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'hy': 'ELITR-ի ոչ բնիկ խոսքի թարգմանությունը IwPLT 2020-ին', 'az': "IWSLT 2020'də ELITR-Tövratlı Söz Çeviri", 'bn': 'ELITR Non-Native Speech Translation at IWSLT 2020', 'bs': 'ELITR Ne-Nativni govor prevod na IWSLT 2020.', 'ca': 'ELITR non-native speech translation at IWSLT 2020', 'cs': 'ELITR Non-Native Speech Translation na IWSLT 2020', 'et': 'ELITR mitte-emakeelne kõne tõlkimine IWSLT 2020', 'fi': 'ELITR ei-natiivipuhekäännös IWSLT 2020 -messuilla', 'jv': 'Language', 'he': 'ELITR non-native speech Translation at IWSLT 2020', 'ha': '@ item license', 'sk': 'ELITR Nedomorodni govorni prevod na IWSLT 2020', 'bo': 'ELITR Non-Native Speech Translation at IWSLT 2020'}
{'en': 'This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020. We describe systems for offline ASR, real-time ASR, and our cascaded approach to offline SLT and real-time SLT. We select our primary candidates from a pool of pre-existing systems, develop a new end-to-end general ASR system, and a hybrid ASR trained on non-native speech. The provided small validation set prevents us from carrying out a complex validation, but we submit all the unselected candidates for contrastive evaluation on the test set.', 'ar': 'هذه الورقة عبارة عن تقديم لنظام ELITR لمهمة ترجمة الكلام غير الأصلية في IWSLT 2020. نصف أنظمة ASR غير المتصلة بالإنترنت و ASR في الوقت الفعلي ونهجنا المتتالي لـ SLT دون اتصال بالإنترنت و SLT في الوقت الحقيقي. نختار المرشحين الأساسيين لدينا من بين مجموعة من الأنظمة الموجودة مسبقًا ، ونطور نظام ASR العام الجديد من طرف إلى طرف ، ونظام ASR الهجين المدربين على الكلام غير الأصلي. تمنعنا مجموعة التحقق الصغيرة المقدمة من إجراء عملية تحقق معقدة ، لكننا نقدم جميع المرشحين غير المختارين للتقييم المتباين في مجموعة الاختبار.', 'pt': 'Este artigo é uma submissão do sistema ELITR para a tarefa de tradução de fala não nativa no IWSLT 2020. Descrevemos sistemas para ASR offline, ASR em tempo real e nossa abordagem em cascata para SLT offline e SLT em tempo real. Selecionamos nossos principais candidatos a partir de um conjunto de sistemas pré-existentes, desenvolvemos um novo sistema ASR geral de ponta a ponta e um ASR híbrido treinado em fala não nativa. O pequeno conjunto de validação fornecido nos impede de realizar uma validação complexa, mas enviamos todos os candidatos não selecionados para avaliação contrastiva no conjunto de teste.', 'es': 'Este documento es una presentación del sistema ELITR para la tarea de traducción de voz no nativa en IWSLT 2020. Describimos los sistemas para ASR fuera de línea, ASR en tiempo real y nuestro enfoque en cascada para SLT fuera de línea y SLT en tiempo real. Seleccionamos a nuestros candidatos principales de un conjunto de sistemas preexistentes, desarrollamos un nuevo sistema ASR general de punta a punta y un ASR híbrido capacitado en voz no nativa. El pequeño conjunto de validación proporcionado nos impide llevar a cabo una validación compleja, pero enviamos todos los candidatos no seleccionados para una evaluación contrastante en el conjunto de prueba.', 'fr': "Cet article est une soumission du système ELITR pour la tâche de traduction vocale non native à l'IWSLT 2020. Nous décrivons des systèmes pour l'ASR hors ligne, l'ASR en temps réel et notre approche en cascade de la SLT hors ligne et de la SLT en temps réel. Nous sélectionnons nos principaux candidats parmi un ensemble de systèmes préexistants, développons un nouveau système ASR général de bout en bout et un ASR hybride formé à la parole non native. Le petit jeu de validation fourni nous empêche d'effectuer une validation complexe, mais nous soumettons tous les candidats non sélectionnés pour une évaluation contrastive sur le jeu de tests.", 'ja': '本稿は、IWSLT 2020における非ネイティブ音声翻訳タスクのためのELITRシステム提出である。オフラインASR、リアルタイムASR、およびオフラインSLTおよびリアルタイムSLTへのカスケードアプローチのためのシステムについて説明します。私たちは、既存のシステムのプールから主要候補を選択し、新しいエンドツーエンドの一般的なASRシステムを開発し、非ネイティブスピーチでトレーニングされたハイブリッドASRを開発します。提供された小さなバリデーションセットは、複雑なバリデーションを実行することを防ぎますが、選択されていない候補をすべてテストセットのコントラスト評価に提出します。', 'zh': '本文为IWSLT 2020非母语语音译者ELITR统。 述于离线 ASR、实时 ASR 之统,及于离线 SLT 、实时 SLT 之级联法。 择我先存之统,择我大选,发一新端以通ASR统,与一基于非母语音语音训练之混ASR。 小验集止杂验,然提所有未择之候选项于试集上较之。', 'hi': 'यह पेपर IWSLT 2020 में गैर-देशी भाषण अनुवाद कार्य के लिए एक ELITR सिस्टम सबमिशन है। हम ऑफ़लाइन ASR, वास्तविक समय ASR, और ऑफ़लाइन SLT और वास्तविक समय SLT के लिए हमारे कैस्केड दृष्टिकोण के लिए सिस्टम का वर्णन करते हैं। हम पहले से मौजूद प्रणालियों के एक पूल से अपने प्राथमिक उम्मीदवारों का चयन करते हैं, एक नया एंड-टू-एंड सामान्य एएसआर सिस्टम विकसित करते हैं, और गैर-देशी भाषण पर प्रशिक्षित एक हाइब्रिड एएसआर विकसित करते हैं। प्रदान किया गया छोटा सत्यापन सेट हमें एक जटिल सत्यापन करने से रोकता है, लेकिन हम परीक्षण सेट पर कंट्रास्टिव मूल्यांकन के लिए सभी अचयनित उम्मीदवारों को प्रस्तुत करते हैं।', 'ru': 'Данная статья является представлением системы ELITR для задачи неродного перевода речи на IWSLT 2020. Мы описываем системы для автономного ASR, ASR в реальном времени и наш каскадный подход к автономному SLT и SLT в реальном времени. Мы отбираем наших основных кандидатов из пула уже существующих систем, разрабатываем новую сквозную общую систему ASR и гибридную ASR, обученную неродной речи. Предоставленный небольшой набор валидации не позволяет нам провести комплексную валидацию, но мы представляем все невыбранные кандидаты для контрастной оценки на наборе испытаний.', 'ga': 'Is aighneacht chórais ELITR é an páipéar seo don tasc aistriúcháin urlabhra neamhdhúchais ag IWSLT 2020. Déanaimid cur síos ar chórais le haghaidh ASR as líne, ASR fíor-ama, agus ár gcur chuige cascáideach maidir le SLT as líne agus SLT fíor-ama. Roghnaímid ár n-iarrthóirí bunscoile ó chomhthiomsú de chórais a bhí ann cheana féin, forbróimid córas ASR ginearálta nua ceann go ceann, agus ASR hibrideach atá oilte ar chaint neamhdhúchais. Cuireann an fhoireann bheag bhailíochtaithe a chuirtear ar fáil cosc orainn bailíochtú casta a dhéanamh, ach cuirimid na hiarrthóirí neamhroghnaithe go léir isteach le haghaidh meastóireacht chodarsnachta ar an tsraith tástála.', 'ka': 'ეს დოკუმენტი არის ELITR სისტემის გადაწყვეტილება IWSLT 2020 წლის დაწყვეტილებისთვის. ჩვენ აღწერეთ სისტემები ASR-ის, რეალური დროის ASR-ის და ჩვენი კაკადირებული გახსნა SLT-ის და რეალური დროის SLT-ის. ჩვენ მონიშნეთ ჩვენი პირველი კანდიდენტები წინაღებული სისტემების ბასენდან, განვითარებით ახალი საკუთარი ASR სისტემა და ჰიბრიტი ASR, რომელიც არ იყოს საკუთარი სისტემაში. ჩვენ შევცვალოთ პატარა გადაწყვეტილება, რომელიც ჩვენ უნდა კომპლექსი გადაწყვეტილება, მაგრამ ჩვენ ჩვენ ყველა გადაწყვეტილი კანდიდენტებს კონტრასტიური გადაწყვეტილებ', 'hu': 'Ez a tanulmány ELITR rendszer benyújtása az IWSLT 2020 nem anyanyelvű fordítási feladatához. Leírjuk az offline ASR, a valós idejű ASR rendszereket, valamint az offline SLT és a valós idejű SLT kaszkádos megközelítését. Az elsődleges jelölteket már meglévő rendszerek közül választjuk ki, új, end-to-end általános ASR rendszert fejlesztünk ki, és egy hibrid ASR képzést fejlesztünk ki a nem anyanyelvi beszédre. A mellékelt kis validációs készlet megakadályozza, hogy komplex validálást végezzünk, de a kiválasztott jelölteket kontrasztív értékelésre küldjük a tesztkészleten.', 'el': 'Αυτή η εργασία είναι μια υποβολή συστήματος ELITR για την εργασία μετάφρασης μη μητρικής ομιλίας στο IWSLT 2020. Περιγράφουμε συστήματα για εκτός σύνδεσης, σε πραγματικό χρόνο και την Cascade προσέγγισή μας για εκτός σύνδεσης και σε πραγματικό χρόνο. Επιλέγουμε τους βασικούς υποψηφίους μας από μια ομάδα προϋπάρχοντων συστημάτων, αναπτύσσουμε ένα νέο γενικό σύστημα και ένα υβριδικό σύστημα εκπαιδευμένο σε μη μητρική γλώσσα. Το παρεχόμενο μικρό σετ επικύρωσης μας εμποδίζει να πραγματοποιήσουμε μια σύνθετη επικύρωση, αλλά υποβάλλουμε όλους τους μη επιλεγμένους υποψηφίους για αντικρουστική αξιολόγηση στο σετ δοκιμών.', 'it': 'Questo articolo è una presentazione del sistema ELITR per il compito di traduzione del linguaggio non nativo di IWSLT 2020. Descriviamo sistemi per ASR offline, ASR in tempo reale e il nostro approccio a cascata per SLT offline e SLT in tempo reale. Selezioniamo i nostri candidati primari da un pool di sistemi preesistenti, sviluppiamo un nuovo sistema ASR generale end-to-end e un ASR ibrido addestrato sul linguaggio non nativo. Il piccolo set di convalida fornito ci impedisce di effettuare una convalida complessa, ma sottoponiamo tutti i candidati non selezionati per una valutazione contrastante sul set di test.', 'kk': 'Бұл қағаз IWSLT 2020 жылы жергілікті сөздерді аудару тапсырмасына ELITR жүйесінің жіберілуі. Қолданыстағы ASR, шын уақыт ASR және SLT және шын уақыт SLT жүйесіне каскадтық тәсілімізді таңдаймыз. Біз бастапқы кандидаттарымызды алдындағы жүйелердің бірінен таңдап, жаңа соңындағы жалпы ASR жүйесін жасап, және жергілікті емес сөйлеу үшін оқылған гибрид ASR. Келтірілген кішкентай тексеру бағдарламасы бізге комплекс тексеруді ұстайды, бірақ біз тексеру бағдарламасында контрастық оқу үшін таңдалмаған кандидаттарды жібереміз.', 'lt': 'This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020.  Mes apibūdiname ne interneto ASR, realiuoju laiku ASR sistemas ir mūsų kaskadinį požiūrį į ne interneto SLT ir realiuoju laiku SLT. Pasirenkame savo pagrindinius kandidatus iš jau egzistuojančių sistemų, sukuriame naują bendrą ASR sistemą nuo galo iki galo ir hibridinę ASR, mokomą ne gimtosios kalbos. Pateiktas nedidelis patvirtinimo rinkinys neleidžia mums atlikti sudėtingo patvirtinimo, tačiau mes pateikiame visus neparinktus kandidatus kontrastiniam vertinimui bandymų rinkinyje.', 'mt': 'Dan id-dokument huwa sottomissjoni tas-sistema ELITR għall-kompitu tat-traduzzjoni tad-diskors mhux nattiv fl-IWSLT 2020. Aħna niddeskrivu sistemi għal ASR offline, ASR f’ħin reali, u l-approċċ kaskadi tagħna għal SLT offline u SLT f’ħin reali. Aħna nagħżlu l-kandidati primarji tagħna minn ġabra ta’ sistemi eżistenti minn qabel, niżviluppaw sistema ġdida ta’ ASR ġenerali minn tarf sa tarf, u ASR ibrida mħarrġa fuq diskors mhux nattiv. Is-sett żgħir ta’ validazzjoni pprovdut jipprevjeni lilna milli nagħmlu validazzjoni kumplessa, iżda nippreżentaw il-kandidati kollha mhux eletti għal evalwazzjoni kuntrastiva fuq is-sett tat-test.', 'ms': 'Kertas ini adalah penghantaran sistem ELITR untuk tugas terjemahan ucapan bukan asli pada IWSLT 2020. Kami menggambarkan sistem untuk ASR diluar talian, ASR masa sebenar, dan pendekatan kaskade kita ke SLT diluar talian dan SLT masa sebenar. Kami memilih calon utama kami dari kolam sistem prawujud, mengembangkan sistem ASR umum akhir-akhir baru, dan ASR hibrid dilatih dalam ucapan bukan asli. Set pengesahihan kecil yang disediakan menghalang kita daripada melakukan pengesahihan kompleks, tetapi kita menghantar semua calon yang tidak dipilih untuk penilaian bertentangan pada set ujian.', 'mk': 'Овој документ е поднесување на ЕЛИТР систем за задачата за превод на нероден говор на IWSLT 2020. Ние ги опишуваме системите за АСР, АСР во реално време, и нашиот каскадиран пристап до СЛТ и СЛТ во реално време. Ние ги избираме нашите главни кандидати од базен на препостоечки системи, развиваме нов генерален систем од крај до крај АСР, и хибриден АСР трениран на нероден говор. Обезбедената мала валидација не спречува да спроведеме комплексна валидација, но ги поднесуваме сите неизбрани кандидати за контрастивна оценка на тестот.', 'ml': 'IWSLT 2020-ല്\u200d നാതാവില്ലാത്ത സംസാരം പരിഭാഷണത്തിനുള്ള ജോലി We describe systems for offline ASR, real-time ASR, and our cascaded approach to offline SLT and real-time SLT.  നിലവിലുള്ള സിസ്റ്റത്തിന്റെ പൂളില്\u200d നിന്നും ഞങ്ങള്\u200d നമ്മുടെ പ്രധാനപ്രാര്\u200dത്ഥികളെ തിരഞ്ഞെടുക്കുന്നു. ഒരു പുതിയ അവസാന സിസ്റ്റത്തിന് കൊടുക്കുന്ന ചെറിയ വിശ്വാസം സജ്ജീകരിക്കുന്നത് നമ്മളെ പരിശോധനത്തിന്റെ വിലാസങ്ങളില്\u200d നിന്ന് പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d തടഞ്', 'mn': 'Энэ цаас бол IWSLT 2020 онд биш орон захирал хөгжүүлэх үйл ажиллагааны ELITR системийн сургалт юм. Офлайн АСР, реаль цаг АСР, газрын SLT болон реаль цаг SLT болон газрын газрын газрын арга замыг тайлбарлаж байна. Бид анхны удирдагчидыг өмнө суурилсан системээс сонгож, шинэ төгсгөл-төгсгөл АСР систем болон орон нутгий ярианд сургалтын гибрид АСР-г хөгжүүлнэ. Бага зэрэг шалгалт гаргасан бага зэрэг бидэнд комплекс шалгалтыг хийхгүйгээр зогсоож байна. Гэхдээ бид шалгалтын комплекс дээр эсрэг шалгалтын тулд сонгогдоггүй хүндлэгчийг дамжуулдаг.', 'pl': 'Niniejszy artykuł jest zgłoszeniem systemu ELITR do zadania tłumaczenia mowy nienative na IWSLT 2020. Opisujemy systemy do offline ASR, ASR w czasie rzeczywistym oraz nasze kaskadowe podejście do offline SLT i SLT w czasie rzeczywistym. Wybieramy naszych głównych kandydatów z puli istniejących wcześniej systemów, opracowujemy nowy kompleksowy system ASR oraz hybrydowy ASR przeszkolony z mową inną. Dostarczony niewielki zestaw walidacji uniemożliwia nam przeprowadzenie skomplikowanej walidacji, ale wszystkich niewybranych kandydatów przekazujemy do kontrastywnej oceny na zestawie testowym.', 'no': 'Denne papiret er ei ELITR-systemoppføring for den ikkje-native taleomsetjinga på IWSLT 2020. Vi skildrar systemet for offline ASR, real-time ASR, og vår kaskadert tilnærming til offline SLT og real-time SLT. Vi veljer våre primære kandidatar frå eit pool av føreeksisterande systemer, utviklar eit nytt ende-til-slutt generell ASR-system, og ein hybrid ASR- trent på ikkje-native tale. Den oppgjevne små validasjonssettet hindrar oss å gjera ein kompleks validasjon, men vi sender alle ikkje valde kandidatane til kontrastevaluering på testsettet.', 'ro': 'Această lucrare este o depunere a sistemului ELITR pentru sarcina de traducere a limbii non-native la IWSLT 2020. Descriem sistemele pentru ASR offline, ASR în timp real și abordarea noastră în cascadă a SLT offline și SLT în timp real. Selectăm candidații noștri primari dintr-un grup de sisteme preexistente, dezvoltăm un nou sistem ASR general end-to-end și un ASR hibrid instruit pe vorbire non-nativă. Setul mic de validare furnizat ne împiedică să efectuăm o validare complexă, dar trimitem toți candidații neselectați pentru evaluare contrastantă pe setul de test.', 'so': 'Warqadan waa nidaamka ELITR oo loo soo dhiibay shaqada turjumista afka aan hooyo ahayn ee IWSLT 2020. Waxaynu sawirannaa nidaamka internetka ee ASR, waqtiga caadiga ah ee ASR, iyo qaabka aan ku xadgudbayno SLT iyo SLT waqtiga dhabta ah. Waxaynu dooranaynaa kandidayada ugu horeeyay oo ka tirsan nidaamka hore, waxaan horumarinaynaa nidaamka cusub ee ugu dambeeya ASR, iyo hibrid ASR oo lagu baray hadal aan hooyo ahayn. Heeganka shaqeynta yar ayaa naga hor jeeda in aan sameyno xaqiijin adag, laakiin waxaynu u dhiibnaa mushaarka aan la dooranayn oo dhan si aan qiimeyn ka duwan tijaabada.', 'si': 'මේ පත්තේ ELITR පද්ධතියක් ඉන්නේ නැති කතාවක් අවවාද කරන වැඩේ IWSLT 2020දී. අපි ඇත්තටම ASR, ඇත්තටම ASR සහ අපේ කැස්කේඩ් විදිහට SLT සහ ඇත්තටම SLT සඳහා ප්\u200dරතිකාර විදිහට පද්ධතිය විස්තර කරනවා. අපි ප්\u200dරධාන පද්ධතියක් තෝරාගන්නේ ප්\u200dරධාන පද්ධතියක් ඉදිරිපත් පද්ධතියක් වලින්, අළුත් අවසාන පද්ධතිය ASR පද්ධතියක්  පුංචි විශ්ලේෂණ සෙට් අපිට ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණයක් කරන්න පුළුවන් වෙනවා, ඒත් අපි පරීක්ෂණ සෙට් එකේ ප්\u200dරතික්\u200dර', 'sr': 'Ovaj papir je podnošenje sistema ELITR za zadatak za prevod neodređenog govora na IWSLT 2020. Opišemo sisteme za offline ASR, realno vrijeme ASR, i naš kaskadni pristup offline SLT-u i realno vrijeme SLT-u. Izabrali smo naše glavne kandidate iz bazena pre-postojećih sustava, razvijali novi generalni sistem za kraj do kraja ASR i hibridni ASR obučen na neorodnom govoru. Snažena mala potvrda nas sprječava da provodimo kompleksno potvrđenje, ali mi predajemo sve nepodabrane kandidate za kontrastivnu procjenu na setu test a.', 'ta': 'This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020.  நாங்கள் ஆஸ்ஆர், உண்மையான நேரத்திற்கான அமைப்புகளை விவரிக்கிறோம், மற்றும் எஸ்எல்டி மற்றும் உண்மையான நேரம் SLT மற்றும் ந நாங்கள் எங்கள் முதல் தேர்ந்தெடுக்கிறோம் முன் இருக்கும் அமைப்புகளின் குளிரியிலிருந்து, புதிய முடிவு முடிவு அமைப்பை உருவாக்குகிற கொடுக்கப்பட்ட சிறிய செலுத்துதல் அமைப்பு சிக்கலான செயல்பாட்டை செய்யாமல் தடுக்கிறது, ஆனால் நாம் அனைத்து தேர்ந்தெடுக்கப்படாத', 'sv': 'Denna uppsats är en ELITR-systeminlämning för översättningsuppgiften för icke-infödda tal vid IWSLT 2020. Vi beskriver system för offline ASR, realtidsASR och vår kaskadbaserade strategi för offline SLT och realtidsSLT. Vi väljer ut våra primära kandidater från en pool av redan existerande system, utvecklar ett nytt allmänt end-to-end-system och en hybrid ASR utbildad på icke-infödd tal. Den medföljande lilla valideringsuppsättningen hindrar oss från att genomföra en komplex validering, men vi skickar in alla icke valda kandidater för kontrastiv utvärdering på testuppsättningen.', 'ur': 'یہ کاغذ IWSLT 2020 میں غیر منطقی سخنرانی ترجمہ کا کام کے لئے ایک الیٹر سیستم تحویل ہے. ہم آف لین آس آس آر، حقیقی زمانی آس آس آر کے لئے سیستموں کو اور ہمارے کاسکے ڈالے ہوئے آف لین SLT اور حقیقی زمانی SLT کے لئے۔ ہم پہلے موجود سیستموں کے پائل سے اپنی اولین کاندینٹوں کو انتخاب کرتے ہیں، ایک نئی انتظام-انتظام آس آس آر سیسٹم، اور ایک ہیبراڈ آس آس آر جو غیر منطقی بات پر آموزش کی جاتی ہے۔ پیدا کیا گیا تھوڑا سا واضح کرنا ہمیں ایک پیچیدہ واضح کرنا منع کرتا ہے لیکن ہم تمام غیر انتخاب کئے ہوئے کاندینٹوں کو آزمائش سٹ پر مقابلہ کا ارزش کرنا چاہتے ہیں.', 'uz': "Bu qogʻoz IWSLT 2020 yildagi nativ tilning tarjima vazifasi uchun ELITR tizimi. Biz Oflayning ASR, haqiqiqiy vaqt ASR, va SLT va haqiqiqiy vaqt SLT orqali ishlatilgan narsalarni aytishimiz mumkin. Biz oldingi tizimdan birinchi asosiy kandidalarni tanamiz, yangi oxirigi ASR tizimini yaratib, va asay gapiradigan xabar ASR ta'minlovchi. Koʻrsatilgan kichki tasdiqlash tugmasini murakkab tasdiqlash bajarishimizdan oldin, lekin biz hamma tanlangan kandida qiymatni tasdiqlash uchun qo'llamiz.", 'vi': 'Tờ giấy này là ủy thác hệ thống ELITA cho các nhiệm vụ dịch chuyển ngôn ngữ không thổ dân tại IWSLT 2020. Chúng tôi mô tả hệ thống ASR ngoại tuyến, ASR thật-time, và hệ thống tốc độ phụ thuộc của chúng tôi với SLT ngoại tuyến và thời gian thực. Chúng tôi chọn những ứng viên hàng đầu từ một hồ các hệ thống đã có sẵn, phát triển một hệ thống ASR chung hoàn to àn mới, và một ASR nhân tạo được huấn luyện trong ngôn ngữ không thổ dân. Một bộ dán tường nhỏ cung cấp không cho phép chúng tôi thực hiện một miếng dán phức tạp, nhưng chúng tôi sẽ gửi tất cả các ứng viên không được chọn để đánh giá tương đối trên các bộ thử.', 'bg': 'Настоящата статия представлява подаване на система за превод на чужд речен превод по Международния транспорт 2020. Описваме системи за офлайн АСР, АСР в реално време и нашия каскаден подход към офлайн АСР и АСР в реално време. Избираме нашите основни кандидати от набор от вече съществуващи системи, разработваме нова обща система от край до край и хибридна система за обучение на чужда реч. Предоставеният малък комплект валидиране ни пречи да извършим комплексна валидация, но ние изпращаме всички неизбрани кандидати за контрастна оценка на тестовия комплект.', 'nl': 'Dit document is een ELITR-systeem inzending voor de niet-native spraakvertaaltaak bij IWSLT 2020. We beschrijven systemen voor offline ASR, real-time ASR, en onze cascaded benadering van offline SLT en real-time SLT. We selecteren onze primaire kandidaten uit een pool van reeds bestaande systemen, ontwikkelen een nieuw end-to-end algemeen ASR systeem en een hybride ASR getraind op niet-native spraak. De meegeleverde kleine validatieset voorkomt dat we een complexe validatie uitvoeren, maar we sturen alle niet geselecteerde kandidaten voor contrastieve evaluatie op de testset.', 'hr': 'Ovaj papir je podnošenje sustava ELITR za zadatak za prevod neodređenog govora na IWSLT 2020. Opišemo sisteme za offline ASR, realno vrijeme ASR i naš kaskadni pristup offline SLT-u i realno vrijeme SLT-u. Izabrali smo naše primjerne kandidate iz bazena prepostojećih sustava, razvijali novi generalni sustav ASR-a do kraja, i hibridni ASR-a obučen na non-native govor. Predložena mala potvrda nas sprječava provoditi kompleksno potvrđenje, ali predajemo sve nepodabrane kandidate za kontrastivnu procjenu na testu.', 'da': 'Denne artikel er en ELITR-systemindsendelse til opgaven med oversættelse af ikke-native tale på IWSLT 2020. Vi beskriver systemer til offline ASR, real-time ASR og vores kaskadeformede tilgang til offline SLT og real-time SLT. Vi udvælger vores primære kandidater fra en pulje af allerede eksisterende systemer, udvikler et nyt end-to-end generelt ASR-system og en hybrid ASR trænet i ikke-native tale. Det medfølgende lille valideringssæt forhindrer os i at udføre en kompleks validering, men vi indsender alle de ikke-valgte kandidater til kontrastevaluering på testsættet.', 'de': 'Dieses Papier ist eine ELITR-Systemeinreichung f羹r die nicht-native Sprach羹bersetzungsaufgabe am IWSLT 2020. Wir beschreiben Systeme f羹r Offline-ASR, Echtzeit-ASR und unseren kaskadierten Ansatz f羹r Offline-SLT und Echtzeit-SLT. Wir w瓣hlen unsere Prim瓣rkandidaten aus einem Pool bereits bestehender Systeme aus, entwickeln ein neues End-to-End allgemeines ASR-System und einen hybriden ASR, der auf nicht-native Sprache trainiert wird. Der mitgelieferte kleine Validierungssatz verhindert, dass wir eine komplexe Validierung durchf羹hren, aber wir reichen alle nicht ausgew瓣hlten Kandidaten zur kontrastiven Bewertung auf dem Testset ein.', 'ko': '본고는 IWSLT2020 비모국어 음성 번역 임무에 ELITR 시스템이 제출한 논문이다.우리는 오프라인 ASR, 실시간 ASR 시스템, 그리고 오프라인 SLT 및 실시간 SLT의 등급 연결 방법을 설명했다.우리는 기존의 시스템 라이브러리에서 우리의 주요 후보를 선택하여 새로운 단말기부터 단말기까지 통용되는 ASR 시스템과 비모국어 음성 기반의 혼합 ASR을 개발했다.작은 인증 세트를 제공하여 복잡한 검증을 할 수 없지만, 선택하지 않은 후보 테스트 세트를 모두 제출하여 비교 평가를 할 것입니다.', 'id': 'Kertas ini adalah pengiriman sistem ELITR untuk tugas terjemahan pidato bukan asli di IWSLT 2020. Kami menggambarkan sistem untuk ASR offline, ASR real-time, dan pendekatan kaskade kita untuk SLT offline dan SLT real-time. Kami memilih kandidat utama kami dari kolam sistem pre-eksistensi, mengembangkan sistem ASR umum akhir-akhir baru, dan sebuah ASR hibrid dilatih dalam pidato bukan asli. Seting penyediaan validasi kecil mencegah kita dari melakukan validasi kompleks, tapi kami menyerahkan semua kandidat yang tidak terpilih untuk evaluasi kontras pada set tes.', 'fa': 'این کاغذ یک تسلیم سیستم ELITR برای تکلیف ترجمه غیر طبیعی در IWSLT 2020 است. ما سیستم\u200cهایی را برای ASR offline، ASR زمان واقعی و طریق کاسکیدی ما به SLT و SLT زمان واقعی توصیف می\u200cکنیم. ما کاندیدات اصلی خود را از یک استخر سیستم\u200cهای پیش\u200cموجود انتخاب می\u200cکنیم، یک سیستم ژنرال ASR جدید به پایان رسید، و یک ASR hybrid آموزش آموزش یافته در سخنرانی غیر طبیعی. این مجموعه تأیید کوچک را پیشنهاد می\u200cکند که ما را از انجام یک تأیید پیچیده جلوگیری می\u200cکند، ولی ما تمام کاندیده\u200cهای غیر انتخاب شده را برای ارزیابی متفاوتی در مجموعه تأیید می\u200cفرستیم.', 'sw': 'Gazeti hili ni mfumo wa ELITR ulioandaliwa kwa ajili ya kazi ya tafsiri isiyo na asili ya hotuba katika IWSLT 2020. We describe systems for offline ASR, real-time ASR, and our cascaded approach to offline SLT and real-time SLT.  Tunawachagua wagombea wetu wa msingi kutoka kwenye viwanja vya mifumo ya awali, kutengeneza mfumo mpya wa mwisho wa mwisho wa ASR, na msafara wa ASR aliyefundishwa kwa hotuba isiyo ya asili. Mpango huo wa uthibitisho mdogo unatuzuia kufanya uhakikisho mzito, lakini tunawasilisha wagombea wote wasiochaguliwa kwa ajili ya kutathmini tofauti katika kituo cha tests.', 'af': "Hierdie papier is 'n ELITR stelsel onderskrywing vir die non-native speech translation taak by IWSLT 2020. Ons beskrywe stelsels vir offline ASR, reël- tyd ASR, en ons kaskadeerde toegang na offline SLT en reël- tyd SLT. Ons kies ons primêre kandidate van 'n pool van voor-bestaande stelsels, ontwikkel 'n nuwe end-to-end algemene ASR stelsel, en 'n hibride ASR onderwerp op nie-natiewe spreek. Die verskaf klein geldigheidstel verhinder ons om 'n kompleks geldigheid te doen, maar ons stuur al die ongeselekteerde kandidate vir kontrastiewe evaluering op die toets stel.", 'sq': 'This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020.  Ne përshkruajmë sistemet për ASR jashtë linje, ASR në kohë reale, dhe qasjen tonë kaskaduar për SLT jashtë linje dhe SLT në kohë reale. Ne zgjedhim kandidatët tanë kryesorë nga një grup sistemesh paraekzistues, zhvillojmë një sistem të ri të përgjithshëm ASR nga fundi në fund, dhe një ASR hibridë të stërvitur në fjalim jo-natyror. Validacioni i siguruar i vogël na pengon të kryejmë një vlerësim kompleks, por ne i paraqesim të gjithë kandidatët e pa zgjedhur për vlerësim kontrastiv në grupin e testit.', 'tr': "Bu kagyz IWSLT 2020'de ýerli çykyş edilmedik çykyş täblisasynyň ELITR sistemi bellenildir. Biz offline ASR, real-zamanly ASR we kaskadyly SLT we real-zamanly SLT üçin sistemlerimizi tasvir ediyoruz. Öň bar sistemlerden ilkinji kandidýalarymyzy saýlaýarys, täze bir soňra-soňra ajaýyp ASR sistemasyny döredip, we ýerlik sözleri bolmadykda bilinmeli ASR(hybrid ASR). Sahyp edilen kiçijik teňramçylyk düzeni bizi kompleks bir teňramçylyk etmäge mane edýär emma testiň düzeninde ähli saýlanmadyklary kandidatlary gönderýäris.", 'am': 'ይህ ገጽ በIWSLT 2020 ውስጥ ለአንድ ወራጆች የንግግር ትርጉም ስራ የELITR ስርዓት ነው፡፡ የASR፣ እውነተኛ ጊዜ ASR እና SLT እና እውነተኛ ሰዓት ለመጠቀም ስርዓታችንን እናሳውቃለን፡፡ አስቀድሞ ሲስተካከል ካለው መጀመሪያዎቹ ምናዳሪዎች እና አዲስ የፍጻሜ የASR ስርዓት እና የአገር ንግግር የማስተማርን የሐብሪዲ አሰራዊ ጉዳይ እናሳድጋለን፡፡ የተሰጠው ታናሽ ማስረጃ ማድረግ ግን በተፈተናው ማረጋገጫ ላይ ተቃውሞ እናስገድዳለን፡፡', 'hy': 'Այս աշխատանքը ELITR համակարգի ներկայացումն է ոչ բնիկ խոսքի թարգմանման հանձնարարության համար IwPLT 2020-ում: Մենք նկարագրում ենք ոչ առցանց ASR-ի, իրական ժամանակի ASR-ի համակարգերը և մեր կասկադի մոտեցումը անառցանց SԼT-ի և իրական ժամանակի SԼT-ի համար: Մենք ընտրում ենք մեր հիմնական թեկնածուներին նախկինում գոյություն ունեցող համակարգերի խմբից, զարգանում ենք նոր, վերջ-վերջ ընդհանուր ASR համակարգ, և հիբրիդ ASR-ը, որը պատրաստված է ոչ բնիկ խոսքի վրա: Տեղադրված փոքրիկ հավասարման համակարգը կանխում է մեզ կատարել բարդ հավասարման, բայց մենք ներկայացնում ենք բոլոր անընտրված թեկնածուներին թեստի համակարգի հակադրական գնահատման համար:', 'bn': 'এই পত্রিকাটি আইউএসএলটি ২০২০-এ নাগরিক ভাষণ অনুবাদের কাজের জন্য একটি ELITR সিস্টেম প্রদান করা হয়েছে। আমরা অফ-লাইন এসার, সত্যিকারের সময় এসার এবং আমাদের অফ-লাইন এসএলটি এবং সত্যিকারের সময় এসএলটির ক্যাসাডেডের ক্ষেত্রে আমাদের ক্য আমরা আমাদের প্রাথমিক প্রার্থীদের নির্বাচন করি পূর্ব বিদ্যমান সিস্টেমের একটি পুল থেকে, নতুন শেষ-শেষ-শেষ ব্যবস্থা তৈরি করা হয়েছে এবং স্থানী প্রদান করা ছোট্ট বৈধতা সেট আমাদের এক জটিল বৈধতা প্রদান করা থেকে বাধা দেয়, কিন্তু আমরা সকল নির্বাচিত প্রার্থীকে প্রতিষ্ঠান দিয়ে', 'az': 'Bu kağıt IWSLT 2020-də yerli deyil sözlər tercümə işləri üçün ELITR sistemi təbliğdir. Biz fərqli ASR, real-time ASR və kaskadlı SLT və real-time SLT sistemlərini təsdiqləyirik. Biz ilk kandidātlarımızı əvvəlki sistemlərdən seçirik, yeni sona-sona gələn genel ASR sistemini və yerli deyil sözlərdə təhsil edilən hibrid ASR sistemini təhsil edirik. Sənə verilən kiçik təsdiqləmə qurğusu bizi kompleks təsdiqləməyə mane edir, amma biz test qurduğu müxtəlif təsdiqləmə üçün seçilmədiyimiz tüm kandidātları göndəririk.', 'bs': 'Ovaj papir je podnošenje ELITR sistema za zadatak za prevod neodređenog govora na IWSLT 2020. Opišemo sisteme za offline ASR, realno vrijeme ASR, i naš kaskadni pristup offline SLT-u i realno vrijeme SLT-u. Izabrali smo naše primjerne kandidate iz bazena pre-postojećih sustava, razvijali novi generalni sistem za kraj do kraja ASR i hibridni ASR obučen na non-native govor. Predložena mala potvrda nas sprječava da provodimo kompleksno potvrđenje, ali mi predajemo sve nepodabrane kandidate za kontrastivnu procjenu na setu test a.', 'ca': "Aquest paper és una presentació del sistema ELITR per a la tasca de traducció de la llengua no nativa a IWSLT 2020. Descrevem els sistemes d'ASR offline, ASR en temps real, i el nostre enfocament cascat a SLT offline i SLT en temps real. Seleccionem els nostres candidats primàries d'un grup de sistemes pre-existents, desenvolupem un nou sistema general d'ASR de final a final, i un sistema híbrid d'ASR entrenat en discurs no natius. El petit conjunt de validació proporcionat ens impedi de fer una validació complex a, però submetem tots els candidats no seleccionats a una evaluació contrastiva en el conjunt de tests.", 'et': 'Käesolev töö on ELITR süsteemi esitamine mitte-emakeelse kõnetõlke ülesandeks IWSLT 2020. Me kirjeldame võrguühenduseta ASR-i, reaalajas ASR-i ja meie kaskadeeritud lähenemisviisi võrguühenduseta SLT-i ja reaalajas SLT-i jaoks. Valime oma peamised kandidaadid olemasolevate süsteemide hulgast, töötame välja uue otsast otsani üldise ASR-süsteemi ja hübriidse ASR-i, mis on koolitatud mitte-emakeelse kõne alal. Pakutud väike valideerimiskomplekt takistab meil teostada keerulist valideerimist, kuid esitame kõik valimata kandidaadid testikomplekti kontrastsele hindamisele.', 'cs': 'Tento příspěvek je předložením systému ELITR pro úlohu překladu řeči bez nativního jazyka na IWSLT 2020. Popisujeme systémy pro offline ASR, real-time ASR a náš kaskádový přístup k offline SLT a real-time SLT. Naše primární kandidáty vybíráme z fondu již existujících systémů, vyvineme nový end-to-end obecný ASR systém a hybridní ASR trénovaný na nerodivnou řeč. Poskytnutá malá validační sada nám brání provádět komplexní validaci, ale všechny nevybrané kandidáty předáváme k kontrastnímu vyhodnocení na testovací sadě.', 'fi': 'Tämä artikkeli on ELITR-järjestelmän lähetys IWSLT 2020:n vieraskieliseen puheen kääntämiseen. Kuvailemme offline-ASR:n, reaaliaikaisen ASR:n sekä offline-SLT:n ja reaaliaikaisen SLT:n vaiheittaista lähestymistapaa. Valitsemme ensisijaiset ehdokkaamme olemassa olevien järjestelmien joukosta, kehitämme uuden päästä päähän kattavan yleisen ASR-järjestelmän ja vieraskieliseen puheeseen koulutetun hybridi-ASR-järjestelmän. Tarjottu pieni validointisarja estää meitä suorittamasta monimutkaista validointia, mutta lähetämme kaikki valitsemattomat ehdokkaat testisarjassa vastakkaiseen arviointiin.', 'sk': 'Ta prispevek je oddaja sistema ELITR za nalogo prevajanja govora tujih jezikov na IWSLT 2020. Opisujemo sisteme za ASR brez povezave, ASR v realnem času in naš kaskadni pristop do SLT brez povezave in SLT v realnem času. Naše primarne kandidate izberemo iz nabora že obstoječih sistemov, razvijamo nov splošni ASR sistem od konca do konca in hibridni ASR, ki se uči na tujem govoru. Zagotovljen majhen komplet validacij nam preprečuje izvedbo kompleksne validacije, vendar vse neizbrane kandidate predložimo v kontrastno oceno na testnem kompletu.', 'he': 'This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020.  אנחנו מתארים מערכות עבור ASR מחוץ לרשת, ASR בזמן אמיתי, והגישה הקסקודית שלנו ל SLT מחוץ לרשת ו SLT בזמן אמיתי. אנחנו בוחרים את המועמדים העיקריים שלנו מבריכה של מערכות קודמות קיימות, לפתח מערכת ASR גנרלית חדשה סוף-סוף, ו ASR היבריד מאומן על נאום לא מקומי. קבוצת האישור הקטנה המסופקת מונעת מאיתנו לבצע אישור מורכב, אך אנחנו מוציאים את כל המועמדים הלא נבחרים לערכה נגדית על קבוצת הבדיקות.', 'jv': 'Ngetongke kuwi perintah sing lunak-sistem kanggo ngilangno apakno kanggo ngilangno apakno IWSLT 2020 Awak dhéwé éntuk sistem kanggo offline ASR, aku-aku ASR lan soko bijine sak dadi offline SLT lan SLT kuwi tur angel. Awak dhéwé milih sing kandidé sing nyebute nang sistem sing gawe raning, iso nggawe sistem sing gawe end-to-end ASR, lan akeh sabên-sabên ASR sing tuksuji tarjamahan ora ono-sabên. Language', 'ha': "@ item license (short name) Munã bayyana masu tsari wa shirin shirin ayuka na kafin da aka samu zuwa SLT da lokaci na gaske. Tuna zãɓi kanayanmu na farko daga wata pool na'urar da ke gaba-gaba, ko za'a buɗa wata na'ura na ƙari zuwa-ƙari na GANS, da an sanar da shi a kan magana wanda ba'a native ba. Ki da aka bai wa masu inganci kaɗan yana hana mu daga tafiyar da gaskiyar inganci mai adadi, kuma amma muna sakar da waɗanan da ba'a zãɓe su ba don an yi rabo da rabon sigar.", 'bo': 'ཤོག་བུ་འདིས་ELITR་མ་ལག་གི་སྐད་ཡིག་ཆ་མིན་པ་ལ་སྤྲོད་ཀྱི་ལས་འགུལ་གྱི་ཚོལ་ཞིག་རེད། IWSLT 2020་ལ། ང་ཚོས་དྲ་བ་དང་བྲལ་ནས་ཡོད་པའི་ASR དང་། དུས་ཚོད་real-time ASR དང་། ང་ཚོའི་Cascaded approach to offline SLT དང་དུས་ཚོད་SLT ཚོར་དང་། ང་ཚོས་དུས་ཡོད་པའི་སྔོན་ཡོད་པའི་མ་ལག་གི་ཐོག་ལས་རྩ་བའི་ཆ་རྐྱེན་པ་ཞིག་གདམ་ཀྱི་ཡོད། བྱིས་ཡོད་པའི་ཞིབ་དཔྱད་ཆུང་ཀུ་ཅིག་གིས་ང་ཚོར་རླུང་ཐུབ་ཀྱིས་མེད་པ་ཡིན་ནའང་ངེད་ཚོར་ཞིབ་དཔྱད་འཛུགས་གྱི་ནང་དུ་ཐད་ར'}
{'en': 'Neural Simultaneous Speech Translation Using Alignment-Based Chunking', 'ar': 'الترجمة العصبية المتزامنة للكلام باستخدام التقسيم القائم على المحاذاة', 'es': 'Traducción de voz simultánea neuronal mediante fragmentación basada en alineamiento', 'pt': 'Tradução de fala simultânea neural usando fragmentação baseada em alinhamento', 'fr': "Traduction vocale simultanée neuronale à l'aide de la segmentation basée sur l'alignement", 'ja': 'アライメントベースのチャンキングを使用したニューラル同時音声翻訳', 'zh': '用齐分块神经同声传译', 'hi': 'संरेखण-आधारित चंकिंग का उपयोग करके तंत्रिका एक साथ भाषण अनुवाद', 'ru': 'Нейронный синхронный перевод речи с использованием чанкинга на основе выравнивания', 'ga': 'Neural Comhuaineach Aistriúchán Urlabhra Ag baint úsáide as Ailíniú-bhunaithe Chunking', 'el': 'Νευρική ταυτόχρονη μετάφραση ομιλίας με βάση την ευθυγράμμιση', 'hu': 'Neurális egyidejű beszédfordítás az igazítás alapú vastagság használatával', 'ka': 'Name', 'it': "Traduzione vocale simultanea neurale utilizzando il chunking basato sull'allineamento", 'kk': 'Нейрондық мәселен сөзді аударуName', 'mt': 'Neural Simultaneous Speech Translation Using Alignment-Based Chunking', 'lt': 'Neural Simultaneous Speech Translation Using Alignment-Based Chunking', 'ml': 'നെയുറല്\u200d സംസാരിക്കുന്ന സംസാര പരിഭാഷപ്പെടുത്തുക', 'ms': 'Terjemahan Ucapan Sementara Neural menggunakan pecahan berdasarkan Jajaran', 'pl': 'Tłumaczenie mowy jednoczesnej neuronowej za pomocą wyrównania opartego na wyrównaniu', 'no': 'Neuralt liknande taleomsetjing ved bruk av justeringsbasert bryting', 'ro': 'Traducerea vocală simultană neurală utilizând Chunking bazat pe aliniere', 'mn': 'Цахилгаан төстэй ярианы хөрөнгө', 'mk': 'Name', 'sr': 'Neuralno simultarno prevodenje govora korištenje isprave', 'ta': 'ஒழுங்குபடுத்தல் அடிப்படையான தொடர்பு மொழிபெயர்ப்பை பயன்படுத்து', 'so': 'Turjumista luqada islamarkaasna', 'si': 'සාමාන්\u200dය සාමාන්\u200dය භාවිතය', 'sv': 'Neural simultan talöversättning med hjälp av justeringsbaserad chunking', 'ur': 'نائورل سیمولٹرنی بات ترجمہ', 'uz': 'Name', 'vi': 'Dịch chuyển hoà thần kinh qua đường dòng', 'hr': 'Neuralno simultarno prevodenje govora korištenje mješavina na osnovu isprave', 'nl': 'Neurale Simultane Spraakvertaling met behulp van op uitlijning gebaseerde Chunking', 'bg': 'Невроден едновременен превод на речта чрез подравняване', 'id': 'Translation Speech Simultaneous Neural menggunakan bagian berdasarkan Alinjasi', 'ko': '정렬 블록 기반 신경 동기화 음성 번역', 'da': 'Neural simultan tale oversættelse ved hjælp af justeringsbaseret chunking', 'de': 'Neuronale Simultane Sprachübersetzung mithilfe von Alignment-Based Chunking', 'af': 'Name', 'fa': 'ترجمه سخنرانی شبیه\u200cای عصبی با استفاده از ترجمه\u200cهای پایه\u200cبندی', 'sw': 'Utafsiri wa Hotuba kwa wakati mmoja kwa kutumia Kuchunguza kwa Msimamo', 'hy': 'Նյարդային համաժամանակ խոսքի թարգմանություն՝ օգտագործելով հավասարման հիմնված բաժանմունք', 'az': 'N칬ral Sim칲l S칬zl칲k 칂evirm톛si', 'tr': 'Çaltylyk', 'bs': 'Neuralno simultarno prevodenje govora korištenje na osnovu isprave', 'sq': 'Përkthimi i Fjalës Neurale Simultane duke përdorur pjesë të bazuar në rregullim', 'am': 'Neural Simultaneous Speech Translation Using Alignment-Based Chunking', 'et': 'Neuraalne samaaegne kõne tõlkimine joonduspõhise tükkimise abil', 'cs': 'Neurální simultánní překlad řeči pomocí srovnání založeného na srovnání', 'ca': 'Traducció neurosimultànea de discurs utilitzant trossos basats en alliniament', 'fi': 'Neuraalisen samanaikaisen puheen kääntäminen tasauspohjaisen niputuksen avulla', 'bn': 'সামান্য ভাষার অনুবাদ', 'jv': 'tutorial_basic', 'sk': 'Živčni simultani prevod govora z uporabo poravnave na osnovi sestavljanja', 'he': 'Neural Simultaneous Speech Translation Using Alignment-Based Chunking', 'ha': '@ item Text character set', 'bo': 'སྔོ་སྒྲིག་བྱ་ཚིག་དང་སྦྲེལ་མཐུད་ལྟར་གཞུང་བའི་བཅད་ཀྱི་ཚིག་རྒྱུད'}
{'en': 'In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. The model is composed of two main components : one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. We train the components jointly and in a manner consistent with the inference conditions. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7 % BLEU absolute.', 'ar': 'في الترجمة الآلية المتزامنة ، الهدف هو تحديد وقت إنتاج ترجمة جزئية في ظل تدفق مستمر من الكلمات المصدر ، مع مفاضلة بين الكمون والجودة. نقترح نموذج ترجمة آلية عصبية (NMT) يتخذ قرارات ديناميكية عند مواصلة التغذية على المدخلات أو توليد كلمات الإخراج. يتكون النموذج من عنصرين رئيسيين: أحدهما لاتخاذ قرار ديناميكي بشأن إنهاء جزء المصدر ، والآخر يترجم الجزء المستهلَك. نقوم بتدريب المكونات بشكل مشترك وبطريقة تتوافق مع شروط الاستدلال. لإنشاء بيانات تدريب مقسمة ، نقترح طريقة تستخدم محاذاة الكلمات مع الحفاظ أيضًا على سياق كافٍ. نحن نقارن النماذج مع المشفرات ثنائية الاتجاه وأحادية الاتجاه بأعماق مختلفة ، سواء في الكلام الحقيقي أو إدخال النص. تفوقت نتائجنا في مهمة IWSLT 2020 من الإنجليزية إلى الألمانية على خط الأساس wait-k بنسبة 2.6 إلى 3.7٪ BLEU مطلق.', 'pt': 'Na tradução automática simultânea, o objetivo é determinar quando produzir uma tradução parcial dado um fluxo contínuo de palavras de origem, com um trade-off entre latência e qualidade. Propomos um modelo de tradução automática neural (NMT) que toma decisões dinâmicas quando continuar alimentando as palavras de entrada ou gerar palavras de saída. O modelo é composto por dois componentes principais: um para decidir dinamicamente sobre o fim de um trecho de origem e outro que traduz o trecho consumido. Treinamos os componentes em conjunto e de forma consistente com as condições de inferência. Para gerar dados de treinamento em partes, propomos um método que utiliza alinhamento de palavras e ao mesmo tempo preserva contexto suficiente. Comparamos modelos com codificadores bidirecionais e unidirecionais de diferentes profundidades, tanto na fala real quanto na entrada de texto. Nossos resultados na tarefa de inglês para alemão do IWSLT 2020 superam uma linha de base wait-k em 2,6 a 3,7% BLEU absoluto.', 'es': 'En la traducción automática simultánea, el objetivo es determinar cuándo producir una traducción parcial con un flujo continuo de palabras fuente, con un equilibrio entre latencia y calidad. Proponemos un modelo de traducción automática neuronal (NMT) que toma decisiones dinámicas sobre cuándo seguir alimentándose de palabras de entrada o generando palabras de salida. El modelo se compone de dos componentes principales: uno para decidir dinámicamente la finalización de un fragmento de origen y otro que traduce el fragmento consumido. Entrenamos los componentes de forma conjunta y coherente con las condiciones de inferencia. Para generar datos de entrenamiento fragmentados, proponemos un método que utiliza la alineación de palabras y, al mismo tiempo, preserva suficiente contexto. Comparamos modelos con codificadores bidireccionales y unidireccionales de diferentes profundidades, tanto en voz real como en entrada de texto. Nuestros resultados en la tarea de inglés a alemán de IWSLT 2020 superan una línea de base wait-k en un 2,6 a un 3,7% de BLEU absoluto.', 'fr': "Dans la traduction automatique simultanée, l'objectif est de déterminer quand produire une traduction partielle compte tenu d'un flux continu de mots sources, avec un compromis entre latence et qualité. Nous proposons un modèle de traduction automatique neuronale (NMT) qui prend des décisions dynamiques lorsqu'il faut continuer à se nourrir des mots d'entrée ou à générer des mots de sortie. Le modèle est composé de deux composants principaux\xa0: l'un pour décider dynamiquement de la fin d'un segment source, et l'autre pour traduire le segment consommé. Nous entraînons les composants conjointement et d'une manière cohérente avec les conditions d'inférence. Pour générer des données d'entraînement fragmentées, nous proposons une méthode qui utilise l'alignement des mots tout en préservant suffisamment de contexte. Nous comparons des modèles avec des encodeurs bidirectionnels et unidirectionnels de différentes profondeurs, à la fois sur la parole réelle et la saisie de texte. Nos résultats sur la tâche anglais-allemand IWSLT 2020 surpassent une valeur de référence attente-k de 2,6 à 3,7\xa0% en valeur absolue de l'UEBL.", 'ja': '同時機械翻訳では、遅延と品質の間のトレードオフを用いて、ソース単語の連続的なストリームを与えられた部分翻訳をいつ生成するかを決定することが目的です。私たちは、入力へのフィードを継続したり、出力単語を生成したりするときに動的な決定を下すニューラル機械翻訳（ NMT ）モデルを提案します。モデルは、ソースチャンクの終了を動的に決定するためのものと、消費されたチャンクを変換するためのものの2つの主要な構成要素で構成されています。推論条件に沿った方法で、コンポーネントを共同でトレーニングします。チャンクトレーニングデータを生成するために、十分なコンテキストを保持しながら、単語の整列を利用する方法を提案します。私たちは、実際の音声入力とテキスト入力の両方で、さまざまな深さの双方向エンコーダと一方向エンコーダとモデルを比較します。IWSLT 2020英語からドイツ語へのタスクの結果は、待機ベースラインを2.6 ～ 3.7 ％上回り、BLEUの絶対値を上回ります。', 'zh': '同声之传译,定于给定源词流,权于迟质之间。 我有一神经机器翻译(NMT)模,动有时输单词。 二主组件:一以动终源块,一以转耗。 吾以推理合练组件。 为生成分块训练数,建一利用单词齐之法,兼存足上下文。 吾等于语音与文本输上较有深度双向与单向编码器模样。 吾于IWSLT 2020英语德语,高于待k基线2.6%至于3.7%,BLEU绝对值也。', 'hi': 'एक साथ मशीन अनुवाद में, उद्देश्य यह निर्धारित करना है कि विलंबता और गुणवत्ता के बीच व्यापार-बंद के साथ स्रोत शब्दों की एक निरंतर धारा को देखते हुए आंशिक अनुवाद का उत्पादन कब किया जाए। हम एक तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल का प्रस्ताव करते हैं जो इनपुट पर खिलाना जारी रखने या आउटपुट शब्दों को उत्पन्न करने के लिए गतिशील निर्णय लेता है। मॉडल दो मुख्य घटकों से बना है: एक गतिशील रूप से एक स्रोत खंड को समाप्त करने पर निर्णय लेने के लिए, और दूसरा जो उपभोग किए गए हिस्से का अनुवाद करता है। हम घटकों को संयुक्त रूप से और अनुमान शर्तों के अनुरूप तरीके से प्रशिक्षित करते हैं। चंक्ड प्रशिक्षण डेटा उत्पन्न करने के लिए, हम एक ऐसी विधि का प्रस्ताव करते हैं जो शब्द संरेखण का उपयोग करती है, जबकि पर्याप्त संदर्भ को भी संरक्षित करती है। हम वास्तविक भाषण और पाठ इनपुट दोनों पर, विभिन्न गहराई के द्विदिश और यूनिडायरेक्शनल एन्कोडर के साथ मॉडल की तुलना करते हैं। IWSLT 2020 अंग्रेजी-से-जर्मन कार्य पर हमारे परिणाम 2.6 से 3.7% BLEU निरपेक्ष द्वारा एक प्रतीक्षा-k बेसलाइन से आगे निकल जाते हैं।', 'ru': 'При одновременном машинном переводе цель состоит в том, чтобы определить, когда производить частичный перевод, учитывая непрерывный поток исходных слов, с компромиссом между запаздыванием и качеством. Мы предлагаем модель нейронного машинного перевода (НМП), которая принимает динамические решения, когда продолжать питаться входными или генерировать выходные слова. Модель состоит из двух основных компонентов: один для динамического принятия решения о завершении исходного фрагмента, а другой для преобразования потребленного фрагмента. Мы обучаем компоненты совместно и в соответствии с условиями вывода. Для генерации фрагментированных обучающих данных мы предлагаем метод, который использует выравнивание слов, сохраняя при этом достаточный контекст. Мы сравниваем модели с двунаправленными и однонаправленными кодировщиками различной глубины, как по реальному речевому, так и по текстовому вводу. Наши результаты по английско-немецкой задаче IWSLT 2020 превосходят базовый уровень wait-k на 2,6-3,7% абсолютного BLEU.', 'ga': 'Maidir le haistriúchán comhuaineach meaisín, is é an cuspóir a chinneadh cathain is ceart aistriúchán páirteach a tháirgeadh i bhfianaise sruth leanúnach focal foinse, le comhbhabhtáil idir fholaigh agus cáilíocht. Molaimid múnla néaraistriúcháin meaisín (NMT) a dhéanann cinntí dinimiciúla cathain is ceart leanúint ar aghaidh ag beathú ar ionchur nó focail aschuir a ghiniúint. Tá an tsamhail comhdhéanta de dhá phríomhchuid: ceann amháin chun cinneadh a dhéanamh go dinimiciúil maidir le deireadh a chur le smután foinse, agus ceann eile a aistríonn an smután caite. Déanaimid na comhpháirteanna a oiliúint i gcomhpháirt agus ar bhealach a thagann leis na coinníollacha tátail. Chun sonraí oiliúna smuchta a ghiniúint, molaimid modh a úsáideann ailíniú focal agus a chaomhnaítear go leor comhthéacs freisin. Déanaimid comparáid idir samhlacha le ionchódóirí déthreocha agus aontreocha de dhoimhneachtaí éagsúla, ar fhíor-ionchur cainte agus téacs araon. Sáraíonn ár dtorthaí ar thasc Béarla-go-Gearmáinis IWSLT 2020 bunlíne feithimh 2.6 go 3.7% glan BLEU.', 'ka': 'ერთადერთი მანქანის გაგრძელებაში, მიზეზი არის განსაზღვრება, როდესაც წევრილი გაგრძელება, როდესაც განსაზღვრება მუშაობელი სიტყვების სიტყვების მსოფლიოს სიტყვების მს ჩვენ მივეღებთ ნეიროლური მაქინის გაგრძელება (NMT) მოდელი, რომელიც დინამიკური გადაწყვეტილება, როდესაც გაგრძელება ან გაგრძელება სიტყვების გაგრძელ მოდელის შექმნა ორი მნიშვნელოვანი კომპონენტებით: ერთი დინამიკურად განსაზღვრება წიგნის დასრულებაზე, და ერთი, რომელიც მომხმარებული წიგნის დასრულება. ჩვენ კომპონტენტები ერთად და სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა. ჩვენ შევქმნა კონტექსტური მონაცემები, რომელიც გამოყენებს სიტყვების დასწორება და კონტექსტური დასწორება. ჩვენ მოდელების შემდგენება განსხვავებული სიგრძნობის მედირექციონალური და ერთეთრექციონალური კოდირებით, რომელიც რეალური სიტყვის და ტექსტის შენახვაზე. ჩვენი წარმოდგენები IWSLT 2020-დან გერმანეთიდან გავაკეთებენ დასაწყებელი წარმოდგენების წარმოდგენება 2,6-3,7% BLEU-დან.', 'hu': 'Az egyidejű gépi fordításban a cél annak meghatározása, hogy mikor kell részleges fordítást készíteni folyamatos forrásszavakkal, a késleltetés és a minőség közötti kompromisszum mellett. Egy neurális gépi fordítási modellt (NMT) javasolunk, amely dinamikus döntéseket hoz, mikor kell folytatni a bemeneti táplálkozást vagy kimeneti szavakat generálni. A modell két fő összetevőből áll: az egyik dinamikusan dönt a forrás darab befejezéséről, a másik pedig az elfogyasztott darab lefordításáról. Az alkatrészeket közösen és a következtetési feltételekkel összhangban képezzük. Az összetett edzési adatok létrehozásához olyan módszert javaslunk, amely a szóigazítást használja, miközben elegendő kontextust is megőrzi. Különböző mélységű kétirányú és egyirányú kódolókkal hasonlítjuk össze a modelleket, mind valós beszéd, mind szövegbevitel esetén. Az IWSLT 2020 angol-német feladat eredményei 2,6-3,7%-kal felülmúlják a várakozás alapját.', 'kk': 'Бірақ компьютердің аудармасында мақсат керек көзінің сөздерінің бөлігін келтірілген аудармасын қазір жасау кезінде анықтауға болады. Біз невралдық компьютердің аудармасын (NMT) үлгісін ұсынамыз. Бұл енгізуге не шығыс сөздерді құру үшін динамикалық шешімдерді жасайды. Бұл үлгі екі негізгі компонентінен құрылады: бірінің динамикалық түрде көзінің бөлшегін аяқтау үшін, бірінің қолданылатын бөлшегін аяқтау үшін, бірінің бірінің бірінің бірін Біз компоненттерді біріктіріп, біріктіру шарттарына сәйкес келеді. Бөлек оқыту деректерін құру үшін, біз сөздерді түзету әдісін қолданатын, сондай-ақ жеткілікті контексті сақтау әдісін қолданатын. Біз үлгілерді басқа түрлі тереңдіктердің, шын сөйлеу мен мәтін келтіру үлгілерімен бір бағытты және бір бағытты кодерлерімен салыстырамыз. Біздің IWSLT 2020-германиялық ағылшын-неміс тапсырмасының нәтижесіміз 2,6-3,7% абсолютті күту-к негізгі жолын жасайды.', 'el': 'Στην ταυτόχρονη μηχανική μετάφραση, ο στόχος είναι να καθοριστεί πότε πρέπει να παραχθεί μια μερική μετάφραση δεδομένου μιας συνεχούς ροής λέξεων προέλευσης, με συμβιβασμό μεταξύ καθυστέρησης και ποιότητας. Προτείνουμε ένα μοντέλο νευρωνικής μηχανικής μετάφρασης (που παίρνει δυναμικές αποφάσεις πότε θα συνεχίσει να τροφοδοτείται από την εισαγωγή ή να παράγει λέξεις εξόδου. Το μοντέλο αποτελείται από δύο κύρια συστατικά: ένα για να αποφασίσει δυναμικά για το τέλος ενός κομματιού προέλευσης και ένα άλλο που μεταφράζει το καταναλωμένο κομμάτι. Εκπαιδεύουμε τα συστατικά από κοινού και με τρόπο σύμφωνο με τις συνθήκες συμπερασμάτων. Για να δημιουργήσετε συγκεντρωμένα δεδομένα εκπαίδευσης, προτείνουμε μια μέθοδο που χρησιμοποιεί ευθυγράμμιση λέξεων διατηρώντας παράλληλα επαρκές πλαίσιο. Συγκρίνουμε μοντέλα με αμφίδρομους και μονόδρομους κωδικοποιητές διαφορετικού βάθους, τόσο στην πραγματική ομιλία όσο και στην εισαγωγή κειμένου. Τα αποτελέσματά μας για την εργασία Αγγλικά-Γερμανικά 2020 ξεπερνούν μια γραμμή αναμονής-k κατά 2.6 έως 3.7% BLEU απόλυτο.', 'it': "Nella traduzione automatica simultanea, l'obiettivo è determinare quando produrre una traduzione parziale con un flusso continuo di parole sorgente, con un compromesso tra latenza e qualità. Proponiamo un modello di traduzione automatica neurale (NMT) che prende decisioni dinamiche quando continuare ad alimentarsi con input o generare parole di output. Il modello è composto da due componenti principali: uno per decidere dinamicamente di terminare un pezzo sorgente, e un altro che traduce il pezzo consumato. Alleniamo i componenti congiuntamente e in modo coerente con le condizioni di inferenza. Per generare dati di allenamento raggruppati, proponiamo un metodo che utilizza l'allineamento delle parole preservando al contempo un contesto sufficiente. Confrontiamo modelli con encoder bidirezionali e unidirezionali di diverse profondità, sia sul parlato reale che sull'input di testo. I nostri risultati sull'attività inglese-tedesca IWSLT 2020 superano la base di attesa del 2,6-3,7% BLEU assoluto.", 'lt': 'Tuo pačiu metu vertant mašiną siekiama nustatyti, kada gaminti dalinį vertimą, kuriame pateikiamas nuolatinis šaltinio žodžių srautas, kompensuojant latenciją ir kokybę. Mes siūlome nervinį mašinų vertimo (NMT) model į, kuris priima dinamiškus sprendimus, kada toliau maitintis iš įvesties arba generuoti išėjimo žodžius. Modelį sudaro du pagrindiniai komponentai: vienas, kuris dinamiškai nusprendžia nutraukti šaltinio dalį, o kitas, kuris verta suvartotą dalį. Sudedamosios dalys mokomos kartu ir laikantis išvados sąlygų. Kad būtų sukurti daliniai mokymo duomenys, siūlome metodą, kuriuo būtų naudojamas žodžių suderinimas ir kartu išsaugotas pakankamas kontekstas. Palyginame modelius su skirtingų gilumų dvikryptiniais ir vienakryptiniais kodatoriais, tiek iš tikrųjų kalbos, tiek iš teksto. Mūsų rezultatai dėl IWSLT 2020 anglų–vokiečių užduoties viršija laukimo k bazę 2,6–3,7 proc. BLEU absoliučiu.', 'ms': 'In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality.  We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words.  Model terdiri dari dua komponen utama: satu untuk memutuskan secara dinamik untuk mengakhiri potongan sumber, dan satu lagi yang menerjemahkan potongan yang dikonsumsi. Kami melatih komponen bersama-sama dan dengan cara yang konsisten dengan syarat kesimpulan. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  Kami membandingkan model dengan pengekod bidireksi dan tidak direksi dengan kedalaman yang berbeza, kedua-dua pada ucapan sebenar dan input teks. Keputusan kita pada IWSLT 2020 tugas Inggeris-Jerman melebihi dasar tunggu-k dengan 2.6 hingga 3.7% absolut BLEU.', 'mt': 'In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality.  Aħna nipproponu mudell ta’ traduzzjoni tal-magni newrali (NMT) li jieħu deċiżjonijiet dinamiċi meta nkomplu nitgħallmu fuq input jew jiġġeneraw kliem ta’ output. Il-mudell huwa magħmul minn żewġ komponenti ewlenin: wieħed biex jiddeċiedi b’mod dinamiku dwar it-tmiem ta’ biċċa mis-sors, u ieħor li jittraduċi biċċa mill-konsum. Aħna nħarrġu l-komponenti b’mod konġunt u b’mod konsistenti mal-kundizzjonijiet ta’ inferenza. Biex niġġeneraw dejta ta’ taħriġ maqsuma, nipproponu metodu li juża l-allinjament tal-kliem filwaqt li nippreservaw ukoll kuntest biżżejjed. Aħna nqabblu mudelli ma’ kodifikaturi bidirezzjonali u unidirezzjonali ta’ fond differenti, kemm fuq diskors reali kif ukoll fuq input tat-test. Ir-riżultati tagħna dwar il-kompitu bejn l-Ingliż u l-Ġermaniż tal-IWSLT 2020 jaqbżu l-linja bażi ta’ stennija-k b’2.6 sa 3.7% assolut tal-BLEU.', 'mn': 'Гэвч машины хөрөнгө оруулалт, зорилго нь хэзээ нэг хэсэг хөрөнгө оруулалт гаргах вэ гэдгийг тодорхойлдог. Бид мэдрэлийн машины хөгжлийн загвар (NMT) загварыг санал болгож өгөх эсвэл үргэлжлүүлэх үгийг гаргадаг. Энэ загвар нь хоёр чухал хэсэгт бүрдсэн: нэг нь эх үүсвэрийн хэсэгт дуусахыг шийдвэрлэх, бас нэг нь хэрэглэгдсэн хэсэгт орлуулдаг. Бид эдгээр компонентуудыг хамтдаа, халдварын нөхцөлтэй холбоотой аргаар суралцаж байна. Бүгдээрээ дасгал хөдөлгөөн өгөгдлийг бий болгохын тулд бид өөрсдийгөө хангалттай нөхцөл байдлыг хадгалах арга зааж өгдөг. Бид загваруудыг өөр гүн гүнзгий, жинхэнэ яриа болон текст өгөгдлийн хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо харьцуулдаг. Бидний IWSLT 2020-н Англи-Герман даалгаварын үр дүнд хүлээн зөвшөөрөгдсөн 2.6-3.7% BLEU-н бүтээгдэхүүнийг хийдэг.', 'ml': 'ഒരേ സമയത്ത് മെഷീന്\u200d പരിഭാഷയില്\u200d, നിലനില്\u200dക്കുന്ന സോര്\u200dസ് വാക്കുകളുടെ നദിയില്\u200d കൊടുക്കുന്ന പാതിക വിഭാഗത്തിന്റെ വാക്കുകള്\u200d ഉല ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ (NMT) മോഡല്\u200d നാം പ്രൊദാനം ചെയ്യുന്നു. അത് ഇന്\u200dപുട്ടില്\u200d ഭക്ഷണം തുടരുമ്പോഴോ പുറത്ത് വാക്കുകള്\u200d  ഈ മോഡല്\u200d രണ്ടു പ്രധാന ഘടകങ്ങളില്\u200d ഉണ്ടാക്കിയിരിക്കുന്നു; ഒരാള്\u200d നിര്\u200dമ്മിക്കാന്\u200d ഒരു സോര്\u200dസ്സ് ചുങ്ക് അവസാനിപ്പിക്കു നമ്മള്\u200d കൂട്ടത്തില്\u200d പഠിപ്പിക്കുന്ന സാധനങ്ങള്\u200d ഒരുമിച്ചും ദുര്\u200dബലമുള്ള അവസ്ഥയോടൊപ്പമാണ്. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  വ്യത്യസ്തമായ ആഴത്തിന്റെ ആഴത്തിന്റെ കൂട്ടത്തില്\u200d നിന്നും വ്യത്യസ്ത വാക്കിന്റെയും ടെക്സ്റ്റ് ഇന്\u200dപുട്ട IWSLT 2020 ഇംഗ്ലീഷ്-മുതല്\u200d ജര്\u200dമ്മന്\u200d ജോലിക്കാരുടെ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മുടെ ഫലങ്ങള്\u200d 2.6 വരെ 3.7% ബെല്ലൂ മുഴുവനായി ഒരു കാത്ത', 'mk': 'Во истовремениот машински превод, целта е да се одреди кога да се произведува делумен превод со континуиран поток на изворни зборови, со разлика помеѓу ланценоста и квалитетот. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words.  Моделот е составен од два главни компоненти: една за динамично одлучување за завршување на делот од изворот, а друга за преведување на конзумираниот дел. We train the components jointly and in a manner consistent with the inference conditions.  To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  Нашите резултати на ИВСЛТ 2020 англиска-германска задача го надминуваат базата на чекање за 2,6 до 3,7 отсто БЛЕ апсолутно.', 'ro': 'În traducerea automată simultană, obiectivul este de a determina momentul în care se produce o traducere parțială dată de un flux continuu de cuvinte sursă, cu un compromis între latență și calitate. Propunem un model de traducere automată neurală (NMT) care ia decizii dinamice atunci când să continue alimentarea cu intrarea sau generarea cuvintelor de ieșire. Modelul este compus din două componente principale: una pentru a decide dinamic despre terminarea unei bucăți sursă, și alta care traduce bucățile consumate. Antrenăm componentele împreună și într-un mod în concordanță cu condițiile de inferență. Pentru a genera date de antrenament în ansamblu, propunem o metodă care utilizează alinierea cuvintelor, păstrând, de asemenea, suficient context. Comparăm modelele cu codificatoare bidirecționale și unidirecționale de diferite adâncimi, atât pe vorbire reală, cât și pe introducerea textului. Rezultatele noastre privind activitatea IWSLT 2020 din limba engleză în germană depășesc nivelul de referință al așteptării cu 2,6 până la 3,7% absolut BLEU.', 'pl': 'W symultanicznym tłumaczeniu maszynowym celem jest określenie, kiedy należy wykonać tłumaczenie częściowe, biorąc pod uwagę ciągły strumień słów źródłowych, z kompromisem między opóźnieniem a jakością. Proponujemy model neuronowego tłumaczenia maszynowego (NMT), który podejmuje dynamiczne decyzje, kiedy kontynuować karmienie się wejściem lub generować wyjściowe słowa. Model składa się z dwóch głównych składników: jednego, który dynamicznie decyduje o zakończeniu fragmentu źródłowego, a drugiego, który tłumaczy zużyty fragment. Szkolimy komponenty wspólnie i w sposób zgodny z warunkami wnioskowania. Aby generować zbudowane dane treningowe, proponujemy metodę, która wykorzystuje wyrównanie słów przy jednoczesnym zachowaniu wystarczającej ilości kontekstu. Porównujemy modele z koderami dwukierunkowymi i jednokierunkowymi o różnej głębokości, zarówno na rzeczywistym wejściu mowy, jak i tekstu. Nasze wyniki dotyczące zadania IWSLT 2020 angielsko-niemieckiego przewyższają wartość wyjściową oczekiwania o 2,6 do 3,7% BLEU absolutnego.', 'no': 'I samtidig maskineoversettelse er målet å bestemme når ein delvis oversettelse skal opprettast eit kontinuerleg kjeldeord, med eit utvikling mellom latens og kvalitet. Vi foreslår eit neuralmaskinsomsetjingsmodul (NMT) som gjer dynamiske beslutningar når du fortsetter å køyra inn eller laga utdata- ord. Modellen er lagt av to hovudkomponentar: ein som dynamisk bestemmer om å slutta ein kjeldepunkt, og ein annan som oversetter den brukte delen. Vi treng komponentane saman og på ein måte saman med infeksjonsverdiane. For å laga fleire opplæringsdata, fører vi ein metode som brukar ordjustering medan også lagrar nok kontekst. Vi samanliknar modeller med bidireksjonale og unidireksjonale kodar med ulike dybde, både på verkeleg tale og tekstinndata. Resultatet våre på oppgåva IWSLT 2020 utfører ein vent-k baseline med 2,6 til 3,7 % absolutt BLEU.', 'sr': 'U istovremenom prevodu mašine, cilj je određivati kada proizvesti deolni prevod s obzirom na kontinuirani potok izvornih riječi, sa trgovinom između latencije i kvalitete. Predlažemo modelu neuronskog prevoda mašine (NMT), koji donosi dinamične odluke kada nastavimo hraniti ulaz ili proizvoditi izlazne reči. Model se sastoji od dve glavne komponente: jedan da dinamički odluči da završi izvorni komad, a drugi koji prevodi konzumiran komad. Uèinjemo komponente zajedno i na način koji odgovara uvjetima infekcije. Da bi stvorili pokvarene podatke o obuci, predlažemo metodu koja koristi prilagodbu reèi i saèuvajući dovoljno konteksta. Uspoređujemo modele sa dvodirektivnim i jednodirektivnim koderima različitih dubina, i pravim govorom i tekstom. Naši rezultati na zadatku IWSLT 2020-a engleski do njemački iznose početnu liniju čekanja od 2,6 do 3,7% absolutnog BLEU-a.', 'si': 'එකම මෙෂින් පරිවර්තනයෙන්, අරමුණය තමයි කොයි වෙලාවක් නිර්මාණය කරන්න තියෙන්නේ කොයි වෙලාවක් තියෙන්නේ මුළු වචන වචන ව අපි න්\u200dයුරෝල් මැෂින් වාර්තාව (NMT) මොඩේල් එකක් ප්\u200dරයෝජනය කරනවා, ඒකෙන් වාර්තාවික තීරණය කරනවා කියලා ඇතුළ මොඩල් එක ප්\u200dරධාන අංශ දෙකක් නිර්මාණය කරලා තියෙනවා: මුළු ප්\u200dරධාන අංශයක් අවසානය කරලා තීරණය කරනවා, සහ අංශ අපි සම්බන්ධයෙන් කොටස් එක්ක සහ ප්\u200dරශ්නයක් සම්බන්ධයෙන් ප්\u200dරශ්නය කරනවා. චැන්ක් ප්\u200dරධාන දත්ත නිර්මාණය කරන්න, අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා වචන සම්බන්ධයක් ප්\u200dරයෝජනය කරන්න. අපි මොඩේල්ස් එක්ක සම්පූර්ණය කරන්නේ වෙනස් ගොඩතුරක් සහ එක්කෙනෙක් ප්\u200dරමාණය සඳහා, ඇත්ත කතාවය සහ පාළුවක්  අපේ ප්\u200dරතිචාරය IWSLT 2020ට ඉංග්\u200dරීසියෙන් ජර්මන් වැඩේ ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් වෙන්නේ ප්\u200dරති', 'so': "Turjumista machine islamarkaasna waxaa lagu qoraa goorma la soo saaro tarjumaadda qeybta ah ee la siiyey durdur joogtada ah oo erayo source ah, waxaana ku qoran baayacmushtarinta u dhexeeya dhamaanta iyo tayada. Tusaale tarjumaadda maskaxda neurada ah (NMT) oo sameeya go'aano dhaqdhaqaaqa marka lagu quudiyo input ama soo saaro hadal soo baxa. Tusaalada waxaa ka mid ah laba qeybood oo muhiim ah: mid si farxad ah ayaa ku go’aansada dhamaadka noocyada, mid kalena waxaa ku qoran tarjuma cuntada cuntada. Waxaannu ku tababarinnaa qeybaha si wada jir ah iyo si ku haboon xaaladaha cudurka. Si aan u sameyno macluumaadka waxbarashada, waxaynu u soo jeedaynaa qaab u isticmaalaya isbedelka hadalka marka xittaa lagu ilaaliyo mukhtarka ku filan. Tusaale ahaan ayaannu isbarbardhignaa noocyada caadiga ah ee moolka kala duduwan, oo ku qoran hadalka runta ah iyo qoraalka. Fashihiisa IWSLT 2020 Ingiriis-to-German-outoutoutoutay wait-k baseline by 2.6 to 3.7% BLEU absolute.", 'ur': 'ایک دوسرے ماشین کی ترجمہ میں، موضوع یہ ہے کہ ایک حصہ کی ترجمہ کس وقت پیدا کرنا ہے جبکہ اسورس لفظ کا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھا سیدھ ہم ایک نئورل ماشین ترجمہ (NMT) موڈل کو پیشنهاد کرتے ہیں کہ جب انپیٹ پر غذا ادامه کریں یا آوٹ ورڈ پیدا کریں تو ڈینامیک تصمیم کرتا ہے۔ Model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. ہم عناصروں کو ایک ساتھ اور ایک طریقہ سے تعلیم دیتے ہیں جو کمزور شرایط کے مطابق قائم ہیں۔ چانک ٹرینگ ڈیٹا پیدا کرنے کے لئے، ہم ایک طریقہ پیشنهاد کرتے ہیں جو کلمات متصلہ کا استعمال کرتا ہے اور کافی متصلہ حفاظت کرتا ہے۔ ہم مدلکوں کو دوسری طرح کی اور ایک طرح کی ایک دوسری طرح کے اندھیروں کے مطابق مطابق دیتے ہیں، دونوں حقیقی باتوں اور پیغام کے مطابق. ہمارے نتیجے IWSLT 2020 میں انگلیسی سے جرمن کے کام سے 2.6 تا 3.7% بلیوس کی مطلق سے وایٹ-ک بنیس لین سے کام لیتے ہیں۔', 'ta': 'ஒரே நேரத்தில் இயந்திர மொழிபெயர்ப்பில், பாகம் மொழிமாற்று கொடுக்கப்பட்ட மூலசொல்களின் தொடர்ந்து தொடர்ந்து தொடர்ந்து வரையறுக்கப நாம் ஒரு புதிய இயந்திர மொழிபெயர்ப்பு( NMT) மாதிரி பரிந்துரைக்கிறோம். அது உள்ளீடு உணவு அல்லது வெளியீட்டு வார்த்தைகள The model is composed of two main components: one to dynamically decide on the end of a source chunk, and another that translates the consumed chunk. நாம் ஒருங்கிணைக்கப்பட்ட பொருள்களை பயிற்சி செய்கிறோம் மற்றும் நோய் நிலைமைகளுடன் பொருத்தும் வழிய To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  நாம் மாதிரிகளை ஒப்பிடுகிறோம் வேறு ஆழத்தின் மாதிரியான மற்றும் தனித்திசையான குறியீடுகளை வெவ்வேறு ஆழ IWSLT 2020 ஆங்கிலத்தில் இருந்து ஜெர்மன் பணியின் முடிவுகள் 2. 6 அடுத்தளத்தில் இருந்து 3. 7% BLEU முழுமையாக செயல்படுத்துகிறது.', 'sv': 'Vid simultan maskinöversättning är syftet att avgöra när en partiell översättning ska produceras med en kontinuerlig ström av källord, med en avvägning mellan latens och kvalitet. Vi föreslår en neural maskinöversättning (NMT) modell som fattar dynamiska beslut när man ska fortsätta mata på input eller generera output ord. Modellen består av två huvudkomponenter: en för att dynamiskt bestämma sig för att avsluta en källbit, och en annan som översätter den förbrukade biten. Vi tränar komponenterna gemensamt och på ett sätt som överensstämmer med inferensvillkoren. För att generera chunked träningsdata föreslår vi en metod som använder ordjustering och samtidigt bevarar tillräckligt med sammanhang. Vi jämför modeller med tvåriktade och enkelriktade kodare av olika djup, både på tal och textinmatning. Våra resultat på IWSLT 2020 engelsk-till-tysk uppgift överträffar en vänt-k baslinje med 2,6 till 3,7% BLEU absolut.', 'uz': "Name Biz tarjima qilayotgan neyrolik tarjima modeli (NMT) davom etishda yoki chiqarish soʻzlarini davom etishda dynamik xususiyatlarni bajariladi. The model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk.  Biz komponentlarni birlashtirishni va muvaffaqiyatlarni birlashtirishni o'rganamiz. Taʼminlovchi maʼlumotni yaratish uchun, biz soʻzni tekislash va xizmatni saqlash imkoniyatini ishlatish mumkin. Biz modellarni boshqa qo'llangan va bir xil kodlash qoidalariga kamaytirimiz, haqiqiqiy gapiruvchi va matn ichida. IWSLT 2020 Inglizcha-Olmoncha vazifaning natijalarimiz 2.6 dan 3.7% BLEU imkoniyati bilan kutib chiqaradi.", 'vi': 'Trong việc dịch chuyển bằng máy đồng thời, mục đích là xác định khi nào thì phải thực hiện một phần dịch chuyển cho một dòng chữ nguồn liên tục, với một sự trao đổi giữa tiềm năng và chất lượng. Chúng tôi đề xuất một mô hình dịch cỗ máy thần kinh (NMB) mà thực hiện quyết định động khi nào thì tiếp tục cung cấp năng lượng hay tạo ra từ xuất. Mô hình được tạo ra bởi hai thành phần chính: một thành phần sẽ quyết định một cách động lực kết thúc một phần nguồn, và một thành phần chuyển cục phân hủy đoạn đã dùng. Chúng tôi huấn luyện các thành phần cùng nhau và theo một cách phù hợp với các điều kiện có hậu quả. Để tạo dữ liệu huấn luyện theo khúc kĩ, chúng tôi đề xuất một phương pháp sử dụng việc chỉnh các từ trong khi còn giữ được bối cảnh. Chúng tôi so sánh các mô hình với mã số trực tiếp và trung tâm của chiều sâu khác nhau, cả trong ngôn ngữ và nhập văn bản. Kết quả của chúng tôi về công việc I.WSLT 2020 Name-Đư-Anh-gọi-Đức đã hoàn thành một đường cơ sở đợi-k theo 2.6-3.7 vi. Tại Tại sao phải hoàn hảo.', 'nl': 'Bij simultane machinevertaling is het doel om te bepalen wanneer een gedeeltelijke vertaling moet worden geproduceerd met een continue stroom bronwoorden, met een compromis tussen latentie en kwaliteit. We stellen een neural machine translation (NMT) model voor dat dynamische beslissingen neemt wanneer je doorgaat met voeden van invoer of outputwoorden genereert. Het model bestaat uit twee hoofdcomponenten: een om dynamisch te beslissen over het beëindigen van een bronchunk, en een andere die de verbruikte chunk vertaalt. We trainen de componenten gezamenlijk en op een manier die in overeenstemming is met de conclusievoorwaarden. Om chunked trainingsgegevens te genereren, stellen we een methode voor die gebruik maakt van woorduitlijning en tegelijkertijd voldoende context behoudt. We vergelijken modellen met bidirectionele en unidirectionele encoders van verschillende dieptes, zowel op echte spraak- als tekstinvoer. Onze resultaten op de IWSLT 2020 Engels-Duitse taak overtreffen een wait-k baseline met 2,6 tot 3,7% BLEU absolute.', 'da': 'Ved simultan maskinoversættelse er formålet at afgøre, hvornår en delvis oversættelse skal fremstilles ved hjælp af en kontinuerlig strøm af kildeord med en afvejning mellem latens og kvalitet. Vi foreslår en neural maskinoversættelsesmodel (NMT), der træffer dynamiske beslutninger, hvornår man skal fortsætte med at fodre input eller generere output ord. Modellen består af to hovedkomponenter: en til dynamisk beslutning om at afslutte en kilde chunk, og en anden, der oversætter den forbrugte chunk. Vi træner komponenterne i fællesskab og på en måde, der er i overensstemmelse med inference betingelserne. For at generere chunked træningsdata foreslår vi en metode, der bruger ordjustering, samtidig med at der bevares nok kontekst. Vi sammenligner modeller med to- og ensrettede encodere af forskellige dybder, både på reel tale og tekst input. Vores resultater på IWSLT 2020 engelsk-til-tysk opgave overgår en wait-k basislinje med 2,6 til 3,7% BLEU absolut.', 'de': 'Bei der maschinellen Simultanübersetzung geht es darum, festzustellen, wann eine Teilübersetzung mit einem kontinuierlichen Quellwortstrom erzeugt werden muss, wobei Latenz und Qualität miteinander in Einklang stehen. Wir schlagen ein neuronales maschinelles Übersetzungsmodell (NMT) vor, das dynamische Entscheidungen trifft, wann die Eingabe fortgesetzt oder die Ausgabe von Wörtern generiert werden soll. Das Modell besteht aus zwei Hauptkomponenten: einer zur dynamischen Entscheidung über das Beenden eines Quellstücks und einer anderen, die den verbrauchten Chunk übersetzt. Wir schulen die Komponenten gemeinsam und in Übereinstimmung mit den Schlussfolgerungsbedingungen. Um Chunked Trainingsdaten zu generieren, schlagen wir eine Methode vor, die Wortausrichtung nutzt und gleichzeitig genügend Kontext beibehält. Wir vergleichen Modelle mit bidirektionalen und unidirektionalen Encodern unterschiedlicher Tiefe, sowohl auf realer Sprach- als auch auf Texteingabe. Unsere Ergebnisse der IWSLT 2020 Englisch-Deutsch-Aufgabe übertreffen eine Wait-k-Baseline um 2,6 bis 3,7% BLEU Absolut.', 'bg': 'При едновременния машинен превод целта е да се определи кога да се произведе частичен превод при непрекъснат поток от изходни думи, с компромис между латентност и качество. Предлагаме модел на невронен машинен превод (НМТ), който взема динамични решения кога да продължим да се храним с входни или генерираме изходни думи. Моделът се състои от два основни компонента: един за динамично решаване на края на източника, и друг, който превежда консумираното парче. Обучаваме компонентите съвместно и по начин, съобразен с условията на заключение. За да генерираме данни за обучение, предлагаме метод, който използва подравняване на думите, като същевременно запазва достатъчно контекст. Сравняваме модели с двупосочни и еднопосочни кодери с различна дълбочина, както на реална реч, така и на въвеждане на текст. Нашите резултати по английско-германската задача превъзхождат базовата база с 2,6 до 3,7% абсолютно.', 'id': 'Dalam terjemahan mesin simultan, tujuan adalah untuk menentukan kapan untuk menghasilkan terjemahan parsial diberikan aliran terus menerus kata sumber, dengan perdagangan antara latensi dan kualitas. Kami mengusulkan model terjemahan mesin saraf (NMT) yang membuat keputusan dinamik ketika melanjutkan makan pada input atau menghasilkan kata-kata output. Model ini terdiri dari dua komponen utama: satu untuk memutuskan secara dinamik untuk mengakhiri sepotong sumber, dan satu lagi yang menerjemahkan sepotong yang dikonsumsi. Kita melatih komponen bersama-sama dan dengan cara yang konsisten dengan kondisi kesimpulan. Untuk menghasilkan data latihan terpotong, kami mengusulkan metode yang menggunakan penyesuaian kata sambil juga memelihara konteks yang cukup. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  Hasil kami pada IWSLT 2020 tugas Inggris-Jerman melebihi dasar tunggu-k dengan 2,6 hingga 3,7% BLEU absolut.', 'sw': 'Katika tafsiri ya mashine wakati huo huo, lengo la kuamua lini kutangaza tafsiri ya sehemu iliyotolewa na mto wa maneno yanayoendelea, na upatikanaji wa biashara kati ya ubora na ubora. Tunazipendekeza mfumo wa kutafsiri mashine ya ubongo (NMT) unaofanya maamuzi yanayobadilika wakati wa kuendelea kulisha kwenye input au kutengeneza maneno ya uzalishaji. Mfano huu umetengenezwa na vifaa viwili vikuu: moja kwa moja linaamua kwa nguvu kuamua kumaliza kichwa cha chanzo, na mwingine kinachotafsiri kichwa kinachotumiwa. Tunafundisha vifaa vya pamoja na kwa namna inayofanana na hali ya ugonjwa. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  Matokeo yetu kwenye kazi ya IWSLT 2020 kwa Kiingereza-hadi Ujerumani yanafanya kazi ya kusubiri kwa asilimia 2.6 hadi 3.7 BLEU.', 'ko': '동기화 기계 번역에서 목표는 연속된 원어 흐름을 정한 상황에서 언제 부분 번역을 생성하고 지연과 품질 사이를 평가하는 것이다.우리는 언제 계속 입력하거나 출력 단어를 생성할지 동적으로 결정할 수 있는 신경기계번역(NMT) 모델을 제시했다.이 모델은 두 개의 주요 구성 요소로 구성되어 있는데 하나는 동적 결정 원본 블록의 끝이고 다른 하나는 소모된 블록을 변환하는 데 사용된다.우리는 추리 조건과 일치하는 방식으로 조립품을 연합하여 훈련한다.블록을 나누는 훈련 데이터를 만들기 위해 우리는 단어를 맞추는 방법을 제시했고 충분한 상하문도 보존했다.우리는 실제 음성과 텍스트 입력을 포함한 서로 다른 깊이의 양방향과 단방향 인코더 모델을 비교했다.2020년까지 우리의 영어 학습 성적은 6.2%의 절대 성적으로 국제여대를 앞질 것이다.', 'tr': 'Meýdança maşynyň terjimelerinde, maksady bolsa çeşme sözleriniň daýatmagy üçin nähili terjime edilmeli, latensiýa we kwalitet arasynda terjime edilmeli. Biz näyral maşynyň terjimesini (NMT) nusgasyna görä dinamik kararlar beren nusgasyna dowam edýäris. Bu nusga iki esasy komponentäň içine ýazylýar: biri dinamik bir çeşme parçasyny soňlamak üçin karar bermek üçin, we consumen parçasyny terjime eden başga bir nusga. Biz bölekleri bir arada we a şyk çykyş şertleri bilen bir şekilde öwredýäris. Çaklanmış eğitim maglumaty döretmek üçin, söz çyzygyny hem ýeterlik konteksti saýlamak üçin bir yöntem teklip edip bilýäris. Biz nusgalary iki görnöşim we bir görnöşim ködlemeleri farklı derinliklerinde, hem gerçek söz hem metin girişinde karşılaştyrýarys. IWSLT 2020-nji ýylda iňlisçe-nemesçe zadymyzyň netijesi 2,6-3,7% BLEU boýunça garaşyp çykýar.', 'fa': 'در ترجمه\u200cهای ماشین همزمان، هدف این است که تعریف کردن یک ترجمه بخشی که به یک رودخانه\u200cی کلمات منبع ادامه داده می\u200cشود، با یک تجارت بین کناره و کیفیت. ما یک مدل ترجمه ماشین عصبی (NMT) را پیشنهاد می\u200cکنیم که تصمیم\u200cگیری\u200cهای دینامیک را می\u200cگیرد زمانی که ادامه دادن به ورودی یا تولید کلمات خروجی را ادامه دهیم. این مدل از دو عنصر اصلی ساخته شده است: یکی که به طور طبیعی تصمیم بگیرد در پایان یک قطعه منبع و دیگری که قطعه مصرف شده را ترجمه می کند. ما بخش ها را با هم آموزش می کنیم و به طریقی که با شرایط آلودگی موجود است. برای تولید داده\u200cهای آموزش قطعه\u200cای، یک روش پیشنهاد می\u200cکنیم که استفاده می\u200cکند تنظیم کلمات در حالی که همچنین محافظت به اندازه کافی محافظت می\u200cکند. ما مدل\u200cها را با رمز\u200cکننده\u200cهای دور و یک مسیر متفاوت از عمق\u200cهای متفاوت مقایسه می\u200cکنیم، هر دو بر گفتار واقعی و وارد متن. نتایج ما در کار انگلیسی و آلمانی IWSLT 2020 به عنوان پایین\u200cپایین\u200cک ۲.۶ تا ۳.۷ درصد BLEU بالاتر است.', 'sq': 'Në përkthimin e njëkohëshëm të makinave, objektivi është të përcaktohet kur të prodhohet një përkthimi i pjesshëm i dhënë një rrjedhë të vazhdueshme fjalësh burimi, me një kompromis midis vonesës dhe cilësisë. Ne propozojmë një model të përkthimit nervor të makinave (NMT) që merr vendime dinamike kur të vazhdojë të ushqehet me input ose të gjenerojë fjalë të daljes. Modeli përbëhet nga dy komponente kryesore: një për të vendosur dinamikisht mbi përfundimin e një pjese burimi dhe një tjetër që përkthen pjesën e konsumuar. Ne i trajnojmë komponentet së bashku dhe në një mënyrë të konsistente me kushtet e përfundimit. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7% BLEU absolute.', 'am': 'በተሰነጠቀው መሳሳይ ትርጓሜ፣ አካባቢው በቁጥጥር እና በጥቅረት እና በጥያቄ እና በጥያቄ መካከለኛ የተሰጠውን የአካል ትርጓሜዎችን መግለጫ ማድረግ ነው፡፡ የናቡር መሣሪያን ትርጉም (NMT) ሞዴል በመጠበቅ ወይም የውጤት ቃላትን በመጠቀም ጊዜ የሚያስተባብል ጥያቄዎችን የሚያደርጋል፡፡ ምሳሌው ሁለት ዋናው ክፍሎች ተካክሎአል፤ አንዱ በኩል ጉዳዩን ለመፈጸም እና አንዱ የተበላውን ጉዳይ ለመፈጸም የሚወሰድ ነው፡፡ አካባቢዎቹን በአንድነት እና በጥቃት ሁኔታ እናስተማራለን፡፡ የድምፅ ማህበረሰብ ዳታ ለመፍጠር፣ የቃላትን መቀናቀል እናስጠጋለን እና በጠቅላላ አስተካክል ለማስቀመጥ እናስፈልጋለን፡፡ እናሳውቃለን፡፡ Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7% BLEU absolute.', 'az': 'Əvvəlcə maşın çevirində, məqsəd, uzaq və keyfiyyət arasındakı alış-veriş ilə müəyyən bir çeviri nə vaxt yaratmaq istəyir. Biz nöral maşın çevirimi (NMT) modelini təbliğ edirik ki, nə vaxt içərisində yemək və ya çıxış sözlərini ürəkləndirmək üçün dinamik kararlar verir. Model iki ana komponentdən oluşur: birini dinamik olaraq mənbə parçasını bitirmək üçün karar vermək üçün, və birini istifadə edən parçasını dəyişdirən. Biz komponentləri birlikdə və a şağılıq şərtlərinə uyğun bir yolla təhsil edirik. Bütün təhsil məlumatları yaratmaq üçün, sözlərin təhsil edilməsini istifadə edən bir metod təklif edirik. Biz modelləri müxtəlif derinliklərin, həqiqət sözlərin və metin girişində iki tərəfli və bir tərəfli kodlayıcıyla salırıq. IWSLT 2020-də İngilizə-Almanca işlərinin sonuçlarımız 2,6-3,7 % BLEU absolutu bir wait-k səhifəsindən üstün olur.', 'hy': 'Միևնույն մեքենայի թարգմանման ժամանակ նպատակը նպատակն է որոշել, թե երբ ստեղծել մասամբ թարգմանություն, որը պարունակում է անընդհատ աղբյուր բառերի հոսք, լանվածության և որակի միջև փոխազդեցություն: Մենք առաջարկում ենք նյարդային մեքենայի թարգմանման (NMT) մոդել, որը դինամիկ որոշումներ է կայացնում, երբ շարունակել կերակրել մուտք գործող կամ արտադրող բառերը: Մոդելը կազմված է երկու հիմնական բաղադրիչներից. մեկը դինամիկ որոշում է վերջացնել աղբյուրի մասը, իսկ մյուսը՝ թարգմանում է սպառված մասը: Մենք միասին ուսուցանում ենք բաղադրիչները, որոնք համապատասխանում են եզրակացության պայմաններին: To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  Մենք համեմատում ենք մոդելները տարբեր խորության երկու ուղղությամբ և միաուղղությամբ կոդերների հետ, ինչպես իրական խոսքի, ինչպես նաև տեքստի ներմուծների վրա: Անգլերեն-գերմանացի IwPLT 2020-ի առաջադրանքի արդյունքները 2.6-3.7 տոկոսով գերակշռում են սպասելիք-k հիմքը:', 'bs': 'U istovremenom prevodu mašine, cilj je utvrditi kada proizvesti djelomičan prevod s obzirom na neprestano potok izvornih riječi, sa trgovinom između latencije i kvalitete. Predlažemo modelu prevoda neuronskih strojeva (NMT), koji donosi dinamične odluke kada nastaviti hraniti ulaz ili proizvoditi izlazne riječi. Model se sastoji od dvije glavne komponente: jedan da dinamički odluči o završetku izvornog komada, a drugi koji prevodi konzumiran komad. Uvježbamo komponente zajedno i na način u skladu sa uvjetima infekcije. Da bi stvorili podatke o razmjerenoj obuci, predlažemo metodu koja koristi poravnanje riječi, a također čuva dovoljno konteksta. Uspoređujemo modele sa bidirektivnim i jednodirektivnim koderima različitih dubina, i pravim govorom i tekstom. Naši rezultati na zadatku IWSLT 2020-a engleski do njemački iznose početnu liniju čekanja od 2,6 do 3,7% absolutnog BLEU-a.', 'bn': 'একই সাথে মেশিন অনুবাদে এই উদ্দেশ্য হলো সিদ্ধান্ত নির্ধারণ করা হবে কোথায় একটি অংশের অনুবাদ তৈরি করা হবে, যার মধ্যে সামান্য এবং মানের মধ্যে  আমরা একটি নিউরেল মেশিন অনুবাদ (এনএমটি) মডেল প্রস্তাব করি যা ইনপুটের খাবার বা আউটপুট শব্দের উৎপাদন করতে থাকার সময় বাস্তব সিদ এই মডেলটি দুটি প্রধান উপাদানের মধ্যে তৈরি করা হয়েছে: একটি সোর্স চাঙ্ক শেষ করার সিদ্ধান্ত নেয়া হয়েছে এবং অন্যটি ভোগ করেছে ভক্ত আমরা সাথে যুক্ত এবং সংক্রান্ত পরিস্থিতির সাথে প্রশিক্ষণ দেই। প্রশিক্ষণের তথ্য তৈরি করার জন্য আমরা একটি পদ্ধতি প্রস্তাব করি যা শব্দের স্থাপন ব্যবহার করে যথেষ্ট পরিসংখ্যা সংরক্ষণ করে। আমরা বিভিন্ন গভীরের বিভিন্ন গভীর, বাস্তব ভাষণ এবং টেক্সট ইনপুটের মাধ্যমে মডেলের তুলনা করি। Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7% BLEU absolute.', 'cs': 'Při simultánním strojovém překladu je cílem určit, kdy vytvořit částečný překlad s ohledem na nepřetržitý proud zdrojových slov, s kompromisem mezi latencí a kvalitou. Navrhujeme model neuronového strojového překladu (NMT), který dělá dynamická rozhodnutí, kdy bude pokračovat v krmení vstupními nebo generovat výstupní slova. Model se skládá ze dvou hlavních složek: jedné pro dynamické rozhodování o ukončení zdrojového kusu a druhé, které překládá spotřebovaný kus. Komponenty trénujeme společně a způsobem odpovídajícím podmínkám závěru. Pro generování kusových tréninkových dat navrhujeme metodu, která využívá zarovnání slov a zároveň zachová dostatek kontextu. Porovnáváme modely s obousměrnými a jednosměrnými snímači různých hloubek, a to jak na reálném řeči, tak na textovém vstupu. Naše výsledky na anglicko-německém úkolu IWSLT 2020 překonávají čekací směrnici o 2,6 až 3,7% BLEU absolutně.', 'ca': "En la traducció simultànea de la màquina, l'objectiu és determinar quan produir una traducció parcial dada un flux continu de paraules fonts, amb un compromís entre la latencia i la qualitat. Proposem un model de traducció neural de màquines (NMT) que pren decisions dinàmices quan seguir alimentant-se de les entrades o generant paraules de sortida. El model està compost de dos components principals: un per decidir dinàmicament sobre acabar un tros de fonts, i un altre per traduir el tros consumit. Ensenyem els components conjuntament i de manera que sigui compatible amb les condicions de inferència. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context.  Comparem models amb codificadors bidireccionals i unidireccionals de diferències profunditats, tant en discurs real com en text. Els nostres resultats en la tasca anglès-alemanya IWSLT 2020 superen un punt de referència d'espera d'un 2,6 a un 3,7% absolut BLEU.", 'fi': 'Simultaanisessa konekäännöksessä tavoitteena on selvittää, milloin tuottaa osittainen käännös, kun lähdesanojen virta on jatkuva, viiveen ja laadun välinen kompromissi. Ehdotamme neurokonekäännösmallia (NMT), joka tekee dynaamisia päätöksiä siitä, milloin syötetään syöttöä tai luodaan lähtösanoja. Malli koostuu kahdesta pääkomponentista: toisesta päättää dynaamisesti lähdelohkon lopettamisesta ja toisesta, joka kääntää kulutetun lohkon. Koulutamme komponentit yhdessä ja päättelyolosuhteiden mukaisella tavalla. Harjoitteludatan tuottamiseksi ehdotamme menetelmää, joka hyödyntää sanalinjausta säilyttäen samalla riittävän kontekstin. Vertaamme malleja eri syvyyksisiin kaksisuuntaisiin ja yksisuuntaisiin koodereihin sekä todellisessa puheessa että tekstinsyötössä. IWSLT 2020:n englannin ja saksan välisessä tehtävässä tulokset ylittävät odotusajankohdan 2,6–3,7% BLEU:n absoluuttisella tasolla.', 'af': "In gelyktydelike masjien vertaling is die doel om te bepaal wanneer 'n gedeeltelike vertaling te produseer wat gegee is 'n voortdurende stroom van bron woorde, met 'n verhandeling tussen latensie en kwaliteit. Ons voorstel 'n neurale masjien vertaling (NMT) model wat dinamiese besluite maak wanneer om voortgaan te voer op invoer of te genereer uitvoer woorde. Die model is gemaak van twee hoofkomponente: een na dynamiese besluit op die einde van 'n bron stuk, en 'n ander wat die gebruikte stuk vertaling. Ons tref die komponente saam en in 'n manier wat ooreenkomstig met die inferensie voorwaardes. Om gekruikte onderwerp data te genereer, voorstel ons 'n metode wat word oplyn gebruik terwyl ook genoeg konteks bewaar word. Ons vergelyk modele met bidireksionale en unidireksionale koders van verskillende diepte, beide op regte spreek en teks invoer. Ons resultate op die IWSLT 2020-Engels-tot-Duitse taak uitvoer 'n wag-k baselyn deur 2,6 tot 3,7 % BLEU absoluut.", 'hr': 'U istovremenom prevodu strojeva cilj je utvrditi kada proizvesti djelomičan prevod s obzirom na kontinuirani potok izvornih riječi, s trgovinom između latencije i kvalitete. Predlažemo modelu prevoda neuralnih strojeva (NMT), koji donosi dinamične odluke kada nastaviti hraniti ulaz ili proizvoditi izlazne riječi. Model se sastoji od dvije glavne komponente: jedan da dinamički odluči o završetku izvornog dijela, a drugi koji prevodi konzumiran dio. Uvježbamo komponente zajedno i na način u skladu s uvjetima infekcije. Da bi stvorili podatke o razmjerenoj obuci, predlažemo metodu koja koristi poravnanje riječi, a također čuva dovoljno konteksta. Uspoređujemo modele sa bidirektivnim i jednosmjernim koderima različitih dubina, kako na pravom govoru i tekstu. Naši rezultati na zadatku IWSLT 2020-a engleski-njemački iznosi početnu liniju čekanja od 2,6 do 3,7% absolutnog BLEU-a.', 'et': 'Sünkroontõlke puhul on eesmärk kindlaks määrata, millal tekitada osaline tõlge pideva lähtesõnade voolu korral, kusjuures latentsus ja kvaliteet on kompromiss. Pakume välja neuraalse masintõlke mudeli (NMT), mis teeb dünaamilisi otsuseid, millal jätkata sisendsõnade söötmist või genereerida väljundsõnad. Mudel koosneb kahest põhikomponendist: üks dünaamiliselt otsustab lähtetüki lõpetamise ja teine, mis tõlgib tarbitud tükki. Koolitame komponente ühiselt ja viisil, mis on kooskõlas järeldustingimustega. Tükkide koolitusandmete genereerimiseks pakume välja meetodi, mis kasutab sõna joondamist, säilitades samas piisavalt konteksti. Võrdleme mudeleid erineva sügavusega kahesuunaliste ja ühesuunaliste kodeerijatega nii reaalse kõne kui ka tekstisisendi puhul. Meie inglise-saksa ülesande IWSLT 2020 tulemused on 2,6–3,7% võrra suuremad oote-k algtasemest.', 'jv': 'Nang sampeyan ingkang sampeyan, goal punika dipoleh nunggo kapan ingkang dipoleh tarjamahan kelas Awak dhéwé nggunakake model sing nyucap alat (NMT), kuwi nggawe dadi Dinalat sing bisa dianggawe ngulinakake tarjamahan kanggo mbanjurakno Samsul Awak dhéwé luwih-luwih karo kabèh lan nganggo sakjane sampek karo pawarang pangan To Genere Where am I Rejaling kita nang IWSLT 2020 ngajar ingkang-karo-alam sing ngendalikno kelas telu, iki dadi 2.6 sampek 3.7% salapang panjenengan', 'sk': 'Pri simultanem strojnem prevajanju je cilj določiti, kdaj je treba delni prevod izdelati ob neprekinjenem toku izvornih besed, s kompromisom med latenco in kakovostjo. Predlagamo model nevronskega strojnega prevajanja (NMT), ki sprejema dinamične odločitve, kdaj naj se hrani z vhodnimi besedami ali generira izhodne besede. Model je sestavljen iz dveh glavnih komponent: ena, ki dinamično odloča o končanju izvornega dela, in druga, ki prevaja porabljen kos. Komponente treniramo skupaj in na način, ki je skladen s pogoji sklepanja. Za ustvarjanje zbranih podatkov o usposabljanju predlagamo metodo, ki uporablja poravnavo besed in hkrati ohranja dovolj konteksta. Modele primerjamo z dvosmernimi in enosmernimi kodirniki različnih globin, tako na realnem govoru kot na besedilnem vnosu. Naši rezultati v angleško-nemški nalogi IWSLT 2020 presegajo osnovno vrednost čakanja k za 2,6 do 3,7% absolutne vrednosti BLEU.', 'he': 'בתרגום המכונה באותו זמן, המטרה היא לקבוע מתי לייצר התרגום חלקי שנתן זרם ממשיך של מילים מקור, עם הסחר בין לאטנציה לאיכות. אנו מציעים מודל לתרגום מכונת עצבית (NMT) שמקבל החלטות דינמיות מתי להמשיך להאכיל על הכניסה או ליצור מילים יציאה. המודל מורכב משני רכיבים ראשיים: אחת כדי להחליט דינמית על סיום חתיכת מקור, ואחרת שתרגם את חתיכת המזוקה. אנו מאמן את המרכיבים ביחד ובדרך מתאימה לתנאי ההנחה. כדי ליצור נתונים של אימון, אנו מציעים שיטה שמשתמשת באימון מילים בזמן ששומר גם מספיק קשר. אנחנו משוותים דוגמנים עם קודים שתיים כיוונים וחסרי כיוון בעומקים שונים, גם על הנאום האמיתי וגם על הכניסה טקסטית. Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7% BLEU absolute.', 'ha': "In translation of mashine sami'a, the objective is to define a lõkacin da za'a zartar da rabon fassarar da aka ba da wata duro na continuous source words, with a busy-away between latent and nau'in. Tuna goyyar da wata salo na fassarar mashine na neural (NMT) wanda ke samar da umarni masu sauya idan za'a goge yin abinci a kan inputi ko kuma za'a ƙãga maganar fitarwa. An samar da shirin ayuka biyu masu ƙaranci: ɗayan ta yi hukunci a lokacin da za'a ƙara ƙarin wani na'ura, da wani na fassara mai ci. Tuna kõre ƙananan da suka haɗi da shi, da misãlai. To, in ƙiƙira data masu tsari da ake kiyaye, za'a buƙata wata hanyor ta yi amfani da masu tsari da kalmar da za'a tsare context mai isa. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  MatamayinMu na kan aikin IWSLT 2020 Ingiriya-to-Jarman outperform a bazalin-k da 2.6 zuwa 3.7% BLEU tamkar.", 'bo': 'དངོས་འབྲེལ་འདི་གཅིག་མཚུངས་གྱི་མིང་འཁོར་བརྗོད་ཀྱི་ནང་དུ་དམིགས་ཡུལ་ནི་ག་དུས་རྗེས་སུ་གཏན་འདུག་གམ། We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. Model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. ང་ཚོས་ཆ་ཤས་ཆ་གཅིག་དང་མཉམ་དུ་སྦྲེལ་བའི་རྣམ་པ་དང་མཐུན་པ་ཡིན་པས། ང་ཚོས་རང་ཉིད་ཀྱི་བསྒྱུར་བའི་ཐབས་ལམ་ཞིག་གསར་བཟོ་བྱེད་པར་ཕྱིར་ཉེན་ཁ་ཡིག་ཆ་སྒྲིག་འཇུག་བྱེད་པའི་སྐབས་ཡིག་ཆ་ལྟ We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. ང་ཚོའི་འབྲས་ཐོག་གི་IWSLT 2020་ལས་དབྱིན་ཡིག་ལས་ཇར་མན་གྱི་ལས་འགན་སྡུད་ལ་རྒྱབ་སྐྱོར་ཡོད།'}
{'en': 'Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference', 'ar': 'استعادة علامات الترقيم التلقائية الفعالة باستخدام محولات ثنائية الاتجاه مع استدلال قوي', 'fr': "Restauration automatique efficace de la ponctuation à l'aide de transformateurs bidirectionnels avec inférence robuste", 'es': 'Restauración automática eficiente de la puntuación mediante transformadores bidireccionales con inferencia sólida', 'pt': 'Restauração de pontuação automática eficiente usando transformadores bidirecionais com inferência robusta', 'ja': '堅牢な推論の双方向変圧器を使用した効率的な自動句読点復元', 'zh': '用鲁棒理能者双向转换器高效者自标点复', 'ru': 'Эффективное автоматическое восстановление пунктуации с использованием двунаправленных трансформаторов с надежным выводом', 'hi': 'कुशल स्वचालित विराम चिह्न बहाली मजबूत अनुमान के साथ द्विदिश ट्रांसफार्मर का उपयोग कर', 'ga': 'Athchóiriú Éifeachtach Uathoibríoch Poncaíochta ag Úsáid Claochladáin Déthreo le Tátail Láidir', 'ka': 'ეფექტიური ავტომატური პონქუტეციის რესტოპაცია გამოყენება ორედირექციონალური ტრანფორმეტრების გამოყენება', 'hu': 'Hatékony automatikus pontozási helyreállítás kétirányú transzformátorokkal robusztus inferenciával', 'el': 'Αποτελεσματική αυτόματη αποκατάσταση στίξης χρησιμοποιώντας αμφίδρομους μετασχηματιστές με ισχυρό συμπέρασμα', 'it': 'Ripristino automatico efficiente della punteggiatura utilizzando trasformatori bidirezionali con forte inferenza', 'kk': 'Қосымша түрлендірушілерді қолданып, автоматты түрлендіру қайталау', 'lt': 'Veiksmingas automatinis taško atkūrimas naudojant dvikrypčius transformatorius su stipria Inferencija', 'mk': 'Ефикасна реставрација на автоматска пунктуација со користење на дворечни трансформери со силна инференција', 'ms': 'Pemulihan Punktuasi Automatik Efisien Mengguna Penukar Dua Arah dengan Inferensi Kuat', 'ml': 'റോബസ്റ്റിന്റെ അഭിപ്രായം ഉപയോഗിക്കുന്നതിന് സ്വയം ശിക്ഷ വീണ്ടും തിരിച്ചറിയുക', 'mn': 'Хоёрдугаар зэрэгцээ шилжүүлэгчдийг ашиглан автоматтын загварын дахин сэргээх', 'mt': 'Ritorn Effiċjenti tal-Puntwazzjoni Awtomatika bl-Użu ta’ Transformaturi Bidirezzjonali b’Inferenza Robusta', 'no': 'Effektiv automatisk oppretting av punktpunktpunkt ved bruk av to retningsformatorar med robust Inference', 'sr': 'Efektivna restauracija automatske nagrade koristeći dvosmjerne transformatore sa snažnim nedostatkom', 'pl': 'Wydajne automatyczne przywracanie interpunkcji za pomocą dwukierunkowych transformatorów z solidnym wnioskiem', 'ro': 'Restaurare automată eficientă a punctajării utilizând transformatoare bidirecționale cu inferență robustă', 'so': 'Efficient Automatic Punctuation Restoration using Bidirectional Transformers with Robust Inference', 'ta': 'Comment', 'sv': 'Effektiv automatisk punkteringsĂ¥terstĂ¤llning med tvĂ¥riktade transformatorer med robust inferens', 'si': 'ස්වයංක්\u200dරීය විරාම විරාම සඳහා ප්\u200dරයෝජනය ස්වයංක්\u200dරීය ස්වයංක්\u200dරීය විරාම ස්වයංක්\u200dරීය විරා', 'ur': 'سفارشی اٹوکیٹ پانچوٹ سٹوریٹ', 'uz': 'Comment', 'vi': 'Bộ phục hồi hoà ký hiệu quả bằng cách sử dụng biến hình hai chiều với liên minh bền.', 'bg': 'Ефективно автоматично възстановяване на пунктуация с помощта на двупосочни трансформатори с здрав извод', 'hr': 'Učinjena restauracija automatskih nagodbi s korištenjem dvosmjernih transformatora s jakom oštećenjem', 'nl': 'Efficiënte automatische interpunctie herstel met behulp van bidirectionele transformatoren met robuuste inferentie', 'da': 'Effektiv automatisk punktering gendannelse ved hjælp af tovejede transformatorer med robust inferens', 'de': 'Effiziente automatische Interpunktionswiederherstellung mit bidirektionalen Transformatoren mit robuster Inferenz', 'fa': 'بازسازی نقطه\u200cهای خود تاثیر با استفاده از تغییر\u200cدهندگان دو جهت با تغییر سخت', 'ko': '양방향 변환과 루팡 추리에 기반한 문장 자동 복구', 'sw': 'Kwa kutumia mabadiliko ya njia mbili na kuzuiwa', 'af': 'Effektiewe Outomatiese Punktuasie Herstelling Gebruik van Bidireksionale Transformeerders met Robust Inferensie', 'tr': 'Etkinleýin Otomatik Açmak Mazmunlary Robust Etkinleýşenler bilen ullanýar', 'id': 'Restruksi Punktuasi Otomatis Efisien Menggunakan Transformer Biarah dengan Inferensi Kuat', 'sq': 'Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference', 'hy': 'Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference', 'am': 'drawable-action', 'az': 'Q칲vv톛tli N칬qsanl캼qla iki y칬n transformat칬rl톛rini istifad톛 ed톛r톛k Avtomatik N칬qsanl캼q Restaurasyonu', 'bn': 'Name', 'bs': 'Učinjena restauracija automatske nagrade s korištenjem dvosmjernih transformatora sa jakim nedostatkom', 'ca': 'Una restauració eficient de puntuació automàtica utilitzant transformadors bidireccionals amb influència robusta', 'cs': 'Efektivní automatické obnovení interpunkce pomocí obousměrných transformátorů s robustní inferencí', 'et': 'Tõhus automaatne täppimise taastamine, kasutades kahesuunalisi transformaatoreid tugeva järeldusega', 'fi': 'Tehokas automaattinen pisteytysten palautus kaksisuuntaisilla muuntajilla, joilla on vankka päätelmä', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'ha': '@ action', 'sk': 'Učinkovito samodejno obnavljanje točk z uporabo dvosmernih transformatorjev z robustnim sklepom', 'bo': 'Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference', 'he': 'שינוי נקודה אוטומטי יעיל באמצעות מעצבים שתיים כיוונים עם אינפרנציה חזקה'}
{'en': 'Though people rarely speak in complete sentences, punctuation confers many benefits to the readers of transcribed speech. Unfortunately, most ASR systems do not produce punctuated output. To address this, we propose a solution for automatic punctuation that is both cost efficient and easy to train. Our solution benefits from the recent trend in fine-tuning transformer-based language models. We also modify the typical framing of this task by predicting punctuation for sequences rather than individual tokens, which makes for more efficient training and inference. Finally, we find that aggregating predictions across multiple context windows improves accuracy even further. Our best model achieves a new state of the art on benchmark data (TED Talks) with a combined F1 of 83.9, representing a 48.7 % relative improvement (15.3 absolute) over the previous state of the art.', 'ar': 'على الرغم من أن الناس نادرًا ما يتحدثون بجمل كاملة ، إلا أن علامات الترقيم تمنح قراء الكلام المنسوخ العديد من الفوائد. لسوء الحظ ، لا تنتج معظم أنظمة ASR مخرجات ذات علامات ترقيم. لمعالجة هذا الأمر ، نقترح حلاً لعلامات الترقيم التلقائي يكون فعالاً من حيث التكلفة وسهل التدريب. يستفيد حلنا من الاتجاه الحديث في ضبط نماذج اللغة القائمة على المحولات. نقوم أيضًا بتعديل الإطار النموذجي لهذه المهمة من خلال التنبؤ بعلامات الترقيم للتسلسلات بدلاً من الرموز الفردية ، مما يجعل التدريب والاستنتاج أكثر كفاءة. أخيرًا ، وجدنا أن تجميع التنبؤات عبر إطارات سياق متعددة يعمل على تحسين الدقة بشكل أكبر. يحقق أفضل نموذج لدينا حالة جديدة من الفن فيما يتعلق بالبيانات المعيارية (محادثات TED) مع F1 مجمعة تبلغ 83.9 ، مما يمثل تحسنًا نسبيًا بنسبة 48.7٪ (15.3 مطلقًا) مقارنة بالحالة السابقة.', 'es': 'Aunque la gente rara vez habla en oraciones completas, la puntuación confiere muchos beneficios a los lectores del habla transcrita. Desafortunadamente, la mayoría de los sistemas ASR no producen resultados puntuados. Para hacer frente a esto, proponemos una solución para la puntuación automática que sea rentable y fácil de entrenar. Nuestra solución se beneficia de la reciente tendencia de ajustar los modelos de lenguaje basados en transformadores. También modificamos el encuadre típico de esta tarea al predecir la puntuación de las secuencias en lugar de fichas individuales, lo que hace que el entrenamiento y la inferencia sean más eficientes. Por último, descubrimos que la agregación de predicciones en múltiples ventanas de contexto mejora aún más la precisión. Nuestro mejor modelo logra un nuevo estado del arte en datos de referencia (TED Talks) con una F1 combinada de 83,9, lo que representa una mejora relativa del 48,7% (15,3 absolutos) con respecto al estado de la técnica anterior.', 'pt': 'Embora as pessoas raramente falem em frases completas, a pontuação confere muitos benefícios aos leitores da fala transcrita. Infelizmente, a maioria dos sistemas ASR não produz saídas pontuadas. Para resolver isso, propomos uma solução para pontuação automática que é econômica e fácil de treinar. Nossa solução se beneficia da recente tendência de ajuste fino de modelos de linguagem baseados em transformadores. Também modificamos o enquadramento típico dessa tarefa, prevendo a pontuação para sequências em vez de tokens individuais, o que torna o treinamento e a inferência mais eficientes. Por fim, descobrimos que agregar previsões em várias janelas de contexto melhora ainda mais a precisão. Nosso melhor modelo alcança um novo estado da arte em dados de benchmark (TED Talks) com um F1 combinado de 83,9, representando uma melhoria relativa de 48,7% (15,3 absolutos) em relação ao estado da arte anterior.', 'fr': "Bien que les gens parlent rarement en phrases complètes, la ponctuation confère de nombreux avantages aux lecteurs de discours transcrits. Malheureusement, la plupart des systèmes ASR ne produisent pas de sortie ponctuée. Pour y remédier, nous proposons une solution de ponctuation automatique qui soit à la fois rentable et facile à entraîner. Notre solution tire parti de la récente tendance à affiner les modèles linguistiques basés sur les transformateurs. Nous modifions également le cadrage typique de cette tâche en prédisant la ponctuation des séquences plutôt que des jetons individuels, ce qui améliore l'efficacité de l'entraînement et de l'inférence. Enfin, nous avons constaté que l'agrégation des prédictions dans plusieurs fenêtres contextuelles améliore encore la précision. Notre meilleur modèle atteint un nouvel état de l'art sur les données de référence (TED Talks) avec un F1 combiné de 83,9, ce qui représente une amélioration relative de 48,7\xa0% (15,3 en valeur absolue) par rapport à l'état de la technique précédent.", 'ja': '人々は完全な文章で話すことはほとんどありませんが、句読点は文字起こしされたスピーチの読者に多くの利点を与えます。残念ながら、ほとんどのASRシステムは、句読点付き出力を生成しません。これに対処するために、コスト効率と訓練が簡単な自動句読点のソリューションを提案します。当社のソリューションは、変圧器ベースの言語モデルを微調整する最近の傾向から恩恵を受けています。また、個々のトークンではなく、シーケンスの句読点を予測することで、このタスクの典型的なフレームを修正し、より効率的なトレーニングと推論を可能にします。最後に、複数のコンテキストウィンドウにわたる予測を集約すると、精度がさらに向上することがわかります。当社の最良のモデルは、ベンチマークデータ（ TEDトーク）で最新の技術を達成し、組み合わせたF 1は83.9で、従来の技術よりも48.7 ％の相対的な改善（ 15.3絶対）を表します。', 'zh': '虽少全句之言,而标点符号为转录音者多所利益。 不幸者,多ASR统不生标点输。 为此者,举一以济高效又易于自标点符号解决方案。 吾解决方案益近微调基于转换器言模之势。 又因占序之标点符号,非单表改事之典框架,是使训理益高效。 最后,我们看见,跨数上下文窗口聚合占进一步提高准确性。 吾之至数(TED Talks)得其先进,F1之组为83.9,增于前技术水平48.7%(绝对值为15.3)。', 'hi': 'यद्यपि लोग शायद ही कभी पूर्ण वाक्यों में बोलते हैं, विराम चिह्न लिखित भाषण के पाठकों को कई लाभ प्रदान करता है। दुर्भाग्य से, अधिकांश एएसआर सिस्टम punctuated आउटपुट का उत्पादन नहीं करते हैं। इसे संबोधित करने के लिए, हम स्वचालित विराम चिह्न के लिए एक समाधान का प्रस्ताव करते हैं जो लागत कुशल और प्रशिक्षित करने में आसान दोनों है। हमारे समाधान ठीक ट्यूनिंग ट्रांसफार्मर आधारित भाषा मॉडल में हाल ही में प्रवृत्ति से लाभ. हम व्यक्तिगत टोकन के बजाय अनुक्रमों के लिए विराम चिह्न की भविष्यवाणी करके इस कार्य के विशिष्ट फ्रेमिंग को भी संशोधित करते हैं, जो अधिक कुशल प्रशिक्षण और अनुमान के लिए बनाता है। अंत में, हम पाते हैं कि कई संदर्भ खिड़कियों में भविष्यवाणियों को एकत्रित करने से सटीकता में और भी सुधार होता है। हमारा सबसे अच्छा मॉडल 83.9 के संयुक्त एफ 1 के साथ बेंचमार्क डेटा (टेड टॉक्स) पर कला की एक नई स्थिति प्राप्त करता है, जो कला की पिछली स्थिति की तुलना में 48.7% सापेक्ष सुधार (15.3 निरपेक्ष) का प्रतिनिधित्व करता है।', 'ru': 'Хотя люди редко говорят в полных предложениях, пунктуация дает много преимуществ читателям транскрибируемой речи. К сожалению, большинство систем ASR не производят прерывистый выход. Для решения этой проблемы мы предлагаем решение для автоматической пунктуации, которое является экономически эффективным и простым в обучении. Наше решение извлекает выгоду из недавней тенденции к тонкой настройке языковых моделей на основе трансформаторов. Мы также модифицируем типичный фрейминг этой задачи, предсказывая пунктуацию для последовательностей, а не для отдельных токенов, что делает более эффективным обучение и вывод. Наконец, мы обнаружили, что агрегирование прогнозов по нескольким контекстным окнам еще больше повышает точность. Наша лучшая модель достигает нового уровня техники по эталонным данным (TED Talks) с комбинированным F1 83,9, что представляет собой относительное улучшение на 48,7% (15,3 абсолютных) по сравнению с предыдущим уровнем техники.', 'ga': 'Cé gur annamh a labhraíonn daoine in abairtí iomlána, cuireann an phoncaíocht go leor buntáistí ar fáil do léitheoirí na cainte tras-scríofa. Ar an drochuair, ní tháirgeann an chuid is mó de na córais ASR aschur poncaithe. Chun aghaidh a thabhairt air seo, molaimid réiteach maidir le poncaíocht uathoibríoch atá cost-éifeachtúil agus éasca le hoiliúint. Baineann ár réiteach leas as an treocht atá ann le déanaí maidir le mionchoigeartú a dhéanamh ar shamhlacha teanga atá bunaithe ar chlaochladán. Déanaimid modhnú tipiciúil an taisc seo a mhodhnú freisin trí phoncaíocht a thuar le haghaidh seichimh seachas comharthaí aonair, rud a fhágann go mbeidh oiliúint agus tátal níos éifeachtaí ann. Ar deireadh, feicimid go bhfeabhsaítear cruinneas níos mó fós trí thuar comhiomlánaithe thar fhuinneoga comhthéacs éagsúla. Baineann ár múnla is fearr amach leibhéal nua den scoth ar shonraí tagarmhairc (TED Talks) le F1 comhcheangailte de 83.9, rud a léiríonn feabhas coibhneasta 48.7% (15.3 absalóideach) ar an úrscothacht roimhe seo.', 'el': 'Αν και οι άνθρωποι σπάνια μιλούν σε πλήρεις προτάσεις, η στίξη παρέχει πολλά οφέλη στους αναγνώστες της μεταγραφής ομιλίας. Δυστυχώς, τα περισσότερα συστήματα δεν παράγουν στιγμιαία έξοδο. Για να αντιμετωπιστεί αυτό, προτείνουμε μια λύση για την αυτόματη στίξη που είναι οικονομικά αποδοτική και εύκολη στην εκπαίδευση. Η λύση μας επωφελείται από την πρόσφατη τάση για την τελειοποίηση των γλωσσικών μοντέλων με βάση τους μετασχηματιστές. Τροποποιούμε επίσης το τυπικό πλαίσιο αυτής της εργασίας προβλέποντας στίξη για ακολουθίες και όχι μεμονωμένα σήματα, γεγονός που καθιστά πιο αποτελεσματική εκπαίδευση και συμπέρασμα. Τέλος, διαπιστώνουμε ότι η συγκέντρωση προβλέψεων σε πολλαπλά παράθυρα περιβάλλοντος βελτιώνει ακόμα περισσότερο την ακρίβεια. Το καλύτερο μοντέλο μας επιτυγχάνει μια νέα κατάσταση της τεχνολογίας σε δεδομένα αναφοράς (συζητήσεις TED) με ένα συνδυασμένο F1 των 83.9, που αντιπροσωπεύει 48,7% σχετική βελτίωση (15,3 απόλυτη) έναντι της προηγούμενης κατάστασης της τεχνολογίας.', 'hu': 'Bár az emberek ritkán beszélnek teljes mondatokban, az írásjelek sok előnyt biztosítanak az átírt beszéd olvasóinak. Sajnos a legtöbb ASR rendszer nem állít elő pontozott kimenetet. Ennek megoldása érdekében az automatikus írásjelek megoldását javasoljuk, amely költséghatékony és könnyen edzhető. Megoldásunk profitál a finomhangoló transzformátor alapú nyelvmodellek legújabb trendjéből. Ennek a feladatnak a tipikus keretezését úgy is módosítjuk, hogy a szekvenciák írásjelzését jósoljuk meg, mint az egyes tokenek, ami hatékonyabb képzést és következtetést tesz lehetővé. Végül megállapítjuk, hogy az előrejelzések összesítése több környezeti ablakban még tovább javítja a pontosságot. Legjobb modellünk egy új technológiát ér el a benchmark adatok (TED Talks) kombinált F1 83,9, ami 48,7%-os relatív javulást (15,3 abszolút) jelent a korábbi technika állapotához képest.', 'ka': 'მაგრამ ადამიანები წარმოდგენიან საუკეთესო სიტყვებში, სტუქტუაცია უფრო მნიშვნელოვანია საკითხველების საუკეთესო სიტყვებში. მართლად, უფრო მეტი ASR სისტემები არ წარმოიქმნენ პონკუტიური გამოყენება. ჩვენ ამის შესახებ ავტომატიკური პონქუტუციებისთვის გადაწყვეტილება, რომელიც ორივე უფრო ეფექციურია და ადვილი გაგრძნობა. ჩვენი პასუხი უკეთესი ტენენდიდან გამოიყენება საუკეთესი ტრანფორმეტრისტრისტრისტრისტრისტრისტრისტურის მოდელში. ჩვენ ასევე ამ დავალების ტიპიკური ფრამეტრების შეცვლა, რომელიც უფრო ეფექტიური განახლება და ინფექტიური განახლებისთვის წარმოდგენებით. საბოლოოდ, ჩვენ აღმოჩნეთ, რომ რამდენიმე კონტექსტური ფანჯრების გარეშე წარმოდგენება უფრო მეტი წარმოდგენება. ჩვენი საუკეთესო მოდელი მიიღება ახალი სურათის ცნობილის მონაცემებზე (TED Talks) 83.9-ის კომბიუნირებული F1-ს, რომელიც 48.7%-ის შესაბამისი უფლება (15.3 აბსოლუტი) წინახალი სურათის შესა', 'it': "Anche se le persone raramente parlano in frasi complete, la punteggiatura conferisce molti benefici ai lettori del discorso trascritto. Purtroppo, la maggior parte dei sistemi ASR non produce output punteggiato. Per affrontare questo problema, proponiamo una soluzione per la punteggiatura automatica che sia sia conveniente che facile da addestrare. La nostra soluzione beneficia della recente tendenza nei modelli linguistici basati su trasformatori di fine-tuning. Modificamo anche la tipica inquadratura di questo compito predicendo la punteggiatura per le sequenze piuttosto che per i singoli token, il che rende più efficiente l'allenamento e l'inferenza. Infine, scopriamo che l'aggregazione delle previsioni in più finestre di contesto migliora ulteriormente l'accuratezza. Il nostro modello migliore raggiunge un nuovo stato dell'arte sui dati benchmark (TED Talks) con una F1 combinata di 83,9, che rappresenta un miglioramento relativo del 48,7% (15,3 assoluto) rispetto al precedente stato dell'arte.", 'mk': 'Иако луѓето ретко зборуваат во целосни реченици, точноста им дава многу бенефиции на читателите на препишаниот говор. За жал, повеќето ASR системи не произведуваат точни излези. To address this, we propose a solution for automatic punctuation that is both cost efficient and easy to train.  Нашето решение има корист од неодамнешниот тренд во финетизирање на јазичните модели базирани на трансформатори. Исто така, ја модификуваме типичната рамка на оваа задача со предвидување на точката за секвенции наместо индивидуални знаци, што овозможува поефикасна обука и конференција. Конечно, откривме дека агрегирањето на предвидувањата низ повеќе контекстни прозорци ја подобрува прецизноста уште понатаму. Нашиот најдобар модел постигнува нова техничка состојба во врска со податоците за споредба (TED Talks) со комбиниран F1 од 83,9, што претставува релативно подобрување од 48,7 отсто (15,3 апсолутно) во однос на претходната техничка состојба.', 'lt': 'Nors žmonės retai kalba visiškais sakiniais, taškas suteikia daug naudos transkriptos kalbos skaitytojams. Deja, dauguma ASR sistemų nesudaro taško išėjimo. Siekdami išspręsti šį klausimą, siūlome sprendimą dėl automatinio taško, kuris būtų ekonomiškai efektyvus ir lengvas mokymas. Mūsų sprendimas yra naudingas naujausia tobulinimo transformatoriais grindžiamų kalbų modelių tendencija. Taip pat keičiame tipišką šios užduoties struktūrą prognozuodami sekų, o ne atskirų ženklų, tašką, o tai leidžia veiksmingiau mokytis ir daryti išvadas. Galiausiai pastebime, kad įvairių kontekstų langų prognozių suvestinė dar labiau padidina tikslumą. Mūsų geriausias modelis pasiekia naują pažangą lyginamųjų duomenų srityje (TED pokalbiai), o bendras F1 – 83,9, o tai yra 48,7 proc. santykinis pagerėjimas (15,3 absoliutus) palyginti su ankstesne pažanga.', 'kk': 'Адамдар толық сөйлемелерде сөйлесіп тұрса да, кеңістік сөйлемелердің оқушыларына көп пайда береді. Кешіріңіз, ASR жүйелерінің көпшілігі таңдалған шығыс жасалмайды. Бұл көмектесу үшін біз автоматты түрлендіру үшін шешімізді таңдаймыз. Бұл көмектесу және оңай. Біздің шешіміміз жаңа тенденциялық түрлендіруші тіл үлгілерінде жақсы түрлендіру үлгілерінде пайда болады. Біз сондай-ақ бұл тапсырманың қалыпты фреймдерін өзгертеміз, бұл тапсырманың әрбір тапсырмаларды, әрбір тапсырмалардың орнына, әрбір тапсырмаларды тапсырмаларды Соңында біз бірнеше контексті терезелердің бірнеше бағдарламаларды біріктіруге болады. Біздің ең жақсы моделіміз кеңістік деректерінің жаңа күйін (TED Talks) түрінде 83,9 жылдық F1- мен біріктіреді, ол 48,7% салысты жақсарту (15,3 абсолюттік) деп аталады.', 'ms': 'Though people rarely speak in complete sentences, punctuation confers many benefits to the readers of transcribed speech.  Malangnya, kebanyakan sistem ASR tidak menghasilkan output tertentu. Untuk mengatasi ini, kami cadangkan penyelesaian untuk punctuasi automatik yang sama-sama efisien dan mudah dilatih. Solusi kita berguna dari perkembangan baru-baru ini dalam penyesuaian model bahasa berdasarkan pengubah. Kami juga mengubah bingkai biasa tugas ini dengan meramalkan punctuasi untuk jujukan daripada token individu, yang membuat latihan dan kesimpulan yang lebih efisien. Akhirnya, kita mendapati bahawa ramalan aggregat di seluruh tetingkap konteks berbilang meningkatkan ketepatan lebih lanjut. Model terbaik kami mencapai kemajuan baru pada data benchmark (TED Talks) dengan F1 kombinasi 83.9, mewakili penambahan relatif 48.7% (15.3 mutlak) atas kemajuan seni sebelumnya.', 'ml': 'മനുഷ്യര്\u200d പൂര്\u200dണ്ണമായ വാക്കുകളില്\u200d സംസാരിക്കുന്നത് കുറച്ച് പേരും പൂര്\u200dണ്ണമായി സംസാരിക്കുന്നില്ലെങ്ക Unfortunately, most ASR systems do not produce punctuated output.  ഇതിനെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു പരിഹാരം പ്രായശ്ചിത്തം ചെയ്യുന്നു. അത് വിലപ്പെടുത്തുന്നതും പരിശ നമ്മുടെ പരിഹാരത്തിന്റെ അടുത്തുള്ള പരിഹാരത്തില്\u200d നിന്നും നമ്മുടെ ഉപകരണങ്ങള്\u200d നല്ല മാറ്റങ്ങളില്\u200d നിന്നും  ഈ ജോലിയുടെ സാധാരണ ചെയ്യുന്നത് നമ്മള്\u200d മാറ്റിക്കൊണ്ടിരിക്കുന്നു. വ്യക്തിപരമായ അടയാളങ്ങളെക്കാള്\u200d പ്രത്യേകിക്കുന്നത് നമ്മള അവസാനം നമുക്ക് കണ്ടെത്തുന്നത് കൂടുതല്\u200d പ്രവചനങ്ങള്\u200d കൂടുതല്\u200d വികസിപ്പിക്കുന്നതാണെന്നാണ്. നമ്മുടെ ഏറ്റവും നല്ല മോഡല്\u200d ബെന്\u200dച്മാര്\u200dക്ക് ഡേറ്റാകളില്\u200d ഒരു പുതിയ സ്ഥാനം നേടുന്നു. എഫ്1, 83. 9-ല്\u200d ഒരുമിച്ചിരിക്കുന്നു. മുമ്പുള്ള കലാകാരത്തില്\u200d 48.', 'mt': 'Għalkemm in-nies rarament jitkellmu f’sentenzi sħaħ, il-puntwazzjoni tagħti ħafna benefiċċji lill-qarrejja tad-diskors trasskritt. Sfortunatament, il-biċċa l-kbira tas-sistemi ASR ma jipproduċux output puntwat. Biex nindirizzaw dan, nipproponu soluzzjoni għall-puntwazzjoni awtomatika li tkun kemm kosteffiċjenti kif ukoll faċli biex titħarreġ. Is-soluzzjoni tagħna tibbenefika mix-xejra reċenti fil-mudelli lingwistiċi bbażati fuq it-trasformaturi. Aħna mmodifikaw ukoll l-oqfsa tipika ta’ dan il-kompitu billi nipprevedu l-puntwazzjoni għal sekwenzi aktar milli għal tokens individwali, li tagħmel għal taħriġ u inferenza aktar effiċjenti. Fl-aħħar nett, isibu li l-aggregazzjoni tat-tbassir f’diversi twieqi ta’ kuntest ittejjeb il-preċiżjoni saħansitra aktar. L-a ħjar mudell tagħna jikseb avvanz ġdid fid-dejta ta’ referenza (TED Talks) b’F1 kombinat ta’ 83.9, li jirrappreżenta titjib relattiv ta’ 48.7% (assolut ta’ 15.3) fuq l-avvanz preċedenti.', 'pl': 'Chociaż ludzie rzadko mówią w pełnych zdaniach, interpunkcja daje wiele korzyści dla czytelników przepisanej mowy. Niestety, większość systemów ASR nie produkuje interpunkcyjnego wyjścia. Aby temu zaradzić, proponujemy rozwiązanie automatycznej interpunkcji, które jest zarówno ekonomiczne, jak i łatwe do przeszkolenia. Nasze rozwiązanie korzysta z najnowszego trendu dostrajania modeli językowych opartych na transformatorach. Modyfikujemy również typowe ramowanie tego zadania poprzez przewidywanie interpunkcji dla sekwencji zamiast poszczególnych tokenów, co pozwala na bardziej efektywne szkolenie i wnioskowanie. Wreszcie okazujemy się, że agregowanie prognoz w wielu oknach kontekstowych jeszcze bardziej poprawia dokładność. Nasz najlepszy model osiąga nowy stan techniki w zakresie danych referencyjnych (TED Talks) dzięki połączeniu F1 z 83.9, reprezentując 48,7% względną poprawę (15,3 absolutną) w stosunku do poprzedniego stanu techniki.', 'mn': 'Хүмүүс бүрэн өгүүлбэр хэлэхдээ ховор ярьдаг ч, тэмдэглэх нь бичсэн ярианы уншигчдад олон ашиг өгдөг. Харамсалтай нь ихэнх АСР системүүд тодорхой үр дүнг бий болгодоггүй. Энэ талаар бодохын тулд бид автоматически тодорхойлолтын шийдэл гаргаж байна. Энэ нь үнэ цэнэтэй болон хөгжүүлэх амархан. Бидний шийдэл саяхан өөрчлөгчийн хэл загваруудын тухай саяхан хувьсгалттай тенденс ашигладаг. Мөн бид энэ ажлын ерөнхий хэлбэрийг өөрчлөхөд хэн нэгэн тодорхойлолтын оронд дарааллын тодорхойлолтын тодорхойлолтыг таамаглаж, илүү үр дүнтэй дасгал болон халдвар хийдэг. Эцэст нь бид олон нөхцөл цонхны дахь тодорхойлолтуудыг нийлүүлэх нь илүү нарийвчлалтай болгодог. Бидний хамгийн шилдэг загвар нь банкмарк өгөгдлийн шинэ байр суурь (TED Talks) болон 83.9 гаригийн F1-тэй холбогдож, урлагийн өмнөх байр суурь дээр 48.7%-ын харьцаатай сайжруулалт (15.3 абсолют) гэсэн үг юм.', 'no': 'Selv om folk rart snakker i fullstendige setningar, vil punkteringa gje mange fordel til lesarane av transkripte tale. Dei fleste ASR-systema produserer ikkje punkterte utdata. For å handtera dette, foreslår vi ein løysing for automatisk punkt som er både kostnad effektivt og enkelt å trenja. Løysinga vårt brukar frå den siste trenden i språk-modellen som finnstillingar transformerer. Vi endrar også den typiske framforminga av denne oppgåva ved å foregå punktet for sekvensar i staden for individuelle teikn, som gjer for meir effektivt trening og infeksjon. Etter slutt, finn vi at samlinga av forhåndsvisingar over fleire kontekstvindauge forbedrar nøyaktighet enda lenger. Det beste modellen vårt gjer eit nytt tilstand til kunsten på benchmark data (TED Talks) med eit kombinasjon F1 av 83,9, som representerer ein relativt forbedring (15,3 absolutt) i 48,7 % over den førre tilstanden av kunsten.', 'ro': 'Deși oamenii rareori vorbesc în propoziții complete, punctuația conferă multe beneficii cititorilor discursului transcris. Din păcate, majoritatea sistemelor ASR nu produc ieșiri punctuate. Pentru a rezolva acest lucru, propunem o soluție pentru punctuația automată, care este atât rentabilă, cât și ușor de instruit. Soluția noastră beneficiază de tendința recentă în modelele lingvistice bazate pe transformatoare fină. De asemenea, modificăm încadrarea tipică a acestei sarcini prin predicția punctuației pentru secvențe mai degrabă decât pentru jetoane individuale, ceea ce face pentru o instruire și inferență mai eficientă. În cele din urmă, constatăm că agregarea previziunilor în mai multe ferestre contextuale îmbunătățește acuratețea și mai mult. Cel mai bun model al nostru atinge o nouă stare a tehnologiei privind datele de referință (TED Talks) cu un F1 combinat de 83,9, reprezentând o îmbunătățire relativă de 48,7% (15,3 absolut) față de starea anterioară a tehnologiei.', 'sr': 'Iako ljudi rijetko govore u potpunim rečenicama, punkcija predstavlja mnogo koristi čitačima prepisanog govora. Nažalost, većina ASR sistema ne proizvodi punctuirani izlaz. Da bi se ovo riješili, predlažemo rešenje za automatsku tačku koja je i koštanje efikasno i lako trenirati. Naše rešenje koristi od nedavnog trenda u modelima jezika koji se baziraju na transformatorima. Takoðe modifikujemo tipičnu okviru ovog zadatka predviđanjem taèke za sekvence umjesto pojedinih znakova, što čini učinkovitijim obukom i infekcijom. Konačno, našli smo da skupljanje predviđanja u višestrukim kontekstskim prozorima i dalje poboljšava tačnost. Naš najbolji model postiže novo stanje umjetnosti na standardnim podacima (TED Talks) sa kombiniranom F1 od 83,9, koji predstavlja relativno poboljšanje 48,7% (15,3 apsolutno) u prethodnom stanju umjetnosti.', 'so': "In kastoo dadku si qiimo ah ugu hadlaan hadal buuxa, xittaa waxey faa'iido badan u helaan kuwa akhriya hadal qoran. Nasiib la’aan, nidaamka ASR intooda badan ma soo saaraan output punctured. Si aan u baaraandegiso, waxaynu soo jeedaynaa xalal ka baaraandegista, taasoo ah kharashka faa’iidada iyo waxbarashada sahlan. Xaruntayada waxyaabaha ay ka heli karaan qaababka ugu dambeeyey oo ku qoran qaababka luuqada bedela oo si fiican ah. Sidoo kale waxaynu beddelinaynaa burburka caadiga ah oo shaqadan ku saabsan qaabka ah, waxaynu ku sii beddelinaynaa aragtida habab ah, taasoo u sameynaya waxbarasho faa'iido badan iyo cudur. Ugu dambaysta waxaynu heli nahay in horumarinta wax ka sii kordhiya waxyaabaha daaqadaha kala duduwan ay sii kordhaan si saxda ah. Tusaale ahaan ugu wanaagsan wuxuu gaadhaa xaalad cusub oo farshaxanka ku saabsan taariikhda bangiga (TED Talks) oo la soo ururiyey F1 oo ka mid ah 83.9, kaas oo ka mid ah 48.7% hagaajinta horumarinta (15.3 absolute) xaaladdii hore ee farshaxanka.", 'sv': 'Även om folk sällan talar i fullständiga meningar, ger skiljetecken många fördelar för läsarna av transkriberat tal. Tyvärr producerar de flesta ASR-system inte punkterad utgång. För att lösa detta föreslår vi en lösning för automatisk skiljetecken som är både kostnadseffektiv och lätt att träna. Vår lösning drar nytta av den senaste trenden inom finjusterande transformatorbaserade språkmodeller. Vi modifierar också den typiska utformningen av denna uppgift genom att förutsäga skiljetecken för sekvenser snarare än enskilda tokens, vilket ger effektivare träning och inferens. Slutligen ser vi att aggregering av förutsägelser över flera kontextfönster förbättrar noggrannheten ytterligare. Vår bästa modell uppnår en ny toppnivå för benchmarkdata (TED Talks) med en kombinerad F1 på 83,9, vilket motsvarar en relativ förbättring på 48,7% (15,3 absolut) jämfört med tidigare toppnivå.', 'ta': 'மக்கள் முழு வாக்கியங்களில் குறைவாக பேசுவதாலும், நிகழ்ச்சி எழுதப்பட்ட பேச்சை படிப்பவர் துரதிர்ஷ்டவசமாக, பெரும்பாலான ASR அமைப்புகள் குறிப்பிட்ட வெளியீட்டை உருவாக்குவதில்லை. இதை முகவரிப்பதற்கு, தானாக தானியங்கி பாங்கின் தீர்வை நாம் பரிந்துரைக்கிறோம். இது விலை செலவு தான் பயிற்சி சுல சமீபத்திலிருந்து எங்கள் தீர்வு பயன்பாடுகள் நன்றாக மாற்றும் மொழி மாற்றம் மாதிரிகளில். நாம் இந்த பணியின் வழக்கமான பிரச்சனைகளை மாற்றுகிறோம் தனித்தனியான குறியீடுகளை விட பின்னங்களை மாற்றுகிறது, அது மேலும் தேவையான கடைசியாக, பல சூழல் சாளரங்களில் மேலும் சரியான சாளரங்களை குறைக்கும் என்பதை நாம் கண்டுபிடிக்கிறோம். எங்கள் சிறந்த மாதிரி பெங்குரு தகவல் மீது புதிய கலைப்பாட்டின் நிலையை பெறுகிறது முந்தைய கலைப்பாட்டின் மூலம் 83. 9 பேச்சுகளில் ஒரு F1 சேர்க்கப்பட்டது,', 'si': 'මිනිස්සු සම්පූර්ණ වචනයෙන් කතා කරන්න බැරි වුනත්, විදිහට ප්\u200dරයෝජනයක් ගොඩක් ප්\u200dරයෝජනයක් ලැබෙනවා කි අවාසනාවට, බොහෝ ASR පද්ධතියක් ප්\u200dරතික්\u200dරියාත්මක නිර්මාණය කරන්නේ නෑ. මේක විශ්වාස කරන්න, අපි ස්වයංක්\u200dරියාත්මක වින්දුවක් සඳහා ප්\u200dරතික්\u200dරියාත්මක වින්දුවක් ප්\u200dරයෝජනය අපේ විස්තරය ප්\u200dරයෝජනය ප්\u200dරයෝජනය කරනවා අලුත් විස්තරයෙන් ප්\u200dරයෝජනය කරනවා නිර්මාණය කරනවා භාෂ අපි මේ වැඩේ සාමාන්\u200dය ප්\u200dරමාණය වෙනස් කරනවා ප්\u200dරතිකාර ප්\u200dරමාණය සහ ප්\u200dරමාණය සඳහා ප්\u200dරතිකාර ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා ප අන්තිමේදී, අපි හොයාගන්නවා විශේෂ කවුළු වලින් සංවේශනය සම්පූර්ණය කරනවා කියලා. අපේ හොඳම මොඩල් එක්ක බෙන්ච්මාර්ක් දත්ත (TED කතාවක්) වල අලුත් ස්ථානයක් ලැබෙනවා, 83.9 වලින් සම්බන්ධ F1 එක්ක, 48.7% සම්බන්ධ විශාලනයක් ප', 'ur': 'اگرچہ لوگوں کو بہت ہی کم کلمات سے بات کہتے ہیں تو ان کے پڑھنے والوں کو بہت فائدہ پہنچاتا ہے بدبختی، اکثر ASR سیستموں نے نقطہ آئٹ پیدا نہیں کیا۔ اس کے بارے میں ہم نے اتماٹی نقطہ کے لئے ایک حل پیش کیا ہے جو both cost efficient and easy to train. ہمارا حل اگلے ٹرنڈ سے فائدہ پہنچاتا ہے جو سیدھی تغییر دینے والی زبان مدل میں ہے۔ ہم نے بھی اس کام کی عام فرمینڈ کی تغییر کر دی ہے کہ ایک شخصی ٹوکنوں کے بجائے نقطہ کے لئے نقطہ کی تغییر کریں، جو زیادہ مفید تربینڈ اور نقطہ کے لئے بناتا ہے. آخر میں ہم دیکھتے ہیں کہ بہت سی کنٹکس وینڈوز میں پیش بینی جمع کرنا بہت زیادہ مضبوط ہوتا ہے۔ ہمارے بہترین مدل بنچم مارک ڈیٹا (TED Talks) پر ایک نئی موقعیت پہنچتی ہے جس میں 83.9 کی ملکیت F1 ہے، جو 48.7% مقابلہ میں مقابلہ تدبیر (15.3 مطلوب) ہے۔', 'uz': "Ko'p odamlar butun so'zlarda gapirayotganda, taqdimlik so'zlar o'quvchilariga ko'p foydalanadi. Afsuski, ko'pchilik ASR tizimlari punctuated output emas. Buni boshqarish uchun, biz avtomatik tashkilotni avtomatik tasavvur qilish imkoniyatini taʼminlashni istaysizmi. Bu ikkita qismi cheksiz va sodda. Yaqinda o'zgarishni o'zgartirish asosiy tilni o'zgartirish modellarida bizning qiziqaruvchimiz yordam beradi. Biz shu vazifaning oddiy harakatini ko'rsatish va bir necha belgilarni ko'rib chiqarishni o'zgartirib o'zgartimiz. Bu ta'limning ko'paytidan foydalanish va tadbirlikni ko'proq qiladi. Endi biz ko'pchilik tarkibi oynalarni ko'paytirishni ko'proq taqdim qilishni anglaymiz. Bizning eng yaxshi modelimiz eng yaxshi sarlavhasi haqida saqlash (TED Talks) haqida 83.9 dan birlashtirilgan F1 (48.7% bogʻliq o'zgarishga (15.3 absolute) yaxshi holatiga ega bo'ladi.", 'vi': 'Mặc dù người ta hiếm khi nói trong câu hoàn chỉnh, dấu chấm này mang lại nhiều lợi ích cho người đọc bài diễn văn được ghi lại. Thật không may, hầu hết các hệ thống ASR không sản xuất theo dấu. Để giải quyết vấn đề này, chúng tôi đề nghị một giải pháp cho việc bắn trúng tự động vừa hiệu quả và dễ dàng để huấn luyện. Cách giải quyết của chúng ta có lợi từ xu hướng gần đây về phương pháp biến đổi. Chúng ta cũng thay đổi khung hình điển hình của nhiệm vụ này bằng cách dự đoán hiệu quả thay vì biểu tượng cá nhân. Điều đó làm cho giáo dục và ngụ ý hiệu quả hơn. Cuối cùng, chúng tôi thấy việc tổng hợp dự đoán trên nhiều cửa sổ ngữ cảnh cải thiện độ chính xác hơn nữa. Người mẫu tốt nhất đạt được một trạng thái mới về dữ liệu tiêu chuẩn (ROOST) với một dạng dạng dạng dạng liên kết F1 of 83.9, đại diện cho một 48.7=.* cải tiến tương đối (15.3 tuyệt đối) so với trạng thái nghệ thuật trước đây.', 'nl': 'Hoewel mensen zelden in volledige zinnen spreken, biedt interpunctie veel voordelen aan de lezers van getranscribeerde spraak. Helaas produceren de meeste ASR-systemen geen interpunctueerde output. Om dit aan te pakken, stellen we een oplossing voor automatische interpunctie voor die zowel kostenefficiënt als gemakkelijk te trainen is. Onze oplossing profiteert van de recente trend in het finetunen van taalmodellen op basis van transformatoren. We modificeren ook de typische framing van deze taak door interpunctie te voorspellen voor sequenties in plaats van individuele tokens, wat zorgt voor efficiëntere training en inferentie. Tot slot stellen we vast dat het aggregeren van voorspellingen over meerdere contextvensters de nauwkeurigheid nog verder verbetert. Ons beste model bereikt een nieuwe stand van de techniek op benchmark data (TED Talks) met een gecombineerde F1 van 83.9, wat een 48,7% relatieve verbetering (15,3 absolute) vertegenwoordigt ten opzichte van de vorige stand van de techniek.', 'hr': 'Iako ljudi rijetko govore u potpunim kaznama, punkcija predstavlja mnoge koristi čitačima prepisanog govora. Nažalost, većina ASR sustava ne proizvodi punctuirani izlaz. Za rješavanje ovoga predlažemo rješenje za automatsku tačku koja je i koštanje učinkovito i lako trenirati. Naša rješenje koristi od nedavnog trenda u modelima jezika koji se temelji na transformatorima. Također smo izmijenili tipičnu okviru ovog zadatka predviđanjem točke za sekvence umjesto pojedinačnih znakova, što čini učinkovitijim obukom i infekcijom. Konačno, našli smo da skupljanje predviđanja u višestrukim kontekstskim prozorima i dalje poboljšava preciznost. Naš najbolji model postiže novo stanje umjetnosti na standardnim podacima (TED Talks) sa kombiniranom F1 od 83,9, predstavljajući relativno poboljšanje 48,7% u prethodnom stanju umjetnosti.', 'bg': 'Въпреки че хората рядко говорят в пълни изречения, пунктуацията дава много ползи на читателите на преписаната реч. За съжаление, повечето системи не произвеждат пунктиран изход. За да се справим с това, предлагаме решение за автоматична пунктуация, което е едновременно рентабилно и лесно за обучение. Нашето решение се възползва от скорошната тенденция в фино настройване на трансформаторни езикови модели. Също така модифицираме типичното рамкиране на тази задача, като предвиждаме пунктуация за последователности, а не за отделни символи, което прави по-ефективно обучение и изводи. И накрая, намираме, че агрегирането на прогнози в няколко контекстни прозореца подобрява точността още повече. Нашият най-добър модел постига ново състояние на изкуството по референтните данни (ТЕД разговори) с комбинирана Ф1 от 83.9, което представлява относително подобрение от 48.7% (15.3 абсолютно) спрямо предишното състояние на изкуството.', 'da': 'Selvom folk sjældent taler i komplette sætninger, giver tegnsætning mange fordele til læserne af transkriberat tale. Desværre producerer de fleste ASR-systemer ikke punkteret output. For at løse dette foreslår vi en løsning til automatisk tegnsætning, der er både omkostningseffektiv og nem at træne. Vores løsning drager fordel af den seneste tendens inden for finjusterende transformerbaserede sprogmodeller. Vi ændrer også den typiske ramme af denne opgave ved at forudsige tegnsætning for sekvenser snarere end individuelle tokens, hvilket giver mere effektiv træning og inference. Endelig finder vi ud af, at aggregering af forudsigelser på tværs af flere kontekstvinduer forbedrer nøjagtigheden yderligere. Vores bedste model opnår en ny state of te art for benchmark data (TED Talks) med en kombineret F1 på 83,9, hvilket repræsenterer en 48,7% relativ forbedring (15,3 absolut) i forhold til den tidligere state of te art.', 'id': 'Meskipun orang jarang berbicara dalam kalimat lengkap, punctuasi memberikan banyak keuntungan kepada pembaca pidato yang ditulis. Sayangnya, kebanyakan sistem ASR tidak menghasilkan output tertentu. Untuk mengatasi hal ini, kami mengusulkan solusi untuk punctuasi otomatis yang baik efisien biaya dan mudah dilatih. Solusi kita berguna dari trend baru-baru ini dalam penyesuaian model bahasa berbasis transformer. We also modify the typical framing of this task by predicting punctuation for sequences rather than individual tokens, which makes for more efficient training and inference.  Akhirnya, kita menemukan bahwa pengumpulan prediksi di seluruh jendela konteks berbilang meningkatkan akurasi lebih lanjut. Model terbaik kami mencapai state of the art baru pada data benchmark (TED Talks) dengan kombinasi F1 83,9, mewakili 48,7% peningkatan relatif (15,3 mutlak) atas state of the art sebelumnya.', 'de': 'Obwohl Menschen selten in ganzen Sätzen sprechen, bietet Interpunktion den Lesern transkribierter Sprache viele Vorteile. Leider produzieren die meisten ASR-Systeme keine punktierte Ausgabe. Um dies zu beheben, schlagen wir eine Lösung für automatische Interpunktion vor, die sowohl kosteneffizient als auch einfach zu trainieren ist. Unsere Lösung profitiert vom jüngsten Trend zur Feinabstimmung transformatorbasierter Sprachmodelle. Wir modifizieren auch das typische Framing dieser Aufgabe, indem wir Interpunktion für Sequenzen anstelle einzelner Token vorhersagen, was ein effizienteres Training und Inferenz ermöglicht. Schließlich stellen wir fest, dass das Aggregieren von Vorhersagen über mehrere Kontextfenster die Genauigkeit noch weiter verbessert. Unser bestes Modell erreicht einen neuen Stand der Technik in Bezug auf Benchmark-Daten (TED Talks) mit einem kombinierten F1 von 83,9 und stellt eine 48,7% relative Verbesserung (15,3 Absolut) gegenüber dem bisherigen Stand der Technik dar.', 'ko': '비록 사람들이 완전한 문장으로 말하는 것은 매우 드물지만, 문장부호는 베낀 독자들에게 많은 이익을 가져다 주었다.불행하게도 대부분의 ASR 시스템은 구두점 출력을 생성하지 않습니다.이 문제를 해결하기 위해 우리는 경제적이고 교육하기 쉬운 자동 구두점 해결 방안을 제시했다.우리의 해결 방안은 최근transformer의 언어 모델을 기반으로 하는 추세를 미세하게 조정한 덕분이다.우리는 또한 하나의 표시가 아닌 예측 서열의 구두점을 통해 이 임무의 전형적인 구조를 수정함으로써 더욱 효과적인 훈련과 추리에 도움이 된다.마지막으로 우리는 여러 개의 상하문 창을 뛰어넘어 집합 예측이 더욱 정확성을 높일 수 있음을 발견했다.우리의 최적 모델은 기준데이터(TED Talks)에서 새로운 수준에 도달했고, F1의 전체 성적은 83.9로 이전 수준보다 상대적으로 48.7%(절대치 15.3) 높아졌다.', 'af': "Alhoewel mense selfs in volledige setings praat, die puntuasie bely baie voordeel aan die lesers van transkripteerde woord. Ongelukkig, die meeste ASR stelsels produseer nie punctuated uitset nie. Om hierdie te adres, voorstel ons 'n oplossing vir outomatiese puntuasie wat beide koste effektief en maklik is om te trein. Ons oplossing is voordeel van die onlangse trend in fyn-tuning transformer-gebaseerde taal modele. Ons het ook die tipiese raam van hierdie taak verander deur die voorskou van punktuasie vir sekwensies eerder as individuele tokens, wat maak vir meer effektief onderwerking en inferensie. Eindelik, ons vind dat die samekoms van voorskou oor veelvuldige konteksvensters waarskynlik nog verder verbeter. Ons beste model bereik 'n nuwe staat van die kuns op benchmark data (TED Talks) met 'n gekombineerde F1 van 83.9, wat 'n 48.7% relatiewe verbetering (15.3 absoluut) oor die vorige staat van die kuns verteenwoordig.", 'sw': 'Ingawa watu nadra sana wanazungumza kwenye hukumu kamili, udhaifu unawapa manufaa mengi kwa wasomaji wa hotuba iliyoandikwa. Kwa bahati mbaya, mifumo mingi ya ASR hazijatoa mazao yanayopungua. Ili kuonyesha hili, tunapendekeza suluhisho la kutengeneza vifaa vya kujitegemea ambavyo ni gharama za ufanisi na rahisi kufundisha mafunzo. suluhisho letu linafaidika na mwenendo wa hivi karibuni katika mifano ya mabadiliko ya lugha yenye msingi wa lugha. Kadhalika tunabadilisha uvunjifu wa kawaida wa kazi hii kwa kutabiri pungua kwa mfululizo badala ya ishara binafsi, ambazo zinafanya mafunzo yenye ufanisi na madhara. Mwisho, tunagundua kwamba kuongeza utabiri katika mitandao mbalimbali yanaongezea uhakika zaidi. Mfano wetu bora unaweza kupata hali mpya ya sanaa kwenye taarifa za bendera (TED mazungumzo) pamoja na F1 ya 83.9, ikiwakilisha asilimia 48.7 yenye maboresho ya sanaa (15.3 yenye umuhimu) katika hali iliyopita ya sanaa.', 'fa': 'اگرچه مردم به سخنرانی کامل سخن می\u200cگویند، نقطه\u200cای به خوانندگان سخنرانی نوشته\u200cاند سودی بسیار می\u200cدهد. متأسفانه، بیشتر سیستم\u200cهای ASR نتیجه\u200cی نقطه\u200cای را تولید نمی\u200cکنند. برای حل این کار، ما پیشنهاد می\u200cکنیم راه حلی برای نقطه\u200cهای خودکار که برای آموزش هزینه\u200cای موثر و آسان است. راه حل ما از طریق اخیر در مدل های زبان\u200cهای تغییر دهنده\u200cای بسیار خوب سود می\u200cدهد. ما همچنین فرم\u200cسازی معمولی این کار را با پیش\u200cبینی کردن نقطه\u200cای برای نقطه\u200cها به جای نشانه\u200cهای فردی تغییر می\u200cدهیم، که برای آموزش و آلودگی بیشتری موثر می\u200cکند. بالاخره، ما پیدا کردیم که جمع پیش بینی\u200cها در پنجره\u200cهای متعدد بیشتر دقیق بیشتری را بهتر می\u200cکند. بهترین مدل ما یک وضعیت جدید از هنر در داده\u200cهای صندوق (TED Talks) با یک F1 از 83.9 ترکیب می\u200cشود که در وضعیت قبلی هنر 48.7 درصد بهترین نسبتی (15.3 مطلق) را نمایش می\u200cدهد.', 'sq': 'Ndonse njerëzit rrallë flasin në fjalë të plota, piktimi u jep shumë përfitime lexuesve të fjalimit të transkriptuar. Fatkeqësisht, shumica e sistemeve ASR nuk prodhojnë dalje të piktuara. Për të trajtuar këtë, ne propozojmë një zgjidhje për piktimin automatik që është si kosto-efikase dhe e lehtë për të trajnuar. Zgjidhja jonë përfiton nga prirja e fundit në rregullimin e modeleve gjuhësore bazuar në transformues. Ne gjithashtu modifikojmë kuadrin tipik të kësaj detyre duke parashikuar piktimin për sekuenca në vend të shenjave individuale, që bën për trainimin dhe përfundimin më të efektshëm. Finally, we find that aggregating predictions across multiple context windows improves accuracy even further.  Modeli ynë më i mirë arrin një gjendje të re të teknologjisë në të dhënat e referimit (TED Talks) me një F1 të kombinuar prej 83.9, që përfaqëson një përmirësim relativ 48.7% (15.3 absolute) mbi gjendjen e mëparshme të teknologjisë.', 'am': 'ምንም እንኳን ሰዎች በተፈጸመ ፍርድ በሚናገሩ ጥቂት ነገር ቢናገሩ፣ ጉዳዩ ለጽሑፍ ንግግር ለሚያነቡ ብዙ ጥቅሞችን ይሰጣል፡፡ በርግጥ፣ ብዙዎቹ ASR ስርዓቶች ጉዳይ ውጤት አያደርጉም፡፡ ለመግለጽ፣ ለራሱ ማስታወቂያውን እና ለማስተማር ቀላል እናስፈልጋለን፡፡ የቀድሞው አካባቢ የቋንቋ ምሳሌዎች በመጠቀም የሚጠቅሙት ፍላጎታችን ነው፡፡ We also modify the typical framing of this task by predicting punctuation for sequences rather than individual tokens, which makes for more efficient training and inference.  በመጨረሻም፣ ብዙ መስኮቶች በተለዩ መስኮቶች ላይ ትንቢት የሚያሳልፍ ውርደትን እንዲያበዛ እናገኛለን፡፡ ትልቁ ምሳሌያችን የቀድሞው የዐርብ ክፍል (TED Talks) በ83.9 ክፍል የተጠቃሚ F1 በመቶ 48.7 በመቶ አካባቢ ማድረግ (15.3 እውል) የተባለፈውን ክፍል ላይ አዲስ የአርላማ ሁኔታ አግኝቷል፡፡', 'tr': 'Adamlar gaty sözler bilen gürläp ýok bolsa-da, wajyp ýazylan sözlerin okaanlaryna köp fayda berýär. Gynansakda köp ASR sistemler puntual çykgyny bejermeýär Muny çözmek üçin, biz awtomatik taýýarlama üçin bir çözüm teklip edip, oýun etmek üçin buýruk we ýeňil. Biziň çözgümiz ýakyn täze bir şekilde täze bir transformasiýat düzümlerinden faydalandyrýar. Biz hem bu zadyň tipik framlaryny indiki işaretlerden başga sıralar üçin noktalaryny tahmin edip, etkinlik eğitim we hasaplamak üçin düzenleyerek üýtgedik. Soňunda, birnäçe kontekst pencereleriniň arasynda öngörümlerniň toplamynyň dogrylygyny has gowurak boldygyny düşünýäris. Biziň iň gowy nusgamyz benchmark maglumatynda (TED Talks) täze bir durumyny 83.9 bilen birleştirilýän F1 we 48.7% sanat gelişmegi (15.3 absolut) diýip kabul edilýär.', 'hy': "Though people rarely speak in complete sentences, punctuation confers many benefits to the readers of transcribed speech.  Դժբախտաբար, ASR համակարգերի մեծ մասը չի արտադրում կենտրոնացված արտադրություն: Այս խնդիրը լուծելու համար մենք առաջարկում ենք մի լուծում ավտոմատիկ կետավորման համար, որը գնահատականորեն արդյունավետ է և հեշտ է վարժեցնել: Մեր լուծումը օգտակար է վերջին միտումներից, որոնք կատարվում են վերափոխողների հիմնված լեզվի մոդելներում: Մենք նաև փոփոխում ենք այս խնդրի բնորոշ կառուցվածքը' կանխատեսելով հաջորդականությունների, ոչ թե անհատական նշանների կետուցվածքը, ինչը դարձնում է ավելի արդյունավետ ուսումնասիրություն և եզրակացություն: Վերջապես, մենք հայտնաբերեցինք, որ բազմաթիվ կոնտեքստի պատուհանների ընդհանուր կանխատեսումները ավելի ճշգրիտ են բարելավում: Մեր լավագույն մոդելը հասնում է նոր տեխնոլոգիայի վերաբերյալ տվյալների (TED ելույթների) վերաբերյալ միավորված F1-ի հետ, որը կազմում է 48.7 տոկոս հարաբերական զարգացում (15.3 բացարձակ) նախորդ տեխնոլոգիայի վերաբերյալ:", 'az': 'Halbuki insanlar çox az sözlərlə danışırlar, sözləri oxuyanlara çox fayda verir. Necə olaraq, çox ASR sistemləri punctual çıxış yaratmaz. Bunu çəkmək üçün otomatik nöqtələrin çözümünü təklif edirik ki, həm də maliyyətli, həm də çalışmaq üçün asanlıdır. Bizim çətinliyimiz yeni tərzindən istifadə edən transformer dil modellerindən faydalanır. Biz həmçinin bu işin tipik çizgisini təmin edirik, individual işaretlərin yerinə sıralar üçün sıralar təmin edərək, bu işin daha müvəffəqiyyətli təcrübəsi və aşağılıq üçün yaratdığını təmin edirik. Sonunda, çoxlu müxtəlif pəncərələr arasındakı tədbirləri toplamaq daha doğruluğunu daha da artırar. Ən yaxşı modellərimiz, sanatın əvvəlki halında 48,7%-nin qohumluğu (15,3 absolut) ilə birləşdirilmiş rəngli məlumatların yeni bir halına gəlir.', 'bn': 'যদিও মানুষ সম্পূর্ণ শাস্তিতে কমই কথা বলে, ক্ষতিগ্রস্ত ভাষণের পাঠকদের অনেক সুবিধা দেয়। Unfortunately, most ASR systems do not produce punctuated output.  এটা ঠিক করার জন্য আমরা একটি সমাধান প্রস্তাব করি স্বয়ংক্রিয়ভাবে ক্ষতিগ্রস্ত হওয়ার জন্য যা প্রশিক্ষণের জন্য দামের খরচ দক্ সাম্প্রতিক ধারায় আমাদের সমাধানের সুবিধা প্রদান করা হয়েছে সুন্দর পরিবর্তনের ভিত্তিক ভাষার মডেলে। এছাড়াও আমরা এই কাজের সাধারণ ভাঙ্গা পরিবর্তন করি ব্যক্তিগত প্রতীকের পরিবর্তে সাধারণ প্রশিক্ষণ এবং অসুস্থ প্রশিক্ষণের জন্য। শেষ পর্যন্ত, আমরা দেখতে পাচ্ছি যে বেশ কয়েকটি প্রেক্ষিত জানালায় ভবিষ্যদ্বাণী বাড়িয়ে দেওয়া যায়, এমনকি আরো স আমাদের সবচেয়ে ভালো মডেল বেনম্যার্ক ডাটা (টেডি কথা) নতুন পরিস্থিতি অর্জন করেছে যার সাথে ৮৩.', 'bs': 'Iako ljudi rijetko govore u potpunim kaznama, kazna predstavlja mnogo koristi čitačima prepisanog govora. Nažalost, većina ASR sistema ne proizvode punctuirani izlaz. Da bi se ovo riješili, predlažemo rješenje za automatsku tačku koja je i koštanje efikasno i lako trenirati. Naše rješenje koristi od nedavnog trenda u modelima jezika koji se temelji na transformatorima. Također smo izmijenili tipičnu okviru ovog zadatka predviđanjem tačke za sekvence umjesto pojedinačnih znakova, što čini učinkovitijim obukom i infekcijom. Konačno, našli smo da skupljanje predviđanja u višestrukim kontekstskim prozorima i dalje poboljšava preciznost. Naš najbolji model postiže novo stanje umjetnosti na standardnim podacima (TED Talks) sa kombiniranom F1 od 83,9, predstavljajući 48,7% relativno poboljšanje (15,3 apsolutno) u prethodnom stanju umjetnosti.', 'ca': "Malgrat que la gent rarament parle en frases completas, la puntuació dóna molts beneficis als lectors del discurs transcrit. Malauradament, la majoria dels sistemes ASR no produeixen sortida puntuada. Per abordar això, proposem una solució per a la puntuació automàtica que sigui cost-eficient i fàcil d'entrenar. La nostra solució beneficia de la tendència recentdels models de llenguatge basats en transformadors. També modifiquem l'estructura típica d'aquesta tasca predint puntuació per seqüències en comptes de fitxes individuals, i això permet una formació i una inferència més eficients. Finalment, trobem que agregar les prediccions a través de múltiples finestres de context millora encara més la precisió. El nostre millor model aconsegueix un nou avançat en dades de referència (TED Talks) amb un F1 combinat de 83,9, representant una millora relativa del 48,7% (15,3 absolut) sobre l'avançat avançat.", 'cs': 'Ačkoli lidé zřídka mluví v kompletních větách, interpunkce poskytuje čtenářům přepisované řeči mnoho výhod. Bohužel většina ASR systémů nevytváří interpunkovaný výstup. Abychom to řešili, navrhujeme řešení automatické interpunkce, které je nákladově efektivní a snadno trénovatelné. Naše řešení těží z nedávného trendu v jemném ladění jazykových modelů založených na transformátorech. Také modifikujeme typické rámování tohoto úkolu predikcí interpunkce pro sekvence spíše než jednotlivé tokeny, což umožňuje efektivnější trénink a inference. Konečně zjišťujeme, že agregování předpovědí napříč několika kontextovými okny ještě více zvyšuje přesnost. Náš nejlepší model dosahuje nového stavu vývoje referenčních dat (TED Talks) kombinovaným F1 z 83,9, což představuje 48,7% relativní zlepšení (15,3 absolutní) oproti předchozímu stavu techniky.', 'et': 'Kuigi inimesed räägivad harva täielikes lausetes, annab kirjavahemärkimine mitmeid eeliseid transkribeeritud kõne lugejatele. Kahjuks ei tooda enamik ASR-süsteeme täpsustatud väljundit. Selle lahendamiseks pakume välja automaatse vahemärkimise lahenduse, mis on nii kulutõhus kui ka lihtne koolitada. Meie lahendus on kasulik viimasest trendist peenhäälestuse trafodel põhinevate keelemudelite osas. Samuti muudame selle ülesande tüüpilist raamimist, ennustades vahemärki järjestustele, mitte üksikutele märkidele, mis muudab tõhusamaks treeningu ja järelduse. Lõpuks leiame, et prognooside koondamine mitmes kontekstiaknas parandab täpsust veelgi. Meie parim mudel saavutab uue tehnika taseme võrdlusandmete (TED Talks) kombineeritud F1 83,9, mis tähendab 48,7% suhtelist paranemist (15,3 absoluutset) võrreldes eelmise tehnika tasemega.', 'fi': 'Vaikka ihmiset puhuvat harvoin kokonaisina lauseina, välimerkit tuovat monia etuja kirjoitetun puheen lukijoille. Valitettavasti useimmat ASR-järjestelmät eivät tuota pisteytettyä ulostuloa. Tämän ratkaisemiseksi ehdotamme automaattisen välimerkin ratkaisua, joka on sekä kustannustehokas että helppo kouluttaa. Ratkaisumme hyötyy viimeaikaisesta trendistä hienosäätöpohjaisissa kielimalleissa. Lisäksi muokkaamme tämän tehtävän tyypillistä kehystystä ennustamalla välimerkkejä sekvensseille yksittäisten merkkien sijaan, mikä tehostaa harjoittelua ja päättelyä. Lopuksi toteamme, että ennusteiden yhdistäminen useissa konteksti-ikkunoissa parantaa tarkkuutta entisestään. Paras mallimme saavuttaa uuden huipputason benchmark datassa (TED Talks) yhdistettynä F1 on 83,9, mikä edustaa 48,7% suhteellista parannusta (15,3 absoluuttista) edelliseen huippuunsa verrattuna.', 'jv': 'politenessoffpolite"), and when there is a change ("assertive Lalah, sistem sing paling ASR lak bisa ngono punctuation politenessoffpolite"), and when there is a change ("assertive Awakdhéwé kaléh perusahaan nggawe barang nggawe aturan anyar tentang nggawe barang nggawe barang nggawe barang. kéné iso ngubah akeh tipik frame sing nggawe task iki dadi supoyo punctuation kanggo sekondirne dipun ciptaaken sing luwih apik, sing wis nggawe barang nggawe cara-cara sing luwih apik lan ujaran. Lha wih-wih, awak dhéwé ngeremus akeh lanjane kapan sampek sing luwih dumateng kapan sithik. Monday', 'sk': 'Čeprav ljudje redko govorijo v celotnih stavkih, ločila prinašajo bralcem prepisanega govora veliko koristi. Na žalost večina ASR sistemov ne proizvaja ločenega izhoda. Za reševanje tega predlagamo rešitev za avtomatsko ločevanje, ki je stroškovno učinkovita in enostavna za usposabljanje. Naša rešitev koristi od nedavnega trenda v finih transformatorskih jezikovnih modelih. Tipično oblikovanje te naloge spreminjamo tudi tako, da predvidevamo ločila za zaporedja namesto posameznih žetonov, kar omogoča učinkovitejše vadbo in sklepanje. Nazadnje ugotavljamo, da združevanje napovedi v več kontekstnih oknih še bolj izboljša natančnost. Naš najboljši model dosega novo stanje na področju referenčnih podatkov (TED Talks) s kombiniranim F1 83,9, kar predstavlja 48,7% relativno izboljšanje (15,3 absolutnega) v primerjavi s prejšnjim stanjem tehnike.', 'ha': "Haƙĩƙa da mutane bã da saura da su faɗi da cikakkun maganar, musammani yana da amfani mai yawa ga ma'abũta magana. Babu'am, masu yawa na'urar ANR ba su fitar da matsayin da aka saka. To address this, we propose a solution for automatic punctuation that is both cost efficient and easy to train.  Cikakcinmu na da amfani daga tun na farko cikin misãlai na shige da salon mai kyau. Kayya, muna gyarar surori na wannan aikin da Muke yi bayani ga kunnuwa wa'anar mutane ko kuma ba da haske guda ba, wanda ke samu da mafiya tsarin mai fasahan da kafiya. Haƙĩƙa, munã gane cewa ƙaranci kunnuwa da tagogi masu yawa za'a samar da tsari mafi taƙaita. Babu misalinmu na sami wani halin sanar da aka iya samar da data na bangon (TeD Talks) da koma F1 daga 83.9, mai tsakanin 48.7% ya sami mafarinta (15.3 mai tsaro) a kan halin na gabani.", 'bo': 'མི་མང་གིས་རྒྱུན་ལྡན་ཞིག་ཡིན་ནའང་མི་སྐད་ཡིག་ཆ་ནང་དུ་བཤད་ཀྱི་ལེགས་སྣང་མང་པོ་ཞིག་ཡོད། ལྷན་མ་པར། ཡིན་ནའང་མ་ལག་གིས་ཆེ་ཤོས་དུ་punctuation རྩིས་འཁྲུར་བྱེད་མི་ཐུབ། འདི་ལ་གསལ་བཤད་ན། ང་ཚོས་རང་འགུལ་གྱི་གནད་སྡུད་གྱི་ཐབས་ཤེས་གཅིག་སྟོན་ཐུབ་པ་དེ་ལས་སླ་ཡོད་པ ང་ཚོའི་ཐབས་ཤེས་ཀྱི་ཆ་འཕྲིན་དེ་ལྟ་བུའི་འཕེལ་རིམ་ལས་ཕན་ཐོགས་གནང་བ་ཡིན། ང་ཚོས་རྣམ་གྲངས་ཀྱི་ལས་འགུལ་གྱི་སྲོལ་རྒྱུན་གྱི་བཀོད་རིས་དེ་ལས་དབྱེ་རིམ་གྱི་གནད་དོན་རྟགས་མ་མཐུན་བཟོ་བྱེད། མཐའ་མར་དུ། སྔོན་ཚུལ་མང་པོ་ཞིག་གི་སྒེའུ་ཁུང་ཐོག་ནས་མཐུན་རྗེས་མཁན་དུ་འགྱུར་བ་དང་། ང་ཚོའི་མ་དབྱིབས་གཟུགས་རིས་ཀྱི་གནས་སྟངས་གསར་བ་ཞིག་དང་མཉམ་དུ་བསྡད་ཡོད།', 'he': 'Though people rarely speak in complete sentences, punctuation confers many benefits to the readers of transcribed speech.  Unfortunately, most ASR systems do not produce punctuated output.  To address this, we propose a solution for automatic punctuation that is both cost efficient and easy to train.  Our solution benefits from the recent trend in fine-tuning transformer-based language models.  אנחנו גם משנים את המסגרת הטיפוסית של המשימה הזאת על ידי צפייה של נקודת רצפים במקום סימנים בודדים, מה שעושה עבור אימונים ויוצאות יעילים יותר. סוף סוף, אנו מוצאים שהצפיות המאוחדות בחלונות הקשר מרובים משפר את הדיוק עוד יותר. המודל הטוב ביותר שלנו משיג מצב חדש של האמנות על נתוני רמז (TED Talks) עם F1 משולב של 83.9, מייצג שיפור יחסי 48.7% (15.3 מוחלט) על מצב האמנות הקודם.'}
