{'en': 'MAST : Multimodal Abstractive Summarization with Trimodal Hierarchical Attention MAST : Multimodal Abstractive Summarization with Trimodal Hierarchical Attention', 'ar': 'MAST: تلخيص تجريدي متعدد الوسائط مع اهتمام هرمي ثلاثي الوسائط', 'es': 'MAST: Resumen abstractivo multimodal con atención jerárquica trimodal', 'pt': 'MAST: Resumo Abstrativo Multimodal com Atenção Hierárquica Trimodal', 'fr': 'MAST\xa0: Synthèse abstraite multimodale avec attention hiérarchique trimodale', 'ja': 'MAST ：三相階層的な注意を伴う多相抽象的な要約', 'zh': 'MAST:三模态多模态抽摘要', 'ru': 'MAST: Мультимодальное абстрактное обобщение с тримодальным иерархическим вниманием', 'hi': 'मस्तूल: Trimodal पदानुक्रमित ध्यान के साथ मल्टीमॉडल अमूर्त Summarization', 'ga': 'MAST: Achoimre Ilmhódach Teibí le Aird Ordlathach Trimodal', 'ka': 'MAST: მულტიმედიალური აბსტრაქტიური კომპანიზაცია რრიმოდეალური hiერაქტიური დაახლოებით', 'kk': 'MAST: Үш модел гиерархикалық назардағы көптеген абстрактивті тұжырымдамасы', 'lt': 'MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention', 'hu': 'MAST: Multimodális Absztraktív Összefoglalás Trimodális Hierarchikus Figyelemmel', 'el': 'Πολυmodale αφηρημένη Σύνοψη με Τριmodale Ιεραρχική Προσοχή', 'ml': 'MAST: ട്രിമോഡാല്\u200d ഹീരാര്\u200dക്കിക്കല്\u200d ശ്രദ്ധ കൊണ്ട് മള്\u200dമോഡല്\u200d അബ്ട്രാക്ട്രാക്ടിവിന്\u200dറെ ചുരുക്കം', 'mt': 'MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention', 'it': 'MAST: Sintesi astratta multimodale con attenzione gerarchica trimodale', 'ms': 'Perhatian Hierarkik Trimodal', 'no': 'MAST: Multimodal abstraktiv samandrag med trimodal hierarkisk merking', 'mn': 'МАСТ: Олон моделийн абстрактив хэмжээ гурван гиерархик анхаарал', 'sr': 'MAST: Multimodalna abstraktivna sažetka sa trimodalnom hijerarhičkom pažnjom', 'si': 'MAST: ත්\u200dරිමෝඩාල් හියාර්චිකල් අවධානය සමග ග ගොඩක් අවධානය', 'mk': 'MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention', 'pl': 'MAST: Multimodalna abstrakcyjna streszczenie z uwagą hierarchiczną trimodalną', 'sv': 'MAST: Multimodal Abstraktiv Sammanfattning med Trimodal Hierarkisk Uppmärksamhet', 'ta': 'MAST: Trimodal Hierarchical Attention with Multimodal Abstractive Summary', 'ur': 'ماسٹ: ٹریموڈال حیرارشیک حفاظت کے ساتھ بہت سی مڈیل آب تراکٹیو جماریز', 'ro': 'MAST: Rezumat abstractiv multimodal cu atenție ierarhică trimodală', 'so': 'MAST: Multimodal Abstractive Summary with Trimodal Hierarchical Attention', 'uz': 'Name', 'vi': 'Sơ suất đa phương với kính thiên hà ba chiều chú ý', 'bg': 'МАСТ: Мултимодално абстрактивно обобщение с тримодално йерархично внимание', 'da': 'MAST: Multimodal Abstraktiv Resumé med Trimodal Hierarkisk Opmærksomhed', 'hr': 'MAST: Multimodalna abstraktivna sažetka s tromodalnom hijerarskom pažnjom', 'nl': 'MAST: Multimodale abstracte samenvatting met trimodale hiërarchische aandacht', 'de': 'MAST: Multimodale abstrakte Zusammenfassung mit trimodaler hierarchischer Aufmerksamkeit', 'id': 'MAST: Multimodal Abstractive Summarization dengan Trimodal Hierarchical Attention', 'ko': 'MAST: 삼모드 차원 주의가 있는 다중모드 추상 요약', 'fa': 'MAST: جمع\u200cآوری بیش\u200cmodal abstractive with Trimodal Hierarchical Attention', 'sw': 'MAST: Ujumbe wa mfululizo wa kidini na uangalizi wa Taifa', 'af': 'MAST: Multimodal Abstractive Opsomming met Trimodal Hierarchical Aangaande', 'am': 'Multimodal Abstractive Summary with Trimodal Hierarchical Attention', 'tr': 'MAST: Üç modal Hiyerarşik Dikkati ile Çoklumodal Abstraktiv Toplaşum', 'sq': 'MAST: Summarization Multimodal Abstractive with Trimodal Hierarchical Attention', 'hy': 'ՄԱՍՏ. Մոլիմոդալ Աբլաստրատիվ համառոտագրություն, որը ունի Երիմոդալ Հիերախիկ ուշադրություն', 'bs': 'MAST: Multimodalna abstraktivna sažetka sa trimodalnom hijerarhičkom pažnjom', 'az': 'MAST: Trimodal Hierarchical Attention ilə Multimodal Abstractive Summarization', 'bn': 'MAST: ত্রিমোডাল হিরেরার্কিক মনোযোগ দিয়ে বহুমোডাল আবত্ত্রিক সামারিজেশন', 'ca': 'MAST: Resumen Abstractiu Multimodal amb Atenció Hierarquica Trimodal', 'fi': 'MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention', 'cs': 'MAST: Multimodální abstraktní shrnutí s trimodální hierarchickou pozorností', 'et': 'MAST: Multimodaalne abstraktne kokkuvõte koos kolmemodaalse hierarhilise tähelepanuga', 'jv': 'MASTA: Multimodal absolutetraction Cummariation with Trimodal Hiaradical Attention', 'sk': 'MAST: Multimodalni abstraktivni povzetek s trimodalno hierarhično pozornostjo', 'ha': 'KCharselect unicode block name', 'bo': 'MAST: Trimodal Hierarchical Attention', 'he': 'סדרה מורכבת אסטרקטיבית עם תשומת לב הייררכית טרימודלית'}
{'en': 'This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities   text, audio and video   in a multimodal video. Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities. We examine the usefulness and challenges of deriving information from the  audio modality  and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the  model  pay more attention to the text modality. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'ar': 'تقدم هذه الورقة MAST ، نموذج جديد لتلخيص النص التجريدي متعدد الوسائط الذي يستخدم المعلومات من جميع الأساليب الثلاثة - النص والصوت والفيديو - في فيديو متعدد الوسائط. العمل المسبق على تلخيص النص التجريدي متعدد الوسائط استخدم فقط المعلومات من طرائق النص والفيديو. ندرس فائدة وتحديات استخلاص المعلومات من الطريقة الصوتية ونقدم نموذجًا متسلسلًا متسلسلًا هرميًا قائمًا على الاهتمام يتغلب على هذه التحديات من خلال السماح للنموذج بإيلاء مزيد من الاهتمام لطريقة النص. يتفوق MAST على الحالة الحالية للنموذج الفني (نص الفيديو) بمقدار 2.51 نقطة من حيث درجة المحتوى F1 و 1.00 نقطة من حيث درجة Rouge-L على مجموعة بيانات How2 لفهم اللغة متعددة الوسائط.', 'es': 'Este artículo presenta MAST, un nuevo modelo de resumen de texto abstractivo multimodal que utiliza información de las tres modalidades (texto, audio y vídeo) en un vídeo multimodal. Los trabajos anteriores sobre la sumarización de textos abstractivos multimodales solo utilizaban información de las modalidades de texto y video. Examinamos la utilidad y los desafíos de derivar información de la modalidad de audio y presentamos un modelo jerárquico trimodal basado en la atención de secuencia a secuencia que supera estos desafíos al permitir que el modelo preste más atención a la modalidad de texto. MAST supera al modelo actual de vanguardia (video-texto) en 2,51 puntos en términos de puntuación de Content F1 y 1,00 puntos en términos de puntuación Rouge-L en el conjunto de datos How2 para la comprensión multimodal del lenguaje.', 'pt': 'Este artigo apresenta o MAST, um novo modelo de sumarização de texto abstrato multimodal que utiliza informações de todas as três modalidades – texto, áudio e vídeo – em um vídeo multimodal. Trabalhos anteriores sobre sumarização de texto abstrato multimodal utilizaram apenas informações das modalidades de texto e vídeo. Examinamos a utilidade e os desafios de derivar informações da modalidade de áudio e apresentamos um modelo baseado em atenção hierárquica trimodal sequência a sequência que supera esses desafios, permitindo que o modelo preste mais atenção à modalidade de texto. O MAST supera o atual modelo de última geração (vídeo-texto) em 2,51 pontos em termos de pontuação F1 de conteúdo e 1,00 pontos em termos de pontuação Rouge-L no conjunto de dados How2 para compreensão de linguagem multimodal.', 'fr': "Cet article présente MAST, un nouveau modèle de synthèse de texte abstrait multimodal qui utilise des informations provenant des trois modalités — texte, audio et vidéo — dans une vidéo multimodale. Les travaux antérieurs sur la synthèse de textes abstraits multimodaux n'utilisaient que les informations provenant des modalités texte et vidéo. Nous examinons l'utilité et les défis liés à la dérivation d'informations à partir de la modalité audio et présentons un modèle hiérarchique trimodal basé sur l'attention séquence-à-séquence qui surmonte ces défis en laissant le modèle accorder plus d'attention à la modalité texte. MAST surpasse le modèle actuel de pointe (vidéo-texte) de 2,51 points en termes de score Content F1 et de 1,00 point en termes de score Rouge-L sur le jeu de données How2 pour la compréhension multimodale des langues.", 'ja': '本稿では、マルチモーダルビデオにおいて、テキスト、オーディオ、ビデオの3つのモダリティすべてからの情報を利用する、マルチモーダル抽象的テキスト要約の新しいモデルであるMASTを紹介する。マルチモーダル抽象的テキストの要約に関する以前の仕事は、テキストおよびビデオモードからの情報のみを利用していた。私たちは、オーディオモダリティから情報を導き出すことの有用性と課題を検討し、モデルがテキストモダリティにより注意を払うことによって、これらの課題を克服するシーケンスツーシーケンスのトリモーダル階層的注意ベースのモデルを提示します。MASTは、マルチモーダル言語の理解のために、コンテンツF 1スコアで2.51ポイント、How 2データセットのRouge - Lスコアで1.00ポイント、現在の最先端モデル（ビデオテキスト）を上回る。', 'zh': '本文言MAST,此多模态象摘要之新模也,可于多模态视频中利用三文(本,音频视频)信息。 前此多模抽象摘要惟用文本及视频文信息。 论音频模态之有用性挑战性者获取信息,为次第之三模态以为形势,使模形多模态以胜之。 多模态言解者How2数集上,MAST先F1得分者(视频文本)高2.51分,Rouge-L得分先1.00分。', 'hi': 'यह पेपर MAST प्रस्तुत करता है, मल्टीमॉडल अमूर्त पाठ सारांशीकरण के लिए एक नया मॉडल जो सभी तीन तौर-तरीकों से जानकारी का उपयोग करता है - पाठ, ऑडियो और वीडियो - एक बहुआयामी वीडियो में। Multimodal abstractive text summarization पर पहले का काम केवल पाठ और वीडियो तौर-तरीकों से जानकारी का उपयोग करता है। हम ऑडियो रूपरेखा से जानकारी प्राप्त करने की उपयोगिता और चुनौतियों की जांच करते हैं और एक अनुक्रम-से-अनुक्रम ट्राइमोडल पदानुक्रमित ध्यान-आधारित मॉडल प्रस्तुत करते हैं जो मॉडल को पाठ पद्धति पर अधिक ध्यान देकर इन चुनौतियों को दूर करता है। MAST सामग्री F1 स्कोर के संदर्भ में 2.51 अंक और मल्टीमॉडल भाषा की समझ के लिए How2 डेटासेट पर रूज-एल स्कोर के संदर्भ में 1.00 अंकों द्वारा कला मॉडल (वीडियो-टेक्स्ट) की वर्तमान स्थिति को मात देता है।', 'ru': 'В этой статье представлена МАЧТА, новая модель для мультимодального абстрактного текстового суммирования, которая использует информацию из всех трех способов – текста, аудио и видео – в мультимодальном видео. В предыдущей работе по мультимодальному абстрактному обобщению текста использовалась только информация из текстовых и видеомодулей. Мы изучаем полезность и проблемы извлечения информации из аудиомодальности и представляем тримодальную иерархическую модель, основанную на иерархическом внимании, которая преодолевает эти проблемы, позволяя модели уделять больше внимания текстовой модальности. MAST опережает текущую современную модель (видеотекст) на 2,51 балла по оценке Content F1 и на 1,00 балла по оценке Rouge-L в наборе данных How2 для мультимодального понимания языка.', 'ga': 'Cuireann an páipéar seo i láthair MAST, samhail nua le haghaidh Achoimriú Ilmhódúil Téacs Teibí a úsáideann faisnéis ó na trí mhódúlacht - téacs, fuaime agus físe - i bhfíseán ilmhódach. Níor úsáideadh réamhobair ar achoimriú téacs ilmhódach teibí ach amháin as faisnéis ó na módúlachtaí téacs agus físe. Scrúdaímid a úsáidí agus na dúshláin a bhaineann le faisnéis a fháil ón modhúlacht fuaime agus cuirimid i láthair múnla ordlathach aird-bhunaithe triantánach seicheamh-go-seicheamh a sháraíonn na dúshláin seo trí ligean don mhúnla aird níos mó a thabhairt ar mhodhúlacht an téacs. Tá 2.51 pointe níos fearr ag MAST ná an tsamhail úrscothach (fístéacs) i dtéarmaí scór Ábhar F1 agus 1.00 pointe i dtéarmaí scór Rouge-L ar thacar sonraí How2 maidir le tuiscint teanga ilmhódach.', 'ka': 'ამ დოკუმენტი MAST- ს ახალი მოდელი მულტიმოდიალური აბსტრაქტიგური ტექსტის კომპანიზაციაში, რომელიც ყველა სამი მოდიალური ინფორმაციის გამოყენება - ტექსტი, ასეთო და ვიდეო -  მულტიმოდიალური აბსტრაქტიური ტექსტის კუნძიზაციაზე მხოლოდ ტექსტის და ვიდეო მოდილიტების გამოყენებული ინფორმაცია. ჩვენ აუდიო მოდიალობიდან ინფორმაციის გამოიყენება და გამოსახულებების გამოყენება და აუდიო მოდიალობიდან მივიღეთ სიკეცემალური თერაქტიკური ინფორმაციის მოდელი, რომელიც ამ გამოსახულებების გამოსახულება, რომელი MAST მოდელის მიმდინარე სტატის მოდულის (ვიდეო- ტექსტის) სტატის განმავლობაზე 2. 51 წერტილით Content F1 წერტილის და 1. 00 წერტილის განმავლობაში Rouge- L წერტილის განმავლობაში How2 მონაცემების მონაცემების მოდულებ', 'hu': 'A tanulmány bemutatja a MAST-t, a multimodális absztraktív szövegösszefoglaló új modelljét, amely mindhárom módszerből származó információkat használ fel multimodális videóban. A multimodális absztraktív szövegösszefoglalással kapcsolatos korábbi munkák kizárólag a szövegből és a videóból származó információkat használták fel. Vizsgáljuk az audiomódszerből származó információk hasznosságát és kihívásait, és bemutatunk egy szekvenciás, hierarchikus figyelem-alapú trimodális modellt, amely ezeket a kihívásokat leküzdi azzal, hogy a modell nagyobb figyelmet fordít a szövegmódszerre. A MAST 2,51 ponttal haladja meg a jelenlegi korszerű modellt (videó-szöveg) az F1 tartalom és 1,00 ponttal a Rouge-L pontszám tekintetében a How2 adatkészleten a multimodális nyelvértés érdekében.', 'el': 'Η παρούσα εργασία παρουσιάζει ένα νέο μοντέλο για την Πολυmodale Περίληψη Κειμένου που χρησιμοποιεί πληροφορίες και από τις τρεις λειτουργίες του κειμένου, του ήχου και του βίντεο σε ένα πολυμοδικό βίντεο. Προηγουμένες εργασίες για την πολυπροπική αφηρημένη σύνοψη κειμένου χρησιμοποιούσαν μόνο πληροφορίες από τις λεπτομέρειες κειμένου και βίντεο. Εξετάζουμε τη χρησιμότητα και τις προκλήσεις της απόκτησης πληροφοριών από την ακουστική τροπικότητα και παρουσιάζουμε ένα τριμοντικό ιεραρχικό μοντέλο που βασίζεται στην προσοχή ακολουθίας-ακολουθίας που ξεπερνά αυτές τις προκλήσεις αφήνοντας το μοντέλο να δώσει μεγαλύτερη προσοχή στην τροπικότητα κειμένου. Το MAST ξεπερνά το σημερινό μοντέλο (βίντεο-κείμενο) κατά 2.51 πόντους όσον αφορά την βαθμολογία περιεχομένου F1 και 1.00 πόντους όσον αφορά την βαθμολογία Rouge-L στο σύνολο δεδομένων How2 για την κατανόηση της πολυμορφικής γλώσσας.', 'it': "Questo articolo presenta MAST, un nuovo modello di sintesi multimodale del testo astratto che utilizza informazioni provenienti da tutte e tre le modalità - testo, audio e video - in un video multimodale. I lavori precedenti sulla sintesi multimodale astratta del testo utilizzavano solo informazioni provenienti dalle modalità testuali e video. Esaminiamo l'utilità e le sfide di ricavare informazioni dalla modalità audio e presentiamo un modello gerarchico di attenzione trimodale sequenza-sequenza che supera queste sfide lasciando che il modello presti maggiore attenzione alla modalità testuale. MAST supera lo stato dell'arte attuale del modello (video-testo) di 2,51 punti in termini di punteggio Content F1 e di 1,00 punti in termini di punteggio Rouge-L sul set di dati How2 per la comprensione multimodale della lingua.", 'kk': 'Бұл қағаз MAST, көпModal Абстрактивті мәтін тұжырымдамасының жаңа үлгісін көрсетеді. Бұл көпModal видеонда мәліметті - мәтін, аудио және видео - барлық үш әдістерден қолданаты Көптеген абстрактивті мәтін тұжырымдамасындағы алдыңғы жұмыс тек мәтін мен видео әдістерінен қолданылған мәліметтер. Мәліметті аудио модулінен алу үшін пайдаланушы мен өзгерістерді тексереміз және реттеу үшін тримодалдық иерархиялық түрінде негізделген үлгісін таңдаймыз. Бұл өзгерістерді өзгерту үшін модулінің мәтін модулін MAST Сурет үлгісінің қазіргі күйі (видео- мәтін) 2. 51 нүкте Content F1 нүктесі мен 1. 00 нүкте бірнеше тілді ойлау үшін How2 деректер жиынындағы Rouge- L нүктесі жоғарылады.', 'lt': 'This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Ankstesniame daugiarūšio pobūdžio abstrakcinio teksto santraukos darbe buvo naudojama tik teksto ir vaizdo būdų informacija. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'mt': 'Dan id-dokument jippreżenta MAST, mudell ġdid għas-Sommarju tat-Test Abstrattiv Multimodali li juża l-informazzjoni mit-tliet modalitajiet kollha - test, awdjo u vidjo - f’vidjo multimodali. Ħidma preċedenti dwar is-sommarju tat-test astrattiv multimodali użat biss informazzjoni mit-test u l-modalitajiet tal-vidjo. Aħna teżamina l-utilità u l-isfidi tad-derivazzjoni tal-informazzjoni mill-modalità awdjo u nippreżentaw mudell trimodali b’sekwenza għal sekwenza bbażat fuq l-attenzjoni ġerarkika li jegħleb dawn l-isfidi billi l-mudell jitħalla jagħti aktar attenzjoni lill-modalità tat-test. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'mk': 'Овој документ претставува MAST, нов модел за мултимодилна апстрактивна резултатација на текстот кој користи информации од сите три модели - текст, аудио и видео - во мултимодилно видео. Претходната работа за мултимодална апстрактивна резултатација на текстот користеше само информации од текстот и видео моделите. Ние ја испитуваме корисноста и предизвиците од извлекувањето информации од аудио модијалноста и претставуваме тримодален хиерархички модел базиран на секвенца на внимание кој ги надминува овие предизвици со дозвола моделот да привлече поголемо внимание на текстот модијалноста. МАСТ го надминува сегашниот најнов модел (видео-текст) за 2,51 поени во поглед на резултатот на Содржината F1 и 1,00 поени во поглед на резултатот на Руџ-Л на податоците How2 за мултимодилно разбирање на јазикот.', 'mn': 'Энэ цаас MAST-г олон моделийн бичлэгээс мэдээллийг хэрэглэдэг олон моделийн Abstractive Text Summarization-ийн шинэ загвар болгодог. Бид олон моделийн абстрактив текст цуглуулалт дээр өмнөх ажил зөвхөн текст болон видео хувилбараас хэрэглэгдсэн мэдээлэл. Бид аудио хувилбараас мэдээллийг гаргах хэрэгтэй болон сорилтуудыг шалгаж, дарааллаар дарааллаар давтагдсан гурван төрлийн анхаарал төвлөрүүлэх загварыг илүү анхаарлаа хандуулж, эдгээр сорилтуудыг даван авч, загварыг текст хувилбарт илүү анха MAST Урлагийн загварын орчин үеийг 2.51 цэгээр үржүүлдэг. Content F1 score болон 1.00 цэгээр олон модель хэлний ойлголтын How2 өгөгдлийн сангийн тоо хэлбэрээр Rouge-L score дээр гаргадаг.', 'ms': 'Kertas ini memperkenalkan MAST, model baru untuk Penapisan Teks Abstratif Multimodal yang menggunakan maklumat dari semua tiga modaliti - teks, audio dan video - dalam video multimodal. Kerja terdahulu pada pengringkasan teks abstraktif multimodal hanya digunakan maklumat dari modaliti teks dan video. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'ml': 'ഈ പത്രത്തില്\u200d മൂന്നു രീതികളില്\u200d നിന്നും വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്ന എല്ലാ വിവരങ്ങളില്\u200d നിന്നും മുള്\u200dട്ടിമോഡല്\u200d അബ്ട്രാക്ട്രാക്ടിവിന്റെ പു പദാവലിയും വീഡിയോ മോഡിറ്റുകളില്\u200d നിന്നും വിവരങ്ങളില്\u200d നിന്നും ഉപയോഗിക്കുന്ന വിവരങ്ങള്\u200d മുമ്പുള്ള ജോലി ഓഡിയോ മോഡിയില്\u200d നിന്നും വിവരങ്ങള്\u200d ലഭ്യമാക്കുന്നതിന്റെ ഉപയോഗവും വ്യാല്\u200dക്രവങ്ങളും ഞങ്ങള്\u200d പരിശോധിക്കുന്നു. ട്രിമോണിക്ക് ട്രിമോഡാല്\u200d ഹിയെരാര്\u200dക്കിക്കല മുള്\u200dട്ടിമോഡാല്\u200d എഫ്1 സ്കോരും 1. 00 പോയിന്റുകളും ഹൌ2 ഡാറ്റാസ്റ്റേറ്റ് ഗ്രഹിക്കുന്നതിനുള്ള മാതൃകയില്\u200d നിലവിലുള്ള സ്ഥിതിയില്\u200d 2. 51 പോയിന്റുകള്\u200d 2. 51 പ', 'ro': 'Această lucrare prezintă MAST, un nou model de Rezumare Multimodală a Textului Abstractiv care utilizează informații din toate cele trei modalități - text, audio și video - într-un video multimodal. Lucrările anterioare privind rezumarea textului multimodal abstractiv utilizează doar informații din modalitățile text și video. Examinăm utilitatea și provocările obținerii informațiilor din modalitatea audio și prezentăm un model ierarhic secvență la secvență bazat pe atenție trimodală, care depășește aceste provocări permițând modelului să acorde mai multă atenție modalității text. MAST depășește modelul actual de ultimă generație (video-text) cu 2,51 puncte în ceea ce privește scorul F1 conținut și 1,00 puncte în ceea ce privește scorul Rouge-L pe setul de date How2 pentru înțelegerea limbilor multimodale.', 'pl': 'W artykule przedstawiono MAST, nowy model multimodalnego podsumowania tekstu abstrakcyjnego, który wykorzystuje informacje ze wszystkich trzech modalności tekstu, audio i wideo w multimodalnym wideo. Wcześniejsze prace nad multimodalną abstrakcyjną streszczeniem tekstu wykorzystywały jedynie informacje z modalności tekstu i wideo. Badamy przydatność i wyzwania związane z pozyskiwaniem informacji z modalności audio i przedstawiamy trimodalny model oparty na uwadze sekwencji na hierarchicznym modelu, który pokonuje te wyzwania poprzez pozwolenie modelowi zwrócić większą uwagę na modalność tekstową. MAST przewyższa aktualny model (wideo-tekst) o 2,51 punkty pod względem wyniku Content F1 oraz 1,00 punkty pod względem wyniku Rouge-L na zbiorze danych How2 dla zrozumienia języka multimodalnego.', 'so': "Warqaddaas wuxuu MAST, model cusub oo u qoran qoraalka hoose-dhexe ee multimodal Abstractive, kaas oo macluumaadka ka isticmaalaya saddexda qaab oo dhan - text, audio iyo fiidiyo ah fiidiyo badan. Shaqo horay ah oo ku saabsan qoraalka la'aanta oo kala duduwan oo la isticmaalay macluumaad la isticmaalay qoraalka iyo fiidiyowga. Waxaan baaraynaa faa'iidada iyo dhibaatooyin ku saabsan helitaanka macluumaadka qaababka codka, waxaana keenaynaa model aad u fiirsaneyso marxaladda hierarchiga ah oo ka adkaysanaya dhibaatooyinkaas si aad u fiirsato qaababka qoraalka. MAST wuxuu ku soo bandhigaa xaaladda muusikada farshaxanka (fiidiyo-text) 2.51 barxad oo ku qoran kooxda F1 iyo 1.00 barxad oo lagu qorayo kooxda Rouge-L ee kooxda aqoonta luuqada kala duduwan ee How2.", 'sv': 'Denna uppsats presenterar MAST, en ny modell för multimodal abstraktiv textsammanfattning som använder information från alla tre modaliteterna - text, ljud och video - i en multimodal video. Tidigare arbete med multimodal abstraktiv textsammanfattning utnyttjade endast information från text- och videomodaliteter. Vi undersöker nyttan och utmaningarna med att härleda information från ljudmodaliteten och presenterar en sekvens-till-sekvens trimodal uppmärksamhetsbaserad modell som övervinner dessa utmaningar genom att låta modellen ägna mer uppmärksamhet åt textmodaliteten. MAST överträffar den nuvarande toppmoderna modellen (video-text) med 2,51 poäng när det gäller Content F1 poäng och 1,00 poäng när det gäller Rouge-L poäng på How2 datauppsättningen för multimodal språkförståelse.', 'ta': 'இந்த தாள் MAST, ஒரு புதிய மாதிரியை கொடுக்கும் பல மாதிரி Abstractive Text சுருக்கமாக்கும் அது அனைத்து மூன்று வகைகளிலிருந்தும் தகவலை பயன்படுத்துகிறது -  பலவிதமான செயல்பாடு உரை சுருக்கம் மட்டும் உரை மற்றும் வீடியோ வகைகளிலிருந்து பயன்படுத்தப்பட்ட தகவல் முன்னிருப்பு பணி கேட்பொலி வகையிலிருந்து தகவல் பெறுவதற்கான பயன்பாட்டுகளையும் சவால்களையும் நாம் பரிசோதிக்கிறோம் மற்றும் ஒரு வரிசையில் இருந்து மூன்று தொடர்ந்து மூன்று ம MAST தற்போதைய கலைப்பாட்டு மாதிரியின் தற்போதைய நிலையை 2. 51 புள்ளிகளால் செயல்படுத்தும் உள்ளடக்க F1 மதிப்பு மற்றும் 1. 00 புள்ளி', 'sr': 'Ovaj papir predstavlja MAST, novi model za sažetak multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom video. Prije rad na sažetku multimodalnog abstraktivnog teksta korišteno je samo informacije iz teksta i video modaliteta. Ispitujemo korisnost i izazove izvlačenja informacija iz audio modaliteta i predstavljamo sekvencu trimodalnog hijerarhičkog model a baziranog na sekvenci, koji prevlada te izazove tako što omogućavamo model da obratite više pažnje na tekstualnu modalitetu. MAST iznosi trenutno stanje umjetničkog modela (video-tekst) sa 2,51 poena u smislu rezultata Content F1 i 1,00 poena u smislu rezultata Rouge-L na setu podataka How2 za razumevanje multimodalnog jezika.', 'no': 'Denne papiret viser MAST, eit ny modell for multimodal abstraktiv tekstsamandrag som brukar informasjon frå alle tre modular – tekst, lyd og video – i eit multimodal video. Førre arbeid på multimodal abstraktiv tekstsammendering er berre brukt informasjon frå teksten og videomodusane. Vi undersøker nødvendigheten og utfordringar for å få informasjon frå lyd-modulitet og presenterer ein trimodal hierarkisk oppmerksbasert modell som overfører desse utfordringane ved å la modellen få meir oppmerksomhet til tekstmodulitet. MAST utfører den gjeldande tilstanden til kunstmodellen (video-tekst) med 2,51 punkt i forhold til innhaldet F1- poeng og 1,00 punkt i forhold til Rouge- L- poeng på How2- datasettet for multimodal språksforståelse.', 'ur': 'This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that uses information from all three modalities - text, audio and video - in a multimodal video. multimodal abstractive text summarization پر پہلے کام صرف متن اور ویڈیو موڈلیٹ سے استعمال کی جاتی ہے. ہم آڈیو موڈلیٹ سے اطلاعات اٹھانے کے کامیابی اور چالوں کے مطابق تحقیق کرتے ہیں اور آڈیو موڈلیٹ سے اٹھانے کے لئے تیموڈالی توجه کی مدل کو پیش کرتے ہیں جو ان چالوں پر غالب آتا ہے اور مدل کو متن موڈلیٹ کے لئے زیادہ توجه کرنا اجازت دیتے ہیں. MAST آرت موڈل (ویڈیو-ٹکسٹ) کی موجود موجود موجود موجود کو 2.51 پوینٹ کے مطابق موجود F1 پوینٹ اور 1.00 پوینٹ کے مطابق موجود زبان سمجھنے کے لئے Hauge-L پوینٹ کے مطابق موجود موجود ہے.', 'si': 'මේ පැත්ත MAST වෙනුවෙන්, අළුත් මොඩියෝල් අවස්ථාවක් පැත්තක් සංවේදනය සඳහා අළුත් මොඩියෝල් එකක් පෙනුවෙන් පෙනුවෙන් ති පාළුවන් සහ විඩියෝ මොඩියෝල් විධානයෙන් විතරයි ප්\u200dරභාවිත විතරයි. අපි ප්\u200dරයෝජනය සහ අවධානය පරීක්ෂා කරනවා ඔඩියෝ මෝඩියෝලියෙන් තොරතුරු ගන්න සහ ප්\u200dරයෝජනය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ත්\u200dරිමෝඩාල MAST ප්\u200dරස්තූති විද්\u200dයාත්මක (විඩියෝ- පාට්ස්) 2.51 පින්තුවක් වලින් විද්\u200dයාත්මක F1 ස්කෝර් වලින් සහ 1.00 පින්තුවක් වලින් Rouge- L ස්කෝර් වලි', 'vi': 'Tờ giấy này giới thiệu MAST, một mô hình mới cho Sơ sài Văn bản đa phương, dùng thông tin từ ba phương thức - văn bản, âm thanh và video- trong một đoạn video đa phương. Việc tổng hợp văn bản trừu tượng đa phương chỉ sử dụng thông tin từ phương thức văn bản và đoạn video. Chúng tôi xem xét sự hữu ích và thử thách của việc lấy thông tin từ chế độ âm thanh và trình bày một mô hình cấp độ phân cấp cấp ba phân loại theo quy trình sắp xếp phân loại để vượt qua những thử thách này bằng cách để mô hình chú ý nhiều hơn đến kiểu văn bản. MAST thực hiện hiện hiện trạng thái hiện thời của mô hình nghệ thuật (đoạn video) bởi 2.51 Point theo như vẫn còn trong nội dung F1.00 theo giá trị ghi số Rouge-L trên tập tin Howl2 để hiểu ngôn ngữ đa phương.', 'uz': "This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Name Biz audio modulidan maʼlumotni olish uchun foydalanuvchi va muammolarni tekshirib ko'rib chiqaramiz va bu muammolarni matn moduliga qo'llash mumkin, bu muammolarni oshirish mumkin. MAST multimodal tilni tushunish uchun Joriy sanam modeli (video- text) 2. 51 нуқтаи bilan ishga tushiriladi.", 'nl': 'Deze paper presenteert MAST, een nieuw model voor multimodale abstracte tekstsamenvatting dat informatie uit alle drie de modaliteiten van tekst, audio en video in een multimodale video gebruikt. Voorafgaand werk aan multimodale abstracte tekstsamenvatting gebruikte alleen informatie uit de tekst- en videomodaliteiten. We onderzoeken het nut en de uitdagingen van het afleiden van informatie uit de audiomodaliteit en presenteren een sequentie-to-sequence trimodaal hiërarchisch aandachtsgebaseerd model dat deze uitdagingen overwinnt door het model meer aandacht te laten besteden aan de tekstmodaliteit. MAST overtreft het huidige state-of-the-art model (video-tekst) met 2.51 punten in termen van Content F1 score en 1.00 punten in termen van Rouge-L score op de How2 dataset voor multimodaal taalbegrip.', 'bg': 'Настоящата статия представя нов модел за мултимодално абстрактивно обобщаване на текста, който използва информация от трите модала - текст, аудио и видео - в мултимодално видео. Предишната работа по мултимодалното абстрактно обобщаване на текста използва само информация от текстовите и видео модалите. Проучваме полезността и предизвикателствата при извличането на информация от аудио модалността и представяме тримодален йерархичен модел последователност към последователност, базиран на вниманието, който преодолява тези предизвикателства, като позволява на модела да обърне повече внимание на текстовия модал. МАСТ превъзхожда съвременния модел (видео-текст) с 2.51 точки по отношение на резултата Съдържание 1 и 1.00 точки по отношение на резултата Руж-Л в набора данни за мултимодално разбиране на езика.', 'hr': 'Ovaj papir predstavlja MAST, novi model za sažetak multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom snimku. Prije rad na sažetku multimodalnog abstraktivnog teksta korišteno je samo informacije iz teksta i video modaliteta. Provjeravamo korisnost i izazove izvlačenja informacija iz zvukovnog modaliteta i predstavljamo trimodalni model na osnovu tri modalne hijerarhijske pažnje koji prevlada te izazove tako što omogućavamo model obratiti više pažnje na modalitet teksta. MAST iznosi trenutno stanje umjetničkog modela (video-teksta) za 2,51 bodova u smislu rezultata Content F1 i 1,00 bodova u smislu rezultata Rouge-L na kompletu How2 podataka za razumijevanje multimodalnog jezika.', 'de': 'Dieser Beitrag stellt MAST vor, ein neues Modell für multimodale abstrakte Textzusammenfassung, das Informationen aus allen drei Modalitäten Text, Audio und Video in einem multimodalen Video nutzt. Bisherige Arbeiten zur multimodalen abstraktiven Textzusammenfassung nutzten ausschließlich Informationen aus den Text- und Videomodalitäten. Wir untersuchen die Nützlichkeit und Herausforderungen der Ableitung von Informationen aus der Audiomodalität und stellen ein sequenz-zu-sequenz trimodales hierarchisches aufmerksamkeitsbasiertes Modell vor, das diese Herausforderungen überwindet, indem das Modell mehr Aufmerksamkeit auf die Textmodalität lenkt. MAST übertrifft den aktuellen Stand der Technik Modell (Video-Text) um 2,51 Punkte in Bezug auf Content F1 Score und 1,00 Punkte in Bezug auf Rouge-L Score auf dem How2 Datensatz für multimodales Sprachverständnis.', 'da': 'Denne artikel præsenterer MAST, en ny model for multimodal abstraktiv tekst summering, der bruger information fra alle tre modaliteter - tekst, lyd og video - i en multimodal video. Tidligere arbejde med multimodal abstraktiv tekst resuméering anvendte kun oplysninger fra tekst og video modaliteter. Vi undersøger nytten og udfordringerne ved at udlede information fra lydmodaliteten og præsenterer en sekvens-til-sekvens trimodal hierarkisk opmærksomhedsbaseret model, der overvinder disse udfordringer ved at lade modellen være mere opmærksom på tekstmodaliteten. MAST overgår den aktuelle state of te art model (video-tekst) med 2,51 point i form af Content F1 score og 1,00 point i form af Rouge-L score på How2 datasættet til multimodal sprogforståelse.', 'id': 'Kertas ini mempersembahkan MAST, model baru untuk Penapisan Teks Abstraktif Multimodal yang menggunakan informasi dari tiga modalitas - teks, audio dan video - dalam video multimodal. Pekerjaan sebelumnya pada penghasilan teks abstraktif multimodal hanya menggunakan informasi dari modalitas teks dan video. Kami memeriksa kebaikan dan tantangan untuk mendapatkan informasi dari modalitas audio dan mempersembahkan model berkurunan-ke-urutan yang berdasarkan perhatian trimodal yang mengatasi tantangan-tantangan ini dengan membiarkan model memperhatikan modalitas teks lebih banyak. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'fa': 'این کاغذ MAST را نشان می\u200cدهد، یک مدل جدید برای جمع کردن متن آب\u200cتراکتی چندیmodal که اطلاعات را از همه سه حالت - متن، صدا و ویدئو - در یک ویدئو چندیmodal استفاده می\u200cکند. کارهای پیشینه روی جمع کردن متن متن چندmodal abstractive تنها اطلاعات استفاده از متن و modalities ویدئو استفاده می\u200cشود. ما مطالبی و چالش\u200cهای استفاده از دسترسی اطلاعات از مدل صدا را تحقیق می\u200cکنیم و یک مدل توجه به مدل سه مدل از مدل\u200cهای مختلف به عنوان مدل توجه به مدل متن را پیشنهاد می\u200cکنیم که این چالش\u200cها را از دست می\u200cدهد، با اجازه دادن مدل توجه بیشتری به مدل مت MAST موقعیت فعلی مدل هنر (ویدئو-متن) با 2.51 نقطه به عنوان نقطه محتوای F1 و 1.00 نقطه به عنوان نقطه\u200cای Rouge-L بر روی مجموعه داده\u200cهای How2 برای درک زبان\u200cهای متعددی بیشتر انجام می\u200cدهد.', 'ko': '본고는 다중모드 추상적 텍스트 요약 모델인 MAST를 제시했는데 다중모드 영상의 모든 세 가지 모드(텍스트, 오디오, 영상)의 정보를 이용했다.이전에 다중모드 추상적인 텍스트 요약에 대한 작업은 텍스트와 영상 모드의 정보만 이용했다.우리는 오디오 모드에서 정보를 추출하는 유용성과 도전을 연구했고 서열을 바탕으로 하는 삼모드 차원 주의 모델을 제시했다. 이 모델은 모델이 텍스트 모드에 더욱 관심을 가지게 함으로써 이러한 도전을 극복한다.다중모드 언어 이해에 사용되는 How2 데이터 집합에서 MAST는 콘텐츠 F1 득점 면에서 현재 가장 선진적인 모델(영상 텍스트)보다 2.51점, Rouge-L 득점 면에서 현재보다 1.00점 높았다.', 'sw': 'Makala hii inaonyesha MAST, mfano mpya kwa ajili ya Ujumbe wa Matambo ya Kimulmodal Abstractive unaotumia taarifa kutoka katika a in a tatu - maandishi, sauti na video - katika video mbalimbali. Kazi ya awali kuhusu muhtasari wa ujumbe wa maandishi yasiyo na maandishi mengi yaliyotumika tu kwa kutumia taarifa kutoka kwenye njia za maandishi na video. Tunajaribu matumizi na changamoto za kupata taarifa kutoka katika mfumo wa sauti na kuweka muundo wa ufuatiliaji wa mifumo ya mitatu kwa mfululizo ambao unashinda changamoto hizi kwa kuruhusu model kusikiliza zaidi kwa namna ya maandishi. MAST inaonyesha hali ya sasa ya muundo wa sanaa (ujumbe wa video-text) kwa pointi 2.51 kwa maana ya score F1 na pointi 1.00 kwa mujibu wa score ya Rouge-L kwenye seti ya data ya How2 kwa ajili ya kuelewa lugha nyingine.', 'tr': "Bu käze MAST'i, Multimodal Abstraktiw Metin Toplaýyşy üçin täze bir nusga görkezýär ki bu multimodal wideoda maglumat ullanýar. Multimodal abstraktiv metin holasasy üstünde öňki işlem diňe metin we video modlerden ullanýar Biz ses modalitatyndan informasiýa çykarmak üçin ullanlygyny we çözgütlerini barlaýarys we bu kynçylyklaryň üstüne çykan trimodal iýerarhiýa tabanly nusgasyny çykarýarys we modaliýasyna köp üns ber. MAST sanat düzümleriniň häzirki durumyny 2.51 puç diýipdir. Mazmunlar F1 अ'da we 1.00 puç diýipdir.", 'am': 'ይህ ገጽ አዲስ የፊደል አዲስ ምሳሌ ለመብሎዶል Abstractive ጽሑፍ ማጠቃለያ ነው፡፡ የጽሑፍ እና የቪዲዮ ድርጅቶች በተጠቃሚ የጽሑፍ ማስታወሻ ብቻ ነው፡፡ የድምፅ አካባቢ መረጃዎችን ለማግኘት ጥቅም እና ውቀቶችን እናፈትናለን፡፡ የፊደል ቅርጽ', 'sq': 'Ky dokument paraqet MAST, një model i ri për përmbledhjen e tekstit abstraktiv multimodal që përdor informacionin nga të tre modalitetet - teksti, audio dhe video - në një video multimodal. Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities.  Ne shqyrtojmë dobinë dhe sfidat e marrjes së informacionit nga modaliteti audio dhe paraqesim një model trimodal sekuencë-në-sekuencë të bazuar në vëmendjen hierarkike që i kapërcen këto sfida duke lejuar modelit të kushtojë më shumë vëmendje modalitetit të tekstit. MAST ekzekuton gjendjen aktuale të modelit të artit (video-text) me 2.51 pikë lidhur me pikën e përmbajtjes F1 dhe 1.00 pikë lidhur me pikën e kuqe-L në kompletin e të dhënave How2 për kuptimin multimodal të gjuhës.', 'af': "Hierdie papier vertoon Mast, 'n nuwe model vir Multimodal Abstractive Teks Opsomming wat inligting gebruik van alle drie modaliteite - teks, oudio en video - in 'n multimodaal video. Vorige werk op multimodale abstraktiewe teks opsomming slegs gebruikte inligting van die teks en video modaliteite. Ons ondersoek die bruikbaarheid en uitdagings van afgeleide inligting van die oudio modaliteit en voorsien 'n volgorde-na-volgorde trimodaal hierarkiese aandag-gebaseerde model wat hierdie uitdagings oorwin deur die model meer aandag aan die teks modaliteit te laat maak. Mas uitvoer die huidige staat van die kuns model (video- text) deur 2. 51 punte in terms van Inhoud F1 telling en 1. 00 punte in terms van Rouge- L telling op die How2 datastel vir multimodale taal verstanding.", 'hy': 'Այս հոդվածը ներկայացնում է MASTA-ը, մի նոր մոդել, որը օգտագործում է բազմամոդալ վերացական տեքստի համառոտացման համար տեղեկատվությունը բոլոր երեք մոդելներից՝ տեքստից, ձայնից և տեսահոլովակից, բազմամոդալ տեսահոլովակում: Անցյալ աշխատանքը բազմամոդալ վերացական տեքստի համառոտագրման վրա օգտագործեց միայն տեքստի և տեսագրական մեթոդների տեղեկատվությունը: Մենք ուսումնասիրում ենք հնչյունների միջոցով տեղեկատվության ստանալու օգտակարությունը և մարտահրավերները և ներկայացնում ենք հաջորդականությունից հաջորդականություն առնող տրամոդային հիերարխիկ ուշադրության հիմնված մոդել, որը հաղթահարում է այս մարտահրավերները, թույլ տալով մոդելը ավելի ու MASTA-ն արտադրում է ներկայիս ամենահարվեստի մոդելը (տեսագրական տեքստը) 2.51 միավորով F1-ի պարունակության և 1.00 միավորով Rուգ-L-ի պարունակության առումով, որը կազմում է բազմամոդալ լեզվի հասկանալու մասին Հոյ2 տվյալների համակարգում:', 'az': "Bu kağıt çoxlu modal Abstraktiv Metin Toplaşdırması üçün yeni bir modeli MAST'i göstərir ki, çoxlu modal videoda məlumatları - metin, audio və video ilə istifadə edir. Çoxlu modal abstraktiv metin qeyd edilməsindən əvvəlki işlər yalnız metin və video modüllərindən istifadə edilmişdir. Biz audio modaliyyətindən məlumatların faydalanılığını və çətinliklərini incidirik və sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama modelini göstəririk ki, bu çətinliklərə üstün gəlir MAST sanat model in in (video-text) ağımdaki durumunu 2.51 pünkt ilə Content F1 score ilə və çox modal dil anlaşılması üçün How2 veri qutusu ilə Rouge-L score ilə 1.00 pünkt göstərir.", 'bn': 'এই পত্রিকাটি মাল্টিমোডাল আবট্রাক্টিভ টেক্সট সামারিজেশনের জন্য একটি নতুন মডেল মাস্টিকে উপস্থাপন করেছে, যা সব তিন মোডেল থেকে তথ্য ব্যবহার করে -  মাল্টিমোডাল অক্ষরিক টেক্সট সংক্ষেপের প্রাথমিক কাজ শুধুমাত্র লেখা এবং ভিডিও মডেল থেকে তথ্য ব্যবহার করা হয় আমরা অডিও মোডেল থেকে তথ্য পাওয়ার কার্যকর এবং চ্যালেঞ্জ পরীক্ষা করি এবং ত্রিমোডাল হিয়ারার্কিকাল ভিত্তিক মডেল উপস্থাপন করি যা এই চ্যালেঞ্জের উপর জয়ী হয়েছে এবং মড মাস্টির বর্তমান শিল্প মডেল (ভিডিও- টেক্সট) দ্বারা ২. 51 পয়েন্ট প্রদর্শন করে বিষয়বস্তু F1 স্কোর এবং ১. ০০ পয়েন্টের মাধ্যমে রোউজ- L স্কোর বিভিন্ন মানুষে', 'et': 'Käesolevas töös tutvustatakse MAST-i, uut mudelit multimodaalse teksti kokkuvõtmiseks, mis kasutab informatsiooni kõigist kolmest mudelist - teksti, heli ja video - multimodaalses videos. Mitmeliigilise abstraktse teksti kokkuvõtte varasem töö kasutas ainult teksti- ja videomudelite infot. Uurime audiomodaalsusest teabe saamise kasulikkust ja väljakutseid ning esitame järjestusest järjestuseni trimodaalse hierarhilise tähelepanu põhineva mudeli, mis lahendab need väljakutsed, lubades mudelil pöörata rohkem tähelepanu tekstimodaalsusele. MAST ületab praeguse tehnika mudeli (video-tekst) 2,51 punkti võrra sisu F1 skoori ja 1,00 punkti Rouge-L skoori How2 andmekogumi mitmeliigilise keele mõistmise kohta.', 'ca': 'This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities.  We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'cs': 'Tento článek představuje MAST, nový model multimodální abstrakční textové shrnutí, který využívá informace ze všech tří modalit textu, audio a videa v multimodálním videu. Předchozí práce na multimodální abstraktivní shrnutí textu využívaly pouze informace z textových a video modalit. Zkoumáme užitečnost a výzvy odvození informací z audio modality a představujeme trimodální hierarchický model založený na pozornosti, který tyto výzvy překonává tím, že model nechá věnovat větší pozornost modalitě textu. MAST překonává současný model (video-text) o 2,51 body z hlediska skóre obsahu F1 a 1,00 bodů z hlediska skóre Rouge-L na datové sadě How2 pro multimodální porozumění jazyků.', 'fi': 'Tässä artikkelissa esitellään MAST, uusi malli multimodaalisen abstraktin tekstin yhteenvetoon, joka hyödyntää tietoa kaikista kolmesta modaalista - teksti, ääni ja video - multimodaalisessa videossa. Aikaisemmassa multimodaalisessa abstraktiivisessa tekstiyhteenvedossa hyödynnettiin vain teksti- ja videomodaaleista saatavaa tietoa. Tutkimme audiomodaalista tiedon tuottamisen hyödyllisyyttä ja haasteita ja esittelemme sekvenssi-sekvenssiin trimodaalisen hierarkkisen huomiopohjaisen mallin, joka voittaa nämä haasteet antamalla mallin kiinnittää enemmän huomiota tekstimodaalisuuteen. MAST ylittää nykytekniikan mallin (video-teksti) 2,51 pisteellä Content F1 -pisteellä ja Rouge-L-pisteellä multimodaalisen kielen ymmärtämisen How2-aineistossa 1,00 pisteellä.', 'bs': 'Ovaj papir predstavlja MAST, novi model za rezervaciju multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom video. Prije rad na sažetku multimodalnog abstraktivnog teksta koristio je samo informacije iz teksta i video modaliteta. Provjeravamo korisnost i izazove izvlačenja informacija iz audio modaliteta i predstavljamo trimodalni model na osnovu tri-sekvence na osnovu hijerarhijske pažnje koji prevlada te izazove tako što omogućavamo modelu da obratite više pažnje na tekstualnu modalitetu. MAST iznosi trenutno stanje umjetničkog modela (video-teksta) sa 2,51 bodova u smislu rezultata Content F1 i 1,00 bodova u smislu rezultata Rouge-L na setu podataka How2 za razumijevanje multimodalnog jezika.', 'jv': 'Gambar iki nambah MART, model sing bagu kanggo Multimodal absolute Text Samurasi sing nggawe informasi ning saben telu modalitat - teks, video lan video - ning video multimodal. Samsul Awak dhéwé éntuk sistem usahaan lan susahé awak dhéwé nggambar informasi ning modalité surat lan gabung ning acara sekène-to-sekène trimodal karo akeh nyong lanjut model sing isiné berarti dhéwé kuwi nggawe modalité teka. MART iso nggambar kalagayet coro Mulalat (video-text) 2.31 punti, ditambalo Content F1 punti lan 1.00 punti', 'sk': 'Ta prispevek predstavlja MAST, nov model za multimodalno povzetek besedila, ki uporablja informacije iz vseh treh modalitet - besedila, avdio in video - v multimodalnem videu. Predhodno delo na multimodalnem abstraktivnem povzetku besedila je uporabljalo le informacije iz besedilnih in video modalih. Preučujemo uporabnost in izzive pridobivanja informacij iz avdio modalnosti in predstavljamo trimodalni hierarhični model, ki temelji na pozornosti, ki te izzive premaga tako, da model več pozornosti nameni besedilni modalnosti. MAST presega trenutno najsodobnejši model (video-besedilo) za 2,51 točke v smislu rezultata vsebine F1 in 1,00 točke v smislu rezultata Rouge-L na naboru podatkov How2 za razumevanje multimodalnega jezika.', 'ha': 'Wannan takardar gaske na gaurar MAS, wata wata shekara na ƙarami wa masu multi-modal Abtractive Text Summariɗar da ke amfani da information daga duk tsari uku - rubutu, sauna da video - cikin wani video mai yawa. Kayyar aikin aiki na multi-multi-dural separation of text only used in amfani da information from modalities na text and video. Tuna jarraba amfani da masu kanana ga motsi daga tsari na saurãre kuma muna gaura wata misali mai sauri-sauri-sauri-dubi-sauri, wanda ke rinjãya masu hanyoyin wannan, da kuma ya yarda motel ya zama masu sauna ga tsarin matsayin. MASA na ƙididdige halin da ke yanzu kamar misalin sanar (video-text) da 2.51 points cikin muhimman F1 score da 1.0 points cikin muhimman kwanan rubutun Rouge-L kan tsarin maɓallin How2 wa gane multi-multi-language.', 'bo': 'ཤོག་བྱང་འདིས་ MAST སྟོན་པ་དང་རྣམ་གྲངས་འདྲ་བའི་སྣ་ཚོགས་རྣམ་གྲངས་སྒྲིག་མཛོད་ཁུངས་ཀྱི་མ་དབྱིབས་གསར་པ་ཞིག་སྟོན་ཐུབ་པའི་ཐབས་ལམ་གསུམ Multimodal abstractive text summarization་གི་སྔོན་གྱི་ལས་སྤྱོད་རྒྱུ་དངོས་ཡིག་གེ་དང་བརྙན་རིས་ཐབས་ལམ་ནང་ལས་ལག་ལེན་འཐབ་པའི་བརྡ་སྟོན་དགོས We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.', 'he': 'This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  עבודה קודמת על סדרת טקסט מולטלמודלית אוסטרקטיבית השתמשה רק במידע מהטקסט והוידאו מודליות. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST מציג את המצב הנוכחי של מודל האומנות (וידאו-טקסט) ב-2.51 נקודות במונחים של תוכן F1 ו-1.00 נקודות במונחים של תואר רוג-L על קבוצת נתונים How2 להבנה multimodal לשפה.'}
{'en': 'Reasoning Over History : Context Aware Visual Dialog', 'ar': 'التفكير في التاريخ: حوار مرئي يدرك السياق', 'fr': "Raisonnement sur l'histoire\xa0: dialogue visuel sensible au contexte", 'es': 'Razonamiento sobre la historia: diálogo visual sensible al contexto', 'pt': 'Raciocínio sobre a história: diálogo visual sensível ao contexto', 'ja': '過去の推理：コンテキスト意識視覚ダイアログ', 'hi': 'इतिहास पर तर्क: संदर्भ जागरूक दृश्य संवाद', 'ru': 'Обоснование истории: контекстно-ориентированный визуальный диалог', 'zh': '史推理:上下文感知视觉对话框', 'ga': 'Réasúnú ar an Stair: Dialóg Amharc ar an gComhthéacs', 'ka': 'ისტორიის გარეშე მიზეზი: კონტექსტის გარეშე ვიზუალური დიალოგი', 'el': 'Λογισμός πάνω από το ιστορικό: Οπτικός διάλογος με επίγνωση του περιβάλλοντος', 'hu': 'Észrevétel az előzmények felett: kontextustudatos vizuális párbeszédpanel', 'it': 'Ragionare sulla storia: dialogo visivo consapevole del contesto', 'kk': 'Журнал бойынша себептері: Контексті көрінетін диалог', 'mk': 'Разумнување во текот на историјата: Визуелен дијалог на контекст', 'lt': 'Reasoning Over History: Context Aware Visual Dialog', 'ms': 'Menyebabkan Atas Sejarah: Dialog Visual Sedia Konteks', 'ml': 'ചരിത്രത്തിനു മുകളില്\u200d വായിക്കുന്നു: കൂട്ടത്തില്\u200d അറിയുന്ന കാഴ്ചയുള്ള ഡയലോഗ്', 'mn': 'Түүхэн дээр шалтгаан: Context Aware Visual Dialog', 'mt': 'Raġunar fuq l-Istorja: Djalogu Viżwali Konxju tal-Kuntest', 'no': 'Årsaker over historie: Visuelt dialogvindauge for kontekstvekking', 'pl': 'Rozumowanie nad historią: Kontekstowe okno wizualne', 'ro': 'Motivarea istoricului: Dialog vizual conștient de context', 'sr': 'Reasoning Over History: Context Aware Visual Dialog', 'si': 'ඉතිහාසයේ හේතුව: සංවේදනය දකින්න පුළුවන් සංවාදය', 'sv': 'Motivering över historik: Context Aware Visual Dialog', 'so': 'Reading Over History: Context aware Visual Dialog', 'ta': 'வரலாற்றின் மேல் படிக்கப்படுகிறது: உள்ளமைப்பு நன்றாக காட்சி உரையாடல்', 'ur': 'تاریخ پر دلیل حاصل کرتا ہے: کنٹکسٹ آگاہ دینے والی دائیلوگ', 'uz': 'Tarixni oʻqish: Context aware Visual Dialog', 'vi': 'Lý lẽ về lịch sử: hộp thoại giao thức', 'bg': 'Разбиране над историята: визуален диалог, осъзнаващ контекста', 'hr': 'Razlog preko povijesti: Kontekstski razvijeni vizualni dijalog', 'nl': 'Redenen boven geschiedenis: contextbewust visueel dialoogvenster', 'da': 'Årsag over historie: Context Aware Visual Dialog', 'de': 'Vernunft über Historie: Kontextbewusster visueller Dialog', 'fa': 'Reasoning Over History: Context Aware Visual Dialog', 'id': 'Menyebabkan Sejarah: Dialog Visual Mengetahui Konteks', 'sw': 'Msoma juu ya Historia: Context Aware Visual Dialog', 'tr': 'Geçmişiň üstünde sebäpli: Kontekst Görkezilen диалог', 'sq': 'Arsyeja mbi historinë: Dialogu vizual i njohur në kontekst', 'af': 'Redigeerder Oor Geskiedenis: Konteks Weg Visuele Dialoog', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'hy': 'Պատմության վերաբերյալ', 'az': 'Tarihin 칲z톛rind톛 s톛b톛b: Kontekst G칬r칲n칲r Dialogu', 'bn': 'ইতিহাসের উপর পাঠ করা হচ্ছে: বিষয়বস্তুর পরিচিত দৃশ্য ডায়ালগ', 'bs': 'Razlog preko povijesti: vizualni dijalog konteksta', 'ca': 'Reasoning Over History: Context Aware Visual Dialog', 'cs': 'Odůvodnění přes historii: vizuální dialog se znalostí kontextu', 'ko': '역사 추리: 상하문이 감지하는 시각적 대화', 'et': 'Ajaloo põhjendamine: kontekstitundlik visuaalne dialoog', 'fi': 'Perustelu historiaan: kontekstitietoinen visuaalinen dialogi', 'ha': 'Media controller element', 'sk': 'Razmišljanje o zgodovini: vizualno pogovorno okno, ki se zaveda konteksta', 'he': 'Reasoning Over History: Context Aware Visual Dialog', 'jv': 'Ngubah Nang Keterangan: context Awake Visual Dialog', 'bo': 'རྒྱུ་མཚན་ལོ་རྒྱུས་དང་བསྟུན་ནས་ཡུལ་རྟོན་པའི་མཐོང་སྣང་གླེང་སྒྲོམ'}
{'en': 'While neural models have been shown to exhibit strong performance on single-turn visual question answering (VQA) tasks, extending VQA to a multi-turn, conversational setting remains a challenge. One way to address this challenge is to augment existing strong neural VQA models with the mechanisms that allow them to retain information from previous dialog turns. One strong VQA model is the  MAC network , which decomposes a  task  into a series of attention-based reasoning steps. However, since the  MAC network  is designed for single-turn question answering, it is not capable of referring to past dialog turns. More specifically, it struggles with  tasks  that require reasoning over the dialog history, particularly  coreference resolution . We extend the MAC network architecture with Context-aware Attention and Memory (CAM), which attends over control states in past dialog turns to determine the necessary reasoning operations for the current question. MAC nets with CAM achieve up to 98.25 % accuracy on the CLEVR-Dialog dataset, beating the existing state-of-the-art by 30 % (absolute). Our  error analysis  indicates that with  CAM , the  model ’s performance particularly improved on questions that required  coreference resolution .', 'ar': 'بينما أظهرت النماذج العصبية أنها تُظهر أداءً قويًا في مهام الإجابة على الأسئلة المرئية (VQA) ذات الدور الواحد ، فإن توسيع VQA إلى إعداد محادثة متعدد الأدوار لا يزال يمثل تحديًا. تتمثل إحدى طرق مواجهة هذا التحدي في زيادة نماذج VQA العصبية القوية الحالية بآليات تسمح لها بالاحتفاظ بالمعلومات من انعطافات الحوار السابقة. أحد نماذج VQA القوية هو شبكة MAC ، والتي تحلل المهمة إلى سلسلة من خطوات التفكير القائمة على الانتباه. ومع ذلك ، نظرًا لأن شبكة MAC مصممة للإجابة على الأسئلة من منعطف واحد ، فإنها غير قادرة على الإشارة إلى المنعطفات السابقة في الحوار. وبشكل أكثر تحديدًا ، فإنه يكافح مع المهام التي تتطلب التفكير في محفوظات الحوار ، ولا سيما دقة المرجع. نقوم بتوسيع بنية شبكة MAC مع الانتباه والذاكرة (CAM) المدركين للسياق ، والذي يتعامل مع حالات التحكم في المنعطفات الحوارية السابقة لتحديد عمليات الاستدلال الضرورية للسؤال الحالي. تحقق شبكات MAC المزودة بـ CAM دقة تصل إلى 98.25٪ على مجموعة بيانات CLEVR-Dialog ، متجاوزة أحدث التقنيات الحالية بنسبة 30٪ (مطلق). يشير تحليل الأخطاء الخاص بنا إلى أنه باستخدام CAM ، تحسن أداء النموذج بشكل خاص في الأسئلة التي تتطلب حلًا مرجعيًا.', 'fr': "Alors que les modèles neuronaux ont démontré de bonnes performances dans les tâches de réponse visuelle aux questions (VQA) à tour unique, l'extension de la VQA à un environnement conversationnel à tours multiples reste un défi. Une façon de relever ce défi consiste à compléter les modèles VQA neuronaux puissants existants avec les mécanismes qui leur permettent de conserver les informations des tournants de dialogue précédents. Un modèle VQA fort est le réseau MAC, qui décompose une tâche en une série d'étapes de raisonnement basées sur l'attention. Toutefois, étant donné que le réseau MAC est conçu pour répondre à des questions en un tour, il n'est pas capable de faire référence aux tours de dialogue précédents. Plus précisément, il est aux prises avec des tâches qui nécessitent un raisonnement sur l'historique des dialogues, en particulier la résolution de coréférence. Nous étendons l'architecture réseau MAC avec l'attention et la mémoire sensibles au contexte (CAM), qui surveillera les états de contrôle lors des tours de dialogue précédents afin de déterminer les opérations de raisonnement nécessaires pour la question en cours. Les réseaux MAC avec CAM atteignent une précision allant jusqu'à 98,25\xa0% sur l'ensemble de données CLEVR-Dialog, dépassant de 30\xa0% (en valeur absolue) l'état actuel de la technologie. Notre analyse des erreurs indique qu'avec la FAO, les performances du modèle se sont particulièrement améliorées pour les questions nécessitant une résolution de coréférence.", 'es': 'Si bien se ha demostrado que los modelos neuronales muestran un rendimiento sólido en las tareas de respuesta visual a preguntas (VQA) de un solo giro, extender el VQA a un entorno conversacional de varios turnos sigue siendo un desafío. Una forma de abordar este desafío es aumentar los modelos de VQA neuronales fuertes existentes con los mecanismos que les permitan retener la información de los turnos de diálogo anteriores. Un modelo de VQA sólido es la red MAC, que descompone una tarea en una serie de pasos de razonamiento basados en la atención. Sin embargo, dado que la red MAC está diseñada para responder preguntas de un solo giro, no es capaz de hacer referencia a giros de diálogo anteriores. Más específicamente, tiene problemas con tareas que requieren razonar sobre el historial de diálogos, en particular la resolución de correferencias. Ampliamos la arquitectura de red MAC con atención y memoria sensible al contexto (CAM), que atiende los estados de control en los turnos de diálogo anteriores para determinar las operaciones de razonamiento necesarias para la pregunta actual. Las redes MAC con CAM alcanzan una precisión de hasta el 98,25% en el conjunto de datos CLEVR-Dialog, superando el estado actual en un 30% (absoluto). Nuestro análisis de errores indica que, con CAM, el rendimiento del modelo mejoró particularmente en las preguntas que requerían la resolución de correferencias.', 'pt': 'Embora os modelos neurais tenham demonstrado um forte desempenho em tarefas de resposta a perguntas visuais de turno único (VQA), estender o VQA para uma configuração de conversação de vários turnos continua sendo um desafio. Uma maneira de enfrentar esse desafio é aumentar os modelos VQA neurais fortes existentes com os mecanismos que permitem que eles retenham informações de turnos de diálogo anteriores. Um modelo VQA forte é a rede MAC, que decompõe uma tarefa em uma série de etapas de raciocínio baseadas na atenção. No entanto, como a rede MAC foi projetada para responder a perguntas de um turno, ela não é capaz de se referir a turnos de diálogo anteriores. Mais especificamente, ele luta com tarefas que exigem raciocínio sobre o histórico de diálogos, particularmente a resolução de correferência. Estendemos a arquitetura de rede MAC com Context-aware Attention and Memory (CAM), que atende os estados de controle em turnos de diálogo anteriores para determinar as operações de raciocínio necessárias para a questão atual. As redes MAC com CAM atingem até 98,25% de precisão no conjunto de dados CLEVR-Dialog, superando o estado da arte existente em 30% (absoluto). Nossa análise de erros indica que, com o CAM, o desempenho do modelo melhorou particularmente em questões que exigiam resolução de correferência.', 'ja': 'ニューラルモデルは、シングルターンビジュアルクエスチョンアンサー（ VQA ）タスクで強力なパフォーマンスを示すことが示されているが、VQAをマルチターンに拡張することは依然として課題である。 この課題に対処する1つの方法は、既存の強力なニューラルVQAモデルを、以前のダイアログターンからの情報を保持できるメカニズムで増強することです。 強力なVQAモデルの1つは、タスクを一連の注意に基づく推論ステップに分解するMACネットワークです。 ただし、MACネットワークはシングルターンクエスチョンアンサー用に設計されているため、過去のダイアログターンを参照することはできません。 より具体的には、ダイアログ履歴、特にコアリファレンスの解決を通じて推論を必要とするタスクに苦労します。 過去のダイアログのターンで制御状態に参加して、現在の質問に必要な推論操作を決定する、コンテキスト認識アテンションとメモリ（ CAM ）を備えたMACネットワークアーキテクチャを拡張します。 CAMを備えたMACネットは、CLEVR - Dialogデータセットで最大98.25 ％の精度を達成し、既存の最先端のものを30 ％ （絶対）上回ります。 当社のエラー分析によると、CAMを使用すると、特にコアリファレンス解決を必要とする質問でモデルのパフォーマンスが向上したことが示されています。', 'zh': '虽神经模形已验于单轮视问答(VQA)其出较强者,然广VQA于多轮次,犹一挑战也。 解此一法,用许留前对轮次信息之机以增见强神经VQA。 强VQA为MAC网络,分职为推步。 然MAC网络为单轮问答设计,故不能引旧对。 更具体地说,其难处须对历史记录推理之任,尤协理解析。 因上下文知内存(CAM)广MAC网络架构,宜架构旧对回合,以定时务。 带 CAM 者 MAC 网络于 CLEVR-Dialog 数集上准确率高 98.25%,高于见者 30%(绝对值)。 臣等差分析表明,用 CAM 之时,模形之性,于须共推理解析之间,特得改进。', 'hi': 'जबकि तंत्रिका मॉडल को एकल-बारी दृश्य प्रश्न उत्तर (वीक्यूए) कार्यों पर मजबूत प्रदर्शन प्रदर्शित करने के लिए दिखाया गया है, वीक्यूए को एक बहु-मोड़ तक विस्तारित करना, संवादी सेटिंग एक चुनौती बनी हुई है। इस चुनौती को संबोधित करने का एक तरीका मौजूदा मजबूत तंत्रिका वीक्यूए मॉडल को उन तंत्रों के साथ बढ़ाना है जो उन्हें पिछले संवाद मोड़ से जानकारी बनाए रखने की अनुमति देते हैं। एक मजबूत VQA मॉडल मैक नेटवर्क है, जो एक कार्य को ध्यान-आधारित तर्क चरणों की एक श्रृंखला में विघटित करता है। हालांकि, चूंकि मैक नेटवर्क को एकल-बारी प्रश्न का उत्तर देने के लिए डिज़ाइन किया गया है, इसलिए यह पिछले संवाद मोड़ का उल्लेख करने में सक्षम नहीं है। अधिक विशेष रूप से, यह उन कार्यों के साथ संघर्ष करता है जिनके लिए संवाद इतिहास पर तर्क की आवश्यकता होती है, विशेष रूप से सह-सम्मेलन संकल्प। हम संदर्भ-जागरूक ध्यान और स्मृति (सीएएम) के साथ मैक नेटवर्क आर्किटेक्चर का विस्तार करते हैं, जो वर्तमान प्रश्न के लिए आवश्यक तर्क संचालन निर्धारित करने के लिए पिछले संवाद मोड़ में नियंत्रण राज्यों पर भाग लेता है। सीएएम के साथ मैक नेट CLEVR-डायलॉग डेटासेट पर 98.25% सटीकता प्राप्त करते हैं, जो मौजूदा अत्याधुनिक को 30% (निरपेक्ष) से हराते हैं। हमारा त्रुटि विश्लेषण इंगित करता है कि सीएएम के साथ, मॉडल के प्रदर्शन में विशेष रूप से उन प्रश्नों पर सुधार हुआ है जिनके लिए कोरेफेरेंस रिज़ॉल्यूशन की आवश्यकता होती है।', 'ru': 'В то время как было показано, что нейронные модели демонстрируют высокую производительность при одновитковых задачах визуального ответа на вопросы (VQA), расширение VQA до многовитковых, разговорная обстановка остается проблемой. Одним из способов решения этой проблемы является дополнение существующих сильных нейронных моделей VQA механизмами, которые позволяют им сохранять информацию из предыдущих диалоговых витков. Одной из сильных моделей VQA является сеть MAC, которая декомпозирует задачу на ряд этапов рассуждений, основанных на внимании. Однако, поскольку сеть MAC предназначена для ответа на вопросы в один оборот, она не может ссылаться на прошлые диалоговые повороты. Более конкретно, он борется с задачами, которые требуют рассуждения в течение истории диалога, в частности, с разрешением основной ссылки. Мы расширяем сетевую архитектуру MAC с помощью Context-ware Attention and Memory (CAM), которая отслеживает состояния управления в прошлых диалоговых поворотах, чтобы определить необходимые логические операции для текущего вопроса. Сети MAC с КУЛАЧКОМ достигают 98,25% точности в наборе данных CLEVR-Dialog, опередив существующий современный уровень на 30% (абсолютный). Наш анализ ошибок показывает, что с помощью CAM производительность модели особенно улучшилась по вопросам, которые требовали ключевого разрешения.', 'ga': "Cé go bhfuil sé léirithe go léiríonn samhlacha néaracha feidhmíocht láidir ar thascanna freagartha ceisteanna amhairc aon-uaine (VQA), is dúshlán fós é VQA a shíneadh go suíomh iliompaithe, comhrá. Bealach amháin chun aghaidh a thabhairt ar an dúshlán seo is ea na samhlacha láidre néaracha VQA atá ann cheana féin a mhéadú leis na meicníochtaí a ligeann dóibh faisnéis a choinneáil ó na hiarrachtaí dialóige roimhe seo. Múnla láidir VQA amháin is ea an líonra MAC, a dhianscaoileann tasc i sraith céimeanna réasúnaíochta atá bunaithe ar aird. Mar sin féin, ós rud é go bhfuil an líonra MAC deartha le haghaidh freagra aon-uaine ar cheisteanna, níl sé in ann tagairt a dhéanamh d'iompaithe dialóige san am a chuaigh thart. Go sonrach, bíonn sé ag streachailt le tascanna a éilíonn réasúnú thar stair na dialóige, go háirithe réiteach croí-chomhdhála. Déanaimid leathnú ar ailtireacht líonra MAC le hAird agus Cuimhne atá Feasach ar an gComhthéacs (CAM), a fhreastalaíonn ar stáit rialaithe san am a chuaigh thart chun na hoibríochtaí réasúnaíochta is gá a chinneadh don cheist reatha. Déanann líonta MAC le CAM cruinneas suas le 98.25% a bhaint amach ar an tacar sonraí CLEVR-Dialog, ag bualadh 30% (iomlán) ar an stát is déanaí atá ann faoi láthair. Léiríonn ár n-anailís earráide, le CAM, gur tháinig feabhas ar fheidhmíocht na samhla ar cheisteanna a raibh réiteach croí-chomhdhála ag teastáil uathu.", 'el': 'Ενώ τα νευρωνικά μοντέλα έχουν αποδειχθεί ότι παρουσιάζουν ισχυρή απόδοση σε εργασίες οπτικής απάντησης μιας στροφής, η επέκταση της σε ένα περιβάλλον πολλαπλών στροφών, συνομιλίας παραμένει μια πρόκληση. Ένας τρόπος αντιμετώπισης αυτής της πρόκλησης είναι να ενισχυθούν τα υπάρχοντα ισχυρά νευρωνικά μοντέλα με μηχανισμούς που τους επιτρέπουν να διατηρούν πληροφορίες από προηγούμενες στροφές διαλόγου. Ένα ισχυρό μοντέλο είναι το δίκτυο το οποίο διασπά μια εργασία σε μια σειρά από βήματα σκέψης βασισμένα στην προσοχή. Ωστόσο, δεδομένου ότι το δίκτυο έχει σχεδιαστεί για απάντηση σε ερωτήσεις μιας μόνο στροφής, δεν είναι σε θέση να αναφερθεί σε προηγούμενες στροφές διαλόγου. Πιο συγκεκριμένα, αγωνίζεται με καθήκοντα που απαιτούν συλλογισμό σχετικά με το ιστορικό διαλόγου, ιδιαίτερα την επίλυση συναλλακτικών διαφορών. Επεκτείνουμε την αρχιτεκτονική δικτύου με προσοχή και μνήμη που παρακολουθεί τις καταστάσεις ελέγχου σε προηγούμενες στροφές διαλόγου για να καθορίσει τις απαραίτητες λειτουργίες συλλογισμού για την τρέχουσα ερώτηση. Τα δίχτυα με CAM επιτυγχάνουν ακρίβεια έως 98,25% στο σύνολο δεδομένων ξεπερνώντας την υπάρχουσα κατάσταση της τεχνολογίας κατά 30% (απόλυτη). Η ανάλυση σφαλμάτων μας δείχνει ότι με την CAM, η απόδοση του μοντέλου βελτιώθηκε ιδιαίτερα σε ερωτήματα που απαιτούσαν την επίλυση αλληλοδιαφορών.', 'hu': 'Míg a neurális modellek kimutatták, hogy nagy teljesítményt mutatnak az egyfordulós vizuális kérdésre válaszoló (VQA) feladatokban, a VQA kiterjesztése többfordulós, a beszélgetési beállítás továbbra is kihívást jelent. Ennek a kihívásnak az egyik módja a meglévő erős neurális VQA modellek bővítése olyan mechanizmusokkal, amelyek lehetővé teszik számukra, hogy megőrizzék a korábbi párbeszédfordulókból származó információkat. Az egyik erős VQA modell a MAC hálózat, amely egy feladatot figyelem alapú érvelési lépésekre bont fel. Mivel azonban a MAC hálózat egyfordulós kérdések megválaszolására van tervezve, nem képes utalni a korábbi párbeszédfordulókra. Pontosabban küzd azokkal a feladatokkal, amelyek a párbeszédtörténetek, különösen a coreferencia felbontását igénylik. A MAC hálózati architektúrát kontextustudatos figyelem és memória (CAM) segítségével bővítjük, amely a korábbi párbeszédfordulók vezérlőállapotát veszi figyelembe, hogy meghatározza az aktuális kérdéshez szükséges érvelési műveleteket. A CAM rendszerrel rendelkező MAC hálók akár 98,25%-os pontosságot érnek el a CLEVR-Dialog adatkészleten, 30%-kal felülmúlva a meglévő korszerűséget. Hibaelemzésünk azt mutatja, hogy a CAM segítségével a modell teljesítménye különösen javult a korreferencia felbontását igénylő kérdésekben.', 'ml': 'ന്യൂറല്\u200d മോഡലുകള്\u200d ഒരു തിരിച്ചുവരുന്ന കാഴ്ച ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകുന്നതില്\u200d ശക്തമായ പ്രദര്\u200dശിപ്പിക്കുന്നത് പ്രദര്\u200dശിപ്പിക്കുന്നത് പോ നിലവിലുള്ള ശക്തിയുള്ള ന്യൂറല്\u200d വിക്യൂഎ മോഡലുകള്\u200d കൂട്ടിചേര്\u200dക്കാന്\u200d ഒരു വഴി മുമ്പുള്ള ഡയലോഗ് തിരിച്ചുവെക്കുന്നതില One strong VQA model is the MAC network, which decomposes a task into a series of attention-based reasoning steps.  എന്നാലും MAC ശൃംഖലം ഒരു തിരിച്ചുമാറ്റുന്ന ചോദ്യം ഉത്തരം നല്\u200dകുന്നതിനായി നിര്\u200dമ്മിക്കപ്പെട്ടതിനാല്\u200d, കഴിഞ്ഞുപോ കൂടുതല്\u200d പ്രത്യേകിച്ച്, അത് ജോലികളുമായി പൊരുതുന്നു. ഡയലോഗ് ചരിത്രത്തെക്കുറിച്ച് കാര്യങ്ങള്\u200d ആവശ്യമുള്ള ജോലി നിലവിലുള്ള ചോദ്യത്തിന്റെ ആവശ്യമുള്ള കാര്യങ്ങള്\u200d തീരുമാനിക്കുന്നതിനായി നാം MAC നെറ്റ്\u200cവര്\u200dക്കെന്\u200dറ് ശ്രദ്ധിക്കുന്നതിനും മെമ്മറിയുമായി  CLEVR-ഡയലോഗ് ഡാറ്റാസറ്റാസെറ്റില്\u200d MAC നെറ്റുകള്\u200d 98. 25% പരിഗണന പ്രാപിക്കുന്നു. നിലവിലുള്ള സ്ഥിതിയില്\u200d 30% (പൂര്\u200dണ്ണമായി) അടിക്ക നമ്മുടെ പിശക് അന്വേഷണം കാണിക്കുന്നത് കാമില്\u200d മോഡലിന്റെ പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രത്യേകിച്ച് മെച്ചപ്പെടുത്തുന്നത', 'mt': 'Filwaqt li ntwera li mudelli newrali juru prestazzjoni qawwija fuq kompiti ta’ tweġiba għall-mistoqsijiet viżivi b’dawra waħda (VQA), l-estensjoni tal-VQA għal ambjent b’ħafna dawriet, il-konverżjoni tibqa’ sfida. Mod wieħed biex tiġi indirizzata din l-isfida huwa li jiżdiedu l-mudelli VQA newrali b’saħħithom eżistenti bil-mekkaniżmi li jippermettulhom iżommu l-informazzjoni minn dawriet ta’ djalogu preċedenti. Mudell wieħed b’saħħtu ta’ VQA huwa n-netwerk MAC, li jiddekomponi kompitu f’serje ta’ passi ta’ raġunament ibbażati fuq l-attenzjoni. Madankollu, peress li n-netwerk MAC huwa mfassal biex iwieġeb mistoqsijiet b’dawra waħda, mhuwiex kapaċi jirreferi għal dawriet tad-djalogu tal-passat. B’mod aktar speċifiku, hija tiġġieled ma’ kompiti li jeħtieġu raġunament fuq l-istorja tad-djalogu, b’mod partikolari r-riżoluzzjoni tal-koreferenza. Aħna jestendu l-arkitettura tan-netwerk MAC bl-Attenzjoni u l-Memorja (CAM), li jattendi fuq l-istati ta’ kontroll fid-djalogu tal-passat, biex jiddeterminaw l-operazzjonijiet ta’ raġunament meħtieġa għall-mistoqsija attwali. MAC nets with CAM achieve up to 98.25% accuracy on the CLEVR-Dialog dataset, beating the existing state-of-the-art by 30% (absolute).  L-analiżi tagħna tal-iżbalji tindika li bil-CAM, il-prestazzjoni tal-mudell tjiebet b’mod partikolari fuq kwistjonijiet li kienu jeħtieġu riżoluzzjoni ta’ koreferenza.', 'ms': 'Sementara model saraf telah dipaparkan untuk menunjukkan prestasi kuat pada satu pusingan jawapan soalan visual (VQA) tugas, memperluas VQA kepada satu pusingan berbilang, tetapan perbualan tetap satu cabaran. Salah satu cara untuk mengatasi cabaran ini adalah menambah model VQA saraf yang ada dengan mekanisme yang membenarkan mereka untuk menyimpan maklumat dari pusingan dialog terdahulu. Satu model VQA yang kuat adalah rangkaian MAC, yang menghancurkan tugas ke dalam siri langkah pemikiran berdasarkan perhatian. Namun, kerana rangkaian MAC direka untuk menjawab soalan satu pusingan, ia tidak mampu merujuk kepada pusingan dialog yang lalu. Lebih khusus, ia berjuang dengan tugas yang memerlukan alasan atas sejarah dialog, terutama resolusi rujukan. Kami memperluas arkitektur rangkaian MAC dengan Perhatian dan Memori (CAM) yang menyertai keadaan kawalan dalam dialog yang lalu berubah untuk menentukan operasi alasan yang diperlukan untuk soalan semasa. Rangkaian MAC dengan CAM mencapai hingga 98.25% ketepatan pada set data CLEVR-Dialog, mengalahkan keadaan-state-of-the-art yang wujud dengan 30% (mutlak). Analisis ralat kami menunjukkan bahawa dengan CAM, prestasi model terutama meningkat pada soalan yang memerlukan resolusi persamaan.', 'lt': 'Nors įrodyta, kad neurologiniai modeliai rodo stiprų vienkartinio vaizdo atsakymo į klausimus užduotis (VQA) rezultatą, VQA išplėtimas iki daugkartinio vaizdo, konversacija tebėra iššūkis. Vienas iš būdų spręsti šį uždavinį – sustiprinti esamus stiprius nervinių VQA modelius mechanizmais, kurie leistų jiems išsaugoti informaciją iš ankstesnių dialogo posūkių. Vienas stiprus VQA model is yra MAC tinklas, kuris užduotį suskirsto į keletą dėmesiu pagrįstų motyvavimo etapų. Tačiau, kadangi MAC tinklas skirtas vienkartiniam atsakymui į klausimus, jis negali remtis ankstesniais dialogo posūkiais. More specifically, it struggles with tasks that require reasoning over the dialog history, particularly coreference resolution.  Mes išplečiame MAC tinklo architektūrą su kontekste žinomu dėmesiu ir atmintimi (CAM), kuri vyksta kontrolės būsenose praeityje vykstančiame dialoge, siekiant nustatyti būtinas motyvavimo operacijas dabartiniam klausimui. MAC tinklai su CAM pasiekia iki 98,25 % tikslumo CLEVR dialogo duomenų rinkinyje, o dabartinės pažangos lygis – 30 % (absoliutus). Mūs ų klaidų analizė rodo, kad taikant CAM modelio veiklos rezultatai ypač pagerėjo klausimais, kuriems reikalinga koreferencinė rezoliucija.', 'mk': 'Иако се покажа дека невровните модели покажуваат силни резултати на задачите за одговор на еднокруговно визуелно прашање (VQA), проширувањето на VQA на мултикруговно поставување останува предизвик. Еден начин да се реши овој предизвик е да се зголемат постојните силни нервни модели на VQA со механизмите кои им овозможуваат да задржат информации од претходните дијалози. Еден силен модел на VQA е мрежата на MAC, која ја разделува задачата во серија чекори на размислување базирани на внимание. However, since the MAC network is designed for single-turn question answering, it is not capable of referring to past dialog turns.  Поконкретно, се бори со задачи кои бараат размислување во врска со историјата на дијалогот, особено резолуцијата на соодветноста. Ја прошируваме мрежната архитектура на MAC со контекстно свесно внимание и меморија (CAM), која присуствува над контролните држави во минатиот дијалог се претвора во одредување на потребните операции за размислување за моменталното прашање. МАЦ мрежи со CAM постигнуваат до 98,25 отсто точност на податоците од CLEVR-Dialog, поразувајќи ја постојаната најнова состојба за 30 отсто (апсолутно). Нашата анализа на грешки покажува дека со CAM, резултатите на моделот особено се подобрија во врска со прашањата кои бараа соодветна резолуција.', 'ka': 'ჩვენ ჩვენებულიან ნეიროლური მოდელები, რომლებიც ერთ-ერთი ვიზუალური კითხვების გასაღების შესახებ (VQA) პარამეტრებზე ძალიან გამოყენება, რომლებიც VQA-ს მრავალური გადატანა, კონტაქციო ერთი გზა ამ განცემების გარეშე არის ძალიან ძალიან ნეიროლური VQA მოდელების გარეშე, რომლებიც მათ უნდა წინა დიალოგიდან ინფორმაციას დახმარება. ერთი ძალიან VQA მოდელი არის MAC ქსელი, რომელიც დააწყება რაოდენობას აღმოჩენებული აღმოჩენების სერიოში. მაგრამ, რადგან MAC ქსელი განაზღვრებულია ერთ-ერთი კითხვის პასუხისთვის, ის არ შეუძლებელია წინა დიალოგის შეცვლა. უფრო განსაკუთრებულია, ის მუშაობს საქმედებით, რომლებიც დიალოგის ისტორიის განსაკუთრებით მოჭირდება, განსაკუთრებით მუშაობის განსაკუთრებით. ჩვენ MAC ქსელის აქტიქტიქტიკურაციას კონტექსტური ატრუქცია და მეხსიერება (CAM) სხვადასხვადასხვადასხვა, რომელიც წინ დიალოგიში კონტროლური სტატიქტიკური სტატიქტიკ MAC ქსელები CAM-თან 98.25% დაიწყება CLEVR- დიალოგის მონაცემების კონტაქტის დამატებით, 30% (აბსოლუტულია) სწორესობის მდგომარეობა. ჩვენი შეცდომა ანალიზია, რომ CAM-ით მოდელის გამოყენება განსაკუთრებულად უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო', 'it': "Mentre i modelli neurali hanno dimostrato di mostrare forti prestazioni nelle attività di risposta visiva alle domande a singolo turno (VQA), estendere il VQA a un ambiente conversazionale a più turni rimane una sfida. Un modo per affrontare questa sfida è quello di aumentare i modelli VQA neurali forti esistenti con i meccanismi che consentono loro di conservare le informazioni dai precedenti turni di dialogo. Un modello VQA forte è la rete MAC, che scompone un compito in una serie di passaggi di ragionamento basati sull'attenzione. Tuttavia, poiché la rete MAC è progettata per rispondere alle domande a turno singolo, non è in grado di fare riferimento ai turni di dialogo passati. Più specificamente, lotta con compiti che richiedono ragionamenti sulla cronologia dei dialoghi, in particolare la risoluzione della coreferenza. Estendiamo l'architettura di rete MAC con Context-aware Attention and Memory (CAM), che assiste agli stati di controllo nei turni di dialogo passati per determinare le operazioni di ragionamento necessarie per la domanda corrente. Le reti MAC con CAM raggiungono fino al 98,25% di precisione sul set di dati CLEVR-Dialog, superando lo stato dell'arte esistente del 30% (assoluto). La nostra analisi degli errori indica che con CAM, le prestazioni del modello sono migliorate in modo particolare su questioni che richiedevano una risoluzione di coreferenza.", 'kk': 'Невралдық моделдері бір- бір бұрышты сұрақ жауап беру (VQA) тапсырмаларында көп бұрышты жұмыс істеу үшін, VQA- ды көп бұрышты өзгерту үшін күшті жұмыс істеу үшін көрсетіліп тұрған,  Бұл мәселеледі шешу үшін бір жол - барлық невралдық VQA үлгілерін алдыңғы диалогындағы мәліметті сақтауға мүмкіндік беретін механизмлерді көтеру. Бір күшті VQA үлгі - MAC желі, тапсырманы бірнеше назардағы тәртіпке негізделген мақсаттау қадамдарына бөліп тастайды. Бірақ MAC желі жауап беру үшін жауап беру үшін құрылған себебі, бұл өткен диалогтың айналысуы мүмкін емес. Көбірек, бұл диалог тарыхында түсініктеме керек тапсырмалар мен күресіп тұрады, әсіресе мәселелердің айырмашылығы. Біз MAC желінің архитектурасын Context-aware Attention and Memory (CAM) арқылы, бұрынғы диалогындағы контрол күйіне қатынау күйіне қатынайды, осы сұрақ үшін қажетті сезім операцияларын анықтау үшін керек CAM арқылы MAC желі CLEVR- диалог деректер жиынында 98, 25% дегенге дейін жеткізеді. Бұл желінің күйі 30% (абсолютті). Қате анализиясыз CAM дегенмен үлгісінің әсері өзгертілген сұрақтардың өзгертілігін жақсы көрсетеді.', 'no': 'Mens nøyrale modeller er viste for å visa sterke utviklingar ved å svara på enkeltvaringsspørsmål (VQA) og utvide VQA til fleire område, vert konvertasjonsinnstillingar fortsatt eit utfordring. Ein måte å handtera denne utfordringen er å auka eksisterande sterke neurale VQA-modeller med mekanismene som tillater dei å lagra informasjon frå førre dialogvindauge. Ein sterk VQA-modell er MAC-nettverket, som dekomprimerer ei oppgåve i ein serie av oppmerksbaserte grunnlag. Siden MAC-nettverket er imidlertid utforma for å svara på eit enkelt snu, kan det ikkje referera til siste dialogvindauge. Det kjem med oppgåver som krev rasjon over dialoghistorien, spesielt koreferanse oppløysing. Vi utvidar MAC- nettverksarkitekturen med kontekst- oppmerkinga og minne (CAM), som deltar over kontrollstilstandar i siste dialogvindauge, for å bestemme dei nødvendige årsakende operasjonane for det gjeldande spørsmålet. MAC- nettverk med CAM oppnår til 98,25% nøyaktighet på datasettet CLEVR- dialogen, og slår den eksisterande tilstanden av kunsten til 30% (absolutt). Feilanalysen vårt viser at med CAM er modellen spesielt forbetra på spørsmål som krevst oppløysing av koreferansen.', 'mn': 'Цөмийн загварууд нэг эргэн хариултын асуулт (VQA) даалгаврын тухай хүчтэй үйл ажиллагааг харуулсан ч, VQA-г олон эргэн тойронд нэмэгдүүлэхэд хэцүү байдал нь хэцүү хэмжээний шаардлагатай. Энэ сорилтыг удирдах нэг арга нь өмнөх диалог дээр мэдээллийг хадгалах боломжтой механизмуудтай суурилсан мэдрэлийн VQA загваруудыг нэмэгдүүлэх юм. Нэг хүчтэй VQA загвар бол MAC сүлжээ юм. Энэ нь ажлыг анхаарлын үндсэн шалтгааныг олон анхаарлын шалтгаан руу хувааж байна. Гэхдээ MAC сүлжээнд нэг эргэлт асуулт хариултын тулд зохион байгуулагдсан учраас энэ нь өнгөрсөн диалог эргэлтийг харуулж чадахгүй. Ялангуяа энэ нь диалог түүхийн тухай ойлголт шаардлагатай ажил, ялангуяа тайвны шийдэл. МАК сүлжээний архитектурыг Context-aware Attention and Memory (CAM) дээр нэмэгдүүлнэ. Энэ нь өнгөрсөн диалог дээр удирдах улс орнуудыг удирдаж байгаа, одоогийн асуултын шаардлагатай шалтгаан үйл ажиллагааг тодорхойлох болом CAM-ын MAC сүлжээний хувьд CLEVR-диалогын өгөгдлийн сан дээр 98.25% зөв байдал хүртэл 30% (абсолютт) орж байна. Бидний алдааны шинжилгээ нь CAM-ээр загварын үйл ажиллагааны үйл ажиллагааг илүү сайжруулж байгааг харуулдаг.', 'ro': 'În timp ce modelele neurale au demonstrat că prezintă performanțe puternice în sarcinile vizuale de răspuns la întrebări (VQA) cu o singură virajă, extinderea VQA la un cadru de conversație cu mai multe viraje rămâne o provocare. O modalitate de a aborda această provocare este de a extinde modelele de VQA neurale puternice existente cu mecanismele care le permit să rețină informații din conversațiile anterioare de dialog. Un model puternic VQA este rețeaua MAC, care descompune o sarcină într-o serie de pași de raționament bazați pe atenție. Cu toate acestea, deoarece rețeaua MAC este proiectată pentru răspunsul la întrebări cu un singur rând, nu este capabilă să se refere la răspunsurile anterioare de dialog. Mai exact, se luptă cu sarcini care necesită raționament în istoricul dialogurilor, în special rezoluția corefenței. Extindem arhitectura rețelei MAC cu atenție și memorie conștientă de context (CAM), care participă la stările de control în conversațiile anterioare de dialog pentru a determina operațiunile necesare de raționament pentru întrebarea curentă. Rețelele MAC cu CAM obțin o precizie de până la 98,25% pe setul de date CLEVR-Dialog, depășind cu 30% (absolut) nivelul de ultimă generație existent. Analiza noastră a erorilor indică faptul că, în cazul CAM, performanța modelului s-a îmbunătățit în special în cazul întrebărilor care necesitau rezolvarea corefenței.', 'pl': 'Podczas gdy wykazano, że modele neuronowe wykazują się dużą wydajnością w zadaniach wizualnego odpowiadania na pytania pojedynczego obrotu (VQA), rozszerzenie VQA na wielokrotne, konwersacyjne otoczenie pozostaje wyzwaniem. Jednym ze sposobów rozwiązania tego wyzwania jest rozszerzenie istniejących silnych neuronowych modeli VQA o mechanizmy, które pozwalają im zachować informacje z poprzednich obrotów dialogowych. Jednym z silnych modeli VQA jest sieć MAC, która rozkłada zadanie na serię kroków rozumowania opartych na uwadze. Ponieważ jednak sieć MAC jest przeznaczona do odpowiedzi na pytania jednorazowe, nie jest w stanie odwoływać się do poprzednich obrotów dialogowych. Mówiąc dokładniej, zmaga się z zadaniami, które wymagają rozumowania w historii dialogu, w szczególności rozwiązywania współreferencji. Rozszerzamy architekturę sieci MAC o Context-aware Attention and Memory (CAM), która obsługuje stany kontroli w poprzednich obrotach dialogowych w celu określenia koniecznych operacji rozumowania dla bieżącego pytania. Sieci MAC z CAM osiągają dokładność do 98,25% na zbiorze danych CLEVR-Dialog, pokonując istniejący state-of-the-art o 30% (absolutny). Nasza analiza błędów wskazuje, że dzięki CAM wydajność modelu poprawiła się szczególnie w kwestiach, które wymagały rozwiązywania współdziałania.', 'so': "Inta lagu muujiyo tusaalaha neurada oo xoog leh oo lagu sameeyo jawaabta su'aalaha hal jeer ah ee aragga (VQA) oo ku fidinaya VQA si loo beddelo in loo beddelo hal jeer ah, dabeecada hadalku waa mid adag. Mid ka mida qaababkan la macaamilo karo waa in lagu kordhiyo noocyada daboolka ah oo xoogga leh ee VQA, kuwaas oo u ogolaada in ay macluumaad ku haystaan dib u soo jeedista dialogiga hore. Tusaale xoog leh oo VQA waa shabakadda MAC, kaas oo shaqada u bedeshaa tallaabooyin kala duduwan oo caqli ah. Si kastaba ha ahaatee shabakadda MAC waxaa loo qoray jawaabta su'aalaha hal jeer ah, mana awoodi karo in loo sheego bedelka labaad ee hore. Si gaar ah waxaa la dagaallamaa shaqaalaha loo baahan yahay inay ka fikiraan taariikhda, khusuusan go’aanka gaarka ah. Waxaannu ku fidinnaa dhismaha shabakadda MAC ee ku jira Context-aware Attention and Memory (CAM), kaas oo ka mid ah dowlada kontrollka ee hore, si aan u go’aamino shuqullada sababta ah ee ay u baahan yihiin su'aalka joogta. shabakada MAC ee CAM waxay gaadhaan ilaa 98.25% si saxda ah oo ku qoran CLEVR-Dialog, oo ku garaaca xaaladda ku jira 30% (absolute). Analyska qaladkayaga waxaa loola jeedaa in sameynta qaababka sameynta si gaar ah loo hagaajiyey su'aalaha loo baahan yahay go'aanka kaarka.", 'sr': 'Dok se pokazuju neurološki modeli kako bi pokazali jaku predstavu na jednookret vizualno pitanje odgovarajućih zadataka (VQA), proširenje VQA na višeokret, razgovorno postavljanje ostaje izazov. Jedan način za rješavanje ovog izazova je povećanje postojećih jakih neuralnih VQA modela sa mehanizama koje im omogućavaju da zadrže informacije iz prethodnog dijaloga. Jedan snažan model VQA je mreža MAC, koja raspoređuje zadatak u nizu razumnih koraka na pažnji. Međutim, pošto je MAC mreža dizajnirana za odgovor na jednookret pitanja, nije sposobna da se odnosi na prošli okret dijaloga. Posebno se bori sa zadacima koji zahtevaju razgovor o istoriji dijaloga, posebno rezolucijom pristojnosti. Proširimo arhitekturu MAC mreže sa pažnjom i pamćenjem konteksta (CAM), koja prisustvuje nad kontrolnim državama u prošlom dijalogu, kako bi utvrdila potrebne operacije razuma za trenutno pitanje. MAC mreže sa CAM postižu do 98,25% tačnosti na setu podataka CLEVR-Dialoga, pobeđujući postojeće stanje umjetnosti za 30% (apsolutno). Naša analiza greške ukazuje na to da je sa CAM-om provedba modela posebno poboljšana na pitanja koja su potrebna rezolucija pristojnosti.', 'si': 'න්\u200dයූරාල් මොඩල් පෙන්වන්න පුළුවන් වෙලා තියෙන්නේ තරම් ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතික්\u200dරියාවට (VQA) ප්\u200dරතික්\u200dරියාවට බලාපොරොත්තු වැඩ මේ අභ්\u200dයානය විශ්වාස කරන්න එක ප්\u200dරමාණයක් තමයි තියෙන්නේ ශක්තිමත් න්\u200dයූරාල VQA මොඩේල්ස් එක්ක ප්\u200dරමාණයක් විශා එක බලාපොරොත්තු VQA මදුල්ය MAC ජාලය, ඒකෙන් අවධානය සඳහා අධ්\u200dයානය අධ්\u200dයානය කරපු පැත්තුවක් විතරයි. නමුත්, MAC ජාලය එකම ප්\u200dරශ්න ප්\u200dරතිච්චාරය සඳහා සැකසුම් කරලා තියෙන්නේ, ඒක අතිත් සංවාදය ප්\u200dරතිචාරය තව විශේෂයෙන්, ඒක සංවාද ඉතිහාසයෙන් හිතන්න අවශ්\u200dය වැඩක් සමඟ ප්\u200dරශ්නය කරනවා, විශේෂයෙන් සම්බන අපි සම්බන්ධ පරීක්ෂණය සහ මතකය (CAM) සමඟ MAC ජාලය සංවිධානය විස්තර කරනවා, ඒක අතින් සංවාදයේ පාලනය සඳහා ප්\u200dරශ්නය සඳහා අව CAM සඳහා MAC ජාලය සඳහා CLEVR-සංවාදයේ තොරතුරු සම්බන්ධතාවට 98.25% තියෙනවා, තියෙන්න තොරතුරු ස්ථිතිය 30% තියෙනවා. අපේ වැරදි විශ්ලේෂණය පෙන්වන්නේ CAM එක්ක, මොඩල් එක්ක ප්\u200dරශ්නයක් විශේෂයෙන් ප්\u200dරශ්නයක් විශේෂය කර', 'ur': 'اگرچہ نئورل نمڈلوں کو دکھایا گیا ہے کہ ایک ٹوٹ ویزیل سؤال کے جواب دینے (VQA) کے بارے میں مضبوط فعالیت دکھائے جاتے ہیں، VQA کو multi-turn تک پھیلاتے ہیں، بات سنیٹ ایک چال ہے۔ اس چال کے بارے میں ایک طریقہ ہے کہ موجود نیورال VQA موڈل کو مکانیزوں کے ساتھ زیادہ کرنا ہے جو ان کو پہلے ڈالیلوگ سے معلومات حفظ کرنے کی اجازت دیتے ہیں. ایک مضبوط VQA موڈل MAC نیٹ ورک ہے جس نے ایک کام کو توجه کی بنیادی منطقی قدم میں تقسیم کرتا ہے. However, since the MAC network is designed for single-turn question replying, it is unable to refer to the past dialog turns. اور زیادہ مخصوص، یہ کاموں کے ساتھ جہاد کرتا ہے جن کی تاریخ کے بارے میں بحث کی ضرورت ہے، مخصوصاً مہربانی رخصت. ہم مک نیٹ ورک معماری کو کنٹکس آگاہ اور مہموری (CAM) کے ساتھ پھیلاتے ہیں جو اگلوں کے دیالوگ میں کنٹرول کی حالت پر حاضر ہوتی ہے اس کے لئے موجود سوال کے لئے ضروری منطقی عملیات کا فیصلہ کرنا ہے۔ CAM کے مطابق MAC نٹے CLEVR-Dialog ڈیٹ سٹ پر 98.25% دقیق پہنچ رہے ہیں، 30% (بالکل) موجود آرٹ کی حالت کو مارتے ہیں۔ ہماری غلطی تحلیل نشان دیتا ہے کہ CAM کے ساتھ مدل کی عملکرد ویسے ہی بہتر ہوئی سوالوں پر جو مہربانی رخصت کی ضرورت رکھتے ہیں۔', 'ta': 'புதிய மாதிரிகள் தனித்திருக்கும் பார்வை கேள்வி விக்கு பதில் உறுதியான செயல்பாட்டை காண்பிக்கும் போது, விக்யூஏவை பல திருப்பும் போது, ப இந்த சவால்களை விளக்க ஒரு வழியாக இருக்கும் வலிமையான புதிய VQA மாதிரிகளை சேர்க்க முடியும் முன்பு உரையாடல் மாறியிலிருந்து  ஒரு வலிமையான VQA மாதிரி MAC வலைப்பின்னல், அது ஒரு செயலை ஒரு வரிசையில் கவனத்தை அடிப்படையான காரணங்களை குறைக்கிறது. ஆனால், MAC வலைப்பின்னல் தனித்திருக்கும் கேள்வி பதில் வடிவமைக்கப்பட்டதால், முந்தைய உரையாடல் மாற்றங்களை குறிப்பிட மேலும் குறிப்பிட்டு, இது செயல்களுடன் போராடுகிறது, உரையாடல் வரலாற்றில் குறிப்பிட்ட குறிப்பிட்ட தீர்வு நாம் MAC வலைப்பின்னல் அமைப்புகளை சூழல் உணர்ந்து கவனிப்பு மற்றும் நினைவகத்துடன் விரிவாக்குகிறோம், அது முந்தைய கட்டுப்பாட்டு நிலைகள் மேல்  CAM உடன் MAC வலைப்புகள் 98. 25% துல்லியமானது CLEVR- உரையாடல் தரவுத்தளத்தின் துல்லியமானது, தற்போதைய நிலையில் இருக்கும் கலை 30% (முழுமையாக). எங்கள் பிழை அறிவிப்பு குறிப்பு தேவைப்படும் கேள்விகளின் மாதிரியின் செயல்பாடு முன்னேற்றப்பட்டது.', 'sv': 'Även om neurala modeller har visat sig uppvisa starka prestanda på VQA-uppgifter (Single-Turn Visual Question Responsing), utökar VQA till en multi-Turn, är konversationsinställning fortfarande en utmaning. Ett sätt att hantera denna utmaning är att utöka befintliga starka neurala VQA-modeller med mekanismer som gör det möjligt för dem att behålla information från tidigare dialogvändningar. En stark VQA-modell är MAC-nätverket, som delar upp en uppgift i en rad uppmärksamhetsbaserade resonemangssteg. Eftersom MAC-nätverket är utformat för att besvara frågor med en enda vändning kan det dock inte hänvisa till tidigare dialogvändningar. Mer specifikt kämpar den med uppgifter som kräver resonemang över dialoghistoriken, särskilt coreference upplösning. Vi utökar MAC-nätverksarkitekturen med Context-aware Attention and Memory (CAM), som deltar i kontrolltillstånd i tidigare dialogsvängar för att fastställa nödvändiga resonemang operationer för den aktuella frågan. MAC-nät med CAM uppnår upp till 98,25% noggrannhet på CLEVR-Dialog-datauppsättningen, vilket slår befintliga toppmoderna med 30% (absolut). Vår felanalys visar att med CAM förbättrades modellens prestanda särskilt på frågor som krävde coreferencelolution.', 'uz': "Name Bu muammolani boshqarish uchun bir usul, mavjud katta neyrol VQA modellarini qoʻshish va ularni oldingi oynalardan maʼlumot davom etishga ruxsat beradi. Bir sterk VQA modeli MAC tarmoqda, bu vazifani bir guruhi paydo bo'lgan sabablarning bir guruhini o'zgartiradi. Lekin, MAC tarmoqda bir necha boshqa savol javob berish uchun yaratilmoqda, past dialog turini aytib boʻlmaydi. Koʻrsatilgan, bu muloqat tarixi tarixi haqida gapirish kerak vazifalari bilan harakat qiladi, hususan murakkab oʻrnatish. Biz MAC tarmoqni taʼminlovchi taʼminlovchi va xotira (CAM) bilan ajratishimiz mumkin. Bu oldingi oyna boshqaruvchi davlatlarni boshqarishga ega bo'lgan muloqat oynasida bo'lgan narsalarni joriy savol uchun kerak sabablar amallarini aniqlashga aytadi. Name Bizning xato analyzerimiz CAM bilan modelning amalni bajarish kerak bo'lgan maslahatlariga bajarishi mumkin.", 'vi': 'Trong khi các mô hình thần kinh được cho thấy khả năng năng đạt được khi đặt câu hỏi bằng một lần (kiểu QA) trong các nhiệm vụ, mở rộng VQA thành nhiều lượt, nhưng đối thoại vẫn là một thử thách. Một cách để giải quyết thử thách này là tăng cường các mô hình thần kinh VQA mạnh bằng các cơ chế giúp họ giữ lại thông tin từ các thay đổi hộp thoại trước. Một mô hình mạnh VQA là mạng MAC, nơi phân hủy một nhiệm vụ thành một chuỗi các bước lập luận dựa trên sự chú ý. Tuy nhiên, vì mạng máy MAC được thiết kế để trả lời câu hỏi một lần, nó không có khả năng sử dụng để sử dụng các thay đổi hộp thoại quá khứ. Cụ thể hơn, nó đấu tranh với các công việc cần lập trình về lịch sử hộp thoại, đặc biệt là giải quyết khả năng. Chúng ta mở rộng cấu trúc mạng MAC với Thông tin chú ý và nhớ (CAM), nó tham gia vào các trạng thái điều khiển trong hộp thoại trước để xác định phương pháp lý giải thích cần thiết cho câu hỏi hiện thời. Một bộ lưới MAC với CAM đạt đến một độ chính xác cao 98.25. trên tập tin được xóa, đánh bại tình trạng tuyệt đối. Theo phân tích lỗi của chúng tôi thì với CAM, hiệu quả của mô hình đã được cải thiện đặc biệt về các vấn đề cần phải giải quyết.', 'bg': 'Доказано е, че невралните модели показват силна производителност при задачи с еднократно визуално отговаряне на въпроси (ВКА), разширяването на ВКА до многократно, разговорната обстановка остава предизвикателство. Един от начините да се справим с това предизвикателство е да разширим съществуващите силни невронни модели с механизми, които им позволяват да задържат информация от предишни диалогови завои. Един силен модел е мрежата, която разгражда задачата в серия от стъпки на разсъждаване, базирани на вниманието. Въпреки това, тъй като мрежата е предназначена за еднократно отговаряне на въпроси, тя не е в състояние да се позовава на минали диалогови завои. По-конкретно, той се бори със задачи, които изискват разсъждаване върху историята на диалога, особено резолюцията на кореференцията. Разширяваме мрежовата архитектура с внимание и памет, които наблюдават състоянието на контрол в минали диалогови завои, за да се определят необходимите операции за разсъждаване на текущия въпрос. Мрежата с МАК постига до 98.25% точност на набора от данни, биейки съществуващите съвременни технологии с 30% (абсолютно). Нашият анализ на грешките показва, че с производителността на модела се подобрява особено при въпроси, които изискват решаване на кореференцията.', 'da': 'Mens neurale modeller har vist sig at udvise stærk ydeevne på single-turn visuel spørgsmål besvarelse (VQA) opgaver, udvider VQA til en multi-turn, samtaleindstilling forbliver en udfordring. En måde at løse denne udfordring på er at udvide eksisterende stærke neurale VQA modeller med de mekanismer, der gør det muligt for dem at bevare oplysninger fra tidligere dialogsving. En stærk VQA-model er MAC-netværket, som opdeler en opgave i en række opmærksomhedsbaserede ræsonneringstrin. Men da MAC-netværket er designet til spørgsmålsbesvarelse med ét sving, er det ikke i stand til at henvise til tidligere dialogsving. Mere specifikt kæmper den med opgaver, der kræver ræsonnement over dialogens historie, især coreferenceopløsning. Vi udvider MAC netværksarkitekturen med Context-award Attention and Memory (CAM), som overvåger kontroltilstande i tidligere dialogsving for at bestemme de nødvendige ræsonnement operationer for det aktuelle spørgsmål. MAC-net med CAM opnår op til 98,25% nøjagtighed på CLEVR-Dialog datasættet, hvilket slår de eksisterende state-of-the-art med 30% (absolut). Vores fejlanalyse viser, at med CAM er modellens ydeevne særligt forbedret på spørgsmål, der krævede coreferenceopløsning.', 'nl': 'Hoewel neuronale modellen sterke prestaties vertonen bij single turn visual question responsing (VQA)-taken, blijft het uitbreiden van VQA naar een gesprekssetting met meerdere turns een uitdaging. Een manier om deze uitdaging aan te pakken is om bestaande sterke neurale VQA modellen uit te breiden met de mechanismen die hen in staat stellen om informatie van eerdere dialogbeurten te behouden. Een sterk VQA-model is het MAC-netwerk, dat een taak opstelt in een reeks aandachtsgebonden redeneerstappen. Aangezien het MAC-netwerk echter is ontworpen voor het beantwoorden van vragen met één beurt, kan het niet verwijzen naar eerdere dialogronden. Meer specifiek worstelt het met taken die redenering vereisen over de dialooggeschiedenis, met name coreferentie resolutie. We breiden de MAC-netwerkarchitectuur uit met Context-aware Attention and Memory (CAM), die controle toestanden in eerdere dialogturns bestudeert om de noodzakelijke redenering operaties voor de huidige vraag te bepalen. MAC netten met CAM bereiken tot 98,25% nauwkeurigheid op de CLEVR-Dialog dataset en verslaan de bestaande state-of-the-art met 30% (absolute). Onze foutanalyse geeft aan dat met CAM de prestaties van het model vooral verbeterd zijn bij vragen die coreferentie-resolutie vereisen.', 'hr': 'Dok se pokazuju neuronski modeli kako bi pokazali jaku učinku na jednookrenutom vizualnom pitanju odgovarajućim zadatkima (VQA), proširenje VQA na višeokrenutom okrenutku, razgovorni nastav ostaje izazov. Jedan način za rješavanje ovog izazova je povećanje postojećih jakih neuralnih VQA modela s mehanizama koje im omogućavaju zadržati informacije iz prethodnog dijaloga. Jedan jak model VQA je mreža MAC-a, koja raspoređuje zadatak u niz razumnih koraka na temelju pažnje. Međutim, budući da je MAC mreža dizajnirana za odgovor na jednookret pitanja, nije sposobna referirati na prošli okret dijaloga. Posebno se bori sa zadacima koji zahtijevaju razgovor u povijesti dijaloga, posebno rješenjem pristojnosti. Proširimo arhitekturu MAC mreže s pozornošću i sjećanjem konteksta (CAM), koja prisustvuje nad kontrolnim državama u prošlom dijalogu, kako bi se utvrdila potrebne operacije razuma za trenutno pitanje. MAC mreže s CAM postigle su do 98,25% preciznosti na kompletu podataka CLEVR-Dialoga, pobjeđujući postojeće stanje umjetnosti za 30% (apsolutno). Naša analiza greške ukazuje na to da je s CAM-om provedba modela posebno poboljšala na pitanja koje su zahtijevale rješenje pristojnosti.', 'de': 'Während neuronale Modelle eine starke Leistung bei Single-Turn Visual Question Responsing (VQA)-Aufgaben aufweisen, bleibt die Ausweitung von VQA auf ein mehrstufiges Gesprächsumfeld eine Herausforderung. Eine Möglichkeit, diese Herausforderung anzugehen, besteht darin, bestehende starke neuronale VQA-Modelle um Mechanismen zu erweitern, die es ihnen ermöglichen, Informationen aus früheren Dialogdrehungen zu speichern. Ein starkes VQA-Modell ist das MAC-Netzwerk, das eine Aufgabe in eine Reihe von aufmerksamkeitsbasierten Denkschritten zerlegt. Da das MAC-Netzwerk jedoch für die Beantwortung von Single-Turn-Fragen ausgelegt ist, kann es sich nicht auf vergangene Dialogdrehungen beziehen. Genauer gesagt kämpft es mit Aufgaben, die eine Überlegung über die Dialoghistorie erfordern, insbesondere die Auflösung von Coreferenz. Wir erweitern die MAC-Netzwerkarchitektur um Context-aware Attention and Memory (CAM), die in vergangenen Dialogdrehungen Kontrollzustände überwacht, um die notwendigen Argumentationsoperationen für die aktuelle Frage zu bestimmen. MAC-Netze mit CAM erreichen eine Genauigkeit von bis zu 98,25% auf dem CLEVR-Dialog Datensatz und übertreffen den bestehenden Stand der Technik um 30% (absolut). Unsere Fehleranalyse zeigt, dass sich mit CAM die Leistung des Modells besonders bei Fragen verbessert hat, die eine Coreferenzlösung erfordern.', 'id': 'Sementara model saraf telah ditunjukkan untuk menunjukkan prestasi yang kuat pada pertanyaan visual single-turn menjawab tugas (VQA), memperluas VQA ke multi-turn, seting konversasi tetap tantangan. Salah satu cara untuk mengatasi tantangan ini adalah meningkatkan model VQA saraf yang ada dengan mekanisme yang memungkinkan mereka untuk menyimpan informasi dari dialog sebelumnya. Satu model VQA yang kuat adalah jaringan MAC, yang menghancurkan tugas menjadi serangkaian langkah pemikiran berdasarkan perhatian. Namun, karena jaringan MAC dirancang untuk menjawab pertanyaan satu putaran, ia tidak mampu merujuk ke putaran dialog yang lalu. Lebih spesifik, ia berjuang dengan tugas yang membutuhkan alasan atas sejarah dialog, terutama resolusi koreferensi. Kami memperluas arsitektur jaringan MAC dengan Perhatian dan Memori (CAM) yang menyaksikan keadaan kontrol dalam dialog yang lalu berubah untuk menentukan operasi alasan yang diperlukan untuk pertanyaan saat ini. Rangkaian MAC dengan CAM mencapai sampai 98,25% akurasi pada set data CLEVR-Dialog, mengalahkan keadaan-state-of-the-art yang ada dengan 30% (absolut). Analisi kesalahan kami menunjukkan bahwa dengan CAM, prestasi model terutama meningkat pada pertanyaan yang memerlukan resolusi koreferensi.', 'ko': '신경모형은 1회 시각문답(VQA) 임무에서 강한 성능을 보였지만, VQA를 다회적 대화 환경으로 확장하는 것은 여전히 도전이다.이 도전을 해결하는 방법은 이전의 대화 라운드 정보를 보존할 수 있는 메커니즘으로 기존의 강신경 VQA 모델을 강화하는 것이다.강력한 VQA 모델은 MAC 네트워크로 임무를 일련의 주의에 기초한 추리 절차로 분해한다.그러나 MAC 네트워크는 단일 라운드 질문에 대한 대답을 위해 설계된 것이기 때문에 과거의 대화 라운드를 인용할 수 없다.더욱 구체적으로 말하면 대화의 역사에 대한 추리가 필요한 임무, 특히 공지의 해소를 처리해야 한다.우리는 상하문 감지 주의와 기억(CAM)으로 MAC 네트워크 체계 구조를 확장시켰다. 이것은 과거의 대화 라운드에서 제어 상태를 주목하여 현재 문제의 필요한 추리 조작을 확정했다.CAM이 있는 MAC 네트워크는 CLEVR 대화 데이터 세트에서 기존 최첨단 수준보다 30%(절대치) 높은 98.25%의 정확도를 달성했다.우리의 오차 분석에 의하면 CAM이 생겨서 모델의 성능은 공통적으로 지적하여 해소해야 하는 문제에서 특별히 개선되었다.', 'sw': 'Wakati mitindo ya neura imeonyeshwa kuonyesha ufanisi wa nguvu juu ya maswali ya kuona moja kwa moja ya kujibu kazi za maoni (VQA), kuongeza VQA kwa upande mwingine, mazungumzo ya mazungumzo yanabaki kuwa changamoto. Njia moja ya kukabiliana na changamoto hili ni kuongeza mifano yenye nguvu ya VQA ya kisasa yenye mfumo ambao unaruhusu kuendelea taarifa kutoka katika mazungumzo yaliyopita. One strong VQA model is the MAC network, which decomposes a task into a series of attention-based reasoning steps.  Hata hivyo, kwa kuwa mtandao wa MAC umeundwa kwa ajili ya kujibu swali moja kwa moja, haina uwezo wa kuielezea mabadiliko ya mazungumzo yaliyopita. Zaidi zaidi, inapambana na kazi zinazohitaji kufikiri kuhusu historia ya mazungumzo, hasa utatuzi wa msingi. Tunaendelea ujenzi wa mtandao wa MAC kwa ajili ya kusikiliza na Kumbukumbu (CAM), ambao unahudhuria juu ya mataifa ya kudhibiti mazungumzo yaliyopita inageuka kuamua shughuli muhimu za maana kwa swali la sasa. Tovuti za MAC na CAM zinafanikiwa kufikia asilimia 98.25 ya uhakika kwenye seti ya data za CLEVR-Dialog, ikipiga hali ya sanaa iliyopo kwa asilimia 30 (haina ujumla). Uchambuzi wetu wa makosa unaonyesha kuwa kwa CAM, utendaji wa mifano ulioboreshwa hasa juu ya maswali yanayohitaji suluhisho la msingi.', 'tr': 'Nytaral nusgalar ýekeje gezek görnüş soraglaryň jogaplarynda güýçli ukyplary görkezmek üçin görkezildi we VQA-ny birnäçe çenli çenli seretse, soňlaşma düzümleri kynçylyk bolup durýar. Bu kynçylygy çözmek üçin bir ýoly mevcut güýçli neural VQA modellerini öňki dialogdan informasiýa saklamak üçin meýdançalar bilen üýtgetmekdir. Bir güýçli VQA nusgasy MAC netijesidir. Bu buýruky üns daýrylýan düşünseler adımlaryna çykarýar. Ýöne MAC şebekesi ýeke bir arz soragy jogap üçin tasarlanýandygyna sebäbi bu geçen dialogyň çarpakyny ýazmak mümkin däl. Aýratyn görä, bu kynçylyklar bilen döwürýär, döwürden geçmişiň üstünde düşünseler gerekli zadlar bilen, iň bellenen çekişmeler. Biz MAC şebeke arhitektegi Kontekst-tarapyndan habaryň we Memory (CAM) bilen uzatdyrys. Bu sistemi geçmişki dialogda kontrol durumlaryň üstünde häzirki soragy üçin gerekli sebäpli operasiýalary bejermek üçin gatnaýar. CAM bilen MAC şebekeleri CLEVR-Dialog verileri takmynan 98.25% derejesine ýetip bilýär. Öň bar sanat durumynda 30% (absolut). Hata analyzamyz CAM bilen nusgynyň üstünliklerini ýöne-ýönelik çözümlenmesi gerekli soraglarynda has gelişmiş bolandygyny görkezýär.', 'fa': 'در حالی که مدل\u200cهای عصبی نشان داده شده\u200cاند که عملکرد قوی بر روی پاسخ\u200cهای سوال\u200cهای دیده\u200cای (VQA) یک برعکس را نمایش دهند، افزایش VQA به یک برعکس چندین برعکس، تنظیم گفتگو یک چالش باقی ماند. یک راه برای حل این چالش این است که مدل\u200cهای عصبی\u200cای قوی موجود با مکانیسم\u200cها که به آنها اجازه می\u200cدهند اطلاعات را از تبدیل\u200cهای محاورۀ قبلی نگه دارند. یک مدل VQA قوی شبکه MAC است که یک کار را به مجموعه قدم\u200cهای منطقی بر روی توجه تقسیم می\u200cکند. با این حال، از آنجا که شبکه MAC برای پاسخ سوال\u200cهای تک برعکس طراحی شده است، قادر به ارتباط به تبدیل\u200cهای محاورۀ گذشته نیست. دقیقاً با وظیفه\u200cهایی که نیاز دارند دلیل\u200cگیری در تاریخ محاوطه، مخصوصاً حل\u200cگیری رعایت کنند، مبارزه می\u200cکند. ما معماری شبکه MAC را با توجه و حافظه (CAM) که در محاورۀ گذشته در حالت کنترل در محاورۀ کنترل حاضر می\u200cشود، با توجه و حافظه\u200cای که به محاورۀ محاورۀ محاورۀ محاورۀ محاورۀ محاورۀ شبکه\u200cهای MAC با CAM تا 98.25% دقیق روی مجموعه داده\u200cهای CLEVR-Dialog می\u200cرسند، با شکست وضعیت هنر موجود به 30% (مطلق). تحلیل خطای ما نشان می دهد که با CAM، عملکرد مدل مخصوصاً در سوالاتی که نیاز به حل احترام نیاز دارند بهتر شده است.', 'sq': 'While neural models have been shown to exhibit strong performance on single-turn visual question answering (VQA) tasks, extending VQA to a multi-turn, conversational setting remains a challenge.  Një mënyrë për të trajtuar këtë sfidë është të rritet modelet ekzistuese të forta të VQA nervore me mekanizmat që i lejojnë ata të mbajnë informacion nga kthesat e dialogut të mëparshëm. Një model i fortë VQA është rrjeti MAC, i cili shkatërron një detyrë në një seri hapash arsyetimi të bazuar në vëmendje. Megjithatë, pasi rrjeti MAC është dizajnuar për përgjigjen e pyetjeve me një kthesë të vetme, ai nuk është i aftë të referohet në kthesat e dialogut të kaluar. Më specifikisht, ai lufton me detyra që kërkojnë arsyetim lidhur me historinë e dialogut, veçanërisht zgjidhjen e koreferencës. Ne zgjerojmë arkitekturën e rrjetit MAC me vëmendje dhe kujtesë (CAM) që ndjek mbi shtetet e kontrollit në dialogun e kaluar kthehet për të përcaktuar operacionet e arsyetimit të nevojshëm për pyetjen aktuale. Rrjetet MAC me CAM arrijnë deri në 98.25% saktësi në kompletin e të dhënave CLEVR-Dialog, duke mundur gjendjen ekzistuese të teknologjisë me 30% (absolut). Analiza jonë e gabimeve tregon se me CAM, performanca e modelit veçanërisht u përmirësua në pyetje që kërkonin zgjidhje koreference.', 'am': 'የነዌብ ዓይነቶች በአንዲስ ቅድሚያ የዓይነ ጥያቄ መልስ (VQA) ስራዎችን ለማሳየት ሲታይ፣ የVQA ለብዙዎች ማሳየት፣ የሚናገሩት አካባቢ ግንኙነት አዋቂ ነው፡፡ ይህንን ጥቃት ለመቀበል አንድ መንገድ ነው፣ የአሁኑን ጠንካራ የVQA ሞዴላዎችን በመጨመር እና መረጃዎችን ከቀድሞው dialog በመስመር እንዲያቆሙ የሚችሉትን አካባቢዎች ለመጨመር ነው፡፡ አንድ ብርቱ VQA model የMAC መረብ ነው፡፡ ነገር ግን የMAC መረብ ለብቻውን ጥያቄ ለመመልስ ከፈጠረ ጀምሮ፣ ባለፈው ጥያቄ ለመመለስ አይችልም፡፡ More specifically, it struggles with tasks that require reasoning over the dialog history, particularly coreference resolution.  የአሁኑ ጥያቄ ጥያቄ ላይ ባለፈው አካባቢ አካባቢ እና ማስታወሻ (CAM) የMAC መረብ መሠረት አካባቢውን እናሳድጋለን፡፡ MAC የመረብ መረብ ከCAM ጋር በCLEVR-Dialog ዳይማር ላይ ቁጥር 98.25 በመቶ ያድጋል፡፡ የስህተታችንን ትምህርት መፍትሕት በሚያስፈልገው ጥያቄዎች የሞዴል ፍትሕት በኩል በማስተካከል የሚያሳየው ነው፡፡', 'hy': "Մինչդեռ ցույց է տվել, որ նյարդային մոդելները ցույց են տալիս ուժեղ արտադրողականություն մեկ անգամ վիզուալ հարցերին պատասխանելու (VQA) խնդիրների վրա, VQA-ի ընդլայնումը բազմաանգամ, հաղորդակցման միջոցը դեռևս Այս մարտահրավերի լուծման մեկ միջոցը գոյություն ունեցող ուժեղ նյարդային VQA մոդելների աճը մեխանիզմներով, որոնք թույլ են տալիս նրանց պահել տեղեկատվությունը նախորդ երկրորդ շրջաններից: Մեկ ուժեղ VQA մոդելը MAC ցանցն է, որը բաժանում է խնդիրը ուշադրության վրա հիմնված մտածողական քայլերի մի շարք: Այնուամենայնիվ, քանի որ MAC ցանցը նախագծված է մեկ անգամ հարցերին պատասխանելու համար, այն չի կարողանում խոսել անցյալ երկրորդ անգամ: Ավելի հատկապես, այն պայքարում է այն խնդիրների հետ, որոնք պահանջում են խորհրդատվություն պատմության մասին, հատկապես հարաբերությունների լուծման: Մենք ընդլայնում ենք MAC ցանցի ճարտարապետությունը Կոնտեքստի գիտակցությամբ Ուշադրություն և Հիշողություն (CAM), որը մասնակցում է վերահսկողական վիճակների վերաբերյալ անցյալ հաղորդակցման մեջ, և որոշում է ներկայիս հարցի համար անհրաժեշտ CAM-ով MAC ցանցերը հասնում են մինչև 98.25 տոկոսի ճշգրիտությունը կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիվ կլիք կլիք կլիք կլիք կլիք կլիք կ Our error analysis indicates that with CAM, the model's performance particularly improved on questions that required coreference resolution.", 'af': "Terwyl neurale modele is vertoon om sterk prestasie op enkel- draai visuele vraag antwoord (VQA) te vertoon, wat VQA uitbrei na 'n multi- draai, omskakelike instelling bly 'n uitdrukking. Een manier om hierdie uitdrukking te adres is om bestaande sterk neurale VQA modele te vergroot met die mekanisme wat hulle toelaat om inligting te hou van vorige dialoog draai. Een sterk VQA model is die MAC-netwerk, wat 'n taak in' n reeks van aandag-gebaseerde redekening stappe ontkoppel. Maar, omdat die MAC netwerk is ontwerp vir enkel- draai vraag antwoord, is dit nie in staat om te verwys na verlede dialoog draai nie. Meir spesifieke, het dit struikel met opdragte wat redening vereis oor die dialoog geskiedenis, spesifieke koreferensieresolusie. Ons uitbrei die MAC netwerk arkitektuur met Context-aware Aangaande en Geheue (CAM), wat aangaan oor beheer staatste in verlede dialoog draai om die nodige rede operasies vir die huidige vraag te bepaal. MAC netwerke met CAM bereik tot 98.25% presies op die CLEVR- Dialog datastel, slaan die bestaande status- of- the- art by 30% (absoluut). Ons fout analisie wys dat met CAM, die model se prestasie spesifieke verbeter het op vrae wat benodig goederheidsoplossing.", 'bn': 'যদিও নিউরেল মডেল প্রদর্শন করা হয়েছে যেখানে একটি প্রত্যেক দৃষ্টিভঙ্গি প্রশ্নের উত্তর (ভিকিউএ) কাজের উপর শক্তিশালী প্রদর্শন করা হয়েছে, যার ফলে ভিকিয়া বহু এই চ্যালেঞ্জের কথা বলার একটি উপায় হচ্ছে বিদ্যমান নিউরেল ভিকিউএ মডেল যোগ করার জন্য যা পূর্ববর্তী ডায়ালগ থেকে তথ্য রাখতে পারে। একটি শক্তিশালী ভিকিউ মডেল হচ্ছে MAC নেটওয়ার্ক, যা একটি কাজের মাধ্যমে মনোযোগ প্রদান করা যায়। তবে যেহেতু MAC নেটওয়ার্ক একক প্রশ্নের উত্তরের জন্য ডিজাইন করা হয়েছে, এটা অতীত ডায়ালগ পরিবর্তনের কথা উল্লেখ করতে সক্ষম নয়। বিশেষ করে এটি কাজের সাথে সংগ্রাম করছে যা ডায়ালগ ইতিহাসের ব্যাপারে বিবেচনা প্রয়োজন, বিশেষ করে সংশোধনীর সিদ্ধান্ত আমরা ম্যাসি নেটওয়ার্ক কাঠামো বিস্তৃতি প্রসারিত করি কন্ট্রোল রাষ্ট্রের উপর মনোযোগ এবং মেমো (সিএম), যা অতীতে নিয়ন্ত্রণের রাষ্ট্রের উপর অংশগ্রহণ করে সিলিভার-ডায়ালগ ডাটাসেটে মাসি নেটওয়ার্ক ৯৮. ২৫% পর্যন্ত সঠিকভাবে পৌঁছেছে, যা বিদ্যমান অবস্থানের শিল্পের পরিস্থিতি ৩০% (সম্পূর্ আমাদের ত্রুটির বিশ্লেষণ নির্দেশ করছে যে কিএম এর সাথে মডেলের কর্মকাণ্ড বিশেষ করে প্রশ্নের প্রয়োজনীয় কোরিফেন্সের সি', 'bs': 'Dok se pokazuju neurološki modeli kako bi pokazali jaku učinku na jednookrenutom vizualnom pitanju odgovarajućim zadacima (VQA), proširenje VQA na višeokrenutom okrenutom, razgovorno postavljanje ostaje izazov. Jedan način za rješavanje ovog izazova je povećanje postojećih jakih neuralnih VQA modela sa mehanizama koje im omogućavaju da zadrže informacije iz prethodnog dijaloga. Jedan jak model VQA je mreža MAC-a, koja raspoređuje zadatak u niz razumnih koraka na temelju pažnje. Međutim, pošto je MAC mreža dizajnirana za odgovor na jednookret pitanja, nije sposobna da se odnosi na prošli okret dijaloga. Posebno se bori sa zadacima koji zahtijevaju razgovor u povijesti dijaloga, posebno rezolucijom pristojnosti. Proširimo arhitekturu MAC mreže s pozornošću i pamćenjem konteksta (CAM), koja prisustvuje nad kontrolnim državama u prošlom dijalogu, kako bi utvrdila potrebne operacije razuma za trenutno pitanje. MAC mreže s CAM postigle su do 98,25% tačnosti na setu podataka CLEVR-Dialoga, pretući postojeće stanje umjetnosti za 30% (apsolutno). Naša analiza greške ukazuje na to da je sa CAM-om provedba modela posebno poboljšana na pitanja koja su potrebna rješavanja pristojnosti.', 'ca': "Mentre que s'ha demostrat que els models neurals mostran un fort rendiment en les tasques de resposta a preguntes visuals d'una sola gira (VQA), l'estensió de VQA a un entorn de conversació molt gira encara és un repte. Una manera d'abordar aquest repte és augmentar els models VQA neurals forts existents amb els mecanismes que els permeten conservar informació de girs de diàleg anteriors. Un model fort de VQA és la xarxa MAC, que descompot una tasca en una sèrie de pas de raonament basats en l'atenció. Però, com que la xarxa MAC està dissenyada per respondre a preguntes de gir únic, no és capaç de referir-se a girs de diàleg passats. Més concretament, lluita amb tasques que requereixen raonament sobre la història del diàleg, sobretot la resolució de coreferencia. Estendem l'arquitectura de la xarxa MAC amb Context-aware Attention and Memory (CAM), que asisteix sobre els estats de control en el diàleg passat gira per determinar les operacions de raonament necessàries per la pregunta actual. Les xarxes MAC amb CAM aconsegueixen fins al 98,25% de precisió en el conjunt de dades CLEVR-Dialog, superant l'actualitat en 30%. L'anàlisi d'error s indica que amb CAM, el rendiment del model es va millorar particularment en qüestions que necessitaven una solució de coreferencia.", 'az': 'Nöral modelləri tək dönüş vizuali sual cavab verən (VQA) işlərində güclü performansı göstərmək üçün göstərildiyi halda, VQA çoxlu dönüş üçün genişlənir, danışmaq qurğuları isə çətin deyildir. Bu çətinlikdən çəkinmək üçün bir yol, əvvəlki dialogdan məlumatları saxlamağa imkan verən mehanizmilərlə mövcud olan nöral VQA modellerini artırmaq. Qüvvətli VQA modeli MAC şəbəkədir ki, bir işi dikkat-tabanlı dəyişiklik adımlarına parçalayır. Ancaq MAC ağı tək dönüş sualına cavab vermək üçün tasarlanmışdır, bu, keçmiş dialog ın dönüşünü danışmağa qadir deyildir. Daha müəyyən olunca, bu dəyişik keçmişi barəsində dəyişiklik lazım olan işlərlə mübahisə edir, özlərinə də mərhəmətli çözünürlük. Biz MAC şəbəkə arhitektarını Context-aware Attention and Memory (CAM) ilə genişləyirik, ki, əvvəlki dialoglarda kontrol durumlarına katılır, hökmən sual üçün ehtiyacı olan razılıq işləri təyin edər. CAM ilə MAC ağları CLEVR-Dialog veri quruluğunda 98.25% ədalətinə qədər yetirir, mövcud mövcuddur sanatın durumunu 30% (absolut) ilə döyürür. Bizim xəta analizimiz CAM ilə modelinin performansı özlərinə də mərhəmətli çözünürlük istədiyi suallarda yaxşılaşdığını göstərir.', 'cs': 'Zatímco bylo prokázáno, že neuronové modely vykazují silný výkon při jednotlivých vizuálních odpovědích na otázky (VQA), rozšíření VQA na multi-turn, konverzační prostředí zůstává výzvou. Jedním ze způsobů, jak tuto výzvu řešit, je rozšířit stávající silné neuronové modely VQA o mechanismy, které jim umožňují uchovávat informace z předchozích dialogových otáček. Jedním ze silných modelů VQA je MAC síť, která rozloží úkol na řadu kroků založených na pozornosti. Vzhledem k tomu, že MAC síť je navržena pro odpovědi na otázky s jedním otočením, není schopna odkazovat na minulé dialogové otáčky. Konkrétněji se potýká s úkoly, které vyžadují uvažování o historii dialogu, zejména řešení koreferencí. Architekturu sítě MAC rozšiřujeme o Context-aware Attention and Memory (CAM), která se v minulých dialogových otáčkách zabývá kontrolou stavů a určuje potřebné uvažovací operace pro aktuální otázku. MAC sítě s CAM dosahují až 98,25% přesnosti v datové sadě CLEVR-Dialog a porazí stávající nejmodernější technologie o 30% (absolutní). Naše analýza chyb ukazuje, že u CAM se výkon modelu zlepšil zejména u otázek, které vyžadovaly řešení koreferencí.', 'fi': 'Vaikka neuromallien on osoitettu osoittavan vahvaa suorituskykyä yhden käännöksen visuaalisissa kysymyksissä (VQA), VQA:n laajentaminen monimutkaiseen keskusteluun on edelleen haaste. Yksi tapa vastata tähän haasteeseen on lisätä olemassa olevia vahvoja hermotason VQA-malleja mekanismeilla, joiden avulla ne voivat säilyttää tietoja aiemmista dialogin käänteistä. Yksi vahva VQA-malli on MAC-verkko, joka hajottaa tehtävän useisiin huomiopohjaisiin päättelyvaiheisiin. Koska MAC-verkko on kuitenkin suunniteltu yhden käännöksen kysymyksiin vastaamiseen, se ei pysty viittaamaan aiempiin valintavuoroihin. Tarkemmin sanottuna se kamppailee sellaisten tehtävien kanssa, jotka edellyttävät pohdintaa dialogin historiassa, erityisesti koreferenssin ratkaisussa. Laajennamme MAC-verkkoarkkitehtuuria Context-aware Attention and Memory (CAM) -toiminnolla (Context-aware Attention and Memory, CAM), joka käsittelee säätötiloja aiemmissa valintavuoroissa määrittääkseen nykyisen kysymyksen edellyttämät päättelytoimet. CAM-tekniikalla varustetut MAC-verkot saavuttavat jopa 98,25% tarkkuuden CLEVR-Dialog-aineistossa ja voittavat nykyisen huipputason 30% (absoluuttinen). Virheanalyysimme osoittaa, että CAM:n avulla mallin suorituskyky parani erityisesti niissä kysymyksissä, jotka vaativat koreferenssin ratkaisua.', 'et': 'Kuigi närvimudelid on näidanud tugevat jõudlust ühekordse visuaalse küsimusele vastamise (VQA) ülesannetes, on VQA laiendamine mitme pöördega, vestluskeskkond endiselt väljakutseks. Üks võimalus selle väljakutse lahendamiseks on täiendada olemasolevaid tugevaid neuraalseid VQA mudeleid mehhanismidega, mis võimaldavad neil säilitada teavet varasematest dialoogipööretest. Üks tugev VQA mudel on MAC-võrk, mis jagab ülesande mitmeks tähelepanupõhiseks arutluseks. Kuna aga MAC võrk on mõeldud ühekordseks küsimustele vastamiseks, ei suuda see viidata varasematele dialoogipööretele. Täpsemalt võitleb see ülesannetega, mis nõuavad dialoogiajaloo arutlemist, eriti ühesuguse resolutsiooni. Laiendame MAC-i võrguarhitektuuri kontekstiteadliku tähelepanu ja mäluga (CAM), mis osaleb juhtimisolekute üle varasemates dialoogipööretes, et määrata kindlaks praeguse küsimuse jaoks vajalikud põhjendustoimingud. CAM-iga MAC-võrgud saavutavad CLEVR-Dialogi andmekogumil kuni 98,25% täpsuse, võrreldes olemasoleva tehnika tasemega 30% (absoluutne). Meie veaanalüüs näitab, et CAM-i puhul paranes mudeli jõudlus eriti küsimustes, mis nõudsid põhiviidete lahendamist.', 'ha': "While neural models have been shown to exhibit strong performance on single-turn visual question answering (VQA) tasks, extending VQA to a multi-turn, conversational setting remains a challenge.  Tsarin da za'a yi amfani da wannan tsohon hanyarwa shine a ƙara motel mai ƙarfi na maɓallin vQA da shiryoyin ayuka da za'a yarda su riƙe tsari daga zauren akwatin bayani na gaba. Wata misalin mai ƙarfi na V QA shi ne shirin MAC, wanda ke karya wani aikin zuwa wasu hanyõyi masu bincike. A'aha, amma, don da aka ƙayyade shirin MAC don a iya karɓa wa tambayar guda-ɗaya, ba za'a iya gaya wa muhallin zauren akwatin bayani ta riga. Kayya, yana ƙaranci da aikin da za'a buƙata yin magana a kan historin akwatin zauren akwatin bayani, kuma da ƙayyade rabo masu inganci. Mu shimfiɗa tsarin shirin MAC na Content-award Attitory and memory (CAM), wanda ke halatar da kan duk mataifa na bayani na bayani zauren akwatin bayani ta riga, yana son ya ƙayyade aikin da ake ƙayyade yanzu. Intanet MAC da CAM sun isa up to 98.25% na daidaita kan data na CLEvR-Dialog, yana beating the existing state-of-the-art by 30% (cikakken). AnalyyinMu na ɓata shine cewa, gabanin misalin na CAM, yana mafĩfĩta game da masu tambayar su da ake buƙata rabo-koronto.", 'he': 'While neural models have been shown to exhibit strong performance on single-turn visual question answering (VQA) tasks, extending VQA to a multi-turn, conversational setting remains a challenge.  דרך אחת להתמודד עם האתגר הזה היא לגדל דוגמניות VQA עצביות חזקות קיימות עם המנגנונים שמאפשרים להם לשמור מידע ממופעות דיאלוג קודמות. מודל VQA חזק אחד הוא רשת MAC, אשר מפרק משימה לסדרה של צעדים הגיוניים מבוססים על תשומת לב. בכל אופן, מאחר שהרשת MAC מתוכננת לענות על שאלות מסתובבות אחת, היא לא מסוגלת להתייחס לסתובבות דיאלוג שעבר. במיוחד, הוא מתאבק עם משימות שדורשות הגיון על ההיסטוריה של הדיולוגים, במיוחד פתרון התייחסות. אנו מארחים את ארכיטקטורת הרשת MAC עם תשומת לב וזיכרון מודעת לקונקסט (CAM), אשר משתתפת במדינות שליטה בדיולוג העבר פונים כדי לקבוע את פעולות ההסבירה הנדרשות לשאלה הנוכחית. רשתות MAC עם CAM משיגות מדויקת עד 98.25% על קבוצת נתונים CLEVR-Dialog, מכות את המצב הנוכחי ביותר ב-30% (מוחלט). ניתוח הטעות שלנו מצביע כי עם CAM, ההופעה של המודל השתפרה במיוחד על שאלות שדורשות פתרון התאמה.', 'sk': 'Medtem ko je bilo dokazano, da nevronski modeli kažejo močno zmogljivost pri opravilih vizualnega odgovarjanja na vprašanja z enim obratom (VQA), razširitev VQA na več obratov, pogovorna nastavitev ostaja izziv. Eden od načinov za reševanje tega izziva je dopolnitev obstoječih močnih nevronskih modelov VQA z mehanizmi, ki jim omogočajo ohranjanje informacij iz prejšnjih zavojev dialoga. Eden od močnih modelov VQA je MAC omrežje, ki razgradi nalogo v niz korakov razmišljanja, ki temeljijo na pozornosti. Ker pa je omrežje MAC zasnovano za odgovarjanje na vprašanja z enim obratom, se ne more sklicevati na pretekle pogovorne obrate. Natančneje se bori z opravili, ki zahtevajo razmišljanje o zgodovini dialoga, zlasti reševanje koreference. Omrežno arhitekturo MAC razširimo z kontekstno zavedanim pozornostjo in pomnilnikom (CAM), ki se ukvarja z nadzornimi stanji v preteklih pogovornih zavojih, da določimo potrebne operacije obrazložitve za trenutno vprašanje. MAC mreže s CAM dosegajo do 98,25-odstotno natančnost na naboru podatkov CLEVR-Dialog, kar premaga obstoječe najsodobnejše za 30% (absolutno). Naša analiza napak kaže, da se je s CAM učinkovitost modela še posebej izboljšala pri vprašanjih, ki so zahtevala rešitev korefeference.', 'jv': 'Mungkin model sing wis ngerasai nggawe akeh bantuan sing nggawe ngubah werong sing bisa ngubah weruh-suaraning langgar sampek (VqA), nggawe VqA sampek multi-tur, terus diputasane conversationpun dumadhi kapan kuwi bisa perbudhakan Layout sing isih dumadhi karo perbudhakan iki dadi kanggo nggawe model sing wis ana, nik VqA model sing berarti karo perbudhakan sing dumadhi kanggo ngerasakno informasi sing kato dialog sing dimulai. Siji maneh sing VqA tambah kuwi MAC tambah, dadi padhas sistem dadi tanggal diputara atens-basa sing basa tanggal. Nanging, dadi MAC net ditambah kanggo sabanjuré kejahatan, kuwi ora bisa ngubah dialog sing mlaku. Juk-Juk ngomong, iso nglanggar nganggo task sing dipunanggap tarjamahan kanggo langutan dialog Awak dhéwé ngebagian architecture MAC tambah sing kontext-Awak Attention lan membersi (CaM), sing ngendalikke supoyo kang kalagayut nguasal dumadhi kanggo ngilangno sistem sing bisa ngubah perusahaan aku In Panjenengan eror kanggo ngerasakno karo CKAM, akeh model kuwi nggawe gerasane kanggo bisa nguasahan seneng nggawe gerarané surat sing bisa nggawe gerarané karo CKAM.', 'bo': 'དཔེ་གཞུང་གི་མིག་དཔེ་དབྱིབས་སྟོན་ཡོད་ནའང་ཞིག་གིས་མཐོང་བའི་རྐྱེན་སྟངས་སྟོན་རུང་ངེས་ཐོག་ལས་གནད་དོན་ལ་ལན་གསལ་བྱ་རྒྱུ་དང་། One way to address this challenge is to increase existing neural VQA models with the mechanisms that allow them to retain information from previous dialog turns. One strong VQA model is the MAC network, which decomposes a task into a series of attention-based reasoning steps. ཡིན་ནའང་། MAC དྲ་བ་ཞིག་ལ་སྤྱིར་བའི་དྲི་ཚིག་གི་ལན་སྐུལ་ལ་ཇི་འདེགས་བྱས་པ་ལས་དུས་འདས་བའི་ཌའི་ལོག་ལ་འགྲེལ་ ཁྱད་དོན་དམིགས་གསལ་བཤད་པ་ཞིག་ནི་བྱ་བ་དག་དང་མཉམ་དུ་འཐབ་རྩོལ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་Context-aware Attention and Memory (CAM)དང་དྲ་བཟོ་སྒྲིག་ཡུལ་འདི་རྒྱ་བསྐྱེད་པ་ཡིན། MAC དྲ་བ་དང་CAM་ཡོད་པའི་རྒྱུ་མཚན་གྱིས་CLEVR-ཌའི་ལོག ང་ཚོའི་ནོར་འཁྲུལ་གྱི་དབྱེ་ཞིབ་དཔྱད་ན་CAM་དང་མིག་གཟུགས་རིས་ལ། མ་དབྱིབས་ཀྱི་ལས་སྟངས་པར་མཐོང'}
