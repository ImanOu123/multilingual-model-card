{'en': 'It’s our fault ! : Insights Into Users’ Understanding and Interaction With an Explanatory Collaborative Dialog System', 'ar': '"هذا خطأنا!": رؤى حول فهم المستخدمين وتفاعلهم مع نظام حوار توضيحي تعاوني', 'es': '«¡Es culpa nuestra!» : Información sobre la comprensión y la interacción de los usuarios con un sistema de diálogo colaborativo explicativo', 'fr': "«\xa0C'est de notre faute\xa0!\xa0» : Aperçu de la compréhension et de l'interaction des utilisateurs avec un système de dialogue collaboratif explicatif", 'ja': '「私たちのせいよ！ ”：説明的なコラボレーションダイアログシステムを使用したユーザーの理解と相互作用への洞察', 'pt': '“A culpa é nossa!”: Insights sobre o entendimento e a interação dos usuários com um sistema de diálogo colaborativo explicativo', 'zh': '"此吾过也!":察用户解释性之解交也', 'hi': '"यह हमारी गलती है!": एक व्याख्यात्मक सहयोगी संवाद प्रणाली के साथ उपयोगकर्ताओं की समझ और बातचीत में अंतर्दृष्टि', 'ru': '«Это наша вина!«: Изучение понимания и взаимодействия пользователей с пояснительной системой совместного диалога', 'ga': '“Is orainne atá an locht!”: Léargas ar Thuiscint agus ar Idirghníomhaíocht na nÚsáideoirí le Córas Dialóige Comhoibríoch Míniúcháin', 'hu': '"A mi hibánk!" Betekintés a felhasználók megértésébe és interakciójába egy magyarázatos együttműködési párbeszédrendszerrel', 'el': '"Εμείς φταίμε!" Γνώσεις στην κατανόηση και αλληλεπίδραση των χρηστών με ένα επεξηγηματικό σύστημα συνεργατικού διαλόγου', 'kk': '"Бұл біздің қате!" Пайдаланушылардың түсініктемесін және интерфейсін түсініктемесін түсініктемесін жасау', 'ka': "'ეს ჩვენი შეცდომა!' Name", 'it': "'E' colpa nostra!': Approfondimenti sulla comprensione e l'interazione degli utenti con un sistema di dialogo collaborativo esplicativo", 'ml': 'അത് നമ്മുടെ തെറ്റാണ്! ഉപയോക്താക്കളുടെ മനസ്സിലാക്കുന്ന വിവരങ്ങളിലേക്കും ഇന്റര്\u200dക്ഷനിലേക്കും ഉപയോക്താക്കള്\u200dക്ക് ഉപയോക്താവ', 'lt': "'It's our fault!':  Naudotojų supratimo ir sąveikos su aiškinamąja bendradarbiavimo dialogo sistema apžvalgos", 'mt': '"Huwa ħsara tagħna!": Insight Into User\'s Understanding and Interaction With an Explanatory Collaborative Dialogue System', 'mn': '"Энэ бол бидний буруу!" Хэрэглэгчдийн ойлголтын, харилцааны тухай ойлголтын тухай бодол', 'ms': "'It's our fault!':  Penglihatan ke dalam Pemahaman Pengguna dan Interaksi Dengan Sistem Dialog Kolaboratif Penjelasan", 'no': '"Det er vårt feil!" Innstillingar i brukarane for forståking og interaksjon med eit forklaringssamarbeidsdialogsystem', 'pl': "'To nasza wina!': Wgląd w zrozumienie i interakcję użytkowników z wyjaśniającym systemem dialogowym współpracy", 'mk': '"Тоа е наша вина!" Внимание во разбирање и интеракција на корисниците со систем за објаснување на колаборативниот дијалог', 'ro': '"E vina noastră!" Informații despre înțelegerea și interacțiunea utilizatorilor cu un sistem de dialog colaborativ explicativ', 'sv': '"Det är vårt fel!" Insikter om användarnas förståelse och interaktion med ett förklarande samarbetsdialogsystem', 'ta': "'அது எங்கள் தவறு!': Name", 'ur': "'یہ ہماری خطا ہے!' استعمال کے سمجھنے اور اضافہ کے اندر ایک واضح مشترک دایالوگریٹ سیسٹم کے ساتھ", 'so': "waa dembigayaga!: Insights Into Users' Understanding and Interaction With an Explanatory Collaborative Dialog System", 'si': "'ඒක අපේ වැරදිය!' ප්\u200dරශ්නයක් සම්බන්ධ සංවාදය පද්ධතියෙන් ප්\u200dරයෝජකයේ තේරුම් සහ සම්බන්ධතාව", 'sr': 'To je naša greška! Inzistiranja u razumijevanje i interakciju korisnika sa objašnjavajućim sistemom saradnje dijaloga', 'uz': 'Bu bizning xatosimiz! Name', 'vi': '"Lỗi của chúng ta!" Chiếu sáng vào sự hiểu biết và tương tác của người dùng Với hệ điều giải thích.', 'nl': "'Het is onze schuld!': Inzicht in het begrip en de interactie van gebruikers met een toelichtend collaboratief dialoogsysteem", 'bg': '"Вината е наша!" Прозрения за разбирането и взаимодействието на потребителите с обяснителна система за диалог за сътрудничество', 'da': '"Det er vores skyld!" Indsigt i brugernes forståelse og interaktion med et forklarende samarbejdsdialogsystem', 'de': "'Es ist unsere Schuld!': Einblicke in das Verständnis und die Interaktion von Nutzern mit einem erklärenden kollaborativen Dialogsystem", 'id': "'Ini kesalahan kita!': Penglihatan ke dalam Pemahaman Pengguna dan Interaksi Dengan Sistem Dialog Kolaboratif Penjelasan", 'ko': '"이건 우리 잘못이야!":해석적 협력 대화 시스템에 대한 사용자의 이해와 상호작용을 깊이 이해하다', 'fa': 'تقصير ماست! توجه به درک و تعامل کاربران با سیستم گفتگوی مشترک توضیح', 'af': '"Dit is ons fout!" Inligting binne gebruikers se verstaan en interaksie met \'n Explanatory Collaborative Dialog System', 'sw': "'Ni makosa yetu!': Picha kwa watumiaji wa Kuelewa na Kuhusiana na Mfumo wa Kishirikiano", 'hr': 'To je naša krivica! Inzistiranja u razumijevanje i interakciju korisnika s objašnjavajućim sustavom saradnje dijaloga', 'am': '"ኀጢአታችን ነው!": Notes and Interaction with an Explanatory Collaborative Dialog System', 'tr': '"Bu biziň ýalňyşymyz!" Ullançylaryň düşünmesi we Interaktiýany Explanatory Collaborative Dialog System bilen Taýýarlanýan', 'bn': "'এটা আমাদের দোষ! Name", 'az': '"Bu bizim günahımızdır!" İstifadəçilərin anlaşılması və İşləşməsi ilə İşləndiriləndir', 'bs': 'To je naša krivica! Inzistiranja u razumijevanje i interakciju korisnika sa objašnjavajućim sistemom saradnje dijaloga', 'cs': "'Je to naše vina!': Přehled o porozumění uživatelům a interakci s vysvětlujícím systémem spolupráce", 'et': '"See on meie süü!" Ülevaated kasutajate mõistmisest ja suhtlemisest selgitava koostöödialoogi süsteemiga', 'fi': '"Se on meid채n vikamme!" Tietoa k채ytt채jien ymm채rt채misest채 ja vuorovaikutuksesta selitt채v채n yhteisty철dialogij채rjestelm채n avulla', 'sq': '"Është faji ynë!": Insight në kuptimin dhe ndërveprimin e përdoruesve me një sistem shpjegues dialogu', 'hy': '"Մեր մեղքն է": Insights Into Users\' Understanding and Interaction With an Explanatory Collaborative Dialog System', 'ca': '"És culpa nostra!" Insights Into Users\' Understanding and Interaction With an Explanatory Collaborative Dialog System', 'he': '"זו אשמתנו!" התבוננות לתוך הבנה והקשר של המשתמשים עם מערכת שיחות שיתוף פעולה מסבירה', 'sk': '"To je naša krivda!" Vpogledi v razumevanje in interakcijo uporabnikov s sistemom pojasnjevalnega dialoga za sodelovanje', 'jv': "'Iki ki salaké !' Intsungane Ing usur' Sampèrasno lan interaction Gambar an ExpAnator collabonation Dialog System", 'bo': "འདི་ང་ཚོའི་སྐྱོན་རེད། Insights Into Users' Understanding and Interaction With an Explanatory Collaborative Dialog System", 'ha': 'Ka ce: "Yã kaitõnmu! @ action'}
{'en': 'Human-AI collaboration, a long standing goal in  AI , refers to a partnership where a human and artificial intelligence work together towards a shared goal. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners. To design collaborative dialog systems, it is important to understand what mental models users form about their AI-dialog partners, however, how users perceive these  systems  is not fully understood. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system. We created a public corpus from 117 conversations and post-surveys and used this to analyze what  mental models  users formed. Key takeaways include : Even when users were not engaged in the  game , they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner separate from the game. This was further supported by users often overestimating the  system ’s abilities and projecting human-like attributes which led to miscommunications. We conclude that creating shared mental models between users and  AI systems  is important to achieving successful dialogs. We propose that our insights on mental models and miscommunication, the  game , and our  corpus  provide useful tools for designing collaborative dialog systems.', 'fr': "La collaboration homme-IA, un objectif de longue date de l'IA, fait référence à un partenariat dans lequel l'intelligence humaine et l'intelligence artificielle travaillent ensemble vers un objectif commun. Le dialogue collaboratif permet aux équipes d'IA humaine de communiquer et de tirer parti des forces des deux partenaires. Pour concevoir des systèmes de dialogue collaboratifs, il est important de comprendre quels modèles mentaux les utilisateurs forment à propos de leurs partenaires AI-Dialog, mais la façon dont les utilisateurs perçoivent ces systèmes n'est pas entièrement comprise. Dans cette étude, nous avons conçu un nouveau jeu de puzzle collaboratif basé sur la communication et un système de dialogue explicatif. Nous avons créé un corpus public à partir de 117 conversations et post-sondages et nous l'avons utilisé pour analyser les modèles mentaux formés par les utilisateurs. Les principaux points à retenir sont les suivants\xa0: Même lorsque les utilisateurs n'étaient pas impliqués dans le jeu, ils percevaient le partenaire AI-Dialog comme intelligent et sympathique, ce qui implique qu'ils le voyaient comme un partenaire distinct du jeu. Cela a été renforcé par le fait que les utilisateurs surestimaient souvent les capacités du système et projetaient des attributs similaires à ceux de l'homme, ce qui entraînait des Nous concluons que la création de modèles mentaux partagés entre les utilisateurs et les systèmes d'IA est importante pour réussir les dialogues. Nous proposons que nos connaissances sur les modèles mentaux et les problèmes de communication, le jeu et notre corpus fournissent des outils utiles pour concevoir des systèmes de dialogue collaboratifs.", 'pt': 'A colaboração entre humanos e IA, um objetivo de longa data em IA, refere-se a uma parceria em que uma inteligência humana e artificial trabalham juntas para um objetivo compartilhado. O diálogo colaborativo permite que as equipes de IA humana se comuniquem e aproveitem os pontos fortes de ambos os parceiros. Para projetar sistemas de diálogo colaborativo, é importante entender quais modelos mentais os usuários formam sobre seus parceiros de diálogo de IA, no entanto, como os usuários percebem esses sistemas não é totalmente compreendido. Neste estudo, projetamos um jogo de quebra-cabeça inovador, colaborativo e baseado em comunicação e um sistema de diálogo explicativo. Criamos um corpus público a partir de 117 conversas e pós-pesquisas e usamos isso para analisar quais modelos mentais os usuários formaram. As principais conclusões incluem: Mesmo quando os usuários não estavam envolvidos no jogo, eles perceberam o parceiro de diálogo de IA como inteligente e agradável, o que implica que o viam como um parceiro separado do jogo. Isso foi ainda mais apoiado pelos usuários, muitas vezes superestimando as habilidades do sistema e projetando atributos semelhantes aos humanos, o que levou a falhas de comunicação. Concluímos que a criação de modelos mentais compartilhados entre usuários e sistemas de IA é importante para alcançar diálogos bem-sucedidos. Propomos que nossos insights sobre modelos mentais e falta de comunicação, o jogo e nosso corpus forneçam ferramentas úteis para projetar sistemas de diálogo colaborativo.', 'ja': 'AIにおける長年の目標である人間とAIのコラボレーションは、人間と人工知能が共通の目標に向けて協力するパートナーシップを指します。 コラボレーションダイアログを使用すると、人間のAIチームが両方のパートナーからの強みを伝え、活用することができます。 共同対話システムを設計するには、ユーザーがAI対話パートナーについてどのようなメンタルモデルを形成しているかを理解することが重要ですが、ユーザーがこれらのシステムをどのように認識しているかは完全には理解されていません。 この研究では、斬新で協働的なコミュニケーションベースのパズルゲームと説明的なダイアログシステムを設計しました。 117の会話とポストサーベイからパブリックコーパスを作成し、これを使用してユーザーが形成したメンタルモデルを分析しました。 主なポイントとしては、ユーザーがゲームに関与していなかった場合でも、AIダイアログパートナーは知的で好感が持てると認識していたことが挙げられ、ゲームとは別のパートナーと見なされていたことが示唆されている。 これは、システムの能力を過大評価し、人間のような属性を投影することが多く、誤ったコミュニケーションにつながったユーザーによってさらに支持されました。 ユーザーとAIシステムの間で共有されたメンタルモデルを作成することは、ダイアログを成功させるために重要であると結論付けます。 私たちは、メンタルモデルと誤ったコミュニケーション、ゲーム、コーパスに関する洞察が、共同対話システムを設計するための有用なツールを提供することを提案します。', 'ar': 'يشير التعاون بين الإنسان والذكاء الاصطناعي ، وهو هدف طويل الأمد في مجال الذكاء الاصطناعي ، إلى شراكة حيث يعمل الذكاء الاصطناعي والبشر معًا لتحقيق هدف مشترك. يتيح الحوار التعاوني لفرق الذكاء الاصطناعي البشرية التواصل والاستفادة من نقاط القوة من كلا الشريكين. لتصميم أنظمة حوار تعاونية ، من المهم فهم النماذج العقلية التي يشكلها المستخدمون عن شركائهم في حوار الذكاء الاصطناعي ، ومع ذلك ، فإن كيفية إدراك المستخدمين لهذه الأنظمة ليست مفهومة تمامًا. في هذه الدراسة ، صممنا لعبة ألغاز جديدة وتعاونية قائمة على التواصل ونظام حوار توضيحي. أنشأنا مجموعة عامة من 117 محادثة واستطلاعات لاحقة واستخدمناها لتحليل النماذج العقلية التي شكلها المستخدمون. تشمل النقاط الرئيسية: حتى عندما لا يشارك المستخدمون في اللعبة ، فإنهم يرون أن شريك حوار الذكاء الاصطناعي ذكي ومحبوب ، مما يعني أنهم رأوه كشريك منفصل عن اللعبة. كان هذا مدعومًا بشكل أكبر من قبل المستخدمين الذين غالبًا ما يبالغون في تقدير قدرات النظام ويظهرون سمات شبيهة بالإنسان مما أدى إلى سوء الاتصال. نستنتج أن إنشاء نماذج ذهنية مشتركة بين المستخدمين وأنظمة الذكاء الاصطناعي أمر مهم لتحقيق حوارات ناجحة. نقترح أن توفر رؤيتنا حول النماذج العقلية وسوء الفهم واللعبة ومجموعتنا أدوات مفيدة لتصميم أنظمة الحوار التعاوني.', 'es': 'La colaboración entre humanos e IA, un objetivo de larga data en la IA, se refiere a una asociación en la que la inteligencia humana y la artificial trabajan juntas para lograr un objetivo compartido. El diálogo colaborativo permite que los equipos de IA humana se comuniquen y aprovechen las fortalezas de ambos socios. Para diseñar sistemas de diálogo colaborativo, es importante entender qué modelos mentales forman los usuarios sobre sus socios de diálogo de IA, sin embargo, no se comprende completamente cómo los usuarios perciben estos sistemas. En este estudio, diseñamos un juego de rompecabezas novedoso, colaborativo y basado en la comunicación y un sistema de diálogo explicativo. Creamos un corpus público a partir de 117 conversaciones y encuestas posteriores y lo utilizamos para analizar qué modelos mentales formaron los usuarios. Los puntos clave incluyen: Incluso cuando los usuarios no participaban en el juego, percibían al socio de diálogo de IA como inteligente y simpático, lo que implica que lo veían como un socio separado del juego. Esto fue respaldado por los usuarios que a menudo sobreestiman las habilidades del sistema y proyectaron atributos similares a los humanos que llevaron a la falta de comunicación. Concluimos que la creación de modelos mentales compartidos entre los usuarios y los sistemas de IA es importante para lograr diálogos exitosos. Proponemos que nuestras ideas sobre los modelos mentales y la falta de comunicación, el juego y nuestro corpus proporcionen herramientas útiles para diseñar sistemas de diálogo colaborativo.', 'hi': 'मानव-एआई सहयोग, एआई में एक लंबे समय से स्थायी लक्ष्य, एक साझेदारी को संदर्भित करता है जहां एक मानव और कृत्रिम बुद्धिमत्ता एक साझा लक्ष्य की दिशा में एक साथ काम करती है। सहयोगी संवाद मानव-एआई टीमों को दोनों भागीदारों से ताकत का संचार करने और लाभ उठाने की अनुमति देता है। सहयोगी संवाद प्रणालियों को डिजाइन करने के लिए, यह समझना महत्वपूर्ण है कि उपयोगकर्ता अपने एआई-संवाद भागीदारों के बारे में क्या मानसिक मॉडल बनाते हैं, हालांकि, उपयोगकर्ता इन प्रणालियों को कैसे समझते हैं, यह पूरी तरह से समझा नहीं गया है। इस अध्ययन में, हमने एक उपन्यास, सहयोगी, संचार-आधारित पहेली खेल और व्याख्यात्मक संवाद प्रणाली तैयार की है। हमने 117 वार्तालापों और पोस्ट-सर्वेक्षणों से एक सार्वजनिक कॉर्पस बनाया और इसका उपयोग यह विश्लेषण करने के लिए किया कि उपयोगकर्ताओं ने किन मानसिक मॉडलों का गठन किया है। प्रमुख takeaways में शामिल हैं: यहां तक कि जब उपयोगकर्ता खेल में लगे नहीं थे, तब भी उन्होंने एआई-संवाद साथी को बुद्धिमान और पसंद करने योग्य माना, जिसका अर्थ है कि उन्होंने इसे खेल से अलग साथी के रूप में देखा। यह उपयोगकर्ताओं द्वारा अक्सर सिस्टम की क्षमताओं को अतिरंजित करने और मानव जैसी विशेषताओं को पेश करने के लिए समर्थित था, जिसके कारण गलतफहमी हुई। हम निष्कर्ष निकालते हैं कि उपयोगकर्ताओं और एआई सिस्टम के बीच साझा मानसिक मॉडल बनाना सफल संवाद प्राप्त करने के लिए महत्वपूर्ण है। हम प्रस्ताव करते हैं कि मानसिक मॉडल और गलतफहमी, खेल और हमारे कॉर्पस पर हमारी अंतर्दृष्टि सहयोगी संवाद प्रणालियों को डिजाइन करने के लिए उपयोगी उपकरण प्रदान करती है।', 'zh': '人与人工智能合者,人工智能之长也;谓人与人工智能同努力实现之伙伴关系也。 协言通人工智能团队,因其势也。 设意协统,要在知用户AI对成之心,然用户视之未尽也。 于此论之,设一新颖,协作者,盖通益智戏说之统也。 吾于117言勘创一公共语料库,以析用户成之心。 其要略曰:虽用户不与戏,亦以为AI对侣为聪明可爱,此其所以为异戏者也。 用户常高估统而射类人之属,以通不通,是助之也。 吾侪之论,用户人工智能之统,共享之心,其于成功为重。 吾言智通于不畅、游戏、语料库之见,设为设为有用之具。', 'ru': 'Сотрудничество между человеком и ИИ, давняя цель в искусственном интеллекте, относится к партнерству, в котором человек и искусственный интеллект работают вместе над достижением общей цели. Совместный диалог позволяет командам по искусственному интеллекту общаться и использовать сильные стороны обоих партнеров. Для разработки совместных диалоговых систем важно понимать, какие ментальные модели формируют пользователи о своих партнерах по ИИ-диалогу, однако, как пользователи воспринимают эти системы, полностью не понято. В этом исследовании мы разработали новую, совместную, основанную на общении игру-головоломку и пояснительную диалоговую систему. Мы создали публичный корпус из 117 бесед и пост-опросов и использовали его для анализа того, какие ментальные модели сформировали пользователи. Ключевые выводы включают: Даже когда пользователи не были вовлечены в игру, они воспринимали партнера по ИИ-диалогу как умного и приятного, подразумевая, что они рассматривали его как партнера отдельно от игры. Это было дополнительно поддержано пользователями, которые часто переоценивали возможности системы и прогнозировали человекоподобные атрибуты, которые приводили к неправильной коммуникации. Мы делаем вывод, что создание общих ментальных моделей между пользователями и системами ИИ важно для достижения успешных диалогов. Мы предлагаем, чтобы наши представления о ментальных моделях и неправильном общении, игре и нашем корпусе предоставляли полезные инструменты для разработки систем совместного диалога.', 'ga': 'Tagraíonn comhar daonna-AI, sprioc atá ann le fada an lá in AI, do chomhpháirtíocht ina n-oibríonn intleacht dhaonna agus shaorga le chéile i dtreo sprioc chomhroinnte. Ligeann dialóg chomhoibríoch d’fhoirne daonna-AI láidreachtaí an dá chomhpháirtí a chur in iúl agus a ghiaráil. Chun córais dialóige comhoibríocha a dhearadh, tá sé tábhachtach a thuiscint cad a fhoirmíonn úsáideoirí samhlacha meabhrach faoina gcomhpháirtithe AI-dialóg, áfach, ní thuigtear go hiomlán conas a bhraitheann úsáideoirí na córais seo. Sa staidéar seo, dhearamar cluiche puzail úrscéal, comhoibríoch, bunaithe ar chumarsáid agus córas dialóige míniúcháin. Chruthaíomar corpas poiblí as 117 comhrá agus iar-shuirbhé agus úsáideamar é seo chun anailís a dhéanamh ar na múnlaí meabhracha a chruthaigh úsáideoirí. Áirítear ar na príomhbhealaí beir leat: Fiú nuair nach raibh úsáideoirí gafa leis an gcluiche, bhraith siad go raibh an comhpháirtí AI-dialóg cliste agus taitneamhach, ag tabhairt le tuiscint go bhfaca siad é mar chomhpháirtí ar leithligh ón gcluiche. Tugadh tacaíocht bhreise dó seo nuair a bhí rómheastachán á dhéanamh ag úsáideoirí go minic ar chumais an chórais agus ag teilgean ar shaintréithe cosúil le daonnacht as a dtáinig míchumarsáid. Tugaimid i gcrích go bhfuil sé tábhachtach samhlacha meabhracha roinnte a chruthú idir úsáideoirí agus córais AI chun dialóga rathúla a bhaint amach. Molaimid go soláthróidh ár léargais ar mhúnlaí meabhracha agus ar mhíchumarsáid, ar an gcluiche agus ar ár gcorpas uirlisí úsáideacha chun córais dialóige comhoibríocha a dhearadh.', 'el': 'Η συνεργασία ανθρώπου-τεχνητής νοημοσύνης, ένας μακροχρόνιος στόχος στην τεχνητή νοημοσύνη, αναφέρεται σε μια συνεργασία όπου ένας άνθρωπος και η τεχνητή νοημοσύνη συνεργάζονται προς έναν κοινό στόχο. Ο συνεργατικός διάλογος επιτρέπει στις ομάδες ανθρώπου-τεχνητής νοημοσύνης να επικοινωνούν και να αξιοποιούν τις δυνάμεις και των δύο εταίρων. Για τον σχεδιασμό συνεργατικών συστημάτων διαλόγου, είναι σημαντικό να κατανοήσουμε τι διανοητικά μοντέλα διαμορφώνουν οι χρήστες για τους εταίρους διαλόγου τους, ωστόσο, το πώς αντιλαμβάνονται οι χρήστες αυτά τα συστήματα δεν είναι πλήρως κατανοητό. Σε αυτή τη μελέτη σχεδιάσαμε ένα νέο, συνεργατικό, επικοινωνιακό παιχνίδι παζλ και σύστημα επεξηγηματικού διαλόγου. Δημιουργήσαμε ένα δημόσιο σώμα από 117 συνομιλίες και μετα-έρευνες και το χρησιμοποιήσαμε για να αναλύσουμε ποια νοητικά μοντέλα σχημάτισαν οι χρήστες. Τα βασικά συμπεράσματα περιλαμβάνουν: Ακόμα και όταν οι χρήστες δεν ασχολούνταν με το παιχνίδι, θεώρησαν τον συνεργάτη διαλόγου τεχνητής νοημοσύνης ως έξυπνο και συμπαθητικό, υποδηλώνοντας ότι τον έβλεπαν ως εταίρο χωριστό από το παιχνίδι. Αυτό υποστηρίχθηκε περαιτέρω από τους χρήστες που συχνά υπερεκτιμούν τις ικανότητες του συστήματος και προβάλλουν ανθρώπινα χαρακτηριστικά που οδήγησαν σε παρεξηγήσεις. Συμπεραίνουμε ότι η δημιουργία κοινών νοητικών μοντέλων μεταξύ χρηστών και συστημάτων τεχνητής νοημοσύνης είναι σημαντική για την επίτευξη επιτυχημένων διαλόγων. Προτείνουμε οι γνώσεις μας σχετικά με τα νοητικά μοντέλα και την παρεξήγηση επικοινωνίας, το παιχνίδι και το σώμα μας να παρέχουν χρήσιμα εργαλεία για τον σχεδιασμό συνεργατικών συστημάτων διαλόγου.', 'ka': 'ადამიანის-ინტელექტიური სამუშაო, დიდი სამუშაო მიზეზია, რომელიც ადამიანის და კულტური ინტელექტიური ინტელექტიური ერთად მუშაობაში ერთად მუშაობაში გა კალბაბორატიური დიალოგში ადამიანის-AI კომუნიკაცია და გამოყენება ორივე პონტერნეტების ძალადობა. სისტემების შესახებ, როგორც გამოყენებელი ამ სისტემების შესახებ არსებობს, გასანიშვნელოვანია გავიგოთ როგორ მენტალური მოდელები გამოყენებელი AI-დიალოგის პონტერნო ამ კვლევაში, ჩვენ პრომენტის, კომუნიკაციური, კომუნიკაციური დაბათი სტაზლის თამაში და განახლებელი დიალოგის სისტემაში დავყენეთ. ჩვენ 117 განსაზღვრებისგან და შემდეგ განსაზღვრებისგან დავიყენეთ საზოგადო კორპუსს და ამას გამოყენეთ, რომ ანალიზაცით რას ფექციური მოდელური მომხმა გასაღების გასაღების შესახებ: თუმცა მომხმარებელი თამაში არ დაკავშირებულია, ისინი AI-ეთალოგის პონტერნო იყოს ინტელექტიური და შესაძლებელი, როგორც იყო, რომ მათ იყო პონტერნ ეს უფრო მეტი იყო მომხმარებელი, რომელიც სისტემის შესაძლებლობა და პროექტირება ადამიანის განსაკუთრებული ატრიბუტები, რომელიც შეცდომის კომუნიკაციას ჩვენ გავაკეთებთ, რომ მომხმარებელი და AI სისტემების შორის გარეშე მნიშვნელოვანია წარმატებული დიალოგების გარეშე. ჩვენ გვეძლევა, რომ ჩვენი მონაცემები ფექციალური მოდელების და შეცდომის კომუნიკაციის შესახებ, თამაში და ჩვენი კომპუსს გამოიყენება საჭირო ხელსაწყობინებები', 'hu': 'Az ember-AI együttműködés, amely a mesterséges intelligencia régóta fennálló célja, olyan partnerségre utal, amelyben az ember és a mesterséges intelligencia együttműködik egy közös cél érdekében. Az együttműködési párbeszéd lehetővé teszi az emberi-AI csapatok számára, hogy kommunikáljanak és kihasználják mindkét partner erősségét. Az együttműködő párbeszédrendszerek kialakításához fontos megérteni, hogy a felhasználók milyen mentális modelleket alkotnak AI-párbeszédpartnereikről, azonban nem teljesen érthető, hogy a felhasználók hogyan érzékelik ezeket a rendszereket. Ebben a tanulmányban egy új, együttműködő, kommunikációs alapú kirakós játékot és magyarázó párbeszédrendszert terveztünk. 117 beszélgetésből és utólagos felmérésből állítottunk össze egy nyilvános korpuszt, amelyet arra használtunk, hogy elemezzük, milyen mentális modelleket alakítottak ki a felhasználók. A legfontosabb feladatok közé tartozik: Még akkor is, amikor a felhasználók nem vettek részt a játékban, az AI-párbeszéd partnerét intelligens és szerethetőnek érezték, ami azt jelenti, hogy a játéktól elkülönülő partnernek tekintik. Ezt továbbá támogatták a felhasználók, akik gyakran túlbecsülték a rendszer képességeit és emberi jellemzőket vetítettek ki, ami félreértésekhez vezetett. Arra a következtetésre jutunk, hogy a sikeres párbeszédek eléréséhez fontos a felhasználók és az AI rendszerek közötti közös mentális modellek kialakítása. Javasoljuk, hogy a mentális modellekre és kommunikációs hibákra, a játékra és a korpuszunkra vonatkozó betekintéseink hasznos eszközöket nyújtsanak az együttműködő párbeszédrendszerek kialakításához.', 'it': "La collaborazione uomo-AI, un obiettivo di lunga data nell'IA, si riferisce a una partnership in cui un'intelligenza umana e artificiale lavorano insieme verso un obiettivo condiviso. Il dialogo collaborativo consente ai team umani-AI di comunicare e sfruttare i punti di forza di entrambi i partner. Per progettare sistemi di dialogo collaborativi, è importante capire quali modelli mentali gli utenti formano sui loro partner di dialogo AI, tuttavia, come gli utenti percepiscono questi sistemi non è pienamente compreso. In questo studio, abbiamo progettato un nuovo puzzle game collaborativo basato sulla comunicazione e un sistema di dialogo esplicativo. Abbiamo creato un corpus pubblico da 117 conversazioni e post-sondaggi e utilizzato questo per analizzare quali modelli mentali gli utenti hanno formato. Anche quando gli utenti non erano coinvolti nel gioco, percepivano il partner di dialogo AI come intelligente e simpatico, il che significa che lo vedevano come un partner separato dal gioco. Questo è stato ulteriormente supportato dagli utenti spesso sopravvalutando le capacità del sistema e proiettando attributi simili a quelli umani che hanno portato a errori di comunicazione. Concludiamo che creare modelli mentali condivisi tra utenti e sistemi AI è importante per ottenere dialoghi di successo. Proponiamo che le nostre intuizioni sui modelli mentali e sull'errata comunicazione, il gioco e il nostro corpus forniscano strumenti utili per progettare sistemi di dialogo collaborativi.", 'mk': 'Human-AI collaboration, a long standing goal in AI, refers to a partnership where a human and artificial intelligence work together towards a shared goal.  Колаборативниот дијалог им овозможува на тимовите на човек-AI да комуницираат и да ги искористат силите од двата партнери. За да се дизајнираат системите на дијалог за соработка, важно е да се разбере кои ментални модели формираат корисниците за нивните партнери на дијалог за AI, сепак, како корисниците ги перцепираат овие системи не се целосно разбираат. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system.  We created a public corpus from 117 conversations and post-surveys and used this to analyze what mental models users formed.  Клучните преземања вклучуваат: Дури и кога корисниците не беа вклучени во играта, тие го сметаа партнерот на дијалогот за интелигентен и привлечен, имплицирајќи дека го виделе како партнер одделен од играта. Ова беше поддржано понатаму од корисниците кои честопати ги преценуваат способностите на системот и проектираат човечки атрибути кои доведоа до погрешни комуникации. Завршуваме дека создавањето на заеднички ментални модели помеѓу корисниците и системите на ИИ е важно за постигнување успешни дијалози. Предлагаме нашите информации за менталните модели и лошата комуникација, играта и нашиот корпус да обезбедат корисни алатки за дизајнирање на системи за соработка.', 'kk': 'Адам-АР жұмыс істеу, AI-де ұзын мақсатты, адам және әртүрлі интеллектер бірге ортақ мақсатта жұмыс істейді. Жалғастыру диалогы адамдар- AI топтарының екі жалғастырушылардың күштерін қатынау және күштерін өзгертуге мүмкіндік береді. Бірлескен диалог жүйелерін құрастыру үшін психикалық үлгілер пайдаланушылардың AI диалог партнері туралы не құрылып жатқанын түсіну маңызды, бірақ пайдаланушылардың осы жүйелерді қа Бұл зерттеулерде, біз романды, жұмыс істейтін, коммуникациялық бақылау ойынын және түсініктеме диалог жүйесін жасадық. Біз 117 сұрақтардан және соңғы сұрақтардан ашық корпус құрып, психикалық моделдердің пайдаланушыларының құрылғанын анализ үшін қолдандық. Кілттерді алу кезінде: пайдаланушылар ойында қатысуға болмаса да, AI диалогтың қатысушысы бақытты және ұқсас болуы мүмкін деп ойлады, олар оны ойындан бөлек деп ойлады. Бұл пайдаланушылар көбінесе жүйеңіздің мүмкіндіктерін және адамдардың ұқсас атрибуттарын жоспарлауға көбірек қолданылады. Біз пайдаланушылар мен AI жүйелердің ортақ психикалық моделдерін құру үшін сәтті диалогтарды жеткізу үшін маңызды. Біз психикалық үлгілерімізді, оқиға және корпусомыздың көмектесу диалог жүйелерін құру үшін пайдалы құрылғыларын қолдануға ұсынамыз.', 'lt': 'Žmogaus ir AI bendradarbiavimas, ilgalaikis AI tikslas, reiškia partnerystę, kurioje žmogaus ir dirbtinė žvalgyba dirba kartu siekiant bendro tikslo. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners.  Siekiant sukurti bendradarbiavimo dialogo sistemas, svarbu suprasti, kokių protinių modelių vartotojai formuoja apie savo AI dialogo partnerius, tačiau kaip vartotojai suvokia šias sistemas nėra visiškai suprantami. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system.  We created a public corpus from 117 conversations and post-surveys and used this to analyze what mental models users formed.  Pagrindinės priemonės apima: Net kai naudotojai nebuvo įtraukti į žaidimą, jie suprato AI dialogo partner į kaip protingą ir panašų, o tai reiškia, kad jis buvo laikomas partneriu, atskiru nuo žaidimo. Be to, naudotojai dažnai per daug įvertino sistemos gebėjimus ir prognozavo žmogiškuosius požymius, dėl kurių atsirado neteisingų ryšių. We conclude that creating shared mental models between users and AI systems is important to achieving successful dialogs.  We propose that our insights on mental models and miscommunication, the game, and our corpus provide useful tools for designing collaborative dialog systems.', 'ml': 'ഒരു നീണ്ട നിലനില്\u200dക്കുന്ന ലക്ഷ്യം മനുഷ്യരുടെയും കൃത്രിമ വിവേകതകളുടെയും സഹകരിക്കുന്ന ഒരു പങ്കാളിയെക്കുറിച്ച് പറയുന്നു. സഹകരിക്കുന്ന ഡയലോഗ് രണ്ടു പങ്കാളികളില്\u200d നിന്നും മനുഷ്യന്\u200d -AI ടീമുകളെ ബന്ധപ്പെടുത്തുന്ന ശക്തികളും ഉപയോഗി സഹകരിക്കുന്ന ഡയലോഗ് സിസ്റ്റം ഡിസൈന്\u200d ചെയ്യാന്\u200d, അവരുടെ AI-ഡയലോഗ് പങ്കാളികളെക്കുറിച്ച് മാനസിക മോഡല്\u200d ഉപയോക്താക്കള്\u200d എന്താണ് രൂ ഈ പഠനത്തില്\u200d ഞങ്ങള്\u200d ഒരു നോവല്\u200d, സഹകരിക്കുന്നു, കമ്മിക്കോണിങ്ങ് അടിസ്ഥാനമാക്കിയ പുസ്സില്\u200d കളിയും വിശദീകരിക്കുന്ന 117 സംഭാഷണങ്ങളില്\u200d നിന്നും പിന്നീട് പരിശോധനങ്ങളില്\u200d നിന്നും ഞങ്ങള്\u200d ഒരു പൊതു കോര്\u200dപ്പസ് ഉണ്ടാക്കിയിട്ടുണ്ട്. മനോഹരമായ കീ എടുക്കുന്നതില്\u200d ചേര്\u200dന്നുണ്ട്: ഉപയോക്താക്കള്\u200d കളിയില്\u200d പ്രവര്\u200dത്തിക്കാതിരുന്നിട്ടും പോലും അവര്\u200d AI-ഡയലോഗ് പങ്കാളിയെ ബുദ്ധിമാനും  സിസ്റ്റത്തിന്റെ കഴിവും മനുഷ്യന്റെ പോലുള്ള വ്യവസ്ഥകളും പ്രോജക്ട് ചെയ്യുന്നതിനാല്\u200d ഉപയോക്താക്കള്\u200d ഇതിനെ പിന്തുണയ ഉപയോക്താക്കള്\u200dക്കും AI സിസ്റ്റത്തിനും തമ്മില്\u200d പങ്കുള്ള മാനസിക മോഡലുകള്\u200d ഉണ്ടാക്കുന്നത് വിജയിച്ചുകൊണ്ട നമ്മുടെ മാനസിക മോഡലുകളും തെറ്റായ വിവരങ്ങളും കളിയും കോര്\u200dപ്പുസിനും നമ്മുടെ കണ്ണുകള്\u200d സഹകരിക്കുന്ന ഡയലോഗ് സിസ്റ്റത്തിന് ഉപകരണങ്', 'mt': 'Il-kollaborazzjoni bejn il-bniedem u l-AI, għan fit-tul fl-AI, tirreferi għal sħubija fejn intelliġenza umana u artifiċjali taħdem flimkien lejn għan komuni. Id-djalogu kollaborattiv jippermetti lit-timijiet tal-bniedem-AI jikkomunikaw u jisfruttaw il-qawwiet miż-żewġ imsieħba. Biex jitfasslu sistemi ta’ djalogu kollaborattiv, huwa importanti li wieħed jifhem liema mudelli mentali jiffurmaw l-utenti dwar l-imsieħba tagħhom tad-djalogu AI, madankollu, kif l-utenti jqisu dawn is-sistemi mhumiex mifhuma kompletament. F’dan l-istudju, iddisinjna logħob ta’ puzzle ġdid, kollaborattiv, ibbażat fuq il-komunikazzjoni u sistema ta’ djalogu ta’ spjegazzjoni. Ħolqien korpus pubbliku minn 117-il konverżjoni u stħarriġ ta’ wara u użajna dan biex tanalizza x’jiffurmaw l-utenti tal-mudelli mentali. It-teħid tal-ideat prinċipali jinkludi: Anke meta l-utenti ma kinux involuti fil-logħob, huma pperċevew lis-sieħeb tad-djalogu AI bħala intelliġenti u simili, li jimplika li raw dan bħala sieħeb separat mill-logħob. Dan kien appoġġjat ukoll mill-utenti li spiss kienu qed jevalwaw wisq l-abbiltajiet tas-sistema u pproġettaw attributi simili għall-bniedem li wasslu għal komunikazzjonijiet żbaljati. Nikkonkludu li l-ħolqien ta’ mudelli mentali kondiviżi bejn l-utenti u s-sistemi AI huwa importanti biex jinkisbu djalogi ta’ suċċess. We propose that our insights on mental models and miscommunication, the game, and our corpus provide useful tools for designing collaborative dialog systems.', 'ms': 'Kerjasama manusia-AI, tujuan yang lama dalam AI, merujuk kepada persatuan di mana intelijen manusia dan buatan bekerja bersama-sama untuk tujuan berkongsi. Dialog kerjasama membolehkan pasukan human-AI berkomunikasi dan menggunakan kekuatan dari kedua-dua rakan. Untuk merancang sistem dialog kerjasama, penting untuk memahami apa bentuk pengguna model mental mengenai rakan-rakan dialog AI mereka, bagaimanapun, bagaimana pengguna memahami sistem ini tidak sepenuhnya dipahami. Dalam kajian ini, kami merancang permainan teka-teki berbasis komunikasi dan sistem dialog penjelasan. Kami mencipta korpus awam dari 117 perbualan dan penyelidikan-penyelidikan dan menggunakan ini untuk menganalisis apa yang dibentuk pengguna model mental. Perambilan kunci termasuk: Walaupun pengguna tidak terlibat dalam permainan, mereka menganggap rakan-rakan dialog-AI sebagai cerdas dan boleh disayangi, bermakna mereka melihatnya sebagai rakan-rakan yang terpisah dari permainan. Ini disokong lebih lanjut oleh pengguna sering menghargai kemampuan sistem dan projek atribut seperti manusia yang menyebabkan kesalahkomunikasi. Kami menyimpulkan bahawa mencipta model mental berkongsi antara pengguna dan sistem AI adalah penting untuk mencapai dialog berjaya. Kami cadangkan bahawa pandangan kita tentang model mental dan kesalahkomunikasi, permainan, dan korpus kami menyediakan alat berguna untuk merancang sistem dialog kerjasama.', 'ro': 'Colaborarea umană-AI, un obiectiv de lungă durată în AI, se referă la un parteneriat în care inteligența umană și artificială lucrează împreună pentru un obiectiv comun. Dialogul colaborativ permite echipelor umane-AI să comunice și să valorifice punctele forte ale ambilor parteneri. Pentru a proiecta sisteme de dialog colaborativ, este important să înțelegem ce modele mentale formează utilizatorii despre partenerii lor de dialog AI, cu toate acestea, modul în care utilizatorii percep aceste sisteme nu este pe deplin înțeles. În acest studiu, am proiectat un nou joc de puzzle, colaborativ, bazat pe comunicare și sistem de dialog explicativ. Am creat un corpus public din 117 conversații și post-sondaje și am folosit acest lucru pentru a analiza ce modele mentale au format utilizatorii. Principalele obiective includ: Chiar și atunci când utilizatorii nu au fost implicați în joc, au perceput partenerul AI-dialog ca fiind inteligent și plăcut, ceea ce implică că l-au văzut ca un partener separat de joc. Acest lucru a fost susținut și de utilizatorii care au supraestimat adesea abilitățile sistemului și au proiectat atribute asemănătoare cu oamenii, ceea ce a dus la erori de comunicare. Concluzionăm că crearea unor modele mentale comune între utilizatori și sisteme AI este importantă pentru realizarea dialogurilor de succes. Propunem ca perspectivele noastre despre modelele mentale și comunicarea greșită, jocul și corpul nostru să ofere instrumente utile pentru proiectarea sistemelor de dialog colaborativ.', 'sr': 'Saradnja sa ljudskim AI-om, dugi stajani cilj u AI-u, odnosi se na partnerstvo gde ljudska i umjetna inteligencija zajedno rade ka zajedničkom cilju. Kolaborativni dijalog omogućava ljudskim AI timovima da komuniciraju i utiču snage od oba partnera. Da bismo dizajnirali sisteme saradnje dijaloga, važno je shvatiti šta korisnici mentalnih modela formiraju o svojim partnerima sa AI-dijalogom, međutim, kako korisnici smatraju da te sisteme nisu potpuno shvaćeni. U ovoj studiji smo dizajnirali roman, saradnju, komunikacijsku igračku zagonetku i objašnjavajući dijalog. Stvorili smo javni korpus iz 117 razgovora i nakon istraživanja i koristili smo ovo da analiziramo šta su formirali korisnici mentalnih modela. Ključni preuzimanji uključuju: čak i kada korisnici nisu bili uključeni u utakmicu, smatrali su partner a AI-dijaloga inteligentnim i sličnim, tvrdili da su ga videli kao partnera odvojenog od utakmice. To su dalje podržavali korisnici često preocjenjuju sposobnosti sistema i proglašavaju ljudske lične atribute koje su dovele do pogrešnih komunikacija. Zaključili smo da je stvaranje zajedničkih mentalnih modela između korisnika i AI-ovih sustava važno za postizanje uspešnih dijaloga. Predlažemo da naši uvidi o mentalnim modelima i nepravednom komunikaciji, igri i našim korpusom pružaju korisne alate za dizajniranje saradnjih dijalogskih sustava.', 'mn': 'Хүн-ХАБ-ын хамтын ажиллагаа, AI-ын урт зорилго, хүн болон уран бүтээлч ухаан хуваалцан зорилго руу хамтдаа ажилладаг хамтын ажиллагааг илэрхийлж байна. Хамтран нийлүүлэх диалог нь хүн-AI баг хоёр хамтрагчдаас хүчтэй холбоотой, хүчтэй холбоотой байдаг. Хамтран ажиллах диалог системүүдийг зохиохын тулд сэтгэл санааны загварын хэрэглэгчид AI-диалогын хамтрагчдын талаар юу болохыг ойлгох нь чухал. Энэ судалгаанд бид шинэ, хамтын ажиллагаатай, харилцааны суурь тоглоом болон тайлбарлах диалог системийг бүтээсэн. Бид 117 ярилцлагаас, дараагийн судалгаанаас нийтийн корпус бүтээсэн. Энэ нь сэтгэл санааны загварын хэрэглэгчид юу бүтээсэн талаар шинжилгээ хийсэн. Тоглоом дээр хэрэглэгчид оролцоогүй ч, AI-диалогын хамтрагч нь ухаантай, дуртай гэдгийг ойлгосон. Үүнийг хэрэглэгчид ихэвчлэн системийн чадварыг дутагдаж, хүн төрөлхтний шиг харилцаа буруу холбоотой байдлыг төсөөлдөг. Бид хэрэглэгчдийн болон AI системийн хоорондох хуваалтын сэтгэл санааны загвар бүтээх нь амжилттай диалогуудыг олох нь чухал. Бид сэтгэл санааны загвар, буруу харилцаа, тоглоом, корпус, хамтран ажиллах диалог системийг зохиохын тулд ашигтай хэрэгсэл хангах гэдгийг санал дэвшүүлнэ.', 'no': 'Menneskelige-AI-samarbeid, ei lang stadig mål i AI, refererer til eit partnerskap der ein menneskelig og kunstig intelligens arbeider sammen mot ei delt mål. Samarbeidsdialogen tillet menneskelige-AI-grupper å kommunisera og levera styrken frå begge partnerar. For å utforme samarbeidsgrensesystemet er det viktig å forstå kva menylige modeller brukarar formar om sine AI-dialogpartnere, men korleis brukarar oppfattar desse systema ikkje er fullstendig forstått. I denne studien designerte vi eit roman, samarbeidsfelt, kommunikasjonsbasert puslespel og forklaringsdialogsystemet. Vi oppretta ein offentleg korpus frå 117 samtaler og post-undersøk og brukte dette for å analysera kva mentale modeller brukarar laga. Nøkkeloppgåver inkluderer: Selv når brukarar ikkje vart engasjert i spelet, oppdaga dei AI-dialogpartneren som intelligent og likevel, som tyder at dei så det som ein partner skilde frå spelet. Dette vart støtta framleis av brukarar som ofte overestimer systemets kapasitet og prognoserer menneskelige attributt som førte til feil kommunikasjon. Vi avsluttar at det er viktig å laga delte mentale modeller mellom brukarar og AI-systemer for å oppnå suksessfulle dialogar. Vi foreslår at utviklingane våre på mentale modeller og feil kommunikasjon, spelet og korpusen våre gjev nyttige verktøy for å utforma samarbeidsfeltsystemet.', 'pl': 'Współpraca człowiek-AI, długotrwały cel w sztucznej inteligencji, odnosi się do partnerstwa, w którym człowiek i sztuczna inteligencja współpracują w kierunku wspólnego celu. Wspólny dialog pozwala zespołom człowiek-AI komunikować się i wykorzystać mocne strony obu partnerów. Aby projektować współpracujące systemy dialogowe, ważne jest, aby zrozumieć, jakie modele mentalne tworzą użytkownicy o swoich partnerach dialogowych AI, jednak nie jest w pełni zrozumiane, jak użytkownicy postrzegają te systemy. W tym opracowaniu zaprojektowaliśmy nowatorską, współpracującą, komunikacyjną grę logiczną i system dialogu wyjaśniającego. Stworzyliśmy publiczny korpus z 117 rozmów i post-ankiet i wykorzystaliśmy go do analizy, jakie modele mentalne tworzyli użytkownicy. Nawet wtedy, gdy użytkownicy nie byli zaangażowani w grę, postrzegali partnera dialogu AI jako inteligentnego i sympatycznego, co oznacza, że postrzegali go jako partnera oddzielnego od gry. Było to dodatkowo wspierane przez użytkowników często przeceniających zdolności systemu i projekcję cech podobnych do człowieka, co doprowadziło do nieporozumień. Stwierdzamy, że tworzenie wspólnych modeli mentalnych pomiędzy użytkownikami a systemami AI jest ważne dla osiągnięcia udanego dialogu. Proponujemy, aby nasze spostrzeżenia na temat modeli mentalnych i błędów komunikacji, gry i korpusu dostarczyły użytecznych narzędzi do projektowania współpracy systemów dialogowych.', 'so': 'Dadka-AI waxaa loola jeedaa shirkad aad u dhaadheer AI, kaas oo loogu talogalay shirkad ay dadka iyo waxyaabaha la xiriira u wada shaqeeyaan goal qayb ah. Dagaalka shaqaalaha ah wuxuu kooxda dadka-AI ka raadsan karaa in labada lammaane laga soo xiriiro xoogga badbaadada shaqaalaha. Si aad u sawiro nidaamka iskaashatada, waxaa muhiim ah in aad fahanto noocyada maskaxda ee isticmaalayaasha noocyada caafimaadka ee lammaanahooda AI-dialog, habase yeeshee sida isticmaalayaashu u garanaya nidaamkan aan si buuxda loo garanayn. Waxbarashadan waxan ku qornay warqad, iskaashatay, ciyaar dhibaato ah oo ku saabsan xiriirka iyo nidaamka diyaarinta. Waxaan ka abuurnay qof dadweynaha ah oo ka soo bilaabay 117 hadal-ka-dib baaritaanka kaddibna waxan aannu u isticmaalnay si aan u baarayno waxa ay u sameeyeen qaababka maskaxda. Qaashada furayaasha waxaa ka mid ah: Xataa marka isticmaalayaashu aysan ciyaar ku qabanayn, waxay garteen lammaanka dialogka AI oo ah mid caqli leh oo u sahlan, taas oo looga jeedo inay u jeedaan sida lammaane ka duwan ciyaarta. Tan waxaa kaloo caawiya isticmaalayaal inta badan qiimeynaya awoodda nidaamka iyo soo saaritaanka tusaale ahaan biniaadamka, taasoo sababtay khiyaano khalad ah. We conclude that creating shared mental models between users and AI systems is important to achieving successful dialogs.  Waxaynu soo jeedaynaa in aragtidayada ku saabsan muuqashada maskaxda, isbedelka, ciyaarta iyo korpusyadeenu ay u fidiyaan qalabka faa’iidada si ay u sameeyaan nidaamka iskaashatada.', 'ur': 'انسان-AI کی تعامل، AI میں ایک طویل موقع ہے، ایک شرکت کی طرف متوجہ ہوتی ہے جہاں ایک انسان اور مصنوعی بصیرت ایک مشترک موقع کی طرف اکٹھے کام کرتی ہے. شرکت دیالوگ انسان-AI ٹیموں کو دونوں شرکتوں سے قوت کا ارتباط اور استعمال کرنا اجازت دیتا ہے. مشارکت دیالوگ سیسٹم کی طراحی کرنے کے لئے، یہ سمجھنا ضروری ہے کہ روانی مدل کارساز ان کے AI دیالوگ شریکوں کے بارے میں کس طرح استعمال کرتے ہیں، ان سیسٹموں کو کس طرح سمجھتے ہیں؟ اس مطالعہ میں ہم نے ایک روانی، همکاری، کامنیک بنیاد پازل کھیل اور واضح طراحی ڈالیٹ سٹم کی طراحی کی۔ ہم نے 117 مکالمانوں اور بعد سؤرٹیوں سے ایک عمومی کورپوس پیدا کیا اور اسے مذہنی موڈل کارساز نے کیا بنایا تھا تحقیق کرنے کے لئے استعمال کیا۔ Key takeaways include: Even when users were not engaged in the game, they perceived the AI-dialog partner as intelligent and likeable, saying they saw it as a partner from the game separated. یہ اضافہ کارساز کی مدد کی گئی تھی کہ اکثر سیسٹم کی قابلیت اور انسان جیسی اضافہ کی تدبیر کرتی تھی جو غلط تعاملات کی وجہ سے ہوتی تھی۔ ہم نے معلوم ہوا کہ کارساز اور AI سیستموں کے درمیان مشترک ذهنی موڈل پیدا کرنے کے لئے موفق دایالوں کو پہنچانے کے لئے اہم ہے. ہم پیشنهاد کرتے ہیں کہ ہماری نظریں روانی موڈل اور غلط ارتباط، کھیل، اور ہماری کورپوس، مشارکت دیالوگ سیستموں کی طراحی کے لئے مفید ابزار بنائیں۔', 'sv': 'Samarbete mellan människa och AI, ett långvarigt mål inom AI, syftar på ett partnerskap där människa och artificiell intelligens arbetar tillsammans mot ett gemensamt mål. Samarbetsdialoger gör det möjligt för människa-AI-team att kommunicera och utnyttja styrkorna från båda partnerna. För att utforma samarbetsdialogsystem är det viktigt att förstå vilka mentala modeller användare bildar om sina AI-dialogpartners, men hur användare uppfattar dessa system är inte helt förstått. I denna studie utformade vi ett nytt, samarbetsbaserat, kommunikationsbaserat pusselspel och förklarande dialogsystem. Vi skapade en offentlig korpus från 117 konversationer och efterundersökningar och använde den för att analysera vilka mentala modeller användarna bildade. Viktiga saker inkluderar: Även när användare inte var engagerade i spelet upplevde de AI-dialogpartnern som intelligent och sympatisk, vilket innebär att de såg den som en partner skild från spelet. Detta stöddes ytterligare av användare som ofta överskattade systemets förmågor och projicerade mänskliga egenskaper vilket ledde till missförstånd. Vi drar slutsatsen att det är viktigt att skapa gemensamma mentala modeller mellan användare och AI-system för att uppnå framgångsrika dialoger. Vi föreslår att våra insikter om mentala modeller och misskommunikation, spelet och vår korpus ger användbara verktyg för att utforma samarbetsdialogsystem.', 'ta': 'மனித-AI ஒரு நீண்ட நிலையான கூட்டத்தை குறிப்பிடுகிறது, ஒரு மனிதன் மற்றும் கலைஞர் புலன்கள் ஒரு பகிர்ந்த இலக்குக்கு ஒன்று சேர்க்கு தொழில்நுட்பமான உரையாடல் மனித - AI குழுக்களை இரு கூட்டாளிகளில் இருந்து கூட்டும் உரையாடல் முறைமைகளை வடிவமைக்க முக்கியமானது, அவர்களுடைய AI- உரையாடல் இணைப்புகளை பற்றி மாதிரி மாதிரிகளை புரிந்து கொள்ள முடிய இந்த ஆராய்ச்சியில், நாங்கள் ஒரு புதிய, கூட்டாளி, தொடர்பு அடிப்படையான புதிர் விளையாட்டு மற்றும் விளக்கமான உர 117 பேச்சுகளிலிருந்து ஒரு பொது குறியீட்டை உருவாக்கினோம் மற்றும் பின்பு ஆய்வுகள் மற்றும் மாதிரி மாதிரிகள் உரு விசை எடுக்கும் வழிகளில் உள்ளது: பயனர்கள் விளையாட்டில் சேராமல் இருந்த போதும், அவர்கள் AI- உரையாடல் பங்காளியாக புரிந்து கொள்ளும் போதும்,  இது மேலும் பயனர்கள் பெரும்பாலும் கணினியின் திறமையை மேலும் மதிப்பிடுகிறது மற்றும் மனிதர் போன்ற குணங்களை திட்டமைக் நாம் முடிவு செய்கிறோம் பயனர்கள் மற்றும் AI முறைமைகளுக்கிடையே பங்கிடப்பட்ட மனநிலை மாதிரிகளை உருவாக்குவத நாங்கள் நினைவூட்டுகிறோம் மாதிரி மற்றும் தவறான தொடர்பு, விளையாட்டு, மற்றும் எங்கள் கூட்டத்திற்கு உதவியான கருவி', 'si': 'මිනිස්සු AI සහයෝගයක්, AI වල ලොකු ස්ථානයේ ඉලක්කයක්, මිනිස්සු සහ ක්\u200dරියාත්මක බුද්ධිමත් එකට සම්බන්ධ වෙන්නේ  සම්බන්ධ සංවාදයෙන් මිනිස්-AI කණ්ඩායම් සම්බන්ධ වෙන්න සහ සම්බන්ධ වෙන්න පුළුවන්. සහාය සංවාදක පද්ධතිය සැකසුම් කරන්න, ඒක තේරුම් ගන්න වැදගත් වෙන්නේ මානසික මොඩේල් ප්\u200dරයෝජකයෝ ඔවුන්ගේ AI-සංවාදක මේ අධ්\u200dයානයේ අපි නිර්මාණයක්, සම්බන්ධයි, සම්බන්ධ සංවාදය අධ්\u200dයානයක් හා ප්\u200dරකේෂණ සංවාදය පද්ධත අපි සාමාන්\u200dය කොර්පස් එකක් නිර්මාණය කරලා 117 කතා කරලා පස්සේ පරීක්ෂණා කරලා මේක පාවිච්චි කරලා මානසික ම යතුරු ගන්න පුළුවන් සම්බන්ධ වෙනවා: ප්\u200dරයෝජකයෝ සෙල්ලම් එක්ක සම්බන්ධ වෙන්නේ නැති වෙලාවත්, ඔවුන් AI-සංවාදය සම්බන්ධ මේක ප්\u200dරයෝජකයෙන් හැමවෙලේම ප්\u200dරයෝජකයෙන් ප්\u200dරමාණය කරනවා පද්ධතියේ ප්\u200dරයෝජනය සහ මිනිස්සු වගේ ප්\u200dරයෝජනය අපි අවස්ථාවෙන්නේ පාවිච්චි සහ AI පද්ධතිය අතර භාවිත මානසික මෝඩල් නිර්මාණය කරන්න වැදගත් වෙනව අපි ප්\u200dරශ්නයක් කරනවා අපේ අදහස් මානසික මොඩල් සහ වැරදි සම්බන්ධයක්, සෙල්ලම, අපේ කොර්පුස් සම්බන්ධ සංවාද පද්ධත', 'uz': "Inson-AI bilan birlashtirish, AIdagi uzun maqsad, inson va ijodkorlik intellektlarni birlashtirilgan maqsad bilan birlashtirish bilan ishlashni anglatadi. Ulanish muloqat oynasi ikkita kompyuterdagi qo'llangan odamlar va qo'llanmalar bilan aloqa qilishga ruxsat beradi. Ulanish muloqat tizimlarini dizalash uchun, ma'lumot modellari foydalanuvchilari AI dialog bilan qanday qilishni tushunish muhim, ammo foydalanuvchilar bunday tizimni butunlay tushunmaydi. Bu o'qituvda biz novel, bilan birlashtirilgan, aloqa asosida yaratilgan puzzli oʻyinlarni yaratdik va fikrlash muloqat tizimi. 117 ta'limdan bir umumiy kompyuter yaratdik va keyin tashqi qilish va bu narsa boshqa modellar nima yaratilganligini aniqlash uchun ishlatdik. Keyingi tugmalar qoʻllanmagan: Foydalanuvchilar o'ynab boʻlmaganda, ular AI dialog шерикларини intellektli va o'xshash deb tushunadi. Ularni oʻyinlaridan bir bir xil deb o'ylashadi. Bu foydalanuvchilar ko'pincha tizimning qobiliyatlarini ko'paytirishdan foydalanuvchilar qo'llanmagan va odamning xususiyatlarini tasavvur qilishda qoʻllaniladi. Bu bizga bog'lash sababini yolg'on beradi. Biz murakkab qilamiz, foydalanuvchilar va AI tizimlar orasidagi qismlarni yaratish juda muhim. Biz o'ylaymiz, ma'nosi modellari, yozuvlar, oʻyinlar va korpusiz bilan ishlab chiqarish uchun foydalanuvchi vositalarni beradi.", 'vi': 'Sự phối hợp giữa nhân tạo và nhân tạo, một mục tiêu lâu dài của AI, là một cộng sự nơi một trí thông minh nhân tạo phối hợp với nhau nhằm đạt mục tiêu chung. Hộp thoại hợp tác cho phép đội người-AI giao tiếp và sử dụng sức mạnh từ cả hai đối tác. Để thiết kế hệ thống hộp thoại hợp tác, cần phải hiểu người dùng mô hình thần kinh gì về đối tác của AI, tuy nhiên, cách người dùng nhận thức hệ thống này không hoàn to àn được hiểu. Trong nghiên cứu này, chúng tôi thiết kế ra một trò chơi đố chữ mới, hợp tác, liên kết và hộp thoại giải thích. Chúng tôi đã tạo ra một tập thể công cộng từ 117 để phân tích những mô hình người dùng. Giải thưởng chính là: ngay cả khi người dùng không tham gia trò chơi, họ cũng nhận ra đối tác của AI là thông minh và dễ thương, có nghĩa là họ thấy nó như một đối tác tách biệt với trò chơi. Điều này được hỗ trợ bởi những người dùng thường đánh giá cao khả năng của hệ thống và bộc lộ khả năng của con người, dẫn đến giao tiếp sai lạc. Chúng tôi kết luận rằng việc tạo ra các mô hình thần kinh chia sẻ giữa người dùng và hệ thống AI là quan trọng để đạt được cách mở thoại. Chúng tôi đề nghị kiến thức về mô hình thần kinh và giao tiếp sai lạc, trò chơi, và cơ thể chúng tôi cung cấp những công cụ hữu ích để thiết kế hệ thống hộp thoại hợp.', 'bg': 'Сътрудничеството между човека и изкуствения интелект, дългогодишна цел в изкуствения интелект, се отнася до партньорство, при което човек и изкуствен интелект работят заедно за постигане на обща цел. Диалогът за сътрудничество позволява на екипите от човешки изкуствен интелект да комуникират и да използват силните страни и от двата партньора. За да се проектират съвместни диалогови системи, е важно да се разбере какви умствени модели формират потребителите за своите партньори в диалогов диалог, но как потребителите възприемат тези системи не е напълно разбрано. В това проучване разработихме нова, съвместна, комуникационна игра пъзел и обяснителна диалогова система. Създадохме публичен корпус от 117 разговора и следанкети и го използвахме, за да анализираме какви умствени модели са формирали потребителите. Ключови изводи включват: Дори когато потребителите не са участвали в играта, те възприемат партньора за диалог с изкуствен интелект като интелигентен и симпатичен, което означава, че го виждат като партньор, отделен от играта. Това е подкрепено и от потребителите, които често надценяват способностите на системата и проектират човешки атрибути, което води до недоразумения. Заключението е, че създаването на споделени умствени модели между потребителите и системите на ИИ е важно за постигането на успешни диалози. Предлагаме нашите прозрения за умствените модели и неправилната комуникация, играта и нашия корпус да предоставят полезни инструменти за проектиране на съвместни диалогови системи.', 'da': 'Human-AI samarbejde, et langvarigt mål i AI, refererer til et partnerskab, hvor en menneskelig og kunstig intelligens arbejder sammen mod et fælles mål. Samarbejdsdialog giver menneskelig-AI teams mulighed for at kommunikere og udnytte styrker fra begge partnere. For at designe samarbejdsdialogsystemer er det vigtigt at forstå, hvilke mentale modeller brugerne danner om deres AI-dialogpartnere, men hvordan brugerne opfatter disse systemer er ikke fuldt ud forstået. I denne undersøgelse designede vi et nyt, samarbejdsbaseret, kommunikationsbaseret puslespil og forklarende dialogsystem. Vi skabte et offentligt korpus ud fra 117 samtaler og post-undersøgelser og brugte dette til at analysere, hvilke mentale modeller brugerne dannede. De vigtigste ting er: Selv når brugerne ikke var engageret i spillet, opfattede de AI-dialogpartneren som intelligent og sympatisk, hvilket antyder, at de så den som en partner adskilt fra spillet. Dette blev yderligere understøttet af brugere, der ofte overvurderede systemets evner og projicerede menneskelige lignende egenskaber, hvilket førte til fejlkommunikation. Vi konkluderer, at det er vigtigt at skabe fælles mentale modeller mellem brugere og AI-systemer for at opnå vellykkede dialoger. Vi foreslår, at vores indsigt i mentale modeller og fejlkommunikation, spillet og vores korpus giver nyttige værktøjer til at designe samarbejdsdialogsystemer.', 'nl': 'Human-AI collaboration, een langdurig doel in AI, verwijst naar een partnerschap waarbij mens en kunstmatige intelligentie samenwerken naar een gezamenlijk doel. Samenwerkende dialoog stelt mens-AI-teams in staat om te communiceren en de sterke punten van beide partners te benutten. Om collaboratieve dialoogsystemen te ontwerpen, is het belangrijk om te begrijpen welke mentale modellen gebruikers vormen over hun AI-dialoogpartners, maar hoe gebruikers deze systemen waarnemen is niet volledig begrepen. In deze studie ontwierpen we een nieuw, collaboratief, communicatiegebaseerd puzzelspel en verklarend dialoogsysteem. We creëerden een openbaar corpus uit 117 gesprekken en post-enquêtes en gebruikten dit om te analyseren welke mentale modellen gebruikers vormden. Belangrijkste aandachtspunten zijn: Zelfs wanneer gebruikers niet betrokken waren bij het spel, zagen ze de AI-dialoogpartner als intelligent en sympathiek, wat betekent dat ze hem zagen als een partner apart van het spel. Dit werd verder ondersteund door gebruikers die vaak de capaciteiten van het systeem overschatten en menselijke attributen projecteerden die tot miscommunicatie leidden. We concluderen dat het creëren van gedeelde mentale modellen tussen gebruikers en AI-systemen belangrijk is voor succesvolle dialogen. We stellen voor dat onze inzichten over mentale modellen en miscommunicatie, het spel en ons corpus nuttige hulpmiddelen bieden voor het ontwerpen van collaboratieve dialoogsystemen.', 'de': 'Die Zusammenarbeit zwischen Mensch und KI, ein langjähriges Ziel in der KI, bezieht sich auf eine Partnerschaft, in der Mensch und künstliche Intelligenz zusammenarbeiten, um ein gemeinsames Ziel zu erreichen. Durch den kollaborativen Dialog können Mensch-KI-Teams kommunizieren und Stärken beider Partner nutzen. Um kollaborative Dialogsysteme zu entwerfen, ist es wichtig zu verstehen, welche mentalen Modelle Benutzer über ihre KI-Dialogpartner bilden, aber wie Benutzer diese Systeme wahrnehmen, ist nicht vollständig verstanden. In dieser Studie haben wir ein neuartiges, kollaboratives, kommunikationsbasiertes Puzzlespiel und erklärendes Dialogsystem entwickelt. Aus 117-Gesprächen und Nachbefragungen haben wir ein öffentliches Korpus erstellt und analysiert, welche mentalen Modelle Nutzer gebildet haben. Wichtige Erkenntnisse sind: Selbst wenn Nutzer nicht am Spiel beteiligt waren, empfanden sie den KI-Dialogpartner als intelligent und sympathisch, was bedeutet, dass sie ihn als einen vom Spiel getrennten Partner sahen. Dies wurde auch dadurch unterstützt, dass Benutzer die Fähigkeiten des Systems oft überschätzten und menschenähnliche Attribute projizierten, was zu Missverständnissen führte. Wir schlussfolgern, dass die Schaffung gemeinsamer mentaler Modelle zwischen Nutzern und KI-Systemen wichtig ist, um erfolgreiche Dialoge zu erreichen. Wir schlagen vor, dass unsere Erkenntnisse über mentale Modelle und Missverständnisse, das Spiel und unser Korpus nützliche Werkzeuge für die Gestaltung kollaborativer Dialogsysteme liefern.', 'ko': '인공지능 협업은 인공지능 분야의 장기적인 목표로 인류와 인공지능이 공통된 목표를 실현하기 위해 협력하는 파트너 관계를 가리킨다.협업 대화는 인공지능 단체가 교류하고 쌍방의 장점을 활용하도록 허용한다.협업 대화 시스템을 설계하려면 사용자가 AI 대화 파트너에 대해 어떤 심리 모델을 형성했는지 파악하는 것이 중요하다. 그러나 사용자가 이러한 시스템을 어떻게 감지하는지는 아직 완전히 이해하지 못했다.이 연구에서 우리는 참신하고 협동적이며 교류를 바탕으로 하는 익지 게임과 해석적 대화 시스템을 설계했다.우리는 117차례의 대화와 게시물 조사에서 공공 어료 라이브러리를 만들어 사용자가 어떤 심리 모델을 형성했는지 분석했다.관건적인 수확은 사용자가 게임에 참여하지 않아도 AI 대화 파트너가 똑똑하고 귀엽다고 생각하는 것은 게임에 독립된 파트너라고 생각하는 것을 의미한다.사용자는 종종 시스템의 능력을 과대평가하고 인간과 유사한 속성을 투사하여 의사소통의 실수를 초래한다. 이것은 이 점을 더욱 지지한다.사용자와 인공지능 시스템 간에 공유된 심지 모델을 만드는 것이 성공적인 대화를 실현하는 데 매우 중요하다는 결론을 얻었다.우리는 심리 모델과 의사소통 실수, 게임과 자료 라이브러리에 대한 견해가 협업 대화 시스템을 설계하는 데 유용한 도구를 제공했다고 생각한다.', 'id': 'Kolaborasi manusia-AI, tujuan yang lama di AI, merujuk kepada sebuah persatuan di mana intelijen manusia dan buatan bekerja sama untuk tujuan yang sama. Dialog kolaboratif memungkinkan tim manusia-AI untuk berkomunikasi dan menggunakan kekuatan dari kedua mitra. Untuk merancang sistem dialog kollaboratif, penting untuk memahami apa bentuk pengguna model mental tentang partnernya dialog AI, bagaimanapun, bagaimana pengguna menyadari sistem ini tidak sepenuhnya dipahami. Dalam studi ini, kami merancang sebuah permainan teka-teki berbasis komunikasi dan sistem dialog penjelasan novel. Kami menciptakan sebuah korpus publik dari 117 percakapan dan post-survei dan menggunakan ini untuk menganalisis apa yang dibuat pengguna model mental. Perambilan kunci termasuk: Bahkan ketika pengguna tidak terlibat dalam permainan, mereka memperlihatkan rekan dialog AI sebagai cerdas dan menyenangkan, berarti mereka melihatnya sebagai rekan terpisah dari permainan. Ini didukung lebih lanjut oleh pengguna sering meremehkan kemampuan sistem dan memproyeksikan atribut seperti manusia yang menyebabkan kesalahan komunikasi. Kami menyimpulkan bahwa menciptakan model mental berbagi antara pengguna dan sistem AI penting untuk mencapai dialog sukses. Kami mengusulkan bahwa penglihatan kita tentang model mental dan salah komunikasi, permainan, dan korpus kita menyediakan alat berguna untuk merancang sistem dialog kollaboratif.', 'fa': 'همکاری انسان-AI، هدف طولانی در AI، به شرکتی که یک هوش انسان و مصنوعی با هم به سمت هدف مشترک کار می کند، ارائه می کند. محاورۀ همکاری اجازه می دهد که تیم\u200cهای انسان-AI به ارتباط و تأثیر قدرت از هر دو شریک ارتباط کنند. برای طراحی سیستم\u200cهای گفتگوی همکاری، مهم است که بفهمیم کاربران مدل\u200cهای روانی در مورد شریک\u200cهای گفتگوی AI\u200cشان چه شکل می\u200cدهند، ولی چگونه کاربران این سیستم\u200cها را کاملا درک نمی\u200cکنند. در این مطالعه، ما یک بازی بازیهای پازل بر اساس ارتباط و سیستم گفتگوی توضیح طراحی کردیم. ما یک شرکت عمومی از 117 صحبت و بعد از تحقیقات ایجاد کردیم و این را برای تحلیل کردن کاربران مدل روانی چه شکل داده است استفاده کردیم. در حالی که کاربران در بازی مشترک نبودند، شریک گفتگوی AI را به عنوان هوشمند و قابل مشترک می\u200cفهمند که آن را به عنوان شریک جدا از بازی دیدند. این بیشتر از آن، توسط کاربران اغلب بیشتر پشتیبانی می\u200cکردند که توانایی سیستم را تحقیق می\u200cکنند و پروژه\u200cسازی ویژه\u200cهای مانند انسان\u200cها که به سوی ارتباطات اشتباهی رخ دادند. ما تصمیم می گیریم که ایجاد مدل روانی مشترک بین کاربر و سیستم های AI برای رسیدن گفتگوهای موفقیت مهم است. ما پیشنهاد می\u200cکنیم که مشاهده\u200cهایمان در مورد مدل\u200cهای روانی و ارتباطات غلط، بازی و کارپوس ما ابزار مفید برای طراحی سیستم\u200cهای گفتگو\u200cهای همکاری را پیشنهاد کنیم.', 'sw': 'Human-AI collaboration, a long standing goal in AI, refers to a partnership where a human and artificial intelligence work together towards a shared goal.  Mjadala wa ushirikiano unaruhusu timu za UKIMWI binadamu kuwasiliana na kutumia nguvu kutoka kwa washirika wote. Kwa ajili ya kutengeneza mifumo ya mazungumzo ya ushirikiano, ni muhimu kuelewa ni kwa nini watumiaji wa mitindo ya akili wanavyotengeneza kuhusu washirika wao wa mazungumzo ya AI, hata hivyo, namna watumiaji wanavyoona mifumo hii haielewi vizuri. Katika utafiti huu, tuliunda riwaya, ushirikiano, mchezo wa pumzi wa mawasiliano na mfumo wa mazungumzo ya kuelezea. Tumetengeneza makampuni ya umma kutoka mazungumzo ya 117 na baada ya utafiti na tukatumia hili kuchambua vipi watumiaji wa mitindo ya akili walivyotengeneza. Toleo muhimu ni pamoja: Hata watumiaji hawakujihusisha na mchezo huo, waligundua mshirika wa mazungumzo ya AI kama mwelekeo wa akili na inawezekana, wakimaanisha kuwa waliiona kama mshirika tofauti na mchezo. Hili liliungwa mkono zaidi na watumiaji mara nyingi wakikadiria uwezo wa mfumo na kutengeneza vifaa kama binadamu vilivyosababisha mawasiliano mabaya. Tunahitimisha kwamba kutengeneza mifano ya akili zilizoshirikishwa kati ya watumiaji na mfumo wa UKIMWI ni muhimu wa kupata mazungumzo ya mafanikio. Tunazipendekeza kwamba mitazamo yetu kuhusu mifano ya akili na mawasiliano yasiyo ya kibinadamu, mchezo, na makampuni yetu yanatoa zana muhimu kwa ajili ya kutengeneza mifumo ya mazungumzo ya ushirikiano.', 'af': "Mense-AI-samarbeid, 'n lang staan doel in AI, verwys na 'n partnerskap waar 'n menslike en kunstenaarle intelligensie saam werk tot 'n gedeelde doel. Kolaboratiewe dialoog laat menslike-AI-teams toe om sterkte van beide partnere te kommuniseer en te verwyder. Om collaborative dialoog stelsels te ontwerp, is dit belangrik om te verstaan wat menslike modele gebruikers vorm oor hul AI-dialoog-partnere, maar hoe gebruikers hierdie stelsels verstaan word nie volledig verstaan nie. In hierdie studie het ons 'n roman, samarbeidende, kommunikasiegebaseerde raaiselspel en uitduidelike dialoog stelsel ontwerp. Ons het 'n openbare korpus skep van 117 gesprekke en post-ondersoek en dit gebruik om te analiseer wat menslike modelle gebruikers gevorm het. Sleutelbewe ingesluit: Selfs wanneer gebruikers nie in die speletjie geantwoord was nie, het hulle die AI-dialoog-partner as intelligent en gelykbaar aangeneem, terwyl hulle dit gesien het as 'n partner apart van die speletjie. Hierdie was verder ondersteun deur gebruikers gedeeltelik oorsaak van die stelsel se moontlikhede en projeksie van menslike eienskappe wat na miskommunikasie gelei het. Ons sluit dat die skep van gedeelde mentale modele tussen gebruikers en AI stelsels belangrik is om suksesvolle dialoog te bereik. Ons stel voorstel dat ons insig oor menslike modele en miskommunikasie, die speletjie en ons korpus nuttige nutsprogramme verskaf vir die ontwerp van samekorbeidende dialoog stelsels.", 'sq': 'Bashkëpunimi njerëzor-AI, një qëllim i gjatë në AI, referohet në një partneritet ku një inteligjencë njerëzore dhe artificiale punojnë së bashku drejt një qëllimi të përbashkët. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners.  Për të dizajnuar sistemet e dialogut bashkëpunimtar, është e rëndësishme të kuptohet se çfarë formojnë përdoruesit e modeleve mentale rreth partnerëve të tyre të dialogut AI, megjithatë, si përdoruesit perceptojnë këto sisteme nuk është e kuptuar plotësisht. Në këtë studim, kemi projektuar një lojë romake, bashkëpunimi, bazuar në komunikim dhe një sistem dialog shpjegues. Ne krijuam një korpus publik nga 117 bisedime dhe pas-sondazhe dhe e përdorëm këtë për të analizuar se çfarë formuan përdoruesit e modeleve mentale. Prerjet kryesore përfshijnë: Edhe kur përdoruesit nuk ishin të angazhuar në lojë, ata e kuptuan partner in e dialogut AI si të zgjuar dhe të pëlqyeshëm, duke nënkuptuar se e panë atë si një partner të ndarë nga loja. Kjo u mbështet më tej nga përdoruesit shpesh duke mbivlerësuar aftësitë e sistemit dhe duke projektuar atribute të ngjashme me njerëzit që çuan në gabime komunikimi. We conclude that creating shared mental models between users and AI systems is important to achieving successful dialogs.  Ne propozojmë që kuptimet tona mbi modelet mendore dhe keqkomunikimin, lojën dhe trupin tonë të ofrojnë mjete të dobishme për dizajnimin e sistemeve të dialogut bashkëpunimtar.', 'hr': 'suradnja ljudskih i umjetnih inteligencija, dugi stojeći cilj u AI-u, odnosi se na partnerstvo gdje ljudska i umjetna inteligencija zajedno rade ka zajedničkom cilju. Saradnji dijalog omogućava ljudskim AI timovima komunicirati i utjecati snage od obje partnera. Kako bi dizajnirali sustave saradnje dijaloga, važno je shvatiti kako korisnici mentalnih modela formiraju o partnerima AI-dijaloga, međutim, kako korisnici shvataju te sustave nisu potpuno razumjeli. U ovom studiju smo dizajnirali roman, saradnju, komunikacijsku igru zagonetke i objašnjavajući dijalog. Stvorili smo javni korpus iz 117 razgovora i nakon istraživanja i koristili smo to kako bi analizirali način korisnika mentalnih modela. Čak i kad korisnici nisu bili uključeni u utakmicu, smatrali su partner a AI-dijaloga inteligentnim i sličnim, tvrdili da su ga videli kao partnera odvojenog od utakmice. To su dalje podržavali korisnici koji često preocjenjuju sposobnosti sustava i proglašavaju ljudske lične atribute koje su dovele do pogrešnih komunikacija. Zaključili smo da je stvaranje zajedničkih mentalnih modela između korisnika i AI sustava važno postići uspješne dijaloge. Predlažemo da naši uvidi o mentalnim modelima i nepravednoj komunikaciji, igri i našim korpusom pružaju korisne alate za dizajniranje sustava saradnje dijaloga.', 'am': 'የሰው-AI ተግባር፣ ረጅም የቆመ አካል፣ የሰው እና የፍጥረት intelligence በአንድነት ወደተካፈለ ጉዳይ የሚሠራበት ተማርነት ነው፡፡ ከሁለቱም ተጋሪዎች ኃይልን እና የድጋፍ ኃይልን ለማግኘት የሰው-AI ቡድን እንዲፈቅድ ይችላል፡፡ የጥያቄ ጥያቄ ሲስተም ለመግለጽ፣ የmental ምሳሌ ተጠቃሚዎቹ ስለ AI-dialog ተጋሪዎቻቸው ምን እንደምሉ መግለጫ ያስተውሉታል፡፡ በዚህ ትምህርት ውስጥ የኖረብ፣ አብራሪ፣ የግንኙነት የቁስል ጨዋታ እና የጥያቄ ማኅበረሰብ ስርዓት ፈጠርነው፡፡ ከ117 ንግግር እና ፖስቲካዎች የህዝብ ኮፕስስ ፈጠርነው እና አካባቢ ምሳሌዎችን እንዴት እንደፈጠሩ አስተያየት ለመፍጠር ነው፡፡ የቁልፍ መቀበል መንገድ ውስጥ ነው፤ ምንም እንኳን ተጠቃሚዎች በጨዋታው ውስጥ ያልተጨማሩ ሲሆኑ የAI-dialog ተጋሪዎችን አስተዋልተዋል፡፡ ይህም በተጨማሪው ተጠቃሚዎች የስርዓቱን ኃይል በማድረግ እና የስህተት ግንኙነትን በመቀበል በሚያሳዩት የሰው ብጤቶች መዘጋጀት ይደግፋሉ፡፡ በተጠቃሚዎች እና በAI ስርዓቶች መካከል የተለየ ማነሻ ምሳሌዎችን መፍጠር የስልጣን ጥያቄን ለማግኘት ያስፈልጋል፡፡ የmental ምሳሌ እና የስህተት ግንኙነት፣ ጨዋታው እና ቆርፓስነታችን የተጠቃሚ የጥያቄ መሣሪያዎችን ለመግለጽ እናስባለን፡፡', 'bn': 'মানুষ-AI সহযোগিতা, AI-এ একটি দীর্ঘ লক্ষ্য, একটি অংশীদারিত্বের কথা উল্লেখ করেছে যেখানে মানুষ এবং শিল্পিক গোয়েন্দা একসাথে শেয়া Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners.  কিভাবে ব্যবহারকারীরা এই সিস্টেম সম্পূর্ণ বুঝতে পারে না। এই গবেষণায় আমরা একটি উপন্যাস, সহযোগিতা, যোগাযোগ ভিত্তিক পাজল গেম এবং ব্যাখ্যা করা ডায়ালগ সিস্টেম গঠন করেছি। আমরা ১১৭ সালের কথোপকথন এবং পর্যবেক্ষণের মধ্য থেকে একটি পাবলিক কোর্পাস তৈরি করেছি এবং এটা ব্যবহার করেছি মানসিক মডেল ব্যবহারকার কী (Key) টেকওয়েইজ অন্তর্ভুক্ত: এমনকি যখন ব্যবহারকারীরা খেলায় অংশগ্রহণ করেনি তখন তারা বুদ্ধিমান এবং সমর্থক হিসেবে আল-ডায়ালগের অংশীদার হিসে ব্যবহারকারীরা প্রায়শই সিস্টেমের ক্ষমতা বেশী হিসেবে সমর্থন করে এবং মানুষের মত বৈশিষ্ট্য প্রকল্প করে যা ভুল যোগাযোগ আমরা উপসংহার প্রদান করেছি যে ব্যবহারকারী এবং AI সিস্টেমের মধ্যে ভাগাভাগি মানসিক মডেল তৈরি করা গুরুত্বপূর্ণ কথো আমরা প্রস্তাব করছি যে আমাদের মানসিক মডেল এবং ভুল যোগাযোগ, খেলা এবং আমাদের কোর্পাসের ব্যাপারে আমাদের দৃষ্টিভঙ্গি সহযোগিতা ডি', 'az': "ńįnsan-AI iŇübirlińüi, AI'nin uzun duran m…ôqs…ôdi, insan v…ô sanatlńĪ istihbarat birlikd…ô paylaŇüńĪlan m…ôqs…ôdil…ô birlikd…ô √ßalńĪŇüan bir Ňü…ôrikliy…ô m…ôlumat edir. ńįŇübirlik√ßi dialońüu insan-AI takńĪmlarńĪn ikisinin ortaqlarńĪndan g√ľcl…ôri iletiŇüim etm…ôsin…ô v…ô istifad…ô etm…ôsin…ô imkan verir. ńįŇübirlik√ßi Dialoog sisteml…ôrini tasarlamaq √ľ√ß√ľn, bu sisteml…ôrin tamamil…ô anlanmadńĪqlarńĪnńĪ d√ľŇü√ľnm…ôk m…ôqs…ôdildir ki, mental modell…ôrin istifad…ô√ßil…ôrinin AI-Dialoog ortaqlarńĪ haqqńĪnda n…ôl…ôr yaratdńĪńüńĪnńĪ anlamaq. Bu t…ôhsil i√ßind…ô, biz roman, iŇübirlik√ßi, komunikasiya tabanlńĪ puzzle oyunu v…ô a √ßńĪq-aydńĪn dialog sistemini tasarladńĪq. Biz 117 danńĪŇümalardan v…ô sonra araŇütńĪrmalardan halkńĪ korpus yaratdńĪq v…ô bunu mental modell…ôrin yaratdńĪńüńĪnńĪ analiz etm…ôk √ľ√ß√ľn istifad…ô etdik. Anahtar alńĪŇüveriŇül…ôrd…ô: istifad…ô√ßil…ôr oyun i√ßind…ô iŇütirak etm…ôdikl…ôri halda, AI-dialog ortańüńĪnńĪ a ńüńĪl v…ô b…ônz…ôr kimi g√∂r√ľrd√ľl…ôr, onu oyundan ayrńĪlmńĪŇü bir ortaq kimi g√∂rd√ľkl…ôrini iddia edirl…ôr. Bu, istifad…ô√ßil…ôrin √ßox √ßox sistemin qabiliyy…ôtini v…ô insanlarńĪn b…ônz…ôrini t…ôŇükil edib, yanlńĪŇü …ôlaq…ôl…ôr…ô yol a√ßan Ňü…ôkill…ôrin d…ôst…ôkl…ôndirildi. ńįŇül…ôyici v…ô AI sisteml…ôri arasńĪnda paylaŇüńĪlmńĪŇü mental modell…ôri yaratmaq m√ľv…ôff…ôqiyy…ôti il…ô m√ľv…ôff…ôqiyy…ôtl…ô m√ľv…ôff…ôqiyy…ôtdir. Biz d√ľŇü√ľnc…ôli modell…ôr v…ô yanlńĪŇü komunikasyon, oyun v…ô korpusumuz iŇübirlik√ßi dialoq sisteml…ôrini dizayn etm…ôk √ľ√ß√ľn faydalńĪ vasit…ôl…ôri t…ôklif edirik.", 'bs': 'Saradnja ljudskih AI-a, dugi stajalni cilj u AI-u, odnosi se na partnerstvo gdje ljudska i umjetna inteligencija zajedno rade ka zajedničkom cilju. Saradnji dijalog omogućava ljudskim timovima AI-a da komuniciraju i utiču snage od oba partnera. Kako bi dizajnirali sisteme saradnje dijaloga, važno je shvatiti koji su korisnici mentalnih modela formirali o partnerima AI-dijaloga, međutim, kako korisnici shvataju da te sisteme nisu potpuno razumjeli. U ovoj studiji smo dizajnirali roman, saradnju, komunikacijsku igračku zagonetku i objašnjavajući dijalog. Stvorili smo javni korpus iz 117 razgovora i nakon istraživanja i koristili smo to da analiziramo koji su korisnici mentalnih modela formirali. Čak i kad korisnici nisu bili uključeni u igru, smatrali su partner a AI-dijaloga inteligentnim i sličnim, tvrdili da su ga videli kao partnera odvojenog od igre. To su dalje podržavali korisnici često preocjenjujući sposobnosti sustava i proglašavajući ljudske lične atribute koji su doveli do pogrešnih komunikacija. Zaključili smo da je stvaranje zajedničkih mentalnih modela između korisnika i AI-a važno postići uspješni dijalog. Predlažemo da naši uvidi o mentalnim modelima i nesporazumom, igri i našim korpusom pružaju korisne alate za dizajniranje saradnjih dijalogskih sustava.', 'ca': "La col·laboració human a-AI, un objectiu de llarg temps en AI, es refereix a una col·laboració on una intel·ligència humana i artificial treballen junts cap a un objectiu compartit. El diàleg de col·laboració permet als equips d'AI humana comunicar-se i aprofitar les forces dels dos parells. Per dissenyar sistemes de diàleg col·laboratiu, és important entendre quins models mentals formen els usuaris sobre les seves parelles de diàleg d'AI, però com els usuaris perceben aquests sistemes no s'entend plenament. En aquest estudi vam dissenyar un joc de rompecabelles novel, col·laborativ, basat en la comunicació i un sistema de diàleg explicativ. Vam crear un cos públic a partir de 117 converses i després d'encuestes i ho vam utilitzar per analitzar quins models mentals van formar els usuaris. Les maneres clau inclouen: Fins i tot quan els usuaris no estaven involucrats en el joc, van percebre la parella del diàleg AI com intel·ligent i agradable, i això implica que ho van veure com una parella separada del joc. Això va ser suportat per usuaris que sovint sobreestimaven les habilitats del sistema i projectaven atributs similars a human s que van portar a malcomunicacions. Conclouem que crear models mentals compartits entre usuaris i sistemes d'AI és important per aconseguir diàlegs d'èxit. Proposem que les nostres idees sobre els models mentals i la mala comunicació, el joc i el nostre cos proporcionen eines útils per dissenyar sistemes de diàleg col·laboratiu.", 'cs': 'Spolupráce mezi člověkem a umělou inteligencí, dlouhodobým cílem v oblasti umělé inteligence, se vztahuje na partnerství, kde člověk a umělá inteligence spolupracují na společném cíli. Spolupráce umožňuje týmům člověka a umělé inteligence komunikovat a využívat silné stránky obou partnerů. Pro navrhování spolupracujících dialogových systémů je důležité pochopit, jaké mentální modely uživatelé vytvářejí o svých partnerech dialogu AI, nicméně, jak uživatelé tyto systémy vnímají, není plně pochopeno. V této studii jsme navrhli novou, spolupracující komunikační puzzle hru a vysvětlující dialogový systém. Z 117 konverzací a post-průzkumů jsme vytvořili veřejný korpus a analyzovali, jaké mentální modely uživatelé vytvořili. Mezi klíčové záležitosti patří: I když uživatelé nebyli ve hře zapojeni, vnímali partnera dialogu AI jako inteligentního a sympatického, což znamená, že ho viděli jako partnera odděleného od hry. To bylo dále podporováno uživateli, kteří často přeceňovali schopnosti systému a promítali lidské atributy, což vedlo k nesprávným komunikacím. Dospěli jsme k závěru, že vytváření sdílených mentálních modelů mezi uživateli a systémy AI je důležité pro dosažení úspěšného dialogu. Navrhujeme, aby naše pohledy na mentální modely a nesprávné komunikace, hru a korpus poskytovaly užitečné nástroje pro navrhování spolupracujících dialogových systémů.', 'et': 'Inimese ja tehisintellekti koostöö, mis on tehisintellekti pikaajaline eesmärk, viitab partnerlusele, kus inimene ja tehisintellekt töötavad koos ühise eesmärgi nimel. Koostöödialoog võimaldab inimese ja tehisintellekti meeskondadel suhelda ja kasutada mõlema partneri tugevaid külgi. Koostöödialoogisüsteemide kujundamiseks on oluline mõista, milliseid vaimseid mudeleid kasutajad oma AI-dialoogipartnerite kohta moodustavad, kuid kuidas kasutajad neid süsteeme tajuvad, ei ole täielikult mõistetud. Käesolevas uuringus töötasime välja uudse, koostööpõhise, kommunikatsioonipõhise puzzle mängu ja selgitava dialoogi süsteemi. Lõime 117 vestlusest ja järelküsitlusest avaliku korpuse, mille abil analüüsisime, milliseid vaimseid mudeleid kasutajad moodustasid. Isegi kui kasutajad ei olnud mängus kaasatud, tajusid nad tehisintellekti dialoogi partnerit intelligentsena ja meeldivana, mis tähendab, et nad nägid seda mängust eraldiseisvana partnerina. Seda toetasid ka kasutajad, kes sageli ülehinnasid süsteemi võimeid ja projitseerisid inimsarnaseid omadusi, mis viisid kommunikatsioonivigadeni. Järeldame, et ühiste vaimsete mudelite loomine kasutajate ja tehisintellekti süsteemide vahel on eduka dialoogi saavutamiseks oluline. Teeme ettepaneku, et meie arusaam vaimsetest mudelitest ja ebaõnnestumisest, mängust ja korpusest pakuvad kasulikke vahendeid koostöödialoogisüsteemide kujundamiseks.', 'fi': 'Tekoälyn pitkäaikainen tavoite on yhteistyö, jossa ihminen ja tekoäly työskentelevät yhdessä kohti yhteistä tavoitetta. Yhteistyödialogin avulla ihmisen ja tekoälyn tiimit voivat kommunikoida ja hyödyntää molempien kumppaneiden vahvuuksia. Yhteistoiminnallisten dialogijärjestelmien suunnittelussa on tärkeää ymmärtää, mitä henkisiä malleja käyttäjät luovat tekoälykumppaneistaan, mutta miten käyttäjät näkevät nämä järjestelmät, ei täysin ymmärretä. Tässä tutkimuksessa suunnittelimme uudenlaisen, yhteisöllisen, viestintäpohjaisen pulmapelin ja selittävän dialogijärjestelmän. Laadimme 117 keskustelusta ja jälkikyselystä julkisen korpusen, jonka avulla analysoimme, mitä henkisiä malleja käyttäjät muodostivat. Tärkeimmät johtopäätökset ovat: Vaikka käyttäjät eivät olleet mukana pelissä, he pitivät tekoälyn dialogi-kumppania älykkäänä ja miellyttävänä, mikä viittaa siihen, että he näkivät sen erillisenä kumppanina pelistä. Tätä tukivat myös käyttäjät, jotka usein yliarvioivat järjestelmän kykyjä ja projisoivat ihmisen kaltaisia ominaisuuksia, mikä johti väärinkäsityksiin. Johtopäätöksenä on, että käyttäjien ja tekoälyjärjestelmien yhteisten henkisten mallien luominen on tärkeää onnistuneen dialogin aikaansaamiseksi. Ehdotamme, että ymmärryksemme henkisistä malleista ja väärinkäsityksistä, pelistä ja korpusestamme tarjoavat hyödyllisiä työkaluja yhteistyödialogijärjestelmien suunnitteluun.', 'tr': "Adamlar-AI işbirliği, AI'de uzak duran maksady, adamlaryň we umyt bilen bir maksadyň ýerine ýerleşýän işbirliğine görýär. Mutlaýyn dialog adamlary-AI toparlaryň ikisinden güýçleri bilen habarlaşmagyna we çykarmagyna mümkin edýär Ýaramsal dialoglary tasarlamak üçin, akyllary nusgalarynyň AI-dialoglary barada nähili düşünýändigini düşünmek örän wajyplyr. Bu okuwda biz roman, işbirliği, komunikaciýa daýanýan bulmacalar we düşündirimli dialog sistemasyny tasarladyk. 117 gürrüňden we soňra görüşmelerden soňra jemgyýet korpusyny bejerdik we muny duýgyş nusgalarynyň nähili ýöredigini çözümlemek üçin ulandyk. Ullançy alyp barlamaklar: Ullançylar oýunda gabat geçmediklerine garamazdan hem AI-dialogyň ortaklaryny akylly we ýaly görünýär, oýundan a ýrylan bir ortak diýip pikir etdiler. Bu köplenç ulananlar sistemiň başaryşlaryny aşa ynamly hasaplanýarlar we adam ýaly hasaplaryny ýalňyşlyk bilen meýilleşdirýärler. Ullançylar we AI sistemalaryň arasynda paylaşyk duýuklary nusgalary bejermek üçin wajyp däldir. Mensiýet nusgalarymyz we ýalňyşlyk bilen düşünjelerimizi, oýun we korpusymyz işbirliklik dialoglary düzenlemek üçin faydaly gurallar saýlamagyny teklip edýäris.", 'hy': "Մարդու-ԱԲ համագործակցությունը, ԱԲ-ի երկար նպատակը, նշանակում է համագործակցություն, որտեղ մարդու և արհեստական ինտելեկտը միասին աշխատում են ընդհանուր նպատակի համար: Ապրակտիվ պատկերացումը թույլ է տալիս մարդկային-ԱԲ թիմերին հաղորդակցվել և օգտագործել երկու գործընկերների ուժեղությունները: Կարևոր է հասկանալ, թե ինչ են մտավոր մոդելներ օգտագործողները ստեղծում իրենց ԱԲ-խոսակցային գործընկերների մասին, սակայն, թե ինչպես են օգտագործողները ընկալում այս համակարգերը ամբողջովին չի հասկանում: Այս ուսումնասիրության ընթացքում մենք ստեղծեցինք մի նոր, համագործակցական, հաղորդակցման հիմնված խաղալիք և բացատրական խոսակցության համակարգ: Մենք ստեղծեցինք մի հանրային կորպոս, որը կազմակերպեց սեփական զրույցներից և հետհետաքննություններից, և օգտագործեցինք սա վերլուծելու համար, թե ինչ են ստեղծվել մտավոր մոդելների օգտագործողները: Նույնիսկ երբ օգտագործողները խաղի մեջ չէին մասնակցում, նրանք ընկալեցին ԱԲ-ի գործընկերոջը որպես խելացի և սիրալի, ինչը նշանակում է, որ տեսան այն որպես խաղից առանձին գործընկեր: This was further supported by users often overestimating the system's abilities and projecting human-like attributes which led to miscommunications.  Մենք եզրակացնում ենք, որ օգտագործողների և ԱԲ համակարգերի միջև ընդհանուր մտավոր մոդելներ ստեղծելը կարևոր է հաջողակ հաղորդակցման համար: Մենք առաջարկում ենք, որ մեր մտավոր մոդելների և սխալ հաղորդակցման մասին մեր ընկալումները, խաղը և մարմնի միջոցը օգտակար գործիքներ տան համագործակցական երկխոսային համակարգերի ստեղծման համար:", 'he': 'שיתוף פעולה אנושי-AI, מטרה עמודה ארוכה ב AI, מתייחס לשותפות שבו אינטליגנציה אנושית ואמנותית עובדת יחד לכיוון מטרה משותפת. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners.  כדי לעצב מערכות דיאלוג שיתוף פעולה, חשוב להבין מה מודלים נפשיים משתמשים נוצרים על השותפים שלהם בדיולוג AI, עם זאת, איך המשתמשים רואים את המערכות הללו אינם מובנים לחלוטין. במחקר הזה עיצבנו משחק פאזל, שיתוף פעולה, מבוסס על תקשורת ומערכת דיאלוג הסבירה. יצרנו קורפוס ציבורי מ-117 שיחות ואחרי הסקרים והשתמשנו בזה כדי לנתח מה יצרו משתמשים במודלים נפשיים. דרכים המפתחות כוללות: אפילו כאשר משתמשים לא היו מעורבים במשחק, הם הבינו את השותף בדיולוג AI כאינטליגנטי ונחמד, מה שמרמז שהם ראו אותו כשותף נפרד מהמשחק. זה תומך נוסף על ידי משתמשים לעתים קרובות מעריכים יתר מידי את היכולות של המערכת ולפרוייקציה תכונות דומות לאדם שהובילו לתקשורת לא נכונה. אנחנו מסכם שביצור מודלים נפשיים משותפים בין משתמשים ומערכות AI חשובים להשיג דיאלוגים מצליחים. We propose that our insights on mental models and miscommunication, the game, and our corpus provide useful tools for designing collaborative dialog systems.', 'jv': 'AI-Njarian sing paling-perbudhakan, langgar sampek luwih ngupakan AI, babagan ingkang sampeyan karo ingkang sampeyan karo ingkang artikse dialog Ngawe ngubah sistem dialog yang sabanjuré, sing akeh lanjut kanggo sabanjuré model sing alam sing dikarepaké karo patiran AI-dialog, sane, piye ngerasaé sistem sing ora luwih apik. Nang barêng-barêng iki, kéné dhewe nggawe un nyumbang, lan ijol-ijolan, gambar kelompok lan sistem dialog sing basa gambar nggambar. Awak dhéwé nggawe barang kamuluh dumadhi kaya ingkang 1 1 ulih dumadhan karo perusahaan anyar tentang karo ngono nggawe modèlan sing sampek manipulan dumadhi. Validity mengkar Bilih sedhaya akeh dumateng liyane ing nguasai nggawe kapan sistem lan nggawe barang karo atiribute sing koyo nggawe barang dumateng. Awak dhéwé éntuk sistem sing berarti model sing kesalakno karo sistem AI sing dikarepaké kanggo nggawe dialog sing luwih dumadhi. Awak dhéwé ngéwé ngerasaé awak dhéwé ning model sing apik lan ijol-komunikasi, gambaran lan barang nggawe barang kelompok kanggo nggawe sistem dialog sing berarti.', 'sk': 'Sodelovanje med človekom in umetno inteligenco, dolgoletni cilj umetne inteligence, se nanaša na partnerstvo, v katerem človek in umetna inteligenca sodelujeta v smeri skupnega cilja. Sodelovalni dialog omogoča ekipam človeka in umetne inteligence, da komunicirajo in izkoristijo prednosti obeh partnerjev. Za oblikovanje sodelovalnih dialognih sistemov je pomembno razumeti, katere duševne modele uporabniki oblikujejo o partnerjih z umetno inteligenco, vendar ni popolnoma razumljeno, kako uporabniki dojemajo te sisteme. V študiji smo oblikovali novo, sodelovalno, komunikacijsko osnovano puzzle igro in pojasnjevalni dialogni sistem. Iz 117 pogovorov in post-anket smo ustvarili javni korpus, s katerim smo analizirali, katere duševne modele so oblikovali uporabniki. Ključni predlogi vključujejo: Tudi ko uporabniki niso bili vključeni v igro, so partnerja za dialog z umetno inteligenco dojeli kot inteligentnega in privlačnega, kar pomeni, da so ga videli kot partnerja ločenega od igre. To so podprli tudi uporabniki, ki so pogosto precenili sposobnosti sistema in projicirali človeku podobne atribute, kar je privedlo do napak v komunikaciji. Sklepamo, da je ustvarjanje skupnih miselnih modelov med uporabniki in sistemi umetne inteligence pomembno za doseganje uspešnih dialogov. Predlagamo, da naši vpogledi v duševne modele in nekomunikacije, igro in korpus zagotavljajo uporabna orodja za oblikovanje sodelovalnih dialognih sistemov.', 'ha': "Samayyarin mutum-AI, goan tsayi mai tsawo a cikin AI, yana madaidaita zuwa wani shirin tãrayya da mutane da ma'abũcin hankalin karya sami zuwa ga goan da aka raba shi. Daga zauren akwatin aiki na yarda da jama'ar-AI su yi wasiyya da ƙarfin aiki na biyu. To, don ka ƙayyade tsarin zauren akwatin bayani na shirin ayuka da ke amfani da misãlai na mantai, kuma amma, za'a buƙata don a fahimta tsarin su ba cikakken zauren akwatin bayani na AI. A cikin wannan lõkaci, muka ƙayyade wani riwaya, da shirin haɗiya, game da gamuwa na mazaɓa da kuma muka bayyana tsarin zauren akwatin bayani. Kuma Mun halicci umarin mutane daga mazaɓa 117 kuma Muka yi amfani da shi a bayan surya kuma Muka yi amfani da wannan dõmin ya yi anayya da misãlai da ke samu. Kayan riƙon kayan aiki na maɓallin su include: Haƙĩƙa, idan ba su yi amfani da shi ba, sai su gane ma'abũcin zauren akwatin AI kamar masu hankali da masu daidaita, kuma sunã faɗin sune shi kamar wani mataimaki wanda ya raba shi daga gamon. Wannan yana ƙaranci da wato mãsu amfani da shi, ana ƙara bayani ga abincin na'urar na'urar na'ura da kuma a gabatar da misãlai wa mutum. We conclude that creating shared mental models between users and AI systems is important to achieving successful dialogs.  Munã kwaɗai cẽwa idãnunku za'a samun misãlai na manti da mawaɓa, game da kuma makarubutunmu za'a sami zane da amfani ga danne tsarin zauren akwatin bayani na daban-daban.", 'bo': 'སྤྱི་ཚོགས་དང་ཆེན་པོ་ཞིག་ལས་ཕལ་ཆེན་རིང་བའི་དམིགས་ཡུལ་ཞིག་ནི་ཆ་རྐྱེན་དང་ལས་རྩན་ཆེན་པོ་ཞིག་ལས་སྦྲེལ་མཐུད་འདོད་ཡོ མཉམ་སྦྲེལ་བའི་ཌའི་ལོག མཉམ་ལས་ཀྱི་ཌའི་ལོག ལྟ་བུའི་ནང་དུ་ང་ཚོས་མཐུན་གཏོང་དང་། མཉམ་སྦྲེལ་མཐུད་ཀྱི་རྩེད་མོ་ཞིག་དང་སྒྲུང་གཏོང ང་ཚོས་མི་སྤྱི་ཚོགས་ཁང་ཞིག་གསར་འཛུགས་བྱས་ན། གཏམ་གླེང་མོལ་དང་ལས་རྗེས་ལྟ་ཞིབ་བྱས་ནས་ Key takeaways include: Even when users were not engaged in the game, they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner in the game. འདི་ནི་ལག་ལེན་པ་ཚོས་རྒྱུན་ལྡན་གྱིས་མ་ལག་གི་ཆ་རྐྱེན་དུ་ཆེ་མཐོང་ནུས་མེད་པའི་ཁྱད་ཆོས་ཉེར་སྤྱོད་མཁན་གྱིས་ར ང་ཚོས་ལག་ལེན་པ་དང་AI་རིགས ང་ཚོས་རྟོགས་པའི་མ་དབུགས་དང་འགན་སྤྲེལ་བའི་ཚོགས་ཀྱི་ལས་འགན་སྤྲོད་ཀྱི་རྩེད་དམ།'}
{'en': 'On  Language Models  for Creoles', 'ar': 'على نماذج اللغة للكريول', 'es': 'Sobre modelos lingüísticos para criollos', 'fr': 'À propos des modèles linguistiques pour les créoles', 'ja': 'クレオールのための言語モデルについて', 'zh': '论克里奥尔语语模样', 'hi': 'Creoles के लिए भाषा मॉडल पर', 'pt': 'Sobre modelos de linguagem para crioulos', 'ga': 'Ar Mhúnlaí Teanga do Chríoltaí', 'ru': 'О языковых моделях для креолов', 'el': 'Σχετικά με τα γλωσσικά μοντέλα για τις κρηόλες', 'hu': 'Kreol nyelvi modellek', 'it': 'Sui modelli linguistici per creoli', 'ka': 'ენის მოდელების შესახებ', 'lt': 'Kalbos modeliai kreuliams', 'mk': 'Name', 'ms': 'Pada Model Bahasa untuk Creoles', 'kk': 'Тіл үлгілерінде', 'mn': 'Холбооны загвар дээр', 'mt': 'On Language Models for Creoles', 'ml': 'ഭാഷ മോഡലുകളില്\u200d ക്രീയോളുകള്\u200d', 'pl': 'O modelach językowych kreolskich', 'ro': 'Despre modelele lingvistice pentru creoli', 'sr': 'Na jezički modeli za kreoles', 'so': 'Tilmaamaha afka ee Creoles', 'no': 'På språk- modeller for krooler', 'sv': 'Om språkmodeller för kreoler', 'ta': 'கிரீல்ஸுக்கான மொழி மாதிரிகளில்', 'si': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Tin tức thời trang', 'bg': 'За езикови модели за креоли', 'hr': 'Na jezički modeli za kreoles', 'nl': 'Taalmodellen voor Creolen', 'id': 'Dalam Model Bahasa untuk Creoles', 'ko': '크리올어의 언어 모델을 논하다', 'fa': 'روی مدل زبان برای کرولز', 'sw': 'Kwenye Modeli za Lugha kwa ajili ya Creoles', 'af': 'Op Taal Modelle vir Creoles', 'sq': 'Në modelet gjuhësore për Creoles', 'da': 'Om sprogmodeller for kreoler', 'de': 'Über Sprachmodelle für Kreolen', 'hy': 'Կրեոլսի լեզվի մոդելների վրա', 'tr': 'Çaltylyk Modelleri', 'am': 'ቋንቋ', 'az': 'Dil Modell톛ri', 'bn': 'ক্রিওলের জন্য ভাষার মডেল', 'bs': 'Na jezički modeli za kreoles', 'et': 'Kreoolide keelemudelite kohta', 'ca': 'En els Models de Llingua de Creoles', 'cs': 'O jazykových modelech pro kreolské jazyky', 'fi': 'Kreolien kielimalleista', 'jv': 'structural navigation', 'ha': '@ action', 'he': 'על דוגמני שפה עבור קרולים', 'sk': 'O jezikovnih modelih za kreole', 'bo': 'རྩི་མོ་བ་ལ་སྤྱོད་པའི་སྐད་ཡིག་གཟུགས་རིས་'}
{'en': 'Creole languages such as  Nigerian Pidgin English  and  Haitian Creole  are under-resourced and largely ignored in the NLP literature. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the  creole  is a complex process. While  creoles  are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations. This paper makes several contributions : We collect existing corpora and release models for  Haitian Creole ,  Nigerian Pidgin English , and  Singaporean Colloquial English . We evaluate these  models  on intrinsic and extrinsic tasks. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones. We investigate whether this is an effect of  over-parameterization  or relative distributional stability, and find that the difference persists in the absence of  over-parameterization , and that drift is limited, confirming the relative stability of  creole languages .', 'es': 'Los idiomas criollos como el inglés pidgin nigeriano y el criollo haitiano no cuentan con recursos suficientes y son ignorados en gran medida en la literatura de la PNL. Los criollos suelen ser el resultado de la fusión de una lengua extranjera con varios idiomas locales, y las características gramaticales y léxicas que se transfieren al criollo es un proceso complejo. Si bien los criollos son generalmente estables, la prominencia de algunas características puede ser mucho más fuerte con ciertos datos demográficos o en algunas situaciones lingüísticas. Este artículo hace varias contribuciones: Recopilamos corpus existentes y modelos de lanzamiento para criollo haitiano, inglés pidgin nigeriano e inglés coloquial de Singapur. Evaluamos estos modelos en tareas intrínsecas y extrínsecas. Motivados por la literatura anterior, comparamos los modelos lingüísticos estándar con los robustos distribucionalmente y descubrimos que, sorprendentemente, los modelos lingüísticos estándar son superiores a los robustos distribucionalmente. Investigamos si esto es un efecto de sobreparametrización o estabilidad distribucional relativa, y encontramos que la diferencia persiste en ausencia de sobreparametrización, y que la deriva es limitada, lo que confirma la estabilidad relativa de las lenguas criollas.', 'ar': 'اللغات الكريولية مثل النيجيرية بيجين الإنجليزية والكريولية الهايتية تعاني من نقص الموارد ويتم تجاهلها إلى حد كبير في أدبيات البرمجة اللغوية العصبية. عادة ما تنتج الكريول من اندماج لغة أجنبية مع لغات محلية متعددة ، وما هي السمات النحوية والمعجمية التي يتم نقلها إلى الكريول هي عملية معقدة. في حين أن الكريول مستقرة بشكل عام ، فإن بروز بعض الميزات قد يكون أقوى بكثير مع بعض التركيبة السكانية أو في بعض المواقف اللغوية. تقدم هذه الورقة العديد من المساهمات: نقوم بجمع النماذج الحالية ونماذج الإصدار للكريولية الهايتية واللغة الإنجليزية النيجيرية Pidgin واللغة الإنجليزية العامية السنغافورية. نقوم بتقييم هذه النماذج على المهام الجوهرية والخارجية. بدافع من الأدبيات المذكورة أعلاه ، نقارن نماذج اللغة القياسية بالنماذج القوية التوزيعية ووجدنا ، بشكل مفاجئ إلى حد ما ، أن نماذج اللغة القياسية تتفوق على النماذج القوية التوزيعية. نحن نتحرى ما إذا كان هذا تأثيرًا للمعلمات المفرطة أو استقرار التوزيع النسبي ، ووجدنا أن الاختلاف يستمر في حالة عدم وجود معاملات مفرطة ، وأن الانجراف محدود ، مما يؤكد الاستقرار النسبي للغات الكريول.', 'fr': "Les langues créoles telles que l'anglais pidgin nigérian et le créole haïtien manquent de ressources et sont largement ignorées dans la littérature sur la PNL. Les créoles résultent généralement de la fusion d'une langue étrangère avec plusieurs langues locales, et les caractéristiques grammaticales et lexicales transférées au créole sont un processus complexe. Bien que les créoles soient généralement stables, la prééminence de certaines caractéristiques peut être beaucoup plus forte avec certains groupes démographiques ou dans certaines situations linguistiques. Cet article apporte plusieurs contributions\xa0: Nous recueillons des corpus existants et des modèles de publication pour le créole haïtien, l'anglais pidgin nigérian et l'anglais familier singapourien. Nous évaluons ces modèles sur des tâches intrinsèques et extrinsèques. Motivés par la littérature ci-dessus, nous comparons les modèles linguistiques standard avec des modèles robustes sur le plan de la distribution et constatons que, de manière quelque peu surprenante, les modèles linguistiques standard sont supérieurs aux modèles robustes sur le plan de la distribution. Nous cherchons à savoir s'il s'agit d'un effet de sur-paramétrisation ou de stabilité relative de la distribution, et nous avons constaté que la différence persiste en l'absence de sur-paramétrisation, et que la dérive est limitée, ce qui confirme la stabilité relative des langues créoles.", 'ja': 'ナイジェリアのピジン英語やハイチのクレオール語などのクレオール語は資源が不足しており、NLPの文献ではほとんど無視されている。 クレオール語は通常、外国語と複数の現地言語の融合から生じるものであり、どのような文法的および語彙的特徴がクレオール語に伝達されるかは複雑なプロセスである。 クレオールは一般的に安定しているが、特定の人口統計学的状況または言語的状況では、いくつかの特徴の顕著さがはるかに強くなる可能性がある。 本稿では、ハイチのクレオール語、ナイジェリアのピジン英語、シンガポールのコロシアム英語の既存のコーラとリリースモデルを収集します。 私たちは、これらのモデルを内在的および外在的なタスクで評価します。 上記の文献に動機づけられているように、標準言語モデルを分布的に堅牢なものと比較すると、ある程度驚くべきことに、標準言語モデルは分布的に堅牢なものよりも優れていることがわかる。 これが過パラメータ化の効果なのか相対的な分布安定性なのかを調査したところ、過パラメータ化がない状態では差異が続き、ドリフトが制限されていることがわかり、クレオール言語の相対的な安定性が確認された。', 'zh': '克里奥尔语,如尼日利亚皮钦英语、海地克里奥尔语,资源不足,其被忽视于NLP文献如此。 克里奥尔语常以一门外语与多方语言相得,何语法与词汇特徵移克里奥尔语复杂也。 虽克里奥尔语常定,而人口统计数据语,其特出者或会强或多。 本文:收海地克里奥尔语,尼日利亚皮钦英语、新加坡口语英语见语料库、发模形。 我们在内和外在事务上评料这些模样。 凡此诸文,与分布鲁棒相较,或可讶者,或可 臣等考其是非参数化与分稳定性,未见参数化,差犹存,而漂移有限,证克里奥尔语之稳定性。', 'ru': 'Креольские языки, такие как нигерийский пиджинский английский и гаитянский креольский, не обеспечены достаточными ресурсами и в значительной степени игнорируются в литературе НЛП. Креолы, как правило, являются результатом слияния иностранного языка с несколькими местными языками, и то, какие грамматические и лексические особенности передаются креольскому языку, является сложным процессом. В то время как креолы, как правило, стабильны, заметность некоторых особенностей может быть гораздо сильнее с определенной демографией или в некоторых языковых ситуациях. Мы собираем существующие корпорации и выпускаем модели для гаитянского креольского, нигерийского пиджинского английского и сингапурского разговорного английского. Мы оцениваем эти модели по внутренним и внешним задачам. Основываясь на приведенной выше литературе, мы сравниваем стандартные языковые модели с дистрибутивно устойчивыми и обнаруживаем, что, что несколько удивительно, стандартные языковые модели превосходят дистрибутивно устойчивые. Мы исследуем, является ли это эффектом чрезмерной параметризации или относительной стабильности распределения, и обнаруживаем, что разница сохраняется в отсутствие чрезмерной параметризации, и что дрейф ограничен, подтверждая относительную стабильность креольских языков.', 'hi': 'नाइजीरियाई पिजिन अंग्रेजी और हाईटियन क्रियोल जैसी क्रियोल भाषाओं को कम संसाधन दिया जाता है और एनएलपी साहित्य में काफी हद तक अनदेखा किया जाता है। क्रियोल्स आमतौर पर कई स्थानीय भाषाओं के साथ एक विदेशी भाषा के संलयन के परिणामस्वरूप होते हैं, और क्या व्याकरणिक और लेक्सिकल विशेषताओं को क्रियोल में स्थानांतरित किया जाता है, यह एक जटिल प्रक्रिया है। जबकि क्रियोल आम तौर पर स्थिर होते हैं, कुछ विशेषताओं की प्रमुखता कुछ जनसांख्यिकी के साथ या कुछ भाषाई स्थितियों में बहुत मजबूत हो सकती है। यह पेपर कई योगदान देता है: हम मौजूदा कॉर्पोरेट एकत्र करते हैं और हाईटियन क्रियोल, नाइजीरियाई पिजिन अंग्रेजी और सिंगापुरके बोलचाल की अंग्रेजी के लिए मॉडल जारी करते हैं। हम आंतरिक और बाह्य कार्यों पर इन मॉडलों का मूल्यांकन करते हैं। उपर्युक्त साहित्य से प्रेरित होकर, हम वितरण रूप से मजबूत लोगों के साथ मानक भाषा मॉडल की तुलना करते हैं और पाते हैं कि, कुछ हद तक आश्चर्यजनक रूप से, मानक भाषा मॉडल वितरण रूप से मजबूत लोगों से बेहतर हैं। हम जांच करते हैं कि क्या यह ओवर-पैरामीटराइजेशन या सापेक्ष वितरण स्थिरता का प्रभाव है, और पाते हैं कि अंतर ओवर-पैरामीटराइजेशन की अनुपस्थिति में बना रहता है, और यह बहाव सीमित है, जो क्रियोल भाषाओं की सापेक्ष स्थिरता की पुष्टि करता है।', 'pt': 'Línguas crioulas, como o inglês pidgin nigeriano e o crioulo haitiano, têm poucos recursos e são amplamente ignorados na literatura de PNL. Os crioulos normalmente resultam da fusão de uma língua estrangeira com vários idiomas locais, e quais recursos gramaticais e lexicais são transferidos para o crioulo é um processo complexo. Embora os crioulos sejam geralmente estáveis, a proeminência de algumas características pode ser muito mais forte com certos dados demográficos ou em algumas situações linguísticas. Este artigo traz várias contribuições: Coletamos corpora e modelos de lançamento existentes para o crioulo haitiano, o inglês pidgin nigeriano e o inglês coloquial de Cingapura. Avaliamos esses modelos em tarefas intrínsecas e extrínsecas. Motivados pela literatura acima, comparamos modelos de linguagem padrão com os robustos de distribuição e descobrimos que, surpreendentemente, os modelos de linguagem padrão são superiores aos robustos de distribuição. Investigamos se isso é um efeito de sobreparametrização ou estabilidade distributiva relativa, e descobrimos que a diferença persiste na ausência de sobreparametrização e que a deriva é limitada, confirmando a relativa estabilidade das línguas crioulas.', 'ga': 'Níl mórán acmhainní ar fáil do theangacha crióla ar nós Béarla Pidgin na Nigéire agus Creole Haitian agus déantar neamhaird den chuid is mó orthu i litríocht an NLP. Is gnách go n-eascraíonn crióla as teanga iasachta a chomhnascadh le teangacha iolracha áitiúla, agus is próiseas casta é na gnéithe gramadaí agus foclóireachta a aistrítear go dtí an criól. Cé go mbíonn creoles cobhsaí go ginearálta, d’fhéadfadh feiceálacht gnéithe áirithe a bheith i bhfad níos láidre i gcás déimeagrafaic áirithe nó i gcásanna áirithe teanga. Déanann an páipéar seo roinnt ranníocaíochtaí: Bailímid samhlacha corpora agus eisithe atá ann cheana féin le haghaidh Haitian Creole, Nigerian Pidgin English, agus Singaporean Colloquial English. Déanaimid na samhlacha seo a mheas ar thascanna intreacha agus eistreacha. Spreagtha ag an litríocht thuas, déanaimid comparáid idir múnlaí caighdeánacha teanga agus múnlaí atá láidir ó thaobh dáiliúcháin de agus is ábhar iontais é gur fearr na múnlaí caighdeánacha teanga ná na cinn atá láidir ó thaobh dáiliúcháin de. Fiosraíonn muid cibé acu an bhfuil sé seo ina éifeacht ró-pharaiméadair nó cobhsaíocht choibhneasta dáileacháin, agus aimsímid go bhfuil an difríocht fós ann in éagmais an ró-pharaiméadair, agus go bhfuil an t-aistriú teoranta, rud a dheimhníonn cobhsaíocht choibhneasta na dteangacha creola.', 'el': 'Οι κρεολικές γλώσσες όπως τα Νιγηριανά Αγγλικά και τα Αϊτινικά Κρεολικά δεν διαθέτουν πόρους και αγνοούνται σε μεγάλο βαθμό στη λογοτεχνία του NLP. Οι κρεόλες συνήθως προκύπτουν από τη συγχώνευση μιας ξένης γλώσσας με πολλές τοπικές γλώσσες, και τα γραμματικά και λεξικά χαρακτηριστικά που μεταφέρονται στην κρεόλα είναι μια πολύπλοκη διαδικασία. Ενώ οι κρεόλες είναι γενικά σταθερές, η προβολή ορισμένων χαρακτηριστικών μπορεί να είναι πολύ ισχυρότερη σε ορισμένα δημογραφικά στοιχεία ή σε ορισμένες γλωσσικές καταστάσεις. Αυτή η εργασία κάνει διάφορες συνεισφορές: Συλλέγουμε υπάρχοντα σώματα και κυκλοφορούμε μοντέλα για τα Αϊτινικά Κρεολικά, τα Νιγηριανά Αγγλικά Πίdgin και τα Συνολικά Αγγλικά της Σιγκαπούρης. Αξιολογούμε αυτά τα μοντέλα σε εγγενείς και εξωτερικές εργασίες. Με κίνητρο από την παραπάνω βιβλιογραφία, συγκρίνουμε τυποποιημένα γλωσσικά μοντέλα με διανεμητικά ισχυρά μοντέλα και διαπιστώνουμε ότι, κάπως έκπληξη, τα τυποποιημένα γλωσσικά μοντέλα είναι ανώτερα από τα διανεμητικά ισχυρά. Ερευνούμε αν αυτό είναι αποτέλεσμα υπερπαραμετροποίησης ή σχετικής σταθερότητας κατανομής, και διαπιστώνουμε ότι η διαφορά παραμένει ελλείψει υπερπαραμετροποίησης, και ότι η μετατόπιση είναι περιορισμένη, επιβεβαιώνοντας τη σχετική σταθερότητα των κρεολικών γλωσσών.', 'ka': 'კრიოლური ენები, როგორც ნეზიერია პიდინ ანგლისური და ჰაიტიანი კრიოლური უფრო რესურსურებულია და უფრო მეტად ინგორიურებულია NLP ლიტერტურაში. კრელეები განსხვავებული ენის ფუზიდან მრავალ ლოკალური ენათებით და რაც გრამიმატური და ლექსიკალური ფუნქციები კრეოლაში გადატანა არის კომპლექსიკური პროცესი. თუმცა კრელეები უბრალოდ სტაბულია, რამდენიმე განსაზღვრებების მნიშვნელობა შეიძლება იყოს უფრო ძალიან განსაზღვრებული დემოგრაფიკაში ან რამდენიმე ლენგურის ეს დოკუმენტი აქვს რამდენიმე მონაცემები: ჩვენ კომპორაციას შევყვანეთ და გახსნა მოდელები ჰაიტიანი კრიოლისთვის, ნიზიერია ოთეჯინი ანგლისთვის და სინდაპურ ჩვენ ეს მოდელები ინტერენტიური და ექსტრინტიური დავალების შესახებ გავუმუშავებთ. ჩვენ მოტივირდებით მეტი ლიტებერტიაზე, ჩვენ სტანდარტული ენის მოდელების გადასრულებას გადასრულებულად ძალიან და ვიცით, რომ სტანდარტურად ენის მოდელები უფრო ძალიან გადასრულებული ენის მოდელები. ჩვენ განსხვავებთ თუ ეს ძალიან პარამეტრიზაციის ეფექტია ან რედაციალური პარამეტრიზაციის სტაბილური სტაბილურობის ეფექტია და დავიწყებთ, რომ განსხვავება უფრო მეტი პარამეტრიზაციის არსებობაში იქნებ', 'hu': 'A kreol nyelvek, mint például a nigériai pidgin angol és a haiti kreol nem rendelkeznek forrásokkal, és nagyrészt figyelmen kívül hagyják az NLP irodalmában. A kreolék jellemzően az idegen nyelv több helyi nyelvvel való összeolvadásából erednek, és hogy milyen nyelvtani és lexikai jellemzők kerülnek át a kreolba, komplex folyamat. Míg a kreol általában stabil, bizonyos jellemzők kiemelkedősége sokkal erősebb lehet bizonyos demográfiai vagy nyelvi helyzetekben. Ez a tanulmány több hozzájárulást tesz: Összegyűjtjük a meglévő corporákat és kiadási modelleket haiti kreol, nigériai pidgin angol és szingapúri kollokviál angol nyelvre. Ezeket a modelleket belső és külső feladatokra értékeljük. A fenti szakirodalom motiválására összehasonlítjuk a standard nyelvi modelleket a disztribúciós szempontból robusztus modellekkel, és meglepően úgy találjuk, hogy a standard nyelvi modellek jobb, mint a disztribúciós szempontból robusztus modellek. Vizsgáljuk, hogy ez a túlparaméterizáció vagy relatív eloszlási stabilitás hatása, és megállapítjuk, hogy a különbség túlparaméterizáció hiányában is fennáll, és hogy a sodródás korlátozott, megerősítve a kreol nyelvek relatív stabilitását.', 'it': "Le lingue creole come l'inglese pidgin nigeriano e il creolo haitiano sono scarse di risorse e ampiamente ignorate nella letteratura NLP. I creoli derivano tipicamente dalla fusione di una lingua straniera con più lingue locali, e quali caratteristiche grammaticali e lessicali vengono trasferite al creolo è un processo complesso. Mentre i creoli sono generalmente stabili, la prominenza di alcune caratteristiche può essere molto più forte con determinate demografie o in alcune situazioni linguistiche. Questo articolo fornisce diversi contributi: Raccogliamo corpora esistenti e rilasciamo modelli per Haitian Creole, Nigerian Pidgin English e Singaporean Colloquial English. Valutiamo questi modelli su compiti intrinseci ed estrinseci. Motivati dalla letteratura di cui sopra, confrontiamo modelli linguistici standard con quelli distributivamente robusti e scopriamo che, sorprendentemente, i modelli linguistici standard sono superiori a quelli distributivamente robusti. Investighiamo se questo sia un effetto di sovraparametrizzazione o relativa stabilità distributiva, e scopriamo che la differenza persiste in assenza di sovraparametrizzazione, e che la deriva è limitata, confermando la relativa stabilità dei linguaggi creoli.", 'lt': 'Kriolių kalbos, pvz., Nigerijos kiaulių anglų ir Haičio kriolių kalbos, yra nepakankamai išteklių ir iš esmės ignoruojamos NLP literatūroje. Kreoliai paprastai atsiranda dėl užsienio kalbos susijungimo su įvairiomis vietinėmis kalbomis, o gramatinės ir leksikinės savybės perkeliamos į kreolius yra sudėtingas procesas. While creoles are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations.  Šiame dokumente pateikiama keletas įnašų: mes renkame esamus korporaus ir paleidimo modelius Haitian Creole, Nigerian Pidgin anglų ir Singapūro kolegijų anglų. Šiuos modelius vertiname atliekant vidines ir išorines užduotis. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones.  Ištiriame, ar tai yra per didelio parametrizavimo ar santykinio paskirstymo stabilumo poveikis, ir nustatome, kad skirtumas išlieka, jei nėra per didelio parametrizavimo, ir kad trūkumas yra ribotas, patvirtinant santykinį kreolių kalbų stabilumą.', 'mk': 'Крилските јазици како што се нигерискиот Пиджин англиски и хаитански Крил се недостасувани и во голема мера игнорирани во литературата на НЛП. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the creole is a complex process.  Иако кролите се генерално стабилни, истакнувањето на некои карактеристики може да биде многу посилно со одредени демографии или во некои лингвистички ситуации. Овој документ дава неколку придонеси: собираме постоечки корпора и ослободуваме модели за Хаитанскиот Крил, Нигерискиот Пидџин англиски и Сингапурскиот колокуален англиски. Ги проценуваме овие модели на внатрешни и надворешни задачи. Мотивирани од наведената литература, ги споредуваме стандардните јазички модели со дистрибуционално силни и откриваме дека, некако изненадувачки, стандардните јазички модели се супериорни од дистрибуционално силните. Истражуваме дали ова е ефект на прекумерна параметризација или релативна дистрибуционална стабилност, и откриваме дека разликата трае во отсуството на прекумерна параметризација, и дека движењето е ограничено, потврдувајќи ја релативната стабилност на јазиците од креол.', 'mt': 'Il-lingwi tal-kreol bħan-Nigerian Pidgin Ingliż u l-Haitian Creole huma sottoriżorsi u fil-biċċa l-kbira tagħhom injorati fil-letteratura tal-NLP. Il-kreoli tipikament jirriżultaw mill-fużjoni ta’ lingwa barranija b’diversi lingwi lokali, u liema karatteristiċi grammatiċi u lexiċi jiġu trasferiti lill-kreol huwa proċess kumpless. Filwaqt li l-kreoli huma ġeneralment stabbli, il-prominenza ta’ xi karatteristiċi tista’ tkun ħafna aktar b’ċerta demografija jew f’xi sitwazzjonijiet lingwistiċi. Dan id-dokument jagħmel diversi kontributi: Aħna nġabru l-mudelli eżistenti tal-korpura u r-rilaxx għall-Haitian Creole, il-Pidgin tan-Niġerja bl-Ingliż, u l-Colloquial English Singapore. Nivvalutaw dawn il-mudelli fuq kompiti intrinsiċi u esterni. Motivat mil-letteratura ta’ hawn fuq, aħna nqabblu mudelli lingwistiċi standard ma’ dawk distribuzzjonalment b’saħħithom u nsibu li, b’mod xi ħaġa sorprendenti, il-mudelli lingwistiċi standard huma superjuri għal dawk distribuzzjonalment b’saħħithom. Aħna ninvestigaw jekk dan huwiex effett ta’ parametrizzazzjoni żejda jew stabbiltà relattiva tad-distribuzzjoni, u nsibu li d-differenza tippersisti fin-nuqqas ta’ parametrizzazzjoni żejda, u dik id-devjazzjoni hija limitata, u tikkonferma l-istabbiltà relattiva tal-lingwi tal-kreol.', 'ml': 'നൈജീരിയന്\u200d പിഡ്ജിന്\u200d ഇംഗ്ലീഷും ഹൈത്യാന്\u200d ക്രീയോലും പോലുള്ള ക്രീയോല്\u200d ഭാഷകള്\u200d NLP സാഹിത്യത്തില്\u200d ഉപേക്ഷിക്കുന്നു. പല ലോക്കല്\u200d ഭാഷകളുള്ള വിദേശ ഭാഷയുടെ ഫ്യൂഷനില്\u200d നിന്നും ക്രീയോളിലേക്കും മാറ്റുന്നത് സാധാരണമായി ഒരു വിദേശ ഭാഷയില്\u200d നിന്നും ഫലമാണ്. ക്ര ക്രീയുകള്\u200d സാധാരണമായി സ്ഥിരമായിരിക്കുമ്പോള്\u200d, ചില പ്രത്യേകങ്ങളുടെ പ്രധാനപ്പെട്ടത് ചില ഡെമോഗ്രോഫിക്കുകളുടെയോ ചില This paper makes several contributions: We collect existing corpora and release models for Haitian Creole, Nigerian Pidgin English, and Singaporean Colloquial English.  നമ്മള്\u200d ഈ മോഡലുകളെ വിലാസപ്പെടുത്തുന്നുണ്ട്. മുകളിലുള്ള സാഹിത്രത്തില്\u200d നിന്നും മുകളില്\u200d നിന്നും നാം സാധാരണ ഭാഷയുടെ മോഡലുകളെ വിഭാഗിക്കപ്പെടുത്തിക്കൊണ്ട് സമര്\u200dപ്പിക്കുന്നു. അതിശയം  ഇത് പരാമീറ്ററേഷന്\u200d അല്ലെങ്കില്\u200d അടുത്ത സ്ഥിരമായ വിതരണ സ്ഥിരമാണോ എന്ന് നമ്മള്\u200d അന്വേഷിക്കുന്നു. വ്യത്യാസവും അധികമായ പരാമീറ്ററേഷനില്\u200d ഇല്ലാതെ നിലനില്\u200dക്', 'ms': 'Bahasa Creole seperti Nigerian Pidgin Inggeris dan Haitian Creole tidak mempunyai banyak sumber dan kebanyakan diabaikan dalam literatur NLP. Creoles biasanya berasal dari fusion bahasa asing dengan berbagai bahasa setempat, dan apa ciri-ciri grammatik dan leksikal dipindahkan ke creole adalah proses kompleks. Sementara kreol secara umum stabil, kelebihan beberapa ciri-ciri mungkin lebih kuat dengan demografi tertentu atau dalam beberapa situasi bahasa. Kertas ini membuat beberapa kontribusi: Kami mengumpulkan corpora yang ada dan model pembebasan untuk Haitian Creole, Nigeria Pidgin English, dan Singapore Colloquial English. Kami menilai model ini pada tugas dalaman dan luar. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones.  Kami menyelidiki sama ada ini adalah kesan dari parameterisasi berlebihan atau stabiliti distribusi relatif, dan mendapati bahawa perbezaan tetap dalam ketidakadaan parameterisasi berlebihan, dan arahan tersebut adalah terbatas, mengesahkan stabiliti relatif bahasa creole.', 'mn': 'Нигерийн Пиджин Англи болон Гаитын Криол зэрэг цөмийн хэлнүүд NLP уран зохиолд ихэнхдээ хамааралтай байдаг. Хүмүүс олон орон нутгийн хэлд гадаад хэлний нэгтгэлээс үр дүнтэй. Грамматик болон лексикийн чадварыг кроул руу шилжүүлэх нь төвөгтэй процесс юм. Хэдийгээр хүмүүс ерөнхийдөө тогтмол байдаг ч зарим зүйлсийн чухал нь зарим демографик эсвэл зарим хэлний нөхцөлд илүү хүчтэй байж болно. Энэ цаас хэд хэдэн нөлөөлөх бөгөөд бид Гаитын Криол, Нигерийн Пиджин Англи, Сингапурын Колокуиалын Англи хэлний үеийн загварыг цуглуулдаг. Бид эдгээр загваруудыг дотроо болон гадна ажил дээр үнэлдэг. Эрх уран зохиолын хөдөлгөөндөө бид стандарт хэл загваруудыг хуваарилсан хүчтэй харьцуулж, нэг гайхалтай зүйл бол стандарт хэл загварууд хуваарилсан хүчтэй хүмүүсээс илүү их байдаг. Бид үүнийг хэт их параметрийн эсвэл харьцангуй хуваарилалтын тогтвортой нөлөөлдөг эсэхийг судалж, ялгаа нь хэт их параметрийн байдлын байдлын тулд үргэлжлүүлдэг эсэхийг олж мэднэ.', 'pl': 'Języki kreolskie takie jak nigeryjski angielski Pidgin i haitański kreolski są niedostatecznie zasobów i w dużej mierze ignorowane w literaturze NLP. Kreole zazwyczaj wynikają z połączenia języka obcego z wieloma lokalnymi językami, a to, jakie cechy gramatyczne i leksykalne są przenoszone na kreol, jest procesem złożonym. Chociaż kreole są ogólnie stabilne, znaczenie niektórych cech może być znacznie silniejsze w niektórych sytuacjach demograficznych lub w niektórych sytuacjach językowych. Niniejszy artykuł wnosi kilka wkładów: zbieramy istniejące korpory i modele wydawnicze dla haitańskiego kreolskiego, nigerianskiego pidgina angielskiego i singapurskiego potocznego angielskiego. Oceniamy te modele na zadaniach wewnętrznych i zewnętrznych. Motywowani powyższą literaturą porównujemy standardowe modele językowe z solidnymi dystrybucyjnie i stwierdzamy, że standardowe modele językowe są lepsze od solidnych dystrybucyjnie. Badamy, czy jest to efekt nadparametryzacji czy względnej stabilności dystrybucji, i stwierdzamy, że różnica utrzymuje się przy braku nadparametryzacji, a dryf jest ograniczony, potwierdzając względną stabilność języków kreolskich.', 'no': 'Creole-språk som Nigerian Pidgin English og Haitian Creole er underressursert og stort ignorert i NLP-literaturen. Kreoler generelt resulterer frå fusjonen av eit eksternt språk med fleire lokale språk, og kva grammatiske og leksiske funksjonar vert overført til krølen er ein kompleks prosess. Mens kreoler er vanlegvis stabile, kan det være mykje sterkere for nokre funksjonar med nokre demografikk eller i nokre lingviske situasjonar. Denne papiret gjer fleire bidrag: Vi samler eksisterande korporasjonar og slepp modeller for Haitian Creole, Nigerian Pidgin English og Singaporean Colloquial English. Vi evaluerer desse modelane på interne og ekstrinske oppgåver. Forskyvde av den øvste literaturen, sammenlignar vi standardmodellen med distribusjonell robust og finn at standardmodellen for språk er vanskeleg enn distribusjonell robust. Vi undersøker om dette er eit effekt av overparameterisering eller relativt distribusjonsstabilitet, og finn at forskjellen persisterer i absence av overparameterisering, og at drift er begrenset, stadfesting relativt stabilitet av krølspråk.', 'kk': 'Нигерия пиджин ағылшын және Гаития криолы секілді криолық тілдері NLP литературасында көпшілікті қалмайды. Бірнеше жергілікті тілдермен ағылшын тілдерді бірнеше тілдерді біріктіруге болады, және грамматикалық және лексикалық қасиеттері кроулға тасымалдау - комплекс процес. Кролелер кәдімгі дұрыс болғанда, кейбір мүмкіндіктердің көбірек демографиялық немесе кейбір лингвистикалық жағдайда көбірек болуы мүмкін. Бұл қағаз бірнеше көмектесу жасайды: Біз бар корпора және Гаитандық криол, Нигерия пиджин ағылшын және сингапуралық колокуалдық ағылшын тілінде үлгілерді жинап береміз. Біз бұл үлгілерді ішкі және сыртқы тапсырмалардан бағалаймыз. Жоғардағы әдебиеттің көшірмесі бойынша, біз стандартты тіл үлгілерін тарату үшін үлкен үлгілерімен салыстырып, бірақ бірнеше қызықты түрде стандартты тіл үлгілері тарату үлгілерінен артық. Біз бұл параметрлердің көп нәтижесі немесе сәйкес дистрибуттық стабилдығын зерттейміз. Бұл параметрлердің көп параметрлердің жоқ болғанда айырмашылығы сол жағдайда тұрады. Бұл көп параметрлердің шектелген', 'si': 'නායිජිරියානු පිඩ්ජින් ඉංග්\u200dරීසි සහ හැයිටියාන් ක්\u200dරීයෝල් වගේ ක්\u200dරීයෝල් භාෂාවල් අඩු සම්පූර්ණය සාමාන්\u200dයයෙන් විදේශ භාෂාවක් ගොඩක් ස්ථානික භාෂාවක් තියෙන විදේශ භාෂාවක් සම්බන්ධයෙන් ප්\u200dරතිචාර විදිය සාමාන්\u200dයයෙන්ම ස්ථිර වෙලා තියෙනවා නමුත්, සමහර විශේෂතාවන්ගේ ප්\u200dරධානය සමහර විශේෂතාවන් සමහර විශේෂතාවන මේ පත්තුවෙන් විශේෂ සම්පූර්ණයක් තියෙනවා: අපි තියෙන්නේ කොර්පෝරා සහ හායිටියන් ක්\u200dරීයෝල්, නිජිරියාන් පිඩ්ජි අපි මේ මෝඩේල්ස් විශ්වාස කරනවා ඇතුළු හා ප්\u200dරධාන වැඩේ ගැන. උපරිම සාක්ෂිකාරයෙන් හිටියා, අපි ප්\u200dරමාණ භාෂා මොඩේල්ස් එක්ක ප්\u200dරමාණික භාෂාව ප්\u200dරමාණය කරනවා වගේම ප්\u200dරමාණික භාෂාව ප්\u200dරම අපි පරීක්ෂා කරනවා මේක ප්\u200dරමාණයක් නැත්නම් ප්\u200dරමාණයක් නැත්නම් සම්බන්ධ ප්\u200dරමාණයක් නැත්නම් නැත්නම් හොයාගන්න, ඒ වගේම ප්\u200dරමාණයක් ප්\u200dරමාණයක', 'sr': 'Kriolički jezici poput Nigerije Pidgin engleskog i Haitskog kreola su pod resursom i uglavnom ignorirani u literaturi NLP. Kreoli obièno rezultuju iz kombinacije stranog jezika sa višestrukim lokalnim jezicima, a ono što se gramatičke i leksičke karakteristike prebacuju u kreolu je kompleksan proces. Iako su krele uglavnom stabilne, velikost nekih karakteristika može biti mnogo jača sa određenim demografijama ili u nekim jezičkim situacijama. Ovaj papir donosi nekoliko doprinosa: skupljamo postojeće korporacije i oslobodimo modele za Haitski kreol, nigerijski pidžin engleski i Singapurski kolokijalni engleski jezik. Procjenjujemo te modele na unutrašnjim i ekstrinsickim zadatkima. Motivirani od iznad literature, uspoređujemo standardne jezičke modele sa distribucionalno robotima i saznamo da su standardni jezički modeli iznenađujuće od distribucionalno robotih. Istražujemo da li je to efekat preko parameterizacije ili relativne distribucijske stabilnosti, i saznamo da razlika nastavlja u odsustvu preko parameterizacije i da je vožnja ograničena, potvrđujući relativnu stabilnost jezika kreola.', 'ro': 'Limbile creole precum engleza pidgin nigeriană și creola haitiană sunt insuficiente resurse și ignorate în mare parte în literatura PNL. Creolele rezultă de obicei din fuziunea unei limbi străine cu mai multe limbi locale, iar caracteristicile gramaticale și lexicale sunt transferate în creol este un proces complex. În timp ce creolele sunt în general stabile, proeminența unor caracteristici poate fi mult mai puternică în anumite situații demografice sau în unele situații lingvistice. Această lucrare face mai multe contribuții: Colectăm corpore existente și lansăm modele pentru creol haitian, engleză nigeriană Pidgin și engleză colocvială singaporeană. Evaluăm aceste modele pe sarcini intrinsece și extrinsice. Motivați de literatura de mai sus, comparăm modelele lingvistice standard cu cele robuste din punct de vedere distribuțional și constatăm că, oarecum surprinzător, modelele lingvistice standard sunt superioare celor robuste din punct de vedere distribuțional. Investigăm dacă acesta este un efect al supra-parametrizării sau al stabilității distribuționale relative și constatăm că diferența persistă în absența supra-parametrizării, iar această derivă este limitată, confirmând stabilitatea relativă a limbilor creole.', 'so': "Luqadaha Creole, sida Nigerian Pidgin Ingiriis iyo Haitian Creole waa hoos-resourceed oo si badan looga jeedo qoraalka NLP. Sida caadiga ah luqada ajnabiga ah waxaa laga soo jeedaa fududeynta luqado kala duduwan, waxaana lagu wareejiyaa takhasuska iyo waxyaabaha leksikalka ah oo lagu soo wareejiyo darafka. Inta lagu caadi karo dabeecadaha qaarkood waxaa laga yaabaa inay aad ugu xoog badnaan karaan dad cayiman ama xaaladaha luuqadaha qaarkood. Warqaddan waxey leedahay qeybo badan: Waxaynu soo urursannaa shirkadaha joogta ah iyo tusaalooyin lagu soo daayo Haitian Creole, Nigerian Pidgin Ingiriis, iyo Shigaporiya Colloquial Ingiriis. Tusaaladan waxaan ku qiimeynaynaa shaqada gudaha iyo dibadda. Taariikhda sare waxaan isbarbardhignaa noocyada afka caadiga ah oo kala duduwan, waxaynu aragnaa inay si yaab leh noocyada luqada caadiga ah ka sarreeyaan kuwa lagu kala qaybiyey. Waxaynu baaraynaa inay tahay saameyn ku saabsan faa'iido kala duduwan ama ay tahay mid ka mid ah, waxaynu ogaanaynaa in kala duwanaanshaha ay ku sii jiraan iyagoo aan la arkin faa'iido kala duduwan, qalabkaasuna waa xadidan, si aad u xaqiijineyso sugnaanshaha ku saabsan luqada.", 'sv': 'Kreolspråk som nigerianska pidgin engelska och haitiska kreolspråk är underresurser och till stor del ignoreras i NLP-litteraturen. Kreoler är vanligtvis resultatet av fusionen av ett främmande språk med flera lokala språk, och vilka grammatiska och lexikala egenskaper som överförs till kreolen är en komplex process. Även om kreoler generellt sett är stabila, kan framväxten av vissa funktioner vara mycket starkare med viss demografi eller i vissa språkliga situationer. Denna uppsats ger flera bidrag: Vi samlar in befintliga korpora och släpper modeller för haitisk kreol, nigeriansk pidgin engelska och singaporiansk kolloquial engelska. Vi utvärderar dessa modeller på inre och yttre uppgifter. Mot bakgrund av ovanstående litteratur jämför vi standardspråkmodeller med distributionsmässigt robusta och finner att standardspråkmodellerna, något överraskande, är överlägsna än de distributionsmässigt robusta. Vi undersöker om detta är en effekt av överparametrisering eller relativ distributionsstabilitet, och finner att skillnaden kvarstår i frånvaro av överparametrisering, och att driften är begränsad, vilket bekräftar den relativa stabiliteten hos kreolspråk.', 'ta': 'Name கிரீயல்கள் வழக்கமாக பல உள்ளூர் மொழிகளுடன் வெளியேற்றத்திலிருந்து வெளியேற்றத்திலிருந்து வெளியேற்றத்தின் முடிவு முடிவு, மற்றும்  கிரீல்கள் பொதுவாக stable இருக்கும் போது, சில குணங்களின் கண்ணியம் சில மக்கள் அல்லது சில மொழிகளில் அதிகமாக இருக்கலாம். இந்த தாள் பல பணிகள் செய்கிறது: நாம் இருக்கும் நிறுவனத்தை சேகரிக்கிறோம் மற்றும் ஹைடியான கிரீயோல், நைஜீரிய பிட்ஜின் ஆங்கிலம், சி நாம் இந்த மாதிரிகளை மதிப்பிடுகிறோம் உள்ளடக்கம் மற்றும் வெளியேற்றும் பணிகளில். மேல் எழுத்தாக்கத்தால் இயக்கப்பட்டது, நாம் நிலையான மொழி மாதிரிகளை பங்கீட்டு முறையில் ஒப்பிடுகிறோம் மற்றும் ஆச்சரியமாக, நிலையான மொழ அதிக அளபுருவின் விளைவு அல்லது சார்ந்த பங்கீட்டு நிலையில் உள்ளதா என்பதை நாம் சோதிக்க வேண்டும். மேலும் அளபுருவின் இல்லாத வித்தியாசம் தான் இருக்கி', 'ur': 'نیجریکا پیڈجین انگلیسی اور ہیتین کروئل کی زبانیں کم سازی ہیں اور زیادہ سے NLP ادبیات میں غفلت کی جاتی ہیں. غریب زبان کی جگہ سے بہت سی محلی زبانوں کے مطابق پیدا ہوتی ہے، اور جو گراماتیک اور لکسیکل ویژگی ویژگی کروئل کی طرف منتقل کئے جاتے ہیں ایک پیچیدہ پرسس ہے. اگرچہ کلوئل معمولاً ثابت ہیں، بعض شخصیتیں کا اظہار بہت زیادہ قوی ہو سکتا ہے کہ بعض جمعیت یا بعض زبان کی موقعیت میں۔ یہ کاغذ بہت سی مشترک ہے: ہم موجود کورپورا کو جمع کرتے ہیں اور ہیتین کروئل، نیجرین پیڈجین انگلیسی اور سینگپورین کالکوکیل انگلیسی کے لئے موڈل آزاد کرتے ہیں۔ ہم ان موڈلوں کو داخلی اور خارجی کاموں پر ارزش دیتے ہیں۔ اوپر لکھائی کے ذریعہ حرکت کی جاتی ہے، ہم استاندارڈ لکھائی موڈل کو تقسیم کے طور پر ثابت قدم رکھتے ہیں اور دیکھتے ہیں کہ، کچھ عجیب بات ہے، استاندارڈ لکھائی موڈل تقسیم کے طور پر زیادہ طاقتور ہیں. ہم تحقیق کرتے ہیں کہ یہ زیادہ پارامتریزی یا نسبتی تقسیم کی ثابت کے اثر ہے، اور دیکھتے ہیں کہ تفاوت زیادہ پارامتریزی کے غیر موجود رہتی ہے، اور یہ ڈریفوٹ محدود ہے، کروئل زبانوں کی نسبتی ثابت کی تصدیق کرتی ہے.', 'uz': "Name Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the creole is a complex process.  Ko'pchiliklar umumiy stabillari bo'lganda, bir necha xususiyatlar haqida ko'proq demokratika yoki bir necha lingvistik holatda ko'proq qulay bo'lishi mumkin. Bu qogʻoz bir necha qancha qanday qanday rivojlanuvchilar qiladi: Biz hayatiya Kreole, Nigeriya Pidgin Inglizchaga va Singaporiya Colloquial ingliz tilidagi modelларни жамлаймиз. Biz bu modellarni ichki va extrinik vazifalarga qiymatmiz. Yuqori littatkorlik tomonidan aniqlangan, biz standard tillar modellarini tarqatish roʻyxatlar bilan kamaytamiz va juda ham ajoyib ko'rsatganda, standard tillar modellari ajratilgan robotlarga ko'proq. Biz murakkab qilamiz, bu parametrlarga ko'proq tarqatish amalning qo'shilgan tashkilotlari, va har xil parametrlarga mavjud emas, va o'zgarishlar qo'shimcha tillarni ishlatishni tasdiqlash chegara qiladi.", 'vi': 'Ngôn ngữ Creole, ví dụ dụ Nigeria Pigetn English và Haitian Creole bị thiếu nguồn lực và hầu hết bị phớt lờ trong văn học NLP. Những vết nhơ hỏa thường là kết quả của sự hợp nhất ngôn ngữ ngoại quốc với nhiều ngôn ngữ địa phương, và các tính chất ngôn ngữ và ngôn ngữ văn học được chuyển giao cho người creole là một tiến trình phức tạp. Trong khi những rạn nứt bình thường ổn định, sự nổi bật của một số đặc điểm có thể mạnh mẽ hơn với một số trường hợp dân sự hoặc trong một số trường hợp ngôn ngữ. Tờ giấy này quyên góp nhiều phần: Chúng tôi thu thập các mẫu vật có sẵn cho Haitian Creole, Nigeria Pizzden English, và singaporean Colloquiaal English. Chúng tôi đánh giá các mô hình về các công việc riêng. Động cơ bởi văn học trên, chúng tôi so sánh các mô hình ngôn ngữ tiêu chuẩn với các mô hình phát triển mạnh mẽ và thấy rằng, hơi bất ngờ, các mô hình ngôn ngữ tiêu chuẩn vượt trội so với các mô hình bền bỉ. Chúng tôi điều tra xem đây có phải là tác động của quá mức đo lường hay độ ổn định phân phát tương đối, và thấy rằng sự khác biệt vẫn tồn tại khi không có mức đo nhiệt độ quá mức, và sự di chuyển đó là giới hạn, xác nhận sự ổn định tương đối của ngôn ngữ creole.', 'hr': 'Kriološki jezici kao što su Nigerijski Pidgin engleski i Haitski kreol su pod resursom i uglavnom ignorirani u literaturi NLP-a. Kreoli obično rezultiraju iz kombinacije stranog jezika s višestrukim lokalnim jezicima, a ono što se gramatičke i leksičke karakteristike prebacuju u kreolu je kompleksan proces. Iako su krele uglavnom stabilne, značajnost neke karakteristike može biti mnogo jača s određenim demografijom ili u nekim jezičkim situacijama. Ovaj papir donosi nekoliko doprinosa: skupljamo postojeće korporacije i oslobodimo modele za Haitski kreol, nigerijski pidgin engleski jezik i Singapurski kolokijalni engleski jezik. Procjenjujemo te modele na unutrašnjim i ekstrinsickim zadatkima. Motivirani od iznad literature, uspoređujemo standardne jezičke modele sa distribucionalno jačima i saznamo da su standardni jezički modeli iznenađujuće od distribucionalno jačih. Istražujemo da li je to učinak preko parameterizacije ili relativne distribucijske stabilnosti i saznamo da je razlika u odsustvu preko parameterizacije i da je drift ograničen, potvrđujući relativnu stabilnost jezika kreole.', 'da': 'Kreolsk sprog som nigeriansk pidgin engelsk og haitisk kreolsk er underressourcer og i vid udstrækning ignoreret i NLP litteraturen. Kreoler stammer typisk fra fusionen af et fremmedsprog med flere lokale sprog, og hvilke grammatiske og leksikologiske træk der overføres til kreolen er en kompleks proces. Mens kreoler generelt er stabile, kan fremhævelsen af nogle funktioner være meget stærkere med visse demografi eller i visse sproglige situationer. Denne artikel giver flere bidrag: Vi indsamler eksisterende corpora og udgiver modeller for haitisk kreolsk, nigeriansk pidgin engelsk og singaporiansk kollokviel engelsk. Vi evaluerer disse modeller på iboende og eksterne opgaver. Motiveret af ovenstående litteratur sammenligner vi standardsprogmodeller med distributionsmæssigt robuste og finder noget overraskende, at standardsprogmodellerne er bedre end de distributionsmæssigt robuste. Vi undersøger, om dette er en effekt af overparametrisering eller relativ fordelingsstabilitet, og finder ud af, at forskellen fortsætter i fravær af overparametrisering, og at afdrift er begrænset, hvilket bekræfter den relative stabilitet af kreolsprog.', 'de': 'Kreolische Sprachen wie das nigerianische Pidgin-Englisch und das haitianische Kreolische werden in der NLP-Literatur weitgehend ignoriert. Kreolen entstehen typischerweise aus der Verschmelzung einer Fremdsprache mit mehreren lokalen Sprachen, und welche grammatischen und lexikalischen Merkmale auf das Kreol übertragen werden, ist ein komplexer Prozess. Während Kreolen im Allgemeinen stabil sind, kann die Bedeutung einiger Merkmale bei bestimmten demografischen oder sprachlichen Situationen viel stärker sein. Diese Arbeit liefert mehrere Beiträge: Wir sammeln bestehende Korpora und veröffentlichen Modelle für Haitian Creole, Nigerian Pidgin English und Singapurean Colloquial English. Wir evaluieren diese Modelle an intrinsischen und extrinsischen Aufgaben. Motiviert durch die obige Literatur, vergleichen wir Standard-Sprachmodelle mit distributionsrobusten Modellen und stellen, etwas überraschenderweise, fest, dass die Standard-Sprachmodelle den distributionsrobusten überlegen sind. Wir untersuchen, ob dies ein Effekt von Überparametrierung oder relativer Verteilungsstabilität ist, und finden heraus, dass der Unterschied auch ohne Überparametrierung besteht und dass die Drift begrenzt ist, was die relative Stabilität kreolischer Sprachen bestätigt.', 'nl': 'Creoolse talen zoals het Nigeriaanse Pidgin Engels en Haïtiaans Creools zijn onvoldoende beschikbaar en worden grotendeels genegeerd in de NLP literatuur. Creolen zijn meestal het resultaat van de fusie van een vreemde taal met meerdere lokale talen, en welke grammaticale en lexicale kenmerken worden overgebracht naar het creools is een complex proces. Hoewel creolen over het algemeen stabiel zijn, kunnen sommige kenmerken veel prominenter zijn bij bepaalde demografische gegevens of in sommige taalkundige situaties. Dit artikel levert verschillende bijdragen: We verzamelen bestaande corpora en release modellen voor Haïtiaans Creools, Nigerian Pidgin Engels en Singaporese Colloquial Engels. We evalueren deze modellen op intrinsieke en extrinsieke taken. Gemotiveerd door bovenstaande literatuur vergelijken we standaard taalmodellen met distributierobuuste modellen en vinden dat, enigszins verrassend genoeg, de standaard taalmodellen superieur zijn aan de distributierobuuste modellen. We onderzoeken of dit een effect is van over-parametrisering of relatieve distributiestabiliteit, en vinden dat het verschil aanhoudt bij afwezigheid van over-parametrisering, en dat drift beperkt is, wat de relatieve stabiliteit van creoolse talen bevestigt.', 'id': 'Bahasa Creole seperti Nigeria Pidgin Bahasa Inggris dan Haitian Creole kekurangan sumber daya dan kebanyakan diabaikan dalam literatur NLP. Creoles biasanya berasal dari fusi bahasa asing dengan berbagai bahasa lokal, dan apa karakteristik grammatik dan leksik yang dipindahkan ke creole adalah proses kompleks. Sementara kreol secara umum stabil, prominensi beberapa fitur mungkin jauh lebih kuat dengan demografi tertentu atau dalam beberapa situasi bahasa. Kertas ini membuat beberapa kontribusi: Kami mengumpulkan corpora yang ada dan model pembebasan untuk Haitian Creole, Nigeria Pidgin Inggris, dan Singapore Colloquial Inggris. Kami mengevaluasi model ini pada tugas intrinsik dan extrinsic. Dimotifkan oleh literatur di atas, kita membandingkan model bahasa standar dengan model bahasa yang kuat secara distribusional dan menemukan bahwa, yang agak mengejutkan, model bahasa standar lebih tinggi dari model bahasa yang kuat secara distribusional. Kami menyelidiki apakah ini adalah efek dari parameterisasi berlebihan atau stabilitas distribusi relatif, dan menemukan bahwa perbedaan tetap dalam ketidakadaan parameterisasi berlebihan, dan drift tersebut terbatas, mengkonfirmasi stabilitas relatif bahasa kreol.', 'fa': 'زبانهای کرولی مثل نویجیریایی پیجین انگلیسی و کرولی هایتین کمتر از منابع و بیشتر در ادبیات NLP نادیده گرفته می شوند. کرئولز معمولاً نتیجه\u200cای از ترکیب زبان خارجی با زبان\u200cهای بسیاری محلی است، و آنچه ویژه\u200cهای گراماتیکی و زبان\u200cشناسی به کرئولی منتقل می\u200cشوند، یک فرایند پیچیده است. در حالی که کرولها معمولاً ثابت هستند، بزرگترین برخی از ویژه\u200cها ممکن است با برخی دموگرافیک یا در برخی موقعیت زبان\u200cشناسی بسیار قوی تر باشد. این کاغذ تعدادی از شرکت\u200cهای موجود را جمع می\u200cکنیم و مدل\u200cهای آزاد می\u200cکنیم برای کرول هایتین، نیجریه\u200cای پیdgin انگلیسی و سینگپوریه انگلیسی کلوکیایی. ما این مدلها را بر روی کار داخلی و خارجی ارزیابی می کنیم. توسط ادبیات بالا حرکت می\u200cکنیم، ما مدل\u200cهای زبان استاندارد را با مدل\u200cهای استاندارد مقایسه می\u200cکنیم و پیدا می\u200cکنیم که مدل\u200cهای زبان استاندارد بر مدل\u200cهای استاندارد استاندارد قوی\u200cترند. ما تحقیق می کنیم که آیا این تاثیر پارامتریزی یا استواری تقسیم نسبتی است، و پیدا می کنیم که تفاوت در غیر پارامتریزی زیادی ادامه دارد، و این دریفت محدود است، تصدیق کردن استواری نسبت به زبانهای کرولی است.', 'bg': 'Креолските езици като нигерийския пиджин английски и хаитянски креолски са недостатъчни ресурси и до голяма степен игнорирани в литературата на НЛП. Креолите обикновено произтичат от сливането на чужд език с множество местни езици и какви граматически и лексикални особености се прехвърлят на креола е сложен процес. Докато креолите обикновено са стабилни, известността на някои характеристики може да бъде много по-силна при определени демографски или в някои езикови ситуации. Тази статия прави няколко приноса: Събираме съществуващи корпори и издаваме модели за хаитянски креол, нигерийски пиджин английски и сингапурски колоквиален английски. Ние оценяваме тези модели по вътрешни и външни задачи. Мотивирани от горепосочената литература, сравняваме стандартните езикови модели с дистрибуционно стабилните и откриваме, че, изненадващо, стандартните езикови модели са по-добри от дистрибуционно стабилните. Проучваме дали това е ефект на свръхпараметризация или относителна дистрибуционна стабилност и откриваме, че разликата продължава при отсъствието на свръхпараметризация и че дрифтът е ограничен, потвърждавайки относителната стабилност на креолските езици.', 'tr': 'Nijeriýa Pidgin iňlisçe we Haiti kroollaryň ýaly köpüji dilleri NLP edebiýatynda ýok bolýar. Gürjükler adatça daşary dillerin birnäçe ýerli diller bilen birleşmesinden netijesi bolýar, we gramatik we leksiýaly karakterleriň kriole gönderilmesinden nähili karmaşık bir prosesdir. Küroler adatça stabil bolsa, käbir möhümleriň esasy demografiki ýa-da lingwistiki ýagdaýda köp güýçli bolup biler. Bu kagyz birnäçe köpüş etýär: Biz bar korpora we haitiýa krool, Nijeriýa Pidgin iňlisçe we Singapurça Koloquial iňlisçe nusgalary jemgylýarys. Bu modelleri iç ve dış görevlerde değerlendiriyoruz. Yukardaky edebiýatan tarapyndan süýtgedilen, biz standart dil modellerini daýlamak güýçleri bilen karşılaşdyrýarys we şuny tapýarys, birnäçe geň bir şekilde standart dil modelleri daýlamak güýçleri bilen üstündir. Biz bu ýagdaýyň aşa parameteriýa ýa-da relativ daýlamak stabilýasynyň täsiri diýip soruşýarys, we tapawutlaryň aşa parameteriýasyz ýok bolmadygyny we çykyş çykyş ýagdaýynyň relativ stabilýasyny tassyklaýarys.', 'af': "Creole tale soos Nigeriër Pidgin Engels en Haitiese Kreole is onder hulpbron en groot geïgnoreer in die NLP literatuur. Creoles is tipik gevaal van die verlossing van 'n vreemde taal met veelvuldige plaaslike tale, en wat grammatiese en leksiese funksies na die krole oordra word is 'n kompleks proses. Alhoewel kreoles generellik stabile is, kan die prominence van sommige funksies baie sterker wees met sekere demografie of in sommige lingvisse situasies. Hierdie papier maak verskeie bydraaiïngs: Ons versamel bestaande korpora en verlos modele vir Haitian Creole, Nigerian Pidgin Engels en Singaporeaanse Koloquial Engels. Ons evalueer hierdie modele op intrinsiese en extrinsic taak. Gebeweging deur die bo-literaat, vergelyk ons standaard taal modele met verspreiding kragtige en vind dat, sommige verwonderbaar, die standaard taal modele is superior aan die verspreiding kragtige. Ons ondersoek of dit 'n effek van oor-parameterisasie of relatiewe verspreidingsstabiliteit is, en vind dat die verskil voortgaan in die absence van oor-parameterisasie, en dat drift is beperk, bevestig die relatiewe stabiliteit van kreole tale.", 'sq': 'Gjuhat e kriolit të tilla si Nigerian Pidgin English dhe Haitian Creole janë të pakufishme dhe kryesisht të injoruara në literaturën NLP. Kriolët zakonisht rezultojnë nga fuzioni i një gjuhe të huaj me gjuhë të shumta lokale dhe çfarë karakteristike grammatike dhe lexike transferohen në kreol është një proces kompleks. Ndërsa krilat janë përgjithësisht të qëndrueshme, shfaqja e disa karakteristikave mund të jetë shumë më e fortë me disa demografi apo në disa situata gjuhësore. Kjo letër bën disa kontribute: ne mbledhim korpra ekzistuese dhe nxjerrim modele për Haitian Creole, Nigerian Pidgin English dhe Singaporean Colloquial English. Ne vlerësojmë këto modele në detyrat e brendshme dhe të jashtme. Motivuar nga literatura e lartë, ne krahasojmë modelet standarde gjuhësh me ato të forta shpërndarëse dhe gjejmë se, disi befasueshëm, modelet standarde gjuhësh janë më të lartë se ato të forta shpërndarëse. Ne hetojmë nëse ky është një efekt i mbiparametrizimit apo stabilitetit relativ shpërndarës, dhe zbulojmë se diferenca vazhdon në mungesën e mbiparametrizimit, dhe se drifti është i kufizuar, duke konfirmuar stabilitetin relativ të gjuhëve kreole.', 'am': 'Creole languages such as Nigerian Pidgin English and Haitian Creole are under-resourced and largely ignored in the NLP literature.  ክሮሌዎች በተለያዩ ቋንቋዎች ውስጥ የውጭ ቋንቋ መቀስቀስ ይደረጋሉ፡፡ በሙሉ የሚቆሙ ሲሆኑ፣ የአንዳንዱ የአፍላጎት ክብር በተለያዩ ዴሞግራፊዎች ወይም በአንዳንድ ቋንቋዊ ጉዳይ ይበረታል፡፡ ይህ ገጽ ብዙዎችን ድጋፍ ያቀርባል፤ አሁን ያለውን ኮርፖርት እና ለሐይታዊ ክሮዮል፣ የናዝሬያዊ ፒድጊን እንግሊዘኛ እና የሲንጋፖር ኮሎክዩኤል እንግሊዘኛ ሞላትን እንሰበስባለን፡፡ የውስጥና የውጭ ስራ ላይ ያሉትን ምሳሌዎች እናሳውቃለን፡፡ በላይኛው የቋንቋ ምሳሌዎች በተለየ የቋንቋ ምሳሌዎችን እናሳስፋለን፡፡ ይህ የባሕላዊ ግንኙነት ወይም የአካባቢ ግንኙነት ወይም የግንኙነት የአካባቢነት ግንኙነት እንዲኖር እናውቃለን፡፡', 'hy': 'Կրեոլական լեզուները, ինչպիսիք են Նիգերիայի Պիջինյան Անգլերենը և Հաիթիայի Կրեոլանը թերռեսուրսներով են և հիմնականում անտեսված ՆԼՊ գրականության մեջ: Քրիոլները սովորաբար արտադրվում են օտար լեզու համալսարանից բազմաթիվ տեղական լեզուներով, և ինչ գրամատիկ և լեքսիկական հատկություններ են փոխանցվում դեպի խրիոլը բարդ գործընթաց է: While creoles are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations.  Այս հոդվածը մի քանի ներդրումներ է տալիս. մենք հավաքում ենք գոյություն ունեցող կապորան և ազատում ենք Հաիթի Կրիոլի, Նիգերիայի Պիջինի Անգլերենի և Սինգապուրայի Կոլոքյուալ Անգլերենի մոդելներ: Մենք գնահատում ենք այս մոդելները ներքին և արտաքին առաջադրանքների վրա: Առաջին գրականության կողմից հիմնված, մենք համեմատում ենք ստանդարտ լեզվի մոդելները բաշխման առումով ուժեղ մոդելների հետ և հայտնաբերում ենք, որ ինչ-որ զարմանալի է, ստանդարտ լեզվի մոդելները գերազանցում են բաշխման առումով ուժեղ մոդե Մենք ուսումնասիրում ենք, արդյոք սա չափազանց պարամարիզացիայի արդյունք է, թե հարաբերական դիսպրոֆիզիոնալ կայունություն, և հայտնաբերում ենք, որ տարբերությունը շարունակում է չափազանց պարամարիզացիայի բացակայության դեպքում, և այդ փոփոխությունը սահմանափակ է, հաստատու', 'bn': 'নাইজেরিয়ার পিডজিন ইংরেজি এবং হাইতিয়ান ক্রিওলের মত ক্রিওল ভাষাগুলোকে অনেক সম্পদের অধীনে অবহেলা করা হয় এবং এনএলপি সাহিত্যে  সাধারণত বিদেশী ভাষায় বিদেশী ভাষার ফ্লুশনের ফলাফল, এবং ক্রিওলে কি গ্রাম্যাটিক্যাল এবং লেক্সিক্যাল বৈশিষ্ট্যাবলী বৈশিষ্ট্যাবল ক্রিওল সাধারণত স্থায়ীত, কিছু বৈশিষ্ট্যের সম্মান কিছু গণগ্রাফিক বা কিছু ভাষার পরিস্থিতিতে অনেক শক্তিশালী হতে পারে। এই পত্রিকা বেশ কয়েকটি অংশগ্রহণ করেছে: আমরা বিদ্যমান কোর্পোরা সংগ্রহ করি এবং হাইতিয়ান ক্রিওল, নাইজেরিয়ান পিডজিন ইংরেজি এবং সিঙ্গাপুর আমরা এই মডেলগুলো বিভিন্ন ভিত্তিক কাজের উপর মূল্যায়ন করি। উপরের সাহিত্যের দ্বারা উৎপাদন করা হয়েছে, আমরা স্ট্যান্ডার্ড ভাষার মডেল বিতরণভাবে রোবটসের সাথে তুলনা করি এবং খুঁজে পাচ্ছি যে কিছু বিস্ময়কর আমরা অনুসন্ধান করি এটা বেশী প্যারামিটারেশন বা আত্মিক বিতরণ স্থাপনের প্রভাব কিনা, আর আমরা খুঁজে বের করি যে পার্টিমেটারেশনের অনুপস্থিতিতে বিভিন্ন পার্থক্য চ', 'az': 'Nijeriya Pidgin İngilizə və Haiti Kreoli kimi kreolik dilləri NLP edebiyatından çox alçaq edilir. Çərçi dillərin çoxlu yerli dilləri ilə birləşdirilməsindən və qrammatik və leksik özellikləri kreoliyə göndərilənlərin kompleks prosesidir. Kreolilər genellikle stabil olduğu halda, bəzi mövzuların böyüklüyü bəzi demografik və bəzi dil şəkillərində daha qüvvətli olar. Bu kağıt bir neçə qədər iştirak edir: Biz həmin korpora toplayır və Haiti Kreoli, Nijerya Pidgin İngilizcisi və Singapur Koloquial İngilizcisi üçün modelləri yayındırırıq. Biz bu modelləri içəri və extrinsic işlərdə değerlendiririk. Yuxarıdaki səhifələr tərəfind ən hərəkət edir, biz standart dil modelləri dağıtılıb güclü modellərlə qarşılaşdırır və buna şaşırtıcı olaraq standart dil modelləri dağıtılıb güclü modellərdən daha üstün olduğunu görürük. Biz araşdırırıq ki, bu, aşırı parametrizaq və yaxşılıq dağıtılmaq stabiliyyətinin etkisidir, fərqliyin çox parametrizaq olmadığında həmişəlik olmadığını və tədrift sınırlandığını, kreolin dillərinin relativ stabiliyyətini təsdiqləyici olaraq.', 'ca': "Les llengües creoles, com el nigerià Pidgin English i el haitian Creole, són insuficients i en gran part ignorades en la literatura NLP. Les creules normalment resulten de la fusió d'un llenguatge estranger amb múltiples llengües locals, i quines característiques gramàtiques i lècsiques es transfereixen a la creole és un procés complexe. While creoles are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations.  Aquest article fa diverses contribucions: Recollim models de corpora i alliberament existents per a Haitian Creole, Nigerian Pidgin English i Singapur Colloquial English. Evaluam aquests models en tasques intrínsecs i extrínses. Motivats per la literatura anterior, comparem els models de llenguatge estàndard amb els de distribució robustos i trobem que, sorprenentment, els models de llenguatge estàndard són superiors als de distribució robustos. Investiguem si això és un efecte de sobreparametrització o estabilitat relativa de distribució, i descobrim que la diferència persisteix en l'absència de sobreparametrització, i que aquesta distorsió és limitada, confirmant l'estabilitat relativa de les llengües creols.", 'bs': 'Kriolički jezici poput Nigerije Pidgin English i Haitian Creole su pod resursom i uglavnom ignorirani u literaturi NLP. Kreoli obično rezultuju iz kombinacije stranog jezika sa višestrukim lokalnim jezicima, a ono što se gramatičke i leksičke karakteristike prebacuju u kreolu je kompleksan proces. Iako su krele uglavnom stabilne, velikost neke karakteristike može biti mnogo jača sa određenim demografijama ili u nekim jezičkim situacijama. Ovaj papir donosi nekoliko doprinosa: skupljamo postojeće korporacije i oslobodimo modele za Haitski kreol, nigerijski pidgin engleski jezik i Singapurski kolokijalni engleski jezik. Procjenjujemo te modele na unutrašnjim i ekstrinsickim zadatkima. Pod motivacijom iznad literatura, uspoređujemo standardne jezičke modele sa distribucionalno robotima i otkrijemo da su, iznenađujuće, standardni jezički modeli nadmašili distribucionalno robotima. Istražujemo da li je to učinak preko parameterizacije ili relativne distribucijske stabilnosti i saznamo da je razlika stala u odsustvu preko parameterizacije i da je drift ograničen, potvrđujući relativnu stabilnost jezika kreole.', 'cs': 'Kreolské jazyky, jako je nigerijská pidgin angličtina a haitská kreolština, jsou nedostatečně zdroje a do značné míry ignorovány v literatuře NLP. Kreoly obvykle vyplývají z fúze cizího jazyka s několika místními jazyky, a jaké gramatické a lexikální rysy jsou přenášeny do kreolštiny, je složitý proces. Zatímco kreoly jsou obecně stabilní, význam některých rysů může být mnohem silnější u určitých demografických údajů nebo v některých jazykových situacích. Tento článek obsahuje několik příspěvků: Shromažďujeme existující korpusy a vydáváme modely pro haitskou kreolštinu, nigerijskou pidginovou angličtinu a singapurskou kolokviální angličtinu. Tyto modely hodnotíme na vnitřních a extrinsických úlohách. Motivováni výše uvedenou literaturou porovnáváme standardní jazykové modely s distribučně robustními modely a zjišťujeme, že standardní jazykové modely jsou poněkud překvapivě lepší než distribučně robustní modely. Zkoumáme, zda se jedná o efekt nadparametrizace nebo relativní distribuční stability, a zjišťujeme, že rozdíl přetrvává i při absenci nadparametrizace a že drift je omezený, což potvrzuje relativní stabilitu kreolských jazyků.', 'fi': 'Kreolikielet, kuten nigerian pidgin-englanti ja haitian kreoli, ovat riittämättömiä ja suurelta osin sivuutetaan NLP:n kirjallisuudessa. Kreolit ovat tyypillisesti seurausta vieraan kielen fuusiosta useiden paikallisten kielten kanssa, ja mitä kieliopillisia ja sanastollisia ominaisuuksia kreoliin siirretään, on monimutkainen prosessi. Vaikka kreolit ovat yleensä vakaita, joidenkin ominaisuuksien näkyvyys voi olla paljon vahvempi tietyissä demografisissa tilanteissa tai joissakin kielitilanteissa. Tässä artikkelissa on useita kommentteja: Keräämme olemassa olevia korpusia ja julkaisemme malleja Haitin kreoli-, Nigerian Pidgin English- ja Singaporen Colloquial English -kielille. Arvioimme näitä malleja sisäisissä ja ulkoisissa tehtävissä. Edellä esitetyn kirjallisuuden pohjalta vertaamme standardikielimalleja jakelullisesti vahvoihin ja huomaamme, että jonkin verran yllättävää on, että standardikielimallit ovat ylivoimaisia jakelullisesti vahvoihin malleihin verrattuna. Tutkimme, johtuuko tämä yliparametrisaation vai suhteellisen jakauman vakauden vaikutuksesta, ja havaitsimme, että ero säilyy ilman yliparametrisaatiota, ja että drift on rajallinen, mikä vahvistaa kreolikielten suhteellisen vakauden.', 'et': 'Kreooli keeled, nagu Nigeeria Pidgin inglise ja Haiti kreooli keel, on NLP kirjanduses vähe ressursse ja suures osas ignoreeritud. Kreoolid tulenevad tavaliselt võõrkeelte ühendamisest mitme kohaliku keelega ning millised grammatilised ja leksikaalsed omadused kreooli üle kantakse, on keeruline protsess. Kuigi kreoolid on üldiselt stabiilsed, võib teatud demograafiliste või keeleliste olukordade puhul mõnede omaduste silmapaistvus olla palju tugevam. Käesolev töö annab mitmeid panuseid: Me kogume olemasolevaid korpuseid ja väljastame mudeleid Haiti kreooli, nigeeria pidgini inglise ja Singapuri kollokviaalse inglise keele jaoks. Hindame neid mudeleid nii sisemiste kui ka väliste ülesannete põhjal. Eespool esitatud kirjandusest lähtuvalt võrdleme standardseid keelemudeleid distributsiooniliselt tugevate mudelitega ja leiame, et mõnevõrra üllatavalt on standardsed keelemudelid distributsiooniliselt tugevatest mudelitest paremad. Uurime, kas see on üleparameerimise või suhtelise jaotusstabiilsuse mõju, ning leiame, et erinevus püsib üleparameerimise puudumisel ja et triiv on piiratud, kinnitades kreoolkeelte suhtelist stabiilsust.', 'ko': '나이지리아 해협 영어와 아이티 크리올어 등 크리올어 자원이 부족해 NLP 문헌에서 기본적으로 무시되고 있다.크리올어는 통상적으로 하나의 외국어와 여러 가지 현지 언어가 융합된 결과이고 크리올어의 문법과 어휘 특징은 복잡한 과정이다.크리올어는 전체적으로 안정적이지만 일부 인구통계학이나 언어 환경에서 일부 특징의 두드러짐이 더욱 강할 수 있다.본고는 몇 가지 공헌을 했다. 우리는 아이티 크리올어, 나이지리아 양경변 영어와 싱가포르 구어 영어의 기존 어료 라이브러리와 발표 모델을 수집했다.우리는 내재와 외재의 임무에 근거하여 이 모델들을 평가한다.상술한 문헌의 계발을 받아 우리는 표준 언어 모델과 분포 안정 모델을 비교한 결과 표준 언어 모델이 분포 안정 모델보다 우수하다는 것을 발견했다. 이것은 좀 놀랍다.우리는 이것이 과도한 매개 변수화인지 상대적인 분포 안정성에 대한 영향을 연구한 결과 이런 차이는 과도한 매개 변수화가 없는 상황에서도 여전히 존재하고 표류가 유한하다는 것을 발견했다. 이것은 크리올어의 상대적인 안정성을 증명했다.', 'sw': 'Lugha za kikatili kama vile Pidgin Kiingereza na Creole wa Haiti zimeandikwa na kupuuzwa sana katika fasihi ya NLP. Kikundi cha kawaida kinatokana na msongamano wa lugha ya kigeni wenye lugha mbalimbali za wenyeji, na vipi tabia za grammatika na lexico zinazohamishwa kwenye eneo hilo ni mchakato wa tatizo. Wakati mafuta yanakuwa imara kwa ujumla, ukubwa wa baadhi ya vipengele vinaweza kuwa na nguvu zaidi kwa idadi fulani au katika baadhi ya mazingira ya lugha. Gazeti hili linafanya michango kadhaa: Tunakusanya makampuni yanayopo na kuachia mfumo wa Creole wa Haiti, Nigeria Pidgin Kiingereza, na Kiingereza cha Colloquial cha Singapore. Tunatathmini mifano hii kwenye kazi za ndani na za nje. Inahamasishwa na fasihi ya juu, tunalinganisha mifano ya lugha ya kawaida na wale wanaochochochea kwa usambazaji na tunagundua kuwa, kwa kushangaza, mifano ya lugha ya kawaida ni bora kuliko wale wanaochochochea. Tunachunguza kama hii ni madhara ya upasuaji au usalama wa karibu wa usambazaji, na tunagundua kuwa tofauti zinaendelea kutokuwepo na upasuaji wa zaidi, na kwamba hatua hiyo inazuiwa, inayothibitisha ustawi wa lugha za watu.', 'he': "Creole languages such as Nigerian Pidgin English and Haitian Creole are under-resourced and largely ignored in the NLP literature.  קרולים בדרך כלל יוצאים מהמיזוג של שפה זרה עם שפות מקומיות רבות, ואיזה תכונות גרמטיות ולקסיות מועברות לקרוול הוא תהליך מורכב. בעוד קרולים הם בדרך כלל יציבים, הבהירות של כמה תכונות עלולה להיות הרבה יותר חזקה עם דמוגרפיה מסוימת או במצבים שפתיים מסוימים. העיתון הזה עושה כמה תרומות: אנחנו אוספים גופרה קיימת ושחררו דוגמנים עבור קרול הייטי, פידג'ין ניגרי אנגלית, וסינגפורית אנגלית קולוקיאלית. אנו מעריכים את הדוגמנים האלה על משימות פנימיות וחיצוניות. מוטיבציה על ידי הספרות העליונה, אנחנו משוותים דוגמנים שפות סטנדרטיים עם דוגמנים חזקים מבחינה פיצועית ומציאים, במיוחד מפתיע, דוגמנים שפות סטנדרטיים הם עדיפים על דוגמנים חזקים מבחינה פיצועית. אנו חוקרים אם זה השפעה של פרמטריזציה יתר או יציבות פיצוי יחסית, ומצאים שההבדל ממשיך בלעדיו של פרמטריזציה יתר, והתנועה הזו מוגבלת, מאשר את יציבות יחסית שפות קרול.", 'sk': 'Kreolski jeziki, kot sta nigerijski pidgin angleščina in haitijski kreol, so premalo sredstev in v veliki meri ignorirani v literaturi NLP. Kreole so običajno posledica združitve tujega jezika z več lokalnimi jeziki, in katere slovnične in leksikalne značilnosti se prenesejo v kreol je kompleksen proces. Medtem ko so kreole na splošno stabilne, je vidnost nekaterih značilnosti lahko veliko močnejša pri določenih demografskih ali v nekaterih jezikovnih situacijah. Ta prispevek vsebuje več prispevkov: Zbiramo obstoječe korpuse in izdajamo modele za haitijsko kreolo, nigerijsko pidgino angleščino in singapursko kolokvijsko angleščino. Te modele ocenjujemo na notranjih in zunanjih nalogah. Na podlagi zgoraj navedene literature primerjamo standardne jezikovne modele z distribucijsko robustnimi modeli in ugotovimo, da so standardni jezikovni modeli nekoliko presenetljivo boljši od distribucijsko robustnih modelov. Preučujemo, ali gre za učinek prekomerne parametrizacije ali relativne distribucijske stabilnosti, in ugotovimo, da razlika ostaja v odsotnosti prekomerne parametrizacije in da je premik omejen, kar potrjuje relativno stabilnost kreolskih jezikov.', 'ha': "Lughan CReole kamar Nigerian Pidgin Ingiriya da haiti-kore are underresource and largely omit in the NLP littãfi. QScriptBreakpointsModel A lokacin da misalin mutane ke tabbatacce, ko ko kuma akwai cikin wasu misali. Wannan karatun na ƙarfafa masu yawa: Munã samun makampuni wanda ke da shi kuma Muke sakar da misãlai masu iya hayitan Kreole, Nigerian Pidgin Ingiriya, da Ingiriya na Kulloquial. Ina ƙaddara waɗannan misãlai a kan aikin na guda da baka. Aka motsi da littafin da ke rufe, muna samfani misãlai na harshen na ɗabi'a da manyan abubuwan da aka raba tsakanin, kuma munã gane, da abu kaɗan, misalin harshen na'ura sun fi girma daga manyan abun wanda aka raba. Munã tambaya ko wannan mai amfani ne ga samar-parameterization ko kuma ma'abũcin tabbatarwa na rabo, kuma tuna cewa bambanci yana madawwama a gaba ga ba da parameterization, kuma a ƙunsa da ƙwarar, yana gaskata tabbatarwa na danganta da harshen bakwai.", 'bo': 'རྩིས་གཞུང་གི་སྐད་ཡིག་དག་གཟུགས་མེད་སྤྱི་ཚོགས་ཀྱི་དབྱིན་ཡིག་དང་ཧེ་ཤི་ཡི་སྒུང་ཁུང་ཚོའི་ནང་དུ་ཉམས་སྤྱོད་མེད་པར་ Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the creole is a complex process. རྩིས་གཞུང་གི་རྒྱུན་ལྡན་ནའང་མ་བཀོད་པ་ཞིག་ཡིན་ནའང་། ཁྱད་ཆོས་ཀྱི་ཁྱད་ཆོས་ཉིད་ཅིག་ཡིན་ཡང་ན་སྐད་ཡིག ཤོག་བྱང་འདིས་ལས་ཕན་ཐུག་སྣེ་མང་པོ་ཞིག་ཡོད། ང་ཚོས་བྱ་རིམ་འདི་དག་ནང་ཁག་དང་གཞན་གྱི་ལས་འགུལ་གྱི་མིག་གཟུགས་རིས་བཏོན་བྱེད་ཀྱི་ཡོད། མཐོང་སྣང་བྱས་པར་བཟོ་བྱས་པ་ཡིན་ན། ང་ཚོས་རྣམ་པ་ཁག་ཅིག་གི་སྐད་ཡིག་ཆ་རྣམས་ལས་མཐོང་ནི་མི་རྣམས་ལས་ཕལ་མེད་བཞག་ཐུབ་པར། སྐད་ཡིག་ We investigate whether this is an effect of over-parameterization or relative distributional stability, and find that the difference persists in the absence of over-parameterization, and that drift is limited, confirming the relative stability of creole languages.', 'jv': 'Suoro langkung kreol sing dibenakake Norian Pidgin Inggris karo Kreol Haitian kuwi nglanggar-perusahaan lan nganggep ingkang NLP. Kerol Nanging kreoles kang stabil, dipunangé awak dhéwé éntuk sing gak dhéwé luwih apik sing gak soalé karo depurasi apat o sak tindakan. Awak dhéwé nggawe barang-barang sing nyenengaké nyenengaké: kéné ngébutaké karo perusahaan lan mbukaké model kanggo nggawe Kreol Haitian, Njuk Pidgin Inggris, lan Singapir Colo-Kijal Inggris. Monday Awak dhéwé éntuk sing luwih apik, kéné sampek model sing luwih padha mêng, nik awak dhéwé sapa-sapa sing luwih hayo, ngono nggawe, model sing luwih apik lan model sing luwih apik dhéwé sing luwih apik têm nggawe kesempatan. Awak dhéwé ujian piye isakno kaya mbok dadi, dadi kapan pangan karo perusahaan langgar, lan nganggep kuwi cah-cah dumadhi kanggo ngilanggar sapa pangan karo diparameter sing gak bakal terus lan kêrbek kuwi wis limitisan, iso nguasai perusahaan langgar sampek winih.'}
{'en': 'Enriching Language Models with Visually-grounded Word Vectors and the Lancaster Sensorimotor Norms L ancaster Sensorimotor Norms', 'es': 'Enriquecer los modelos de lenguaje con vectores de palabras con base visual y las normas sensorimotoras de Lancaster', 'pt': 'Enriquecendo modelos de linguagem com vetores de palavras visualmente fundamentados e as normas sensório-motoras da Lancaster', 'ar': 'إثراء نماذج اللغة بموجهات الكلمات ذات الأسس المرئية وقواعد لانكستر الحسية', 'fr': 'Enrichir les modèles de langage avec des vecteurs de mots visuellement ancrés et les normes sensorimotrices de Lancaster', 'zh': '用基于视词向量兰开斯特动则丰言模', 'ru': 'Обогащение языковых моделей визуально обоснованными векторами слов и сенсоримоторными нормами Ланкастера', 'ja': '視覚的に接地されたワードベクトルとランカスターセンサー運動規範で言語モデルを豊かにする', 'hi': 'नेत्रहीन-आधारित वर्ड वैक्टर और लैंकेस्टर सेंसरीमोटर मानदंडों के साथ भाषा मॉडल को समृद्ध करना', 'ga': 'Samhlacha Teanga a shaibhriú le Veicteoirí Focal Atá bunaithe ar Amharc agus Normanna Lancaster Sensorimotor', 'ka': 'სიტყვის მოდელების გაზრუქება ვიზუალურად გაზრუქებული სიტყვის გვეკტორებით და ლანკასტერის სენსიორიმეტორის ნორმებით', 'hu': 'Gazdagító nyelvi modellek vizuálisan alapozott szóvektorokkal és a Lancaster Sensormotor Normákkal', 'el': 'Εμπλουτισμό γλωσσικών μοντέλων με οπτικά γειωμένα διανύσματα λέξεων και τα αισθητήρια πρότυπα του Λάνκαστερ', 'it': 'Arricchire i modelli linguistici con i vettori di parole visivamente fondati e le norme sensorimotorie Lancaster', 'kk': 'Тіл үлгілерін көрінетін сөз векторлары мен Ланкастер сенсоримоторы нормаларымен жақсарту', 'mk': 'Богати јазички модели со визуелно основани вектори на зборови и норми за сензоримотор на Ланкастер', 'lt': 'Kalbos modelių turtinimas su regėjimo pagrindu grindžiamais žodžių vektoriais ir Lankasterio jutiklių normomis', 'ml': 'കാഴ്ചയുള്ള വാക്ക് വെക്റ്ററുകളും ലാന്\u200dകാസ്റ്റര്\u200d സെന്\u200dസറിമോറ്റര്\u200d നോര്\u200dമുകളും ഉള്ള ഭാഷ മോഡലുകള്\u200d', 'mn': 'Түүний хэл загваруудыг харагддаг үг векторууд болон Ланкастер мэдрэгчийн нормуудыг багасгах', 'no': 'Forstørrar språk- modeller med visuelt bakgrunnsfarge ordvektorar og Lancaster- sentoriomotornormar', 'mt': 'Mudelli lingwistiċi rikki b’Vetturi tal-kliem b’bażi viżwali u n-Normi tas-Sensorimotor Lancaster', 'pl': 'Wzbogacanie modeli językowych o wizualnie uziemione wektory słowa i normy sensoryczne Lancaster', 'sr': 'Objačavanje jezičkih modela sa vizualno osnovanim vektorima riječi i Lancaster Sensorimotora Norma', 'si': 'භාෂා මොඩේල්ස් විශ්වාසයෙන් වචන වෙක්ටර් සහ ලැන්කාස්ටර් සෙන්සෝරිමෝටර් නෝර්ම්ස්', 'ro': 'Îmbunătățirea modelelor lingvistice cu vectori de cuvinte cu bază vizuală și Normele senzorimotor Lancaster', 'sv': 'Berika språkmodeller med visuellt grundade ordvektorer och Lancaster Sensorimotor Norms', 'ms': 'Name', 'ta': 'Name', 'ur': 'Visually-grounded Word Vectors and the Lancaster Sensorimotor Norms', 'so': 'Modelooyinka afka lagu kordhiyo oo ku yaala Vector-horaadka hadalka si aragga ah iyo Sensorimotor Norms', 'uz': 'Name', 'vi': 'Chế độ ngôn ngữ làm giàu bằng kính ngữ cũ và những tiêu chuẩn nhạy bén Lancaster', 'hr': 'Objačavanje jezičkih modela sa vidljivim vektorima riječi i Lancaster Sensorimotor Norma', 'nl': 'Verrijking van taalmodellen met visueel geaarde woordvectoren en de sensormotorische normen van Lancaster', 'bg': 'Обогатяване на езикови модели с визуално обосновани вектори на думи и сензоримоторните норми на Ланкастър', 'da': 'Berigende sprogmodeller med visuelt grundede ordvektorer og Lancaster Sensormotor Normer', 'id': 'Mengkaya Model Bahasa dengan Vektor Perkataan Berdasar Visual dan Norm Sensorimotor Lancaster', 'ko': '풍부한 언어 모델의 시각적 기초 어향량과 란체스터 감각 운동 규범', 'sw': 'Modala za Lugha zenye maendeleo na Vectors of Visual Word and Sensorimotor of Lancaster', 'tr': 'Görnöş görnöşinde Sözler Vektory we Lancaster Sensorimotor Normalary bilen Ullanyş Modelleri', 'de': 'Anreicherung von Sprachmodellen mit visuell geerdeten Wortvektoren und den sensormotorischen Normen von Lancaster', 'fa': 'برتری مدلهای زبانی با ویکتورهای کلمه\u200cهای روشن و سنسوریموتور لنکستر', 'am': 'ቋንቋዎች', 'az': 'Dil Modell…ôrini G√∂zl…ôŇüdirilmiŇü Kelimi VektorlarńĪ v…ô Lancaster Sensorimotor NormalarńĪ il…ô geniŇül…ôŇüdirilmiŇü', 'af': 'Vergroot Taal Modelle met Visuel- Grootte Woord Vektors en die Lancaster Sensorimotor Norms', 'sq': 'Modelet e pasura të gjuhës me vektorët e fjalëve të bazuar në pamje dhe normat e sensorëve Lancaster', 'bs': 'Objačavanje jezičkih modela sa vizualno osnovanim vektorima riječi i Lancaster Sensorimotor Norma', 'hy': 'Լեզվաբանական մոդելները հարուստ են տեսողական հիմքով բառերի վեկտորներով և Լանկաստերի սենսորիմոտոր Նորմներով', 'et': 'Keelemudelite rikastamine visuaalselt põhjendatud sõnavaktorite ja Lancasteri sensorimootoriliste normidega', 'ca': 'Models de llenguatge enriqueixant amb vectors de paraules visuals i els Nòrmes de Sensorimotor Lancaster', 'cs': 'Obohacující jazykové modely s vizuálně uzemněnými slovními vektory a senzomotorickými normami Lancaster', 'fi': 'Kielimallien rikastaminen visuaalisesti pohjautuvilla sanavektoreilla ja Lancasterin sensorimoottorinormeilla', 'bn': 'Name', 'ha': '@ item Text character set', 'jv': 'Ngubah Gambar-Ngerawat model Language karo Visual-grundtering Word vector karo nggambar Lanakster Sensiomotor Norm', 'he': 'מודלים שפות עשירים עם קוקטורי מילים מבחינה ראייתית ונורמות Sensorimotor Lancaster', 'sk': 'Obogatenje jezikovnih modelov z vizualno označenimi besednimi vektorji in Lancasterjevimi senzoromotornimi standardi', 'bo': 'མཐོང་ནུས་ཀྱིས་མཐོང་རྣམས་པའི་སྐད་ཡིག་ཆ་བརྙན་རིས་དང་Lancaster Sensorimotor སྦྲེལ་མཐུད་དང་འབྲེལ་བ་མཚོན་ནི།'}
{'en': 'Language models are trained only on text despite the fact that humans learn their first language in a highly interactive and multimodal environment where the first set of learned words are largely concrete, denoting physical entities and embodied states. To enrich language models with some of this missing experience, we leverage two sources of information : (1) the Lancaster Sensorimotor norms, which provide ratings (means and standard deviations) for over 40,000 English words along several dimensions of embodiment, and which capture the extent to which something is experienced across 11 different sensory modalities, and (2) vectors from coefficients of binary classifiers trained on images for the BERT vocabulary. We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark. We find that enriching  language models  with the Lancaster norms and image vectors improves results in both tasks, with some implications for robust  language models  that capture holistic linguistic meaning in a language learning context.', 'es': 'Los modelos lingüísticos se entrenan solo en texto a pesar del hecho de que los humanos aprenden su lengua materna en un entorno altamente interactivo y multimodal donde el primer conjunto de palabras aprendidas es en gran medida concreto, denotando entidades físicas y estados encarnados. Para enriquecer los modelos lingüísticos con parte de esta experiencia faltante, aprovechamos dos fuentes de información: (1) las normas sensorimotoras de Lancaster, que proporcionan calificaciones (medias y desviaciones estándar) para más de 40.000 palabras en inglés a lo largo de varias dimensiones de encarnación, y que capturan hasta qué punto algo se experimenta en 11 modalidades sensoriales diferentes y (2) vectores de coeficientes de clasificadores binarios entrenados en imágenes para el vocabulario BERT. Entrenamos previamente el modelo ELECTRA y ajustamos el modelo RoBerta con estas dos fuentes de información, luego lo evaluamos utilizando el punto de referencia GLUE establecido y el punto de referencia Visual Dialog. Descubrimos que enriquecer los modelos lingüísticos con las normas de Lancaster y los vectores de imágenes mejora los resultados en ambas tareas, con algunas implicaciones para los modelos lingüísticos sólidos que capturan el significado lingüístico holístico en un contexto de aprendizaje de idiomas.', 'pt': 'Os modelos de linguagem são treinados apenas em texto, apesar do fato de que os humanos aprendem sua primeira língua em um ambiente altamente interativo e multimodal, onde o primeiro conjunto de palavras aprendidas é em grande parte concreto, denotando entidades físicas e estados incorporados. Para enriquecer os modelos de linguagem com um pouco dessa experiência perdida, utilizamos duas fontes de informação: (1) as normas Lancaster Sensorimotor, que fornecem classificações (médias e desvios padrão) para mais de 40.000 palavras em inglês ao longo de várias dimensões de corporificação, e que capturam o até que ponto algo é experimentado em 11 modalidades sensoriais diferentes e (2) vetores de coeficientes de classificadores binários treinados em imagens para o vocabulário BERT. Nós pré-treinamos o modelo ELECTRA e ajustamos o modelo RoBERTa com essas duas fontes de informação e depois avaliamos usando o benchmark GLUE estabelecido e o benchmark Visual Dialog. Descobrimos que enriquecer os modelos de linguagem com as normas de Lancaster e vetores de imagem melhora os resultados em ambas as tarefas, com algumas implicações para modelos de linguagem robustos que capturam o significado linguístico holístico em um contexto de aprendizado de idiomas.', 'ar': 'يتم تدريب النماذج اللغوية فقط على النص على الرغم من حقيقة أن البشر يتعلمون لغتهم الأولى في بيئة تفاعلية ومتعددة الوسائط حيث تكون المجموعة الأولى من الكلمات المكتسبة ملموسة إلى حد كبير ، مما يدل على الكيانات المادية والحالات المجسدة. لإثراء نماذج اللغة ببعض من هذه التجربة المفقودة ، فإننا نستفيد من مصدرين للمعلومات: (1) معايير Lancaster Sensorimotor ، التي توفر تصنيفات (الوسائل والانحرافات المعيارية) لأكثر من 40000 كلمة إنجليزية على طول عدة أبعاد من التجسيد ، والتي تلتقط إلى أي مدى يتم اختبار شيء ما عبر 11 طريقة حسية مختلفة ، و (2) متجهات من معاملات المصنفات الثنائية المدربة على الصور لمفردات BERT. لقد قمنا بتدريب نموذج ELECTRA مسبقًا وضبطنا نموذج RoBERTa بهذين المصدرين للمعلومات ثم قمنا بالتقييم باستخدام معيار GLUE المحدد ومعيار Visual Dialog. وجدنا أن إثراء نماذج اللغة بمعايير لانكستر ونواقل الصور يحسن النتائج في كلا المهمتين ، مع بعض الآثار المترتبة على نماذج اللغة القوية التي تلتقط المعنى اللغوي الشامل في سياق تعلم اللغة.', 'fr': "Les modèles de langage ne sont formés que sur du texte malgré le fait que les humains apprennent leur langue maternelle dans un environnement hautement interactif et multimodal où les premiers mots appris sont largement concrets, désignant des entités physiques et des états incarnés. Pour enrichir les modèles linguistiques avec une partie de cette expérience manquante, nous utilisons deux sources d'information\xa0: (1) les normes sensorimotrices de Lancaster, qui fournissent des évaluations (moyennes et écarts-types) pour plus de 40 000 mots anglais selon plusieurs dimensions de l'incarnation, et qui saisissent la mesure dans laquelle quelque chose est expérimenté à travers 11 modalités sensorielles différentes, et (2) des vecteurs à partir de coefficients de classificateurs binaires entraînés sur des images pour le vocabulaire BERT. Nous avons pré-entraîné le modèle ELECTRA et affiné le modèle Roberta avec ces deux sources d'information, puis nous l'avons évalué à l'aide du benchmark GLUE établi et du benchmark Visual Dialog. Nous avons constaté que l'enrichissement des modèles linguistiques avec les normes de Lancaster et les vecteurs d'image améliore les résultats dans les deux tâches, avec certaines implications pour les modèles linguistiques robustes qui saisissent la signification linguistique holistique dans un contexte d'apprentissage des langues.", 'ja': '言語モデルは、人間が高度にインタラクティブでマルチモーダルな環境で第一言語を学習するにもかかわらず、テキストのみで訓練されています。そこでは、最初の学習された単語のセットはほぼ具体的であり、物理的な実体と具現化された状態を表しています。 この欠落した経験の一部で言語モデルを豊かにするために、私たちは2つの情報源を活用します。（ 1 ）実施形態のいくつかの次元に沿って40,000を超える英単語の評価（平均および標準偏差）を提供し、11の異なる感覚モードにわたって何かが経験される程度を捕捉するランカスターセンソリモーターの規範、および（ 2 ） BERTボキャブラリーの画像でトレーニングされたバイナリ分類子の係数からのベクトル。 エレクトラモデルを事前にトレーニングし、これら2つの情報源でRoBERTaモデルを微調整した後、確立された接着ベンチマークとビジュアルダイアログベンチマークを使用して評価しました。 ランカスター規範と画像ベクトルで言語モデルを豊かにすることで、両方のタスクの結果が改善され、言語学習の文脈で全体的な言語的意味を取り込む堅牢な言語モデルにいくつかの意味があることがわかっています。', 'hi': 'भाषा मॉडल को केवल इस तथ्य के बावजूद पाठ पर प्रशिक्षित किया जाता है कि मनुष्य अपनी पहली भाषा को अत्यधिक इंटरैक्टिव और बहुआयामी वातावरण में सीखते हैं जहां सीखे गए शब्दों का पहला सेट काफी हद तक ठोस होता है, जो भौतिक संस्थाओं और सन्निहित राज्यों को दर्शाता है। इस लापता अनुभव में से कुछ के साथ भाषा मॉडल को समृद्ध करने के लिए, हम जानकारी के दो स्रोतों का लाभ उठाते हैं: (1) लैंकेस्टर सेंसरिमोटर मानदंड, जो अवतार के कई आयामों के साथ 40,000 से अधिक अंग्रेजी शब्दों के लिए रेटिंग (साधन और मानक विचलन) प्रदान करते हैं, और जो उस हद तक कब्जा करते हैं जिस तक कुछ 11 अलग-अलग संवेदी तौर-तरीकों में अनुभव किया जाता है, और (2) BERT शब्दावली के लिए छवियों पर प्रशिक्षित बाइनरी क्लासिफायरके गुणांक से वैक्टर। हमने ELECTRA मॉडल को पूर्व-प्रशिक्षित किया और जानकारी के इन दो स्रोतों के साथ RoBERTa मॉडल को ठीक किया, फिर स्थापित GLUE बेंचमार्क और Visual Dialog बेंचमार्क का उपयोग करके मूल्यांकन किया। हम पाते हैं कि लैंकेस्टर मानदंडों और छवि वैक्टर के साथ भाषा मॉडल को समृद्ध करने से दोनों कार्यों में परिणामों में सुधार होता है, जिसमें मजबूत भाषा मॉडल के लिए कुछ निहितार्थ होते हैं जो भाषा सीखने के संदर्भ में समग्र भाषाई अर्थ को कैप्चर करते हैं।', 'zh': '言语形于文本,虽人伦高互动,多模态习其第一语,其第一组学者单词大矣,物理之实体也。 以多言模,以两息之原:(1)兰开斯特觉动,为过40,000一英语单词,循数维度之评级(平均值,差),而获11种之觉模态,(2)出于BERT词汇表之象二进制分类器系数之向量。 吾预练ELECTRA模形,用此二信息源微RoBERTa,然后用已立者GLUE准与Visual Dialog准评之。 吾见用兰开斯特规模图像向量多言模可以改善者,于言学之中获其体义者鲁棒其言体有所染也。', 'ru': 'Языковые модели обучаются только на тексте, несмотря на то, что люди изучают свой первый язык в очень интерактивной и мультимодальной среде, где первый набор изученных слов в значительной степени конкретен, обозначает физические сущности и воплощенные состояния. Чтобы обогатить языковые модели некоторыми из этого недостающего опыта, мы используем два источника информации: (1) нормы Lancaster Sensorimotor, которые предоставляют рейтинги (средние значения и стандартные отклонения) для более чем 40 000 английских слов по нескольким измерениям варианта реализации, и которые фиксируют степень, в которой что-то испытывается в 11 различных сенсорных модальностях, и (2) векторы из коэффициентов двоичных классификаторов, обученных на изображениях для лексики BERT. Мы предварительно обучили модель ELECTRA и доработали модель RoBERTa с этими двумя источниками информации, а затем оценили с использованием установленного эталона КЛЕЯ и эталона визуального диалога. Мы обнаружили, что обогащение языковых моделей нормами Ланкастера и векторами изображений улучшает результаты в обеих задачах, с некоторыми последствиями для надежных языковых моделей, которые захватывают целостное лингвистическое значение в контексте изучения языка.', 'ga': 'Is ar théacs amháin a chuirtear oiliúint ar mhúnlaí teanga in ainneoin go bhfoghlaimíonn daoine a gcéad teanga i dtimpeallacht an-idirghníomhach agus ilmhódach ina bhfuil an chéad sraith d’fhocail fhoghlamtha nithiúil den chuid is mó, rud a léiríonn aonáin fhisiceacha agus stáit chorpraithe. Chun samhlacha teanga a shaibhriú le cuid den taithí seo atá in easnamh, bainimid úsáid as dhá fhoinse faisnéise: (1) noirm Lancaster Sensorimotor, a sholáthraíonn rátálacha (modhanna agus diallais chaighdeánacha) do níos mó ná 40,000 focal Béarla feadh roinnt toisí den chorprúchán, agus a ghabhann leis an a mhéid a bhfuil taithí ar rud éigin thar 11 mhódúlachtaí céadfacha éagsúla, agus (2) veicteoirí ó chomhéifeachtaí aicmitheoirí dénártha a bhfuil oiliúint orthu ar íomhánna don stór focal BERT. Rinneamar réamhoiliúna ar mhúnla ELECTRA agus rinneamar mionchoigeartú ar mhúnla RoBERTa leis an dá fhoinse faisnéise seo agus ansin déanaimid meastóireacht ag baint úsáide as an tagarmharc GLUE bunaithe agus an tagarmharc Amhairc dialóg. Feictear dúinn go bhfeabhsaítear saibhriú samhlacha teanga le noirm Lancaster agus le veicteoirí íomhá torthaí sa dá thasc, le roinnt impleachtaí do mhúnlaí láidre teanga a ghabhann brí iomlánaíoch teangeolaíoch i gcomhthéacs foghlama teanga.', 'el': 'Τα γλωσσικά μοντέλα εκπαιδεύονται μόνο στο κείμενο παρά το γεγονός ότι οι άνθρωποι μαθαίνουν την πρώτη τους γλώσσα σε ένα ιδιαίτερα διαδραστικό και πολυμορφικό περιβάλλον όπου το πρώτο σύνολο των διδαχθέντων λέξεων είναι σε μεγάλο βαθμό συγκεκριμένο, υποδηλώνοντας φυσικές οντότητες και ενσαρκωμένες καταστάσεις. Για να εμπλουτίσουμε τα γλωσσικά μοντέλα με κάποια από αυτή την εμπειρία που λείπει, αξιοποιούμε δύο πηγές πληροφοριών: (1) τα πρότυπα αισθητήρων που παρέχουν αξιολογήσεις (μέσα και τυπικές αποκλίσεις) για πάνω από 40.000 αγγλικές λέξεις κατά μήκος διαφόρων διαστάσεων ενσάρκωσης, και που αποτυπώνουν τον βαθμό στον οποίο κάτι βιώνεται σε 11 διαφορετικές αισθητήριες λεπτομέρειες, και (2) διανύσματα από συντελεστές δυαδικών ταξινομητών εκπαιδευμένους σε εικόνες για το λεξιλόγιο BERT. Προεκπαιδεύσαμε το μοντέλο και τελειοποιήσαμε το μοντέλο με αυτές τις δύο πηγές πληροφοριών, στη συνέχεια αξιολογήσαμε χρησιμοποιώντας το καθιερωμένο σημείο αναφοράς και το σημείο αναφοράς οπτικού διαλόγου. Διαπιστώνουμε ότι ο εμπλουτισμός των γλωσσικών μοντέλων με τους κανόνες και τους φορείς εικόνας βελτιώνει τα αποτελέσματα και στις δύο εργασίες, με ορισμένες επιπτώσεις για ισχυρά γλωσσικά μοντέλα που αποτυπώνουν ολιστική γλωσσική σημασία σε ένα πλαίσιο εκμάθησης γλωσσών.', 'hu': 'A nyelvi modelleket csak a szövegre képezik annak ellenére, hogy az emberek egy nagyon interaktív és multimodális környezetben tanulják első nyelvüket, ahol a tanult szavak első sorozata nagyrészt konkrét, fizikai entitásokat és testesített állapotokat jelöl. Annak érdekében, hogy a nyelvi modelleket a hiányzó tapasztalatok némelyikével gazdagítsuk, két információforrást használunk: (1) a Lancaster Sensorimotor normákat, amelyek több mint 40 000 angol szó minősítését biztosítják a megtestesülés több dimenziója mentén, és amelyek megragadják, hogy valamit milyen mértékben tapasztalnak meg 11 különböző érzékszervi módon, és (2) vektorok a BERT szókincsében képzett bináris osztályozók együtthatóiból. Az ELECTRA modellt előkészítettük és finomhangoltuk a RoBERTa modellt ezzel a két információforrással, majd értékeltük a megalapozott GLUE benchmark és a Visual Dialog benchmark használatával. Úgy találjuk, hogy a Lancaster normákkal és képvektorokkal való gazdagítása mindkét feladatban javítja az eredményeket, néhány hatással van a robusztus nyelvi modellekre, amelyek holisztikus nyelvi jelentést rögzítenek a nyelvtanulási kontextusban.', 'kk': 'Тіл үлгілері тек мәтінде оқылған, адамдар бірінші тілді интерактивті және көп- модалдық ортада үйреніп, бірінші білім сөздердің бірінші жиыны көп конкретті, физикалық нысандарды және енгізілг Тіл үлгілерін кейбір тәжірибенің бірнеше түсініктеріне бағалау үшін, екі мәліметтің көзі бар: (1) Ланкастер сенсоримотор нормалары, олар 40,000 ағылшын сөздерінің көп өлшемдері мен бірнеше ағылшын сөздеріне көмектеседі. Бұл 11 түрлі сенсориялық т BERT сөздігінің кескіндерінде оқылған бинарлық классификаторлардың коэфициенттерінен (2) векторы. Біз ELECTRA үлгісін алдын- ала оқыдық және RoBERTa үлгісін осы екі мәліметтің көзі менеджерімен түзеттік. Содан кейін GLUE бағдарламасын және көрінетін диалог бағдарламасын қолдану үшін оқы Ланкастер нормаларымен мен кескіндерді векторлармен тіл үлгілерін бағалау үшін екі тапсырмалардың нәтижесін жақсартып, тілді оқыту контекстінде жұмыс тіл үлгілерінің кейбір нәтижесін жасайды.', 'ka': 'ენის მოდელები მხოლოდ ტექსტიდან აკეთებულია, თუმცა ადამიანები თავის პირველი ენაზე ძალიან ინტერაქტიური და მულტიმოდიალური გარეშე, სადაც პირველი სწავლილი სიტყვების ნაწილი უფრო კონკრეტულია,  ჩვენ ამ გამოიყენებულ გამოცდილობის მოდელების შესახებ, ჩვენ ორი ინფორმაციის გამოყენება: (1) ლანკასტერის სენსიორიოტორის ნორმი, რომლებიც უფრო 40 000 ანგლისური სიტყვებისთვის უფრო მეტი განსხვავებული სიტყვებისთვის, და რომლებიც განსხვავებული სიტყვე BERT სიტყვებულის გამოსახულებისთვის კოეფექტირების კოეფექტირების კოეფექტირების და (2) ვიქტორები. ჩვენ ELECTRA მოდელის წინ შევსწავლოთ და RoBERTa მოდელის შესახებ ამ ორი ინფორმაციის ფორმატებით შემდეგ გამოყენებული GLUE ბანქმერის და ვიზუალური დიალოგის ბანქმერის გამოყენება. ჩვენ აღმოჩნეთ, რომ ლანკასტერის ნორმებით და გამოსახულების გვექტორებით უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო ძალიან ენახულების მოდელებისთვის, რომელიც ჰოლუ', 'it': "I modelli linguistici sono formati solo sul testo, nonostante il fatto che gli esseri umani imparino la loro prima lingua in un ambiente altamente interattivo e multimodale in cui le prime parole apprese sono in gran parte concrete, denotando entità fisiche e stati incarnati. Per arricchire i modelli linguistici con alcune di queste esperienze mancanti, sfruttiamo due fonti di informazione: (1) le norme Sensorimotor Lancaster, che forniscono valutazioni (mezzi e deviazioni standard) per oltre 40.000 parole inglesi lungo diverse dimensioni di incarnazione, e che catturano la misura in cui qualcosa è vissuto attraverso 11 diverse modalità sensoriali, e (2) vettori da coefficienti di classificatori binari formati sulle immagini per il vocabolario BERT. Abbiamo pre-addestrato il modello ELECTRA e perfezionato il modello RoBERTa con queste due fonti di informazioni, quindi abbiamo valutato utilizzando il benchmark GLUE stabilito e il benchmark Visual Dialog. Troviamo che l'arricchimento dei modelli linguistici con le norme Lancaster e i vettori di immagine migliora i risultati in entrambi i compiti, con alcune implicazioni per modelli linguistici robusti che catturano il significato linguistico olistico in un contesto di apprendimento delle lingue.", 'lt': 'Kalbos modeliai mokomi tik tekstu, nepaisant to, kad žmonės mokosi savo pirmąją kalbą labai interaktyvioje ir daugiarūšio pobūdžio aplinkoje, kurioje pirmasis mokomų žodžių rinkinys yra iš esmės konkretus, nurodantis fizinius subjektus ir įtvirtintas valstybes. Norėdami praturtinti kalbų modelius su tam tikra trūkstama patirtimi, mes naudojame du informacijos šaltinius: 1) Lancaster Sensorimotor normas, kurios suteikia reitingus (vidurkius ir standartinius nukrypimus) daugiau kaip 40 000 anglų žodžių pagal kelis įterpimo matmenis ir apima, kiek kažkas patiriamas 11 skirtingų jutimo būdų, ir (2) vektoriai iš dviejų klasifikatorių koeficientų, apmokytų BERT žodyno vaizduose. Iš anksto parengėme ELECTRA model į ir patobulinome RoBERTa modelį šiais dviem informacijos šaltiniais, o vėliau įvertinome naudojant nustatytą GLUE lyginamąjį rodiklį ir Vizualinio dialogo lyginamąjį rodiklį. Mes manome, kad praturtinant kalbos modelius Lancaster normomis ir vaizdo vektoriais pagerinami abiejų užduočių rezultatai, o tai daro tam tikrą poveikį patikimiems kalbos modeliams, kurie apima holistinę kalbos reikšmę kalbų mokymosi kontekste.', 'ml': 'മനുഷ്യര്\u200d തങ്ങളുടെ ആദ്യത്തെ ഭാഷയില്\u200d പഠിക്കുന്നത് വളരെ interactive, multimodal പരിസ്ഥിതിയില്\u200d മാത്രമാണ് ഭാഷ മോഡലുകള്\u200d പഠിക്കുന്നത്. ആദ്യത്തെ വാക്കുകള്\u200d കൂടുതല്\u200d ക്രമീകര ഈ കാണാത്ത അനുഭവങ്ങളുടെ കൂടെ ഭാഷ മോഡലുകള്\u200d സമ്പന്നപ്പെടുത്താന്\u200d ഞങ്ങള്\u200d വിവരങ്ങളുടെ രണ്ട് സ്രോതസ്സുകള്\u200d ഉപയോഗിക്കുന്നു: (1) ലാന്\u200dകാസ്റ്റര്\u200d സെന്\u200dസ്സറിമോട്ടര്\u200d നിയമങ്ങള്\u200d നല്\u200dകുന്നു. അതിന്\u200dറ ബെര്\u200dട്ടിയുടെ പദസനത്തിനുള്ള ചിത്രങ്ങളില്\u200d പഠിപ്പിക്കപ്പെട്ട ബൈനരി ക്ലാസ്ഫിഫയരുടെ കൂട്ടത്തില്\u200d നിന്നും വെക We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark.  We find that enriching language models with the Lancaster norms and image vectors improves results in both tasks, with some implications for robust language models that capture holistic linguistic meaning in a language learning context.', 'ms': 'Model bahasa hanya dilatih pada teks walaupun manusia belajar bahasa pertama mereka dalam persekitaran yang sangat interaktif dan multimodal di mana set pertama perkataan yang belajar adalah kebanyakan konkrit, menunjukkan entiti fizik dan keadaan yang terbentuk. To enrich language models with some of this missing experience, we leverage two sources of information: (1) the Lancaster Sensorimotor norms, which provide ratings (means and standard deviations) for over 40,000 English words along several dimensions of embodiment, and which capture the extent to which something is experienced across 11 different sensory modalities, - dan (2) vektor dari koeficien klasifikasi binari dilatih pada imej untuk vokbulari BERT. Kami melatih model ELECTRA dan menyesuaikan model RoBERTa dengan dua sumber maklumat ini kemudian menilai menggunakan tanda referensi GLUE yang ditetapkan dan tanda referensi Dialog Visual. Kami mendapati bahawa model bahasa yang kaya dengan norma Lancaster dan vektor imej meningkatkan hasil dalam kedua-dua tugas, dengan beberapa implikasi untuk model bahasa yang kuat yang menangkap makna bahasa holistik dalam konteks pembelajaran bahasa.', 'mt': 'Il-mudelli lingwistiċi huma mħarrġa biss fuq it-test minkejja l-fatt li l-bnedmin jitgħallmu l-ewwel lingwa tagħhom f’ambjent interattiv ħafna u multimodali fejn l-ewwel sett ta’ kliem imgħallmu huma fil-biċċa l-kbira konkreti, li jindikaw entitajiet fiżiċi u stati inkorporati. Sabiex jiġu arrikkiti mudelli lingwistiċi b’xi wħud minn din l-esperjenza nieqsa, aħna ninfurzaw żewġ sorsi ta’ informazzjoni: (1) in-normi tas-Sensorimotor Lancaster, li jipprovdu klassifikazzjonijiet (mezzi u devjazzjonijiet standard) għal aktar minn 40,000 kelma Ingliża tul diversi dimensjonijiet ta’ inkorporazzjoni, u li jaqbdu sa liema punt xi ħaġa tiġi esperjenzata fi ħdax-il modalità sensorja differenti, ) u (2) vetturi minn koeffiċjenti ta’ klassifikaturi binarji mħarrġa fuq immaġni għall-vokabulari BERT. Aħna tħarrġu minn qabel il-mudell ELECTRA u aġġustajna l-mudell RoBERTa b’dawn iż-żewġ sorsi ta’ informazzjoni u mbagħad ivvalutajna bl-użu tal-punt ta’ riferiment tal-GLUE stabbilit u l-punt ta’ riferiment tad-Djalogu Viżwali. Issibu li l-mudelli lingwistiċi arrikkiti man-normi Lancaster u l-vetturi tal-immaġni jtejbu r-riżultati fiż-żewġ kompiti, b’xi implikazzjonijiet għal mudelli lingwistiċi robusti li jaqbdu t-tifsira lingwistika olistika f’kuntest ta’ tagħlim tal-lingwi.', 'mk': 'Моделите на јазик се обучени само на текст и покрај фактот дека луѓето го научуваат својот прв јазик во високо интерактивна и мултимодилна средина каде што првиот сет научени зборови се во голема мера конкретни, укажувајќи на физичките ентитети и вградени држави. За да ги збогатиме јазичните модели со некои од ова недостасувачко искуство, користиме два извори на информации: (1) нормите на Ланкастерскиот сензоримотор, кои обезбедуваат рејтинг (средства и стандардни одбивања) за повеќе од 40.000 англиски зборови долж неколку димензии на обележување, и кои го заземаат степенот во кој нешто се иск Вектори од коефициентите на бинарните класификатори обучени на слики за речникот BERT. Го претрениравме моделот на ЕЛЕКТРА и го пофиниравме моделот на Роберта со овие два извори на информации, а потоа го проценивме користејќи го поставениот GLUE референциски параметр и референцискиот параметр на Визуелниот дијалог. Најдовме дека богатувањето на јазичките модели со нормите на Ланкастер и векторите на сликите ги подобрува резултатите на двете задачи, со некои импликации за силни јазички модели кои го фатат холистичкото јазичко значење во контекст на учење јазици.', 'mn': 'Хүмүүс анхны хэлийг интерактив болон олон модуль орчинд суралцаж байхаас гадна анхны сургалтын үгийг ихэвчлэн тодорхой, физикийн төрлүүд болон тодорхойлогдсон улс орчинд суралцаж байгаа ч хэл загвар нь текст дээр л сургал Энэ алдагдсан туршлагын зарим хэл загваруудыг баян авч үзэхийн тулд бид хоёр мэдээллийн эх үүсвэрийг ашигладаг: (1) Ланкастер сэтгэл хөдлөлийн нормууд нь 40,000 гаруй англи хэлний хэмжээсүүдийн хэмжээсүүдийг ашиглаж, 11 өөр мэдрэмжтэй байдлаар ямар нэгэн зүйл туршлагдсан талаар ашигладаг БЕРТ үгийн зураг дээр сургалтын хоёр дахь классификаторын коэффициентүүдийн векторууд. Бид ELECTRA загварыг урьд суралцаж, RoBERTa загварыг эдгээр хоёр мэдээллийн эх үүсвэртэй тодорхойлож, тэгээд GLUE багц болон Visual Dialog багц ашиглан үнэлэх болно. Бид Ланкастер нормууд болон зураг векторуудын хэл загваруудыг багасгах нь хоёр даалгаварын үр дүнг улам сайжруулж, хэл суралцах нөхцөлд бүрэн хэл загваруудын зарим нөлөөлөлт гаргадаг.', 'no': 'Språk- modeller vert berre trengte på tekst, selv om at mennesker lærer den første språket sine i eit svært interaktiv og multimodal miljø der det første settet av lærte ord er stort beton, som viser fysiske einingar og inkluderte tilstandar. For å rykke språk-modeller med nokre av denne manglande opplevelsen, leverer vi to kjelde for informasjon: (1) Lancaster Sensorimotor-normalane, som tilbyr rating (betyr og standard avvik) for over 40.000 engelske ord langs fleire dimensjonar av innbygging, og som tar inn kor mykje noko er opplevert i 11 forskjellige sensoremodusar, og (2) vektorar frå koeffisienten av binærklassifiserar som trengte på bilete for BERT- ordboka. Vi har forelært ELECTRA-modellen og fint opp RoBERTa-modellen med desse to kjeldene for informasjon, og deretter evaluer ved hjelp av den oppretta GLUE-benchmarken og den visuelle dialogbenchmarken. Vi finn at røyking av språk-modeller med Lancaster-normalar og biletvektorene forbedrar resultatet i begge oppgåver, med nokre implikasjonar for sterke språk-modeller som inneholder holistisk språk-mening i eit språk-læringskontekst.', 'pl': 'Modele językowe są trenowane tylko na tekście pomimo faktu, że ludzie uczą się języka pierwszego w bardzo interaktywnym i multimodalnym środowisku, w którym pierwszy zestaw nauczonych słów jest w dużej mierze konkretny, oznaczający istoty fizyczne i stany ucieleśnione. Aby wzbogacić modele językowe o niektóre z tych brakujących doświadczeń, wykorzystujemy dwa źródła informacji: (1) normy Lancaster Sensoromotor, które zapewniają oceny (średnie i standardowe odchylenia) dla ponad 40.000 angielskich słów wzdłuż kilku wymiarów wcielenia i które uwzględniają stopień, w jakim coś jest doświadczane w 11.różnych modalnościach sensorycznych, i (2) wektorów ze współczynników klasyfikatorów binarnych przeszkolonych na obrazach dla słownictwa BERT. Przeszkololiśmy model ELECTRA i dostroiliśmy model RoBERTa z tymi dwoma źródłami informacji, a następnie oceniliśmy przy użyciu ustalonego standardu GLUE i standardu Visual Dialog. Stwierdzono, że wzbogacanie modeli językowych o normy Lancaster i wektory obrazu poprawia wyniki w obu zadaniach, z pewnymi konsekwencjami dla solidnych modeli językowych, które uchwycałościowe znaczenie językowe w kontekście nauki języka.', 'si': 'භාෂා මොඩල් පාළුවේ විතරයි මිනිස්සු ඔවුන්ගේ පළමු භාෂාව ඉගෙන ගන්න බැරි විතරයි. මුලින් ඉගෙන ගන්න පුළුවන් භාෂාවක් වගේම ඉග මේ අතුරුදන් අවස්ථාවක් වලින් භාෂා මොඩල් එක්ක සමහර දෙයක් තියෙන්න, අපි ලැන්කාස්ටර් සෙන්සෝරිමෝටර් නෝර්ම්ස් වලින් දෙන්න පුළුවන් කරනවා: (1) ලැන්කාස්ටර් සෙන්සෝ BERT භාෂාවිකාරය සඳහා පින්තූර සඳහා පින්තූරයේ බායිනාරි ක්\u200dරීසිකරුවන්ගේ සම්බන්ධ වෙක්ටර් වලින අපි ELECTRA මදුල්ය සහ RoBERTa මදුල්ය සමග මේ තොරතුරු දෙකක් සඳහා ප්\u200dරධානය කළා ඊට පස්සේ ස්ථාපිත GLUE බෙන්ච්මාර්ක් සහ ප්\u200dරධාන සංවාද අපි හොයාගන්නවා ලැන්කාස්ටර් නෝර්ම්ස් සහ පින්තූර වෙක්ටර්ස් එක්ක භාෂා මොඩේල්ස් එක්ක විශේෂ කරනවා දෙන්නම් වෙක්ටර්ස් එක්ක,', 'ro': 'Modelele lingvistice sunt instruite numai pe text, în ciuda faptului că oamenii învață prima limbă într-un mediu foarte interactiv și multimodal, unde primul set de cuvinte învățate sunt în mare măsură concrete, denotând entități fizice și stări întrupate. Pentru a îmbogăți modelele lingvistice cu o parte din această experiență lipsă, valorificăm două surse de informație: (1) Normele senzorimotor Lancaster, care oferă evaluări (mijloace și abateri standard) pentru peste 40.000 de cuvinte engleze de-a lungul mai multor dimensiuni ale întruchipării, și care surprind măsura în care ceva este experimentat în 11 moduri senzoriale diferite, și (2) vectori din coeficienții clasificatorilor binari instruiți pe imagini pentru vocabularul BERT. Am pre-instruit modelul ELECTRA și am ajustat modelul RoBERTa cu aceste două surse de informații, apoi am evaluat utilizând benchmark GLUE stabilit și benchmark Visual Dialog. Considerăm că îmbogățirea modelelor lingvistice cu normele Lancaster și vectorii de imagine îmbunătățește rezultatele în ambele sarcini, cu unele implicații pentru modele lingvistice robuste care capturează semnificația lingvistică holistică într-un context de învățare a limbilor străine.', 'sr': 'Jezikovi modeli su obučeni samo na tekstu, uprkos činjenici da ljudi uče svoj prvi jezik u veoma interaktivnom i multimodalnom okruženju gde su prvi skup učenih reči u velikoj meri konkretni, označavajući fizičke entitete i inkodirane države. Da bismo obogatili jezičke modele sa nekim od ovog nedostajalog iskustva, iskorištavali smo dve izvore informacija: 1) norme Lancastera Sensorimotora, koje pružaju ocjene (sredstva i standardne devijacije) za preko 40.000 engleskih riječi duž nekoliko dimenzija prevođenja, i koje hvataju koliko je nešto iskusilo u 11 različitih senzornih modaliteta, i (2) vektori od koeficijenta binarnih klasifikatora obučenih na slikama za rečnik BERT. Pretrenirali smo model ELECTRA i finalizirali model RoBERTa sa ovim dva izvora informacija, zatim procjenjivali korištenje uspostavljenog kritika GLUE i kritika vizuelnog dijaloga. Nalazimo da bogatstvo jezičkih modela sa Lancasterskim normom i vektorima slika poboljšava rezultate obe zadatke, sa nekim implikacijom za robne jezičke modele koji uključuju holističko jezičko značenje u kontekstu učenja jezika.', 'ur': 'زبان موڈل صرف متن پر آموزش کی جاتی ہیں حالانکہ انسانوں نے اپنی پہلی زبان کو ایک بہت اہم اور بہت سی موڈال محیط میں سکھایا ہے جہاں پہلی سیکھی زبانوں کا مجموعہ اکثر قطعی ہے، فیزیکی موجودات اور پیدا ہوئی موجودات کا ذکر کرتا ہے. اس گم ہونے کی تجربہ کے ساتھ زبان کی مدلکوں کو ثروت دینے کے لئے، ہم دو منبع معلومات کے استعمال کرتے ہیں: (1) لنکستار سنسوریموٹر کے نوروں میں، جو 40,000 انگلیسی کلمات کے زیادہ اندازے سے زیادہ انگلیسی کلمات کے لئے راتینگ (معلومات اور استاندارڈ تبدیل) دیتے ہیں، اور جو کئی اندازے کے ساتھ کئی معلومات کے BERT vocabulary کے لئے تصاویروں پر آموزش کی جاتی ہے بیناری کلاسیر کے کفائدٹوں سے اور (2) ویکتور۔ ہم نے ELECTRA موڈل کو پہلے تطالب کیا اور روBERTa موڈل کو ان دو منبع معلومات کے ساتھ ٹھیک تطالب کیا پھر اس کے ذریعہ مطالب GLUE بنچم مارک اور Visual Dialog benchmark کے مطالب مطالب کیا۔ ہم دیکھتے ہیں کہ لانکستر کے نورموں اور تصویر ویکتروں کے ساتھ زبان مدلکوں کو ثروت دینے کا نتیجہ دونوں کاموں میں بہتر ہوتا ہے، اور بہترین زبان مدلکوں کے لئے بہترین اثرات کے ساتھ جو ایک زبان سکھانے کے منظور میں تعلیم زبان کی معنی کو پکڑتے', 'so': "Tusaalada luuqadda waxaa lagu baraa qoraal keliya, inkastoo ay dadku afkooda ugu horeeyo ku baraan deegaan aad u faa’iido leh oo kala duduwan, kuwaas oo ay marka ugu horeysa hadal baran yihiin mid aad u adag, waxyaabaha jimicsiga ah ku qoran iyo dowlada aad u saxeysan. Si aan u hodanayno noocyada afka ah qaar ka mid ah aragtidan la'aanta, waxaan u soo dirnaa laba soul oo macluumaad ah: (1) qaybaha Sensorimotor ee Lancaster, kaas oo bixiya heerarka (micnaheedu iyo qalloocnaanta standardka) oo ugu badnaan 40,000 hadal ingiriisiisiga ah oo ku qoran kooxo kala duduwan, waxaana qabsan darajada ay wax ku taabtay 11 noocyo oo kala duduwan, iyo (2) vectors oo ka mid ah kooxaha labada fasax oo lagu baray sawirro ku qoran hadalka BERT. Tusaalada ELECTRA horay ayaannu ku tababarnay, waxaana ku hagnay modelkii RoBERta, waxaana ku qiimeynay labadan sourceed oo macluumaad ah kadibna isticmaalnay bangiga GLUE iyo bandhigga aragtida. Waxaynu helnaa in lagu hodanayo qaababka afka ee Lancaster iyo waddooyinka sawirku ay u bedeshaan shaqada labadooda, waxaana laga helaa qaar saameyn ku leh tusaalaha afka la dhacay oo ay ku qabsadaan micneheeda afka hooliga ah oo ku qoran barashada afka.", 'ta': 'மொழி மாதிரிகள் மட்டுமே உரையில் பயிற்சி செய்யப்படுகிறது ஆனால் மனிதர்கள் முதல் மொழியை மிக இடைவெளிப்படுத்தும் பல்வேறு சூழலிலும் கற்றுக் கொள்கிறார்கள இந்த காணவில்லாத அனுபவத்தில் மொழி மாதிரிகளை வளர்ச்சி செய்வதற்கு, நாம் தகவல் மூலம் இரண்டு மூலங்களை வழங்குகிறோம்: (1) லான்காஸ்டர் சென்ஸர்மோடர் விதிகள், அது 40,000 க்கு மேற்பட்ட ஆங்கிலத்திற்கு (அர பிரெட் சொல்வளத்திற்கான பிம்பங்களில் பயிற்சி செய்யப்பட்ட இரு வகுப்பாளர்களின் குணங்களில் இருந்து வெக்டார்கள். நாங்கள் முன் பயிற்சி ELECTRA மாதிரி மற்றும் நன்றாக ரோபெர்டா மாதிரி இந்த இரண்டு தகவல் மூலங்களை கொண்டு சரியாக்கி பின்னர் நிறுவப்பட்ட GLUE பென்ந்த நாம் கண்டுபிடிக்கிறோம் லான்காஸ்டர் இயல்புகள் மற்றும் பிம்பத்தின் வெக்டார்களுடன் மொழி மாதிரிகளை வளர்ச்சி செய்வது, இரு பணிகளுக்கும் மேலும் முடிவ', 'sv': 'Språkmodeller tränas endast på text trots att människor lär sig sitt första språk i en mycket interaktiv och multimodal miljö där den första uppsättningen av lärda ord till stor del är konkreta, betecknar fysiska entiteter och förkroppsligade tillstånd. För att berika språkmodeller med en del av denna saknade erfarenhet utnyttjar vi två informationskällor: (1) Lancaster Sensorimotor normer, som ger betyg (medel och standardavvikelser) för över 40 000 engelska ord längs flera dimensioner av förkroppsligande, och som fångar i vilken utsträckning något upplevs över 11 olika sensoriska modaliteter, och (2) vektorer från koefficienter av binära klassificerare utbildade på bilder för BERT ordförråd. Vi förberedde ELECTRA-modellen och finjusterade RoBERTa-modellen med dessa två informationskällor och utvärderade sedan med hjälp av det etablerade GLUE-riktmärket och Visual Dialog-riktmärket. Vi finner att berikande språkmodeller med Lancasters normer och bildvektorer förbättrar resultaten i båda uppgifterna, med vissa implikationer för robusta språkmodeller som fångar holistisk språklig betydelse i en språkinlärningskontext.', 'uz': "Language models are trained only on text despite the fact that humans learn their first language in a highly interactive and multimodal environment where the first set of learned words are largely concrete, denoting physical entities and embodied states.  Bu yo'q tajriba bilan tillar modellarini ko'paytirish uchun biz ikkita maʼlumot manbasiga yordam qilamiz: (1) Lancaster Sensorimotor qoidalarini qo'shish, bu bir necha xil paytlarda 40,000 dan ortiq so'zlar (ma'noda va standard deviations) ga ega bo'ladi, va bu bir necha xil sohalarda bir necha xil bo'lgan narsalarni qabul qiladi va 11 boshqa sensori usullarda bir (2) va BERT vositasi uchun rasmlar uchun o'rganilgan ikkita klassiflarning foydalanuvchidan foydalanuvchilar. Biz ELECTRA modelini oldin o'rganib, RoBERTA modelini uning ikkita maʼlumot manbasiga yordam berdik, keyin quyidagi GLUE benchmark va Visual Dialog benchmark yordamida qiymat qilamiz. Biz o'ylaymiz, Lancaster qoidalari va rasm vektorlari bilan tillar modellarini ko'paytirish mumkin, bu ikkita vazifalarning natijalarini bajaradi. Bu tilni o'rganish muvaffaqiyatlarida o'xshash tillar modellarini o'zgartiradi.", 'vi': 'Các mô hình ngôn ngữ chỉ được đào tạo về văn bản mặc dù con người học ngôn ngữ đầu tiên trong một môi trường tương tác và đa phương, nơi những từ học đầu tiên rất cụ thể, chỉ ra các thực thể và các bang được nhập cảnh. Để làm giàu các mô hình ngôn ngữ bằng một số kinh nghiệm thiếu sót này, chúng ta dùng hai nguồn thông tin: 1) các tiêu chuẩn Nhạy Cảm Lancaster, cung cấp bảng xếp hạng (phương tiện và độ lệch tiêu chuẩn) cho hơn 400,000 từ Anh ngữ theo nhiều chiều hướng nhập, và nắm bắt độ lớn kinh nghiệm của một vật thể trải qua 11 khác nhau các phương thức cảm xúc, và (2) véc- tơ từ hiệu ứng các phân loại nhị phân được đào tạo trên ảnh cho từ vựng sót của BERT. Chúng tôi đã được đào tạo kỹ thuật cho mô hình ECU và chỉnh lại mô hình RoennTa với hai nguồn thông tin này rồi đánh giá bằng tiêu chuẩn GLUE đã được xác định và tiêu chuẩn Hộp thoại Sinh động. Chúng tôi thấy việc bổ sung các mô hình ngôn ngữ với các tiêu chuẩn Lancaster và các phương trình hình ảnh sẽ cải thiện kết quả của cả hai nhiệm vụ, với một số ảnh hưởng đến mô hình ngôn ngữ vững chắc, thu thập các nghĩa về ngôn ngữ về các ngữ ở ngữ ngữ học ngữ.', 'hr': 'Jezikovi modeli su obučeni samo na tekstu uprkos činjenici da ljudi uče svoj prvi jezik u veoma interaktivnom i multimodalnom okruženju gdje su prvi skup učenih riječi u velikoj mjeri betonski, navodi fizičke entitate i uključene države. Za bogate jezičke modele s nekim od ovog nedostajalog iskustva, primjenjujemo dvije izvore informacija: 1) norme Lancastera Sensorimotora, koje pružaju ocjene (sredstva i standardne odstupanje) za preko 40.000 engleskih riječi duž nekoliko dimenzija proizvoda, i koje uhvate mjeru u kojoj je nešto iskusilo u 11 različitih senzornih modaliteta, i (2) vektori od koeficijenata binarnih klasifikatora obučenih na slikama za riječnik BERT-a. Pretrenirali smo model ELECTRA i finalizirali model RoBERTa s ovim dva izvora informacija, a zatim procjenjivali korištenjem utvrđenog kritika GLUE-a i kritika vizuelnog dijaloga. Nalazimo da bogatstvo jezičkih modela sa Lancasterskim normom i vektorima slika poboljšava rezultate obje zadatke, s nekim implikacijom za jače jezičke modele koji uključuju holističko jezičko značenje u kontekstu učenja jezika.', 'bg': 'Езиковите модели се обучават само върху текст, въпреки факта, че хората научават първия си език в силно интерактивна и мултимодална среда, където първите научени думи са до голяма степен конкретни, означаващи физически същности и въплътени състояния. За да обогатим езиковите модели с част от това липсващо преживяване, използваме два източника на информация: (1) сензоримоторните норми на Ланкастър, които предоставят оценки (средства и стандартни отклонения) за над 40 000 английски думи в няколко измерения на въплъщението и които улавят степента, до която нещо се преживява в 11 различни сетивни модали, и (2) вектори от коефициенти на двоични класификатори, обучени върху изображения за речника на BERT. Предварително обучихме модела и финализирахме модела с тези два източника на информация, след което оценихме с помощта на установения показател и показателя за визуален диалог. Установяваме, че обогатяването на езиковите модели с нормите на Ланкастър и векторите на изображенията подобрява резултатите и при двете задачи, с някои последици за стабилни езикови модели, които улавят холистично лингвистично значение в контекста на езиковото обучение.', 'nl': 'Taalmodellen worden alleen getraind op tekst ondanks het feit dat mensen hun eerste taal leren in een zeer interactieve en multimodale omgeving waar de eerste set van geleerde woorden grotendeels concreet is, wat fysieke entiteiten en belichaamde staten aangeeft. Om taalmodellen te verrijken met een deel van deze ontbrekende ervaring, maken we gebruik van twee bronnen van informatie: (1) de Lancaster Sensormotor normen, die ratings (gemiddelde en standaardafwijkingen) bieden voor meer dan 40.000 Engelse woorden langs verschillende dimensies van belichaming, en die de mate vastleggen waarin iets wordt ervaren in elf verschillende zintuiglijke modaliteiten, en (2) vectoren uit coëfficiënten van binaire classificatoren getraind op afbeeldingen voor de BERT-woordenschat. We hebben het ELECTRA-model vooraf getraind en het RoBERTa-model verfijnd met deze twee informatiebronnen en vervolgens geëvalueerd met behulp van de gevestigde GLUE benchmark en de Visual Dialog benchmark. We vinden dat het verrijken van taalmodellen met de Lancaster normen en beeldvectoren de resultaten in beide taken verbetert, met enkele implicaties voor robuuste taalmodellen die holistische linguïstische betekenis vastleggen in een taalleercontext.', 'da': 'Sprogmodeller trænes kun på tekst på trods af, at mennesker lærer deres første sprog i et meget interaktivt og multimodalt miljø, hvor det første sæt af lærte ord i vid udstrækning er konkrete, hvilket angiver fysiske enheder og legemliggjorte tilstande. For at berige sprogmodeller med nogle af disse manglende erfaringer, udnytter vi to kilder til information: (1) Lancaster Sensorimotor normer, som giver ratings (midler og standardafvigelser) for over 40.000 engelske ord langs flere dimensioner af legemliggørelse, og som fanger omfanget af, hvorvidt noget opleves på tværs af 11 forskellige sensoriske modaliteter, og (2) vektorer fra koefficienter af binære klassificerere uddannet på billeder til BERT ordforråd. Vi forududdannede ELECTRA modellen og finjusterede RoBERTa modellen med disse to informationskilder og evaluerede derefter ved hjælp af den etablerede GLUE benchmark og Visual Dialog benchmark. Vi finder ud af, at berigelse af sprogmodeller med Lancaster normer og billedvektorer forbedrer resultaterne i begge opgaver, med nogle implikationer for robuste sprogmodeller, der fanger holistisk sproglig betydning i en sprogindlæringskontekst.', 'id': 'Model bahasa hanya dilatih pada teks meskipun manusia belajar bahasa pertama mereka dalam lingkungan yang sangat interaktif dan multimodal di mana set pertama kata-kata belajar adalah kebanyakan konkrit, menunjukkan entitas fisik dan negara-negara terbentuk. Untuk memperkaya model bahasa dengan beberapa pengalaman yang hilang ini, kami menggunakan dua sumber informasi: (1) norma Sensorimotor Lancaster, yang menyediakan nilai (nilai dan deviasi standar) untuk lebih dari 40.000 kata Inggris sepanjang beberapa dimensi embodimensi, dan yang menangkap jangkauan yang sesuatu mengalami melalui 11 modalitas sensor yang berbeda, / dan (2) vektor dari koeficien dari klasifikasi binari dilatih pada gambar untuk vokbulari BERT. Kami melatih model ELECTRA dan memperbaiki model RoBERTa dengan dua sumber informasi ini kemudian mengevaluasi menggunakan benchmark GLUE yang ditetapkan dan benchmark Dialog Visual. Kami menemukan bahwa model bahasa yang kaya dengan norma Lancaster dan vektor gambar memperbaiki hasil dalam kedua tugas, dengan beberapa implikasi untuk model bahasa yang kuat yang menangkap arti bahasa holistik dalam konteks belajar bahasa.', 'ko': '언어 모델은 텍스트만을 대상으로 훈련한다. 비록 인류가 고도의 상호작용과 다중모드적 환경에서 제1언어를 학습하지만 그 중에서 제1조가 학습한 단어는 기본적으로 구체적이고 물리적 실체와 구체적인 상태를 나타낸다.이러한 부족한 경험을 바탕으로 풍부한 언어 모델을 사용하기 위해 우리는 두 가지 정보원을 이용했다. (1) 란케이스터 감각 운동 규범은 4만여 개의 영어 단어가 여러 차원에서 평가(평균치와 기준차)를 제공하고 11가지 서로 다른 감각 모델의 체험 정도를 포착했다.그리고 (2) 이미지에서 훈련된 2치 분류기 계수의 벡터로 버트 어휘표에 사용된다.우리는 ELECTRA 모델을 미리 훈련시키고 이 두 가지 정보원을 사용하여 RoBERTA 모델을 미세하게 조정한 다음에 이미 세워진 GLUE 기준과 Visual Dialog 기준을 사용하여 평가했다.우리는 란체스터 규범과 이미지 벡터로 풍부한 언어 모델을 활용하면 이 두 가지 임무를 개선할 수 있다는 결과를 발견했고 언어 학습 환경에서 전체적인 언어 의미를 포착하는 안정적인 언어 모델에 대해 어느 정도 시사점을 주었다.', 'fa': 'مدلهای زبان تنها بر متن آموزش داده می شوند، با وجود اینکه انسان اولین زبان خود را در یک محیط بسیار متفاوت و بسیار متفاوت یاد می گیرند که اولین مجموعه کلمات یاد گرفته بسیار قطعی هستند، که متفاوت فیزیکی و ایالت\u200cهای متفاوت می\u200c برای توانگری از مدلهای زبان با بعضی از این تجربه گم شده، دو منبع اطلاعات را تغییر می دهیم: (۱) نورمهای سنسوریموتور لنکستر، که برای بیش از ۴۰ هزار کلمه انگلیسی در طول بعضی اندازه\u200cهای انگلیسی تحریک می\u200cکنند، و به اندازه\u200cای که چیزی در ۱۱ modalities sensory مختلف تجربه می\u200cشود، و (۲) ویکتورها از تعداد\u200cهای مختصات دوگانی که روی تصاویر واژه BERT آموزش داده شده\u200cاند. ما مدل ELECTRA را پیش آموزش دادیم و مدل RoBERTa را با این دو منبع اطلاعات با استفاده از نقشه\u200cهای GLUE و نقشه\u200cی صندوق دیدگاه\u200cهای بینایی ارزیابی کردیم. ما پیدا می\u200cکنیم که دارای مدل\u200cهای زبانی با نورمهای لنکستر و ویکتورهای تصویر نتیجه\u200cهای هر دو کار را بهتر می\u200cکند، با بعضی اثرات برای مدل\u200cهای قوی زبانی که معنی زبان\u200cشناسی holistic را در یک محیط یادگیری زبان می\u200cگیرند.', 'sw': 'Mradi wa lugha unafundishwa kwa ujumbe tu wa maandishi licha ya ukweli kwamba binadamu wanajifunza lugha yao ya kwanza katika mazingira yenye ushirikiano mkubwa na yenye mazingira mengi ambapo seti ya kwanza ya maneno yanayojifunza ni ya ushirikiano mkubwa, ikisitiza vitu vya kimwili na vinavyofungwa. Kutajirisha mifano ya lugha kwa baadhi ya uzoefu huu ambao hauonekani, tunatumia vyanzo viwili vya habari: (1) utaratibu wa Sensorimotor wa Lancaster, ambao unatoa ratiba (maana na mabadiliko ya kiwango cha kawaida) kwa zaidi ya maneno ya Kiingereza 40,000 pamoja na maeneo kadhaa ya udhibiti huo, na unachukua kiwango ambacho kinapitiwa katika njia 11 tofauti za hisia, na vectori kutoka kwa ufanisi wa wataalamu wawili waliofundishwa kwenye picha kwa ajili ya maneno ya BERT. Tulimifundisha modeli ya ELECTRA na tukampa mtindo mzuri wa RoBERTa kwa kutumia vyanzo hivi viwili vya habari na baadae kutathmini kwa kutumia bendera iliyoanzishwa na GLUE pamoja na bendera ya Mazungumzo ya Visual Dialog. Tunapata utajiri wa mifano ya lugha kwa utamaduni wa Lancaster na vectors za picha huboresha matokeo ya kazi zote, na baadhi ya madhara ya mifano ya lugha yanayochapisha maana ya lugha yenye utamaduni wa kitaifa katika muktadha wa kujifunza lugha.', 'de': 'Sprachmodelle werden nur auf Text trainiert, obwohl Menschen ihre Muttersprache in einer hoch interaktiven und multimodalen Umgebung lernen, in der die ersten erlernten Wörter weitgehend konkret sind und physische Einheiten und verkörperte Zustände bezeichnen. Um Sprachmodelle mit etwas dieser fehlenden Erfahrung zu bereichern, nutzen wir zwei Informationsquellen: (1) die Lancaster Sensormotorik Normen, die Bewertungen (Mittel und Standardabweichungen) für über 40.000 englische Wörter entlang mehrerer Dimensionen der Verkörperung liefern und die das Ausmaß erfassen, in dem etwas über elf verschiedene sensorische Modalitäten erfahren wird. und (2) Vektoren aus Koeffizienten binärer Klassifikatoren, die auf Bildern für das BERT-Vokabular trainiert wurden. Wir haben das ELECTRA-Modell vortrainiert und das RoBERTa-Modell mit diesen beiden Informationsquellen fein abgestimmt und anschließend anhand des etablierten GLUE Benchmarks und des Visual Dialog Benchmarks ausgewertet. Wir finden, dass die Anreicherung von Sprachmodellen mit den Lancaster Normen und Bildvektoren die Ergebnisse in beiden Aufgaben verbessert, mit einigen Implikationen für robuste Sprachmodelle, die ganzheitliche linguistische Bedeutung in einem Sprachlernkontext erfassen.', 'af': "Taal-modelles word slegs op teks opgelei, behalwe die feit dat mense hul eerste taal leer in 'n baie interaktief en multimodaal omgewing waar die eerste stel van geleerde woorde groot beteken is, wat fysiske entiteite en embodieerde staatste vertoon word. Om te ryk taal modele met sommige van hierdie ontbrekende erfaring, laat ons twee bronne van inligting: (1) die Lancaster Sensorimotor-norms, wat ratings (beteken en standaard afwysings) verskaf vir meer 40,000 Engelske woorde langs verskeie dimensies van inprop, en wat die uitbreiding vervang waar iets deur 11 verskeie sensoremodualiteite verskaf word, En (2) vektore van koeffisientes van binêre klassifiseerders wat op beelde gelei is vir die BERT woordeboek. Ons het die ELECTRA model vooraf opgelei en die RoBERTa model met hierdie twee bronne van inligting gevind en dan evalueer met die gebruik van die geïnstalleerde GLUE benchmark en die Visuele dialoog benchmark. Ons vind dat die verrykking van taal modele met die Lancaster norme en beeldvektore verbeter resultate in beide opdragte, met sommige inplikasies vir robust taal modele wat holistiese lingvisiese betekening in 'n taal leer konteks opneem.", 'tr': 'Dil modelleri insanlar ilkinji dillerini örän etkileşimli we multimodal ortamda öwrenip biljek mektuplarda diňe tekst üzerinde eğitilýärler. Bu ýerde ilkinji gezek beter konkretdir, fiziksel zatlary we biçimlenmiş döwletleri bölýärler. Bu ýok tejribeleriň birnäçesi bilen baý dil nusgalaryny baglaşdyrmak üçin, iki daşlyk bilen dowam edýäris: (1) Lancaster Sensorimotor normlaryny, 40,000 iňlis sözleriniň birnäçe ölçüsi bilen tejribe edip duran ýagdaýyny ýagdaýlaýarlar we 11 dürli duýdury ýagdaýynda nähili bir zat tarapýarlar, BERT sözleri üçin resimlerde eğitilen binali klasifikatlardan (2) vektörler. Biz ELECTRA nusgasyny öňünden eğitip, RoBERTa nusgasyny bu iki çeşme malümaty bilen dyrypdyk we soňra gürrüň kaynaklygyny we görsel dialogyň kaynaklygyny ulanmakdan çykar. Lancaster normlary we surat vektörleri bilen dil nusgalaryny baýlayan şeklinde bilim öwrenmegi kontekstinde tutan güýçli dil nusgalarynyň käbir täsiri bilen gowylaşdyrýar.', 'sq': 'Modelet gjuhësore janë trajnuar vetëm në tekst pavarësisht nga fakti se njerëzit mësojnë gjuhën e tyre të parë në një mjedis shumë interaktiv dhe multimodal ku grupi i parë i fjalëve të mësuara janë kryesisht konkrete, duke treguar njësi fizike dhe shtete të përfshira. Për të pasuruar modelet gjuhësore me disa nga këto përvojë të munguara, ne përdorim dy burime informacioni: (1) normat e Sensorimotorit Lankaster, që ofrojnë vlerësime (mjete dhe devijime standarde) për mbi 40,000 fjalë angleze përgjatë disa dimensioneve të embodimentit dhe që kapin shkallën në të cilën diçka përjetohet në 11 modalitete të ndryshme sensore, - dhe (2) vektorë nga koeficientet e klasifikuesve binarë të trajnuar në imazhe për fjalorin BERT. Ne paratrajnuam modelin ELECTRA dhe rregulluam modelin RoBERTa me këto dy burime informacioni dhe pastaj vlerësojmë duke përdorur referencën e vendosur GLUE dhe referencën e dialogut vizual. Ne zbulojmë se pasurimi i modeleve gjuhësore me normat Lancaster dhe vektorët e imazhit përmirëson rezultatet në të dy detyrat, me disa pasoja për modele të forta gjuhësh që kapin kuptimin gjuhësor holistik në një kontekst mësimi gjuhësh.', 'bn': 'ভাষার মডেল শুধুমাত্র টেক্সটে প্রশিক্ষণ প্রদান করা হয়েছে যদিও মানুষ তাদের প্রথম ভাষায় তাদের প্রথম ভাষা শিক্ষা প্রদান করে একটি অত্যন্ত সক্রিয় এবং বহুবিধা এই অনুপস্থিত অভিজ্ঞতার মাধ্যমে ভাষার মডেল সমৃদ্ধ করার জন্য আমরা দুটি তথ্য প্রদান করি: (১) ল্যাঙ্কাস্টার সেন্সরিমোটর নীতি প্রদান করি, যার মানে ৪০,০০০ বেশী ইংরেজী শব্দের বিভিন্ন ভাষায় বিভি এবং (২) ভেক্টর বাইনারি শ্রেণীবিভাষার জন্য ছবিগুলোতে প্রশিক্ষণ প্রদান করা হয়েছে। আমরা ELECTRA মডেল প্রশিক্ষণ পূর্বে প্রশিক্ষণ দিয়েছিলাম এবং রোবের্তা মডেলের সুন্দর করেছিলাম এই দুটি তথ্যের সূত্র দিয়ে, তারপর স্থাপন করা গ্লোবালুয়ের বে আমরা দেখতে পাচ্ছি যে ল্যাঙ্কাস্টারের নীতি এবং ছবি ভেক্টর দ্বারা ভাষার মডেল সমৃদ্ধ করার ফলে উভয় কাজের ফল উন্নত হয়, যার ফলে ভাষার মোডেলের কিছু প্রভাব রয়েছে যা', 'am': 'የቋንቋ ዓይነቶች ብቻ በመጽሐፍ ተማሪዎች ናቸው፤ ሰው የፊተኛውን ቋንቋ ቋንቋቸውን በብዙ ተማሪ እና በብዛት ተማሪ አካባቢ እና የተማሩ ቃላት አብዛኛዎቹ የሚቆጠሩ፣ የሥጋዊ አካል አካላትን እና የክፍለ ሀገራት አካባቢ ነው፡፡ ከዚህም አንዳንዱ የጠፋውን የቋንቋ ምሳሌዎች ለማብረቅ፣ ሁለት የመረጃ ምንጮች አሰራጅተናል:(1) ለላንካስር ሰንሰርቨር ትምህርት (ማድረግ እና standard deviation) ለ40,000 የኢንጂል ቃላት በብዙ ክፍል በተለየ ብዛት እና በ11 ልዩ ልዩ ልዩ ዓይነቶች ላይ የተመሳሰለውን ክፍሎች ያሳያል፡፡ እና (2) vectors from binary classifiers to the BERT vocabulary. የELECTRA ሞዴል አስቀድመን ባስተማርነው የሮብERTA ሞዴል በሁለቱ የመረጃ ምንጮች እና የGLUE benchmark እና የVisual Dialog benchmark በመጠቀም አስተዋልነው፡፡ በቋንቋ ምሳሌዎች እና የምስል መንገዶች ውስጥ የቋንቋ ምሳሌዎችን ማሳየት እና በቋንቋ ትምህርት ትምህርት ውስጥ የቋንቋን ትምህርት ማድረግ የሚያስፈልገውን እናገኛለን፡፡', 'bs': 'Jezikovi modeli su obučeni samo na tekstu, uprkos činjenici da ljudi uče svoj prvi jezik u veoma interaktivnom i multimodalnom okruženju gdje su prvi skup učenih riječi u velikoj mjeri konkretni, označavajući fizičke entitete i uključene države. Da bismo obogatili jezičke modele s nekim od ovog nedostajalog iskustva, privlačili smo dvije izvore informacija: 1) norme Lancastera Sensorimotora, koje pružaju ocjene (sredstva i standardne devijacije) za preko 40.000 engleskih riječi duž nekoliko dimenzija prevođenja, i koje uhvate mjeru u kojoj je nešto iskusilo u 11 različitih senzornih modaliteta, i (2) vektori iz koeficijenta binarnih klasifikatora obučenih na slikama za rečnik BERT-a. Pretrenirali smo model ELECTRA i finalizirali model RoBERTa sa ovim dva izvora informacija, a zatim procjenjivali korištenje utvrđenog kritike GLUE i kritike vizuelnog dijaloga. Nalazimo da bogatstvo jezičkih modela sa Lancasterskim normom i vektorima slika poboljšava rezultate u obje zadatke, s nekim implikacijom za robne jezičke modele koji uključuju holističko jezičko značenje u kontekstu učenja jezika.', 'az': 'Dil modelləri ancaq mətn üzərində təhsil edilir. İnsanların ilk dilini çox interaktiv və çoxlu modal ortamda öyrəndiklərinə baxmayaraq, ilk öyrənmiş sözlərin çox konkreti, fiziki entitələri və mövcud durumları belə təhsil edirlər. Bu qeyb təcrübələrindən bəzisini zəngin dil modellərini artırmaq üçün, iki məlumatın mənbəsini təmin edirik: 1) Lancaster Sensorimotor normalarını təmin edir ki, 40.000 İngilizə sözlərinin çox ölçüləri ilə birlikdə 40.000-dən artıq İngilizə sözlərini təmin edir, və bunlar 11 farklı sensor modalitələrində bir şey təcrübə edir. BERT sözləri üçün şəkillərdə təhsil edilmiş binar klasifikatçıların koeficientlərindən və (2) vektorilər. Biz ELECTRA modelini əvvəl təhsil etdik və RoBERTa modelini bu iki məlumat kaynaqları ilə düzəltdik və sonra qurulmuş GLUE benchmark və Görünül Dialog benchmark vasitəsilə təhsil etdik. Biz Lancaster normları və görüntü vektörləri ilə dil modellərini genişləndirmək hər iki işin sonuçlarını yaxşılaşdırır, dil öyrənməsi məqsədilində holistik dil modellərinin bəzi implikasları ilə istifadə edir.', 'hy': 'Լեզու մոդելները կրթություն են ստանում միայն տեքստի վրա, չնայած այն փաստին, որ մարդիկ սովորում են իրենց առաջին լեզուն բարձր ինտերակտիվ և բազմամոդալ միջավայրում, որտեղ սովորված բառերի առաջին խումբը հիմնականում բնական է, որը նշանակում է ֆի Այս բացակայած փորձից որոշ լեզվի մոդելներ հարստացնելու համար մենք օգտագործում ենք տեղեկատվության երկու աղբյուրներ: 1) Լանկաստերի սենսորիմոտորի նորմերը, որոնք տրամադրում են գնահատականներ (միջոցներ և ստանդարտ շեղումներ) ավելի քան 40,000 անգլերեն բառերի համար ներգրավման մի քանի չափերի ընթացքում, և որոնք ներկայացնում են այն չափը - և (2) վեկտորները BER բառարանի նկարների վրա վարժեցված երկու դասակարգչի կոեֆեկցիոններից: Մենք նախապատրաստում էինք ELLECT-ի մոդելը և բարելավում էինք Ռոբերթայի մոդելը այս երկու տեղեկատվության աղբյուրներով, հետո գնահատում էինք օգտագործելով հիմնված GLUE-ի հարաբերականը և Վիզուալ դասախոսության հարաբերականը: Մենք հայտնաբերում ենք, որ Լանկաստերի նորմերի և պատկերների վեկտորների օգնությամբ հարստացող լեզվի մոդելները բարելավում են երկու խնդիրների արդյունքները, որոշ հետևանքներ ունենալով ուժեղ լեզվի մոդելների համար, որոնք ընդունում են լեզվի սովորելու համատեքստ', 'ca': "Els models de llenguatge només s'entrenen en text malgrat el fet que els humans aprenguin la seva primera llenguatge en un entorn altament interactiu i multimodal on el primer conjunt de paraules aprengutes són en gran part concretes, indicant entitats físiques i estats incorporats. Per enriquecer els models de llenguatge amb algunes d'aquestes experiències que falten, utilitzem dues fonts d'informació: 1) les normes de Lancaster Sensorimotor, que proporcionen valoracions (mitjans i desviacions estándar) per més de 40.000 paraules angleses a llarg de diverses dimensions d'encarnament, i que capturen el punt en què alguna cosa s'experimenta a través d'11 modalitats sensorials diferents, i (2) vectors de coeficients de classificadors binaris entrenats en imatges del vocabulari BERT. Vam preparar el model ELECTRA i vam ajustar el model RoBERTa amb aquestes dues fonts d'informació, i després vam evaluar fent servir el criteri de referència GLUE estabelect i el criteri de diàleg visual. Trobem que els models de llenguatge enriqueixants amb les normes de Lancaster i els vectors d'imatge milloren els resultats en ambdues tasques, amb algunes implicacions per models de llenguatge robustos que capturen el significat lingüístic holístic en un context d'aprenentatge de llenguatges.", 'cs': 'Jazykové modely jsou trénovány pouze na textu navzdory skutečnosti, že se lidé učí svůj první jazyk ve vysoce interaktivním a multimodálním prostředí, kde první sada učených slov je z velké části konkrétní, označující fyzické entity a ztělesněné stavy. Abychom obohatili jazykové modely o některé z těchto chybějících zkušeností, využíváme dvou zdrojů informací: (1) Lancaster Sensoromotor normy, které poskytují hodnocení (střední a standardní odchylky) pro více než 40.000 anglických slov podél několika dimenzí ztělesnění a které zachycují rozsah, do jakého se něco prožívá napříč 11.různými smyslovými modalitami, a (2) vektory z koeficientů binárních klasifikátorů trénovaných na obrázkech pro slovní zásobu BERT. Předškolili jsme model ELECTRA a vyladili model RoBERTa s těmito dvěma zdroji informací a následně vyhodnotili pomocí zavedeného GLUE benchmarku a Visual Dialog benchmarku. Zjistili jsme, že obohacení jazykových modelů o Lancasterovy normy a obrazové vektory zlepšuje výsledky v obou úkolech, s určitými důsledky pro robustní jazykové modely, které zachycují holistický jazykový význam v kontextu výuky jazyka.', 'fi': 'Kielimallit koulutetaan vain tekstiin huolimatta siitä, että ihmiset oppivat ensimmäisen kielensä erittäin interaktiivisessa ja multimodaalisessa ympäristössä, jossa ensimmäiset opitut sanat ovat pitkälti konkreettisia, tarkoittaen fyysisiä kokonaisuuksia ja ruumiillistuneita tiloja. Rikastaaksemme kielimalleja tällä puuttuvalla kokemuksella hyödynnämme kahta tietolähtettä: (1) Lancasterin sensorimotoriset normit, jotka antavat luokitukset (keskiarvot ja standardipoikkeamat) yli 40 000 englanninkieliselle sanalle useissa kehonmuodostuksen ulottuvuuksissa, ja jotka kuvaavat, missä määrin jotakin koetaan 11 eri aistimodaalissa, ja (2) vektorit binääriluokittelijoiden kertoimista, jotka on koulutettu kuviin BERT-sanastoa varten. Esikoulutimme ELECTRA-mallin ja hienosäädimme RoBERTa-mallin näillä kahdella tietolähteellä ja arvioimme sen jälkeen GLUE-vertailuarvon ja Visual Dialog -vertailuarvon avulla. Havaitsemme, että kielimallien rikastuttaminen Lancasterin normeilla ja kuvavektoreilla parantaa tuloksia molemmissa tehtävissä, mikä vaikuttaa vankkoihin kielimalleihin, jotka kuvaavat kokonaisvaltaista kielellistä merkitystä kieltenoppimisen kontekstissa.', 'et': 'Keelemudeleid koolitatakse ainult tekstile vaatamata asjaolule, et inimesed õpivad oma esimest keelt väga interaktiivses ja mitmeliigilises keskkonnas, kus esimesed õppitud sõnad on suures osas konkreetsed, tähistades füüsilisi üksusi ja kehastunud olekuid. Selleks, et rikastada keelemudeleid mõningate puuduvate kogemustega, kasutame kahte teabeallikat: (1) Lancasteri sensorimotoorseid norme, mis annavad hinnangud (keskmised ja standardhälbed) enam kui 40 000 inglise sõna kohta mitmes kehastuse mõõtmes ning mis kajastavad, mil määral midagi kogetakse 11 erineva sensoorse mudeli puhul, ja (2) vektorid binaarsete klassifitseerijate koefitsientidest, mis on koolitatud BERT sõnavara piltidele. Me eelkoolitasime ELECTRA mudelit ja täpsustasime RoBERTa mudelit nende kahe teabeallika abil, seejärel hindasime seda kehtestatud GLUE võrdlusaluse ja visuaalse dialoogi võrdlusaluse abil. Leiame, et keelemudelite rikastamine Lancasteri normide ja pildivektoritega parandab tulemusi mõlemas ülesandes, mõningaid tagajärgi tugevatele keelemudelitele, mis kajastavad keeleõppe kontekstis terviklikku keelelist tähendust.', 'jv': 'Masking Language Ing nggawe model sing luwih nggawe karo akeh operasi iki, awake dhéwé iso nggawe informasi luwih kaya ngono (1) nggawe sistem sing beraksi aké limang nyanggo dolanan luwih (karo dolanan sing bakal terus) kanggo awak dhéwé 40000, kuwi tanggal sing beraksi sakjane sampek karo akeh nyong, lan ujaran iso nggawe nguasah dumadhi kaya senhor sampek 11 Path Awak dhéwé wis luwih-luwih cara-luwih nggawe model el el-ETRA lan ngaweh-luwih dumateng iki bakal kelompok informasi iki dadi nyong ngerasai bendhukaan GLUE lan nganggo bendhukaan dialoog Visual. Awak dhéwé nggawe sistem nggawe barang nggawe tindang model sing nggawe lombak karo nglanggar tarjamahan lan vector alam kuwi nggawe barang bantuan ingkang sampeyan kaya sistem gawe barang nggawe sistem sing berarti alam sing paling-alam kuwi nggawe barang langgar sampeyan ingkang.', 'ha': "An sanar da misalin harshe kawai kan matsayin, kuma ingawa mutane sun sanar da harshen farkonsu a cikin muhalli mai girma mai fara-interaction da multi-multi, inda na farkon matsayin da aka sanar, za'a ƙara masu tsari da masu nau'in da aka lokace. To, in riki misãlai na harshen zuwa wani abu daga wannan da ba'a gane ba, sai Mu sami sunaye biyu na ma'anar information: (1) Rubuwa na kasar fassarori (ma'anar da kuma tsakanin nau'i) ga sauri 40,000 na Ingiriya sami duk turɓãya masu da wani abu ya sami da shi akan hanyoyin 11,000,000, dictionary variant We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark.  Tuna gane cewa masu riki misãlai na harshe da shiryoyin ayukan na lancaster da shiryoyi na zane sun ƙara matsayin aikin dukansu, da wasu masu muhimmada wa misãlai da aka rubũta harshen, waɗand a ke riƙon fasalin cikin muhallin da aka karanta harshe.", 'sk': 'Jezikovni modeli se usposabljajo samo na besedilu kljub dejstvu, da se ljudje naučijo svojega prvega jezika v zelo interaktivnem in multimodalnem okolju, kjer so prvi nabor naučenih besed večinoma konkretni in označujejo fizične entitete in utelešena stanja. Za obogatitev jezikovnih modelov z nekaterimi manjkajočimi izkušnjami uporabljamo dva vira informacij: (1) Lancasterjeve senzormotorične norme, ki zagotavljajo ocene (sredstva in standardna odstopanja) za več kot 40.000 angleških besed vzdolž različnih dimenzij utelešenja, in ki zajemajo obseg, v katerem se nekaj doživlja v 11 različnih senzoričnih modalijah, in (2) vektorji iz koeficientov binarnih klasifikatorjev, usposobljenih na slikah za besedišče BERT. Model ELECTRA smo predhodno usposobili in model RoBERTa natančno nastavili s tema dvema vira informacij, nato pa ocenili z uporabo uveljavljene referenčne vrednosti GLUE in referenčne vrednosti vizualnega dialoga. Ugotavljamo, da obogatitev jezikovnih modelov z Lancasterovimi normami in slikovnimi vektorji izboljšuje rezultate obeh nalog, kar ima nekaj posledic za robustne jezikovne modele, ki zajemajo celostni jezikovni pomen v kontekstu učenja jezikov.', 'he': 'דוגמני שפת מאומנים רק על טקסט למרות העובדה שבני אדם לומדים את שפתם הראשונה בסביבה אינטראקטיבית ומיולטומודלית ביותר כדי לעשיר דוגמני שפה עם חלק מהחוויה הנעדרת הזו, אנו משתמשים בשני מקורות מידע: (1) נורמות Sensorimotor לנקסטר, אשר מספקות ציונים ויקטורים (2) ממוצעים של קליזצים בינריים מאומנים על תמונות למילון BERT. אימנו מראש את דוגמנית ELECTRA ומתאימנו את דוגמנית RoBERTa עם שני מקורות המידע האלה ואז ערכים באמצעות המרמז GLUE המבוסס והרמז של דיאלוג ויזואלי. אנו מוצאים שמעשירים דוגמני שפה עם נורמות לנקסטר וקטורים תמונות משתפרים תוצאות בשני המשימות, עם השלכות מסוימות לדוגמני שפה חזקים שמתפסיקים משמעות שפתית הוליסטית בקשר ללמוד שפות.', 'bo': 'སྐད་ཡིག་མིག་དཔེ་དབྱིབས་ཡིག་ཆ་ཁོ་ན་ཡིག་གེ་བསྟུན་ནས། མི་ཚོའི་སྐད་ཡིག་ཆ་དང་རང་གི་སྐད་ཡིག སྐད་ཡིག་ཆ་མེད་པའི་བརྗོད་འཚོལ་ལས་ཀྱང་ཚང་མཉམ་དུ་འགྱུར་བའི་ཆ་འཕྲིན་གཉིས་ཀྱི་ལག་ཁྱེར་གྱི་ཡོད། BERT ཡི་གླེང་སྒྲོམ་ནང་གི་བརྙན་རིས་སྦྱོར་བྱེད་པའི་གཉིས་ཆ་རྣམས་གྲངས་ཀ་ལས་མཐུན་རྐྱེན་པའི་(2)vectors. We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark. ང་ཚོར་མཐོང་ན། Lancaster སྲོལ་རིམ་དང་བརྙན་ཁང་ཆ་རྣམས་ལས་མཐུན་འགྱུར་བ་མང་ཙམ་མཐུན་བཟོ་བྱེད་པའི་སྐད་ཡིག་ཐབས་ལམ་གཞན་ཞིག་ཡིན་པས།'}
{'en': 'Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction', 'ar': 'تكشف التدخلات المضادة للواقع عن التأثير السببي لإقرارات الفقرة النسبية على توقع الاتفاق', 'es': 'Las intervenciones contrafácticas revelan el efecto causal de las representaciones de cláusulas relativas en la predicción de acuerdos', 'fr': "Les interventions contrefactuelles révèlent l'effet causal des représentations de clauses relatives sur la prédiction de l'accord", 'pt': 'Intervenções Contrafactuais Revelam o Efeito Causal das Representações de Cláusulas Relativas na Previsão de Acordos', 'zh': '反事干预揭示对条表示协议的因果效应', 'ja': '反事実的介入合意予測に対する相対条項表現の因果関係を明らかにする', 'ru': 'Контрфактные вмешательства выявляют причинный эффект заявлений относительных пунктов на предсказание соглашения', 'ga': 'Nochtann Idirghabhálacha Frithfhíorasacha an Éifeacht Chúis atá ag Léirithe i gClásal Coibhneasta ar Thuar Comhaontaithe', 'hi': 'प्रतिवादी हस्तक्षेप समझौते की भविष्यवाणी पर सापेक्ष खंड प्रतिनिधित्व के कारण प्रभाव को प्रकट करते हैं', 'el': 'Οι παραποιημένες παρεμβάσεις αποκαλύπτουν την αιτιολογική επίδραση των αντιπροσωπειών σχετικής ρήτρας στην πρόβλεψη συμφωνίας', 'it': "Interventi contraffatti rivelano l'effetto causale delle rappresentazioni relative delle clausole sulla previsione degli accordi", 'kk': 'Келтірілген қарсы интервенциялар Келтірілгенде қатынастық клауз таңбаларының шектеу эффектін көрсету', 'hu': 'A hamisított beavatkozások feltárják a relatív záradék-ábrázolások ok-okozati hatását a megállapodás előrejelzésére', 'lt': 'Faktinės intervencijos atskleidžia santykinių sąlygų atstovavimų priežastinį poveikį susitarimo prognozei', 'ka': 'კონტრეფიალური ინტერვინციები გამოჩვენება შესაბამისი კლასოს გამოსახულებების შესაბამისი ეფექტი', 'ms': 'Intervention palsu mengungkapkan Kesan Sebab Perwakilan Clause Relative pada Perjanjian', 'mt': 'Interventi Falsifikati Jiżvelaw l-Effett Kawżiku tar-Rappreżentanzi tal-Klawżola Relattiva fuq it-Tbassir tal-Ftehim', 'mk': 'Лажните интервенции го откриваат причинниот ефект на релативните претставувања на клаузулите за предвидување на договорот', 'pl': 'Podrobione interwencje ujawniają przyczynowy wpływ reprezentacji klauzuli względnej na przewidywanie umów', 'ml': 'അക്കണക്കിലുള്ള ഇടപാടുകള്\u200d വ്യക്തമാക്കുന്നു ബന്ധപ്പെട്ട ക്ലൌസിന്റെ പ്രതിനിധികള്\u200dക്കുള്ള കായുസേല്\u200d പ്രഭാവ', 'mn': 'Дүрсийн харьцангуй холбоотой холбоотой холбоотой холбоотой холбоотой байгууллагуудын нөлөөг нээлттэй.', 'no': 'Kontreflektiv intervensjonar viser avbrytingseffekten av relativ klassesrepresentasjonar på forhåndsvising av forhåndsvising', 'sr': 'Kontrafektne intervencije otkrivaju utjecaj optužnice Relativnih predstavljanja klase o predviđanju sporazuma', 'sv': 'Förfalskade ingripanden avslöjar orsakseffekterna av relativ klausulrepresentation på avtalsförutsägelse', 'si': 'CounterfReal Intervences', 'ro': 'Intervențiile contrafăcute dezvăluie efectul cauzal al reprezentărilor relative ale clauzelor asupra predicției acordului', 'ur': 'کنٹرفارفیل انٹرنوینٹیوں نے معاہدہ کی پیش بینی کے بارے میں معاہدہ کلاس کے معاہدہ کی روکنی اثرات کو ظاہر کیا ہے', 'so': 'Heshiiska xisaabta ah', 'ta': 'எண்ணிக்கையான இடைவெளிப்பாடு', 'uz': 'Doimiy interfeys', 'vi': 'Chống đối thực tố Làm trái ngược hiệu ứng của Liên quan đến các phái nhánh đấu giá', 'da': 'Forfalskede interventioner afslører årsagsvirkningen af relative klausulrepresentationer på aftaleforudsigelse', 'nl': 'Namaakinterventies onthullen het oorzakelijke effect van representaties van relatieve clausules op de voorspelling van overeenkomsten', 'bg': 'Фалшивите интервенции разкриват причинното въздействие на относителните клаузи върху прогнозирането на споразумението', 'ko': '반사실의 개입은 관계가 문장 표징에서 일치성 예측에 대한 인과적 영향을 드러냈다', 'de': 'Gefälschte Interventionen enthüllen den ursächlichen Effekt von Repräsentationen relativer Klauseln auf die Vorhersage von Vereinbarungen', 'fa': 'اثر بازداشت بازداشتی کلاس مربوط به پیشنهاد توافق', 'sw': 'Mazungumzo ya Hesabu yanaonyesha madhara ya Matukio ya Matukio ya Kuhusiana na Makubaliano ya Makubaliano', 'hr': 'Provlačne intervencije otkrivaju učinak optužnice Relativnih predstavljanja klauzula o predviđanju sporazuma', 'tr': 'Gerçekleşen Araglar Görkezilýär', 'af': 'Teikerfekte Interventions Vertoon die Uitbreiding Effek van Relatiewe Klasse voorstellings op ooreenkoms voorskrywing', 'sq': 'Ndërhyrjet e rrejshme zbulojnë efektin shkak të përfaqësimeve të kushteve të lidhura mbi parashikimin e marrëveshjes', 'id': 'Interventi palsu mengungkapkan efek penyebab dari Perwakilan Clause Relatif pada Perjanjian Perjanjian', 'am': 'የውይይት መቀናቀል የሚታየው የአካባቢ ክፍል በይፋ ላይ አቀማመጥ አቀናመጥ', 'hy': 'Կատար միջամտումները բացահայտում են հարաբերական պայմանների ներկայացումների պատճառը համաձայնության կանխատեսման վրա', 'bn': 'প্রতিনিধি সম্পর্কিত ক্লাসের প্রতিনিধির ক্ষেত্রে ক্যাসাল প্রভাব প্রকাশ করে', 'az': 'Counterfactual Interventions Open the Causal Effect of Relative Clause Representations on Agreement Prediction', 'bs': 'Protivfaktične intervencije otkrivaju učinak optužnice Relativnih predstavljanja klauzula o predviđanju sporazuma', 'et': 'Võltsitud sekkumised paljastavad suhtelise klausli esitamise põhjusliku mõju kokkuleppe prognoosimisele', 'fi': 'Väärennetyt interventiot paljastavat suhteellisten lausekkeiden esittämisen syy-seuraukset sopimusennusteeseen', 'ca': "Intervencions falses revelen l'efecte causal de les representacions relativas de les clausoles en la predicció d'acords", 'cs': 'Padělané intervence odhalují příčinný vliv reprezentací relativní doložky na predikci dohody', 'ha': '@ action', 'he': 'התערבות מזויפות חשפו את ההשפעה הגורמית של מייצגות מסיבות יחסיות על ציפוי הסכם', 'bo': 'Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction', 'sk': 'Ponarejeni posegi razkrivajo vzročni učinek predstavitev relativnih klavzul na napoved dogovora', 'jv': 'olar'}
{'en': 'When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language? We propose AlterRep, an intervention-based method to address this question. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the  feature  is encoded, while leaving in- tact all other aspects of the original  representation . By measuring the change in a  model ’s word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the  model ’s behavior. We apply this method to study how BERT models of different sizes process relative clauses (RCs). We find that BERT variants use RC boundary information during  word prediction  in a manner that is consistent with the rules of English grammar ; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category.', 'pt': 'Quando os modelos de linguagem processam sentenças sintaticamente complexas, eles usam suas representações da sintaxe de maneira consistente com a gramática da linguagem? Propomos o AlterRep, um método baseado em intervenção para abordar esta questão. Para qualquer traço linguístico de uma dada sentença, AlterRep gera representações contrafactuais alterando como o traço é codificado, deixando intactos todos os outros aspectos da representação original. Ao medir a mudança no comportamento de previsão de palavras de um modelo quando essas representações contrafactuais são substituídas pelas originais, podemos tirar conclusões sobre o efeito causal da característica linguística em questão no comportamento do modelo. Aplicamos este método para estudar como modelos BERT de diferentes tamanhos processam cláusulas relativas (RCs). Descobrimos que as variantes BERT usam informações de limite RC durante a previsão de palavras de uma maneira consistente com as regras da gramática inglesa; esta informação de limite de RC generaliza em uma extensão considerável entre diferentes tipos de RC, sugerindo que BERT representa RCs como uma categoria linguística abstrata.', 'es': 'Cuando los modelos de lenguaje procesan oraciones sintácticamente complejas, ¿utilizan sus representaciones de la sintaxis de manera coherente con la gramática del idioma? Proponemos AlterRep, un método basado en la intervención para abordar esta cuestión. Para cualquier característica lingüística de una oración dada, AlterRep genera representaciones contrafácticas al alterar la forma en que se codifica la característica, mientras deja intactos todos los demás aspectos de la representación original. Al medir el cambio en el comportamiento de predicción de palabras de un modelo cuando estas representaciones contrafácticas se sustituyen por las originales, podemos sacar conclusiones sobre el efecto causal de la característica lingüística en cuestión en el comportamiento del modelo. Aplicamos este método para estudiar cómo los modelos BERT de diferentes tamaños procesan las cláusulas relativas (RC). Encontramos que las variantes de BERT utilizan la información de límites de RC durante la predicción de palabras de una manera que es coherente con las reglas de la gramática inglesa; esta información de límites de RC se generaliza en gran medida en diferentes tipos de RC, lo que sugiere que BERT representa a los RC como una categoría lingüística abstracta.', 'ar': 'عندما تعالج نماذج اللغة الجمل المعقدة نحويًا ، فهل تستخدم تمثيلاتها النحوية بطريقة تتوافق مع قواعد اللغة؟ نقترح AlterRep ، وهي طريقة قائمة على التدخل لمعالجة هذا السؤال. بالنسبة لأي سمة لغوية لجملة معينة ، يقوم AlterRep بإنشاء تمثيلات معاكسة عن طريق تغيير كيفية تشفير الميزة ، مع ترك جميع الجوانب الأخرى للتمثيل الأصلي في مأمن. من خلال قياس التغيير في سلوك التنبؤ بالكلمة لنموذج ما عندما يتم استبدال هذه التمثيلات الواقعية بالواقع الأصلي ، يمكننا استخلاص استنتاجات حول التأثير السببي للميزة اللغوية المعنية على سلوك النموذج. نطبق هذه الطريقة لدراسة كيفية قيام نماذج BERT ذات الأحجام المختلفة بمعالجة الجمل النسبية (RCs). وجدنا أن متغيرات BERT تستخدم معلومات حدود RC أثناء التنبؤ بالكلمات بطريقة تتوافق مع قواعد قواعد اللغة الإنجليزية ؛ تُعمم معلومات حدود RC هذه إلى حد كبير عبر أنواع مختلفة من RC ، مما يشير إلى أن BERT تمثل RC كفئة لغوية مجردة.', 'fr': "Lorsque les modèles de langage traitent des phrases complexes sur le plan syntaxique, utilisent-ils leurs représentations syntaxiques d'une manière cohérente avec la grammaire de la langue\xa0? Nous proposons AlterRep, une méthode basée sur l'intervention pour répondre à cette question. Pour toute caractéristique linguistique d'une phrase donnée, AlterRep génère des représentations contrefactuelles en modifiant la façon dont la caractéristique est codée, tout en laissant intacts tous les autres aspects de la représentation d'origine. En mesurant le changement dans le comportement de prédiction de mots d'un modèle lorsque ces représentations contrefactuelles sont remplacées par les représentations originales, nous pouvons tirer des conclusions sur l'effet causal de la caractéristique linguistique en question sur le comportement du modèle. Nous appliquons cette méthode pour étudier comment les modèles BERT de différentes tailles traitent les clauses relatives (RC). Nous trouvons que les variantes BERT utilisent les informations de limite RC pendant la prédiction de mots d'une manière qui est cohérente avec les règles de la grammaire anglaise\xa0; ces informations de limites RC se généralisent dans une large mesure entre les différents types de RC, suggérant que BERT représente les RC comme une catégorie linguistique abstraite.", 'zh': '语法杂句,与言语语法同语法乎? 臣等建AlterRep,一本于干预之道。 给定言者,AlterRep变编码以成反事,兼存其始者也。 测事易始单词占行之变,可得而论言对模型行之因效也。 以此论大小BERT何以处对子句(RC)。 见BERT变体在单词占中以应英语语法法用RC界信息。 此 RC 界信息于相当程度上推及异 RC 之类,明 BERT 以 RC 为抽象之言类也。', 'hi': 'जब भाषा मॉडल वाक्यात्मक रूप से जटिल वाक्यों को संसाधित करते हैं, तो क्या वे वाक्यविन्यास के अपने प्रतिनिधित्व का उपयोग इस तरह से करते हैं जो भाषा के व्याकरण के अनुरूप है? हम AlterRep, इस प्रश्न को संबोधित करने के लिए एक हस्तक्षेप-आधारित विधि का प्रस्ताव करते हैं। किसी दिए गए वाक्य की किसी भी भाषाई विशेषता के लिए, AlterRep मूल प्रतिनिधित्व के अन्य सभी पहलुओं को छोड़ते हुए, सुविधा को एन्कोडेड करने के तरीके को बदलकर प्रतिवादी प्रतिनिधित्व उत्पन्न करता है। एक मॉडल के शब्द भविष्यवाणी व्यवहार में परिवर्तन को मापने के द्वारा जब इन प्रतिवादात्मक अभ्यावेदनों को मूल लोगों के लिए प्रतिस्थापित किया जाता है, तो हम मॉडल के व्यवहार पर प्रश्न में भाषाई विशेषता के कारण प्रभाव के बारे में निष्कर्ष निकाल सकते हैं। हम इस विधि को यह अध्ययन करने के लिए लागू करते हैं कि विभिन्न आकारों के BERT मॉडल सापेक्ष खंडों (RCs) को कैसे संसाधित करते हैं। हम पाते हैं कि BERT वेरिएंट शब्द की भविष्यवाणी के दौरान RC सीमा जानकारी का उपयोग इस तरह से करते हैं जो अंग्रेजी व्याकरण के नियमों के अनुरूप है; यह आरसी सीमा जानकारी विभिन्न आरसी प्रकारों में काफी हद तक सामान्यीकृत होती है, यह सुझाव देते हुए कि BERT एक अमूर्त भाषाई श्रेणी के रूप में RCs का प्रतिनिधित्व करता है।', 'ja': '言語モデルが構文的に複雑な文を処理するとき、彼らは言語の文法と一致する方法で構文の表現を使用しますか？ この問題に対処するための介入ベースの方法であるAlterRepを提案します。 所与の文の任意の言語的特徴について、AlterRepは、元の表現の他のすべての側面に触れたまま、特徴がどのようにエンコードされるかを変更することによって反事実的表現を生成する。 これらの反事実的表現を元の表現に置き換えたときのモデルの単語予測行動の変化を測定することにより、問題の言語的特徴がモデルの行動に与える因果効果について結論を導き出すことができる。 この方法を適用して、異なるサイズのBERTモデルが相対項（ RC ）を処理する方法を研究します。 BERTバリアントは、単語予測中に英語の文法の規則と一致する方法でRC境界情報を使用していることがわかりました。このRC境界情報は、異なるRCタイプ間でかなりの程度一般化されており、BERTが抽象的な言語カテゴリとしてRCを表していることを示唆しています。', 'ru': 'Когда языковые модели обрабатывают синтаксически сложные предложения, используют ли они свои представления синтаксиса в соответствии с грамматикой языка? Для решения этого вопроса мы предлагаем метод AlterRep, основанный на интервенциях. Для любой лингвистической особенности данного предложения, AlterRep генерирует контрафактные представления путем изменения того, как функция кодируется, оставляя в контакте все другие аспекты первоначального представления. Измеряя изменение в поведении прогнозирования слов модели, когда эти контрафактные представления заменяются исходными, мы можем сделать выводы о причинном влиянии рассматриваемой лингвистической особенности на поведение модели. Мы применяем этот метод для изучения того, как модели BERT разных размеров обрабатывают относительные условия (RC). Мы обнаружили, что варианты BERT используют информацию о границах RC при предсказании слов в соответствии с правилами английской грамматики; эта информация о границах RC в значительной степени обобщает различные типы RC, предполагая, что BERT представляет RC как абстрактную лингвистическую категорию.', 'ga': 'Nuair a phróiseálann samhlacha teanga abairtí atá casta go comhréire, an mbaineann siad úsáid as a léiriú ar chomhréir ar bhealach atá ag teacht le gramadach na teanga? Molaimid AlterRep, modh bunaithe ar idirghabháil chun aghaidh a thabhairt ar an gceist seo. Maidir le haon ghné theangeolaíoch d’abairt ar leith, gineann AlterRep léirithe frithfhíorasacha trí athrú a dhéanamh ar an gcaoi a n-ionchódaítear an ghné, agus ag an am céanna gach gné eile den léiriú bunaidh a fhágáil slán. Trí athrú ar iompar tuar focal múnla a thomhas nuair a chuirtear na huiríll frithfhíorasacha seo in ionad na mbunáite, is féidir linn tátail a bhaint as éifeacht chúiseach na gné teangeolaíochta atá i gceist ar iompar na samhla. Cuirimid an modh seo i bhfeidhm chun staidéar a dhéanamh ar conas a phróiseálann samhlacha BERT de mhéideanna éagsúla clásail choibhneasta (RCanna). Faighimid amach go n-úsáideann leagan BERT faisnéis teorann RC le linn réamhinsint focal ar bhealach atá ag teacht le rialacha ghramadach an Bhéarla; ginearálaíonn an t-eolas teorann RC seo go pointe thar na cineálacha éagsúla RC, rud a thugann le tuiscint go seasann CRETanna mar chatagóir teibí teangeolaíochta.', 'hu': 'Amikor a nyelvi modellek szintaktikailag összetett mondatokat dolgoznak fel, a szintaxis ábrázolását olyan módon használják, amely összhangban van a nyelv nyelvtanával? Javasoljuk az AlterRep-et, egy intervenciós alapú módszert, amely ennek a kérdésnek a megoldására szolgál. Az AlterRep egy adott mondat bármely nyelvi jellemzőjének megváltoztatásával ellentétes reprezentációt generál a funkció kódolásának módosításával, miközben érintésben hagyja az eredeti ábrázolás minden egyéb aspektusát. Egy modell szópredikciós viselkedésében bekövetkező változások mérésével, amikor ezeket az ellentényálló reprezentációkat helyettesítik az eredetiekkel, következtetéseket vonhatunk le a kérdéses nyelvi jellemzőnek a modell viselkedésére gyakorolt okozati hatásáról. Ezt a módszert alkalmazzuk annak tanulmányozására, hogy a különböző méretű BERT modellek hogyan dolgozzák fel a relatív záradékokat (RC). Úgy találjuk, hogy a BERT változatok az RC határinformációkat használják a szó előrejelzése során olyan módon, amely összhangban van az angol nyelvtan szabályaival; Ez az RC határvonalakra vonatkozó információ jelentős mértékben általánosítja a különböző RC típusokat, ami arra utal, hogy a BERT absztrakt nyelvi kategóriában képviseli a RC-ket.', 'el': 'Όταν τα γλωσσικά μοντέλα επεξεργάζονται συντακτικά σύνθετες προτάσεις, χρησιμοποιούν τις αναπαραστάσεις της σύνταξης τους με τρόπο σύμφωνο με τη γραμματική της γλώσσας; Προτείνουμε μια μέθοδο παρέμβασης για την αντιμετώπιση αυτού του ζητήματος. Για οποιοδήποτε γλωσσικό χαρακτηριστικό μιας συγκεκριμένης πρότασης, το AlterRep παράγει αντιπραγματικές αναπαραστάσεις αλλάζοντας τον τρόπο κωδικοποίησης του χαρακτηριστικού, αφήνοντας παράλληλα σε επαφή όλες τις άλλες πτυχές της αρχικής αναπαράστασης. Μετρώντας την αλλαγή στη συμπεριφορά πρόβλεψης λέξεων ενός μοντέλου όταν αυτές οι αντιφατικές αναπαραστάσεις αντικαθίστανται από τις αρχικές, μπορούμε να εξάγουμε συμπεράσματα σχετικά με την αιτιώδη επίδραση του εν λόγω γλωσσικού χαρακτηριστικού στη συμπεριφορά του μοντέλου. Εφαρμόζουμε αυτή τη μέθοδο για να μελετήσουμε πώς τα μοντέλα διαφόρων μεγεθών επεξεργάζονται σχετικές ρήτρες (Ρ). Διαπιστώνουμε ότι οι παραλλαγές χρησιμοποιούν πληροφορίες ορίων κατά τη διάρκεια της πρόβλεψης λέξεων με τρόπο σύμφωνο με τους κανόνες της αγγλικής γραμματικής. οι πληροφορίες αυτές γενικεύουν σε σημαντικό βαθμό μεταξύ διαφορετικών τύπων RC, υποδηλώνοντας ότι ο BERT αντιπροσωπεύει τις RC ως αφηρημένη γλωσσική κατηγορία.', 'kk': 'Тіл үлгілері синтактикалық комплекс сөздерді жасағанда, олар тілдің грамматтарына сәйкес келетін синтаксисын қолданады ба? Біз бұл сұрақты шешу үшін AlterRep дегенді қолданамыз. Келтірілген сөздің лингвистикалық мүмкіндіктері үшін AlterRep қанша кодтамасын өзгертіп, басқа түрінің басқа аспектерін қолдану үшін қанша қаншалық кескіндерді жасайды. Үлгісінің өзгерістерін өлшеп, бұл өзгерістер бастапқы мәліметтер үшін алмастырылғанда, үлгісінің қасиетінің себепті лингвистикалық мүмкіндіктерінің негізгі эффекті туралы шешу болады. Біз бұл әдістерді BERT түрлі өлшемдердің қалай процесстер сәйкес клауз (RC) үлгілерін зерттеу үшін қолданымыз. Біз BERT айнымалылары сөздерді бақылау кезінде RC шектерінің мәліметін ағылшын грамматикалық ережелеріне сәйкес келетін түрде қолданады. Бұл RC шектерінің мәліметі түрлі RC түрлерінде маңызды көлемі болады. БЕРТ RC дегенді абстракты лингвистикалық санаты ретінде көрсетеді.', 'ka': 'როდესაც ენის მოდელები სინტაქტიკურად კომპლექსი სიტყვების პროცესება, ისინი სინტაქსის გამოყენებას გამოყენებენ რამდენიმე გრამიმარით? ჩვენ შეგიძლიათ AlterRep-ს, ინტერვანციის გარეშე გარეშე ეს კითხვა. AlterRep-ის ყველაფერი ენგურისტიკური განსაზღვრებისთვის შექმნა განსაზღვრებები, როგორ ფუნქციის კოდირება იქნება, როცა ორიგინალური განსაზღვრებისთვის ყველა განსაზღვრების განსაზღვრების მოდელის სიტყვების წინასწარმატების ცვლილებას, როდესაც ეს წინასწარმატებული რესპეცენტაციები ორიგიალური რესპეცენტაციებისთვის შეცვლა, ჩვენ შეგვიძლია გავაკეთოთ წინასწარმატების მიზეზი ინგური ჩვენ ამ პროცემის გამოყენება, როგორ განსხვავებული ზომის BERT მოდელები პროცესიური კლასების პროცესიური კლასების გამოყენება. ჩვენ ვიფიქრობთ, რომ BERT გარიანტები RC გარეშე ინფორმაციის გამოყენება სიტყვების წინასწორებაში, რომელიც ანგლისური გრამატურის წინასწორებებისთვის შემდგენებ RC-ის განსხვავებული RC ტიპების განსხვავებულ განსხვავებულ განსხვავებულ განსხვავებულ ინფორმაციის განსხვავება, რომელიც BERT იყოს RCs როგორც აბსტრაქტური ლენგურისტიკის კატეგ', 'it': "Quando i modelli linguistici elaborano frasi sintatticamente complesse, usano le loro rappresentazioni della sintassi in modo coerente con la grammatica della lingua? Proponiamo AlterRep, un metodo basato sull'intervento per affrontare questa domanda. Per qualsiasi caratteristica linguistica di una determinata frase, AlterRep genera rappresentazioni controfattuali alterando il modo in cui la caratteristica è codificata, lasciando nel tatto tutti gli altri aspetti della rappresentazione originale. Misurando il cambiamento nel comportamento di previsione delle parole di un modello quando queste rappresentazioni controfattuali sono sostituite a quelle originali, possiamo trarre conclusioni sull'effetto causale della caratteristica linguistica in questione sul comportamento del modello. Applichiamo questo metodo per studiare come i modelli BERT di diverse dimensioni elaborano le clausole relative (RCs). Troviamo che le varianti BERT utilizzano le informazioni di confine RC durante la previsione delle parole in modo coerente con le regole della grammatica inglese; Questa informazione al confine RC si generalizza in larga misura tra diversi tipi RC, suggerendo che BERT rappresenti RC come categoria linguistica astratta.", 'lt': 'Kai kalbos modeliai tvarko sintetiškai sudėtingus sakinius, ar jie naudoja savo sintaksų rodmenis taip, kad atitiktų kalbos gramatiką? Mes siūlome AlterRep, intervenciniu metodu šiam klausimui spręsti. Kiekvieno tam tikro sakinio kalbinės savybės atveju AlterRep sukuria priešingus duomenis, keičiant savybės kodavimą, paliekant kontaktinius visus kitus pirminio atstovavimo aspektus. Matuojant modelio žodžių prognozavimo elgesio pokyčius, kai šie priešingi rodmenys pakeičiami pradiniais rodmenimis, galime daryti išvadas dėl atitinkamos kalbinės savybės priežastinio poveikio modelio elgesiui. Taikome šį metodą, kad ištirtume, kaip skirtingų dydžių BERT modeliai tvarko santykines išlygas. Nustatome, kad BERT variantai naudoja RC ribinę informaciją žodžių prognozavimo metu taip, kad atitiktų anglų gramatikos taisykles; ši RK ribinė informacija gerokai paplitusi įvairių RK tipų atžvilgiu, ir tai rodo, kad RK yra abstrakti kalbų kategorija.', 'ml': 'ഭാഷ മോഡലുകള്\u200d സങ്കീര്\u200dണ്ണമായി സങ്കീര്\u200dണ്ണമായ വാക്കുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുമ്പോള്\u200d, അവരുടെ പ്രതിനിധികള്\u200d സിന്\u200dകാസ്റ്റാക് ഈ ചോദ്യം വിശദീകരിക്കാനുള്ള ഇടപെടല്\u200d അടിസ്ഥാനമായ രീതി തെരഞ്ഞെടുത്ത വാക്കിന്റെ ഏതെങ്കിലും ഭാഷകങ്ങള്\u200d മോഡലിന്റെ വാക്കിന്റെ പ്രവചനത്തിന്റെ സ്വഭാവത്തിന്റെ മാറ്റങ്ങള്\u200d അളന്നുകൊടുക്കുന്നതിനാല്\u200d, ഈ പ്രതിനിധികള്\u200d മൂല പ്രതിനിധികള്\u200dക്ക് പകരം മാറ്റുമ്പോള വ്യത്യസ്ത വലിപ്പം പ്രക്രിയയുടെ മോഡലുകള്\u200d എങ്ങനെയാണെന്ന് ഞങ്ങള്\u200d പഠിക്കാന്\u200d ഈ രീതിയില്\u200d പ്രയോഗിക്കുന്നു.  വാക്ക് പ്രവചിക്കുമ്പോള്\u200d ബെര്\u200dട്ടി വേറെന്റര്\u200dമാര്\u200d RC അതിര്\u200dത്തിയിലെ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു ഇംഗ്ലീഷ് ഗ്രാ ഈ RC അതിര്\u200dത്തിയിലെ വിവരങ്ങള്\u200d വ്യത്യസ്ത രീതികളിലേക്കുള്ള വിവിധ വിവരങ്ങളിലേക്ക് വളരെയധികം സൃഷ്ടിക്കുന്നു. ബെര്\u200dട്ടിയില്\u200d RCs ന', 'mk': 'Кога јазичните модели процесираат синтактички комплексни реченици, дали тие ги користат своите претставувања на синтаксија на начин кој е во согласност со граматиката на јазикот? Предложуваме Алтерреп, метод базиран на интервенција за решавање на ова прашање. За секоја јазична карактеристика на одредена реченица, AlterRep генерира контрафактни претставувања со измена на кодирањето на карактеристиката, додека ги остава сите други аспекти на оригиналното претставување во контакт. Со мерење на промената во однесувањето на предвидувањето на зборовите на моделот кога овие контрафактични претставувања се заменети за оригиналните, можеме да донесеме заклучоци за причинниот ефект на лингвистичката карактеристика во прашање на однесувањето на моделот. Го применуваме овој метод за да проучуваме како BERT моделите од различни големини процесираат релативни клаузули (RCs). Најдовме дека варијантите на BERT користат гранични информации на RC за време на предвидување на зборови на начин кој е во согласност со правилата на англиската граматика; Оваа гранична информација на РЦ се генерализира во значителен степен во различни типови на РЦ, што укажува на тоа дека БЕРТ ги претставува РЦ како апстрактна лингвистичка категорија.', 'mt': 'Meta l-mudelli lingwistiċi jipproċessaw sentenzi sinrattikament kumplessi, jużaw ir-rappreżentazzjonijiet tagħhom ta’ sintaks b’mod li jkun konsistenti mal-grammar tal-lingwa? Aħna nipproponu AlterRep, metodu bbażat fuq l-intervent biex nindirizzaw din il-kwistjoni. Għal kwalunkwe karatteristika lingwistika ta’ sentenza partikolari, AlterRep jiġġenera rappreżentazzjonijiet kontrofattwali billi jbiddel kif il-karatteristika hija kkodifikata, filwaqt li jħalli in-tact l-aspetti l-oħra kollha tar-rappreżentazzjoni oriġinali. Billi tkejjel il-bidla fl-imġiba tat-tbassir tal-kliem ta’ mudell meta dawn ir-rappreżentazzjonijiet kontrofattwali jiġu sostitwiti għal dawk oriġinali, nistgħu niġbdu konklużjonijiet dwar l-effett kawżali tal-karatteristika lingwistika inkwistjoni fuq l-imġiba tal-mudell. Aħna napplikaw dan il-metodu biex nistudjaw kif mudelli BERT ta’ daqsijiet differenti jipproċessaw klawżoli relattivi (RCs). Aħna nsibu li l-varjanti BERT jużaw l-informazzjoni tal-konfini RC matul it-tbassir tal-kelma b’mod konsistenti mar-regoli tal-grammar Ingliż; din l-informazzjoni dwar il-fruntiera tar-RC tiġġeneralizza b’mod konsiderevoli fit-tipi differenti tar-RC, u tissuġġerixxi li l-BERT jirrappreżenta r-RC bħala kategorija lingwistika astratta.', 'no': 'Når språk-modeller prosesserer syntaksisk komplekse setningar, brukar dei sine representasjonane av syntaks på ein måte som er konsistent med grammatikken av språket? Vi foreslår alterRep, ein intervensbasert metode for å handtera dette spørsmålet. For alle lingviske funksjonar av eit gitt setning, vil alterRep laga vilkårleg representasjonar ved å endra korleis funksjonen er koda, mens alle andre aspektane av den opprinnelige representasjonen vert lagt i stad. Ved å måle endringane i ordforhåndsvisinga i eit modell når desse kontrafaktiske representasjonane vert erstatta for dei opprinnelige, kan vi teikna konklusjonar om grunnleggjande effekten av den lingviske funksjonen i spørsmålet på oppførselen til modellen. Vi bruker denne metoden for å studera korleis BERT-modeller av ulike storleik prosesserer relative klausar (RC). Vi finn at BERT-variantane brukar RC-grenseinformasjon under ordforhåndsvising på ein måte som er konsistent med reglane på engelsk grammar. denne RC-grenseinformasjonen genereliserer til ein betydelig storleik over ulike RC-typar, som tyder på at BERT representerer RC som ein abstrakt lingvisk kategori.', 'pl': 'Kiedy modele językowe przetwarzają składniowo złożone zdania, czy używają swoich reprezentacji składni w sposób zgodny z gramatyką języka? Proponujemy AlterRep, metodę opartą na interwencji, aby rozwiązać to pytanie. W przypadku dowolnej cechy językowej danego zdania AlterRep generuje reprezentacje przeciwfaktyczne poprzez zmianę sposobu kodowania cechy, pozostawiając w akcie wszystkie inne aspekty oryginalnej reprezentacji. Pomierzając zmianę w zachowaniu predykcyjnym modelu słowa, gdy te przeciwfaktyczne reprezentacje są zastąpione oryginalnymi, możemy wyciągnąć wnioski o przyczynowym wpływie danej cechy językowej na zachowanie modelu. Stosujemy tę metodę do badania, w jaki sposób modele BERT o różnej wielkości przetwarzają klauzule względne (RCs). Stwierdzamy, że warianty BERT wykorzystują informacje o granicach RC podczas przewidywania słowa w sposób zgodny z zasadami gramatyki angielskiej; Ta informacja o granicach RC w znacznym stopniu uogólnia się w różnych typach RC, sugerując, że BERT reprezentuje RCs jako abstrakcyjną kategorię językową.', 'ms': 'Apabila model bahasa memproses kalimat yang kompleks secara sintaks, adakah mereka menggunakan perwakilan sintaks mereka dengan cara yang konsisten dengan grammar bahasa? Kami cadangkan AlterRep, kaedah berdasarkan intervensi untuk mengatasi soalan ini. Untuk mana-mana ciri bahasa bagi kalimat tertentu, AlterRep menghasilkan perwakilan kontrafaktual dengan mengubah bagaimana ciri dikodifikasi, sementara meninggalkan dalam- takt semua aspek lain perwakilan asal. Dengan mengukur perubahan dalam perilaku prediksi perkataan model apabila perwakilan kontrafaktual ini digantikan untuk perwakilan asal, kita boleh menarik kesimpulan mengenai kesan penyebab ciri-ciri bahasa yang ditanya tentang perilaku model. Kami melaksanakan kaedah ini untuk mempelajari bagaimana model BERT saiz berbeza memproses klausul relatif (RCs). Kami mendapati bahawa varian BERT menggunakan maklumat sempadan RC semasa ramalan perkataan dalam cara yang konsisten dengan peraturan grammar Inggeris; maklumat sempadan RC ini menyebarkan secara luas melalui jenis RC yang berbeza, menyarankan bahawa BERT mewakili RC sebagai kategori bahasa abstrak.', 'ro': 'Atunci când modelele lingvistice procesează propoziții sintactic complexe, folosesc ele reprezentările sintaxei într-un mod care este în concordanță cu gramatica limbii? Propunem AlterRep, o metodă bazată pe intervenție pentru a aborda această întrebare. Pentru orice caracteristică lingvistică a unei anumite propoziții, AlterRep generează reprezentări contrafactuale prin modificarea modului în care caracteristica este codificată, lăsând în tact toate celelalte aspecte ale reprezentării originale. Măsurând schimbarea comportamentului de predicție a cuvântului unui model atunci când aceste reprezentări contrafactuale sunt înlocuite cu cele originale, putem trage concluzii despre efectul cauzal al caracteristicii lingvistice în cauză asupra comportamentului modelului. Aplicăm această metodă pentru a studia modul în care modelele BERT de diferite dimensiuni procesează clauze relative (RCs). Am constatat că variantele BERT utilizează informațiile de limită RC în timpul predicției cuvintelor într-un mod care este în concordanță cu regulile gramaticii engleze; aceste informații privind limitele RC generalizează într-o măsură considerabilă la diferite tipuri RC, sugerând că BERT reprezintă RC ca categorie lingvistică abstractă.', 'so': "Marka sameynta qaababka luuqadu ay si wada qallafsan u baaraandegaan hadal adag, ma waxay u isticmaalayaan qaab u eg qaab ku qoran karta qoraalka luuqada? Waxaynu soo jeedaynaa AlterRep, qaab ku saleysan intervention ah si aan su'aalahan looga hadlo. Qof kasta oo luqad ah oo uu ku qoran yahay sentence, AlterRep wuxuu soo bandhigaa noocyo rasmi ah si uu u beddelo sida loo qorayo, iyadoo uu ka tagayo-tacliiyo dhinaca kale ee wakiilka asalka ah. Markii aan qiyaasayno beddelka hababka wax sii sheegidda modellka, marka loo beddelo noocyadan qof ka mid ah oo loo beddelo asalka ah, waxaynu tegi karnaa dhamaadyo ku saabsan saamaynta ku saabsan qaababka afka ku saabsan dabeecada. Waxaynu u codsanaynaa qaababkan si aan u barano noocyada BERT oo kala duduwan xiliga kala duduwan oo ay u qoran yihiin xiriir (RCs). Waxaynu helnaa in beddelaadka BERT ay isticmaalaan macluumaad xuduudaha RC xilliga wax lagu sii sheegayo hadalka oo ku haboon sharciyada qoraalka Ingiriiska; macluumaadkaas soohdinta RC waxay si adag ugu muuqataa noocyo kala duduwan oo RC ah, waxayna ka jeedaan in BERT u representaa RCs oo ay ka mid tahay qayb luqad ah oo abstract ah.", 'mn': 'Холын загварууд синтактикийн төвөгтэй өгүүлбэрийг шийдвэрлэхэд тэд өөрсдийнхөө синтаксикийн үзүүлбэрийг хэлний грамматаар харьцуулдаг вэ? Бид AlterRep-г энэ асуултыг зохицуулахын тулд оролцох аргыг санал болгож байна. Өөрсөн өгүүлбэрийн аль ч хэл хэлний хувьд AlterRep нь өөрчлөлтийг хэрхэн шинэчлэгдсэн талаар шинэчлэх боломжтой болгодог. Загварын хэлбэрийн өөрчлөлтийг хэмжээгээр эдгээр зөрчилдөөн үзүүлэлтийг эхний хэлбэрээр орлуулахад бид загварын үйл ажиллагаанд асуудал дээрх хэлний чадварын шалтгаан нөлөөлдөг шалтгаан зурж болно. Бид энэ арга хэрхэн өөр хэмжээний BERT загваруудын харьцангуй клаузыг хэрхэн үйлдвэрлэхийг судалдаг. Бид BERT хувилбарууд RC хязгаарын мэдээллийг хэлний тодорхойлолт үед Англи хэлний грамматикийн дүрэм зэрэг ашигладаг гэдгийг олж мэднэ. Энэ RC хязгаарын мэдээлэл нь олон RC төрлүүд дээр ихэвчлэн нийтлэгддэг. БЕРТ нь RC-г abstract хэлний хэлбэртэй гэж үзүүлдэг.', 'si': 'භාෂා මොඩේල් සංවිධානය සම්පූර්ණයෙන් සංවිධානය කරන්න, ඔවුන් ඔවුන්ගේ සංවිධානයේ සංවිධානය භාවිත කරන අපි මේ ප්\u200dරශ්න විශ්වාස කරන්න alterrep ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක්. දෙන්න වාක්යේ කිසිම භාෂාවික විශේෂය සඳහා, alterrep සම්පූර්ණය සම්පූර්ණ විශේෂ ප්\u200dරතිචාරයක් නිර්මාණය කරනවා කොහොමද කොඩ්  මොඩේල්ගේ වචන ප්\u200dරශ්නයක් වෙනස් වෙනුවෙන් මාර්ගන්න පුළුවන් වෙනුවෙන් මොඩේල්ගේ වචන ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් මූලික වචන ප්\u200dර අපි මේ විධානය භාවිතා කරනවා වෙනස් ප්\u200dරමාණය සම්බන්ධ ප්\u200dරමාණය (RCs) ගැන BERT මොඩේල් කියලා පරීක්ෂණ අපිට හොයාගන්න පුළුවන් BERT වෙනස් RC සීමාව තොරතුරු භාවිත කරන්න පුළුවන් වචන අනතුරු විදියට ඉංග්\u200dරීසි ග්\u200dර මේ RC සීමාවික තොරතුරු සාමාන්\u200dය විශේෂ RC වර්ගයක් වෙනුවෙන් ගොඩක් විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විද', 'sr': 'Kada jezički modeli procesuju sintaktički kompleksne rečenice, da li koriste svoje predstave sintaksije na način na koji odgovara gramatici jezika? Predlažemo AlterRep, metodu na intervenciji da se rešimo pitanje. Za bilo koju jezičku karakteristiku određene rečenice, AlterRep stvara falsifikalne predstave mijenjajući način kodiranja funkcije, dok odlaze u taktiku sve ostale aspekte originalne predstave. Mjerajući promjenu predviđanja reèi model a kada se ove proizvoljne predstave zamene za originalne, možemo nacrtati zaključke o uzrokovanom efektu jezičkog karakteristika u pitanju na ponašanje modela. Primjenjujemo ovu metodu da proučimo kako BERT modeli različitih veličina procesiraju relativne klauzule (RC). Pronašli smo da varianti BERT koriste graničnu informaciju RC tijekom predviđanja reči na način na koji odgovara pravilima engleske gramatike; Ova granična informacija RC generalizuje u velikoj mjeri u različitim tipovima RC-a, sugerirajući da BERT predstavlja RC kao apstraktnu lingvističku kategoriju.', 'ta': 'மொழி மாதிரிகள் செயல்படும் சிக்கலான வாக்கியங்களை ஒத்திசைவாக செயல்படுத்தும்போது, மொழியின் வரைப்படத்துடன் ஒத்திசைப்படு இந்த கேள்வியை தேர்வு செய்ய ஒரு இடைவெளி முறையை நாம் மாற்றுகிறோம். கொடுக்கப்பட்ட வாக்கியத்தின் எந்த மொழியில் குணங்களுக்கும், மாற்று மாற்றி மாற்றும் தன்மைக் குறியீட்டு எப்படி மாற்றும், முதலில் உள்ள அனைத மாதிரியின் வார்த்தை முன்னோட்டு நடத்தையின் மாற்றங்களை அளவிடுவதால் இந்த எதிர்காரண குறிப்புகள் முதலில் மாற்றப்படும் போது, மாதிரியின் நடத்தையின் காரணத நாம் இந்த முறையை பயன்படுத்தி பிரெட் மாதிரிகளை எவ்வாறு வேறு அளவுகள் செயல்பாடு சார்ந்த குறிப்புகளின் (RCகள்) ச BERT மாறிகள் RC எல்லை விவரங்களை பயன்படுத்தும் வார்த்தை முன்வெளிப்பாட்டிற்கு போது அது ஆங்கிலத்தின் கிராமம் விதிகளு இந்த ஆர்சி எல்லை தகவல் வேறு ஆர்சி வகைகளுக்கு முழுமையான அளவில் பொதுவாக்குகிறது, BERT RC களை ஒதுக்கிராக் மொழி வகையாக பிரித்துக்கொள்', 'ur': 'جب زبان مدلکوں کو سینٹیکٹی پیچیدہ جماعتوں کی پیدائش کرتا ہے تو کیا وہ اپنے سینٹکس کی تصویر کو ایسی طریقے سے استعمال کرتے ہیں جو زبان کی گرماٹی کے ساتھ مطابق ہے؟ ہم AlterRep کی پیشنهاد کریں گے، اس سؤال کے بارے میں ایک انٹرنس کی بنیادی طریقہ۔ جتنے لکھے ہوئے جماعت کے ہر زبان ویژگی ویژگی کے لئے، AlterRep نے مخالف حقیقی معجزات پیدا کیے ہیں، اس طرح ویژگی کی کوڈی کی جاتی ہے، حالانکہ اصلی نمایش کے تمام دوسرے منظور کو چھوڑ دیتے ہیں. ایک موڈل کے کلمات کی پیش بینی رفتار کی بدلنے کے ذریعہ اندازے سے جب یہ مخالف دکھانے کی بدلنے کی جاتی ہیں، ہم موڈل کے رفتار پر سوال میں زبان شناسی فکرت کے سبب کے باعث نتیجے کرسکتے ہیں. ہم اس طریقہ کو پڑھنے کے لئے استعمال کرتے ہیں کہ BERT موڈل کس طرح مختلف اندازوں کے پرسس نسبت کلاس (RC) کے مطابق۔ ہم دیکھتے ہیں کہ BERT متغیرات کلمات کی پیش بینی کے وقت RC مرز معلومات کا استعمال کرتی ہیں ایک طریقہ سے جو انگلیسی گرماٹی کے قانون کے مطابق ہے۔ یہ RC حدود کی معلومات مختلف RC طریقوں میں بہت زیادہ متفاوت ہوتی ہے، جو بتاتی ہے کہ BERT RC کو صریح زبان کی کاٹی کے طور پر نمایش دیتا ہے.', 'sv': 'När språkmodeller bearbetar syntaktiskt komplexa meningar, använder de sina framställningar av syntax på ett sätt som överensstämmer med språkets grammatik? Vi föreslår AlterRep, en interventionsbaserad metod för att ta itu med denna fråga. För varje språklig egenskap i en given mening genererar AlterRep kontrafaktiska representationer genom att ändra hur funktionen kodas, samtidigt som alla andra aspekter av den ursprungliga representationen lämnas i kontakt. Genom att mäta förändringen i en modells ordprediktionsbeteende när dessa kontrafaktiska representationer ersätts med de ursprungliga, kan vi dra slutsatser om orsakseffekten av den språkliga funktionen i fråga på modellens beteende. Vi använder denna metod för att studera hur BERT-modeller av olika storlekar bearbetar relativa klausuler (RCs). Vi finner att BERT-varianter använder RC-gränsinformation vid ordprediktion på ett sätt som är förenligt med reglerna för engelsk grammatik; Denna RC-gränsinformation generaliserar i betydande utsträckning över olika RC-typer, vilket tyder på att BERT representerar RC som en abstrakt språklig kategori.', 'uz': "Tillar modellari birlashtirilgan murakkab soʻzlarni bajarayotganda, ular tillarning grammatika bir xil boʻlgan usulda foydalaniladi? Biz bu savol boshqarish uchun AlterRep, intervention asosiy usuli. Name Modelning so'zlarini o'zgartirish natijasida o'zgarishni o'zgartirish orqali o'zgartirishimiz mumkin, biz modelning xususiyatining sabablar natijasi haqida o'ylab turamiz. Biz bu usulni o'rganish uchun BERT modellarini o'rganish uchun boshqa siz jarayonlarining qismlari (RCs). Biz o'ylaymiz, BERT varianteri biz so'zlar taqdimotida bir so'zlik grammatika bir xil qoidalarida RC chegara maʼlumotdan foydalanadi; Bu RC chegarasi maʼlumotni boshqa tarkibi RC turlariga aniqlanadi, BERT RCs'ni abstract lingvistik turi deb belgilaydi.", 'vi': 'Khi các mô hình ngôn ngữ xử lý các câu phức tạp, họ có sử dụng các biểu hiện của cú pháp theo cách phù hợp với ngữ pháp của ngôn ngữ không? Chúng tôi đề nghị Thay đổi Rep, một phương pháp được dùng để giải quyết câu hỏi này. Thay đổi khả năng ngôn ngữ của một bản, thay đổi khả năng ghi chép của nó bằng cách thay đổi cách mã hóa chức năng trong khi kiểm tra các khía cạnh khác của đại diện gốc. Bằng cách đo lường s ự thay đổi trong hành vi dự đoán từ của mô hình khi những biểu hiện ngược với những biểu hiện gốc, chúng tôi có thể kết luận về hiệu quả của tính năng ngôn ngữ đó trên hành vi của mô hình. Chúng tôi áp dụng phương pháp này để nghiên cứu cách xử lý các mô hình BERT với các kích thước khác nhau (RCs). Chúng tôi thấy rằng các biến thể của BERT sử dụng thông tin biên giới RC trong giai đoạn từ dự đoán theo cách phù hợp với các quy tắc của ngữ pháp Anh. Thông tin biên giới này quy định một mức độ lớn về các loại RC khác nhau, gợi ý rằng BERT đại diện C như một loại ngôn ngữ trừu tượng.', 'da': "Når sprogmodeller behandler syntaktisk komplekse sætninger, bruger de så deres syntaksrepræsentationer på en måde, der er i overensstemmelse med sprogets grammatik? Vi foreslår AlterRep, en interventionsbaseret metode til at løse dette spørgsmål. For ethvert sprogligt træk i en given sætning genererer AlterRep kontrafaktiske repræsentationer ved at ændre, hvordan funktionen er kodet, samtidig med at alle andre aspekter af den oprindelige repræsentation efterlades i berøring. Ved at måle ændringen i en models ordforudsigelsesadfærd, når disse kontrafaktiske repræsentationer erstattes af de oprindelige, kan vi drage konklusioner om årsagseffekten af det pågældende sproglige træk på modellens adfærd. Vi anvender denne metode til at undersøge, hvordan BERT-modeller af forskellige størrelser behandler relative klausuler (RCs). Vi finder ud af, at BERT varianter bruger RC grænseoplysninger under ordforudsigelse på en måde, der er i overensstemmelse med reglerne i engelsk grammatik; disse RC-grænseoplysninger genererer i betydelig grad på tværs af forskellige RC-typer, hvilket tyder på, at BERT repræsenterer RC'er som en abstrakt sproglig kategori.", 'bg': 'Когато езиковите модели обработват синтактично сложни изречения, използват ли те своите представи на синтаксиса по начин, който съответства на граматиката на езика? Предлагаме алтернативен реп, базиран на интервенция метод за решаване на този въпрос. За всяка лингвистична характеристика на дадено изречение AlterRep генерира контрафактически представяния, като променя начина на кодиране на характеристиката, като същевременно оставя в такт всички останали аспекти на оригиналното представяне. Чрез измерване на промяната в поведението на модела за предсказване на думи, когато тези контрафактически представи са заменени с оригиналните, можем да направим заключения за причинно-следствения ефект на въпросната лингвистична характеристика върху поведението на модела. Ние прилагаме този метод, за да проучим как моделите от различни размери обработват относителни клаузи (РС). Установяваме, че вариантите използват информация за границите при предсказване на думи по начин, който е съобразен с правилата на английската граматика; тази информация за границите на РС се обобщава в значителна степен в различните типове РС, което предполага, че BERT представлява РС като абстрактна лингвистична категория.', 'de': 'Wenn Sprachmodelle syntaktisch komplexe Sätze verarbeiten, verwenden sie dann ihre Repräsentationen der Syntax in einer Weise, die mit der Grammatik der Sprache übereinstimmt? Wir schlagen AlterRep vor, eine interventionsbasierte Methode, um diese Frage zu beantworten. Für jedes sprachliche Merkmal eines bestimmten Satzes erzeugt AlterRep kontrafaktische Darstellungen, indem es die Kodierung des Merkmals ändert, während alle anderen Aspekte der ursprünglichen Darstellung in Berührung bleiben. Durch die Messung der Veränderung des Wortvorhersageverhaltens eines Modells, wenn diese kontrafaktischen Repräsentationen durch die ursprünglichen ersetzt werden, können wir Rückschlüsse auf den kausalen Effekt des fraglichen linguistischen Merkmals auf das Verhalten des Modells ziehen. Mit dieser Methode untersuchen wir, wie BERT-Modelle unterschiedlicher Größe Relativklauseln (RCs) verarbeiten. Wir finden heraus, dass BERT-Varianten RC-Grenzinformationen während der Wortvorhersage in einer Weise verwenden, die mit den Regeln der englischen Grammatik übereinstimmt; Diese RC-Grenzinformationen verallgemeinern sich in erheblichem Maße über verschiedene RC-Typen, was darauf hindeutet, dass BERT RCs als abstrakte linguistische Kategorie darstellt.', 'id': 'Ketika model bahasa memproses kalimat sintaks kompleks, apakah mereka menggunakan representation sintaks mereka dengan cara yang konsisten dengan grammar bahasa? Kami mengusulkan AlterRep, metode berdasarkan intervensi untuk mengatasi pertanyaan ini. Untuk fitur bahasa apapun dari kalimat tertentu, AlterRep menghasilkan representation kontrafaktual dengan mengubah bagaimana fitur dikodeksi, sementara meninggalkan dalam- takt semua aspek lain dari representation asli. Dengan mengukur perubahan dalam perilaku prediksi kata model ketika represisi kontrofaksi ini diganti untuk yang asli, kita dapat menarik kesimpulan tentang efek penyebab dari karakteristik bahasa yang dipertanyakan pada perilaku model. Kami menerapkan metode ini untuk mempelajari bagaimana model BERT dari ukuran berbeda memproses klausul relatif (RC). Kami menemukan bahwa varian BERT menggunakan informasi perbatasan RC selama prediksi kata dalam cara yang konsisten dengan aturan grammar Inggris; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category.', 'ko': '언어 모델이 문법이 복잡한 문장을 처리할 때, 그것들은 언어 문법과 일치하는 방식으로 문법 표시를 사용합니까?우리는 AlterRep을 제기하여 이 문제를 해결하는 데 관여하는 방법을 제시했다.주어진 문장의 모든 언어 특징에 대해 AlterRep는 특징의 인코딩을 바꾸어 반사실 표현을 생성하고 원시 표현의 모든 다른 방면을 보존한다.이러한 반사실적 표징이 원시 표징을 대체할 때 모델 단어가 행위를 예측하는 변화를 측정함으로써 우리는 언어 특징이 모델 행위에 미치는 인과적 영향에 대한 결론을 얻을 수 있다.우리는 이런 방법을 응용하여 서로 다른 규모의 BERT 모델이 관계종문(RCs)을 어떻게 처리하는지 연구한다.우리는 BERT 변체가 단어 예측에서 RC 경계 정보를 사용하는 방식이 영어 문법 규칙에 부합되는 것을 발견했다.이런 RC 경계 정보는 어느 정도에 서로 다른 RC 유형을 요약하고 버트가 RCs를 추상적인 언어 범주로 표시했음을 나타낸다.', 'nl': 'Wanneer taalmodellen syntactisch complexe zinnen verwerken, gebruiken ze dan hun representaties van syntaxis op een manier die consistent is met de grammatica van de taal? We stellen AlterRep voor, een interventiegebaseerde methode om deze vraag aan te pakken. Voor elk taalkundig kenmerk van een bepaalde zin genereert AlterRep contrafactische representaties door de manier waarop het kenmerk is gecodeerd te wijzigen, terwijl alle andere aspecten van de oorspronkelijke representatie in tact blijven. Door de verandering in het woordvoorspellingsgedrag van een model te meten wanneer deze contrafactische representaties worden vervangen door de oorspronkelijke, kunnen we conclusies trekken over het causale effect van de betreffende linguïstische eigenschap op het gedrag van het model. We passen deze methode toe om te onderzoeken hoe BERT modellen van verschillende groottes relatieve clausules (RCs) verwerken. We vinden dat BERT-varianten RC-grensinformatie gebruiken tijdens woordvoorspelling op een manier die consistent is met de regels van de Engelse grammatica; Deze RC-grensinformatie veralgemeent in aanzienlijke mate over verschillende RC-typen, wat suggereert dat BERT RCs vertegenwoordigt als een abstracte linguïstische categorie.', 'hr': 'Kada jezički modeli procesiraju sintaktički kompleksne rečenice, da li koriste svoje zastupanje sintaksije na način koji odgovara gramatici jezika? Predlažemo AlterRep, metodu temeljenu na intervenciji da se riješimo ovom pitanju. Za bilo koju jezičku karakteristiku određene rečenice, AlterRep stvara lažne predstave mijenjajući način kodiranja karakteristike, dok odlaze u taktiku sve ostale aspekte originalne predstave. Mjerajući promjenu predviđanja riječi model a kada su te pretjeračne predstave zamijenjene za originalne, možemo nacrtati zaključke o uzrokovanom učinku jezičke funkcije u pitanju na ponašanje modela. Primjenjujemo ovu metodu da proučimo kako BERT modeli različitih veličina procesiraju relativne klauzule (RC). Pronašli smo da varianti BERT koriste granične informacije RC tijekom predviđanja riječi na način koji odgovara pravilima engleske gramatike; Ova granična informacija RC-a generalizira u velikoj mjeri u raznim tipovima RC-a, ukazujući na to da BERT predstavlja RC kao apstraktnu lingvističku kategoriju.', 'fa': 'زمانی که مدل زبان\u200cها جمله\u200cهای پیچیده\u200cای را فرایند می\u200cکنند، آیا آنها از نمایش\u200cهای خود استفاده می\u200cکنند به طریقی که با نمایش\u200cهای زبان موجود است؟ ما پیشنهاد AlterRep را می\u200cدهیم، یک روش بر اساس مدارک برای حل این سوال. برای هر ویژگی زبان\u200cشناسی از یک جمله داده شده، AlterRep با تغییر کردن چگونه ویژگی\u200cها رمزگذاری می\u200cشود، در حالی که همه\u200cی ویژه\u200cهای دیگری از نمایش اصلی را ترک می\u200cکند. با اندازه\u200cگیری تغییرات در رفتار پیش\u200cبینی کلمه یک مدل وقتی این نمایش\u200cهای ضبط\u200cحقیقی برای نمایش\u200cهای اصلی جایگزین می\u200cشوند، می\u200cتوانیم نتیجه\u200cها را درباره\u200cی تاثیر دلیلی از ویژه\u200cهای زبان\u200cشناسی در سوال بر رفتار مدل بکنیم. ما این روش را برای مطالعه کردن چگونه مدل BERT از اندازه\u200cهای مختلف فرآیند کلاس\u200cهای نسبت (RC) استفاده می\u200cکنیم. ما پیدا می\u200cکنیم که متغیرات BERT در طول پیش بینی کلمه از اطلاعات مرز RC استفاده می\u200cکنند به طریقی که با قوانین گرامی انگلیسی قابل توافق است. این اطلاعات مرز RC به اندازه بسیار زیادی از نوع RC متفاوت متفاوت می\u200cشود که BERT به عنوان یک نوع زبان مطلق RC نمایش می\u200cدهد.', 'af': "Wanneer taal modelles sintaktisies komplekse setings proses, gebruik hulle voorstellings van sintaks in 'n manier wat konsistent is met die grammatiek van die taal? Ons voorstel AlterRep, 'n intervention-gebaseerde metode om hierdie vraag te adres. Vir enige lingwisiese eienskap van 'n gegewe seting, AlterRep genereer teenwerklike voorstellings deur te verander hoe die eienskap kodeerd is, terwyl alle ander aspekte van die oorspronklike voorstelling verlaat word. Deur die verandering in 'n model se woord voorskou gedrag te maak wanneer hierdie kontrafeilike voorskyning vir die oorspronklike voorskyning vervang word, kan on s conclusies teken oor die oorsaaklike effek van die lingvisiese funksie in vraag op die model se gedrag. Ons het hierdie metode aanwend om te studier hoe BERT modele van verskillende grootte proses relatiewe klauses (RCs). Ons vind dat BERT variante RC grens inligting gebruik tydens woord voorskou in 'n manier wat ooreenkomstig is met die reëls van Engelske grammatiek; Hierdie RC grens inligting genereliseer na 'n aansienlike uitbreiding oor verskillende RC tipes, voorstel dat BERT RCs as 'n abstrakte lingvisiese kategorie verteenwoordig word.", 'tr': "Dil nusgalary sintaktik karmaşık sözleri işleýände, diliň gramatiýasy bilen bir şekilde ylalaşýarlar? Biz AlterRep'i, bu soragy çözmek üçin bir aralyga tabanly bir yöntem teklip edip görýäris. Berilen sözläniň her hili dil özellikleri üçin AlterRep üýtgewleri nähili kodlaýandygyny üýtgedir we orijinal suratynyň beýleki sahypalaryny üýtgedir. Bir modeliniň s öz öngörümlerini ölçüp bu netijesi original çykyşlar üçin üýtgedilýän zaman, modeliniň davranışynda lingwistiki özellikleriň sebäpli netijesini çykyp bileris. BERT nusgalarynyň farklı ölçüleriniň (RC) klaslarynyň nädip işleýändigini öwrenmek üçin bu ýola uygulapdyrys. BERT wariantlaryň söz öňünde RC sahypalaryny Iňlis gramatiýasynyň düzgünlerine uygun bir şekilde ulanýandygyny görýäris; Bu RC sınır maglumaty farklı RC türlerinde örän möhüm bir şekilde döredir, BERT'yň RC'i abstrakt dil kategoriýasy hökmünde temin edip bilýär.", 'sw': 'Wakati mifano ya lugha huendesha sentensi tata, je, wanatumia uwakilishi wao wa kodi kwa namna inayofanana na gramma ya lugha? Tunapendekeza AlterRep, njia inayotumika na kuingilia swali hili. Kwa utambulisho wowote wa lugha wa hukumu iliyotolewa, AlterRep hutengeneza uwakilishi wa a in a tofauti kwa kubadilisha namna utaratibu huo unavyowekwa, wakati akiacha - kukabiliana na mambo mengine mengine ya uwakilishi wa awali. Kwa kupima mabadiliko ya tabia ya utabiri wa muundo wakati wakiwakilisha maoni haya yanabadilishwa kwa ajili ya asili, tunaweza kuchora hitimisho kuhusu madhara ya utambulisho wa lugha katika maswali ya tabia za mtindo. Tunatumia mbinu hii ili kusoma namna mbinu za BERT za mchakato tofauti unavyohusiana na makubaliano (RCs). Tunapata kwamba mabadiliko ya BERT hutumia taarifa za mipaka ya RC wakati wa utabiri wa maneno kwa namna ambayo yanaunganisha na kanuni za gramma ya Kiingereza; taarifa hizi za mipaka ya RC zinatengeneza kwa kiwango kikubwa katika aina mbalimbali za RC, zinazopendekeza kwamba BERT inawakilisha RCs kama kigezo cha lugha tofauti.', 'sq': 'Kur modelet e gjuhës procesojnë fraza sintetikisht komplekse, a përdorin përfaqësimet e tyre të sintaksit në një mënyrë që është në përputhje me gramatikën e gjuhës? Ne propozojmë AlterRep, një metodë bazuar në ndërhyrje për të trajtuar këtë pyetje. Për çdo karakteristikë gjuhësore të një fjalie të caktuar, AlterRep gjeneron përfaqësime kundërfaktore duke ndryshuar se si karakteristika është koduar, duke lënë në-takt të gjitha aspektet e tjera të përfaqësimit origjinal. Duke matur ndryshimin në sjelljen e parashikimit të fjalës s ë një modeli kur këto përfaqësime kundërfaktore zëvendësohen për ato origjinale, ne mund të tërheqim përfundime rreth efektit shkak të karakteristikës gjuhësore në diskutim mbi sjelljen e modelit. Ne zbatojmë këtë metodë për të studiuar se si modelet BERT të madhësive të ndryshme procesojnë klauzula relative (RCs). Ne zbulojmë se variantet BERT përdorin informacionin kufitar RC gjatë parashikimit të fjalëve në një mënyrë që është në përputhje me rregullat e gramatikës angleze; ky informacion kufitar RC gjeneralizon në një shkallë të konsiderueshme nëpërmjet tipeve të ndryshëm RC, duke sugjeruar se BERT përfaqëson RC si një kategori gjuhësore abstrakte.', 'hy': "When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language?  Մենք առաջարկում ենք Ալտեր Ռեպ, միջամտելու հիմնված մեթոդ այս հարցի լուծման համար: Տեղադրված նախադասության ցանկացած լեզվաբանական առանձնահատկության համար ALTERREP-ը ստեղծում է հակափաստական ներկայացումներ' փոխելով առանձնահատկության կոդավորման ձևը, միաժամանակ թողնելով հնարավոր ներկայացման բոլոր այլ առանձնահատկությունները: Մոդելի բառերի կանխատեսման պահվածքի փոփոխությունը չափելով, երբ այս հակափաստական ներկայացումները փոխարինվում են սկզբնական ներկայացումներին, մենք կարող ենք եզրակացություններ կատարել այդ լեզվաբանական առանձնահատկության պատճառային ազդեցության մասին մոդելի պահվածքի վրա: Մենք կիրառում ենք այս մեթոդը, որպեսզի ուսումնասիրենք, թե ինչպես են տարբեր չափերի BER մոդելները վերլուծում հարաբերական բառերը (ՌԿ-ները): Մենք հայտնաբերում ենք, որ BER տարբերակները օգտագործում են ՌԿ-ի սահմանային տեղեկությունը բառերի կանխատեսման ժամանակ այնպես, որ համապատասխանում է անգլերենի գրաֆիկայի կանոններին: այս ՌԿ սահմանային տեղեկատվությունը մեծ մասամբ ընդհանուր է տարբեր ՌԿ տեսակների միջև, առաջարկում է, որ ԲԵՌթը ներկայացնում է ՌԿ-ը որպես վերացական լեզվաբանական կատեգորիա:", 'am': 'ቋንቋ ምሳሌዎች በተጨማሪው ውጤቶች ሲሞክሩ፣ በቋንቋው ቋንቋ ማህበረሰብ በተደጋገመ የሲንካስብ መልዕክቶች ይጠቀቃሉን? ይህንን ጥያቄ ለመቀበል የሚደረገውን የጣራ መግለጫ እናስባለን፡፡ ለቋንቋዊ ክፍል በተሰጠው የቋንቋ ምርጫዎች፣ AlterRep የፊደል መልዕክቶች እንዴት እንደሚለወጥ በመለወጥ ይሠራል፡፡ የሞዴል ቃላት የመፍጠር ቃላት ቀለም በመለካት፣ እነዚህ ተቃዋሚ መልዕክቶች ለመጀመሪያዎቹ በተለወጡ ጊዜ፣ የቋንቋዊው ጥያቄ በሞዴል ሥርዓት ላይ የሚደረገውን የውጤት ውጤት እናሳውቃለን፡፡ የBERT ዓይነቶች የልዩ ልዩ ደረጃዎች ክፍተቶችን (RCs) እንዳደረገ እናስተምር ዘንድ ይህንን ሥርዓት እናደርጋለን፡፡ BERT variables RC ዳርቻ መረጃዎችን በመስጠት በአንግሊዝኛ ትርጉም ሥርዓት በተደጋገመ እንደሆነ እናገኛለን፡፡ ይህ የRC ዳርቻ መረጃ በተለዩ RC ዓይነቶች ላይ በተለየ ጥያቄ ያቆማል፡፡ BERT RCs እንደ ተቃውሞ ቋንቋ ክፍተት ያቆማል፡፡', 'az': "Dil modelləri sintaktik olaraq kompleks sözləri işlədikdə dilin gramatika ilə uyğun şəkildə sintaks göstəricilərini istifadə edirlər? Biz bu suala çəkmək üçün AlterRep təklif edirik. Verilən cümlənin hər bir dil özelliğin ə görə AlterRep özünün kodlanmasını dəyişdirərək, orijinal göstəricisinin bütün başqa aspectlərini tərk edir. Modelin s özlərin tədbir davranışlarının dəyişikliyini ölçürək, bu tədbir göstəricilərin əvəzinə tədbir edildikdə, model in davranışı haqqında sual edilən dil özelliğinin səbəbi təsiri haqqında sonuçları çəkə bilərik. Biz bu metodu müxtəlif ölçülərin BERT modellərinin necə işlədiyini öyrənmək üçün istifadə edirik. Beləliklə, BERT dəyişikliklərinin RC sınır məlumatını sözlərin tədbir sırasında İngilizə gramatika qanunlarına uyğun bir yolla istifadə edir. Bu RC sınır məlumatı fərqli RC türlərinin arasında çox böyük bir dəyişiklik olar, BERT'nin RC'ləri abstrakt dil kategoriyası olaraq göstərir.", 'cs': 'Pokud jazykové modely zpracovávají syntakticky složité věty, používají své reprezentace syntaxe způsobem, který je v souladu s gramatikou jazyka? Navrhujeme AlterRep, intervenční metodu pro řešení této otázky. Pro libovolný jazykový rys dané věty AlterRep generuje kontrafactické reprezentace tím, že změní způsob kódování prvku, přičemž ponechává v kontaktu všechny ostatní aspekty původní reprezentace. Měřením změny v chování predikce slov modelu, když jsou tyto kontrafactické reprezentace nahrazeny za původní, můžeme vyvodit závěry o příčinném vlivu daného jazykového rysu na chování modelu. Používáme tuto metodu ke studiu, jak BERT modely různých velikostí zpracovávají relativní klauzule (RCs). Zjišťujeme, že varianty BERT využívají informace o hranicích RC při predikci slova způsobem, který je v souladu s pravidly anglické gramatiky; Tato informace o hranicích RC se do značné míry zobecňuje napříč různými typy RC, což naznačuje, že BERT reprezentuje RCs jako abstraktní jazykovou kategorii.', 'bs': 'Kada jezički modeli procesiraju sintaktički kompleksne rečenice, da li koriste svoje predstave sintaksije na način na koji odgovara gramatici jezika? Predlažemo AlterRep, metodu na temelju intervencije da riješimo ovo pitanje. Za bilo koju jezičku karakteristiku određene rečenice, AlterRep stvara falsifikalne predstave mijenjajući način kodiranja funkcije, dok odlaze u taktiku sve ostale aspekte originalne predstave. Mjerajući promjenu predviđanja riječi model a, kada se ovi kontrafaktični predstavnici zamjenjuju za originalne, možemo nacrtati zaključke o uzročnom učinku jezičkog karakteristika u pitanju na ponašanje modela. Primjenjujemo ovu metodu da proučimo kako BERT modeli različitih veličina procesiraju relativne klauzule (RC). Pronašli smo da varianti BERT koriste graničnu informaciju RC tijekom predviđanja riječi na način na koji odgovara pravilima engleske gramatike; Ova granična informacija o RC-u generalizuje u velikoj mjeri u raznim tipovima RC-a, sugerirajući da BERT predstavlja RC kao apstraktnu lingvističku kategoriju.', 'ca': "Quan els models de llenguatge processen frases sinàcticament complexes, utilitzen les seves representacions de sintaxi d'una manera que està coherent amb la gramàtica del llenguatge? Proposem AlterRep, un mètode basat en intervenció per abordar aquesta pregunta. Per a qualsevol característica lingüística d'una frase dada, AlterRep genera representacions contrafetes canviant la codificació de la característica, deixant en contacte tots els altres aspectes de la representació original. Medint el canvi en el comportament de predicció de paraules d'un model quan aquestes representacions contrafetiques s ón substituïdes per les original s, podem treure conclusions sobre l'efecte causal de la característica lingüística en qüestió sobre el comportament del model. Aplicam aquest mètode per estudiar com els models BERT de diferents dimensions processen clàusules relativas. Trobem que les variants BERT utilitzen la informació sobre les fronteres RC durant la predicció de paraules d'una manera que està coherent amb les regles de la gramàtica anglesa; aquesta informació fronteriza del RC s'generalitza en gran medida a diferents tipus de RC, suggerent que el BERT representa els RC com a categoria lingüística abstracta.", 'bn': 'When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language?  আমরা প্রস্তাব করছি আল্টাররেপ, এই প্রশ্নের কথা বলার একটি ইন্টারনেটভিত্তিক পদ্ধতি। প্রদত্ত বাক্যের যে কোন ভাষাগত বৈশিষ্ট্যের জন্য AlterRep তৈরি করে কিভাবে এই বৈশিষ্ট্য এনকোড করা হয়, যখন তারা মূল প্রতিনিধিত্বের অন্যান্য প্রতিনিধ মোডেলের শব্দের ভবিষ্যদ্বাণী আচরণের পরিবর্তন পরিমাপের মাধ্যমে যখন এই প্রতিনিধিত্বের প্রথম প্রতিনিধির জন্য প্রতিনিধিত্ব করা হয়, তখন আমরা মডেলের আচরণের কারণে ভাষাগত আমরা বিভিন্ন আকারের প্রক্রিয়ার মডেল কিভাবে প্রক্রিয়া আত্মিক ক্লায়াস (RCs) পড়ার জন্য এই পদ্ধতি প্রয়োগ করি। আমরা খুঁজে পাচ্ছি যে বেরেটি ভেরিয়েন্টরা শব্দের ভবিষ্যদ্বাণীর সময় RC সীমান্ত তথ্য ব্যবহার করে যেভাবে ইংরেজি গ্রামার এই RC সীমানার তথ্য বিভিন্ন RC ধরনের ব্যাপক পরিমাণে জেনারেল করে, যার পরামর্শ দেয়া হচ্ছে যে বিবেরেট রিসিকে এক অস্বীকৃত ভাষার বিভাগ হিসে', 'fi': 'Kun kielimallit käsittelevät syntaktisesti monimutkaisia lauseita, käyttävätkö he syntaksin esitystään tavalla, joka on sopusoinnussa kielen kieliopin kanssa? Ehdotamme AlterRep:tä, interventioon perustuvaa menetelmää tämän kysymyksen ratkaisemiseksi. Minkä tahansa lauseen kielellisen ominaisuuden osalta AlterRep luo vastakohtaisia esityksiä muuttamalla ominaisuuden koodausta, jättäen samalla kosketuksiin kaikki alkuperäisen esityksen muut näkökohdat. Mittaamalla mallin sanaennustuskäyttäytymisen muutosta, kun nämä vastakohtaiset esitykset korvataan alkuperäisillä, voimme tehdä johtopäätöksiä kyseisen kielellisen ominaisuuden syy-vaikutuksesta mallin käyttäytymiseen. Tämän menetelmän avulla tutkimme, miten erikokoiset BERT-mallit käsittelevät suhteellisia lausekkeita (RCs). Huomaamme, että BERT-variantit käyttävät RC-rajatietoja sanojen ennustamisessa tavalla, joka on sopusoinnussa englannin kieliopin sääntöjen kanssa; Tämä RC-raja-informaatio yleistyy huomattavasti eri RC-tyypeille, mikä viittaa siihen, että BERT edustaa RCs:tä abstraktina kielellisenä kategoriana.', 'et': 'Kui keelemudelid töötlevad süntaktiliselt keerukaid lauseid, kas nad kasutavad oma süntaksi esitusi viisil, mis on kooskõlas keele grammatikaga? Me pakume välja AlterRep, sekkumisel põhineva meetodi selle küsimuse lahendamiseks. Iga lause keelelise iseloomu puhul tekitab AlterRep vastufaktuaalseid esitusi, muutes selle kodeerimist, jättes samas sisse kõik teised algse esituse aspektid. Mõõtes mudeli sõna ennustamise käitumise muutust, kui need vastufaktuaalsed esitused asendatakse algsete esitustega, saame teha järeldusi kõnealuse keelelise tunnuse põhjusliku mõju kohta mudeli käitumisele. Selle meetodi abil uurime, kuidas erineva suurusega BERT mudelid töötlevad suhtelisi klausleid (RCs). Leiame, et BERT variandid kasutavad RC piiriteavet sõna ennustamisel viisil, mis on kooskõlas inglise grammatika reeglitega; see RC piiriteave üldistub märkimisväärsel määral erinevate RC tüüpide vahel, mis viitab sellele, et BERT esindab RCsid abstraktse keelelise kategooriana.', 'jv': 'Laptop" and "Desktop We proposal Alterrep, an interance-supported method to Address this question. Alterrep generated count representations by Alterrep Nerimo kuwi nggawe gerambut kanggo languangguna barêng model kuwi, iso disebarke cara nggawe barang languangguna kuwi mau Awakdhéwé aplikasi ngono kuwi nggambar model BERT karo akeh basa gambar nggawe Awak dhéwé éntuk karo variant BERT iso ngubah informasi nggawe barang nggawe barang nggambar barang nggambar barang ingles Informasi nggawe barang PNG iki dipunanggé kanggo kalaayuni sampeyan anyar tentang', 'ha': "Idan misãlai-harshen za'a yi aiki a haɗikant, za'a yi amfani da masãlanin su masu haɗuwa da matsayin sunanta cikin wani irin da ya sami da grammar harshen? Tuna goyyar da AlterRep, wata hanyor a kan yin magana ga wannan tambayi. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the feature is encoded, while leaving in- tact all other aspects of the original representation.  Ina iya ƙayyade musanyi cikin al'amarin na ɗabi'a-ayuka idan an canza waɗannan masu motsi masu motsi zuwa masu farko, za'a iya goyi ƙarshen ƙaramako ga muhimmin littafan lingui masu tambaya kan aikin motel. Tuna amfani da wannan hanyon ya karanta misãlai na BERT na danganta cikin jarayon girgije masu hushi (RCs). Tuna gane cewa masu variant na BERT sunã amfani da maɓallin tsari na RC a lokacin da ake yi bayani ga kalmar da ke sami da takardar grammar Ingiriya; @ item: inmenu", 'sk': 'Ko jezikovni modeli obdelujejo sintaktično kompleksne stavke, ali uporabljajo svoje predstavitve sintakse na način, ki je skladen s slovnico jezika? Predlagamo AlterRep, intervencijsko metodo za obravnavanje tega vprašanja. Za vsako jezikovno značilnost danega stavka AlterRep ustvarja kontrafaktualne reprezentacije tako, da spremeni način kodiranja značilnosti, hkrati pa prepušča vse druge vidike izvirne reprezentacije. Z merjenjem spremembe besednega napovedovalnega vedenja modela, ko se te kontrafaktualne reprezentacije nadomestijo z izvirnimi, lahko sklepamo o vzročnem učinku zadevne jezikovne značilnosti na vedenje modela. To metodo uporabljamo za preučevanje, kako BERT modeli različnih velikosti obdelujejo relativne klavzule (RCs). Ugotavljamo, da različice BERT med napovedovanjem besed uporabljajo informacije o mejah RC na način, ki je skladen s pravili angleške slovnice; te informacije o mejah RC se v veliki meri posplošijo v različnih vrstah RC, kar kaže, da BERT predstavlja RCs kot abstraktno jezikovno kategorijo.', 'he': 'כאשר דוגמני שפה מעבדים משפטים מסובכים באופן סינטקטי, הם משתמשים בייצוגים שלהם של סינטקס באופן שמתאים לתרמטיקה של השפה? אנחנו מציעים AlterRep, שיטה מבוססת התערבות כדי להתמודד עם השאלה הזאת. עבור כל תכונה שפתית של משפט מסוים, AlterRep יוצר מייצגים נגד עובדות על ידי שינוי איך התוכנית מוצפנת, בעוד משאיר את כל היבטים האחרים של הייצגה המקורית באופן טקטי. על ידי למדוד את השינוי בתנהגות חזיון מילים של דוגמנית כאשר היציגות הלא-עובדות האלה מוחלפות למוצאות המקוריות, אנו יכולים למצוא מסקנות על השפעה הסיבית של התחום הלשוני בספק על התנהגותו של דוגמנית. אנחנו משתמשים בשיטה זו כדי ללמוד איך דוגמנים BERT של גודלים שונים מעבדים פסקים יחסיים (RCs). אנחנו מוצאים ששונים BERT משתמשים במידע גבול RC במהלך חיזוי מילים באופן שיתואם לחוקים של גרמטיקה אנגלית; מידע גבול RC זה מתפשט במידה משמעותית בכל סוגי RC שונים, מצביע כי BERT מייצג RC כקטגוריה שפתית אסטרקטית.', 'bo': "སྐད་རིགས་མིག་དཔེ་དབྱེ་སྟངས་ལ་ཆ་སྦྱོར་བའི་ཚིག་རྟགས་ཀྱིས་སྦྱར་བའི་ཚིག་རྟགས་ལ་སྤྱོད་དགོས་སམ། ང་ཚོས་རྗེས་མཁན་གྱི་བསྒྱུར་བཅོས་དང་། ང་ཚོས་དྲི་ཚིག་འདི་བཤད་ཐབས་ལམ་ལ་གཞི་རྟེན་ཏེ། For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the feature is encoded, while leaving in-tact all other aspects of the original representation. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the feature is encoded, while leaving in-tact all other aspects of the original representation. By measuring the change in a model's word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the model's behavior. ང་ཚོས་བྱ་རིམ་འདི་ལྟ་བུ་ཅི་ཞིབ་ཚད་མི་འདྲ་བ་གི་ཆེ་ཆུང་མི་འདྲ་བ་དང་མཐུན་པའི་སྒྲིག་འགོད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་BERT་ཡི་སྣེ་ཚོགས་ཀྱི་འགྱུར་བ་དེ་ཚིག་གི་སྔོན RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category."}
{'en': 'Who’s on First? : Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains', 'ar': 'من هو أولاً؟: استكشاف قدرات التعلم والتمثيل لنماذج اللغة في المجالات المحددة المغلقة', 'fr': "Qui est sur First\xa0? : Sondage des capacités d'apprentissage et de représentation des modèles linguistiques dans des domaines fermés déterministes", 'es': '¿Quién sale primero? : Explorando las capacidades de aprendizaje y representación de los modelos lingüísticos en dominios cerrados deterministas', 'pt': 'Quem está em primeiro lugar?: Provando as capacidades de aprendizagem e representação de modelos de linguagem em domínios fechados determinísticos', 'zh': '孰先之?确定性封域上索言学以见能', 'ja': 'ファーストは誰だ？ ：決定論的クローズドドメイン上の言語モデルの学習および表現能力の探究', 'ru': 'Кто на "Первом"?: Исследование возможностей изучения и представления языковых моделей в детерминированных закрытых доменах', 'hi': 'पहले कौन है?: नियतात्मक बंद डोमेन पर भाषा मॉडल की सीखने और प्रतिनिधित्व क्षमताओं की जांच करना', 'ga': 'Cé atá ar Thús', 'ka': 'ვინ პირველად არის? სწავლება და გამოსახულება ენის მოდელების შესაძლებლობა დეტერმინისტიკური დახურებული დიომენების შესაძლებლობა', 'hu': 'Ki az első? A nyelvi modellek tanulási és reprezentációs képességeinek vizsgálata determinisztikus zárt tartományokon', 'el': 'Ποιος είναι στο Πρώτο; Έλεγχος των δυνατοτήτων εκμάθησης και αναπαράστασης των γλωσσικών μοντέλων σε ντετερμινιστικούς κλειστούς τομείς', 'it': 'Chi è al primo? Analisi delle capacità di apprendimento e rappresentazione dei modelli linguistici su domini chiusi deterministici', 'kk': 'Біріншіден кім бар? Дефинистикалық жабылған домендердің тіл үлгілерінің оқыту және таңдау мүмкіндігін тексеру', 'mk': "Who's on First?:  Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains", 'ml': "Who's on First?:  ഭാഷ മോഡലുകളുടെ പഠനത്തിന്റെയും പ്രതിനിധികളുടെയും ശക്തികള്\u200d പരിശോധിക്കുന്നു", 'mn': 'Эхлээд хэн байна вэ? Тодорхойлолтын хаягдсан хэл загварын суралцах болон төлөөлөх боломжуудыг судалж,', 'no': 'Kva er på første? Å prøve å lære og reprezentasjonskapasiteten for språk-modeller på definerte lukka domene', 'pl': 'Kto jest na pierwszym? Badanie możliwości uczenia się i reprezentacji modeli językowych na deterministycznych domenach zamkniętych', 'mt': 'Min huwa fuq l-Ewwel?:  L-ittestjar tal-Kapaċitajiet ta’ Tagħlim u Rappreżentanza tal-Mudelli tal-Lingwi fuq Domenijiet Deterministiċi magħluqa', 'lt': 'Kas pirmas? Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains', 'sr': 'Ko je na prvom? Verovatno je mogućnost učenja i predstavljanja jezičkih modela na određenim zatvorenim domenama', 'ms': 'Siapa yang pertama? Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains', 'si': 'කවුද පළවෙනි ඉන්නේ? විශ්වාසික වහලා තියෙන්නේ භාෂාව මොඩේන්ස් වලට ඉගෙන හා ප්\u200dරතිස්ථාපනය සක්ෂමතා', 'sv': 'Vem är på First? Undersökning av inlärnings- och representationsförmågan hos språkmodeller på deterministiska slutna domäner', 'ro': 'Cine e pe primul? Proiectarea capacităților de învățare și reprezentare a modelelor lingvistice pe domenii deterministe închise', 'so': 'Yaa ugu horeeya?: Horumarinta awoodda Barshada iyo Representation Models of Language on Deterministic Closed Domains', 'ta': 'யார் முதலில் இருக்கிறார்? மொழி மோடத்தின் படிப்புகள் மற்றும் பிரதிநிதிப்பு மூடிய கூட்டத்திற்கு முன்னிருப்பு படிப்புகள் மற்றும் த', 'ur': 'پہلے کون ہے؟ تعریف دینے والی ڈومین پر زبان مدل کی تعلیم اور نمایش کے قابلیت کی تصدیق کرنے کی', 'uz': 'Birinchi kim?: Name', 'vi': 'Ai chơi First? Đang phát triển khả năng học hỏi và phát triển ngôn ngữ mẫu trên các địa bàn tủ xác định', 'nl': 'Wie zit er op First? Onderzoek van de leer- en representatievermogen van taalmodellen op deterministische gesloten domeinen', 'da': 'Hvem er på første? Undersøgelse af sprogmodels lærings- og repræsentationsevner på deterministiske lukkede domæner', 'bg': 'Кой е на първа линия? Проучване на възможностите за учене и представителство на езиковите модели върху детерминистични затворени домейни', 'hr': 'Tko je na prvom? Vjerojatnost mogućnosti učenja i predstavljanja jezičkih modela na određenim zatvorenim domenama', 'fa': 'اول کي هست؟ شاید توانایی یادگیری و نمایش نمایش مدل زبان در دامنهای بسته\u200cشده\u200cی تعیین\u200cکننده', 'de': 'Wer ist auf First?: Untersuchung der Lern- und Repr瓣sentationsf瓣higkeit von Sprachmodellen auf deterministischen geschlossenen Dom瓣nen', 'ko': '누가 먼저 올라갑니까?확정적 폐쇄역상 언어 모델의 학습과 표현 능력을 탐색하다', 'sw': 'Nani yuko kwanza?: Kuonyesha uwezo wa Kufundisha na Kuwakilishwa kwa Modeli za Lugha Kuhusu Makazi Zifungwa', 'tr': 'Ilkinji adam? Däklemeler barada Diller öwrenmek we Görkezilişim Jakynlama Kiçimleri', 'sq': 'Kush është në fillim?: Prova e aftësive të mësimit dhe përfaqësimit të modeleve gjuhësore në domenet e mbyllura determinative', 'af': 'Wie is op eerste? Probeer die Leer en Voorstelling Kapabiliteit van Taal Modelle op Deterministiese Gesluit Domeine', 'am': 'መጀመሪያ ማን ነው? የቋንቋ ሞዴል ማስተማር እና ማስታወቂያ ስልጣናት በማስታወቂያ ዝጋ ባለው አዲስ ዶሞዎች ላይ', 'id': 'Siapa yang pertama?: Mencoba Kemampuan Belajar dan Representasi Model Bahasa pada Domain Tertutup Deterministik', 'hy': 'Ո՞վ է առաջին հատվածում: Լեզվային մոդելների սովորելու և ներկայացման հնարավորությունների փորձարկումը որոշող փակված վայրերում', 'az': 'İlk başında kim var? Deterministic Closed Domains Üstündə Dil Modellərinin Öyrənməsi və Təşkil Mümkünlükləri', 'bn': 'কে প্রথমে? ভাষা মোডেলের শিক্ষা ও প্রতিনিধিত্বের ক্ষমতা প্রমাণ করা হচ্ছে', 'bs': 'Ko je na prvom mjestu? Vjerojatnost mogućnosti učenja i predstavljanja jezičkih modela na određenim zatvorenim domenama', 'et': 'Kes on esimesel? Keelemudelite õppimis- ja esindamisvõime uurimine deterministlikel suletud domeenidel', 'cs': 'Kdo je na prvním? Snímání učebních a reprezentačních schopností jazykových modelů na deterministických uzavřených doménách', 'ca': "Qui està en primer lloc? Probar les capacitats d'aprenentatge i representació dels models de llenguatge en dominis cerrats determinants", 'fi': 'Kuka on ykkösellä? Kielimallien oppimis- ja edustamiskyvyn kartoittaminen deterministisillä suljetuilla toimialueilla', 'jv': 'Piye susahke tho ? Jejaring', 'he': 'מי בראשונה? Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains', 'ha': 'Wãne ne na farko?: KCharselect unicode block name', 'sk': 'Kdo je na prvem? Prodiranje učnih in reprezentativnih zmogljivosti jezikovnih modelov na determinističnih zaprtih domenah', 'bo': 'སྔ་འཛིན་གྱི་ནང་དུ་ག་རེ་ཡིན་ནམ། Deterministic Closed Domains'}
{'en': 'The capabilities of today’s  natural language processing systems  are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to  artificial distributions  and  incomplete knowledge . Artifacts arising from artificial distributions can overstate  language model  performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that  language models  of three different architectures can answer questions about  world states  using only verb-like encodings of activity. Our approach is extensible to new  language models  and additional question-answering tasks.', 'ar': 'عادةً ما يتم تقييم قدرات أنظمة معالجة اللغة الطبيعية الحالية باستخدام مجموعات بيانات كبيرة من الأسئلة والأجوبة المنسقة. في حين أن هذه معايير مهمة للتقدم ، إلا أنها تعاني أيضًا من الضعف بسبب التوزيعات الاصطناعية والمعرفة غير الكاملة. يمكن للقطع الأثرية الناشئة عن التوزيعات الاصطناعية أن تبالغ في أداء نموذج اللغة ، بينما تحد المعرفة غير الكاملة من التحليل الدقيق. في هذا العمل ، نقدم نهجًا تكميليًا لقياس الأداء يعتمد على تتبع نشاط اللغة المبسطة (SPLAT). SPLATs هي مجموعة من ترميزات اللغة للنشاط في بعض المجالات المغلقة (ندرس الآثار من ألعاب الشطرنج والبيسبول في هذا العمل). تستخدم مجموعات بيانات SPLAT توزيعات تنشأ بشكل طبيعي ، وتسمح بتوليد أزواج من الأسئلة والأجوبة على نطاق واسع ، وتوفر معرفة كاملة في مجالاتها المغلقة. نظهر أن النماذج اللغوية لثلاث معماريات مختلفة يمكنها الإجابة على أسئلة حول حالات العالم باستخدام ترميز النشاط الشبيه بالأفعال فقط. نهجنا قابل للتوسيع لنماذج اللغة الجديدة ومهام الإجابة على الأسئلة الإضافية.', 'fr': "Les capacités des systèmes de traitement du langage naturel actuels sont généralement évaluées à l'aide de grands ensembles de données de questions et réponses organisées. Bien qu'il s'agisse de repères critiques de progrès, ils souffrent également de faiblesses dues à des distributions artificielles et à des connaissances incomplètes. Les artefacts issus de distributions artificielles peuvent surestimer les performances des modèles de langage, tandis que des connaissances incomplètes limitent les analyses fines. Dans ce travail, nous introduisons une approche d'analyse comparative complémentaire basée sur les traces d'activité linguistique simplifiées (SPLAT). Les SPLT sont des corpus d'encodages de langage d'activité dans un domaine fermé (nous étudions les traces de parties d'échecs et de baseball dans cet ouvrage). Les ensembles de données SPLAT utilisent des distributions naturelles, permettent la génération de paires question-réponse à grande échelle et fournissent des connaissances complètes dans leurs domaines fermés. Nous montrons que les modèles de langage de trois architectures différentes peuvent répondre à des questions sur les états du monde en utilisant uniquement des encodages d'activité de type verbe. Notre approche est extensible à de nouveaux modèles linguistiques et à des tâches supplémentaires de réponse aux questions.", 'es': 'Las capacidades de los sistemas actuales de procesamiento del lenguaje natural se evalúan normalmente mediante grandes conjuntos de datos de preguntas y respuestas seleccionadas. Si bien estos son puntos de referencia críticos para el progreso, también sufren debilidad debido a las distribuciones artificiales y al conocimiento incompleto. Los artefactos que surgen de distribuciones artificiales pueden exagerar el rendimiento del modelo lingüístico, mientras que el conocimiento incompleto limita el análisis detallado. En este trabajo, introducimos un enfoque de evaluación comparativa complementario basado en SimpliFed Language Activity Traces (SPLAT). Los SPLAT son corpus de codificaciones lingüísticas de la actividad en algún dominio cerrado (en este trabajo estudiamos las huellas de los juegos de ajedrez y béisbol). Los conjuntos de datos SPLAT utilizan distribuciones naturales, permiten la generación de pares de preguntas y respuestas a escala y ofrecen un conocimiento completo en sus dominios cerrados. Mostramos que los modelos lingüísticos de tres arquitecturas diferentes pueden responder preguntas sobre los estados del mundo utilizando solo codificaciones de actividad verbosas. Nuestro enfoque es extensible a los nuevos modelos lingüísticos y a las tareas adicionales de respuesta a preguntas.', 'pt': 'As capacidades dos atuais sistemas de processamento de linguagem natural são normalmente avaliadas usando grandes conjuntos de dados de perguntas e respostas selecionadas. Embora sejam referências críticas de progresso, elas também sofrem de fraqueza devido a distribuições artificiais e conhecimento incompleto. Artefatos decorrentes de distribuições artificiais podem exagerar o desempenho do modelo de linguagem, enquanto o conhecimento incompleto limita a análise refinada. Neste trabalho, apresentamos uma abordagem complementar de benchmarking baseada em SimPlified Language Activity Traces (SPLAT). SPLATs são corpora de codificações linguísticas de atividade em algum domínio fechado (nós estudamos traços de jogos de xadrez e beisebol neste trabalho). Os conjuntos de dados SPLAT usam distribuições que surgem naturalmente, permitem a geração de pares pergunta-resposta em escala e proporcionam conhecimento completo em seus domínios fechados. Mostramos que modelos de linguagem de três arquiteturas diferentes podem responder perguntas sobre estados do mundo usando apenas codificações de atividade do tipo verbo. Nossa abordagem é extensível a novos modelos de linguagem e tarefas adicionais de resposta a perguntas.', 'ja': '今日の自然言語処理システムの能力は、通常、キュレーションされた質問と回答の大きなデータセットを使用して評価されます。 これらは進歩の重要なベンチマークですが、人工的な分布と不完全な知識に起因する弱点もあります。 人工的な分布から生じるアーティファクトは、言語モデルのパフォーマンスを過大評価する可能性があり、不完全な知識は細かい分析を制限します。 この研究では、SimPlified Language Activity Trace （ SPLAT ）に基づいた補完的なベンチマークアプローチを紹介します。 SPLATは、いくつかのクローズドドメインでのアクティビティの言語エンコーディングのコーパです（本作では、チェスや野球ゲームからのトレースを研究しています）。 SPLATデータセットは、自然に成長する分布を使用し、大規模な質問応答ペアの生成を可能にし、クローズドドメインで完全な知識を提供します。 3つの異なるアーキテクチャの言語モデルは、動詞のようなアクティビティエンコーディングのみを使用して、世界の状態に関する質問に答えることができることを示しています。 私たちのアプローチは、新しい言語モデルと追加の質問に答えるタスクに拡張可能です。', 'hi': 'आज की प्राकृतिक भाषा प्रसंस्करण प्रणालियों की क्षमताओं का मूल्यांकन आमतौर पर क्यूरेट किए गए प्रश्नों और उत्तरों के बड़े डेटासेट का उपयोग करके किया जाता है। जबकि ये प्रगति के महत्वपूर्ण बेंचमार्क हैं, वे कृत्रिम वितरण और अधूरे ज्ञान के कारण कमजोरी से भी पीड़ित हैं। कृत्रिम वितरण से उत्पन्न होने वाली कलाकृतियां भाषा मॉडल के प्रदर्शन को ओवरस्टेट कर सकती हैं, जबकि अपूर्ण ज्ञान ठीक-ठाक विश्लेषण को सीमित करता है। इस काम में, हम SimPlified Language Activity Traces (SPLAT) के आधार पर एक पूरक बेंचमार्किंग दृष्टिकोण पेश करते हैं। SPLATs कुछ बंद डोमेन में गतिविधि की भाषा एन्कोडिंग के निगम हैं (हम इस काम में शतरंज और बेसबॉल गेम से निशान का अध्ययन करते हैं)। SPLAT डेटासेट स्वाभाविक रूप से उत्पन्न होने वाले वितरण का उपयोग करते हैं, पैमाने पर प्रश्न-उत्तर जोड़े की पीढ़ी की अनुमति देते हैं, और अपने बंद डोमेन में पूर्ण ज्ञान प्रदान करते हैं। हम दिखाते हैं कि तीन अलग-अलग आर्किटेक्चर के भाषा मॉडल गतिविधि के केवल क्रिया-जैसे एन्कोडिंग का उपयोग करके दुनिया के राज्यों के बारे में सवालों के जवाब दे सकते हैं। हमारा दृष्टिकोण नई भाषा मॉडल और अतिरिक्त प्रश्न-उत्तर देने वाले कार्यों के लिए एक्सटेंसिबल है।', 'zh': '今自然语言治统之功,常用大选及对案数集评之。 虽然进步之要,由人为布列不完之知,亦有弱点。 由人工分布者伪影或增大言模之性,而不全者限细粒度析。 于此等事,引入一基于简言(SPLAT)补准测试方法。 SPLAT封域之言编码语料库(究国际象棋棒球之迹)。 SPLAT数集用自然之布,许大生问对,并于封域全知。 吾明三架构之言,可以类动词编码以应天下。 我们的方法可以扩到新的言语模样和他问答。', 'ru': 'Возможности современных систем обработки естественного языка обычно оцениваются с использованием больших наборов курируемых вопросов и ответов. Хотя эти показатели являются критически важными для прогресса, они также страдают от слабости, обусловленной искусственным распределением и неполнотой знаний. Артефакты, возникающие из искусственных распределений, могут завышать производительность языковой модели, в то время как неполные знания ограничивают мелкозернистый анализ. В этой работе мы внедряем дополнительный подход к бенчмаркингу на основе SimPlified Language Activity Traces (SPLAT). SPLAT - это корпуса языковых кодировок активности в каком-то закрытом домене (в этой работе мы изучаем следы от шахматных и бейсбольных игр). Наборы данных SPLAT используют естественно возникающие распределения, позволяют генерировать пары вопросов и ответов в масштабе и позволяют получать полные знания в своих закрытых доменах. Мы показываем, что языковые модели трех различных архитектур могут отвечать на вопросы о мировых состояниях, используя только глаголоподобные кодировки активности. Наш подход применим к новым языковым моделям и дополнительным задачам с ответом на вопросы.', 'ga': 'Go hiondúil déantar cumais chórais phróiseála teanga nádúrtha an lae inniu a mheas agus úsáid á baint as tacair shonraí mhóra de cheisteanna agus de fhreagraí coimeádta. Cé gur tagarmharcanna criticiúla dul chun cinn iad seo, tá laige orthu freisin de bharr dáiltí saorga agus eolas neamhiomlán. Is féidir le déantúsáin a eascraíonn as dáiltí saorga feidhmíocht na samhla teanga a áibhéil, agus cuireann eolas neamhiomlán teorainn le hanailís mhionsonraithe. San obair seo, tugaimid isteach cur chuige tagarmharcála comhlántach bunaithe ar Rianta Gníomhaíochta Teanga Simplithe (SPLAT). Is corpasaí iad SPLATanna d’ionchóduithe teanga ar ghníomhaíocht i bhfearann dúnta áirithe (déanaimid staidéar ar rianta ó chluichí fichille agus baseball sa saothar seo). Úsáideann tacair sonraí SPLAT dáiltí a éiríonn go nádúrtha, ligeann siad do phéirí ceisteanna-freagra ar scála a ghiniúint, agus tugann siad eolas iomlán ina bhfearainn dhúnta. Léirímid gur féidir le samhlacha teanga de thrí ailtireacht dhifriúla ceisteanna a fhreagairt faoi stáit an domhain ag baint úsáide as ionchóduithe gníomhaíochta atá cosúil le briathra amháin. Tá ár gcur chuige fairsing do mhúnlaí nua teanga agus do thascanna breise freagartha ceisteanna.', 'el': 'Οι δυνατότητες των σημερινών συστημάτων επεξεργασίας φυσικής γλώσσας αξιολογούνται συνήθως χρησιμοποιώντας μεγάλα σύνολα δεδομένων επιλεγμένων ερωτήσεων και απαντήσεων. Μολονότι πρόκειται για κρίσιμα σημεία αναφοράς προόδου, υποφέρουν επίσης από αδυναμία λόγω τεχνητών διανομών και ελλιπών γνώσεων. Τα τεχνουργήματα που προκύπτουν από τεχνητές διανομές μπορούν να υπερβάλλουν την απόδοση του γλωσσικού μοντέλου, ενώ η ελλιπής γνώση περιορίζει τη λεπτόκοκκη ανάλυση. Στην εργασία αυτή, εισάγουμε μια συμπληρωματική προσέγγιση συγκριτικής αξιολόγησης βασισμένη σε ίχνη γλωσσικής δραστηριότητας (SPLAT). Τα SPLAT είναι σώματα γλωσσικών κωδικοποιήσεων δραστηριότητας σε κάποιο κλειστό τομέα (μελετάμε ίχνη από σκάκι και παιχνίδια μπέιζμπολ σε αυτή την εργασία). Τα σύνολα δεδομένων χρησιμοποιούν φυσικά αναδυόμενες διανομές, επιτρέπουν τη δημιουργία ζευγαριών ερώτησης-απάντησης σε κλίμακα και παρέχουν πλήρη γνώση στους κλειστούς τομείς τους. Δείχνουμε ότι τα γλωσσικά μοντέλα τριών διαφορετικών αρχιτεκτονικών μπορούν να απαντήσουν σε ερωτήσεις σχετικά με τις παγκόσμιες καταστάσεις χρησιμοποιώντας μόνο ρήμα κωδικοποιήσεις δραστηριότητας. Η προσέγγισή μας επεκτείνεται σε νέα γλωσσικά μοντέλα και πρόσθετες εργασίες απάντησης σε ερωτήσεις.', 'hu': 'Napjaink természetes nyelvfeldolgozó rendszereinek képességeit jellemzően nagy adatkészletek segítségével értékelik. Bár ezek a fejlődés kritikus referenciaértékei, a mesterséges eloszlás és a hiányos ismeretek miatt is gyengeségben szenvednek. A mesterséges eloszlásokból származó tárgyak túlságosan becsülhetik a nyelvmodell teljesítményét, míg a hiányos ismeretek korlátozzák a finomszemcsés elemzést. Ebben a munkában egy kiegészítő benchmarking megközelítést vezetünk be a Simplified Language Activity Traces (SPLAT) alapján. Az SPLAT-ek egy zárt területen végzett tevékenység nyelvi kódolásának korpuszai (ebben a munkában sakk és baseball játékok nyomait tanulmányozzuk). Az SPLAT adatkészletek természetesen keletkező eloszlásokat használnak, lehetővé teszik a kérdés-válasz párok létrehozását nagyszabású léptékben, és teljes ismeretet biztosítanak zárt területeiken. Megmutatjuk, hogy három különböző architektúra nyelvi modelljei kizárólag igészerű aktivitási kódolásokkal válaszolhatnak a világállapotokkal kapcsolatos kérdésekre. Megközelítésünk kiterjeszthető az új nyelvi modellekre és további kérdésekre is.', 'ka': 'დღეს ნაირადი ენერგიის პროცესი სისტემის შესაძლებლობა ტიპოლურად გაუმუშავებულია, რომელიც გამოყენებული დიდი მონაცემების კითხვების და პასუხების გამოყენ მაგრამ ეს კრიტიკური პროგრესის კონქმიკური ბანქმარი, ისინი ასევე მსგავსიდან დაბრუნდება ხელსახური გაყოფილი და უკეთესი ცნობიდან. არტიფექტაქტები, რომლებიც არტიფექტიური გაყოფილებებიდან იქნება ენის მოდელის გამოსახულება, მაგრამ არსებული ცნობიერების განსახულებელი განსახულებელი ანალიზია. ამ სამუშაოში ჩვენ დავიყენებთ კომპლენტერიური ბენქმარიკაციის პროგრამა, რომელიც სიმპლეფიცირებული ენაქტივის ბენქმარიკაციის განსაზღვრებით (SPLAT). SPLAT არის რამდენიმე დახურებული დიომინში ენის კოდირების კოპორა (ჩვენ ამ სამუშაოში შაფსის და ბეიბოლური თამაშიდან შესწავლობთ). SPLAT მონაცემების კონფიგურაციები გამოყენებენ ნაირადი განსაზღვრებული განსაზღვრებები, შესაძლებელია კითხვა-პასუხის კონფიგურაციის განსაზღვრება მაგალითად და დასაწყებენ ჩვენ ჩვენ აჩვენებთ, რომ სამი განსხვავებული არქტიქტურების ენახური მოდელები შეუძლიათ მსოფლიო სტატიქტურების შესახებ მხოლოდ ვიყენებთ ვერბურ ჩვენი პროგორმაცია ახალი ენის მოდელისთვის და დამატებული კითხვების მისაღებისთვის უფრო დიდია.', 'it': "Le capacità dei sistemi di elaborazione del linguaggio naturale odierni sono tipicamente valutate utilizzando grandi set di dati di domande e risposte curate. Sebbene questi siano parametri critici di progresso, soffrono anche di debolezza dovuta a distribuzioni artificiali e conoscenze incomplete. Gli artefatti derivanti da distribuzioni artificiali possono sopravvalutare le prestazioni del modello linguistico, mentre la conoscenza incompleta limita l'analisi a grana fine. In questo lavoro, introduciamo un approccio di benchmarking complementare basato su Tracce di attività linguistiche semplificate (SPLAT). Gli SPLAT sono corpora di codificazioni linguistiche di attività in qualche dominio chiuso (studiamo tracce di scacchi e partite di baseball in questo lavoro). I dataset SPLAT utilizzano distribuzioni naturali, consentono la generazione di coppie domanda-risposta su larga scala e offrono una conoscenza completa nei loro domini chiusi. Mostriamo che i modelli linguistici di tre diverse architetture possono rispondere alle domande sugli stati del mondo utilizzando solo codificazioni verbali di attività. Il nostro approccio è estensibile a nuovi modelli linguistici e ulteriori compiti di risposta alle domande.", 'kk': 'Бүгін табиғи тілдерді өңдеу жүйелерінің мүмкіндіктері әдетте бұл көп деректер қорлары мен жауаптары қолданылады. Бұл жұмыс белгісінің критикалық бағдарламалары, сондай-ақ олар кәсіпшілік тарату және толық білім сияқты күліктерінен өтеді. Өлшемді тарату үшін келесі артефакттар тіл үлгісін көтеруге болады, білім толық шектері жақсы таратылған анализ шектерін шектеуге болады. Бұл жұмыста SimPlified Language Activity Tracks (SPLAT) негізінде біз қосымша белгілеу тәртібін келтіреміз. SPLAT - бір жабылған доменде тіл кодтамасының корпорасы (бұл жұмыстың шахт мен бейсбол ойындарының іздеулерін зерттейміз). SPLAT деректер қорлары табиғатты тарату үшін қолданылады, сұрақ- жауап қорларын масштабына құруға мүмкіндік береді, жабылған домендерінде толық білім береді. Біз үш әртүрлі архитектуралардың тіл үлгілері әлемдік күйлері туралы сұрақтарына жауап бере аламыз, тек белсендік кодтамасын қолдану үшін. Біздің тәсіліміз жаңа тіл үлгілеріне және қосымша сұрақ жауап беру тапсырмаларына кеңейтіледі.', 'mk': 'Капацитетите на денешните природни системи за обработување јазик се обично проценуваат со користење на големи податоци од курирани прашања и одговори. While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge.  Уметничките факти кои се појавуваат од вештачките дистрибуции можат да ја преценат резултатот на јазичкиот модел, додека нецелосното знаење ја ограничува фината анализа. Во оваа работа, воведуваме комплементарен пристап на benchmarking базиран на SimPlified Language Activity Traces (SPLAT). СПЛАТ се корпора на јазичките кодирања на активноста во некоја затворена област (ние студираме траги од шах и бејзбол игри во оваа работа). СПЛАТ датотеки користат природни дистрибуции, овозможуваат генерација на парови прашања-одговори на скала и си дозволуваат целосно знаење во нивните затворени домени. Ние покажуваме дека јазичките модели од три различни архитектури можат да одговараат на прашања за светските држави користејќи само кодирање на активност на вид на гласници. Нашиот пристап е проширен за новите јазички модели и дополнителни задачи за одговор на прашања.', 'ms': 'Kemampuan sistem pemprosesan bahasa semulajadi hari ini biasanya diukur menggunakan set data besar soalan dan jawapan yang dikurasi. Walaupun ini merupakan benchmarks kritik kemajuan, mereka juga menderita kelemahan disebabkan distribusi buatan dan pengetahuan tidak lengkap. Artifakta yang muncul dari distribusi buatan boleh melebihi prestasi model bahasa, walaupun pengetahuan tidak lengkap mengawal analisis yang sempurna. Dalam kerja ini, kami memperkenalkan pendekatan benchmarking tambahan berdasarkan Trek Aktiviti Bahasa SimPlified (SPLAT). SPLAT adalah korpra pengekodan bahasa aktiviti dalam beberapa domain tertutup (kami mempelajari jejak dari permainan catur dan baseball dalam kerja ini). Set data SPLAT menggunakan distribusi yang muncul secara alami, membenarkan generasi pasangan soalan-jawapan pada skala, dan membenarkan pengetahuan lengkap dalam domain tertutup mereka. Kami menunjukkan bahawa model bahasa tiga arkitektur yang berbeza boleh menjawab soalan mengenai negara dunia hanya menggunakan pengekodan aktiviti seperti verb. Pendekatan kita boleh diperluaskan kepada model bahasa baru dan tugas sambungan soalan tambahan.', 'ml': 'ഇന്നുള്ള സ്വാഭാവിക ഭാഷ പ്രക്രിയശ്ചിത്രങ്ങളുടെ കഴിവ് സാധാരണ ചോദ്യങ്ങളും ഉത്തരങ്ങളും ഉപയോഗിച്ച് വലിയ ഡാറ്റാസറ്റ്  ഇതൊക്കെ പുരോഗതിയുടെ കാര്യങ്ങളാണെങ്കില്\u200d കൃത്രിമ വിതരണങ്ങളും പൂര്\u200dണ്ണമായ അറിവുകളും കാരണം അവര്\u200d ദുര്\u200dബലരാണ്. കൃത്രിമ വിഭാഗങ്ങളില്\u200d നിന്നുള്ള ആര്\u200dട്ടിഫാക്റ്റുകള്\u200d ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d സിമിപ്പ്ലെഡ് ഭാഷ പ്രവര്\u200dത്തനങ്ങള്\u200d അടിസ്ഥാനമായി ഒരു കൂടുതല്\u200d ബെന്\u200dമെങ്കിങ്ങിങ് പ്രായോഗ്ര എസ്പിലാറ്റുകള്\u200d ചില ഡൊമെയിനിലെ പ്രവര്\u200dത്തനങ്ങളുടെ ഭാഷ കോര്\u200dപ്പോരാണ് (ചെസ്സില്\u200d നിന്നും ബെസ്ബോള്\u200d കളികളില്\u200d നിന്നും നമ്മ SPLAT ഡേറ്റാസറ്റുകള്\u200d സ്വാഭാവികമായ വിഭാഗങ്ങള്\u200d ഉപയോഗിക്കുന്നു, ചോദ്യത്തിന്റെ ഉത്തരമുള്ള ജോട്ടുകളുടെ തലമുറയില്\u200d അനു മൂന്നു വ്യത്യസ്ത്രീകങ്ങളുടെ ഭാഷ മോഡലുകള്\u200dക്ക് ലോക രാജ്യങ്ങളെപ്പറ്റിയുള്ള ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകാന്\u200d കഴിയ പുതിയ ഭാഷ മോഡലുകള്\u200dക്കും കൂടുതല്\u200d ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകുന്ന ജോലികള്\u200dക്കും നമ്മുടെ പ്രായോഗ്', 'mt': 'Il-kapaċitajiet tas-sistemi naturali tal-ipproċessar tal-lingwi tal-lum huma tipikament evalwati bl-użu ta’ settijiet ta’ dejta kbar ta’ mistoqsijiet u tweġibiet ikkurati. Filwaqt li dawn huma punti ta’ riferiment kritiċi tal-progress, huma jsofru wkoll minn dgħufija minħabba distribuzzjonijiet artifiċjali u għarfien mhux komplut. L-oġġetti li jirriżultaw minn distribuzzjonijiet artifiċjali jistgħu jiskattaw wisq il-prestazzjoni tal-mudell lingwistiku, filwaqt li l-għarfien mhux komplut jillimita l-analiżi bir-reqqa. F’dan ix-xogħol, a ħna nintroduċu approċċ kumplimentari ta’ benchmarking ibbażat fuq Traċċi ta’ Attività Lingwistika SimPlifikata (SPLAT). L-SPLATs huma korpra ta’ kodifikazzjonijiet lingwistiċi ta’ attività f’xi dominju magħluq (nistudjaw traċċi minn logħob ta’ xaqq u baseball f’dan ix-xogħol). Is-settijiet tad-dejta SPLAT jużaw distribuzzjonijiet li jirriżultaw b’mod naturali, jippermettu l-ġenerazzjoni ta’ pari ta’ mistoqsijiet-tweġibiet fuq skala, u jippermettu għarfien sħiħ fl-oqsma magħluqa tagħhom. Aħna nuru li mudelli lingwistiċi ta’ tliet arkitetturi differenti jistgħu jwieġbu mistoqsijiet dwar l-istati dinjija bl-użu ta’ kodiċijiet ta’ attività li jixbħu l-verbi biss. Our approach is extensible to new language models and additional question-answering tasks.', 'lt': "The capabilities of today's natural language processing systems are typically evaluated using large datasets of curated questions and answers.  Nors šie rodikliai yra esminiai pažangos rodikliai, jie taip pat patiria silpnumą dėl dirbtinio platinimo ir neišsamių žinių. Iš dirbtinio platinimo atsirandantys daiktai gali pernelyg įvertinti kalbos modelio veiksmingumą, o neišsamios žinios apriboja smulkių grūdų analizę. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT).  SPLAT yra tam tikroje uždaroje srityje veikiančių kalbų kodų korpora (šiame darbe tiriame šachmų ir beisbolo žaidimų pėdsakus). SPLAT duomenų rinkiniai naudoja natūraliai atsirandančius platinimus, leidžia kurti klausimų ir atsakymų poros mastu ir suteikia galimybę visapusiškai žinoti uždarose srityse. Mes rodome, kad trijų skirtingų architektūrų kalbiniai modeliai gali atsakyti į klausimus apie pasaulio valstybes tik naudojant į žodžius panašius veiklos kodus. Mūsų požiūris apima naujus kalbų modelius ir papildomas užduotis atsakyti į klausimus.", 'mn': 'Өнөөдөр байгалийн хэл үйлдвэрлэх системийн чадваруудыг ихэвчлэн асуулт болон хариултуудын том өгөгдлийн сангуудыг ашиглан үнэлдэг. Хэдийгээр эдгээр нь хөгжлийн чухал хэмжээсүүд боловч уран бүтээгдэхүүний хуваарилалт болон бүтэлгүйтгүй мэдлэгтэй учраас хүчтэй байдаг. Урлаг хуваариллагаас гарсан уран бүтээлүүд хэл загварын үйл ажиллагааг багасгаж чадна. Бүтэн мэдлэг нь сайн тарианы шинжилгээг хязгаарлаж чадна. Энэ ажил дээр бид SimPlified Language Activity Traces (SPLAT) дээр суурилсан нэмэлт банкварчлал аргыг танилцуулдаг. СПЛАТ гэдэг нь хэл хөгжлийн корпора юм. SPLAT өгөгдлийн сангууд байгалийн үүсгэн тархи ашиглаж, асуулт хариултын хоёрыг хэмжээнд зөвшөөрөх боломжтой болгож, хамгийн гадна бүрэн мэдлэг олгох боломжтой. Бид 3 өөр архитектурын хэл загварын загварууд дэлхийн улс орнуудын талаар зөвхөн хэлний шиг үйл ажиллагааны кодлог ашиглан хариулж чадна. Бидний ойлголт нь шинэ хэл загварууд болон асуулт хариултыг нэмэгдүүлэх даалгаварууд юм.', 'no': 'Innstillingane for naturspråksbehandlingssystemet i dag er vanlegvis evaluert med stor datasett med kurserte spørsmål og svar. Selv om desse er kritiske benchmarke for framgang, så har dei også kjøp frå svakhet på grunn av kunstiske distribusjonar og ukjente kunnskap. Artifaktar som oppstår frå kunstige distribusjonar kan overstyra språk-modellen, mens ikkje komplett kunnskap grenser fine-grained analyse. I denne arbeiden introduserer vi ein complementær benchmarking tilnærming basert på Simpliserte språktivitetsspor (SPLAT). SPLAT er korpora av språkkkoding av aktivitet i nokre lukka domene (me studerer spor frå sjakk og baseballspel i denne arbeidet). SPLAT Vi viser at språk-modeller av tre ulike arkitektur kan svara på spørsmål om verdenstilstandar med berre verb-liknande koding av aktivitet. Tilnærminga vårt er utvidbare til nye språk-modeller og fleire oppgåver som svarar på spørsmål.', 'pl': 'Możliwości dzisiejszych systemów przetwarzania języka naturalnego są zazwyczaj oceniane przy użyciu dużych zbiorów danych kuratorskich pytań i odpowiedzi. Chociaż są to krytyczne punkty odniesienia postępu, cierpią one również z powodu słabości ze względu na sztuczne rozkłady i niepełną wiedzę. Artykuły wynikające ze sztucznych rozkładów mogą przeceniać wydajność modelu językowego, podczas gdy niepełna wiedza ogranicza precyzyjną analizę. W niniejszej pracy wprowadzamy komplementarne podejście porównawcze oparte na SimPlified Language Activity Traces (SPLAT). SPLAT to korpusy językowych kodowań aktywności w jakiejś zamkniętej dziedzinie (badamy ślady z gry w szachy i baseball w niniejszej pracy). Zestawy danych SPLAT wykorzystują naturalnie powstające dystrybucje, umożliwiają generowanie par pytania-odpowiedzi na skalę i zapewniają pełną wiedzę w ich zamkniętych domenach. Pokazujemy, że modele językowe trzech różnych architektur mogą odpowiadać na pytania dotyczące stanów świata używając tylko czasowopodobnych kodowań aktywności. Nasze podejście można rozszerzyć o nowe modele językowe i dodatkowe zadania odpowiadające na pytania.', 'ro': 'Capacitățile sistemelor de procesare a limbajului natural de astăzi sunt de obicei evaluate folosind seturi mari de date de întrebări și răspunsuri curatoriate. Deși acestea reprezintă criterii critice ale progresului, ele suferă, de asemenea, de slăbiciune din cauza distribuțiilor artificiale și a cunoștințelor incomplete. Articolele rezultate din distribuții artificiale pot supraestima performanța modelului lingvistic, în timp ce cunoștințele incomplete limitează analiza fină. În această lucrare, introducem o abordare complementară de benchmarking bazată pe simplificate Language Activity Traces (SPLAT). SPLAT-urile sunt corpuri de codări lingvistice de activitate într-un domeniu închis (studiem urme de șah și jocuri de baseball în această lucrare). Seturile de date SPLAT utilizează distribuții naturale, permit generarea perechilor de întrebări-răspuns la scară și oferă cunoștințe complete în domeniile lor închise. Aratăm că modelele lingvistice ale trei arhitecturi diferite pot răspunde la întrebări despre stările lumii folosind numai codări de activitate ca verbe. Abordarea noastră este extinsă la noi modele lingvistice și sarcini suplimentare de răspuns la întrebări.', 'si': 'අදින් ස්වාභික භාෂාව ප්\u200dරක්\u200dරියාසය පද්ධතියේ සාමාන්\u200dයයෙන් ලොකු දත්ත සේට් සහ උත්තර ප්\u200dරශ්නය සඳහා වි මේවා විශේෂ බෙන්ච්මාර්ක් වෙනුවෙන් ඉන්නවා නමුත් එයාලා වඩා දුර්වලයෙන් දුර්වල් වෙනුවෙන් ඉන්නවා. කළුණු විතරයෙන් පිළිබඳින්න පුළුවන් භාෂා මොඩල් ප්\u200dරභාවිත විදිහට වැඩ කරන්න, සම්පූර්ණ දන්නවක් න මේ වැඩේ අපි සිම්ප්ලිෆීඩ් භාෂාව ක්\u200dරියාක්\u200dරියාත්මක පරීක්ෂණය (SPLAT) විසින් සම්පූර්ණ බෙන්ච්මාර් SPLATs තමයි භාෂාව සංකේතනයේ ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක (අප SPLAT දත්ත සටහන් ස්වභාවිතයෙන් ප්\u200dරශ්න- ප්\u200dරතිච්චාරයක් පාවිච්චි කරන්න, ප්\u200dරශ්න- ප්\u200dරතිචාරයක් ප්\u200dරමාණයෙන්  අපි පෙන්වන්නේ වෙනස් විදිහට ස්ථාපනය තුනක් වගේ භාෂා මොඩේල් ප්\u200dරශ්න පුළුවන් ලෝක ස්ථානය ගැන ප්\u200d අපේ විදිහට අලුත් භාෂා මොඩේල් වලින් ප්\u200dරශ්න ප්\u200dරතික්\u200dරියාවක් වලින් ප්\u200dරශ්න වැඩ කරන්න පුළ', 'sr': 'Sposobnosti današnjih prirodnih jezičkih obrađivanja obično se procjenjuju koristeći velike podatke izloženih pitanja i odgovora. Iako su to kritični kritični kritični kritični znakovi napretka, oni takođe pate od slabosti zbog umjetnih raspodjela i nepotpunih znanja. Artifakti koji se pojavljuju iz umjetničkih distribucija mogu nadmašiti provedbu jezičkog modela, dok nepotpuno znanje ograničava ispravnu analizu. U ovom poslu predstavljamo dodatni pristup kriteriji na temelju Simpliziranih tragova aktivnosti jezika (SPLAT). SPLAT su korporacija jezičkih kodiranja aktivnosti u nekom zatvorenom domenu (proučavamo tragove šaha i bejzbol igre u ovom poslu). SPLAT podaci koriste prirodno rastuće distribucije, omogućavaju generaciju par odgovora na pitanje u skali i priuštiti potpuno znanje u zatvorenim domenama. Pokazujemo da jezički modeli tri različite arhitekture mogu odgovoriti na pitanja o svetskim državama koristeći samo kodiranje aktivnosti poput verba. Naš pristup je širok za nove jezičke modele i dodatne odgovore na pitanje.', 'sv': 'Möjligheterna hos dagens naturliga språkbehandlingssystem utvärderas vanligtvis med hjälp av stora datamängder med kuraterade frågor och svar. Även om dessa är kritiska riktmärken för framsteg lider de också av svaghet på grund av artificiell fördelning och ofullständig kunskap. Artefakter som uppstår från artificiella distributioner kan överskatta språkmodellens prestanda, medan ofullständig kunskap begränsar finkornig analys. I detta arbete introducerar vi en kompletterande benchmarking-metod baserad på Simplified Language Activity Traces (SPLAT). SPLAT är korpora av språkkodningar av aktivitet inom någon sluten domän (vi studerar spår från schack och baseball spel i detta arbete). SPLAT-datauppsättningar använder naturliga distributioner, möjliggör generering av frågor-svar par i stor skala och ger fullständig kunskap inom sina slutna domäner. Vi visar att språkmodeller av tre olika arkitekturer kan besvara frågor om världstillstånd med endast verbliknande aktivitetskodningar. Vårt tillvägagångssätt kan utvidgas till nya språkmodeller och ytterligare frågeställningar.', 'so': "Aqoonsiga nidaamka baaritaanka luqada asalka ah ee maanta waxaa sida caadiga ah loo qiimeynayaa isticmaalka sawirro badan oo su'aalo ah iyo jawaabo la koobay. Intii ay kuwanu yihiin qaybaha horumarinta ee muhiim ah, waxay sidoo kale ka xanuunsadaan itaaldarrada, qaybinta farsamada iyo aqoonta aan dhamayn darteed. Qoraalka farshaxanka ka soo baxa qaybsiga farshaxanka ayaa ka hor marin kara sameynta muuqashada luuqada, iyadoo aan dhamaan aqoonta la'aantiisu ay xadgudbaan baaritaanka saxda. Markaas waxan, waxaynu soo bandhignaynaa qaab kamid ah oo ku saleysan habka dhaqdhaqaaqa ee luqada SimPlified (SPLAT). SPLATs waa shirkad kaarar ah oo ku qoran waxqabad luqadeed oo ku yaala meelo qarsoon (waxan ka baranaynaa wadooyin ka yimaada ciyaaraha chess iyo ciyaaraha baseball). SPLAT waxey isticmaalaan qaybaha asalka ah oo si dabiicadda ah u isticmaalaya, ku raadsan yihiin abuurista labada mas’uul oo ku saabsan, wuxuuna heli karaa aqoon kamid ah oo ku qoran meelahooda qarsoon. Waxaynu tusnaynaa in noocyada afka ee saddex meelood oo kala duduwan ay ka jawaabi karaan su'aalo ku saabsan dowlada dunida oo ay isticmaalaan kooxaha waxqabadka oo la mid ah oo kaliya. Dhaqdhaqaalahayagu waa mid aad u badan yihiin modelalka luuqada cusub iyo shaqaalaha su'aalaha ka jawaabaya oo kale.", 'ta': 'இன்றைய நாளின் இயற்கையான மொழி செயல்பாட்டு அமைப்புகளின் இயல்பான திறன் பெரிய தகவல் அமைப்புகளை பயன்படுத்தி மதிப்பிடப்பட இந்த முன்னேற்றத்தின் முக்கியமான குறிப்புகள் இருக்கும் போது, அவர்கள் தோல்வியுற்றத்தின் காரணத்தால் மற்றும் மு கலைப்பாட்டிலிருந்து வரையறுக்கப்படும் கலைப்பாட்டாளர் இந்த வேலையில், நாம் சுலபமான மொழி செயல்பாடு தட்டுகளை அடிப்படையில் ஒரு சுருக்கமான benchmarking approach introduced (SPLAT). SPLATs சில மூடிய களத்தில் செயல்பாடுகளின் மொழி குறியீடுகள் (நாம் இந்த வேலையில் செஸ்ஸ் மற்றும் பேஸ்பால் விளையாட்டுகள SPLAT தகவல் அமைப்பு மூன்று வேறு வித்தியாசமான அடைவுகளின் மொழி மாதிரிகளை காட்டுகிறோம் உலக நாடுகள் பற்றிய கேள்விகளுக்கு பதில் அளிக் புதிய மொழி மாதிரிகள் மற்றும் கூடுதல் கேள்வி பதில் செய்யும் பணிகளுக்கு எங்கள் வழி விரைவாக உள்ளது.', 'ur': 'آج کے طبیعی زبان پرسس سیسٹم کے قابلیت معمولاً بڑے ڈیٹسٹ کے مطابق مطابق سوال اور جواب کے استعمال کرتے ہیں. اگرچہ یہ بڑی اضطراری باتیں ہیں، ان کو بھی کمزوری کی وجہ سے پہنچ رہی ہے، کیونکہ وہ مصنوعی تقسیم اور بے پوری علم کی وجہ سے۔ مصنوعی تقسیم کے باعث آلودہ معلومات زبان مدل کی عملکرد سے زیادہ زیادہ زیادہ کر سکتے ہیں، حالانکہ غیرپورے علم کے اندازے اچھی دانے کی تحلیل سے محدود ہیں. ہم اس کام میں سیم پلیفڈ زبان فعالیت تریس (SPLAT) پر بنیاد رکھتے ہیں، ایک اضافہ بنچم مارکینگ طریقہ پیش کرتے ہیں۔ SPLATs کچھ بند ڈومین میں فعالیت کی زبان کا اکنوڈینگ کا کوپورا ہے (ہم اس کام میں شکس اور بیسبال کھیل سے پڑھتے ہیں)۔ SPLAT ڈاٹ سٹیوں کو طبیعی طور پر اٹھانے والی تقسیم کے مطابق استعمال کرتا ہے، سوال جوڑوں کی نسل کو ترازو سے اجازت دیتا ہے، اور ان کے بند ڈومین میں پورا علم خرچ کرتا ہے۔ ہم دکھاتے ہیں کہ تین مختلف معماروں کی زبان مدل دنیا کی حالت کے بارے میں سوال پوچھ سکتے ہیں صرف فعالیت کے مطابق ویرڈ جیسے اکنوڈینگ کے مطابق۔ ہمارا تقریبا نئی زبان مدل اور اضافہ سوال جواب دینے کے کاموں کے لئے پھیلانے والا ہے.', 'vi': 'Khả năng của hệ thống xử lý ngôn ngữ tự nhiên hiện nay được đánh giá bằng các tập tin đầy đủ các câu hỏi và câu trả lời. Mặc dù đây là những tiêu chuẩn quan trọng của tiến bộ, nhưng chúng cũng bị yếu do phân phát nhân tạo và kiến thức chưa hoàn thiện. Thành phần từ phân phát nhân tạo có thể tăng cường khả năng mô phỏng ngôn ngữ, trong khi kiến thức chưa hoàn chỉnh giới hạn phân tích. Trong công việc này, chúng ta sẽ áp dụng một phương pháp định nghĩa khác dựa trên Dấu Hiện Hành trình Tư Mã Lai Mô phỏng. Đội vệ binh là hạ sĩ của các loại ngôn ngữ có hoạt động trong vài khu vực kín (chúng tôi nghiên cứu dấu vết từ cờ vua và bóng chày trong công việc này). Một bộ hiện giải thoát dọn tự nhiên, cho phép có câu hỏi bằng cách đó, và cho phép có trị hoàn toàn bộ trong khu vực của họ. Chúng tôi cho thấy các mô hình ngôn ngữ của ba kiến trúc khác nhau có thể trả lời câu hỏi về các bang thế giới chỉ sử dụng các mã động từ như các hoạt động. Cách tiếp cận của chúng ta có thể mở rộng ngôn ngữ mới và các nhiệm vụ trả lời câu hỏi.', 'uz': "Bugun tilning tabiiy tizimi boshqarish tizimlarining qobiliyatlari odatda katta maʼlumotlar va javoblar bilan ishlatiladi. While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge.  Faqat tarqatish soʻzlaridan tasdiqlangan Artifaktlar tilning model natijasini oshirish mumkin, ammo muvaffaqiyatli taʼminot toʻplamligini ajratish mumkin. Bu ishda, biz Simpled Tilning Activity Trayerlari (SPLAT) asosida yaratilgan murakkablik benchmarking usulini ko'rsamiz. Name Name Biz bu tilning uchta boshqa arxituvlar modellari dunyo davlatlari haqida savollariga javob berishi mumkin. Biz faqat qo'llangan tashkilotlardan foydalanish mumkin. Bizning usuli yangi tillar modellari va qoʻshimcha savol javoblar ishlariga yetarlicha.", 'bg': 'Възможностите на съвременните системи за обработка на естествени езици обикновено се оценяват с помощта на големи набори от данни от подбрани въпроси и отговори. Въпреки че това са критични показатели за напредъка, те също страдат от слабост поради изкуствено разпределение и непълни знания. Артефактите, произтичащи от изкуствени разпределения, могат да надценят производителността на езиковия модел, докато непълните знания ограничават финия анализ. В тази работа въвеждаме допълнителен подход за сравнително оценяване, базиран на СимПЛИфицирани Езикови Дейности (SPLAT). SPLAT са корпоративни езикови кодировки на дейност в някои затворени области (в тази работа изучаваме следи от шах и бейзболни игри). Наборите от данни използват естествено възникващи дистрибуции, позволяват генерирането на двойки въпроси-отговори в мащаб и предоставят пълни знания в техните затворени области. Показваме, че езиковите модели на три различни архитектури могат да отговорят на въпроси за световните състояния, използвайки само глаголоподобни кодировки на активността. Нашият подход е разширим към нови езикови модели и допълнителни задачи за отговаряне на въпроси.', 'da': 'Mulighederne i nutidens natursprogbehandlingssystemer evalueres typisk ved hjælp af store datasæt af kuraterede spørgsmål og svar. Selv om disse er kritiske benchmarks for fremskridt, lider de også af svagheder på grund af kunstige fordelinger og ufuldstændig viden. Artefakter, der opstår fra kunstige distributioner, kan overvurdere sprogmodellens ydeevne, mens ufuldstændig viden begrænser finkornet analyse. I dette arbejde introducerer vi en komplementær benchmarking tilgang baseret på Simplified Language Activity Traces (SPLAT). SPLATs er korpora af sprogkodninger af aktivitet i et lukket domæne (vi studerer spor fra skak og baseball spil i dette værk). SPLAT datasæt bruger naturligt opståede distributioner, tillader generering af spørgsmål-svar par i skala og giver fuld viden på deres lukkede domæner. Vi viser, at sprogmodeller af tre forskellige arkitekturer kan besvare spørgsmål om verdenstilstande ved hjælp af verbagtige aktivitetskodninger. Vores tilgang kan udvides til nye sprogmodeller og yderligere spørgsmålsbesvarelsesopgaver.', 'nl': "De mogelijkheden van de huidige systemen voor natuurlijke taalverwerking worden meestal geëvalueerd met behulp van grote datasets van samengestelde vragen en antwoorden. Hoewel dit cruciale maatstaven zijn voor vooruitgang, lijden zij ook onder zwakte als gevolg van kunstmatige verdelingen en onvolledige kennis. Artifacten die voortkomen uit kunstmatige distributies kunnen de prestaties van taalmodellen overschatten, terwijl onvolledige kennis fijnkorrelige analyse beperkt. In dit werk introduceren we een complementaire benchmarking aanpak gebaseerd op SimPlified Language Activity Traces (SPLAT). SPLAT's zijn corpora van taalcoderingen van activiteit in een gesloten domein (we bestuderen sporen van schaak en honkbal spelen in dit werk). SPLAT datasets maken gebruik van natuurlijke distributies, maken het genereren van vraag-antwoord paren op schaal mogelijk en bieden volledige kennis in hun gesloten domeinen. We laten zien dat taalmodellen van drie verschillende architecturen vragen over wereldstaten kunnen beantwoorden met behulp van werkwoorden-achtige coderingen van activiteit. Onze aanpak is uitbreidbaar naar nieuwe taalmodellen en aanvullende vragen beantwoorden taken.", 'hr': 'Sposobnosti današnjih prirodnih sustava obradivanja jezika obično se procjenjuju koristeći velike podatke izliječenih pitanja i odgovora. Iako su to kritične kritične kritike napretka, oni također pate od slabosti zbog umjetnih raspodjela i nepotpunih znanja. Artifakti iz umjetničkih distribucija mogu nadmašiti učinkovitost jezičkog modela, dok nepotpuno znanje ograničava ispravnu analizu. U ovom poslu predstavljamo dodatni kritični pristup na temelju SimPlificiranog praćenja aktivnosti jezika (SPLAT). SPLAT su korporacija jezičkih kodiranja aktivnosti u nekom zatvorenom domenu (proučavamo tragove šaha i bejzbol igre u ovom poslu). SPLAT podaci koriste prirodno rastuće distribucije, omogućavaju generaciju par odgovora na pitanje u skali i priuštiti potpune znanje u zatvorenim domenama. Pokazujemo da jezički modeli tri različite arhitekture mogu odgovoriti na pitanja o svijetskim državama koristeći samo kodiranje aktivnosti poput verba. Naš pristup je širok za nove jezičke modele i dodatne odgovorne zadatke na pitanje.', 'de': 'Die Fähigkeiten heutiger Systeme zur Verarbeitung natürlicher Sprache werden typischerweise anhand großer Datensätze kuratierter Fragen und Antworten bewertet. Diese sind zwar kritische Maßstäbe für den Fortschritt, leiden aber auch unter Schwäche durch künstliche Verteilungen und unvollständiges Wissen. Artefakte, die durch künstliche Verteilungen entstehen, können die Leistung von Sprachmodellen überbewerten, während unvollständiges Wissen die feinkörnige Analyse begrenzt. In dieser Arbeit stellen wir einen ergänzenden Benchmarking-Ansatz vor, der auf SimPlified Language Activity Traces (SPLAT) basiert. SPLAts sind Korpora von Sprachcodierungen von Aktivitäten in einem geschlossenen Bereich (wir untersuchen Spuren aus Schach und Baseballspielen in dieser Arbeit). SPLAT-Datensätze verwenden natürlich auftretende Verteilungen, ermöglichen die Generierung von Frage-Antwort-Paaren im großen Maßstab und ermöglichen vollständiges Wissen in ihren geschlossenen Domänen. Wir zeigen, dass Sprachmodelle von drei verschiedenen Architekturen Fragen über Weltzustände beantworten können, indem sie nur Verb-ähnliche Codierungen von Aktivität verwenden. Unser Ansatz ist auf neue Sprachmodelle und zusätzliche Fragestellungen erweiterbar.', 'id': 'Kemampuan dari sistem proses bahasa alami hari ini biasanya diuji menggunakan set data besar pertanyaan dan jawaban. Sementara ini adalah benchmark kritis kemajuan, mereka juga menderita kelemahan karena distribusi buatan dan pengetahuan tidak lengkap. Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis.  Dalam pekerjaan ini, kami memperkenalkan pendekatan benchmarking komplementari berdasarkan SimPlified Language Activity Traces (SPLAT). SPLAT adalah korpra dari kode bahasa aktivitas di beberapa domain tertutup (kami mempelajari jejak dari catur dan permainan bisbol dalam pekerjaan ini). Set data SPLAT menggunakan distribusi yang muncul secara alami, memungkinkan generasi pasangan pertanyaan-jawaban pada skala, dan membeli pengetahuan lengkap dalam domain tertutup mereka. Kami menunjukkan bahwa model bahasa dari tiga arsitektur yang berbeda dapat menjawab pertanyaan tentang negara-negara dunia hanya menggunakan kode aktivitas seperti verb. pendekatan kita dapat diperluaskan untuk model bahasa baru dan tugas tambahan menjawab pertanyaan.', 'ko': '오늘날 자연 언어 처리 시스템의 능력은 통상적으로 대량의 정성스럽게 기획된 문제와 답안 데이터 집합을 사용하여 평가한다.진보의 관건적인 기준이지만 인위적인 분포와 불완전한 지식 때문에 약점도 있다.인공 분포로 인해 발생하는 부품은 언어 모델의 성능을 과장할 수 있고 불완전한 지식은 세립도 분석을 제한할 수 있다.이 작업에서 우리는 간소화된 언어 활동 추적(SPLAT)을 바탕으로 하는 보충 기준 테스트 방법을 소개했다.splat는 폐쇄적인 분야에서 활동하는 언어 인코딩 자료 라이브러리이다.SPLAT 데이터 세트는 자연 발생의 분포를 사용하여 문제 - 정답 쌍을 대규모로 생성하고 폐쇄된 도메인의 전체 지식을 제공합니다.우리는 세 가지 서로 다른 체계 구조의 언어 모델이 동사식의 활동 코드만 사용하여 세계 상태와 관련된 문제를 대답할 수 있다는 것을 증명했다.우리의 방법은 새로운 언어 모델과 추가 문답 임무로 확대될 수 있다.', 'tr': 'Bu gün tebigy dil işlemek sistemleriniň üýtgeşmeleri bilen çykyş soraglaryň we jogabalaryň uly sanlary ullanýar. Bu ýerler ilerleme döwletlerinden wajyp görkezilýän çykyşlar bolsa hem döwüräk paýlamak we bolmadyk bilim sebäbi zayıflatlykdan çykýarlar. Yap taýýarlardan gelen sanat eserleri dil nusgasyny üstüne getirip biler, bilim ýok taýýarlanmagynyň çykmasyny mümkin edýär. Bu işde SimPlified Dil Etkinliği Traces (SPLAT) tabanlı bir tabanlı etimleme metodlarını tanıtıyoruz. SPLAT ködlemeleri ýapylan domandaki dil ködlemeleriniň korporadyr (biz bu işde küşt we beýsbol oýnunyň izi öwrenip otyrys). SPLAT veri düzümleri dogrudan gaýşartýan döwletleri ulanýar, sorag-jogabat çiftlerini ölçekde döwletlere rugsat bermek we ýapyk alanlarynda tam bilgi bermek üçin rugsat berir. Biz üç dürli arhitekturyň dili nusgalarynyň dünýä döwletleri barada diňe bir verb ýaly ködlemeler üçin jogap berip biler. Biziň ýaryşymyz täze dil nusgalaryna we soraglaryň jogaplaryna golaýdyr.', 'sw': 'Uwezekano wa mfumo wa utaratibu wa lugha za asili wa leo unapitiwa kwa kutumia seti kubwa ya data za maswali na jibu. Wakati hizi ni kanuni muhimu za maendeleo, pia wanakabiliwa na udhaifu kutokana na usambazaji wa ubunifu na ufahamu usio kamili. Wasanii wanaotokana na usambazaji wa ubunifu wanaweza kuongeza utendaji wa mifano ya lugha, wakati maarifa yasiyo kamili yanazuia uchambuzi mzuri. Katika kazi hii, tunaonyesha mbinu za kuchuja bendera kwa msingi wa utaratibu wa lugha SimPlified (SPLAT). SPLATs ni makampuni ya mfumo wa shughuli za lugha katika baadhi ya maeneo yaliyofungwa (tunasoma picha za mchezo wa chess na baseball katika kazi hii). seti za taarifa za SPLAT hutumia usambazaji wa asili, ruhusu kizazi cha wawili wa majibu kwa kiwango kikubwa, na kupata maarifa kamili katika maeneo yao yaliyofungwa. Tunaonyesha kuwa mifano ya lugha ya majengo mitatu tofauti yanaweza kujibu maswali kuhusu majimbo ya dunia kwa kutumia ujumbe wa shughuli kama vile tu. Hatua yetu ni muhimu kwa mifano mpya ya lugha na kazi nyingine za kujibu maswali.', 'fa': 'توانایی سیستم\u200cهای پرداخت زبان طبیعی امروز معمولا با استفاده از مجموعه\u200cهای داده\u200cهای بزرگ از سوالات و جواب\u200cهای پرداخته\u200cشده ارزیابی می\u200cشوند. در حالی که اینها سنجیره های مهم پیشرفت هستند، آنها همچنین از ضعیفی به سبب توزیع مصنوعی و دانش کامل رنج می\u200cبرند. مصنوعی که از توزیع\u200cهای مصنوعی می\u200cآید می\u200cتواند عملکرد مدل زبان را زیادی کند، در حالی که دانش کامل تحلیل\u200cهای دانه\u200cای را محدود می\u200cکند. در این کار، ما یک روش تخمین بیشتری را معرفی می\u200cکنیم که بر اساس ردیابی فعالیت زبانی SimPlified (SPLAT). SPLAT\u200cها در برخی از دامنه\u200cهای بسته\u200cشده (ما ردیابی از بازی\u200cهای شطرنج و بیسبال در این کار مطالعه می\u200cکنیم). مجموعه\u200cهای داده\u200cهای SPLAT از توزیع\u200cهای طبیعی بالا می\u200cبرند، اجازه می\u200cدهند نسل جفت\u200cهای سوال و جواب را در مقیاس و اجازه می\u200cدهند دانش کامل در دامنهای بسته\u200cشان. ما نشان می دهیم که مدل زبانی از سه معماری متفاوت می تواند سوالات درباره ایالات دنیا را با استفاده از تنها رمز\u200cبندی\u200cهای فعالیت مانند ویژه جواب دهد. دسترسی ما برای مدل های جدید زبان و مسئله های جواب سوال اضافه است.', 'am': 'የዛሬ የፍጥረቱ ቋንቋ ፕሮጀክት ስርዓቶች በተለየ ትልቁ የዳታ ጥያቄዎችን እና መልስ በመጠቀም ይታያል፡፡ እነዚህም የውጤት ግንኙነት አካባቢዎች ሲሆኑ፥ አካባቢ እውቀትና ፍጹም ስህተት ምክንያት ከድካም ይቀማሉ። አርፋፊዎች ከቋንቋው ምሳሌ አድራጊዎችን ማሳየት ይችላል፡፡ በዚህ ስራ፣ በተጨማሪው ቋንቋ ተግባር (SPLAT) የተመሳሳይ የድምፅ ድርጊት (SPLAT) የተጠቃሚ የbenchmarking ሥርዓት እናሳውቃለን፡፡ SPLAT የቋንቋ አካባቢዎች በክፍለ አካባቢ አካባቢዎች ናቸው (በዚህ ሥራ የደረጃ መስኮቶች እና የbaseball ጨዋታዎችን እናስተምራለን፡፡ የSPLAT ዳታ ማህበረሰብ በአዳማዊ አካባቢ አካባቢ እፍላጎችን ይጠቅማል፣ የጥያቄ መልስ ሁለቶችን በመጠቀም ይፈቅዳሉ፣ እናም በተዘጋጀባቸው ሰፈር ውስጥ ሙሉ እውቀትን አግኝቷል፡፡ የሦስት መልዕክቶች የቋንቋዎች ምሳሌዎች በዓለም ሀገራት ላይ ጥያቄን ብቻ በዝርዝር የሚመስል የሥርዓት አካባቢ ቀለሞች የሚመልስ እንደሆነ እናሳየዋለን፡፡ አዲስ ቋንቋ ምሳሌዎች እና ለጥያቄ መልስ ስራዎችን ለመስጠት ይችላል፡፡', 'sq': 'Përaftësitë e sistemeve natyrore të përdorimit të gjuhës sot vlerësohen tipikisht duke përdorur të dhëna të mëdha të pyetjeve dhe përgjigjeve të kuruara. Ndërsa këto janë pika kritike të përparimit, ata vuajnë gjithashtu nga dobësia për shkak të shpërndarjeve artificiale dhe njohurive të pakompletuara. Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis.  Në këtë punë, ne futim një metodë komplementare referimi bazuar në SimPlied Language Activity Traces (SPLAT). SPLATs janë korpra e kodifikimit të gjuhës të aktivitetit në një domeni të mbyllur (ne studiojmë gjurmë nga lojrat e shahut dhe bejsbollit në këtë punë). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains.  Ne tregojmë se modelet gjuhësore të tre arkitekturave të ndryshme mund të përgjigjen pyetjeve rreth shteteve botërore duke përdorur vetëm kodifikime të aktivitetit të ngjashme me verbe. Përqasja jonë është e shtrirë ndaj modeleve të reja gjuhësh dhe detyrave shtesë që përgjigjen pyetjeve.', 'az': 'Bugünün təbiətli dil işləmə sistemlərinin qabiliyyəti genellikle böyük verilən soruşmalar və cevaplar vasitəsilə müəyyən edilir. Bunlar tədbirlik dəyişiklikləridir, həmçinin məhsul dağıtılması və tamamlanmış bilgi üzündən zəiflik üzündən çəkilirlər. Yaxşı dağıtımlardan gələn məhsullar dil modellərinin performansını üstün edə bilər, çünki tamamlanmış bilgi sünbül analizi limitləyir. Bu işdə, SimPlified Dil Etkinlik İzləri (SPLAT) üzərində dayanan complementary benchmarking approach təşkil edirik. SPLAT bəzi qapılmış domandakı dil kodlaması korporasıdır (biz bu işdə satranç və beysbol oyunlarından izləri öyrənirik). SPLAT veri qurğuları təbiətlə yüksək dağıtımları istifadə edir, sual-cavab çiftlərinin nəslinə ölçüdə müəyyən edir və qapılmış alanlarda tamam bilgi verirlər. Biz üç müxtəlif arhitekturların dil modellərinin dünya eyaletleri barəsində yalnız verb kimi kodlamaları ilə cavab verə bilər. Bizim tərzimiz yeni dil modellərinə və daha çox sual cavab verən işlərə genişlənir.', 'af': "Die moontlikhede van vandag se natuurlike taal verwerking stelsels word tipies uitgewerk deur te gebruik groot datastelle van gekuierde vrae en antwoorde. Alhoewel hierdie kritiese benchmarke van vordering is, lyk hulle ook van swakheid vanweë kunstige verspreidings en onvolledige kennis. Artifakte wat uit kunstenaarle verspreidings opkom, kan taal-model-prestasie oorskryf, terwyl onvolledige kennis beperk fyn-graad analisie. In hierdie werk introduseer ons 'n komplementêre benchmarking toegang gebaseer op Simpliseerde Taal Aktiviteitsspore (SPLAT). Spelts is korpora van taal kodering van aktiviteit in sommige gesluit domein (ons studeer spore van skaak en baseball speletjies in hierdie werk). SPLAT datastelle gebruik natuurlik-opstaande verspreidings, laat die generasie van vraag-antwoord paar op skaal toe, en toelaat volledige kennis in hulle gesluit domeine. Ons wys dat taal modele van drie verskillende arkitektuure kan antwoord vrae oor wêreld staatste met slegs verb-lyke kodering van aktiviteit. Ons toegang is uitbreidig vir nuwe taal modele en addisionele vraag-antwoordende taak.", 'hy': 'Այսօրվա բնական լեզվի վերամշակման համակարգերի հնարավորությունները սովորաբար գնահատվում են օգտագործելով մեծ տվյալների համակարգեր կորացված հարցեր և պատասխաններ: Մինչդեռ դրանք առաջընթացի կարևոր համեմատական նշաններ են, նրանք նաև թույլ են տառապում արհեստական տարածումների և անկատարյալ գիտելիքների պատճառով: Արվեստական տարածումներից առաջացած արվեստի փաստերը կարող են գերագնահատել լեզվի մոդելի արդյունքը, մինչդեռ անկատարյալ գիտելիքները սահմանափակում են նրբագեղ վերլուծությունը: Այս աշխատանքի ընթացքում մենք ներկայացնում ենք համալրացուցիչ համեմատական մոտեցում, որը հիմնված է Սիմպլիֆեյթ լեզվի ակտիվության հետքերի վրա (SIMPLAT). ՍՊԼԱԹ-ները մի քանի փակ ոլորտում գտնվող լեզվի կոդավորման կապորա են (մենք ուսումնասիրում ենք շախմային և բեյսբոլի խաղերի հետքերը այս աշխատանքում): Սպլաթ տվյալների համակարգերը օգտագործում են բնական տարածումներ, հնարավորություն են տալիս հարցերի և պատասխանների զույգերի ստեղծման մեջ, և հնարավորություն են տալիս լիովին գիտելիք իրենց փակ ոլորտներում: Մենք ցույց ենք տալիս, որ երեք տարբեր ճարտարապետության լեզվային մոդելները կարող են պատասխանել աշխարհային երկրների մասին հարցերին միայն օգտագործելով բայի նման ակտիվության կոդավորումներ: Our approach is extensible to new language models and additional question-answering tasks.', 'bn': 'আজকের প্রাকৃতিক ভাষা প্রক্রিয়ার সিস্টেমের ক্ষমতা সাধারণত বিশাল তথ্য সংক্রান্ত প্রশ্ন ও উত্তর ব্যবহার করে মূল্য While these are critical benchmarks of progress, they also suffer from weakness due to artificial distributions and incomplete knowledge.  শৈল্পিক বিতরণের ক্ষেত্রে আর্টিফ্যাক্টরা ভাষার মডেলের প্রদর্শনের বাড়িয়ে দিতে পারে, আর সম্পূর্ণ জ্ঞানের বিশ্লেষণে এই কাজে আমরা সিমপ্লিফিড ভাষা কার্যক্রম ট্রাসের ভিত্তিতে একটি সহায়ক ব্যাংমেন্টমেন্টিং পদক্ষেপ উপস্থাপন করি। এসপিল্যাটিস কিছু বন্ধ ডোমেইনে কার্যক্রমের কোর্পোরা ভাষার কোর্পোরা (আমরা এই কাজে চাক এবং বেস্বল খেলা থেকে ট্রেক পড়ি)। SPLAT ডাটাসেটগুলো স্বাভাবিকভাবে বিতরণ ব্যবহার করে, প্রশ্নের উত্তরের জোড়া তৈরি করার অনুমতি দেয় এবং তাদের বন্ধ ডোমেইনে পুরো জ্ঞ আমরা দেখাচ্ছি যে তিনটি ভিন্ন প্রতিষ্ঠানগুলোর ভাষার মডেল বিশ্বের রাষ্ট্র সম্পর্কে প্রশ্নের উত্তর দিতে পারে কেবল ক নতুন ভাষার মডেল এবং অতিরিক্ত প্রশ্নের উত্তরের কাজের জন্য আমাদের প্রতিযোগিতা সম্ভব।', 'bs': 'Sposobnosti današnjih prirodnih jezičkih obrađivanja obično se procjenjuju koristeći velike podatke izliječenih pitanja i odgovora. Iako su to kritične kritične kritične kritike napretka, oni također pate od slabosti zbog umjetnih raspodjela i nepotpunih znanja. Artifakti iz umjetničkih distribucija mogu nadmašiti učinkovitost jezičkog modela, dok nepotpuno znanje ograničava ispravnu analizu. U ovom poslu predstavljamo dodatni pristup kriteriji na temelju SimPlificiranog jezičkog aktivnosti (SPLAT). SPLAT su korporacija jezičkih kodiranja aktivnosti u nekom zatvorenom domenu (proučavamo tragove šaha i bejzbol igre u ovom poslu). SPLAT podaci koriste prirodno rastuće distribucije, omogućavaju generaciju par odgovora na pitanje u skali i priuštiti potpuno znanje u zatvorenim domenama. Pokazujemo da jezički modeli tri različite arhitekture mogu odgovoriti na pitanja o svijetskim državama koristeći samo kodiranje aktivnosti poput verba. Naš pristup je širok za nove jezičke modele i dodatne odgovorne zadatke na pitanje.', 'cs': 'Schopnosti dnešních systémů zpracování přirozeného jazyka jsou obvykle hodnoceny pomocí velkých datových sad kurátovaných otázek a odpovědí. Přestože jde o kritická měřítka pokroku, trpí také slabostí v důsledku umělého rozdělení a neúplných znalostí. Artefakty vznikající z umělých distribucí mohou přehánět výkonnost jazykového modelu, zatímco neúplné znalosti omezují jemnou analýzu. V této práci představujeme doplňkový benchmarking přístup založený na SimPlified Language Activity Traces (SPLAT). SPLAT jsou korpusy jazykových kódů aktivity v některé uzavřené oblasti (v této práci studujeme stopy z šachů a baseballových her). Datové sady SPLAT využívají přirozeně vznikající distribuce, umožňují generování párů otázek-odpověď v měřítku a poskytují kompletní znalosti v jejich uzavřených doménách. Ukazujeme, že jazykové modely tří různých architektur mohou odpovědět na otázky týkající se světových stavů pouze pomocí slovesově podobného kódování aktivity. Náš přístup je rozšířen na nové jazykové modely a další úkoly zodpovězení otázek.', 'ca': "Les capacitats dels sistemes natural s de processament de llenguatges d'avui en dia s'evaluen utilitzant grans conjunts de dades de preguntes i respostes curades. Mentre aquests són punts de referència crítics del progrés, també pateixen debilitat degut a distribucions artificials i coneixement incomplet. Els artefactes que surten de distribucions artificials poden sobrevaluar el rendiment del model lingüístic, mentre que el coneixement incomplet limita l'anàlisi fina. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT).  SPLATs són corpora de codificacions lingüístices d'activitat en un domini tancat (estudiem rastres dels jocs d'xadrex i de beisbol en aquest treball). Els conjunts de dades SPLAT utilitzen distribucions naturals, permeten generar parells de preguntes-respostes a escala i permeten coneixement complet en els seus dominis tancats. Mostrem que els models lingüístics de tres arquitectures diferents poden respondre preguntes sobre els estats mundials només fent servir codificacions d'activitat com verbs. El nostre enfocament és extensible a nous models lingüístics i tasques adicionals de resposta a preguntes.", 'et': 'Tänapäeva looduskeele töötlemise süsteemide võimalusi hinnatakse tavaliselt suurte andmekogumite abil, mis sisaldavad kureeritud küsimusi ja vastuseid. Kuigi need on edusammude kriitilised kriteeriumid, kannatavad nad ka kunstliku jaotuse ja ebatäielike teadmiste tõttu nõrkuse all. Kunstlikust levitamisest tulenevad esemed võivad keelemudeli jõudlust üle hinnata, samas kui puudulikud teadmised piiravad täpset analüüsi. Käesolevas töös tutvustame täiendavat võrdlusanalüüsi lähenemisviisi, mis põhineb SimPlified Language Activity Traces (SPLAT). SPLAT-d on keelekogeerimise korpused mõnes suletud valdkonnas (uurime selles töös male- ja pesapallimängude jälgi). SPLAT andmekogumid kasutavad loomulikult tekkivaid jaotusi, võimaldavad luua küsimuste ja vastuste paare mastaabis ning võimaldavad täielikke teadmisi oma suletud valdkondades. Näitame, et kolme erineva arhitektuuri keelemudelid suudavad vastata maailma seisundite küsimustele, kasutades ainult tegusõnalisi kodeeringuid. Meie lähenemisviis on laiendatav uutele keelemudelitele ja täiendavatele küsimustele vastamise ülesannetele.', 'fi': 'Nykypäivän luonnollisen kielen käsittelyjärjestelmien valmiuksia arvioidaan tyypillisesti suurilla tietokokonaisuuksilla, jotka sisältävät valikoituja kysymyksiä ja vastauksia. Vaikka nämä ovat kehityksen kriittisiä mittareita, ne kärsivät myös keinotekoisesta jakautumisesta ja puutteellisesta tiedosta johtuvasta heikkoudesta. Keinotekoisista jakeluista syntyvät artefaktit voivat yliarvioida kielimallin suorituskykyä, kun taas epätäydellinen tieto rajoittaa hienojakoista analyysiä. Tässä työssä esittelemme täydentävän vertailuanalyysin, joka perustuu SimPlified Language Activity Traces (SPLAT) -menetelmään. SPLAT:t ovat kielikoodauksen korpusia jollakin suljetulla alueella (tutkimme tässä työssä shakki- ja baseball-pelien jälkiä). SPLAT-aineistot käyttävät luonnostaan syntyviä jakaumia, mahdollistavat kysymyksen ja vastauksen parien luomisen mittakaavassa ja tarjoavat täydellistä tietoa suljetuista toimialueistaan. Osoitamme, että kolmen eri arkkitehtuurin kielimallit voivat vastata maailman tilaa koskeviin kysymyksiin käyttämällä vain verbimaisia aktiviteettikoodauksia. Lähestymistapamme on laajennettavissa uusiin kielimalleihin ja lisäkysymyksiin vastaamiseen.', 'jv': 'Punika kapan kanggo ngilangno sistem perusahaan nggunakake Genjer-genjer saiki iki diangkamu nggawe gerakan kanggo dianggap, wong iki ngono kaleh luwih apik lan alam sing ora nggawe kesempatan kanggo ngilangno. Artik sing wis kelompok karo Distribution artipe iso nggawe nggawe modèl kuwi tindang Nang barêng-barêng iki, kéné gunakake sistem sempliified Language Active traces (PLLAT). Delokan-Delokan sing dibenakno pergambar kanggo nggawe layang kelas nang sembarang dibenakno (kita yatak tarjamahan karo cah-cah lan kelas barang nggo barang iki). Spanish Awak dhéwé ngerasakno sistem ing tindang karo telu architecture sing sampeyan uga bisa cebagian sing mungkin karo hal-sangan kuwi wis ngubah mungkin verb-like koding kanggo mulasakno. Rasané awak dhéwé iso nggambar nggo modèl anyar karo ngono cejang bantuan karo cejang.', 'sk': 'Zmožnosti današnjih sistemov za obdelavo naravnega jezika se običajno ocenjujejo z uporabo velikih podatkovnih naborov urejenih vprašanj in odgovorov. Čeprav so to kritična merila napredka, trpijo tudi zaradi umetne porazdelitve in nepopolnega znanja. Artifakti, ki izhajajo iz umetnih distribucij, lahko pretiravajo učinkovitost jezikovnega modela, medtem ko nepopolno znanje omejuje drobnozrnato analizo. V tem delu predstavljamo dopolnilni pristop primerjalne analize, ki temelji na SimPlified Language Activity Traces (SPLAT). SPLAT so korpusi jezikovnega kodiranja aktivnosti v nekaterih zaprtih domenih (v tem delu preučujemo sledi šaha in baseball iger). Zbirki podatkov SPLAT uporabljajo naravno nastajajoče distribucije, omogočajo ustvarjanje parov vprašanj-odgovorov v obsegu in omogočajo popolno znanje na svojih zaprtih področjih. Pokazali smo, da lahko jezikovni modeli treh različnih arhitektur odgovarjajo na vprašanja o svetovnih stanjih z uporabo samo glagolskih kodiranj aktivnosti. Naš pristop je razširjen na nove jezikovne modele in dodatne naloge odgovarjanja na vprašanja.', 'he': 'היכולות של מערכות העבודה טבעיות של השפה היום בדרך כלל מתערכות באמצעות קבוצות נתונים גדולות של שאלות ומשובות מטופשות. בעוד אלה נקודות רמז קריטיות של התקדמות, הם גם סובלים מחלשה בגלל פיצוצים מלאכותיים וידע לא מלא. עובדות אומנות שמוצאות מהפיצוחים מלאכותיים יכולות לעלות על ההופעה של דוגמני שפה, בעוד ידע לא מושלם מגביל ניתוח מעולה. בעבודה הזו, אנו מציגים גישה משותפת של שיקול רמז מבוססת על עקבות פעילות שפה סימפליפציה (SPLAT). SPLATs הם גופורה של קודים שפות של פעילות באיזה תחום סגור (אנחנו לומדים עקבות משחקי שחמט ובייסבול בעבודה הזאת). קומות נתונים SPLAT משתמשים בהפיצות נוצרות באופן טבעי, מאפשרים לדור זוגות תשובות-שאלות בקנה מידה, ולהרשות לעצמם ידע מושלם בתחומים סגורים שלהם. אנחנו מראים שדוגמני שפה של שלושה ארכיטקטורות שונות יכולים לענות על שאלות על מדינות העולם בשימוש רק קודים של פעילות דומים לשפתיים. הגישה שלנו נמשכת למודלים שפותיים חדשים ומשימות נוספות לענות על שאלות.', 'ha': "An ƙaddara abincin tsarin masu zartar da harshen kwanan a yau, a yi amfani da matsayin tsari masu yawa na tambayar da ake karya. Alhãli kuwa waɗannan masu kamfata matsayin mafaƙo, sun yi cũtar da rauni sabõda rabo na fassarar da ilmi ba'a cika. San'afactan da ke fara rabon da ko wani abu na fassara, za'a iya ƙara tsarin misalin harshen, kuma idan an cikakken ilmi na ƙayyade tsarin Ana-grafi. Daga wannan aikin, Munã ƙara wata matsayi da ba'a iya lissafa ba, a kan karatun Cikakken Aiki na SimPlad (SPLET). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work).  KCharselect unicode block name Tuna nũna cewa misãlai na harshe na sakan masu turu masu cikin matsayi uku dabam-daban, sunã iya karɓa wa maswali masu hususann mataifa duniya da ke amfani da kodi kamar kodi na firam kawai. Mataimakinmu yana cikin misalin zane da wasu masu tambayar da ke karɓa.", 'bo': 'དེ་རིང་གི་སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ལས་སྦྱོར་བའི་ལུགས་སྤྱོད་ཀྱི་ཆ་རྐྱེན་ཅིག་རྟགས་པར་མཐུན་རྐྱེན་ཡོད་པ དེ་དག་ནི་ཡར་རྒྱས་ཁབ་ཀྱི་གནད་དོན་དག་ཆེན་མཁན་མེད་པའི་རྐྱེན་ཁག་ཅིག་ཡིན་ནའང་ཡང་གནོད་པ་ཞིག་གི་ཡོད། Artifacts arising from artificial distributions can overstate language model performance, while incomplete knowledge limits fine-grained analysis. SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encoding of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. ང་ཚོས་སྐད ང་ཚོའི་གཟུགས་སྐོར'}
{'en': 'Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction', 'ar': 'زيادة البيانات لدمج أنماط الخطأ الحقيقي والمعرفة اللغوية لتصحيح الأخطاء النحوية', 'es': 'Aumento de datos para incorporar patrones de error reales y conocimiento lingüístico para la corrección de errores gramaticales', 'pt': 'Aumento de dados da incorporação de padrões de erro reais e conhecimento linguístico para correção de erros gramaticais', 'fr': "Augmentation des données grâce à l'intégration de modèles d'erreur réels et de connaissances linguistiques pour la correction des erreurs grammaticales", 'ja': '文法的誤り訂正のための実際の誤りパターンと言語学的知識の組み込みのデータ拡張', 'zh': '合真谬模语数增强,施于语法纠错', 'hi': 'व्याकरणिक त्रुटि सुधार के लिए वास्तविक त्रुटि पैटर्न और भाषाई ज्ञान को शामिल करने का डेटा संवर्धन', 'ru': 'Расширение данных для включения шаблонов реальных ошибок и лингвистических знаний для коррекции грамматических ошибок', 'ga': 'Méadú Sonraí ar Ionchorprú Fíorphatrúin Earráide agus Eolas Teangeolaíoch le haghaidh Ceartú Earráide Gramadaí', 'ka': 'გრამიტური შეცდომის რეალური შეცდომის მონაცემების აგგგენტირება და სინგუტიური უცნობა', 'el': 'Ενσωμάτωση πραγματικών προτύπων σφαλμάτων και γλωσσικών γνώσεων για τη γραμματική διόρθωση σφαλμάτων', 'hu': 'Valós hibaminták és nyelvtudás beépítésének adatbővítése nyelvtani hibajavításhoz', 'it': 'Aumento dei dati per incorporare modelli di errore reali e conoscenze linguistiche per la correzione degli errori grammaticali', 'lt': 'Duomenų didinimas įtraukiant tikrųjų klaidų modelius ir kalbines žinias gramatinių klaidų koregavimui', 'mk': 'Агментација на податоците за вклопување на шаблони за вистинска грешка и јазичко знаење за корекција на граматска грешка', 'ms': 'Pembesaran Data untuk Memasukkan Corak Ralat Sebenar dan Pengetahuan Bahasa untuk Pembetulan Ralat Grammatik', 'mt': 'Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction', 'ml': 'ഗ്രാമാറ്റിക്കല്\u200d പിശക് തിരിച്ചറിയുന്നതിനുള്ള വിവരങ്ങളുടെ റിയാലിക്കല്\u200d പിശക് പിശകുകളും ലിങ്ഗിസ്റ്റിക്ക് അറ', 'mn': 'Үйлдлийн бодит алдаа загварын өгөгдлийн нэмэгдүүлэлт', 'no': 'Data-augmentasjon av inkorporasjon av verkeleg feilmønster og lingskjennomsikt for grammatisk feilretting', 'pl': 'Rozszerzenie danych włączania rzeczywistych wzorców błędów i wiedzy językowej dla korekcji błędów gramatycznych', 'sr': 'Povećavanje podataka o uključivanju pravih uzorka greška i lingwističkih znanja za korištenje gramatičkih greška', 'kk': 'Қате түзету үлгілерін және грамматикалық қатені түзету үшін лингвистикалық білім үлгілерінің деректерін көтеру', 'ro': 'Augmentarea datelor încorporării modelelor reale de eroare și cunoștințelor lingvistice pentru corectarea erorilor gramaticale', 'so': 'Ogeysiinta macluumaadka ku saabsan korsashada khaladda xaqiiqa ah', 'ta': 'சிறந்த பிழை திருத்தத்திற்கான தகவல் சேர்ப்பு', 'sv': 'Dataförstärkning av inkorporering av verkliga felmönster och språklig kunskap för grammatisk felkorrigering', 'si': 'ග්\u200dරාමාටිකල් දෝෂාව සඳහා ලිග්විස්ටික දැනගන්න', 'ur': 'گرامٹیکل خطا اصلاح کے لئے داٹا اگنٹ کرنا اور لینگیستیک علم', 'uz': 'Name', 'vi': 'Sự gia tăng dữ liệu cấu hình các mẫu lỗi thật và kiến thức ngôn ngữ cho lỗi máy tính', 'bg': 'Увеличаване на данните за включване на реални модели на грешки и езикови знания за корекция на граматични грешки', 'nl': 'Data Augmentation van het opnemen van echte foutpatronen en taalkundige kennis voor grammaticale foutcorrectie', 'hr': 'Povećavanje podataka uključujući pravi uzorak greške i Lingističke znanje za ispravu greške', 'da': 'Dataforøgelse af inkorporering af reelle fejlmønstre og sproglig viden til grammatisk fejlrettelse', 'de': 'Datenerweiterung der Einbindung realer Fehlermuster und sprachlicher Kenntnisse zur grammatischen Fehlerkorrektur', 'ko': '실제 오류 패턴과 언어 지식을 결합하여 문법 오류를 바로잡는 데이터 확장', 'id': 'Data Augmentation of Incorporating Real Error Patterns and Language Knowledge for Grammatical Error Correction', 'fa': 'افزایش داده\u200cهای الگوهای خطای واقعی و دانش لینگیستیک برای اصلاح خطای گرماتیک', 'sw': 'Uongezeko wa data wa Wazalendo na Ujuzi wa Kilinguistic', 'tr': 'Grammatikal Hata Düzeltmek üçin Hata Girişi Hata Şablonlar we Dilli Bilim', 'af': 'Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction', 'sq': 'Rritja e të dhënave për Korrektimin e Gabimeve Gramatike', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Տվյալների աճը, որը ներառում է իրական սխալների պատկերներ և լեզվաբանական գիտելիքներ գրամմատիկ սխալների ուղղելու համար', 'az': 'Qısqa Hata Şablarını və Gramatik Hata Düzəltməsi üçün Linguistik Bilməsi', 'bn': 'গ্রাম্মাটিক্যাল ত্রুটি সংস্কারের জন্য প্রকৃত ত্রুটি প্যাটার্ন এবং লিঙ্গিস্টিক জ্ঞানের তথ্য অংগ্রেপশন', 'bs': 'Povećavanje podataka o uključujući pravi uzorak greške i Lingističko znanje za korištenje gramatičkih greška', 'ca': "Aumentació de dades d'incorporar patrons d'error real i coneixement lingüístic per a corregir errors gramàtics", 'cs': 'Rozšíření dat začlenění reálných chybových vzorů a jazykových znalostí pro gramatickou korekci chyb', 'et': 'Tõeliste vigade mustrite ja keeleoskuste lisamine grammatilise vea parandamiseks', 'fi': 'Todellisten virhemallien ja kielitaitojen yhdistäminen kielioppivirheiden korjaukseen', 'jv': 'undo-type', 'ha': 'KCharselect unicode block name', 'he': 'גידול נתונים של תוספת דפוסי שגיאות אמיתיות ומידע לשונות לתיקון שגיאות גראמטיות', 'sk': 'Povečanje podatkov vključevanja vzorcev resničnih napak in jezikovnega znanja za slovnično popravljanje napak', 'bo': 'Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction'}
{'en': 'Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of  grammatical error correction (GEC) . In practice, there are a great number of real error patterns in the manually annotated training data. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. Moreover, we also find that linguistic knowledge can be incorporated into  data augmentation  for generating more representative and more diverse  synthetic data . In this paper, we propose a novel data augmentation method that fully considers the real error patterns and the linguistic knowledge for the GEC task. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.', 'ar': 'تهدف زيادة البيانات إلى توسيع بيانات التدريب بنص نظيف باستخدام مخططات التشويش لتحسين أداء تصحيح الأخطاء النحوية (GEC). من الناحية العملية ، هناك عدد كبير من أنماط الخطأ الحقيقي في بيانات التدريب المشروحة يدويًا. نجادل بأن أنماط الخطأ الحقيقية هذه يمكن إدخالها في نص نظيف لتوليد بيانات تركيبية أكثر واقعية وعالية الجودة ، والتي لم يتم استكشافها بالكامل من خلال الدراسات السابقة. علاوة على ذلك ، نجد أيضًا أنه يمكن دمج المعرفة اللغوية في زيادة البيانات لتوليد بيانات تركيبية أكثر تمثيلاً وتنوعًا. في هذه الورقة ، نقترح طريقة جديدة لزيادة البيانات تراعي بشكل كامل أنماط الخطأ الحقيقي والمعرفة اللغوية لمهمة GEC. نجري تجارب مكثفة على مجموعات البيانات العامة وتظهر النتائج التجريبية أن طريقتنا تتفوق في الأداء على العديد من خطوط الأساس القوية مع بيانات نصية نظيفة خارجية أقل بكثير ، مما يسلط الضوء على فعاليتها غير العادية في مهمة GEC التي تفتقر إلى بيانات التدريب الموسومة على نطاق واسع.', 'es': 'El aumento de datos tiene como objetivo ampliar los datos de entrenamiento con texto limpio utilizando esquemas de ruido para mejorar el rendimiento de la corrección de errores gramaticales (GEC). En la práctica, hay un gran número de patrones de error reales en los datos de entrenamiento anotados manualmente. Sostenemos que estos patrones de error reales pueden introducirse en texto limpio para generar de manera efectiva datos sintéticos más reales y de alta calidad, lo que no ha sido explorado completamente en estudios anteriores. Además, también encontramos que el conocimiento lingüístico se puede incorporar en el aumento de datos para generar datos sintéticos más representativos y diversos. En este artículo, proponemos un novedoso método de aumento de datos que considera plenamente los patrones de error reales y el conocimiento lingüístico para la tarea de GEC. Llevamos a cabo experimentos exhaustivos con conjuntos de datos públicos y los resultados experimentales muestran que nuestro método supera a varias líneas de base sólidas con muchos menos datos de texto limpio sin etiquetar externos, lo que destaca su extraordinaria eficacia en la tarea de GEC que carece de datos de capacitación etiquetados a gran escala.', 'fr': "L'augmentation des données vise à étendre les données d'entraînement avec un texte propre à l'aide de schémas de bruit afin d'améliorer les performances de la correction des erreurs grammaticales (GEC). En pratique, il existe un grand nombre de modèles d'erreur réels dans les données d'entraînement annotées manuellement. Nous soutenons que ces modèles d'erreur réels peuvent être introduits dans du texte propre afin de générer efficacement des données synthétiques plus réelles et de haute qualité, ce qui n'a pas été complètement exploré par les études précédentes. En outre, nous constatons également que les connaissances linguistiques peuvent être intégrées à l'augmentation des données afin de générer des données synthétiques plus représentatives et plus diversifiées. Dans cet article, nous proposons une nouvelle méthode d'augmentation des données qui tient pleinement compte des modèles d'erreur réels et des connaissances linguistiques pour la tâche GEC. Nous menons des expériences approfondies sur des ensembles de données publics et les résultats expérimentaux montrent que notre méthode surpasse plusieurs niveaux de base solides avec beaucoup moins de données de texte vierge externes non étiquetées, soulignant son efficacité extraordinaire dans la tâche GEC qui manque de données d'entraînement étiquetées à grande échelle.", 'pt': 'O aumento de dados visa expandir os dados de treinamento com texto limpo usando esquemas de ruído para melhorar o desempenho da correção de erros gramaticais (GEC). Na prática, há um grande número de padrões de erro reais nos dados de treinamento anotados manualmente. Argumentamos que esses padrões de erro reais podem ser introduzidos em texto limpo para gerar efetivamente dados sintéticos mais reais e de alta qualidade, que não são totalmente explorados por estudos anteriores. Além disso, também descobrimos que o conhecimento linguístico pode ser incorporado ao aumento de dados para gerar dados sintéticos mais representativos e diversificados. Neste artigo, propomos um novo método de aumento de dados que considera plenamente os padrões de erro reais e o conhecimento linguístico para a tarefa GEC. Realizamos extensos experimentos em conjuntos de dados públicos e os resultados experimentais mostram que nosso método supera várias linhas de base fortes com muito menos dados de texto limpo não rotulados externos, destacando sua extraordinária eficácia na tarefa GEC que carece de dados de treinamento rotulados em larga escala.', 'ja': 'データ拡張は、文法誤り訂正（ GEC ）のパフォーマンスを向上させるために、ノイズスキームを使用してクリーンテキストでトレーニングデータを拡張することを目的としています。 実際には、手動でアノテーションされたトレーニングデータには多数の実際のエラーパターンがあります。 私たちは、これらの実際のエラーパターンをクリーンテキストに導入して、より現実的で高品質な合成データを効果的に生成することができると主張していますが、これは以前の研究では完全には検討されていません。 さらに、より代表的で多様な合成データを生成するために、言語学的知識をデータ拡張に組み込むことができることも見出されます。 本稿では， GECタスクのために，実際の誤差パターンと言語学的知識を十分に考慮した新しいデータ増強法を提案する． 私たちは公開データセットの広範な実験を行い、実験結果は、外部のラベル付けされていないクリーンテキストデータで、私たちの方法がいくつかの強力なベースラインを上回っていることを示し、大規模なラベル付けされたトレーニングデータを欠いているGECタスクにおける卓越した有効性を強調しています。', 'zh': '据增旨在用噪声方案用净文本广练数,以崇语法纠错(GEC)之性。 在实践中,手动注训数多有真误。 臣愚以为错误模式引净本,效成真高质量,而前论未尽。 语言知识,入数增强,以生更具代表性多样化之综数。 本文举充分考虑GEC实谬模式及语言知识新型数增其法。 吾于公共数据集广实验,实验结果表明吾法外示净文数优于数强基线,显其乏大标练数之GEC有效性。', 'hi': 'डेटा संवर्धन का उद्देश्य व्याकरणिक त्रुटि सुधार (जीईसी) के प्रदर्शन में सुधार करने के लिए नोइज़िंग योजनाओं का उपयोग करके स्वच्छ पाठ के साथ प्रशिक्षण डेटा का विस्तार करना है। व्यवहार में, मैन्युअल रूप से एनोटेट किए गए प्रशिक्षण डेटा में वास्तविक त्रुटि पैटर्न की एक बड़ी संख्या है। हम तर्क देते हैं कि इन वास्तविक त्रुटि पैटर्न को अधिक वास्तविक और उच्च गुणवत्ता वाले सिंथेटिक डेटा को प्रभावी ढंग से उत्पन्न करने के लिए स्वच्छ पाठ में पेश किया जा सकता है, जो पिछले अध्ययनों द्वारा पूरी तरह से पता नहीं लगाया गया है। इसके अलावा, हम यह भी पाते हैं कि भाषाई ज्ञान को अधिक प्रतिनिधि और अधिक विविध सिंथेटिक डेटा उत्पन्न करने के लिए डेटा संवर्धन में शामिल किया जा सकता है। इस पेपर में, हम एक उपन्यास डेटा संवर्धन विधि का प्रस्ताव करते हैं जो जीईसी कार्य के लिए वास्तविक त्रुटि पैटर्न और भाषाई ज्ञान पर पूरी तरह से विचार करता है। हम सार्वजनिक डेटा सेट पर व्यापक प्रयोग करते हैं और प्रयोगात्मक परिणामों से पता चलता है कि हमारी विधि बहुत कम बाहरी बिना लेबल वाले स्वच्छ पाठ डेटा के साथ कई मजबूत बेसलाइनों को मात देती है, जीईसी कार्य में इसकी असाधारण प्रभावशीलता को उजागर करती है जिसमें बड़े पैमाने पर लेबल किए गए प्रशिक्षण डेटा की कमी होती है।', 'ru': 'Расширение данных направлено на расширение данных обучения чистым текстом с использованием схем шумоподавления для улучшения производительности грамматической коррекции ошибок (GEC). На практике существует большое количество реальных шаблонов ошибок в вручную аннотированных обучающих данных. Мы утверждаем, что эти реальные паттерны ошибок могут быть введены в чистый текст, чтобы эффективно генерировать более реальные и высококачественные синтетические данные, которые не были полностью изучены в предыдущих исследованиях. Кроме того, мы также обнаружили, что лингвистические знания могут быть включены в расширение данных для создания более репрезентативных и более разнообразных синтетических данных. В данной работе мы предлагаем новый метод дополнения данных, который полностью учитывает реальные закономерности ошибок и лингвистические знания для задачи ГЭК. Мы проводим обширные эксперименты над общедоступными наборами данных, и экспериментальные результаты показывают, что наш метод превосходит несколько сильных базовых линий с гораздо меньшим количеством внешних немаркированных чистых текстовых данных, подчеркивая его исключительную эффективность в задаче ГЭК, в которой отсутствуют крупномасштабные меченые обучающие данные.', 'ga': 'Tá sé mar aidhm ag méadú sonraí sonraí oiliúna a mhéadú le téacs glan trí úsáid a bhaint as scéimeanna torainn chun feabhas a chur ar fheidhmíocht ceartaithe earráide gramadaí (GEC). Go praiticiúil, tá líon mór patrúin earráide fíor sna sonraí oiliúna anótáilte de láimh. Áitímid gur féidir na patrúin earráide fíor seo a thabhairt isteach i dtéacs glan chun níos mó sonraí sintéiseacha fíor agus ardchaighdeáin a ghiniúint go héifeachtach, rud nach bhfuil iniúchadh iomlán déanta orthu ag staidéir roimhe seo. Ina theannta sin, feicimid freisin gur féidir eolas teanga a ionchorprú i méadú sonraí chun sonraí sintéiseacha níos ionadaíche agus níos éagsúla a ghiniúint. Sa pháipéar seo, molaimid modh núíosach méadaithe sonraí a bhreithníonn go hiomlán na fíorphatrúin earráide agus an t-eolas teangeolaíoch do thasc an GEC. Déanaimid turgnaimh fhairsing ar thacair sonraí poiblí agus léiríonn na torthaí turgnamhacha go sáraíonn ár modh roinnt bonnlínte láidre le i bhfad níos lú sonraí téacs glan neamhlipéadaithe seachtracha, ag léiriú a éifeachtúlacht urghnách i dtasc GEC nach bhfuil sonraí oiliúna lipéadaithe ar scála mór ann.', 'el': 'Η αύξηση δεδομένων αποσκοπεί στην επέκταση των δεδομένων κατάρτισης με καθαρό κείμενο χρησιμοποιώντας συστήματα θορύβου για τη βελτίωση της απόδοσης της διόρθωσης γραμματικών σφαλμάτων (GEC). Στην πράξη, υπάρχει μεγάλος αριθμός πραγματικών προτύπων σφαλμάτων στα μη αυτόματο σχολιασμένα δεδομένα εκπαίδευσης. Υποστηρίζουμε ότι αυτά τα πραγματικά μοτίβα σφάλματος μπορούν να εισαχθούν σε καθαρό κείμενο για να δημιουργήσουν αποτελεσματικά πιο πραγματικά και υψηλής ποιότητας συνθετικά δεδομένα, τα οποία δεν έχουν διερευνηθεί πλήρως από προηγούμενες μελέτες. Επιπλέον, διαπιστώνουμε επίσης ότι η γλωσσική γνώση μπορεί να ενσωματωθεί στην αύξηση δεδομένων για τη δημιουργία πιο αντιπροσωπευτικών και πιο ποικίλων συνθετικών δεδομένων. Στην παρούσα εργασία, προτείνουμε μια νέα μέθοδο αύξησης δεδομένων που λαμβάνει πλήρως υπόψη τα πραγματικά μοτίβα σφαλμάτων και τις γλωσσικές γνώσεις για το έργο της ΓΕΚ. Διεξάγουμε εκτεταμένα πειράματα σε δημόσια σύνολα δεδομένων και τα πειραματικά αποτελέσματα δείχνουν ότι η μέθοδος μας ξεπερνά αρκετές ισχυρές γραμμές βάσης με πολύ λιγότερα εξωτερικά χωρίς ετικέτα δεδομένα καθαρού κειμένου, αναδεικνύοντας την εξαιρετική αποτελεσματικότητά της στην εργασία που στερείται μεγάλης κλίμακας επισημασμένων δεδομένων κατάρτισης.', 'ka': 'Data augmentation aims to expand training data with clean text using noise schemes to improve the performance of grammatical error correction (GEC). პრაქტიკურად მრავალი შეცდომების მონაცემებში არსებობს ძალიან მრავალი შეცდომების მონაცემებში. ჩვენ არგებთ, რომ ეს ნამდვილად შეცდომების მონაცემები შეიძლება წაშლა ტექსტში გადატანა, რომ ეფექტიურად უფრო რეალური და მაღალური სინტეტიკური მონაცემები შექმნა დამატებით, ჩვენ ვფიქრობთ, რომ ლენგურისტიკური მეცნიერება შეიძლება მონაცემების აგგენტაციაში დავყენება უფრო რესპენტეტიკური და უფრო განსხვავებული სინტე ამ დოკუნეში ჩვენ ახალი მონაცემების ახადუმენტაციის მეტი, რომელიც ყველაფერად ახალი შეცდომის შაბლოები და ენდუმენტიკური ცოდნა GEC დავალებისთვის. ჩვენ გავაკეთებთ განსაკუთრებული ექსპერიმენტები საერთო მონაცემები და ექსპერიმენტები გავაკეთებთ, რომ ჩვენი მეთოდი უფრო ძალიან ძალიან ფექსტური ფექსტური ტექსტური მონაცემები გავაკეთებს, რომელიც', 'hu': 'Az adatbővítés célja a képzési adatok tiszta szöveggel történő bővítése zajszabási sémák segítségével a nyelvtani hibakorrekció (GEC) teljesítményének javítása érdekében. A gyakorlatban számos valós hibaminta van a manuálisan jegyzetelt edzési adatokban. Azzal érvelünk, hogy ezeket a valós hibamintákat tiszta szövegbe lehet bevezetni, hogy hatékonyabban létrehozzanak valós és kiváló minőségű szintetikus adatokat, amelyeket korábbi tanulmányok nem vizsgálnak teljesen. Továbbá azt is megállapítjuk, hogy a nyelvtudás beépíthető az adatbővítésbe, hogy reprezentatívabb és sokszínűbb szintetikus adatokat hozzon létre. Ebben a tanulmányban egy új adatbővítési módszert javasolunk, amely teljes mértékben figyelembe veszi a GEC feladat valós hibamintáit és nyelvtudását. Széleskörű kísérleteket végzünk nyilvános adatkészleteken, és a kísérleti eredmények azt mutatják, hogy módszerünk több erős alapvetőséget is felülmúlja, sokkal kevesebb külső címke nélküli tiszta szövegadattal, kiemelve annak rendkívüli hatékonyságát a nagyszabású címkézett képzési adatok hiányában lévő GEC feladatban.', 'it': "L'aumento dei dati mira a espandere i dati di allenamento con testo pulito utilizzando schemi di rumorosità per migliorare le prestazioni della correzione degli errori grammaticali (GEC). In pratica, ci sono un gran numero di modelli di errore reali nei dati di allenamento annotati manualmente. Sosteniamo che questi modelli di errore reali possono essere introdotti nel testo pulito per generare efficacemente dati sintetici più reali e di alta qualità, che non sono completamente esplorati da studi precedenti. Inoltre, troviamo anche che le conoscenze linguistiche possono essere incorporate nell'aumento dei dati per generare dati sintetici più rappresentativi e diversificati. In questo articolo, proponiamo un nuovo metodo di aumento dei dati che tiene pienamente conto dei modelli di errore reali e delle conoscenze linguistiche per il compito GEC. Conduciamo esperimenti approfonditi su set di dati pubblici e i risultati sperimentali mostrano che il nostro metodo supera diverse linee di base forti con dati di testo pulito senza etichetta esterni molto meno, evidenziando la sua straordinaria efficacia nel compito GEC che manca di dati di formazione etichettati su larga scala.", 'kk': 'Деректерді жақсарту мақсатында, грамматикалық қателерді түзету үшін (GEC) дыбыс сұлбаларын қолдану үшін бақылау мәтінді таза мәтінде көтеру деректерін жасау үшін. Жұмыс істеу үшін қолмен жазылған оқыту деректерінде шын қате үлгілері бар. Біз бұл шын қатенің үлгілерін таза мәтініне енгізу үшін шын және жоғары сапалы синтетикалық деректерді құру үшін, бұл өткен зерттеулерде толық зерттелмеген. Сонымен қатар, лингвистикалық білім көптеген және көптеген синтетикалық деректерді құру үшін деректерді көптегендіру мүмкін болады. Бұл қағазда, GEC тапсырмасы үшін шындық қате үлгілерін және лингвистикалық білім үшін жаңа деректерді қосу әдісін таңдаймыз. Біз көпшілік деректер жиындарында кеңейтілген тәжірибелер және тәжірибелі нәтижелер біздің әдіміміздің бірнеше күшті негізгі сызық мәтін деректері арқылы жазылмаған сыртқы сыртқы мәтін деректері арқылы көп', 'lt': 'Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of grammatical error correction (GEC).  Praktiškai rankiniu būdu pažymėtuose mokymo duomenise yra daug tikrų klaidų. Mes teigiame, kad šie tikrų klaidų modeliai gali būti įtraukti į švarų tekstą, kad būtų veiksmingai sukurti realesni ir aukštos kokybės sintetiniai duomenys, kurie nebuvo išsamiai išnagrinėti ankstesniuose tyrimuose. Be to, mes taip pat nustatome, kad kalbos žinios gali būti įtrauktos į duomenų didinimą, siekiant sukurti reprezentatyvesnius ir įvairesnius sintetinius duomenis. Šiame dokumente siūlome naują duomenų didinimo metodą, kuris visapusiškai atsižvelgtų į tikrus klaidų modelius ir kalbines žinias GEC užduotyje. Atliekame išsamius eksperimentus su viešaisiais duomenų rinkiniais, o eksperimentiniai rezultatai rodo, kad mūsų metodas yra didesnis už kelis tvirtus bazinius duomenis su gerokai mažiau išoriniais be ženklo pažymėtais švarių tekstų duomenimis, pabrėžiant jo ypatingą veiksmingumą GEC užduotyje, kurioje trūksta didelio masto pažymėtų mokymo duomenų.', 'mk': 'Зголемувањето на податоците има за цел проширување на податоците за обука со чист текст користејќи звучни шеми за подобрување на резултатите на корекцијата на граматичките грешки (ГЕЦ). Во практиката постојат голем број реални грешки во рачно анотираните податоци за обука. Ние тврдиме дека овие реални шаблони на грешки може да се внесат во чист текст за ефикасно да се генерираат пореални и висококвалитетни синтетски податоци, кои не се целосно истражуваат од претходните студии. Покрај тоа, исто така, откриваме дека јазичното знаење може да се вклучи во зголемувањето на податоците за генерирање попретставнички и поразлични синтетички податоци. Во овој весник предложуваме нов метод за зголемување на податоците кој целосно ги смета вистинските грешки и јазичното знаење за задачата на ГЕЦ. Ние спроведуваме експерименти на јавни податоци и експерименталните резултати покажуваат дека нашиот метод надминува неколку силни основни линии со многу помалку надворешни неозначени чисти текстови податоци, истакнувајќи ја нејзината исклучителна ефективност во задачата на ГЕЦ, која недостасува на големо обеле', 'ml': 'ഡേറ്റാ കൂട്ടിചേര്\u200dക്കുന്നതിന്റെ ഗ്രാമ്മാട്ടിക്കല്\u200d തിരിച്ചറിയുന്നതിനുള്ള പ്രവര്\u200dത്തനത്തിനുള്ള പ്രവര്\u200dത്തനപ്രകൃ പ്രവര്\u200dത്തനത്തില്\u200d, കൈയ്യിലായി പരിശീലനത്തിന്റെ വിവരങ്ങളില്\u200d ഒരുപാട് പിശക് രീതിയിലുണ്ട്. ഈ യഥാര്\u200dത്ഥ തെറ്റുകളുടെ രീതികള്\u200d ശുദ്ധമായ പദാവലിയിലേക്ക് പരിചയപ്പെടുത്തുവാന്\u200d സാധ്യതയുള്ള വിവരങ്ങള്\u200d സൃഷ്ടിക്കാന്\u200d സാ അതുകൊണ്ടും, ഭാഷ വിവരങ്ങള്\u200d കൂടുതല്\u200d പ്രതിനിധികളും വ്യത്യസ്തമായ വിവരങ്ങളും ഉണ്ടാക്കുന്നതിന് വേണ്ടി ഡേറ്റാ കൂടുതല്\u200d വിവരങ്ങളില ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d ഒരു നോവല്\u200d ഡേറ്റാ കൂട്ടുന്ന രീതി പൊതുവിന്റെ ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d നമ്മള്\u200d വിശാലമായ പരീക്ഷണങ്ങള്\u200d നടത്തുന്നു. പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ രീതിയില്\u200d കൂടുതല്\u200d ശക്തിയുള്ള ബേസ്ലെയിനുകള', 'ms': 'Peningkatan data bertujuan untuk mengembangkan data latihan dengan teks bersih menggunakan skema bunyi untuk meningkatkan prestasi pembetulan ralat grammatik (GEC). Dalam praktik, terdapat banyak corak ralat sebenar dalam data latihan yang dicatat secara manual. Kami menyangka corak ralat sebenar ini boleh diperkenalkan ke dalam teks bersih untuk secara efektif menghasilkan data sintetik yang lebih nyata dan kualiti tinggi, yang tidak dikenalpasti sepenuhnya oleh kajian sebelumnya. Selain itu, kita juga mendapati bahawa pengetahuan bahasa boleh disertai dalam peningkatan data untuk menghasilkan data sintetik yang lebih mewakili dan berbeza. Dalam kertas ini, kami cadangkan kaedah peningkatan data yang secara penuh mempertimbangkan corak ralat sebenar dan pengetahuan bahasa untuk tugas GEC. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.', 'mt': 'Iż-żieda fid-dejta għandha l-għan li tespandi d-dejta tat-taħriġ b’test nadif bl-użu ta’ skemi ta’ storbju biex ittejjeb il-prestazzjoni tal-korrezzjoni tal-iżbalji grammatiċi (GEC). Fil-prattika, hemm għadd kbir ta’ mudelli ta’ żbalji reali fid-dejta tat-taħriġ annotata manwalment. Aħna jargumentaw li dawn ix-xejriet ta’ żball reali jistgħu jiġu introdotti f’test nadif biex b’mod effettiv jiġġeneraw dejta sintetika aktar reali u ta’ kwalità għolja, li mhijiex esplorata kompletament minn studji preċedenti. Barra minn hekk, isibu wkoll li l-għarfien lingwistiku jista’ jiġi inkorporat f’żieda fid-dejta għall-ġenerazzjoni ta’ dejta sintetika aktar rappreżentattiva u aktar diversifikata. F’dan id-dokument, qed nipproponu metodu ġdid ta’ żieda fid-dejta li jikkunsidra bis-sħiħ ix-xejriet reali ta’ żball u l-għarfien lingwistiku għall-kompitu tal-GEC. Aħna nagħmlu esperimenti estensivi fuq settijiet ta’ dejta pubblika u r-riżultati sperimentali juru li l-metodu tagħna jaqbeż bosta linji bażi b’ħafna inqas dejta esterna tat-test nadif mingħajr tikketta, li tenfasizza l-effettività straordinarja tiegħu fil-kompitu tal-GEC li m’għandux dejta ta’ taħriġ tikkettata fuq skala kbira.', 'no': 'Data-augmentasjon må utvida treningsdata med rein tekst ved hjelp av støyskjemar for å forbetra utviklinga av grammatiske feilretting (GEC). I praksis finn det mange rekke feilmønster i dei manuelt opplæringsdata. Vi argumenterer at desse verkelege feilmønstrene kan innførast i rein tekst for å laga meir verkeleg og høg kvalitetsintetiske data, som ikkje er fullstendig utforska av tidlegare studiar. I tillegg finn vi også at lingviske kunnskap kan inkluderast i økning av data for å laga meir reprezentativ og meir ulike syntetiske data. I denne papiret foreslår vi ein novel data-augmentasjon metode som fullstendig gjer det verkelege feilmønsteret og den linguistiske kunnskapen for GEC-oppgåva. Vi gjer utvida eksperimenter på offentlige datasett og eksperimentelle resultatene viser at metoden vårt utfører fleire sterke baselinjer med mykje mindre ekstern uten merkelige rein tekstdata, og markerer ekstra effektiviteten i GEC-oppgåva som manglar stor skala merkelige opplæringsdata.', 'pl': 'Rozszerzenie danych ma na celu poszerzenie danych treningowych o czysty tekst z wykorzystaniem schematów hałasu w celu poprawy wydajności korekcji błędów gramatycznych (GEC). W praktyce istnieje duża liczba rzeczywistych wzorców błędów w ręcznie adnotacji danych treningowych. Twierdzimy, że te rzeczywiste wzorce błędów można wprowadzić do czystego tekstu, aby skutecznie generować bardziej rzeczywiste i wysokiej jakości dane syntetyczne, które nie są w pełni zbadane w poprzednich badaniach. Ponadto zauważamy, że wiedza językowa może być włączona do rozszerzania danych w celu generowania bardziej reprezentatywnych i bardziej zróżnicowanych danych syntetycznych. W niniejszym artykule proponujemy nową metodę powiększania danych, która w pełni uwzględnia rzeczywiste wzorce błędów i wiedzę językową dla zadania GEC. Przeprowadzamy obszerne eksperymenty na publicznych zbiorach danych, a wyniki eksperymentalne pokazują, że nasza metoda przewyższa kilka silnych linii bazowych z dużo mniej zewnętrznych nieoznakowanych czystych danych tekstowych, podkreślając jej niezwykłą skuteczność w zadaniu GEC, którym brakuje dużej skali etykietowanych danych treningowych.', 'mn': 'Дасгал өгөгдлийн нэмэгдүүлэлт нь грамматикийн алдаа засах үйл ажиллагааг сайжруулахын тулд цэвэр текстэй дасгал өгөгдлийн мэдээллийг нэмэгдүүлэх зорилго юм. Жишээлбэл, сургалтын өгөгдлийн талаар маш олон бодит алдаа загвар байдаг. Бид эдгээр бодит алдаа загваруудыг цэвэр текст рүү оруулж чадна гэдгийг хэлж байна. Өмнөх судалгаанаас бүрэн судалж чадахгүй. Мөн бид хэлний мэдлэг нь илүү олон төрлийн синтетик өгөгдлийг бий болгохын тулд өгөгдлийн нэмэгдүүлэлт оруулж болно. Энэ цаасан дээр бид GEC ажлын бодит алдаа загварыг, хэлний мэдлэгийг бүрэн ойлгох шинэ өгөгдлийн нэмэгдүүлэх арга загварыг сануулдаг. Бид олон нийтийн өгөгдлийн хэмжээний туршилтууд хийдэг бөгөөд туршилтын үр дүнд бидний арга нь олон хүчтэй суурь шугам өгөгдлийг бага зэрэг цэвэр бичигдэггүй цэвэр текст өгөгдлийг ашиглаж, том хэмжээний тэмдэглэгдсэн сургалтын өгөгдлийг алдаггүй', 'ro': 'Augmentarea datelor vizează extinderea datelor de instruire cu text curat folosind scheme de zgomot pentru a îmbunătăți performanța corectării erorilor gramaticale (GEC). În practică, există un număr mare de modele reale de eroare în datele de antrenament adnotate manual. Susținem că aceste modele reale de eroare pot fi introduse în text curat pentru a genera în mod eficient date sintetice mai reale și de înaltă calitate, care nu sunt pe deplin explorate de studiile anterioare. Mai mult decât atât, constatăm, de asemenea, că cunoștințele lingvistice pot fi încorporate în mărirea datelor pentru a genera date sintetice mai reprezentative și mai diverse. În această lucrare, propunem o metodă nouă de augmentare a datelor care ia în considerare pe deplin modelele reale de eroare și cunoștințele lingvistice pentru sarcina GEC. Efectuăm experimente extinse pe seturi de date publice, iar rezultatele experimentale arată că metoda noastră depășește mai multe linii de bază puternice, cu mult mai puține date externe fără etichete text curat, evidențiind eficacitatea extraordinară a acesteia în sarcina GEC care lipsește date de instruire etichetate la scară largă.', 'sr': 'Povećavanje podataka je cilj proširenja podataka obuke sa čistim tekstom koristeći šeme buke kako bi poboljšala učinkovitost isprave gramatičkih grešaka (GEC). U praksi postoji veliki broj pravih pogrešnih obrazaca u podacima o ruènom annotiranju obuke. Tvrdimo da se ovi pravi greški obrasce mogu uvesti u čist tekst kako bi efikasno stvorili realnije i visoke kvalitetne sintetičke podatke, koje se ne potpuno istražuju prethodnim studijama. Osim toga, takođe smatramo da se jezičko znanje može uključiti u povećanje podataka za stvaranje više reprezentativnih i različitih sintetičkih podataka. U ovom papiru predlažemo novu metodu povećanja podataka koja potpuno smatra pravim greškama i jezičkim znanjem za GEC zadatak. Provodimo široke eksperimente na javnim setima podataka i eksperimentalnim rezultatima pokazuju da naš metod iznosi nekoliko jakih osnovnih linija sa mnogo manjim vanjskim podacima o čistom tekstu, naglašavajući svoju izvanrednu efikasnost u zadatku GEC-a koja nedostaje velike označene podatke o obuci.', 'so': "Horumarinta macluumaadka waxaa loogu talogalay in la sii wado macluumaad waxbarasho oo ku qoran qoraal nadiif ah oo lagu isticmaalo qorshaha codsiga si uu u hagaajiyo hagaajinta khaladda grammatika (GEC). Sida caadiga ah macluumaadka waxbarashada ee qofka gacanta lagu qabanayo waxaa ku jira noocyo badan oo khalad ah. Waxaynu ka fekeraynaa in qalabkan dhabta ah looga soo bandhigi karo qoraal nadiif ah si aad u faa’iido leh u sameyn karto macluumaadka kaamilka ah oo aad u sareeya, taasoo aan si buuxda loo baarayn waxbarashada hore. Sidoo kale waxaynu ognahay in aqoonta luqada lagu soo koobi karo kordhinta macluumaadka, si loo sameyno macluumaad ka badan iyo macluumaad kala duduwan. In this paper, we propose a novel data augmentation method that fully considers the real error patterns and the linguistic knowledge for the GEC task.  Waxaan sameynaa imtixaamo dheeraad ah oo ku saabsan kooxda macluumaadka dadweynaha, waxaana tusinayaa qaababka imtixaanka ah in qaababkayagu uu soo saaraa qaar saldhig xoog leh oo ay ka yar yihiin macluumaad daahir ah oo dibadda ah oo aan la labeyn karin, waxaana ka muujinaynaa faa'iido caadi ah oo ku saabsan shaqada GEC oo aan u baahan macluumaad waxbarasho oo aad u weyn.", 'si': 'දත්ත විශාලනය අදහස් කරනවා සුදුසු පාළුවක් සමඟ ප්\u200dරශ්නය දත්ත විස්තර කරන්න, ශබ්ද විස්තර පරීක්ෂණය සඳහා සුද පරීක්ෂණයෙන්, ඇත්ත වැරැද්දක් තොරතුරු ඇතුළත් වැරැද්දක් තියෙනවා. අපි ප්\u200dරශ්නයක් කරනවා මේ ඇත්ත වැරදි ප්\u200dරශ්නයක් පිළිබඳ පාළුවෙන් පිළිබඳු පාළුවෙන් ප්\u200dරශ්නයක් වෙන්න පුළු තවත් අපිට හොයාගන්න පුළුවන් විදිහට භාෂාවික දන්නවත් තොරතුරු විශාල විදිහට සම්බන්ධ වෙන්න පුළුවන් මේ පත්තරේ අපි නියම දත්ත විශාලනය විදියට ප්\u200dරතිචාරයක් කරනවා, ඒ වගේම ඇත්ත වැරදි ප්\u200dරතිචාරය සහ GEC වැඩ සඳහා භ අපි සාමාන්\u200dය දත්ත සැට් වල විශාල ප්\u200dරයෝජනය කරනවා ඒ වගේම ප්\u200dරයෝජනය විදියට අපේ විදියට ප්\u200dරයෝජනය ප්\u200dරයෝජනය කරන්න පුළුවන් විතරයි අපේ විදියට ප්\u200dරයෝ', 'sv': 'Dataförstärkning syftar till att utöka träningsdata med ren text med hjälp av bullerscheman för att förbättra prestandan för grammatisk felkorrigering (GEC). I praktiken finns det ett stort antal verkliga felmönster i de manuellt kommenterade träningsdata. Vi menar att dessa verkliga felmönster kan införas i ren text för att effektivt generera mer verkliga och högkvalitativa syntetiska data, vilket inte utforskas fullt ut av tidigare studier. Dessutom finner vi att språkkunskaper kan införlivas i dataökning för att generera mer representativa och mångsidiga syntetiska data. I denna uppsats föreslår vi en ny dataaugmentationsmetod som fullt ut beaktar de verkliga felmönstren och språkliga kunskaperna för GEC-uppgiften. Vi genomför omfattande experiment på offentliga datauppsättningar och de experimentella resultaten visar att vår metod överträffar flera starka baslinjer med betydligt mindre externa omärkta rena textdata, vilket belyser dess extraordinära effektivitet i GEC-uppgiften som saknar storskalig märkt träningsdata.', 'ta': 'தரவு சேர்ப்பு பயிற்சி தகவலை சுத்தமான உரையை பயன்படுத்தி ஒலி முறைமைகளை விரிவாக்குவதற்கு குறிப்பிட்ட பிழை திருத்தம் செய் முயற்சியில், கைமுறையாக குறிப்பிட்ட பயிற்சி தரவில் பல உண்மையான பிழை வடிவங்கள் உள்ளன. நாம் விவாதம் செய்கிறோம் என்றால், இந்த உண்மையான பிழை முறைமைகள் சுத்தமான உரையில் முன்னால் முழுமையாக ஆராய்ந்து கொள்ளாத மேலும், நாம் கண்டுபிடிக்கிறோம் மொழி அறிவு தகவல் மேம்படுத்தல் மற்றும் மேலும் பல்வேறு கூட்டிணைப்பு தகவலை உருவாக்குவதற்க இந்த காகிதத்தில், நாம் ஒரு புதிய தகவல் கூட்டுதல் முறைமையை பரிந்துரைக்கிறோம். அது சரியான பிழை முறைமைகளையும் GEC பணிக்கான ம பொது தரவு அமைப்புகளில் நாம் விரிவான சோதனைகளை செய்கிறோம் மற்றும் சோதனையின் முடிவுகள் காண்பிக்கிறது எங்கள் முறைமை பல வலிமையான அடிப்படைகளை வெளியேற்றுகிறது வெளியே', 'ur': 'ڈاٹا افزایش کا ارادہ ہے کہ پاک ٹیکسٹ کے ساتھ تدریس ڈیٹ پھیلانے کا استعمال کرنا ہے کہ صدا سکیموں کے مطابق گراماتیکی خطا اصلاح (GEC) کی عملکرد کو بہتر کرے۔ آزمائش میں بہت سی حقیقی خطا پٹرنے کی تعلیم دادہ میں ہے. ہم argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. اور ہم نے بھی دیکھا ہے کہ زبان شناسی علم ڈیٹا اضافہ کرنے کے لئے زیادہ معجزات اور زیادہ مختلف سینٹیسی ڈیٹے پیدا کرنے کے لئے داخل ہو سکتا ہے۔ اس کاغذ میں، ہم ایک نو ڈیٹا اضافہ طریقہ پیش کریں گے جو GEC کام کے لئے واقعی خطا پٹرنے اور زبان شناسی علم کو پورا سمجھتا ہے. ہم عمومی ڈیٹا سٹ پر بہت زیادہ آزمائش کرتے ہیں اور آزمائش نتیجے دکھاتے ہیں کہ ہمارا طریقہ بہت زیادہ طاقتور بنسٹ لین کے ساتھ بہت کم کم بغیر معلوم نہیں ہوئے پاک ٹیکسٹ ڈیٹا کے ساتھ عمل کرتا ہے، جسے GEC ٹیسک میں اخلاق اثبات کی تعلیم کر', 'uz': "Name Taʼminlovchi taʼminlovchi maʼlumotlarda ko'p haqiqiqiy xato patternlari mavjud. Biz murakkab qilamiz, bu haqiqiqiy xato tuzillari qoʻllaniladi. Bu oldingi o'rganishlar davomida juda ko'proq va katta tizim tizimini yaratish mumkin. Ko'rib, biz o'ylaymiz, tillarning илмi qo'shish mumkin va ko'proq va ko'proq bir xil syntetik maʼlumotini yaratish uchun maʼlumot yordamida qo'yish mumkin. Bu hujjatda, biz GEC vazifasi haqiqiqiy xato tuzillarini va lugʻlik ilmogasini butunlay o'ylayapmiz. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.", 'vi': 'Sự gia tăng dữ liệu nhằm hướng tới việc mở rộng dữ liệu đào tạo bằng văn bản sạch, sử dụng các biện pháp rung động để cải thiện khả năng sửa sai ngữ pháp (GEC). Trong thực tế, có rất nhiều dạng lỗi thực sự trong dữ liệu huấn luyện được ghi chú bằng tay. Chúng tôi cho rằng những mô hình lỗi thật sự này có thể được đưa vào trong văn bản sạch để tạo ra các dữ liệu tổng hợp chất thật hơn và chất lượng cao, mà chưa được nghiên cứu đầy đủ. Chúng tôi cũng thấy rằng kiến thức ngôn ngữ có thể nhập vào việc tăng cường dữ liệu để tạo ra những dữ liệu nhân tạo đại diện hơn và đa dạng hơn. Trong tờ giấy này, chúng tôi đề xuất một phương pháp gia tăng dữ liệu mới mà hoàn toàn cân nhắc các mô hình sai lầm thực sự và kiến thức ngôn ngữ cho nhiệm vụ GED. Chúng tôi tiến hành nhiều thí nghiệm về hệ thống dữ liệu công cộng và kết quả thử nghiệm cho thấy phương pháp của chúng tôi hoàn thành nhiều bản nền vững chắc hơn nhiều thông tin về văn bản không được dán kín bên ngoài, nhấn mạnh hiệu quả phi thường của nó trong công việc trí trí trí tuệ thiếu các dữ liệu huấn luyện trên quy mô lớn.', 'bg': 'Увеличаването на данните има за цел да разшири данните за обучение с чист текст, използвайки шумови схеми за подобряване на ефективността на граматическата корекция на грешки (ГЕК). На практика има голям брой реални модели на грешки в ръчно анотираните данни за обучение. Ние твърдим, че тези реални модели на грешки могат да бъдат въведени в чист текст, за да се генерират ефективно по-реални и висококачествени синтетични данни, които не са напълно проучени от предишни проучвания. Освен това откриваме, че езиковото знание може да бъде включено в увеличаването на данните за генериране на по-представителни и по-разнообразни синтетични данни. В настоящата статия предлагаме нов метод за увеличаване на данните, който напълно отчита реалните модели на грешки и езиковите познания за задачата. Провеждаме обширни експерименти с обществени набори от данни и експерименталните резултати показват, че методът ни превъзхожда няколко силни базови линии с далеч по-малко външни немаркирани данни за чист текст, подчертавайки изключителната му ефективност в задачата на ГЕК, която не разполага с големи обозначени данни за обучение.', 'da': 'Data augmentation sigter mod at udvide træningsdata med ren tekst ved hjælp af støjeordninger for at forbedre ydeevnen af grammatisk fejlkorrektion (GEC). I praksis er der et stort antal reelle fejlmønstre i de manuelt kommenterede træningsdata. Vi hævder, at disse reelle fejlmønstre kan indføres i ren tekst for effektivt at generere mere reelle og syntetiske data af høj kvalitet, som ikke er fuldt udforsket af tidligere undersøgelser. Desuden finder vi også, at sproglig viden kan indarbejdes i dataforøgelse for at generere mere repræsentative og mere forskelligartede syntetiske data. I denne artikel foreslår vi en ny dataaugmentationsmetode, der fuldt ud tager hensyn til de reelle fejlmønstre og den sproglige viden til GEC-opgaven. Vi gennemfører omfattende eksperimenter på offentlige datasæt, og de eksperimentelle resultater viser, at vores metode overgår flere stærke baselines med langt mindre eksterne mærkede clean text data, hvilket fremhæver dens ekstraordinære effektivitet i GEC-opgaven, der mangler store mærkede træningsdata.', 'hr': 'Povećavanje podataka je cilj proširenja podataka o obuci čistom tekstu koristeći šeme buke kako bi se poboljšala učinkovitost isprave gramatičkih grešaka (GEC). U praksi postoji veliki broj pravih pogrešnih obrazaca u podacima o ručno označenim obuku. Tvrdimo da se ovi pravi pogrešni obrasce mogu uvesti u čist tekst kako bi učinkovito stvorili realnije i visoke kvalitetne sintetičke podatke, koje se ne potpuno istražuju prethodnim ispitivanjima. Osim toga, također smatramo da se jezičko znanje može uključiti u povećanje podataka za stvaranje više predstavnika i raznolikosti sintetičkih podataka. U ovom papiru predlažemo novu metodu povećanja podataka koja potpuno smatra pravim pogrešnim obrazacima i jezičkim znanjem za zadatak GEC-a. Provodimo široke eksperimente na javnim podacima i eksperimentalnim rezultatima pokazuju da naš metod iznosi nekoliko jakih osnovnih linija s mnogo manjim vanjskim podacima o čistom tekstu, naglašavajući svoju izvanrednu učinkovitost u zadatku GEC-a koji nedostaje velike označene podatke o obuci.', 'nl': "Data augmentation is bedoeld om trainingsgegevens uit te breiden met schone tekst met behulp van ruisschema's om de prestaties van grammatical error correction (GEC) te verbeteren. In de praktijk zijn er een groot aantal echte foutpatronen in de handmatig geannoteerde trainingsgegevens. We argumenteren dat deze echte foutpatronen kunnen worden geïntroduceerd in schone tekst om effectief meer echte en hoogwaardige synthetische gegevens te genereren, die niet volledig is onderzocht door eerdere studies. Bovendien vinden we ook dat taalkennis kan worden opgenomen in data augmentation om representatievere en diversere synthetische data te genereren. In dit artikel stellen we een nieuwe data augmentation methode voor die volledig rekening houdt met de werkelijke foutpatronen en de taalkennis voor de GEC taak. We voeren uitgebreide experimenten uit met publieke datasets en de experimentele resultaten tonen aan dat onze methode meerdere sterke baselines overtreft met veel minder externe onbevoegde clean text data, wat de buitengewone effectiviteit benadrukt in de GEC-taak die ontbreekt aan grootschalige gelabelde trainingsgegevens.", 'de': 'Ziel der Datenerweiterung ist die Erweiterung von Trainingsdaten mit sauberem Text mithilfe von Rauschschemata, um die Leistung der grammatischen Fehlerkorrektur (GEC) zu verbessern. In der Praxis gibt es eine Vielzahl realer Fehlermuster in den manuell kommentierten Trainingsdaten. Wir argumentieren, dass diese realen Fehlermuster in sauberen Text eingeführt werden können, um effektiver realere und qualitativ hochwertige synthetische Daten zu generieren, die in früheren Studien nicht vollständig erforscht wurden. Darüber hinaus stellen wir fest, dass linguistisches Wissen in die Datenaugmentation einfließen kann, um repräsentativere und vielfältigere synthetische Daten zu generieren. In diesem Beitrag schlagen wir eine neuartige Methode zur Datenauswertung vor, die die realen Fehlermuster und das sprachliche Wissen für die GEC-Aufgabe vollständig berücksichtigt. Wir führen umfangreiche Experimente an öffentlichen Datensätzen durch und die experimentellen Ergebnisse zeigen, dass unsere Methode mehrere starke Baselines mit weit weniger externen, nicht beschrifteten Reintextdaten übertrifft, was ihre außerordentliche Effektivität in der GEC-Aufgabe unterstreicht, bei der es an großflächig markierten Trainingsdaten mangelt.', 'id': 'Peningkatan data bermaksud memperluas data pelatihan dengan teks bersih menggunakan skema suara untuk meningkatkan prestasi koreksi kesalahan gramatik (GEC). Dalam praktek, ada banyak pola kesalahan nyata dalam data latihan yang dicatat secara manual. Kami berdebat bahwa pola kesalahan nyata ini dapat diperkenalkan ke dalam teks bersih untuk secara efektif menghasilkan data sintetik yang lebih nyata dan kualitas tinggi, yang tidak sepenuhnya dieksplorasi oleh studi sebelumnya. Selain itu, kami juga menemukan bahwa pengetahuan bahasa dapat dimasukkan ke dalam peningkatan data untuk menghasilkan data sintetik yang lebih mewakili dan lebih berbeda. Dalam kertas ini, kami mengusulkan metode peningkatan data baru yang mempertimbangkan pola kesalahan yang sebenarnya dan pengetahuan bahasa untuk tugas GEC. Kami melakukan eksperimen ekstensif pada set data publik dan hasil eksperimen menunjukkan bahwa metode kami melampaui beberapa garis dasar yang kuat dengan data teks bersih yang jauh kurang luar tanpa label, menandakan efektifitas luar biasa dalam tugas GEC yang kekurangan data pelatihan yang disebut skala besar.', 'ko': '데이터 확충의 목적은 소음 제거 방안을 사용하여 깨끗한 텍스트의 훈련 데이터를 확장하여 문법 오류 수정(GEC)의 성능을 향상시키는 것이다.실천 과정에서 인공적으로 표시된 훈련 데이터에는 대량의 진실한 오류 패턴이 존재한다.우리는 이러한 진실한 오류 모델이 깨끗한 텍스트에 도입되어 더욱 진실하고 질 좋은 합성 데이터를 효과적으로 생성할 수 있다고 생각한다. 이것은 이전의 연구에서 충분히 연구하지 못한 것이다.그 밖에 더욱 대표적이고 다양한 합성 데이터를 생성하기 위해 언어 지식을 데이터 확충에 포함시킬 수 있다는 것을 발견했다.본고에서 우리는 GEC 임무의 진실한 오류 모델과 언어 지식을 충분히 고려한 새로운 데이터 확충 방법을 제시했다.우리는 공공 데이터 집합에서 대량의 실험을 실시했는데, 실험 결과에 의하면, 우리의 방법은 외부에 깨끗한 텍스트 데이터가 많이 표시되지 않은 상황에서 몇 개의 강력한 기선보다 우수하고, 대규모 표기 훈련 데이터가 부족한 GEC 임무에서의 비범한 유효성을 두드러지게 했다.', 'fa': 'افزایش داده\u200cها هدف دارند که اطلاعات آموزش با متن پاکیزه با استفاده از برنامه\u200cهای صوتی برای افزایش فعالیت اصلاح خطای گراماتیک (GEC) را گسترش دهند. در تمرین، تعداد زیادی از الگوهای خطای واقعی در داده های آموزش را به دست نشان داده شده وجود دارد. ما بحث می\u200cکنیم که این الگوهای خطای واقعی می\u200cتوانند به متن پاکیزه وارد شوند تا به طور موثر اطلاعات سینتاتیک واقعی و کیفیت بالاتر را تولید کند، که توسط تحقیقات قبلی کاملاً تحقیق نمی\u200cشود. علاوه بر این، ما همچنین یافتیم که دانش زبان\u200cشناسی می\u200cتواند در افزایش داده\u200cها برای تولید داده\u200cهای نماینده\u200cتری و متفاوت\u200cتری از اطلاعات\u200cشناسی شامل شود. در این کاغذ، ما یک روش افزایش داده\u200cهای نوی پیشنهاد می\u200cکنیم که الگوهای واقعی خطا و دانش زبان\u200cشناسی برای کار GEC را کاملاً به نظر می\u200cرسد. ما آزمایش های زیادی روی مجموعه داده های عمومی انجام می دهیم و نتیجه آزمایشی نشان می دهند که روش ما چند خط بنیادی قوی با داده های متن پاک پاک خارجی بیشتر از حد کمتر استفاده می کند، و فعالیت غیرعادی خود را در کار GEC که داده های آموزشی بسیار زیادی را لازم دارد، تخ', 'tr': 'Maglumat ýetişirmeginiň amasyny gramatik hatalaryň täzeliklerini ýüzeltmek üçin sag metin bilen okuw maglumatyny açmak üçin hedeflenýär. praktika görä, el duýgulanan okuwçylyk maglumatynda gaty köp hata nusgalar bar. Biz bu hakyky hata örneklerini temiz metin içine girebilir ki, önceki araştırmalar tarafından tam olarak keşfedilmedik şekilde düzgün ve yüksek kalitede syntetik verileri oluşturabiler. Munuň üçin, biz ýene-de lingwistiki bilgileri daýary üýtgetmek üçin daýary üýtgedip bileris. Bu kagyzda, biz GEC işi üçin dogry hata şartlaryny we dil bilgilerini doly düşünýän bir roman maglumat yöntemi teklip edýäris. Biz halk maglumat setirlerinde örän köp deneyler edýäris we deneyler netijesinde biziň metodamyz birnäçe güýçli baseliniň daşary daşary ýazman metin maglumatyny ýok edip, GEC buýrukynda gaty täsirli etkinlik etkinleşigini ýagtylaýar we uly ölçekli etiket edilen eğitim maglumatynyň ýetme', 'sw': 'Kuongezeka kwa taarifa inakusudia kuongeza taarifa za mafunzo kwa kutumia ujumbe safi kwa kutumia mipango ya sauti ili kuboresha ufanisi wa uharibifu wa makosa ya kigrammatika (GEC). Katika mazoea, kuna namna nyingi za makosa halisi katika taarifa za mafunzo yanayokerwa kwa mikononi. Tunahoji kuwa miundo haya ya makosa yanaweza kutambulishwa katika maandishi safi ili kutengeneza takwimu za ukweli na za kiwango kikubwa zaidi, ambazo hazijunguzwa vizuri na tafiti zilizopita. Zaidi, tunagundua pia kuwa maarifa ya lugha inaweza kuingizwa katika ongezeko la data kwa ajili ya kutengeneza mwakilishi zaidi na data tofauti za pamoja. Katika gazeti hili, tunapendekeza njia ya kuongeza taarifa za riwaya ambazo hufikiria miundo halisi ya makosa na maarifa ya lugha kwa kazi ya GEC. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.', 'sq': 'Rritja e të dhënave synon të zgjerojë të dhënat e trainimit me tekst të pastër duke përdorur skema zhurmuese për të përmirësuar performancën e korrektimit të gabimeve grammatike (GEC). Në praktikë, ka një numër të madh modelesh gabimi të vërtetë në të dhënat e stërvitjes të anotuara manualisht. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies.  Përveç kësaj, gjejmë gjithashtu se njohuria gjuhësore mund të përfshihet në rritjen e të dhënave për krijimin e të dhënave më përfaqësuese dhe më të ndryshme sintetike. Në këtë letër, propozojmë një metodë të re shtimi të të dhënave që konsideron plotësisht modelet e gabimeve reale dhe njohuritë gjuhësore për detyrën e GEC. Ne kryejmë eksperimente të gjerë në grupet e të dhënave publike dhe rezultatet eksperimentale tregojnë se metoda jonë mbizotëron disa linja bazë të forta me shumë më pak të dhëna të jashtme teksti të pastër pa etiketë, duke theksuar efektshmërinë e saj të jashtëzakonshme në detyrën e GEC që mungon të dhëna të trajnimit të etiketuar në shkallë të madhe.', 'am': 'የዳታ ማጠቃለያ የስህተት ተሳካሚ ስህተት ማድረግ አቅራቢያ (GEC) በመጠቀም የድምፅ ፕሮግራሙን በመጠቀም የድምፅ ጽሑፍ ማሰናከል ነው፡፡ በተግባር፣ የእውነቱ ስህተት ዓይነቶች እጆቹ በሚያስተማሩ ዳታዎች ብዙ ናቸው፡፡ ይህ እውነተኛ ስህተት ዓይነቶች ንጹሕ ጽሑፎችን ለመግለጽ እና በጥሩ እና ከፍተኛ እና ከፍተኛ የስንተርናዊ ዳታዎችን ለመፍጠር ይችላል፡፡ ደግሞም የቋንቋው እውቀት ደግሞ አብዛኛውን አካባቢ እና የበለጠ ልዩ ልዩ የስንቲካዊ ዳታዎችን ለመፍጠር ወደ ዳታ ማድረግ እንዲሰበስብ እናገኛለን፡፡ በዚህ ፕሮግራም፣ የእውነቱን የስህተት ዓይነቶች እና የቋንቋዊው እውቀት ለGEC ስራ የሚያስፈልገውን የመረጃ ዳታ አካባቢ ማድረግ እናሳልቃለን፡፡ የህዝባዊ ዳታዎችን ማሳየት እናደርጋለን፡፡', 'af': "Data vergroot doel om onderwerp data met skoon teks te uitbrei deur gebruik van ruigskemas om die prestasie van grammatiese fout korreksie (GEC) te verbeter. In praksie is daar 'n groot aantal werklike fout patrone in die handmatig opvoer data. Ons argumenteer dat hierdie regte foutpatrene in skoon teks ingevoer kan word om effektief meer regte en hoë kwaliteit sintetiese data te genereer, wat nie volledig deur vorige studie ondersoek word nie. Ook, ons vind ook dat lingwisiese kennis kan ingesluit word in data augmentasie vir die genereering van meer reprezentante en meer verskillende sintetiese data. In hierdie papier, voorstel ons 'n nuwe data augmentasie metode wat volledig die regte foutpatrene en die lingwisiese kennis vir die GEC taak aanneem. Ons doen uitbreidige eksperimente op publieke data stelle en die eksperimentele resultate wys dat ons metode verskeie sterke basisline uitvoer met veel minder eksterne ongeabelde skoon teks data, verlig sy uitbreidige effektiviteit in die GEC taak wat nie groot-skaal etiketeerde onderwerp data is nie.", 'hy': 'Տվյալների աճը նպատակում է աճել կրթության տվյալները մաքուր տեքստով օգտագործելով ձայնային ծրագրեր, որպեսզի բարելավեն գրամատիկական սխալների ուղղությունը: Փաստորեն, ձեռքով նկարագրված ուսումնասիրության տվյալների մեծ քանակությամբ սխալներ կան: Մենք փաստարկում ենք, որ այս իրական սխալների կաղապարները կարող են ներդրվել մաքուր տեքստի մեջ, որպեսզի արդյունավետ ստեղծեն ավելի իրական և բարձր որակի սինթետիկ տվյալներ, որոնք նախորդ ուսումնասիրություններում ամբողջովին չեն Ավելին, մենք նաև հայտնաբերում ենք, որ լեզվաբանական գիտելիքները կարող են ներգրավվել տվյալների աճի մեջ ավելի ներկայացուցիչ և ավելի բազմազան սինթետիկ տվյալներ ստեղծելու համար: Այս թղթի մեջ մենք առաջարկում ենք նոր տվյալների բարձրացման մեթոդ, որը լիովին հաշվի է առնում իրական սխալների կաղապարները և լեզվաբանական գիտելիքները, որոնք կատարվում են ԳԵԿ-ի առաջադրանքի համար: Մենք կատարում ենք բազմազան փորձարկումներ հանրային տվյալների համակարգերի վրա, և փորձարկման արդյունքները ցույց են տալիս, որ մեր մեթոդը գերազանցում է որոշ ուժեղ հիմնական գծեր, որոնք շատ ավելի քիչ արտաքին առանց սպիտակ մաքուր տեքստի տվյալներ ունեն, և նշել է', 'az': 'Məlumat artırması təhsil məlumatları təhsil məlumatları ilə təhsil məlumatlarını genişləmək məqsədilə, grammatik xəta düzəltməsini yaxşılaşdırmaq üçün səs schemlarını istifadə edir. Əlavədə, əlli təhsil məlumatlarında çox haqq xəta örtükləri var. Biz mübahisə edirik ki, bu həqiqət xəta modellərinin təmiz metinə daxil oluna bilər ki, daha çox həqiqət və yüksək kaliteli sintetik məlumatları yaratmaq üçün, əvvəlki təhsil ilə tamamilə keşfedilməz. Daha da, dil bilgi daha çox reprezentativ və daha müxtəlif sintetik məlumatları yaratmaq üçün məlumatların artırmasına qatılabilir. Bu kağızda, GEC işinin həqiqət xəta şartlarını və dil bilgisini tamamilə düşünən yeni məlumatları artırma metodlarını təklif edirik. Biz halkı məlumat qurğuları ilə geniş təcrübələr etdik və təcrübə sonuçları göstərdik ki, metodumuzun çox qüvvətli təcrübə səhifələrindən çox az təmiz məlumat məlumatları ilə istifadə edir, böyük ölçüdə etiket edilmiş təcrübə məlumatları yoxdur GEC işində təcrübə etkin', 'bn': 'Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of grammatical error correction (GEC).  প্রশিক্ষণের তথ্যে অনেক বাস্তব সমস্যার প্যাটারেন্ট রয়েছে। আমরা যুক্তি দিচ্ছি যে পূর্ববর্তী গবেষণার দ্বারা পুরোপুরি তথ্য তৈরি করা যায় না। এছাড়াও আমরা খুঁজে পাচ্ছি যে ভাষাগত জ্ঞানের সাথে তথ্য যোগাযোগ করা যাবে আরো প্রতিনিধি এবং বিভিন্ন ভিন্ন সিন্টেটিক ডাটা  এই কাগজটিতে আমরা একটি নোভেল ডাটা যোগাযোগ মাধ্যমে প্রস্তাব করি যা পুরোপুরি ভুল প্যাটার এবং জেসির কাজের ভাষাগত জ্ঞান সম্পর্কে  আমরা জনগণের তথ্য সেটে বিস্তারিত পরীক্ষা করি এবং পরীক্ষার ফলাফল দেখাচ্ছি যে আমাদের পদ্ধতি বেশ কয়েকটি শক্তিশালী বেসাইনের প্রযুক্তি প্রদর্শন করে যার ফলে বাইরের পরিষ্কারের তথ্', 'cs': 'Cílem rozšíření dat je rozšíření tréninkových dat o čistý text pomocí šumových schémat pro zlepšení výkonnosti gramatické korekce chyb (GEC). V praxi existuje velké množství skutečných chybových vzorů v ručně anotovaných tréninkových datech. Tvrdíme, že tyto skutečné chybové vzorce lze zavést do čistého textu a efektivně generovat reálnější a vysoce kvalitní syntetická data, která nejsou plně zkoumána v předchozích studiích. Kromě toho zjišťujeme, že jazykové znalosti mohou být začleněny do rozšíření dat pro generování reprezentativnějších a rozmanitějších syntetických dat. V tomto článku navrhujeme novou metodu rozšíření dat, která plně zohledňuje reálné chybové vzorce a jazykové znalosti pro úlohu GEC. Provádíme rozsáhlé experimenty na veřejných datových sadách a experimentální výsledky ukazují, že naše metoda překonává několik silných základních linií s mnohem méně externími neoznačenými čistými textovými daty, což zdůrazňuje její mimořádnou efektivitu v úkolu GEC, který postrádá rozsáhlá označená tréninková data.', 'ca': "L'augment de les dades té l'objectiu d'ampliar les dades d'entrenament amb text net utilitzant esquemes ruidosos per millorar el rendiment de la correcció d'errors gramàtics (GEC). En la pràctica hi ha un gran nombre de patrons d'errors reals en les dades d'entrenament anotats manualment. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies.  També descobrim que el coneixement lingüístic pot ser incorporat en el augment de les dades per a generar dades sintètiques més representatives i diversificades. En aquest paper, proposem un mètode nou d'augmentació de dades que consideri plenament els patrons d'errors reals i el coneixement lingüístic de la tasca GEC. Fem experiments extensos en conjunts de dades públices i els resultats experimentals mostren que el nostre mètode supera diverses línies de base fortes amb molt menys dades externes de text net sense etiqueta, destacant la seva extraordinaria eficacia en la tasca GEC que no té dades de formació etiquetades a gran escala.", 'bs': 'Povećavanje podataka je cilj proširenja podataka o obuci čistom tekstu koristeći šeme buke kako bi poboljšala učinkovitost isprave gramatičkih grešaka (GEC). U praksi postoji veliki broj pravih pogrešnih obrazaca u podacima o ručno annotiranju obuke. Tvrdimo da se ovi pravi obrasci greške mogu uvesti u čist tekst kako bi efikasno stvorili realnije i visoke kvalitetne sintetičke podatke, koje se ne potpuno istražuju prethodnim ispitivanjima. Osim toga, također smatramo da se jezičko znanje može uključiti u povećanje podataka za stvaranje više predstavnika i raznolikosti sintetičkih podataka. U ovom papiru predlažemo novu metodu povećanja podataka koja potpuno smatra pravim greškama i jezičkim znanjem za zadatak GEC-a. Provodimo široke eksperimente na javnim setima podataka i eksperimentalni rezultati pokazuju da naš metod iznosi nekoliko jakih osnovnih linija sa mnogo manjim vanjskim podacima o čistom tekstu, naglašavajući svoju izvanrednu učinkovitost u zadatku GEC-a koji nedostaje velike označene podatke o obuci.', 'et': 'Andmete suurendamise eesmärk on laiendada koolitusandmeid puhta tekstiga, kasutades mürakavasid grammatilise veaparanduse (GEC) tulemuslikkuse parandamiseks. Praktikas on käsitsi märgitud koolitusandmetes palju tõelisi veamustreid. Väidame, et neid tõelisi veamustreid saab kasutada puhtasse tekstisse, et tõhusalt luua reaalsemaid ja kvaliteetsemaid sünteetilisi andmeid, mida varasemates uuringutes ei ole täielikult uuritud. Lisaks leiame, et keeleteadmisi saab lisada andmete suurendamisse, et luua representatiivsemaid ja mitmekesisemaid sünteetilisi andmeid. Käesolevas töös pakume välja uudse andmete suurendamise meetodi, mis võtab täielikult arvesse tegelikke veamustreid ja keeleoskusi GEC ülesande jaoks. Me teeme laiaulatuslikke katseid avalike andmekogumitega ja eksperimentaalsed tulemused näitavad, et meie meetod ületab mitmeid tugevaid lähtejooni palju vähem väliseid märgistamata puhta teksti andmeid, rõhutades selle erakordset efektiivsust GEC ülesandes, millel puuduvad suuremahulised märgistatud koolitusandmed.', 'fi': 'Tiedon lisäämisellä pyritään laajentamaan koulutusdataa puhtaalla tekstillä käyttämällä melujärjestelmiä kieliopillisen virhekorjauksen (GEC) suorituskyvyn parantamiseksi. Käytännössä manuaalisesti merkityissä harjoitustiedoissa on suuri määrä todellisia virhekuvioita. Väitämme, että nämä todelliset virhemallit voidaan sisällyttää puhtaaseen tekstiin, jotta saadaan tehokkaasti todellisempaa ja korkealaatuisempaa synteettistä tietoa, jota aikaisemmissa tutkimuksissa ei ole täysin tutkittu. Lisäksi havaitsemme, että kielitaito voidaan sisällyttää datan lisäämiseen edustavamman ja monipuolisemman synteettisen datan tuottamiseksi. Tässä työssä ehdotamme uutta datan lisäämismenetelmää, jossa otetaan täysin huomioon GEC-tehtävän todelliset virhemallit ja kielitaito. Teemme laajoja kokeita julkisilla tietoaineistoilla ja kokeelliset tulokset osoittavat, että menetelmämme suoriutuu useita vahvoja perusviivoja huomattavasti vähemmän ulkoisella merkitsemättömällä puhtaalla tekstitiedolla, mikä korostaa sen poikkeuksellista tehokkuutta GEC-tehtävässä, jossa ei ole laajamittaista merkittyä koulutustietoa.', 'he': 'שיפור נתונים מכוון להרחיב נתוני אימון עם טקסט נקי באמצעות תכניות רעשות כדי לשפר את ההפעלה של תיקון שגיאות גרמטית (GEC). למעשה, יש מספר גדול של דפוסי שגיאות אמיתיות במידע האימונים המכתב יד. אנחנו טוענים שדפוסי טעויות אמיתיות האלה יכולים להציג לטקסט נקי כדי ליצור בעצם נתונים סינטטיים אמיתיים ואיכויים גבוהים יותר, שלא ניחוש במלוא על ידי מחקרים קודמים. חוץ מזה, אנו מוצאים גם שידע שפתי יכול להיות מעורב בתרבות נתונים כדי ליצור נתונים סינטטיים יותר מייצגים ומגווונים יותר. בעיתון הזה, אנו מציעים שיטת גידול נתונים חדשה שמשקלת לחלוטין את דפוסי הטעות האמיתיים והידע השפתי למשימה של GEC. אנו מבצעים ניסויים רחבים על קבוצות נתונים ציבוריים והתוצאות הניסיוניים מראות שהשיטה שלנו עולה מעל מספר קווי בסיס חזקים עם נתונים טקסט נקיים בלתי חוץ הרבה פחות ללא סימנים, ומדגישים את היעילות המיוחדת שלה במשימה של GEC שאין נתונים אימונים גדולים.', 'sk': 'Cilj povečanja podatkov je razširitev podatkov o usposabljanju s čistim besedilom z uporabo shem hrupa za izboljšanje učinkovitosti slovničnega popravka napak (GEC). V praksi obstaja veliko resničnih vzorcev napak v ročno označenih podatkih o usposabljanju. Trdimo, da je mogoče te vzorce resničnih napak vnesti v čisto besedilo, da bi učinkovito ustvarili resničnejše in kakovostnejše sintetične podatke, ki jih prejšnje študije niso v celoti raziskale. Poleg tega ugotavljamo, da je jezikovno znanje mogoče vključiti v povečanje podatkov za ustvarjanje bolj reprezentativnih in raznolikih sintetičnih podatkov. V prispevku predlagamo novo metodo povečanja podatkov, ki v celoti upošteva vzorce resničnih napak in jezikovno znanje za nalogo GEC. Izvajamo obsežne eksperimente na javnih naborih podatkov, rezultati eksperimentov pa kažejo, da naša metoda presega več močnih osnovnih črt z veliko manj zunanjimi neoznačenimi čistimi besedilnimi podatki, kar poudarja njeno izjemno učinkovitost pri nalogi GEC, ki nima obsežnih označenih podatkov o usposabljanju.', 'ha': "Ƙaraɗawa na danne na aimi ya ƙãra data na amfani da matsayin mai tsari, da amfani da ruwan sauti dõmin ya gyara aikin kure na grammati (GEC). In practice, there are a great number of real error patterns in the manually annotated training data.  Munã jãyayya cẽwa, za'a iya introduce waɗannan shiryoyin ɓata cikin matsayin mai tsari dõmin a ƙiƙiro wasu data masu gaske da baƙaƙo tsari, da kuma ba za'a cikakke su ba da gamuwa. Furan haka, munã gane cewa ilimi na lugha za'a shigar da shi a cikin ƙaramako ga data dõmin ya sami wasu wakin da wasu daban-daban na haɗi. Ga wannan takardan, Munã buɗa wata hanyor ƙaramako da data na nowaya wanda ke cikakken ka ƙayyade tsarin ɓata da kuma sanin linguistic wa aikin GEC. Munã aikin jarrabãwa masu yawa a kan daidaita data na jamii, kuma matsalatan jarrabai yana nũna cewa hanyoyinmu yana samar da wasu masu ƙarfi, da data masu ƙaranci da ba'a rubutu da tsari ba'a rubutu ba, na nuna fasarinta mai girma a cikin aikin GEC wanda bã ya da data mai amfani da shi mai girma.", 'jv': 'Go Genjer-Genjer Awak dhéwé éntuk barêng-barêng sing nyimpen kelangan kelangan iki dadi sing katêpakan karo text sing basa gambar gak dhéwé, dadi sing paling dhéwé kuwi sistem sing gak dhéwé, sing ora bisa ngesiku akeh perusahaan seneng pisan dumadhi. Nambah, awak dhéwé ngerasakno karo akeh akeh ingkang dipun-akeh liyane sak nguasakno ning awak dhéwé nggawe akeh basa luwih-luwih lan uga luwih-luwih liyane Nang pepulan iki, kita supoyo sistem anyir dadi ampungan kuwi nggawe barang kelas kang alam sing nyimpen eror lan alam nggawe barang kelas kanggo nggawe GEC task. Awak dhéwé éntuk éntuk sistem sing gak perusahaan dengané dadi nggunaké Publik lan dadi sing paling nggawe barang dhéwé, dadi sing paling dhéwé, gak dhéwé nggawe barang langgar-sistem sing paling dhéwé, winih ngono perusahaan langgar-sistem sing gak nggawe dadi GEC sing ora bisa perusahaan barang lang', 'bo': 'དམིགས་ཡུལ་ནི་ཚོར་ཆེ་བསྐྱེད་པའི་བརྩལ་སྒྲིག་ཆ་འཕྲིན་ཡིག་གི་ནང་དུ་དམིགས་ཡུལ ལག་སྟར་བྱེད་སྐབས་ནོར་འཁྲུལ་གྱི་གཟུགས་རིས་མང་པོ་ཡོད་པ་ནི་ལག་བཟོས་སྦྱོར་བྱེད་ཀྱི་ཡོད་པ་རེད། We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. ད་དུང་། ང་ཚོས་སྐད་རིགས་ཤེས་ཀྱི་ཆ་འཕྲིན་ཡིག་ཆ་གསལ་བཙུགས་ཏེ། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་གསར་འགུལ་གྱི་ཆ་འཕྲིན་ཡིག་ཆ་སྐྱེན་བཟོ་བྱེད་ཀྱི་ཐབས་ལམ་ཞིག་སྟོན་ཡོད། We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.'}
{'en': 'A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs', 'ar': 'معيار متعدد اللغات للتحقق من الوعي بالنفي بأدنى حد من الأزواج', 'pt': 'Um benchmark multilíngue para sondar a consciência de negação com pares mínimos', 'fr': 'Une référence multilingue pour sonder la conscience de la négation avec des paires minimales', 'es': 'Un punto de referencia multilingüe para sondear la conciencia de negación con pares mínimos', 'ja': '最小限のペアで否定的な認識を探るための多言語ベンチマーク', 'zh': '以至小对探测否定感知的多言语基准', 'hi': 'न्यूनतम जोड़े के साथ नकारात्मक-जागरूकता की जांच के लिए एक बहुभाषी बेंचमार्क', 'ru': 'Многоязычный эталон для определения отрицательного восприятия с минимальными парами', 'ga': 'Tagarmharc Ilteangach chun Diúltú a Fhíorú - Feasacht le Péirí Íosta', 'ka': 'Name', 'el': 'Ένας πολύγλωσσος δείκτης αναφοράς για τον έλεγχο της άρνησης-ευαισθητοποίησης με ελάχιστα ζευγάρια', 'hu': 'Többnyelvű referenciaérték a negatív tudatosság vizsgálatára minimális párokkal', 'it': 'Un benchmark multilingue per sondare la consapevolezza della negazione con coppie minime', 'kk': 'Көп тілдік бенхемарк минималдық жұмыс туралы терістеу- теңілдемесін тексеру үшін', 'lt': 'Daugiakalbis orientacinis rodiklis, skirtas neigiamo sąmoningumo su mažiausiomis poromis tikrinimui', 'mk': 'Мултијазичен спореден знак за проверка на свесност за негативноста со минимални парови', 'ms': 'A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs', 'mt': 'Punt ta’ riferiment multilingwi għall-prova tal-għarfien tan-Negozju ma’ Pawġi Minimi', 'ml': 'ചെറിയ പേയറുകളോടൊപ്പം മുഴുവന്\u200d ഭാഷ ബെന്\u200dച്മാര്\u200dക്ക്', 'mn': 'Олон хэлний банкемарк нь хамгийн бага хэлбэртэй холбогдолтыг шалгах', 'no': 'Name', 'ro': 'Un criteriu de referință multilingv pentru testarea conștientizării negării cu perechi minime', 'pl': 'Wielojęzyczny wskaźnik odniesienia do badania negatywnej świadomości z minimalnymi parami', 'sr': 'Mnogo jezičkog standarda za ispitivanje svijesti o pregovorima sa minimalnim parema', 'si': 'Name', 'sv': 'Ett flerspråkigt riktmärke för undersökning av negativ medvetenhet med minimala par', 'ta': 'Name', 'so': 'A Benchmark for Probining Neigration-Awareness with Minimal Pairs', 'ur': 'بہت سی زبان سنچم کے لئے کم جوڑوں کے ساتھ ناگواری اور آگاہ کرنے کے لئے', 'uz': 'Name', 'vi': 'Bài tập đa ngôn ngữ cho việc xác định khả năng thao tác', 'bg': 'Многоезичен показател за изследване на осведомеността за отрицанието с минимални двойки', 'hr': 'Većina jezičkih znakova za ispitivanje svijesti o pregovorima s minimalnim parema', 'da': 'Et flersproget benchmark for undersøgelse af negativ bevidsthed med minimale par', 'de': 'Ein mehrsprachiger Benchmark zur Untersuchung von Negationsbewusstsein mit minimalen Paaren', 'ko': '부정의식을 탐지하는 최소한의 다국어 기준으로', 'nl': 'Een meertalige benchmark voor het onderzoeken van negatieve bewustwording met minimale paren', 'fa': 'Name', 'tr': 'Minimal Pairs bilen gözlemek-tanyş testi üçin köp dilli seleňçi', 'af': 'Name', 'sw': 'Bendera ya lugha nyingi kwa ajili ya Kujaribu Kufahamika kwa Ushirikiano wa Kuhusu', 'id': 'A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs', 'sq': 'Një shenjë referimi shumëgjuhës për provimin e ndërgjegjësimit të negativës me çifte minimale', 'az': 'Dərgahlıq-xəbərdarlığı sınamaq üçün çoxlu dilli Benchmark', 'bs': 'Većina jezičkih standarda za ispitivanje svijesti o pregovorima s minimalnim parema', 'hy': 'A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs', 'am': 'የቋንቋ ቋንቋዎች የውይይት-ማስታወቂያ እና ትንሽ ሽፋዎች ጋር', 'et': 'Mitmekeelne võrdlusnäitaja negatiivsuse uurimiseks minimaalsete paaridega', 'ca': 'Un punt de referència multilingüe per provar consciència negativa amb parelles mínimas', 'cs': 'Vícejazyčný benchmark pro zkoumání negativního povědomí s minimálními páry', 'bn': 'নেতৃত্ব-সচেতনতার জন্য একটি মাল্টিভাষার বেঞ্চার্কName', 'fi': 'Monikielinen vertailuarvo negatiivisuuden mittaamiseen pienillä pareilla', 'jv': 'A Multilanguage Bench for Test Neration-Awakeness with minimal Pars', 'ha': 'KCharselect unicode block name', 'he': 'סימן מיוחד לשפה לאבחן מודעות לשלום עם זוגות מינימיים', 'sk': 'Večjezična merila za merjenje ozaveščenosti o zanikanju z minimalnimi pari', 'bo': 'A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs'}
{'en': 'Negation is one of the most fundamental concepts in human cognition and language, and several natural language inference (NLI) probes have been designed to investigate pretrained language models’ ability to detect and reason with  negation . However, the existing probing datasets are limited to English only, and do not enable controlled probing of performance in the absence or presence of  negation . In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation. We use the benchmark to probe the negation-awareness of multilingual language models and find that models that correctly predict examples with negation cues, often fail to correctly predict their counter-examples without negation cues, even when the cues are irrelevant for semantic inference.', 'pt': 'A negação é um dos conceitos mais fundamentais na cognição e linguagem humana, e várias sondas de inferência de linguagem natural (NLI) foram projetadas para investigar a capacidade de modelos de linguagem pré-treinados de detectar e raciocinar com negação. No entanto, os conjuntos de dados de sondagem existentes são limitados apenas ao inglês e não permitem sondagem controlada de desempenho na ausência ou presença de negação. Em resposta, apresentamos uma coleção de referência multilíngue (inglês, búlgaro, alemão, francês e chinês) de exemplos de NLI gramaticais e corretamente rotulados, como resultado de inspeção manual e reformulação. Usamos o benchmark para sondar a consciência de negação de modelos de linguagem multilíngue e descobrimos que modelos que preveem corretamente exemplos com pistas de negação, muitas vezes falham em prever corretamente seus contra-exemplos sem pistas de negação, mesmo quando as pistas são irrelevantes para inferência semântica.', 'es': 'La negación es uno de los conceptos más fundamentales en la cognición y el lenguaje humanos, y se han diseñado varias sondas de inferencia del lenguaje natural (NLI) para investigar la capacidad de los modelos de lenguaje previamente entrenados para detectar y razonar con la negación. Sin embargo, los conjuntos de datos de sondeo existentes están limitados solo al inglés y no permiten el sondeo controlado del rendimiento en ausencia o presencia de negación. En respuesta, presentamos una colección de referencia multilingüe (inglés, búlgaro, alemán, francés y chino) de ejemplos de NLI gramaticales y correctamente etiquetados, como resultado de la inspección manual y la reformulación. Utilizamos el punto de referencia para investigar la conciencia de negación de los modelos lingüísticos multilingües y descubrimos que los modelos que predicen correctamente ejemplos con señales de negación, a menudo no predicen correctamente sus contraejemplos sin señales de negación, incluso cuando las señales son irrelevantes para la inferencia semántica.', 'ar': 'النفي هو أحد المفاهيم الأساسية في الإدراك البشري واللغة ، وقد تم تصميم العديد من تحقيقات الاستدلال اللغوي الطبيعي (NLI) للتحقيق في قدرة النماذج اللغوية المدربة مسبقًا على الكشف والاستدلال بالنفي. ومع ذلك ، فإن مجموعات بيانات الاستقصاء الحالية مقصورة على اللغة الإنجليزية فقط ، ولا تُمكِّن من مراقبة الأداء في غياب أو وجود النفي. رداً على ذلك ، نقدم مجموعة معايير متعددة اللغات (الإنجليزية والبلغارية والألمانية والفرنسية والصينية) لأمثلة NLI التي تكون نحوية ومعنونة بشكل صحيح ، كنتيجة للفحص اليدوي وإعادة الصياغة. نحن نستخدم المعيار لسبر وعي النفي لنماذج اللغة متعددة اللغات والعثور على أن النماذج التي تتنبأ بشكل صحيح بأمثلة مع إشارات النفي ، غالبًا ما تفشل في التنبؤ بشكل صحيح بأمثلةها المضادة دون إشارات النفي ، حتى عندما تكون الإشارات غير ذات صلة بالاستدلال الدلالي.', 'fr': "La négation est l'un des concepts les plus fondamentaux de la cognition humaine et du langage, et plusieurs sondes d'inférence du langage naturel (NLI) ont été conçues pour étudier la capacité des modèles de langage préentraînés à détecter et à raisonner la négation. Toutefois, les ensembles de données de sondage existants sont limités à l'anglais uniquement et ne permettent pas un contrôle contrôlé des performances en l'absence ou en présence de négation. En réponse, nous présentons une collection de références multilingue (anglais, bulgare, allemand, français et chinois) d'exemples de NLI qui sont grammaticaux et correctement étiquetés, à la suite d'une inspection manuelle et d'une reformulation. Nous utilisons le benchmark pour sonder la sensibilité à la négation des modèles linguistiques multilingues et nous constatons que les modèles qui prédisent correctement les exemples avec des indices de négation échouent souvent à prédire correctement leurs contre-exemples sans indices de négation, même lorsque les indices ne sont pas pertinents pour l'inférence sémantique.", 'zh': '是非人之大略,已设数自然语言推理(NLI)探针以究先训之言模形以否检测推理之能。 然今之探数止于英语,且于无非不支性能之受控。 供一多言(英语,保加利亚语,德语,法语与中文)准试合,NLI示例经语法正标,手动检查和更定之。 吾以准测多言之非意,而见是非之示例,常无以无非测其反例,虽与语义推之不关也。', 'ja': 'ネガティブは、人間の認知と言語における最も基本的な概念の1つであり、いくつかの自然言語推論（ NLI ）プローブは、事前に訓練された言語モデルが否定で検出して推論する能力を調査するように設計されています。ただし、既存のプロービングデータセットは英語のみに限定されており、否定の有無にかかわらず、パフォーマンスの制御されたプロービングを可能にしません。これに対し、私たちは、手動での検査と再策定の結果として、文法的で正しくラベル付けされたNLIの例の多言語（英語、ブルガリア語、ドイツ語、フランス語、中国語）ベンチマークコレクションを提示します。ベンチマークを使用して、多言語モデルの否定認識を調査し、否定の手がかりで例を正しく予測するモデルは、たとえ手がかりが意味的推論に無関係であっても、否定の手がかりなしに反例を正しく予測できないことが多いことを発見します。', 'hi': 'नकारात्मकता मानव अनुभूति और भाषा में सबसे बुनियादी अवधारणाओं में से एक है, और कई प्राकृतिक भाषा अनुमान (एनएलआई) जांच को पूर्व-प्रशिक्षित भाषा मॉडल की नकारात्मकता के साथ पता लगाने और तर्क करने की क्षमता की जांच करने के लिए डिज़ाइन किया गया है। हालांकि, मौजूदा जांच डेटासेट केवल अंग्रेजी तक सीमित हैं, और नकारात्मकता की अनुपस्थिति या उपस्थिति में प्रदर्शन की नियंत्रित जांच को सक्षम नहीं करते हैं। जवाब में, हम एक बहुभाषी (अंग्रेजी, बल्गेरियाई, जर्मन, फ्रेंच और चीनी) एनएलआई उदाहरणों का बेंचमार्क संग्रह प्रस्तुत करते हैं जो मैन्युअल निरीक्षण और पुनर्निर्माण के परिणामस्वरूप व्याकरणिक और सही ढंग से लेबल किए गए हैं। हम बहुभाषी भाषा मॉडल के निषेध-जागरूकता की जांच करने के लिए बेंचमार्क का उपयोग करते हैं और पाते हैं कि मॉडल जो नकारात्मक संकेतों के साथ उदाहरणों की सही भविष्यवाणी करते हैं, अक्सर निषेध संकेतों के बिना अपने काउंटर-उदाहरणों की सही भविष्यवाणी करने में विफल रहते हैं, भले ही संकेत शब्दार्थ अनुमान के लिए अप्रासंगिक हों।', 'ru': 'Отрицание является одной из самых фундаментальных концепций человеческого познания и языка, и несколько зондов вывода естественного языка (NLI) были разработаны для исследования способности предварительно обученных языковых моделей обнаруживать и рассуждать с отрицанием. Тем не менее, существующие наборы данных зондирования ограничены только английским языком и не позволяют осуществлять контролируемое зондирование производительности при отсутствии или наличии отрицания. В ответ мы представляем многоязычную (английский, болгарский, немецкий, французский и китайский языки) подборку примеров NLI, которые являются грамматическими и имеют правильную маркировку в результате ручной проверки и переформулировки. Мы используем эталон, чтобы исследовать отрицание-сознание многоязычных языковых моделей и обнаружить, что модели, которые правильно предсказывают примеры с отрицательными подсказками, часто не могут правильно предсказать свои контр-примеры без отрицательных подсказок, даже когда подсказки не имеют значения для семантического вывода.', 'ga': 'Tá an diúltachas ar cheann de na coincheapa is bunúsaí i gcognaíocht agus i dteanga an duine, agus dearadh roinnt taiscéalaithe tátail nádúrtha teanga (NLI) chun imscrúdú a dhéanamh ar chumas samhlacha teanga réamh-oilte a bhrath agus réasúnaíocht a dhéanamh le faillí. Mar sin féin, tá na tacair sonraí taiscéalaithe atá ann faoi láthair teoranta do Bhéarla amháin, agus ní chumasaíonn siad iniúchadh rialaithe ar fheidhmíocht in éagmais nó i láthair diúltaithe. Mar fhreagra air sin, cuirimid i láthair bailiúchán tagarmharcála ilteangach (Béarla, Bulgáiris, Gearmáinis, Fraincis agus Sínis) de shamplaí LNÉ atá gramadaí agus lipéadaithe i gceart, mar thoradh ar iniúchadh láimhe agus athfhoirmliú. Bainimid úsáid as an tagarmharc chun an fheasacht diúltach ar shamhlacha teanga ilteangacha a fhiosrú agus faighimid amach gur minic go dteipeann ar shamhlacha a dhéanann samplaí a thuar i gceart le leideanna diúltacha a gcuid frithshamplaí a thuar i gceart gan leideanna diúltacha, fiú nuair nach mbaineann na leideanna le hábhar don tátal shéimeantach.', 'ka': 'ნეგრაცია არის ადამიანის კონციონიციაში და ენაში ყველაზე ფუნდამეტური კონციონიციაში და რამდენიმე ნეგრამიური ენათის ინფრენციაში (NLI) პრობენტების განსაზღვრება, რომელიც განსაზღვრებული ენათის მო მაგრამ არსებობს ანგლისურად არსებობს ან არსებობის კონტროლექტის შესახებ. ჩვენ მრავალენგური (ანგლისური, ბულდარიური, გერმანური, ფრანგური და ჩინეთი) NLI მაგალითების კოლექცია, რომლებიც გრამატური და მართლად აღნიშვნელია, რომლებიც მანქანური ინსპექცია და რეფორ ჩვენ გამოვიყენებთ ბენქმარკის გამოყენება, რომ მრავალენგური მადელების ნეგრაცია-ცნობიერება და მოდელები, რომლებიც მართლად გადაწყენებენ ნეგრაციის სიმბოლოებით მაგალითებით, ბევრად არ შეუძლებელია მათი კონტრების მაგალითების გადა', 'el': 'Η άρνηση είναι μια από τις πιο θεμελιώδεις έννοιες στην ανθρώπινη γνώση και γλώσσα, και αρκετοί ανιχνευτές συμπερασμάτων φυσικής γλώσσας έχουν σχεδιαστεί για να διερευνήσουν την ικανότητα των προκαθορισμένων γλωσσικών μοντέλων να ανιχνεύουν και να λογικεύουν με άρνηση. Ωστόσο, τα υπάρχοντα σύνολα δεδομένων ανίχνευσης περιορίζονται μόνο στα αγγλικά και δεν επιτρέπουν την ελεγχόμενη ανίχνευση της απόδοσης ελλείψει ή παρουσία άρνησης. Ως απάντηση, παρουσιάζουμε μια πολύγλωσση (αγγλικά, βουλγαρικά, γερμανικά, γαλλικά και κινέζικα) συλλογή προτύπων αναφοράς που είναι γραμματικά και επισημαίνονται σωστά, ως αποτέλεσμα χειροκίνητης επιθεώρησης και αναδιάρθρωσης. Χρησιμοποιούμε το σημείο αναφοράς για να διερευνήσουμε την άρνηση-επίγνωση των πολύγλωσσων γλωσσικών μοντέλων και διαπιστώνουμε ότι τα μοντέλα που προβλέπουν σωστά παραδείγματα με ενδείξεις άρνησης, συχνά αποτυγχάνουν να προβλέψουν σωστά τα αντίπαραδείγματα τους χωρίς ενδείξεις άρνησης, ακόμα και όταν οι ενδείξεις είναι άσχετες για τη σημασιολογική συμπέρασμα.', 'hu': 'A negatív az emberi megismerés és nyelv egyik legalapvetőbb fogalma, és számos természetes nyelvi következtetés (NLI) szondát úgy terveztek, hogy vizsgálják az előkészített nyelvmodellek képességét a negatív felismerésre és érvelésre. A meglévő vizsgálati adathalmazok azonban csak angol nyelvre korlátozódnak, és nem teszik lehetővé a teljesítmény ellenőrzött vizsgálatát tagadás hiányában vagy jelenlétében. Válaszul egy többnyelvű (angol, bolgár, német, francia és kínai) referenciagyűjteményt mutatunk be, amely nyelvtani és helyesen feliratozott NLI példákat tartalmaz, kézi ellenőrzés és átdolgozás eredményeként. A referenciaértéket arra használjuk, hogy vizsgáljuk a többnyelvű nyelvi modellek negatív-tudatosságát, és megállapítsuk, hogy azok a modellek, amelyek negatív jelekkel jól megjósolják a példákat, gyakran nem tudják megfelelően megjósolni ellenpéldáikat negatív jelek nélkül, még akkor is, ha a jelek irrelevánsak a szemantikai következtetés szempontjából.', 'it': "La negazione è uno dei concetti più fondamentali nella cognizione e nel linguaggio umano, e diverse sonde di inferenza del linguaggio naturale (NLI) sono state progettate per indagare la capacità dei modelli linguistici pre-addestrati di rilevare e ragionare con la negazione. Tuttavia, i set di dati esistenti sono limitati solo all'inglese e non consentono la verifica controllata delle prestazioni in assenza o presenza di negazione. In risposta, presentiamo una raccolta di benchmark multilingue (inglese, bulgaro, tedesco, francese e cinese) di esempi NLI grammaticali e correttamente etichettati, come risultato di ispezione manuale e riformulazione. Usiamo il benchmark per sondare la negazione-consapevolezza dei modelli linguistici multilingue e scopriamo che i modelli che predicono correttamente gli esempi con indizi di negazione, spesso non riescono a prevedere correttamente i loro controesempi senza indizi di negazione, anche quando gli indizi sono irrilevanti per l'inferenza semantica.", 'mk': 'Негативноста е еден од најфундаменталните концепти во човечката когниција и јазик, и неколку природни инференции на јазик (НЛИ) се дизајнирани за истрага на способноста на предобучените јазички модели да детектираат и размислуваат со негативност. Сепак, постојните датотеки за истражување се ограничени само на англиски и не овозможуваат контролирано истражување на резултатите во отсуство или присуство на негативност. In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation.  Ние го користиме benchmark за да ја испитаме негативната свест за мултијазичните јазички модели и да откриеме дека моделите кои правилно предвидуваат примери со негативни знаци, честопати не успеваат да ги предвидат своите контрапримери без негативни знаци, дури и кога знаците се нерелевантни за семантична инференција.', 'lt': 'Negacija yra viena iš svarbiausių žmogaus pažinimo ir kalbos sąvokų, o keli gamtinių kalbų išvadų (NLI) sondai buvo sukurti siekiant ištirti iš anksto mokomų kalbų modelių gebėjimą aptikti ir pagrįsti neigiamu būdu. Tačiau esami sondančių duomenų rinkiniai yra apriboti tik anglų kalba ir neleidžia kontroliuojamo veikimo sondančių duomenų rinkinių, jei jų nėra arba nėra neigiamų. Atsakydami į tai pateiksime daugiakalbį (anglų, bulgarų, vokiečių, prancūzų ir kinų) lyginamąjį NLI pavyzdžių rinkinį, kuris yra gramatinis ir teisingai paženklintas rankiniu patikrinimu ir persvarstymu. Naudojame lyginamąjį rodiklį, kad ištirtume daugiakalbių modelių neigiamą supratimą ir nustatome, kad modeliai, kurie teisingai prognozuoja pavyzdžius su neigiamais ženklais, dažnai neteisingai prognozuoja savo priešingų pavyzdžių be neigiamų ženklų, net jei ženklai nėra svarbūs semantinei išvadai.', 'kk': 'Тексеру - адамдардың білім мен тілдегі ең негізгі концепцияларының бірі, және бірнеше табиғи тілдер инфекциясы (NLI) белгісімен табу мен себептерді табу мүмкіндігін зерттеу үшін құрылған. Бірақ, бар сынақтар деректер жиындары тек ағылшын тіліне шектелмейді, және негізі болмаса, әрекеттерді тексеруді рұқсат етпейді. Жауап беру үшін біз көптеген тілді (ағылшын, Болгария, неміс, француз және қытайша) NLI мысалдарын қолмен тексеру және реформулациялау үшін грамматикалық және дұрыс жарлықты жазылған нәтижелер жинақтап көр Біз көптілік тіл үлгілерінің негизациялық түсініктерін тексеру үшін қолданып, негизациялық белгілерді дұрыс таңдайтын үлгілерді табу үшін, негизациялық белгілерінің негизациялық белгілерінің қарсы мәселелерін дұрыс таңдауға болмайды,', 'ms': 'Negasi adalah salah satu konsep paling dasar dalam pengetahuan dan bahasa manusia, dan beberapa penyelesaian bahasa alam (NLI) telah direka untuk menyelidiki kemampuan model bahasa yang dilatih untuk mengesan dan alasan dengan negatif. Namun, set data penyiasatan yang wujud terhadap bahasa Inggeris sahaja, dan tidak membolehkan penyiasatan penyiasatan prestasi yang dikawal dalam ketiadaan atau kehadiran negatif. Sebagai balasan, kami mempersembahkan koleksi benchmark berbilang bahasa (Bahasa Inggeris, Bulgarian, Jerman, Perancis dan Cina) contoh NLI yang ditabel secara grammatik dan betul, sebagai hasil pemeriksaan manual dan reformulasi. Kami menggunakan tanda referensi untuk menguji kesadaran negatif bagi model bahasa berbilang bahasa dan mencari bahawa model yang benar meramalkan contoh dengan tanda negatif, sering gagal meramalkan contoh-contoh mereka dengan betul tanpa tanda negatif, walaupun tanda-tanda tidak relevan untuk kesimpulan semantik.', 'mt': 'In-negazzjoni hija wieħed mill-kunċetti l-aktar fundamentali fil-konoxximent u l-lingwa umani, u diversi sondi ta’ inferenza lingwistika naturali (NLI) ġew iddisinjati biex jinvestigaw il-ħila tal-mudelli lingwistiċi mħarrġa minn qabel li jidentifikaw u jirriżultaw b’negazzjoni. Madankollu, is-settijiet ta’ dejta eżistenti dwar is-sondaġġ huma limitati għall-Ingliż biss, u ma jippermettux sondaġġ ikkontrollat tal-prestazzjoni fin-nuqqas jew fil-preżenza ta’ negazzjoni. Bħala tweġiba, qed nippreżentaw ġabra ta’ punti ta’ riferiment multilingwi (Ingliż, Bulgaru, Ġermaniż, Franċiż u Ċiniż) ta’ eżempji NLI li huma grammatiċi u ttikkettati korrettament, bħala riżultat ta’ spezzjoni manwali u riformulazzjoni. Aħna nużaw il-punt ta’ riferiment biex niżvelaw l-għarfien tan-negazzjoni tal-mudelli multilingwi u nsibu li mudelli li jipprevedu b’mod korrett eżempji b’sinjali ta’ negazzjoni, spiss jonqsu milli jipprevedu b’mod korrett il-kontro-eżempji tagħhom mingħajr sinjali ta’ negazzjoni, anke meta l-sinjali huma irrelevanti għall-inferenza semantika.', 'ml': 'മനുഷ്യപരിചയപ്പെടുത്തുന്നതിലും ഭാഷയിലും ഏറ്റവും അടിസ്ഥാനപൂര്\u200dണ്ണമായ ആശയങ്ങളില്\u200d നിന്നാണ് നേഗഗേഷന്\u200d. പിന്നെ സ്വാഭാവികമായ ഭാഷയിലെ അപരിഹാരം നിരീക്ഷിക എന്നാലും നിലവിലുള്ള ഡാറ്റാസറ്റുകള്\u200d ഇംഗ്ലീഷിലേക്ക് മാത്രമേ നിയന്ത്രിക്കപ്പെട്ടിരിക്കുന്നുള്ളൂ, പ്രവര്\u200dത്തനങ്ങള പ്രതികരിക്കുന്നതിന് നമ്മള്\u200d ഒരു പല ഭാഷ (ഇംഗ്ലീഷ്, ബുള്\u200dഗേരിയന്\u200d, ജര്\u200dമ്മന്\u200d, ഫ്രെഞ്ച് ചൈനീസ്) ബെന്\u200dച്മാര്\u200dക്ക് ചേര്\u200dക്കുന്നു. കൈയ്യില്\u200d പരിശോധിക്കുന് പല ഭാഷയുടെ മോഡലുകളുടെ നെഗനേഷന്\u200d -വിശ്വാസം തെളിയിക്കാന്\u200d ഞങ്ങള്\u200d ബെന്\u200dച്മാര്\u200dക്ക് ഉപയോഗിക്കുന്നു. പിന്നീട് നെഗനേഷന്\u200d ക്യൂകളുടെ മാതൃകങ്ങള്\u200d ശരിയായി പ്രവചിക്കുന്ന മോ', 'mn': 'Хүмүүсийн мэдлэг болон хэл дээрх хамгийн чухал ойлголтын нэг юм. Мөн олон байгалийн хэл халдвар (NLI) судалгаа нь хамаагүй хэл загварын чадварыг судлах зориулагдсан. Гэхдээ суурилсан судалгааны өгөгдлийн сангууд зөвхөн Англи хэл хязгаарлагддаг. Харин хамаагүй эсвэл хамаагүй байх үед ажиллагааны судалгааг хянах боломжгүй. Хариултын тулд бид олон хэл (Англи, Болгари, Герман, Франц, Хятад) NLI жишээ цуглуулж, гарын шалгалт, шинэчлэлийн үр дүнд грамматик болон зөв нэрлэгдсэн олон жишээг үзүүлнэ. Бид олон хэл загварын эсрэг сэтгэл санааг судалж, сөрөг тэмдэгт жишээ зөв тодорхойлж байгаа загваруудыг зөв тодорхойлж, эсрэг жишээ нь сөрөг тэмдэглэгүйгээр зөв тодорхойлж чадахгүй байдаг.', 'no': 'Negasjon er ein av dei mest grunnleggjande konseptane i menneskelige kognisjon og språk, og fleire naturspråk-infeksjonspråk (NLI) er utvikla for å undersøke evnskapen på språk-modeller for å finna og årsaken med negasjon. Den eksisterande proberingsdatasetta er berre begrenset til engelsk, og ikkje slår på kontrollerte probering av utviklinga når det ikkje finst eller ikkje finst negasjon. I svar presenterer vi eit fleirspråk (engelsk, bulgarsk, tysk, fransk og kinesisk) benchmarksamling av NLI-eksemplar som er grammatisk og rett merket som resultat av manuelt inspeksjon og reformulering. Vi bruker benchmarket for å prøve negasjonsforsiktigheten av fleirspråk-modeller og finne at modeller som rett foregår eksemplar med negasjonsmønsterer, kan ofte ikkje foregå dei moteksemplane rett utan negasjonsmønsterer, sjølv når mønsterene er uavhengig for semantisk infeksjon.', 'pl': 'Negacja jest jedną z najbardziej podstawowych koncepcji ludzkiego poznania i języka, a kilka sond wnioskowania języka naturalnego (NLI) zostało zaprojektowanych w celu zbadania zdolności modeli językowych do wykrywania i rozumowania z negacją. Jednak istniejące zbiory danych sondujących są ograniczone tylko do języka angielskiego i nie umożliwiają kontrolowanego sondowania wydajności w przypadku braku lub obecności negacji. W odpowiedzi przedstawiamy wielojęzyczny (angielski, bułgarski, niemiecki, francuski i chiński) zestaw referencyjnych przykładów NLI, które są gramatyczne i poprawnie oznaczone, w wyniku ręcznej kontroli i reformulacji. Wykorzystujemy benchmark, aby zbadać świadomość negacji wielojęzycznych modeli językowych i stwierdzić, że modele, które poprawnie przewidują przykłady z negacją, często nie potrafią poprawnie przewidzieć swoich kontrprzykładów bez negacji, nawet jeśli wskazówki te są nieistotne dla wnioskowania semantycznego.', 'ro': 'Negarea este unul dintre cele mai fundamentale concepte în cunoașterea și limbajul uman, iar mai multe sonde de inferență a limbajului natural (NLI) au fost concepute pentru a investiga capacitatea modelelor lingvistice pre-instruite de a detecta și raționa cu negarea. Cu toate acestea, seturile de date existente de sondare sunt limitate numai la limba engleză și nu permit testarea controlată a performanței în absența sau prezența negației. Ca răspuns, prezentăm o colecție de referință multilingvă (engleză, bulgară, germană, franceză și chineză) de exemple NLI care sunt gramaticale și etichetate corect, ca rezultat al inspecției manuale și reformulării. Folosim benchmark-ul pentru a investiga conștientizarea negației modelelor lingvistice multilingve și descoperim că modelele care prezic corect exemplele cu indicii de negație, adesea nu reușesc să prezică corect contraexemplele lor fără indicii de negație, chiar și atunci când indiciile sunt irelevante pentru inferența semantică.', 'sr': 'Negacija je jedna od najfundamentalnijih koncepta u ljudskoj kogniciji i jeziku, a nekoliko prirodnih infekcija jezika (NLI) je dizajnirano za istragu sposobnosti jezičkih modela preklinjenih jezika da otkriju i razum sa negacijom. Međutim, postojeće datoteke za probu ograničene su samo na engleski, i ne omogućavaju kontroliranu probu performanstva u odsustvu ili prisustvu negacije. U odgovoru, predstavljamo višejezičku (englesku, bugarsku, njemačku, francusku i kinesku) kriteriju NLI primjera koji su gramatički i ispravno označeni kao rezultat manualne inspekcije i reformulacije. Koristimo kritiku da probamo negativno svijest multijezičkih modela i nađemo da modeli koji ispravno predviđaju primjere sa negativnim znakovima, često nisu ispravno predviđali njihove protivne primjere bez negativnih znakova, čak i kada su znakovi neovisni za semantičku infekciju.', 'si': 'ප්\u200dරතික්\u200dරියාත්මක තමයි මිනිස්සුන්ගේ පරිස්සම් සහ භාෂාත්මක සම්බන්ධයෙන් හැකියාවක් තියෙන්නේ, සහ ස්වභාවික භාෂාත්මක සංක්\u200dර නමුත්, තියෙන්න තියෙන්නේ පරීක්ෂණා දත්ත සේට් ඉංග්\u200dරීසිය විතරයි, ඒ වගේම පාලනය සක්\u200dරිය කරන්නේ නැහැ නැහැ  ප්\u200dරතිචාරයෙන්, අපි බුල්ගරියාන්, ජර්මාන්, ෆ්\u200dරෑන්ස් හා චීනියාන් (ඉංග්\u200dරීස්, බුල්ගරියාන්, ජර්මාන්, ෆ්\u200dරෑන්ස් සහ චීනියාන් අපි බෙන්ච්මාර්ක් පාවිච්චි කරනවා බොහොම භාෂාවක් මොඩේල්ස් ගැන අනතුරු දැනගන්න සඳහා අනතුරු විදිහට පරීක්ෂා කරනවා කියලා හොයාගන්න සඳහා මොඩේල්ස් හරියටම අන', 'so': "Negation waa mid ka mid ah fikrada ugu muhiimsan ee aqoonsiga iyo luqada dadka, waxaana loo qoray baaritaanka afka asalka ah (NLI) in lagu baaraandegayo muuqashada afka hore oo ay awood u leedahay inay ogaato iyo sabab ku ogaato waxyaabaha la naco. Si kastaba ha ahaatee, kooxda macluumaadka ee jiraa waa ay ku xadanyihiin Ingiriis oo kaliya, mana awoodin in la caddeeyo muuqashada la'aanta ama la joogo halaag la'aanta. Jawaal ahaan waxaynu soo bandhignaa qoraal ku qoran luuqado kala duduwan (Ingiriis, Bulgarian, Jarmal, Faraansiis iyo Shiino) tusaalaha NLI oo lagu qoray maamulka iyo si saxda ah, sababtoo ah baaritaanka dhaqanka iyo hagaajinta. Waxaynu u isticmaalnaa qoraalka si aan u caddeyno garashada tusaalaha luuqadaha kala duduwan, waxaynu helnaa tusaalaha si saxda ah u sii sheegaya tusaale ahaan cudurada waxtarka ah, marar badan waxay ku baahan yihiin inay si hagaagsan u sii sheegaan tusaalooyinkooda oo aan cudurada waxtarka lahayn, xitaa xittaa haddii cuduradu aan u baahnayn cudurka semantika.", 'sv': 'Negation ﾃ､r ett av de mest grundlﾃ､ggande begreppen inom mﾃ､nsklig kognition och sprﾃ･k, och flera natursprﾃ･ksundersﾃｶkningar (NLI) har utformats fﾃｶr att undersﾃｶka fﾃｶrtrﾃ､nade sprﾃ･kmodellens fﾃｶrmﾃ･ga att upptﾃ､cka och resonera med negation. De befintliga undersﾃｶkningsdatauppsﾃ､ttningarna ﾃ､r dock begrﾃ､nsade till endast engelska och mﾃｶjliggﾃｶr inte kontrollerad provning av prestanda i frﾃ･nvaro eller nﾃ､rvaro av negation. Som svar presenterar vi en flersprﾃ･kig (engelska, bulgariska, tyska, franska och kinesiska) benchmark samling av NLI-exempel som ﾃ､r grammatiska och korrekt mﾃ､rkta, som ett resultat av manuell inspektion och omformulering. Vi anvﾃ､nder riktmﾃ､rket fﾃｶr att undersﾃｶka negationsmedvetenheten hos flersprﾃ･kiga sprﾃ･kmodeller och finner att modeller som korrekt fﾃｶrutspﾃ･r exempel med negationstecken ofta misslyckas med att korrekt fﾃｶrutsﾃ､ga sina motexempel utan negationstecken, ﾃ､ven nﾃ､r ledtrﾃ･darna ﾃ､r irrelevanta fﾃｶr semantisk inferens.', 'ur': 'منظورت انسان کی شناخت اور زبان میں سب سے زیادہ بنیادی نظریں میں سے ایک ہے، اور بہت سی طبیعی زبان ناپسندیدہ (NLI) اسپورڈز کی طراحی کی گئی ہیں کہ منظورت کے ساتھ پیش رین زبان مدل کی قابلیت کی تحقیق کرنے کے لئے اور دلیل کا اظہار کرنے کے لئے بنا However, the existing probing data sets are limited to English, and do not enable controlled probing of performance in absence or presence of negative. ہم نے NLI مثالوں کے ایک بہت سی زبان (انگلیسی, بلگاری, جرمانی, فرانسوی اور چینی) بنچم مارک (بنچم مارک) کو پیش کیا ہے جو مثالیں گراماتیکی اور درست لکھی جاتی ہیں، ہاتھی کی تحقیق اور اصلاح کے نتیجہ سے۔ ہم نے بنچم مارک کا استعمال کرتا ہے کہ بہت سی زبان کی مدل کے منحصر اور بغیر منحصر معلوم ہونے کے لئے اور یہ معلوم ہوتا ہے کہ مدل جو منحصر معلومات کے ساتھ مثالیں ٹھیک پیش بینی کرتی ہیں، اگرچہ معلومات معلومات کے لئے اضافہ نہیں ہوتی۔', 'ta': 'நேஜியன் மனித அடிப்படையான கருத்துக்களில் மற்றும் மொழியில் ஒரு முக்கியமான கருத்துக்களில் உள்ளது, மற்றும் எதிர்மறையால் கண்டறியும் காரணத்திலும் சில இயற் ஆனால் இருக்கும் தரவு அமைப்பு கைமுறை பரிசோதிப்பு மற்றும் திருத்துதல் முடிவினால் NLI உதாரணங்களை குறிப்பிட்ட பல் மொழிகளின் (ஆங்கிலத்தில், புல்கேரியனி, ஜெர்மன், பிரெஞ்சு மற்றும்  நாம் பல மொழி மாதிரிகளின் எதிர்மறை புரிந்து கொள்ள பயன்படுத்துகிறோம் மற்றும் கண்டுபிடிக்க முடியும் மாதிரிகள் எதிர்மறை கூம்களுடன் சரியாக முன்வாக்குகிறது, பெரும்பாலும் எத', 'uz': "Negatiya inson ta'limni aniqlash va tilning eng asosiy fikrlaridan biri, va bir necha tabiiy tilning infeksiyati (NLI) imkoniyatlarini o'rganish uchun oddiy tilning modellarini o'rganish va sabablarni o'rganish uchun ko'rsatish mumkin. Ammo, mavjud maʼlumotlar tizimi faqat ingliz tilidagi chegara, va hech qanday mavjud emas yoki yoʻq mavjud boʻlgan amalni boshqarish imkoniyatini yoqib boʻlmaydi. Javob beradi, biz bir necha tillar (Ingliz, Bulgariy, Olmoncha, Fransuzcha va Xitoycha) benchmark collection va NLI misollarini grammatikk va toʻgʻri tahrirlash natijasida yozib qo'lbola tekshirish va reformatlash sababchi natijasi uchun. Biz ko'plab tillar modellarining negativ natijaligini aniqlashga foydalanamiz va bu modellarni o'xshash namoyishni ko'rsatadigan modellar o'ylab, ko'p paytda negativ cummolarni noto'g'ri deb o'ylab boʻlmaydi, agar xullar semantik suhbatda emas bo'lsa, ko'pchilik shakllarini o'zgartirib boʻlmaydi.", 'vi': 'Suy luận là một trong những khái niệm cơ bản nhất của nhận thức và ngôn ngữ con người, và nhiều thiết bị phát hiện ngôn ngữ tự nhiên (NLl) được thiết kế để điều tra khả năng phát hiện và lý lẽ của các mô hình ngôn ngữ trước khi rơi. Tuy nhiên, các bộ dữ liệu thăm dò hiện thời chỉ giới hạn với tiếng Anh, và không cho phép kiểm tra khả năng ứng dụng khi không có hay không. Đáp lại, chúng tôi giới thiệu một bộ sưu tập đa dạng (Anh, Bulgaria, Đức, Pháp và Trung Quốc) tiêu điểm tập hợp các ví dụ NLI được đánh dấu theo ngữ pháp và được đánh dấu chính xác, nhờ kết quả kiểm tra bằng tay và cải tạo lại. Chúng tôi dùng tiêu chuẩn để thăm dò sự cấm đoán của các mô hình ngôn ngữ đa dạng và phát hiện ra rằng các mẫu dự đoán chính xác các ví dụ kèm theo tiêu cực, thường không dự đoán đúng cách đối trường mà không có dấu hiệu tiêu cực, ngay cả khi tính ngữ nghĩa không liên quan.', 'bg': 'Отрицанието е една от най-фундаменталните понятия в човешкото познание и език, и няколко сонди за извод на естествения език (НЛИ) са разработени, за да изследват способността на предварително тренирани езикови модели да откриват и разсъждават с отрицанието. Съществуващите набори от данни за сондиране обаче са ограничени само до английски език и не позволяват контролирано сондиране на производителността при липса или наличие на отрицание. В отговор представяме многоезична (английски, български, немски, френски и китайски) сравнителна колекция от примери, които са граматически и правилно етикетирани, в резултат на ръчна проверка и реформация. Използваме бенчмарка, за да изследваме осведомеността за отрицание на многоезичните езикови модели и откриваме, че модели, които правилно предсказват примери с отрицателни знаци, често не успяват правилно да предскажат своите контра-примери без отрицателни знаци, дори когато знаците са без значение за семантичното заключение.', 'nl': 'Negatie is een van de meest fundamentele concepten in menselijke cognitie en taal, en verschillende Natural Language Inference (NLI) sondes zijn ontworpen om het vermogen van vooraf getrainde taalmodellen om negatie te detecteren en te redeneren te onderzoeken. De bestaande meetdatasets zijn echter beperkt tot het Engels en maken geen gecontroleerde meting van prestaties mogelijk bij afwezigheid of aanwezigheid van negatie. Als reactie hierop presenteren we een meertalige (Engels, Bulgaars, Duits, Frans en Chinees) benchmark verzameling NLI voorbeelden die grammaticaal en correct gelabeld zijn, als resultaat van handmatige inspectie en herformulering. We gebruiken de benchmark om het negatiebewustzijn van meertalige taalmodellen te onderzoeken en vinden dat modellen die voorbeelden correct voorspellen met negatiebewustjes, vaak hun tegenvoorbeelden niet correct voorspellen zonder negatiebewustjes, zelfs als de cues irrelevant zijn voor semantische inferentie.', 'hr': 'Negacija je jedna od najtemeljnijih koncepta u ljudskoj kogniciji i jeziku, a nekoliko prirodnih infekcija jezika (NLI) je dizajnirano za istragu sposobnosti jezičkih modela preliječenih jezika otkrivanja i razloga s negacijom. Međutim, postojeće datoteke za probu ograničene su samo na engleski i ne omogućavaju kontroliranu probu učinkovitosti u odsustvu ili prisustvu negacije. U odgovoru, predstavljamo višejezičku (englesku, bugarsku, njemačku, francusku i kinesku) skupljanje primjera NLI-a koji su gramatički i ispravno označeni kao rezultat manualne inspekcije i reformulacije. Koristimo kritiku da probamo negativno svijest multijezičkih modela i pronađemo da modeli koji ispravno predviđaju primjere sa negativnim znakovima, često ne predviđaju njihove protivne primjere bez negativnih znakova, čak i kada su znakovi neovisni za semantičku infekciju.', 'id': 'Negasi adalah salah satu konsep paling dasar dalam pengetahuan dan bahasa manusia, dan beberapa penyelesaian bahasa alami (NLI) telah dirancang untuk menyelidiki kemampuan model bahasa terlatih untuk mendeteksi dan alasan dengan negati. Namun, dataset penyelidikan yang ada dibatasi hanya dengan bahasa Inggris, dan tidak memungkinkan penyelidikan penyelidikan prestasi dalam ketiadaan atau kehadiran negatif. Sebagai respon, kami mempersembahkan koleksi benchmark berbagai bahasa (Inggris, Bulgari, Jerman, Perancis dan Cina) contoh NLI yang diberikan secara grammatis dan dengan benar, sebagai hasil dari inspeksi manual dan reformulasi. We use the benchmark to probe the negation-awareness of multilingual language models and find that models that correctly predict examples with negation cues, often fail to correctly predict their counter-examples without negation cues, even when the cues are irrelevant for semantic inference.', 'de': 'Negation ist eines der fundamentalsten Konzepte in der menschlichen Kognition und Sprache, und mehrere Natural Language Inference (NLI)-Sonden wurden entwickelt, um die Fähigkeit von vortrainierten Sprachmodellen zu untersuchen, Negation zu erkennen und mit Negation zu argumentieren. Die vorhandenen Messdatensätze sind jedoch nur auf Englisch beschränkt und ermöglichen keine kontrollierte Leistungsmessung in Abwesenheit oder Gegenwart von Negation. Als Antwort darauf präsentieren wir eine mehrsprachige (Englisch, Bulgarisch, Deutsch, Französisch und Chinesisch) Benchmark-Sammlung von NLI-Beispielen, die grammatikalisch und korrekt beschriftet sind, als Ergebnis manueller Überprüfung und Neuformulierung. Wir verwenden den Benchmark, um das Negationsbewusstsein mehrsprachiger Sprachmodelle zu untersuchen und stellen fest, dass Modelle, die Beispiele mit Negationshinweisen korrekt vorhersagen, oft ihre Gegenbeispiele ohne Negationshinweise nicht richtig vorhersagen können, selbst wenn diese für die semantische Inferenz irrelevant sind.', 'da': 'Negation er et af de mest grundlæggende begreber i menneskelig kognition og sprog, og adskillige natursprog inference sonder (NLI) er designet til at undersøge forudtrænede sprogmodels evne til at opdage og fornufte med negation. De eksisterende undersøgelsesdatasæt er imidlertid begrænset til kun engelsk og muliggør ikke kontrolleret undersøgelse af ydeevne i mangel af eller tilstedeværelse af negation. Som svar præsenterer vi en flersproget (engelsk, bulgarsk, tysk, fransk og kinesisk) benchmark samling af NLI eksempler, der er grammatiske og korrekt mærket, som følge af manuel inspektion og omformulering. Vi bruger benchmark til at undersøge negationsbevidstheden af flersprogede sprogmodeller og finde ud af, at modeller, der korrekt forudsiger eksempler med negationssignaler, ofte undlader at forudsige deres modeksempler korrekt uden negationssignaler, selv når lederne er irrelevante for semantisk inferens.', 'tr': 'Ýagtym adamlaryň tanaýaty we dillerinde iñ esasy düşünjäniň biridir we tebigy dillerin (NLI) sanatlaryna gözlemek üçin öňünden gelen dil modelleriniň tapylygyny we netijesi bilen gözlemek üçin guruldy. Ýöne, bar synaglama veri sahypalary diňe iňlisçe mümkin edýär we munuň ýok bolmadykda ýa-da täsirsizlik barlamasyny mümkin etmez. Jogapda, biz esasy görnüşde gramatik we dogry etiket edilen NLI örneklerini (iňlisçe, bulgarça, nemesçe, fransuzça we Çinçe) görnüşdürýäris. Biz multi dil nusgalarynyň täsirini maslahat etmek üçin etiketli çykyşyny ulanýarys we bu nusgalar negatiýa ukarlar bilen dogry öňden geçirjek nusgalary tapýarys. Köplenç öz mäzelerini negatiýa ukarlar bolmasa, hatda işaretler semantik hasaplamada çykyş ýok bolsa hem düzgün öňden çykyp bilmeýäris.', 'af': "Negasie is een van die mees fundamentele konsepte in die menslike kognisie en taal, en verskeie natuurlike taal inferensie (NLI) probes is ontwerp om voorstrekte taal modelle se kapasiteit te ondersoek om en rede met negasie te ontdek. Maar die bestaande probeer datastelle is alleen beperk na Engels, en doen nie die kontroleerde probeer van prestasie in die absence of voorsiening van negasie aktiveer nie. In antwoord stel ons 'n multilinglike (Engels, Bulgarse, Duits, Frans en Sjinees) benchmark versameling van NLI voorbeelde wat grammatiese en korrek gemerk is, as resultaat van hand inspeksie en reformulasie. Ons gebruik die benchmark om die negasie-awareness van multilinglike taal modele te probeer en te vind dat modele wat korrek voorskou voorbeelde met negasie-tekens, dikwels misluk om hulle anti-voorbeelde korrek te voorskou sonder negasie-tekens, selfs wanneer die tekens nie relevant is vir semantiese inferensie.", 'ko': '부정은 인류의 인지와 언어에서 가장 기본적인 개념 중 하나로 사람들은 몇 가지 자연 언어 추리(NLI) 탐지기를 설계하여 언어 모델이 부정에 대한 검측과 추리 능력을 미리 훈련시키는 것을 연구했다.그러나 기존의 탐지 데이터 집합은 영어에만 한정되어 있고 부정이 없거나 존재하지 않는 상황에서 성능을 제어하여 탐지할 수 없다.응답으로 우리는 여러 언어(영어, 불가리아어, 독일어, 프랑스어, 중국어)의 NLI 예시 기준 집합을 제공했다. 이 예시들은 수동 검사와 재편성을 거쳐 문법이 정확하고 표기가 정확하다.우리는 기준 테스트를 이용하여 다국어 언어 모델의 부정의식을 탐색하고 부정적 단서가 있는 예를 정확하게 예측하는 모델을 발견했다. 이런 단서가 의미 추리와 무관하더라도 부정적 단서가 없는 반례를 정확하게 예측할 수 없다.', 'sw': 'Negation ni moja ya dhana za msingi zaidi katika kutambua na lugha ya binadamu, na maambukizi kadhaa ya lugha za asili (NLI) yametengenezwa ili kuchunguza uwezo wa mifano ya lugha iliyopita ya kutambua na sababu yenye hasi. Hata hivyo, seti za taarifa zinazojaribu zinazuiwa kwa Kiingereza tu, na hawawezi kuwezesha kuchunguza utendaji katika kutokuwepo au kuwepo kwa hasi. Katika majibu, tunaleta mkusanyiko wa bendera wa lugha mbalimbali (Kiingereza, Bulgaria, Ujerumani, Ufaransa na Kichina) wa mifano ya NLI ambayo ni maarufu na kwa sahihi, kutokana na utafiti na mageuzi. Tunatumia bendera hiyo ili kuthibitisha uelewa wa mifano ya lugha mbalimbali na kutafuta mifano ambayo yanatabiri mifano sahihi kwa misitu ya hasi, mara nyingi hushindwa kutabiri mifano yao bila misitu yenye hasi, hata kama viungo vinavyohitajika kwa ugonjwa wa kimapenzi.', 'am': "Negation is one of the most fundamental concepts in human cognition and language, and several natural language inference (NLI) probes have been designed to investigate pretrained language models' ability to detect and reason with negation.  ምንም እንኳን፣ የአሁኑን ዳታዎችን ማረጋገጫ በንግግሊዘኛ ብቻ ነው፣ በሽብር ወይም በመቀናኘት የሥርዓቱን ማረጋገጥ አያስችሉም፡፡ በጥያቄ፣ የብዙ ቋንቋ (እንግሊዘኛ፣ ቡልጋሪኛ፣ ጀርመን፣ ፈረንሳይኛ እና ቻይኖች) የNLI ምሳሌዎች መቆጣጠርን እናቀርባለን፡፡ የቋንቋ ቋንቋዎች ምሳሌዎች የሽፋን-ማስታወቂያውን ለማድረግ እናገኘዋለን እናም ምሳሌዎችን በሽፋን ክፍሎች የሚያስተባብሉ እናደርጋለን፡፡", 'hy': 'Մերժումը մարդկային ճանաչության և լեզվի ամենահիմնարար գաղափարներից մեկն է, և մի քանի բնական լեզվի եզրակացությունների (ՆԼԻ) ուսումնասիրություններ են ստեղծվել, որպեսզի ուսումնասիրեն նախկինում ուսումնասիրեն լեզվի մոդելների կարողությունը բացահայ Այնուամենայնիվ, գոյություն ունեցող ուսումնասիրելու տվյալների համակարգերը սահմանափակվում են միայն անգլերենով և չեն հնարավորություն տալիս վերահսկվող ուսումնասիրել արդյունքը բացակայության կամ բացակայության դեպքում: In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation.  Մենք օգտագործում ենք համեմատական նշանը բազմալեզու լեզվի մոդելների բացասական գիտակցության ուսումնասիրելու համար և գտնում ենք, որ մոդելները, որոնք ճիշտ կանխատեսում են օրինակները բացասական նշաններով, հաճախ չեն կարողանում ճիշտ կանխատեսել իրենց հակաօրինակները առանց բացասական նշանների, նույնիսկ երբ', 'az': 'ńįnsan tanńĪdńĪqlarńĪ v…ô dill…ôrin …ôn fundamental fikirl…ôrind…ôn biridir. NLI t…ôbi…ôtli dill…ôrin t…ôbi…ôtl…ôrind…ôn √ßox t…ôbi…ôtli t…ôbi…ôtl…ôrini t…ôŇükil etm…ôk √ľ√ß√ľn t…ôŇükil edilmiŇüdir. Ancaq h…ômin probing veri qurńüularńĪ yalnńĪz ńįngiliz…ô sńĪnńĪrlandńĪrńĪr, yoxdur ya da yoxdur, yoxdur v…ô yoxdur. Cevap verm…ôkd…ô, biz, …ôlli t…ôŇüviq v…ô reformulaŇüdńĪrma s…ôb…ôbi, √ßoxlu dil (ńįngilizce, Bulgarca, Almanca, FransńĪz v…ô √áinc…ô) NLI misallarńĪnńĪn benchmark koleksiyonunu g√∂st…ôririk. Biz √ßoxlu dil modellerinin negativ-x…ôb…ôrdarlńĪńüńĪ t…ôsdiql…ôm…ôk √ľ√ß√ľn benchmark istifad…ô edirik v…ô bu modell…ôri negativ m…ôqs…ôdil…ô dońüru t…ôsdiql…ôy…ôn modell…ôr…ô g√∂r…ô bil…ôrik ki, √ßoxlu sńĪralar negativ m…ôqs…ôdil…ôr olmadan, h…ôtta m…ôqs…ôdil…ôr semantik infeksiya q…ôtiyy…ôti olmayan m…ôqs…ôdil…ô dońüru t…ôsdiql…ôm…ôy…ô baŇüa d√ľŇüm√ľrl…ôr.', 'bn': 'নেগেশন মানুষের চিন্তা এবং ভাষায় সবচেয়ে মৌলিক ধারণার মধ্যে একটি এবং বেশ কিছু প্রাকৃতিক ভাষার আক্রান্ত (এনলিআই) পরীক্ষা করা হয়েছে যাতে নেতিবৃত ভাষার ম তবে বিদ্যমান ডাটাবিন্যাসেট শুধুমাত্র ইংরেজীতে সীমাবদ্ধ এবং অনুপস্থিতি অথবা নেতিগেশনের উপস্থিতিতে নিয়ন্ত্রণের প্রদর্শনে এর প্রতিক্রিয়ায় আমরা একটি বহুভাষায় (ইংরেজী, বুলগেরিয়ান, জার্মান, ফরাসী এবং চীনা) বেঞ্চার্মের সংগ্রহের সংগ্রহ উপস্থাপন করছি, যা গ্রামান্টিক এবং সঠিক ভাবে  আমরা বেনম্যার্ক ব্যবহার করি বহুভাষাভাষী ভাষার মডেলের নেতিবেশন-সচেতনতা প্রমাণ করার জন্য এবং খুঁজে পাই যে মডেল যারা সঠিকভাবে ভবিষ্যদ্বাণী করে নেতেজেন্টিক কু ছাড়া তাদের বি', 'bs': 'Negacija je jedna od najtemeljnijih koncepta u ljudskoj kogniciji i jeziku, a nekoliko prirodnih infekcija jezika (NLI) je dizajnirano za istragu sposobnosti jezičkih modela pretvorenih jezika da otkriju i razum sa negacijom. Međutim, postojeće datoteke za probu ograničene su samo na engleski, i ne omogućavaju kontroliranu probu učinkovitosti u odsustvu ili prisustvu negacije. U odgovoru, predstavljamo višejezičku (englesku, bugarsku, njemačku, francusku i kinesku) skupljanje primjera NLI koji su gramatički i ispravno označeni kao rezultat manualne inspekcije i reformulacije. Koristimo kritiku da probamo negativno svijest multijezičkih modela i pronađemo da modeli koji ispravno predviđaju primjere sa negativnim znakovima, često ne predviđaju njihove protivne primjere bez negativnih znakova, čak i kada su znakovi neovisni za semantičku infekciju.', 'ca': "La negatió és un dels conceptes més fonamentals de la cognitió i el llenguatge humans, i diverses sondes de la inferència natural del llenguatge (NLI) han estat dissenyades per investigar l'habilitat dels models de llenguatge predireccionats de detectar i raonar amb negatió. No obstant això, els conjunts de dades de sondages existents estan limitats només a l'anglès, i no permeten sondages controlades de rendiment en ausencia o presencia de negatió. En resposta, presentem una col·lecció de referències multilingües (anglès, búlgar, alemany, francès i xinès) d'exemples de la NLI que són gramàtics i etiquetats correctament, a raó de la inspecció manual i la reformulació. Utilitzem el punt de referència per investigar la consciència negativa dels models multilingües i trobem que els models que predien correctament exemples amb indicacions negatives sovint no predien correctament els seus contraexemples sense indicacions negatives, fins i tot quan les indicacions són irrelevants per a la inferència semàntica.", 'sq': 'Negimi është një nga konceptet më thelbësore në njohjen dhe gjuhën njerëzore dhe disa sonda të inferencës natyrore të gjuhës (NLI) janë projektuar për të hetuar aftësinë e modeleve të gjuhës së paratrajnuar për të zbuluar dhe arsyetuar me negativ. Megjithatë, grupet ekzistuese të të dhënave sondazh janë të kufizuara vetëm në anglisht dhe nuk lejojnë sondazhin e kontrolluar të performancës në mungesë apo praninë e negativit. In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation.  Ne përdorim normën për të hetuar ndërgjegjësimin negativ të modeleve shumëgjuhësore të gjuhës dhe të gjejmë se modelet që parashikojnë saktësisht shembujt me shembuj negativ, shpesh nuk parashikojnë saktësisht kundërshembujt e tyre pa shembuj negativ, edhe kur shembujt janë të pavarur për përfundimin semantik.', 'fa': 'مذاکره یکی از اصلی\u200cترین مفهوم\u200cهای شناختن و زبان انسان است، و چند امتحان آلودگی زبان طبیعی (NLI) برای تحقیق توانایی مدل\u200cهای زبان پیش\u200cفرض برای شناسایی و دلیل\u200cهایی با منفی طراحی شده است. با این حال، مجموعه\u200cهای داده\u200cهای تحقیق موجود فقط به انگلیسی محدود می\u200cشوند، و در غیر یا موجود منفی تحقیق عملکرد کنترل را فعال نمی\u200cکند. در پاسخ، ما یک مجموعه نقشه\u200cهای مثال NLI از مثال\u200cهای گراماتیک و درست نقشه\u200cهای زبانی (انگلیسی، بلگاری، آلمانی، فرانسوی و چینی) را پیشنهاد می\u200cکنیم که به نتیجه بازرسی و تغییرات دستی برگزار می\u200cشود. ما از صندوق استفاده می کنیم تا آگاهی منفی از مدل های زبان چندین زبان را تحقیق کنیم و یافتیم که مدل هایی که درست پیش بینی می کنند مثالهایی با نشانه های منفی، اغلب نمی توانند مثالهایشان را درست پیش بینی کنند بدون نشانه های منفی، حتی زمانی که نشانه ها برای آلودگی semantic بی اهمیت دارند.', 'et': 'Negatsioon on inimese tunnetuse ja keele üks põhilisemaid kontseptsioone ning mitmed looduskeele järelduse sondid on välja töötatud selleks, et uurida eeltreenitud keelemudelite suutlikkust tuvastada ja mõelda negatsiooniga. Olemasolevad prooviandmekogumid on siiski piiratud ainult inglise keelega ning need ei võimalda kontrollitud proovida jõudlust negatsiooni puudumisel või olemasolul. Vastuseks esitame mitmekeelse (inglise, bulgaaria, saksa, prantsuse ja hiina) võrdluskogumi NLI näidetest, mis on grammatilised ja korrektselt märgistatud käsitsi kontrollimise ja ümberkujundamise tulemusena. Me kasutame võrdlusalust mitmekeelsete keelemudelite negatiivse teadlikkuse uurimiseks ja leiame, et mudelid, mis ennustavad õigesti näiteid negatiivsete vihjetega, ei suuda sageli õigesti ennustada oma vastunäiteid ilma negatiivsete vihjeta, isegi kui vihjed ei ole semantilise järelduse jaoks olulised.', 'fi': 'Negaatio on yksi ihmisen kognitiossa ja kielessä keskeisimmistä käsitteistä, ja useat luonnollisen kielen päättelyluotaimet (NLI) on suunniteltu tutkimaan esikoulutettujen kielimallien kykyä havaita ja järkeillä kieltä. Olemassa olevat luotaustiedostot on kuitenkin rajoitettu vain englanniksi, eivätkä ne salli kontrolloitua testaamista suorituskyvyn puuttuessa tai läsnä ollessa kieltämistä. Vastauksena esittelemme monikielisen (englanti, bulgaria, saksa, ranska ja kiina) vertailukokoelman NLI-esimerkkejä, jotka ovat kieliopillisia ja oikein merkittyjä manuaalisen tarkastuksen ja uudelleenmuotoilun tuloksena. Tutkimme vertailukohdan avulla monikielisten kielimallien kieltämistä-tietoisuutta ja havaitsemme, että mallit, jotka ennustavat oikein esimerkkejä kieltämisvihjeillä, eivät usein pysty ennustamaan oikein vastaesimerkkiään ilman kieltämisvihjeitä, vaikka vihjeillä ei olisi merkitystä semanttisen päättelyn kannalta.', 'cs': 'Negace je jedním z nejzákladnějších konceptů lidského poznání a jazyka a několik sond pro inferenci přirozeného jazyka (NLI) bylo navrženo pro zkoumání schopnosti předtrénovaných jazykových modelů detekovat a rozumovat s negací. Stávající datové sady sondování jsou však omezeny pouze na angličtinu a neumožňují kontrolované sondování výkonu při absenci nebo přítomnosti negace. V reakci na to představujeme vícejazyčnou (angličtinu, bulharštinu, němčinu, francouzštinu a čínštinu) referenční sbírku NLI příkladů, které jsou gramaticky a správně označeny, v důsledku manuální kontroly a přeformulace. Používáme benchmark k zkoumání negativního uvědomění vícejazyčných jazykových modelů a zjišťujeme, že modely, které správně předpovídají příklady s negativními návody, často nedokážou správně předpovídat své protipříklady bez negativních návodů, i když jsou pro sémantickou inferenci irelevantní.', 'jv': 'Ngubah iku ing saben sing paling kelompok saben nggunaken winih lan luwih, lan akeh langgar langgar sampeyan (NLI) supoyo nggunakake tualisangit kanggo ngerasai model sing perusahaan banget kuwi nggunakake tarjamahan. slot Nanging repakan, kita mulai akeh akeh langgar-langgar (Inggal, Bombergal, Jeman, Perancis lan Cino) nggawe barang nggambar kuwi kesemplak NLI sing ngegambar obah basa gambar lan oleh, kaya ngono ujak-ujak lan mputurasi manut. Awak dhéwé nggunaké bendhèwèké kanggo kuwi nggawe gerambut-awak kuwi tindakan anyar tentang karo ngono nggawe modèl kuwi nggawe bener diagram sing dipunserané karo aturan macem, sapa uwis kuwi nggawe gerambut kuwi mèwèké tarjamahan kaya ngono kuwi nggawe gerambut kuwi dianggap ceh dumaten, ora iso nggawe tchek dhéwé kuwi', 'he': 'שלילה היא אחת מהמושגים הבסיסיים ביותר בהכרה והשפה האנושית, וכמה חוקרי שפת טבעיות (NLI) נועדו לחקור את היכולת של דוגמני שפת מתאמנים עם זאת, קבוצות נתונים הנוכחים מוגבלות לאנגלית בלבד, ולא מאפשרות חקירה שולטת של ביצועים בהיעדרות או נוכחות של שליטה. בתגובה, אנו מציגים אסוף רמזים רבולוגי (אנגלית, בולגרית, גרמנית, צרפתית וסינית) של דוגמאות NLI שמתווידות גרמטית ומתאורת נכון, כתוצאה של בדיקה ידנית ושינוי. אנו משתמשים במרמז כדי לחקור את מודעות השלילות של דוגמני שפה רבות שפות ומצאים שמדוגמנים שצפויים נכון דוגמאות עם סימני השלילות, לעתים קרובות לא מצליחים לחזות נכון את דוגמאותיהם נגד ללא סימני השלילות, אפילו כאשר סימנים לא רלוונטיים למסקנה סמנטית.', 'ha': "Negasion yana daga mafiya muhimmin fikanci ga mutane da harshe, kuma an design misalin wasu mutane na harshe na natsuwa (NLI) ko dõmin an yi tambayar misalin misalin harshe da za'a iya gane da saba da haske. A lokacin da, tsarin da ake jarraba maɓallin da ake ƙunsa kawai zuwa Ingiriya kawai, kuma bã su fara a iya jarraba performance da ba'a gaba ko kuma don a halarce haske. In a iya amfani da shi, ko kuma za mu halatar da komai da misãlai na NLI masu cikin mulki-lingui (Ingiriya, Bulgaria, Jarman, Faransa da Kinesi) wanda aka rubũta shi na rubutu da inganci. Munã amfani da bangon kwamfyuta dõmin ka jarraba masu haske-fahimta ga misalin misalin harshe masu cikin mulki-lingui kuma mu gane misãlai waɗanda ke yi bastarwa da alƙaluman aiki daidai, ko da yawa, za'a kasancẽwa bayani ga misãlai masu bastarwa masu hasara ko kuma idan cunukan na da zartar da kafin na semantic.", 'sk': 'Negativnost je eden najpomembnejših konceptov v človeškem spoznavanju in jeziku, več sond za sklepanje naravnega jezika (NLI) pa je bilo zasnovanih za raziskovanje sposobnosti predtreniranih jezikovnih modelov za zaznavanje in razumevanje zanikanja. Vendar pa so obstoječi nabori podatkov o sondiranju omejeni samo na angleščino in ne omogočajo nadzorovanega sondiranja delovanja v odsotnosti ali prisotnosti zanikanja. V odgovor predstavljamo večjezično (angleščina, bolgarščina, nemščina, francoščina in kitajščina) referenčno zbirko primerov NLI, ki so slovnični in pravilno označeni kot rezultat ročnega pregleda in reformulacije. Uporabljamo referenčno vrednost za proučevanje zavedanja zanikanja večjezičnih jezikovnih modelov in ugotovimo, da modeli, ki pravilno napovedujejo primere z negativnimi namigi, pogosto ne uspejo pravilno napovedati svojih protiuprimerov brez negativnih namigov, tudi če so namigi nepomembni za semantično sklepanje.', 'bo': 'མིག་ཆ་ནི་མི་ཤེས་དང་སྐད་ཡིག་ནང་གི་ཆེས་རྨན་ཅིག་རེད། ཡིན་ནའང་། གནས་ཡོད་པའི་ཚོལ་ཞིབ་བྱས་ཆོག་ཡིག་ཆ་ཁོ་ན་ལྟར་མཚམས་བཅད་ཡོད། In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation. Name ང་ཚོས་རྟགས་དམག་མེད་སྐད་ཡིག་གི་མིང་དཔེ་དབྱེ་རིགས་ལ་གསལ་བསམ་བྱེད་པར་གནད་དོན་མེད་སྤྱད་ནས།'}
{'en': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing POS  Tagging, and Constituent Parsing', 'es': 'Un marco de etiquetado de grosero a fino para la segmentación conjunta de palabras, el etiquetado de PDV y el análisis de componentes', 'ar': 'إطار عمل لوضع العلامات من الخشنة إلى الدقيقة للتجزئة المشتركة للكلمات ، وعلامات نقاط البيع ، والتحليل المكونة', 'pt': 'Uma estrutura de rotulagem de grosso a fino para segmentação de palavras conjuntas, marcação POS e análise de constituintes', 'fr': "Un cadre d'étiquetage grossier à fin pour la segmentation conjointe des mots, le marquage POS et l'analyse des constituants", 'ja': 'ジョイントワードセグメンテーション、POSタグ付け、および構成要素解析のための粗いラベリングフレームワーク', 'ru': 'Структура грубой и тонкой маркировки для совместной сегментации слов, маркировки POS-терминалов и компонентного анализа', 'zh': '以合分词、POS 解析之粗到框架', 'hi': 'संयुक्त शब्द विभाजन, पीओएस टैगिंग, और संविधान पार्सिंग के लिए एक मोटे-से-ठीक लेबलिंग फ्रेमवर्क', 'ga': 'Creat Lipéadaithe Garbh go Mín le haghaidh Comhdheighilt Focal, Clibeáil POS, agus Parsáil Comhábhair', 'ka': 'ერთადერთი სიტყვების სეგენტაციის, POS ჭდეს და კონსტისტენტისტენტის გადაწყვეტის პარამეტრი', 'hu': 'Durva-finom címkézési keretrendszer a közös szószegmentáláshoz, POS-címkézéshez és alkotóelemezéshez', 'el': 'Ένα πλαίσιο χονδρικής έως λεπτής επισήμανσης για την κοινή τμηματοποίηση λέξεων, την επισήμανση και την ανάλυση συστατικών', 'it': 'Un quadro di etichettatura da grossolano a fine per segmentazione congiunta delle parole, etichettatura POS e analisi costituente', 'kk': 'Бірлескен сөз сегментациясы, POS тегтері және конститутты талдау', 'lt': 'Bendros žodžių segmentacijos, POS ženklinimo ir sudedamųjų dalių analizavimo etiketės pagrindas', 'mk': 'Рамка за обележување на зборови од грешка до фина за заедничка сегментација на зборови, обележување на POS и анализирање на конститунти', 'ms': 'Name', 'mn': 'Нэгдсэн үг хэвлэх, POS Tagging, Байгамшигтай эхлэх гэрэл', 'ml': 'യൂണ്ട് വാക്ക് സെഗ്മെന്റേഷന്\u200d, പോസ് ടാഗ്ഗിങ്ങ്, പാര്\u200dസ് പാര്\u200dസിങ്ങ് ചെയ്യുന്നതിനുള്ള കോര്\u200dസ് മുതല്\u200d നല്ല ല ലാബില', 'mt': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing', 'no': 'Name', 'ro': 'Un cadru de etichetare grosieră până la fină pentru segmentarea comună a cuvintelor, etichetarea POS și interpretarea constitutivă', 'pl': 'Ramy etykietowania grubego do drobnego dla segmentacji wspólnych słów, tagowania POS i analizy składników', 'si': 'සම්පූර්ණ වචන විශේෂණය, POS ටැග් එක, සහ ස්ථායිත විශේෂණය සඳහා කෝර්ස් එක්ක හොඳ ලේබිලින් ක්\u200dරීම්වර්', 'sr': 'Okvir za zajedničku segmentaciju riječi, označavanje POS-a i određeno razmatranje', 'ta': 'Name', 'ur': 'Joint Word Segmentation, POS Tagging, and Constituent Parsing for a Coarse-to-Fine Labeling Framework', 'so': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing', 'sv': 'En grov till fin märkningsram för gemensam ordsegmentering, POS-märkning och konstituerande tolkning', 'uz': 'Name', 'vi': 'A bộ kiểm soát được ãnh hướng về một thứ mật bằng và một thứ tượng chung', 'nl': 'Een grof tot fijn etiketteringskader voor gezamenlijke woordsegmentatie, POS-tagging en constitution parsing', 'bg': 'Рамка за етикетиране от грубо до фино за съвместна сегментация на думи, етикетиране на ПОС и съставно анализиране', 'da': 'En grov til fin mærkningsramme for fælles ordsegmentering, POS-mærkning og konstituerende fortolkning', 'hr': 'Okvir za zajedničku segmentaciju riječi, označavanje POS-a i određeno razmatranje', 'de': 'Ein grobes bis feines Beschriftungsrahmen für gemeinsame Wortsegmentierung, POS-Tagging und Constituent Parsing', 'id': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing', 'fa': 'یک چهارچوب برچسب\u200cبندی برای جدا کردن کلمات متحد، برچسب\u200cبندی POS و پژوهش پایدار', 'ko': '연합분사, 어성 표기 및 성분 분석에 사용되는 굵기부터 정교한 라벨 프레임', 'sw': 'Mfumo wa Uchaguzi wa Uchaguzi wa Sauti ya Marufuku, Uchaguzi wa POS, na Mwanasheria wa Uchaguzi', 'tr': 'Birleşen söz Segmentation, POS Taglamak we Durumlu Taýmlama üçin Jezgi Etiketleme Çerçemi', 'af': 'Name', 'sq': 'Një Kornizë Etiketimi nga Rreth në Rreth për Segmentimin e Fjalëve të Përbashkëta, Etiketimin POS dhe Analizën Kushtetuese', 'am': 'ምርጫዎች', 'hy': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing', 'az': 'Joint Word Segmentation, POS Tagging, and Constituent Parsing Framework for a Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging and Constituent Parsing', 'bn': 'সংযুক্ত শব্দ বিভাগ, পোস ট্যাগিং এবং সংবিধান পার্সিং', 'bs': 'Okvir za zajedničku segmentaciju riječi, označavanje POS-a i određeno razmatranje', 'cs': 'Rámec hrubého až jemného označování pro segmentaci společných slov, značení POS a analýzu složek', 'et': 'Ühise sõna segmenteerimise, POSi märgistamise ja koostisosade parsimise karm kuni peen märgistusraamistik', 'ca': "Un marc d'etiquetage de cors a fins per segmentar paraules comunes, etiquetar POS i analitzar els components", 'fi': 'Karkeasta hienoon merkintäkehykseen yhteisen sanasegmentoinnin, POS-merkinnän ja osatekijöiden jäsentämisen osalta', 'sk': 'Okvir za grobo do drobno označevanje za skupno segmentacijo besed, označevanje prodajnih mest in razdeljevanje sestavnih delov', 'ha': 'KCharselect unicode block name', 'he': 'סגרת תגויות מעל לגבוה עבור שיתוף מילים משותף, תגויות POS, ומחקר קבוע', 'jv': 'A', 'bo': 'A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing'}
{'en': 'The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges. First, a larger label set (e.g.,   600) and longer inputs both increase computational costs. Second, it is difficult to rule out illegal trees containing conflicting production rules, which is important for reliable model evaluation. If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries. To deal with both challenges, this work proposes a two-stage coarse-to-fine labeling framework for joint WS-POS-PAR. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e., phrase, subphrase, word, subword). The  tree  is guaranteed to be legal via constrained CKY decoding. In the fine labeling stage, the  model  expands each coarse label into a final label (such as VP, VP *, VV, VV *). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the  pipeline approach  on both settings of  w/o  and  w/ BERT , and achieves new state-of-the-art performance.', 'ar': 'إن النهج الأكثر مباشرة لتجزئة الكلمات المشتركة (WS) ، وعلامات جزء من الكلام (POS) ، والتحليل المكونة هو تحويل شجرة على مستوى الكلمة إلى شجرة على مستوى الحرف ، مما يؤدي ، مع ذلك ، إلى تحديين خطيرين. أولاً ، تؤدي مجموعة الملصقات الأكبر (على سبيل المثال ، 600) والمدخلات الأطول إلى زيادة التكاليف الحسابية. ثانيًا ، من الصعب استبعاد الأشجار غير القانونية التي تحتوي على قواعد إنتاج متضاربة ، وهو أمر مهم لتقييم نموذج موثوق. إذا كانت علامة POS (مثل VV) أعلى علامة عبارة (مثل VP) في شجرة الإخراج ، يصبح تحديد حدود الكلمات أمرًا معقدًا للغاية. للتعامل مع كلا التحديين ، يقترح هذا العمل إطار عمل من مرحلتين من الخشن إلى الدقيق لوضع العلامات من أجل WS-POS-PAR المشترك. في مرحلة وضع العلامات التقريبية ، يُخرج النموذج المشترك شجرة بين قوسين ، حيث تتوافق كل عقدة مع واحدة من أربع تسميات (أي عبارة ، عبارة فرعية ، كلمة ، كلمة فرعية). الشجرة مضمونة لتكون قانونية من خلال فك تشفير CKY المقيد. في مرحلة وضع العلامات الدقيقة ، يوسع النموذج كل ملصق خشن إلى ملصق نهائي (مثل VP و VP * و VV و VV *). توضح التجارب على Chinese Penn Treebank 5.1 و 7.0 أن نموذجنا المشترك يتفوق باستمرار على نهج خط الأنابيب في كل من إعدادات w / o و w / BERT ، ويحقق أداءً متطورًا جديدًا.', 'fr': "L'approche la plus simple pour la segmentation conjointe des mots (WS), le balisage des parties du discours (POS) et l'analyse des constituants consiste à convertir une arborescence au niveau des mots en une arborescence au niveau des caractères, ce qui entraîne cependant deux défis majeurs. Tout d'abord, un jeu d'étiquettes plus grand (par exemple, 600) et des entrées plus longues augmentent les coûts de calcul. Deuxièmement, il est difficile d'exclure des arbres illégaux contenant des règles de production contradictoires, ce qui est important pour une évaluation fiable des modèles. Si une balise POS (comme VV) se trouve au-dessus d'une étiquette de phrase (comme VP) dans l'arbre de sortie, il devient assez complexe de déterminer les limites des mots. Pour faire face à ces deux défis, ce travail propose un cadre d'étiquetage grossier à fin en deux étapes pour le WS-POS-PAR commun. Au stade de l'étiquetage grossier, le modèle conjoint produit un arbre entre crochets, dans lequel chaque nœud correspond à l'une des quatre étiquettes (c'est-à-dire phrase, sous-phrase, mot, sous-mot). L'arbre est garanti légal grâce au décodage CKY contraint. Au stade de l'étiquetage fin, le modèle étend chaque étiquette grossière en une étiquette finale (telle que VP, VP*, VV, VV*). Des expériences sur les bancs chinois Penn Treebank 5.1 et 7.0 montrent que notre modèle conjoint surpasse constamment l'approche pipeline sur les deux réglages w/o et w/BERT, et atteint de nouvelles performances de pointe.", 'es': 'El enfoque más sencillo para la segmentación conjunta de palabras (WS), el etiquetado de partes de voz (POS) y el análisis de componentes es convertir un árbol a nivel de palabras en un árbol a nivel de caracteres, lo que, sin embargo, conlleva dos desafíos graves. Primero, un conjunto de etiquetas más grande (por ejemplo, 600) y entradas más largas aumentan los costos computacionales. En segundo lugar, es difícil descartar árboles ilegales que contienen reglas de producción conflictivas, lo cual es importante para una evaluación confiable del modelo. Si una etiqueta POS (como VV) está por encima de una etiqueta de frase (como VP) en el árbol de salida, se vuelve bastante complejo decidir los límites de las palabras. Para hacer frente a ambos desafíos, este trabajo propone un marco de etiquetado de grueso a fino de dos etapas para el WS-POS-PAR conjunto. En la etapa de etiquetado grosero, el modelo conjunto genera un árbol entre corchetes, en el que cada nodo corresponde a una de las cuatro etiquetas (es decir, frase, subfrase, palabra, subpalabra). Se garantiza que el árbol es legal a través de la decodificación CKY restringida. En la etapa de etiquetado fino, el modelo expande cada etiqueta gruesa en una etiqueta final (como VP, VP*, VV, VV*). Los experimentos en los Penn Treebank 5.1 y 7.0 chinos muestran que nuestro modelo conjunto supera sistemáticamente el enfoque de canalización en ambas configuraciones de sin y con BERT, y logra un nuevo rendimiento de vanguardia.', 'pt': 'A abordagem mais direta para segmentação de palavras conjuntas (WS), marcação de parte da fala (POS) e análise de constituintes é converter uma árvore de nível de palavra em uma árvore de nível de caractere, o que, no entanto, leva a dois grandes desafios. Primeiro, um conjunto de rótulos maior (por exemplo, 600) e entradas mais longas aumentam os custos computacionais. Em segundo lugar, é difícil descartar árvores ilegais contendo regras de produção conflitantes, o que é importante para uma avaliação confiável do modelo. Se uma tag POS (como VV) estiver acima de uma tag de frase (como VP) na árvore de saída, torna-se bastante complexo decidir os limites das palavras. Para lidar com ambos os desafios, este trabalho propõe uma estrutura de rotulagem grosseira a fina de dois estágios para WS-POS-PAR conjunto. No estágio de rotulagem grosseira, o modelo conjunto gera uma árvore entre colchetes, na qual cada nó corresponde a um dos quatro rótulos (ou seja, frase, subfrase, palavra, subpalavra). A árvore é garantida como legal por meio de decodificação CKY restrita. No estágio de rotulagem fina, o modelo expande cada rótulo grosseiro em um rótulo final (como VP, VP*, VV, VV*). Experimentos no chinês Penn Treebank 5.1 e 7.0 mostram que nosso modelo conjunto supera consistentemente a abordagem de pipeline em ambas as configurações de sem e com BERT e alcança um novo desempenho de última geração.', 'ja': '合同ワードセグメンテーション（ WS ）、一部音声（ POS ）タグ付け、および構成解析への最も簡単なアプローチは、ワードレベルのツリーを文字レベルのツリーに変換することです。しかし、これは2つの厳しい課題につながります。 第１に、より大きなラベルセット（例えば、６ ０ ０ ）及びより長い入力は、両方とも計算コストを増加させる。 第二に、信頼性の高いモデル評価に重要な、競合する生産ルールを含む違法な木を排除することは困難である。 POSタグ（ VVのような）が出力ツリーのフレーズタグ（ VPのような）の上にある場合、単語の境界を決定するのは非常に複雑になります。 この研究は、両方の課題に対処するために、ジョイントWS - POS - PARのための2段階の粗いラベル付けフレームワークを提案する。粗いラベル付け段階では、ジョイントモデルは、各ノードが4つのラベル（すなわち、フレーズ、サブフレーズ、ワード、サブワード）のうちの1つに対応するブラケット付きツリーを出力する。 このツリーは、制約されたCKYデコードを介して合法であることが保証されています。 ファインラベル段階では、モデルは各粗いラベルを最終ラベル（ VP、VP *、VV、VV *など）に展開します。 中国ペンツリーバンク5.1および7.0の実験では、当社の共同モデルは、w/oとw/BERTの両方の設定でパイプラインアプローチを一貫して上回り、新しい最先端のパフォーマンスを達成していることが示されています。', 'zh': '合分词 (WS)、词性 (POS) 标、成分解析最直者,将单词级树转为字符级树,然二严挑战也。 首大标集(如600)、更长皆增计算成本。 其次,难排冲突之非法树,于模评为重。 若 POS 标记(如 VV)在输树中短语(如 VP)之上,则单词界将变为非常复杂。 为此二者挑战,为WS-POS-PAR合一两粗到细标签框架。 其略标记,合模输一带括号树,其节点应四标签(曰短语、子短语、单词、子单词)之一。 受约束者CKY解码保树是法也。 凡细者,以粗为终(VP,VP *VVV*)。 宾州树库5.1、7.0之实验,合形于w/o、w/BERT二者,始终如一,而先进之新性也。', 'hi': 'संयुक्त शब्द विभाजन (डब्ल्यूएस), पार्ट-ऑफ-स्पीच (पीओएस) टैगिंग, और घटक पार्सिंग के लिए सबसे सीधा दृष्टिकोण एक शब्द-स्तर के पेड़ को चार-स्तरीय पेड़ में परिवर्तित कर रहा है, जो हालांकि, दो गंभीर चुनौतियों की ओर जाता है। सबसे पहले, एक बड़ा लेबल सेट (उदाहरण के लिए, 600) और लंबे समय तक इनपुट दोनों कम्प्यूटेशनल लागत में वृद्धि करते हैं। दूसरा, परस्पर विरोधी उत्पादन नियमों वाले अवैध पेड़ों को खारिज करना मुश्किल है, जो विश्वसनीय मॉडल मूल्यांकन के लिए महत्वपूर्ण है। यदि एक पीओएस टैग (वीवी की तरह) आउटपुट ट्री में एक वाक्यांश टैग (जैसे वीपी) से ऊपर है, तो शब्द सीमाओं को तय करना काफी जटिल हो जाता है। दोनों चुनौतियों से निपटने के लिए, यह काम संयुक्त WS-POS-PAR के लिए दो-चरण मोटे-से-ठीक लेबलिंग ढांचे का प्रस्ताव करता है। मोटे लेबलिंग चरण में, संयुक्त मॉडल एक ब्रैकेटेड पेड़ को आउटपुट करता है, जिसमें प्रत्येक नोड चार लेबलों में से एक से मेल खाता है (यानी, वाक्यांश, उप-वाक्यांश, शब्द, उपशब्द)। पेड़ को विवश CKY डिकोडिंग के माध्यम से कानूनी होने की गारंटी दी जाती है। ठीक लेबलिंग चरण में, मॉडल प्रत्येक मोटे लेबल को अंतिम लेबल (जैसे वीपी, वीपी *, वीवी, वीवी *) में विस्तारित करता है। चीनी पेन ट्रीबैंक 5.1 और 7.0 पर प्रयोगों से पता चलता है कि हमारा संयुक्त मॉडल लगातार डब्ल्यू / ओ और डब्ल्यू / बर्ट की दोनों सेटिंग्स पर पाइपलाइन दृष्टिकोण को बेहतर बनाता है, और नए अत्याधुनिक प्रदर्शन को प्राप्त करता है।', 'ru': 'Наиболее простым подходом к совместной сегментации слов (WS), тегированию части речи (POS) и компонентному синтаксическому анализу является преобразование дерева на уровне слов в дерево на уровне символов, что, однако, приводит к двум серьезным проблемам. Во-первых, больший набор меток (например,  600) и более длинные входные данные увеличивают вычислительные затраты. Во-вторых, трудно исключить незаконные деревья, содержащие противоречащие друг другу правила производства, что имеет важное значение для надежной оценки моделей. Если POS-тег (как VV) находится над тегом фразы (как VP) в выходном дереве, становится довольно сложно определить границы слова. Для решения обеих задач в данной работе предлагается двухступенчатая схема маркировки от грубой до тонкой для совместной WS-POS-PAR. На этапе грубой маркировки совместная модель выводит заключенное в скобки дерево, в котором каждому узлу соответствует одна из четырех меток (т.е. фраза, подфраза, слово, подслово). Дерево гарантированно будет легальным с помощью ограниченного декодирования CKY. На этапе тонкой маркировки модель расширяет каждую крупную метку до конечной метки (например, VP, VP*, VV, VV*). Эксперименты на китайском Penn Treebank 5.1 и 7.0 показывают, что наша совместная модель последовательно превосходит трубопроводный подход по обеим настройкам без и без BERT и достигает новых современных показателей.', 'ga': 'Is é an cur chuige is simplí maidir le deighilt focal comhpháirteach (WS), clibeáil pháirteach cainte (POS), agus parsáil na gcomhábhar ná crann ar leibhéal na bhfocal a thiontú ina chrann leibhéal rua, as a dtagann dhá dhúshlán thromchúiseach, áfach. Ar an gcéad dul síos, méadaíonn tacar lipéad níos mó (m.sh., 600) agus ionchuir níos faide costais ríomhaireachta. Ar an dara dul síos, is deacair crainn mhídhleathacha a bhfuil rialacha táirgeachta contrártha iontu a chur as an áireamh, rud atá tábhachtach le haghaidh meastóireachta samhlacha iontaofa. Má tá clib POS (cosúil le VV) os cionn clib frása (cosúil le VP) sa chrann aschuir, bíonn sé casta go leor teorainneacha focal a chinneadh. Chun déileáil leis an dá dhúshlán, molann an obair seo creat lipéadaithe garbh go mín dhá chéim le haghaidh WS-POS-PAR comhpháirteach. Sa chéim lipéadaithe gharbh, aschuireann an tsamhail chomhpháirteach crann lúibíní, ina gcomhfhreagraíonn gach nód do cheann amháin de cheithre lipéad (i.e. frása, fofhrása, focal, fofhocal). Cinntítear go mbeidh an crann dlíthiúil trí dhíchódú srianta CKY. Sa chéim lipéadaithe mín, leathnaíonn an tsamhail gach lipéad garbh ina lipéad deiridh (amhail VP, VP*, VV, VV*). Léiríonn turgnaimh ar Penn Treebank Síneach 5.1 agus 7.0 go n-éiríonn lenár gcomhshamhail go seasta níos fearr ná an cur chuige píblíne ar an dá shuíomh w/o agus w/ BERT, agus go mbaineann sé feidhmíocht úrscothach amach.', 'el': 'Η πιο απλή προσέγγιση για την κοινή τμηματοποίηση λέξεων (WS), την επισήμανση μέρους ομιλίας (POS) και την ανάλυση συστατικών είναι η μετατροπή ενός δέντρου επιπέδου λέξεων σε δέντρο επιπέδου χαρακτήρων, το οποίο, ωστόσο, οδηγεί σε δύο σοβαρές προκλήσεις. Πρώτον, ένα μεγαλύτερο σύνολο ετικετών (π.χ. 600) και μεγαλύτερες εισόδους αυξάνουν το υπολογιστικό κόστος. Δεύτερον, είναι δύσκολο να αποκλειστούν παράνομα δέντρα που περιέχουν αντικρουόμενους κανόνες παραγωγής, γεγονός που είναι σημαντικό για την αξιόπιστη αξιολόγηση του μοντέλου. Εάν μια ετικέτα (όπως VV) βρίσκεται πάνω από μια ετικέτα φράσης (όπως VP) στο δέντρο εξόδου, γίνεται αρκετά περίπλοκο να αποφασίσετε τα όρια λέξεων. Για την αντιμετώπιση και των δύο προκλήσεων, η παρούσα εργασία προτείνει ένα πλαίσιο ευρείας έως λεπτής σήμανσης δύο σταδίων για κοινή WS-POS-PAR. Στο στάδιο της χονδρικής επισήμανσης, το κοινό μοντέλο παράγει ένα δέντρο με αγκύλες, στο οποίο κάθε κόμβος αντιστοιχεί σε μία από τις τέσσερις ετικέτες (π.χ., φράση, υποφράση, λέξη, υπολέξη). Το δέντρο είναι εγγυημένο να είναι νόμιμο μέσω περιορισμένης αποκωδικοποίησης CKY. Στο στάδιο της λεπτής επισήμανσης, το μοντέλο επεκτείνει κάθε χονδρή ετικέτα σε μια τελική ετικέτα (όπως VP, VP*, VV, VV*). Τα πειράματα στην κινεζική τράπεζα 5.1 και 7.0 δείχνουν ότι το κοινό μοντέλο μας ξεπερνά σταθερά την προσέγγιση του αγωγού και στις δύο ρυθμίσεις του και επιτυγχάνει νέες επιδόσεις τελευταίας τεχνολογίας.', 'ka': 'ყველაზე მხოლოდ სიტყვების სექმენტირება (WS), სიტყვების ნაწილად (POS) და სექმენტების პარასტირება არის სიტყვების ნაწილად სიტყვების ნაწილად სიტყვების ნაწილად სიტყვების ნაწილად, რომელიც ორი ძალიან პირველად, დიდი მართლის შენახვა (მაგალითად, 600) და უფრო მეტი მართლის შენახვა ორივე კომპუტაციალური პასუხი. მეორე, ძალიან რთულია გადაწყენოთ illegal trees containing conflicting production rules, which is important for reliable model evaluation. თუ POS ნიშანი (როგორც VV) გამოყენებული ხეში ფრაზის ნიშანის (როგორც VP) ზემოთ, სიტყვების ზემოთ გადაწყენება უფრო კომპლექსია. ამ სამუშაო მუშაოდ ორი განსაზღვრებისთვის შესაძლებელია, რომელიც საერთო WS-POS-PAR-ისთვის ორი განსაზღვრებულია. ჩვენი მარტივის სტაზაში ერთადერთი მოდელი გადატანა ბრაკეტული ხე, რომელიც ყოველ კონფიგურაცია ერთი ოთხი მარტივის (მაგალითად, ფრაზა, სტრაზაცია, სიტყვა, სტრაზაცია). ეყპგჲრჲ ვ დაპანრთპანჲ ეა ვ ლვდალნჲ, ოპვჱ ჲდპანთპანთვ ნა CKY ევკჲეთპაŒვ. მარტივის მარტივის ფაეზში, მოდელი ყოველ გარეშე etiket გაფარდება ბოლო etiket (როგორც VP, VP*, VV, VV*). ჩინეთის პენ Treebank 5. 1 და 7. 0 ექსპერიმენტები აჩვენებენ, რომ ჩვენი ერთადერთი მოდელი მუშაობელად გავაკეთებენ გარეშე გარეშე გარეშე w/ o და w/ BERT-ის ორივე პარამეტრებზე და მიიღებენ ახალი გარეშე.', 'hu': 'A közös szószegmentáció (WS), a beszédrész (POS) címkézés és az alkotóelemek elemzésének legegyszerűbb megközelítése a szószintű fát karakterszintű fává alakítja át, ami azonban két komoly kihíváshoz vezet. Először is, a nagyobb címkekészlet (pl. 600) és a hosszabb bemenet egyaránt növeli a számítási költségeket. Másodszor, nehéz kizárni az ellentétes termelési szabályokat tartalmazó illegális fákat, ami fontos a megbízható modellértékelés szempontjából. Ha egy POS tag (például VV) egy kifejezéscímke fölött van a kimeneti fában (például VP), elég bonyolulttá válik a szóhatárok meghatározása. Mindkét kihívás kezelése érdekében ez a munka a közös WS-POS-PAR kétlépcsős, durva és finom címkézési keretrendszerét javasolja. A durva címkézési szakaszban a közös modell zárójeles fát ad ki, amelyben minden egyes csomópont megfelel a négy címke egyikének (azaz kifejezés, alcím, szó, alcím). A fa garantáltan legális a korlátozott CKY dekódolással. A finom címkézési szakaszban a modell minden durva címkét egy végleges címkévé bővít (például VP, VP*, VV, VV*). A kínai Penn Treebank 5.1 és 7.0 kísérletei azt mutatják, hogy a közös modellünk következetesen felülmúlja a vezetékek megközelítését mind a w/o, mind a w/ BERT beállításaiban, és új, korszerű teljesítményt ér el.', 'it': "L'approccio più semplice alla segmentazione congiunta delle parole (WS), al tag part-of-speech (POS) e all'analisi costituente è convertire un albero a livello di parola in un albero a livello di caratteri, il che, tuttavia, porta a due gravi sfide. In primo luogo, un set di etichette più grande (ad esempio 600) e ingressi più lunghi aumentano entrambi i costi di calcolo. In secondo luogo, è difficile escludere alberi illegali contenenti norme di produzione contrastanti, cosa importante per una valutazione affidabile dei modelli. Se un tag POS (come VV) è sopra un tag di frase (come VP) nell'albero di output, diventa abbastanza complesso decidere i confini delle parole. Per affrontare entrambe le sfide, questo lavoro propone un quadro di etichettatura in due fasi per WS-POS-PAR congiunto. Nella fase di etichettatura grossolana, il modello congiunto emette un albero parentesi, in cui ogni nodo corrisponde a una delle quattro etichette (ad esempio, frase, sottofrase, parola, sottoparola). L'albero è garantito per essere legale tramite la decodifica CKY vincolata. Nella fase di etichettatura fine, il modello espande ogni etichetta grossolana in un'etichetta finale (come VP, VP*, VV, VV*). Esperimenti su Penn Treebank cinese 5.1 e 7.0 mostrano che il nostro modello congiunto supera costantemente l'approccio pipeline su entrambe le impostazioni di w/o e w/BERT, e raggiunge nuove prestazioni all'avanguardia.", 'kk': 'Бірлестірілген сөздердің сегментациясының (WS), сөздердің бөлігі (POS) тегтері және бөліктердің талдауы сөздердің деңгейінің ағашын таңбаша деңгейіне аударып, бірақ бұл сөздердің екі қатты мәселелеріне өзгерт Біріншіден, үлкен жарлығы (мысалы, 600) және ұзындығы есептеу бағаттарын екеуі көтереді. Екіншіден, сенімді үлгілерді бағалау үшін қайшылық өндіру ережелері бар жарамсыз ағаштарды шешу қиын. Егер POS тегті (VV сияқты) шығыс бұтақтағы фраз тегтің (VP сияқты) үстінде болса, сөздің шектерін шешу мүмкіндік болады. Екі мәселелерді шешу үшін, бұл жұмыс біріктірілген WS-POS-PAR үшін екі этап жарлық жарлық жарлық қоршауын ұсынады. Бірлескен жарлықты белгілеу кезегінде, біріктірілген үлгісі біріктірілген ағаш шығарылады. Әрбір түрде төрт жарлықтың біріне сәйкес келеді (мысалы, сөз, субфрейз, сөз, субсөз). Бұтақ CKY декодтамасы шектелген арқылы юридикалық болуын талап етеді. Жарлық жарлықтау кезегінде, әрбір жарлық жарлығын соңғы жарлығына кеңейту үшін (VP, VP*, VV, VV*) кеңейту үлгісі. Қытайша Penn Treebank 5. 1 және 7. 0 тәжірибелерінде біздің біріктірілген моделіміз w/ o және w/ BERT параметрлерінің қайшылығын жұмыс істеп жатқан және жаңа орындау күйіне жеткізеді.', 'lt': 'The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges.  Pirma, didesnis etiketės rinkinys (pvz., 600) ir ilgesni duomenys padidina skaičiavimo sąnaudas. Antra, sunku atmesti neteisėtus medžius, kuriuose yra prieštaringų gamybos taisyklių, kurie yra svarbūs patikimam modelio vertinimui. Jei POS žymenys (kaip VV) yra virš išėjimo medžio frazės žymens (kaip VP), nusprendžiant žodžių ribas tampa gana sudėtinga. Siekiant išspręsti abu uždavinius, šiame darbe siūloma dviejų etapų bendro WS-POS-PAR ženklinimo sistema. Dideliame ženklinimo etape jungtinis modelis gamina skliaustelinį medį, kuriame kiekvienas mazgas atitinka vieną i š keturių etikečių (t. y. frazę, parašą, žodį, parašą). Užtikrinama, kad medis yra teisėtas ribojant CKY kodavimą. Tinkamame ženklinimo etape modelis išplečia kiekvieną didžiąją etiketę į galutinę etiketę (pvz., VP, VP*, VV, VV*). Eksperimentai su Kinijos švirkštiklių medžio banku 5.1 ir 7.0 rodo, kad mūsų bendras modelis nuosekliai viršija vamzdynų metodą, taikomą ir pagal w/o, ir w/BERT nustatymus, ir pasiekia naujų pažangiausių rezultatų.', 'mk': 'Наједноставниот пристап до заедничката сегментација на зборови (WS), означувањето на дел од говорот (POS) и анализирањето на конститутите е претворањето на дрво на зборови во дрво на ниво на знаци, што, сепак, води до два сериозни предизвици. Прво, поголемиот нацрт на етикети (на пример, 600) и подолгите внесувања ги зголемуваат компјутациските трошоци. Второ, тешко е да се исклучат илегалните дрвја кои содржат конфликтни производствени правила, што е важно за доверлива проценка на моделот. Ако POS tag (како VV) е над фраза tag (како VP) во излезната дрва, станува доста комплексно да се одлучат границите на зборовите. За да се справи со двата предизвици, оваа работа предложува двофазична рамка за обележување на обележување на обележување на глупости до фини за заедничката WS-POS-PAR. Во стадијата на грубата етикета, заедничкиот модел излегува од дрво со појачување, во кое секој јазол одговара на една од четирите етикети (т.е., фраза, подфраза, збор, подзбор). Дрвото е гарантирано да биде легално преку ограничено CKY декодирање. Во фината фаза на етикетирање, моделот ја проширува секоја груба етикета во финална етикета (како што се VP, VP*, VV, VV*). Експериментите на Кинескиот пен дрвен банк 5.1 и 7.0 покажуваат дека нашиот заеднички модел константно го надминува пристапот на гасоводот на двете поставувања на w/o и w/BERT, и постигнува нова најсовремена претстава.', 'mt': 'L-approċċ l-aktar sempliċi għas-segmentazzjoni konġunta tal-kliem (WS), it-tikkettar tal-parti tad-diskors (POS), u l-analiżi kostitwenti qed jikkonverti siġar fil-livell tal-kliem f’siġar fil-livell tal-karattri, li madankollu jwassal għal żewġ sfidi severi. First, a larger label set (e.g.,  600) and longer inputs both increase computational costs.  It-tieni nett, huwa diffiċli li jiġu esklużi siġar illegali li fihom regoli ta’ produzzjoni konfliġġenti, li huwa importanti għal evalwazzjoni affidabbli tal-mudell. Jekk tikketta POS (bħal VV) tkun ’il fuq minn tikketta ta’ frażi (bħal VP) fis-siġra tal-ħruġ, issir pjuttost kumplessa li tiddeċiedi l-limiti tal-kliem. Biex jiġu indirizzati ż-żewġ sfidi, din il-ħidma tipproponi qafas ta’ tikkettar ta’ żewġ stadji gross-to-fine għal WS-POS-PAR konġunta. Fl-istadju tat-tikkettar gross, il-mudell tal-ġogi joħroġ siġar bil-parentesi, li fih kull nodu jikkorrispondi għal waħda minn erba’ tikketti (jiġifieri frażi, sottofrażi, kelma, sottokelma). Is-siġar huwa garantit li jkun legali permezz ta’ dekodifikazzjoni ristretta tas-CKY. Fl-istadju ta’ tikkettar fin, il-mudell jespandi kull tikketta grossa f’tikketta finali (bħal VP, VP*, VV, VV*). L-esperimenti fuq il-Pinna Treebank Ċiniża 5.1 u 7.0 juru li l-mudell konġunt tagħna b’mod konsistenti jeċċedi l-approċċ tal-pipeline fuq iż-żewġ settijiet ta’ w/o u w/BERT, u jikseb prestazzjoni ġdida ta’ l-aktar avvanzata.', 'no': 'Den enklere tilnærminga til samsvarande ordsegmentasjon (WS), del av tale (POS) er å konvertera eit ordnivåtreet til eit teiknivåtreet, som imidlertid fører til to vanskeleg utfordringar. Først sett eit større merkelapp (f.eks. 600) og lenger innfører begge økt datakostnader. Andre, er det vanskeleg å avslutta illegale trær som inneheld konflikt produksjonsreglar, som er viktig for tiltruleg evaluering av modeller. Dersom eit POS- merkelapp (som VV) er over eit frase- merkelapp (som VP) i utdata- treet, blir det ganske komplisert å bestemma ordgrensa. For å handtera begge utfordringar, foreslår denne arbeidet ein to stadig farge-til-fint etiketteringsrammeverk for joint WS-POS-PAR. I staden for merkelappen utfører samlingsmodulet e in parentesen tre, der kvar node tilsvarar e i av fire merkelapper (t.d. frase, underfrase, ord, underord). Treet vert garantert til å vera rett ved å avgrensa CKY- koding. I den finte merkelappen utvidar modellen kvar merkelappen til ein sluttmerkelapp (som VP, VP*, VV, VV*). Eksperimentar på kinesisk Penn Treebank 5. 1 og 7. 0 viser at vår samlingsmodul konsistent utfører rørslinjetilnærminga på både innstillingar av w/ o og w/ BERT, og oppnår nye kunstfullføring.', 'ms': 'Pendekatan yang paling mudah untuk segmentasi perkataan kongsi (WS), tag bahagian-dari-ucapan (POS), dan penghuraian komponen adalah menukar pokok aras-perkataan ke pokok aras-aksara, yang, bagaimanapun, membawa kepada dua cabaran yang berat. Pertama, set label yang lebih besar (contohnya, . 600) dan input yang lebih panjang kedua-dua meningkatkan biaya pengiraan. Kedua, sukar untuk mengeluarkan pokok haram yang mengandungi peraturan produksi yang berkonflik, yang penting untuk penilaian model yang boleh dipercayai. Jika tag POS (seperti VV) berada di atas tag frasa (seperti VP) dalam pokok output, ia menjadi agak kompleks untuk memutuskan sempadan perkataan. Untuk menghadapi kedua-dua cabaran, kerja ini melaporkan kerangka label dua tahap kasar-kepada-baik untuk WS-POS-PAR bersama. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e., phrase, subphrase, word, subword).  Pohon dijamin untuk sah melalui pengekodan CKY yang dikuasai. Dalam tahap label halus, model mengembangkan setiap label tebal ke label akhir (seperti VP, VP*, VV, VV*). Eksperimen pada Pinn Treebank Cina 5. 1 dan 7. 0 menunjukkan bahawa model kongsi kita secara konsisten melebihi pendekatan paip pada kedua- dua tetapan w/ o dan w/ BERT, dan mencapai prestasi state- of- the- art baru.', 'ml': 'വാക്ക് സംഘത്തിലേക്ക് ചേര്\u200dക്കാന്\u200d ഏറ്റവും നേരിട്ടുള്ള അടുത്തേക്ക്, വാക്കിന്റെ ഭാഗം (പോഎസ്) ടാഗിങ്ങ് ചേര്\u200dന്ന് പാര്\u200dസിങ് ഒരു വാക്ക് നില വൃക്ഷ ആദ്യം, ഒരു വലിയ ലേബ്ലെറ്റ് സെറ്റ് (ഉദാഹരണത്തിന്, 600) കൂടുതല്\u200d ഇന്\u200dപുട്ടുകളും കണക്കൂട്ടിക്കൊണ്ടുള്ള വില കൂടു രണ്ടാമത്തേത്, നിയമവൃക്ഷങ്ങളെ നിയന്ത്രിക്കാന്\u200d പ്രയാസകരമാണ്, കുഴപ്പമുള്ള ഉല്\u200dപാദിപ്പിന്റെ നിയമങ്ങള്\u200d ഉള്\u200dപ്പ Name രണ്ടു വിലാസങ്ങളുടെയും കൈകാര്യം ചെയ്യാന്\u200d ഈ ജോലി രണ്ട് സ്റ്റേജ് കോര്\u200dസില്\u200d നിന്നും നല്ല ല ലേബില്\u200d ഫ്രെയിക്ക് പ്രായസ്ത് തെരുക്കിന്റെ ലേബിള്\u200d സ്റ്റേജില്\u200d, യൂണ്ട് മോഡല്\u200d ഒരു ബ്രാക്കെറ്റ് കെട്ടിട്ടുള്ള വൃക്ഷത്തിന്റെ പുറത്ത് വരുന്നു. അതില്\u200d ഓരോ നോഡും നാല് ലേബിള്\u200dക CKY ഡികോഡിങ്ങില്\u200d നിയന്ത്രിക്കപ്പെട്ടിരിക്കുന്നതിന് വേണ്ടി ഈ മരത്തെ നിയമമായി ഉറപ്പാണ്. നല്ല ല ലേബിള്\u200d സ്റ്റേജില്\u200d, ഓരോ കോര്\u200dസ് ലേബിലേറ്റിനും അവസാനത്തെ ലേബലിലേക്ക് മാതൃകയാണു് (VP, VP*, VV, VV*) പോലെ. ചൈനീസ് പെന്\u200d ട്രീബാങ്കിന്\u200dറെ 5. 1, 7. 0 എന്ന പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ യൂട്ട് മോഡല്\u200d കൂടുതല്\u200d പൈപ്പൈലൈന്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത് w/O, w/ BERT സജ', 'mn': 'Хамгийн энгийн арга баримтууд нь үг хэвлэлийн хэсэг (WS), хэлэлцээний хэсэг (POS) маркинг болон хэмжээний хуваалцах нь үг хэмжээний модыг шар хэмжээний мод руу шилжүүлж байна. Гэхдээ энэ нь хоёр чухал сорилт болгодог. Эхлээд том загвар (жишээлбэл, 600) болон урт нь тооны зардал хоёуланг нэмэгдүүлдэг. Хоёрдугаарт, бусад хуулийн мод нь зөрчилдөөн үйлдвэрлэлийн дүрмийг агуулдаг. Энэ нь итгэлтэй загварын үнэлгээнд чухал. Хэрвээ POS тегт (VV шиг) нь үг хязгаарыг шийдвэрлэхэд (VP шиг) үгийн тегт дээр байвал илүү нарийн болно. Хоёр сорилтуудын тулд энэ ажил хоёр дахь дахь загварын загварын загварын загварын загварын тулд WS-POS-PAR хоёр дахь загварын загварын загвар өгдөг. Холбоотой загвар нь холбоотой модыг гаргадаг. Холбоотой бүр дөрвөн загварын нэгтэй холбоотой. Мод нь хязгаарлагдсан CKY хууль болох байх. Загвар нь загвар бүр сүүлийн загвар руу шилжүүлдэг (VP, VP*, VV, VV*) гэх мэт. Хятад Пенс Treebank 5.1 болон 7.0-ын туршилтын туршилтууд бидний нийлбэр загвар w/o болон w/BERT-ийн хоёр тохиолдолд хоолойн шугам загварыг үргэлж үзүүлдэг ба шинэ урлагийн үйл ажиллагааг гаргадаг.', 'sr': 'Najjednostavniji pristup zajedničkoj segmentaciji reči (WS), dijelom govora (POS) označavanju, i razmatranje sastavnih uloga je pretvaranje drveta na nivo reči u drvo na nivo šarma, što međutim vodi do dva teška izazova. Prvo, veći set etiketa (npr. 600) i duži ulazi i povećava računalne troškove. Drugo, teško je isključiti ilegalno drvo koje sadrže sukobe pravila proizvodnje, što je važno za pouzdanu ocjenu modela. Ako je znak POS (poput VV) iznad znaka fraze (poput VP) u drvetu izlaska, postaje kompleksno odlučiti granice riječi. Da bi se riješio obe izazove, ovaj rad predlaže okvir za zajedničku WS-POS-PAR-u. U toj fazi oznake, zajednički model iznosi narukviceno drvo, u kojem svaki čvor odgovara jednoj od četiri etikete (tj. fraze, podfraze, reč, podreč). Drvo se garantuje da bude legalno preko ograničenog dekodiranja CKY-a. U finoj fazi označavanja, model se proširi svaka etiketa u konačnu etiketu (kao što su VP, VP*, VV, VV*). Eksperimenti na kineskoj Penn Treebank 5.1 i 7.0 pokazuju da naš zajednički model konsekventno iznosi pristup cijevi na obje postavke w/o i w/ BERT-a, i postiže novi postupak umjetnosti.', 'si': 'සම්බන්ධ වචනය (WS), කොටස් කිරීම (POS) ටැග් කරනවා වචනය සම්බන්ධ වර්ගයක් පරිවර්තනය කරනවා වචනය සම්බන්ධ වර්ගයක් චාර්ට් ලේවල් වර්ගයක් වලට, ඒකෙ මුලින්ම, වැඩි ලේබල් සෙට් වෙනවා (උදාහරණය, 600) සහ වැඩි ලේබල් සෙට් වෙනවා පරිගණනය විශාලයක් දෙන්නම්. දෙවෙනි වෙනුවෙන්, අනීතිමත් ගස්ස් එක්ක ප්\u200dරදේශ නීතියක් තියෙන්න අමාරුයි, ඒක විශ්වාස කරන්න ප්\u200dරමාණය POS ටැග (VV වගේ) ප්\u200dරකාශ ටැග (VP වගේ) ප්\u200dරකාශ වර්ගයේ ඉහළට තියෙනවනම්, වර්ගය සීමාව තීරණය කරන්න පුළුවන් ප්\u200dරශ්ණ දෙන්නම ප්\u200dරශ්නයක් තියෙන්න, මේ වැඩේ ප්\u200dරශ්නයක් තියෙනවා සම්බන්ධ WS-POS කෝර්ස් ලේබලින්ග් ස්ථානයේදී, සම්බන්ධ මොඩේල් එක බ්\u200dරැකෙට් ගස් එකක් පිළිගන්නවා, ඒ වගේම හැම නෝඩ් හතරක් ලේබල් එකක් එකක් සම්බන මේ ගස්සය CKY ඩිකොඩ් එකෙන් නීතිමත් වෙන්න පුළුවන් වෙනවා. හොඳ ලේබල් පද්ධතියේ, මොඩල් හැම කෝර්ස් ලේබල් එකක් අන්තිම ලේබල් වලට විස්තර කරනවා (VP, VP*, VV, VV*). චීනී පෙන් ට්\u200dරී බැන්ක් 5.1 සහ 7.0 වල පරීක්ෂණය පෙන්වනවා අපේ සම්බන්ධ මොඩේල් එක සාමාන්\u200dය විදිහට w/o සහ w/ BERT වල සැකසුම් දෙන්නම් පායිප්ලා', 'pl': 'Najprostszym podejściem do wspólnej segmentacji słów (WS), tagowania części mowy (POS) i parsowania składników jest przekształcenie drzewa na poziomie słowa w drzewo na poziomie znaków, co jednak prowadzi do dwóch poważnych wyzwań. Po pierwsze, większy zestaw etykiet (np. 600) i dłuższe wejścia zwiększają koszty obliczeniowe. Po drugie, trudno jest wykluczyć nielegalne drzewa zawierające sprzeczne zasady produkcji, co jest ważne dla wiarygodnej oceny modelu. Jeśli znacznik POS (jak VV) znajduje się ponad znacznikiem fraz (jak VP) w drzewie wyjściowym, decydowanie o granicach słów staje się dość skomplikowane. Aby sprostać obu wyzwaniom, w niniejszej pracy proponowano dwustopniowe ramy etykietowania grube do drobne dla wspólnego WS-POS-PAR. Na etapie etykietowania grubego wspólny model wydaje drzewo w nawiasie, w którym każdy węzeł odpowiada jednej z czterech etykiet (tj. fraze, podfraza, słowo, podsłowo). Drzewo jest gwarantowane legalnie dzięki ograniczonemu dekodowaniu CKY. Na etapie drobnego etykietowania model rozszerza każdą grubą etykietę na końcową etykietę (taką jak VP, VP*, VV, VV*). Eksperymenty na chińskim Penn Treebank 5.1 i 7.0 pokazują, że nasz wspólny model konsekwentnie przewyższa podejście do rurociągu w obu ustawieniach w/o i w/BERT oraz osiąga nowe, najnowocześniejsze wydajności.', 'ro': 'Cea mai simplă abordare a segmentării comune a cuvintelor (WS), etichetării părții de vorbire (POS) și analizării constitutive este transformarea unui arbore de nivel de cuvânt într-un arbore de nivel de caracter, ceea ce, cu toate acestea, duce la două provocări grave. În primul rând, un set de etichete mai mare (de exemplu, 600) și intrări mai lungi cresc costurile de calcul. În al doilea rând, este dificil să se excludă copacii ilegali care conțin norme de producție contradictorii, ceea ce este important pentru evaluarea fiabilă a modelului. Dacă o etichetă POS (cum ar fi VV) se află deasupra unei etichete de expresie (cum ar fi VP) în arborele de ieșire, devine destul de complex să decidă limitele cuvintelor. Pentru a face față ambelor provocări, această lucrare propune un cadru de etichetare grosieră până la fină în două etape pentru WS-POS-PAR comun. În etapa de etichetare grosieră, modelul comun produce un arbore parantezat, în care fiecare nod corespunde uneia din cele patru etichete (de exemplu, frază, subfrază, cuvânt, subcuvânt). Arborele este garantat a fi legal prin decodarea CKY constrânsă. În etapa de etichetare fină, modelul extinde fiecare etichetă grosieră într-o etichetă finală (cum ar fi VP, VP*, VV*). Experimentele efectuate pe Penn Treebank chinezesc 5.1 și 7.0 arată că modelul nostru comun depășește în mod constant abordarea conductelor în ambele setări de w / o și w / BERT și obține noi performanțe de ultimă generație.', 'so': 'Dhaqdhaqaaqa ugu toosan ee u dhexeeya hadalka isku xiran (WS), qayb ka mid ah hadalka (POS) tagging, baaritaanka baaritaanku wuxuu beddelinayaa geed heer ah oo ku qoran geed xaraf ah, taasoo, habase yeeshee, waxay u jeedaa laba dhibaatooyin oo adag. Marka ugu horeysa, mid ka weyn calaamada (tusaale, 600) iyo mid ka sii dheer input labadooda waxaa kordhiya kharashka xisaabinta. Second, waa adag tahay in la xukumo geedaha sharciga ah oo ku jira sharciyada soo saarashada, taas oo muhiim ah in lagu qiimeeyo model aamin ah. If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries.  Si ay u qabtaan labada dhibaatooyin, shuqulkaas wuxuu soo jeedaa koox-two-stage-to-fine-lab framework for joint WS-POS-PAR. Tilmaamaha koorsigu wuxuu ka soo saaraa geed qalcadaysan oo qof kastaaba uu u eg yahay mid ka mid ah afarta calaamad (tusaale ahaan af, hadal, hadal, hoose). Geedka waxaa looga guarantan yahay sharciyeed codsiga CKY oo qasab ah. Qoraalka aad u fiirsaneyso ayaa modelku ku fidiyaa calaamad kasta oo koorsooyin ah wuxuu u bedelaa calaamad ugu dambeysa (sida VP, VP*, VV, VV*). Imtixaanka ku saabsan Penn Treebank 5.1 iyo 7.0 waxay muuqataa in noocyada wadajirka ah uu si joogto ah u sameynayo qaababka looga baaraandegayo qoraalka u dhexeeya w/o iyo w/ BERT, wuxuuna gaadhaa xaaladda cusub ee farshaxanka.', 'ta': 'வார்த்தை பிரிப்பத்துடன் சேர்க்க நேரடியாக அணுகும், பேச்சின் பாகம் (POS) குறிக்கும் பகுதி மற்றும் தொகுப்பாளர் பாடல் ஒரு வார்த்தை மட்டத்தில் ஒரு வரைமட் முதலில், ஒரு பெரிய விளக்கச்சீட்டு அமைப்பு (உதாரணமாக, 600) மற்றும் நீண்ட உள்ளீடுகள் இருவரும் கணக்கிட விலைகளை அதிகரிக Second, it is difficult to rule out illegal trees containing conflicting production rules, which is important for reliable model evaluation.  வெளியீட்டு மரத்தில் ஒரு POS ஒட்டு (VV போன்ற) வார்த்தையின் ஒட்டு (விபி) மேல் இருந்தால், வார்த்தை எல்லைகளை தீர்மானிக்க ம இரண்டு சவால்களையும் நிர்வகிக்க, இந்த வேலை விரும்புகிறது WS-POS-PAR சேர்ந்த இரண்டு stage coarse-to-fine-labeling சட்டம். தெற்கையின் சிட்டையின் முறைமையில், இணைப்பு மாதிரி ஒரு குறிப்பிட்ட மரத்தை வெளியிடுகிறது, அதில் ஒவ்வொரு நாட்டு சிட்டைகளுக்கும் ஒப்புரையும கட்டுப்படுத்தப்பட்ட CKY குறிமுறையாக்கம் வழியாக மரம் சட்டமாக இருக்கும் என்று உறுதிப்படுத்தப்படுக நல்ல குறியீட்டு நிலையில், மாதிரி ஒவ்வொரு குறியீட்டின் விளக்கச்சீட்டை கடைசி விளக்கச் சீட்டாக விரிவாக்குகிறது (விப Name', 'ur': 'ایک کلمه جدائی (WS) کے زیادہ سیدھا تقریبا ہے، ایک کلمه جدائی (POS) کے ٹاگ، اور ایک مجموعہ جدائی کا تقریبا ہے کہ ایک کلمه سطح درخت کو ایک چار سطح درخت میں تبدیل کرتا ہے، جسے چاہے دو سخت چالیں پہنچتا ہے۔ پہلے، ایک بڑا لیبل سٹ (مثال → 600) اور دور دراز کمپیوٹر کی قیمت دونوں کو اضافہ کرتا ہے۔ دوسرا، یہ غیرقانونی درختوں کو دور کرنے کا مشکل ہے جو پیدا کرنے کے قانون میں مختلف ہیں، جو یقین رکھنے والی موڈل کے لئے اہم ہے. اگر ایک POS ٹاگ (جیسا VV) آئٹ درخت میں ایک فریز ٹاگ (جیسا VP) کے اوپر ہے تو کلمات کے حدوں کا فیصلہ کرنا بہت پیچیدہ ہوجاتا ہے۔ دونوں چالوں کے ساتھ استعمال کرنے کے لئے، یہ کام دو سٹیج کی کورس-تا-پاکیزہ لابلینگ فرم کی پیشنهاد کرتا ہے جو joint WS-POS-PAR کے لئے ہے. کورس لابلینگ سٹیج میں، جونس موڈل ایک برکت درخت نکالتا ہے، جس میں ہر نود چار لابل میں سے ایک کے مطابق ملتا ہے (یعنی فرض، subphrase, word, subword). اس درخت کو قانون رکھا گیا ہے کہ CKY دکھانے کے ذریعہ مجبور ہوگا۔ اچھی لابلینگ سٹیج میں، موڈل ہر کورس لابلیج کو آخری لابلیج میں پھیلاتا ہے (جیسے VP, VP*, VV, VV*). چین پن تری بینک 5.1 اور 7.0 کے تجربے دکھاتے ہیں کہ ہمارے جولنٹ موڈل کو w/o اور w/ BERT کے دونوں سیٹیوں پر پائپ لین طریقے سے زیادہ کامل کرتے ہیں اور نئی ایٹیوں کی عملکرد پہنچاتے ہیں.', 'sv': 'Den mest okomplicerade metoden för gemensam ordsegmentering (WS), POS-märkning och komponenttolkning är att omvandla ett ordnivåträd till ett tecken-nivå träd, vilket dock leder till två allvarliga utmaningar. För det första ökar både en större etikettuppsättning (t.ex. 600) och längre ingångar beräkningskostnaderna. För det andra är det svårt att utesluta olagliga träd som innehåller motstridiga produktionsregler, vilket är viktigt för tillförlitlig modellutvärdering. Om en POS-tagg (som VV) ligger ovanför en frastagg (som VP) i utdataträdet blir det ganska komplicerat att bestämma ordgränser. För att hantera båda utmaningarna föreslår detta arbete en tvåstegs grov till fin märkningsram för gemensam WS-POS-PAR. I den grova märkningsstadiet ger den gemensamma modellen ut ett parentessträd, där varje nod motsvarar en av fyra etiketter (dvs fras, underfras, ord, underord). Trädet är garanterat lagligt genom begränsad CKY avkodning. I finmärkningsstadiet expanderar modellen varje grov etikett till en slutlig etikett (t.ex. VP, VP*, VV, VV*). Experiment på Chinese Penn Treebank 5.1 och 7.0 visar att vår gemensamma modell konsekvent överträffar pipeline-metoden på båda inställningarna av w/o och w/BERT, och uppnår ny state-of-the-art prestanda.', 'uz': "Name Birinchi marta katta yorliq belgilangan (m. g., 600) va uzoq kiritish hamma kompyuterning qiymatini oshirish. Ikkinchi so'zda, murakkablik produktlar qoidalari bilan harakat daraxtlarni boshqarish juda qiyin, bu muammo modelni qiymatga muhim. @ info: whatsthis Ikkita muammolar bilan boshqarish uchun bu ishni WS-POS-PAR birlashtirish uchun ikki darajada yaxshi ko'paytirish qoidasini anglatadi. Koʻrsatilgan tugmalar birikmasida bir bir bir bir tugma boshlanadi. Bu yerda har biri to'rtta lab- ketlikga qisqaraydi. Daraxt CKY kodlash orqali shart bo'lishi mumkin. In the fine labeling stage, the model expands each coarse label into a final label (such as VP, VP*, VV, VV*).  Name", 'vi': 'Cách tiếp cận rõ ràng nhất tới việc phân biệt các chữ một cách tổng hợp (WS), định nghĩa một phần của bài phát âm (POS) và phân tích nội dung là chuyển một cây ở mức chữ thành một cây chỉ, mà, tuy nhiên, dẫn tới hai thử thách nghiêm trọng. Đầu tiên, một bộ nhãn lớn hơn (v.d. 600) và lượng nhập dài hơn cả hai đều tăng giá trị tính. Thứ hai, rất khó để loại bỏ những cây trái phép có những quy tắc sản xuất mâu thuẫn, điều đó rất quan trọng cho mô hình đáng tin cậy. Nếu một thẻ POS (như VV) nằm trên một nhãn từ (như Phó) trong cây xuất, nó trở nên rất phức tạp để quyết định ranh giới từ. Để đối phó với cả hai thử thách, dự án này đề nghị một dàn xếp đặt cạnh lề hai giai đoạn cho W-POS-PAR. Trong giai đoạn đánh dấu thô, mô- đun khớp sẽ xuất ra một cây liên kết, trong đó mỗi nút tương ứng với một trong bốn nhãn (tức là cụm từ, chữ dưới, từ, chữ phụ). Cây được đảm bảo hợp pháp bằng cách giải mã CK bị hạn chế. Trong giai đoạn đánh dấu cẩn thận, mô- đun này sẽ mở rộng các nhãn rộng thành nhãn cuối (v.d. Các thí nghiệm trên China Penn Treebank 5.1 và 7.0 cho thấy rằng mô hình chung của chúng ta hoàn toàn vượt qua các phương pháp dẫn đường trên cả hai thiết lập w/o và w/ BERT, và đạt được một trình độ mới.', 'bg': 'Най-простият подход към съвместна сегментация на думи (WS), маркиране на част от речта (ПОС) и съставно анализиране е превръщането на дърво на ниво дума в дърво на ниво символ, което обаче води до две сериозни предизвикателства. Първо, по-големият набор от етикети (например 600) и по-дългите входове увеличават изчислителните разходи. Второ, трудно е да се изключи незаконните дървета, съдържащи противоречиви производствени правила, което е важно за надеждна оценка на моделите. Ако ПОС таг (като VV) е над фразов таг (като VP) в изходното дърво, става доста сложно да се определят границите на думите. За да се справи и с двете предизвикателства, тази работа предлага двуетапна рамка за етикетиране от грубо до фино за съвместна WS-POS-PAR. В етапа на грубо етикетиране съвместният модел извежда скоби дърво, в което всеки възел съответства на един от четирите етикета (т.е. фраза, субфраза, дума, поддума). Дървото е гарантирано, че е законно чрез ограничено декодиране. В етапа на фино етикетиране моделът разширява всеки груб етикет в окончателен етикет (като VP, VP*, VV, VV*). Експериментите на китайския Пен Трейбанк 5.1 и 7.0 показват, че нашият съвместен модел постоянно превъзхожда подхода на тръбопровода и при двете настройки на без/без и без/БЕРТ и постига ново най-съвременно представяне.', 'da': 'Den mest ligetil tilgang til fælles ordsegmentering (WS), POS-taggning (part-of-speech) og komponentfortolkning er at konvertere et ordniveau træ til et tegn-niveau træ, hvilket dog fører til to alvorlige udfordringer. For det første øger et større labelsæt (f.eks. 600) og længere input begge beregningsomkostninger. For det andet er det vanskeligt at udelukke ulovlige træer med modstridende produktionsregler, hvilket er vigtigt for en pålidelig modelvurdering. Hvis et POS-tag (som VV) ligger over et sætningstag (som VP) i outputtræet, bliver det ret komplekst at bestemme ordgrænser. For at håndtere begge udfordringer foreslår dette arbejde en to-trins grov-til-fin mærkningsramme for fælles WS-POS-PAR. I den grove mærkning fase udsender den fælles model et parentes træ, hvor hver knude svarer til en af fire etiketter (dvs. sætning, underformulering, ord, underord). Træet er garanteret at være lovligt via begrænset CKY afkodning. I den fine mærkning fase udvider modellen hver grov etiket til en endelig etiket (f.eks. VP, VP*, VV, VV*). Eksperimenter med kinesisk Penn Treebank 5.1 og 7.0 viser, at vores fælles model konsekvent overgår pipeline-tilgangen på begge indstillinger af w/o og w/BERT, og opnår nye state-of-the-art ydeevne.', 'hr': 'Najjednostavniji pristup zajedničkom segmentaciji riječi (WS), dijelom govora (POS) označavanju, a dijelom razmatranja komponenta preobraća drvo na razinu riječi u drvo na razinu čara, što međutim vodi do dva teška izazova. Prvo, veći nastav etikete (npr. 600) i duži ulazi i povećava računalne troškove. Drugo, teško je isključiti ilegalne drveće koje sadrže sukobne pravila proizvodnje, što je važno za pouzdanu procjenu modela. Ako je oznaku POS (poput VV) iznad oznaku fraze (poput VP) u drvetu izlaza, postaje kompleksno odlučiti granice riječi. Za rješavanje obe izazova, ovaj rad predlaže okvir za zajedničku WS-POS-PAR-u za dva stupnja. U toj fazi oznake, zajednički model iznosi narukviceno drvo, u kojem se svaki čvor odgovara jednoj od četiri etikete (tj. fraza, podfraza, riječ, podriječ). Drvo se garantuje da bude pravno preko ograničenog dekodiranja CKY-a. U dobroj fazi označavanja, model se proširi svaku označenu etiketu u konačnu etiketu (poput VP, VP*, VV, VV*). Eksperimenti na kineskoj Penn Treebank 5.1 i 7.0 pokazuju da naš zajednički model konsekventno nadmašuje pristup cijevi na obje postavke w/o i w/ BERT-a i postiže novi postupak umjetnosti.', 'nl': 'De meest eenvoudige aanpak voor gezamenlijke woordsegmentatie (WS), part-of-speech (POS) tagging en constitution parsing is het omzetten van een boom op woordniveau in een boom op tekenniveau, wat echter leidt tot twee grote uitdagingen. Ten eerste verhogen een grotere labelset (bijv. 600) en langere inputs beide de rekenkosten. Ten tweede is het moeilijk om illegale bomen met tegenstrijdige productieregels uit te sluiten, wat belangrijk is voor een betrouwbare modelbeoordeling. Als een POS-tag (zoals VV) boven een phrase tag (zoals VP) in de uitvoerboom staat, wordt het vrij complex om woordgrenzen te bepalen. Om beide uitdagingen het hoofd te bieden, wordt in dit werk een tweetraps grof tot fijn etiketteringskader voorgesteld voor gezamenlijke WS-POS-PAR. In de grove labeling fase geeft het gezamenlijke model een boom met haakjes uit, waarin elk knooppunt overeenkomt met een van de vier labels (d.w.z. frase, subfrase, woord, subwoord). De boom is gegarandeerd legaal via beperkte CKY decodering. In de fine labeling fase breidt het model elk grof label uit tot een definitief label (zoals VP, VP*, VV, VV*). Experimenten op Chinese Penn Treebank 5.1 en 7.0 tonen aan dat ons gezamenlijk model consistent de pijpleidingbenadering overtreft op beide instellingen van w/o en w/BERT, en nieuwe state-of-the-art prestaties bereikt.', 'de': 'Der einfachste Ansatz für Joint Word Segmentation (WS), Part-of-Speech (POS) Tagging und Constitutive Parsing besteht darin, einen Wortbaum in einen Zeichenbaum umzuwandeln, was jedoch zu zwei großen Herausforderungen führt. Erstens erhöhen ein größerer Label-Satz (z.B. 600) und längere Eingänge die Rechenkosten. Zweitens ist es schwierig, illegale Bäume mit widersprüchlichen Produktionsregeln auszuschließen, was für eine zuverlässige Modellbewertung wichtig ist. Wenn ein POS-Tag (wie VV) über einem Phrase-Tag (wie VP) im Ausgabebaum steht, wird es ziemlich komplex, Wortgrenzen zu bestimmen. Zur Bewältigung beider Herausforderungen schlägt diese Arbeit einen zweistufigen Grob-bis-Fein-Kennzeichnungsrahmen für gemeinsame WS-POS-PAR vor. In der Grob-Beschriftungsstufe gibt das Joint-Modell einen Baum in Klammern aus, in dem jeder Knoten einem von vier Beschriftungen entspricht (d. h. Phrase, Subtext, Wort, Unterwort). Der Baum ist garantiert legal durch eingeschränkte CKY-Decodierung. In der Feinbeschriftungsphase erweitert das Modell jedes grobe Etikett zu einem endgültigen Etikett (wie VP, VP*, VV, VV*). Experimente an der chinesischen Penn Treebank 5.1 und 7.0 zeigen, dass unser gemeinsames Modell den Pipeline-Ansatz in beiden Settings von w/o und w/BERT durchwegs übertrifft und neue State-of-the-Art Performance erzielt.', 'ko': '연합분사(WS), 어성표시(POS)와 성분분석의 가장 직접적인 방법은 단어급 트리를 문자급 트리로 전환하는 것이다. 그러나 이것은 두 가지 심각한 도전을 가져올 것이다.우선, 비교적 큰 라벨 집합(예를 들어 600)과 비교적 긴 입력은 계산 원가를 증가시킬 수 있다.그 다음으로 충돌 발생식 규칙을 포함하는 불법 트리를 배제하기 어려우므로 신뢰할 수 있는 모델 평가에 매우 중요하다.출력 트리의 단어 표시(예를 들어 VV)가 단어 표시(예를 들어 VP) 위에 있으면 단어의 경계를 정하는 것이 매우 복잡해진다.이 두 가지 도전에 대응하기 위해 본고는 굵기부터 정교함까지의 두 단계의 WS-POS-PAR 연합 라벨 구조를 제시했다.대략적인 표기 단계에서 연합모델은 괄호가 있는 트리를 출력하는데 그 중에서 각 노드는 네 개의 라벨 중 하나(즉 단어, 자단어, 단어, 자단어)에 대응한다.이 트리는 제한된 CKY 디코딩을 통해 합법적임을 보증합니다.세밀한 치수 단계에서 모델은 각 대략적인 치수를 최종 치수(예: VP, VP*, VV, VV*)로 확장합니다.중국 Penn Treebank 5.1과 7.0에서의 실험에 의하면 우리의 연합 모델은 w/o와 w/BERT 두 가지 설정에서 파이프 방법보다 시종일관 우수하고 최신 성능을 실현하였다.', 'fa': 'نزدیکترین نزدیک به ترکیب جدایی کلمات (WS)، پاره\u200cای از کلمات (POS) و ترکیب جدایی\u200cهای پاره\u200cای است که یک درخت سطح کلمات را به درخت سطح پاره\u200cای تبدیل می\u200cکند، که با این حال به دو چالش سخت می\u200cکند. اول، یک مجموعه برچسب بزرگتر (مثل: 600) و بیشتر هر دو هزینه\u200cهای محاسبه را افزایش می\u200cدهد. دوم، درختان غیرقانونی که دارند قانون تولید مخالف هستند، که برای ارزیابی قابل اطمینان مدل مهم است، قانون های غیرقانونی را از دست دادن سخت است. اگر یک برچسب POS (مانند VV) بالای یک برچسب عبارت (مانند VP) در درخت خروجی باشد، برای تصمیم گرفتن مرزهای کلمه کاملا پیچیده می شود. برای حل با هر دو چالش، این کار یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها در مرحله نقاشی قالب، مدل متصل یک درخت بسته شده را بیرون می\u200cآورد، در آن هر گره با یکی از چهار نقاشی (یعنی عبارت، عبارت، عبارت، کلمه، زیر کلمه) متصل می\u200cشود. این درخت از طریق دکوندن CKY محدود قانونی است. در مرحله نقاشی خوب، مدل هر نقاشی را به نقاشی نهایی گسترش می\u200cدهد (مثل VP, VP*, VV, VV*). تجربه های پن تری بانک چین ۵.۱ و ۷.۰ نشان می دهند که مدل مشترک ما به طور مستقل از طریق لوله بر هر دو تنظیمات w/o و w/ BERT برسد و به انجام وضعیت هنری جدید برسد.', 'id': 'Pendekatan paling sederhana untuk segmentasi kata kongsi (WS), tag-part-of-speech (POS), dan penghuraian konstitusi adalah mengubah pohon tahap kata menjadi pohon tahap karakter, yang, bagaimanapun, menyebabkan dua tantangan yang berat. First, a larger label set (e.g.,  600) and longer inputs both increase computational costs.  Kedua, sulit untuk mengeluarkan pohon ilegal yang mengandung aturan produksi yang bertentangan, yang penting untuk evaluasi model yang dipercaya. Jika tag POS (seperti VV) berada di atas tag frasa (seperti VP) di pohon output, menjadi cukup kompleks untuk memutuskan batas kata. Untuk menghadapi kedua tantangan, pekerjaan ini mengusulkan dua tahap kuadrat label kasar-untuk-baik untuk WS-POS-PAR kongsi. Dalam tahap label yang kasar, model kongsi mengeluarkan pohon berkunci, di mana setiap node sepadan dengan salah satu dari empat label (i.e., frasa, subpfrasa, kata, subkata). Pohon ini dijamin untuk menjadi legal melalui dekodasi CKY yang dikuasai. Dalam tahap pencetakan halus, model memperluas setiap label kasar ke label akhir (seperti VP, VP*, VV, VV*). Eksperimen di Pinn Treebank Cina 5.1 dan 7.0 menunjukkan bahwa model bersama kami secara konsisten melebihi pendekatan pipa pada kedua pengaturan w/o dan w/BERT, dan mencapai pertunjukan terbaru.', 'sw': 'The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges.  Kwanza, kituo kikubwa zaidi (kwa mfano, 600) na matokeo mengi zaidi yanaongezeka gharama za hesabu. Pili, ni vigumu kutawala miti isiyo halali ikiwa ina sheria za uzalishaji zinazochanganya, ambazo ni muhimu kwa ajili ya uchunguzi wa mifano inayoaminika. Kama alama ya POS (kama VV) ni juu ya alama ya neno (kama VP) kwenye mti wa matumizi, itakuwa vigumu kuamua mipaka ya neno. Kukabiliana na changamoto hizi mbili, kazi hii inapendekeza mfumo wa treni wa jukwaa mbili-kuelekea vyema kwa ajili ya kuungana na WS-POS-PAR. Katika jukwaa la maabara la kodi, muundo wa pamoja unatoa mti wa nguo, ambapo kila upande wa node unalinganisha na moja ya alama nne (yaani maneno, maneno, maneno, subword). Mti unahakikishwa kuwa sheria kwa kupitia kupanuka kwa CKY. Katika jukwaa zuri la maabara, mifano inaeneza kila alama ya kodi katika alama ya mwisho (kama vile VP, VP*, VV, VV*). Majaribio kwenye Penn Treebank 5.1 na 7.0 ya China yanaonyesha kuwa muundo wetu wa pamoja kwa ujumla unaonyesha mbinu za pipeline za mikakati ya w/o na w/ BERT, na kupata hali mpya ya mambo ya sanaa.', 'tr': 'Birleşik söz segmentasiýasynyň (WS), sözleriniň bir parçasyny (POS) etiketlemesi we meýilleşik parslemesi söz düzeýji agajyny karakter derejesi agajyna üýtgetmekdir. Şol sebäpden iki kyn kynçylyka ýöreýär. Ilkinji, täze bir etiket setir (mysal. ,600) we uly bir etiket hem sanatyň paýtlaryny artýar. Ikinjisi ýagdaýda döwletli çykyş kurallary bolan yasalan agaçlary çykarmak kyn. Bu güýçli nusga çykmak üçin wajypdyr. Eger bir POS tägi (VV ýaly) çikgin agaçynda fraz tägi üstünde bolsa, söz sahtalaryny çözmek üçin gaty kompleks bolar. Her iki kynçylykla çözmek için bu çalışma, birleşen WS-POS-PAR için iki fazla koörs-to-fine etiketleme çerçevesini teklif ediyor. Gowureg etiketleme sahypasynda, toplam nusgasy çykyş agajyny çykar, i çinde her düğüm dört etiketleriň birine (myselm, fraz, subfraz, söz, sübsöz) meňzeýär. Bu agaç CKY ködleme alyndan hukuk bolmagy garanylýar. Ýenen etiketleme sahnesinde, model her etiketi soňky etikete ekleýär (VP, VP*, VV, VV*). Name Çinçe Penn Treebank 5.1 we 7.0 arasynda örneklerimiziň birlikde nusgasymyz w/o we w/BERT düzümlerinde pipeline yaklaşyny ýok edip, we täze sanat taýýarlanmagyny başarmaýar.', 'af': "Die mees eenvoudige toegang tot saamstemming van woord segmentasie (WS), deel van woord (POS) merking, en konstituent verwerking is om 'n woord-vlak boom te omskakel na 'n karaktervlak boom, wat tog lei na twee swaar uitdrukkings. Eerste, â\x80\x99n groter etiket stel (bv. 600) en langer inplaas beide verhoog rekenaar koste. Tweede, dit is moeilik om illegale bome te uittrek wat verskillende produksiereëls bevat, wat belangrik is vir betroubare model evaluering. As 'n POS etiket (soos VV) bo' n frase etiket (soos VP) in die uitvoer boom is, word dit heeltemal kompleks om woord grense te besluit. Om beide uitdagings te behandel, voorstel hierdie werk 'n twee-stadige coarse-to-fine etiket raamwerk vir joint WS-POS-PAR. In die koörse etiketting stadium, uitvoer die saamgevoerde model 'n gekommerde boom, waarin elke node ooreenstem met een van vier etikette (bv. frase, subfrase, woord, subwoord). Die boom is garantieer om wettig te wees deur beheinde Cky dekodering. In die fyn etiket stadium word die model uitbrei elke koörse etiket in 'n eindelike etiket (soos VP, VP*, VV, VV*). Eksperimente op Sjinese Penn Treebank 5. 1 en 7. 0 wys dat ons joint model konsistentlik die pyperlyn toegang uitvoer op beide instellings van w/ o en w/ BERT, en bereik nuwe staat- van- die- kunsten-prestasie.", 'am': 'The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges.  መጀመሪያ፣ ትልቅ ምልክት ማዘጋጀት (ምሳሌ፣ 600) እና የረጅም input ሁለቱን ቁጥጥር ያበዛል፡፡ ሁለተኛ፣ በተቃራኒ የፍሬት ሥርዓት ውስጥ ያሉትን illegal ዛፎችን በመግለጽ አስቸጋሪ ነው፣ ይህም ለሚታመነው ሞዴል ማረጋገጫ muhimu ነው፡፡ የPOS ምልክት (እንደ VV) ከ የንግግር ምልክት (እንደ VP) በሚወጣው ዛፍ ላይ ቢሆን የቃላት ዳርቻ መወሰን ይጨምር ነበር፡፡ የሁለቱን ጥያቄዎች ለመቀበል ይህ ሥራ የሁለት ደረጃዎች የኮርፖርስ ወደ መልካም የጽሑፍ ፍሬማር ለWS-POS-PAR ጥያቄ ያቀርባል፡፡ በአራቱ ምልክት የሚታያየው የአራቱ ምልክት (ምሳሌ ቃላት፣ ደብረ ገጽ፣ ቃላት፣ ደብዳቤ ቃላት) የሚታያየው የአራቱ ምልክቶች የሚታየው የግንኙነት ምሳሌ አወጣል፡፡ ዛፉ የCKY ጽሑፍ በመግለጽ ሕግ እንዲሆን መግለጫ ነው፡፡ በጥሩ ደረጃ ውስጥ ሞዴል በየኮርፖር ምልክት ወደ መጨረሻ ምልክት ይዘረጋል (እንደ VP, VP*, VV, VV*). በቻይናውያን ፓኒን ቴሬቡክ 5.1 እና 7.0 ላይ የተፈተና ሞዴላታችን የ/O እና w/BERT አካባቢ እና አዲስ የ-አርእስት ሥርዓት አግኝቷል፡፡', 'sq': 'Përqasja më e thjeshtë për segmentimin e përbashkët të fjalëve (WS), shënimin e pjesës së fjalës (POS) dhe analizimin e përbërësve është duke konvertuar një pemë me nivel fjalësh në një pemë me nivel karakteri, e cila megjithatë shpie në dy sfida të rënda. Së pari, një etiketë më e madhe (për shembull, 600) dhe input më të gjatë të dy rritin kostot llogaritare. Së dyti, është e vështirë të përjashtohen pemët e paligjshme që përmbajnë rregulla konfliktuese prodhimi, e cila është e rëndësishme për vlerësimin e model it të besueshëm. Nëse një etiketë POS (si VV) është mbi një etiketë fraze (si VP) në pemën e daljes, bëhet mjaft kompleks për të vendosur kufijtë e fjalës. Për të trajtuar të dy sfidat, ky punë propozon një kuadër të etiketimit dy-fazor të rreptë në të mirë për WS-POS-PAR të përbashkët. Në skenën e etiketave të mëdha, model i i përbashkët nxjerr një pemë me kornizë, në të cilën çdo nyjë korrespondon me një nga katër etiketat (pra, frazë, nënfrazë, fjalë, nënfjalë). Pema është garantuar të jetë e ligjshme nëpërmjet dekodimit të kufizuar CKY. Në fazën e etiketave të holla, modeli zgjeron çdo etiketë të madhe në një etiketë përfundimtare (të tillë si VP, VP*, VV, VV*). Eksperimentet në Pinn Treebank kinez 5.1 dhe 7.0 tregojnë se modeli ynë i përbashkët ekziston vazhdimisht më shumë se qasja e tubacionit në të dy rregullimet e w/o dhe w/BERT dhe arrin shfaqje të reja më të larta.', 'bn': 'যোগ দিয়ে শব্দ বিভক্ত করার (ডাব্লিউএস), ভাষণের অংশ (পোএস) ট্যাগিং এবং প্রতিনিধিদের পার্সিং একটি শব্দ-স্তরের গাছে একটি চ্যার-স্তরের গাছে পরিবর্তন করা হচ্ছে, য প্রথমত, একটি বড় লেবেলেট সেট (উদাহরণস্বরূপ, ৬০০) এবং আরো বেশী ইনপুট গণনামূল্য বৃদ্ধি করে। দ্বিতীয়, বিভ্রান্ত উৎপাদন নিয়মের মধ্যে অবৈধ গাছগুলো নিয়ন্ত্রণ করা কঠিন, যা বিশ্বস্ত মডেলের মূল্যের জন্য গুরুত যদি একটি POS ট্যাগ (যেমন ভিভি) আউটপুট গাছের একটি বাক্য ট্যাগের উপর (যেমন ভিপি) থাকে, তাহলে শব্দ সীমানার সিদ্ধান্ত নেয়ার জন্য এটি খ দুটো চ্যালেঞ্জের মুখোমুখি হওয়ার জন্য এই কাজের প্রস্তাব দুই-মেয়াদের কোর্স থেকে ভালো লেবেলের কার্যক্রমের প্রস্তাব করেছ ককোর্সের লেবেলের পর্যায়ে যৌথ মডেল একটি ব্র্যাককেট গাছের উৎপাদন করে, যেখানে প্রত্যেক নোড চার লেবেলের সাথে যোগাযোগ করে (উদাহরণস্বরূপ, বাক্যার, শ The tree is guaranteed to be legal via constrained CKY decoding.  সুন্দর লেবেলিং স্টেজে মডেল প্রত্যেক কোর্স লেবেল ফাইনাল লেবেলে প্রসারিত করে (যেমন ভিপি, ভিপি*, ভিভি, ভিভি*)। চীনা পেন ট্রেবাঙ্ক ৫. ১ এবং ৭. ০-এর পরীক্ষার পরীক্ষা দেখাচ্ছে যে আমাদের যোগাযোগ মডেল বিশেষ করে উই/ও/ বার্টি-এর বৈশিষ্ট্যাবলীর পাইপেলাইনের প্রতিক্রি', 'bs': 'Najjednostavniji pristup zajedničkoj segmentaciji riječi (WS), dijelom govora (POS) označavanju, i dijelom razmatranja komponenta je pretvaranje drveta na nivo riječi u drvo na nivo čarolije, što međutim vodi do dva teška izazova. Prvo, veći set etikete (npr. 600) i duži ulazi i povećavaju računalne troškove. Drugo, teško je isključiti ilegalno drvo koje sadrže sukobe pravila proizvodnje, što je važno za pouzdanu ocjenu modela. Ako je znak POS (kao VV) iznad značke fraze (poput VP) u drvetu izlaza, postaje kompleksno odlučiti granice riječi. Za rješavanje obe izazova, ovaj rad predlaže okvir za zajedničku WS-POS-PAR-u. U toj fazi oznake, zajednički model iznosi narukviceno drvo, u kojem svaki čvor odgovara jednoj od četiri etikete (tj. fraze, podfraze, riječ, podriječ). Drvo se garantuje da bude legalno preko ograničenog dekodiranja CKY-a. U finoj fazi označavanja, model se proširi svaku označenu etiketu u konačnu etiketu (poput VP, VP*, VV, VV*). Eksperimenti na kineskoj Penn Treebank 5.1 i 7.0 pokazuju da naš zajednički model konsekventno nadmašuje pristup cijevi na obje postavke w/o i w/ BERT-a i postigne nove postupke umjetnosti.', 'hy': 'Ամենապարզ մոտեցումը բառերի միասնական սեգրեգացիայի (wS), խոսքի մասի (POS) նշանների և բաղադրիչների վերլուծության համար բառերի մակարդակի ծառը վերածվում է նշանների մակարդակի ծառի, ինչը, այնուամենայնիվ, հանգեցնում է երկու լուրջ մարտահրավերների: Առաջինը, ավելի մեծ պիտակները (օրինակ՝ 600) և ավելի երկար ներմուծները երկուսն էլ աճում են հաշվարկների արժեքները: Երկրորդ, դժվար է բացատրել անօրինական ծառերը, որոնք պարունակում են հակառակ արտադրության կանոններ, ինչը կարևոր է վստահելի մոդելի գնահատման համար: Եթե POS-ի (ինչպիսին է VV) թեգը դուրս գալիս գտնվող ծառի արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված արտահայտված ար Երկու մարտահրավերներին լուծելու համար այս աշխատանքը առաջարկում է երկու փուլում ընդհանուր ՎՍ-ՊՕՍ-ՊԱ-ի պիտակագրման շրջանակ: Միացյալ մոդելը ծառ է հանում, որտեղ յուրաքանչյուր կետ համապատասխանում է չորս պիտակներից մեկին (այսինքն, արտահայտություն, ենթաարտահայտություն, բառ, ենթաբառ): The tree is guaranteed to be legal via constrained CKY decoding.  Մոդելը նրբագեղ պիտակում ընդլայնում է յուրաքանչյուր խոր պիտակում վերջնական պիտակում (ինչպիսիք են VP, VP*, VV, VV*): Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the pipeline approach on both settings of w/o and w/ BERT, and achieves new state-of-the-art performance.', 'az': 'Ən düzgün söz segmentasyonu (WS), sözlərin bir parçası (POS) etiketi və müəyyən ayırması sözlərin səviyyəsi a ğacını char-level ağacına çevirməkdir. Bu is ə iki çətin çətinliklərə yol verər. Əvvəlcə, daha böyük bir etiket seti (məsələn, 600) və daha uzun hər ikisini hesap maliyyətini artırar. İkincisi, güvenilir modellərin değerlendirməsi üçün müxtəlif ürək qaydaları barəsində yasadışı ağacları çəkmək zordur. Əgər POS etiketi (VV kimi) çıxış a ğacında fraz etiketi (VP kimi) üstündə olsa, söz sınırlarını qərarlaşdırmaq çox çətin olur. İki çətinliklərlə çəkinmək üçün bu işin birlikdə WS-POS-PAR üçün iki dəfə müəyyən edilən etiketli çerçivi təklif edir. Üstünlük etiketləmə sahəsində, birləşdirilmiş modellər dörd etiketlərdən birinə uyğun bir a ğacı çıxarır. Ağaç CKY kodlaması ilə yasal olmasını əmin edir. İyi etiketləmə sahəsində, modellər hər nöqtəsi etiketini son etiketə genişləyir (VP, VP*, VV, VV*). Çin Penn Treebank 5.1 və 7.0 təcrübələrinin birlikdə modellərimizin w/o və w/ BERT ayarlarının hər ikisinin bor çizgisinin təcrübəsini və yeni sanatın təcrübəsini başa çatdığını göstərir.', 'cs': 'Nejpříjemnějším přístupem ke společné segmentaci slov (WS), značení části řeči (POS) a analýze slov je přeměna stromu na úrovni znaků, což však vede ke dvou závažným problémům. Za prvé, větší sada štítků (např. 600) a delší vstupy zvyšují výpočetní náklady. Za druhé je obtížné vyloučit nelegální stromy obsahující protichůdná produkční pravidla, což je důležité pro spolehlivé hodnocení modelu. Pokud je POS tag (jako VV) nad frázovou značkou (jako VP) ve výstupním stromu, je docela složité rozhodovat o hranicích slov. Pro řešení obou problémů navrhuje tato práce dvoustupňový rámec hrubého až jemného označování pro společné WS-POS-PAR. Ve fázi hrubého označování vydává společný model strom s závorkou, ve kterém každý uzel odpovídá jednomu ze čtyř štítků (tj. fráze, podfráze, slovo, podslovo). Strom je zaručeně legální díky omezenému dekódování CKY. Ve fázi jemného značení model rozšiřuje každý hrubý štítek na finální štítek (například VP, VP*, VV, VV*). Experimenty na čínské Penn Treebank 5.1 a 7.0 ukazují, že náš společný model důsledně překonává přístup potrubí v obou nastaveních bez/o i bez BERT a dosahuje nového nejmodernějšího výkonu.', 'fi': 'Yksinkertaisin lähestymistapa yhteiseen sanasegmentointiin (WS), osa-of-speech (POS) -tagaukseen ja osatekijöiden jäsentämiseen on sanatason puun muuntaminen char-tason puuksi, mikä kuitenkin johtaa kahteen vakavaan haasteeseen. Ensinnäkin suurempi tarrasarja (esim. 600) ja pidempi syöttö lisäävät laskennallisia kustannuksia. Toiseksi on vaikea sulkea pois laittomia puita, jotka sisältävät ristiriitaisia tuotantosääntöjä, mikä on tärkeää mallien luotettavan arvioinnin kannalta. Jos POS-tagi (kuten VV) on lausetagin (kuten VP) yläpuolella tulospuussa, sanarajojen päättäminen on melko monimutkaista. Molempien haasteiden ratkaisemiseksi tässä työssä ehdotetaan kaksivaiheista karkeasta hienoon merkintäkehystä yhteiselle WS-POS-PAR-järjestelmälle. Karkeassa merkintävaiheessa yhteismalli tuottaa suluissa olevan puun, jossa jokainen solmu vastaa yhtä neljästä merkinnästä (eli lause, alifraasi, sana, alasana). Puu on taattu lailliseksi rajoitetun CKY-dekoodauksen avulla. Hienomerkintävaiheessa malli laajentaa jokaisen karkean etiketin lopulliseksi etiketiksi (kuten VP, VP*, VV, VV*). Kiinalaisen Penn Treebankin 5.1:n ja 7.0:n kokeet osoittavat, että yhteinen mallimme on johdonmukaisesti parempi kuin putkilinjan lähestymistapa sekä w/o että w/BERT:n asetuksissa ja saavuttaa uuden huipputason suorituskyvyn.', 'ca': "L'enfocament més senzill a la segmentació de paraules conjuntes (WS), etiqueta de part-of-speech (POS) i l'analització de components és convertir un arbre de nivell de paraules en un arbre de nivell de caracteres, el que, no obstant això, porta a dos desafiaments graves. Primer, un conjunt d'etiquetes més gran (per exemple, 600) i entrades més llargues augmenten els costos computacionals. Segon, és difícil excluir arbres ilícits que contenen normes de producció conflictuals, que és important per a una evaluació fiable del model. Si una etiqueta POS (com VV) està per sobre d'una etiqueta de frases (com VP) a l'arbre de sortida, esdevé bastant complexa decidir els límits de paraules. Per enfrontar ambdós reptes, aquesta feina proposa un marc d'etiquetage de dos etapes gros a fins per a WS-POS-PAR conjunt. A l'escenari de l'etiqueta grossa, el model articular produeix un arbre paràquetat, en el qual cada nod correspondeix a una de les quatre etiquetes (és a dir, frase, subpraça, paraula, subparaula). The tree is guaranteed to be legal via constrained CKY decoding.  En la fina etapa d'etiquetar, el model expandeix cada etiqueta grossa en una etiqueta final (com VP, VP*, VV, VV*). Els experiments de la Chinese Penn Treebank 5.1 i 7.0 mostren que el nostre model conjunt supera constantment l'enfocament de pipeline en ambdós ajustes de w/o i w/BERT, i aconsegueix un nou rendiment d'última edat.", 'et': 'Kõige lihtsam lähenemine ühise sõnasegmentatsiooni (WS), kõneosa (POS) sildistamisele ja koostisosade parsimisele on sõnatasemel puu teisendamine märgistataseme puuks, mis aga toob kaasa kaks tõsist väljakutset. Esiteks suurendavad suurem etikettide komplekt (nt 600) ja pikemad sisendid mõlemad arvutuskulusid. Teiseks on raske välistada ebaseaduslikke puid, mis sisaldavad vastuolulisi tootmiseeskirju, mis on oluline mudeli usaldusväärse hindamise seisukohalt. Kui POSi silt (nagu VV) asub väljundpuu fraasisildi (nagu VP) kohal, muutub sõnapiiride otsustamine üsna keeruliseks. Mõlema probleemi lahendamiseks pakutakse käesolevas töös välja kaheastmeline jämedast peeneks märgistamise raamistik ühise WS-POS-PAR jaoks. jämeda märgistamise etapis väljastab ühismudel sulgudega puu, kus iga sõlm vastab ühele neljast märgistusest (st fraas, alamsõna, sõna). Puu on garanteeritud seaduslikuks piiratud CKY dekodeerimise kaudu. Peenmärgistamise etapis laiendab mudel iga jämeda etiketi lõplikuks etiketiks (nt VP, VP*, VV, VV*). Hiina Penn Treebanki 5.1 ja 7.0 eksperimendid näitavad, et meie ühine mudel on pidevalt ületanud torujuhtme lähenemisviisi nii ilma ja ilma BERT seadete puhul ning saavutab uue tipptasemel jõudluse.', 'sk': 'Najbolj enostaven pristop k skupni segmentaciji besed (WS), označevanju dela govora (POS) in razčlenjevanju sestavnih delov je pretvorba drevesa na ravni besed v drevo na ravni znakov, kar pa vodi do dveh resnih izzivov. Prvič, večji nabor oznak (npr. 600) in daljši vhodi povečujeta računalniške stroške. Drugič, težko je izključiti nezakonita drevesa, ki vsebujejo nasprotujoča si pravila proizvodnje, kar je pomembno za zanesljivo oceno modela. Če je oznaka POS (kot je VV) nad oznako fraze (kot je VP) v izhodnem drevesu, postane precej kompleksno določiti meje besed. Za reševanje obeh izzivov to delo predlaga dvostopenjski okvir za označevanje grobe do drobe za skupno WS-POS-PAR. V fazi grobega označevanja skupni model izda drevo z oklepaji, v katerem vsako vozlišče ustreza eni od štirih označb (tj. fraza, podbeseda, beseda, podbeseda). Drevo je zagotovljeno, da je zakonito z omejenim dekodiranjem CKY. V fazi finega označevanja model vsako grobo nalepko razširi v končno nalepko (kot so VP, VP*, VV, VV*). Poskusi na kitajskem Penn Treebanku 5.1 in 7.0 kažejo, da naš skupni model dosledno presega pristop cevovodov v obeh nastavitvah brez in brez BERT ter dosega novo najsodobnejšo zmogljivost.', 'ha': "Tsarawa mafi daidaita zuwa haɗin magana segment (WS), rabon magana (PoS) tagogi, kuma parse na musanya magana na zama mai musanya wata itãce-daraja zuwa wata itãce ta char-daraja, da haka kuma yana ƙara matabbata biyu masu tsanani. First, an daidaita wata mafi girma cikin label (misali, 600) da ana ƙara cikin suna suna ƙara cikakken lissafi. Kijan da na, ya zama mai ƙunci a rule it ãce haram wanda yana da sharuɗe na manunufi, wanda yana da muhimu ga muhimmi a ƙidãya misãlai da ake amintar. Idan wata alama na PSS (kamar vV) na saman wata alama na magana (kamar vP) cikin it ãcen fitarwa, za'a zama mai ƙunci domin yin hukuncin grensa na magana. Daga haɗi da su biyu masu kansalar, wannan aikin yana bukãtar da firam biyu-zuwa-mai mai kyau wa shirin WS-PS-PAR. Kuma cikin fasar alama na kõre, misalin na haɗi na fitar da wata itãce mai bõyayya, inda duk node yana daidai da ɗayan alƙaluma huɗu (misali, magana, subword, subword). Ana garanta cewa cewa za'a halatta a cikin kodin CKY. Idan yana cikin wani fasa mai kyau, shirin ayuka yana faɗa ɗawa kowace label na kõre zuwa wata label ta ƙarami (kamar misali, vP*, V, V*). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the pipeline approach on both settings of w/o and w/ BERT, and achieves new state-of-the-art performance.", 'jv': 'text-tool-action First, a big label set (e.g. ,200) and long inputs Siji-siji, sak susah-susahe kuwi ora oleh sing berarti hukum sing nganggep nggawe barang manut, sing dikarepaké kanggo kuwi nggawe model sing apik. Display routing Ngawe iki ambekan karo hal-iki dadi, akeh gunakake iki-paken sekang kotar-to-fini etiket trus kanggo nggawe WS-po-PAR. string" in "context_BAR_stringLink Punika dipunangé hukum sing ditambah CKY ditambah string" in "context_BAR_stringLink Ombudhakan neng Panting Pen Stringke sing 5.1 lan 7.0 ngomong nik model sing dibenakake nggawe barang nggawe dolanan lanjure nggawe sistem kut setunggal w/o karo w/BERT, lan akeh iso dianggap sistem sing dibenakake nggawe barang dumadhi.', 'he': 'הגישה הכי ישירה לגזרת מילים משותפת (WS), תג חלק מהנאום (POS) והמחקר המרכיב היא להפוך עץ רמה מילים לעץ רמה סמל, אשר, עם זאת, מוביל לשני אתגרים חמורים. ראשית, קבוצת תווית גדולה יותר (למשל, 600) וכניסים ארוכים יותר מגבילות את העלות החישובית. שנית, קשה לשלול עצים בלתי חוקים שמכילים חוקי יצירה מתנגדים, שזה חשוב להערכה מודל אמין. אם תג POS (כמו VV) נמצא מעל תג ביטוי (כמו VP) בעץ ההוצאה, זה הופך למדי מורכב להחליט גבולות מילים. כדי להתמודד עם שני האתגרים, העבודה הזו מציעה מסגרת תיקון משני שלבים, גס עד גס, עבור WS-POS-PAR משותפת. בשלב התווית העצום, הדוגמנית המשותפת יוציאה עץ צמיד, שבה כל קשר מתאים לאחד מארבעה תוויות (כלומר, ביטוי, מילה, מילה, תחת מילה). העץ מובטח להיות חוקי באמצעות פיקוד מוגבל CKY. בשלב התיקוי הטוב, הדוגמא מרחיב כל תווית עצומה לתוך תווית סופית (כמו VP, VP*, VV, VV*). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the pipeline approach on both settings of w/o and w/ BERT, and achieves new state-of-the-art performance.', 'bo': 'The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree to a char-level tree, which however, leads to two severe challenges. It is the most straightforward approach to joint word segmentation (WS), part-of-speech དང་པོ་ནས་ཤོག་བྱང་ཆེ་ཤོག་བྱང་སྟངས་འདྲ་བར་བཙུགས་ཡོད། དཔེར་ན། 600 གཉིས་པ་བརྗོད། རྒྱ་ནག་གིས་མི་སྒྲིག་གི་དབུས་བཟོས་པའི་བཟོ་བརྗོད་གཞི་ཡོད་པའི་བཟོ་བཅོས་དེ་ལས་གལ་ཆེན་པོ་ཡིན། If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries. To deal with both challenges, this work proposes a two-stage coarse-to-fine labeling framework for joint WS-POS-PAR. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e. phrase, subphrase, word, subword). སྡོང་བོའི་དབྱིབས་CKY སྒྲིག་འཛུགས་ཀྱིས་ཕན་བཟོ་བྱེད་ནུས་པ་ཁག་ཆེན་ཡིན། In the fine labeling stage, the model expands each coarse label into a final label (such as VP, VP*, VV, VV*).  Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the pipeline approach on both settings of w/o and w/ BERT, and achieves new state-of-the-art performance.'}
{'en': 'Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries', 'es': 'Comprender hasta qué punto las métricas de calidad del contenido miden la calidad de la información de los resúmenes', 'ar': 'فهم المدى الذي تقيس به مقاييس جودة المحتوى جودة معلومات الملخصات', 'pt': 'Entendendo até que ponto as métricas de qualidade do conteúdo medem a qualidade da informação dos resumos', 'fr': "Comprendre dans quelle mesure les indicateurs de qualité du contenu mesurent la qualité de l'information des résumés", 'ja': 'コンテンツ品質指標がサマリーの情報品質を測定する範囲を理解する', 'zh': '知质量指标量摘要信息之量也', 'hi': 'उस सीमा को समझना जिसमें सामग्री गुणवत्ता मैट्रिक्स सारांश की जानकारी की गुणवत्ता को मापते हैं', 'ru': 'Понимание степени, в которой показатели качества контента измеряют качество информации резюме', 'ga': 'A Thuiscint ar an Méid a Tomhaiseann Méadrachtaí Cáilíochta Ábhair Cáilíocht Faisnéise Achoimrí', 'el': 'Κατανόηση της έκτασης στην οποία τα μετρικά ποιότητας περιεχομένου μετρούν την ποιότητα πληροφοριών των συνοπτικών εργασιών', 'hu': 'Az összefoglalók információminőségének mérésének mértékének megértése', 'it': 'Comprendere la misura in cui le metriche di qualità dei contenuti misurano la qualità delle informazioni dei riassunti', 'lt': 'Supranti, kiek turinio kokybės metriniai rodikliai vertina informacijos santraukų kokybę', 'ka': 'განსხვავებული განზომილება, რომელიც Content Quality Metrics განზომილება ინფორმაციის კვალეტის განზომილება', 'kk': 'Мазмұның сапасы метрикалық мәліметтің сапасын өлшейтін кеңейтуін түсіндіру', 'ms': 'Memahami Sambungan ke mana Metrik Kualiti Kandungan mengukur Kualiti Maklumat Ringkasan', 'ml': 'വിവരങ്ങളുടെ വിവരങ്ങളുടെ വിവരങ്ങളുടെ വിവരങ്ങള്\u200d അളവ് ചെയ്യുക', 'mk': 'Разбирање на степенот до кој квалитетните метрики на содржината го мерат квалитетот на информациите на резултатите', 'mn': 'Мэдээлэл дурангуудын хэмжээний хэмжээний хэмжээний хэмжээг ойлгохын тулд', 'no': 'For å forstå utvidinga som innhaldskvalitetmetrikar målar informasjonskvaliteten til samandrag', 'ro': 'Înțelegerea măsurii în care metricile calității conținutului măsoară calitatea informațiilor rezumate', 'pl': 'Zrozumienie zakresu, w jakim wskaźniki jakości treści mierzą jakość informacji w podsumowaniach', 'so': 'Waxa garanaya wadanka u dhexeeya ee ku qiyaasa qiimaha macluumaadka ee Summaries', 'si': 'සම්බන්ධතාවක් ප්\u200dරශ්ණතාවක් මීට්\u200dරික් මාර්ගන්න ප්\u200dරශ්ණතාවක් තේරුම්ගන්න', 'sr': 'Razumevanje proširenja u kojoj metrici za kvalitet sadržaja mjera kvalitet informacija sažetaka', 'sv': 'FĂ¶rstĂ¥ i vilken utstrĂ¤ckning innehĂ¥llskvalitetsmĂ¤tningar mĂ¤ter informationskvaliteten pĂ¥ sammanfattningar', 'ta': '@ info', 'ur': 'سمجھتے ہیں کہ کس طرح Content Quality متریک معلومات کی کیفیت کی مزید مزید کرتا ہے', 'mt': 'Il-fehim tal-estensjoni li biha l-Metriki tal-Kwalità tal-Kontenut ikejlu l-Kwalità tal-Informazzjoni tas-Sommarji', 'vi': 'Sự hiểu rộng bao nhiêu đo đo giới hạn chất lượng nội dung của các cuộc họp mặt', 'uz': 'Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries', 'bg': 'Разбиране на степента, до която измерванията за качество на съдържанието измерват качеството на информацията на резюметата', 'nl': 'Inzicht in de mate waarin inhoudskwaliteitsstatistieken de informatiekwaliteit van samenvattingen meten', 'da': 'Forståelse af, i hvilket omfang indholdskvalitetsmålinger måler informationskvaliteten af resuméer', 'hr': 'Razumijevanje široke mjere kvalitete sadržaja mjere kvalitete informacija sažetaka', 'id': 'Memahami Ekstensi Metrik Kualitas Kandungan Memukur Kualitas Informasi Ringkasan', 'de': 'Verstehen des Umfangs, in dem Content Quality Metrics die Informationsqualität von Zusammenfassungen messen', 'fa': 'درک کردن طولانی که متریک کیفیت محتویات به کدام کیفیت اطلاعات جشن اندازه می\u200cگیرد', 'ko': '내용 품질 지표를 이해하여 요약 정보의 질을 평가하는 정도', 'sw': 'Kwa kuelewa Kipande ambacho Kiwango cha Viwango vya Maudhui', 'tr': 'Mazmunlar Qualityny Metrici Maglumat Qualityni Nişanlaryň Ýardamy', 'af': 'Verstaan die Uitbreiding na wat Inhoud Kwaliteit Metrike Maat die Informasie Kwaliteit van Opsomming', 'sq': 'Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries', 'hy': 'Հասկանալ, թե ինչքանով է պարունակության որակային մետրիկները չափում համառոտագրությունների տեղեկատվության որակը', 'am': 'ማጠቃለያ የኩነቶች መጠን', 'bn': 'সামারের তথ্যের মান পরিমাপ বুঝতে পারে', 'az': 'Qısqanların Malümatı Qısqanlığını Ölçüyən Dərgəni anlamaq üçün', 'ca': "Entendre l'extensió a la que els mètrics de qualitat del contingut mesuren la qualitat de la informació dels resums", 'bs': 'Razumijevanje proširenja do kojeg mjera metrika kvalitete sadržaja informacijske kvalitete sažetaka', 'cs': 'Porozumění rozsahu, do kterého metriky kvality obsahu měří kvalitu informací shrnutí', 'et': 'Mõistmine, mil määral sisukvaliteedi meetrid mõõdavad kokkuvõtete teabekvaliteeti', 'fi': 'Sisällönlaatumittarit mittaavat tiivistelmien tietojen laatua.', 'jv': 'Peringatan', 'ha': 'KCharselect unicode block name', 'sk': 'Razumevanje obsega meritev kakovosti vsebine merijo kakovost informacij povzetkov', 'he': 'להבין את המרחק למדידת איכות התוכן למדוד את איכות המידע של סדרות', 'bo': 'རྒྱ་བསྐྱེད་ཚད་གིས་ནང་དོན་ཀྱི་སྒྲིག་ཚད་ཚད་གཞི་རྩིས་ཐོག་གནས་སྟངས་ཀྱི་ཚད་སྒྲིག་པ'}
{'en': 'Reference-based metrics such as  ROUGE  or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary’s information quality by calculating how much information the summaries have in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely can not be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. Further, we provide evidence that this result holds true for many other summarization evaluation metrics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community’s research goal, to generate summaries with high-quality information. However, we conclude by demonstrating that a recently proposed  metric , QAEval, which scores summaries using  question-answering , appears to better capture  information quality  than current evaluations, highlighting a direction for future research.', 'ar': 'تقوم المقاييس القائمة على المراجع مثل ROUGE أو BERTScore بتقييم جودة محتوى الملخص من خلال مقارنة الملخص بمرجع. من الناحية المثالية ، يجب أن تقيس هذه المقارنة جودة معلومات الملخص عن طريق حساب مقدار المعلومات المشتركة بين الملخصات. في هذا العمل ، نقوم بتحليل محاذاة الرمز المميز المستخدمة من قبل ROUGE و BERTScore لمقارنة الملخصات ونجادل بأن درجاتهم لا يمكن تفسيرها إلى حد كبير على أنها قياس تداخل المعلومات. بدلا من ذلك ، فهي تقديرات أفضل لمدى مناقشة الملخصات نفس المواضيع. علاوة على ذلك ، نقدم دليلًا على صحة هذه النتيجة للعديد من مقاييس تقييم التلخيص الأخرى. نتيجة هذه النتيجة هي أن مقاييس تقييم التلخيص الأكثر استخدامًا لا تتوافق مع هدف بحث المجتمع ، لتوليد ملخصات بمعلومات عالية الجودة. ومع ذلك ، نختتم بإثبات أن المقياس المقترح مؤخرًا ، QAEval ، والذي يسجل الملخصات باستخدام الإجابة على الأسئلة ، يبدو أنه يلتقط جودة المعلومات بشكل أفضل من التقييمات الحالية ، مما يبرز اتجاه البحث في المستقبل.', 'es': 'Las métricas basadas en referencias, como ROUGE o BertScore, evalúan la calidad del contenido de un resumen comparándolo con una referencia. Idealmente, esta comparación debería medir la calidad de la información del resumen calculando cuánta información tienen en común los resúmenes. En este trabajo, analizamos las alineaciones de fichas utilizadas por ROUGE y BertScore para comparar resúmenes y argumentamos que sus puntuaciones no pueden interpretarse en gran medida como una superposición de información de medición. Más bien, son mejores estimaciones de la medida en que los resúmenes discuten los mismos temas. Además, proporcionamos evidencia de que este resultado es válido para muchas otras métricas de evaluación de resumen. La consecuencia de este resultado es que las métricas de evaluación de resumen más utilizadas no se alinean con el objetivo de investigación de la comunidad, para generar resúmenes con información de alta calidad. Sin embargo, concluimos demostrando que una métrica propuesta recientemente, QaEval, que califica los resúmenes mediante respuestas a preguntas, parece captar mejor la calidad de la información que las evaluaciones actuales, lo que resalta una dirección para la investigación futura.', 'pt': 'Métricas baseadas em referência, como ROUGE ou BERTScore, avaliam a qualidade do conteúdo de um resumo comparando o resumo com uma referência. Idealmente, essa comparação deve medir a qualidade da informação do resumo calculando quanta informação os resumos têm em comum. Neste trabalho, analisamos os alinhamentos de token usados por ROUGE e BERTScore para comparar resumos e argumentamos que suas pontuações em grande parte não podem ser interpretadas como medidas de sobreposição de informações. Em vez disso, são melhores estimativas da extensão em que os resumos discutem os mesmos tópicos. Além disso, fornecemos evidências de que esse resultado é válido para muitas outras métricas de avaliação de sumarização. A consequência desse resultado é que as métricas de avaliação de sumarização mais utilizadas não se alinham com o objetivo de pesquisa da comunidade, de gerar resumos com informações de alta qualidade. No entanto, concluímos demonstrando que uma métrica proposta recentemente, QAEval, que pontua resumos usando respostas a perguntas, parece capturar melhor a qualidade da informação do que as avaliações atuais, destacando uma direção para pesquisas futuras.', 'fr': "Des métriques basées sur des références telles que ROUGE ou BertScore évaluent la qualité du contenu d'un résumé en le comparant à une référence. Idéalement, cette comparaison devrait mesurer la qualité de l'information du résumé en calculant la quantité d'informations que les résumés ont en commun. Dans ce travail, nous analysons les alignements de jetons utilisés par ROUGE et BertScore pour comparer les résumés et nous soutenons que leurs scores ne peuvent en grande partie pas être interprétés comme mesurant le chevauchement d'informations. Il s'agit plutôt d'une meilleure estimation de la mesure dans laquelle les résumés abordent les mêmes sujets. De plus, nous apportons la preuve que ce résultat est vrai pour de nombreuses autres mesures d'évaluation de synthèse. La conséquence de ce résultat est que les mesures d'évaluation de synthèse les plus fréquemment utilisées ne correspondent pas à l'objectif de recherche de la communauté, qui consiste à générer des résumés contenant des informations de haute qualité. Cependant, nous concluons en démontrant qu'une mesure récemment proposée, QAEval, qui note les résumés à l'aide de réponses aux questions, semble mieux saisir la qualité de l'information que les évaluations actuelles, ce qui met en évidence une orientation pour les recherches futures.", 'ja': 'ROUGEやBERTScoreなどの参照ベースの指標は、サマリーを参照と比較することによって、サマリーのコンテンツ品質を評価します。 理想的には、この比較は、要約に共通する情報の量を計算することによって、要約の情報品質を測定する必要があります。 この研究では、ルージュとBERTScoreが要約を比較するために使用したトークンアライメントを分析し、それらのスコアはほとんどが情報の重複を測定しているとは解釈できないと主張します。 むしろ、それらは、概要が同じトピックを論じる程度をよりよく見積もったものである。 さらに、この結果が他の多くの要約評価指標に当てはまることを示す証拠を提供します。 この結果の結果は、最も頻繁に使用される要約評価指標が、コミュニティの研究目標と一致しないことで、高品質の情報を含む要約を生成することになります。 しかし、最近提案された指標であるQAEvalは、質問への回答を使用して要約をスコアリングすることで、現在の評価よりも情報の質を把握することができるように見え、将来の研究の方向性を強調していることを示すことで締めくくります。', 'zh': '盖引用之指标(, ROUGE BERTScore)因将摘要与引用校较摘要质也。 计摘要多少,共量摘要息。 于此论ROUGEBERTScore以较摘要令牌,以为分数不可胜言。 反此,其益意摘要论同主题也。 此外供证据,多所总评指标。 凡此诸事,大率指标与社区不同,无以成高质量信之摘要。 然臣等所论,近出一指标QAEval,其用问对摘要评分,似愈于前评,显其未来所究。', 'ru': 'Справочные метрики, такие как ROUGE или BERTScore, оценивают качество контента резюме, сравнивая резюме со ссылкой. В идеале это сравнение должно измерять качество информации в резюме путем расчета объема информации, общей для резюме. В этой работе мы анализируем выравнивания токенов, используемые ROUGE и BERTScore для сравнения сводок, и утверждаем, что их оценки в значительной степени не могут быть интерпретированы как измерение перекрытия информации. Скорее, они являются более точными оценками того, в какой степени в резюме обсуждаются одни и те же темы. Кроме того, мы предоставляем доказательства того, что этот результат справедлив для многих других метрик оценки суммирования. Следствием этого результата является то, что наиболее часто используемые метрики оценки обобщения не согласуются с целью исследования сообщества, чтобы генерировать резюме с высококачественной информацией. Тем не менее, мы завершаем свое выступление демонстрацией того, что недавно предложенная метрика, QAEval, которая оценивает резюме с помощью ответов на вопросы, по-видимому, лучше отражает качество информации, чем текущие оценки, подчеркивая направление для будущих исследований.', 'hi': 'संदर्भ-आधारित मैट्रिक्स जैसे रूज या BERTScore सारांश की तुलना किसी संदर्भ से करके सारांश की सामग्री गुणवत्ता का मूल्यांकन करते हैं. आदर्श रूप से, इस तुलना को सारांश की जानकारी की गुणवत्ता को यह गणना करके मापना चाहिए कि सारांश में कितनी जानकारी आम है। इस काम में, हम सारांश की तुलना करने के लिए रूज और BERTScore द्वारा उपयोग किए जाने वाले टोकन संरेखणों का विश्लेषण करते हैं और तर्क देते हैं कि उनके स्कोर को काफी हद तक जानकारी ओवरलैप को मापने के रूप में व्याख्या नहीं की जा सकती है। इसके बजाय, वे उस हद तक बेहतर अनुमान हैं जिस पर सारांश एक ही विषय पर चर्चा करते हैं। इसके अलावा, हम सबूत प्रदान करते हैं कि यह परिणाम कई अन्य सारांश मूल्यांकन मीट्रिक के लिए सच है। इस परिणाम का परिणाम यह है कि सबसे अधिक बार उपयोग किए जाने वाले सारांश मूल्यांकन मीट्रिक समुदाय के शोध लक्ष्य के साथ संरेखित नहीं होते हैं, उच्च गुणवत्ता वाली जानकारी के साथ सारांश उत्पन्न करने के लिए। हालांकि, हम यह प्रदर्शित करके निष्कर्ष निकालते हैं कि हाल ही में प्रस्तावित मीट्रिक, QAEval, जो प्रश्न-उत्तर का उपयोग करके सारांश स्कोर करता है, वर्तमान मूल्यांकन की तुलना में जानकारी की गुणवत्ता को बेहतर तरीके से कैप्चर करने के लिए प्रकट होता है, जो भविष्य के शोध के लिए एक दिशा को उजागर करता है।', 'ga': 'Déanann méadracht atá bunaithe ar thagairtí mar ROUGE nó BERTScore cáilíocht an ábhair in achoimre a mheas trí an achoimre a chur i gcomparáid le tagairt. Go hidéalach, ba cheart go ndéanfadh an chomparáid seo cáilíocht faisnéise na hachoimre a thomhas tríd an méid faisnéise atá i gcoiteann sna hachoimrí a ríomh. San obair seo, déanaimid anailís ar na hailínithe comharthacha a úsáideann ROUGE agus BERTScore chun achoimrí a chur i gcomparáid agus áitíonn siad nach féidir a gcuid scóir a léirmhíniú den chuid is mó mar fhorluí faisnéise a thomhas. Ina ionad sin, is meastacháin níos fearr iad ar a mhéid a phléann na hachoimrí na hábhair chéanna. Ina theannta sin, cuirimid fianaise ar fáil go bhfuil an toradh seo fíor i gcás go leor méadrachtaí meastóireachta achoimre eile. Is é an toradh atá ar an toradh seo ná nach bhfuil na méadrachtaí meastóireachta achoimrithe is minice a úsáidtear ag teacht le sprioc taighde an phobail, chun achoimrí a ghiniúint le faisnéis ardcháilíochta. Mar fhocal scoir, áfach, léirímid go bhfuil an chuma air go bhfuil cáilíocht faisnéise níos fearr ag méadrach a moladh le déanaí, QAEval, a dhéanann scóráil achoimrí ag baint úsáide as freagra na gceisteanna, ná na meastóireachtaí reatha, ag leagan béime ar threo do thaighde amach anseo.', 'ka': 'Reference-based metrics such as ROUGE or BERTScore evaluates the content quality of a summary by comparing the summary with a reference. Ideally, this comparison should measure the information quality of the summary by calculating how much information the summaries have in common. ამ სამუშაოში, ჩვენ ვაანალიზებთ ROUGE და BERTScore-ის გამოყენებული სიმბოლოების შესაბამისთვის და არგუმენტებით, რომ მათი სიმბოლოები უფრო დიდი სიმბოლოების შესაბამისთვის შესაბამისთვი მაგრამ, ისინი უკეთესი განსაზღვრებები იგივე ტემების განსაზღვრებით. დამატებით, ჩვენ მივიღეთ წარმოდგენები, რომ ეს წარმოდგენა მნიშვნელოვანი სხვა რეზიუმიზაციის მეტრიკისთვის. ამ შედეგის შედეგია არის, რომ ყველაზე ბევრი გამოყენებული სისუბუზაციის განსაზღვრება მეტრიკები საზოგადოებო მიზეზი საზოგადოებო საზოგადოებო საზოგადოებო მიზეზი არ მაგრამ ჩვენ გავაკეთებთ, რომელიც ახლა წინასწარმოადგილებული მეტრიკური QAEval, რომელიც კითხვების გარეშე გამოყენება, უკეთესია ინფორმაციის კაalitეტის გააკეთება, ვიდრე მიმდინარეობის გარეშე.', 'el': 'Μετρητές βασισμένες σε αναφορές, όπως το ROUGE ή το BERTScore αξιολογούν την ποιότητα περιεχομένου μιας σύνοψης συγκρίνοντας τη σύνοψη με μια αναφορά. Ιδανικά, η σύγκριση αυτή θα πρέπει να μετρά την ποιότητα των πληροφοριών της περίληψης υπολογίζοντας πόσες πληροφορίες έχουν κοινές οι περιλήψεις. Σε αυτή την εργασία, αναλύουμε τις ευθυγραμμίσεις σημάτων που χρησιμοποιούνται από το ROUGE και το BERTScore για να συγκρίνουν περιλήψεις και υποστηρίζουμε ότι οι βαθμολογίες τους σε μεγάλο βαθμό δεν μπορούν να ερμηνευθούν ως επικάλυψη πληροφοριών μέτρησης. Αντίθετα, είναι καλύτερες εκτιμήσεις του βαθμού στον οποίο οι περιλήψεις συζητούν τα ίδια θέματα. Επιπλέον, παρέχουμε αποδείξεις ότι αυτό το αποτέλεσμα ισχύει για πολλές άλλες μετρήσεις αξιολόγησης συνοψίας. Η συνέπεια αυτού του αποτελέσματος είναι ότι οι πιο συχνά χρησιμοποιούμενες μετρήσεις αξιολόγησης συνοψίας δεν ευθυγραμμίζονται με τον ερευνητικό στόχο της κοινότητας, να δημιουργήσουν περιλήψεις με πληροφορίες υψηλής ποιότητας. Ωστόσο, καταλήγουμε αποδεικνύοντας ότι μια πρόσφατα προτεινόμενη μετρική, η οποία βαθμολογεί περιλήψεις χρησιμοποιώντας απαντήσεις σε ερωτήσεις, φαίνεται να αποτυπώνει καλύτερα την ποιότητα των πληροφοριών από τις τρέχουσες αξιολογήσεις, αναδεικνύοντας μια κατεύθυνση για μελλοντική έρευνα.', 'hu': 'A referencia-alapú mutatók, mint például a ROUGE vagy a BERTScore, az összefoglaló tartalmának minőségét egy hivatkozással történő összehasonlításával értékelik. Ideális esetben ennek az összehasonlításnak az összefoglaló információminőségét kellene mérnie azáltal, hogy kiszámítja, mennyi közös információt tartalmaz az összefoglalókban. Ebben a munkában elemezzük a ROUGE és BERTScore által használt token igazításokat az összefoglalók összehasonlítására, és azzal érvelünk, hogy pontszámaik nagyrészt nem értelmezhetők úgy, mint a mérési információk átfedése. Inkább jobban becsülik, hogy az összefoglalók milyen mértékben vitatják meg ugyanazokat a témákat. Továbbá bizonyítékot szolgáltatunk arra, hogy ez az eredmény igaz számos más összefoglaló értékelési mutató esetében. Ennek az eredménynek az a következménye, hogy a leggyakrabban használt összefoglaló értékelési mutatók nem igazodnak a közösség kutatási céljához, hogy kiváló minőségű információkat tartalmazó összefoglalókat készítsenek. Azonban azzal zárjuk le, hogy bebizonyítjuk, hogy egy nemrégiben javasolt mutató, a QAEval, amely a kérdésekre adott összefoglalókat eredményezi, jobban rögzíti az információk minőségét, mint a jelenlegi értékelések, kiemelve a jövőbeli kutatások irányát.', 'kk': 'ROUGE немесе BERTScore секілді сілтеме негіздеген метрикалар, тұжырымдамасын сілтемелерімен салыстырып, тұжырымдамасының мазмұнын бағалайды. Идеялық, бұл салыстыруы тұжырымдамасының мәліметінің сапасын қанша мәліметті жалпы деп есептеп өлшеу керек. Бұл жұмыс ішінде, ROUGE және BERTScore қолданылатын таңбаларды салыстыру үшін анализ және олардың нәтижелерін көбінде мәліметті өлшеу үшін толтырылмайды. Әйтпесе, олар бір тақырыптарды таңдау үшін жақсы бағалау. Сонымен қатар, бұл нәтижесі басқа жазуларды бағалау метрикалары үшін дұрыс болады дегенді көрсеткіземіз. Бұл нәтижесінің нәтижесі - ең көбірек қолданылатын тұжырымдамасын бағалау метрикалары қоғамдық зерттеу мақсатымен бірге тұжырымдамасын жоғары сапатты мәліметтерді құру үшін. Бірақ біз соңғы келтірілген метрикалық QAEval мәліметтерін көрсету арқылы сұрақ жауап беру арқылы мәліметтердің сапасын қазіргі бағалауынан жақсы түсіндіру арқылы, келесі зерттеулердің бағыттауын бо', 'it': "Le metriche basate su riferimento come ROUGE o BERTScore valutano la qualità del contenuto di un riassunto confrontando il riassunto con un riferimento. Idealmente, questo confronto dovrebbe misurare la qualità delle informazioni della sintesi calcolando quante informazioni hanno in comune le sintesi. In questo lavoro analizziamo gli allineamenti token utilizzati da ROUGE e BERTScore per confrontare i riassunti e sosteniamo che i loro punteggi in gran parte non possono essere interpretati come sovrapposizioni di informazioni di misurazione. Si tratta piuttosto di una migliore stima della misura in cui i riassunti discutono gli stessi argomenti. Inoltre, forniamo prove che questo risultato vale per molte altre metriche di valutazione di sintesi. La conseguenza di questo risultato è che le metriche di valutazione di sintesi più utilizzate non si allineano con l'obiettivo di ricerca della comunità, per generare riassunti con informazioni di alta qualità. Tuttavia, concludiamo dimostrando che una metrica proposta di recente, QAEval, che segna riassunti utilizzando la risposta alle domande, sembra catturare meglio la qualità delle informazioni rispetto alle valutazioni attuali, evidenziando una direzione per la ricerca futura.", 'mk': 'Метрики базирани на референција, како што се ROUGE или BERTScore го проценуваат квалитетот на содржината на резултатот со споредба на резултатот со референција. Идеално, оваа споредба треба да го мери квалитетот на информациите на резултатот со пресметка на колку информации имаат заеднички резултати. Во оваа работа, ги анализираме прилагодувањата на знаците кои ги користат ROUGE и BERTScore за да ги споредиме резултатите и да тврдиме дека нивните резултати во голема мера не можат да се толкуваат како мерење на прекривањето на информациите. Rather, they are better estimates of the extent to which the summaries discuss the same topics.  Покрај тоа, ние обезбедуваме докази дека овој резултат е точен за многу други метрики за резултат на евалуацијата. Последницата од овој резултат е дека најчесто употребените метрики на резултатот на проценката не се согласуваат со целта на истражувањето на заедницата, за генерирање резултати со висококвалитетни информации. Сепак, заклучуваме со демонстрација дека неодамна предложениот метричен QAEval, кој поставува резултати користејќи одговори на прашања, се чини дека подобро го зазема квалитетот на информациите отколку сегашните оценки, истакнувајќи ја насоката за идното истражување.', 'ms': 'Metrik berasaskan rujukan seperti ROUGE atau BERTScore menilai kualiti kandungan ringkasan dengan membandingkan ringkasan dengan rujukan. Idealnya, perbandingan ini patut mengukur kualiti maklumat ringkasan dengan mengira berapa banyak maklumat ringkasan mempunyai secara umum. Dalam kerja ini, kami menganalisis penyesuaian token yang digunakan oleh ROUGE dan BERTScore untuk membandingkan ringkasan dan membantah bahawa skor mereka kebanyakan tidak dapat diterangkan sebagai mengukur maklumat meliputi. Sebaliknya, mereka adalah perhitungan yang lebih baik terhadap jumlah yang ringkasan membincangkan topik yang sama. Selain itu, kami memberikan bukti bahawa hasil ini adalah benar untuk banyak metrik penilaian ringkasan lain. Hasilnya ialah bahawa metrik penilaian ringkasan yang paling sering digunakan tidak sepadan dengan tujuan kajian komuniti, untuk menghasilkan ringkasan dengan maklumat kualiti tinggi. Namun, kami menyimpulkan dengan menunjukkan bahawa metrik yang diusulkan baru-baru ini, QAEval, yang mencetak ringkasan menggunakan jawapan-soalan, kelihatan lebih baik menangkap kualiti maklumat daripada penilaian semasa, menyatakan arah untuk kajian masa depan.', 'ml': 'രൂജെയോ ബെര്\u200dട്ടിസ്കോരോ പോലുള്ള പരിഗണന മെറ്റിക്കുകള്\u200d ഒരു വിവരണത്തിന്റെ ഉള്ളടക്കത്തിന്റെ ഉള്ളടക്കത്തിന്റെ ഉള്ളടക്കത് ആശയത്തില്\u200d, ഈ താല്\u200dക്കൂട്ടത്തില്\u200d വിവരങ്ങളുടെ വിവരങ്ങള്\u200d എത്ര സാധാരണ വിവരങ്ങളുണ്ടെന്ന് കണക്കാക്കുന്നതിനാല്\u200d വിവ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d രൂജെയും ബെര്\u200dട്ടിസ്കോരും ഉപയോഗിക്കുന്ന അടയാളങ്ങള്\u200d അന്വേഷിക്കുന്നു. വിവരങ്ങളുടെ സ്കോര്\u200d മുകളില്\u200d വിവരങ്ങള്\u200d അളക് മറിച്ച്, അതിനെക്കാളും നല്ല കണക്കുകളാണ് ഈ വേനലുകള്\u200d ഒരേ കാര്യത്തില്\u200d സംസാരിക്കുന്നത്. അതിനുശേഷം, നമുക്ക് തെളിവുകള്\u200d നല്\u200dകുന്നു, ഇതിന്റെ ഫലം വേറെയൊരു ചുരുക്കുന്ന വിലാസം മെട്രിക്കിന് സത് ഈ ഫലത്തിന്റെ ഫലമെന്തെന്നാല്\u200d ഏറ്റവും പ്രാവശ്യം ഉപയോഗിക്കുന്ന വിലാസവിശേഷവില മെട്രിക്കുകള്\u200d സമൂഹത്തിന്റെ പഠനത്തിന്റെ ലക്ഷ്യം കൊണ് എന്നാലും നമ്മള്\u200d തീരുമാനിക്കുന്നത് പ്രസ്താവിക്കുന്ന ക്യൂഎവാലിന്റെ അടുത്തുള്ള പ്രായശ്ചിത്ത മെറ്റിക്ക്, ചോദ്യത്തിന്റെ ഉത്തരമുള്ള വിവരങ', 'mt': 'Il-metriċi bbażati fuq referenza bħal ROUGE jew BERTScore jevalwaw il-kwalità tal-kontenut ta’ sommarju billi jqabblu s-sommarju ma’ referenza. Idealment, dan it-tqabbil għandu jkejjel il-kwalità tal-informazzjoni tas-sommarju billi jikkalkula kemm informazzjoni għandhom is-sommarji komuni. F’dan ix-xogħol, aħna tanalizzaw l-allinjamenti tat-tokens użati minn ROUGE u BERTScore biex jitqabblu s-sommarji u jargumentaw li l-punteġġi tagħhom fil-biċċa l-kbira ma jistgħux jiġu interpretati bħala kejl ta’ sovrappożizzjoni tal-informazzjoni. Minflok, huma stimi aħjar tal-punt sa fejn is-sommarji jiddiskutu l-istess suġġetti. Barra minn hekk, nagħtu evidenza li dan ir-riżultat jgħodd għal ħafna metriċi oħra ta’ evalwazzjoni tas-sommarju. Il-konsegwenza ta’ dan ir-riżultat hija li l-metriċi tal-evalwazzjoni tas-sommarju l-aktar użati ma jallinjawx mal-għan tar-riċerka tal-komunità, biex jiġġeneraw sommarji b’informazzjoni ta’ kwalità għolja. Madankollu, a ħna kkonkludew billi nippruvaw li l-valutazzjoni metrika proposta reċentement, QAEval, li tagħmel sommarji bl-użu tat-tweġibiet għall-mistoqsijiet, tidher li taqbad aħjar il-kwalità tal-informazzjoni mill-evalwazzjonijiet attwali, u tenfasizza direzzjoni għar-riċerka futura.', 'mn': 'ROUGE эсвэл BERTScore зэрэг тодорхойлолтын хэмжээсүүдийг тодорхойлоход тодорхойлолтын үнэ цэнэтэй метрик юм. Эдгээр харьцуулалтын хэмжээний мэдээллийн хэмжээний нийтлэг мэдээллийг тооцоолж энэ харьцуулалт хэмжээтэй. Энэ ажлын тулд бид ROUGE болон BERTScore-ын хэрэглэгдсэн тодорхойлолтуудыг харьцуулж, тэдний тодорхойлолтуудыг ихэнхдээ мэдээлэл дутагдаж чадахгүй гэдгийг хэлдэг. Үнэндээ тэд ижил сэдэв дээр хэлэхэд илүү сайн тооцоологддог. Дараа нь бид энэ үр дүн нь бусад олон жинхэнэ дүгнэлтийн метрийг үнэн гэдгийг баталж байна. Үүний үр дүний үр дүнг нь хамгийн ихэвчлэн хэрэглэгдсэн жинхэнэ хэмжээсүүд нь нийгмийн судалгааны зорилго, өндөр чанартай мэдээллийн жинхэнэ хэмжээсүүд бий болгох боломжгүй. Гэхдээ бид сүүлийн үед асуулт хариултыг ашиглан хэмжээний метрик QAEval-ын санал болгон мэдээллийн чанарыг одоогийн шалгалтаас илүү сайхан аваад ирээдүйн судалгааны замыг тодорхойлж байна.', 'pl': 'Oparte na referencjach wskaźniki, takie jak ROUGE lub BERTScore, oceniają jakość treści podsumowania poprzez porównanie podsumowania z odniesieniem. Najlepiej, porównanie to powinno mierzyć jakość informacji podsumowania poprzez obliczenie ilości informacji mają wspólne podsumowania. W niniejszej pracy analizujemy wyrównania tokenów używane przez ROUGE i BERTScore do porównywania podsumowań i argumentujemy, że ich wyniki w dużej mierze nie mogą być interpretowane jako nakładanie się informacji pomiarowych. Są to raczej lepsze oszacowania zakresu, w jakim streszczenia omawiają te same tematy. Ponadto dostarczamy dowody, że wynik ten dotyczy wielu innych wskaźników oceny podsumowania. Konsekwencją tego wyniku jest to, że najczęściej stosowane wskaźniki oceny podsumowania nie są zgodne z celem badawczym społeczności, jakim jest generowanie podsumowań z wysokiej jakości informacji. Podsumowujemy jednak, wykazując, że niedawno proponowana metryka QAEval, która ocenia podsumowania za pomocą odpowiedzi na pytania, wydaje się lepiej przechwytywać jakość informacji niż obecne oceny, wskazując kierunek dla przyszłych badań.', 'ro': 'Măsurătorile bazate pe referință, cum ar fi ROUGE sau BERTScore, evaluează calitatea conținutului unui rezumat prin compararea rezumatului cu o referință. În mod ideal, această comparație ar trebui să măsoare calitatea informațiilor rezumatului prin calcularea câtor informații au în comun rezumatele. În această lucrare, analizăm alinierile token folosite de ROUGE și BERTScore pentru a compara rezumatele și susținem că scorurile lor nu pot fi interpretate în mare măsură ca suprapunerea informațiilor de măsurare. Mai degrabă, acestea reprezintă o estimare mai bună a măsurii în care rezumatele discută aceleași subiecte. Mai mult, furnizăm dovezi că acest rezultat este valabil pentru multe alte măsuri de evaluare a rezumatului. Consecința acestui rezultat este că cele mai frecvent utilizate metrice de evaluare a rezumatului nu se aliniază cu obiectivul comunității de cercetare, pentru a genera rezumate cu informații de înaltă calitate. Cu toate acestea, concluzionăm demonstrând că o metrică recent propusă, QAEval, care punctează rezumate folosind răspunsul la întrebări, pare să capteze mai bine calitatea informațiilor decât evaluările actuale, evidențiind direcția pentru cercetarea viitoare.', 'no': 'Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Dette sammenligninga skal måle informasjonskvaliteten til sammendraga ved å rekna ut kor mykje informasjon sammendraga har i felles. I denne arbeida analyserer vi innstillingane for token som er brukt av ROUGE og BERTScore for å samanlikna samandringar og argumenterer at poeng sine hovudsakelig kan ikkje tolkast som målarinformasjon overlappar. I staden er dei bedre vurdering av kor mykje sammendragane diskuterer dei same emna. I tillegg har vi beviser at denne resultatet inneheld sann for mange andre sammendragsverdimetrikar. Resultatet av denne resultatet er at dei mest ofte brukte sammendragsresuleringsmetrikane ikkje tilsvarar samfunnets forskningsmål, for å laga sammendragar med høg kvalitetsinformasjon. Men vi avsluttar med å demonstrere at ein nyleg foreslått metrisk QAEval, som reknar samandrag med spørsmålssvar, ser ut til at det er betre å henta informasjonskvalitet enn gjeldande evaluering, som markerer ein retning for framtidige forskning.', 'lt': "Nuorodomis pagrįsti metriniai rodikliai, pavyzdžiui, ROUGE arba BERTScore, vertina santraukos turinio kokybę palygindami santrauką su nuoroda. Idealu, kad šis palyginimas turėtų įvertinti santraukos informacijos kokybę apskaičiuojant, kiek informacijos santraukos turi bendrai. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely cannot be interpreted as measuring information overlap.  Rather, they are better estimates of the extent to which the summaries discuss the same topics.  Further, we provide evidence that this result holds true for many other summarization evaluation metrics.  The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community's research goal, to generate summaries with high-quality information.  Vis dėlto galime daryti išvadą įrodydami, kad neseniai pasiūlytas metrinis QAEval, kuriame pateikiamos santraukos naudojant atsakymus į klausimus, atrodo geriau apibūdinama informacijos kokybė nei dabartiniai vertinimai, pabrėžiant būsimų mokslinių tyrimų kryptį.", 'sv': 'Referensbaserade mätvärden som ROUGE eller BERTScore utvärderar innehållskvaliteten i en sammanfattning genom att jämföra sammanfattningen med en referens. Helst bör denna jämförelse mäta sammanfattningens informationskvalitet genom att beräkna hur mycket information sammanfattningarna har gemensamt. I detta arbete analyserar vi de tokenjusteringar som ROUGE och BERTScore använder för att jämföra sammanfattningar och argumenterar för att deras poäng till stor del inte kan tolkas som att mätinformation överlappar. Det är snarare bättre uppskattningar av i vilken utsträckning sammanfattningarna diskuterar samma ämnen. Vidare ger vi bevis för att detta resultat stämmer för många andra sammanfattningsutvärderingsmetoder. Konsekvensen av detta resultat är att de vanligaste mätvärdena för sammanfattning inte stämmer överens med gemenskapens forskningsmål, att generera sammanfattningar med högkvalitativ information. Vi avslutar dock med att visa att ett nyligen föreslaget mätvärde, QAEval, som poängterar sammanfattningar med hjälp av frågesvar, verkar bättre fånga in information kvalitet än nuvarande utvärderingar och belysa en riktning för framtida forskning.', 'sr': 'Na referenciji bazirane metrike poput ROUGE ili BERTScore procjenjuju kvalitet sadržaja sažetka uspoređujući sažetak sa referencijom. Idealno, ta usporedba bi trebala izmjeriti kvalitet informacija sažetka izračunati koliko informacija imaju zajedničke sažetke. U ovom poslu analiziramo poravnanje znakova koje su koristili ROUGE i BERTScore kako bi usporedili sažetke i tvrdili da njihovi rezultati u velikoj meri ne mogu biti interpretisani kao mjerenje informacija. Umesto toga, oni su bolja procjena koliko su sažetke razgovarale o istim temama. Nadalje, pružamo dokaze da ovaj rezultat ima istinu za mnoge druge metrike za procjenu rezervacije. Posljedica ovog rezultata je da najčešće korištenija metrika za procjenu rezervacije ne odgovara istraživanjama zajednice, kako bi stvorila sažetke sa visokokvalitetnim informacijama. Međutim, zaključili smo pokazivajući da nedavno predloženi metrički QAEval, koji rezultira sažetke koristeći odgovor na pitanje, izgleda da je bolje uhvatiti kvalitet informacija nego trenutne procjene, naglašavajući pravac za buduće istraživanje.', 'si': 'Reference-based metrics, e.g. ROUGE හෝ BERTScore, evalute the contingent of a summary by comparing the summary to a reference. සාමාන්\u200dය විශේෂයෙන්, මේ විරුද්ධ විරුද්ධ විශේෂය සමාන්\u200dය තොරතුරු ගොඩක් තොරතුරු තොරතුරු ගැන ගණන මේ වැඩේදී, අපි ROUGE සහ BERTScore වල භාවිත කරපු ටොකෙන් සංවිධානය විශ්ලේෂණය කරනවා සංවිධානය සහ ඔවුන්ගේ සංකේතය ගොඩක් විශේෂණය වෙනස් විතරයි, ඔවුන් හොඳ විශ්වාස කරනවා ඒ වගේම විශ්වාස කතා කරනවා කියලා. තවත්, අපි සාක්ෂියක් දෙන්නේ මේ ප්\u200dරතිචාර අනිත් සාක්ෂියක් විශ්වාස කරනවා කියලා. මේ ප්\u200dරතිචාරයේ ප්\u200dරතිචාරයක් තමයි සාමාන්\u200dය විශ්වාස කරන්න ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් සමාජයේ පරීක්ෂණ අරමුණ සමග ස නමුත්, අපි පෙන්වන්න පුළුවන් විදිහට ප්\u200dරතික්ෂා කරනවා මෙට්\u200dරික්, QAeval, ප්\u200dරශ්ණ ප්\u200dරතික්ෂණ ප්\u200dරතික්ෂණය සඳහා ප්\u200dරශ්ණ ප්\u200dරවේශනය', 'ta': 'குறிப்பிட்ட மெட்ரிக்கள் ROUGE அல்லது BERTScore போன்ற சுருக்கத்தின் உள்ளடக்கத்தின் தரமை மதிப்பிடும் சுருக்கத்தை குறிப்பிட இந்த ஒப்பிடுதல் சுருக்கிய தகவல் எத்தனை பொதுவாக இருக்கும் என்பதை கணக்கிடும் பொது சுருக்க தகவல் தரம் சுருக்கிய தரம் அளவ இந்த வேலையில், ROUGE மற்றும் BERTScore பயன்படுத்தப்பட்ட குறியீட்டு ஒழுங்குப்பெயர்ப்புகளை ஆய்வு செய்து சுருக்கத்தை ஒப்பிடுவதற்காகவும் வாதம அதற்குப் பதிலாக, குருக்குகள் அதே தலைப்புகளை பேசிக் கொண்டிருக்கும் அளவில் அவர்கள் சிறந்த கணக்கிடுகிறார்கள். மேலும், இந்த முடிவு உண்மையானது மற்ற பல சுருக்கல் மதிப்பின் முறைகளுக்கு உண்மையானது. இந்த முடிவின் முடிவு என்னவென்றால் அதிகமாக பயன்படுத்தப்பட்ட சுருக்கல் மதிப்பீடு மெட்ரிக்கள் சமூகத்தின் ஆராய்ச்சியின் இலக்குகளுடன் ஒத் எனினும், நாம் முடிவு செய்து குறிப்பிடுவதால் சமீபத்தில் கேள்வி பதில் விடையை பயன்படுத்தி மதிப்புகளை பிடிக்கும் தகவல் தரம் தற்போதைய மதிப்புகளை விட சி', 'ur': 'Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. نظریہ سے، یہ مقایسہ کیسا معلومات کا اندازہ کرنا چاہیے، جتنی معلومات کی تعداد کے مطابق ہے. اس کام میں ہم روگ اور BERTScore کے ذریعے استعمال ہوئے ٹونٹ الیمینٹوں کو تحقیق کرتے ہیں کہ ان کے نمائندے بہت بڑے طور پر معلومات کے مطابق مطابق نہیں کر سکتے۔ بلکہ یہ بہتر اندازے ہیں جس طرح سراسر سراسر موضوع کے بارے میں صحبت کرتے ہیں اور ہم نے مدد دی ہے کہ یہ نتیجہ بہت سے دوسرے سراسر ارزیابی متریک کے لئے سچا ہے۔ اس نتیجہ کا نتیجہ یہ ہے کہ سب سے زیادہ استعمال کیا گیا سامنے کا ارزش مطالعہ متریک کمونٹی کی تحقیق کا موقعہ سے برابر نہیں ہوتا، بلند کیفیت معلومات کے ساتھ سراسر پیدا کرنے کے لئے۔ لیکن ہم نے دکھایا ہے کہ اچھی طرح ایک متریک QAEval، جو سوال جواب کے مطابق اسکور کرتا ہے، اس سے بہتر اطلاعات کی کیفیت حاصل کرتی ہے، اور آینده تحقیقات کے لئے ایک طریقہ ہلاک کرتی ہے.', 'so': "Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference.  Ideally, this comparison should measure the summary's information quality by calculating how much information the summaries have in common.  Shuqulkaas waxaynu baaraynaa sawirada ee loo isticmaalay ROUGE iyo BERTScore, si aan u barbardhigno summirka islamarkaasna waxaynu ka doodaynaa in scorahooda ugu badan looma turjumi karo sida qiyaasta macluumaadka la kordhiyo. Intaas waxaa ka wanaagsan qiimeynta ay ku hadlaan isla maadooyinka xagaagu. Sidoo kale waxaan siinaynaa caddeynta in sababtu ay run u leedahay qiimeynta qiimeynta kale oo badan. Sababtaas dhamaadkeedu waa in inta badan lagu isticmaalay qiimeynta qiimeynta summarinta aysan la mid dhigin goalka waxbarashada ee bulshada, in lagu soo saaro summariyo macluumaad sare. However, we conclude by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research.", 'vi': 'Âm tiết dựa trên kinh nghiệm, như ROLạ hay BERTSdại, đánh giá chất lượng của một bản tóm tắt bằng cách so sánh bản tóm tắt với một tham khảo. Lý tưởng nhất là so s ánh này sẽ đo mức độ chất lượng thông tin của bản tóm tắt bằng cách tính số thông tin mà các bản tóm tắt có chung. Trong công việc này, chúng tôi phân tích kết hợp tượng trưng được sử dụng bởi ROG và BERTSCORE để so sánh các bản tóm tắt và nói rằng điểm của họ không thể được giải thích như đo đạc thông tin chồng chéo. Thay vào đó, chúng là những ước tính tốt hơn về mức độ các bản tóm tắt thảo luận cùng một chủ đề. Chúng tôi cung cấp bằng chứng rằng kết quả này đúng với nhiều âm lượng đánh giá mô phỏng khác. Kết quả của kết quả này là hệ thống đo hồ s ơ được sử dụng thường xuyên không phù hợp với mục tiêu nghiên cứu của cộng đồng, để tạo ra các bản tóm tắt với thông tin chất cao. Tuy nhiên, kết thúc bằng cách chứng minh rằng một thước đo mét gần đây, QAEval, ghi điểm cho các bản tóm tắt dùng câu hỏi, có vẻ nắm bắt cao chất lượng thông tin hơn những đánh giá hiện thời, nhằm nhấn mạnh hướng dẫn cho nghiên cứu tương lai.', 'uz': "Name @ info: whatsthis Bu vazida, biz qismlarni kamaytirish uchun RAUGE va BERTScore tomonidan foydalanuvchi belgilarni تەھلىل qilamiz va qidirish mumkin, ularning qiymatlari ko'proq maʼlumot yopib olib tashlab boʻlmaydi deb o'ylaymiz. Hullas, maktablar bitta mavzu bilan gapirayotganda eng yaxshi qiymatlar. Ko'pchilik, bu natijasi boshqa ko'pchilik qiymati metriklariga haqiqida ega bo'ladi. Bu natijaning natijasi, ko'p ko'p ishlatilgan qiymatni qiymatlash metriklari jamiyatning qidirish maqola bilan birlashtirilmaydi, eng darajali maʼlumot bilan qiymatni yaratish uchun. Lekin, biz yaqinda rivojlanadigan metrik, QAEval, savol javoblari bilan qiymatni qiymatida qiymatni ko'rsatish mumkin, hozirgi qiymatlardan yaxshi maʼlumot sifatini olib tashlash mumkin, kelajak qidirish uchun bir tizimni ko'rsatish mumkin.", 'bg': 'Референтните показатели като оценяват качеството на съдържанието на резюме чрез сравняване на резюмето с препратка. В идеалния случай това сравнение трябва да измерва качеството на информацията в резюмето чрез изчисляване на общата информация в резюмето. В тази работа анализираме символните подравнявания, използвани от ROUGE и BERTScore за сравняване на резюмета и твърдим, че техните оценки до голяма степен не могат да бъдат тълкувани като измерване на припокриване на информацията. По-скоро те са по-добри оценки за степента, в която резюметата обсъждат едни и същи теми. Освен това предоставяме доказателства, че този резултат важи за много други показатели за оценка на обобщението. Последствие от този резултат е, че най-често използваните показатели за оценка на обобщението не съответстват на научноизследователската цел на общността, да генерират резюмета с висококачествена информация. В заключение обаче демонстрираме, че наскоро предложеният показател, който оценява резюметата чрез отговор на въпроси, изглежда по-добре улавя качеството на информацията в сравнение с настоящите оценки, подчертавайки посоката за бъдещи изследвания.', 'hr': 'Premjerene metrike poput ROUGE ili BERTScore procjenjuju kvalitet sadržaja sažetka uspoređujući sažetak s referentom. Idealno, ta usporedba bi trebala mjeriti kvalitet informacija sažetka izračunati koliko informacija imaju zajedničke sažetke. U ovom poslu analiziramo poravnanje znakova koje su koristili ROUGE i BERTScore kako bi usporedili sažetke i tvrdili da njihovi rezultati u velikoj mjeri ne mogu biti interpretirani kao mjerenje informacija. Umjesto toga, oni su bolja procjena u mjeri u kojoj sažetci razgovaraju o istim temama. Nadalje, pružamo dokaze da je taj rezultat istinito za mnoge druge mjere za procjenu rezervacije. Posljedica ovog rezultata je da najčešće korištenija metrika za procjenu sažetke ne odgovara istraživačkom cilju zajednice, kako bi proizvela sažetke s visokokvalitetnim informacijama. Međutim, zaključili smo pokazivajući da nedavno predloženi metrički QAEval, koji rezultira sažetke koristeći odgovor na pitanje, čini se da je bolje uhvatiti kvalitet informacija nego trenutne procjene, naglašavajući smjeru za buduće istraživanje.', 'nl': 'Referentiegebaseerde statistieken zoals ROUGE of BERTScore evalueren de inhoudskwaliteit van een samenvatting door de samenvatting te vergelijken met een referentie. Idealiter zou deze vergelijking de informatiekwaliteit van de samenvatting moeten meten door te berekenen hoeveel informatie de samenvattingen gemeen hebben. In dit werk analyseren we de token alignments die ROUGE en BERTScore gebruiken om samenvattingen te vergelijken en stellen we vast dat hun scores grotendeels niet kunnen worden geïnterpreteerd als meetinformatie overlap. Het zijn veeleer betere schattingen van de mate waarin de samenvattingen dezelfde onderwerpen behandelen. Verder leveren we bewijs dat dit resultaat geldt voor vele andere samenvattingsevaluatiestatistieken. Het gevolg van dit resultaat is dat de meest gebruikte samenvattingsevaluatiestatistieken niet overeenkomen met het onderzoeksdoel van de gemeenschap, om samenvattingen te genereren met hoogwaardige informatie. We sluiten echter af door aan te tonen dat een recent voorgestelde metric, QAEval, die samenvattingen scoort met behulp van vragenantwoorden, de kwaliteit van informatie beter lijkt te vangen dan huidige evaluaties, wat een richting voor toekomstig onderzoek benadrukt.', 'da': 'Referencebaserede målinger som ROUGE eller BERTScore evaluerer indholdskvaliteten af et resumé ved at sammenligne resuméet med en reference. Ideelt set bør denne sammenligning måle resuméets informationskvalitet ved at beregne, hvor mange oplysninger resuméerne har til fælles. I dette arbejde analyserer vi de tokenjusteringer, der bruges af ROUGE og BERTScore til at sammenligne resuméer og argumenterer for, at deres scores stort set ikke kan fortolkes som overlapning af måleinformationer. De er snarere bedre vurderinger af, i hvilket omfang resuméerne drøfter de samme emner. Desuden giver vi dokumentation for, at dette resultat gælder for mange andre opsummeringsevalueringsmålinger. Konsekvensen af dette resultat er, at de hyppigst anvendte opsummeringsevalueringsmålinger ikke stemmer overens med fællesskabets forskningsmål om at generere opsummeringer med information af høj kvalitet. Vi konkluderer dog med at demonstrere, at en nyligt foreslået metric, QAEval, som scorer resuméer ved hjælp af spørgsmål-besvarelse, synes bedre at fange informationskvaliteten end nuværende evalueringer og fremhæve en retning for fremtidig forskning.', 'de': 'Referenzbasierte Metriken wie ROUGE oder BERTScore bewerten die Inhaltsqualität einer Zusammenfassung, indem sie die Zusammenfassung mit einer Referenz vergleichen. Idealerweise sollte dieser Vergleich die Informationsqualität der Zusammenfassung messen, indem berechnet wird, wie viele Informationen die Zusammenfassungen gemeinsam haben. In dieser Arbeit analysieren wir die Token Alignments, die von ROUGE und BERTScore verwendet werden, um Zusammenfassungen zu vergleichen und argumentieren, dass ihre Scores weitgehend nicht als Überlappung von Messinformationen interpretiert werden können. Vielmehr sind sie bessere Schätzungen darüber, inwieweit die Zusammenfassungen dieselben Themen behandeln. Darüber hinaus liefern wir Beweise dafür, dass dieses Ergebnis für viele andere Summaryzation Evaluation Metriken zutrifft. Die Konsequenz dieses Ergebnisses ist, dass die am häufigsten verwendeten Summarisierungsmetriken nicht mit dem Forschungsziel der Community übereinstimmen, Zusammenfassungen mit hochwertigen Informationen zu generieren. Wir schließen jedoch mit dem Nachweis, dass eine kürzlich vorgeschlagene Metrik, QAEval, die Zusammenfassungen mittels Fragebeantworterung bewertet, die Informationsqualität besser erfasst als aktuelle Auswertungen, was eine Richtung für zukünftige Forschung aufzeigt.', 'id': 'Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference.  Idealnya, perbandingan ini harus mengukur kualitas informasi ringkasan dengan menghitung berapa banyak informasi ringkasan memiliki secara umum. Dalam pekerjaan ini, kami menganalisa penyesuaian token yang digunakan oleh ROUGE dan BERTScore untuk membandingkan ringkasan dan argumen bahwa skor mereka kebanyakan tidak dapat diterjemahkan sebagai mengukur informasi yang meliputi. Sebaliknya, merekalah perhitungan yang lebih baik dari seberapa besar sumber ringkasan mendiskusikan topik yang sama. Selain itu, kami menyediakan bukti bahwa hasil ini benar untuk banyak metrik penghargaan penghargaan lainnya. Konsekuensi dari hasil ini adalah bahwa metrik pengiraan pengiraan yang paling sering digunakan tidak sesuai dengan tujuan penelitian komunitas, untuk menghasilkan ringkasan dengan informasi kualitas tinggi. Namun, kami menyimpulkan dengan menunjukkan bahwa metrik yang baru-baru ini diusulkan, QAEval, yang mencetak ringkasan menggunakan jawaban pertanyaan, tampaknya lebih baik menangkap kualitas informasi daripada evaluasi saat ini, menyatakan arah untuk penelitian masa depan.', 'fa': 'متریک\u200cهای بنیاد بررسی مانند ROUGE یا BERTScore، کیفیت محتویات یک جمع را با مقایسه کردن جمع با یک بررسی ارزش می\u200cدهد. این مقایسه باید کیفیت اطلاعات عمومی را با محاسبه کردن چقدر اطلاعات عمومی دارند اندازه گیری کند. در این کار، ما تفاوت\u200cهای نشانه\u200cها را که توسط ROUGE و BERTScore استفاده می\u200cکنند تحلیل می\u200cکنیم تا جمعیت\u200cها را مقایسه کنیم و بحث کنیم که امتیاز\u200cهایشان بیشتر نمی\u200cتوانند به عنوان اندازه\u200cگیری اطلاعات تفاوت کنند. بلکه آنها تقدیر بهتر از حدی است که جمع\u200cها در مورد همان موضوع صحبت می\u200cکنند. بعلاوه، ما مدرک می دهیم که این نتیجه برای مقدار تعداد زیادی دیگر حقیقت دارد. نتیجه این نتیجه این است که متریک ارزیابی جمع\u200cآوری که اغلب استفاده می\u200cشود با هدف تحقیقات جامعه تطبیق نمی\u200cکنند، برای تولید جمع\u200cآوری با اطلاعات کیفیت بالا. با این حال، ما با نشان دادن که اخیراً یک متریک QAEval پیشنهاد شده است، که با استفاده از پاسخ پرسش، جمع\u200cآوری می\u200cکند، به نظر می\u200cرسد که کیفیت اطلاعات بهتر از ارزیابی\u200cهای جاری گرفتن اطلاعات را از ارزیابی\u200cهای جاری است، و راهی برای تحقیقات', 'ko': 'ROUGE 또는 BERTScore와 같은 참조 지표를 기준으로 요약과 참조를 비교하여 요약의 내용 품질을 평가합니다.이상적인 상황에서 이런 비교는 모두 얼마나 많은 정보를 계산하여 총결한 정보의 질을 평가해야 한다.이 작업에서 우리는 ROUGE와 BERTScore가 비교 총결산에 사용하는 표기 정렬을 분석했고 그들의 점수는 측정 정보가 중첩된 것으로 해석할 수 없다고 주장했다.반대로 그들은 같은 주제를 총괄적으로 토론하는 정도에 대한 더 좋은 평가이다.그 밖에 우리가 제공한 증거에 의하면 이 결과는 많은 다른 총괄 평가 지표에 적용된다고 한다.이 결과의 결과는 가장 자주 사용하는 요약 평가 지표와 지역사회의 연구 목표가 일치하지 않아 질 좋은 정보를 가진 요약을 만들 수 없다는 것이다.그러나 최근 제시된 지표인 QAEval(Q&amp;A로 요약을 채점)은 현재의 평가보다 정보의 질을 더 잘 포착하고 미래 연구에 방향을 제시하는 것 같다는 결론이다.', 'sw': 'mbinu zilizotegemea kwenye michoro kama vile ROUGE au BERTScore kutathmini kiwango cha muhtasari kwa kulinganisha muhtasari na kurejesha maoni. Kadhalika, hii inapaswa kupima kiwango cha habari cha muhtasari kwa kuhesabu kiasi gani taarifa za kiangazi cha kiangazi cha kiangazi kinachofanana. Katika kazi hii, tunachambua alama zinazotumiwa na ROUGE na BERTScore ili kulinganisha muhtasari na kusema kuwa score zao kwa kiasi kikubwa hauwezi tafsiri kama kupima upya taarifa. Badala yake, wanakadiriwa vizuri zaidi kwa kiasi gani muhtasari wa kiangazi hujadili mada hiyo. Further, we provide evidence that this result holds true for many other summarization evaluation metrics.  Matokeo ya matokeo haya ni kwamba mbinu za uchunguzi mara nyingi zinazotumiwa mara kwa mara hazijaunganisha na lengo la utafiti wa jamii, kutengeneza muhtasari kwa taarifa za juu. Hata hivyo, tunahitimisha kwa kuonyesha kuwa mbinu iliyopendekezwa hivi karibuni, QAEval, ambayo inaonyesha muhtasari kwa kutumia majibu ya maswali, inaonekana kuwa ni vizuri zaidi ya kiwango cha taarifa kuliko tafiti za sasa, ikionyesha mwelekeo wa utafiti wa baadaye.', 'af': "Verwysing- gebaseerde metries soos ROUGE of BERTScore evalueer die inhoud kwaliteit van 'n opsomming deur vergelyking van die opsomming na 'n verwysing te vergelyk. Ideële, hierdie vergelyking moet die opsomming se inligting-kwaliteit maat deur te bereken hoe veel inligting die opsommings in gemeenskap het. In hierdie werk, ons analyseer die teken-alignments wat deur ROUGE en BERTScore gebruik word om opsommings te vergelyk en te arguseer dat hulle telling grootste kan nie as maating inligting oorvloei word nie. Hier is hulle beter estimaties van die uitbreiding waarop die opsommings dieselfde onderwerpe bespreek. Verder, ons verskaf getuienis dat hierdie resultaat waar hou vir baie ander opsomming evaluering metries. Die gevolg van hierdie resultaat is dat die mees dikwels gebruikte opsommingsevaluering metries nie gelyk met die gemeenskap se reseksdoel nie, om opsommings met hoë-kwaliteit inligting te genereer nie. Maar ons sluit deur te wys dat 'n onlangs voorgestelde metriese QAEval, wat tel opsommings gebruik vraag-antwoord, verskyn om beter inligting kwaliteit te vang as huidige evaluasies, verlig 'n rigting vir toekomstige ondersoek.", 'am': 'ምርጫዎች ይህ ተሳያየት የጠቅላላ መረጃዎች ምን ያህል ዕድል እንዲኖሩ በመቆጠር የኩነቶች መረጃ ጥያቄን እንዲያካክሉ ይገባዋል፡፡ በዚህ ስራ፣ የሮUGE እና BERTScore የተደረገውን ምልክቶች እናስተያይዛለን፡፡ ይልቁንም የጎዳና ጉዳዩ በአንድ ጉዳይ በሚያነጋገሩበት ወቅት ይሻላል፡፡ ከዚህም በላይ ይህ ምክንያት ለብዙ አካለ ማነስ ማተሚያዎች እውነተኛ መሆኑን እናደርጋለን፡፡ የዚህ ፍጻሜ ግንኙነት፣ ብዙ ጊዜ የተጠቀመው ማሳየት ማድረግ ማተሚያዎች በተለየ ማኅበረሰብ የጥናት ጉዳይ፣ ከፍተኛ የጥሩ መረጃዎችን ለመፍጠር ነው፡፡ ምንም እንኳን፣ የቀድሞው የጥያቄውን መልስ የተጠቃሚ ሚትሪክ የQAEval ጉዳይ በማሳየት፣ የአሁኑን አስተያየት ጥያቄን ከመቀናኘት ትምህርት ይልቅ የተሻለ ሆኖ በመያዝ እናሳውቃለን፡፡', 'tr': "ROUGE ýa BERTScore holamyň maksadynyň keyfiňini çykarýar Iň pikirimçe, bu karşılaşyk sumyň maglumatynyň näçe maglumatynyň orta maglumatyny hasaplap etmeli. Bu işde, ROUGE we BERTScor tarapyndan ullanýan token çyzygyny çözümleýäris we olaryň sanlarynyň üstünde ölçüsi şeklinde terjime edilemez. Ýöne, toparlaryň şol tema bilen gürrüň berýän ýagdaýynyň has gowy görnüşleri. Munuň üçin bir näme üçin bu netijeden beýleki jemgyýet duýgulama metrikleri üçin dogry bolandygyny maslahat berýäris. Bu netijelerin netijesi iň köplen ullanýan toplumyň araştyrymy maksady bilen çykarmaýar, üst-kalitede maglumatlar bilen toplumyň düzümlerni döretmek üçin. Ýagna görä, biz iň soňky günlerde teklip eden metriýa QAEval'yň hat ýagdaýyny görkezýäris, sorag jogabyny ulanan toparyň howplygyny häzirki deňleşdirmelerden has gowy gözükýär we gelejek araştyrmalar üçin bir görnüş ýagtylamak üçin has gowy görüný", 'sq': 'Metrikat bazuar në referencë të tilla si ROUGE apo BERTScore vlerësojnë cilësinë e përmbajtjes së një përmbledhjeje duke krahasuar përmbledhjen me një referencë. Idealisht, ky krahasim duhet të matë cilës in ë e informacionit të përmbledhur duke llogaritur sa informacion kanë të përbashkët përmbledhjet. Në këtë punë, ne analizojmë rregullimet e shenjave të përdorura nga ROUGE dhe BERTScore për të krahasuar përmbledhjet dhe argumentuar se rezultatet e tyre në mënyrë të madhe nuk mund të interpretohen si matje e mbikryhjes së informacionit. Përkundrazi, ato janë vlerësime më të mira të shkallës në të cilën përmbledhjet diskutojnë të njëjtat temë. Për më tepër, ne japim prova se ky rezultat është i vërtetë për shumë metrika të tjera të përmbledhjes së vlerësimit. Pasojat e këtij rezultati janë se metrikat e vlerësimit të përmbledhjes më të shpeshta të përdorura nuk përputhen me qëllimin e kërkimit të komunitetit, për të gjeneruar përmbledhje me informacion të cilës is ë s ë lartë. However, we conclude by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research.', 'hy': 'Առաջնական հիմնված մետրիկները, ինչպիսիք են ROUGe կամ BELT, գնահատում են համառոտագրության պարունակության որակը համեմատելով համառոտագրությունը համեմատության հետ: Իրականում, այս համեմատությունը պետք է չափի համառոտագրության տեղեկատվության որակը հաշվարկելով համառոտագրությունների ընդհանուր տեղեկատվության քանակը: Այս աշխատանքի ընթացքում մենք վերլուծում ենք ROUge-ի և BER-ի կողմից օգտագործված նշանների հավասարումները համառոտագրությունների համեմատելու համար և բանավեճում ենք, որ նրանց գնահատականները հիմնականում չեն կարող մեկնաբանել որպես տեղեկատվության անկման չափման: Փոխարենը, դրանք ավելի լավ գնահատում են, թե ինչքանով են համառոտագրությունները քննարկում նույն թեմաները: Ավելին, մենք ապացույցներ ենք տալիս, որ այս արդյունքը ճիշտ է շատ այլ համառոտագրման գնահատման մետրիկների համար: Այս արդյունքի հետևանքն այն է, որ ամենահաճախ օգտագործված համառոտագրման գնահատման մետրիկները չեն համապատասխանում համայնքի ուսումնասիրության նպատակին՝ համառոտագրություններ ստեղծելու բարձր որակի տեղեկատվության հետ: Այնուամենայնիվ, մենք եզրակացում ենք, ցույց տալով, որ վերջերս առաջարկված մետրական QAE-ը, որը համառոտագրում է հարցերի պատասխաններ օգտագործելով, ավելի լավ է ընդունում տեղեկատվության որակը, քան ներկայիս գնահատումները, շեշտելով ապագա հետազոտությունների ուղղությունը:', 'bn': 'গণভিত্তিক মেট্রিক, যেমন রুজের অথবা বেরিটিস্কোর, সারসার্কের মানের বিষয়বস্তুর বিষয়বস্তুর বিষয়বস্তুর মান মূল্যায়ন করে একটি  চিন্তাভাবে এই তুলনাটি সামাজিক তথ্যের মান পরিমাপ করা উচিত। এই কাজে আমরা রুজের এবং বের্ট সংক্ষেপের তুলনা করার জন্য ব্যবহার করা চিহ্ন বিশ্লেষণ করি এবং যুক্তি করি যে তাদের সংক্রান্ত সংক্রান্ত তথ্য বাড়িয়ে দ তার পরিবর্তে তারা যে পর্যায়ে সামারিক বিষয় নিয়ে আলোচনা করেছে তা ভালো হিসাব গ্রহণ করেছে। এছাড়াও, আমরা প্রমাণ প্রদান করি যে এই ফলাফল অন্যান্য অনেক সারসংক্ষিপ্ত মেট্রিকের জন্য সত্য। এর ফলাফল হচ্ছে যে সবচেয়ে প্রায়শই ব্যবহার করা সারসংক্ষেপ মেট্রিক সম্প্রদায়ের গবেষণার লক্ষ্যের সাথে একত্রিত নয়, যাতে তারা উচ্চমান তথ্যের সাম তবে আমরা সমাপ্তি প্রদর্শন করেছি যে সম্প্রতি প্রস্তাবিত মেট্রিক, কিয়াভাল, যা প্রশ্নের উত্তর ব্যবহার করে সংক্ষেপের সংক্রান্ত সংক্ষেপের সাথে সংক্ষেপ করেছ', 'bs': 'Na referenciji bazirane metrike poput ROUGE ili BERTScore procjenjuju kvalitet sadržaja sažetka uspoređujući sažetak s referencijom. Idealno, ta usporedba bi trebala mjeriti kvalitet informacija sažetka izračunati koliko informacija imaju zajedničke sažetke. U ovom poslu analiziramo poravnanje znakova koji su koristili ROUGE i BERTScore kako bi usporedili sažetke i tvrdili da njihovi rezultati u velikoj meri ne mogu biti interpretisani kao mjerenje informacija. Umesto toga, oni su bolja procjena u mjeri u kojoj su sažeti razgovarali o istim temama. Nadalje, pružamo dokaze da ovaj rezultat ima istinu za mnoge druge metrike za procjenu rezimetaka. Posljedstvo ovog rezultata je da najčešće korištenija metrika za procjenu rezimetara ne odgovara istraživanjama zajednice, kako bi stvorila sažetke s visokokvalitetnim informacijama. Međutim, zaključili smo pokazivajući da nedavno predloženi metrički QAEval, koji rezultira sažetke koristeći odgovor na pitanje, čini se da je bolje uhvatiti kvalitet informacija nego trenutne procjene, naglašavajući smjer za buduće istraživanje.', 'ca': "Mètriques basades en referència com ROUGE o BERTScore valoren la qualitat del contingut d'un resum comparant el resum amb una referència. Idealment, aquesta comparació hauria de mesurar la qualitat de la informació del resum calculant quanta informació tenen en comú. En aquest treball, analitzem els alliniaments de fitxes utilitzats per ROUGE i BERTScore per comparar resumes i argumentar que les seves puntuacions en gran part no es poden interpretar com mesurant la sobreposió d'informació. Més aviat, són millors estimacions del punt en què els resums discuten els mateixos temes. També provem que aquest resultat és cert per a moltes altres mètriques d'evaluació de resum. La conseqüència d'aquest resultat és que les mètriques d'evaluació de resum més freqüentment utilitzades no s'alinquen amb l'objectiu de la investigació de la comunitat, per generar resums amb informació d'alta qualitat. Tot i així, concluim demostrant que una QAEval, que fa poc proposada, que puntueix resumes utilitzant respostes a preguntes, sembla captar millor la qualitat de la informació que les evaluacions actuals, destacant una direcció per a la futura investigació.", 'az': 'ROUGE ya da BERTScore kimi təmizlənmə məlumatının qiymətini təmizləyib, təmizlənməsini bir referans ilə qarşılaşdırmaq vasitəsilə dəyişdirir. Düzgün olaraq, bu karşılaşdırma təmizlənənlərin məlumatların keyfiyyətini çəkməsi lazımdır, təmizlənənlərin nə qədər məlumatların ortaq olduğunu hesablayaraq. Bu işdə, ROUGE və BERTScore vasitəsilə istifadə edilən möcüzələri analiz edirik və onların nöqtələrinin çox böyük ölçü məlumatlarının üstünü çəkilməsi üçün mübahisə edirik. Əksinə, bu müsəlmanlar eyni məsələlər barəsində daha yaxşı təsəvvür edirlər. Daha sonra, bu sonuç başqa bir çoxlu qurğulama müqayisədə doğru olduğunu göstəririk. Bu sonuçların sonuçları, ən çox istifadə edilən toplumların araştırma məqsədilə, yüksək kaliteli məlumatları ilə istifadə etmək üçün istifadə edilən qurğulama müəyyənləşdirilməsidir. Lakin biz, yeni təbliğ edilmiş metrik QAEval, soruşma cavabı vasitəsilə istifadə edən qeyri-qiymətləri ilə istifadə edən məlumat keyfiyyətini artırmaq üçün daha yaxşı görünür.', 'cs': 'Metriky založené na referencích, jako jsou ROUGE nebo BERTScore, hodnotí kvalitu obsahu souhrnu porovnáním souhrnu s referencí. V ideálním případě by toto srovnání mělo měřit kvalitu informací souhrnu výpočtem toho, kolik informací shrnutí mají společného. V této práci analyzujeme zarovnání tokenů používané ROUGE a BERTScore k porovnání souhrnů a argumentujeme, že jejich skóre z velké části nelze interpretovat jako překrývání informací o měření. Jedná se spíše o lepší odhady, do jaké míry shrnutí diskutují stejná témata. Dále poskytujeme důkazy, že tento výsledek platí pro mnoho dalších metrik shrnutí hodnocení. Důsledkem tohoto výsledku je, že nejčastěji používané hodnotící metriky shrnutí nesouhlasí s výzkumným cílem komunity, vytvářet shrnutí s kvalitními informacemi. Na závěr však ukážeme, že nedávno navržená metrika QAEval, která hodnotí shrnutí pomocí odpovědi na otázky, se zdá, že lépe zachycuje kvalitu informací než současná hodnocení, což zdůrazňuje směr pro budoucí výzkum.', 'et': 'Viitepõhised mõõdikud, näiteks ROUGE või BERTScore, hindavad kokkuvõtte sisu kvaliteeti, võrreldes kokkuvõtet viitega. Ideaaljuhul peaks see võrdlus mõõtma kokkuvõtte teabe kvaliteeti, arvutades kokkuvõtetel ühist teavet. Käesolevas töös analüüsime ROUGE ja BERTScore poolt kokkuvõtete võrdlemiseks kasutatud märkide joondusi ning väidame, et nende tulemusi ei saa enamasti tõlgendada kui mõõtmisteabe kattuvust. Pigem on need paremad hinnangud selle kohta, mil määral kokkuvõtetes käsitletakse samu teemasid. Lisaks esitame tõendeid selle kohta, et see tulemus kehtib paljude teiste kokkuvõtliku hindamise mõõdikute puhul. Selle tulemuse tagajärjel ei ole kõige sagedamini kasutatavad kokkuvõtliku hindamise mõõdikud kooskõlas kogukonna uurimiseesmärgiga, luua kokkuvõtteid kvaliteetse teabega. Kokkuvõttes näitame siiski, et hiljuti välja pakutud mõõdik QAEval, milles hinnatakse kokkuvõtteid küsimustele vastamise abil, näib olevat parem teabe kvaliteet kui praegused hinnangud, rõhutades suunda tulevaste uuringute jaoks.', 'fi': 'Viiteperusteiset mittarit, kuten ROUGE tai BERTScore, arvioivat tiivistelmän sisällön laatua vertaamalla tiivistelmää viittaukseen. Ihannetapauksessa vertailussa mitataan tiivistelmän tietojen laatua laskemalla, kuinka paljon tietoja tiivistelmillä on yhteistä. Tässä työssä analysoimme ROUGEn ja BERTScore:n käyttämiä token-linjauksia yhteenvedon vertailussa ja väitämme, että niiden pisteitä ei voida tulkita mittaustietojen päällekkäisyydeksi. Ne ovat pikemminkin parempia arvioita siitä, missä määrin tiivistelmissä käsitellään samoja aiheita. Lisäksi tarjoamme näyttöä siitä, että tämä tulos pätee moniin muihin yhteenvetoarviointimittareihin. Tuloksena on, että yleisimmin käytetyt tiivistelmäarviointimittarit eivät vastaa yhteisön tutkimustavoitetta eli tuottaa tiivistelmiä laadukkaalla tiedolla. Päätämme kuitenkin osoittamalla, että hiljattain ehdotettu mittari QAEval, jossa pisteytetään yhteenvedot kysymyksiin vastaamisen avulla, näyttää kuvaavan paremmin tiedon laatua kuin nykyisissä arvioinneissa ja korostavan suuntaa tulevalle tutkimukselle.', 'jv': 'Ref-format Node Nang barêng-barêng iki, kita ranjelisar token alignments sing gambar LOUGE karo BERT buddy Digawe, kita anggadahi punika bakal nggawe barang nggawe barang akeh luwih dadi kampun dadi kampun. Pesemple sing dadi iki dadi punika dipunamende kanggo teka nggawe dolanan piyambak dolanan karo perusahaan kanggo sampek dadi kanggo ngilangno komunitas, njaluk sumulasi karo informasi luwih apik-kalitas politenessoffpolite"), and when there is a change ("assertive', 'sk': 'Referenčne meritve, kot sta ROUGE ali BERTScore, ocenjujejo kakovost vsebine povzetka s primerjavo povzetka s sklicevanjem. V idealnem primeru bi morala ta primerjava meriti kakovost informacij v povzetku z izračunom, koliko informacij imajo povzetki skupne. V tem delu analiziramo poravnave žetonov, ki sta jih ROUGE in BERTScore uporabljala za primerjavo povzetkov, in trdimo, da njihovih rezultatov v veliki meri ni mogoče razlagati kot prekrivanje merilnih informacij. Namesto tega so boljše ocene obsega, v katerem povzetki obravnavajo iste teme. Poleg tega zagotavljamo dokaze, da ta rezultat velja za številne druge meritve vrednotenja povzetkov. Posledica tega rezultata je, da najpogosteje uporabljene meritve vrednotenja povzetkov niso usklajene z raziskovalnim ciljem skupnosti, da ustvarijo povzetke z visokokakovostnimi informacijami. Vendar pa zaključimo z dokazovanjem, da se zdi, da nedavno predlagana merila QAEval, ki ocenjuje povzetke z uporabo odgovorov na vprašanja, bolje zajema kakovost informacij kot sedanje ocene in poudarja smer za prihodnje raziskave.', 'ha': "Metric mai amfani da aka ƙayyade shi kamar rubutu ko BERTscore, ana ƙaddara tsarin wani ƙara da aka sami da tsohon zuwa wani fassara. @ info: whatsthis Daga wannan aikin, Munã yin anayyar da alama masu daidaita da RuUGE da BERTscore da ke amfani da shi dõmin a sami ƙarami kuma munã yi jãyayya cẽwa, ba za'a fassarar da scores mafi yawa ba kamar a ƙaddara canza tsarin data da za'a samu. Ã'a, sun fi alhẽri da ƙidãya wadda jama'a suke yin magana da shi. Furan, Munã sami shaidar cẽwa matsayin ta gaskata zuwa mataimaki masu ƙari dabam. Babu ƙarshen ta kasance cẽwa, metrici da ake amfani da muharinta mafi yawa ba su daidaita da goanin lõkaci na jamii ba, don ya sami ƙarami da babban-sifati. Hata haka, tuna ƙare da Muke nuna cewa wani metric wanda aka buɗa a yanzu, QAEeval, wanda yana ƙari yana da rabo masu karɓa wa tambaya, yana kasancẽwa mafiya kyau ga kãma tsarin information mafi kyaun idan an ƙayyade yanzu, yana bayyana wata shirin wa research na gabani.", 'he': "מטריות מבוססות על רמז, כמו ROUGE או BERTScore מעריכים את איכות התוכן של סכם על ידי השוואה של הסכם למרמז. באופן אידיאלי, השוואה הזאת צריכה למדוד את איכות המידע של הסכם על ידי חישוב כמה מידע יש לסורטים במשותף. בעבודה הזאת, אנו מנתחים את התאמות של סימנים שנמשכו על ידי ROUGE וברטסקור כדי להשוות סדרות ולטוען שהציונים שלהם בעיקר לא יכולים להתפרש כדידור מידע מתקפל. במקום זאת, הן הערכות טובות יותר על המידה שבה הסדרות מדברות על אותם נושאים. חוץ מזה, אנחנו מספקים ראיות שהתוצאה הזו נכונה למטריקות עריכה רבות אחרות. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community's research goal, to generate summaries with high-quality information.  בכל אופן, אנחנו מסתיימים על ידי להוכיח כי מטריקה הציעה לאחרונה, QAEval, אשר קולט ציונים באמצעות תשובות לשאלות, נראית לכלוף טוב יותר איכות מידע מאשר הערכות הנוכחיות, ומדגיש כיוון למחקר עתידי.", 'bo': "Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary's information quality by calculating how much information the summary has in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely cannot be interpreted as measuring information overlap. འདི་མིན་ན། Summaries་གི་དོན་ཚན་གཅིག་གི་གཏམ་གླེང་བའི་གྲངས་རྩིས་ཡོད་པ་རེད། Further, we provide evidence that this result holds true for many other summarization evaluation metrics. གཟའ་འབྲས་འདི་ནི་ཕལ་ཆེ་ཤོས་རང་ཉིད་སྤྱོད་པའི་བཅུད་སྡུད་ཟིན་བྲིས་མེད་པར། མི་སྤྱི་ཚོགས་ཀྱི་འཚོལ་ཞིབ་དང་མཐུན་སྒྲིག་ཡོད་མེད། However, we conclude by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research."}
{'en': 'Summary-Source Proposition-level Alignment : Task, Datasets and Supervised Baseline', 'fr': 'Alignement au niveau de la proposition Summary-Source\xa0: tâche, ensembles de données et référence supervisée', 'ar': 'محاذاة مستوى العرض الموجزة المصدر: المهمة ومجموعات البيانات وخط الأساس الخاضع للإشراف', 'es': 'Alineación a nivel de propuesta de fuente de resumen: tarea, conjuntos de datos y línea de base supervisada', 'pt': 'Alinhamento em nível de proposta de origem de resumo: tarefa, conjuntos de dados e linha de base supervisionada', 'zh': '摘要-源命题级对齐:务、数、督基线', 'ja': '概要-ソース提案レベルの整合：タスク、データセット、および監視されたベースライン', 'hi': 'सारांश-स्रोत प्रस्ताव-स्तर संरेखण: कार्य, डेटासेट और पर्यवेक्षित आधार रेखा', 'ru': 'Сводка - согласование на уровне исходного предложения: задачи, наборы данных и контролируемая базовая линия', 'ga': 'Achoimre-Foinse Ailíniú Leibhéal Tairiscint: Tasc, Tacar Sonraí agus Bunlíne Maoirsithe', 'ka': 'საზოგადომი- Source Proposition- Level Alignment: Task, Datasets and Supervised Baseline', 'hu': 'Összefoglaló-forrás javaslat-szintű igazítás: feladat, adatkészletek és felügyelt alapkészlet', 'el': 'Στοίχιση σε επίπεδο πρότασης σύνοψης-πηγής: Εργασία, σύνολα δεδομένων και εποπτευόμενη γραμμή βάσης', 'it': 'Allineamento a livello di proposta: attività, set di dati e linea di base supervisionata', 'kk': 'Тұжырымдық- көзі Көрсету- деңгейінің туралауы: тапсырма, деректер қорлары және бақылау негізгі жолы', 'mk': 'Израмнување на нивото на пропозиција на изворот: задача, датотеки и надгледувана основна линија', 'ms': 'Jajaran Aras cadangan Sumber: Tugas, Dataset dan Garis Asas Diperhatikan', 'lt': 'Santraukos šaltinio pasiūlymo lygio suderinimas: užduotis, duomenų rinkiniai ir prižiūrima pradinė linija', 'ml': 'ചുരുക്കത്തിന്റെ സൂര്യ സ്രോതസ്സ് പ്രോപ്ഷഷന്\u200d - നില മാന്യം', 'mn': 'Холбоо-эх үүсвэр зөвлөгөө-түвшин зөвлөгөө: Тапсыг, өгөгдлийн сан болон Хэрэглэгдсэн суурь шугам', 'no': 'Samandrag- kjeldeforandring- nivå: Oppgåve, databaser og oversikt baselinje', 'pl': 'Wyrównanie na poziomie podsumowania – źródło propozycji: zadania, zbiory danych i nadzorowana linia bazowa', 'ro': 'Alinierea la nivel de propunere: sarcini, seturi de date și linie de referință supravegheată', 'mt': 'Allinjament fil-livell tal-Propożizzjoni tas-Sommarju-Sors: Kompitu, Datasets u Linja Bażi Superviża', 'sr': 'Sažetak-izvor propisanje nivoa prijedloga: zadatak, podaci i nadzorna osnovna linija', 'so': 'Summary-Source Proposition-level: Shaqo, Dataset and Supervised Baseline', 'sv': 'Sammanfattning-Källa Proposition Level Alignment: Uppgift, datauppsättningar och övervakad baslinje', 'si': 'සාර්ථාව- මූල ප්\u200dරතිපත්තිය- තත්වය සංවිධානය: වැඩ, දත්ත සංවිධානය සහ බලන්න ප්\u200dරතිපත්තිය', 'ur': 'Summary-Source Proposition-level Alignment: Task, Datasets and Supervised Baseline', 'ta': 'சுருக்கம்- மூலத்தின் குறிப்பு- நிலை ஒழுங்குப்படுத்தல்: பணி, தகவல் அமைப்புகள் மற்றும் சேர்க்கப்பட்ட அடிப்படை', 'uz': 'Hisobot', 'vi': 'Liên kết hình dạng dạng dạng dạng lời thỉnh cầu:', 'da': 'Oversigt-Kilde Forslag-niveau Justering: Opgave, datasæt og overvåget basislinje', 'bg': 'Подравняване на нивото на предложението: задача, набори от данни и надзорна базова линия', 'id': 'Penjajaran Level Proposisi Sumber-Ringkasan: Tugas, Dataset dan garis dasar yang Diperhatikan', 'ko': '요약: 원본 명제 수준 정렬: 작업, 데이터 집합과 감독 기선', 'hr': 'Sažetak-izvor propisa na nivou prijedloga: zadatak, podaci i nadzorna početna linija', 'nl': 'Samenvatting-bronpropositie-niveau uitlijning: Taak, gegevenssets en begeleide basislijn', 'tr': 'Häzirki-Çeşme Görniş Görniş Derjesi Ýygymy: Görniş, Maglumaty we Görniş Opşenler', 'fa': 'تنظیم سطح پیشنهاد مقدار منبع: کار، داده\u200cها و خط بنیادی تحت نظر', 'sw': 'Upande wa Mkutano', 'de': 'Ausrichtung auf Projektebene auf Summary-Source: Aufgabe, Datensätze und überwachte Baseline', 'af': 'Opsomming- Bron Proposisie- vlak Oplyn: Opdrag, Databases en Besigtig Basislien', 'sq': 'Përcaktimi i nivelit të propozimit të burimit të përmbledhur: detyrë, bazë të dhënash dhe linjë bazë e mbikqyrur', 'hy': 'Summary-Source Proposition-level Alignment: Task, Datasets and Supervised Baseline', 'az': 'QńĪsqa-m…ônb…ô Proposisyon-s…ôviyy…ôsi ńįzl…ôm…ô: G√∂nd…ôr, Veri Qeyd Et G√∂zl…ônmiŇü S…ôtir', 'ca': 'Allinjament del nivell de proposició de fonts de resum: tasca, asets de dades i línia de base supervisada', 'bs': 'Sažetak-izvor propisa na nivou prijedloga: zadatak, podaci i nadzorna osnovna linija', 'am': 'ምርጫዎች', 'cs': 'Souhrn-zdroj Zarovnání na úrovni návrhu: Úkol, datové sady a dohledovaná základní linie', 'bn': 'সার্ম- সূত্র প্রোপশন- স্তর: কাজ, ডাটাসেট এবং সাপারভিস্ট বেসাইলিন', 'et': 'Kokkuvõte-allika ettepanekute tasandi joondamine: ülesanne, andmekogumid ja järelevalve alusväärtus', 'fi': 'Yhteenveto-lähde Ehdotuksen tason tasaus: Tehtävä, tietoaineistot ja valvottu lähtötilanne', 'jv': 'AllProgressBar', 'ha': 'KCharselect unicode block name', 'bo': 'བཅུད་དོན', 'sk': 'Poravnava na ravni predloga povzetka-vira: opravilo, nabori podatkov in nadzorovana osnovna vrsta', 'he': 'התאמת רמת ההצעה במקור סדרתי: משימה, קבוצות נתונים ובסיס משגיח'}
{'en': 'Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for  salience detection . Despite its assessed utility, the alignment step was mostly approached with heuristic unsupervised methods, typically ROUGE-based, and was never independently optimized or evaluated. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties : (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task. To that end, we created a novel  training dataset  for proposition-level alignment, derived automatically from available summarization evaluation data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.', 'pt': 'Alinhar frases em um resumo de referência com suas contrapartes em documentos de origem mostrou-se como uma tarefa auxiliar útil de sumarização, principalmente para gerar dados de treinamento para detecção de saliência. Apesar de sua utilidade avaliada, a etapa de alinhamento foi abordada principalmente com métodos heurísticos não supervisionados, tipicamente baseados em ROUGE, e nunca foi otimizado ou avaliado de forma independente. Neste artigo, propomos estabelecer o alinhamento resumo-fonte como uma tarefa explícita, ao mesmo tempo em que introduzimos duas novidades principais: (1) aplicá-lo no nível de amplitude de proposição mais preciso e (2) abordá-lo como uma tarefa de classificação supervisionada. Para esse fim, criamos um novo conjunto de dados de treinamento para alinhamento em nível de proposição, derivado automaticamente dos dados de avaliação de sumarização disponíveis. Além disso, realizamos crowdsourcing de conjuntos de dados de desenvolvimento e teste, permitindo o desenvolvimento de modelos e a avaliação adequada. Utilizando esses dados, apresentamos um modelo de linha de base de alinhamento de proposição supervisionado, mostrando melhor qualidade de alinhamento em relação à abordagem não supervisionada.', 'es': 'La alineación de oraciones en un resumen de referencia con sus contrapartes en los documentos fuente se mostró como una tarea de resumen auxiliar útil, especialmente para generar datos de entrenamiento para la detección de prominencia. A pesar de su utilidad evaluada, el paso de alineación se abordó principalmente con métodos heurísticos no supervisados, generalmente basados en Rouge, y nunca se optimizó ni evaluó de forma independiente. En este artículo, proponemos establecer la alineación resumen-fuente como una tarea explícita, a la vez que introducimos dos novedades principales: (1) aplicarla al nivel de intervalo de proposición más preciso y (2) abordarla como una tarea de clasificación supervisada. Con ese fin, creamos un conjunto de datos de entrenamiento novedoso para la alineación a nivel de propuesta, derivado automáticamente de los datos de evaluación de resumen disponibles. Además, colaboramos con conjuntos de datos de desarrollo y pruebas, lo que permitió el desarrollo de modelos y la evaluación adecuada. Utilizando estos datos, presentamos un modelo de línea base de alineación de proposiciones supervisada, que muestra una mejor calidad de alineación con respecto al enfoque no supervisado.', 'ar': 'تم عرض محاذاة الجمل في ملخص مرجعي مع نظرائهم في المستندات المصدر كمهمة تلخيص مساعدة مفيدة ، لا سيما لتوليد بيانات التدريب لاكتشاف البروز. على الرغم من فائدتها المقدرة ، تم التعامل مع خطوة المحاذاة في الغالب بأساليب إرشادية غير خاضعة للإشراف ، وعادة ما تستند إلى ROUGE ، ولم يتم تحسينها أو تقييمها بشكل مستقل. في هذه الورقة ، نقترح إنشاء محاذاة مصدر الملخص كمهمة صريحة ، مع تقديم اثنين من المستجدات الرئيسية: (1) تطبيقه على مستوى نطاق الاقتراح الأكثر دقة ، و (2) الاقتراب منه كمهمة تصنيف خاضعة للإشراف. ولهذه الغاية ، أنشأنا مجموعة بيانات تدريب جديدة لمحاذاة مستوى الاقتراح ، مشتقة تلقائيًا من بيانات تقييم التلخيص المتاحة. بالإضافة إلى ذلك ، قمنا بالاستعانة بمصادر خارجية لتطوير واختبار مجموعات البيانات ، مما يتيح تطوير النموذج والتقييم المناسب. باستخدام هذه البيانات ، نقدم نموذجًا أساسيًا لمحاذاة الاقتراح الخاضع للإشراف ، مما يُظهر جودة المحاذاة المحسنة على النهج غير الخاضع للإشراف.', 'fr': "L'alignement des phrases dans un résumé de référence avec leurs homologues dans les documents sources s'est révélé être une tâche auxiliaire utile de synthèse, notamment pour générer des données d'entraînement pour la détection de la saillance. Malgré son utilité évaluée, l'étape d'alignement a été principalement abordée avec des méthodes heuristiques non supervisées, généralement basées sur Rouge, et n'a jamais été optimisée ou évaluée indépendamment. Dans cet article, nous proposons d'établir l'alignement sommaire-source en tant que tâche explicite, tout en introduisant deux nouveautés majeures\xa0: (1) l'appliquer au niveau de la portée de proposition le plus précis, et (2) l'aborder comme une tâche de classification supervisée. À cette fin, nous avons créé un nouveau jeu de données d'entraînement pour l'alignement au niveau de la proposition, dérivé automatiquement des données d'évaluation de synthèse disponibles. En outre, nous avons externalisé des ensembles de données de développement et de test, ce qui a permis le développement de modèles et une évaluation appropriée À l'aide de ces données, nous présentons un modèle de référence d'alignement de proposition supervisé, montrant une meilleure qualité d'alignement par rapport à l'approche non supervisée.", 'hi': 'स्रोत दस्तावेज़ों में अपने समकक्षों के साथ एक संदर्भ सारांश में वाक्यों को संरेखित करना एक उपयोगी सहायक सारांशीकरण कार्य के रूप में दिखाया गया था, विशेष रूप से लचीलापन का पता लगाने के लिए प्रशिक्षण डेटा उत्पन्न करने के लिए। इसकी मूल्यांकन उपयोगिता के बावजूद, संरेखण चरण को ज्यादातर हेरिस्टिक असुरक्षित तरीकों के साथ संपर्क किया गया था, आमतौर पर रूज-आधारित, और कभी भी स्वतंत्र रूप से अनुकूलित या मूल्यांकन नहीं किया गया था। इस पेपर में, हम सारांश-स्रोत संरेखण को एक स्पष्ट कार्य के रूप में स्थापित करने का प्रस्ताव करते हैं, जबकि दो प्रमुख नवीनताओं को पेश करते हैं: (1) इसे अधिक सटीक प्रस्ताव अवधि स्तर पर लागू करना, और (2) इसे पर्यवेक्षित वर्गीकरण कार्य के रूप में पहुंचना। उस अंत तक, हमने प्रस्ताव-स्तर संरेखण के लिए एक उपन्यास प्रशिक्षण डेटासेट बनाया, जो स्वचालित रूप से उपलब्ध सारांश मूल्यांकन डेटा से व्युत्पन्न है। इसके अलावा, हमने मॉडल विकास और उचित मूल्यांकन को सक्षम करते हुए, देव और परीक्षण डेटासेट को क्राउडसोर्स किया। इन आंकड़ों का उपयोग करते हुए, हम एक पर्यवेक्षित प्रस्ताव संरेखण बेसलाइन मॉडल प्रस्तुत करते हैं, जो असुरक्षित दृष्टिकोण पर बेहतर संरेखण-गुणवत्ता दिखाता है।', 'zh': '将参考摘要中句与源文件中句对齐显有用之佐摘要,特以成显著性检之数。 虽估其效用,而齐步驿主用启发式无监督之法,常基于ROUGE,未尝独立优化评也。 于本文,请以摘要源对齐为明务,兼引二大要新颖性:(1)宜用于更确之命跨度级,及(2)以为督分。 于是创造了一个新命题级对齐训练数据集,该数集自己从可用的摘要评数中得出来。 此外还众包开测试数据集,以成模形适量。 因此数据,立一监命齐基线模形,示与无监督之法相比,对齐质有所提高。', 'ja': '参照要約の文章をソースドキュメントの文章と整列させることは、特に顕著性検出のためのトレーニングデータを生成するための有用な補助要約タスクとして示された。 評価された有用性にもかかわらず、アライメントステップは、主にヒューリスティックな非監督方法、典型的にはROUGEベースの方法でアプローチされ、独立して最適化または評価されることはなかった。 本稿では，明示的な課題としてサマリソースアライメントを確立すると同時に， （ 1 ）より正確な命題スパンレベルで適用すること， （ 2 ）監督下の分類課題としてアプローチすることの2つの主要な新規性を紹介する． そのために、利用可能な要約評価データから自動的に導出される、命題レベルの整列のための新しいトレーニングデータセットを作成しました。 さらに、開発およびテストデータセットをクラウドソーシングし、モデル開発と適切な評価を可能にしました。 これらのデータを利用して、私たちは、監督されていないアプローチよりも改善されたアラインメント品質を示す、監督された提案アラインメントベースラインモデルを提示します。', 'ru': 'Согласование предложений в справочном резюме с их аналогами в исходных документах было показано в качестве полезной вспомогательной задачи обобщения, особенно для создания учебных данных для обнаружения выраженности. Несмотря на свою оценочную полезность, к этапу выравнивания в основном подходили с помощью эвристических методов без надзора, обычно основанных на ROUGE, и никогда не были независимо оптимизированы или оценены. В этой статье мы предлагаем установить выравнивание сводных источников в качестве явной задачи, вводя при этом две основные новшества: (1) применение его на более точном уровне диапазона предложения и (2) подход к нему в качестве контролируемой задачи классификации. С этой целью мы создали новый набор обучающих данных для выравнивания на уровне предложений, автоматически получаемый из имеющихся данных оценки обобщения. Кроме того, мы краудсорсинг DEV и тестовые наборы данных, что позволяет разрабатывать модели и правильно оценивать. Используя эти данные, мы представляем контролируемую базовую модель выравнивания предложений, демонстрирующую улучшенное качество выравнивания по сравнению с неконтролируемым подходом.', 'ga': 'Léiríodh ailíniú abairtí in achoimre thagartha lena gcomhghleacaithe i ndoiciméid foinse mar thasc achoimrithe cúnta úsáideach, go háirithe chun sonraí oiliúna a ghiniúint chun suntas a bhrath. In ainneoin a háisiúlachta measúnaithe, chuathas i ngleic leis an gcéim ailínithe den chuid is mó le modhanna heorastúla gan mhaoirseacht, go hiondúil bunaithe ar ROUGE, agus níor rinneadh é a uasmhéadú ná a mheasúnú go neamhspleách riamh. Sa pháipéar seo, molaimid ailíniú foinse achomair a bhunú mar thasc sainráite, agus dhá mhórscéalta á dtabhairt isteach ag an am céanna: (1) é a chur i bhfeidhm ar an leibhéal réise tairiscintí níos cruinne, agus (2) é a dhéanamh mar thasc aicmithe faoi mhaoirseacht. Chuige sin, chruthaíomar tacar sonraí oiliúna nua le haghaidh ailíniú ar leibhéal na tairisceana, a dhíorthaítear go huathoibríoch ó shonraí meastóireachta achoimre atá ar fáil. Ina theannta sin, rinneamar tacair shonraí forbartha agus tástála plódaithe, rud a chuir ar ár gcumas forbairt samhlacha agus meastóireacht cheart a dhéanamh. Agus na sonraí seo á n-úsáid againn, cuirimid i láthair múnla bunlíne um ailíniú tairiscint maoirsithe, a thaispeánann cáilíocht feabhsaithe an ailínithe thar an gcur chuige gan mhaoirseacht.', 'hu': 'A referencia-összefoglalóban szereplő mondatok összehangolását a forrásdokumentumokban szereplő társaikkal hasznos kiegészítő összefoglaló feladatként mutatták be, különösen a nyilvánosság felismeréséhez szükséges képzési adatok előállításához. Mértékelt hasznossága ellenére az igazítási lépést leginkább felügyelet nélküli heurisztikus módszerekkel közelítették meg, jellemzően ROUGE alapú, és soha nem optimalizálták vagy értékelték önállóan. Ebben a tanulmányban az összefoglaló-forrás összehangolás kifejezett feladatként történő meghatározását javasoljuk, miközben két fő újdonságot mutatunk be: (1) pontosabb javaslattartományban történő alkalmazását, és (2) felügyelt osztályozási feladatként történő megközelítését javasoljuk. Ennek érdekében létrehoztunk egy új képzési adatkészletet a javaslat szintű összehangolására, amely automatikusan a rendelkezésre álló összefoglaló értékelési adatokból származik. Ezenkívül közösségi forrásból fejlesztő és tesztelő adatokat gyűjtöttünk, lehetővé téve a modellfejlesztést és a megfelelő értékelést. Ezen adatok felhasználásával egy felügyelt javaslat-igazítási alapmodellt mutatunk be, amely a felügyelet nélküli megközelítéshez képest javult az igazítás-minőséget mutatja.', 'el': 'Η ευθυγράμμιση των προτάσεων σε μια περίληψη αναφοράς με τα ομόλογά τους στα έγγραφα προέλευσης παρουσιάστηκε ως μια χρήσιμη βοηθητική εργασία σύνοψης, ιδίως για τη δημιουργία δεδομένων κατάρτισης για τον εντοπισμό σημασιών. Παρά την αξιολόγησή του, το βήμα ευθυγράμμισης προσεγγίστηκε κυρίως με heuristικές μεθόδους χωρίς επίβλεψη, συνήθως βασισμένες σε ROUGE, και ποτέ δεν βελτιστοποιήθηκε ή αξιολογήθηκε ανεξάρτητα. Στην παρούσα εργασία, προτείνουμε την καθιέρωση συνοπτικής ευθυγράμμισης-πηγής ως σαφή εργασία, ενώ εισάγουμε δύο σημαντικές καινοτομίες: (1) την εφαρμογή της στο ακριβέστερο επίπεδο φάσματος προτάσεων και (2) την προσέγγιση της ως εποπτευόμενη εργασία ταξινόμησης. Για το σκοπό αυτό, δημιουργήσαμε ένα νέο εκπαιδευτικό σύνολο δεδομένων για ευθυγράμμιση σε επίπεδο προτάσεων, το οποίο προέρχεται αυτόματα από τα διαθέσιμα δεδομένα αξιολόγησης συνοψίας. Επιπλέον, δημιουργήσαμε σύνολα δεδομένων ανάπτυξης και δοκιμής, επιτρέποντας την ανάπτυξη μοντέλων και την κατάλληλη αξιολόγηση. Χρησιμοποιώντας αυτά τα δεδομένα, παρουσιάζουμε ένα εποπτευμένο μοντέλο βάσης ευθυγράμμισης προτάσεων, το οποίο δείχνει βελτιωμένη ποιότητα ευθυγράμμισης σε σχέση με την προσέγγιση χωρίς επίβλεψη.', 'ka': 'მართლას რეფერენტის რესუმენტის რესუმენტის რესუმენტის გამოყენება მათი კომპორტები მხოლოდ დოკუმენტებში გამოყენებულია როგორც საჭირო დახმარებელი რესუმენტის პარამეტ მისი განსაზღვრებული სუტილიტების მაგრამ, განსაზღვრებული კონფიგურაცია უფრო მეტი ჰეურისტიკური არ განსაზღვრებული მეტოვებით დაახლობა, როგორც როგორც ROUGE-დაბათებული და არასოდენობით ო ამ დომენტში, ჩვენ მინდომა გავაკეთებთ საზოგადომი წიგნილება, როგორც გავაკეთებთ ორი მნიშვნელოვანი პრომენტი: (1) მას უფრო დარწმუნეთ წიგნილების განზომილების განზომილება, და (2) მას გადავაკეთებთ როგ მისი დასაწყისთვის, ჩვენ შევქმნა პროგრამეტური მონაცემების კონფიგურაცია საზოგადომი დონეზე დასწორებლად, ავტომატურად დასწორებული კონფიგურ დამატებით, ჩვენ მუშაობით განვითარება და ტესტის მონაცემები, მოდელის განვითარება და მარტივი გაუმუშაობა. ამ მონაცემების გამოყენება, ჩვენ ჩვენ აღმოვაჩვენებთ მონაცემებული პროგრამების მხარეს მოდელი, რომელიც უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ', 'it': "L'allineamento delle frasi in un riassunto di riferimento con le loro controparti nei documenti di origine è stato dimostrato come un utile compito ausiliario di sintesi, in particolare per generare dati di formazione per il rilevamento della salienza. Nonostante la sua utilità valutata, la fase di allineamento è stata per lo più affrontata con metodi euristici non supervisionati, tipicamente basati su ROUGE, e non è mai stata ottimizzata o valutata indipendentemente. In questo articolo, proponiamo di stabilire l'allineamento sommario-sorgente come un compito esplicito, introducendo due importanti novità: (1) applicarlo al livello più accurato della proposizione span, e (2) approcciarlo come un compito di classificazione supervisionato. A tal fine, abbiamo creato un nuovo set di dati formativi per l'allineamento a livello di proposta, derivato automaticamente dai dati di valutazione di sintesi disponibili. Inoltre, abbiamo raccolto in crowdsourcing set di dati di sviluppo e test, consentendo lo sviluppo di modelli e una corretta valutazione. Utilizzando questi dati, presentiamo un modello di base di allineamento delle proposizioni supervisionato, che mostra una migliore qualità di allineamento rispetto all'approccio non supervisionato.", 'lt': 'Atskaitos santraukos sakinių suderinimas su jų kolegomis šaltinio dokumentuose buvo įrodytas kaip naudinga papildoma santraukos užduotis, visų pirma rengiant mokymo duomenis, skirtus druskos aptikimui. Nepaisant įvertinto naudingumo, suderinimo etapas daugiausia buvo taikomas naudojant heuristinius, paprastai ROUGE pagrįstus, nenustatytus metodus ir niekada nebuvo nepriklausomai optimizuotas ar įvertintas. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties: (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task.  Tuo tikslu sukūrėme naują mokymo duomenų rinkinį pasiūlymų lygio suderinimui, gautą automatiškai iš turimų santraukų vertinimo duomenų. Be to, mes surinkėme dev ir bandymų duomenų rinkinius, sudarydami sąlygas modelio kūrimui ir tinkamam vertinimui. Naudodamiesi šiais duomenimis, pristatome prižiūrėtą pasiūlymų suderinimo pradinį model į, kuriame parodoma geresnė suderinimo kokybė negu nepažiūrėtas metodas.', 'mk': 'Прилагодувањето на референциските реченици со нивните колеги во изворните документи беше покажано како корисна помошна задача за резервирање, особено за генерирање на податоци за обука за детективирање на ослободување. И покрај нејзината проценета корисност, чекорот на пристапување беше приближен претежно со хеористички ненадгледувани методи, обично базирани на РУГЕ, и никогаш не беше независно оптимизиран или проценет. Во овој документ, предложуваме воспоставување на поедноставно обврзување со изворот како експлицитна задача, при што воведуваме две главни новости: (1) апликација на попрецизно ниво на пропозиција и (2) приближување на неа како надгледувана класификациска задача. За тоа, создадовме нов набор на податоци за обука за пристапување на нивото на предлозите, автоматски извлечен од достапните податоци за резултатирање. Покрај тоа, ги набавивме дев и тестирачките податоци, овозможувајќи развој на моделот и соодветна оценка. Користејќи ги овие податоци, претставуваме надгледуван основен модел за подигнување на предлозите, кој покажува подобрен квалитет на подигнување во однос на ненадгледуваниот пристап.', 'kk': 'Көздегі құжаттардың сілтеме тұжырымдамасында сөйлемелерді түзету үшін пайдалы көмектесу тапсырмасы ретінде көрсетілді, осымен қатар сілтемелерді анықтау үшін оқыту деректерін құру үшін. Бұл құрылған утилитаға қарамастан, кеңейту қадамысы көпшілігінде геуристік жоқ әдістерімен, әдетте ROUGE негізделген, және әрқашанда ешқашан оптимизацияланбады не бағаламады. Бұл қағазда, біз түсінікті тапсырма ретінде тәртібі түсінікті түсініктіру үшін, екі негізгі романды келтіру үшін: 1) оны дұрыс түсінікті тапсырма деңгейінде қолдану және (2) оны бақылау тапсырмасы ретінде жақы Бұл үшін біз қосымша деңгейіндегі теңдеу үшін жаңа оқыту деректер жинағын құрып, автоматты түрде қол жеткізетін тұжырымдамасынан шығарылады. Қосымша, біз үлгілерді жасау және дұрыс бағалау үшін көпшілік көпшілікті жасау және деректер қорларын тексердік. Бұл деректерді пайдалану үшін біз бақылап тұрған жұмысының негізгі сызық үлгісін көрсеткіздік. Бұл жағдайда тұрақтың сапасы жақсы көрсетеді.', 'mt': 'L-allinjament tas-sentenzi f’sommarju ta’ referenza mal-kontropartijiet tagħhom fid-dokumenti tas-sors intwera bħala kompitu ta’ sommarju awżiljarju utli, notevolment għall-ġenerazzjoni ta’ dejta ta’ taħriġ għall-individwazzjoni tas-salienza. Minkejja l-utilità vvalutata tiegħu, il-pass ta’ allinjament ġie approċċ l-aktar b’metodi ewristiċi mhux sorveljati, tipikament ibbażati fuq ROUGE, u qatt ma ġie ottimizzat jew evalwat b’mod indipendenti. F’dan id-dokument, qed nipproponu li jiġi stabbilit allinjament bejn is-sorsi sommarji bħala kompitu espliċitu, filwaqt li jintroduċu żewġ novitajiet ewlenin: (1) l-applikazzjoni tiegħu fil-livell ta’ firxa ta’ proposti aktar preċiża, u (2) l-approċċ tiegħu bħala kompitu ta’ klassifikazzjoni sorveljat. Għal dak il-għan, a ħna ħolqu sett ġdid ta’ dejta dwar it-taħriġ għall-allinjament fil-livell tal-proposta, derivat awtomatikament mid-dejta disponibbli dwar l-evalwazzjoni tas-sommarju. Barra minn hekk, aħna ffurmawna settijiet ta’ dejta tad-dev u tat-testijiet b’ħafna sorsi, li jippermettu l-iżvilupp tal-mudell u l-evalwazzjoni xierqa. Bl-użu ta’ din id-dejta, qed nippreżentaw mudell ta’ linja bażi ta’ allinjament tal-proposta sorveljat, li juri kwalità ta’ allinjament imtejba fuq l-approċċ mhux sorveljat.', 'ml': 'സോര്\u200dസ്സ് രേഖകളില്\u200d അവരുടെ കൂട്ടുകാരുമായി വാക്കുകള്\u200d പരിശോധിക്കുന്നതിനുള്ള പരിശീലന വിവരങ്ങള്\u200d ഉണ്ടാക്കുന്നതിന് പ്രത്യേകിച്ച് പരിശീ അതിന്റെ ഉപയോഗങ്ങള്\u200d മുഴുവനായും ഹൂരിസ്റ്റിക്ക് സംരക്ഷിക്കപ്പെടാത്ത മാര്\u200dഗ്ഗങ്ങളുടെ അടുത്ത് എത്തിയിരുന്നു. സാധാരണയായി റോയുജിനെ അടിസ്ഥാനമ ഈ പത്രത്തില്\u200d നമ്മള്\u200d വ്യക്തമായ ഒരു ജോലിയായി സ്ഥാപിക്കാന്\u200d പ്രായണം ചെയ്യുന്നു. രണ്ട് പ്രധാന ന നോവലുകള്\u200d പരിചയപ്പെടുത്തുമ്പോള്\u200d: (1) അതിനെ കൂടുതല്\u200d വിശിഷ്ടമായ പ് To that end, we created a novel training dataset for proposition-level alignment, derived automatically from available summarization evaluation data.  കൂടാതെ, നമ്മള്\u200d ഡെവിസ്സിനെയും പരീക്ഷിക്കുന്ന ഡാറ്റാസറ്റുകളെയും പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു. ഈ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നത് നമ്മള്\u200d പരിശോധിക്കപ്പെട്ട പ്രോജക്ഷന്\u200d മാതൃകയുടെ ബേസ്ലൈന്\u200d മോഡല്\u200d കാണിക്കുന്നു. സൂക്ഷിക്ക', 'ms': 'Jajarkan kalimat dalam ringkasan rujukan dengan rakan-rakan mereka dalam dokumen sumber dipaparkan sebagai tugas ringkasan bantuan berguna, terutama untuk menghasilkan data latihan untuk pengesan salience. Walaupun utiliti yang diukur, langkah penyesuaian kebanyakan didekati dengan kaedah heuristik yang tidak diawasi, biasanya berasaskan ROUGE, dan tidak pernah dipotomatis secara bebas atau diuji. Dalam kertas ini, kami cadangkan penyesuaian sumber-ringkasan sebagai tugas eksplicit, sementara memperkenalkan dua novelti utama: (1) melaksanakannya pada tahap jangkauan cadangan yang lebih tepat, dan (2) mendekatinya sebagai tugas klasifikasi yang diawasi. Untuk tujuan itu, kami mencipta set data latihan baru untuk penyesuaian aras-cadangan, dibuang secara automatik dari data penilaian ringkasan yang tersedia. Selain itu, kami crowdsourced dev dan set data ujian, membolehkan pembangunan model dan penilaian yang betul. Menggunakan data ini, kami memperkenalkan model dasar penyesuaian cadangan yang diawasi, menunjukkan kualiti penyesuaian yang lebih baik atas pendekatan yang tidak diawasi.', 'mn': 'Мэдээллүүдийг эх үүсвэрийн баримтын хамтрагчдаас хамтрагчдаас хамтрагч өгүүлбэрийг тодорхойлох нь тусламжтай тодорхойлолтын даалгавар гэж харуулагдсан. Ялангуяа цэвэрлэлтийн мэдээллийг олох боломжтой бол Түүний шалгалтын хэрэглээнээс гадна тэгшитгэлийн алхам ихэнхдээ хэмжээгээр хэмжээгээр хэмжээгээр хэмжээгээр зориулагддаггүй арга замаар ойртож байлаа. Олон хэмжээгээр ROUGE-д суурилсан, хэзээ ч өөр Энэ цаасан дээр бид хэвлэлийн эх үүсвэрийг тодорхой даалгавар болгож, хоёр чухал шинэ нээлтийг тайлбарлаж, илүү тодорхой санал нийлүүлэлтийн түвшинд хэрэглэх боломжтой болно. Үүний тулд бид шинэ сургалтын өгөгдлийн санал төвшин тэгшитгэлийн төвшинд шинэ сургалтын өгөгдлийн санал бүтээсэн. Тэр нь автоматжуулан ашиглаж байгаа жинхэнэ дүгнэлтийн Үүнээс гадна бид олон хүн төрөлхтний хөгжлийн болон өгөгдлийн сангуудыг шалгаж, загварын хөгжлийн болон зөв үнэлгээг ашиглаж байна. Эдгээр өгөгдлийг ашиглаж, бид удирдагдсан санал дээр байрлах суурь шугам загварыг харуулж, сайжруулагдаагүй арга загварын талаар сайжруулах чадварыг харуулж байна.', 'pl': 'Wyrównanie zdań w podsumowaniu referencyjnym z ich odpowiednikami w dokumentach źródłowych zostało przedstawione jako użyteczne dodatkowe zadanie podsumowania, w szczególności w celu generowania danych szkoleniowych do wykrywania saliencji. Pomimo ocenianej użyteczności, krok dostosowania był podejmowany głównie metodami heurystycznymi bez nadzoru, zazwyczaj opartymi na ROUGE, i nigdy nie był niezależnie optymalizowany ani oceniany. W niniejszym artykule proponujemy ustanowienie dostosowania podsumowania-źródła jako wyraźnego zadania, przy jednoczesnym wprowadzeniu dwóch głównych nowości: (1) stosowanie go na dokładniejszym poziomie zakresu propozycji oraz (2) podejście do niego jako nadzorowanego zadania klasyfikacji. W tym celu stworzyliśmy nowy zestaw danych szkoleniowych dla dostosowania na poziomie propozycji, pochodzący automatycznie z dostępnych danych oceny podsumowującej. Dodatkowo zbieraliśmy crowdsourcing danych deweloperskich i testowych, umożliwiając rozwój modelu i prawidłową ocenę. Wykorzystując te dane, prezentujemy nadzorowany model podstawowy dostosowania propozycji, pokazujący lepszą jakość dostosowania w porównaniu z podejściem bez nadzoru.', 'no': 'Tilpassing av setningar i ei referanssamandrag med dei mottakarane i kjeldedokumenta vart vist som eit nyttig hjelpssamandrag oppgåve, spesielt for å laga opplæringsdata for oppdaging av salienskap. Til tross av verktøyet sitt vurdert, var justeringssteg hovudsakelig nært med heuristiske ulike metodar, som vanlegvis er ROUGE-basert, og aldri vart optimalisert eller evaluert uavhengig. I denne papiret foreslår vi å oppretta samandrag-kjeldejustering som ein ekspliskt oppgåve, medan du introduserer to store novelar: (1) som brukar det på den meir nøyaktige forslag-brettet, og (2) nærmer det som ei oversikt klassifikasjon-oppgåve. I denne slutten oppretta vi eit nytt opplæringsdataset for forslag-nivå-justering, avhengig automatisk frå tilgjengelege samanseringsdata. I tillegg kan vi gjere tilfeldig dev- og test- datasett, og bruke modelleutvikling og rett evaluering. Ved å bruka desse data, presenterer vi ein oversikt baseline-modell for innstillingar, som viser forbetra innstillingskvalitet over den ugjennomsiktige tilnærminga.', 'so': 'Markii lagu qorayo erayada lagu qorayo dhamaanka reference ee lammaanahooda ku jira dukumentiyada sourceed waxaa lagu muujiyey shaqo faa’iido ah oo ku saabsan heshiiska dhamaanka, khusuusan dhashay macluumaadka waxbarashada aqoonsiga badbaadada. Inkastoo ay isticmaalkeeda qiimeysay, tallaabo isbedelka waxaa loo soo dhowaaday habab aan la ilaalin karo, sida caadiga ah ROUGE ku saleysan, oo aan marna loo beddelin ama lagu qiimeyn. Qoraalkan waxaynu ka soo jeedaynaa in lagu sameyno isbedelka koorsiga ah oo ah shaqo cad, marka lagu soo bandhigayo laba riwaayadood oo muhiim ah:(1) ku codsanayo heerka saxda ah oo saxda ah oo lagu qoro iskuulka span iyo (2) oo u soo dhowaanaya sida shaqada la ilaaliyo fasax. Taas darteed waxan sameynay sawirada waxbarashada sawir ah si loo isbedelayo heerka sawirida, waxaana ka keenay macluumaadka qiimeynta qiimeynta. Intaas waxaa dheer, waxaynu soo bandhignay dev iyo imtixaano, waxaana sameynaya horumarinta modellka iyo qiimeynta saxda ah. Si aan ugu isticmaalno macluumaadyadan, waxaan soo bandhignaa qaab la ilaaliyo sameynta qoraalka hoose-dhigista, waxaana tusinayaa mid la beddelo isbedelka oo ka mid ah qaababka aan la ilaalinayn.', 'sv': 'Att anpassa meningarna i en referenssammanfattning till deras motsvarigheter i källdokument visade sig vara en användbar kompletterande sammanfattningsuppgift, särskilt för att generera utbildningsdata för detektering av saliens. Trots dess bedömda användbarhet närmade sig justeringssteget mestadels med heuristiska icke övervakade metoder, vanligtvis ROUGE-baserade, och blev aldrig oberoende optimerad eller utvärderad. I denna uppsats föreslår vi att man fastställer sammanfattning-källjustering som en explicit uppgift, samtidigt som man introducerar två viktiga nyheter: (1) att tillämpa den på den mer exakta propositionsspann nivå, och (2) att närma sig den som en övervakad klassificeringsuppgift. För detta ändamål skapade vi en ny utbildningsdatauppsättning för justering på propositionsnivå, hämtad automatiskt från tillgängliga sammanfattningsutvärderingsdata. Dessutom har vi crowdsourcing av utvecklings- och testdataset, vilket möjliggör modellutveckling och korrekt utvärdering. Med hjälp av dessa data presenterar vi en övervakad modell för justering av förslag som visar förbättrad justeringskvalitet jämfört med den obevakade metoden.', 'sr': 'Prikazivanje rečenica u referentnom sažetku sa svojim kolegama u izvornim dokumentima pokazalo je kao korisni zadatak za sažetak pomoći, posebno za stvaranje podataka o obuci za otkrivanje salijencije. Uprkos procjenom korisnosti, korak usklađivanja je uglavnom bio pristupan heurističkim nepotrebnim metodama, obično na ROUGE-u, i nikada nije bio neovisno optimiziran ili procenjen. U ovom papiru predlažemo uspostavljanje poravnanja iz sažetaka kao objašnjenje zadatka, dok uvedemo dve velike novine: 1) primjenjivanje na točnijoj razini razdoblja prijedloga, i 2) približavanje njemu kao nadzorni zadatak klasifikacije. Za taj cilj, stvorili smo novi set podataka za obuku za usklađenje nivoa prijedloga, koji je automatski proizveden od dostupnih podataka o procjeni sumiranja. Osim toga, mi smo crowdsourced dev i test datasets, omogućavajući razvoj modela i odgovarajuću procjenu. Koristeći te podatke, predstavljamo nadzorni model prijedloga o osnovnoj liniji usklađenja, pokazujući poboljšan kvalitet usklađenja nad neodređenim pristupom.', 'ro': 'Alinierea frazelor dintr-un rezumat de referință cu omologii lor din documentele sursă a fost demonstrată ca o sarcină utilă de rezumare auxiliară, în special pentru generarea de date de formare pentru detectarea salienței. În ciuda utilității sale evaluate, etapa de aliniere a fost abordată în principal cu metode euristice nesupravegheate, de obicei bazate pe ROUGE, și nu a fost niciodată optimizată sau evaluată independent. În această lucrare, propunem stabilirea alinierii sumar-sursă ca o sarcină explicită, introducând în același timp două noutăți majore: (1) aplicarea acesteia la nivelul mai precis al intervalului de propunere și (2) abordarea acesteia ca o sarcină de clasificare supravegheată. În acest scop, am creat un nou set de date de instruire pentru alinierea la nivel de propunere, derivat automat din datele disponibile de evaluare a rezumatului. În plus, am crowdsourcing seturi de date pentru dezvoltare și testare, permițând dezvoltarea modelului și evaluarea corespunzătoare. Utilizând aceste date, prezentăm un model supravegheat de aliniere a propunerii, care arată o calitate îmbunătățită a alinierii față de abordarea nesupravegheată.', 'ta': 'மூல ஆவணங்களில் தங்கள் நண்பர்களுடன் வாக்குறிப்பு சுருக்கத்தில் உள்ள வாக்கியங்களை ஒதுக்குவது பயனுள்ள கூடுதல் சுருக்கல் செயலாக்குதல், பிரதி அதன் பயன்பாட்டை மதிப்பிடப்பட்டாலும், ஒழுங்குபடி படி பெரும்பாலாகவே பாதுகாப்பாக்கப்படாத முறைகளுடன் நெருங்கி வந்தது, வழக்கமாக ROUGE-அடிப்படையில்,  இந்த காகிதத்தில், நாம் சுருக்கம்- மூலத்தின் ஒழுங்குப்பொருளை வெளிப்படையான செயலாக உருவாக்குவதற்கு பரிந்துரைக்கிறோம், இரண்டு பெரிய புத்தகங்களை அறிவிக்கும்  இந்த முடிவிற்கு, நாம் ஒரு புதிய பயிற்சி தகவல் அமைப்பை உருவாக்கினோம் பரிந்துரைப்பு மட்டத்திற்கு, கிடைக்கும் சுருக் கூடுதலாக, நாங்கள் டிபிஎஸ் மற்றும் சோதனை தகவல் அமைப்புகளை அனுப்பி வைத்தோம், மாதிரி உருவாக்கத்தையும் சரியா இந்த தரவை பயன்படுத்தி, நாம் பரிந்துரைக்கப்பட்ட பரிந்துரைக்கப்பட்ட முறைமையை கொண்டு வருகிறோம், பாதுகாப்பாக்கப்படாத செயல்பா', 'si': 'සම්බන්ධ වාර්තාවක් සමඟ සංවේදනයක් සංවේදනයක් සමඟ ඔවුන්ගේ සම්බන්ධ වාර්තාවක් තියෙන්නේ ප්\u200dරයෝජනය සම්බන්ධ වැඩක එයාගේ විශ්වාස කරපු ප්\u200dරයෝජනයක් නමුත්, සමාන්\u200dය විශ්වාස කරපු ප්\u200dරයෝජනයක් හෙයුරිස්ටික් විශ්වාස කරපු ප්\u200dරයෝජනයක් සමඟ ලඟ මේ පැත්තේ, අපි ප්\u200dරශ්නයක් නිර්මාණය කරන්න ප්\u200dරශ්නයක් විදිහට ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් දෙකක් ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ ඒ අවසානයෙන්, අපි ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ, ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරශ ඒ වගේම, අපි සම්පූර්ණයෙන් විශාලනය සහ පරීක්ෂා දත්ත සේට් කරනවා, මදුල් විකාශය සහ හොඳ විශාලන මේ දත්ත පාවිච්චි කරනවා, අපි බලන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා, ප්\u200dරශ්නයක් නැති විශ්නයක්', 'ur': 'سورس دکھانوں میں ان کے کنٹرپارتوں کے ساتھ ایک سرگوشی سرگوشی میں جمع کرنے کی تعریف ایک مفید مددگاری سرگوشی کے کام کے طور پر دکھائی گئی تھی، مخصوصاً سیلینس ڈیٹ کے لئے ترینس ڈیٹ پیدا کرنے کے لئے۔ اس کی آزمائش کے مطابقہ کے بغیر، اس تفریق قدم بہت زیادہ حوریستی غیر قابل تحقیق کی طریقے سے پہنچ گیا تھا، معمولاً ROUGE کی بنیاد ہے، اور وہ کسی طرح اچھی طریقہ یا ارزش نہیں کی گئی۔ اس کاغذ میں، ہم نے ایک صریح کام کے طور پر summary-source alignment کا مقرر کرنا پیشنهاد کرتا ہے، جبکہ دو بڑے نوائی پیشنهاد کرتا ہے: (1) اسے زیادہ دقیق پیشنهاد سطح پر لازم کرتا ہے، اور (2) اس کے نزدیک ایک تحت نظر کی کلاسیفوں کے طور پر لازم کرتا ہے۔ اس کے لئے ہم نے ایک نئی تدریس ڈیٹ سٹ پیدا کیا ہے جو پیشنهاد-سطح تدریج کے لئے ہے، جو اپنے ساتھ موجود سامنے تدریج ڈیٹ سے پائی جاتی ہے. اس کے علاوہ، ہم نے گھوٹ ڈیٹسٹ اور ڈیٹسٹ کو امتحان کیا، موڈل ڈولوپ اور ٹھیک ارزیابی کو امکان دیتے ہیں. ہم ان ڈیٹوں کو استعمال کرتے ہیں، ہم نے ایک نظارت کی پیشنهاد بنیس لین موڈل کو پیش کیا ہے، جو غیر قابل تحقیق کی طریقہ پر زیادہ سیدھی سیدھی سیدھی سیدھی سیدھی سیدھی سیدھی سیدھی سی', 'uz': "@ info: whatsthis Koʻrinadigan foydalanuvchi bo'lsa, tasdiqlash tugmasi ko'pchiligi heuristik saqlangan usullar bilan ishlatilgan edi, odatda ROUGE asosida va hech qachon qo'llanmagan yoki qiymatmaydi. Bu qogʻozda, biz juda yaxshi vazifa sifatida qisqartmalangan yangilikni tasavvur qilish talab qilamiz, va ikkita asosiy yoʻl bilan ishlatish imkoniyatlarini anglatdik: (1) buni eng yaxshi darajada qo'llash va (2) taʼminlovchi darajaga olib tashlash. Shunday qilib, biz taʼminlovchi darajadagi taʼminlovchi maʼlumot bazasini yaratdik. Mavjud muhit qiymatni avtomatik olib tashlab boʻladi. Ko'pchilik, biz dev va sinov maʼlumotlar tartiblarini guruhlashimiz mumkin, model taʼminlovchisi va juda yaxshi qiymatni yordam beradi. Ushbu maʼlumotlardan foydalanish bilan, biz saqlab boʻlmaydigan tugmalar birikmasini boshqarish mumkin.", 'vi': 'Việc xác định các câu trong một bản tóm tắt tham chiếu với các đối tác trong các tài liệu nguồn được cho thấy là một nhiệm vụ bổ trợ để tóm tắt, đặc biệt để tạo ra dữ liệu đào tạo để phát hiện độ nổi tiếng. Mặc dù nó có tiện ích được đánh giá, các bước thẳng hàng được tiếp cận với các phương pháp phi theo luật, đặc biệt dựa trên ROCENE, và chưa bao giờ được tối ưu tiên hay đánh giá độc lập. Trong tờ giấy này, chúng tôi đề nghị thiết lập sự thẳng hàng nguồn tóm tắt như một nhiệm vụ dứt khoát, trong khi đưa ra hai tiểu thuyết lớn: 1) áp dụng nó ở mức độ phân công việc chính xác hơn, và (2) tiếp cận nó như một nhiệm vụ phân hạng được giám sát. Vì vậy, chúng tôi đã tạo ra một tập tin mới cho việc chỉnh vị trên mức độ công việc, tự động có nguồn từ dữ liệu đánh giá Tóm tắt. Thêm vào đó, chúng tôi tụ họp các nhóm dữ liệu và thử nghiệm, phát triển mô hình và đánh giá thích đáng. Sử dụng những dữ liệu này, chúng tôi giới thiệu một mô hình cấu hình vị trí xuất bản giám sát, hiển thị chất định tốt hơn.', 'nl': 'Het afstemmen van zinnen in een referentiesamenvatting met hun tegenhangers in brondocumenten werd aangetoond als een nuttige aanvullende samenvattingstaak, met name voor het genereren van trainingsgegevens voor saliëntiedetectie. Ondanks het beoordeelde nut werd de uitlijningsstap meestal benaderd met heuristische methoden zonder toezicht, typisch ROUGE-gebaseerd, en werd nooit onafhankelijk geoptimaliseerd of geëvalueerd. In dit artikel stellen we voor om samenvatting-bron alignment als een expliciete taak vast te stellen, terwijl we twee belangrijke nieuwigheden introduceren: (1) het toepassen op het nauwkeurigere propositie span niveau, en (2) het benaderen als een begeleide classificatietaak. Daartoe creëerden we een nieuwe trainingsdataset voor uitlijning op propositie-niveau, automatisch afgeleid van beschikbare samenvattingsevaluatiegegevens. Daarnaast hebben we dev- en test datasets crowdsourced, waardoor modelontwikkeling en correcte evaluatie mogelijk zijn. Met behulp van deze gegevens presenteren we een supervised proposition alignment baseline model, dat een verbeterde alignment-kwaliteit toont ten opzichte van de onbeheerde aanpak.', 'de': 'Das Ausrichten von Sätzen in einer Referenzzusammenfassung mit ihren Gegenstücken in Quelldokumenten wurde als nützliche Hilfsaufgabe gezeigt, insbesondere zur Generierung von Trainingsdaten zur Salienzerkennung. Trotz seines bewerteten Nutzens wurde der Ausrichtungsschritt meist mit heuristischen unüberwachten Methoden angegangen, typischerweise ROUGE-basierten, und nie unabhängig voneinander optimiert oder evaluiert. In diesem Papier schlagen wir vor, die Zusammenfassungsquellenausrichtung als explizite Aufgabe zu etablieren und dabei zwei wichtige Neuerungen einzuführen: (1) sie auf der genaueren Propositionsspanne anzuwenden und (2) sie als überwachte Klassifikationsaufgabe zu betrachten. Zu diesem Zweck haben wir einen neuartigen Trainingsdatensatz für die Ausrichtung auf Propositionsebene erstellt, der automatisch aus verfügbaren Zusammenfassungsevaluationsdaten abgeleitet wird. Darüber hinaus haben wir Entwicklungs- und Testdatensätze crowdsourced, was die Modellentwicklung und die korrekte Auswertung ermöglichte. Anhand dieser Daten präsentieren wir ein Baseline-Modell zur Supervised Proposition Alignment, das eine verbesserte Alignment-Qualität gegenüber dem unüberwachten Ansatz zeigt.', 'da': 'Tilpasning af sætninger i et referenceresumé med deres modstykker i kildedokumenter blev vist som en nyttig hjælpeopgave, navnlig til generering af træningsdata til påvisning af fremhævelse. På trods af dets vurderede nytte blev justeringsfasen for det meste nærmet sig med heuristiske ikke-overvågede metoder, typisk ROUGE-baserede, og blev aldrig uafhængigt optimeret eller evalueret. I denne artikel foreslår vi at etablere sammenfattende-kilde justering som en eksplicit opgave, samtidig med at vi introducerer to vigtige nyheder: (1) anvende den på det mere præcise proposition span niveau, og (2) nærme den som en overvåget klassifikationsopgave. Til det formål har vi skabt et nyt træningsdatasæt til justering på forslag-niveau, der automatisk udledes af tilgængelige sammenfattende evalueringsdata. Derudover har vi crowdsourceret udviklings- og testdatasæt, hvilket muliggør modeludvikling og korrekt evaluering. Ved hjælp af disse data præsenterer vi en overvåget baseline model for tilpasning af forslag, der viser forbedret tilpasningskvalitet i forhold til den uautoriserede tilgang.', 'id': 'Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for salience detection.  Meskipun utilitas yang diperkirakan, langkah penyesuaian kebanyakan didekati dengan metode heuristik yang tidak diawasi, biasanya berdasarkan ROUGE, dan tidak pernah secara independen diterima atau diterima. Dalam kertas ini, kami mengusulkan menetapkan penyesuaian sumber sebagai tugas eksplisit, sementara memperkenalkan dua novelti utama: (1) menerapkannya pada tingkat jangkauan proposisi yang lebih akurat, dan (2) mendekatinya sebagai tugas klasifikasi yang diawasi. Untuk itu, kami menciptakan dataset pelatihan baru untuk penyesuaian tingkat proposisi, yang dipakai secara otomatis dari data evaluasi ringkasan yang tersedia. Selain itu, kami crowdsourced dev dan tes dataset, memungkinkan pembangunan model dan evaluasi yang tepat. Menggunakan data ini, kami mempersembahkan model dasar penyesuaian proposisi yang diawasi, menunjukkan kualitas penyesuaian yang lebih baik atas pendekatan yang tidak diawasi.', 'hr': 'Prikazivanje rečenica u referentnom sažetku s njihovim kolegama u izvornim dokumentima pokazalo je kao korisni zadatak za pomoćno sažetanje, posebno za stvaranje podataka o obuci za otkrivanje salijencije. Uprkos procjenom korisnosti, korak usklađivanja je uglavnom pristupan heurističkim nepotrebnim metodama, obično na ROUGE-u, a nikada nije bio neovisno optimiziran ili procjenjivan. U ovom papiru predlažemo utvrđivanje usklađenja sažetkog izvora kao objašnjenje zadatka, dok uvodimo dvije velike novine: 1) primjenjivanje ga na točnijoj razini razdoblja razdoblja prijedloga, i 2) približavanje ga kao nadzorni zadatak klasifikacije. Za taj cilj, stvorili smo novu obuku podataka za usklađenje na nivou prijedloga, koji je automatski proizveden od dostupnih podataka o procjeni sažetke. Osim toga, mi smo crowdsourced dev i test datasets, omogućavajući razvoj modela i odgovarajuću procjenu. Koristeći te podatke, predstavljamo model prijedloga o osnovnoj liniji usklađivanja, pokazujući poboljšanu kvalitetu usklađivanja nad neodređenim pristupom.', 'fa': 'تعیین کردن جمله\u200cها در یک جمع ارتباط با همکاران آنها در سند منبع به عنوان یک کار تعیین کمک مفید نشان داده شد، مخصوصا برای تولید داده\u200cهای آموزش برای شناسایی استفاده. با وجود استفاده ارزیابی\u200cاش، قدم تنظیم بیشتر با روش\u200cهای غیر قابل تحریک، معمولاً بر روی ROUGE نزدیک شده بود و هرگز به طور مستقل تحریک یا ارزیابی نخواهد شد. در این کاغذ، ما پیشنهاد می\u200cکنیم که به عنوان یک وظیفه توضیح تعمیر منبع جمعیت را به عنوان یک وظیفه توضیح دهیم، در حالی که دو نویسه بزرگ را معرفی می\u200cکنیم: (۱) آن را در سطح مقدار پیشنهاد دقیق\u200cتری انجام می\u200cدهیم، و (۲) به عنوان یک برای همین، ما یک مجموعه اطلاعات آموزش نوی برای تضامین سطح پیشنهاد ایجاد کردیم، که از اطلاعات تحقیقات جمع کردن موجود می شود. در اضافه، ما مجموعه\u200cی توسعه\u200cهای داده\u200cهای توسعه و آزمایش\u200cهای توسعه مدل و ارزیابی مناسبی را اجرا می\u200cکنیم. با استفاده از این داده ها، ما یک مدل اصلاح زیر خط تحت نظر قرار می دهیم که کیفیت اصلاح بهتر را بر روی طریق غیرقابل تحت نظر قرار می دهیم.', 'ko': '요약 중의 문장을 원본 문서의 대응하는 문장과 맞추는 것은 유용한 보조 요약 작업이며 특히 현저성 검사를 위한 훈련 데이터를 생성하는 데 사용된다.비록 교정 절차에 대해 효용 평가를 실시했지만 교정 절차는 대부분 계발식 무감독 방법을 사용하고 보통 연지를 바탕으로 독립적으로 최적화하거나 평가한 적이 없다.본고에서 우리는 요약원을 명확한 임무로 삼고 두 가지 주요 혁신점을 도입할 것을 제안한다. (1) 이를 더욱 정확한 명제의 넓이 단계에 응용하고 (2) 이를 감독 분류 임무로 삼을 것이다.이를 위해, 우리는 새로운 명제급 정렬 훈련 데이터 집합을 만들었는데, 이 데이터 집합은 사용 가능한 요약 평가 데이터에서 자동으로 파생되었다.그 밖에 우리 패키지 개발과 테스트 데이터 집합은 모델 개발과 적당한 평가를 지원한다.이러한 데이터를 이용하여 우리는 감독이 있는 명제 정렬 기선 모델을 제시했는데 감독 방법이 없는 것보다 이 모델은 더욱 좋은 정렬 품질을 나타냈다.', 'bg': 'Приравняването на изреченията в справочно резюме с техните колеги в изходните документи беше показано като полезна допълнителна задача за обобщаване, особено за генериране на данни за обучение за откриване на видимост. Въпреки оценяваната си полезност, стъпалото на подравняване е подхождало предимно с евристични методи без надзор, обикновено базирани на РОУГ, и никога не е било самостоятелно оптимизирано или оценено. В настоящата статия предлагаме установяване на подравняване на обобщения източник като изрична задача, като същевременно въвеждаме две основни новости: (1) прилагането му на по-точното ниво на обхват на предложението и (2) подхода му като задача за надзорно класифициране. За тази цел създадохме нов набор от данни за обучение за изравняване на ниво предложение, получен автоматично от наличните данни за оценка на обобщението. В допълнение, ние събрахме множество данни за разработки и тестване, давайки възможност за разработване на модели и правилна оценка. Използвайки тези данни, представяме надзорен базов модел за подравняване на предложенията, показващ подобрено качество на подравняване в сравнение с ненадзорния подход.', 'tr': 'Sözleri çeşme senedlerde çaplanmak üçin süýtgetmek üçin ullanýar. Görnüşdirilen aralygyna rağmen, çyzyglaşdyrma adım köplenç heuristik(suçsuz) şeklinde gollanmaýar, adatça ROUGE-de tabanly we hiç haçan boýunça optimiz edilmedi we hiç haçan deňlenmedi. Bu kagyzda, biz topar-çeşme çyzygyny a çıklamak üçin tassyklandyrmak teklip edýäris, we iki esasy taýdan soňra golaý taýýarlamak üçin (1) muny daa dogry teklip derejesinde uygulamak we (2) muny gözlemli klasifikasyon zady hökmünde golaýlaýarys. Şol üçin, biz teklip derejesi çykarmak üçin täze bir okuw sanatyny bejerdik. Munuň üçin biz köpüräk gelişmek we maglumat setirlerini barlaýarys, nusgala ösümäni we dogry deňleşdirmegi mümkin edýäris. Bu maglumatlary ulanyp, gözlemýän teklib çyzyglama şartlygy nusgasyny görkezip, garşyrlmayan ýagdaýyň üstünde gelişmiş çyzyglama howplygyny görkez.', 'am': 'የአሁኑን ሰነዱን በማቀናኘት የሚጠቅምበት የአጠቃሚ ማቀናጃ አድራሻ ነው፡፡ ምንም እንኳን በተወሰነ ጥያቄ ቢሆንም፣ መተላለፊያው ደረጃዎች አብዛኛውን በሀሪክኛ ያልጠበቀው ሥርዓት፣ በተለየው ሮዩጂ በመሠረት፣ አብዛኛውም በተለየ የተመሳሳይ ወይም በተመሳሳይ አልተደረገም፡፡ በዚህ ፕሮግራም፣ ሁለት ታላላቆች የመረጃዎች ትልቁ ጉዳዮች ሲያስተምሩ፣ (1) በተጨማሪው የስፓን ደረጃዎች እና (2) በተጠበቀ መግለጫ ስራ እንዲያቀርቡት ለመጠቀም እናስባለን፡፡ ለዚህም ምክንያት የጠቅላላ ማቀናጃ ዳታዎችን ለመቀናቀል አቀረብን፡፡ በተጨማሪም፣ ዲ ዲ እና የዳታ መስኮቶችን አሰናብተን እና የሞዴል ፍጥረት እና እውነተኛ አስተያየት እናስችላለን፡፡ እነዚህን ዳታዎች በመጠቀም፣ በተጠበቀው ጥያቄ ላይ የደረጃ መሠረት ሞዴል እናሳየዋለን፡፡', 'sw': 'Kutambua hukumu katika muhtasari wa maoni na wenzao katika nyaraka za vyanzo walionyesha kama jukumu la muhtasari wa muhtasari, hasa kwa kutengeneza taarifa za mafunzo kwa ajili ya uchunguzi wa hadhira. Pamoja na matumizi yake iliyopitishwa, hatua ya upinzani ilifikiwa zaidi na mbinu zisizo na usalama wa heuristic, kwa kawaida, na haikuwa na matumaini au kutathmini kwa uhuru. Katika gazeti hili, tunapendekeza kuanzisha jukumu la muhtasari kama jukumu la wazi, wakati kuwasilisha riwaya mbili muhimu: (1) kutengeneza katika kiwango cha sahihi cha pendekezo la spania, na (2) kuikaribia kama jukumu la uangalizi. Kwa mwisho huo, tulitengeneza taarifa za mafunzo ya riwaya kwa ajili ya kujipanga kwa kiwango cha mapendekezo, iliyotokana na taarifa za uchunguzi wa muhtasari zinazopatikana. Zaidi ya hayo, tulitumia mashindano na seti za taarifa za kujaribu, na kuwawezesha maendeleo ya mifano na tafiti sahihi. Kwa kutumia taarifa hizi, tunaweka muundo wa msingi wa pendekezo lililothibitishwa, kuonyesha uborefu wa usawa wa usafiri juu ya mbinu zisizo sahihi.', 'az': 'Mənbə belələrində qonaqları ilə cümlələri təmizləmək üçün istifadə edən təmizləmə məlumatı olaraq göstərildi, özlərinə də təmizləmə məlumatı təhsil etmək üçün. Görünülmüş faydalarına baxmayaraq, çəkinmə adımı çox çox heuristik təmizlənmiş metodlarla yaxınlaşdı, genellikle ROUGE-ə dayanan və heç vaxt bağımsız olaraq optimizlənmədi və təmizlənmədi. Bu kağızda, bir a çıq görev kimi summary-source alignment təyin etməyi təklif edirik, iki böyük yenilik təyin edirik: 1) daha doğru təklif müddətində istifadə edir və 2) onu gözləyirli klasifikasiya görevi olaraq yaxınlaşdırmağı təklif edirik. Bu məqsədilə, təklif-seviyyəti tərəfləndirmək üçün yeni təhsil verilən verilənlər yaratdıq, avatomatik olaraq istifadə edilən təhsil verilənlərdən alındı. Əvvəlcə biz çox qüvvətli dev və veri qurğuları sınamaq, modellərin gelişməsini və düzgün değerlendirməsini qabilleşdirdik. Bu məlumatları istifadə edərək, gözlənilmiş təklif çəkmə səviyyəsi modelini göstərdik, müəyyən edilməmiş təklif üzərində daha yaxşı təklif kalitetini göstərdik.', 'af': "Verwydering van teikens in 'n verwysing opsomming met hul kunstenaars in bron dokumente was vertoon as 'n nuttige hulpbruk opsomming taak, spesifieke vir die genereer van onderwerking data vir saliensbeskrywing. Terwyl sy aangestelde nutsprogram, was die aanpassing stap meeste toegekom met heuristiese onverondersteunde metodes, tipies ROUGE-gebaseerde, en was nooit onafhanklik optimaliseer of evalueer nie. In hierdie papier, voorstel ons om opsomming-bron-gelyking te stel as 'n eksplisiese taak, terwyl twee grootste novelies ingevoer word: (1) wat dit op die meer presies voorstelling span vlak toewend word, en (2) wat dit as 'n ondersoekte klassifikasie taak aanvaar. En tot daardie einde het ons 'n nuwe onderwerp datastel geskep vir voorstellings-vlak belyning, outomaties afgelei van beskikbaar opsomming evaluering data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. By die gebruik van hierdie data, voorsien ons 'n ondersoekte voorstelling belyning baselyn model, wys verbeterde belyning-kwaliteit oor die onverondersteunde toegang.", 'sq': 'Rregullimi i fjalëve në një përmbledhje referimi me homologët e tyre në dokumentet e burimit u shfaq si një detyrë ndihmëse e përmbledhjes, veçanërisht për gjenerimin e të dhënave të trainimit për zbulimin e saliencës. Megjithë shërbimin e vlerësuar të saj, hapi i përshtatjes u afrua kryesisht me metoda heuristike të pazgjidhura, tipikisht bazuar në ROUGE dhe nuk u optimizua apo u vlerësua kurrë në mënyrë të pavarur. Në këtë letër, propozojmë vendosjen e përshtatjes së përmbledhur-burimit si një detyrë të qartë, ndërsa paraqesim dy novitete të mëdha: (1) zbatimin e saj në nivelin më të saktë të fushës së propozimeve dhe (2) afrimin e saj si një detyrë klasifikimi të mbikqyrur. Për këtë qëllim, krijuam një sërë të dhënash të rinj trajnimit për përshtatjen e nivelit të propozimit, të nxjerrur automatikisht nga të dhënat në dispozicion të përmbledhjes së vlerësimit. Përveç kësaj, ne crowdsourced dev dhe test datasets, duke mundësuar zhvillimin e modelit dhe vlerësimin e duhur. Duke përdorur këto të dhëna, ne paraqesim një model bazë të rregullimit të propozimit të mbikqyrur, duke treguar cilësinë e përmirësuar të rregullimit lidhur me qasjen e pa mbikqyrur.', 'bn': 'সোর্স ডকুমেন্টে তাদের সহযোগীদের সাথে রেফারেন্স সার্কারের সারিটে বাক্য চিহ্নিত করা হয়েছে সংক্ষেপের কাজ হিসেবে দেখা যায়, বিশে এর মূল্যবান ব্যবহার সত্ত্বেও বেশীরভাগ হারিস্টিক অরক্ষণশীল পদ্ধতির সাথে যুক্ত হয়েছিল, সাধারণত রোজের ভিত্তিক এবং স্বাধীনতার ক্ষেত্রে স্বাধ এই কাগজটিতে আমরা সার্মিন সোর্সের সার্ভারের সামাজিক কাজ হিসেবে প্রস্তাব করার প্রস্তাব প্রস্তাব করছি, আর দুটি গুরুত্বপূর্ণ নোভান্ডার উপস্থাপন করেছে: (1) এটি আরো সঠ এই পর্যন্ত আমরা প্রস্তাব-স্তরের সার্মিজেশনের জন্য একটি নোভেল প্রশিক্ষণের ডাটাসেট তৈরি করেছি, স্বয়ংক্রিয়ভাবে প্রাপ্ত সংক এছাড়াও আমরা জনসংখ্যা ডিভি এবং পরীক্ষা ডাটাসেটের সূত্র প্রদান করেছি, মডেল উন্নয়ন এবং সঠিক মূল্যায়নের ব্যবস্থা  এই তথ্য ব্যবহার করে আমরা একটি পর্যবেক্ষিত প্রস্তাব বেস-লাইন মডেল উপস্থাপন করি, যেখানে সংরক্ষিত পদ্ধতির ব্যাপারে উন্নয়নের মান উন্নত করা হয়', 'bs': 'Prikazivanje rečenica u referentnom sažetku sa svojim kolegama u izvornim dokumentima pokazalo je kao korisni zadatak za pomoćno sažetanje, posebno za stvaranje podataka o obuci za otkrivanje salijencije. Uprkos procjenom korisnosti, korak usklađivanja je uglavnom bio pristupan heurističkim nepotrebnim metodama, obično na ROUGE-u, a nikada nije bio neovisno optimiziran ili procjenjivan. U ovom papiru predlažemo uspostavljanje usklađenja iz sažetkog izvora kao objašnjenje zadatka, dok se uvede dvije velike novine: 1) primjenjivanje toga na točnijoj razini razdoblja razdoblja prijedloga, i 2) približavanje njemu kao nadzorni zadatak klasifikacije. Za taj cilj smo stvorili novi set podataka za obuku za usklađenje nivoa prijedloga, koji je automatski proizveden od dostupnih podataka o procjeni rezimetiranja. Osim toga, mi smo crowdsourced dev i test datasets, omogućavajući razvoj modela i odgovarajuću procjenu. Koristeći te podatke, predstavljamo model prijedloga o osnovnoj liniji usklađivanja, pokazujući poboljšan kvalitet usklađivanja nad neodređenim pristupom.', 'hy': 'Առաջին փաստաթղթերում գտնվող համառոտագրում գտնվող նախադասությունները հավասարեցնելը ցույց տվեց որպես օգտակար օգտակար համառոտագրման խնդիր, հատկապես արտահայտության հայտնագործման ուսուցման տվյալների ստեղծման համար: Չնայած դրա գնահատված օգտակարությանը, հարմարեցման քայլը հիմնականում մոտեցվել էր հորիստիկ անվերահսկված մեթոդներով, սովորաբար ROUGe-ի հիմքում, և երբեք անկախ օպտիմացված կամ գնահատված չէր: In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties: (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task.  Այդ պատճառով մենք ստեղծեցինք նոր ուսուցման տվյալների համակարգ առաջարկության մակարդակի հարմարեցման համար, որը ինքնաբերաբար ստացվում է հասանելի համառոտագրման գնահատման տվյալներից: Ավելին, մենք հավաքվեցինք Dev-ի և փորձարկումների տվյալների համակարգերին, որոնք հնարավորություն էին տալիս մոդելների զարգացումը և ճիշտ գնահատումը: Օգտագործելով այս տվյալները, մենք ներկայացնում ենք վերահսկված առաջարկների հարմարեցման հիմնական մոդելը, որը ցույց է տալիս բարելավված հարմարեցման որակը առանց վերահսկված մոտեցության դեպքում:', 'cs': 'Srovnání vět v referenčním souhrnu s jejich protějšky ve zdrojových dokumentech bylo ukázáno jako užitečný pomocný souhrnný úkol, zejména pro generování tréninkových dat pro detekci salience. Navzdory hodnocené užitečnosti byl krok zarovnání přistupován většinou heuristickými metodami bez dohledu, typicky založenými na ROUGE, a nikdy nebyl nezávisle optimalizován ani vyhodnocen. V tomto článku navrhujeme stanovit souhrnné sladění zdrojů jako explicitní úkol, přičemž představujeme dvě hlavní novinky: (1) aplikaci na přesnější úrovni rozpětí návrhů a (2) přistupování k němu jako k dozorovanému klasifikačnímu úkolu. Za tímto účelem jsme vytvořili novou sadu tréninkových dat pro zarovnání na úrovni návrhů, odvozenou automaticky z dostupných souhrnných hodnotících dat. Kromě toho jsme crowdsourcingové vývojové a testovací datové sady umožnili vývoj modelu a řádné vyhodnocení. S využitím těchto dat představujeme základní model zarovnávání návrhů s dohledem, který ukazuje lepší kvalitu zarovnání oproti přístupu bez dohledu.', 'et': 'Võrdluskokkuvõttes olevate lausete vastavusse viimist algdokumentides olevate lausetega näidati kasuliku kokkuvõtliku lisaülesandena, eelkõige koolitusandmete loomisel silmapaistvuse tuvastamiseks. Vaatamata hinnatud kasulikkusele, lähenes joondamise etapile enamasti heuristiliste järelevalveta meetoditega, tavaliselt ROUGE-põhiste, ning seda ei optimeeritud ega hinnatud kunagi iseseisvalt. Käesolevas töös teeme ettepaneku luua kokkuvõtliku allika ühtlustamine selgesõnalise ülesandena, tuues sisse kaks peamist uuendust: (1) rakendada seda täpsemalt ettepaneku ulatuse tasemel ja (2) läheneda sellele järelevalveülesandena. Selleks loosime ettepanekute tasandil vastavusse viimiseks uue koolitusandmekogumi, mis tuletati automaatselt kättesaadavatest kokkuvõtliku hindamise andmetest. Lisaks kogusime ühisallikaid arendus- ja testiandmekogumitele, mis võimaldavad mudelite arendamist ja nõuetekohast hindamist. Neid andmeid kasutades esitame järelevalve all esitatud ettepanekute vastavuse baasmudeli, mis näitab paremat vastavuse kvaliteeti võrreldes järelevalveta lähenemisviisiga.', 'fi': 'Viitekertomuksen lauseiden yhdenmukaistaminen lähdeasiakirjoissa olevien vastaavien lauseiden kanssa osoittautui hyödylliseksi yhteenvetotehtäväksi erityisesti harjoitustietojen tuottamiseksi salienssin havaitsemista varten. Arvioidusta hyödyllisyydestään huolimatta linjausvaihetta lähestyttiin enimmäkseen heuristisilla valvomattomilla menetelmillä, tyypillisesti ROUGE-pohjaisilla, eikä sitä koskaan optimoitu tai arvioitu itsenäisesti. Tässä artikkelissa ehdotamme tiivistelmän ja lähdekoodin yhdenmukaistamista eksplisiittiseksi tehtäväksi ja esittelemme kaksi suurta uutuutta: (1) sen soveltamista tarkemmalla proposition span -tasolla ja (2) sen lähestymistä valvottuna luokittelutehtävänä. Tätä varten loimme uuden koulutusaineiston ehdotustason yhdenmukaistamista varten, joka johdetaan automaattisesti saatavilla olevista yhteenvetoarviointitiedoista. Lisäksi joukkoistamme kehitys- ja testiaineistoja, mikä mahdollistaa mallin kehittämisen ja asianmukaisen arvioinnin. Näiden tietojen pohjalta esitämme valvotun ehdotuksen linjauksen perusmallin, joka osoittaa paremman linjauksen laadun kuin valvomaton lähestymistapa.', 'ca': "L'allinjament de frases en un resum de referència amb les seves homologues en documents de fonts va ser mostrat com una tasca útil de resum auxiliar, sobretot per generar dades d'entrenament per detectar saliència. Malgrat la seva utilitat evaluada, el pas d'allinjament es va apropar principalment amb mètodes heurístics no supervisats, típicament basats en ROUGE, i mai no va ser optimitzat o evaluat independentment. En aquest paper, proposem establir l'alliniament resum-font com una tasca explícita, mentre introduïm dues novetats importants: (1) aplicar-la a un nivell d'abast de proposicions més precis, i (2) aproximar-la com a tasca de classificació supervisada. Per això vam crear un nou conjunt de dades d'entrenament per allinjar el nivell de proposició, derivat automàticament de les dades d'evaluació de resum disponibles. A més, vam recollir conjunts de dades de dev i de tests, permetent desenvolupar models i evaluar adequadament. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.", 'sk': 'Uskladitev stavkov v referenčnem povzetku z njihovimi kolegi v izvornih dokumentih je bila prikazana kot koristna pomožna naloga povzetka, zlasti za ustvarjanje podatkov o usposabljanju za odkrivanje sline. Kljub ocenjeni uporabnosti je bil korak poravnave večinoma pristopen z heurističnimi nenadzorovanimi metodami, običajno na osnovi ROUGE, in nikoli ni bil neodvisno optimiziran ali ocenjen. V prispevku predlagamo vzpostavitev usklajevanja povzetka-vira kot eksplicitne naloge, obenem pa uvajamo dve glavni novosti: (1) uporabo na natančnejši ravni obsega predloga in (2) pristopanje k njej kot nadzorovani nalogi klasifikacije. V ta namen smo ustvarili nov nabor podatkov o usposabljanju za usklajevanje na ravni predloga, ki je samodejno izpeljan iz razpoložljivih podatkov o vrednotenju povzetka. Poleg tega smo zbrali množične nabore razvojnih in testnih podatkov, kar je omogočilo razvoj modelov in ustrezno vrednotenje. Z uporabo teh podatkov predstavljamo osnovni model nadzorovanega usklajevanja predlogov, ki kaže izboljšano kakovost usklajevanja v primerjavi z nenadzorovanim pristopom.', 'jv': 'Gjer-align Nanging ketahane kapan pangan anyi nggawe gerakan kanggo kowe aksi nggawe ketahan tentang karo perusahaan ungi ketahanan sing ora bisa perusahaan, Tipik-perusahaan LOUGE ambek, lan ora iso nggawe nguasai perusahaan anyi mên. In this paper, we proposal to set up a sumy-source alignment as an explicity task, when inserting 2 key romadas: Saiki, kéné nggawe nyimpen dataset sing nggawe nggawe Kelangan-tanggal nggawe barang, dino-tanggal kuwi ono wektu nggawe data dine sisampungan Nambah, awak dhéwé tambah bantên Dev lan ujian dataset kuwi ngêkaké, iso nggawe model nggawe lan ujian sing apik. Ngawe Perintah-Ngerawat data kuwi, kita sampeyan ngewehke perusahaan anyar nggawe sistem di antar, iso nggawe kalitas tekan-nggawe barang apik sing ora bisasai perusahaan.', 'ha': "Ana sanar da gargaɗin a cikin takardar Reference da masayyatan su cikin takardun kwanan kwanan kwanan, an nuna su as wani mai amfani da aikin zartarwa na gaskiyar gaskiyar, da ƙayyade ga ƙiƙira data na tsarin wa gane salon. Babu da amfani da shi, ba za'a iya amfani da hanyarsa masu daidaita ba da shiryoyin heuristic wanda aka tsare, a bayan rubutun, kuma ba a iya amfani da shi ba ko an ƙaddara shi ba. Ga wannan takardan, Munã buɗa a samun a samar-surori kamar wani aiki mai bayyanãwa, a lokacin da Muke ƙarfafa wasu riƙo biyu masu girma: (1) za'a amfani da shi a cikin daraja mafi taƙaita na fassarar span da kuma (2) ke kusantar da shi kamar wani aikin wanda aka tsare shi. Ga wannan, mun ƙiƙira wani tsari na takardar aiki na yanzu dõmin juyi-daraja na faɗa ɗaɗabi'a, don ka motsa data na ƙidãyayar ƙararini da ke iya amfani da shi farat ɗaya. Da wannan, muka ƙarfafa masu tsari da shaidar da aka jarraba, masu iya amfani da shirin ayuka da hakki. Yi amfani da waɗannan data, Muna gabatar da wata misãlai mai tsaro a danne-bangon jujjuya, mai nuna koda tsarin tsayi da ba'a tsare.", 'he': 'הציון משפטים בסרט התייחסות עם השותפים שלהם במסמכים מקורים הוצג כמשימה תועלת לסרטיזציה שימושית, במיוחד לייצור נתונים אימונים לזיהוי מילוי. למרות שירותיו המערכות, צעד התאמה הגיע בעיקר בשיטות היוריסטיות ללא השגחה, בדרך כלל מבוססת על ROUGE, ולעולם לא אופטימי או עריך באופן עצמאי. בעיתון הזה, אנו מציעים לקבוע התאמה של מקור-סכם כמשימה ברורה, בעוד להציג שני חדשות גדולות: (1) להפעיל אותו ברמה המדייקת של ההצעה, ו (2) להתקרב אליו כמשימה מסווג מושגת. למטרה זו, יצרנו קבוצת נתונים של אימונים חדשות עבור התאמה ברמה הצעה, שנוצרה באופן אוטומטי ממידע הערכה של הסיוריזציה זמין. בנוסף, קיבלנו קופסאות מידע ודיווי ומבחנים, מאפשרים פיתוח מודל וערכה נכונה. בשימוש בנתונים האלה, אנחנו מציגים מודל התאמת ההצעה המבוטחת בסיסית, שמראה איכות התאמה משופרת על הגישה הלא ממבוטחת.', 'bo': 'ཐོག་མའི་ཡིག་ཆ་ནང་གི་ཚོགས་རྣམ་གྲངས་བསྡུས་པའི་བརྡ་སྟོན་བཅུག་པ ཞིབ་དཔྱད་བྱས་པའི་ལག་ལེན་འཐབ་རྩིས་མེད་པར། གྲལ་སྒྲིག་གི་གྲལ་རིམ་གྱི་ལམ་ལུགས་ལ་ཕན་ཚུགས་ཐབས་ལམ་ལ་ཕན་ཚུགས་བྱུང་།རྒྱུན་ལྡན་གྱིས་ROU ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་མཛོད་ཁུངས་གྱི་གྲལ་སྒྲིག་འཇུག་རྒྱུ་དང་གསལ་བཤད་ཀྱི་བྱ་འགུལ་བཞིན་བཟོ་བཀལ་དགོས། དེ་ལས་གསར་གཏོད་ཆེན་གཉིས་སྤྲོད་ཀྱི་ཡོད: (1) བྱ་ མཇུག་ལ་དེ་ལ། ང་ཚོས་རང་འགུལ་གྱིས་རྗེས་སུ་གཏོང་གི་འཇུག་རིམ་གྱི་བཟོ་རྣམ་གྲངས་སྒྲིག་ཆ་འཕྲིན་གསར་གཏོང་བ མ་ཟད། ང་ཚོས་མང་ཆེ་བས་ཡོད་པའི་dev ར་དང་། བརྟག་ཞིབ་བྱས་པའི་ཆ་འཕྲིན་ཡིག་ཆ་ལྟར་བསམ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ལག་སྟར་བྱེད་པའི་ཆ་འཕྲིན་འདི་དག་ལྟ་རྟོག་པའི་བསམ་འཆར་གཞི་གྲལ་སྒྲིག་རིམ་པ་ཞིག་སྟོན་ཡོད།'}
{'en': 'Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning', 'ar': 'فرض بنية العلاقة في نماذج اللغة المضمنة باستخدام التعلم التقابلي', 'es': 'Imposición de la estructura de relación en las incrustaciones de modelos lingüísticos mediante el aprendizaje contrastivo', 'pt': 'Impondo Estrutura de Relação em Incorporações de Modelos de Linguagem Usando Aprendizagem Contrastiva', 'fr': "Imposer une structure de relation dans les intégrations de modèles de langage à l'aide de l'apprentissage contrastif", 'ja': '対照的な学習を使用した言語モデルの埋め込みにおける関係構造の強制', 'zh': '用对比学在语言模样嵌入中强加关系', 'hi': 'Contrastive Learning का उपयोग करके भाषा-मॉडल एम्बेडिंग में संबंध संरचना को लागू करना', 'ru': 'Навязывание структуры отношений во вложениях в языковые модели с использованием контрастного обучения', 'ga': 'Struchtúr Caidrimh a Fhorchur i Leabú Múnla Teangacha ag Úsáid Foghlaim Chodarsnachta', 'hu': 'Relatív struktúra beépítése a nyelvi modell beágyazásokban kontrasztív tanulás segítségével', 'el': 'Επιβολή δομής σχέσης σε ενσωμάτωση προτύπων γλωσσών χρησιμοποιώντας την Αντίσταση Μάθηση', 'ka': 'Name', 'it': "Imporre una struttura relazionale nelle incorporazioni di modelli linguistici utilizzando l'apprendimento contrastante", 'kk': 'Тіл үлгілерінде қатынас құрылымын импорттау', 'lt': 'Ryšių struktūros nustatymas kalbos modelio įrangose, kuriose naudojamas kontrastinis mokymasis', 'ms': 'Memasukkan Struktur Hubungan dalam Pencampuran Model Bahasa Mengguna Belajar Kontrastif', 'ml': 'ഭാഷ- മോഡല്\u200d എംബെഡിങ്ങുകളില്\u200d ബന്ധപ്പെടുത്തുന്ന സ്ട്രാക്ട്രെക്റ്റര്\u200dട്ട്രൂക്റ്റര്\u200d ഉപയോഗിക', 'mk': 'Вметнување на структурата на односите во вградувањата на јазичкиот модел со користење контрастивно учење', 'mn': 'Холын загварын нэгтгэлийн харилцааны структур импорт', 'no': 'Comment', 'mt': 'L-Impożizzjoni ta’ Struttura ta’ Relazzjoni fl-Embedding tal-Mudell tal-Lingwa bl-Użu ta’ Tagħlim Kontrastiv', 'pl': 'Wprowadzanie struktury relacji w osadzeniach modeli językowych przy użyciu uczenia się kontrastywnego', 'ro': 'Impunerea structurii relațiilor în încorporarea modelelor lingvistice folosind învățarea contrastivă', 'sr': 'Импорзирање структуре връзка у замбављању језика- модела користећи контрастивно учиње', 'si': 'Name', 'so': 'Imposing structure xiriirka ku qoran qalabka afka-Model ee isticmaalka iskuulka', 'sv': 'Imponera relationsstruktur i språkmodellinbäddningar med hjälp av kontrastivt lärande', 'ta': 'மொழி- மாதிரி உட்பொதிகளில் தொடர்பு உருவாக்கம் செயல்படுத்தப்படுகிறது', 'ur': 'Name', 'vi': 'Tạo kết cấu liên quan trong môi trường ngôn ngữ học sử dụng học tương phản', 'uz': 'Name', 'bg': 'Налагане на относителна структура в вграждането на езикови модели чрез контрастивно обучение', 'nl': 'Relatiestructuur in Language-Model Embeddings opleggen met behulp van Contrastive Learning', 'hr': 'Uvezna struktura odnosa u integraciji jezičkog modela koristeći kontrastivno učenje', 'da': 'Imponering af relationsstruktur i sprogmodel-indlejringer ved hjælp af kontrastiv læring', 'de': 'Imponieren von Beziehungsstrukturen in Sprachmodell-Einbettungen unter Verwendung von kontrastivem Lernen', 'ko': '비교 학습 기반의 언어 모델 삽입에서의 관계 구조', 'id': 'Memasukkan Struktur Hubungan dalam Embedding Language-Model Menggunakan Belajar Kontrastif', 'fa': 'وارد کردن ساختار ارتباط در انجمن مدل زبان استفاده از یادگیری متفاوت', 'sw': 'Kubadilisha Miundombinu ya Kuhusiana katika Mipango ya Utafiti', 'tr': 'Çaltylyk Modeli Girdir', 'af': 'In voer Relasie Struktuur in Taal- Model Inlegtings gebruik Kontrasteef Leer', 'sq': 'Duke vendosur strukturën e marrëdhënieve në përfshirjet e modelit gjuhësor duke përdorur mësimin kontrastiv', 'am': 'Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning', 'hy': 'Գործել հարաբերությունների կառուցվածքը լեզվի-մոդելի ներգրավման մեջ, օգտագործելով հակադրական սովորելը', 'az': 'Dil Modeli 캻fad톛l톛rind톛 캻fad톛 Et', 'bn': 'ভাষা-মোডেল এমবেডিং ব্যবহার করে সম্পর্কের কাঠামো প্রভাবিত করা হচ্ছে', 'bs': 'Uvezna struktura odnosa u integraciji jezičkog modela koristeći kontrastivno učenje', 'ca': 'Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning', 'et': 'Suhtestruktuuri kehtestamine keelemudeli manustamisel kontrastiivse õppe abil', 'cs': 'Vložení vztahové struktury v vložení jazykových modelů pomocí kontrastivního učení', 'fi': 'Suhteellisen rakenteen määrittäminen kielimallien upotuksissa kontrastiivista oppimista käyttäen', 'he': 'מייצג מבנה מערכת יחסים בתכניות מודל לשפה בשימוש ללמוד נגד', 'ha': '@ action', 'jv': 'Imposing Relative structural in Language-model embedding Using contraststive Learning', 'sk': 'Vstavljanje relativne strukture v jezikovnih modelih z uporabo kontrastivnega učenja', 'bo': 'Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning'}
{'en': 'Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. In this paper, we propose a novel contrastive learning framework that trains  sentence embeddings  to encode the relations in a  graph structure . Given a sentence (unstructured text) and its  graph , we use contrastive learning to impose relation-related structure on the token level representations of the sentence obtained with a CharacterBERT (El Boukkouri et al., 2020) model. The resulting relation-aware sentence embeddings achieve state-of-the-art results on the relation extraction task using only a simple KNN classifier, thereby demonstrating the success of the proposed method. Additional visualization by a tSNE analysis shows the effectiveness of the learned  representation space  compared to baselines. Furthermore, we show that we can learn a different space for  named entity recognition , again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.', 'ar': 'على الرغم من أن تضمين نصوص نموذج اللغة قد أحدث ثورة في أبحاث البرمجة اللغوية العصبية ، إلا أن قدرتها على التقاط المعلومات الدلالية عالية المستوى ، مثل العلاقات بين الكيانات في النص ، محدودة. في هذه الورقة ، نقترح إطارًا تعليميًا متباينًا جديدًا يقوم بتدريب زخارف الجملة لتشفير العلاقات في بنية الرسم البياني. بالنظر إلى الجملة (نص غير منظم) والرسم البياني الخاص بها ، فإننا نستخدم التعلم التباين لفرض الهيكل المرتبط بالعلاقة على تمثيلات المستوى الرمزي للجملة التي تم الحصول عليها باستخدام نموذج CharacterBERT (El Boukkouri et al. ، 2020). تحقق عمليات دمج الجملة المدركة للعلاقة الناتجة أحدث النتائج في مهمة استخراج العلاقة باستخدام مصنف KNN بسيط فقط ، مما يدل على نجاح الطريقة المقترحة. يظهر التصور الإضافي من خلال تحليل tSNE فعالية مساحة التمثيل المكتسبة مقارنة بخطوط الأساس. علاوة على ذلك ، نظهر أنه يمكننا تعلم مساحة مختلفة للتعرف على الكيانات المسماة ، مرة أخرى باستخدام هدف تعليمي متباين ، ونوضح كيفية الجمع بين فضاءات التمثيل بنجاح في مهمة علاقة الكيان.', 'pt': 'Embora as incorporações de texto de modelos de linguagem tenham revolucionado a pesquisa de PNL, sua capacidade de capturar informações semânticas de alto nível, como relações entre entidades no texto, é limitada. Neste artigo, propomos uma nova estrutura de aprendizagem contrastiva que treina a incorporação de sentenças para codificar as relações em uma estrutura de grafos. Dada uma sentença (texto não estruturado) e seu gráfico, usamos aprendizagem contrastiva para impor estrutura relacionada às relações nas representações de nível de token da sentença obtidas com um modelo CharacterBERT (El Boukkouri et al., 2020). Os embeddings de sentenças com reconhecimento de relações resultantes alcançam resultados de última geração na tarefa de extração de relações usando apenas um classificador KNN simples, demonstrando assim o sucesso do método proposto. A visualização adicional por uma análise de tSNE mostra a eficácia do espaço de representação aprendido em comparação com as linhas de base. Além disso, mostramos que podemos aprender um espaço diferente para reconhecimento de entidades nomeadas, novamente usando um objetivo de aprendizado contrastivo, e demonstramos como combinar com sucesso ambos os espaços de representação em uma tarefa entidade-relação.', 'es': 'Si bien la inserción de texto en modelos lingüísticos ha revolucionado la investigación sobre PNL, su capacidad para capturar información semántica de alto nivel, como las relaciones entre entidades en el texto, es limitada. En este artículo, proponemos un novedoso marco de aprendizaje contrastivo que entrena la incrustación de oraciones para codificar las relaciones en una estructura gráfica. Dada una oración (texto no estructurado) y su gráfica, utilizamos el aprendizaje contrastivo para imponer una estructura relacionada con la relación en las representaciones a nivel de ficha de la oración obtenidas con un modelo CharacterBert (El Boukkouri et al., 2020). Las incorporaciones de oraciones que tienen en cuenta las relaciones resultantes logran resultados de vanguardia en la tarea de extracción de relaciones utilizando solo un clasificador KNN simple, lo que demuestra el éxito del método propuesto. La visualización adicional mediante un análisis TsNE muestra la eficacia del espacio de representación aprendido en comparación con las líneas de base. Además, demostramos que podemos aprender un espacio diferente para el reconocimiento de entidades nombradas, nuevamente utilizando un objetivo de aprendizaje contrastivo, y demostrar cómo combinar con éxito ambos espacios de representación en una tarea de relación entre entidades.', 'fr': "Bien que les intégrations de texte de modèles linguistiques aient révolutionné la recherche sur la PNL, leur capacité à capturer des informations sémantiques de haut niveau, telles que les relations entre les entités dans le texte, est limitée. Dans cet article, nous proposons un nouveau cadre d'apprentissage contrastif qui entraîne les incorporations de phrases pour coder les relations dans une structure graphique. À partir d'une phrase (texte non structuré) et de son graphique, nous utilisons l'apprentissage contrastif pour imposer une structure liée à la relation aux représentations au niveau du jeton de la phrase obtenues avec un modèle CharacterBert (El Boukkouri et al., 2020). Les intégrations de phrases sensibles aux relations qui en résultent permettent d'obtenir des résultats de pointe sur la tâche d'extraction de relation en utilisant uniquement un simple classificateur KNN, démontrant ainsi le succès de la méthode proposée. Une visualisation supplémentaire par une analyse TsNe montre l'efficacité de l'espace de représentation appris par rapport aux lignes de base. En outre, nous montrons que nous pouvons apprendre un espace différent pour la reconnaissance d'entités nommées, toujours en utilisant un objectif d'apprentissage contrastif, et montrons comment combiner avec succès les deux espaces de représentation dans une tâche entité-relation.", 'ja': '言語モデルのテキスト埋め込みは、NLP研究に革命をもたらしたが、テキスト内のエンティティ間の関係など、高レベルの意味情報を取り込む能力は限られている。 この論文では、グラフ構造における関係をエンコードするための文章埋め込みをトレーニングする、新しい対照的な学習フレームワークを提案します。 文（非構造化テキスト）とそのグラフを考えると、対照的な学習を使用して、CharacterBERT （ El Boukkouri et al., 2020 ）モデルで得られた文のトークンレベルの表現に関係関連の構造を課します。 結果として生じる関係認識文埋め込みは、単純なKNN分類子のみを使用して関係抽出タスクで最先端の結果を達成し、提案された方法の成功を実証する。 TSNE分析による追加の視覚化は、ベースラインと比較して学習された表現空間の有効性を示す。 さらに、対照的な学習目標を使用して、名前付きエンティティ認識の異なる空間を学習し、エンティティ関連タスクで両方の表現空間をうまく組み合わせる方法を示すことができます。', 'zh': '虽言语模文本嵌彻底改变已NLP研究,然其获高语义信息(如文本之实)力有限矣。 本文中,新比学框架,当框架练句嵌图编码。 给定一句(非结构化文本)及其图形,我用比学加于用CharacterBERT(El Boukkouri等,2020)模得句之表。 是以知句之KNN器之先进也,以验其成功。 因 tSNE 析额可视化示,比于基线,学示空有效性。 又吾再用比学,明吾可以学空名实体,演示成功于实体之间。', 'hi': 'यद्यपि भाषा मॉडल पाठ एम्बेडिंग ने एनएलपी अनुसंधान में क्रांति ला दी है, लेकिन उच्च-स्तरीय शब्दार्थ जानकारी को कैप्चर करने की उनकी क्षमता, जैसे कि पाठ में संस्थाओं के बीच संबंध, सीमित है। इस पेपर में, हम एक उपन्यास कंट्रास्टिव लर्निंग फ्रेमवर्क का प्रस्ताव करते हैं जो ग्राफ संरचना में संबंधों को एन्कोड करने के लिए वाक्य एम्बेडिंग को प्रशिक्षित करता है। एक वाक्य (असंरचित पाठ) और इसके ग्राफ को देखते हुए, हम एक CharacterBERT (El Boukkouri et al., 2020) मॉडल के साथ प्राप्त वाक्य के टोकन स्तर के प्रतिनिधित्व पर संबंध से संबंधित संरचना को लागू करने के लिए contrastive learning का उपयोग करते हैं। परिणामी संबंध-जागरूक वाक्य एम्बेडिंग केवल एक साधारण केएनएन क्लासिफायर का उपयोग करके संबंध निष्कर्षण कार्य पर अत्याधुनिक परिणाम प्राप्त करते हैं, जिससे प्रस्तावित विधि की सफलता का प्रदर्शन होता है। एक tSNE विश्लेषण द्वारा अतिरिक्त विज़ुअलाइज़ेशन बेसलाइन की तुलना में सीखा प्रतिनिधित्व स्थान की प्रभावशीलता को दर्शाता है। इसके अलावा, हम दिखाते हैं कि हम नामित इकाई मान्यता के लिए एक अलग स्थान सीख सकते हैं, फिर से एक विरोधाभासी सीखने के उद्देश्य का उपयोग करके, और प्रदर्शित कर सकते हैं कि एक इकाई-संबंध कार्य में दोनों प्रतिनिधित्व रिक्त स्थान को सफलतापूर्वक कैसे संयोजित किया जाए।', 'ru': 'Хотя вложения текста языковой модели произвели революцию в исследованиях NLP, их способность захватывать семантическую информацию высокого уровня, такую как отношения между объектами в тексте, ограничена. В этой статье мы предлагаем новую контрастную структуру обучения, которая обучает вложения предложений для кодирования отношений в структуре графа. Учитывая предложение (неструктурированный текст) и его график, мы используем контрастное обучение, чтобы навязать связанную с отношениями структуру на символьных представлениях уровня предложения, полученных с помощью модели CharacterBERT (El Boukkouri et al., 2020). Полученные вложения предложений, учитывающие отношения, достигают самых современных результатов в задаче извлечения отношений, используя только простой классификатор KNN, тем самым демонстрируя успех предлагаемого метода. Дополнительная визуализация с помощью анализа tSNE показывает эффективность изученного пространства представления по сравнению с базовыми линиями. Кроме того, мы показываем, что мы можем выучить другое пространство для распознавания именованных сущностей, опять же используя контрастную цель обучения, и продемонстрировать, как успешно объединить оба пространства представления в задаче сущности-связи.', 'ga': 'Cé gur athraigh leabú téacs samhlacha teanga taighde NLP, tá a gcumas faisnéis shéimeantach ardleibhéil a ghabháil, mar an caidreamh idir eintitis i dtéacs, teoranta. Sa pháipéar seo, molaimid creat foghlama codarsnachta úrnua a threoraíonn leabú abairtí chun an caidreamh a ionchódú i struchtúr graif. I bhfianaise abairte (téacs neamhstruchtúrtha) agus a ghraf, bainimid úsáid as foghlaim chodarsnachta chun struchtúr gaolmhar a fhorchur ar na léirithe ag leibhéal comharthaí na habairte a fuarthas le múnla CharacterBERT (El Boukkouri et al., 2020). Baintear amach torthaí úrscothacha ar thasc asbhainte an chaidrimh leis na leabuithe abairte gaolmhar a thagann dá bharr agus úsáid á baint as aicmitheoir simplí KNN amháin, rud a léiríonn rath an mhodha atá beartaithe. Léiríonn léirshamhlú breise trí anailís SNE éifeachtacht an spáis ionadaíochta foghlamtha i gcomparáid le bonnlínte. Ina theannta sin, léirímid gur féidir linn spás difriúil a fhoghlaim chun aonán ainmnithe a aithint, arís ag baint úsáide as cuspóir foghlama codarsnachta, agus léiriú conas an dá spás ionadaíochta a chomhcheangal go rathúil i dtasc a bhaineann le haonáin.', 'ka': 'თუმცა ენის მოდელური ტექსტის შესაბამისი რეგჲლუციაცია NLP შესაბამისი შესაბამისი, მათი შესაბამისი სიმენტიკური ინფორმაცია, როგორც ტექსტის ელექტის შესაბამისი შესაბამისი ამ დონტაქტში ჩვენ მინდა პრომენტური კონტრასტური სწავლების ფრამეტრი, რომელიც წარმოდგენებული წარმოდგენების კონტრასტურაციის კონტრასტურაციის სიტყვა (არსტრუქტურული ტექსტი) და მისი გრაფიკის შესახებ, ჩვენ გამოყენებთ კონტრუქტური სწავლება, რომელიც შესახებ შესახებ სტრუქტურაციის შესახებ მნიშვნელოვანების გამოსახულებაში, რომელი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი შემ Name დამატებით, ჩვენ ვაჩვენებთ, რომ ჩვენ შეგვიძლია ვისწავლოთ განსხვავებული სივრცე ინტერტიკის განაცნობისთვის, ისინი გამოყენებული კონტრასტური სწავლების მიზეზი, და გამოჩვენებთ როგორ წარმოდგენ', 'el': 'Αν και η ενσωμάτωση κειμένου γλωσσικού μοντέλου έχει φέρει επανάσταση στην έρευνα, η ικανότητά τους να συλλαμβάνουν σημασιολογικές πληροφορίες υψηλού επιπέδου, όπως σχέσεις μεταξύ οντοτήτων στο κείμενο, είναι περιορισμένη. Στην παρούσα εργασία, προτείνουμε ένα νέο πλαίσιο μάθησης που εκπαιδεύει την ενσωμάτωση προτάσεων για να κωδικοποιήσει τις σχέσεις σε μια δομή γραφήματος. Δεδομένης μιας πρότασης (μη δομημένο κείμενο) και του γραφήματός της, χρησιμοποιούμε την αντίθετη μάθηση για την επιβολή δομής σχετιζόμενης με τη σχέση στις αναπαραστάσεις σε επίπεδο συμβολικών της πρότασης που λαμβάνεται με ένα μοντέλο του κ.α., 2020. Οι προκύπτουσες ενσωμάτωσης προτάσεων με γνώμονα τη σχέση επιτυγχάνουν αποτελέσματα τελευταίας τεχνολογίας στην εργασία εξαγωγής σχέσεων χρησιμοποιώντας μόνο έναν απλό ταξινομητή, αποδεικνύοντας έτσι την επιτυχία της προτεινόμενης μεθόδου. Η πρόσθετη απεικόνιση με ανάλυση δείχνει την αποτελεσματικότητα του μαθημένου χώρου αναπαράστασης σε σύγκριση με τις γραμμές βάσης. Επιπλέον, δείχνουμε ότι μπορούμε να μάθουμε έναν διαφορετικό χώρο αναγνώρισης ονομασίας οντότητας, χρησιμοποιώντας και πάλι έναν αντικρουστικό μαθησιακό στόχο, και να δείξουμε πώς μπορούμε να συνδυάσουμε επιτυχώς και τους δύο χώρους αναπαράστασης σε μια εργασία οντότητας-σχέσης.', 'hu': 'Bár a nyelvi modellek szövegbeágyazása forradalmasította az NLP kutatását, korlátozott a magas szintű szemantikai információk rögzítésére, mint például a szövegben lévő entitások közötti kapcsolatok. Ebben a tanulmányban egy új kontrasztos tanulási keretrendszert javasolunk, amely a mondatok beágyazását képezi, hogy a kapcsolatokat egy grafikonos struktúrába kódolják. Egy mondat (strukturálatlan szöveg) és annak grafikonja alapján kontrasztív tanulást használunk arra, hogy a CharacterBERT (El Boukkouri et al., 2020) modellel kapott mondat tokenszintű reprezentációjára erősítsük a kapcsolatokkal kapcsolatos struktúrát. A kapcsolat-tudatos mondatbeágyazások csak egy egyszerű KNN osztályozó segítségével érnek el korszerű eredményeket a kapcsolat-extrakciós feladat során, ezzel bizonyítva a javasolt módszer sikerét. További vizualizáció tSNE elemzéssel mutatja a tanult reprezentációs tér hatékonyságát a kiindulási vonalakhoz képest. Ezenkívül megmutatjuk, hogy egy másik teret tudunk megtanulni a nevezett entitás felismeréséhez, ismét egy kontrasztos tanulási célkitűzéssel, és bemutatjuk, hogyan lehet sikeresen kombinálni mindkét reprezentációs teret egy entitás-kapcsolat feladatban.', 'lt': 'Nors kalbos modelio tekstų įtraukimas revoliucijavo NLP mokslinius tyrimus, jų gebėjimas surinkti aukšto lygio semantinę informaciją, pavyzdžiui, ryšius tarp teksto subjektų, yra ribotas. Šiame dokumente siūlome naują kontrastinį mokymosi sistemą, kuria rengiami sakinių įtraukimai, kad santykiai būtų koduojami grafikos struktūroje. Atsižvelgdami į sakinį (nesustruktūruotą tekstą) ir jo grafiką, naudojame kontrastinį mokymąsi, kad su santykiais susijusiai struktūrai būtų nustatytas žodžio, gauto naudojant CharacterBERT (El Boukkouri et al., 2020) model į, simbolių lygis. Atsižvelgiant į tai, kad įterpiami santykiai žinomi sakiniai, pasiekti naujausi santykių išgavimo užduoties rezultatai naudojant tik paprastą KNN klasifikatorių, taip įrodant siūlomo metodo sėkmę. Papildomas tSNE analizės vizualizavimas rodo įgytos reprezentacinės erdvės veiksmingumą, palyginti su bazinėmis linijomis. Be to, mes parodome, kad galime pasimokyti skirtingą erdvę vardiniam subjekto pripažinimui, vėl naudojant kontrastinį mokymosi tikslą, ir parodyti, kaip sėkmingai sujungti abu atstovavimo skyrius su subjektu susijusioje užduotyje.', 'it': "Sebbene le incorporazioni di testo dei modelli linguistici abbiano rivoluzionato la ricerca NLP, la loro capacità di catturare informazioni semantiche di alto livello, come le relazioni tra entità nel testo, è limitata. In questo articolo, proponiamo un nuovo framework di apprendimento contrastante che addestra gli embedding delle frasi per codificare le relazioni in una struttura grafica. Data una frase (testo non strutturato) e il suo grafico, utilizziamo l'apprendimento contrastante per imporre una struttura relazionale sulle rappresentazioni a livello token della frase ottenuta con un modello CharacterBERT (El Boukkouri et al., 2020). Le incorporazioni di frasi correlate risultanti ottengono risultati all'avanguardia nel compito di estrazione delle relazioni utilizzando solo un semplice classificatore KNN, dimostrando così il successo del metodo proposto. La visualizzazione aggiuntiva mediante un'analisi tSNE mostra l'efficacia dello spazio di rappresentazione appreso rispetto alle linee di base. Inoltre, mostriamo che possiamo imparare uno spazio diverso per il riconoscimento di entità con nome, sempre utilizzando un obiettivo di apprendimento contrastante, e dimostrare come combinare con successo entrambi gli spazi di rappresentazione in un compito di relazione entità.", 'kk': 'Тіл үлгісінің мәтін ендіру үлгісі NLP зерттеулерін революциялау үшін, олардың ең жоғары деңгейіндегі семантикалық мәліметін түсіру мүмкіндігі, мысалы мәтіндегі Бұл қағазда, графикалық құрылғысында қатынастарды кодтамыз үшін жаңа контрастық оқыту фреймін ұсынамыз. Сөзді (құрылмаған мәтін) және оның графикасына сәйкес келтірілген мәтін (El Boukkouri et al., 2020) үлгісімен сәйкес келтірілген құрылымдарды таңдау үшін контрастық оқытуды қолданамыз. Сонымен қатынасы білмейтін сұрақтардың ендірімі күй- жай тапсырмасының қатынасын тарқату тапсырмасының нәтижесін тек қарапайым KNN классификаторымен жеткізеді, сондықтан ұсынылған әдісінің сәтті tSNE анализациясының қосымша визуализациясы негізгі сызықтардың салыстырылып, үйренген кеңістік орының ең әсерілігін көрсетеді. Қосымша, біз аталған нысандарды анықтау үшін басқа орын үйрене аламыз, қайталап контрастырлық оқыту мақсатын қолдануға болады, және нысандар қатынасына қалай екеуін жақсы түрде біріктіруге болады деп көрсетеді.', 'mk': 'Иако текстовите на јазичкиот модел го револуционираа истражувањето на НЛП, нивната способност да заземат семантични информации на високо ниво, како што се односите меѓу ентитетите во текстот, е ограничена. Во овој весник предложуваме нова контрастивна рамка за учење која тренира вградување на реченици за кодирање на односите во структура на график. Со оглед на реченицата (неструктурен текст) и нејзиниот граф, користиме контрастивно учење за да наметнеме структура поврзана со односите на претставувањата на нивото на знаци на реченицата добиена со моделот на ЧарактерБЕРТ (Ел Букури и ал., 2020). Резултатите на вклучувањата на речениците свесни за односите постигнуваат најнови резултати на задачата за извлекување на односите користејќи само едноставен класификатор на KNN, со што ќе се демонстрира успехот на предложениот метод. Дополнителна визуелизација од страна на анализа tSNE ја покажува ефикасноста на научениот простор за претставување во споредба со основните линии. Покрај тоа, покажуваме дека можеме да научиме различен простор за препознавање на именувани ентитети, повторно користејќи контрастивна цел за учење, и да демонстрираме како успешно да ги комбинираме двете места за претставување во задача со однос на ентитетот.', 'ml': 'ഭാഷ മോഡല്\u200d ടെക്സ്റ്റ് എംഎല്\u200dപി പഠനം വിപ്ലവമാക്കിയിരിക്കുന്നുവെങ്കിലും അവയുടെ കഴിവ് ഉയര്\u200dന്ന നിലയിലെ സെമാന്റിക് വിവരങ്ങള്\u200d പി ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഒരു നോവല്\u200d വിരോധമായ പഠിപ്പിക്കുന്ന ഫ്രെയിമ്പ് പ്രൊദ്ദേശിപ്പിക്കുന്നു. വാക്കുകള്\u200d പ്രദര്\u200dശിപ് ഒരു വാക്ക് (സ്ഥാപിക്കപ്പെട്ട ട ടെക്സ്റ്റ്) കൊണ്ടും, അതിന്റെ ഗ്രാഫും കൊണ്ട്, നമ്മള്\u200d വിരോധമായ പഠിപ്പിക്കുന്നത് വിശ്വാസം ഉപയോഗിക്കുന്നു. വാക്കിന്റെ സ്ഥ പരിചയപ്പെടുത്തുന്ന ബന്ധത്തിന്റെ വാക്കിന്റെ ഉള്ളിലുള്ള സ്റ്റേറ്റ് ഓഫ്-ആര്\u200dട്ടിന്റെ ഫലങ്ങള്\u200d ഒരു ലളിതമായ കെന്\u200dഎന്\u200d എണ്ണി ക്ലാസ്ഫിഫയര്\u200d മാ Additional visualization by a tSNE analysis shows the effectiveness of the learned representation space compared to baselines.  അതിനുശേഷം, നമ്മള്\u200d കാണിക്കുന്നത് ശരാര്യം തിരിച്ചറിയാന്\u200d വേറൊരു സ്ഥലം നമുക്ക് പഠിക്കാന്\u200d കഴിയും, വീണ്ടും വിരോധമായ പഠിക്കുന്ന ലക്ഷ്യം ഉപയ', 'ms': 'Walaupun penerbangan teks model bahasa telah revolusi kajian NLP, kemampuan mereka untuk menangkap maklumat semantik tinggi, seperti hubungan antara entiti dalam teks, adalah terbatas. Dalam kertas ini, kami melaporkan kerangka pembelajaran bertentangan yang baru yang melatih pembangunan kalimat untuk mengekodkan hubungan dalam struktur graf. Mengingat kalimat (teks tidak struktur) dan grafnya, kami menggunakan pembelajaran bertentangan untuk memaksa struktur berkaitan hubungan pada perwakilan aras token kalimat yang diperoleh dengan model AksaraBERT (El Boukkouri et al., 2020). Penampilan kalimat yang berasal dari hubungan-sedar mencapai keputusan-state-of-the-art pada tugas ekstraksi hubungan menggunakan hanya pengklasifikasi KNN sederhana, dengan demikian menunjukkan kesuksesan kaedah yang direncanakan. Visualisasi tambahan oleh analisis tSNE menunjukkan kegunaan ruang perwakilan belajar dibandingkan dengan garis dasar. Lagipun, kita menunjukkan bahawa kita boleh belajar ruang yang berbeza untuk pengenalan entiti bernama, lagi menggunakan objektif pembelajaran bertentangan, dan menunjukkan bagaimana untuk bergabung dengan sukses kedua-dua ruang mewakili dalam tugas hubungan entiti.', 'mt': 'Għalkemm l-inkorporazzjonijiet tat-test tal-mudell lingwistiku rrevoluzzjonaw ir-riċerka NLP, il-kapaċità tagħhom li jaqbdu informazzjoni semantika ta’ livell għoli, bħar-relazzjonijiet bejn entitajiet fit-test, hija limitata. F’dan id-dokument, qed nipproponu qafas ġdid ta’ tagħlim kuntrastiv li jħarreġ l-inkorporazzjoni tas-sentenzi biex jiġu kkodifikati r-relazzjonijiet fi struttura grafika. Minħabba sentenza (test mhux strutturat) u l-grafika tagħha, a ħna nużaw tagħlim kuntrastiv biex nimponu struttura relatata mar-relazzjoni fuq ir-rappreżentazzjonijiet fil-livell tat-token tas-sentenza miksuba b’mudell CharacterBERT (El Boukkouri et al., 2020). L-inkorporazzjonijiet tas-sentenzi li jirriżultaw li huma konxji mir-relazzjoni jiksbu riżultati l-aktar avvanzati dwar il-kompitu ta’ estrazzjoni tar-relazzjoni bl-użu ta’ klassifikatur sempliċi KNN biss, u b’hekk juru s-suċċess tal-metodu propost. Additional visualization by a tSNE analysis shows the effectiveness of the learned representation space compared to baselines.  Furthermore, we show that we can learn a different space for named entity recognition, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.', 'no': 'Selv om språk-modellen har revolusjonart NLP-forskning, er dei moglege å henta semantisk informasjon på høg nivå, som forholdet mellom einingar i tekst begrenset. I denne papiret foreslår vi eit nytt kontrastisk læringsrammeverk som treng setningar innebygd for å koda forholdet i eit grafstruktur. Given eit setning (ikkje strukturert tekst) og grafen, bruker vi kontrastlæring for å impossera relasjonsrelasjonsstrukturen på teiknenivået representasjonane av setninga som er oppteken med eit teiknbart (El Boukkouri et al., 2020). Det følgjande uttrykkinga av setningane i relasjonsveit gjer tilstand til kunsten til resultatet på uttrykkinga av relasjonsoppgåva med berre ein enkel KNN- klassifisering, slik at det viser suksess på den foreslåtte metoden. Ekstra visualisering av ein tSNE-analyse viser effektiviteten til den lærte representasjonsmessinga i sammenligning med baselinjer. I tillegg viser vi at vi kan lære eit anna plass for gjenkjenning av namnet entitet, igjen ved å bruka eit kontrastivt læringsmål, og demonstrera korleis begge representasjonsmessingar skal kombinererast med suksessfull i ei oppgåve med entitetsrelasjon.', 'pl': 'Chociaż osadzenia tekstu modelu językowego zrewolucjonizowały badania NLP, ich zdolność do przechwytywania wysokiego poziomu informacji semantycznych, takich jak relacje między podmiotami w tekście, jest ograniczona. W niniejszym artykule proponujemy nowe kontrastywne ramy uczenia się, które trenują osadzenia zdań w celu zakodowania relacji w strukturze wykresu. Biorąc pod uwagę zdanie (tekst nieustrukturyzowany) i jego wykres, używamy uczenia kontrastywnego, aby narzucić strukturę relacji na poziomie tokenów reprezentacji zdania uzyskanego za pomocą modelu CharacterBERT (El Boukkouri et al., 2020). Powstałe osadzenia zdań świadomych relacji uzyskują najnowocześniejsze wyniki w zadaniu ekstrakcji relacji przy użyciu jedynie prostego klasyfikatora KNN, co pokazuje sukces proponowanej metody. Dodatkowa wizualizacja za pomocą analizy tSNE pokazuje skuteczność nauczonej przestrzeni reprezentacyjnej w porównaniu z liniami bazowymi. Ponadto pokazujemy, że możemy nauczyć się innej przestrzeni do rozpoznawania nazwanych jednostek, ponownie przy użyciu kontrastywnego celu uczenia się, oraz pokazać, jak skutecznie łączyć obie przestrzenie reprezentacyjne w zadaniu relacji jednostka.', 'mn': 'Хэдийгээр хэл загварын текстүүдийн нэгтгэл нь NLP судалгааны хувьсгал болсон ч, тэдний өндөр түвшингийн семантик мэдээллийг барьж, жишээ нь текстүүдийн хоорондын харилцаа хязгаарлагддаг. Энэ цаасан дээр бид график бүтээгдэхүүний харилцааны кодлох боломжтой шинэ эсрэг суралцах үйл ажиллагааг суралцаж байна. Үүний график (бүтээгдэхүүнгүй текст) болон харилцааны харилцаа холбоотой бүтцийг CharacterBERT (El Boukkouri et al., 2020) загвартай гарсан өгүүлбэрээс гаргасан өгүүлбэрээс илэрхийлэх тэмдэгтийг ашиглаж байна. Үүний үр дүнд харилцааны мэдрэмжтэй өгүүлбэрүүд нь зөвхөн хялбар KNN хэлбэрийг ашиглан харилцааны хувьд урлагийн үр дүнг гаргаж ирнэ. Энэ нь зарласан арга замын амжилтыг харуулж байна. tSNE шинжлэх ухааны нэмэлт үзэл нь сурсан үзүүлэлтийн орон зайн суурь шулуунтай харьцуулахад үр дүнтэй харагдаж байна. Үүнээс гадна бид биетийн хүлээн зөвшөөрөх өөр орон зай сурах боломжтой болж, эсрэг суралцах зорилго ашиглаж, биетийн холбоотой ажлын хоёуланг хэрхэн амжилттай нийлүүлэхийг харуулж чадна.', 'ro': 'Deși încorporările de text ale modelului lingvistic au revoluționat cercetarea PNL, capacitatea lor de a capta informații semantice la nivel înalt, cum ar fi relațiile dintre entitățile din text, este limitată. În această lucrare, propunem un nou cadru de învățare contrastant care antrenează încorporările propozițiilor pentru a codifica relațiile într-o structură grafică. Având în vedere o propoziție (text nestructurat) și graficul acesteia, folosim învățarea contrastantă pentru a impune structura relațională reprezentărilor la nivel token ale propoziției obținute cu un model CharacterBERT (El Boukkouri et al., 2020). Încorporările propozițiilor rezultate conștiente de relație obțin rezultate de ultimă generație în sarcina de extragere a relațiilor utilizând doar un simplu clasificator KNN, demonstrând astfel succesul metodei propuse. Vizualizarea suplimentară printr-o analiză tSNE arată eficacitatea spațiului de reprezentare învățat în comparație cu liniile de referință. Mai mult, arătăm că putem învăța un spațiu diferit pentru recunoașterea entităților denumite, din nou folosind un obiectiv de învățare contrastant, și demonstrăm cum să combinăm cu succes ambele spații de reprezentare într-o sarcină de relație entitate.', 'so': 'In kastoo qoraalka muusikada afka ah uu ku qoray qoraal baaritaanka NLP, waxaa xadgudban kara awooddooda ay qabsadaan macluumaadka heerka sare, sida xiriirka u dhexeeya alaabta qoraalka. Qoraalkan waxaynu soo jeedaynaa qoraal ah oo ka mid ah iskuul barashada, kaas oo ku tababaraya ciqaabka ku qoran xarunta sawirka. Sida lagu helo ereyga (qoraalka la dhisay) iyo sawirkiisa, waxaynu isticmaalnaa barashada kala duwan si aan u dhigno dhismo la xiriira ee heerka calaamadda ee uu ku qoray qoraalka xarafka BERT (El Boukkouri et al., 2020). Xerka xiriirka aqoonsan ee sababtooda ah waxay gaadhaa xaalad-the-art resultaris ku saabsan shaqada la soo saaro oo keliya isticmaalaya fasax fudud KNN, taas darteed waxay muujineysaa liibaanka qaababka la soo jeeday. Faahfaahin dheeraad ah oo ku qoran tSNE baaritaankeedu wuxuu muujiyaa shaqaalaha meesha lagu barto oo la bartay saldhigyada hoose. Sidoo kale waxaynu tusnaynaa in aynu baran karno goob kale oo lagu magacaabay aqoonsiga entity, mar kale waxaynu isticmaali karnaa goal ka duwan waxbarashada, waxaana tusinaynaa sida aad ugu liibaansan karno labada goobood ee wakiilka ah goobta shaqada xiriirka.', 'sv': 'ﾃёen om sprﾃ･kmodelltextinbﾃ､ddningar har revolutionerat NLP-forskningen, ﾃ､r deras fﾃｶrmﾃ･ga att fﾃ･nga in semantisk information pﾃ･ hﾃｶg nivﾃ･, sﾃ･som relationer mellan entiteter i text, begrﾃ､nsad. I denna uppsats fﾃｶreslﾃ･r vi ett nytt kontrastivt lﾃ､rramverk som trﾃ､nar meningar inbﾃ､ddningar fﾃｶr att koda relationerna i en grafstruktur. Med tanke pﾃ･ en mening (ostrukturerad text) och dess graf anvﾃ､nder vi kontrastivt lﾃ､rande fﾃｶr att infﾃｶra relationsrelaterad struktur pﾃ･ symbolnivﾃ･representationer av meningen som erhﾃ･llits med en CharacterBERT-modell (El Boukkouri et al., 2020). De resulterande relationsmedvetna meningsbﾃ､ddningarna uppnﾃ･r toppmoderna resultat pﾃ･ relationsextraktionsuppgiften med endast en enkel KNN-klassificerare, vilket visar framgﾃ･ngen med den fﾃｶreslagna metoden. Ytterligare visualisering med hjﾃ､lp av en tSNE-analys visar effektiviteten av det inlﾃ､rda representationsutrymmet jﾃ､mfﾃｶrt med baselines. Vidare visar vi att vi kan lﾃ､ra oss ett annat utrymme fﾃｶr namngiven entitetsigenkﾃ､nning, ﾃ･terigen med hjﾃ､lp av ett kontrastivt lﾃ､rmﾃ･l, och visa hur vi framgﾃ･ngsrikt kombinerar bﾃ･da representationsutrymmen i en entitetsrelationsuppgift.', 'sr': 'Iako su integracije teksta jezika revolucionisale istraživanje NLP-a, njihova sposobnost uhvatiti semantičke informacije na visokom nivou, poput odnosa između entitata u tekstu, ograničena. U ovom papiru predlažemo novi kontrastivni okvir učenja koji obučava rečenicu da kodira odnose u grafskoj strukturi. S obzirom na rečenicu (neostrukturni tekst) i njegov grafik, koristimo kontrastivno učenje da namestimo strukturu povezanu sa odnosima na predstavljanje rečenice na nivou znakova koja je dobila sa modelom CharacterBERT (El Boukkouri et al., 2020). Rezultati uvođenja rečenica svjesne veze postižu rezultate stanja umjetnosti na zadatku izvlačenja odnosa koristeći samo jednostavnu klasifikatoru KNN, tako pokazujući uspjeh predložene metode. Dodatna vizualizacija analiza tSNE pokazuje učinkovitost svemira učenih predstavljanja u usporedbi sa osnovnim linijama. Osim toga, pokazujemo da možemo naučiti drugačiji prostor za priznanje entiteta, ponovo koristeći kontrastivni cilj učenja, i pokazati kako uspešno kombinirati oba prostora predstavljanja u zadatku vezanom za entitet.', 'si': 'භාෂාව මොඩේල් පාළුවක් ඇම්බෙන්ඩ් එක්ක NLP පරීක්ෂණය වික්\u200dරමය කරලා තියෙනවා නමුත්, ඔවුන්ගේ පුළුවන් වික්\u200dරමය සම්බ මේ පත්තරේ අපි ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් කරනවා කියලා වචන සංවේදනයක් සංවේදනය කරනවා කියලා ග්\u200dරාෆ් සංව වාක්ය (නිස්තූරිත පාළුවක්) සහ එයාගේ ග්\u200dරාෆ් එක්ක, අපි සම්බන්ධතාවක් සම්බන්ධතාවක් නිර්මාණය කරන්න සම්බන්ධතාවක් ප්\u200dරතිනිධානය කරන්න ප්\u200dරත ප්\u200dරතිචාර සම්බන්ධ වාක්ය සම්බන්ධ වාක්ය සම්බන්ධ විධානය සම්බන්ධ විධානය සම්බන්ධ විධානය සඳහා සම්බන්ධ විධානය සඳහ Name තවත්, අපි පෙන්වන්න පුළුවන් වෙනස් කාමරයක් ඉගෙන ගන්න පුළුවන් කියලා, ආයෙත් ප්\u200dරතික්\u200dරියාත්මක ඉගෙන ගන්න අරමුණක් භාවිත කරන්න, සහ ප', 'ta': 'Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited.  இந்த காகிதத்தில், நாம் ஒரு புதிய மாற்று கற்றுக்கொள்ளும் சட்டத்தை பரிந்துரைக்கிறோம். இது வாக்கியத்தை உள்ளிடுகிறது, வரைபட ஒரு வாக்கியத்தை (அடிப்படைக்கப்படாத உரை) மற்றும் அதன் வரைபடம் கொண்டு, நாம் தொடர்புடைய கட்டுப்பாட்டை தொடர்புடைய கட்டுப்பாட்டை குறிப்பிட்ட சொல்லின் குறிப்பு நி @ info: whatsthis TSNE ஆராய்ச்சியால் கூடுதல் பார்வைப்பு அடிப்படைக்கோடுகளுக்கு ஒப்பிடும் கற்ற குறிப்பிட்ட இடங்களின் விளை மேலும், நாம் பெயரிடப்பட்ட பொருள் அடையாளத்திற்கு வேறு இடத்தை கற்றுக் கொள்ள முடியும் என்பதை காட்டுகிறோம். மீண்டும் ஒரு முறையான கற்றுக் கொள்ள', 'ur': 'Though language model embedding has revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. اس کاغذ میں، ہم ایک نئی مخالف تعلیم کا فرم پیشنهاد کرتے ہیں جو ایک گراف ساختاری میں رابطہ کا کوڈ کرنا چاہتا ہے. اور اس کے گراف کے مطابق ایک جماعت (غیر ساختہ متن) اور اس کے گراف سے، ہم مخالف تعلیم کا استعمال کرتے ہیں کہ ہم ایک CharacterBERT (El Boukkouri et al., 2020) موڈل کے ساتھ حاصل ہونے والی جماعت کے ٹوکین سطح کے معاملات پر رابطہ تختہ مقرر کریں۔ نتیجہ کا ارتباط معلوم ہونے والی جماعت ایمبڈینگ ایک ساده KNN کلاسیر کے مطابق ارتباط اٹھانے والی کام پر موجود ہوتا ہے، اس کے ذریعہ سے پیش کیا گیا طریقہ کا موفقیت دکھاتا ہے. ٹی سی ان کی تحلیل کے ذریعے اضافہ ویزیزیزی کے ذریعے سیکھا ہوا نمایش جگہ کے مطابق بنسس لین کے مقابلہ میں ثابت قدم دکھاتا ہے. اور ہم نشان دیتے ہیں کہ ہم ایک ایست کی شناسایی کے لئے ایک مختلف جگہ سیکھ سکتے ہیں، دوبارہ مختلف تعلیم کا موضوع استعمال کرتا ہے، اور نشان دیتے ہیں کہ ان دونوں نمایش جگہ کو کس طرح ایک ایست کی نسبت کے کام میں مکمل کرنا ہے۔', 'vi': 'Mặc dù việc ghép văn bản mô hình ngôn ngữ đã cách mạng hóa nghiên cứu ngôn ngữ, nhưng khả năng thu thập thông tin ngữ pháp cấp cao, như quan hệ giữa các tổ chức trong văn bản, rất hạn chế. Trong tờ giấy này, chúng tôi đề xuất một cơ sở học tương đối mới, để rèn luyện câu chữ để mã hóa các quan hệ trong một cấu trúc đồ thị. Dựa vào một câu nói (văn bản không xây dựng) và đồ thị của nó, chúng tôi dùng học tương đối để áp đặt các cấu trúc tương quan trên các biểu tượng hình biểu tượng trên biểu tượng tượng tượng tượng tượng biểu tượng trên các chữ ký được lấy bằng mô hình Kí tự (El Boukkouri et al., 2020). Kết quả nhận dạng kết quả của việc ghép câu có kết quả tối tân về nhiệm vụ khai thác mối quan hệ chỉ với một người phân loại KNN đơn giản, bằng cách chứng minh thành công của phương pháp được đề nghị. Sự mường tượng thêm dựa trên một phân tích TSNE cho thấy hiệu quả của khoảng đại diện học so với các đường cơ bản. Hơn nữa, chúng tôi cho thấy chúng tôi có thể học một không gian khác cho việc nhận dạng thực thể tên, lần nữa sử dụng một mục tiêu học tương đối, và chứng minh cách kết hợp cả hai không gian đại diện thành công trong một nhiệm vụ liên hệ thực thể.', 'uz': "Agar tillar modeli matnning chegarasi NLP tafsilotlarini revolutionary qiladi, ularning eng darajada semantik maʼlumotini qabul qilish imkoniyatini, matnning butunlay bogʻlamalari juda chegara. Bu qogʻozda, biz murakkablarni grafik strukturedagi murakkablarini kodlash uchun o'rganish qatlamni o'rganish uchun qoʻllanmalarni tahrirlash. Bu so'z (tuzililgan matn) va grafik bilan, biz murojaat bilan bogʻliq tuzuvchi tuzuvni o'rganishni foydalanamiz va bir harf BERT (El Boukkouri et al., 2020) modeli bilan keladigan so'zning signal darajadagi tashkilotlarini qo'llashga ishlatamiz. Name Name Ko'rib chiqqamiz, biz tashkilotni tasdiqlash uchun boshqa joyni o'rganishingiz mumkin, yana boshqa o'rganishni o'rganish mumkin va ikkita tashkilotning joylarini muvaffaqiyatli birlashtirishni ko'rsatishimiz mumkin.", 'da': 'Selvom indlejringer af sprogmodeller har revolutioneret NLP-forskningen, er deres evne til at fange semantisk information på højt niveau, såsom relationer mellem entiteter i tekst, begrænset. I denne artikel foreslår vi en ny kontrastiv læringsramme, der træner sætninger indlejringer til at kode relationerne i en grafstruktur. Med en sætning (ustruktureret tekst) og dens graf bruger vi kontrastiv læring til at pålægge relationsrelateret struktur på symbolniveau repræsentationer af sætningen opnået med en CharacterBERT (El Boukkouri et al., 2020)-model. De resulterende relationsbevidste sætningsindlejringer opnår state-of-the-art resultater på relationsudvindingsopgaven ved hjælp af kun en simpel KNN-klassifikation, hvilket viser succesen med den foreslåede metode. Yderligere visualisering ved hjælp af en tSNE-analyse viser effektiviteten af det lærte repræsentationsrum sammenlignet med basislinjerne. Desuden viser vi, at vi kan lære et andet rum for navngivet entitetsgenkendelse, igen ved hjælp af et kontrastivt læringsmål, og demonstrere, hvordan vi med succes kombinerer begge repræsentationsrum i en entitetsrelation opgave.', 'bg': 'Въпреки че вграждането на текстови модели на езика революционизира изследванията на НЛП, способността им да улавят семантична информация на високо ниво, като например отношенията между субектите в текста, е ограничена. В настоящата статия предлагаме нова контрастна учебна рамка, която тренира вграждането на изречения за кодиране на отношенията в графична структура. Като се има предвид изречение (неструктуриран текст) и неговата графика, използваме контрастивно обучение, за да наложим структура, свързана с връзката, върху символните изображения на изречението, получено по модела на CharacterBERT (El Boukkuri et al., 2020). Получените релационни вграждания на изречения постигат най-съвременни резултати по задачата за извличане на релации, използвайки само прост класификатор, като по този начин демонстрират успеха на предложения метод. Допълнителната визуализация чрез анализ показва ефективността на наученото пространство за представяне в сравнение с базовите линии. Освен това, ние показваме, че можем да научим различно пространство за разпознаване на имената на субекти, отново използвайки контрастна учебна цел, и демонстрираме как успешно да комбинираме двете представителни пространства в задача за връзка между субекти.', 'hr': 'Iako su integracije teksta jezičkih modela revolucionirale istraživanje NLP-a, njihova sposobnost uhvatiti semantičke informacije na visokoj razini, poput odnosa između entitata u tekstu, ograničena je. U ovom papiru predlažemo novi kontrastivni okvir učenja koji trenira uvođenje kazne za kodiranje odnosa u grafskoj strukturi. S obzirom na rečenicu (neostrukturni tekst) i njegov grafik, koristimo kontrastno učenje kako bi stavili strukturu vezane s odnosima na predstavljanje razine znakova rečenice dobijene s model CharacterBERT (El Boukkouri et al., 2020). U rezultatima uvođenja rečenica svjesnog odnosa postigne rezultate stanja umjetnosti na zadatku izvlačenja odnosa koristeći samo jednostavnu klasifikatoru KNN-a, tako pokazujući uspjeh predložene metode. Dodatna vizualizacija analiza tSNE pokazuje učinkovitost učenog prostora zastupanja u usporedbi s početnim linijama. Nadalje, pokazujemo da možemo naučiti drugačiji prostor za priznanje imena entiteta, ponovno koristeći kontrastveni cilj učenja, i pokazati kako uspješno kombinirati oba prostora predstavljanja u zadatku vezano za entitet.', 'de': 'Obwohl Sprachmodelltexteinbettungen die NLP-Forschung revolutioniert haben, ist ihre Fähigkeit, hochrangige semantische Informationen wie Beziehungen zwischen Entitäten im Text zu erfassen, begrenzt. In diesem Beitrag schlagen wir ein neuartiges kontrastives Lernframework vor, das Satzbedeckungen trainiert, um die Beziehungen in einer Graphstruktur zu kodieren. Anhand eines Satzes (unstrukturierter Text) und seines Graphen verwenden wir kontrastives Lernen, um auf der Tokenebene Repräsentationen des Satzes, der mit einem CharacterBERT-Modell (El Boukkouri et al., 2020) erhalten wurde, eine relationsbezogene Struktur aufzuzwingen. Die resultierenden relationsbewussten Satzbedlungen erzielen mit nur einem einfachen KNN-Klassifikator aktuelle Ergebnisse bei der Beziehungsextraktionsaufgabe und belegen damit den Erfolg der vorgeschlagenen Methode. Zusätzliche Visualisierung durch eine tSNE-Analyse zeigt die Effektivität des erlernten Repräsentationsraums im Vergleich zu Baselines. Darüber hinaus zeigen wir, dass wir einen anderen Raum für die Erkennung benannter Entitäten erlernen können, wieder mit einem kontrastiven Lernziel, und zeigen, wie man beide Repräsentationsräume erfolgreich in einer Entitäten-Relation Aufgabe kombinieren kann.', 'ko': '언어 모델의 텍스트 삽입은 자연 언어 처리에 대한 연구를 철저히 변화시켰지만 고급 의미 정보를 포획하는 능력에 한계가 있다. 예를 들어 텍스트의 실체 간의 관계이다.본고에서 우리는 새로운 대비 학습 프레임워크를 제시했다. 이 프레임워크는 문장을 삽입하여 도형 구조의 관계를 인코딩하는 훈련을 한다.문장(비구조화된 텍스트)과 그 도형을 지정하고CharacterBERT(El Boukkkouriet al., 2020) 모델에서 얻은 문장 표기급 표시에 관계 관련 구조를 비교 학습한다.이로 인해 발생하는 관계 감지 문장 삽입은 간단한 KNN 분류기 하나만 사용하면 관계 추출 작업에서 가장 선진적인 결과를 얻을 수 있어 제시한 방법의 성공을 증명했다.tSNE 분석의 추가 시각화 디스플레이를 통해 기선에 비해 배운 표시 공간이 효과적이다.그 밖에 우리는 서로 다른 명칭의 실체 식별 공간을 배우고 비교 학습 목표를 다시 사용할 수 있으며 실체 관계 임무에서 이 두 표현 공간을 어떻게 성공적으로 결합시키는지 보여주었다.', 'id': 'Meskipun masukan teks model bahasa telah revolusi penelitian NLP, kemampuan mereka untuk menangkap informasi semantis tinggi, seperti hubungan antara entitas dalam teks, terbatas. Dalam kertas ini, kami mengusulkan rangkaian pembelajaran kontras yang baru yang melatih pembangunan kalimat untuk mengkode hubungan dalam struktur grafik. Mengingat kalimat (teks tidak struktur) dan grafiknya, kami menggunakan belajar kontras untuk memaksa struktur berkaitan hubungan pada perwakilan tingkat token kalimat yang diperoleh dengan model CharacterBERT (El Boukkouri et al., 2020). Penampilan kalimat yang berasal dari hubungan yang sadar mencapai hasil terbaik pada tugas ekstraksi hubungan hanya menggunakan klasifikasi KNN sederhana, dengan demikian menunjukkan sukses dari metode yang diusulkan. Visualisasi tambahan oleh analisis tSNE menunjukkan efektivitas ruang representation belajar dibandingkan dengan garis dasar. Selain itu, kita menunjukkan bahwa kita dapat belajar ruang yang berbeda untuk pengenalan entitas bernama, lagi menggunakan tujuan belajar kontras, dan menunjukkan bagaimana untuk sukses menggabungkan kedua ruang perwakilan dalam tugas hubungan entitas.', 'nl': 'Hoewel het inbedden van tekst in taalmodellen het NLP-onderzoek revolutionair heeft gemaakt, is hun vermogen om semantische informatie op hoog niveau vast te leggen, zoals relaties tussen entiteiten in tekst, beperkt. In dit artikel stellen we een nieuw contrastief leerkader voor dat zinsinsluitingen traint om de relaties in een grafiekstructuur te coderen. Gezien een zin (ongestructureerde tekst) en de grafiek ervan, gebruiken we contrastief leren om relatiegerelateerde structuur op te leggen op de tokenniveau representaties van de zin verkregen met een CharacterBERT (El Boukkouri et al., 2020) model. De resulterende relatiebewuste zinsinbeddingen bereiken state-of-the-art resultaten op de relatiebetrekkingstaak met slechts een eenvoudige KNN classificator, waardoor het succes van de voorgestelde methode wordt aangetoond. Aanvullende visualisatie door een tSNE analyse toont de effectiviteit van de geleerde representatieruimte ten opzichte van basislijnen. Verder tonen we aan dat we een andere ruimte kunnen leren voor naamsbekendheid, opnieuw met behulp van een contrastief leerdoel, en demonstreren we hoe we beide representatieruimtes succesvol kunnen combineren in een entiteit-relatie taak.', 'sw': 'Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited.  Katika gazeti hili, tunapendekeza mfumo wa kujifunza wa riwaya wenye utata ambao unafundisha hukumu inaingia ili kuingiza mahusiano katika muundo wa picha. Kutokana na hukumu (maandishi yasiyotengenezwa) na picha yake, tunatumia kujifunza tofauti ili kuweka muundo wa mahusiano katika kiwango cha alama cha uwakilishi wa hukumu iliyopatikana na mfumo wa CharacterBERT (El Boukkouri et al., 2020). Hukumu inayotokana na maarifa yanayotokana na uhusiano unaleta matokeo ya hali ya sanaa juu ya kazi ya utekelezaji kwa kutumia mchangazaji rahisi wa KNN, kwa hiyo inaonyesha mafanikio ya njia ya pendekezo. Uonyesho wa ziada na uchambuzi wa tSNE unaonyesha ufanisi wa nafasi ya uwakilishaji wa elimu ukilinganishwa na misingi ya msingi. Zaidi ya hayo, tunaonyesha kwamba tunaweza kujifunza nafasi tofauti kwa jina la kutambua entity, kwa mara nyingine kwa kutumia lengo la kujifunza linalopingana, na kuonyesha namna ya kuunganisha nafasi zote za uwakilishi katika kazi ya uhusiano wa entity.', 'tr': 'Dil nusgasy metin gabdalyklary NLP araştyrmasyny rewolusiýarlapdyr. Olaryň ýokary dereje semantik maglumatlaryny, metin bilen gabdalyklaryň arasyndaky baglaýyşlary çykaryp bardyr. Bu kagyzda biz grafik düzümlerini kodlamak üçin sözlemi doldurýan täze bir nusgatly öwrenme çerçevesini teklip edýäris. Sözlemiň (düzgünsiz metin) we grafynyň görä, syýasy bilen baglanyşyk düzgünlerini karakterBERT (El Boukkouri et al., 2020) nusgasyna düzenlemek üçin kontrast öwrenmegi ullanýarys. netijäki görnüş-bilinç sözleriň içine-de-sungat netijesi diňe KNN klasifikatyny ulanan ýagdaýyň durumyny tapylýar, şol sebäpli teklip eden täblisiniň üstesini görkezip. tSNE analizi tarapyndan öwrenmiş temel alanlaryň basit hatlaryla karşılaştyrylygyny görkez. Munuň üçin birnäçe hedef tanamak üçin üýtgeşik ýeri öwrenip biljegimizi görkezip, bir gezek täsirli öwrenmek maksadyny ulanyp, we munuň hem birnäçe üýtgeşik ýerlerini birbirine gatnaşmagyny görkezip bileris.', 'fa': 'اگرچه پیوند متن مدل زبانی تحقیقات NLP را انقلاب کرده است، توانایی آنها برای گرفتن اطلاعات semantic طبقه بالا، مانند رابطه بین واحدهای متن محدود است. در این کاغذ، ما یک چهارچوب یادگیری جدید متفاوتی را پیشنهاد می\u200cکنیم که جمله\u200cها را آموزش می\u200cدهد تا رابطه\u200cها را در یک ساختار گراف رمز کند. با توجه به یک جمله (متن غیر ساخته شده) و گرافش، ما از یادگیری متفاوتی استفاده می\u200cکنیم تا ساختار ارتباط با ارتباط بر نمایش سطح نشانه\u200cهای جمله\u200cای که با یک مدل CharacterBERT (El Boukkouri et al., 2020) گرفته شده استفاده کنیم. در نتیجه مجازات آگاهی با ارتباط، نتیجه\u200cهای وضعیت هنری بر روی کار خارج کردن ارتباط با استفاده از فقط یک گروه\u200cکننده KNN ساده می\u200cرسد، به این دلیل موفقیت روش پیشنهاد را نشان می\u200cدهد. تصویری اضافه توسط تحلیل tSNE فعالیت فضای نمایش یاد گرفته را در مقایسه با خطوط پایین نشان می دهد. علاوه بر این، نشان می دهیم که می توانیم فضای متفاوتی را برای شناسایی عنوان entity یاد بگیریم، دوباره با استفاده از هدف یادگیری متفاوتی، و نشان می دهیم چگونه با موفقیت هر دو فضای نمایش را در یک وظیفه ارتباط با entities combinat کنیم.', 'sq': 'Ndonse përfshirjet e tekstit të modelit gjuhësor kanë revolucionuar kërkimin e NLP, aftësia e tyre për të kapur informacion semantik të nivelit të lartë, të tillë si marrëdhëniet midis njësive në tekst, është e kufizuar. In this paper, we propose a novel contrastive learning framework that trains sentence embeddings to encode the relations in a graph structure.  Duke pasur parasysh një fjali (tekst të papërstrukturuar) dhe grafikun e saj, ne përdorim mësimin kontrastues për të imponuar strukturën lidhur me marrëdhëniet në përfaqësimet e nivelit të token të dënimit të fituar me një model CharacterBERT (El Boukkouri et al., 2020). Ndërtesat e fjalëve të lidhura me lidhjen me të cilat arrijnë rezultate më të larta në detyrën e nxjerrjes së lidhjes duke përdorur vetëm një klasifikues të thjeshtë KNN, duke demonstruar kështu suksesin e metodës së propozuar. Vizualizimi shtesë nga një analizë tSNE tregon efektshmërinë e hapësirës së përfaqësimit të mësuar krahasuar me linjat bazë. Përveç kësaj, ne tregojmë se mund të mësojmë një hapësirë tjetër për njohjen e emëruar të njësisë, përsëri duke përdorur një objektiv të mësimit kontrastues dhe të demonstrojmë si të kombinojmë me sukses të dy hapësirat përfaqësuese në një detyrë lidhje me njësi.', 'am': 'የቋንቋ ምሳሌ የጽሑፍ ጥያቄ የNLP ምርመራ ቢደረጉ ግን የደረጃውን የsemantic መረጃ ማግኘት ሥልጣን እንደ አካባቢዎች በጽሑፍ ውስጥ ግንኙነት ግንኙነት ግልፅ ነው፡፡ በዚህ ፕሮግራም፣ የውይይት ግንኙነትን በgraph አካባቢ ውስጥ ለማክበር የሚያስተምረን የመረጃ ፍሬም እናሳውቃለን፡፡ የጽሑፍ (የጽሑፍ መክፈት) እና ቀረፋው በተደረገ ጊዜ፣ የግንኙነት ግንኙነት የደረጃ ግንኙነት አካባቢ እናደርጋለን፡፡ የግንኙነት ግንኙነት የሚታወቀው ግንኙነት የ-የ-የ-የ-አርእስት ውጤቶች በተቀናቀለ KNN ክፍል ብቻ ይደረጋል፡፡ TSNE-analysis በተማሩት የአስተማሪነ ስፍራን ከመቀመጫው ጋር የተማረ ጥያቄ ያሳያል፡፡ በተጨማሪም፣ አካባቢ ማወቅ የተለየውን ቦታ እናሳያቸዋለን፣ ደግሞም በተቃዋሚ ትምህርት አካባቢ እና ሁለትን ቦታዎች እንዴት ማቀናቀል እናሳያቸዋለን፡፡', 'af': "Alhoewel taal model teks inbêding het revolusioneer NLP-ondersoek, is hulle moontlik om hoë vlak semantiese inligting te vang, soos verhouding tussen entiteite in teks, beperk. In hierdie papier, voorstel ons 'n roman kontrastiewe leer raamwerk wat trein sin inbettings om die verwantings in 'n graafstruktuur te kodeer. Omdat ons 'n seting (ongestruktureerde teks) en sy graaf gebruik, gebruik ons kontrastiewe leer om relasie-verwante struktuur op die token vlak voorstellings van die seting wat met 'n KarakterBERT (El Boukkouri et al., 2020) ontvang word. Die resulteerde verwanting- awarene setinge inbettings bereik state- of- the- art resultate op die verwanting uittrekking taak gebruik slegs 'n eenvoudige KNN klassifiseerder, daarom vertoon die sukses van die voorgestelde metode. Addisionele visualisering deur 'n tSNE analiseer vertoon die effektiviteit van die leer verteenwoordigheidspasie vergelyk met baselyn. Ons wys ook dat ons 'n ander spasie kan leer vir genoem entiteiterkenning, weer gebruik 'n kontrastiewe leer objek en wys hoe om beide verteenwoordingsspasies suksesvol in 'n entiteitverwanting taak te kombinerer.", 'hy': 'Չնայած լեզվի մոդելի տեքստի ներդրումը հեղափոխել է ՆԼՊ հետազոտությունը, նրանց կարողությունը վերցնել բարձր մակարդակի սեմանտիկ տեղեկատվություն, ինչպիսիք են տեքստի կազմակերպությունների միջև հարաբերությունները, սահմանափակ է Այս թղթի մեջ մենք առաջարկում ենք նոր հակադրական ուսումնական շրջանակ, որը սովորեցնում է նախադասությունների ներդրումներ գրաֆիկի կառուցվածքի հարաբերությունների կոդավորման համար: Եթե հաշվի առնենք նախադասությունը (անկառուցված տեքստը) և դրա գրաֆիկը, մենք օգտագործում ենք հակադրական ուսումնասիրությունը հարաբերություններին կապված կառուցվածքի պարտադրելու համար նախադասության նշանների մակարդակի ներկայացումների վրա, որոնք ստացվել են Սիմպտեր Բե Արդյունքում ստացված հարաբերություններով գիտակցած նախադասությունների ներդրումները հասնում են հարաբերությունների վերացման հանձնարարության ամենաբարձր արդյունքներին, օգտագործելով միայն մի պարզ KnN դասակարգիչ, ինչը ցույց է տալիս առաջարկված մեթոդի հաջողությունը: Ավելի վիզուալիզացիա tCNE-ի վերլուծության միջոցով ցույց է տալիս սովորված ներկայացման տարածության արդյունավետությունը համեմատած հիմնական գծերի հետ: Ավելին, մենք ցույց ենք տալիս, որ մենք կարող ենք սովորել տարածք անվանված էության ճանաչելու համար, կրկին օգտագործելով հակադրական ուսումնական նպատակ, և ցույց տալ, թե ինչպես հաջողությամբ համադրել երկու ներկայացման տարածքները էության-հարաբերության խնդրում:', 'az': 'Dil modeli metin in şalları NLP araştırmalarını dəyişmiş olsa da, onların yüksək seviyyətli semantik məlumatlarını, mətndə məlumatlar arasındakı ilişkiler, müəyyən edilmişdir. Bu kağızda, biz yeni müxtəlif öyrənmə framework ünü təklif edirik ki, cümlələri grafik strukturlarında kodlamaq üçün yayılır. Bir cümlənin və onun grafəsinə görə, əlaqələri ilə əlaqələri ilə olan cümlənin göstərilməsi üçün müxtəlif öyrənməyi kullanırıq. Növbəti bağlı cümlələrdən xəbərdar edilən cümlələr istifadə edilən sadəcə KNN klasifikatçısını istifadə edərək, təklif olunan metodun başarısızlığını göstərən mümkün olaraq əlaqələr qovuşduğu müxtəlif sonuçlarına yetişir. TSNE analizi tərəfindən artıq vizualizasyon öyrəndiyi göstərilmə alanının əsas sətirlərlə qarşılaşdığı faydallığını göstərir. Daha sonra, biz indiklərin tanıması üçün başqa bir yer öyrənə bilərik, yenidən müxtəlif öyrənmə məqsədilə istifadə edərək və hər ikisinin təşkil etmə məqsədilə müvəffəqiyyəti ilə birləşdirilməsini göstərərik.', 'bn': 'যদিও ভাষার মডেলের টেক্সট বিপ্লবে এনএলপি গবেষণা বিপ্লব করেছে, তাদের ক্ষমতা উচ্চ স্তরের সেম্পেন্টিক তথ্য ধরার, যেমন লেখায় বস্তুর মধ্যে  এই কাগজটিতে আমরা একটি উপন্যাসের বিরোধী শিক্ষা ফ্রেমের প্রস্তাব করি যেটি গ্রাফ কাঠামোর সম্পর্ক এনকোড করার প্রশিক্ষণ প্রদান করে। একটি শাস্তি এবং তার গ্রাফের মাধ্যমে আমরা বিরোধী শিক্ষা ব্যবহার করি একটি চার্কার্টার বার্তা (এল বুকুরি এবং আল, ২০২০) মডেলের মাধ্যমে পেয়েছিলাম যে বাক্যের প্রতিনিধিত্ এর ফলে সম্পর্ক-সচেতনতার বাক্যে প্রস্তাবিত পদ্ধতির সাফল্য প্রদান করা হয়েছে যে সম্পর্ক বের করার ফলাফল শুধুমাত্র একটি সাধারণ কেএনএন ক্লাসিফারার ব্যবহার করে,  টিএসএনএন বিশ্লেষণের মাধ্যমে আরও দৃষ্টিভঙ্গি প্রদর্শন করা হয়েছে বেসেলাইনের তুলনায় শিক্ষিত প্রতিনিধিত্বের স্থান এছাড়াও, আমরা দেখাচ্ছি যে আমরা পৃথিবীর নামের স্বীকৃতির জন্য একটি ভিন্ন জায়গা শিখতে পারি, আবার একটি বিরোধী শিক্ষা উদ্দেশ্য ব্যবহার করতে পারি, আর প্রদর্শন করি', 'bs': 'Iako su integracije teksta jezika revolucionisale istraživanje NLP-a, njihova sposobnost uhvatiti semantičke informacije na visokom nivou, poput odnosa između entitata u tekstu, ograničena je. U ovom papiru predlažemo novi kontrastivni okvir učenja koji trenira uvođenje kazne za kodiranje odnosa u grafskoj strukturi. S obzirom na rečenicu (neostrukturni tekst) i njegov grafik, koristimo kontrastivno učenje kako bi stavili strukturu povezanu s odnosima na predstavljanje razine znakova rečenice dobijene sa modelom CharacterBERT (El Boukkouri et al., 2020). Rezultati uvođenja rečenica svjesne veze postignu rezultate stanja umjetnosti na zadatku izvlačenja veza koristeći samo jednostavnu klasifikatoru KNN, tako da pokazuju uspjeh predložene metode. Dodatna vizualizacija analiza tSNE pokazuje učinkovitost učenog prostora zastupanja u usporedbi s početnim linijama. Osim toga, pokazujemo da možemo naučiti drugačiji prostor za priznanje entiteta, ponovo koristeći kontrastni cilj učenja, i pokazati kako uspješno kombinirati oba prostora predstavljanja u zadatku vezano za entitet.', 'ca': "Encara que les incorporacions de textos del model lingüístic han revolucionat la recerca de la NLP, la seva capacitat de capturar informació semàntica d'alt nivell, com les relacions entre entitats en text, és limitada. En aquest paper, proposem un nou marc d'aprenentatge contrastiu que entrena incorporacions de frases per codificar les relacions en una estructura de gràfic. Tenint en compte una frase (text no estructurat) i el seu gràfic, utilitzem l'aprenentatge contrastiu per imposar estructura relacionada amb la relació a les representacions de nivell de fitxes de la frase obtenida amb un model CharacterBERT (El Boukkouri et al., 2020). Les incorporacions de frases conscients de la relació obtenen resultats més avançats en la tasca d'extracció de la relació només fent servir un classificador KNN senzill, demostrant així l'èxit del mètode proposat. La visualització adicional per l'anàlisi tSNE mostra l'eficacia de l'espai de representació aprenent comparat amb les línies de base. A més, demostram que podem aprendre un espai diferent per al reconeixement d'entitats anomenats, utilitzant un objectiu d'aprenentatge contrastiu, i demostrar com combinar amb èxit ambdós espais de representació en una tasca relacionada entre entitats.", 'cs': 'Ačkoli vkládání textu do jazykových modelů revolučně způsobilo výzkum NLP, jejich schopnost zachytit sémantické informace na vysoké úrovni, jako jsou vztahy mezi entitami v textu, je omezená. V tomto článku navrhujeme nový kontrastní učební rámec, který trénuje vkládání vět k kódování vztahů do grafové struktury. Vzhledem k větě (nestrukturovanému textu) a jejímu grafu používáme kontrastní učení k vnucení vztahové struktury reprezentací věty získané pomocí modelu CharacterBERT (El Boukkouri et al., 2020). Výsledné vložení vět s větami, které jsou orientovány na vztahy, dosahuje nejmodernějších výsledků na úlohu extrakce vztahů pouze pomocí jednoduchého klasifikátoru KNN, čímž dokazuje úspěch navrhované metody. Další vizualizace pomocí tSNE analýzy ukazuje efektivitu naučeného reprezentačního prostoru ve srovnání s základními liniemi. Dále ukazujeme, že se můžeme naučit jiný prostor pro rozpoznávání pojmenovaných entit, opět pomocí kontrastivního učebního cíle, a ukázat, jak úspěšně kombinovat oba reprezentační prostory v úkolu entity-relace.', 'et': 'Kuigi keelemudelite teksti manustamine on uue õppeprogrammi uurimistööd revolutsiooniliseks muutnud, on nende võime jäädvustada kõrgetasemelist semantilist teavet, näiteks seoseid üksuste vahel tekstis piiratud. Käesolevas töös pakume välja uudse kontrastse õpperaamistiku, mis koolitab lausete manustamist, et kodeerida seoseid graafilises struktuuris. Arvestades lauset (struktureerimata tekst) ja selle graafikut, kasutame kontrastiivset õpet, et kehtestada seosega seotud struktuur CharacterBERT (El Boukkouri et al., 2020) mudeli abil saadud lause märgitasemel esitustele. Sellest tulenevad seosteadlikud laused saavutavad seose ekstraheerimise ülesandes kaasaegsed tulemused, kasutades ainult lihtsat KNN klassifikaatorit, näidates seeläbi kavandatud meetodi edukust. Täiendav visualiseerimine tSNE analüüsi abil näitab õppitud esindusruumi efektiivsust võrreldes lähtejoontega. Lisaks näitame, et saame õppida erinevat ruumi nimetatud olemi tuvastamiseks, kasutades taas kontrastiivset õppeeesmärki, ja näidata, kuidas edukalt kombineerida mõlemad esindusruumid olemi-suhte ülesandes.', 'fi': 'Vaikka kielimallien tekstiupotukset ovat mullistaneet NLP:n tutkimuksen, niiden kyky tallentaa korkean tason semanttista tietoa, kuten entiteettien välisiä suhteita tekstissä, on rajallinen. Tässä työssä ehdotamme uutta kontrastiivista oppimiskehystä, joka kouluttaa lauseiden upottamista kuvaajarakenteen suhteiden koodaamiseksi. Kun otetaan huomioon lause (strukturoimaton teksti) ja sen kaavio, käytämme kontrastiivista oppimista pakottaaksemme suhteeseen liittyvän rakenteen lauseen symbolitason representaatioihin, jotka on saatu CharacterBERT (El Boukkouri et al., 2020) -mallilla. Tuloksena saadut relaatiotietoiset lauseupotukset saavuttavat viimeisimpiä tuloksia relaatiouuttotehtävässä käyttämällä vain yksinkertaista KNN-luokitusta, mikä osoittaa ehdotetun menetelmän onnistumisen. Lisävisualisointi tSNE-analyysin avulla osoittaa opitun esitystilan tehokkuuden suhteessa lähtölinjoihin. Lisäksi osoitamme, että voimme oppia erilaisen tilan nimetylle entiteetintunnistukselle käyttämällä jälleen kontrastiivista oppimistavoitetta, ja osoittaa, miten onnistutaan yhdistämään molemmat representaatiotilat entiteettisuhdetehtävässä.', 'sk': 'Čeprav so vgradnje besedila jezikovnih modelov revolucionarno spremenile raziskave NLP, je njihova sposobnost zajemanja semantičnih informacij na visoki ravni, kot so odnosi med entitetami v besedilu, omejena. V prispevku predlagamo nov kontrastni učni okvir, ki trenira vdelave stavkov za kodiranje relacij v grafski strukturi. Glede na stavek (nestrukturirano besedilo) in njegov graf uporabljamo kontrastno učenje za uvedbo strukture, povezane z odnosom, na predstavitve stavka na ravni žetonov, pridobljenega z modelom CharacterBERT (El Boukkouri et al., 2020). Nastale vgradnje stavkov, ki se zavedajo odnosov, dosežejo najsodobnejše rezultate pri opravilu ekstrakcije odnosov z uporabo samo preprostega klasifikatorja KNN in s tem dokazujejo uspeh predlagane metode. Dodatna vizualizacija z analizo tSNE kaže učinkovitost učenega reprezentativnega prostora v primerjavi z osnovnimi črtami. Poleg tega pokažemo, da se lahko naučimo drugačnega prostora za prepoznavanje imenovanih entitet, ponovno z uporabo kontrastnega učnega cilja, in pokažemo, kako uspešno združiti oba reprezentativna prostora v nalogi entitete-odnosa.', 'he': 'למרות שפת מודל טקסט הופך מחקר NLP למהפכה, היכולת שלהם לתפוס מידע סמנטי ברמה גבוהה, כמו יחסים בין יחסים בטקסט, מוגבלת. בעיתון הזה, אנו מציעים מסגרת לימוד נוספת בניגוד לאימונים משפטים מקדמות כדי לקוד את היחסים במבנה גרף. בהתחשב במשפט (טקסט לא מבושל) והגרף שלו, אנו משתמשים בהלימוד נגד כדי להכריח מבנה קשור למערכת יחסים על רמת הסימנים של המשפט שנקבל עם מודל CharacterBERT (El Boukkouri et al., 2020). תוכניות המשפטים המודעות לקשר הנוצאות מגיעות לתוצאות מוקדמות על משימת החילוץ הקשר בשימוש רק מסווג KNN פשוט, כך להוכיח את הצלחה של השיטה המוצעת. ויזואליזציה נוספת על ידי ניתוח tSNE מראה את היעילות של מרחב היציגה הלמוד בהשוואה לקווים הבסיסים. בנוסף, אנחנו מראים שאנחנו יכולים ללמוד מרחב אחר לזהות ישויות בשם, שוב בשימוש מטרה למידה נוגדית, ולהראות כיצד לשלב בהצלחה את שני מרחבי מייצג במשימה יחסי יחסי ישויות.', 'jv': 'Display language model text Nang mapun iki, kita supoya ndherek kuwi nyumbang kelas kuwi padha uga luwih basa sing diranggawe barang nggawe barang seneng nggo nggawe barang seneng pisan graf. Genjer Refs Ngawe ngilanggar tarjamahan tS ne dipulusi sistem punika efek karo penting anyar mpulusi bangsane karo perusahaan bangsane Label', 'ha': "Ingawa da aka shigar da matsayin misalin harshe sun yi revolutiona research na NLP, ana ƙayyade abincinsu da za'a sami tsari ga babban-daraja, kamar da mazaɓa tsakanin abubuwa cikin matsayin. Ga wannan takardan, Munã ƙayyade wani firam mai iya motsi da aka sanar da shi na fasahar da aka shigar da azãba dõmin ya kodi da mazaɓa cikin tsarin grafi. Gida wata kalma (wanda ba'a samar da matsayin ba) da grafi, za mu yi amfani da fassarar kwamfyuta yin ƙidãya wa zane-danganta a kan matsayin alama da aka samu da misalin karatar BERT (El Boukkouri et al, 2020). Suna ƙara da filin da aka sani ya sami fassarar-the-art na sami matsalar wa aikin cire-abun da ke amfani da shi kawai mai sauƙi na KNN, kuma ya nuna babban rabo na zaɓen aikin da aka buƙata. KCharselect unicode block name Furan wannan, Munã nũna wa za mu iya sanar wani fili daban wa sunan ganin abun abun, an a yi amfani da abun da aka yi motsi, kuma Mu nuna yadda za mu sami duk filayen su da babban rabo a cikin wani aikin da aka yi danganta da shi.", 'bo': 'སྐད་ཡིག་གི་མ་དབྱིབས་ཡིག་གེ་གནས འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཚོར་བ་སྐྱེན་པའི་ལྟ་བུ ཚིག་ཡིག་དང་གྲངས་འབྲེལ་མེད་པའི་ཚིག དབྱིབས་འབྱུང་བའི་ཚིག་ཡིག་གནས་ཚུལ་གསལ་བཤད་པ tSNE་ཞིབ་གིས་མཐོང་སྣང་བ་མང་ཙམ་མང་ཆོས་ཡོད་པ་དེ་གིས་རྟོགས་པའི་བར་སྟོང་བ་དང་མཉམ་དུ་བསྡུར་ཡོད་པ Furthermore, we show that we can learn a different space for named entity recognition, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.'}
{'en': 'Pragmatic competence of pre-trained language models through the lens of discourse connectives', 'pt': 'Competência pragmática de modelos de linguagem pré-treinados através da lente dos conectivos discursivos', 'ar': 'الكفاءة البراغماتية لنماذج اللغة المدربة مسبقًا من خلال عدسة روابط الخطاب', 'es': 'Competencia pragmática de modelos lingüísticos previamente entrenados a través de la lente de los conectivos del discurso', 'fr': 'Compétence pragmatique de modèles linguistiques préformés à travers le prisme des connectives discursives', 'ja': '事前にトレーニングされた言語モデルの話し方のつながりのレンズを通じての実用的な能力', 'zh': '语接者镜头先训之实用也', 'hi': 'प्रवचन संयोजी के लेंस के माध्यम से पूर्व-प्रशिक्षित भाषा मॉडल की व्यावहारिक क्षमता', 'ru': 'Прагматическая компетентность предварительно обученных языковых моделей через объектив дискурсовых связующих', 'ga': 'Inniúlacht phragmatach samhlacha teanga réamhoilte trí lionsa na nascóirí dioscúrsa', 'hu': 'Előképzett nyelvi modellek gyakorlati kompetenciája a diskurzus kapcsolatok lencséjén keresztül', 'ka': 'პრაგმატიკური კომპექტირება წინატვირთებული ენის მოდელების პროგმატიკური კომპექტირება', 'el': 'Πραγματική ικανότητα των προ-εκπαιδευμένων γλωσσικών μοντέλων μέσα από το φακό των συνδετικών συζητήσεων', 'lt': 'Išankstinio mokymo kalbų modelių praktinė kompetencija naudojant diskursinių jungčių sklaidytuvą', 'mk': 'Прагматска надлежност на предобучените јазички модели преку линијата на дискурсните поврзувања', 'ms': 'Kompetensi pragmatik bagi model bahasa yang dilatih-dilatih melalui lensa sambungan diskors', 'ml': 'സംസാരിക്കുന്ന ബന്ധങ്ങളുടെ ലൈനുകളിലൂടെ മുന്\u200dപരിശീലന ഭാഷ മോഡലുകളുടെ പ്രാഗ്മാനിക് മാന്ത്രിക ഭാ', 'mt': 'Pragmatic competence of pre-trained language models through the lens of discourse connectives', 'mn': 'Өмнө сургалтын хэл загварын прагматик чадвар ярианы холбоотой холбоотой', 'no': 'Pragmatisk kompetanse for før- trengte språk- modeller gjennom lensen av diskurstilkoplingar', 'kk': 'Алдын- ала оқылған тіл үлгілерінің прагматикалық көмегімен дискурстар қосылымдарының линзі арқылы', 'pl': 'Kompetencje pragmatyczne wstępnie przeszkolonych modeli językowych przez soczewkę łączników dyskursu', 'ro': 'Competența practică a modelelor lingvistice pre-instruite prin lentilele conectivelor discursului', 'sr': 'Pragmatična kompetencija predobučenih jezičkih modela kroz lense diskurskih veza', 'so': 'Aqoonta aqoonta hore ee samooyinka afka hore lagu tababaray', 'si': 'ප්\u200dරාග්මතික භාෂාව ප්\u200dරධානයක් ප්\u200dරධාන භාෂාව මොඩේල්ස් වලින් කතාවක් සම්බන්ධයක් වලින්', 'sv': 'Praktisk kompetens hos färdigutbildade språkmodeller genom linsen av diskurskontakter', 'ta': 'முன் பயிற்சி மொழி மாதிரிகளின் பேச்சு இணைப்புகளின் மூலம் மூலம் பிரச்சனையான திறமை', 'ur': 'پیش آموزش کی زبان موڈل کی پراگرماتیک تعریف کی', 'it': 'Competenza pratica di modelli linguistici pre-formati attraverso la lente dei connettivi del discorso', 'uz': 'Name', 'vi': 'Quyền năng quái đản của các mô hình ngôn ngữ được đào tạo qua thấu kính của liên lạc.', 'nl': 'Pragmatische competentie van voorgetrainde taalmodellen door de lens van discoursverbinders', 'da': 'Praktisk kompetence af prætrænede sprogmodeller gennem linsen af diskursforbindelser', 'hr': 'Pragmatična kompetencija predobučenih jezičkih modela kroz lense diskurskih veza', 'de': 'Pragmatische Kompetenz von vortrainierten Sprachmodellen durch die Linse von Diskursverbindern', 'bg': 'Прагматична компетентност на предварително обучените езикови модели през обектива на дискурсните връзки', 'ko': '어편 연결어를 통해 미리 훈련된 언어 모델의 어용 능력을 보다', 'fa': 'تمرین پراگرماتیک مدل های پیش آموزش زبانی از طریق لینز ارتباطات صحبت', 'sw': 'Uwezekano wa mifano ya lugha zilizofunzwa kabla kupitia mistari ya mazungumzo yanayohusiana', 'tr': 'Diskurs baglaýyşlary tarapyndan öňünden eğlenen dil nusgalarynyň pragmatik ukyplygyny', 'sq': 'Pragmatic competence of pre-trained language models through the lens of discourse connectives', 'af': 'Name', 'am': 'በንግግር ግንኙነት ግንኙነት የቋንቋ ምሳሌዎችን ለመቀበል የስልጣዊ ግንኙነት', 'hy': 'Նախապատրաստված լեզվի մոդելների պրագմատիկ հմտությունները խոսակցային կապերի ոսպնյակի միջոցով', 'az': '√Ėn t…ôhsil edilmiŇü dil modell…ôrinin pragmatik qabiliyy…ôti diskurs bańülantńĪlarńĪ il…ô', 'id': 'Kompetensi pragmatis dari model bahasa pra-terlatih melalui lensa konektif diskors', 'bs': 'Pragmatična kompetencija predobučenih jezičkih modela kroz lense diskurskih veza', 'bn': 'পূর্ব প্রশিক্ষিত ভাষার মডেলের প্রাক্তনিক ক্ষমতা', 'fi': 'Esikoulutettujen kielimallien pragmaattinen osaaminen diskurssiyhteyksien linssin kautta', 'ca': 'La competència pragmàtica dels models de llenguatges pré-entrenats a través de la lent dels connexius de discurs', 'cs': 'Pragmatická kompetence předškolených jazykových modelů pomocí objektivu diskurzních konektivů', 'et': 'Eelkoolitud keelemudelite pragmaatiline pädevus diskursuse sidemete läätse kaudu', 'jv': 'Pak-perbudhakan pragatik karo model sing wis luwih akeh lanus', 'bo': 'Pragmatic competence of pre-trained language models through the lens of discourse connectives', 'sk': 'Pragmatična kompetenca predhodno usposobljenih jezikovnih modelov skozi lečo diskurznih povezav', 'ha': 'QScriptBreakpointsModel', 'he': 'כישור פרגמטי של דוגמני שפה מאומנים מראש דרך העדשה של קשרי דיבור'}
{'en': 'As pre-trained language models (LMs) continue to dominate  NLP , it is increasingly important that we understand the depth of language capabilities in these  models . In this paper, we target pre-trained LMs’ competence in  pragmatics , with a focus on  pragmatics  relating to discourse connectives. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from  psycholinguistics . We focus on testing  models ’ ability to use pragmatic cues to predict discourse connectives,  models ’ ability to understand implicatures relating to connectives, and the extent to which  models  show humanlike preferences regarding temporal dynamics of connectives. We find that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower. Models also do not show substantial humanlike temporal preferences. Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.', 'ar': 'مع استمرار هيمنة نماذج اللغة المدربة مسبقًا (LMs) على البرمجة اللغوية العصبية (NLP) ، من المهم بشكل متزايد أن نفهم عمق القدرات اللغوية في هذه النماذج. في هذه الورقة ، نستهدف كفاءة LM المدربين مسبقًا في البراغماتية ، مع التركيز على البراغماتية المتعلقة بروابط الخطاب. نقوم بصياغة اختبارات بأسلوب cloze باستخدام مزيج من البيانات التي تحدث بشكل طبيعي والمدخلات الخاضعة للرقابة المستمدة من علم اللغة النفسي. نحن نركز على اختبار قدرة النماذج على استخدام الإشارات البراغماتية للتنبؤ بروابط الخطاب ، وقدرة النماذج على فهم الآثار الضمنية المتعلقة بالروابط ، ومدى إظهار النماذج للتفضيلات البشرية فيما يتعلق بالديناميات الزمنية للوصلات. وجدنا أنه على الرغم من أن النماذج تتنبأ بوصلات جيدة بشكل معقول في سياق البيانات التي تحدث بشكل طبيعي ، عندما نتحكم في السياقات لعزل الإشارات البراغماتية عالية المستوى ، فإن حساسية النموذج تكون أقل بكثير. النماذج أيضًا لا تظهر تفضيلات زمنية كبيرة مثل الإنسان. بشكل عام ، تشير النتائج إلى أن نماذج ما قبل التدريب السائدة في الوقت الحالي لا تؤدي إلى كفاءة عملية كبيرة في نماذجنا.', 'pt': 'À medida que os modelos de linguagem pré-treinados (LMs) continuam a dominar a PNL, é cada vez mais importante que entendamos a profundidade dos recursos de linguagem nesses modelos. Neste artigo, visamos a competência de LMs pré-treinados em pragmática, com foco na pragmática relacionada aos conectivos do discurso. Formulamos testes no estilo cloze usando uma combinação de dados que ocorrem naturalmente e entradas controladas extraídas da psicolinguística. Nós nos concentramos em testar a capacidade dos modelos de usar pistas pragmáticas para prever os conectivos do discurso, a capacidade dos modelos de entender as implicaturas relacionadas aos conectivos e até que ponto os modelos mostram preferências humanas em relação à dinâmica temporal dos conectivos. Descobrimos que, embora os modelos prevejam conectivos razoavelmente bem no contexto de dados que ocorrem naturalmente, quando controlamos contextos para isolar pistas pragmáticas de alto nível, a sensibilidade do modelo é muito menor. Os modelos também não mostram preferências temporais substanciais semelhantes às humanas. No geral, os resultados sugerem que, atualmente, os paradigmas pré-treinamento dominantes não resultam em competência pragmática substancial em nossos modelos.', 'es': 'A medida que los modelos lingüísticos (LM) previamente entrenados siguen dominando la PNL, es cada vez más importante que comprendamos la profundidad de las capacidades lingüísticas de estos modelos. En este artículo, nos centramos en la competencia pragmática de los LM previamente entrenados, con un enfoque en la pragmática relacionada con los conectivos del discurso. Formulamos pruebas de estilo cloze utilizando una combinación de datos naturales e insumos controlados extraídos de la psicolingüística. Nos centramos en probar la capacidad de los modelos para usar señales pragmáticas para predecir los conectivos del discurso, la capacidad de los modelos para comprender las implicaciones relacionadas con los conectivos y el grado en que los modelos muestran preferencias similares a las humanas con respecto a la dinámica temporal de los conectivos. Descubrimos que, aunque los modelos predicen las conexiones razonablemente bien en el contexto de los datos naturales, cuando controlamos los contextos para aislar las señales pragmáticas de alto nivel, la sensibilidad del modelo es mucho menor. Los modelos tampoco muestran preferencias temporales sustanciales similares a las humanas. En general, los hallazgos sugieren que, en la actualidad, los paradigmas dominantes de preentrenamiento no dan como resultado una competencia pragmática sustancial en nuestros modelos.', 'fr': "Alors que les modèles linguistiques préformés (LM) continuent de dominer la PNL, il est de plus en plus important que nous comprenions la profondeur des capacités linguistiques de ces modèles. Dans cet article, nous ciblons la compétence des ML pré-formés en pragmatique, en mettant l'accent sur la pragmatique liée aux connectives du discours. Nous formulons des tests rapprochés en utilisant une combinaison de données naturelles et d'entrées contrôlées tirées de la psycholinguistique. Nous nous concentrons sur le test de la capacité des modèles à utiliser des indices pragmatiques pour prédire les connectifs du discours, la capacité des modèles à comprendre les implicatures relatives aux connectifs et la mesure dans laquelle les modèles montrent des préférences humaines en ce qui concerne la dynamique temporelle des connecteurs. Nous constatons que, bien que les modèles prédisent assez bien les connectives dans le contexte de données naturelles, lorsque nous contrôlons les contextes pour isoler des indices pragmatiques de haut niveau, la sensibilité du modèle est beaucoup plus faible. Les modèles ne montrent pas non plus de préférences temporelles substantielles de type humain. Dans l'ensemble, les résultats suggèrent qu'à l'heure actuelle, les paradigmes prédominants de pré-formation ne se traduisent pas par une compétence pragmatique substantielle dans nos modèles.", 'hi': 'जैसा कि पूर्व-प्रशिक्षित भाषा मॉडल (एलएम) एनएलपी पर हावी रहना जारी रखते हैं, यह तेजी से महत्वपूर्ण है कि हम इन मॉडलों में भाषा क्षमताओं की गहराई को समझें। इस पेपर में, हम पूर्व-प्रशिक्षित एलएम की क्षमता को व्यावहारिकता में लक्षित करते हैं, जिसमें प्रवचन संयोजी से संबंधित व्यावहारिकताओं पर ध्यान केंद्रित किया जाता है। हम स्वाभाविक रूप से होने वाले डेटा और साइकोलिंग्विस्टिक्स से खींचे गए नियंत्रित इनपुट के संयोजन का उपयोग करके क्लोज़-शैली परीक्षण तैयार करते हैं। हम परीक्षण मॉडल की क्षमता पर ध्यान केंद्रित करते हैं कि वे प्रवचन संयोजी की भविष्यवाणी करने के लिए व्यावहारिक संकेतों का उपयोग कर सकते हैं, संयोजी से संबंधित इंप्लीचर को समझने के लिए मॉडल की क्षमता, और जिस हद तक मॉडल संयोजी की अस्थायी गतिशीलता के बारे में मानवीय प्राथमिकताओं को दिखाते हैं। हम पाते हैं कि हालांकि मॉडल स्वाभाविक रूप से होने वाले डेटा के संदर्भ में संयोजी की भविष्यवाणी करते हैं, जब हम उच्च-स्तरीय व्यावहारिक संकेतों को अलग करने के लिए संदर्भों को नियंत्रित करते हैं, तो मॉडल संवेदनशीलता बहुत कम होती है। मॉडल भी पर्याप्त मानवीय अस्थायी प्राथमिकताओं को नहीं दिखाते हैं। कुल मिलाकर, निष्कर्ष बताते हैं कि वर्तमान में, प्रमुख पूर्व-प्रशिक्षण प्रतिमानों के परिणामस्वरूप हमारे मॉडल में पर्याप्त व्यावहारिक क्षमता नहीं होती है।', 'zh': '随预训语(LM)续主NLP,知言功之深益重。 先训者LM语用学之力也,重者,语之语用学也。 用自然之数,与心语言学之受控,制闭锁式试之。 专于试模用实用线以占语连接词,解连接词之隐含,与模形于多大程度之上出对连接词日月动作之人偏好。 虽自然之数上下文可以善占连接词,当吾制上下文以离高实,灵敏度下多矣。 模形亦未见实质性类人之时偏好。 总体而言,讲结果表明,主导地位之预练范式,未有实质性于我者也。', 'ja': '事前に訓練された言語モデル（ LM ）がNLPを支配し続けるにつれて、これらのモデルにおける言語能力の深さを理解することがますます重要になる。 この論文では、事前に訓練されたLMの実践力を対象とし、ディスカッションコネクティブに関連する実践力に焦点を当てている。 私たちは、自然発生データと心理言語学から得られた制御された入力の組み合わせを使用して、クローズスタイルのテストを策定します。 私たちは、話のつながりを予測するために実用的な手がかりを使用するモデルの能力、つながりに関連する暗示性を理解するモデルの能力、およびつながりの時間的ダイナミクスに関してモデルが人間のような好みを示す程度をテストすることに焦点を当てています。 私たちは、モデルが自然発生データの文脈でコネクティブを合理的に予測するものの、高レベルの実用的な手がかりを分離するために文脈を制御するとき、モデルの感度ははるかに低いことを発見しました。 モデルはまた、実質的な人間のような時間的嗜好を示さない。 全体的に見て、この知見は、現在、支配的な事前トレーニングのパラダイムは、私たちのモデルにおける実質的な実用的能力をもたらさないことを示唆している。', 'ru': 'Поскольку предварительно обученные языковые модели (LMS) продолжают доминировать в NLP, все более важно, чтобы мы понимали глубину языковых возможностей в этих моделях. В этом документе мы рассматриваем предварительно обученную компетенцию LMS в прагматике с акцентом на прагматику, относящуюся к связям дискурса. Мы формулируем закрытые тесты, используя комбинацию встречающихся в природе данных и контролируемых входных данных, полученных из психолингвистики. Мы сосредоточены на тестировании способности моделей использовать прагматические подсказки для предсказания соединений дискурса, способности моделей понимать импликатуры, относящиеся к соединениям, и степени, в которой модели показывают человекоподобные предпочтения в отношении временной динамики соединений. Мы обнаружили, что, хотя модели довольно хорошо предсказывают связи в контексте встречающихся в природе данных, когда мы контролируем контексты, чтобы изолировать прагматические сигналы высокого уровня, чувствительность модели намного ниже. Модели также не демонстрируют существенных человекоподобных временных предпочтений. В целом, сделанные выводы свидетельствуют о том, что в настоящее время доминирующие парадигмы предварительной подготовки не приводят к существенной прагматической компетентности в наших моделях.', 'ga': 'De réir mar a leanann samhlacha teanga réamh-oilte (LManna) chun tosaigh ar an NLP, tá sé ag éirí níos tábhachtaí go dtuigimid doimhneacht inniúlachtaí teanga na múnlaí seo. Sa pháipéar seo, dírímid ar inniúlacht LManna réamhoilte sa phragmatach, agus dírímid ar phragmataic a bhaineann le naisc dioscúrsa. Déanaimid tástálacha ar an stíl cloze ag baint úsáide as meascán de shonraí a tharlaíonn go nádúrtha agus ionchuir rialaithe ó shíctheangeolaíocht. Dírímid ar chumas samhlacha a thástáil leideanna pragmatacha a úsáid chun nascálacha dioscúrsa a thuar, cumas samhlacha tuiscint a fháil ar impleachtanna a bhaineann le naisc, agus a mhéid a léiríonn samhlacha roghanna daonna maidir le dinimic ama na nasc. Faighimid amach cé go ndéanann samhlacha tuar réasúnta maith ar naisc i gcomhthéacs sonraí a tharlaíonn go nádúrtha, nuair a rialaimid comhthéacsanna chun leideanna pragmatacha ardleibhéil a leithlisiú, tá íogaireacht na samhla i bhfad níos ísle. Ní thaispeánann samhlacha ach oiread roghanna suntasacha ama daonna. Tríd is tríd, tugann na torthaí le tuiscint nach bhfuil inniúlacht phragmatach shubstaintiúil inár múnlaí mar thoradh ar pharaidímí réamhoiliúna ceannasacha faoi láthair.', 'el': 'Καθώς τα προ-εκπαιδευμένα γλωσσικά μοντέλα (LM) συνεχίζουν να κυριαρχούν στο NLP, είναι όλο και πιο σημαντικό να κατανοήσουμε το βάθος των γλωσσικών δυνατοτήτων σε αυτά τα μοντέλα. Σε αυτή την εργασία, στοχεύουμε την ικανότητα των προ-εκπαιδευμένων LM στην πραγματιστική, με έμφαση στην πραγματιστική που σχετίζεται με τα συνδετικά στοιχεία του λόγου. Σχεδιάζουμε τεστ τύπου κλόζ χρησιμοποιώντας ένα συνδυασμό φυσικών δεδομένων και ελεγχόμενων εισροών που προέρχονται από την ψυχογλωσσολογία. Εστιάζουμε στη δοκιμή της ικανότητας των μοντέλων να χρησιμοποιούν ρεαλιστικές ενδείξεις για την πρόβλεψη των συνδετικών συζητήσεων, της ικανότητας των μοντέλων να κατανοήσουν τις επιπτώσεις που σχετίζονται με συνδετικά, και του βαθμού στον οποίο τα μοντέλα δείχνουν ανθρώπινες προτιμήσεις σχετικά με τη χρονική δυναμική των συνδετικών. Διαπιστώνουμε ότι παρόλο που τα μοντέλα προβλέπουν τις συνδέσεις αρκετά καλά στο πλαίσιο των φυσικών δεδομένων, όταν ελέγχουμε τα πλαίσια για να απομονώσουμε υψηλού επιπέδου πραγματιστικές ενδείξεις, η ευαισθησία του μοντέλου είναι πολύ χαμηλότερη. Τα μοντέλα επίσης δεν παρουσιάζουν σημαντικές ανθρώπινες χρονικές προτιμήσεις. Συνολικά, τα πορίσματα δείχνουν ότι επί του παρόντος, κυρίαρχα παραδείγματα προ-κατάρτισης δεν οδηγούν σε ουσιαστική πραγματιστική ικανότητα στα μοντέλα μας.', 'hu': 'Mivel az előképzett nyelvi modellek továbbra is dominálják az NLP-t, egyre fontosabb, hogy megértsük a nyelvi képességek mélységét ezekben a modellekben. Ebben a tanulmányban az előképzett LM-ek pragmatikai kompetenciáját célozzuk meg, különös tekintettel a diskurzus kapcsolatokkal kapcsolatos pragmatikára. A természetesen előforduló adatok és a pszicholingvistikából származó kontrollos bemenetek kombinációjával állítunk össze állítási stílusú teszteket. Arra összpontosítunk, hogy a modellek képesek pragmatikus utakat használni a diskurzus kapcsolatok előrejelzésére, a modellek képesek megérteni a kapcsolatok vonatkozásait, és hogy a modellek milyen mértékben mutatják meg az emberi preferenciákat a kapcsolatok idődinamikájával kapcsolatban. Úgy találjuk, hogy bár a modellek meglehetősen jól előrejelzik a kapcsolatokat a természetes adatok kontextusában, amikor kontextusokat irányítunk a magas szintű pragmatikus utak izolálására, a modellérzékenység sokkal alacsonyabb. A modellek sem mutatnak jelentős emberiszerű időbeli preferenciákat. Összességében a megállapítások arra utalnak, hogy jelenleg a domináns képzés előtti paradigmák nem eredményeznek lényeges pragmatikus kompetenciát modelleinkben.', 'ka': 'როგორც წინ განსწავლა ენის მოდელები (LMs) გადასრულებულია NLP-ს, უფრო მნიშვნელოვანია, რომ ჩვენ ვიცით ენის შესაძლებლობების დუბი ამ მოდელში. ჩვენ პრაგმატიკაში პრაგმატიკაში, პრაგმატიკაში დავუყენებთ პროგმატიკაში, რომელიც კონფიკურებულია პროგმატიკაში. ჩვენ კლოზის სტილის ტესტის გამოყენება, რომელიც ნაირად მოხდება მონაცემების და კონტროლური მონაცემების კონტროლური მონაცემების გამოყენება. ჩვენ მოდელების შესაძლებლობა გამოიყენოთ პრაგმატიკური სიმბოლოების შესაძლებლობა, მოდელების შესაძლებლობა გავიგოთ კონფიკაციების შესაძლებლობა, რომელიც კონფიკაციების შესახებ, და რომელიც მოდელები ადამიანის პრეფი ჩვენ აღმოჩნეთ, რომ მოდელები დაკავშირებების შესახებ წარმოდგენენა, რადგან ჩვენ მოდელების შესახებ, როდესაც ჩვენ კონტექსტები იზოლურებთ პრაგმატიკური სიმბოლობებისთვისებად, მო მოდელები ასევე არ ჩვენებენ მნიშვნელოვანი ადამიანური პროგრამეტრებისთვის. ჩვენი მოდელეების შესახებ, რომ ახლა დომინტური პროგრამიკური პარადიგმები ჩვენი მოდელში არ გავაკეთებენ მნიშვნელოვანი პრაგმატიკური კომპენტები.', 'it': 'Poiché i modelli linguistici pre-formati continuano a dominare la PNL, è sempre più importante comprendere la profondità delle capacità linguistiche in questi modelli. In questo articolo, puntiamo sulla competenza degli LMs pre-formati in pragmatica, con un focus sulla pragmatica relativa ai connettivi del discorso. Formuliamo test in stile cloze utilizzando una combinazione di dati naturali e input controllati ricavati dalla psicolinguistica. Ci concentriamo sulla capacità dei modelli di testare la capacità di usare indizi pragmatici per prevedere i connettivi del discorso, la capacità dei modelli di comprendere le implicazioni relative ai connettivi e la misura in cui i modelli mostrano preferenze umane rispetto alle dinamiche temporali dei connettivi. Troviamo che sebbene i modelli prevedano i connettivi ragionevolmente bene nel contesto dei dati naturali, quando controlliamo i contesti per isolare indizi pragmatici di alto livello, la sensibilità del modello è molto più bassa. I modelli inoltre non mostrano sostanziali preferenze temporali umane. Nel complesso, i risultati suggeriscono che attualmente i paradigmi dominanti di pre-formazione non comportano una competenza pragmatica sostanziale nei nostri modelli.', 'mk': 'Бидејќи предобучените јазички модели (ЛМ) продолжуваат да доминираат во НЛП, сé важно е да ја разбереме длабочината на јазичките способности во овие модели. Во овој весник, ние се насочуваме конкурентноста на предобучените ЛМ во прагматика, со фокус на прагматиката поврзана со дискурсните поврзувања. Формулираме тестови во стил на клоз користејќи комбинација на природни податоци и контролирани внесувања извлечени од психолингвистика. Ние се фокусираме на способноста на тестирање на моделите да користат прагматски знаци за предвидување на дискурсни поврзувања, способноста на моделите да ги разберат импликациите поврзани со поврзувањата, и степенот во кој моделите покажуваат човечки преференции во врска со температ Најдовме дека иако моделите реално добро предвидуваат врски во контекст на природни податоци, кога контролираме контексти за изолирање на прагматски знаци на високо ниво, моделот е многу пониска. Models also do not show substantial humanlike temporal preferences.  Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.', 'kk': 'Алдын- ала оқылған тіл үлгілері (LMs) NLP үлгілерін бастау үшін, бұл үлгілердегі тіл мүмкіндіктерінің тереңдігін түсіну үшін көп маңызды. Бұл қағазда, бұл парақтың алдын- ала оқылған LMs компетентін прагматикалық көмегімен, дискурстар қосылымдарының прагматикалық көмегімен көмектесіп тұрмыз. Біз психолингвистикадан алып жатқан деректерді және басқару үшін клос стилінің сынақтарын формулиру. Біз үлгілерді сынақтау мүмкіндігін, дискурстар қосылымдарды, үлгілердің қосылымдарды түсіндіру мүмкіндігін таңдау үшін прагматикалық белгілерді қолдану мүмкіндігіне көздейміз, және үлгілердің уақытша қосылымдард Біз үлгілер қосылымдарды таңдау үшін табиғатты деректердің контексті жақсы көрсетеді, біз бағдарламаларды жоғары деңгейіндегі прагматикалық белгілерді бөліктеу үшін контексттерді басқанда, үлгілер сезімд Үлгілер сондай-ақ уақытша параметрлердің сияқты адамдарды көрсетпейді. Барлық тапсырмалар қазіргі уақытта, доминистік алдындағы парадигмдер үлгілерімізде көп прагматикалық көмектеспейді.', 'ms': 'Sebagaimana model bahasa terlatih (LMs) terus dominasi NLP, semakin penting bahawa kita memahami kedalaman kemampuan bahasa dalam model ini. Dalam kertas ini, kita sasarkan kemampuan LMs yang dilatih-dilatih dalam pragmatik, dengan fokus pada pragmatik yang berkaitan dengan sambungan diskors. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from psycholinguistics.  Kami fokus pada kemampuan menguji model untuk menggunakan isyarat pragmatik untuk meramalkan sambungan diskors, kemampuan model untuk memahami implikasi berkaitan dengan sambungan, dan jangkauan mana model menunjukkan keutamaan seperti manusia berkaitan dengan dinamika sementara sambungan. Kami mendapati bahawa walaupun model meramalkan sambungan cukup baik dalam konteks data yang berlaku secara alami, apabila kita mengawal konteks untuk mengisolasi isyarat pragmatik tinggi, sensitiviti model jauh lebih rendah. Model juga tidak menunjukkan keutamaan sementara yang sah seperti manusia. Secara keseluruhan, penemuan menunjukkan bahawa pada masa ini, paradigma pralatihan dominan tidak mengakibatkan kemampuan pragmatik yang besar dalam model kita.', 'ml': "മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലുകള്\u200d (എല്\u200dഎംഎംഎല്\u200dപി) നിയന്ത്രിക്കുന്നത് കൊണ്ട് തുടരുന്നത് കൊണ്ടാണ്, ഈ മോഡലിലെ ഭാഷയുടെ ആഴത ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d മുന്\u200dപ് പരിശീലിക്കപ്പെട്ട എല്\u200dമിസിന്\u200dറെ അധികാരത്തെ ലക്ഷ്യമാക്കുന്നു, സംസാരിക്കുന്ന ബന്ധങ്ങളുമായി ബന്ധ സ്വാഭാവികമായ സംഭവിക്കുന്ന വിവരങ്ങളുടെ കൂട്ടത്തില്\u200d നിന്നും നിയന്ത്രിക്കപ്പെട്ടുകൊണ്ടും സൈക്കോലിന്\u200dഗിസ്റ്റിക We focus on testing models' ability to use pragmatic cues to predict discourse connectives, models' ability to understand implicatures relating to connectives, and the extent to which models show humanlike preferences regarding temporal dynamics of connectives.  സ്വാഭാവികമായ സംഭവിക്കുന്ന വിവരങ്ങളുടെ കൂട്ടത്തില്\u200d മോഡലുകള്\u200d പ്രവചിക്കുന്നുവെങ്കിലും സ്വാഭാവികമായ വിവരങ്ങളുടെ കൂട്ടത്തില്\u200d സ്വാഭാവി മോഡലുകളും മനുഷ്യരെപ്പോലെയുള്ള മനുഷ്യര്\u200dക്ക് മാതൃക മുന്\u200dഗണങ്ങള്\u200d കാണിക്കുന്നില്ല. എല്ലാത്തിലും കണ്ടെത്തുന്നത് ഇപ്പോള്\u200d മുന്നോട്ട് പരിശീലനത്തിന്റെ പ്രധാനപ്പെട്ട പരാദങ്ങള്\u200dക്ക് നമ്മുടെ മോഡലില്\u200d വലിയ", 'mt': "Billi mudelli lingwistiċi mħarrġa minn qabel ikomplu jiddominaw il-NLP, huwa dejjem aktar importanti li nifhmu l-fond tal-kapaċitajiet lingwistiċi f’dawn il-mudelli. F'dan id-dokument, a ħna nindirizzaw il-kompetenza tal-LMs imħarrġa minn qabel fil-pragmatika, b'enfasi fuq il-pragmatika relatata mal-konnettivi tad-diskors. Aħna nifformulaw testijiet bl-istil tal-għeluq bl-użu ta’ kombinazzjoni ta’ dejta li sseħħ b’mod naturali u inputs ikkontrollati miġbura mill-psikolinġistika. Aħna niffokaw fuq l-abbiltà tal-ittestjar tal-mudelli li jużaw sinjali prammatiċi biex jipprevedu konnettivi diskors, il-kapaċità tal-mudelli li jifhmu implikazzjonijiet relatati mal-konnettivi, u sa liema punt il-mudelli juru preferenzi simili għall-bniedem fir-rigward tad-dinamika temporali tal-konnettivi. Issibu li għalkemm il-mudelli jipprevedu l-konnettivi raġonevolment tajjeb fil-kuntest tad-dejta li sseħħ b’mod naturali, meta nikkontrollaw il-kuntesti biex niżolaw sinjali prammatiċi ta’ livell għoli, is-sensittività tal-mudell hija ħafna aktar baxxa. Il-mudelli ma jurux ukoll preferenzi temporali sostanzjali simili għall-bniedem. B’mod ġenerali, is-sejbiet jissuġġerixxu li bħalissa, il-paradigmi dominanti ta’ qabel it-taħriġ ma jirriżultawx f’kompetenza prammatika sostanzjali fil-mudelli tagħna.", 'pl': 'Ponieważ wstępnie przeszkolone modele językowe (LM) nadal dominują NLP, coraz ważniejsze jest, abyśmy zrozumieli głębokość możliwości językowych w tych modelach. W niniejszym artykule skupiamy się na kompetencjach przeszkolonych LM w zakresie pragmatyki, ze szczególnym uwzględnieniem pragmatyki związanej z łącznikami dyskursu. Formułujemy testy w stylu cloze wykorzystując połączenie naturalnie występujących danych i kontrolowanych danych pochodzących z psycholingwistyki. Skupiamy się na testowaniu zdolności modeli do wykorzystania pragmatycznych wskazówek do przewidywania łączności dyskursu, zdolności modeli do zrozumienia implikacji związanych z łącznościami oraz stopniu, w jakim modele wykazują ludzkie preferencje dotyczące dynamiki czasowej łączności. Odkrywamy, że chociaż modele dość dobrze przewidują połączenia w kontekście naturalnie występujących danych, kiedy kontrolujemy konteksty w celu izolowania wysokiego poziomu pragmatycznych wskazówek, wrażliwość modelu jest znacznie niższa. Modele również nie wykazują istotnych ludzkich preferencji czasowych. Ogólnie rzecz biorąc, ustalenia sugerują, że obecnie dominujące paradygmaty przedszkoleniowe nie skutkują znacznymi kompetencjami pragmatycznymi w naszych modelach.', 'no': 'Som først trengte språk-modeller (LMs) fortsetter å dominere NLP, er det viktig å forstå dybde på språk-kapasiteten i desse modelane. I denne papiret mål vi først trengte LMs-kompetansen på pragmatikk, med fokus på pragmatikk som relatert til diskurs-tilkoplingar. Vi formerer klosestiltestar med ein kombinasjon av naturlig gjeldande data og kontrollerte inndata teikna frå psycholinguistic. Vi fokuserer på å testa modellen til å bruka pragmatiske måtar for å foregå diskurs-tilkoplingar, modellen til å forstå implikatørar som relaterte til tilkoplingar, og kor mykje modeller viser menneskelige innstillingar som relaterte tidlegare dynamikk av tilkoplingar. Vi finn at selv om modeller foregår tilkoplingar rett godt i konteksten av naturleg data, når vi kontrollerer kontekstar til å isolere høg nivå pragmatiske teikn, er modellesensitivitet mykje lavere. Modellar viser ikkje også mykje menneske innstillingar. Generelt, oppdagane tyder på at dominerende føreøvingsparadigmar ikkje fører til substantielle pragmatiske kompetanse i våre modeller i dag.', 'ro': 'Deoarece modelele lingvistice pre-instruite continuă să domine PNL, este din ce în ce mai important să înțelegem profunzimea capacităților lingvistice din aceste modele. În această lucrare, vizăm competența LM pre-instruită în pragmatică, cu accent pe pragmatică referitoare la conexiunile discursului. Formulăm teste în stil cloze folosind o combinație de date naturale și intrări controlate extrase din psihologistică. Ne concentrăm pe testarea capacității modelelor de a folosi indicii pragmatice pentru a prezice conectivul discursului, capacitatea modelelor de a înțelege implicațiile legate de conectivul și măsura în care modelele prezintă preferințe umane în ceea ce privește dinamica temporală a conectivului. Considerăm că, deși modelele prezic conectivele destul de bine în contextul datelor naturale, atunci când controlăm contextele pentru a izola indicii pragmatice de nivel înalt, sensibilitatea modelului este mult mai mică. Modelele, de asemenea, nu prezintă preferințe temporale substanțiale asemănătoare omului. În general, constatările sugerează că, în prezent, paradigmele dominante de pre-formare nu duc la o competență pragmatică substanțială în modelele noastre.', 'sr': 'Kako predobučeni jezički modeli (LMs) nastavljaju dominirati NLP, sve je važnije da razumemo dubinu jezičkih sposobnosti u ovim modelima. U ovom papiru, ciljamo predobučenu sposobnost LMs-a u pragmatiku, sa fokusom na pragmatiku u vezi sa vezama diskursa. Formuliramo testove za kloz-stil koristeći kombinaciju prirodno pojavljivih podataka i kontroliranih ulaza iz psihologistike. Fokusiramo se na sposobnost testiranja modela da koristimo pragmatične znakove kako bi predvidjeli veze diskursa, sposobnost modela da razumemo implikatore vezane sa povezivanjem, i u kakvoj mjeri modela pokazuju ljudske preferencije u vezi temporalne dinamike veza. Pronašli smo da, iako modeli razumno dobro predviđaju veze u kontekstu prirodno događajućih podataka, kada kontroliramo kontekste izolovanja pragmatičnih znakova na visokom nivou, osetljivost modela je mnogo niža. Modeli takođe ne pokazuju značajne ljudske preferencije kao privremene. U svemu, nalazi sugeriraju da trenutno dominantne paradigme pre obuke ne rezultuju značajnu pragmatičnu kompetenciju u našim modelima.', 'si': 'ප්\u200dරධානය කරපු භාෂා මොඩල් වලින් (LMs) NLP ප්\u200dරධානය කරනවා කියලා, අපිට මේ මොඩල් වලින් භාෂා ක්\u200dරියාත්මක ක්\u200dරියාත්මක මේ පැත්තට, අපි ප්\u200dරාග්මැටික් වලින් ප්\u200dරධානය කරලා තියෙන ප්\u200dරාග්මැටික් වලින් ප්\u200dරාග්මැටික් වලින් ප්\u200dරධානයක් ගැන අපි ස්වභාවිකයෙන් වෙන්න පුළුවන් දත්ත සහ පාලනය කරන්න පුළුවන් පරීක්ෂණාවක් පරීක්ෂණය කරනවා. අපි පරීක්ෂණය කරනවා මොඩේලන්ගේ ක්\u200dරියාත්මක ක්\u200dරියාත්මක ප්\u200dරයෝජනය කරන්න පුළුවන් පරීක්ෂණය, මොඩේලන්ගේ ක්\u200dරියාත්මක සම්බන්ධතාවක් සම්බන්ධතාවක අපිට හොයාගන්න පුළුවන් විදියට මොඩේල් සංවේදනය හොඳ විදියට සම්බන්ධතාවක් හොඳයි, ස්වභාවික විදියට සංවේදනය විදියට, අපි ප්\u200dරති මොඩේල් වගේම විශාල මනුෂ්\u200dයය වගේම පෙන්වන්නේ නැහැ. සාමාන්\u200dයයෙන්, හොයාගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා අපේ මොඩල් වලට ප්\u200dරශ්නයක් නෑ කියලා.', 'mn': 'Өмнөх сургалтын хэл загварууд (LMs) нь NLP-г давамгайлах тусам бид эдгээр загваруудын хэл чадварын гүн гүнзгийг ойлгох нь илүү чухал. Энэ цаасан дээр бид анх сургалтын ЛНХ-ын прагматикийн талаар сургалтыг зориулж, ярианы холбоотой прагматикийн талаар анхаарлаа хандуулдаг. Бид сэтгэл зүйн хэлний мэдээллээс гарч ирсэн мэдээлэл болон хяналттай мэдээллийг ашиглан клоз хэлбэрийн тестийг тооцоолж байна. Бид загварын шинжлэх ухааны талаар ярианы холбоотой холбоотой, загварын холбоотой холбоотой зүйлсийг ойлгохын тулд прагматикийн загваруудыг ашиглах чадварын талаар анхаарлаа төвлөрүүлдэг. Бид загварууд байгалийн мэдээллийн тухай холбоотой холбоотой байдлыг тодорхойлж байгаа ч, өндөр төвшин прагматик тэмдэглэгдэх үед, загварын мэдрэмж маш бага байдаг. Загварууд мөн цаг хугацааны сонголтуудыг харуулахгүй. Ихэнх тохиолдолд бидний загвар дээрх сургалтын өмнө давамгайлах парадигм нь бидний загвар дээрх чухал прагматикийн чадварыг үр дүнгүй гэсэн үг.', 'so': 'Sida samooyinka afka horay loo tababaray (LMs) ay u sii socoto maamulida NLP, waxaa muhiim ah inaannu fahanno moolka awoodda afka ee modelladan. Qoraalkan waxaynu ku hagaynaa aqoonta horay loo tababariyey LMs-da, kaas oo focus ugu leh hadalka la xiriira xiriirka hadalka. Waxaannu sameynaa imtixaanka dabiicadda ah oo lagu isticmaalayo isku xiran macluumaad dabiicadda ah iyo wax lagu maamulo oo laga soo dhaqdhaqaaqay cilmi-luuqada dhimirka. Waxaan ku kalsoonaynaa tijaabada qaababka imtixaanka, si aan u sii sheegno xiriirka hadalka, awoodda qaababka sameynta garashada saamaynta xiriirka, iyo mudada qaababka tusaalayaasha u muujinta doorashooyinka dadka oo kale ee ku saabsan wakhtiga ku meelgaarka ah dhaqdhaqaaqa xiriirka. Waxaynu heli nahay in kastoo muusikadu uu wax si fiican u sii sheego iskula xiriira taariikhda dabiicadda ah, markaynu u maamulno xilliyada si aynu u goosanno cudurada caadooyinka sare, waxaa ka hoosaysa dhaqaalaha dabeecada. Modelooyinka sidoo kale ma muujiyaan doorashooyinka dadka ugu weyn sida waqti ku meelgaar ah. Sida caadiga ah dhamaantooda waxaa loola jeedaa in marka la joogo paradiyada horumarinta ah aysan sababin aqoonta caadiga ah ee noocyada.', 'sv': 'I takt med att färdigutbildade språkmodeller fortsätter att dominera NLP blir det allt viktigare att vi förstår djupet i språkförmågan i dessa modeller. I den här uppsatsen riktar vi oss mot färdigutbildade LMs kompetens inom pragmatik, med fokus på pragmatik relaterat till diskurssammanhang. Vi formulerar cloze-style tester med hjälp av en kombination av naturligt förekommande data och kontrollerade input hämtade från psykolingvistik. Vi fokuserar på att testa modellernas förmåga att använda pragmatiska ledtrådar för att förutsäga diskurskopplingar, modellernas förmåga att förstå implikationer relaterade till kopplingar och i vilken utsträckning modellerna visar mänskliga preferenser gällande tidsdynamik hos kopplingar. Vi finner att även om modeller förutspår kopplingar ganska bra i samband med naturligt förekommande data, när vi kontrollerar kontexter för att isolera pragmatiska ledtrådar på hög nivå, är modellkänsligheten mycket lägre. Modeller uppvisar inte heller väsentliga mänskliga tidsmässiga preferenser. Sammantaget tyder resultaten på att dominerande pre-training paradigm för närvarande inte leder till väsentlig pragmatisk kompetens i våra modeller.', 'ta': "As pre-trained language models (LMs) continue to dominate NLP, it is increasingly important that we understand the depth of language capabilities in these models.  இந்த காகிதத்தில், நாம் முன்பு பயிற்சி LMs' திறமைப்பை குறிக்கும், பேச்சு இணைப்புகளை பற்றிய பேச்சு தொடர்பு கொண்டுள்ள புத நாம் தானாகவே நடக்கும் தகவல் மற்றும் கட்டுப்படுத்தப்பட்ட உள்ளீடுகளை மைகோள் மொழிகளிலிருந்து வரையப்பட்டுள்ளது. பேச்சு இணைப்புகள், மாதிரிகளின் தொடர்புகளை புரிந்து கொள்ள முடியும் மாதிரிகளின் தொடர்புகளை புரிந்து கொள்ள முடியும் மாதிரிகளின் முன்னுரிமைகளை பயன்படுத்த நாம் கண்டுபிடிக்கும் போது மாதிரிகள் தொடர்புகளை சரியாக முற்படுத்துகிறது என்றாலும் தானாகவே நடக்கும் தகவலின் மூலம், அதிக நிலையில் தனிப்படுத்து மாதிரிகளும் தற்காலிக விருப்பங்களைப் போன்ற மதிப்பெரிய மனிதனை காட்ட முடியாது. மொத்தமாக, கண்டுபிடிப்புகள் தற்போது, முன் பயிற்சி அளபுருக்கள் எங்கள் மாதிரிகளில் பெரிய முக்கியமான திறமையை கொண்டு வரு", 'ur': 'جیسے پہلے آموزش کی زبان مدل (LMs) NLP کی حکومت ادھر رہے ہیں، یہ بہت اہم ہے کہ ہم ان مدلوں میں زبان کے قابلیت کی depth سمجھتے ہیں. ہم اس کاغذ میں پیش آموزش دی گئی LMs کی تعلیم پر قابل مقرر کر رہے ہیں، اس کے ذریعہ پراگوٹیکوں کے ساتھ تمرکز کررہے ہیں. ہم کلوز استیل کی آزمائش کو طبیعی طور پر حاضر ہونے والی ڈیٹا اور روانی زبان شناسی سے نکالے ہوئے اینپوٹ کے استعمال سے فرمول کرتے ہیں. ہم نمڈلوں کی آزمائش کی قابلیت پر تغییر کریں گے کہ پراگماتیک کوئٹوں کو استعمال کریں، ڈیکورس کے اتصال، نمڈلوں کی قابلیت سمجھ سکیں کہ اتصال کے معاملہ میں مشابہ ہوں، اور جس طرح نمڈلوں نے انسان کی طرح طرح طرح طرح طرح طرح کائنات کے متعلق انسان کی ہمیں معلوم ہے کہ اگرچہ موڈلے نہایت اچھے طریقے سے اتصال کرنے والے ڈیٹے کے کنٹکسٹ میں اچھے طریقے سے اچھے طریقے سے اچھے طریقے سے پیش بینی کریں، جب ہم اچھے سطح کے نہایت اچھے سطح کے نہایت اچھے طریقے کے لئے کنٹکسٹ موڈلز بھی موقتی ترجیح کے مطابق زیادہ انسان کو دکھاتے نہیں ہیں۔ سب سے، اچھے معلومات کی توصیف کرتی ہیں کہ اب، حکومت پیش آموزش پارادیگ ہمارے مدلکوں میں زیادہ پراگرماتیک تعلیم کا نتیجہ نہیں ہوتا۔', 'lt': "Kadangi iš anksto parengti kalbų modeliai ir toliau dominuoja NLP, vis svarbesni suprasti kalbų gebėjimų gilumą šiuose modeliuose. In this paper, we target pre-trained LMs' competence in pragmatics, with a focus on pragmatics relating to discourse connectives.  Mes formuojame klozo stilius bandymus naudojant natūralių duomenų ir kontroliuojamų įvedimų, gautų iš psichologikos, derinį. Mes daugiausia dėmesio skiriame bandymų modelių gebėjimui naudoti pragmatinius įrodymus diskursiniams jungiamiesiems ryšiams prognozuoti, modelių gebėjimui suprasti su jungiamiesiems ryšiams susijusius padarinius ir mastui, kiek modeliai rodo žmoniškas preferencijas, susijusias su jungiamųjų jungiamųjų ryšių temporaine dinamika. We find that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower.  Be to, modeliuose nenustatyta didelių žmogiškųjų laikinųjų preferencijų. Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.", 'vi': 'Khi các mô hình ngôn ngữ được huấn luyện trước (LMs) tiếp tục thống trị ngôn ngữ ngọt ngào, điều ngày càng quan trọng là chúng ta hiểu được độ sâu của khả năng ngôn ngữ trong các mô hình này. Trong tờ giấy này, chúng ta nhắm vào năng lực thực dụng của LMs được rèn luyện trước, với một tập trung vào thực dụng liên quan tới liên lạc đàm luận. Chúng tôi soạn các thử nghiệm kiểu quần quật nhờ kết hợp các dữ liệu hiện tại tự nhiên và các nội dung được trích từ tâm học. Chúng tôi tập trung vào việc thử nghiệm khả năng sử dụng các mô hình dụng thực tế để dự đoán các liên lạc trong ngôn ngữ, khả năng của các mô hình để hiểu kết nối liên quan, và kích thước các mô- đun cho thấy khả năng của con người về tính to án thời gian của các kết nối. Chúng tôi thấy rằng mặc dù các mô hình dự đoán kết nối hợp lý lý trong trường hợp có tồn tại tự nhiên, khi chúng tôi điều khiển các ngữ cảnh để phân tách các tác dụng ưu việt cao cấp, độ nhạy của mô hình còn thấp hơn. Màu mẫu cũng không cho thấy thích nghi tạm thời rộng lớn. Về mặt chung, những kết quả cho thấy hiện tại, mô hình hàng đầu huấn luyện không dẫn đến sự thực dụng thực tế trong các mô hình của chúng ta.', 'uz': "Birinchi taʼminlovchi tillar modellari (LMs) NLP'ni boshqarishda davom etishda, bu modellarda tillar qobiliyatining keng qobiliyatini tushirishimiz juda muhim. Bu qogʻozda, biz pre-trained LMs'ning taqdimotini o'rganamiz, suhbat bilan bog'liq bog'liqlari bilan bog'langan pragmatiklarga foydalanamiz. Name Biz modellarni sinovlash uchun pragmatik xususiyatlarni ishlatish uchun foydalanamiz, bogʻlamalar bilan bog'liqlarni aniqlash mumkin, modellarning qobiliyatini tushirish mumkin, va modellar bilan bogʻ'liq narsalarni tushirish mumkin, va modellar bilan bogʻlash uchun muloqat parametrlarini koʻrsatish mumkin. Biz o'ylaymiz, modellar tabiiy bo'lgan maʼlumot tarkibida juda yaxshi bog'lanishini o'rganadi, biz yuqori darajada pragmatik xususiyatlarni boshqarishni boshqarishda, model sensitilik juda kamaytirish. @ info Hozirda, murakkablar hozirgi o'rganishdan oldin paradigmlar modelлариdagi muhim pragmatik qobiliyatga sababchi emas.", 'bg': 'Тъй като предварително обучените езикови модели продължават да доминират в НЛП, все по-важно е да разбираме дълбочината на езиковите възможности в тези модели. В настоящата статия се насочваме към компетентността на предварително обучените УМ по прагматика, с фокус върху прагматиката, свързана с дискурсните съединения. Формулираме тестове в клозов стил, използвайки комбинация от естествено срещани данни и контролирани входове, извлечени от психолингвистиката. Фокусираме се върху тестването на способността на моделите да използват прагматични знаци за предсказване на дискурсните съединения, способността на моделите да разбират импликациите, свързани с съединителните, и степента, в която моделите показват човешки предпочитания по отношение на времевата динамика на съединителните. Установяваме, че макар моделите да предвиждат съединенията сравнително добре в контекста на естествени данни, когато контролираме контекстите, за да изолираме прагматични знаци на високо ниво, чувствителността на модела е много по-ниска. Моделите също не показват значителни човешки темпорални предпочитания. Като цяло констатациите показват, че понастоящем доминиращите парадигми преди обучението не водят до значителна прагматична компетентност в нашите модели.', 'nl': "Aangezien voorgetrainde taalmodellen (LMs) NLP blijven domineren, wordt het steeds belangrijker dat we de diepte van taalcapaciteiten in deze modellen begrijpen. In dit artikel richten we ons op de competentie van voorgetrainde LMs in pragmatiek, met een focus op pragmatiek met betrekking tot discoursconnectieven. We formuleren cloze-style tests met behulp van een combinatie van natuurlijk voorkomende gegevens en gecontroleerde inputs uit psycholinguïstiek. We richten ons op het testen van het vermogen van modellen om pragmatische cues te gebruiken om discoursconnectieven te voorspellen, het vermogen van modellen om implicaties met betrekking tot connectieven te begrijpen en de mate waarin modellen menselijke voorkeuren tonen met betrekking tot temporele dynamiek van connectieven. Hoewel modellen connectieven redelijk goed voorspellen in de context van natuurlijk voorkomende data, is de gevoeligheid van modellen veel lager wanneer we contexten controleren om pragmatische aanwijzingen op hoog niveau te isoleren. Modellen tonen ook geen substantiële menselijke temporele voorkeuren. Over het algemeen suggereren de bevindingen dat dominante pre-training paradigma's momenteel niet leiden tot substantiële pragmatische competentie in onze modellen.", 'da': "Da forududdannede sprogmodeller fortsat dominerer NLP, er det stadig vigtigere, at vi forstår dybden af sprogkapaciteter i disse modeller. I denne opgave målretter vi forududdannede LM'ers kompetence i pragmatik med fokus på pragmatik relateret til diskursforbindelser. Vi formulerer cloze-style tests ved hjælp af en kombination af naturligt forekommende data og kontrollerede input fra psykolingvistik. Vi fokuserer på at teste modellernes evne til at bruge pragmatiske signaler til at forudsige diskursforbindelser, modellernes evne til at forstå implikationer relateret til forbindelser, og i hvilket omfang modellerne viser menneskelige præferencer vedrørende forbindelsers tidsdynamik. Vi finder ud af, at selvom modeller forudsiger forbindelser rimeligt godt i forbindelse med naturligt forekommende data, når vi kontrollerer sammenhænge for at isolere pragmatiske signaler på højt niveau, er modelfølsomheden meget lavere. Modeller viser heller ikke betydelige menneskelige tidspræferencer. Samlet set tyder resultaterne på, at dominerende paradigmer inden for uddannelse i øjeblikket ikke resulterer i en væsentlig pragmatisk kompetence i vores modeller.", 'hr': 'Dok predobučeni jezički modeli (LMs) nastavljaju dominirati NLP, sve je važnije da razumijemo dubinu jezičkih sposobnosti u ovim modelima. U ovom papiru, ciljamo predobučenu nadležnost LMs-a na pragmatiku, s fokusom na pragmatiku u vezi s vezama s diskusijama. Formuliramo testove kloznog stila koristeći kombinaciju prirodno pojavljivih podataka i kontroliranih ulaganja iz psihologističke. Fokusiramo se na sposobnost testiranja modela koristiti pragmatične znakove kako bi predvidjeli veze s diskusijama, sposobnost modela razumjeti implikatne veze s povezivanjem, te u mjeri u kojoj modeli pokazuju ljudske preferencije u pogledu vremenske dinamike veza. Mi smatramo da, iako modeli razumno dobro predviđaju veze u kontekstu prirodno događajućih podataka, kada kontroliramo kontekste izoliranja pragmatičnih znakova visokog nivoa, osjetljivost modela je mnogo niža. Modeli također ne pokazuju značajne ljudske preferencije kao privremene. U ukupnom slučaju, nalazi sugeriraju da trenutno dominantne paradigme predobučenja ne uzrokuju značajnu pragmatsku kompetenciju u našim modelima.', 'id': 'Sebagai model bahasa yang terlatih (LMs) terus mendominasi NLP, semakin penting bahwa kita memahami kedalaman kemampuan bahasa dalam model ini. Dalam kertas ini, kami menargetkan kompetensi LMs pragmatik, dengan fokus pada pragmatik yang berhubungan dengan konektif diskors. Kami menyusun tes gaya kloze menggunakan kombinasi data yang terjadi secara alami dan masukan terkendali yang ditarik dari psikologi. Kami fokus pada kemampuan menguji model untuk menggunakan tanda pragmatis untuk memprediksi konektif diskors, kemampuan model untuk memahami implikasi berkaitan dengan konektif, dan sejauh mana model menunjukkan keutamaan seperti manusia mengenai dinamika temporal konektif. Kami menemukan bahwa meskipun model memprediksi konektif cukup baik dalam konteks data yang terjadi secara alami, ketika kita mengontrol konteks untuk mengisolasi tanda pragmatis tingkat tinggi, sensitivitas model jauh lebih rendah. Model juga tidak menunjukkan keutamaan temporal yang substansial seperti manusia. Secara umum, penemuan menunjukkan bahwa pada saat ini, paradigma pre-pelatihan dominan tidak menghasilkan kompetensi pragmatis substansial dalam model kita.', 'de': 'Da vortrainierte Sprachmodelle (LMs) NLP weiterhin dominieren, wird es immer wichtiger, dass wir die Tiefe der sprachlichen Fähigkeiten in diesen Modellen verstehen. In diesem Beitrag konzentrieren wir uns auf die Pragmatikkompetenz von vortrainierten LMs mit einem Fokus auf Pragmatik im Zusammenhang mit Diskurskonnektiven. Wir formulieren Cloze-Tests mit einer Kombination von natürlich vorkommenden Daten und kontrollierten Eingaben aus der Psycholinguistik. Wir konzentrieren uns darauf, die Fähigkeit von Modellen zu testen, pragmatische Hinweise zur Vorhersage von Diskurskonnektiven zu verwenden, die Fähigkeit von Modellen, Implikationen im Zusammenhang mit Konnektiven zu verstehen und inwieweit Modelle menschliche Präferenzen hinsichtlich der zeitlichen Dynamik von Konnektiven zeigen. Wir stellen fest, dass, obwohl Modelle Konnektive im Kontext natürlich vorkommender Daten relativ gut vorhersagen, wenn wir Kontexte kontrollieren, um pragmatische Hinweise auf hoher Ebene zu isolieren, die Modellsensitivität viel geringer ist. Modelle zeigen auch keine wesentlichen humanartigen zeitlichen Präferenzen. Insgesamt deuten die Ergebnisse darauf hin, dass gegenwärtig dominante Vorbildungsparadigmen keine wesentliche pragmatische Kompetenz in unseren Modellen zur Folge haben.', 'fa': 'همانطور که مدل های پیش آموزش زبانی (LMs) ادامه می دهند که NLP را تسلیم کنند، بیشتر مهم است که عمیق توانایی زبانی را در این مدل درک کنیم. در این کاغذ، ما مسئولیت LMs پیش آموزش یافته در پراگرماتیک را هدف می\u200cدهیم، با تمرکز روی پراگرماتیک رابطه به ارتباطات صحبت. ما با استفاده از ترکیب داده های طبیعی و ورودهای کنترل از روانشناسی کشیده شده\u200cایم. ما روی آزمایش توانایی مدل\u200cها تمرکز می\u200cکنیم که از نشانه\u200cهای پراگرماتیک استفاده کنیم تا ارتباط\u200cهای صحبت را پیش\u200cبینی کنیم، توانایی مدل\u200cها برای فهمیدن معلومات ارتباط\u200cهایی که ارتباط دارند، و به اندازه\u200cای که مدل\u200cها ترجیح\u200cهای انسانی را در مورد دینامیک ما پیدا می\u200cکنیم که هر چند مدل\u200cها ارتباطات را به طور منطقی خوب پیش بینی می\u200cکنند در محیط داده\u200cهای طبیعی، زمانی که ما محیط\u200cها را کنترل می\u200cکنیم تا نشانه\u200cهای پراگرماتیک بالا را جدا کنیم، حساسیت مدل بسیار پایین است. مدل\u200cها همچنین گزینه\u200cهای موقتی انسان\u200cهای زیادی را نشان نمی\u200cدهند. در کل، نتیجه\u200cها پیشنهاد می\u200cدهند که در حال حاضر، پارادیگ\u200cهای پیش آموزشی dominant do not result in substantial pragmatic competence in our models.', 'ko': '예훈련 언어모델(LMs)이 NLP를 계속 주도함에 따라 우리는 이러한 모델에서 언어 능력의 깊이를 이해하는 것이 점점 중요해진다.본고에서 우리는 사전에 교육된 LMs의 어용 능력을 목표로 하고 언어 연결어와 관련된 어용학에 중점을 두었다.우리는 자연적으로 발생하는 데이터와 심리언어학의 통제된 입력을 결합하여 완형충전 테스트를 제정한다.우리는 모델이 언어용 단서를 사용하여 언어의 연결어를 예측하는 능력, 모델이 연결어와 관련된 의미를 이해하는 능력, 그리고 모델이 어느 정도에 인류가 연결어의 시간 동태에 대한 선호도를 나타냈는지 중점적으로 테스트했다.우리는 모델이 자연적으로 발생하는 데이터 배경에서 연결어를 잘 예측할 수 있지만 언어 환경을 제어하여 고급 언어의 단서를 분리할 때 모델의 민감성이 훨씬 낮다는 것을 발견했다.모델도 실질적인 인간형 시간 선호를 나타내지 못했다.전반적으로 연구 결과에 따르면 현재 우리 모델에서 주도적인 위치를 차지하는 훈련 전 모델은 실질적인 어용 능력을 형성하지 못했다.', 'tr': "횜흫ki bilim sistemasynda (LMs) NLP'i domine etm채ge dowam ed첵채r. Bu nusgalarda dili ukyplaryny흫 derinliklerini d체힊체nmek 철r채n m철h체m. Bu kagyzda, pragmatiklerde 철흫체nden bilim alyny힊lary흫 pragmatiklerine g철z 철흫체nde guruldyr첵arys. Bir dogry 첵aly g철r체n첵채n maglumatlary we psikololingwistiklerden 챌ykan i챌eri kontrol edilen 챌yky힊lary ulanyp kloz stilini 챌ykar첵arys. Biz modelleri흫 pragmatik cuerlary흫 s철zle힊melerini 철nlemek 체챌in, nusgalary흫 bagla첵y힊laryny d체힊체nmek 체챌in ukyplaryny barla첵arys, we nusgalary흫 wagty흫 dinamiklary barada ynsanlary흫 tercihlerini g철rkezmegi 체챌in 체첵tged첵채n ukyplaryny barla첵arys. Munu흫 pikirim챌e modelleri흫 bagla첵y힊lary dogry 첵agda첵da gaty gowy 챌akla첵an bolsa-da, 첵okary dereje pragmatik cuerlary흫 we model du첵durlygy흫 철r채n a힊agy d체힊체r. Modeller 챌yky힊 zamanlar tercihleri 첵aly adama g철rkezmez. Adat챌a, netijeler 힊uwagt, domini첵an 철흫체nden 철흫체nden 철흫체nden 철흫체nden 철흫체nden 철흫체nden howply pragmatik ukyplarymyz d채ldir.", 'af': "As voor-opgelei taal modele (LMs) voortgaan om NLP te domineer, is dit meer belangrik dat ons die diepte van taal kapasiteite in hierdie modele verstaan. In hierdie papier, ons doen voor-opgelei LMs se kompetenceit in pragmatike, met 'n fokus op pragmatike wat betrekking tot diskurse verbindings. Ons formeer klose-styl toets deur te gebruik van 'n kombinasie van natuurlik voorkomde data en kontroleerde inputs wat van psyklinguistika geteken word. Ons fokus op die toets van modelle se kapasiteit om pragmatike tekens te gebruik om diskursie verbindings te voorskou, modelle se kapasiteit om implikature te verstaan met verbindings, en die uitbreiding waarmee modele menslike voorkeure aangaande tydelike dinamike van verbindings vertoon word. Ons vind dat alhoewel modele verbindings redelik goed voorskou in die konteks van natuurlik voorgekom data, wanneer ons konteks beheer om hoë vlak pragmatiske tekens te isolere, is model sensitiviteit baie minder. Models moet ook nie substantiele menslike tydelike voorkeure vertoon nie. In die hele manier, die gevinde beveel dat vandag dominante voor-oerwinning paradigme nie in substantiele pragmatiske kompetensie in ons modele resulteer nie.", 'am': 'ቀድሞ ተማሪ የቋንቋ ምሳሌዎች (LMs) በNLP ላይ እንዲገዛ እንደገና፣ የቋንቋ ችሎታችንን ጥልቅ እናስተውል ማለት በጣም muhimu ነው፡፡ በዚህ ፕሮግራም፣ አስቀድሞ የተማረዱትን የኤምሲን ባለሥልጣን እናስመክራለን፡፡ እና ከpsycholinguistic ጥያቄ የተለየውን ዳታ እና የተቆጣጠረውን ጥያቄዎች እናደርጋለን፡፡ የአካባቢ ግንኙነት፣ የሞዴል ግንኙነት ግንኙነትን ለመቀበል እናስቀምጣለን፡፡ ምሳሌዎች በአካባቢነት የሚሆነውን ዳራዎች በተለየ ጥሩ ሲያያጋራሉ እናገኛለን፡፡ ሞዴል ደግሞ አካባቢ የሰው ምርጫዎች እንደሚያሳዩ አያሳዩም፡፡ በሙሉ፣ ፍላጎቹ አሁን፣ አስቀድሞ ትምህርት የነበሩ ተማሪዎች ተማሪዎች በዓይነታችን አካባቢ ስልጣን አያደርግም፡፡', 'sw': 'Wakati mifano ya lugha zilizofunzwa kabla (LMs) inaendelea kuitawala NLP, ni muhimu zaidi kwamba tunaelewa kina cha uwezo wa lugha katika mifano hii. Katika karatasi hii, tunalenga ushirikiano wa LMs wa zamani wa mafunzo katika mazungumzo, wenye lengo la mazungumzo yanayohusiana na uhusiano wa mazungumzo. Tunaweza kutengeneza mtihani wa kufungia kwa kutumia muunganiko wa taarifa zinazotokea asili na zile zinazodhibitiwa kutoka kwenye lugha ya kisaikolojia. Tuna lengo la kujaribu uwezo wa mifano kutumia vifaa vya mazungumzo ili kutabiri uhusiano wa mazungumzo, uwezo wa mifano kuelewa maajabu yanayohusiana na uhusiano, na kwa kiwango ambacho mifano inaonyesha vipaumbele vya binadamu kama vile vipaumbele kuhusu utaratibu wa muda mfupi wa mawasiliano. Tunapata kwamba ingawa mifano inatabiri uhusiano vizuri katika muktadha wa taarifa za asili zinazotokea, tunapodhibiti michoro ya kutenga vifaa vya juu, hali ya msingi ni chini sana. Vilevile vile hawaonyeshi vipaumbele vya binadamu vikubwa kama vile nyakati. Kwa ujumla, matokeo hayo yanapendekeza kwamba kwa sasa, wanachama maarufu wa mafunzo ya kabla hayajasababisha uwezo mkubwa wa utawala katika mifano yetu.', 'sq': 'Ndërsa modelet e gjuhëve të paratrajnuara (LMs) vazhdojnë të mbizotërojnë NLP, është gjithnjë e më e rëndësishme që ne të kuptojmë thellësinë e aftësive gjuhësore në këto modele. Në këtë letër, ne synojmë kompetencën e LMs të paratrajnuara në pragmatikë, me përqëndrim në pragmatikën lidhur me lidhjet diskursore. Ne formojmë teste me stil kloze duke përdorur një kombinim të të dhënave që ndodhin natyralisht dhe të dhënave të kontrolluara të tërhequra nga psikologjika. Ne përqëndrohemi në testimin e aftësisë së modeleve për të përdorur shenja pragmatike për të parashikuar lidhjet diskursore, aftësinë e modeleve për të kuptuar implikimet lidhur me lidhjet e lidhjeve dhe shkallën në të cilën modelet tregojnë preferenca njerëzore lidhur me dinamikën temporale të lidhjeve. Ne zbulojmë se megjithëse modelet parashikojnë lidhjet mjaft mirë në kontekstin e të dhënave që ndodhin natyralisht, kur ne kontrollojmë kontekstet për të izoluar shenjat pragmatike të nivelit të lartë, ndjeshmëria e modelit është shumë më e ulët. Modelet gjithashtu nuk tregojnë preferenca thelbësore të përkohshme si njerëzit. Në përgjithësi, përfundimet sugjerojnë se në këtë moment paradigmat mbizotëruese të paratrainimit nuk rezultojnë në kompetencë pragmatike thelbësore në modelet tona.', 'hy': "Քանի որ նախապատրաստված լեզվի մոդելները շարունակում են գերիշխում ՆԼՊ-ին, ավելի կարևոր է, որ մենք հասկանանք այս մոդելների լեզվի ունակությունների խորությունը: In this paper, we target pre-trained LMs' competence in pragmatics, with a focus on pragmatics relating to discourse connectives.  Մենք ձևավորում ենք փորձարկումներ, որոնք օգտագործում են բնական տեղի ունեցող տվյալների և հոգեբանության կողմից վերահսկվող ներմուծների համակցությունը: Մենք կենտրոնանում ենք մոդելների փորձարկումների հնարավորության վրա, որպեսզի օգտագործենք պրագմատիկ նշաններ խոսակցական կապերի կանխատեսելու համար, մոդելների հնարավորության հասկանալ կապերի հետ կապված հետևանքները, և այն չափի վրա, որպեսզի մոդելները ցույց Մենք հայտնաբերում ենք, որ չնայած որ մոդելները բավականին լավ կանխատեսում են կապերը բնական տվյալների կոնտեքստում, երբ մենք վերահսկում ենք կոնտեքստները բարձր մակարդակի պրագմատիկ նշանների մեկուսացման համար, մոդելը զգացմունքը շատ ավելի ցածր է Մոդելները նույնպես չեն ցույց տալիս մարդկային նման ժամանակական նախընտրություններ: Ընդհանուր առմամբ, արդյունքները ցույց են տալիս, որ ներկայիս գերիշխող նախապատրաստման պարադիգմերը չի հանգեցնում մեր մոդելների պրագմատիկ հնարավորություններին:", 'bn': 'পূর্ব প্রশিক্ষিত ভাষার মডেল (এলএমএস) এনএলপিকে ক্ষমতা প্রদান করার চেষ্টা করছে, এটা বেশি গুরুত্বপূর্ণ যে আমরা এই মডেলের ভাষার ক্ষমতা এই কাগজটিতে আমরা প্রশিক্ষিত এলমিসের পূর্বপুরো প্রশিক্ষণের ক্ষমতার লক্ষ্য রাখি, যেখানে কথোপকথনের সংযোগের সাথে যোগাযোগের কথ আমরা স্বাভাবিকভাবে সংঘটিত তথ্য এবং নিয়ন্ত্রণিত ইনপুটের মানসিক ভাষার কাছ থেকে আঁকা ইনপুট ব্যবহার করে ক্লোজ-শৈলীর পর কথোপকথনের সংযোগ, মডেলের সাথে যোগাযোগের প্রভাব সম্পর্কে বুঝতে পারার জন্য আমরা মডেল পরীক্ষার ক্ষমতার উপর মনোযোগ দিচ্ছি এবং মোডেলের সাথে যোগাযোগের সাথে যোগাযোগ আমরা খুঁজে পাচ্ছি যে যদিও মডেলগুলো স্বাভাবিক সংক্রান্ত তথ্যের প্রেক্ষাপটে ভালোভাবে যোগাযোগের কথা ভবিষ্যৎবাণী করে, যখন আমরা উচ্চ-স্তরের প্র এছাড়াও মোডেল মানুষের মাধ্যমে সাময়িক পছন্দ প্রদর্শন করে না। সাধারণত, এই পরিস্থিতির পরামর্শ প্রদান করা হয়েছে যে বর্তমানে ক্ষমতাশালী প্রশিক্ষণের প্যারাডিমেন্ট আমাদের মডেলে প্রযুক্ত', 'az': 'Əvvəlcə təhsil edilmiş dil modelləri NLP hökmünü daxil edib, bu modellərdə dil qabiliyyətlərinin derinliklərini anlamaq daha çox mövcuddur. Bu kağızda, pragmatiklərlə əvvəlcə təhsil edilmiş LMs-lərin pragmatiklərini təşkil edirik, söhbət bağlantılarıyla bağlı pragmatiklərə odaqlanırıq. Biz, doğal olaraq gələn məlumatların və psikololingwistiklərdən çıxarılan inputlərin kombinatsiyası ilə kloz stili testlərini formüləyirik. Biz modellərin pragmatik əlamətlərini istifadə etmək üçün danışma bağlantılarını, modellərin bağlantıları ilə bağlantıları anlama gücünü və modellərin temporal dinamik haqqında insanlar kimi seçimləri göstərməsi üçün təsirlərini təmin edirik. Modellər təbiətli olaraq gələn məlumatların məlumatlarının məlumatlarına çox yaxşı tərzdə bağlantıları öyrənməsə də, yüksək seviyyətli pragmatik məlumatların tərzlərini təşkil etmək üçün müxtəlif məlumatları təşkil etdiyimiz zaman, modellərin duyarlığı çox düşür. Modellər də vaxtlı seçimlər kimi çox insanlıq göstərməz. Əlbəttə, sonuçlar, həmin vaxt, dominantlı öyrənmə paradigləri modellərimizdə çox pragmatik mümkün olmadığını göstərir.', 'bs': 'Kako predobučeni jezički modeli (LMs) nastavljaju dominirati NLP, sve je važnije da razumijemo dubinu jezičkih sposobnosti u ovim modelima. U ovom papiru, ciljamo nadležnost predobučenih LMs-a na pragmatiku, s fokusom na pragmatiku u vezi sa vezama diskursa. Formuliramo testove kloznog stila koristeći kombinaciju prirodno pojavljivih podataka i kontroliranih ulaganja iz psihologistike. Fokusiramo se na sposobnost testiranja modela da koristimo pragmatične znakove kako bi predvidjeli veze s diskursima, sposobnost modela da razumijemo implikacije vezane sa povezivanjem, i u mjeri u kojoj modeli pokazuju ljudske preferencije u vezi privremene dinamike veza. Pronašli smo da, iako modeli razumno dobro predviđaju veze u kontekstu prirodno događajućih podataka, kada kontroliramo kontekste izolovanja pragmatičnih znakova na visokom nivou, osjetljivost modela je mnogo niža. Modeli takođe ne pokazuju značajne ljudske preferencije kao privremene. U ukupnom slučaju, nalazi sugeriraju da trenutno dominantne paradigme pre obuke ne rezultuju značajnu pragmatsku kompetenciju u našim modelima.', 'et': 'Kuna NLP domineerivad endiselt eelõpetatud keelemudelid, on üha olulisem mõista nende mudelite keeleoskuse sügavust. Käesolevas töös keskendume eelkoolitud LMide pragmaatika pädevusele, keskendudes diskursuse sidemetega seotud pragmaatikale. Me sõnastame kloze-stiilis teste, kasutades kombinatsiooni looduslikest andmetest ja kontrollitud sisenditest, mis on saadud psühholingvistikast. Me keskendume mudelite suutlikkuse testimisele kasutada pragmaatilisi vihjeid diskursuse sidemete prognoosimiseks, mudelite suutlikkusele mõista sidemetega seotud mõjusid ja sellele, mil määral mudelid näitavad inimlikke eelistusi sidemete ajalise dünaamika suhtes. Leiame, et kuigi mudelid ennustavad looduslike andmete kontekstis sidemeid üsna hästi, on mudeli tundlikkus palju madalam, kui kontrollime kontekste kõrgetasemeliste pragmaatiliste vihjete isoleerimiseks. Mudelid ei näita ka olulisi inimlikke ajalisi eelistusi. Kokkuvõttes näitavad tulemused, et praegu ei too domineerivad koolituseelsed paradigmad meie mudelites kaasa märkimisväärset pragmaatilist pädevust.', 'fi': 'Koska esikoulutetut kielimallit hallitsevat edelleen NLP:t채, on yh채 t채rke채mp채채 ymm채rt채채 n채iden mallien kielitaitojen syvyys. T채ss채 ty철ss채 keskityt채채n esikoulutettujen LM:n pragmatiikkaosaamiseen keskittyen diskurssiyhteyksiin liittyv채채n pragmatiikkaan. Muodostamme klozetyylisi채 testej채 k채ytt채m채ll채 luonnollista dataa ja psykolingvistiikasta saatuja kontrolloituja sy철tteit채. Keskitymme testaamaan mallien kyky채 k채ytt채채 pragmaattisia vihjeit채 diskurssikytkent철jen ennustamiseen, mallien kyky채 ymm채rt채채 kytkent철ihin liittyvi채 implikaatioita ja miss채 m채채rin mallit osoittavat inhimillisi채 mieltymyksi채 kytkent철jen ajalliseen dynamiikkaan n채hden. Havaitsemme, ett채 vaikka mallit ennustavat yhteyksi채 kohtuullisen hyvin luonnossa esiintyv채n datan yhteydess채, kun kontrolloimme konteksteja erist채채ksemme korkean tason pragmaattisia vihjeit채, mallin herkkyys on paljon pienempi. Mallit eiv채t my철sk채채n osoita merkitt채vi채 inhimillisi채 ajallisia mieltymyksi채. Kaiken kaikkiaan tulokset viittaavat siihen, ett채 t채ll채 hetkell채 hallitsevat esikoulutuksen paradigmat eiv채t johda malliemme huomattavaan pragmaattiseen osaamiseen.', 'cs': 'Vzhledem k tomu, že předškolené jazykové modely (LM) nadále dominují NLP, je stále důležitější, abychom pochopili hloubku jazykových schopností v těchto modelech. V tomto článku se zaměřujeme na předškolené kompetence LM v pragmatice se zaměřením na pragmatiku vztahující se k diskurzním konektivům. Formulujeme cloze-style testy s využitím kombinace přirozeně se vyskytujících dat a kontrolovaných vstupů čerpaných z psycholingvistiky. Zaměřujeme se na testování schopnosti modelů používat pragmatická nápověda k predikci diskurzních konektivů, schopnosti modelů porozumět implikacím týkajícím se konektivů a míry, do jaké modely ukazují lidské preference ohledně časové dynamiky konektivů. Zjišťujeme, že ačkoli modely předpovídají konektivy poměrně dobře v kontextu přirozeně se vyskytujících dat, když kontrolujeme kontexty za účelem izolace pragmatických návodů na vysoké úrovni, citlivost modelu je mnohem nižší. Modely také nevykazují podstatné lidské časové preference. Zjištění celkově naznačují, že v současné době dominantní paradigmata předškolení nevede k podstatné pragmatické kompetenci v našich modelech.', 'ca': "Mentre els models de llenguatge pré-entrenats segueixen dominant la NLP, és cada vegada més important que entenguem la profunditat de les capacitats de llenguatge d'aquests models. En aquest paper, ens centrem en la capacitat de les LMs pré-formades en la pragmàtica, centrant-nos en les pragmàtiques relacionades amb els connectius de discurs. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from psycholinguistics.  Ens centrem en provar l'habilitat dels models d'utilitzar indicacions pragmàtiques per predir connexions de discurs, l'habilitat dels models d'entendre implicacions relacionades amb connexions i el punt en què els models mostren preferències humanes en relació amb la dinàmica temporal dels connexions. Trobem que malgrat que els models predien les connexions raonablement bé en el context de dades naturals, quan controlem els contextos per aïllar indicis pragmàtics d'alt nivell, la sensibilitat al model és molt més baixa. Els models tampoc mostren preferències substancialscom les temporals. En general, els descobriments suggereixen que actualment els paradigmes dominants de pré-formació no donen lloc a una competencia pragmàtica substancial en els nostres models.", 'jv': "Sampeyan model sing preliminé, ingkang sampeyan luwih dumadhi NLP, dadi luwih dumadhi kanggo awak dhéwé kuwi tindakan kapasituran kanggo model iki. Nang pepul iki, kita tuku nggawe kelas akeh luwih dumadhi Lan ingkang prag-ingkang, lan nganggo langgambar kuwi prag-ingkang nggawe barang langgambar Awak dhéwé ngeralakno pancen close-style Awak dhéwé éntuk nggunakaé testing model' kapan kanggo nggunakaé pragmulaten dumateng, supoyo nggawe barang kelanganan model kuwi nggawe barang sampeyan ingkang sampeyan karo konnek sampeyan, lan akeh sampeyan nganggep model sing usul dumateng manyak layang langgar sampeyan dumateng modèl Awak dhéwé luwih akeh model kuwi nggawe akeh sampeyan luwih dumadhi sak ngono data cekelan model Manyak gak bener, maneh dumadhan kang terus-terus popularan Pak hal-hal, akeh mbukakipun sumungane kuwi, nik awak dhéwé iso mulasah karo paké, nik awak dhéwé kuwi model sing apik dhéwé.", 'ha': "Kama da misãlai na zaman-wa'anar harshe (LM) za'a ƙara domin NLP, sai yana da muhimmi da mu fahimta kinan abincin harshe cikin wannan misalin. Ga wannan takardan, Munã kula da ma'abũcin LM'in da aka yi wa zaman-hakar a cikin mazaɓa, yana da fokus a kan mazaɓa masu husũma da haɗi ga mazaɓa. Tuna ƙayyade jarrabo-salon ƙarze da Muke amfani da koma cikin data masu cikin natura da za'a sami cikin taƙaita daga linguistics. Tuna fokus a kan jarraba misalin ayuka da za'a yi amfani da nau'in abubuwa dõmin ka yi bayani ga haɗi da mazaɓa, abincin motel ya fahimta masu husu'a da haɗi, da gwargwadon da misalin za'a nuna masu motsi kamar son mutane a kan sauri-dandiyoyi na haɗi. Muna gane cewa, kuma kõ da misãlai sun yi bashi yana haɗi da shi mai kyau a cikin muhimman data masu fara-faɗi, idan za mu yi mamlaka da tarakin da za'a kiyaye nau'in-daraja, sai zafi masu ƙaranci. @ info: whatsthis Kila da haka, fassaran yana son cẽwa, a yanzu, paradigm masu tawada da ke gabani, bã ya halatta ga matsayin prajiki mai girma a cikin misalinmu.", 'bo': "སྔོན་གྲངས་བསླབས་པའི་སྐད་ཡིག་གཟུགས་རིས་ལྟར་འགྲོ་བ་ཀྱི་མིག་དཔེ་ལ་དག་གི་འགྱུར་བར་གལ་ཆེ་བས་ཡོད། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འོང་ཚོས་སྔོན་སྒྲིག་འཛིན་པའི་དུས་ཚོད་སྒེར་གྱི་རང་ཉིད་ཀྱི་ཁྱོད་རས་གནང་བ ང་ཚོས་རང་བཞིན་གྱིས་འབྱུང་བའི་ཆ་འཕྲིན་དང་ལྟ་བུའི་ནང་བཙུགས་སྟངས་ལ་བསྟར་ཐབས་ཤིག་ཐབས་བྱས་པ་རེད། We focus on testing models' ability to use pragmatic cues to predict discourse connectives, models' ability to understand implicatures relating to connectives, and the extent to which models show humanlike preferences regarding temporal dynamics of connectives. ང་ཚོའི་མིག་དཔེ་གཟུགས་རིས་སྔོན་འཛུགས་པའི་སྦྲེལ་མཐུད་དེ་རྟོགས་པ་སྦེ། མིག་དབྱིབས་ཡིག་ཆ་དེ་ལ་མི་རྒྱུན་ལྡན་གྱི་རང་མོས་སྒྲིག་འགོད་དང་མཐོ་རུང་བ་མངོན་མི་བྱེད་པ ཡོངས་ཁྱད་པར་ཕྲན་ཚོགས་ནི་ད་ལྟ་བུའི་སྔོན་གྲངས་སྒྲིག་གི་སྔོན་གྲངས་བསྒྲིག་སྟངས་ལ་རྐྱེན་པའི་སྟོན་རྩན་བྱས་མེད་འདུག", 'sk': 'Ker predhodno usposobljeni jezikovni modeli še naprej prevladujejo NLP, je vse pomembneje, da razumemo globino jezikovnih zmogljivosti teh modelov. V prispevku smo usmerili kompetence vnaprej usposobljenih LM na področju pragmatike s poudarkom na pragmatiki, ki se nanaša na diskurzne povezave. S kombinacijo naravno prisotnih podatkov in nadzorovanih vložkov iz psiholingvistike oblikujemo kloze-stilske teste. Osredotočamo se na testiranje sposobnosti modelov, da uporabljajo pragmatične namige za napovedovanje diskurznih povezav, sposobnosti modelov, da razumejo implikacije, povezane s povezavami, in obseg, v katerem modeli kažejo človeške preference glede časovne dinamike povezav. Ugotavljamo, da je občutljivost modela precej nižja, čeprav modeli v kontekstu naravno prisotnih podatkov razumno dobro napovedujejo povezave, kadar kontekste nadziramo za izolacijo pragmatičnih znakov na visoki ravni. Modeli prav tako ne kažejo znatnih časovnih preferenc človeku. Na splošno ugotovitve kažejo, da trenutno prevladujoče paradigme pred usposabljanjem ne prinašajo bistvene pragmatične kompetence v naših modelih.', 'he': "כפי שדוגמני שפה מאומנים מראש (LMs) ממשיכים לשלוט NLP, חשוב יותר ויותר שאנחנו מבינים את עמוק היכולות לשפה במדוגמנים אלה. In this paper, we target pre-trained LMs' competence in pragmatics, with a focus on pragmatics relating to discourse connectives.  אנחנו נוצרים בדיקות בסגנון הפסיכולוגיה באמצעות שילוב של נתונים מתרחשים בטבעי והכניסות שולטות ששולטות מהפסיכולוגיה. We focus on testing models' ability to use pragmatic cues to predict discourse connectives, models' ability to understand implicatures relating to connectives, and the extent to which models show humanlike preferences regarding temporal dynamics of connectives.  אנו מוצאים שאם דוגמנים חושפים את הקשר היטב בקשר למידע שקורה באופן טבעי, כשאנחנו שולטים בקשר לבודד סימנים פרגמטיים ברמה גבוהה, רגישות דוגמנית הרבה יותר נמוכה. דוגמנים גם לא מראים עדיפות זמניות משמעותיות כמו בני אדם. באופן כללי, הממצאים מצביעים כי כרגע, פרדיגמים שליטיים לפני האימון לא גורמים למיומנות פרגמטית משמעותית בדוגמנים שלנו."}
{'en': 'Scaffolded input promotes atomic organization in the recurrent neural network language model', 'ar': 'تعزز المدخلات المقيدة التنظيم الذري في نموذج لغة الشبكة العصبية المتكررة', 'fr': "L'entrée échafaudée favorise l'organisation atomique dans le modèle de langage de réseau neuronal récurrent", 'es': 'La entrada estructurada promueve la organización atómica en el modelo de lenguaje de red neuronal recurrente', 'ja': '足場かけ入力は、再帰的ニューラルネットワーク言語モデルにおける原子の組織化を促進する', 'pt': 'A entrada com andaime promove a organização atômica no modelo de linguagem de rede neural recorrente', 'zh': '脚手架输循环神经网络言语原子', 'hi': 'Scaffolded इनपुट आवर्तक तंत्रिका नेटवर्क भाषा मॉडल में परमाणु संगठन को बढ़ावा देता है', 'ga': 'Cuireann ionchur scafall eagrú adamhach chun cinn i múnla teanga an líonra néaraigh athfhillteach', 'ru': 'Входные данные с каркасом способствуют организации атомов в рекуррентной модели языка нейронной сети', 'ka': 'Name', 'hu': 'Az állványozott bemenet elősegíti az atomszerveződést a visszatérő neurális hálózati nyelvmodellben', 'it': "L'input impalcato promuove l'organizzazione atomica nel modello di linguaggio della rete neurale ricorrente", 'kk': 'Скаффелделген кіріс қайталанатын невралды желі тіл үлгісінде атомдық құрылымды өзгертеді', 'lt': 'Scaffolded input promotes atomic organization in the recurrent neural network language model', 'ms': 'Input berfungsi mempromosikan organisasi atomik dalam model bahasa rangkaian saraf yang berulang', 'el': 'Η σκαλωσιακή εισαγωγή προωθεί την ατομική οργάνωση στο επαναλαμβανόμενο μοντέλο γλώσσας νευρικών δικτύων', 'ml': 'വീണ്ടും വരുന്ന നെയുറല്\u200d നെറുറല്\u200d നെറ്റാള്\u200d ഭാഷ മോഡലില്\u200d ആറ്റാമിക് സംഘടനയെ പ്രോമേജ് ചെയ്യുന്നു', 'mt': 'Scaffolded input promotes atomic organization in the recurrent neural network language model', 'pl': 'Scaffolded wejście promuje organizację atomową w modelu języka powtarzającej się sieci neuronowej', 'mn': 'Скафлолд орлуулалт нь дахин сэтгэл сүлжээний хэл загварын атомын байгууллагуудыг дэмжиж,', 'sr': 'Skafoldirani ulaz promovira atomsku organizaciju u recidivnom modelu neuralne mreže', 'ro': 'Intrarea schelată promovează organizarea atomică în modelul de limbaj recurent al rețelei neurale', 'si': 'Name', 'sv': 'Ställd ingång främjar atomorganisation i den återkommande neurala nätverksspråkmodellen', 'ta': 'மீண்டும் நிகழ்ந்த புதிய பிணைய மொழி மாதிரியில் அணுகல் நிறுவனத்தை உயர்த்துகிறது', 'mk': 'Скафлодираниот внес промовира атомска организација во рецидентниот модел на неурална мрежа јазик', 'ur': 'اسکافولڈ اینٹ پی نٹ ورل کی زبان موڈل میں اتمیک سازمان کو پیدا کرتا ہے', 'no': 'Skalert inndata forekommer atomorganisasjon i den gjentaande neuralnettverksspråk- modellen', 'so': 'Shirkadaha la xiriiray waxey horumariyaa urur nuurka ah oo ku qoran tilmaanka afka neurada ee soo socda', 'uz': 'Qaytarilgan tarmoq tili modelidagi atomik tarmoqni foydalanadi', 'vi': 'Tin vào thần rừng thúc đẩy tổ chức nguyên tử trong mô hình ngôn ngữ mạng thần kinh thường xuyên', 'bg': 'Скафолд вход насърчава атомната организация в повтарящия се модел на езика на невронната мрежа', 'nl': 'Gestructureerde input bevordert atomaire organisatie in het terugkerende neurale netwerktaalmodel', 'da': 'Stilladsinput fremmer atomorganisation i den tilbagevendende neurale netværkssprogmodel', 'de': 'Scaffolded Input fördert die atomare Organisation im wiederkehrenden Sprachmodell neuronaler Netze', 'hr': 'Skafolded input promovira atomsku organizaciju u recidivnom modelu jezika neurone mreže', 'id': 'Masukan Scaffolded mempromosikan organisasi atom dalam model bahasa jaringan saraf yang berkurang', 'sw': 'Vifaa vilivyopangwa vinasangaza shirika la atomi katika mtindo wa lugha ya kijamii unaoendelea', 'tr': 'Garaşan girdi tekrarly nuýal dilinde atom organizasyny töwekgelýär', 'ko': '귀속 신경 네트워크 언어 모델에서 브래킷 입력은 원자 조직을 촉진시켰다', 'fa': 'ورودی اسکافولد سازمان اتمی در مدل زبان شبکه عصبی تکرار می\u200cکند', 'af': 'Name', 'sq': 'Shfaqja Scaffolded nxit organizatën atomike në model in e gjuhës së rrjetit neural të përsëritur', 'am': 'አካባቢ ድርጅት በሁለተኛ የደዌብ መረብ ቋንቋ model ውስጥ ያበረታል', 'hy': 'Սկաֆոլդված ներմուծը խրախուսում է ատոմային կազմակերպությունը կրկնվող նյարդային ցանցի լեզվի մոդելի մեջ,', 'az': 'S…ôhifli giriŇü atom organizasiyasńĪnńĪ tekrarlńĪ n√∂ral Ňü…ôb…ôk…ô dili modelind…ô t…ôŇükil edir', 'bn': 'পুনরাবার নিউরেল নেটওয়ার্ক ভাষার মডেলে আটকিক সংস্থার প্রচার করেছে', 'bs': 'Skafolded input promovira atomsku organizaciju u recidivnom modelu jezika neuralne mreže', 'ca': "L'entrada Scaffolded promou l'organització atòmica en el model recurrent de llenguatge de la xarxa neural", 'fi': 'Scaffolded input edistää atomien organisointia toistuvassa neuroverkon kielimallissa', 'et': 'Scaffold sisend soodustab aatomiorganisatsiooni korduva närvivõrgu keele mudelis', 'cs': 'Scaffoldovaný vstup podporuje atomovou organizaci v recidivním jazykovém modelu neuronové sítě', 'jv': 'Advance', 'ha': "Fitarwa da aka samu tsarin atomic cikin misalin harshen harshe na'urar da aka daura", 'sk': 'Odrski vhod spodbuja atomsko organizacijo v ponavljajočem se jezikovnem modelu nevronskega omrežja', 'he': 'Scaffolded input promotes atomic organization in the recurrent neural network language model', 'bo': 'Scaffolded input promotes atomic organization in the recurrent neural network language model'}
{'en': 'The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data. Despite its enormous success in representing  lexical sequences , little is known about the quality of the  lexical representations  that it acquires. In this work, we conjecture that it is straightforward to extract  lexical representations  (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information. We conceptualize this limitation of the RNN as a failure to learn atomic internal states-states which capture information relevant to single word types without being influenced by redundant information provided by words with which they co-occur. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.', 'ar': 'يعد نموذج لغة الشبكة العصبية المتكررة (RNN) أداة قوية لتعلم التبعيات المتسلسلة التعسفية في بيانات اللغة. على الرغم من نجاحها الهائل في تمثيل المتواليات المعجمية ، لا يُعرف سوى القليل عن جودة التمثيلات المعجمية التي تكتسبها. في هذا العمل ، نفترض أنه من السهل استخراج التمثيلات المعجمية (أي تضمين الكلمة الثابتة) من RNN ، لكن كمية المعلومات الدلالية التي يتم ترميزها تكون محدودة عندما توفر العناصر المعجمية في بيانات التدريب معلومات دلالية زائدة عن الحاجة. نحن نصور هذا التقييد لـ RNN على أنه فشل في تعلم الحالات الداخلية الذرية - الحالات التي تلتقط المعلومات ذات الصلة بأنواع الكلمات المفردة دون أن تتأثر بالمعلومات الزائدة التي توفرها الكلمات التي تحدث معها. باستخدام مجموعة من اللغة الاصطناعية ، نتحقق من أن التكرار في بيانات التدريب ينتج حالات داخلية غير ذرية ، ونقترح طريقة جديدة لتحفيز الحالات الداخلية الذرية. نوضح أن 1) طريقتنا تحفز بنجاح التنظيم الداخلي الذري في التجارب الخاضعة للرقابة ، و 2) في ظل ظروف أكثر واقعية حيث يتكون التدريب من لغة موجهة للأطفال ، فإن تطبيق طريقتنا يحسن أداء التمثيلات المعجمية في مهمة التصنيف الدلالي النهائية. .', 'es': 'El modelo de lenguaje de redes neuronales recurrentes (RNN) es una herramienta poderosa para aprender dependencias secuenciales arbitrarias en los datos del idioma. A pesar de su enorme éxito en la representación de secuencias léxicas, poco se sabe sobre la calidad de las representaciones léxicas que adquiere. En este trabajo, suponemos que es sencillo extraer representaciones léxicas (es decir, incrustaciones de palabras estáticas) de una RNN, pero que la cantidad de información semántica que se codifica es limitada cuando los elementos léxicos de los datos de entrenamiento proporcionan información semántica redundante. Conceptualizamos esta limitación de la RNN como un fracaso en el aprendizaje de estados atómicos internos, estados que capturan información relevante para tipos de palabras individuales sin ser influenciados por información redundante proporcionada por palabras con las que coexisten. Utilizando un corpus de lenguaje artificial, verificamos que la redundancia en los datos de entrenamiento produce estados internos no atómicos, y proponemos un método novedoso para inducir estados internos atómicos. Demostramos que 1) nuestro método induce con éxito la organización interna atómica en experimentos controlados, y 2) en condiciones más realistas en las que el entrenamiento consiste en un lenguaje dirigido por niños, la aplicación de nuestro método mejora el rendimiento de las representaciones léxicas en una semántica descendente tarea de categorización.', 'pt': 'O modelo de linguagem de rede neural recorrente (RNN) é uma ferramenta poderosa para aprender dependências sequenciais arbitrárias em dados de linguagem. Apesar de seu enorme sucesso na representação de sequências lexicais, pouco se sabe sobre a qualidade das representações lexicais que adquire. Neste trabalho, conjecturamos que é simples extrair representações lexicais (ou seja, embeddings de palavras estáticas) de uma RNN, mas que a quantidade de informação semântica codificada é limitada quando itens lexicais nos dados de treinamento fornecem informações semânticas redundantes. Conceituamos essa limitação do RNN como uma falha em aprender estados internos atômicos - estados que capturam informações relevantes para tipos de palavras únicas sem serem influenciados por informações redundantes fornecidas por palavras com as quais elas ocorrem. Usando um corpus de linguagem artificial, verificamos que a redundância nos dados de treinamento produz estados internos não atômicos e propomos um novo método para induzir estados internos atômicos. Mostramos que 1) nosso método induz com sucesso a organização interna atômica em experimentos controlados, e 2) sob condições mais realistas em que o treinamento consiste em linguagem dirigida à criança, a aplicação de nosso método melhora o desempenho de representações lexicais em uma tarefa de categorização semântica a jusante .', 'ja': '再帰ニューラルネットワーク（ ＲＮＮ ）言語モデルは、言語データにおける任意の順序依存性を学習するための強力なツールである。 語彙配列を表すのに非常に成功しているにもかかわらず、それが獲得する語彙表現の質についてはほとんど知られていない。 この研究では、RNNから語彙表現（すなわち、静的な単語埋め込み）を抽出することは簡単であるが、訓練データ内の語彙項目が冗長な意味情報を提供する場合、符号化される意味情報の量が制限されると推測する。 我々は、RNNのこの制限を、原子内部状態（単一の単語タイプに関連する情報を、それらが共存する単語によって提供される冗長な情報の影響を受けることなく取り込む状態）を学習することの失敗として概念化する。 人工言語のコーパスを使用して、訓練データの冗長性が非原子内部状態をもたらすことを検証し、原子内部状態を誘導するための新たな方法を提案する。 私たちは、1 ）制御された実験で私たちの方法が原子内部組織をうまく誘導することを示し、2 ）トレーニングが児童向け言語で構成されるより現実的な条件下で、私たちの方法を適用することで、下流の意味分類タスクでの語彙表現のパフォーマンスが向上することを示します。', 'hi': 'आवर्ती तंत्रिका नेटवर्क (आरएनएन) भाषा मॉडल भाषा डेटा में मनमाने ढंग से अनुक्रमिक निर्भरता सीखने के लिए एक शक्तिशाली उपकरण है। लेक्सिकल अनुक्रमों का प्रतिनिधित्व करने में इसकी भारी सफलता के बावजूद, इसे प्राप्त करने वाले लेक्सिकल अभ्यावेदन की गुणवत्ता के बारे में बहुत कम जाना जाता है। इस काम में, हम अनुमान लगाते हैं कि आरएनएन से लेक्सिकल अभ्यावेदन (यानी स्थैतिक शब्द एम्बेडिंग) को निकालना सीधा है, लेकिन यह कि एन्कोडेड शब्दार्थ जानकारी की मात्रा सीमित है जब प्रशिक्षण डेटा में लेक्सिकल आइटम अनावश्यक शब्दार्थ जानकारी प्रदान करते हैं। हम परमाणु आंतरिक राज्यों को सीखने में विफलता के रूप में आरएनएन की इस सीमा की अवधारणा करते हैं - राज्य जो उन शब्दों द्वारा प्रदान की गई अनावश्यक जानकारी से प्रभावित हुए बिना एकल शब्द प्रकारों के लिए प्रासंगिक जानकारी को कैप्चर करते हैं जिनके साथ वे सह-घटित होते हैं। कृत्रिम भाषा के एक कॉर्पस का उपयोग करते हुए, हम सत्यापित करते हैं कि प्रशिक्षण डेटा में अतिरेक गैर-परमाणु आंतरिक राज्यों की उपज देता है, और परमाणु आंतरिक राज्यों को प्रेरित करने के लिए एक उपन्यास विधि का प्रस्ताव करता है। हम दिखाते हैं कि 1) हमारी विधि सफलतापूर्वक नियंत्रित प्रयोगों में परमाणु आंतरिक संगठन को प्रेरित करती है, और 2) अधिक यथार्थवादी परिस्थितियों में जिसमें प्रशिक्षण में बाल-निर्देशित भाषा होती है, हमारी विधि का अनुप्रयोग एक डाउनस्ट्रीम शब्दार्थ वर्गीकरण कार्य पर लेक्सिकल प्रतिनिधित्व के प्रदर्शन में सुधार करता है।', 'zh': '递归神经网络 (RNN) 言法者,学言数之任顺恃强大之具也。 虽取巨大成功于词法序,而人知之甚少于词法。 于此之中,推RNN取词法(即静词嵌)甚简,然当训练数中词法项供冗余语义信息,编码之语义信息量有限也。 吾以RNN之限概念化为不可学原子内 - 得与单单词相关者,不与同单词之冗余也。 用人工语言语料库,验练数之冗余,非原子内也,设诱原子内之新法。 吾明1)吾道之于实验也,诱之于原子内也,2)之于童子之言也,以吾道成于下流语义类词汇也。', 'fr': "Le modèle de langage du réseau neuronal récurrent (RNN) est un outil puissant pour apprendre des dépendances séquentielles arbitraires dans les données de langage. Malgré son énorme succès dans la représentation de séquences lexicales, on sait peu de choses sur la qualité des représentations lexicales qu'il acquiert. Dans ce travail, nous supposerons qu'il est simple d'extraire des représentations lexicales (c'est-à-dire des incorporations de mots statiques) à partir d'un RNN, mais que la quantité d'informations sémantiques codées est limitée lorsque les éléments lexicaux des données d'apprentissage fournissent des informations sémantiques redondantes. Nous concevons cette limitation du RNN comme un échec à apprendre les états internes atomiques - des états qui capturent des informations pertinentes pour des types de mots uniques sans être influencés par des informations redondantes fournies par des mots avec lesquels ils coapparaissent. À l'aide d'un corpus de langage artificiel, nous vérifions que la redondance des données d'apprentissage produit des états internes non atomiques, et proposons une nouvelle méthode pour induire des états internes atomiques. Nous montrons que 1) notre méthode induit avec succès une organisation interne atomique dans des expériences contrôlées, et 2) dans des conditions plus réalistes dans lesquelles la formation consiste en un langage dirigé par l'enfant, l'application de notre méthode améliore les performances des représentations lexicales sur une sémantique en aval tâche de catégorisation.", 'ga': 'Uirlis chumhachtach is ea samhail teanga an líonra néar-athfhillteaigh (RNN) chun spleáchais sheicheamhacha treallach ar shonraí teanga a fhoghlaim. In ainneoin a rath ollmhór maidir le seichimh foclóireachta a léiriú, is beag atá ar eolas faoi cháilíocht na léirithe foclóireachta a fhaigheann sé. Sa obair seo, measaimid go bhfuil sé simplí léirithe foclóireachta a bhaint as RNN (i.e. leabú focal statach) ó RNN, ach go bhfuil teorainn leis an méid faisnéise shéimeantach a ionchódaítear nuair a sholáthraíonn míreanna foclóireachta sna sonraí oiliúna faisnéis shéimeantach iomarcach. Déanaimid coincheapú ar an teorannú seo ar an RNN mar mhainneachtain stáit inmheánacha adamhacha a fhoghlaim - stáit a shealbhaíonn faisnéis a bhaineann le cineálacha focal aonair gan a bheith faoi thionchar an eolais iomarcach a sholáthraíonn focail a dtarlaíonn siad leo. Trí úsáid a bhaint as corpas teanga shaorga, dearbhaímid go n-eascraíonn iomarcaíocht sna sonraí oiliúna stáit inmheánacha neamh-adamhacha, agus molaimid modh nua chun stáit inmheánacha adamhach a aslú. Léirímid 1) go n-éiríonn lenár modh eagrú inmheánach adamhach i dturgnaimh rialaithe a aslú go rathúil, agus 2) faoi choinníollacha níos réadúla ina bhfuil an oiliúint comhdhéanta de theanga atá dírithe ar an leanbh, feabhsaíonn cur i bhfeidhm ár modh feidhmíocht léirithe foclóireachta ar thasc catagóirithe séimeantach iartheachtacha. .', 'ru': 'Языковая модель рекуррентной нейронной сети (RNN) является мощным инструментом для изучения произвольных последовательных зависимостей в языковых данных. Несмотря на огромный успех в представлении лексических последовательностей, мало что известно о качестве лексических представлений, которые он приобретает. В этой работе мы предполагаем, что легко извлечь лексические представления (т.е. статические вложения слов) из RNN, но что объем семантической информации, которая кодируется, ограничен, когда лексические элементы в обучающих данных предоставляют избыточную семантическую информацию. Мы концептуализируем это ограничение RNN как неспособность выучить атомные внутренние состояния - состояния, которые захватывают информацию, относящуюся к типам одного слова, не подвергаясь влиянию избыточной информации, предоставляемой словами, с которыми они совместно встречаются. Используя корпус искусственного языка, мы проверяем, что избыточность в обучающих данных приводит к неатомным внутренним состояниям, и предлагаем новый метод для индукции атомных внутренних состояний. Показано, что 1) наш метод успешно индуцирует атомную внутреннюю организацию в контролируемых экспериментах, и 2) в более реалистичных условиях, в которых обучение состоит из языка, ориентированного на ребенка, применение нашего метода улучшает выполнение лексических представлений на задаче нижележащей семантической категоризации.', 'ka': 'რეკურენტური ნეიროლური ქსელი (RNN) ენის მოდელი არის ძალიან ხელსაწყო, რომელიც ენის მონაცემებში არბრიტური სკენტური დასაწყვებელობების შესაძლებლობად. ლექსიკალური წარმატების გამოსახულებაში, მარტივი იცნობია ლექსიკალური გამოსახულებების კალექტაციაზე, რომელიც მიიღება. ამ სამუშაოში ჩვენ ვფიქრობთ, რომ ლექსიკალური გამოსახულებები (ან სტატიკალური სიტყვებები) RNN-დან გამოყენებულია, მაგრამ რომ სიმენტიკალური ინფორმაციის რაოდენობა, რომელიც კოდირებულია, უდრის, როცა ლექსიკალური ელ ჩვენ პროგრამის განსაზღვრება როგორც არომიკური ინტერული სტატუსების შეცდომა - სტატუსები, რომლებიც ინფორმაციას ერთი სიტყვის ტიპებისთვის შესაბამისი შესაბამისი სიტყვის შესაბამისი შესაბამი კულტური ენის კორპუსის გამოყენება, ჩვენ დავწერეთ, რომ განსწავლის მონაცემების გარკვეულება არატომიური ინტერესტური ქვეყნებში იქნება და ატუმენტიური ინტერესტური ქვეყნების გამოყენება. ჩვენ გამოჩვენებთ, რომ 1) ჩვენი მეტი წარმატებით ატომიური ინტერული ორგანიზაციას კონტროლურებული ექსპერიმენტებში, და 2) უფრო რეალური ღირებულებაში, რომლებიც განსწავლება ბავშვების მიერ ენაზე, ჩვენი მეტის გამოყენება', 'it': "Il modello di linguaggio della rete neurale ricorrente (RNN) è un potente strumento per imparare dipendenze sequenziali arbitrarie nei dati linguistici. Nonostante il suo enorme successo nel rappresentare sequenze lessicali, poco si sa sulla qualità delle rappresentazioni lessicali che acquisisce. In questo lavoro, supponiamo che sia semplice estrarre rappresentazioni lessicali (cioè incorporazioni statiche di parole) da un RNN, ma che la quantità di informazioni semantiche codificate sia limitata quando gli elementi lessicali nei dati di formazione forniscono informazioni semantiche ridondanti. Concettualizziamo questa limitazione dell'RNN come un fallimento nell'apprendimento degli stati interni atomici - stati che catturano informazioni rilevanti per i singoli tipi di parole senza essere influenzati da informazioni ridondanti fornite dalle parole con le quali esse coincidono. Utilizzando un corpus di linguaggio artificiale, verifichiamo che la ridondanza nei dati di addestramento produca stati interni non atomici, e proponiamo un nuovo metodo per indurre stati interni atomici. Dimostriamo che 1) il nostro metodo induce con successo l'organizzazione interna atomica in esperimenti controllati, e 2) in condizioni più realistiche in cui l'addestramento consiste nel linguaggio diretto dai bambini, l'applicazione del nostro metodo migliora le prestazioni delle rappresentazioni lessicali su un compito di categorizzazione semantica a valle.", 'kk': 'Қайталанған неврал желі (RNN) тіл моделі - тіл деректерінде тәуелдік тәуелдіктерді оқыту үшін күшті құрал. Лексикалық реттеулерді көрсету үшін оның үлкен сәттілігіне қарамастан, ол жеткізген лекскалық таңбалардың сапасы туралы білмейді. Бұл жұмыс ішінде, Лексикалық таңбаларды (яғни Статикалық сөздерді ендіру) RNN- ден шығару дегенді біз ойлаймыз, бірақ кодірілген семантикалық мәліметтердің саны шектеп тұрған кезде лексикалық мәліметтердің тегістерін шектеп береді. Біз бұл RNN шектеуді атомдық ішкі күйлерін үйрену сәтсіз деп ойлаймыз - бір сөз түрлеріне қатысты мәліметті сәйкес түрлеріне қатысты мәліметті сәйкес түрлеріне қатысты мәліметті түсі Бір тілдің корпус қолдану үшін біз бақылау деректерінің атомдық ішкі дәрежесі емес дегенді тексеріп, атомдық ішкі дәрежелерді жасау әдісін қолданамыз. Біз 1) әдіміміздің ішкі тәртібімізді бақылау тәртібінде атомдық ішкі тәртібінде, 2) бақылау тәртібінде бақылау тәртібінде, әдіміздің бағдарламасы келесі семантикалық категорияциялау тапсырмасында лексикалық', 'lt': 'The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data.  Despite its enormous success in representing lexical sequences, little is known about the quality of the lexical representations that it acquires.  In this work, we conjecture that it is straightforward to extract lexical representations (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information.  Mes suvokiame šį RNN apribojimą kaip nesugebėjimą mokytis atominių vidaus būklių - būklės, kuriose gaunama informacija, susijusi su vieno žodžio tipais, neturint įtakos nereikalingai informacijai, teikiamai žodžiais, su kuriais jie susiduria. Naudodami dirbtinės kalbos korpusą, tikriname, kad mokymo duomenų perteklius lemia ne atomines vidaus valstybes, ir siūlome naują atominių vidaus valstybių skatinimo metodą. Mes parodome, kad 1) mūsų metodas sėkmingai skatina kontroliuojamų eksperimentų atominę vidaus organizaciją, ir 2) realistiškesnėmis sąlygomis, kai mokymą sudaro vaikų orientuota kalba, mūsų metodo taikymas pagerina leksinių atstovavimų rezultatus atliekant tolesnę semantinę kategorijizacijos užduotį.', 'hu': 'A visszatérő neurális hálózat (RNN) nyelvmodell hatékony eszköz a nyelvi adatok tetszőleges szekvenciális függőségeinek tanulására. A lexikális szekvenciák ábrázolásának óriási sikere ellenére keveset tudunk az általa megszerzett lexikális reprezentációk minőségéről. Ebben a munkában feltételezzük, hogy egyszerű kivonni a lexikai reprezentációkat (azaz statikus szóbeágyazásokat) egy RNN-ből, de hogy a kódolt szemantikai információk mennyisége korlátozott, ha a képzési adatok lexikai elemei redundáns szemantikai információt nyújtanak. Az RNN ezt a korlátozását úgy fogalmazzuk meg, mint az atom belső állapotának elsajátításának elmulasztását - olyan állapotokat, amelyek egyetlen szótípusra vonatkozó információkat rögzítenek anélkül, hogy befolyásolnák azokat a szavakat, amelyekkel együtt előfordulnak. Mesterséges nyelvű korpusz segítségével ellenőrizzük, hogy a képzési adatok redundanciája nem-atomi belső állapotokat eredményez, és új módszert javasolunk az atomi belső állapotok indukálására. Megmutatjuk, hogy 1) módszerünk sikeresen indukálja az atom belső szerveződését kontrollált kísérletekben, és 2) reálisabb körülmények között, ahol a képzés gyermek-irányított nyelvből áll, módszerünk alkalmazása javítja a lexikai reprezentációk teljesítményét egy downstream szemantikai kategorizálási feladaton.', 'mk': 'Рекурентната нервна мрежа (RNN) јазички модел е моќна алатка за учење арбитрални секвенцијални зависности во јазичките податоци. И покрај нејзиниот огромен успех во претставувањето на лексичките секвенции, малку е познато за квалитетот на лексичките претставувања што ги добива. Во оваа работа, претпоставуваме дека е едноставно да се извлечат лексикалните претставувања (т.е. статички зборови внесени) од РНН, но дека количината на семантични информации кодирани е ограничена кога лексикалните предмети во податоците за обука обезбедуваат претерани семантични информации. Ние ја концептуализираме оваа ограничување на РНН како неуспех да се научи атомски внатрешни држави - држави кои заземаат информации релевантни за типовите на еден збор без да бидат влијани од претерани информации обезбедени од зборови со кои тие се соочуваат. Користејќи корпус на вештачки јазик, потврдиме дека отпуштањето на податоците за обука предизвикува неатомски внатрешни држави, и предложуваме нов метод за индукција на атомски внатрешни држави. Ние покажуваме дека 1) нашиот метод успешно индуцира атомска внатрешна организација во контролираните експерименти, и 2) под пореални услови во кои обуката се состои од јазик директиран на децата, апликацијата на нашиот метод ја подобрува изведбата на лексичките претставувања на задачата за семантична категоризација на', 'ml': 'ആവര്\u200dത്തിച്ചുകൊണ്ടിരിക്കുന്ന നെയുറല്\u200d ശൃംഖല (RNN) ഭാഷ മോഡല്\u200d ഭാഷ പഠിപ്പിക്കുന്നതിനായി ശക്തിയുള്ള ഉപകരണമാണു് ലെക്സിക്സിക്കല്\u200d സെക്കന്\u200dസിന്\u200dറെ പ്രതിനിധിയില്\u200d അതിന്\u200dറെ വലിയ വിജയം തന്നെയാണെങ്കിലും അത് സമ്പാദിക്കുന്ന ലെക്സിക് ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമുക്ക് തോന്നുന്നത് ഒരു RNN-ല്\u200d നിന്നും ലെക്സിക്കല്\u200d പ്രതിനിധികളെ പുറത്തെടുക്കാന്\u200d നേരെയാണെന്നാണ്. പക്ഷെ പരിശീലനത്തിലെ ലെക്സിക്കല്\u200d വസ്തുക്കള്\u200d കു നമ്മള്\u200d RNN ന്റെ ഈ പരിധിയെ ആറ്റോമിക്കല്\u200d ആന്തരിക രാജ്യങ്ങള്\u200d പഠിക്കാന്\u200d പരാജയപ്പെട്ടിരിക്കുന്നു- ഒരേ വാക്കിന്റെ തരത്തില്\u200d ബന്ധപ്പെട്ട വിവരങ്ങള്\u200d പി സൃഷ്ടിക ഭാഷ ഉപയോഗിക്കുന്ന ഒരു കോര്\u200dപ്പസ് ഉപയോഗിച്ച്, പരിശീലനത്തിലെ വിവരങ്ങളില്\u200d നിന്നും അണ്ടോമിക്കല്\u200d ആന്\u200dറിക്കല്\u200d നാട്ടുകള്\u200d ഉള്\u200dപ്പെടു നമ്മുടെ രീതി വിജയിച്ചു കാണിക്കുന്നു. നിയന്ത്രണ പരീക്ഷണങ്ങളില്\u200d ആറ്റോമിക്കല്\u200d ആന്തരിക സംഘടനയെ നിയന്ത്രിക്കുന്നു. 2) കൂടുതല്\u200d യഥാര്\u200dത്ഥ സ്ഥിതികളില്\u200d... കുട്ടികള്\u200d നേര്\u200dവഴിയ', 'mt': "Il-mudell lingwistiku rikorrenti tan-netwerk newrali (RNN) huwa għodda qawwija għat-tagħlim ta’ dipendenzi sekwenzjali arbitrarji fid-dejta lingwistika. Minkejja s-suċċess enormi tiegħu fir-rappreżentazzjoni tas-sekwenzi lexiċi, ftit huwa magħruf dwar il-kwalità tar-rappreżentazzjonijiet lexiċi li jakkwista. F’dan ix-xogħol, aħna nżuru li huwa sempliċi li jiġu estratti rappreżentazzjonijiet lexiċi (jiġifieri inkorporazzjonijiet statiċi ta’ kliem) minn RNN, i żda li l-ammont ta’ informazzjoni semantika li hija kkodifikata huwa limitat meta oġġetti lexiċi fid-dejta tat-taħriġ jipprovdu informazzjoni semantika żejda. Aħna nikkonċettwalizzaw din il-limitazzjoni tal-RNN bħala nuqqas ta' tagħlim ta' stati interni atomiċi - stati li jaqbdu informazzjoni rilevanti għal tipi ta' kliem wieħed mingħajr ma jiġu influwenzati minn informazzjoni żejda pprovduta minn kliem li magħhom jikkoinċidu. Bl-użu ta’ korpus ta’ lingwa artifiċjali, a ħna nivverifikaw li s-sensja fid-dejta tat-taħriġ tirriżulta fi stati interni mhux atomiċi, u nipproponu metodu ġdid għall-induzzjoni ta’ stati interni atomiċi. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.", 'el': 'Το μοντέλο γλώσσας επαναλαμβανόμενου νευρικού δικτύου (είναι ένα ισχυρό εργαλείο για την εκμάθηση αυθαίρετων διαδοχικών εξαρτήσεων σε γλωσσικά δεδομένα. Παρά την τεράστια επιτυχία της στην αναπαράσταση λεξικών ακολουθιών, ελάχιστα είναι γνωστά για την ποιότητα των λεξικών αναπαραστάσεων που αποκτά. Σε αυτή την εργασία, υποθέτουμε ότι είναι απλό να εξαγάγουμε λεξικές αναπαραστάσεις (δηλαδή στατικές ενσωματώσεις λέξεων) από ένα αλλά ότι η ποσότητα σημασιολογικών πληροφοριών που κωδικοποιούνται είναι περιορισμένη όταν λεξικά στοιχεία στα δεδομένα εκπαίδευσης παρέχουν περιττές σημασιολογικές πληροφορίες. Θεωρούμε αυτόν τον περιορισμό του RNN ως αποτυχία εκμάθησης ατομικών εσωτερικών καταστάσεων σε καταστάσεις που συλλαμβάνουν πληροφορίες σχετικές με μεμονωμένους τύπους λέξεων χωρίς να επηρεάζονται από περιττές πληροφορίες που παρέχονται από λέξεις με τις οποίες συμβαίνουν. Χρησιμοποιώντας ένα σώμα τεχνητής γλώσσας, επαληθεύουμε ότι η πλεονασματικότητα στα δεδομένα εκπαίδευσης παράγει μη ατομικές εσωτερικές καταστάσεις, και προτείνουμε μια νέα μέθοδο για την πρόκληση ατομικών εσωτερικών καταστάσεων. Δείχνουμε ότι 1) η μέθοδος μας προκαλεί επιτυχώς ατομική εσωτερική οργάνωση σε ελεγχόμενα πειράματα, και 2) υπό πιο ρεαλιστικές συνθήκες στις οποίες η εκπαίδευση αποτελείται από γλώσσα που κατευθύνεται προς το παιδί, η εφαρμογή της μεθόδου μας βελτιώνει την απόδοση των λεξικών αναπαραστάσεων σε μια μεταγενέστερη εργασία σημασιολογικής κατηγοριοποίησης.', 'no': 'Språk- modellen for gjentakelig neuralnettverk (RNN) er eit kraftig verktøy for å lære tilfeldig sekvensiske avhengighet i språk- data. Til tross stor suksess i å representera leksiske sekvensar, er liten kjent om kvaliteten på dei leksiske representasjonane som han gjer. I denne arbeida har vi forstått at det er enkelt å pakka ut leksiske representasjonar (t.d. statiske ord innebygging) frå e it RNN, men at mengda av semantiske informasjon som er koda er begrenset når leksiske elementar i opplæringsdata gjev redundant semantisk informasjon. Vi konseptualiserer denne grensen på RNN som ein feil i å lære atomiske interne tilstandar - tilstandar som hentar informasjon relevant til enkelte ord- typar utan å bli påvirka av redundant informasjon gjeven av ord som dei samtidig skjer. I bruk av ein korpus av kunstige språk kan vi kontrollere at rødvendighet i øvingsdata gjev ikkje-atomiske interne tilstandar, og foreslår ein novel metode for å indusera atomiske interne tilstandar. Vi viser at 1) vårt metode fører til at atomiske interne organisasjon er vellukka i kontrollerte eksperimenter, og 2) under meir realistiske vilkår der opplæringa inneheld frå barnsdirekte språk, vil metoden vårt forbetra utviklinga av leksiske representasjonar på ein nedstrekke semantisk kategorisasjon.', 'ro': 'Modelul de limbaj recurent al rețelei neurale (RNN) este un instrument puternic pentru învățarea dependențelor secvențiale arbitrare în datele lingvistice. În ciuda succesului său enorm în reprezentarea secvențelor lexicale, se știe puțin despre calitatea reprezentărilor lexicale pe care le dobândește. În această lucrare, presupunem că este simplu să extragem reprezentări lexicale (adică încorporări statice de cuvinte) dintr-un RNN, dar că cantitatea de informații semantice codificate este limitată atunci când elementele lexicale din datele de instruire furnizează informații semantice redundante. Noi conceptualizăm această limitare a RNN ca pe un eșec de a învăța stările interne atomice - stări care captează informații relevante pentru tipurile de cuvinte unice fără a fi influențate de informații redundante furnizate de cuvinte cu care acestea coincid. Folosind un corpus de limbaj artificial, verificăm dacă redundanța datelor de instruire generează stări interne non-atomice și propunem o metodă nouă pentru inducerea stărilor interne atomice. Arătăm că 1) metoda noastră induce cu succes organizarea atomică internă în experimente controlate, și 2) în condiții mai realiste în care instruirea constă în limbaj direcționat de copii, aplicarea metodei noastre îmbunătățește performanța reprezentărilor lexicale pe o sarcină de categorizare semantică din aval.', 'mn': 'Дахин давтагдсан мэдрэлийн сүлжээний загвар нь хэл өгөгдлийн мэдээллээс хамааралтай байдлыг сурах хүчтэй хэрэгсэл юм. Лексийн дарааллыг үзүүлэхэд маш их амжилт хүртэл бага зэрэг олж авдаг лектикийн үзүүлэлтийн талаар ойлгомжтой. Энэ ажлын хувьд бид ДНХ-ээс лексикийн үзүүлэлтийг хялбар гаргах нь хязгаарлагддаг гэдгийг ойлгож байна. Гэхдээ шинэчлэгдсэн семантик мэдээллийн хэмжээ нь сургалтын өгөгдлийн лексикийн бичлэгүүд маш олон семантик мэдээллийг өгдөг. Бид ДНХ-ын хязгаарыг атомын дотоод орнуудыг суралцахгүй гэдгийг ойлгож үздэг. Тэд нэг үг төрлийн мэдээллийг хамтран нөлөөлөхгүй байдаг. Бид уран бүтээлч хэлний корпус ашиглан суралцах өгөгдлийн давхар нь атомын дотоод бус орнууд болон атомын дотоод орнуудыг үйлдвэрлэх шинэ арга зам өгдөг. Бид 1) бидний аргаар амжилттай атомын дотоод байгууллагуудыг хяналттай туршилтуудын тулд хөгжүүлж, 2) хүүхдүүдийн дасгал хөгжүүлэх хэл болох бодит нөхцөл байдлын тулд, бидний аргаар хэрэглэх арга нь бага зэрэг семантийн хэлбэрийн дасгал дээр', 'si': 'ආපහු ප්\u200dරතික්\u200dරියාත්මක ජාලය (RNN) භාෂාව මොඩේල් එකක් භාෂාව දත්තේ භාෂාව සිදුවීම සඳහා ප්\u200dරතික්\u200dරිය ලෙක්සිකල් පරීක්ෂණයක් ප්\u200dරතිනිධානය කරලා තියෙන්නේ ඒක ගොඩක් සාර්ථක විශේෂතාවක් ගැන, පොඩ්ඩක් දැනගන්නේ  මේ වැඩේ අපි හිතන්නේ ඒක හරියටම ලෙක්සිකල් ප්\u200dරතිනිධානය (i.e. static word Embdings) RNN වලින්, ඒත් ඒක සෙමාන්ටික් තොරතුරු කිරීම සීමාන්තික තොරතුරු සීමාන්තික තොරතුරු ස අපි RNN ගේ සීමාව අවස්ථාවක් වෙනුවෙන් අභ්\u200dයාමික ඇතුළු ස්ථානයක් ඉගෙන ගන්න බැරි විදියට පරීක්ෂා කරනවා - ස්ථානයක් තියෙන්නේ එක වච අපි ප්\u200dරශ්නයක් තියෙන්නේ කාර්පස් භාෂාවක් ප්\u200dරයෝජනය කරනවා, අපි ප්\u200dරශ්නයක් තියෙන්නේ නැත්තම් අභ්\u200dයාණ්\u200dය භාෂාවක් නෙවෙ අපි පෙන්වන්නේ 1) අපේ විධානය සමහරවිට අතමාන්\u200dය ඇතුළු සංවිධානය පාලනය කරනවා පරීක්ෂණය කරලා තියෙන්නේ, 2) වඩා ඇතුළු ස්ථානයක් තියෙන්නේ පුද්ගලික භ', 'so': 'Shabakadda neurada ee soo socda (RNN) waa qalabka xoogga leh ee barashada ku xiran macluumaadka ku saabsan arbitaalka xilliga. Inta kastoo ay guulaysteen liibaanka aad u weyn ee ku qeybqaadashada xilliyada leksikada, wax yar waxaa la yaqaan tijaabada noocyada xuquuqda leksikalka ah oo uu helayo. Markaas waxaynu u malaynaynaa inay si toos ah u soo bixiso qof ka mid ah RNN, laakiin in macluumaadka semantika lagu qorayo ay xadgudbaan marka macluumaadka waxbarashada laga helaa macluumaad ka yar. Waxaynu u fekeraynaa xuduudkan RNN oo aan u baaqan inay barto wadamada hoose ee atomic - wadamada ay qabsadaan macluumaad ku saabsan noocyada kaliya oo aan saameyn ku lahayn macluumaad yar oo ay ku qoran yihiin hadal ay ku wada socoto. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states.  Waxaynu muujinnaa in qaababkayagu uu ku liibaani karo urur hoose u dhexeeya jirrabaadka la ilaaliyo, iyo 2) iyadoo ku jirta xaaladaha rasmiga ah oo ku saabsan waxbarashada oo ku jirta luqada la hagayo carruurta, codsiga qaabilsashada qaababkayaga ayaa hagaajiya sameynta qofka leksiga ah oo lagu sameeyo qasabka qaybinta hoose.', 'sv': 'Den återkommande neurala nätverksspråkmodellen (RNN) är ett kraftfullt verktyg för att lära sig godtyckliga sekventiella beroenden i språkdata. Trots dess enorma framgång med att representera lexikala sekvenser, är det lite känt om kvaliteten på de lexikala representationer som den förvärvar. I detta arbete antar vi att det är enkelt att extrahera lexikala representationer (dvs statiska ordinbäddningar) från ett RNN, men att mängden semantisk information som kodas är begränsad när lexikala objekt i utbildningsdata ger redundant semantisk information. Vi begriper denna begränsning av RNN som ett misslyckande att lära sig atomära interna tillstånd - stater som fångar information relevant för enstaka ordtyper utan att påverkas av överflödig information som tillhandahålls av ord som de samtidigt förekommer med. Med hjälp av en korpus av artificiellt språk verifierar vi att redundans i träningsdata ger icke-atomära interna tillstånd, och föreslår en ny metod för att inducera atomära interna tillstånd. Vi visar att 1) vår metod framgångsrikt inducerar atomisk intern organisation i kontrollerade experiment, och 2) under mer realistiska förhållanden där utbildningen består av barnstyrt språk, tillämpningen av vår metod förbättrar prestanda av lexikala representationer på en nedströms semantisk kategoriseringsuppgift.', 'sr': 'Рекорентна неврална мрежа (RNN) језик модел је моћен инструмент за учење произволно последователно зависимости у езиковим данима. Uprkos ogromnom uspjehu u predstavljanju leksičkih sekvencija, malo je poznato o kvaliteti leksičkih predstavljanja koje dobija. U ovom poslu pretpostavljamo da je jednostavno izvući leksičke predstave (tj. statične reči ugrađene) iz RNN-a, ali da je količina semantičkih informacija koja je kodirana ograničena kada leksičke predmete u podacima obuke pružaju smanjene semantičke informacije. Konceptujemo ovu ograničenje RNN kao neuspjeh učenja atomskih unutrašnjih država - država koja uhvate informacije relevantne za jedine reèi, a da ne utiču na snažne informacije koje se predstavljaju reèima s kojima se sarađuju. Koristeći korpus umjetničkog jezika, potvrđujemo da redundancija podataka o obuci daje neoatomske unutrašnje države i predlažemo novu metodu induciranja atomskih unutrašnjih država. Pokazujemo da 1) naša metoda uspešno inducira atomsku unutrašnju organizaciju u kontroliranim eksperimentima, i 2) pod realističnijim uslovima u kojima se obuka sastoji od jezika na kojem se upućuje dete, primjena našeg metoda poboljšava učinkovitost leksičkih predstavljanja na zadatak semantičke kategorije.', 'ta': 'நிகழ்ந்த புதிய பிணையம் (RNN) மொழி மாதிரி மாதிரி மாதிரி என்பது பின்வரும் சார்ந்த சார்புகளை மொழி தரவில் கற்றுக்கொள்வதற வெற்றிகரமான வெற்றியும் இருந்தாலும், லெக்சிக்சியல் தொகுதிகளின் தரம் பற்றி சிறிது தெரியும். இந்த வேலையில், நாம் நேராக நினைக்கிறோம் RNN லிருந்து லெக்சியல் பிரிவுகளை வெளியேற்றுவதற்கு (அதாவது நிலையான வார்த்தை உள்ளடக்கி) என்பது, ஆனால் குறியீட்டில் உள்ள பொருள நாம் ஆர்என்னின் எல்லையை ஒரு அணுக்கு உள்ளார்ந்த நாடுகளில் கற்றுக்கொள்ள இயலவில்லை- நாடுகள் அது ஒற்றை வார்த்தை வகைகளுடன் தொடர்புடைய தகவலை பிடிக்கும் ப தொழில்நுட்பமான மொழியை பயன்படுத்தி, பயிற்சியில் தகவலின் குறைவு அணுகல் உள்ளார்ந்த நாடுகளுக்கு வழங்குகிறது என்பதை சரிபார் நாம் காண்பிக்கிறோம் என்றால், எங்கள் முறையில் வெற்றிகரமாக அணுகல் உள்ளார்ந்த நிறுவனத்தை கட்டுப்படுத்தும் சோதனைகளில், மற்றும் 2) அதிக உண்மையான நிலைகளில் பயிற்சி குழந்த', 'ms': 'Model bahasa rangkaian saraf (RNN) berulang adalah alat yang berkuasa untuk mempelajari dependensi urutan arbitrari dalam data bahasa. Walaupun sukses besar dalam mewakili urutan leksikal, sedikit diketahui tentang kualiti perwakilan leksikal yang ia dapatkan. Dalam kerja in i, kita menyangka bahawa ia adalah mudah untuk mengekstrak perwakilan leksikal (iaitu penyampilan perkataan statik) dari RNN, tetapi jumlah maklumat semantik yang dikodifikasikan adalah terbatas apabila item leksikal dalam data latihan menyediakan maklumat semantik yang berlebihan. Kami konseptualisasi keterangan RNN ini sebagai gagal untuk belajar keadaan dalaman atom - keadaan yang menangkap maklumat yang berkaitan dengan jenis perkataan tunggal tanpa dipengaruhi oleh maklumat berlebihan yang diberikan oleh perkataan yang mereka bersamaan dengan. Dengan menggunakan sebuah korpus bahasa buatan, kami mengesahkan bahawa ketidaktepatan dalam data latihan menghasilkan keadaan dalaman bukan-atom, dan mencadangkan kaedah baru untuk mengakibatkan keadaan dalaman atom. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.', 'pl': 'Model językowy rekrutującej sieci neuronowej (RNN) jest potężnym narzędziem do nauki dowolnych zależności sekwencyjnych w danych językowych. Pomimo ogromnego sukcesu w reprezentowaniu sekwencji leksykalnych, niewiele wiadomo o jakości reprezentacji leksykalnych, które nabywa. W niniejszej pracy przypuszczamy, że proste jest wyodrębnienie reprezentacji leksykalnych (tj. statycznych osadzeń słów) z RNN, ale ilość zakodowanych informacji semantycznych jest ograniczona, gdy elementy leksykalne w danych treningowych dostarczają zbędnych informacji semantycznych. Konceptujemy to ograniczenie RNN jako brak nauki atomowych stanów wewnętrznych stanów stanów, które przechwytują informacje istotne dla pojedynczych typów słów bez wpływu na zbędne informacje dostarczane przez słowa, z którymi współwystępują. Za pomocą korpusu sztucznego języka weryfikujemy, czy redundancja w danych treningowych daje nieatomowe stany wewnętrzne i proponujemy nową metodę indukowania atomowych stanów wewnętrznych. Pokazujemy, że 1) nasza metoda z powodzeniem indukuje atomową organizację wewnętrzną w kontrolowanych eksperymentach, a 2) w bardziej realistycznych warunkach, w których szkolenie składa się z języka kierowanego dzieckiem, zastosowanie naszej metody poprawia wydajność reprezentacji leksykalnych na dalszym zadaniu kategoryzacji semantycznej.', 'ur': 'روکنٹ نیورل نیٹورل (RNN) زبان کی موڈل زبان ڈاٹی میں ایک قابل تولیل ہے جو زبان کی ڈاٹی میں غیر قابل تعلیم کرتی ہے۔ لیکسیکل سفارش کی نمایش میں اس کی بہت بڑی موفقیت کے بغیر، بہت ہی کم معلوم ہے کہ اس کے پیدا ہونے والی لکسیکل سفارش کی کیفیت کے بارے میں۔ اس کام میں ہم سمجھتے ہیں کہ یہ ایک RNN سے لکسیکل معجزات (یعنی static word embeddings) نکالنے کے لئے ساده ہے، لیکن یہ سیمانتی معلومات کی مقدار محدود ہوتی ہے جبکہ تدریس ڈیٹوں میں لکسیکل معجزات کمی ہوتی ہیں۔ ہم نے RNN کی اس محدودیت کو اتمیک داخلی حالت کی سیکھنے کے لئے غلطی کے طور پر سمجھ لیا ہے - ایسے حالت ہیں جو ایک کلمات کے متعلق معلومات کو پکڑتے ہیں بغیر اس کے کہ کلمات کے ذریعہ ان کے ساتھ اتمام ہوتے ہیں ان کے متعلق بہت زیادہ معلومات کے ذری ہمیں معلوم زبان کی کورپوس کی استعمال کرتا ہے، ہم تصدیق کرتے ہیں کہ تعلیم دادہ میں بہت زیادہ غیر اتمیک داخلی ایٹیٹوں کو پیدا کرتا ہے، اور اتمیک داخلی ایٹیٹوں کو پیدا کرنے کے لئے ایک نو طریقہ پیش کرتا ہے. ہم نشان دیتے ہیں کہ 1) ہمارا طریقہ موفق طور پر اتم کی داخلی سازمان کو کنٹرول کی آزمائش میں پیش کرتا ہے اور 2) اس میں بہت حقیقی شرایطوں کے اندر جس میں تمرین بچے کی سمجھ کی زبان میں ہے، ہمارے طریقے کا کاربرد ہمارے طریقے کے مطابق ایک نیچے سیمنٹی کاٹریزی ٹیکٹریزی کے کام', 'uz': "@ info: whatsthis Leksikal seksiyatlarini tashqarish uchun juda katta muvaffaqiyatli bo'lsa, Leksikal tashkilotlarining sifatida yaxshi ko'rinadi. In this work, we conjecture that it is straightforward to extract lexical representations (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information.  Biz RNN chegarasini bir xil holatda o'rganish muvaffaqiyatli deb tasavvur qilamiz - bir so'z turlari bilan bog'liq maʼlumotni qabul qiladigan holatlarga qo'llab keladigan so'zlar bilan bir necha maʼlumot yordamida ishlatilmaydi. Biz ta'lim sohasini ishlatish uchun taʼminlovchi maʼlumotning kuchi atomik ichki davlatga ega bo'ladi, va atomik ichki davlatlarni ishlab chiqarish uchun novel usulini tasavvur qilamiz. Biz shunday ko'rsatganmiz: 1) usulidagi muvaffaqiyatli boshqaruv tajribalarda atomik internal tashkilotlarini boshqaradi, 2 va ko'proq haqida, o'sha holatda, bolalik qo'shilgan tillar bo'lgan bo'lgan, o'sha usullarning foydalanishimiz o'zgarishni o'zgartiradi.", 'vi': 'Mô hình ngôn ngữ mạng thần kinh liên tục (RNN) là một công cụ mạnh mẽ để học các phụ thuộc ngẫu nhiên trong dữ liệu ngôn ngữ. Mặc dù thành công lớn trong việc đại diện các chuỗi văn học, nhưng không biết gì về chất lượng các biểu tượng văn học mà nó thu thập được. Trong công việc này, chúng tôi đoán rằng rất dễ dàng để trích xuất các biểu tượng từ ngữ (v.d. Sự tác cài ghép từ tĩnh mạch) từ RNN, nhưng rằng lượng thông tin ngữ pháp được mã hóa bị hạn là giới hạn khi các mục văn học trong dữ liệu đào tạo ra các thông tin ngữ pháp không cần thiết. Chúng tôi tưởng tượng giới hạn này của RNN như là việc không học được các bang nội bộ nguyên tử (nguyên tử) mà thu thập thông tin liên quan đến các loại từ đơn mà không bị ảnh hưởng bởi thông tin dư thừa cung cấp bởi những từ mà họ cộng tác. Bằng cách sử dụng một tập hợp ngôn ngữ nhân tạo, chúng tôi xác minh rằng dự phòng trong dữ liệu đào tạo đem lại không nguyên tử nội bang, và đề xuất một phương pháp mới để tạo ra các bang nội bộ nguyên tử. Chúng tôi cho thấy rằng 1) phương pháp của chúng tôi đã tạo ra một tổ chức nội bộ nguyên tử trong các thí nghiệm được kiểm soát, và 2) trong những điều kiện thực tế hơn khi đào tạo gồm ngôn ngữ hướng dẫn trẻ em, sử dụng phương pháp của chúng tôi cải thiện hiệu quả của các biểu tượng văn học trên một nhiệm vụ phân loại theo chiều theo dòng.', 'nl': 'Het recidivierende neurale netwerk (RNN) taalmodel is een krachtig hulpmiddel voor het leren van willekeurige sequentiële afhankelijkheden in taalgegevens. Ondanks het enorme succes in het weergeven van lexicale sequenties, is weinig bekend over de kwaliteit van de lexicale representaties die het verwerft. In dit werk veronderstellen we dat het eenvoudig is om lexicale representaties (d.w.z. statische woordinbeddingen) uit een RNN te extraheren, maar dat de hoeveelheid semantische informatie die gecodeerd wordt beperkt is wanneer lexicale items in de trainingsgegevens redundante semantische informatie verstrekken. We conceptualiseren deze beperking van de RNN als een mislukking om atomaire interne toestanden te leren. Zuständen die informatie vastleggen die relevant is voor enkele woordtypen zonder beïnvloed te worden door overbodige informatie verstrekt door woorden waarmee ze samen voorkomen. Met behulp van een corpus van kunstmatige taal verifiëren we dat redundantie in de trainingsgegevens niet-atomaire interne toestanden oplevert, en stellen we een nieuwe methode voor om atomaire interne toestanden te induceren. We tonen aan dat 1) onze methode succesvol atomaire interne organisatie induceert in gecontroleerde experimenten, en 2) onder realistischere omstandigheden waarin de training bestaat uit kindergerichte taal, de toepassing van onze methode verbetert de prestaties van lexicale representaties op een downstream semantische categorisatietaak.', 'bg': 'Езиковият модел на повтаряща се невронна мрежа (РНН) е мощен инструмент за изучаване на произволни последователни зависимости в езиковите данни. Въпреки огромния успех в представянето на лексикалните последователности, малко се знае за качеството на лексикалните представи, които придобива. В тази работа предполагаме, че е лесно да се извличат лексикални представяния (т.е. статични вграждания на думи) от РНН, но количеството семантична информация, която се кодира, е ограничено, когато лексикалните елементи в данните за обучение предоставят излишна семантична информация. Ние концептуализираме това ограничение на РНН като неспособност да се научат атомни вътрешни състояния - състояния, които улавят информация, свързана с единични типове думи, без да бъдат повлияни от излишна информация, предоставена от думи, с които те съвместно се срещат. Използвайки корпус от изкуствен език, ние проверяваме, че redundanteстта в тренировъчните данни дава неатомни вътрешни състояния и предлагаме нов метод за индуциране на атомни вътрешни състояния. Показваме, че 1) методът ни успешно индуцира атомна вътрешна организация в контролирани експерименти, и 2) при по-реалистични условия, при които обучението се състои от детски език, прилагането на метода ни подобрява изпълнението на лексикалните представяния при задача за семантична категоризация надолу по веригата.', 'da': 'Den tilbagevendende neurale netværk (RNN) sprogmodel er et kraftfuldt værktøj til at lære vilkårlige sekventielle afhængigheder i sprogdata. På trods af sin enorme succes med at repræsentere leksikalske sekvenser, kendes der ikke meget om kvaliteten af de leksikalske repræsentationer, den erhverver. I dette arbejde formoder vi, at det er ligetil at udtrække lexikale repræsentationer (dvs. statiske ord indlejringer) fra et RNN, men at mængden af semantisk information, der er kodet, er begrænset, når lexikale elementer i træningsdataene giver overflødig semantisk information. Vi opfatter denne begrænsning af RNN som en manglende læring af atomare interne tilstande - tilstande, der indfanger information relevant for enkelte ordtyper uden at blive påvirket af overflødige oplysninger leveret af ord, som de forekommer sammen med. Ved hjælp af et korpus af kunstigt sprog kontrollerer vi, at redundans i træningsdata giver ikke-atomare interne tilstande, og foreslår en ny metode til at inducere atomare interne tilstande. Vi viser, at 1) vores metode med succes inducerer atom intern organisering i kontrollerede eksperimenter, og 2) under mere realistiske forhold, hvor træningen består af børnerettet sprog, anvendelse af vores metode forbedrer ydeevnen af leksikalske repræsentationer på en nedstrøms semantisk kategoriseringsopgave.', 'hr': 'Rezervantni jezički model neuralne mreže (RNN) je moćan alat za učenje proizvodnje sekvencijske zavisnosti u jezičkim podacima. Uprkos ogromnom uspjehu predstavljanja leksičkih sekvencija, malo je poznato o kvaliteti leksičkih predstavljanja koje dobija. U ovom poslu pretpostavljamo da je jednostavno izvući leksičke predstave (tj. statične riječi uključene) iz RNN-a, ali da je količina semantičkih informacija koja je kodirana ograničena kada leksičke predstave u podacima obuke pružaju smanjene semantičke informacije. Mi konceptualiziramo ovu ograničenje RNN kao neuspjeh naučiti atomske unutrašnje države - države koje hvataju informacije relevantne za jedine riječi, a ne utječu na redundantne informacije koje su predstavljene riječima s kojima se sarađuju. Koristeći korpus umjetničkog jezika, potvrđujemo da redundancija podataka o obuci daje neoatomske unutrašnje države i predlažemo novu metodu induciranja atomskih unutrašnjih država. Mi pokazujemo da 1) naša metoda uspješno inducira atomsku unutarnju organizaciju u kontroliranim eksperimentima, i 2) pod realističnijim uvjetima u kojima se obuka sastoji od jezika upućenog na djecu, primjena našeg metoda poboljšava učinkovitost leksičkih predstavljanja na zadatak za semantičku kategoriju.', 'de': 'Das wiederkehrende neuronale Netzwerk (RNN) Sprachmodell ist ein leistungsfähiges Werkzeug, um beliebige sequenzielle Abhängigkeiten in Sprachdaten zu erlernen. Trotz seines enormen Erfolgs bei der Darstellung lexikalischer Sequenzen ist wenig über die Qualität der lexikalischen Repräsentationen, die es erwirbt, bekannt. In dieser Arbeit vermuten wir, dass es einfach ist, lexikalische Repräsentationen (d.h. statische Worteinbettungen) aus einem RNN zu extrahieren, dass die Menge an semantischen Informationen, die verschlüsselt werden, begrenzt ist, wenn lexikalische Elemente in den Trainingsdaten redundante semantische Informationen liefern. Wir konzipieren diese Begrenzung des RNN als ein Versagen, atomare innere Zustände zu lernen, Zustände, die Informationen erfassen, die für einzelne Worttypen relevant sind, ohne von redundanten Informationen beeinflusst zu werden, die von Wörtern bereitgestellt werden, mit denen sie zusammen auftreten. Mit Hilfe eines Korpus künstlicher Sprache verifizieren wir, dass Redundanz in den Trainingsdaten nicht-atomare interne Zustände liefert, und schlagen eine neue Methode zur Induktion atomarer interner Zustände vor. Wir zeigen, dass 1) unsere Methode erfolgreich atomare interne Organisation in kontrollierten Experimenten induziert, und 2) unter realistischeren Bedingungen, in denen das Training aus kindgesteuerter Sprache besteht, die Anwendung unserer Methode die Leistung lexikalischer Repräsentationen auf einer nachgelagerten semantischen Kategorisierungsaufgabe verbessert.', 'id': 'Model bahasa jaringan saraf (RNN) yang berulang-ulang adalah alat yang kuat untuk mempelajari dependensi sekwensial secara arbitrar dalam data bahasa. Meskipun sukses besar dalam mewakili urutan lexik, sedikit diketahui tentang kualitas representation lexik yang ia dapatkan. Dalam pekerjaan in i, kita menduga bahwa itu mudah untuk mengekstrak representation leksik (i.e. embedding kata statis) dari RNN, tetapi jumlah informasi semantik yang dikodifikasikan adalah terbatas ketika item leksik dalam data latihan menyediakan informasi semantik yang berlebihan. Kami konseptualisasi batasan RNN ini sebagai gagal untuk belajar negara-negara interna atomik - negara-negara yang menangkap informasi yang relevan untuk tipe kata tunggal tanpa dipengaruhi oleh informasi redundant yang diberikan oleh kata-kata yang mereka sama-sama terjadi. Dengan menggunakan sebuah tubuh bahasa buatan, kita mengkonfirmasi bahwa ketidaksengajaan dalam data latihan menghasilkan negara-negara interna bukan atom, dan mengusulkan metode baru untuk menginduksi negara-negara interna atom. Kami menunjukkan bahwa 1) metode kami berhasil menginduksi organisasi internal atom dalam eksperimen terkendali, dan 2) dalam kondisi yang lebih realistis di mana pelatihan terdiri dari bahasa direksi anak, aplikasi metode kami meningkatkan prestasi dari represisi leksik pada tugas kategorisasi semantis turun.', 'ko': '역귀신경망(RNN) 언어 모델은 언어 데이터의 임의의 순서 의존 관계를 학습하는 유력한 도구다.비록 그것이 어휘 서열을 나타내는 데 큰 성공을 거두었지만, 사람들은 그것이 얻은 어휘 표시의 질에 대해 아는 것이 매우 적다.이 작업에서 우리는 RNN에서 어휘 표시(즉 정적 단어 삽입)를 추출하는 것은 매우 간단하다고 추측하지만 훈련 데이터의 어휘 항목이 쓸데없는 의미 정보를 제공할 때 인코딩된 의미 정보량은 유한하다.우리는 RNN의 이러한 한계를 원자 내부 상태를 배울 수 없다는 개념으로 만들었다. 이러한 상태는 한 단어의 유형과 관련된 정보를 포착하고, 동시에 나오는 단어가 제공하는 불필요한 정보의 영향을 받지 않는다.인공 언어 자료 라이브러리를 이용하여 우리는 훈련 데이터 중의 군더더기가 비원자 내부 상태를 발생시켰음을 검증하고 새로운 원자 내부 상태를 유도하는 방법을 제시했다.우리의 연구에 의하면 1) 우리의 방법은 통제된 실험에서 원자 내부 조직을 성공적으로 유도했다. 2) 더욱 현실적인 상황에서 어린이가 안내하는 언어로 구성된 훈련을 하는 상황에서 우리의 방법의 응용은 어휘 표징이 하류의 의미 분류 업무에서의 성능을 향상시켰다.', 'sw': 'Mtandao wa neura unaoendelea (RNN) wa lugha ni nyenzo yenye nguvu ya kujifunza kutegemea kwa takwimu za lugha. Pamoja na mafanikio makubwa katika kuwakilisha mfululizo wa sekta za lexico, bado hakijua kiwango cha uwakilishi wa lexico kinachopata. Katika kazi hii, tunadhani ni moja kwa moja kuwatoa wakiwakilishi wa lexico (yaani neno la stadi) kutoka RNN, lakini kwamba kiasi cha taarifa za kimapenzi kinachojumuishwa vimepungua pale vitu vya lexico katika taarifa za mafunzo vinapotoa taarifa kidogo za kimapenzi. Tunawafikiria ukomo wa chama hicho cha RNN kama kushindwa kujifunza nchi za ndani - majimbo ambayo yanachukua taarifa zinazohusiana na aina moja ya maneno bila kuathiriwa na taarifa chache zilizotolewa na maneno ambayo yanatokea. Kwa kutumia makampuni ya lugha ya kibunifu, tunathibitisha kwamba kiwango cha taarifa za mafunzo kinaleta nchi isiyo na atomu, na kupendekeza njia ya riwaya kwa ajili ya kutengeneza nchi za ndani za atomu. Tunaonyesha kuwa 1) mbinu zetu kwa mafanikio yanafanya shirika la ndani la atomi katika majaribio yanayodhibitiwa, na 2) chini ya hali halisi ambazo mafunzo yanajumuisha lugha inayoongozwa na watoto, matumizi ya mbinu yetu yanaboresha ufanisi wa uwakilishi wa lexico katika kazi ya makundi ya mitaani.', 'fa': 'شبکه عصبی بازگشت (RNN) مدل زبان یک ابزار قدرتمند برای یادگیری بستگی\u200cهای اتفاق\u200cانگیز در داده\u200cهای زبان است. با وجود موفقیت بسیار بزرگی که در نمایش رشته\u200cهای زبانی است، کمی در مورد کیفیت نمایش\u200cهای زبانی که می\u200cگیرد شناخته می\u200cشود. در این کار، ما تصور می\u200cکنیم که این نمایش\u200cهای زبانی (یعنی جمع\u200cآوری\u200cهای static word embeddings) از یک RNN ساده است، ولی مقدار اطلاعات semantic که رمزگذاری می\u200cشود محدودیت می\u200cشود زمانی که وسیله\u200cهای زبانی در داده\u200cهای آموزش اطلاعات semantic را فراهم می\u200cکنند. ما این محدودیت RNN را به عنوان شکست یادگیری از وضعیت های داخلی اتمی می که اطلاعات مربوط به نوع یک کلمه متعلق به یک کلمه گرفته اند، بدون تأثیر توسط اطلاعات زیادی که توسط کلمه هایی که همکاری می کنند، تأثیر داده می شویم. با استفاده از یک کورپوس زبان مصنوعی، ما تصدیق می\u200cکنیم که دوره\u200cای در داده\u200cهای آموزش به ایالت\u200cهای داخلی غیر اتمی ارائه می\u200cدهد و یک روش جدید برای تولید ایالت\u200cهای داخلی اتمی پیشنهاد می\u200cدهد. ما نشان می دهیم که ۱) روش ما با موفقیت سازمان داخلی اتمی را در آزمایشات کنترل می کند، و ۲) زیر شرایط واقعی بیشتری که آموزش از زبان کودک هدایت می کند، کاربرد روش ما انجام دادن نمایش\u200cهای زبان\u200cشناسی را در یک وظیفه\u200cی جدید\u200cشناسی پایین پایین می\u200cکند.', 'tr': "Hata nusgala (RNN) Letikal terjimeleri üýtgetmek üçin uly başarnygynyň rağmen, ýene alan lektikal terjimeleriniň howplygyny barada az bilýär. Bu i şde, biziň pikirimçe bir RNN'den lektik suratlary çykmak aňsatlyk diýip hasaplanýarys, ýöne kodlanýan semantik maglumatyň haýsyzlyk durmuşy e ğitim maglumatynda azat semantik maglumaty berilýän wagtynda kesişik bolar. Biz RNN'iň bu limitini atom daşarky döwletleri öwrenmek üçin bir hata diýip düşünýäris - durumlar ýeke söz tipleri bilen meňzeşlik maglumaty alýarlar we olaryň hem bolan sözler tarapyndan täsirli gazanýarlar. Surat diliniň korpusyny ulanyp, bilim maglumatynyň daşary ýok döwletleriniň atom döwletleriniň ýok döwletleriniň taýýarlanmagyny barlaýarys we atom daşary döwletlerini täsir etmek üçin bir nusga teklip edip bileris. 1) biziň döwürimiziň üstünlik ýüze atom daşary düzenlemeklerinde kontrol edilen deneylerde täsirleýär we 2) çagalar dilinde durmuş çykyş taýýarlamasynyň üstünliklerini gowurar.", 'sq': 'Modeli i gjuhës së rrjetit neural të përsëritur (RNN) është një mjet i fuqishëm për mësimin e varësive sekuenciale arbitrare në të dhënat e gjuhës. Despite its enormous success in representing lexical sequences, little is known about the quality of the lexical representations that it acquires.  Në këtë punë, ne supozojmë se është e thjeshtë të nxjerrim përfaqësime lexike (pra përfaqësime statike fjalësh) nga një RNN, por se sasia e informacionit semantik që është koduar është e kufizuar kur elementet lexike në të dhënat e stërvitjes ofrojnë informacion semantik të tepërt. Ne e konsiderojmë këtë kufizim të RNN-së si një dështim për të mësuar shtete të brendshme atomike - shtete që kapin informacion të rëndësishëm për tipet e fjalëve të vetme pa u ndikuar nga informacioni i tepruar furnizuar nga fjalët me të cilat a to bashkëpunojnë. Duke përdorur një trup gjuhësh artificiale, ne verifikojmë se redundanca në të dhënat e trainimit jep shtete të brendshme jo-atomike dhe propozojmë një metodë të re për induktimin e shteteve të brendshme atomike. Ne tregojmë se 1) metoda jonë indukton me sukses organizatën e brendshme atomike në eksperimente të kontrolluara, dhe 2) në kushte më realiste në të cilat trajnimi përbëhet nga gjuha e drejtuar nga fëmijët, zbatimi i metodës tonë përmirëson performancën e përfaqësimeve lexike në një detyrë semantike poshtë.', 'af': "Die herhaalde neuralnetwerk (RNN) taal model is 'n kragtige gereedskap vir die leer van arbitrêre sekwensiele afhanklikhede in taal data. Onthou sy groot sukses in die verteenwoordigheid van leksiese sekwensies, is klein bekend oor die kwaliteit van die leksiese verteenwoordigheid wat dit kry. In hierdie werk, ons verwerp dat dit eenvoudig is om leksiese voorstellings (i.e. statiese woord inbettings) uit 'n RNN te uitpak, maar dat die hoeveelheid semantiese inligting wat kodeerd word beperk word wanneer leksiese items in die onderwerp data redundant semantiese inligting verskaf word. Ons konseptualiseer hierdie beperking van die RNN as 'n mislukking om atomiese interne staatste te leer - staatste wat inligting betrokke aan enkele woord tipes ontvang sonder om deur redendande inligting te influens deur woorde wat hulle saamgebeur word. By die gebruik van 'n korpus van kunstenaar taal, bevestig ons dat roondagtigheid in die onderwerking data non-atomiese interne staatste gee en voorstel 'n nuwe metode om atomiese interne staatste te induseer. Ons wys dat 1) ons metode suksesvol atomiese interne organisasie in kontroleerde eksperimente induseer, en 2) onder meer realistiese voorwaardes waarin die onderwerking bestaan van kindergraf taal, toepassing van ons metode verbeter die prestasie van leksiese voorstellings op 'n onderstreem semantiese kategorisasie taak.", 'am': 'በቋንቋው ምሳሌ ውስጥ የሚቀጥለው የኒጀር መረብ (RNN) ከሌክሲካዊ ግንኙነት ማቀናቀል በታላቅ ድል ምንም እንኳ የሌክሲካዊ መልዕክቶች ጥሩ ማወቅ ጥቂት ነው፡፡ በዚህ ሥራ፣ የሊክሲካዊ መልዕክቶች (የstatic word embedding) ከRNN ለመውጣት ቀላል ይመስላል፤ ነገር ግን የሌክሲካዊ አካላት በሚያስተምሩ ዳታዎች ውስጥ የስሜክሲካዊ መረጃዎች ሲሰጥተው የስሜክሲካዊ መረጃዎች የሚቆጠሩ ተቃውሞ ነው፡፡ ይህንን የRNN ግንኙነት አካባቢ የውይይት ሀገራት ለማስተማር ስህተት እናስባለን - እና በአንድ ቃላት የተገኘውን የኢንተርኔት መልዕክት በማንቀሳቀስ በተደረገው ቃላት በማንቀሳቀስ በማንጠቃቀፍ የሚጠይቁትን አዋጅ እናደርጋለን፡፡ በጥያቄ ቋንቋ በመጠቀም፣ የትምህርት ዳታዎችን የሚያስቀናቅል የአካባቢ ውስጥነት ሀገራት እንዲወጣ እና የአንባቢካዊ ሀገራት ለመግለጥ የኖረብ ዘዴ እና የአንባቢ ሀገራት እንዲያስፈልግ እናስታውቃለን፡፡ 1) መንገዳችን በሥልጣኑ ፈተናዎች ውስጥ አካባቢ የሆኑን ድርጅት እና 2) በተጨማሪው የሕፃን-ተመራጭ ቋንቋ የሚኖሩበትን እናሳየዋለን፣ የልኬክሲ መልዕክታችንን በአውራው ውጤት ክፍተት ላይ የሌክሲካዊ መልዕክት ማድረግ ያሳድጋል፡፡', 'hy': 'Նյարդային ցանցի (ՌՆՆ) լեզվի մոդելը հզոր գործիք է լեզվի տվյալներում կամավոր հաջորդական կախվածությունների սովորելու համար: Despite its enormous success in representing lexical sequences, little is known about the quality of the lexical representations that it acquires.  Այս աշխատանքի ընթացքում մենք ենթադրում ենք, որ հեշտ է վերցնել լեքսիկական ներկայացումները (այսինքն, ստատիկ բառերի ներառումները) ՌՆԹ-ից, բայց որ սեմանտիկ տեղեկատվության քանակը, որը կոդավորված է, սահմանափակված է, երբ ուսուցման տվյալների լեքսիկական առարկաները պարունակում են ավելին սեմանտիկ տեղեկատվություն: Մենք ընկալում ենք ՌՆԹ-ի սահմանափակումը որպես ատոմային ներքին վիճակներ սովորելու ձախողումը, այն վիճակներ, որոնք հավաքում են տեղեկատվություն, որը կապված է միակ բառի տեսակների հետ, առանց ազդեցության ունենալու անհրաժեշտ տեղեկատվության վրա, որը տրամ Օգտագործելով արհեստական լեզվի կորպոս, մենք ստուգում ենք, որ կրթության տվյալների չափազանցությունը հանգեցնում է ոչ ատոմային ներքին նահանգներ, և առաջարկում ենք ատոմային ներքին նահանգների ինդուկցիայի նոր մեթոդ: Մենք ցույց ենք տալիս, որ 1) մեր մեթոդը հաջողությամբ առաջացնում է ատոմային ներքին կազմակերպությունը կառավարվող փորձերում, և 2) ավելի իրական պայմաններում, երբ փորձը կազմված է երեխաների ուղղությամբ աշխատող լեզվից, մեր մեթոդի կիրառումը բարելավում է լեքսիկական ներկայացումների ար', 'bn': 'প্রত্যাবর্তিত নিউরেল নেটওয়ার্ক (RNN) ভাষার মডেল ভাষার মোডেল একটি শক্তিশালী টুল যা ভাষার তথ্যে বৈধতার পরবর্তী নির্ভর লেক্সিক্যাল সেকেন্সের প্রতিনিধিত্বের বিশাল সাফল্য সত্ত্বেও, লেক্সিকাল প্রতিনিধিদের মান সম্পর্কে কম জানা যায় য এই কাজে আমরা ধারণা করি যে লেক্সিক্যাল প্রতিনিধিত্ব (যেমন স্টেটিক শব্দ বিভিন্ন বিষয়বস্তুকে বের করার জন্য সাধারণত, কিন্তু সেমান্টিক তথ্য য যা এনকোড করা হয় তা সীমিত, যখন প্রশ আমরা আরএনএন-এর এই সীমাবদ্ধতা ব্যর্থ হিসেবে ধারণা করি আনবিক অভ্যন্তরীণ রাষ্ট্রের শিক্ষা শিখতে ব্যর্থ - রাষ্ট্রগুলো যেগুলো একই শব্দের সাথে যুক্ত তথ্য প্ শৈল্পিক ভাষার কোর্পাস ব্যবহার করে আমরা নিশ্চিত করি যে প্রশিক্ষণের তথ্যের সংক্রান্ত কমানোর ফলে আটকিক ভাষায় অভ্যন্তরীণ রাষ্ট্রের ফলে প্রস্তাব আমরা দেখাচ্ছি যে ১) আমাদের পদ্ধতি সফলভাবে নিয়ন্ত্রণিত পরীক্ষার মধ্যে আত্মিক অভ্যন্তরীণ প্রতিষ্ঠান, আর ২) বাস্তবতার পরিস্থিতিতে বাচ্চাদের নির্দেশিত ভাষায় প্রশিক্ষণের', 'ca': "The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data.  Malgrat el seu enorme èxit en representar seqüències lècsiques, poc es coneix sobre la qualitat de les representacions lècsiques que aconsegueix. En aquesta feina, suposem que és senzill extrair representacions lècsiques (és a dir, incorporacions de paraules estàtiques) d'un RNN, però que la quantitat d'informació semàntica codificada està limitada quan els elements lècsiques de les dades d'entrenament proporcionen informació semàntica redundant. Conceptuem aquesta limitació del RNN com un fracàs en aprendre estats interns atòmics - estats que capturan informació rellevant a tipus de paraules senza ser influenciat per informació redundant proporcionada per paraules amb les que coincideixen. Utilitzant un cos de llenguatge artificial, verifiquem que la redundancia en les dades d'entrenament produeix estats interns no atòmics, i proposem un nou mètode per inducir estats interns atòmics. Mostrem que 1) el nostre mètode indueix amb èxit l'organització atòmica interna en experiments controlats, i 2) en condicions més realistes en les quals l'entrenament consisteix en un llenguatge dirigit pel nen, l'aplicació del nostre mètode millora el rendiment de les representacions lècsiques en una tasca de categorització semàntica avall.", 'az': 'Tekrarlanan nöral a ğ (RNN) dil modeli dil məlumatının dil məlumatından müəyyən edilən müvəffəqiyyəti öyrənmək üçün güclü bir vasitədir. Ən böyük müvəffəqiyyəti ilə, leksik seçmələrini göstərməyə rağmen, əldə etdiyi leksik təsirlərin keyfiyyəti haqqında az bilər. Bu i şdə, biz zənn edirik ki, bir RNN-dən leksik göstəriciləri (i.e. static word embeddings) çıxartmaq düzgün olduğunu, lakin kodlanmış semantik məlumatların dəyişiklik məlumatları təhsil məlumatlarında leksik məlumatların azaldığı zaman sınırlandırılır. Biz bu RNN limitini atom içəri durumları öyrənməyə başarısız olaraq düşünürük - tək söz növlərinə olan məlumatları təklif edirlər, onların birlikdə olduğu sözlər ilə təklif edilməyən çox çətin məlumatlar təsirləndirilmədən. Yaxşı dilin korpusu istifadə edərək, təhsil məlumatlarında çox azaldığını təsdiqləyirik ki, atom iç durumları təhsil etmək üçün yeni bir yol təklif edir. Biz göstəririk ki, 1) metodumuz atom içəri organizasyonu kontrol edilmiş eksperimentlərdə təşkil edir və 2) çox reallı şərtlərdə, bu təhsil çocuk dilindən olub, metodumuzun uyğulaması, indirilmiş semantik kategoriyasiyası işlərində leksik təşkil etmələrinin performansını yaxşılaşdırır.', 'bs': 'Ponavljajući jezički model neuralne mreže (RNN) je moćan alat za učenje proizvodnje sekvencijske zavisnosti u jezičkim podacima. Uprkos ogromnom uspjehu predstavljanja leksičkih sekvencija, malo je poznato o kvaliteti leksičkih predstavljanja koje dobija. U ovom poslu pretpostavljamo da je jednostavno izvući leksičke predstave (tj. statične riječi ugrađene) iz RNN-a, ali da je količina semantičkih informacija koja je kodirana ograničena kada leksičke predstave u podacima o obuci pružaju smanjene semantičke informacije. Mi konceptualiziramo ovu ograničenje RNN kao neuspjeh naučiti atomske unutrašnje države - države koje uhvate informacije relevantne za jedine reči, a da ne utiču na snažne informacije koje se predstavljaju riječima s kojima se sarađuju. Koristeći korpus umjetničkog jezika, potvrđujemo da redundancija podataka o obuci daje neoatomske unutrašnje države i predlažemo novu metodu induciranja atomskih unutrašnjih država. Pokazujemo da 1) naša metoda uspješno inducira atomsku unutrašnju organizaciju u kontroliranim eksperimentima, i 2) pod realističnijim uvjetima u kojima se obuka sastoji od jezika upućenog na djecu, primjena našeg metoda poboljšava učinkovitost leksičkih predstavljanja na zadatak semantičke kategorije.', 'cs': 'Jazykový model rekurentní neuronové sítě (RNN) je výkonným nástrojem pro učení libovolných sekvenčních závislostí v jazykových datech. Navzdory obrovskému úspěchu v reprezentaci lexikálních sekvencí je o kvalitě lexikálních reprezentací, které získává, málo známo. V této práci se domníváme, že je jednoduché extrahovat lexikální reprezentace (tj. statické vložení slov) z RNN, ale že množství sémantických informací, které jsou kódovány, je omezené, pokud lexikální položky v tréninkových datech poskytují redundantní sémantické informace. Toto omezení RNN konceptujeme jako selhání naučit se atomové vnitřní stavy, které zachycují informace relevantní pro jednotlivé typy slov, aniž by byly ovlivněny redundantními informacemi poskytovanými slovy, se kterými se spolu vyskytují. Pomocí korpusu umělého jazyka ověřujeme, že redundance v tréninkových datech přináší neatomové vnitřní stavy a navrhujeme novou metodu indukce atomových vnitřních stavů. Ukazujeme, že 1) naše metoda úspěšně indukuje atomovou vnitřní organizaci v řízených experimentech a 2) za realističtějších podmínek, kdy se výcvik skládá z dětského jazyka, aplikace naší metody zlepšuje výkon lexikálních reprezentací na následné sémantické kategorizační úlohy.', 'et': 'Korduv närvivõrgu (RNN) keelemudel on võimas vahend meelevaldsete järjestikuste sõltuvuste õppimiseks keeleandmetes. Vaatamata oma tohutule edule esindada leksikaalseid järjestusi, vähe on teada kvaliteedi leksikaalseid esitusi, et ta omandab. Käesolevas töös oletame, et RNN-ist on lihtne ekstraheerida leksikaalseid esitusi (st staatilisi sõnu manustamisi), kuid kodeeritava semantilise informatsiooni hulk on piiratud, kui leksikaalsed elemendid koolitusandmetes annavad üleliigset semantilist informatsiooni. Me kontseptualiseerime seda RNN piirangut kui ebaõppimist õppida aatomisiseseid olekuid - olekuid, mis koguvad üksikute sõnatüüpide kohta olulist teavet, ilma et neid mõjutaks üleliigne teave, mida annavad sõnad, millega nad koos esinevad. Kunstliku keele korpuse abil kontrollime, et koolitusandmete redundantsus annab mitteatomilisi sisemiseid olekuid, ning pakume välja uue meetodi aatomisisemise oleku indutseerimiseks. Näitame, et 1) meie meetod indutseerib edukalt aatomisisese organisatsiooni kontrollitud eksperimentides ja 2) realistlikumates tingimustes, kus koolitus koosneb lapsepõhisest keelest, parandab meie meetodi rakendamine leksikaalsete representatsioonide jõudlust allvoolu semantilise kategoriseerimise ülesandel.', 'fi': 'Toistuvan neuroverkon (RNN) kielimalli on tehokas työkalu mielivaltaisten sekvensaalisten riippuvuuksien oppimiseen kieliaineistossa. Huolimatta sen valtavasta menestyksestä esittää leksikaalisia sekvenssejä, vain vähän tiedetään sen hankkimien leksikaalisten representaatioiden laadusta. Tässä työssä otaksumme, että on suoraviivaista poimia leksikaalisia esityksiä (eli staattisia sanaupotuksia) RNN:stä, mutta että koodattavan semanttisen tiedon määrä on rajallinen, kun leksikaaliset kohdat koulutusaineistossa tarjoavat tarpeetonta semanttista tietoa. Käsittelemme tämän RNN:n rajoituksen epäonnistumiseksi oppia atomin sisäisiä tiloja - tiloja, jotka keräävät yksittäisille sanatyypeille merkityksellistä tietoa ilman, että niihin vaikuttaa niiden rinnakkaiselon sanojen tuottama tarpeeton tieto. Keinotekoisen kielen korpusella toteutamme, että harjoitusdatan redundanssi tuottaa ei-atomisia sisäisiä tiloja, ja ehdotamme uutta menetelmää atomisten sisäisten tilojen indusoimiseksi. Osoitamme, että 1) menetelmämme onnistuneesti indusoi atomisen sisäisen organisaation kontrolloiduissa kokeissa ja 2) realistisemmissa olosuhteissa, joissa koulutus koostuu lapsiohjatusta kielestä, menetelmämme soveltaminen parantaa leksikaalisten esitysten suorituskykyä semanttisessa kategorisointitehtävässä.', 'ha': "@ info: whatsthis Inã rantsuwa da babban babban rabo a wakilishi masu sakan leksisi, an sani kaɗan a kan sifar sifar mutane na leksisi da ke samu. In this work, we conjecture that it is straightforward to extract lexical representations (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information.  Tuna ƙayyade wannan tsarin RNN kamar an kasa sanar da halin atomic guda - states which take information related to one word but don a yi amfani da ƙaranci information wanda they bãyar da sami da shi. Yi amfani da wani nau'i na lugha wanda ba'a sani ba, za mu gaskata cewa rabon da data za'a fitar states na guda ba-atomic, kuma za'a buƙata hanyoyi wa masu ƙarai na nufi. Tuna nũna cewa, hanyoyinmu na cin nasara ya induce shirin atomi na guda a cikin jarrabo masu lissafa, da kuma 2) a cikin mazaɓa mafi gaskiya, a cikinsa, wa'adin na haɗi lugha masu shirya da yãro, da shiryoyin hanyonmu, yana ƙarai ga aikin littafan leksilaki a kan wani aikin mai rabo na ƙarami.", 'sk': 'Jezikovni model ponavljajočega se nevronskega omrežja (RNN) je zmogljivo orodje za učenje poljubnih zaporednih odvisnosti v jezikovnih podatkih. Kljub velikemu uspehu pri predstavljanju leksikalnih zaporedij je o kakovosti leksikalnih reprezentacij, ki jih pridobiva, malo znano. V tem delu domnevamo, da je iz RNN enostavno izvleči leksikalne reprezentacije (t.j. statične besede), vendar je količina semantičnih informacij, ki so kodirane, omejena, kadar leksikalni elementi v podatkih usposabljanja zagotavljajo redundantne semantične informacije. To omejitev RNN konceptualiziramo kot neuspeh pri učenju atomskih notranjih stanj - stanj, ki zajemajo informacije, pomembne za posamezne vrste besed, ne da bi nanje vplivale odvečne informacije, ki jih zagotavljajo besede, s katerimi se soočajo. Z uporabo korpusa umetnega jezika preverimo, da redundanca v treningskih podatkih prinaša neatomska notranja stanja in predlagamo novo metodo za indukcijo atomskih notranjih stanj. Pokazali smo, da 1) naša metoda uspešno inducira atomsko notranjo organizacijo v kontroliranih eksperimentih in 2) pod realističnejšimi pogoji, v katerih je usposabljanje sestavljeno iz otroško usmerjenega jezika, uporaba naše metode izboljša učinkovitost leksikalnih reprezentacij pri nadaljnji semantični kategorizaciji.', 'he': 'מודל שפת הרשת העצבית המחזורת (RNN) הוא כלי חזק ללמוד תלויות רצופיות רצופיות במידע שפת. Despite its enormous success in representing lexical sequences, little is known about the quality of the lexical representations that it acquires.  בעבודה הזו, אנו מניחים שזה פשוט להוציא מייצגים לקסיים (כלומר מילים סטטיות) מRNN, אבל שהכמות של מידע סמנטי שמוקוד מוגבלת כאשר פריטים לקסיים בנתונים האימונים מספקים מידע סמנטי מיותר. אנו מתייחסים את הגבלה הזאת של RNN ככישלון ללמוד מדינות פנימיות אטומיות - מדינות שמתפסות מידע רלוונטי לטיפוסי מילים אחת בלי להיות משפיעה על ידי מידע מיותר שנוסף על ידי מילים שהם מתרחשים יחד. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states.  We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.', 'bo': 'རྗེས་མའི་མེ་འཁོར་དྲ་བ(RNN)སྐད་རིགས་དཔེ་དབྱིབས་ནི་སྐད་ཡིག་ཆ་ནང་གི་རྗེས་སུ་འབྲེལ་མཐུད སྐད་རིགས་དབྱེ་བ་དེ་དག་གི་གོ་སྐབས་ཆེ་ཆུང་བའི་གྲུབ་འབྲས་ཀྱི་རྩ་བའི་ནང་དུ་ཕལ་ཆེན་ཤེས་ཀྱི་མེད། In this work, we conjecture that it is straightforward to extract lexical representations (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information. ང་ཚོས་RNN་གི་ཚད སྤྱད་ནས་བཟོས་ཅན་གྱི་སྐད་ཡིག་ཚང་ཞིག་བྱས་པ་ལས་ ང་ཚོས་རྣམས་ལས་ཕར་ཆེན་པོ་ཞིག་ལས་ཕར་རྐྱེན་ཐབས་ཤིག་འདྲ་བྱེད་དགོས། We show that 1) our method successfully induced atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.', 'jv': 'Sampeyan anyar nggo langgambar Nyural (DNN) Nanging kabèh akeh lan saiki dipunangé sampeyan luwih nêmên banget, akeh iso ngerasai kapan ning cualitas sing larang lexèké awak dhéwé kuwi tindakan. Awak dhéwé nggunakeh iki, awak dhéwé luwih akeh basa luwih (i.e.g. embedding word wrapping) sak arnN saiki, nguasai kesempatan sematik dhéwé Awak dhéwé nggawe limiting this limitation of the DNN as a Failed to Learn Atomic Intranet Stats - Stats that Capture information Relative to single word types Ngawe ngubah bangsa akeh artikse, kita ngomong sinau kanggo mbatalungkur dadi nggawe barang-sistem sing gak bakal Atomok bukani, lan supoyo nggawe sistem sing gak bener alam kanggo ingkang dipun dadi Atomok. Awak dhéwé éntuk 1) ngerti nggawe barang akeh gunakake sistem Atomok tentang kanggo nguasai winih, lan 2) sing kalagayuté sing diranggawe barang kelas sistem sing katêpakan karo langgambar kelas supoyo cilas, aplikasi tentang kanggo nyebutuhan langgambarang langgambar sistem sing gawe nguasai perusahaan langgambar uwong.'}
{'en': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'es': 'Razonamiento de trayectoria bidireccional consciente de las relaciones para responder a preguntas de sentido común', 'ar': 'استدلال المسار ثنائي الاتجاه المدرك للعلاقة لإجابة سؤال العموم', 'pt': 'Raciocínio de caminho bidirecional com reconhecimento de relação para resposta a perguntas de senso comum', 'fr': 'Raisonnement de chemin bidirectionnel sensible aux relations pour répondre aux questions de bon sens', 'ja': '常識的な質問への回答のための関係認識双方向パス推論', 'zh': '常识性问答感知双向径推理', 'hi': 'संबंध-जागरूक द्विदिश पथ तर्क कॉमनसेंस प्रश्न उत्तर देने के लिए', 'ru': 'Обоснование двунаправленного пути, учитывающего отношение, для ответа на вопрос здравого смысла', 'ga': 'Conair Dhéthreorach Feasach ar an ngaol Réasúnaíocht le Freagra Ceist Commonsense', 'el': 'Αμφίδρομη λογική διαδρομής για την απάντηση σε ερωτήσεις κοινής λογικής', 'ka': 'Name', 'hu': 'Kapcsolattudatos kétirányú útvonal Az általános kérdések megválaszolásának indokolása', 'lt': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'kk': 'Қатысушылардың екі бағыттық жолының жауап беру үшін Қатысушылық сұрақтарының түсініктемесі', 'it': 'Ragionamento del percorso bidirezionale consapevole della relazione', 'mt': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'ms': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'no': 'Reaksjon for å svara på spørsmål frå forbindelsveit', 'pl': 'Rozumowanie dwukierunkowej ścieżki uzasadniania odpowiedzi na pytania o zdrowy sens', 'ro': 'Relație conștientă de calea bidirecțională Motivarea răspunsurilor la întrebări de bun sens', 'mk': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'sr': 'Odgovor na pitanje javnosti', 'ml': 'കമോണ്\u200dസണ്\u200dസിന്റെ ചോദ്യം ഉത്തരം ചോദിക്കുന്നതിനുള്ള ബന്ധപ്പെട്ട ബൈഡഡിയല്\u200d വഴി', 'so': "Qoraalka su'aalaha ku saabsan mas’uulka xiriirka wadada labaad ee xiriirka", 'mn': 'Харилцаа холбоотой хоёр шугам замын шалтгаан нь Commonsense асуулт хариултын шалтгаан', 'ur': 'رابطہ جاننے والی دو دقیق مسیر کیونس سؤال جواب کے لیے رابطہ', 'si': 'සම්බන්ධ ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතිච්චාරය සඳහා සම්බන්ධ ප්\u200dරශ්නයක් දෙවෙනි පාර හේතුව', 'sv': 'Relationsmedveten tvåriktad väg Motivering för Commonsense Fråga Svar', 'ta': 'தொடர்பு தெரியும் இருதிசைப் பாதையில் கேள்வி பதில்', 'uz': 'Comment', 'vi': 'Đối tượng hiểu biết về Đường dẫn nhỏ Tìm câu trả lời câu hỏi Bình thường', 'nl': 'Relatiebewuste Bidirectionele Path Redening voor het beantwoorden van Commonsense Questions', 'bg': 'Обмисляне на двупосочни пътища за отговор на въпроси с общ разум', 'da': 'Relation-bevidst Todirectional Path Årsag til Commonsense Spørgsmål Besvarelse', 'de': 'Beziehungsbewusste bidirektionale Path Reasoning für die Beantwortung von Commonsense-Fragen', 'id': 'Hubungan-sadar Jalan Biarah Menyebabkan Jawaban Pertanyaan Komunis', 'hr': 'Odgovor na pitanje javnosti', 'ko': '관계 감지에 기초한 상식 문답 양방향 경로 추리', 'fa': 'واکنش مسیر دوچرخه\u200cای با ارتباط برای پاسخ سوال هماهنگ', 'tr': 'Commonsense Soragy jogap', 'sw': 'Njia ya moja kwa moja inayofahamika na mawasiliano Kusoma swali la Maswali', 'af': 'Relasie- aware Bidirectional Path Reasoning for Commonsense Question Answering', 'sq': 'Rregullimi i rrugës dy-drejtore për përgjigjet e pyetjeve të zakonshme', 'az': 'ńįliŇükisi-bilikli ńįki t…ôr…ôfli Yol Reasoning for Commonsense Question Response', 'bn': 'কমন্সেন্স প্রশ্নের উত্তর প্রাপ্ত', 'am': 'የኩነቶች ጥያቄ', 'hy': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'ca': 'Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering', 'bs': 'Odgovor na pitanje javnosti', 'cs': 'Obousměrné odůvodnění cesty pro odpověď na otázky zdravého rozumu', 'et': 'Suheteadlik kahesuunaline tee põhjendamine üldise mõttega küsimustele vastamiseks', 'fi': 'Suhteen tietoinen kaksisuuntainen polku järkeily Commonsense Kysymyksiin vastaaminen', 'jv': 'AllProgressBarUpdates', 'sk': 'Razlog dvosmerne poti za odgovor na vprašanja na splošna smiselna', 'ha': 'QUnicodeControlCharacterMenu', 'he': 'היחסים מודעים לכיוון שני כיוונים', 'bo': 'མཐུན་འབྲེལ་བ་དེ་གཉིས་གཡུལ་གྱི་འགྲུལ་ལམ་ལ་རྗེས་འབྲེལ་བའི་འདྲི་ཚིག་ལན་སྐོར་བ'}
{'en': 'Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through  commonsense reasoning . Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform  reasoning  on  knowledge graphs . However, these methods do not explicitly model the  relations  that connect entities, which are informational and can be used to enhance  reasoning . To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths. relations  that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'ar': 'تعد الإجابة على الأسئلة من منظور العموم مهمة مهمة لمعالجة اللغة الطبيعية (NLP) والتي تهدف إلى التنبؤ بالإجابة الصحيحة لسؤال من خلال التفكير المنطقي. تستخدم الدراسات السابقة النماذج المدربة مسبقًا على الشركات الكبيرة مثل BERT ، أو تؤدي المنطق على الرسوم البيانية المعرفية. ومع ذلك ، فإن هذه الأساليب لا تشكل نموذجًا صريحًا للعلاقات التي تربط الكيانات ، وهي معلوماتية ويمكن استخدامها لتعزيز التفكير. لمعالجة هذه المشكلة ، نقترح طريقة تفكير مدرك للعلاقة. تستخدم طريقتنا الشبكة العصبية للرسم البياني المدرك للعلاقة لالتقاط المعلومات السياقية الغنية من كل من الكيانات والعلاقات. مقارنة بالطرق التي تستخدم دعوات العلاقات الثابتة من النماذج المدربة مسبقًا ، يقوم نموذجنا ديناميكيًا بتحديث العلاقات مع المعلومات السياقية من مخطط فرعي متعدد المصادر ، مبني من مصادر معرفة خارجية متعددة. ثم يتم تغذية التمثيلات المحسنة للعلاقات إلى وحدة التفكير ثنائية الاتجاه. يتم تطبيق آلية انتباه ثنائية الاتجاه بين تسلسل الأسئلة والمسارات التي تربط الكيانات ، مما يوفر لنا قابلية تفسير شفافة. توضح النتائج التجريبية على مجموعة بيانات CommonsenseQA أن طريقتنا تؤدي إلى تحسينات كبيرة على الخطوط الأساسية مع توفير مسارات تفكير واضحة أيضًا.', 'pt': 'A resposta a perguntas de senso comum é uma importante tarefa de processamento de linguagem natural (PLN) que visa prever a resposta correta a uma pergunta por meio do raciocínio de senso comum. Estudos anteriores utilizam modelos pré-treinados em corpora de grande escala, como BERT, ou realizam raciocínio em gráficos de conhecimento. No entanto, esses métodos não modelam explicitamente as relações que conectam as entidades, que são informativas e podem ser usadas para aprimorar o raciocínio. Para resolver esse problema, propomos um método de raciocínio consciente da relação. Nosso método usa uma rede neural de grafos com reconhecimento de relação para capturar as ricas informações contextuais de entidades e relações. Comparado com métodos que usam embeddings de relações fixas de modelos pré-treinados, nosso modelo atualiza dinamicamente as relações com informações contextuais de um subgrafo de várias fontes, construído a partir de várias fontes externas de conhecimento. As representações aprimoradas de relações são então alimentadas a um módulo de raciocínio bidirecional. Um mecanismo de atenção bidirecional é aplicado entre a sequência de perguntas e os caminhos que conectam as entidades, o que nos proporciona uma interpretabilidade transparente. Os resultados experimentais no conjunto de dados CommonsenseQA ilustram que nosso método resulta em melhorias significativas nas linhas de base, além de fornecer caminhos de raciocínio claros.', 'fr': "La réponse aux questions de bon sens est une tâche importante de traitement du langage naturel (PNL) qui vise à prédire la bonne réponse à une question grâce à un raisonnement de bon sens. Les études précédentes utilisent des modèles pré-entraînés sur des corpus à grande échelle tels que BERT, ou effectuent un raisonnement sur des graphes de connaissances. Cependant, ces méthodes ne modélisent pas explicitement les relations qui relient les entités, qui sont informatives et peuvent être utilisées pour améliorer le raisonnement. Pour résoudre ce problème, nous proposons une méthode de raisonnement sensible aux relations. Notre méthode utilise un réseau neuronal graphique sensible aux relations pour capturer les informations contextuelles riches à la fois des entités et des relations. Comparé aux méthodes qui utilisent des intégrations de relations fixes issues de modèles préentraînés, notre modèle met à jour dynamiquement les relations avec des informations contextuelles provenant d'un sous-graphe multi-sources, construit à partir de plusieurs sources de connaissances externes. Les représentations améliorées des relations sont ensuite transmises à un module de raisonnement bidirectionnel. Un mécanisme d'attention bidirectionnel est appliqué entre la séquence de questions et les chemins qui relient les entités, ce qui nous fournit une interprétabilité transparente. Les résultats expérimentaux sur l'ensemble de données CommonSenseQA montrent que notre méthode entraîne des améliorations significatives par rapport aux lignes de base tout en fournissant des pistes de raisonnement claires.", 'es': 'La respuesta a preguntas de sentido común es una importante tarea de procesamiento del lenguaje natural (NLP) que tiene como objetivo predecir la respuesta correcta a una pregunta a través del razonamiento de sentido común. Los estudios anteriores utilizan modelos previamente entrenados en corpus a gran escala, como BERT, o realizan razonamientos en gráficos de conocimiento. Sin embargo, estos métodos no modelan explícitamente las relaciones que conectan a las entidades, que son informativas y se pueden utilizar para mejorar el razonamiento. Para abordar este problema, proponemos un método de razonamiento que tenga en cuenta las relaciones. Nuestro método utiliza una red neuronal gráfica consciente de las relaciones para capturar la rica información contextual de entidades y relaciones. En comparación con los métodos que utilizan incrustaciones de relaciones fijas de modelos previamente entrenados, nuestro modelo actualiza dinámicamente las relaciones con información contextual de un subgrafo de múltiples fuentes, creado a partir de múltiples fuentes de conocimiento externas. Las representaciones mejoradas de las relaciones se envían luego a un módulo de razonamiento bidireccional. Se aplica un mecanismo de atención bidireccional entre la secuencia de preguntas y los caminos que conectan a las entidades, lo que nos proporciona una interpretabilidad transparente. Los resultados experimentales del conjunto de datos CommonSenseQA demuestran que nuestro método produce mejoras significativas con respecto a las líneas de base, al tiempo que proporciona vías de razonamiento claras.', 'ja': '共通感覚の質問に対する回答は、共通感覚の推論を通じて質問に対する正解を予測することを目的とした重要な自然言語処理（ NLP ）タスクです。 以前の研究では、BERTなどの大規模なコーパスで事前にトレーニングされたモデルを利用したり、ナレッジグラフで推論を行いました。 しかしながら、これらの方法は、エンティティを接続する関係を明示的にモデル化するものではなく、情報的であり、推論を強化するために使用することができる。 この問題に対処するために、関係を意識した推論方法を提案します。 私たちの方法は、リレーションシップを認識するグラフニューラルネットワークを使用して、エンティティとリレーションシップの両方から豊富なコンテキスト情報をキャプチャします。 事前にトレーニングされたモデルからの固定関係埋め込みを使用する方法と比較して、当社のモデルは、複数の外部知識ソースから構築されたマルチソースのサブグラフからコンテキスト情報との関係を動的に更新します。 次いで、関係の拡張された表現は、双方向推論モジュールに供給される。 質問シーケンスとエンティティを接続するパスの間に双方向の注意メカニズムが適用され、透明な解釈可能性が提供されます。 CommonsenseQAデータセットの実験結果は、当社の方法がベースラインを大幅に改善すると同時に、明確な推論パスを提供することを示しています。', 'zh': '常识性问答,自然语言处(NLP)务,指常识推理以占正对。 前论用於大语料库(如BERT)之先教者,或推理于知图谱。 然不显式连体建模,信息性也,可以益理。 为此一事,吾等发明推理之法。 吾法用感知图神经网络以获实体之丰上下文。 比之于用,用之于外多源子图上下文信息更新。 然后强致双向推理模块。 序接径之间双向宜用机制,这为供明可解释性。 常识QA数集之实验结果表明,吾法比基线著改进,兼资清理。', 'hi': 'Commonsense Question Answering एक महत्वपूर्ण प्राकृतिक भाषा प्रसंस्करण (NLP) कार्य है जिसका उद्देश्य CommonSense Reasoning के माध्यम से किसी प्रश्न के सही उत्तर की भविष्यवाणी करना है। पिछले अध्ययन बड़े पैमाने पर कॉर्पोरेट जैसे BERT पर पूर्व-प्रशिक्षित मॉडल का उपयोग करते हैं, या ज्ञान रेखांकन पर तर्क करते हैं। हालांकि, ये विधियां स्पष्ट रूप से उन संबंधों को मॉडल नहीं करती हैं जो संस्थाओं को जोड़ती हैं, जो सूचनात्मक हैं और तर्क को बढ़ाने के लिए उपयोग की जा सकती हैं। इस मुद्दे को हल करने के लिए, हम एक संबंध-जागरूक तर्क विधि का प्रस्ताव करते हैं। हमारी विधि दोनों संस्थाओं और संबंधों से समृद्ध प्रासंगिक जानकारी को कैप्चर करने के लिए एक संबंध-जागरूक ग्राफ तंत्रिका नेटवर्क का उपयोग करती है। उन तरीकों की तुलना में जो पूर्व-प्रशिक्षित मॉडल से निश्चित संबंध एम्बेडिंग का उपयोग करते हैं, हमारा मॉडल गतिशील रूप से बहु-स्रोत सबग्राफ से प्रासंगिक जानकारी के साथ संबंधों को अपडेट करता है, जो कई बाहरी ज्ञान स्रोतों से बनाया गया है। संबंधों के बढ़े हुए अभ्यावेदन को तब एक द्विदिश तर्क मॉड्यूल को खिलाया जाता है। प्रश्न अनुक्रम और संस्थाओं को जोड़ने वाले पथों के बीच एक द्विदिश ध्यान तंत्र लागू किया जाता है, जो हमें पारदर्शी व्याख्याक्षमता प्रदान करता है। CommonsenseQA डेटासेट पर प्रयोगात्मक परिणाम बताते हैं कि हमारी विधि के परिणामस्वरूप बेसलाइन पर महत्वपूर्ण सुधार होते हैं, जबकि स्पष्ट तर्क पथ भी प्रदान करते हैं।', 'ru': 'Ответ на вопросы общего смысла - это важная задача обработки естественного языка (NLP), цель которой - предсказать правильный ответ на вопрос с помощью здравого смысла. Предыдущие исследования используют предварительно обученные модели на крупномасштабных телах, таких как BERT, или выполняют рассуждения на графах знаний. Однако эти методы не моделируют отношения, связывающие сущности, которые являются информационными и могут быть использованы для улучшения рассуждений. Для решения этой проблемы мы предлагаем метод аргументации, основанный на учете отношений. Наш метод использует нейронную сеть графов с распознаванием отношений для захвата богатой контекстной информации как от сущностей, так и от отношений. По сравнению с методами, использующими вложения фиксированных отношений из предварительно обученных моделей, наша модель динамически обновляет отношения контекстной информацией из многоисточника, построенного из множества внешних источников знаний. Расширенные представления отношений затем подаются в двунаправленный модуль рассуждений. Между последовательностью вопросов и путями, соединяющими сущности, применяется двунаправленный механизм внимания, который обеспечивает нам прозрачную интерпретируемость. Экспериментальные результаты по набору данных CommonsenseQA показывают, что наш метод приводит к значительным улучшениям по сравнению с базовыми линиями, а также обеспечивает четкие пути рассуждений.', 'ga': 'Is tasc tábhachtach próiseála teanga nádúrtha (NLP) é Freagra Ceist Commonsense a bhfuil sé mar aidhm aige an freagra ceart ar cheist a thuar trí réasúnaíocht chiallmhar. Úsáideann staidéir roimhe seo samhlacha réamh-oilte ar chorpas mórscála mar BERT, nó déanann siad réasúnaíocht ar ghraif eolais. Mar sin féin, ní dhéanann na modhanna seo múnla sainráite den chaidreamh a nascann eintitis, atá faisnéiseach agus is féidir a úsáid chun an réasúnaíocht a fheabhsú. Chun aghaidh a thabhairt ar an tsaincheist seo, molaimid modh réasúnaíochta atá feasach ar an gcaidreamh. Úsáideann ár modh líonra néarach graif atá feasach ar ghaol chun an t-eolas comhthéacsúil saibhir ó aonáin agus caidreamh a ghabháil. I gcomparáid le modhanna a úsáideann leabú caidrimh sheasta ó mhúnlaí réamh-oilte, déanann ár múnla an caidreamh a nuashonrú go dinimiciúil le faisnéis chomhthéacsúil ó fhoghraf ilfhoinse, tógtha ó iliomad foinsí seachtracha eolais. Cothaítear léiriú feabhsaithe an chaidrimh ansin chuig modúl réasúnaíochta déthreoch. Cuirtear meicníocht aird dhéthreoch i bhfeidhm idir seicheamh na gceisteanna agus na cosáin a nascann eintitis, rud a thugann inléirmhíniú trédhearcach dúinn. Léiríonn torthaí turgnamhacha ar thacar sonraí CommonsenseQA go dtagann feabhsuithe suntasacha as ár modh thar na bonnlínte agus ag an am céanna cuireann sé cosáin shoiléire réasúnaíochta ar fáil.', 'el': 'Η απάντηση σε ερωτήσεις κοινής λογικής είναι μια σημαντική εργασία επεξεργασίας φυσικής γλώσσας που στοχεύει στην πρόβλεψη της σωστής απάντησης σε μια ερώτηση μέσω λογικής λογικής. Προηγούμενες μελέτες χρησιμοποιούν προ-εκπαιδευμένα μοντέλα σε μεγάλα σώματα όπως το ή εκτελούν συλλογισμό σε γραφήματα γνώσης. Ωστόσο, αυτές οι μέθοδοι δεν μοντελοποιούν ρητά τις σχέσεις που συνδέουν οντότητες, οι οποίες είναι πληροφοριακές και μπορούν να χρησιμοποιηθούν για την ενίσχυση της συλλογιστικής. Για να αντιμετωπιστεί αυτό το ζήτημα, προτείνουμε μια μέθοδο συλλογισμού με συνείδηση των σχέσεων. Η μέθοδος μας χρησιμοποιεί ένα νευρωνικό δίκτυο γραφήματος για να συλλάβει τις πλούσιες πληροφορίες περιβάλλοντος τόσο από οντότητες όσο και από σχέσεις. Σε σύγκριση με μεθόδους που χρησιμοποιούν ενσωματωμένες σταθερές σχέσεις από προ-εκπαιδευμένα μοντέλα, το μοντέλο μας ενημερώνει δυναμικά τις σχέσεις με πληροφορίες περιβάλλοντος από ένα υπογράφημα πολλαπλών πηγών, κατασκευασμένο από πολλαπλές εξωτερικές πηγές γνώσης. Οι ενισχυμένες αναπαραστάσεις των σχέσεων τροφοδοτούνται στη συνέχεια σε μια ενότητα αμφίδρομης λογικής. Εφαρμόζεται ένας αμφίδρομος μηχανισμός προσοχής μεταξύ της ακολουθίας ερωτήσεων και των διαδρομών που συνδέουν οντότητες, γεγονός που μας παρέχει διαφανή ερμηνεία. Τα πειραματικά αποτελέσματα στο σύνολο δεδομένων της Κοινής QA καταδεικνύουν ότι η μέθοδος μας οδηγεί σε σημαντικές βελτιώσεις πέρα από τις γραμμές βάσης παρέχοντας επίσης σαφείς διαδρομές συλλογισμού.', 'it': 'La risposta alle domande di commonsense è un importante compito di elaborazione del linguaggio naturale (NLP) che mira a prevedere la risposta corretta a una domanda attraverso ragionamenti di commonsense. Gli studi precedenti utilizzano modelli pre-addestrati su corpora su larga scala come BERT, o eseguono ragionamenti su grafici di conoscenza. Tuttavia, questi metodi non modellano esplicitamente le relazioni che collegano le entità, che sono informative e possono essere utilizzate per migliorare il ragionamento. Per affrontare questo problema, proponiamo un metodo di ragionamento relazionale consapevole. Il nostro metodo utilizza una rete neurale grafica consapevole delle relazioni per catturare le ricche informazioni contestuali sia dalle entità che dalle relazioni. Rispetto ai metodi che utilizzano incorporazioni di relazioni fisse da modelli pre-addestrati, il nostro modello aggiorna dinamicamente le relazioni con informazioni contestuali provenienti da un sottografico multi-source, costruito da più fonti di conoscenza esterne. Le rappresentazioni potenziate delle relazioni vengono poi alimentate ad un modulo di ragionamento bidirezionale. Un meccanismo di attenzione bidirezionale viene applicato tra la sequenza delle domande e i percorsi che collegano le entità, che ci fornisce una leggibilità trasparente. I risultati sperimentali sul set di dati CommonseQA dimostrano che il nostro metodo porta a miglioramenti significativi rispetto alle linee di base, fornendo al contempo chiari percorsi di ragionamento.', 'hu': 'Az általános kérdések megválaszolása egy fontos természetes nyelvfeldolgozási (NLP) feladat, amelynek célja, hogy megjósolja a helyes választ egy kérdésre a közértelmes érveléssel. A korábbi tanulmányok előre képzett modelleket használnak nagyszabású corporákon, mint például a BERT, vagy érvelést végeznek a tudásdiagramokon. Ezek a módszerek azonban nem modellezik kifejezetten az entitásokat összekapcsoló kapcsolatokat, amelyek információs jellegűek és használhatók az érvelés fokozására. Ennek a kérdésnek a megoldása érdekében egy kapcsolattudatos érvelési módszert javasolunk. Módszerünk egy kapcsolattudatos gráf neurális hálózatot használ, hogy mind az entitások, mind a kapcsolatok gazdag kontextuális információit rögzítsük. Azokkal a módszerekkel összehasonlítva, amelyek rögzített kapcsolatok beágyazását használják előre képzett modellekből, modellünk dinamikusan frissíti a kapcsolatokat egy több forrásból származó, több külső tudásforrásból származó kontextuális információkkal. A kapcsolatok fokozott ábrázolását ezután egy kétirányú érvelési modulba tápláljuk. A kérdéssorozat és az entitásokat összekötő útvonalak között kétirányú figyelmet alkalmazunk, ami átlátható értelmezhetőséget biztosít számunkra. A CommonseQA adatkészleten szereplő kísérleti eredmények azt mutatják, hogy módszerünk jelentős javulást eredményez a kiindulási vonalakhoz képest, miközben világos érvelési utakat is biztosít.', 'kk': 'Жауап беру - маңызды тәуелді тілді өңдеу (NLP) тапсырмасы. Бұл сұраққа дұрыс жауап беруді көпшілікті сезім арқылы көпшілікті түсініктемелеу үшін маңызд Алдыңғы зерттеулері BERT секілді үлкен масштабтағы корпораға алдын- ала оқылған үлгілер қолданылады немесе білім графиктерінің түсініктемесін жасайды. Бұл әдістер бірліктерді қосып, мәліметті қосылу үшін қолданатын қатынастарды түсіндірмейді. Бұл мәселеге сәйкес беру үшін біз қатынастың түсінікті түсінікті әдісін ұсынамыз. Біздің әдіміміз қатынасыз белгілі график неврал желіне қатынасыз керек контексті мәліметті жасау үшін қолданылады. Алдын- оқылған үлгілерден тұрақты қатынастарды қолданатын әдістерімен салыстырып, біздің үлгіміз бірнеше сыртқы білім көзінен құрылған көптеген көптеген мәліметтермен қатынастарды динамикалық жаң Қатысушылардың көтерілген түсініктемелері, содан кейін екі директивалық түсініктеме модуліне беріледі. Бізге мөлдірлікті түсініктемелерді беретін сұрақ ретінде және біздің қосылу жолдары арасында қолданылады. CommonsenseQA деректер қорларының эксперименталдық нәтижелері біздің әдіміміз негізгі жолдардың негізгі жақсартылығын көрсетеді, сондай-ақ таңдау жолдарын қолдану керек болса да', 'lt': 'Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning.  Ankstesniuose tyrimuose naudojami iš anksto parengti didelio masto korporacijų modeliai, pvz., BERT, arba pagrįsti žinių grafiką. However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning.  To address this issue, we propose a relation-aware reasoning method.  Mūsų metodas naudoja ryšiams žinomą grafinį nervinį tinklą, kad gautų turtingą kontekstinę informaciją ir iš subjektų, ir iš santykių. Palyginti su metodais, kuriais naudojami fiksuotų santykių įterpimai iš iš anksto parengtų modelių, mūsų modelis dinamiškai atnaujina santykius su kontekstine informacija iš daugialypio pografo, sukurto iš įvairių išorinių žinių šaltinių. The enhanced representations of relations are then fed to a bidirectional reasoning module.  A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability.  Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'mk': 'Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning.  Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform reasoning on knowledge graphs.  Сепак, овие методи не експлицитно ги моделираат односите кои ги поврзуваат ентитетите, кои се информативни и можат да се користат за подобрување на размислувањето. За да го решиме ова прашање, предлагаме метод на размислување свесен за односите. Нашиот метод користи неврална мрежа на график со свесност за односи за да ги фати богатите контекстуални информации од ентитетите и односите. Во споредба со методите кои користат фиксни односи вклучени од предобучени модели, нашиот модел динамично ги оневозможува односите со контекстни информации од мултиизворен субграф, изграден од повеќе надворешни извори на знаење. Подготвените претставувања на односите потоа се прехранат со дворечен модул за размислување. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability.  Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'ka': 'საზოგადოებო კითხვების პასუხი არის მნიშვნელოვანი თავისუფალური ენის პროცესი (NLP) რაოდენობა, რომელიც უნდა წინახოთ მარტივი პასუხი კითხვის საზოგადოება წინა სწავლება იყენებს უფრო დიდი მაგალითი კორპორაში, როგორც BERT, ან გავაკეთებთ უცნობის გრაფიკზე პასუხი. მაგრამ, ეს მეტი არ გამოიყენება განსაზღვრებული განსაზღვრებების შესახებ, რომლებიც ინფორმაციულია და შეიძლება გამოიყენება პარამენტის უფლებისთვის. ამ პრობლემას გადაწყვეტის შესახებ, ჩვენ მინდომებით პრობლემა დავიცნობით პარამენტის მეტი. ჩვენი მეთოდი გამოყენება გრაფიკური ნეიროლური ქსელი, რომელიც განსაზღვრებული კონტექსტური ინფორმაციას და განსაზღვრებებიდან გამოყენებს. ჩვენი მოდელი დინამიკურად განახლებელია კონტექსტური ინფორმაციის მრავალფორმაციის სპეგრაფიდან, რაც მრავალფორმაციის გარეშე ინფორმაციის გამოყენებულია. შემდეგ უფრო დიდირექციური განსაზღვრებების მოდულისთვის გადატანა. კითხვების წესების და გეზების შესახებ, რომლებიც ჩვენ დავუკავშირებთ განსხვავებელობით. ექსპერიმენტიური შედეგები CommonsenseQA მონაცემების შესახებ ილუსტრირებს, რომ ჩვენი მედიოდის შედეგება მნიშვნელოვანი გაუქმედება ბაზის ხაზების შესახებ, როცა ასევე', 'ml': 'കമോണ്\u200dസണ്\u200dസെന്\u200dസ് ചോദ്യങ്ങള്\u200d മുമ്പുള്ള പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d ബെര്\u200dട്ടിയെപ്പോലെയുള്ള കോര്\u200dപ്പോരിയില്\u200d ഉപയോഗിക്കുന്നു, അല്ലെങ്കില്\u200d  എന്നാലും ഈ രീതികള്\u200d വ്യക്തമായി ബന്ധപ്പെടുത്തുന്ന സാധനങ്ങളുടെ ബന്ധങ്ങള്\u200d മാതൃകയില്ല, അത് വിവരങ്ങള്\u200d വിവരങ്ങളാണ്. കാരണങ്ങള്\u200d കൂ ഈ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു ബന്ധപ്പെട്ട കാര്യങ്ങളുടെ രീതിയില്\u200d പ്രാ നമ്മുടെ രീതിയില്\u200d സമ്പന്നരായ സാധനങ്ങളില്\u200d നിന്നും ബന്ധങ്ങളില്\u200d നിന്നും സമ്പന്നരായ വിവരങ്ങള്\u200d പിടികൂടാന്\u200d ബന്ധപ്പെട് മുമ്പ് പരിശീലന മോഡലില്\u200d നിന്നും നിശ്ചയിച്ച ബന്ധങ്ങള്\u200d ഉപയോഗിക്കുന്ന രീതികളോടൊപ്പമാണ് ഞങ്ങളുടെ മോഡല്\u200d ഡൈനാമിക്കല്\u200d വിവരങ്ങളുമായി പുതുക്കുന്നത്, പല-സോ ബന്ധങ്ങളുടെ മെച്ചപ്പെട്ട പ്രതിനിധികള്\u200d പിന്നീട് ഒരു ബിഡിയര്\u200dട്ടിക്കല്\u200d കാരണങ്ങളുടെ ഘടകം തിന്നുന്നു. ചോദ്യത്തിന്റെ സെക്കന്റിനും സാധാരണ വസ്തുക്കളെ ബന്ധപ്പെടുത്തുന്ന വഴികള്\u200dക്കും ഇടയില്\u200d ശ്രദ്ധ പ്രയോഗിക്കുന്നു. അത് നമുക്ക്  ക്യൂഎ ഡാറ്റാസെറ്റിന്റെ പരീക്ഷണ ഫലങ്ങള്\u200d വ്യക്തമാക്കുന്നു നമ്മുടെ രീതിയില്\u200d നമ്മുടെ മാര്\u200dഗ്ഗങ്ങള്\u200d അടിസ്ഥാനങ്ങളില്\u200d മുന്\u200dഗണന മ', 'mt': 'It-tweġiba għall-mistoqsijiet komuni hija kompitu importanti ta’ pproċessar tal-lingwi naturali (NLP) li għandu l-għan li jipprevedi t-tweġiba korretta għal mistoqsija permezz ta’ raġunament komuni. Studji pre ċedenti jużaw mudelli mħarrġa minn qabel fuq korpra fuq skala kbira bħal BERT, jew iwettqu raġunament fuq grafiċi tal-għarfien. However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning.  Biex nindirizzaw din il-kwistjoni, nipproponu metodu ta’ raġunament li jkun konxju tar-relazzjoni. Il-metodu tagħna juża netwerk newrali grafiku konxju tar-relazzjoni biex jinqabad l-informazzjoni kuntestwali rikka kemm mill-entitajiet kif ukoll mir-relazzjonijiet. Meta mqabbel ma’ metodi li jużaw inkorporazzjonijiet ta’ relazzjonijiet fissi minn mudelli mħarrġa minn qabel, il-mudell tagħna jaġġorna b’mod dinamiku r-relazzjonijiet ma’ informazzjoni kuntestwali minn sottografu b’diversi sorsi, mibni minn diversi sorsi esterni ta’ għarfien. Imbagħad ir-rappreżentazzjonijiet imtejba tar-relazzjonijiet jingħataw lil modulu ta’ raġunament bidirezzjonali. Mekkaniżmu ta’ attenzjoni bidirezzjonali huwa applikat bejn is-sekwenza tal-mistoqsijiet u l-mogħdijiet li jgħaqqdu l-entitajiet, li jipprovdilna interpretabbiltà trasparenti. Riżultati esperimentali dwar is-sett tad-dejta CommonsenseQA juru li l-metodu tagħna jirriżulta f’titjib sinifikanti fuq il-linji bażi filwaqt li jipprovdi wkoll rotot ċari ta’ raġunament.', 'ms': 'Jawapan soalan umum adalah tugas pemprosesan bahasa alam (NLP) yang bermaksud meramalkan jawapan yang betul kepada soalan melalui alasan umum. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform reasoning on knowledge graphs.  However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning.  Untuk mengatasi isu ini, kami cadangkan kaedah alasan yang sedar hubungan. Kaedah kami menggunakan rangkaian saraf graf yang sedar hubungan untuk menangkap maklumat kontekstual kaya dari kedua-dua entiti dan hubungan. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources.  The enhanced representations of relations are then fed to a bidirectional reasoning module.  A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability.  Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'pl': 'Odpowiedź na pytania Commonsense jest ważnym zadaniem przetwarzania języka naturalnego (NLP), którego celem jest przewidywanie poprawnej odpowiedzi na pytanie poprzez rozumowanie zdrowego rozsądku. Poprzednie badania wykorzystują wstępnie przeszkolone modele na dużych korporach, takich jak BERT, lub wykonują rozumowanie na wykresach wiedzy. Metody te nie modelują jednak wyraźnie relacji łączących podmioty, które są informacyjne i mogą być wykorzystane do wzmocnienia rozumowania. Aby rozwiązać tę kwestię, proponujemy metodę rozumowania świadomego relacji. Nasza metoda wykorzystuje świadomą relacji wykresu sieć neuronową do przechwytywania bogatych informacji kontekstowych zarówno z podmiotów, jak i relacji. W porównaniu z metodami, które wykorzystują osadzenia relacji stałych z wstępnie przeszkolonych modeli, nasz model dynamicznie aktualizuje relacje z informacjami kontekstowymi z podgrafu wielu źródeł, zbudowanego z wielu zewnętrznych źródeł wiedzy. Ulepszone reprezentacje relacji są następnie przekazywane do dwukierunkowego modułu rozumowania. Między sekwencją pytań a ścieżkami łączącymi podmioty stosuje się dwukierunkowy mechanizm uwagi, co zapewnia nam przejrzystą interpretację. Wyniki eksperymentalne na zbiorze danych CommonseQA ilustrują, że nasza metoda skutkuje znaczącymi ulepszeniami w stosunku do linii bazowych, zapewniając jednocześnie jasne ścieżki rozumowania.', 'mn': 'Хариулт нь хамгийн чухал байгалийн хэл үйлдвэрлэл (NLP) юм. Энэ нь асуултын зөв хариултыг олон ойлголтын үр дүнд таамаглах зорилго юм. Өмнөх судалгаанууд БЕРТ шиг том хэмжээний корпоратын өмнө суралцагдсан загваруудыг ашиглаж, эсвэл мэдлэг графикийн талаар бодлого хийдэг. Гэхдээ эдгээр арга нь мэдээлэл болон урьдчилан сэтгэл хөдлөхийн тулд хэрэглэгдэж болно. Энэ асуудлыг асуухын тулд бид холбоотой ойлголтын аргыг санал болгоно. Бидний арга нь харилцааны мэдрэгч график мэдрэлийн мэдрэлийн сүлжээг ашиглаж байдаг. Өмнөх сургалтын загвараас тогтмол харилцаа ашигладаг арга загвартай харьцуулсан. Бидний загвар нь олон эх үүсвэрийн субграфикийн харилцаа, олон гадаад мэдлэгтэй эх үүсвэрээс бүтээгдэхүүнтэй харилцаа шинэчлүүлдэг. Хариултын илүү өндөртэй харилцааны илэрхийлэл дараа нь хоёр дахь арга хэмжээний шалтгаан модуль болно. Энэ нь бидэнд тодорхой ойлголтын тухай холбогдож байгаа асуулт дарааллын хоорондоо холбогдолтой анхаарлын механизм хэрэглэгддэг. CommonsenseQA өгөгдлийн сангийн туршилтын үр дүнд бидний арга нь суурь шугам дээр маш чухал сайжруулах боломжтой гэдгийг харуулдаг.', 'sr': 'Odgovor na pitanje javnosti je važan prirodni jezik obrađivanja (NLP) zadatak koji je cilj predviđati ispravan odgovor na pitanje kroz objašnjenje razuma. Prethodne studije koriste predobučene modele na velikoj korporaciji kao što je BERT, ili izvode razgovor o graficima znanja. Međutim, ove metode ne obrađuju jasno odnose koje povezuju entitate, koje su informativne i koje se mogu koristiti za poboljšanje razuma. Da bi se riješili ovom pitanju, predlažemo metodu razumljivanja svesti odnosa. Naša metoda koristi neuralnu mrežu sa svijestima veze kako bi uhvatili bogate kontekstualne informacije od objekata i odnosa. U usporedbi sa metodama koja koriste fiksne veze iz predobučenih model a, naš model dinamički aktualizuje odnose sa kontekstualnim informacijama iz višeizvorskog podgrafa, izgrađenih iz višestrukih izvora spoljnih znanja. Povećane predstave odnosa se onda hrane za dvodirektivni modul razuma. Mehanizam za dvodirektivnu pažnju se primjenjuje između sekvence pitanja i puteva koje povezuju entitete, koja nam pruža transparentnu interpretabilnost. Eksperimentalni rezultati na kompletu podataka CommonsenseQA ukazuju na to da naša metoda rezultira značajnim poboljšanjima preko osnovnih linija, a takođe pružaju jasne puteve razumljivanja.', 'so': "jawaabta su'aalka heshiiska waa shaqo muhiim ah oo ka baaraandegista afka asalka ah (NLP) oo ku qoran karta jawaabta saxda ah ee su'aalka ku saabsan sababta shirkadda. Waxbarashada hore waxay ku isticmaali karaan tusaale ahaan shirkad aad u weyn, sida BERT, ama waxay sameyn karaan sababo ku saabsan sawirada aqoonta. However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning.  Si aan arrintan ula macaamilo karno, waxaynu soo jeedaynaa qaab ku saabsan waxyaabaha xiriirka. Metalkeenu wuxuu isticmaalaa shabakadda caqabadaha ee la xiriira si uu taajirka ah uga qabsado macluumaadka joogtada ah ee dhamaanka iyo xiriirka. Isbarbarbardhig qaababka isticmaalaya meelaha ku xiriirta ee saxda ah oo ka soo bandhigaya modellada hore-tababarida, modelkayaga ayaa si dynamic ah u cusboonaysa xiriirka la xiriira macluumaadka joogtada ah xagga subgraf badan oo laga dhisay noocyo badan oo aqoonta dibadda ah. Dhaqaalaha horumarinta ee xiriirka waxaa lagu siiyaa nooca sababta qasabka ah. Isku xiriirka daryeelka la xiriira waxaa lagu dalban karaa qaababka su'aalaha iyo waddooyinka la xiriira waxyaabaha la xiriira, kaas oo na siiya turjubaan muuqda. QA macluumaadka ku saabsan imtixaanka waxaa ka muuqda in qaababkayaga uu ka soo jeedaa hagaajiyada saldhigga hoose iyo sidoo kale lagu siinayo wadooyin cad.", 'no': 'Svar på spørsmål om kommunikasjon er ein viktig naturspråk- handsaming (NLP) oppgåve som mål å foregå korrekt svar på eit spørsmål gjennom vanleg rasjon. Førre studier brukar føretrainerte modeller på storskala korpora som BERT, eller utfør rasjon på kunnskapsgrafene. Desse metodane er imidlertid ikkje eksplisisert modeller forholdene som koplar til einingar, som er informasjonelle og kan brukast for å forbetra rasjonar. For å handtera dette problemet, foreslår vi ein samsvarsverdingsmetode. Metoden vårt bruker eit relasjonsvart grafennettverk for å henta rikt kontekstinformasjon frå både einingar og relasjonar. Sammenlignet med metodar som brukar fast relasjonsinnbygging frå før- trengte modeller, vår modell dynamisk oppdaterer relasjon med kontekstinformasjon frå ein fleire kjeldeundergraf, bygd frå fleire eksterne kunnskjelder. Den forbetre representasjonane av relasjonane blir derfor tilført til ein bidireksjonal redeksjonsmodul. Dette er brukt ein bidireksjonal oppmerksmekanisme mellom spørsmålsrekvensen og banene som koplar opplysningar, som gjev oss gjennomsiktig tolkingar. Eksperimentale resultat på datasettet CommonsenseQA illustrerer at metoden vårt resulterer i signifikante forbedringar over baselinjene medan også tilbyr klare årsaker.', 'ro': 'Răspunsul la întrebări de bază este o sarcină importantă de procesare a limbajului natural (PNL), care are ca scop prezicerea răspunsului corect la o întrebare prin raționament de bază. Studiile anterioare utilizează modele pre-instruite pe corporații la scară largă, cum ar fi BERT, sau efectuează raționament pe grafice de cunoaștere. Cu toate acestea, aceste metode nu modelează explicit relațiile care conectează entitățile, care sunt informaționale și pot fi folosite pentru a spori raționamentul. Pentru a aborda această problemă, propunem o metodă de raționament conștientă de relație. Metoda noastră folosește o rețea neuronală grafică conștientă de relații pentru a capta informațiile contextuale bogate atât de la entități, cât și de la relații. Comparativ cu metodele care utilizează încorporări de relații fixe din modele pre-instruite, modelul nostru actualizează dinamic relațiile cu informații contextuale dintr-un subgraf multi-sursă, construit din mai multe surse externe de cunoștințe. Reprezentările îmbunătățite ale relațiilor sunt apoi alimentate unui modul de raționament bidirecțional. Se aplică un mecanism bidirecțional de atenție între secvența de întrebări și căile care conectează entitățile, ceea ce ne oferă o interpretare transparentă. Rezultatele experimentale ale setului de date CommonseQA ilustrează faptul că metoda noastră duce la îmbunătățiri semnificative față de liniile de referință, oferind, de asemenea, căi clare de raționament.', 'sv': 'Commonsense Question Answering är en viktig uppgift för Natural Language Processing (NLP) som syftar till att förutsäga rätt svar på en fråga genom allmänt förnuft resonemang. Tidigare studier använder sig av pre-utbildade modeller på storskaliga corpora som BERT, eller utför resonemang på kunskapsgrafer. Dessa metoder modellerar dock inte uttryckligen relationerna som förbinder entiteter, som är informativa och kan användas för att förbättra resonemanget. För att ta itu med denna fråga föreslår vi en förhållandemedveten resonemetod. Vår metod använder ett relationsmedvetet grafneuralt nätverk för att fånga den rika kontextuella informationen från både entiteter och relationer. Jämfört med metoder som använder fasta relationer inbäddningar från förutbildade modeller uppdaterar vår modell dynamiskt relationer med kontextuell information från en undergraf med flera källor, byggd från flera externa kunskapskällor. De förbättrade representationerna av relationer matas sedan till en tvåriktad resonemodul. En tvåriktad uppmärksamhetsmekanism tillämpas mellan frågesekvensen och de vägar som förbinder entiteter, vilket ger oss transparent tolkning. Experimentella resultat på CommonseQA-datauppsättningen visar att vår metod resulterar i betydande förbättringar jämfört med baslinjerna samtidigt som den ger tydliga resonemang vägar.', 'ta': 'தொழில்நுட்பம் கேள்வி பதில் ஒரு முக்கியமான இயல்பான மொழி செயல்பாடு (NLP) செயல்பாடு, ஒரு கேள்விக்கு சரியான விடையை முன்வாக்கு முந்தைய ஆய்வுகள் BERT போன்ற பெரிய அளவு நிறுவனத்தில் முன்பயிற்சிய மாதிரிகளை பயன்படுத்துகிறது, அல்லது அறிவு வரைபடங்கள் பற் எனினும், இந்த முறைகள் வெளிப்படையாக மாற்றுவதில்லை பொருள்களை இணைக்கும் தொடர்புகள், அது தகவல் மற்றும் காரணத்தை அதிகரிக்க பயன்பட இந்த பிரச்சனையை விளக்க, நாம் ஒரு தொடர்பு அறிந்து கொள்ளும் காரணங்கள் முறையை பரிந்துரைக்க Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations.  முன் பயிற்சிக்கப்பட்ட மாதிரிகளிலிருந்து நிலையான தொடர்பு உள்ளிடுதலை பயன்படுத்தும் முறைமைகளை ஒப்பிட்டால், எங்கள் மாதிரி தானாகவே தேவைப்படுத்தும் தற் மேம்படுத்தப்பட்ட உறவுகளின் குறிப்புகள் பின்னர் ஒரு கட்டுப்பாடு காரணம் கூறுக்கு உணவளிக்கப்படுகின்றன. கேள்வி விகிதத்திற்கும் மற்றும் இணைக்கும் பாதைகளுக்கும் இடையே ஒரு பிடியாக கவனம் முறைமை QA தரவுத்தளத்தின் முடிவுகள் குறிப்பிடுகிறது நமது முறைமை அடிப்பகுதிகளில் முக்கியமான முன்னேற்றங்களை கொண்டு வருகிறது மற்றும் த', 'si': 'සම්බන්ධ ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්නයක් වැදගත් ස්වභාවික භාෂාව ප්\u200dරශ්නයක් (NLP) වැඩක් වෙන්නේ ඒක සා මුලින් පරීක්ෂණ අධ්\u200dයානය සඳහා ප්\u200dරධානය කරලා තියෙන්න පුළුවන් ප්\u200dරධානය කරලා තියෙන්නේ බෙර්ට් වගේ ල නමුත්, මේ විධානය ප්\u200dරශ්නයෙන්ම නිර්මාණය කරන්නේ නැහැ සම්බන්ධතාවන් සම්බන්ධ වෙනුවෙන් සම්බන්ධතාවන් මේ ප්\u200dරශ්නය විස්තර කරන්න, අපි සම්බන්ධ විස්තරයක් ප්\u200dරශ්නය කරනවා. අපේ විධානය ප්\u200dරයෝජනය සම්බන්ධ වෙන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරනවා සම්බන්ධ විධානය සහ සම්බන්ධ ව මුලින් ප්\u200dරශ්නය කරපු මොඩල් වලින් ස්ථිර සම්බන්ධ සම්බන්ධයක් භාවිත කරපු විදියට සම්බන්ධ විදියට සම්බන්ධ විදියට, අපේ මො සම්බන්ධ සංවිධානය ගැන වැඩි සංවිධානයක් පස්සේ දෙන්න පුළුවන් විදියට සම්බන්ධ විශ් ප්\u200dරශ්න පද්ධතිය සහ ප්\u200dරශ්න පද්ධතිය සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් ප්\u200dරශ්න පද්ධතිය සඳහා ප්\u200dරශ් කොම්සෙන්ස්ස් QA දත්ත සෙට් එකේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර විදිහට ප්\u200dරතිචාර කරනවා අපේ විදිහට ප්\u200dරතිචාර වි', 'ur': 'کمنسیس سؤال جواب دینے کا ایک اہم طبیعی زبان پردازی (NLP) کام ہے جو ایک سؤال کے درست جواب کو معلوم کرنا چاہتا ہے۔ پہلے کی مطالعہ سے پہلے تدریس کی موڈلیاں بڑے مقدار کورپور پر استعمال کرتے ہیں جیسے BERT، یا علم گراف کے بارے میں بحث کرتے ہیں. However, these methods do not explicitly model the relationships that connect entities, which are informal and can be used to enhance reasoning. اس مسئلہ کے بارے میں ہم ایک رابطہ جانتے ہوئے منظور کا طریقہ پیش کریں گے۔ ہمارا طریقہ ایک رابطہ معلوم گراف نائرول نیٹورک کا استعمال کرتا ہے کہ دونوں شرکتوں اور رابطہ سے ثروت منصفات معلومات کو پکڑے۔ ان طریقوں سے مقررہ نسبت ایمبڈینگ استعمال کرتی ہیں جو پہلے تدریس کی موڈل سے استعمال کرتے ہیں، ہمارے موڈل کو ہدایت سے متوسط معلومات کے ساتھ متوسط سورج زیب گراف سے آغاز کرتا ہے، جو بہت سے باہر علم سوسوں سے بنائے جاتے ہیں. اس کے بعد رابطہ کی مزید نمونات ایک دوسری رابطہ منظور موڈیل کو کھایا جاتا ہے. سؤال کے سفارش اور مسیروں کے درمیان ایک دوسری توجه کی مکانیزی کاربرد کی جاتی ہے جو واضح تعبیر کے ذریعہ ہمیں پیدا کرتی ہے۔ کمنسیس کیا ڈاٹ سٹ پر تجربہ کا نتیجہ دکھاتا ہے کہ ہمارا طریقہ بنیاس لینوں پر بہت اضافہ ہوتا ہے اور واضح منطقی طریقے بھی پیش کرتا ہے۔', 'uz': "Comment Oldingi taʼminlovlar BERT kabi katta taʼminlovchi modellardan foydalanadi, yoki ta'minlovchi grafik haqida ko'rsatish mumkin. Lekin, bu usullar maʼlumot maʼlumot va sabablarni oshirish uchun ishlatiladi. Bu muammolani boshqarish uchun biz murakkab o'xshash ma'lumot usulini talab qilamiz. Bizning usuli bog'liq grafik neyron tarmoqda foydalanadi va ma'lumotlar va bogʻliqlaridagi taxminan taxminan taxpaytlarni qabul qilish uchun. Oldingi taʼminlovchi modellardan foydalanuvchi usullarga kamaytirish mumkin, modelimiz bir necha tarkibi maʼlumotdan bir necha xil maʼlumot manbasiga yaratiladigan multidan foydalanuvchi maʼlumot bilan yangilanadi. Name Name QA maʼlumotlar tarkibini tahrirlash natijalari mumkin, bizning usuli asosiy satrlarida juda muhim yaxshi o'zgarishga ega, va bu yerda clear reasoning yoʻllarini beradi.", 'vi': 'Câu trả lời bình thường là một nhiệm vụ xử lý ngôn ngữ tự nhiên quan trọng, nhằm dự đoán câu trả lời đúng vào một câu hỏi bằng một lý lẽ thông thường. Những nghiên cứu trước sử dụng các mô hình được rèn luyện trên quy mô lớn như BERT, hay làm lý lẽ về biểu đồ kiến thức. Tuy nhiên, các phương pháp này không thể mô tả rõ ràng các mối quan hệ kết nối các thực thể, mà là thông tin và có thể dùng để tăng lý trí. Để giải quyết vấn đề này, chúng tôi đề xuất phương pháp lập luận quan trọng. Phương pháp của chúng tôi sử dụng một mạng lưới thần kinh dày-nhạy với quan điểm để thu thập các thông tin ngữ cảnh giàu có từ cả các thực thể và quan hệ. So với các phương pháp dùng mối quan hệ cố định từ các mẫu được huấn luyện trước, mẫu của chúng ta cập nhật theo động lực các mối quan hệ với các nội dung từ một tiểu thư đa nguồn, được xây dựng từ nhiều nguồn kiến thức bên ngoài. Sau đó những biểu hiện của quan hệ được cung cấp cho một mô-đun lý lẽ hai trực tiếp. Giữa chuỗi câu hỏi và các đường dẫn kết nối các thực thể, nó cho chúng ta dễ hiểu hơn. Các kết quả thử nghiệm của bộ dữ liệu Commonwealth QA, cho thấy phương pháp của chúng tôi dẫn tới một sự cải tiến đáng kể trên các đường hầm, và cũng cho thấy các phương pháp rõ ràng.', 'da': 'Commonsense Spørgsmål Besvarelse er en vigtig Natural Language Processing (NLP) opgave, der sigter mod at forudsige det korrekte svar på et spørgsmål gennem almindelig ræsonnement. Tidligere undersøgelser anvender præ-trænede modeller på store corpora såsom BERT, eller udfører ræsonnement på vidensgrafer. Disse metoder modellerer imidlertid ikke eksplicit de relationer, der forbinder enheder, som er informative og kan bruges til at forbedre ræsonnement. For at løse dette problem foreslår vi en relationsbevidst ræsonnement metode. Vores metode bruger et relationsbevidst grafneuralt netværk til at fange de rige kontekstuelle oplysninger fra både enheder og relationer. Sammenlignet med metoder, der bruger faste relationsindlejringer fra prætrænede modeller, opdaterer vores model dynamisk relationerne med kontekstuel information fra en multi-source undergraf, bygget fra flere eksterne videnkilder. De forbedrede repræsentationer af relationer føres derefter til et bidirektionelt ræsonnement modul. Der anvendes en todirektiv opmærksomhedsmekanisme mellem spørgsmålssekvensen og de stier, der forbinder enheder, hvilket giver os gennemsigtig fortolkning. Eksperimentelle resultater på CommonseQA datasættet illustrerer, at vores metode resulterer i betydelige forbedringer i forhold til basislinjerne og samtidig giver klare ræsonneringsveje.', 'bg': 'Отговарянето на въпроси е важна задача за обработка на естествения език (НЛП), която има за цел да предвиди правилния отговор на въпрос чрез разумно разсъждение. Предишни проучвания използват предварително обучени модели върху мащабни корпуси като или извършват разсъждения върху графики на знанието. Тези методи обаче не моделират изрично отношенията, които свързват субектите, които са информационни и могат да се използват за подобряване на разсъжденията. За да се справим с този проблем, предлагаме метод на разсъждение, осъзнаващ отношенията. Нашият метод използва графична невронна мрежа, която отчита връзките, за да улови богатата контекстуална информация както от единици, така и от релации. В сравнение с методите, които използват вграждания с фиксирани релации от предварително обучени модели, нашият модел динамично актуализира отношенията с контекстуална информация от подграфа с много източници, изградена от множество външни източници на знание. Подобрените представи на отношенията след това се подават към двупосочен модул за разсъждение. Между последователността на въпросите и пътищата, които свързват субектите, се прилага двупосочен механизъм за внимание, което ни осигурява прозрачна интерпретация. Експерименталните резултати на набора от данни илюстрират, че методът ни води до значителни подобрения спрямо базовите линии, като същевременно предоставя ясни пътища на разсъждение.', 'de': 'Commonsense Question Answering ist eine wichtige Aufgabe zur Verarbeitung natürlicher Sprache (NLP), die darauf abzielt, die richtige Antwort auf eine Frage durch Vernunft vorherzusagen. Frühere Studien verwenden vortrainierte Modelle auf großen Korpora wie BERT oder führen Argumentation auf Wissensgraphen durch. Diese Methoden modellieren jedoch nicht explizit die Beziehungen, die Entitäten verbinden, die informativ sind und zur Verbesserung der Argumentation verwendet werden können. Um dieses Problem anzugehen, schlagen wir eine relationsbewusste Argumentationsmethode vor. Unsere Methode verwendet ein relationsbewusstes neuronales Graphennetzwerk, um die reichhaltigen Kontextinformationen sowohl von Entitäten als auch von Beziehungen zu erfassen. Im Vergleich zu Methoden, die feste Beziehungseinbettungen aus vortrainierten Modellen verwenden, aktualisiert unser Modell Beziehungen dynamisch mit kontextuellen Informationen aus einem Multi-Source-Subgraph, der aus mehreren externen Wissensquellen erstellt wurde. Die erweiterten Darstellungen von Beziehungen werden dann einem bidirektionalen Argumentationsmodul zugeführt. Zwischen der Fragesequenz und den Pfaden, die Entitäten verbinden, wird ein bidirektionaler Aufmerksamkeitsmechanismus angewendet, der uns eine transparente Interpretierbarkeit bietet. Experimentelle Ergebnisse auf dem CommonsQA Datensatz zeigen, dass unsere Methode zu signifikanten Verbesserungen gegenüber den Basislinien führt und gleichzeitig klare Argumentationspfade liefert.', 'nl': "Het beantwoorden van Commonsense Questions is een belangrijke taak voor het verwerken van natuurlijke talen (NLP) die tot doel heeft het juiste antwoord op een vraag te voorspellen door middel van gezond verstand. Eerdere studies maken gebruik van vooraf getrainde modellen op grootschalige corpora's zoals BERT, of voeren redenering uit op kennisgrafieken. Deze methoden modelleren echter niet expliciet de relaties die entiteiten verbinden, die informatief zijn en kunnen worden gebruikt om redenering te verbeteren. Om dit probleem aan te pakken, stellen we een relatiebewuste redeneringsmethode voor. Onze methode maakt gebruik van een relatiebewust grafisch neuraal netwerk om de rijke contextuele informatie van zowel entiteiten als relaties vast te leggen. Vergeleken met methoden die vaste relaties insluiten uit vooraf getrainde modellen, werkt ons model relaties dynamisch bij met contextuele informatie uit een subgraaf uit meerdere bronnen, opgebouwd uit meerdere externe kennisbronnen. De verbeterde representaties van relaties worden vervolgens gevoed naar een bidirectionele redeneringsmodule. Er wordt een bidirectioneel aandachtsmechanisme toegepast tussen de vragenvolgorde en de paden die entiteiten verbinden, wat ons een transparante interpreteerbaarheid biedt. Experimentele resultaten op de CommonseQA dataset illustreren dat onze methode resulteert in significante verbeteringen ten opzichte van de baselines en tegelijkertijd duidelijke redeneringspaden biedt.", 'hr': 'Odgovor na pitanje javnosti je važan zadatak prirodnog obradivanja jezika (NLP), koji je cilj predvidjeti ispravan odgovor na pitanje putem razmišljanja o zajedničkom smislu. Prethodna ispitivanja koriste predobučene modele na velikoj korporaciji kao što je BERT, ili izvode razgovor o graficima znanja. Međutim, te metode ne izračunaju objašnjenje odnosa koje povezuju subjekte, koje su informativne i mogu se koristiti za poboljšanje razuma. Da bi se riješili ovom pitanju, predlažemo metodu razumljivanja svjesnog odnosa. Naša metoda koristi neuralnu mrežu s svijestima veze kako bi uhvatili bogate kontekstualne informacije od objekata i odnosa. U usporedbi s metodama koje koriste utvrđene veze iz predobučenih model a, naš model dinamički aktualizira odnose s kontekstskim informacijama iz višeizvornog podgrafa, izgrađene iz višestrukih izvora vanjskih znanja. Povećane predstave odnosa se onda hrane za dvodirektivni modul razuma. Mehanizam privlačne pažnje primjenjuje se između sekvence pitanja i puteva koje povezuju entitate, koja nam pruža transparentnu interpretabilnost. Eksperimentalni rezultati na kompletu podataka CommonsenseQA ukazuju na to da naša metoda rezultira značajnim poboljšanjima preko početnih linija, a također pružaju jasne puteve razumljivanja.', 'fa': 'پاسخ سؤال هماهنگ یک وظیفه پرداخت زبان طبیعی مهم است که هدف دارد پاسخ درست به یک سؤال را از طریق دلیل عادی پیش بینی کند. مطالعات قبلی از مدل های پیش آموزش شده در شرکت بسیار بزرگ مانند BERT استفاده می\u200cکند، یا دلیل\u200cگیری در گرافهای علم انجام می\u200cدهد. با این حال، این روش\u200cها روابط\u200cهایی را که وابسته\u200cهایی هستند، که اطلاعاتی هستند و می\u200cتوانند برای افزایش منطق استفاده کنند، به طور کامل نمونه نمی\u200cکنند. برای حل این مسئله، ما یک روش منطقی با ارتباط پیشنهاد می کنیم. روش ما از یک شبکه عصبی با ارتباط آگاهی استفاده می\u200cکند تا اطلاعات موضوع ثروتمندی را از هر موضوع و ارتباط بگیرد. در مقایسه با روش\u200cهای استفاده از رابطه\u200cهای ثابت استفاده از مدل\u200cهای پیش آموزش شده، مدل ما با اطلاعات متوسط از یک زیر منبع متوسط، از منبع\u200cهای دانش\u200cهای خارجی بسته شده است. نمایش\u200cهای بیشتر رابطه\u200cها سپس به یک مولد منطقی دوباره تغذیه می\u200cشوند. یک مکانیسم توجه دوره\u200cای بین رده\u200cی سوال و مسیر\u200cهایی که متصل کردن واحد\u200cها هستند، که ما را با تفسیر شفافیت می\u200cدهد، اجازه می\u200cدهد. نتیجه\u200cهای تجربه روی مجموعه داده\u200cهای CommonsenseQA نشان می\u200cدهند که روش\u200cهای ما به بهترین شدید روی خطوط پایین\u200cها نتیجه می\u200cدهد و همچنین راه\u200cهای منطقی روشن می\u200cدهد.', 'id': 'Jawaban Pertanyaan Komuni adalah tugas penting proses bahasa alam (NLP) yang bertujuan untuk memprediksi jawaban yang benar kepada pertanyaan melalui alasan yang sama. Studi sebelumnya menggunakan model prapelatih pada korpra skala besar seperti BERT, atau melakukan alasan pada grafik pengetahuan. Namun, metode-metode ini tidak secara eksplicit model hubungan yang menghubungkan entitas, yang informasional dan dapat digunakan untuk meningkatkan alasan. Untuk mengatasi masalah ini, kami mengusulkan metode alasan yang menyadari hubungan. Metode kami menggunakan jaringan saraf grafik yang sadar hubungan untuk menangkap informasi kontekstual kaya dari entitas dan hubungan. Dibandingkan dengan metode yang menggunakan hubungan tetap embedding dari model pra-terlatih, model kami dinamik memperbaharui hubungan dengan informasi kontekstual dari subgraf multisumber, dibangun dari berbagai sumber pengetahuan eksternal. Perwakilan berkembang hubungan kemudian diberi makan ke modul pemikiran bidireksi. Mekanisme perhatian bidireksi diaplikasikan antara urutan pertanyaan dan jalur yang menghubungkan entitas, yang menyediakan kita interpretasi transparan. Hasil percobaan pada set data CommonsenseQA menunjukkan bahwa metode kita menghasilkan peningkatan yang signifikan di atas garis dasar sambil menyediakan jalan alasan yang jelas.', 'ko': '상식 문답은 상식 추리를 통해 문제의 정답을 예측하는 중요한 자연 언어 처리 임무이다.이전의 연구는 대형 어료 라이브러리(예를 들어 BERT)에서 미리 훈련된 모형을 사용하거나 지식도에서 추리를 했다.그러나 이런 방법은 실체를 연결하는 관계를 명확하게 모델링하지 않고 이런 실체는 정보적이며 추리를 강화할 수 있다.이 문제를 해결하기 위해서 우리는 관계 감지 추리 방법을 제기하였다.우리의 방법은 관계 감지도 신경 네트워크를 이용하여 실체와 관계에서 풍부한 상하문 정보를 얻는다.예비 훈련 모델 중의 고정된 관계를 삽입하는 방법을 사용하는 것보다 우리 모델은 여러 외부 지식원에서 온 다원 서브맵의 상하문 정보의 동적 업데이트 관계를 사용한다.그리고 관계의 강화는 양방향 추리 모듈로 전송된다는 것을 나타낸다.문제 서열과 실체를 연결하는 경로 사이에 양방향 주의 메커니즘을 응용했는데 이것은 우리에게 투명한 해석성을 제공했다.CommonsenseQA 데이터 세트에서의 실험 결과에 따르면 우리의 방법은 명확한 추리 경로를 제공하는 동시에 기선을 현저하게 개선시켰다.', 'sw': 'Majibu ya Maswali ya Maoni ni kazi muhimu ya upasuaji wa lugha asilia (NLP) inayokusudia kutabiri jibu sahihi la swali kwa njia ya maana ya umma. Tafiti zilizopita zinatumia mifano ya mafunzo ya awali kwenye makampuni makubwa kama vile BERT, au kufanya maoni kuhusu picha za maarifa. Hata hivyo, mbinu hizi hazina ufafanuzi wa mahusiano yanayounganisha vifaa, ambavyo vinaweza kutumika kwa ajili ya kuongeza sababu. Kupambana na suala hili, tunapendekeza njia inayofahamika na uelewa wa mahusiano. Utawala wetu unatumia mtandao wa picha inayofahamika na maarifa ya ubongo wa kisasa ili kupata taarifa za utajiri kutoka kwa vyombo na mahusiano. Kulinganishwa na mbinu ambazo zinatumia mahusiano ya moja kwa moja kutoka kwenye mifano ya zamani iliyoendelea, mifano yetu inatumia mahusiano ya kisasa na taarifa za kisasa kutoka kwenye viwanja vingi vya vyanzo vingi vya maarifa vya nje. The enhanced representations of relations are then fed to a bidirectional reasoning module.  Mfumo wa ufuatiliano unatumiwa kati ya mfululizo wa swali na njia zinazounganisha vifaa, ambazo vinatupa ufafanuzi wa wazi. Matokeo ya majaribio kwenye taarifa za CommonseQA yanaonyesha kuwa mbinu yetu inatokea maboresho makubwa zaidi ya misingi na pia kutoa njia zilizo wazi za maana.', 'af': "Saamsinse Vrag Antwoord is 'n belangrik natuurlike taal verwerking (NLP) taak wat doel om die korrekte antwoord na' n vraag te voorskou deur gemeenskaplike redening. Vorige studie gebruik voorafgeleerde modele op groot-skaal korpora soos BERT, of doen redening op kennis grafieke. Maar hierdie metodes doen nie uitduidelik die relasies wat entiteite verbind, wat inligtinglike is en kan gebruik word om redening te verbeter nie. Om hierdie probleem te adres, voorstel ons 'n verwanting-bewyse rederingmetode. Ons metode gebruik 'n verbinding- bewyse graaf neuralnetwerk om die ryk konteksual inligting van beide entiteite en relasies te vang. Vergelyk met metodes wat vaste verwanting inbettings gebruik van vooraf-opgelei modele, ons model dinamies opdateer verwantings met kontekslike inligting van 'n veelvuldige bron subgraaf, gebou van veelvuldige eksterne kennis bronne. Die verbeterde voorstellings van verwantighede word dan opgevoer na 'n bidireksjoneel redening module. 'n Bidireksionale aandag mekanisme word aangepas tussen die vraag sekwensie en die paaie wat konnekteer entiteite, wat ons verskaf met deursigtige uitlegging. Eksperimentale resultate op die CommonsenseQA datastel illustreer dat ons metode in betekende verbeteringe oor die basisline resultaat terwyl ook duidelike redekening pad verskaf word.", 'tr': 'Kommunesçe sorag jogap etmek - adalat dil işlemegi (NLP) zady hemişe bir soraga dogry jogabyny duýdurmak üçin maksat edýär. Öňki araştyrmalar BERT ýaly öňki bilim grafiklerinde düşünýän nusgalary ulanýarlar. Ýöne bu ýagdaýlar birbirlerini baglaýan baglaýyşlaryň görnüşini kesinlikle örän nusgala däldir. Bu ýagdaýlar informasiýaly we razylygy azaltmak üçin ullanylar. Bu meseleyi çözmek üçin, suçlamak bilen nähili düşününç yöntemi teklip edip görýäris. Biziň ýüregimiz, baý contextual maglumaty hem birnäçe guramlardan çekmek üçin baglaşykly grafik näyral şebekesini ulanýar. Öň bilim çeşmelerinden sabit baglanyşyk integralary ulanan yöntemlerle karşılaşdyryldy. Derejeleriň gelişmeleri we soňra iki görnöşim razylygy modula berilýär. Bize transparent terjime edip biljek mekanismi soragy seriýasy we gurallaryň arasynda uygulanýar. CommonsenseQA veri setindeki örän netijeleri biziň metodamyzyň baseliniň üstünde örän gowuraklary bolup geçirýändigini görkez.', 'sq': 'Përgjigja e zakonshme e pyetjeve është një detyrë e rëndësishme e procesimit natyror të gjuhës (NLP) që synon të parashikojë përgjigjen e saktë të një pyetjeje nëpërmjet arsyetimit të zakonshëm. Studimet e mëparshme përdorin modele paratrajnuar në korpra të shkallës së madhe të tilla si BERT ose bëjnë arsyetim në grafikat e njohurive. Megjithatë, këto metoda nuk modelojnë shprehësisht marrëdhëniet që lidhin njësitë, të cilat janë informacionale dhe mund të përdoren për të përmirësuar arsyetimin. Për të trajtuar këtë çështje, ne propozojmë një metodë arsyetimi të ndërgjegjshëm për marrëdhënie. Metoda jonë përdor një rrjet nervor grafik të ndërgjegjshëm për të kapur informacionin e pasur kontekstual nga njësitë dhe marrëdhëniet. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources.  Përfaqësuesit e përmirësuar të marrëdhënieve pastaj ushqehen në një modul arsyetimi dy-drejtues. Një mekanizëm vëmendje dy-drejtues është aplikuar midis sekuencës së pyetjeve dhe rrugëve që lidhin njësitë, që na ofron interpretueshmëri transparente. Rezultatet eksperimentale në grupin e të dhënave të CommonsenseQA ilustrojnë se metoda jonë rezulton në përmirësime të rëndësishme mbi linjat bazë duke ofruar gjithashtu rrugë të qarta arsyetimi.', 'az': 'Commonsense sual cavab vermək çox möhkəm təbiətli dil işləməsi (NLP) işidir. Bu, çox münasibətli fikirləşdirmək vasitəsilə bir suala doğru cavab vermək istəyir. Önceki öyrənmələr BERT kimi böyük ölçüdə öyrənmiş modellər istifadə edir və ya elm grafikləri barəsində müzakirə edir. Ancaq bu metodlar məlumatları bağlayan və dəyişiklik artırmaq üçün istifadə edilə bilərlər. Bu məsələdən çəkinmək üçün, əlaqələrimizdən xəbərdar bir dəyişiklik metodu təbliğ edirik. Bizim metodumuz hər birinin və əlaqələrindən baxıl müxtəlif məlumatları almaq üçün bağlantılı bilən graf nöral a ğını istifadə edir. Əvvəlcə təhsil edilmiş modellərdən sabit ilişkilər istifadə edən metodlarla, modellərimiz dinamik müxtəlif məlumatlarla çoxlu mənbə apagrafından müxtəlif məlumatlarla birlikdə yeniləşdirilmişdir. İlişkilərin daha yüksək göstərilmələri, sonra iki dəyişiklik dəyişiklik moduluna verilir. Bizə açıq bir yorumluluğu sağlayan sual seçməsi ilə birləşdirilən yolların arasında iki təsirli dikkati mehanizması istifadə edilir. CommonsenseQA verilən qutusundakı təcrübə sonuçları, həmçin in metodumuzun baz çətinliklərin üstündə möhkəm düzəltmələrinə nəticə etdiyini göstərir.', 'am': 'የመጠየቅ ጥያቄ መልስ የአፍሪካዊ ቋንቋ ማቀናጃ (NLP) ስራ ነው፡፡ የቀድሞው ትምህርት፣ እንደBERT፣ ወይም እውቀት ካርፓርቲ ላይ የደረጃ ምርጫዎችን በመጠቀም የሚጠይቁትን ምሳሌዎች ይጨምሩታል፡፡ ምንም እንኳን፣ እነዚህ ሥርዓቶች አካባቢዎችን የሚያግናኙትን ግንኙነት በሙሉ አይመስክሩም፣ እነዚህም አካባቢዎች ማስታወቂያውን ለመሻል ይችላሉ፡፡ ይህንን ጉዳይ ለመቀበል፣ የግንኙነት አስተዋይ ልማድ እናሳውቃለን፡፡ የግንኙነት አካባቢ እና ግንኙነት ሀብታሞችን ከሀብታሞች እና ግንኙነት ለመያዝ የግንኙነታችንን የግንኙነት መረብ ይጠቅማል፡፡ Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources.  የግንኙነት አካባቢ ግንኙነት አካባቢ አካባቢ አካል ነው፡፡ በጥያቄ እና አካባቢዎችን በሚያጋጠሙ መንገዶች መካከል የተጠያየቁ የጥያቄ ማስታወቂያውን ያሳየናል፡፡ QA dataset ውጤቶች የውጤት ፍጻሜ በመስመር ላይ እና የተለየ አዋቂዎችን መንገዶች እንዲያሳየው ነው፡፡', 'bn': 'কমান্সনসেন্স প্রশ্নের উত্তর হচ্ছে একটি গুরুত্বপূর্ণ প্রাকৃতিক ভাষা প্রক্রিয়া (এনএলপি) কাজ যার লক্ষ্য হচ্ছে কমিনসেন্সেন্সে পূর্ববর্তী গবেষণাগুলো বিবের্টের মতো বিশাল পরিমাপে প্রশিক্ষিত পূর্ব প্রশিক্ষিত মডেল ব্যবহার করে, অথবা জ্ঞান গ্রাফের ব তবে এই পদ্ধতিগুলো পরিষ্কারভাবে মডেল করে না যে সমস্ত বস্তুর সাথে যোগাযোগ করে, যা তথ্য এবং কারণ বৃদ্ধির জন্য ব্যবহার করা যায়। এই বিষয়টি নিয়ে কথা বলার জন্য, আমরা একটি সম্পর্ক-সচেতনতা প্রস্তাব করি। আমাদের পদ্ধতি একটি সম্পর্ক-পরিচিত গ্রাফ নিউরেল নেটওয়ার্ক ব্যবহার করে সমৃদ্ধ বস্তু এবং সম্পর্কের উভয় তথ্য ধরার জন্য। পূর্ব প্রশিক্ষিত মডেল থেকে নির্ধারিত সম্পর্ক ব্যবহার করা মোডেলের সাথে তুলনায় আমাদের মডেলের মাধ্যমে এক বহুস্থান সাবগ্রাফ থেকে আন্তর্জাতিক তথ্যের সাথে  তারপর সম্পর্কের উন্নত প্রতিনিধিত্ব বাড়িয়ে দেয়া হয়েছে একটি বিদ্যমান কারণ মডিউলে। প্রশ্নের সংক্রান্ত প্রযুক্তি এবং সংযোগের পথের মধ্যে প্রয়োগ করা হয়, যা আমাদের স্বচ্ছতার ব্যাখ্যা দেয়। কমানসেন্সQA ডাটাসেটের পরীক্ষার ফলাফল তুলে ধরেছে যে আমাদের পদ্ধতি বেসেলাইনের উপর বিশাল উন্নয়নের ফলে তুলে ধরেছে এবং সেখানে পরিষ্কার কারণ', 'hy': 'Հիմնական հարցերի պատասխանը կարևոր բնական լեզվի վերլուծություն է, որը նպատակում է կանխատեսել հարցի ճիշտ պատասխանը ընդհանուր մտածողության միջոցով: Անցյալ ուսումնասիրությունները օգտագործում են նախապատրաստված մոդելներ մեծ մակարդակի վրա, ինչպիսիք են BER-ը, կամ գիտելիքի գրաֆիկների վրա խորհուրդ են կատարում: Այնուամենայնիվ, այս մեթոդները բացահայտորեն չեն մոդելավորում այն հարաբերությունները, որոնք կապում են միավորներ, որոնք տեղեկատվական են և կարող են օգտագործվել մտածողության բարելավման համար: Այս խնդիրը լուծելու համար մենք առաջարկում ենք հարաբերություններով գիտակցած մտածողության մեթոդ: Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations.  Համեմատելով այն մեթոդների հետ, որոնք օգտագործում են նախապատրաստված մոդելների ֆիքսավոր հարաբերությունները, մեր մոդելը դինամիկ կերպով վերականգնում է հարաբերությունները բազմա աղբյուրների ենթագրաֆիայի կոնտեքստալ տեղեկատվության հետ, որը կառո Հետո հարաբերությունների բարելավված ներկայացումները օգտագործվում են երկու ուղղությամբ մտածողության մոդուլը: Երկու ուղղությամբ ուշադրության մեխանիզմ օգտագործվում է հարցի հաջորդականության և այն ուղիների միջև, որոնք միացնում են միավորները, ինչը մեզ տրամադրում է թափանցիկ մեկնաբանելիություն: Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'et': 'Küsimustele vastamine on oluline looduskeele töötlemise (NLP) ülesanne, mille eesmärk on ennustada õiget vastust küsimusele läbi mõistliku arutluse. Varasemates uuringutes kasutatakse eelnevalt koolitatud mudeleid suuremahulistel korpustel nagu BERT või arutletakse teadmiste graafikutel. Kuid need meetodid ei modelleeri selgesõnaliselt suhteid, mis ühendavad üksusi, mis on informatiivsed ja mida saab kasutada arutluse parandamiseks. Selle probleemi lahendamiseks pakume välja seosteadliku arutlusmeetodi. Meie meetod kasutab seosteadlikku graafiku neurovõrku, et jäädvustada rikkalikku kontekstiteavet nii olemitest kui ka seostest. Võrreldes meetoditega, mis kasutavad fikseeritud seoste manustamist eelnevalt koolitatud mudelitest, värskendab meie mudel dünaamiliselt suhteid mitmest välisest teadmisallikast pärit kontekstiteabega. Suhete täiustatud esitused toimetatakse seejärel kahesuunalise arutluse moodulisse. Küsimustejada ja olemeid ühendavate teede vahel rakendatakse kahesuunalist tähelepanu mehhanismi, mis tagab meile läbipaistva tõlgendatavuse. CommonsenseQA andmekogumi eksperimentaalsed tulemused näitavad, et meie meetod parandab oluliselt võrreldes lähtejoontega, pakkudes samal ajal selgeid aruteluviise.', 'fi': 'Commonsense Question Answering on tärkeä luonnollisen kielen käsittelytehtävä, jonka tavoitteena on ennustaa oikea vastaus kysymykseen järkevän päättelyn avulla. Aiemmissa tutkimuksissa hyödynnetään esikoulutettuja malleja suurissa korpussa, kuten BERT, tai tehdään päättelyä tietograafilla. Nämä menetelmät eivät kuitenkaan nimenomaisesti mallinna yhteisöjä yhdistäviä suhteita, jotka ovat informatiivisia ja joita voidaan käyttää järkeilyn parantamiseen. Tämän ongelman ratkaisemiseksi ehdotamme suhdetietoista päättelymenetelmää. Menetelmämme käyttää suhdetietoista graafisen neuroverkkoa keräämään rikkaita kontekstuaalisia tietoja sekä entiteeteistä että suhteista. Verrattuna menetelmiin, joissa käytetään ennalta koulutettujen mallien kiinteitä suhdeupotuksia, mallimme päivittää dynaamisesti suhteita kontekstuaalisella tiedolla useasta lähteestä, joka on rakennettu useista ulkoisista tietolähteistä. Suhteiden tehostetut esitykset syötetään sitten kaksisuuntaiseen päättelymoduuliin. Kysymysjakson ja entiteettejä yhdistävien polkujen välillä käytetään kaksisuuntaista huomiomekanismia, joka mahdollistaa läpinäkyvän tulkinnan. Kokeelliset tulokset CommonsenseQA-aineistosta osoittavat, että menetelmämme tuottaa merkittäviä parannuksia lähtölinjoihin nähden ja tarjoaa selkeitä päättelypolkuja.', 'bs': 'Odgovor na pitanje javnosti je važan zadatak prirodnog obradivanja jezika (NLP), koji je cilj predviđati ispravan odgovor na pitanje kroz objašnjenje razuma. Prethodne studije koriste predobučene modele na velikoj korporaciji kao što je BERT, ili izvode razgovor o graficima znanja. Međutim, te metode ne obrađuju jasno odnose koje povezuju entitate, koje su informativne i koje se mogu koristiti za poboljšanje razuma. Da bi se riješili ovom pitanju, predlažemo metodu razumljivanja svjesnog odnosa. Naša metoda koristi neuralnu mrežu s svijestima veze kako bi uhvatili bogate contextualne informacije od objekata i odnosa. U usporedbi s metodama koje koriste fiksne veze ugrađene iz predobučenih model a, naš model dinamički aktualizira odnose sa kontekstualnim informacijama iz višeizvornog podgrafa, izgrađene iz višestrukih izvora vanjskih znanja. Povećane predstave odnosa se onda hrane za dvodirektivni modul razuma. Mehanizam dvodirektivne pažnje se primjenjuje između sekvence pitanja i puteva koje povezuju entitate, koja nam pruža transparentnu interpretabilnost. Eksperimentalni rezultati na kompletu podataka CommonsenseQA ukazuju na to da naša metoda rezultira značajnim poboljšanjima na osnovnim linijama, a također pružaju jasne puteve razumljivanja.', 'ca': "Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning.  Els estudis anteriors utilitzen models pré-entrenats en corpores a gran escala com BERT, o realitzen raonament en gràfics de coneixement. No obstant això, aquests mètodes no modelen explícitament les relacions que connecten entitats, que són informatives i poden ser utilitzats per millorar el raonament. Per abordar aquesta qüestió, proposem un mètode de raonament conscient de les relacions. El nostre mètode utilitza una xarxa neural gràfica conscient de la relació per capturar la riquesa informació contextual de les entitats i les relacions. Comparat amb els mètodes que utilitzen integracions de relacions fixes de models pré-entrenats, el nostre model actualitza dinàmicament les relacions amb informació contextual d'un subgràfic de múltiples fonts, construït de múltiples fonts externes de coneixement. Les representacions millorades de les relacions s'alimentan després d'un módul de raonament bidireccional. S'aplica un mecanisme d'atenció bidireccional entre la seqüència de preguntes i els camins que connecten entitats, que ens proporciona interpretabilitat transparent. Els resultats experimentals del conjunt de dades CommonsenseQA ilustren que el nostre mètode provoca millores significatives sobre les línies de base, proporcionant també camins clars de raonament.", 'cs': 'Odpověď na otázky zdravého rozumu je důležitý úkol zpracování přirozeného jazyka (NLP), jehož cílem je předpovědět správnou odpověď na otázku prostřednictvím zdravého rozumu uvažování. Předchozí studie využívají předem trénované modely na velkých korpusech, jako je BERT, nebo provádějí uvažování na znalostních grafech. Tyto metody však explicitně nemodelují vztahy propojující entity, které jsou informační a mohou být použity k posílení uvažování. Pro řešení této problematiky navrhujeme metodu uvažování o vztahu. Naše metoda využívá grafovou neuronovou síť, která zachycuje bohaté kontextové informace z entit i vztahů. Ve srovnání s metodami, které využívají vložení pevných vztahů z předškolených modelů, náš model dynamicky aktualizuje vztahy s kontextovými informacemi z podgrafu více zdrojů sestaveného z více externích zdrojů znalostí. Rozšířené reprezentace vztahů jsou pak předávány do modulu obousměrného uvažování. Mezi sekvencí otázek a cestami propojujícími entity je aplikován obousměrný mechanismus pozornosti, což nám poskytuje transparentní interpretaci. Experimentální výsledky na datové sadě CommonseQA ukazují, že naše metoda vede k významným zlepšením nad základními liniemi a zároveň poskytuje jasné cesty uvažování.', 'jv': 'Common question responses Laptop" and "Desktop politenessoffpolite, politenessoffpolite"), and when there is a change ("assertive Ngawe nyibagi iki kesempatan, kita supoyo perusahaan tanggal apakno. Awakdhéwé éntuk sistem sing nggawe barang-Awak dhéwé ngerasakno karo pakem "informasi contextual" sing dikanggambar barang sampek karo barang sampek Samsul karo pertama sing gambar perusahaan embedding Wang string" in "context_BAR_stringLink Perintah sing paling nggambar barang nggambar barang nggambar barang nggawe barang nggawe barang seneng dolanan sing nyimpen maneh dumadhi maning, ngono nggawe barang ngentambahan perusahaan.', 'sk': 'Odgovarjanje na vprašanja je pomembna naloga obdelave naravnega jezika (NLP), katere cilj je napovedati pravilen odgovor na vprašanje s pomočjo splošnega razumevanja. Predhodne študije uporabljajo vnaprej usposobljene modele na velikih korpusih, kot je BERT, ali pa opravljajo razmišljanje na grafih znanja. Vendar te metode ne izrecno modelirajo odnosov, ki povezujejo subjekte, ki so informacijski in se lahko uporabljajo za izboljšanje razmišljanja. Za reševanje tega vprašanja predlagamo metodo razmišljanja o odnosih. Naša metoda uporablja nevronsko omrežje grafov, ki se zaveda relacij, da zajame bogate kontekstualne informacije iz entitet in relacij. V primerjavi z metodami, ki uporabljajo vdelave fiksnih relacij iz vnaprej usposobljenih modelov, naš model dinamično posodablja relacije z kontekstualnimi informacijami iz več virov podgrafije, zgrajene iz več zunanjih virov znanja. Izboljšane predstavitve odnosov se nato prenesejo v modul dvosmernega razmišljanja. Med zaporedjem vprašanj in potmi, ki povezujejo entitete, se uporablja dvosmerni mehanizem pozornosti, kar nam zagotavlja pregledno razlago. Eksperimentalni rezultati podatkovnega nabora CommonsenseQA kažejo, da naša metoda prinaša znatne izboljšave v primerjavi z osnovnimi vrsticami, hkrati pa zagotavlja jasne poti razmišljanja.', 'ha': "Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning.  Yi amfani da shiryoyin da aka riga ta zaman su yi amfani da misãlai masu yin amfani da shi a kan makampuni mai girma kamar BERT, ko kuma ka sami yin hankali da fassarar zane. A lokacin da, waɗannan hanyõyin ba su bayyana shirin haɗi da abubuwa waɗanda ke haɗa maɓalli, waɗanda bã da wani labanci ba, kuma za a yi amfani da su wajen ƙara saba'in. Domin da za mu yi addu'a ga wannan masu al'amarin, za'a buƙata wata hanyor masu fahimta da masu husũma. MethoyinMu na amfani da wani zane na zane-zane zuwa zane-zane na dangantar da mawadãci masu riki daga abubuwa da dangantaka. @ info: status An samar da masu haɗi ga danganta, sa'an nan kuma a ba su zuwa modulen baka mai saukarwa. An amfani da wani alama masu kiyaye wa sauri a tsakanin sequence na tambayi da hanyõyi waɗanda ke haɗa masu tsari da abubuwa, da mai gajiya fassarar da bayyane. QA dataset na bayyana cewa hanyoyinmu yana ƙara mafiya kyau a kan bango, kuma da kuma yana samar da hanyõyi bayyananne.", 'he': 'Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning.  מחקרים קודמים משתמשים בדוגמנים מאומנים מראש על גופורים בקנה מידה גדולה כמו BERT, או לבצע הגיון על גרפי ידע. However, these methods do not explicitly model the relations that connect entities, which are informational and can be used to enhance reasoning.  To address this issue, we propose a relation-aware reasoning method.  השיטה שלנו משתמשת ברשת עצבית של גראפ מודע למערכת יחסים כדי לתפוס את המידע הקונקסטי העשיר משני היחידות וגם מערכות יחסים. בהשוואה לשיטות אשר משתמשות באמצעות מערכות יחסים קבועות ממודלים מאומנים מראש, המודל שלנו מעדכן מערכות יחסים דינמיות עם מידע קונטקטואלי ממקור רב, בנוי ממקורי ידע חיצוניים רבים. The enhanced representations of relations are then fed to a bidirectional reasoning module.  A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability.  Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.', 'bo': 'Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through commonsense reasoning. སྔོན་གྱི་གནད་དོན་ལྟའི་ནང་དུ་བྱ་ཚིག་ལས་སྔོན་གྲངས་འཛིན་པའི་མིག་གཟུགས་རིས་སྤྱོད་ཀྱི་ཡོད། འོན་ཀྱང་། ཐབས་ལམ་འདི་དག་ནི་དབུལ་འབྲེལ་མཐུད་དང་སྦྲེལ་མཐུད་པའི་མཐུན་འབྲེལ་གསལ་བཤད་མེད་པ་ལས་རྟོགས་བསམ་གཏོང་འཕེལ དོན་དག་གནས་ཚུལ་འདི་ལ་བཤད་ན་ང་ཚོས་འབྲེལ་བ་དང་ཤེས་པའི་རྐྱེན་ལམ་ལུགས་ཅིག་སྤྲོད་ཡོད། ང་ཚོའི་ལམ་ལུགས་འདིས་དང་འབྲེལ་བ་གཉིས་ཀྱིས་མཐུན་པའི་གྲངས་སུ་འབྲེལ་བ་དང་མཐུན་འབྲེལ་གྱི་རྩོམ་པ་ཞིག་སྤྱད་ནས་ Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. རྒྱུ་དངོས་འབྲེལ་བ་གཉིས་ཀྱི་ཁྱད་དུ་རྒྱས་བཤད་ཀྱི་ཐབས་ལམ་ཞིག་ལ་སྤྲོད་ཡོད། འདྲི་ཚིག་གི་དབྱེ་རིམ་དང་དབང་ཆ་མཐུད་པའི་འགྲུལ་སྐྱོད་ཀྱི་ཐབས་ལམ་ཞིག་ནི་ལག་སྟར་བྱེད་ཡོད་པ CommonsenseQA གནད་སྡུད་ཕྱོགས་ཀྱི་ལས་འཚོལ་དག་གི་ཐབས་ལམ་ལ་གསལ་པོ་ཞིག་ཏུ་འགྱུར་བ་རྐྱེན་ཏེ།'}
{'en': 'Commonsense Knowledge in  Word Associations  and ConceptNet C oncept N et', 'ar': 'معرفة العموم في اتحادات الكلمات و ConceptNet', 'fr': 'Connaissances de bon sens dans les associations de mots et ConceptNet', 'es': 'Conocimiento de sentido común en asociaciones de palabras y ConceptNet', 'pt': 'Conhecimento de senso comum em associações de palavras e ConceptNet', 'ja': 'ワードアソシエーションとコンセプトネットにおけるコモンセンス知識', 'hi': 'Word Associations और ConceptNet में Commonsense Knowledge', 'zh': '单词联名网中常识', 'ru': 'Знание здравого смысла в ассоциациях Word и ConceptNet', 'ga': 'Eolas Commonsense i Cumainn Focal agus ConceptNet', 'ka': 'Comment', 'hu': 'Commonsense Knowledge in Word Associations and ConceptNet', 'el': 'Γνώση κοινής λογικής σε ενώσεις λέξεων και ConceptNet', 'it': 'Conoscenza del comune nelle associazioni di parole e ConceptNet', 'mk': 'Comment', 'kk': 'Comment', 'lt': 'Commonsense Knowledge in Word Associations and ConceptNet', 'ms': 'Commonsense Knowledge in Word Associations and ConceptNet', 'ml': 'വാക്ക് സമൂഹങ്ങളും കോണ്\u200dസെപ്റ്റ്നെറ്റുമുള്ള വിവരങ്ങള്\u200d', 'mt': 'Għarfien Komuni fl-Assoċjazzjonijiet tal-Kliem u ConceptNet', 'no': 'Comment', 'mn': 'Холбооны холбоотой болон Концепцийн мэдлэг', 'pl': 'Znajomość powszechnego sensu w stowarzyszeniach słownych i ConceptNet', 'ro': 'Cunoștințe bune în asociațiile Word și ConceptNet', 'sr': 'Komunikacijska znanja u pridruživanju reèi i koncepciji', 'si': 'Comment', 'so': 'Aqoonta heshiiska ee ururada hadalka iyo bogga shabakadda', 'sv': 'Commonsense Kunskap i Word Associations och ConceptNet', 'ur': 'Word Associations and ConceptNet میں کمپنس علم', 'ta': 'Name', 'vi': 'Kiến thức thông thường trong các tổ chức từ ngữ và văn hóa', 'uz': 'Name', 'bg': 'Общосъвестно знание в Словените асоциации и КонцептNet', 'da': 'Almindelig viden i Word Associations og ConceptNet', 'nl': 'Commonsense Kennis in Woordassociaties en ConceptNet', 'hr': 'ZNANJE ZAVJENJA ZA RUČNIH SJEDNIH', 'ko': '어휘 연상과 개념망 속의 상식 지식', 'de': 'Commonsense Wissen in Word Assoziationen und ConceptNet', 'id': 'Pengetahuan Komunis dalam Asosiasi Kata dan ConceptNet', 'fa': 'دانش کمونس در ارتباطات کلمات و تفسیر شبکه', 'tr': 'Bilim', 'af': 'Comment', 'sw': 'Ujuzi wa Mawasiliano katika Chama cha Matokeo na Mtandao wa Mtandao', 'sq': 'Commonsense Knowledge in Word Associations and ConceptNet', 'am': 'የቃላት ማኅበረሰብ እና ConceptNet', 'hy': 'Comment', 'az': 'Söz İşyaları və ConceptNet', 'bs': 'Komunikacijska znanja u pridruživanju riječi i koncepciji', 'bn': 'ওয়ার্ড অ্যাসোসিয়েশন এবং কনসেপ্টেটনেটে কমিনসেন্স জ্ঞান', 'ca': 'Conexus comuns en Word Associations i ConceptNet', 'cs': 'Znalosti obecného rozumu ve slovních asociacích a ConceptNet', 'fi': 'Commonsense Knowledge in Word Associations and ConceptNet', 'et': 'Üldteadmised sõnaühendustes ja ConceptNetis', 'he': 'Commonsense Knowledge in Word Associations and ConceptNet', 'jv': 'Coberturan Kemerdekaan Winter Associations lan Mawurung', 'ha': 'KCharselect unicode block name', 'sk': 'Splošno znanje v besednih združenjih in ConceptNet', 'bo': 'Commonsense Knowledge in Word Associations and ConceptNet'}
{'en': 'Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This  commonsense knowledge  is rarely communicated explicitly, however, understanding how  commonsense knowledge  is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge :  ConceptNet , an engineered relational database, and SWOW, a  knowledge graph  derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two  graphs , as well as the extent of situational commonsense knowledge present in the two  resources . We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.', 'ar': 'يستخدم البشر عددًا لا يحصى من الحقائق الأساسية والمشتركة حول العالم للتنقل بكفاءة في بيئتهم. نادرًا ما يتم توصيل هذه المعرفة المنطقية بشكل صريح ، ومع ذلك ، فإن فهم كيفية تمثيل المعرفة المنطقية في نماذج مختلفة أمر مهم من أجل (أ) فهم أعمق للإدراك البشري و (ب) زيادة أنظمة التفكير التلقائي. تقدم هذه الورقة مقارنة متعمقة لمصدرين واسعي النطاق للمعرفة العامة: ConceptNet ، وهي قاعدة بيانات علائقية هندسية ، و SWOW ، رسم بياني معرفي مشتق من جمعيات الكلمات ذات المصادر الجماعية. ندرس الهيكل والتداخل والاختلافات بين الرسمين البيانيين ، بالإضافة إلى مدى معرفة المنطق الظرفية الموجودة في هذين المصدرين. لقد أظهرنا أخيرًا بشكل تجريبي أن كلا المصدرين يحسنان أداء المهام النهائية على معايير الاستدلال المنطقي على خطوط الأساس النصية فقط ، مما يشير إلى أن بيانات اقتران الكلمات واسعة النطاق ، والتي تم الحصول عليها من عدة لغات من خلال التعهيد الجماعي ، يمكن أن تكون مكملاً قيماً للمعرفة المنسقة الرسوم البيانية.', 'fr': "Les humains utilisent d'innombrables informations de base partagées sur le monde pour naviguer efficacement dans leur environnement. Ces connaissances de bon sens sont rarement communiquées explicitement, cependant, il est important de comprendre comment le savoir de bon sens est représenté dans différents paradigmes pour (a) une meilleure compréhension de la cognition humaine et (b) pour augmenter les systèmes de raisonnement automatique. Cet article présente une comparaison approfondie de deux ressources de connaissances générales à grande échelle\xa0: ConceptNet, une base de données relationnelle conçue, et SWOW, un graphe de connaissances dérivé d'associations de mots provenant de sources participatives. Nous examinons la structure, le chevauchement et les différences entre les deux graphiques, ainsi que l'étendue des connaissances situationnelles de bon sens présentes dans les deux ressources. Enfin, nous montrons empiriquement que les deux ressources améliorent les performances des tâches en aval sur des repères de raisonnement de bon sens par rapport aux bases de référence textuelles uniquement, suggérant que les données d'association de mots à grande échelle, obtenues pour plusieurs langues par le biais du crowd-sourcing, peuvent être un complément précieux à graphiques de connaissances.", 'pt': 'Os seres humanos usam inúmeros fatos básicos compartilhados sobre o mundo para navegar com eficiência em seu ambiente. Esse conhecimento de senso comum raramente é comunicado explicitamente, no entanto, entender como o conhecimento de senso comum é representado em diferentes paradigmas é importante para (a) uma compreensão mais profunda da cognição humana e (b) aumentar os sistemas de raciocínio automático. Este artigo apresenta uma comparação detalhada de dois recursos de conhecimento geral em larga escala: ConceptNet, um banco de dados relacional projetado, e SWOW, um gráfico de conhecimento derivado de associações de palavras de origem coletiva. Examinamos a estrutura, a sobreposição e as diferenças entre os dois gráficos, bem como a extensão do conhecimento situacional do senso comum presente nos dois recursos. Finalmente, mostramos empiricamente que ambos os recursos melhoram o desempenho de tarefas downstream em benchmarks de raciocínio de senso comum sobre linhas de base somente de texto, sugerindo que dados de associação de palavras em larga escala, que foram obtidos para vários idiomas por meio de crowdsourcing, podem ser um complemento valioso para o conhecimento curado gráficos.', 'es': 'Los seres humanos utilizan innumerables datos básicos y compartidos sobre el mundo para navegar eficientemente en su entorno. Este conocimiento de sentido común rara vez se comunica explícitamente, sin embargo, entender cómo se representa el conocimiento de sentido común en los diferentes paradigmas es importante para (a) una comprensión más profunda de la cognición humana y (b) aumentar los sistemas de razonamiento automático. Este artículo presenta una comparación en profundidad de dos recursos de conocimiento general a gran escala: ConceptNet, una base de datos relacional diseñada, y SWOW, un gráfico de conocimiento derivado de asociaciones de palabras de colaboración colectiva. Examinamos la estructura, la superposición y las diferencias entre los dos gráficos, así como el alcance del conocimiento situacional de sentido común presente en los dos recursos. Finalmente, demostramos empíricamente que ambos recursos mejoran el desempeño de las tareas posteriores en puntos de referencia de razonamiento de sentido común en comparación con las líneas de base solo de texto, lo que sugiere que los datos de asociación de palabras a gran escala, que se han obtenido para varios idiomas a través de la colaboración colectiva, pueden ser un valioso complemento de la curaduría gráficos de conocimiento.', 'ja': '人間は、世界に関する無数の基本的な共有された事実を使用して、環境を効率的にナビゲートします。 この常識的な知識は明示的に伝達されることはほとんどないが、異なるパラダイムで常識的な知識がどのように表現されるかを理解することは、（ a ）人間の認知のより深い理解と（ b ）自動推論システムの増強にとって重要である。 工学的な関係データベースであるConceptNetと、クラウドソーシングされたワードアソシエーションから派生したナレッジグラフであるSWOWの2つの大規模な一般知識リソースを深く比較した。 私たちは、2つのグラフ間の構造、オーバーラップ、および差異、ならびに2つのリソースに存在する状況共通感覚の知識の範囲を検討します。 最後に、両方のリソースが、テキストのみのベースラインよりも共通の推論ベンチマークの下流タスクのパフォーマンスを改善することを経験的に示し、クラウドソーシングを通じていくつかの言語で得られた大規模な単語関連データが、キュレーションされたナレッジグラフの貴重な補完になる可能性があることを示唆します。', 'zh': '人用无数世界,共享之事,效于境导航。 常识性知少明,然而知所以异于(a)者,所以明知与(b)自推理系统也。 本文深较二大凡知识:ConceptNet,一工数据库,及SWOW,一自众包单词联图谱。 我们研究了两个图间的结构,重重和差异,及两个资源中存的情境常识知识的限限。 吾终以经验明之,与纯文本基线相比,此二资于常识推理基准上增下任之性,明因众包得之多种语言大单词关联数据可以为谋图谱之宝贵补充。', 'hi': 'मनुष्य अपने वातावरण में कुशलतापूर्वक नेविगेट करने के लिए दुनिया के बारे में अनगिनत बुनियादी, साझा तथ्यों का उपयोग करते हैं। इस सामान्य ज्ञान को शायद ही कभी स्पष्ट रूप से संप्रेषित किया जाता है, हालांकि, यह समझना कि विभिन्न प्रतिमानों में कॉमनसेंस ज्ञान का प्रतिनिधित्व कैसे किया जाता है, (ए) मानव अनुभूति की गहरी समझ और (बी) स्वचालित तर्क प्रणालियों को बढ़ाने के लिए महत्वपूर्ण है। यह पेपर सामान्य ज्ञान के दो बड़े पैमाने पर संसाधनों की गहराई से तुलना प्रस्तुत करता है: कॉन्सेप्टनेट, एक इंजीनियर रिलेशनल डेटाबेस, और SWOW, भीड़-स्रोत शब्द संघों से व्युत्पन्न एक ज्ञान ग्राफ। हम संरचना, ओवरलैप और दो रेखांकनों के बीच अंतर की जांच करते हैं, साथ ही साथ दो संसाधनों में मौजूद स्थितिजन्य सामान्य ज्ञान की सीमा भी। हम अंतमें अनुभवजन्य रूप से दिखाते हैं कि दोनों संसाधन पाठ-केवल बेसलाइन पर कॉमनसेंस रीजनिंग बेंचमार्क पर डाउनस्ट्रीम कार्य प्रदर्शन में सुधार करते हैं, यह सुझाव देते हुए कि बड़े पैमाने पर वर्ड एसोसिएशन डेटा, जो भीड़-सोर्सिंग के माध्यम से कई भाषाओं के लिए प्राप्त किया गया है, क्यूरेटेड ज्ञान ग्राफ के लिए एक मूल्यवान पूरक हो सकता है।', 'ru': 'Люди используют бесчисленные базовые, общие факты о мире, чтобы эффективно ориентироваться в своей среде. Эти знания здравого смысла редко передаются в явной форме, однако понимание того, как знания здравого смысла представлены в различных парадигмах, имеет важное значение для (а) более глубокого понимания человеческого познания и (б) расширения автоматических систем мышления. В этой статье представлено углубленное сравнение двух крупномасштабных ресурсов общих знаний: ConceptNet, сконструированной реляционной базы данных, и SWOW, графа знаний, полученного из ассоциаций краудсорсинговых слов. Мы изучаем структуру, перекрытие и различия между двумя графиками, а также степень знания общего смысла ситуации, присутствующего в двух ресурсах. Наконец, мы эмпирически демонстрируем, что оба ресурса улучшают выполнение задач ниже по потоку, по сравнению с базовыми линиями только для текста, предполагая, что крупномасштабные данные ассоциации слов, которые были получены для нескольких языков с помощью краудсорсинга, могут быть ценным дополнением к курируемым графикам знаний.', 'ga': 'Úsáideann daoine fíorais bhunúsacha, roinnte faoin domhan mór chun dul i ngleic go héifeachtach ina dtimpeallacht. Is annamh a chuirtear an t-eolas ciallmhar seo in iúl go sainráite, áfach, tá sé tábhachtach tuiscint a fháil ar an gcaoi a léirítear eolas ciallmhar i bparaidímí éagsúla chun (a) tuiscint níos doimhne a fháil ar chognaíocht dhaonna agus (b) córais uathoibríocha réasúnaíochta a mhéadú. Cuirtear i láthair sa pháipéar seo comparáid dhomhain idir dhá acmhainn eolais ghinearálta ar scála mór: ConceptNet, bunachar sonraí gaolmhar a ndearnadh innealtóireacht air, agus SWOW, graf eolais díorthaithe ó chomhcheangail focal sluafhoinsithe. Scrúdóimid an struchtúr, an forluí agus na difríochtaí idir an dá ghraf, chomh maith le méid an eolais chiallmhar staide atá sa dá acmhainn. Léirímid ar deireadh go heimpíreach go bhfeabhsaítear an dá acmhainn feidhmíocht tascanna iartheachtacha ar thagarmharcanna réasúnaíochta ciallmhara thar bhunlínte téacs amháin, rud a thugann le tuiscint gur féidir le sonraí ar scála mór comhlachais focal, a fuarthas le haghaidh teangacha éagsúla trí slua-fhoinsiú, a bheith ina gcomhlánú luachmhar ar eolas coimeádta. graif.', 'ka': 'ადამიანები მსოფლიოს შესახებ მსოფლიოს ბევრი ფექტურები გამოყენებენ, რომლებიც ეფექტურად გადავიწყებენ სამყაროში. ეს საერთო სიცოცხლეების ცოცხლეობა არაფერად კომუნიკაცია განსხვავებული პარადიგმებში იყოს გასანიშვნელოვანი ადამიანის კონციფიკაციის და b) ავტომატური აზუსტირების სისტემების აზუსტირება. ეს დოკუნეტი ჩვენებს ორი დიდი მეცნიერების რესურსების დამატება: ConceptNet, ინეზინერიური შესახებ დაბაზა და SWOW, ცნობიერების გრაფიკი, რომელიც მუშაობის სიტყვების შესახებ გამოიყენებული. ჩვენ შევხედავთ სტრუქტურაციას, გადარწმუნებას და განსხვავებას ორი გრაფიკაში, და სტრუქტურაციული საზოგადოებო ცნობილების განსხვავებას, რომელიც ორი რესურ საბოლოოდ ჩვენ ემპერიკურად ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ორივე რესურსი უფრო მეტად გავაკეთება მონაცემების კონქმენტის პარამენტის კონქმენტის კონქმენტის კონქმენტის მხოლოდ ტექსტური ბაზილი', 'hu': 'Az emberek számtalan alapvető, megosztott tényt használnak a világról, hogy hatékonyan navigáljanak a környezetükben. Ezt a közérzeti tudást ritkán kommunikálják kifejezetten, azonban fontos annak megértése, hogy a különböző paradigmákban hogyan jelenik meg a közérzeti tudás (a) az emberi megismerés mélyebb megértése és (b) az automatikus érvelési rendszerek bővítése szempontjából. Ez a tanulmány két nagyszabású általános tudás erőforrásának mélyreható összehasonlítását mutatja be: ConceptNet, egy tervezett relációs adatbázis, és SWOW, egy tömegből származó szóasszociációkból származó tudásgraf. Vizsgáljuk a két grafikon struktúráját, átfedését és különbségeit, valamint a két erőforrásban jelen lévő helyzeti közérzeti ismeretek mértékét. Végül empirikusan megmutatjuk, hogy mindkét erőforrás javítja a downstream feladatok teljesítményét a közértelmes érvelési referenciaértékek alapján a csak szöveg alapján, ami arra utal, hogy a nagyszabású szóasszociációs adatok, amelyek több nyelven közösségi forrásból származnak, értékes kiegészítője lehetnek a kurátorozott tudásgrafoknak.', 'el': 'Οι άνθρωποι χρησιμοποιούν αμέτρητα βασικά, κοινά γεγονότα για τον κόσμο για να πλοηγηθούν αποτελεσματικά στο περιβάλλον τους. Αυτή η γνώση κοινής λογικής σπάνια επικοινωνείται ρητά, ωστόσο, η κατανόηση του τρόπου με τον οποίο η γνώση κοινής λογικής εκπροσωπείται σε διαφορετικά παραδείγματα είναι σημαντική για (α) μια βαθύτερη κατανόηση της ανθρώπινης γνώσης και (β) την αύξηση των συστημάτων αυτόματου συλλογισμού. Η παρούσα εργασία παρουσιάζει μια σε βάθος σύγκριση δύο μεγάλης κλίμακας πόρων γενικής γνώσης: μια κατασκευασμένη σχεσιακή βάση δεδομένων και ένα γράφημα γνώσης που προέρχεται από ενώσεις λέξεων που προέρχονται από το πλήθος. Εξετάζουμε τη δομή, την επικάλυψη και τις διαφορές μεταξύ των δύο γραφημάτων, καθώς και την έκταση της κατάστασης της γνώσης κοινής λογικής που υπάρχει στους δύο πόρους. Τέλος, αποδεικνύουμε εμπειρικά ότι και οι δύο πόροι βελτιώνουν την απόδοση εργασιών σε δείκτες αναφοράς λογικής λογικής πάνω από γραμμές βάσης μόνο κειμένου, υποδηλώνοντας ότι τα δεδομένα συσχέτισης λέξεων μεγάλης κλίμακας, τα οποία έχουν ληφθεί για αρκετές γλώσσες μέσω της προσέγγισης πλήθους, μπορούν να αποτελέσουν ένα πολύτιμο συμπλήρωμα σε επιμελημμένα γραφήματα γνώσης.', 'it': 'Gli esseri umani usano innumerevoli fatti fondamentali e condivisi sul mondo per navigare in modo efficiente nel loro ambiente. Questa conoscenza del senso comune è raramente comunicata esplicitamente, tuttavia, capire come la conoscenza del senso comune è rappresentata in diversi paradigmi è importante per (a) una comprensione più profonda della cognizione umana e (b) aumentare i sistemi di ragionamento automatico. Questo articolo presenta un confronto approfondito di due risorse di conoscenza generale su larga scala: ConceptNet, un database relazionale ingegnerizzato, e SWOW, un grafico della conoscenza derivato da associazioni di parole crowd-sourcing. Esaminiamo la struttura, la sovrapposizione e le differenze tra i due grafici, così come la portata della conoscenza situazionale del senso comune presente nelle due risorse. Infine, mostriamo empiricamente che entrambe le risorse migliorano le prestazioni delle attività a valle sui benchmark di ragionamento di buon senso rispetto alle linee di base testuali, suggerendo che i dati di associazione di parole su larga scala, che sono stati ottenuti per diverse lingue attraverso il crowdsourcing, possono essere un prezioso complemento ai grafici di conoscenza curati.', 'kk': 'Адамдар өзінің ортасында тәжірибелеу үшін әлемді жұмыс істеу үшін есепті негізгі және бөлікті факттарды қолданады. Бұл көпшілік мәлімет көпшілік түсініктерге салыстырылмайды, бірақ білім көпшілік түсініктерге қанша түсінікті түсініктерді түсініктерге (a) адамдардың білімін түсініктерінің Бұл қағаз жалпы білімдердің екі үлкен масштабының қатынасын салыстыруға арналған: ConceptNet, инженериялық қатынасыз деректер қоры және SWOW, көпшілікті сөздердің құрылымынан шығарылған білім графикасы Біз екі графика арасындағы құрылғыны, қайталап, қайталап, қайталап, қайталап, екі ресурстағы көптеген мәліметтердің шегін тексереміз. Екі ресурстар тек мәтін негізгі сызықтарының көпшілікті тапсырмалардың көпшілікті бағдарламаларының көпшілікті тапсырмаларды жақсартып, бірнеше тілдерге көпшілікті көпшілікті көпшілікті мәтін бағдарламаларынан', 'lt': 'Žmonės efektyviai naviguoja savo aplinkoje naudoja nemažai pagrindinių ir bendrų faktų apie pasaulį. Vis dėlto šios bendros žinios retai aiškiai perduodamos, tačiau supratimas, kaip bendros žinios yra atstovaujamos skirtingais paradigmais, yra svarbus: a) gilesniam žmogaus pažinimo supratimui ir b) automatinių motyvavimo sistemų stiprinimui. Šiame dokumente pateikiamas išsamus dviejų didelio masto bendrųjų žinių išteklių palyginimas: ConceptNet, in žinerinė santykių duomenų bazė, ir SWOW, žinių grafikas, gautas iš visuomenės šaltinių žodžių asociacijų. Mes nagrinėjame abiejų grafikų struktūrą, dubliavimąsi ir skirtumus, taip pat padėties bendrų žinių, esančių abiejuose ištekliuose, mastą. Galiausiai empiriniu būdu parodome, kad abu ištekliai pagerina tolesnių užduočių rezultatus, susijusius su bendru pagrįstumo lyginamuoju rodikliu, palyginti su tik teksto bazinėmis linijomis, ir tai rodo, kad didelio masto žodžių asociacijos duomenys, gaunami keliomis kalbomis naudojant visuomenės išteklius, gali būti vertingas papildymas kuruojamoms žinių grafikoms.', 'mk': 'Луѓето користат безброј основни, споделени факти за светот за ефикасно да навигираат во нивната околина. Сепак, ова заедничко знаење ретко се комуницира експлицитно, разбирањето како заедничкото знаење е претставено во различни парадигми е важно за (a) подлабоко разбирање на човечкото знаење и (b) зголемување на автоматското размислување системи. Овој весник претставува длабока споредба на два големи ресурси на генерално знаење: ConceptNet, инженерска релативна база на податоци, и SWOW, граф на знаење извлечен од друштво на зборови од публика. We examine the structure, overlap and differences between the two graphs, as well as the extent of situational commonsense knowledge present in the two resources.  Конечно емпирички покажуваме дека двата ресурси ја подобруваат резултатот на задачите во понатамошниот текст на заедничките резултати за размислување во однос на основните линии само за текст, што сугерира дека податоците за голем степен на зборови асоцијација, кои се добиени за неколку јазици преку публички извори, можат да бидат вредни допо', 'ml': 'മനുഷ്യര്\u200d ലോകത്തെക്കുറിച്ചുള്ള അടിസ്ഥാനമില്ലാത്ത, പങ്കാളികളുടെ സത്യങ്ങള്\u200d ഉപയോഗിക്കുന്നു. അവരുടെ പരിസ്ഥി ഈ കമോണ്\u200dസണ്\u200dസെന്\u200dസ് അറിവ് വ്യക്തമായി വിവരിച്ചുകൊടുക്കുന്നത് വളരെ കുറച്ച് പ്രധാനപ്പെട്ടിരിക്കുന്നു. എങ്കിലും വ്യത്യസ്ത വിവരങ്ങളില്\u200d കമ്പനോണ്\u200dസണ്\u200dസെന്\u200d ഈ പത്രത്തില്\u200d രണ്ടു വലിയ വിജ്ഞാനത്തിന്റെ വിഭവങ്ങളുടെ ആഴത്തില്\u200d നിന്നും ഒരു താല്\u200dപ്പര്യമുണ്ടാക്കുന്നു. കോണ്\u200dസെപ്റ്റര്\u200dനെറ്റ്, എഞ്ചിനീയറ്റിയ വിവരങ ഈ രണ്ടു ഗ്രാഫുകള്\u200dക്കിടയിലുള്ള സ്ഥിതി, വ്യത്യാസവും, രണ്ടു വിഭവങ്ങളിലുള്ള സാഹചര്യത്തിന്\u200dറെ അറിവിന്\u200dറെ വ്യത്യാസവും അവസാനം നമ്മള്\u200d കാണിക്കുന്നത് സമ്പത്തില്\u200d രണ്ട് വിഭവങ്ങളും കോണ്\u200dസണ്\u200dസെന്\u200dസിന്\u200dറെ കാര്യത്തില്\u200d മെച്ചപ്പെടുത്തുന്നതാണ്. ടെക്സ്റ്റ്-മാത്രം അടിസ്ഥാനങ്ങളില്\u200d മാത്രമായി വാക്', 'ms': 'Humans use countless basic, shared facts about the world to efficiently navigate in their environment.  This commonsense knowledge is rarely communicated explicitly, however, understanding how commonsense knowledge is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems.  Kertas ini mempersembahkan perbandingan dalam-dalam dua sumber skala besar pengetahuan umum: ConceptNet, pangkalan data relatif yang direka, dan SWOW, graf pengetahuan yang dipilih dari persekutuan perkataan yang berasal dari ramai. We examine the structure, overlap and differences between the two graphs, as well as the extent of situational commonsense knowledge present in the two resources.  Akhirnya kita menunjukkan secara empirik bahawa kedua-dua sumber meningkatkan prestasi tugas turun pada tanda rujukan umum atas garis dasar teks-sahaja, menyarankan bahawa data persekutuan perkataan skala besar, yang telah diperoleh untuk beberapa bahasa melalui crowd-sourcing, boleh menjadi tambahan yang berharga untuk graf pengetahuan terkurus.', 'mn': 'Хүмүүс дэлхийн тухай маш олон үндсэн, хуваалцаагүй зүйлсийг хэрэглэдэг. Энэ ерөнхий мэдрэмжтэй мэдлэг ховор тодорхой холбогдолтой байдаг. Гэхдээ өөр парадигмд мэдрэмжтэй мэдлэг хэрхэн илэрхийлэгддэг вэ гэдгийг ойлгох нь (a) хүн төрөлхтний мэдлэг гүн гүнзгий ойлголт болон (b) автоматжуулалтын Энэ цаас ерөнхий мэдлэгтэй хоёр том хэмжээний нөөц боловсруулалтыг гүн гүнзгий харьцуулж байна: ConceptNet, инженерийн харилцааны өгөгдлийн санг, SWOW, олон хүмүүсийн эх үүсвэрээс гарсан мэдлэг график юм. Бид хоёр график хоорондын өөрчлөлтийг, мөн хоёр нөхцөлд байгаа нөхцөл байдлын мэдлэгийг судалж байна. Эцэст нь бид хоёр баялаг үйл ажиллагааны үйл ажиллагааг нийтлэг ойлголтын шалтгаан нь текст зөвхөн суурь шугам дээр илүү сайжруулж, олон хэл дээр олон хэлний нийтлэг боловсруулсан том хэмжээний хамтын өгөгдлийн санал болгож, мэдлэг графикийг сайжруулах үнэ ц', 'no': 'Menneske brukar ulike grunnleggjande, delte faktar om verden for å flytta effektivt i miljøet sine. Denne vanlege kunnskapen er ofte kommunisert eksplisisk, men forstår korleis vanlege kunnskapen er representert i ulike paradigmar er viktig for a) ein dypere forståelse av menneske kognisjon og b) økning av automatiske redensingssystemer. Denne papiret viser ein i dybde sammenligning med to stor stor ressursar med generelle kunnskap: ConceptNet, ein ingeniarert relasjonal database og SWOW, eit kunnskap graf som er avhengig frå crowd sourced word associations. Vi undersøker strukturen, overlapp og forskjeller mellom dei to grafene, og storleiken på situasjonelle fellesske kunnskap som finst i dei to ressursane. Vi viser til slutt empirisk at begge ressursar forbedrar nedstremde oppgåver på vanleg rasjonsbankar over tekst-berre baselinjer, som tyder på at store stor ord-assosiasjonsdata, som er henta for fleire språk gjennom crowd-sourcing, kan vera eit verdileg komplement til korrigerte kunnskap-grafikk.', 'pl': 'Ludzie używają niezliczonych podstawowych, dzielonych faktów o świecie, aby skutecznie poruszać się po swoim otoczeniu. Ta wiedza zdrowego rozsądku rzadko jest przekazywana wyraźnie, jednak zrozumienie, w jaki sposób wiedza zdrowego rozsądku jest reprezentowana w różnych paradygmatach, jest ważne dla (a) głębszego zrozumienia ludzkiego poznania i (b) rozszerzania systemów automatycznego rozumowania. W artykule przedstawiono dogłębne porównanie dwóch dużych zasobów wiedzy ogólnej: ConceptNet, inżynierii relacyjnej bazy danych oraz SWOW, wykresu wiedzy pochodzącego z skojarzeń słowowych pochodzących z crowdsourcingu. Badamy strukturę, nakładanie się i różnice między dwoma wykresami, a także zakres wiedzy sytuacyjnej obecnej w obu zasobach. Wreszcie pokazujemy empirycznie, że oba zasoby poprawiają wydajność zadań w dalszym szczeblu w odniesieniu do wskaźników rozumowania zdrowego rozsądku w stosunku do linii bazowych tylko tekstowych, sugerując, że duże dane dotyczące skojarzeń słów, które zostały uzyskane dla kilku języków poprzez crowdsourcing, mogą być cennym uzupełnieniem kuratorowanych wykresów wiedzy.', 'ro': 'Oamenii folosesc nenumărate fapte de bază, împărtășite despre lume pentru a naviga eficient în mediul lor. Această cunoaștere comună este rareori comunicată explicit, cu toate acestea, înțelegerea modului în care cunoașterea comună este reprezentată în diferite paradigme este importantă pentru (a) o înțelegere mai profundă a cunoașterii umane și (b) creșterea sistemelor automate de raționament. Această lucrare prezintă o comparație aprofundată a două resurse de cunoaștere generală la scară largă: ConceptNet, o bază de date relațională ingineriată, și SWOW, un grafic de cunoaștere derivat din asociații de cuvinte crowd-sourced. Examinăm structura, suprapunerea și diferențele dintre cele două grafice, precum și amploarea cunoștințelor situaționale de bun sens prezente în cele două resurse. În cele din urmă, demonstrăm empiric că ambele resurse îmbunătățesc performanța activităților în aval pe criterii de raționament comun în raport cu liniile de referință doar text, sugerând că datele de asociere a cuvintelor la scară largă, care au fost obținute pentru mai multe limbi prin crowdsourcing, pot fi un complement valoros pentru graficele de cunoștințe curate.', 'si': 'මිනිස්සුන්ට ලෝකය ගැන විශේෂ විශේෂ විශේෂ විදිහට ප්\u200dරයෝජනය කරන්න පුළුවන් විශේෂ විද මේ සාමාන්\u200dය දැනගන්නේ දැනගන්න බැරි විදිහට සම්බන්ධ වෙන්නේ, නමුත්, ස්වයංක්\u200dරීය විදිහට සමාන්\u200dය දැනගන්නේ කොච්චර දැනගන්න පුළුවන්  This papers presents a in-depth comparison of 2 Large-scaled ressources of General Knowing: ConcNet, an Engineering Associate Data, and SWOW, a Knowing Graph from Public-source Words Association. අපි ග්\u200dරාෆ් දෙකක් අතර පරීක්ෂා කරනවා, ප්\u200dරතිචාර දෙකක් අතර වෙනස් කරනවා, ඒ වගේම ප්\u200dරතිචාර දේශ දෙකක් තියෙන්න ත අපි අන්තිමේදී පෙන්වන්නේ අන්තිමේදී විශේෂයෙන් දෙන්නම් පරීක්ෂණ වැඩක් විශේෂය කරන්න පුළුවන් විශේෂයෙන් පිළිබඳ සාමාන්\u200dය විශේෂයෙන් පිළිබඳ ව', 'sr': 'Ljudi koriste bezbrojne osnovne, zajedničke činjenice o svetu kako bi se efikasno navigarali u svojoj okolini. Ovo znanje često čudno je rijetko komunicirano jasno, međutim, shvatanje kako često čudno znanje predstavlja u različitim paradigmima je važno za a) dublje razumijevanje ljudske kognicije i b) povećanje automatskih razumnih sustava. Ovaj papir predstavlja duboko usporedbu dve velike resurse općeg znanja: ConceptNet, in ženjerirana vezna baza podataka, i SWOW, grafik znanja koji je proizveden iz udruženja riječima iz crowd-sourced words. Pregledali smo strukturu, preklapanje i razlike između dva grafika, kao i mjeru situacionalnog znanja zajedničkog smisla koji su prisutni u dva resursa. Konačno pokazujemo empirički da obe resurse poboljšavaju funkcionalni rezultat u odnosu na standarde razumljivanja uobičajenih razuma samo na osnovnim linijama teksta, sugerirajući da podaci o velikoj skali asocijacije riječi koje su dobile za nekoliko jezika putem resursa publika mogu biti vrijedan dodatak korištenih grafika znanja.', 'so': 'Dadku waxay isticmaalaan waxyaabaha aasaasiga ah ee caalamiga ah oo saameyn la’aan ah si ay si fiican ugu socoto deegaankooda. This commonsense knowledge is rarely communicated explicitly, however, understanding how commonsense knowledge is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems.  Qoraalkan waxaa soo bandhiga hoos u dhigta laba maalmood oo aad u weyn aqoonta guud: ConceptNet, taas oo ah macluumaad xiriir ah, iyo SWOW, sawir aqoonta ah oo ka soo baxay ururada macluumaadka dadka badan. Waxaannu baaraynaa dhismaha, isku bedelashada iyo kala duwanaanshaha labada tusaale ahaan iyo sidoo kale aqoonta shirkadda ee labada maalmood ku jira. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.', 'sv': 'Människor använder otaliga grundläggande fakta om världen för att effektivt navigera i sin omgivning. Denna allmännyttiga kunskap kommuniceras sällan explicit, men att förstå hur allmännyttig kunskap representeras i olika paradigm är viktigt för (a) en djupare förståelse av mänsklig kognition och (b) förstärkning av automatiska resonemang system. Denna uppsats presenterar en djupgående jämförelse av två storskaliga resurser av allmän kunskap: ConceptNet, en konstruerad relationsdatabas, och SWOW, en kunskapsgraf som härrör från crowd-sourced ordassociationer. Vi undersöker strukturen, överlappningen och skillnaderna mellan de två graferna, samt omfattningen av situationskunskap som finns i de två resurserna. Slutligen visar vi empiriskt att båda resurserna förbättrar prestationen nedströms på allmännyttiga resonemang benchmarks jämfört med text-only baselines, vilket tyder på att storskaliga ordassociationsdata, som har erhållits för flera språk genom crowdsourcing, kan vara ett värdefullt komplement till kuraterade kunskapsgrafer.', 'ta': 'மனிதர்கள் எண்ணிக்கையில்லாத அடிப்படையாளர், பங்கிடப்பட்ட காரியங்களை பயன்படுத்துகிறார்கள் இந்த தொழில்நுட்ப அறிவு குறைவாகவே தொடர்பு கொள்ளப்படுகிறது, ஆனாலும் வேறு அளபுருக்களில் எவ்வாறு தொழில்நுட்ப அறிவு குறைந்தது என்பதை புரிந்து கொள்ளும இந்த காகிதத்தில் இரண்டு பெரிய அளவு அறிவின் மூலங்களின் ஆழமான ஒப்பிடுப்பதை கூட்டுகிறது: கான்ஸ்பெட்டின், ஒரு பொறிய தொடர்பு தரவுத்தளத்தில் இருந்து கொ நாம் இரண்டு வரைபடங்களுக்கிடையே உள்ள கட்டமைப்பு, மேல் மற்றும் வேறுபாடுகளை பரிசோதிக்கிறோம், மற்றும் இரண்டு வளங்களில் இருக்கு இறுதியாக நாம் வெறுமையாக காண்பிக்கிறோம் என்றால், இரண்டு மூலங்களும் கீழே நீர் செயல் செயல்பாட்டை மேம்படுத்துகிறது, உரையின் மேல் மட்டும் அடிப்படைகளில் உள்ள காரணங்களை மேல் ம', 'ur': 'انسانوں نے دنیا کے بارے میں بے شمار بنیادی اور مشترک حقیقت کا استعمال کیا ہے کہ ان کے محیط منظور میں اثرات کے ساتھ سفر کریں۔ یہ معمولی علم بہت کم واضح طور پر اتاری جاتی ہے، لیکن سمجھ لیتے ہیں کہ کس طرح معمولی علم مختلف بہشتوں میں دکھائی جاتی ہے، انسان کی معلومات کی عمیقی سمجھ اور (b) اتمام بحث نظام کی زیادہ اضافہ کرتی ہے۔ یہ کاغذ ایک عمومی علم کے دو بڑے مقدار منبع کے مطابق عمیق مقایسہ کے طور پر پیش کرتا ہے: ConceptNet، ایک انجینریر رابطہ ڈیٹابیس، اور SWOW، ایک علم گراف جو جماعت کے منبع سے آئی ہے. ہم ان دونوں گراف کے درمیان ساختار اور تفریق کی تحقیق کررہے ہیں اور دونوں منابعوں میں موجود معلوم علم کی کثرت بھی ہے ہم بالکل مطمئن طور پر دکھاتے ہیں کہ دونوں منبع کائناٹ ٹاکس کی عملکرد کو کمترین سمجھانے کے بغیر پایس لینوں پر بنچم مارک ترجیح دیتے ہیں، یہ بات کرتا ہے کہ بہت سی زبانوں کے لئے بہت سی زبانوں کے ذریعہ حاصل کیا گیا ہے، جماعت-سورسینگ کے ذریعہ، علم گراف کے لئے', 'mt': 'Humans use countless basic, shared facts about the world to efficiently navigate in their environment.  Dan l-għarfien komuni rarament jiġi kkomunikat b’mod espliċitu, madankollu, il-fehim ta’ kif l-għarfien komuni huwa rappreżentat f’paradigmi differenti huwa importanti għal (a) fehim aktar profond tal-konoxximent uman u (b) żieda fis-sistemi ta’ raġunament awtomatiku. Dan id-dokument jippreżenta tqabbil fil-fond ta’ żewġ riżorsi fuq skala kbira ta’ għarfien ġenerali: ConceptNet, bażi ta’ dejta relattiva in ġinerizzata, u SWOW, grafika ta’ għarfien derivata minn assoċjazzjonijiet ta’ kliem ta’ crowd-sourced. Aħna jeżaminaw l-istruttura, il-koinċidenza u d-differenzi bejn iż-żewġ grafiċi, kif ukoll il-firxa tal-għarfien komuni tas-sitwazzjoni preżenti fiż-żewġ riżorsi. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.', 'uz': "Insonlar dunyo haqida ko'p asosiy, bilan birlashtirilgan haqida ishlatiladi. Ularning muhitda tasavvur qilish uchun. Bu kommunikasi ma'lumot juda oddiy narsa bilan bog'liqdir, ammo, boshqa paradiglarga qanday kommunikasi aniqlashni o'rganish imkoniyatini (a) qo'shimcha imkoniyatlarni ajratish muhim va (b) avtomatik sabablar tizimini oshirish muhimdir. Bu qogʻoz umumiy ma'lumotning ikkita katta murakkab manbalarning qismlariga mos keladi: ConceptNet, muhandiya murakkab maʼlumot bazasi va SWOW, jamoatlar manbasiga ega ma'lumot grafik. Biz ikkita grafikning orasidagi tuzuvni, koʻpchirish va o'zgarishlarni va ikkita rasmlarda mavjud narsalar imkoniyatining darajasini tekshirimiz. Biz oxirgi imkoniyatlarni ko'rsatganimiz, ikkita rasmlar soni quyidagi matn asosidagi imkoniyatlarni bajarish imkoniyatini o'zgartiradi. Bu holatning ko'pchilik soʻzning bir necha tillar uchun bog'liq foydalanilgan ma'lumotlarni bir necha tillar orqali jamiyatlarni o'rganish mumkin, ma'lumot grafiklarni qiymatga qo", 'vi': 'Con người sử dụng vô số dữ liệu cơ bản, chia sẻ về thế giới để sử dụng năng lượng trong môi trường. Thông tin phổ biến này hiếm khi được phổ biến trực tiếp, tuy nhiên, hiểu được cách thức phổ biến được đại diện trong các tư tưởng khác nhau là quan trọng cho: a) hiểu biết sâu hơn về nhận thức con người và b) tăng cường hệ thống lập luận tự động. Tờ giấy này cho thấy một sự so sánh sâu sắc với hai nguồn tài nguyên lớn của kiến thức chung: ConcPTNet, một cơ sở dữ liệu liên quan cải tạo, và SWOW, một đồ thị kiến thức chiết xuất từ liên minh từ từ tiếng đông. Chúng tôi kiểm tra cấu trúc, sự chồng chéo và sự khác nhau giữa hai biểu đồ, cũng như quy mô của kiến thức phổ biến có trong hai nguồn tài nguyên. Chúng ta cuối cùng cùng thể hiện bằng kinh nghiệm cả hai nguồn tài nguyên cải thiện khả năng làm việc theo quy định chung trên nền tảng chỉ có văn bản, cho thấy rằng dữ liệu liên kết từ ngữ rộng lớn, được lấy ra cho nhiều ngôn ngữ qua nguồn hàng đông, có thể là một bổ sung quý giá cho đồ thị kiến thức.', 'da': 'Mennesker bruger utallige grundlæggende, delte fakta om verden til effektivt at navigere i deres miljø. Denne almindelige viden formidles sjældent eksplicit, men forståelsen af, hvordan almindelig viden repræsenteres i forskellige paradigmer er vigtig for (a) en dybere forståelse af menneskelig kognition og (b) forøgelse af automatiske ræsonnementssystemer. Denne artikel præsenterer en dybdegående sammenligning af to store ressourcer af generel viden: ConceptNet, en konstrueret relationsdatabase, og SWOW, en vidensgraf afledt af crowd-sourced ord associationer. Vi undersøger strukturen, overlapningen og forskellene mellem de to grafer samt omfanget af situationel almindelig viden til stede i de to ressourcer. Endelig viser vi empirisk, at begge ressourcer forbedrer downstream opgavernes ydeevne på almindelig ræsonnement benchmarks i forhold til tekstbaserede basislinjer, hvilket tyder på, at storstilede ordassocieringsdata, som er opnået for flere sprog gennem crowdsourcing, kan være et værdifuldt supplement til kuraterede vidensgrafer.', 'hr': 'Ljudi koriste bezbrojne osnovne, zajedničke činjenice o svijetu kako bi učinkovito navigarali u njihovom okruženju. Međutim, to znanje često čudno rijetko se objašnjava jasno, razumijevanje kako često čudno znanje predstavlja u različitim paradigmima je važno za a) dublje razumijevanje ljudskog znanja i b) povećanje automatskih razumnih sustava. Ovaj papir predstavlja duboko usporedbu dvije velike sredstva općeg znanja: ConceptNet, in ženjerirana vezna baza podataka i SWOW, grafik znanja iz udruženja riječima iz masovnih izvora. Provjeravamo strukturu, preklapanje i razlike između dva grafika, kao i mjeru situacijskog znanja zajedničkog smisla koji su prisutni u dva resursa. Konačno pokazujemo empirički da obje resurse poboljšavaju učinkovitost zadatka u skladu s razumnim kriterijama samo teksta na osnovnim linijama, sugerirajući da podaci o velikoj skali udruženja riječi koje su dobile za nekoliko jezika putem izvođenja masovnih izvora mogu biti vrijedan dodatak korištenih znanja.', 'de': 'Menschen nutzen unzählige grundlegende, geteilte Fakten über die Welt, um effizient in ihrer Umgebung zu navigieren. Dieses Wissen des gesunden Menschenverstandes wird selten explizit kommuniziert, aber das Verständnis, wie das Wissen des gesunden Menschenverstandes in verschiedenen Paradigmen dargestellt wird, ist wichtig für (a) ein tieferes Verständnis der menschlichen Wahrnehmung und (b) die Erweiterung automatischer Denksysteme. Der vorliegende Beitrag stellt einen detaillierten Vergleich zweier großer allgemeiner Wissensressourcen vor: ConceptNet, eine technische relationale Datenbank, und SWOW, ein Wissensgraph, der aus Crowdsourcing-Wortassoziationen abgeleitet wird. Wir untersuchen die Struktur, Überlappung und Unterschiede zwischen den beiden Graphen sowie das Ausmaß des situativen gesunden Wissens in den beiden Ressourcen. Schließlich zeigen wir empirisch, dass beide Ressourcen die Leistung von nachgelagerten Aufgaben bei Benchmarks für gesundes Denken gegenüber reinen Text-Baselines verbessern, was darauf hindeutet, dass große Wortzuordnungsdaten, die für mehrere Sprachen durch Crowdsourcing gewonnen wurden, eine wertvolle Ergänzung zu kuratierten Wissensgraphen darstellen können.', 'bg': 'Хората използват безброй основни, споделени факти за света, за да се ориентират ефективно в средата си. Това общо разумно знание рядко се съобщава изрично, но разбирането как общото разумно знание е представено в различните парадигми е важно за (а) по-задълбочено разбиране на човешкото познание и (б) увеличаване на автоматичните системи за разсъждаване. Настоящата статия представя задълбочено сравнение на два широкомащабни ресурса на общото знание: проектирана релационна база данни и графика на знанието, получена от групови думи асоциации. Разглеждаме структурата, припокриването и разликите между двете графики, както и степента на познанията за ситуацията, присъстващи в двата ресурса. Най-накрая показваме емпирично, че и двата ресурса подобряват изпълнението на задачите надолу по веригата по референтните показатели за разумни разсъждения върху базовите линии само за текст, което предполага, че широкомащабните данни за асоцииране на думи, които са получени за няколко езика чрез групово търсене, могат да бъдат ценно допълнение към подбраните графики на знанието.', 'ko': '인류는 헤아릴 수 없이 많은 세계의 기본, 공유에 관한 사실을 사용하여 환경에서 효과적으로 내비게이션을 한다.이런 상식적 지식은 명확하게 전달되지 않지만 상식적 지식이 서로 다른 모델에서의 표현 방식을 이해하는 것은 (a) 인류의 인지를 깊이 이해하고 (b) 자동 추리 시스템을 강화하는 데 매우 중요하다.본고는 두 가지 대규모의 통용 지식 자원을 깊이 있게 비교했다. 그것이 바로 공학 관계 데이터베이스인ConceptNet과 패키지 단어와 관련된 지식 그림인 SWOW이다.우리는 두 도표 간의 구조, 중첩과 차이, 그리고 두 자원에 존재하는 상황 상식 지식의 범위를 검사했다.마지막으로 우리는 순수한 텍스트 기선에 비해 이 두 가지 자원이 상식 추리 기준에서 하위 임무의 성능을 향상시켰다는 것을 경험적으로 증명했다. 이는 패키지를 통해 얻은 다양한 언어의 대규모 단어 관련 데이터가 정성스럽게 기획된 지식도에 가치 있는 보충이 될 수 있음을 나타낸다.', 'nl': "Mensen gebruiken talloze fundamentele, gedeelde feiten over de wereld om efficiënt te navigeren in hun omgeving. Deze kennis van gezond verstand wordt zelden expliciet gecommuniceerd, maar begrijpen hoe gezond verstand wordt vertegenwoordigd in verschillende paradigma's is belangrijk voor (a) een dieper begrip van menselijke cognitie en (b) het uitbreiden van automatische redeneringssystemen. Deze paper presenteert een diepgaande vergelijking van twee grootschalige bronnen van algemene kennis: ConceptNet, een engineered relational database, en SWOW, een kennisgrafiek afgeleid van crowdsourced woordassociaties. We onderzoeken de structuur, overlapping en verschillen tussen de twee grafieken, evenals de mate van situationele gezond verstand kennis aanwezig in de twee bronnen. We laten ten slotte empirisch zien dat beide resources de prestaties van downstreamtaken verbeteren op basis van gezond verstand redeneren benchmarks ten opzichte van alleen tekst baselines, wat suggereert dat grootschalige woordassociatiegegevens, die zijn verkregen voor meerdere talen via crowdsourcing, een waardevolle aanvulling kunnen zijn op curated kennisgrafieken.", 'id': 'Manusia menggunakan banyak fakta dasar, berbagi tentang dunia untuk navigasi secara efisien di lingkungan mereka. Pengetahuan umum ini jarang dikomunikasi secara eksplisit, bagaimanapun, memahami bagaimana pengetahuan umum diwakili dalam paradigma yang berbeda adalah penting untuk (a) pemahaman lebih dalam pengetahuan manusia dan (b) meningkatkan sistem pemikiran otomatis. Kertas ini mempersembahkan perbandingan dalam-dalam dua sumber daya skala besar dari pengetahuan umum: ConceptNet, sebuah database relatif yang direncanakan, dan SWOW, grafik pengetahuan yang berasal dari asosiasi kata yang berasal dari ramai. Kami memeriksa struktur, overlap dan perbedaan antara kedua grafik, serta lebar pengetahuan umum situasi yang ada di kedua sumber daya. Akhirnya kami menunjukkan secara empiris bahwa kedua sumber daya meningkatkan prestasi tugas turun pada benchmark pemikiran umum atas garis dasar teks-hanya, yang menyarankan bahwa data asosiasi kata skala besar, yang telah diperoleh untuk beberapa bahasa melalui crowd-sourcing, dapat menjadi komplimen yang berharga untuk grafik pengetahuan curated.', 'af': "Mense gebruik tel basiese, gedeelde fakte oor die wêreld om effektief in hul omgewing te navigeer. Hierdie gemeenskaplike kennis is selfs uitsonderlik gekommuniseerd, maar verstaan hoe gemeenskaplike kennis in verskillende paradigme verteenwoordig word, is belangrik vir (a)  'n dieper verstanding van menslike kognisie en (b) vergroot automatiese redensiesystemee. Hierdie papier stel 'n in-diepte vergelyking van twee groot-skaal hulpbronne van algemene kennis: ConceptNet, 'n ingenieërde relatiewe databasis en SWOW, 'n kennisgraaf afgelei van skaal-gebronde woord assosiasies. Ons ondersoek die struktuur, oorvloei en verskillinge tussen die twee grafieke, en die uitbreiding van situasielike gemeenskaplike kennis wat in die twee hulpbronne voorsien is. Ons wys eindelik empiriese dat beide hulpbronne onderstreem taak-prestasie op gemeenskaplike redekende benchmarke oor teks-alleen basisline verbeter, wat voorstel dat groot-skaal woord-assosiasie data, wat vir verskeie tale deur skare-sourcing verskaf is, kan 'n waardelike komplement wees om gewysigde kennisgraaf.", 'fa': 'انسان ها از حقیقت های بنیادی بی عدد و مشترک در مورد جهان استفاده می کنند تا به طور موثرت در محیط محیط خودشان سفر کند. این دانش معمولی کم کم به طور توضیح ارتباط می\u200cدهد، ولی بفهمید که چگونه دانش معمولی در پارادیگ\u200cهای مختلف معرفی می\u200cشود، برای درک عمیق\u200cتر از شناختن انسان و (b) افزایش سیستم\u200cهای منظوری خودکار مهم است. این کاغذ یک مقایسه عمیق از دو منابع مقایسه بزرگ از دانش عمومی را نشان می دهد: ConceptNet، یک داده\u200cگاه ارتباطی مهندسی، و SWOW، یک گراف دانش از ارتباطات کلمات متعلق به جمعیت است. ما ساختار، تفاوت و تفاوت بین دو گراف را تحقیق می\u200cکنیم، و وسیله دانش معمولی موقعیت که در دو منابع وجود دارد را تحقیق می\u200cکنیم. بالاخره ما به صورت امپراطوری نشان می دهیم که هر دو منابع عملکرد عملیات پایین\u200cترین عملیات را بر روی منطقه\u200cهای منطقی بر روی خطوط\u200cهای پایین\u200cترین متن بهتر می\u200cکند، پیشنهاد می\u200cدهد که داده\u200cهای اتصال کلمات بزرگ، که برای چندین زبان\u200cها از طریق استفاده از جمعیت\u200cترین ز', 'tr': 'İnsanlar dünya hakkındaki sayısız temel ve paylaşık gerçekleri çevrelerinde etkileşimli şekilde dolaşmak için kullanır. Bu ýagdaýy duýgunlaşyk bilgi (a) adamlaryň tanyşynyň derinliki düşünmesi we (b) awtomatik düşünme sistemalarynda nähili duýgunlaşyk edilýän bilimi düzümlendirilýändir. Bu kagyz umumy bilgi üçin 2 uly kalam çeşmeleriniň derinlikli baglaşyklygyny görkezýär: ConceptNet, in ženjeriliýan baglaşykly databank we SWOW, toplum tarapyndan çykan bilim grafiki. Biz iki grafik aralygynda döredişi, üstünlik we farklygyny çykarýarys, we iki çeşmede bolan ýagdaýynyň bilimi bilen çykarýarys. Soňunda biz empiriýa görkezilýän iki çeşme günahlaryň düşürmegi diňe metin-diňe basehatlaryň üstünde düşürmegi üçin azaltýan täzelikleri geliştirmegini, köpürler sebäbi bolan dilleriň birnäçe görnüşleri üçin golaý sözler guralýan grafiklere golaýlaşýar.', 'sw': 'Watu wanatumia ukweli wa msingi, unaosambazwa na ukweli kuhusu dunia ili kusafiri kwa ufanisi katika mazingira yao. Ujuzi huu wa mkusanyiko unawasiliana nadra sana, hata hivyo, kuelewa jinsi maarifa ya umma inavyowakilishwa katika vifaa tofauti ni muhimu kwa (a) kuelewa zaidi maarifa ya binadamu na (b) kuongeza mfumo wa kujieleza. Gazeti hili linatoa ulinganisho wa kina wa rasilimali mbili kubwa za ufahamu mkubwa: ConceptNet, database ya mahusiano, na SWOW, picha ya maarifa iliyotolewa kutoka kwenye mashirika ya maneno yanayopatikana na watu wengi. Tunajaribu muundo, upanuzi na tofauti kati ya picha hizo mbili, pamoja na kiwango cha maarifa ya umma yanayopo katika rasilimali hizi mbili. Hatimaye tunaonyesha kwa makini kwamba rasilimali zote hizi zinaboresha utendaji wa kazi za mitandao kwa makubaliano yanayojadili misingi yenye maandishi pekee, tunapendekeza kuwa taarifa kubwa za ushirikiano wa maneno, ambazo zimekwisha kupatikana kwa lugha kadhaa kupitia vyanzo vya umma, inaweza kuwa complement muhimu wa kufungia picha za maarifa.', 'am': 'ሰዎች በአካባቢው ውስጥ በጥቅም ለመሄድ የሚጠቅሙ የዓለማዊ መሠረት፣ የተካፈሉት ውሸቶች ይጠቅማሉ፡፡ ይህ የድምፅ እውቀት ግልፅ ፍለጋዊ ግልጾች ብቻ ነው፣ ነገር ግን በተለያዩ አካባቢዎች ውስጥ የድምፅ እውቀት እንዴት እንደተገለጠ ማስተዋል (a) ለሰው ማውቀት ጥልቅ ማስተዋል እና (b) የራሳቸውን ማስተዋል ሲያበዛል፡፡ ይህ ገጽ የሁለት ትልቅ እውቀት ሀብትን ለማስተካከል ጥልቅ ያሳያል፡፡ ConceptNet፣ የግንኙነት ዳታቤል እና SWOW፣ ከሰብአዊ ቋንቋ ማኅበረሰብ የተገኘውን እውቀት መክፈት ነው፡፡ በሁለቱ ግንኙነት መካከል እና በሁለቱ ሀብት ውስጥ ያሉትን የአካባቢነት እውቀት እውቀትን እናፈትናለን፡፡ በመጨረሻም ሁለንተናው የውይይት ጉዳይ የድምፅ አካባቢዎችን በጽሑፍ ብቻ መቀመጫዎች ላይ በሚያሳድጉ አዋጅ እንዲያሳየን እናሳየዋለን፡፡', 'hy': 'Մարդիկ օգտագործում են անթիվ հիմնական, կիսված փաստեր աշխարհի մասին, որպեսզի արդյունավետ նայեն իրենց միջավայրում: Այս ընդհանուր գիտելիքները հազվադեպ են հաղորդակցվում բացատրաբար, սակայն հասկանալը, թե ինչպես են ընդհանուր գիտելիքները ներկայացված տարբեր պարադիգմերում, կարևոր է a) մարդկային ճանաչության ավելի խորը հասկանալու համար և b) ավտոմատիկ մտածողության համակարգերի աճի համար: This paper presents an in-depth comparison of two large-scale resources of general knowledge: ConceptNet, an engineered relational database, and SWOW, a knowledge graph derived from crowd-sourced word associations.  Մենք ուսումնասիրում ենք երկու գրաֆիկների կառուցվածքը, կապը և տարբերությունները, ինչպես նաև երկու ռեսուրսներում գոյություն ունեցող իրավիճակական ընդհանուր գիտելիքների ծավալը: Մենք վերջապես էմպիրիկապես ցույց ենք տալիս, որ երկու ռեսուրսները բարելավում են ընդհանուր մտածողական համեմատությունները միայն տեքստի հիմնական գծերի վերաբերյալ, առաջարկում են, որ բառերի կապվածության մեծ մասշտաբով տվյալները, որոնք ստացվել են բազմաթիվ լեզուներում ժողովրդի հարաբերությունների միջոցով, կարող են ար', 'sq': 'Njerëzit përdorin shumë fakte bazë dhe të ndara rreth botës për të naviguar efektivisht në mjedisin e tyre. Kjo njohuri e përbashkët rrallë komunikohet shprehësisht, megjithatë, kuptimi se si njohuria e përbashkët përfaqësohet në paradigma të ndryshme është i rëndësishëm për (a) një kuptim më të thellë të njohurisë njerëzore dhe (b) rritjen e sistemeve automatike të arsyetimit. Ky artikull paraqet një krahasim të thellë të dy burimeve të shkallës së madhe të njohurive të përgjithshme: ConceptNet, një bazë të dhënash marrëdhënieve të inxhinieruar dhe SWOW, një grafik njohurie të nxjerrë nga shoqatat e fjalëve të burimit të turmës. Ne e shqyrtojmë strukturën, mbishtypjen dhe dallimet midis dy grafikëve, si dhe shkallën e njohurive të përbashkëta të gjendjes në të dy burimet. Ne përfundimisht tregojmë empirikisht se të dy burimet përmirësojnë performancën e detyrës poshtë rrjedhës mbi normat e arsyetimit të zakonshëm mbi linjat bazë vetëm teksti, duke sugjeruar se të dhënat e shoqërimit të fjalëve në shkallë të madhe, të cilat janë marrë për disa gjuhë nëpërmjet crowd-sourcing, mund të jenë një komplement të vlefshëm për grafikat e njohurive të kuruara', 'bn': 'মানুষ তাদের পরিবেশে কার্যকর ভাবে যাত্রা করার জন্য বিশ্বের মৌলিক, ভাগাভাগি তথ্য ব্যবহার করে। This commonsense knowledge is rarely communicated explicitly, however, understanding how commonsense knowledge is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems.  এই পত্রিকাটি সাধারণ জ্ঞানের দুটি বিশাল সম্পদের তুলনায় একটি গভীরভাবে তুলনা করেছে: কনসেপ্টনেট, একটি প্রকাশিত সম্পর্কের তথ্যের বাস্তবতা এবং এসওয়াউ, জনসূত্র আমরা এই দুই গ্রাফের মধ্যে কাঠামোর, আপাতল এবং পার্থক্য পরীক্ষা করি, আর দুই সম্পদের মধ্যে অবস্থান কমিউনিসেন্সের জ্ঞানের পরীক্ষা কর শেষ পর্যন্ত আমরা ক্ষমতার সাথে দেখাচ্ছি যে দুটি সম্পদ কমানসেন্সের মাধ্যমে বেনম্যানেক্সের মাধ্যমে কমিউনিস্ট্রিমেন্সের কাজের উন্নতি পাওয়া যাচ্ছে, যেখানে পরামর্শ দেয় যে বিশাল ম', 'az': 'İnsanlar dünya haqqında sayısız temel, paylaşılmış həqiqətlərdən istifadə edirlər ki, onların çevresində müvəffəqiyyəti olaraq navigatiya edərlər. Bu çoxlu hiss elmi a çıq-aydın bildirildir, amma insanların tanıdıqlarını daha derin anlaması və (b) avtomatik dəyişiklik sistemlərini artırmaq üçün çoxlu münasibdir. Bu kağıt genel bilginin iki böyük ölçülü kaynaqlarının derinliklə karşılaşdırılmasını göstərir: ConceptNet, mühendisə bağlı verilən verilən verilənlər və SWOW, qüvvətli söz bağlantılarından gələn elm grafı. İki grafik arasında müxtəlif quruluş, çəkilmək və fərqləşmək, həmçin in iki kaynaqların içində yaşayan müxtəlif biliklərin genişliyini də incidirik. Sonunda, hər ikisi istifadə edirik ki, çoxlu dillərə istifadə edilən çoxlu dillərə istifadə edilən çoxlu məlumat grafiklərinə çoxlu dəyişiklik göstərilən çoxlu dəyişiklik məlumatların düzəltməsi haqqında çoxlu dəyişiklik göstəricisi nəticəsini daha yaxşılaşdırır.', 'bs': 'Ljudi koriste bezbrojne osnovne, zajedničke činjenice o svijetu kako bi učinkovito navigarali u njihovom okruženju. Ovo znanje često čudno rijetko se objavljuje jasno, međutim, razumijevanje kako često čudno znanje predstavlja u različitim paradigmima je važno za a) dublje razumijevanje ljudskog kognicije i b) povećanje automatskih razumnih sustava. Ovaj papir predstavlja duboko usporedbu dvije velike resurse općeg znanja: ConceptNet, in ženjerirana vezna baza podataka, i SWOW, grafik znanja koji je proizveden iz udruženja riječima iz masovnih izvora. Provjeravamo strukturu, preklapanje i razlike između dva grafika, kao i mjeru situacionalnog znanja zajedničkog smisla koji su prisutni u dva resursa. Konačno pokazujemo empirički da obje resurse poboljšavaju funkcionalni rezultat na osnovnim kriterijama razumljivanja zajedničkih razuma samo na tekstu, sugerirajući da podaci o velikoj skali asocijacije riječi koje su dobile za nekoliko jezika putem izvođenja masovnih izvora mogu biti vrijedan dodatak korištenih grafika znanja.', 'ca': "Els humans utilitzen innumerables fets bàsics i compartits sobre el món per navegar eficientment al seu entorn. Aquest coneixement comú rarament es comunica explícitament, però entendre com el coneixement comú es representa en diferents paradigmes és important per a (a) una comprensió més profunda de la cognitió humana i (b) augmentar els sistemes de raonament automàtic. Aquest article presenta una comparació en profunditat de dos recursos a gran escala del coneixement general: ConceptNet, una base de dades de relacions enginyeria, i SWOW, un gràfic de coneixement derivat d'associacions de paraules d'una multitud. Examinem l'estructura, la sobreposió i les diferències entre els dos gràfics, i l'extensió del coneixement comú de la situació present en els dos recursos. Finalment demostram empíricament que ambdós recursos milloren el rendiment de les tasques en avall en punts de referència de raonament comuns sobre les línies de referència només de text, suggerent que les dades d'associació de paraules a gran escala, que s'han obtenit per diverses llengües a través de crowd sourcing, poden ser un complement valiós a gràfics de coneixement curats.", 'cs': 'Lidé používají nespočet základních, sdílených faktů o světě k efektivní navigaci ve svém prostředí. Tato znalost zdravého rozumu je zřídka explicitně sdělována, nicméně pochopení toho, jak jsou znalosti zdravého rozumu reprezentovány v různých paradigmatech, je důležité pro (a) hlubší porozumění lidskému poznání a (b) rozšíření automatických systémů uvažování. Tento článek představuje hloubkové srovnání dvou rozsáhlých zdrojů obecných znalostí: ConceptNet, inženýrská relační databáze, a SWOW, znalostní graf odvozený z crowdsourcingových slovních asociací. Zkoumáme strukturu, překrývání a rozdíly mezi oběma grafy, stejně jako rozsah situačních znalostí zdravého rozumu přítomných v obou zdrojích. Konečně empiricky ukazujeme, že oba zdroje zlepšují výkon následných úkolů na srovnávacích měřítkách zdravého rozumu oproti textovým základním liniím, což naznačuje, že rozsáhlá data o asociaci slov, která byla získána pro několik jazyků prostřednictvím crowdsourcingu, mohou být cenným doplňkem kurátorovaných znalostních grafů.', 'et': 'Inimesed kasutavad lugematuid põhilisi fakte maailma kohta, et tõhusalt oma keskkonnas navigeerida. Seda mõistlikku teadmist edastatakse harva selgesõnaliselt, kuid mõistmine, kuidas mõistlikku teadmist esindatakse erinevates paradigmades, on oluline (a) inimese tunnetuse sügavamaks mõistmiseks ja (b) automaatsete arutlussüsteemide suurendamiseks. Käesolevas töös esitatakse põhjalik võrdlus kahe suuremahulise üldteadmiste ressursi vahel: ConceptNet, konstrueeritud relatsiooniandmebaas ja SWOW, teadmisgraafik, mis tuleneb rahvahulga sõnaseostest. Uurime kahe graafiku struktuuri, kattuvust ja erinevusi, samuti olukorra üldteadmiste ulatust kahes ressursis. Lõpuks näitame empiiriliselt, et mõlemad ressursid parandavad ülesannete tulemuslikkust järgnevate mõistlike arutlusnäitajate põhjal ainult tekstipõhiste lähtejoontega, mis viitavad sellele, et mitmete keelte kohta ühisallikate kaudu saadud suuremahulised sõnaseotud andmed võivad olla väärtuslikuks täienduseks kureeritud teadmisgraafikutele.', 'fi': 'Ihmiset käyttävät lukemattomia perustietoja maailmasta navigoidakseen tehokkaasti ympäristössään. Tätä järjetöntä tietoa harvoin välitetään nimenomaisesti, mutta ymmärrys siitä, miten järjetöntä tietoa esiintyy eri paradigmaissa, on tärkeää (a) syvemmälle ymmärrykselle ihmisen kognitiosta ja (b) automaattisten päättelyjärjestelmien lisäämiselle. Tässä artikkelissa vertaillaan perusteellisesti kahta laajaa yleistiedon resurssia: ConceptNet, suunniteltu relaatiotietokanta, ja SWOW, tietokaavio, joka on johdettu joukkolähteistä peräisin olevista sanayhdistyksistä. Tutkimme näiden kahden kaavion rakennetta, päällekkäisyyttä ja eroja sekä resursseissa esiintyvän tilannetieton laajuutta. Lopuksi osoitamme empiirisesti, että molemmat resurssit parantavat loppupään tehtävien suorituskykyä järkevän päättelyn vertailuarvoissa pelkkien tekstipohjaisten perusviivojen sijaan, mikä viittaa siihen, että monille kielille joukkohankinnan kautta saatu laajamittainen sanaassosiaatiodata voi olla arvokas täydennys kuratoiduille tietokaavioille.', 'he': 'בני אדם משתמשים בעובדות בסיסיות חסרות ספר על העולם כדי לנווט בצורה יעילה בסביבתם. הידע המפורסם הזה נדירות מתקשר באופן ברור, עם זאת, הבנה כיצד הידע המפורסם מוצג בפרדיגמות שונות חשוב ל (a) הבנה עמוקה יותר של הידע האנושי ו (b) מגדילה מערכות ההיגיון אוטומטיות. This paper presents an in-depth comparison of two large-scale resources of general knowledge: ConceptNet, an engineered relational database, and SWOW, a knowledge graph derived from crowd-sourced word associations.  אנו בודקים את המבנה, התכפילות וההבדלים בין שני הגרפים, כמו גם את המידע המקומי של הידע המשותף הנוכחי בשני המשאבים. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.', 'sk': 'Ljudje uporabljajo nešteto osnovnih dejstev o svetu za učinkovito navigacijo v svojem okolju. To splošno znanje se redko posreduje izrecno, vendar je razumevanje, kako je splošno znanje predstavljeno v različnih paradigmah, pomembno za (a) globlje razumevanje človeškega spoznanja in (b) povečanje avtomatskih sistemov razmišljanja. V prispevku je predstavljena poglobljena primerjava dveh obsežnih virov splošnega znanja: ConceptNet, konstruirana relacijska baza podatkov, in SWOW, graf znanja, pridobljen iz množičnih besednih asociacij. Preučujemo strukturo, prekrivanje in razlike med obema grafikonoma ter obseg razmišljanja, prisotnega v obeh virih. Na koncu empirično pokažemo, da oba vira izboljšujeta uspešnost opravil v nadaljnji verigi na podlagi referenčnih vrednosti za splošno razmišljanje nad osnovnimi vrsticami samo besedila, kar kaže, da so lahko obsežni podatki o združevanju besed, ki so bili pridobljeni za več jezikov prek množičnega vira, dragoceno dopolnilo urejenim grafom znanja.', 'bo': 'Humans use countless basic, shared facts about the world to efficiently navigate in their environment. སྤྱིར་བཏང་བའི་ཤེས་ཚོར་འདི་ཀྱང་དཀའ་ངལ་ཞིག་ཡིན་ནའང་། ཡིན་ནའང་། ཇི་འདྲ་བ་དེ་རང་ཉིད་ཀྱི་ཤེས་ཚོར་སྟོན་པའི་གྲངས་རིགས་སོ་སོའི་ནང་ནས་གལ་ཆེ་ཤོས་ This paper presents an in-depth comparison of two large-scale resources of general knowledge: ConceptNet, an engineered relational database, and SWOW, a knowledge graph derived from crowd-sourced word associations. ང་ཚོས་རྣམ་པ་གཉིས་དབར་གྱི་སྒྲིག་འགོད་དང་། དྲ་རིས་གཉིས་དབར་གྱི་ཁྱད་པར་དང་མཐུན་རྐྱེན་གྱི་གནས་སྟངས་ཤེས་ཀྱི་རྒྱུ་རྐྱེན་གཉིས་ནང ང་ཚོས་མཐའ་མཇུག་གི་རྒྱུ་དངོས་ཐོག་ལས་ཉུང་མཇུག་གི་ལས་འགན་འགྱུར་བ་ནི་ཕལ་ཐོག་ལས་ཀྱང་མཐོང་ནི་ཡིག་གེ་ཁོ་ན་དག་བཤད་པ་ཡིན།', 'ha': "Mutane sunã amfani da fakta masu bincike da bã da lissafa ba a cikin duniya dõmin su yi matafiya da mafiya kai a cikin muhimmarsu. Ana fahimtar da ilmi na kommuni da bayan bayani, kuma amma, ana fahimta jinsi da ake wakilisha ilmi a cikin paradigm daban-daban na da muhimu ga (a) fahimta mafi ƙaranci ga ganin mutum da (b) kuma yana ƙara wa'anar fassarar-bayan farat ɗaya. Wannan karatun na bãyar da wani masafa biyu masu girma wa ilmi: ConceptNet, an iya samar da masu inganci masu hushi, da SWOW, wata fassara na saniya daga mutane-sourced word associations. Munã jarraba bakin, dukka da sãɓãni a tsakanin grafyutan biyu, da tsakanin ma'anar masu sanki ga halin da ke cikin duk biyu. Ga ƙarshe Muke nuna marubuci cẽwa, ma'anar dukansu sun fi kyautata aikin aiki na ƙarami a kan kommunansa masu hankali da bangon matsayi masu bakin rubutun-bango kawai, Munã shawarar da cewa data masu girma da mutane masu haɗi da magana, wanda aka motsa wa masu cikin lugha ko da manyan-sourcen-mutane, za'a iya zama kammala mai kima ga kurated grafyuta na ilmi.", 'jv': 'Wong wong liya nggunakake kuwi cah-cah dumadhi, barang-barêng kuwi nggawe barang penggunaké dolanan sing bisa dianggap banjur Awakdhéwé éntuk iki dadi akeh basa dipun kesalakno nang ngerasakno, dadi, awakdhéwé kesempatan piye dipun ajeng ngregani apa (a) nggawe luwih basa awak dhéwé karo kesempatan wong liyane lan (b) ogwih sistem usahaan awak dhéwé. Perintah sing nggawe barang akeh dumaten kanggo nggawe kelas telas telas nang ngerasahan iki luwih dumaten punika ingkang dipunangé Awak dhéwé éntuk sistem, nggawe gerakan karo kalaayurakan ning sampeyan éwé graphifa iki, lan kabèh dhéwé kuwi tindakan kesempatan pangan iki. Awak dhéwé éntuk ngomong cara-cara sing luwih nêmên, wong kuwi tindakan hasil nêmên langkung nggawe gerarané nggawe gerarané perusahaan seneng nggawe sistem sing ruma nêmên, ndéwong-suarané perusahaan langkung sampeyan wigatining pasar dumaten, winih-suarané perusahaan kuwi nggawe gerarané perusahaan'}
{'en': 'Cross-document Event Identity via Dense Annotation', 'pt': 'Identidade de evento entre documentos por meio de anotação densa', 'es': 'Identidad de eventos de documentos cruzados mediante anotación densa', 'fr': "Identité d'événement entre documents via une annotation dense", 'ar': 'هوية حدث عبر المستندات عبر التعليقات التوضيحية الكثيفة', 'ja': '密度の高いアノテーションによるドキュメント間のイベント識別', 'zh': '密集批注成跨文档事', 'hi': 'घने एनोटेशन के माध्यम से क्रॉस-दस्तावेज़ ईवेंट पहचान', 'ru': 'Идентификация события кросс-документа через плотную аннотацию', 'ga': 'Aitheantas Imeachta Trasdhoiciméad trí Anótáil Dhian', 'ka': 'Name', 'hu': 'Dokumentumok közötti eseményazonosítás sűrű megjegyzéssel', 'el': 'Ταυτότητα συμβάντος μεταξύ εγγράφων μέσω πυκνής σημείωσης', 'it': "Identificazione dell'evento attraverso documenti incrociati tramite annotazione densa", 'mk': 'Cross-document Event Identity via Dense Annotation', 'kk': 'Құжаттың бірнеше оқиға идентификациясы Dense Annotation арқылы', 'lt': 'Tarpdokumentinis įvykio tapatybės nustatymas naudojant tankių pranešimus', 'ms': 'Identiti Peristiwa Salib-dokumen melalui Annotasi Dense', 'mt': 'Cross-document Event Identity via Dense Annotation', 'mn': 'Хэрэглэгч баримт үйл явдлын тодорхойлолт Dense Annotation аргаар', 'ml': 'Cross-document Event Identity via Dense Annotation', 'no': 'Kryss- dokument- hendingsdidentitet via Dense- notasjon', 'pl': 'Tożsamość zdarzeń między dokumentami za pomocą gęstej adnotacji', 'ro': 'Identitatea evenimentului încrucișată cu ajutorul adnotării dense', 'sr': 'Identiteta događaja preko Dense Annotation', 'si': 'Name', 'so': 'Aqoonsiga dhacdooyinka iskuulka', 'sv': 'Cross-document händelseidentitet via täta noteringar', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Ghi chú đại sự kiện qua mật báo', 'bg': 'Идентичност на събитието чрез плътна анотация', 'nl': 'Documentoverschrijdende gebeurtenisidentiteit via dichte annotatie', 'da': 'Krydsdokument begivenhedsidentitet via tæt notering', 'hr': 'Identiteta događaja preko Denske Annotacije', 'de': 'Dokumentübergreifende Ereignisidentität über dichte Anmerkungen', 'id': 'Identitas peristiwa saling dokumen melalui Annotasi Dense', 'fa': 'شناسایی رویداد عبور سند', 'ko': '밀집된 주석을 통해 여러 문서 이벤트 표식', 'sw': 'Utambulisho wa Tukio la Kusini kupitia Tamko la Dense', 'tr': '_Senedler', 'af': 'Name', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'Dense Annotation vasitəsilə Xəta Döyüşə Görüş Kimliği', 'hy': 'Comment', 'bn': 'ডেন্স বিজ্ঞাপনের মাধ্যমে ক্রস-নথি ইভেন্ট পরিচয়', 'bs': 'Identiteta događaja preko Denske Annotacije', 'ca': "Identitat d'eventos en documentos múltiples a través d'anotació densa", 'cs': 'Identita událostí mezi dokumenty prostřednictvím husté anotace', 'et': 'Dokumentidevaheline sündmuse identiteet tiheda annotatsiooni abil', 'fi': 'Asiakirjojen välinen tapahtumaidentiteetti tiheän merkinnän avulla', 'sq': 'Identiteti i Eventit në mes të dokumentit nëpërmjet Anotacionit Dense', 'ha': "Masana'antar duk takardan aiki na KCharselect unicode block name", 'jv': 'structural navigation', 'sk': 'Identiteta dogodka med dokumenti z gostimi opombami', 'he': 'זהות אירוע בצד מסמך באמצעות הערות', 'bo': 'དྲན་འཛུགས་ཀྱི་འགྲེལ་བཤད་དང་བསྟུན་ནས་ཡིག་ཆ་རམ་པའི་འབྱུང་སྟངས་དང་འབྲེལ་བ'}
{'en': 'In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the  annotations  to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between  identity decisions  and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.', 'ar': 'في هذه الورقة ، ندرس هوية الأحداث النصية من وثائق مختلفة. بينما تمت دراسة الطبيعة المعقدة لهوية الحدث مسبقًا (Hovy et al. ، 2013) ، فإن حالة الأحداث عبر المستندات غير واضحة. العمل المسبق على مرجع أحداث المستند المتقاطع له عيبان رئيسيان. أولاً ، يقصرون التعليقات التوضيحية على مجموعة محدودة من أنواع الأحداث. ثانيًا ، لم يتعاملوا بشكل كافٍ مع مفهوم هوية الحدث. يقلل إعداد التعليق التوضيحي من مجموعة إشارات الأحداث ويمنع المرء من النظر في إمكانية وجود علاقات شبه هوية. نقترح نهجًا مكثفًا للشرح التوضيحي لإثبات مرجعية الأحداث عبر المستندات ، والذي يشتمل على مصدر غني للإشارات إلى الأحداث وجهد توضيحي مكثف بين أزواج المستندات ذات الصلة. تحقيقا لهذه الغاية ، نقوم بتصميم سير عمل التعليقات التوضيحية الجديدة مع مراقبة الجودة بعناية وواجهة تعليقات توضيحية سهلة الاستخدام. بالإضافة إلى الروابط ، نقوم أيضًا بجمع سياقات الأحداث المتداخلة ، بما في ذلك الوقت والموقع والمشاركين ، لإلقاء بعض الضوء على العلاقة بين قرارات الهوية والسياق. نقدم مجموعة بيانات مفتوحة الوصول لمرجع حدث عبر المستندات ، CDEC-WN ، تم جمعها من Wikinews الإنجليزية ومجموعة أدوات التعليقات التوضيحية مفتوحة المصدر لتشجيع المزيد من البحث حول مهام التوثيق المتقاطع.', 'pt': 'Neste artigo, estudamos a identidade de eventos textuais de diferentes documentos. Embora a natureza complexa da identidade do evento seja estudada anteriormente (Hovy et al., 2013), o caso de eventos entre documentos não é claro. O trabalho anterior na correferência de eventos entre documentos tem duas desvantagens principais. Primeiro, eles restringem as anotações a um conjunto limitado de tipos de eventos. Em segundo lugar, eles abordam insuficientemente o conceito de identidade do evento. Essa configuração de anotação reduz o conjunto de menções de eventos e impede que se considere a possibilidade de relações de quase identidade. Propomos uma abordagem de anotação densa para correferência de eventos entre documentos, compreendendo uma rica fonte de menções de eventos e um esforço de anotação denso entre pares de documentos relacionados. Para isso, projetamos um novo fluxo de trabalho de anotação com controle de qualidade cuidadoso e uma interface de anotação fácil de usar. Além dos links, também coletamos contextos de eventos sobrepostos, incluindo tempo, local e participantes, para esclarecer a relação entre as decisões de identidade e o contexto. Apresentamos um conjunto de dados de acesso aberto para correferência de eventos entre documentos, CDEC-WN, coletados do Wikinews em inglês e nosso kit de ferramentas de anotação de código aberto para incentivar pesquisas adicionais sobre tarefas entre documentos.', 'es': 'En este artículo, estudiamos la identidad de los eventos textuales de diferentes documentos. Si bien la naturaleza compleja de la identidad de los eventos se ha estudiado previamente (Hovy et al., 2013), el caso de los eventos en los documentos no está claro. El trabajo previo sobre la correferencia de eventos de documentos cruzados tiene dos inconvenientes principales. En primer lugar, restringen las anotaciones a un conjunto limitado de tipos de eventos. En segundo lugar, abordan de manera insuficiente el concepto de identidad del evento. Esta configuración de anotación reduce el conjunto de menciones de eventos y evita que se considere la posibilidad de relaciones de cuasiidentidad. Proponemos un enfoque de anotación densa para la correferencia de eventos entre documentos, que comprende una rica fuente de menciones de eventos y un esfuerzo de anotación denso entre pares de documentos relacionados. Con este fin, diseñamos un nuevo flujo de trabajo de anotación con un control de calidad cuidadoso y una interfaz de anotación fácil de usar. Además de los enlaces, recopilamos contextos de eventos superpuestos, incluidos la hora, el lugar y los participantes, para arrojar algo de luz sobre la relación entre las decisiones de identidad y el contexto. Presentamos un conjunto de datos de acceso abierto para la correferencia de eventos entre documentos, CDEC-WN, recopilados de Wikinews en inglés y nuestro kit de herramientas de anotación de código abierto para fomentar la investigación adicional sobre las tareas de documentos cruzados.', 'fr': "Dans cet article, nous étudions l'identité des événements textuels de différents documents. Bien que la nature complexe de l'identité de l'événement ait déjà fait l'objet d'études (Hovy et al., 2013), le cas des événements dans les documents n'est pas clair. Les travaux antérieurs sur la coréférence d'événements entre documents présentent deux inconvénients principaux. Tout d'abord, ils limitent les annotations à un ensemble limité de types d'événements. Deuxièmement, ils n'abordent pas suffisamment le concept d'identité d'événement. Une telle configuration d'annotation réduit le nombre de mentions d'événements et empêche d'envisager la possibilité de relations de quasi-identité. Nous proposons une approche d'annotation dense pour la coréférence d'événements entre documents, comprenant une source riche de mentions d'événements et un effort d'annotation dense entre les paires de documents connexes. À cette fin, nous concevons un nouveau flux de travail d'annotation avec un contrôle qualité minutieux et une interface d'annotation facile à utiliser. En plus des liens, nous collectons également les contextes d'événements qui se chevauchent, y compris l'heure, le lieu et les participants, afin de faire la lumière sur la relation entre les décisions relatives à l'identité et le contexte. Nous présentons un jeu de données en libre accès pour la coréférence d'événements entre documents, CDEC-WN, collecté auprès de Wikinews anglais et notre boîte à outils d'annotation open source pour encourager la poursuite des recherches sur les tâches inter-documents.", 'ja': '本稿では、異なる文書からのテキストイベントのアイデンティティを研究する。 事象同一性の複雑な性質が以前に研究されているが（ Hovy et al., 2013 ）、文書全体の事象の事例は不明である。 クロスドキュメントイベントコアレフィケーションの先行作業には、2つの主な欠点があります。 まず、注釈をイベントタイプの限られたセットに制限します。 第二に、彼らはイベントアイデンティティの概念に十分に取り組んでいない。 このようなアノテーション設定は、イベント言及のプールを減らし、準同一性関係の可能性を考慮することを妨げる。 私たちは、ドキュメント間のイベントコアリファレンスのための濃密な注釈アプローチを提案します。これには、豊富なイベントメンションのソースと、関連するドキュメントペア間の濃密な注釈の取り組みが含まれます。 そのために、慎重な品質管理と使いやすいアノテーションインターフェイスを備えた新しいアノテーションワークフローを設計しています。 リンクに加えて、時間、場所、参加者を含む重複するイベントコンテキストを収集し、アイデンティティの決定とコンテキストの関係を明らかにします。 私たちは、クロスドキュメントイベントコアレファレンスのためのオープンアクセスデータセット、英語のWikinewsから収集されたCDEC - WNと、クロスドキュメントタスクのさらなる研究を奨励するためのオープンソースのアノテーションツールキットを提示します。', 'hi': 'इस पेपर में, हम विभिन्न दस्तावेजों से पाठ्य घटनाओं की पहचान का अध्ययन करते हैं। जबकि घटना की पहचान की जटिल प्रकृति का पहले अध्ययन किया गया है (होवी एट अल। क्रॉस-दस्तावेज़ ईवेंट कोरेफेरेंस पर पहले के काम में दो मुख्य कमियां हैं। सबसे पहले, वे एनोटेशन को ईवेंट प्रकारों के सीमित सेट तक सीमित करते हैं। दूसरा, वे अपर्याप्त रूप से घटना पहचान की अवधारणा से निपटते हैं। इस तरह के एनोटेशन सेटअप घटना उल्लेख के पूल को कम कर देता है और अर्ध-पहचान संबंधों की संभावना पर विचार करने से रोकता है। हम क्रॉस-दस्तावेज़ ईवेंट कोरेफेरेंस के लिए एक घने एनोटेशन दृष्टिकोण का प्रस्ताव करते हैं, जिसमें घटना के उल्लेख का एक समृद्ध स्रोत और संबंधित दस्तावेज़ जोड़े के बीच एक घने एनोटेशन प्रयास शामिल हैं। इस अंत के लिए, हम सावधानीपूर्वक गुणवत्ता नियंत्रण और एक आसान-से-उपयोग एनोटेशन इंटरफ़ेस के साथ एक नया एनोटेशन वर्कफ़्लो डिज़ाइन करते हैं। लिंक के अलावा, हम पहचान निर्णयों और संदर्भ के बीच संबंधों पर कुछ प्रकाश डालने के लिए समय, स्थान और प्रतिभागियों सहित अतिव्यापी घटना संदर्भों को आगे बढ़ाते हैं। हम क्रॉस-डॉक्यूमेंट ईवेंट कोरेफेरेंस, सीडीईसी-डब्ल्यूएन के लिए एक ओपन-एक्सेस डेटासेट प्रस्तुत करते हैं, जो अंग्रेजी विकिसमाचार से एकत्र किया गया है और क्रॉस-डॉक्यूमेंट कार्यों पर आगे के शोध को प्रोत्साहित करने के लिए हमारे एनोटेशन टूलकिट को ओपन-सोर्स करता है।', 'zh': '本文之中,究其异文档。 虽前治杂(Hovy等,2013),而跨文档未详。 前跨文档事共引有二短。 先之,以批注限为事。 其次,不尽其事。 此注设减事提及池,并防人思准之性。 臣等条上跨文档事协推理之密注,兼备源流文档密注之。 为设新注流程,有细质制易用之注界面。 自链接之外,更集重叠之上下文,日月地参与者,以明决策上下文之间。 臣等条上跨文档事共征开访数集CDEC-WN,当数集从英语维基新闻中,并开源注工具包,以劝跨文档。', 'ru': 'В данной работе мы изучаем идентичность текстовых событий из разных документов. Хотя сложный характер идентичности событий изучался ранее (Hovy et al., 2013), случай событий в документах неясен. Предыдущая работа над междокументарным ядром событий имеет два основных недостатка. Во-первых, они ограничивают аннотации ограниченным набором типов событий. Во-вторых, они недостаточно учитывают концепцию идентичности событий. Такая настройка аннотаций уменьшает пул упоминаний событий и не позволяет рассмотреть возможность квазиидентичных отношений. Мы предлагаем подход плотной аннотации для междокументарной ядра события, включающий богатый источник упоминаний событий и плотную аннотацию усилий между соответствующими парами документов. Для этого мы разрабатываем новый рабочий процесс аннотации с тщательным контролем качества и простым в использовании интерфейсом аннотации. В дополнение к связям, мы также собираем перекрывающиеся контексты событий, включая время, место и участников, чтобы пролить свет на связь между решениями об идентичности и контекстом. Мы представляем открытый доступ к набору данных для междокументарного ядра событий, CDEC-WN, собранный из английской Wikinews и нашего инструментария аннотации с открытым исходным кодом для поощрения дальнейших исследований по кросс-документарным задачам.', 'ga': 'Sa pháipéar seo, déanaimid staidéar ar chéannacht imeachtaí téacsúla ó dhoiciméid éagsúla. Cé go ndéantar staidéar ar nádúr casta céannacht imeachtaí roimhe seo (Hovy et al., 2013), ní léir cás na n-imeachtaí trasna doiciméad. Tá dhá phríomh-mhíbhuntáiste ag baint le réamhobair ar chroílár imeachtaí trasdoiciméid. Ar an gcéad dul síos, cuireann siad srian ar na nótaí go sraith teoranta de chineálacha imeachtaí. Ar an dara dul síos, ní théann siad i ngleic go leordhóthanach le coincheap na féiniúlachta imeachta. Laghdaíonn socrú anótála den sórt sin líon na gcuairteanna ócáidí agus cuireann sé cosc ar dhuine an fhéidearthacht a bhaineann le caidreamh cuas-aitheantais a mheas. Molaimid cur chuige dlúithe nótaí le haghaidh croí-chomhdhála imeachtaí trasdoiciméid, a chuimseoidh foinse shaibhir tagairtí imeachta agus dianiarracht nótaí idir péirí doiciméad gaolmhar. Chuige sin, dearaimid sreabhadh oibre nótaí nua le rialú cáilíochta cúramach agus comhéadan nótaí atá éasca le húsáid. Chomh maith leis na naisc, bailímid tuilleadh comhthéacsanna imeachtaí forluiteacha, lena n-áirítear am, suíomh, agus rannpháirtithe, chun léargas a thabhairt ar an ngaol idir cinntí aitheantais agus comhthéacs. Cuirimid i láthair tacar sonraí rochtana oscailte le haghaidh croíchomhdhála imeachtaí trasdoiciméad, CDEC-WN, a bhailítear ó English Wikinews agus foinse oscailte ár bhfoireann uirlisí nótaí chun tuilleadh taighde a spreagadh ar thascanna trasdoiciméid.', 'hu': 'Ebben a tanulmányban különböző dokumentumokból származó szöveges események identitását vizsgáljuk. Míg az eseményidentitás komplex jellegét korábban tanulmányozták (Hovy et al., 2013), az események esete a dokumentumok között nem világos. A keresztdokumentumok közötti eseménycoreferenciával kapcsolatos előzetes munkáknak két fő hátránya van. Először is, a jegyzetek korlátozott eseménytípusokra korlátozódnak. Másodszor, nem kezelik megfelelően az eseményidentitás fogalmát. Az ilyen megjegyzések beállítása csökkenti az eseményemlítések állományát és megakadályozza, hogy figyelembe vegye a kvázi-identitás kapcsolatok lehetőségét. Javasoljuk a keresztdokumentumok eseménycoreferenciájának sűrű jegyzetelési megközelítését, amely magában foglalja az eseményemlítések gazdag forrását és a kapcsolódó dokumentumpárok közötti sűrű jegyzetelési erőfeszítést. Ennek érdekében új jegyzetelési munkafolyamatot tervezünk gondos minőségellenőrzéssel és egy könnyen használható jegyzetelési felülettel. A linkek mellett egymást átfedő eseménykontextusokat is gyűjtünk, beleértve az időt, a helyszínt és a résztvevőket, hogy megvilágítsuk az identitási döntések és a kontextus közötti kapcsolatot. Bemutatunk egy nyílt hozzáférésű adatkészletet a keresztdokumentumok eseménycoreferenciájához, a CDEC-WN-hez, amelyet az angol Wikinews-től gyűjtöttünk össze, és nyílt forráskódú jegyzetkészletünket, hogy ösztönözzük a keresztdokumentumok feladatainak további kutatását.', 'ka': 'ამ დოკუმენტში, ჩვენ ტექსტური მოვლენების განსხვავებული დოკუმენტების იდენტიფიკაციას ვისწავლით. თუმცა მოვლენების იდენტიფიკაციის კომპლექსი ნათობა წინ მოსწავლია (Hovy et al., 2013), მოვლენების შემთხვევაში დოკუმენტების შემთხვევაში არ უცნობი. პირველი სამუშაო მრავალე დოკუმენტის მოვლენების შესაძლებლობა აქვს ორი მნიშვნელოვანი დაკავშირება. პირველად, ისინი მოვლენის ტიპების დასაზღვრებულება. მეორე, ისინი არაფექტიურად მოვლენების იდენტიფიკაციის კონფიგურაციას გააკეთებენ. ასეთი მონიტაციის შესაძლებლობა მოვლენების ბასონის გადასრულება და გადახმარება ერთი კვასი-იდენტიფიკაციის შესაძლებლობას. ჩვენ გვეძლევა კონტაქტის კონტაქტიური მოვლენების კონტრექციის გასაკეთებლად, რომლებიც მოვლენების ბედნიერი მსოფლიოს გამოსახულება და დაკავშირებული დოკუმენტის კონტ ამ მიზეზით, ჩვენ ახალი ანტორაციის სამუშაო გამოყენება ახალი ანტორაციის კონტროლისთვის და მართლად გამოყენებელი ანტორაციის ინტერფექტისთვის დავ დამატებით, ჩვენ კონტექსტის შესახებ კონტექსტის დამატებით, რომელიც დრო, ადგილება და დაწყვეტებელი, დავიყენებთ განსხვავებული განსხვავებას და კონტექსტის განსხვავებას,  ჩვენ აჩვენებთ გახსნილი მონაცემების კონტაქტის მონაცემების შესახებ CDEC-WN, რომელიც ანგლისური ვიკინუტების და გახსნილი ფოსტიდან ჩვენი მონაცემების მონაცემების კონტაქტის კონტაქტი', 'kk': 'Бұл қағазда біз әртүрлі құжаттардан мәтін оқиғалардың идентификациясын зерттейміз. Оқиға идентификациясының комплексті қасиеті алдында (Hovy et al., 2013), құжаттардың арасындағы оқиғалардың әдісі білмейді. Құжатты бірнеше құжатты оқиғалардың қасиеттерінің алдындағы жұмысының екі негізгі жолы бар. Біріншіден, олар жазбаларды оқиға түрлеріне шектелген жиынға шектеп береді. Екіншіден, олар оқиға идентификациясының концепциясын жеткілікті емес. Бұл жазбаларды баптау оқиғалардың жазбаларының бірін квази- идентификациялық қатынастарының мүмкіндігін еске салуға болмайды. Біз құжаттың көпшілік оқиғалардың қасиеттері үшін тұрақтық жазбалардың қасиеттерін және қосылған құжаттың екі арасындағы тұрақтық жазбалардың көзі бар. Бұл соңында, біз жаңа жазбалар жұмысын сапатты басқару мен оңай қолданылатын жазбалар интерфейсін құрамыз. Сілтемелердің қосымша, біз оқиғалардың көптеген тәртіптерін, уақыт, орналасуы және қатысушылардың арасындағы сілтемелердің қатынасын жарықтыру үшін бірнеше жарықтығын жинақтаймыз. Ағылшын Викиновесінен және ашық көзгерту құжаттардың тапсырмаларын зерттеу үшін ашық қатынау деректер жиынын таңдаймыз.', 'el': 'Στην παρούσα εργασία μελετάμε την ταυτότητα κειμένων γεγονότων από διάφορα έγγραφα. Ενώ η πολύπλοκη φύση της ταυτότητας γεγονότων έχει μελετηθεί προηγουμένως (κ.α., 2013), η περίπτωση συμβάντων σε έγγραφα είναι ασαφής. Οι προηγούμενες εργασίες σχετικά με τη συνάφεια συμβάντων μεταξύ εγγράφων έχουν δύο κύρια μειονεκτήματα. Πρώτον, περιορίζουν τα σχόλια σε ένα περιορισμένο σύνολο τύπων συμβάντων. Δεύτερον, αντιμετωπίζουν ανεπαρκώς την έννοια της ταυτότητας γεγονότων. Μια τέτοια ρύθμιση σχολιασμού μειώνει τη συγκέντρωση αναφορών γεγονότων και εμποδίζει κάποιον να εξετάσει τη δυνατότητα σχετιζόμενων σχέσεων ταυτότητας. Προτείνουμε μια πυκνή προσέγγιση σχολιασμού για τη συνάφεια συμβάντων μεταξύ εγγράφων, που περιλαμβάνει μια πλούσια πηγή αναφορών συμβάντων και μια πυκνή προσπάθεια σχολιασμού μεταξύ σχετικών ζευγαριών εγγράφων. Για το σκοπό αυτό, σχεδιάζουμε μια νέα ροή εργασίας σχολιασμού με προσεκτικό ποιοτικό έλεγχο και μια εύχρηστη διεπαφή σχολιασμού. Εκτός από τους συνδέσμους, συλλέγουμε περαιτέρω επικαλυπτόμενα πλαίσια γεγονότων, συμπεριλαμβανομένου του χρόνου, του τόπου και των συμμετεχόντων, για να ρίξουμε λίγο φως στη σχέση μεταξύ αποφάσεων ταυτότητας και πλαισίου. Παρουσιάζουμε ένα σύνολο δεδομένων ανοικτής πρόσβασης για τη συγχορήγηση συμβάντων μεταξύ εγγράφων, που συλλέγονται από τα Αγγλικά Βικινέα και ανοιχτού κώδικα το εργαλείο σχολιασμού μας για να ενθαρρύνουμε περαιτέρω έρευνα σε εργασίες μεταξύ εγγράφων.', 'lt': 'Šiame dokumente tiriame tekstinių įvykių tapatybę iš skirtingų dokumentų. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear.  Prior work on cross-document event coreference has two main drawbacks.  First, they restrict the annotations to a limited set of event types.  Antra, jos nepakankamai atsižvelgia į įvykio tapatybės sąvoką. Toks anotacijos nustatymas sumažina renginių paminėjimų grupę ir neleidžia apsvarstyti galimybių palaikyti kvazitapatybės santykius. Siūlome griežtą įvairių dokumentų renginių koreferencijos anotacijos metodą, apimantį daug renginių paminėjimų šaltinio ir griežtas susijusių dokumentų poros anotacijos pastangas. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface.  Be ryšių, mes toliau renkame sutampančias renginių aplinkybes, įskaitant laiką, vietą ir dalyvius, kad išryškintume asmens tapatybės sprendimų ir kontekstų santykį. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.', 'it': "In questo articolo, studiamo l'identità di eventi testuali provenienti da diversi documenti. Mentre la natura complessa dell'identità degli eventi è stata precedentemente studiata (Hovy et al., 2013), il caso degli eventi tra i documenti non è chiaro. Il lavoro precedente sulla correferenza di eventi tra documenti incrociati presenta due principali svantaggi. In primo luogo, limitano le annotazioni a un insieme limitato di tipi di eventi. In secondo luogo, non affrontano sufficientemente il concetto di identità degli eventi. Tale impostazione di annotazione riduce il pool di menzioni di eventi e impedisce di considerare la possibilità di relazioni quasi-identitarie. Proponiamo un approccio denso di annotazione per la coreferenza di eventi cross-document, comprendente una ricca fonte di menzioni di eventi e un denso sforzo di annotazione tra coppie di documenti correlati. A tal fine, progettiamo un nuovo flusso di lavoro di annotazione con un attento controllo qualità e un'interfaccia di annotazione facile da usare. Oltre ai link, raccogliamo anche contesti di eventi sovrapposti, tra cui tempo, luogo e partecipanti, per fare luce sulla relazione tra decisioni identitarie e contesto. Presentiamo un set di dati ad accesso aperto per la correferenza di eventi cross-document, CDEC-WN, raccolto da Wikinews in inglese e il nostro toolkit di annotazione open source per incoraggiare ulteriori ricerche sulle attività cross-document.", 'mk': 'In this paper, we study the identity of textual events from different documents.  Иако комплексната природа на идентитетот на настаните претходно е проучена (Hovy и други, 2013), случајот на настаните низ документите не е јасен. Prior work on cross-document event coreference has two main drawbacks.  Прво, ги ограничуваат анотациите на ограничени типови на настани. Second, they insufficiently tackle the concept of event identity.  Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations.  We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs.  За ова, дизајнираме нов тек на анотации со внимателна контрола на квалитетот и лесно употребен интерфејс на анотации. Покрај врските, понатаму собираме контекстни настани, вклучувајќи го и времето, локацијата и учесниците, за да објасниме врска помеѓу одлуките за идентитет и контекстот. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.', 'ms': 'Dalam kertas ini, kami mempelajari identiti peristiwa teks dari dokumen yang berbeza. Sementara sifat kompleks identiti peristiwa telah dipelajari sebelumnya (Hovy et al., 2013), kes peristiwa di seluruh dokumen tidak jelas. Kerja sebelumnya pada persamaan peristiwa saling dokumen mempunyai dua kelemahan utama. Pertama, mereka sempadan anotasi kepada set terbatas jenis peristiwa. Second, they insufficiently tackle the concept of event identity.  Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations.  Kami cadangkan pendekatan anotasi padat untuk persamaan peristiwa saling dokumen, yang mengandungi sumber yang kaya sebutan peristiwa dan usaha anotasi padat antara pasangan dokumen berkaitan. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface.  In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between identity decisions and context.  Kami perkenalkan set data akses terbuka untuk persamaan peristiwa saling dokumen, CDEC-WN, dikumpulkan dari Wikinews Inggeris dan sumber terbuka alat anotasi kami untuk mendorong kajian lanjut mengenai tugas saling dokumen.', 'ml': 'ഈ പത്രത്തില്\u200d വ്യത്യസ്ത രേഖകളില്\u200d നിന്നും ടെക്സ്ചുല്\u200d സംഭവിക്കുന്ന സംഭവങ്ങളുടെ ഐച്ഛികം ഞങ്ങള സംഭവിക്കുന്നതിന്റെ സ്വഭാവം മുമ്പ് പഠിക്കപ്പെട്ടിരിക്കുമ്പോള്\u200d (ഹോവി et al., 2013) എല്ലാ രേഖകളിലും സംഭവിച്ചിരിക ക്രിസ്റ്റോക്കേഷന്\u200d സംഭവിക്കുന്ന കോര്\u200dഫെന്\u200dസില്\u200d മുമ്പ് ജോലി രണ്ടു പ്രധാനപ്പെട്ട വരയ്ക ആദ്യം, അവർ സംഭവിക്കുന്ന ഒരു പരിധികളുടെ തരത്തിലേക്ക് അഭിപ്രായകങ്ങളെ നിര്\u200dബന്ധിക്കുന്നു. രണ്ടാമത്തേത്, അവർ സംഭവിക്കുന്നതിന്റെ ഐച്ഛികം തീരുമാനിക്കുന്നില്ല. ഇങ്ങനെയുള്ള അഭിപ്രായശ്ചിത്രത്തിന്റെ സംസാരത്തിന്റെ പൂള്\u200d കുറയ്ക്കുന്നു. ക്വാസി ഐച്ഛിക ബന്ധങ്ങളുടെ സാധ ക്രിസ്റ്റ് രേഖയുടെ കോര്\u200dഫെന്\u200dസിന്റെ കൂട്ടത്തില്\u200d നിന്നും നമ്മള്\u200d ഒരു കൂടുതല്\u200d അഭിപ്രായശ്ചിത്തം പ്രായശ്ചിത്തമാക്കുന ഈ അവസാനത്തിനുള്ളില്\u200d, സൂക്ഷ്മതയുള്ള നിയന്ത്രണത്തോടും ഉപയോഗിക്കാന്\u200d എളുപ്പമുള്ള വിവരങ്ങള്\u200dക്കുമുള്ള ഒരു പു ലിങ്കുകള്\u200d കൂടാതെ, സമയം, സ്ഥലം, പങ്കാളികളുമുള്ള സംഭവങ്ങള്\u200d പൂര്\u200dണ്ണമായി പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന് കൂടാതെ നമ്മള്\u200d കൂടുതല്\u200d പ്രശ്നമ ക്രിസ്റ്റ് രേഖപ്പെടുത്തുന്ന കോര്\u200dഫെന്\u200dസിന്റെ കോര്\u200dഫെന്\u200dസിനായി ഞങ്ങള്\u200d ഒരു തുറന്ന വിവരങ്ങള്\u200d കാണിച്ചുകൊടുക്കുന്നു. ഇംഗ്ലീഷ് വിക്വി', 'mt': "In this paper, we study the identity of textual events from different documents.  Filwaqt li n-natura kumplessa tal-identità tal-avveniment ġiet studjata qabel (Hovy et al., 2013), il-każ ta’ avvenimenti fid-dokumenti mhuwiex ċar. Il-ħidma preċedenti dwar il-koerenza bejn l-avvenimenti bejn id-dokumenti għandha żewġ nuqqasijiet ewlenin. L-ewwel nett, jirrestrinġu l-annotazzjonijiet għal sett limitat ta’ tipi ta’ avvenimenti. It-tieni nett, ma jindirizzawx biżżejjed il-kunċett ta’ identità tal-avvenimenti. Dan it-twaqqif ta’ annotazzjoni jnaqqas il-ġabra ta’ sejħiet għall-avvenimenti u jipprevjeni wieħed milli jikkunsidra l-possibbiltà ta’ relazzjonijiet kważi-identità. Aħna nipproponu approċċ dens ta' annotazzjoni għall-koreferenza bejn l-avvenimenti bejn id-dokumenti, li jinkludi sors għoli ta' sejħiet għall-avvenimenti u sforz dens ta' annotazzjoni bejn il-pari ta' dokumenti relatati. Għal dan il-għan, a ħna niddisinjaw fluss ta’ ħidma ġdid ta’ annotazzjoni b’kontroll ta’ kwalità bir-reqqa u interfaċilità ta’ annotazzjoni faċli biex tintuża. Minbarra r-rabtiet, aħna nġabru aktar kuntesti ta’ avvenimenti li jikkoinċidu, inkluż iż-żmien, il-post, u l-parteċipanti, biex nixfu ftit dawl fuq ir-relazzjoni bejn id-deċiżjonijiet ta’ identità u l-kuntest. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.", 'no': 'I denne papiret studerer vi identiteten til teksthendingar frå ulike dokument. Mens det komplekse naturen av hendingssidentet er tidlegare studiert (Hovy et al., 2013), er tilfellet for hendingar over dokument ukjent. Førre arbeid på kryssdokumenthendingsformasjon har to hovudtrekking. Først begrenser dei notasjonane til ei begrenset set av hendingstypar. Andre, dei har ikkje nok tilstrekkelig å løyse opphevet av hendingssidentet. Desse notasjonsoppsettet reduserer innstillingane for hendingar og hindrar ein til å gjera opp muligheten for kvasi- identitetforhold. Vi foreslår ein tett notasjonstilnærming for koreferanse for kryssdokumenthendingar, som inneheld ein rikk kjelde for hendingar og ein tett notasjonsforsøk mellom tilhøyrande dokumentpar. I denne slutten designerer vi eit nytt arbeidsfløys med forsiktig kvalitetkontroll og eit enkelt å bruka notasjonsgrensesnitt. I tillegg til lenkjene samler vi meir overlapping hendingskontekstar, inkludert tid, plassering og deltakarar, for å slå litt lys på forholdet mellom identitetbeslutningar og kontekst. Vi presenterer eit datasett for åpen-tilgang for koreferanse for kryssdokumenthendingar, CDEC-WN, samla frå engelsk Wikinews og åpen-kjelde vårt annotasjonsverktøy for å oppretta framtidige forskning om kryssdokumentoppgåver.', 'pl': 'W artykule badamy tożsamość zdarzeń tekstowych z różnych dokumentów. Podczas gdy złożony charakter tożsamości zdarzeń jest wcześniej badany (Hovy et al., 2013), przypadek zdarzeń w dokumentach jest niejasny. Wcześniejsze prace nad współreferencją zdarzeń między dokumentami mają dwie główne wady. Po pierwsze, ograniczają adnotacje do ograniczonego zestawu typów zdarzeń. Po drugie, niewystarczająco rozwiązują one koncepcję tożsamości zdarzeń. Taka konfiguracja adnotacji zmniejsza pulę wspomnień o zdarzeniach i uniemożliwia rozważanie możliwości relacji quasi-tożsamości. Proponujemy gęste podejście adnotacyjne dla współreferencji zdarzeń między dokumentami, obejmujące bogate źródło wzmianek zdarzeń i gęsty wysiłek adnotacyjny pomiędzy powiązanymi parami dokumentów. W tym celu projektujemy nowy przepływ adnotacji z uważną kontrolą jakości i łatwym w użyciu interfejsem adnotacji. Oprócz linków zbieramy również nakładające się konteksty wydarzeń, w tym czas, miejsce i uczestników, aby rzucić trochę światła na związek między decyzjami o tożsamości a kontekstem. Przedstawiamy otwarty zestaw danych dla współpracy wydarzeń między dokumentami CDEC-WN, zebrany z angielskiej Wikinews oraz open source nasz zestaw narzędzi adnotacyjnych, aby zachęcić do dalszych badań nad zadaniami między dokumentami.', 'ro': 'În această lucrare, studiem identitatea evenimentelor textuale din diferite documente. Deși natura complexă a identității evenimentului este studiată anterior (Hovy et al., 2013), cazul evenimentelor din documente este neclar. Lucrările anterioare privind corefența evenimentelor încrucișate au două dezavantaje principale. În primul rând, ele restricționează adnotările la un set limitat de tipuri de evenimente. În al doilea rând, acestea abordează insuficient conceptul de identitate a evenimentului. Astfel de setări de adnotare reduc rezerva mențiunilor de evenimente și împiedică persoana să ia în considerare posibilitatea unor relații cvasi-identitare. Propunem o abordare densă de adnotare pentru corefența evenimentelor cross-document, cuprinzând o sursă bogată de mențiuni de evenimente și un efort dens de adnotare între perechile de documente asociate. În acest scop, proiectăm un nou flux de lucru de adnotare cu un control atent al calității și o interfață de adnotare ușor de utilizat. Pe lângă link-uri, colectăm în continuare contexte de evenimente suprapuse, inclusiv timp, locație și participanți, pentru a pune o lumină asupra relației dintre deciziile de identitate și context. Vă prezentăm un set de date cu acces deschis pentru corefența evenimentelor încrucișate, CDEC-WN, colectat de la Wikinews în limba engleză și setul nostru de instrumente de adnotare open-source pentru a încuraja cercetarea suplimentară asupra sarcinilor încrucișate de documente.', 'si': 'මේ පැත්තට, අපි වෙනස් විදිහට පැත්තක් අවස්ථාවක් ගැන පරීක්ෂණය කරනවා. සම්පූර්ණයේ අනතුරු ස්වභාවිතාවය පස්සේ පරීක්ෂණය කරලා තියෙනවා නමුත් (Hovy et al., 2013), ලිපින්ත වලින් සිද්ධ ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරතිපත්ති දෙකක් තියෙනවා. මුලින්ම, ඔවුන් ප්\u200dරතිචාරයක් සීමාවිත විදිහට සීමාවිත විදිහට සීමාවෙන්න. දෙවෙනි විදියට, ඔවුන් සිද්ධ විදියට පරික්ෂා කරන්න බෑ. අනිවාර්ය සැකසුම් සම්බන්ධ වෙනුවෙන් සැකසුම් සම්බන්ධ වෙනුවෙන් පුළුවන් වෙනුවෙන් පුළුවන් වෙනුවෙන්  අපි ප්\u200dරශ්නයක් කරනවා විශිෂ්ට වැඩසටහන් වැඩසටහන් සම්බන්ධ වැඩසටහන් සඳහා විශිෂ්ට ප්\u200dරශ්නයක් සම්බන්ධ වෙන්න, ස මේ අවසානයෙන්, අපි අලුත් ප්\u200dරවේශනයක් විද්\u200dයාපනය කරන්නේ පරික්ෂාව පාලනය සහ ප්\u200dරවේශනයක් පාවිච්චි කරන්න සම්බන්ධය සමඟ, අපි තවත් ප්\u200dරමාණ විශ්වාස සම්බන්ධය සම්බන්ධයක් සම්බන්ධ කරනවා, වෙලාව, තැනය, සහ සම්බන්ධකාරීන්ට, අනත අපි ප්\u200dරවේශනයක් ප්\u200dරවේශනයක්, CDEC WN, ඉංග්\u200dරීසි විකිනුවර්ස් වලින් සහ ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් තියෙන්නේ. අපේ විකිනුවර', 'so': 'Warqaddan waxaynu ka baranaynaa aqoonsiga dhacdooyinka qoraalka oo ka yimid dukumentiyada kala duduwan. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear.  Prior work on cross-document event coreference has two main drawbacks.  Marka ugu horeysa waxay ku xadgudbaan noocyo cayiman ah. Second, waxay macaamiloon karaan fekerka aqoonsiga dhacdooyinka. Tan oo kale waxaa hoos u dhiga macluumaadka xaaladaha dhacda, wuxuuna ka hortagaa in laga fikiro suurtagalka xiriirka aqoonsiga. Waxaannu horumarinaynaa qaab aad u fudud oo ku saabsan sameynta dhacdooyinka dukumentiyada kala duduwan, kaas oo qabanaya nooc taajir ah oo ku saabsan xujooyinka dhacdooyinka iyo qalabka dhibaatada aad u adag oo u dhexaysa labada dukumenti ee la xiriira. Taas darteed waxaynu dhadhanaynaa safar cusub oo shaqo la xiriiro si taxadar leh iyo qaab fudud oo lagu isticmaalo isticmaalka xanaaq. Inta dheer xiriirka, waxaynu soo ururinnaa qoraalka dhacdooyinka oo kale, kuwaas oo ah waqti, meesha, iyo kuwa ka qayb qaata, si aan u fududayno xiriirka go’aanka aqoonsiga iyo qorsheynta. Waxaynu soo bandhignaa sawirada furan oo loo qorayo macluumaadka dhacdooyinka, CDEC-WN, oo laga soo ururiyey Ingiriis Wikinews iyo furan qalabka alaabtayada si aan u dhiirrigelino waxbarasho dheeraad ah oo ku saabsan shaqooyinka wargeyska.', 'sv': 'I denna uppsats studerar vi identiteten av texthändelser från olika dokument. Även om händelseidentitetens komplexitet har studerats tidigare (Hovy et al., 2013), är fallet med händelser över dokument oklart. Tidigare arbete med korsdokumentskareferens har två huvudsakliga nackdelar. För det första begränsar de kommentarerna till en begränsad uppsättning händelsetyper. För det andra angriper de inte tillräckligt begreppet händelseidentitet. Sådan anteckningsinställning minskar poolen av händelseomnämnanden och hindrar en från att överväga möjligheten av kvasi-identitetsrelationer. Vi föreslår ett tätt kommenteringstillvägagångssätt för korsdokument händelsekorreferens, som omfattar en rik källa till händelseomnämnanden och en tät kommenteringsinsats mellan relaterade dokumentpar. Därför utformar vi ett nytt arbetsflöde för anteckningar med noggrann kvalitetskontroll och ett lättanvänt anteckningsgränssnitt. Utöver länkarna samlar vi även in överlappande händelsesammanhang, inklusive tid, plats och deltagare, för att belysa relationen mellan identitetsbeslut och sammanhang. Vi presenterar en open-access datauppsättning för cross-document event coreference, CDEC-WN, insamlad från engelska Wikinews och öppen källkod vår anteckningsverktygslåda för att uppmuntra vidare forskning om cross-document uppgifter.', 'ta': 'இந்த காகிதத்தில், நாம் வேறு ஆவணங்களில் இருந்து நிகழ்வுகளின் அடையாளத்தை படிக்கிறோம். @ info: whatsthis முன்னிருப்பு ஆவண நிகழ்வு குறிப்பு மூலம் இரண்டு முக்கிய பின்னணி உள்ளது. முதலில், அவர்கள் அறிவிப்புகளை ஒரு வரையறை நிகழ்வு வகைகளுக்கு கட்டுப்படுத்துகிறார்கள். இரண்டாவது, அவர்கள் நிகழ்வு அடையாளத்தின் கருத்தை பொருத்துவதில்லை. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations.  நாம் ஒரு தூரமான அறிவிப்பு செயல்பாட்டை மாற்றுகிறது, ஒரு செயல்பாடு நிகழ்வு குறிப்பிடும் மூலம் மற்றும் தொடர்பு ஆவண ஜோடிகளுக்க இந்த முடிவிற்கு, நாம் ஒரு புதிய அறிவிப்பு வேலையை வடிவமைக்கிறோம். கவனமான தரம் கட்டுப்பாட்டுடன் மற்றும் எளிதா இணைப்புகளுக்கு மேலும், நேரம், இடத்தை மற்றும் பங்குகிறவர்களையும் கூட நிகழ்வு மீண்டும் மேலும் சேகரி நாங்கள் ஒரு திறந்த அணுகல் தகவல் அமைப்பை காண்பிக்கிறோம், CDEC-WN, ஆங்கிலத்திலிருந்து சேகரிக்கப்பட்டுள்ளது, மற்றும் திறக்கப்பட்ட அலங்கார கருவிப', 'sr': 'U ovom papiru proučavamo identitet tekstualnih događaja iz različitih dokumenta. Iako se ranije proučava kompleksna priroda identiteta događaja (Hovy et al., 2013), slučaj događaja kroz dokumente nije jasan. Prije posla o prikladnosti događaja preko dokumenta ima dve glavne nedostatke. Prvo, oni ograničavaju annotacije na ograničen set tipova događaja. Drugo, oni nedovoljno rješavaju koncept identiteta događaja. Takva napomena smanjuje bazen događaja koji spominje i sprečava jednog da razmotri mogućnost kvazi-identitetnih odnosa. Predlažemo gusti pristup annotacijama za pristojnost događaja u krsnom dokumentu, uključujući bogat izvor događaja koji spominje i gusti napor za annotaciju između povezanih parova dokumenta. Za taj cilj, dizajniramo novi tok rada za annotaciju sa pažljivom kontrolom kvalitete i lakom interfejsom za upotrebu annotacija. Pored veza, dalje sakupljamo kontekste preklapanja događaja, uključujući vrijeme, lokaciju i sudionike, kako bi se malo svjetlo o vezi između odluka o identitetu i konteksta. Predstavljamo komplet podataka otvorenog pristupa za pristojnost događaja preko dokumenta, CDEC-WN, okupljen iz engleskog Wikinews i otvorenog izvora, naš instrument za upotrebu daljnjih istraživanja o zadacima preko dokumenta.', 'mn': 'Энэ цаасан дээр бид өөр бичил баримтын текст үйл явдлыг судалдаг. Өмнө нь үйл явдлын тодорхойлолтын төвөгтэй байдлыг судалж байсан ч (Hovy et al., 2013), баримт дахь үйл явдлын тухай тодорхойгүй байдаг. Өмнөх бичсэн үйл явдлын тухай өмнөх ажил хоёр чухал халдвартай байдаг. Эхлээд, тэд тэмдэглэгдэхийг хоорондоо хязгаарлагддаг. Хоёрт, тэд үйл явдлын тодорхойлолтыг хангалттай зориулж чадахгүй. Ийм жагсаалт байгууллага нь үйл явдлын хэмжээсүүдийг багасгаж, нэгнийг квази-идентификацийн харилцааны боломжтой байдлыг анзаарах боломжтой болгодог. Бид бичсэн үйл явдлын тухай баян эх үүсвэр болон холбоотой баримт хоёр хоёр хоорондоо жигтэй анзаарлын тухай зөвхөн анзаарлын тухай санал болгож байна. Энэ төгсгөлд бид анзаарлах шинэ ажлын урсгал, ухаантай чанарын удирдах, ашиглах амархан анзаарлах интерфейс бүтээж байна. Харин холбоотой холбоотой холбоотой холбоотой холбоотой холбоотой, цаг, байр суурь болон оролцогчдын холбоотой холбоотой гэрлийг цуглуулдаг. Бид хэд хэдэн баримт үйл явдлын зөвшөөрөл, CDEC-WN болон Англи хэлний Wikinews болон нээлттэй эх үүсвэрээс цуглуулсан нээлттэй өгөгдлийн санг тайлбарлаж өгдөг.', 'ur': 'اس کاغذ میں، ہم مختلف سندментوں سے تفصیل حادثوں کی شناسیت پڑھتے ہیں۔ حاﻻنکہ اپنا پیچیدہ پیچیدہ تعبیر پہلے پڑھا جاتا ہے (Hovy et al., 2013), سندментوں کے درمیان حادثوں کا موقع معلوم نہیں ہے. کرسٹ سنیٹ ایڈیومٹ ایڈیونٹ کے مطابق پہلے کام دو main drawbacks ہیں. پہلی بار، انہوں نے اپنا اظہار ایک محدود سٹ کے لئے محدود کر دیا ہے. دوسرا، انہوں نے اتفاق پہچان کے منظور کو کافی تکلیف نہیں دی۔ اس طرح کی آواز سنائی کے ذریعے ذکر کے پائل کو کاٹ دیتی ہے اور کسی کو اس طرح سے منع کرتا ہے کہ چوڑی شناسی رابطہ کے امکانات کو سمجھ سکے۔ ہم ایک گہرے مضبوط مضبوط مضبوط حادثہ کے مطابق ایک مضبوط مضبوط مضبوط مضبوط طریقہ کی پیشنهاد کرتے ہیں، جو حادثہ کے ذکر کے ثروت منبع ہیں اور ایک گہرے مضبوط مضبوط مضبوط جفت کے درمیان ہے اس کے لئے ہم نے ایک نئی آہستہ آہستہ آہستہ آہستہ آہستہ اہستہ کی کنٹرول کے ساتھ ایک نئی آہستہ آہستہ آہستہ آہستہ آہستہ آہستہ آہستہ آہستہ آہستہ کارفل لینکس کے علاوہ، ہم اس سے زیادہ اورلپ پینگ ایڈینٹ کنٹکسٹس جمع کرتے ہیں، جیسے زمانہ، موقعیت، اور شرکت کرنے والوں کے ساتھ، جاننے کے فیصلے اور کنٹکسٹ کے درمیان رابطہ کے بارے میں کچھ نور نکالنے کے لئے۔ ہم مختلف دکھانے کے لئے ایک کھولی دسترسی ڈیٹ سٹ کو پیش کرتے ہیں، CDEC-WN، انگلیسی ویکینیوز سے جمع کیا گیا ہے اور ہمارے اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا انٹوریٹ تولکیٹ کرس-ڈیکوم', 'uz': "Bu hujjatda, biz texnologiya hodisalarning shaxsiyatini boshqa hujjatdan o'rganamiz. @ info: whatsthis Name Birinchi marta, hodisalarni cheksiz turli turlariga qaror qiladi. Ikkinchi so'zda ular hodisa shaxsiyatning fikrini qo'llashmaydi. Bu taʼrif tugmasi hodisa xususiyatlarini kichiklashtirish va qo'shish shaxsiyatlarini tasdiqlash imkoniyatini kuzatishga harakat qiladi. Biz qoʻllangan hujjatning boshqa shaklga oshirish xizmatlari uchun qiyin taʼminlov qilamiz, hodisa taʼminlovchi soʻzlarning chegarasi va bog'liq hujjat qoʻllari orasidagi chegara taʼminlovchi jarayonlarini qo'shish. Mana shu paytda, biz taqdim holatni boshqarish va foydalanish uchun oddiy interfeys bilan yangi taʼminlovchi ishlayotni nazarlashmiz. Bogʻlamalar bilan boshqa bogʻlamalar bilan, vaqt, manzil, bilan bogʻlanuvchi hodisalarni bir nechta ko'pchilik qilamiz. @ info: whatsthis", 'vi': 'Trong tờ giấy này, chúng tôi nghiên cứu danh tính các sự kiện văn bản từ các tài liệu khác nhau. Trong khi tính chất phức tạp của danh tính sự kiện được nghiên cứu trước đây (Hoy et al., thẩm tê), trường hợp các sự kiện liên quan trong tài liệu không rõ ràng. Công việc đầu tiên về sự kiện tài liệu chéo hạn hạn chế có hai trục trặc chính. Thứ nhất, họ hạn chế chú thích cho một tập tin các kiểu sự kiện có giới hạn. Thứ hai, họ không xử lý được khái niệm danh tính sự kiện. Thiết lập ghi chú kiểu này sẽ làm giảm tỷ lệ các sự kiện đề cập và cản trở khả năng quan hệ phân biệt danh tính. Chúng tôi đề nghị một phương pháp ghi chú dày đặc về sự kiện tài liệu chéo, gồm một nguồn đầy đủ các sự kiện đề cập và một độ chú ý dày đặc giữa các cặp tài liệu liên quan. Chúng tôi thiết kế một dòng ghi chú mới với một sự điều khiển chất lượng cẩn thận và một giao diện chú thích dễ dùng. Ngoài các liên kết, chúng tôi còn thu thập các địa điểm các sự kiện chồng chéo, bao gồm thời gian, địa điểm, và các diễn viên, để làm sáng tỏ quan hệ giữa các quyết định danh tính và ngữ cảnh. Chúng tôi giới thiệu một bộ dữ liệu truy cập mở cho sự kiện tài liệu chéo, hạn chót, CDO-WN, thu thập từ WikiLnews Anh và ban nguồn dụng cụ ghi chú của chúng tôi để khuyến khích nghiên cứu thêm về các công việc chéo tài liệu.', 'bg': 'В настоящата статия изследваме идентичността на текстови събития от различни документи. Докато сложният характер на идентичността на събитията е проучен преди това (Хови и др., 2013), случаят на събитията в документите е неясен. Предишната работа по кръстосаната документация среща два основни недостатъка. Първо, те ограничават анотациите до ограничен набор от типове събития. Второ, те недостатъчно се занимават с концепцията за идентичност на събитието. Такава настройка на анотацията намалява набора от споменавания на събития и пречи на човек да разгледа възможността за квазиидентичност отношения. Предлагаме подход на гъста анотация за кръстосана кореференция на събития, включващ богат източник на споменаване на събития и гъста анотация между свързани двойки документи. За тази цел проектираме нов работен поток за анотация с внимателен контрол на качеството и лесен за използване интерфейс за анотация. В допълнение към връзките, събираме и припокриващи се контексти на събития, включително време, местоположение и участници, за да хвърлим известна светлина върху връзката между решенията за идентичност и контекста. Представяме съвкупност от данни с отворен достъп за междудокументни събития, събрани от английския Уикинюз и нашия набор от инструменти за анотация с отворен код, за да насърчим по-нататъшни изследвания на задачите с междудокументни връзки.', 'da': 'I denne artikel undersøger vi identiteten af teksthændelser fra forskellige dokumenter. Mens den komplekse karakter af begivenheds identitet tidligere er undersøgt (Hovy et al., 2013), er tilfældet med begivenheder på tværs af dokumenter uklart. Forudgående arbejde med krydsdokument begivenhedskoreference har to vigtigste ulemper. For det første begrænser de anmærkningerne til et begrænset sæt af begivenhedstyper. For det andet behandler de ikke i tilstrækkelig grad begrebet begivenhedsidentitet. En sådan annotationsopsætning reducerer puljen af begivenhedsnævnelser og forhindrer en i at overveje muligheden for kvasi-identitetsrelationer. Vi foreslår en tæt annotationstilgang til korreference af hændelser på tværs af dokumenter, der omfatter en rig kilde til hændelsesnævnelser og en tæt annotationsindsats mellem relaterede dokumentpar. Til dette formål designer vi en ny annotationsarbejdsgang med omhyggelig kvalitetskontrol og en brugervenlig annotationsgrænseflade. Ud over linkene indsamler vi yderligere overlappende eventsammenhænge, herunder tid, sted og deltagere, for at kaste lys over forholdet mellem identitetsbeslutninger og kontekst. Vi præsenterer et open-access datasæt til cross-document event coreference, CDEC-WN, indsamlet fra engelsk Wikinews og open-source vores annoteringsværktøjssæt for at tilskynde til yderligere forskning i cross-document opgaver.', 'nl': 'In dit artikel bestuderen we de identiteit van tekstuele gebeurtenissen uit verschillende documenten. Hoewel de complexe aard van gebeurtenisidentiteit eerder is bestudeerd (Hovy et al., 2013), is het geval van gebeurtenissen in documenten onduidelijk. Voorafgaand werk aan coreferentie tussen documenten heeft twee grote nadelen. Ten eerste beperken ze de annotaties tot een beperkte set gebeurtenistypen. Ten tweede pakken ze onvoldoende het concept event identity aan. Een dergelijke annotatieopstelling vermindert de pool van gebeurtenisvermeldingen en voorkomt dat men de mogelijkheid van quasi-identiteitsrelaties overweegt. We stellen een dichte annotatiebenadering voor cross-document event coreference voor, bestaande uit een rijke bron van gebeurtenisvermeldingen en een dichte annotatie inspanning tussen verwante documentparen. Hiervoor ontwerpen we een nieuwe annotatie workflow met zorgvuldige kwaliteitscontrole en een gebruiksvriendelijke annotatie interface. Naast de links verzamelen we ook overlappende evenementcontexten, waaronder tijd, locatie en deelnemers, om wat licht te werpen op de relatie tussen identiteitsbeslissingen en context. We presenteren een open-access dataset voor cross-document event coreference, CDEC-WN, verzameld uit Engels Wikinews en open-source onze annotatie toolkit om verder onderzoek naar cross-document taken aan te moedigen.', 'hr': 'U ovom papiru proučavamo identitet tekstualnih događaja iz različitih dokumenta. Iako se ranije proučava kompleksna priroda identiteta događaja (Hovy et al., 2013), slučaj događaja kroz dokumente nije jasan. Prije posla o prikladnosti događaja u krsnom dokumentu ima dvije glavne nedostatke. Prvo, ograničavaju oznake na ograničeni skup vrsta događaja. Drugo, oni nedovoljno rješavaju koncept identiteta događaja. Takva uspostava za annotaciju smanjuje bazen događaja koji spominje i sprječava jednog da razmotri mogućnost kvazi-identitetnih odnosa. Predlažemo gusti pristup oznake za prikladnost događaja u krsnom dokumentu, uključujući bogati izvor događaja spominjanja i gusti napor oznake između povezanih par dokumenta. Za taj cilj, dizajniramo novi radni tok annotacije s pažljivom kontrolom kvalitete i lakom interfejsom za upotrebu annotacija. Pored veza, dalje sakupljamo kontekste preklapanja događaja, uključujući vrijeme, lokaciju i sudionike, kako bi se malo svjetlo o vezi između odluka o identitetu i konteksta. Predstavljamo komplet podataka otvorenog pristupa za pristojnost događaja preko dokumenta, CDEC-WN, prikupljen iz engleskih Wikinews i otvorenog izvora, naš instrument za upotrebu daljnjih istraživanja o zadatkima preko dokumenta.', 'fa': 'در این کاغذ، ما هویت اتفاقات متن را از مدارک مختلف مطالعه می کنیم. در حالی که طبیعت پیچیده هویت رویداد پیش از این مطالعه شده است (Hovy et al., 2013), پرونده رویداد در طول سند مشخص نیست. کارهای پیشینه روی رضایت حادثه\u200cهای مختلف سند دو کمک اصلی دارد. اول، آنها نشانه\u200cها را به مجموعه\u200cای از نوع\u200cهای حادثه محدود می\u200cکنند. دوم، آنها به اندازه کافی از نظر هویت رویداد حل نمی کنند. این تنظیمات نوشته\u200cها، استخره\u200cهای رویداد را کاهش می\u200cکند و مانع می\u200cکند که یکی از احتمال ارتباط\u200cهای کوسی هویت را در نظر بگیرد. ما پیشنهاد می\u200cکنیم یک روش اظهار تند برای رضایت حادثه\u200cهای مختلف سند، که شامل یک منبع ثروتمند حادثه\u200cها و تلاش اظهار تند بین جفت\u200cهای سند رابطه است. برای این قسمت، ما یک جریان نویسندگی جدید با کنترل کیفیت دقیق و یک ارتباط نویسندگی برای استفاده آسان طراحی می کنیم. در addition to the links, we further collect overlapping events contexts, including time, location and participants, to put some light on the relationship between identities decisions and context. ما یک مجموعه اطلاعات دسترسی باز برای رضایت حادثه\u200cهای مختلف سند، CDEC-WN، از ویکینویس انگلیسی و منبع باز برای تحقیقات بیشتری در مورد کار های مختلف سند جمع شده\u200cایم.', 'id': 'Dalam kertas ini, kami mempelajari identitas peristiwa teks dari dokumen yang berbeda. Sementara alam kompleks identitas peristiwa sebelumnya dipelajari (Hovy et al., 2013), kasus peristiwa di seluruh dokumen tidak jelas. Pekerjaan sebelumnya pada koreferensi peristiwa saling dokumen memiliki dua kelemahan utama. Pertama, mereka membatasi anotasi untuk set terbatas jenis peristiwa. Kedua, mereka tidak cukup mengatasi konsep identitas peristiwa. Pengaturan anotasi seperti ini mengurangi kolam cerita peristiwa dan mencegah seseorang mempertimbangkan kemungkinan hubungan quasi-identitas. Kami mengusulkan pendekatan anotasi padat untuk persamaan peristiwa saling dokumen, yang mengandung sumber yang kaya cerita peristiwa dan usaha anotasi padat antara pasangan dokumen berkaitan. Untuk tujuan ini, kami merancang aliran kerja anotasi baru dengan kendali kualitas hati-hati dan antaramuka anotasi mudah digunakan. Selain hubungan, kita lebih lanjut mengumpulkan konteks peristiwa yang saling bertindak, termasuk waktu, lokasi, dan peserta, untuk memberi cahaya pada hubungan antara keputusan identitas dan konteks. Kami mempersembahkan set data akses terbuka untuk koreferensi peristiwa saling dokumen, CDEC-WN, dikumpulkan dari Wikinews Inggris dan sumber terbuka alat anotasi kami untuk mendorong penelitian lanjut pada tugas saling dokumen.', 'ko': '본고에서 우리는 서로 다른 문헌에서 텍스트 사건의 동일성을 연구했다.앞서 사건 신원의 복잡성(Hovy 등, 2013년)을 연구했지만 크로스파일 사건의 상황은 알려지지 않았다.이전에 크로스 문서 이벤트의 협동 인용에 관한 작업은 두 가지 주요 결점이 있다.우선, 주석을 유한한 이벤트 형식으로 제한합니다.그 다음으로 그들은 사건의 신분을 충분히 처리할 개념이 없다.이러한 주석 설정은 사건에 대한 언급을 줄이고 신분 관계를 정확하게 고려할 가능성을 방지한다.우리는 다양한 이벤트 언급 출처와 관련 문서 쌍 간의 밀집 주석 작업을 포함하여 크로스 문서 이벤트가 모두 가리키는 밀집 주석 방법을 제시했다.이를 위해 우리는 세밀한 품질 제어와 사용하기 쉬운 주석 인터페이스를 가진 새로운 주석 작업 흐름을 설계했다.이러한 링크를 제외하고 우리는 중첩된 사건 상하문, 즉 시간, 장소와 참여자를 포함하여 신분이 상하문과의 관계를 결정하는 것을 밝히기 위해 수집했다.우리는 크로스 문서 이벤트의 협동 인용에 사용되는 오픈 액세스 데이터 집합 CDEC-WN을 제공합니다. 이 데이터 집합은 영어 위키 뉴스와 소스 주석 도구 패키지에서 나온 것으로 크로스 문서 작업에 대한 진일보한 연구를 장려합니다.', 'sw': 'Katika karatasi hii, tunasoma utambulisho wa matukio ya uhalisia kutoka katika nyaraka tofauti. Wakati utambulisho wa tukio hili ulisomwa kabla (Hovy et al., 2013), kesi ya matukio yanayotokana na nyaraka hazikuwa bayana. Kazi ya awali katika mkutano wa tukio hilo la kupitia nyaraka zina vikosi viwili vikuu. Kwanza, wanazuia matatizo katika aina mipaka ya tukio. Second, they insufficiently tackle the concept of event identity.  Taarifa hiyo inapunguza viwango vya kutajwa kwa tukio hilo na kuzuia mtu kuangalia uwezekano wa mahusiano ya kiutambulisho. Tunazipendekeza mbinu yenye uchunguzi mkubwa wa tukio la tukio hilo la kupitia nyaraka, ikiwa ni pamoja na chanzo tajiri cha tajwa la tukio na jitihada za uchunguzi wa kina kati ya wanandoa wa nyaraka zinazohusiana. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface.  Zaidi ya viungo hivyo, tunakusanya zaidi mikutano ya tukio, ikiwa ni pamoja na wakati, mahali, na washiriki, ili kutoa mwangaza kuhusu uhusiano kati ya maamuzi ya utambulisho na muktadha. Tunaweza kuweka seti ya upatikanaji wa taarifa za wazi kwa ajili ya kituo cha habari cha matukio yanayovuka kupitia nyaraka, CDEC-WN, kilikusanyika kutoka Kiingereza Wikinews na kutumiwa wazi vifaa vyetu vya uchunguzi ili kuhamasisha tafiti zaidi kuhusu kazi za kupitia nyaraka.', 'af': "In hierdie papier, ondersoek ons die identiteit van tekstuele gebeurtenis van verskillende dokumente. Terwyl die kompleks natuur van gebeurtenis identiteit voorheen ondersoek word (Hovy et al., 2013), is die geval van gebeurtenis oor dokumente onbekend. Vorige werk op kruisdokument gebeurtenis voorkeur het twee hoofdrukkings. Eerste, hulle beperk die notasies na 'n beperkte stel van gebeurtenis tipes. Tweede, hulle is onvoldoende die konsepte van gebeurtenis identiteit. Hierdie annotasie opstelling verduur die poort van gebeurtenis en verhinder een om die moontlikheid van quasi- identiteitsverhouding te onderwerp. Ons voorstel 'n dense annotasie toegang vir kruisdokument-gebeurtenis koreferensie, wat 'n ryk bron van gebeurtenis bepaal en 'n dense annotasie versoek tussen verwante dokument paar. Op hierdie einde ontwerp ons 'n nuwe annotasie werksvloei met versigtige kwaliteit beheer en 'n maklik- te gebruik annotasie koppelvlak. In addition to the links, we collect further overlapping event contexts, including time, location, and participants, to shed some light on the relation between identity decisions and context. Ons stel 'n oop-toegang datastel voor die kruisdokument-gebeurtenis-koreferensie, CDEC-WN, versamel van Engels Wikinews en oop-bron ons annotasie-nutsbalk om verdere ondersoek op kruisdokument-opdragte te bevestig.", 'tr': 'Bu kagyzda çykyş sahypalaryň kimligini başga seneden okaýarys. Öň öňden öň bellenen hadysalaryň karmaşık tebigaty (Hovy et al., 2013), senediň arasynda geçen hadysalaryň ýagdaýy däldir. Çapraz senediň ehlini tertiblemekde üçin öňki işi iki sany çekmek üçin bar. Ilkinji gezek, olar täzelikleri çakylan täzeliklere bölýändirler. Ikinjisi, olar bolup geçýän hadysynyň kimligine ýetersiz çykyp bilmeýärler. Böyle duyurular tespit olaryň çözümlerini azaltýar ve birini quasi-kimlik ilişkilerinin mümkünliğini düşünmekten engelleýär. Biz çerçe sened çykyşynyň diňe golaý ýazmagyny teklip edip otyrýarys. Olaryň baý çeşmesi we baglany sened çiftleri arasynda tussak täsirli ýazmagyny maslahat berýäris. Bu üçin, biz täze bir duýdurma aklysyny dikkatli kwalitet kontroli we ulanmak a ňsat bir duýdurma interface düzenledik. Baglaýyşyň daşynda, olar öňünde geçişik duşuşygyny ýazmak üçin wagt, ýer we iştirakçiler bilen kimlik kararlaryny we kontekst arasynda bir ýagtylyk çykarmak üçin ýygnaýarys. Biz çerçe sened howplygynyň döredilişi üçin açyk erişikli maglumat setirini görkeýäris', 'sq': 'Në këtë letër, ne studiojmë identitetin e ngjarjeve tekstuale nga dokumente të ndryshme. Ndërsa natyra komplekse e identitetit të ngjarjes është studiuar më parë (Hovy et al., 2013), rasti i ngjarjeve nëpër dokumente nuk është i qartë. Puna e mëparshme mbi bashkëdrejtimin e ngjarjeve ndërdokumentore ka dy dëme kryesore. Së pari, i kufizojnë anotacionet në një grup të kufizuar të llojeve të ngjarjeve. Së dyti, ata nuk trajtojnë në mënyrë të mjaftueshme konceptin e identitetit të ngjarjes. Vendosja e tillë e anotacionit redukton bazën e përmendimeve të ngjarjeve dhe pengon një të konsiderojë mundësinë e marrëdhënieve quasi-identiteti. Ne propozojmë një qasje të dendur anotacioni për korreferencën e ngjarjeve ndërdokumentore, duke përfshirë një burim të pasur përmendimesh ngjarjesh dhe një përpjekje të dendur anotacioni midis çifteve të dokumenteve të lidhura. Për këtë qëllim, ne dizajnojmë një rrjedhë të re pune anotacioni me kontrollin e kujdesshëm të cilësisë dhe një ndërfaqe të lehtë për përdorim anotacioni. Përveç lidhjeve, ne mbledhim më tej kontekste të ngjarjeve të mbishtypura, duke përfshirë kohën, vendndodhjen dhe pjesëmarrësit, për të hedhur disa drita mbi lidhjen midis vendimeve të identitetit dhe kontekstit. Ne paraqesim një sërë të dhënash me akses të hapur për ngjarjen e korreferencës midis dokumenteve, CDEC-WN, të mbledhur nga English Wikinews dhe burim të hapur paketën tonë të anotacionit për të inkurajuar kërkime të mëtejshme mbi detyrat e ndërdokumenteve.', 'am': 'In this paper, we study the identity of textual events from different documents.  የቀድሞው የኢንተርኔት ግንኙነት ግንኙነት (Hovy et al., 2013) በተማረከ ጊዜ፣ በሰነድ ሰነድ ውስጥ ያሉት ጉዳይ አይታወቅም፡፡ የሥዕል ምርጫዎች በመጀመሪያ፣ አካባቢዎቹን በተወሰነ ድርጊት ዓይነቶች ላይ ያሰናክላሉ፡፡ ሁለተኛ፣ የጉዳዩ ማወቃየት አይበቃቸውም፡፡ እንደዚህ አካባቢ ግንኙነት የግንኙነቱን ማስታወሻ ያሳድጋል እናም የquasi-identity ግንኙነት መሳሰል የሚከለክለው ነው፡፡ ሰነድ አካባቢ እና በተገኘው ሰነድ አካባቢዎች መካከል ባለጠጋ የኢንተርኔት ግንኙነት እና የተጠቃሚ ጉዳይ አሰናክሎ እና በተጨማሪው ሰነድ አካባቢ ጉዳይ እና ጥልቅ ጉዳይ እናደርጋለን፡፡ ለዚህ መጨረሻ አዲስ የጥያቄ ግንኙነት እና ቀላል የተጠቃሚ አቀማመጥ ማቀናጃ ማቀናጃ እና አዲስ አካባቢ ሥራ አቀማመጥ እናደርጋለን፡፡ ግንኙነት በተጨመረ ጊዜ፣ ቦታ እና ተጋሪዎችን እና ግንኙነቱን እና ግንኙነት መካከል ግንኙነት እና ግንኙነት እና ማሰናከል፡፡ የክፍለ ሰነድ ጉዳይ ክፍተት የCDEC-WN የኢንግሊዝኛ Wikinews እና የግልፅ ጉዳይ ማሳየት የግልፅ አካባቢ ማድረጊያውን እናስቀምጣለን፡፡', 'hy': "Այս թղթի մեջ մենք ուսումնասիրում ենք տարբեր փաստաթղթերից գրական իրադարձությունների ինքնությունը: While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear.  Առաջին աշխատանքը թղթափաստաթղթերի իրադարձությունների համախմբման վրա ունի երկու հիմնական թերություն: Առաջինը, նրանք սահմանափակում են նշումները իրադարձությունների սահմանափակ տեսակի վրա: Երկրորդ, նրանք բավարար չափով վերաբերվում են իրադարձությունների ինքնության գաղափարին: Այսպիսի նոտացիաների կառուցվածքը նվազեցնում է իրադարձությունների հիշողությունները և կանխում է մեկին հաշվի առնել կոզի-ինքնության հարաբերությունների հնարավորությունը: Մենք առաջարկում ենք խիստ annoտացիոն մոտեցում միջ-փաստաթղթերի իրադարձությունների համախմբման համար, որը ներառում է իրադարձությունների մեջբերման հարուստ աղբյուր և խիստ annoտացիոն փորձ կապված փաստաթղթերի զույգերի միջև: Այսպիսով, մենք նախագծում ենք նոր annoտացիայի աշխատանքի հոսք' զգույշ որակի վերահսկողությամբ և հեշտ օգտագործվող annoտացիայի ինտերֆեյս: Ավելին կապերին, մենք շարունակում ենք հավաքել հատուկ իրադարձությունների կոնտեքստները, ներառյալ ժամանակը, տեղակայությունը և մասնակիցները, որպեսզի լուսավորենք ինքնության որոշումների և կոնտեքստի միջև կապը: Մենք ներկայացնում ենք բաց հասանելիության տվյալների համակարգ թղթափաստաթղթերի իրադարձությունների կորֆերանսի համար, CDEQ-Ու-ն, որոնք հավաքվել են Անգլերեն Վիքինուսից և բաց կոդը մեր annoտացիայի գործիքների համակարգը, որպեսզի խրախուսենք", 'az': 'Bu kağızda, müxtəlif dökümlərdən textual olaraqların kimliğini öyrənirik. Vaxt kimliğinin kompleks təbiəti əvvəl oxunduğu halda (Hovy et al., 2013), belələrin arasındakı olaraq təbiətlərin məlumatı açıq-aydın deyildir. Əvvəlki döküm olaraq qabaqlıq təsiri barəsində əvvəlki işin iki ana çəkilməsi var. Əvvəlcə, bu məlumatları müəyyən edilmiş bir dəstə tərzlərinə sıkışdırırlar. İkincisi, onlar həqiqət kimliğinin fikrində çox çəkilməz. Bütün bu xəbərdarlıq quruluşu olaraq təhlükəsizlərin istifadəsini azaldır və birini kvasi-kimlik əlaqələrinin mümkünlüyünü düşünməyə mane edir. Biz çoxlu dökümət vaxtı təsiri üçün yoxlu təsiri təklif edirik, vaxtın yada salınmasının çoxlu kaynağı və bağlı dökümət çiftləri arasındakı yoxlu təsirli təsiri təklif edirik. Bu səbəbdə, dikkatli keyfiyyət kontrolü və asanlıqla istifadə etmək üçün yeni bir işaret fəaliyyətini tasarlayırıq. Bağlantılara istifadə edirək, zamanı, yeri və iştirakçilər barəsindəki kimlik kararları və məlumatları arasındakı bağlantı barəsində bəzi işıq çəkmək üçün daha çox üstünlük olaraq məlumatları toplayırıq. İngiliz Wikinews və açıq-kaynağımız məlumatlarını daha çox döküm işləri barəsində araştırmaq üçün açıq-əlaqə verilən verilər qutusunu göstəririk.', 'de': 'In diesem Beitrag untersuchen wir die Identität textueller Ereignisse aus verschiedenen Dokumenten. Während die Komplexität der Ereignisidentität bereits untersucht wurde (Hovy et al., 2013), ist der Fall von Ereignissen über Dokumente hinweg unklar. Bisherige Arbeiten an dokumentübergreifenden Ereignissen haben zwei wesentliche Nachteile. Zunächst beschränken sie die Anmerkungen auf eine begrenzte Anzahl von Ereignistypen. Zweitens greifen sie das Konzept der Ereignisidentität unzureichend an. Eine solche Annotationseinrichtung reduziert den Pool an Ereigniserwähnungen und verhindert, dass man die Möglichkeit von Quasi-Identitätsbeziehungen in Betracht zieht. Wir schlagen einen dichten Annotationsansatz für dokumentübergreifende Event-Coreferenz vor, der eine reiche Quelle von Ereigniserwähnungen und einen dichten Annotationsaufwand zwischen verwandten Dokumentenpaaren umfasst. Dazu konzipieren wir einen neuen Annotations-Workflow mit sorgfältiger Qualitätskontrolle und einer einfach zu bedienenden Annotations-Schnittstelle. Zusätzlich zu den Links sammeln wir auch überlappende Eventkontexte, einschließlich Zeit, Ort und Teilnehmer, um Licht auf die Beziehung zwischen Identitätsentscheidungen und Kontext zu werfen. Wir präsentieren einen Open-Access-Datensatz für dokumentübergreifende Event-Coreferenz, CDEC-WN, gesammelt aus englischen Wikinews und Open-Source unser Annotation Toolkit, um weitere Recherchen zu dokumentübergreifenden Aufgaben zu fördern.', 'bs': 'U ovom papiru proučavamo identitet tekstualnih događaja iz različitih dokumenta. Iako se ranije proučava kompleksna priroda identiteta događaja (Hovy et al., 2013), slučaj događaja kroz dokumente nije jasan. Prije posla o prikladnosti događaja u krsnom dokumentu ima dvije glavne nedostatke. Prvo, oni ograničavaju annotacije na ograničeni set vrsta događaja. Drugo, oni nedovoljno rješavaju koncept identiteta događaja. Takva uspostava za annotaciju smanjuje bazen spominjanja događaja i sprječava jednog da razmotri mogućnost kvazi-identitetnih odnosa. Predlažemo gusti pristup annotacije za pristojnost događaja u krsnom dokumentu, uključujući bogat izvor događaja koji spominje i gusti napor za annotaciju između povezanih par dokumenta. Za taj cilj, dizajniramo novi radni tok annotacije sa pažljivom kontrolom kvalitete i lakom interfejsom za upotrebu annotacija. Pored veza, dalje sakupljamo kontekste preklapanja događaja, uključujući vrijeme, lokaciju i sudionike, kako bi se malo svjetlo o vezi između odluka o identitetu i konteksta. Predstavljamo kompletu podataka otvorenog pristupa za pristojnost događaja preko dokumenta CDEC-WN, okupljenu iz engleskog Wikinews i otvorenog izvora, naš instrument za annotaciju kako bi potaknuli daljnje istraživanje o preko dokumentovanih zadataka.', 'bn': 'এই পত্রিকায় আমরা বিভিন্ন নথিপত্র থেকে টেক্সচুয়াল ঘটনার পরিচয় পড়ি। যদিও পূর্বে অনুষ্ঠানের পরিচয়পত্রের জটিল প্রকৃতি পড়া হয় (হোভি et al., ২০১৩), সারা ডকুমেন্টের ঘটনার ঘটনা অজ্ঞ। Prior work on cross-document event coreference has two main drawbacks.  প্রথমত, তারা এই বিষয়টিকে সীমিত একটি ধরনের অনুষ্ঠানের সীমাবদ্ধ করে রেখেছে। দ্বিতীয়, তারা অনুষ্ঠানের পরিচয়ের ধারণা যথেষ্ট প্রতিক্রিয়া করে না। এই ধরনের বিস্তারিত ব্যবস্থা অনুষ্ঠানের উল্লেখের পুল কমিয়ে দেয় এবং কোয়াসি পরিচিতির সম্পর্ক বিবেচনা করার সম্ভাবনা থেক আমরা প্রস্তাব করছি ক্রস-নথি অনুষ্ঠানের কোরেফারেন্সের জন্য গভীরভাবে বিবেচনা প্রস্তাব, যেখানে অনুষ্ঠানের উৎস এবং সংযুক্ত নথি এই শেষ পর্যন্ত আমরা একটি নতুন শিক্ষার্থীর ফ্লুয়ার ডিজাইন করি সাবধানের মান নিয়ন্ত্রণ এবং সহজেই ব্যবহার করা ব্যাবহারের লিঙ্ক ছাড়াও আমরা আরো অনুষ্ঠানের প্রতিযোগিতা সংগ্রহ করি, যার মধ্যে সময়, অবস্থান এবং অংশগ্রহণকারীদের মধ্যে রয়েছে, যাতে পরিচিতির সিদ্ধান্ত ক্রাস্ট ডকুমেন্টের অনুষ্ঠানের কোরেফারেন্স, সিডিসি-উইনএন, ইংরেজী উইকিনিউজ থেকে সংগ্রহ করা এবং খোলা সোর্স থেকে আমাদের বিভিন্ন তথ্যের', 'cs': 'V tomto článku studujeme identitu textových událostí z různých dokumentů. Zatímco komplexní povaha identity událostí je dříve studována (Hovy et al., 2013), případ událostí napříč dokumenty je nejasný. Předchozí práce na koreferenci událostí mezi dokumenty má dvě hlavní nevýhody. Za prvé, omezují anotace na omezenou sadu typů událostí. Za druhé se nedostatečně zabývají konceptem identity událostí. Takové nastavení anotace snižuje množství zmínek událostí a brání zvažování možnosti kvazi-identity vztahů. Navrhujeme hustý anotační přístup pro koreferenci událostí mezi dokumenty, zahrnující bohatý zdroj zmínek událostí a husté anotace úsilí mezi souvisejícími páry dokumentů. Za tímto účelem navrhujeme nový anotací workflow s pečlivou kontrolou kvality a snadno použitelným anotacím rozhraním. Kromě odkazů dále shromažďujeme překrývající se kontexty událostí, včetně času, místa a účastníků, abychom vrhli trochu světla na vztah mezi rozhodnutím o identitě a kontextem. Představujeme otevřený přístup datový soubor pro koreferenci událostí mezi dokumenty, CDEC-WN, shromážděný z anglických Wikinews a open source náš anotacní nástroj pro podporu dalšího výzkumu týkajících se úkolů mezi dokumenty.', 'ca': "En aquest article estudiem l'identitat dels esdeveniments textuals de diferents documents. Mentre que la complexitat de l'identitat d'events s'ha estudiat anteriorment (Hovy et al., 2013), el cas d'events entre documents no és clar. La feina anterior en la coreferencia d'esdeveniments transdocumentals té dos inconvenients principals. Primer, limitan les anotacions a un conjunt limitat de tipus d'esdeveniments. Segon, no aborden suficientment el concepte d'identitat d'eventos. Aquesta configuració d'anotació redueix el conjunt de mentions d'eventos i evita que un consideri la possibilitat de relacions quasi-identitàries. Proposem un enfocament dens d'anotació per a la coreferència d'esdeveniments transdocumentals, que consisteix en una font rica de mencions d'esdeveniments i un esforç dens d'anotació entre parells de documents relacionats. Per això, dissenyem un nou flux de treball d'anotació amb un control de qualitat atent i una interfície d'anotació fàcil d'utilitzar. A més dels enllaços, també recollim contextes d'esdeveniments overlapping, incloent el temps, la llocalització i els participants, per donar llum a la relació entre decisions d'identitat i context. Presentam un conjunt de dades d'accés obert per a la conferència d'eventos transversals, CDEC-WN, recollit de Wikinews anglesos i de codi obert per a animar més recerca sobre tasques transversals.", 'et': 'Käesolevas töös uurime tekstisündmuste identiteeti erinevatest dokumentidest. Kuigi sündmuste identiteedi keerukust on varem uuritud (Hovy et al., 2013), on sündmuste juhtum dokumentides ebaselge. Eelneval tööl ristdokumentidevahelise sündmuste kaasreferentsiga on kaks peamist puudust. Esiteks piiravad nad märkused piiratud sündmuste tüüpidega. Teiseks ei käsitle nad piisavalt sündmuse identiteedi kontseptsiooni. Selline annotatsiooni seadistamine vähendab sündmuste mainimiste kogumit ja takistab kaaluda kvaasiidentiteedsete suhete võimalust. Pakume välja tiheda annoteerimise lähenemisviisi dokumentidevahelise sündmuste kortereferentsi jaoks, mis hõlmab rikkalikku sündmuste mainimise allikat ja tihedat annoteerimist seotud dokumendipaaride vahel. Selleks kujundame uue annotatsioonitöövoo hoolika kvaliteedikontrolli ja lihtsalt kasutatava annotatsiooniliidesega. Lisaks linkidele kogume ka kattuvaid sündmuste kontekste, sealhulgas aega, asukohta ja osalejaid, et valgustada identiteedi otsuste ja konteksti seost. Esitame avatud juurdepääsuga andmekogumi, CDEC-WN, mis on kogutud inglise Wikinewsist ja avatud lähtekoodiga meie märkuste tööriistakomplekti, et julgustada edasisi uuringuid dokumentidevaheliste ülesannete kohta.', 'fi': 'Tässä työssä tutkitaan tekstitapahtumien identiteettiä eri dokumenteista. Vaikka tapahtumaidentiteetin monimutkaista luonnetta on tutkittu aiemmin (Hovy et al., 2013), tapahtumien tapaus dokumenteissa on epäselvä. Aikaisemmassa cross-document event co-reference -työssä on kaksi keskeistä haittapuolta. Ensinnäkin ne rajoittavat merkinnät rajoitettuun tapahtumatyyppien joukkoon. Toiseksi niissä ei käsitellä riittävästi tapahtumaidentiteetin käsitettä. Tällainen huomautusasetus vähentää tapahtumamainintojen määrää ja estää harkitsemasta kvasi-identiteettisuhteiden mahdollisuutta. Ehdotamme tiheää annotointia dokumenttien väliselle tapahtumakoreferenssille, joka sisältää monipuolisen tapahtumamaininnan lähteen ja tiheän annotointipyrkimyksen dokumenttiparien välillä. Tätä varten suunnittelemme uuden merkintätyönkulun huolellisella laadunvalvonnalla ja helppokäyttöisellä merkintärajapinnalla. Linkkien lisäksi keräämme päällekkäisiä tapahtumakonteksteja, kuten aikaa, paikkaa ja osallistujia, valottaaksemme identiteettipäätösten ja kontekstin suhdetta. Esittelemme avoimen aineiston cross-document event coreferencea varten, CDEC-WN, joka on kerätty englanninkielisestä Wikinewsistä ja avoimen lähdekoodin merkintätyökalupakkimme kannustaaksemme jatkotutkimukseen cross-document tehtävistä.', 'ha': "Ga wannan takardan, Munã karatun shaidar ayuka na littafi daga wasu takardar. A lokacin da ake jarraba halin shaidar tukio da aka riga aka karanta (Hovie et al., 2013), halin al'amarin na dukkan takardar nan ba'a sani ba. Kayyar aiki na zaman shawarar wata takardar-takardar ta yi amfani da biyu masu motsi. First, they restrict the annotations to a limited set of event types.  Da na ƙarshe, ba su sami zaɓen wani zato ba. Wannan shirin zartar da shi yana ƙarantar ƙarami da za'a ambaci abun ayuka kuma yana hana wanda ya yi tunãni a kan muhimmin haɗi da bayani na daidaita. Tuna goyyar da wata matsayi mai sanyi wa shirin ayuka da ke tsakanin dukkan takardar-takardar, wanda ke samu da wani marãyi mai yawa na ambaci da aikin zartar gaske tsakanin takardar nan da aka yi danganta. Ga wannan, muna ƙayyade wani shirin mai sanarwa da shirin taƙaitacce da taƙaitacce masu tsari da kuma an yi amfani da interfekt masu sauƙi da yin amfani da. Ga bayan linki, muna samo kodi matsayin ayuka da aka rufe su, kamar lokaci, wurin da ke da shirin haɗuwa, dõmin Mu nuna wani haske kan muhimmin ka tsakanin maaɓallin sigar da mazaɓa. Tuna nuna wani matsayi da ake haɗa wa shirin ayukan-takardar-ɗabi'a, CDAC-WN, wanda aka samu daga Ingiriya Wikinews da kuma Muke buɗe zanen zartar da zane-zane don ka ƙara research kan aikin-takardar-ɗabi'a.", 'he': 'בעיתון הזה, אנחנו לומדים את זהות האירועים הטקסטאליים ממסמכים שונים. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear.  העבודה הקודמת על סידור אירועים בין מסמכים יש שני חסרונות ראשיים. ראשית, הם מגבילים את ההערות לסוגי אירועים מוגבלים. שנית, הם לא מתמודדים מספיק עם הרעיון של זהות אירוע. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations.  We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs.  To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface.  בנוסף לקשר, אנו אוספים עוד קשרי אירועים מתקפלים, כולל זמן, מיקום, ושתתפים, כדי לשפוך קצת אור על היחסים בין החלטות זהות לקשר. אנחנו מציגים קבוצת נתונים גישה פתוחה עבור התאמה לאירועים חוצה מסמך, CDEC-WN, שנאספה מ Wikinews אנגלית ומקור פתוח כלי הערות שלנו כדי לעודד מחקר נוסף על משימות חוצה מסמך.', 'sk': 'V prispevku preučujemo identiteto besedilnih dogodkov iz različnih dokumentov. Čeprav je kompleksna narava identitete dogodkov že prej proučena (Hovy et al., 2013), primer dogodkov v dokumentih ni jasen. Predhodno delo na področju navzkrižne dokumentacije dogodkov ima dve glavni pomanjkljivosti. Najprej omejijo opombe na omejen nabor vrst dogodkov. Drugič, premalo se ukvarjajo s konceptom identitete dogodka. Takšna nastavitev označevanja zmanjšuje nabor omemb dogodkov in preprečuje upoštevanje možnosti navideznih odnosov. Predlagamo pristop gostih opomb za meddokumentsko koreferenco dogodkov, ki vključuje bogat vir omenjanja dogodkov in gosto opombe med sorodnimi pari dokumentov. V ta namen oblikujemo nov potek dela označevanja s skrbnim nadzorom kakovosti in enostavnim vmesnikom označevanja. Poleg povezav zbiramo tudi prekrivajoče se dogodkovne kontekste, vključno s časom, lokacijo in udeleženci, da bi osvetlili razmerje med identitetnimi odločitvami in kontekstom. Predstavljamo odprt dostop podatkov za meddokumentsko povezovanje dogodkov, CDEC-WN, zbran iz angleške Wikinews in odprtokodni nabor orodij za opombe, da bi spodbudili nadaljnje raziskave o meddokumentnih nalogah.', 'jv': 'Nang pegatining iki, awake dhéwé isih perkaraan kelas textual karo dokumen sing sampeyan. politenessoffpolite"), and when there is a change ("assertivepoliteness echoH e l l o space w o r l d periodHelloworldHello world Awak dhéwé, wong dhéwé nggawe aturan awak dhéwé kanggo Kemerdekaan sing dikenakno Pakabèh, wong-wong kuwi ora cukuraké nggawe gerakan kanggo ngerasakno iki dadi. Wurunggo dolanan sing beraksi perusahaan nggawe tindakan sing perusahaan anyar tentang karo perusahaan langgar sampeyan karo perusahaan karo perusahaan Awak dhéwé nggawe Perintah Pangawean nggawe Perintah Pangawean Ngomongke iki, kita disenyongno sistem Anya nggawe barang nggawe nguasakno ngono nggawe barang apik lan gampang-gampang Nanging tambah liyane, kita luwih akeh pisan denganjut operasi nggawe ngubah perkaran, aku, kabeh, lan patingkarani Awak dhéwé éntuk dataset Open-access kanggo nggawe corefèren nggawe dokumen karo perangkat-akéwé, Cdromek-WN, ngregasi kanggo ngerasakno ning anglisar wiwicarita lan Open-source', 'bo': 'ཤོག་བྱང་འདིའི་ནང་གི་ཡིག་ཆ་མི་འདྲ་ནས་ཡིག་གེ་འགྲེལ་བཤད་པའི་བྱ་ཚིག་དང་ཤོག་བྱས་པ་རེད། སྔོན་གྱིས་བྱ་འགུལ་གྱི་ཚོར་བ་སྦྱོར་བའི་རང་བཞིན་གནས་ཚུལ་ཁག་ཅིག་ལྷག་ཞིང་། ཡིག་ཆ་དང་བསུབ་པའི་བྱ་འགུལ་གདོང་ལེན་སྔོན་གྱི་ལས་འགུལ་ལ་རྩ་བའི་རྒྱབ་ལྗོངས་གཉིས་ཡོད། དང་པོར་བརྗོད་བྱས་ན། དེའི་རྣམ་གྲངས་ལ་བྱ་འགུལ་གྱི་སྒྲིག་འཛུགས་ཚད་ཉེན་ཡོད་པ་མ་ཟད། གཉིས་པ། དེ་དག་ནི་བྱ་ཚིག་དང་འབྲེལ་བ་དེར་ཐབས་མེད་པ་རེད། འདིའི་བསྐུལ་གྱི་གཞི་སྒྲིག་གིས་བྱ་འགུལ་གྱི་གྲོང་ཁྱེར་ཚོའི་ནང་དུ་ཉེན་ཁ་ཡིག་ཅིག་ལ་བསམ་བྱེད་རྒྱུ་ཡིན། ང་ཚོས་ཡིག་གེའི་གནད་དོན་འགྱུར་བ་འདིའི་གྲངས་སུ་འབྲེལ་བའི་འགྲེལ་བཤད་ཀྱི་ཐབས་ལམ་ཞིག་བཤད་ཀྱི་ཡོད། མཇུག་གི་དོན་ལ། ང་ཚོས་དྲན་སྐུལ་གསར་པ་ཞིག་གི་སྒྲིག་སྟངས་གདོང་ཚད་དང་སྟབས་བདེ་བོའི་སྐུལ་སྤྱོད་བརྗོད་བ དེ་ལས་སྦྲེལ་མཐུད་དེ་བསྡུར་ན། ང་ཚོས་དུས་ཚོད་བྱ་ཚུལ་དང་ཁྱད་ཆོས་བྱེད་པའི་དོན་དག་ཐོག་ཏུ་བསྡུར་བྱེད་དགོས་པ་མེད། We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.'}
{'en': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'ar': 'تقييم قائم على حالة النفي لقرار النفي الشامل', 'es': 'Evaluación basada en negación de la resolución de negación de extremo a extremo', 'pt': 'Avaliação baseada em instância de negação da resolução de negação de ponta a ponta', 'fr': "Évaluation basée sur l'instance de négation de la résolution de bout en bout de la négation", 'ja': 'エンドツーエンドのネガティブな解決策のネガティブなインスタンスベースの評価', 'zh': '盖非例之端到端否定解析评估', 'hi': 'नेगेशन-इंस्टेंस आधारित मूल्यांकन एंड-टू-एंड नेगेशन रिज़ॉल्यूशन का', 'ru': 'Оценка разрешения отрицательного результата, основанная на конкретном случае, для сквозного отрицательного результата', 'ga': 'Meastóireacht Diúltach-Bhunaithe ar Rún Diúltaithe ó Dheireadh go Deireadh', 'el': 'Αξιολόγηση της ολοκληρωμένης επίλυσης της άρνησης με βάση την άρνηση', 'ka': 'ბოლოდან ბოლოდან ბოლოდან ბოლოდან ბოლოდან დასრულებული განსაზღვრების განსაზღვრება', 'it': "Valutazione basata sull'istanza di negazione della risoluzione di negazione end-to-end", 'hu': 'Negációs példány alapú értékelés a végtől végig negatív megoldásról', 'ms': 'Evaluasi Berasas Kejadian-Negasi Resolusi Negasi Akhir-Akhir', 'kk': 'Аяқтау- аяқтау мөлшерлемесінің негізіндегі мөлшерлемесі', 'lt': 'Negacijos atveju pagrįstas Negacijos nutarimo pabaigoje vertinimas', 'mt': 'Evalwazzjoni bbażata fuq l-Instanza tan-Negozjar tar-Riżoluzzjoni tan-Negozjar minn Tmiem sa Tmiem', 'mk': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'mn': 'Шүүмжлэх-Instance Based Evaluation of End-to-End Negation Resolution', 'ml': 'അവസാനം മുതല്\u200d അവസാനിക്കുന്നതിന്റെ നേഗന്\u200d ഇന്\u200dസ്റ്റെന്\u200dസ് അടിസ്ഥാനപ്പെടുത്തിയിരിക്കുന്നു', 'sr': 'Оцена резолюције преговарања на крају до крају', 'no': 'Negatingsinstans basert evaluering av slutttil sluttNegatingsoppløysing', 'pl': 'Ocena kompleksowej likwidacji negacji opartej na instancji negacji', 'ro': 'Evaluarea bazată pe instanțe de negare a rezoluției de negare end-to-end', 'si': 'අවසානයෙන් අවසානයෙන් අවසානයෙන් අවසානය විශේෂණය', 'so': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'ta': 'முடிவில் இருந்து முடிவில் இருந்து திரைத் தெளிவுத்திறனுக்கு அடிப்படையான செயல்பாடு', 'sv': 'Negationsinstansbaserad utvärdering av End-to-End Negation Resolution', 'ur': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'uz': 'Comment', 'vi': 'Phiên bản đánh giá cuối cùng của giải pháp', 'da': 'Negation-Instance Baseret Evaluering af End-to-End Negation Resolution', 'nl': 'Negatie-Instance Gebaseerde Evaluatie van End-to-End Negatie Resolutie', 'bg': 'Оценка, базирана на отрицателни инстанции, на решаването на отрицателни действия от край до край', 'id': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'de': 'Negation-Instance Based Evaluation of End-to-End Negation Resolution', 'sw': 'Uchunguzi wa Mawasiliano Kutokana na Uthibitisho wa Kuishia mpaka Kuishia Kushinikiza Mazingira', 'ko': '부정 실례에 기초한 끝에서 끝까지의 부정 해석 평가', 'fa': 'ارزیابی پایه\u200cای از ارزیابی حل\u200cسازی پایان به پایان', 'af': 'Negasie- Instans gebaseerde evaluering van Einde- na- Einde Negasie Resolusie', 'sq': 'Vlerësimi i rezolutës së negativës së fundit në fund', 'am': 'አድራሻ', 'hr': 'Pregovorni instanci temeljena procjena rezolucije pregovora do kraja', 'hy': 'Բացասական-ինտենցիայի հիմնված բացասական լուծումների վերջ-վերջ գնահատումը', 'tr': 'Soňra-soňra Ýüklemek Çözümlerini Taýýarla', 'az': 'Sona-sona-sona-sona Bölüm Çözünürlüyünün İşləməsinin İşləmə-İşləməsi', 'cs': 'Vyhodnocení komplexního řešení negativního řešení založeného na negativní instanci', 'ca': 'Evaluació basada en una instància de negatiu de la resolució final a final', 'et': 'Negatiivsuse astmepõhine hindamine lõpust lõpuni negatiivse lahenduse kohta', 'bn': 'সমাপ্তি থেকে শেষ পর্যন্ত নেগেশন সংস্থার মূল্যায়ন', 'fi': 'Kieltämisasetukseen perustuva arviointi päästä päähän -kielteisen ratkaisun ratkaisusta', 'bs': 'Pregovorni instanci temeljna procjena rezolucije za kraj do kraja pregovora', 'sk': 'Ocena reševanja celotnega zavračanja na podlagi negativnih primerov', 'he': 'הערכה מבוססת על תקופת שלילה של פתרון שלילה מסוף לסוף', 'ha': '@ action', 'bo': 'མཇུག་ལ་བསྡུས་ནས་མཇུག་ལ་མ་ཐང་བའི་གནས་སྟངས་ལ་གཞི་རྟེན་ནས་ཡོད་པའི་ཚད་ལྟར', 'jv': 'Language'}
{'en': 'In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. not, never) and scope resolution. In the context of previous shared tasks, a variety of evaluation metrics have been proposed. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult. Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution. Our proposed  metrics  correspond to expectations over per-instance scores and hence are intuitively interpretable. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.', 'ar': 'في هذه الورقة ، نعيد النظر في مهمة حل النفي ، والتي تتضمن المهام الفرعية للكشف عن الإشارات (مثل "لا" ، "أبدًا") ودقة النطاق. في سياق المهام المشتركة السابقة ، تم اقتراح مجموعة متنوعة من مقاييس التقييم. عادةً ما تستخدم الأعمال اللاحقة مجموعات فرعية مختلفة منها ، بما في ذلك الاختلافات والتطبيقات المخصصة ، مما يجعل المقارنات المفيدة بين الأنظمة أمرًا صعبًا. عند فحص المشكلة من منظور لغوي ومن وجهة نظر المصب ، فإننا ندافع هنا عن نهج قائم على مثيل النفي لتقييم قرار الرفض. تتوافق مقاييسنا المقترحة مع التوقعات على درجات كل حالة ، وبالتالي فهي قابلة للتفسير بشكل حدسي. لجعل البحث قابلاً للمقارنة ولتعزيز العمل المستقبلي ، نقدم نتائج لمجموعة من أحدث الأنظمة الحالية لحل النفي في ثلاث مجموعات باللغة الإنجليزية ، ونجعل تنفيذنا لنصوص التقييم متاحًا للجمهور.', 'pt': 'Neste artigo, revisitamos a tarefa de resolução de negação, que inclui as subtarefas de detecção de pistas (por exemplo, “não”, “nunca”) e resolução de escopo. No contexto de tarefas compartilhadas anteriores, uma variedade de métricas de avaliação foi proposta. Trabalhos subsequentes geralmente usam diferentes subconjuntos deles, incluindo variações e implementações personalizadas, dificultando comparações significativas entre sistemas. Examinando o problema tanto de uma perspectiva linguística quanto de um ponto de vista a jusante, defendemos aqui uma abordagem baseada em instâncias de negação para avaliar a resolução da negação. Nossas métricas propostas correspondem às expectativas sobre as pontuações por instância e, portanto, são intuitivamente interpretáveis. Para tornar a pesquisa comparável e promover trabalhos futuros, fornecemos resultados para um conjunto de sistemas atuais de última geração para resolução de negação em três corpora em inglês e disponibilizamos publicamente nossa implementação dos roteiros de avaliação.', 'es': 'En este artículo, revisamos la tarea de resolución de negación, que incluye las subtareas de detección de señales (por ejemplo, «no», «nunca») y resolución de alcance. En el contexto de las tareas compartidas anteriores, se ha propuesto una variedad de métricas de evaluación. Los trabajos posteriores suelen utilizar diferentes subconjuntos de estos, incluidas variaciones e implementaciones personalizadas, lo que dificulta las comparaciones significativas entre sistemas. Examinando el problema tanto desde una perspectiva lingüística como desde un punto de vista descendente, aquí defendemos un enfoque basado en la negación para evaluar la resolución de la negación. Las métricas que proponemos corresponden a las expectativas sobre las puntuaciones por instancia y, por lo tanto, son interpretables intuitivamente. Para hacer que la investigación sea comparable y fomentar el trabajo futuro, proporcionamos los resultados de un conjunto de sistemas actuales de vanguardia para la resolución de negaciones en tres corpus ingleses, y ponemos a disposición del público nuestra implementación de los guiones de evaluación.', 'ja': '本稿では、否定解消の課題について再検討する。否定解消には、キュー検出のサブタスク（例えば、「NOT」、「NEVER」）とスコープ解消のサブタスクが含まれる。以前の共有タスクのコンテキストでは、さまざまな評価指標が提案されています。その後の作品は通常、バリエーションやカスタム実装を含むこれらの異なるサブセットを使用し、システム間の有意義な比較を困難にしている。言語学的な観点と下流の観点の両方から問題を検討し、否定解決を評価する否定-インスタンスベースのアプローチを主張する。提案されている指標は、インスタンスごとのスコアに対する期待に対応しているため、直感的に解釈可能です。研究を同等にし、将来の仕事を促進するために、3つの英語のコーパスの否定解決のための現行の最先端システムのセットの結果を提供し、評価スクリプトの実装を公開します。', 'zh': '本文重审否解析之务,其提检(如"不","不")及限解析子职。 前此共享之背景,已有评估指标。 续事异子集,变体自定义成,使统间之义难矣。 以语言学与下流论之,吾于此主用一法以质之。 臣等所议指标与例分数相应,故可直观解。 为可比性而趋来者,为三英语语料库先否解析统,使吾评脚本明可也。', 'fr': "Dans cet article, nous revoyons la tâche de résolution de négation, qui inclut les sous-tâches de détection de signal (par exemple «\xa0non\xa0», «\xa0jamais\xa0») et de résolution de portée. Dans le contexte des tâches partagées précédentes, diverses mesures d'évaluation ont été proposées. Les travaux ultérieurs utilisent généralement différents sous-ensembles de ceux-ci, y compris des variations et des implémentations personnalisées, ce qui rend difficile les comparaisons significatives entre les systèmes. En examinant le problème à la fois d'un point de vue linguistique et d'un point de vue en aval, nous préconisons ici une approche basée sur une instance de négation pour évaluer la résolution de la négation. Les métriques que nous proposons correspondent aux attentes par rapport aux scores par instance et sont donc intuitivement interprétables. Afin de rendre la recherche comparable et de favoriser les travaux futurs, nous fournissons les résultats d'un ensemble de systèmes actuels de pointe pour la résolution des négations sur trois corpus anglais, et rendons notre implémentation des scripts d'évaluation accessible au public.", 'ga': "Sa pháipéar seo, déanaimid athchuairt ar an tasc a bhaineann le réiteach diúltaithe, lena n-áirítear na subtascanna a bhaineann le cue a bhrath (m.sh. “ní”, “riamh”) agus réiteach scóip. I gcomhthéacs na dtascanna comhroinnte roimhe seo, tá méadracht mheastóireachta éagsúla molta. Is gnách go n-úsáideann oibreacha ina dhiaidh sin fo-thacair éagsúla díobh seo, lena n-áirítear éagsúlachtaí agus cur i bhfeidhm saincheaptha, rud a fhágann go bhfuil sé deacair comparáidí bríocha a dhéanamh idir córais. Ag scrúdú na faidhbe ó pheirspictíocht teanga agus ó thaobh le sruth araon, déanaimid argóint anseo ar son cur chuige atá bunaithe ar dhiúltuithe maidir le measúnú a dhéanamh ar réiteach an diúltachais. Freagraíonn ár méadracht bheartaithe d'ionchais thar scóir in aghaidh na huaire agus mar sin is féidir iad a léirmhíniú go hintuigthe. Chun an taighde a dhéanamh inchomparáide agus chun obair amach anseo a chothú, cuirimid torthaí ar fáil do thacar de chórais úrscothacha reatha le haghaidh réiteach caibidlíochta ar thrí chorparáid Shasana, agus cuirimid ár gcur i bhfeidhm na scripteanna meastóireachta ar fáil go poiblí.", 'hi': 'इस पेपर में, हम नकारात्मक संकल्प के कार्य को फिर से देखते हैं, जिसमें क्यू डिटेक्शन (जैसे "नहीं", "कभी नहीं") और स्कोप रिज़ॉल्यूशन के उप-कार्य शामिल हैं। पिछले साझा कार्यों के संदर्भ में, विभिन्न प्रकार के मूल्यांकन मैट्रिक्स प्रस्तावित किए गए हैं। बाद के काम आमतौर पर इनमें से विभिन्न उपसमुच्चय का उपयोग करते हैं, जिसमें विविधताएं और कस्टम कार्यान्वयन शामिल हैं, जो सिस्टम के बीच सार्थक तुलना को मुश्किल बनाते हैं। एक भाषाई परिप्रेक्ष्य से और एक डाउनस्ट्रीम दृष्टिकोण से दोनों समस्या की जांच करते हुए, हम यहां नकारात्मक संकल्प का मूल्यांकन करने के लिए एक नकारात्मक-उदाहरण आधारित दृष्टिकोण के लिए तर्क देते हैं। हमारे प्रस्तावित मैट्रिक्स प्रति-उदाहरण स्कोर पर अपेक्षाओं के अनुरूप हैं और इसलिए सहज रूप से व्याख्या योग्य हैं। अनुसंधान को तुलनीय बनाने और भविष्य के काम को बढ़ावा देने के लिए, हम तीन अंग्रेजी कॉर्पोरेट पर नकार संकल्प के लिए वर्तमान अत्याधुनिक प्रणालियों के एक सेट के लिए परिणाम प्रदान करते हैं, और मूल्यांकन लिपियों के हमारे कार्यान्वयन को सार्वजनिक रूप से उपलब्ध कराते हैं।', 'ru': 'В этой статье мы возвращаемся к задаче разрешения отрицания, которая включает в себя подзадачи обнаружения подсказки (например, «не», «никогда») и разрешения области применения. В контексте предыдущих общих задач были предложены различные оценочные показатели. В последующих работах обычно используются различные их подмножества, включая вариации и пользовательские реализации, что затрудняет значимые сравнения между системами. Рассматривая проблему как с лингвистической точки зрения, так и с точки зрения нисходящего потока, мы здесь отстаиваем подход к оценке разрешения отрицания, основанный на отрицании. Наши предлагаемые показатели соответствуют ожиданиям в отношении баллов по каждому конкретному случаю и, следовательно, интуитивно интерпретируются. Чтобы сделать исследования сопоставимыми и способствовать будущей работе, мы предоставляем результаты для набора современных систем разрешения отрицания в трех английских корпорациях и делаем нашу реализацию сценариев оценки общедоступной.', 'hu': 'Jelen tanulmányban áttekintjük a negatív felbontás feladatát, amely magában foglalja a cue detektálás (pl. "nem", "soha") és a hatókör felbontásának altfeladatait. A korábbi megosztott feladatok összefüggésében számos értékelési mutatót javasoltak. A későbbi munkák általában ezek különböző részhalmazait használják, beleértve a változatokat és az egyéni implementációkat, ami megnehezíti a rendszerek értelmes összehasonlítását. A problémát mind nyelvi szempontból, mind downstream szempontból vizsgáljuk, itt egy negatív példány alapú megközelítés mellett érvelünk a negatív megoldás értékelésére. Javasolt mutatóink megfelelnek az egyes példányokra vonatkozó elvárásoknak, ezért intuitív módon értelmezhetők. A kutatások összehasonlíthatóvá tétele és a jövőbeli munka előmozdítása érdekében három angol korpora negatív megoldására szolgáló jelenlegi korszerű rendszerek eredményeit biztosítjuk, és nyilvánosan hozzáférhetővé tesszük az értékelő szkriptek megvalósítását.', 'ka': "ამ დომენტში ჩვენ გავაკეთებთ მინდომის გარეშექმნა, რომელიც შეიყვანს მინდომის განახსნა (მაგალითად: 'არა', 'არასოდენობა') და მინდომის გარეშექმნა. წინა გაყოფილი დავალების კონტექსტში, განსაზღვრებული მეტრიკების განსაზღვრებულება იყო. შემდეგი სამუშაო მუშაო გამოყენება განსხვავებული სპექსტის გამოყენება, რომელიც განსხვავებები და განსხვავებული მომუშაობები, რომელიც სისტემის განსხვავებ პრობლემას ინგლინგისტიკური პერვისტიკური პერვისტიკისგან და ჩვენ აქ ახალგაზრდებით ნეგრაციის კონსტიკური პრობლემას განსაზღვრებისთვის განსაზღვრებისთვის. ჩვენი მოძლევებული მეტრიკები კონფიგურაციას, რომელიც ყოველ ინსტუტიურად განსხვავებულია. თუ გადასწორებელი და მომავალე სამუშაო სამუშაო მუშაო მუშაო სისტემის შესაძლებლობად გადასწორება, ჩვენ გავაკეთებთ მიმდინარე სამუშაო სისტემის შესაძლებლობად დასწორება ანგლის", 'el': 'Σε αυτή την εργασία, επανεξετάζουμε το έργο της ανάλυσης άρνησης, η οποία περιλαμβάνει τις δευτερεύουσες εργασίες της ανίχνευσης σημάτων (π.χ. "όχι", "ποτέ") και την ανάλυση πεδίου. Στο πλαίσιο προηγούμενων κοινών εργασιών, έχει προταθεί ποικιλία μετρήσεων αξιολόγησης. Οι επόμενες εργασίες συνήθως χρησιμοποιούν διαφορετικά υποσύνολα αυτών, συμπεριλαμβανομένων παραλλαγών και προσαρμοσμένων εφαρμογών, καθιστώντας σημαντικές συγκρίσεις μεταξύ συστημάτων δύσκολες. Εξετάζοντας το πρόβλημα τόσο από γλωσσική όσο και από μεταγενέστερη άποψη, υποστηρίζουμε εδώ μια προσέγγιση βασισμένη στην άρνηση για την αξιολόγηση της επίλυσης της άρνησης. Οι προτεινόμενες μετρήσεις αντιστοιχούν στις προσδοκίες σχετικά με τις βαθμολογίες ανά περίπτωση και ως εκ τούτου είναι διαισθητικά ερμηνευτές. Για να καταστήσουμε την έρευνα συγκρίσιμη και να προωθήσουμε μελλοντικές εργασίες, παρέχουμε αποτελέσματα για ένα σύνολο σύγχρονων συστημάτων επίλυσης άρνησης σε τρία αγγλικά σώματα, και θέτουμε την εφαρμογή των σεναρίων αξιολόγησης δημοσίως διαθέσιμη.', 'it': "In questo articolo, rivediamo il compito della risoluzione della negazione, che include le sottoattività del rilevamento di cue (ad esempio 'non', 'mai') e della risoluzione dello scope. Nel contesto di precedenti attività condivise, sono state proposte varie metriche di valutazione. I lavori successivi di solito utilizzano diversi sottoinsiemi di questi, incluse variazioni e implementazioni personalizzate, rendendo difficili i confronti significativi tra i sistemi. Esaminando il problema sia da una prospettiva linguistica che da un punto di vista a valle, qui sosteniamo un approccio basato sull'istanza di negazione per valutare la risoluzione della negazione. Le metriche proposte corrispondono alle aspettative sui punteggi per istanza e quindi sono intuitivamente interpretabili. Per rendere la ricerca comparabile e promuovere il lavoro futuro, forniamo i risultati di una serie di sistemi attuali all'avanguardia per la risoluzione della negazione su tre corpora inglesi e rendiamo pubblica la nostra implementazione degli script di valutazione.", 'lt': 'Šiame dokumente persvarstome neigiamos rezoliucijos užduotį, į kurią įtraukiami požymių nustatymo (pvz. „ne“, „niekada“) ir taikymo srities rezoliucijos požymiai. Atsižvelgiant į ankstesnes bendras užduotis, buvo pasiūlyta įvairių vertinimo rodiklių. Tolesniuose darbuose paprastai naudojami skirtingi jų pogrupiai, įskaitant pokyčius ir pritaikytą įgyvendinimą, todėl sunku reikšmingai palyginti sistemas. Nagrinėdami šią problem ą tiek kalbiniu, tiek tolesniu požiūriu, mes čia raginame taikyti neigiamo sprendimo vertinimo metodą. Mūsų siūlomi rodikliai atitinka lūkesčius, palyginti su kiekvieno atvejo rezultatais, todėl yra intuityviai aiškinami. Kad moksliniai tyrimai būtų palyginami ir būtų skatinamas būsimas darbas, mes teikiame rezultatus dabartinėms pažangiausioms neigiamo sprendimo sistemoms trijų anglų korporų atžvilgiu ir viešai paskelbsime mūsų vertinimo scenarijų įgyvendinimą.', 'kk': "Бұл қағазда, мәліметтерді анықтау (мысалы, 'емес', 'ешқашан') және сәйкестігінің айырмашылығын қайталап көреміз. Алдыңғы ортақ тапсырмалардың контексті бірнеше бағалау метрикалары ұсынылды. Келесі жұмыстар әдетте бұлардың әртүрлі бөлшектерін қолданады, өзгерістер мен өзгерістер қолданады, жүйелер арасындағы маңызды салыстыруды көрсетеді. Мәселені лингвистикалық перспективадан да, төменгі көрініс нәтижесінен да тексеру үшін негизациялық инстанциясының негизациялық айырмашылығын тексеру үшін аргументіміз келеді. Біздің келтірілген метрикалық инстанциялық нөмірлерінен артық күтулерімізге сәйкес келеді, сондықтан бұл интуитивті түсінікті болады. Біз зерттеулерді салыстыруға және болашақ жұмыстарды көмектесу үшін, үш ағылшын корпорасындағы негативті айырмашылық жүйелердің нәтижелерін жасап, оқу скрипттерін жалғастыруға мүмкін болады.", 'ms': "Dalam kertas ini, kita mengulangi tugas resolusi negati, yang termasuk subtaskan pengesan isyarat (cth. 'not', 'never') dan resolusi skop. Dalam konteks tugas berkongsi terdahulu, pelbagai metrik penilaian telah diusulkan. Kerja berikutnya biasanya menggunakan subset yang berbeza daripada ini, termasuk variasi dan implementasi suai, menjadikan perbandingan bermakna antara sistem sukar. Memeriksa masalah dari sudut pandang bahasa dan dari sudut pandang turun, kita di sini berdebat untuk pendekatan berdasarkan contoh negatif untuk menilai resolusi negatif. Metrik yang diusulkan kita sepadan dengan jangkaan atas skor per-kejadian dan oleh itu boleh diterangkan secara intuitif. Untuk membuat penyelidikan boleh dibandingkan dan untuk meningkatkan kerja masa depan, kami menyediakan keputusan untuk set sistem semasa-semasa untuk resolusi negatif pada tiga korpra Inggeris, dan membuat pelaksanaan kami skrip penilaian tersedia kepada masyarakat.", 'mk': 'Во овој документ ја повторуваме задачата за резолуција на негативите, која ги вклучува подзадачите за детекција на знаци (np. „не“, „никогаш“) и резолуција на опфатот. Во контекст на претходните заеднички задачи, се предложени различни метрики за проценка. Последните дела обично користат различни подгрупи од овие, вклучително и варијации и сопствени имплементации, правејќи значајни споредби помеѓу системите тешки. Истражувајќи го проблемот од јазичка перспектива и од понатамошна точка на поглед, ние тука тврдиме за пристап базиран на негативна инстанција за проценка на негативна резолуција. Нашите предложени метрики одговараат на очекувањата во однос на резултатите на секоја инстанција и затоа се интуитивно интерпретабилни. За да го направиме истражувањето споредливо и за да ја поттикнеме идната работа, ние обезбедуваме резултати за сегашните најсовремени системи за резолуција на негативите за три англиски корпора, и да го направиме нашето спроведување на сценаријата за проценка јавно достапни.', 'mt': "F'dan id-dokument, aħna nirrevedu l-kompitu tar-riżoluzzjoni tan-negazzjoni, li jinkludi s-sottomistoqsijiet tal-identifikazzjoni tal-indikazzjonijiet (e ż. 'mhux', 'qatt') u r-riżoluzzjoni tal-ambitu. Fil-kuntest ta’ kompiti kondiviżi preċedenti, ġew proposti varjetà ta’ metriċi ta’ evalwazzjoni. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult.  L-eżaminazzjoni tal-problem a kemm minn perspettiva lingwistika kif ukoll minn perspettiva ’l isfel, hawnhekk a ħna argumentaw għal approċċ ibbażat fuq l-istanza ta’ negazzjoni għall-evalwazzjoni tar-riżoluzzjoni tan-negazzjoni. Il-metriċi proposti tagħna jikkorrispondu mal-aspettattivi fuq il-punteġġi ta’ kull każ u għalhekk huma interpretabbli intwittivament. Biex ir-riċerka ssir komparabbli u biex titrawwem ix-xogħol futur, a ħna nipprovdu riżultati għal sett ta' sistemi moderni attwali għar-riżoluzzjoni tan-negazzjoni fuq tliet korpi Ingliżi, u nagħmlu l-implimentazzjoni tagħna tal-iskripti ta' evalwazzjoni disponibbli għall-pubbliku.", 'pl': 'W niniejszym artykule przedstawiamy zadanie rozdzielczości negacji, które obejmuje podzadania detekcji cue (np. "nie", "nigdy") i rozdzielczości zakresu. W kontekście poprzednich wspólnych zadań zaproponowano różne wskaźniki oceny. Kolejne prace zazwyczaj używają różnych podzbiorów, w tym wariantów i implementacji niestandardowych, co utrudnia znaczące porównania między systemami. Analizując problem zarówno z perspektywy językowej, jak i z perspektywy dalszej, opowiadamy się tutaj za podejściem opartym na negacji instancji do oceny rozwiązywania negacji. Nasze proponowane wskaźniki odpowiadają oczekiwaniom dotyczącym wyników poszczególnych instancji i dlatego są intuicyjnie interpretowalne. Aby uczynić badania porównywalne i wspierać przyszłą pracę, dostarczamy wyniki dla zestawu aktualnych systemów rozwiązywania negacji na trzech angielskich korporach oraz udostępniamy naszą implementację skryptów oceniających.', 'ml': "In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. 'not', 'never') and scope resolution.  മുമ്പ് പങ്കുചേര്\u200dന്ന ജോലികളുടെ കൂട്ടത്തില്\u200d, വ്യത്യസ്തമായ വില മെറ്റിക്ക് പ്രായശ്ചിത്തമാണ്. പിന്നീട് പ്രവര്\u200dത്തിക്കുന്ന ജോലികള്\u200d സാധാരണ വ്യത്യസ്ത വിഭാഗങ്ങളില്\u200d ഉപയോഗിക്കുന്നു, വേരിഷങ്ങളും സ്വകാര്യ പ്രവര്\u200d ഭാഷകങ്ങളുടെ ഭാഷയില്\u200d നിന്നും താഴെ നദിയില്\u200d നിന്നും പ്രശ്നത്തില്\u200d നിന്നും പരിശോധിക്കുന്ന പ്രശ്നം നമ്മളിവിടെ നെഗറേഷന്\u200d സിസ്റ നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മെട്രിക്കങ്ങള്\u200d ഓരോ ഉദാഹരണത്തിനും പ്രതീക്ഷിക്കുന്ന പ്രതീക്ഷകള്\u200dക്കും സമ്മത ഭാവിയുടെ ജോലി തുല്യമാക്കുവാനും നാം നിലവിലുള്ള സിസ്റ്റേറ്റ് സിസ്റ്റം സംവിധാനങ്ങള്\u200dക്ക് ഫലങ്ങള്\u200d നല്\u200dകുന്നു, മൂന്നു ഇംഗ്ലീഷ് കോര്\u200dപ്പോരിയില", 'mn': "Энэ цаасан дээр бид хасах шийдвэрлэлийн даалгаврыг дахин дахин дахин дахин шийдвэрлэдэг. Энэ нь тэмдэглэл тогтоох (жишээ нь биш, хэзээ ч биш') болон шийдвэрлэл юм. Өмнөх хуваалтын ажлын турш олон төрлийн үнэлгээний метрик санал өгсөн. Дараа нь эдгээрийн өөр хэсгийг ашигладаг, өөрчлөлт, хувилбар хэрэгжүүлэх, системийн хоорондын утгатай харьцуулалт хэцүү. Энэ асуудлыг хэлний харцгаанаас болон доорх харцгаанаас шалгахад бид сөрөг тохиолдлыг шалгахын тулд сөрөг тохиолдлыг үнэлэх арга барилгын тухай ярьж байна. Бидний санал дэвшүүлсэн метрик нь инстанц дээр илүү олон хүлээн зөвшөөрөгдөж байгаа юм. Иймээс илүү ойлгомжтой. Ирээдүйн ажлыг харьцуулах болон дэмжих судалгааны хувьд бид 3 Англи хэлний корпоратын хамааралтай шийдвэрлэх үйл явдал дээр орчин үеийн урлагийн системийн үр дүнг гаргаж, үнэлгээний бичгийг олон нийтэд ашиглаж чадна.", 'no': 'I denne papiret gjenoppretter vi oppgåva for negasjonsoppløysing, som inneheld underspørsmåla for oppdaging av teikn (t.d. «ikkje», «aldri») og oppløysing av området. I konteksten av tidlegare delte oppgåver er det foreslått mange evalueringsmetrikar. Neste arbeidar vanlegvis brukar ulike undergrupper av desse, inkludert variasjonar og eigendefinerte implementasjonar, og viser meningsverdiane samanlikning mellom systemet vanskeleg. Eksempel på problemet både frå ein lingvisk perspektiv og frå ein nedstrekksynspunkt, argumenterer vi her for ein negasjonsinstans basert tilnærming til å evaluera negasjonsoppløysing. Våre foreslått metrikar tilsvarar forventingar over kvar instans- poeng og derfor er intuitivt tolkbar. For å gjera forskningssammenlignbar og for å forstørra framtidige arbeid, gir vi resultat for eit sett av gjeldande kunstsystemet for negasjonsoppløysing på tre engelsk korpora, og gjera vårt implementasjon av evalueringsskriptene offentlig tilgjengeleg.', 'ro': 'În această lucrare, revizuim sarcina rezoluției negației, care include subactivitățile detectării tacului (de exemplu, "nu", "niciodată") și rezoluția scopului. În contextul sarcinilor partajate anterioare, au fost propuse o varietate de valori de evaluare. Lucrările ulterioare folosesc, de obicei, diferite subseturi ale acestora, inclusiv variații și implementări personalizate, făcând comparații semnificative între sisteme dificile. Examinând problema atât din perspectivă lingvistică, cât și din punct de vedere din aval, argumentăm aici pentru o abordare bazată pe instanțe de negare a evaluării rezolvării negațiilor. Valorile noastre propuse corespund așteptărilor privind scorurile pe instanță și, prin urmare, sunt interpretabile intuitiv. Pentru a face cercetarea comparabilă și pentru a promova activitatea viitoare, oferim rezultate pentru un set de sisteme actuale de ultimă generație pentru rezolvarea negațiilor pe trei corpore engleze și punem la dispoziție public implementarea scripturilor de evaluare.', 'sr': "U ovom papiru reviziramo zadatak rezolucije negacije, koji uključuje podstaze detekcije znakova (npr. ne', 'nikad') i rezolucije opcije. U kontekstu prethodnih zajedničkih zadataka predloženo je razne mjere procjene. Sljedeći radovi obično koriste različite podsjetnike tih podsjetnika, uključujući varijacije i obične implementacije, čineći smislene usporedbe između sistema teško. Ispitivajući problem i iz jezičke perspektive i iz nižeg pogleda, ovdje se raspravljamo za negativni pristup procjene rezolucije negacije. Naša predložena metrika odgovara oèekivanjima preko rezultata svakog instanca i stoga su intuitivno interpretabilne. Da bi se istraživanje usporedilo i podržalo budući rad, pružili smo rezultate za skup trenutnih državnih umjetničkih sistema za rezoluciju negacije o tri engleskog korpora, i javno omogućili naše provedbe procjenskih skripta.", 'so': "Qoraalkan waxaynu ku qornaa shaqada go'aanka diiwaanka, kaasoo ku jira samooyinka ku baaqashada kooxaha (tusaale ahaan'aan', 'marna') iyo go'aanka kooban. Marka lagu jiro shuqullada hore oo la qaybsaday waxaa la soo jeeday qiimeyn kala duduwan. Shaqooyinka soo socda sida caadiga ah waxay isticmaalaan kooxo kala duduwan, kuwaas oo ka mid ah beddelaadyo iyo hababka caadiga ah, waxayna ka dhigayaan isbardhigyo faa'iido leh oo ku adag nidaamka dhexdooda. Tan waxaan ka baaraynaa dhibaatada aragtida luqada iyo aragtida hoose ee webiga, halkan waxaynu ka doodaynaa qaab ku saabsan qiimeynta go'aanka diidmada. Wadamada la soo jeeday waxay u eg yihiin rajada tusaale ahaan, taas darteed waxaa loo turjumi karaa si caqli ah. Si aan u sameyno waxbarasho u eg iyo horumarinta shaqada mustaqbalka, waxaynu u siinaynaa koox kamid ah nidaamka xaaladda-farshaxanta, si ay u sameeyaan go'aanka burburka saddexda shirkad oo Ingiriis ku qoran, waxaana si bayaan ah u sameynaynaa qoraalka qiimeynta.", 'sv': 'I denna uppsats går vi igenom uppgiften med negationslösning, som inkluderar underaktiviteterna för cue detection (t.ex. "inte", "aldrig") och scope resolution. I samband med tidigare delade uppgifter har en mängd utvärderingsmetoder föreslagits. Efterföljande arbeten använder vanligtvis olika delmängder av dessa, inklusive variationer och anpassade implementeringar, vilket gör meningsfulla jämförelser mellan system svåra. Genom att undersöka problemet både ur ett språkligt perspektiv och från ett nedströms perspektiv argumenterar vi här för ett negationsinstansbaserat tillvägagångssätt för att utvärdera negationslösning. Våra föreslagna mätvärden motsvarar förväntningarna över poäng per instans och är därför intuitivt tolkningsbara. För att göra forskningen jämförbar och främja framtida arbete tillhandahåller vi resultat för en uppsättning aktuella state-of-the-art system för negation resolution på tre engelska korpora, och gör vår implementering av utvärderingsskripten offentligt tillgänglig.', 'si': 'මේ පත්තරේදී, අපි ප්\u200dරතික්\u200dරියාත්මක විශේෂණයේ ක්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක කරනවා, ඒ වගේම cue පරීක්ෂණයේ ප්\u200dරතික්\u200dරි මුලින් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් මෙට්\u200dරික්ස් විවිදියට ප්\u200dරතිචාරයක් තියෙනවා. පස්සේ වැඩ කරනවා සාමාන්\u200dයයෙන්ම වෙනස් සම්බන්ධයක් පාවිච්චි කරන්න, වෙනස් සහ සැකසුම් පද්ධතිය අතර අමාරුයි,  භාෂාත්මක ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් පරීක්ෂණය කරනවා වගේම පහත් ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් පරීක්ෂණය කරනවා අපේ ප්\u200dරයෝජනය ප්\u200dරමාණයක් ප්\u200dරමාණයකට ප්\u200dරමාණයක් වෙනුවෙන් ඉන්න ප්\u200dරමාණයකට සම්බන්ධ වෙන්න පුළුවන් ව ඉංග්\u200dරීසි කොර්පෝරා තුන්දෙනුවෙන් අනාගතයේ වැඩ සඳහා පරීක්ෂණය සඳහා ප්\u200dරතිචාරයක් සඳහා ප්\u200dරතිචාරයක් දෙන්න, අපි ඉංග්\u200dරීසි කොර', 'ta': 'இந்த காக்கியத்தில், நாம் எதிர்மறை தெளிவுத்திறன் பணியை மீண்டும் திரும்பச் செய்கிறோம், அது கூய் கண்டுபிடிப்பதின் உப ச்செயல் முந்தைய பகிர்ந்த பணிகளின் சூழலில், பல மதிப்பு முறைகள் பரிந்துரைக்கப்பட்டுள்ளது. பின்வரும் வேலைகள் வழக்கமாக மாறிகள் மற்றும் தனிப்பயன் செயல்பாடுகளை பயன்படுத்தும், முறைமைகளுக்கிடையில் மிகவும் கடினமா இந்த பிரச்சனையை மொழிமாற்றும் காட்சியிலிருந்தும் தேர்ந்தெடுத்து, நாம் இங்கு எதிர்மறை தெளிவுத்திறனை மதிப்பதற்கான எதிர்ம ம ஒவ்வொரு உதாரணத்திற்கும் மேல் எதிர்பார்ப்புகளுக்கும் எதிர்பார்ப்புகளுக்கு பொருத்தமான மெட்ரிக்கள்  ஆராய்ச்சி ஒப்பிட்டு மற்றும் எதிர்கால வேலையை உயர்த்த வேண்டுமானால், நாம் தற்போதைய நிலைமை- கலை அமைப்புகளுக்கு முடிவுகளை வழங்குகிறோம் -மூன்ற', 'ur': 'اس کاغذ میں ہم نے ناپسندیدہ حل کے کام کو دوبارہ تغییر کر دیا ہے، جس میں علائم شناسایے کے (مثال نہیں، ہرگز نہیں)، اور سطح حل کے مطابق شامل ہے۔ پہلے مشترک کاموں کے بارے میں ایک مختلف ارزیابی متریک پیشنهاد کی گئی ہے. اس کے بعد ان میں سے مختلف سوسٹوں کو معمولاً استعمال کرتا ہے، مختلف طریقے کے ساتھ اور تنظیم عملومات کے ساتھ، سیستموں کے درمیان مطلوب مقایسات کا رینڈر کرتا ہے. اس مسئلہ کی تحقیق میں ایک زبان کی نظر سے اور ایک نیچے نظر پوینٹ سے، ہم یہاں ایک منفی مثال کے ذریعہ سے منفی رخصت کے لئے جھگڑتے ہیں۔ ہمارے مقرر کردہ میٹریک ایک مثال کے اسکور پر انتظار کے مطابق مطابق ہے اور اس کے نتیجہ میں نظریہ تفسیر قابل ہے اس لئے کہ تحقیقات مقایسہ اور مستقبل کام کے ساتھ اضافہ کرنے کے لئے، ہم تین انگلیسی کورپور پر ناپسند کرنا کے لئے موجود حالت کی سیستم کے لئے نتیجے پیش کرتے ہیں، اور ہماری تحقیقات کے اسکریٹوں کو ظاہر طور پر موجود بناتے ہیں.', 'uz': "Bu qogʻozda, biz qanday qilish muvaffaqiyatlarini qaytadan qayta yuboramiz. Bu xususiyatlarning tub vazifalarini (m.g. 'hech qachon') va scope oʻlchamini oʻzgartirish mumkin. Oldingi bilan bogʻliq vazifalar davomida, bir necha qiymatlar metriklarini talab qilindi. Comment Bu muammolarni lingʻlik koʻrinishining fikrini tekshirish va quyidagi oynalarni ko'rib chiqqamiz, biz bu yerda negativ usulni qiymatga asoslangan qanday qilish uchun murakkab qilamiz. Bizning talab qilingan metriklarimiz bir misol scorida kutilgan kutilgan kutilgan kutilgan narsalarga ega bo'ladi va shunday qilib o'rganish kerak. Tafitini o'xshash qilish va kelajakdagi ishni foydalanish uchun, biz 3 Ingliz kompaniya uchun hech qanday holatning holati tizimlarini yozib olish uchun natijalarni bajaramiz, va bizni qiymatlar skriptlarini ko'paytirish mumkin.", 'vi': 'Trong bài báo này, chúng ta phải xem lại nhiệm vụ giải quyết cấm đoán, bao g ồm các yêu cầu tìm dấu chấm (v.d. không, không bao giờ) và giải quyết phạm vi. Đối với các công việc chia sẻ trước đó, đã đề xuất một số lượng tử đo đánh giá khác nhau. Những tác phẩm sau thường sử dụng các nhóm khác nhau trong những thứ này, bao gồm sự biến đổi và dụng cụ riêng, khiến so sánh có ý nghĩa giữa hệ thống khó khăn. Nghiên cứu vấn đề này từ một khía cạnh ngôn ngữ và từ một khía cạnh xuôi dòng, chúng tôi ủng hộ một phương pháp dựa trên trường hợp cấm đoán để đánh giá giải pháp cấm. Những thứ đo như dự kiến tương ứng với mong đợi trên điểm mỗi lần và do đó là trực tiếp thể hiểu. Để làm nghiên cứu tương đối và thúc đẩy công việc tương lai, chúng tôi cung cấp kết quả cho một loạt hệ thống hiện đại để giải quyết âm bản về ba bằng hữu Anh Quốc, và công khai việc thực hiện các kịch bản đánh giá.', 'nl': "In dit artikel bespreken we de taak van ontkenning resolutie, die de subtaken van cue detectie (bijv. 'not', 'never') en scope resolutie omvat. In de context van eerdere gedeelde taken zijn verschillende evaluatiestatistieken voorgesteld. Latere werken gebruiken meestal verschillende subsets van deze, waaronder variaties en aangepaste implementaties, waardoor betekenisvolle vergelijkingen tussen systemen moeilijk worden. Door het probleem zowel vanuit een linguïstisch perspectief als vanuit een downstream perspectief te onderzoeken, pleiten we hier voor een op negatie gebaseerde benadering van het evalueren van ontkenningsoplossing. Onze voorgestelde metrics komen overeen met verwachtingen over scores per instantie en zijn daardoor intuïtief te interpreteren. Om onderzoek vergelijkbaar te maken en toekomstig werk te bevorderen, leveren we resultaten voor een reeks huidige state-of-the-art systemen voor ontkenningsresolutie op drie Engelse corpora's en maken we onze implementatie van de evaluatiescripts openbaar.", 'da': 'I denne artikel gennemgår vi opgaven med negation resolution, som omfatter underopgaverne med cue detection (f.eks. "ikke", "aldrig") og scope resolution. I forbindelse med tidligere delte opgaver er der foreslået en række evalueringsmetrics. Efterfølgende værker bruger normalt forskellige delmængder af disse, herunder variationer og brugerdefinerede implementeringer, hvilket gør meningsfulde sammenligninger mellem systemer vanskelige. Når vi undersøger problemet både fra et sprogligt perspektiv og fra et downstream synspunkt, argumenterer vi her for en negationsinstans baseret tilgang til evaluering af negationsløsning. Vores foreslåede metrics svarer til forventningerne til pr. instans scores og kan derfor fortolkes intuitivt. For at gøre forskningen sammenlignelig og fremme fremtidigt arbejde leverer vi resultater for et sæt nuværende state-of-the-art systemer til negation resolution på tre engelske korpora, og gør vores implementering af evalueringsscripts offentligt tilgængelig.', 'de': 'In diesem Beitrag beleuchten wir die Aufgabe der Negationsauflösung, die die Teilaufgaben der Cue-Erkennung (z.B. "not", "never") und der Scope-Auflösung umfasst. Im Rahmen früherer gemeinsamer Aufgaben wurden verschiedene Bewertungsmetriken vorgeschlagen. Nachfolgende Arbeiten verwenden in der Regel verschiedene Teilmengen davon, einschließlich Variationen und benutzerdefinierte Implementierungen, was aussagekräftige Vergleiche zwischen Systemen erschwert. Betrachtet man das Problem sowohl aus sprachlicher als auch aus nachgelagerter Sicht, argumentieren wir hier für einen negationsinstanzbasierten Ansatz zur Bewertung der Negationslösung. Unsere vorgeschlagenen Metriken entsprechen den Erwartungen an die einzelnen Instanzen und sind daher intuitiv interpretierbar. Um Forschung vergleichbar zu machen und zukünftige Arbeiten zu fördern, stellen wir Ergebnisse für eine Reihe aktueller Systeme zur Negationsauflösung auf drei englischen Korpora zur Verfügung und machen unsere Implementierung der Evaluationsskripte öffentlich zugänglich.', 'bg': 'В тази статия преразглеждаме задачата за решаване на отрицания, която включва подзадачите за откриване на сигнали (напр. "не", "никога") и разделяне на обхвата. В контекста на предишни споделени задачи бяха предложени различни показатели за оценка. Следващите работи обикновено използват различни подгрупи от тях, включително вариации и персонализирани реализации, което прави смислените сравнения между системите трудни. Разглеждайки проблема както от лингвистична гледна точка, така и от гледна точка надолу по веригата, ние тук спорим за подход, основан на отрицателни инстанции, за оценка на разрешаването на отрицанията. Нашите предложени показатели съответстват на очакванията за оценките на дадена инстанция и следователно са интуитивно интерпретирани. За да направим изследванията сравними и да насърчим бъдещата работа, ние предоставяме резултати за набор от съвременни системи за решаване на отрицания на три английски корпора и правим внедряването на скриптовете за оценка публично достъпно.', 'id': "Dalam kertas ini, kita mengulangi tugas resolusi negati, yang termasuk subtasks deteksi sinyal (contohnya 'tidak', 'tidak pernah') dan resolusi skop. Dalam konteks tugas berbagi sebelumnya, banyak metrik evaluasi telah diusulkan. Pekerjaan berikutnya biasanya menggunakan subkelompok yang berbeda dari ini, termasuk variasi dan implementasi suai, membuat perbandingan yang berarti antara sistem sulit. Memeriksa masalah dari sudut pandang bahasa dan dari sudut pandang turun, kami di sini berdebat untuk pendekatan berdasarkan contoh negatif untuk mengevaluasi resolusi negatif. Metrik yang diusulkan kita cocok dengan harapan atas skor per contoh dan oleh itu intuitif dapat diterjemahkan. Untuk membuat penelitian dapat dibandingkan dan untuk mendorong pekerjaan masa depan, kami menyediakan hasil untuk set sistem terbaik saat ini untuk resolusi negatif pada tiga korpora Inggris, dan membuat implementasi kami skrip evaluasi tersedia publik.", 'ko': "본고에서 우리는 부정적 해소의 임무를 되돌아봤다. 단서 검측(예를 들어'아니오','아니오'와 범위 해소의 하위 임무를 포함한다.이전에 임무를 공유한 배경에서 각종 평가 지표를 제시했다.후속 작업은 일반적으로 그 중의 서로 다른 서브집합을 사용하는데 변체와 사용자 정의 실현을 포함하기 때문에 시스템 간에 의미 있는 비교를 하기 어렵다.우리는 언어학의 측면과 하류의 측면에서 이 문제를 연구하고 이를 통해 부정 실례를 바탕으로 부정 해결을 평가하는 방법을 사용하자고 주장한다.우리가 제시한 지표는 모든 실례의 득점에 대한 기대에 대응하기 때문에 직관적으로 해석할 수 있다.연구를 비교할 수 있고 미래의 업무를 추진하기 위해 우리는 세 개의 영어 어료 라이브러리에 현재 가장 선진적인 부정 해소 시스템의 결과를 제공하고 우리의 평가 각본의 실시를 공개했다.", 'sw': 'Katika gazeti hili, tunapitia jukumu la suluhisho la hasi, ambalo linajumuisha majukumu ya uchunguzi wa koma (kama vile ‘sio’, ‘kamwe’) na suluhisho la kupunguza. Katika mukhtadha wa shughuli za zamani zilizoshirikishwa, mbinu mbalimbali za uchunguzi zimependekezwa. Kazi za baadae huwa hutumia makundi mbalimbali ya aina hii, ikiwa ni pamoja na mabadiliko na kutekeleza matumizi ya utamaduni, na kufanya ulinganisho wenye maana kati ya mifumo vigumu. Kujaribu tatizo hilo linatokana na mtazamo wa lugha na kutokana na mtazamo wa mito ya chini, hapa tunahojiana kwa njia yenye hasi ya kutathmini suluhisho la hasi. mbinu zetu zilizopendekezwa zinalinganisha na matarajio ya juu ya vipindi vya kila mfano na hivyo vinaelezea ufanisi. Ili kufanya utafiti unafananisha na kukuza kazi za baadae, tunatoa matokeo ya mfumo wa sasa wa hali ya sanaa kwa ajili ya suluhisho la uchochezi kwenye makampuni matatu ya Kiingereza, na kutekeleza utumiaji wetu wa maandiko ya uchunguzi unapatikana hadharani.', 'tr': "Bu kagyzda, biz çözümlenme çözümleriniň g örevini terjime edip, bu da cuer deteksiyonyň çözümlerini (meselâ, 'däl', 'hiç', 'hiç') we süýşikligini dahil edýäris. Öňki paýlaşan zadlaryň kontekstinde birnäçe deňlenme metrikleri teklip edildi. Sonra işlemler genellikle farklı bir subsetlerini kullanır, değişiklikler ve şahsel uygulamalar, sistemler arasında anlamlı karşılaştırmalar zorlaştırır. Meseläni lingwistiki perspektivden hem a şaky görnüşden hem çykyş noktalardan çykyp, bärde negativ instansiýanyň çözümlerini çykmak üçin taryşýarys. Biziň teklip eden metriklerimiz instansiýa notlaryň üstünde gözlenmelere meňzeýär we şonuň üçin intuitiv terjime edilebilir. Araştyrymyzy görşikli we gelejekde işi täzeden çykarmak üçin, biz häzirki möhüm sanat sistemalarynyň üç iňlisçe korporatyň çözümlenmesi üçin netijesini berýäris we çözümlenme skriptlerini halkara mejbur etmäge rugsat berýäris.", 'hr': "U ovom papiru reviziramo zadatak rezolucije negacije, koji uključuje podstaze otkrivanja znakova (npr. ne', 'nikad') i rezolucije opsega. U kontekstu prethodnih zajedničkih zadataka predloženo je razne mjere procjene. Sljedeći radovi obično koriste različite podsjetnike tih podsjetnika, uključujući varijacije i obične provedbe, čineći smislene usporedbe između sustava teško. Ispitivajući problem i iz jezičke perspektive i iz nižeg pogleda, ovdje se raspravljamo za negativni pristup procjene rezolucije negacija. Naša predložena metrika odgovara očekivanjima iznad rezultata svake instance i stoga su intuitivno interpretabilne. Za usporedbu istraživanja i podizanje budućeg rada, pružamo rezultate za skup trenutnih državnih umjetničkih sustava za rezoluciju negacije o tri engleskog korpora i javno omogućavamo provedbu procjenskih skripta.", 'fa': 'در این کاغذ، ما کار تغییر تغییر تغییر دهیم، که شامل تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغییر تغ در محیط کارهای مشترک پیشین، متریک های ارزیابی مختلف پیشنهاد شده است. کارهای بعدی معمولاً از زیر زیر\u200cهای مختلف این\u200cها استفاده می\u200cکنند، شامل تغییرات و کاربردهای شخصی، مقایسه\u200cهای معنی بین سیستم\u200cها سخت می\u200cشود. تحقیق مشکل هر دو از یک نگاه زبان و از یک نقطه نظر پایین، ما در اینجا برای یک طریق بنیاد منفی برای ارزیابی حل منفی بحث می کنیم. متریک پیشنهاد ما با انتظارهای بیشتر از امتیاز هر مثال تعبیر می کنند و بنابراین قابل تفسیر به نظر می رسد. برای مقایسه کردن تحقیقات قابل مقایسه و تحویل کار آینده، نتیجه\u200cها را برای مجموعه\u200cی سیستم\u200cهای موجود هنری برای حل\u200cسازی ناپذیری در سه شرکت انگلیسی ارائه می\u200cدهیم، و عملکرد ما از نوشته\u200cهای ارائه\u200cسازی را به طور عمومی در دسترس', 'hy': 'Այս թղթի մեջ մենք վերադառնում ենք բացասական լուծումների խնդիրը, որը ներառում է ազդանշանների հայտնաբերման ենթախնդիրները (օրինակ «ոչ», «երբեք») և դիրքի լուծումները: Անցյալ ընդհանուր խնդիրների համատեքստում մի շարք գնահատման չափումներ են առաջարկվել: Հաջորդ աշխատանքները սովորաբար օգտագործում են դրանց տարբեր ենթախմբեր, ներառյալ տարբերությունները և հատուկ իրականացումները, որոնք դժվարանում են համակարգերի միջև իմաստալից համեմատությունները: Խնդիրը լեզվաբանական տեսանկյունից և հետագա տեսանկյունից ուսումնասիրելով, մենք այստեղ պնդում ենք բացասական օրինակով հիմնված մոտեցում բացասական լուծումների գնահատման համար: Our proposed metrics correspond to expectations over per-instance scores and hence are intuitively interpretable.  Հետազոտությունները համեմատական դարձնելու և ապագա աշխատանքի խրախուսելու համար մենք ապահովում ենք արդյունքներ ներկայիս ամենահետաքրքիր համակարգերի համար, որոնք օգտագործում են բացասական լուծումները երեք անգլերեն կոպորա վրա, և հանրային հասանելիություն դարձնում ենք գնահատման գրքերի իրական', 'am': 'በዚህ ገጽ፣ የቁም ማስታወቂያውን (ለምሳሌ ‹‹ከቶ›› አይደለም) እና የመስመር ማስታወቂያውን የሚጨምር የክፋት መልዕክት እናስመለሳለን፡፡ የቀድሞው በተካፈሉት ስራዎች ውስጥ፣ በተለያዩ ማስታወቂያ ማተሚያዎች ተዘጋጅቷል፡፡ የሚከተሉት ሥራ በተለያዩ ክፍሎች እና የተለየ ጥያቄዎችን በተጨማሪነት እና በተለየ ጥያቄዎች በተጨማሪው የስርዓት መካከልም የሚያስታወቅ ትክክል እንዲያደርጉ ይጠይቃሉ፡፡ የቋንቋዊ ስህተት እና ከታችኛው ውይይት እና ጉዳዩን በመፈትነው፣ በዚህ የnegative መልስ አካሄድን ለማስተካከል ለመቆጣጠር እንዋጋለን፡፡ የተዘጋጀን መተላለፊያ ለሁሉም ጥያቄዎች የሚደረገውን ተስፋዎች እና ስለዚህም አስተያየት ይችላል፡፡ ትምህርት ለመተካከል እና ለኋለኛይቱ ሥራ ለማሳደግ ፍሬዎችን ለመቀናቀል፣ በሦስት እንግሊዝኛ ኮርፖርት ላይ የጥላቻን የሥርዓት ሥርዓት እናደርጋለን፡፡', 'sq': "Në këtë letër, ne përsërisim detyrën e rezolutës së negativës, e cila përfshin nëndetyrat e zbulimit të shenjave (për shembull 'jo', 'kurrë') dhe rezolutën e fushës. Në kontekstin e detyrave të përbashkëta të mëparshme, janë propozuar një shumëllojshmëri metrike vlerësimi. Punët e mëvonshme zakonisht përdorin nëngrupe të ndryshme të këtyre, duke përfshirë variacione dhe zbatimin e personalizuar, duke bërë të vështira krahasime të kuptueshme midis sistemeve. Duke shqyrtuar problemin nga një perspektivë gjuhësore dhe nga një pikëpamje poshtë, ne këtu argumentojmë për një qasje të bazuar në shembull negativ për vlerësimin e rezolutës negative. Metrikat tona të propozuara korrespondojnë me shpresat mbi rezultatet për çdo rast dhe kështu janë të interpretueshme intuitivisht. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.", 'bn': "এই পত্রিকায় আমরা নেতিবাচক সিদ্ধান্তের কাজের পুনরায় পুনরায় প্রতিবেদন করি, যার মধ্যে কু আবিষ্কারের (যেমন 'না', 'কখনোই') এবং স্কোপ সিস In the context of previous shared tasks, a variety of evaluation metrics have been proposed.  পরবর্তীতে কাজ সাধারণত সিস্টেমের মধ্যে কঠিন তুলনায় বিভিন্ন বিভিন্ন সাবস্টগুলো ব্যবহার করে, যার মধ্যে ভিন্ন ভিন্ন ভ ভাষার ভাষার দৃষ্টিভঙ্গি থেকে এবং নিচের নদীর দৃষ্টিভঙ্গি থেকে সমস্যা পরীক্ষা করা হচ্ছে, আমরা এখানে নেতেশনের সিদ্ধান্তের মূল্যের ব আমাদের প্রস্তাবিত মেট্রিক প্রতি উদাহরণ স্কোরের প্রতি প্রত্যেক প্রতিশ্রুতির সাথে যুক্ত এবং এর ফলে বুদ্ধিমান গবেষণার সমতুল্য এবং ভবিষ্যতের কাজ উৎপাদনের জন্য আমরা বর্তমান রাষ্ট্র-অফ-শিল্প সিস্টেমের ফলাফল প্রদান করি তিন ইংরেজি কর্পোরায় নেতিবেশনের জন্য এবং মূল্য স", 'ca': 'En aquest paper, revisem la tasca de resolució de negatió, que inclou les subtaskes de detecció de signes (com per exemple "no", "mai") i resolució de portada. En el context de tasques compartides anteriors, s\'han proposat diverses mètriques d\'evaluació. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult.  Analitzant el problem a tant d\'una perspectiva lingüística com d\'un punt de vista avall, aquí argumentem per un enfocament basat en una instancia de negatió a l\'evaluació de la resolució de negatió. Les nostres mètriques proposades corresponden a les expectatives sobre puntuacions per instant i, per tant, són intuïtivament interpretables. Per fer la recerca comparable i fomentar el treball futur, proporcionem resultats per a un conjunt de sistemes actuals d\'última generació de resolució de negatió en tres corpores anglesos, i fer pública la nostra implementació dels escripts d\'evaluació.', 'cs': 'V tomto článku se zabýváme úkolem rozlišení negace, který zahrnuje podúkoly detekce cue (např. "ne", "nikdy") a rozlišení rozsahu. V kontextu předchozích sdílených úkolů byla navržena řada hodnotících metrik. Následující práce obvykle využívají různé podmnožiny těchto skupin, včetně variací a vlastních implementací, což ztěžuje smysluplné srovnání mezi systémy. Při zkoumání problému z jazykového i následného hlediska zde argumentujeme pro přístup založený na negativní instanci k hodnocení řešení negace. Naše navrhované metriky odpovídají očekáváním ohledně skóre jednotlivých instancí a jsou tedy intuitivně interpretovatelné. Pro srovnatelnost výzkumu a podporu budoucí práce poskytujeme výsledky souboru současných nejmodernějších systémů pro řešení negací na třech anglických korpusech a zveřejňujeme implementaci evaluačních skriptů.', 'et': 'Käesolevas dokumendis vaatame uuesti läbi negatiivse lahendamise ülesande, mis hõlmab vihje tuvastamist (nt "mitte", "mitte kunagi") ja ulatuse lahendamist. Varasemate jagatud ülesannete kontekstis on esitatud mitmesuguseid hindamismeetodeid. Järgnevates töödes kasutatakse tavaliselt nende erinevaid alamhulke, sealhulgas variatsioone ja kohandatud rakendusi, mis muudab süsteemide sisulise võrdluse raskeks. Analüüsides probleemi nii keelelisest vaatenurgast kui ka allpoolsest vaatenurgast, toetame siin negatsiooni juhtumipõhist lähenemisviisi negatsiooni lahendamise hindamisel. Meie pakutud mõõdikud vastavad ootustele ühe eksemplari skoori kohta ja on seega intuitiivselt tõlgendatavad. Teadustöö võrreldavaks muutmiseks ja edasise töö edendamiseks anname tulemusi kolme inglise korpuse negatiivse lahendamise praeguste kaasaegsete süsteemide kohta ning teeme hindamisskriptide rakendamise avalikult kättesaadavaks.', 'az': 'Bu kağızda, biz negativ çözünürlük işlərini yenidən dəyişdiririk, bu da cue detection (məsələn, deyil, heç vaxt) və scope çözünürlüklərini dahil edər. Əvvəlki paylaşılmış işlərin məlumatında, müxtəlif değerlendirmə metrikləri təbliğ edilmişdir. Sonrakı işlər genellikle müxtəlif subgruplarını istifadə edir, variasiyaları və şəkildə istifadə edirlər, sistemlərin arasında anlamlı müxtəlif müxtəlif müxtəliflər göstərirlər. Həmçinin dil perspektivindən və a şağı görünüş nöqtəsindən problemi təsdiqləmək üçün negasyon instansiyasından təsdiqlənmək üçün mübahisə edirik. Bizim təbliğ etdiyimiz metriklərimiz hər instanslı nöqtələrin üstündə gözləmələrə uyuşar və buna görə də intuitiv təfsil edilə bilər. Araştırmaları salışılabilir və gələcək işi art ırmaq üçün, üç İngilizə korporasında negativ çözünürlük sistemlərinin müəyyən edilməsi üçün, müəyyən edilmə skriptlərini a çıq-aşkar mövcuddur.', 'af': "In hierdie papier, ons hersien die taak van negasie oplossing, wat die subtaske van cue-opdekking (bv. 'n nie', 'nooit') en omvang-oplossing insluit. In die konteks van vorige gedeelde taak is 'n verskillende evalueringsmetries voorgestel. Volgende werke gebruik gewoonlik verskillende subartikels van hierdie, insluitend veranderinge en pasmaak implementasies, wys betekende vergelykings tussen stelsels moeilik. Ons ondersoek die probleem beide van 'n lingvisiese perspektief en van 'n onderstreem aansigpunt, hier argueer ons vir 'n negatiewe voorbeeld gebaseerde toegang om negatiewe oplossing te evalueer. Ons voorgestelde metries ooreenstem met verwagtings oor per instansie telling en daarom is intuitief uittelbare. Om ondersoek vergelykbaar te stel en toekomstige werk te verskaf, verskaf ons resultate vir 'n stel van huidige staat-van-kunstenstelsels vir negasie-oplossing op drie Engelske korpora en ons implementasie van die evalueringsskripte openlik beskikbaar maak.", 'fi': 'Tﾃ､ssﾃ､ artikkelissa tarkastelemme uudelleen kieltﾃ､misen ratkaisun tehtﾃ､vﾃ､ﾃ､, joka sisﾃ､ltﾃ､ﾃ､ alatehtﾃ､vﾃ､t vihjeen havaitseminen (esim. "ei", "ei koskaan") ja soveltamisalan ratkaiseminen. Aiempien yhteisten tehtﾃ､vien yhteydessﾃ､ on ehdotettu erilaisia arviointimittareita. Myﾃｶhemmissﾃ､ tﾃｶissﾃ､ kﾃ､ytetﾃ､ﾃ､n yleensﾃ､ eri osajoukkoja nﾃ､istﾃ､, mukaan lukien variaatioita ja mukautettuja toteutuksia, mikﾃ､ vaikeuttaa jﾃ､rjestelmien merkityksellistﾃ､ vertailua. Tarkastellessamme ongelmaa sekﾃ､ kielellisestﾃ､ ettﾃ､ loppupﾃ､ﾃ､n nﾃ､kﾃｶkulmasta vaadimme tﾃ､ssﾃ､ kieltﾃ､miseen perustuvaa lﾃ､hestymistapaa kieltﾃ､misen ratkaisun arviointiin. Ehdotetut mittarit vastaavat odotuksia tapauskohtaisesta pistemﾃ､ﾃ､rﾃ､stﾃ､ ja ovat siten intuitiivisesti tulkittavissa. Tehdﾃ､ksemme tutkimuksesta vertailukelpoista ja edistﾃ､ﾃ､ksemme tulevaa tyﾃｶtﾃ､, annamme tuloksia kolmesta englanninkielisestﾃ､ korpusesta ja julkaisemme arviointikﾃ､sikirjoitusten toteuttamisen julkisesti saataville.', 'bs': "U ovom papiru reviziramo zadatak rezolucije negacije, koji uključuje podstaze detekcije znakova (npr. ne', 'nikad') i rezolucije opsega. U kontekstu prethodnih zajedničkih zadataka predloženo je razne mjere procjene. Sljedeći radovi obično koriste različite podsjetnike tih podsjetnika, uključujući varijacije i obične provedbe, čineći smislene usporedbe između sustava teško. Ispitivajući problem i iz jezičke perspektive i iz nižeg pogleda, ovdje se raspravljamo za negativni pristup procjene rezolucije negacija. Naša predložena metrika odgovara očekivanjima preko rezultata svakog instanca i stoga su intuitivno interpretabilne. Za usporedbu istraživanja i podizanje budućeg rada, pružamo rezultate za skup trenutnih državnih umjetničkih sustava za rezoluciju negacije o tri engleskog korpora i učinimo našu provedbu procjenskih skripta javno dostupnim.", 'ha': 'Ga wannan takardan, za mu sake raba aikin juyin aiki na halarce, wanda ke ƙunsa da misali masu nuna wa kwanan aiki (misali, "ba\'a\'), da buƙata masu buƙata. @ info: whatsthis Yi amfani da jama\'a masu daban a yi amfani da jama\'a masu daban-daban daga waɗannan, kamar shiryoyin ayuka da shiryoyin ayuka na ɗabi\'a, kuma ya sanya misalin da masu muhimu a tsakanin system masu nau\'i. Aka jarraba masu zartar da su daga wani mtazami na lugha da kuma daga wani point na ƙarƙashin ruwa, za mu yi jãyayya a kan wani misali bakin nega dõmin ya ƙaddara rabo-rayi. Mimetric da aka buƙata da su sami da matumaini kan kowace misali, kuma sai za\'a fassara masu buƙata. Ga ta sami research da kwamfyuta, kuma za mu ƙarfafa aikin bayani, za\'a ba da matsala na ma\'anar-halin-sanatarwa na yanzu ta zama masu motsi a kanzu\'in rubutu uku a kan makampuni na Ingiriya, kuma za\'a samarar mu da manuscriptun evaluation bayani.', 'sk': 'V tem prispevku ponovno obravnavamo nalogo reševanja zanikanja, ki vključuje podnaloge zaznavanja znakov (npr. "ne", "nikoli") in reševanja obsega. V okviru prejšnjih skupnih nalog so bile predlagane različne meritve ocenjevanja. Naslednja dela običajno uporabljajo različne podskupine teh, vključno z variacijami in implementacijami po meri, zaradi česar so smiselne primerjave med sistemi težke. Proučujemo problem tako z jezikovnega vidika kot z vidika nadaljnje verige, zato se tukaj zavzemamo za pristop, ki temelji na negativnih primerih pri ocenjevanju reševanja zanikanja. Naše predlagane meritve ustrezajo pričakovanjem glede rezultatov na primer in so zato intuitivno razložljive. Da bi raziskave postale primerljive in spodbujale prihodnje delo, zagotavljamo rezultate za nabor sedanjih najsodobnejših sistemov za reševanje zanikanja na treh angleških korpusih in dajemo našo implementacijo ocenjevalnih scenarijev javno dostopno.', 'jv': 'mi Genjer-Genjer windows-action Ngawe ngilanggar perbudhakan languangka nggo languangka lan nggo languangka ngilangno, kita didasai nggo languangka sing basa bantuan kanggo nggawe Resolusi languangka Perintah sing dipunangé Ing ngejaraké perusahaan kelas karo nggawe aturan sing beraksi lan nggawe aturan sing beraksi perusahaan winih kanggo kejahatan dhéwé sistem dadi-perusahaan kanggo ngilangno karo perusahaan sing telu, lan akeh iso nggawe perusahaan mripat kanggo Kemerdekaan karo perusahaan kanggo ngilangno kuwi', 'he': "בעיתון הזה, אנו חוזרים על המשימה של פיתרון השלילות, אשר כולל את השאלות של זיהוי סימנים (למשל 'לא', 'לעולם') ופתרון הסקופ. In the context of previous shared tasks, a variety of evaluation metrics have been proposed.  Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult.  Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution.  המטריקות המוצעות שלנו מתאימות לצפיות על נקודות לדוגמא וכך הן אינטואיטיבית אפשרות לפרש. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.", 'bo': 'འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འོང་ཚོས་གསལ་བཀོད་མིན་པར་བཤད་ཀྱི་བྱ་འགུལ་ལ་བསྐྱར་བཟོ་བྱེད་ཀྱི་ཡོད། སྔོན་གྱི་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་གནས་ཚུལ་ནང་དུ་ཚད་རིམ་པ་སྣ་ཚོགས་བསམ་བྱུང་། རྗེས་མ་ལག་གི་རྒྱུན་ལྡན་དེ་དག་ལས་ཕན་ཚན་མ་འདྲ་བ་སྤྱད་ནས་འགྱུར་བ་དང་རང་བཟོས་སྒྲིག སྐད་ཡིག Our proposed metrics correspond to expectations over per-instance scores and hence are intuitively interpretable. དབུལ་ཡིག་གི་སྐོར་དང་མཐུན་བཟོ་བྱེད་པར་དབུལ་ཞིབ་དང་ཡར་རྒྱས་སྐྱོར་བྱེད་པར། ང་ཚོས་ད་ལྟོའི་གནས་སྟངས་གཙོ་རིམ་འདུག་མཛོད་ཁང་གསུམ་དང་འཛམ'}
{'en': 'Controlling Prosody in End-to-End TTS : A Case Study on Contrastive Focus Generation TTS : A Case Study on Contrastive Focus Generation', 'ar': 'التحكم في الإيجابيات في تحويل النص إلى كلام من طرف إلى طرف: دراسة حالة حول توليد التركيز التقابلي', 'es': 'Control de la prosodia en el TTS de extremo a extremo: un estudio de caso sobre la generación de enfoque contrastivo', 'fr': 'Contrôle de la prosodie dans le TTS de bout en bout\xa0: une étude de cas sur la génération de focus contrastif', 'pt': 'Controlando a prosódia em TTS de ponta a ponta: um estudo de caso sobre geração de foco contrastivo', 'ja': 'エンドツーエンドTTSにおけるプロソディーの制御：コントラストフォーカス生成のケーススタディ', 'ru': 'Управление просодией в сквозной ТТС: тематическое исследование по формированию контрастной фокусировки', 'zh': '端到端TTS中制韵:比焦点成例', 'hi': 'एंड-टू-एंड टीटीएस में प्रोसोडी को नियंत्रित करना: कंट्रास्टिव फोकस जेनरेशन पर एक केस स्टडी', 'ga': 'Prosóid a Rialú i TTS Deireadh le Deireadh: Cás-Staidéar ar Ghiniúint Fócais Chodarsnachta', 'hu': 'Proszódia szabályozása a végtől-végig TTS-ben: esettanulmány a kontrasztív fókusz generálásáról', 'el': 'Έλεγχος Προσφοράς σε Ολοκληρωμένη Μελέτη περίπτωσης για την Δημιουργία Αντίθετης Εστίασης', 'ka': 'Comment', 'it': 'Controlling Prosody in End-to-End TTS: un caso di studio sulla generazione di focus contrastanti', 'lt': 'Kontroliuojama prosodija TPS pabaigoje: Kontrastinės fokuso generacijos atvejų tyrimas', 'kk': 'TTS аяқтау мен аяқтау тәртібін басқару: Контрастық назарды құру үшін әріптерді оқу', 'mk': 'Контролирање на прозодијата во TTS од крај до крај: Студија на случаи за генерација контрастивен фокус', 'ml': 'അവസാന- മുതല്\u200d അവസാനിക്കുന്ന ടിടിഎസില്\u200d നിയന്ത്രിക്കുന്ന പ്രോസോഡി: കോണ്\u200dട്രാസ്റ്റേറ്റിവ് ഫോക്സ് സൃഷ', 'ms': 'Mengkawal Prosody dalam TTS Akhir-Akhir: Sebuah kajian kes pada Jenerasi Fokus Kontrastif', 'mn': 'TTS-ийн төгсгөл-төгсгөлд төгсгөл судалгаа', 'no': 'Kontrollering av prosedyr i slutttil slutt TTS: Eit små bokstavar på kontrastiv fokusgenerering', 'pl': 'Kontrolowanie prozodii w kompleksowym TTS: studium przypadku generowania kontrastywnego ostrości', 'ro': 'Controlul prosodiei în TTS end-to-end: un studiu de caz privind generarea focalizării contrastive', 'sr': 'Kontroliranje proizvodnje na kraju do kraja TTS: istraživanje slučajeva o generaciji kontrastivnog fokusa', 'si': 'Comment', 'so': 'Control Prosody in End-to-End TTS: A Case Study on Contrastive Focus Generation', 'sv': 'Kontroll av prosodi i End-to-End TTS: En fallstudie om kontrastiv fokusgenerering', 'ta': 'கட்டுப்படுத்தும் விவரம் முடிவில் இருந்து முடிவு TTS: தொடர்புடைய முன்னிருப்பு உருவாக்கத்தில் ஒரு விஷயம் பட', 'ur': 'ٹیٹس کی پایان-پایان میں کنٹرولینگ پروڈی: کنٹروسٹیو فوकस پیدا کرنے کے بارے میں ایک کیس تحقیق', 'mt': 'Kontroll tal-Prosodija fit-TTS minn tmiem sa tmiem: Studju ta’ Każ dwar il-Ġenerazzjoni ta’ Fokus Kontrastiv', 'uz': '@ info: whatsthis', 'vi': 'Kiểm soát phần mềm trong giai đoạn cuối: Một nghiên cứu về sự tương phản.', 'bg': 'Контролиране на простодията в ТТС от край до край: казус за генериране на контрастивен фокус', 'da': 'Kontrol af prosodi i end-to-end TTS: Et casestudie om generering af kontrastivt fokus', 'nl': 'Het beheersen van prosodie in end-to-end TTS: een casestudy over het genereren van contrasterende focus', 'hr': 'Kontroliranje proizvoda u TTS-u do kraja: Ispitivanje slučajeva o generaciji kontrastivnog fokusa', 'de': 'Kontrolle von Prosodie in End-to-End TTS: Eine Fallstudie zur Generierung kontrastiver Fokussierung', 'fa': 'کنترل پروژه در TTS پایان و پایان: یک مطالعه پروژه در مورد نسل تمرکز کنترل', 'id': 'Kontrol Prosody dalam TTS Akhir-Akhir: Sebuah Studi Kasus tentang Generasi Fokus Kontrastif', 'sw': 'Uthibiti katika mwisho-to-mwisho TTS: A Case Study on Contrastive Focus Generation', 'tr': "TTS'iň soňundan-soňunda kanunlar ösümi: A Case Study on Contrastive Focus Generation", 'af': "Kontroleer Prosodie in Einde- na- Einde TTS: ' n Kas Studie op Kontrasteef Fokus Generasie", 'sq': 'Kontrollimi i Prosodisë në TTS nga fundi në fund: Një studim rasti mbi gjenerimin e fokusit kontrastues', 'am': 'Controlling Prosody in End-to-End TTS: A Case Study on Contrastive Focus Generation', 'hy': 'ՏՏՍ-ի վերջ-վերջ պրոցեդիայի վերահսկողությունը. հակադրական ֆոկուսի ստեղծման դեպքերի ուսումնասիրություն', 'az': 'TVS son-to-end t…ôhsil iŇül…ôtm…ôsi: KontrastlńĪ Fokus M…ôxluqatńĪ', 'bn': 'টিটিএস- এর শেষ- থেকে শেষ পর্যন্ত নিয়ন্ত্রণের প্রোসোডি: কন্ট্রেসিটিভ ফোকাস প্রজন্মের একটি কেস স্টিডিয়া', 'bs': 'Kontroliranje proizvoda u TTS-u do kraja: istraživanje slučajeva o generaciji kontrastivnog fokusa', 'cs': 'Řízení prozodií v end-to-end TTS: Případová studie o generování kontrastního zaostření', 'ko': '끝에서 끝까지 TTS에서의 운율 제어: 초점 생성에 대한 개안 연구', 'et': 'Prooodia kontrollimine lõpp-lõpuni TTS: juhtumiuuring kontrastiivse fookuse genereerimise kohta', 'ca': 'Control Prosody in End-to-End TTS: A Case Study on Contrastive Focus Generation', 'fi': 'Prosodian hallinta päästä päähän TTS: tapaustutkimus kontrastiivisen fokusin luomisesta', 'he': 'Controlling Prosody in End-to-End TTS: A Case Study on Contrastive Focus Generation', 'sk': 'Nadzor prosodije pri TTS od konca do konca: študija primera o ustvarjanju kontrastivnega fokusa', 'ha': 'KCharselect unicode block name', 'jv': 'Validity', 'bo': 'Controlling Prosody in End-to-End TTS: A Case Study on Contrastive Focus Generation'}
{'en': 'While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over  prosody . For instance, generating  speech  with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control  prosody  directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific  dataset  for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example,  smart speakers  to be programmatically controlled in terms of output prosody.', 'es': 'Si bien la conversión de texto a voz (TTS) End-2-End ha logrado avances significativos en los últimos años, estos sistemas aún carecen de controles intuitivos para el usuario sobre la prosodia. Por ejemplo, generar el habla con un control profundo de la prosodia (prominencia prosódica, emociones contextualmente apropiadas) sigue siendo un desafío abierto. En este artículo, investigamos si podemos controlar la prosodia directamente desde el texto de entrada, para codificar información relacionada con el enfoque contrastivo que enfatiza una palabra específica que es contraria a los supuestos del interlocutor. Creamos y compartimos un conjunto de datos específico para este propósito y mostramos que permite entrenar un sistema TTS donde esta característica prosódica de grano fino se puede transmitir correctamente mediante tokens de control. Nuestra evaluación compara enunciados sintéticos y naturales y demuestra que los patrones prosódicos de enfoque contrastivo (variaciones de Fo, Intensidad y Duración) se pueden aprender con precisión. Este hito es importante para permitir, por ejemplo, que los altavoces inteligentes se controlen mediante programación en términos de prosodia de salida.', 'fr': "Alors que la synthèse vocale de bout en bout (TTS) a fait des progrès significatifs au cours des dernières années, ces systèmes ne disposent toujours pas de contrôles utilisateur intuitifs sur la prosodie. Par exemple, générer un discours avec un contrôle précis de la prosodie (prosodie prosodique, émotions adaptées au contexte) reste un défi ouvert. Dans cet article, nous étudions si nous pouvons contrôler la prosodie directement à partir du texte d'entrée, afin de coder des informations liées à la mise au point contrastive qui met l'accent sur un mot spécifique qui est contraire aux présupposés de l'interlocuteur. Nous créons et partageons un ensemble de données spécifique à cette fin et montrons qu'il permet d'entraîner un système TTS où cette caractéristique prosodique fine peut être correctement transmise à l'aide de jetons de contrôle. Notre évaluation compare les énoncés synthétiques et naturels et montre que les modèles prosodiques de mise au point contrastive (variations de Fo, d'intensité et de durée) peuvent être apprises avec précision. Un tel jalon est important pour permettre, par exemple, de contrôler par programme les haut-parleurs intelligents en termes de prosodie de sortie.", 'ar': 'في حين أن تحويل النص إلى كلام End-2-End (TTS) قد أحرز تقدمًا ملحوظًا على مدار السنوات القليلة الماضية ، إلا أن هذه الأنظمة لا تزال تفتقر إلى ضوابط المستخدم البديهية على العرض. على سبيل المثال ، لا يزال توليد الكلام من خلال التحكم الدقيق في العروض الصوتية (بروز عرضي ، وعواطف مناسبة للسياق) يمثل تحديًا مفتوحًا. في هذه الورقة ، نتحرى ما إذا كان بإمكاننا التحكم في العرض مباشرة من نص الإدخال ، من أجل ترميز المعلومات المتعلقة بالتركيز التباين الذي يؤكد على كلمة معينة تتعارض مع الافتراضات المسبقة للمحاور. نقوم ببناء مجموعة بيانات محددة ومشاركتها لهذا الغرض ونوضح أنها تسمح بتدريب نظام تحويل النص إلى كلام إذا كان يمكن نقل هذه الميزة النقطية الدقيقة بشكل صحيح باستخدام رموز التحكم. يقارن تقييمنا بين الأقوال التركيبية والطبيعية ويظهر أن الأنماط العرضية للتركيز التباين (الاختلافات في Fo ، والشدة ، والمدة) يمكن تعلمها بدقة. يعد هذا المعلم مهمًا للسماح ، على سبيل المثال ، بالتحكم في مكبرات الصوت الذكية برمجيًا من حيث عرض الإخراج.', 'pt': 'Embora o Text-to-Speech (TTS) End-2-End tenha feito progressos significativos nos últimos anos, esses sistemas ainda carecem de controles intuitivos do usuário sobre a prosódia. Por exemplo, gerar fala com controle de prosódia refinado (proeminência prosódica, emoções contextualmente apropriadas) ainda é um desafio em aberto. Neste artigo, investigamos se podemos controlar a prosódia diretamente a partir do texto de entrada, a fim de codificar informações relacionadas ao foco contrastivo que enfatiza uma palavra específica contrária aos pressupostos do interlocutor. Construímos e compartilhamos um conjunto de dados específico para esse fim e mostramos que ele permite treinar um sistema TTS onde esse recurso prosódico de granulação fina pode ser transmitido corretamente usando tokens de controle. Nossa avaliação compara enunciados sintéticos e naturais e mostra que padrões prosódicos de foco contrastivo (variações de Fo, Intensity e Duration) podem ser aprendidos com precisão. Esse marco é importante para permitir, por exemplo, que alto-falantes inteligentes sejam controlados programaticamente em termos de prosódia de saída.', 'zh': '虽端到端文本至语音转换(TTS)于往数年中得重大进展,而系统犹乏对韵之直观用户。 如生细粒度韵制(韵出,上下文适情)语音犹悬而未决挑战也。 本文之中,究其可直输文本,以对焦点相关之信编码,当与对话者相反之特定单词。 共享一特定之数,明其训练TTS统,若此细粒度韵特徵可用制令牌正传。 吾评校合成自然语,明可正学比焦点韵式(Fo,强度持续时间之变)。 如此者里程碑许智能扬声器输韵编程制之甚重。', 'hi': 'जबकि एंड-2-एंड टेक्स्ट-टू-स्पीच (टीटीएस) ने पिछले कुछ वर्षों में महत्वपूर्ण प्रगति की है, इन प्रणालियों में अभी भी प्रोसोडी पर सहज ज्ञान युक्त उपयोगकर्ता नियंत्रण की कमी है। उदाहरण के लिए, ठीक दानेदार प्रोसोडी नियंत्रण (प्रोसोडिक प्रमुखता, प्रासंगिक रूप से उपयुक्त भावनाओं) के साथ भाषण उत्पन्न करना अभी भी एक खुली चुनौती है। इस पेपर में, हम जांच करते हैं कि क्या हम इनपुट टेक्स्ट से सीधे प्रोसोडी को नियंत्रित कर सकते हैं, ताकि कॉन्ट्रास्टिव फोकस से संबंधित जानकारी को कोड किया जा सके जो एक विशिष्ट शब्द पर जोर देता है जो वार्ताकार की पूर्वधारणाओं के विपरीत है। हम इस उद्देश्य के लिए एक विशिष्ट डेटासेट का निर्माण और साझा करते हैं और दिखाते हैं कि यह एक टीटीएस सिस्टम को प्रशिक्षित करने की अनुमति देता है, इस ठीक-दाने वाली प्रोसोडिक सुविधा को नियंत्रण टोकन का उपयोग करके सही ढंग से व्यक्त किया जा सकता है। हमारा मूल्यांकन सिंथेटिक और प्राकृतिक कथनों की तुलना करता है और दिखाता है कि कंट्रास्टिव फोकस (एफओ, तीव्रता और अवधि की विविधताओं) के प्रोसोडिक पैटर्न को सटीक रूप से सीखा जा सकता है। इस तरह के एक मील का पत्थर की अनुमति देने के लिए महत्वपूर्ण है, उदाहरण के लिए, स्मार्ट वक्ताओं को आउटपुट प्रोसोडी के संदर्भ में प्रोग्रामेटिक रूप से नियंत्रित किया जाना चाहिए।', 'ja': 'エンド2 -エンドテキストツー-スピーチ（ TTS ）は過去数年間に大きな進歩を遂げましたが、これらのシステムはまだプロソディーに対する直感的なユーザーコントロールを欠いています。 例えば、細かいプロソディーコントロール（プロソディーの顕著さ、文脈的に適切な感情）を伴うスピーチを生成することは、依然としてオープンな課題である。 本稿では、対話者の前提条件に反する特定の単語を強調する対照的な焦点に関する情報をコード化するために、入力テキストから直接プロソディーを制御できるかどうかを検討する。 この目的のために特定のデータセットを構築して共有し、制御トークンを使用してこの細かいプロソディック機能を正しく伝えることができれば、TTSシステムをトレーニングすることができることを示します。 当社の評価は、合成発話と自然発話を比較し、コントラストフォーカスのプロソディックパターン（ Fo、強度、持続時間のバリエーション）を正確に学習できることを示しています。 このようなマイルストーンは、例えば、スマートスピーカーが出力プロソディーの観点からプログラム的に制御されることを可能にするために重要である。', 'ru': 'Несмотря на то, что за последние несколько лет компания End-2-End Text-to-Speech (TTS) добилась значительных успехов, этим системам все еще не хватает интуитивно понятного пользовательского контроля над proody. Например, генерация речи с мелкозернистым контролем просодии (просодическая заметность, контекстно-подходящие эмоции) все еще остается открытым вызовом. В этой статье мы исследуем, можем ли мы управлять просодией непосредственно из входного текста, чтобы кодировать информацию, связанную с контрастным фокусом, который подчеркивает конкретное слово, противоречащее предположениям собеседника. Мы создаем и совместно используем конкретный набор данных для этой цели и показываем, что он позволяет обучать систему TTS, если эта мелкозернистая просодическая особенность может быть правильно передана с помощью токенов управления. Наша оценка сравнивает синтетические и естественные высказывания и показывает, что просодические паттерны контрастного фокуса (вариации Fo, интенсивности и продолжительности) могут быть изучены точно. Такая веха важна для того, чтобы позволить, например, умным динамикам быть программно управляемыми с точки зрения производительности.', 'ga': 'Cé go bhfuil dul chun cinn suntasach déanta le blianta beaga anuas ag Téacs-go-Caint (TTS) de chuid End2-End, níl rialuithe iomasach úsáideoirí ar shórpóid fós ag na córais seo. Mar shampla, is dúshlán oscailte fós é caint a ghiniúint le rialú prósóide mín (tábhacht mhór, mothúcháin atá oiriúnach don chomhthéacs). Sa pháipéar seo, déanaimid imscrúdú an féidir linn prósóid a rialú go díreach ón téacs ionchuir, chun faisnéis a bhaineann le fócas codarsnachta a chódú a leagann béim ar fhocal ar leith atá contrártha le réamhshuíomh an idirghabhálaí. Déanaimid tacar sonraí ar leith a thógáil agus a roinnt chun na críche seo agus léirímid go gceadaíonn sé córas TTS a thraenáil dá bhféadfaí an ghné phródálach mhíne seo a chur in iúl i gceart trí úsáid a bhaint as comharthaí rialaithe. Déanann ár meastóireacht comparáid idir idir chaint shintéiseach agus nádúrtha agus taispeánann sé gur féidir patrúin prósóideacha d’fhócas codarsnachta (éagsúlachtaí Fo, Déine agus Fad) a fhoghlaim go cruinn. Tá cloch mhíle den sórt sin tábhachtach chun go bhféadfaí, mar shampla, cainteoirí cliste a rialú go cláir i dtéarmaí prósóid aschuir.', 'ka': 'შემდეგ რამდენიმე წლის შემდეგ ბოლო- 2- ბოლო ტექსტის კონტულაზე (TTS) მნიშვნელოვანი პროგრესი გავაკეთეთ, მაგრამ ამ სისტემების ინტუტიური მომხმარებელი კონტულ მაგალითად, საუკეთესო კონტროლის კონტროლისთვის წარმოქმება (პროსოდიური მნიშვნელობა, კონტექსტურად მსგავსი ემოციები) უკვე განხორციელია. ამ გვერდიში, ჩვენ შევხედავთ თუ შეგვიძლია კონტროსტიური ტექსტიდან კონტროსტიური ინფორმაციის შესახებ, რომელიც კონტროსტიური ფოსტიური სიტყვების განმავლობას, რომელიც ინტერლექტორის წინა ჩვენ განსაზღვრებული მონაცემების სოფციფიკალური საზოგადომის შესახებ და გამოწევთ, რომ TTS სისტემის შესაძლებლობა გასწავლა იყო ეს კონტროლური პროსორეული ფუნქცია, რომელიც შე ჩვენი განსაზღვრება სინტეტიკური და ნაირთო სიტყვებების შემდგენება და ჩვენი განსაზღვრებას, რომ კონტროსტიური ფოკუსის პროსოდიკური ნაგულები (ფო, ინტენტენტიკური და განსრულების გან რაღაც გასანიშვნელოვანია, რომ, მაგალითად, სმიერი საუკეთესო საუკეთესო საუკეთესო პროგრამეტურად კონტროლეცია გამოყენება.', 'el': 'Ενώ το κείμενο-σε-ομιλία έχει σημειώσει σημαντικές εξελίξεις τα τελευταία χρόνια, αυτά τα συστήματα εξακολουθούν να στερούνται διαισθητικού ελέγχου από τους χρήστες σχετικά με την προσωδία. Για παράδειγμα, η δημιουργία ομιλίας με λεπτόκοκκο έλεγχο της προσοδίας (προσωδική προβολή, ανάλογα συναισθήματα στο πλαίσιο) εξακολουθεί να αποτελεί ανοικτή πρόκληση. Στην παρούσα εργασία διερευνούμε αν μπορούμε να ελέγξουμε την προσωδία απευθείας από το κείμενο εισαγωγής, προκειμένου να κωδικοποιήσουμε πληροφορίες που σχετίζονται με την αντίθεση εστίασης που τονίζει μια συγκεκριμένη λέξη που είναι αντίθετη με τις προϋποθέσεις του συνομιλητή. Κατασκευάζουμε και μοιραζόμαστε ένα συγκεκριμένο σύνολο δεδομένων για το σκοπό αυτό και δείχνουμε ότι επιτρέπει την εκπαίδευση ενός συστήματος όπου αυτό το λεπτόκοκκο προσωδικό χαρακτηριστικό μπορεί να μεταφερθεί σωστά χρησιμοποιώντας σήματα ελέγχου. Η αξιολόγησή μας συγκρίνει συνθετικές και φυσικές εκφράσεις και δείχνει ότι μπορούν να διδαχθούν με ακρίβεια προσωδικά μοτίβα αντίθεσης εστίασης (παραλλαγές της έντασης και της διάρκειας). Ένα τέτοιο ορόσημο είναι σημαντικό για να επιτρέψει, για παράδειγμα, στα έξυπνα ηχεία να ελέγχονται προγραμματικά από την άποψη της προσοδίας εξόδου.', 'it': "Mentre End-2-End Text-to-Speech (TTS) ha fatto progressi significativi negli ultimi anni, questi sistemi mancano ancora di controlli intuitivi sull'utente prosody. Ad esempio, generare discorsi con controllo prosodico a grana fine (prominenza prosodica, emozioni contestualmente appropriate) è ancora una sfida aperta. In questo articolo si indaga se sia possibile controllare la prosodia direttamente dal testo di input, al fine di codificare informazioni relative a focus contrastanti che enfatizzano una parola specifica contraria ai presupposti dell'interlocutore. Costruiamo e condividiamo un dataset specifico per questo scopo e mostriamo che consente di addestrare un sistema TTS dove questa caratteristica prosodica a grana fine può essere correttamente trasmessa utilizzando token di controllo. La nostra valutazione mette a confronto espressioni sintetiche e naturali e mostra che modelli prosodici di messa a fuoco contrastante (variazioni di Fo, Intensità e Durata) possono essere appresi con precisione. Tale traguardo è importante per consentire, ad esempio, di controllare programmaticamente gli altoparlanti intelligenti in termini di prosody di uscita.", 'hu': 'Míg a End-2-End Text-to-Speech (TTS) jelentős előrelépéseket tett az elmúlt években, ezeknek a rendszereknek még mindig hiányzik az intuitív felhasználói vezérlés a prosódia felett. Például a finom szemcsés prosódiával történő beszéd generálása (prozódikus kiemelkedés, kontextuálisan megfelelő érzelmek) még mindig nyitott kihívás. Ebben a tanulmányban azt vizsgáljuk, hogy közvetlenül a bemeneti szövegből tudjuk-e irányítani a prozódiát annak érdekében, hogy a kontrasztos fókuszhoz kapcsolódó információkat kódoljunk, amelyek hangsúlyozzák egy konkrét szót, amely ellentétes a beszélgető feltételeivel. Erre a célra konkrét adatkészletet építünk és osztunk meg, és megmutatjuk, hogy ez lehetővé teszi egy TTS rendszer kiképzését, amennyiben ezt a finomszemcsés prozódikus funkciót vezérlő tokenek segítségével helyesen lehet továbbítani. Értékelésünk összehasonlítja a szintetikus és természetes kifejezéseket, és azt mutatja, hogy a kontrasztív fókusz prozódikus mintázatai (Fo, intenzitás és időtartam változatai) pontosan tanulhatók. Ez a mérföldkő fontos ahhoz, hogy például az intelligens hangsugárzók programozott vezérlését a kimeneti prosódia szempontjából lehessen lehetővé tenni.', 'kk': '2- аяқтау мәтін- мен сөйлеу (TTS) соңғы жылдар бойынша маңызды жұмыс істегенде, бұл жүйелердің проsody- тың интуитивті пайдаланушыларының контролі жоқ. Мысалы, дұрыс бақылау бақылау (просодикалық көңіл, көңіл көңіл көңіл көңіл көңіл көңіл) әлі жеткізілген мәселе. Бұл қағазда, біз просодияны енгізу мәтінінен тікелей басқаруға болады дегенді зерттеп, контрастық назардағы мәліметтің мәліметін бақылап, интерлоктордың алдындағы мәліметіне қарсы бір сөзді бағыттайтын. Біз бұл мақсат үшін ерекше деректер жинағын құрып, бөліп, TTS жүйесін оқыту мүмкіндігін көрсету мүмкіндігін көрсету мүмкіндігін көрсету мүмкіндігін көрсету мүмкіндігін, бұ Біздің оқиғамыз синтетикалық және табиғи сөздерді салыстырып, контрастырлық үлгілердің проsodикалық үлгілерін (фо, тұрақтық және ұзақтығының айнымалылығы) дұрыс оқиға алады. Мысалы, мысалы, мысалы, смарт сөйлейтіншілерді бағдарламалық түрде шығару проsody қасиетінде бақылау үшін маңызды.', 'ml': 'കഴിഞ്ഞ കുറച്ചു വര്\u200dഷങ്ങളില്\u200d അവസാന- 2- അവസാന പദാവലി- ടിടിഎസ്- സംസാരിക്കുമ്പോള്\u200d ഈ സിസ്റ്റം പ്രൊസോഡിയില്\u200d നിയന്ത്രിക്കുന്ന ബു ഉദാഹരണത്തിന്, നല്ല പ്രൊസോഡി നിയന്ത്രണത്തോടൊപ്പം സംസാരിക്കുന്നതാണ് (പ്രൊസോഡിക്ക് പ്രഭുതം, സഹകരിതമായ വികാരങ്ങള്\u200d)  ഈ പത്രത്തില്\u200d നാം നേരിട്ട് ഇന്\u200dപുട്ട് ടെക്സ്റ്റില്\u200d നിന്ന് പ്രോസ്ഡിയെ നിയന്ത്രിക്കാന്\u200d സാധിക്കുമോ എന്ന് അന്വേഷിക്കുന്നു. അതിനാല്\u200d നിര്\u200dബന്ധി ഈ ലക്ഷ്യത്തിനുവേണ്ടി ഞങ്ങള്\u200d ഒരു പ്രത്യേക ഡാറ്റാസെറ്റ് പണിയുകയും പങ്കുകാണിക്കുകയും ടിടിഎസ് സിസ്റ്റം പരിശീലിപ്പിക്കാന്\u200d അനുവദി Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately.  ഉദാഹരണത്തിനായി സ്മാര്\u200dട്ട് സംസാരിക്കുന്നവര്\u200dക്ക് പ്രോഗ്രാമിക്കല്\u200d നിയന്ത്രിക്കേണ്ടതിന് ഒരു മൈല്\u200d കല്ലിന്', 'mk': '袠邪泻芯 褌械泻褋褌芯褌 写芯 谐芯胁芯褉 薪邪 泻褉邪褬芯褌 芯写 2 泻褉邪褬 (TTS) 锌芯褋褌懈谐薪邪 蟹薪邪褔懈褌械谢薪懈 薪邪锌褉械写芯褑懈 胁芯 褌械泻芯褌 薪邪 懈蟹屑懈薪邪褌懈褌械 薪械泻芯谢泻褍 谐芯写懈薪懈, 薪邪 芯胁懈械 褋懈褋褌械屑懈 褋茅 褍褕褌械 懈屑 薪械写芯褋褌邪褋褍胁邪 懈薪褌褍懈褌懈胁薪邪 泻芯薪褌褉芯谢邪 薪邪 泻芯褉懈褋薪懈褑懈褌械 薪邪写 锌褉芯蟹芯写懈褬邪褌邪. 袧邪 锌褉懈屑械褉, 谐械薪械褉懈褉邪褮械褌芯 薪邪 谐芯胁芯褉 褋芯 褎懈薪邪 泻芯薪褌褉芯谢邪 薪邪 锌褉芯蟹芯写懈褬邪褌邪 (锌褉芯蟹芯写懈褔薪邪 懈褋褌邪泻薪褍胁邪褮械, 泻芯薪褌械泻褋褌薪芯 褋芯芯写胁械褌薪懈 械屑芯褑懈懈) 褋茅 褍褕褌械 械 芯褌胁芯褉械薪 锌褉械写懈蟹胁懈泻. 袙芯 芯胁芯褬 胁械褋薪懈泻, 懈褋褌褉邪卸褍胁邪屑械 写邪谢懈 屑芯卸械屑械 写邪 褬邪 泻芯薪褌褉芯谢懈褉邪屑械 锌褉芯蟹芯写懈褬邪褌邪 写懈褉械泻褌薪芯 芯写 胁薪邪褌褉械褕薪懈芯褌 褌械泻褋褌, 褋芯 褑械谢 写邪 谐懈 泻芯写懈褉邪屑械 懈薪褎芯褉屑邪褑懈懈褌械 锌芯胁褉蟹邪薪懈 褋芯 泻芯薪褌褉邪褋褌懈胁薪懈芯褌 褎芯泻褍褋 泻芯褬 懈褋褌邪泻薪褍胁邪 褋锌械褑懈褎懈褔械薪 蟹斜芯褉 泻芯褬 械 褋锌褉芯褌懈胁械薪 薪邪 锌褉械褌锌芯褋褌邪胁褍胁邪褮邪褌邪 薪邪 懈薪褌械褉谢芯泻褍褌芯褉芯褌. 小芯蟹写邪胁邪屑械 懈 褋锌芯写械谢褍胁邪屑械 褋锌械褑懈褎懈褔薪懈 锌芯写邪褌芯褑懈 蟹邪 芯胁邪邪 褑械谢 懈 锌芯泻邪卸褍胁邪屑械 写械泻邪 芯胁芯蟹屑芯卸褍胁邪 写邪 褋械 芯斜褍褔褍胁邪 TTS 褋懈褋褌械屑 邪泻芯 芯胁邪邪 褎懈薪邪 锌褉芯蟹芯写懈褔薪邪 泻邪褉邪泻褌械褉懈褋褌懈泻邪 屑芯卸械 写邪 褋械 锌褉械薪械褋械 锌褉邪胁懈谢薪芯 泻芯褉懈褋褌械褬褱懈 泻芯薪褌褉芯谢薪懈 蟹薪邪褑懈. 袧邪褕邪褌邪 锌褉芯褑械薪泻邪 谐懈 褋锌芯褉械写褍胁邪 褋懈薪褌械褌懈褔泻懈褌械 懈 锌褉懈褉芯写薪懈褌械 懈蟹褉邪蟹懈 懈 锌芯泻邪卸褍胁邪 写械泻邪 锌褉芯蟹芯写懈褔薪懈褌械 褕械屑懈 薪邪 泻芯薪褌褉邪褋褌懈胁械薪 褎芯泻褍褋 (胁邪褉懈褬邪褑懈懈 薪邪 肖芯, 懈薪褌械薪蟹懈褌械褌 懈 褌褉邪械褮械) 屑芯卸械 写邪 褋械 薪邪褍褔邪褌 锌褉械褑懈蟹薪芯. Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody.', 'lt': 'Nors per pastaruosius kelerius metus teksto teksto ir kalbos pabaigoje (TTS) padaryta didelė pažanga, šioms sistemoms vis dar trūksta intuityvių naudotojų kontrolių dėl prosody. Pavyzdžiui, kalbos sukūrimas su švelniagrūdine prosodijos kontrole (prosodinis akcentavimas, kontekste tinkamos emocijos) vis dar yra atviras iššūkis. Šiame dokumente mes tiriame, ar galime kontroliuoti prosody tiesiogiai iš įvedamo teksto, kad koduotume informaciją, susijusią su kontrastiniu dėmesiu, kuriame pabrėžiamas konkretus žodis, prieštaraujantis interlocutorio prielaidoms. We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens.  Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately.  Toks svarbus etapas, kad, pavyzdžiui, pažangieji kalbėtojai galėtų būti programiškai kontroliuojami išėjimo prosodijos požiūriu.', 'ms': 'Sementara End-2-End Text-to-Speech (TTS) telah membuat kemajuan yang signifikan selama beberapa tahun terakhir, sistem ini masih kekurangan kawalan pengguna intuitif atas prosody. Contohnya, menghasilkan ucapan dengan kawalan prosody yang baik (prominensi prosodik, emosi yang sesuai secara konteks) masih satu cabaran terbuka. Dalam kertas ini, kita menyelidiki sama ada kita boleh mengawal prosody secara langsung dari teks input, untuk kod maklumat berkaitan dengan fokus bertentangan yang menekankan perkataan khusus yang bertentangan dengan anggapan interlocutor. Kami membina dan berkongsi set data khusus untuk tujuan ini dan menunjukkan bahawa ia membenarkan untuk melatih sistem TTS adalah ciri prosodik yang baik ini boleh dihantar dengan betul menggunakan token kawalan. Evaluasi kami membandingkan ungkapan sintetik dan semulajadi dan menunjukkan bahawa corak prosodik fokus kontras (variasi Fo, Intensity dan Duration) boleh dipelajari dengan tepat. Batu batu ini penting untuk membolehkan, contohnya, pembicara pintar dikawal secara programmatik dalam terma prosodi output.', 'mt': 'Filwaqt li matul dawn l-aħħar ftit snin it-Test għall-Kellem tat-Tmiem tat-Tmiem (TTS) għamel progress sinifikanti, dawn is-sistemi għadhom ma għandhomx kontrolli intwittivi tal-utent fuq il-prosodija. Pereżempju, il-ġenerazzjoni ta’ diskors b’kontroll tal-prosodija fina (prominenza prosodika, emozzjonijiet kuntestwalment xierqa) għadha sfida miftuħa. In this paper, we investigate whether we can control prosody directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor.  Aħna nibnu u nqasmu sett ta’ dejta speċifiku għal dan l-iskop u nuru li dan jippermetti t-taħriġ ta’ sistema TTS jekk din il-karatteristika prosodika ta’ ħbub irfinat tista’ tiġi trasportata b’mod korrett bl-użu ta’ tokens ta’ kontroll. L-evalwazzjoni tagħna tqabbel l-espressjonijiet sintetiċi u naturali u turi li jistgħu jitgħallmu b’mod preċiż xejriet prosodiċi ta’ fokus kuntrastiv (varjazzjonijiet ta’ Fo, Intensità u Tul). Dan l-istadju importanti huwa li jippermetti, pereżempju, li l-kelliema intelliġenti jkunu kkontrollati b’mod programmatiku f’termini ta’ prosodija tal-output.', 'pl': 'Chociaż End-2-End Text-to-Speech (TTS) poczynił znaczące postępy w ciągu ostatnich kilku lat, systemy te nadal brakują intuicyjnej kontroli użytkownika nad prosodią. Na przykład generowanie mowy z precyzyjną kontrolą prozodii (promieniowanie prozodii, odpowiednie kontekstowo emocje) jest nadal otwartym wyzwaniem. W artykule badamy, czy możemy kontrolować prozodię bezpośrednio z tekstu wejściowego, aby kodować informacje związane z kontrastywnym skupieniem, które podkreśla konkretne słowo sprzeczne z założeniami rozmówcy. Budujemy i udostępniamy konkretny zestaw danych w tym celu i pokazujemy, że pozwala on na trenowanie systemu TTS, gdzie ta drobnoziarnista funkcja prozodyczna może być poprawnie przekazywana za pomocą tokenów kontrolnych. Nasza ocena porównuje syntetyczne i naturalne wypowiedzi i pokazuje, że prozodyczne wzorce kontrastywnego ostrości (odmiany Fo, Intensywności i Czasu trwania) można dokładnie nauczyć się. Taki kamień milowy jest ważny, aby umożliwić np. sterowanie inteligentnymi głośnikami programowe pod względem prozodii wyjściowej.', 'ro': 'În timp ce End-2-End Text-to-Speech (TTS) a făcut progrese semnificative în ultimii ani, aceste sisteme încă nu dispun de controale intuitive ale utilizatorilor asupra prosodiei. De exemplu, generarea discursului cu control fin al prosodiei (proeminență prosodică, emoții adecvate contextual) este încă o provocare deschisă. În această lucrare, investigăm dacă putem controla prosodia direct din textul de intrare, pentru a coda informații legate de focalizarea contrastantă care subliniază un anumit cuvânt contrar presupunerilor interlocutorului. Construim și împărtășim un set de date specific în acest scop și arătăm că permite instruirea unui sistem TTS în cazul în care această caracteristică prosodică fină poate fi transmisă corect folosind token-uri de control. Evaluarea noastră compară cuvintele sintetice și naturale și arată că modelele prosodice de focalizare contrastantă (variații de Fo, Intensitate și Durată) pot fi învățate cu precizie. Un astfel de reper este important pentru a permite, de exemplu, difuzoarelor inteligente să fie controlate programatic în ceea ce privește prosodia de ieșire.', 'mn': 'Сүүлийн хэдэн жилийн турш 2-ын төгсгөл текст-ээс ярианд маш чухал хөгжлийг гаргасан ч эдгээр системүүд хувьд зөвхөн хэрэглэгчийн удирдлагатай байхгүй. Жишээлбэл, жишээлбэл, сайхан тарианы удирдлагатай яриаг бий болгох нь нээлттэй сорилт юм. Энэ цаасан дээр бид үүнийг бичсэн текстээс шууд удирдаж чадах эсэхийг судалж, харьцуулагчдын эсрэг тодорхой үгийг тодорхойлж чадна. Бид энэ зорилго дээр тодорхой өгөгдлийн санг бүтээж хуваалцаж, TTS системийг суралцах боломжтой гэдгийг харуулж байна. Энэ сайхан тарианы хувьд контрол тэмдэгтийг ашиглан зөв холбогдож болно. Бидний оюутнууд синтетик, байгалийн хэлэлцээг харьцуулж, эсрэг төвлөрүүлэлтийн происодик хэлбэрүүдийг зөв суралцаж чадна. Жишээлбэл, ухаантай илтгэгчид бүтээгдэхүүний хувьд програм хандлагатай боломж олгох нь чухал.', 'no': 'Mens slutt2- slutttekst- til- tale (TTS) har gjort signifikante framgangar i løpet av dei siste få år, manglar desse systema fortsatt intuitivt brukarnontrollar over prosodi. For eksempel er det framleis eit opna utfordring for å laga tale med fin-korn prosodisk kontroll (prosodisk viktig, samtidig tilpassande følelser). I denne papiret undersøker vi om vi kan kontrollera prosody direkte frå inndatateksten, for å kunna kode informasjon relatert til kontrastfokus, som undersøker eit spesifikke ord som er motsatt motsetningane av interlocutoren. Vi bygger og deler ein spesifikk dataset for dette målet og viser at det tillater å trenja ein TTS- system var denne fyrste prosodiske funksjonen som kan rett konverterast med kontrollteikn. Evalueringa vårt samanliknar syntetiske og naturlege uttrykk og viser at prosodiske mønster med kontrastfokus (variasjonar av Fo, intensitet og lengd) kan lærast nøyaktig. Dette er viktig for å tillata, for eksempel, smart taler å vera programmet kontrollert under utgangspunkt.', 'so': 'Intii uu dham-2-End Text-to-Speech (TTS) uu horumariyey horumar aad u weyn sanadkii hore, nidaamkan weli ma baahna maamulka isticmaalka waxgarashada ah ee prosody. Tusaale ahaan hadal ku soo bixinta maamulka dhillooyinka (muuqashada dhillooyinka, fikrada ku habboon) weli waa dhibaato furan. Qoraalkan waxaynu baaraynaa in aan toos uga maamuli karno qoraalka gudaha, si aan u qorno macluumaad la xiriira iskuulka ka geesta ah, kaas oo ku qoraya hadal gaar ah oo ka gees ah horumarinta qofka wadanka ah. Waxaynu dhisaynaa oo u qaybnaynaa sawirada gaar ah taas darteed waxaana tusaynaa in lagu barto nidaamka TTS-da in lagu sameyn karo alaabta maamulka ah ee sharafta leh. Qiimeyntayada ayaa isbarbardhiga hadallada dhexe iyo dabiicadda ah, wuxuuna muujiyaa in si saxda ah loo baro qaabab ka gees ah (kala duwan Fo, Intaanta iyo Dureerka). Tusaale ahaan waxaa muhiim ah in lagu ogolaado kuwa hadla kuwa caqliga leh si programka lagu maamulo waxyaabaha la soo baxay prosody.', 'sv': 'Även om End-2-End Text-to-Speech (TTS) har gjort betydande framsteg under de senaste åren saknar dessa system fortfarande intuitiv användarkontroll över prosody. Till exempel, att generera tal med finkornig prosodkontroll (prosodisk framträdande, kontextuellt lämpliga känslor) är fortfarande en öppen utmaning. I denna uppsats undersöker vi om vi kan styra prosodi direkt från inmatningstexten, för att koda information relaterad till kontrastivt fokus som betonar ett specifikt ord som strider mot samtalspartens förutsättningar. Vi bygger och delar ett specifikt dataset för detta ändamål och visar att det gör det möjligt att träna ett TTS-system där denna finkorniga prosodiska funktion kan överföras korrekt med hjälp av kontrolltokens. Vår utvärdering jämför syntetiska och naturliga uttryck och visar att prosodiska mönster av kontrastivt fokus (variationer av Fo, Intensitet och Varaktighet) kan läras korrekt. En sådan milstolpe är viktig för att t.ex. smarta högtalare ska kunna styras programmatiskt i termer av output prosodi.', 'sr': 'Iako je kraj 2-kraj tekst na govor (TTS) postigao značajne napredke u proteklih nekoliko godina, ovi sistemi još uvek nedostaju kontrole intuitivnog korisnika nad prosodijom. Na primjer, stvaranje govora sa kontrolom prosodijskih prozora (prosodijska velikost, u kontekstu odgovarajuća emocija) još uvijek je otvoren izazov. U ovom papiru istražujemo da li možemo upravljati prozorom direktno iz teksta ulaska, kako bi kodirali informacije povezane sa kontrastivnim fokusom koja naglašava specifičnu reč koja je suprotna predstavljanju interlocutor a. Mi izgradimo i dijelimo specifičnu setu podataka za ovu svrhu i pokažemo da omogućava trenirati TTS sistem, da je ova prosodska karakteristika mogla biti ispravno povezana koristeći kontrolne znakove. Naša procjena uspoređuje sintetičke i prirodne reči i pokazuje da se prosodičke obrasce kontrastivnog fokusa (varijacije Fo, intenzivnosti i trajanja) mogu precizno naučiti. Takva mješavina je važna kako bi, na primer, pametni govornici omogućili da budu programski kontrolirani u smislu prosodije izlaza.', 'si': 'අන්තිම 2- අවසානය පාළුවෙන් (TTS) කියලා පසුගින් අවුරුදු කීපයකින් ගොඩක් වැඩ කරලා තියෙනවා නම්, මේ පද්ධතියට තවමත් ප්\u200dරය උදාහරණයෙන්, හොඳ ප්\u200dරොසෝඩි පාලනය සමග කතාවක් නිර්මාණය කරන්න (ප්\u200dරොසෝඩික් ප්\u200dරොසෝඩික් ප්\u200dරශ්නයක්, සම්පූර මේ පත්තරේ අපි පරීක්ෂණය කරනවා අපිට ප්\u200dරොසොඩි පාළුවන් පුළුවන්ද කියලා ඇතුළු පාළුවන් පුළුවන්ද කියලා, කෝඩ් තොරතුරු සම්බන්ධ විශ අපි මේ අදහසට විශේෂ දත්ත සූදානයක් නිර්මාණය කරනවා ඒ වගේම පෙන්වන්නේ TTS පද්ධතියට ප්\u200dරයෝජනය කරන්න පුළුවන් කියලා ප්\u200dරයෝ අපේ විශ්ලේෂණය සහ ස්වභාවික කියන්න සහ ප්\u200dරොසොඩික් පෙන්වන්න පුළුවන් කියලා පෙන්වන්නේ ප්\u200dරොසොඩික් පෙන්වන්න පුළුවන් සිද මෙච්චර ප්\u200dරශ්නයක් වැදගත් වෙන්නේ උදාහරණයෙන්, ස්මාර්ට් ස්පීකර්ට් වලින් ප්\u200dරශ්නයක් ප්\u200dරශ්නයකින් ප්\u200d', 'ur': 'حالانکہ آخر-2-End Text-to-Speech (TTS) اگلوں کے چند سالوں میں اہم طرح پیش آئی ہے، ان سیسٹموں کو ابھی بھی غیر نظریہ کارساز کی کنٹرول نہیں ہے۔ مثال یہ ہے کہ پاکیزہ دانے کے کنٹرول کے ساتھ کلام پیدا کرنے کا ایک کھلا چال ہے۔ ہم اس کاغذ میں تحقیق کریں کہ ہم اپنا پیغام ٹیکسٹ سے مستقیماً پروسڈی کو کنٹرول کر سکتے ہیں، کیونکہ کنٹروسٹ فوकस کے معاملات کے لئے کوڈ معلومات کی تدبیر کریں جو ایک خاص کلم کو تدبیر کرتا ہے جو بیٹروسٹر کی پیش آپٹ موق ہم نے اس کے لئے ایک خاص ڈیٹ سٹ بنایا اور شریک بنایا اور دکھائی کہ یہ TTS سیستم کی ترین کرنا اجازت دیتا ہے کہ یہ پاکیزہ دانہ پروسوڈیک فوکتور سیدھی طرح کنٹرول ٹوکنوں کے مطابق اٹھائی جاتی ہے۔ ہماری ارزیابی سینٹیسی اور طبیعی کلمات کی مثال بیان کرتی ہے اور دکھاتی ہے کہ مخالف فو کی پروسوڈیسی پٹرنے کو دقیق سمجھ سکتے ہیں۔ اس طرح کا مائلسٹون اہم ہے کہ مثال، اسمائلٹ صحبت کرنے والوں کو پوروگرامیکی طور پر کنٹرول کرنا اجازت دے۔', 'ta': 'முடிவு- 2- முடிவு உரையில் இருந்து பேச்சு (TTS) கடந்த சில வருடங்களில் முக்கியமான முன்னேற்றங்கள் செய்துள்ளது, இந்த அமைப்புகள் இன்னும்  உதாரணத்திற்கு, நல்ல பிடிக்கப்பட்ட பிராஸ்டி கட்டுப்பாட்டுடன் பேச்சை உருவாக்குதல் (பிரோசோடிக் கண்ணியம், பொருத்தமான உண இந்த காகிதத்தில், நாம் நேரடியாக உள்ளீட்டு உரையிலிருந்து பிராசியை கட்டுப்படுத்த முடியுமா என்று ஆராய்ச்சி செய்கிறோம், இது மாற்று முன்னிரு இந்த காரணத்திற்கான குறிப்பிட்ட தகவல் அமைப்பை நாம் கட்டுப்பாட்டு குறிப்பிட்டு பகிர்ந்து ஒரு TTS அமைப்பை பயிற்சிக்க அனுமதிக்கும நம்முடைய மதிப்பினை ஒப்பிடும் சார்ந்த வார்த்தைகளை ஒப்பிடும் மற்றும் காண்பிக்கிறது எதிர்பார்ப்பு முன்னோடிக்கையின் மாதிரிகள Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody.', 'uz': "@ info: whatsthis Masalan, ajoyib prosodi boshqaruvi bilan gapirish (prosodik taxminan, taxminan hissiyalar) hammasi ochiq challeng. Bu qogʻozda, biz kiritish matnning tarkibini aniqlab boshqarishimiz mumkin, boshqa fokus bilan bogʻ'liq maʼlumotni kodlash uchun ularning interlocutorining joylariga bog'liq boʻlgan notoʻgʻri soʻzni qo'yish mumkin. Biz bu uchun foydalanuvchi uchun foydalanuvchi maʼlumotlar tarkibini yaratib boʻlishimiz va u TTS tizimini ishlatish imkoniyatini koʻrsatish mumkin, bu ajoyib boʻlgan prosodik imkoniyatini to ʻgʻri boshqarish belgini ishlatish mumkin. Bizning qiymatlarimiz syntetik va tabiiy so'zlarni kamaytirish va ko'rsatish mumkin, prosodik foydalanuvchi shakllar (Fo, Intensitiv va davomida o'zgarishlar) toʻgʻri o'rganadi. Masalan, shpritz prosodiya davomida smart gapiruvchilarni programatik boshqarish muhim.", 'vi': 'Tuy rằng cuối-2-End Văn bản-gọi-Ngôn (TTP) đã có những tiến bộ đáng kể trong vài năm qua, nhưng hệ thống này vẫn thiếu kiểm soát người dùng trực tiếp về giai đoạn này. Ví dụ, phát ngôn bằng cách điều khiển văn chương (nét nổi bật, cảm xúc tương xứng) vẫn là một thử thách cởi mở. Trong tờ giấy này, chúng tôi tìm hiểu xem có thể kiểm soát giai đoạn trực tiếp từ văn bản nhập không, để mã hóa thông tin liên quan tới tiêu điểm tương phản, mà nhấn mạnh một từ cụ thể trái với giả thuyết của người liên kết. Chúng tôi xây dựng và chia sẻ một bộ dữ liệu cụ thể cho mục đích này và cho thấy nó cho phép huấn luyện một hệ thống TTP nếu đó là tính năng văn chương phức tạp này có thể được chuyển đúng bằng các vật điều khiển. Bài đánh giá của chúng tôi so sánh những phát biểu tổng hợp và tự nhiên và cho thấy các mô hình văn học tương phản (biến đổi độ mạnh, độ dài và độ dài) có thể được học chính xác. Một mốc quan trọng như vậy là để cho phép những người nói thông minh được kiểm soát theo lập trình về giai đoạn sản xuất.', 'bg': 'Въпреки че през последните няколко години е постигнат значителен напредък, тези системи все още нямат интуитивен потребителски контрол върху прозодията. Например генерирането на реч с фин контрол на прозодите (прозодна популярност, контекстуално подходящи емоции) все още е отворено предизвикателство. В настоящата статия изследваме дали можем да контролираме прозодията директно от входния текст, за да кодираме информация, свързана с контрастивния фокус, който подчертава конкретна дума, която противоречи на предположенията на събеседника. Създаваме и споделяме специфичен набор от данни за тази цел и показваме, че той позволява да се обучава система, където тази фино зърнеста прозодна функция може да бъде правилно предадена с помощта на контролни токени. Нашата оценка сравнява синтетични и естествени изказвания и показва, че прозодните модели на контрастивен фокус (вариации на Фо, интензитет и продължителност) могат да бъдат научени точно. Такъв етап е важен, за да се позволи например на интелигентните високоговорители да бъдат програмно контролирани по отношение на прозодията на изхода.', 'nl': 'Hoewel End-2-End Text-to-Speech (TTS) de afgelopen jaren aanzienlijke vooruitgang heeft geboekt, missen deze systemen nog steeds intuïtieve gebruikerscontrole over prosodie. Zo is het genereren van spraak met fijnkorrelige prosodiecontrole (prosodische prominentie, contextueel passende emoties) nog steeds een open uitdaging. In dit artikel onderzoeken we of we prosodie direct vanuit de invoertekst kunnen controleren, om informatie te coderen die betrekking heeft op contrastieve focus die een specifiek woord benadrukt dat in strijd is met de vooronderstellingen van de gesprekspartner. We bouwen en delen een specifieke dataset voor dit doel en laten zien dat het toelaat om een TTS-systeem te trainen waar deze fijnkorrelige prosodische functie correct kan worden overgebracht met behulp van control tokens. Onze evaluatie vergelijkt synthetische en natuurlijke uitingen en toont aan dat prosodische patronen van contrastieve focus (variaties van Fo, Intensiteit en Duur) nauwkeurig kunnen worden geleerd. Een dergelijke mijlpaal is belangrijk om bijvoorbeeld slimme speakers programmatisch te laten aansturen in termen van outputprosodie.', 'da': 'Mens End-2-End Text-to-Speech (TTS) har gjort betydelige fremskridt i løbet af de seneste par år, mangler disse systemer stadig intuitiv brugerkontrol over prosody. For eksempel er det stadig en åben udfordring at generere tale med finkornet prosodikontrol (prosodisk fremtræden, kontekstuelt passende følelser). I denne artikel undersøger vi, om vi kan styre prosodi direkte fra input teksten, for at kode information relateret til kontrast fokus, der understreger et specifikt ord, der er i strid med samtalens forudsætninger. Vi bygger og deler et specifikt datasæt til dette formål og viser, at det gør det muligt at træne et TTS-system, hvor denne finkornede prosodiske funktion kan formidles korrekt ved hjælp af kontroltokens. Vores evaluering sammenligner syntetiske og naturlige udtalelser og viser, at prosodiske mønstre af kontrastivt fokus (variationer af Fo, Intensitet og Varighed) kan læres præcist. En sådan milepæl er vigtig for eksempel at gøre det muligt for smarte højttalere at styres programmatisk i form af output prosodi.', 'hr': 'Iako je u proteklih nekoliko godina krajnji tekst na govor (TTS) postigao značajan napredak, ovi sustavi još uvijek nedostaju kontrole intuitivnog korisnika nad prosodijom. Na primjer, stvaranje govora sa kontrolom prosodijske prosodije (prosodijska velikost, u kontekstu odgovarajuće emocije) još uvijek je otvoren izazov. U ovom papiru istražujemo da li možemo upravljati prozorom direktno iz teksta ulaska kako bi kodirali informacije povezane s kontrastivnim fokusom koja naglašava specifičnu riječ koja je suprotna predstavljanju interlocutor a. Mi izgradimo i dijelimo specifičnu setu podataka za ovu svrhu i pokazujemo da omogućava trenirati TTS sustav da je ova prosodska funkcija dobra zrnca mogla biti ispravno povezana koristeći kontrolne znakove. Naša procjena uspoređuje sintetičke i prirodne riječi i pokazuje da se prosodičke obrasce kontrastivnog fokusa (varijacije Fo, Intenzitet i Duration) mogu precizno naučiti. Takva mješavina je važna kako bi, na primjer, omogućila da pametni govornici budu programski kontrolirani u smislu prosodije proizvoda.', 'de': 'Während End-2-End Text-to-Speech (TTS) in den letzten Jahren erhebliche Fortschritte gemacht hat, fehlt es diesen Systemen immer noch an intuitiven Bedienelementen über Prosodie. Zum Beispiel ist die Erzeugung von Sprache mit feingranularer Prosodienkontrolle (prosodische Prominenz, kontextbezogene Emotionen) nach wie vor eine offene Herausforderung. In diesem Beitrag untersuchen wir, ob wir die Prosodie direkt aus dem Eingabetext steuern können, um Informationen im Zusammenhang mit kontrastiver Fokussierung zu kodieren, die ein bestimmtes Wort betont, das den Annahmen des Gesprächspartners widerspricht. Wir bauen und teilen einen spezifischen Datensatz zu diesem Zweck und zeigen, dass damit ein TTS-System trainiert werden kann, in dem diese feinkörnige prosodische Funktion mit Control Tokens korrekt übertragen werden kann. Unsere Auswertung vergleicht synthetische und natürliche Äußerungen und zeigt, dass prosodische Muster des kontrastiven Fokus (Variationen von Fo, Intensität und Dauer) genau erlernt werden können. Ein solcher Meilenstein ist wichtig, um beispielsweise intelligente Lautsprecher programmatisch in Bezug auf die Ausgangsprosodie steuern zu können.', 'id': 'Sementara End-2-End Text-to-Speech (TTS) telah membuat kemajuan yang signifikan selama beberapa tahun terakhir, sistem-sistem ini masih kekurangan kontrol pengguna intuitif atas prosody. For instance, generating speech with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge.  Dalam kertas ini, kita menyelidiki apakah kita dapat mengendalikan prosody langsung dari teks input, untuk kode informasi berkaitan dengan fokus kontras yang menekankan kata spesifik yang bertentangan dengan anggapan interlocutor. Kami membangun dan berbagi set data spesifik untuk tujuan ini dan menunjukkan bahwa itu memungkinkan untuk melatih sistem TTS adalah karakteristik prosodik fine grained ini dapat disampaikan dengan benar menggunakan token kendali. Evaluasi kami membandingkan ucapan sintetis dan alami dan menunjukkan bahwa pola prosodik fokus kontras (variasi Fo, Intensity dan Duration) dapat dipelajari dengan tepat. Hal ini penting untuk memungkinkan, contohnya, pembicara pintar untuk dikendalikan secara programmatis dalam terma prosody output.', 'ko': '과거 몇 년 동안 끝에서 끝까지 텍스트에서 음성(TTS)으로 큰 진전을 거두었지만 이러한 시스템은 여전히 사용자가 운율에 대한 직관적인 제어가 부족하다.예를 들어 세립도 운율 제어(운율이 두드러지고 언어 환경이 적당한 정서)를 가진 음성을 생성하는 것은 여전히 개방적인 도전이다.본고에서 우리는 입력 텍스트에서 운율을 직접 제어하여 대비 초점과 관련된 정보를 인코딩하고 대비 초점은 대화자가 설정한 것과 상반된 특정 단어를 강조할 수 있는지 연구한다.우리는 이를 위해 특정한 데이터 집합을 구축하고 공유했으며 이러한 세립도 운율 특징이 제어 표시를 사용하여 정확하게 전달할 수 있다면 TTS 시스템을 훈련할 수 있음을 나타냈다.우리의 평가는 합성어와 자연어를 비교하고 초점을 비교하는 운율모델(Fo, 강도와 지속시간의 변화)을 정확하게 학습할 수 있음을 나타냈다.예를 들어 이런 이정표는 스마트 스피커가 출력 운율에 대해 프로그래밍 제어를 할 수 있도록 하는 데 매우 중요하다.', 'sw': 'Wakati mwisho-2-End-Text-to-Speech (TTS) umefanya maendeleo makubwa katika miaka michache iliyopita, mifumo hii bado hayana uwezo wa kudhibiti mtumiaji wenye ufahamu juu ya prosody. Kwa mfano, kutengeneza hotuba yenye udhibiti mzuri wa mashoga (umaarufu wa kimapenzi, hisia zinazohitajika) bado ni changamoto iliyo wazi. In this paper, we investigate whether we can control prosody directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor.  Tunajenga na kusambaza seti maalum kwa ajili ya lengo hili na kuonyesha kwamba inaruhusu kufundisha mfumo wa TTS kama utaratibu huu mzuri wa mazoea unaweza kusambazwa kwa kutumia alama za udhibiti. Utafiti wetu unalinganisha maneno ya pamoja na asili na inaonyesha kuwa mitindo ya kimapenzi ya mtazamo tofauti (mabadiliko ya Fo, Ujasiri na Miadi) yanaweza kujifunza kwa sahihi. Simu kama hiyo ni muhimu kuruhusu, kwa mfano, wazungumzaji wenye akili kudhibitiwa kwa programu kwa sababu ya matumizi ya prosody.', 'tr': '2-i흫 so흫ky metin we s철zleri흫 (TTS) ge챌en birn채챌e 첵yldan b채ri m철h체m 철s체힊ip 첵철r채n boldy, bu sistemler hala 철흫체nde n채hili m철h체m 첵체z tutarlar. Mesela, i흫lisi ta첵첵arlyk kontrol bilen 챌yky힊 d철retm채ge (kyn챌ylyk, du첵gular) ent채gem a챌yk kyn챌ylykdyr. Bu kagyzda, biz esasy s철zleri흫 giri힊 metinden 첵체z tutyp biljegimizi barla첵arys di첵ip soru힊첵arys, we bu s철zleri흫 kontrast fokus bilen baglany힊yk s철zleri흫 gar힊ylaryna gar힊y edilen s철zleri흫 gar힊y. Biz bu maksady흫 체챌in belli bir veri setirini in힊a edip payla힊첵arys we TTS sistemini 철wrenm채ge m체mkin ed첵채ndigini g철rkez. Bizi흫 de흫lemegimiz sintetik we tebigy s철zlerini kar힊캇la힊첵ar we dogry 철wrenip biler. 횜rne휓in, akylly s철zleri 챌yky힊 철n체nde programatik 힊eklinde kontrol etmek 체챌in wajyp d체힊er.', 'fa': 'در حالی که متن\u200cهای پایان ۲-پایان به سخنرانی (TTS) در چند سال گذشته پیشرفت\u200cهای بزرگی را انجام داده است، این سیستم\u200cها هنوز کنترل کاربر\u200cهای بی\u200cنظیر در مورد پیشرفت وجود ندارند. برای مثال، تولید سخنرانی با کنترل کنترل قوانین پاکیزه (احساسات مناسب در موقعیت) هنوز یک چالش باز است. در این کاغذ، ما تحقیق می\u200cکنیم که آیا می\u200cتوانیم مستقیماً از متن ورودی پروسد را کنترل کنیم، تا اطلاعات کد مربوط به تمرکز متفاوتی که به یک کلمه خاص تضمین می\u200cدهد که بر خلاف موقعیت پیش\u200cبینی\u200cهای پرچم\u200cکننده است. ما یک مجموعه داده خاص را برای این هدف ساختیم و تقسیم می\u200cکنیم و نشان می\u200cدهیم که آن اجازه می\u200cدهد سیستم TTS را آموزش دهد که این ویژگی prosodic با استفاده از نشانه\u200cهای کنترل دقیقاً می\u200cتواند با استفاده از نشانه\u200cهای کنترل به طور درست ارزیابی ما کلمات سینتاتیک و طبیعی را مقایسه می\u200cکند و نشان می\u200cدهد که الگوهای مختلف تمرکز (تغییرات فو، هوشمند و طول) دقیقاً می\u200cتوانند یاد بگیرند. چنین مایلستان مهم است که برای مثال اجازه دهند سخنرانی باهوش به صورت برنامه\u200cریزی تحت کنترل قرار دهند.', 'af': "Terwyl Einde- 2- Einde Teks na- Spraak (TTS) betekeurige vorderings in die verlede paar jaar gemaak het, het hierdie stelsels nog intuitiewe gebruiker beheer oor prosody. Byvoorbeeld, die genereering van spraak met fyn-graad prosodie kontrole (prosodie prominence, contextually appropriate emosies) is nog 'n oop uitdrukking. In hierdie papier, ons ondersoek of ons direk kan kontroleer die voorwerp van die invoer teks, om kode inligting wat verwanter is met kontrastiese fokus wat 'n spesifieke woord bepaal wat teen die voorwerp posisies van die interlocutor is. Ons bou en deel 'n spesifieke datastel vir hierdie doel en wys dat dit toelaat om 'n TTS stelsel te trein was hierdie fyn-koring prosodiese funksie kan korrek verbind word deur beheer tokens. Ons evaluering vergelyk sintetiese en natuurlike uitspraak en wys dat prosodiese patrone van kontrastiese fokus (variasies van Fo, Intensiteit en Duur) presies geleer kan word. So 'n milestone is belangrik om, byvoorbeeld, slimme sprekkers te toelaat om programmatiek beheer te word in terms van uitvoer voorspoedie.", 'am': 'የመጨረሻ-2-መጨረሻ ጽሑፍ-ወደ-ንግግር (TTS) ባለፉት ጥቂት ዓመታት የበለጠ ውጤቶች ባደረገ ጊዜ፣ እነዚህ ስርዓቶች በፕሮዝዲዩ ላይ የሚቆጠሩ ተጠቃሚዎች ገና አይደሉም፡፡ ለምሳሌ፣ በተመሳሳይ የፕሮግራሙዲ ግንኙነት ንግግር መፍጠር (የፕሮጀዲክ ክፍልፍል፣ አስተያየት የሚያስፈልገው እውቀት) ገና የተከፈተ ጉዳይ ነው፡፡ በዚህ ገጽ ውስጥ ፕሮስዲዮን ከመግለጫው ጽሑፍ አቅራቢያ መቆጣጠር እናችላለን፣ በተቃዋሚ ፎክሎት ላይ ያሉትን የጽሑፍ መረጃዎች እና በመቃወም የሚቃወሙትን የተለየውን ቃል እናስጠንቃለን፡፡ We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens.  ማስታወቂያውን የሲንቲካዊ እና የአፍሪካዊ ቃላትን ያሳያል እናም የተቃውሞ ፎቶ (የፎ፣ ማወቂያ እና ማወቅ) በተፈንታ ይማራል፡፡ እንደዚህ ሚሊ ድንጋይ፣ ለምሳሌ ብልሃተኞች የውጤት ፕሮጀክዲ በተደረገው በፕሮግራም ለመቆጣጠር ያስፈልጋሉ፡፡', 'az': 'Son-2-Son Metin-to-Speech (TTS) son neçə il ərzində möhkəm tədbir etdiyi halda, bu sistemlər hələ də prosodi üzərində intuitiv istifadəçi kontrolləri yoxdur. Məsələn, gözəl dənələr kontrolü ilə danışmaq (prosodik vəziyyət, müxtəlif möhkəm duygular) hələ də açıq bir çətinlikdir. Bu kağızda, biz prosodiya daxilindən doğrudan istifadə edə biləcəyimizi təsdiqləyirik, müxtəlif fokusla bağlı kodlar informasiyasını təsdiqləyirik ki, müxtəlif sözlərin əvvəlcə istifadə edə biləcəyimizi təsdiqləyirik. Biz bu məqsəd üçün müəyyən bir verilən qurğunu inşa edir və paylaşırıq və göstəririk ki, TTS sistemini təhsil etməyə imkan verir, bu prosodik fəaliyyəti kontrol işaretləri ilə düzgün təhsil edilə bilər. Növbətimiz sintetik və təbiətli sözləri ilə qarşılaşdırır və prosodik şəkillərin (Fo, Intensity və Duration dəyişiklikləri) doğrudan öyrənə bilər. Örneğin, bu səviyyədə a ğıllı danışanların çıxış prosodiyyəti ilə proqrametik olaraq kontrol edilməsini imkan vermək vacibdir.', 'bn': 'বিগত কয়েক বছরের মধ্যে শেষ-২-শেষ টেক্সট-ট্রো-বক্তৃতা বিশাল অগ্রগতি সৃষ্টি করেছে, কিন্তু এই সিস্টেম প্রোসোডির উপর ব্যবহারকারীদের ব উদাহরণস্বরূপ, সুন্দর প্রোসোডি নিয়ন্ত্রণের সাথে বক্তৃতা তৈরি করা হচ্ছে (প্রোসোডিক বিশ্ববিদ্যালয়, যুক্ত অনুভূতির এই কাগজটিতে আমরা তদন্ত করি আমরা ইনপুট টেক্সট থেকে সরাসরি প্রোসোডিকে নিয়ন্ত্রণ করতে পারি কিনা, যাতে বিরোধী ফোকাসের সাথে সংক্রান্ত তথ্য প্রদান করা যায় যা  আমরা এই উদ্দেশ্যের জন্য একটি নির্দিষ্ট ডাটাসেট তৈরি করি এবং শেয়ার করি এবং দেখাচ্ছি যে এটি টিটিএস সিস্টেম প্রশিক্ষণ করার অনুমতি দেয় যে এই ভালো ক্ আমাদের মূল্যায়ন সিন্টেটিক এবং প্রাকৃতিক বক্তব্যের তুলনা করে এবং দেখাচ্ছে যে বিরোধী ফোকাসের প্রাকৃতিক প্রাকৃতিক প্রাকৃতিক প্রাক উদাহরণস্বরূপ, আউটপুট প্রোসোডির মাধ্যমে স্মার্ট ভাষাকে প্রোগ্রামিক্যালিক নিয়ন্ত্রণের অনুমতি দেওয়া গুরুত', 'bs': 'Iako je kraj 2-kraj tekst na govor (TTS) proveo značajne napredke u proteklih nekoliko godina, ovi sistemi još uvijek nedostaju kontrole intuitivnog korisnika nad prosodijom. Na primjer, stvaranje govora sa nadzornom prosodijskom kontrolom (prosodijska velikost, u kontekstu odgovarajuća emocija) još uvijek je otvoren izazov. U ovom papiru istražujemo da li možemo upravljati prozorom direktno iz teksta ulaska, kako bi kodirali informacije povezane sa kontrastivnim fokusom koja naglašava specifičnu riječ koja je suprotna predstavljanju interlocutor a. Mi izgradimo i dijelimo specifičnu setu podataka za ovu svrhu i pokazujemo da omogućava trenirati TTS sistem da je ova prosodska karakteristika mogla biti ispravno povezana koristeći kontrolne znakove. Naša procjena uspoređuje sintetičke i prirodne izraze i pokazuje da se prosodičke obrasce kontrastivnog fokusa (varijacije Fo, Intenzitet i Duration) mogu precizno naučiti. Takva mješavina je važna kako bi, na primjer, pametni govornici omogućili da budu programski kontrolirani u smislu prosodije izlaza.', 'ca': "Mentre que en els últims anys el text fins al discurs (TTS) ha fet progrés significatius, aquests sistemes encara no tenen control intuitiu dels usuaris sobre la prosòdia. Per exemple, generar discurs amb el control de la prosòpia fina (prominença prosòdica, emocions adaptades contextualment) encara és un repte obert. En aquest paper, investigam si podem controlar la prosòdia directament del text d'entrada, per codificar informació relacionada amb el foc contrastiu que enfatiza una paraula específica que és contraria a les presuncions del interlocutor. Construim i compartim un conjunt de dades específics per aquest objectiu i demostrem que permet treinar un sistema TTS si aquesta característica prosòdica fina pugui ser transmitida correctament fent servir fitxes de control. La nostra evaluació compara expressions sintètiques i naturals i mostra que es poden aprendre amb precisió patrons prosòdics de foc contrastiu (variacions de Fo, Intensitat i Duració). Una etapa tan important és permetre, per exemple, que els oradors intel·ligents siguin controlats programàticament en termes de prosòdia de producció.", 'cs': 'Zatímco End-2-End Text-to-Speech (TTS) v posledních několika letech udělal významný pokrok, tyto systémy stále postrádají intuitivní uživatelské ovládání prosodií. Například generování řeči s jemnou kontrolou prozodií (prozodická prominence, kontextově vhodné emoce) je stále otevřenou výzvou. V tomto článku zkoumáme, zda můžeme kontrolovat prozodii přímo ze vstupního textu, abychom kódovali informace související s kontrastním zaměřením, které zdůrazňuje konkrétní slovo, které je v rozporu s předpoklady partnera. Pro tento účel sestavujeme a sdílíme specifickou datovou sadu a ukazujeme, že umožňuje trénovat TTS systém, kde lze tento jemnozrnný prozodický prvek správně přenášet pomocí kontrolních tokenů. Naše hodnocení srovnává syntetické a přirozené výroky a ukazuje, že prozodické vzorce kontrastního zaostření (variace Fo, Intenzity a Délky) lze přesně naučit. Takový milník je důležitý, aby například umožnil programově řízení inteligentních reproduktorů z hlediska výstupní prosodii.', 'fi': 'Vaikka TTS (End-2-End Text-to-Speech) on edistynyt merkittävästi viime vuosina, näistä järjestelmistä puuttuu edelleen intuitiivinen käyttäjäkontrolli prosodian suhteen. Esimerkiksi puheen luominen hienojakoisella prosodiakontrollilla (prosodinen näkyvyys, asiayhteyteen sopivat tunteet) on edelleen avoin haaste. Tässä artikkelissa selvitämme, voimmeko kontrolloida prosodiaa suoraan syöttötekstistä koodaamaan kontrastiiviseen fokukseen liittyvää tietoa, joka korostaa tiettyä sanaa, joka on ristiriidassa keskustelukumppanin oletusten kanssa. Rakennamme ja jaamme tätä tarkoitusta varten tietyn datajoukon ja osoitamme, että sen avulla voidaan kouluttaa TTS-järjestelmää, jos tämä hienorakeinen prosodinen ominaisuus voidaan välittää oikein ohjauspoleteilla. Arvioinnissamme vertaillaan synteettisiä ja luonnollisia lauseita ja osoitetaan, että prosodiset kontrastikuviot (Fo, Intensity ja Duration) voidaan oppia tarkasti. Tällainen virstanpylväs on tärkeä, jotta esimerkiksi älykkäitä kaiuttimia voidaan ohjata ohjelmallisesti lähtöprosodian suhteen.', 'hy': 'Մինչդեռ վերջնական 2-ի տեքստի դեպի ելույթ (ԹԹՍ) նշանակալի առաջընթաց է արել վերջին մի քանի տարիների ընթացքում, այս համակարգերը դեռևս չունեն ինտուիտիվ օգտագործողների վերահսկողություններ բարոյականության վերաբերյալ: Օրինակ, խոսակցություն ստեղծելը գեղեցիկ պրոսոդի կառավարման միջոցով (պրոսոդիկ հայտնաբերություն, կոնտեքստոնալ հարմար զգացմունքներ) դեռևս բաց մարտահրավեր է: Այս թղթի մեջ մենք ուսումնասիրում ենք, թե արդյոք մենք կարող ենք վերահսկել մարմինը ուղղակի ներմուծված տեքստից, որպեսզի կոդավորենք ինֆորմացիան, որը կապված է հակադրական կենտրոնաշփությամբ, որը նշանակում է որոշակի բառ, որը հակադրվում է ինտեր We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens.  Մեր գնահատումը համեմատում է սինթետիկ և բնական արտահայտությունները և ցույց է տալիս, որ կոնտրաստիվ կենտրոնացման պրոսոդիկ կաղապարները (ֆո, ինտենսիվության և տևողության տարբերությունները) կարող են ճշգրիտ սովորվել: Այսպիսի զարգացում կարևոր է, օրինակ, թույլ տալու համար, որ խելացի խոսնակները ծրագրավորված վերահսկվեն արտադրյալ բարեկեցության տեսանկյունից:', 'sq': 'Ndërsa End-2-End Text-to-Speech (TTS) ka bërë përparime të rëndësishme gjatë viteve të fundit, këto sisteme ende mungon kontrolli intuitiv të përdoruesve mbi prosody. Për shembull, gjenerimi i fjalimit me kontroll të mirë të prosodisë (shfaqje prosodike, emocione të përshtatshme në kontekst) është ende një sfidë e hapur. In this paper, we investigate whether we can control prosody directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor.  Ne ndërtojmë dhe ndajmë një set të dhënash specifike për këtë qëllim dhe tregojmë se ajo lejon të trajnojë një sistem TTS nëse ky funksion prosodik i hollë mund të transmetohet korrekt duke përdorur shenjat e kontrollit. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately.  Një pikë e tillë është e rëndësishme për të lejuar, për shembull, që folësit e zgjuar të kontrollohen programatikisht lidhur me prosodinë e daljes.', 'et': 'Kuigi viimastel aastatel on teinud märkimisväärseid edusamme, puuduvad need süsteemid endiselt intuitiivselt kasutajate kontrolli prosoodia üle. Näiteks kõne genereerimine peeneteraalse prosoodia kontrolliga (prosoodiline esiletõstmine, kontekstis sobivad emotsioonid) on endiselt avatud väljakutse. Käesolevas töös uurime, kas saame kontrollida prosoodiat otse sisendtekstist, et kodeerida kontrastiivse fookusega seotud informatsiooni, mis rõhutab konkreetset sõna, mis on vastuolus vestluspartneri eeldustega. Selleks loome ja jagame konkreetset andmekogumit ning näitame, et see võimaldab TTS-süsteemi koolitada, kui seda peeneteralist prosoodilist funktsiooni saab õigesti edastada kontrolltokenite abil. Meie hinnang võrdleb sünteetilisi ja looduslikke väljendeid ning näitab, et kontrastse fookuse prosoodilisi mustreid (Fo, intensiivsuse ja kestuse variatsioonid) saab täpselt õppida. Selline verstapost on oluline, et võimaldada näiteks nutikaid kõlariid programmiliselt kontrollida väljundprosoodia osas.', 'sk': 'Čeprav je končno besedilo v govor (TTS) v zadnjih nekaj letih dosegel znaten napredek, ti sistemi še vedno nimajo intuitivnega nadzora uporabnikov nad prosodijo. Na primer, ustvarjanje govora z drobnozrnatim nadzorom prosodije (prosodična prepoznavnost, kontekstualno ustrezna čustva) je še vedno odprt izziv. V prispevku raziskujemo, ali lahko prosodijo nadzorujemo neposredno iz vhodnega besedila, da bi kodirali informacije, povezane s kontrastnim fokusom, ki poudarja določeno besedo, ki je v nasprotju s predpostavkami sogovornika. V ta namen zgradimo in delimo določen nabor podatkov in dokazujemo, da omogoča usposabljanje sistema TTS, če je ta drobnozrnata prosodična funkcija mogoče pravilno prenesti z uporabo krmilnih žetonov. Naša ocena primerja sintetične in naravne izjave in kaže, da se prosodične vzorce kontrastnega fokusa (variacije Fo, intenzivnosti in trajanja) lahko natančno naučimo. Takšen mejnik je pomemben, da se na primer omogoči programsko nadzorovanje pametnih zvočnikov v smislu izhodne prosodije.', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Sampeyan, nggawe kelas kang cuarep nggawe nguasai paten sing apik (suprotik sak, sampeyan apik) kang isih durung apik. Nang pewiti iki, kita sissislahi kung arah akeh bantuan dipunangé nggambar kelas teks input, dadi kanggo kelas informasi sing nggawe ingkang contrast Awak dhéwé nggawe lan beraksi barêng-barêng dataset kanggo nggawe iki dadi ngono ngono kuwi wis dianggawe sistem TTS iki dadi bono-bono sing bisa dianggap perusahaan prosok sing bisa ngelarang liyane Isopo Soopo kanggo ngilangno sistem sing dikarepaké kanggo sampeyan, dadi, bisa nguasakno cilik kanggo nguasakno supoyo kanggo ngerwih akeh proyek.', 'he': 'למרות שטקסט לשיחה (TTS) קיבל התקדמות משמעותיות בשנים האחרונות, המערכות הללו עדיין חסרות שליטה אינטואיטיבית של משתמשים על פרוסודיה. לדוגמא, ליצור נאום עם שליטה פרוסודית (פרוסודית בראשות, רגשות מתאימים באופן קונטקסטי) עדיין אתגר פתוח. בעיתון הזה, אנו חוקרים אם אנחנו יכולים לשלוט בפרוזודיה ישירות מהטקסט הכניסה, כדי לקוד מידע קשור למוקד ההתנגדות אנו בונים וחלוקים קבוצת נתונים ספציפית למטרה זו ולהראות שהיא מאפשרת לאמן מערכת TTS אם תכונת פרוסודית מעולה זו יכולה להעביר בצורה נכונה באמצעות סימנים שליטה. הערכה שלנו שווה ביטויים סינטטיים וטבעיים ומראה שדפוסים פרוסודיים של התמקדות הנגדית (שווירציות של Fo, Intensity and Duration) יכולים ללמוד בדיוק. Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody.', 'ha': "A lokacin da aka ƙara-2-Daidai-zuwa-Speakin (NTS) ya sami marubuci mai girma a cikin shẽkaru kaɗan da suka riga, wannan na'ura yana ƙaranci tsarin masu amfani da inganci masu kanana da mazaɓa na fasodi. Misali, mai ƙiƙiro magana da Control na mazaɓa mai kyau (prominence, hisia'ar da ke daidai da shi), sai yana da wata tsãwa mai bayyanãwa. Ga wannan takardan, Munã tambaya ko za mu iya iya iya lissafa gaba ɗaya daga matsayin akwatin inputan, dõmin mu kodi information masu husũma da fokus mai motsi da kiyaye, wanda ya ƙayyade wani kalma mai ƙayyade da ke kanana da sifori masu tsakanin mataimaki. Tuna samar da kuma Muke share wani tsari na danne masu ƙayyadadde dõmin wannan aikin ka nuna kuma za'a yarda da shi in tafiyar da wani tsari na TSS idan wannan tsarin tsari mai kyau na samu'a, za'a iya haɗa bayani don a yi amfani da alama na Control. Kayaniyarmu yana samfani da maganar synthetic da natsuwa kuma yana nũna cewa, ana iya iya sanar da misãlai masu motsi na fokus (variants na Fo, Intense da Duri). Ga wannan jerin ayuka na muhimu a yarda, dõmin misali, za'a iya lissafa wasu mãsu magana masu hankali da su zama shiryoyin ayuka a lokacin fitarwa.", 'bo': 'དེ་ལྟ་མི་ཚིག་གི་ལོ་ཚིགས་རྗེས་མཇུག་གི་ཡི་གེ་སྒེར་གྱི་ནང་དུ་ཚོ་ཡང་མཐོ་རྐྱེན་བྱུང་། དཔེར་ན། བློ་གཏོང་དང་གནད་དོན་ལས་ཕར་ཆེན་ལ་བཟོ་བཞིན་ཡོད། འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་འུ་ཅག་གིས་བྱུང་བའི་ཚིག་ཡིག་གི་འགྲེལ་བཤད་ཀྱི་ཆ་འཕྲིན་དང་མཐུན་འགྱུར་བའི་གསལ་བཤད་དུ་གཏོང་ཡོད་མིན་བཟོ་བཀལ We build and share a specific dataset for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. ང་ཚོའི་དབྱེ་ཞིབ་ཀྱིས་དབྱེ་བ་དང་སྤྱིར་བའི་ཐ་སྙད་དང་མཐུན་པ་གཉིས་ཀྱིས་མཐུན་ཐུབ་ཀྱི་གཟུགས་རིས་འདྲ་བྱུང་། Such a milestone is important to allow, for example, smart speakers to be programmatically controlled in terms of output prosody.'}
{'en': 'A Large-scale Comprehensive Abusiveness Detection Dataset with Multifaceted Labels from Reddit R eddit', 'es': 'Un conjunto de datos de detección de abuso integral a gran escala con etiquetas multifacéticas de Reddit', 'fr': "Un ensemble de données complet de détection d'abus à grande échelle avec des étiquettes multiformes de Reddit", 'pt': 'Um conjunto de dados abrangente de detecção de abuso em grande escala com rótulos multifacetados do Reddit', 'ar': 'مجموعة بيانات شاملة وواسعة النطاق لاكتشاف إساءة الاستخدام مع ملصقات متعددة الأوجه من Reddit', 'ja': 'Redditの多面的なラベルを備えた大規模な包括的な乱用検出データセット', 'zh': '自Reddit多方标签,大综滥用检测数集', 'hi': 'Reddit से बहुआयामी लेबल के साथ एक बड़े पैमाने पर व्यापक अपमानजनकता डिटेक्शन डेटासेट', 'ru': 'Масштабный комплексный набор данных по выявлению злоупотреблений с многогранными метками от Reddit', 'ga': 'Tacar Sonraí um Bhrath Mí-úsáide Cuimsitheach ar Mhórscála le Lipéid Ilghnéitheacha ó Reddit', 'hu': 'Nagyléptékű, átfogó visszaéléseket észlelő adatkészlet a Reddit többoldalú címkéivel', 'el': 'Ένα ευρείας κλίμακας ολοκληρωμένο σύνολο δεδομένων ανίχνευσης κακοποίησης με πολυδιάστατες ετικέτες από το Reddit', 'it': 'Un set di dati completo di rilevamento di abusi su larga scala con etichette sfaccettate di Reddit', 'kk': 'Көптеген жарлықтарды көптеген үлкен масштабтағы жеңіліктерді анықтау деректер бағдарламасы', 'ka': 'Name', 'lt': 'Didelio masto visapusiško piktnaudžiavimo nustatymo duomenų rinkinys su daugiafunkčiais Reddit ženklais', 'mt': 'Sett ta’ Dejta ta’ Detezzjoni Komprensiva tal-Abużività fuq skala kbira b’Tikketti Multifaceti minn Reddit', 'ms': 'Name', 'mk': 'Name', 'mn': 'Ихэнх хэмжээний хүчирхийллийн хүчирхийллийн мэдээллийн баталгаа Reddit-аас олон талаар', 'ml': 'റെഡിഡിറ്റില്\u200d നിന്നുള്ള പലമുഖമുള്ള ലേബെല്ലുകളുമായി ഒരു വലിയ സ്കേള്\u200d പൂര്\u200dണ്ണമായ അബുസിന്റ് ഡിറ്റെറ്റി', 'no': 'Name', 'pl': 'Kompleksowy zestaw danych o wykrywaniu nadużyć na dużą skalę z wielofunkcyjnymi etykietami Reddit', 'si': 'Name', 'ro': 'Un set de date complet de detectare a abuzurilor la scară largă, cu etichete multiple de la Reddit', 'sr': 'Velika skala komprehensive Abusivenest Detection Data Database sa višestrukim etiketama iz Reddita', 'sv': 'Ett omfattande dataset för upptäckt av missbruk i stor skala med mångfacetterade etiketter från Reddit', 'ta': 'Name', 'so': 'Taariikhda cadaawayaasha baahida ah ee aad u weyn ee dhameystiran', 'ur': 'Name', 'uz': 'Name', 'vi': 'Thiết lập dữ liệu trinh sát lạm dụng rộng rãi với các nhãn đa mặt của Reddit', 'da': 'Et omfattende datasæt til registrering af misbrug i stor skala med flere facetter fra Reddit', 'hr': 'Velika skala komprehensive Abusivenest Detection Data Database sa višestrukim etiketama iz Reddita', 'nl': 'Een grootschalige uitgebreide dataset voor misbruikdetectie met veelzijdige labels van Reddit', 'bg': 'Голям мащабен цялостен набор от данни за откриване на злоупотреби с многостранни етикети от Редит', 'id': 'Sebuah Dataset Deteksi Kekasaran Komprensif Skala Besar dengan Label Multifaceted dari Reddit', 'ko': 'Reddit 는 다방면 라벨 을 갖춘 대규모 종합 남용 검출 데이터 세트 를 제공했다', 'de': 'Ein umfangreicher Datensatz zur Missbrauchserkennung mit facettenreichen Etiketten von Reddit', 'fa': 'Name', 'sw': 'Kiwango kikubwa cha Kugundua Taarifa za Kutokana na Ukosefu wa Kutokana na Labela za Kimbalimbali kutoka Reddit', 'af': 'Name', 'tr': 'Ullakan', 'sq': 'Një bazë të dhënash për zbulimin e abuzimit në shkallë të madhe me etiketa të shumëfaqesuara nga Reddit', 'am': 'undo-type', 'hy': 'Մեծ մասշտաբով ընդհանուր չարաշահության հայտնաբերման տվյալներ Reddit-ից բազմամասնությամբ պիտակներով', 'bn': 'রেডিডিট থেকে বহুমুখী লেবেলের সাথে একটি বিশাল পরিমাপ সম্পূর্ণ অভিযুক্ত তথ্য', 'ca': "Un conjunt de dades de detecció completa d'abusivitat a gran escala amb etiquetes multifacetes de Reddit", 'az': "Reddit'dən çoxlu-fərqli Etiketlər olan Büyük ölçüdə Təşkil Zayıflıq Keşfetmə Veriləri", 'bs': 'Velika skala komprehensive Abusivenest Detection Data Data Data sa Multifaced Labels iz Reddit', 'cs': 'Rozsáhlý komplexní datový set detekce zneužití s mnohostrannými štítky od společnosti Reddit', 'fi': 'Laajamittainen kattava väärinkäytösten tunnistustietosarja, jossa on Redditin monipuolinen etiketti', 'et': 'Laiaulatuslik põhjalik kuritarvitamise tuvastamise andmekogum koos Redditi mitmetahuliste siltidega', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': 'KCharselect unicode block name', 'sk': 'Obsežen celovit nabor podatkov o zaznavanju zlorabe z večplastnimi nalepkami iz Reddita', 'he': 'קבוצת נתונים לגילוי התעללות מורכבת בסולם גדול עם תוויות מרובות מפני Reddit', 'bo': 'A Large-scale Comprehensive Abusiveness Detection Dataset with Multifaced Labels from Reddit'}
{'en': 'As users in  online communities  suffer from severe side effects of  abusive language , many researchers attempted to detect abusive texts from  social media , presenting several  datasets  for such detection. However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of  annotations , leading to much increased  complexity . In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts. Our  dataset  is annotated hierarchically for an efficient  annotation  through  crowdsourcing  on a large-scale. We also empirically explore the characteristics of our  dataset  and provide a detailed analysis for novel insights. The results of our experiments with strong pre-trained natural language understanding models on our  dataset  show that our  dataset  gives rise to meaningful performance, assuring its practicality for abusive language detection.', 'pt': 'Como os usuários em comunidades online sofrem graves efeitos colaterais de linguagem abusiva, muitos pesquisadores tentaram detectar textos abusivos de mídias sociais, apresentando vários conjuntos de dados para tal detecção. No entanto, nenhum deles contém rótulos abrangentes e informações contextuais, essenciais para detectar minuciosamente todos os tipos de abusividade dos textos, uma vez que conjuntos de dados com recursos tão refinados exigem uma quantidade significativa de anotações, levando a uma complexidade muito maior. Neste artigo, propomos um Conjunto de Dados de Detecção de Abusividade Abrangente (CADD), coletado das postagens em inglês do Reddit, com rótulos e contextos multifacetados. Nosso conjunto de dados é anotado hierarquicamente para uma anotação eficiente por meio de crowdsourcing em grande escala. Também exploramos empiricamente as características de nosso conjunto de dados e fornecemos uma análise detalhada para novos insights. Os resultados de nossos experimentos com fortes modelos de compreensão de linguagem natural pré-treinados em nosso conjunto de dados mostram que nosso conjunto de dados gera um desempenho significativo, garantindo sua praticidade para detecção de linguagem abusiva.', 'es': 'Como los usuarios de las comunidades en línea sufren los graves efectos secundarios del lenguaje abusivo, muchos investigadores intentaron detectar textos abusivos en las redes sociales, presentando varios conjuntos de datos para tal detección. Sin embargo, ninguno de ellos contiene tanto etiquetas completas como información contextual, que son esenciales para detectar a fondo todo tipo de abusividad de los textos, ya que los conjuntos de datos con características tan detalladas requieren una cantidad significativa de anotaciones, lo que lleva a una complejidad mucho mayor. En este artículo, proponemos un conjunto de datos integral de detección de abuso (CADD), recopilado de las publicaciones de Reddit en inglés, con etiquetas y contextos multifacéticos. Nuestro conjunto de datos se anota jerárquicamente para una anotación eficiente a través del crowdsourcing a gran escala. También exploramos empíricamente las características de nuestro conjunto de datos y proporcionamos un análisis detallado para obtener información novedosa. Los resultados de nuestros experimentos con modelos sólidos de comprensión del lenguaje natural previamente entrenados en nuestro conjunto de datos muestran que nuestro conjunto de datos da lugar a un rendimiento significativo, lo que garantiza su practicidad para la detección del lenguaje abusivo.', 'ar': 'نظرًا لأن المستخدمين في المجتمعات عبر الإنترنت يعانون من آثار جانبية شديدة للغة المسيئة ، حاول العديد من الباحثين اكتشاف النصوص المسيئة من وسائل التواصل الاجتماعي ، وقدموا العديد من مجموعات البيانات لمثل هذا الاكتشاف. ومع ذلك ، لا يحتوي أي منها على تسميات شاملة ومعلومات سياقية ، والتي تعتبر ضرورية للكشف الشامل عن جميع أنواع التعسف من النصوص ، نظرًا لأن مجموعات البيانات التي تحتوي على مثل هذه الميزات الدقيقة تتطلب قدرًا كبيرًا من التعليقات التوضيحية ، مما يؤدي إلى زيادة التعقيد. في هذه الورقة ، نقترح مجموعة بيانات شاملة للكشف عن إساءة الاستخدام (CADD) ، تم جمعها من منشورات Reddit الإنجليزية ، مع تسميات وسياقات متعددة الأوجه. تم وضع تعليقات توضيحية لمجموعة البيانات الخاصة بنا بشكل هرمي للحصول على تعليق توضيحي فعال من خلال التعهيد الجماعي على نطاق واسع. نحن أيضًا نستكشف بشكل تجريبي خصائص مجموعة البيانات الخاصة بنا ونقدم تحليلاً مفصلاً للحصول على رؤى جديدة. تُظهر نتائج تجاربنا مع نماذج فهم اللغة الطبيعية القوية المدربة مسبقًا على مجموعة البيانات الخاصة بنا أن مجموعة البيانات الخاصة بنا تؤدي إلى أداء هادف ، مما يضمن التطبيق العملي لاكتشاف اللغة المسيئة.', 'fr': "Comme les utilisateurs des communautés en ligne souffrent des effets secondaires graves du langage abusif, de nombreux chercheurs ont tenté de détecter les textes abusifs sur les réseaux sociaux, en présentant plusieurs ensembles de données pour une telle détection. Cependant, aucun d'entre eux ne contient à la fois des étiquettes complètes et des informations contextuelles, qui sont essentielles pour détecter de manière approfondie toutes sortes d'abus dans les textes, étant donné que les ensembles de données présentant des caractéristiques aussi fines nécessitent une quantité importante d'annotations, ce qui augmente considérablement la complexité. Dans cet article, nous proposons un jeu de données complet sur la détection de l'abus (CADD), collecté à partir des publications Reddit en anglais, avec des étiquettes et des contextes à multiples facettes. Notre jeu de données est annoté hiérarchiquement pour une annotation efficace grâce au crowdsourcing à grande échelle. Nous explorons également de manière empirique les caractéristiques de notre ensemble de données et fournissons une analyse détaillée pour obtenir de nouvelles informations. Les résultats de nos expériences avec des modèles solides de compréhension du langage naturel pré-entraînés sur notre ensemble de données montrent que notre jeu de données donne lieu à des performances significatives, garantissant son caractère pratique pour la détection de langage abusif.", 'ja': 'オンラインコミュニティのユーザーは、罵倒的な言葉の重大な副作用に苦しんでいるため、多くの研究者は、ソーシャルメディアから罵倒的なテキストを検出しようとし、そのような検出のためのいくつかのデータセットを提示しました。 しかしながら、そのような細かい機能を持つデータセットはかなりの量の注釈を必要とし、複雑さの大幅な増加につながるため、テキストからあらゆる種類の乱用を徹底的に検出するために不可欠な包括的なラベルと文脈情報の両方を含むものはありません。 本稿では、英語のReddit投稿から収集された総合的な虐待検出データセット（ CADD ）を、多面的なラベルとコンテキストを用いて提案します。 当社のデータセットは、大規模なクラウドソーシングを通じて効率的なアノテーションのために階層的にアノテーションされています。 また、データセットの特徴を実証的に探索し、新規の洞察のための詳細な分析を提供します。 データセット上の強力な事前訓練された自然言語理解モデルの実験結果は、データセットが有意義なパフォーマンスを生み出し、濫用言語検出のための実用性を保証することを示しています。', 'hi': 'चूंकि ऑनलाइन समुदायों में उपयोगकर्ता अपमानजनक भाषा के गंभीर दुष्प्रभावों से पीड़ित हैं, इसलिए कई शोधकर्ताओं ने सोशल मीडिया से अपमानजनक ग्रंथों का पता लगाने का प्रयास किया, इस तरह का पता लगाने के लिए कई डेटासेट प्रस्तुत किए। हालांकि, उनमें से किसी में भी व्यापक लेबल और प्रासंगिक जानकारी दोनों शामिल नहीं हैं, जो ग्रंथों से सभी प्रकार के अपमानजनकता का पूरी तरह से पता लगाने के लिए आवश्यक हैं, क्योंकि इस तरह के ठीक-ठाक सुविधाओं वाले डेटासेट एनोटेशन की एक महत्वपूर्ण मात्रा की मांग करते हैं, जिससे जटिलता में बहुत वृद्धि होती है। इस पेपर में, हम एक व्यापक अपमानजनकता डिटेक्शन डेटासेट (सीएडीडी) का प्रस्ताव करते हैं, जो अंग्रेजी रेडिट पोस्ट से एकत्र किया गया है, जिसमें बहुआयामी लेबल और संदर्भ हैं। हमारे डेटासेट को बड़े पैमाने पर क्राउडसोर्सिंग के माध्यम से एक कुशल एनोटेशन के लिए पदानुक्रमित रूप से एनोटेट किया गया है। हम अपने डेटासेट की विशेषताओं का भी अनुभवजन्य रूप से पता लगाते हैं और उपन्यास अंतर्दृष्टि के लिए एक विस्तृत विश्लेषण प्रदान करते हैं। हमारे डेटासेट पर मजबूत पूर्व-प्रशिक्षित प्राकृतिक भाषा समझने वाले मॉडल के साथ हमारे प्रयोगों के परिणाम बताते हैं कि हमारा डेटासेट सार्थक प्रदर्शन को जन्म देता है, अपमानजनक भाषा का पता लगाने के लिए इसकी व्यावहारिकता का आश्वासन देता है।', 'zh': '以在线社区中用户遭诟詈语言之甚副作用,诸治人试于社交媒体中检诟性文本,并给数集以检之。 然皆不兼总上下文息,于检本滥用至重,盖有其细粒度数集须大注,而复杂性大增也。 于本文中,具滥用检测数集(CADD),当数集从英语Reddit帖中收之,多方标上下文。 臣等据集按层次结构注释,以大众包之。 又以经验探数集之征,并为新见详析。 吾于数集上用强预训练自然语言解模形之实验结果表明,吾数集有义之性,保其妄检之实用性。', 'ru': 'Поскольку пользователи в онлайн-сообществах страдают от серьезных побочных эффектов оскорбительного языка, многие исследователи попытались обнаружить оскорбительные тексты из социальных сетей, представив несколько наборов данных для такого обнаружения. Однако ни один из них не содержит как всеобъемлющих меток, так и контекстной информации, которые необходимы для тщательного выявления всех видов оскорбительности из текстов, поскольку наборы данных с такими мелкозернистыми признаками требуют значительного количества аннотаций, что приводит к значительно большей сложности. В этой статье мы предлагаем Комплексный набор данных по выявлению злоупотреблений (CADD), собранный из английских постов Reddit, с многогранными метками и контекстами. Наш набор данных имеет иерархическую аннотацию для эффективной аннотации через краудсорсинг в большом масштабе. Мы также эмпирически изучаем характеристики нашего набора данных и предоставляем подробный анализ для новых инсайтов. Результаты наших экспериментов с сильными предварительно обученными моделями понимания естественного языка на нашем наборе данных показывают, что наш набор данных порождает значимую производительность, гарантирующую его практичность для оскорбительного обнаружения языка.', 'ga': 'Agus úsáideoirí i bpobail ar líne ag fulaingt ó fho-iarmhairtí tromchúiseacha a bhaineann le teanga mhí-úsáideach, rinne go leor taighdeoirí iarracht téacsanna maslacha a bhrath ó na meáin shóisialta, agus chuir siad roinnt tacar sonraí i láthair lena bhrath. Mar sin féin, níl lipéid chuimsitheacha agus faisnéis chomhthéacsúil in aon cheann acu, atá riachtanach chun gach cineál mí-úsáide ó théacsanna a bhrath go críochnúil, ós rud é go n-éilíonn tacair sonraí a bhfuil gnéithe míne den sórt sin méid suntasach nótaí acu, rud a fhágann go mbíonn castacht i bhfad níos mó ann. Sa pháipéar seo, molaimid Tacar Sonraí Cuimsitheach um Bhrath Mí-úsáide (CADD), a bhailítear ó phoist Reddit Béarla, le lipéid agus comhthéacsanna ilghnéitheacha. Déantar ár dtacar sonraí a anótáil go ordlathach le haghaidh nóta éifeachtach trí sluafhoinsiú ar scála mór. Déanaimid iniúchadh eimpíreach freisin ar shaintréithe ár dtacar sonraí agus cuirimid anailís mhionsonraithe ar fáil le haghaidh léargais nua. Léiríonn torthaí ár dturgnaimh ar mhúnlaí láidre réamhoilte tuisceana teanga nádúrtha ar ár dtacar sonraí go n-eascraíonn ár dtacar sonraí feidhmíocht bhríoch, ag dearbhú a praiticiúlacht maidir le teanga mhí-úsáideach a bhrath.', 'hu': 'Mivel az online közösségek felhasználói súlyos mellékhatásoktól szenvednek a visszaélő nyelvek, sok kutató megpróbálta felismerni a visszaélő szövegeket a közösségi médiából, és számos adatkészletet mutatott be az ilyen felderítéshez. Egyikük sem tartalmaz azonban átfogó címkéket és kontextuális információkat, amelyek alapvető fontosságúak a szövegekből való visszaélések alapos felismeréséhez, mivel az ilyen finomszemcsés funkciókkal rendelkező adatkészletek jelentős mennyiségű jegyzetelést igényelnek, ami sokkal bonyolultabb. Ebben a tanulmányban javasoljuk az angol Reddit posztokból gyűjtött Átfogó Abusivitás Detection Dataset (CADD), sokoldalú címkékkel és kontextusokkal. Adatkészletünket hierarchikusan jegyzeteltük, hogy hatékony jegyzetelést biztosítsunk a nagy méretű közösségi források révén. Emellett empirikusan feltárjuk adatkészletünk jellemzőit, és részletes elemzést nyújtunk az új betekintésekhez. Az erős, előre képzett természetes nyelvértési modellekkel végzett kísérleteink eredményei azt mutatják, hogy adatkészletünk értelmes teljesítményt eredményez, biztosítva annak gyakorlatiasságát a visszaélések nyelvészleléséhez.', 'el': 'Καθώς οι χρήστες σε διαδικτυακές κοινότητες υποφέρουν από σοβαρές παρενέργειες της καταχρηστικής γλώσσας, πολλοί ερευνητές προσπάθησαν να εντοπίσουν καταχρηστικά κείμενα από τα μέσα κοινωνικής δικτύωσης, παρουσιάζοντας διάφορα σύνολα δεδομένων για τέτοια ανίχνευση. Ωστόσο, καμία από αυτές δεν περιέχει τόσο περιεκτικές ετικέτες όσο και πληροφορίες περιβάλλοντος, οι οποίες είναι απαραίτητες για την πλήρη ανίχνευση όλων των ειδών της καταχρηστικότητας από κείμενα, καθώς τα σύνολα δεδομένων με τέτοια λεπτόκοκκα χαρακτηριστικά απαιτούν σημαντικό αριθμό σχολίων, οδηγώντας σε πολύ αυξημένη πολυπλοκότητα. Στην παρούσα εργασία, προτείνουμε ένα περιεκτικό σύνολο δεδομένων ανίχνευσης κατάχρησης (CADD), που συλλέγονται από τις αγγλικές δημοσιεύσεις Reddit, με πολλαπλές ετικέτες και πλαίσια. Το σύνολο δεδομένων μας σχολιάζεται ιεραρχικά για αποτελεσματική σχολιασμό μέσω της μεγάλης κλίμακας. Επίσης διερευνούμε εμπειρικά τα χαρακτηριστικά του συνόλου δεδομένων μας και παρέχουμε μια λεπτομερή ανάλυση για νέες γνώσεις. Τα αποτελέσματα των πειραμάτων μας με ισχυρά προ-εκπαιδευμένα μοντέλα κατανόησης φυσικής γλώσσας στο σύνολο δεδομένων μας δείχνουν ότι το σύνολο δεδομένων μας δίνει νόημα στην απόδοση, εξασφαλίζοντας την πρακτικότητά του για την ανίχνευση καταχρηστικών γλωσσών.', 'kk': 'Интернеттегі қоғамдардың пайдаланушылары жетістік тілдерінің қатты жағдайларының белсенділіктері болғанда, көптеген зерттеушілер социалдық медиақтардан жетістік мәтінді табу әрекетін Бірақ олардың ешкімінде жарлық жарлық пен мәтіндегі мәліметтер барлық түрлерінің жетістілігін анықтау үшін маңызды болмайды, себебі бұл жетістікті жарлық жарлық жарлық жарлықтар мен мәліметтері барлық жарлық жарлықтарды аны Бұл қағазда біз бірнеше жарлық жарлықтар мен контексттармен ағылшын редит поштасынан жинақталған комплексті қауіпсіздік табу деректер бағдарламасын (CADD) ұсынамыз. Деректер жиынымыз үлкен масштабтағы көпшілікті көпшілікті жазбалар үшін иерархиялық жазбаларды жазылады. Сонымен қатар, деректер жиының қасиеттерін зерттеп, романдық түсініктерге тегжейлі анализ береміз. Деректер жиынындағы тәжірибелеріміздің нәтижелері біздің деректер жиынымыз маңызды істеу үшін, өзінің тәжірибелі тілді анықтау үшін тәжірибелігін тексеру мүмкіндігін көрсетеді.', 'it': "Poiché gli utenti delle comunità online soffrono di gravi effetti collaterali del linguaggio abusivo, molti ricercatori hanno tentato di rilevare testi abusivi dai social media, presentando diversi set di dati per tale rilevamento. Tuttavia, nessuno di essi contiene sia etichette complete che informazioni contestuali, che sono essenziali per rilevare accuratamente tutti i tipi di abuso dai testi, dal momento che set di dati con caratteristiche a grana fine richiedono una quantità significativa di annotazioni, portando a una complessità molto maggiore. In questo articolo, proponiamo un Comprehensive Abusivity Detection Dataset (CADD), raccolto dai post inglesi Reddit, con etichette e contesti poliedrici. Il nostro set di dati è annotato gerarchicamente per un'annotazione efficiente attraverso il crowdsourcing su larga scala. Esploriamo anche empiricamente le caratteristiche del nostro set di dati e forniamo un'analisi dettagliata per nuove intuizioni. I risultati dei nostri esperimenti con solidi modelli di comprensione del linguaggio naturale pre-addestrati sul nostro set di dati mostrano che il nostro set di dati dà luogo a prestazioni significative, assicurando la sua praticità per il rilevamento abusivo del linguaggio.", 'ka': 'როგორც ინტერნეტი საზოგადოებში მომხმარებელი ძალიან ძალიან ბედნიერი ენის ეფექტებისგან მომხმარებელი მოცდილობენ სოციალური მედიაზე გამოცდილობული ტექსტის განახლებას,  მაგრამ არაფერი აქვს ყველა ყველაფერი ნიშანები და კონტექსტური ინფორმაცია, რომელიც უფრო მნიშვნელოვანია ყველა სხვადასხვა წერტილიდან წარმოადგენებისთვის, რადგან მონაცემების კონტექსტური ინფორმაციების შესაძ ამ დოკუნტში ჩვენ მინდომენეთ ყველაფერი მონაცემების მონაცემების მონაცემები (CADD), რომელიც ინგლისური რედიტის პოსტიდან შექმნილი, მრავალფექტური ჭეშებით და კონტექსტი ჩვენი მონაცემების კონტაქტი იერაქტიკურად ეფექტიური ანოტაციისთვის მუშაობით დიდი მაგალითში. ჩვენ ასევე ემპერიკურად ჩვენი მონაცემების პროგრამეტრების გამოყენება და ახალგაზრულებების განსაზღვრებისთვის განსაზღვრებული ანალიზია. ჩვენი ექსპერიმენტების შედეგები, რომლებიც ჩვენი მონაცემების კონფიგურაციაში ძალიან წარმოადგენებული საბოლოო ენის მოდელები ჩვენი მონაცემების კონფიგურაციაში ჩვენი მონაცემების', 'lt': 'Kadangi interneto bendruomenėse naudotojai patiria didelį piktnaudžiavimo kalba šalutinį poveikį, daugelis mokslininkų bandė nustatyti piktnaudžiaujančius social in ės žiniasklaidos tekstus ir pateikė keletą duomenų rinkinių tokiam aptikimui. Tačiau nė viename iš jų nėra išsamių etikečių ir kontekstinės informacijos, kurios yra būtinos visapusiškam tekstų piktnaudžiavimui nustatyti, nes duomenų rinkiniai, turintys tokių smulkių grūdų savybių, reikalauja daug pastabų, todėl labai sudėtingesni. In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts.  Mūsų duomenų rinkinys yra hierarchiškai anotuotas veiksmingai anotacijai naudojant didelės apimties crowdsourcing. Taip pat empiriniu būdu ištiriame savo duomenų rinkinio ypatumus ir išsamiai analizuojame naujas žinias. Mūsų eksperimentų su stipriais iš anksto parengtais gamtos kalbų supratimo modeliais rezultatai rodo, kad mūsų duomenų rinkinys sukuria prasmingus rezultatus, užtikrinant jo praktiškumą piktnaudžiaujant kalbų aptikimu.', 'ms': 'Sebagaimana pengguna di komuniti online menderita kesan sampingan yang berat bahasa yang mengganggu, ramai peneliti cuba untuk mengesan teks yang mengganggu dari media sosial, memperkenalkan beberapa set data untuk pengesan tersebut. Bagaimanapun, tiada satupun dari mereka mengandungi kedua-dua label komprensif dan maklumat kontekstual, yang penting untuk mengesan secara teliti semua jenis kejahatan dari teks, kerana set data dengan ciri-ciri-ciri yang sempurna itu memerlukan sejumlah yang signifikan anotasi, yang menyebabkan kemuliaan yang meningkat. Dalam kertas ini, kami cadangkan Dataset Pengesan Kesalahan Komprensif (CADD), dikumpulkan dari pos Reddit Inggeris, dengan label dan konteks berbilang. Set data kita dicatat secara hierarkis untuk anotasi efisien melalui crowdsourcing pada skala besar. Kami juga secara empirik mengeksplorasi ciri-ciri set data kami dan memberikan analisis terperinci untuk pandangan baru. Hasil eksperimen kita dengan model pemahaman bahasa alam yang berpelatih yang kuat pada set data kita menunjukkan bahawa set data kita memberikan hasil kepada prestasi yang bermakna, memastikan praktikalnya untuk pengesan bahasa yang melampaui batas.', 'mk': 'Бидејќи корисниците во онлајн заедниците страдаат од сериозни странски ефекти од злоупотребата на јазикот, многу истражувачи се обидоа да откријат злоупотребни тексти од социјалните медиуми, претставувајќи неколку податоци за вакво откривање However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of annotations, leading to much increased complexity.  Во овој весник, предложуваме комплетен податок за детекција на злоупотреба (CADD), собран од англиските постови Reddit, со мултифактични етикети и контексти. Нашиот компјутер на податоци е хиерархично анотиран за ефикасна анотација преку пулсорсирање на голема skalа. Исто така емпирички ги истражуваме карактеристиките на нашиот податок и обезбедуваме детална анализа за нови информации. Резултатите од нашите експерименти со силни предобучени модели за разбирање на природниот јазик на нашиот компјутер на податоци покажуваат дека нашиот компјутер на податоци предизвикува значајна перформанса, осигурувајќи ја својата практичност за злоупотреба на детекција на јази', 'ml': 'ഓണ്\u200dലൈന്\u200d സമൂഹത്തിലെ ഉപയോക്താക്കള്\u200d അപകടത്തിന്റെ കഠിനമായ ഭാഷയുടെ പ്രഭാവങ്ങളില്\u200d നിന്ന് കഷ്ടപ്പെടുന്നുണ്ടെങ്കില്\u200d, പലര്\u200d ശ്രദ്ധ എന്നാലും അവയില്\u200d ഒരാള്\u200dക്കും പൂര്\u200dണ്ണമായ ചിട്ടയും ഉള്ള വിവരങ്ങളും കിട്ടിയിട്ടില്ല. എല്ലാ തരത്തില്\u200d നിന്നും എല്ലാ തിന്മകളും പൂര്\u200dണ്ണമായി കണ്ടുപിടിക്കുന്നതിനായി അതിന്റെ പ്രധാ ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു പൂര്\u200dണ്ണമായ അബുസിവെന്റ് ഡെറ്റിഷന്\u200d ഡേറ്റീഷന്\u200d ഡേറ്റെറ്റ് സെറ്റ് ചെയ്തിരിക്കുന്നു. ഇംഗ്ലീഷ് റെഡിഡ് പ നമ്മുടെ ഡാറ്റാസെറ്റ് ഹിയാര്\u200dക്കിക്കാലികമായി വിഷമിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. ഒരു വലിയ തൂക്കത്തില്\u200d മുഴ നമ്മുടെ ഡാറ്റാസറ്റിന്റെ വ്യക്തിത്വങ്ങള്\u200d ശ്രമിക്കുകയും, നോവല്\u200d കണ്ണുകള്\u200dക്ക് വിശദീകരിക്കുകയും ചെയ്യുന്നു. നമ്മുടെ ഡാറ്റാസെറ്റില്\u200d ശക്തിയുള്ള സ്വാഭാവിക ഭാഷയുടെ ബുദ്ധിമുട്ടിയുള്ള പരീക്ഷണങ്ങളുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ ഡാറ്റാ', 'mt': 'Peress li l-utenti fil-komunitajiet onlajn isofru minn effetti sekondarji severi ta’ lingwa abbużiva, ħafna riċerkaturi ppruvaw isibu testi abbużivi mill-midja soċjali, u ppreżentaw diversi settijiet ta’ dejta għal tali skoperta. Madankollu, l-ebda wieħed minnhom ma fih kemm tikketti komprensivi kif ukoll informazzjoni kuntestwali, li huma essenzjali biex jiġu identifikati bir-reqqa t-tipi kollha ta’ abbużività mit-testi, peress li settijiet ta’ dejta b’karatteristiċi fini bħal dawn jitolbu ammont sinifikanti ta’ annotazzjonijiet, li jwasslu għal kumplessità akbar ħafna. F’dan id-dokument, qed nipproponu Dataset Komprensiv ta’ Detezzjoni ta’ Abużività (CADD), miġbur mill-postijiet Ingliżi Reddit, b’tikketti u kuntesti multipli. Is-sett tad-dejta tagħna huwa annotat b’mod ġerarkiku għal annotazzjoni effiċjenti permezz ta’ crowdsourcing fuq skala kbira. Niesploraw ukoll empirikament il-karatteristiċi tas-sett tad-dejta tagħna u nipprovdu analiżi dettaljata għal fehmiet ġodda. Ir-riżultati tal-esperimenti tagħna b’mudelli qawwija ta’ fehim tal-lingwi naturali mħarrġa minn qabel fuq is-sett tad-dejta tagħna juru li s-sett tad-dejta tagħna jagħti lok għal prestazzjoni sinifikanti, u jiżgura l-prattikalità tiegħu għal skoperta abbużiva tal-lingwi.', 'mn': 'Интернет нийгмийн хэрэглэгчид хүчирхийллэг хэл дээр хүчирхийллэг нөлөөтэй болж, олон судлаачид нийгмийн хэвлэлээс хүчирхийллэг жагсаалтыг олохыг хичээсэн бөгөөд ийм олон өгөгдлийн санг гаргаж Гэвч тэдгээрийн аль нэг нь бичиг баримтуудын бүрэн зэрэг хүчирхийллийг олохын тулд хамааралтай жагсаалт болон орчин үеийн мэдээлэл байхгүй. Энэ нь бүх төрлийн зэрэг хүчирхийллийг олохын тулд чухал. Учир нь ийм сайхан давсагтай өгөгдлийн сангууд маш Энэ цаасан дээр бид Англи Реддит захиргаанаас цуглуулагдсан, олон хэлбэртэй тэмдэглэл, нөхцөл байдлаар бүрдүүлэгдсэн хүчирхийлэл мэдээллийн санал болгож байна. Бидний өгөгдлийн сангууд ихэнх хэмжээнд хүмүүсийн сэтгэл хөрөнгө оруулахын тулд эерэг сэтгэл хангалттай байдаг. Мөн бид өгөгдлийн сангийн чанарыг судалж, шинэ ойлголтын тухай нарийвчлалтай шинжилгээ өгдөг. Бидний туршилтын үр дүнд бидний өгөгдлийн санд хүчтэй байгалийн хэл ойлгох загваруудын үр дүнг нь бидний өгөгдлийн санд үнэ цэнэтэй үйл ажиллагааг нэмэгдүүлж, хүчирхийллэг хэлний олох бодит байдлыг баталж байна.', 'no': 'Som brukarar i tilkoplingane har alvorleg side-effektar av abusive språk, prøvde mange forsøkarar å finna abusive tekstar frå sosiale media, og presenterte fleire datasett for slike oppdaging. Men ingen av desse inneheld både komplette merkelappar og kontekstinformasjon, som er viktig for å finna alle typar abusivitet frå tekstar, sidan datasett med slike fyrke funksjonar krev ein betydelig mengd merkelappar, som fører til mykje økt kompleksitet. I denne papiret foreslår vi eit kompleksiv databaset for oppdaging av abusivitet (CADD), samla frå engelske rediditeringspostane, med fleirfastsette etikettar og kontekstar. Datasettet våre er hierarkisk merka på eit effektivt merking gjennom crowdsourcing på ein stor skala. Vi utforskar også empirisk karakteristikaren av datasettet vårt og gjer ein detaljert analyse for novel innsyningar. Resultatet av eksperimentene våre med sterke først trengte naturspråk-forstørringsmodular på datasettet vårt viser at datasettet vårt gjer opp til mening av utviklingar, og sikrer at det praktiske for å oppdaga abusive språk.', 'pl': 'Ponieważ użytkownicy w społecznościach internetowych cierpią na poważne skutki uboczne obraźliwego języka, wielu badaczy próbowało wykryć nadużywające teksty z mediów społecznościowych, przedstawiając kilka zbiorów danych do takiego wykrycia. Żadna z nich nie zawiera jednak zarówno kompleksowych etykiet, jak i informacji kontekstowych, które są niezbędne do dokładnego wykrywania wszelkiego rodzaju nadużyć tekstów, ponieważ zbiory danych o tak precyzyjnych cechach wymagają znacznej ilości adnotacji, co prowadzi do znacznie zwiększonej złożoności. W niniejszym artykule proponujemy kompleksowy zestaw danych wykrywania nadużyć (CADD), zebrany z angielskich postów Redditu, z wieloaspektowymi etykietami i kontekstami. Nasz zestaw danych jest adnotacjonowany hierarchicznie w celu efektywnej adnotacji poprzez crowdsourcing na dużą skalę. Badamy również empirycznie cechy naszego zbioru danych i zapewniamy szczegółową analizę w celu uzyskania nowych informacji. Wyniki naszych eksperymentów z silnymi wstępnie przeszkolonymi modelami rozumienia języka naturalnego na naszym zbiorze danych pokazują, że nasz zbiór danych daje początek znaczącej wydajności, zapewniając jego praktyczność do wykrywania języka nadużywającego.', 'sr': 'Dok korisnici u internetskim zajednicama pate od teških nuspojava nasilnog jezika, mnogi istraživači su pokušali da otkriju nasilne tekste iz društvenih medija, predstavljajući nekoliko podataka za takvo otkrivanje. Međutim, nijedna od njih ne sadrži i sveobuhvatne etikete i kontekstne informacije, koje su ključne za temeljno otkrivanje svih vrsta zloupotrebe iz teksta, pošto kompleksa podataka sa takvim dobrokoženim karakteristikama zahteva značajnu količinu annotacija, što dovodi do veće kompleksnosti. U ovom papiru predlažemo komplektivni datum za detekciju nadmašivanja (CADD), prikupljen iz engleskih reddit postova, sa višestrukim etiketama i kontekstima. Naša kompleta podataka je hijerarhički annotirana za efikasnu annotaciju kroz crowdsourcing na velikoj skali. Istražujemo i karakteristike našeg seta podataka i pružamo detaljnu analizu za nove uvide. Rezultati naših eksperimenata sa jakim predobučenim prirodnim modelima razumevanja jezika na našem setu podataka pokazuju da naš set podataka dovodi do značajnog izvođenja, osiguravajući svoju praktičnost za otkrivanje nasilnih jezika.', 'ro': 'Deoarece utilizatorii din comunitățile online suferă de efecte secundare grave ale limbajului abuziv, mulți cercetători au încercat să detecteze texte abuzive de pe rețelele de socializare, prezentând mai multe seturi de date pentru o astfel de detectare. Cu toate acestea, niciuna dintre ele nu conține atât etichete cuprinzătoare, cât și informații contextuale, care sunt esențiale pentru detectarea temeinică a tuturor tipurilor de abuzuri din texte, deoarece seturile de date cu astfel de caracteristici fine-granulate necesită o cantitate semnificativă de adnotări, ceea ce duce la o complexitate mult mai mare. În această lucrare, vă propunem un set de date de detectare a abuzurilor cuprinzătoare (CADD), colectat din postările Reddit în limba engleză, cu etichete și contexte multiple. Setul nostru de date este adnotat ierarhic pentru o adnotare eficientă prin crowdsourcing la scară largă. De asemenea, explorăm empiric caracteristicile setului nostru de date și oferim o analiză detaliată pentru informații noi. Rezultatele experimentelor noastre cu modele puternice de înțelegere a limbajului natural pre-instruite pe setul nostru de date arată că setul nostru de date dă naștere la performanțe semnificative, asigurând caracterul practic al acestuia pentru detectarea limbajului abuziv.', 'so': "Sida isticmaalayaasha shabakada internetka ah ay ku xanuunsadaan saameyn adag oo afka isticmaalka ah, waxbarasho badan ayaa isku dayay in ay soo ogaato qoraal isticmaal ah oo ay ka soo bandhigtaan macluumaadka bulshada, oo ay soo bandhigtaan koox macluumaad oo kale. Si kastaba ha ahaatee midkoodna kuma jiro alaabta aasaasiga ah iyo macluumaadka ku saabsan, kuwaas oo muhiim u ah in aad si aad uga ogaato isticmaalka cayn kasta oo caafimaadka ah, sababtoo ah taariikhda ay leedahay takhasusyo caynkaas ah oo sharaf leh waxay u baahan yihiin dhibaatooyin aad u badan, taasoo sababtay dhibaatooyin badan. Qoraalkan waxaynu ka soo jeedaynaa qoraal kamid ah baaritaanka (CADD), oo laga soo ururiyey warqadaha ingiriisiga Reddit, oo lagu qoray alaabta labo badan iyo baaritaanka. Taariikhdayada waxaa lagu dhibaataysiiyey hierarkiisa si faa’iido ah oo aad u badan. Sidoo kale si fiican ayaannu u baaraynaa takhasuska danbiyadeeda, waxaynu siinaynaa baaritaan faa'iido ah oo faa'iido ah oo la garto aragtida hore. Imtixaankayada oo ku qoran modellada waxgarashada afka dabiicadda ah ee horay loo tababaray waxay ka muuqataa in sawirkayada macluumaadkaygu ay ka muuqato faa’iido faa’iido leh, waxayna ka hubsadaan waxyaabaha ku saabsan baaritaanka luuqada waxyeellada ah.", 'sv': 'Eftersom användare i nätsamhällen lider av allvarliga biverkningar av kränkande språk försökte många forskare upptäcka kränkande texter från sociala medier och presentera flera datauppsättningar för sådan upptäckt. Men ingen av dem innehåller både omfattande etiketter och kontextuell information, vilket är avgörande för att noggrant upptäcka alla typer av missbruk från texter, eftersom datauppsättningar med sådana finkorniga funktioner kräver en betydande mängd anteckningar, vilket leder till mycket ökad komplexitet. I den här uppsatsen föreslår vi ett omfattande dataset för upptäckt av missbruk (CADD), insamlat från de engelska Reddits inlägg, med mångfacetterade etiketter och sammanhang. Vårt dataset är hierarkiskt kommenterat för en effektiv kommentering genom crowdsourcing i stor skala. Vi utforskar också empiriskt egenskaperna hos vår dataset och ger en detaljerad analys för nya insikter. Resultaten av våra experiment med starka förutbildade modeller för förståelse av naturligt språk på vår dataset visar att vår dataset ger upphov till meningsfull prestanda, vilket säkerställer dess praktiska funktion för kränkande språkupptäckt.', 'si': 'ඇන්ලයින් සමාජයේ ප්\u200dරයෝජකයෙන් අපරාධ කරපු භාෂාවගේ සාමාජික ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර නමුත්, ඔවුන්ගෙන් කිසිම දෙනෙක් සම්පූර්ණ ලේබල් සහ සම්පූර්ණ තොරතුරු නැති වෙන්නේ නැහැ, ඒ වගේම සියළු වර්ගයක් පරික්ෂා කරන්න හැම වර්ගයක්ම ප්\u200dර මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පරීක්ෂණය දත්තස්ථාව (CADD), ඉංග්\u200dරීසි රෙඩිට් පොස්ට්ස් වලින් සංග අපේ තොරතුරු සම්බන්ධයක් ලොකු ප්\u200dරමාණයක් වලින් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ් අපි සමහර විශේෂයෙන් අපේ තොරතුරු සැකසුම්ගේ විශේෂතාවක් පරීක්ෂණය කරනවා සහ විස්තර විශේෂණයක් සඳහා ප අපේ පරීක්ෂණයේ ප්\u200dරතිචාර ප්\u200dරශ්නයක් තියෙන්නේ අපේ දත්ත සෙට්ටුවේ ප්\u200dරතිචාරයේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ අපේ දත්ත සැට', 'ur': 'جیسے آنلاین کمونٹیوں میں استعمال کرنے والے زبان کی سخت غیر اثرات سے پہنچ رہے ہیں، بہت سے تحقیقات کرنے والوں نے سوسیل میڈیا سے زبردستی پیغام پہنچانے کی کوشش کی تھی، اس طرح پہنچانے کے لئے بہت سی ڈیٹ سٹ پیش لیکن ان میں سے کوئی بھی نہیں ہے سب سے محکم لیبل اور متوسط معلومات، جو تمام مختلف پیغامات سے بدکاری کا انتظام کرنے کے لئے ضرورت ہے، کیونکہ اس طرح بہت زیادہ پیچیدگی کی وجہ سے ڈاٹ سٹ کے ساتھ بہت سی مطلب کی ضرورت ہے. اس کاغذ میں ہم ایک مشکل مضائقہ آزمائش ڈیٹس (CADD) کی پیشنهاد کرتے ہیں جو انگلیسی ریڈیٹ پوسٹوں سے جمع کئے گئے ہیں، بہت سی چہرے لیبل اور متوسط کے ساتھ۔ ہمارا ڈاٹ سٹ ایک بڑے مقدار پر جماعت کے ذریعہ ایک اثبات انٹوریٹ کے لئے اظہار کیا گیا ہے. ہم نے اپنے ڈاٹ سٹ کی خصوصیات کو بھی اچھی طرح تحقیق کرلیا اور تاریخی نظریں کے لئے تفصیح تحقیق کرلیا۔ ہمارے آزمائش کا نتیجہ ہمارے ڈاٹ سٹ پر مضبوط پیش آموزش کی طبیعی زبان کی سمجھ کی موڈل کے ساتھ دکھاتا ہے کہ ہمارے ڈاٹ سٹ کا مطلق کامیابی کے لئے اضافہ کرتا ہے، اور اس کی غلط زبان کی شناسی کے لئے مطمئ', 'ta': 'ஆன்லைன் சமூகத்தில் உள்ள பயனீட்டாளர்கள் வலிமையான மொழியின் கடுமையான விளைவுகள் பாதிக்கும் போது, பல ஆராய்ச்சிகள் சமூக ஊடகங்களிலிருந் ஆனால், அவைகளில் யாரும் சூழ்நிலையான சிட்டைகளையும் பொதுவான தகவலையும் கொண்டிருக்கவில்லை, அது உரைகளிலிருந்து முழுமையான அனைத்து வகையான தீவினைகளையும் கண்டறிய முக்கியமானத இந்த காகிதத்தில், நாம் ஒரு முழுமையான பாதுகாப்பு கண்டுபிடிப்பு தகவல் அமைப்பை பரிந்துரைக்கிறோம், ஆங்கிலத்தில் இருந்து செல்லப்பட்ட எங்கள் தகவல் அமைப்பு பெரிய அளவில் மக்கள் மூலம் தேவையான அறிவிப்பு குறிக்கப்பட்டுள்ளது. நாம் எங்கள் தரவுத்தளத்தின் தன்மைகளையும் தேடி புதிய காணங்களுக்கு ஒரு விவரமான ஆய்வு வழங்குகிறோம். எங்கள் தகவல் அமைப்பில் வலிமையான முன்பயிற்சி மொழி புரிந்து கொள்ள மாதிரிகள் முடிவுகளின் முடிவு', 'uz': "Onlayn jamiyatlaridagi foydalanuvchilar taqdim tilning qiziqarli chegara effektlariga ega bo'ladi, ko'pchilik o'qituvchilar jamiyat medyayasidagi ta'minlovchi textlarni aniqlashga harakat qilishni istadi. Bundan foydalanish uchun bir necha maʼlumot Lekin, ularda hech kimdan butunlay yorlar va davom etilgan maʼlumot mavjud emas. Bu matnlardan hamma narsa yomonlikni aniqlash uchun juda muhim, chunki bu ajoyib qo'llangan shakllar bilan maʼlumotlar tarkibini juda muhim tadbirlik talab qiladi, bu juda murakkablikga oshadi. Bu qogʻozda biz Inglizcha Reddit postlaridan bir ko'plab qo'llangan lab va tartiblar bilan тўпланган kompyuterni aniqlash (CADD) maʼlumotini tahrirlashni talab qilamiz. Maʼlumotlar sahifasi juda katta ko'proq jamoatlar orqali ajoyib tajriba qiladi. Biz haqida maʼlumotlar satrlarimizning xususiyatlarini aniqlamiz va novel ko'rinishlari учун тафсилотли тафаккур qilamiz. The results of our experiments with strong pre-trained natural language understanding models on our dataset show that our dataset gives rise to meaningful performance, assuring its practicality for abusive language detection.", 'vi': 'Nhiều nhà nghiên cứu đã cố gắng phát hiện những văn bản xấu xa từ truyền thông xã hội, đưa ra nhiều bộ dữ liệu để phát hiện. Tuy nhiên, không có cái nào chứa cả các nhãn đầy đủ và các thông tin ngữ cảnh, những điều cần thiết để tìm ra khả năng lạm dụng tối đa từ các văn bản, vì các dữ liệu với các tính chất phức tạp như vậy đòi hỏi một lượng đáng chú ý, dẫn đến sự phức tạp hơn nhiều. Trong tờ giấy này, chúng tôi đề nghị một bộ sưu tập dữ liệu trinh thám lạm dụng toàn diện (CADD), được lấy từ các bài viết của người Anh Reddit, với các mặt chữ đầy đủ. Hệ thống dữ liệu của chúng tôi được ghi chú theo lập trình phân biệt hiệu quả nhờ cách cách ăn năn trên diện rộng. Chúng tôi cũng nghiên cứu các đặc điểm của bộ dữ liệu và cung cấp một phân tích chi tiết cho những nghiên cứu mới. Kết quả thí nghiệm với các mô hình hiểu ngôn ngữ tự nhiên được huấn luyện mạnh trên bộ dữ liệu của chúng tôi cho thấy rằng bộ dữ liệu mang lại hiệu quả có ý nghĩa, đảm bảo thực tế cho việc phát hiện ngôn ngữ ngược đãi.', 'da': 'Da brugere i onlinefællesskaber lider af alvorlige bivirkninger af misbrug af sprog, forsøgte mange forskere at opdage misbrug af tekster fra sociale medier og præsenterede flere datasæt til en sådan opdagelse. Men ingen af dem indeholder både omfattende etiketter og kontekstuelle oplysninger, som er afgørende for grundigt at detektere alle former for misbrug fra tekster, da datasæt med sådanne finkornede funktioner kræver en betydelig mængde kommentarer, hvilket fører til meget mere kompleksitet. I denne artikel foreslår vi et Comprehensive Abusivity Detection Datasæt (CADD), indsamlet fra de engelske Reddits indlæg, med mange facetter etiketter og sammenhænge. Vores datasæt er hierarkisk annoteret for en effektiv annotering gennem crowdsourcing i stor skala. Vi undersøger også empirisk karakteristika ved vores datasæt og leverer en detaljeret analyse for nye indsigter. Resultaterne af vores eksperimenter med stærke prætrænede modeller for forståelse af natursprog på vores datasæt viser, at vores datasæt giver anledning til meningsfuld ydeevne, der sikrer dets praktiske anvendelighed til misbrug af sprog detektering.', 'nl': 'Omdat gebruikers in online gemeenschappen last hebben van ernstige bijwerkingen van misbruik van taal, probeerden veel onderzoekers misbruikende teksten van sociale media op te sporen en presenteerden ze verschillende datasets voor dergelijke detectie. Geen van hen bevat echter zowel uitgebreide labels als contextuele informatie, die essentieel zijn voor het grondig detecteren van allerlei soorten misbruik van teksten, aangezien datasets met dergelijke fijnkorrelige functies een aanzienlijke hoeveelheid annotaties vereisen, wat leidt tot een veel grotere complexiteit. In dit artikel stellen we een Comprehensive Abusivity Detection Dataset (CADD) voor, verzameld uit de Engelse Reddit berichten, met veelzijdige labels en contexten. Onze dataset is hiërarchisch geannoteerd voor een efficiënte annotatie door middel van crowdsourcing op grote schaal. We onderzoeken ook empirisch de kenmerken van onze dataset en bieden een gedetailleerde analyse voor nieuwe inzichten. De resultaten van onze experimenten met sterke vooraf getrainde modellen voor het begrijpen van natuurlijke taal op onze dataset tonen aan dat onze dataset aanleiding geeft tot zinvolle prestaties, waardoor de bruikbaarheid ervan voor misbruik van taal wordt gewaarborgd.', 'bg': 'Тъй като потребителите в онлайн общности страдат от тежки странични ефекти от злоупотребяващ език, много изследователи се опитаха да открият злоупотребяващи текстове от социалните медии, представяйки няколко набора от данни за такова откриване. Никой от тях обаче не съдържа както изчерпателни етикети, така и контекстуална информация, които са от съществено значение за цялостното откриване на всички видове злоупотреба от текстовете, тъй като наборите от данни с такива фини характеристики изискват значително количество анотации, което води до много по-голяма сложност. В настоящата статия предлагаме цялостен набор от данни за откриване на злоупотреби, събран от публикациите на английски Редит, с многостранни етикети и контексти. Нашият набор от данни е анотиран йерархично за ефективна анотация чрез груудсорсинг в голям мащаб. Също така изследваме емпирично характеристиките на нашия набор от данни и предоставяме подробен анализ за нови прозрения. Резултатите от нашите експерименти със силни предварително обучени модели за разбиране на естествения език в нашия набор от данни показват, че нашият набор от данни води до смислено представяне, което гарантира неговата практичност за злоупотребяващо откриване на език.', 'de': 'Da Nutzer in Online-Communities unter schweren Nebenwirkungen missbräuchlicher Sprache leiden, versuchten viele Forscher, missbräuchliche Texte aus sozialen Medien zu erkennen und stellten mehrere Datensätze für diese Erkennung vor. Allerdings enthält keines von ihnen sowohl umfassende Beschriftungen als auch Kontextinformationen, die für die gründliche Erkennung aller Arten von Missbrauch aus Texten unerlässlich sind, da Datensätze mit solchen feinkörnigen Merkmalen eine erhebliche Menge an Anmerkungen erfordern, was zu einer deutlich erhöhten Komplexität führt. In diesem Beitrag schlagen wir einen Comprehensive Abusivity Detection Dataset (CADD) vor, der aus den englischen Reddit-Beiträgen mit vielfältigen Bezeichnungen und Kontexten gesammelt wurde. Unser Datensatz wird hierarchisch kommentiert, um eine effiziente Annotation durch Crowdsourcing in großem Maßstab zu ermöglichen. Darüber hinaus untersuchen wir empirisch die Eigenschaften unseres Datensatzes und liefern eine detaillierte Analyse für neue Erkenntnisse. Die Ergebnisse unserer Experimente mit starken vortrainierten Modellen für das Verständnis natürlicher Sprache auf unserem Datensatz zeigen, dass unser Datensatz eine sinnvolle Leistung liefert und seine Praktikabilität für die Erkennung missbräuchlicher Sprache gewährleistet.', 'id': 'Sebagai pengguna di komunitas online menderita efek samping yang berat dari bahasa yang kasar, banyak peneliti mencoba untuk mendeteksi teks yang kasar dari media sosial, mempersembahkan beberapa set data untuk deteksi tersebut. Namun, tidak satupun dari mereka mengandung label komprensif dan informasi kontekstual, yang penting untuk mendeteksi secara teliti segala jenis kekerasan dari teks, karena dataset dengan ciri-ciri halus seperti ini menuntut jumlah yang signifikan anotasi, yang menyebabkan banyak meningkat kompleksitas. Dalam kertas ini, kami mengusulkan sebuah Data Deteksi Kesalahan Komprensif (CADD), dikumpulkan dari pos Reddit Inggris, dengan label dan konteks berbilang. Set data kita dicatat secara hierarkis untuk anotasi efisien melalui crowdsourcing pada skala besar. Kami juga secara empiris mengeksplorasi karakteristik dataset kami dan menyediakan analisis terperinci untuk pemahaman baru. Hasil dari eksperimen kami dengan model pemahaman bahasa alam yang sangat kuat yang dilatih di dataset kami menunjukkan bahwa dataset kami memberikan hasil untuk prestasi yang berarti, memastikan praktikalnya untuk deteksi bahasa yang abusif.', 'sw': 'Wakati watumiaji wa jamii za mtandaoni wanakabiliwa na madhara makubwa ya lugha ya matumizi, watafiti wengi walijaribu kutambua maandishi yanayotumiwa na mitandao ya kijamii, wakitoa taarifa kadhaa za taarifa kwa ajili ya kutambua aina hiyo. Hata hivyo, hakuna mmoja wao anayeishi alama za kina na taarifa za kimataifa, ambazo ni muhimu kwa kutambua ukatili wa aina zote kutoka kwenye maandishi, kwa sababu taarifa zinazohusu vipengele vya vizuri vinahitaji kiasi kikubwa cha udhalilishaji, na kusababisha ongezeko kubwa la utata. Katika gazeti hili, tunapendekeza seti ya Kuchunguza Habari za Kukosa Udhalili (CADD), iliyokusanywa kutoka makala za Kiingereza Reddit, yenye mabango na matatizo mengi. Seti yetu ya takwimu inakerushwa kwa kuchanganyikiwa kwa ufanisi kupitia vyanzo vya habari vya watu kwa kiasi kikubwa. Pia tunachunguza sifa za seti zetu za taarifa na kutoa uchambuzi wa kina kwa maoni ya kisasa. Matokeo ya majaribio yetu yenye mifano ya kuelewa lugha za asili zilizo na mafunzo ya awali katika seti yetu ya databases yanaonyesha kuwa seti yetu ya takwimu inaongezeka kwa ufanisi wa maana, na kuhakikisha uhalisia wake wa kutambua lugha za unyanyasaji.', 'hr': 'Dok korisnici internetske zajednice pate od teških nuspojava nasilnog jezika, mnogi istraživači su pokušali otkriti nasilne tekste iz društvenih medija, predstavljajući nekoliko podataka za takvo otkrivanje. Međutim, nijedan od njih ne sadrži i obuhvatljive etikete i contextualne informacije, koje su ključne za temeljno otkrivanje svih vrsta zloupotrebe iz teksta, jer kompleksi podataka s takvim zgodnim karakteristikama zahtijevaju značajnu količinu annotacija, što dovodi do mnogo povećane kompleksnosti. U ovom papiru predlažemo kompleksni datum za otkrivanje nadmašivanja (CADD), skupljen iz engleskih reddit postova, s višestrukim etiketama i kontekstima. Naša kompleta podataka je hijerarhički annotirana za učinkovitu annotaciju kroz crowdsourcing na velikoj skali. Također empirički istražujemo karakteristike našeg seta podataka i pružamo detaljnu analizu za novi uvid. Rezultati naših eksperimenata sa jakim predobučenim prirodnim modelima razumijevanja jezika na našem sastavu podataka pokazuju da naš sastav podataka povećava značajnu funkciju, osiguravajući svoju praktičnost za otkrivanje nasilnog jezika.', 'ko': '온라인 커뮤니티 사용자들이 욕설 언어의 심각한 부작용을 겪었기 때문에 많은 연구자들은 소셜 미디어의 욕설 텍스트를 검출하려고 시도했고 이런 검출에 사용되는 몇 가지 데이터 집합을 제공했다.그러나 이들은 전면적인 라벨과 상하문 정보를 포함하지 않기 때문에 텍스트의 각종 남용 행위를 철저히 검출하는 데 매우 중요하다. 이런 세립도 특징을 가진 데이터 집합은 대량의 주석이 필요하기 때문에 복잡성이 크게 증가한다.본고에서 우리는 영어 Reddit 게시물을 수집하고 다방면의 라벨과 상하문을 가진 종합 남용 검측 데이터 집합(CADD)을 제시했다.우리의 데이터 집합은 대규모 하청을 통해 층을 나누어 주석을 해서 효율적인 주석을 실현한다.우리는 또한 데이터 집합의 특징에 대해 실증 연구를 하고 새로운 견해를 상세하게 분석했다.우리의 데이터 집합에서 강력한 자연 언어 이해 모델을 사용하여 실시한 실험 결과 우리의 데이터 집합은 의미 있는 성능을 형성하여 남용 언어 검측에서의 실용성을 확보했다.', 'fa': 'در حالی که کاربران در جامعه\u200cهای آنلاین از اثرات جانبی سخت زبان زبان زبان زبان زبان زبان می\u200cزنند، بسیاری از تحقیقات\u200cکنندگان سعی کردند متن\u200cهای زبان\u200cآزار را از رسانه\u200cهای اجتماعی شناسایی کنند، و چندی ولی هیچ کدام از آنها هم نقاشی\u200cهای کامل و اطلاعات متوسط وجود ندارد، که برای دقیقاً شناسایی از همه نوع تباهی از متن ضروری دارند، زیرا مجموعه\u200cهای داده\u200cها با چنین ویژه\u200cهای خوشمزه\u200cای نیاز دارند که تعداد زیادی از نوشته\u200cهای بزرگی می\u200cخواهند، که باعث می\u200cشود به پیچی در این کاغذ، ما پیشنهاد می\u200cکنیم یک Databases Detection of Abusiveness Comprehensive (CADD), جمع شده از نقطه\u200cهای Reddit انگلیسی، با نقطه\u200cهای مختلف و موضوع. مجموعه\u200cی داده\u200cهای ما به عنوان یک اظهار مفید با توجه به یک مقیاس بزرگ به نظر می\u200cرسد. ما همچنین با استفاده از ویژگی\u200cهای مجموعه\u200cی داده\u200cهایمان را تحقیق می\u200cکنیم و تحلیل جزئیات برای مشاهده\u200cهای روانی می\u200cدهیم. نتیجه آزمایشات ما با مدل\u200cهای درک کردن زبان طبیعی پیش آموزش داده شده در مجموعه داده\u200cهای ما نشان می\u200cدهد که مجموعه داده\u200cهای ما به عملکرد معنی رشد می\u200cدهد، و مطمئن می\u200cشود که عملکرد آن برای شناسایی زبان زبان\u200cهای', 'am': 'በመንግሥት ማኅበረሰብ ውስጥ የተጠቃሚዎች የቋንቋ ቋንቋ ጥቃት ሲቀበሉ ብዙዎች አስተማሪዎቹ ከማኅበራዊ ሚዲያ የተቃወሙ ጽሑፎችን ለማግኘት ይፈልጋሉ፡፡ ምንም እንኳን፣ ከእነዚህ ሁሉ የጽሑፎች ሁኔታ ግፍ ማግኘት ያስፈልጋል፡፡ በዚህ ፕሮግራም፣ የኢንግሊዝኛ ቀድድ ደብዳቤዎች፣ በብዙ የበለጠ ምልክቶች እና ጥያቄዎች የተሰበሰቡ የጥያቄ መረጃዎች (CADD) መዘጋጀት እናደርጋለን፡፡ የዳውሬታችን ሰርቨሮች በተለጠቀው ብዙኃን በመጠቀም በሚያበዛው አካባቢ ነው፡፡ የዳታ ሳጥን እናሳውቃለን እና ለመጠየቅ የአሁኑን አስተያየት የሚዘረዝር Analysis እናደርጋለን፡፡ የድምፅ አካባቢ ቋንቋ ማስተዋል ምሳሌዎች የጠንካራ የፍጻሜን ፍጻሜዎች በዳታ ሳትሰራችን የዳታ ሳጥን አዋቂውን እንዲያሳውቅ እና ለቋንቋ ማስታወቂያውን እንዲያረጋግጥ ያሳያል፡፡', 'tr': 'Çaltylyk jemgyýetlerindeki ullançylar ýalňyşlyk dilleriniň gaty ýakyn netijesinden çykyp barýarlar, köpüsi araştyrçylar sosyal medýädälerden soňra ýalňyş metinleri tapyp synanyşýarlar we şonuň ýaly tanyş üç Emma hiçbiri hem döwlet etiketleri hem contextual maglumatlary ýok edýär. Bu şekilde tüm nähili çirkin sözleri tanamak üçin wajyp däldir, sebäbi bu şekilde çirkin sözleri bilen daty düzümlenmeler üçin gaty uly bir şekilde täsir etmek isleýär. Bu şekilde gaty kynçylyklyk bilen üý Bu kagyzda, iňlisçe Reddit sahypalaryndan toplanýan, birnäçe-ýüz etiketler we şartlaýyşlar bilen soňra gatnaşmaga teklip edýäris. Biziň veri setmimiz iýerarhiýany uly ölçekde crowdsourcing bilen etkinlik bir ýazgyt üçin duýýardy. Biz hem berüvlerimizin karakterlerimizi keşfet we novel düşünjeleri üçin detaylar çözümleşdirip bileris. Veri setidimizde ukyp öňünden öňünden öňünden öňünden dowam edilen tebigy dil düşünüjilik modellerinden netijelerimiz munuň netijelerimiz bardygyny görkezýär.', 'af': "Wanneer gebruikers in onlinese gemeenskappe lyk van swaar sekere effekte van abusive taal, het baie ondersoekers probeer om abusive teks van sosiale media te ontdek en verskeie datastelle vir sodanige opdecking te voorsien. Maar niemand van hulle bevat beide kompensuurlike etikette en konteksuurlike inligting, wat behoorlik is om alle soorte abusiviteit van tekste te besluit, omdat datastelle met so fyn-graan funksies â\x80\x99n betekende hoeveelheid notasies vervra, wat tot baie vergroot kompleksiteit verkondig word. In hierdie papier, voorstel ons 'n Kompleksiewe Abusivenes Deteksie Dataset (CADD), versamel van die Engelse Reddit Possies, met multifaced etikette en kontekste. Ons datastel is hierarkies aangeteken vir 'n effektief annotasie deur skakeloorsporing op 'n groot skaal. Ons ook empiriese uitsoek die karakteristieke van ons datastel en verskaf 'n gedetale analisie vir nuwe insigs. Die resultate van ons eksperimente met sterk voorafgevorderde natuurlike taal verstaan modele op ons datastel wys dat ons datastel veroorsaak tot betekende prestasie, en bevestig sy praktiese verstandigheid vir abusive taal beskrywing.", 'sq': 'Ndërsa përdoruesit në komunitetet online vuajnë nga efekte të rënda anësore të gjuhës abuzive, shumë kërkues u përpoqën të zbulojnë tekste abuzive nga media sociale, duke paraqitur disa grupe të dhënash për zbulim të tillë. Megjithatë, asnjë prej tyre nuk përmban si etiketa tërësore dhe informacion kontekstual, të cilat janë thelbësore për zbulimin në mënyrë të plotë të të gjitha llojeve të abuzimit nga tekstet, pasi të dhënat me këto karakteristika të hollësishme kërkojnë një sasi të konsiderueshme anotacionesh, që çojnë në një kompleksitet shumë të rritur. Në këtë gazetë, propozojmë një bazë të dhënash për zbulimin e abuzimit të plotë (CADD), të mbledhur nga postimet angleze Reddit, me etiketa dhe kontekste të shumëfaqeve. Të dhënat tona janë shënuar hierarkikisht për një shënim të efektshëm nëpërmjet crowdsourcing në një shkallë të madhe. Ne gjithashtu eksplorojmë në mënyrë empirike karakteristikat e grupit tonë të dhënash dhe ofrojmë një analizë të hollësishme për kuptime të reja. Rezultatet e eksperimenteve tona me modele të forta të paratrajnuara të kuptimit të gjuhës natyrore në grupin tonë të dhënash tregojnë se grupi ynë i dhënash jep origjinë për shfaqje të kuptueshme, duke siguruar praktikën e tij për zbulimin e gjuhës abuzive.', 'az': 'İnternett cəmiyyətlərdə istifadəçilər şiddətli dillərin dəhşətli təsirlərindən üz verən kimi, çox araştırmacılar sosyal mediyalarından istifadə edən məktubları keşfetməyə çalışırlar və buna görə bir çox verilən qurğular göstərərlər. Lakin, onların heç biri hər cür müxtəlif etiketlər və müxtəlif məlumatları içərisində deyildir. Bu məlumatlardan hər cür təcavüzlülük keşfetmək üçün məlumatları tamamilə təcavüzlük edir, çünki bu müxtəlif müxtəlif məlumatları ilə verilən məlumatlar böyük müxtəlif məlumatları tələb edir, böyük çox Bu kağızda, İngilizce Reddit məktumlarından toplanmış, çoxlu-yüzlü etiketlər və müxtəlif məlumatlarla birlikdə müxtəlif Abusivenes Detection Dataset (CADD) təklif edirik. Bizim verilən qurğumuz böyük ölçüdə crowdsourcing vasitəsilə hiyerarşik olaraq mükafatlandırılır. Biz həmçinin məlumatlarımızın xüsusiyyətlərini təşkil edirik və yeni baxışlar üçün detaylı analizi təşkil edirik. Bizim təcrübələrimizin əvvəlcə təhsil edilmiş təbiətli dil anlama modellərinin sonuçları verilən qurğumuz məlumatlarının anlayışına gəlməsini göstərər ki, verilən qurğumuz məlumatlarının anlayışlıqlarını təsdiqləyir, həddi-aşkar dil keşfet', 'ca': "Com que els usuaris de comunitats on-line pateixen efectes secundaris graves de llenguatge abusiv, molts investigadors van intentar detectar textos abusivs dels mitjans socials, presentant diversos conjunts de dades per tal de detectar. No obstant això, cap d'elles conté tant etiquetes completas com informació contextual, que són essencials per detectar completament tota mena d'abusió dels textos, ja que els conjunts de dades amb aquestes característiques fins requereixen una quantitat significativa d'anotacions, portant a una complexitat molt més gran. En aquest article, proposem un conjunt de dades de detecció completa de l'abusivitat (CADD), recollit a partir de les publicacions angleses Reddit, amb etiquetes i contextos multifacets. Our dataset is annotated hierarchically for an efficient annotation through crowdsourcing on a large-scale.  També explorem empíricament les característiques del nostre conjunt de dades i proporcionem una anàlisi detallada de noves idees. Els resultats dels nostres experiments amb models forts de comprensió de llenguatges naturals pré-entrenats del nostre conjunt de dades mostren que el nostre conjunt de dades dóna lloc a un rendiment significatiu, assegurant la seva pràcticitat per a la detecció abusiva de llenguatges.", 'cs': 'Vzhledem k tomu, že uživatelé v online komunitách trpí závažnými vedlejšími účinky zneužívajících jazyků, mnoho výzkumníků se pokusilo odhalit zneužívající texty ze sociálních médií a představilo několik datových sad pro takovou detekci. Nicméně žádná z nich neobsahuje jak komplexní štítky, tak kontextové informace, které jsou nezbytné pro důkladnou detekci všech druhů zneužívání textů, protože datové sady s takovými jemnými rysy vyžadují značné množství anotací, což vede k mnohem zvýšené složitosti. V tomto článku navrhujeme komplexní dataset detekce abusivity (CADD), shromážděný z anglických Redditových příspěvků, s mnohostrannými štítky a kontextem. Náš datový soubor je hierarchicky anotován pro efektivní anotaci prostřednictvím crowdsourcingu ve velkém měřítku. Rovněž empiricky zkoumáme charakteristiky našeho datového souboru a poskytujeme detailní analýzu pro nové poznatky. Výsledky našich experimentů se silnými předškolenými modely porozumění přirozenému jazyku na našem datovém setu ukazují, že naše datová sada vede k smysluplnému výkonu, což zaručuje její praktičnost pro detekci zneužívajícího jazyka.', 'et': 'Kuna internetikogukondade kasutajad kannatavad kuritarvitava keele tõsiste kõrvaltoimete all, püüdsid paljud teadlased tuvastada kuritarvitavaid tekste sotsiaalmeedias, esitades selleks mitu andmekogumit. Ükski neist ei sisalda aga nii põhjalikke märgiseid kui ka kontekstiteavet, mis on olulised igasuguse kuritarvitamise põhjalikuks tuvastamiseks tekstidest, sest nii peenete funktsioonidega andmekogumid nõuavad märkimisväärset hulka märkmeid, mis suurendab palju keerukust. Käesolevas töös pakume välja inglise Redditi postitustest kogutud põhjaliku kuritarvitamise tuvastamise andmekogumi (CADD), millel on mitmetahulised sildid ja kontekstid. Meie andmekogum on hierarhiliselt anoteeritud tõhusaks annoteerimiseks läbi laiaulatusliku ühishankimise. Samuti uurime empiiriliselt oma andmekogumi omadusi ja pakume üksikasjalikku analüüsi uudsete teadmiste jaoks. Meie katsete tulemused tugevate eelnevalt koolitatud looduskeele mõistmise mudelitega meie andmekogumil näitavad, et meie andmekogum annab tulemusliku jõudluse, tagades selle praktilisuse kuritarvitava keele tuvastamiseks.', 'hy': 'Որովհետև առցանց համայնքների օգտագործողները տառապում են խիստ կողմնակի ազդեցություններից, շատ հետազոտողներ փորձեցին հայտնաբերել սոցիալական լրատվամիջոցների կողմնակի հաղորդագրություններ, ներկայացնելով մի քանի տվյալների համակարգեր Այնուամենայնիվ, նրանցից ոչ մեկը չի պարունակում ընդհանուր պիտակներ և կոնտեքստալ ինֆորմացիա, որոնք կարևոր են տեքստների բոլոր տեսակի չարաշահությունների հիմնական հայտնաբերման համար, քանի որ այդպիսի գեղեցիկ հատկություններով տվյալների համակարգերը պահանջում են նշանակալի քանակությամբ Այս թղթի մեջ մենք առաջարկում ենք ընդհանուր չարաշահության հայտնաբերման տվյալներ (CADD), որոնք հավաքվել են անգլերեն Reddit-ի տեղադրություններից, բազմատեսակ պիտակներով և կոնտեքստներով: Մեր տվյալների համակարգը հիերարխիկապես նշում է արդյունավետ նշումների համար բազմաթիվ չափերի միջոցով: Մենք նաև էմպրիկապես ուսումնասիրում ենք մեր տվյալների համակարգի հատկությունները և ապահովում ենք մանրամասն վերլուծություն նոր բացահայտումների համար: Մեր փորձարկումների արդյունքները մեր տվյալների համակարգում հզոր նախապատրաստված բնական լեզվի հասկանալու մոդելների օգնությամբ ցույց են տալիս, որ մեր տվյալների համակարգը հանգեցնում է իմաստալից արտադրողությունների, ապահովում է լեզվի չարաշահու', 'bn': 'যেহেতু অনলাইন সম্প্রদায়ের ব্যবহারকারীরা নির্যাতন ভাষার কঠোর পাশাপাশি প্রভাব দিয়েছে, অনেক গবেষক সামাজিক প্রচার মাধ্যম থেকে অত্যা কিন্তু তাদের মধ্যে কেউ উভয়ের মধ্যে সম্পূর্ণ লেবেল এবং প্রাক্তন তথ্য রয়েছে না, যা লেখা থেকে সকল ধরনের নির্যাতনের জন্য গুরুত্বপূর্ণ, যেহেতু এই ধরনের সুন্দর বৈশিষ্ট্যের সাথে ড এই পত্রিকায় আমরা একটি সম্পূর্ণ অভিযুক্ত তথ্যের ডিটেক্টরেশন ডেটাসেট (CADD) প্রস্তাব করছি, যা ইংরেজী রেডিট পোস্ট থেকে সংগ্রহ করা হয়েছে, যার মাল আমাদের ডাটাসেট ব্যাপারে বিরক্তিকর ভাবে বিরক্তিকর ভাবে গণসূর্সিং এর মাধ্যমে কার্যকর ক্ষোভের জন্য। We also empirically explore the characteristics of our dataset and provide a detailed analysis for novel insights.  আমাদের প্রাকৃতিক প্রশিক্ষিত প্রাকৃতিক ভাষা বুঝতে পারে আমাদের পরীক্ষার ফলাফল আমাদের ডাটাসেটের মডেল দেখাচ্ছে যে আমাদের ডাটাসেটের', 'bs': 'Dok korisnici internetske zajednice pate od teških nuspojava nasilnog jezika, mnogi istraživači su pokušali otkriti nasilne tekste iz društvenih medija, predstavljajući nekoliko podataka za takvo otkrivanje. Međutim, nijedan od njih ne sadrži i sveobuhvatne etikete i contextualne informacije, koje su ključne za temeljno otkrivanje svih vrsta zloupotrebe iz teksta, jer kompleksa podataka sa takvim zgodnim karakteristikama zahtijeva značajnu količinu annotacija, što dovodi do mnogo povećane kompleksnosti. U ovom papiru predlažemo kompletni datum za detekciju nadmašivanja (CADD), skupljen iz engleskih reddit postova, sa višestrukim etiketama i kontekstima. Naša kompleta podataka je hijerarhički annotirana za efikasnu annotaciju kroz crowdsourcing na velikoj skali. Također empirički istražujemo karakteristike našeg seta podataka i pružamo detaljnu analizu za novi uvid. Rezultati naših eksperimenata sa jakim predobučenim prirodnim modelima razumijevanja jezika na našem setu podataka pokazuju da naš set podataka povećava značajnu funkciju, osiguravajući svoju praktičnost za otkrivanje nasilnih jezika.', 'fi': 'Koska verkkoyhteisöjen käyttäjät kärsivät loukkaavan kielen vakavista sivuvaikutuksista, monet tutkijat yrittivät havaita loukkaavia tekstejä sosiaalisesta mediasta esittäen useita datakokonaisuuksia tällaista havaitsemista varten. Mikään niistä ei kuitenkaan sisällä sekä kattavia etikettejä että asiayhteyteen liittyviä tietoja, jotka ovat välttämättömiä kaikenlaisten väärinkäytösten perusteelliselle havaitsemiselle teksteistä, koska tällaiset hienojakoiset ominaisuudet vaativat huomattavan määrän huomautuksia, mikä lisää huomattavasti monimutkaisuutta. Tässä artikkelissa ehdotamme englanninkielisistä Reddit-julkaisuista kerättyä kattavaa väärinkäytöstietoaineistoa, jossa on monitahoisia tunnisteita ja konteksteja. Aineistomme on hierarkisesti merkitty, jotta se on tehokasta joukkoistamisen avulla. Tutkimme empiirisesti myös aineistomme ominaisuuksia ja teemme yksityiskohtaisen analyysin uusista oivalluksista. Kokeemme vahvoilla esikoulutetuilla luonnollisen kielen ymmärtämismalleilla osoittavat, että aineistomme tuottaa mielekästä suorituskykyä ja varmistaa sen käytännöllisyyden loukkaavan kielen havaitsemisessa.', 'sk': 'Ker uporabniki spletnih skupnosti trpijo zaradi hudih stranskih učinkov zlorabljajočega jezika, so mnogi raziskovalci poskušali odkriti zlorabljajoča besedila iz družbenih omrežij in predstaviti več podatkovnih nizov za takšno odkrivanje. Vendar pa nobena od njih ne vsebuje celovitih oznak in kontekstualnih informacij, ki so bistvene za temeljito odkrivanje vseh vrst zlorabe iz besedil, saj zbirke podatkov s tako drobnozrnatimi značilnostmi zahtevajo precejšnjo količino opomb, kar povzroči veliko večjo kompleksnost. V tem prispevku predlagamo celovit nabor podatkov o ugotavljanju zlorabe (CADD), zbran iz angleških objav Reddit, z večplastnimi oznakami in konteksti. Naš nabor podatkov je hierarhično označen za učinkovito označevanje prek množičnega nabora v velikem obsegu. Empirično raziskujemo tudi značilnosti našega nabora podatkov in zagotavljamo podrobno analizo za nove vpoglede. Rezultati naših eksperimentov z močnimi vnaprej usposobljenimi modeli razumevanja naravnega jezika na našem naboru podatkov kažejo, da naš nabor podatkov prinaša smiselno učinkovitost in zagotavlja njegovo praktičnost za ugotavljanje zlorabe jezika.', 'ha': "Kama da masu amfani da mataimaka masu cũtar da alãmi masu tsananin haske wa harshen abuse, masu yawa na tafiti sun yi jarrabi su gane matsayin abubuwa daga mitandai na jamii, kuma sunã gaya wasu matsayi masu tsari ga wannan gano. However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of annotations, leading to much increased complexity.  Ga wannan takardan, Munã buɗa wata Comprehent Cikakken Abusive (CADD), wanda aka tattara daga posten Ingiriya Rededit, da wasu alama da matangazo. Ana zartar da danganyinMu da hiararkiki don an yi zartar da wani sharri mai amfani ga mutane da ke samu'i mai girma. Kayya, muna sami karatun mafiya kyauta masu tsarin danganyinmu kuma mu sami wani analai daki-daki wa masu basĩri na yanzu. Matarin jarrabai da masu ƙarfi da misãlai masu fahimta cikin harshen farko da aka yi wa zaman tsari a cikin zanen da ke nuna cewa tsarin dataset na ƙara danganyinmu yana da mafaniki, kuma yana sikar da halinsa ga misalin harshe na abuse.", 'he': 'כאשר משתמשים בקהילות באינטרנט סובלים משפעות לוואי חמורות של שפה מתעללת, חוקרים רבים ניסו לגלות הודעות מתעללות ממדיה חברתית בכל אופן, אף אחד מהם לא מכיל תוויות כוללות ומידע קונטקסטי, שהם חיוניים לגלות בצורה יסודית כל סוגי התעללות מהטקסטים, מכיוון שמערכת נתונים In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts.  קבוצת הנתונים שלנו נכתבת הייררכית עבור ציון יעיל דרך מציאות קהל בקנה מידה גדולה. אנחנו גם חוקרים באימפריקה את האופיינים של קבוצת המידע שלנו ולספק ניתוח פרטי לתבנות חדשות. התוצאות של הניסויים שלנו עם דוגמנים חזקים של הבנה טבעית לשפה מאומנים מראים על קבוצת הנתונים שלנו נותנים את התוצאות שלנו להופעה משמעותית', 'bo': 'དྲ་རྒྱའི་ཚོགས་སྡེའི་ནང་གི་སྤྱོད་མཁན་ཚོར་བ་ནི་ལག་ལེན་འཐབ་པའི་སྐད་རིགས་ལ་ཉུང་བའི་གྲངས་འབྲེལ་བ་དང་། ལྟ་ཞིབ་པས་རྒྱ་ནག However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of annotations, leading to much increased complexity. In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaced labels and contexts. ང་ཚོའི་སྒྲིག་ཆ་འཕྲིན་ཡིག ང་ཚོས་ཀྱང་རང་ཚོའི་ཆ་འཕྲིན་ཡིག་ཆ་གི་ཁྱད་ཆོས་ཀྱང་འཚོལ་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་བརྟག་ཞིབ་ཀྱི་གྲུབ', 'jv': 'Taning bener online politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé ngêngé kuwi, kéné supoyo akeh onêmên, dadi kapan-kapan di antasun kompêter Clear Awak dhéwé éntuk empire karo pernik nggawe dataset nganggo nggawe akeh panelusuran kanggo nggawe tarjamahan kanggo nggambar barang urip kuwi. Rejalaké awak dhéwé éntuk sing gak bener tentang karo model sing beraksi awak dhéwé, nik awak dhéwé kuwi nggawe dataset nganggep kuwi awak dhéwé butakor sing bakal terus nggawe gerakan, iso ngêngguna kuwi pratike nggawe gerakan kelangan langkung apik.'}
{'en': 'Predicting non-native speech perception using the Perceptual Assimilation Model and state-of-the-art acoustic models', 'hi': 'अवधारणात्मक आत्मसात मॉडल और अत्याधुनिक ध्वनिक मॉडल का उपयोग करके गैर-देशी भाषण धारणा की भविष्यवाणी करना', 'fr': "Prédire la perception de la parole non native à l'aide du modèle d'assimilation perceptuelle et de modèles acoustiques de pointe", 'pt': 'Prevendo a percepção de fala não nativa usando o Modelo de Assimilação Perceptiva e modelos acústicos de última geração', 'ja': '知覚同化モデルと最先端の音響モデルを使用して非ネイティブの音声知覚を予測する', 'ar': 'التنبؤ بإدراك الكلام غير الأصلي باستخدام نموذج الاستيعاب الحسي والنماذج الصوتية الحديثة', 'es': 'Predicción de la percepción del habla no nativa mediante el Modelo de Asimilación Perceptual y modelos acústicos de última generación', 'zh': '用感知同化模形及最先进者声学测非母语音语音感知', 'ru': 'Прогнозирование неродного восприятия речи с использованием модели перцептивной ассимиляции и современных акустических моделей', 'ga': 'Dearcadh cainte neamhdhúchais a thuar ag baint úsáide as an tSamhail Chomhshamhlaithe Dearcadh agus samhlacha fuaimiúla den scoth', 'hu': 'A nem natív beszédérzékelés előrejelzése az Érzékelési Assimilációs Modell és a legkorszerűbb akusztikai modellek segítségével', 'ka': 'პერსექტულ აციმილიაციის მოდელის და სურათის აკსტიკური მოდელის გამოყენება', 'el': 'Πρόβλεψη μη εγγενής αντίληψης ομιλίας χρησιμοποιώντας το μοντέλο αντιληπτικής αντιστοίχισης και σύγχρονα ακουστικά μοντέλα', 'it': "Prevedere la percezione del parlato non nativo utilizzando il modello di assimilazione percettiva e modelli acustici all'avanguardia", 'kk': 'Тізбекті емес сөйлеу арқылы Perceptual Assimilation Моделі мен Суреттің күйі акустикалық үлгілерін қолдануға болады', 'lt': 'Negimtinės kalbos suvokimo prognozavimas naudojant Perceptinio panašumo modelį ir moderniausius akustinius modelius', 'mk': 'Предвидување на перцепција на нероден говор користејќи го Перцептуалниот модел на асимилација и најсовремените акустички модели', 'mn': 'Байгалийн хэлэлцээгүй байдлын ойлголтыг хувьд багасгах загвар болон урлагийн байдлын акустик загварыг ашиглаж', 'ml': 'സ്ഥാനമില്ലാത്ത സംസാരിക്കാനുള്ള കാഴ്ചപ്പെടുത്തുന്നത് പെര്\u200dസിപ്റ്റല്\u200d അസിമിലേഷന്\u200d മോഡല്\u200d ഉപയോഗിക്കുന്നു.', 'ms': 'Mengimbas persepsi ucapan bukan-asli menggunakan Model Perspektif Assimilation dan model akustik state-of-the-art', 'mt': 'Il-previżjoni tal-perċezzjoni tad-diskors mhux nattiv bl-użu tal-Mudell ta’ Assimilazzjoni Perċettwali u l-mudelli akustiċi l-aktar avvanzati', 'no': 'Forventar ikkje-native taleoppfatning ved hjelp av den proseptuelle akseptiske modellen og status-of-the-art akustiske modellen', 'pl': 'Przewidywanie percepcji mowy innych niż natywne za pomocą modelu asymilacji percepcyjnej i najnowocześniejszych modeli akustycznych', 'ro': 'Predicția percepției vorbirii non-native utilizând modelul de asimilare perceptuală și modele acustice de ultimă generație', 'so': 'Horumarinta aragtida aan hooyo aheyn isticmaalka noocyada kaalmeynta ee rasmiga ah', 'sv': 'Förutsägning av icke-infödd taluppfattning med hjälp av Perceptual Assimilation Model och state-of-the-art akustiska modeller', 'ur': 'غیر منطقی بات کی نظر کی پیش بینی کرتی ہے کہ پرسپٹی آسیمیل موڈل اور هنر کی حالت آکوستیک موڈل کے مطابق', 'sr': 'Predviđavajući percepciju neproditeljnog govora koristeći model proceptualne asimulacije i stanje umjetničkih akustičkih modela', 'si': 'ප්\u200dරශ්ණාත්මක විශේෂය සම්ප්\u200dරශ්ණ මොඩේල් සහ ස්ථානය-of-the-art acoustic මොඩේල් භාවිත කරන්න පුළුවන්', 'ta': 'உள்ளூர் பேச்சு பார்வையில்லாத பார்வையை குறிப்பிடுகிறது Perceptual Assimilation Model and state- of- the- art acoustic models', 'vi': 'Dự đoán nhận thức ngôn ngữ không thổ dân qua phương pháp xác nhận gán ghép và các mô hình âm thanh hiện đại', 'uz': 'Name', 'bg': 'Прогнозиране на чуждо възприемане на речта с помощта на модела на възприемане на възприемане и съвременни акустични модели', 'da': 'Forudsigelse af ikke-native taleopfattelse ved hjælp af Perceptual Assimilation Model og state-of-the-art akustiske modeller', 'nl': 'Voorspelling van niet-native spraakperceptie met behulp van het Perceptual Assimilation Model en state-of-the-art akoestische modellen', 'hr': 'Predviđavajući percepciju neprodičnog govora koristeći proceptualni model asimulacije i state-of-the-art akustičke modele', 'de': 'Vorhersage der nicht-nativen Sprachwahrnehmung mit dem Perzeptual Assimilation Model und modernsten akustischen Modellen', 'id': 'Memprediksi persepsi pidato bukan asli menggunakan Model Perseptual Assimilation dan model akustik state-of-the-art', 'fa': 'پیش\u200cبینی از مشاهده سخنرانی غیر طبیعی با استفاده از مدل تغییر نظریه و مدل\u200cهای آکوستیک هنر', 'sw': 'Akizungumzia mtazamo wa hotuba asiye na asili kwa kutumia Mradi wa Ushambulizi wa Peru na hali ya sanaa', 'ko': '감지 동화 모델과 최신 성학 모델을 이용하여 비모국어 음성 감지를 예측하다', 'af': 'Voorskou nie-natuurlike praat aanvaar deur te gebruik die Perseptuele Assimilation Model en staat-van-kuns akustiese modele', 'sq': 'Duke parashikuar perceptimin e fjalës jo-natyrore duke përdorur Modelin e Asimilimit Perceptual dhe modelet akustike më të moderne', 'am': 'የአገራዊ ንግግር አስተያየት፣ የPerceptual Assimilation Model እና state of the art acoustic models', 'bn': 'স্থানীয় ভাষণের দৃষ্টিভঙ্গি নির্ধারণ করা হচ্ছে পার্সিপ্টুয়াল অ্যাসাইমিলেশন মডেল এবং শিল্প-শ্রেণীর প্রাকৃতি', 'hy': 'Պատկերացնելով ոչ բնիկ խոսքի ընկալումը՝ օգտագործելով ընկալման մոդելը և ամենաբարձր ձայնային մոդելները', 'ca': "Predir la percepció del discurs no natiu utilitzant el Model d'Assimilació Perceptual i els models acústics més moderns", 'bs': 'Predviđavajući percepciju neproditeljnog govora koristeći perspektivni model asimulacije i state-of-the-art akustičke modele', 'cs': 'Předpověď vnímání řeči mimo nativní řeč pomocí Perceptuálního asimilačního modelu a nejmodernějších akustických modelů', 'tr': 'Taýdan çykyş alyşyny modinde düşünýän ýagdaý çykyş welaýaty', 'et': 'Mittemaailmse kõnetaju prognoosimine tajumise mudeli ja kaasaegsete akustiliste mudelite abil', 'fi': 'Muiden kuin natiivien puhehavaintojen ennustaminen Perceptual Assimilation Modelin ja viimeisimpien akustisten mallien avulla', 'az': 'Düzgünlü Assimilation Modelini və sanatın vəziyyəti akustik modellərini istifadə edərək yerli deyil söz görünüşünü təmin edir.', 'sk': 'Napovedovanje tujega govora z uporabo modela perceptualne asimilacije in najsodobnejših akustičnih modelov', 'ha': 'Preparing non-native mazaɓa game da the Perceptal Assimition Model and state-of-the-art acocitic', 'he': 'צפוי התפיסה של נאום לא מקומי באמצעות מודל התייחסות התפיסה ומודלים אקוסטיים חדשים', 'jv': 'Learn Mode', 'bo': 'སྔོན་འཛུགས་པ་མིན་པའི་སྐད་བརྗོད་མི་མང་པོ་ཞིག་གིས་མཐོང་སྣང་ཚོར་བ་དང་།'}
{'en': 'Our  native language  influences the way we perceive  speech sounds , affecting our ability to discriminate non-native sounds. We compare two ideas about the influence of the  native language  on  speech perception  : the Perceptual Assimilation Model, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations tuned to the statistics of the native language, are sufficient. We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. We present a new, open dataset of French- and English-speaking participants’ speech perception behaviour for 61 vowel sounds from six languages. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background. We also show that wav2vec 2.0, while not good at capturing the effects of  native language  on  speech perception , is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during  speech perception .', 'fr': "Notre langue maternelle influence la façon dont nous percevons les sons de la parole, affectant notre capacité à distinguer les sons non natifs. Nous comparons deux idées sur l'influence de la langue maternelle sur la perception de la parole\xa0: le modèle d'assimilation perceptuelle, qui fait appel à une classification mentale des sons en catégories de phonèmes natifs, par opposition à l'idée que les représentations phonétiques riches et fines s'accordent avec les statistiques du natif langue, suffisent. Nous rendons cette idée opérationnelle à l'aide de représentations de deux modèles vocaux de pointe, un modèle de mélange gaussien par procédé Dirichlet et le modèle plus récent wav2vec 2.0. Nous présentons un nouvel ensemble de données ouvert sur le comportement de perception de la parole des participants francophones et anglophones pour 61 voyelles provenant de six langues. Nous montrons que l'assimilation des phonèmes est un meilleur prédicteur que la modélisation phonétique fine, à la fois pour le comportement de discrimination dans son ensemble et pour la prédiction des différences de discriminabilité associées aux différences dans les origines de la langue maternelle. Nous montrons également que wav2vec 2.0, bien qu'il ne soit pas efficace pour saisir les effets de la langue maternelle sur la perception de la parole, est complémentaire aux informations sur l'assimilation des phonèmes natifs et fournit un bon modèle de représentations phonétiques de bas niveau, soutenant l'idée que la perception à la fois catégorique et fine sont utilisés lors de la perception de la parole.", 'ar': 'تؤثر لغتنا الأم على الطريقة التي ندرك بها أصوات الكلام ، مما يؤثر على قدرتنا على التمييز بين الأصوات غير الأصلية. نقارن بين فكرتين حول تأثير اللغة الأم على إدراك الكلام: نموذج الاستيعاب الإدراكي ، الذي يناشد التصنيف العقلي للأصوات إلى فئات صوتية أصلية ، مقابل فكرة أن التمثيلات الصوتية الغنية والدقيقة يتم ضبطها وفقًا لإحصائيات لغتهم الأم كافية. نقوم بتفعيل هذه الفكرة باستخدام تمثيلات من نموذجين حديثين في الكلام ، نموذج خليط Gaussian لعملية Dirichlet ونموذج wav2vec 2.0 الأحدث. نقدم مجموعة بيانات جديدة ومفتوحة لسلوك إدراك الكلام للمشاركين الناطقين بالفرنسية والإنجليزية لـ 61 صوتًا متحركًا من ست لغات. نظهر أن الاستيعاب الصوتي هو مؤشر أفضل من النمذجة الصوتية الدقيقة ، سواء بالنسبة لسلوك التمييز ككل ، أو للتنبؤ بالاختلافات في التمييز المرتبط بالاختلافات في خلفية اللغة الأم. نوضح أيضًا أن wav2vec 2.0 ، على الرغم من أنه ليس جيدًا في التقاط تأثيرات اللغة الأم على إدراك الكلام ، فهو مكمل للمعلومات حول استيعاب الصوت الأصلي ، ويوفر نموذجًا جيدًا للتمثيل الصوتي منخفض المستوى ، مما يدعم فكرة أن كلاهما قاطع ودقيق - يستخدم الإدراك الحبيبي أثناء إدراك الكلام.', 'ja': '母国語は発話音の捉え方に影響を与え、非母語音を識別する能力に影響を与えます。 私たちは、母国語の音声認識への影響についての2つのアイデアを比較します。これは、音を母国語の音素カテゴリーに分類することを精神的にアピールする知覚同化モデルと、母国語の統計に調整された豊かで細かい音声表現が十分であるというアイデアです。 このアイデアは、2つの最先端の音声モデル、Dirichletプロセスガウス混合モデルと最近のwav 2 vec 2.0モデルからの表現を使用して実用化されています。 私たちは、6つの言語からの61の母音音について、フランス語と英語圏の参加者の音声認識行動の新しいオープンデータセットを提示します。 我々は、音素同化が、差別行動全体にとっても、母語の背景の違いに関連する差別性の違いを予測するためにも、細かい音声モデリングよりも優れた予測因子であることを示している。 また、wav 2 vec 2.0は、音声知覚に対するネイティブ言語の効果を捉えるのが苦手であるが、ネイティブ音素同化に関する情報を補完し、低レベルの音声表現の良いモデルを提供し、音声知覚の間にカテゴリカルな知覚と微細な知覚の両方が使用されるという考えを裏付けることを示している。', 'es': 'Nuestro idioma nativo influye en la forma en que percibimos los sonidos del habla, lo que afecta nuestra capacidad de discriminar los sonidos no nativos. Comparamos dos ideas sobre la influencia de la lengua nativa en la percepción del habla: el Modelo de Asimilación Perceptual, que apela a una clasificación mental de los sonidos en categorías de fonemas nativos, frente a la idea de que las representaciones fonéticas ricas y de grano fino se ajustan a las estadísticas del nativo idioma, son suficientes. Ponemos en práctica esta idea utilizando representaciones de dos modelos de voz de última generación, un modelo de mezcla gaussiana del proceso de Dirichlet y el modelo wav2vec 2.0 más reciente. Presentamos un nuevo conjunto de datos abierto del comportamiento de percepción del habla de los participantes de habla francesa e inglesa para 61 sonidos de vocales de seis idiomas. Demostramos que la asimilación de fonemas es un mejor predictor que el modelado fonético detallado, tanto para el comportamiento discriminatorio en su conjunto, como para predecir las diferencias en la discriminabilidad asociadas con las diferencias en el origen del idioma nativo. También mostramos que wav2vec 2.0, aunque no es bueno para captar los efectos del idioma nativo en la percepción del habla, es complementario a la información sobre la asimilación de fonemas nativos y proporciona un buen modelo de representaciones fonéticas de bajo nivel, lo que respalda la idea de que la percepción tanto categórica como fina se utilizan durante la percepción del habla.', 'pt': 'Nossa língua nativa influencia a maneira como percebemos os sons da fala, afetando nossa capacidade de discriminar sons não nativos. Comparamos duas ideias sobre a influência da língua nativa na percepção da fala: o Modelo de Assimilação Perceptiva, que apela a uma classificação mental de sons em categorias de fonemas nativos, versus a ideia de que representações fonéticas ricas e refinadas sintonizadas com as estatísticas do língua nativa, são suficientes. Operacionalizamos essa ideia usando representações de dois modelos de fala de última geração, um modelo de mistura gaussiana de processo Dirichlet e o mais recente modelo wav2vec 2.0. Apresentamos um novo conjunto de dados aberto do comportamento de percepção de fala de participantes falantes de francês e inglês para 61 sons de vogais de seis idiomas. Mostramos que a assimilação de fonemas é um melhor preditor do que a modelagem fonética refinada, tanto para o comportamento de discriminação como um todo, quanto para prever diferenças na discriminabilidade associadas a diferenças na origem da língua nativa. Mostramos também que o wav2vec 2.0, embora não seja bom em capturar os efeitos da língua nativa na percepção da fala, é complementar às informações sobre a assimilação de fonemas nativos e fornece um bom modelo de representações fonéticas de baixo nível, apoiando a ideia de que tanto categórica quanto fina -percepção granulada são usados durante a percepção da fala.', 'zh': '吾母语感知音,分非母语声力。 余校母语之二说:感知同化,则声心分为本地音素类,而丰盛,细粒度音调母语之统计数据足矣。 二者,先入者也;一者,狄利克雷也;一者,近wav2vec 2.0也。 发一新,开数集,施于法语英语参与者六语61元音音感知行。 故音素同化者,比细粒度音建模善占因,辨行异母语背景者判别性异也。 wav2vec 2.0虽不善捕母语语音所感,然与地音素同化者相成,而给一善下语,以类细粒度之。', 'ru': 'Наш родной язык влияет на то, как мы воспринимаем звуки речи, влияя на нашу способность различать неродные звуки. Мы сравниваем две идеи о влиянии родного языка на восприятие речи: модель перцептивной ассимиляции, которая апеллирует к ментальной классификации звуков по категориям родных фонем, с идеей о том, что достаточно богатых, мелкозернистых фонетических представлений, настроенных на статистику родного языка. Мы реализуем эту идею, используя представления из двух современных моделей речи, модель процесса Гаусса Дирихле и более позднюю модель wav2vec 2.0. Мы представляем новый, открытый набор данных о восприятии речи франкоязычными и англоязычными участниками для 61 гласного звука с шести языков. Показано, что ассимиляция фонем является лучшим предиктором, чем мелкозернистое фонетическое моделирование, как для дискриминационного поведения в целом, так и для прогнозирования различий в дискриминационности, связанных с различиями в происхождении родного языка. Мы также показываем, что wav2vec 2.0, хотя и не хорошо отражает влияние родного языка на восприятие речи, дополняет информацию об ассимиляции родных фонем и предоставляет хорошую модель низкоуровневых фонетических представлений, поддерживая идею о том, что при восприятии речи используется как категориальное, так и мелкозернистое восприятие.', 'hi': 'हमारी मूल भाषा भाषण ध्वनियों को समझने के तरीके को प्रभावित करती है, जिससे गैर-देशी ध्वनियों में भेदभाव करने की हमारी क्षमता प्रभावित होती है। हम भाषण धारणा पर मूल भाषा के प्रभाव के बारे में दो विचारों की तुलना करते हैं: अवधारणात्मक आत्मसात मॉडल, जो देशी फोनेम श्रेणियों में ध्वनियों के मानसिक वर्गीकरण के लिए अपील करता है, बनाम यह विचार है कि मूल भाषा के आंकड़ों के अनुरूप समृद्ध, ठीक-ठीक ध्वन्यात्मक प्रतिनिधित्व पर्याप्त हैं। हम इस विचार को दो अत्याधुनिक भाषण मॉडल, एक Dirichlet प्रक्रिया गाऊसी मिश्रण मॉडल और हाल ही में wav2vec 2.0 मॉडल से अभ्यावेदन का उपयोग करके संचालित करते हैं। हम छह भाषाओं से 61 स्वर ध्वनियों के लिए फ्रेंच और अंग्रेजी बोलने वाले प्रतिभागियों के भाषण धारणा व्यवहार का एक नया, खुला डेटासेट प्रस्तुत करते हैं। हम दिखाते हैं कि फोनम आत्मसात ठीक-ठाक ध्वन्यात्मक मॉडलिंग की तुलना में एक बेहतर भविष्यवक्ता है, दोनों एक पूरे के रूप में भेदभाव व्यवहार के लिए, और मूल भाषा पृष्ठभूमि में मतभेदों से जुड़े भेदभाव में अंतर की भविष्यवाणी करने के लिए। हम यह भी दिखाते हैं कि wav2vec 2.0, जबकि भाषण धारणा पर मूल भाषा के प्रभावों पर कब्जा करने में अच्छा नहीं है, देशी फोनमे आत्मसात के बारे में जानकारी के पूरक है, और निम्न-स्तरीय ध्वन्यात्मक प्रतिनिधित्व का एक अच्छा मॉडल प्रदान करता है, इस विचार का समर्थन करता है कि भाषण धारणा के दौरान दोनों स्पष्ट और ठीक-दाने वाली धारणा का उपयोग किया जाता है।', 'ga': 'Bíonn tionchar ag ár dteanga dhúchais ar an mbealach a bhraitheann muid fuaimeanna cainte, rud a chuireann isteach ar ár gcumas idirdhealú a dhéanamh ar fhuaimeanna neamhdhúchasacha. Déanaimid comparáid idir dhá smaoineamh faoi thionchar na teanga dúchais ar aireachtáil chainte: an tSamhail Chomhshamhlaithe Dearcadh, a mheallann aicmiú meabhrach fuaimeanna i gcatagóirí fóinéimí dúchais, i gcomparáid leis an smaoineamh go bhfuil léirithe saibhre, mionghrámhara foghraíochta ag teacht le staitisticí an Fhorais. teanga dhúchais, is leor. Déanaimid an smaoineamh seo a oibriú ag baint úsáide as léirithe ó dhá mhúnla cainte úrscothach, samhail de mheascán Gaussach le próiseas Dirichlet agus an tsamhail wav2vec 2.0 níos déanaí. Cuirimid i láthair tacar sonraí nua oscailte d’iompraíocht braistintí cainte rannpháirtithe Fraincise agus Béarla do 61 fhuaim guta as sé theanga. Léirímid gur fearr an tuar a bheith ag comhshamhlú fóinéime ná samhaltú foghraíochta mínghlan, don iompar idirdhealaithe ina iomláine agus chun difríochtaí idirdhealaitheachta a bhaineann le héagsúlachtaí cúlra teanga dhúchais a thuar. Léirímid freisin go bhfuil wav2vec 2.0, cé nach bhfuil sé go maith ag gabháil le héifeachtaí teanga dhúchais ar aireachtáil cainte, comhlántach leis an bhfaisnéis faoi chomhshamhlú fóinéimí dúchais, agus go soláthraíonn sé múnla maith de léirithe foghraíochta ar leibhéal íseal, ag tacú leis an smaoineamh go bhfuil catagóiriúil agus mín araon. - úsáidtear dearcadh gráin le linn dearcadh cainte.', 'el': 'Η μητρική μας γλώσσα επηρεάζει τον τρόπο με τον οποίο αντιλαμβανόμαστε τους ήχους ομιλίας, επηρεάζοντας την ικανότητά μας να διακρίνουμε τους μη φυσικούς ήχους. Συγκρίνουμε δύο ιδέες σχετικά με την επίδραση της μητρικής γλώσσας στην αντίληψη της ομιλίας: το μοντέλο αντιληπτικής αντιστοίχισης, το οποίο απευθύνεται σε μια νοητική ταξινόμηση ήχων σε μητρικές κατηγορίες φωνωμάτων, έναντι της ιδέας ότι επαρκούν πλούσιες, λεπτόκοκκες φωνητικές αναπαραστάσεις συντονισμένες με τις στατιστικές της μητρικής γλώσσας. Λειτουργούμε αυτή την ιδέα χρησιμοποιώντας αναπαραστάσεις από δύο σύγχρονα μοντέλα ομιλίας, ένα μοντέλο Gaussian μείγματος διαδικασίας και το πιο πρόσφατο μοντέλο wav2vec 2.0. Παρουσιάζουμε ένα νέο, ανοικτό σύνολο δεδομένων της συμπεριφοράς αντίληψης ομιλίας των γαλλόφωνων και αγγλόφωνων συμμετεχόντων για 61 ήχους φωνήθων από έξι γλώσσες. Αποδεικνύουμε ότι η αφομοίωση φωνωμάτων είναι καλύτερος παράγοντας πρόβλεψης από τη λεπτόκοκκη φωνητική μοντελοποίηση, τόσο για τη συμπεριφορά διακρίσεων στο σύνολό της, όσο και για την πρόβλεψη διαφορών στην διακριτικότητα που σχετίζονται με διαφορές στο υπόβαθρο της μητρικής γλώσσας. Επίσης, καταδεικνύουμε ότι το 2.0, αν και δεν είναι καλό στην καταγραφή των επιπτώσεων της μητρικής γλώσσας στην αντίληψη του λόγου, είναι συμπληρωματικό με τις πληροφορίες σχετικά με την αφομοίωση του εγγενούς φωνήματος και παρέχει ένα καλό μοντέλο φωνητικών αναπαραστάσεων χαμηλού επιπέδου, υποστηρίζοντας την ιδέα ότι κατά την αντίληψη του λόγου χρησιμοποιούνται τόσο κατηγορηματική όσο και λεπτή αντίληψη.', 'hu': 'Anyanyelvünk befolyásolja a beszédhangok érzékelését, befolyásolja a nem anyanyelvű hangok megkülönböztetésének képességét. Két elképzelést hasonlítunk össze az anyanyelv beszédérzékelésre gyakorolt hatásáról: az Érzékelési Assimilációs Modell, amely a hangok anyanyelv kategóriáiba történő mentális besorolására vonatkozik, szemben azzal az elképzeléssel, hogy az anyanyelv statisztikájára hangolt gazdag, finom szemű fonetikai reprezentációk elegendőek. Ezt az ötletet két korszerű beszédmodell, egy Dirichlet folyamat Gauss keverékmodell és a legújabb wav2vec 2.0 modell reprezentációjával operáljuk. A francia és angol nyelvű résztvevők beszédérzékelési viselkedésének új, nyílt adatkészletét mutatjuk be hat nyelvből származó 61 magánhangzás esetében. Megmutatjuk, hogy a fonema asszimiláció jobb előrejelző, mint a finomszemcsés fonetikai modellezés, mind a diszkriminációs viselkedés egészében, mind pedig az anyanyelvi háttér különbségeivel összefüggő diszkriminációs különbségek előrejelzésére. Azt is megmutatjuk, hogy a wav2vec 2.0, bár nem jó az anyanyelv beszédérzékelésre gyakorolt hatásainak rögzítésében, kiegészíti az anyanyelv fonema asszimilációjára vonatkozó információkat, és jó modellt nyújt az alacsony szintű fonetikai reprezentációkra, támogatva azt az elképzelést, hogy a beszédérzékelés során kategorikus és finomszemcsés érzékelést is használnak.', 'ka': 'ჩვენი დედაქალური ენაზე იქნება, როგორც ჩვენ ვხედავთ სიტყვების სიტყვები, როგორც ჩვენი შესაძლებლობა დისკრიმინაცია არ არის დედაქალური ენაზე. ჩვენ ორი იდეების შემთხვევაში, რომლებიც პერსექტიური ასიმილიაციის მოდელი, რომელიც სიტყვების ფონემების კლასიფიკაციას მიერ ფონემების კატეგორიაში დავუწყება, შემდეგ იდეა, რომ ბედნიერი, ფონეტიკური გამოსახულებები, რომლებიც ჩვენ ამ იდეას გამოყენებთ გამოყენებული ორი განსხვავებული სიტყვების მოდელიდან, დირიქლეტის პროცესის დაუსიანური მთქსური მოდელიდან და უფრო ახალი wav2vec 2.0 მოდელიდან. ჩვენ ახალი, გახსნილი მონაცემების კონფინური და ინგლისური საუბრის მონაცემების მონაცემების მონაცემების მოქმედება 61 საუბრივი ხსნის შვიდი ენაზე. ჩვენ ჩვენ აჩვენებთ, რომ ფონემის აციმთლაცია უკეთესი პროგრამებია, ვიდრე უკეთესი ფონეტიკური მოდელეციისგან, ორივე დისკრიმინაციის ქცევაზე ყველაფერი, და დისკრიმინაციის განსხვავებას,  ჩვენ ასევე ჩვენ აჩვენებთ, რომ wav2vec 2.0, მაგრამ სახლის ენერგიის ეფექტურების შესახებისათვის არ უფრო კარგი იყო ინფორმაციის შესახებისათვის, რომელიც ინფორმაციის შესახებ სახლის ფონემის აციმთლაციის შესახებ, და უფრო კარგიური ფონ', 'lt': 'Mūsų gimtoji kalba daro įtaką mūsų kalbos garsų suvokimui, daro įtaką mūsų gebėjimui diskriminuoti ne gimtojus garsus. Palyginame dvi idėjas apie gimtosios kalbos įtaką kalbos suvokimui: Perceptinio panašumo modelį, kuris kreipiasi į mintinę garsų klasifikaciją į gimtosios kalbos kategorijas, palyginti su idėja, kad pakanka turtingų, smulkiai grūdintų fonetinių nuotraukų, pritaikytų prie gimtosios kalbos statistikos. Įgyvendiname šią idėją naudojant dviejų naujausių kalbos modelių, Dirichlet proceso Gausijos mišinio modelio ir naujausio wav2vec 2.0 modelio atstovavimus. Pateikiame naują, atvirą prancūzų ir anglų kalbomis kalbančių dalyvių kalbos suvokimo elgesio duomenų rinkinį 61 garsiams iš šešių kalbų. Mes rodome, kad fonemų asimiliacija yra geresnis prognozuotojas nei smulkiai išgrūdintas fonetinis modeliavimas, tiek visam diskriminaciniam elgesiui, tiek prognozuojant diskriminacijos skirtumus, susijusius su gimtųjų kalbų kilmės skirtumais. Taip pat parodome, kad wav2vec 2.0, nors nėra geras suvokiant gimtosios kalbos poveikį kalbos suvokimui, papildo informaciją apie gimtosios fonemijos asimiliaciją ir suteikia gerą žemo lygio fonetinių atvaizdų model į, kuriuo remiama idėja, kad kalbos suvokimo metu naudojama ir kategoriška, ir smulkiai išgrūdinta suvokimas.', 'it': "La nostra lingua madre influenza il modo in cui percepiamo i suoni vocali, influenzando la nostra capacità di discriminare i suoni non nativi. Confrontiamo due idee sull'influenza della lingua madre sulla percezione del parlato: il Modello di Assimilazione Percettuale, che fa appello a una classificazione mentale dei suoni in categorie fonemiche native, contro l'idea che siano sufficienti rappresentazioni fonetiche ricche e a grana fine sintonizzate sulle statistiche della lingua madre. Operazionalizziamo questa idea utilizzando le rappresentazioni di due modelli di discorso all'avanguardia, un modello Gaussian mix di processo Dirichlet e il più recente modello wav2vec 2.0. Presentiamo un nuovo dataset aperto del comportamento di percezione del discorso dei partecipanti di lingua francese e inglese per 61 suoni vocali provenienti da sei lingue. Dimostriamo che l'assimilazione fonemica è un predittore migliore della modellazione fonetica a grana fine, sia per il comportamento discriminatorio nel suo complesso, sia per la previsione delle differenze di discriminazione associate alle differenze di background linguistico. Mostriamo anche che wav2vec 2.0, sebbene non sia bravo a catturare gli effetti della lingua madre sulla percezione del parlato, è complementare alle informazioni sull'assimilazione del fonema nativo e fornisce un buon modello di rappresentazioni fonetiche di basso livello, sostenendo l'idea che sia la percezione categorica che a grana fine sono utilizzate durante la percezione del parlato.", 'kk': 'Біздің негізгі тіліміз сөйлеу дыбыстарын түсінуге әсер етеді, негізгі дыбыстарды таңдау мүмкіндігімізге әсер етеді. Біз тілінің түсініктерінің әсері туралы екі идеяны салыстырамыз: Мекен тілінің статистикасына сәйкес етілген психикалық салыстыру үлгісі, ол дыбыстардың психикалық салыстыруын негізгі фонемдер санаттарына салыстыру үлгісі жеткілікті. Бұл идеяны екі күй- жай сөйлеу үлгілерінен, дириклет процесінің Гауссияның аралас моделі мен соңғы wav2vec 2. 0 үлгілерінен келтіріп орындаймыз. Біз французша және ағылшын тілінде қатысушылардың 61 дыбыс қарау әрекетін жаңа, ашық деректер жиынын таңдаймыз. Біз фонемді асимиляциялау - тіл тілінің аясындағы айырмашылығындағы дискриминациялық тәртібінен да жақсы прогнозер деп көрсетедік. Сонымен қатар, wav2vec 2.0 дегенді көрсету үшін, тіл тілінің эффекттерін сөйлеу үшін түсініктеріне түсініп, негізгі фонемді асимилациялау туралы мәліметті қосып, төмен деңгейіндегі фонетикалық түсініктердің жақсы үлгісін қолдану үшін, сөйлеу ү', 'ms': 'Bahasa asli kita mempengaruhi cara kita percepti bunyi ucapan, mempengaruhi kemampuan kita untuk mendiskriminasi bunyi bukan asli. Kita membandingkan dua idea mengenai pengaruh bahasa asli pada persepsi ucapan: Model Perspektif Assimilasi, yang menarik kepada klasifikasi mental bunyi ke kategori fonem asli, melawan idea bahawa persembahan fonetik kaya dan berwarna ganda yang sesuai dengan statistik bahasa asli, cukup. Kita operasikan idea ini menggunakan perwakilan dari dua model ucapan yang terbaik, proses Dirichlet model campuran Gaussia dan model wav2vec 2.0 yang baru-baru ini. Kami perkenalkan set data baru, terbuka bagi perilaku percepsi ucapan peserta bahasa Perancis dan Inggeris untuk 61 bunyi suara dari enam bahasa. Kami menunjukkan bahawa persamaan fonem adalah prediksi yang lebih baik daripada pemodelan fonetik berbulu, kedua-dua untuk perilaku diskriminasi sebagai keseluruhan, dan untuk prediksi perbezaan dalam pembahagian yang berkaitan dengan perbezaan dalam latar belakang bahasa asli. Kami juga menunjukkan bahawa wav2vec 2.0, walaupun tidak baik dalam menangkap kesan bahasa asli pada percepsi ucapan, adalah kumplimentar kepada maklumat mengenai asimilasi fonem asli, dan menyediakan model yang baik untuk persembahan fonetik tahap rendah, menyokong idea bahawa percepsi kategori dan benih baik digunakan semasa percepsi ucapan.', 'mk': 'Нашиот роден јазик влијае на начинот на кој го перцепираме звукот на говорот, влијаејќи на нашата способност да дискриминираме неродни звуки. Ние споредуваме две идеи за влијанието на родниот јазик на перцепцијата на говорот: Моделот на перцептуална асимилација, кој се повикува на ментална класификација на звуците во родните категории на фономи, во споредба со идејата дека богатите, фино населени фонетски претставувања приспособени на статистиката на родниот јазик, се доволни. Ја операционализираме оваа идеја користејќи претставувања од два најсовремени говорни модели, процес Диричлет Гаусски мешанички модел и последниот модел wav2vec 2.0. Презентираме нов, отворен набор на податоци за однесување на перцепцијата на говорот на француски и англиски учесници за 61 звуци од шест јазици. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background.  Исто така покажуваме дека wav2vec 2.0, иако не е добар во заземањето на ефектите на родниот јазик на перцепцијата на говорот, е комплиментарен на информациите за асимилирање на родниот фонет, и обезбедува добар модел на ниско ниво фонетски претставувања, поддржувајќи ја идејата дека категоричната и фина перцепција се користат за време на перцепцијата на говорот', 'ml': 'നമ്മുടെ സ്വന്തം ഭാഷ ഞങ്ങള്\u200d സംസാരിക്കുന്ന ശബ്ദം കാണുന്നത് പ്രധാനപ്പെടുത്തുന്നു. നമ്മുടെ സ്ഥാനമില്ലാത്ത സംസാരിക്കുന്നതിനെ സംബന്ധിച്ച് നമ്മള്\u200d രണ്ടു ആശയങ്ങളെ താല്\u200dപ്പര്യമാക്കുന്നു: പെര്\u200dസെപ്റ്റല്\u200d അസിമിലേഷന്\u200d മോഡല്\u200d, ശബ്ദങ്ങളുടെ മാനസിക വിഭാഗങ്ങളിലേക്ക് പ്രാര്\u200dത്ഥിക്കുന്ന ശബ്ദ നമ്മള്\u200d ഈ ഐഡിയയെ പ്രവര്\u200dത്തിപ്പിക്കുന്നത് രണ്ട് സ്റ്റേറ്റ് സംസാര മോഡലില്\u200d നിന്നും പ്രതിനിധികള്\u200d ഉപയോഗിക്കുന്നു. ഒരു ഡരിച്ച്ലെറ്റ് പ്രക ഫ്രെഞ്ച് സംസാരിക്കുന്ന പങ്കാളികളുടെ വാക്കുകളുടെ പ്രഭാഷണപ്രകൃതിയുടെ പുതിയ, തുറന്ന ഡാറ്റാസസേറ്റ് 61 ഭാഷകള ഫോണിമെന്\u200d അന്വേഷിക്കുന്നത് നല്ല ഫോണെറ്റിക് മോഡലിലേക്കാള്\u200d മെച്ചപ്പെടുത്തുന്നവനാണെന്ന് നമ്മള്\u200d കാണിക്കുന്നു. മുഴുവന്\u200d വ്യത്യസ്ത പ്രവര്\u200dത്തനത് നമ്മളും കാണിക്കുന്നു വാവ്2വേക്ക് 2.0, സംസാരിക്കുന്നതിന്റെ പ്രഭാവങ്ങള്\u200d പിടികൂടുന്നതില്\u200d നല്ലതായിരുന്നില്ല, സംസാരിക്കുന്നതിന്റെ പ്രഭാഷണത്തിന്റെ പ്രഭാഷണങ്ങള്\u200d സംബന്ധിച്ച് വ', 'mn': 'Бидний ээж хэл бидний ярианы дуу ойлгох аргыг нөлөөлдөг. Бидний орон нутгийн дуу бус дуудыг ялгах чадварыг нөлөөлдөг. Бид үндэсний хэл ойлголтын нөлөөтэй тухай хоёр санааг харьцуулж байна: Үүний үндэсний сэтгэл санааны хуваалтын загвар, үндэсний фонемын хэлбэрээр дуу санааны хуваалтыг зохион байгуулдаг, баян, цэвэрхэн фонетик үзүүлэлт нь үндэсний хэлний статистик дээр хангалттай. Бид энэ санааг хоёр улсын урлагийн ярианы загвараас илэрхийллийг ашиглаж, дириклетийн хувьсалын загвар болон саяхан wav2vec 2.0 загвараас ашигладаг. Бид Француз болон Англи хэлний оролцогчдын ярианы үндэслэлийн шинэ, нээлттэй өгөгдлийн сангуудыг зургаан хэлээс 61 дуу авч үзэх үйл явдал үзүүлнэ. Бид фонемийн ассимилацийг тодорхойлогч гэдэг нь тодорхойлогдсон фонетик загвараас илүү сайн тодорхойлогч гэдгийг харуулж байна. Хоёулаа ялгаагүй байдлын төлөө, гэр бүлийн хэл хэлний өөрчлөлттэй холбогдсон ялгааг тодорхойлох Мөн бид wav2vec 2.0 гэдгийг харуулж байна. Гэхдээ эх хэл нь ярианы ойлголтын нөлөөлөлийг авахдаа сайн биш, үндэсний фонемийн ассимилацийн тухай мэдээллийг нэмэгдүүлж, бага хэмжээний фонетийн төлөвлөгөөний сайхан загвар өгч, ярианы ойлголтын үед хоёр категорийн болон сайхан', 'mt': "Il-lingwa nattiva tagħna tinfluwenza l-mod kif naħsbu l-ħsejjes tad-diskors, u taffettwa l-kapaċità tagħna li niddiskriminaw ħsejjes mhux nattivi. Aħna nqabblu żewġ ideat dwar l-influwenza tal-lingwa nattiva fuq il-perċezzjoni tad-diskors: il-Mudell ta’ Assimilazzjoni Perċettwali, li jappella għal klassifikazzjoni mentali tal-ħoss f’kategoriji ta’ fonemi nattivi, meta mqabbel mal-idea li rappreżentazzjonijiet fonetiċi rikki u fini a ġġustati mal-istatistika tal-lingwa nattiva, huma biżżejjed. Aħna noperazzjonalizzaw din l-idea billi nużaw rappreżentazzjonijiet minn żewġ mudelli ta’ diskors avvanzati, proċess Dirichlet mudell ta’ taħlita Gaussjana u l-mudell wav2vec 2.0 aktar riċenti. Aħna nippreżentaw sett ġdid u miftuħ ta' dejta dwar l-imġiba tal-perċezzjoni tad-diskors tal-parteċipanti bil-Franċiż u bl-Ingliż għal 61 ħoss vokali minn sitt lingwi. Aħna nuru li l-assimilazzjoni tal-fonimi hija tbassir a ħjar minn mudellar fonetiku b’qamħ fin, kemm għall-imġiba diskriminatorja b’mod ġenerali, kif ukoll għat-tbassir tad-differenzi fid-diskriminazzjoni assoċjati mad-differenzi fl-isfond tal-lingwa nattiva. Aħna nuru wkoll li wav2vec 2.0, filwaqt li mhuwiex tajjeb fil-qabda tal-effetti tal-lingwa nattiva fuq il-perċezzjoni tad-diskors, huwa kumplimentari għall-informazzjoni dwar l-assimilazzjoni tal-fonema nattiva, u jipprovdi mudell tajjeb ta’ rappreżentazzjonijiet fonetiċi ta’ livell baxx, li jappoġġja l-idea li l-perċezzjoni kemm kategorika kif ukoll dik fina tintuża matul il-perċezzjoni tad-diskors.", 'pl': 'Nasz język ojczysty wpływa na sposób postrzegania dźwięków mowy, wpływając na naszą zdolność do rozróżniania dźwięków nieojczystych. Porównujemy dwie idee dotyczące wpływu języka ojczystego na percepcję mowy: Model asymilacji percepcyjnej, który odwołuje się do mentalnej klasyfikacji dźwięków na rodzime kategorie fonemów, a idea, że wystarczające są bogate, drobnoziarniste reprezentacje fonetyczne dostrojone do statystyk języka ojczystego. Operacjonalizujemy tę ideę wykorzystując reprezentacje z dwóch najnowocześniejszych modeli mowy, procesu Dirichleta modelu mieszaniny Gaussa oraz najnowszego modelu wav2vec 2.0. Przedstawiamy nowy, otwarty zestaw danych zachowań percepcji mowy uczestników francusko- i angielskojęzycznych dla 61 samogłosek z sześciu języków. Pokazujemy, że asymilacja fonemów jest lepszym predyktorem niż precyzyjne modelowanie fonetyczne, zarówno dla zachowań dyskryminacyjnych jako całości, jak i dla przewidywania różnic w dyskryminacji związanych z różnicami w języku ojczystym. Pokazujemy również, że wav2vec 2.0, choć nie jest dobry w uchwyceniu wpływu języka ojczystego na percepcję mowy, jest uzupełniający informacje o asymilacji fonemów ojczystych i stanowi dobry model niskopoziomowych reprezentacji fonetycznych, wspierający ideę, że podczas percepcji mowy stosuje się zarówno kategoryczną, jak i drobnoziarnistą percepcję.', 'sr': 'Naš jezik utiče na način na koji osjećamo zvukove govora, koji utiče na naše sposobnosti da diskrimiramo neproditeljne zvuke. Uspoređujemo dve ideje o utjecaju jezika na percepciju govora: Model za proceptualnu asimulaciju, koji privlači mentalnu klasifikaciju zvuka u kategorije materijalnih telefona, protiv ideje da su bogati, finozgrađeni fonetički predstavnici prilagođeni statistici jezika, dovoljni. Operalizujemo ovu ideju koristeći predstave iz dva model a govora iz države umjetnosti, Dirichletskog procesa Gausijskog mješavinskog modela i skoriji model wav2vec 2.0. Predstavljamo novo, otvoreno podatke o ponašanju govora francuskog i engleskog učesnika za 61 zvuka glasova iz šest jezika. Pokazujemo da je telefonska asimilacija bolji predviđa č nego fino zrno fonetički modeling, kao i za diskriminacijsko ponašanje u cijelom stanju, i za predviđanje razlika u diskriminaciji povezanih sa razlikama u pozadini jezika. Takoðe pokazujemo da je wav2vec 2.0, iako nije dobar u uhvativanju efekta jezika na percepciju govora, dodatno informacijama o naseljenim fonemom asimilaciji, i pruža dobar model fonetičkih predstavljanja niskog nivoa, podržavajući ideju da se kategorijsko i dobro zrno percepcije koriste tokom percepcije govora.', 'ro': 'Limba noastră maternă influențează modul în care percepem sunetele vorbirii, afectând capacitatea noastră de a discrimina sunetele non-native. Comparăm două idei despre influența limbii materne asupra percepției vorbirii: Modelul de Assimilare Perceptuală, care face apel la o clasificare mentală a sunetelor în categorii foneme native, versus ideea că reprezentările fonetice bogate, cu granule fine, adaptate la statisticile limbii materne, sunt suficiente. Operaționalizăm această idee folosind reprezentări din două modele de discurs de ultimă generație, un model de amestec gaussian proces Dirichlet și modelul mai recent wav2vec 2.0. Vă prezentăm un nou set de date deschis despre comportamentul percepției vorbirii limbii franceze și engleze al participanților pentru 61 de sunete vocale din șase limbi. Aratăm că asimilarea fonemei este un predictor mai bun decât modelarea fonetică fină, atât pentru comportamentul discriminatoriu în ansamblu, cât și pentru predicția diferențelor de discriminare asociate cu diferențele în limba maternă. De asemenea, demonstrăm că wav2vec 2.0, deși nu este bun la captarea efectelor limbii native asupra percepției vorbirii, este complementar informațiilor despre asimilarea fonemei native și oferă un bun model de reprezentări fonetice de nivel scăzut, susținând ideea că percepția atât categorică, cât și cea fină sunt utilizate în timpul percepției vorbirii.', 'so': 'Luqadeena hooyo wuxuu saameyn ku yeelan karaa sida aan u aragno codka hadalka, taasoo saameyn ku yeelan kara awooddayada kala takoorista codka aan aheyn hooyo. Waxaynu isbarbardhignaa laba fikrada oo ku saabsan saameyn ku saabsan afka hooyo ee ku saabsan aragtida hadalka: Tusaalada kaalmada ee Perceptura, kaas oo ugu yeedhaya fasaxa dhimirka oo u bedela kooxo afka hooyo, iyadoo ka gees ah fikrada ku saabsan inay taqsiirada afka hooyo ee hodanka ah ku qoran tahay, waxaa ku filan. Waxaynu ka shaqeynaynaa fikradan si loo isticmaalo noocyada hadalka farshaxanka labada dowladood, tusaale baaritaanka kala duwan ee Dirichlet iyo sameynta wav2vec 2.0. Waxaynu soo bandhignaynaa macluumaad cusub oo furan oo ah dabeecada aragtida afka Faraansiinta- iyo Ingiriiska ka qayb gala 61 oo ka baxaya lix luqadood oo af. Waxaynu muujinnaa in takoorida foomka uu yahay mid ka wanaagsan wax ka sii sheegi kara tusaale-qaab fiican oo telefoonka ah, labadoodaba habka takoorista oo dhan, iyo si loo sii sheegayo kala duwanaanshaha takoorka oo ku saabsan kala duwan afka hooyo. Sidoo kale wav2vec 2.0, iyadoo aan wanaagsanayn in la qabsado saameyaasha afka hooyo ee aragtida hadalka, waxay u adag tahay macluumaad ku saabsan isku qiimeynta sawifanka asalka ah, wuxuuna sameynayaa tusaale wanaagsan oo u egista telefonetka hoose, kaas oo taageeraya fikrada in labada kooxal iyo arag wanaagsan lagu isticmaalo xilliga hadalka.', 'sv': 'Vårt modersmål påverkar hur vi uppfattar talljud, vilket påverkar vår förmåga att särskilja icke-infödda ljud. Vi jämför två idéer om modersmålets påverkan på taluppfattningen: Perceptual Assimilation Model, som appellerar till en mental klassificering av ljud i modersmålskategorier, jämfört med tanken att rika, finkorniga fonetiska representationer anpassade till modersmålets statistik, är tillräckliga. Vi operativiserar denna idé med hjälp av representationer från två state-of-the-art talmodeller, en Dirichlet process Gaussian mixed model och den nyare wav2vec 2.0 modellen. Vi presenterar en ny, öppen datauppsättning av fransk- och engelsktalande deltagares talperceptionsbeteende för 61 vokalljud från sex språk. Vi visar att fonemisimilering är en bättre prediktor än finkornig fonetisk modellering, både för diskrimineringsbeteendet som helhet och för att förutsäga skillnader i diskriminering förknippade med skillnader i modersmålsbakgrund. Vi visar också att wav2vec 2.0, även om det inte är bra på att fånga upp effekterna av modersmål på taluppfattning, kompletterar information om infödd fonem assimilering, och ger en bra modell av lågnivåfonetiska representationer, stöder idén att både kategorisk och finkornig perception används vid taluppfattning.', 'si': 'අපේ ජාතික භාෂාව අපි කතාවක් ශබ්ද දැනගන්න ප්\u200dරශ්නයක් කරනවා, අපේ ශක්තියක් ප්\u200dරශ්නයක් කරනවා නැති ජා අපි අදහස් දෙකක් සම්බන්ධ කරනවා ජාතික භාෂයේ ප්\u200dරශ්නයක් ගැන භාෂාව ප්\u200dරශ්නයක් ගැන: ප්\u200dරශ්නයක් සම්බන්ධ විශ්නයක් වෙනුවෙන්, සම්බන්ධ විශ්නයක් වලින අපි මේ අදහසට ප්\u200dරතිනිධානය කරන්නේ ප්\u200dරතිනිධානය දෙකක් ප්\u200dරතිනිධානය කරන්න, ඩිරිච්ලෙට් ප්\u200dරතිස්ථානයක් ගෝසියාන් මික්සුර්  අපි ෆ්\u200dරෑන්ස් සහ ඉංග්\u200dරීසි කතා කරන්නේ අලුත් දත්ත සූදානයක් පෙන්වන්නේ - අංග්\u200dරීසි කතා කරන්නේ අංග්\u200dරීසි ක අපි පෙන්වන්නේ ෆෝනේම් අසිමිලේෂන් හොඳ ප්\u200dරදේශකයෙක් විශ්වාස කරනවා හොඳ ප්\u200dරදේශකයෙක්, හොඳ ප්\u200dරදේශකයෙක්, හොඳ ප්\u200dරදේශකයෙන්, හැම ප අපි වගේම පෙන්වන්නේ වැව්වෙක් 2.0, ජාතික භාෂයේ ප්\u200dරභාව අල්ලගන්න හොඳ නැති විදියට, ජාතික ෆෝනේම් සසිමිලේෂන් ගැන තොරතුරු සම්පූර්ණය සඳහා සම්පූර්ණය සඳහා හ', 'ta': 'நாங்கள் பேச்சு ஒலிகளை பார்க்கும் முறையில் எங்கள் நாட்டு மொழி பாதிக்கும், எங்கள் சக்தியை நாட்டும் ஒலிகளை வி நாம் இரண்டு கருத்துக்களை ஒப்பிடுகிறோம் பேச்சு பார்வையின் பாக்கியத்தை பற்றி இரண்டு மொழியின் விளைவுகளை பற்றி: செயல்படுத்தல் மாதிரி, அது தாய் தொலைபேசி வகுப்பின் மாதிரி வகுப்பில் ஒ இரண்டு நிலையில் இருந்து கலை பேச்சு மாதிரிகளில் இருந்து குறிப்புகளை பயன்படுத்தி இந்த யோசனை செயல்படுத்துகிறோம், ஒரு டைரிக்லட் செயல்பாடு கா ஆறு மொழிகளில் இருந்து 61 சத்திர ஒலிகளுக்கான பேச்சு பேசும் பேச்சு பார்ப்பு பார்வையில் புதிய, திறந்த தகவல் அமைப்ப நாம் காண்பிக்கிறோம் நோக்கி ஒப்புக்கொள்வது நல்ல போன்டியல் மாதிரிப்பாளரை விட சிறந்தது புதிய முறைமையாகும், முழு வேறுபாடு நடத்தைக்கும் முழு நாம் காண்பிக்கிறோம் என்றால் உள்ள மொழி பேச்சு பார்வையின் விளைவுகளை பெறுவதில் நன்றாக இல்லை என்பதை வாவ்2vec 2.0 க்கும் காட்டுகிறது, பேச்சு போன்போம் ஒப்பிடுதல் பற்றிய தகவல்களுக்கு சிறப்', 'no': 'Målspråket vårt påvirkar måten vi oppfattar talelydar, og påvirkar vårt kapasitet til å diskriminere ikkje-native lydar. Vi sammenliknar to idear om påvirkninga av den mottalespråket på taleoppfatningen: den proseptuelle sammenlikningsmodulen, som appellar til ein mental klassifikasjon av lydar til dei mottale fonemakategoriane, mot ideen at rike, finkorne fonetiske representasjonar som er sett til statistikken av den mottalespråket, er nok. Vi operasjonarer denne ideen ved å bruka representasjonar frå to tilstandsmodular for kunsten, ein Dirichlet-prosess Gaussian mixture model og den siste wav2vec 2.0-modellen. Vi presenterer eit nytt, opna datasett av språk frå fransk og engelsk deltakarar for 61 lydar frå seks språk. Vi viser at telefonassimilasjonen er ein bedre forhåndsvising enn fine-grained phonetic modelling, både for diskriminasjonen som heilt, og for å forhåndsvisa forskjeller i diskriminasjonen som er forbunda med forskjeller i den mottale språkkbakgrunnen. Vi viser også at wav2vec 2.0, mens det ikkje er bra å henta effekten av den mottalespråket på taleoppfatning, er komplementært til informasjon om den mottale fonema-assimilasjon, og tilbyr ein god modell av låg nivå fonetiske representasjonar, som støttar ideen at både kategoriske og fyrke oppfatningar vert brukt under taleoppfatning.', 'ur': 'ہماری ماں کی زبان ایسی طرح اثر دیتی ہے جس طرح ہم زبان آواز کو دیکھتے ہیں اور اپنے غیر ماں کی آوازوں کو جدائی کرنے کے قابلیت پر اثر دیتے ہیں۔ ہم بولنے کی نظر پر ماں کی زبان کی تاثیر کے بارے میں دو ایڈیوں کو مقایسہ کرتے ہیں: پرسپٹی آسیمیل موڈل، جو صدا کی روانی کلاسیفون کو ماں کی فونیم کاٹیوں میں پکارتا ہے، اور اس ایڈیوں کے مقابلہ میں کہ ماں کی زبان کی آمارت کے مطابق بہترین، بہترین غلاموں کی نمونات کافی ہیں۔ ہم نے اس ایڈیون کو دوسرے ایٹیٹ کی سخنرانی موڈل سے روشنی کے مطابق کرلیا ہے، ایک ڈریچلت پرسس گاوسی میکسٹر موڈل اور اس سے زیادہ اخیر wav2vec 2.0 موڈل کے مطابق کرلیا ہے. ہم فرنسیس اور انگلیسی بات کرنے والوں کے صحبت کرنے والوں کے بارے میں ایک نئی، کھولی ڈاٹ سٹ کو چھ زبانوں سے 61 واول آواز کے بارے میں پیش کرتے ہیں. ہم دکھاتے ہیں کہ فونیمی آسیمیل ایک بہتر پیش بینی ہے جو پاکیزہ دانے کی فونیک موڈلینگ سے بہتر ہے، دونوں مختلف رفتار کے لئے، اور ماں کی زبان کے پچھلے میں مختلف فرق کی پیش بینی کے لئے۔ ہم نے بھی دکھایا ہے کہ wav2vec 2.0، حالانکہ زبان کی اصلی زبان کی اثرات کو پکڑنے کے لئے اچھی نہیں ہے، وطن کی فونیم آسیمیل کے بارے میں اطلاعات کے مطابق اضافہ ہے، اور کم سطح کے فانیک نمونے کی ایک اچھی نمونے کے مطابق پیش کرتا ہے، اس ایده کی مدد کرتی ہے کہ کلیٹریک اور نیک دانے کی نظر', 'vi': 'Ngôn ngữ của chúng ta ảnh hưởng đến cách chúng ta nhận thức âm thanh ngôn ngữ, ảnh hưởng đến khả năng phân biệt âm thanh không thổ dân. Chúng tôi so sánh hai ý tưởng về ảnh hưởng của ngôn ngữ bản về nhận thức của ngôn ngữ nói: Mô hình nhận thức phân bổ, yêu cầu phân loại âm thanh trong tâm thần thành các loại ngữ ngữ ngữ ngữ ngữ tự, so với ý tưởng rằng các biểu ngữ âm giàu có, dồn đậm chất theo các thống kê của ngôn ngữ bản xứ, là đủ. Chúng tôi vận hành ý tưởng này bằng các biểu tượng của hai mẫu ngôn ngữ hiện đại, một kiểu hỗn hợp kiểu Gaussian và một mô hình hỗn hợp Wav2vec 2.0 gần đây. Chúng tôi giới thiệu một bộ dữ liệu mới mở của những người tham dự ngôn ngữ Pháp và Anh để nhận thức ngôn ngữ 61 âm thanh từ sáu ngôn ngữ. Chúng tôi cho thấy việc đồng hóa niên ngữ là một người dự đoán tốt hơn cả mô hình ghép, cả cho hành vi phân biệt trong toàn bộ, và để dự đoán sự khác biệt về sự phân biệt khi khác nhau trong nền ngôn ngữ bản. Chúng tôi cũng cho thấy Wav2vec 2', 'uz': "Bizning natijadagi tilimiz gapiruvchi tovushlarni ko'rinishimizga ta'siradi, natijadagi tovushlarni ajratish imkoniyatini beradi. Biz natijadagi tillarning fikrlarini tasavvur qilamiz: Perceptal Assimilation Model (PerPerceptual Assimilation Model), bu o'zida o'zining o'ylab tovushlarni nativiy telefon turlariga ega'ladi, va o'ylab, hozir, o'ylab keladigan o'ylab, o'ylab, nativiy tilning statistikasiga bog'liq fikrlarni o'xshash o'ylab keladi. Biz bu g'oyani ikkita holatdagi rasm modellaridan foydalanish bilan boshqaramiz, Dirichlet jarayonlarida gaussiya mix modeli va yaqinda yaqinda wav2vec 2.0 modeldan foydalanamiz. Biz 61 tildan afrikansa va ingliz tilda gapiradigan gapiruvchi xuddi yangi ochiq maʼlumot tarkibini yetdik. Biz o'ylaymiz, foydalanuvchi yaxshi foydalanuvchi modellikdan yaxshi ko'rinishini ko'rsatumiz, butun ta'minlovchi xuddi, va nativiy tillar orqa orqali o'xshash o'zgarishlar bilan o'xshash o'zgarishni ko'rganamiz. Vav2vec 2.0 ni ko'rsatishimiz mumkin, o'sha tilning tasavvurini tasavvur qilishda juda yaxshi emas, va nativiy foydalanish haqida ma'lumotga murakkab bo'ladi, va o'ylab tasavvur qilish haqida juda yaxshi foydalanish modelini qo'llaydi, bu g'oyani bir kategorik va yaxshi ko'rinishiga qo'llaydi.", 'bg': 'Родният ни език влияе върху начина, по който възприемаме речните звуци, засягайки способността ни да дискриминираме чужди звуци. Сравняваме две идеи за влиянието на родния език върху възприемането на речта: модела на възприемане на асимилация, който привлича умствената класификация на звуците в категории родни фонеми, срещу идеята, че богатите, фино-зърнести фонетични представи, настроени към статистиката на родния език, са достатъчни. Операционализираме тази идея, използвайки представи от два най-съвременни модела на речта, модел на смесване на Дирихлет и по-новия модел на вав2век 2.0. Представяме нов отворен набор от данни за поведението на френско и англоговорящите участници в възприемането на речта за 61 гласни звуци от шест езика. Показваме, че асимилацията на фонемите е по-добра предсказваща от финото фонетично моделиране, както за дискриминационното поведение като цяло, така и за прогнозиране на разликите в дискриминацията, свързани с разликите в произхода на родния език. Показваме също, че макар и да не е добър в улавянето на ефектите на родния език върху възприемането на речта, той допълва информацията за асимилацията на родния фонем и осигурява добър модел на фонетични представи на ниско ниво, подкрепяйки идеята, че при възприемането на речта се използват както категорично, така и финозърнато възприемане.', 'nl': 'Onze moedertaal beïnvloedt de manier waarop we spraakgeluiden waarnemen en beïnvloedt ons vermogen om niet-moedergeluiden te onderscheiden. We vergelijken twee ideeën over de invloed van de moedertaal op spraakperceptie: het Perceptual Assimilation Model, dat aanspreekt op een mentale classificatie van geluiden in native foneemcategorieën, versus het idee dat rijke, fijnkorrelige fonetische representaties, afgestemd op de statistieken van de moedertaal, voldoende zijn. We operationaliseren dit idee met behulp van representaties van twee state-of-the-art spraakmodellen, een Dirichlet proces Gaussian mix model en het meer recente wav2vec 2.0 model. We presenteren een nieuwe, open dataset van het spraakperceptiegedrag van Franstalige en Engelstalige deelnemers voor 61-klinkergeluiden uit zes talen. We tonen aan dat foneemassimilatie een betere voorspeller is dan fijngranige fonetische modellering, zowel voor het discriminatiegedrag als voor het voorspellen van verschillen in discriminatie geassocieerd met verschillen in moedertaalachtergrond. We tonen ook aan dat wav2vec 2.0, hoewel niet goed in het vastleggen van de effecten van moedertaal op spraakperceptie, complementair is aan informatie over native foneemassimilatie, en een goed model biedt van fonetische representaties op laag niveau, ondersteund het idee dat zowel categorische als fijnkorrelige perceptie worden gebruikt tijdens spraakperceptie.', 'id': 'Bahasa asli kita mempengaruhi cara kita menyadari suara pidato, mempengaruhi kemampuan kita untuk diskriminasi suara bukan asli. Kita membandingkan dua ide tentang pengaruh bahasa asli pada persepsi pidato: Model Perspektif Assimilasi, yang menarik kepada klasifikasi mental suara ke kategori fonema asli, dibandingkan ide bahwa representation fonetik kaya, berwarna gandum yang sesuai dengan statistik bahasa asli, cukup. Kita menggunakan gambaran dari dua model pidato terbaik, proses Dirichlet model campuran Gaussia dan model wav2vec 2.0 yang baru ini. Kami mempersembahkan dataset baru, terbuka dari persepsi pidato peserta bahasa Perancis dan Inggris untuk 61 suara suara dari enam bahasa. Kami menunjukkan bahwa asimilasi fonem adalah prediksi yang lebih baik daripada model fonetik yang bersinar baik, baik untuk perilaku diskriminasi secara keseluruhan, dan untuk prediksi perbedaan dalam diskriminabilitas terkait dengan perbedaan dalam latar belakang bahasa asli. Kami juga menunjukkan bahwa wav2vec 2.0, meskipun tidak baik dalam menangkap efek bahasa asli pada persepsi pidato, adalah komplimentar untuk informasi tentang asimilasi fonema asli, dan menyediakan model yang baik dari persepsi fonetik tingkat rendah, mendukung ide bahwa persepsi kategori dan benih baik digunakan selama persepsi pidato.', 'de': 'Unsere Muttersprache beeinflusst die Art und Weise, wie wir Sprachgeräusche wahrnehmen, und beeinflusst unsere Fähigkeit, nicht-native Töne zu unterscheiden. Wir vergleichen zwei Vorstellungen über den Einfluss der Muttersprache auf die Sprachwahrnehmung: das Perzeptual Assimilation Model, das eine mentale Klassifizierung von Klängen in native Phoneme Kategorien anspricht, gegenüber der Vorstellung, dass reiche, feinkörnige phonetische Darstellungen, abgestimmt auf die Statistik der Muttersprache, ausreichen. Wir operationalisieren diese Idee mit Repräsentationen aus zwei hochmodernen Sprachmodellen, einem Dirichlet-Prozess Gauß-Mischungsmodell und dem neueren wav2vec 2.0-Modell. Wir präsentieren einen neuen, offenen Datensatz des Sprachwahrnehmungsverhaltens französisch- und englischsprachiger Teilnehmer für 61-Vokaltöne aus sechs Sprachen. Wir zeigen, dass Phonem-Assimilation ein besserer Prädiktor ist als feingranulare phonetische Modellierung, sowohl für das Diskriminierungsverhalten als auch für die Vorhersage von Unterschieden in der Diskriminierung im Zusammenhang mit Unterschieden im Hintergrund der Muttersprache. Wir zeigen auch, dass wav2vec 2.0, obwohl es nicht gut ist, die Auswirkungen der Muttersprache auf die Sprachwahrnehmung zu erfassen, komplementär zu Informationen über die native Phonem-Assimilation ist und ein gutes Modell für phonetische Darstellungen auf niedrigem Niveau bietet, was die Idee unterstützt, dass sowohl kategorische als auch feinkörnige Wahrnehmung während der Sprachwahrnehmung verwendet werden.', 'da': 'Vores modersmål påvirker den måde, vi opfatter talelyde på, og påvirker vores evne til at skelne ikke-indfødte lyde. Vi sammenligner to ideer om modersprogets indflydelse på taleopfattelsen: Perceptual Assimilation Model, som appellerer til en mental klassificering af lyde i modersmål fonemkategorier, versus tanken om, at rige, finkornede fonetiske repræsentationer afstemt til modersmål statistik, er tilstrækkelige. Vi operationealiserer denne idé ved hjælp af repræsentationer fra to state-of-the-art talemodeller, en Dirichlet proces Gaussian blanding model og den nyere wav2vec 2.0 model. Vi præsenterer et nyt, åbent datasæt af fransk- og engelsktalende deltageres taleopfattelsesadfærd for 61 vokalelyde fra seks sprog. Vi viser, at fonemisimilering er en bedre forudsiger end finkornet fonetisk modellering, både for diskriminationsadfærden som helhed og for at forudsige forskelle i diskriminationsevne forbundet med forskelle i modersmål baggrund. Vi viser også, at wav2vec 2.0, selvom den ikke er god til at fange virkningerne af modersmål på taleopfattelsen, supplerer oplysninger om native foneme assimilering, og giver en god model for lavt niveau fonetiske repræsentationer, der understøtter tanken om, at både kategorisk og finkornet opfattelse bruges under taleopfattelsen.', 'hr': 'Naš jezik utječe na način na koji osjećamo zvukove govora, utječe na našu sposobnost diskriminiranja neproditeljskih zvuka. Uspoređujemo dvije ideje o utjecaju jezika na percepciju govora: Model proceptualne asimulacije, koji apeluje na mentalnu klasifikaciju zvuka u kategorije domaćih telefona, protiv ideje da su bogati, dobrogromni fonetički predstavnici navedeni na statistiku jezika dovoljni. Operaliziramo ovu ideju koristeći predstave iz dva model a govora stanja umjetnosti, Dirichlet procesa Gaussian mixture model i skoriji model wav2vec 2.0. Predstavljamo novi, otvoreni podaci o ponašanju govora francuskog i engleskog učesnika za 61 glasnih zvuka iz šest jezika. Pokazujemo da je telefonska asimilacija bolji predviđa č nego fino zrno fonetičko modeliranje, kao i za diskriminaciju u cijelom položaju, kao i za predviđanje razlika u diskriminaciji povezanih s razlikama u pozadini jezika. Također pokazujemo da je wav2vec 2,0, iako nije dobar u uhvaćenju učinka jezika na percepciju govora, dodatak informacijama o naseljenim fonemom asimilaciji, i pruža dobar model fonetičkih predstavljanja niskog nivoa, podržavajući ideju da se kategorijska i zgodna percepcija koriste tijekom percepcije govora.', 'ko': '우리의 모국어는 우리가 음성을 감지하는 방식에 영향을 주고 비모국어 소리를 판별하는 능력에 영향을 준다.우리는 두 가지 모국어가 음성 감지에 미치는 영향에 대한 관점을 비교했다. 감지 동화 모델은 소리를 모국어의 음소 유형에 따라 심리적으로 분류할 것을 호소하고 풍부하고 세립도의 음성은 모국어의 통계 데이터와 부합되는 관점으로 충분하다.우리는 두 가지 가장 선진적인 음성 모델을 사용하는데 하나는 Dirichlet 프로세스 고스 혼합 모델이고 다른 하나는 최근의wav2vec 2.0 모델로 이 생각을 실현한다.우리는 6개 언어의 61개의 모음에서 나온 새로운 프랑스어와 영어 참여자의 음성 감지 행위 데이터 집합을 제공했다.우리는 음소 동화가 세립도 음성 모델링보다 전체적인 변별 행위를 예측할 수 있고 모국어 배경 차이와 관련된 변별성 차이도 예측할 수 있다는 것을 발견했다.우리는wav2vec2.0이 모국어가 음성 감지에 미치는 영향을 잘 포착하지 못하지만 모국어의 음소 동화에 관한 정보를 보충하고 좋은 저수준 음성 표징 모델을 제공하여 음성 감지 과정에서 범주 감지와 세립도 감지를 동시에 사용하는 관점을 지원한다.', 'sw': 'Lugha yetu ya asili inaathiri jinsi tunavyoelewa sauti za hotuba, inayoathiri uwezo wetu wa kutofautisha sauti zisizo wenyeji. Tunawalinganisha mawazo mawili kuhusu athari ya lugha ya asili juu ya mtazamo wa hotuba: Modeli ya Ushafidhina wa Peru, ambayo inaita sifa za kisaikolojia katika makundi ya simu za asili, kinyume na wazo kwamba wawakilishaji wa simu za mkononi wenye utajiri, wenye ufadhili mzuri unaohusika na takwimu za lugha za asili, inatosha. Tunafanya wazo hili kwa kutumia uwakilishi kutoka kwenye mifano miwili ya hotuba ya sanaa, mtindo wa mchakato wa mchanganyiko wa Gaussia na mtindo wa wav2vec 2.0 wa hivi karibuni. Tunaweza kuweka taarifa mpya ya wazi ya mazungumzo ya washiriki wa lugha ya Kifaransa na Kiingereza kwa sauti za ahadi 61 kutoka lugha sita. Tunaonyesha kuwa ubaguzi wa simu ni mtabiri bora kuliko muundo mzuri wa simu za mkononi, wote kwa tabia za ubaguzi wote, na kwa kutabiri tofauti katika ubaguzi unaohusiana na tofauti za lugha za asili. Tunaonyesha pia kuwa wav2vec 2.0, wakati si vizuri katika kuchukua madhara ya lugha ya asili kwenye mtazamo wa hotuba, ni muhimu wa taarifa kuhusu usambazaji wa simu za asili, na pia inatoa mtindo mzuri wa uwakilishaji wa simu za mkononi kwa kiwango cha chini, kwa kusaidia wazo kwamba nchi zote zinatumiwa na mitazamo ya kigaidi na yenye ufanisi mzuri.', 'sq': 'Gjuha jonë natyrore ndikon në mënyrën se si ne perceptojmë tingujt e fjalimit, duke ndikuar në aftësinë tonë për të diskriminuar tingujt jo natyrore. Ne krahasojmë dy ide rreth ndikimit të gjuhës natyrore në perceptimin e fjalës: Modelin e Asimilimit Perceptual, i cili apelon për një klasifikim mental të tingujve në kategoritë e telefonimeve natyrore, në krahasim me idenë se përfaqësimet fonetike të pasura dhe të holla të përshtatura me statistikat e gjuhës natyrore, janë të mjaftueshme. Ne e operationalizojmë këtë ide duke përdorur përfaqësime nga dy modele fjalimi më të lartë, një proces Dirichlet model përzier Gausi dhe modeli më i fundit wav2vec 2.0. Ne paraqesim një grup të ri të të dhënash të hapura të sjelljes së perceptimit të fjalimit të pjesëmarrësve në gjuhën franceze dhe angleze për 61 tinguj vokale nga gjashtë gjuhë. Ne tregojmë se asimilimi i telefonimeve është një parashikues më i mirë se modelimi fonetik me kokërra të holla, si për sjelljen diskriminuese si të tërë, ashtu dhe për parashikimin e dallimeve në diskriminabilitetin lidhur me dallimet në sfondin e gjuhës lindore. Ne tregojmë gjithashtu se wav2vec 2.0, ndërsa nuk është i mirë në kapjen e efekteve të gjuhës natyrore në perceptimin e fjalës, është komplementar me informacionin rreth asimilimit të telefonimeve natyrore dhe ofron një model të mirë të përfaqësimeve fonetike të nivelit të ulët, duke mbështetur idenë se perceptimi si kategorik ashtu edhe i hollë përdoret gjatë perceptimit të fjalës.', 'fa': 'زبان مادرمان به طریقی که صدای سخنرانی را درک می\u200cکنیم تأثیر می\u200cدهد و توانایی ما را در اختلاف صدای غیر مادری تأثیر می\u200cدهد. ما دو ایده را در مورد تاثیر زبان مادری بر مشاهده سخنرانی مقایسه می کنیم: Model Assimilation Perseptual, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations adjusted to the statistics of the native language, are sufficient. ما این ایده را با استفاده از نمایش\u200cهایی از دو مدل سخنرانی هنری، یک مدل مخلوط گاوسی و مدل جدیدتر wav2vec 2.0 عملیات می\u200cکنیم. ما یک مجموعه اطلاعات جدید، باز و باز از رفتار مشترک سخنرانی فرانسوی و انگلیسی برای صدای 61 صوت از شش زبان پیشنهاد می کنیم. ما نشان می دهیم که آسیمیل تلفن یک پیش بینی بهتر از نمونه\u200cهای تلفنی\u200cای است، هر دو برای رفتار جدایی در کل، و برای پیش بینی فرق\u200cهایی در اختلاف\u200cهای جدایی که مربوط به فرق\u200cهایی در زمینه زبان مادری هستند. ما همچنین نشان می دهیم که wav2vec 2.0، در حالی که اثرات زبان طبیعی روی perception سخنرانی خوب نیست، به اطلاعات درباره آسیمیل فونیم طبیعی اضافه می شود، و یک مدل خوب از نمایش\u200cهای فونیک پایین سطح می\u200cدهد، که پشتیبانی از ایده\u200cای است که در طول perception سخنرانی هر دو گونه و دانه\u200cهای خوب استفاده می\u200c', 'am': 'የአገራዊ ቋንቋችን የንግግር ድምፅ እንደምናውቀው ድምፅ እናስጨንቃለን፡፡ ሁለትን የአገር ቋንቋ በቋንቋ አስተያየት ላይ ግንኙነትን እናሳያታለን፤ የድምፅ አካባቢ እና ድምጾችን በአገራዊ ፎልክ ክፍሎች ላይ የሚጠይቅ እናስባለን፡፡ ባለ ጠጋ፣ የተጠቃሚ የፎንnetic መልዕክቶች በአገር ቋንቋ ቁጥር ላይ የተጠቃሚ ጥያቄ ይበቃል፡፡ ይህንን አእምሮዎች ከሁለት ሀገራት የንግግር ዓይነት፣ የዳሪክሌት ፕሮጀክት ጋውስሲዊ ትካክል ሞዴል እና የቀድሞው wav2vec 2.0 ሞዴል በመጠቀም እናደርጋለን፡፡ የፍረንሳይ እና እንግሊዘኛ እና የንግግር ቋንቋ ተጋሪዎችን አዲስ የተከፈተ ዳታዎችን ከስድስት ቋንቋዎች የስድስት ቋንቋዎች ድምፅ እናቀርባለን፡፡ የፎምፎችን ማነሳቀል በአገሪቱ ቋንቋ መሬት ላይ በተለያዩ ልዩነት በተለየ ቋንቋ ውይይት ከሚያሳየው ጥያቄ የሚሻል የፎንnetic ምሳሌ እናሳየዋለን፡፡ እና wav2vec 2.0፣ የአገር ቋንቋን በንግግር እውቀት ላይ ማስታወቂያውን ለማግኘት ጥሩ ሳይሆን፣ የአገሪቱ ፎፎፎን ማቀናቀል በተጨማሪነት እና በንግግር እውቀት ላይ የሚጠቀሙት የፎንnetic ምሳሌ እናደርጋለን፡፡', 'tr': 'Bizi흫 ene dilimiz 챌yky힊y흫 sesini g철r체p bilmegimizi t채sirle첵채r we ene-de ses d채l etmegimizi t채sirle첵채r. Biz ene dilini흫 g철rn체힊inde 첵akynla힊dyrylmagy barada iki pikir g철r첵채ris: Perseptual Assimilation Modeli, bu ses d체첵힊체nden di흫e phoneme kategori첵asyna s체첵tge첵채r, we ba첵, gowy phonetik suratlary흫 ene dili흫 statisti첵asyna d체z체len pikir 첵eterli. Bu fikri iki durum sanatl캇 konu힊ma modellerinden, Dirichlet s체recinde Gaussian kar캇힊캇k modellerinden ve daha yeni wav2vec 2.0 modellerinden olu힊turuyoruz. Biz fransuz챌a we i흫lis dilinden 61 sany ses g철rkezil첵채n 챌yky힊lyklary흫 barlag t채ze, a 챌yk maglumatlary g철rke첵채ris. Biz fonem assimilasi첵asyny흫 d체zg체n fonetik modellerinden has gowydygyny 철흫체nd체r첵채ris, hem diskriminasi첵a hem bir zat 체챌in we ene dilde 체첵tge힊meler bilen d체첵tge힊iklerini 철흫체ndirmek 체챌in. Biz hem wav2vec 2.0 di첵ip g철r체n첵채rdik, ene dilini흫 s철zlerine t채sirlerini almakda gowy d채ldir, ene foneme assimilasy barada maglumaty흫 da흫lapdyr we d체힊체k d체힊체k d체힊체k fonetik t채sirlerini흫 gowy nusgasyny berer, 챌yky힊 d체힊체n체힊inde hem kategori첵aly hem gowy d체힊체n체힊 ulanyl첵andygy d체힊체n체흫e destekle첵채ris.', 'hy': "Our native language influences the way we perceive speech sounds, affecting our ability to discriminate non-native sounds.  Մենք համեմատում ենք երկու գաղափար բնիկ լեզվի ազդեցության մասին խոսքի ընկալումը' ընկալումների նման մոդելը, որը հնարավորություն է տալիս ձայների մտավոր դասակարգումը բնիկ ֆոնեմի կատեգորիաների մեջ, համեմատությամբ այն գաղափարի հետ, որ հարուստ, գեղեցիկ ֆոնետիկ ներկայացումները, որոնք համապատասխանում են Մենք կիրառում ենք այս գաղափարը օգտագործելով երկու բարձրագույն խոսքի մոդելների ներկայացումներ, Դիրիկլետի գործընթացը՝ Գուսիայի խառնուրդ մոդելը և վերջին մոդելը՝ wov2vec 2.0: Մենք ներկայացնում ենք ֆրանսերեն և անգլերեն խոսքի մասնակիցների նոր, բաց տվյալների համակարգ 6 լեզուներից 61 ձայնի ընկալումը: Մենք ցույց ենք տալիս, որ հեռախոսների ասիմիլացիան ավելի լավ կանխատեսող է, քան գեղեցիկ ֆոնետիկ մոդելներ, ինչպես խտրականության վարքագծի համար որպես ամբողջ, ինչպես նաև արտահայտության տարբերությունների կանխատեսման համար, որոնք կապված են բնիկ լեզուների տարբերությունների հետ: Մենք նաև ցույց ենք տալիս, որ wov2vec 2.0-ը, չնայած, որ լավ չէ բնիկ լեզվի ազդեցությունները խոսքի ընկալության վրա նկարահանելու համար, համալրացնում է բնիկ հեռախոսների ասիմիլացիայի մասին տեղեկատվությունը, և ապահովում է ցածր մակարդակի ֆոնետիկ ներկայացումների լավ մոդել, որը աջակցնում է այն գաղափարը, որ խոսքի", 'af': "Ons moedertaal influens die manier waarop ons spreekklanke aanvaar, wat ons vermoë het om nie-native klanke te diskrimineer. Ons vergelyk twee idees oor die influens van die taal van die taal op spraak aandag: die Perseptieële Assimilation Model, wat op 'n menslike klasifikasie van klanke appel na 'n natuurlike foneme kategorie, teenoor die idee wat ryk, fyn-graanese fonetiese voorstellings wat aan die statistiek van die taal aangestel is, is genoeg. Ons operatiseer hierdie idee deur te gebruik voorstellings van twee staat-van-die-kunstens spreek modele, 'n Dirichlet proses Gaussian gemakking model en die meer onlangse wav2vec 2.0 model. Ons stel 'n nuwe, oopgemaakte datastel van Frans- en Engels- spreekbaar deelnaders se praatverweking gedrag vir 61 geluide van ses tale. Ons wys dat foneme assimilasie 'n beter voorskouer is as fyn-graad fonetiese modellering, beide vir die diskriminasie gedrag as 'n hele, en vir voorskou verskille in diskriminasie wat geassosieer is met verskille in die taal agtergrond. Ons wys ook dat wav2vec 2.0, terwyl nie goed is om die effekte van natuurlike taal op spraak verstaan te neem nie, is komplementeer tot inligting oor natuurlike foneme assimilasie, en verskaf 'n goeie model van lae vlak fonetiese voorstellings, ondersteun die idee dat beide kategoriese en fyn-graan verstaan gebruik word tydens spraak verstaan.", 'bn': 'আমাদের স্থানীয় ভাষা যেভাবে আমরা ভাষণের শব্দ দেখতে পাচ্ছি সেভাবে প্রভাবিত হয়েছে, যা আমাদের স্থানীয় শব্দ বৈষম্যে আমরা স্থানীয় ভাষার ভাষার প্রভাব নিয়ে দুটি চিন্তার তুলনা করি: পার্সিপ্টুয়াল অ্যাসিমিলেশন মডেল, যা শব্দের মানসিক বিভাগের মানসিক বিভাগের প্রতি আহ্বান জানাচ্ছে, তার বিপরীতে এই ধারণ আমরা এই চিন্তা ব্যবহার করি দুই রাষ্ট্র-শিল্পের প্রতিনিধিত্ব, একটি ডিরিচেল প্রক্রিয়া গাউসিয়ান মিশ্রিত মডেল এবং সাম্প্রতিক ওয়াভি২ভেক ২. আমরা একটি নতুন, খোলা তথ্য সংক্রান্ত ফ্রেঞ্চ এবং ইংরেজী ভাষায় অংশগ্রহণকারীদের ভাষণের ভাষণের দৃষ্টিভঙ্গি আচরণের জন্য আমরা দেখাচ্ছি যে ফোনেমের সমতুল্যের ভালো ভবিষ্যদ্বাণী হচ্ছে ভালোভাবে গ্রেফতার করা ফোনেটিক মডেলিং এর চেয়ে ভালো ভবিষ্যদ্বাণী, সারা বৈষম্যের জন্য,  আমরা একই সাথে দেখাচ্ছি যে ওয়াভি২ভেক ২.', 'bs': 'Naš jezik utječe na način na koji osjećamo zvukove govora, utječe na našu sposobnost diskriminacije neproditeljskih zvuka. Uspoređujemo dvije ideje o utjecaju jezika na percepciju govora: Model proceptualne asimulacije, koji apeluje na mentalnu klasifikaciju zvuka u kategorije domaćih telefona, protiv ideje da su bogate, dobrogromne fonetičke predstave navedene na statistiku jezika dovoljne. Operaliziramo ovu ideju koristeći predstave iz dva model a govora iz države umjetnosti, Dirichlet procesa Gausijskog mješavinskog modela i skoriji model wav2vec 2.0. Predstavljamo novi, otvoreni set podataka o ponašanju govora francuskog i engleskog učesnika za 61 zvuka glasova iz šest jezika. Pokazujemo da je telefonska asimilacija bolji predviđa č nego fino zrno fonetički modeling, i za diskriminaciju u cjelokupnom položaju, i za predviđanje razlika u diskriminaciji povezanih sa razlikama u pozadini jezika. Također pokazujemo da je wav2vec 2.0, iako nije dobar u uhvativanju učinka jezika na percepciju govora, dodatno informacijama o naseljenim asimilacijama foneme, i pruža dobar model fonetičkih predstavljanja niskog nivoa, podržavajući ideju da se kategorijska i fino zrncana percepcija koriste tijekom percepcije govora.', 'cs': 'Náš rodný jazyk ovlivňuje způsob, jakým vnímáme zvuky řeči, což ovlivňuje naši schopnost rozlišovat zvuky, které nejsou rodné. Porovnáváme dvě představy o vlivu rodného jazyka na vnímání řeči: Perceptuální asimilační model, který apeluje na mentální klasifikaci zvuků do rodných fonémových kategorií, oproti představě, že postačují bohaté, jemnozrnné fonetické reprezentace naladěné na statistiky rodného jazyka. Tuto myšlenku operujeme pomocí reprezentací ze dvou nejmodernějších modelů řeči, Gaussova směsi Dirichleta procesu a novějšího wav2vec 2.0 modelu. Představujeme nový otevřený datový soubor chování francouzsky a anglicky mluvících účastníků vnímání řeči pro 61 samohlásek ze šesti jazyků. Ukazujeme, že asimilace fonému je lepším prediktorem než jemnozrnné fonetické modelování, a to jak pro diskriminační chování jako celek, tak pro predikci rozdílů v diskriminaci spojených s rozdíly v rodném jazyce. Dále ukazujeme, že wav2vec 2.0, ačkoli není dobrý v zachycení vlivu rodného jazyka na vnímání řeči, doplňuje informace o nativní asimilaci fonémů a poskytuje dobrý model nízkoúrovňových fonetických reprezentací, podporující myšlenku, že při vnímání řeči se používají jak kategorické, tak jemnozrnné vnímání.', 'az': 'Ana dilimiz danışma seslərini gördüyümüz kimi təsirləndirir, yersiz səslərimizi təsirləndirir. Biz söhbət görünüşünün anası dilinin təsiri haqqında iki fikirləri ilə qarşılaşdırırıq: Adı dilinin statistikasına müəyyən edilmiş səslərin ruhsal klasifikasyonu yerli fonema kategoriyalarına ça ğırır. Biz bu ideyanı iki mövcud danışma modellərindən, Dirichlet prosesi Gaussian karışma modellərindən və daha yeni wav2vec 2.0 modellərindən göstərilməklə işlədirik. Biz Fransızca-İngilizce danışanların 61 səs dilindən 61 səs səsinin davranışını göstəririk. Biz telefon asimilasiyasının ən yaxşı tədbir edilən fonetik modellərindən daha yaxşı tədbir olduğunu göstəririk, hər ikisi də ayrı-ayrı davranışların hamısı üçün və yerli dil arxa planında fərqli fərqli tədbirlərin tədbir edilməsi üçün. Biz də göstəririk ki, wav2vec 2.0, söhbət görünüşünün yerli dilinin etkisini almaq üçün yaxşı deyil, yerli fonema asimilasiyası haqqında məlumatlarına uyğunlaşdırır və düşük səviyyədə fonetik göstəricilərin yaxşı modeli təklif edir, söhbət görünüşünün hər ikisinin kategorikalı və yaxşı dənəli görünüşünün istifadə edilməsini dəstəkləyir.', 'ca': "La nostra llengua materna influeix en la manera en què percebem sons de parla, afectant la nostra habilitat de discriminar sons no natius. Comparem dues idees sobre l'influència del llenguatge natiu en la percepció del discurs: el Modell d'Assimilació Perceptual, que atrau a una classificació mental de sons en categories fonèmiques natives, en comparació amb la idea que són suficients representacions fonètiques ricas i fins grains adaptades a les estadístiques del llenguatge natiu. Operacionem aquesta idea fent servir representacions de dos models de discurs més avançats, un procés Dirichlet model de mistura gaussia i el model Wav2vec 2.0 més recent. We present a new, open dataset of French- and English-speaking participants' speech perception behaviour for 61 vowel sounds from six languages.  Mostrem que l'asimilació fonèmica és un predictor millor que la modelació fonètica fina, tant per al comportament discriminatiu com per al conjunt, com per predir diferències en la discriminabilitat associada a diferències en el fons de la llengua materna. També demostram que wav2vec 2.0, tot i que no és bo en capturar els efectes del llenguatge natiu en la percepció de la fala, és complementar a la informació sobre l'assimilació del fonem natiu, i proporciona un bon model de representacions fonètiques de baix nivell, sostenint la idea que la percepció tant categórica com fina s'utilitzen durant la percepció de la fala.", 'et': 'Meie emakeel mõjutab kõnehelide tajumist, mõjutades meie võimet diskrimineerida mitte-emakeelseid helisid. Me võrdleme kahte ideed emakeele mõju kohta kõnetajumisele: tajumise assimileerimise mudel, mis kutsub üles helide vaimsele klassifitseerimisele emakeele foneemide kategooriatesse, versus idee, et emakeele statistikale häälestatud rikkalikud peeneteralised foneetilised representatsioonid on piisavad. Operatsionaliseerime seda ideed kahest kaasaegsest kõnemudelist, Dirichleti protsessi Gaussi segumudelist ja uuemast wav2vec 2.0 mudelist. Tutvustame uut avatud andmekogumit prantsuse ja inglise keelt kõnelevate osalejate kõnetajumise käitumisest 61 vokaali kohta kuuest keelest. Näitame, et foneemide assimileerimine on parem ennustaja kui peenrahaline foneetiline modelleerimine nii diskrimineerimiskäitumise kui terviku kui ka emakeele tausta erinevustega seotud diskrimineerimatuse erinevuste prognoosimisel. Samuti näitame, et wav2vec 2.0, kuigi emakeele mõju kõnetajumisele ei ole hea, täiendab see informatsiooni emakeele assimileerimise kohta ning pakub hea madala taseme foneetiliste esituste mudeli, toetades ideed, et kõnetajumisel kasutatakse nii kategoorialist kui peeneteraalist tajumist.', 'fi': 'Kotikielemme vaikuttaa siihen, miten havaitsemme puheen äänet, mikä vaikuttaa kykyymme erottaa ei-syntyperäisiä ääniä. Vertailemme kahta käsitystä äidinkielen vaikutuksesta puheentunnistukseen: Perceptual Assimilation Model, joka vetoaa äänien henkiseen luokitteluun äidinkielen foneemikategioihin, ja ajatusta siitä, että äidinkielen tilastoihin viritetyt rikkaat, hienojakoiset foneettiset esitykset riittävät. Operationalisoimme tämän ajatuksen kahden nykyaikaisen puhemallin, Dirichlet-prosessin gaussilaisen sekoitusmallin ja uudemman wav2vec 2.0 -mallin avulla. Esittelemme uuden avoimen aineiston ranskaa ja englantia puhuvien osallistujien puhekäyttäytymisestä 61 vokaaliäänelle kuudelta kieleltä. Osoitamme, että foneemien assimilaatio ennustaa paremmin kuin hienojakoinen foneettinen mallinnus, sekä syrjintäkäyttäytymisen kokonaisuutena että äidinkielen taustaeroihin liittyvien syrjimättömyyserojen ennustamisessa. Osoitamme myös, että wav2vec 2.0 ei ole hyvä kuvaamaan äidinkielen vaikutuksia puheentunnistukseen, mutta täydentää tietoa äidinkielen assimilaatiosta ja tarjoaa hyvän mallin matalatasoisista foneettisista representaatioista, mikä tukee ajatusta siitä, että puheentunnistuksessa käytetään sekä kategorista että hienojakoista havainnointia.', 'ha': "Lugha'inmu na nati'a yana yin amfani da jinin da muke fahimta sautin maganar, yana da zartar da awonmu ga ka rarrabe saurãren da ba'a sauti. Tuna samfanfani biyu game da mai fassarar harshen uwar a kan hoton: Model na Perceptural Assiminci, wanda ke ƙara wa fassarar saurãre zuwa categori na mataifa, kuma ana sami idãnun da ke da mawadãci, ma'anar matalauci, masu fassarar fanati na da fassarar littafan a cikin harshe na native, zai isa. Tuna aiki wannan idãnar da ke amfani da misãlai biyu na-state-the-art-art, wata shirin jarrabo na gaussian haɗi da Gaussian da misalin wav2vc 2.0 na ƙarshen a shekara. Tuna halatar da wani danna na'urar magana na fassarar Faransa da Ingiriya masu buɗe wa saurãren saurãre na 61 cikin lugha 6. Tuna nũna cewa, surikancin filin na fi zama mafi alhẽri daga mai bashiri da misãli mai kyau na sami-sami, duk zuwa ga aikin yin takanci duka ɗaya, kuma dõmin ka yi bayani ga sãɓãni masu haɗi da sãɓãni masu cikin bakin harshen native. Tuna nũna wa wav2vc 2.0, kuma amma bã da da alhẽri a sami fanfani ga fassarar harshen uwar kan magana, yana da kamfata zuwa ma'anar mutane na mutane, kuma yana bãyar da wani misali mai kyau ga masu tsari da sauri-daraja, kuma yana ƙarfafa idãnun da za'a yi amfani da shi ga fassarar da na fassarar magana.", 'sk': 'Naš materni jezik vpliva na način zaznavanja govornih zvokov in vpliva na našo sposobnost diskriminacije tujih zvokov. Primerjamo dve zamisli o vplivu maternega jezika na zaznavanje govora: model perceptualne asimilacije, ki privlači k duševni klasifikaciji zvokov v kategorije maternega fonema, in idejo, da zadostujejo bogate, drobnozrnate fonetične reprezentacije, prilagojene statistiki maternega jezika. To idejo operacionalizaliziramo s pomočjo reprezentacij iz dveh najsodobnejših govornih modelov, gaussijskega mešanega modela Dirichlet procesa in novejšega modela wav2vec 2.0. Predstavljamo nov, odprt nabor podatkov o zaznavanju govora francosko in angleško govorečih udeležencev za 61 samoglasnikov iz šestih jezikov. Pokazali smo, da je asimilacija fonema boljši napovedovalec kot drobnozrnato fonetično modeliranje, tako za diskriminacijsko vedenje kot celoto kot za napovedovanje razlik v diskriminaciji, povezanih z razlikami v maternem jeziku. Pokazali smo tudi, da wav2vec 2.0, čeprav ni dober pri zajemanju učinkov maternega jezika na zaznavanje govora, dopolnjuje informacije o asimilaciji domačega fonema in zagotavlja dober model fonetičnih reprezentacij nizke ravni, kar podpira idejo, da se med zaznavanjem govora uporabljata tako kategorična kot drobnozrnata percepcija.', 'he': 'השפה הילדית שלנו משפיעה על הדרך בה אנו רואים את קולות הנאום, משפיעה על היכולת שלנו להבדיל קולות לא הילדים. אנו משוותים שני רעיונות על השפעה של השפה הילדית על תפיסת הנאום: מודל ההדמיון ההדמיוני, אשר מתייחס לסטטיסטיקה נפשית של צלילים לקטגוריות פונומות הילדיות, בניגוד לרעיון שהמייצגות פונטיות עשירות ומצטיינות מתאימות לסטטיסטיקה של השפה הילדית, מספיקות. We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model.  אנחנו מציגים קבוצת נתונים חדשה פתוחה של התנהגות של השתתפים בשפה צרפתית ואנגלית לתפיסה הנאום של 61 קולות קולות משש שפות. אנו מראים שהאסימילציה טלפונית היא חזייה טובה יותר מאשר דוגמנית פונטית מעולה, גם עבור התנהגות הבחינה בכלל, וגם עבור צפוי ההבדלים בין ההבדלים הקשורות להבדלים ברקע השפה האדומה. We also show that wav2vec 2.0, while not good at capturing the effects of native language on speech perception, is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during speech perception.', 'bo': 'ང་ཚོའི་སྐད་ཡིག་ཆ་ནི་ང་ཚོའི་ཁ་བརྗོད་ཀྱི་སྒྲ་ཚིགས་ཀྱི་ལམ་ལུགས་དང་། ང་ཚོའི་མཐུན་རྐྱེན་མིན་པའི་སྒྲ་ཚིགས་གསལ ང་ཚོས་སྐད་ཡིག་གཟུགས་དང་འབྲེལ་བའི་ནང་དུ་གླེང་སྒྲུང་གི་མིང་ཚོའི་དབྱེ་བ་གཉིས་དང་བསྟུན་ནས། We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. ང་ཚོས་སྐད་རིགས་ཀྱི་འགྱུར་བ་དང་། ཕྱིར་ཡིག་དང་ཨིན་རིའི་ནང་དུ་འགྲེལ་བཤད་པའི་སྐྱེས་ཆ་གསར་པ་ཞིག་སྟོན་ཡོད། ང་ཚོས་དྲ་རྒྱ་ལ་རྒྱབ་སྐྱོར་བ་དང་ཅུང་ཁག་ཅིག་གི་སྔོན་འཛིན་ཐབས་རྩིས་མེད་པའི་ཐབས་ལམ་ལ་དང་། ཕྱོགས་འགྱུར་བ་སྐྱེས་པའི་བྱ་ཚུལ་གང་བར་བྱེད་པར་དང་། ས ང་ཚོས་ཀྱང་wav2vec 2.0་དེ་ལྟ་བུ་འཇུག་སྐད་ཡིག་གི་འཚོལ་ཁག་ཅིག་ཡོད་མིན་པའི་སྐད་ཡིག་གི་འཚོལ་ཞིབ་བསྟར་ན།', 'jv': 'Awak dhéwé ning langkung wiharé mengko ana ing tindang awak dhéwé Awak dhéwé nggawe ide sing duwé banjuré nggawe langkung urip ning langgar luwih: modèl Percepual Assimition, sing ngedhalan kelas kuwi nggawe gerakan kelas mentegal sing katéwan karo kategori penyane, lan uwis aké budhakan langgar, akeh barêng-barêng, winih-barêng langgar banjuré nggawe gerakan cenas ning awak dhéwé. We operationaliza this idée usang representations from 2 state-of-the-arts language model, a dir ihlete program Goss Mixure model and the last recent WA2vec 2.0 model. Awak dhéwé éntukno nggawe sistem sing bagian, bukir dataset kapulungan karo Perancis- lan basa-ingkang barang kanggo ngerasakno perkaraan kanggo teka-teka sing larang kanggo sesuk urip. Awak dhéwé éntuk aksiléné telegram sing luwih apik dhéwé ning model Fontetik sing luwih apik, gambar dhéwé nggawe gerakan dhéwé, lan nglanggar kalaayuni barêng langa sing bakal terus petani sing paling dhéwé. Awak dhéwé éntuk wong ke wa2vec 2.0, sampeyan ora luwih apik nêmêr sing apik dhéwé kuwi kesempatan nggawe kesempatan, kelompoler kanggo informasi babagan kelompok teléké, lan akeh iso nggawe model sing apik dhéwé, ndêmêr susahé supaya iki bakal kelompok, akeh iso nggawe gerakêr suarané diuwisan pangan kelompok.'}
