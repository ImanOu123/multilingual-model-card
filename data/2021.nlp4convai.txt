{'en': 'Not So Fast, Classifier   Accuracy and Entropy Reduction in Incremental Intent Classification', 'ar': 'ليس سريعًا جدًا ، مصنف - الدقة وخفض الانتروبيا في تصنيف النوايا المتزايد', 'es': 'Clasificador no tan rápido: precisión y reducción de entropía en la clasificación de intención incremental', 'fr': "Pas si rapide, classificateur — Précision et réduction de l'entropie dans la classification incrémentielle d'intention", 'pt': 'Não Tão Rápido, Classificador - Precisão e Redução de Entropia na Classificação Incremental de Intenção', 'ja': '高速ではない、分類子–増分インテント分類の精度とエントロピー低減', 'zh': '不然,分类器 – 增量意类之准确性熵减也', 'hi': 'इतना तेज़ नहीं, क्लासिफायर - वृद्धिशील आशय वर्गीकरण में सटीकता और एन्ट्रॉपी में कमी', 'ru': 'Не так быстро, классификатор – точность и снижение энтропии в инкрементной классификации намерений', 'ga': 'Níl sé chomh gasta sin, aicmitheoir – Cruinneas agus Laghdú Eantrópachta in Aicmiú Incriminteach Intinn', 'hu': 'Nem olyan gyors, Classifier - Pontosság és entrópia csökkentés az inkrementális szándék osztályozásában', 'el': 'Όχι τόσο γρήγορη, ταξινομητής-μείωση ακρίβειας και Entropie στη βαθμιαία ταξινόμηση προθέσεων', 'it': "Non così veloce, Classificatore - Accuratezza e riduzione dell'entropia nella classificazione degli intenti incrementali", 'lt': 'Ne taip greitai, klasifikatorius – tikslumo ir entropijos mažinimas didėjančioje ketinimo klasifikacijoje', 'kk': 'Бірақ жылдам емес, классификатор - Тәуелсіздік және ентропиялық көбейту үшін көбейту үшін', 'mk': 'Не толку брзо, класификатор - намалување на точноста и ентропијата во екстременталната класификација', 'ms': 'Not So Fast, Classifier - Accuracy and Entropy Reduction in Incremental Intent Classification', 'ml': 'വേഗത്തില്\u200d അല്ല, ക്ലാസിക്കേഴ്സിയര്\u200d - കൂടുതല്\u200d ക്ലാസ്റ്റോപ്പി കുറച്ചു', 'mt': 'Mhux daqshekk mgħaġġel, Klassifikatur - Tnaqqis fl-eżattezza u l-entropija fil-Klassifikazzjoni tal-Intent Akkumentali', 'pl': 'Nie tak szybko, klasyfikator – Dokładność i redukcja entropii w klasyfikacji intencji przyrostowych', 'ro': 'Nu atât de rapid, Clasificator - Precizia și reducerea entropiei în clasificarea intenției incrementale', 'sr': 'Ne tako brzo, klasifikator - preciznost i smanjenje entropije u povećanoj intenzivnoj klasifikaciji', 'si': 'එච්චර වේගයෙන් නෙවෙයි, ක්ලාසිෆායිර් - හරියට සහ ප්\u200dරවේගය අඩු වෙන්න', 'no': 'Ikkje så rask, klassifiserer – nøyaktighet og oppskriftsreduksjon i økt intens klassifikasjon', 'sv': 'Inte så snabbt, Classifier - Noggrannhet och entropireduktion i inkrementell Intent Klassificering', 'so': 'Si dhaqso ah, fasixiyaha - Heshiiska iyo kirada ee fasaxa kordhinta', 'ta': 'வேகமாக இல்லை, வகைப்படுத்தி - சரியான மற்றும் உள்ளடக்கமான வகைப்பில் குறை', 'ka': 'ნვ რჲლკჲგა ბყპჱჲ.', 'ur': 'اس سے سریع نہیں، کلاسفار - دقیق اور انٹروپی کمزور', 'mn': 'Ийм хурдан биш, классификатор', 'vi': "Không quá nhanh, mô tả phân loại'chính xác và giảm ảnh dẫn trong tính chất phức tạp", 'uz': 'Comment', 'da': 'Ikke så hurtigt, Classifier - Nøjagtighed og entropi reduktion i inkrementel intent klassificering', 'bg': 'Не толкова бързо, класификатор - точност и намаляване на ентропията в степенната класификация', 'nl': 'Niet zo snel, Classifier-Nauwkeurigheid en Entropie Vermindering in Incrementale Intent Classificatie', 'id': 'Tidak begitu cepat, Klasifikator - Ketepatan dan Penurangan Entropi dalam Klasifikasi Intent Incremental', 'fa': 'نه اینقدر سریع، کلاس\u200cگر - دقیق و کاهش انتروپی در کلاس\u200cشناسی هوشمندانه\u200cی افزایش', 'ko': '그렇게 빠르지 않아, 분류기-증량의도분류에서의 정확도와 엔트로피 감소', 'de': 'Nicht so schnell, Classifier-Genauigkeit und Entropie Reduktion in Inkremental Intent Classification', 'af': 'Nie So Vinnig, Klassifikasie - Naakkuraat en Entropie Reduksie in Inkremental Intent Klassifikasie', 'sw': 'Sio kwa haraka sana, Msalama - Upunguzo na Upunguzo wa Ujadala wa Intaneti', 'tr': 'Bu şekilde hızlı değil, Klassifikatör', 'sq': 'Jo kaq shpejt, klasifikues - Shkurtimi i saktësisë dhe entropisë në klasifikimin me qëllim në rritje', 'hy': 'Ոչ այնքան արագ, դասակարգչային. ճշգրտությունը և էնտրոպիայի կրճատմանը', 'am': 'በቶሎ አይደለም፥ ክላሲያር - በአስቸጋሪ ማቀናጃ እና የግል ማቀናቀል ውስጥ', 'az': 'Bu q톛d톛r h캼zl캼 deyil, Klasifikat - Q캼ymet v톛 Entropy Reduction in Incremental Intent Classification', 'bn': 'এত দ্রুত নয়, ক্লাসিকার- বাড়াবাড়ি বিভিন্ন সংক্রান্ত গ্রাহক', 'bs': 'Ne tako brzo, klasifikator - preciznost i smanjenje entropije u povećanoj intenzivnoj klasifikaciji', 'et': 'Mitte nii kiire, klassifikaator - täpsus ja entroopia vähendamine incrementaalse kavatsuse klassifikatsioonis', 'ca': "No tan ràpid, classificador - Reducció d'exactitud i entropia en la classificació de intenció incremental", 'cs': 'Není tak rychlé, klasifikátor – Snížení přesnosti a entropie v inkrementální klasifikaci záměru', 'fi': 'Ei niin nopea, Luokitus - Tarkkuus ja Entropia Vähennys Incremental Intent Luokitus', 'hr': 'Ne tako brzo, klasifikator - preciznost i smanjenje entropije u povećanoj intenzivnoj klasifikaciji', 'he': 'לא כל כך מהר, מסווג - מדויקת ואנטרופיה קטנה בסווג בכוונה גבוהה', 'sk': 'Ni tako hitro, razvrstitev - natančnost in zmanjšanje entropije pri stopnjevalni razvrstitvi namena', 'jv': 'Ora iku, kelas', 'bo': 'དེ་མིན་ན་མགྱོག་མེད། རྩིས་འབྲི་མིན་པར། དྲང་འབོར་དང་ཐོག་འཕྲུལ་རིམ་སྒྲིག་འགོད་ལ་ཉར་གཏོང', 'ha': '@ action: button'}
{'en': 'Incremental intent classification requires the assignment of intent labels to partial utterances. However, partial utterances do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence). Using the final interpretation as the ground truth to measure a ', 'fr': "La classification incrémentielle d'intention nécessite l'affectation d'étiquettes d'intention aux énoncés partiels. Cependant, les énoncés partiels ne contiennent pas nécessairement suffisamment d'informations pour être mappés à la classe d'intention de leur énoncé complet (correctement et avec un certain degré de confiance). L'utilisation de l'interprétation finale comme vérité de base pour mesurer la précision d'un classificateur lors de la classification par intention d'énoncés partiels est donc problématique. Nous publions InClic, un ensemble de données d'énoncés partiels et complets avec des annotations humaines d'étiquettes d'intention plausible pour différentes parties de chaque énoncé, comme base supérieure (humaine) pour la classification incrémentielle des intentions. Nous analysons les annotations incrémentielles et proposons la réduction de l'entropie comme mesure de la convergence des annoteurs humains sur une interprétation (c'est-à-dire une étiquette d'intention). Nous soutenons que, lorsque les annotateurs ne convergent pas vers une ou plusieurs interprétations possibles et que le classificateur identifie déjà très tôt la classe d'intention finale, c'est un signe de sur-ajustement qui peut être attribué aux artefacts de l'ensemble de données.", 'ar': 'يتطلب تصنيف النية المتزايد تخصيص تسميات النية للألفاظ الجزئية. ومع ذلك ، فإن الكلام الجزئي لا يحتوي بالضرورة على معلومات كافية ليتم ربطها بفئة النية في نطقها الكامل (بشكل صحيح وبدرجة معينة من الثقة). ومن ثم فإن استخدام التفسير النهائي كحقيقة أساسية لقياس دقة المصنف أثناء تصنيف النية للألفاظ الجزئية يمثل مشكلة. أصدرنا inCLINC ، وهي مجموعة بيانات من الكلام الجزئي والكامل مع التعليقات التوضيحية البشرية لتسميات النية المعقولة لأجزاء مختلفة من كل كلام ، كخط أساس علوي (بشري) لتصنيف النية المتزايد. نحن نحلل التعليقات التوضيحية الإضافية ونقترح تقليل الانتروبيا كمقياس لتقارب المعلقين على تفسير ما (أي تسمية النية). نجادل أنه عندما لا تتقارب الحواشي مع تفسير واحد أو عدة تفسيرات محتملة ومع ذلك فإن المصنف يحدد بالفعل فئة النية النهائية في وقت مبكر ، فهذه علامة على التجهيز الزائد الذي يمكن أن يُعزى إلى المصنوعات اليدوية في مجموعة البيانات.', 'es': 'La clasificación de intención incremental requiere la asignación de etiquetas de intención a enunciados parciales. Sin embargo, los enunciados parciales no contienen necesariamente suficiente información para ser mapeados a la clase de intención de su enunciado completo (correctamente y con cierto grado de confianza). Por lo tanto, es problemático utilizar la interpretación final como la verdad fundamental para medir la precisión de un clasificador durante la clasificación por intención de enunciados parciales. Publicamos Clinc, un conjunto de datos de enunciados parciales y completos con anotaciones humanas de etiquetas de intención plausibles para diferentes partes de cada enunciado, como una línea de base superior (humana) para la clasificación incremental de intenciones. Analizamos las anotaciones incrementales y proponemos la reducción de la entropía como una medida de la convergencia de los anotadores humanos en una interpretación (es decir, etiqueta de intención). Argumentamos que, cuando los anotadores no convergen en una o unas pocas interpretaciones posibles y, sin embargo, el clasificador ya identifica la clase de intención final desde el principio, es una señal de sobreajuste que se puede atribuir a los artefactos en el conjunto de datos.', 'pt': 'A classificação de intenção incremental requer a atribuição de rótulos de intenção a enunciados parciais. No entanto, enunciados parciais não contêm necessariamente informações suficientes para serem mapeados para a classe de intenção de seu enunciado completo (corretamente e com certo grau de confiança). Usar a interpretação final como a verdade básica para medir a precisão de um classificador durante a classificação de intenção de enunciados parciais é, portanto, problemático. Lançamos o inCLINC, um conjunto de dados de enunciados parciais e completos com anotações humanas de rótulos de intenção plausíveis para diferentes partes de cada enunciado, como uma linha de base superior (humana) para classificação de intenção incremental. Analisamos as anotações incrementais e propomos a redução de entropia como medida da convergência dos anotadores humanos em uma interpretação (ou seja, rótulo de intenção). Argumentamos que, quando os anotadores não convergem para uma ou algumas interpretações possíveis e ainda assim o classificador já identifica a classe de intenção final logo no início, é um sinal de overfitting que pode ser atribuído a artefatos no conjunto de dados.', 'ja': 'インクリメンタルインテント分類では、インテントラベルを部分発話に割り当てる必要があります。 しかし、部分発話は必ずしも完全な発話の意図クラスにマッピングされるのに十分な情報を含んでいるとは限らない（正しく、ある程度の信頼性を持って）。 したがって、部分発話の意図分類中の分類子の精度を測定するために、最終的な解釈を基礎真理として使用することは問題である。 私たちは、インクリメンタルインテント分類のための上位（ヒト）ベースラインとして、各発話の異なる部分についての妥当なインテントラベルのヒューマンアノテーションを含む部分的および完全なインテントのデータセットinCLINCをリリースします。 私たちは、増分注釈を分析し、解釈上の人間の注釈者の収束（つまり、意図ラベル）の尺度としてエントロピー低減を提案します。 私たちは、注釈者が1つまたはいくつかの可能な解釈に収束せず、分類子が既に早期に最終的な意図クラスを識別している場合、それはデータセットのアーティファクトに帰属させることができるオーバーフィッティングの兆候であると主張しています。', 'zh': '增量意向分类求标分语。 然语不必足以射全语之意(正而有置信度)。 故意分类者,用终说以为本,量分类器者准确性有以也。 吾发 inCLINC,此一含全语之数集也,其含辞异理者注之,以为增量意之上限(人)基线。 臣等论增量注释,并立熵减为人解释者(即意标)趋同之衡量也。 臣愚以为,当注释器不收于一说,而类器已识其终类时,此过拟合之迹,可归因于数集之人工制品。', 'hi': 'वृद्धिशील आशय वर्गीकरण के लिए आंशिक उच्चारण के लिए आशय लेबल के असाइनमेंट की आवश्यकता होती है। हालांकि, आंशिक कथनों में आवश्यक रूप से पर्याप्त जानकारी नहीं होती है जिसे उनके पूर्ण उच्चारण के इरादे वर्ग में मैप किया जा सकता है (सही ढंग से और आत्मविश्वास की एक निश्चित डिग्री के साथ)। आंशिक उच्चारण के इरादे वर्गीकरण के दौरान एक क्लासिफायर की सटीकता को मापने के लिए जमीनी सच्चाई के रूप में अंतिम व्याख्या का उपयोग करना इस प्रकार समस्याग्रस्त है। हम INCLINC जारी करते हैं, प्रत्येक कथन के विभिन्न भागों के लिए प्रशंसनीय इरादे लेबल के मानव एनोटेशन के साथ आंशिक और पूर्ण कथनों का एक डेटासेट, वृद्धिशील इरादे वर्गीकरण के लिए एक ऊपरी (मानव) बेसलाइन के रूप में। हम वृद्धिशील एनोटेशन का विश्लेषण करते हैं और एक व्याख्या (यानी इरादा लेबल) पर मानव एनोटेटर्स के अभिसरण के उपाय के रूप में एन्ट्रॉपी में कमी का प्रस्ताव करते हैं। हम तर्क देते हैं कि, जब एनोटेटर एक या कुछ संभावित व्याख्याओं के लिए अभिसरण नहीं करते हैं और फिर भी क्लासिफायर पहले से ही अंतिम आशय वर्ग की पहचान करता है, तो यह ओवरफिटिंग का संकेत है जिसे डेटासेट में कलाकृतियों के लिए जिम्मेदार ठहराया जा सकता है।', 'ru': 'Классификация дополнительных намерений требует присвоения меток намерений частичным высказываниям. Однако частичные высказывания не обязательно содержат достаточно информации, чтобы быть сопоставленными с классом намерения их полного высказывания (правильно и с определенной степенью уверенности). Таким образом, использование окончательного толкования в качестве основной истины для измерения точности классификатора при намеренной классификации частичных высказываний является проблематичным. Мы выпускаем в CLINC набор данных частичных и полных высказываний с человеческими аннотациями правдоподобных меток намерения для различных частей каждого высказывания в качестве верхней (человеческой) базовой линии для инкрементальной классификации намерения. Мы анализируем инкрементные аннотации и предлагаем снижение энтропии как меру конвергенции человеческих аннотаторов на интерпретации (т.е. метку намерения). Мы утверждаем, что, когда аннотаторы не сходятся с одной или несколькими возможными интерпретациями, и все же классификатор уже определяет окончательный класс намерения на ранней стадии, это является признаком переобучения, которое может быть приписано артефактам в наборе данных.', 'ga': 'Éilíonn aicmiú incriminteach intinne go sannfar lipéid intinne do chainteanna páirteacha. Ní gá, áfach, go mbíonn go leor eolais i bpáirtráite chun iad a mhapáil de réir na haicme rún faoina gcuid cainte iomlán (i gceart agus le leibhéal áirithe muiníne). Is fadhb mar sin é an léirmhíniú deiridh a úsáid mar bhunfhírinne chun cruinneas an aicmitheora a thomhas le linn rún a aicmiú ar chainteanna páirteacha. Eisímid inCLINC, tacar sonraí de chainteanna iomlána agus pháirteacha le nótaí daonna de lipéid intinne sochreidte do chodanna éagsúla de gach focal, mar bhunlíne uachtarach (daonna) le haghaidh aicmiú rún incriminteach. Déanaimid anailís ar na nótaí incriminteacha agus molaimid laghdú eantrópachta mar thomhas ar chóineasú anótálaithe daonna ar léirmhíniú (i.e. lipéad intinne). Áitímid, nuair nach dtagann na nótaíadóirí le chéile le léirmhíniú féideartha amháin nó le cúpla léirmhíniú féideartha agus go n-aithníonn an t-aicmitheoir an rang intinne deiridh go luath cheana féin, gur comhartha rófheistithe é is féidir a chur i leith na ndéantúsáin sa tacar sonraí.', 'hu': 'Az inkrementális szándék besorolása szükségessé teszi a szándék címkék részleges kimondásokhoz való hozzárendelését. A részleges kimondások azonban nem feltétlenül tartalmaznak elegendő információt ahhoz, hogy teljes kimondásuk szándékos osztályához legyenek feltérképezve (helyesen és bizonyos fokú bizalommal). A végső értelmezés alapvető igazságként történő felhasználása tehát problémát jelent az osztályozó pontosságának mérésére a részleges kimondások szándékos besorolása során. Az inCLINC egy részleges és teljes kifejezésekből álló adatkészletet bocsátunk rendelkezésre, amelynek emberi megjegyzései valószínűsíthető szándékcímkéket tartalmaznak az egyes kifejezések különböző részeihez, mint felső (emberi) alapkészlet az inkrementális szándékcsoportosításhoz. Elemezzük az inkrementális megjegyzéseket és javasoljuk az entrópia csökkentését, mint az emberi megjegyzések konvergenciájának mérését egy értelmezéssel (azaz szándék címkével). Azt állítjuk, hogy amikor a kommentátorok nem konvergálnak egy vagy néhány lehetséges értelmezéshez, és mégis az osztályozó már korán azonosítja a végső szándékosztályt, az a túlterhelés jele, amely az adatkészletben található tárgyaknak tulajdonítható.', 'el': 'Η βαθμιαία ταξινόμηση προθέσεων απαιτεί την εκχώρηση ετικετών προθέσεων σε μερικές εκφράσεις. Ωστόσο, μερικές εκφράσεις δεν περιέχουν απαραίτητα αρκετές πληροφορίες για να αντιστοιχιστούν στην κατηγορία προθέσεων της πλήρους τους έκφρασης (σωστά και με κάποιο βαθμό εμπιστοσύνης). Η χρήση της τελικής ερμηνείας ως βασικής αλήθειας για τη μέτρηση της ακρίβειας ενός ταξινομητή κατά την ταξινόμηση προθέσεων μερικών εκφράσεων είναι επομένως προβληματική. Απελευθερώνουμε ένα σύνολο δεδομένων μερικών και πλήρους εκφρασμάτων με ανθρώπινες σχολιάσεις εύλογων ετικετών προθέσεων για διαφορετικά τμήματα κάθε εκφρασμού, ως ανώτερη (ανθρώπινη) βάση για την βαθμιαία ταξινόμηση προθέσεων. Αναλύουμε τις αυξανόμενες σημειώσεις και προτείνουμε τη μείωση της εντροπίας ως μέτρο σύγκλισης των ανθρώπινων σχολιαστών σε μια ερμηνεία (δηλ. ετικέτα πρόθεσης). Υποστηρίζουμε ότι, όταν οι σχολιαστές δεν συγκλίνουν σε μία ή μερικές πιθανές ερμηνείες και όμως ο ταξινομητής προσδιορίζει ήδη την τελική τάξη πρόθεσης νωρίς, είναι ένα σημάδι υπερπροσαρμογής που μπορεί να αποδοθεί σε αντικείμενα στο σύνολο δεδομένων.', 'it': "La classificazione incrementale degli intenti richiede l'assegnazione di etichette di intenti a dichiarazioni parziali. Tuttavia, le dichiarazioni parziali non contengono necessariamente informazioni sufficienti per essere mappate alla classe di intenti della loro pronuncia completa (correttamente e con un certo grado di fiducia). Usare l'interpretazione finale come verità di base per misurare l'accuratezza di un classificatore durante la classificazione intenzionale di dichiarazioni parziali è quindi problematico. Rilasciamo inCLINC, un set di dati di dichiarazioni parziali e complete con annotazioni umane di etichette di intenti plausibili per diverse porzioni di ogni pronuncia, come base di riferimento superiore (umana) per la classificazione incrementale degli intenti. Analizziamo le annotazioni incrementali e proponiamo la riduzione dell'entropia come misura della convergenza degli annotatori umani su un'interpretazione (cioè l'etichetta intent). Noi sosteniamo che, quando gli annotatori non convergono ad una o poche possibili interpretazioni e tuttavia il classificatore identifica già in anticipo la classe di intenti finale, è un segno di overfitting che può essere attribuito agli artefatti del dataset.", 'lt': 'Didesnio ketinimo klasifikavimas reikalauja, kad ketinimo etiketės būtų priskiriamos daliniams žodžiams. Vis dėlto daliniame išraiške nebūtinai pateikiama pakankamai informacijos, kad būtų galima nurodyti tikslinę jų visiško išraiško klasę (teisingai ir tam tikru pasitikėjimu). Taigi galutinio aiškinimo kaip pagrindo tiesos naudojimas klasifikatoriaus tikslumui vertinti ketinant klasifikuoti dalinius žodžius yra problemiškas. Mes išleidžiame inCLINC, dalinių ir visiškų išraiškų duomenų rinkinį su žmogaus anotacijomis tikėtinų ketinimų etiketėmis skirtingoms kiekvieno išraiško dalims, kaip viršutinę (žmogaus) pradinę vertę palaipsniui ketinimų klasifikacijai. Analizuojame papildomas anotacijas ir siūlome sumažinti entropiją kaip žmogaus anotatorių konvergencijos dėl a i škinimo (t. y. ketinimo etiketės) matavimą. We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.', 'mk': 'Класификацијата на зголемената намера бара додавање на ознаки на намера на делумни изрази. Сепак, делумните изрази не неопходно содржат доволно информации за да бидат мапирани до намерната класа на нивниот целосен израз (точно и со одреден степен на доверба). Користењето на конечната интерпретација како основна вистина за мерење на точноста на класификаторот за време на намерната класификација на делумни изрази е, така, проблематично. Ние објавуваме inCLINC, податок на делумни и целосни изрази со човечки анотации на веројатни намери етикети за различни делови од секој израз, како врвна (човечка) основа за екстрементална класификација на намери. Ние ги анализираме екстременталните анотации и предложуваме намалување на ентропијата како мерка на конвергенцијата на човечките анотатори за интерпретација (т.е. намерна етикета). Ние тврдиме дека, кога анотаторите не се приближуваат до една или неколку можни интерпретации, а сепак класификаторот веќе ја идентификува финалната класа на намера на почетокот, тоа е знак на премногу приспособување што може да се припишува на артефакти во податоците.', 'ms': 'Incremental intent classification requires the assignment of intent labels to partial utterances.  Namun, ucapan sebahagian tidak perlu mengandungi maklumat yang cukup untuk dipetakan ke kelas niat ucapan lengkap mereka (dengan betul dan dengan tingkat tertentu kepercayaan). Menggunakan interpretasi terakhir sebagai kebenaran tanah untuk mengukur ketepatan pengklasifikasi semasa klasifikasi niat ucapan sebahagian adalah sebagaimana masalah. Kami melepaskan inCLINC, set data dari ucapan sebahagian dan penuh dengan anotasi manusia dari label niat yang mudah untuk bahagian yang berbeza dari setiap ucapan, sebagai dasar atas (manusia) untuk kelasukan niat tambahan. Kami menganalisis anotasi tambahan dan mencadangkan pengurangan entropi sebagai ukuran konvergensi annotator manusia pada interpretasi (iaitu label niat). Kami menyangka bahawa, apabila penganotator tidak berkumpul kepada satu atau beberapa interpretasi yang mungkin dan namun pengklasifikasi telah mengenali kelas tujuan akhir awal, ia adalah tanda overfitting yang boleh ditakrif kepada artefakta dalam set data.', 'ml': 'Incremental intent classification requires the assignment of intent labels to partial utterances.  എന്നാലും പകുതിയ വാക്കുകള്\u200d അവരുടെ പൂര്\u200dണ്ണമായ വാക്കുകളുടെ ലക്ഷ്യം ക്ലാസിലേക്ക് മാപ്പ് ചെയ്യാന്\u200d മതിയായ വിവരങ്ങള്\u200d ലഭ്യമായിട്ടി ഭാഗവാക്കുകളുടെ വിശദീകരണത്തിനുള്ള സമയത്ത് ക്ലാസ്ഫിക്കേഷറിന്\u200dറെ സത്യം അളന്നുകൊടുക്കാന്\u200d അവസാന വ്യാഖ്യാനം ഉപയോ എല്ലാ വാക്കിന്റെയും വ്യത്യസ്ത ഭാഗങ്ങള്\u200dക്കും വേണ്ടിയുള്ള മനുഷ്യരുടെ ലക്ഷ്യങ്ങളുള്ള പ്രസ്താനങ്ങളുടെ ഒരു ഡാറ്റാസേറ്റ് നമ്മള്\u200d ഇന്\u200dസിലിന്\u200dസിയെ വിട നമ്മള്\u200d വിശദീകരിക്കുന്ന അഭിപ്രായങ്ങള്\u200d അന്വേഷിക്കുകയും, മനുഷ്യരുടെ വ്യാഖ്യാനത്തിന്\u200dറെ സംസാരത്തിന്\u200dറെ ഒരു അളവാക്കായി എന്\u200dട നമ്മള്\u200d വാദിക്കുന്നു, അഭിപ്രായക്കാര്\u200d ഒരോ സാധ്യതയോ വ്യാഖ്യാനിക്കാതിരിക്കുമ്പോഴും ക്ലാസ്ഫിക്കര്\u200d ഇപ്പോള്\u200d തിരിച്ചറിയുന്നുണ്ടെങ്കില്\u200d ഡാറ', 'mt': "Il-klassifikazzjoni tal-intenzjoni inkrementali teħtieġ l-assenjazzjoni ta’ tikketti tal-intenzjoni għal dikjarazzjonijiet parzjali. Madankollu, l-istqarrijiet parzjali ma fihomx neċessarjament biżżejjed informazzjoni biex jiġu mmappjati għall-klassi tal-intenzjoni tal-istqarrija sħiħa tagħhom (b’mod korrett u b’ċertu grad ta’ kunfidenza). Għalhekk huwa problematiku li tintuża l-interpretazzjoni finali bħala l-verità tal-bażi biex titkejjel il-preċiżjoni tal-klassifikatur matul il-klassifikazzjoni bl-intenzjoni ta’ dikjarazzjonijiet parzjali. Aħna nirrilaxxaw inCLINC, sett ta’ dejta ta’ dikjarazzjonijiet parzjali u sħa ħ b’annotazzjonijiet umani ta’ tikketti ta’ intenzjoni plawżibbli għal porzjonijiet differenti ta’ kull dikjarazzjoni, bħala linja bażi ta’ fuq (umana) għall-klassifikazzjoni inkrementali ta’ intenzjoni. We analyse the incremental annotations and propose entropy reduction as a measure of human annotators' convergence on an interpretation (i.e. intent label).  We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.", 'ka': 'კლასიფიკაცია კონქრემენტური მისამართი უნდა მისამართო ნიშანების დააყენება ფართო სიტყვებისთვის. მაგრამ განსაკუთრებული სიტყვები არ უნდა შეიყვარს მსგავსი ინფორმაცია, რომელიც უნდა იყოს საკუთრებო კლასში (მართლად და განსაკუთრებო დარწმუნება). გამოყენება საკუთარი სიტყვების კლასიფიკაცია, როგორც სამყარო სიტყვების მართლად კლასიფიკაცია კლასიფიკაცია, პრობლემატიურია. ჩვენ inCLINC-ს გახსნა, სამუშაო და ფრთხოვნილი სიტყვების მონაცემები, რომელიც ადამიანის ამოცემების ამოცემებების განსხვავებული საზოგადოება, ყოველ სიტყვების განსხვავებული ნაწილებისთვის, როგ ჩვენ ანალიზებთ ინტერპემენტიური ანოტაციები და მინდომარებით ენტროპიის შემცირება, როგორც ადამიანის ანოტატორის კონგერგენციის შემცირებით ინტერპექციის შემცირებით ჩვენ ვთქვათ, რომ, როდესაც ანტოტორიები ერთი ან რამდენიმე შესაძლებელი ინტერპუქციებისთვის არ შემდეგ შემდეგ შემდეგ შემდეგ კლასიფიკაციელი უკვე განვიცნობს საკუთარი საზოგადო კლასის საწყისი წინ დავიწყება,', 'mn': 'Ихэнх зорилготой хуваалцах нь нэг хэсэг хэлэлцээнд зорилготой маркилгуудыг тайлбарлах шаардлагатай. Гэхдээ хэсэг хэлэлцээний хэлэлцээнд тэдний бүхэл хэлэлцээний зорилгоор газрын зурагт хангалттай мэдээллийг агуулах хэрэггүй (зөв, итгэл үнэмшилтэй). Эцсийн тодорхойлолтыг хэмжээний үнэнийг хэмжээний тулд хуваалцагчийн зөв байдлыг хэмжээний тулд хэмжээний тодорхойлолтыг ашиглах нь энэ нь асуудал юм. Бид инКЛИНК-г, хүн төрөлхтний хэсэг бүрт өөр хэсэг бүрт итгэлтэй зорилготой, бүрэн хэлэлцүүлэх өгөгдлийн сангуудыг нэмэгдүүлдэг. Бид нэмэлт сэтгэл хөдлөлүүдийг шинжилж, энтропийн багасгалыг хүн төрөлхтний тэмдэглэгчдийн тухай хэмжээний хэмжээнд (яг л зорилготой тэмдэглэл). Бид хэлэхдээ анзаарагчид нэг эсвэл хэд хэдэн тодорхойлолтоор холбогдохгүй гэдгийг хэлж байна. Гэхдээ анхны анзаарагчид хамгийн сүүлийн зорилго анзаарлыг эхлээд танилцуулж байгаа юм бол өгөгдлийн сангийн артефактууд дээр бичиж болно.', 'kk': 'Кеңейтілген мақсатты классификациясы бөлек сөздерге мақсатты жарлықтарды таңдау керек. Бірақ бөлшекті сөйлемелерінде толық сөйлемелер класына (дұрыс және бір сенімдік деңгейінде) карталау үшін жеткілікті мәлімет жоқ. Соңғы түсініктемесін түсіндіру үшін классификациясының дұрыстығын өлшеу үшін, бөлек сөздерді шектеу кезінде, бұл мәселе болады. Біз inCLINC, адамдардың түрлі бөліктері үшін көптеген және толық сөйлемелердің деректер жиынын ашып, әрбір сөйлеменің түрлі бөліктері үшін, көптеген мақсатты классификациялау үшін жоғары (адамдардың) негіз Біз көптеген жазбаларды анализ және ентропиялық түрлендірушілердің түрлендіру (яғни мақсатты белгісі) үшін ентропиялық түрлендіру үшін ұсынамыз. Біз айтып тұрамыз, ескертушілер бір не бірнеше мүмкін толыққа сәйкес келмегенде, бірақ классификациясы соңғы мақсатты классын бастап көрсетеді, бұл деректер қорындағы артефакттарға артефакттарға жазылмайды.', 'pl': 'Klasyfikacja intencji przyrostowych wymaga przypisania etykiet intencji do częściowych wypowiedzi. Jednakże wypowiedzi częściowe niekoniecznie zawierają wystarczająco dużo informacji, aby zostały odwzorowane do klasy intencji ich całkowitego wypowiedzenia (poprawnie i z pewnym stopniem pewności). Wykorzystanie ostatecznej interpretacji jako podstawowej prawdy do mierzenia dokładności klasyfikatora podczas klasyfikacji intencyjnej wypowiedzi częściowych jest zatem problematyczne. Wydajemy inCLINC, zbiór danych częściowych i pełnych wypowiedzi z ludzkimi adnotacjami wiarygodnych etykiet intencji dla różnych części każdej wypowiedzi, jako górną (ludzką) bazę podstawową dla przyrostowej klasyfikacji intencji. Analizujemy adnotacje przyrostowe i proponujemy redukcję entropii jako miarę konwergencji ludzkich adnotatorów na interpretacji (tj. etykietę intencji). Twierdzimy, że gdy adnotatory nie zbiegają się do jednej lub kilku możliwych interpretacji, a jednak klasyfikator już na wczesnym etapie identyfikuje ostateczną klasę intencji, jest to oznaka nadmiernego dopasowania, którą można przypisać artefaktom w zbiorze danych.', 'ro': 'Clasificarea incrementală a intențiilor necesită atribuirea etichetelor de intenție unor pronunțări parțiale. Cu toate acestea, pronunțările parțiale nu conțin neapărat suficiente informații pentru a fi mapate la clasa de intenție a pronunțării lor complete (corect și cu un anumit grad de încredere). Prin urmare, utilizarea interpretării finale ca adevăr fundamental pentru a măsura acuratețea unui clasificator în timpul clasificării intenționale a pronunțărilor parțiale este problematică. Lansăm inCLINC, un set de date de pronunțări parțiale și complete cu adnotări umane de etichete de intenție plauzibile pentru diferite porțiuni ale fiecărei pronunțări, ca bază superioară (umană) pentru clasificarea intențiilor incrementale. Analizăm adnotările incrementale și propunem reducerea entropiei ca măsură a convergenței adnotatorilor umani asupra unei interpretări (adică eticheta intenției). Susținem că, atunci când adnotatorii nu converg la una sau câteva interpretări posibile și totuși clasificatorul identifică deja clasa finală de intenție timpuriu, este un semn de supraîncărcare care poate fi atribuit artefactelor din setul de date.', 'no': 'Klassifikasjonen for økt måte krev å tilordna merkelapper til delvis uttrykk. Dei delvis uttalene inneheld ikkje nødvendig nok informasjon som skal karterast til hjelpeteksten av dei fullstendige uttalene (rett og med ein viss tiltrudd). Bruk den siste tolkinga som bakgrunnsannheten for å måle akkuratet til ein klassifiserer under vilkårleg klassifisering av delvis uttaler er derfor problematisk. Vi avsluttar inCLINC, ein dataset med delvis og fulle uttrykk med menneskelige notasjonar med tilgjengelege uttrykk for ulike deler av kvar uttrykk, som ein øvre (menneskelig) baseline for inkrementalt uttrykk. Vi analyserer økende notasjonane og foreslår å redusera entropien som mål av konvergensen til menneske annotatorar på eit tolking (t.d. merkelapp). Vi argumenterer at når annotatorane ikkje samsvarar med ein eller ein par moglege tolkingar, og likevel klassifiseringen allereie identifiserer den siste intensjonsklassen tidlegare på, er det ein teikn på overpassing som kan skrivast til artefaktar i datasettet.', 'sv': 'Inkrementell avsiktsklassificering kräver tilldelning av avsiktsetiketter till partiella yttranden. Emellertid innehåller partiella yttranden inte nödvändigtvis tillräckligt med information för att kartläggas till avsiktsklassen för deras fullständiga yttrande (korrekt och med en viss grad av förtroende). Att använda den slutliga tolkningen som grundsanning för att mäta en klassificerares noggrannhet vid avsiktsklassificering av partiella yttranden är därför problematiskt. Vi släpper inCLINC, en datauppsättning av partiella och fullständiga yttranden med mänskliga anteckningar av rimliga avsiktsetiketter för olika delar av varje yttrande, som en övre (mänsklig) baslinje för inkrementell avsiktsklassificering. Vi analyserar inkrementella noteringar och föreslår entropireduktion som ett mått på mänskliga kommentatorers konvergens på en tolkning (dvs intent label). Vi hävdar att när kommentatorerna inte konvergerar till en eller några möjliga tolkningar och ändå klassificeraren redan tidigt identifierar den slutliga avsiktsklassen, är det ett tecken på överpassning som kan tillskrivas artefakter i datauppsättningen.', 'sr': 'Povećavajuća klasifikacija namjere zahteva dodavanje namjernih etiketa na dijelične reči. Međutim, delimične reči ne sadrže dovoljno informacija da se mapiraju na namjernu klasu potpunog govora (ispravno i sa određenom stupom samopouzdanja). Koristeći konačnu interpretaciju kao temeljnu istinu za mjerenje tačnosti klasifikatora tijekom namere klasifikacije djelomičnih govora je tako problematično. Puštamo inCLINC, kompletu podataka djelomičnih i punih govora sa ljudskim annotacijom uvjerljivih namera etiketa za različite dijelove svakog govora, kao početnu liniju gornje (ljudska) klasifikacije povećavajućih namera. Analiziramo incrementalne annotacije i predlažemo smanjenje entropije kao mjeru konverģencije ljudskih annotatora na interpretaciji (tj. namernog etiketa). Svađamo se da, kada annotatori se ne pridružuju sa jednim ili nekoliko mogućih interpretacija, a ipak klasifikator već identifikuje konačnu klasu namjere ranije, to je znak preusmjerenja koja se može pripisati artefaktima u setu podataka.', 'si': 'විශාලනය ක්\u200dරියාත්මක විශේෂණය අවශ්\u200dය වෙන්නේ අවශ්\u200dය ලේබෙල්ලගේ අවශ්\u200dය වෙන්න. නමුත්, අංශික කියන්න අවශ්\u200dයයෙන් ඇති තොරතුරු තියෙන්නේ නැහැ ඔවුන්ගේ සම්පූර්ණ විශ්වාස විශ්වාස විශ්වාස අන්තිම අන්තිම අන්තර්ගය භූමික ඇත්ත විදිහට ප්\u200dරශ්නයක් වෙනුවෙන් විශ්වාස කරනවා ක්\u200dරියාත්මක ක්\u200dරියාත්මක ව අපි ඉන්ක්ලින්ක් විස්තර කරනවා, මිනිස්සුන්ගේ ප්\u200dරමාණය සහ සම්පූර්ණ කිරීමේ දත්ත සූදානම් අපි විශ්ලේෂණය කරනවා විශ්ලේෂණය සහ ඇන්ට්\u200dරෝපිය අඩංගුවක් විශ්ලේෂණය කරනවා මිනිස්සු ඇන්ටෝටර්ස්ගේ සම්බන්ධ විශ් අපි ප්\u200dරශ්නයක් කරනවා කියලා, අනතුරු ප්\u200dරශ්නයක් එකක් නැත්නම් පුළුවන් කිහිපයක් සම්බන්ධ වෙන්නේ නැත්නම්, ඒත් විශ්වාසිකයා දැනටමත් අන්තිම අ', 'so': "Takhasuska firaaqada ah waxaa loo baahan yahay in loo qeyb ahaan u sameeyo calaamada qasabka ah. Si kastaba ha ahaatee hadal qeyb ah uma jirto macluumaad ku filan in lagu sawiro fasalka ku qoran hadalkooda dhamaantooda (si saxda ah iyo shahaado cayiman ah). Isku isticmaalka turjumka ugu dambeeya sida runta dhulka si uu u qiyaaso saxda fasaxa marka loo kala fasaxo hadalka qayb ahaan waa dhibaato. InCLINC, waxaan bixinaynaa sawir kamid ah oo ku qoran hadal buuxa ah oo dadka ku saabsan calaamado qasab ah oo aad u baahan karto meelo kala duduwan oo ku qoran hadal kasta, sida qoraal kor (human) oo loo qoro fasax aad u daran. Anagaa qiimeynaynaa dhibaatada korsocodka, waxaana soo jeedinaynaa in koob ka kooban turjubaanka dadka ku saabsan turjubaanka (tusaale ahaan calaamadda). Waxaynu ka sheekaynaynaa in marka aan turjubaan u bedelan hal ama dhawr suurtagal ah, laakiin fasalka ugu dambeeya uu horay u caddeeyo fasalka ugu dambeeya, waa calaamad aad u faa'iideyso, taas oo lagu qeyb gelin karo waxyaabaha lagu sameeyo macluumaadka.", 'ur': 'افزایش کا ارادہ کلاسپیٹ کی ضرورت ہے کہ مقررہ لابلوں کے مقررہ مقررہ تعریف کریں۔ However, partial words do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence). آخری تعبیر کو زمین کی حقیقت کے طور پر استعمال کرنے کے لئے ایک کلاسیر کی دقیقیت کا اندازہ مقرر کرنے کے لئے حصۂ کلاسیفوں کی تعبیر کے وقت مشکل ہے۔ ہم اپنا کلام کے مختلف حصے کے لئے انسان کی آگاہ کرنے والی مطالبہ لابل کے ذریعے ایک حصہ اور پوری کلام کے ڈاٹ سٹ کو آزاد کریں گے، اور اس کے لئے اضافہ مطالبہ کرنا ہے. ہم نے اضافہ اضافہ کی باتوں کو تحقیق کر لیا ہے اور انٹروپی کاٹنے کی پیشنهاد کرتا ہے ایک تفسیر (یعنی قصد لیبل) پر انسان کے اضافہ کرنے والوں کے معاملہ میں۔ ہم argue that when the annotators do not combine with one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be attributed to artefacts in the data set.', 'ta': 'அதிகமான intent classification requires intent labels to assign to partial words. ஆனால், பாகமான வார்த்தைகள் போதுமான தகவல்களை வரைபடத்தில் இருக்கவில்லை( சரியாக மற்றும் சில நம்பிக்கையுடன்) பாகமான வார்த்தைகளை வகுப்பதற்கு நிலையில் வகுப்பாளரின் சரியை அளக்க முடியும் பொழுது இறுதியான விளக்கம் என்பது பிரச்சனை நாம் inCLINC, பாகம் மற்றும் முழு வார்த்தைகளின் தகவல் அமைப்பை வெளியிடுகிறோம் மனிதன் அறிவிப்புகளுடன் வெவ்வேறு வார்த்தையின் மேல் (மனிதன்) பிரிவினை ப நாம் அதிகமான அறிவிப்புகளை ஆராய்ச்சி மற்றும் நுழைவு குறைப்பை மனித அறிவிப்பாளர்களின் மாற்றத்திற்கு ஒரு அளவு பரிந்துரைக்கிற நாங்கள் விவாதம் செய்தால், அறிவிப்பாளர்கள் ஒன்று அல்லது சில சாத்தியமான மொழிபெயர்ப்புகளுக்கு மாறாது மற்றும் வகுப்பாளர் ஏற்கனவே முடிவு செய்யும் கடைசி', 'uz': "Tafsilotning katta darajasini bir necha so'zlarga qatorlashtirish kerak. Lekin bir qismlar so'zlarida ma'lumotni butun so'zlarning tashqi sinfga qarashga ega maʼlumot mavjud emas. Bir necha so'zlarni sinf qilish uchun darajalashtiruvchining haqiqatdan foydalanish juda muammo. Biz inCLINC, bir qismlar va butun gapiradigan ma'lumotlar tarkibini boshqa gapiradigan odamlar bilan bir so'zlar uchun qo'llab keladigan ko'plab belgini ajratuvchimiz. Biz ko'proq tajribalarni analyzeriz va inson taʼminlovchilarning turini o'zgartirish (ma'anaviy label) haqida o'zgarishni anglatamiz. Biz murakkab qilamiz, taʼminlovchilar bir yoki bir necha muvaffaqiyatli tarjima qilmaydigan paytda va faqat darajadagi oxirgi darajani aniqlaydi, bu maʼlumotlar sahifadagi artektlarga bog'lash mumkin.", 'vi': 'Phân loại mục đích phức tạp yêu cầu việc gán nhãn mục đích vào phát biểu một phần. Tuy nhiên, những phát ngôn viên không cần thiết chứa đủ thông tin để được vạch ra theo hạng mục đích của lời phát biểu hoàn to àn (chính xác và với một mức độ tin tưởng nhất định). Việc dùng cách giải thích cuối cùng như s ự thật mặt đất để đo mức độ chính xác của người phân loại người phân loại bằng người phân loại người phân phát ra có chủ đích là vấn đề. Chúng tôi công bố in CLINNC, một bộ dữ liệu với các lời khai đầy đủ bằng chú ý của con người với các chú thích hợp về các phần khác nhau của mỗi lời phát âm, như một cơ sở cơ bản (con người) trên để phân loại mục số dần dần. Chúng tôi phân tích các chú thích tăng dần và đề nghị giảm lượng ngẫu nhiên như một thước đo sự hội tụ của người biên niên theo một cách diễn giải (tức là nhãn hiệu mục đích). Chúng tôi cho rằng, khi các nhà biên niên đại không hội tụ về một hoặc vài cách giải thích có thể xảy ra nhưng người phân loại đã xác định lớp mục đích cuối ngay từ đầu, đó là dấu hiệu lạm dụng khả năng được gán cho các đồ vật trong bộ dữ liệu.', 'nl': 'Incrementele intentieclassificatie vereist de toewijzing van intentielabels aan gedeeltelijke uitingen. Gedeeltelijke uitingen bevatten echter niet noodzakelijkerwijs voldoende informatie om te worden toegewezen aan de intentieklasse van hun volledige uiting (correct en met een zekere mate van vertrouwen). Het is dus problematisch om de uiteindelijke interpretatie als grondwaarheid te gebruiken om de nauwkeurigheid van een classificator te meten tijdens intentieclassificatie van gedeeltelijke uitingen. We geven inCLINC uit, een dataset van gedeeltelijke en volledige uitingen met menselijke annotaties van plausibele intentielabels voor verschillende delen van elke uiting, als een hogere (menselijke) basislijn voor incrementele intentieclassificatie. We analyseren de incrementele annotaties en stellen entropiereductie voor als maatstaf voor de convergentie van menselijke annotatoren op een interpretatie (intent label). We stellen dat, wanneer de annotatoren niet convergeren naar een of enkele mogelijke interpretaties en toch de classificator al vroeg de definitieve intentieklasse identificeert, dit een teken van overfitting is dat kan worden toegeschreven aan artefacten in de dataset.', 'bg': 'Класификацията на нарастващите намерения изисква определянето на етикети на намеренията на частични изказвания. Въпреки това, частичните изказвания не съдържат непременно достатъчно информация, за да бъдат картографирани към класа намерения на тяхното пълно изказване (правилно и с определена степен на увереност). По този начин използването на окончателната интерпретация като основна истина за измерване на точността на класификатора по време на умишлено класифициране на частични изказвания е проблематично. Ние публикуваме набор от данни от частични и пълни изказвания с човешки анотации на етикети с правдоподобни намерения за различни части от всяка изказване, като горна (човешка) базова линия за класификация на постепенно намерение. Анализираме допълнителните анотации и предлагаме редукция на ентропията като мярка за конвергенцията на човешките анотатори върху интерпретация (т.е. етикет за намерение). Ние твърдим, че когато анотаторите не се сближават с една или няколко възможни интерпретации и въпреки това класификаторът вече идентифицира крайния клас намерение рано, това е знак за прекомерно приспособяване, който може да се приписва на артефакти в набора от данни.', 'hr': 'Povećavajuća klasifikacija namjera zahtijeva dodavanje namjernih etiketa na djelomične izjave. Međutim, djelomične govore ne sadrže dovoljno informacija da se mapiraju na namjernu klasu potpunog govora (ispravno i s određenom stupom povjerenja). Koristeći konačnu interpretaciju kao temeljnu istinu za mjerenje tačnosti klasifikatora tijekom namjerne klasifikacije djelomičnih izraza je tako problematično. Puštamo inCLINC, skup podataka djelomičnih i punih izraza s ljudskim annotacijom uvjerljivih namjernih etiketa za različite dijelove svakog govora, kao početnu liniju gornje (ljudska) klasifikacije povećavajućih namjera. Analiziramo povećan e annotacije i predlažemo smanjenje entropije kao mjeru konverģencije ljudskih annotatora na interpretaciji (tj. namjerne etikete). Tvrdimo se da, kada annotatori ne spojuju sa jednim ili nekoliko mogućih interpretacija, a ipak klasitelj već identificira konačnu klasu namjere ranije, to je znak preusmjerenja koja se može pripisati artefaktima u setu podataka.', 'da': 'Inkrementel hensigtsklassificering kræver tildeling af hensigtsetiketter til delvise udtalelser. Delvise udtalelser indeholder dog ikke nødvendigvis tilstrækkelige oplysninger til at blive kortlagt til hensigtklassen for deres fuldstændige udtalelse (korrekt og med en vis grad af tillid). Det er derfor problematisk at bruge den endelige fortolkning som grundsandhed til at måle en klassificeres nøjagtighed under hensigtsklassificering af partielle udtalelser. Vi udgiver inCLINC, et datasæt af delvise og fulde udtalelser med menneskelige noteringer af plausible intention labels for forskellige dele af hver udtalelse, som en øvre (menneskelig) baseline for inkrementel intention klassificering. Vi analyserer de inkrementelle noteringer og foreslår entropireduktion som et mål for menneskelige kommentatorers konvergens på en fortolkning (dvs. intent label). Vi hævder, at når kommentatorerne ikke konvergerer til en eller nogle få mulige fortolkninger, og alligevel klassificereren allerede tidligt identificerer den endelige intent klasse, er det et tegn på overtilpasning, der kan tilskrives artefakter i datasættet.', 'id': 'Klasifikasi tujuan incremental membutuhkan pengaturan label tujuan ke ucapan parsial. Namun, ucapan parsial tidak necessarily mengandung cukup informasi untuk dipetakan ke kelas tujuan dari ucapan lengkap mereka (benar dan dengan tingkat tertentu kepercayaan). Menggunakan interpretasi terakhir sebagai kebenaran dasar untuk mengukur akurasi klasifikasi selama klasifikasi niat ucapan parsial adalah sehingga masalah. We release inCLINC, a dataset of partial and full utterances with human annotations of plausible intent labels for different portions of each utterance, as an upper (human) baseline for incremental intent classification.  Kami menganalisis annotasi incremental dan mengusulkan reduksi entropi sebagai ukuran konvergensi annotator manusia pada sebuah interpretasi (i.e. label niat). Kami berdebat bahwa, ketika annotator tidak konvergensi ke salah satu atau beberapa interpretasi yang mungkin dan namun klasifikasi sudah mengidentifikasi kelas tujuan akhir awal, itu adalah tanda overfitting yang dapat ditunjukkan kepada artefakta di dataset.', 'de': 'Die inkrementelle Absichtsklassifizierung erfordert die Zuweisung von Absichtsetiketten zu Teiläußerungen. Teiläußerungen enthalten jedoch nicht notwendigerweise genügend Informationen, um der Intentklasse ihrer vollständigen Äußerung zugeordnet zu werden (korrekt und mit einem gewissen Grad an Vertrauen). Es ist daher problematisch, die endgültige Interpretation als Grundwahrheit zu verwenden, um die Genauigkeit eines Klassifikators während der Absichtsklassifikation von Teiläußerungen zu messen. Wir veröffentlichen inCLINC, einen Datensatz von partiellen und vollständigen Äußerungen mit menschlichen Anmerkungen plausibler Intent Labels für verschiedene Teile jeder Äußerung, als obere (menschliche) Baseline für inkrementelle Intent Klassifizierung. Wir analysieren die inkrementellen Annotationen und schlagen Entropiereduktion als Maß für die Konvergenz menschlicher Annotatoren auf einer Interpretation (d.h. Intent Label) vor. Wir argumentieren, dass, wenn die Annotatoren nicht zu einer oder einigen möglichen Interpretationen konvergieren und der Klassifikator die endgültige Intent-Klasse bereits früh identifiziert, dies ein Zeichen für Überfitting ist, das Artefakten im Datensatz zugeschrieben werden kann.', 'fa': 'برنامه\u200cهای هدف افزایش نیاز دارد که برنامه\u200cهای هدف را به زبان\u200cهای قسمتی تعیین کند. ولی کلمات بخشی لازم نیست که به اندازه کافی اطلاعات را برای نقشه کردن به کلاس کلمات کامل (درست و با یک درجه مطمئن) دارند. با استفاده از تعبیر نهایی به عنوان حقیقت زمینی برای اندازه دادن دقیقات یک گروه در زمان جدایی کردن کلمات بخشی مشکل است. ما inCLINC را آزاد می\u200cکنیم، یک مجموعه داده\u200cای از گفته\u200cهای قسمتی و کامل با نوشته\u200cهای انسان از نوشته\u200cهای هدف قابل توجه برای قسمت\u200cهای متفاوتی از هر کلمه، به عنوان یک خط پایین (انسان) بالا برای گروه\u200cهای هدف افزایش. ما توضیح اضافه\u200cهای اضافه\u200cای را تحلیل می\u200cکنیم و پیشنهاد می\u200cکنیم کاهش انتروپی را به عنوان اندازه\u200cای از ترجمه\u200cهای اضافه\u200cکنندگان انسان در یک تفسیر (یعنی نقاشی هدف). ما بحث می\u200cکنیم که هنگامی که نویسنده\u200cها با یک یا چند تعبیر ممکن متصل نمی\u200cشوند و هنگامی که کلاس نهایی هدف را زودتر از آن شناسایی می\u200cکند، نشانه\u200cای از متصل است که می\u200cتواند به ارتفاوت\u200cها در مجموعه داده\u200cها نوشته شود.', 'ko': '증량 의도 분류는 일부 언어에 의도 라벨을 지정해야 한다.그러나 일부 언어는 완전한 언어의 의도 유형에 충분한 정보를 포함하지 않는다(정확하고 어느 정도 신뢰도가 있다).따라서 일부 언어를 의도적으로 분류할 때 최종 해석을 기본적인 사실로 삼아 양사의 정확성을 평가하는 것은 문제가 있다.우리는 부분과 완전한 언어를 포함하는 데이터 집합을 발표했는데 그 중에서 각 언어의 서로 다른 부분마다 합리적인 의도 라벨이 있는 인류 주석을 증량의도 분류의 상(인간) 기선으로 삼았다.우리는 증량 주석을 분석하고 엔트로피 감소가 인류 주석자로서 해석(즉 의도 라벨)에서 수렴되는 도량을 제시했다.우리는 주석자가 한 가지 또는 몇 가지 가능한 해석을 수렴하지 않고 분류기가 초기에 최종 의도류를 식별했을 때 데이터가 인공제품에 집중된 과도한 의합 징후라고 생각한다.', 'sw': "Utafiti wa kiwango kinachoongezeka unahitaji kuchukua alama za maana kwa maneno ya sehemu. Hata hivyo, maneno ya sehemu hayana lazima ya taarifa za kutosha ili kupata ramani kwenye darasa la kusema kamili (kwa sahihi na kwa kiwango fulani cha imani). Using the final interpretation as the ground truth to measure a classifier's accuracy during intent classification of partial utterances is thus problematic.  Tunatoa taarifa ya inCLINC, seti ya maneno ya sehemu na kamili yenye matangazo ya binadamu ya alama zenye nia mbalimbali za kila namna ya hotuba, kama msingi wa juu (binadamu) kwa ajili ya kutangaza kwa lengo la kuongezeka. Tunafahamu matatizo yanayozidi kuongezeka na kupendekeza kupunguza ujasiriano kama hatua ya mazungumzo ya watambuzi wa binadamu kuhusu tafsiri (yaani alama ya kusudia). Tunahoji kuwa, pale watangazaji hawazungumzi na tafsiri chache zinazowezekana na hata hivyo mwandishi tayari anatambua darasa la mwisho mapema, ni ishara ya kuporomoka ambayo inaweza kuhusiana na viumbe katika seti ya data.", 'sq': "Klasifikimi i qëllimeve rritëse kërkon vendosjen e etiketave të qëllimeve në shprehje të pjesshme. However, partial utterances do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence).  Përdorimi i interpretimit përfundimtar si e vërteta themelore për të matur saktësinë e një klasifikues gjatë klasifikimit me qëllim të shprehjeve të pjesshme është kështu problematik. Ne lëshojmë inCLINC, një grup të dhënash të shprehjeve të pjesshme dhe të plota me anotacione njerëzore të etiketave të besueshme të qëllimeve për pjesë të ndryshme të çdo shprehjeje, si një bazë të lartë (njerëzore) për klasifikimin e qëllimeve shtesë. Ne analizojmë anotacionet shtesë dhe propozojmë reduktimin e entropisë si një masë të konvergencës së anotatorëve njerëzorë në një interpretim (i.e. etiketë qëllimi). Ne argumentojmë se, kur anotatorët nuk konvergojnë në një apo disa interpretime të mundshme dhe megjithatë klasifikuesi identifikon tashmë klasën e qëllimit përfundimtar herët në fillim, kjo është një shenjë e mbipajtimit që mund t'u atribuohet artefakteve në grupin e të dhënave.", 'tr': "Gelişik maksady klasifikasynda niýe etitlerini parça sözlere takyklamak gerek. Ýöne, bölüm sözleri doly sözleriniň niýeti derejesine (dogry we ynamly derejesi bilen) surat edilmek üçin ýeterlik maglumat ýok däldir. Soňky terjime edilen çykyşyň dogrylygyny görkezmek üçin klasifikatçyň dogrylygyny görkezmek üçin problematik bar. Biz inCLINC'i, insan sözleriniň beýleki bölümleri üçin, üst bir (insan) beýleki niýetleri ylalaşyk bilen doly sözlerini seredip otyrýarys. Biz artık duygusal duygulamaları analiz edip, insan duygulamalarının bir terjime (yani niyetli etiket) düşürmesini öneririz. Muny gürrüň edýäris, haçan ýazgyşlar bir ýa-da birnäçe mümkin terjimelere çarpmazlar, ýöne klasifikatçy eýýäm üçin soňky maksadyň synpyny erken tanaýarlar, muny maglumatlarda artefaktlara ýazyklanabilir bir işaretdir.", 'am': "በአስቸጋሪው መግለጫ የአስቸጋሪ ምልክቶችን ለክፍል ንግግር ማሳየት ያስፈልጋል፡፡ ምንም እንኳን የአካባቢው ቃላት በሙሉ ቃላቸውን ለመቀረብ የሚበቃ መረጃ አያስፈልግም (በአስተካከል እና በተስማማማው መጠን) ነው፡፡ Using the final interpretation as the ground truth to measure a classifier's accuracy during intent classification of partial utterances is thus problematic.  የኢንCLINC ዳታ እና ሙሉ ንግግር እና ለሁሉም ንግግር በተለየ ልዩ ክፍሎች ላይ (የሰው) መደገፊያ ለማድረግ ማሰሪያ እናስቀራለን፡፡ አካባቢ ግንኙነቶችን እናሳውቃለን እና የኢንተሮፓን አካውንት በሰው አካባቢዎች ግንኙነቱን በመተርጓሜ ላይ እናሳውቃለን፡፡ አናጋሪዎቹ ለአንድ ወይም ለጥቂት የሚቻለው ትርጉም ባይለውጡ ጊዜ ግን መጨረሻው የፍጻሜውን ጥያቄ አስቀድሞ በማሳወቅ፣ የዳታ አርጤክስቶችን በመጠቀም የሚችል ምልክት ነው፡፡", 'az': "Artırma niyyəti klasifikasiyasının qismi sözlərə niyyətli etiketlərin təyin edilməsi lazımdır. Lakin, parçalıq sözləri tamamlayıb sözlərinin niyyətinə qoyulmaq üçün kifayət məlumatları olmaz (düzgün və təvəkkül dərəsi ilə). Qiyamət yozumunu yerli gerçək kimi təkrar etmək üçün klasifikatçının doğruluğunu ölçürmək üçün parçacıq s özlərin klasifikasyonu yaratmaq belə problematik olur. Biz inCLINC'i, insanların müxtəlif sözlərinin müxtəlif bölümlərinə inanılmaz niyyətlərin yazılması ilə dəyişiklik və bütün sözlərin dəyişiklik dəyişikliklərini, böyük (insan) niyyətini artırmaq üçün dəyişiklik dəyişiklik olaraq yayındırıq. Biz artıqlıq məlumatlarını analiz edir və entropi azaltmağını insanların məlumatlarının bir yozumun ( məlumatların məlumatlarının məlumatlarının məlumatlarını ) ilə təklif edirik. Biz mübahisə edirik ki, annotatorlar bir ya da bir neçə mümkün təfsil ilə birlikdə olmadığında, lakin klasifikatçı çox əvvəlcə son niyyətin sınıfını təsdiqlədiyi zaman, verilən qutuda artefaktlara yazılabilir.", 'af': "Inkrementeel doel klassifikasie benodig die toewysing van doel etikette na deel uitspraak. Maar gedeeltelike uitspraak bevat nie noodsaaklik genoeg inligting om te maak na die doel klas van hul volledige uitspraak (korrek en met 'n sekere grad vertroue). Gebruik van die eindelike uitlegging a s die grond waarheid om 'n klassifiseerder se presisiteit te maak tydens intekenklassifikasie van gedeeltelike uitdrukkings is so problematiek. Ons verlos in CLINC, 'n datastel van gedeeltelike en volle uitspraak met menslike notasies van plaasbare doel etikette vir verskillende dele van elke uitspraak, as 'n boonste (menslike) basisline vir inkremensielike doel klasifikasie. Ons analyseer die inkremensiele annotasies en voorstel entropie reduksie as 'n maat van menslike annotators se konvergensie op 'n uitlegging (bv. doel etiket). Ons argumenteer dat wanneer die annotators nie saamgekom met een of 'n paar moontlike uitleggings nie, en tog die klassifiseerder reeds die eindelike doel klas vroeg op identifiseer nie, is dit 'n teken van overfitting wat kan aan artefakte in die datastel geskrywe word.", 'bs': 'Povećavajuća klasifikacija namjera zahtijeva dodavanje namjernih etiketa na djelomične izreke. Međutim, djelimične govore ne sadrže dovoljno informacija da se mapiraju na namjernu klasu potpunog govora (ispravno i sa određenom stupom povjerenja). Koristeći konačnu interpretaciju kao temeljnu istinu za mjerenje tačnosti klasifikatora tijekom namjerne klasifikacije djelomičnih govora je tako problematično. Puštamo inCLINC, skup podataka djelomičnih i punih govora sa ljudskim annotacijom uvjerljivih namjernih etiketa za različite dijelove svakog govora, kao početnu liniju gornje (ljudska) klasifikacije povećavajućih namjera. Analiziramo povećan e annotacije i predlažemo smanjenje entropije kao mjeru konverģencije ljudskih annotatora na interpretaciji (tj. namjerno etikete). Svađamo se da, kada annotatori se ne pridružuju sa jednim ili nekoliko mogućih interpretacija, a ipak klasifikator već identificira konačnu klasu namjere ranije, to je znak preusmjerenja koja se može pripisati artefaktima u setu podataka.', 'ca': "La classificació de intencions incrementals requereix l'asignació d'etiquetes de intencions a expressions parcials. No obstant això, les expressions parcials no contenen necessariament suficient informació per ser mapeades a la classe d'intenció de la seva expressió completa (correctament i amb un cert grau de confiança). Utilitzar l'interpretació final com la veritat fonamental per mesurar la precisió d'un classificador durant la classificació intencional de frases parcials és així problemàtica. Vam publicar l'inCLINC, un conjunt de dades de frases parcials i plenes amb anotacions humanes de etiquetes plausibles d'intenció per diferents porcions de cada frase, com una base superior (human a) per a la classificació incremental d'intenció. Analitzem les anotacions incrementals i proposem una reducció d'entropia com a mesura de la convergència dels anotators humans en una interpretació (i.e. etiqueta d'intenció). We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.", 'hy': "Ավելի մեծ նպատակի դասակարգումը պահանջում է, որ նպատակի պիտակները դասակարգում են մասամբ արտահայտություններին: Այնուամենայնիվ, մասամբ արտահայտությունները պարտադիր չունեն բավարար տեղեկատվություն, որպեսզի քարտեզագրվեն իրենց ամբողջ արտահայտության նպատակային դասին (ճիշտ և որոշակի վստահությամբ): Using the final interpretation as the ground truth to measure a classifier's accuracy during intent classification of partial utterances is thus problematic.  Մենք արտադրում ենք InCINC-ը, մարդկային նշումներով մասամբ և ամբողջական արտահայտությունների տվյալներ, որոնք հավատալի մտադրության պիտակներ են արտադրում յուրաքանչյուր արտահայտության տարբեր մասերի համար, որպես վերևի (մարդկային) հիմք, որպեսզի կարողանանք դասակարգել աճ Մենք վերլուծում ենք աճող նոտացիաները և առաջարկում ենք էնտրոպիայի կրճատմանը որպես մարդկային նոտացիաների մոտեցումը մեկնաբանության վրա (այսինքն, մտադրության պիտակ): Մենք բանավեճում ենք, որ երբ annoտորները չեն մոտենում մեկ կամ մի քանի հնարավոր մեկնաբանություններին, բայց դասակարգիչը արդեն վաղ սկզբում հայտնաբերում է վերջնական նպատակային դասակարգը, դա չափազանց լավ համակարգման նշան է, որը կարող է պատասխանվել տվյալների համակարգում գտնվող արտեֆեկտների", 'bn': 'বেশীরভাগ গন্তব্য ক্লাসাফেশনের ক্ষেত্রে গুরুত্বপূর্ণ ভাষণের জন্য বৈশিষ্ট্য লেবেলের দায়িত্ব চায়। তবে আংশিক ভাষণের মধ্যে যথেষ্ট তথ্য নেই যাতে তাদের পুরোপুরি বাক্যের ক্ষেত্রে ম্যাপ করা যায় (সঠিক এবং নির্দিষ্ট ক্ষেত্রে ব পার্টিক ভাষার ব্যাপারে ক্লাসাফারের সঠিকভাবে পরিমাপ করার জন্য চূড়ান্ত ব্যাখ্যা ব্যবহার করা হচ্ছে বিষয়টি সমস্যায়। আমরা ইনসিলিএনসি প্রত্যেক বক্তব্যের বিভিন্ন ভিন্ন অংশের জন্য মানুষের বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভাষার জন্য মানুষের প আমরা বিশ্লেষণ করি ক্রমবর্ধমান বিষয়টি বিশ্লেষণ এবং মানুষের বিভিন্ন ব্যাখ্যার ব্যাপারে (যেমন উদ্দেশ্য লেবেলেবেল)-এর পরিমা আমরা যুক্তি দিচ্ছি যে যখন ব্যাখ্যাতিকরা এক বা কয়েকটি সম্ভাব্য ব্যাখ্যার সাথে যোগাযোগ করে না এবং ক্লাসিফাররা ইতোমধ্যে শুরুতে শেষ পর্যন্ত চিহ্নিত করেছেন', 'fi': 'Incremental intent -luokitus edellyttää intent-merkintöjen määrittämistä osittaisille lauseille. Osittaiset lausumat eivät kuitenkaan välttämättä sisällä riittävästi tietoa, jotta ne voitaisiin liittää niiden täydellisen lausuman intent-luokkaan (oikein ja tietyllä varmuudella). Lopullisen tulkinnan käyttäminen pohjatotuutena luokittelijan tarkkuuden mittaamiseen osittaisten sanontojen tarkoituksellisessa luokittelussa on näin ollen ongelmallista. Julkaisemme inCLINC-aineiston, joka sisältää osittaisia ja täydellisiä lauseita, joissa on inhimillisiä huomautuksia uskottavista intent-etiketeistä kunkin lauseen eri osille, ylempänä (inhimillisenä) lähtötasona inkrementaaliselle intent-luokitukselle. Analysoimme inkrementaaliset annotaatiot ja ehdotamme entropian reduktiota ihmisen annotaattoreiden lähentymisen mittana tulkinnassa (intent label). Väitämme, että kun merkinnät eivät lähene yhteen tai muutamaan mahdolliseen tulkintaan ja luokittelija tunnistaa lopullisen intent-luokan jo varhaisessa vaiheessa, se on merkki ylikuormituksesta, joka voidaan liittää aineiston esineisiin.', 'cs': 'Inkrementální klasifikace záměru vyžaduje přiřazení štítků záměru k částečným projevům. Dílčí výroky však nemusí nutně obsahovat dostatek informací, aby byly mapovány do třídy záměrů jejich úplného projevu (správně a s určitou mírou důvěry). Použití konečné interpretace jako základní pravdy k měření přesnosti klasifikátoru při záměrné klasifikaci dílčích výroků je tedy problematické. Vydáváme inCLINC, datovou sadu částečných a úplných výroků s lidskými anotacemi věrohodných popisků záměru pro různé části každého výroku, jako horní (lidský) základní základ pro přírůstkovou klasifikaci záměru. Analyzujeme inkrementální anotace a navrhujeme redukci entropie jako měřítko konvergence lidských anotátorů na interpretaci (tzn. intent label). Tvrdíme, že když anotátory nesouhlasí s jednou nebo několika možnými interpretacemi a přesto klasifikátor již brzy identifikuje konečnou třídu záměru, je to známka nadměrného přizpůsobení, které lze přičíst artefaktům v datové sadě.', 'et': 'Kasvava kavatsuse klassifitseerimine nõuab kavatsuse märgistuse määramist osalistele väljenditele. Osalised väljendid ei pruugi siiski sisaldada piisavalt teavet, et kaardistada nende täieliku väljenduse kavatsusklassi (õigesti ja teatud kindlusega). Seega on lõpliku tõlgenduse kasutamine alustõena klassifitseerija täpsuse mõõtmiseks osaliste väljendite kavatsuslikul klassifitseerimisel problemaatiline. Avaldame inCLINC-i, osaliste ja täielike väljendite andmekogumi, mis sisaldab inimlikke märkusi tõenäoliste kavatsuste märgistustega iga väljendi eri osade kohta, kui ülemise (inimliku) lähtekohana täiendava kavatsuse klassifitseerimiseks. Analüüsime täiendavaid annotatsioone ja pakume entroopia vähendamist inimeste annotatorite lähenemise mõõtmena tõlgendamisel (s.o intent label). Väidame, et kui annotaatorid ei lähene ühele või mõnele võimalikule tõlgendusele, kuid klassifitseerija tuvastab lõpliku kavatsusklassi juba varakult, on see märk ülemäärasest sobivusest, mida võib omistada andmekogumis olevatele esemetele.', 'ha': "Tsarin da ke ƙara, ya ƙayyade juyin alama masu yiwuwa wa'ura zuwa rabin magana. Babu lazima ba ya ƙunsa da maɓallin tsari ba dõmin a karo zuwa ma'abũcin fassarar magana da suka cika (da gaske kuma da wani daraja na aminci). Yi amfani da fassarar ƙarshen kamar bangon gaske zuwa ya cika tsarin mai classifar a lokacin da za'a yi rabo ga rabin magana, don haka yana cikin matalauci. Munã saka inCLINC, da wani danganta masu rabon da cikakken magana na mutane da alama masu yin plausi wa sunaye na daban-rabo ga duk maganar, kamar da wani rubutu na samar (mutum) wa fasalin mai ƙaranci. Ana yi anayya ga takardar da ke ƙara kuma Muke buƙatan ƙarantarwa ga entropy kamar wani gwargwadon mutane da ke cikin fassarar (misali). Munã jãyayya da cẽwa, idan ma'anarsa ba su haɗa zuwa fassarar guda ko da kaɗan masu iya yiwuwa kuma amma mai fassara ya riga yana gane fasalar ƙarshen gabanin, shine wata ãyar ta samu da za'a sami da wasu matsayi cikin danganta.", 'sk': 'Razvrstitev pospeševalnega namena zahteva dodelitev oznak namena delnim izgovorom. Vendar delni izgovori ne vsebujejo nujno dovolj informacij, da bi jih lahko preslikali v razred namena njihovega popolnega izgovora (pravilno in z določeno stopnjo zaupanja). Zato je problematična uporaba končne interpretacije kot osnovne resnice za merjenje točnosti klasifikatorja med namerno klasifikacijo delnih izgovorov. Izdajamo inCLINC, podatkovni nabor delnih in popolnih izjav s človeškimi pripombami z verjetnimi oznakami namena za različne dele vsakega izjave, kot zgornjo (človeško) osnovo za stopnjsko klasifikacijo namena. Analiziramo postopne opombe in predlagamo redukcijo entropije kot merilo konvergence človeških opombe na interpretaciji (oznaka intent). Trdimo, da je, kadar se označevalniki ne konvergirajo v eno ali nekaj možnih interpretacij in kljub temu klasifikator že zgodaj identificira končni razred namena, znak prekomernega prilagajanja, ki ga je mogoče pripisati artefaktim v naboru podatkov.', 'he': "שיעור הכוונה הגדול דורש את שיעור תוויות הכוונה לבטאות חלקיות. בכל אופן, מבטאות חלקיות לא בהכרח מכילות מספיק מידע כדי להיות ממפים לכיתת הכוונה של מבטאות מלאה שלהם (נכון ובמעמד מסוים של אמון). להשתמש בפרשנות הסופית כאמת הקרקע כדי למדוד את מדויקתו של מסווג במהלך מסווג הכוונה של מבטות חלקיות הוא ככה בעייתי. אנחנו משחררים inCLINC, קבוצת נתונים של מבטות חלקיות ומלאות עם ציונים אנושיים של תוויות כוונות אמיתיות עבור חלקים שונים של כל מבטות, כבסיס העליון We analyse the incremental annotations and propose entropy reduction as a measure of human annotators' convergence on an interpretation (i.e. intent label).  We argue that, when the annotators do not converge to one or a few possible interpretations and yet the classifier already identifies the final intent class early on, it is a sign of overfitting that can be ascribed to artefacts in the dataset.", 'bo': 'Inkremental intent classification requires the assignment of intent labels to partial utterances. However, partial utterances do not necessarily contain enough information to be mapped to the intent class of their complete utterance (correctly and with a certain degree of confidence). མཐའ་མཇུག་གི་ཕན་ཚིག་སྤྱད་པ་ལ་རྒྱལ་གཞི་དངོས་བདེན་པ་ཞིག་གིས་དམིགས་ཡུལ་གྱི་ཐ་སྙད་ཅིག We release inCLINC, a dataset of partial and full utterances with human annotations of plausible intent labels for different portions of each utterance, as an upper (human) baseline for incremental intent classification. ང་ཚོས་རང་ཉིད་ཀྱི་གསལ་བཤད་ཀྱི་སྣང་ཚུལ་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དུས་མཐུན་བཟོ་བྱེད་མཁན་གྱི་འགྲེལ་བཤད་པ་ཞིག་དང་མཐུན་བཟོ་བྱེད་མི་ཐུབ་པའི་སྐབས་སུ།', 'jv': 'AllProgressBar politenessoffpolite, "), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertive Awak dhéwé éntuk inCLINC, akeh dataset oleh patial karo cah nguasai perbudhakan karo hal-hal sing dadi nggawe barang nggawe ngubah sing gawe ngubah, akhar tanggal dhéwé (nambah) sing paling dhuwur kuwi cah stifta cah-stifta sing gawe ngubah Awakdhéwé énglek dhéwé éngleki nggawe tarjamahan karo nggawe soko nggawe barang nggawe barang nggawe tarjamahan kanggo nganggep nggawe tarjamahan (i.e. nambah nambah). Awak dhéwé ngerti, nek atusan akeh sing or a nggawe liyane perusahaan karo nganggo perusahaan sing beraksi iki dadi, winih dhéwé luwih nêmên ngerti perusahaan winih dhéwé, lan akeh dhéwé mengko perusahaan karo perusahaan langkung sampek.'}
{'en': 'Amendable Generation for Dialogue State Tracking', 'fr': 'Génération modifiable pour le suivi des états de dialogue', 'ar': 'جيل قابل للتعديل لتتبع حالة الحوار', 'es': 'Generación modificable para el seguimiento del estado del diálogo', 'pt': 'Geração Alterável para Rastreamento do Estado do Diálogo', 'ja': 'ダイアログの状態追跡のための修正可能な生成', 'zh': '言随者正', 'ru': 'Изменяемое поколение для отслеживания состояния диалога', 'hi': 'संवाद राज्य ट्रैकिंग के लिए संशोधन योग्य पीढ़ी', 'ga': 'Giniúint Incheadaithe le haghaidh Rianú Stáit Idirphlé', 'ka': 'დიალოგის სტატუსის მონაცემების შექმნა', 'hu': 'Módosítható generáció a párbeszéd állapotának nyomon követéséhez', 'el': 'Τροποποιημένη γενιά για παρακολούθηση κατάστασης διαλόγου', 'it': 'Generazione modificabile per il monitoraggio dello stato del dialogo', 'kk': 'Диалог күйін қадағалау үшін өзгертуі мүмкін', 'lt': 'Iš dalies keičiama dialogo būklės sekimo generacija', 'ms': 'Jenerasi Boleh Berubah untuk Pengjejak Keadaan Dialog', 'mk': 'Изменлива генерација за следење на состојбата на дијалогот', 'ml': 'ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്ക് ചെയ്യുന്നതിനുള്ള സജ്ജീകരണം', 'mt': 'Ġenerazzjoni Emendabbli għat-Traċċar tal-Istat tad-Djalogu', 'mn': 'Диалог тогтолцоонд шинэчлэх боломжтой бүтээл', 'ro': 'Generare modificabilă pentru urmărirea stării dialogului', 'sr': 'Изменима генерација за трагиране дјатеља диалога', 'pl': 'Zmienne generowanie dla śledzenia stanu dialogu', 'so': 'Generation for tracking of Dialog State', 'no': 'Endra generering for dialogtilstand', 'sv': 'Ändrbar generering för spårning av dialogtillstånd', 'ur': 'Dialog State Tracking کے لئے بدلنے والی پیدائش', 'ta': 'உரையாடல் நாட்டின் பின்பற்றிக்கு ஏற்படுத்தக்கூடிய உருவாக்கம்', 'si': 'Name', 'uz': 'Dialog holatini tahrirlash uchun yaratish', 'vi': 'Thế hệ mới sửa chữa định vị bang', 'bg': 'Променяемо генериране за проследяване на състоянието на диалога', 'hr': 'Promjenljiva generacija za praćenje države dijaloga', 'nl': 'Wijzigbare generatie voor het bijhouden van dialoogstatus', 'da': 'Ændrebar generering til sporing af dialogtilstand', 'de': 'Veränderbare Generation für die Verfolgung des Dialogstatus', 'id': 'Generasi yang bisa diubah untuk melacak keadaan dialog', 'ko': '대화 상태 추적 수정 가능 생성', 'fa': 'تولید قابل تغییر\u200cپذیر برای ردیابی وضعیت دیalog', 'sw': 'Kizazi kinachoendeshwa kwa ajili ya kufuatilia Taifa ya Dialogue', 'tr': 'Dälog Durum Nişary üçin üýtget', 'af': 'Veranderbare Generasie vir Dialoog Staat Volg', 'sq': 'Gjenerimi i ndryshueshëm për ndjekjen e gjendjes së dialogut', 'am': 'የውይይት መድረክ', 'az': 'Dialoog Eyaleti 캻zl톛m톛si 칲칞칲n Adland캼r캼labilir', 'hy': 'Comment', 'bn': 'ডায়ালগ স্টেট ট্র্যাকিং এর জন্য সংশোধনীয় প্রজন্ম', 'cs': 'Upravitelná generace pro sledování stavu dialogu', 'bs': 'Pomoćna generacija za praćenje države dijaloga', 'ca': "Generació canviable per a seguir l'estat del diàleg", 'et': 'Muudetav genereerimine dialoogi oleku jälgimiseks', 'fi': 'Muutettava sukupolvi dialogin tilan seurantaa varten', 'ha': '@ action', 'jv': 'General', 'he': 'יצור שינוי עבור מעקב מצב דיאלוג', 'sk': 'Spremenljiva generacija za sledenje stanju dialoga', 'bo': 'ཌའི་ལོག་གནས་སྟངས་རྗེས་ཀྱི་བསྒྱུར་བཅོས་བྱེད་རུང་བའི་བཟོ་བཅོས'}
{'en': 'In task-oriented dialogue systems, recent dialogue state tracking methods tend to perform one-pass generation of the dialogue state based on the previous dialogue state. The mistakes of these ', 'ar': 'في أنظمة الحوار الموجه نحو المهام ، تميل أساليب تتبع حالة الحوار الحديثة إلى أداء مرحلة واحدة لحالة الحوار بناءً على حالة الحوار السابقة. أخطاء هذه النماذج عند المنعطف الحالي عرضة للانتقال إلى المنعطف التالي ، مما يتسبب في انتشار الخطأ. في هذه الورقة ، نقترح جيلًا جديدًا قابل للتعديل لتتبع حالة الحوار (AG-DST) ، والذي يحتوي على عملية إنشاء ثنائية المسار: (1) إنشاء حالة حوار بدائية بناءً على حوار المنعطف الحالي وحالة الحوار السابقة و (2) تعديل حالة الحوار البدائية من المرور الأول. من خلال تمرير التوليد التعديلي الإضافي ، تم تكليف نموذجنا بمعرفة تتبع حالة حوار أكثر قوة من خلال تعديل الأخطاء التي لا تزال موجودة في حالة الحوار البدائي ، والتي تلعب دور المراجع في عملية التحقق المزدوج وتخفيف انتشار الخطأ غير الضروري. تظهر النتائج التجريبية أن AG-DST يتفوق بشكل كبير على الأعمال السابقة في مجموعتي بيانات DST نشطين (MultiWOZ 2.2 و WOZ 2.0) ، مما يحقق أداءً جديدًا على أحدث طراز.', 'pt': 'Em sistemas de diálogo orientados a tarefas, os métodos recentes de rastreamento de estado de diálogo tendem a realizar a geração de um passo do estado de diálogo com base no estado de diálogo anterior. Os erros desses modelos cometidos no turno atual são propensos a serem transportados para o próximo turno, causando propagação de erros. Neste artigo, propomos uma nova Geração Alterável para Rastreamento de Estado de Diálogo (AG-DST), que contém um processo de geração de duas passagens: (1) gerar um estado de diálogo primitivo baseado no diálogo do turno atual e do estado de diálogo anterior , e (2) alterando o estado de diálogo primitivo da primeira passagem. Com o passe de geração de alteração adicional, nosso modelo é encarregado de aprender um rastreamento de estado de diálogo mais robusto, corrigindo os erros que ainda existem no estado de diálogo primitivo, que desempenha o papel de revisor no processo de verificação dupla e alivia a propagação de erros desnecessária. Resultados experimentais mostram que AG-DST supera significativamente trabalhos anteriores em dois conjuntos de dados ativos de DST (MultiWOZ 2.2 e WOZ 2.0), alcançando novos desempenhos de última geração.', 'es': 'En los sistemas de diálogo orientados a tareas, los métodos recientes de seguimiento del estado de diálogo tienden a realizar la generación de un solo paso del estado de diálogo en función del estado de diálogo anterior. Los errores de estos modelos cometidos en el giro actual tienden a trasladarse al siguiente giro, provocando la propagación de errores. En este artículo, proponemos una nueva generación modificable para el seguimiento del estado del diálogo (AG-DST), que contiene un proceso de generación de dos pasos: (1) generar un estado de diálogo primitivo basado en el diálogo del turno actual y el estado de diálogo anterior, y (2) modificar el estado de diálogo primitivo del primera pasada. Con el pase de generación de enmiendas adicional, nuestro modelo tiene la tarea de aprender un seguimiento más sólido del estado del diálogo mediante la modificación de los errores que aún existen en el estado de diálogo primitivo, que desempeña el papel de revisor en el proceso de doble verificación y alivia la propagación innecesaria de errores. Los resultados experimentales muestran que AG-DST supera significativamente los trabajos anteriores en dos conjuntos de datos DST activos (MultiWOZ 2.2 y WOZ 2.0), logrando nuevos rendimientos de última generación.', 'fr': "Dans les systèmes de dialogue orientés tâches, les méthodes récentes de suivi de l'état du dialogue ont tendance à générer en un seul passage l'état de dialogue sur la base de l'état de dialogue précédent. Les erreurs de ces modèles commises lors du virage en cours sont susceptibles d'être reportées au virage suivant, ce qui entraîne une propagation des erreurs. Dans cet article, nous proposons une nouvelle génération modifiable pour le suivi de l'état du dialogue (AG-DST), qui contient un processus de génération en deux passes\xa0: (1) génération d'un état de dialogue primitif basé sur le dialogue du tournant actuel et de l'état de dialogue précédent, et (2) modification de l'état de dialogue primitif à partir de première passe. Avec la passe de génération de modification supplémentaire, notre modèle est chargé d'apprendre un suivi d'état de dialogue plus robuste en modifiant les erreurs qui existent encore dans l'état de dialogue primitif, qui joue le rôle de réviseur dans le processus de double vérification et évite la propagation inutile des erreurs. Les résultats expérimentaux montrent que l'AG-DST surpasse de manière significative les travaux précédents dans deux ensembles de données DST actifs (MultiWOZ 2.2 et WOZ 2.0), obtenant de nouvelles performances de pointe.", 'ja': 'タスク指向の対話システムでは、最近の対話状態追跡方法は、以前の対話状態に基づいて対話状態のワンパス生成を実行する傾向がある。 現在のターンで行われたこれらのモデルのミスは、次のターンに持ち越されやすく、エラーの伝播を引き起こします。 本稿では、(1)現在のターンのダイアログと以前のダイアログの状態に基づいて原始的なダイアログの状態を生成すること、(2)最初のパスから原始的なダイアログの状態を修正すること、の2パス生成プロセスを含む新規のAmendable Generation for Dialogue State Tracking (AG - DST)を提案する。 追加の修正ジェネレーションパスを使用して、当社のモデルは、ダブルチェックプロセスでリビジャーの役割を果たし、不必要なエラー伝播を緩和するプリミティブダイアログ状態にまだ存在するエラーを修正することによって、より堅牢なダイアログ状態追跡を学ぶことができます。 実験結果は、2つのアクティブなDSTデータセット（ MultiWOZ 2.2およびWoz 2.0 ）でAG - DSTが過去の作品を大幅に上回り、新たな最先端のパフォーマンスを実現していることを示しています。', 'zh': '向事之言统,近对之对法,向前之对一次性生。 其形在今曲处所犯之误易及下一转,以致差传。 本文中,新语踵(AG-DST),一再生成:(1)回合,与前对生对,(2)从初传改始对。 额外之改成道,吾之修原始,而学其强大,修其重者,轻其过也。 实验结果表明,AG-DST两跃之DST数集(MultiWOZ 2.2WOZ 2.0)显优前作,致新之先进也。', 'hi': 'कार्य-उन्मुख संवाद प्रणालियों में, हाल ही में संवाद राज्य ट्रैकिंग विधियां पिछले संवाद राज्य के आधार पर संवाद राज्य की एक-पास पीढ़ी का प्रदर्शन करती हैं। वर्तमान मोड़ पर किए गए इन मॉडलों की गलतियों को अगले मोड़ पर ले जाने की संभावना है, जिससे त्रुटि प्रसार होता है। इस पत्र में, हम संवाद राज्य ट्रैकिंग (एजी-डीएसटी) के लिए एक उपन्यास संशोधन योग्य पीढ़ी का प्रस्ताव करते हैं, जिसमें दो-पास पीढ़ी की प्रक्रिया होती है: (1) वर्तमान मोड़ और पिछले संवाद राज्य के संवाद के आधार पर एक आदिम संवाद राज्य उत्पन्न करना, और (2) पहले पास से आदिम संवाद राज्य को संशोधित करना। अतिरिक्त संशोधन पीढ़ी पास के साथ, हमारे मॉडल को उन त्रुटियों को संशोधित करके अधिक मजबूत संवाद राज्य ट्रैकिंग सीखने का काम सौंपा गया है जो अभी भी आदिम संवाद राज्य में मौजूद हैं, जो डबल-चेकिंग प्रक्रिया में संशोधनकर्ता की भूमिका निभाता है और अनावश्यक त्रुटि प्रसार को कम करता है। प्रयोगात्मक परिणामों से पता चलता है कि एजी-डीएसटी दो सक्रिय डीएसटी डेटासेट (MultiWOZ 2.2 और WOZ 2.0) में पिछले कार्यों को काफी हद तक बेहतर बनाता है, नए अत्याधुनिक प्रदर्शन प्राप्त करता है।', 'ru': 'В системах диалога, ориентированных на решение конкретных задач, методы отслеживания состояния диалога в последнее время, как правило, выполняют генерацию состояния диалога в один проход на основе предыдущего состояния диалога. Ошибки этих моделей, сделанные на текущем повороте, склонны переноситься на следующий поворот, вызывая распространение ошибок. В этой статье мы предлагаем новое поколение с поправками для отслеживания состояния диалога (AG-DST), которое содержит двухпроходной процесс генерации: (1) генерирование примитивного состояния диалога на основе диалога текущего хода и предыдущего состояния диалога, и (2) изменение примитивного состояния диалога с первого прохода. С дополнительным пропуском генерации поправок нашей модели поручено изучить более надежное отслеживание состояния диалога путем исправления ошибок, которые все еще существуют в примитивном состоянии диалога, который играет роль редактора в процессе двойной проверки и облегчает ненужное распространение ошибок. Экспериментальные результаты показывают, что AG-DST значительно превосходит предыдущие работы в двух активных наборах данных DST (MultiWOZ 2.2 и WOZ 2.0), достигая новых современных показателей.', 'ga': 'I gcórais dialóige atá dírithe ar thascanna, is gnách go bhfeidhmíonn modhanna rianaithe stáit idirphlé le déanaí giniúint aon-pas de staid an chomhphlé bunaithe ar staid an chomhphlé roimhe seo. Is dóichí go dtabharfar anonn go dtí an chéad chasadh eile botúin na múnlaí seo a dhéantar ag an gcas reatha, rud a fhágann iomadú earráide. Sa pháipéar seo, molaimid Giniúint Incheadaithe le haghaidh Rianú Stáit Idirphlé (AG-DST), ina bhfuil próiseas giniúna dhá phas: (1) staid idirphlé primitive a ghiniúint bunaithe ar an idirphlé ar an cas reatha agus ar staid an chomhphlé roimhe seo. , agus (2) ag leasú staid an chomhphlé primitive ón gcéad pas. Leis an pas giniúna leasaitheach breise, tá sé de chúram ar ár múnla rianú stáit idirphlé níos láidre a fhoghlaim trí na hearráidí atá fós ann sa stát idirphlé primitive a leasú, a imríonn ról an athbhreithneora sa phróiseas seiceála dúbailte agus a mhaolaíonn iomadú earráide gan ghá. Léiríonn torthaí turgnamhacha go sáraíonn AG-DST saothair roimhe seo go mór in dhá thacar sonraí gníomhacha DST (MultiWOZ 2.2 agus WOZ 2.0), ag baint amach léirithe nua den scoth.', 'hu': 'A feladatorientált párbeszédrendszerekben a legújabb párbeszédállapot nyomon követési módszerek hajlamosak a párbeszédállapot egymenetes generálására az előző párbeszédállapot alapján. Ezeknek a modelleknek az aktuális fordulóban elkövetett hibái hajlamosak a következő fordulóra átvinni, ami hiba terjedését okozza. Ebben a tanulmányban egy új, módosítható generációt javasolunk a párbeszédállapot nyomon követésére (AG-DST), amely egy kétlépcsős generációs folyamatot tartalmaz: (1) az aktuális fordulat és az előző párbeszédállapot párbeszédén alapuló primitív párbeszédállapot kialakítása, valamint (2) a primitív párbeszédállapot módosítása az első átjárástól. A további módosító generációs belépővel modellünk feladata, hogy erőteljesebb párbeszédállapot-nyomon követést tanuljunk a primitív párbeszédállapotban még fennálló hibák módosítása révén, amely a kettős ellenőrzési folyamatban felülvizsgáló szerepet játszik, és enyhíti a felesleges hibaterjedést. Kísérleti eredmények azt mutatják, hogy az AG-DST jelentősen felülmúlja a korábbi munkákat két aktív DST adatkészletben (MultiWOZ 2.2 és WOZ 2.0), így új, korszerű teljesítményt ér el.', 'el': 'Στα συστήματα διαλόγου προσανατολισμένα προς την εργασία, οι πρόσφατες μέθοδοι παρακολούθησης κατάστασης διαλόγου τείνουν να εκτελούν παραγωγή μιας κατάστασης διαλόγου με βάση την προηγούμενη κατάσταση διαλόγου. Τα λάθη αυτών των μοντέλων που γίνονται στην τρέχουσα στροφή είναι επιρρεπείς να μεταφερθούν στην επόμενη στροφή, προκαλώντας διάδοση σφαλμάτων. Στην παρούσα εργασία, προτείνουμε μια νέα τροποποιημένη γενιά για παρακολούθηση κατάστασης διαλόγου (η οποία περιέχει μια διαδικασία δημιουργίας δύο περάσεων: (1) δημιουργία μιας πρωτόγονης κατάστασης διαλόγου βασισμένης στο διάλογο της τρέχουσας στροφής και της προηγούμενης κατάστασης διαλόγου, και (2) τροποποίηση της πρωτόγονης κατάστασης διαλόγου από την πρώτη μετάβαση. Με το πρόσθετο πέρασμα τροποποίησης γενιάς, το μοντέλο μας έχει ως αποστολή να μάθει πιο ισχυρή παρακολούθηση κατάστασης διαλόγου τροποποιώντας τα σφάλματα που εξακολουθούν να υπάρχουν στην πρωτόγονη κατάσταση διαλόγου, η οποία διαδραματίζει το ρόλο του αναθεωρητή στη διαδικασία διπλού ελέγχου και ανακουφίζει την περιττή διάδοση σφαλμάτων. Τα πειραματικά αποτελέσματα δείχνουν ότι η AG-DST ξεπερνά σημαντικά τα προηγούμενα έργα σε δύο ενεργά σύνολα δεδομένων DST (MultiWOZ 2.2 και WOZ 2.0), επιτυγχάνοντας νέες επιδόσεις τελευταίας τεχνολογίας.', 'it': "Nei sistemi di dialogo orientati alle attività, i recenti metodi di monitoraggio dello stato di dialogo tendono ad eseguire la generazione in un passaggio dello stato di dialogo basato sullo stato di dialogo precedente. Gli errori di questi modelli fatti al turno corrente sono inclini a essere riportati al turno successivo, causando propagazione degli errori. In questo articolo, proponiamo una nuova generazione modificabile per il monitoraggio dello stato di dialogo (AG-DST), che contiene un processo di generazione in due passaggi: (1) generare uno stato di dialogo primitivo basato sul dialogo della svolta corrente e dello stato di dialogo precedente, e (2) modificare lo stato di dialogo primitivo dal primo passaggio. Con l'ulteriore passaggio di generazione modificante, il nostro modello ha il compito di imparare un monitoraggio più solido dello stato di dialogo modificando gli errori che ancora esistono nello stato di dialogo primitivo, che svolge il ruolo di revisore nel processo di doppio controllo e allevia la propagazione inutile degli errori. I risultati sperimentali mostrano che AG-DST supera significativamente i lavori precedenti in due set di dati DST attivi (MultiWOZ 2.2 e WOZ 2.0), ottenendo nuove prestazioni all'avanguardia.", 'lt': 'Į užduotis orientuotų dialogo sistemų metu naujausi dialogo valstybės stebėjimo metodai paprastai atlieka vienkartinę dialogo valstybės kartą, pagrįstą ankstesne dialogo būkle. Šių modelių klaidos, padarytos dabartiniu apsisukimu, greičiausiai bus perkeltos į kitą apsisukimą ir sukelia klaidų plitimą. Šiame dokumente siūlome naują iš dalies keičiamą dialogo valstybės sekimo kartą (AG-DST), kurioje dalyvauja dviejų kartų procesas: 1) pirminio dialogo valstybės sukūrimas, pagrįstas dabartinio posūkio ir ankstesnio dialogo valstybės dialogu, ir 2) pirminio dialogo valstybės pakeitimas nuo pirmojo posūkio. Papildomos kartos pakeitimo patvirtinimu mūsų modelio užduotis – išmokti patikimesnį dialogo būklės sekimą iš dalies keičiant klaidas, kurios vis dar egzistuoja pirminio dialogo būklėje, kuri atlieka peržiūrėtojo vaidmenį dvigubo tikrinimo procese ir palengvina nereikalingą klaidų plitimą. Eksperimentiniai rezultatai rodo, kad AG-DST gerokai viršija ankstesnius darbus dviejuose aktyviuose DST duomenų rinkiniuose (MultiWOZ 2.2 ir WOZ 2.0), siekiant naujų pažangiausių rezultatų.', 'kk': 'Тапсырма бағытталған диалог жүйелерінде, жаңа диалог күйін қадағалау әдістері алдыңғы диалог күйіне негізделген диалог күйінің бір- бірін құру әдістерін жасайд Қолданыстағы өзгертілген моделдердің қатесі келесі өзгертілген, қате пропагациясы болады. Бұл қағазда, диалог күйін қадағалау (AG- DST) үшін түзету мүмкіндігін жасауға мүмкіндік беретін жасау процесін ұсынамыз: (1) қазіргі диалог диалогының диалогының негізінде, алдыңғы диалог күйіне негізінде, алдыңғы диалог күйін өзгерт Қосымша өзгерту үшін, біздің үлгіміз қосымша диалог күйін қадағалау үшін, әлі қателерді алғашқы диалог күйінде өзгертіп, қос тексеру процесінде редакцияның рөлін ойнатып, қателерді өзгертуге болады. Эксперименталдық нәтижелер AG-DST екі белсенді DST деректер қорларында (MultiWOZ 2.2 және WOZ 2.0) алдыңғы жұмыс істеу үшін әсер етеді.', 'ka': 'პარამეტრების დიალოგის სისტემებში, ახლა დიალოგის სტატის მონაცემების მეტოვებში დიალოგის სტატის ერთონაცემის შემდეგ გავაკეთება. ამ მოდელების შეცდომაები, რომლებიც მიმდინარე შემდეგ გადატანა, შეცდომა პროგრაციაში. ამ დომენტში ჩვენ მინდა დიალოგის სტატის მონაცემების პროცესი (AG-DST) პროცესი, რომელიც მხოლოდ ოროდან განვითარება პრიმიტიური დიალოგის სტატის განვითარება მიმდინარეობის და წინა დიალოგის სტატის განვითარებაზე და (2) პრიმიტიური დიალ დამატებული შეცვლელების შეცვლელების გადასვლა, ჩვენი მოდელი უფრო ძალიან დიალოგის შეცვლელების შეცვლელებით, რომლებიც პრიმიტიური დიალოგის სტაციაში არსებობს, რომელიც ორივე შეცვლელების პროცესის პროცესის პროცესის პროც ექსპერიმენტიური შედეგი ჩვენებს, რომ AG-DST მნიშვნელოვანად უფრო მეტად გავაკეთებს წინა ორი აქტიური DST მონაცემების კონფიგურაციაში (MultiWOZ 2.2 და WOZ 2.0) და ახალი მონაცემების შედეგი', 'ml': 'പ്രവര്\u200dത്തിപ്പിക്കുന്ന ഡയലോഗ് സിസ്റ്റമില്\u200d, അടുത്ത ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്കിങ്ങ് രീതികള്\u200d മുമ്പ് ഡയലോഗ് സ്റ്റേറ്റ്  ഇപ്പോഴത്തെ തിരിച്ചുകൊണ്ടിരിക്കുന്ന ഈ മോഡലുകളുടെ തെറ്റുകള്\u200d അടുത്ത തിരിയിലേക്ക് കൊണ്ടുപോകുന്നതാണ്. പ ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്കിങ്ങിനുള്ള ഒരു നോവല്\u200d മാറ്റുന്നതിനുള്ള പ്രക്രിയയുണ്ട്: (1) നിലവിലുള്ള തിരിച്ചറിയുന്നതിനും മുമ്പുള്ള ഡയലോഗ് സ്റ്റേറ്റില്\u200d അട കൂടുതല്\u200d മാറ്റം വരുത്തുന്ന തലമുറയുടെ പാസ്സില്\u200d നമ്മുടെ മോഡല്\u200d കൂടുതല്\u200d റോബോസ്റ്റ് ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്കിങ്ങ് പഠിക്കാന്\u200d ശ്രമിക്കുന്നു. പ്രൈമിറ്റിവ്  പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു പുതിയ ഡിസ്റ്റ് ഡാറ്റാസറ്റുകളില്\u200d മുമ്പുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രധാനപ്പെടുത്തുന്നത് AG-DST പ്രധാന', 'mk': 'Во дијалошките системи ориентирани на задачите, неодамнешните дијалошки методи за следење на состојбата имаат тенденција да спроведат генерација на една паса на состојбата на дијалог базирана на претходната дијалошка Грешките на овие модели направени во моменталниот круг се пренесени на следниот круг, предизвикувајќи проширување грешки. In this paper, we propose a novel Amendable Generation for Dialogue State Tracking (AG-DST), which contains a two-pass generation process: (1) generating a primitive dialogue state based on the dialogue of the current turn and the previous dialogue state, and (2) amending the primitive dialogue state from the first pass.  Со дополнителната промена на генерацијата, нашиот модел е задолжен да научи посилно следење на состојбата на дијалогот со измена на грешките кои сé уште постојат во примитивната состојба на дијалогот, која ја игра улогата на ревизионер во процесот на двојно проверка и ја олесни непотребната пропага Експерименталните резултати покажуваат дека AG-DST значително ги надминува претходните дела во две активни податоци на DST (МултиWOZ 2.2 и WOZ 2.0), постигнувајќи нови најсовремени претстави.', 'mt': 'F’sistemi ta’ djalogu orjentati lejn ix-xogħol, il-metodi reċenti ta’ djalogu dwar it-traċċar tal-istat għandhom it-tendenza li jwettqu ġenerazzjoni ta’ pass wieħed tal-istat ta’ djalogu bbażat fuq l-istat ta’ djalogu preċedenti. L-iżbalji ta’ dawn il-mudelli li saru fid-dawl attwali huma suxxettibbli li jinġarru fid-dawl li jmiss, u jikkawżaw propagazzjoni ta’ żbalji. F’dan id-dokument, qed nipproponu Ġenerazzjoni Emendabbli ġdida għat-Traċċar tal-Istat tad-Djalogu (AG-DST), li fiha proċess ta’ ġenerazzjoni b’żewġ passi: (1) li tiġġenera stat ta’ djalogu primitiv ibbażat fuq id-djalogu tad-dawra attwali u l-istat ta’ djalogu preċedenti, u (2) li temenda l-istat ta’ djalogu primitiv mill-ewwel pass. Bil-pass addizzjonali tal-ġenerazzjoni emendatorja, il-mudell tagħna għandu l-kompitu li jitgħallem traċċar tal-istat tad-djalogu aktar b’saħħtu billi jiġu emendati l-iżbalji li għadhom jeżistu fl-istat tad-djalogu primitiv, li għandu r-rwol ta’ reviżur fil-proċess ta’ verifika doppja u jtaffi l-propagazzjoni ta’ żbalji mhux meħtieġa. Riżultati esperimentali juru li AG-DST qed twettaq xogħlijiet preċedenti b’mod sinifikanti f’żewġ settijiet ta’ dejta DST attivi (MultiWOZ 2.2 u WOZ 2.0), li jiksbu prestazzjonijiet ġodda tal-aħħar.', 'ms': 'Dalam sistem dialog bertujuan tugas, kaedah pengesan keadaan dialog baru-baru ini cenderung melakukan generasi satu-pass keadaan dialog berdasarkan keadaan dialog terdahulu. Kesalahan model ini dibuat pada giliran semasa adalah cenderung untuk dibawa ke giliran berikutnya, menyebabkan penyebaran ralat. Dalam kertas ini, kami cadangkan Generasi Boleh Berubah untuk Pengjejak Negara Dialog (AG-DST), yang mengandungi proses generasi dua-pass: (1) menghasilkan keadaan dialog primitif berdasarkan dialog giliran semasa dan keadaan dialog sebelumnya, dan (2) mengubah keadaan dialog primitif dari laluan pertama. Dengan pemindahan generasi tambahan, model kami ditugaskan untuk belajar pengesan keadaan dialog yang lebih kuat dengan mengubah ralat yang masih wujud dalam keadaan dialog primitif, yang memainkan peran penyulit dalam proses pemeriksaan ganda dan mengurangkan penyebaran ralat yang tidak diperlukan. Experimental results show that AG-DST significantly outperforms previous works in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new state-of-the-art performances.', 'mn': 'Тайлбарт дамжуулан диалог системд, саяхан диалог байр суурь дамжуулах арга нь өмнөх диалог байр суурь дээр диалог байр суурилсан нэг дамжуулах байр сууриллагааг хийдэг. Энэ загваруудын алдаа дараагийн эргэлтэй рүү дамжуулж буй загварууд алдаа хөгжүүлэх боломжтой. Энэ цаасан дээр бид Диалог улсын дагуулах (AG-DST) болон хоёр дагуулах үйлдвэрлэлийн шинэ шинэчлэл дэвшүүлэх боломжийг санал болгож байна. Энэ нь одоогийн эргэлтийн болон өмнөх диалогын байр суурь дээр эхний диалогын төлөвлөгөөс үндсэн анхны диалогын байр суурь болон (2) түүний Дараагийн шинэчлэлтийн үеийнхээ хувьд бидний загвар нь хоёр дахин шалгах үйл явцдаа шинэчлэгчийн дүр зураг болон хэрэггүй алдаа дэвшүүлэхэд илүү хүчтэй диалог байр суралцах зорилго юм. Түүний туршилтын үр дүнд AG-DST хоёр актив DST өгөгдлийн санд (MultiWOZ 2.2 болон WOZ 2.0), шинэ урлагийн үйл ажиллагааг гаргаж чаддаг гэдгийг харуулж байна.', 'no': 'I oppgåveorienterte dialogsystemet er det vanleg å utføra førre dialogtilstandsmetoder for å spora ein passar av dialogtilstanden basert på den førre dialogtilstanden. Feilene på desse modelane som er lagt på gjeldande snu er nøyaktig å flyttast til neste snu, som fører til feilpropagasjon. I denne papiret foreslår vi eit nytt generering for dialogtilstand-sporing (AG-DST), som inneheld ein to-pass-genereringsprosess: (1) som lagar ein primitivt dialogtilstand basert på dialogen for gjeldande snøt og den førre dialogtilstanden, og (2) endrar primitivt dialogtilstanden frå første pass. Med den nye genereringa, er modellen vårt oppgåve for å lære meir sterkt dialogsporing ved å endra feilen som fortsatt finst i den primære dialogtilstanden, som speler rollen av revisoren i prosessen med dobbeltkontroll og reduserer unngåve feilpropagasjon. Eksperimentale resultat viser at AG-DST utfører tidlegare arbeid i to aktive DST-datasett (MultiWOZ 2.2 og WOZ 2.0) og når det gjer nye kunsthandlingar.', 'pl': 'W systemach dialogu zorientowanego na zadania, najnowsze metody śledzenia stanu dialogu mają tendencję do generowania jednoosobowego stanu dialogu w oparciu o poprzedni stan dialogu. Błędy tych modeli popełnione na bieżącym zakręcie są podatne na przeniesienie na kolejny zakręt, powodując rozprzestrzenianie się błędów. W niniejszym artykule proponujemy nową zmieniającą generację dla śledzenia stanu dialogu (AG-DST), która zawiera proces generowania dwuprzepustowego: (1) generowania prymitywnego stanu dialogu opartego na dialogu bieżącego i poprzedniego stanu dialogu oraz (2) zmianę stanu dialogu prymitywnego od pierwszego przejścia. Dzięki dodatkowemu przepustowi generacji zmieniającemu nasz model ma za zadanie nauczyć się bardziej solidnego śledzenia stanu dialogu poprzez zmianę błędów, które nadal istnieją w prymitywnym stanie dialogu, który odgrywa rolę korektora w procesie podwójnej kontroli i łagodzi niepotrzebne propagowanie błędów. Wyniki eksperymentalne pokazują, że AG-DST znacznie przewyższa poprzednie prace w dwóch aktywnych zestawach danych DST (MultiWOZ 2.2 i WOZ 2.0), osiągając nowe, najnowocześniejsze osiągnięcia.', 'ro': 'În sistemele de dialog orientate spre sarcini, metodele recente de urmărire a stării dialogului tind să realizeze generarea cu o singură trecere a stării dialogului bazată pe starea anterioară a dialogului. Greșelile acestor modele făcute la virajul curent sunt predispuse să fie transferate la virajul următor, cauzând propagarea erorilor. În această lucrare, propunem o nouă generație modificabilă pentru urmărirea stării dialogului (AG-DST), care conține un proces de generare în două treceri: (1) generarea unei stări primitive de dialog bazată pe dialogul curentului și starea dialogului anterior și (2) modificarea stării dialogului primitiv de la prima trecere. Cu trecerea suplimentară de modificare a generației, modelul nostru este însărcinat să învețe urmărirea mai robustă a stării de dialog prin modificarea erorilor care încă există în starea de dialog primitiv, care joacă rolul de revizor în procesul de dublă verificare și atenuează propagarea inutilă a erorilor. Rezultatele experimentale arată că AG-DST depășește semnificativ lucrările anterioare în două seturi de date DST active (MultiWOZ 2.2 și WOZ 2.0), obținând noi performanțe de ultimă generație.', 'sr': 'U sistemima dijaloga orijentiranih na zadatke, nedavne metode praćenja država dijaloga navode da izvrše jednu prošlost generacije države dijaloga na temelju prethodnog stanja dijaloga. Greške ovih modela koji su napravljeni u trenutnom okretu su spremne da se prebace na sledeći okret, uzrokujući propagaciju greška. U ovom papiru predlažemo novu izmjenu generacije za praćenje država dijaloga (AG-DST), koja sadrži proces generacije dva prolaza: (1) stvaranja primitivnog stanja dijaloga baziranog na dijalogu trenutnog okreta i prethodnog stanja dijaloga, i (2) izmjena primitivnog stanja dijaloga iz prvog prolaza. Uz dodatnu prošlost generacije izmjene, naš model je zadatak da naučimo jače praćenje država dijaloga izmjenom grešaka koja još uvijek postoje u primitivnom dijalogu, koja igra ulogu revizira u procesu dvostrukog provjere i smanjuje nepotrebnu propagaciju grešaka. Eksperimentalni rezultati pokazuju da AG-DST značajno iznosi prethodne delove u dve aktivne DST datasete (MultiWOZ 2.2 i WOZ 2.0), ostvarivši nove postupke umjetnosti.', 'si': 'සංවාද පද්ධතියෙන්, අලුත් සංවාද පරීක්ෂණ විධානයේ සංවාද පද්ධතියෙන් සංවාද ස්ථානය ප්\u200dරවෘතියෙන් ප මේ මොඩේල් එකේ වැරැද්ද වැරැද්ද වෙලා තියෙන්නේ පස්සේ වැරැද්ද වැරැද්ද වැරැද්ද වෙන්න. In this papers, we preach a new Amideble General for dialog state tracing (AG-DST), that has a 2-pass generation process: (1) generousing a primitive dialog state on the base of the ongoing turn and the preceding dialog state, and (2) mending the primitive dialog state from the first pass. තවත් ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා, අපේ මොඩල් වැඩිය හැකියා තවත් ශක්තිමත් සංවාද ස්ථානය පරීක්ෂණය සඳහා ප්\u200dරමාණය සංවාද ස්ථානයේ තියෙන දෝෂාවක් වි පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ AG-DST විශේෂයෙන් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ප්\u200dරතිච', 'so': 'Isticmaalka dialogka ee shaqo-oriented waxaa lagu sameeyaa qaababka ku socda dowladda ee ugu dambeeya oo ku saleysan dowladda hore. Xaaladaha modelladan ee lagu sameeyo marka hore waxaa loo caddeeyaa in loo wado bedelka soo socda, sababtoo ah in lagu ogeysiiyo qalad. Qoraalkan waxaan ka soo jeedaynaa qoraal u bedelanaya Generation for Dialogue State Tracking (AG-DST), kaas oo ku jirta jarayo laba-pass-process: (1) oo sameynaya dowlad asal ah oo ku saleysan dialog ku qoran labada jeer ah iyo dowlad hore, iyo (2) in lagu beddelo xaaladda dialog-primitive ka soo baxdo baasabkii ugu horraysay. Marka uu soo dhaafo qarniga beddelka ah, waxaa lagu qasbaa in modellkayaga la barto si ka badan oo la soconayo dowladda gobolka ee robotiisa lagu hagaajiyo qaladka weli ku jirta dowladda hoose, kaas oo ka qayb gala bedelka xiliga labada jeer-baaritaanka, wuxuuna fududeeyaa ogeysiiska baahida aan u baahnayn. Imtixaanka waxaa ka muuqda in AG-DST si muhiim ah u sameeyaa shaqaalaha hore oo ka mid ah labada xafiiska shaqada ee active DST (MultiWOZ 2.2 iyo WOZ 2.0), oo dhamaystiraya tababaro cusub-of-the-art.', 'sv': 'I uppgiftsorienterade dialogsystem tenderar de senaste metoderna för spårning av dialogtillstånd att generera dialogtillståndet med en gång baserat på föregående dialogtillstånd. Misstagen i dessa modeller som görs vid den aktuella svängen är benägna att föras över till nästa sväng, vilket orsakar felspridning. I denna uppsats föreslår vi en ny Ändrbar Generation for Dialogue State Tracking (AG-DST), som innehåller en två-pass generationsprocess: (1) generera ett primitivt dialogtillstånd baserat på dialogen i nuvarande sväng och föregående dialogtillstånd, och (2) ändra det primitiva dialogtillståndet från första gången. Med den extra ändringsgeneration pass har vår modell i uppgift att lära sig mer robust dialogtillståndsspårning genom att ändra de fel som fortfarande finns i det primitiva dialogtillståndet, som spelar rollen som granskare i dubbelkontrollprocessen och lindrar onödig felspridning. Experimentella resultat visar att AG-DST avsevärt överträffar tidigare arbeten i två aktiva DST-dataset (MultiWOZ 2.2 och WOZ 2.0), vilket ger nya toppmoderna prestanda.', 'ur': 'تابع-oriented диалог سیسٹموں میں، اگلے диалог سٹیٹ ٹراکینگ طریقوں میں ایک پاس پیدا کرنے کے لئے پہلے диалог سٹیٹ پر بنیاد رکھتا ہے. ان موڈلوں کی خطائیں ہیں جو موجود بار میں بنائے گئے ہیں ان کی آگئی بار تک پہنچائی جاتی ہیں، اور گمراہی پھیلانے کی وجہ سے ہے. اس کاغذ میں ہم ایک نئی بدلنے والی نسل ڈالیلوگ سٹیٹ ترکینگ (AG-DST) کے لئے پیشنهاد کرتے ہیں، جس میں دو پاس نسل پروسس ہے: (1) ایک نئی ڈالیلوگ سٹیٹ پیدا کرتا ہے جو موجود ویرٹ اور پہلے ڈالیلوگ سٹیٹ کے ڈالیوں پر بنیاد ہے، اور (2) پہلی پاس سے نئی ڈالیلوگ سٹی اضافہ تغییر کی نسل پھس کے ساتھ، ہماری مدل کو زیادہ مضبوط دیالوگ کی حالت ترکینگ کی سیکھنے کے لئے کام کی جاتی ہے، جو ابھی پہلی دیالوگ کی حالت میں بھی موجود ہیں، جو دوبل-چک کی پروسس میں ریویڈر کا رول لگا رہا ہے اور بے نیاز خطا پھیلانے کو کمزور کرتا ہے. آزمائش نتیجے دکھاتے ہیں کہ AG-DST دو فعال DST ڈیٹ سٹ میں پہلے کاروں کو بہت اضافہ کرتا ہے (MultiWOZ 2.2 اور WOZ 2.0) اور نئی ایرٹ کے مطابق پہنچاتا ہے.', 'ta': 'பணியில் சேர்ந்த உரையாடல் முறைமைகளில், சமீபத்தில் உரையாடல் நிலை பின்பற்றும் முறைமையில் முந்தைய உரையாடல் நிலையை அடிப்படையி தற்போதைய முறையில் செய்யப்பட்ட இந்த மாதிரிகளின் பிழைகள் அடுத்த முறைக்கு செலுத்தப்பட்டுள்ளது, பிழை வெளிப்படு இந்த காகிதத்தில், நாம் உரையாடல் நாட்டு பின்பற்றிய புதிய உருவாக்கத்தை உருவாக்குவதற்கு (AG- DST), அதில் இரண்டு கடந்து செல்லும் உரையாடல் செயல்பாடு: (1) தற்போதைய முறையில் உள்ள உரையாடல் பெட கூடுதல் மாற்றுதல் தலைமுறை கடந்து, எங்கள் மாதிரி மாதிரி உரையாடல் நிலையை மாற்றி முதல் உரையாடல் நிலையில் இருக்கும் பிழைகளை மாற்றி முதல் உரையாடல் நிலையில் இருக்கும் பிழ முயற்சி முடிவுகள் AG- DST முந்தைய செயல்களை இரண்டு செயல்படுத்தும் DST தகவல் அமைப்புகளில் முந்தைய செயல்பாடுகளை வெளியேற்றுகிறது என்பதை காட்டுகிறது (MultiWOZ', 'uz': 'Vazifani yaratib boʻlgan dialog tizimida, yangi oyna davom etish usullari oldingi oyna asosida yaratilgan dialog holatining bir marta yozma taʼminlovchisi. @ info Bu hujjatda, biz ikki marta yaratish jarayoni (AG- DST) yaratish uchun tugma yaratishni davom qilamiz: (1) Joriy oyna va oldingi oyna muloqat oynasida yaratish asosiy muloqat oynasini yaratish va (2) birinchi marta boshqa muloqat holatini oʻzgartirish. With the additional amending generation pass, our model is tasked to learn more robust dialogue state tracking by amending the errors that still exist in the primitive dialogue state, which plays the role of reviser in the double-checking process and alleviates unnecessary error propagation.  Name', 'vi': 'Trong hệ thống đối thoại hướng dẫn nhiệm vụ, các phương pháp theo dõi quốc gia đối thoại gần đây có xu hướng thực hiện sản phẩm kênh liên lạc một chiều dựa trên bang trước. Những sai lầm của những mô hình này xảy ra ở khúc cua hiện tại dễ bị chuyển qua khúc tiếp theo gây ra lỗi lan truyền. Trong bài báo này, chúng tôi đề xuất một thế hệ mới đáng xem xét việc theo dõi quốc gia liên lạc (AG-DST), gồm cả một quy trình sản sinh hai lần: 1) tạo ra một trạng thái cuộc đối thoại nguyên thủy dựa trên cuộc đối thoại giữa giai đoạn hiện tại và giai đoạn đối thoại trước, và 2) thay đổi trạng thái cuộc đối thoại nguyên thủy ngay từ lần đầu tiên. Với giấy phép tạo đổi mới, mẫu của chúng tôi được giao nhiệm vụ tìm hiểu tình trạng cuộc đối thoại vững chắc hơn bằng cách thay đổi những lỗi vẫn còn trong trạng thái cuộc đối thoại nguyên sơ, đóng vai trò người kiểm tra trong quá trình kiểm soát kép và giảm đi việc trục xuất lỗi không cần thiết. Các kết quả thử nghiệm cho thấy là A-DST hoàn thiện bản trước khá nhiều trong hai bộ dữ liệu DSS (MulWOZ 2.2 và WOZ 2.0) đã đạt được những trình độ mới nhất.', 'bg': 'В системите за диалог, ориентирани към задачи, последните методи за проследяване на състоянието на диалога са склонни да изпълняват еднократно генериране на състоянието на диалога въз основа на предишното състояние на диалога. Грешките на тези модели, направени при текущия завой, са склонни да бъдат пренесени към следващия завой, причинявайки разпространение на грешките. В настоящата статия предлагаме ново изменяемо поколение за проследяване на състоянието на диалога (което съдържа процес на генериране в два хода: (1) генериране на примитивно състояние на диалог въз основа на диалога на текущия завой и предишното състояние на диалога, и (2) изменение на примитивното състояние на диалога от първия ход. С допълнителния пропуск за генериране на изменения, нашият модел е натоварен да научи по-стабилно проследяване на състоянието на диалога чрез изменение на грешките, които все още съществуват в примитивното състояние на диалог, което играе ролята на ревизатор в процеса на двойна проверка и облекчава ненужното разпространение на грешки. Експерименталните резултати показват, че значително превъзхожда предишните произведения в два активни масива от данни за DST (MultiWOZ 2.2 и WOZ 2.0), постигайки нови съвременни изпълнения.', 'hr': 'U sustavima dijaloga orijentiranih na zadatke, nedavne metode praćenja država dijaloga tendencije izvršavaju jedinstvenu generaciju stanja dijaloga na temelju prethodnog stanja dijaloga. Greške ovih modela koji su napravljeni na trenutnom okretu su sklone da se prebace na sljedeći okret, uzrokujući propagaciju greška. U ovom papiru predlažemo novu izmjenu generacije za praćenje država dijaloga (AG-DST), koja sadrži proces generacije dvoprolaza: (1) stvaranje primitivnog dijaloga na temelju dijaloga trenutnog okreta i prethodnog stanja dijaloga, i (2) izmjena primitivnog dijaloga iz prvog prolaza. Uz dodatnu prošlost generacije izmjene, naš model je zadatak naučiti jače praćenje stanja dijaloga izmjenom grešaka koja još uvijek postoje u primitivnom dijalogu, koja igra ulogu revizira u procesu dvostrukog provjere i smanjuje nepotrebnu propagaciju grešaka. Eksperimentalni rezultati pokazuju da AG-DST značajno iznosi prethodne djela u dvije aktivne DST podatke (MultiWOZ 2.2 i WOZ 2.0), ostvarivši nove postupke umjetnosti.', 'nl': 'In taakgerichte dialoogsystemen hebben recente methoden voor het bijhouden van de dialoogstatus de neiging de dialoogstatus in één keer te genereren op basis van de vorige dialoogstatus. De fouten van deze modellen die in de huidige bocht worden gemaakt, kunnen worden overgedragen naar de volgende bocht, waardoor fouten zich verspreiden. In dit artikel stellen we een nieuwe Amendable Generation for Dialogue State Tracking (AG-DST) voor, die een tweepas generatieproces bevat: (1) het genereren van een primitieve dialoogstaat gebaseerd op de dialoog van de huidige beurt en de vorige dialoogstaat, en (2) het wijzigen van de primitieve dialoogstaat vanaf de eerste pas. Met de aanvullende wijzigingsgeneratiepas wordt ons model belast met het leren van robuustere monitoring van dialoogstaten door de fouten te wijzigen die nog steeds bestaan in de primitieve dialoogtoestand, die de rol van revisor speelt in het dubbele controleproces en onnodige foutverspreiding verlicht. Experimentele resultaten tonen aan dat AG-DST de vorige werken in twee actieve DST datasets (MultiWOZ 2.2 en WOZ 2.0) aanzienlijk overtreft en nieuwe state-of-the-art prestaties behaalt.', 'da': 'I opgaveorienterede dialogsystemer har de seneste metoder til sporing af dialogtilstande tendens til at udføre en-passgenerering af dialogtilstanden baseret på den tidligere dialogtilstand. Fejlene i disse modeller begået ved den nuværende sving er tilbøjelige til at blive overført til næste sving, hvilket forårsager fejludbredelse. I denne artikel foreslår vi en ny ændret generation for dialog stat tracking (AG-DST), som indeholder en to-trins generationsproces: (1) generering af en primitiv dialog tilstand baseret på dialogen i den nuværende drejning og den tidligere dialog tilstand, og (2) ændring af den primitive dialog tilstand fra første gang. Med den ekstra ændringsgeneration pass, vores model har til opgave at lære mere robust dialog tilstand sporing ved at ændre de fejl, der stadig findes i den primitive dialog tilstand, som spiller rollen som revisor i dobbeltkontrolprocessen og lindrer unødvendig fejlspredning. Eksperimentelle resultater viser, at AG-DST yder betydeligt bedre end tidligere værker i to aktive DST datasæt (MultiWOZ 2.2 og WOZ 2.0), hvilket opnår nye state-of-the-art præstationer.', 'id': 'In task-oriented dialogue systems, recent dialogue state tracking methods tend to perform one-pass generation of the dialogue state based on the previous dialogue state.  Kesalahan dari model ini yang dibuat pada giliran saat ini cenderung untuk dibawa ke giliran berikutnya, menyebabkan kesalahan propagasi. Dalam kertas ini, kami mengusulkan generasi yang dapat diubah untuk melacak negara dialog (AG-DST), yang mengandung proses generasi dua-pass: (1) menghasilkan negara dialog primitif berdasarkan dialog dari putaran saat ini dan negara dialog sebelumnya, dan (2) mengubah negara dialog primitif dari putaran pertama. Dengan pemindahan generasi tambahan, model kami ditugaskan untuk belajar pelacakan keadaan dialog yang lebih kuat dengan mengubah kesalahan yang masih ada dalam keadaan dialog primitif, yang bermain peran revisor dalam proses pemeriksaan ganda dan mengurangi propagasi kesalahan yang tidak perlu. Hasil percobaan menunjukkan bahwa AG-DST jauh lebih dari pekerjaan sebelumnya dalam dua set data DST aktif (MultiWOZ 2.2 dan WOZ 2.0), mencapai pertunjukan terbaru.', 'de': 'In aufgabenorientierten Dialogsystemen führen neuere Dialogzustandsverfolgungsmethoden dazu, den Dialogzustand in einem Durchgang basierend auf dem vorherigen Dialogzustand zu generieren. Die Fehler dieser Modelle, die in der aktuellen Kurve gemacht werden, sind anfällig, auf die nächste Kurve übertragen zu werden, was zu einer Fehlerausbreitung führt. In diesem Beitrag schlagen wir eine neue, modifizierbare Generation für Dialogzustandsverfolgung (AG-DST) vor, die einen Zwei-Pass-Generierungsprozess enthält: (1) Erzeugung eines primitiven Dialogzustandes basierend auf dem Dialog des aktuellen Turns und des vorherigen Dialogzustandes, und (2) Änderung des primitiven Dialogzustandes ab dem ersten Durchgang. Mit dem zusätzlichen Änderungs-Generationspass ist unser Modell beauftragt, robustere Dialogzustandsverfolgung zu erlernen, indem die Fehler korrigiert werden, die noch im primitiven Dialogzustand existieren, der die Rolle des Revisors im Doppelüberprüfungsprozess spielt und unnötige Fehlervermehrung reduziert. Experimentelle Ergebnisse zeigen, dass AG-DST bisherige Arbeiten in zwei aktiven DST-Datensätzen (MultiWOZ 2.2 und WOZ 2.0) deutlich übertrifft und neue State-of-the-Art-Leistungen erzielt.', 'ko': '임무를 위한 대화 시스템에서 최근의 대화 상태 추적 방법은 이전의 대화 상태를 바탕으로 대화 상태를 생성하는 경향이 있다.이 모델들이 현재 라운드에서 저지른 실수는 다음 라운드로 넘어가기 쉬워 실수가 전파된다.본고에서 우리는 새로운 수정 가능한 대화 상태 추적 생성(AG-DST)을 제시했다. 이것은 두 번의 생성 과정을 포함한다. (1) 현재 라운드와 이전 대화 상태를 바탕으로 하는 대화는 원시 대화 상태를 생성하고 (2) 첫 번째 대화 상태에서 원시 대화 상태를 수정한다.추가 수정 생성 과정을 통해 우리의 모델의 임무는 원시 대화 상태에 존재하는 오류를 수정함으로써 더욱 건장한 대화 상태 추적을 배우는 것이다. 이것은 이중 검사 과정에서 수정자의 역할을 하고 불필요한 오류 전파를 경감시킨다.실험 결과 두 개의 활발한 DST 데이터 세트(MultiWOZ 2.2와 WOZ 2.0)에서 AG-DST는 이전의 작업보다 현저히 우수하여 새로운 최신 성능을 실현하였다.', 'sw': 'Katika mfumo wa mazungumzo yenye juhudi, mbinu za ufuatiliaji wa mazungumzo ya hivi karibuni za serikali zinazotumia kutekeleza kizazi kimoja cha mazungumzo yenye hali ya mazungumzo yaliyopita. Matukio ya mifano haya yaliyofanywa wakati wa upande wa sasa yanaonyesha kuwa yanaendelea kuelekea upande ujao, na kusababisha kutangaza kosa. Katika karatasi hii, tunapendekeza kizazi cha kitabu kinachobadilika kwa ajili ya Ufuatiliaji wa Taifa ya Dialogue (AG-DST), ambacho kina mchakato wa kizazi cha mara mbili: (1) kutengeneza mazungumzo ya awali kwa msingi wa mazungumzo ya sasa na hali ya mazungumzo yaliyopita, na (2) kurekebisha hali ya mazungumzo ya awali kutoka kwa njia ya kwanza. Wakati kizazi kinachopitia mabadiliko zaidi, mwelekeo wetu unatumiwa kujifunza zaidi kufuatilia mazungumzo ya kijeshi kwa kurekebisha makosa ambayo bado yanaendelea katika hali ya mazungumzo ya msingi, ambayo inacheza jukumu la upya katika mchakato wa kuchunguza mara mbili na kupunguza propaganda za kosa lisilohitaji. Matokeo ya majaribio yanaonyesha kwamba AG-DST inafanya kazi zilizopita kwa kiasi kikubwa katika seti mbili za data za DST (MultiWOZ 2.2 na WOZ 2.0), ili kutekeleza hali mpya ya ya sanaa.', 'tr': 'Görniş görkezilen dýaloglar sisteminde, ýakynda dýalogyň durum taýýarlama yöntemleri, öňki dýalogyň durumyna dayanan bir pass däldir. Häzirki gezek ýüzünde eden bu nusgalaryň ýalňyşlyklary indiki gezek geçirilip gitmelidir. Bu nusgalaryň ýalňyşlygyna sebäp ýitirdi. Bu kagyzda, biz Dialog durum takibi (AG-DST) üçin bir täze döredijili roman teklip edip görýäris. Bu iki geçiş döredijili: (1) häzirki dönüň we öňki dialogyň durumyna daýanýan ilkinji döredijili we (2) ilkinji geçişinden ilkinji dialogyň durumyny üýtget. Diňe üýtgetmek taryhy bilen, biziň modelimiz ýok-ymyklyk bilen, ilkinji dialoogda hem bolan hatalary üýtgetmek üçin peýtget dialog durumyny öwrenmek üçin zada tapylýar. Bu hat çift-ymyklyk prosesinde üýtgedeniň rolini oýnaýar we gerekli hatalaryň täzelenmesini azaltýar. Aramanyň netijesi AG-DST 2.2 we WOZ 2.0-de öňki işleriň täze möhüm bolup geçýän işleriň üstüne ýok bolmagyny görkezýär.', 'af': "In die taak-orienteerde dialoog stelsels, die onlangse dialoog staat agtervolg metodes tendeer na uitvoer een-pass generasie van die dialoog staat gebaseer op die vorige dialoog staat. Die foute van hierdie modele gemaak by die huidige skakel is voorspoedig om oor te neem na die volgende skakel, veroorsaak fout propagasie. In hierdie papier, voorstel ons 'n novel veranderbare Generasie vir Dialoog Staat Volg (AG- DST), wat bevat 'n twee- pass generasie proses: (1) genereer 'n primitiewe dialoog staat gebaseer op die dialoog van die huidige skakel en die vorige dialoog staat, en (2) wysig die primitiewe dialoog staat van die eerste pas. Met die addisionele verandering generasie verbygaan, is ons model opgedra om meer sterkte dialoog staat agtervolg te leer deur die foute verander wat nog bestaan in die primitiewe dialoog staat, wat speel die rol van hersieer in die dubbel- kontroleering proses en alleviaat onnoodsaaklike fout propagasie. Eksperimentale resultate wys dat AG-DST betekenlik voorheende werke in twee aktiewe DST datastelle uitvoer (MultiWOZ 2.2 en WOZ 2.0), met nuwe staat-van-kunstens te bereik.", 'sq': 'Në sistemet e dialogut të orientuar ndaj detyrave, metodat e fundit të dialogut për gjurmimin e shtetit kanë tendencë të kryejnë një gjeneratë pas gjeneratës së dialogut bazuar në gjendjen e mëparshme të dialogut. Gabimet e këtyre modeleve të bërë në kthesën aktuale janë të ngjarë të transferohen në kthesën tjetër, duke shkaktuar përhapjen e gabimeve. Në këtë letër, propozojmë një gjeneratë të ndryshueshme të re për gjurmën e dialogut shtetëror (AG-DST), e cila përmban një proces dy-kalimesh gjenerate: (1) krijimin e një shteti të dialogut primitiv bazuar në dialogun e kthesës së tanishme dhe në gjendjen e dialogut të mëparshëm dhe (2) ndryshimin e gjendjes së dialogut primitiv nga kalimi i parë. With the additional amending generation pass, our model is tasked to learn more robust dialogue state tracking by amending the errors that still exist in the primitive dialogue state, which plays the role of reviser in the double-checking process and alleviates unnecessary error propagation.  Rezultatet eksperimentale tregojnë se AG-DST tejkalon në mënyrë të konsiderueshme punët e mëparshme në dy grupe të dhënash DST aktive (MultiWOZ 2.2 dhe WOZ 2.0), duke arritur shfaqje të reja më të larta.', 'am': 'በአዲስ ዶሴ ፍጠር የአሁኑ ተቃውሞ የእነዚህ ዓይነቶች ስህተት የሚደረጉት ስህተት ወደ ቀጥተኛው ክፍል እንዲወሰድ ነው፡፡ በዚህ ፕሮግራም ውስጥ የአሁኑን ዘርፍ እና የቀድሞውን መምረጫዎች እና የቀድሞውን መምረጫዎች እና (2) የመጀመሪያውን መክፈት የሚለውን የጥያቄ አካባቢ ፕሮጀክት ያስጀምርበታል፡፡ በተጨማሪው አዲስ ትውልድ ሲያልፍ ሞዴላያችን በጥምቀት ጥያቄ ጥያቄ ውስጥ ያሉትን ስህተቶችን በማሻሻል እና በሁለት-checking ፕሮግራም ውስጥ የሚያሳስፈልገውን የስህተት ፕሮግራም ማሳየት ያስፈልጋል፡፡ ከፈተናው ውጤቶች AG-DST በሁለት active DST ዳታተሮችን (MultiWOZ 2.2 እና WOZ 2.0) በአዲስ የ-art ድረ-አካባቢዎችን እንዲያገኘ በአዲስ ሁኔታ ላይ እንዲያሳየው ያሳያል፡፡', 'az': 'Gözəl-tərəfli dijalog sistemlərində, son dijalog vəziyyəti izləmə metodları, keçmişki dijalog vəziyyətinə dayanan dijalog vəziyyətinin tək keçici nəsilini təqdim edir. Şimdiki dönüşündə yapılmış modellərin xətaları sonraki dönüşünə götürülür, xəta propagasyonu olaraq. Bu kağızda, Dialog State Tracking (AG-DST) üçün yeni dəyişiklik nəzəriyyəti təklif edirik. İki dəyişiklik nəzəriyyəti içərik: (1) a ğımdaki dönüş və əvvəlki dialogın dəyişikliyinə dayanan ilk dəyişiklik durumunu təşkil edir və (2) ilk keçmişdən ilk dəyişiklik durumunu dəyişdirir. Əlavə dəyişdirilmiş nəsillərlə, modelimiz daha qüvvətli dijalog durumunu izləmək üçün, hələ də ilk dijalog durumunda olan xətaları dəyişdirmək üçün, çünki ikiqat kontrol prosesində yeniləndiricinin rolünü oynayır və tələb etməyən xətaları azaltır. Müxtəlif sonuçlar, AG-DST iki aktif DST veri qutusu (MultiWOZ 2.2 və WOZ 2.0) içində əvvəlki işləri daha çox üstün etdiyini göstərir, yeni sanat performanslarını başa çatdırar.', 'bn': 'পূর্ববর্তী ডায়ালগ অবস্থায় ভিত্তিক ডায়ালগের একটি প্রজন্মের ডায়ালগ রেস্টের মধ্যে সাম্প্রতিক ডায়ালগ ট্র্যাকিং পদ্ধতি প্রদর্শন করে  বর্তমান পর্যবেক্ষণে এই মডেলগুলোর ভুল প্রমাণিত হচ্ছে পরবর্তী পাল্টানোর জন্য, যার ফলে ত্রুটি প্রচার করা হচ্ছে। এই কাগজটিতে আমরা ডায়ালগ রাষ্ট্রীয় ট্র্যাকিং এর জন্য একটি নতুন প্রজন্মের প্রস্তাব করছি, যার মধ্যে একটি দুই-পাস প্রজন্ম প্রক্রিয়া (১) বর্তমান পর্যবেক্ষণ এবং পূর্ববর্তী ডায়ালগ রাস্তার ভিত্তিতে  অতিরিক্ত সংশোধনী প্রজন্মের পাসের মাধ্যমে আমাদের মডেল আরও রোবটস ডায়ালগ রাষ্ট্র ট্র্যাকিং শিখতে চায় প্রাথমিক ডায়ালগের রাষ্ট্রে যে সমস্ত ভুল সংশোধনের মাধ্যমে বর্তমানে  Experimental results show that AG-DST significantly outperforms previous works in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new state-of-the-art performances.', 'bs': 'U sistemima dijaloga orijentiranih na zadatke, nedavne metode praćenja država dijaloga tendencije izvršavaju jednoprolaznu generaciju države dijaloga na temelju prethodnog stanja dijaloga. Greške ovih modela koji su napravljeni u trenutnom okretu su spremne da se prebace na sljedeći okret, uzrokujući propagaciju greška. U ovom papiru predlažemo novu izmjenu generacije za praćenje država dijaloga (AG-DST), koja sadrži proces generacije dva prolaza: (1) stvaranja primitivnog stanja dijaloga baziranog na dijalogu trenutnog okreta i prethodnog stanja dijaloga, i (2) izmjena primitivnog stanja dijaloga iz prvog prolaza. Uz dodatnu prošlost generacije izmjene, naš model je zadatak da naučimo jače praćenje država dijaloga izmjenom grešaka koja još uvijek postoje u primitivnom dijalogu, koja igra ulogu revizira u procesu dvostrukog provjere i smanjuje nepotrebnu propagaciju grešaka. Eksperimentalni rezultati pokazuju da AG-DST značajno iznosi prethodne funkcije u dvije aktivne DST dataset (MultiWOZ 2.2 i WOZ 2.0), ostvarivši nove postupke umjetnosti.', 'hy': 'Ներկայական երկրի հետևման մեթոդները հակված են առաջին երկրի վրա հիմնված երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրորդ երկրում: Այս մոդելների սխալները, որոնք տեղի են ունենում ներկայիս շրջանում, հակված են հաջորդ շրջանում տեղափոխվելու և սխալների տարածման պատճառով: Այս թղթի մեջ մենք առաջարկում ենք մի նոր Փոփոխվող սերունդ երկրի հետևելու համար (ԱԳ-ԴՍԹ), որը պարունակում է երկու հաջորդ սերունդների գործընթաց: (1) ստեղծելու համար պարզունակ երկու հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ հաջորդ Ավելի փոփոխվող սերնդի ընթացքում մեր մոդելը պարտադիր է սովորել ավելի ուժեղ երկխոսային վիճակի հետևումը փոփոխելով այն սխալները, որոնք դեռ գոյություն ունեն նախատիվ երկխոսային վիճակում, ինչը խաղում է վերանայողի դերը կրկնակի վերահսկման գործընթացում և նվազեցնում անհրաժ Փորձարկվող արդյունքները ցույց են տալիս, որ ԱԳ-ԴՍT-ը նշանակալիորեն գերազանցում է նախորդ աշխատանքները երկու ակտիվ ԴՍT տվյալների համակարգերում (Մուլիվոզ 2.2 և Մուլիվոս 2.0), որպեսզի հասնի նոր բարձրակարգ արտադր', 'ca': "En sistemes de diàleg orientats a les tasques, els mètodes recents de diàleg de seguiment de l'estat tendeixen a fer una generació d'un pas de l'estat de diàleg basat en l'estat de diàleg anterior. Els errors d'aquests models fets al voltant actual són propensos a ser portats al voltant següent, causant propagació d'errors. En aquest paper, proposem una nova generació canviable per a seguir l'estat del diàleg (AG-DST), que conté un procés de generació de dos passos: (1) generar un estat primitiu de diàleg basat en el diàleg de la gira actual i l'estat anterior del diàleg, i (2) modificar l'estat primitiu del diàleg des del primer pas. Amb el passat adicional de generació modificadora, el nostre model té la tasca d'aprendre un seguiment d'estat de diàleg més robust modificant els errors que encara existeixen en l'estat de diàleg primitiu, que juga el paper de revisor en el procés de doble verificació i alivia la propagació d'errors innecessàries. Experimental results show that AG-DST significantly outperforms previous works in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new state-of-the-art performances.", 'et': 'Ülesannetele orienteeritud dialoogisüsteemides kipuvad hiljutised dialoogi oleku jälgimise meetodid sooritama dialoogi oleku ühekäigulist generatsiooni, mis põhineb eelmisel dialoogi olekul. Nende mudelite praegusel pöördel tehtud vead võivad üle kanda järgmisse pöördesse, põhjustades vea levikut. Käesolevas töös pakume välja uudse dialoogi oleku jälgimise muudetava generatsiooni (AG-DST), mis sisaldab kahesuunalist generatsiooniprotsessi: (1) primitiivse dialoogi oleku genereerimine praeguse pöörde ja eelmise dialoogi oleku dialoogil ning (2) primitiivse dialoogi oleku muutmine esimesest käigust. Täiendava muutmise generatsioonipääsuga on meie mudelil ülesanne õppida tugevamat dialoogi oleku jälgimist, muutes vigu, mis on endiselt olemas primitiivses dialoogi olekus, mis mängib topeltkontrolli protsessis korrigeerija rolli ja leevendab ebavajalikku vigade levikut. Eksperimentaalsed tulemused näitavad, et AG-DST on oluliselt ületanud varasemaid töid kahes aktiivses DST andmekogumis (MultiWOZ 2.2 ja WOZ 2.0), saavutades uued tipptasemel esitused.', 'fi': 'Tehtävälähtöisissä dialogijärjestelmissä viimeaikaiset dialogin tilan seurantamenetelmät yleensä suorittavat yhden kierroksen dialogin tilan edellisen dialogitilan perusteella. Näiden mallien nykyisellä käännöksellä tehdyt virheet ovat alttiita seuraavalle käännökselle aiheuttaen virheiden leviämistä. Tässä artikkelissa ehdotamme uutta Alterndable Generation for Dialogue State Tracking (AG-DST), joka sisältää kaksivaiheisen sukupolven prosessin: (1) primitiivisen dialogitilan luomisen nykyisen käänteen ja edellisen dialogitilan dialogiin perustuen ja (2) primitiivisen dialogitilan muuttamisen ensimmäisestä vaiheesta lähtien. Lisämuokkausgeneraatiopassin avulla mallimme tehtävänä on oppia selkeämpää dialogin tilan seurantaa muuttamalla alkeellisessa dialogitilassa edelleen olevia virheitä, jotka ovat tarkistajan roolissa kaksoistarkistusprosessissa ja helpottavat tarpeetonta virheiden leviämistä. Kokeelliset tulokset osoittavat, että AG-DST suoriutuu merkittävästi edellisistä teoksista kahdessa aktiivisessa DST-aineistossa (MultiWOZ 2.2 ja WOZ 2.0), saavuttaen uusia huipputason esityksiä.', 'cs': 'V dialogových systémech orientovaných na úkoly, nedávné metody sledování stavu dialogu mají tendenci provádět jednorázové generování stavu dialogu na základě předchozího stavu dialogu. Chyby těchto modelů provedené v současné zatáčce jsou náchylné k přenášení na další zatáčku, což způsobuje šíření chyb. V tomto článku navrhujeme novou změnitelnou generaci pro sledování stavu dialogu (AG-DST), která obsahuje dvouprůchodový generační proces: (1) generování primitivního stavu dialogu založeného na dialogu aktuálního a předchozího stavu dialogu a (2) změnu primitivního stavu dialogu od prvního průchodu. Díky dodatečnému generačnímu průchodu má náš model za úkol naučit se robustnější sledování stavu dialogu tím, že změní chyby, které stále existují v primitivním stavu dialogu, který hraje roli revizora v procesu dvojí kontroly a zmírňuje zbytečné šíření chyb. Experimentální výsledky ukazují, že AG-DST výrazně překonává předchozí práce ve dvou aktivních DST datových sadách (MultiWOZ 2.2 a WOZ 2.0) a dosahuje nových nejmodernějších výkonů.', 'fa': 'در سیستم\u200cهای محاورۀ مشاورۀ کار، روش\u200cهای ردیابی وضعیت محاورۀ تازه\u200cای از محاورۀ محاورۀ محاورۀ محاورۀ یک ردیابی بر اساس وضعیت محاورۀ قبلی انجام می\u200cدهد. اشتباه\u200cهای این مدل\u200cها که در حال تبدیل شدن در حال حاضر ساخته شده\u200cاند، مقدار است که به نور بعدی حمل می\u200cشوند، باعث گسترش خطایی است. در این کاغذ، ما یک نسل تغییر قابل تغییر قابل توجه برای ردیابی وضعیت دیalog (AG-DST) پیشنهاد می\u200cکنیم که در آن یک فرایند نسل دو ردیابی وجود دارد: (۱) ایجاد یک وضعیت محاورۀ ابتدایی بر اساس محاورۀ تبدیل فعلی و وضعیت دیalog قبلی، و (۲) تغییر و با گذشت نسل اصلاح اضافه، مدل ما به یاد گرفتن ردیابی وضعیت صحبت سخت\u200cتری از طریق اصلاح کردن اشتباهی که هنوز در وضعیت صحبت ابتدایی وجود دارد، که نقش تغییر کننده در فرایند دوبرابر بررسی می\u200cکند و تغییر دادن خطای لازمی را کم می\u200cکند. نتیجه\u200cهای تجربه نشان می\u200cدهد که AG-DST در دو مجموعه داده\u200cهای DST فعال (MultiWOZ 2', 'jv': 'dialogs-action Eror In this paper, we proposal a rome Common: Ngucap Perintah sing paling nggambar barang ARG-dsT kuwi wis ngerasakno sing digaweng langgar sampeyan sing dumadhi dataset dsT (MultiWOZ 2.2 lan WOZ 2.0), kang dipolehasno langgar tarjamahan sing isiné permaneh.', 'sk': 'V sistemih dialoga, usmerjenih v naloge, nedavne metode spremljanja stanja dialoga običajno izvajajo enega prehoda stanja dialoga, ki temelji na prejšnjem stanju dialoga. Napake teh modelov, narejene v trenutnem zavoju, so nagnjene k prenosu na naslednji zavoj, kar povzroča širjenje napak. V prispevku predlagamo novo Spremenljivo generacijo za sledenje stanja dialoga (AG-DST), ki vsebuje proces generacije dveh prehodov: (1) ustvarjanje primitivnega stanja dialoga, ki temelji na dialogu trenutnega obrata in prejšnjega stanja dialoga, in (2) spremembo primitivnega stanja dialoga od prvega prehoda. Z dodatnim generacijskim prehodom sprememb je naš model naložen naučiti robustnejšega sledenja stanja dialoga s spremembo napak, ki še vedno obstajajo v primitivnem stanju dialoga, ki igra vlogo revizorja v procesu dvojnega preverjanja in ublaži nepotrebno širjenje napak. Eksperimentalni rezultati kažejo, da AG-DST bistveno presega prejšnja dela v dveh aktivnih naborih podatkov DST (MultiWOZ 2.2 in WOZ 2.0), kar dosega nove najsodobnejše predstave.', 'ha': "cikin tsarin zauren akwatin bayanin akwatin bayanin da aka yi farin ciki a yanzu, zauren akwatin bayanin akwatin bayani na bayani na bayani na farko, za'a yi amfani da shiryoyin jerin bayani na zauren akwatin bayani. Kuskure wa waɗannan misãlai da aka aikata a yanzu, za'a iya ɗau su zuwa gefen nan gaba, kuma ya sabo da ɓata. cikin wannan takardan, Munã buɗe wani Jerin da aka yi amfani da wa Jerin Aiki na Dialog (AG-Dstan), wanda ke ƙunsa da wani jararin bayani na gudãna biyu: (1) mai ƙãga zauren akwatin bayani na farko, a kan zauren akwatin bayanin da aka yanzu ta yanzu, da kuma (2) ya gyare halin zauren akwatin bayani na farko. Fãce da shirin kiyãye mai gyare-gyare, za'a yi amfani da mu ƙara zauren akwatin bayanin akwatin bayani na goyi bayani na goyi bayani na bayani na goyi bayani na ƙaranci, ko kuma ya gyare ɓallin mai gyare cikin halin zauren akwatin bayani na farko, da ya yi amfani da aikin mai gyare cikin jarraba-checking biyu kuma ya sauƙaƙara bayani na ɓarna wanda bã ya buka. Matariyan jarrabãwa na nuna that AG-DSt significantly outperforms previous works in biyu active DS data set (mulWOZ 2.2 and WOZ 2.0), mai sãmun new state-of-the-art performances.", 'he': 'במערכות דיאלוג ממוקדות למשימות, שיטות דיאלוג לאחרונה נוטים לבצע דור חד-דרך של מדינת הדיולוג המבוססת על מדינת הדיולוג הקודמת. הטעויות של הדוגמנים האלה שנעשו בתור הנוכחי נוטות להעביר לתור הבא, גורמים לפזרת טעויות. בעיתון הזה, אנו מציעים דנרציה חדשה שינויה עבור מעקב מדיום דיאלוג (AG-DST), שמכילה תהליך דור שתי מעלות: (1) יוצר מדינת דיאלוג פרימיטיבית מבוססת על דיאלוג של התור הנוכחי ומדיום הדיולוג הקודם, ו (2) שינוי מדינת דיאלוג פרימיטיבי מהמעבר הראשון. עם מעבר הדור הנוסף, המודל שלנו מועמד ללמוד מעקב דיאלוג חזק יותר על ידי שינוי השגיאות שעדיין קיימות במצב הדיולוג הפרימיטיבי, אשר משחק את תפקיד המחזיר בתהליך הבדיקה כפולה ומקל על ההתפתחות של שגיאות לא הכרחית. Experimental results show that AG-DST significantly outperforms previous works in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new state-of-the-art performances.', 'bo': 'In task-oriented dialog systems, recent dialog state tracking methods tend to perform one-pass of the dialog state based on the previous dialog state. ད་ལྟོའི་སྐོར་ལས་མིག In this paper, we propose a novel Amendable Generation for Dialogue State Tracking (AG-DST), which contains a two-pass generation process: (1) generating a primitive dialog state based on the dialog of the current turn and the previous dialog state, and (2) amending the primitive dialog state from the first pass. With the additional amending generation pass, our model is tasked to learn more robust dialog state tracking by amending the errors that still exist in the primitive dialog state, which plays the role of reviser in the double-checking process and alleviates unnecessary error propagation. Experimental results show that AG-DST significantly outperforms previous works in two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new state-of-the-art performances.'}
{'en': 'What Went Wrong? Explaining Overall Dialogue Quality through Utterance-Level Impacts', 'ar': 'ماذا حصل؟ شرح جودة الحوار الشاملة من خلال التأثيرات على مستوى الكلام', 'es': '¿Qué salió mal? Explicación de la calidad general del diálogo a través de los impactos a nivel', 'fr': "Qu'est-ce qui a mal tourné\xa0? Expliquer la qualité globale du dialogue grâce aux impacts au niveau de l'énoncé", 'pt': 'O que deu errado? Explicando a qualidade geral do diálogo por meio dos impactos no nível de enunciado', 'ja': '何が間違っていたのか？ウタランスレベルのインパクトを通じて全体的な対話の質を説明する', 'zh': '何误之有? 以言语之故,解体对话质量', 'hi': 'क्या गलत हुआ? कथन-स्तर प्रभावों के माध्यम से समग्र संवाद गुणवत्ता की व्याख्या', 'ru': 'Что пошло не так? Объяснение общего качества диалога через влияние на уровне высказываний', 'ga': 'Cad a chuaigh mícheart? Cáilíocht Iomlán na Comhphlé a Mhíniú trí Thionchair ar Leibhéal cainte', 'el': 'Τι πήγε στραβά; Εξήγηση της συνολικής ποιότητας του διαλόγου μέσω επιπτώσεων σε επίπεδο εκφρασμού', 'ka': 'კაკგჲ ჟრანა ოჲდპვქნჲ? ყველა დიალოგის კაalitეტის გამოსახულება გამოყენება', 'hu': 'Mi történt rosszul? Az átfogó párbeszéd minőségének magyarázata a kiterjedtségi szintű hatásokon keresztül', 'kk': 'Қате болды? Бүкіл диалогтың сапатын уттеранс- деңгейінің әсері арқылы түсіндіру', 'it': "Cos'e' andato storto? Spiegare la qualità globale del dialogo attraverso gli impatti a livello di efficacia", 'lt': 'Kas nutiko? Bendros dialogo kokybės paaiškinimas taikant naudojimo lygio poveikį', 'mk': 'Што не е во ред? Објаснување на целокупниот квалитет на дијалогот преку влијанието на нивото на употреба', 'ml': 'എന്ത് തെറ്റായിരുന്നു? മൊത്തം ഡയലോഗിന്റെ ഗുണവും വിശദീകരിക്കുക', 'mt': "X'Mar ħażin? Explaining Overall Dialogue Quality through Utterance-Level Impacts", 'ms': 'Apa yang salah? Menjelaskan Kualiti Dialog Umum melalui Impak Aras-Utterance', 'ro': 'Ce a mers prost? Explicarea calității dialogului general prin impacturi la nivel de experiență', 'mn': 'Юу буруу болсон бэ? Ихэнх диалогын сайн чанарыг хэрэглэх түвшинд тайлбарлах', 'no': 'Kva skjedde feil? Utklarar overalt dialogkvalitet gjennom brukarnivå', 'pl': 'Co poszło źle? Wyjaśnienie ogólnej jakości dialogu poprzez skutki na poziomie wypowiedzi', 'so': 'Maxaa khalad galay? Tilmaamaha diyalogka oo dhan', 'sr': 'Šta je bilo pogrešno? Objašnjavanje kvalitete ukupnog dijaloga kroz uticaj na nivou korištenja', 'ta': 'என்ன தவறு நடந்தது? Explaining Overall Dialogue Quality through Utterance-Level Impacts', 'ur': 'کیا غلط ہوا؟ استٹرانس-سطح اثرات کے ذریعہ تمام ڈیلوگ کیلوٹی سفارش کر رہے ہیں', 'si': 'මොකක්ද වැරැද්ද? සම්පූර්ණ සංවාද කුළුවත් ප්\u200dරශ්නය කරන්න පුළුවන් උපයෝජනය- ස්ථානය සඳහා', 'sv': 'Vad gick fel? Förklaring av den övergripande dialogens kvalitet genom effekter på utvecklingsnivå', 'uz': 'Nima xato qildi? Dialogning hamma qiymatini tasdiqlash', 'vi': 'Có chuyện gì? Giải thích Chất lượng cuộc đối thoại tổng hợp', 'bg': 'Какво се обърка? Обясняване на цялостното качество на диалога чрез въздействие на категорично ниво', 'da': 'Hvad gik galt? Forklaring af den overordnede dialogkvalitet gennem virkninger på udbredelsesniveau', 'nl': 'Wat ging er mis? Verklaring van de algehele kwaliteit van de dialoog door middel van effecten op Utterance Level', 'hr': 'Što je bilo pogrešno? Objašnjavanje cjelokupnog kvaliteta dijaloga kroz utjecaje na nivou korištenja', 'de': 'Was ist schief gelaufen? Erklärung der Gesamtqualität des Dialogs durch Auswirkungen auf Äußerungsebene', 'id': 'What Went Wrong?  Menjelaskan Kualitas Dialog Umum melalui Impak Tingkat Utterance', 'ko': '무슨 일이야?언어 차원의 영향을 통해 전체 대화의 질을 해석하다', 'tr': 'Näme ýalñyş boldy? Geditiň derejesi etkinleýän ählisini baglaýyn', 'af': 'Wat het verkeerd gegaan? Verduidelik Gewone Dialoog Kwaliteit deur Utterance- Vlak Impekte', 'sq': 'Çfarë ka ndodhur keq? Duke shpjeguar cilësinë e dialogut të përgjithshëm nëpërmjet ndikimeve të nivelit të përdorimit', 'sw': 'Tulikuwa kosa gani? Utawala wa Dialogu Jumla kupitia Impact of Utterance-Level', 'fa': 'چي شده؟ توضیح کیفیت محاورۀ عمومی از طریق تاثیرات سطح استفاده', 'hy': 'Ի՞նչ սխալ է եղել: Պատկերացնելու համար ընդհանուր պատմության որակը օգտագործման մակարդակի ազդեցությունների միջոցով', 'az': 'Nə yanlış oldu? Bütün Dialoog Qüdrətini Utterans-Seviye Etkinlikləri ilə aydınlaşdırma', 'bs': 'Šta je bilo pogrešno? Objašnjavanje kvalitete ukupnog dijaloga kroz utjecaje na nivou korištenja', 'ca': 'Què va passar malament? Explaining Overall Dialogue Quality through Utterance-Level Impacts', 'am': 'ምን ስህተት ነበር? dialogs-action', 'cs': 'Co se stalo špatně? Vysvětlení celkové kvality dialogu prostřednictvím dopadů na úrovni vyjádření', 'fi': 'Mikä meni pieleen? Vuoropuhelun laadun selittäminen selkeiden vaikutusten avulla', 'bn': 'কি ভুল হয়েছে? সারা ডায়ালগের মান ব্যাখ্যা করা হচ্ছে', 'et': 'Mis valesti läks? Dialoogi üldise kvaliteedi selgitamine põhjaliku mõju kaudu', 'jv': 'Olo kuwi njuk wae ? Jejaring', 'he': 'מה קרה? הסבר איכות השיחה הכללית באמצעות השפעות ברמה השתמשות', 'sk': 'Kaj je šlo narobe? Pojasnitev splošne kakovosti dialoga z jasnimi učinki na ravni', 'ha': 'Mẽne ne ya ɓace? @ action', 'bo': 'What Went Wrong?! ལག་ལེན་བྱེད་པའི་གནས་རིམ་གྱི་གནོད་འགྱུར་བ་སྤྱད་པར་དབྱེ་བ་ཡོངས'}
{'en': 'Improving user experience of a ', 'fr': "L'amélioration de l'expérience utilisateur d'un système de dialogue nécessite souvent des efforts intensifs des développeurs pour lire les journaux de conversation, exécuter des analyses statistiques et comprendre l'importance relative des faiblesses du système. Cet article présente une nouvelle approche de l'analyse automatisée des journaux de conversations qui apprend la relation entre les interactions utilisateur-système et la qualité globale du dialogue. Contrairement aux travaux antérieurs sur la prédiction de la qualité au niveau de l'énoncé, notre approche apprend l'impact de chaque interaction à partir de l'évaluation globale de l'utilisateur sans annotation au niveau de l'énoncé, ce qui permet de tirer des conclusions du modèle résultant sur la base de preuves empiriques et à faible coût. Notre modèle identifie les interactions qui ont une forte corrélation avec la qualité globale du dialogue dans un environnement de chatbot. Les expériences montrent que l'analyse automatisée de notre modèle est en accord avec les jugements des experts, ce qui fait de ce travail le premier à montrer qu'un apprentissage aussi faiblement supervisé de la prédiction de qualité au niveau de l'énoncé est hautement réalisable.", 'pt': 'Melhorar a experiência do usuário de um sistema de diálogo geralmente requer um esforço intensivo do desenvolvedor para ler os logs de conversa, executar análises estatísticas e intuir a importância relativa das deficiências do sistema. Este artigo apresenta uma nova abordagem para análise automatizada de logs de conversação que aprende a relação entre as interações usuário-sistema e a qualidade geral do diálogo. Ao contrário de trabalhos anteriores sobre previsão de qualidade no nível de enunciado, nossa abordagem aprende o impacto de cada interação a partir da classificação geral do usuário sem anotação no nível de enunciado, permitindo que as conclusões do modelo resultantes sejam derivadas com base em evidências empíricas e a baixo custo. Nosso modelo identifica interações que têm uma forte correlação com a qualidade geral do diálogo em uma configuração de chatbot. Experimentos mostram que a análise automatizada do nosso modelo concorda com os julgamentos de especialistas, tornando este trabalho o primeiro a mostrar que esse aprendizado fracamente supervisionado da previsão de qualidade no nível de enunciado é altamente alcançável.', 'ar': 'غالبًا ما يتطلب تحسين تجربة المستخدم لنظام الحوار جهودًا مكثفة للمطورين لقراءة سجلات المحادثة ، وإجراء التحليلات الإحصائية ، واستشعار الأهمية النسبية لأوجه القصور في النظام. تقدم هذه الورقة مقاربة جديدة للتحليل الآلي لسجلات المحادثة التي تتعلم العلاقة بين تفاعلات نظام المستخدم وجودة الحوار الشاملة. على عكس العمل السابق على التنبؤ بالجودة على مستوى الكلام ، يتعلم منهجنا تأثير كل تفاعل من التقييم العام للمستخدم دون شرح توضيحي على مستوى الكلام ، مما يسمح باستخلاص استنتاجات النموذج الناتجة على أساس الأدلة التجريبية وبتكلفة منخفضة. يحدد نموذجنا التفاعلات التي لها علاقة قوية بجودة الحوار الشاملة في إعداد روبوت المحادثة. تُظهر التجارب أن التحليل الآلي من نموذجنا يتفق مع أحكام الخبراء ، مما يجعل هذا العمل أول من يُظهر أن مثل هذا التعلم الخاضع للإشراف الضعيف للتنبؤ بالجودة على مستوى النطق يمكن تحقيقه بشكل كبير.', 'es': 'Mejorar la experiencia del usuario de un sistema de diálogo a menudo requiere un esfuerzo intensivo del desarrollador para leer los registros de conversaciones, ejecutar análisis estadísticos e intuir la importancia relativa de las deficiencias del sistema. Este artículo presenta un enfoque novedoso para el análisis automatizado de los registros de conversación que aprende la relación entre las interacciones entre el usuario y el sistema y la calidad general del diálogo. A diferencia del trabajo anterior sobre la predicción de la calidad a nivel de enunciado, nuestro enfoque aprende el impacto de cada interacción a partir de la calificación general de los usuarios sin anotación a nivel de enunciado, lo que permite derivar las conclusiones del modelo resultante sobre la base de evidencia empírica y a bajo costo. Nuestro modelo identifica interacciones que tienen una fuerte correlación con la calidad general del diálogo en un entorno de chatbot. Los experimentos muestran que el análisis automatizado de nuestro modelo concuerda con los juicios de los expertos, por lo que este trabajo es el primero en demostrar que este aprendizaje débilmente supervisado de la predicción de la calidad del nivel de enunciado es altamente alcanzable.', 'hi': 'एक संवाद प्रणाली के उपयोगकर्ता अनुभव में सुधार के लिए अक्सर वार्तालाप लॉग को पढ़ने, सांख्यिकीय विश्लेषण चलाने और सिस्टम की कमियों के सापेक्ष महत्व को शामिल करने के लिए गहन डेवलपर प्रयास की आवश्यकता होती है। यह पेपर वार्तालाप लॉग के स्वचालित विश्लेषण के लिए एक उपन्यास दृष्टिकोण प्रस्तुत करता है जो उपयोगकर्ता-सिस्टम इंटरैक्शन और समग्र संवाद गुणवत्ता के बीच संबंधों को सीखता है। उच्चारण-स्तर की गुणवत्ता की भविष्यवाणी पर पूर्व कार्य के विपरीत, हमारा दृष्टिकोण उच्चारण-स्तर के एनोटेशन के बिना समग्र उपयोगकर्ता रेटिंग से प्रत्येक बातचीत के प्रभाव को सीखता है, जिससे परिणामी मॉडल निष्कर्ष अनुभवजन्य साक्ष्य के आधार पर और कम लागत पर प्राप्त किए जा सकते हैं। हमारा मॉडल उन इंटरैक्शन की पहचान करता है जिनका चैटबॉट सेटिंग में समग्र संवाद गुणवत्ता के साथ एक मजबूत संबंध है। प्रयोगों से पता चलता है कि हमारे मॉडल से स्वचालित विश्लेषण विशेषज्ञ निर्णयों से सहमत है, जिससे यह काम यह दिखाने के लिए पहला है कि उच्चारण-स्तर की गुणवत्ता की भविष्यवाणी के इस तरह के कमजोर-पर्यवेक्षित सीखने को अत्यधिक प्राप्त किया जा सकता है।', 'zh': '善言系统者用户体常须开发人员精力读对日志,运行统计分析,直观知系统之要。 本文设自析对日志新法,其法学用户与统交与体对话质量之际。 与前言异事,吾法从一体用户评级中学每交互,而无语注,许以低成本推导生为法。 吾形识聊天机器人设中之体,强相关性之交也。 实验明自析与专家同,使始明其弱监学之高可也。', 'ja': '対話システムのユーザーエクスペリエンスを改善するには、多くの場合、会話ログを読み取り、統計分析を実行し、システムの欠点の相対的な重要性を直感的に理解するための開発者の集中的な努力が必要です。本論文では、ユーザーとシステムの相互作用と全体的な対話の質との関係を学習する会話ログの自動分析に対する新規アプローチを提示した。発話レベルの品質予測に関する以前の研究とは異なり、私たちのアプローチは、発話レベルの注釈なしに全体的なユーザー評価から各インタラクションの影響を学習し、結果として得られるモデルの結論を実証的な根拠に基づいて低コストで導き出すことができます。当社のモデルは、チャットボットの設定における全体的な対話の質と強い相関があるインタラクションを特定します。実験によると、私たちのモデルからの自動分析は専門家の判断に同意しており、発話レベルの品質予測のこのような弱い監督下での学習が非常に達成可能であることを最初に示した。', 'ru': 'Улучшение пользовательского опыта системы диалога часто требует интенсивных усилий разработчиков для чтения журналов разговоров, выполнения статистических анализов и понимания относительной важности системных недостатков. В данной статье представлен новый подход к автоматизированному анализу журналов разговоров, который изучает взаимосвязь между взаимодействиями пользователя и системы и общим качеством диалога. В отличие от предыдущей работы по прогнозированию качества на уровне высказываний, наш подход изучает влияние каждого взаимодействия на основе общего рейтинга пользователей без аннотации на уровне высказываний, что позволяет делать результирующие выводы модели на основе эмпирических данных и при низких затратах. Наша модель определяет взаимодействия, которые имеют сильную корреляцию с общим качеством диалога в настройках чат-бота. Эксперименты показывают, что автоматизированный анализ из нашей модели согласуется с экспертными суждениями, что делает эту работу первой, чтобы показать, что такое слабо контролируемое обучение прогнозированию качества на уровне речи является высокодостижимым.', 'ga': 'Is minic go dteastaíonn dianiarracht ón bhforbróir chun taithí an úsáideora ar chóras comhphlé a fheabhsú chun logaí comhrá a léamh, anailísí staitistiúla a rith, agus intuit tábhacht choibhneasta easnaimh chórais. Cuireann an páipéar seo cur chuige nua i láthair maidir le hanailís uathoibrithe ar logaí comhrá a fhoghlaimíonn an gaol idir idirghníomhaíochtaí córais úsáideora agus cáilíocht iomlán an chomhphlé. Murab ionann agus réamhobair ar thuar cáilíochta ar leibhéal cainte, foghlaimíonn ár gcur chuige tionchar gach idirghníomhaíochta ón rátáil iomlán úsáideora gan anótáil leibhéal cainte, rud a ligeann do chonclúidí samhla iarmhartacha a dhíorthú ar bhonn fianaise eimpíreach agus ar chostas íseal. Aithníonn ár múnla idirghníomhaíochtaí a bhfuil comhghaol láidir acu le cáilíocht fhoriomlán an chomhphlé i suíomh chatbot. Léiríonn turgnaimh go n-aontaíonn an anailís uathoibrithe ónár múnla le breithiúnais na saineolaithe, rud a fhágann gurb í an obair seo an chéad cheann a thaispeánann go bhfuil a leithéid d’fhoghlaim faoi mhaoirseacht lag ar thuar cáilíochta ag leibhéal cainte an-infheidhmithe.', 'el': 'Η βελτίωση της εμπειρίας χρήστη ενός συστήματος διαλόγου συχνά απαιτεί εντατική προσπάθεια προγραμματιστών να διαβάσουν αρχεία καταγραφής συνομιλίας, να εκτελέσουν στατιστικές αναλύσεις και να διαισθανθούν τη σχετική σημασία των ελλείψεων του συστήματος. Η παρούσα εργασία παρουσιάζει μια νέα προσέγγιση στην αυτοματοποιημένη ανάλυση των αρχείων καταγραφής συνομιλίας που μαθαίνει τη σχέση μεταξύ αλληλεπιδράσεων χρήστη-συστήματος και συνολικής ποιότητας διαλόγου. Σε αντίθεση με προηγούμενες εργασίες σχετικά με την πρόβλεψη ποιότητας σε επίπεδο έκφρασης, η προσέγγισή μας μαθαίνει τον αντίκτυπο κάθε αλληλεπίδρασης από τη συνολική αξιολόγηση χρηστών χωρίς σχολιασμό σε επίπεδο έκφρασης, επιτρέποντας την εξαγωγή των αποτελεσμάτων μοντέλων με βάση εμπειρικά στοιχεία και με χαμηλό κόστος. Το μοντέλο μας εντοπίζει αλληλεπιδράσεις που έχουν ισχυρή συσχέτιση με τη συνολική ποιότητα διαλόγου σε ένα περιβάλλον chatbot. Τα πειράματα δείχνουν ότι η αυτοματοποιημένη ανάλυση από το μοντέλο μας συμφωνεί με τις εκτιμήσεις εμπειρογνωμόνων, καθιστώντας αυτό το έργο το πρώτο που δείχνει ότι μια τέτοια αδύναμη παρακολούθηση εκμάθησης της πρόβλεψης ποιότητας σε επίπεδο έκφρασης είναι εξαιρετικά εφικτή.', 'ka': 'დიალოგის სისტემის მომხმარებელი გამოცდილობას უფრო მეტი უნდა ინტერნექტიური განვითარებელი ძალადობა საუკეთესო სისტემის შესახებ, სტატისტიკური ანალიზების გავაკ ეს დოკუმენტი აჩვენებს პრომენტური პროგრამის ავტომატიური ანალიზაციის შესახებ, რომელიც მომხმარებელი სისტემის ინტერფექციების და ყველა დიალოგის კაalitესტის ჩვენი მიღება ყველა ინტერფექციის შესახებ ყველა გამოყენებელი რეირექციის განმავლობაზე, რომელიც უნდა გამოყენებელი რეირექციის განმავლობაზე გადასწავლა, რომელიც შესაძლებელი მოდელური გადასწავლებები იქნება ემპრიკალური წ ჩვენი მოდელი იდენტიფიკურებს ინტერფექციები, რომლებიც ძალიან კორელექცია საერთო დიალოგის კავილექტში. ექსპერიმენტები ჩვენი მოდელიდან ავტომატიური ანალიზია ექსპერტის გადაწყვეტილებებით, რომლებიც ეს მუშაობა პირველი, რომლებიც აჩვენებს, რომ ასეთი ძალიან დამარწმუნებული სწავლება საუკეთეს', 'hu': 'A párbeszédrendszerek felhasználói élményének javítása gyakran intenzív fejlesztői erőfeszítéseket igényel a beszélgetésnaplók olvasására, statisztikai elemzések futtatására és a rendszerhibák relatív jelentőségére. A tanulmány a beszélgetésnaplók automatizált elemzésének új megközelítését mutatja be, amely megtanulja a felhasználó-rendszer interakciók és az általános párbeszédminőség kapcsolatát. A kimondási szintű minőségi előrejelzéssel kapcsolatos korábbi munkákkal ellentétben megközelítésünk az egyes interakciók hatását az általános felhasználói minősítésből tanulmányozza, anélkül, hogy kimondási szintű megjegyzések nélkül, lehetővé téve, hogy az eredményes modellkövetkeztetéseket empirikus bizonyítékok alapján és alacsony költségek mellett lehessen levonni. Modellünk azonosítja azokat az interakciókat, amelyek erős összefüggésben állnak az általános párbeszédminőséggel egy chatbot beállításban. A kísérletek azt mutatják, hogy modellünkből származó automatizált elemzés egyetért a szakértői ítéletekkel, így ez a munka az első, amely azt mutatja, hogy a kimondási szintű előrejelzés ilyen gyengén felügyelt tanulása nagyon elérhető.', 'lt': 'Norint pagerinti dialogo sistemos naudotojų patirtį, dažnai reikia intensyvių vystytojų pastangų skaityti pokalbių žurnalus, atlikti statistinę analizę ir suvokti santykinę sistemos trūkumų svarbą. Šiame dokumente pateikiamas naujas požiūris į automatizuotą pokalbių žurnalų analizę, kuria sužinojamas ryšys tarp naudotojo ir sistemos sąveikos ir bendros dialogo kokybės. Priešingai nei ankstesnis darbas, susijęs su išraiškos lygio kokybės prognozėmis, mūsų požiūris sužino kiekvienos sąveikos poveikį iš bendro vartotojo reitingo be išraiškos lygio anotacijos, leidžiant gauti rezultatų modelio išvadas remiantis empiriniais įrodymais ir mažomis sąnaudomis. Mūsų modelis nustato sąveikas, kurios yra tvirtai susijusios su bendra dialogo kokybe chatbot setting. Eksperimentai rodo, kad automatizuota mūsų modelio analizė sutinka su ekspertų sprendimais, todėl pirmasis rezultatas rodo, kad toks silpnai prižiūrimas kalbos kokybės prognozės mokymasis yra labai pasiekiamas.', 'it': "Migliorare l'esperienza utente di un sistema di dialogo richiede spesso un intenso sforzo degli sviluppatori per leggere i registri delle conversazioni, eseguire analisi statistiche e intuire l'importanza relativa delle carenze del sistema. Questo articolo presenta un nuovo approccio all'analisi automatizzata dei registri delle conversazioni che apprende la relazione tra le interazioni utente-sistema e la qualità generale del dialogo. A differenza dei precedenti lavori sulla previsione della qualità a livello di pronuncia, il nostro approccio apprende l'impatto di ogni interazione dalla valutazione complessiva degli utenti senza annotazioni a livello di pronuncia, consentendo di ricavare le conclusioni del modello risultante sulla base di prove empiriche e a basso costo. Il nostro modello identifica interazioni che hanno una forte correlazione con la qualità complessiva del dialogo in un'impostazione chatbot. Gli esperimenti dimostrano che l'analisi automatizzata del nostro modello concorda con i giudizi degli esperti, rendendo questo lavoro il primo a dimostrare che tale apprendimento debolmente supervisionato della previsione della qualità di pronuncia è altamente realizzabile.", 'ml': 'ഡയലോഗ് സിസ്റ്റത്തിന്റെ ഉപയോക്താവിന്റെ അനുഭവങ്ങള്\u200d മുന്\u200dകൂട്ടുന്നതിനായി എപ്പോഴും സംസാരിക്കുന്ന ലോഗുകള്\u200d വായിക്കുവാനും സിസ് ഈ പത്രത്തില്\u200d സംസാരിക്കുന്ന ലോഗുകളുടെ സ്വതന്ത്രമായി അന്വേഷിക്കാനുള്ള ഒരു നോവല്\u200d സാധ്യതയെ കാണിക്കുന്നു. അത് ഉപയോക്താ വാക്ക്-നില പ്രവചനത്തിന്റെ മുമ്പുള്ള പണിയെല്ലാം വ്യത്യസ്തമായിട്ടില്ല, നമ്മുടെ പ്രായോഗ്യം എല്ലാ ഉപയോക്താവിന്റെയും സംവിധാനത്തില്\u200d നിന്നും പ്രഭാവം പഠ നമ്മുടെ മോഡല്\u200d ചട്ട്ബോട്ട് സംവിധാനത്തില്\u200d ഒരു ശക്തിയുള്ള ബന്ധമുള്ള തമ്മിലുള്ള ബന്ധങ്ങള്\u200d കണ്ടെത്തുന്ന പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് നമ്മുടെ മോഡലില്\u200d നിന്നുള്ള സ്വയം അന്വേഷിക്കുന്നത് വിശേഷ വിധികളോടൊപ്പം സമ്മതിക്കുന്നു. ഇത് ആദ്യം പ', 'kk': 'Диалог жүйесінің пайдаланушылардың тәжірибесін жақсарту көбінде, сұхбат журналын оқу, статистикалық анализацияларды жұмыс істеу және жүйелік жеткіліктердің қатынастығын көру Бұл қағаз пайдаланушылар жүйесі интерфейстері мен жалпы диалогтың сапасы арасындағы қатынастығын автоматты түрде анализ журналдарының автоматты түрде қатынасын көрсетеді. Алдыңғы сөйлеу деңгейіндегі сапатты бақылау жұмысының әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір әрбір қатынастығын сөйлеу деңгейіндегі белгіліктемесіз арқылы оқытып Біздің моделіміз сұхбат баптауларының жалпы диалогтың сапасы мен күшті қатынасы бар әріптерді анықтайды. Тәжірибелер моделіміздің автоматты анализ эксперттердің тәжірибелерімізге қатынайды. Бұл жұмыс біріншіден біріншіден бұл сөйлеу деңгейіндегі сапатты бақылау үшін бақылап тұрған оқиға', 'mt': 'It-titjib tal-esperjenza tal-utenti ta’ sistema ta’ djalogu ta’ spiss jeħtieġ sforz intensiv tal-iżviluppatur biex jaqra r-reġistri tal-konverżjonijiet, iwettaq analiżi statistika, u jintuża l-importanza relattiva tan-nuqqasijiet tas-sistema. Dan id-dokument jippreżenta approċċ ġdid għall-analiżi awtomatizzata tal-logs tal-konverżjoni li jitgħallem ir-relazzjoni bejn l-interazzjonijiet bejn l-utent u s-sistema u l-kwalità ġenerali tad-djalogu. Għall-kuntrarju tax-xogħol preċedenti dwar it-tbassir tal-kwalità fil-livell ta’ utteranza, l-approċċ tagħna jitgħallem l-impatt ta’ kull interazzjoni mill-klassifikazzjoni ġenerali tal-utent mingħajr annotazzjoni fil-livell ta’ utteranza, li tippermetti li l-konklużjonijiet tal-mudell li jirriżultaw jiġu derivati fuq il-bażi ta’ evidenza empirika u bi prezz baxx. Il-mudell tagħna jidentifika interazzjonijiet li għandhom korrelazzjoni qawwija mal-kwalità ġenerali tad-djalogu f’ambjent chatbot. L-esperimenti juru li l-analiżi awtomatizzata mill-mudell tagħna taqbel ma’ sentenzi esperti, u b’hekk din il-ħidma ssir l-ewwel biex turi li dan it-tagħlim ta’ tbassir tal-kwalità fil-livell ta’ utteranza li huwa sorveljat b’mod dgħajjef jista’ jinkiseb ħafna.', 'mk': 'Подобрувањето на искуството на корисникот од дијалогот честопати бара интензивни напори на развивачите за читање на дневниците на разговорите, спроведување статистички анализи и интуитирање на релативната важност на системските недостатоци. Овој весник претставува нов пристап до автоматизирана анализа на дневниците на разговорите кои ја научи врската помеѓу интеракциите помеѓу корисникот и системот и целокупниот квалитет на дијалогот. За разлика од претходната работа на предвидување на квалитетот на нивото на изразување, нашиот пристап го научи влијанието на секоја интеракција од целокупниот рејтинг на корисникот без анотација на нивото на изразување, овозможувајќи резултатните заклучоци на моделот да се извлечат на основа на емпирички докази Нашиот модел идентификува интеракции кои имаат силна корелација со целокупниот квалитет на дијалогот во поставувањето chatbot. Експериментите покажуваат дека автоматизираната анализа од нашиот модел се согласува со експертски пресуди, што го прави ова прво да функционира за да покаже дека ваквото слабо надгледувано учење на предвидување на квалитетот на ниво на изразување е високо достапно.', 'ms': 'Perbaikan pengalaman pengguna sistem dialog sering memerlukan usaha pembangun intens untuk membaca log perbualan, jalankan analisis statistik, dan intuit kepentingan relatif kekurangan sistem. Kertas ini memperkenalkan pendekatan baru untuk analisis automatik log perbualan yang mempelajari hubungan antara interaksi sistem-pengguna dan kualiti dialog keseluruhan. Tidak seperti kerja sebelumnya pada ramalan kualiti aras-ucapan, pendekatan kita mempelajari kesan setiap interaksi dari nilai pengguna keseluruhan tanpa anotasi aras-ucapan, membolehkan kesimpulan model hasil untuk dibuang berdasarkan bukti empirik dan pada biaya rendah. Our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting.  Eksperimen menunjukkan bahawa analisis automatik dari model kita setuju dengan penilaian ahli, membuat ini bekerja pertama untuk menunjukkan bahawa pembelajaran kualiti aras-perkataan yang terlemah-mengawasi adalah sangat mencapai.', 'no': 'For å forbetra brukaropplevelsen av eit dialogsystemet krev ofte intensivt utviklar for å lesa samtaleloggar, køyra statistiske analyser og innføre relativt viktighet for system shortcomings. Denne papiret viser ein novel tilnærming til automatisk analysering av samtaleloggar som lærer forholdet mellom brukersystemet- interaksjonar og overalt dialogkvalitet. I motsetjing til førre arbeid på forhåndsvising av uttalenivået, lærer tilnærminga vårt påvirkning av kvar interaksjon frå den generelle brukaranevalueringa utan uttalenivå-annotasjon, slik at resultatet model-konklusjonar skal avhennast på grunn av empiriske beviser og med låg kostnad. Modellen vårt identifiserer interaksjonar som har ein sterk korrelasjon med den generelle dialogkvaliteten i eit samtaleoppsett. Eksperimentar viser at automatisk analysen frå modellen vår er samordnet med ekspertsprøytebrukar, og det første arbeidet viser at slik viktig oversikt læring av uttalenivåkvalitetforventinga er svært tilgjengeleg.', 'pl': 'Poprawa doświadczeń użytkowników systemu dialogowego często wymaga intensywnego wysiłku dewelopera, aby odczytać dzienniki konwersacji, przeprowadzić analizy statystyczne i wyczuć względne znaczenie niedociągnięć systemu. W artykule przedstawiono nowatorskie podejście do zautomatyzowanej analizy dzienników rozmów, które poznaje związek między interakcjami użytkownika-systemu a ogólną jakością dialogu. W przeciwieństwie do wcześniejszych prac nad predykcją jakości wypowiedzi, nasze podejście uczy się wpływu każdej interakcji na podstawie ogólnej oceny użytkowników bez adnotacji na poziomie wypowiedzi, co pozwala na wyprowadzenie wynikających z modelu wniosków na podstawie dowodów empirycznych i przy niskich kosztach. Nasz model identyfikuje interakcje, które mają silną korelację z ogólną jakością dialogu w ustawieniach chatbota. Eksperymenty pokazują, że zautomatyzowana analiza z naszego modelu zgadza się z ocenami ekspertów, co czyni tę pracę pierwszą, która wykazała, że takie słabo nadzorowane uczenie się przewidywania jakości wypowiedzi na poziomie wypowiedzi jest wysoce osiągalne.', 'ro': 'Îmbunătățirea experienței utilizatorilor a unui sistem de dialog necesită adesea eforturi intense de a citi jurnalele conversațiilor, de a rula analize statistice și de a intui importanța relativă a deficiențelor sistemului. Această lucrare prezintă o abordare nouă a analizei automatizate a jurnalelor de conversație care învață relația dintre interacțiunile utilizator-sistem și calitatea generală a dialogului. Spre deosebire de lucrările anterioare privind predicția calității la nivel de rostire, abordarea noastră învață impactul fiecărei interacțiuni din evaluarea generală a utilizatorilor fără adnotări la nivel de rostire, permițând ca concluziile modelului rezultat să fie derivate pe baza dovezilor empirice și la costuri reduse. Modelul nostru identifică interacțiunile care au o corelație puternică cu calitatea generală a dialogului într-o setare chatbot. Experimentele arată că analiza automată din modelul nostru este de acord cu judecățile experților, făcând această lucrare prima care arată că o astfel de învățare slab supravegheată a predicției calității la nivel de rostire este foarte realizabilă.', 'mn': 'Диалог системийн хэрэглэгчдийн туршлагын сайжруулах нь ихэвчлэн ярианы логийг унших, статистикийн шинжилгээг ажиллах, системийн алдагдлын харьцаатай чухал ач холбогдол хэрэгтэй. Энэ цаас хэрэглэгчийн системийн харилцааны харилцааны хоорондын харилцааны харилцааны автоматжуулалтын шинжилгээнд шинэ арга зам гаргадаг. Өмнөх хэмжээний чанарын таамаглал дээр ажиллах эсрэгээр, бидний арга баримт хэрэглэгчдийн харилцааны нөлөөг илтгэл хэмжээний түвшинд бага үнэ цэнэтэй байдлаас суралцдаг. Үүний үр дүнтэй загварын шийдвэр нь эзэмшигийн баримт, бага үнэ цэнэт Бидний загварын загвар нь чадвартай холбоотой харилцааныг тодорхойлдог. Эмчилгээний туршилтууд бидний загварын автоматжуулсан шинжилгээ нь мэргэжилтнүүдийн шүүмжлэлтэй холбогдож байгааг харуулдаг. Энэ үйл ажиллагааг эхлээд илтгэл хэмжээний сайн чанарын таамаглалтын суралцах нь маш их хүчтэй гэ', 'sr': 'Poboljšanje iskustva korisnika sistema dijaloga često zahteva intenzivne napore razvijača za čitanje dnevnika razgovora, obavljanje statističkih analiza i intuiranje relativne važnosti nedostataka sustava. Ovaj papir predstavlja novi pristup automatskoj analizi dnevnika razgovora koji nauči vezu između interakcija korisnika i ukupnog kvaliteta dijaloga. Za razliku od prethodnog rada o predviđanju kvalitete na nivou govora, naš pristup nauči uticaj svake interakcije od ukupnog ocjena korisnika bez annotacije nivoa govora, omogućavajući rezultate model zaključka da se donose na temelju empiričkih dokaza i na niske cene. Naš model identifikuje interakcije koje imaju jaku korelaciju sa ukupnom kvalitetom dijaloga u postavljanju razgovora. Eksperimenti pokazuju da se automatska analiza našeg modela slaže sa ekspertskim osuđivanjima, čineći to prvo da pokaže da je tako slabo nadzirano učenje kvalitetnog predviđanja na nivou reči vrlo dostupno.', 'so': "Horumarinta aqoonta isticmaalayaasha nidaamka dialogka inta badan waxaa loo baahan yahay in aad u dadaasho horumarinta si uu u akhriyo qoraalada hadalka, baaritaanka takhasuska, iyo in loo sameeyo muhiim muhiim u ah koobnaha nidaamka. Kanu warqaddaas wuxuu diyaariyaa qaab warqad ah oo u sameynaya baaritaanka qoraalka conversation oo baranaya xiriirka u dhexeeya xiriirka isticmaalka iyo u dhexeeya takhasuska dialogka oo dhan. Shaqo horay oo aan ka dhigin wax ku saabsan wax ku saabsan waxyaabaha heerka hadalka, dhaqdhaqaaqyadeenu waxay saameyn ku leedahay faa'iidada isticmaalaha oo dhan, iyadoo aan dhibaato ku lahayn heerka hadalka, waxaana suurtowda dhamaadka modelalka, si ay ugu heshiiyaan caddeynta faa'iido ah iyo kharashka yar. Tusaalkayagu wuxuu muuqanayaa xiriir xoog leh oo la xiriira qiimaha dialogka oo dhan, taas oo ku qoran chatbot. Imtixaanka waxaa muuqda in baaritaanka bilowga ah ee modellkayaga uu ka heshiiyaa xukummada khaaska ah, taas oo ka dhiganaya marka ugu horeysa inuu muujiyo in barashada aqoonta qiimaha heerka ee hadalka aad looga maamulo.", 'sv': 'Att f철rb채ttra anv채ndarupplevelsen av ett dialogsystem kr채ver ofta intensiva utvecklingsanstr채ngningar f철r att l채sa konversationsloggar, k철ra statistiska analyser och f철rst책 den relativa betydelsen av systemfrister. Denna uppsats presenterar en ny metod f철r automatiserad analys av konversationsloggar som l채r sig relationen mellan anv채ndar-system interaktioner och 철vergripande dialogkvalitet. Till skillnad fr책n tidigare arbete med kvalitetsf철ruts채gelse p책 yttrandeniv책 l채r vi oss effekten av varje interaktion fr책n det 철vergripande anv채ndarbetyget utan kommentarer p책 yttrandeniv책, vilket g철r det m철jligt att dra slutsatser fr책n resultatet av modellen utifr책n empirisk evidens och till l책g kostnad. V책r modell identifierar interaktioner som har ett starkt samband med den 철vergripande dialogkvaliteten i en chattbot inst채llning. Experiment visar att den automatiserade analysen fr책n v책r modell 철verensst채mmer med expertbed철mningar, vilket g철r detta arbete till det f철rsta f철r att visa att ett s책dant svagt 철vervakat l채rande av uttalskvalitetsf철ruts채gelse 채r mycket uppn책eligt.', 'ta': 'உரையாடல் முறைமையின் பயனர் அனுபவத்தை மேம்படுத்துவது பெரும்பாலும் உரையாடல் முறைமையில் மேம்படுத்தும் முயற்சி தேவைப்படுகிறது, பேச் This paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality.  முன்னால் வார்த்தையின் தரம் முன்வைப்பு வேலையை வெளிப்படுத்துவதற்கு முன்னால், எங்கள் முறைமை ஒவ்வொரு இடைவெளிப்பாட்டின் விளைவை மொத்த பயனர் விகிதத்திலிரு எங்கள் மாதிரி அரட்டை அமைப்பில் ஒரு மொத்த உரையாடல் தரம் உடன் உறுதியான இணைப்புகளை குறிப்பிடும். முயற்சிகளில் இருந்து தானியங்கிய ஆய்வு நம் மாதிரியிலிருந்து விசேஷ நிறுவனங்களுடன் ஒப்புக்கொள்கிறது, இது முதலில் செயல்படுத்துகிறது இது மிகவும் பல', 'si': 'සංවාද පද්ධතියේ ප්\u200dරයෝජකය අභ්\u200dයාගයක් වැඩ කරන්න ප්\u200dරයෝජනය විශ්වාස කරනවා සංවාද ලොග් කියවන්න, සංවාද විශ්ලේෂණ මේ පැත්තේ ප්\u200dරවේශකය- පද්ධති සම්බන්ධය සහ සාමාන්\u200dය සංවාදය ගැන ස්වයංක්\u200dරීය විශ්ලේෂණය සඳහා සම්බන්ධය ප්\u200dරවේ ප්\u200dරශ්න ස්තූතිය ප්\u200dරශ්නයක් විදිහට පස්සේ වැඩ කරන්න අනමුත්, අපේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ඉගෙන ගන්නවා හැම ප්\u200dරශ්නයක්ම ප්\u200dරශ්නයක්ම ප්\u200dරශ්නයක්ම ප්\u200d අපේ මොඩල් එක්ක සම්බන්ධයක් හඳුනානවා ඒ වගේම ශක්තිමත් සම්බන්ධයක් තියෙනවා සම්බන්ධ සංවාදය සැකසු පරීක්ෂණය පෙන්වන්නේ අපේ මොඩේල් එකේ ස්වයංක්\u200dරිය විශ්ලේෂණ විශ්ලේෂණයක් විශ්වාස කරන්න පුළුවන් විදියට, මේ වැඩ පෙන්වන්න පළම', 'ur': 'ایک диалог سیسٹم کا کارساز تجربہ بہت زیادہ اضافہ کرنے کی ضرورت ہے کہ کلام لاگ پڑھنے کے لئے بہت اضافہ ڈولوپٹر کی کوشش کریں، ایسٹیسٹی تحلیل کریں اور سیسٹم ناکاموں کی نسبت اضافہ کریں۔ یہ کاغذ ایک نئی طریقہ پیش کرتا ہے جو مکالمانی لاگ کی آٹوٹی تحلیل کے لئے ہے جو کارساز-سیستم مصاحبات کے درمیان رابطہ کی تعلیم کرتا ہے اور کل ڈالگو کی کیفیت کے لئے۔ بات سطح کی کیفیت پیش بینی کے بارے میں پہلے کے کام کے مطابق، ہماری تقریبا ہر تعامل کا تأثیر معلوم کرتا ہے کلام استعمال سطح کے بغیر کلمات سطح کے علائم سے، اور نتیجہ موڈل کا نتیجہ معلوم کرنا اجازت دیتا ہے کہ امپریکل دلیلیں اور کم قیمت پر پائیں ہماری مدل ایک چاٹبوٹ سٹینٹ میں مضبوط تعلق کے ساتھ مضبوط تعلق ہے۔ تجربے دکھاتے ہیں کہ ہمارے موڈل سے اتوماٹی تحلیل مطابق مخصوص فیصلے کے ساتھ موافق ہوتی ہے، یہ کام پہلی دکھاتا ہے کہ یہ بات سطح کی کیفیت کی پیش بینی کی کمزور تحقیق کی تعلیم بہت زیادہ موافق ہے۔', 'uz': "Improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings.  Name Bizning birinchi so'zlar darajadagi taqdimlik ishni o'rganadi, bizning fikrimimiz hamma foydalanuvchidagi interaksiyatlarning tashkilotlarini o'rganadi, gapiruvchi darajadagi taqdimot emas, va natijadagi modelning natijalarini muvaffaqiyatlar va qiymatda kichkina qiymatda yaratishga ruxsat beradi. Bizning modelimiz chatbot moslamalarida umumiy muloqat loyihasiga murojaat qiladigan interfektlarni aniqlaydi. Tajribalar modelimizning avtomatik analyzeri ekspert xukunalar bilan bog'liqdir. Bu birinchi ishni ko'rsatish mumkin, bu suhbat darajadagi o'rganishni o'rganish juda juda muhimiy emas.", 'vi': 'Việc tăng kinh nghiệm của người dùng trong hệ thống đối thoại thường yêu cầu lập trình tăng cường nỗ lực đọc nhật trình trò chuyện, thực hiện các phân tích thống, và thấu hiểu tầm quan trọng của hệ thống thiếu sót. Tờ giấy này cung cấp một phương pháp mới cho việc phân tích các cuộc đối thoại tự động. Nó học được mối quan hệ giữa các hệ thống người dùng và chất lượng cuộc đối thoại. Không giống như dự đoán chất lượng cấp thấp trước, phương pháp của chúng tôi học tác động của mỗi giao tiếp từ đánh giá tổng thể người dùng mà không ghi chú cấp độ phát âm, cho phép kết luận mẫu kết quả dựa trên chứng cứ thực tế và với giá thấp. Mô hình của chúng ta xác định các tương tác có mối tương quan mạnh với chất lượng cuộc đối thoại tổng hợp trong một thiết lập chat. Thí nghiệm cho thấy rằng cách phân tích tự động từ mô hình của chúng ta đồng ý với phán quyết của chuyên gia, làm việc này trở thành việc đầu tiên cho thấy khả năng dự đoán chất lượng thấp có khả năng được theo dõi.', 'nl': "Het verbeteren van de gebruikerservaring van een dialoogsysteem vereist vaak intensieve inspanningen van ontwikkelaars om conversatieloogs te lezen, statistische analyses uit te voeren en het relatieve belang van systeemtekortkomingen te begrijpen. Dit artikel presenteert een nieuwe benadering van geautomatiseerde analyse van conversation logs die de relatie leert tussen gebruiker-systeem interacties en algemene dialoogkwaliteit. In tegenstelling tot eerdere werkzaamheden met betrekking tot kwaliteitsvoorspelling op uitingsniveau, leert onze aanpak de impact van elke interactie uit de algemene gebruikersbeoordeling zonder annotatie op uitingsniveau, waardoor resulterende modellconclusies kunnen worden afgeleid op basis van empirisch bewijs en tegen lage kosten. Ons model identificeert interacties die een sterke correlatie hebben met de algemene dialoogkwaliteit in een chatbot-instelling. Experimenten tonen aan dat de geautomatiseerde analyse van ons model overeenkomt met de beoordelingen van deskundigen, waardoor dit werk als eerste aantoont dat zo'n zwak begeleid leren van voorspelling van kwaliteit op uitingsniveau zeer haalbaar is.", 'da': 'Forbedring af brugeroplevelsen af et dialogsystem kræver ofte en intensiv udviklerindsats for at læse samtalelog, køre statistiske analyser og indse den relative betydning af systemmangler. Denne artikel præsenterer en ny tilgang til automatiseret analyse af samtalelog, der lærer forholdet mellem bruger-system interaktioner og overordnet dialog kvalitet. I modsætning til tidligere arbejde med forudsigelse af kvalitet på taleniveau lærer vores tilgang effekten af hver interaktion ud fra den samlede brugervurdering uden kommentarer på taleniveau, hvilket gør det muligt at udlede resultaterne af modelkonsuklusioner på grundlag af empirisk evidens og til lave omkostninger. Vores model identificerer interaktioner, der har en stærk sammenhæng med den overordnede dialogkvalitet i en chatbot-indstilling. Eksperimenter viser, at den automatiserede analyse fra vores model er i overensstemmelse med ekspertvurderinger, hvilket gør dette arbejde til det første til at vise, at en sådan svagt overvåget læring af taleniveau kvalitet forudsigelse er yderst opnåelig.', 'bg': 'Подобряването на потребителското преживяване на диалоговата система често изисква интензивни усилия на разработчиците за четене на дневниците на разговорите, извършване на статистически анализи и интуиция на относителната важност на системните недостатъци. Тази статия представя нов подход към автоматизиран анализ на дневниците на разговори, който научава връзката между взаимодействията потребител-система и цялостното качество на диалога. За разлика от предишната работа по прогнозиране на качеството на изказването, нашият подход научава въздействието на всяко взаимодействие от общия потребителски рейтинг без анотация на ниво изказване, което позволява резултатните заключения от модела да бъдат извлечени въз основа на емпирични доказателства и при ниски разходи. Нашият модел идентифицира взаимодействия, които имат силна корелация с цялостното качество на диалога в чатбот настройка. Експериментите показват, че автоматизираният анализ от нашия модел съответства на експертните преценки, което прави тази работа първата, която показва, че такова слабо контролирано обучение на прогнозиране на качеството на изказването е високо постижимо.', 'hr': 'Poboljšavanje iskustva korisnika sustava dijaloga često zahtijeva intenzivne napore razvijača za čitanje dnevnika razgovora, provođenje statističkih analiza i uvjeravanje relativne važnosti nedostataka sustava. Ovaj papir predstavlja novi pristup automatskoj analizi dnevnika razgovora koji nauči odnos između interakcija korisnika i ukupnog dijaloga. Za razliku od prethodnog rada o predviđanju kvalitete na razini govora, naš pristup nauči učinak svake interakcije od ukupnog ocjena korisnika bez oznake na razini govora, omogućavajući rezultate model zaključka da se donose na temelju empiričkih dokaza i na niske cijene. Naš model identificira interakcije koje imaju jaku korelaciju sa ukupnom kvalitetom dijaloga u postavku za razgovor. Eksperimenti pokazuju da se automatska analiza našeg modela slaže sa stručnim osuđivanjima, čineći to prvo da pokaže da je tako slabo nadzirano učenje kvalitetnog predviđanja na razini govora vrlo dostupno.', 'de': 'Die Verbesserung der Benutzererfahrung eines Dialogsystems erfordert oft intensive Entwicklungsanstrengungen, um Konversationsprotokolle zu lesen, statistische Analysen durchzuführen und die relative Bedeutung von Systemmängeln zu erkennen. Dieser Beitrag stellt einen neuartigen Ansatz zur automatisierten Analyse von Konversationsprotokollen vor, der den Zusammenhang zwischen Benutzer-System-Interaktionen und der allgemeinen Dialogqualität lernt. Im Gegensatz zu früheren Arbeiten zur Vorhersage der Qualität auf Äußerungsebene lernt unser Ansatz die Auswirkungen jeder Interaktion aus der Gesamtbewertung der Nutzer ohne Annotation auf Äußerungsebene, sodass daraus resultierende Modellfolgerungen auf Basis empirischer Evidenz und zu geringen Kosten abgeleitet werden können. Unser Modell identifiziert Interaktionen, die eine starke Korrelation mit der allgemeinen Dialogqualität in einem Chatbot-Setting haben. Experimente zeigen, dass die automatisierte Analyse unseres Modells mit Expertenmeinungen übereinstimmt, so dass diese Arbeit erstmals zeigt, dass ein solches schwach überwachtes Lernen von Äußerungsqualitätsvorhersagen sehr realisierbar ist.', 'ko': '대화 시스템의 사용자 체험을 개선하려면 개발자가 대화 로그를 대량으로 읽고 통계 분석을 하며 시스템 결함의 상대적인 중요성을 직관적으로 이해해야 한다.본고는 대화 로그를 자동으로 분석하는 새로운 방법을 제시하여 사용자 시스템의 상호작용과 전체 대화의 질 간의 관계를 이해할 수 있다.이전의 언어 수준 품질 예측에 관한 작업과 달리 우리의 방법은 언어 수준 주석이 없는 전체적인 사용자 평점에서 모든 상호작용의 영향을 배워서 경험적 증거와 낮은 원가를 바탕으로 최종 모델 결론을 얻는다.우리의 모델은 채팅 로봇 환경에서 전체 대화의 질과 밀접한 관계를 가진 상호작용을 확정했다.실험에 의하면 우리 모델의 자동 분석은 전문가의 판단과 일치한다. 이것은 이런 약한 감독 학습의 언어 품질 예측이 고도로 실현될 수 있다는 것을 처음으로 증명한 것이다.', 'id': 'Menembak pengalaman pengguna dari sistem dialog sering membutuhkan usaha pengembang intens untuk membaca catatan percakapan, menjalankan analisis statistik, dan intuit penting relatif kekurangan sistem. Kertas ini menunjukkan pendekatan baru untuk analisis otomatis log percakapan yang mempelajari hubungan antara interaksi pengguna-sistem dan kualitas dialog umum. Tidak seperti pekerjaan sebelumnya pada prediksi kualitas tingkat ucapan, pendekatan kita mempelajari dampak setiap interaksi dari nilai pengguna keseluruhan tanpa anotasi tingkat ucapan, memungkinkan kesimpulan model hasil untuk diproduksi berdasarkan bukti empiris dan dengan biaya rendah. Model kita mengidentifikasi interaksi yang memiliki korelasi yang kuat dengan kualitas dialog umum dalam seting chatbot. Experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable.', 'sw': 'Kuboresha uzoefu wa mtumiaji wa mfumo wa mazungumzo mara nyingi unahitaji jitihada za maendeleo yenye nguvu ya kusoma loga za mazungumzo, kufanya uchambuzi wa takwimu, na kuweka bayana umuhimu wa ukosefu wa mfumo wa mfumo. Gazeti hili linaleta mbinu ya riwaya ya uchambuzi wa blogu za mazungumzo yanayojifunza uhusiano kati ya mijadala ya watumiaji na kiwango kikubwa cha mazungumzo. Tofauti na kazi za kabla kuhusu utabiri wa kiwango cha mazungumzo, mbinu yetu inajifunza athari ya kila mahusiano kutoka kwa watumiaji wa jumla bila kutangaza kiwango cha mazungumzo, na kuwaruhusu matokeo ya mifano yanayotokana kwa msingi wa ushahidi na kwa gharama ndogo. Mfano wetu unaonyesha mahusiano yanayohusiana na kiwango kikubwa cha mazungumzo katika mazungumzo ya mazungumzo. Majaribio yanaonyesha kwamba uchambuzi wa mifano yetu unakubaliana na maamuzi ya wataalam, na kufanya kazi hii ya kwanza ya kuonyesha kwamba utabiri wa kiwango cha kiwango cha kusema umefanikiwa sana.', 'tr': 'Ullançylaryň bir dialoog sisteminiň täzeliklerini gowlaşdyrmak köplenç sohbet günlüklerini okamak, statistik analyzlary çaplamak we sistem ýeterlikleriniň wajyplygyny çykarmak üçin gaty uly täzelikleri gerek. Bu kagyz ullançy-sistem etkileşimleri we ähli dijalog howplygynyň arasyndaky baglaýyşyny awtomatik analyze etmäge täze bir ýazşy görkezýär. Sözleşme derejesi kwalitet öňünde öňki işiň ýaly, biziň ýaryşymyz hemme ullançylaryň söz derejesi ýok ýagşyrymyzdan täsirini öwredýär, netijeli nusgalary empirik kanunlaryň esasynda we düşük bahalaryň üstünde çykarýar. Biziň modelimiz çäbiň düzümlerinde güýçli bir baglaýyşlygyny tanap edýär Denminatlar biziň modelimizdeki awtomatik analýusiýanyň uzmanly hökmünler bilen ylalaşýandygyny görkezýär. Bu işi ilkinji gezek çykyş ýok-ýuwaşlyk bilen kellämiz howpsuzlyk öwrenmesiniň uly ýetişdirilýändigini görkezýär.', 'af': "Geverbetering van gebruiker erfaring van 'n dialoog stelsel benodig dikwels intensiewe ontwikkelaar versoek om gesprekslys logs te lees, hardloop statistiese analiserings en intuig die relatiewe belangrikheid van stelsel kortpad. Hierdie papier stel 'n nuwe toegang aan outomatiese analisie van gesprekslys logs wat leer die verhouding tussen gebruiker- stelsel interaksies en die hele dialoog kwaliteit. Ongelyks van vooraf werk op uitspraak-vlak-kwaliteit voorskou, leer ons toegang die effekt van elke interaksie van die hele gebruiker-reitings sonder uitspraak-vlak-annotasie, toelaat resultateerde model-konklusies op die basis van empiriese bevestigheid en op lae koste afgelei word. Ons model identifiseer interaksies wat 'n sterk korrelasie het met die hele dialoog-kwaliteit in 'n geselskap instelling. Eksperimente wys dat die outomatiese analisie van ons model ooreenkomstig met ekspertige oordelinge, maak hierdie werk die eerste om te wys dat sodanige swak-ondersoekte leer van uitspraak-vlak-kwaliteit voorskou baie aanvaarbaar is.", 'fa': 'بهتر تجربه کاربر از یک سیستم محاوره اغلب نیاز به تلاش\u200cهای توسعه\u200cکننده\u200cی سخت\u200cگیری برای خواندن یادداشتهای صحبت، تحلیل\u200cهای استاریسی را اجرا کند و مهم نسبت به ناتوانی سیستم را مشاهده کند. این کاغذ یک روش نویسی برای تحلیل خودکار از مجموعه\u200cهای صحبت را نشان می\u200cدهد که رابطه بین تعاملات سیستم کاربر و کیفیت کل صحبت را یاد می\u200cگیرد. برخلاف کارهای قبلی در پیش بینی کیفیت سطح سخنرانی، دستور ما تاثیر هر تعامل از ارتباط عمومی از نویسندگی سطح سخنرانی بدون نویسندگی سطح سخنرانی یاد می\u200cگیرد، که اجازه می\u200cدهد نتیجه\u200cهای مدل نتیجه بر اساس مدارک امپراتیک و با هزینه\u200cهای کم با مدل ما تعاملات های قوی را شناسایی می کند که با کیفیت کلی محاورش در یک تنظیمات صحبت دارند. تجربه ها نشان می دهند که تحلیل اتوماتیک از مدل ما با قضاوت های متخصص موافق است، و این کار را اول انجام می دهد که نشان می دهد که این یادگیری که کم تحت نظر گرفته شده از پیش بینی کیفیت سطح سخنرانی بسیار قابل رسیدگی است.', 'am': 'በጥያቄ ማኅበረሰብ ውስጥ የሚጠቅመውን የጥያቄ እውቀት ብዙ ጊዜም የድምፅ አካባቢ ዝርዝር ማነብ፣ statistical analyzer እንዲያስፈልግ እና የስርዓት ጉዳይ ግንኙነት እንዲያስፈልግ ያስፈልጋል፡፡ ይህ ፕሮግራም በተጠቃሚ የስርዓት ግንኙነት እና በጥያቄ ጥያቄ መካከል ግንኙነትን የሚያስተምር የኖሮውን አቀማመጥ የሚያቀርብ ነው፡፡ ከቀድሞ የቃላት-ደረጃ ጥያቄ ለመፍጠር የሚደረግ ሥራ፣ የሁሉንም ግንኙነት ከንግግር-ደረጃ ማቀናቀል፣ የፍሬው የሞዴል ፍጻሜ በአስማሪ ማስረጃ እና በዋጋው ዋጋ ታናሽ ክፍል እንዲሆን ይችላል፡፡ ሞዴሌያችን በአካባቢት አካባቢ ጥያቄ ላይ በጥያቄ ጥያቄ የሚያስፈልገውን ግንኙነት የሚያሳውቃቸዋል፡፡ ፈተናዎች የሞዴል አካባቢ ምርጫዎች ከደካማ የቃላት-ደረጃ ሙሉ ትንቢት ትንቢት መግለጽ እጅግ የሚያስፈልገው እንደሆነ የመጀመሪያውን ሥራ ያሳያል፡፡', 'sq': 'Përmirësimi i përvojës së përdoruesve të një sistemi dialogu shpesh kërkon përpjekje intensive për zhvilluesit për të lexuar regjistrat e bisedimeve, për të kryer analiza statistike dhe për të intuituar rëndësinë relative të mungesave të sistemit. Ky dokument paraqet një qasje të re për analizën e automatizuar të regjistrimeve të bisedimeve që mëson lidhjen midis ndërveprimeve përdorues-sistemi dhe cilësisë së përgjithshme të dialogut. Ndryshe nga puna e mëparshme mbi parashikimin e cilësisë në nivelin e shprehjes, qasja jonë mëson ndikimin e çdo ndërveprimi nga vlerësimi i përgjithshëm i përdoruesit pa anotacion në nivelin e shprehjes, duke lejuar përfundimet e modelit rezultues të nxirren në bazë të provave empirike dhe me kosto të ulët. Modeli ynë identifikon ndërveprime që kanë një korrelacion të fortë me cilësinë e përgjithshme të dialogut në një përcaktim chatbot. Eksperimentet tregojnë se analiza e automatizuar nga modeli ynë është dakord me gjykimet eksperte, duke e bërë këtë punë të parë për të treguar se mësimi i tillë i dobët mbikqyrur i parashikimit të cilësisë në nivelin e shprehjes është mjaft i arritshëm.', 'hy': 'Հաճախ անհրաժեշտ է ինտենսիվ զարգացողների փորձ օգտագործելու համար խոսակցության օրագիրներ կարդալու, վիճակագրական վերլուծություններ կատարելու և համակարգի բացակայությունների հարաբերական կարևորությունը ինտուիտիվ: Այս հոդվածը ներկայացնում է խոսակցության օրագիրների ավտոմատիկ վերլուծության նոր մոտեցում, որը սովորում է օգտագործողի և համակարգի փոխազդեցությունների և ընդհանուր պատմության որակի հարաբերությունները: Ի տարբերություն արտահայտության մակարդակի որակի կանխատեսման նախորդ աշխատանքին, մեր մոտեցումը սովորում է յուրաքանչյուր փոխազդեցության ազդեցությունը ընդհանուր օգտագործողի գնահատականից առանց արտահայտության մակարդակի նշումների, թույլ տալով, որ արդյունքում եղած մոդելի եզրա Մեր մոդելը բացահայտում է փոխազդեցություններ, որոնք ուժեղ կապ ունեն խոսակցության ընդհանուր որակի հետ: Փորձարկումները ցույց են տալիս, որ մեր մոդելի ավտոմատիկ վերլուծությունը համաձայն է մասնագետների դատողությունների հետ, դարձնելով այս աշխատանքը առաջինը ցույց տալու համար, որ խոսքի մակարդակի որակի կանխատեսման այդպիսի թույլ վերահսկվող ուսումնասիրությունը շատ հասանելի', 'ca': "Per millorar l'experiència dels usuaris d'un sistema de diàleg sovint es necessita un esforç intensiv de desenvolupament per llegir registres de converses, fer anàlisis estadístics i intuir la relativa importància dels defectes del sistema. Aquest paper presenta un nou enfocament a l'anàlisi automatitzada dels registres de converses que aprenen la relació entre les interaccions entre l'usuari i el sistema i la qualitat general del diàleg. A diferència de la feina anterior sobre la predicció de la qualitat del nivell d'expressió, el nostre enfocament aprene l'impacte de cada interacció a partir de la puntuació general de l'usuari sense anotació del nivell d'expressió, permetent que les conclusions del model resultant es derivin sobre la base d'evidències empíriques i a baix cost. El nostre model identifica interaccions que tenen una forta correlació amb la qualitat global del diàleg en un entorn de chatbot. Els experiments demostren que l'anàlisi automatitzada del nostre model està d'acord amb els judicis d'experts, fent que aquesta funció sigui la primera que demostre que l'aprenentatge de predicció de qualitat de nivell d'expressió tan dèbil és altament aconseguible.", 'az': 'Dialog sisteminin istifadəçilərinin təcrübəsini yaxşılaşdırmaq çox sıxıntılı inkişafçı günlüklərini oxumaq, statistik analizlərini çalışmaq və sistemin zəifliklərinin əlaqəsizlik məqsədilə təcrübə etmək lazımdır. Bu kağıt istifadəçi-sistem istifadəçilərin və bütün dijalog keyfiyyəti arasındakı ilişkisini öyrənən avtomatik analizi üçün yeni bir yol göstərir. Sözlük seviyyəti tədbirlərinin əvvəlki çalışmalarına bənzər, bizim tərzimiz hər istifadəçinin tədbirlərinin təsirini söyləmə seviyyəsi olmadan öyrənir, böyük modellərin sonuçlarını empirik kanıtların və düşük qiymətlərin tərəfindən istifadə edir. Bizim modellərimiz çöpçü ayarlarında bütün dijalog keyfiyyəti ilə güclü bir bağlantıları tanıyır. Həqiqətən, modelimizdən automatsk analizi müxtəlif hökmlərə razılıq edir, bu işi ilk dəfə göstərmək üçün böyük zəif-gözləyirli sözlər seviyyəti tədbirlərin tədbirlərinin çox mümkün olduğunu göstərər.', 'bn': 'ডায়ালগ সিস্টেমের ব্যবহারকারীদের অভিজ্ঞতা উন্নতি করার প্রায়শ প্রয়োজন যে কথোপকথন লগগুলো পড়ার জন্য গভীর উন্নয়নের প্রচেষ্টা প্রয়োজন, পরি এই পত্রিকাটি আলোচনার ব্লগের স্বয়ংক্রিয়ভাবে বিশ্লেষণের জন্য একটি নভেল প্রযুক্তি উপস্থাপন করেছে যা ব্যবহারকারী সিস্টেমের ইন ভাষার মানের ভবিষ্যদ্বাণীর পূর্বে কাজের প্রভাব ছাড়া আমাদের প্রত্যেকটি কাজের প্রভাব শিখতে পারে সাধারণ ব্যবহারকারীদের কথাবার্তা পর্যায়ের ক্ষেত্রে ব্যবহারকারীর আমাদের মডেল চ্যাটবোট বৈশিষ্ট্যের সাথে সাধারণ আলোচনার মানে শক্তিশালী সম্পর্ক চিহ্নিত করেছে। পরীক্ষাগুলো দেখাচ্ছে যে আমাদের মডেল থেকে স্বয়ংক্রিয় বিশেষজ্ঞ বিচারের সাথে স্বয়ংক্রিয় বিশেষজ্ঞ চুক্তি প্রদান করেছে, এটা প্রথমে কাজ করেছে', 'bs': 'Poboljšanje iskustva korisnika sustava dijaloga često zahtijeva intenzivne napore razvijača za čitanje dnevnika razgovora, obavljanje statističkih analiza i intuiranje relativne važnosti nedostataka sustava. Ovaj papir predstavlja novi pristup automatskoj analizi dnevnika razgovora koji nauči vezu između interakcija korisnika i ukupnog dijaloga. Za razliku od prethodnog rada o predviđanju kvalitete na nivou govora, naš pristup nauči učinak svake interakcije od ukupnog ocjena korisnika bez annotacije nivoa govora, omogućavajući rezultate model zaključka da se donose na temelju empiričkih dokaza i na niske cijene. Naš model identificira interakcije koje imaju jaku korelaciju sa ukupnom kvalitetom dijaloga u postavku za razgovor. Eksperimenti pokazuju da se automatska analiza našeg modela slaže sa stručnim osuđivanjima, čineći to prvo da pokaže da je tako slabo nadzirano učenje kvalitetnog predviđanja na nivou govora jako dostupno.', 'cs': 'Zlepšení uživatelské zkušenosti dialogového systému často vyžaduje intenzivní úsilí vývojářů číst konverzační protokoly, provádět statistické analýzy a intuitivní význam systémových nedostatků. Tento článek představuje nový přístup k automatizované analýze konverzačních protokolů, který se naučí vztah mezi interakcí uživatele-systému a celkovou kvalitou dialogu. Na rozdíl od předchozích prací na predikci kvality výroku se náš přístup naučí dopad každé interakce z celkového hodnocení uživatelů bez anotace na úrovni výroku, což umožňuje odvodit výsledné modelové závěry na základě empirických důkazů a za nízké náklady. Náš model identifikuje interakce, které mají silnou korelaci s celkovou kvalitou dialogu v nastavení chatbotu. Experimenty ukazují, že automatizovaná analýza z našeho modelu souhlasí s odbornými posudky, takže tato práce jako první ukázala, že takové slabě dohlížené učení predikce kvality výroku je vysoce dosažitelné.', 'et': 'Dialoogisüsteemi kasutajakogemuse parandamine nõuab sageli intensiivseid arendajate pingutusi vestluslogide lugemiseks, statistiliste analüüside tegemiseks ja süsteemi puuduste suhtelise tähtsuse tajumiseks. Käesolev töö tutvustab uudset lähenemisviisi vestluslogide automatiseeritud analüüsile, mis õpib seost kasutaja-süsteemi suhtluse ja üldise dialoogi kvaliteedi vahel. Erinevalt varasematest töödest väljendustaseme kvaliteedi prognoosimisel õpib meie lähenemisviis iga suhtluse mõju kasutaja üldisest hinnangust ilma väljendustaseme märgistuseta, võimaldades tulemuslikke mudelite järeldusi teha empiiriliste tõendite põhjal ja madalate kuludega. Meie mudel tuvastab interaktsioone, millel on tugev seos vestlusboti üldise dialoogi kvaliteediga. Eksperimentid näitavad, et meie mudeli automatiseeritud analüüs on kooskõlas ekspertide hinnangutega, mistõttu see töö on esimene, mis näitab, et niisugune nõrgalt järelevalvetud kõnede kvaliteedi prognoosimise õppimine on väga saavutatav.', 'fi': 'Dialoogijärjestelmän käyttäjäkokemuksen parantaminen vaatii usein intensiivistä kehittäjän työtä keskustelulokien lukemiseen, tilastollisten analyysien suorittamiseen ja järjestelmän puutteiden suhteellisen merkityksen ymmärtämiseen. Tässä artikkelissa esitellään uusi lähestymistapa keskustelulokien automaattiseen analysointiin, joka oppii käyttäjän ja järjestelmän vuorovaikutuksen ja dialogin laadun välisen suhteen. Toisin kuin aiemmat lausuntotason laadunvarmistustyöt, lähestymistapamme oppii kunkin vuorovaikutuksen vaikutuksen käyttäjäluokituksesta ilman lausuntotason merkintöjä, jolloin tuloksena olevat mallijohtopäätökset voidaan tehdä empiirisen näytön perusteella ja edullisesti. Mallimme tunnistaa vuorovaikutukset, joilla on vahva korrelaatio chatbotin yleisen dialogin laatuun. Kokeet osoittavat, että mallimme automatisoitu analyysi sopii asiantuntijoiden arviointiin, joten tämä työ on ensimmäinen, joka osoittaa, että tällainen heikosti valvottu lauseen laadun ennustamisen oppiminen on erittäin saavutettavissa.', 'jv': 'Ngawe nggunakake alamat sistem sing dibutuhke ing nggunakake sistem sing butuh kudu nggawe barang nggawe tarjamahan, ngubah dipileksi dadi stasitik lan ngawe barang nggawe sistem sing dikarolan nggawe Perintah sing nyebatasan dadi nganggo akeh penjelok automatik kanggo nggawe conversasi dadi iki bakal mlaku nggawe barang gambaran interaksi sistem karo akeh cogaturan dialog Speaking modellu Awak dhéwé éntuk karo hal-hal akeh lanjut ning model sing beraksi barêng nggawe aturan sing paling nggawe aturan kuwi, nggawe ngubah iki ulih apik dhéwé iso nguasai iki bakal terus lanjut cara sing paling-perbudhakan sing apik dhéwé.', 'ha': "Fara wajen aikin mai amfani da shi na tsarin zauren akwatin bayani na zauren akwatin bayani waɗancan, ana buƙata aikin mai ƙaranci wajen karanta logogi masu husũma, da yin tafiyar Ana Ana saka da ƙayyade, kuma ana ƙayyade muhimmin muhimmanci na ƙararra na system. Wannan takardan na ƙayyade wani matsayi na yanzu dõmin a yi anarwa farat ɗaya wa logogi na mazaɓa, da yana sanar da mazaɓa tsakanin interfessor masu amfani da na'urar zauren zauren akwatin bayani na jumla. Di motsi da kafin aiki a kan kunyar sifar-leveli na magana, hanyoyinmu yana fahimta mai amfani da duk interaction daga rabon mai amfani da shi gaba ɗaya, kuma bã da wani haske mai magana ba, kuma yana yarda a sami ƙaramakon misãlai masu fasahan misãlai, a kan bayan umarni da ke ƙaranci. @ info: whatsthis Experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable.", 'he': 'שיפור ניסיון משתמש של מערכת דיאלוג דורש לעתים קרובות מאמץ מתפתח אינטנסיבי לקרוא יומני שיחה, לרוץ ניתוח סטטיסטי, ולאינטואיט את חשיבות יחסית של חסרות מערכת. העיתון הזה מציג גישה חדשה לניתוח אוטומטי של לוגי שיחה שמלמד את מערכת היחסים בין אינטראקציות משתמש-מערכת לאיכות הדיולוג הכללי. בניגוד לעבודה קודמת על חיזוי איכות רמת המילה, הגישה שלנו לומדת את ההשפעה של כל אינטראקציה מהשיעור של המשתמש הכללי ללא חיזוי רמת המילה, מאפשר למסקנות מודל תוצאות להידרש על בסיס ראיות אמפיריות ובמחיר נמוך. הדוגמא שלנו מזהה אינטראקציות שיש לה קשר חזק עם איכות הדיולוג הכללי בתוכנית chatbot. ניסויים מראים שהניתוח האוטומטי מהמודל שלנו מסכים עם שיפוטים מומחים, גורם לזה לעבוד הראשון כדי להראות שלמדה חולשה כזו של חיזוי איכות ברמה מילוטית הוא מאוד ניתן להשיג.', 'sk': 'Izboljšanje uporabniške izkušnje dialognega sistema pogosto zahteva intenzivno prizadevanje razvijalcev za branje dnevnikov pogovorov, izvajanje statističnih analiz in zaznavanje relativnega pomena pomanjkljivosti sistema. V prispevku je predstavljen nov pristop k avtomatizirani analizi dnevnikov pogovorov, ki spozna odnos med interakcijami med uporabnikom in sistemom ter splošno kakovostjo dialoga. V nasprotju s predhodnim delom na področju napovedovanja kakovosti izgovora se naš pristop uči učinek vsake interakcije iz celotne ocene uporabnikov brez opombe na ravni izgovora, kar omogoča, da rezultatne zaključke modela izpeljemo na podlagi empiričnih dokazov in z nizkimi stroški. Naš model identificira interakcije, ki imajo močno povezavo s splošno kakovostjo dialoga v nastavitvi klepetalnega bota. Eksperimenti kažejo, da se avtomatizirana analiza iz našega modela ujema s strokovnimi presojami, zaradi česar je to delo prvo, ki pokaže, da je takšno šibko nadzorovano učenje napovedi kakovosti izgovora zelo mogoče doseči.', 'bo': 'གླེང་སྒྲོམ་གྱི་ལག་ལེན་པ་ལ་སྤྱོད་མཁན་གྱི་ལྟ་ཞིབ་ཡར་རྒྱས ཤོག་བྱང་འདིས་སྤྱོད་མཁན་གྱི་གནད་དོན་དམིགས་འདི་ལ་རང་འགུལ་གྱིས་གཏམ་གླེང་སྒྲོམ་ནང་གི་མཐུན་སྒྲིག་ནི་ Unlike before work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. ང་ཚོའི་མ་དབྱིབས་ཀྱིས་མཐུན་སྣེ་ཡོད་པའི་གླེང་སྒྲོམ་གྱི་སྒྲིག་འགོད་ཐོག་གི་མཐུན་སྒྲིག་འབྲེལ་བ་ཡོད་པ ལག་ལེན་བྱ་ཚིག་གིས་ང་ཚོའི་མ་དབུགས་ལས་རང་འགུལ་གྱི་དབྱེ་ཞིབ་དཔྱད་ཞིབ་བྱེད་པ་ལས་གནད་དོན་ནི་གསལ་རྟོགས་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Semi-supervised Intent Discovery with Contrastive Learning', 'ar': 'اكتشاف النوايا شبه الخاضع للإشراف مع التعلم التقابلي', 'fr': "Découverte d'intention semi-supervisée avec apprentissage contrastif", 'pt': 'Descoberta de intenção semi-supervisionada com aprendizagem contrastiva', 'es': 'Descubrimiento de intenciones semisupervisado con aprendizaje contrastivo', 'ja': '対照的な学習による半監督的な意図の発見', 'zh': '有半监于学者', 'hi': 'Contrastive Learning के साथ अर्ध-पर्यवेक्षित इरादा डिस्कवरी', 'ru': 'Полунамеренное открытие под наблюдением с контрастным обучением', 'ga': 'Fionnachtain Rúin leathmhaoirsithe le Foghlaim Chodarsnachta', 'ka': 'ნახევარჯერი ინტერნტი განახლება კონტრესტიგური სწავლების შესახებ', 'el': 'Ημι-εποπτευόμενη ανακάλυψη προθέσεων με Αντιστατική Μάθηση', 'hu': 'Félig felügyelt Intent Discovery kontrasztív tanulással', 'it': 'Scoperta di Intent Semisupervisionata con Apprendimento Contrastivo', 'lt': 'Puskontroliuojamas ketinimas atskleisti kontrastinį mokymąsi', 'kk': 'Контрастырлық оқу арқылы жарты бақылау үшін', 'ms': 'Penemuan Intent Semi-mengawasi dengan Belajar Kontrastif', 'ml': 'കോണ്\u200dട്രാസ്റ്ററിവ് പഠിക്കുന്നതിനൊപ്പം സെമി- നിരീക്ഷിക്കപ്പെട്ട ഉള്ള ഡിസ്ക്വറി', 'mt': 'Sejbien Intent Semi-Sorveljat b’Tagħlim Kontrastiv', 'mn': 'Хагасалтай суралцах талаар удирдлагатай ухаан олох', 'no': 'Halvoversikt intentoppdaging med kontrastiv læring', 'pl': 'Pół-nadzorowane odkrycie intencji z kontrastywnym uczeniem się', 'mk': 'Половина надгледувано откривање на намерата со контрастивно учење', 'ro': 'Descoperirea intenției semi-supravegheată cu învățare contrastivă', 'si': 'සම්බන්ධ විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට පරීක්ෂණය කරන්න', 'so': 'Ku baaraandegista waxbarashada xiriirka', 'sv': 'Halvövervakad Intent Discovery med kontrastivt lärande', 'ta': 'பாதி கண்காணிக்கப்பட்ட உள்ளடக்க கண்டுபிடிப்பு', 'ur': 'کنٹرسٹیو سیکھنے کے ساتھ نصف نظارت والی مضبوط دیسکوری', 'sr': 'Polovično nadgledano intenzivno otkriće sa kontrastivnim učenjem', 'uz': '@ info: whatsthis', 'vi': 'Nửa giám sát tỉ lệ thu nhập với Tương phản học', 'nl': 'Semi-supervised Intent Discovery met Contrastive Learning', 'bg': 'Полунадзорно откриване на намерения с контрастивно обучение', 'hr': 'Polovično nadzirano intenzivno otkriće s kontrastivnim učenjem', 'da': 'Semi-supervised Intent Discovery med kontrastiv læring', 'de': 'Halbüberwachte Intent Discovery mit kontrastivem Lernen', 'id': 'Penemuan Intent Semi-supervised dengan Belajar Kontrastif', 'ko': '비교 학습에 기초한 반감독 의도 발견', 'sw': 'Ugunduzi wa Intaneti na Ufundishaji Mkuu', 'fa': 'پایین مراقبت مشهور با یادگیری متفاوت', 'af': 'Half- superviseer Intent Discovery met kontrastiewe leer', 'tr': 'Kontrol öğrenmek ile kalan Kontrol Kontrol Kalamy', 'am': 'CategoryName', 'sq': 'Semi-supervised Intent Discovery with Contrastive Learning', 'bn': 'পরিচিতি শিক্ষা দ্বারা সামিন-পর্যবেক্ষণ করা ইন্টারনেট ডিস্কোরি', 'hy': 'Կամի-վերահսկված մտադրական բացահայտությունը հակադրական ուսումնասիրությամբ', 'bs': 'Pola nadzornog Intenzivnog otkrića s kontrastivnim učenjem', 'az': 'Kontrast 칬yr톛nm톛si il톛 yar캼-g칬zl톛yirl톛n 칐yr톛nm톛', 'ca': 'Descubrir intencions semisupervisades amb aprenentatge contrastiu', 'et': 'Pooljuhendatud kavatsuste avastamine koos kontrastiivse õppega', 'cs': 'Objevování záměru s polovičním dohledem s kontrastním učením', 'fi': 'Semi-ohjattu Intent Discovery with Contrastive Learning', 'sk': 'Polnadzorovano odkrivanje namenov s kontrastnim učenjem', 'ha': '@ action', 'jv': 'Learn Mode', 'he': 'Semi-supervised Intent Discovery with Contrastive Learning', 'bo': 'རྒྱ་སྐྱེན་ཚད་ལྷན་རྒྱས་ལྗོངས་ཀྱི་སྣ་ཚོགས་སྟོན་པ'}
{'en': 'User intent discovery is a key step in developing a Natural Language Understanding (NLU) module at the core of any modern Conversational AI system. Typically, human experts review a representative sample of user input data to discover new intents, which is subjective, costly, and error-prone. In this work, we aim to assist the NLU developers by presenting a novel method for discovering new intents at scale given a corpus of utterances. Our method utilizes supervised contrastive learning to leverage information from a domain-relevant, already labeled dataset and identifies new intents in the corpus at hand using unsupervised K-means clustering. Our method outperforms the ', 'ar': 'يعد اكتشاف نية المستخدم خطوة أساسية في تطوير وحدة فهم اللغة الطبيعية (NLU) في صميم أي نظام حديث للذكاء الاصطناعي للمحادثة. عادة ، يقوم الخبراء البشريون بمراجعة عينة تمثيلية من بيانات إدخال المستخدم لاكتشاف نوايا جديدة ، وهي ذاتية ومكلفة وعرضة للخطأ. في هذا العمل ، نهدف إلى مساعدة مطوري NLU من خلال تقديم طريقة جديدة لاكتشاف نوايا جديدة على نطاق واسع في ضوء مجموعة من الأقوال. تستخدم طريقتنا التعلم التباين الخاضع للإشراف للاستفادة من المعلومات من مجموعة بيانات ذات صلة بالمجال ومُصنفة بالفعل وتحدد النوايا الجديدة في المجموعة الموجودة باستخدام مجموعات K غير الخاضعة للإشراف. تتفوق طريقتنا في الأداء على أحدث التقنيات بهامش كبير يصل إلى 2٪ و 13٪ على مجموعتي بيانات معياريتين ، تقاس بدقة التجميع. علاوة على ذلك ، نطبق طريقتنا على مجموعة بيانات كبيرة من مجال السفر لإثبات فعاليتها في حالة استخدام في العالم الحقيقي.', 'pt': 'A descoberta de intenção do usuário é uma etapa fundamental no desenvolvimento de um módulo de compreensão de linguagem natural (NLU) no centro de qualquer sistema de IA conversacional moderno. Normalmente, especialistas humanos analisam uma amostra representativa de dados de entrada do usuário para descobrir novas intenções, que são subjetivas, caras e propensas a erros. Neste trabalho, pretendemos ajudar os desenvolvedores de NLUs apresentando um novo método para descobrir novas intenções em escala dado um corpus de enunciados. Nosso método utiliza aprendizado contrastivo supervisionado para alavancar informações de um conjunto de dados já rotulado e relevante para o domínio e identifica novas intenções no corpus em questão usando clustering K-means não supervisionado. Nosso método supera o estado da arte por uma grande margem de até 2% e 13% em dois conjuntos de dados de referência, medidos pela precisão do agrupamento. Além disso, aplicamos nosso método em um grande conjunto de dados do domínio de viagens para demonstrar sua eficácia em um caso de uso do mundo real.', 'fr': "La découverte de l'intention de l'utilisateur est une étape clé dans le développement d'un module de compréhension du langage naturel (NLU) au cœur de tout système d'IA conversationnelle moderne. En général, les experts humains examinent un échantillon représentatif de données d'entrée utilisateur pour découvrir de nouvelles intentions, ce qui est subjectif, coûteux et sujet aux erreurs. Dans ce travail, nous visons à aider les développeurs de la NLU en présentant une nouvelle méthode pour découvrir de nouvelles intentions à l'échelle à partir d'un corpus d'énoncés. Notre méthode utilise l'apprentissage contrastif supervisé pour exploiter les informations d'un ensemble de données pertinent pour le domaine et déjà étiqueté et identifier de nouvelles intentions dans le corpus à l'aide d'un clustering K-means non supervisé. Notre méthode surpasse l'état de la technologie par une marge importante allant jusqu'à 2\xa0% et 13\xa0% sur deux ensembles de données de référence, mesurée par la précision du clustering. De plus, nous appliquons notre méthode à un large ensemble de données du domaine du voyage afin de démontrer son efficacité sur un cas d'utilisation réel.", 'es': 'El descubrimiento de la intención del usuario es un paso clave en el desarrollo de un módulo de comprensión del lenguaje natural (NLU) que sea el núcleo de cualquier sistema de IA conversacional moderno. Por lo general, los expertos humanos revisan una muestra representativa de los datos de entrada de los usuarios para descubrir nuevas intenciones, que son subjetivas, costosas y propensas a errores. En este trabajo, nuestro objetivo es ayudar a los desarrolladores de NLU presentando un método novedoso para descubrir nuevas intenciones a escala dado un conjunto de enunciados. Nuestro método utiliza el aprendizaje contrastivo supervisado para aprovechar la información de un conjunto de datos relevante para el dominio, ya etiquetado, e identifica nuevas intenciones en el corpus en cuestión mediante la agrupación de K-means no supervisada. Nuestro método supera al estado de la técnica por un amplio margen de hasta un 2% y un 13% en dos conjuntos de datos de referencia, medidos por la precisión de los clústeres. Además, aplicamos nuestro método en un gran conjunto de datos del dominio de viajes para demostrar su eficacia en un caso de uso del mundo real.', 'ja': 'ユーザーインテント発見は、現代の会話型AIシステムの中核である自然言語理解（ NLU ）モジュールを開発するための重要なステップです。通常、人間の専門家は、代表的なユーザー入力データのサンプルをレビューして、主観的でコストが高く、エラーが発生しやすい新しいインテントを発見します。この研究では、発話の主体として与えられた規模で新しいインテントを発見するための斬新な方法を提示することで、NLU開発者を支援することを目指しています。私たちの方法は、監視下の対照的な学習を利用して、ドメインに関連する、すでにラベル付けされたデータセットからの情報を活用し、監視下のK平均クラスタリングを使用して、手元のコーパス内の新しいインテントを識別します。当社の方法は、クラスタリングの精度によって測定される2つのベンチマークデータセットで、最先端のものを最大2%と13%の大幅なマージンで上回っています。さらに、旅行ドメインの大きなデータセットにメソッドを適用して、実際のユースケースでの有効性を実証します。', 'zh': '用户意发自然语言解(NLU)模块之关键步骤,自然语言解(NLU)模块今世会话AI统之心也。 凡人伦专家审有代表性者用户输数样本,以见新意,此主观也,贵而易失也。 于此之事,所以助NLU开发人员新,大见新意于给定语料库也。 吾法以监督比学以自关、已标之数,而用无监之K均值聚类以识手头语料库中新意。 吾法于两准集上以达2%13%之巨胜优于先进,以聚类准确性量之。 宜用于旅行域之大集,以验用例之有效性。', 'hi': 'उपयोगकर्ता इरादे की खोज किसी भी आधुनिक संवादात्मक एआई सिस्टम के मूल में एक प्राकृतिक भाषा समझ (एनएलयू) मॉड्यूल विकसित करने में एक महत्वपूर्ण कदम है। आमतौर पर, मानव विशेषज्ञ नए इरादों की खोज करने के लिए उपयोगकर्ता इनपुट डेटा के एक प्रतिनिधि नमूने की समीक्षा करते हैं, जो व्यक्तिपरक, महंगा और त्रुटि-प्रवण है। इस काम में, हम कथनों के एक कॉर्पस को दिए गए पैमाने पर नए इरादों की खोज के लिए एक उपन्यास विधि प्रस्तुत करके एनएलयू डेवलपर्स की सहायता करने का लक्ष्य रखते हैं। हमारी विधि एक डोमेन-प्रासंगिक, पहले से ही लेबल किए गए डेटासेट से जानकारी का लाभ उठाने के लिए पर्यवेक्षित कंट्रास्टिव लर्निंग का उपयोग करती है और असुरक्षित के-मतलब क्लस्टरिंग का उपयोग करके हाथ में कॉर्पस में नए इरादों की पहचान करती है। हमारी विधि दो बेंचमार्क डेटासेट पर 2% और 13% तक के बड़े मार्जिन से अत्याधुनिक को मात देती है, जिसे क्लस्टरिंग सटीकता द्वारा मापा जाता है। इसके अलावा, हम वास्तविक दुनिया के उपयोग के मामले पर अपनी प्रभावशीलता प्रदर्शित करने के लिए यात्रा डोमेन से एक बड़े डेटासेट पर हमारी विधि लागू करते हैं।', 'ru': 'Обнаружение намерений пользователя является ключевым шагом в разработке модуля понимания естественного языка (NLU) в основе любой современной системы разговорного ИИ. Как правило, эксперты-люди рассматривают репрезентативную выборку входных данных пользователей, чтобы обнаружить новые намерения, которые являются субъективными, дорогостоящими и подверженными ошибкам. В этой работе мы стремимся помочь разработчикам НЛУ, представив новый метод обнаружения новых намерений в масштабе, учитывая совокупность высказываний. Наш метод использует контролируемое контрастное обучение для использования информации из домена, уже помеченного набором данных, и идентифицирует новые намерения в имеющемся корпусе с использованием неконтролируемой кластеризации K-средних. Наш метод превосходит современный по большому запасу до 2% и 13% на двух эталонных наборах данных, измеренных по точности кластеризации. Кроме того, мы применяем наш метод на большом наборе данных из области путешествий, чтобы продемонстрировать его эффективность в реальном сценарии использования.', 'ga': 'Is céim ríthábhachtach é fionnachtain rún an úsáideora chun modúl Tuiscint Teanga Nádúrtha (NLU) a fhorbairt i gcroílár aon chórais nua-aimseartha AI Conversational. De ghnáth, déanann saineolaithe daonna athbhreithniú ar shampla ionadaíoch de shonraí ionchuir úsáideoirí chun rúin nua a fháil amach, atá suibiachtúil, costasach agus seans maith go bhfuil earráidí ann. San obair seo, tá sé mar aidhm againn cabhrú le forbróirí an NLU trí mhodh úrnua a chur i láthair le hintinn nua a aimsiú ar scála i bhfianaise corpas cainte. Úsáideann ár modh foghlaim chodarsnachta maoirsithe chun faisnéis a ghiaráil ó thacar sonraí a bhaineann leis an bhfearann, atá lipéadaithe cheana féin agus sainaithnítear cuspóirí nua sa chorpas atá idir lámha ag baint úsáide as cnuasach K-modhanna gan mhaoirseacht. Feidhmíonn ár modh níos fearr ná an úrscothacht le corrlach mór suas le 2% agus 13% ar dhá thacar sonraí tagarmhairc, arna dtomhas ag cruinneas cnuasaithe. Ina theannta sin, cuirimid ár modh i bhfeidhm ar thacar sonraí mór ón bhfearann taistil chun a éifeachtúlacht a léiriú ar chás úsáide sa saol fíor.', 'hu': 'A felhasználói szándék felfedezése kulcsfontosságú lépés egy természetes nyelvi megértés (NLU) modul kifejlesztésében, amely minden modern beszélgetési AI rendszer középpontjában áll. Általában az emberi szakértők áttekintik a felhasználói beviteli adatok reprezentatív mintáját, hogy új szándékokat fedezzenek fel, amelyek szubjektív, költséges és hibákra hajlamosak. Ebben a munkában az NLU fejlesztőinek segítséget kívánunk nyújtani egy új módszer bemutatásával, amelynek segítségével új szándékokat fedezhetünk fel nagyságrendű kifejezésekkel. Módszerünk felügyelt kontrasztív tanulást használ arra, hogy felhasználjuk a domain-releváns, már megjelölt adatkészletből származó információkat, és felügyelet nélküli K-means klaszterezéssel azonosítsuk az aktuális korpuszban található új szándékokat. Módszerünk nagy mértékben, akár 2%-kal, akár 13%-kal felülmúlja a korszerű adatokat a klaszterezési pontossággal mérve. Ezenkívül a módszerünket az utazási domain nagy adathalmazára alkalmazzuk, hogy igazoljuk hatékonyságát egy valós felhasználási esetben.', 'el': 'Η ανακάλυψη προθέσεων χρήστη είναι ένα βασικό βήμα για την ανάπτυξη μιας ενότητας κατανόησης φυσικής γλώσσας στον πυρήνα οποιουδήποτε σύγχρονου συστήματος τεχνητής νοημοσύνης συνομιλίας. Συνήθως, οι ανθρώπινοι εμπειρογνώμονες εξετάζουν ένα αντιπροσωπευτικό δείγμα δεδομένων εισόδου χρηστών για να ανακαλύψουν νέες προθέσεις, οι οποίες είναι υποκειμενικές, δαπανηρές και επιρρεπείς σε σφάλματα. Σε αυτή την εργασία, στοχεύουμε να βοηθήσουμε τους προγραμματιστές παρουσιάζοντας μια νέα μέθοδο για την ανακάλυψη νέων προθέσεων σε κλίμακα με βάση ένα σωρό εκφράσεων. Η μέθοδος μας χρησιμοποιεί εποπτευμένη αντίθετη μάθηση για να αξιοποιήσει πληροφορίες από ένα σχετικό, ήδη επισημασμένο σύνολο δεδομένων και να εντοπίσει νέες προθέσεις στο εν λόγω σώμα χρησιμοποιώντας μη επιτηρημένη συσσώρευση Κ-μέσων. Η μέθοδος μας ξεπερνά τη σύγχρονη τεχνολογία κατά μεγάλο περιθώριο έως 2% και 13% σε δύο σύνολα δεδομένων αναφοράς, που μετρώνται με ακρίβεια ομαδοποίησης. Επιπλέον, εφαρμόζουμε τη μέθοδο μας σε ένα μεγάλο σύνολο δεδομένων από τον τομέα των ταξιδιών για να αποδείξουμε την αποτελεσματικότητά της σε μια πραγματική περίπτωση χρήσης.', 'ka': 'მომხმარებლის მისამართვის აღმოჩენა - საკუთარი კონფიგურაციო სისტემის კონფიგურაციის მოდულის განვითარებაში. ადამიანის ექსპერტები გამოსახულებელი მონაცემების გამოსახულებელი გამოსახულებელი მონაცემების გამოსახულება, რომელიც განსახულებელია ახალი მისახულებები, რომელიც სუბე ამ სამუშაოში ჩვენ მინდა დახმარება NLU განვითარებისთვის პრომენტის მეთოდის გაჩვენება ახალი საზოგადოებების მაგალითვის, როგორც კოპუსის გამოყენება. ჩვენი მეთოდი გამოყენებს მონაცემებული კონტროსტიური სწავლება, რომელიც დიომინის შესახებ შესახებ ინფორმაციის შესახებ, უკვე მონიშნული მონაცემების სეტატიდან და განსახულებს ახალი საზო ჩვენი პროცემი გავაკეთება კლასტერისტის მარტივის შესაძლებლობით 2% და 13% უფრო მეტი. დამატებით, ჩვენ გავაკეთებთ ჩვენი მეთოდი მონაცემების დიდი მონაცემების კონფიგურაციის დემონიდან, რომ გამოყენებთ მისი ეფექტიურობა რეალური მსოფლიო', 'it': "La scoperta delle intenzioni degli utenti è un passo chiave nello sviluppo di un modulo di comprensione del linguaggio naturale (NLU) al centro di qualsiasi moderno sistema di intelligenza artificiale conversazionale. In genere, gli esperti umani esaminano un campione rappresentativo di dati inseriti dagli utenti per scoprire nuovi intenti, che sono soggettivi, costosi e soggetti a errori. In questo lavoro, miriamo ad assistere gli sviluppatori di NLU presentando un nuovo metodo per scoprire nuovi intenti su larga scala dato un corpus di dichiarazioni. Il nostro metodo utilizza l'apprendimento contrastante supervisionato per sfruttare le informazioni provenienti da un set di dati già etichettato rilevante per il dominio e identifica nuovi intenti nel corpus in questione utilizzando clustering non supervisionato di K-means. Il nostro metodo supera lo stato dell'arte di un ampio margine fino al 2% e al 13% su due set di dati benchmark, misurati con precisione di clustering. Inoltre, applichiamo il nostro metodo su un ampio set di dati del dominio viaggi per dimostrare la sua efficacia su un caso d'uso reale.", 'lt': 'Naudotojo ketinimų atradimas yra pagrindinis žingsnis kuriant modulį „Natural Language Understanding“ (NLU), kuris yra bet kurios modernios konversacinės AI sistemos pagrindas. Paprastai žmogaus ekspertai peržiūri reprezentatyvų naudotojų duomenų rinkinį, kad galėtų nustatyti naujus tikslus, kurie yra subjektyvūs, brangūs ir linkę klaidų. In this work, we aim to assist the NLU developers by presenting a novel method for discovering new intents at scale given a corpus of utterances.  Mūsų metodas naudoja kontroliuojamą kontrastinį mokymąsi, kad sutelktume informaciją iš dominijai svarbių, jau pažymėtų duomenų rinkinio ir nustato naujus ketinimus aptariamame korpuse naudojant nepastebimą K priemonių klasifikavimą. Mūsų metodas dviejuose lyginamuosiuose duomenų rinkiniuose, išmatuotuose klasifikuojant tikslumą, viršija pažangiausią lygį iki 2 % ir 13 %. Be to, mes taikome savo metodą dideliam kelionių srities duomenų rinkiniui, kad įrodytume jo veiksmingumą realaus pasaulio naudojimo atveju.', 'mk': 'User intent discovery is a key step in developing a Natural Language Understanding (NLU) module at the core of any modern Conversational AI system.  Типично, човечките експерти прегледуваат претставен примерок на кориснички внесени податоци за откривање на нови намери, кои се субјективни, скапи и спротивни на грешки. Во оваа работа, ние имаме за цел да им помогнеме на развивачите на НЛУ со претставување на нов метод за откривање на нови намери на скала со оглед на корпус на изрази. Нашиот метод го користи надгледуваното контрастивно учење за да се искористи информациите од домен релевантни, веќе означени податоци и идентификува нови намери во корпусот во рацете користејќи ненадгледувано кластерирање на K-средства. Нашиот метод ја надминува најдобрата технологија со голема маргина до 2 и 13 отсто на двата бази на податоци, мерени со групирање на точноста. Покрај тоа, го применуваме нашиот метод на голем компјутер податоци од доменот за патување за да ја демонстрираме нејзината ефикасност во случајот на искористување во реалниот свет.', 'ms': 'Penemuan niat pengguna adalah langkah kunci dalam mengembangkan modul Pemahaman Bahasa Biasa (NLU) di inti mana-mana sistem AI Perbualan Modern. Secara biasa, ahli manusia meninjau sampel mewakili data input pengguna untuk menemukan niat baru, yang subjektif, mahal, dan cenderung-ralat. Dalam kerja ini, kami bertujuan untuk membantu pembangun NLU dengan memperkenalkan kaedah baru untuk menemukan niat baru pada skala diberikan satu korpus ucapan. Our method utilizes supervised contrastive learning to leverage information from a domain-relevant, already labeled dataset and identifies new intents in the corpus at hand using unsupervised K-means clustering.  Kaedah kami melampaui keadaan-state-of-the-art dengan margin besar sehingga 2% dan 13% pada dua set data benchmark, diukur dengan ketepatan clustering. Selain itu, kami menggunakan kaedah kami pada set data besar dari domain perjalanan untuk menunjukkan keefektivitasnya pada kes penggunaan dunia nyata.', 'ml': 'ഉപയോക്താവിന്റെ ലക്ഷ്യം കണ്ടുപിടിക്കുന്നത് സ്വാഭാവിക ഭാഷയുടെ (NLU) ഗ്രഹിക്കുന്നതില്\u200d നിന്നും ആധുനിക സംസാരിക്കുന്ന ഏതെങ സാധാരണ മനുഷ്യരുടെ വിശേഷിപ്പുകാര്\u200d ഉപയോക്താവിന്റെ ഇന്\u200dപുട്ട് വിവരങ്ങളുടെ പ്രതിനിധിയുടെ ഉദാഹരണമായി പരിശോധിക്കുന്നു. അത്  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d NLU വികസിപ്പിക്കുന്നവരെ സഹായിക്കാന്\u200d ഉദ്ദേശിക്കുന്നു. വാക്കുകളുടെ കോര്\u200dപ്പുസ് കൊണ്ട് പുതിയ ഉദ്ദ നമ്മുടെ രീതിയില്\u200d നിരീക്ഷിക്കപ്പെട്ട വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നത് ഒരു ഡൊമെയിന്\u200d ബന്ധപ്പെട്ട വിവരങ്ങളില്\u200d നിന്നും നിരീക്ഷിക്കപ്പെട്ട വിവരങ്ങള്\u200d ഉപ നമ്മുടെ രീതിയില്\u200d രണ്ട് ശതമാനത്തേക്കുള്ള ഒരു വലിയ മാര്\u200dഗിനിലൂടെയും 13% പ്രവര്\u200dത്തിപ്പിക്കുന്നു. രണ്ട് ബെന്\u200dച്മാര്\u200dക്ക് ഡേറ്റ അതിനുശേഷം, ഞങ്ങള്\u200d ഞങ്ങളുടെ രീതിയില്\u200d യാത്ര ഡോമെയില്\u200d നിന്നും വലിയ ഡാറ്റാസെറ്റില്\u200d പ്രയോഗിക്കുന്നു. അതിന്റെ പ്രഭാവ', 'mn': 'Хэрэглэгчийн зорилго олж мэдэх нь байгалийн хэл ойлголтын (NLU) модулийг орчин үеийн ярилцлагын AI системийн төвшинд хөгжүүлэх чухал алхам юм. Хүмүүсийн мэргэжилтнүүд хэрэглэгчийн өгөгдлийн загварын жишээ нь шинэ зорилго олж мэдэхэд хэрэглэгчийн өгөгдлийн загварыг шалгаж үздэг. Энэ ажлын тулд бид НЛУ хөгжүүлэгчдэд шинэ зорилго олж мэдэхийн тулд шинэ арга замыг нээхэд тусалдаг. Бидний арга нь холбоотой мэдээллийг хэрэгжүүлэхэд, аль хэдийн нэрлэгдсэн өгөгдлийн сангуудыг удирдах эсрэг суралцах суралцаг ашигладаг. Мөн холбоотгүй K-means кластеринг ашиглаж байгаа корпус-ын шинэ зорилго тодорхой Бидний арга нь урлагийн хувьд 2% болон 13% хүртэл хоёр давхар өгөгдлийн сангийн хувьд хэмжээтэй байдаг. Мөн бид аялал холбоотой том өгөгдлийн санг бодит ертөнцийн хэрэглээний тухай үр дүнтэй байдлыг харуулахын тулд өөрсдийн арга замыг ашигладаг.', 'no': 'Brukarhending er ein nøkkelsteg i å utvikla ein naturleg språk-forståking (NLU) modul på kjernen av alle moderne samtalesystemet. Vanlegvis er menneskelige ekspertar gjennomsikt eit reprezentativt prøve av brukaradata for å oppdaga nye forstånadar, som er subjektiv, kostnad og feilprone. I denne arbeiden må vi hjelpa NLU-utviklarane ved å oppdaga ein novel metode for å oppdaga nye innstillingar på skala gjeve eit korpus av uttaler. Metoden vårt bruker kontrollerte kontrastlæring for å levera informasjon frå ein domenerelevant, allereie merket datasett og identifiserer nye innstillingar i korpusen ved hånd ved hjelp av ikkje oppretta K- betyr klassering. Metoden vårt utfører kunsttilstanden med ein stor margin opp til 2 % og 13 % på to benchmarkdatasett, målt ved klassering av nøyaktighet. I tillegg kan vi bruke metoden vårt på ein stor dataset frå reisområdet for å demonstrere effektiviteten på ein verkeleg bruk tilfelle.', 'mt': 'L-iskoperta tal-intenzjoni tal-utent hija pass ewlieni fl-iżvilupp ta’ modulu ta’ Ftehim tal-Lingwa Naturali (NLU) fil-qalba ta’ kwalunkwe sistema modern a tal-AI Konversazzjonali. Tipikament, l-esperti umani jirrevedu kampjun rappreżentattiv tad-dejta tal-input tal-utent biex jiskopru intenzjonijiet ġodda, li huma soġġettivi, għaljin u suxxettibbli għall-iżbalji. In this work, we aim to assist the NLU developers by presenting a novel method for discovering new intents at scale given a corpus of utterances.  Il-metodu tagħna juża t-tagħlim kontrastiv sorveljat biex iħeġġeġ l-informazzjoni minn sett ta’ dejta rilevanti għad-dominju, diġà ttikkettat u jidentifika intenzjonijiet ġodda fil-korpus inkwistjoni bl-użu ta’ raggruppament mhux sorveljat tal-mezzi K. Il-metodu tagħna huwa aktar avvanzat minn marġini kbir sa 2% u 13% fuq żewġ settijiet ta’ dejta ta’ referenza, imkejla permezz ta’ raggruppament ta’ preċiżjoni. Barra minn hekk, a ħna napplikaw il-metodu tagħna fuq sett kbir ta’ dejta mid-dominju tal-ivvjaġġar biex nippruvaw l-effettività tiegħu fuq każ ta’ użu fid-dinja reali.', 'pl': 'Odkrywanie intencji użytkownika jest kluczowym krokiem w opracowywaniu modułu zrozumienia języka naturalnego (NLU) w rdzeniu każdego nowoczesnego systemu sztucznej inteligencji konwersacyjnej. Zazwyczaj eksperci ludzie przeglądają reprezentatywną próbkę danych wejściowych użytkowników, aby odkryć nowe intencje, które są subiektywne, kosztowne i podatne na błędy. W niniejszej pracy chcemy pomóc deweloperom NLU przedstawiając nowatorską metodę odkrywania nowych intencji na skalę biorąc pod uwagę korpus wypowiedzi. Nasza metoda wykorzystuje nadzorowane uczenie się kontrastywne, aby wykorzystać informacje z istotnego dla domeny, już oznaczonego zbioru danych i identyfikować nowe intencje w danym korpusie za pomocą nienadzorowanego klastrowania K-środków. Nasza metoda przewyższa state-of-the-art o duży margines do 2% i 13% na dwóch zbiorach danych referencyjnych mierzonych dokładnością klastrowania. Ponadto stosujemy naszą metodę na dużym zbiorze danych z domeny podróży, aby zademonstrować jej skuteczność w realnym przypadku użycia.', 'sr': 'Otkrivanje korisnika namjere je ključni korak u razvoju modula prirodnog razumevanja jezika (NLU) u jezeru svakog modernog razgovornog AI sistema. Obično, ljudski stručnjaci pregledaju reprezentativan uzorak podataka za ulazak korisnika kako bi otkrili nove namjere, koje su subjektivne, skupe i pogrešne. U ovom poslu, mi ciljamo da pomognemo razvojnicima NLU predstavljajući novu metodu za otkrivanje novih namera na skali s obzirom na korpus govora. Naša metoda koristi nadzorno kontrastivno učenje da utiče na informacije iz domena relevantne, već označene podatke i identifikuje nove namjere u korpusu na ruku koristeći nepotrebne skupljanje K-znakova. Naša metoda iznosi stanje umjetnosti sa velikom marginom do 2% i 13% na dva seta podataka o kriteriji, mjerena po skupljanju tačnosti. Osim toga, mi primjenjujemo našu metodu na veliku kompletu podataka iz domena putovanja da pokažemo svoju efikasnost na slučaju korištenja stvarnog svijeta.', 'kk': 'Пайдаланушының мақсаты табу - табиғи тілді түсініктіру (NLU) модулін кез келген қазіргі қатынастық AI жүйесінің негізінде жасау үшін кілт қадам. Әдетте, адамдар эксперттері жаңа мақсаттарды табу үшін пайдаланушылардың келтірілген деректерінің үлгісін тексеру үшін, бұл мақсатты, бағатты және қатені түсіндіру үшін. Бұл жұмыс ішінде НЛУ жасаушыларына көмектесу мақсатымыз, сөздердің корпусы келтірілген жаңа мақсаттарын табу үшін романдық әдісін көрсету арқылы. Біздің әдіміміз доменге қатынасыз етілген деректер жинағынан мәліметті өзгерту үшін бақылайтын контрастырлық оқытуды қолданады және қолданыстағы корпустың жаңа мақсаттарын K- means кластерін қолдану ү Біздің әдіміміз 2% және 13% деңгейіндегі құрылғының күйіне шектеу үлкен шектері, кластерлік дұрыстығымен өлшемін. Қосымша, біз әдімімізді саяқтау доменінің үлкен деректер жиынына қолдану үшін әлемдік пайдалану үшін оның ең әсер етілігін көрсету үшін қолданамыз.', 'ro': 'Descoperirea intenției utilizatorului este un pas cheie în dezvoltarea unui modul Natural Language Understanding (NLU) în centrul oricărui sistem modern conversațional AI. De obicei, experții umani revizuiesc un eșantion reprezentativ de date introduse de utilizatori pentru a descoperi noi intenții, care sunt subiective, costisitoare și predispuse la erori. În această lucrare, ne propunem să ajutăm dezvoltatorii NLU prin prezentarea unei metode noi de descoperire a intențiilor noi la scară, dată fiind un corpus de pronunțări. Metoda noastră utilizează învățarea contrastivă supravegheată pentru a valorifica informațiile dintr-un set de date relevant pentru domeniu, deja etichetat și identifică noi intenții în corpul respectiv folosind clustering nesupravegheat K-means. Metoda noastră depășește cele mai moderne standarde cu o marjă mare de până la 2% și 13% pe două seturi de date de referință, măsurate prin acuratețea clusterizării. Mai mult decât atât, aplicăm metoda noastră pe un set mare de date din domeniul turismului pentru a demonstra eficacitatea acestuia într-un caz de utilizare din lumea reală.', 'si': 'පාවිච්චි අදහසක් හොයාගන්නේ ස්වභාවික භාෂාව තේරුම්ගන්න (NLU) මොඩ්යුල් එකක් හොයාගන්න පුළුවන් පැත්ත සාමාන්\u200dයයෙන්, මිනිස්සු විශ්වාසිකයෝ ප්\u200dරභාවිතයේ ඇතුළු තොරතුරු නිර්මාණයක් පරීක්ෂණය කරන්න, අළුත් අරමුණ මේ වැඩේ අපි අදහස් කරනවා NLU විකාශකයන්ට උදව් කරන්න, අලුත් අදහස් හොයාගන්න අළුත් අදහස් ප්\u200dරවේශයක් තියෙන්නේ කොර්පුස් ව අපේ විධානය පාලනය කරනවා පරීක්ෂා වෙන්න ප්\u200dරතික්\u200dරියාත්මක ඉගෙනීම සඳහා ඩොමේන් එක්ක සම්බන්ධ වෙන්න තොරතුරු ප්\u200dරතික්\u200dරියාත්මක වි අපේ විධානය තත්වය 2% සහ 13% විශාල දත්ත සේට් දෙකට වැඩියි, ස්ථානයක් සිද්ධ විශාල කරන්නේ. තවත්, අපි අපේ විදියට ප්\u200dරයෝජනයක් ඇත්ත ලෝකයේ ප්\u200dරයෝජනයක් විදියට ප්\u200dරයෝජනය කරන්න ලොකු දත්ත සෙට් එක්ක ප්\u200dර', 'so': "Isticmaaluhu waxyaabaha ku saabsan in uu horumariyo qalabka waxgarashada afka asalka ah (NLU) oo ku qoran kooxa nidaamka caalamiga ah ee la hadlo oo dhan. Sida caadiga ah khabiiriyiinta dadku waxay ka fiiriyaan tusaale ahaan macluumaadka internetka si ay u ogaadaan waxyaabaha cusub, kaas oo ah mid la dhiganayo, kharash iyo kharash. Markaas waxan, waxaynu ku talo galaynaa in aan u caawinno horumarinta NLU-ka soo hormariyo qaab saxda ah oo lagu soo ogaado qasabka cusub ee lagu soo qoray hadal. Our method utilizes supervised contrastive learning to leverage information from a domain-relevant, already labeled dataset and identifies new intents in the corpus at hand using unsupervised K-means clustering.  Midabkayagu wuxuu ku soo bandhigaa xaaladda farshaxanta oo aad u weyn ilaa 2% iyo 13% oo ku qoran labada sawirada ee benchmark, oo lagu qiyaasay saxda. Intaas waxaa dheer, qaabkeenna waxaynu ku isticmaalnaa macluumaad badan oo ka yimid gudaha safarka si aan u muujinno faa'iidadeeda xaalada isticmaalka ee caalamka ah.", 'ta': '@ info புதிய உள்ளீட்டு தரவை கண்டுபிடிக்க மனித சிறப்பாளர்கள் ஒரு பிரதிநிதிய மாதிரியை பார்க்கவும், புதிய செயல்பாடு இந்த வேலையில், நாம் NLU உருவாக்குபவர்களுக்கு உதவ வேண்டும் புதிய வார்த்தைகள் கொடுக்கப்பட்ட பேச்சுகளின் குறுக்குறிப்பை கண்டு எங்கள் முறைமையை பயன்படுத்துகிறது ஒரு களம் தொடர்புடையது, ஏற்கனவே குறிப்பிடப்பட்ட தகவல் அமைப்பிலிருந்து தேவைப்படுத்தப்பட்டுள்ளது, மற்றும் குறிப்புகளில எங்கள் முறை 2% மற்றும் 13% க்கு மேல் இரு பெங்க்மார்க் தரவுத்தளங்களில் இருந்து முறையில் செயல்படுத்துகிறது, தெளிவாக்கும் சரிய அதற்கும், நாம் பயணம் களத்திலிருந்து பெரிய தகவல் அமைப்பில் எங்கள் முறையை பயன்படுத்துகிறோம் ஒரு உண்மையான உலக பயன்பாடு விஷயத்', 'sv': 'Upptäckt av användaravsikter är ett viktigt steg i utvecklingen av en Natural Language Understanding (NLU) modul som är kärnan i alla moderna konversations AI-system. Vanligtvis granskar mänskliga experter ett representativt urval av användarindata för att upptäcka nya intentioner, som är subjektiva, kostsamma och felbenägna. I detta arbete syftar vi till att hjälpa NLU-utvecklarna genom att presentera en ny metod för att upptäcka nya intentioner i skala givet en korpus av yttranden. Vår metod använder övervakad kontrastiv inlärning för att utnyttja information från en domänrelevant, redan märkt datauppsättning och identifierar nya intentioner i den aktuella korpusen med hjälp av oövervakad K-means klustring. Vår metod överträffar toppmodern med en stor marginal på upp till 2% och 13% på två referensdatauppsättningar, mätt med klustringsnoggrannhet. Dessutom använder vi vår metod på en stor datamängd från resedomänen för att visa dess effektivitet på ett verkligt användningsfall.', 'ur': 'یوسٹر کا مطلب اچانک ایک کلی سٹم ہے جسے ہر مدرنی مکالمانی AI سیسٹم کے مرکز میں ایک طبیعی زبان سمجھنے کے (NLU) موڈل کو توسعہ دینے میں۔ عام طور پر، انسان کے متخصص ایک نمونہ کے مطابق کارساز اینپیٹ ڈیٹے کی روشن کریں تاکہ نئی مطابق پیدا کریں، جو سرپرست، قیمت اور غلطی کے مطابق ہے. اس کام میں ہم نے NLU ڈلوگروں کی مدد کرنا چاہا ہے کہ ایک نو طریقہ پیش کریں کہ ایک کلمات کی کورپوس کے ذریعے نئی قصد کو اچھی تلاش کریں۔ ہمارا طریقہ ایک ڈومین کے معاملہ سے اطلاعات لازم کرنے کے لئے نظارت کی مخالفت کی تعلیم کے مطابق استعمال کرتا ہے، پہلے سے لکھی ہوئی ڈاٹ سٹ اور حاضر کورپوس میں نئی مطابق پہچان دیتا ہے جو غیر قائم کی مطابق کلاستر کے مطا ہمارا طریقہ آرتی کی حالت کو 2% تک اور 13% تک ایک بڑی مارجینٹ سے نکلتا ہے، دو بنچم مارک ڈیٹ سٹ پر، کلسٹر کی دقیق سے اندازہ کیا گیا ہے۔ اور ہم نے اپنے طریقے کو سفر ڈومین سے ایک بڑے ڈاٹ سٹ پر لازم کیا ہے کہ ایک حقیقی دنیا کے استعمال کیس پر اس کا اثرات دکھائے۔', 'uz': "Name Odatda, oddiy oddiy ekspertlar foydalanuvchi input maʼlumotini aniqlash uchun yangi qanday qanday bogʻ'liq, qiymati va xato roʻy beradi. In this work, we aim to assist the NLU developers by presenting a novel method for discovering new intents at scale given a corpus of utterances.  Bizning usuli domen muhim maʼlumotni koʻpaytirish uchun boshqaruvchi o'rganishdan foydalanadi. Maʼlumotlar tarkibini tayyorlash va qoʻllanmagan K- ma'noda qo'llanmagan yangi qatlamni aniqlaydi. Bizning usuli sanarning holatini 2% va 13% dan ikkita benchmark maʼlumotlar tarkibida bajaradi. Bu tashkilotni tayyorlash mumkin. Ko'pchilik, biz safar domenadan katta maʼlumotlar tarkibini qo'llayapmiz, bu muallif dunyodagi foydalanish davomida ishlatishni ko'rsatish uchun.", 'vi': 'Phát hiện mục đích người dùng là một bước quan trọng trong việc phát triển mô- đun ngôn ngữ tự nhiên (Ntrường) ở trung tâm của hệ thống AI đối thoại hiện đại. Thường thì, chuyên gia nhân loại xem xét một mẫu dữ liệu nhập người dùng đại diện để khám phá ý định mới, mà là chủ quan, tốn kém và dễ bị lỗi. Trong công việc này, chúng tôi dự định giúp đỡ những người phát triển Ntrường hợp này bằng cách đưa ra một phương pháp mới để khám phá những ý định mới trên quy mô dựa vào tập hợp những lời nói. Phương pháp của chúng tôi dùng khả năng học tương đối giám sát để thu thập thông tin từ một tập hợp dữ liệu tương ứng miền, đã được đánh dấu và xác định các mục đích mới trong tập hợp này. Cách của chúng tôi vượt trội khả năng đạt được trạng thái nghệ thuật, với một khoảng cách lớn đến 2+ và 13=. trên hai tập tin tiêu chuẩn, đo được bằng độ chính xác lập. Chúng tôi dùng phương pháp của chúng tôi trên một tập tin lớn từ miền du lịch để chứng minh hiệu quả của nó trong một trường hợp sử dụng thực tế.', 'bg': 'Откриването на намеренията на потребителя е ключова стъпка в разработването на модул за разбиране на естествения език (НЛУ) в основата на всяка модерна система за разговор с изкуствен интелект. Обикновено човешките експерти преглеждат представителна извадка от потребителски входни данни, за да открият нови намерения, които са субективни, скъпи и склонни към грешки. В тази работа ние се стремим да подпомогнем разработчиците на НЛУ чрез представяне на нов метод за откриване на нови намерения в мащаб, даден корпус от изказвания. Нашият метод използва контролирано контрастивно обучение, за да използва информация от съответния домейн, вече обозначен набор от данни и идентифицира нови намерения в настоящия корпус, като използва ненадзорни клъстери. Нашият метод превъзхожда най-съвременните с голям марж до 2% и 13% при два сравнителни набора данни, измерени чрез точност на клъстерите. Освен това прилагаме метода си върху голям набор от данни от областта на пътуването, за да демонстрираме ефективността му при реални случаи на употреба.', 'nl': 'User Intent Discovery is een belangrijke stap in het ontwikkelen van een Natural Language Understanding (NLU)-module die de kern vormt van elk modern Conversational AI-systeem. Meestal beoordelen menselijke experts een representatieve steekproef van gebruikersinvoergegevens om nieuwe intenties te ontdekken, die subjectief, duur en foutgevoelig zijn. In dit werk willen we de NLU ontwikkelaars helpen door een nieuwe methode voor het ontdekken van nieuwe intenties op schaal te presenteren met behulp van een corpus van uitingen. Onze methode maakt gebruik van supervised contrastive learning om informatie uit een domein-relevante, reeds gelabelde dataset te benutten en nieuwe intenties in het betreffende corpus te identificeren met behulp van onbeheerde K-means clustering. Onze methode overtreft de state-of-the-art met een grote marge tot 2% en 13% op twee benchmark datasets, gemeten door clustering nauwkeurigheid. Daarnaast passen we onze methode toe op een grote dataset uit het travel domein om de effectiviteit ervan aan te tonen op een real-world use case.', 'hr': 'Otkrivanje korisnika namjere je ključni korak u razvoju modula prirodnog razumijevanja jezika (NLU) u srži svakog modernog razgovornog sustava AI-a. Obično, ljudski stručnjaci pregledaju reprezentativan uzorak podataka za ulazak korisnika kako bi otkrili nove namjere, koje su subjektivne, skupe i pogrešne. U ovom poslu ciljamo pomoći razvojnicima NLU-a predstavljajući novu metodu za otkrivanje novih namjera na skali s obzirom na korpus govora. Naša metoda koristi nadzorno kontrastivno učenje kako bi iskoristili informacije iz domena relevantne, već označene podatke i identificirali nove namjere u korpusu na ruku koristeći nepotrebne skupljanje K-means. Naša metoda iznosi stanje umjetnosti velikom marginom do 2% i 13% na dvije baze podataka o referenciji, mjerene po skupljanju to čnosti. Osim toga, mi primjenjujemo našu metodu na veliku kompletu podataka iz domena putovanja kako bi pokazali svoju učinkovitost na slučaju korištenja stvarnog svijeta.', 'da': 'Opdagelse af brugerhensigter er et vigtigt skridt i udviklingen af et NLU-modul (Natural Language Understanding), som er kernen i ethvert moderne Conversational AI-system. Typisk gennemgår menneskelige eksperter et repræsentativt udsnit af brugerinput data for at opdage nye hensigter, som er subjektive, dyre og fejltilbøjelige. I dette arbejde har vi til formål at hjælpe NLU-udviklerne ved at præsentere en ny metode til at opdage nye intentioner i skala givet et korpus af udtalelser. Vores metode bruger overvåget kontrastiv læring til at udnytte oplysninger fra et domænerelateret, allerede mærket datasæt og identificerer nye hensigter i det aktuelle korpus ved hjælp af ukontrolleret K-means clustering. Vores metode overgår den nyeste teknologi med en stor margin på op til 2% og 13% på to benchmark datasæt målt ved klyngernes nøjagtighed. Desuden anvender vi vores metode på et stort datasæt fra rejsedomænet for at demonstrere dens effektivitet på en virkelig brugssag.', 'ko': '사용자의 의도 발견은 자연언어 이해(NLU) 모듈을 개발하는 관건적인 절차이고 자연언어 이해 모듈은 어떠한 현대 대화 인공지능 시스템의 핵심이다.통상적으로 인류 전문가들은 사용자가 입력한 데이터의 대표적인 견본을 살펴보고 새로운 의도를 발견하는데 이것은 주관적이고 대가가 높으며 잘못되기 쉽다.이 작업에서 우리의 목표는 NLU 개발자가 주어진 언어 자료 라이브러리에서 대규모의 새로운 의도를 발견하도록 돕는 새로운 방법을 제시하는 것이다.우리의 방법은 감독이 있는 대비 학습을 이용하여 분야와 관련된 이미 표시된 데이터 집합의 정보를 활용하고 감독이 없는 K-균일치 집합을 이용하여 수중 어료 라이브러리의 새로운 의도를 식별한다.집계 정확도 측정을 통해 우리의 방법은 두 기준 데이터 집합에서 최신 기술보다 훨씬 우수한데 각각 2%와 13퍼센트에 달한다.그 밖에 우리는 우리의 방법을 관광 분야의 대형 데이터 집합에 응용하여 현실 세계의 용례에서 그 유효성을 증명할 것이다.', 'de': 'User Intent Discovery ist ein wichtiger Schritt bei der Entwicklung eines Natural Language Understanding (NLU)-Moduls im Kern eines modernen Conversational AI-Systems. Normalerweise überprüfen menschliche Experten eine repräsentative Stichprobe von Benutzereingabedaten, um neue Absichten zu entdecken, die subjektiv, kostspielig und fehleranfällig sind. In dieser Arbeit wollen wir die NLU-Entwickler unterstützen, indem wir eine neuartige Methode vorstellen, um neue Intentionen im Maßstab anhand eines Korpus von Äußerungen zu entdecken. Unsere Methode nutzt überwachtes kontrastives Lernen, um Informationen aus einem domänenrelevanten, bereits markierten Datensatz zu nutzen und neue Intentionen im vorliegenden Korpus mittels unbeaufsichtigtem K-Means Clustering zu identifizieren. Unsere Methode übertrifft den Stand der Technik um eine große Marge bis zu 2% und 13% auf zwei Benchmark-Datensätzen, gemessen durch Clustering-Genauigkeit. Darüber hinaus wenden wir unsere Methode auf einem großen Datensatz aus der Travel Domain an, um deren Wirksamkeit auf einem realen Anwendungsfall zu demonstrieren.', 'id': 'Penemuan niat pengguna adalah langkah kunci dalam mengembangkan modul Pemahaman Bahasa Alami (NLU) di inti setiap sistem AI konversasi modern. Secara biasa, ahli manusia meninjau sampel reprezentatif dari data input pengguna untuk menemukan tujuan baru, yang subjektif, mahal, dan cenderung kesalahan. In this work, we aim to assist the NLU developers by presenting a novel method for discovering new intents at scale given a corpus of utterances.  Metode kami menggunakan pembelajaran kontras yang diawasi untuk menggunakan informasi dari set data yang relevan domain, yang sudah ditabel dan mengidentifikasi niat baru dalam tubuh di tangan menggunakan clustering K-means yang tidak diawasi. Metode kita melebihi state-of-the-art dengan margin besar hingga 2% dan 13% pada dua set data benchmark, diukur dengan akurasi clustering. Furthermore, we apply our method on a large dataset from the travel domain to demonstrate its effectiveness on a real-world use case.', 'fa': 'کشف هدف کاربر یک قدم کلید در توسعه یک مدول درک زبان طبیعی (NLU) در مرکز هر سیستم مکالمه\u200cی AI مدرن است. معمولاً متخصص\u200cکننده\u200cهای انسان یک نمونه نمونه\u200cای از داده\u200cهای ورودی کاربر را برای کشف هدف\u200cهای جدید تحقیق می\u200cکنند، که موجود، ارزشمند و خطایی است. در این کار، ما هدف داریم به توسعه\u200cکنندگان NLU کمک کنیم با پیشنهاد روش نویسی برای کشف هدف\u200cهای جدید در مقیاس با یک جسد سخنرانی داده شود. روش ما از یادگیری متفاوتی که از یک دامنه مربوط به اطلاعات تحت نظر قرار گرفته است استفاده می\u200cکند و از طریق کلاسترینگ K-یعنی غیرقابل تحت نظر قرار گرفته است هدف\u200cهای جدید در کورپوس مشخص می\u200cکند. روش ما با یک مرز بزرگ تا ۲ درصد و ۱۳ درصد در دو مجموعه اطلاعات صندوق، به اندازه\u200cگیری با دقیق تنظیم می\u200cشود. علاوه بر این، ما روش خود را روی یک مجموعه داده بزرگ از دامنه سفر برای نشان دادن موثرتش در مورد پرونده استفاده از دنیای واقعی استفاده کنیم.', 'sw': 'Lengo la mtumiaji kutambua ni hatua muhimu katika kuandaa kituo cha kuelewa lugha ya asili (NLU) katika mfumo wa UKI wa kisasa. Kwa kawaida, wataalam wa binadamu wanapitia mfano wa mwakilishi wa taarifa za watumiaji ili kutambua malengo mapya, ambayo ni muhimu, gharama na yenye makosa. Katika kazi hii, tunalenga kusaidia waendelezaji wa NLU kwa kutoa mbinu ya riwaya ya kutambua nia mpya kwa kiwango kinachotolewa na makampuni ya hotuba. Utawala wetu unatumia utaratibu wa kujifunza tofauti za kutoa taarifa kutoka kwenye seti ya taarifa zinazohusiana na ndani, tayari zinaonyesha nia mpya katika makampuni hayo kwa kutumia viungo vya K-maana yasiyoeleweka. Utawala wetu unaonyesha hali ya sanaa kwa kiwango kikubwa cha kufikia asilimia 2 na asilimia 13 kwenye seti mbili za bendera, zilizopima kwa usahihi. Zaidi ya hayo, tunatumia njia yetu kwenye seti kubwa ya taarifa kutoka kwenye eneo la safari ili kuonyesha ufanisi wake kwenye kesi ya matumizi ya dunia halisi.', 'tr': 'Ullan챌y maksady ke힊fedilmek, Tebi첵al Dili d체힊체nmek (NLU) modulyny her modern Conversational AI sistemini흫 esbapynda 첵eti힊dirmek 체챌in wajyp ad캇md캇r. Adamlar uzmanlary t채ze ni첵etleri tapmak 체챌in ullan챌ylary흫 girdi maglumatyny흫 t채ze ni첵etlerini tapmak 체챌in bir nusgasyny barla첵arlar. Bu i힊de NLU 철wrenmelerine k철mek etmek ama챌ladyk. T채ze ni첵etleri bir k철p체s beril첵채n 챌yky힊lary a 챌mak 체챌in t채ze maksady a챌mak 체챌in bir t채ze y철ntem g철rkezmek 체챌in. Bizi흫 y철ntemimiz, 체st체nde g철zlenen kontrast 철wrenmegi domeny흫 m철h체m bolan, e첵첵채m etilen veri setirmelerinden ge챌irmek 체챌in g철zlenen kontrast 철wrenmegi ullan첵ar we 철nde kod첵usda t채ze maksadlary tany첵ar. Bizi흫 첵agda첵ymyz 2% we 13% b체y체k gabdaly iki benchmark veri setirlerinde 철l챌체p 첵철re첵채r. Daha da, biz yolculuklardan b체y체k bir dataset 체zerinde y철n체mizi ger챌ek d체n첵채 i힊le첵채n durumda etkinli휓ini kan캇tlamak 체챌in uyguladyk.', 'af': "Gebruiker doel ontdekking is 'n sleutel stap in die ontwikkeling van 'n Natuurlike Taal Verstaan (NLU) module by die kern van enige moderne Gespraakte AI stelsel. Tipe, menslike eksperte hersien 'n voorskynlike voorbeeld van gebruiker invoer data om nuwe doels te ontdek, wat is subjektief, koste en fout- prone. In hierdie werk is ons doel om die NLU ontwikkelaars te help deur 'n nuwe metode te voorsien om nuwe doels op skaal te ontdek wat 'n korpus van uitspraak gegee het. Ons metode gebruik die ondersoekte kontrastiewe leer om inligting van 'n domein- relevante, reeds etiketeerde datastel te verwys en identifiseer nuwe doels in die korpus by die hand te gebruik met onondersoekte K- betekens clustering. Ons metode uitvoer die state-of-the-art deur 'n groot marjin tot 2% en 13% op twee benchmarkdatastelle, gemeet deur klastering presies. Ons het ook ons metode aanwend op 'n groot datastel van die reis domein om sy effektiviteit te wys op 'n reël wêreld gebruik geval.", 'sq': 'Zbulimi i qëllimeve të përdoruesit është një hap kyç në zhvillimin e një moduli të kuptimit të gjuhës natyrore (NLU) në qendër të çdo sistemi modern AI konversational. Zakonisht, ekspertët njerëzorë shqyrtojnë një shembull përfaqësues të të dhënave të hyrjes së përdoruesve për të zbuluar qëllime të reja, që janë subjektive, të shtrenjta dhe të rrezikshme për gabime. Në këtë punë, ne synojmë të ndihmojmë zhvilluesit e NLU duke paraqitur një metodë të re për zbulimin e qëllimeve të reja në shkallë të dhënë një korpus shprehjesh. Metoda jonë përdorë mësimin kontrastiv të mbikqyrur për të përdorur informacionin nga një grup i të dhënave të rëndësishme për domenin, të etiketuar tashmë dhe identifikon qëllime të reja në korpus në dorë duke përdorur grupimin e K-means të pa mbikqyrur. Metoda jonë e tejkalon gjendjen më të avancuar me një marxh të madh deri në 2% dhe 13% në dy grupe të dhënash referenciale, të matura nga grupimi i saktësisë. Përveç kësaj, ne aplikojmë metodën tonë në një set të madh të dhënash nga domenia e udhëtimit për të demonstruar efektshmërinë e saj në një rast përdorimi në botën reale.', 'am': 'User intent discovery is a key step in developing a Natural Language Understanding (NLU) module at the core of any modern Conversational AI system.  በተለመደው፣ የሰው ባለምህርት አዋቂዎች አዲስ ዓይነት፣ ዋጋው እና የስህተት ስህተት የሚያስፈልገውን አዲስ ዓይነት ለማግኘት የጥያቄ የድምፅ ምሳሌ ይመልሳሉ፡፡ በዚህ ሥራ የNLU አካባቢዎች የንግግር አካባቢ የተሰጠውን አዲስ አሳብ ለማግኘት አዲስ ልማድ እናስረዳለን፡፡ የድምፅ አካባቢ መረጃዎችን ከዶሜን-አካባቢ እና አዲስ ጉዳይ በኮንፓስ ውስጥ በተጠበቀው የK-ማዕከል ጉዳይ በመጠቀም አዲስ ጉዳይ ይታያል፡፡ የ-የ-የ-ዐርድ ግንኙነታችን 2 በመቶ እና 13 በመቶ በሁለት የbenchmark ዳርቻዎች ላይ ያሳርፋል፡፡ በተጨማሪም፣ መንገዳችንን በመንገድ ዳታዎች ላይ እናስጠጋለን፡፡', 'hy': 'Օգտագործողի մտադրության հայտնաբերումը գլխավոր քայլ է բնական լեզվի հասկանալու (ՆԼU) մոդուլների զարգացման մեջ ցանկացած ժամանակակից հաղորդակցման ԱԲ համակարգի հիմքում: Սովորաբար մարդու մասնագետները վերլուծում են օգտագործողի մուտքագրման տվյալների ներկայացուցիչ նմուշը նոր նպատակներ հայտնաբերելու համար, որոնք սուբյեկտիվ են, թանկ և սխալների հակված են: Այս աշխատանքի ընթացքում մենք նպատակում ենք օգնել ՆԼԵՄ-ի զարգացողներին ներկայացնելով նոր մեթոդ նոր նպատակների հայտնաբերելու համար աստիճաններով: Մեր մեթոդը օգտագործում է վերահսկված հակադրական ուսումնասիրությունը, որպեսզի օգտագործենք տեղեկատվությունը, որը արդեն նշանակում է բնագավառի, արդեն պիտակուցված տվյալների համակարգում, և հայտնաբերում է նոր նպատակներ ձեռքի մարմնում, օգտագործելով անվերահսկ Մեր մեթոդը գերազանցում է ամենակարևորը մինչև 2 և 13 տոկոսով երկու համեմատական տվյալների համակարգերի վրա, չափված ճշգրտության խմբագրման միջոցով: Furthermore, we apply our method on a large dataset from the travel domain to demonstrate its effectiveness on a real-world use case.', 'bn': 'User intent discovery is a key step in developing a Natural Language Understanding (NLU) module at the core of any modern Conversational AI system.  সাধারণত মানুষ বিশেষজ্ঞরা নতুন উদ্দেশ্য আবিষ্কারের জন্য ব্যবহারকারীর ইনপুট তথ্যের প্রতিনিধির নমুনা পর্যবেক্ষণ করেছেন, যা  এই কাজে আমরা এনএলইউ ডেভেলপারদের সাহায্য করার উদ্দেশ্য হচ্ছি ভাষণের কোর্পাসের কারণে নতুন উদ্দেশ্য আবিষ্কারের মাধ্যমে একটি নবনের মাধ্ আমাদের পদ্ধতি একটি ডোমেইন-সম্পর্কিত তথ্য প্রদান করার জন্য বিরোধীতা শিক্ষা ব্যবহার করে, ইতোমধ্যে লেবেল করা হয়েছে ডাটাসেট এবং কোর্পাসে নতুন উদ্দেশ্য চিহ্নি আমাদের পদ্ধতি দুই বেনম্যার্ক ডাটাসেটের মাধ্যমে বিশাল মার্জিনের দ্বারা দুই শতাংশ এবং ১৩% বেঞ্চার্ক ডাটাসেটের মাধ্যমে প এছাড়াও, আমরা ভ্রমণের ডোমেইন থেকে বিশাল ডাটাসেটের মাধ্যমে আমাদের পদ্ধতি প্রয়োগ করি একটি বাস্তব ব্যবহারের কেসের উপর তার কার', 'ca': "El descobriment de l'intenció de l'usuari és un pas clau en el desenvolupament d'un módul d'Entensió de Llingua Natural (NLU) al nucli de qualsevol sistema d'AI conversacional modern. Normalment, els experts humans revisen una mostra representativa de dades d'entrada d'usuaris per descobrir noves intencions, subjectives, costoses i propensos a errors. En aquest treball, busquem ajudar els desenvolupadors de la NLU presentant un mètode nou per descobrir noves intencions a escala dada un corpus d'expressions. El nostre mètode utilitza l'aprenentatge contrastiu supervisat per aprofitar la informació d'un conjunt de dades relevants per domini, ja etiquetat, i identifica noves intencions al cos a mà fent servir una agrupació de mitjans K sense supervisió. El nostre mètode supera l'actualitat d'un gran marge fins al 2% i al 13% en dos conjunts de dades de referència, mesurats agrupant la precisió. A més, aplicam el nostre mètode en un gran conjunt de dades del domini de viatge per demostrar la seva eficacia en un cas d'ús del món real.", 'bs': 'Otkrivanje korisnika namjere je ključni korak u razvoju modula prirodnog razumijevanja jezika (NLU) u jezeru svakog modernog razgovornog AI sistema. Obično, ljudski stručnjaci pregledaju reprezentantni uzorak podataka za ulazak korisnika kako bi otkrili nove namjere, koje su subjektivne, skupe i pogrešne. U ovom poslu, mi ciljamo da pomognemo razvojnicima NLU-a predstavljajući novu metodu za otkrivanje novih namjera na skali s obzirom na korpus govora. Naša metoda koristi nadzorno kontrastivno učenje kako bi iskoristili informacije iz domena relevantne, već označene podatke i identificirali nove namjere u korpusu na ruku koristeći nepotrebne skupljanje K-medija. Naša metoda iznosi stanje umjetnosti velikom marginom do 2% i 13% na dvije baze podataka o referenciji, mjerene po skupljanju tačnosti. Osim toga, mi primjenjujemo našu metodu na veliku kompletu podataka iz domena putovanja kako bi pokazali svoju učinkovitost na slučaju korištenja stvarnog svijeta.', 'cs': 'Zjištění záměru uživatele je klíčovým krokem při vývoji modulu porozumění přirozenému jazyku (NLU) v jádru každého moderního konverzačního AI systému. Lidští odborníci obvykle zkontrolují reprezentativní vzorek vstupních dat uživatelů, aby objevili nové záměry, které jsou subjektivní, nákladné a náchylné k chybám. Cílem této práce je pomoci vývojářům NLU představením nové metody pro objevování nových záměrů v měřítku vzhledem k korpusu projevů. Naše metoda využívá kontrastní učení, které využívá k využití informací z doménově relevantní, již označené datové sady a identifikuje nové záměry v daném korpusu pomocí bez dozoru K-means clustering. Naše metoda výrazně překonává nejmodernější stav techniky až do 2% a 13% na dvou referenčních datových sadách měřených přesností clusteru. Dále aplikujeme naši metodu na velký datový soubor z cestovní domény, abychom demonstrovali její efektivitu na reálném případě použití.', 'az': 'İstifadəçi niyyəti keşif hər modern Konuşatlı AI sisteminin dibində təbiətli dil anlama modulu təşkil etmək üçün anahtar adımdır. İnsan ekspertləri yeni niyyətləri keşf etmək üçün istifadəçilərin giriş verilənlərin nümunəsini təhsil edirlər, bu da subjektiv, mal və xəta-prone idir. Bu işdə NLU mükəmməçilərinə kömək etmək istəyirik, sözlərin korpusu ilə yeni niyyətləri keşfetmək üçün yeni bir metod göstərmək üçün. Bizim metodumuz domenalı məlumatlardan məlumatları istifadə etmək üçün gözləyirli müxtəlif öyrənmək üçün istifadə edir, əvvəlcə etiket edilmiş veri qutusu və əlində olan korpusda yeni niyyətləri tanıyır ki-məlumatların klasterindən istifadə edilməz. Bizim metodumuz 2%-ə və 13%-ə qədər böyük bir margin ilə, iki benchmark veri qutusu ilə ölçülür. Daha sonra, biz yolculuğumuzu gerçek dünyanın istifadə etmə məsələsində çox böyük bir veri qutusuna istifadə edirik.', 'fi': 'Käyttäjän aikomusten löytäminen on keskeinen askel kehitettäessä Natural Language Understanding (NLU) -moduulia jokaisen nykyaikaisen Conversational AI -järjestelmän ytimessä. Tyypillisesti ihmisasiantuntijat tarkistavat edustavan otoksen käyttäjän syöttötiedoista löytääkseen uusia tarkoituksia, jotka ovat subjektiivisia, kalliita ja virhealttiita. Tässä työssä pyrimme auttamaan NLU:n kehittäjiä esittelemällä uudenlaisen menetelmän uusien aikomusten löytämiseen mittakaavassa lausekorpusen avulla. Menetelmämme hyödyntää valvottua kontrastioppimista hyödyntäen tietoa toimialueen relevantista, jo merkitystä aineistosta ja tunnistaa uusia tarkoituksia käsillä olevassa korpusessa valvomattomalla K-means-klusteroinnilla. Menetelmämme suoriutuu viimeisintä tekniikkaa suuremmalla marginaalilla, jopa 2% ja 13% kahdella vertailuaineistolla klusteroinnin tarkkuudella mitattuna. Lisäksi käytämme menetelmäämme suuressa matkustusalueen aineistossa osoittaaksemme sen tehokkuuden todellisessa käyttötapauksessa.', 'et': 'Kasutaja kavatsuste avastamine on oluline samm loodusliku keele mõistmise mooduli väljatöötamisel, mis on mis tahes kaasaegse vestlusliku AI süsteemi keskmes. Tavaliselt vaatavad inimeksperdid läbi kasutaja sisendandmete representatiivse valimi, et avastada uusi kavatsusi, mis on subjektiivsed, kulukad ja veakalduvad. Käesolevas töös on meie eesmärk aidata NLU arendajaid, esitades uudse meetodi uute kavatsuste avastamiseks mastaabis väljenduskorpuse alusel. Meie meetod kasutab juhendatud kontrastiivset õpet, et kasutada teavet domeeni asjakohasest, juba märgistatud andmekogumist ning tuvastada käesolevas korpuses uued kavatsused, kasutades järelevalveta K-means klastrit. Meie meetod ületab tehnika taseme suure marginaaliga kuni 2% ja 13% kahe võrdlusandmekogumi puhul, mida mõõdetakse klastrite täpsusega. Lisaks rakendame oma meetodit reisi domeeni suurtele andmekogumitele, et demonstreerida selle efektiivsust reaalses maailmas kasutusjuhtumis.', 'sk': 'Odkrivanje namena uporabnikov je ključni korak pri razvoju modula za razumevanje naravnega jezika (NLU) v jedru katerega koli sodobnega sistema pogovorne umetne inteligence. Običajno človeški strokovnjaki pregledajo reprezentativni vzorec vnosnih podatkov uporabnikov, da odkrijejo nove namene, ki so subjektivni, dragi in nagnjeni k napakam. V tem delu želimo pomagati razvijalcem NLU s predstavitvijo nove metode odkrivanja novih namenov v obsegu glede na korpus izgovorov. Naša metoda uporablja nadzorovano kontrastno učenje za izkoriščanje informacij iz domensko pomembnega, že označenega nabora podatkov in identificira nove namene v obravnavanem korpusu z uporabo nenadzorovanega grozdja K-means. Naša metoda presega najsodobnejše rezultate z veliko maržo do 2% in 13% na dveh referenčnih naborih podatkov, merjenih z natančnostjo grozdov. Poleg tega našo metodo uporabljamo na velikem naboru podatkov iz potovalne domene, da dokažemo njeno učinkovitost v realnem primeru uporabe.', 'ha': "Aiki na amfani da mai amfani da shi yana da wata matsayi cikin buɗe wani module na Fasahan Lugha na Natural (NLU) a ƙarƙashin wani na'ura na masu haɗi da AI na yanzu. A bayani, masu sani na mutum suna rubutu wani misali na misali da mazaɓa na amfani da cikin shirin ayuka dõmin ya gane na zane-zane, wanda yana da ƙanƙantar da, masu kyauta, da kuma don ya sami ɓata. Daga wannan aikin, Munã nufin mu taimake NLU masu developer da su gaura wata hanyoyi na yanzu dõmin ka gane wata kashfa na yanzu a tsakanin da aka ba da wata kalma na magana. MethoyinMu na amfani da tsarin da aka tsare mutane da ake amfani da shi zuwa tsarin bayani da aka samu da shi, wanda aka yi amfani da shi na tsarin danahan da aka yi amfani da shi, kuma yana gane na yanzu cikin makampyutan da aka tsare shi, kuma don ka yi amfani da clundin na K-ma'anar da ba'a tsare shi ba. Tayiyinmu na samar da halin-art mai girma zuwa 2% da 13% a kan data-bankers biyu, aka ƙaddara shi da ya ƙari tsari. Furan haka, za mu yi amfani da hanyoyinmu kan tsarin bayani masu girma daga gudan safari dõmin mu nuna masu amfani da halinsa a cikin duniya.", 'he': 'גילוי הכוונה של המשתמש הוא צעד מפתח בפיתוח מודול להבין שפת טבעית (NLU) בלב כל מערכת AI משוחרת מודרנית. בדרך כלל, מומחים אנושיים מבקרים דגימה מייצגית של נתוני הכניסה של משתמשים כדי לגלות כוונות חדשות, שהיא סוביקטיבית, יקרה, ונוטלת לשגיאות. בעבודה הזו, אנחנו מתכוונים לסייע לפיתוחים של NLU על ידי הצגת שיטה חדשה לגלות כוונות חדשות בקנה מידה השיטה שלנו משתמשת ללמוד נוגד מבוקש כדי להשיג מידע ממערכת נתונים רלוונטית לתחום, שכבר מסומנת ומזוהה כוונות חדשות בקורפוס בידיים באמצעות קבוצת K-means לא מבוקשת. השיטה שלנו מעליפה את המצב המיוחד על ידי שווה גדולה עד 2% ו-13% על שני קבוצות נתונים של רמז, המדודה על ידי מדויקת קבוצה. חוץ מזה, אנחנו משתמשים בשיטה שלנו על קבוצת נתונים גדולה מתחום הנסיעה כדי להוכיח את היעילות שלה על מקרה שימוש בעולם אמיתי.', 'jv': 'Ngawe Perintah Panjenengan pengguna nggawe barang kelas kuwi nggawe modul Terasar Ingkang Sampeyan (NLU) nang sampek sistem AI sing nambah. Tipik, Human Skill Nang lan iki, awak dhéwé iso nglanggar bantuan NLU pengguna-pengguna neng gewis ngulinakake tarjamahan kanggo kebebasan bingi kebutaan kanggo nguasakno perusahaan anyar. We method used super Vised contrastative Learning to raise information from a domain-responsible, before label dataset and detects new ntents in the corus at hand use unupperused K-means clustering. method We use this method on a big dataset from the time domain to show the effect on a true-world use Case.', 'bo': 'སྤྱོད་མཁན་གྱི་དམིགས་ཡུལ་དེ་རྙོགས་ཚུལ་ནི་རང་བཞིན་པའི་སྐད་རིགས་རྟོགས་ཀྱི་རྩིས་མཐུན་ཤིག་ཅིག་རེད། སྤྱིར་བཏང་བ། མི་ནོར་ཆེན་གྱིས་ལག་ལེན་པའི་ནང་འཇུག་བྱས་ཆ་གསརཔ་ཞིག་ལ་བལྟ་བུ་འཇུག་བྱེད་པའི་དཔེ་བརྗོད་རྐྱེན་བྱས་ཆོས། འོན་ཀྱང་། ང་ཚོས་རྩོམ་པ་འདིའི་ནང་དུ་NLU་དར་སྤེལ་པོ་ཚོར་བརྗོད་ཀྱི་ཐབས་ལམ་གསར་བ་ཞིག་སྟོན་རྒྱུ་དང་། Our method utilizes supervised contrastive learning to leverage information from a domain-relevant, already labeled dataset and identifies new intents in the corpus at hand using unsupervised K-means clustering. ང་ཚོའི་ལམ་ལུགས་འདིས་གནས་སྟངས་གཟུགས་རིས་ཀྱི་གནས་སྟངས་འདི་ཚད་གཞིར་གྱི་ཚད་གཞིར་སྟངས་གཉིས་ལས་བརྩམས་གཏོང་ཚད་གཞིར་བཟོ་བ་ཡིན། ད་དུང་། ང་ཚོས་ཀྱི་ཐབས་ལམ་ཞིག་གཡིས་ཆེན་པོ་ཞིག་གིས་འགྲུལ་སྐྱོང་ཆེན་གྱིས་དོན་འཛམ་གླིང་གི་ལག་ལེན་བྱེད་'}
{'en': 'CS-BERT : a pretrained model for customer service dialogues', 'ar': 'CS-BERT: نموذج تم اختباره مسبقًا لحوارات خدمة العملاء', 'pt': 'CS-BERT: um modelo pré-treinado para diálogos de atendimento ao cliente', 'es': 'CS-BERT: un modelo preentrenado para los diálogos de atención al cliente', 'fr': 'CS-BERT\xa0: un modèle préformé pour les dialogues avec le service client', 'zh': 'CS-BERT:客户服务言训模', 'ja': 'CS - BERT ：カスタマーサービスダイアログの事前トレーニングモデル', 'hi': 'CS-BERT: ग्राहक सेवा संवादों के लिए एक pretrained मॉडल', 'ru': 'CS-BERT: предварительно обученная модель для диалогов по обслуживанию клиентов', 'ga': 'CS-BERT: samhail réamhoilte le haghaidh idirphlé seirbhíse custaiméara', 'el': 'CS-BERT: ένα προσχεδιασμένο μοντέλο για τους διαλόγους εξυπηρέτησης πελατών', 'ka': 'CS- BERT: კლიენტის სერვისი დიალოგებისთვის მოდელი', 'hu': 'CS-BERT: az ügyfélszolgálati párbeszédek előkészített modell', 'it': 'CS-BERT: un modello pre-addestrato per i dialoghi con il servizio clienti', 'mk': 'CS- BERT: предобучен модел за дијалози за служба на клиентите', 'kk': 'CS- BERT: клиенттер қызметі диалогтарының алдындағы моделі', 'lt': 'CS-BERT: iš anksto parengtas klientų paslaugų dialogų modelis', 'ms': 'CS-BERT: a pretrained model for customer service dialogues', 'ml': 'CS- BERT: കസ്റ്റര്\u200d സേവനത്തിനുള്ള ഡയലോഗുകള്\u200dക്കുള്ള ഒരു മോഡല്\u200d', 'mn': 'CS-BERT: хэрэглэгчийн үйл ажиллагааны диалогуудын хувьд', 'pl': 'CS-BERT: wstępnie przeszkolony model dialogu obsługi klienta', 'ro': 'CS-BERT: un model pregătit pentru dialogurile cu clienții', 'no': 'CS- BERT: ein modell for klientteneste', 'sr': 'CS-BERT: model za klijentske usluge', 'si': 'CS- BERT: ග්\u200dරාහකයාරු සේවා සංවාදය සඳහා ප්\u200dරීට්\u200dරීන් මොඩේලයක්', 'so': 'CS-BERT: Tusaale hore oo u eg dialogueyada adeegga macaamiisha', 'sv': 'CS-BERT: en förkränad modell för kundtjänstdialoger', 'ta': 'CS- BERT: தனிப்பயன் சேவை உரையாடல்களுக்கான முன்னோக்கப்பட்ட மாதிரி', 'ur': 'CS-BERT: مشتری سرویس диалогوں کے لئے ایک پرٹرینڈ موڈل', 'mt': 'CS-BERT: mudell imħarreġ minn qabel għad-djalogi dwar is-servizzi tal-klijenti', 'uz': 'CS- BERT: customer xizmati dialoglari uchun koʻrilgan model', 'vi': 'CS-BERT: một mô hình đẹp cho tư vấn dịch vụ khách hàng', 'bg': 'CS-BERT: предварително обучен модел за диалози за обслужване на клиенти', 'hr': 'CS-BERT: pretkišni model za dijalogove klijentske usluge', 'nl': 'CS-BERT: een vooraf getraind model voor klantenservicedialogen', 'de': 'CS-BERT: ein vortrainiertes Modell für Kundendienstdialoge', 'id': 'CS-BERT: model yang dilatih sebelumnya untuk dialog layanan pelanggan', 'ko': 'CS-BERT: 사전 훈련된 고객 서비스 대화 모델', 'da': 'CS-BERT: en forudtrænet model for kundeservicedialoger', 'tr': 'CS-BERT: müşteri häsiýet dialoglary üçin önünde gözlenen nusga', 'sw': 'CS-BERT: mfano wa mazungumzo ya wateja', 'fa': 'CS-BERT: یک مدل پیش\u200cفرض برای گفتگوهای خدمات مشتری', 'sq': 'CS-BERT: një model i stërvitur para dialogut të shërbimit të klientëve', 'am': 'CS-BERT:', 'af': 'CS- BERT: √Ę¬Ä¬ôn pretre√ęerde model vir kli√ęnt diens dialoog', 'hy': 'CS-BELT: A նախապատրաստված մոդել հաճախորդների ծառայությունների հաղորդագրությունների համար', 'az': 'CS-BERT: müşterilər servisi dialogları üçün təklif edilmiş modeli', 'bn': 'CS-BERT: ক্যাস্টার সার্ভিস ডায়ালগের জন্য একটি প্রেমেন্ট মডেল', 'bs': 'CS-BERT: pretkišni model za dijalogove klijentske usluge', 'ca': 'CS-BERT: un model pre-entrenat per a diàlegs de servei al client', 'cs': 'CS-BERT: předtrénovaný model dialogů se zákaznickým servisem', 'et': 'CS-BERT: eeltreenitud mudel klienditeeninduse dialoogide jaoks', 'fi': 'CS-BERT: esikoulutettu malli asiakaspalvelukeskusteluihin', 'jv': 'CS-BERT: model sing paling dadi kanggo kelengatan dialog kebebasan', 'sk': 'CS-BERT: vnaprej usposobljen model dialogov o storitvah za stranke', 'ha': 'KCharselect unicode block name', 'he': 'CS- BERT: מודל מאומן מראש לדיולוגי שירות לקוחות', 'bo': 'CS-BERT: ཞབས་ཞུ་བ་ཞབས་ཞུ་བའི་བྱ་རིམ་གླེང་སྒྲོམ་ཚུལ་ལ་སྔོན་སྒྲིག་མ་དབྱིབས'}
{'en': 'Large-scale pretrained transformer models have demonstrated state-of-the-art (SOTA) performance in a variety of NLP tasks. Nowadays, numerous pretrained models are available in different model flavors and different languages, and can be easily adapted to one’s downstream task. However, only a limited number of ', 'ar': 'أظهرت نماذج المحولات سابقة التدريب واسعة النطاق أداءً متطورًا (SOTA) في مجموعة متنوعة من مهام البرمجة اللغوية العصبية. في الوقت الحاضر ، تتوفر العديد من النماذج سابقة التدريب بنكهات نماذج مختلفة ولغات مختلفة ، ويمكن تكييفها بسهولة مع المهمة النهائية للمرء. ومع ذلك ، لا يتوفر سوى عدد محدود من النماذج لمهام الحوار ، وعلى وجه الخصوص ، مهام الحوار الموجه نحو الهدف. بالإضافة إلى ذلك ، يتم تدريب النماذج الجاهزة المتاحة على لغة المجال العام ، مما يؤدي إلى عدم تطابق بين لغة ما قبل التدريب ولغة مجال المصب. في هذه المساهمة ، نقدم CS-BERT ، نموذج BERT تم اختباره مسبقًا في ملايين الحوارات في مجال خدمة العملاء. نقوم بتقييم CS-BERT في العديد من مهام حوار خدمة العملاء النهائية ، ونوضح أن تدريبنا المسبق في المجال مفيد مقارنة بالنماذج الأخرى التي تم اختبارها مسبقًا في كل من تجارب إطلاق النار الصفري وكذلك في تجارب الضبط الدقيق ، خاصة في إعداد البيانات منخفضة الموارد.', 'es': 'Los modelos de transformadores preentrenados a gran escala han demostrado un rendimiento de vanguardia (SOTA) en una variedad de tareas de PNL. Hoy en día, numerosos modelos preentrenados están disponibles en diferentes sabores de modelos y diferentes idiomas, y se pueden adaptar fácilmente a las tareas posteriores de cada uno. Sin embargo, solo hay un número limitado de modelos disponibles para las tareas de diálogo y, en particular, las tareas de diálogo orientadas a objetivos. Además, los modelos preentrenados disponibles están entrenados en el lenguaje de dominio general, lo que crea una discordancia entre el idioma de preentrenamiento y el lenguaje de dominio descendente. En esta contribución, presentamos CS-BERT, un modelo BERT preentrenado en millones de diálogos en el campo de la atención al cliente. Evaluamos CS-BERT en varias tareas posteriores de diálogo de servicio al cliente y demostramos que nuestra capacitación previa en el dominio es ventajosa en comparación con otros modelos previamente entrenados tanto en experimentos de tiro cero como en experimentos de ajuste, especialmente en un entorno de datos de bajos recursos.', 'fr': "Les modèles de transformateurs préentraînés à grande échelle ont démontré des performances de pointe (SOTA) dans diverses tâches de PNL. De nos jours, de nombreux modèles préentraînés sont disponibles dans différentes versions de modèles et dans différentes langues, et peuvent être facilement adaptés à une tâche en aval. Cependant, seul un nombre limité de modèles sont disponibles pour les tâches de dialogue, en particulier les tâches de dialogue orientées vers des objectifs. En outre, les modèles préentraînés disponibles sont formés sur le langage général du domaine, ce qui crée une discordance entre le langage de pré-apprentissage et le langage de domaine en aval. Dans cette contribution, nous présentons CS-BERT, un modèle BERT préformé sur des millions de dialogues dans le domaine du service client. Nous évaluons le CS-BERT sur plusieurs tâches de dialogue avec le service client en aval et démontrons que notre pré-entraînement dans le domaine est avantageux par rapport à d'autres modèles préentraînés, tant dans les expériences zero-shot que dans les expériences de réglage fin, en particulier dans un environnement de données à faibles ressources.", 'pt': 'Modelos de transformadores pré-treinados em grande escala demonstraram desempenho de última geração (SOTA) em uma variedade de tarefas de PNL. Hoje em dia, vários modelos pré-treinados estão disponíveis em diferentes tipos de modelos e diferentes idiomas e podem ser facilmente adaptados à tarefa de downstream. No entanto, apenas um número limitado de modelos está disponível para tarefas de diálogo e, em particular, tarefas de diálogo orientadas para objetivos. Além disso, os modelos pré-treinados disponíveis são treinados em linguagem de domínio geral, criando uma incompatibilidade entre a linguagem de pré-treinamento e a linguagem de domínio downstream. Nesta contribuição, apresentamos o CS-BERT, um modelo BERT pré-treinado em milhões de diálogos no domínio do atendimento ao cliente. Avaliamos o CS-BERT em várias tarefas de diálogo de atendimento ao cliente downstream e demonstramos que nosso pré-treinamento no domínio é vantajoso em comparação com outros modelos pré-treinados em experimentos de tiro zero e em experimentos de ajuste fino, especialmente em uma configuração de dados de poucos recursos.', 'ja': '大規模な事前訓練された変圧器モデルは、様々なNLPタスクで最先端の（ SOTA ）性能を示しています。現在では、数多くの事前に訓練されたモデルが、さまざまなモデルのフレーバーとさまざまな言語で利用可能であり、自分の下流のタスクに簡単に適応することができます。ただし、対話タスク、特に目標指向の対話タスクに利用できるモデルは限られている。さらに、利用可能な事前トレーニングされたモデルは、一般的なドメイン言語でトレーニングされ、事前トレーニング言語と下流ドメイン起動の間に不一致を生み出します。この寄稿では、CS - BERTを紹介します。CS - BERTは、カスタマーサービス領域で数百万の対話に基づいて事前に訓練されたBERTモデルです。私たちは、いくつかの下流のカスタマーサービスダイアログタスクでCS - BERTを評価し、ゼロショット実験と微調整実験の両方で、特に低リソースのデータ設定で、ドメイン内の事前トレーニングが他の事前トレーニングモデルと比較して有利であることを実証します。', 'zh': '大预训练变压器形于百NLP,展先进之(SOTA)。 今诸习者,皆有异辞,可以易适下流。 然惟有限之形可以对事,特向之对事也。 此外,可以预练模形于域语,而于预训言下流域冗长之间生不偶。 于此篇中,介于CS-BERT,此客户服务域之数百万次,预为训练之BERT也。 吾于数下客户服务质于事CS-BERT,而证吾域内预训练比诸预练模形,于零次实验、微调实验中皆利,尤在低资源数。', 'hi': 'बड़े पैमाने पर pretrained ट्रांसफॉर्मर मॉडल NLP कार्यों की एक किस्म में अत्याधुनिक (SOTA) प्रदर्शन का प्रदर्शन किया है। आजकल, कई प्रीट्रेन्ड मॉडल विभिन्न मॉडल स्वादों और विभिन्न भाषाओं में उपलब्ध हैं, और आसानी से किसी के डाउनस्ट्रीम कार्य के लिए अनुकूलित किए जा सकते हैं। हालांकि, संवाद कार्यों के लिए केवल सीमित संख्या में मॉडल उपलब्ध हैं, और विशेष रूप से, लक्ष्य-उन्मुख संवाद कार्य। इसके अलावा, उपलब्ध pretrained मॉडल सामान्य डोमेन भाषा पर प्रशिक्षित कर रहे हैं, pretraining भाषा और डाउनस्ट्रीम डोमेन launguage के बीच एक बेमेल बनाने. इस योगदान में, हम CS-BERT, एक BERT मॉडल प्रस्तुत करते हैं जो ग्राहक सेवा डोमेन में लाखों संवादों पर पूर्वनिर्धारित है। हम कई डाउनस्ट्रीम ग्राहक सेवा संवाद कार्यों पर सीएस-बर्ट का मूल्यांकन करते हैं, और प्रदर्शित करते हैं कि हमारे इन-डोमेन प्रीट्रेनिंग दोनों शून्य-शॉट प्रयोगों के साथ-साथ महीन प्रयोगों में अन्य प्रीट्रेन्ड मॉडल की तुलना में फायदेमंद है, विशेष रूप से कम संसाधन डेटा सेटिंग में।', 'ru': 'Крупномасштабные предварительно обученные модели трансформаторов продемонстрировали современную производительность (SOTA) в различных задачах NLP. В настоящее время существует множество предварительно обученных моделей с разным вкусом и на разных языках, которые могут быть легко адаптированы к своим последующим задачам. Однако для выполнения задач диалога и, в частности, задач, ориентированных на достижение конкретных целей, имеется лишь ограниченное число моделей. Кроме того, имеющиеся предварительно подготовленные модели обучаются общему языку домена, создавая несоответствие между языком предварительного обучения и последующим лаунжуажем домена. В этом вкладе мы представляем CS-BERT, модель BERT, предварительно обученную миллионам диалогов в области обслуживания клиентов. Мы оцениваем CS-BERT по нескольким задачам последующего диалога с клиентами и демонстрируем, что наше предварительное обучение в домене выгодно по сравнению с другими предварительно обученными моделями как в экспериментах с нулевым выстрелом, так и в экспериментах с тонкой настройкой, особенно в настройках данных с низким объемом ресурсов.', 'ga': 'Tá feidhmíocht úrscothach (SOTA) léirithe ag samhlacha claochladáin réamhoilte ar mhórscála i raon tascanna NLP. Sa lá atá inniu ann, tá go leor samhlacha réamhoilte ar fáil i blasanna samhlacha éagsúla agus i dteangacha éagsúla, agus is féidir iad a oiriúnú go héasca don tasc iartheachtach. Mar sin féin, níl ach líon teoranta samhlacha ar fáil le haghaidh tascanna idirphlé, agus go háirithe tascanna idirphlé atá dírithe ar spriocanna. Ina theannta sin, cuirtear oiliúint ar na múnlaí réamhoilte atá ar fáil ar theanga ghinearálta an fhearainn, rud a chruthaíonn neamhréir idir an réamhoiliúint agus an teanga fearainn iartheachtacha. Sa rannchuidiú seo, cuirimid i láthair CS-BERT, samhail BERT réamhoilte ar na milliúin comhphlé i réimse na seirbhíse do chustaiméirí. Déanaimid meastóireacht ar CS-BERT ar roinnt tascanna comhphlé seirbhíse custaiméara iartheachtacha, agus léirímid go bhfuil buntáiste ag baint lenár réamhoiliúint in-fhearainn i gcomparáid le samhlacha réamhoilte eile i dturgnaimh náid lámhaigh agus i dturgnaimh mhionchoigeartaithe, go háirithe i suíomh sonraí íseal-acmhainne.', 'ka': 'დიდი განსაზღვრებული ტრანფორმეტრის მოდელები გამოჩვენეთ განსხვავებულ NLP დავალების განსაზღვრებულებაში. ახლა მრავალი მოდელები განსხვავებული მოდელური სიყვარებში და განსხვავებული ენაში ხელხიან, და შეიძლება მარტივი ადგილურად ადგილურად ადგილურად გადააყენება ერთი ქვემოსტრემის მაგრამ, დიალოგის დავალებისთვის მხოლოდ მარტივი მოდელების რაოდენობა, და განსაკუთრებით, მისაღების დიალოგის დავალებისთვის. დამატებით, ხელმისაწარმოდგენებული მოდელები საერთო დიომინის ენაზე განსწავლებიან, შექმნილი არასწორება საერთო ენაზე და სამუშაო დიომინის წარმოდგენა. ამ დამატებით, ჩვენ CS-BERT-ს მოდელში, BERT მოდელში მილიონი დიალოგის დიალოგიში კლიენტერის სერვისონის დიომინში გადატანა. ჩვენ CS-BERT-ს განსაზღვრებით რამდენიმე კლიენტერის სერვისტის დიალოგის მოქმედებზე და გამოჩვენებით, რომ ჩვენი დიომინში გადაწყვეტილება უფრო მნიშვნელოვანია სხვა მოდელთან გადამწყვეტილებული მოდელთან ორივე ნულ სტარტის ექ', 'hu': 'A nagyméretű előképzett transzformátormodellek a legkorszerűbb (SOTA) teljesítményt mutatták a különböző NLP feladatokban. Manapság számos előképzett modell kapható különböző modellízekben és különböző nyelvekben, és könnyen adaptálható a downstream feladathoz. A párbeszédfeladatokhoz azonban csak korlátozott számú modell áll rendelkezésre, különösen a célorientált párbeszédfeladatokhoz. Ezenkívül a rendelkezésre álló előképzett modelleket az általános domain nyelvre képezik, ami eltérést eredményez az előkészítő nyelv és a downstream domain launche között. Ebben a közreműködésben bemutatjuk a CS-BERT modellt, amely az ügyfélszolgálati területen több millió párbeszédet előkészített. Számos downstream ügyfélszolgálati párbeszéd során értékeljük a CS-BERT-et, és bebizonyítjuk, hogy a területen belüli előkészítésünk előnyös más előkészített modellekhez képest mind a nulla lövéses kísérletekben, mind a finomhangolási kísérletekben, különösen alacsony erőforrású adatbeállításokban.', 'el': 'Τα μοντέλα μετασχηματιστών μεγάλης κλίμακας έχουν επιδείξει επιδόσεις τελευταίας τεχνολογίας σε ποικίλες εργασίες. Σήμερα, πολλά προσχεδιασμένα μοντέλα είναι διαθέσιμα σε διαφορετικές γεύσεις μοντέλων και διαφορετικές γλώσσες, και μπορούν εύκολα να προσαρμοστούν στις μεταγενέστερες εργασίες κάποιου. Ωστόσο, μόνο περιορισμένος αριθμός μοντέλων είναι διαθέσιμος για καθήκοντα διαλόγου, και ιδίως για καθήκοντα διαλόγου προσανατολισμένο στον στόχο. Επιπλέον, τα διαθέσιμα προ-εκπαιδευμένα μοντέλα εκπαιδεύονται στη γενική γλώσσα τομέα, δημιουργώντας μια ασυμφωνία μεταξύ της γλώσσας προ-εκπαίδευσης και της μεταγενέστερης γλώσσας εκκίνησης τομέα. Σε αυτή τη συνεισφορά, παρουσιάζουμε ένα μοντέλο που έχει προετοιμαστεί για εκατομμύρια διαλόγους στον τομέα της εξυπηρέτησης πελατών. Αξιολογούμε το CS-BERT σε διάφορες εργασίες διαλόγου εξυπηρέτησης πελατών και αποδεικνύουμε ότι η προ-εκπαίδευση εντός του τομέα μας είναι επωφελής σε σύγκριση με άλλα προ-εκπαιδευμένα μοντέλα τόσο σε πειράματα μηδενικής βολής όσο και σε πειράματα λεπτομέρειας, ειδικά σε μια ρύθμιση δεδομένων χαμηλής περιεκτικότητας σε πόρους.', 'lt': 'Didelio masto išankstinio mokymo transformatorių modeliai parodė pažangiausius (SOTA) rezultatus įvairiose NLP užduotyse. Šiandien daugelis išankstinio mokymo modelių yra prieinami skirtingais modelių skoniais ir skirtingomis kalbomis ir gali būti lengvai pritaikyti prie savo tolesnės užduoties. Tačiau dialogo užduotims, ypač tiksliniams dialogo užduotims, galima atlikti tik nedidelį skaičių modelių. Be to, turimi išankstinio mokymo modeliai mokomi bendromis domeninėmis kalbomis, dėl kurių atsiranda neatitikimas tarp išankstinio mokymo kalbos ir tolesnės domeninės kalbos. In this contribution, we present CS-BERT, a BERT model pretrained on millions of dialogues in the customer service domain.  We evaluate CS-BERT on several downstream customer service dialogue tasks, and demonstrate that our in-domain pretraining is advantageous compared to other pretrained models in both zero-shot experiments as well as in finetuning experiments, especially in a low-resource data setting.', 'kk': 'Үлкен масштабы өзгертілген түрлендіру үлгілері NLP тапсырмаларында күй- жай (SOTA) әрекеттерін көрсетті. Қазір, көптеген өзгертілген моделдер әртүрлі үлгілер мен түрлі тілдерде қол жеткізеді, және оның төменгі тапсырмасына оңай адаптауға болады. Бірақ диалог тапсырмалары үшін тек шектелген үлгілер саны бар, осымен қатар, мақсатты диалог тапсырмалары. Қосымша, қол жеткізетін алдыңғы үлгілер жалпы домен тілінде оқылған, олардың алдыңғы тілі мен төменгі доменді жегу арасында сәйкес келмейді. Бұл қосымша, біз CS-BERT үлгісін келтіреміз, клиенттер қызметінің доменінде миллиондардың диалогтарының алдындағы BERT үлгісін көрсетеді. Біз CS-BERT дегенді бірнеше бағытталған клиенттер қызметтерінің диалог тапсырмаларында оқу және домендегі өзіміздің бағытталған моделдерімізге сәйкес келген нөл шарт эксперименттерінде, сондай-ақ бірнеше тәжірибелерді жақсы түрде', 'it': "I modelli di trasformatori pretrained su larga scala hanno dimostrato prestazioni all'avanguardia (SOTA) in una varietà di attività NLP. Al giorno d'oggi, numerosi modelli pre-addestrati sono disponibili in diversi gusti di modello e lingue diverse, e possono essere facilmente adattati al proprio compito a valle. Tuttavia, solo un numero limitato di modelli sono disponibili per le attività di dialogo, e in particolare per quelle di dialogo orientate agli obiettivi. Inoltre, i modelli pre-addestrati disponibili sono formati sul linguaggio di dominio generale, creando una disallineazione tra il linguaggio pre-formazione e il launguage di dominio a valle. In questo contributo presentiamo CS-BERT, un modello BERT pre-addestrato su milioni di dialoghi nel settore del servizio clienti. Valutiamo CS-BERT su diverse attività di dialogo del servizio clienti a valle e dimostriamo che il nostro pretraining in-domain è vantaggioso rispetto ad altri modelli pre-addestrati sia in esperimenti zero-shot che in esperimenti di finetuning, specialmente in un setting di dati a basso contenuto di risorse.", 'mt': 'Large-scale pretrained transformer models have demonstrated state-of-the-art (SOTA) performance in a variety of NLP tasks.  Illum, bosta mudelli mħarrġa minn qabel huma disponibbli f’togħmiet mudell differenti u lingwi differenti, u jistgħu jiġu adattati faċilment għall-kompitu downstream ta’ wieħed. Madankollu, numru limitat biss ta’ mudelli huma disponibbli għal kompiti ta’ djalogu, u b’mod partikolari, kompiti ta’ djalogu orjentati lejn l-għanijiet. Barra minn hekk, il-mudelli disponibbli mħarrġa minn qabel huma mħarrġa fil-lingwa ġenerali tad-dominju, li toħloq diskrepanza bejn il-lingwa ta’ qabel it-taħriġ u l-lingwa downstream tad-dominju. F’din il-kontribuzzjoni, qed nippreżentaw CS-BERT, mudell BERT imħarreġ minn qabel fuq miljuni ta’ djalogi fil-qasam tas-servizz tal-klijenti. Aħna jevalwaw CS-BERT fuq diversi kompiti ta’ djalogu downstream dwar is-servizzi tal-klijenti, u nippruvaw li t-taħriġ minn qabel fl-oqsma tagħna huwa vantaġġuż meta mqabbel ma’ mudelli oħra mħarrġa minn qabel kemm f’esperimenti mingħajr skop kif ukoll f’esperimenti ta’ rfinar, speċjalment f’ambjent ta’ dejta b’riżorsi baxxi.', 'mk': 'Големите предобучени трансформаторски модели покажаа најнови резултати (СОТА) во различни задачи на НЛП. Денес, бројни предобучени модели се достапни во различни моделни вкуси и различни јазици, и може лесно да се адаптираат на својата задача. Сепак, само ограничен број модели се достапни за задачите на дијалогот, а особено задачите на дијалогот насочени кон целите. Покрај тоа, достапните предобучени модели се обучени на генерален јазик на домен, создавајќи несогласување помеѓу предобучениот јазик и понатамошниот јазик на домен. Во овој придонес, го претставуваме CS-BERT, модел BERT претрениран на милиони дијалози во доменот на клиентската служба. Ние ја проценуваме CS-BERT на неколку задачи на дијалог за служба на клиентите во последниот тек, и демонстрираме дека нашето претренирање во домен е предност во споредба со други претренирани модели во нулта експерименти, како и во финетирање експерименти, особено во поставување на податоци со ниски ресурси.', 'ml': 'വലുതായ വലിയ സ്കാല്\u200d പ്രത്യേകിച്ചു മാറ്റങ്ങളുടെ മോഡലുകള്\u200d വ്യത്യസ്തമായ പ്രവര്\u200dത്തനങ്ങളില്\u200d NLP ജോലികളില്\u200d പ്രദര്\u200dശിപ്പിച്ചു ഇന്ന് വ്യത്യസ്ത മോഡലുകളിലും വ്യത്യസ്ത ഭാഷകളിലും ധാരാളം മോഡലുകള്\u200d ലഭ്യമാകുന്നു. ഒരാളുടെ താഴ്വരയുടെ ജോലിയിലേക്ക് മാറ്റാന എന്നാലും, സംസാരിക്കുന്ന ജോലികള്\u200dക്കും, പ്രത്യേകിച്ച്, ലക്ഷ്യമുള്ള ഡയലോഗ് ജോലികള്\u200dക്കും മാത്രം പരിധിയില്ലാത്ത ഒരു  കൂടാതെ, ലഭ്യമല്ലാത്ത പ്രചരിപ്പിക്കപ്പെട്ട മോഡലുകള്\u200d സാധാരണ ഡൊമെയിന്\u200d ഭാഷയില്\u200d പഠിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. മഴയുട ഈ ഭാഗ്യത്തില്\u200d നമ്മള്\u200d CS-BERT-നെ കാണിക്കുന്നു. ഒരു ബെര്\u200dട്ടി മോഡല്\u200d കോടികണക്കിന് സംസാരിക്കുന്നു നമ്മള്\u200d കുറച്ചു താഴ്വരയിലെ കസ്റ്റമറ്\u200d സേവനത്തിന്റെ ഡയലോഗ് ജോലികളില്\u200d CS-BERT പരിശോധനങ്ങള്\u200d വിലയിക്കുന്നു. പ്രത്യേകിച്ച് കുറഞ്ഞ വിഭവങ്ങളുടെ ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d നമ്മ', 'mn': 'Олон хэмжээний шилжүүлэгч загварууд нь NLP даалгаварын төрлийн үйл ажиллагааг харуулсан. Өнөөдөр олон арьстай загварууд өөр загварын амттай, өөр хэл дээр ашиглаж байна. Мөн хүний доорх ажил дээр амархан адилтгаж болно. Гэхдээ зөвхөн хэд хэдэн загварууд диалог даалгаварын тулд, ялангуяа зорилготой диалог даалгаварын тулд ашиглах боломжтой. Үүнээс илүү олон арга загварууд нь ерөнхий хэл дээр сургалтын загвар өгдөг. Өмнөх хэл болон доорх дотоод холбоотой хэл хоорондоо холбоотой байдал бий болгодог. Үүний тусламжтайгаар бид CS-BERT загварыг хэрэглэгчийн үйл ажиллагаанд сая сая диалогуудын тусламжтайгаар үзүүлсэн. Бид CS-BERT-г олон төвөгтэй хэрэглэгчийн үйлчилгээний диалог даалгаврын талаар үнэлдэг. Мөн бидний дотор холбогдолтой даалгаврын даалгаврыг нь 0-шүтлэг туршилтын хоёр даалгаврын арга загвартай харьцуулахад ашигтай гэдгийг харуулж байна.', 'no': 'Stor skala transformerte transformeringsmodeller har demonstrert utvikling av kunsttilstanden (SOTA) i mange NLP-oppgåver. Denne daga er mange modeller som blir brukt i forskjellige modeller og forskjellige språk, og kan enkelt tilpassast til ei nedtrekkoppgåve. Men berre eit begrenset tal modeller er tilgjengeleg for dialogoppgåver, og spesielt for målsorientert dialogoppgåver. I tillegg vert dei tilgjengelege pretrained modelane utlærte på generelle domenespråk, og laga ei ikkje samsvar mellom pretraining language og nedstrømdområdet. I denne bidraga presenterer vi CS-BERT, ein BERT-modell, som er foreløyst på millioner av dialogar i klientteneste-domenet. Vi evaluerer CS-BERT på fleire oppgåver i dialogvindauget for nedstrømmende klienttenester, og demonstrerer at våre inndomene-område er nyttig samanlikna med andre pretrainerte modeller i begge null-snitteksperimenter, og i fint-utføring av eksperimenter, spesielt i ein låg ressursdatainnstilling.', 'ro': 'Modelele de transformatoare pre-instruite la scară largă au demonstrat performanțe de ultimă oră (SOTA) într-o varietate de sarcini NLP. În zilele noastre, numeroase modele pre-instruite sunt disponibile în diferite arome de model și limbi diferite și pot fi ușor adaptate sarcinii din aval. Cu toate acestea, numai un număr limitat de modele sunt disponibile pentru sarcinile de dialog și, în special, sarcinile de dialog orientate spre obiective. În plus, modelele pre-instruite disponibile sunt instruite pe limbajul domeniului general, creând o neconcordanță între limbajul pre-instruire și lansarea domeniului din aval. În această contribuție, vă prezentăm CS-BERT, un model BERT pregătit pe milioane de dialoguri în domeniul serviciului pentru clienți. Evaluăm CS-BERT pe mai multe sarcini de dialog în aval cu serviciul de relații cu clienții și demonstrăm că pregătirea noastră în domeniu este avantajoasă comparativ cu alte modele pre-pregătite atât în experimentele zero-shot, cât și în experimentele fintuning, în special într-o setare de date cu resurse reduse.', 'pl': 'Wielkoskalowe modele transformatorów wstępnie trenowanych wykazały najnowocześniejszą wydajność (SOTA) w różnych zadaniach NLP. Obecnie liczne wstępnie trenowane modele są dostępne w różnych smakach modeli i różnych językach i można je łatwo dostosować do dalszych zadań. Jednakże dostępna jest tylko ograniczona liczba modeli dla zadań dialogowych, a w szczególności zadań dialogowych ukierunkowanych na cel. Ponadto dostępne modele wstępnego treningu są przeszkolone na ogólnym języku domeny, co powoduje niedopasowanie języka wstępnego do dalszego języka uruchamiania domeny. W tym artykule przedstawiamy CS-BERT, model BERT wstępnie przeszkolony na milionach dialogów w dziedzinie obsługi klienta. Oceniamy CS-BERT podczas kilku dalszych zadań dialogu z obsługą klienta i wykazujemy, że nasze wstępne szkolenie w domenie jest korzystne w porównaniu z innymi modelami wstępnie trenowanymi zarówno w eksperymentach zero-shot, jak i w eksperymentach precyzyjnych, zwłaszcza w przypadku niskich zasobów ustawień danych.', 'so': "Tusaalada beddelka ee aad u weyn ee la soo hor jeeday waxay muujiyeen xaalada farshaxanka (SOTA) oo ah shaqooyin kala duduwan NLP. Maanta waxaa la heli karaa tusaalooyin badan oo lagu soo daabacay tusaalooyin kala duduwan iyo luuqado kala duduwan, oo waxaa si fudud loogu beddeli karaa shaqada hoose-hoose. Si kastaba ha ahaatee waxaa la heli karaa tusaalooyin aad u xadan oo kaliya, shaqooyinka dialogka, khusuusan goobaha diyaarinta ee la jeedo. Waxaa intaas dheer oo lagu tababariyaa tusaalooyin lagu soo daayay afka guud ee deegaanka, taas oo u abuuraya isku mid ah luqada hore-ka iyo luqada hoose-durka. Qaybdaas waxan ku soo bandhignaa CS-BERT, model BERT ah oo lagu soo daabacay malayan dialogues oo ku yaala goobta adeegga macaamiisha. Waxaynu ku qiimeynaynaa CS-BERT shaqooyinka adeegga macaamiisha ee badda hoose ka socda, waxaana caddaynaynaa in dabooliddayada gudaha ah uu faa'iido u yahay isbarbarbardhigga modelalka kale oo la sameynayo imtixaanka zero-shot iyo imtixaanka Finnishing, khusuusan ku sameynta danbiyada hoose-resource.", 'ms': 'Model pengubah yang dilatih sebesar skala besar telah menunjukkan prestasi state-of-the-art (SOTA) dalam pelbagai tugas NLP. Pada hari ini, banyak model yang dilatih sebelum dilatih tersedia dalam aroma model yang berbeza dan bahasa yang berbeza, dan boleh mudah disesuaikan dengan tugas turun. Namun, hanya sejumlah model yang terbatas yang tersedia untuk tugas dialog, dan terutama tugas dialog yang ditujukan tujuan. Selain itu, model pralatih yang ada dilatih pada bahasa domain umum, mencipta ketidakpadanan antara bahasa pralatih dan bahasa domain turun. Dalam kontribusi ini, kami perkenalkan CS-BERT, model BERT yang dilatih dahulu pada jutaan dialog dalam domain perkhidmatan pelanggan. We evaluate CS-BERT on several downstream customer service dialogue tasks, and demonstrate that our in-domain pretraining is advantageous compared to other pretrained models in both zero-shot experiments as well as in finetuning experiments, especially in a low-resource data setting.', 'sr': 'Velika skala transformacijskih modela pokazala su predstavu umjetnosti (SOTA) u raznim zadacima NLP-a. Danas su dostupni brojni pretkišni modeli u različitim uzorcima i različitim jezicima, i mogu se lako prilagoditi nekom sledećem zadatku. Međutim, dostupni su samo ograničeni broj modela za zadatak dijaloga, i posebno zadatak sa ciljem orientiranim dijalogom. Osim toga, dostupni modeli su obučeni na općem jeziku domena, stvarajući nesporazum između jezika pretkivanja i praonice domena. U ovom doprinosu predstavljamo CS-BERT model BERT koji se pretvarao na milione dijaloga u domenu usluga klijenata. Procjenjujemo CS-BERT na nekoliko zadataka o dijalogu usluga klijenata, i pokazujemo da je naša pretrenja u domenu prednost u usporedbi sa drugim pretreniranim modelima u oba eksperimenta sa nulom pucnjavom, kao i u finalnim eksperimentima, posebno u postavljanju podataka sa niskim resursima.', 'si': 'ලොකු ප්\u200dරමාණය ප්\u200dරමාණයක් වෙන්න ප්\u200dරමාණයක් නිර්මාණය කරලා තියෙන්නේ NLP විවිධ වැඩකට ස්ථානය-of-the-art (SOTA) ප්\u200dරකා අදින්, වෙනස් මෝඩේල් වලට සහ වෙනස් භාෂාවල් වලින් ප්\u200dරමාණ විදිහට පුළුවන් වෙනස් විදිහට ප්\u200dරමාණ විදිහට, සහ කෙ නමුත්, සංවාද කාර්යාලය සඳහා සීමාවිත අංකයක් විතරයි, විශේෂයෙන්ම, ඉලක්ෂණය සඳහා සංවාද කාර්යා ඒ වගේම, පුළුවන් ප්\u200dරීට්\u200dරේන්ඩ් මොඩේල් එක සාමාන්\u200dය ඩොමේන් භාෂාවට ප්\u200dරශ්නය කරනවා, ප්\u200dරීට්\u200dරේන්ඩ් භාෂාවය ස මේ සම්බන්ධයෙන්, අපි CS-BERT පෙන්වන්නම්, BERT මොඩල් එකක් ප්\u200dරතිස්ථාපනය කරලා ග්\u200dරහස්ථාපකය සේවාවේ මිලියන් සං අපි CS-BERT විශ්වාස කරනවා සේවා සේවා වැඩක් විතරයි, ඒ වගේම ප්\u200dරකාශ කරනවා අපේ ඩොමේන් එකේ ප්\u200dරීට්\u200dරේන්ස් එක්ක අනිත් ප්\u200dරීට්\u200dරේන්ස් මොඩේල්ස් එක්ක අනිත් ප්\u200dරය', 'sv': 'Storskaliga förkränade transformatormodeller har visat state-of-the-art (SOTA) prestanda i en mängd olika NLP-uppgifter. Numera finns många förkränade modeller tillgängliga i olika modellsmaker och olika språk, och kan enkelt anpassas till ens nedströms uppgift. Det finns dock bara ett begränsat antal modeller för dialoguppgifter, särskilt målinriktade dialoguppgifter. Dessutom utbildas de tillgängliga förkränade modellerna i allmänt domänspråk, vilket skapar en missmatchning mellan förkränningsspråket och efterföljande domänlaunguage. I detta bidrag presenterar vi CS-BERT, en BERT-modell som har förtränats på miljontals dialoger inom kundserviceområdet. Vi utvärderar CS-BERT på flera kundtjänstdialoguppgifter i efterföljande led, och visar att vår in-domain pretraining är fördelaktig jämfört med andra förkränade modeller i både nollskottsexperiment och finjusteringsexperiment, särskilt i en datainställning med låga resurser.', 'ta': 'பெரிய அளவு மாற்று மாற்றும் மாதிரிகள் பல்வேறு NLP பணிகளில் நிலைமை- கலை( SOTA) செயல்பாட்டை காட்டியுள்ளது. இன்று, பல மாதிரியான மாதிரிகள் மற்றும் வேறு மொழிகளில் கிடைக்கும் மாதிரிகளில், மற்றும் மாதிரிகளில், மற்றும் சுலபமாக ஒருவரின்  ஆனால், உரையாடல் செயல்களுக்கு மட்டும் குறைந்த மாதிரிகள் மட்டுமே கிடைக்கும், குறிப்பாக, சேர்க்கப்பட்ட உரையாடல் செ கூடுதலாக, கிடைக்கப்பட்ட மாதிரிகள் பொதுவான களம் மொழியில் பயிற்சி செய்யப்பட்டுள்ளது, பொதுவான மொழி மற்றும் கீழ் தளத்தின் க இந்த செயல்பாட்டில், நாம் CS-BERT காண்பிக்கிறோம், ஒரு பிரெட் மாதிரி மில்லியன் உரையாடல் கஸ்டமர் சேவை தளத்தில் உள்ளது. We evaluate CS-BERT on several downstream customer service dialogue tasks, and demonstrate that our in-domain pretraining is advantageous compared to other pretrained models in both zero-shot experiments as well as in finetuning experiments, especially in a low-resource data setting.', 'ur': 'بہت بڑی اسکیل کی پرٹرینٹر موڈل نے NLP کے مختلف کاموں میں موقعیت-of-the-art (SOTA) کو دکھایا ہے۔ آج، بہت سی موڈلیاں مختلف موڈل کی مہمانوں اور مختلف زبانوں میں موجود ہیں، اور ایک کے نیچے نیچے کام کے ساتھ آسان طور پر اضافہ کر سکتے ہیں. لیکن، صرف ایک مقدار نمڈلوں کی تعداد ڈالیلوگ کے کاموں کے لئے موجود ہیں، اور مخصوصاً موجود دیالوگ کے کاموں کے لئے موجود ہیں. اور اس کے علاوہ، موجود پرٹرین ڈومین کی زبان پر آموزش کی جاتی ہیں، پرٹرین کی زبان اور ڈونسٹریم ڈومین لانگ کے درمیان ایک غلطی پیدا کرتی ہے. ہم نے CS-BERT کے ذریعے ایک BERT موڈل کو مشترک سرویس ڈومین میں میلیونوں ڈالگوں پر پیش کیے۔ ہم نے CS-BERT کو بہت سی ڈونسٹریم کائناٹ سرویس ڈالیوں کے کاموں پر ارزش کیا ہے، اور دکھاتے ہیں کہ ہماری دامنی پرٹرینگ دوسری پرٹرینڈ ڈالیوں کے مقابلہ میں فائدہ اٹھاتی ہے، دونوں صفر-شٹ آزمائش میں اور بہترین آزمائش میں، مخصوصاً کم رسورس ڈ', 'uz': "Katta qo'llangan transformer modellari NLP tashkilotlarida (SOTA) bajarish holatini koʻrsatilgan. Bugun hozirda ko'pgina taxminan modellar boshqa shakllar va har xil tillarda mavjud, va bir necha ishlatish imkoniyatini oddiy o'zgartirish mumkin. Ammo, muloqat vazifalari uchun faqat chegara modellar mavjud emas, hususan qanday oyna- oynasidagi vazifalar uchun. Ko'rsatilgan foydalanilgan modellar umumiy domen tilida o'rganiladi, o'zgarishni o'zgartirish tilidagi o'zgarishni va quyidagi domen soʻzlarini o'zgartirish mumkin. Bu paytda, biz CS-BERT modelini boshqaruvchi xizmatning xonaga millionlab muloqatlarni o'zgartiradi. Biz CS-BERT haqida ko'pchilik foydalanuvchi muloqat muloqat vazifalarini qiymatimiz, va domen tahrirlashimiz juda foydalanishimizni ko'rsatishimiz mumkin. Biz o'zimiz qo'shilgan tizimlarning ikkita nuqta saqlangan modellariga va tizimni ajratish imtiyozlarida bajarayonligimizni va bajarish imtiyozlarida bajariladiga", 'vi': 'Các mô hình máy biến thế trước mưa lớn đã chứng minh hiệu suất hiện đại (SOTA) trong nhiều công việc lập NLP. Ngày nay, có rất nhiều mẫu premưa được tìm thấy trong nhiều loại hương vị khác nhau và ngôn ngữ khác nhau, và có thể dễ dàng thích nghi với công việc xuôi dòng. Tuy nhiên, chỉ có một số mẫu giới hạn cho các nhiệm vụ đối thoại, và đặc biệt là những nhiệm vụ hướng dẫn đối thoại. Thêm vào đó, các mô hình sẵn sàng được đào tạo bằng ngôn ngữ miền chung, tạo ra sự không phù hợp giữa ngôn ngữ sản xuất trước và kiểu miền xuôi dòng. Trong phần đóng góp này, chúng tôi giới thiệu CS-BERT, một mô hình của BERT được trông đợi từ hàng triệu cuộc ca khúc trong lĩnh vực dịch vụ khách hàng. Chúng tôi đánh giá CS-BERT trong nhiều nhiệm vụ đối thoại dịch vụ khách hàng xuôi dòng, và chứng minh rằng chất lượng trước mặt là thuận lợi hơn so với những mẫu trước kia, cả trong các thí nghiệm không bắn cũng như trong các thí nghiệm cải thiện độ chính xác, đặc biệt trong việc cung cấp dữ liệu ít nguồn.', 'bg': 'Широкомащабните предварително тренирани трансформаторни модели демонстрират най-съвременна производителност при различни задачи на НЛО. В днешно време многобройни предварително обучени модели се предлагат в различни модели вкусове и различни езици и могат лесно да бъдат адаптирани към задачата надолу по веригата. Въпреки това, само ограничен брой модели са налични за задачи по диалог, и по-специално за задачи по диалог, ориентирани към целта. В допълнение, наличните предварително обучени модели се обучават на общ език на домейна, което създава несъответствие между езика на предварително обучение и стартирането на домейна надолу по веригата. В този принос представяме модел, който се подготвя за милиони диалози в областта на обслужване на клиенти. Ние оценяваме по няколко задачи за диалог с обслужване на клиенти надолу по веригата и демонстрираме, че нашето предварително обучение в областта е изгодно в сравнение с други предварително обучени модели както при експерименти с нулеви изстрели, така и при експерименти с фино настройване, особено при настройка на данни с ниски ресурси.', 'da': 'Storskalige fortrænede transformatormodeller har demonstreret state-of-the-art (SOTA) ydeevne i en række NLP-opgaver. I dag er talrige prætrænede modeller tilgængelige i forskellige modelsvarianter og forskellige sprog, og kan nemt tilpasses ens downstream opgave. Der er dog kun et begrænset antal modeller til rådighed for dialogopgaver og især målrettede dialogopgaver. Desuden er de tilgængelige pre-trained modeller trænet i almindeligt domænesprog, hvilket skaber en mismatch mellem pre-training sprog og downstream domænesprog. I dette bidrag præsenterer vi CS-BERT, en BERT-model, der er forudtrænet på millioner af dialoger inden for kundeserviceområdet. Vi evaluerer CS-BERT på flere downstream kundeservice dialogopgaver, og demonstrerer, at vores in-domæne forudtræning er fordelagtig sammenlignet med andre forudtrænede modeller i både nul-shot eksperimenter og finjusterende eksperimenter, især i en dataindstilling med lav ressource.', 'hr': 'Velika skala pretkišnih modela transformer a pokazala su učinkovitost stanja umjetnosti (SOTA) u raznim zadacima NLP-a. Danas su dostupni brojni pretkišni modeli u različitim uzorcima i različitim jezicima, i mogu se lako prilagoditi njegovom zadatku. Međutim, dostupni su samo ograničeni broj modela za zadatke dijaloga, i posebno zadatke s ciljem orientiranim dijalogom. Osim toga, dostupni modeli pretkišeni su obučeni na općem jeziku domena, stvarajući nesporazum između jezika pretkišenja i praonice domena dolje. U ovom doprinosu predstavljamo CS-BERT model BERT koji se pretvarao na milijune dijaloga u domenu usluga klijenata. Procjenjujemo CS-BERT na nekoliko zadataka o dijalogu s uslugama klijenata, i pokazujemo da je naša pretreniranja u domenu prednost u usporedbi s drugim pretreniranim modelima u oba eksperimenta s nulom pucnjavom, kao i u finetujućim eksperimentima, posebno u postavljanju podataka s niskim resursima.', 'de': 'Große vortrainierte Transformatormodelle haben in einer Vielzahl von NLP-Aufgaben State-of-the-Art (SOTA) Leistung demonstriert. Heutzutage stehen zahlreiche vortrainierte Modelle in verschiedenen Modellvarianten und Sprachen zur Verfügung und können problemlos an die nachgelagerte Aufgabe angepasst werden. Für Dialogaufgaben, insbesondere für zielorientierte Dialogaufgaben, stehen jedoch nur wenige Modelle zur Verfügung. Darüber hinaus werden die verfügbaren vortrainierten Modelle auf allgemeine Domänensprache trainiert, wodurch eine Diskrepanz zwischen der Vortrainingssprache und der nachgelagerten Domänensprache entsteht. In diesem Beitrag stellen wir CS-BERT vor, ein BERT-Modell, das auf Millionen von Dialogen im Kundenservice-Bereich vortrainiert wurde. Wir evaluieren CS-BERT auf mehreren nachgelagerten Kundendialogaufgaben und zeigen, dass unser In-Domain-Pretraining sowohl in Zero-Shot-Experimenten als auch in Finetuning-Experimenten, insbesondere in einer ressourcenarmen Datensetzung, vorteilhaft gegenüber anderen Vortrainierungsmodellen ist.', 'nl': 'Grootschalige voorgetrainde transformatormodellen hebben state-of-the-art (SOTA) prestaties aangetoond in een verscheidenheid van NLP-taken. Tegenwoordig zijn tal van voorgetrainde modellen beschikbaar in verschillende modellen smaken en verschillende talen, en kunnen ze gemakkelijk worden aangepast aan de downstream taak. Er is echter slechts een beperkt aantal modellen beschikbaar voor dialoogtaken, en met name voor doelgerichte dialoogtaken. Daarnaast worden de beschikbare pre-training modellen getraind op algemene domeintaal, waardoor een mismatch ontstaat tussen de pre-training taal en de downstream domein launchage. In deze bijdrage presenteren we CS-BERT, een BERT model dat vooraf is getraind op miljoenen dialogen in het klantenservicedomein. We evalueren CS-BERT op verschillende downstream customer service dialogtaken en tonen aan dat onze in-domain pretraining voordelig is ten opzichte van andere vooraf getrainde modellen in zowel zero-shot experimenten als in finetuning experimenten, vooral in een lage resource data setting.', 'id': "Model transformer yang dilatih sebesar skala besar telah menunjukkan prestasi state-of-the-art (SOTA) dalam berbagai tugas NLP. Nowadays, numerous pretrained models are available in different model flavors and different languages, and can be easily adapted to one's downstream task.  Namun, hanya sejumlah model terbatas yang tersedia untuk tugas dialog, dan khususnya, tugas dialog oriented tujuan. Selain itu, model yang tersedia yang dilatih sebelum dilatih dilatih dalam bahasa domain umum, menciptakan ketidaksesuaian antara bahasa pelatih sebelum dilatih dan pembersihan domain turun. Dalam kontribusi ini, kami mempersembahkan CS-BERT, model BERT yang dilatih di depan jutaan dialog dalam domain layanan pelanggan. Kami mengevaluasi CS-BERT pada beberapa tugas dialog pelanggan turun, dan menunjukkan bahwa pralatihan kita dalam domain adalah keuntungan dibandingkan dengan model-model lainnya yang dilatih sebelumnya dalam percobaan zero-shot dan dalam penentuan percobaan, terutama dalam pengaturan data sumber daya rendah.", 'sw': 'Mradi wa mabadiliko makubwa uliofanana kuwa umeonyesha utendaji wa hali ya sanaa (SOTA) katika kazi mbalimbali za NLP. Hivi sasa, mifano mingi yanapatikana katika mifano tofauti na lugha tofauti, na inaweza kubadilishwa kwa urahisi katika kazi ya moja ya mitandao. Hata hivyo, idadi kubwa tu ya mifano inapatikana kwa ajili ya kazi za mazungumzo, na hasa, majukumu ya mazungumzo yanayoelekezwa na lengo. Zaidi ya hayo, mifano inayopatikana inafundishwa kwa lugha ya kawaida ya ndani, na kutengeneza upinzani wa kutokupana na lugha ya kudanganya na nguo za ndani ya mito. Katika mchango huu, tunawasilisha CS-BERT, mtindo wa BERT uliofanana na mamilioni ya mazungumzo katika eneo la huduma za wateja. Tutathmini CS-BERT juu ya majaribio kadhaa ya mazungumzo ya wateja wa mito ya chini, na kuonyesha kwamba matumizi yetu ya ndani inafaa kulinganisha na mifano mengine yanayojionyesha katika majaribio yasiyo na sifa pamoja na majaribio ya kufikia, hususani katika mazingira ya taarifa ya chini ya rasilimali.', 'fa': 'مدلهای تغییر\u200cدهنده\u200cی مقیاس بزرگ پیش\u200cفرینش\u200cکننده\u200cی مقیاس هنر (SOTA) در کارهای مختلف NLP نشان داده\u200cاند. امروز، مدل\u200cهای زیادی پیش\u200cپوشیده در مزه\u200cهای متفاوت و زبانهای متفاوت در دسترسی دارند، و می\u200cتوانند به راحتی به کار پایین\u200cترین یکی adapt شوند. ولی تنها تعدادی از مدل محدود برای وظیفه\u200cهای گفتگو وجود دارد، و مخصوصاً وظیفه\u200cهای گفتگوی با هدف است. در addition, the available pre-rained models are trained on general domain language, creating a mismatch between the pretraining language and the downstream domain launguage. در این شرکت، ما CS-BERT را پیشنهاد می\u200cکنیم، یک مدل BERT که بر میلیون\u200cها صحبت\u200cها در دامنه خدمت مشتری پیشنهاد شده است. ما CS-BERT را در مورد چندین وظیفه صحبت مشتری پایین ارزیابی می\u200cکنیم، و نشان می\u200cدهیم که تغییر داده\u200cهای کم منبع ما در مقایسه با دیگر مدل\u200cهای تغییر تغییر داده شده در هر دو آزمایش\u200cهای صفر و در آزمایش\u200cهای تغییر تغییر داده\u200cایم.', 'tr': "Ullakan ölçekli önlenmiş transformer modelleri NLP görevlerinde durum-of-the-art (SOTA) täzelikleri görkezildi. Şu wagt, birnäçe öň önsüz nusgalar farklı nusgalarda we dürli dillerde bar we kişiniň iň aşak täzeliklere aňsatlyk üýtgebilir. Ýöne diňe diňe birnäçe nusgalar diňe dialogyň görevleri üçin meýdanlaşýar Beýleki, elýeterli önlenmiş nusgalar umumy domenyň dilinde eğitilýär. Öňlenmek dilinde we a şağı domenyň başlangıçysynyň arasynda hiç duşuşygy ýok edip biler. Bu tekrarda, biz CS-BERT'i, BERT modelini müşteri hızmeti domundaki milyonlarla dialoglar üzerinde önlenmiştik. Biz CS", 'af': "Groot-skaal voorstrek transformeerde modele het die state-of-the-art (SOTA) prestasie in 'n verskillende NLP-opdragte bevestig. Vandag, veelvuldige pretreënde modele is beskikbaar in verskillende modellevorms en verskillende tale, en kan maklik aan een se onderstreem taak aanpas word. Maar net 'n beperkte aantal modele is beskikbaar vir dialoog opdragte, en in besonderhede is die doel-orienteerde dialoog opdragte. In addition, the available pretrained models are trained on general domain language, creating a mismatch between the pretraining language and the downstream domain launguage. In hierdie bydraag, ons voorsien CS-BERT, 'n BERT model wat op miljoene van dialoog in die kliënt diens domein voorsien het. Ons evalueer CS-BERT op verskeie onderstreem kliënt diens dialoog opdragte, en wys dat ons in-domein pretraining voordeel is vergelyk met ander pretrained modele in beide zero-skoot eksperimente as ook in finetuning eksperimente, veral in 'n lae-hulpbron data instelling.", 'sq': 'Modelet e transformuesve të stërvitur në shkallë të madhe kanë demonstruar performancën më të lartë (SOTA) në një shumëllojshmëri detyrash NLP. Sot, modele të shumta të parastërvitur janë në dispozicion në shije të ndryshme modeli dhe gjuhë të ndryshme dhe mund të përshtaten lehtë ndaj detyrës s ë dikujt. Megjithatë, vetëm një numër i kufizuar modelesh janë në dispozicion për detyrat e dialogut dhe veçanërisht për detyrat e dialogut me qëllim. Përveç kësaj, modelet e disponueshme të stërvitura para-stërvitura janë trajnuar në gjuhën e përgjithshme të domenit, duke krijuar një mospërputhje midis gjuhës së stërvitjes para-stërvitjes dhe gjuhës së poshtme të domenit. Në këtë kontribut, ne paraqesim CS-BERT, një model BERT i stërvitur në miliona dialoge në domenin e shërbimit të klientëve. Ne vlerësojmë CS-BERT në disa detyra më poshtë të dialogut të shërbimit të klientëve dhe demonstrojmë se parastërvitja jonë në domeni është e dobishme krahasuar me modele të tjerë të parastërvitur në eksperimente me zero-shot si dhe në rregullimin e eksperimenteve, veçanërisht në një vendosje të dhënash me burime të ulëta.', 'am': 'ትልቅ ምርጫዎች በተለያዩ የNLP ስርዓቶች የ-የ-የ-art (SOTA) ስርዓት አካባቢ ነው፡፡ ዛሬ፣ በተለየ ዓይነቶች በተለያዩ ምሳሌ ብዛት እና በልዩ ቋንቋዎች ውስጥ የተመሳሳይ ሞዴላዎች ተገኝተዋል፡፡ ምንም እንኳን ለጥያቄ ስራዎች እና በተለየ አቀማመጥ የመስኮት ማነሻ ስራቶች የተደረገ ብዙዎች ብቻ ናቸው፡፡ በተጨማሪም፣ የተገኘው የድምፅ ዓይነቶች በጠቅላላ ዶሜን ቋንቋ ያስተማራሉ፡፡ በዚህ አቀማመጥ፣ የBERT ምሳሌ በመሊዮን በሚሊዮን የሚቆጠሩ የጋዜጠኝነት አገልግሎት አካባቢዎች ላይ የተዘጋጀ እናደርጋለን፡፡ የCS-BERT በብዙ ውኃ አካባቢ አገልግሎት ማኅበረሰብ ማኅበረሰብ ስራዎችን እናሳውቃለን፡፡', 'hy': 'Մեծ մասշտաբով նախապատրաստված վերափոխման մոդելները ցույց են տալիս նորաձևակերպ գործողությունները ՆԼՊ-ի բազմաթիվ խնդիրներում: Այսօր բազմաթիվ նախավարժված մոդելներ տարբեր մոդելների համերություններով և տարբեր լեզուներով են հասանելի, և դրանք հեշտությամբ կարող են հարմարվել իրենց հետագա խնդրին: Այնուամենայնիվ, միայն մի սահմանափակ թիվ մոդելներ հասանելի են խոսակցական խնդիրների համար, հատկապես նպատակով ուղղությամբ խոսակցական խնդիրների համար: Ավելին, հասանելի նախավարժված մոդելները սովորեցվում են ընդհանուր բնագավառի լեզվի վրա, ստեղծում են անհամապատասխանություն նախավարժվող լեզվի և ներքևի բնագավառի լվացքի միջև: In this contribution, we present CS-BERT, a BERT model pretrained on millions of dialogues in the customer service domain.  Մենք գնահատում ենք CS-BER-ը հաճախորդների ծառայությունների բացատրության որոշ հետագա խնդիրների վրա և ցույց ենք տալիս, որ մեր տիեզերքում նախադասությունը օգտակար է համեմատած այլ նախադասությունների մոդելների հետ՝ զրոյի փորձարկումներում, ինչպես նաև փորձարկումներում, հատկապես ցածր ռեսուրս', 'ko': '대규모 예비훈련 변압기 모형은 이미 각종 NLP 임무 중에서 최첨단(SOTA) 성능을 보여 주었다.현재 많은 예비 훈련을 거친 모델들이 서로 다른 모델 스타일과 언어를 가지고 있어 하류 임무에 쉽게 적응할 수 있다.그러나 유한한 수량의 모델만 대화 임무, 특히 목표를 향한 대화 임무에 사용할 수 있다.또한 사용 가능한 예훈련 모델은 통용 분야 언어에서 훈련된 것으로 예훈련 언어와 하류 분야 언어 간의 불일치를 초래했다.본고에서 CS-BERT를 소개했는데 이것은 고객 서비스 분야의 수백만 개의 대화를 바탕으로 하는 BERT 모델이다.우리는 몇 개의 하위 고객 서비스 대화 임무에서 CS-BERT에 대해 평가를 실시했고 우리의 역내 예비 훈련은 다른 예비 훈련 모델에 비해 제로 포 실험과 마이크로 조정 실험에서 특히 저자원 데이터 환경에서 우위를 가진다는 것을 증명했다.', 'bn': 'বিশাল পর্যায়ের প্রাপ্ত পরিবর্তন মডেল বিভিন্ন ধরনের এনএলপি কাজে প্রদর্শন করেছে (SOTA) শিল্পের অবস্থা (SOTA) প্রদর্শন করেছে। বর্তমানে বিভিন্ন মডেলের স্বাদ এবং বিভিন্ন ভাষায় অনেক ভাষায় প্রাপ্ত মডেল পাওয়া যাচ্ছে এবং একের নীচের কাজে সহজে পাওয়া যাবে। তবে ডায়ালগ কাজের জন্য শুধুমাত্র সীমিত কয়েকটি মডেল পাওয়া যায়, বিশেষ করে লক্ষ্য-উদ্দেশ্যে ডায়ালগ কাজের জন্য। এছাড়াও, প্রাপ্ত প্রেমিক মডেল সাধারণ ডোমেইন ভাষায় প্রশিক্ষণ প্রদান করা হয়েছে, প্রেমিং ভাষা এবং নীচের নদীনের ডোমেইন ভাষার মধ্যে  এই অবদানের মধ্যে আমরা সিসি-বেরেট উপস্থাপন করছি, একটি বেরেটি মডেল, যা ক্যাস্টামার সার্ভিস ডোমেইনে লক্ষ লক্ষ আলোচনার উপর প্রাপ্ত হয়ে আমরা সিসি-বেরেটের বেশ কয়েকটি নীচের ক্যাস্টার সার্ভিসের ডায়ালগের কাজের উপর মূল্যায়ন করি এবং প্রদর্শন করি যে আমাদের ডোমেইনের ভাবে বৃষ্টি হচ্ছে অন্যান্য প্রেমিক মডেলের তুলনায়,', 'bs': 'Velika skala pretkišnih modela transformer a pokazala su izvršnost stanja umjetnosti (SOTA) u raznim zadacima NLP-a. Danas su dostupni brojni pretkišni modeli u različitim uzorcima i različitim jezicima, i mogu se lako prilagoditi njegovom zadatku. Međutim, dostupni su samo ograničeni broj modela za zadatak dijaloga, i posebno zadatak s ciljem orientiranim dijalogom. Osim toga, dostupni modeli pretkišeni su obučeni na općem jeziku domena, stvarajući nesporazum između jezika pretkišenja i praonice domena. U ovom doprinosu predstavljamo CS-BERT model BERT koji se pretvarao na milijune dijaloga u domenu usluga klijenata. Procjenjujemo CS-BERT na nekoliko zadataka o dijalogu s uslugama klijenata, i pokazujemo da je naša pretreniranja u domenu prednost u usporedbi s drugim pretreniranim modelima u oba eksperimenta sa nulom pucnjavom, kao i u finalnim eksperimentima, posebno u postavljanju podataka s niskim resursima.', 'az': "Büyük ölçülü pretransformer modelləri NLP işlərində müxtəlif növbənöv işlərdə müəyyən etdilər. Bugünlər, çoxlu əvvəlki modellər fərqli modellərdə və fərqli dillərdə faydalanır, və birinin aşağı yüksək işin ə asanlaşdırılabilir. Ancaq müəyyən edilən məqsədilə müəyyən edilən məlumatlar üçün müəyyən edilmiş bir neçə modellər müəyyən edilir. Əvvəlcə, mümkün modeller genel domena dilində təhsil edilir, pretraining dili və a şağı-aşağı domena başlatması arasında bir uyğun yaradılır. Bu səbəbdə, müşterilər servisi domeində milyonlarla müzakirçi məlumatlarında BERT modeli göstəririk. Biz CS-BERT'i bir neçə a şağı müşterilər servisi dialoglarında değerləşdiririk, və domenin önlənməsimiz hər ikisinin sıfır sıfır sıfır sıfır sıfır sıfırlarında və həmçin in təcrübələrin yaxşılıqlarında, özlərinə də aşağı ressurs verilənlərin qurmasında faydalı olduğunu göstəririk.", 'ca': "Models de transformadors pré-entrenats a gran escala han demostrat el rendiment d'última generació (SOTA) en una varietat de tasques del NLP. Avui en dia, molts model s pré-entrenats estan disponibles en diferents gusts models i llengües, i poden ser fàcilment adaptats a la tasca avall. However, only a limited number of models are available for dialogue tasks, and in particular, goal-oriented dialogue tasks.  A més, els models de pré-entrenament disponibles són entrenats en llenguatge general de domini, creant un desacord entre el llenguatge de pré-entrenament i el blanqueig de domini avall. En aquesta contribució, presentem CS-BERT, un model BERT pré-entrenat en milions de diàlegs en el domini del servei al client. Evaluam CS-BERT en diverses tasques de diàleg de servei al client en avall, i demostrem que la nostra pré-capacitació en domini és avantatgia comparada amb altres models pré-capacitats en experiments de zero, com també en fines experiments, especialment en un entorn de baix recursos de dades.", 'cs': 'Rozsáhlé modely předtrénovaných transformátorů prokázaly nejmodernější výkon (SOTA) v různých úkolech NLP. V současné době je k dispozici mnoho předem trénovaných modelů v různých příchutích modelů a různých jazycích a lze je snadno přizpůsobit následnému úkolu. Pro úkoly dialogu, a zejména úkoly dialogu orientované na cíl, je však k dispozici pouze omezený počet modelů. Kromě toho jsou dostupné předtrénované modely trénovány na obecný doménový jazyk, což vytváří nesoulad mezi předtrénovacím jazykem a následným spouštěcím jazykem domény. V tomto příspěvku představujeme CS-BERT, model BERT předtrénovaný na miliony dialogů v oblasti zákaznického servisu. Vyhodnocujeme CS-BERT na několika následných úkolech dialogu zákaznického servisu a demonstrujeme, že náš in-domain předtrénink je výhodný ve srovnání s ostatními předtrénovanými modely jak v experimentech s nulovým výstřelem, tak v experimentech s jemným laděním, zejména v nastavení dat s nízkými zdroji.', 'et': 'Suuremahulised eeltreenitud trafo mudelid on näidanud kaasaegset (SOTA) jõudlust mitmesugustes NLP ülesannetes. Tänapäeval on paljud eeltreenitud mudelid saadaval erinevates mudelite maitsetes ja erinevates keeltes ning neid saab hõlpsasti kohandada oma alljärgneva ülesandega. Dialoogiülesannete ja eelkõige eesmärkidele suunatud dialoogiülesannete jaoks on saadaval vaid piiratud arv mudeleid. Lisaks koolitatakse olemasolevaid eelõpetatud mudeleid üldise domeenikeele alal, mis tekitab ebakõla eelõpetamiskeele ja alljärgneva domeenikäivitamise vahel. Käesolevas panuses tutvustame CS-BERT-i, BERT mudelit, mis on eeltreenitud miljonitele klienditeeninduse valdkonnas peetavatele dialoogidele. Hindame CS-BERTi mitmete alltootmisahela klienditeeninduse dialoogiülesannete puhul ja näitame, et meie domeenisisene eeltreening on kasulik võrreldes teiste eeltreenitud mudelitega nii null-shot katsetes kui ka peenhäälestuse katsetes, eriti vähese ressursiga andmeseadmete puhul.', 'fi': 'Laajamittaiset esikoulutetut muuntajamallit ovat osoittaneet huippuluokan (SOTA) suorituskykyä erilaisissa NLP-tehtävissä. Nykyään lukuisia esikoulutettuja malleja on saatavilla eri mallimakuilla ja eri kielillä, ja niitä voidaan helposti mukauttaa omaan loppupään tehtävään. Vuoropuhelutehtäviin ja erityisesti tavoitteellisiin vuoropuhelutehtäviin on kuitenkin käytettävissä vain rajallinen määrä malleja. Lisäksi saatavilla olevat esikoulutetut mallit on koulutettu yleiseen verkkotunnuksen kieleen, mikä luo yhteensopimattomuuden esikoulutuskielen ja loppupään verkkotunnuksen käynnistyksen välillä. Tässä artikkelissa esittelemme CS-BERT-mallin, joka on esikoulutettu miljooniin asiakaspalvelun dialogeihin. Arvioimme CS-BERT:tä useissa jatkotason asiakaspalveludialogitehtävissä ja osoitamme, että sisäinen esikoulutus on edullista muihin esikoulutettuihin malleihin verrattuna sekä nollashot-kokeiluissa että hienosäätökokeissa, erityisesti vähäresurssisessa dataympäristössä.', 'ha': "@ info: whatsthis Daga yanzu, masu yawa masu motsi da aka daɗa su cikin wasu misãlai daban-daban, kuma an iya iya daidaita zuwa aikin mutum na ƙarami. Amma, za'a iya sãmu ƙidãyar masallaci wanda aka ƙayyade wa aikin zauren akwatin bayani, kuma da ƙayyade aikin zauren akwatin bayani masu da aka yi goani. Da wannan, an sanar da misãlai masu motsi da aka ƙayyade shi a cikin harshen ɗamfyuta, ana ƙara wani mai maras daidai a tsakanin harshen mai kiyãwa da launin da ke ƙarƙashin ruwa. In this contribution, we present CS-BERT, a BERT model pretrained on millions of dialogues in the customer service domain.  Tuna ƙaddara wa masu amfani da abincin mazaɓa na mazaɓa na mazaɓa na dabam-dabam, kuma Muke nuna cewa, misalin ayukanmu a cikin-Domin yana da amfani da kuma misãlai masu da aka yi wa zaman sura cikin jarrabo masu yin nufi da kuma a cikin finfinfinfinfinfinfinfinfining, da kuma, cikin tsari na danne-resource data.", 'sk': 'Veliki predtrenirani transformatorski modeli so pokazali najsodobnejšo zmogljivost (SOTA) pri različnih nalogah NLP. Danes so številni predtrenirani modeli na voljo v različnih okusih modelov in različnih jezikih in jih je mogoče enostavno prilagoditi posameznikovi nalogi. Vendar pa je za naloge dialoga na voljo le omejeno število modelov, zlasti za naloge dialoga, usmerjene v cilje. Poleg tega so razpoložljivi predtrenirani modeli usposobljeni na splošnem domenskem jeziku, kar ustvarja neskladje med jezikom predtreniranja in zaganjanjem domenskih omrežij. V tem prispevku predstavljamo CS-BERT, BERT model, ki je predhodno poučen na milijonih dialogih na področju storitev za stranke. CS-BERT ocenjujemo pri več nalogah dialoga za storitve strankam na koncu verige in dokazujemo, da je naše domensko predusposabljanje koristno v primerjavi z drugimi predusposabljenimi modeli tako v poskusih brez strela kot tudi v poskusih finega nastavitve, zlasti v nastavitvi podatkov z nizkimi viri.', 'he': 'מודלים של משתנים מראש מיומנים גדולים הראו ביצועים מוקדמים (SOTA) במגוון של משימות NLP. כיום, דוגמנים רבים מתאמנים מראש זמינים בטעמים דוגמנים שונים ושפות שונות, ויכולים להתאים בקלות למשימה האחרונה. עם זאת, רק מספר מודלים מוגבל זמינים למשימות דיאלוג, ובמיוחד למשימות דיאלוג ממוקדות למטרה. בנוסף, הדוגמנים הנוכחים מתאמנים על שפת תחום כללית, יוצרים אי-התאמה בין שפת תחום האימון ולשפת תחום האימון. בתרומה הזו, אנחנו מציגים CS-BERT, מודל BERT מתאמן מראש על מיליוני דיאלוגים בתחום שירות הלקוחות. אנו מעריכים CS-BERT על מספר משימות דיאלוג שירות לקוחות למטה, ולהראות שהשימוש מראש בתחום שלנו הוא יתרון בהשוואה לדוגמאות מראש מאימון אחרות שני ניסויים אפס כמו גם בניסויים מתאימים, במיוחד בסיס מידע נמוך משאבים.', 'jv': 'Laptop" and "Desktop Ngawih, akeh model sing paling-paling yang sampeyan nèng model lagi pangutung karo tindan sampeyan, lan iso diandelah sampeyan ngono nggo sampeyan akeh dhéwé. politenessoffpolite"), and when there is a change ("assertivepoliteness In Addition, the available presspied modes are cured on General domain language, create a mismatch amongst the pressping language and the downtream domain lanuage. Nanging perusahaan iki, kita sampeyan CS-BERT, model BERT seneng dipunangkamu milion karo dialog kanggo ngilangno dolanan ping kabian We assess CS-BERT on a number downtream service dialog tasks, and show that we in-domain presining is benevolent', 'bo': 'Large-scale pretrained transformer models have demonstrated state-of-the-art (SOTA) performance in a variety of NLP tasks. ད་ལྟ་བུའི་མཐོང་སྣང་མང་པོ་ཞིག་ཡོད་པའི་མིག་དཔེ་དབྱིབས་དང་སྐད་རིགས་མི་འདྲ་བའི་ནང་དུ་སྤྱོད་ཐུབ། ཡིན་ནའང་མིན་པར། མིག་དཔེ་གཏོང་གི་མིག་དཔེ་གཏོང In addition, the available pretrained models are trained on general domain language, creating a mismatch between the pretraining language and the downstream domain launguage. In this contribution, we present CS-BERT, a BERT model pretrained on millions of dialogues in the customer service domain. We evaluate CS-BERT on several downstream customer service dialog tasks, and demonstrate that our in-domain pretraining is advantageous compared to other pretrained models in both zero-shot experiments as well as in finetuning experiments, especially in a low-resource data setting.'}
{'en': 'PLATO-KAG : Unsupervised Knowledge-Grounded Conversation via Joint Modeling', 'ar': 'PLATO-KAG: محادثة معرفية غير خاضعة للرقابة من خلال النمذجة المشتركة', 'pt': 'PLATO-KAG: conversação fundamentada no conhecimento não supervisionada por meio de modelagem conjunta', 'es': 'PLATO-KAG: Conversación no supervisada basada en el conocimiento a través del modelado conjunto', 'fr': 'PLATO-KAG\xa0: Conversation non supervisée fondée sur les connaissances via la modélisation conjointe', 'ja': 'PLATO - KAG ：ジョイントモデリングを介した監督されていない知識に基づく会話', 'zh': 'PLATO-KAG曰:合建模而无监也', 'ru': 'PLATO-KAG: Неконтролируемая наукоемкая беседа с помощью совместного моделирования', 'hi': 'प्लेटो-KAG: संयुक्त मॉडलिंग के माध्यम से असुरक्षित ज्ञान-आधारित वार्तालाप', 'ga': 'PLATO-KAG: Comhrá Bunaithe ar an Eolas gan Maoirseacht trí Chomhshamhaltú', 'ka': 'PLATO-KAG', 'el': 'PLATO-KAG: Μη εποπτευόμενη συζήτηση βασισμένη στη γνώση μέσω κοινής μοντελοποίησης', 'hu': 'PLATO-KAG: Felügyeletlen tudásalapú beszélgetés közös modellezéssel', 'it': 'PLATO-KAG: Conversazione basata sulla conoscenza non sorvegliata tramite la modellazione congiunta', 'kk': 'PLATO', 'lt': 'PLATO-KAG: Neprižiūrima žiniomis grindžiama konversija taikant bendrą modeliavimą', 'mk': 'ПЛАТО-КАГ: Ненадгледувана конверзија врз основа на знаење преку заедничко моделирање', 'ml': 'പ്ലാറ്റോ- കേഗ്: ജ്ഞാനം- ഗ്രൌണ്ടേഷന്\u200d സംസാരിക്കാത്ത ജ്ഞാനം', 'mt': 'PLATO-KAG: Konverżjoni mhux sorveljata bbażata fuq l-Għarfien permezz ta’ Mudellar Konġunt', 'mn': 'PLATO-KAG: Холбоотой загварын аргаар дэмжигдэхгүй мэдлэг-хөндлөн ярилцлага', 'no': 'PLATO', 'pl': 'PLATO-KAG: Niekontrolowana rozmowa oparta na wiedzy poprzez wspólne modelowanie', 'ro': 'PLATO-KAG: Conversație bazată pe cunoaștere nesupravegheată prin modelare comună', 'sr': 'PLATO-KAG: Neodređen razgovor o znanju pod podrškom zajedničkog modela', 'si': 'PlaATO-KAG: සමාන්ත මොඩලින් විදියට සම්බන්ධ නැති දැනගන්න', 'ms': 'Constellation name (optional)', 'so': 'PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling', 'sv': 'PLATO-KAG: Icke övervakad kunskapsbaserad konversation via gemensam modellering', 'ta': 'பிலாடோ- கேக்: இணைப்பு மாதிரிதல் மூலம் பரிசோதிக்கப்படவில்லை', 'ur': 'PLATO-KAG: مشترک موڈلینگ کے ذریعہ غیر قابل تحقیق کی علم-Grounded گفتگو', 'uz': 'Name', 'vi': 'PLTO-KAG: chưa giám sát cuộc đối thoại bằng dạng phổ biến', 'bg': 'Плато-КАГ: Неконтролиран разговор, основан на знание чрез съвместно моделиране', 'da': 'PLATO-KAG: Uovervåget vidensbaseret samtale via fælles modellering', 'hr': 'PLATO-KAG: Neodređen razgovor o znanju pod područjem zajedničkog modela', 'nl': 'PLATO-KAG: Onbegeleid kennisgebaseerd gesprek via gezamenlijke modellering', 'id': 'PLATO-KAG: Perbualan tanpa pengawasan berdasarkan pengetahuan melalui Modeling Berkongsi', 'de': 'PLATO-KAG: Unbeaufsichtigtes wissensbasiertes Gespräch über Joint Modeling', 'ko': '플라톤 카그: 연합 모델링을 통해 지식 기반의 무감독 대화를 진행한다', 'sw': 'PLATO-KAG: Mazungumzo yasiyoangaliwa na maarifa yaliyosababishwa kupitia Utawala wa pamoja', 'tr': 'PLATO-KAG', 'fa': 'PLATO', 'sq': 'PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling', 'af': 'PLATO-KAG: Onondersteunde kennis-groundeerde gesprek deur Gesameleid Modelering', 'am': 'PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling', 'hy': 'Պլատո-ԿԱԳ. Գիտության հիմնված անվերահսկվող հաղորդակցման միջոցով', 'az': 'PLATO', 'bs': 'PLATO-KAG: Neodređen razgovor o znanju pod područjem zajedničkog modela', 'ca': 'PLATO-KAG: Conversació sense supervisió basada en el coneixement a través del Modell Conjunt', 'cs': 'PLATO-KAG: nekontrolovaná konverzace založená na znalostech prostřednictvím společného modelování', 'bn': 'প্ল্যাটো- কেগ: যুক্ত মডেলিং মাধ্যমে অনভার করা জ্ঞান-গ্রাউন্ডের সংক্রান্ত আলোচনা', 'fi': 'PLATO-KAG: Valvonnaton tietopohjainen keskustelu yhteismallinnuksen avulla', 'et': 'PLATO-KAG: Järelevalveta teadmistepõhine vestlus ühismodelleerimise kaudu', 'jv': 'PLATO-KAG: Gak Cocok Bilge-Gruundd conversations Ngawe Joint model', 'ha': 'KCharselect unicode block name', 'sk': 'PLATO-KAG: Nenadzorovan pogovor na znanju temelječ prek skupnega modeliranja', 'he': 'PLATO-KAG: שיחה ללא פיקוח מבוססת ידע באמצעות מודל משותף', 'bo': 'PLATO-KAG:རྒྱུན་སྒྲིག་མེད་པའི་ཤེས་ཡུལ་གྱི་སྡོམ་གླེང་སྒྲོམ་ནང་དུ་མཐུན་མཐུན་རྣམ་པ'}
{'en': 'Large-scale conversation models are turning to leveraging ', 'ar': 'تتجه نماذج المحادثة واسعة النطاق إلى الاستفادة من المعرفة الخارجية لتحسين الدقة الواقعية في توليد الاستجابة. بالنظر إلى عدم جدوى شرح المعرفة الخارجية للمؤسسات الحوارية واسعة النطاق ، فمن المستحسن تعلم اختيار المعرفة وتوليد الاستجابة بطريقة غير خاضعة للإشراف. في هذه الورقة ، نقترح PLATO-KAG (الجيل المعزز بالمعرفة) ، وهو نهج تعليمي غير خاضع للإشراف لنمذجة محادثة معرفية شاملة. بالنسبة لكل سياق حوار ، يتم اختيار عناصر المعرفة ذات الصلة من فئة top k ثم توظيفها في توليد الاستجابة القائمة على المعرفة. تم تحسين عنصري اختيار المعرفة وتوليد الاستجابة بشكل مشترك وفعال تحت هدف متوازن. تؤكد النتائج التجريبية على مجموعتي بيانات متاحتين للجمهور تفوق PLATO-KAG.', 'fr': "Les modèles de conversation à grande échelle se tournent vers l'exploitation de connaissances externes pour améliorer la précision factuelle dans la génération de réponses. Compte tenu de l'impossibilité d'annoter les connaissances externes pour des corpus de dialogue à grande échelle, il est souhaitable d'apprendre la sélection des connaissances et la génération de réponses de manière non supervisée. Dans cet article, nous proposons PLATO-KAG (Knowledge-Augmented Generation), une approche d'apprentissage non supervisée pour la modélisation de conversations fondées sur les connaissances de bout en bout. Pour chaque contexte de dialogue, les k principaux éléments de connaissances pertinents sont sélectionnés puis utilisés dans la génération de réponses fondées sur les connaissances. Les deux composantes de la sélection des connaissances et de la génération de réponses sont optimisées conjointement et efficacement dans le cadre d'un objectif équilibré. Les résultats expérimentaux sur deux ensembles de données accessibles au public confirment la supériorité de PLATO-KAG.", 'es': 'Los modelos de conversación a gran escala están recurriendo al aprovechamiento del conocimiento externo para mejorar la precisión de los hechos en la generación de respuestas. Teniendo en cuenta la inviabilidad de anotar el conocimiento externo para los cuerpos de diálogo a gran escala, es deseable aprender la selección de conocimiento y la generación de respuestas de manera no supervisada. En este artículo, proponemos PLATO-KAG (Generación aumentada de conocimiento), un enfoque de aprendizaje sin supervisión para el modelado de conversaciones basado en el conocimiento de principio a fin. Para cada contexto de diálogo, se seleccionan los k principales elementos de conocimiento relevantes y luego se emplean en la generación de respuestas basadas en el conocimiento. Los dos componentes de la selección de conocimiento y la generación de respuestas se optimizan conjunta y eficazmente bajo un objetivo equilibrado. Los resultados experimentales en dos conjuntos de datos disponibles públicamente validan la superioridad de PLATO-KAG.', 'pt': 'Modelos de conversação em larga escala estão se voltando para alavancar o conhecimento externo para melhorar a precisão factual na geração de respostas. Considerando a inviabilidade de anotar o conhecimento externo para corpora de diálogo em larga escala, é desejável aprender a seleção de conhecimento e geração de resposta de forma não supervisionada. Neste artigo, propomos PLATO-KAG (Knowledge-Augmented Generation), uma abordagem de aprendizado não supervisionado para modelagem de conversação baseada em conhecimento de ponta a ponta. Para cada contexto de diálogo, os principais elementos de conhecimento relevantes são selecionados e então empregados na geração de respostas fundamentadas no conhecimento. Os dois componentes de seleção de conhecimento e geração de resposta são otimizados conjunta e efetivamente sob um objetivo equilibrado. Resultados experimentais em dois conjuntos de dados disponíveis publicamente validam a superioridade do PLATO-KAG.', 'ja': '大規模な会話モデルは、応答生成の事実精度を向上させるために外部知識を活用することに変わりつつある。大規模な対話体の外部知識に注釈を付けることは不可能であることを考慮すると、知識選択と応答生成を監督されていない方法で学習することが望ましい。本稿では，エンドツーエンドの知識基盤型会話モデリングのための教師なし学習アプローチであるPLATO - KAG （ Knowledge - Augmented Generation ）を提案する．各対話コンテキストについて、トップkの関連知識要素が選択され、知識に基づいた応答生成に採用される。知識選択と応答生成の2つの要素は、バランスの取れた目標の下で共同で効果的に最適化されています。２つの一般に入手可能なデータセットの実験結果は、ＰＬＡＴＯ － ＫＡＧの優位性を検証する。', 'zh': '大言模形方转用外知以应生成之实准确性。 念对外部注以大对语料库不可行,宜以无监学应之。 本文PLATO-KAG(增生),所以端到端对建模无监学也。 凡对上下文,择前 k 相关元素,然后施于应生。 知与反生组成部分平衡共得优化。 两公数集实验验PLATO-KAG之优越性。', 'ru': 'Крупномасштабные модели общения переходят к использованию внешних знаний для повышения фактической точности при генерации ответов. Учитывая нецелесообразность аннотирования внешних знаний для крупномасштабных диалоговых структур, желательно изучать процесс отбора знаний и генерирования ответов в неконтролируемом порядке. В этой статье мы предлагаем PLATO-KAG (Поколение, дополненное знаниями), неконтролируемый подход к обучению для сквозного моделирования разговора, основанного на знаниях. Для каждого контекста диалога выбираются наиболее важные элементы знаний, которые затем используются при выработке основанных на знаниях ответных мер. Два компонента отбора знаний и генерирования ответов оптимизируются совместно и эффективно в рамках сбалансированной цели. Экспериментальные результаты по двум общедоступным наборам данных подтверждают превосходство PLATO-KAG.', 'hi': 'बड़े पैमाने पर वार्तालाप मॉडल प्रतिक्रिया पीढ़ी में तथ्यात्मक सटीकता में सुधार करने के लिए बाहरी ज्ञान का लाभ उठाने के लिए बदल रहे हैं। बड़े पैमाने पर संवाद निगम के लिए बाहरी ज्ञान को एनोटेट करने की अव्यवहार्यता को ध्यान में रखते हुए, ज्ञान चयन और प्रतिक्रिया पीढ़ी को एक असुरक्षित तरीके से सीखना वांछनीय है। इस पेपर में, हम प्लेटो-केएजी (नॉलेज-संवर्धित पीढ़ी) का प्रस्ताव करते हैं, जो एंड-टू-एंड नॉलेज-ग्राउंडेड वार्तालाप मॉडलिंग के लिए एक असुरक्षित सीखने का दृष्टिकोण है। प्रत्येक संवाद संदर्भ के लिए, शीर्ष-कश्मीर प्रासंगिक ज्ञान तत्वों का चयन किया जाता है और फिर ज्ञान-आधारित प्रतिक्रिया पीढ़ी में नियोजित किया जाता है। ज्ञान चयन और प्रतिक्रिया पीढ़ी के दो घटकों को एक संतुलित उद्देश्य के तहत संयुक्त रूप से और प्रभावी ढंग से अनुकूलित किया जाता है। दो सार्वजनिक रूप से उपलब्ध डेटासेट पर प्रयोगात्मक परिणाम प्लेटो-केएजी की श्रेष्ठता को मान्य करते हैं।', 'ga': 'Tá samhlacha comhrá ar scála mór ag casadh ar eolas seachtrach a ghiaráil chun cruinneas fíorasach a fheabhsú i nginiúint freagartha. I bhfianaise a neamhfhéidearthachta an t-eolas seachtrach a anótáil le haghaidh corpóra comhphlé ar mhórscála, is inmhianaithe roghnú an eolais agus giniúint freagartha a fhoghlaim ar bhealach gan mhaoirseacht. Sa pháipéar seo, molaimid PLATO-KAG (Giniúint Mhéadaithe Eolais), cur chuige foghlama gan mhaoirseacht le haghaidh samhaltú comhrá eolasbhunaithe ó cheann ceann go ceann. Maidir le gach comhthéacs idirphlé, roghnaítear na heilimintí ábhartha barr-k eolais agus ansin baintear úsáid astu i nginiúint freagraí eolasbhunaithe. Déantar an dá chomhpháirt de roghnú eolais agus giniúint freagartha a optamú go comhpháirteach agus go héifeachtach faoi chuspóir cothromaithe. Déanann torthaí turgnamhacha ar dhá thacar sonraí atá ar fáil go poiblí sármhaitheas PLATO-KAG a bhailíochtú.', 'ka': 'დიდი განსაკუთრების მოდელები გადავიწყებენ გარეშე ცნობილებისთვის, რომ გარეშე განახლებისთვის ფაქტიური წესიერებას უფრო მეტივად. შევხედავთ, რომ გარეშე ცნობიერება დიალოგის კოპორაციისთვის გარეშე ცნობიერება, უნდა ვისწავლოთ ცნობიერება და განახლება განსხვავებას არსხვავებული გზითით. ამ დომენტში, ჩვენ PLATO-KAG (მეცნიერება-ავგმენტირებული პერიონიაცია), უცნობიერებული სწავლების მოწყობილობა დასასრულებელი მეცნიერებების მიზეზით. ყოველ დიალოგის კონტექსტისთვის, ყველაზე მნიშვნელოვანი მეცნიერების ელემენტები მონიშნულია და შემდეგ მომხმარებულია ცნობიერების განახლების ორი კომპონენტები ცნობიერების მონიშნობის და რეაქციის განვითარებას ერთადერთად და ეფექტიურად ბალანსტირებული მიზეზეზეზი. ესპერიმენტიური შედეგი ორი სახელსაწინო მონაცემების მონაცემების შეცდომა PLATO- KAG-ის უფრო მეტი.', 'el': 'Τα μοντέλα συνομιλίας μεγάλης κλίμακας στρέφονται στην αξιοποίηση εξωτερικών γνώσεων για τη βελτίωση της πραγματικής ακρίβειας στη δημιουργία απόκρισης. Λαμβάνοντας υπόψη την αδυναμία σχολιασμού της εξωτερικής γνώσης για μεγάλα σώματα διαλόγου, είναι επιθυμητό να μάθουμε την επιλογή γνώσης και τη δημιουργία απόκρισης χωρίς επίβλεψη. Στην παρούσα εργασία, προτείνουμε μια προσέγγιση μάθησης χωρίς επίβλεψη για μοντελοποίηση συνομιλίας βασισμένης στη γνώση. Για κάθε πλαίσιο διαλόγου, επιλέγονται τα σχετικά στοιχεία γνώσης κορυφής-k και στη συνέχεια χρησιμοποιούνται για τη δημιουργία απόκρισης βασισμένης στη γνώση. Τα δύο συστατικά της επιλογής γνώσεων και της δημιουργίας απόκρισης βελτιστοποιούνται από κοινού και αποτελεσματικά υπό έναν ισορροπημένο στόχο. Πειραματικά αποτελέσματα σε δύο δημόσια διαθέσιμα σύνολα δεδομένων επικυρώνουν την υπεροχή του PLATO-KAG.', 'hu': 'A nagyszabású beszélgetési modellek a külső ismeretek kihasználására fordulnak, hogy javítsák a válaszkészítés tényleges pontosságát. Tekintettel arra, hogy a nagyszabású párbeszédkorpuszok külső tudásának jegyzetelésének lehetetlenségére, kívánatos felügyelet nélkül megtanulni a tudás kiválasztását és a válasz generálását. Jelen tanulmányban javasoljuk a PLATO-KAG (Knowledge-Augmented Generation), egy felügyelet nélküli tanulási megközelítést a end-to-end tudásalapú beszélgetések modellezéséhez. Minden párbeszéd kontextusában a top k releváns tudáselemeket választják ki, majd alkalmazzák a tudásalapú válasz generálásában. A tudás kiválasztásának és a válasz generálásának két összetevője együttesen és hatékonyan optimalizálódik egy kiegyensúlyozott célkitűzés mellett. Két nyilvánosan elérhető adathalmaz kísérleti eredményei igazolják a PLATO-KAG felsőbbrendűségét.', 'it': "I modelli di conversazione su larga scala stanno sfruttando le conoscenze esterne per migliorare l'accuratezza fattuale nella generazione delle risposte. Considerata l'impossibilità di annotare la conoscenza esterna per corpora di dialogo su larga scala, è auspicabile imparare la selezione della conoscenza e la generazione della risposta in modo non supervisionato. In questo articolo, proponiamo PLATO-KAG (Knowledge-Augmented Generation), un approccio di apprendimento non supervisionato per la modellazione end-to-end della conversazione basata sulla conoscenza. Per ogni contesto di dialogo, gli elementi di conoscenza rilevanti top-k vengono selezionati e poi impiegati nella generazione di risposte basate sulla conoscenza. Le due componenti della selezione della conoscenza e della generazione della risposta sono ottimizzate congiuntamente ed efficacemente in base a un obiettivo equilibrato. I risultati sperimentali su due set di dati disponibili pubblicamente confermano la superiorità di PLATO-KAG.", 'kk': 'Үлкен масштабтау үлгілері сыртқы білімдерді жауап беру үшін шындық дұрыстығын жасау үшін өзгертіп тұрады. Шығыс мәліметті үлкен диалог корпорасы үлкен мәліметті белгілеу мүмкіндігін қарастырып, білім таңдау мен жауап жасау арқылы білмейді. Бұл қағазда, біз PLATO-KAG (білім көтерілген жалғастыру) дегенді, білім көтерілген мәліметтердің аяқтау тәртібі үшін оқыту тәсілігін таңдаймыз. Әрбір диалог контексті үшін жоғарғы мәлімет элементтері таңдалып, кейін білім негізінде жауап беру үшін қолданылады. Білім таңдау мен жауап жасау компоненттерінің екі компоненті біріктірілген мақсаттың астында оптимизацияланды. Екі жалпы деректер қорларының эксперименталдық нәтижелері PLATO- KAG- ның жоғарығын тексеру.', 'lt': 'Didelio masto pokalbių modeliai keičiasi į išorės žinių panaudojimą siekiant pagerinti faktinį atsako generavimo tikslumą. Atsižvelgiant į tai, kad didelio masto dialogo korpora išorės žinios gali būti užfiksuotos, pageidautina nepastebimai išmokti žinių atrankos ir atsako generavimo. Šiame dokumente siūlome PLATO-KAG (žiniomis pagrįsta karta), neprižiūrėtą mokymosi metodą, skirtą mokymosi modeliavimui, grindžiamam žiniomis. Kiekviename dialogo kontekste atrinkti svarbiausi k žinių elementai, o vėliau naudojami žiniomis pagrįstų atsakų k ūrimui. Dvi žinių atrankos ir atsako sukūrimo sudedamosios dalys optimizuojamos kartu ir veiksmingai siekiant subalansuoto tikslo. Dviejų viešai prieinamų duomenų rinkinių eksperimentiniai rezultatai patvirtina PLATO-KAG viršenybę.', 'ms': 'Large-scale conversation models are turning to leveraging external knowledge to improve the factual accuracy in response generation.  Mengingat kebolehan untuk anotasi pengetahuan luaran untuk korpra dialog skala besar, ia diinginkan untuk belajar pemilihan pengetahuan dan generasi balas secara tidak diawasi. Dalam kertas ini, kami melamar PLATO-KAG (Generasi Pengetahuan-Pengetahuan), pendekatan pembelajaran tidak diawasi untuk pemodelan perbualan berdasarkan pengetahuan akhir-akhir. Untuk setiap konteks dialog, unsur pengetahuan berkaitan top-k dipilih dan kemudian digunakan dalam generasi balas berdasarkan pengetahuan. Dua komponen pemilihan pengetahuan dan generasi balas ditentukan bersama-sama dan secara efektif di bawah objek yang seimbang. Keputusan percubaan pada dua set data yang tersedia secara awam sahkan kelebihan PLATO-KAG.', 'mk': 'Моделите на голем разговор се свртат кон искористување на надворешното знаење за подобрување на фактичната точност во генерацијата на одговор. Со оглед на неспособноста да се анотира надворешното знаење за големиот дијалог корпора, е желно да се научи избор на знаење и генерација на одговор на ненадгледуван начин. In this paper, we propose PLATO-KAG (Knowledge-Augmented Generation), an unsupervised learning approach for end-to-end knowledge-grounded conversation modeling.  За секој контекст на дијалогот, се избрани и потоа се користат елементите на најважно знаење на генерацијата на одговор на основа на знаење. Двете компоненти на селекцијата на знаење и генерацијата на одговор се оптимизирани заедно и ефикасно под балансирана цел. Експерименталните резултати на двата јавно достапни податоци ја потврдуваат супериорноста на ПЛАТО-КАГ.', 'ml': 'വലിയ സംസാര മോഡലുകള്\u200d പുറത്തുള്ള അറിവുകള്\u200d കൊടുക്കുന്നതിലേക്ക് തിരിച്ചുവരുന്നു. പ്രതികരണ തലമുറതലമുറയിലെ യ പുറത്തുള്ള വിവരങ്ങളുടെ പുറത്തുള്ള അറിവ് കോര്\u200dപ്പോരിയ്ക്കുള്ള അസാധ്യതയെക്കുറിച്ച് ബോധ്യപ്പെടുത്തുന്നതിനാല്\u200d, അറിവ് തെരഞ്ഞെടു ഈ പത്രത്തില്\u200d നമ്മള്\u200d പ്ലാറ്റോ-കാഗ് (അറിവ്-ഓഗ്മെന്റ് ജനാനത്തിന്\u200dറെ) പ്രൊദ്ദേശിക്കുന്നു. പരിജ്ഞാനത്തിന്\u200dറെ അവസാനത്തിലേക്ക് മാത് ഓരോ ഡയലോഗിന്റെയും കൂട്ടത്തിനും മുകളില്\u200d പ്രധാനപ്പെട്ട അറിവുകളുടെ മൂലകങ്ങള്\u200d തെരഞ്ഞെടുക്കപ്പെടുന്നു. പിന The two components of knowledge selection and response generation are optimized jointly and effectively under a balanced objective.  പ്ലാറ്റോ- കെയാഗിന്റെ മേല്\u200dനോട്ടത്തിന്റെ രണ്ട് പൊതുവില്\u200d ലഭ്യമായ ഡാറ്റാസറ്റുകളുടെ പരീക്ഷണ ഫലങ്ങള്\u200d തെ', 'mn': 'Том хэмжээний үеийн загварууд хариу үйлдвэрлэлийн үнэн зөв байдлыг сайжруулахын тулд гадаад мэдлэгийг ашиглаж байна. Ихэнх хэмжээний диалог корпоратын гадаад мэдлэгийг илэрхийлж чадахгүй байх нь мэдлэг сонголтыг болон хариу үйлдлийн үр дүнг сурах нь хүсэлтэй. Энэ цаасан дээр бид ПЛАТО-KAG (Мэдлэг-Өнгөрсөн Нийтлэл), мэдлэг-төгсгөл мэдлэг-төгсгөл ярианы загварын төгсгөлд суралцах боломжгүй арга зам санал өгдөг. Диалог бүрт хамааралтай мэдлэгтэй элементүүд сонгогдож, дараа нь мэдлэгтэй хариу үйлдэлд ажилладаг. Мэдлэгийн сонголт болон хариу үйлдвэрлэлийн хоёр хэсэг нь баланслагдсан зорилго доор хамтдаа, эффективно сайжруулагддаг. Хоёр олон нийтэд ашиглах өгөгдлийн сангийн туршилтын үр дүнг PLATO-KAG-ын өндөр байдлыг шалгана.', 'no': 'Stor skala samtalemodeller gjer til å levera eksterne kunnskap for å forbedra faktisk nøyaktighet i opprettinga av svar. Dette er ønskjelig å lære kunnskapselen og svargenerasjonen på ein ukjend måte ved å oppmerke den eksterne kunnskapselen for storskala dialogkorpora. I denne papiret foreslår vi PLATO-KAG (kunnskap-augmentert generasjon), eit ukjend læringstilnærming for å modellera konnskap-basert med slutt til slutt. For kvar dialog-kontekst vert dei øvste tilhøyrande kunnskapeelementa valde og så arbeida i opprettinga av kunnskapegrunnsfarga svar. Dei to komponentane av utvalet av kunnskap og opprettinga av svar er optimaliserte saman og effektivt under ein balansert mål. Eksperimentale resultat på to tilgjengelege datasett er validert over PLATO- KAG.', 'mt': 'Il-mudelli ta’ konverżjoni fuq skala kbira qed iduru lejn l-ingranaġġ tal-għarfien estern biex itejbu l-preċiżjoni fattwali fil-ġenerazzjoni tar-rispons. Meta wieħed iqis l-infeżibbiltà li l-għarfien estern jiġi annotat għal korpra ta’ djalogu fuq skala kbira, huwa mixtieq li wieħed jitgħallem l-għażla tal-għarfien u l-ġenerazzjoni tar-rispons b’mod mhux sorveljat. In this paper, we propose PLATO-KAG (Knowledge-Augmented Generation), an unsupervised learning approach for end-to-end knowledge-grounded conversation modeling.  Għal kull kuntest ta’ djalogu, jintgħażlu l-elementi ta’ għarfien rilevanti l-aktar importanti u mbagħad jintużaw fil-ġenerazzjoni ta’ rispons ibbażat fuq l-għarfien. Iż-żewġ komponenti tal-għa żla tal-għarfien u l-ġenerazzjoni tar-rispons huma ottimizzati b’mod konġunt u effettiv taħt objettiv ibbilanċjat. Riżultati sperimentali fuq żewġ settijiet ta’ dejta disponibbli għall-pubbliku jivvalidaw is-superjorità tal-PLATO-KAG.', 'pl': 'Duże modele konwersacji zwracają się na wykorzystanie zewnętrznej wiedzy w celu poprawy dokładności faktycznej w generowaniu odpowiedzi. Biorąc pod uwagę niemożliwość adnotacji wiedzy zewnętrznej dla dużych korpusów dialogowych, pożądane jest, aby nauczyć się doboru wiedzy i generowania odpowiedzi w sposób bez nadzoru. W niniejszym artykule proponujemy PLATO-KAG (Knowledge-Augmented Generation), podejście do nauki bez nadzoru do kompleksowego modelowania konwersacji opartej na wiedzy. Dla każdego kontekstu dialogu wybierane są istotne elementy wiedzy, a następnie wykorzystywane do generowania odpowiedzi opartej na wiedzy. Dwa elementy selekcji wiedzy i generowania reakcji są optymalizowane wspólnie i skutecznie w ramach zrównoważonego celu. Wyniki eksperymentalne na dwóch publicznie dostępnych zbiorach danych potwierdzają wyższość PLATO-KAG.', 'sr': 'Veliki razgovorni modeli se pretvaraju u uticaj vanjskih znanja kako bi poboljšali činjeničnu tačnost u generaciji odgovora. S obzirom na nedovoljnost annotacije vanjskih znanja za veliku dijalogsku korporu, poželjno je naučiti izbor znanja i generaciju odgovora na neodređen način. U ovom papiru predlažemo PLATO-KAG (generacija povećana znanja), neodređen pristup učenja za modeliranje razgovora na temelju kraja do kraja znanja. Za svaki kontekst dijaloga, najvažniji znanstveni elementi su izabrani i posluženi u generaciji odgovora na temelju znanja. Dva komponenta selekcije znanja i generacije odgovora su optimizirana zajednički i efikasno pod ravnoteženim ciljem. Eksperimentalni rezultati na dve javno dostupne podatke potvrđuju nadvišenost PLATO-KAG-a.', 'ro': 'Modelele de conversație la scară largă se îndreaptă spre valorificarea cunoștințelor externe pentru a îmbunătăți acuratețea faptelor în generarea de răspunsuri. Având în vedere imposibilitatea de a adnota cunoștințele externe pentru corporele de dialog la scară largă, este de dorit să se învețe selecția cunoștințelor și generarea de răspunsuri într-o manieră nesupravegheată. În această lucrare, propunem PLATO-KAG (Knowledge-Augmented Generation), o abordare de învățare nesupravegheată pentru modelarea conversațiilor bazate pe cunoaștere end-to-end. Pentru fiecare context de dialog, elementele de cunoaștere relevante top-k sunt selectate și apoi utilizate în generarea de răspunsuri bazate pe cunoaștere. Cele două componente ale selecției cunoștințelor și generării de răspuns sunt optimizate în comun și eficient în cadrul unui obiectiv echilibrat. Rezultatele experimentale pe două seturi de date disponibile publicului validează superioritatea PLATO-KAG.', 'si': 'ලොකු ස්කේල් කතා කරණාකරණ මොඩේල්ස් ප්\u200dරතික්\u200dරියාවට ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විශේෂයෙ ලොකු සංවාද කොර්පෝරාව සඳහා පුරුද්ගලික දැනගන්න පුළුවන් අවස්ථාවක් ගැන බලන්න, ඒක අවශ්\u200dය විදියට දැනගන්න සහ ප්\u200dරත මේ පත්තරයේදී, අපි ප්ලාටෝක් KAG (දැනගන්න-විශාල විශාල ප්\u200dරමාණයක්), අන්තිම දැනගන්න ප්\u200dරමාණයක් සඳහා අන්තිම දැනගන්න බැර හැම සංවාදය සම්බන්ධයෙන්, උඩ- k සම්බන්ධ දන්න අයිතිය තෝරාගන්නවා ඊට පස්සේ දන්න ප්\u200dරතික්\u200dරියාවක්  දැනගන්න තෝරණය සහ ප්\u200dරතික්\u200dරියාත්මක පරීක්ෂණයේ අංකයක් දෙකක් සම්බන්ධයෙන් සහ සම්බන්ධයෙන් සහ ස ප්\u200dරජාතික දත්ත සැටි දෙකට තියෙන්න පුළුවන් පරීක්ෂණ ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විද', 'so': 'Tusaalada hadalka oo waaweyn waxay u leeyihiin inay soo diraan aqoonta dibadda si ay u hagaajiyaan saxda runta ah oo ku qoran qarniga jawaabta. Sida loo fiirsado garashada dibadda ee shirkadda dialogue ballaadhan, waxaa haboon inaad barto doorashada aqoonta iyo soo celinta qarniga aqoonta oo aan la ilaalin. Qoraalkan waxaan ka soo jeedaynaa PLATO-KAG (Generation of Knowledge-Augmented), taas oo ah qaab waxbarasho aan la ilaalinayn sameynta sameynta hadalka aqoonta ee ugu dambaysta. Qof kasta oo dialog ah waxaa la doortaa qaybaha aqoonta ee ugu sarreeya, kadibna waxaa lagu shaqeeyaa qarniga jawaabta aqoonta aasaasan. Labada qayb oo ka mid ah doorashada aqoonta iyo qarniga jawaabta waxaa lagu bedelaa wadajir iyo si faa’iido leh oo ku hoos jira goal siman. Imtixaanka waxaa ku qoran labo macluumaad oo caadiga ah oo la heli karo, waxayna xaqiijiyaan maamulka PLATO-KAG.', 'sv': 'Storskaliga konversationsmodeller vänder sig till att utnyttja extern kunskap för att förbättra den faktiska noggrannheten i svarsgenerering. Med tanke på omöjligheten att kommentera den externa kunskapen för storskaliga dialogkorpor är det önskvärt att lära sig kunskapsval och responsgenerering på ett obevakat sätt. I denna uppsats föreslår vi PLATO-KAG (Knowledge-Augmented Generation), en oövervakad inlärningsmetod för end-to-end kunskapsbaserad konversationsmodellering. För varje dialogkontext väljs de toppk relevanta kunskapselementen ut och används sedan i kunskapsbaserad responsgenerering. De två komponenterna i kunskapsval och responsgenerering optimeras gemensamt och effektivt under ett balanserat mål. Experimentella resultat på två allmänt tillgängliga datauppsättningar bekräftar PLATO-KAG:s överlägsenhet.', 'ta': 'பெரிய அளவு பேச்சு மாதிரிகள் வெளி அறிவை வழங்குவதற்கு மாற்றி விடுகிறது பதில் உருவாக்கத்தில் உண்மையான சரிப்பாட பெரிய அளவு உரையாடல் நிறுவனத்திற்கான வெளிப்புறை அறிவை குறிப்பிடுவதற்கான பாதிப்பாக்கும் பொருட்டு, அறிவு தேர்வு மற்றும் பதில் தலைமுற இந்த காகிதத்தில், நாம் பிளாடோ-KAG (அறிவு - கூட்டுதல் உருவாக்கத்திற்கு, முடிவிலிருந்து முடிவு அறிவு அடிப்படையான பேச்சு மாதிரிக்க @ info அறிவு தேர்ந்தெடுப்பு மற்றும் பதில் உருவாக்குதலின் இரண்டு பொருள்கள் ஒன்றாக மேம்படுத்தப்பட்டுள்ளது ஒரு நிறைவ Name', 'ur': 'بڑی مکالمانی موڈل بیرونی علم کو اضافہ کرنے کے لئے پھیر رہے ہیں۔ بڑے اندازے کے باہر علم کے ذریعہ مشورہ کرنے کے لئے غیر قابل تحقیق کرنا چاہتا ہے کہ علم کا انتخاب اور جواب نسل کو بغیر قابل تحقیق کے ساتھ سکھنا چاہتا ہے. اس کاغذ میں ہم PLATO-KAG (علم-Augmented Generation) کی پیشنهاد کرتے ہیں، ایک ناپابندی علم-grounded conversation modeling کے لئے سیکھنے کی طرح۔ ہر قسمت کے متعلق، سب سے زیادہ معاملہ علم عناصر منتخب کیے جاتے ہیں اور پھر علم کی وجہ سے جواب دینے کی نسل میں استعمال کیے جاتے ہیں. علم کے انتخاب اور جواب کی نسل کے دو قسموں کو ایک تعمیر مقررہ مقررہ مقررہ کے نیچے اور عمدہ طور پر optimized کیا جاتا ہے. دو عمومی دسترسی ڈاٹ سٹ پر تجربے کا نتیجہ PLATO- KAG کی زیادتی کی تصدیق کرتا ہے.', 'uz': "Katta taʼminlovchi muloqat modellari natijada aniqlarni qo'yish uchun javob generalida haqiqiqiylikni oshirish uchun. Ko'pchilik muloqat kompaniya uchun tashqi ma'lumotni tashqi qilish haqida o'ylab turib, ilmiy tanlash va javob generasi haqida xavfsiz qilmagan usulda o'rganish kerak. Bu qogʻozda, biz ilmiy taʼminlovchi taʼminot yaratuvchi PLATO KAG (ta'lim taʼminlovchi Generatori) davom etamiz va oxiriga o'rganish muvaffaqiyatsiz tugadi. @ info: whatsthis Faylni tanlash va javob yaratish ikki qismlari birlashtirilgan va effektiv obʼekt bilan ishlatiladi. Name", 'vi': 'Các mô hình cuộc đối thoại rộng lớn đang hướng tới việc vận dụng kiến thức bên ngoài để cải thiện sự chính xác trong hệ thống phản ứng. Dựa vào khả năng không thể xác định được kiến thức bên ngoài cho cuộc đối thoại hoành tráng, bạn nên học thế hệ kiến thức tuyển chọn và hồi đáp theo một cách không giám sát. Trong bài báo này, chúng tôi đề nghị PLTO-KAG (Thế hệ tri thức-tăng lên), một phương pháp học không giám sát để tạo mẫu cuộc đối thoại. Đối với mỗi ngữ cảnh thoại, các yếu tố tri thức liên quan hàng đầu được chọn và sau đó được tuyển dụng trong thế hệ phản ứng dựa trên kiến thức. Hai thành phần của sự chọn kiến thức và sản xuất phản ứng được tối ưu tiên cùng nhau và hiệu quả trong một mục tiêu cân bằng. Kết quả thử nghiệm trên hai bộ dữ liệu công khai xác nhận ưu thế của PLTO-KAG.', 'da': "Store samtalemodeller bruger ekstern viden til at forbedre den faktuelle nøjagtighed i responsgenerering. I betragtning af den manglende evne til at kommentere den eksterne viden til store dialogkorpora, er det ønskeligt at lære vidensudvalg og responsgenerering på en ubevåget måde. I denne artikel foreslår vi PLATO-KAG (Knowledge-Augmented Generation), en uafvåget læringstilgang til end-to-end vidensbaseret samtalemodellering. For hver dialogkontekst udvælges de øverste k relevante videnselementer og anvendes derefter i vidensbaseret responsgenerering. De to komponenter i vidensudvalg og responsgenerering optimeres i fællesskab og effektivt under et afbalanceret mål. Eksperimentelle resultater på to offentligt tilgængelige datasæt bekræfter PLATO-KAG's overlegenhed.", 'hr': 'Veliki razgovorni modeli se pretvaraju u uticaj vanjskih znanja kako bi poboljšali činjeničnu preciznost u generaciji odgovora. S obzirom na nedovoljnost annotiranja vanjskih znanja za veliku dijalogsku korporaciju, poželjno je naučiti izbor znanja i generaciju odgovora na neodređen način. U ovom papiru predlažemo PLATO-KAG (Povećana generacija znanja), neodređeni pristup učenja modelima razgovora na temelju znanja na kraju do kraja. Za svaki kontekst dijaloga, odabrani su najvažniji znanstveni elementi i zatim zaposleni u generaciji odgovora na temelju znanja. Dva komponenta selekcije znanja i generacije odgovora zajednički i učinkovito su optimizirana pod ravnoteženim ciljem. Eksperimentalni rezultati na dvije javno dostupne podatke potvrđuju nadvišenost PLATO-KAG-a.', 'bg': 'Моделите на мащабни разговори се обръщат към използването на външни знания, за да подобрят точността на фактите при генерирането на отговори. Като се има предвид невъзможността да се анотират външните знания за корпуси за широкомащабен диалог, е желателно да се научат подбора на знания и генерирането на реакции без надзор. В настоящата статия предлагаме подход за обучение без надзор за моделиране на разговори, основано на знанието от край до край. За всеки контекст на диалога се избират най-важните елементи на знанието и след това се използват в генерирането на основани на знанието реакции. Двата компонента на подбора на знания и генерирането на реакции са оптимизирани съвместно и ефективно при балансирана цел. Експерименталните резултати на два обществено достъпни набора данни потвърждават превъзходството на PLATO-KAG.', 'de': 'Große Konversationsmodelle nutzen externes Wissen, um die faktische Genauigkeit bei der Antwortgenerierung zu verbessern. In Anbetracht der Unmöglichkeit, das externe Wissen für große Dialogkorpora zu kommentieren, ist es wünschenswert, die Wissensauswahl und die Antwortgenerierung unbeaufsichtigt zu erlernen. In diesem Beitrag schlagen wir PLATO-KAG (Knowledge-Augmented Generation) vor, einen unüberwachten Lernansatz für die durchgängige wissensbasierte Konversationsmodellierung. Für jeden Dialogkontext werden die top-k relevanten Wissenselemente ausgewählt und anschließend in der wissensbasierten Response-Generierung eingesetzt. Die beiden Komponenten Wissensauswahl und Antwortgenerierung werden gemeinsam und effektiv unter einem ausgewogenen Ziel optimiert. Experimentelle Ergebnisse an zwei öffentlich zugänglichen Datensätzen bestätigen die Überlegenheit von PLATO-KAG.', 'id': 'Model percakapan skala besar berubah untuk menggunakan pengetahuan luar untuk meningkatkan akurasi fakta dalam generasi respon. Mengingat ketidakmampuan untuk anotasi pengetahuan eksternal untuk korpra dialog skala besar, diinginkan untuk belajar pemilihan pengetahuan dan generasi respon dengan cara yang tidak diawasi. Dalam kertas ini, kami mengusulkan PLATO-KAG, pendekatan belajar yang tidak diawasi untuk model percakapan berbasis pengetahuan akhir-akhir. Untuk setiap konteks dialog, elemen pengetahuan relevanti top-k dipilih dan kemudian digunakan dalam generasi respon berdasarkan pengetahuan. Dua komponen dari pemilihan pengetahuan dan generasi respon optimisasi bersama-sama dan efektif di bawah tujuan yang seimbang. Hasil percobaan pada dua set data yang tersedia publik menentukan ketinggian PLATO-KAG.', 'nl': "Grootschalige gespreksmodellen gebruiken externe kennis om de feitelijke nauwkeurigheid bij het genereren van responsen te verbeteren. Gezien de onmogelijkheid om externe kennis voor grootschalige dialoogcorpora's te annoteren, is het wenselijk om de kennisselectie en responsgeneratie op een onbeheerde manier te leren. In dit artikel stellen we PLATO-KAG (Knowledge-Augmented Generation) voor, een onbeheerde leerbenadering voor end-to-end kennisgebaseerde conversatiemodellering. Voor elke dialoogcontext worden de top-k relevante kenniselementen geselecteerd en vervolgens ingezet bij kennisgebaseerde responsgeneratie. De twee componenten kennisselectie en responsgeneratie worden gezamenlijk en effectief geoptimaliseerd onder een evenwichtige doelstelling. Experimentele resultaten op twee publiek beschikbare datasets valideren de superioriteit van PLATO-KAG.", 'fa': 'مدلهای مکالمه بزرگ به تأثیر دانش خارجی تبدیل می شوند تا دقیقات حقیقی را در نسل پاسخ بهبود دهند. با توجه به غیر قابل توجه به دانش خارجی برای شرکت گفتگوی بزرگ، برای یاد گرفتن انتخاب دانش و پاسخ به طریق غیرقابل توجه است. در این کاغذ، ما پیشنهاد PLATO-KAG (نسل دانش-افزایش) را پیشنهاد می\u200cکنیم، یک روش آموزش غیرقابل تحقیق برای مدل\u200cسازی مکالمه\u200cهای پایین\u200cپایین دانش\u200cها. برای هر محیط گفتگوی، عناصر علمی بالا-k انتخاب می\u200cشوند و سپس در نسل پاسخ بر زمینه علم استخدام می\u200cشوند. دو بخش انتخاب دانش و نسل پاسخ با هم و موثرت تحت یک هدف مقایسه ترکیب می\u200cشوند. نتیجه\u200cهای تجربه در دو مجموعه داده\u200cهای عمومی موجود است که بالاترین PLATO-KAG را باور می\u200cکند.', 'ko': '대규모 대화 모델은 외부 지식을 활용해 응답 생성의 사실 정확성을 높이는 방향으로 바뀌고 있다.대형 대화 자료 라이브러리에서 외부 지식에 대한 주석을 할 수 없기 때문에 감독이 없는 상황에서 지식 선택과 응답 생성을 배우는 것은 바람직하다.본고에서 우리는 플라톤-KAG(Knowledge Augmented Generation)를 제시했는데 이것은 지식에 기초한 대화 모델링에 사용되는 무감독 학습 방법이다.모든 대화의 언어 환경에 대해 top-k와 관련된 지식 요소를 선택한 다음에 이를 지식을 바탕으로 하는 반응 생성에 사용한다.하나의 균형적인 목표 아래 지식 선택과 응답 생성의 두 구성 부분은 연합하여 효과적으로 최적화된다.두 개의 공개 데이터 집합에서의 실험 결과는 플라톤 카그의 우월성을 검증했다.', 'sq': 'Modelet e bisedës në shkallë të madhe po kthehen në përdorimin e njohurive të jashtme për të përmirësuar saktësinë faktike në gjeneratën e përgjigjes. Duke konsideruar papërshtatshmërinë për të anotuar njohuritë e jashtme për korprën e dialogut në shkallë të madhe, është e dëshirueshme të mësohet zgjedhja e njohurive dhe gjenerata e përgjigjes në një mënyrë të pazgjidhur. Në këtë letër, propozojmë PLATO-KAG, një metodë mësimi pa mbikqyrje për modelimin e bisedimeve të bazuara në njohuri. Për çdo kontekst dialog, elementet e njohurive të rëndësishme top-k zgjedhen dhe pastaj përdoren në gjeneratën e përgjigjes bazuar në njohuri. Të dy komponentet e zgjedhjes së njohurive dhe gjenerimit të përgjigjes janë optimizuar së bashku dhe efektivisht nën një objektiv të balancuar. Rezultatet eksperimentale në dy grupe të dhënash të disponueshme publikisht validojnë superioritetin e PLATO-KAG.', 'sw': 'Mradi wa mazungumzo makubwa unageuka kutumia maarifa ya nje ili kuboresha ukweli wa kweli katika kizazi cha majibu. Considering the infeasibility to annotate the external knowledge for large-scale dialogue corpora, it is desirable to learn the knowledge selection and response generation in an unsupervised manner.  Katika karatasi hii, tunapendekeza PLATO-KAG (Uzazi wa Ujuzi-Augmented), mwelekeo wa kujifunza usio na uhakika wa kutengeneza mazungumzo yenye ufahamu wa mwisho. Kwa kila muktadha wa mazungumzo, vipengele muhimu vya maarifa vya juu vya juu vinachaguliwa na kisha kutumika katika kizazi kinachotumiwa kwa ujuzi. Vifaa viwili vya uchaguzi wa maarifa na kizazi cha majibu vinawezeshwa kwa pamoja na kwa ufanisi chini ya lengo lililofanana. Matokeo ya majaribio yanayotokana na takwimu mbili zinazopatikana hadharani yanathibitisha juu ya PLATO-KAG.', 'af': "Groot-skaal gesprekslykmodele draai om eksterne kennis te verwyder om die faktiese presisie in reaksogensie te verbeter. Aangesien die onverwagtigheid om die eksterne kennis vir groot-skaal dialoog korpora te annoteer, is dit desibaar om die kennis keuse en antwoord generasie te leer op 'n onverwagte manier. In hierdie papier, voorstel ons PLATO-KAG (Knowledge-Augmented Generation), â\x80\x99n onveranderde onderwerp onderwerp toegang vir end-to-end kennis-agtergrond gesprekslykmodeling. Vir elke dialoog-konteks word die top-k relevante kennis-elemente gekies en dan gebruik word in kennis-agtergrondde antwoord generasie. Die twee komponente van kennis keuse en antwoord generasie is saamstig en effektief optimaliseer onder 'n balanseerde doel. Eksperimentale resultate op twee openbaar beskikbaar datastelle geldigheid die hoogheid van PLATO- KAG.", 'am': 'ትልቅ ትልቅ የንግግር ዓይነቶች የውጭ እውቀትን በመስጠት ትክክለኛውን ትውልድ ለማሻል ይዞራሉ፡፡ የውጭው እውቀት ለባሕላዊ አካባቢ ኮርፖር ማሳየት አይቻለውም፣ እውቀትን የመረጥና የመመልስ ትውልድ በተጠበቀው መልዕክት ማወቅ ያስፈልጋል፡፡ In this paper, we propose PLATO-KAG (Knowledge-Augmented Generation), an unsupervised learning approach for end-to-end knowledge-grounded conversation modeling.  ለሁሉም ጥያቄ ጥያቄ፣ ላይኛው-k ተቃውሞ እውቀት አካላት የተመረጠና ከዚያም በኋላ እውቀት-መሠረት በመስጠት ትውልድ ይሠራል፡፡ የእውቀት ምርጫ እና የመልስ ትውልድ ሁለቱ ክፍሎች በአንድነት የተሻሉ እና በተመሳሳይ አካባቢ ውስጥ ጥሩ ናቸው፡፡ የስህተት ውጤቶች በሁለት ህብረት የተገኘ የዳታ መስኮቶች የፕላጦ-KAG ክፍተቱን የሚያረጋግጥ ነው፡፡', 'tr': 'Ullakan çykyş nusgalary çykyş etmek üçin daşarydaky bilim üýtgetmek üçin barýar. Daşarydaky bilimi uly ölçekli dijalog korporaty üçin ýagşyrymyzlygyny düşünýän, bilim saýlamagyny we jogap döretmegini boýunça öwrenmek isleýändir. Bu kagyzda PLATO-KAG (Bilgi-Augmented Generasy), bilim sistemasy taýdan soňra bilmek gabdaly soňra çykmak üçin bilim sistemasyny teklip edýäris. Her dijal konteksti üçin iň üst möhüm bilgi elementleri saýlandyr we soňra bilim sisteminde jogap döredişi. Bilim saýlawynyň we jogap dörediginiň iki bölegi bir beýleki maksadyň altynda optimizalýar. PLATO-KAG nyşanlarynyň üstesini barlaýan iki sany tapylşyr', 'hy': 'Մեծ մասշտաբով խոսակցության մոդելները շրջվում են արտաքին գիտելիքների օգտագործման վրա, որպեսզի բարելավեն պատասխանի սերունդների փաստացի ճշգրտությունը: Եթե հաշվի առնենք մեծ քանակությամբ հաղորդակցվող մարմնի արտաքին գիտելիքները նկարագրելու անհնարավորությունը, ցանկալի է անվերահսկված կերպ սովորել գիտելիքների ընտրությունը և արձագանքը: Այս թղթի մեջ մենք առաջարկում ենք PLATO-KOG (Գիտերի աճեցված սերունդ), անվերահսկված ուսումնական մոտեցում գիտելիքի հիմնված խոսակցության մոդելավորման համար: Յուրաքանչյուր խոսակցության համար ընտրվում են գլխավոր k-ի նշանակալի գիտելիքի տարրերը, հետո օգտագործվում են գիտելիքի հիմնված արձագանքի սերունդում: Գիտելու ընտրության և արձագանքի երկու բաղադրիչները միասին և արդյունավետ են օպտիմացվում հավասարակշռության մեջ: Երկու հանրային հասանելի տվյալների համակարգի փորձարկման արդյունքները հաստատում են PLATO-K-ի գերազանցությունը:', 'az': "Büyük ölçülü müzakirə modelləri reaksiya nəsilində həqiqiliyi yaxşılaşdırmaq üçün dış bilgiləri istifadə edirlər. Böyük ölçüdə diyalət korporası üçün dış bilgi təbliğ etmək mümkün olmadığını düşünürək elm seçilməsini və cavab verəcəyi nəslini tədriclə öyrənmək istəyir. Bu kağızda, PLATO-KAG (Bilim-Yükselmiş nəsil) təklif edirik, bilim-sona qədər təklif edilməyən öyrənmə metodu. Hər dijalog məlumatı üçün ən yüksək məlumatlı bilgi elementləri seçildi və sonra bilgi tərəfindən cavab verəndə istifadə edildi. Bilim seçilməsinin və reaksiya nəslinin iki komponenti birlikdə və müəyyən olunmuş objektif altında optimizlənir. İki halda faydalanır verilən verilənlərin təcrübə sonuçları PLATO-KAG'nin üstünlüyünü təsdiqləyir.", 'bs': 'Veliki razgovorni modeli se pretvaraju u uticaj vanjskih znanja kako bi poboljšali činjeničnu preciznost u generaciji odgovora. S obzirom na nedovoljnost annotiranja vanjskih znanja za veliku dijalogsku korporaciju, poželjno je naučiti izbor znanja i generaciju odgovora na neodređen način. U ovom papiru predlažemo PLATO-KAG (Povećana generacija znanja), neodređeni pristup učenja modelima razgovora na temelju znanja na kraju do kraja. Za svaki kontekst dijaloga, odabrani su najvažniji znanstveni elementi, a zatim su zaposleni u generaciji odgovora na temelju znanja. Dva komponenta selekcije znanja i generacije odgovora su optimizirana zajedno i učinkovito pod ravnoteženim ciljem. Eksperimentalni rezultati na dvije javno dostupne podatke potvrđuju nadvišenost PLATO-KAG-a.', 'cs': 'Rozsáhlé konverzační modely se obrací k využití externích znalostí ke zlepšení faktické přesnosti při generování reakcí. Vzhledem k nemožnosti anotovat externí znalosti pro rozsáhlé dialogové korpusy je žádoucí se naučit výběr znalostí a generování odpovědí bez dohledu. V tomto článku navrhujeme PLATO-KAG (Knowledge-Augmented Generation), přístup bez dozoru pro komplexní modelování konverzací založené na znalostech. Pro každý kontext dialogu jsou vybrány relevantní znalostní prvky top-k a následně použity při generování odpovědí založených na znalostech. Obě složky výběru znalostí a generování reakcí jsou optimalizovány společně a efektivně za vyváženého cíle. Experimentální výsledky na dvou veřejně dostupných datových sadách potvrzují nadřazenost PLATO-KAG.', 'et': 'Laiaulatuslikud vestlusmudelid pöörduvad välisteadmiste kasutamise poole, et parandada reaktsioonide loomise faktilist täpsust. Arvestades, et suuremahuliste dialoogikorpuste väliseid teadmisi ei ole võimalik märkida, on soovitav õppida teadmiste valikut ja reageerimist järelevalveta. Käesolevas töös pakume välja PLATO-KAG (Knowledge-Augmented Generation), järelevalveta õppimise lähenemisviisi lõpuni teadmistepõhiseks vestluse modelleerimiseks. Iga dialoogi konteksti jaoks valitakse välja kõige olulisemad teadmiseelemendid ja kasutatakse seejärel teadmistepõhise reageerimise loomisel. Teadmiste valiku ja reageerimise kaks komponenti optimeeritakse ühiselt ja tõhusalt tasakaalustatud eesmärgi alusel. Kahe avalikult kättesaadava andmekogumi katsetulemused kinnitavad PLATO-KAG paremust.', 'bn': 'ব্যাপক পর্যায়ে আলোচনার মডেল প্রতিক্রিয়া প্রজন্মের বাইরে জ্ঞান বাড়িয়ে দেয়ার জন্য বাইরে যাচ্ছে। বিশাল পর্যায়ের ডায়ালগ কর্পোরার জন্য বাইরের জ্ঞানের বিষয়টি বিস্তারিত বিষয়টি বিবেচনা করার ক্ষেত্রে বিভিন্ন ভাবে এটি জ্ঞান নির্বাচন এব এই পত্রিকায় আমরা প্ল্যাটো-কেজ (জ্ঞান-অগমেন্ট জেনারেশন) প্রস্তাব করি, যা শেষ পর্যন্ত জ্ঞান-ভূমিকা আলোচনার মডেলের জন্য এক অরক্ষিত শিক্ষার প্রত্যেক ডায়ালগের প্রেক্ষাপটের জন্য, সর্বোচ্চ প্রাসঙ্গিক জ্ঞানের উপাদান নির্বাচিত হয় এবং তারপর জ্ঞান-ভিত জ্ঞান নির্বাচন এবং প্রতিক্রিয়া প্রজন্মের দুটি অংশ একত্রিত এবং কার্যকর একটি পরিমাণ উদ্দেশ্যের অধীনে বিশেষ করা হয়। প্ল্যাটো-কেজের উচ্চতার পরীক্ষার ফলাফল বৈধ করা হয়েছে দুটি প্রকাশ্যে বিদ্যমান ডাটাসেটের পরীক্ষার ফলাফল।', 'ca': "Els models de conversació a gran escala s'estan centrant en aprofitar el coneixement extern per millorar la precisió de fet en la generació de resposta. Tenint en compte la infeasibilitat d'anotar el coneixement extern de la corpora de diàleg a gran escala, és desitjable aprendre la selecció del coneixement i la generació de resposta d'una manera no supervisada. En aquest paper, proposem PLATO-KAG (generació augmentata en el coneixement), un enfocament d'aprenentatge sense supervisió per modelar converses basades en el coneixement. Per cada contexte de diàleg, s'seleccionen els elements de coneixement més relevants i després s'utilitzen en la generació de resposta basada en el coneixement. Els dos components de la selecció del coneixement i la generació de resposta estan optimitzats conjuntament i efectivament sota un objectiu equilibrat. Els resultats experimentals de dos conjunts de dades públicament disponibles validen la superioritat del PLATO-KAG.", 'fi': 'Laajamittaiset keskustelumallit pyrkivät hyödyntämään ulkoista tietämystä vastauksen tuottamisen faktatietojen tarkkuuden parantamiseksi. Koska ulkoista tietoa ei ole mahdollista merkitä laajamittaiseen dialogikorporaan, on toivottavaa oppia tiedon valintaa ja vastausten tuottamista valvomattomasti. Tässä työssä ehdotamme PLATO-KAG (Knowledge-Augmented Generation), valvomatonta oppimista kokonaisvaltaiseen tietopohjaiseen keskustelumalliin. Kussakin vuoropuhelukontekstissa valitaan tärkeimmät tietoelementit, joita käytetään tietopohjaiseen vastausten tuottamiseen. Tiedon valinnan ja vastausten tuottamisen kaksi osatekijää optimoidaan yhdessä ja tehokkaasti tasapainoisen tavoitteen mukaisesti. Kokeelliset tulokset kahdesta julkisesti saatavilla olevasta aineistosta vahvistavat PLATO-KAG:n paremmuuden.', 'jv': 'text-tool-action Inga nggunakake kapan kanggo nglanggar ngerasakno ora seneng nggawe barang kelas kanggo ngilanggar nggawe barang dumadhi, ora bisa dianggap kanggo ngerasakno ngerasakno karo dolang langgar kuwi ora bisa apik. Nang pentunggu iki, kita gunakake PLATO-KAG (knowknowknowness-opmented Generation) Sampeyan nganggo dialog sak, nggo langgar-k saiki wis dipileh karo pakem kesempatan lan nguasai nggawe barang langgar-sistem sing ngerasakno Kayiné kabèh sing dipun nggo langgar sampeyan karo akeh mbugal sing luwih apik lan nganggo langgar sampeyan tambahan. Reulti sing paling dhéwé éntuk gawe dataset sing perusahaan tanggal gawe PLATO-KAG.', 'sk': 'Modeli velikega obsega pogovorov se obračajo na izkoriščanje zunanjega znanja za izboljšanje dejanske natančnosti pri ustvarjanju odzivov. Glede na neizvedljivost označevanja zunanjega znanja za obsežne dialogske korpuse je zaželeno, da se izbira znanja in ustvarjanje odzivov naučimo na nenadzorovan način. V prispevku predlagamo PLATO-KAG (Knowledge-Augmented Generation), nenadzorovan učni pristop za modeliranje pogovorov, temelječih na znanju. Za vsak okvir dialoga se izberejo najbolj pomembni elementi znanja in nato uporabijo pri ustvarjanju odzivov na znanju temelječih. Obe komponenti izbire znanja in ustvarjanja odzivov sta skupaj in učinkovito optimizirani v okviru uravnoteženega cilja. Poskusni rezultati dveh javno dostopnih naborov podatkov potrjujejo superiornost PLATO-KAG.', 'ha': "Modellan mazaɓa mai girma sun yi motsi zuwa a samar da ilmi na fita dõmin ya gyãra gaskiyar gaskiyar cikin kizalin ajiya. Aka tunãni, bã ya kasancẽwa ya zartar da ilmi na bakin bayani wa shirin zauren akwatin bayani mai girma, sai yana son ya sanar da zaɓen ilmi da kuma ma'abũcin jawãfi cikin wata tsari wanda ba ya tsare. Ga wannan takardan, Munã buɗar da PLETO-KAG (Mai Sann-Augmented), wata hanyarwa da ba'a tsare ta ba ta tsare wa samun mazaɓa na bakin bayan-zuwa-ƙari. @ action: button An fi fi fifĩfĩta biyu compocompound na zaɓen ilmi da kuma za'a yi amfani da shi gabã ɗaya da mai kyau a cikin wani objecti da za'a daidaita. Imrabai matsala biyu bayani da ake iya amfani da database, yana gaskata mafi kyauta wa PLETO-KAG.", 'bo': 'ཚད་ཆེ་ཤོས་ཀྱི་གཏམ་གླེང་མིག་གཟུགས་རིས་མང་པོ་ཞིག་གིས་ཕྱི་རིག་གནས་ཚུལ་ལ་ཡར་རྒྱས་གཏོང་དང་། ཕྱིར་གྱི་གནས་ཚུལ་མཐོང་སྣང་གི་མཐུད་སྣེ་མཐོང་བའི་གོ་སྐབས་འགའ་བ་ཞིག་ཡིན་པ་ལ་བསམ་གཞིའི་གྲངས་སྒྲིག་དང་མཐུན་སྣང་མེད་པར་སྦྱོར ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་PLATO-KAG(Knowledge-Augmented Generation)ལ་བསམ་འཆར་ཐབས་ལམ་ཞིག་ལ། མ་ཤེས་པའི་གྲངས་སྐོར་དང་མཐར་མཇུག་བསྡད་པའི་སྐད སྒྲུབ་གླེང་མོལ་སོ་སོ་སོ་ལ་ཐོག་ཏུ། མཐོ་རིམ་མཐུན་པའི་ཆ་རྐྱེན་པས་གདམ་པ་དང་དེ་ནས་ཤེས་ཡོད་པའི་རྒྱབ དབྱིན་ཤེས་པའི་ཆ་ཤས་གཉིས་ཀྱིས་གདམ་ཀ་དང་ལན་སྐོར་གྱི་རྒྱལ་ཁབ་གཉིས་ཀྱིས་མཐུན་སྒྲིག སྤྱི་ཚོགས་མང་ཆོས་ཡོད་པའི་གནད་སྡུད་ཚན་གཉིས་ཀྱི་ལས་འཚོལ་གྱི་རྐྱེན་སྟངས་ལ་རྟགས་བཀལ་བྱེད།PLATO-KAG', 'he': 'דוגמני שיחה בקנה מידה גדולה מתחילים להשתמש בידע חיצוני כדי לשפר את מדויקת העובדות בדור התגובה. בהתחשב בנפשרות להציין את הידע החיצוני של גופורה לדיולוג בקנה מידה גדולה, זה רצוי ללמוד את הבחירה של הידע ודור התגובה בדרך ללא השגחה. In this paper, we propose PLATO-KAG (Knowledge-Augmented Generation), an unsupervised learning approach for end-to-end knowledge-grounded conversation modeling.  For each dialogue context, the top-k relevant knowledge elements are selected and then employed in knowledge-grounded response generation.  שני המרכיבים של בחירת הידע ודור התגובה אופטימולים באופן משותף וביעיל תחת מטרה מאוזנת. תוצאות ניסויים על שני קבוצות נתונים זמינות לציבור מאשרות העליון של PLATO-KAG.'}
{'en': 'Personalized Search-based Query Rewrite System for Conversational AI', 'ar': 'نظام إعادة كتابة الاستعلام المخصص القائم على البحث من أجل AI للمحادثة', 'fr': "Système de réécriture de requêtes personnalisé basé sur la recherche pour l'IA conversationnelle", 'es': 'Sistema de reescritura de consultas personalizado basado en búsquedas para IA conversacional', 'pt': 'Sistema de reescrita de consulta personalizado baseado em pesquisa para IA conversacional', 'ja': '会話型AIのためのパーソナライズされた検索ベースのクエリ書き換えシステム', 'hi': 'संवादात्मक AI के लिए वैयक्तिकृत खोज-आधारित क्वेरी पुनर्लेखन सिस्टम', 'zh': '基于搜索之会话AI个性化询重写系统', 'ru': 'Персонализированная поисковая система перезаписи запросов для разговорного ИИ', 'ga': 'Córas Athscríobh Fiosrúcháin Pearsantaithe Cuardaithe le haghaidh AI Comhráite', 'ka': 'პერსონალიზური ძიება დაბათებული კითხვის გადაწერის სისტემა პარაციონალური AI- სთვის', 'hu': 'Személyre szabott keresés-alapú lekérdezés újraírási rendszer a beszélgetési AI számára', 'el': 'Εξατομικευμένο σύστημα επαναγραφής ερωτήματος βασισμένο στην αναζήτηση για τη συνομιλία τεχνητή νοημοσύνη', 'it': 'Sistema personalizzato di riscrittura delle query basato sulla ricerca per AI conversazionali', 'lt': 'Name', 'ml': 'വ്യക്തിപരമായ തെരച്ചില്\u200d അടിസ്ഥാനമാക്കിയ അന്വേഷണത്തിനു് വീണ്ടും എഴുതുക', 'ms': 'Comment', 'kk': 'Жеке іздеу негіздеген сұраныс қайта жазу жүйесі', 'mn': 'Хэрэглэгч Хайлтын AI-ын хувьд суурилсан хайрын сууриллагаар дахин бичих систем', 'no': 'Personalisert søkebasert spørjingssystem for omskriving på nytt for samtale AI', 'mk': 'Name', 'mt': 'Sistema ta’ Riskrizzjoni ta’ Talbiet Personalizzata bbażata fuq it-Tfittxija għal AI Konversazzjonali', 'ro': 'Sistem personalizat de rescriere a interogării bazat pe căutare pentru AI conversațional', 'so': 'Query Rewrite System for Conversation AI', 'sr': 'Personalizirani sistem prepisanja pretraživanja za razgovorni AI', 'ta': 'Comment', 'pl': 'Personalizowany system przepisywania zapytań oparty na wyszukiwaniu dla konwersacyjnej AI', 'si': 'පුද්ගලික හොයාගන්න අධ්\u200dයාත්මක ප්\u200dරශ්නය ආපහු ලියන පද්ධතිය', 'ur': 'مکالمانی AI کے لئے شخصی جگہ بنیاد کی کوئریہ دوبارہ لیکن سیسٹم', 'sv': 'Anpassat sökbaserat frågeomräkningssystem för konversation AI', 'uz': 'Query', 'vi': 'Hệ thống tìm kiếm riêng cho AI đối thoại', 'bg': 'Персонализирана система за пренаписване на заявки, базирана на търсене, за разговорски изкуствен интелект', 'hr': 'Personalizirani sustav prepisanja pitanja na temelju pretraživanja za razgovorni AI', 'nl': 'Gepersonaliseerde zoekgebaseerde Query Rewrite System voor Conversational AI', 'da': 'Personaliseret søgebaseret forespørgsel omskrive system til samtale AI', 'id': 'Sistem Pencarian Berdasarkan Peribadi Tulis ulang untuk AI Konversional', 'fa': 'سیستم بازنوشتن سوال بر اساس جستجو شخصی برای AI مکالمه', 'de': 'Personalisiertes suchbasiertes Query Rewrite System für Conversational AI', 'sw': 'Rewrite System for Conversation AI', 'af': 'Personaliseer Soektog-gebaseerde Navraag Herskryf Stelsel vir Gespraak AI', 'am': 'Rewrite System for Conversational AI', 'tr': 'Söwürüş AI üçin Şahsy Arama tabanly Query Täze ýazma Sistemi', 'ko': '개성화된 검색 기반의 세션 인공지능 검색 리셋 시스템', 'sq': 'Sistemi i Rishkrimit të Kërkimit me bazë në kërkim personalizuar për AI konversational', 'hy': 'Comment', 'az': '兯湵얟浡⁁䤠쎼쎧쎼渠瓉饨獩氭瓉饨獩氠䅲慭愭瑡扡湬쒱⁓潲杵⁙敮楤즙渠奡稠卩獴敭椊', 'ca': 'Sistema personalitzat de reescripció de la consulta per AI conversacional', 'bn': 'ব্যক্তিগত অনুসন্ধানের ভিত্তিক অনুসন্ধান পুনরায় লেখা সিস্টেম', 'bs': 'Personalizirani sustav prepisanja pitanja na osnovu pretraživanja za razgovorni AI', 'cs': 'Personalizovaný systém přepisu dotazů založený na vyhledávání pro konverzační AI', 'et': 'Personaalne otsingupõhine päringute ümberkirjutamise süsteem vestlusliku AI jaoks', 'fi': 'HenkilĂ¶kohtainen hakupohjainen kyselyjen uudelleenkirjoitusjĂ¤rjestelmĂ¤ keskustelutekoĂ¤lylle', 'jv': "Menu item to Open 'Search for Open Files' dialog", 'sk': 'Prilagojeni sistem za preoblikovanje poizvedb na podlagi iskanja za pogovorno AI', 'ha': 'QSystemSemaphore', 'he': 'Name', 'bo': 'གཏམ་གླེང་གླེང་མོལ་AI(Personalized Search-based Query Rewrite System)'}
{'en': 'Query rewrite (QR) is an emerging component in conversational AI systems, reducing user defect. User defect is caused by various reasons, such as errors in the spoken dialogue system, users’ slips of the tongue or their abridged language. Many of the user defects stem from personalized factors, such as user’s speech pattern, ', 'ar': 'تعد إعادة كتابة الاستعلام (QR) مكونًا ناشئًا في أنظمة الذكاء الاصطناعي للمحادثة ، مما يقلل من عيوب المستخدم. ينتج عيب المستخدم عن أسباب مختلفة ، مثل الأخطاء في نظام الحوار المنطوق أو زلات لسان المستخدمين أو لغتهم المختصرة. تنبع العديد من عيوب المستخدم من عوامل مخصصة ، مثل نمط كلام المستخدم أو لهجته أو تفضيلاته. في هذا العمل ، نقترح إطار عمل QR قائم على البحث المخصص ، والذي يركز على التقليل التلقائي لعيب المستخدم. نقوم ببناء فهرس مخصص لكل مستخدم ، والذي يشمل طبقات تقارب متنوعة ليعكس التفضيلات الشخصية لكل مستخدم في الذكاء الاصطناعي للمحادثة. يحتوي نظام QR المخصص لدينا على طبقات استرداد وترتيب. بدعم من التعلم القائم على ملاحظات المستخدم ، لا يتطلب تدريب نماذجنا بيانات مشروحة يدويًا. أظهرت التجارب على مجموعة الاختبار الشخصية أن نظام الاستجابة السريعة المخصص لدينا قادر على تصحيح الأخطاء النظامية والمستخدم من خلال استخدام المدخلات الصوتية والدلالية.', 'fr': "La réécriture des requêtes (QR) est un composant émergent des systèmes d'IA conversationnelle, qui réduit les défauts de l'utilisateur. Le défaut de l'utilisateur est causé par diverses raisons, telles que des erreurs dans le système de dialogue vocal, des glissades de langue de l'utilisateur ou son langage abrégé. Bon nombre des défauts de l'utilisateur découlent de facteurs personnalisés, tels que le modèle de discours, le dialecte ou les préférences de l'utilisateur. Dans ce travail, nous proposons un framework QR personnalisé basé sur la recherche, qui met l'accent sur la réduction automatique des défauts de l'utilisateur. Nous créons un index personnalisé pour chaque utilisateur, qui comprend diverses couches d'affinité afin de refléter les préférences personnelles de chaque utilisateur dans l'IA conversationnelle. Notre système QR personnalisé contient des couches de récupération et de classement. Soutenue par un apprentissage basé sur les commentaires des utilisateurs, la formation de nos modèles ne nécessite pas de données annotées à la main. Des expériences sur des ensembles de tests personnalisés ont montré que notre système QR personnalisé est capable de corriger les erreurs systématiques et les erreurs de l'utilisateur en utilisant des entrées phonétiques et sémantiques.", 'es': 'La reescritura de consultas (QR) es un componente emergente en los sistemas de IA conversacional, que reduce los defectos del usuario. El defecto del usuario se debe a varias razones, como errores en el sistema de diálogo oral, los deslizamientos de la lengua de los usuarios o su lenguaje abreviado. Muchos de los defectos del usuario se deben a factores personalizados, como el patrón de habla, el dialecto o las preferencias del usuario. En este trabajo, proponemos un marco de QR personalizado basado en la búsqueda, que se centra en la reducción automática de los defectos del usuario. Creamos un índice personalizado para cada usuario, que abarca diversas capas de afinidad para reflejar las preferencias personales de cada usuario en la IA conversacional. Nuestro sistema QR personalizado contiene capas de recuperación y clasificación. Con el apoyo del aprendizaje basado en los comentarios de los usuarios, el entrenamiento de nuestros modelos no requiere datos anotados a mano. Experimentos en conjuntos de pruebas personalizadas mostraron que nuestro sistema QR personalizado es capaz de corregir errores sistemáticos y de usuario mediante el uso de entradas fonéticas y semánticas.', 'pt': 'A reescrita de consulta (QR) é um componente emergente em sistemas de IA conversacionais, reduzindo o defeito do usuário. O defeito do usuário é causado por vários motivos, como erros no sistema de diálogo falado, lapsos de linguagem dos usuários ou seu idioma abreviado. Muitos dos defeitos do usuário derivam de fatores personalizados, como padrão de fala, dialeto ou preferências do usuário. Neste trabalho, propomos um framework QR personalizado baseado em busca, que foca na redução automática do defeito do usuário. Construímos um índice personalizado para cada usuário, que engloba diversas camadas de afinidade para refletir as preferências pessoais de cada usuário na IA conversacional. Nosso sistema QR personalizado contém camadas de recuperação e classificação. Apoiado pelo aprendizado baseado em feedback do usuário, o treinamento de nossos modelos não requer dados anotados à mão. Experimentos em conjuntos de testes personalizados mostraram que nosso sistema QR personalizado é capaz de corrigir erros sistemáticos e do usuário utilizando entradas fonéticas e semânticas.', 'hi': 'क्वेरी पुनर्लेखन (QR) संवादी एआई सिस्टम में एक उभरता हुआ घटक है, जो उपयोगकर्ता दोष को कम करता है। उपयोगकर्ता दोष विभिन्न कारणों से होता है, जैसे कि बोली जाने वाली संवाद प्रणाली में त्रुटियां, उपयोगकर्ताओं की जीभ की पर्ची या उनकी संक्षिप्त भाषा। उपयोगकर्ता दोषों में से कई व्यक्तिगत कारकों से उत्पन्न होते हैं, जैसे कि उपयोगकर्ता का भाषण पैटर्न, बोली, या प्राथमिकताएं। इस काम में, हम एक व्यक्तिगत खोज-आधारित क्यूआर फ्रेमवर्क का प्रस्ताव करते हैं, जो उपयोगकर्ता दोष की स्वचालित कमी पर केंद्रित है। हम प्रत्येक उपयोगकर्ता के लिए एक व्यक्तिगत सूचकांक का निर्माण करते हैं, जिसमें संवादी एआई में प्रत्येक उपयोगकर्ता के लिए व्यक्तिगत प्राथमिकताओं को प्रतिबिंबित करने के लिए विविध आत्मीयता परतों को शामिल किया गया है। हमारे व्यक्तिगत QR प्रणाली पुनर्प्राप्ति और रैंकिंग परतों में शामिल हैं. उपयोगकर्ता प्रतिक्रिया आधारित सीखने द्वारा समर्थित, हमारे मॉडल को प्रशिक्षित करने के लिए हाथ से एनोटेट किए गए डेटा की आवश्यकता नहीं होती है। व्यक्तिगत परीक्षण सेट पर प्रयोगों से पता चला है कि हमारी व्यक्तिगत क्यूआर प्रणाली ध्वन्यात्मक और शब्दार्थ इनपुट का उपयोग करके व्यवस्थित और उपयोगकर्ता त्रुटियों को सही करने में सक्षम है।', 'ja': 'クエリ書き換え（ QR ）は、会話型AIシステムの新たなコンポーネントであり、ユーザーの欠陥を軽減します。ユーザーの欠陥は、口頭の対話システムの誤り、ユーザーの舌の滑り、または言語の短縮など、さまざまな理由によって引き起こされます。ユーザーの欠陥の多くは、ユーザーの発話パターン、方言、または好みなどのパーソナライズされた要因に由来します。本作では、ユーザーの不具合の自動軽減に焦点を当てた、パーソナライズされた検索ベースのQRフレームワークを提案します。私たちは、会話AIで各ユーザーの個人的な好みを反映するために、多様な親和性レイヤーを含む、各ユーザーのためのパーソナライズされたインデックスを構築します。当社のパーソナライズされたQRシステムには、検索レイヤーとランキングレイヤーが含まれています。ユーザーフィードバックベースの学習に支えられている当社のモデルのトレーニングは、手動で注釈を付けたデータを必要としません。パーソナライズされたテストセットの実験では、当社のパーソナライズされたQRシステムは、音声入力とセマンティック入力を利用することにより、システム的なエラーとユーザーエラーを修正することができることが示されました。', 'zh': '询重写(QR)是会话AI系统新兴组件,可减用户缺陷。 用户缺陷由诸故起,如口语对话系统之误,用户之口误与其删节语。 诸用户缺陷,本于个性化素,如用户语音模式,方言偏好。 于是条上搜索之个性化QR框架,当框架侧重于自损用户阙。 每用户一个性化索引,各有亲和力层,以见会话AI之偏用户。 吾个性化QR系统包检,排名图层。 于用户反馈之学,训我模形,不须手动注之数。 个性化试集之实验,吾个性化QR统得以语音语义输以正其用户非。', 'ru': 'Перезапись запросов (QR) - это новый компонент в разговорных системах ИИ, уменьшающий дефекты пользователя. Дефект пользователя вызван различными причинами, такими как ошибки в системе разговорного диалога, проскальзывание языка пользователями или их сокращенный язык. Многие из дефектов пользователя связаны с персонализированными факторами, такими как речевой паттерн, диалект или предпочтения пользователя. В этой работе мы предлагаем персонализированный поисковый QR-фреймворк, который фокусируется на автоматическом уменьшении дефекта пользователя. Мы строим персонализированный индекс для каждого пользователя, который включает в себя различные слои аффинности, чтобы отразить личные предпочтения для каждого пользователя в разговорном ИИ. Наша персонализированная QR-система содержит слои поиска и ранжирования. Обучение наших моделей, поддерживаемое обучением на основе отзывов пользователей, не требует данных с ручной аннотацией. Эксперименты на персонализированном тестовом наборе показали, что наша персонализированная QR-система способна исправлять систематические и пользовательские ошибки, используя фонетические и семантические входные данные.', 'ga': 'Is comhpháirt atá ag teacht chun cinn i gcórais chomhrá AI é athscríobh fiosrúcháin (QR), rud a laghdóidh fabht úsáideoirí. Cúiseanna éagsúla is cúis le lochtanna úsáideoirí, mar earráidí sa chóras cainte labhartha, sleamhnú teanga na n-úsáideoirí nó a dteanga ghiorraithe. Eascraíonn go leor de na lochtanna úsáideoirí ó fhachtóirí pearsantaithe, mar phatrún cainte an úsáideora, canúint, nó roghanna. San obair seo, molaimid creat QR pearsantaithe cuardaigh-bhunaithe, a dhíríonn ar laghdú uathoibríoch a dhéanamh ar fhabht úsáideora. Tógaimid innéacs pearsantaithe do gach úsáideoir, a chuimsíonn sraitheanna éagsúla cleamhnais chun roghanna pearsanta gach úsáideoir san AI comhrá a léiriú. Tá sraitheanna aisghabhála agus rangúcháin inár gcóras QR pearsantaithe. Le tacaíocht ó fhoghlaim atá bunaithe ar aiseolas ó úsáideoirí, ní theastaíonn sonraí lámh-nótaithe chun ár múnlaí a oiliúint. Léirigh turgnaimh ar thacar tástála pearsantaithe go bhfuil ár gcóras QR pearsanta in ann earráidí córasacha agus úsáideora a cheartú trí úsáid a bhaint as ionchuir foghraíochta agus shéimeantacha.', 'ka': 'კითხვა გადაწერა (QR) არის კომპონტაქტიური AI სისტემებში აღმოჩენებული კომპონტაქტი, რომელიც გამოყენებელი დეფექტის შემცირება. მომხმარებლის შეცდომა განსხვავებული მიზეზებიდან იქნება, როგორც შეცდომა სისტემის შეცდომა, გამოიყენებელი ენის შეცდომა ან ისინი გარეშე ენაში. მომხმარებლის დიალექტი პროგრამეტრების ფონტაქტების, როგორც მომხმარებლის სიტყვა, დიალექტი, ან პროგრამეტრები. ამ სამუშაოში ჩვენ პროგრამეტურად საძიებო QR ფრამეტრის გადავიწყებთ, რომელიც მომხმარებელი განსხვავებაზე ავტომატურად დავაკლება. ჩვენ ყველა გამოყენებელისთვის პორციალური ინდექსტის შექმნა, რომელიც განსხვავებული განსხვავებული განსხვავებული განსხვავებულებების შაბლოების განსხვავება, რომ ყველა გამოყენებელის ჩვენი პროგრამიზებული QR სისტემა იყენებს მიღება და რენექტირება. მომხმარებლის შესაბამისი შესაბამისი შესაბამისი შესწავლება, ჩვენი მოდელების შესაბამისი შესაბამისი მონაცემები არ მოჭირდება. პორციალური ტესტის გამოცდილება ჩვენი პორციალური QR სისტემის შესაძლებლობა სისტემისტიკური და გამოყენებელი შეცდომის შეცდომის გამოყენებით ფონეტიკური და ჟენმანტიკურ', 'hu': 'A Query rewrite (QR) a beszélgető AI rendszerek egyik feltörekvő összetevője, amely csökkenti a felhasználói hibákat. A felhasználói hibát különböző okok okozzák, mint például a beszélt párbeszédrendszer hibái, a felhasználók nyelvcsúszásai vagy rövidített nyelvük. A felhasználói hibák többsége személyre szabott tényezőkből ered, mint például a felhasználó beszédmintája, dialektusa vagy preferenciái. Ebben a munkában egy személyre szabott keresési alapú QR keretrendszert javasolunk, amely a felhasználói hibák automatikus csökkentésére összpontosít. Minden felhasználó számára személyre szabott indexet építünk, amely különböző affinitási rétegeket tartalmaz, hogy tükrözze az egyes felhasználók személyes preferenciáit a beszélgetési mesterséges intelligenciában. Személyre szabott QR rendszerünk visszakeresési és rangsorolási rétegeket tartalmaz. A felhasználói visszajelzések alapú tanulás támogatásával modelleink képzése nem igényel kézzel megjegyzett adatokat. A személyre szabott tesztkészleten végzett kísérletek kimutatták, hogy a személyre szabott QR rendszerünk fonetikai és szemantikai bemenetek segítségével képes korrigálni a szisztematikus és felhasználói hibákat.', 'el': 'Η επανάληψη ερωτήματος (είναι ένα αναδυόμενο στοιχείο στα συστήματα συνομιλίας, μειώνοντας το ελάττωμα του χρήστη. Το ελάττωμα του χρήστη προκαλείται από διάφορους λόγους, όπως λάθη στο σύστημα προφορικού διαλόγου, ολίσθηση της γλώσσας των χρηστών ή συντομευμένη γλώσσα τους. Πολλά από τα ελαττώματα του χρήστη προέρχονται από εξατομικευμένους παράγοντες, όπως το μοτίβο ομιλίας, η διάλεκτος ή οι προτιμήσεις του χρήστη. Στην εργασία αυτή, προτείνουμε ένα εξατομικευμένο πλαίσιο βασισμένο στην αναζήτηση, το οποίο επικεντρώνεται στην αυτόματη μείωση των ελαττωμάτων του χρήστη. Φτιάχνουμε ένα εξατομικευμένο ευρετήριο για κάθε χρήστη, το οποίο περιλαμβάνει διάφορα επίπεδα συγγένειας για να αντικατοπτρίζει τις προσωπικές προτιμήσεις για κάθε χρήστη στην επικοινωνιακή τεχνητή νοημοσύνη. Το εξατομικευμένο σύστημα μας περιέχει στρώματα ανάκτησης και κατάταξης. Υποστηριζόμενη από τη μάθηση των χρηστών που βασίζεται στην ανατροφοδότηση, η εκπαίδευση των μοντέλων μας δεν απαιτεί σχολιασμένα δεδομένα με το χέρι. Τα πειράματα σε εξατομικευμένο σετ δοκιμών έδειξαν ότι το εξατομικευμένο σύστημα μας είναι σε θέση να διορθώσει συστηματικά λάθη και λάθη χρηστών χρησιμοποιώντας φωνητικές και σημασιολογικές εισόδους.', 'lt': "Klausimo perrašymas (QR) yra nauja konversacinių AI sistemų sudedamoji dalis, mažinanti naudotojo defektą. Vartotojų defektas sukeliamas dėl įvairių priežas čių, pavyzdžiui, kalbos dialogo sistemos klaidų, naudotojų kalbos lapų arba jų sutrumpintos kalbos. Many of the user defects stem from personalized factors, such as user's speech pattern, dialect, or preferences.  Šiame darbe siūlome personalizuotą paieškos pagrindu pagrįstą QR sistemą, kurioje daugiausia dėmesio skiriama automatiniam vartotojo defektų mažinimui. Kiekvienam naudotojui sukuriame individualų indeksą, kuris apima įvairius afiniteto sluoksnius, kad atspindėtų kiekvieno naudotojo asmenines preferencijas pokalbio AI. Mūsų personalizuotoje QR sistemoje yra surinkimo ir ranking ų sluoksnių. Naudotojo grįžtamojo mokymosi pagrindu remiamas mokymasis mūsų modeliams nereikalauja rankiniu būdu užrašytų duomenų. Experiments on personalized test set showed that our personalized QR system is able to correct systematic and user errors by utilizing phonetic and semantic inputs.", 'it': "Query rewrite (QR) è un componente emergente nei sistemi di intelligenza artificiale conversazionale, riducendo i difetti dell'utente. Il difetto dell'utente è causato da vari motivi, come errori nel sistema di dialogo parlato, errori di lingua degli utenti o la loro lingua abbreviata. Molti dei difetti dell'utente derivano da fattori personalizzati, come il modello vocale dell'utente, il dialetto o le preferenze. In questo lavoro, proponiamo un framework QR personalizzato basato sulla ricerca, che si concentra sulla riduzione automatica dei difetti dell'utente. Costruiamo un indice personalizzato per ogni utente, che comprende diversi livelli di affinità per riflettere le preferenze personali di ogni utente nell'IA conversazionale. Il nostro sistema QR personalizzato contiene livelli di recupero e posizionamento. Supportato dall'apprendimento basato sui feedback degli utenti, la formazione dei nostri modelli non richiede dati annotati manualmente. Esperimenti su set di test personalizzati hanno dimostrato che il nostro sistema QR personalizzato è in grado di correggere errori sistematici e utente utilizzando input fonetici e semantici.", 'ms': 'Tulis semula permintaan (QR) adalah komponen yang muncul dalam sistem AI perbualan, mengurangi cacat pengguna. Galat pengguna disebabkan oleh sebab-sebab berbeza, seperti ralat dalam sistem dialog bercakap, slip pengguna bahasa atau bahasa singkat mereka. Banyak kesalahan pengguna berasal dari faktor peribadi, seperti corak ucapan pengguna, dialekt, atau keutamaan. Dalam kerja ini, kami melamar kerangka QR berasaskan pencarian pribadi, yang fokus pada pengurangan automatik cacat pengguna. Kami membina indeks peribadi bagi setiap pengguna, yang meliputi lapisan afini berbeza untuk mencerminkan keutamaan peribadi bagi setiap pengguna dalam AI perbualan. Sistem QR personalisasi kami mengandungi lapisan pemulihan dan rangkaian. Disokong oleh pembelajaran berbasis feedback pengguna, melatih model kami tidak memerlukan data anotated-tangan. Eksperimen pada set ujian peribadi menunjukkan bahawa sistem QR peribadi kita mampu memperbaiki ralat sistemik dan pengguna dengan menggunakan input fonetik dan semantik.', 'kk': 'Сұраныс қайта жазу (QR) деген парақшалық AI жүйелерінде қайта жазылатын компонент, пайдаланушының қауіпсіздігін азайту. Пайдаланушының қауіпсіздігі әртүрлі себептерінің себебі, мысалы, сөйлейтін диалог жүйесінде қателері, пайдаланушылардың тілінің қалқалары немесе олардың күшірілген Пайдаланушының көпшілігі жеке факторлардан, мысалы, пайдаланушының сөйлесу үлгісі, диалекті немесе параметрлері. Бұл жұмыста, QR негіздеген жеке іздеу бағдарламасын ұсынып, пайдаланушыларды автоматты түрде азайту үшін негізделген. Біз әрбір пайдаланушы үшін өзінің индексін құрамыз. Бұл әрбір пайдаланушылардың көпшілікті қабаттарын қарай, әрбір пайдаланушының көпшілікті AI параметрлерін көр Жеке QR жүйесімізде алу және реттеу қабаттары бар. Пайдаланушылардың қайталау бағдарламасының қолдауы, үлгілерімізді оқыту үлгілерімізге қол белгілеу деректері керек емес. Жеке тексерілген сынақтардың тәжірибесі жеке QR жүйесіміз фонетикалық және semantiкалық кірістерді қолдану арқылы жүйелік және пайдаланушының қатесін түзетуге болады.', 'ml': 'സംസാരിക്കുന്ന AI സിസ്റ്റത്തില്\u200d വീണ്ടും എഴുതുന്ന ഘടകം വീണ്ടും ചോദിക്കുക സംസാരിക്കപ്പെട്ട ഡയലോഗ് സിസ്റ്റത്തില്\u200d പിശകുകള്\u200d, ഉപയോക്താവിന്റെ ഭാഷയുടെ സ്ലിപ്പുകള്\u200d അല്ലെങ്കില്\u200d അവരുടെ ഭാഷയില്\u200d നി ഉപയോക്താവിന്റെ സംസാര ര രീതിയില്\u200d നിന്നും വ്യക്തിപരമായ കാരണങ്ങളില്\u200d നിന്നും പലരും തെറ്റുകളുണ്ട്. ഉപയോക്താവിന്റെ  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d ഒരു വ്യക്തിപരമായ തെരച്ചില്\u200d അടിസ്ഥാനമായ ക്യൂ ആര്\u200d ഫ്രെയിമാര്\u200dക്ക് പ്രായശ്ചിത്തമാക്ക എല്ലാ ഉപയോക്താവിനും വ്യക്തിപരമായ ഒരു സൂചിപ്പ് നാം പണിയുന്നു. സംസാരിക്കുന്ന എല്ലാ ഉപയോക്താവിനും സ്വകാര്യ മുന്\u200dഗണനകള Our personalized QR system contains retrieval and ranking layers.  ഉപയോക്താവിന്റെ ഫിഡിബ്ബാക്ക് അടിസ്ഥാനമായ പഠനം ഉപയോഗിക്കുന്നതിനാല്\u200d പിന്തുണയ്ക്കുന്നു, നമ്മുടെ മോഡ വ്യക്തിപരമായ പരീക്ഷണസെറ്റിലെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു ഞങ്ങളുടെ വ്യക്തിപരമായ ക്യൂആര്\u200d സിസ്റ്റം സിസ്റ്റീമിക്കും ഉപയോക്താവിന്റെ ത', 'mn': 'Хэрэглэгчдийн алдагдлыг багасгаж, харилцааны AI системийн шинэ компонент юм. Хэрэглэгчийн алдагдлыг олон шалтгаанаас шалтгаалдаг. Яг л ярианы диалог системийн алдагдлыг, хэрэглэгчийн хэл эсвэл хаягдсан хэл. Хэрэглэгчийн ихэнх нь хувийн хүчин зүйлээс гарч ирдэг. Яг хэрэглэгчийн ярианы загвар, диалект, эсвэл сонголт. Энэ ажил дээр бид хувийн хайлтын QR суурилсан хэлбэрийг санал болгож байна. Энэ нь хэрэглэгчийн алдагдлыг автоматжуулан багасгах төвлөрөгдөж байна. Бид хэрэглэгч бүрт хувийн индекс бүтээж, харилцааны AI-д хэрэглэгч бүрт хувийн сонголтуудыг харуулахын тулд олон төрлийн загваруудыг дүүргэдэг. Бидний хувилбар QR систем хүлээн авах, цуврах давхарга агуулдаг. Хэрэглэгчдийн хариу өгүүлэлт суралцах, загварыг суралцах нь гараар анзаарсан өгөгдлийн шаардлагагүй. Хувийн туршилтын туршилтын туршилт нь бидний хувийн QR систем phonetic, semantic input ашиглаж системийн болон хэрэглэгчийн алдаа засаж чадна гэдгийг харуулсан.', 'mt': 'Il-miktub mill-ġdid tal-mistoqsijiet (QR) huwa komponent emerġenti fis-sistemi tal-AI ta’ konverżjoni, li jnaqqas id-difett tal-utent. Id-difett tal-utent huwa kkawżat minn raġunijiet varji, bħal żbalji fis-sistema ta’ djalogu mitkellm, slips tal-utenti tal-ilsien jew il-lingwa mqassra tagħhom. Ħafna mid-difetti tal-utent jirriżultaw minn fatturi personalizzati, bħal mudell tad-diskors tal-utent, dijalekt, jew preferenzi. F’dan ix-xogħol, qed nipproponu qafas ta’ QR personalizzat ibbażat fuq it-tiftix, li jiffoka fuq it-tnaqqis awtomatiku tad-difett tal-utent. Aħna nibnu indiċi personalizzat għal kull utent, li jinkludi saffi differenti ta’ affinità biex jirriflettu preferenzi personali għal kull utent fl-AI ta’ konverżjoni. Is-sistema personalizzata tagħna ta’ QR fiha saffi ta’ rkupru u klassifikazzjoni. Appoġġ minn tagħlim ibbażat fuq ir-rispons tal-utenti, it-taħriġ tal-mudelli tagħna ma jeħtieġx dejta annotata bl-idejn. L-esperimenti fuq sett personalizzat tat-testijiet urew li s-sistema personalizzata tagħna tal-QR hija kapaċi tikkoreġi żbalji sistematiċi u tal-utent billi tuża inputs fonetiċi u semantiċi.', 'pl': 'Przepisywanie zapytań (QR) jest pojawiającym się komponentem w systemach konwersacyjnej AI, zmniejszającym wady użytkownika. Wada użytkownika jest spowodowana różnymi przyczynami, takimi jak błędy w systemie dialogu mówionego, poślizgnięcia języka użytkownika lub skrócony język. Wiele wad użytkownika wynika ze spersonalizowanych czynników, takich jak wzór mowy użytkownika, dialekt lub preferencje. W niniejszej pracy proponujemy spersonalizowany framework QR oparty na wyszukiwaniu, który koncentruje się na automatycznej redukcji wad użytkownika. Budujemy spersonalizowany indeks dla każdego użytkownika, który obejmuje różne warstwy powinowactwa, aby odzwierciedlać osobiste preferencje dla każdego użytkownika w konwersacyjnej AI. Nasz spersonalizowany system QR zawiera warstwy pobierania i rankingu. Wspierane przez uczenie się oparte na opiniach użytkowników, szkolenie naszych modeli nie wymaga ręcznie adnotacji danych. Eksperymenty na spersonalizowanym zestawie testowym wykazały, że nasz spersonalizowany system QR jest w stanie korygować błędy systematyczne i użytkownika poprzez wykorzystanie wejść fonetycznych i semantycznych.', 'mk': 'Query rewrite (QR) is an emerging component in conversational AI systems, reducing user defect.  Погрешките на корисникот се предизвикани од различни причини, како што се грешките во системот на зборуваниот дијалог, лизгите на корисниците од јазикот или нивниот скратен јазик. Многу од дефектите на корисникот потекнуваат од персонализирани фактори, како што е образот на говорот на корисникот, дијалектот или преференциите. Во оваа работа предложуваме персонализирана QR рамка базирана на пребарување, која се фокусира на автоматско намалување на корисничкиот дефект. We build a personalized index for each user, which encompasses diverse affinity layers to reflect personal preferences for each user in the conversational AI.  Нашиот персонализиран QR систем содржи обезбедување и рангирање на слоеви. Поддржано од учење базирано на корисничката реакција, обуката на нашите модели не бара податоци со рака. Experiments on personalized test set showed that our personalized QR system is able to correct systematic and user errors by utilizing phonetic and semantic inputs.', 'ro': 'Rescrierea interogării (QR) este o componentă emergentă în sistemele conversaționale AI, reducând defectele utilizatorului. Defectul utilizatorului este cauzat de diferite motive, cum ar fi erorile în sistemul de dialog vorbit, alunecările utilizatorilor de limbă sau limba lor scurtă. Multe dintre defectele utilizatorului provin din factori personalizați, cum ar fi modelul de vorbire al utilizatorului, dialectul sau preferințele. În această lucrare, propunem un cadru QR personalizat bazat pe căutare, care se concentrează pe reducerea automată a defectelor utilizatorului. Construim un index personalizat pentru fiecare utilizator, care cuprinde diferite straturi de afinitate pentru a reflecta preferințele personale pentru fiecare utilizator în AI conversațional. Sistemul nostru QR personalizat conține straturi de recuperare și clasare. Sprijinită de învățarea bazată pe feedback-ul utilizatorilor, formarea modelelor noastre nu necesită date adnotate manual. Experimentele pe setul de teste personalizat au arătat că sistemul nostru QR personalizat este capabil să corecteze erorile sistematice și ale utilizatorilor prin utilizarea intrărilor fonetice și semantice.', 'sr': 'Prepisanje ispitivanja (QR) je pojavljujući komponent u razgovornim AI sistemima, smanjujući poremećaj korisnika. Poremećaj korisnika je uzrokovan različitim razlogom, kao što su greške u rečenom dijalogu, korisnički komadi jezika ili njihovog proširenog jezika. Mnogi od korisnika poremećaja dolaze iz osobnih faktora, kao što su obrazac govora korisnika, dijalekt ili preferencija. U ovom poslu predlažemo lični QR okvir na potrazi, koji se fokusira na automatsko smanjenje poremećaja korisnika. Napravili smo lični indeks za svakog korisnika, koji obuhvaća različite slojeve afinitnosti da odraže lične preferencije svakog korisnika u razgovornom AI-u. Naš lični QR sistem sadrži preuzimanje i redovne slojeve. Podržavaju učenje na osnovu reakcije korisnika, obuku našeg modela ne zahteva podatke s rukama. Eksperimenti na setu ličnih testova pokazali su da naš lični QR sistem može ispraviti sistemske greške i korisnike koristeći fonetičke i semantične ulaze.', 'si': 'ප්\u200dරශ්නය ආපහු ලියවන්න (QR) ප්\u200dරශ්නයක් වාර්තාවික AI පද්ධතියේ ප්\u200dරශ්නයක්, ප්\u200dරයෝජකය අතාරිත් පාවිච්චි අවස්ථාවක් විවිධ හේතුවක් නිසා විවිධ හේතුවක් වලින්, කතා කරපු සංවාද පද්ධතියේ වැරදි වලින ප්\u200dරයෝජකයෙන් ගොඩක් අවස්ථාවක් පුද්ගලික විශේෂ විද්\u200dයාපකයෙන් ඉන්නවා, වගේම ප්\u200dරයෝජකයේ භාවිතා මේ වැඩේ අපි පෞද්ගලික විශ්වාසයෙන් පරික්ෂා කරන්න QR පරික්ෂාවක් ප්\u200dරතිකාර කරනවා, ඒක ස්වයංක්\u200dරියාවිත අපි හැම ප්\u200dරයෝජකයෙක්ට පුද්ගලික සංකේතයක් හදන්නවා, ඒක විවිධ සංකේතයක් සම්පූර්ණය කරනවා හැම ප්\u200dරයෝජකයෙක්ට ප අපේ පෞද්ගලික QR පද්ධතිය ප්\u200dරවේශනය සහ ප්\u200dරවේශනය කරනවා. භාවිතා ප්\u200dරතිචාර ප්\u200dරතිචාරයක් අධාරිත විදියට උදව් කරනවා, අපේ මොඩල් ප්\u200dරධානය අපේ අත්තර ප්\u200dරතිච පෞද්ගලික පරීක්ෂණ සෙට් එකේ පරීක්ෂණය පෙන්වන්න පුළුවන් කියලා අපේ පුද්ගලික QR පද්ධතිය පද්ධතිය පද්ධතිය සහ ප්\u200dර', 'so': 'Soo weydii rewrite (QR) waa qayb ka soo baxaya nidaamka iskala hadlayaasha AI, wuxuuna ka fekeraa dhibaatada isticmaalaha. Dhibaatooyinka isticmaaluhu waxay sababo kala duduwan u timaadaan tusaale ahaan qaladyada nidaamka kala hadlaya, qalabka luuqada isticmaalayaasha ama luqadooda baahida ah. Dhibaatooyinka badan ee isticmaalayaasha waxaa ka soo baxa waxyaabo gaar ah, tusaale ahaan qaabka hadalka ee isticmaalaha, sawir ama doorasho. Markaas waxan, waxaynu soo jeedaynaa qorshaha QR ee gaarka loo leeyahay, kaas oo ku kalsoonaadaya dib u dhigista dhibaatada isticmaalaha. Waxaan u dhisnaa index gaar ah oo isticmaalaha ah, kaas oo ku qoran xarumo xirfadeed oo kala duduwan si aan ugu fiirsanno doorashooyinka gaarka ah ee isticmaalaha oo ku qoran AI. nidaamka QR ee gaarka loo leeyahay waxay ku jirtaa meelo lagu soo celiyo iyo meelo lagu sameynayo. Kaalmeynta waxbarashada ku saleysan feedbacyada isticmaalayaasha, waxbarashada modelalkayaga looma baahna macluumaad lagu cadaadiyo gacanta. Imtixaanka ku qoran imtixaanka shakhsiyadeed waxay muujinaysaa in nidaamka QR ee gaarka loo leeyahay uu ku hagi karo nidaamka iyo khaladda isticmaalka midibka telefonetka iyo semantika.', 'ta': 'கேள்வி மீண்டும் எழுதுதல் (QR) ஒரு பேச்சு AI முறைமைகளில் வரும் உறுப்பாகும், பயனர் பிழையை குறைக்கும். பேசும் உரையாடல் முறைமையில் பிழைகள், பயன்படுத்துபவர்களின் மொழியின் குறுக்குகள் அல்லது தங்கள் நீக்கப்பட்ட மொழி பயனர் பிழைகள் தனிப்பட்ட காரணிகளிலிருந்து வந்துள்ளது, பயனரின் பேச்சு மாதிரி இந்த வேலையில், நாம் தனிப்பட்ட தேடல் அடிப்படையில் கியூஆர் சட்டத்தை பரிந்துரைக்கிறோம், அது பயனர் பிழையை தானாக குறை நாம் ஒவ்வொரு பயனருக்கும் தனிப்பட்ட சுட்டுவரிசையை உருவாக்குகிறோம், அது பல்வேறு தொடர்பு அடுக்குகளை சூழ்ந்து இருக்கும்,  எங்கள் தனிப்பட்ட கியூஆர் அமைப்பு மீண்டும் மற்றும் மீண்டும் அடுக்குகள் உள்ளது. பயனர் சார்ந்த படிப்பு அடிப்படையில் பயிற்சியால் ஆதரிக்கப்படுகிறது, எங்கள் மாதிரிகளை பயிற்சி செய்யும் கையி தனிப்பட்ட பரிசோதனை அமைப்பில் சோதனைகள் காண்பித்தது எங்கள் தனிப்பட்ட கியூஆர் அமைப்பு மூலம் போன்டெடிக் மற்றும் அரை உள்ளீடுகளை பயன்படுத்த', 'no': 'Spør om skriving (QR) er eit oppgåande komponent i konversjonal AI- systemet, som reduserer brukardefekt. Brukardefekten vert forårsaken av ulike grunnar, slik som feil i den tale dialogsystemet, språk frå brukarar eller språket deres utrygt. Mange av brukardefektane stemmer frå personaliserte faktorer, slik som talemønster, dialekt eller innstillingar for brukaren. I denne arbeida foreslår vi eit personalisert søkjebasert QR-rammeverk, som fokuserer på automatisk reduksjon av brukardefekt. Vi bygger ei personalisert indeks for kvar brukar, som omformar ulike affinititetslag for å refleksera personlege innstillingar for kvar brukar i samtale AI. Personleg QR- systemet vårt inneheld henting og rangering av lag. Støtta av brukarapplæring basert på tilbakemeldingar, trening våre modeller krev ikkje håndnotata data. Eksperimentar på personaliserte testsett viste at vår personaliserte QR-systemet kan korrigera systematiske og brukerfeilar ved å bruka fonetiske og semantiske inndata.', 'sv': 'Query rewrite (QR) är en framväxande komponent i konversationella AI-system, vilket minskar användarfel. Användarfel orsakas av olika orsaker, t.ex. fel i det talade dialogsystemet, användares språklappar eller förkortade språk. Många av användardefekterna beror på personliga faktorer, såsom användarens talmönster, dialekt eller preferenser. I detta arbete föreslår vi ett personligt sökbaserat QR-ramverk som fokuserar på automatisk minskning av användarfel. Vi bygger ett personligt index för varje användare, som omfattar olika affinitetslager för att återspegla personliga preferenser för varje användare i konversations AI. Vårt personliga QR-system innehåller hämtnings- och rankningslager. Med stöd av användarfeedback baserat lärande kräver utbildning av våra modeller inte handkommenterade data. Experiment på personaliserade testset visade att vårt personaliserade QR-system kan korrigera systematiska och användarfel genom att använda fonetiska och semantiska inmatningar.', 'ur': '(QR) کوئوری دوبارہ لکھ رہی ہے، مکانٹریشن AI سیسٹم میں ایک اگلوں کی رقم ہے، کارساز ناکامی کم کر رہی ہے۔ کارساز غلطی مختلف دلیلوں کی وجہ سے ہوتی ہے، جیسے بات کی گفتگو سیسٹم میں غلطی، کارساز کی زبان یا ان کی غلطی کی زبان میں غلطی. بہت سے کارساز ناکام ہوتے ہیں شخصی فکتوروں سے، جیسے کارساز کی بات پٹرن، دیالکت، یا ترجیح. ہم نے اس کام میں ایک شخصی جگہ پر بنیاد رکھا ہوا QR فرمیک پیشنهاد کرتا ہے جو کارساز ناکام کی آٹوٹی کمی پر تمرکز کرتا ہے۔ ہم ہر کاربر کے لئے ایک شخصی انڈکس بناتے ہیں، جو مختلف اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا انتخاب کرتا ہے، جو مختلف اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا ا ہمارے شخصی QR سیسٹم کے ذریعے پھیرنے اور رینگ لہروں میں ہے. استعمال فیڈبک بنیاد کی تعلیم کی مدد کی جاتی ہے، ہمارے نمڈلوں کی تعلیم کی ضرورت نہیں ہے خصوصی تست سٹ کے تجربے دکھائے گئے کہ ہمارے شخصی QR سیستم سیستم سیستماتیک اور کارساز کی خطائیں سمجھ سکتی ہیں', 'uz': "Name Name Ko'pchilik foydalanuvchidagi xatolar foydalanuvchi shaklning turi, dialect, yoki parametrlar kabi shaxsiy factoridan iborat. Bu ishda, biz shaxsiy qidirish asosiy QR freymini talab qilamiz, bu foydalanuvchi xatolarni avtomatik kamaytirish uchun foydalanuvchiga qarang. Biz har bir foydalanuvchi uchun shaxsiy indeksni yaratib, bu muloqat AIda har bir foydalanuvchi uchun shaxsiy parametrlarni tashqi qilish uchun har xil qatlamlarni ajratuvchi. Bizning shaxsiy QR tizimimizda qaytarish va chegara qatlam bor. Name Shaxsiy sinov moslamalarida imtiyozlar bilan shaxsiy QR tizimimizni fonetik va semantik kiritish yordamida tizim va foydalanuvchi xatolarni tozalash mumkin.", 'vi': 'Do việc viết lại câu hỏi (QR) là thành phần mới nhất trong hệ thống AI để giảm khiếm khuyết của người dùng. Anh bị lỗi là do nhiều lý do, như lỗi trong hệ thống đối thoại đã nói, lỗi của người dùng hay ngôn ngữ bị cắt. Nhiều khuyết điểm của người dùng là do tư cách cá nhân tạo nên các yếu tố như cách nói, ngữ điệu, phương ngữ, hoặc s ở thích. Trong công việc này, chúng tôi đề xuất một cơ sở cá nhân dựa trên QR, tập trung vào việc giảm lỗi của người dùng. Chúng tôi tạo một chỉ mục cá nhân cho mỗi người dùng, nó bao gồm các lớp có độ đồng thuận khác nhau để phản ánh khoái cảm cá nhân của mỗi người dùng trong AI đối thoại. Hệ thống cá nhân của chúng tôi chứa các lớp phục hồi và xếp hạng. Sự huấn luyện các mẫu không cần dữ liệu ghi chú bằng tay. Thử nghiệm trên bộ thử nghiệm cá nhân cho thấy hệ thống QR riêng của chúng tôi có khả năng sửa sai hệ thống có hệ thống có tính to án và người dùng bằng cách sử dụng nội dung ngữ âm.', 'nl': 'Query herschrijven (QR) is een opkomend onderdeel in conversationele AI-systemen, waardoor gebruikersfouten worden verminderd. Gebruikfout wordt veroorzaakt door verschillende oorzaken, zoals fouten in het gesproken dialoogsysteem, taalfouten van gebruikers of hun verkorte taal. Veel van de gebruikersgebreken komen voort uit gepersonaliseerde factoren, zoals het spraakpatroon, dialect of voorkeuren van de gebruiker. In dit werk stellen we een gepersonaliseerd zoekgebaseerd QR framework voor, dat zich richt op automatische vermindering van gebruikersdefecten. We bouwen een gepersonaliseerde index voor elke gebruiker, die verschillende affiniteitslagen omvat om persoonlijke voorkeuren voor elke gebruiker in de conversationele AI weer te geven. Ons gepersonaliseerde QR-systeem bevat retrieval- en rankingslagen. Ondersteund door gebruikersfeedback gebaseerd leren, vereist het trainen van onze modellen geen hand geannoteerde gegevens. Experimenten op gepersonaliseerde testset toonden aan dat ons gepersonaliseerde QR-systeem systematische en gebruikersfouten kan corrigeren door gebruik te maken van fonetische en semantische invoer.', 'bg': 'Пренаписването на заявка (QR) е нововъзникващ компонент в разговорните системи с изкуствен интелект, намалявайки дефектите на потребителя. Дефектът на потребителя се дължи на различни причини, като грешки в системата за говорен диалог, подхлъзване на езика на потребителя или съкратен език. Много от дефектите на потребителя произтичат от персонализирани фактори, като например модела на речта на потребителя, диалект или предпочитания. В тази работа предлагаме персонализирана базирана на търсене рамка, която се фокусира върху автоматично намаляване на потребителските дефекти. Създаваме персонализиран индекс за всеки потребител, който обхваща различни слоеве на афинитет, за да отразява личните предпочитания на всеки потребител в разговорния изкуствен интелект. Нашата персонализирана система съдържа слоеве за извличане и класиране. Подкрепена от обучение въз основа на обратна връзка от потребителите, обучението на нашите модели не изисква ръчно анотирани данни. Експерименти с персонализиран тест набор показаха, че нашата персонализирана система е в състояние да коригира систематични и потребителски грешки чрез използване на фонетични и семантични входове.', 'da': 'Query rewrite (QR) er en nyere komponent i konversationelle AI-systemer, der reducerer brugerfejl. Brugerfejl skyldes forskellige årsager, f.eks. fejl i det talte dialogsystem, brugerens tungeforskydning eller deres forkortede sprog. Mange af brugerfejlene stammer fra personlige faktorer, såsom brugerens talemønster, dialekt eller præferencer. I dette arbejde foreslår vi en personlig søgebaseret QR ramme, der fokuserer på automatisk reduktion af brugerfejl. Vi opbygger et personligt indeks for hver bruger, som omfatter forskellige affinitetslag for at afspejle personlige præferencer for hver bruger i den samtale AI. Vores personlige QR-system indeholder hentning og rangering lag. Understøttet af brugerfeedback baseret læring kræver træning af vores modeller ikke håndnoterede data. Eksperimenter med personlige testsæt viste, at vores personlige QR-system er i stand til at rette systematiske og brugerfejl ved at bruge fonetiske og semantiske input.', 'hr': 'Prepisanje ispitivanja (QR) je novi komponent u razgovornim AI sustavima, smanjujući poremećaj korisnika. Pobjeda korisnika uzrokuje različitim razlogom, poput grešaka u rečenom dijalogu, korisničkih klikova jezika ili njihovog proširenog jezika. Mnogi od korisnika poremećaja dolaze iz osobnih faktora, poput obrazaca govora korisnika, dijalekta ili preferencija. U ovom poslu predlažemo personalizirani okvir QR na potrazi, koji se fokusira na automatsko smanjenje poremećaja korisnika. Izgradimo osobni indeks za svakog korisnika, koji obuhvaća različite slojeve afinitnosti da odraže osobne preferencije svakog korisnika u razgovornom AI-u. Naš lični QR sustav sadrži povlačenje i redovne slojeve. Podržavaju učenje na temelju korisničkih povratka, obuka našeg modela ne zahtijeva podatke o kojima se nalaze ruke. Eksperimenti na nastavu personaliziranih testova pokazali su da naš personalizirani QR sustav može ispraviti sistemske i korisničke greške koristeći fonetičke i semantičke ulaze.', 'de': 'Query Rewrite (QR) ist eine neue Komponente in konversativen KI-Systemen, die Benutzerfehler reduziert. Benutzerfehler werden durch verschiedene Gründe verursacht, wie Fehler im gesprochenen Dialogsystem, Sprachfehler des Benutzers oder seine verkürzte Sprache. Viele der Benutzerfehler beruhen auf personalisierten Faktoren, wie Sprachmuster, Dialekt oder Vorlieben des Benutzers. In dieser Arbeit schlagen wir ein personalisiertes suchbasiertes QR-Framework vor, das sich auf die automatische Reduzierung von Benutzerfehlern konzentriert. Wir erstellen einen personalisierten Index für jeden Benutzer, der verschiedene Affinitätsebenen umfasst, um persönliche Präferenzen für jeden Benutzer in der dialogischen KI widerzuspiegeln. Unser personalisiertes QR-System enthält Retrieval- und Ranking-Layer. Unterstützt durch Benutzerfeedback-basiertes Lernen, erfordert das Training unserer Modelle keine manuell kommentierten Daten. Experimente an personalisierten Testsets zeigten, dass unser personalisiertes QR-System in der Lage ist, systematische Fehler und Benutzerfehler durch phonetische und semantische Eingaben zu korrigieren.', 'id': 'Penulisan ulang pertanyaan (QR) adalah komponen muncul dalam sistem AI konversasi, mengurangi kesalahan pengguna. Galat pengguna disebabkan oleh berbagai alasan, seperti kesalahan dalam sistem dialog berbicara, slips pengguna lidah atau bahasa singkat mereka. Banyak kesalahan pengguna berasal dari faktor pribadi, seperti pola pidato pengguna, dialekt, atau keutamaan. Dalam pekerjaan ini, kami mengusulkan rangkaian QR berasaskan pencarian pribadi, yang fokus pada pengurangan otomatis kesalahan pengguna. Kami membangun indeks pribadi untuk setiap pengguna, yang meliputi lapisan affinitas berbeda untuk merefleksikan keutamaan pribadi bagi setiap pengguna dalam AI konversasi. Sistem QR personalisasi kami mengandung lapisan penemuan dan rangkaian. Didukung oleh pembelajaran berbasis feedback pengguna, pelatihan model kita tidak membutuhkan data anotasi tangan. Eksperimen pada set tes pribadi menunjukkan bahwa sistem QR pribadi kita mampu memperbaiki kesalahan sistemik dan pengguna dengan menggunakan input fonetik dan semantik.', 'fa': 'بازنوشتن (QR) یک بخش پیدا می\u200cشود در سیستم\u200cهای AI مکالمه، کاهش شکست کاربر است. شکست کاربر به دلایل مختلف باعث می\u200cشود، مانند اشتباهی در سیستم گفتگو، قطعه\u200cهای کاربر زبان یا زبان خارج شده\u200cشان. بسیاری از کاربر ناتوانی از faktورهای شخصی به عنوان الگوی سخنرانی، دیالکت یا ترجیح کاربر است. در این کار، ما پیشنهاد می\u200cکنیم یک چهارچوب QR بر اساس جستجوی شخصی که روی کاهش خودکار شکست کاربر تمرکز می\u200cکند. ما یک نقشه شخصی برای هر کاربر ساختیم، که لایه\u200cهای مختلف پیوند\u200cهای مختلف را محیط می\u200cکند تا ترجیح\u200cهای شخصی برای هر کاربر در AI مکالمه نشان دهیم. سیستم QR شخصی ما دارای لایه\u200cهای دریافت و رشته\u200cگیری وجود دارد. پشتیبانی از طریق یادگیری بر پایه برخورد کاربر، آموزش مدل\u200cهای ما نیاز به داده\u200cهای مشخص دست ندارد. تجربه\u200cها در مجموعه آزمایش شخصی نشان دادند که سیستم QR شخصی ما می\u200cتواند اشتباه\u200cهای سیستماتیک و کاربر را درست کند با استفاده از ورودهای فونیک و semantic.', 'ko': '쿼리 리셋(Query Rewrite, QR)은 세션 인공지능 시스템의 신흥 구성 요소로 사용자의 결함을 줄일 수 있다.사용자의 결함은 여러 가지 원인으로 인해 발생한다. 예를 들어 구어 대화 시스템의 오류, 사용자의 말실수, 또는 그들의 간략한 언어 등이다.많은 사용자의 결함은 개성화된 요소, 예를 들어 사용자의 음성 모델, 사투리 또는 선호에서 비롯된다.이 작업에서 우리는 개성화된 검색을 바탕으로 하는 QR 프레임워크를 제시했는데 그 중점은 사용자의 결함을 자동으로 줄이는 것이다.우리는 모든 사용자를 위해 개성화된 색인을 구축했는데 그 중에서 서로 다른 친화층을 포함하여 대화 인공지능에서 모든 사용자의 개인적인 선호도를 반영한다.Google의 맞춤형 QR 시스템은 검색과 순위층을 포함합니다.사용자 피드백을 바탕으로 하는 학습 지원 아래 우리 모델을 훈련할 때 수동으로 데이터를 표시할 필요가 없다.개성화된 테스트 집합에서의 실험에 의하면 우리의 개성화된 QR시스템은 음성과 의미 입력을 이용하여 시스템 오류와 사용자 오류를 바로잡을 수 있다.', 'tr': "Mazmunlar AI sistemlerinde yzyna ýazmak üçin soragy (QR) aýratyn bir komponentdir. Ullançy ýeteniň näçe sebäpleriň sebäbi, gepleşen dijalog sisteminde ýalňyşlyklar, dilleriniň ýada ýalňyşlyklarynyň düşürmeklerinden sebäbi bolar. Ullançylaryň köpüsi ýagdaýynyň şahsy faýllaryndan, isleýän çykyş nusgasyna, dialekte ýa-da tercihleri. Bu işde biz şahsy bir gözlemäge tabanly QR çerçevesini teklip edip, ullançylaryň arzuwyny otomatik ýitirmegine üns berýäris. Biz her Ullançy üçin şahsy bir indeks in şa edýäris, we bu çeşitli affinity katlamalary paýlaşýar, soňlaşma AI'de her Ullançy üçin şahsy tercihleri näbelli etmek üçin. Biziň şahsy QR sistemimiz gaýd etmek we düzümlenmeklerimiz bar. Ullançylaryň feedback öwrenmeleri tarapyndan desteklenýän, nusgalarymyzy öwrenmelerimiz elimizde näbelli maglumatlary gerek däl. Şahsy testiň düzümleriniň denetimleri biziň şahsy QR sistemimiziň fonetik we semantik girişlerini ulanyp sistematik we ullançylaryň hatalaryny dogryşdyryp biljekdigini görkezildi.", 'af': "Navraag herskryf (QR) is 'n opkommende komponent in gesprekslyn AI stelsels, verduur gebruiker defekte. Gebruiker-defekte is veroorsaak deur verskeie redes, soos foute in die gespreek dialoog stelsel, gebruikers se slippe van die taal of hulle uitgebreekte taal. Baie van die gebruiker ontbreek van persoonlike faktore, soos gebruiker se sprekkpatroon, dialekte of voorkeure. In hierdie werk voorstel ons 'n persoonlike soektog-gebaseerde QR raamwerk wat fokus op automatiese reduksie van gebruiker-defekte. Ons bou 'n persoonlike indeks vir elke gebruiker, wat verskeie affinities laag omsluit om persoonlike voorkeure vir elke gebruiker te reflekteer in die gesprekslys AI. Ons persoonlike QR stelsel bevat ontvanging en ranking lagte. Ondersteun deur gebruiker terugmelding gebaseerde leer, onderriging van ons modele benodig nie hand- annotated data nie. Eksperimente op persoonlike toets stel het vertoon dat ons persoonlike QR stelsel kan korrigeer systematiese en gebruiker foute deur die gebruik van fonetiese en semantiese inputs.", 'sw': 'Swali upya kuandika (QR) ni kitengele kinachotokea katika mfumo wa mazungumzo ya AI, kupunguza tatizo la mtumiaji. Tatizo la mtumiaji linasababishwa na sababu mbalimbali, kama vile makosa katika mfumo wa mazungumzo yanayozungumzwa, vifo vya watumiaji vya lugha au lugha yao iliyovunjwa. Matukio mengi ya watumiaji yanatokana na sababu binafsi, kama namna ya hotuba ya mtumiaji, utambulisho, au upendeleo. Katika kazi hii, tunapendekeza mfumo wa utafutaji binafsi wa QR, ambao unajikita kwenye kupunguza tatizo lazima la mtumiaji. Tunajenga index binafsi kwa kila mtumiaji, ambayo inajumuisha vipande mbalimbali vya mahusiano ili kutafakari upendeleo binafsi kwa kila mtumiaji katika AI ya mazungumzo. Mfumo wetu binafsi wa QR una vipande vya kupatikana na viwango vya juu. Inaungwa mkono na mwitikio wa mtumiaji wa kujifunza kwa msingi wa kujifunza, kufundisha mifano yetu haihitaji taarifa zinazotokana na mikononi. Majaribio kwenye seti ya jaribio binafsi yalionyesha kuwa mfumo wetu binafsi wa QR unaweza kuhakikisha makosa ya mfumo na watumiaji kwa kutumia vipengele vya simu na sekunde vya kimapenzi.', 'hy': 'Խոսակցության ԱԲ համակարգերի զարգացող բաղադրիչ է, որը նվազեցնում է օգտագործողի թերությունը: Օգտագործողի սխալը պատճառ է տալիս բազմաթիվ պատճառներից, ինչպիսիք են արտահայտված հաղորդակցման համակարգի սխալները, օգտագործողների լեզուների սխալները կամ նրանց կարճ լեզուները: Օգտագործողների բազմաթիվ թերություններ առաջացնում են անձնական գործոններից, ինչպիսիք են օգտագործողի խոսքի կաղապարը, դիալեկտը կամ նախընտրությունները: Այս աշխատանքի ընթացքում մենք առաջարկում ենք անձնական որոնման հիմնված QR շրջանակ, որը կենտրոնանում է օգտագործողի թերության ավտոմատիկ նվազեցման վրա: Մենք յուրաքանչյուր օգտագործողի համար անձնական ինդեքս ենք կառուցում, որը ներառում է բազմազան հարաբերությունների շերտեր, որոնք արտացոլում են յուրաքանչյուր օգտագործողի անձնական նախընտրությունները խոսակցական ԱԲ-ում Մեր անձնական QR համակարգը պարունակում է վերադարձման և դասակարգման շերտեր: Օգտագործողների հետ կապված ուսումնասիրությամբ աջակցված, մեր մոդելների ուսումնասիրությունը չի պահանջում ձեռքով գրված տվյալներ: Հանձնական փորձարկումները ցույց տվեցին, որ մեր անձնական QR համակարգը կարողանում է ուղղել սիստեմատիկ և օգտագործողի սխալները՝ օգտագործելով ֆոնետիկ և սեմանտիկ ներմուծներ:', 'bn': 'আলোচনায় AI সিস্টেমে পুনরায় লেখা (QR) একটি উদ্ভাবনী অংশ, যা ব্যবহারকারীর সমস্যা কমিয়ে দেয়। ব্যবহারকারীর বিভিন্ন কারণে ব্যবহারকারীর সমস্যা হয়, যেমন কথোপকথনীয় ডায়ালগ সিস্টেম, ব্যবহারকারীদের ভাষার স্লিপ অথবা তাদের অপসা ব্যবহারকারীদের অনেকেই ব্যক্তিগত কারখানা থেকে ব্যক্তিগত ব্যবহারকারীর ভাষণের প্যাটার, ডায়ালেক্টর অথবা পছন্দের মত। এই কাজে আমরা ব্যক্তিগত অনুসন্ধান-ভিত্তিক কিউ আর ফ্রেম্যাকারের প্রস্তাব করছি, যা ব্যবহারকারীর দুর্ঘটনার উপর স্বয়ংক্রিয় কমা আমরা প্রত্যেক ব্যবহারকারীর জন্য একটি ব্যক্তিগত সূচী তৈরি করি, যা বিভিন্ন সংশ্লিষ্ট স্তরের মধ্যে রয়েছে যাতে আলোচনায় এ-এ প্রত্যেক আমাদের ব্যক্তিগত কিআর সিস্টেমের মধ্যে পুনরুদ্ধার এবং রেঙ্কিং লেখা আছে। ব্যবহারকারীদের ফিডব্যাক ভিত্তিক শিক্ষা দ্বারা সমর্থিত, আমাদের মডেলের প্রশিক্ষণ প্রদান করার প্রয়োজনীয় হাত Experiments on personalized test set showed that our personalized QR system is able to correct systematic and user errors by utilizing phonetic and semantic inputs.', 'sq': "Pyetja e rishkrimit (QR) është një komponent në rritje në sistemet conversational AI, duke reduktuar difektin e përdoruesit. Gabimi i përdoruesit shkaktohet nga arsye të ndryshme, të tilla si gabimet në sistemin e dialogut të folur, rrëshqitjet e përdoruesve të gjuhës ose gjuhën e shkurtër të tyre. Many of the user defects stem from personalized factors, such as user's speech pattern, dialect, or preferences.  Në këtë punë, propozojmë një kuadër QR të personalizuar bazuar në kërkim, i cili përqëndrohet në reduktimin automatik të defektit të përdoruesit. Ne ndërtojmë një indeks personalizuar për çdo përdorues, i cili përfshin shtresa të ndryshme afiniteti për të pasqyruar preferencat personale për çdo përdorues në AI bisedë. Sistemi ynë i personalizuar QR përmban shtresa të marrjes dhe renditjes. Mbështetur nga mësimi bazuar në përgjigjet e përdoruesve, trajnimi i modeleve tona nuk kërkon të dhëna të anotuara me dorë. Eksperimentet në grupin e testeve personalizuar treguan se sistemi ynë i personalizuar QR është në gjendje të korrigjojë gabimet sistematike dhe të përdoruesve duke përdorur inputs fonetike dhe semantike.", 'am': 'ጥያቄ እንደገና ይጻፍ (QR) የተጠቃሚ አካባቢ ሆኖ በአካባቢው AI ስርዓት ውስጥ ሲያሳየፍ ተጠቃሚ ስህተት ነው። የተጠቃሚ ስህተት፣ የቋንቋ ቋንቋ ወይም የተጠቃሚ ቋንቋቸው በመስመር ውስጥ ስህተት ነው፡፡ የተጠቃሚ ስህተቶች ብዙዎች እንደተጠቃሚ ንግግር ምሳሌ፣ dialect ወይም ምርጫዎች የሚቆጠሩ የራሳቸው ጉዳዮች ናቸው፡፡ በዚህ ስራ፣ የተለየ የQR ፍሬም የተመሳሳይ የሆኑት የጥያቄውን ስህተት በራሱ አካባቢ የሚያሳስል ነው፡፡ ለሁሉም ተጠቃሚዎች የአ.আই.ን ለመመለስ የራሳቸውን ምርጫዎች ለማሳየት የግልኙነት ደረጃዎችን ለሚያነካው የራሳቸውን ማውጫ እናደርጋለን፡፡ የኩነቶች የኩነታችን የQR ስርዓት መግቢያ እና ደረጃዎች ውስጥ ነው፡፡ በተጠቃሚ feedback በማስተማር የተደገመ፣ ሞዴላዎቻችንን ለማስተማር እጃቸውን ማሳሰል አያስፈልጋቸውም፡፡ የግልኙነት ፈተና ማሰናከል የQR ስርዓታችን የስህተት እና የተጠቃሚ ስህተቶችን በመጠቀም የፎኔት እና የsemantic inputs በመጠቀም ይችላል፡፡', 'az': 'Yenidən yazma (QR) müzakirçi AI sistemlərində yenidən yazılan komponentdir, istifadəçilərin zəifliyini azaltır. İstifadəçilərin xətası müxtəlif səbəbləri ilə, danışılmış диалог sistemində xətalar, dillərin və dillərinin qırılması kimi istifadəçilərin qırılmasına sebeb olar. İstifadəçilərin çoxunu kişisel faktörlərdən, istifadəçilərin s öz örtüsü, dialekti və ya seçimləri kimi, təhsil edilmiş faktörlərdən gəlir. Bu işdə, biz kişisel bir QR qurğusu təklif edirik ki, istifadəçilərin təhlükəsizliklərini avtomatik düşürməyə odaqlanır. Biz hər istifadəçi üçün kişisel bir indeks in şa edirik ki, bu hər istifadəçin in müzakirçi AI-nin kişisel seçimlərini təmsil etmək üçün müxtəlif affinity katları ilə birləşdirir. Şahsiyyətli QR sistemimiz alış və səf-səf düzümləri içərir. İstifadəçilərin feedback təhsil edilən öyrənməsi, modellərimizi təhsil etmək əl-annotated məlumatlarına ehtiyacı yoxdur. Şahsiyleştirilmiş sınama quruluşunda təcrübələrimiz QR sistemimizin fonetik və semantik inputləri istifadə edərək sistematik və istifadəçi hatalarını düzəltə biləcəyini göstərdi.', 'bs': 'Prepisanje ispitivanja (QR) je novi komponent u razgovornim AI sistemima, smanjujući poremećaj korisnika. Nedostatak korisnika uzrokuje različitim razlogom, poput grešaka u rečenom dijalogu, korisničkih komada jezika ili njihovog proširenog jezika. Mnogi od korisnika nedostaju iz osobnih faktora, poput obrazaca govora korisnika, dijalekta ili preferencija. U ovom poslu predlažemo personalizirani okvir QR na pretraživanju, koji se fokusira na automatsko smanjenje poremećaja korisnika. Napravili smo lični indeks za svakog korisnika, koji obuhvaća različite slojeve afinitnosti da odraže lične preferencije svakog korisnika u razgovornom AI-u. Naš lični QR sistem sadrži preuzimanje i redovne slojeve. Podržavaju učenje na osnovu reakcije korisnika, obuka našeg modela ne zahtijeva podatke s rukama. Eksperimenti na setu personalizovanih testova pokazali su da naš personalizovan QR sistem može ispraviti sistemske i korisničke greške koristeći fonetičke i semantične ulaze.', 'ca': "La reescripció de la consulta (QR) és un component emergent en els sistemes d'AI conversacionals, reduint el defecte de l'usuari. El defecte de l'usuari és causat per diverses raons, com els errors en el sistema de diàleg parlat, els esboços de la llengua dels usuaris o la seva llengua abreviada. Molts dels defectes de l'usuari provienen de factors personalitzats, com el patró de la fala, el dialecte o les preferències de l'usuari. En aquest treball, proposem un marc QR personalitzat basat en la recerca, centrat en la reducció automàtica del defecte de l'usuari. Construim un índex personalitzat per cada usuari, que inclou diverses capes d'afinitat per reflexionar les preferències personals per cada usuari a l'AI de conversació. El nostre sistema QR personalitzat conté capes de recuperació i classificació. Suportat per l'aprenentatge basat en el feedback dels usuaris, formar els nostres models no requereix dades anotates a mà. Els experiments en un conjunt de proves personalitzats van demostrar que el nostre sistema QR personalitzat és capaç de corregir errors sistemàtics i d'usuari utilitzant entrades fonètiques i semàntiques.", 'cs': 'Přepis dotazů (QR) je vznikající součástí konverzačních systémů AI, která snižuje vady uživatele. Vada uživatele je způsobena různými důvody, jako jsou chyby v mluveném dialogovém systému, uklouznutí jazyka uživatele nebo jejich zkrácený jazyk. Mnoho z vad uživatele vychází z personalizovaných faktorů, jako je vzor řeči uživatele, dialekt nebo preference. V této práci navrhujeme personalizovaný QR framework založený na vyhledávání, který se zaměřuje na automatické snížení vad uživatele. Pro každého uživatele vytváříme personalizovaný index, který zahrnuje různé vrstvy afinity, aby odrážel osobní preference každého uživatele v konverzační AI. Náš personalizovaný QR systém obsahuje vyhledávací a hodnocení vrstvy. Školení našich modelů podporované učením založeným na zpětné vazbě uživatelů nevyžaduje ručně anotovaná data. Experimenty na personalizované testovací sadě ukázaly, že náš personalizovaný QR systém je schopen opravit systematické a uživatelské chyby pomocí fonetických a sémantických vstupů.', 'et': 'Päringu ümberkirjutamine (QR) on tekkinud komponent vestluslikes AI süsteemides, vähendades kasutajate defekte. Kasutaja defekti põhjustavad mitmesugused põhjused, näiteks vead kõnelevas dialoogisüsteemis, kasutaja keeleliigutus või lühendatud keel. Paljud kasutaja defektid tulenevad isikupärastatud teguritest, näiteks kasutaja kõnemustrist, murdest või eelistustest. Selles töös pakume välja isikupärastatud otsingupõhise QR raamistiku, mis keskendub kasutajadefektide automaatsele vähendamisele. Loome iga kasutaja jaoks isikupärastatud indeksi, mis hõlmab erinevaid afiinsuskihti, et kajastada iga kasutaja isiklikke eelistusi vestluslikus AI-s. Meie isikupärastatud QR süsteem sisaldab tagasivõtmise ja järjestamise kihte. Kasutajate tagasisidepõhise õppe toel ei nõua meie mudelite koolitamine käsitsi märgitud andmeid. Personaliseeritud testikomplekti katsed näitasid, et meie personaalne QR-süsteem suudab korrigeerida süstemaatilisi ja kasutaja vigu foneetiliste ja semantiliste sisendite abil.', 'fi': 'Kyselyn uudelleenkirjoittaminen (QR) on kehittyvä komponentti keskusteluissa tekoälyjärjestelmissä, joka vähentää käyttäjän vikoja. Käyttäjävika johtuu erilaisista syistä, kuten puhejärjestelmän virheistä, kielen lipsahduksista tai lyhennetystä kielestä. Monet käyttäjän virheistä johtuvat henkilökohtaisista tekijöistä, kuten käyttäjän puhekuviosta, murteesta tai mieltymyksistä. Tässä työssä ehdotamme personoitua hakuun perustuvaa QR-kehystä, joka keskittyy käyttäjävikojen automaattiseen vähentämiseen. Rakennamme jokaiselle käyttäjälle personoidun indeksin, joka sisältää erilaisia affinity-tasoja, jotka heijastavat jokaisen käyttäjän henkilökohtaisia mieltymyksiä keskustelutekoälyssä. Henkilökohtainen QR-järjestelmämme sisältää nouto- ja ranking-tasoja. Käyttäjäpalautepohjaisen oppimisen tuella malliemme kouluttaminen ei vaadi käsin merkittyä dataa. Henkilökohtaisella testisarjalla tehdyt kokeet osoittivat, että henkilökohtainen QR-järjestelmämme pystyy korjaamaan systemaattisia ja käyttäjävirheitä foneettisten ja semanttisten syötteiden avulla.', 'jv': 'Perintah Ngubah (qR) kang kompon sing paling nang sistem AI conversationr, ngregan batir pangan Awak Devhelp user Nang barêng-barêng iki, kita supoyo perusahaan kanggo nyakakipon mulasai, yen ambem nggawe barang nggawe barang nggunakake tresno. Awak dhéwé nggawe indeks persoenlike kanggo saben pengguna, sing kompleh akeh luwih karbot gak nggawe perintah pengguna kanggo nguasai nggo saben pengguna nêmên AI conversations. Tuwe Perintah-Ngerawat Tomorrow\\u2003%l:%M %p" --> "Tomorrow 1:00 PM Gebudhakan peringatan karo peringatan surat sing bisa mlebu nang sistem perusahaan KR sing bisa nguasai sistem sistem lan gambaran eror tentang karo iso nggunakake inputs teletiki lan sematik.', 'he': "כתב מחדש של שאלות (QR) הוא רכיב מתפתח במערכות AI שיחה, להפחית פגם משתמש. User defect is caused by various reasons, such as errors in the spoken dialogue system, users' slips of the tongue or their abridged language.  רבים מהפגיעות של המשתמשים מגיעים מגורמים אישיים, כמו דפוס הנאום של המשתמש, דיאלקט, או העדיפות. בעבודה הזו, אנו מציעים מסגרת QR מבוססת חיפוש אישית, שמתמקדת על הפחות אוטומטית של פגם משתמש. אנו בונים אינדיקס אישי לכל משתמש, שמכיל שכבות חיוביות מגוונות כדי לשקף עדיפות אישיות לכל משתמש ב AI השיחה. מערכת QR האישית שלנו מכילה שכבות גילוי ודרגה. תומך על ידי לימוד מבוסס על תשובה משתמשת, האימונים הדוגמנים שלנו לא דורשים נתונים משותפים ביד. ניסויים על קבוצת בדיקות אישית הראו כי מערכת QR האישית שלנו מסוגלת לתקן טעויות מערכתיות ומשתמשים על ידי השימוש בתכניות פונטיות וסמנטיות.", 'sk': 'Prepis poizvedbe (QR) je nastajajoča komponenta v pogovornih sistemih AI, ki zmanjšuje napake uporabnikov. Napako uporabnika povzročajo različni razlogi, kot so napake v govorjenem dialogu, uporabnikovi zdrsi jezika ali skrajšani jezik. Mnoge napake uporabnikov izhajajo iz osebnih dejavnikov, kot so uporabnikov govorni vzorec, narečje ali preference. V tem delu predlagamo personaliziran QR okvir, ki temelji na iskanju, ki se osredotoča na samodejno zmanjšanje uporabniških napak. Za vsakega uporabnika zgradimo prilagojeni indeks, ki vključuje različne sloje afinitete, ki odražajo osebne preference za vsakega uporabnika v pogovorni AI. Naš osebni QR sistem vsebuje pridobivanje in razvrščanje plasti. Ob podpori učenja na podlagi povratnih informacij uporabnikov usposabljanje naših modelov ne zahteva ročno označenih podatkov. Eksperimenti na personaliziranem testnem naboru so pokazali, da je naš personalizirani QR sistem sposoben popraviti sistematične in uporabniške napake z uporabo fonetičnih in semantičnih vhodov.', 'ha': "@ action: button Yi sakar da mai amfani da shi don sababin daban, kamar misali masu cikin tsarin zauren akwatin bayanin da aka yi magana, sunayen mai amfani da shi ko lugha da aka ƙẽtare su. Many of the user defects stem from personalized factors, such as user's speech pattern, dialect, or preferences.  Daga wannan aikin, muna buƙata wani firam na search-based QR, wanda ke muhalli wa ƙarancin bayani na amfani da shi farat ɗaya. Munã samar wani index wanda ke da ɗabi'a wa mai amfani da shi, mai ƙunsa da zane-zane-zane-zane-zane-zane-zane-zane ga kowane mai amfani da shi cikin AI mai sauya. Tsarin QR na da ɗabi'a yana da riƙo da zane-zane. Yana ƙaranci da mai amfani da feedback a kan karatun, kuma yana amfani da misalinmu ba ya ƙayyade data da aka sanar da hannu ba. Tajararin da aka daidaita jarrabo na ɗabi'a ya nuna cewa na tsarin QR na kanana yana iya iya daidaita makorari na'ura da mai amfani da shi da ya yi amfani da inputi na fomat da semantic.", 'bo': 'Query rewrite (QR)ནི་གཏམ་གླེང་གླེང་སྒྲོམ་གྱི་མ་ལག་ནང་དུ་ཡར་རྒྱས་ཁབ་ཅིག་ཡིན་པ སྐད སྤྱོད་མཁན་གྱི་སྐྱོན་རུང་མང་པོ་ཞིག་ནི་སྒེར་གྱི་ཆ་རྐྱེན་པས་བཞག་མི་འདུག དཔེར་ན་སྤྱོད་མཁན་གྱི་སྐད་འཆར་ཆོས In this work, we propose a personalized search-based QR framework, which focuses on automatic reduction of user defect. ང་ཚོས་སྤྱོད་མཁན་རེ་རེར་སྤྱོད་མཁན་ལ་རང་བཟོས་པའི་ཟུར་ཐོ་ཞིག་བཟོ་བྱེད་ཀྱི་ཡོད་པ་དེ་འདྲ་བཟོ་བྱེད་པའི་རྣམ་གྲངས་སྒྲིག་འགོད་ ང་ཚོའི་རང་བཟོས་ཟིན་པའི་QR་མ་ལག་གིས་ལྟ་ཀློག་དང་རིམ་པ་གྱི་བང་རིམ་ཡོད་པ ལག་ལེན་པ་ལྟ་བུའི་སྐུལ་ལྟ་བུ་དང་རྒྱབ་སྐྱོར་བྱེད་པའི་སྤྱོད་མཁན་གྱི་ལྟ་བུ་དགོས་པ་མིན་འདུག རང་བཟོས་ཟིན་པའི་བརྟག'}
{'en': 'AuGPT : Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models', 'fr': 'AugPT\xa0: tâches auxiliaires et augmentation des données pour un dialogue de bout en bout avec des modèles linguistiques préformés', 'ar': 'AuGPT: المهام المساعدة وزيادة البيانات للحوار الشامل مع نماذج اللغة التي تم تدريبها مسبقًا', 'pt': 'AuGPT: Tarefas Auxiliares e Aumento de Dados para Diálogo de Ponta a Ponta com Modelos de Linguagem Pré-treinados', 'es': 'AuGPT: Tareas auxiliares y aumento de datos para el diálogo de principio a fin con modelos de lenguaje preentrenados', 'ja': 'AuGPT ：事前にトレーニングされた言語モデルを使用したエンドツーエンドの対話のための補助タスクとデータ拡張', 'zh': 'AuGPT:辅命益数,以对言端到端', 'hi': 'AuGPT: पूर्व-प्रशिक्षित भाषा मॉडल के साथ एंड-टू-एंड संवाद के लिए सहायक कार्य और डेटा संवर्धन', 'ru': 'AuGPT: Вспомогательные Задачи и Усиление Данных для End-To-End Диалога с Предварительно Обученными Языковыми Моделями', 'ga': 'Lúnasa: Tascanna Cúnta agus Méadú Sonraí le haghaidh Idirphlé Ceann go Deireadh le Múnlaí Teanga RéamhOilte', 'ka': '@ info', 'hu': 'AugPT: Kiegészítő feladatok és adatbővítés az előkészített nyelvi modellekkel végzett párbeszédhez', 'it': 'AugPT: attività ausiliarie e aumento dei dati per il dialogo end-to-end con modelli linguistici pre-formati', 'el': 'Βοηθητικές εργασίες και αύξηση δεδομένων για διάλογο με προσχεδιασμένα γλωσσικά μοντέλα', 'kk': 'AuGPT: Аяқтау- аяқтау диалогының көмегімен тапсырмалар мен деректерді көмектесу', 'lt': 'AuGPT: pagalbinės užduotys ir duomenų didinimas dialogui nuo pabaigos su išankstinio mokymo kalbos modeliais', 'mk': 'AuGPT: Помошни задачи и зголемување на податоците за дијалогот крај до крај со предобучени јазички модели', 'ms': 'AuGPT: Tugas Bantuan dan Pembesaran Data untuk Dialog Akhir-Ke-Akhir dengan Model Bahasa Latihan-Pra', 'ml': 'ഓജിപിടി: മുന്\u200dപ് പരിശീലന ഭാഷ മോഡലുകളോടൊപ്പം അവസാനിക്കുന്ന അവസാനത്തേക്കുള്ള കൂടുതല്\u200d ജോലികളും ഡേറ്റാ ഓഗ്മെന്റേഷനും', 'mn': 'AuGPT: Сургуулсан хэл загвартай төгсгөл-төгсгөлийн диалогын тусламжтай ажил, өгөгдлийн нэмэгдүүлэлт', 'mt': 'AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models', 'no': 'AuGPT: Hjelpeoppgåver og data- augmentasjon for sluttvindauget med føreøvinga språk- modeller', 'pl': 'AugPT: Zadania pomocnicze i rozszerzenie danych dla kompleksowego dialogu z przeszkolonymi modelami językowymi', 'ro': 'AugPT: Sarcini auxiliare și mărirea datelor pentru dialogul end-to-end cu modele lingvistice pre-instruite', 'sr': 'AuGPT: Pomoćni zadatak i povećanje podataka za dijalog za kraj do kraja sa predobučenim jezičkim modelima', 'si': '@ info', 'so': 'AuGPT: Shaqooyinka la xiriira iyo codsiga macluumaadka ee dhamaadka ee ku qoran dialogue-to-dhamaadka sameynta Models for Pre-Trained Luqada', 'sv': 'AugPT: Hjälpuppgifter och dataförstärkning för end-to-end dialog med förberedda språkmodeller', 'ta': 'AuGPT: முன்பு பயிற்சி மொழி மாதிரிகளுடன் முடிவு முடிவு உரையாடலுடன் கூட்டுதல் பணிகள் மற்றும் தரவு கூறுதல் ஒப்பிடுதல்', 'ur': 'AuGPT: پیش ترین زبان موڈل کے ساتھ End-to-End Dialog کے لئے مددگاری ٹاکس اور ڈیٹا اگنٹمنٹ', 'uz': 'AuGPT: Ta\xa0ľrifi qilingan tillar modellari bilan oxirish- to- oxirish oynasi uchun alohida vazifalar va ma\xa0ľlumot o\xa0Ľrnatish', 'vi': 'Hỗ trợ: Các thao tác phụ và gia tăng dữ liệu cho cuộc đối thoại cuối cùng với các mô hình ngôn ngữ', 'da': 'AugPT: Hjælpeopgaver og dataudvidelse til end-to-end dialog med før-uddannede sprogmodeller', 'bg': 'Допълнителни задачи и увеличаване на данни за диалог от край до край с предварително обучени езикови модели', 'hr': 'AuGPT: Pomoćni zadatak i povećanje podataka za dijalog kraja do kraja s predobučenim jezičkim modelima', 'ko': 'AuGPT: 사전에 훈련된 언어 모델을 통해 끝에서 끝까지 대화하는 보조 임무와 데이터 확충', 'nl': 'AugPT: Hulpstaken en Data Augmentation voor end-to-end dialoog met vooraf getrainde taalmodellen', 'de': 'AugPT: Hilfsaufgaben und Datenerweiterung für den End-to-End Dialog mit vortrainierten Sprachmodellen', 'id': 'AuGPT: Tugas Bantuan dan Pembesaran Data untuk Dialog Akhir-Untuk-Akhir dengan Model Bahasa Latihan-Pra', 'fa': 'AuGPT: کارهای کمک و افزایش داده برای محاورۀ پایان تا پایان با مدل های پیش آموزش زبان', 'sw': 'keyboard label', 'af': 'AuGPT: Assistiewe Opdragte en Data Augmentasie vir Einde- na- Einde dialoog met Voorgeoefende Taal Modelle', 'sq': 'AuGPT: Detyrat ndihmëse dhe rritja e të dhënave për dialogun përfundimtar me modelet e gjuhës së stërvitur para', 'tr': '彂䅒弊', 'am': 'AuGPT: ምርጫዎች', 'az': 'AuGPT: Ön-Eğitimli Dil Modelləri ilə End-to-End Dialog üçün Yardımcıl Göndərmələr və Veri Uygulaması', 'hy': 'AuGPT: Օգնական առաջադրանքներ և տվյալներ ավելացնելը վերջ-վերջ դասախոսության համար նախապատրաստված լեզվի մոդելների հետ', 'bn': 'অজিপিটি: পূর্ববর্তী প্রশিক্ষিত ভাষা মোডেল সহযোগিতা কাজ এবং ডাটা অ্যাগমেন্টেশন', 'cs': 'AugPT: Pomocné úkoly a rozšíření dat pro komplexní dialog s předškolenými jazykovými modely', 'ca': 'AuGPT: Tasks auxiliars i augmentació de dades per diàleg final a final amb models de llenguatge pré-entrenats', 'bs': 'AuGPT: Pomoćni zadatak i povećanje podataka za dijalog kraja do kraja sa predobučenim jezičkim modelima', 'fi': 'ApuGPT: Aputeht채v채t ja tietojen lis채채minen p채채st채 p채채h채n -vuoropuheluun esikoulutettujen kielimallien kanssa', 'et': 'AbiGPT: abiülesanded ja andmete lisamine lõpuni dialoogi jaoks eelõpetatud keelemudelitega', 'ha': 'KCharselect unicode block name', 'sk': 'Pomožna opravila in podatkovno dopolnitev za celoten dialog z vnaprej usposobljenimi jezikovnimi modeli', 'he': 'AuGPT: משימות נועדות וגדלת נתונים לדיולוג סוף-סוף עם דוגמני שפה מאומנים מראש', 'jv': 'Language', 'bo': 'AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialog with Pre-Trained Language Models'}
{'en': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via ', 'pt': 'Modelos de linguagem pré-treinados baseados em atenção, como o GPT-2, trouxeram um progresso considerável para a modelagem de diálogo de ponta a ponta. No entanto, eles também apresentam riscos consideráveis para o diálogo orientado para a tarefa, como falta de base de conhecimento ou diversidade. Para resolver esses problemas, introduzimos objetivos de treinamento modificados para ajuste fino do modelo de linguagem e empregamos o aumento maciço de dados por meio de tradução reversa para aumentar a diversidade dos dados de treinamento. Examinamos ainda as possibilidades de combinar dados de várias fontes para melhorar o desempenho no conjunto de dados de destino. Avaliamos cuidadosamente nossas contribuições com métodos humanos e automáticos. Nosso modelo supera substancialmente a linha de base nos dados do MultiWOZ e mostra um desempenho competitivo com o estado da arte em avaliação automática e humana.', 'ar': 'حققت النماذج اللغوية المدربة مسبقًا والقائمة على الانتباه مثل GPT-2 تقدمًا كبيرًا في نمذجة الحوار من طرف إلى طرف. ومع ذلك ، فإنها تمثل أيضًا مخاطر كبيرة للحوار الموجه نحو المهام ، مثل الافتقار إلى أسس المعرفة أو التنوع. لمعالجة هذه المشكلات ، نقدم أهدافًا تدريبية معدلة لضبط نموذج اللغة ، ونستخدم زيادة هائلة في البيانات عبر الترجمة العكسية لزيادة تنوع بيانات التدريب. ندرس كذلك إمكانيات دمج البيانات من مصادر متعددة لتحسين الأداء على مجموعة البيانات المستهدفة. نقوم بتقييم مساهماتنا بعناية بالطرق البشرية والآلية. يتفوق نموذجنا بشكل كبير على خط الأساس لبيانات MultiWOZ ويظهر أداءً تنافسيًا مع أحدث ما توصلت إليه التكنولوجيا في كل من التقييم الآلي والبشري.', 'fr': "Les modèles de langage pré-entraînés basés sur l'attention, tels que GPT-2, ont permis des progrès considérables dans la modélisation de dialogue de bout en bout. Cependant, ils présentent également des risques considérables pour le dialogue axé sur les tâches, tels que le manque de connaissances ou de diversité. Pour résoudre ces problèmes, nous introduisons des objectifs de formation modifiés pour le peaufinage des modèles linguistiques, et nous utilisons une augmentation massive des données via la rétro-traduction pour augmenter la diversité des données de formation. Nous examinons également les possibilités de combiner des données provenant de sources multiples afin d'améliorer les performances sur l'ensemble de données cible. Nous évaluons soigneusement nos contributions à l'aide de méthodes humaines et automatiques. Notre modèle surpasse largement la base de référence sur les données MultiWOZ et affiche des performances compétitives avec des performances de pointe en matière d'évaluation automatique et humaine.", 'es': 'Los modelos lingüísticos preentrenados basados en la atención, como GPT-2, aportaron un progreso considerable al modelado de diálogo de extremo a extremo. Sin embargo, también presentan riesgos considerables para el diálogo orientado a las tareas, como la falta de base de conocimientos o la diversidad. Para abordar estos problemas, introducimos objetivos de capacitación modificados para el ajuste del modelo lingüístico y empleamos el aumento masivo de datos mediante la retrotraducción para aumentar la diversidad de los datos de capacitación. Examinamos más a fondo las posibilidades de combinar datos de múltiples fuentes para mejorar el rendimiento en el conjunto de datos objetivo. Evaluamos cuidadosamente nuestras contribuciones con métodos humanos y automáticos. Nuestro modelo supera sustancialmente el rendimiento de referencia en los datos de MultiWoz y muestra un rendimiento competitivo con lo último en evaluación automática y humana.', 'ja': 'GPT -2などの注意に基づく事前訓練された言語モデルは、エンドツーエンドの対話モデリングにかなりの進歩をもたらした。しかし、これらはまた、知識の欠如や多様性の欠如など、タスク指向の対話にかなりのリスクをもたらします。これらの問題に対処するために、言語モデル微調整のための修正されたトレーニング目標を導入し、トレーニングデータの多様性を高めるために、バック翻訳を介した大規模なデータ拡張を採用しています。さらに、複数のソースからのデータを組み合わせて、ターゲットデータセットのパフォーマンスを向上させる可能性を検討します。私たちは、人間と自動の両方の方法を使用して、私たちの貢献を慎重に評価します。当社のモデルは、MultiWOZデータのベースラインを大幅に上回り、自動評価と人間評価の両方で最先端のパフォーマンスと競争力のあるパフォーマンスを示しています。', 'zh': '盖注意之预训言语模样(如 GPT-2)端对建模大致进展。 然亦为之大险,如乏知多样性。 入其言而微调训练之,反海量其数以益其多样性。 更加研究了数源的数据以高的数据集性能。 我因人工与自术细评我。 形于MultiWOZ数,大优于基线,显于自与人工评量,以见先进水平之竞。', 'hi': 'जीपीटी -2 जैसे ध्यान-आधारित पूर्व-प्रशिक्षित भाषा मॉडल ने एंड-टू-एंड डायलॉग मॉडलिंग में काफी प्रगति की। हालांकि, वे कार्य-उन्मुख संवाद के लिए काफी जोखिम भी पेश करते हैं, जैसे कि ज्ञान ग्राउंडिंग या विविधता की कमी। इन मुद्दों को हल करने के लिए, हम भाषा मॉडल finetuning के लिए संशोधित प्रशिक्षण उद्देश्यों को पेश करते हैं, और हम प्रशिक्षण डेटा की विविधता को बढ़ाने के लिए बैक-अनुवाद के माध्यम से बड़े पैमाने पर डेटा वृद्धि को नियोजित करते हैं। हम लक्ष्य डेटासेट पर प्रदर्शन में सुधार करने के लिए गुणक स्रोतों से डेटा के संयोजन की संभावनाओं की आगे जांच करते हैं। हम मानव और स्वचालित दोनों तरीकों के साथ हमारे योगदान का सावधानीपूर्वक मूल्यांकन करते हैं। हमारा मॉडल MultiWOZ डेटा पर बेसलाइन को काफी हद तक बेहतर बनाता है और स्वचालित और मानव मूल्यांकन दोनों में कला की स्थिति के साथ प्रतिस्पर्धी प्रदर्शन दिखाता है।', 'ru': 'Основанные на внимании заранее подготовленные языковые модели, такие как GPT-2, принесли значительный прогресс в моделирование сквозного диалога. Вместе с тем они также сопряжены со значительными рисками для ориентированного на решение конкретных задач диалога, такими, как отсутствие знаний или разнообразие. Чтобы решить эти проблемы, мы вводим модифицированные цели обучения для тонкой настройки языковой модели, и мы используем массовое увеличение данных посредством обратного перевода для увеличения разнообразия данных обучения. Мы далее изучаем возможности объединения данных из множественных источников для повышения эффективности целевого набора данных. Мы тщательно оцениваем свой вклад как человеческими, так и автоматическими методами. Наша модель существенно превосходит базовую линию по данным MultiWOZ и демонстрирует конкурентоспособную производительность по сравнению с современным уровнем как в автоматической, так и в человеческой оценке.', 'ga': 'Rinne samhlacha teanga réamhoilte aird-bhunaithe mar GPT-2 dul chun cinn suntasach ar shamhaltú idirphlé ceann go ceann. Mar sin féin, tá rioscaí suntasacha ag baint leo freisin maidir le hidirphlé tasc-dhírithe, amhail easpa bonn eolais nó éagsúlachta. Chun dul i ngleic leis na saincheisteanna seo, tugaimid isteach cuspóirí oiliúna modhnaithe le haghaidh mionchoigeartú na múnlaí teanga, agus úsáidimid méadú ollmhór ar shonraí trí aisaistriúchán chun éagsúlacht na sonraí oiliúna a mhéadú. Scrúdaímid tuilleadh na féidearthachtaí a bhaineann le sonraí ó fhoinsí iolracha a chomhcheangal chun feidhmíocht ar an sprioc-thacar sonraí a fheabhsú. Déanaimid meastóireacht chúramach ar ár ranníocaíochtaí le modhanna daonna agus uathoibríocha araon. Is fearr go mór ár múnla ná an bonnlíne ar shonraí MultiWOZ agus taispeánann sé feidhmíocht iomaíoch le scoth na meastóireachta uathoibríocha agus daonna araon.', 'ka': 'დაახლოებით უფრო დარწმუნებული ენის მოდელები, როგორც GPT- 2, მივიღეთ მნიშვნელოვანი პროგრესი დასასრულებელი დიალოგის მოდელებისთვის. მაგრამ, ისინი ასევე მნიშვნელოვანი რისკები იყენებენ რაოდენობით განსაზღვრებული დიალოგისთვის, როგორც ცნობიერების განსაზღვრება ან განსხვავება ამ პრობლემების შესახებ, ჩვენ დავიყენებთ განახლებული საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი მო ჩვენ შევხედავთ მონაცემების შესაძლებლობა მონაცემების შესაძლებლობა გამრავლებული მრავალისგან გამრავლებული ფუნქტების შესაძლებლობა მიზეზეზეზის მონა ჩვენ ყველაზე ადამიანის და ავტომატიკური მეტისთვის ჩვენი დამატებულებების გავამუშავებთ. ჩვენი მოდელი ძალიან უფრო მეტად უფრო მეტად გავაკეთება MultiWOZ მონაცემებისთვის და გამოჩვენება კონსპექტიური გავაკეთებას სურათის სტაციას და ადამიანის გავა', 'el': 'Τα προ-εκπαιδευμένα γλωσσικά μοντέλα με βάση την προσοχή, όπως το GPT-2, έφεραν σημαντική πρόοδο στη μοντελοποίηση ολοκληρωμένου διαλόγου. Ωστόσο, παρουσιάζουν επίσης σημαντικούς κινδύνους για διάλογο προσανατολισμένο στα καθήκοντα, όπως η έλλειψη θεμελίωσης της γνώσης ή η πολυμορφία. Για να αντιμετωπιστούν αυτά τα ζητήματα, εισάγουμε τροποποιημένους εκπαιδευτικούς στόχους για τον συντονισμό γλωσσικών μοντέλων και χρησιμοποιούμε μαζική αύξηση δεδομένων μέσω της αντίστροφης μετάφρασης για να αυξήσουμε την ποικιλομορφία των δεδομένων κατάρτισης. Εξετάζουμε περαιτέρω τις δυνατότητες συνδυασμού δεδομένων από πολλαπλές πηγές για τη βελτίωση της απόδοσης στο σύνολο δεδομένων-στόχων. Αξιολογούμε προσεκτικά τις συνεισφορές μας τόσο με ανθρώπινες όσο και με αυτόματες μεθόδους. Το μοντέλο μας ξεπερνά σημαντικά τη βάση δεδομένων και παρουσιάζει ανταγωνιστικές επιδόσεις με την τελευταία τεχνολογία τόσο στην αυτόματη όσο και στην ανθρώπινη αξιολόγηση.', 'hu': 'A figyelem alapú, előre képzett nyelvi modellek, mint például a GPT-2, jelentős előrelépést hoztak a végpontok közötti párbeszédmodellezés terén. Ugyanakkor jelentős kockázatokat jelentenek a feladatorientált párbeszéd szempontjából is, mint például a tudásalapítás hiánya vagy a sokszínűség. E kérdések megoldása érdekében módosított képzési célkitűzéseket vezetünk be a nyelvi modell finomhangolására, és jelentős adatbővítést alkalmazunk visszafordítással, hogy növeljük a képzési adatok sokféleségét. Továbbá megvizsgáljuk a többszörös forrásból származó adatok kombinálásának lehetőségeit a céladatok teljesítményének javítása érdekében. Gondosan értékeljük hozzájárulásainkat emberi és automatikus módszerekkel egyaránt. Modellünk lényegesen felülmúlja a MultiWOZ adatok alapját, és versenyképes teljesítményt mutat mind az automatikus, mind az emberi értékelésben.', 'it': "Modelli linguistici pre-formati basati sull'attenzione come GPT-2 hanno portato notevoli progressi nella modellazione end-to-end dei dialoghi. Tuttavia, essi presentano anche notevoli rischi per il dialogo orientato ai compiti, come la mancanza di conoscenze fondate o la diversità. Per affrontare questi problemi, introduciamo obiettivi formativi modificati per la messa a punto dei modelli linguistici e impieghiamo un'enorme aumento dei dati tramite la traduzione posteriore per aumentare la diversità dei dati formativi. Esaminiamo ulteriormente le possibilità di combinare dati provenienti da fonti multiple per migliorare le prestazioni sul set di dati target. Valutiamo attentamente i nostri contributi con metodi sia umani che automatici. Il nostro modello supera sostanzialmente la base dei dati MultiWOZ e mostra prestazioni competitive con lo stato dell'arte sia nella valutazione automatica che umana.", 'kk': 'GPT- 2 секілді, назардағы алдын- оқылған тіл үлгілері, соңғы- соңғы диалог модельдеріне маңызды жағдайды. Бірақ олар тапсырманың бағытталған диалогының маңызды тәуелдерін көрсетеді, мысалы, білім тәсілдері не әртүрлі тәуелдері жоқ. Бұл мәселелерді өзгерту мақсаттарын тіл үлгісінің кеңейту үшін өзгертілген оқыту мақсаттарын келтіреміз, және оқыту мәліметінің әртүрлігін өзгерту үшін қайта аудар Біз көптеген көптеген деректерді біріктіру мүмкіндігін мақсатты деректер жинағының жақсарту үшін тексереміз. Біз адамдардың және автоматты әдістеріміздің қатынасымызды тәжірибелерімізге тәжірибелейміз. Біздің үлгіміз көп WOZ деректерінің негізгі жолын өзгертіп, автоматты және адамдардың оқиғаларының күйінде әртүрлі жағдайды көрсетеді.', 'mk': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling.  However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity.  За да ги решиме овие прашања, воведуваме модификувани обукни цели за финетизирање на јазичкиот модел, и користиме масовно зголемување на податоците преку превод за зголемување на различноста на податоците за обука. Понатаму ги испитуваме можностите за комбинација на податоци од многутрински извори за подобрување на резултатите на наборот на податоци на целта. Внимателно ги проценуваме нашите придонеси со човечки и автоматски методи. Нашиот модел значително ја надминува основата на податоците од МултиВОЗ и покажува конкурентна резултатност со најсовремената во автоматска и човечка проценка.', 'ml': 'ജിപിടി- 2 പോലെ ശ്രദ്ധിക്കുന്നതിന്റെ അടിസ്ഥാനമായ മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലുകള്\u200d അവസാനിപ്പിക്കുന്നതിനായി  എങ്കിലും ജോലിയുള്ള സംസാരത്തിന് അവര്\u200dക്കും വളരെ അപകടം ഉണ്ടാക്കുന്നു. ജ്ഞാനത്തിന്റെ അഭിപ്രായം അല്ലെങ്കില്\u200d വ്യത് ഈ പ്രശ്നങ്ങളെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d ഭാഷ മോഡല്\u200d ഫിന്തൂണിനുള്ള പരിശീലനത്തിന്റെ ലക്ഷ്യങ്ങള്\u200d പരിശോധിക്കുന്നു. പിന്നീട് ട We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset.  മനുഷ്യനും സ്വയമായ രീതികളും കൊണ്ട് നമ്മുടെ പങ്കുകള്\u200d ശ്രദ്ധിച്ച് വിലാസപ്പെടുത്തുന്നു. നമ്മുടെ മാതൃകയാണ് മിടുട്ടുവോസ് ഡേറ്റായിട്ടുള്ള അടിസ്ഥാനത്ത് പ്രവര്\u200dത്തിപ്പിക്കുന്നത്. സ്വയമോട്ടിക്കും മനുഷ്യരുടെ വിലയി', 'mt': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling.  However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity.  Biex nindirizzaw dawn il-kwistjonijiet, aħna nintroduċu għanijiet ta’ taħriġ modifikati għall-irfinar tal-mudell lingwistiku, u aħna nużaw żieda massiva fid-dejta permezz ta’ traduzzjoni retrospettiva biex iżżidu d-diversità tad-dejta tat-taħriġ. Aħna neżaminaw aktar il-possibbiltajiet li ngħaqdu d-dejta minn sorsi multipli biex itejbu l-prestazzjoni fuq is-sett tad-dejta fil-mira. We carefully evaluate our contributions with both human and automatic methods.  Il-mudell tagħna huwa sostanzjalment ogħla mil-linja bażi tad-dejta MultiWOZ u juri prestazzjoni kompetittiva bl-aktar avvanzata kemm fl-evalwazzjoni awtomatika kif ukoll fil-bniedem.', 'mn': 'GPT-2 шиг анхаарал дээр сургалтын өмнө сургалтын хэл загварууд дуусгах диалог загварын төгсгөлд маш их хөгжлийг авч ирсэн. Гэхдээ тэд мөн ажил дээр ориентирогдсон диалогт маш их эрсдэлтэй байдаг. Яг л мэдлэгтэй суурь, олон төрлийн байдал байхгүй. Эдгээр асуудлуудыг олохын тулд бид хэл загварын төлөвлөгөөний төлөвлөгөөний өөрчлөгдсөн сургалтын зорилготой зорилготуудыг тайлбарлаж, бид эргэн хөрөнгө оруулахын тулд маш олон өгөгдлийн нэ Бид олон эх үүсвэрээс өгөгдлийг нэгтгэх боломжуудыг зорилготой өгөгдлийн сангийн үйл ажиллагааг сайжруулахын тулд судалж байна. Бид хүн болон автоматик аргаар өөрсдийнхөө хөрөнгө оруулалтыг анхаарлаа үнэлдэг. Бидний загвар нь олон ВОЗ өгөгдлийн суурь шугам дээр үндсэн, автоматик болон хүн төрөлхтний оюутнуудад урлагийн байдалтай өрсөлдөг үйл ажиллагааг харуулдаг.', 'pl': 'Wstępnie przeszkolone modele językowe oparte na uwadze, takie jak GPT-2, przyniosły znaczny postęp w modelowaniu dialogu końcowego. Stanowią one jednak również znaczne ryzyko dla dialogu ukierunkowanego na zadania, takie jak brak wiedzy lub różnorodność. Aby rozwiązać te problemy, wprowadzamy zmodyfikowane cele szkoleniowe w zakresie dostosowywania modelu językowego oraz wykorzystujemy masowe powiększanie danych poprzez tłumaczenie wsteczne, aby zwiększyć różnorodność danych szkoleniowych. Ponadto badamy możliwości łączenia danych z wielu źródeł w celu poprawy wydajności docelowego zbioru danych. Dokładnie oceniamy nasze wkłady zarówno metodami ludzkimi, jak i automatycznymi. Nasz model znacznie przewyższa bazę danych MultiWOZ i wykazuje konkurencyjność z najnowocześniejszą technologią zarówno w zakresie automatycznej, jak i ludzkiej oceny.', 'no': 'Førehandsvising-basert språk-modeller som GPT-2 har fått stor framgang til modellering av dialogvindauget for slutt-til-slutt. Dei viser likevel mykje mykje risiko for oppgåveorientert dialogvindauge, slik som mangling av kunnskapsgrunnlegging eller mangfolding. For å handtera desse problemene, introduserer vi endra opplæringsmålsettingar for språk-modellen finetuning, og vi bruker massivt opplæring av data gjennom tilbakeomsetjing for å øke mangfoldigheten av opplæringsdata. Vi undersøker meir mulighetene for å kombinere data frå multipliserer kjelder for å forbetra utviklinga på måldatasettet. Vi evaluerer både menneske og automatiske metodar våre bidrag. Vårt modell utfører grunnlinja på multiWOZ-dataene og viser konkurentivt utvikling med kunststanden i både automatisk og menneskelig evaluering.', 'ro': 'Modelele lingvistice pre-instruite bazate pe atenție, precum GPT-2, au adus progrese considerabile în modelarea dialogurilor end-to-end. Cu toate acestea, acestea prezintă, de asemenea, riscuri considerabile pentru dialogul orientat spre sarcini, cum ar fi lipsa de bază a cunoștințelor sau diversitatea. Pentru a aborda aceste probleme, introducem obiective modificate de instruire pentru finisarea modelului lingvistic și utilizăm mărirea masivă a datelor prin traducerea înapoi pentru a crește diversitatea datelor de instruire. Examinăm în continuare posibilitățile de a combina date din surse multiple pentru a îmbunătăți performanța setului de date țintă. Evaluăm cu atenție contribuțiile noastre atât cu metode umane, cât și cu metode automate. Modelul nostru depășește substanțial valoarea de referință a datelor MultiWOZ și arată performanțe competitive cu state of art atât în evaluarea automată, cât și în cea umană.', 'sr': 'Na temelju pažnje predobučeni jezički modeli poput GPT-2 donosili su značajan napredak u modelling dijaloga do kraja. Međutim, oni takođe predstavljaju značajne rizike za dijalog orijentiran na zadatke, kao što je nedostatak temelja znanja ili raznolikosti. Da bi se riješili ovim pitanjima, predstavljamo modificirane ciljeve obuke za finetuniranje jezičkog modela, i koristimo masivnu povećanju podataka putem povratnog prevoda kako bi povećali raznolikost podataka o obuci. Dalje pregledamo mogućnosti kombinacije podataka iz mnogih izvora kako bi poboljšali provedbu na ciljnoj seti podataka. Pažljivo procjenjujemo naše doprinos ljudskim i automatskim metodama. Naš model značajno iznosi početnu liniju podataka o multiWOZ-u i pokazuje konkurentne funkcije sa stanjem umjetnosti u automatskoj i ljudskoj procjeni.', 'si': 'අවධානය සඳහා ප්\u200dරධානය සඳහා ප්\u200dරධානය සඳහා GPT-2 භාෂාව මොඩේල් වලින් අවධානය සඳහා අවධානය සඳහා ප්\u200dරධ නමුත්, ඔවුන් ඒවගේම ගොඩක් අවස්ථාවක් තියෙනවා වැඩක් ප්\u200dරමාණය සඳහා සංවාදය සඳහා විශේෂ අවස්ථාව මේ ප්\u200dරශ්නයක් විධානය කරන්න, අපි භාෂාව මොඩල් විධානය කරන්න ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් අර අපි තවත් පරීක්ෂා කරන්න පුළුවන් විශාල දත්ත සම්බන්ධයෙන් ගොඩක් මුළුවන් වලින් දත්ත සම්බන්ධය කරන්න අපි මිනිස්සු සහ ස්වයංක්\u200dරිය විදියට අපේ සම්බන්ධ විදියට පරීක්ෂා කරනවා. අපේ මොඩේල් විශේෂයෙන් විශේෂයෙන් අධාර්යය ප්\u200dරදේශය කරන්න පුළුවන් වෙනවා MultiWOZ දත්තේ සහ ස්වයංක්\u200dරීය සහ මිනිස්සු', 'so': 'Tusaalada afka hore oo lagu tababaray, tusaale ahaan GPT-2 waxay u keeneen horumar aad u badan si uu u dhamaado sameynta dialogue-ku-dhamaadka. Si kastaba ha ahaatee waxay sidoo kale jiraan khatar badan oo ku saabsan dialogue-ku-jeeda shaqaalaha, tusaale ahaan baahida aqoonta guryaha ama kala duduwan. Si aan u qabsado arrimahan, waxaan u soo bandhignaynaa goalo waxbarashada la beddelay tusaale ahaan qalabka luuqada, waxaana u shaqeynaa kordhiska macluumaad faro badan xagga dib-turjumista si aan u kordhiyo kala duduwanta waxbarashada. Waxaynu sii baaraynaa suurtagalka ku soo ururinta macluumaadka laga soo ururiyo manfacyada kala duduwan si loo hagaajiyo sameynta kooxda macluumaadka. We carefully evaluate our contributions with both human and automatic methods.  Tusaale ahaan ayaa sameynaya asalka ku qoran macluumaadka badan ee MultiWOZ, wuxuuna muujiyaa tababar iskutar ah oo ku sameynaya xaaladda farshaxanka ee iskibka iyo qiimeynta dadka.', 'ta': '@ info ஆனாலும், அவர்கள் பணிமுறைமையான உரையாடலுக்கு மிகவும் பெரிய ஆபத்துகள் கொண்டிருக்கிறார்கள், போன்ற அறிவு கூட்டம் அல் இந்த பிரச்சனைகளை நிர்வகிக்க, மொழி மாதிரி மாதிரி பின்தூனிங் க்கு மாற்றப்பட்ட பயிற்சியின் தலைப்புகளை குறிப்பிடுகிறோம், மற்றும இலக்கு தகவல் அமைப்பில் உள்ள செயல்பாட்டை மேம்படுத்துவதற்காக பல மூலங்களில் இருந்து தரவை சேர்த்து சாத்தியங்களை மே நாங்கள் கவனமாக எங்கள் பங்குகளை மனிதன் மற்றும் தானியங்கி முறைகளையும் மதிப்பிட வேண்டும். நம்முடைய மாதிரி பெரிய பல்WOZ தரவுகளின் அடிப்படைக்கோட்டை மேல் செயல்படுத்துகிறது மற்றும் தானியங்கி மற்றும் மனித மதிப்புகளில்', 'sv': 'Uppmärksamhetsbaserade förklädda språkmodeller som GPT-2 medförde avsevärda framsteg när det gäller att modellera dialoger mellan olika parter. De utgör emellertid också avsevärda risker för den uppgiftsinriktade dialogen, t.ex. bristande kunskapsgrund eller mångfald. För att ta itu med dessa frågor introducerar vi ändrade utbildningsmål för finjustering av språkmodeller, och vi använder massiv dataökning via backöversättning för att öka mångfalden av utbildningsdata. Vi undersöker vidare möjligheterna att kombinera data från flera källor för att förbättra prestandan på måldatauppsättningen. Vi utvärderar noggrant våra bidrag med både mänskliga och automatiska metoder. Vår modell överträffar avsevärt baseline på MultiWOZ data och visar konkurrenskraftig prestanda med toppmodern teknik i både automatisk och mänsklig utvärdering.', 'ur': 'توجه کی بنیاد پر پیش ترسین کی زبان موڈل جیسے GPT-2 نے اخری-پا-پا-پا ڈالیلوگ موڈلینگ کے لئے بہت اضافہ پیش آئی۔ لیکن یہ بھی کام کی طرف سے صحبت کے لئے بہت اچھے خطرے پیش کرتے ہیں، جیسے علم کی وجہ یا مختلف وجہ سے کمی ہے. ان مسائلوں کے بارے میں ہم نے زبان موڈل فین ٹینٹونگ کے لئے بدل دیے ہوئے تطارین موضوعوں کو معلوم کرلیا ہے اور ہم پچھلے ٹرنگ کے ذریعے بڑھنے کے لئے بہت سی ڈیٹا اضافہ کریں گے۔ ہم اس سے زیادہ نظر کرتے ہیں کہ موقع ڈیٹ سٹ پر فعالیت کا تدبیر کرنے کے لئے مزید سروروں سے ڈیٹ کو جمع کریں۔ ہم نے انسان اور اتماٹیکل طریقے سے اپنا حصہ ادا کیا ہے۔ ہمارا موڈل بہت زیادہ زیادہ زیادہ مطابق MultiWOZ ڈیٹا کے بنیاس لین کو اضافہ کرتا ہے اور آٹیٹ کی وضعیت کے ساتھ آٹیٹ کی وضعیت کے ساتھ مطابق مطابق کرتا ہے اور انسان کی وضعیت کے سات', 'ms': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling.  Namun, mereka juga mengandungi risiko yang besar untuk dialog oriented tugas, seperti kekurangan pengetahuan dasar atau pelbagai. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via back-translation to increase the diversity of the training data.  Kami memeriksa lebih lanjut kemungkinan untuk menggabungkan data dari sumber berbilang untuk meningkatkan prestasi pada set data sasaran. Kami berhati-hati menilai kontribusi kami dengan kaedah manusia dan automatik. Model kami sangat melebihi dasar pada data MultiWOZ dan menunjukkan prestasi kompetitif dengan kemajuan dalam penilaian automatik dan manusia.', 'lt': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling.  However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity.  Siekdami spręsti šiuos klausimus, įvedame modifikuotus mokymo tikslus kalbos modelio tobulinimui ir naudojame didžiulį duomenų didinimą grįžtamaisiais vertimais siekiant padidinti mokymo duomenų įvairovę. Toliau nagrinėjame galimybes derinti įvairių šaltinių duomenis siekiant pagerinti tikslinių duomenų rinkinio rezultatus. We carefully evaluate our contributions with both human and automatic methods.  Mūsų modelis gerokai viršija MultiWOZ duomenų bazę ir rodo, kad automatinio ir žmogiškojo vertinimo rezultatai yra konkurencingi ir pažangiausi.', 'uz': "Name Шунингдек, улар масъалага тўғри келадиган dialog учун катта қизиқни ҳозир кўрсатади, мисоли илм гуруҳлари ёки турли тафсирлар мавжуд эмас. Bu muammolarni boshqarish uchun biz tilning modeli finfinfinfinfining uchun o'zgarishni o'zgartirib o'rganamiz. va biz taʼminlovchi maʼlumot tarjimasini oshirish uchun juda katta maʼlumot soʻzlashni bajaramiz. Bir nechta manba maʼlumotlarni birlashtirish imkoniyatlarini ko'proq ko'proq maʼlumotlar bajarishini bajarish mumkin. Biz inson va avtomatik usullar bilan qiymatimiz. Bizning modelimiz MultiWOZ маълумотлари асосий манзилларини бажаришга кўрсатади ва sanam holatida avtomatik va inson qiymatlarida rivojlanishni ko'rsatadi.", 'vi': 'Các mô hình ngôn ngữ được đào tạo chú ý như GPT-2 đã tạo ra một tiến bộ đáng kể cho mô hình cuộc đối thoại. Tuy nhiên, nó cũng có nguy cơ lớn cho cuộc đối thoại hướng dẫn nhiệm vụ, như thiếu kiến thức hay đa dạng. Để giải quyết những vấn đề này, chúng ta sẽ tạo ra các mục tiêu huấn luyện sửa đổi cho mô hình ngôn ngữ tinh xảo, và chúng ta sử dụng việc tăng cường dữ liệu bằng cách quay lại để tăng sự khác biệt trong dữ liệu đào tạo. Chúng tôi còn xem xét khả năng kết hợp dữ liệu từ các nguồn nhân tạo để tăng hiệu quả trên bộ dữ liệu đích. Chúng tôi đánh giá cẩn thận những cống hiến của mình với phương pháp con người và tự động. Cơ chế của chúng tôi hoàn thiện cơ bản dựa trên các dữ liệu đa WOZ và trình diễn khả năng cạnh tranh với các phẩm chất hiện đại trong việc đánh giá tự động và con người.', 'nl': "Aandacht-gebaseerde voorgetrainde taalmodellen zoals GPT-2 hebben aanzienlijke vooruitgang geboekt op het gebied van end-to-end dialoogmodellering. Zij vormen echter ook aanzienlijke risico's voor een taakgerichte dialoog, zoals een gebrek aan kennisbasis of diversiteit. Om deze problemen aan te pakken, introduceren we aangepaste trainingsdoelstellingen voor het finetunen van taalmodellen en gebruiken we massale data augmentatie via back-translation om de diversiteit van de trainingsgegevens te vergroten. We onderzoeken verder de mogelijkheden om data uit meerdere bronnen te combineren om de prestaties op de doeldataset te verbeteren. We evalueren onze bijdragen zorgvuldig met zowel menselijke als automatische methoden. Ons model presteert aanzienlijk beter dan de baseline op de MultiWOZ-gegevens en toont concurrerende prestaties met state of the art in zowel automatische als menselijke evaluatie.", 'da': 'Opmærksomhedsbaserede præuddannede sprogmodeller som GPT-2 medførte betydelige fremskridt med hensyn til end-to-end dialog modellering. De udgør imidlertid også betydelige risici for en opgaveorienteret dialog, f.eks. manglende vidensgrundlægning eller mangfoldighed. For at løse disse problemer indfører vi ændrede træningsmål for finjustering af sprogmodel, og vi anvender massiv dataforøgelse via back-translation for at øge mangfoldigheden af træningsdata. Vi undersøger yderligere mulighederne for at kombinere data fra flere kilder for at forbedre ydeevnen på måldatasættet. Vi evaluerer omhyggeligt vores bidrag med både menneskelige og automatiske metoder. Vores model overgår væsentligt baseline på MultiWOZ data og viser konkurrencedygtige resultater med state of te art i både automatisk og menneskelig evaluering.', 'id': 'Model bahasa berdasarkan perhatian yang dilatih sebelumnya seperti GPT-2 membawa kemajuan yang konsiderel ke model dialog akhir-akhir. Namun, mereka juga mengakibatkan risiko yang konsiderel untuk dialog orientasi tugas, seperti kekurangan pengetahuan dasar atau diversitas. Untuk mengatasi isu-isu ini, kami memperkenalkan tujuan pelatihan yang diubah untuk memperbaiki model bahasa, dan kami menggunakan peningkatan data besar melalui terjemahan belakang untuk meningkatkan diversitas data pelatihan. Kami lebih lanjut memeriksa kemungkinan untuk menggabungkan data dari banyak sumber untuk meningkatkan prestasi pada set data target. Kami memperhatikan kontribusi kita dengan metode manusia dan otomatis. Model kami sangat melebihi dasar data MultiWOZ dan menunjukkan prestasi kompetitif dengan state of the art dalam evaluasi otomatis dan manusia.', 'ko': '주의력을 바탕으로 하는 사전 훈련 언어 모델, 예를 들어 GPT-2는 처음부터 끝까지 대화 모델링에 큰 발전을 가져왔다.그러나 그것들은 임무에 대한 대화에 상당한 위험을 가져왔다. 예를 들어 지식의 기초가 부족하거나 다양성이 부족하다.이러한 문제점을 해결하기 위해 우리는 개선된 언어 모델 마이크로스피커 훈련 목표를 도입하고 역방향 번역을 통해 대량의 데이터를 추가하여 훈련 데이터의 다양성을 증가시켰다.우리는 목표 데이터 집합의 성능을 향상시키기 위해 여러 개의 원본에서 나온 데이터를 조합하는 가능성을 한층 더 연구했다.우리는 인공과 자동적인 방법으로 우리의 공헌을 자세하게 평가한다.우리의 모델은 MultiWOZ 데이터에서 베이스라인보다 현저히 우수하고 자동 및 인공 평가에서 가장 선진적인 수준의 경쟁력을 나타낸다.', 'fa': 'مدل\u200cهای زبان پیش آموزش یافته\u200cی توجه مانند GPT-2 پیشرفت زیادی به مدل\u200cسازی گفتگوی پایان به پایان آورد. با این وجود، آنها همچنین خطرهای بزرگی برای گفتگوی مستقیم به کار را نشان می دهند، مانند ناتوانی پایه\u200cهای دانش یا مختلف. برای حل این مسائل، ما هدف آموزشی تغییر داده شده را برای آفرینش مدل زبان معرفی می کنیم، و ما از طریق ترجمه پشتی برای افزایش مختلف داده های آموزشی استفاده می کنیم. ما احتمالات ترکیب داده ها را از منبع های چندین برابر عملکرد در مجموعه داده های هدف تحقیق می کنیم. ما با دقت توجه\u200cهای خودمان را با روش\u200cهای انسان و خودکار ارزیابی می\u200cکنیم. مدل ما خیلی بیشتر از خط پایین روی داده های MultiWOZ انجام می دهد و اجرای مسابقه با وضعیت هنر در ارزیابی خودکار و انسان را نشان می دهد.', 'de': 'Aufmerksamkeitsbasierte vortrainierte Sprachmodelle wie GPT-2 brachten erhebliche Fortschritte bei der End-to-End Dialogmodellierung. Sie bergen aber auch erhebliche Risiken für den aufgabenorientierten Dialog, wie fehlende Wissensgrundlage oder Diversität. Um diese Probleme anzugehen, führen wir modifizierte Trainingsziele für die Feinabstimmung von Sprachmodellen ein und setzen eine massive Datenaugmentation durch Rückübersetzung ein, um die Vielfalt der Trainingsdaten zu erhöhen. Wir untersuchen weiter die Möglichkeiten, Daten aus mehreren Quellen zu kombinieren, um die Leistung des Zieldatensatzes zu verbessern. Wir bewerten unsere Beiträge sorgfältig mit menschlichen und automatischen Methoden. Unser Modell übertrifft die Basiswerte der MultiWOZ-Daten erheblich und zeigt eine wettbewerbsfähige Leistung mit dem neuesten Stand der Technik in der automatischen und menschlichen Auswertung.', 'sw': 'Mfano wa lugha zilizo msingi wa kusikiliza kama vile GPT-2 ulileta maendeleo makubwa ya kuendeleza mjadala wa mwisho wa majadiliano. Hata hivyo, pia wanaweka hatari kubwa kwa mazungumzo yanayoongozwa na kazi, kama vile ukosefu wa makundi ya ufahamu au tofauti. Ili kuzungumzia masuala haya, tunaanzisha malengo ya mafunzo mabadiliko ya mifano ya lugha kwa ajili ya kuinua, na tunatumia kuongeza taarifa kubwa kwa kutumia tafsiri ya nyuma ili kuongeza tofauti ya taarifa za mafunzo. We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset.  Tutathmini kwa makini michango yetu kwa njia za binadamu na binadamu. Mfano wetu unaonyesha msingi wa takwimu za MultiWOZ na unaonyesha ufanisi wa ushindani wa hali ya sanaa kwa ajili ya utafiti wa binadamu na utafiti wa kibinadamu.', 'tr': 'GPT-2 ýaly agyrylan öňden öňden eğlenen dil nusgalary, iň soňky-soňky диалог modellerine çykyp gitdi. Ýöne, işe görnüşi diýolgy üçin örän möhüm riskleri görkezýärler, ýaly bilim sistemasy ýa-da näçeşitliligi ýok. Bu meselelere çözmek üçin, dil nusgasyny fin çykarmak üçin üýtgedilmiş bilim amaçlaryny tanyşdyrýarys we biz yzyna terjime etmek üçin örän uly maglumatlary ulanýarys. Bir näçe çeşmeden maglumatlary birleştirmek üçin maksady datawatlaryň üstünliklerini gowlaşdyrmak üçin maglumatlaryň birleşmesini barlaýarys. Biz adamlaryň we otomatik yöntemlerimiz bilen öz täsirlerimizi ünsli çykýarys. Biziň modelimiz MultiWOZ maglumatynyň esasy hatyny çykarýar we öz-özünden we adamlaryň değerlendirmegi bilen ýaryşykly etkinlik ukyplaryny görkez.', 'af': 'Aansig-gebaseerde voorafoerende taal modelles soos GPT-2 het betekende vordering gebring na end-to-end dialoog modellering. Maar hulle stel ook bepaalde risiko voor die taak-orienteerde dialoog, soos die ontbreek van kennis agtergrond of diversiteit. Om hierdie probleem te raak, introduseer ons modifiseerde onderwerp doel vir taal model finetuning, en ons gebruik massiewe data vergroot deur terugvertaling om die verskeidigheid van die onderwerp data te vermeerder. Ons verder ondersoek die moontlikhede van die kombinasie van data vanaf vermenigbronne om prestasie op die doel datastel te verbeter. Ons veroorsaak ons bydraaghings met menslike en automatiese metodes. Ons model buitengewoon uitvoer die basislien op die MultiWOZ-data en wys gemeenskaplike prestasie met staat van die kuns in beide automatiese en menslike evaluering.', 'sq': 'Modelet e gjuhës paratrajnuara me bazë në vëmendje të tilla si GPT-2 sollën përparim të konsiderueshëm në modelimin e dialogut nga fundi në fund. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity.  Për të trajtuar këto çështje, ne futim objektivat e modifikuara të trainimit për përmirësimin e modelit gjuhësor dhe përdorim rritje masive të të dhënave nëpërmjet përkthimit mbrapa për të rritur diversitetin e të dhënave të trainimit. Ne shqyrtojmë më tej mundësitë e kombinimit të të dhënave nga burime të shumta për të përmirësuar performancën në grupin e të dhënave objektiv. Ne vlerësojmë me kujdes kontributet tona me metodat njerëzore dhe automatike. Our model substantially outperforms the baseline on the MultiWOZ data and shows competitive performance with state of the art in both automatic and human evaluation.', 'am': 'መግለጫ ነገር ግን ደግሞ እውቀት መብረቅ ወይም ልዩ ልዩ ልዩ ልዩነት እንዳይኖር ለስራ አካባቢ ማኅበረሰብ የሚያስቸኩል መከራ አቀረበዋል፡፡ እነዚህን ጉዳዮች ለመቀበል፣ ለቋንቋ ምሳሌ ፊንስር የተለወጠውን ትምህርት አቃውሞ እናስጠጋለን፣ የቴናው ዳታዎችን ልዩ ልዩነት ለመጨመር በጀርባ ትርጓሜ እናስጠጋለን፡፡ አካላቢው ዳታዎችን ለማሻሻል ከብዙ ምንጮች ማሰናከል የሚችሉትን ምናልባት እናምር፡፡ በጥንቃቄ የሰው እና በራሱ ልማድ አካሄዳችንን እናሳውቃለን፡፡ ሞዴሌያችን በብዙ WOZ ዳታዎች ላይ መሠረትን ያሳያል እና የዐርላዊ ብሔራዊ እና በሰው አካውንት ላይ የሚቻለውን የሥርዓት ድረ ገጽ ያሳያል፡፡', 'hy': 'Ուշադրության վրա հիմնված նախապատրաստված լեզվի մոդելները, ինչպիսիք են GPT-2-ը, մեծ առաջընթաց բերեցին վերջ-վերջ տարբերակի մոդելավորման համար: Այնուամենայնիվ, դրանք նաև նշանակալի ռիսկեր են ներկայացնում խնդիրների վրա ուղղությամբ խոսակցության համար, ինչպիսիք են գիտելիքների բացակայությունը կամ բազմազանությունը: Այս հարցերի լուծման համար մենք ներկայացնում ենք փոփոխված ուսուցման նպատակներ լեզվի մոդելի փոփոխման համար, և մենք օգտագործում ենք հսկայական տվյալների աճ վերադարձ թարգմանության միջոցով, որպեսզի աճենք ուսուցման տվյալների բազմազանություն Մենք նաև ուսումնասիրում ենք բազմաթիվ աղբյուրներից ստացված տվյալների համադրման հնարավորությունները, որպեսզի բարելավենք նպատակային տվյալների համակարգի արդյունավետությունը: Մենք ուշադիր գնահատում ենք մեր ներդրումը մարդկային և ավտոմատիկ մեթոդներով: Մեր մոդելը հիմնականում գերազանցում է բազմազան աշխարհային տվյալների հիմքերը և ցույց է տալիս մրցակցության արդյունքները արվեստի բարձրակարգությամբ՝ ինչպես ավտոմատիկ, ինչպես նաև մարդկային գնահատման մեջ:', 'bn': 'মনোযোগ প্রদান করা ভিত্তিক ভিত্তিক ভাষার পূর্ব প্রশিক্ষিত ভাষার মডেল, যেমন জিপিটি-২, শেষ পর্যন্ত ডায়ালগ মডেলেলের তবে তারা কাজের উদ্দেশ্যে আলোচনার জন্য বিশাল ঝুঁকি উপস্থাপন করেছে, যেমন জ্ঞান গ্রাউন্ডিং অথবা বৈচিত্র্যের অভাব। এই সমস্ত বিষয়গুলো নিয়ে কথা বলার জন্য আমরা ভাষার মডেল ফিনিউটিং এর জন্য পরিবর্তন প্রশিক্ষণের লক্ষ্য উপস্থাপন করি এবং আমরা প্রশিক্ষণের তথ্য বৈচিত্র্য বৃ আমরা আরো পরীক্ষা করি বেশ কিছু সূত্র থেকে তথ্য যুক্ত করার সম্ভাবনা সম্ভাবনা সম্পর্কে লক্ষ্যের ডাটাসেটে উন্নতি করার জন্য আমরা সাবধানে মানুষ এবং স্বয়ংক্রিয় পদ্ধতিগুলোর মাধ্যমে আমাদের অংশগ্রহণের পরিমাণ মূল্যায়ন করি। আমাদের মডেল মাল্টিউডওজের তথ্যের বেসাইটলাইন প্রদর্শন করে এবং স্বয়ংক্রিয়ভাবে এবং মানুষের মূল্যের দ্বারা প্রতিযোগিতার প্রদর্', 'az': 'GPT-2 kimi gözləmə təhsil edilmiş dil modelləri sona-sona dəyişiklik modellərinə böyük tədbir göstərdi. Lakin onlar həmçinin həmçinin elm tərəfindən və cürbəcür müxtəlif olmayan məsələlər üçün böyük risklər göstərirlər. Bu məsələləri çəkmək üçün dil modeli finetuning üçün dəyişdirilmiş təhsil məqsədilərini tanıdırıq və təhsil məlumatlarının müxtəlifliyini artırmaq üçün çox böyük məlumatları geri çevirib artırmaq vasitəsilə istifadə edirik. Biz çoxlu kaynaqlardan verilən məlumatları birləşdirmək mümkünlüyünü həmin məlumat qutusunda xeyirxahlıq etmək üçün baxırıq. Biz insanların və avtomatik yollarıyla müvəffəqiyyətimizi dikkatli değerləyirik. Modelimiz çoxlu WOZ verilənlərin əsas səhifəsini çox üstün edir və sanatın vəziyyəti ilə müqayisədə müqayisədə və insan değerlendirməsini göstərir.', 'ca': "Models de llenguatges pré-entrenats basats en l'atenció, com el GPT-2, van portar progrés considerable a la modelació del diàleg de final a final. No obstant això, també presenten riscs consideràveis per al diàleg orientat a les tasques, com la falta de fundaments de coneixement o diversitat. Per abordar aquests problemes, introduïm objectius de formació modificats per a perfeccionar el model lingüístic, i utilitzem un augment massiu de dades a través de traducció posterior per augmentar la diversitat de les dades de formació. Examinem més les possibilitats de combinar dades de múltiples fonts per millorar el rendiment del conjunt de dades d'objectiu. Evaluam cuidadosament les nostres contribucions amb mètodes humans i automàtics. El nostre model supera substancialment la base de dades de MultiWOZ i mostra rendiment competitiu amb l'avançat en l'evaluació automàtica i humana.", 'bs': 'Na temelju pažnje predobučeni jezički modeli poput GPT-2 donosili su značajan napredak na modelling dijaloga do kraja. Međutim, oni također predstavljaju značajne rizike za dijalog usmjeren na zadatke, poput nedostatka temelja znanja ili raznolikosti. Da bi se riješili ovim pitanjima, predstavljamo modificirane ciljeve obuke za finetuniranje jezičkog modela i upotrebimo ogromnu povećanju podataka putem povratnog prevoda kako bi povećali raznolikost podataka o obuci. Dalje pregledamo mogućnosti kombinacije podataka iz mnogih izvora kako bi poboljšali učinkovitost na ciljnom setu podataka. Pažljivo procjenjujemo naše doprinos ljudskim i automatskim metodama. Naš model značajno iznosi početnu liniju podataka o multiWOZ-u i pokazuje konkurentne funkcije sa stanjem umjetnosti u automatskoj i ljudskoj procjeni.', 'cs': 'Předškolené jazykové modely založené na pozornosti, jako je GPT-2, přinesly značný pokrok v modelování komplexního dialogu. Představují však také značná rizika pro dialog orientovaný na úkoly, například nedostatek znalostí nebo rozmanitost. Pro řešení těchto problémů představujeme upravené cíle školení pro jemné ladění jazykových modelů a využíváme masivní rozšíření dat prostřednictvím zpětného překladu, abychom zvýšili rozmanitost tréninkových dat. Dále zkoumáme možnosti kombinování dat z několika zdrojů pro zlepšení výkonu cílového datového souboru. Naše příspěvky pečlivě hodnotíme jak lidskými, tak automatickými metodami. Náš model výrazně překonává základní základní hodnotu na údajích MultiWOZ a vykazuje konkurenční výkon s nejmodernějšími technologiemi v oblasti automatického i lidského hodnocení.', 'et': 'Tähelepanu põhinevad eelkoolitud keelemudelid, nagu GPT-2, tõid märkimisväärset edu dialoogi lõpuni modelleerimisel. Siiski kujutavad need endast märkimisväärseid ohte ülesannetele suunatud dialoogile, näiteks teadmiste puudumise või mitmekesisuse tõttu. Nende probleemide lahendamiseks tutvustame keelemudelite täpsustamise muudetud koolituseesmärke ja kasutame massilist andmete suurendamist tagantõlke kaudu, et suurendada koolitusandmete mitmekesisust. Lisaks uurime mitmest allikast pärit andmete kombineerimise võimalusi sihtandmekogumi tulemuslikkuse parandamiseks. Hindame hoolikalt oma panust nii inimlike kui ka automaatsete meetoditega. Meie mudel ületab oluliselt MultiWOZ andmete baasi ja näitab konkurentsivõimelist tulemuslikkust nii automaatse kui ka inimese hindamise tipptasemel.', 'fi': 'Huomioon perustuvat esikoulutetut kielimallit, kuten GPT-2, toivat huomattavaa edistystä kokonaisvaltaisen vuoropuhelun mallinnuksessa. Ne aiheuttavat kuitenkin myös merkittäviä riskejä tehtävälähtöiselle vuoropuhelulle, kuten tietämyksen puutteen tai monimuotoisuuden. Näiden ongelmien ratkaisemiseksi otamme käyttöön muokattuja koulutustavoitteita kielimallin hienosäätöä varten ja käytämme massiivista datan lisäämistä taaksekääntämisen avulla koulutusdatan monimuotoisuuden lisäämiseksi. Lisäksi tutkimme mahdollisuuksia yhdistää dataa useista lähteistä kohdeaineiston suorituskyvyn parantamiseksi. Arvioimme panoksemme huolellisesti sekä inhimillisillä että automaattisilla menetelmillä. Mallimme ylittää merkittävästi MultiWOZ-datan lähtötilanteen ja näyttää kilpailukykyistä suorituskykyä sekä automaattisessa että inhimillisessä arvioinnissa.', 'hr': 'Na temelju pažnje predobučeni jezički modeli poput GPT-2 donosili su značajan napredak u modeliranju dijaloga do kraja. Međutim, oni također predstavljaju značajne rizike za dijalog orientiran na zadatke, poput nedostatka temelja znanja ili raznolikosti. Za rješavanje tih pitanja, predstavljamo modificirane ciljeve obuke za finetuniranje jezičkog modela i upotrebljavamo masivnu povećanje podataka putem povratnog prevoda kako bi povećali raznolikost podataka o obuci. Dalje pregledamo mogućnosti kombinacije podataka iz mnogih izvora kako bi poboljšali učinkovitost na ciljnom setu podataka. Pažljivo procjenjujemo naše doprinos ljudskim i automatskim metodama. Naš model značajno iznosi početnu liniju podataka o multiWOZ-u i pokazuje konkurentne učinke s stanjem umjetnosti u automatskoj i ljudskoj procjeni.', 'bg': 'Предварително обучените езикови модели, базирани на вниманието, като GPT-2, доведоха до значителен напредък в моделирането на диалога от край до край. Те обаче представляват и значителни рискове за ориентирания към задачите диалог, като липса на обосновка на знания или разнообразие. За да се справим с тези проблеми, въвеждаме модифицирани цели за обучение за фино настройване на езикови модели и използваме масивно увеличаване на данните чрез обратен превод, за да увеличим многообразието на данните за обучение. Проучваме и възможностите за комбиниране на данни от множество източници за подобряване на ефективността на целевия набор от данни. Ние внимателно оценяваме приноса си както с човешки, така и с автоматични методи. Нашият модел значително превъзхожда базовите данни и показва конкурентни резултати с най-съвременни технологии както при автоматична, така и при човешка оценка.', 'he': 'דוגמני שפת מאומנים מראש למבוסס תשומת לב כמו GPT-2 הביאו התקדמות משמעותית למודל דיאלוג מסוף-לסוף. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity.  כדי להתמודד עם הנושאים האלה, אנו מכירים מטרות אימונים משוננות למודל שפת מתאים, ואנחנו משתמשים בהעלות נתונים מסיבית דרך התרגום האחורי כדי להעלות את מגוון נתוני האימון. אנו בודקים יותר את האפשרויות של שילוב נתונים ממקורים רבים כדי לשפר את ההפעלה על קבוצת נתונים המטרה. אנו מערכים בזהירות את התרומות שלנו בשיטות אנושיות ואוטומיות. המודל שלנו יוצא משמעותית מעל הבסיס על נתוני MultiWOZ ומראה ביצועים תחרותיים עם מצב האומנות באוטומטי ובעריכה אנושית.', 'sk': 'Predhodno usposobljeni jezikovni modeli, kot je GPT-2, so prinesli precejšen napredek pri modeliranju dialoga od konca do konca. Vendar pa predstavljajo tudi precejšnja tveganja za dialog, usmerjen v naloge, kot je pomanjkanje osnove znanja ali raznolikost. Za reševanje teh vprašanj uvajamo spremenjene cilje usposabljanja za fino nastavitev jezikovnih modelov in uporabljamo obsežno povečanje podatkov prek nazaj prevajanja, da povečamo raznolikost podatkov o usposabljanju. Nadalje preučujemo možnosti kombiniranja podatkov iz več virov za izboljšanje učinkovitosti ciljnega nabora podatkov. Naše prispevke skrbno ocenjujemo s človeškimi in avtomatskimi metodami. Naš model bistveno presega osnovno osnovo podatkov MultiWOZ in prikazuje konkurenčno uspešnost z najsodobnejšim pri avtomatičnem in človeškem ocenjevanju.', 'ha': '@ action: button Haƙĩƙa, suna zuwa hatari mai girma wa zauren akwatin bayani masu shiryuwa da aiki, kamar bã da wani sanyi bakin hargo ko dabam-dabam. Domin ka yi tambaya ga masu yiwuwa, za mu ƙãga abun da aka canza wa misalin harshen finfintution, kuma muna aikin ƙaramako da data masu girma a bayani-tarjima dõmin ya ƙara diffukan danne na tsarin. Ko ƙara, Munã jarraba awon ku haɗa data daga sourcen masu yawa dõmin ya improve performance a kan danne-danne da ake amfani da. Ina ƙaddara aikinmu da hanyõyin mutane da farat ɗaya. MisalinMu na fara ƙaranci a kan data na multi-WOZ kuma yana nũna fara-tarakin da halin sanar ta farat ɗaya da kake iya ƙayyade mutum.', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Nanging, wong-wong pada ingkang dipontong sing gak nggawe dialog-urip task-urip, koyo ngono kuwi tindakan layang-sistem sing ora ono nggawe kesempatan Mbok kanggo kowe nggawe perusahaan langgar, kita nyengkuyung nggawe bukal kanggo ngilanggar tarjamahan kanggo ngilanggar model kuwi nggawe, lan kita nguasai perusahaan podho kebutuhan langgar-terjamahan kanggo bisa langgar nggawe dadi podho tukang. section Awak dhéwé nglanggar-langgar aturan awak dhéwé iki dadi éwé ngono perbudhakan lan sing otomatik. Model sing ngerasai akeh barang nggawe barang nggawe dadi MultiWOZ lan ngawe barang langgar sampeyan karo hal-sampeyan karo perusahaan sing nguasai perusahaan karo perusahaan karo perusahaan sampeyan.', 'bo': 'Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialog modelling. ཡིན་ནའང་། ཁོང་ཚོས་བློ་གཏོང་གི་གླེང་སྒྲུང་ལ་ཉུང་བའི་རྐྱེན་ཚད་མང་པོ་ཡོད། གནད་དོན་འདི་དག་ལ་བཤད་ན། ང་ཚོས་སྐད་ཡིག་གི་མ་དཔེ་གཏན་གྱིས་བཟོ་བཅོས་བའི་གྲ་སྒྲིག་གི་དམིགས་ཡུལ་ལ་ངོས་འཛིན་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ཐོག་མའི་རྒྱུ་དངོས་ཐོག་མའི་ཆ་འཕྲིན་ཡིག་ཆ་བསྡུར་བའི་གོ་སྐབས་མང་ཙམ་ཞིབ་དཔྱད་བྱེད་དགོས། ང་ཚོས་མིའི་དང་རང་འགུལ་གྱི་ཐབས་ལམ་གཉིས་ལས་ང་ཚོའི་གུས་རྐྱེན་ཚད་ལྟར་འཛིན་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མ་དབུགས་གྱིས་སྒྲུབ་ཀྱི་རྩལ་གཞི་རྟེན་འདི་གྲངས་སུ་བཏོན་པ་ཡིན་པས། རང་འགུལ་གྱིས་དང་མི་རིག་ཐག'}
{'en': 'Using Pause Information for More Accurate Entity Recognition', 'ar': 'استخدام معلومات الإيقاف المؤقت للتعرف على الكيانات بشكل أكثر دقة', 'fr': 'Utilisation des informations de pause pour une reconnaissance plus précise des entités', 'pt': 'Usando informações de pausa para reconhecimento de entidade mais preciso', 'es': 'Uso de información de pausa para un reconocimiento de entidades más preciso', 'ja': 'より正確なエンティティ認識のための一時停止情報の使用', 'hi': 'अधिक सटीक एंटिटी पहचान के लिए रोकें जानकारी का उपयोग करना', 'zh': '用暂停信息更确的实体识别', 'ru': 'Использование информации о паузе для более точного распознавания сущности', 'ga': 'Ag Úsáid Faisnéise ar Sos chun Aitheantas Aonáin Níos Cruinn', 'el': 'Χρήση πληροφοριών παύσης για πιο ακριβή αναγνώριση οντοτήτων', 'hu': 'Szüneteltetési információk használata a pontosabb szervezeti felismeréshez', 'ka': 'დამატებითი ინტერტის განახლებისთვის პოზაციის ინფორმაციის გამოყენება', 'it': 'Utilizzo delle informazioni di pausa per un riconoscimento più accurato delle entità', 'kk': 'Көбірек таңдау нысандарының аялдау мәліметін қолдану', 'lt': 'Using Pause Information for More Accurate Entity Recognition', 'mk': 'Користење на информации за пауза за попрецизно препознавање на ентитетите', 'ms': 'Mengguna Maklumat Paus untuk Pengenalan Entiti Lebih Tepat', 'mn': 'Үнэхээр тодорхой нэгж танихын тулд завсарлагын мэдээлэл хэрэглэх', 'mt': 'L-użu ta’ Informazzjoni dwar il-Pausa għal Rikonoxximent Aktar Akkwat ta’ Entità', 'ml': 'കൂടുതല്\u200d അക്കൌണ്ട്രെയിറ്റി തിരിച്ചറിയുന്നതിനുള്ള വിവരങ്ങള്\u200d താമസം ഉപയോഗിക്കുന്നു', 'no': 'Bruk pausinformasjon for meir nøyaktig gjenkjenning av einingar', 'pl': 'Korzystanie z informacji o wstrzymaniu dla bardziej dokładnego rozpoznawania podmiotów', 'sr': 'Koristeći informacije o pauzi za prepoznavanje preciznih podataka', 'ro': 'Utilizarea informațiilor de pauză pentru o recunoaștere mai exactă a entităților', 'si': 'තවත් හරියට අවස්ථාවක් අඳුරගන්න ස්ථානය තොරතුරු භාවිත කරන්න', 'so': 'Isticmaalka macluumaadka joogitaanka ee aqoonsashada daryeelka xisaabta', 'ur': 'اور زیادہ دقیق ایٹنی پتچانی کے لئے استعمال کی جاتی ہے', 'sv': 'Använda pausinformation för mer exakt entitetsigenkänning', 'ta': 'Using Pause Information for More Accurate Entity Recognition', 'uz': 'Qoò£shimcha hisobot toò£gò£rilash uchun toò£xtatish maò¥lumotidan foydalanish', 'vi': 'Dùng thông tin tạm thời cho nhận dạng đơn vị nhiều hơn', 'bg': 'Използване на информация за пауза за по-точно разпознаване на обекти', 'nl': 'Informatie pauzeren gebruiken voor nauwkeurigere entiteitsherkenning', 'da': 'Brug af pauseoplysninger til mere nøjagtig genkendelse af enheder', 'de': 'Verwenden von Pauseninformationen für eine genauere Entitätserkennung', 'ko': '정지 정보를 사용하여 더욱 정확한 실체 식별을 진행하다', 'id': 'Using Pause Information for More Accurate Entity Recognition', 'hr': 'Koristeći informacije o pauzi za prepoznavanje preciznih podataka', 'fa': 'استفاده از اطلاعات متوقف برای شناسایی واحد دقیق بیشتری', 'sw': 'Kwa kutumia taarifa za Kutumia Matukio kwa Kutambua Ujumbe wa Zaidi', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'tr': 'Dahili Dyggat Otomatik Gaýd etmek üçin Duruz Maglumaty ullan', 'sq': 'Përdorimi i informacionit të pauzës për njohjen më të saktë të njësisë', 'hy': 'Օգտագործելով դադարի տեղեկատվությունը ավելի ճշգրիտ անհատականության ճանաչելու համար', 'az': 'Daha nöqsanlıq Entity Recognition üçün Paz Malümatını qullanılır', 'bn': 'অতিরিক্ত অ্যাকার্টিটি পরিচিতির জন্য ব্যবহার করা থামানো তথ্য ব্যবহার করা হচ্ছে', 'bs': 'Koristeći informacije o pauzi za prepoznavanje preciznih podataka', 'cs': 'Použití informací o pozastavení pro přesnější rozpoznávání entit', 'ca': 'Utilitzar la informació de pausa per a reconèixer una entitat més exacta', 'et': 'Peatusteabe kasutamine olemi täpsemaks tuvastamiseks', 'fi': 'Keskeytystietojen käyttäminen entistä tarkempaan entiteetin tunnistamiseen', 'af': 'Gebruik van Paus Informasie vir meer Akkuraat Entiteit herken', 'sk': 'Uporaba informacij o premoru za natančnejše prepoznavanje subjekta', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'ཐེབས་བདེན་སྦྱོར་པང་རྩིས་འཛུགས་པ་ལ་ཐེམ་གྲངས་བརྡ་སྤྱོད་བཞིན་པ', 'he': 'השימוש במידע הפסקה לזיהוי ישות מדויק יותר', 'ha': 'Yi amfani da Cikakken Dabatar da Kyaushe'}
{'en': 'Entity tags in human-machine dialog are integral to natural language understanding (NLU) tasks in conversational assistants. However, current systems struggle to accurately parse spoken queries with the typical use of text input alone, and often fail to understand the user intent. Previous work in ', 'ar': 'تعد علامات الكيان في الحوار بين الإنسان والآلة جزءًا لا يتجزأ من مهام فهم اللغة الطبيعية (NLU) في مساعدي المحادثة. ومع ذلك ، تكافح الأنظمة الحالية لتحليل الاستعلامات المنطوقة بدقة مع الاستخدام المعتاد لإدخال النص وحده ، وغالبًا ما تفشل في فهم هدف المستخدم. حدد العمل السابق في علم اللغة ميلًا عبر اللغات لإيقاف الكلام لفترة أطول حول الأسماء مقارنة بالأفعال. نوضح أنه يمكن استخدام الملاحظة اللغوية في فترات التوقف المؤقت لتحسين الدقة في مهام فهم اللغة التي تتعلمها الآلة. يُظهر تحليل فترات التوقف المؤقت في النطق باللغتين الفرنسية والإنجليزية من المساعد الصوتي التجاري الاختلاف ذي الدلالة الإحصائية في مدة الإيقاف المؤقت حول حدود امتداد الكيان متعدد الرموز مقارنةً بداخل امتدادات الكيان. بالإضافة إلى ذلك ، على عكس NLU المستندة إلى النص ، فإننا نطبق مدة الإيقاف المؤقت لإثراء حفلات الزفاف السياقية لتحسين التحليل الضحل للكيانات. تُظهر النتائج أن عمليات التضمين الجديدة المقترحة تعمل على تحسين معدل الخطأ النسبي بنسبة تصل إلى 8٪ بشكل ثابت عبر ثلاثة مجالات للفرنسية ، دون أي تعليقات توضيحية أو تكاليف محاذاة إضافية للمحلل اللغوي.', 'fr': "Les étiquettes d'entité dans le dialogue homme-machine font partie intégrante des tâches de compréhension du langage naturel (NLU) dans les assistants conversationnels. Cependant, les systèmes actuels ont du mal à analyser avec précision les requêtes vocales avec l'utilisation typique de la saisie de texte seule, et souvent ils ne parviennent pas à comprendre l'intention de l'utilisateur. Des travaux antérieurs en linguistique ont identifié une tendance interlinguistique pour des pauses plus longues autour des noms par rapport aux verbes. Nous démontrons que l'observation linguistique pendant les pauses peut être utilisée pour améliorer la précision des tâches de compréhension de la langue apprises par machine. L'analyse des pauses dans les énoncés en français et en anglais à partir d'un assistant vocal commercial montre la différence statistiquement significative de la durée de pause autour des limites d'une entité à plusieurs jetons par rapport à l'intérieur des plages d'entités. De plus, contrairement à la NLU basée sur du texte, nous appliquons une durée de pause pour enrichir les intégrations contextuelles afin d'améliorer l'analyse superficielle des entités. Les résultats montrent que les nouvelles intégrations proposées améliorent le taux d'erreur relatif jusqu'à 8\xa0% de manière cohérente dans trois domaines pour le français, sans aucun coût supplémentaire d'annotation ou d'alignement pour l'analyseur.", 'pt': 'As tags de entidade no diálogo homem-máquina são essenciais para as tarefas de compreensão de linguagem natural (NLU) em assistentes de conversação. No entanto, os sistemas atuais lutam para analisar com precisão as consultas faladas apenas com o uso típico de entrada de texto e muitas vezes não conseguem entender a intenção do usuário. Trabalhos anteriores em linguística identificaram uma tendência entre línguas para pausas de fala mais longas em torno de substantivos em comparação com verbos. Demonstramos que a observação linguística em pausas pode ser usada para melhorar a precisão em tarefas de compreensão de linguagem aprendidas por máquina. A análise de pausas em enunciados em francês e inglês de um assistente de voz comercial mostra a diferença estatisticamente significativa na duração da pausa em torno dos limites de extensão de entidade de vários tokens em comparação com intervalos de entidade. Além disso, em contraste com a NLU baseada em texto, aplicamos a duração da pausa para enriquecer as incorporações contextuais para melhorar a análise superficial de entidades. Os resultados mostram que nossos novos embeddings propostos melhoram a taxa de erro relativa em até 8% de forma consistente em três domínios para francês, sem qualquer anotação adicional ou custos de alinhamento para o analisador.', 'es': 'Las etiquetas de entidad en el diálogo hombre-máquina son parte integral de las tareas de comprensión del lenguaje natural (NLU) en los asistentes conversacionales. Sin embargo, los sistemas actuales tienen dificultades para analizar con precisión las consultas habladas con el uso típico de la entrada de texto únicamente y, a menudo, no entienden la intención del usuario. Trabajos anteriores en lingüística han identificado una tendencia entre idiomas a pausas del habla más largas alrededor de los sustantivos en comparación con los verbos. Demostramos que la observación lingüística en las pausas se puede utilizar para mejorar la precisión en las tareas de comprensión del lenguaje con aprendizaje automático. El análisis de las pausas en las expresiones en francés e inglés de un asistente de voz comercial muestra la diferencia estadísticamente significativa en la duración de la pausa alrededor de los límites del intervalo de entidades de varios tokens en comparación con los intervalos dentro de la entidad. Además, a diferencia de la NLU basada en texto, aplicamos la duración de pausa para enriquecer las incrustaciones contextuales y mejorar el análisis superficial de las entidades. Los resultados muestran que nuestras incorporaciones novedosas propuestas mejoran la tasa de error relativo en hasta un 8% de manera consistente en tres dominios para el francés, sin ningún costo adicional de anotación o alineación para el analizador.', 'ja': 'ヒューマンマシンダイアログのエンティティタグは、会話アシスタントの自然言語理解（ NLU ）タスクに不可欠です。 しかしながら、現在のシステムは、テキスト入力の典型的な使用だけで、話し言葉のクエリを正確に解析することに苦労しており、しばしばユーザの意図を理解できない。 言語学における以前の研究では、動詞と比較して、名詞を取り巻くより長い発話休止の傾向が認められている。 私たちは、一時停止に関する言語学的観察が、機械学習言語理解タスクの精度を向上させるために使用できることを実証します。 商用音声アシスタントによるフランス語および英語の発話の一時停止の分析は、複数トークンのエンティティのスパンの境界の周りの一時停止の持続時間がエンティティのスパン内と比較して統計的に有意な差を示しています。 さらに、テキストベースのNLUとは対照的に、エンティティの浅い解析を改善するために、コンテキスト埋め込みを豊富にするために一時停止時間を適用します。 結果によると、提案されている新規の埋め込みは、パーサーにアノテーションやアライメントコストを追加することなく、フランス語の3つのドメイン間で相対的なエラー率を最大8%まで一貫して改善します。', 'zh': '人机对话之实体,会话助手自然语言解 (NLU) 任不可或缺之一体也。 然时统难仅以文本输正解析语音询问,常不解用户意。 前语言学已定一跨语势,即比于动词,名词左右语音顿长。 吾证其可以言观机器学言解事者准确性。 其于商声助手之法语,与英语语之顿见,比之跨度内,多令牌跨度界之顿持续时间著异于计上显。 此外比于文本之 NLU ,宜权宜停持续时间以丰上下文嵌,以改实体之浅层解析。 结果表明三域之新颖嵌法语者,以相错误率为8%,而不为解析器所增注对齐成本。', 'hi': 'मानव-मशीन संवाद में एंटिटी टैग संवादात्मक सहायकों में प्राकृतिक भाषा समझ (एनएलयू) कार्यों के लिए अभिन्न अंग हैं। हालांकि, वर्तमान सिस्टम अकेले पाठ इनपुट के विशिष्ट उपयोग के साथ बोले गए प्रश्नों को सही ढंग से पार्स करने के लिए संघर्ष करते हैं, और अक्सर उपयोगकर्ता के इरादे को समझने में विफल रहते हैं। भाषाविज्ञान में पिछले काम ने क्रियाओं की तुलना में संज्ञाओं के आसपास लंबे समय तक भाषण विराम के लिए एक क्रॉस-लैंग्वेज प्रवृत्ति की पहचान की है। हम प्रदर्शित करते हैं कि विराम पर भाषाई अवलोकन का उपयोग मशीन-सीखी गई भाषा समझने के कार्यों में सटीकता में सुधार करने के लिए किया जा सकता है। एक वाणिज्यिक आवाज सहायक से फ्रेंच और अंग्रेजी उच्चारण में ठहराव का विश्लेषण इकाई स्पैन की तुलना में बहु-टोकन इकाई अवधि सीमाओं के आसपास ठहराव अवधि में सांख्यिकीय रूप से महत्वपूर्ण अंतर दिखाता है। इसके अतिरिक्त, पाठ-आधारित एनएलयू के विपरीत, हम संस्थाओं के उथले पार्सिंग में सुधार करने के लिए प्रासंगिक एम्बेडिंग को समृद्ध करने के लिए विराम अवधि लागू करते हैं। परिणामों से पता चलता है कि हमारे प्रस्तावित उपन्यास एम्बेडिंग फ्रेंच के लिए तीन डोमेन में लगातार 8% तक सापेक्ष त्रुटि दर में सुधार करते हैं, पार्सर के लिए किसी भी अतिरिक्त एनोटेशन या संरेखण लागत के बिना।', 'ru': 'Теги сущностей в диалоге человек-машина являются неотъемлемой частью задач понимания естественного языка (NLU) в помощниках по общению. Тем не менее, современные системы испытывают трудности с точным анализом устных запросов с типичным использованием только ввода текста и часто не понимают намерений пользователя. Предыдущая работа в лингвистике выявила кросс-лингвистическую тенденцию к более длительным паузам речи вокруг существительных по сравнению с глаголами. Мы демонстрируем, что лингвистическое наблюдение на паузах может быть использовано для повышения точности в задачах машинного понимания языка. Анализ пауз во французских и английских высказываниях от коммерческого голосового помощника показывает статистически значимую разницу в продолжительности паузы вокруг границ размаха нескольких токенов сущности по сравнению с внутри размахов сущности. Кроме того, в отличие от текстового NLU, мы применяем длительность паузы для обогащения контекстных вложений для улучшения неглубокого синтаксического анализа сущностей. Результаты показывают, что предлагаемые нами новые вставки улучшают относительную частоту ошибок до 8% последовательно в трех доменах для французского языка без каких-либо дополнительных затрат на аннотацию или выравнивание для анализатора.', 'ga': 'Tá clibeanna aonáin sa dialóg daonna-inneall lárnach do thascanna tuiscint teanga nádúrtha (NLU) i gcúntóirí comhrá. Mar sin féin, bíonn deacrachtaí ag córais reatha fiosrúcháin labhartha a pharsáil go beacht le gnáthúsáid ionchuir téacs amháin, agus is minic nach dtuigeann siad rún an úsáideora. Aithníodh in obair na teangeolaíochta roimhe seo go bhfuil claonadh trastheangach ann go mbeidh sosanna cainte níos faide timpeall ar ainmfhocail i gcomparáid le briathra. Léirímid gur féidir an bhreathnóireacht theangeolaíoch ar sosanna a úsáid chun cruinneas a fheabhsú i dtascanna tuiscint teanga meaisín-fhoghlaim. Léiríonn anailís ar shosanna i bhfocail Fraincise agus Béarla ó chúntóir gutha tráchtála an difríocht shuntasach staitistiúil i ré sosanna timpeall teorainneacha réise aonáin ilchomharthaí i gcomparáid le laistigh de réisí aonáin. Ina theannta sin, i gcodarsnacht le NLU téacsbhunaithe, cuirimid ré sos i bhfeidhm chun leabú comhthéacs a shaibhriú chun parsáil éadomhain eintiteas a fheabhsú. Léiríonn torthaí go bhfeabhsaítear an ráta coibhneasta earráide de suas le 8% go comhsheasmhach thar thrí réimse don Fhraincis mar gheall ar ár leabú úrscéalta molta, gan aon chostais bhreise nó ailínithe don pharsálaí.', 'el': 'Οι ετικέτες οντότητας στο διάλογο ανθρώπου-μηχανής είναι αναπόσπαστο μέρος των εργασιών κατανόησης φυσικής γλώσσας σε βοηθούς συνομιλίας. Ωστόσο, τα τρέχοντα συστήματα δυσκολεύονται να αναλύσουν με ακρίβεια τα προφορικά ερωτήματα με τη συνήθη χρήση της εισαγωγής κειμένου μόνο και μόνο και συχνά αποτυγχάνουν να κατανοήσουν την πρόθεση του χρήστη. Προηγούμενες εργασίες στη γλωσσολογία έχουν εντοπίσει μια τάση μεταξύ γλωσσών για μεγαλύτερες παύσεις ομιλίας που περιβάλλουν ουσιαστικά σε σύγκριση με ρήματα. Αποδεικνύουμε ότι η γλωσσική παρατήρηση σε παύσεις μπορεί να χρησιμοποιηθεί για τη βελτίωση της ακρίβειας σε εργασίες κατανόησης γλώσσας που μαθαίνονται από μηχανές. Η ανάλυση των παύσεων σε γαλλικές και αγγλικές εκφράσεις από έναν εμπορικό βοηθό φωνής δείχνει τη στατιστικά σημαντική διαφορά στη διάρκεια παύσης γύρω από τα όρια κάλυψης οντότητας πολλαπλών σημάτων σε σύγκριση με τα πλαίσια ενότητας. Επιπλέον, σε αντίθεση με το κείμενο, εφαρμόζουμε τη διάρκεια παύσης για να εμπλουτίσουμε τις ενσωματώσεις περιβάλλοντος για να βελτιώσουμε την ρηχή ανάλυση οντοτήτων. Τα αποτελέσματα δείχνουν ότι οι προτεινόμενες νέες ενσωματώσεις βελτιώνουν το σχετικό ποσοστό σφαλμάτων μέχρι και 8% σταθερά σε τρεις τομείς για τα γαλλικά, χωρίς πρόσθετο κόστος σχολιασμού ή ευθυγράμμισης στον αναλυτή.', 'hu': 'Az ember-gép párbeszédpanelen lévő entitáscímkék szerves részét képezik a beszélgetési asszisztensek természetes nyelvmegértési (NLU) feladatainak. A jelenlegi rendszerek azonban nehezen tudják pontosan elemezni a beszélt lekérdezéseket a szövegbevitel tipikus használatával, és gyakran nem értik meg a felhasználói szándékot. Korábbi nyelvészeti munkák azonosították, hogy a főneveket körülvevő hosszabb beszédszünetek iránti tendenciát, mint az igék. Bemutatjuk, hogy a szüneteken végzett nyelvi megfigyelések segítségével javíthatók a gépi nyelvértési feladatok pontossága. A francia és angol nyelvű szünetek elemzése egy kereskedelmi hangasszisztens segítségével azt mutatja, hogy statisztikailag szignifikáns különbség van a szünetek időtartamában a multi-tokenes entitási határok körül az entitási határokhoz képest. Ezenkívül a szövegalapú NLU-val ellentétben szünet időtartamát alkalmazunk a kontextuális beágyazások gazdagítására az entitások sekély elemzésének javítása érdekében. Az eredmények azt mutatják, hogy a javasolt új beágyazások következetesen akár 8%-kal javítják a relatív hibaarányt három francia tartományban, anélkül, hogy az elemző hozzáadott jegyzetelési vagy igazítási költségeket növelnénk.', 'ka': 'ადამიანის მანქანის დიალოგიში ინტერგულია სიტყვის განსხვავებას (NLU) პარამეტრებული asistenტებში. მაგრამ, მიმდინარე სისტემები ძალიან ძალიან წარმოდგენა, რომ მხოლოდ ტექსტის შეტყობინების ტიპიკური გამოყენება, და ძალიან არ შეუძლებელია მომხმარებელი საზო პირველი სამუშაო ლინგურისტიკის განსაზღვრებულია სამუშაო სიტყვების ტენენცია, რომელიც უფრო მეტი სიტყვების განსაზღვრებულია. ჩვენ ევმონსტრაცით, რომ ლენგურისტიკური მონაცემები პოსეზების შესაძლებელია გამოყენება მაქსინურად სწავლილი ენგური განსხვავების საქმებში. ტრანუს და ინგლისური სიტყვების პასუზების ანალიზაცია კომპერაციული სიტყვებისგან სტატისტიკურად მნიშვნელოვანი განსხვავება განსხვავებულია სტატისტიკურად მნიშვნელოვანი ინტე დამატებით, ტექსტის დაბათი NLU-ს კონტრასტში, ჩვენ განვიყენებთ პოსტუსის დროის განმავლობისთვის კონტექსტური დამატებისთვის განმავლობისთვის, რომ უფრო მეტი განმავლობ შედეგი გამოჩვენება, რომ ჩვენი პრომენტის შეცდომა შეცდომის სიმაღლე უფრო მეტი 8% უფრო მხოლოდ სამი დომენი ფრანუსის სახლში, ანტორაციის ან დამატებული სიმაღლე პანსერისთვი', 'it': "I tag delle entità nella finestra di dialogo uomo-macchina sono parte integrante delle attività di comprensione del linguaggio naturale (NLU) negli assistenti conversazionali. Tuttavia, i sistemi attuali faticano ad analizzare accuratamente le query parlate con l'uso tipico di input di testo da solo, e spesso non riescono a capire l'intento dell'utente. Precedente lavoro in linguistica ha identificato una tendenza cross-language per pause vocali più lunghe intorno ai sostantivi rispetto ai verbi. Dimostriamo che l'osservazione linguistica nelle pause può essere utilizzata per migliorare l'accuratezza nelle attività di comprensione delle lingue apprese automaticamente. L'analisi delle pause in francese e inglese da parte di un assistente vocale commerciale mostra la differenza statisticamente significativa nella durata della pausa intorno ai confini della portata di entità multi-token rispetto all'interno degli intervalli di entità. Inoltre, a differenza dell'NLU basata sul testo, applichiamo la durata della pausa per arricchire le incorporazioni contestuali per migliorare l'analisi superficiale delle entità. I risultati mostrano che le nostre nuove incorporazioni proposte migliorano il tasso di errore relativo fino all'8% in modo coerente su tre domini per il francese, senza alcun costo aggiuntivo di annotazione o allineamento per il parser.", 'lt': 'Subjektų žymenys žmogaus ir mašin ų dialoge yra neatsiejamas nuo gamtos kalbos supratimo (NLU) užduočių pokalbių asistentams. Tačiau dabartinės sistemos stengiasi tiksliai išanalizuoti kalbėtus klausimus naudojant tik teksto įrašą ir dažnai nesupranta naudotojo ketinimo. Ankstesnis kalbos tyrimas parodė, kad kalbos pertraukų aplink vardinius žodžius tendencija yra ilgesnė, palyginti su žodžiais. Mes įrodome, kad kalbinis stebėjimas dėl pertraukų gali būti naudojamas tikslesniam mašin ų mokomų kalbų supratimo uždavinių tikslumui gerinti. Prancūzijos ir anglų kalbų pertraukų analizė iš komercinio balso asistento rodo statistiškai reikšmingą pertraukos trukmės skirtumą aplink daugelio ženklų ūkio subjekto intervalo ribas, palyginti su ūkio subjekto intervalais. Be to, priešingai nei tekstu pagrįsta NLU, mes taikome pauzės trukmę, kad praturtintume kontekstinį įterpimą, kad pagerintume paviršin į subjektų analizavimą. Rezultatai rodo, kad mūsų siūlomi nauji įrašai nuolat didina santykinę klaidų lygį iki 8 proc. trijose prancūzų srityse, be jokių papildomų anotacijų ar suderinimo išlaidų analizatoriui.', 'mk': 'Entity tags in human-machine dialog are integral to natural language understanding (NLU) tasks in conversational assistants.  However, current systems struggle to accurately parse spoken queries with the typical use of text input alone, and often fail to understand the user intent.  Претходната работа во лингвистиката идентификуваше тенденција на меѓујазик за подолгите паузи на говорот околу имениците во споредба со речениците. Демонстрираме дека јазичното набљудување на паузите може да се користи за подобрување на прецизноста во задачите за разбирање на јазикот со машинско учење. Анализата на паузите на француски и англиски изрази од комерцијален гласовен асистент ја покажува статистички значителната разлика во траењето на паузата околу границите на растојанието на мнозински ентитети во споредба со границите на ентитетите. Покрај тоа, во разлика од текстовиот НЛУ, применуваме пауза за да ги збогатиме контекстуалните вградувања за подобрување на ниското анализирање на ентитетите. Резултатите покажуваат дека нашите предложени нови вклучувања ја подобруваат релативната стапка на грешки за 8 отсто константно во три домени за француски, без додавање на трошоците за анотација или прилагодување на анализаторот.', 'kk': 'Адам- машинаның диалогындағы нысандар тапсырмаларды қатынау көмекшілерінде тәуелді тілді түсінуге (NLU) деген тапсырмалар үшін бөлек. Бірақ назардағы жүйелер тек мәтін келтірілген сұрақтарды дұрыс талдау үшін жұмыс істейді, әдетте пайдаланушының мақсатын түсінбейді. Лингистикалықтағы алдыңғы жұмыс белгілерімен салыстыру үшін ұзындық сөйлеу тенденциясын анықтады. Біз күту туралы лингвистикалық наблюдение машиналық оқылған тілдердің тапсырмаларын түсіндіру үшін қолданылады. Коммерциялық дыбыс көмекшісінен француз және ағылшын сөздерінің аялдатылығының талдауы бірнеше белгілер арасындағы көп белгілер арасындағы көп белгілер арасындағы көп белгілер арасында Қосымша, мәтін негіздеген NLU- ге қарамастан, біз бағдарламаларды жалғыз талдау үшін контексті ендіру үшін пауза ұзақтығын қолданамыз. Нәтижелер жасалған романдық ендіруіміздің салыстырмалы қатенің жылдамдығын 8% дегенге дейін французша үш доменге салыстырып көрсетеді, оқушыларға қосылған жазбалар не түзету бағалары жо', 'ms': 'Tag entiti dalam dialog mesin-manusia adalah integral kepada tugas pemahaman bahasa alam (NLU) dalam pembantu perbualan. Namun, sistem semasa berjuang untuk hurai pertanyaan bercakap dengan tepat dengan penggunaan biasa input teks sahaja, dan sering gagal memahami niat pengguna. Kerja terdahulu dalam bahasa telah mengenalpasti kecenderungan bahasa-saling untuk istirahat ucapan lebih panjang mengelilingi nama dibandingkan dengan verb. We demonstrate that the linguistic observation on pauses can be used to improve accuracy in machine-learnt language understanding tasks.  Analisi paus dalam ungkapan Perancis dan Inggeris dari pembantu suara komersial menunjukkan perbezaan statistik yang signifikan dalam jangka paus sekitar sempadan jangkauan entiti berbilang-token dibandingkan dengan dalam jangkauan entiti. Selain itu, sebagai perbandingan dengan NLU berdasarkan teks, kami melaksanakan tempoh rehat untuk memperkaya penyampilan kontekstual untuk meningkatkan penghuraian entiti yang rendah. Keputusan menunjukkan bahawa pelengkapan novel yang kami cadangkan meningkatkan kadar ralat relatif sehingga 8% secara konsisten melalui tiga domain untuk Perancis, tanpa sebarang anotasi tambahan atau biaya penyesuaian ke penghurai.', 'ml': 'മനുഷ്യന്\u200d മെഷീന്\u200d ഡയലോഗിലെ എന്റിറ്റി ടാഗ്സുകള്\u200d സ്വാഭാവിക ഭാഷയിലെ ബുദ്ധിമുട്ടുകളിലേക്ക് ഒരുമിച്ചിരിക്കു എന്നാലും ഇപ്പോഴത്തെ സിസ്റ്റത്തില്\u200d സംസാരിക്കപ്പെട്ട ചോദ്യങ്ങള്\u200d കൃത്യമായി പാര്\u200dസ് ചെയ്യുന്നതിനായി പോരാടുന്നു. ടെ ഭാഷകങ്ങളില്\u200d മുമ്പുള്ള ജോലിയുണ്ടാക്കിയിരിക്കുന്നു വാര്\u200dപ്പുകള്\u200dക്ക് ചുറ്റുമുള്ള നീണ്ട സംസാരം നിര്\u200dണ് നിര്\u200dത്താനുള്ള ഭാഷകങ്ങളുടെ നിരീക്ഷണങ്ങള്\u200d മെഷീന്\u200d പഠിക്കുന്ന ഭാഷയിലെ വിശദീകരണത്തില്\u200d കൃത്യമായി മെച്ചപ്പെ ഒരു കമ്പനിഷ്യല്\u200d ശബ്ദം സഹായിയില്\u200d നിന്നും ഫ്രെഞ്ചിലും ഇംഗ്ലീഷ് വാക്കുകളില്\u200d നിന്നും നിര്\u200dത്തുന്ന നിര്\u200dത്തുന്നതിന്റെ അന്വേഷണം പല-ടോങ്ക് വസ്ത കൂടാതെ, വാചകം അടിസ്ഥാനമാക്കുന്ന NLU-നെപ്പറ്റിയുള്ള വ്യത്യാസവും, നിലവിലുള്ള പാര്\u200dസിങ്ങുകള്\u200d മെച്ചപ്പെടുത്തുന്നതിന് വേണ് Results show that our proposed novel embeddings improve the relative error rate by up to 8% consistently across three domains for French, without any added annotation or alignment costs to the parser.', 'mt': 'Entity tags in human-machine dialog are integral to natural language understanding (NLU) tasks in conversational assistants.  Madankollu, is-sistemi attwali qed ibatu biex janalizzaw b’mod preċiż il-mistoqsijiet mitkellma bl-użu tipiku tal-input tat-test waħdu, u spiss jonqsu milli jifhmu l-intenzjoni tal-utent. Xogħol preċedenti fil-lingwistika identifika tendenza translingwistika għal waqfiet itwal tad-diskors madwar ismijiet meta mqabbel mal-verbs. Aħna nuru li l-osservazzjoni lingwistika dwar il-pawżi tista’ tintuża biex tittejjeb il-preċiżjoni fil-kompiti ta’ fehim tal-lingwi li jitgħallmu bil-magna. L-analiżi tal-waqfiet fi kliem Franċiż u Ingliż minn assistent tal-vuċi kummerċjali turi d-differenza statistikament sinifikanti fit-tul tal-waqfiet madwar il-limiti tal-firxa tal-entitajiet b’ħafna tokens meta mqabbla mal-firxa tal-entitajiet. Additionally, in contrast to text-based NLU, we apply pause duration to enrich contextual embeddings to improve shallow parsing of entities.  Ir-riżultati juru li l-inkorporazzjonijiet ġodda proposti tagħna jtejbu r-rata ta’ żball relattiv b’sa 8% b’mod konsistenti fi tliet oqsma għall-Franċiż, mingħajr ebda annotazzjoni miżjuda jew spejjeż ta’ allinjament għall-analizzatur.', 'ro': 'Etichetele entităților din dialogul om-mașină sunt integrate în sarcinile de înțelegere a limbajului natural (NLU) în asistenții conversaționali. Cu toate acestea, sistemele actuale se luptă să analizeze cu exactitate interogările vorbite doar cu utilizarea tipică a introducerii textului și adesea nu reușesc să înțeleagă intenția utilizatorului. Lucrările anterioare în lingvistică au identificat o tendință interlingvistică pentru pauze de vorbire mai lungi în jurul substantivelor, comparativ cu verbele. Demonstrăm că observația lingvistică în pauze poate fi utilizată pentru a îmbunătăți acuratețea în sarcinile de înțelegere a limbilor învățate automat. Analiza pauzelor în limba franceză și engleză de la un asistent vocal comercial arată diferența semnificativă statistic în durata pauzei în jurul limitelor de intervale ale entităților multi-token comparativ cu intervalele entității. În plus, spre deosebire de NLU bazată pe text, aplicăm durata pauzei pentru a îmbogăți încorporările contextuale pentru a îmbunătăți analizarea superficială a entităților. Rezultatele arată că noile noastre încorporări propuse îmbunătățesc rata de eroare relativă cu până la 8% în mod constant pe trei domenii pentru franceză, fără costuri adăugate de adnotare sau aliniere la parser.', 'mn': 'Хүн-машины диалогын бүрдлийн тегтүүд нь байгалийн хэл ойлголтын (НLU) ажлыг харилцааны тусламжтайгаар бүрдүүлдэг. Гэвч одоогийн системүүд текст орноос ганцаараа ашиглаж ярианы кверитүүдийг зөв хуваалцах зорилгодог, ихэвчлэн хэрэглэгчийн зорилго ойлгохгүй. Өмнөх хэлний ухааны ажил нь хэлний хэл дээр илтгэлийн тухай олон хэлний давхар байдлыг тодорхойлдог. Бид завсарлагын хэлний ажиллагааг машин сурсан хэлний ойлголтын даалгаврыг сайжруулахын тулд ашиглаж болно. Француз болон Англи хэлэлцээний зогсохын шинжилгээ нь худалдааны дуу сангийн тусламжтайгаас хэдэн тооны хэмжээний хугацаанд хэдэн тооны зайны хязгаарлалтыг харьцуулахад статистик хэмжээний ялгааг харуулдаг. Мөн текст суурилсан НЛУ-ын эсрэгээр бид баян орчин үеийн байдлыг хөгжүүлэхэд зогсохын тулд зогсохын тулд зогсохын хугацааны хугацааны хугацааны хугацааны хугацааны хугацааны хуга Үүний үр дүнд бидний санал өгсөн шинэ нэвтрүүлэлт нь харьцаатай алдаа хурдыг 8% хүртэл Французчуудын гурван сүлжээнд сайжруулдаг гэдгийг харуулдаг.', 'no': 'Entitetsmerker i menneskardialogen er integral til naturspråksforståking (NLU) i samtaleassistentar. Det gjeldande systemet trur imidlertid for å tolka nøyaktig tale spørjingar med den typiske bruken av tekstinndata alene, og ofte feil å forstå brukaren. Førre arbeid i lingvistikk har identifisert ein krysspråk tendens for lengre tale pauser rundt namn som sammenlignet med verbar. Vi demonstrerer at språkkobservasjonen på pausar kan brukast for å forbedra nøyaktighet i maskinelærte språkkforståking av oppgåver. Analysering av pausar i fransk og engelsk uttrykk frå ei kommersiell stemmeassistent viser den statistisk betydelige forskjellen i pausdura rundt fleire teiknkombinasjonsgrensene i sammenligninga med innbyggingsavstandar. I tillegg, i contrast til tekstbasert NLU, bruker vi pausehandlinga for å rygge kontekst- innbygging for å forbetra fleire tolking av einingar. Resultater viser at våre foreslått innbygging av roman forbedrar relativt feilrate med up to 8% konsistent over tre domene for fransk, utan nokon tilleggskonstilling eller justeringskostnad til tolkaren.', 'pl': 'Tagi podmiotów w dialogu człowiek-maszyna są integralną częścią zadań rozumienia języka naturalnego (NLU) w asystentach konwersacyjnych. Jednak obecne systemy borykają się z dokładną analizą zapytań mówionych przy typowym wykorzystaniu samego wprowadzania tekstu i często nie rozumieją intencji użytkownika. Poprzednie prace w językoznawstwie zidentyfikowały tendencję do dłuższych przerw mowy otaczających rzeczowniki w porównaniu z czasownikami. Pokazujemy, że obserwacja językowa na przerwach może być wykorzystana do poprawy dokładności w zadaniach uczonych maszynowo językiem rozumienia. Analiza przerw w wypowiedziach francuskich i angielskich z komercyjnego asystenta głosowego pokazuje statystycznie istotną różnicę w czasie trwania przerwy wokół granic wielotokenowych jednostek w porównaniu z wewnątrz rozpięć jednostek. Dodatkowo, w przeciwieństwie do tekstowej NLU, stosujemy czas trwania pauzy, aby wzbogacić kontekstowe osadzenia w celu poprawy płytkiego parsowania podmiotów. Wyniki pokazują, że nasze proponowane nowe osadzenia poprawiają względny wskaźnik błędów o nawet 8% konsekwentnie w trzech domenach dla francuskiego, bez dodatkowych adnotacji lub wyrównania kosztów dla parsera.', 'sr': 'Oznake entiteta u dijalogu sa ljudskim mašinama su integralne za prirodno razumevanje jezika (NLU) zadatke u razgovornim asistentima. Međutim, trenutni sistemi se bore za precizno analiziranje govornih pitanja sa tipičnom upotrebom samo teksta, i često ne razumeju nameru korisnika. Prethodni rad na jeziku je identifikovao krstojezičku tendenciju za duži govor, pauze oko imena u usporedbi s verbima. Pokazujemo da se jezička promatranja na pauzi može iskoristiti kako bi se poboljšala tačnost u zadatkima razumevanja jezika koji su naučili mašinom. Analiza pauza na francuskom i engleskom govoru od komercijalnog glasovnog asistenta pokazuje statistički značajnu razliku u trajanju pauze oko granica širenja višetokenih entiteta u usporedbi s unutar prostora entiteta. Pored toga, u suprotnosti sa tekstualnim NLU, primjenjujemo pauzu za bogate kontekstualne integracije kako bi poboljšali plitko parsanje entiteta. Rezultati pokazuju da naša predložena knjiga u novinama poboljšava relativnu stopu greške do 8% konsekventno u tri domena za francuski, bez dodatne annotacije ili poravnanja troškova analizatoru.', 'si': 'මිනිස්සු මැෂින් සංවාදයේ ඉන්න අන්තිම ටැග් සාමාන්\u200dය භාෂාව තේරුම්ගන්න (NLU) වැඩක් සංවාදය සහායා නමුත්, ප්\u200dරස්ථානයේ පද්ධතිය ප්\u200dරශ්නයක් සාමාන්\u200dය භාවිතයෙන් කතා කරපු ප්\u200dරශ්නයක් සඳහා සිද්ධ විශ්ලේෂණය ක භාෂාවිද්\u200dයාත්මක වලින් පිරිසිදු වැඩේ විශාල භාෂාවිද්\u200dයාත්මක විශාල කතාව සඳහා ලොකු කතාව සඳහා වි අපි පැහැදිලි කරනවා විනාශ විදිහට භාෂාත්මක බලන්න පුළුවන් විදිහට පරික්ෂා කරන්න පුළුවන් පරික්ෂාවක්  ප්\u200dරේන්සි සහ ඉංග්\u200dරීසි කියන විශ්ලේෂණ විශ්ලේෂණයක් පෙන්වනවා ව්\u200dයාපාරික ශබ්ද සහායකයෙක් වලින් විශ්ලේෂණය විශ්ලේෂණය ව තවත්, පාළ- අධාරිත NLU වෙනුවෙන්, අපි ප්\u200dරතිස්ථානය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සඳහා ප්\u200dරතිස්ථානය සම්පූ ප්\u200dරතිචාරය පෙන්වන්නේ අපේ ප්\u200dරතිචාරිත ප්\u200dරතිචාරිත ප්\u200dරතිචාරයක් ප්\u200dරතිචාරිතයෙන් 8% වෙනුවෙන් සම්බන්ධ වැරදිලි වැර', 'sv': 'Entitetstaggar i dialog människa-maskin är en integrerad del av NLU-uppgifter i konversationsassistenter. Nuvarande system har dock svårt att korrekt tolka talade frågor med den typiska användningen av textinmatning ensam, och ofta misslyckas med att förstå användarens avsikt. Tidigare arbete inom lingvistik har identifierat en tvärspråklig tendens till längre talpauser kring substantiv jämfört med verb. Vi visar att den språkliga observationen på pauser kan användas för att förbättra noggrannheten i maskinlärda språkkunskaper. Analys av pauser i franska och engelska uttryck från en kommersiell röstassistent visar den statistiskt signifikanta skillnaden i pausens varaktighet kring multi-token entitetsspann gränser jämfört med inom entitetsspann. Till skillnad från textbaserad NLU tillämpar vi paustid för att berika kontextuella inbäddningar för att förbättra ytlig tolkning av entiteter. Resultaten visar att våra föreslagna nya inbäddningar förbättrar den relativa felfrekvensen med upp till 8% konsekvent över tre domäner för franska, utan några extra kommentarer eller justeringskostnader för parsern.', 'so': "Macluumaadka muusikada shaqada ee ku qoran qoraalka maskaxda ee dadku waa mid ka mid ah waxyaabaha ku garashada afka dabiiciga (NLU) ee caawiyayaasha kala hadla. Si kastaba ha ahaatee nidaamka joogtada ah waxay u dagaalamayaan inay si saxda ah u baaraandegaan su'aalaha la hadlay oo kaliya isticmaalka qoraalka oo kaliya, marar badanna ma garan karo qasabka isticmaalaha. Shaqo hore oo luqada ku qoran wuxuu aqoonsaday qaab luqad kala duwan oo ay hadal dheer ku dhamaadaan noocyada ku wareegsan sida la barbarto hadalka. Waxaynu muujinnaa in aragtida afka lagu daayo waxaa loo isticmaali karaa in lagu kordhiyo saxda ah oo lagu barto shaqooyinka barashada luuqada machadka. Analysis of pauses in French and English utterances from a commercial voice assistant shows the statistically significant difference in pause duration around multi-token entity span boundaries compared to within entity spans.  Waxaa kaloo dheer, si ka duwan qoraalka NLU, waxaynu u codsanaynaa mudada joogtada ah si aan u hodanayno meelaha joogtada ah si uu u hagaajiyo baaritaanka dhamaadka. Xilliyadu waxay muuqataa in qofkayada la soo jeeday uu kordhinayo kharashka qaladka ee la soo jeedo ugu badnaan karo 8% si waafaqsan sadex dalool oo faransiis ku yaal, iyadoon ku jirin kharash la xiriiro ama la isbedeli karo baaritaanka.", 'ta': 'மனித இயந்திரம் உரையாடலில் உள்ள தனிப்பட்ட ஒட்டுகள் இயற்கையான மொழி புரிந்து (NLU) பணிகளில் பேசும் உதவியாளர்களில் ஒன்றா However, தற்போதைய அமைப்பு மொழிகளில் முந்தைய வேலை சொற்களுக்கு ஒப்பிடும் வார்த்தைகளை ஒப்பிடும் நீண்ட பேச்சு நிறுத்தும் நிறுத்தும நிறுத்தப்பட்ட மொழியில் மொழி புரிந்து கொள்ளும் செயல்களை மேம்படுத்த முடியும் என்பதை நாம் குறிப்பிடுகிறோம். பிரெஞ்சு மற்றும் ஆங்கிலம் மொழிகளிலிருந்து ஒரு வணிக கேட்பு உதவியாளரில் இருந்து நிறுத்தப்பட்ட இடைவெளியிலிருந்து புள்ளிவிவரமான வேறுபாடு பெர கூடுதலாக, உரையில் அடிப்படையான NLU க்கு மாறாக இருந்தால், நாம் நிறுத்தும் கால அளவை பயன்படுத்துகிறோம் தற்போதைய உள்ளடக்கங்களை வளர்ந்து  முடிவு', 'ur': 'انسان-ماشین دیالوگ میں اینتیٹ ٹاگ طبیعی زبان سمجھنے (NLU) کے کاموں میں نقطے ہیں۔ لیکن، موجود سیسٹم صرف ٹیکسٹ اینپیٹ کے استعمال کے ساتھ صحیح طریقے سے بات کی سؤال کے بارے میں مشغول ہوتے ہیں، اور اکثر اکثر کارساز کا ارادہ سمجھنے کے لئے ناکام ہوتے ہیں. زبان شناسی کے پہلے کام نے کلام کے مقابلہ میں بہت زیادہ زبان کی تنظیم کی ہے۔ ہم دکھاتے ہیں کہ پاوٹوں پر زبان کی نظر استعمال کر سکتے ہیں ماشین کے علم زبان کی سمجھ کے کاموں میں دقیق ترقیت کے لئے استعمال کر سکتے ہیں. فرنس اور انگلیسی کلمات کی تحقیقات فرنس اور انگلیسی کلمات کی تحقیقات ایک تجارتی آواز مددگار سے ایسٹیوں کے اندر مقابلہ کے مطابق بہت سی ٹوکنوں کے اندر متفاوت کی تفاوت دکھاتی ہے. اور اضافہ، متن بنیادی NLU کے مقابلہ میں، ہم ایک ٹیکسٹ کے بارے میں استراحت کی مدت کے لئے استراحت کریں گے کہ بہت کم پارس کرنے کے لئے بہتر ہوں۔ نتیجے دکھاتے ہیں کہ ہماری پیشنهاد نومین ایمبڈینگ کی نسبت خطا رض کو 8% تک پہنچا دیتی ہے جو فرنسیس کے لئے تین ڈومین پر ہمیشہ رہتی ہے، بغیر کسی اضافہ یا برابری کے مطابق پارچر کے لئے اضافہ کیا جائے گا', 'uz': "Name Lekin, ҳозирги системаҳар фақат матн таркибида фойдаланиш мумкин саволларни аниқ тарқатиш учун қизиқтирмоқдалар ва доимо фойдаланиш учун фойдаланувчи ҳожатини тушунишда муваффақиятсиз муваффақиятсиз мумкин. Oldingi tillarda ishni o'xshash tilda o'xshash gapiradigan o'zgarishlar davomida o'zgarishni qo'shishga tayyorlaydi. Biz o'sha ko'rsatganimiz, o'sha vazifalarga tilni o'rganish vazifalarini foydalanish mumkin. Name Qo'shimcha, matn asosida NLU bilan boshqaruvchi davomida, biz maʼlumotlarni kichkina ajratish uchun davom etishni qoʻllayapmiz. Natijalar hodisa ko'rsatadi, yaxshi darajada qo'llanmiz qo'shilgan novel yozib qoʻshilgan xato chegarasini Fransuzcha uchta domen bilan 8% darajaga oshirish mumkin, chegaraga qoʻshish yoki tenglashga qoʻshish qiymati yoʻq.", 'vi': 'Các thẻ liệt kê trong hộp thoại máy tính là một phần của công việc hiểu ngôn ngữ tự nhiên (Ntrường) trong các trợ lý đối thoại. Tuy nhiên, hệ thống hiện tại đang đấu tranh để phân tích chính xác các câu hỏi được đọc bằng cách dùng tiêu biểu của chỉ nhập văn bản, và thường không hiểu được mục đích người dùng. Trước đây, ngôn ngữ học đã xác định được một xu hướng xuyên ngoại ngữ cho những khoảng dừng giọng nói quanh danh từ so với động từ. Chúng tôi chứng minh rằng quan sát ngôn ngữ trên những nốt lặng có thể được dùng để tăng độ chính xác trong các nhiệm vụ hiểu biết ngôn ngữ. Phân tích các tạm dừng ở tiếng Pháp và Anh từ một trợ lý giọng nói thương mại cho thấy sự khác biệt trong tính to án quan trọng trong khoảng thời gian tạm dừng xung quanh giới hạn rộng đa vật thể vượt qua giới hạn so với quy tắc cơ thể. Thêm vào đó, đối với căn bản Ntrường hợp này, chúng tôi tạm dừng thời gian để cải thiện nội dung để khai thác các thực thể nông cạn. Kết quả cho thấy sự nhúng mới dự kiến của chúng ta cải thiện tỷ lệ sai sót tương đối với tới 8=.=) liên tục trong ba miền dành cho người Pháp, không có ghi chú hay chi phí chỉnh sửa thêm cho người phân giải.', 'bg': 'Етикетите за същества в диалоговия прозорец човек-машина са неразделна част от задачите за разбиране на естествения език (НЛУ) в разговорните асистенти. Въпреки това, сегашните системи се борят да анализират точно говорените заявки само с типичната употреба на въвеждане на текст и често не разбират намеренията на потребителя. Предишни изследвания в лингвистиката идентифицират тенденция за по-дълги речни паузи около съществителните в сравнение с глаголите. Ние демонстрираме, че лингвистичното наблюдение на паузите може да се използва за подобряване на точността при машинно изучаваните задачи за разбиране на езика. Анализът на паузите във френските и английските изказвания от търговски гласов асистент показва статистически значимата разлика в продължителността на паузата около границите на обхвата на множество символи в сравнение с тези в обхвата на единиците. Освен това, за разлика от текстово базирания НЛУ, ние прилагаме продължителност на паузата, за да обогатим контекстуалните вграждания, за да подобрим плиткото анализиране на обекти. Резултатите показват, че предложените от нас нови вграждания подобряват относителния процент на грешки с до 8% последователно в три домейна за френски език, без допълнителни разходи за анотация или подравняване на анализатора.', 'nl': "Entiteitstags in het dialoogvenster mens-machine zijn een integraal onderdeel van taken voor het begrijpen van natuurlijke taal (NLU) in gespreksassistenten. Echter, huidige systemen worstelen om gesproken query's nauwkeurig te parsen met het typische gebruik van tekstinvoer alleen en begrijpen vaak niet de bedoeling van de gebruiker. Eerder werk in de linguïstiek heeft een tendens geïdentificeerd voor langere spraakpauzes rondom zelfstandige naamwoorden in vergelijking met werkwoorden. We tonen aan dat de taalobservatie op pauzes kan worden gebruikt om de nauwkeurigheid te verbeteren in machine-learned taalbegrijptaken. Analyse van pauzes in Franse en Engelse uitspraken van een commerciële spraakassistent toont het statistisch significante verschil in pauzeduur rond multi-token entiteitspannegrenzen in vergelijking met binnen entiteitspannen. Bovendien passen we, in tegenstelling tot tekstgebaseerde NLU, pauzeduur toe om contextuele insluitingen te verrijken om oppervlakkige parsing van entiteiten te verbeteren. De resultaten tonen aan dat onze voorgestelde nieuwe embeddings het relatieve foutpercentage met maximaal 8% consistent verbeteren over drie domeinen voor Frans, zonder extra annotatie- of uitlijningskosten voor de parser.", 'da': 'Entitetsmærker i dialogen menneske-maskine er integreret i opgaver med naturlig sprogforståelse (NLU) i samtalsassistenter. De nuværende systemer har imidlertid svært ved at analysere talte forespørgsler præcist med den typiske brug af tekstinput alene, og de forstår ofte ikke brugerens hensigt. Tidligere arbejde i lingvistik har identificeret en tværsproglig tendens til længere talepauser omkring substantiver sammenlignet med verber. Vi demonstrerer, at den sproglige observation på pauser kan bruges til at forbedre nøjagtigheden i maskinlærte sprogforståelsesopgaver. Analyse af pauser i fransk og engelsk udtalelser fra en kommerciel stemmeassistent viser den statistisk signifikante forskel i pausevarighed omkring multi-token entitets spænder grænser sammenlignet med inden for entitets spænder. I modsætning til tekstbaseret NLU anvender vi desuden pausevarighed for at berige kontekstuelle indlejringer for at forbedre overfladisk fortolkning af enheder. Resultaterne viser, at vores foreslåede nye indlejringer forbedrer den relative fejlrate med op til 8% konsekvent på tværs af tre domæner for fransk, uden ekstra annoterings- eller justeringsomkostninger til fortolkeren.', 'hr': 'Oznake objekata u dijalogu ljudskih strojeva integralne su prirodnom razumijevanju jezika (NLU) zadatkima u razgovornim asistentima. Međutim, trenutni sustavi se bore za precizno analiziranje govornih pitanja sa tipičnom upotrebom samo teksta, a često ne razumiju namjeru korisnika. Prethodni rad na jeziku identificirao je tendenciju preko jezika za duže govore pauze oko imena u usporedbi s verbima. Pokazujemo da se jezička promatranja na pauzi može koristiti kako bi se poboljšala preciznost u zadatkima razumijevanja jezika koji su naučili mašinom. Analiza pauza na francuskim i engleskim izjavama od komercijalnog pomoćnika glasa pokazuje statistički značajnu razliku u trajanju pauze oko granica razdoblja višetokenih entiteta u usporedbi s unutar prostora entiteta. Osim toga, suprotno tekstualnom NLU, primjenjujemo trajanje pauze za bogate kontekstualne integracije kako bi poboljšali plitko razmatranje entitata. Rezultati pokazuju da naši predloženi novi integraciji poboljšavaju relativnu stopu greške do 8% konsekventno u tri domena za francuski, bez dodatne annotacije ili prilagodbe troškova analizatoru.', 'de': 'Entity-Tags im Mensch-Maschine-Dialog sind integraler Bestandteil von Aufgaben zum Verstehen natürlicher Sprache (NLU) in Gesprächsassistenten. Heutige Systeme haben jedoch Schwierigkeiten, gesprochene Abfragen mit der typischen Verwendung von Texteingaben allein präzise zu analysieren und verstehen oft nicht die Absicht des Benutzers. Frühere Arbeiten in der Linguistik haben eine sprachübergreifende Tendenz zu längeren Sprachpausen in der Umgebung von Substantiven im Vergleich zu Verben identifiziert. Wir zeigen, dass die sprachliche Beobachtung von Pausen genutzt werden kann, um die Genauigkeit von maschinell erlernten Sprachverständnisaufgaben zu verbessern. Die Analyse von Pausen in französischen und englischen Äußerungen eines kommerziellen Sprachassistenten zeigt den statistisch signifikanten Unterschied in der Pausendauer um Multi-Token Entity Spann Grenzen im Vergleich zu innerhalb Entity Spanns. Im Gegensatz zur textbasierten NLU wenden wir außerdem Pausendauer an, um kontextbezogene Einbettungen zu bereichern, um das flache Parsen von Entitäten zu verbessern. Die Ergebnisse zeigen, dass unsere vorgeschlagenen neuen Einbettungen die relative Fehlerrate um bis zu 8% konsistent in drei Domänen für Französisch verbessern, ohne dass zusätzliche Annotations- oder Ausrichtungskosten für den Parser anfallen.', 'ko': '인간 대화의 실체 표시는 세션 보조원의 자연 언어 이해(NLU) 임무의 구성 부분이다.그러나 현재 시스템은 텍스트 입력만 사용하는 음성 조회를 정확하게 해석하기 어렵고 사용자의 의도를 이해하지 못한다.이전의 언어학 연구에 따르면 동사에 비해 명사 주위의 정지 시간이 더 길다는 것은 일종의 크로스 언어 경향이다.우리는 멈추는 언어에 대한 관찰이 기계 학습 언어 이해 임무의 정확성을 높일 수 있다는 것을 증명했다.상업 음성 조수의 프랑스어와 영어 언어의 정지에 대한 분석에 따르면 실체 경계 주변의 정지 지속 시간과 실체 경계 내의 정지 지속 시간은 통계적으로 현저한 차이가 존재한다.또한 텍스트 기반 NLU보다 일시 중지 기간을 적용하여 컨텍스트 포함을 풍부하게 함으로써 솔리드의 얕은 계층 해석을 개선합니다.그 결과 우리가 제시한 새로운 삽입 방법은 세 개의 법어역에서 상대적인 오류율을 8% 높였고 해석기에 주석이나 정렬 비용을 증가시키지 않았다.', 'id': 'Tag entitas dalam dialog manusia-mesin adalah integral untuk mengerti bahasa alam (NLU) tugas dalam asisten konversasi. Namun, sistem saat ini berjuang untuk menganalisa persis pertanyaan yang dibicarakan dengan penggunaan biasa dari input teks sendirian, dan sering gagal memahami niat pengguna. Pekerjaan sebelumnya dalam bahasa telah mengidentifikasi kecenderungan bahasa salib untuk pidato yang lebih panjang berhenti mengelilingi nama dibandingkan dengan verb. Kami menunjukkan bahwa pengamatan bahasa pada istirahat dapat digunakan untuk meningkatkan akurasi dalam tugas pemahaman bahasa belajar mesin. Analisi istirahat dalam ucapan Perancis dan Inggris dari asisten suara komersial menunjukkan perbedaan statistik signifikan dalam jangka istirahat sekitar batas jangka entitas multi-token dibandingkan dalam jangka entitas. Selain itu, dalam perbedaan dengan NLU berdasarkan teks, kami menerapkan waktu istirahat untuk memperkaya embedding kontekstual untuk meningkatkan penghuraian rendah entitas. Hasil menunjukkan bahwa penerbangan novel kami yang diusulkan meningkatkan tingkat kesalahan relatif dengan sampai 8% konsisten di tiga domain untuk Perancis, tanpa ada annotasi tambahan atau biaya penyesuaian ke parser.', 'sw': 'Alama za ujasiri katika mazungumzo ya mashine ya binadamu ni moja kwa moja kuelewa lugha asili (NLU) katika wasaidizi wa mazungumzo. Hata hivyo, mfumo wa sasa unapambana na kuunganisha maswali yanayozungumzwa kwa sahihi na matumizi ya kawaida ya maandishi peke yake, na mara nyingi hushindwa kuelewa nia ya mtumiaji. Kazi iliyopita katika lugha imetambua tabia ya lugha yenye lugha mbalimbali kwa ajili ya kuacha kwa muda mrefu wa hotuba zinazozunguka vizuri kama ilivyolinganisha na maneno. We demonstrate that the linguistic observation on pauses can be used to improve accuracy in machine-learnt language understanding tasks.  Uchambuzi wa hotuba za Kifaransa na Kiingereza kutoka kwa msaidizi wa sauti ya kibiashara unaonyesha tofauti muhimu katika kipindi cha kukatishwa katika mipaka ya vifaa vingi ikilinganishwa na ndani ya kipindi cha habari. Kwa kuongezea, tofauti na NLU yenye maandishi, tunatumia muda wa kuahirishwa kwa kutajirisha mabango ya kisasa ili kuboresha ubora mdogo wa vitu. Matokeo yanaonyesha kuwa riwaya yetu inayopendekezwa inaboresha kiwango cha makosa kwa kiwango cha asilimia 8 kwa kiasi kikubwa katika maeneo matatu ya Ufaransa, bila kuongezeka kwa gharama za kuongezeka au kupangwa kwa mchambuzi.', 'fa': 'برچسب\u200cهای واحدی در محاورۀ محاورۀ ماشین\u200cهای بشر برای تعلیم زبان طبیعی (NLU) در کمک\u200cکنندگان مکالمه\u200cهای مکالمه بی\u200cنیاز هستند. ولی سیستم\u200cهای فعلی برای دقیقا بررسی از سوالات صحبت می\u200cکنند با استفاده معمولی تنها از ورودهای متن، و اغلب نمی\u200cتوانند قصد کاربر را درک کنند. کار قبلی در زبان\u200cشناسی یک نقطه\u200cای از زبان\u200cهای متفاوتی برای سخنرانی طولانی در محیط اسم\u200cها در مقایسه با زبان استفاده می\u200cکند. ما نشان می دهیم که مراقبت زبان\u200cشناسی در پایگانه\u200cها می\u200cتواند برای بهبود دادن دقیق در کار درک زبان\u200cشناسی ماشین استفاده شود. تحلیل استراحت در زبان فرانسوی و انگلیسی از یک دستیاری صوت تجاری تفاوت در طول استراحت در محدودیت طول استراحت زیادی از محدودیت متفاوت\u200cهای متفاوتی در مقایسه با اندازه\u200cهای متفاوت\u200cهای متفاوت را نشان می\u200cده به اضافه، در مقابل NLU بر پایه متن، مدت استراحت برای وسیله\u200cهای محیط ثروتمندی برای بهترین پاره\u200cبندی زیادی از عناصر استفاده می\u200cکنیم. نتیجه\u200cها نشان می\u200cدهند که توسعه\u200cهای رمانی پیشنهاد ما نرخ خطای نسبتی را به حدود ۸ درصد بیشتر از سه دامنی برای فرانسوی، بدون هزینه\u200cهای اضافه\u200cای یا تنظیم برای بازشنگر، بهتر می\u200cکند.', 'tr': "İnsan-maşyndaky ähli tägleri tebigy dillerin düşünmesine (NLU) tägleri görkezilişinde. Ýöne häzirki sistemler gepleşilen soraglary diňe bir tekst girişi bilen düzgün analyze etmek üçin mücadele edýärler we köplenç Ullançylaryň niýetini düşünemeýärler. Dillerde öňki işlem, verbelere görä durmuş çykyş bilen durmuş dillerde gaty bir görnüş tanap etdi. Biz düzümlerde lingwistiki gözlemek maşyndaky dillerde takyklyklyk diýmek üçin ulanylýar. Fransuzça we iňlisçe sözleriniň biraz komersiýal sesi kömekçisinden duranlaryň, birnäçe-token unit aralygynda, unit aralygynda görä gelişinde statistiki üýtgeşigini görkezýär. Üstelik, metin tabanly NLU'a garşymyzda durmuş durmuşyny baýlamak üçin baýlaşýarys. Netijenler biziň teklip eden romanlarymyzyň görkezilişi ýagdaýyň ratyny 8%-a çenli Fransuz dilinde diňe 3 sahypa artýardygyny görkezýär, oýlçylara hiç hili duýdurma ýa-da çykarma tölegimiz ýok.", 'sq': 'Etiketat e njësisë në dialogun njerëzor-makinë janë integrale në detyrat e kuptimit natyror të gjuhës (NLU) në asistentët bisedorë. Megjithatë, sistemet aktuale luftojnë për të analizuar saktësisht pyetjet e folura me përdorimin tipik të hyrjes së tekstit vetëm dhe shpesh nuk kuptojnë qëllimin e përdoruesit. Puna e mëparshme në gjuhë ka identifikuar një tendencë ndërgjuhësore për pauza më të gjata të fjalimit rreth emrave krahasuar me verbet. Ne demonstrojmë se vëzhgimi gjuhësor në pauza mund të përdoret për të përmirësuar saktësinë në detyrat e kuptimit të gjuhës të mësuar nga makina. Analiza e pauzave në shprehjet franceze dhe angleze nga një ndihmës zëri komercial tregon dallimin statistikisht të rëndësishëm në gjatësinë e pauzave rreth kufijve të fushës së njësisë me shumë shenja krahasuar me brenda fushës së njësisë. Përveç kësaj, në kundërshtim me NLU me bazë teksti, ne aplikojmë afatin e pauzës për të pasuruar përfshirjet kontekstuale për të përmirësuar analizimin e sipërfaqe të njësive. Rezultatet tregojnë se përfshirjet tona të propozuara të reja përmirësojnë normën e gabimeve relativë me deri në 8% në mënyrë konsistente nëpër tre fusha për francezët, pa ndonjë shtim të anotacionit apo kostoja të rregullimit në analizuesin.', 'am': 'በአካባቢው ቋንቋ ማስታወቂያው (NLU) ስራዎችን በአካባቢ ረጃዎች ውስጥ የሚቆጠሩ ተርሚዎች ናቸው፡፡ ምንም እንኳን፣ የአሁኑ ስርዓቶች በተጨማሪው የጽሑፍ ጥያቄ ብቻውን ለመፍጠር ይጋደላሉ፡፡ የቀድሞው ቋንቋ ቋንቋ ውስጥ የቋንቋ ቋንቋ ግንኙነት ከንግግር ጋር በተደረገ ቋንቋ የሚቆርጥ ቁጥጥር አግኝቷል፡፡ የቋንቋ ቋንቋ ማስተዋልም ስራዎችን ለማሻሻል የሚችል የቋንቋ ቋንቋ ማስተዋል ማድረግ እናሳየዋለን፡፡ የንግድ ድምፅ ረዳት በተደረገው ግንኙነት በፖርስቲካ እና በኢንግሊዝኛ ቋንቋዎች ላይ የሚቆጠሩ ግንኙነትን በአካባቢው ድምፅ በተለየ ቁጥጥር በተለይ ግንኙነት ላይ በተለየ ጥያቄ የሚያሳያል፡፡ በተጨማሪም፣ የጽሑፍ አካባቢ (NLU) በተለየ፣ የአሁኑን ግንኙነት አካባቢዎችን ለመጠቀም እናስቀራለን፡፡ ፍጥረቶቹ የአሁኑን አቀማመጥ የቅርብ ስህተት ቁጥጥር በሦስት ፈረንሳይ ክፍተት ላይ 8 በመቶ ያሳድጋል፡፡', 'hy': 'Entity tags in human-machine dialog are integral to natural language understanding (NLU) tasks in conversational assistants.  Այնուամենայնիվ, ներկայիս համակարգերը պայքարում են ճշգրիտ վերլուծել խոսված հարցերը միայն տեքստի ներմուծի բնորոշ օգտագործման հետ, և հաճախ չեն հասկանում օգտագործողի մտադրությունը: Լեզվաբանության նախորդ աշխատանքը բայերի հետ համեմատած ցույց է տալիս երկար խոսքի կանգ առնելու երկար լեզվի հակվածությունը: Մենք ցույց ենք տալիս, որ կանգ առնելու լեզվաբանական հետազոտությունը կարող է օգտագործվել մեքենայով սովորած լեզուների ճշգրիտության բարելավման համար: Ֆրանսերենի և անգլերենի արտահայտությունների վերլուծությունը առևտրային ձայնային օգնականի կողմից ցույց է տալիս դադարի տևողության վիճակագրական նշանակալի տարբերությունը բազմանշան առանձնահատկությունների տարածության սահմանների շուրջ, համեմատած առան Ավելին, հակառակ տեքստի հիմնված ՆԼԵ-ին, մենք կիրառում ենք դադարի տևողությունը կոնտեքստային ներդրումների հարստացնելու համար, որպեսզի բարելավենք էության մակերեսային վերլուծությունը: Արդյունքները ցույց են տալիս, որ մեր առաջարկած նորարար ներդրումները բարելավում են համեմատական սխալների չափը մինչև 8 տոկոսով համեմատաբար ֆրանսերենի երեք բնագավառներում, առանց որևէ նշումների կամ հավասարման արժեքների վերլուծում:', 'bs': 'Etikete podataka u dijalogu ljudskih mašina su integralne za prirodno razumijevanje jezika (NLU) zadatke u razgovornim asistentima. Međutim, trenutni sistemi se bore za precizno analiziranje govornih pitanja sa tipičnom upotrebom samo teksta, i često ne razumiju namjeru korisnika. Prethodni rad na jezičkim jezicima identificirao je krstojezičku tendenciju za duži govor pauze oko imena u usporedbi s verbima. Pokazujemo da se jezička promatranja na pauzi može iskoristiti kako bi se poboljšala preciznost u zadacima razumijevanja jezika koji su naučili mašinom. Analiza pauza na francuskom i engleskom govoru od komercijalnog pomoćnika glasa pokazuje statistički značajnu razliku u trajanju pauze oko granica širenja višetokenih entiteta u usporedbi s unutar prostora entiteta. Osim toga, u suprotnosti sa tekstualnim NLU, primjenjujemo duraciju pauze za bogate kontekstualne integracije kako bi poboljšali plitko analiziranje entitata. Rezultati pokazuju da naše predložene knjige u novelu poboljšavaju relativnu stopu greške do 8% konsekventno u tri domena za francuski, bez dodatne annotacije ili poravnanja troškova analizatoru.', 'af': "Entiteit etikette in die mens- masjien dialoog is integraal tot natuurlike taal verstanding (NLU) opdragte in gesprekslys assistente. Maar, huidige stelsels struikel om regtig gespreek vrae te verwerk met die tipiese gebruik van teks invoer alleen, en dikwels misluk om die gebruiker doel te verstaan. Vorige werk in lingwisiese het 'n kruistaal tendensie geïdentifiseer vir langer spreek staan rondom noume soos vergelyk met verbe. Ons wys dat die lingwisiese opservasie op pause gebruik kan word om die presisie in masjien-leer taal verstaan opdragte te verbeter. Analiseer van pause in Frans en Engels uitspraak van 'n kommersiele stem assistent vertoon die statistiese betaling verskil in pause duur rondom multi- token entiteitspansegrense vergelyk met binne entiteitspanses. In contrast to text-based NLU, we apply pause duration to enrich contextual embedding to improve shallow parsing of entities. Resultate wys dat ons voorgestelde novel inbêdings die relatiewe fout verbeter deur tot 8% konsistentlik deur drie domeine vir Frans, sonder enige bygevoeg annotasie of alignment koste aan die ontwerker.", 'az': 'İnsan-maşın dialoglarındakı bütün etiketlər təbiətli dil anlayışına (NLU) müzakirə yardımcılarında təbiətli işlərdir. Halbuki, ağımdaki sistemlər yalnız mətn girişinin istifadəsi ilə danışan sualları doğrudan ayırmaq üçün mübahisə edir və çox zaman istifadəçinin niyyətini anlamaq üçün başa düşmürlər. Dillərin əvvəlki işləri verblərlə qarşılaşdığı kimi, uzun danışma üçün dillərin ətrafındakı adları tərpənməsi üçün çox dil tərzini tanıdı. Biz göstəririk ki, pauslardaki dil gözləməsi maşın öyrənmiş dil anlama işlərində ədaləti düzəltmək üçün istifadə edilə bilər. Fransızca və İngilizce dilində duranların analizi ticarət səs yardımcısından statistik olaraq müddətlərinin çoxlu-token ünvanların sərhədlərinin ətrafındakı müddətlərin istifadəsində dəyişiklik göstərir. Üstəlik, metin tabanlı NLU ilə dəyişdirilməsində, zəngin müxtəlif məlumatların çoxluğunu daha yaxşılaşdırmaq üçün duran müddəti istifadə edirik. Sonuçlarımız belə göstərir ki, təbliğ edilmiş roman inbinglərinin qohumluq xəta hüquqlarını Fransızca üç domena boyunca 8%-ə qədər daha yaxşılaşdırır, ayırıcıya heç bir təbliğ və tədriğ maliyyəti olmadan.', 'bn': 'মানুষ-মেশিন ডায়ালগের প্রাকৃতিক ভাষা বুঝতে পারে (এনএলইউ) কাজ যোগাযোগী সহকারীদের কাছে প্রাকৃতিক ভাষার তবে বর্তমান সিস্টেম সঠিকভাবে কথা বলা অনুসন্ধান পার্স করার জন্য সংগ্রাম করছে একাই টেক্সট ইনপুট ব্যবহার করে এবং প্রায়শই ব্যবহারকার ভাষার ভাষায় পূর্ববর্তী কাজ চিহ্নিত করা হয়েছে যে ভাষার তুলনায় আরো দীর্ঘ ভাষণের ব্যাপারে কোন ভাষার ব্যাপারে বিরত থ আমরা দেখাচ্ছি যে মেশিন-শিক্ষা ভাষা বুঝতে পারে ভাষার পর্যবেক্ষণ ব্যবহার করতে পারে। বাণিজ্যিক কণ্ঠস্বর সহকারী থেকে ফরাসী ও ইংরেজি ভাষায় বিরতি বিশ্লেষণের বিশ্লেষণ দেখাচ্ছে যে বিষয়বস্তুর সীমানার মধ্যে তুলনায় অনেক গুরুত্বপূর এছাড়াও, টেক্সট ভিত্তিক এনএলইউ-এর বিপরীতে, আমরা বিরতির সময় প্রয়োগ করি যাতে বিষয়বস্তুদের পার্সিং উন্নত করার জন্য সাধারণ বিষয়বস্তু সমৃদ্ধি  ফলাফল দেখা যাচ্ছে যে আমাদের প্রস্তাবিত উপন্যাসের মাধ্যমে আত্মিক ভুলের হার বাড়িয়ে ফ্রেঞ্চের জন্য তিনটি ডোমেনের মাধ্যমে ৮% বেড়ে যায়, য', 'ca': "Les etiquetes de les entitats en el diàleg humano-màquines són integrals a les tasques d'enteniment natural de llenguatge (NLU) en assistents de conversació. Però els sistemes actuals lluiten per analitzar amb precisió les preguntes parlades només amb l'ús típic de les entrades de text, i sovint no entenen la intenció de l'usuari. Previous work in linguistics has identified a cross-language tendency for longer speech pauses surrounding nouns as compared to verbs.  Demostram que l'observació lingüística de les pauses pot ser utilitzada per millorar la precisió en les tasques d'enteniment del llenguatge aprenent a màquines. L'anàlisi de les pauses en frases franceses i angleses d'un assistent de veu comercial mostra la diferència estadísticament significativa en la duració de la pausa al voltant dels límits de l'espai d'entitats multifitxes comparats amb l'espai d'entitats. A més, al contrari de la NLU basada en text, fem pausa per enriquecer les integracions contextuals per millorar l'analització baixa d'entitats. Els resultats mostren que les noves incorporacions proposades milloren el índex d'error relativ d'un 8% consistentment en tres dominys en francès, sense cap anotació ni costos d'alliniament a l'analitzador.", 'et': 'Olemussildid inimese-masina dialoogis on lahutamatud loomuliku keele mõistmise (NLU) ülesannete jaoks vestlusassistentides. Praegustel süsteemidel on aga raskusi räägitud päringute täpse parsimisega ainult tekstisisestuse tüüpilise kasutamisega ning sageli ei mõista kasutaja kavatsust. Varasemad lingvistikas tehtud tööd on tuvastanud keeleülese tendentsi pikematele kõnepausidele nimisõnade ümbruses võrreldes tegusõnadega. Näitame, et keelelist vaatlust pausidel saab kasutada masinõppe keelest mõistvate ülesannete täpsuse parandamiseks. Prantsuse- ja ingliskeelsete kõnede pauside analüüs kommertsliku hääleassisti abil näitab pausi kestuse statistiliselt olulist erinevust mitme märgiga olemi ulatuse piiride ümber võrreldes olemi ulatusega. Lisaks rakendame erinevalt tekstipõhisest NLP-st pausi kestust kontekstipõhiste manustamiste rikastamiseks, et parandada olemite madalat parsimist. Tulemused näitavad, et meie kavandatud uudsed manustamised parandavad suhtelist veamäära kuni 8% võrra järjekindlalt kolmes prantsuse domeenis, ilma et parserile lisataks märkimis- või kohandamiskulusid.', 'cs': 'Značky entit v dialogu člověk-stroj jsou nedílnou součástí úloh porozumění přirozenému jazyku (NLU) v konverzačních asistentech. Současné systémy se však snaží přesně analyzovat mluvené dotazy s typickým použitím textového vstupu samotného a často nedokážou porozumět záměru uživatele. Předchozí práce v lingvistice identifikovala tendenci mezi jazyky k delším pauzám řeči okolo podstatných jmen ve srovnání s slovesami. Ukazujeme, že jazykové pozorování na pauzách může být využito ke zlepšení přesnosti v úkolech strojově učeného porozumění jazyků. Analýza pauz ve francouzských a anglických výrokech komerčního hlasového asistenta ukazuje statisticky významný rozdíl v délce pauzy kolem vícetokenových rozpětí entity ve srovnání s rozpětím entity. Navíc, na rozdíl od textové NLU, používáme délku pauzy k obohacení kontextových vložení pro zlepšení mělké analýzy entit. Výsledky ukazují, že naše navrhované nové vložení zlepšují relativní chybovou míru až o 8% konzistentně napříč třemi doménami pro francouzštinu, bez jakýchkoli přidaných anotací nebo zarovnání nákladů na parser.', 'fi': 'Yksikkötagit ihmisen ja koneen välisessä dialogissa ovat olennainen osa keskusteluavustajien luonnollisen kielen ymmärtämistä (NLU). Nykyiset järjestelmät eivät kuitenkaan pysty tulkitsemaan puhekyselyjä tarkasti pelkällä tekstinsyöttöllä, eivätkä usein ymmärrä käyttäjän tarkoitusta. Aiemmat lingvistiikan opinnot ovat havainneet monikielisen taipumuksen pidemmille puhetauoille substantiivien ympärillä verbeihin verrattuna. Osoitamme, että taukojen kielellisen havainnoinnin avulla voidaan parantaa koneoppimisen kielen ymmärtämisen tarkkuutta. Ranskankielisten ja englanninkielisten lauseiden tauon analyysi kaupallisesta ääniavustajasta osoittaa tilastollisesti merkitsevän eron tauon kestossa monimerkkisten entiteettirajojen ympärillä verrattuna entiteettirajojen sisällä. Lisäksi, toisin kuin tekstipohjainen NLU, käytämme tauon kestoa täydentämään kontekstuaalisia upotuksia entiteettien matalan jäsentämisen parantamiseksi. Tulokset osoittavat, että ehdotetut uudet upotuksemme parantavat suhteellista virheastetta jopa 8% johdonmukaisesti kolmella ranskan verkkotunnuksella ilman lisähuomautus- tai kohdentamiskustannuksia jäsentäjälle.', 'jv': 'structural navigation politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé éntuk ning langga luwih dumadhi kapan langgar sampek bantuan ingkang luwih dumadhi kapan kanggo nggawe gerarané karo verb. Awak dhéwé éntuk nglanggar kuwi pawaran kanggo nguasai pawaran kanggo nggawe gerakan kanggo nggawe barang nggawe barang maburén. Tanalé kapan kanggo ngilanggar Perancis lan ingles politenessoffpolite"), and when there is a change ("assertivepoliteness Ngomongé wong-wong kuwi nggawe dolanan sing dibenalke boton sing nyimpen karo eror sing dumadhi tanggal 8% sampek sabên telu domain kanggo sabên Perancis, lan ora nambah sing apik, dadi sing nambah nyong, iso ngubah sing dibenalke mrogram.', 'he': 'תוויות יחידות בדיולוג בני אדם-מכונה הן אינטגרטליות למשימות הבנה טבעית של שפת (NLU) בעוזרים שיחה. בכל אופן, מערכות הנוכחיות נאבקות לאבד בדיוק את השאלות המפורסמות עם השימוש הטיפוסי של הכניסה טקסטית לבד, ולפעמים קרובות לא מבינים את כוונת המשתמש. העבודה הקודמת בשפתיים זיהיה נטייה לשפת צליבה לאורך הפסקות דיבורים מסביבות לשמועות בהשוואה לכתבים. אנחנו מראים שהתצפית השפתית על הפסקות יכולה להשתמש כדי לשפר את הדיוק במשימות הבנה של שפת ללמוד במכונות. Analysis of pauses in French and English utterances from a commercial voice assistant shows the statistically significant difference in pause duration around multi-token entity span boundaries compared to within entity spans. בנוסף, בניגוד לני.אן.איי מבוסס בטקסט, אנו משתמשים במשך הפסקה כדי לעשיר תוכניות קונטקסטיות התוצאות מראות שהתוכניות הרומניות המוצעות שלנו משתפרות את שיעור השגיאות היחסית עד 8% באופן קבוע בשלושה תחומות לצרפתית, בלי שום ציונים נוספים או עלות התאמה למחקר.', 'ha': "Tagogi na cikin zauren akwatin bayanin mutum-mafaɓa, masu haɗi zuwa masu fahimtar da harshen asili (NLU) cikin mataimaki masu haɗi. A lokacin da, na'urar da ake kai yanzu don ya yi amfani da matsayin ayuka da aka faɗaɗa su daidaita, kuma ana kasa yin fahimta da sunan mai amfani da shi kawai. Yin aikin da ya gabata cikin harshen ya gane wata na'urar-harshen-tsohon wa'urar-sauran da aka yi wa daɗi a cire-nau'in da aka sami zuwa verbs. Tuna nũna cewa tsarin lugha da za'a yi amfani da shi dõmin a improve tsari a cikin aikin masu fahimtar harshen-da-zane. Anarari wa saurin da aka yi fasa cikin French da Ingiriya daga wani mataimaki wa sauti na fatauci, yana nũna wa tsakanin mai muhimmi cikin lokaci da aka yi tsawo a tsakanin maɓallin multi-tag span da aka sammeni da kuma a cikin kwanan kwanan-span abun. Furan, da inganci da aka inganci da NLU na rubutun matsayi, za mu yi amfani da durowa wa lokaci wa za'a rikitar da embedded guda don ya canza parse ɗin basu. Results show that our proposed novel embeddings improve the relative error rate by up to 8% consistently across three domains for French, without any added annotation or alignment costs to the parser.", 'bo': 'མིག་དང་མ་ལག་གི་གླེང་སྒྲོམ་ནང་གི་ཤོག་བྱང་རྣམས་རང་རུང་བའི་སྐད་རིགས་ལ་ཕན་ཚུལ་ལྡན་པའི་བྱ་རིམ། ཡིན་ནའང་། ད་ལྟོའི་མ་ལག་གིས་ཡིག སྐད་རིགས་སྐད་ཡིག་ནང་གི་སྔོན་གྱི་ལས་ཀ་དེ་ལ་སྐད་རིགས་ཀྱི་སྣ་ཚོགས་རམ་ཅིག་མཐོང་བ་ཡིན། ང་ཚོས་ཐེངས་ཐོག་ཏུ་སྐད་རིགས་ལྟ་ཀློག་ནི་ཐ་སྙད་པའི་མཐོང་ཚད་འཛིན་བྱེད་པར་སྤྱོད་ཐུབ་པ་ལས་་་ བརྡ་སྤྲོད་ཀྱི་སྐད་ཆ་རྣམས་དང་དབྱིན་ཡིག་གི་བརྗོད་ཐོག་ལས་ཐུམ་འཕྱུར་བའི་བརྡ་ཞིབ་ཀྱིས་པར་རྩིས་གཏོང་། འོན་ཀྱང་། ཡི་གེའི་རྨས་གཞི་ལ་ཡོད་པའི་NLU་དང་མཐུན་པ་ལས། ང་ཚོས་རྣམ་གྲངས་ཀྱི་གནས་ཚུལ་ཁུངས་བསྐྲུན་གཏོང་བའི་སྐབས་མཚམས་འཇུག་ས གྲུབ་འབྲས་བ་དེ་ནི་ང་ཚོའི་སྔོན་སྒྲིག་གསར་བ་ནང་དུ་འཇུག་སྣོད་པར་ལྡན་པའི་ནོར་འཁྲུལ་ལྟར་ཡར་རྒྱས་གཏོང་ཡོད་པ་ལས་ཉེན་རྐྱེན་ཡིན', 'sk': 'Oznake entitet v pogovornem oknu človek-stroj so sestavni del opravil razumevanja naravnega jezika (NLU) v pogovornih pomočnikih. Vendar pa sedanji sistemi težko natančno razčlenijo govorjene poizvedbe samo z običajno uporabo vnosa besedila in pogosto ne razumejo namena uporabnika. Prejšnje delo v jezikoslovju je ugotovilo nagnjenost k daljšim govornim premorom okoli samostalnikov v primerjavi z glagoli. Pokazali smo, da je jezikovno opazovanje na premorih mogoče uporabiti za izboljšanje natančnosti strojno učenih nalog razumevanja jezika. Analiza premorov v francoskem in angleškem izgovoru s komercialnega glasovnega pomočnika kaže statistično značilno razliko v trajanju premora okoli meja obsega več žetonov entitet v primerjavi z znotraj obsega entitet. Poleg tega v nasprotju z besedilnim NLU uporabljamo trajanje pavze, da bogatimo kontekstualne vdelave in izboljšamo plitvo razčlenjevanje entitet. Rezultati kažejo, da naše predlagane nove vdelave dosledno izboljšujejo relativno stopnjo napak za do 8% v treh domenah za francoščino, brez dodanih stroškov pripomb ali uskladitve razčlenjevalniku.'}
{'en': 'Teach Me What to Say and I Will Learn What to Pick : Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models', 'es': 'Enséñame qué decir y aprenderé qué elegir: selección de conocimiento sin supervisión a través de la generación de respuestas con modelos generativos preentrenados', 'ar': 'علمني ماذا أقول وسأتعلم ماذا أختار: اختيار المعرفة غير الخاضع للإشراف من خلال توليد الاستجابة باستخدام النماذج التوليدية المدربة مسبقًا', 'fr': "Apprenez-moi ce que je dois dire et j'apprendrai ce qu'il faut choisir\xa0: sélection de connaissances non supervisée par génération de réponse avec des modèles génératifs préentraînés", 'ja': '何を言うべきかを教え、何を選ぶべきかを学びます：事前に訓練された生成モデルによる応答生成を通じて、監督されていない知識の選択', 'pt': 'Ensine-me o que dizer e eu aprenderei o que escolher: seleção de conhecimento não supervisionada por meio da geração de respostas com modelos generativos pré-treinados', 'ru': 'Научите меня, что сказать, и я научусь, что выбрать: неконтролируемый отбор знаний через генерацию ответов с заранее обученными генеративными моделями', 'zh': '教我言,吾将学之:豫教之形,以应无监之知', 'hi': 'मुझे सिखाएं कि क्या कहना है और मैं सीखूंगा कि क्या चुनना है: पूर्वप्रशिक्षित जनन मॉडल के साथ प्रतिक्रिया पीढ़ी के माध्यम से असुरक्षित ज्ञान चयन', 'ga': 'Múin dom Cad atá le rá agus Foghlaimeoidh Mé Cad a Roghnóidh: Roghnú Faisnéise Gan Maoirseacht Trí Ghiniúint Freagartha le Múnlaí Giniteacha Réamhthraenáilte', 'hu': 'Taníts meg, mit mondjak, és megtanulom, mit válasszak: Felügyelet nélküli tudásválasztás a válasz generálásán keresztül előkészített generációs modellekkel', 'el': 'Μάθε με τι να πω και θα μάθω τι να διαλέξω: Μη εποπτευόμενη επιλογή γνώσης μέσω της δημιουργίας απόκρισης με προκαθορισμένα Generative μοντέλα', 'ka': 'მე ვისწავლეთ რა უნდა ვთქვათ და მე ვისწავლე რა მონიშნოთ: არაფერიზებული მეცნიერების არჩევა განსხვავებით განსხვავებით განსხვავებით განსხვავებით განსხვავებით შემდეგ წ', 'it': 'Insegnami cosa dire e imparerò cosa scegliere: selezione delle conoscenze non supervisionate attraverso la generazione di risposte con modelli generativi pretensionati', 'lt': 'Mokykite mane ką pasakyti ir išmoksiu ką pasirinkti: Neprižiūrima žinių atranka per atsako generaciją su išankstinio mokymo generaciniais modeliais', 'kk': 'Неге айтуды оқыту мен не таңдау үшін оқытуды үйренемін: жауап беру үлгілерімен жауап беру арқылы мәліметті таңдау', 'mk': 'Научи ме што да кажам и ќе научам што да изберам: Ненадгледуван избор на знаење преку генерација на одговор со претренирани генеративни модели', 'ms': 'Ajarkan saya apa yang perlu dikatakan dan saya akan belajar apa yang perlu dipilih: Pemilihan pengetahuan tanpa pengawasan melalui Jenerasi Respon dengan Model Generatif Terlatih', 'mt': "Tagħraf X'għandi ngħid u se nitgħallem X'għandi nagħżel: Għażla ta' Għarfien Mhux Sorveljat Permezz tal-Ġenerazzjoni ta' Rispons b'Mudelli Ġenerattivi Mħarrġa minn Qabel", 'ml': 'എന്ത് പറയണം എന്ന് പഠിപ്പിക്കുക. എന്ത് തെരഞ്ഞെടുക്കണമെന്ന് ഞാന്\u200d പഠിപ്പിക്കാം: പഠിപ്പിക്കപ്പെട്ട ജനറല്\u200d മോഡിളുമായി', 'no': 'Lær meg hva skal si, og eg vil læra kva å velja: Utval av ukjend kjennomsikt gjennom oppretting av svar med forståande genererte modeller', 'pl': 'Naucz mnie, co powiedzieć, a ja dowiem się, co wybrać: nienadzorowany wybór wiedzy poprzez generowanie odpowiedzi za pomocą wstępnie przeszkolonych modeli generacyjnych', 'ro': 'Învață-mă ce să spun și voi învăța ce să aleg: Selectarea cunoștințelor nesupravegheate prin generarea de răspunsuri cu modele generative pretrainate', 'si': 'මට කියන්න මොකද්ද කියලා ඉගෙන ගන්නේ, මම ඉගෙන ගන්නම් මොකද්ද තෝරාගන්නේ: ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විදියට', 'so': 'Tear Me What to say and I will Learn What to Pick: Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models', 'sv': 'Lär mig vad jag ska säga och jag kommer att lära mig vad jag ska välja: Oserverat kunskapsval genom responsgenerering med förutbestämda generativa modeller', 'sr': 'Nauči me šta da kažem i naučiću šta da biram: neodređeni izbor znanja kroz generaciju odgovora sa predivnim modelima generacije', 'mn': 'Надад юу хэлэх вэ гэдгийг зааж өгье. Би юу сонгох вэ гэдгийг суралцах болно: Хариултын хариу үйлдвэрлэлийн төрөл төрөлхтний загваруудын хувьд', 'ur': 'مجھے بتاؤ کہ کیا کہوں اور میں بتاؤں کہ کیا انتخاب کروں گا: غیر محفوظ علم اختیار کے ذریعہ جواب سنانے والوں کے ذریعہ جو بہترین نمونے ہیں', 'ta': 'என்ன சொல்ல வேண்டும் என்று எனக்கு கற்றுக் கொடுக்கவும், நான் என்ன தேர்வு கற்றுக் கொள்வேன்: முன்னேற்றப்பட்ட உருவாக்க முடியும்', 'uz': "Nima aytishni o'rgang va nima qilishni o'rganaman: Taʼminlovchi nomaʼlum tanlanmagan javob berilmagan javob yaratish muvaffaqiyatsiz modellari orqali", 'vi': 'Dạy tôi nói gì và tôi sẽ biết phải chọn gì: Chọn kiếm thức không giám sát qua Thế Hệ Đáp ứng với Chế độ Tự Động Giả Giả.', 'hr': 'Nauči me što da kažem i naučit ću što da biram: neodređen izbor znanja kroz generaciju odgovora sa predivnim modelima generacije', 'nl': 'Leer me wat te zeggen en ik zal leren wat te kiezen: onbewaakte kennisselectie door responsgeneratie met vooraf getrainde generatieve modellen', 'de': 'Bringen Sie mir bei, was zu sagen ist und ich werde lernen, was zu wählen ist: Unbeaufsichtigte Wissensauswahl durch Response Generation mit vortrainierten Generativen Modellen', 'id': 'Mengajarkan saya apa yang harus dikatakan dan saya akan belajar apa yang harus dipilih: Pemilihan pengetahuan yang tidak diawasi melalui generasi respon dengan Model Generatif Terlatih', 'bg': 'Научи ме какво да кажа и ще науча какво да избера: Неконтролиран подбор на знания чрез генериране на отговор с предварително обучени генеративни модели', 'sw': 'Nifundishe Nini Niseme na nitajifunza Nini ya kuchagua: Uchaguzi wa maarifa yasiyoangaliwa kupitia Uzalishaji wa Jibu na Modeli zilizojifunza', 'tr': 'Bana ne s철yleyece휓imi 철휓ret ve ne se챌meyi 철휓renece휓im: Ta힊캇nmam캇힊 Bilgi Se챌imi D철n체힊t체r체len D철n체힊t체r체len D체zenleme Modelleri ile', 'ko': '나에게 무엇을 말하는지 가르쳐 주면 나는 무엇을 선택하는지 배울 수 있다. 예훈련을 통해 모델을 생성하고 반응을 생성하며 무감독의 지식 선택을 한다.', 'da': 'Lær mig, hvad jeg skal sige, og jeg vil lære, hvad jeg skal vælge: Uovervåget vidensvalg gennem responsgenerering med prætrænede generative modeller', 'fa': 'به من آموزش بده چه بگویم و یاد می\u200cگیرم چی برگزینم: برگزیدن دانش غیرقابل توجه به نسل جواب با نمونه\u200cهای مختلف', 'af': 'Leer My Wat om te sê en ek sal leer Wat om te kies: Ononderwerp kennis Keuse Deur Antwoord Generasie', 'sq': 'MĂ« mĂ«so Ă§farĂ« tĂ« them dhe do tĂ« mĂ«soj Ă§farĂ« tĂ« zgjedh: zgjedhje e njohurive tĂ« pashpejtuara nĂ«pĂ«rmjet gjenerimit tĂ« pĂ«rgjigjeve me modele gjenerative tĂ« parastĂ«rvitura', 'am': 'ምን ልናገር አስተምሩኝ እና ምን ልምረጡ እማራለሁ: Unwatched Knowledge Selection through Response Generation with Pretrained Generative Models', 'hy': 'Ինձ սովորեցրու, թե ինչ ասել, և ես կսովորեցնեմ, թե ինչ ընտրել. անվերահսկված գիտելիքների ընտրությունը պատասխանի ստեղծման միջոցով նախապատրաստված գեներատիվ մոդելներով', 'bn': 'আমাকে কি বলতে শিখিয়ে দাও এবং আমি কি নির্বাচন শিখিয়ে দিবো: প্রশিক্ষিত জেনারেটিভ মোডেলের মাধ্যমে অনভায়ভাবে জ্ঞান নির্বাচনের ম', 'ca': 'Ensenyeu-me què dir i aprendré què escollir: Selecció de coneixements sense supervisió a través de la generació de resposta amb models generals pré-entrenats', 'az': 'Mənə nə deyiləcəyini öyrətin və mən nəyi seçəcəyini öyrənəcəyəm: Öyrənməyən elm seçməsini Öyrənəcəyəm: Öyrənməyən nütfədə olan nütfədə müəyyən edilmiş nütfədə', 'et': 'Õpeta mulle, mida öelda ja ma õpin, mida valida: järelevalveta teadmiste valik vastuse genereerimise kaudu eelnevalt treenitud generatiivsete mudelitega', 'fi': 'Opeta minulle, mitä sanoa, niin opin, mitä valita: valvomaton tietämyksen valinta vastausten luomisen kautta ennalta koulutetuilla generatiivisilla malleilla', 'bs': 'Nauči me šta da kažem i naučiću šta da biram: neodređeni izbor znanja iz generacije odgovora sa modelima predivnih generacija', 'cs': 'Naučte mě, co říct a já se naučím, co si vybrat: Výběr znalostí bez dohledu prostřednictvím generování reakcí s předprogramovanými generačními modely', 'jv': 'Yalewat aku sing arep nggambar lan aku cilen piye nggawe Kemerdekaan Winih: masalah luwih apik Kemerdekaan Karo responsuji kapan Generasi Gak Kemerdekaan Generasi', 'sk': 'Nauči me, kaj naj rečem in naučil se bom, kaj naj izberem: izbira znanja brez nadzora skozi ustvarjanje odzivov s predhodno uveljavljenimi generativnimi modeli', 'ha': "Ka sanar da Ni abin da ya faɗa kuma In Za Za Za Za Za Zaɓi: Zaɓi Zani Babba'a da Cilmi Daidai da Jawab Gidan da aka Faso da Motsi na Tayyar da", 'he': 'Teach Me What to Say and I Will Learn What to Pick: Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models', 'bo': '嘟勦紜嘟｀紜嘟呧讲嗉嬥綎嘟︵綐嗉嬥綎嗑赤郊嗉嬥絺嘟忇郊嘟勦紜嘟撪紞 嘟勦溅嗉嬥絽嘟侧紜嘟炧讲嘟傕紜嘟傕綉嘟樴紜嘟︵綘嘟侧紜嘟︵緪嘟监舰嗉嬥剑嗉嬥綎嘟︵境嘟栢紜嘟撪紞 嘟︵荆嘟勦紜嘟樴胶嘟戉紜嘟斷綘嘟侧紜嘟む胶嘟︵紜嘟氞郊嘟傕溅嗉嬥絺嘟戉綐嗉嬥溅嘟犩讲嗉嬥綐嘟愢酱嘟撪紜嘟︵荆嘟脆綐嗉嬥綒嘟监絺嘟︵紜嘟戉絼嗉嬥綐嘟夃綐嗉嬥綉'}
{'en': 'Knowledge Grounded Conversation Models are usually based on a selection / retrieval module and a generation module, trained separately or simultaneously, with or without having access to a ‘gold’ knowledge option. With the introduction of large pre-trained generative models, the selection and generation part have become more and more entangled, shifting the focus towards enhancing knowledge incorporation (from multiple sources) instead of trying to pick the best knowledge option. These approaches however depend on knowledge labels and/or a separate dense retriever for their best performance. In this work we study the unsupervised selection abilities of pre-trained generative models (e.g. BART) and show that by adding a score-and-aggregate module between ', 'es': 'Los modelos de conversación basados en el conocimiento generalmente se basan en un módulo de selección/recuperación y un módulo de generación, entrenados por separado o simultáneamente, con o sin acceso a una opción de conocimiento «dorada». Con la introducción de grandes modelos generativos previamente entrenados, la parte de selección y generación se ha enredado cada vez más, cambiando el enfoque hacia la mejora de la incorporación del conocimiento (de múltiples fuentes) en lugar de tratar de elegir la mejor opción de conocimiento. Sin embargo, estos enfoques dependen de etiquetas de conocimiento y/o de un recuperador denso separado para obtener el mejor rendimiento. En este trabajo estudiamos las habilidades de selección no supervisada de los modelos generativos previamente entrenados (por ejemplo, BART) y mostramos que al agregar un módulo de puntuación y agregación entre el codificador y el decodificador, son capaces de aprender a elegir el conocimiento adecuado minimizando la pérdida de modelado del lenguaje (es decir, sin tener etiquetas de acceso a conocimientos). Entrenado como tal, nuestro modelo, K-Mine, muestra un rendimiento competitivo de selección y generación frente a modelos que se benefician de etiquetas de conocimiento y/o recuperadores densos separados.', 'fr': "Les modèles de conversation fondés sur les connaissances sont généralement basés sur un module de sélection/récupération et un module de génération, formés séparément ou simultanément, avec ou sans accès à une option de connaissances «\xa0or\xa0». Avec l'introduction de grands modèles génératifs pré-entraînés, la partie sélection et génération est devenue de plus en plus enchevêtrée, déplaçant l'accent sur l'amélioration de l'intégration des connaissances (provenant de sources multiples) au lieu d'essayer de choisir la meilleure option de connaissances. Ces approches dépendent toutefois des labels de connaissances et/ou d'un récupérateur dense distinct pour obtenir les meilleures performances. Dans ce travail, nous étudions les capacités de sélection non supervisée de modèles génératifs pré-entraînés (par exemple BART) et montrons qu'en ajoutant un module de score et d'agrégation entre l'encodeur et le décodeur, ils sont capables d'apprendre à sélectionner les bonnes connaissances en minimisant la perte de modélisation du langage (c'est-à-dire sans avoir accès aux labels de connaissances). Formé en tant que tel, notre modèle - K-Mine - montre des performances de sélection et de génération compétitives par rapport aux modèles qui bénéficient d'étiquettes de connaissances et/ou de récupérateurs denses séparés.", 'ar': 'تستند نماذج المحادثة القائمة على المعرفة عادة إلى وحدة اختيار / استرجاع ووحدة توليد ، يتم تدريبها بشكل منفصل أو في وقت واحد ، مع أو بدون إمكانية الوصول إلى خيار المعرفة "الذهبي". مع إدخال النماذج التوليدية الكبيرة المدربة مسبقًا ، أصبح جزء الاختيار والتوليد أكثر تشابكًا ، مما أدى إلى تحويل التركيز نحو تعزيز دمج المعرفة (من مصادر متعددة) بدلاً من محاولة اختيار أفضل خيار معرفي. ومع ذلك ، تعتمد هذه الأساليب على تسميات المعرفة و / أو مسترد كثيف منفصل للحصول على أفضل أداء. في هذا العمل ، ندرس قدرات الاختيار غير الخاضعة للإشراف للنماذج التوليدية المدربة مسبقًا (على سبيل المثال BART) ونبين أنه من خلال إضافة وحدة النقاط والتجميع بين وحدة التشفير وفك التشفير ، فإنهم قادرون على تعلم اختيار المعرفة المناسبة من خلال تقليل اللغة إلى الحد الأدنى فقدان النمذجة (أي بدون الوصول إلى ملصقات المعرفة). على هذا النحو ، فإن نموذجنا - K-Mine - يُظهر الاختيار التنافسي وأداء التوليد مقابل النماذج التي تستفيد من ملصقات المعرفة و / أو المسترد الكثيف المنفصل.', 'pt': "Os Modelos de Conversação Baseada no Conhecimento geralmente são baseados em um módulo de seleção/recuperação e um módulo de geração, treinados separadamente ou simultaneamente, com ou sem acesso a uma opção de conhecimento 'ouro'. Com a introdução de grandes modelos generativos pré-treinados, a parte de seleção e geração tornou-se cada vez mais emaranhada, mudando o foco para melhorar a incorporação de conhecimento (de múltiplas fontes) em vez de tentar escolher a melhor opção de conhecimento. Essas abordagens, no entanto, dependem de rótulos de conhecimento e/ou de um denso retriever separado para seu melhor desempenho. Neste trabalho, estudamos as habilidades de seleção não supervisionada de modelos generativos pré-treinados (por exemplo, BART) e mostramos que, adicionando um módulo de pontuação e agregação entre codificador e decodificador, eles são capazes de aprender a escolher o conhecimento adequado minimizando a linguagem perda de modelagem (ou seja, sem ter acesso a rótulos de conhecimento). Treinado como tal, nosso modelo - K-Mine - mostra seleção competitiva e desempenho de geração em relação a modelos que se beneficiam de rótulos de conhecimento e/ou retriever denso separado.", 'ja': '知識基盤型会話モデルは、通常、「ゴールド」知識オプションへのアクセスの有無にかかわらず、別々にまたは同時にトレーニングされた選択/検索モジュールと生成モジュールに基づいています。 大規模な事前訓練された生成モデルの導入に伴い、選択と生成の部分がますます絡み合い、最良の知識オプションを選択しようとするのではなく、（複数のソースからの）知識の組み込みを強化することに焦点を移しています。 しかしながら、これらのアプローチは、それらの最高のパフォーマンスのために、知識ラベルおよび／または別個の密集リトリーバーに依存する。 この研究では、事前に訓練された生成モデル（例えば、BART ）の監督されていない選択能力を研究し、エンコーダとデコーダの間にスコアアンドアグリゲートモジュールを追加することで、言語モデリングの損失を最小限に抑えることによって（すなわち、知識ラベルにアクセスすることなく）適切な知識を選択することを学習できることを示します。 そのように訓練された当社のモデル、K - Mineは、ナレッジラベルや個別の高密度リトリーバーの恩恵を受けるモデルに対して、競争力のある選択と生成性能を示しています。', 'zh': '大抵知识之对,常于择/检模块成模块,独与同时训练,权访黄金选项。 随大预练成模之引入,选成转相纠缠,转增知识整合(出于数),非试择其最佳者选项。 然其法赖于标/独密检索器以获得最佳性能。 于此之事,考其成形(如BART)之无监择,明加分数聚模块于编码器解码器之间,其能以最小化言建模损(无法访问知)以学择正也。 若此者, - K-Mine - 与受益/独密检索器,见竞争力之选而成性也。', 'hi': "नॉलेज ग्राउंडेड कन्वर्सेशन मॉडल आमतौर पर एक चयन / पुनर्प्राप्ति मॉड्यूल और एक पीढ़ी मॉड्यूल पर आधारित होते हैं, जो अलग-अलग या एक साथ प्रशिक्षित होते हैं, एक 'गोल्ड' ज्ञान विकल्प तक पहुंच के साथ या बिना। बड़े पूर्व-प्रशिक्षित उत्पादक मॉडल की शुरुआत के साथ, चयन और पीढ़ी का हिस्सा अधिक से अधिक उलझ गया है, सर्वोत्तम ज्ञान विकल्प चुनने की कोशिश करने के बजाय ज्ञान निगमन (कई स्रोतों से) को बढ़ाने की दिशा में ध्यान केंद्रित कर रहा है। हालांकि ये दृष्टिकोण ज्ञान लेबल और / या उनके सर्वोत्तम प्रदर्शन के लिए एक अलग घने रिट्रीवर पर निर्भर करते हैं। इस काम में हम पूर्व-प्रशिक्षित उत्पादक मॉडल (जैसे BART) की असुरक्षित चयन क्षमताओं का अध्ययन करते हैं और दिखाते हैं कि एन्कोडर और डिकोडर के बीच एक स्कोर-एंड-एग्रीगेट मॉड्यूल जोड़कर, वे भाषा मॉडलिंग हानि को कम करने के माध्यम से उचित ज्ञान चुनने के लिए सीखने में सक्षम हैं (यानी ज्ञान लेबल तक पहुंच के बिना)। इस तरह के रूप में प्रशिक्षित, हमारा मॉडल - के-माइन - उन मॉडलों के खिलाफ प्रतिस्पर्धी चयन और पीढ़ी के प्रदर्शन को दिखाता है जो ज्ञान लेबल और / या अलग-अलग घने रिट्रीवर से लाभ उठाते हैं।", 'ru': 'Модели основанного на знаниях разговора обычно основаны на модуле выбора/извлечения и модуле генерации, обученном отдельно или одновременно, с доступом или без доступа к «золотой» опции знаний. С внедрением крупных заранее подготовленных генеративных моделей отбор и генерация становятся все более запутанными, смещая акцент в сторону более широкого внедрения знаний (из нескольких источников) вместо того, чтобы пытаться выбрать наилучший вариант знаний. Однако эти подходы зависят от меток знаний и/или отдельного плотного ретривера для их лучшей производительности. В этой работе мы изучаем возможности неконтролируемого отбора предварительно обученных генеративных моделей (например, BART) и показываем, что, добавляя модуль оценки и агрегации между кодером и декодером, они способны научиться выбирать правильные знания за счет минимизации потери языкового моделирования (т.е. без доступа к меткам знаний). Наша модель K-Mine, прошедшая соответствующее обучение, демонстрирует конкурентоспособный отбор и производительность генерации по сравнению с моделями, которые извлекают выгоду из меток знаний и/или отдельных плотных ретриверов.', 'ga': "Go hiondúil bíonn Múnlaí Comhrá Bunaithe ar an Eolas bunaithe ar mhodúl roghnúcháin/aisghabhála agus ar mhodúl giniúna, a gcuirtear oiliúint orthu go leithleach nó go comhuaineach, le nó gan rochtain ar rogha eolais `ór'. Le tabhairt isteach samhlacha giniúna móra réamhoilte, tá an chuid roghnúcháin agus giniúna ag dul i bhfostú níos mó agus níos mó, ag aistriú an fhócas i dtreo ionchorprú eolais a fheabhsú (ó fhoinsí iolracha) in ionad iarracht a dhéanamh an rogha eolais is fearr a roghnú. Braitheann na cineálacha cur chuige seo, áfach, ar lipéid eolais agus/nó ar aisghabhálaí dlúth ar leith chun a bhfeidhmíocht is fearr a bhaint amach. Sa obair seo déanaimid staidéar ar chumas roghnúcháin neamh-mhaoirsithe na múnlaí giniúna réamhoilte (m.sh. BART) agus taispeánann muid, trí mhodúl scór agus comhiomlán a chur leis idir ionchódóir agus díchódóir, go bhfuil siad in ann an t-eolas cuí a phiocadh tríd an teanga a íoslaghdú. caillteanas samhaltaithe (i.e. gan rochtain ar lipéid eolais). Ar an mbealach sin, taispeánann ár múnla - K-Mine - roghnú iomaíoch agus feidhmíocht ghiniúna i gcoinne samhlacha a bhaineann leas as lipéid eolais agus/nó aisghabhálaí dlúth ar leith.", 'ka': "მეცნიერების შესაბამისი შესაბამისი მოდელეები საერთოდ არჩევა/მიღება მოდულისთვის და შესაბამისი მოდულისთვის, რომელიც განსაკუთრებულად ან ერთოდნენ შესაბამისი შესაბამისი `gold' მოცემის მო დიდი წინასწარმოქმებული გენერატიური მოდელების შეცვალებით, არჩევა და დავიწყება უფრო და უფრო კონუქტირებულია, რომელიც კონუქტირებულია ცნობიერების შესაძლებლობა (მრავალ ფორტებიდან) გა მაგრამ ეს დახმარება იყოს ცნობიერების ნიშანებზე და/ან განსაკუთრებული საშუალებელი მიღებელი მათი საუკეთესო მუშაობისთვის. ამ სამუშაოში ჩვენ შევსწავლობთ წინ შესწავლობული წინ შესწავლობული გენერატიური მოდელების შესაძლებლობა (მაგალითად BART) და ჩვენ ჩვენ ჩვენ ამოჩვენებთ, რომ კოდერის და დეკოდერის შორის მოდულის დამატებით, ისინი შეუძლებელია მოსწავლობა მარტივი ცნობილების ჩვენი მოდელი - K-მინი - გამოყენება კონპექტიური არჩევა და შემდეგ შემდეგ მოდელების გამოყენება, რომლებიც მეცნიერების ლებლიდან და/ან განყოფილი დუნური მოღებელიდან.", 'hu': 'A tudásalapított beszélgetési modellek általában egy kiválasztó/visszahívó modulon és egy generációs modulon alapulnak, amelyeket külön-külön vagy egyidejűleg képeznek, hozzáféréssel vagy anélkül, hogy hozzáférnének egy "gold" tudási opcióhoz. A nagyméretű, előre képzett generációs modellek bevezetésével a kiválasztási és generációs rész egyre inkább összekapcsolódott, így a figyelmet a tudás beépítésének (több forrásból) javítására irányítja, ahelyett, hogy megpróbálná kiválasztani a legjobb tudási lehetőséget. Ezek a megközelítések azonban a tudáscímkéktől és/vagy egy külön sűrű retrievertől függnek a legjobb teljesítményük érdekében. Ebben a munkában tanulmányozzuk az előre képzett generációs modellek (pl. BART) felügyelet nélküli kiválasztási képességeit, és bemutatjuk, hogy a kódoló és dekódoló közötti pontszám-és-aggregátum modul hozzáadásával képesek megtanulni a megfelelő ismeretek kiválasztását a nyelvmodellezési veszteség minimalizálásával (azaz tudáscímkékhez való hozzáférés nélkül). Az ilyen képzésű modellünk - K-Mine - versenyképes választékot és generációs teljesítményt mutat a tudáscímkék és/vagy külön sűrű retriever modellekkel szemben.', 'el': 'Τα μοντέλα συζήτησης βασίζονται συνήθως σε μια ενότητα επιλογής/ανάκτησης και μια ενότητα παραγωγής, εκπαιδευμένα ξεχωριστά ή ταυτόχρονα, με ή χωρίς πρόσβαση σε μια επιλογή "χρυσής" γνώσης. Με την εισαγωγή μεγάλων προ-εκπαιδευμένων παραγωγικών μοντέλων, η επιλογή και η παραγωγή έχουν εμπλακεί όλο και περισσότερο, μετατοπίζοντας την εστίαση στην ενίσχυση της ενσωμάτωσης της γνώσης (από πολλαπλές πηγές) αντί να προσπαθούν να επιλέξουν την καλύτερη επιλογή γνώσης. Αυτές οι προσεγγίσεις, ωστόσο, εξαρτώνται από ετικέτες γνώσης ή/και ένα ξεχωριστό πυκνό ανάκτορο για την καλύτερη απόδοση τους. Στην παρούσα εργασία μελετούμε τις δυνατότητες επιλογής χωρίς επίβλεψη των προ-εκπαιδευμένων γενετήσιων μοντέλων (π.χ. και καταδεικνύουμε ότι με την προσθήκη μιας ενότητας σκορ-και-συγκεντρωτική μεταξύ κωδικοποιητή και αποκωδικοποιητή, είναι σε θέση να μάθουν να επιλέγουν τη σωστή γνώση ελαχιστοποιώντας την απώλεια μοντελοποίησης γλώσσας (δηλαδή χωρίς να έχουν πρόσβαση σε ετικέτες γνώσης). Εκπαιδευμένο ως τέτοιο, το μοντέλο μας παρουσιάζει ανταγωνιστική απόδοση επιλογής και παραγωγής έναντι μοντέλων που επωφελούνται από ετικέτες γνώσης ή/και χωριστό πυκνό ανακτητή.', 'kk': "Мәліметтер Төмендеген сөйлесу үлгілері әдетте таңдау/алу модуліне негізделген және бір-бірінен бөлек немесе бірге оқылған модуліне негізделген, олардың 'алтын' мәліметіне қатынау параметрі Үлкен алдын- ала оқылған генерациялық үлгілерді келтіру үшін таңдау және құрылу бөлігі көбірек болып, білім құрылғысын (бірнеше көзінен) жақсы білім параметрін таңдау орнына көбірек көбірек Бұл жағдайлар, білім жарлықтарына тәуелді және/немесе олардың ең жақсы істеу үшін бөлек тәжірибелеріне тәуелді. Бұл жұмыс ішінде біз алдын- оқылған генерациялық үлгілердің таңдау мүмкіндігін зерттеп, кодер мен декодер арасындағы нақты және агрегациялық модульді қосу үшін, олар тілді модельді жоғалу үшін дұрыс білімді таңдауға мүмкіндік береді (мысалы, білім жарлықта Бұл секілді біздің үлгіміз - K-Mine - білім мәліметтерден және бөлек тұтықты алу үлгілеріне қарсы жақсы таңдау және құрылу әрекеттерін көрсетеді.", 'it': 'I modelli di conversazione basati sulla conoscenza sono generalmente basati su un modulo di selezione/recupero e su un modulo di generazione, addestrati separatamente o contemporaneamente, con o senza avere accesso a un\'opzione di conoscenza "gold". Con l\'introduzione di grandi modelli generativi pre-addestrati, la parte di selezione e generazione è diventata sempre più impigliata, spostando l\'attenzione verso il miglioramento dell\'incorporazione della conoscenza (da più fonti) invece di cercare di scegliere l\'opzione migliore della conoscenza. Questi approcci dipendono tuttavia da etichette di conoscenza e/o da un denso retriever separato per le loro migliori prestazioni. In questo lavoro studiamo le capacità di selezione non supervisionate di modelli generativi pre-addestrati (ad esempio BART) e mostriamo che aggiungendo un modulo score-and-aggregate tra encoder e decoder, sono in grado di imparare a scegliere le conoscenze appropriate riducendo al minimo la perdita di modellazione linguistica (cioè senza avere accesso alle etichette di conoscenza). Formati come tali, il nostro modello - K-Mine - mostra prestazioni competitive di selezione e generazione rispetto a modelli che beneficiano di etichette di conoscenza e/o di denso retriever separato.', 'mk': "Knowledge Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without having access to a `gold' knowledge option.  Со воведувањето на големи предобучени генерални модели, делот од селекцијата и генерацијата станаа сé повеќе вмешани, префрлајќи го фокусот кон подобрување на интеграцијата на знаењето (од повеќе извори) наместо да се обиде да ја избере најдобрата опција за знаење. Сепак, овие пристапи зависат од етикетите на знаење и/или одделен густ резервер за нивната најдобра резултат. Во оваа работа ги проучуваме ненадгледуваните способности за селекција на предобучени генеративни модели (np. БАРТ) и покажуваме дека додавајќи модул со оценки и агрегет помеѓу кодерот и декодерот, тие се способни да научат да го изберат соодветното знаење преку минимизирање на загубата на моделирањето на јазикот (np. без пристап до ознаките Како такво, нашиот модел - K-Mine - покажува конкурентна селекција и генерациска резултат против моделите кои имаат корист од ознаките на знаење и/или одделен густ резервер.", 'lt': 'Žinių pagrindu grindžiami konversijos modeliai paprastai grindžiami atrankos ir (arba) atkūrimo moduliu ir kartos moduliu, kuris mokomas atskirai arba vienu metu, su „aukso“ žinių pasirinkimu arba be jo. Įdiegus didelius iš anksto apmokytus kartų modelius, atrankos ir kartų dalis vis labiau įsitraukė, o dėmesys nukreiptas į žinių įtraukimo didinimą (iš įvairių šaltinių), o ne į geriausių žinių pasirinkimą. Tačiau šie metodai priklauso nuo žinių etiketės ir (arba) nuo atskiro tankio surinkimo įrenginio, kad jie galėtų geriausiai veikti. Šiame darbe mes tiriame i š anksto apmokytų kartų modelių (pvz., BART) nepastebimus atrankos gebėjimus ir parodomi, kad prie koduotojo ir dekoderio pridėjus rezultatus ir bendrą modulį, jie gali mokytis rinkti tinkamas žinias mažindami kalbų modeliavimo praradimą (t. y. neturint galimybės naudotis žinių etiketėmis). Mūsų modelis, K-Mine, parengtas kaip toks, rodo konkurencingą atranką ir gamybos rezultatus, palyginti su modeliais, kurie naudojasi žinių etiketėmis ir (arba) atskiru tankiu gavėju.', 'ms': "Model Pertukaran Berdasarkan Pengetahuan biasanya berdasarkan modul pemilihan/pemulihan dan modul generasi, dilatih secara terpisah atau secara bersamaan, dengan atau tanpa mempunyai akses ke pilihan pengetahuan `emas'. With the introduction of large pre-trained generative models, the selection and generation part have become more and more entangled, shifting the focus towards enhancing knowledge incorporation (from multiple sources) instead of trying to pick the best knowledge option.  Pendekatan ini bagaimanapun bergantung pada label pengetahuan dan/atau pemulih yang padat terpisah untuk prestasi terbaik mereka. Dalam kerja ini, kami mempelajari kemampuan pemilihan yang tidak diawasi bagi model generatif pra-dilatih (cth. BART) dan menunjukkan bahawa dengan menambah modul skor-dan-aggregat antara pengekod dan dekoder, mereka mampu belajar untuk memilih pengetahuan yang betul melalui minimalisasi kehilangan model bahasa (cth. tanpa mempunyai akses ke label pengetahuan). Berlatih sebagai seperti itu, model kita - K-Mine - menunjukkan pemilihan kompetitif dan prestasi generasi terhadap model yang berguna dari label pengetahuan dan/atau pemulihan tebal terpisah.", 'ml': 'അറിവ് ഭൂമിയിലുള്ള സംസാര മോഡലുകള്\u200d സാധാരണയായി തെരഞ്ഞെടുക്കുന്നത്/വീണ്ടെടുക്കുന്ന ഘടകം അടിസ്ഥാനമാകുന്നു. ഒരു തലമുറയുടെ ഘടകം, വേര്\u200dതിരിച് പഠിപ്പിക്കപ്പെട്ട മോഡലുകളെ പരിചയപ്പെടുത്തുമ്പോള്\u200d തിരഞ്ഞെടുക്കുന്നതും തലമുറയുടെ ഭാഗവും കൂടുതല്\u200d ശ്രദ്ധിക്കപ്പെട്ടിരിക്കുന്നു. പരിജ്ഞാനം കൂടു These approaches however depend on knowledge labels and/or a separate dense retriever for their best performance.  ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മള്\u200d പരിശീലിക്കപ്പെടാത്ത ജെനററിവ് മോഡലുകളുടെ തെരഞ്ഞെടുപ്പിന്റെ കഴിവുകള്\u200d പഠിക്കുകയും കാണിക്കുകയും ചെയ്യുന്നു എന്\u200dകോഡോര്\u200dഡിനും ഇടയില്\u200d ഒരു സ്കോര്\u200dക്കും കൂട്ടുന്ന ഘടകം ചേ നമ്മുടെ മോഡല്\u200d - കെ- മൈന്\u200d - പരിശീലനം കാണിക്കുന്നത് പരിശീലനം കാണിക്കുന്നു. പരിജ്ഞാനത്തിന്റെ ചിത്രങ്ങളില്\u200d നിന്നും വേര്\u200dതിരിച', 'mn': 'Knowledge Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without access to a gold knowledge option. Ихэнх сургалтын өмнө сургалтын үйлдвэрлэлийн загваруудыг танилцуулахад, сонголт болон үеийн хэсэг нь хамгийн сайн мэдлэгийн сонголтыг сонгохын оронд анхаарлыг мэдлэгийг нэмэгдүүлэх (олон эх үүсвэрээс) шилжүүлсэн. Гэвч эдгээр арга барилгууд нь мэдлэг тэмдэглээнээс хамааралтай, эсвэл хамгийн сайн үйл ажиллагааны хувьд ялгаатай байдаг. Энэ ажлын тулд бид урьд сургалтын үйлдвэрлэлийн загвар (жишээ нь БАРТ) болон коддогч болон коддогч хоорондын тоо болон нийтлэг модуль нэмэхэд хэлний модель алдагдахаар зөв мэдлэг сонгох боломжтой болно. Ийм мэт сургалтын загвар, бидний K-Мин-ын загвар нь мэдлэг загвараас ашигладаг загваруудын эсрэг өрсөлдөөний сонголт болон үеийн үйл ажиллагааг харуулдаг.', 'no': 'Kvitensmodeller for grunnleggte samtale er vanlegvis basert på eit utval/henting- modul og ein genereringsmodul, trengt separat eller samtidig, med eller utan tilgang til ein «gull» kunnskap. Med innføring av store først trengte generativmodeller har utvalet og genereringsdelen blitt meir og meir innhaldet, og forandrar fokusen til å forbetra kunnskapsporasjon (frå fleire kilder) i staden for å prøva å velja den beste kunnskapsvalet. Desse tilnærmingane er imidlertid avhengig av kunnskapsetikettar og/eller ein separe tetthentar for dei beste utviklingane. I denne arbeida studerer vi utvalskapasiteten for før-trengte genereringsmodeller (f.eks. BART) og viser at ved å leggja til ein score-og-aggregat modul mellom koder og dekoder, kan dei læra å velja den riktige kunnskapen gjennom å minimera tap av språk-modelleringa (f.eks. utan tilgang til kjennemerket). Treng som slik, vår modell - K-Mine - viser konkurrentivt utval og generering mot modeller som nyttar frå kunnskapsetikettar og/eller separe tetthentar.', 'mt': 'Mudelli ta’ Konverżjoni bbażati fuq l-Għarfien normalment huma bbażati fuq modulu ta’ għa żla/ġbir lura u modulu ta’ ġenerazzjoni, imħarrġa separatament jew simultanjament, b’għażla ta’ għarfien ta’ ‘deheb’ jew mingħajrha. Bl-introduzzjoni ta’ mudelli ġenerattivi kbar imħarrġa minn qabel, il-parti tal-għażla u l-ġenerazzjoni saret dejjem aktar involuta, billi l-fokus sar lejn it-titjib tal-inkorporazzjoni tal-għarfien (minn sorsi multipli) minflok ma ppruvaw jagħżlu l-aħjar għażla tal-għarfien. Madankollu, dawn l-approċċi jiddependu fuq it-tikketti tal-għarfien u/jew minn riċevitur dens separat għall-a ħjar prestazzjoni tagħhom. F’dan ix-xogħol nistudjaw il-ħiliet ta’ g ħa żla mhux sorveljati ta’ mudelli ġenerattivi mħarrġa minn qabel (pereżempju BART) u nuru li biż-żieda ta’ modulu ta’ punteġġ u aggregat bejn l-ikkodifikatur u d-dekodifikatur, huma kapaċi jitgħallmu jagħżlu l-għarfien xieraq billi jimminimizzaw it-telf tal-mudellar tal-lingwi (jiġifieri mingħajr aċċess għat-tikketti tal-għarfien). Bħala tali, il-mudell tagħna - K-Mine - juri għażla kompetittiva u prestazzjoni tal-ġenerazzjoni kontra mudelli li jibbenefikaw minn tikketti tal-għarfien u/jew minn riċevitur dens separat.', 'sr': "Modeli razgovora znanja uglavnom su zasnovani na selekciji/prikupljanju modula i modulu generacije, obučenom odvojeno ili istovremeno, sa ili bez pristupa opciji znanja `zlato'. Uz uvođenje velikih predobučenih generativnih modela, deo selekcije i generacije postalo je sve više uključen, mijenjajući fokus ka povećanju uključenja znanja (iz višestrukih izvora) umjesto pokušavanja odabrati najbolju opciju znanja. Ovi pristupi, međutim, zavise od etiketa znanja i/ili odvojenog gustog otkupljača za najbolje izvršenje. U ovom poslu proučavamo nepotrebne sposobnosti selekcije predobučenih generativnih modela (npr. BART) i pokažemo da dodajući modul rezultata i aggregata između kodera i dekodera, oni su sposobni da uče da izaberu odgovarajuće znanje sa smanjenjem gubitka jezika modela (npr. bez pristupa znanja etiketama). Naš model - K-Mine - pokazuje konkurentnu selekciju i produkciju generacije protiv modela koji koriste od etiketa znanja i/ili odvojene guste prikupljača.", 'si': 'දැනගන්න ග්\u200dරූඩ් කතාවිච්චි මොඩියුල් සාමාන්\u200dයයෙන්ම තෝරාගන්න/ආරක්ෂා මොඩියුල් සහ ජීවිත මොඩියුල් සඳහා අධාරිත වෙනවා,  ලොකු ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන, තෝරණය සහ ප්\u200dරධාන ප්\u200dරධාන කොටස් වඩා විශාල වෙලා තියෙනවා, දැනගන්න ඒ වගේම මේ අවස්ථාවක් දැනගන්න ලේබල් වලින් විශ්වාස කරනවා නැත්නම්/නැත්නම් වෙනුවෙන් ප්\u200dරතිශීල මේ වැඩේ අපි ප්\u200dරශ්නයක් කරන්නේ ප්\u200dරශ්නයක් නැති විශ්නයක් ප්\u200dරශ්නයක් නිර්මාණය කරලා ප්\u200dරශ්නයක් වෙන්නේ (උදාහරණය BART) සහ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්නේ ස්කෝර් සහ ඒ වගේම ප්\u200dරධානය කරලා තියෙන්නේ, අපේ මොඩේල් - K-මයින් - ප්\u200dරධානයක් තෝරාගන්න සහ ප්\u200dරධානයක් පෙන්වන්නේ, ඒ වගේම ද', 'so': "Tusaalada hadalka aqoonta ee la dhigay waxey inta badan ku saleysan yihiin qalabka doorashada/dib-u-qaadashada iyo module qarni ah, laguu baran karo gooni ahaan ama si isku mid ah, isla markaasna ama ayan helin doorasho aqoonta `dahab'. Markii la soo bandhiyo tusaalooyin waaweyn oo la tababaray horay, doorashada iyo farshaxanta waxaa ka mid ah kuwo aad u qallafsan, wuxuuna beddelinayaa focus si uu u kordhiyo isqabsashada aqoonta (laga koriyo sourceo badan) badala in aan isku dayo doorashada aqoonta ugu wanaagsan. Si kastaba ha ahaatee soo dhowaanshahaas waxay ku xiran yihiin calaamada aqoonta iyo/ama dib u soo qaadashada meelaha ugu wanaagsan. Shuqulkaas ayaannu ku baranaynaa awoodaha aan la ilaalinayn doorashada modelalka horumarinta ah (e.g. BART) waxaana tusaynaa in lagu daro qalabka aqoonta iyo koowaad dhexdooda, waxay awoodaan in ay bartaan aqoonta saxda ah si ay u doortaan si ay u hoosaysiiyaan khasaarada tusaale ahaan luqada (tusaale ahaan iyagoo aan helin aqoonta labo). Waxbarashada tusaale ahaan Tusaale-K-Mine (K-Mine) wuxuu tusiyaa doorashooyinka iskutallada ah iyo tababarka farsamada ka gees ah tusaale ahaan kuwa faa’iido ka leh calaamada aqoonta iyo/ama dib u qaadashada culus.", 'sv': 'Knowledge Grounded Conversation Models är vanligtvis baserade på en urvals-/hämtningsmodul och en generationsmodul, utbildade separat eller samtidigt, med eller utan att ha tillgång till ett "gold"-kunskapsalternativ. I och med införandet av stora förutbildade generativa modeller har urvals- och generationsdelen blivit mer och mer invecklad, vilket har flyttat fokus mot att förbättra kunskapsinkorporeringen (från flera källor) istället för att försöka välja det bästa kunskapsalternativet. Dessa tillvägagångssätt är dock beroende av kunskapsetiketter och/eller en separat tät retriever för deras bästa prestanda. I detta arbete studerar vi de oövervakade urvalsförmågorna hos förutbildade generativa modeller (t.ex. BART) och visar att de genom att lägga till en score-and-aggregatmodul mellan encoder och dekoder, kan lära sig att plocka rätt kunskap genom att minimera språkmodelleringsförlusten (dvs. utan att ha tillgång till kunskapsetiketter). Vår modell - K-Mine - är utbildad som sådan och visar konkurrenskraftigt urval och generationsprestanda mot modeller som drar nytta av kunskapsetiketter och/eller separat tät retriever.', 'ta': 'அறிவு பூர்த்திய பேச்சு மாதிரிகள் வழக்கமாக தேர்ந்தெடுப்பு/மீட்டுதல் கூறுக்கும் அடிப்படையிலாக இருக்கிறது மற்றும் ஒரு தலைமுறை கூறு பெரிய பயிற்சி முன் பயிற்சி பொது மாதிரிகளை முதலில் தேர்ந்தெடுப்பு மற்றும் சந்திப்பு பகுதியை மேலும் சுருங்கியுள்ளது, அறிவு உள்ளடக்கத்தை மேலும் மாற் இந்த அணுகுகள் எப்படியும் அறிவு சிட்டைகள் மற்றும்/அல்லது சிறந்த செயல்பாட்டிற்கான ஒரு தனியான அடர்த்தி பெறுவத இந்த வேலையில் நாம் முன்பயிற்சி பொது மாதிரிகளின் பாதுகாப்பாக்கப்படாத த தேர்வு தேர்ந்தெடுக்கப்படாத த தேர்வுகளை படிக்கிறோம் மற்றும் குறியீட்டிற்கும் இடையே ஒரு மதிப்பெண் மற்றும் குறியீட எங்கள் மாதிரி - K- Mine - தேர்ந்தெடுப்பு மற்றும் உருவாக்கும் மாதிரிகளுக்கு எதிராக தேர்ந்தெடுப்பு செயல்பாட்டை காட்டுகிறது', 'ur': "علم Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without access to a `gold' knowledge option. بڑے پیش آموزش کی نمونے کے معلوم ہونے کے ساتھ، انتخاب اور نسل کا ایک حصہ زیادہ اور زیادہ مشکل ہو گیا ہے، اور اس کی تدبیر کو علم کے ساتھ (بہت سی سوروں سے) اضافہ کرنے کی جگہ سے (بہت سے) اچھی علم اختیار کرنے کی کوشش کرنا ہے۔ لیکن ان کے پاس علم لیبل اور/یا ایک مختلف گہرے پھیرنے والے پر اپنا بہترین عمل کیلئے بستہ ہے. ہم اس کام میں پڑھتے ہیں کہ پہلے تدریس کی جرائٹ موڈل کے غیر قابل انتخاب کرنے کے قابل ہیں اور دکھاتے ہیں کہ کوڈر اور ڈکوڈر کے درمیان ایک اسکور اور جمع موڈل کو اضافہ کریں، وہ سمجھنے کے قابل ہیں کہ سمجھنے کی سمجھ لیں اور زبان موڈلینگ خسارہ کے ذریعہ مکمل کریں (یعنی علم لیبلوں کی دسترسی کے بغیر اس طرح کی تعلیم کی جاتی ہے، ہماری مدل - K-Mine - نمائندوں کے مقابلہ میں مسابلہ انتخاب اور نسل کی عملہ دکھاتا ہے جو علم لیبل سے فائدہ اٹھاتے ہیں اور/یا مختلف گہرے اٹھانے والے کے مقابلہ میں۔", 'pl': 'Modele konwersacji oparte są zwykle na modułach selekcji/pobierania oraz modułach generacyjnych, szkolonych oddzielnie lub jednocześnie, z dostępem do opcji wiedzy "złotej". Wraz z wprowadzeniem dużych, wstępnie przeszkolonych modeli generacyjnych część selekcji i generacji stała się coraz bardziej splątana, przesuwając nacisk na poprawę integracji wiedzy (z wielu źródeł) zamiast starać się wybrać najlepszą opcję wiedzy. Podejścia te zależą jednak od etykiet wiedzy i/lub osobnego gęstego retrievera, aby uzyskać najlepszą wydajność. W niniejszej pracy badamy zdolności selekcji bez nadzoru wstępnie przeszkolonych modeli generacyjnych (np. BART) i pokazujemy, że poprzez dodanie modułu punktacyjnego pomiędzy koderem a dekoderem, są one w stanie nauczyć się dobierać właściwą wiedzę poprzez minimalizację utraty modelowania języka (tj. bez dostępu do etykiet wiedzy). Przeszkolony jako taki, nasz model, KeK-Mine, wykazuje konkurencyjną wydajność selekcji i generacji w porównaniu z modelami, które korzystają z etykiet wiedzy i/lub oddzielnego gęstego retriepera.', 'ro': 'Modelele de conversație bazate pe cunoștințe sunt, de obicei, bazate pe un modul de selecție/recuperare și un modul de generație, instruite separat sau simultan, cu sau fără a avea acces la o opțiune de cunoaștere "gold". Odată cu introducerea unor modele generative de mari dimensiuni pre-instruite, partea de selecție și generație au devenit din ce în ce mai încurcată, schimbând accentul spre îmbunătățirea încorporării cunoștințelor (din mai multe surse) în loc să încerce să aleagă cea mai bună opțiune de cunoaștere. Aceste abordări depind totuși de etichetele cunoștințelor și/sau de un retriever dens separat pentru performanțele lor optime. În această lucrare studiem abilitățile de selecție nesupravegheate ale modelelor generative pre-instruite (de exemplu BART) și arătăm că prin adăugarea unui modul score-and-agregat între encoder și decoder, acestea sunt capabile să învețe să aleagă cunoștințele corespunzătoare prin minimizarea pierderii modelului lingvistic (adică fără a avea acces la etichetele cunoștințelor). Instruit ca atare, modelul nostru - K-Mine - prezintă o selecție competitivă și performanță de generație în raport cu modelele care beneficiază de etichete de cunoaștere și/sau de retriever dense separat.', 'vi': 'Kiến thức Chế độ Chuyển đổi Nền thường được dựa trên một mô- đun chọn/lấy dạng và một mô- đun thế hệ được đào tạo riêng hay đồng thời, với hoặc không có quyền sử dụng kiến thức "vàng". Với việc sử dụng các mô hình tạo được huấn luyện lớn, phần tuyển chọn và sản xuất đã trở nên phức tạp hơn, thay vì chọn lựa lựa kiến thức tốt nhất. Cách tiếp cận này tùy thuộc vào nhãn kiến thức và/hoặc một trình phục hồi dày đặc riêng cho khả năng tốt nhất. Trong công việc này, chúng tôi nghiên cứu khả năng chọn không g i ám sát của các mô hình tạo được huấn luyện trước (v. d. BART) và cho thấy rằng bằng cách thêm một mô- đun điểm và-kết hợp giữa mã hóa và mã giải, họ có khả năng học được cách thu thập những kiến thức thích đáng bằng cách giảm thiểu khả năng mô phỏng ngôn ngữ (v. d. không có quyền truy cập vào nhãn tri thức). Được đào tạo như vậy, mô hình\'K-Mine\'của chúng tôi cho thấy khả năng chọn lựa cạnh tranh và sản xuất dựa trên các mô hình có lợi thế từ nhãn kiến thức và/hoặc cách nhau phục hồi mật độ.', 'uz': "Maʼlumot bogʻlamalar moduli oddiy tanlangan/tiklash moduli va bir xil uchun alohida yoki bir nechta oʻrnatilgan moduli asosida yaratiladi. Bir necha taʼminlovchi generativ modellarni ishga tushirishda, tanlangan va avval qismlari ko'proq qo'shilgan va eng yaxshi bo'lgan edi. Fan ta'limni bir necha manbalardan birlashtirishni o'zgartirish uchun fokusni o'zgartiradi. Agar bu murakkablar yaxshi bajarish uchun ilmiy tegnlarda va/yoki ajoyib keladigan chegara olishga murojaat qiladi. Bu vazida biz avval taʼminlovchi generativ modellari (BART) haqida saqlash imkoniyatlarini o'rganamiz va uning kodlash va kodlash usulini qoʻshish mumkin, ular o'z tilni modellash usulini yaratish yordamida haqiqiqiqiy maʼlumot yordamida o'rganadi (balki aql tegnlari yoʻq). Mana, modelmiz K-Mine - modelimizdan foydalanuvchi va foydalanuvchi modellardan foydalanuvchi modellarni ko'rsatadi.", 'da': "Knowledge Grounded Conversation Models er normalt baseret på et udvælgelses-/hentningsmodul og et generationsmodul, trænet separat eller samtidigt, med eller uden adgang til en 'gold' viden mulighed. Med indførelsen af store prætrænede generative modeller er udvælgelses- og generationsdelen blevet mere og mere indviklet, hvilket flytter fokus mod at øge inddragelsen af viden (fra flere kilder) i stedet for at forsøge at vælge den bedste viden mulighed. Disse metoder afhænger imidlertid af viden etiketter og/eller en separat tæt retriever for deres bedste ydeevne. I dette arbejde studerer vi de uudviklede udvælgelsesevner hos prætrænede generative modeller (f.eks. BART) og viser, at de ved at tilføje et score-and-aggregatmodul mellem encoder og dekoder er i stand til at lære at vælge den rette viden ved at minimere sprogmodelleringstab (dvs. uden at have adgang til vidensetiketter). Uddannet som sådan viser vores model - K-Mine - konkurrencedygtig udvælgelse og generations ydeevne i forhold til modeller, der drager fordel af viden etiketter og/eller separat density retriever.", 'bg': 'Моделите за разговор, основани на знанието, обикновено се основават на модул за подбор/извличане и модул за генериране, обучени поотделно или едновременно, със или без достъп до опция за "златни" знания. С въвеждането на големи предварително обучени генеративни модели частта за подбор и генериране става все по-заплетена, като фокусът се насочва към подобряване на интегрирането на знания (от множество източници), вместо да се опитва да избере най-добрия вариант на знания. Тези подходи обаче зависят от етикети на знанието и/или отделен гъст ретривър за най-доброто им представяне. В тази работа изучаваме способностите за подбор без надзор на предварително обучени генеративни модели (напр. БАРТ) и показваме, че чрез добавяне на модул за оценка и агрегиране между кодера и декодера, те са способни да се научат да избират подходящите знания чрез минимизиране на загубата на езиково моделиране (т.е. без достъп до етикети на знания). Обучени като такъв, нашият модел - показва конкурентни резултати при подбор и генериране спрямо модели, които се възползват от етикети на знанието и/или отделен гъст ретривър.', 'nl': "Knowledge Grounded Conversation Modellen zijn meestal gebaseerd op een selectie/retrieval module en een generatie module, apart of gelijktijdig getraind, met of zonder toegang tot een 'gouden' kennisoptie. Met de introductie van grote voorgetrainde generatieve modellen zijn selectie en generatie steeds meer verstrikt geraakt, waardoor de focus verschuift naar het verbeteren van kennisintegratie (vanuit meerdere bronnen) in plaats van te proberen de beste kennisoptie te kiezen. Deze benaderingen zijn echter afhankelijk van kennislabels en/of een aparte dichte retriever voor hun beste prestaties. In dit werk bestuderen we de onbeheerde selectiemogelijkheden van vooraf getrainde generatieve modellen (bijv. BART) en laten we zien dat door het toevoegen van een score-and-aggregatie module tussen encoder en decoder, ze in staat zijn om de juiste kennis te kiezen door het verlies van taalmodellering te minimaliseren (d.w.z. zonder toegang tot kennislabels). Als zodanig getraind toont ons model de concurrerende selectie- en genereringsprestaties ten opzichte van modellen die profiteren van kennislabels en/of aparte dichte retriever.", 'id': "Model konversasi Berdasarkan Pengetahuan biasanya berdasarkan modul seleksi/retrieval dan modul generasi, dilatih secara terpisah atau secara bersamaan, dengan atau tanpa akses ke pilihan pengetahuan `emas'. With the introduction of large pre-trained generative models, the selection and generation part have become more and more entangled, shifting the focus towards enhancing knowledge incorporation (from multiple sources) instead of trying to pick the best knowledge option.  Pendekatan ini bagaimanapun bergantung pada label pengetahuan dan/atau pemulih yang terpisah untuk prestasi terbaik mereka. Dalam pekerjaan ini kami mempelajari kemampuan seleksi yang tidak diperhatikan dari model generasi prapelatih (contohnya BART) dan menunjukkan bahwa dengan menambahkan modul skor-dan-agregat antara pengekode dan dekoder, mereka mampu belajar untuk memilih pengetahuan yang tepat melalui minimalisasi kehilangan model bahasa (i.e. tanpa akses ke label pengetahuan). Dilatih sebagai seperti itu, model kami - K-Mine - menunjukkan seleksi kompetitif dan prestasi generasi melawan model yang berguna dari label pengetahuan dan/atau pemulihan yang padat terpisah.", 'ko': "지식 기반의 대화 모델은 일반적으로 선택/검색 모듈과 생성 모듈을 바탕으로 각각 또는 동시에 교육을 받거나'황금'지식 옵션이 있거나 없다.대량의 사전 훈련의 생성 모델이 도입됨에 따라 선택과 생성 부분은 점점 복잡해지고 지식 통합(여러 원천에서)을 강화하는 데 중점을 두고 최선의 지식 옵션을 선택하려 하지 않는다.그러나 이러한 방법은 지식 라벨과/또는 단독 밀집 검색기에 의존하여 최상의 성능을 얻는다.이 작업에서 우리는 미리 훈련된 생성 모델(예를 들어 BART)의 무감독 선택 능력을 연구했고 인코더와 디코더 사이에 점수와 집합 모듈을 추가함으로써 언어 모델링 손실(예를 들어 지식 라벨에 접근할 필요가 없음)을 최소화함으로써 적당한 지식을 선택할 수 있음을 나타냈다.이러한 훈련을 통해 모델 K-Mine은 지식 태그 및/또는 독립 밀집 검색기의 모델에 비해 경쟁적인 선택과 생성 성능을 보여줍니다.", 'sw': "Knowledge Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without having access to a `gold' knowledge option.  Kutokana na kuanzishwa kwa mifano makubwa ya vizazi vilivyojifunza kabla, uchaguzi na kizazi umekuwa ukizidi kushinikizwa, na kubadilisha malengo ya kuongeza ushirikiano wa maarifa (kutoka vyanzo vingi) badala ya kujaribu kuchagua chaguo zuri la maarifa. Hata hivyo, mbinu hizi zinategemea alama za maarifa na/au vifaa vinavyojitokeza kwa ajili ya utendaji wao bora. Katika kazi hii tunasoma uwezo wa uchaguzi usio na uhakika wa mifano ya uzoefu wa vizazi vya awali (mfano BART) na kuonyesha kwamba kwa kuongeza kifaa cha upana kati ya kodi na kodi, wanaweza kujifunza kuchagua maarifa sahihi kwa kupunguza hasara ya mifano ya lugha (yaani bila kupata nafasi ya maambukizi). Imefundishwa kama vile, mifano yetu - K-Mine - inaonyesha uchaguzi wa ushindani na utendaji wa kizazi dhidi ya mifano inayofaidika na maabara ya maarifa na/au kupata nafasi ya kutosha.", 'fa': 'مدل مکالمه\u200cهای مکالمه\u200cهای زیادی دانش معمولاً بر روی یک مولد انتخاب/پذیرش و یک مولد نسل متخصص یا همزمان آموزش داده می\u200cشوند، با یا بدون دسترسی به گزینه\u200cی علم «طلا» یا دسترسی دارند. با توجه به مدلهای پیش آموزش پیش آموزش شده، بخش انتخاب و نسل بیشتر و بیشتر متصل شدند، تغییر تمرکز به افزایش شرکت علم (از منبع متعدد) به جای سعی کردن بهترین گزینه دانش را انتخاب کند. این دسترسی به هر حال بستگی دارند از نقاشی دانش و/یا یک بازیابی متفاوت برای بهترین عملشان. در این کار ما توانایی انتخاب غیرقابل تحقیق از مدل پیش آموزش یافته\u200cاند (مثل BART) را مطالعه می\u200cکنیم و نشان می\u200cدهیم که با اضافه کردن یک مدل\u200cهای ثبت و جمع بین رمزگار و رمزگار، آنها توانند یاد بگیرند که دانش مناسب را با کمینه کردن فقدان مدل\u200cکردن زبان (مثلا بدون دسترسی به etiketهای علم) انتخاب کنند. مانند این آموزش یافته شده، مدل ما - K-Mine - انتخاب رقابتی و فعالیت نسل در مقابل مدل\u200cهایی را نشان می\u200cدهد که از نقاشی علم و/یا بازیابی مغزی جدا می\u200cشوند.', 'af': "Knowledge Grounded Conversation Models is gewoonlik gebaseer op 'n keuse/herhaal module en 'n generasie module, onderwerp indien of samelewing, met of sonder toegang tot 'n goud' kennis opsie. Met die inligting van groot voorafoerende genereerbare modele, het die keuse en generasie deel meer en meer gehandel geword, en die fokus verskuif tot verhoog van kennis inkorporering (van veelvuldige bronne) in plaas van probeer om die beste kennis opsie te kies. Hierdie toegang is egter afhanklik van kennis etikette en/of 'n aparte dens ontvanger vir hul beste prestasie. In hierdie werk studeer ons die ongeonderwerpende keuse kapasiteite van vooraf-onderwerpende genereerbare modele (bv. BART) en wys dat deur 'n telling- and- aggregate module tussen enkoder en dekoder byvoeg te voeg, is hulle in staat om te leer om die regte kennis te kies deur die minimalisering van die taal modellering verlies (bv. sonder toegang tot kennis etikette te hê). Ons model - K-Mine - wys gemeenskaplike keuse en generasie-prestasie teen modele wat voordeel van kennis etikette en/of aparte dens ontvanger.", 'hr': "Modeli razgovora znanja uglavnom se temeljuju na modulu selekcije/prikupljanja i modulu generacije, obučenom odvojeno ili istovremeno, sa ili bez pristupa opciji znanja `zlato'. Uz uvođenje velikih predobučenih generativnih modela, dio izbora i generacije postao je sve više uključen, mijenjajući fokus ka povećanju uključenja znanja (iz višestrukih izvora) umjesto pokušavanja odabrati najbolju mogućnost znanja. Ovi pristupi, međutim, ovise o znanstvenim etiketama i/ili odvojenom gustom otkupcu za njihovu najbolju učinku. U ovom poslu proučavamo nepotrebne sposobnosti selekcije predobučenih generativnih modela (npr. BART) i pokazujemo da dodajući rezultat i aggregatni modul između kodera i dekodera, oni su sposobni učiti da izaberu odgovarajuće znanje minimizirajući gubitak jezika modela (npr. bez pristupa znanja etiketama). Naš model - K-Mine - pokazuje konkurentni izbor i učinkovitost generacije protiv modela koji koriste etikete znanja i/ili odvojeno gusto uzgajanje.", 'de': 'Knowledge Grounded Conversation Models basieren in der Regel auf einem Selektions-/Retrieval-Modul und einem Generierungsmodul, die separat oder gleichzeitig trainiert werden, mit oder ohne Zugang zu einer "Gold"-Wissensoption. Mit der Einführung von großen vortrainierten generativen Modellen haben sich Selektion und Generierung zunehmend verflochten, was den Fokus auf die Verbesserung der Wissensintegration (aus mehreren Quellen) verlagert, anstatt zu versuchen, die beste Wissensoption auszuwählen. Diese Ansätze hängen jedoch von Knowledge Labels und/oder einem separaten dichten Retriever für ihre beste Leistung ab. In dieser Arbeit untersuchen wir die unbeaufsichtigten Selektionsfähigkeiten von vortrainierten generativen Modellen (z.B. BART) und zeigen, dass sie durch Hinzufügen eines Score-and-Aggregatmoduls zwischen Encoder und Decoder lernen können, das richtige Wissen auszuwählen, indem sie den Verlust der Sprachmodellierung minimieren (d.h. ohne Zugang zu Wissenslabels). Als solches ausgebildet, zeigt unser Modell, dass wettbewerbsfähige Auswahl- und Generierungsleistung gegenüber Modellen zeigt, die von Wissensetiketten und/oder separaten dichten Retrievern profitieren.', 'tr': "Bilim Ululyky Qonuşma Modelleri adatça saýlaw/gaýd etmek modulyna dayalýar. Bu modul ayrı-ayrı ýa-da bir gezek bejerilýän, bir `gold' bilgi seçgisine erişip bolmady. Uly öň-bilim sistemasy döredijilik nusgalaryň girişi bilen, saýlamak we döredijilik bölegi has köp bölegi çykarmak üçin fokusyny bilgi döredilmesine (köpürler çeşmelerden) üýtgetmek yerine üýtgetmek üçin üýtgedendir. Bu golaýlar bilgi etiketlere we/ýöne özleriniň gowy başarylyklaryna baglanýarlar. Bu i şde biz öň-öňünde bilim taýýarlanmadyk ýagdaýylan nusgalaryň (mysal. BART) ukyplaryny öwrenip, koder we dekoder arasynda scorer we toplam modulyny ekleýän, olar dili modellendirmek üçin dogry bilimi taýýarlamak mümkin edip bilerler. Şonuň ýaly bilim etiketlerinden we/ýöne ýigrenç alyp beren nusgalaryna garşy, biziň modelimiz - K-Min - rekabetçi saýlamak we döredijilik taýýarlaryny görkez.", 'am': "ምርጫ/ማሳየት ሞዴል እና ትውልድ ሞዴል በተለየ ወይም በአንድ ሰዓት የተማረከ ወይም `ወርቅ' እውቀት ምርጫን ለማግኘት ሳይኖር የተጨማሪው እውቀት ማድረግ ነው፡፡ ከዚህ በፊት ተማሪ ዘረኝነት ዓይነቶች በመግለጥ፣ ምርጫ እና ትውልድ ክፍል የበዛና የበለጠ እና ተጨማሪ ሆኖአል፣ እውቀትን ማቀናቀል (ከብዙ ምንጮች) በማሻሻል እውቀት ምርጫን ከመምረጥ ፋንታ ማሳየትን ለመሻል ይለውጣሉ፡፡ እነዚህም አካባቢዎች እውቀት ምልክቶች እና/ወይም የተለየ ጥልቅ ድምፅ ለማድረግ ነው፡፡ በዚህ ስራ ውስጥ አስቀድሞ የተጠቃሚ የፍትሕት ዓይነቶች (BART) የመረጠውን ምርጫዎች እናሳያቸዋለን፡፡ በኮድ እና በኮድ መካከልም ክፍተት የሚጨምሩ ክፍተት እውቀትን ለመምረጥ ይችላሉ፡፡ Trained as such, our model - K-Mine - shows competitive selection and generation performance against models that benefit from knowledge labels and/or separate dense retriever.", 'hy': "Գիտության հիմնված հաղորդակցման մոդելները սովորաբար հիմնված են ընտրության և վերադարձման մոդուլների և սերունդների մոդուլների վրա, որոնք առանձին կամ միաժամանակ են վարժեցվում, ունենալով կամ առանց 'ոսկու' գիտելիքների հնարավորության: Մեծ նախապատրաստված սերնդի մոդելների ներկայացման արդյունքում ընտրության և սերնդի մասը դարձավ ավելի ու ավելի ներգրավված, կենտրոնացնելով գիտելիքների ներգրավման (բազմաթիվ աղբյուրներից) բարելավման վրա՝ լավագույն գիտելիքների ընտրության փոխարեն: Այս մոտեցումները, այնուամենայնիվ, կախված են գիտելիքների պիտակներից և (կամ) առանձին խտությունը վերադարձնողից իրենց լավագույն արդյունքների համար: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք նախապատրաստված սերնդի մոդելների (օրինակ Բարթ) առանց վերահսկվող ընտրության հնարավորությունները և ցույց ենք տալիս, որ միացնելով կոդերի և դեկոդերի միջև կոդվող գնահատականներ և համախմբվող մոդելներ, նրանք կարող են սովորել ընտրել ճիշտ գիտելիքները՝ նվազեցնելով լեզվի մոդելների կորստ Ինչպես այդպիսի, մեր մոդելը, K-Mine-ը, ցույց է տալիս մրցակցության ընտրությունը և սերունդների արտադրողությունը մոդելների հետ, որոնք օգտակար են գիտելիքների պիտակներից և", 'bn': 'জ্ঞান গ্রাউন্ট কনফিগারেশন মোডেল সাধারণত একটি নির্বাচন/পুনরুদ্ধার মডিউল এবং একটি প্রজন্ম মডিউলের উপর ভিত্তি করে থাকে, একে বিভিন্ন অথবা একই সাথে প্রশিক্ পূর্ব প্রশিক্ষিত জেনারেলিয়েটিভ মডেল প্রদর্শনের পরে নির্বাচন এবং প্রজন্মের অংশ বেশী আরো বেশী জড়িয়ে পড়েছে, জ্ঞান বৃদ্ধির প্রতি মনোযোগ পাল্টাচ্ছে (বেশ কিছু  কিন্তু এই প্রযুক্তিগুলো জ্ঞানের লেবেল এবং/অথবা তাদের সর্বোচ্চ প্রদর্শনের জন্য বিভিন্ন গভীর উদ্ধারের উপর নি এই কাজে আমরা পূর্ব প্রশিক্ষিত জেনারেটিভ মডেল (যেমন বিআরটি) নির্বাচনের ক্ষমতা গবেষণা করছি এবং দেখাচ্ছি যে এনকোডার এবং ডিকোডারের মধ্যে একটি স্কোর- আর- গ্রেগ্রেট মডিউল যোগ করে তারা ভাষার মডেলেলের ক্ষতি  যেমন আমাদের মডেল- কে- মাইন- প্রতিযোগিতায় নির্বাচন এবং প্রজন্মের প্রদর্শন করা হয়েছে মডেলের বিরুদ্ধে যা জ্ঞানের লেবেল এবং/অথবা বিভিন', 'sq': "Modelet e konversimit të bazuar në njohuri zakonisht bazohen në një modul zgjedhjeje/marrje dhe një modul gjenerate, të trajnuar veçanërisht apo njëkohësisht, me apo pa pasur akses në një opsion njohurie `gold'. Me futjen e modeleve të mëdha gjenerative të paratrajnuar, pjesa e zgjedhjes dhe gjeneratës është bërë gjithnjë e më e përfshirë, duke lëvizur fokusin drejt përmirësimit të përfshirjes së njohurive (nga burime të shumta) në vend të përpjekjes për të zgjedhur opsionin më të mirë të njohurive. Këto metoda megjithatë varen nga etiketat e njohurive dhe/ose nga një kërkues i përbashkët i dendur për performancën më të mirë të tyre. Në këtë punë ne studiojmë aftësitë e zgjedhjes së papërshqyrtuara të modeleve të paratrajnuar gjenerative (për shembull BART) dhe tregojmë se duke shtuar një modul rezultati-dhe-aggregat midis koduesit dhe dekoderit, ata janë në gjendje të mësojnë të zgjedhin njohuritë e duhura nëpërmjet minimizimit të humbjes së modelimit gjuhësor (pra pa pasur akses në etiketat e njohurive). Trained as such, our model - K-Mine - shows competitive selection and generation performance against models that benefit from knowledge labels and/or separate dense retriever.", 'bs': "Modeli razgovora znanja uglavnom se temelji na selekciji/prikupljanju modula i modulu generacije, obučenom odvojeno ili istovremeno, sa ili bez pristupa opciji znanja `zlato'. Uz uvođenje velikih predobučenih generativnih modela, dio selekcije i generacije postao je sve više uključen, mijenjajući fokus ka povećanju uključenja znanja (iz višestrukih izvora) umjesto pokušavanja odabrati najbolju opciju znanja. Ovi pristupi, međutim, zavise od etiketa znanja i/ili odvojenog gustog otkupljača za najbolje učinke. U ovom poslu proučavamo nepotrebne sposobnosti selekcije predobučenih generativnih modela (npr. BART) i pokazujemo da dodajući rezultat i aggregatni modul između kodera i dekodera, oni su sposobni učiti da izaberu pravo znanje minimizirajući gubitak jezika modela (npr. bez pristupa etiketama znanja). Naš model - K-Mine - pokazuje konkurentni izbor i produkciju generacije protiv modela koji koriste etikete znanja i/ili odvojene guste dobitnike.", 'cs': 'Modely konverzace na základě znalostí jsou obvykle založeny na modulu výběru/vyhledávání a generačním modulu, trénovaných samostatně nebo současně, s přístupem k možnosti znalostí "zlatého". Se zavedením velkých předškolených generačních modelů se část výběru a generace stále více propletla, což posunulo zaměření na zlepšení začlenění znalostí (z více zdrojů) namísto snahy vybrat nejlepší možnost znalostí. Tyto přístupy však závisí na znalostních etiketách a/nebo samostatném hustém retrieveru pro jejich nejlepší výkon. V této práci studujeme výběrové schopnosti předem trénovaných generačních modelů (např. BART) a ukážeme, že přidáním bodového modulu mezi kodérem a dekodérem jsou schopni se naučit vybrat správné znalosti minimalizací ztráty jazykového modelování (tj. bez přístupu k znalostním štítkům). Vyškolený jako takový, náš model CokK-Mine vykazuje konkurenční výběr a generační výkon oproti modelům, které využívají znalostní štítky a/nebo samostatný hustý retriever.', 'et': 'Teadmistepõhised vestlusmudelid põhinevad tavaliselt valiku-/päringumoodulil ja generatsioonimoodulil, mida koolitatakse eraldi või samaaegselt, millel on juurdepääs kuldsetele teadmistele või ilma. Suurte eelnevalt koolitatud generatiivsete mudelite kasutuselevõtuga on valiku ja generatsiooni osa üha enam seotud, suunates tähelepanu teadmiste kaasamise parandamisele (mitmest allikast), selle asemel, et valida parim teadmisvõimalus. Need lähenemisviisid sõltuvad siiski teadmiste märgistest ja/või eraldi tihedast otsijast nende parima tulemuse saavutamiseks. Käesolevas töös uurime eelnevalt koolitatud generatiivsete mudelite (nt BART) järelevalveta valimisvõimeid ning näitame, et kodeerija ja dekoodri vahele skoor-and-aggregate mooduli lisamisega on nad võimelised õppima õigete teadmiste valimist, minimeerides keele modelleerimise kadu (st ilma juurdepääsu teadmiste märgistustele). Sellisena väljaõpetatud mudel K-Mine näitab konkurentsivõimelist valiku- ja generatsioonitõhusust mudelitega, mis saavad kasu teadmistemärgistest ja/või eraldi tiheda retriiverist.', 'ca': 'Models de conversació basats en el coneixement normalment es basan en un módul de selecció/recuperació i en un módul de generació, entrenats separadament o simultàneament, amb o sense accés a una opció de coneixement "or". Amb la introducció de grans models de generació pré-entrenats, la part de selecció i generació s\'ha involucrat cada cop més, canviant l\'enfocament cap a millorar l\'incorporació del coneixement (de múltiples fonts) en lloc d\'intentar triar la millor opció de coneixement. No obstant això, aquests enfocaments depenen de les etiquetes del coneixement i/o d\'un recuperador dens separat per al seu millor rendiment. En aquesta feina estudiem les habilitats de selecció no supervisades de models generadors pré-entrenats (p.ex. BART) i demostram que afegint un módul de puntuació i agregació entre codificador i decodificador, són capaços d\'aprendre a escollir el coneixement adequat minimitzant la pèrdua de modelació lingüística (i.e. sense tenir accés a etiquetes de coneixement). Format com a tal, el nostre model - K-Mine - mostra selecció competitiva i rendiment de generació en comparació amb models que beneficien d\'etiquetes de coneixement i/o recuperador dens separat.', 'az': "Bilim Üstünlü Qonuşma Modelləri genellikle seçmə/alış modulu və nəsli modulu təhsil edilən, ayrı-ayrı və eyni zamanda təhsil edilən, `altın' bilgi seçgisinə istifadə edilməyən və ya olmadan təhsil edilir. Böyük təhsil edilmiş nütfədə modellərin tanışması ilə, seçim və nəslin bir parçası daha çox çəkilib, təhsil etməyi ən yaxşı bilgi seçimi seçmək yerinə elm inkişafını artırmağa (çoxlu mənbələrdən) dəyişdirir. Bu yaxınlıqlar elm etiketlərinə və/yaxud yaxşılıqlarına görə ayrı yoxluq almağa bağlı idilər. Bu i şdə biz əvvəlcə təhsil edilmiş nütfədən modellərin (BART) seçmə qabiliyyətlərini öyrənirik və g östərdik ki, kodlayıcı və dekoder arasındakı nütfədə və aggregat modulu əlavə edərək, dil modelləri azaltmaq vasitəsilə doğru bilgi seçməyi öyrənə bilərlər. Bu kimi təhsil edilmişdir, modelimiz - K-Mine - münafiqli seçim və nəsil performansını elm etiketlərindən faydalayan modellərə və/yaxud ayrı yox alıcı göstərir.", 'fi': 'Knowledge Grounded Conversation Models -mallit perustuvat yleensä valinta-/hakumoduuliin ja sukupolvimoduuliin, jotka on koulutettu erikseen tai samanaikaisesti, joilla on mahdollisuus käyttää "kultaista" tietovaihtoehtoa. Suurten esikoulutettujen generatiivisten mallien käyttöönoton myötä valinta- ja generointiosa on yhä enemmän kietoutunut, mikä on siirtänyt painopistettä tietämyksen lisäämiseen (useista lähteistä) parhaan tietovaihtoehdon valitsemisen sijaan. Nämä lähestymistavat riippuvat kuitenkin tietomerkinnöistä ja/tai erillisestä tiheästä noutajasta parhaan suorituskyvyn saavuttamiseksi. Tässä työssä tutkitaan ennalta koulutettujen generatiivisten mallien (esim. BART) valvomatonta valintakykyä ja osoitetaan, että lisäämällä pisteytys- ja aggregaattimoduulin kooderin ja dekooderin väliin he pystyvät oppimaan valitsemaan oikean tiedon minimoimalla kielimallinnuksen menetystä (eli ilman tietomerkkejä). Sellaisena koulutettu K-Mine -mallimme näyttää kilpailukykyistä valinta- ja sukupolvisuorituskykyä verrattuna malleihin, jotka hyötyvät tietomerkeistä ja/tai erillisistä dense retriever -laitteista.', 'sk': 'Modeli pogovora na podlagi znanja običajno temeljijo na modulu za izbiro/pridobivanje in generacijskem modulu, ki se izobražujeta ločeno ali hkrati, z dostopom do "zlate" možnosti znanja ali brez njega. Z uvedbo velikih vnaprej usposobljenih generativnih modelov sta se del izbire in generacije vedno bolj zapletla, pri čemer sta se osredotočenost premaknila na izboljšanje vključevanja znanja (iz več virov), namesto da bi poskušala izbrati najboljšo možnost znanja. Ti pristopi pa so odvisni od oznak znanja in/ali ločenega gostega iskalnika za njihovo najboljšo učinkovitost. V tem delu preučujemo nenadzorovane selekcijske sposobnosti predhodno usposobljenih generativnih modelov (npr. BART) in pokažemo, da se z dodajanjem rezultatov in agregatnega modula med kodirnikom in dekodirnikom naučijo izbirati ustrezno znanje z zmanjšanjem izgube jezikovnega modeliranja (tj. brez dostopa do oznak znanja). Tako usposobljen model - K-Mine - kaže konkurenčno izbiro in produkcijsko zmogljivost v primerjavi z modeli, ki imajo koristi od oznak znanja in/ali ločenega gostega pridobivalca.', 'he': "מודלים שינוי מידע מבוססים בדרך כלל על מודול בחירה/השיגה ומודל דור, מאומנים בנפרד או באותו זמן, עם או בלי גישה לאפשרות ידע 'זהב'. עם ההצגה של דוגמנים דורתיים גדולים מאומנים מראש, החלק הבחירה והדור הופך יותר ויותר מעורב, להעביר את המרכז לשימוש התקיפה של ידע (ממקורים רבים) במקום לנסות לבחור את אפשרות הידע הטובה ביותר. בכל אופן, גישות אלה תלויות בתוויות ידע ו/או משיג צפוף נפרד עבור ההופעה הטובה ביותר שלהם. בעבודה הזו אנו לומדים את יכולות הבחירה ללא השגחה של דוגמנים דולריים מאומנים מראש (למשל BART) ולהראות כי על ידי הוספת מודול נקודות ואגוגרטיבי בין הקודר לבין הקודר, הם מסוגלים ללמוד לבחור את הידע הנכון באמצעות מיניזם את אובדן הדוגמנים לשפה (למשל בלי גישה לתוויות הידע). מוכשר ככה, המודל שלנו - K-Mine - מראה בחירה תחרותית והביצועים של דור נגד מודלים שמשתמשים בתוויות ידע ו/או משיג צפוף נפרד.", 'ha': "Knowledge Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without having access to a `gold' knowledge option.  Ko da ana ƙara wa masu motsi masu motsi na farko da aka wahamata, sai zaɓi da haihuwa sun fi ƙaranci, kuma ya musanya fokus dõmin a ƙara lissafin ilmi (daga sourcen masu yawa) kuma ba ya yi jarraba zaɓen zafi da sani ba. Waɗannan sukan tsari ko kuma, amma, sun ƙayyade alama na ilmi da/ko wata dabam-dabam da ake samun su da mafi kyaun aikin su. Daga wannan aikin, Munã karanta abincin shirin da ba'a tsare ba na tsare masu tsari na shiryayya na farko mai ƙidãya (misali, BArT) kuma Muke nuna cewa, a ƙara wata module-na-nau'in tsakanin kode da kode-kode, za su iya iya karanta zane masu inganci da inganci da ke ƙaranci hasara ga misalin ayuka (misali, bã ya da iya haɗi cikin alama na ilmi). An tsare misali kamar misalinmu - K-Mine - yana nũna zaɓen shirin yin gaura a kan misãlai wanda yake amfani da shi daga alama na ilmi da/ko mai gaurawa mai sauya.", 'bo': "Knowledge Grounded Conversation Models are usually based on a selection/retrieval module and a generation module, trained separately or simultaneously, with or without access to a `gold' knowledge option. With the introduction of large pre-trained generative models, the selection and generation part have become more and more entangled, shifting the focus towards enhancing knowledge incorporation (from multiple sources) instead of trying to pick the best knowledge option. ཡིན་ནའང་། གནད་དོན་འདི་དག་ནི་ཤེས་པའི་ཁ་ཡིག་གཟུགས་རྟགས་དང/ཡང་ན། In this work we study the unsupervised selection abilities of pre-trained generative models (e.g. BART) and show that by adding a score-and-aggregate module between encoder and decoder, they are capable of learning to pick the proper knowledge through minimising the language modelling loss (i.e. without having access to knowledge labels). Trained as such, our model - K-Mine - shows competitive selection and generation performance against models that benefit from knowledge labels and/or separate dense retriever.", 'jv': "knowknow Gruundd conversation modes are often supported on a select/retienal module and a Generation module, traced separately or at the same time, with or not have access to a 'golf' option. Jadi ngendadi model sing diantesik ro-cara model sing gak bakal kelas, bisalahan karo winih sing gak penting, dadi nggawe perspektur nggawe ngubah dhéwé, njalukake nggawe perspektur nggawe ngubah awak dhéwé (usul sakjane Sources) instead of gewis nggawe perspektur nggawe akeh awak dhéwé Awak dhéwé nglarang-Awak dhéwé ngerasakno ngono/nggawe gerakan tanggal nggawe barang awak dhéwé. Nang barêng-barêng iki kita alih sing g a we ngubah akeh perusahaan de model sing bisa nguasai perusahaan (dumateng PART) lan wong-wong kuwi mêtêmên karo koder karo akeh lan akeh-ngregasi sing paling, kuwi iso ngubah siyen yen perusahaan langkung sampek iso nggawe diulangno adalah mêtêm nggawe ngubah ilegal (mute, nik akses acess karo etiket karo perusahaan Rasané koyo ngono, model sing model- K-Mine - iso nggambar perusahaan karo model sing apik etokno karo perusahaan lagi mau"}
{'en': 'Influence of user personality on dialogue task performance : A case study using a rule-based dialogue system', 'ar': 'تأثير شخصية المستخدم على أداء مهمة الحوار: دراسة حالة باستخدام نظام حوار قائم على القواعد', 'fr': "Influence de la personnalité de l'utilisateur sur les performances des tâches de dialogue\xa0: étude de cas utilisant un système de dialogue basé sur des règles", 'pt': 'Influência da personalidade do usuário no desempenho da tarefa de diálogo: um estudo de caso usando um sistema de diálogo baseado em regras', 'es': 'Influencia de la personalidad del usuario en el desempeño de las tareas de diálogo: un estudio de caso que utiliza un sistema de diálogo basado', 'ja': 'ダイアログタスクパフォーマンスへのユーザーパーソナリティの影響：ルールベースのダイアログシステムを使用したケーススタディ', 'zh': '用户人格绩效事——以法为例', 'hi': 'संवाद कार्य प्रदर्शन पर उपयोगकर्ता व्यक्तित्व का प्रभाव: नियम-आधारित संवाद प्रणाली का उपयोग करके एक केस स्टडी', 'ru': 'Влияние личности пользователя на выполнение задачи диалога: тематическое исследование с использованием системы диалога, основанной на правилах', 'ga': 'Tionchar pearsantacht an úsáideora ar fheidhmíocht tasc idirphlé: Cás-staidéar a úsáideann córas dialóige bunaithe ar rialacha', 'ka': 'მომხმარებელი პირადნობის შესაძლებლობა დიალოგის დავალების შესაძლებლობა: კოსტატის შესაძლებლობა, რომელიც კოსტატის შესაძლებლობა დიალოგი', 'it': "Influenza della personalità dell'utente sulle prestazioni delle attività di dialogo: un caso di studio utilizzando un sistema di dialogo basato su regole", 'kk': 'Диалог тапсырмасының істеу үшін пайдаланушының қасиеттері: ережелер негізінде диалог жүйесін қолданатын үлкен- кіші зерттеу', 'hu': 'A felhasználói személyiség hatása a párbeszédfeladat teljesítményére: Esettanulmány szabályalapú párbeszédrendszer alkalmazásával', 'lt': 'Naudotojo asmenybės įtaka dialogo užduočių vykdymui: atvejų tyrimas, kuriame naudojama taisyklėmis grindžiama dialogo sistema', 'mk': 'Влијание на личноста на корисникот врз извршувањето на задачите во дијалогот: случајна студија со користење на систем на дијалог базиран на правила', 'ms': 'Influence of user personality on dialogue task performance: A case study using a rule-based dialogue system', 'ml': 'ഡയലോഗ് ജോലിയുടെ പ്രവര്\u200dത്തനത്തിന്റെ ഉപയോക്താവിന്റെ വ്യക്തിത്വം: നിയമപരമായ ഒരു ഡയലോഗ് സിസ്റ്റം ഉപയോ', 'el': 'Επίδραση της προσωπικότητας του χρήστη στην απόδοση εργασιών διαλόγου: Μια μελέτη περίπτωσης με χρήση ενός συστήματος διαλόγου βασισμένου σε κανόνες', 'mt': 'L-influwenza tal-personalità tal-utent fuq il-prestazzjoni tal-kompiti ta’ djalogu: Studju ta’ każ li juża sistema ta’ djalogu bbażata fuq ir-regoli', 'mn': 'Хэрэглэгчийн хувьцааны нөлөө нь диалог ажлын үйл ажиллагааны үйл ажиллагаанд: хууль дээр суурилсан диалог системийг ашиглаж', 'no': 'Utviklinga av brukarnamnet på oppgåve i dialogvindauget: Eit tilfeldige studie med eit regelbasert dialogsystem', 'ro': 'Influența personalității utilizatorului asupra performanței sarcinilor de dialog: Un studiu de caz utilizând un sistem de dialog bazat pe reguli', 'pl': 'Wpływ osobowości użytkownika na wykonywanie zadań dialogowych: studium przypadku z wykorzystaniem systemu dialogu opartego na regułach', 'si': 'ප්\u200dරයෝජකය පුද්ගලිකත්වය සංවාද කාර්යාලය වැඩේ ප්\u200dරශ්ණතාව: නීතිය අධාරිත සංවාද පද්ධතිය', 'sr': 'uticaj osobnosti korisnika na funkciju dijaloga: istraživanje slučajeva korištenje sistema dijaloga na pravilima', 'ta': 'Name', 'ur': 'Name', 'sv': 'Påverkan av användarpersonlighet på dialoguppgiftens prestanda: En fallstudie med hjälp av ett regelbaserat dialogsystem', 'so': 'Infaa’iido ku saabsan shakhsiyadda isticmaalayaasha ku saabsan sameynta shaqada dialogka: Waxbarashada xaaladda ee ku isticmaalaya nidaamka dialogka ee ku qoran', 'uz': 'Name', 'vi': 'Sự ảnh hưởng của cá nhân người dùng lên khả năng đàm phán: Một trường hợp nghiên cứu dựa trên quy luật', 'bg': 'Влияние на личността на потребителя върху изпълнението на задачите по диалога: Проучване на случай, използващ система за диалог, основана на правила', 'da': 'Indflydelse af brugerpersonlighed på dialogopgavernes ydeevne: Et casestudie ved hjælp af et regelbaseret dialogsystem', 'hr': 'utjecaja osobnosti korisnika na učinkovitost zadataka dijaloga: istraživanje slučajeva koristeći sustav dijaloga na temelju pravila', 'nl': 'Invloed van gebruikerspersoonlijkheid op de prestaties van dialoogtaken: Een casestudy met behulp van een regelgebaseerd dialoogsysteem', 'de': 'Einfluss der Nutzerpersönlichkeit auf die Leistung von Dialogaufgaben: Eine Fallstudie unter Verwendung eines regelbasierten Dialogsystems', 'ko': '사용자 개성이 대화 임무 실적에 미친 영향: 규칙을 바탕으로 하는 대화 시스템의 사례 연구', 'fa': 'تأثیر شخصیت کاربر بر روی عملکرد کارهای محاورۀ گفتگو: یک مطالعه پرونده با استفاده از سیستم محاورۀ محاورۀ قانون', 'sw': 'Tafiti la kesi kwa kutumia mfumo wa mazungumzo yenye msingi wa sheria', 'af': "Ieffens van gebruiker persoonlik op dialoog taak uitvoer: ' n Kas studie gebruik 'n reël gebaseerde dialoog stelsel", 'tr': 'Ullançy şahslyklaryň etkinlik täblisasinde etkinlik: Ködleme sistemini ulanan kiçi/beýik harplary', 'sq': 'Influenca e personalitetit të përdoruesit në kryerjen e detyrave të dialogut: Një studim rasti duke përdorur një sistem dialog bazuar në rregulla', 'hy': 'Օգտագործողի անհատականության ազդեցությունը երկխոսային խնդիրների կատարման վրա. օրենքներով հիմնված երկխոսային համակարգ օգտագործող մի դեպքի ուսումնասիրություն', 'am': 'A case study using a rule-based dialog system', 'az': 'İstifadəçi kişiliğinin müxtəlif rəngli işləri: qayda sistemi ilə istifadə edilən rəngli təhsil', 'bn': 'ডায়ালগ কাজের প্রদর্শনের উপর ব্যবহারকারীর ব্যক্তিগত প্রভাব: নিয়মিত ডায়ালগ সিস্টেম ব্যবহার করে একটি কেস গবেষণা', 'bs': 'utjecaja osobnosti korisnika na provedbu zadataka dijaloga: studija slučajeva koristeći sistem dijaloga na temelju pravila', 'id': 'Influensi kepribadian pengguna pada prestasi tugas dialog: Sebuah studi kasus menggunakan sistem dialog berdasarkan aturan', 'cs': 'Vliv osobnosti uživatele na výkon úkolů dialogu: Případová studie využívající systém dialogu založený na pravidlech', 'ca': "Influencia de la personalitat de l'usuari en el desempeny de la tasca de diàleg: Un estudi de cas utilitzant un sistema de diàleg basat en regles", 'et': 'Kasutaja isiksuse mõju dialoogiülesannete täitmisele: juhtumiuuring reeglipõhise dialoogisüsteemi abil', 'fi': 'KĂ¤yttĂ¤jĂ¤persoonallisuuden vaikutus dialogitehtĂ¤vĂ¤n suoritukseen: tapaustutkimus sĂ¤Ă¤ntĂ¶pohjaisen dialogijĂ¤rjestelmĂ¤n avulla', 'jv': 'Gambar uwong kelas ping pengguna perbudhakan kanggo nggawe dialog atik: Una batir kang digawe sistem sing usulah dialog', 'sk': 'Vpliv osebnosti uporabnika na izvedbo nalog dialoga: študija primera z uporabo pravil temelječega sistema dialoga', 'he': 'השפעה של אישיות המשתמש על ביצוע משימות דיאלוג: מחקר מקרים בשימוש מערכת דיאלוג מבוססת על חוקים', 'bo': 'སྒེར', 'ha': 'An ƙulli wa masu amfani da amfani da tsarin zauren akwatin bayani na zauren akwatin bayani:'}
{'en': 'Endowing a task-oriented dialogue system with adaptiveness to ', 'ar': 'يمكن أن يساعد منح نظام حوار موجه نحو المهام مع القدرة على التكيف مع شخصية المستخدم بشكل كبير في تحسين أداء مهمة الحوار. ومع ذلك ، يمكن أن يكون تنفيذ نظام الحوار هذا تحديًا عمليًا ، لأنه من غير الواضح كيف تؤثر شخصية المستخدم على أداء مهمة الحوار. لاستكشاف العلاقة بين شخصية المستخدم وأداء مهمة الحوار ، قمنا بتسجيل المشاركين عبر التعهيد الجماعي للإجابة أولاً على استبيانات شخصية محددة ثم الدردشة مع نظام حوار لإنجاز المهام المعينة. تم استخدام نظام حوار قائم على القواعد حول مهمة Multi-Domain Wizard-of-Oz (MultiWOZ) السائدة. تم جمع وتحليل ما مجموعه 211 شخصية من المشاركين و 633 حوارًا. كشفت النتائج أن الأشخاص المنفتحين والمؤنسين يميلون إلى فشل المهمة ، في حين أن الأشخاص العصابيين كانوا أكثر عرضة للنجاح. لقد استخرجنا الميزات المتعلقة بسلوكيات حوار المستخدم وقمنا بإجراء مزيد من التحليل لتحديد نوع السلوك الذي يؤثر على أداء المهمة. ونتيجة لذلك ، حددنا أن متوسط طول الكلام والفتحات لكل كلام هي السمات الرئيسية لسلوك الحوار التي ترتبط ارتباطًا وثيقًا بكل من أداء المهمة وشخصية المستخدم.', 'es': 'Dotar a un sistema de diálogo orientado a tareas con capacidad de adaptación a la personalidad del usuario puede ayudar en gran medida a mejorar el rendimiento de una tarea de diálogo. Sin embargo, este sistema de diálogo puede ser prácticamente difícil de implementar, porque no está claro cómo la personalidad del usuario influye en el desempeño de las tareas de diálogo. Para explorar la relación entre la personalidad del usuario y el desempeño de las tareas de diálogo, inscribimos a los participantes a través de la colaboración colectiva para que respondieran primero a cuestionarios de personalidad específicos y luego charlaran con un sistema de diálogo para realizar Se utilizó un sistema de diálogo basado en reglas sobre la tarea predominante Mago de OZ multidominio (MultiWoz). Se recopilaron y analizaron un total de 211 personalidades de los participantes y sus 633 diálogos. Los resultados revelaron que las personas sociables y extrovertidas tendían a fallar en la tarea, mientras que las personas neuróticas tenían más probabilidades de triunfar. Extrajimos características relacionadas con los comportamientos de diálogo de los usuarios y realizamos análisis adicionales para determinar qué tipo de comportamiento influye en el rendimiento de las tareas Como resultado, identificamos que la duración media de los enunciados y los espacios por enunciado son las características clave del comportamiento del diálogo que están altamente correlacionadas con el rendimiento de las tareas y la personalidad del usuario.', 'pt': 'Dotar um sistema de diálogo orientado a tarefas com adaptabilidade à personalidade do usuário pode ajudar muito a melhorar o desempenho de uma tarefa de diálogo. No entanto, tal sistema de diálogo pode ser praticamente desafiador de implementar, porque não está claro como a personalidade do usuário influencia o desempenho da tarefa de diálogo. Para explorar a relação entre a personalidade do usuário e o desempenho da tarefa de diálogo, inscrevemos participantes por meio de crowdsourcing para primeiro responder a questionários de personalidade especificados e depois conversar com um sistema de diálogo para realizar as tarefas atribuídas. Foi usado um sistema de diálogo baseado em regras na tarefa predominante do Multi-Domain Wizard-of-Oz (MultiWOZ). Um total de 211 personalidades dos participantes e seus 633 diálogos foram coletados e analisados. Os resultados revelaram que pessoas sociáveis e extrovertidas tendiam a falhar na tarefa, enquanto pessoas neuróticas eram mais propensas a ter sucesso. Extraímos recursos relacionados aos comportamentos de diálogo do usuário e realizamos análises adicionais para determinar que tipo de comportamento influencia o desempenho da tarefa. Como resultado, identificamos que a duração média do enunciado e os slots por enunciado são as principais características do comportamento do diálogo que estão altamente correlacionadas tanto com o desempenho da tarefa quanto com a personalidade do usuário.', 'fr': "Le fait de doter un système de dialogue axé sur les tâches d'une adaptation à la personnalité de l'utilisateur peut grandement contribuer à améliorer les performances d'une tâche de dialogue. Cependant, un tel système de dialogue peut être difficile à mettre en œuvre, car on ne sait pas exactement comment la personnalité de l'utilisateur influence la performance des tâches de dialogue. Pour explorer la relation entre la personnalité de l'utilisateur et les performances des tâches de dialogue, nous avons inscrit les participants via le crowdsourcing pour répondre d'abord à des questionnaires de personnalité spécifiques, puis discuter avec un système de dialogue pour accomplir les tâches assignées. Un système de dialogue basé sur des règles sur la tâche multidomaine Wizard-of-OZ (MultiWOZ) courante a été utilisé. Au total, la personnalité de 211 participants et leurs 633 dialogues ont été collectés et analysés. Les résultats ont révélé que les personnes sociables et extraverties avaient tendance à échouer, alors que les névrosés étaient plus susceptibles de réussir. Nous avons extrait les caractéristiques liées aux comportements de dialogue des utilisateurs et effectué une analyse plus approfondie afin de déterminer quel type de comportement influence la performance des tâches. En conséquence, nous avons constaté que la longueur moyenne de l'énoncé et les créneaux par énoncé sont les principales caractéristiques du comportement de dialogue qui sont fortement corrélées à la fois avec les performances des tâches et la personnalité de l'utilisateur.", 'hi': 'उपयोगकर्ता व्यक्तित्व के लिए अनुकूलता के साथ एक कार्य-उन्मुख संवाद प्रणाली को समाप्त करना एक संवाद कार्य के प्रदर्शन को बेहतर बनाने में बहुत मदद कर सकता है। हालांकि, इस तरह की संवाद प्रणाली को लागू करने के लिए व्यावहारिक रूप से चुनौतीपूर्ण हो सकता है, क्योंकि यह स्पष्ट नहीं है कि उपयोगकर्ता व्यक्तित्व संवाद कार्य प्रदर्शन को कैसे प्रभावित करता है। उपयोगकर्ता व्यक्तित्व और संवाद कार्य प्रदर्शन के बीच संबंधों का पता लगाने के लिए, हमने पहले निर्दिष्ट व्यक्तित्व प्रश्नावली का उत्तर देने के लिए क्राउडसोर्सिंग के माध्यम से प्रतिभागियों को नामांकित किया और फिर असाइन किए गए कार्यों को पूरा करने के लिए एक संवाद प्रणाली के साथ चैट किया। प्रचलित मल्टी-डोमेन विज़ार्ड-की-Oz (MultiWOZ) कार्य पर एक नियम-आधारित संवाद प्रणाली का उपयोग किया गया था। कुल 211 प्रतिभागियों के व्यक्तित्व और उनके 633 संवादों को एकत्र और विश्लेषण किया गया था। परिणामों से पता चला कि मिलनसार और बहिर्मुखी लोग कार्य को विफल करने की प्रवृत्ति रखते थे, जबकि न्यूरोटिक लोगों के सफल होने की अधिक संभावना थी। हमने उपयोगकर्ता संवाद व्यवहार से संबंधित सुविधाओं को निकाला और यह निर्धारित करने के लिए आगे विश्लेषण किया कि किस प्रकार का व्यवहार कार्य प्रदर्शन को प्रभावित करता है। नतीजतन, हमने पहचान की कि औसत उच्चारण लंबाई और प्रति उच्चारण स्लॉट संवाद व्यवहार की प्रमुख विशेषताएं हैं जो कार्य प्रदर्शन और उपयोगकर्ता व्यक्तित्व दोनों के साथ अत्यधिक सहसंबद्ध हैं।', 'ja': 'ユーザーパーソナリティへの適応性を備えたタスク指向の対話システムを提供することは、対話タスクのパフォーマンスを向上させるのに大いに役立ちます。 しかしながら、このような対話システムは、ユーザーの性格が対話タスクのパフォーマンスにどのように影響するかが不明であるため、実装するのは実質的に困難である。 ユーザーパーソナリティと対話タスクのパフォーマンスの関係を探るために、クラウドソーシングを介して参加者を登録し、最初に指定されたパーソナリティのアンケートに答え、次に対話システムとチャットして割り当てられたタスクを達成します。 一般的なMulti - Domain Wizard - of - Oz (MultiWOZ)タスクのルールベースのダイアログシステムが使用されました。 総勢211人の参加者の性格と633人の対話を収集し、分析した。 結果は、社交的で外向的な人々がタスクに失敗する傾向があるのに対し、神経質な人々は成功する可能性が高いことを明らかにしました。 ユーザーの対話行動に関連する機能を抽出し、タスクのパフォーマンスに影響を与える行動の種類を決定するためにさらなる分析を行いました。 その結果、発話の平均的な長さと発話ごとのスロットが、タスクのパフォーマンスとユーザーパーソナリティの両方と高度に相関する対話行動の主要な特徴であることを特定しました。', 'zh': '赋予乡言系统对用户性适应性,可以大助言。 然则统实难成,未详用户性之所以动言也。 求用户性与言事相关,因众包募参与者,先答指性问卷,然后与对语系统聊天以成分配之任。 用一法之统,施于流行之多域绿野仙踪(MultiWOZ)。 凡采析211名参与者之性,及其633对。 结果显示善交外向者不能成其事,而神经质者益有功。 取用户之所关,而更论之,以定其绩效。 是以见均言之长,槽位言之要,与任性相关,与用户性相关。', 'ru': 'Наделение системы диалога, ориентированной на решение конкретных задач, способной адаптироваться к личности пользователя, может в значительной степени способствовать повышению эффективности выполнения задачи диалога. Однако такая система диалога может быть практически сложной для реализации, поскольку неясно, как пользовательская личность влияет на выполнение задачи диалога. Чтобы изучить взаимосвязь между личностью пользователя и выполнением задачи диалога, мы зачислили участников с помощью краудсорсинга, чтобы сначала ответить на определенные анкеты личности, а затем пообщаться с системой диалога для выполнения поставленных задач. Была использована основанная на правилах система диалога по преобладающей задаче "Многодоменный мастер-оз" (MultiWOZ). Было собрано и проанализировано в общей сложности 211 личностей участников и их 633 диалога. Результаты показали, что общительные и экстравертные люди, как правило, не справляются с этой задачей, в то время как невротические люди имеют больше шансов на успех. Мы выделили особенности, связанные с поведением в диалоге с пользователем, и провели дальнейший анализ, чтобы определить, какое поведение влияет на выполнение задачи. В результате мы определили, что средняя длина речи и слоты на фразу являются ключевыми особенностями поведения диалога, которые в значительной степени коррелируют как с выполнением задачи, так и с личностью пользователя.', 'ga': 'Is féidir go mór le feabhas a chur ar fheidhmíocht taisc idirphlé trí chóras idirphlé tasc-dhírithe a chur in oiriúint do phearsantacht an úsáideora. Mar sin féin, is féidir le córas idirphlé den sórt sin a bheith beagnach dúshlánach a chur i bhfeidhm, toisc nach bhfuil sé soiléir conas a théann pearsantacht úsáideora i bhfeidhm ar fheidhmíocht tasc idirphlé. Chun iniúchadh a dhéanamh ar an ngaol idir pearsantacht úsáideora agus feidhmíocht tascanna idirphlé, rinneamar rannpháirtithe a chlárú trí sluafhoinsiú chun ceistneoirí sonraithe pearsantachta a fhreagairt ar dtús agus ansin comhrá a dhéanamh le córas idirphlé chun tascanna sannta a chur i gcrích. Baineadh úsáid as córas comhphlé bunaithe ar rialacha ar an tasc forleathan Il-Fearainn Draoi Oz (MultiWOZ). Bailíodh agus rinneadh anailís ar phearsantachtaí 211 rannpháirtí agus a 633 idirphlé. Léirigh na torthaí go raibh an claonadh ann go dteipfeadh ar dhaoine sochaíocha agus easghluaiseachta an tasc, ach gur mó an seans go n-éireodh le daoine néareolaíocha. Bhaineamar amach gnéithe a bhaineann le hiompraíochtaí comhphlé le húsáideoirí agus rinneamar anailís bhreise chun a fháil amach cén cineál iompair a mbíonn tionchar aige ar fheidhmíocht tascanna. Mar thoradh air sin, d’aithníomar gurb iad meánfhad cainte agus sliotáin in aghaidh na cainte na príomhghnéithe den iompar idirphlé a bhfuil comhghaol mór acu le feidhmíocht tasc agus pearsantacht an úsáideora araon.', 'ka': 'მომხმარებელი პერიციონალექტისთვის ადაპტიფიკაციას დასრულებული დავალება დიალოგის დამუშავებაზე დიალოგის მომხმარებას ძალიან დახმარება. მაგრამ ასეთი დიალოგის სისტემა შეიძლება პროფექტიურად გავამუშავებელი იყოს, რადგან არ უცნობია, როგორ მომხმარებელი პირადნობა დიალოგის დავამუშავებ თუ გამოყენებელი პირადნობის და დიალოგის დავალების შესახებ შესახებ, ჩვენ მომხმარებელი მსოფლიოს გამოყენება პირველი განსახულებული პირადნობის კითხვებისთვის და შემდეგ დიალოგის სისტემისთვის საუბ პროგრამეტური დიალოგური სისტემა გამოყენებულია მრავალეთომენის საქაღალდე Oz (MultiWOZ) მომხმარებელი საქაღალდე. 211 მოთავსდებულების პირადნობები და 633 დიალოგიები შექმნა და ანალიზაცია. წარმოდგენები გააჩვენეთ, რომ სოციალური და ექსტრობერტიური ადამიანები უფრო შეუძლებელია გავაკეთებონ საქმე, მაგრამ ნეიროტიური ადამიანები უფრო შესაძ მომხმარებელი დიალოგის ქცევების შესახებ და დამატებული ანალიზი გავაკეთეთ, რომელიც ქცევის შესახებ მომხმარებას მომხმარებას. შემდეგ, ჩვენ განვიცნეთ, რომ საშუალო სიგრძე და სიგრძე ყველა სიგრძე არის დიალოგის მონაცემების გასაკუთარი ფუნქციები, რომლებიც უფრო კოლექტურია საქმედებო', 'hu': 'A felhasználói személyiséghez igazodó, feladatorientált párbeszédrendszer létrehozása nagymértékben segíthet javítani egy párbeszédfeladat teljesítményét. Egy ilyen párbeszédrendszer azonban gyakorlatilag kihívást jelenthet, mert nem világos, hogy a felhasználói személyiség hogyan befolyásolja a párbeszédfeladat teljesítményét. A felhasználói személyiség és a párbeszédfeladat teljesítménye közötti kapcsolat feltárásához crowdsourcing segítségével regisztráltuk a résztvevőket, hogy először meghatározott személyiségi kérdőívekre válaszoljanak, majd beszélgessenek egy párbeszédrendszerrel a kijelölt feladatok elvégzéséhez. Egy szabályalapú párbeszédrendszert használtunk az elterjedt Multi-Domain Wizard-of-Oz (MultiWOZ) feladatra. Összesen 211 résztvevő személyiségét és 633 párbeszédét gyűjtöttük össze és elemeztük. Az eredmények azt mutatták, hogy a társasági és extrovertált emberek hajlamosak voltak kudarcot vallani a feladatnak, míg a neurotikus emberek nagyobb valószínűséggel sikerülnek. Kivontuk a felhasználói párbeszéd viselkedéséhez kapcsolódó funkciókat, és további elemzéseket végeztünk annak meghatározására, hogy milyen viselkedés befolyásolja a feladat teljesítményét. Ennek eredményeképpen azonosítottuk, hogy az átlagos kimondási hossz és a kimondásonkénti rések a párbeszédviselkedés kulcsfontosságú jellemzői, amelyek nagymértékben összefüggnek mind a feladatteljesítménnyel, mind a felhasználói személyiséggel.', 'el': 'Η παροχή ενός συστήματος διαλόγου προσανατολισμένου στην εργασία με προσαρμοστικότητα στην προσωπικότητα του χρήστη μπορεί σε μεγάλο βαθμό να βοηθήσει στη βελτίωση της απόδοσης μιας εργασίας διαλόγου. Ωστόσο, ένα τέτοιο σύστημα διαλόγου μπορεί να είναι πρακτικά δύσκολο να εφαρμοστεί, επειδή δεν είναι σαφές πώς η προσωπικότητα του χρήστη επηρεάζει την απόδοση των εργασιών διαλόγου. Για να διερευνήσουμε τη σχέση μεταξύ της προσωπικότητας του χρήστη και της απόδοσης της εργασίας διαλόγου, εγγράψαμε τους συμμετέχοντες μέσω για να απαντήσουν πρώτα σε συγκεκριμένα ερωτηματολόγια προσωπικότητας και στη συνέχεια να συνομιλήσουμε με ένα σύστημα διαλόγου για να ολοκληρώσουμε τις εργασίες που έχουν ανατεθεί. Χρησιμοποιήθηκε ένα σύστημα διαλόγου βασισμένο σε κανόνες για την κυρίαρχη εργασία του οδηγού πολλαπλών τομέων (MultiWOZ). Συγκεντρώθηκαν και αναλύθηκαν συνολικά οι προσωπικότητες των 211 συμμετεχόντων και οι 633 διαλόγοι τους. Τα αποτελέσματα έδειξαν ότι κοινωνικοί και εξωστρεφωμένοι άνθρωποι τείνουν να αποτυγχάνουν στο έργο, ενώ οι νευρωτικοί άνθρωποι ήταν πιο πιθανό να πετύχουν. Εξαγάλαμε χαρακτηριστικά που σχετίζονται με συμπεριφορές διαλόγου χρηστών και πραγματοποιήσαμε περαιτέρω ανάλυση για να προσδιορίσουμε ποιο είδος συμπεριφοράς επηρεάζει την απόδοση εργασιών. Ως αποτέλεσμα, εντοπίσαμε ότι το μέσο μήκος ομιλίας και οι αυλακώσεις ανά ομιλία είναι τα βασικά χαρακτηριστικά της συμπεριφοράς διαλόγου που συσχετίζονται ιδιαίτερα με την απόδοση εργασιών και την προσωπικότητα του χρήστη.', 'it': "Fornire un sistema di dialogo orientato ai compiti con adattabilità alla personalità dell'utente può contribuire notevolmente a migliorare l'esecuzione di un compito di dialogo. Tuttavia, un tale sistema di dialogo può essere praticamente difficile da implementare, perché non è chiaro come la personalità dell'utente influenzi le prestazioni delle attività di dialogo. Per esplorare la relazione tra la personalità dell'utente e le prestazioni delle attività di dialogo, abbiamo arruolato i partecipanti tramite crowdsourcing per rispondere prima a questionari specifici della personalità e poi chattare con un sistema di dialogo per eseguire le attività assegnate. È stato utilizzato un sistema di dialogo basato su regole sull'attività prevalente Multi-Domain Wizard-of-Oz (MultiWOZ). Sono state raccolte e analizzate 211 personalità dei partecipanti e i loro 633 dialoghi. I risultati hanno rivelato che le persone socievoli ed estroversa tendevano a fallire il compito, mentre le persone nevrotiche erano più propense ad avere successo. Abbiamo estratto funzionalità relative ai comportamenti di dialogo degli utenti ed eseguito ulteriori analisi per determinare quale tipo di comportamento influenza le prestazioni delle attività. Di conseguenza, abbiamo identificato che la lunghezza media di pronuncia e gli slot per pronuncia sono le caratteristiche chiave del comportamento del dialogo che sono altamente correlate sia con le prestazioni delle attività che con la personalità dell'utente.", 'kk': 'Тапсырма бағытталған диалог жүйесін пайдаланушының қасиеттеріне адаптациялығымен аяқтау диалог тапсырмасын жасау үшін көмектесе алады. Бірақ бұл диалог жүйесі жұмыс істеу үшін әсер етеді, себебі пайдаланушының қалай пайдаланушының диалог тапсырмаларының істеу нәтижесін білмейді. Пайдаланушылардың личілігі мен диалог тапсырмаларының қатынасын зерттеу үшін, қатысушыларды келтірілген жеке сұрақтарына бірінші жауап беріп, келтірілген тапсырмаларды орындау үшін диалог жүйесіне сұрақтады Келтірілген көп- домен- Oz (көп- WOZ) тапсырмасындағы ережелер негіздеген диалог жүйесі қолданылды. 211 қатысушылардың адамдары мен 633 диалогтарының жалпы жинақталды. Нәтижелер көмектесетін және экстровертті адамдар тапсырманы сәтсіздіруге болады, бірақ невротикалық адамдар сәтсіздіруге болады. Біз пайдаланушылардың диалог әрекеттеріне сәйкес болатын мүмкіндіктерді тарқатып, тапсырмалардың әрекеттеріне қандай тәртіпсіздігін анықтау үшін қосымша Сонымен біз тапсырмалар және пайдаланушылардың қасиеттері мен диалог әрекеттерінің орташа сөздердің ұзындығы мен слоттарын анықтадық.', 'lt': "Įgyvendinant užduotims orientuotą dialogo sistemą, kuri prisitaikytų prie naudotojo asmenybės, gali labai padėti pagerinti dialogo užduoties vykdymą. Tačiau tokia dialogo sistema gali būti praktiškai sudėtinga įgyvendinti, nes neaišku, kaip vartotojo asmenybė daro įtaką dialogo užduočių vykdymui. Siekdami išnagrinėti vartotojų asmenybės ir dialogo užduočių santykius, dalyviams dalyvavome naudojant visuomenės išteklius, pirmiausia atsakydami į konkrečius asmenybės klausimynus, o vėliau pasikalbėjome su dialogo sistema, kad atliktume nustatytas užduotis. Buvo naudojama taisyklėmis grindžiama dialogo sistema, susijusi su vyraujančiu daugiadominiu Oz (MultiWOZ) burtininku. A total of 211 participants' personalities and their 633 dialogues were collected and analyzed.  The results revealed that sociable and extroverted people tended to fail the task, whereas neurotic people were more likely to succeed.  Ištraukėme savybes, susijusias su vartotojų dialogo elgesiu, ir atlikome tolesnę analizę, kad nustatytume, koks elgesys turi įtakos užduočių vykdymui. As a result, we identified that average utterance length and slots per utterance are the key features of dialogue behavior that are highly correlated with both task performance and user personality.", 'ms': 'Meninggalkan sistem dialog orientasi tugas dengan adaptiviti kepada kepribadian pengguna boleh membantu dengan besar meningkatkan prestasi tugas dialog. Namun, sistem dialog seperti ini boleh menjadi praktikal mencabar untuk dilaksanakan, kerana tidak jelas bagaimana kepribadian pengguna mempengaruhi prestasi tugas dialog. Untuk mengeksplorasi hubungan antara kepribadian pengguna dan prestasi tugas dialog, kami mendaftar peserta melalui crowdsourcing untuk menjawab pertanyaan kepribadian tertentu pertama dan kemudian berbual dengan sistem dialog untuk menyelesaikan tugas yang ditugaskan. Sistem dialog berdasarkan peraturan pada tugas Wizard-of-Oz (MultiWOZ) Multi-Domain yang berkuasa digunakan. Jumlah 211 kepribadian peserta dan 633 dialog mereka telah dikumpulkan dan dianalisis. The results revealed that sociable and extroverted people tended to fail the task, whereas neurotic people were more likely to succeed.  Kami mengekstrak ciri-ciri berkaitan dengan perilaku dialog pengguna dan melakukan analisis lanjut untuk menentukan jenis perilaku apa yang mempengaruhi prestasi tugas. Sebagai hasilnya, kami mengenalpasti bahawa panjang dan slot rata-rata perkataan per perkataan adalah ciri-ciri utama perilaku dialog yang sangat berkorrelasi dengan prestasi tugas dan kepribadian pengguna.', 'mt': 'It-tmiem ta’ sistema ta’ djalogu orjentata lejn ix-xogħol b’adattabilità għall-personalità tal-utent jista’ jgħin ħafna fit-titjib tal-prestazzjoni ta’ kompitu ta’ djalogu. Madankollu, sistema ta’ djalogu bħal din tista’ tkun prattikament sfida biex tiġi implimentata, minħabba li mhuwiex ċar kif il-personalità tal-utent tinfluwenza l-prestazzjoni tal-kompiti tad-djalogu. Biex nistudjaw ir-relazzjoni bejn il-personalità tal-utent u l-prestazzjoni tal-kompiti tad-djalogu, irreġistrajna l-parteċipanti permezz tal-crowdsourcing għall-ewwel tweġiba għall-kwestjonarji tal-personalità speċifikati u mbagħad tkellem ma’ sistema ta’ djalogu biex twettaq kompiti assenjati. Intużat sistema ta’ djalogu bbażata fuq ir-regoli dwar il-kompitu prevalenti tal-Magu Multidomestiku tal-Oz (MultiWOZ). Ġie miġbur u analizzat total ta’ 211 personalità tal-parteċipanti u s-633 djalogu tagħhom. Ir-riżultati żvelaw li nies soċjabbli u estreverti kellhom it-tendenza li jfallu l-kompitu, filwaqt li nies newrotiċi kienu aktar probabbli li jirnexxu. Aħna estrajna karatteristiċi relatati mal-imġibiet tad-djalogu tal-utenti u għamilna analiżi ulterjuri biex niddeterminaw liema tip ta’ imġiba taffettwa l-prestazzjoni tal-kompiti. As a result, we identified that average utterance length and slots per utterance are the key features of dialogue behavior that are highly correlated with both task performance and user personality.', 'no': 'Med slutting av eit dialog med oppgåveorientert oppgåve med tilpassighet til brukarpersonlegheit kan du hjelpa stort å forbedra utviklinga av eit dialogoppgåve. Denne dialogsystemet kan imidlertid vera praktisk vanskeleg for å implementera, fordi det er ikkje klart korleis brukaren påvirkar oppgåva i dialogvindauget. For å utforske forholdet mellom brukarglassen og oppgåva i dialogvindauget, skrev vi inn deltakarar ved å gjera crowdsourcing til første svar på spesifiserte oppgåver for personalitet og så prate med eit dialogsystem for å fullføra tildelte oppgåver. Ein regelbasert dialogsystem på den prevalente multidomene- vegvisaren av Oz (MultiWOZ) oppgåva vart brukt. Samla og analysera innsamlingar av 211 deltakarar og 633 dialogar. Resultatene viste at sosiale og ekstroverte mennesker har tendert å mislukka oppgåva, mens neurotiske menneske var meir sannsynleg å velja. Vi ekstraherte funksjonar som relaterte til brukardialogen og utførte fleire analyser for å bestemme kva typen oppførsel påvirkar oppgåva. I resultatet har vi identifisert at gjennomsnittlig uttalelengd og plasser per uttale er nøkkelfunksjonane for dialogoppførsel som er svært korrelatert med både oppgåvefunksjonen og brukarnamnet.', 'mn': 'Хэрэглэгчийн хувьцааны адаптацийг ашиглах боломжтой диалог системийн төгсгөлд диалог даалгаврын үйл ажиллагааг сайжруулж чадна. Гэвч ийм диалог систем хэрхэн хэрэглэгчийн хувьд диалогын үйл ажиллагаанд нөлөөлдөг талаар хэцүү болж чадна. Хэрэглэгчийн хувилбар болон диалог ажлын үйл ажиллагааны хоорондын харилцааныг судалж үзэхийн тулд бид оролцогчдыг олон нийтэд анхны хувилбарын асуулт асуултын хариулт өгч, дараа нь тайлбарласан ажил хийх диалог системтэй ярилца Дүрмийн олон домайн шидтэн-of-Oz (MultiWOZ) ажлын тухай дүрмийн үндсэн диалог системийг ашигласан. 211 оролцогчдын хувьд, 633 диалогууд цуглуулж, шинжилгээ хийгдсэн. Үүний үр дүнд нийгмийн болон экстроверт хүмүүс үүнийг бүтэлгүйтдэг байсан. Гэхдээ мэдрэлийн хүмүүс илүү амжилттай байсан. Бид хэрэглэгчийн диалог үйл ажиллагаатай холбогдсон чадваруудыг гаргаж, ажиллагааны үйл ажиллагаанд нөлөөлдөг үйл ажиллагааг тодорхойлохын тулд дахин шинжилгээ хийсэн Үүний үр дүнд бид ажил үйлдвэрлэлтэй болон хэрэглэгчийн хувьцааны хоорондоо холбоотой дундаж хэлэлцээний урт болон слотууд гэдгийг ойлгосон.', 'pl': 'Wprowadzenie systemu dialogu zorientowanego na zadania z adaptacją do osobowości użytkownika może znacznie pomóc w poprawie wykonywania zadania dialogowego. Jednak taki system dialogu może być praktycznie trudny do wdrożenia, ponieważ nie jest jasne, w jaki sposób osobowość użytkownika wpływa na wykonanie zadań dialogowych. Aby zbadać związek między osobowością użytkownika a wykonywaniem zadań dialogowych, zarejestrowaliśmy uczestników za pośrednictwem crowdsourcingu, aby najpierw odpowiedzieć na określone kwestionariusze osobowości, a następnie porozmawiać z systemem dialogu w celu wykonania przypisanych zadań. Zastosowano oparty na regułach system dialogu na powszechnym zadaniu Wizard-of-Oz (MultiWOZ). Zebrano i analizowano osobowości uczestników 211 oraz ich dialogi 633. Wyniki ujawniły, że osoby towarzyskie i ekstrawertyczne skłonność do niepowodzenia zadania, natomiast osoby neurotyczne mają większe szanse na sukces. Wyodrębniliśmy funkcje związane z zachowaniami dialogu użytkowników i przeprowadziliśmy dalszą analizę, aby określić, jaki rodzaj zachowania wpływa na wydajność zadania. W rezultacie zidentyfikowaliśmy, że średnia długość wypowiedzi i sloty na wypowiedź są kluczowymi cechami zachowania dialogu, które są wysoce skorelowane zarówno z wydajnością zadania, jak i osobowością użytkownika.', 'ro': 'Oferirea unui sistem de dialog orientat spre sarcini cu adaptabilitate la personalitatea utilizatorului poate contribui în mare măsură la îmbunătățirea performanței unei sarcini de dialog. Cu toate acestea, un astfel de sistem de dialog poate fi practic dificil de implementat, deoarece nu este clar modul în care personalitatea utilizatorului influențează performanța sarcinii de dialog. Pentru a explora relația dintre personalitatea utilizatorului și performanța sarcinilor de dialog, am înscris participanții prin crowdsourcing pentru a răspunde mai întâi la chestionare specifice de personalitate și apoi chat cu un sistem de dialog pentru a îndeplini sarcinile atribuite. A fost folosit un sistem de dialog bazat pe reguli pentru activitatea predominantă Multi-Domain Wizard-of-Oz (MultiWOZ). Au fost colectate și analizate în total 211 personalități ale participanților și 633 de dialoguri ale acestora. Rezultatele au arătat că oamenii sociabili și extrovertizați tindeau să eșueze sarcina, în timp ce oamenii nevrotici erau mai predispuși să reușească. Am extras caracteristici legate de comportamentele de dialog ale utilizatorilor și am efectuat analize suplimentare pentru a determina ce fel de comportament influențează performanța sarcinii. Ca rezultat, am identificat că lungimea medie a rostirii și sloturile pe rostire sunt caracteristicile cheie ale comportamentului de dialog, care sunt foarte corelate atât cu performanța sarcinii, cât și cu personalitatea utilizatorului.', 'ml': "ഉപയോക്താവിന്റെ സ്വകാര്യത്തോട് പൂര്\u200dത്തീകരിക്കാനുള്ള ഒരു ജോലിയുടെ തിരഞ്ഞെടുത്ത ഡയലോഗ് സിസ്റ്റം അവസാനിപ്പ എങ്കിലും ഇതുപോലുള്ള ഒരു ഡയലോഗ് സിസ്റ്റം പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d പ്രധാനപ്പെടുത്തുന്നതിനായി വ്യാല്\u200dച്ചല്\u200d ചെയ്യു ഉപയോക്താവിന്റെ വ്യക്തിത്വവും ഡയലോഗ് ജോലി പ്രവര്\u200dത്തനവും തമ്മിലുള്ള ബന്ധങ്ങള്\u200d പരിശോധിക്കാന്\u200d ഞങ്ങള്\u200d പങ്കാളികളെ ആദ്യം വ്യക്തിപരമായ വ്യക്തിപരമാ മുമ്പ് പല- ഡൊമെയിന്\u200d മന്ത്രവാദി- ഓസിന്\u200dറെ (MultiWOZ) ജോലി ഉപയോഗിക്കുന്ന നിയമപരമായ ഡയലോഗ് സിസ്റ്റം ഉപയോഗിച്ചു. A total of 211 participants' personalities and their 633 dialogues were collected and analyzed.  അതിന്റെ ഫലങ്ങള്\u200dക്ക് വ്യക്തമായിരുന്നു സമൂഹത്തിലും വ്യത്യസ്ത വ്യത്യാസങ്ങളിലും ആളുകള്\u200d ജോലിയെ പരാജയപ്പെടുത്തുകയാ ഉപയോക്താവിന്റെ ഡയലോഗിന്റെ സ്വഭാവങ്ങളുമായി ബന്ധപ്പെട്ട സ്വഭാവങ്ങള്\u200d ഞങ്ങള്\u200d പുറത്തെടുക്കുകയും, ഏത് തരത്തിലെ പ്രവര്\u200d അതിന്റെ ഫലമായി ഞങ്ങള്\u200d തിരിച്ചറിഞ്ഞു കൊണ്ടിരിക്കുന്നു, സംസാരത്തിന്റെ സാധാരണ വാക്കുകളുടെ നീളവും സ്ലോട്ടുകളും സംസാരിക്കുന്നത", 'so': "Isku dhamaadka nidaamka diyaarinta shaqada oo ku habboon u isticmaalka wuxuu aad ugu caawin karaa horumarinta sameynta shaqada dialog. However, such a dialogue system can be practically challenging to implement, because it is unclear how user personality influences dialogue task performance.  Si aan u baarayno xiriirka u dhexeeya shakhsiga isticmaalka iyo sameynta shaqada dialogka, waxaynu u soo qornay kuwa ka qayb gala shaqada koowaad si aan ugu jawaabno su'aalaha ugu horraysa su'aalaha shakhsiga ah, dabadeedna waxaan la hadlnay nidaamka dialog si uu u dhamaado shaqada la qaybiyey. Waxaana isticmaalay nidaamka dialogue-based oo ku qoran shaqo saaxir badan-Domain-of-Oz (MultiWOZ). Dhammaan waxaa la soo ururiyey oo la analyaday dhamaantood 211 dadka ka qeybqaaday iyo 633 hadalkoodii. resultiyadii waxay muuqatay in dadka bulshada iyo midab-kala geystay ay ay dhamaadaan shaqada, laakiin dadka neuro-ku-jirta ayaa ka suurtowday inay liibaanaato. Waxaannu soo saarnay tayooyin la xiriira tababarada dialogue-ka isticmaalayaasha, waxaana sameynay baaritaan dheeraad ah si aan u ogaano caynkii tababarka shaqada saameyn ku yeelan karo. Sababtaas darteed waxaynu ogaannay in dhererka hadalka iyo waxyaabaha ku saabsan hadalka, waa xujooyinka ku saabsan tababarka shaqada iyo tababarka isticmaalaha.", 'sv': 'Ett uppgiftsorienterat dialogsystem som anpassar sig till användarens personlighet kan i hög grad bidra till att förbättra utförandet av en dialoguppgift. Ett sådant dialogsystem kan dock vara praktiskt taget utmanande att implementera, eftersom det är oklart hur användarpersonligheten påverkar dialoguppgiftens prestanda. För att utforska relationen mellan användarpersonlighet och dialoguppgiftsförmåga anmälde vi deltagare via crowdsourcing för att först besvara specifika personlighetsfrågor och sedan chatta med ett dialogsystem för att utföra tilldelade uppgifter. Ett regelbaserat dialogsystem för den vanligaste guiden för flera domäner (MultiWOZ) användes. Totalt 211 deltagares personligheter och deras 633 dialoger samlades in och analyserades. Resultaten visade att sällskapliga och utåtriktade människor tenderade att misslyckas med uppgiften, medan neurotiska människor var mer benägna att lyckas. Vi extraherade funktioner relaterade till användardialogbeteenden och utförde ytterligare analyser för att avgöra vilken typ av beteende som påverkar uppgifternas prestanda. Som ett resultat identifierade vi att genomsnittlig yttringslängd och intervall per yttring är de viktigaste funktionerna i dialogbeteende som är starkt korrelerade med både uppgifts prestanda och användarpersonlighet.', 'sr': 'Završiti sistem dijaloga orijentiranog na zadatke sa prilagodnošću ličnosti korisnika može veliko pomoći da poboljša funkciju dijaloga. Međutim, takvi dijalogski sistem može biti praktično izazovan za provedbu, jer nije jasno kako ličnost korisnika utiče na izvršnost zadataka dijaloga. Da bi istražili odnos između osobnosti korisnika i funkcije dijaloga, uključili smo učesnike putem crowdsourcing na prvi odgovor na ispitivanje osobnosti i onda razgovarali sa sistemom dijaloga kako bi postigli određene zadatke. Koristio je sistem dijaloga na pravilima o prevalenciji višedomeničkog čarobnjaka Oza (MultiWOZ) zadatka. Skupljeno je i analizirano ukupno ličnosti 211 sudionika i njihovih 633 dijaloga. Rezultati su otkrili da su društveni i ekstrovertirani ljudi tendencijali da propadnu zadatak, dok su neurotički ljudi vjerovatnije uspeli. Izvukli smo karakteristike povezane sa ponašanjem dijaloga korisnika i izvršili daljnju analizu kako bi utvrdili kakvo ponašanje utiče na učinkovitost zadataka. Kao rezultat toga, identifikovali smo da su prosječna dužina govora i slotovi po govoru ključne karakteristike ponašanja dijaloga koje su veoma povezane sa zadatkom i ličnostima korisnika.', 'ta': 'பயனர் தனிப்பட்டியலுக்கு ஒதுங்கும் பொருட்டு பணி செலுத்தப்பட்ட உரையாடல் முறைமை However, such a dialogue system can be practically challenging to implement, because it is unclear how user personality influences dialogue task performance.  பயனர் தன்மையுடன் உரையாடல் பணி செயல்பாட்டிற்கும் இடையே தொடர்பை கண்டறிவதற்கு, நாங்கள் குறிப்பிட்ட தனிப்பட்ட கேள்விகளின் மூலம் பங்கெடுப்பவர்களை சேர முன்னிருப்பு பல- டொமைன் வழிகாட்டி- of- Oz (MultiWOZ) பணியில் ஒரு விதிமுறையான உரையாடல் அமைப்பு பயன்படுத்தப்பட்டது. மொத்தமான 211 பங்குகிறவர்களின் தனிப்பட்டுள்ளவர்கள் மற்றும் அவர்களுடைய 633 உரையாடல்கள் சேகரிக்கப்பட்டு ஆராய்ச்ச முடிவுகள் வெளிப்படுத்தப்பட்டது சமூக மற்றும் மாற்றியமைக்கப்பட்ட மக்கள் பணியை தோல்வியுற்றது என்பது, ஆனால் நரம்புற மக் நாங்கள் பயனர் உரையாடல் நடத்தைகளுடன் தொடர்புடைய குணங்களை வெளியிட்டு மற்றும் எந்த வகையான நடத்தை பணியின் செயல்பாட்டை பா முடிவினால், நாங்கள் ஒவ்வொரு வார்த்தைக்கும் சராசரி வார்த்தை நீளம் மற்றும் செருகுகள் என்பதை கண்டுபிடித்துக் கொண்டிருக்கிறோம', 'si': 'භාවිත ප්\u200dරතිකාරයෙන් විශේෂතාවට සැකසුම් සඳහා කාර්යය ප්\u200dරතිකාර පද්ධතියක් අවසානය කරන්න පුළුවන් සංව නමුත්, ඒ වගේ සංවාද පද්ධතියක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන්, මොකද ප්\u200dරයෝජකය පුළුවන් පුළුව භාවිත පුද්ගලිකතාවය සහ සංවාද කාර්ය වැඩක් අතර සම්බන්ධය පරීක්ෂා කරන්න, අපි මුලින්ම පුද්ගලික පුද්ගලිකතාවය ප්\u200dරශ්නය ප්\u200dරශ්නය ප ප්\u200dරභාවිත ගොඩක් ඩෝමේන් විජාර්ඩ්-of-Oz (MultiWOZ) වැඩේ නීති අධාරිත සංවාද පද්ධතියක් භාවිත කළා. සම්පූර්ණයෙන් 211 අංශිකාරීන්ගේ පුද්ගලිකත්වය සහ එයාලගේ 633 සංවාද සම්පූර්ණය සහ විශේෂ ක ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරමාණය සහ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති අපි ප්\u200dරයෝජක සංවාදය සම්බන්ධ වෙනුවෙන් සම්බන්ධ විශ්ලේෂණය කරලා තියෙන්නේ කොහොමද ව්\u200dයාපෘතිය ව ප්\u200dරතිචාරයෙන්, අපි හොයාගත්තා සාමාන්\u200dය ප්\u200dරතිචාරය සහ ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් සංවාදය වැඩක් වලින් සංවාද', 'ur': 'کارساز شخصیت کے ساتھ اچھی طرح کے ساتھ ایک کام-oriented диалог سیسٹم کی پایان کرنا بہت بڑی مدد کرسکتا ہے کہ ایک ڈالگو کے کام کو بہتر کر سکے۔ However, such a dialog system can be practically challenging to implement, because it is unclear how user personality influences dialog task performance. کارساز شخصیت اور ڈیلوگ ٹاکس کے کام کے درمیان رابطہ کا تحقیق کرنے کے لئے، ہم نے مشرکین کو جمع سورسینس کے ذریعہ پہلی جواب دینے کے لئے سوال کرنے کے لئے لکھا تھا اور پھر ایک ڈیلوگ سیسٹم کے ساتھ بات کرنے کے لئے۔ اوز (MultiWOZ) کے مطابق بڑے ڈومین جادوگر (جادوگر) کے کام پر ایک قانون-بنیاد دیالوگ سیسٹم استعمال کیا گیا۔ 211 شرکت کرنے والوں کے شخصیت اور ان کے 633 ڈالگوں کو جمع کیا گیا اور تحلیل کیا گیا۔ نتیجے ظاہر کر رہے ہیں کہ اجتماعی اور غیر غیر غیر غیر قابل عمل کرنے والے لوگ ہیں، حالانکہ نیروٹیک لوگ بہت زیادہ کامیاب ہونے والے تھے. ہم نے کارساز ڈالیلوگ رفتار کے ساتھ مشترک خصوصے اٹھائے ہیں اور اس کے لئے اضافہ تحلیل کیا ہے کہ کس طرح رفتار کا تاثیر کرتا ہے۔ اس کے نتیجے میں ہم نے پہچان لیا کہ متوسط کلمات کی طول اور اسلوٹ ہر کلمات کے بارے میں ڈالیٹ رفتار کی کلی ویژگی ہیں جو کام کی عملکرد اور کارساز کی شخصیت کے ساتھ بہت اضافہ ہے.', 'mk': 'Endowing a task-oriented dialogue system with adaptiveness to user personality can greatly help improve the performance of a dialogue task.  However, such a dialogue system can be practically challenging to implement, because it is unclear how user personality influences dialogue task performance.  За да ја истражуваме врската помеѓу карактерската личност и извршувањето на задачите на дијалогот, ги пријавивме учесниците преку пулсурсирање на првиот одговор на специфицираните прашалници за персоналност и потоа разговаравме со дијалог систем за исполнување на задачите. Беше употребен систем на дијалог базиран на правилата за постојаната задача на мултидомен волшебник од Оз (МултиWOZ). Вкупно 211 учесници и нивните 633 дијалози беа собрани и анализирани. Резултатите открија дека друштвените и екстровертните луѓе имаат тенденција да ја пропаднат задачата, додека невротичките луѓе имаат поголема веројатност да успеат. Извадивме карактеристики поврзани со однесувањата на дијалогот на корисниците и изведовме понатамошна анализа за да утврдиме кој вид на однесување влијае на извршувањата на задачите. Како резултат на тоа, идентификувавме дека просечната должина на изразот и вредностите за израз се клучните карактеристики на однесувањето на дијалогот кои се високо поврзани со извршувањето на задачите и со карактерската личност.', 'uz': "Name Lekin, bu muloqat tizimi ishga tushirishga murakkab beradi, chunki foydalanuvchi shaxsiyatli dialog vazifalarni qanday ishga tayyorlaydi emas. Name A rule-based dialogue system on the prevalent Multi-Domain Wizard-of-Oz (MultiWOZ) task was used.  Muallif 211 participants shaxsiyatlari va 633 muloqatlarini olib tashlangan va analyzed. Natijalar ko'rsatadi, jamiyat va o'zgartirilgan odamlar vazifani bajaradi, ammo neyronik odamlari muvaffaqiyatli yetardi. Biz foydalanuvchi dialog xususiyatlariga bog'liq xususiyatlarni chiqardik va vazifaning qanday amalni ishga tayyorlash uchun boshqa analyzerni bajardik. Va natijada biz bir so'zlar orasidagi soʻzning uzunligi va boshqa chegaralari - muloqat xususiyatlarining muhim xususiyatlaridir va vazifa bajarish va foydalanuvchi shaxsiyati bilan juda bog'liq.", 'vi': 'Kết thúc một hệ thống đối thoại hướng nhiệm vụ có khả năng thích ứng với cá nhân người dùng có thể giúp cải thiện hiệu quả của nhiệm vụ đối thoại. Tuy nhiên, một hệ thống đối thoại như vậy có thể là một thử thách thực hiện, bởi vì không rõ người dùng có ảnh hưởng thế nào tới hiệu ứng nhiệm vụ của đối thoại. Để tìm hiểu mối quan hệ giữa cá nhân người dùng và vai trò đối thoại, chúng tôi đã tham gia vào cuộc họp qua cách tụ họp để trả lời các câu hỏi cá nhân và sau đó trò chuyện với một hệ thống đối thoại để thực hiện các nhiệm vụ được giao. Một hệ thống thoả thuận của nó về chiến dịch đa miền phổ biến của Oz được dùng. Đã thu thập và phân tích toàn bộ tính cách của người tham dự và bộ thoại 633 của họ. Kết quả cho thấy những người thân thiện và xa hoa có xu hướng thất bại trong nhiệm vụ, trong khi những người thần kinh có khả năng thành công hơn. Chúng tôi đã chiết xuất các tính năng liên quan đến hành vi của cuộc đối thoại người dùng và phân tích thêm để xác định loại hành vi nào ảnh hưởng đến hiệu ứng nhiệm vụ. Kết quả là, chúng tôi xác định được độ dài trung bình và khe hở mỗi phát âm là các yếu tố chủ yếu của hành vi đối thoại có mối quan hệ chặt chẽ với cả khả năng làm việc và tính cách người dùng.', 'nl': 'Een taakgericht dialoogsysteem dat zich aanpast aan de persoonlijkheid van de gebruiker kan de prestaties van een dialoogtaak aanzienlijk verbeteren. Een dergelijk dialoogsysteem kan echter praktisch uitdagend zijn om te implementeren, omdat het onduidelijk is hoe de persoonlijkheid van de gebruiker de prestaties van de dialoogtaak beïnvloedt. Om de relatie tussen gebruikerspersoonlijkheid en prestaties van dialoogtaken te onderzoeken, hebben we deelnemers via crowdsourcing ingeschreven om eerst specifieke persoonlijkheidsvraagstukken te beantwoorden en vervolgens te chatten met een dialoogsysteem om toegewezen taken uit te voeren. Er werd een regelgebaseerd dialoogsysteem gebruikt voor de veelgebruikte Multi-Domain Wizard-of-Oz (MultiWOZ) taak. In totaal werden de persoonlijkheden van 211 deelnemers en hun 633 dialogen verzameld en geanalyseerd. De resultaten toonden aan dat sociale en extroverte mensen de neiging hadden om de taak te mislukken, terwijl neurotische mensen eerder zouden slagen. We hebben functies geëxtraheerd met betrekking tot gebruikersdialooggedrag en hebben verdere analyses uitgevoerd om te bepalen welk soort gedrag de prestaties van taken beïnvloedt. Als gevolg hiervan hebben we vastgesteld dat de gemiddelde uitsprekingslengte en slots per uiting de belangrijkste kenmerken zijn van dialooggedrag die sterk gecorreleerd zijn met zowel taakprestaties als gebruikerspersoonlijkheid.', 'bg': 'Даването на ориентирана към задачите диалогова система с адаптивност към личността на потребителя може значително да помогне за подобряване на изпълнението на диалогова задача. Подобна диалогова система обаче може да бъде практически предизвикателна за изпълнение, тъй като не е ясно как личността на потребителя влияе върху изпълнението на задачите на диалога. За да проучим връзката между потребителската личност и изпълнението на задачите по диалога, записахме участници чрез crowdsourcing, за да отговорим първо на определени въпросници за личността и след това да разговаряме със система за диалог, за да изпълним възложените задачи. Използвана е базирана на правила диалогова система за преобладаващата задача Многодомейнен съветник от Оз (MultiWOZ). Бяха събрани и анализирани общо 211 личности на участниците и техните 633 диалога. Резултатите показват, че общителни и екстровертирани хора са склонни да се провалят в задачата, докато невротичните хора са по-склонни да успеят. Извадихме функции, свързани с поведението на потребителския диалог и извършихме допълнителен анализ, за да определим какъв вид поведение влияе върху изпълнението на задачите. В резултат на това установихме, че средната дължина на изказването и слотовете на изказване са ключовите характеристики на поведението на диалога, които са силно свързани както с изпълнението на задачите, така и с личността на потребителя.', 'da': 'Et opgaveorienteret dialogsystem med tilpasningsevne til brugerpersonlighed kan i høj grad bidrage til at forbedre udførelsen af en dialogopgave. Et sådant dialogsystem kan imidlertid være praktisk talt udfordrende at implementere, fordi det er uklart, hvordan brugerpersonlighed påvirker dialogopgavernes ydeevne. For at undersøge forholdet mellem brugerpersonlighed og dialogopgavernes ydeevne tilmeldte vi deltagere via crowdsourcing til først at besvare specifikke personlighedsspørgeskemaer og derefter chatte med et dialogsystem for at udføre tildelte opgaver. Der blev brugt et regelbaseret dialogsystem på den fremherskende Multi-Domain Wizard-of-Oz (MultiWOZ) opgave. I alt 211 deltageres personligheder og deres 633 dialoger blev indsamlet og analyseret. Resultaterne viste, at sociale og udadvendte mennesker havde tendens til at mislykkes opgaven, mens neurotiske mennesker var mere tilbøjelige til at lykkes. Vi udpakkede funktioner relateret til brugerdialogens adfærd og udførte yderligere analyser for at afgøre, hvilken slags adfærd der påvirker opgavernes ydeevne. Som et resultat identificerede vi, at gennemsnitlig udtalelseslængde og slots pr. udtalelse er de vigtigste træk ved dialogadfærd, der er stærkt korreleret med både opgaveydelse og brugerpersonlighed.', 'hr': 'Završiti sustav dijaloga orijentiranog na zadatke s prilagodnošću osobnosti korisnika značajno može pomoći poboljšati učinkovitost zadatka dijaloga. Međutim, takav dijalogski sustav može biti praktično izazovan za provedbu, jer nije jasno kako osobnost korisnika utječe na učinkovitost zadataka dijaloga. Da bismo istražili odnos između osobnosti korisnika i zadatka dijaloga, uključili smo učesnike putem crowdsourcing na prvi odgovor na ispitivanje osobnosti i onda razgovarali s dijalogskim sustavom kako bi postigli određene zadatke. Koristio je sistem dijaloga na pravilima o prevalenciji višedomeničkog čarobnjaka-od-Oz (MultiWOZ) zadatka. Ukupno je prikupljeno i analizirano osobnosti 211 učesnika i njihovih 633 dijaloga. Rezultati su otkrili da su društveni i ekstrovertirani ljudi tendencijali propustiti zadatak, dok su neurotički ljudi vjerojatniji da će uspjeti. Izvukli smo karakteristike povezane s ponašanjem dijaloga korisnika i proveli daljnju analizu kako bi utvrdili kakvo ponašanje utjecalo na učinkovitost zadataka. Kao rezultat toga, identificirali smo da su prosječna dužina govora i mjesta po govoru ključne karakteristike dijalogskog ponašanja koje su vrlo povezane sa zadatkom i osobnošću korisnika.', 'de': 'Die Bereitstellung eines aufgabenorientierten Dialogsystems mit Anpassungsfähigkeit an die Benutzerpersönlichkeit kann erheblich dazu beitragen, die Leistung einer Dialogaufgabe zu verbessern. Ein solches Dialogsystem kann jedoch praktisch schwierig zu implementieren sein, da unklar ist, wie die Benutzerpersönlichkeit die Leistung von Dialogaufgaben beeinflusst. Um den Zusammenhang zwischen Benutzerpersönlichkeit und Dialogaufgabenleistung zu untersuchen, haben wir Teilnehmer per Crowdsourcing eingeschrieben, um zuerst bestimmte Persönlichkeitsfragebögen zu beantworten und dann mit einem Dialogsystem zu chatten, um zugewiesene Aufgaben zu erfüllen. Es wurde ein regelbasiertes Dialogsystem zum gängigen Multi-Domain Wizard-of-Oz (MultiWOZ) Task verwendet. Insgesamt wurden Persönlichkeiten der 211 Teilnehmer und deren 633 Dialoge gesammelt und analysiert. Die Ergebnisse zeigten, dass gesellige und extrovertierte Menschen eher versagen, während neurotische Menschen eher erfolgreich waren. Wir extrahierten Funktionen im Zusammenhang mit Benutzerdialogverhalten und führten weitere Analysen durch, um festzustellen, welche Art von Verhalten die Aufgabenleistung beeinflusst. Als Ergebnis haben wir festgestellt, dass durchschnittliche Äußerungslänge und Zeitfenster pro Äußerung die Schlüsselmerkmale des Dialogverhaltens sind, die sowohl mit der Aufgabenleistung als auch mit der Benutzerpersönlichkeit korrelieren.', 'id': 'Mengakhiri sebuah sistem dialog oriented tugas dengan adaptivitas pada kepribadian pengguna dapat membantu dengan besar meningkatkan prestasi tugas dialog. Namun, sistem dialog seperti itu dapat praktis menantang untuk menerapkan, karena tidak jelas bagaimana kepribadian pengguna mempengaruhi prestasi tugas dialog. Untuk mengeksplorasi hubungan antara kepribadian pengguna dan prestasi tugas dialog, kami mendaftar peserta melalui crowdsourcing untuk menjawab pertanyaan kepribadian tertentu pertama dan kemudian berbicara dengan sistem dialog untuk menyelesaikan tugas yang ditugaskan. Sistem dialog berdasarkan aturan pada tugas Multi-Domain Wizard of-Oz (MultiWOZ) yang berkuasa digunakan. Seluruhnya 211 peserta pribadi dan 633 dialog mereka dikumpulkan dan dianalisis. Hasilnya menunjukkan bahwa orang-orang sosial dan ekstrovert cenderung gagal tugas, sementara orang-orang neurotis lebih mungkin berhasil. Kami mengekstrak fitur berkaitan dengan perilaku dialog pengguna dan melakukan analisis lanjut untuk menentukan perilaku apa yang mempengaruhi prestasi tugas. Sebagai hasilnya, kami mengidentifikasi bahwa panjang istilah rata-rata dan slot per istilah adalah fitur kunci perilaku dialog yang sangat terkait dengan prestasi tugas dan kepribadian pengguna.', 'ko': '임무를 위한 대화 시스템에 사용자 개성에 대한 적응성을 부여하면 대화 임무의 성능을 크게 향상시킬 수 있다.그러나 이러한 대화 시스템은 실제적으로 실현하기 어렵다. 왜냐하면 사용자 개성이 대화 임무의 집행에 어떻게 영향을 미치는지 아직 분명하지 않기 때문이다.사용자의 개성과 대화 임무 실적 간의 관계를 탐색하기 위해 우리는 패키지를 통해 참여자를 모집하고 특정한 개성 설문지에 먼저 대답한 다음에 대화 시스템과 채팅을 해서 지정된 임무를 완성한다.유행하는 다중 도메인 Oz 마법사(MultiWOZ) 작업에 규칙 기반 대화 시스템을 사용했습니다.참여자 211명의 개성과 633단의 대화를 수집·분석했다.그 결과 사교형과 외향형은 실패하고 신경질적인 사람은 성공하기 쉽다는 결과가 나왔다.우리는 사용자의 대화 행위와 관련된 특징을 추출하고 어떤 행위가 임무의 집행에 영향을 미칠지 한층 더 분석했다.따라서 우리는 평균 언어의 길이와 매번 언어의 시간 간격이 대화 행위의 관건적인 특징으로 임무 실적과 사용자 개성과 매우 관련이 있다는 것을 발견했다.', 'fa': 'پایان کردن یک سیستم محاورۀ محاورۀ تابع با توجه به شخصیت کاربر می\u200cتواند بسیار کمک کند که فعالیت یک کار محاورۀ محاورۀ بهتر شود. ولی این سیستم گفتگو می تواند در واقع برای عملکرد سخت باشد، زیرا مشخص نیست که شخصیت کاربر چگونه تأثیر عملکرد گفتگو را تأثیر می دهد. برای تحقیق رابطه بین شخصیت کاربر و عملکرد وظیفه\u200cی مشاوره\u200cای از طریق سرمایه\u200cگذاری جمعیت برای اولین جواب سوال\u200cهای شخصیت مشخص شده و سپس با یک سیستم محاوره برای انجام وظیفه\u200cهای مشخص صحبت کردیم. یک سیستم محاورۀ قانونی بر روی کار فراوان جادوگر-از-Oz (MultiWOZ) چند دامنه استفاده شد. کلی شخصیت 211 شرکت کننده و گفتگوهای 633 آنها جمع و تحلیل شدند. نتیجه\u200cها نشان دادند که افراد اجتماعی و خارج شده\u200cاند که از کار شکست خوردند، در حالی که افراد عصبی بیشتر احتمال موفقیت می\u200cکنند. ما ویژگی\u200cهای مربوط به رفتارهای محاورۀ محاورۀ کاربر استخراج کردیم و تحلیل بیشتری را انجام دادیم تا تعیین کنیم که کدام نوع رفتاری بر عملکرد کار تاثیر می\u200cدهد. به نتیجه، ما شناسایی کردیم که طول عمومی و نقطه\u200cهای متوسط در هر گفتار ویژه\u200cهای کلیدی رفتار محاورۀ گفتگو هستند که با انجام کار و شخصیت کاربر بسیار ارتباط دارند.', 'sw': 'Kumaliza mfumo wa mazungumzo yenye malengo yenye upatikanaji wa utumiaji unaweza kusaidia kuboresha utendaji wa kazi ya mazungumzo. Hata hivyo, mfumo wa mazungumzo kama haya unaweza kuwa na changamoto ya kutekeleza, kwa sababu haijaeleweka jinsi watumiaji wanavyoathiri utendaji wa mazungumzo. Ili kuchunguza uhusiano kati ya mtumiaji binafsi na utendaji wa juhudi la mazungumzo, tuliwahusisha washiriki kupitia vyanzo vya umma ili kujibu maswali ya kwanza maalum na kisha kuzungumza na mfumo wa mazungumzo ili kutekeleza kazi zilizotengenezwa. Mfumo wa mazungumzo yenye msingi wa sheria uliotumiwa katika kazi ya Wizara ya Ki-Oz (MultiWOZ). Jumla ya watu wa washiriki 211 na mazungumzo yao 633 yalikusanyika na kuchambuliwa. Matokeo yalionyesha kuwa watu wenye asili ya kijamii na waliobadili wamekuwa wakishindwa kufanya kazi hiyo, wakati watu wa neuro walikuwa na uwezekano wa kufanikiwa. Tumevuta tabia zinazohusiana na tabia za mazungumzo ya watumiaji na tukafanya uchambuzi zaidi ili kutambua aina gani ya tabia inaathiri utendaji wa kazi. Matokeo yake, tuligundua kuwa kiwango cha wastani cha hotuba na vidole kwa lugha ni hoja za tabia za mazungumzo ambazo zinaunganishwa sana na utendaji wa kazi na utumiaji.', 'tr': "Ullançy şahslyklara adatýanlyk bilen täze görniş sistemini soňlandyrmak üçin bir dialoog täbligini gowurap biler. Ýöne bu dialoog sistemi implementlemek üçin has kynçylyk edip biler, sebäbi ullançy şahslyklaryň dialog täsirinden nähili täsir etjek bolup bilmeýär. Ullançylaryň şahslyklary we dialoglaryň täblisasy arasyndaky baglaýyşyny gözlemek üçin, biz gatnaşlyklary görkezilen şahslyk soraglarynyň ilkinji jogap berip, we soňra belirlenýän zady başarmak üçin bir dialog sistemi bilen soňlaşdyrdyk. Oz'yň köp-sahypa Wizard-of-Oz (MultiWOZ) işinde daýanýan bir düzgün sistemi ullanýardy. 211-nji iştirakçileriniň kişilikleri we 633 dialoglarynyň toplamynda ýygnandy we çözümlendi. Netijeler jemgyýetli we ýok edilen adamlaryň görevini boýun gaçyrmaklygyny bildirdi. Nädogry adamlar başarap biljek bolup pikir edýärler. Ullançylar dialogy davrançylara baglanýan özellikleri çykardyk we işlerin nähili iş etkinleşigine täsirleýändigini bejermek üçin başga çözümleri çykardyk. Sonuçta, sözleriniň ortalama sözleriniň uzunlygyny we ýerleriniň sözleriniň a ýratynyň hem işgärligi we ullançylaryň şahslyklary bilen baglanýan dijal zadynyň açyk özellikleridir.", 'af': "Einde van 'n taak-orienteerde dialoog stelsel met aanpasbaarheid na gebruiker persoonlikheid kan baie help om die prestasie van 'n dialoog taak te verbeter. Maar sodanige 'n dialoog stelsel kan praktiese praktiese praktiese aanvaardig wees om te implementeer, omdat dit onbekende is hoe gebruiker persoonlikheid die dialoog taak uitvoer. Om die verwanting tussen gebruiker persoonlik en dialoog-taak uitvoer te ondersoek, het ons deelnaders ingeskryf deur verskeidende verwanting na die eerste antwoord gespesifiseerde persoonlike vraagnaire en dan gesprek met 'n dialoog stelsel om toegewyse taak te voltooi. 'n Reël- gebaseerde dialoog stelsel op die oorspronklike Multi- Domein Assistent- of- Oz (MultiWOZ) taak was gebruik. 'n Totaal van 211 deelnaders se persoonlik en hulle 633 dialoog is versamel en analyseer. Die resultate het geopenbaar dat sosiale en extroverteerde mense die taak gevaal het, terwyl neurotiese mense meer waarskynlik om te sukses. Ons het uitgevoer funksies wat verwante met gebruikerdialoog gedragte is en verdere analisie uitgevoer om te bepaal watter soort gedrag het die taak uitvoer. As 'n resultaat, ons het geïdentifiseer dat gemiddelde uitspraak lengte en slots per uitspraak die sleutel funksies van dialoog gedrag wat baie korrelasieer is met beide taak uitspraak en gebruiker persoonlik.", 'sq': 'Mbyllja e një sistemi dialogu të orientuar në detyra me përshtatje ndaj personalitetit të përdoruesit mund të ndihmojë në mënyrë të madhe përmirësimin e performancës së një detyre dialogu. However, such a dialogue system can be practically challenging to implement, because it is unclear how user personality influences dialogue task performance.  Për të eksploruar marrëdhëniet midis personalitetit të përdoruesit dhe performancës së detyrave të dialogut, ne regjistruam pjesëmarrësit nëpërmjet crowdsourcing për të përgjigjur së pari pyetësat e specifikuara të personalitetit dhe pastaj bisedojmë me një sistem dialog për të kryer detyrat e caktuara. U përdor një sistem dialog bazuar në rregulla mbi detyrën e mbizotërueshme të Magjistarit Multi-Domain-of-Oz (MultiWOZ). Një total prej 211 personaliteteve të pjesëmarrësve dhe 633 dialogeve të tyre u mblodhën dhe u analizuan. Rezultatet zbuluan se njerëzit shoqërues dhe ekstrovertë kanë tendencë të dështojnë detyrën, ndërsa njerëzit neurotikë kanë më shumë gjasa të kenë sukses. Ne nxorrëm karakteristika të lidhura me sjelljet e dialogut të përdoruesve dhe kryem analiza të mëtejshme për të përcaktuar se cili lloj sjellje ndikon në performancën e detyrave. Si rezultat, ne identifikuam se gjatësia mesatare e shprehjes dhe intervalet për shprehje janë karakteristikat kryesore të sjelljes së dialogut që janë shumë të lidhura me performancën e detyrës dhe personalitetin e përdoruesit.', 'hy': 'Վերջացնելը գործողության անհատականությանը հարմարեցնող համակարգին կարող է մեծ օգնությամբ բարելավել գործողությունները: Այնուամենայնիվ, այդպիսի հաղորդակցման համակարգը կարող է իրականացնել մարտահրավեր, քանի որ անհասկանալի է, թե ինչպես է օգտագործողի անհատականությունը ազդում հաղորդակցման գործողություններին: Որպեսզի ուսումնասիրենք օգտագործողի անհատականության և հաղորդակցման գործողությունների միջև կապը, մենք ներգրավեցինք մասնակիցներին խմբավորման միջոցով առաջին անհատականության հարցերին պատասխանելու և հետո խոսեցինք հաղորդակցված գործողությունների կատարման համար: Օզայի բազմաբնույթի կախարդանի (multiwoz) հիմնված կանոններով խոսակցության համակարգը օգտագործվեց: Ընդհանուր առմամբ 211 մասնակիցների անհատականությունները և նրանց 633 հաղորդագրությունները հավաքվեցին և վերլուծվեցին: The results revealed that sociable and extroverted people tended to fail the task, whereas neurotic people were more likely to succeed.  Մենք դուրս բերեցինք հատկություններ, որոնք կապված են օգտագործողների հաղորդակցման վարքագիծների հետ, և կատարեցինք ավելի շատ վերլուծություններ, որպեսզի պարզենք, թե ինչ տեսակի վարքագիծը ազդում է աշխատանքի արտա Արդյունքում, մենք հայտնաբերեցինք, որ արտահայտության միջին երկարությունը և արտահայտության ընթացքում արտահայտությունը բաժին արտահայտության հիմնական հատկություններն են, որոնք շատ կապված են աշխատանքի արտադրողության և օգտագործողի անհատականության հետ:', 'am': 'የመስኮት ማህበረሰብ በተጨማሪም ለሚጠቃሚ ስብሰባ መቆጣጠር የሚችል የጥያቄ ስብሰባ ማድረግ ማድረግ ይችላል፡፡ ምንም እንኳን፣ እንደዚህ ያሉ አካባቢ ስርዓት የጥያቄ ግንኙነት እንዴት ማድረግ የሚጠቅመው አይገልጽም፡፡ To explore the relationship between user personality and dialogue task performance, we enrolled participants via crowdsourcing to first answer specified personality questionnaires and then chat with a dialogue system to accomplish assigned tasks.  ብዙ-ዶሜን-የOz (MultiWOZ) ስራ የተጠቀመ የሥርዓት መክፈቻ ስርዓት ተጠቃሚ ነው። በሙሉ 211 ተጋሪዎቹ personality እና 633 ጥያቄዎቻቸው የተሰበሰቡ እና የተAnalyzed ናቸው፡፡ ፍሬዎቹም ማኅበራዊ እና የተለወጡት ሰዎች ስራውን ለማድረግ ይቻላል፤ ነገር ግን የነዌብ ሕዝብ ሊከናወጥ ይችላል፡፡ በተጠቃሚ ማኅበረሰብ ላይ የሚታያየውን ጥያቄ እና ምን ዓይነት በሥርዓት የሚጠቅመውን ጥያቄን ለማረጋገጥ እናሳውቀዋለን፡፡ ይሄንን ምክንያት፣ የቃላት ርዝመት እና የንግግር ግንኙነት እና የቃላት ግንኙነት በሥርዓት እና በተጠቃሚ የስራ ግንኙነት እና የተጠቃሚ ግንኙነት ጋር የታሰራች የdialogue ሁኔታ መክፈቻዎች ናቸው ብለን እናውቃለን፡፡', 'az': 'İstifadəçi kişiliğə uyğunluğu ilə işarə tərəf yönəlmiş dialoq sistemini bitirmək Dialoog işinin işarətini yaxşılaşdırmağa çox kömək edə bilər. Ancaq bu dialoq sistemi istifadə etmək üçün çox çətin olar, çünki istifadəçi kişilikləri dialog işləri növbəsini necə etmişdir. İstifadəçilərin kişilik və diyalət işləri arasındakı ilişkisini keşfetmək üçün, insanları qüvvətli səhifələr vasitəsilə ilk müəyyən kişilik soruşmalarına cavab vermək üçün yazdıq və sonra müəyyən edilmiş işləri yerinə yetirmək üçün diyalət sistemi ilə sohbet edirik. Böyük çox-Domen Sihirbazı-of-Oz (MultiWOZ) işi üzərində qayda-tabanlı диалог sistemi istifadə edildi. 211 iştirakçilərin kişilikləri və 633 dialogları toplanmış və analiz edilmişdir. Sonuçlar ortaya çıxartdı ki, sosyal və extrovert insanlar bu işin başarısız olmasına səbəb oldular, halbuki nörotik insanlar başarılı olaraq daha çox olardı. Biz istifadəçi dialogların davranışlarına bağlı özellikləri çıxartdıq və işlər işlətməsinin nə cür təsirlərinin etkisini belə müəyyən etmək üçün daha çox analizi etdik. Sonuç olaraq, hər sözlə ortalama sözlərin uzunluğunu və slotların dinik davranışlarının düzgün özellikləridir ki, hər işin performansı və istifadəçi kişiliği ilə çox bağlı olanlar.', 'bn': 'ব্যবহারকারীর ব্যক্তিত্বের প্রতি যোগ্যতার সাথে একটি কাজের মুখোমুখি ডায়ালগ সিস্টেম সমাপ্তি করা যায় একটি ডায়ালগ কাজের প্রদর তবে এই ধরনের ডায়ালগ ব্যবস্থা বাস্তবায়িত করতে পারে, কারণ ব্যবহারকারীর ব্যক্তিগত ব্যক্তিগত কিভাবে ডায়ালগ কর্মকর্তার প্রভাব ফেলতে প ব্যবহারকারীদের ব্যক্তিত্ব এবং ডায়ালগ কার্যক্রমের মধ্যে সম্পর্ক খুঁজে বের করার জন্য আমরা প্রথম ব্যক্তিগত প্রশ্নের উত্তর দিয়ে অংশগ্রহণকারীদের লিখেছি  পূর্ববর্তী বহ-ডোমেইন যাদুকর অফ-Oz (MultiWOZ) কাজের উপর নিয়মিত ডায়ালগ সিস্টেম ব্যবহার করা হয়েছে। মোট ২১১ অংশগ্রহণকারীদের ব্যক্তিত্ব এবং তাদের 633 আলোচনা সংগ্রহ করা হয় এবং বিশ্লেষণ করা হয়। ফলাফল প্রকাশ করেছে যে সমাজ এবং বিদ্রোহীত লোকেরা এই কাজ ব্যর্থ হয়েছে, কিন্তু নিউরোটিক লোকেরা আরো সফল হতে পারে। আমরা ব্যবহারকারী ডায়ালগের আচরণের সাথে সম্পর্কিত বৈশিষ্ট্য উদ্ধার করেছি এবং কোন ধরনের আচরণ নির্ধারণ করার জন্য আরো বিশ্লেষণ করে এর ফলে আমরা চিহ্নিত করেছি যে সাধারণ কথাবার্তার দীর্ঘ এবং ব্যবহারকারীদের ব্যক্তিত্বের সাথে যোগাযোগের মূল বৈশিষ্ট্য।', 'bs': 'Završiti sistem dijaloga orijentiranog na zadatke sa prilagodnošću ličnosti korisnika može mnogo pomoći poboljšati učinkovitost zadataka dijaloga. Međutim, takvi dijalogski sistem može biti praktično izazovan za provedbu, jer nije jasno kako ličnost korisnika utječe na provedbu zadataka dijaloga. Da bi istražili odnos između osobnosti korisnika i funkcije dijaloga, uključili smo učesnike putem crowdsourcing na prvi odgovor na ispitivanje osobnosti i onda razgovarali sa sistemom dijaloga kako bi postigli određene zadatke. Koristio je sistem dijaloga na pravilima o prevalenciji višedomeničkog čarobnjaka-od-Oz (MultiWOZ) zadatka. Skupljeno je i analizirano ukupno ličnosti 211 učesnika i njihovih 633 dijaloga. Rezultati su otkrili da su društveni i ekstrovertirani ljudi tendencijali da propadnu zadatak, dok su neurotički ljudi vjerojatniji da će uspjeti. Izvukli smo karakteristike povezane sa ponašanjem dijaloga korisnika i proveli daljnju analizu kako bi utvrdili kakvo ponašanje utjecalo na učinkovitost zadataka. Kao rezultat toga, identifikovali smo da su prosječna dužina govora i slotovi po govoru ključne karakteristike ponašanja dijaloga koje su visoko povezane sa zadatkom i osobnošću korisnika.', 'ca': "Finar un sistema de diàleg orientat a les tasques amb adaptació a la personalitat de l'usuari pot ajudar molt a millorar el desempeny d'una tasca de diàleg. Tanmateix, aquest sistema de diàleg pot ser pràcticament difícil d'implementar, perquè no és clar com la personalitat de l'usuari influeix en el desempeny de les tasques del diàleg. Per explorar la relació entre la personalitat de l'usuari i el desempeny de les tasques de diàleg, vam matricular els participants a través de crowdsourcing per respondre primer a cuestionaris de personalitat especificats i després vam conversar amb un sistema de diàleg per aconseguir tasques especificades. Es va utilitzar un sistema de diàleg basat en regles sobre la tasca prevalent Multi-Domain Wizard of Oz (MultiWOZ). Un total de 211 persones de participants i els seus 633 diàlegs van ser recollits i analitzats. Els resultats van revelar que les persones socials i extrovertes tendien a fracassar la tasca, mentre que les persones neurotiques tenien més probabilitat de tenir èxit. Vam extreure característiques relacionades amb els comportaments del diàleg d'usuaris i vam fer més anàlisis per determinar quin tipus de comportament influeix en el desempeny de les tasques. As a result, we identified that average utterance length and slots per utterance are the key features of dialogue behavior that are highly correlated with both task performance and user personality.", 'cs': 'Nadání dialogového systému orientovaného na úkoly s přizpůsobivostí osobnosti uživatele může značně pomoci zlepšit výkon dialogového úkolu. Takový dialogový systém však může být prakticky náročný na implementaci, protože není jasné, jak osobnost uživatele ovlivňuje výkon dialogových úkolů. Abychom prozkoumali vztah mezi osobností uživatele a výkonem dialogových úkolů, zapsali jsme účastníky prostřednictvím crowdsourcingu, aby nejprve odpověděli na konkrétní dotazníky osobnosti a poté chatovali s dialogovým systémem, abychom splnili přidělené úkoly. Byl použit dialogový systém založený na pravidlech převládající úlohy Multi-Domain Wizard-of-Oz (MultiWOZ). Celkem byly shromážděny a analyzovány osobnosti účastníků 211 a jejich 633 dialogy. Výsledky ukázaly, že společenskí a extrovertní lidé mají tendenci selhat úkol, zatímco neurotičtí lidé měli větší pravděpodobnost, že uspějí. Extrahovali jsme funkce související s chováním dialogu uživatelů a provedli další analýzu, abychom určili, který druh chování ovlivňuje výkon úkolů. V důsledku toho jsme identifikovali, že průměrná délka výroku a sloty na výrok jsou klíčovými rysy chování dialogu, které jsou vysoce korelované jak s výkonem úkolu, tak s osobností uživatele.', 'fi': 'Teht채v채l채ht철isen dialogij채rjestelm채n antaminen k채ytt채j채persoonallisuuteen mukautuvaksi voi suuresti auttaa parantamaan dialogiteht채v채n suorituskyky채. T채llainen dialogij채rjestelm채 voi kuitenkin olla k채yt채nn철ss채 haastava toteuttaa, koska on ep채selv채채, miten k채ytt채j채persoonallisuus vaikuttaa dialogiteht채v채n suorittamiseen. Tutkimme k채ytt채j채persoonallisuuden ja dialogiteht채v채n suorituskyvyn suhdetta joukkoistamalla osallistujia vastaamaan ensin tiettyihin persoonallisuuskyselyihin ja keskustelemaan sitten dialogij채rjestelm채n kanssa teht채vien suorittamiseksi. K채yt철ss채 oli s채채nt철pohjainen dialogij채rjestelm채 vallitsevaan Multi-Domain Wizard-of-Oz (MultiWOZ) -teht채v채채n. Yhteens채 211 osallistujan persoonallisuutta ja heid채n 633 dialogiaan ker채ttiin ja analysoitiin. Tulokset osoittivat, ett채 sosiaaliset ja extrovertuneet ihmiset ep채onnistuivat teht채v채ss채, kun taas neuroottiset ihmiset menestyiv채t todenn채k철isemmin. Poistimme k채ytt채jien vuoropuheluk채ytt채ytymiseen liittyvi채 ominaisuuksia ja suoritimme lis채analyysin selvitt채채ksemme, millainen k채ytt채ytyminen vaikuttaa teht채v채n suoritukseen. Tuloksena havaitsimme, ett채 keskim채채r채inen puheen pituus ja l채ht철kohdat lausetta kohden ovat dialogin k채ytt채ytymisen keskeisi채 ominaisuuksia, jotka korreloivat voimakkaasti sek채 teht채v채n suorituskykyyn ett채 k채ytt채j채persoonallisuuteen.', 'et': 'Ülesandepõhise dialoogisüsteemi kindlustamine, mis on kohandatud kasutaja isiksusega, võib oluliselt aidata parandada dialoogiülesande täitmist. Sellise dialoogisüsteemi rakendamine võib aga olla praktiliselt keeruline, sest ei ole selge, kuidas kasutaja isiksus mõjutab dialoogi ülesannete täitmist. Et uurida seost kasutaja isiksuse ja dialoogiülesannete täitmise vahel, registreerisime osalejad ühishankimise kaudu, et esmalt vastata konkreetsetele isiksuse küsimustikele ja seejärel vestelda dialoogisüsteemiga määratud ülesannete täitmiseks. Kasutati reeglipõhist dialoogisüsteemi, mis käsitleb valdavat Multi-Domain Wizard-of-Oz (MultiWOZ) ülesannet. Kokku koguti ja analüüsiti 211 osalejate isiksust ja nende 633 dialoogi. Tulemused näitasid, et sotsiaalsed ja ekstrovertsed inimesed kaldusid ülesande läbi kukkuma, samas kui neurootilised inimesed olid suurema tõenäosusega edukad. Me ekstraheerisime kasutajate dialoogikäitumisega seotud funktsioone ja tegime täiendava analüüsi, et teha kindlaks, milline käitumine mõjutab ülesannete täitmist. Selle tulemusena tuvastasime, et keskmine väljenduspikkus ja aegad ühe väljendi kohta on dialoogikäitumise põhijooned, mis on väga korrelatsioonis nii ülesannete täitmise kui ka kasutaja isiksusega.', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Nanging, sistem dialog sing bisa ngejarang dipepot kanggo nggawe nguasai, soalé ora ngerasai kapan pengguna kuwi nggawe kesempatan kanggo nggawe barang dialog. Jejaring A rule-basic dialog System on the usual Multi-domain Wizzar-of-Oz (MultiWOZ) task was used. Total nganggo perkarahaan kanggo masara-masara iki-masara iki karo dialog yang bantulang lan nganggo cara-cara bantên Rejaling ngomong nik kabèh sabên lan jewaké durung-jewèké wong liya ngono nggawe gerakan kanggo ngilangno sistêm kuwi mau, lan uwong-uwong sing isa luwih sabên susahe nêmên. Awak dhéwé buturan cara-cara sing nggawe barang nggambar barêng nggambar lan nganggep petani sing nyimpen kanggo nggawe barang nggawe barang nggawe FindOK', 'he': 'Endowing a task-oriented dialogue system with adaptiveness to user personality can greatly help improve the performance of a dialogue task.  עם זאת, מערכת דיאלוג כזו יכולה להיות למעשה מאתגרת להפעיל, כי לא ברור איך אישיות המשתמש משפיעה על ביצוע משימות דיאלוג. כדי לחקור את מערכת היחסים בין אישיות משתמשת לבצע משימות דיאלוג, נרשמנו משתתפים דרך crowdsourcing לתשובה ראשונה שאלונות אישיות מוגדרים ואז לשוחח עם מערכת דיאלוג כדי להשלים משימות מוגדרות. השתמשת מערכת דיאלוג מבוססת על חוקים על משימה קוסם של אוז (MultiWOZ) המורבי-דומין. לכל 211 אישיות משתתפים וה633 דיאלוגים שלהם נאספו ונבחנו. התוצאות חשפו שאנשים חברתיים וחוצרים נוטים להיכשל במשימה, בעוד שאנשים נוירוטים היו יותר סבירים להצליח. הוצאנו תכונות קשורות להתנהגות של דיאלוג משתמשים ובצענו ניתוח נוסף כדי לקבוע איזה סוג של התנהגות משפיעה על ביצוע המשימה. כתוצאה מכך, זיהינו שאורך הממוצע של מילוי ומקומות לכל מילוי הם האופיינים המרכזיים של התנהגות בדיולוגים שמתורבים באופן גבוה עם ביצוע המשימה ואישיות המשתמש.', 'sk': 'Dodeljevanje dialogskega sistema, usmerjenega v naloge, s prilagodljivostjo osebnosti uporabnika, lahko v veliki meri pomaga izboljšati izvedbo dialogske naloge. Vendar pa je tak dialogni sistem lahko praktično zahteven za izvajanje, saj ni jasno, kako osebnost uporabnika vpliva na izvedbo dialogske naloge. Za raziskovanje odnosa med osebnostjo uporabnika in izvedbo dialoga smo udeležence vključili prek množičnega sourcinga, da najprej odgovorijo na določene osebnostne vprašalnike in nato klepetajo s sistemom dialoga za izpolnitev dodeljenih nalog. Uporabljen je bil sistem dialoga, ki temelji na pravilih za prevladujoče opravilo Multi-Domain Wizard-of-Oz (MultiWOZ). Zbranih in analiziranih je bilo 211 osebnosti udeležencev in 633 dialogov. Rezultati so pokazali, da so družabni in ekstrovertni ljudje nagnjeni k neuspehu naloge, medtem ko so nevrotični ljudje bolj verjetni k uspehu. Izvlekli smo funkcije, povezane z vedenjem uporabniškega dialoga, in opravili nadaljnjo analizo, da bi ugotovili, katero vedenje vpliva na uspešnost opravila. Kot rezultat smo ugotovili, da so povprečna dolžina izgovora in reži na izgovor ključne značilnosti dialogskega vedenja, ki so močno povezane z uspešnostjo opravil in osebnostjo uporabnika.', 'ha': "Endowing a task-oriented dialogue system with adaptiveness to user personality can greatly help improve the performance of a dialogue task.  Kayya, ma'anar wannan zauren akwatin zauren akwatin bayani yana iya yin zartar da shi, don haka ba mai sani ba yadda mutane na amfani da shi yana shagala ga aikin zauren akwatin bayani. To, dõmin mu nẽmi taimako a tsakanin mutum da mazaɓan akwatin zauren akwatin bayani, mun shigar da mãsu haɗuwa a bayani na umam-source zuwa a farkon su tambayi masu ƙayyade masu tambayar su na kanana da kuma ka yi mazaɓa da wata zauren akwatin bayani dõmin ya cika aikin da aka ƙayyade su. An yi amfani da tsarin zauren akwatin bayani na ƙayyade a kan mai gabatar da multi-Domen-of-Oz (multi-WOZ). Gamlar mutane na farko da mazaunin 211 na sami zauren su da 633. Mataimakin ta bayyana cẽwa jama'a da waɗanda aka riga-tarawa sun yi mafiya rauni ga aikin, kuma amma mutane neurotic sun fi kusa su ci nasara. Mun fizge masu husũma da mazaɓa na zauren zauren akwatin bayani na amfani da kuma Muka sami wani anayyar daban dõmin ya san wane irin aikin zai yi amfani da aikin aiki. Kayyar wannan, mun gane cewa tsakanin magana da slogansa ko magana sun kasance maɓallin aikin zauren akwatin zauren akwatin bayani waɗand a suke yin giraffi da tsakanin aikin da kuma masu amfani da shi.", 'bo': 'སྤྱོད་མཁན་གྱི་མི་སྒེར་གྱི་མཐུན་སྒྲིག་ནི་ལྟ་བུའི་བྱ་འགུལ་གྱི་གླེང་སྒྲོམ་གྱི་མ་ལག ཡིན་ནའང་མ་འདིའི་ཌའི་ལོག་བློ་གཏད་ནི་ལག་ལེན་འཐབ་པར་ལས་གནད་ངལ་ཆོག བྱས་ན་སྤྱོད་མཁན་གྱི་མི་སྒེར་དང་གླེང་སྒྲོམ་གྱི་ལས་འགུལ་གྱི་འབྲེལ་བ་འདྲི་ཞིབ་དཔྱད་དགོས་པ་དང་མཉམ་དུ་བསྡུས་པའི་མི་སྒེར་གནད་དོན་དག་དང་མཉམ prevalent Multi-Domain Wizard-of-Oz(MultiWOZ)ལས་ཀ་ཐོག་ལས་གཞི་རྟེན་བཀོད་པའི་སྲོལ་སྒྲིག་བཀོད་སྤྱོད་མ་ལག་ཅིག མཉམ་དུ་ཚང་མཁན་གྱི་སྒེར་གཤིས་འདྲ་ཞིག་དང་ཁོང་ཚོའི་གླེང་མོལ་གྱི་དབྱེ་སྟངས་དང་དབྱེ་ཞིབ དབྱངས་འབྲས་བ་ནི་སྤྱི་ཚོགས་འབྲེལ་བ་དང་ཁྱད་པར་བྱེད་མཁན་གྱི་མི་མང་གིས་ལས་ཀ་སྐྱོན་བརྗོད་ཡོད། ང་ཚོས་སྤྱོད་མཁན་གྱི་ཌའི་ལོག་འགྲོ་བ འོན་ཀྱང་། ང་ཚོས་ཐོག་མའི་མཐུན་རིམ་དང་ཐོག་མའི་རིང་ཐོག'}
{'en': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'ar': 'نحو صفر وقليل من الطلقات التي تبحث عن المعرفة في الكشف عن الأدوار في أنظمة الحوار الموجهة نحو المهام', 'es': 'Hacia la detección de giros de búsqueda de conocimiento cero y de pocos disparos en sistemas de diálogo orientados a tareas', 'pt': 'Em direção à detecção de turnos de busca de conhecimento zero e poucos tiros em sistemas de diálogo orientados a tarefas', 'fr': 'Vers une détection de virage à la recherche de connaissances zéro et à faible émission dans les systèmes de dialogue orientés tâches', 'ja': 'タスク指向のダイアログシステムでのゼロおよびほとんどショットの知識探索ターン検出に向けて', 'zh': '于向事对话系统中成零和少镜头知识搜索回检', 'hi': 'शून्य और कुछ-शॉट ज्ञान की ओर- कार्य-उन्मुख संवाद प्रणालियों में टर्न डिटेक्शन की मांग', 'ru': 'На пути к нулевому и малозадачному обнаружению поворотов в системах диалога, ориентированных на решение поставленных задач', 'ga': 'I dTreo Nialais agus Beagán lámhaigh a fhéachann le heolas i gCórais Chomhphlé atá Dírithe ar Thascanna', 'ka': 'ნულის და ცოტა სტატის კონფიგურაციის ძიება მისამართებელი დიალოგის სისტემებში', 'hu': 'Tudáskereső fordulatfelismerés felé a feladatorientált párbeszédrendszerekben', 'el': 'Προς την ανίχνευση στροφών μηδενικού και ελάχιστου πυροβολισμού που αναζητά γνώση σε συστήματα διαλόγου προσανατολισμένα στις εργασίες', 'it': 'Verso il rilevamento dei turni alla ricerca di conoscenze zero e pochi colpi nei sistemi di dialogo orientati alle attività', 'kk': 'Тапсырма бағытталған диалог жүйелерінде нөл және кішкентай мәліметтерді іздеу', 'mk': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'ml': 'ജോലി തിരിച്ചറിയുന്ന ഡയലോഗ് സിസ്റ്റത്തിലേക്ക് തിരിച്ചറിയുന്നതിന് മുകളിലേക്കും കുറച്ച് വെടിയുള്ള അറിവ', 'lt': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'mt': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'no': 'Gå til null og få biletsøk i oppgåveorientert dialogvindauge', 'ro': 'Către detectarea virajelor în căutarea cunoștințelor zero și puține împușcături în sistemele de dialog orientate spre sarcini', 'ms': 'Ke arah Zero dan Beberapa-Shots Knowledge-Looking Turn Detection in Task-oriented Dialogue Systems', 'si': 'සීරෝ සහ ටිකක් වෙඩි තියෙන්නේ දැනගන්න- හොයාගන්නේ වැඩක් ප්\u200dරමාණය සංවාද පද්ධතියේ', 'so': 'Towards Zero and few-shot aqoonta raadinta dib u celinta nidaamka shaqo-oriented', 'mn': 'Нэг болон бага хэмжээний мэдлэг хайж буй ажил дээр дамжуулан диалог системийн эргүүл тогтоохын тулд', 'pl': 'W kierunku zerowego i niewielkiego wykrywania zakrętów poszukującego wiedzy w systemach dialogowych zorientowanych na zadania', 'ta': 'சூழ்நிலையில் மற்றும் சிறிய தேடும் அறிவிப்பு தேடும் திரும்ப திருப்பி கண்டுபிடிப்பு மேலே செல்', 'sv': 'Mot noll- och få skott Kunskapssökande vänddetektering i uppgiftsorienterade dialogsystem', 'ur': 'صفر اور تھوڑی شٹ کی طرف علم-تلاش کے لئے ٹاکس-oriented диалог سیستموں میں ٹاکس کی پیدا کرنا', 'sr': 'Do nule i malog otkrivanja znanja u sistemima dijaloga orientisanih na zadatke', 'uz': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'vi': 'Hướng tới hệ thống truy tìm nguồn thức vài phát hiện trong các hệ thống đối thoại', 'bg': 'Към нулево и маловажно откриване на завой в системите за диалог, ориентирани към задачите', 'nl': 'Naar Zero en Few-shot kenniszoekende draaidetectie in taakgerichte dialoogsystemen', 'da': 'På vej mod nul og få skud videnssøgende svingedetektion i opgaveorienterede dialogsystemer', 'hr': 'Do nule i manje snimke otkrivanja znanja u sustavima dijaloga orientiranih na zadatke', 'id': 'Menuju Zero dan Few-shot Knowledge-Looking Turn Detection in Task-oriented Dialogue Systems', 'de': 'Auf dem Weg zur Null- und Wenig-Schuss-wissensbasierten Wendeerkennung in aufgabenorientierten Dialogsystemen', 'ko': '임무를 위한 대화 시스템에서 0회와 소회 지식의 전향 탐지', 'fa': 'به سمت صفر و کم تصویر شناسایی پیدا کردن گردش در سیستم\u200cهای محاورۀ مشارکت به کار', 'sw': 'Upande wa Siro na Ujuzi wenye picha wachache wanaotafuta Kugundua Kuzungumza katika Mfumo wa Tamko', 'af': 'Gaan na Zero en min- shot kennis- soek Skakel Opdekking in Opdrag- orienteerde dialoog stelsels', 'tr': 'Görev Görniş Derjesinde Zero we Kiçi Görniş Bilgi Aramalaryna Ýery Aňlamak', 'am': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems', 'az': 'Sıfır-sıfır Bilim-İstifadəçi Dönüş Görüntü Dialoog Sistemlərindəki Sənə tərəf', 'sq': 'Për Zero dhe Pak Gjithçka që kërkon njohuri Kthehu Detektimi në Sistemet e Dialogut të Orientuar në Detyra', 'bn': 'কাজের দিক দিয়ে ডায়ালগ সিস্টেমে প্রত্যাখ্যানের তথ্য অনুসন্ধান', 'hy': 'Որպես զրո և քիչ գիտելիքներ փնտրող դարձնել հայտնաբերությունը գործի ուղղությամբ ուղղությամբ գտնվող դասախոսության համակարգերում', 'et': 'Teadmistepõhise pöörete tuvastamise suunas ülesannetele orienteeritud dialoogisüsteemides', 'bs': 'Do nule i manje snimke otkrivanja znanja u sistemima dijaloga orijentiranih na zadatke', 'ca': 'En direcció a la detecció de girs de cero i poces fotografies en sistemes de diàleg orientats a les tasques', 'cs': 'Směrem k nulové a malé detekci zatáček hledající znalosti v dialogových systémech orientovaných na úkoly', 'fi': 'Kohti nolla- ja harvinainen tiedonhakuinen kĂ¤Ă¤nteentunnistus tehtĂ¤vĂ¤lĂ¤htĂ¶isissĂ¤ vuoropuhelujĂ¤rjestelmissĂ¤', 'jv': 'ProgressBarUpdates', 'ha': '@ action', 'sk': 'Zaznavanje obratov, ki išče znanje, v sistemih dialoga, usmerjenih v naloge', 'bo': 'ས Zero་དང་བརྙན་རིས་ཆ་ལྷན་རྩོམ་པ་ལ་བཅས་ནུས་བྱ་འགུལ་ལྡོག་སྒྲོམ་གླེང་སྒྲོམ་ནང་ལ་ཕྱིར་བཤེར་བ', 'he': 'Towards Zero and Few-shot Knowledge-seeking Turn Detection in Task-orientated Dialogue Systems'}
{'en': 'Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs. However, users may have requests that are out of the scope of these ', 'fr': "La plupart des travaux antérieurs sur les systèmes de dialogue orientés tâches se limitent à la prise en charge des API de domaine. Toutefois, les utilisateurs peuvent avoir des requêtes qui sortent du cadre de ces API. Ce travail se concentre sur l'identification de telles demandes des utilisateurs. Les méthodes existantes pour cette tâche reposent principalement sur le réglage fin de modèles pré-entraînés sur de grandes données annotées. Nous proposons une nouvelle méthode, REDE, basée sur l'apprentissage adaptatif des représentations et l'estimation de la densité. Le REDE peut être appliqué à des cas de tir zéro et apprend rapidement un détecteur hautes performances avec seulement quelques prises de vue en mettant à jour des paramètres inférieurs à 3K. Nous démontrons les performances concurrentielles de REDE sur les données DSTC9 et sur notre ensemble de tests nouvellement collecté.", 'ar': 'يقتصر معظم العمل المسبق على أنظمة الحوار الموجه نحو المهام على دعم واجهات برمجة تطبيقات المجال. ومع ذلك ، قد يكون لدى المستخدمين طلبات خارج نطاق واجهات برمجة التطبيقات هذه. يركز هذا العمل على تحديد طلبات المستخدم هذه. تعتمد الأساليب الحالية لهذه المهمة بشكل أساسي على ضبط النماذج المدربة مسبقًا على بيانات مشروحة كبيرة. نقترح طريقة جديدة ، REDE ، تعتمد على التعلم بالتمثيل التكيفي وتقدير الكثافة. يمكن تطبيق REDE على حالات إطلاق النار الصفري ، وسرعان ما يتعلم كاشفًا عالي الأداء ببضع لقطات فقط عن طريق تحديث معلمات أقل من 3K. نعرض الأداء التنافسي لـ REDE على بيانات DSTC9 ومجموعة الاختبار التي تم جمعها حديثًا.', 'pt': 'A maioria dos trabalhos anteriores em sistemas de diálogo orientados a tarefas se restringe ao suporte a APIs de domínio. No entanto, os usuários podem ter solicitações que estão fora do escopo dessas APIs. Este trabalho se concentra em identificar tais solicitações de usuários. Os métodos existentes para esta tarefa dependem principalmente do ajuste fino de modelos pré-treinados em grandes dados anotados. Propomos um novo método, REDE, baseado em aprendizagem de representação adaptativa e estimativa de densidade. O REDE pode ser aplicado a casos de disparo zero e aprende rapidamente um detector de alto desempenho com apenas alguns disparos, atualizando parâmetros de menos de 3K. Demonstramos o desempenho competitivo da REDE em dados DSTC9 e nosso conjunto de testes recém-coletado.', 'es': 'La mayoría de los trabajos anteriores sobre sistemas de diálogo orientados a tareas se limitan a admitir API de dominio. Sin embargo, es posible que los usuarios tengan solicitudes que estén fuera del alcance de estas API. Este trabajo se centra en identificar dichas solicitudes de los usuarios. Los métodos existentes para esta tarea se basan principalmente en el ajuste fino de modelos previamente entrenados en datos anotados de gran tamaño. Proponemos un método novedoso, REDE, basado en el aprendizaje de la representación adaptativa y la estimación de la densidad. REDE se puede aplicar a casos de tiro cero y aprende rápidamente un detector de alto rendimiento con solo unos pocos disparos mediante la actualización de parámetros de menos de 3K. Demostramos el rendimiento competitivo de REDE en los datos de DSTC9 y en nuestro conjunto de pruebas recién recopilado.', 'ja': 'タスク指向のダイアログシステムに関する以前の作業のほとんどは、ドメインAPIのサポートに限定されています。ただし、ユーザーは、これらのAPIの範囲外の要求を持っている場合があります。この作業は、そのようなユーザーの要求を特定することに焦点を当てています。このタスクの既存の方法は、主に大規模な注釈付きデータ上で事前にトレーニングされたモデルを微調整することに依存しています。適応表現学習と密度推定に基づいた新たな方法、REDEを提案します。REDEはゼロショットのケースに適用でき、3 K未満のパラメータを更新することで、わずか数ショットで高性能の検出器をすばやく学習できます。私たちは、DSTC 9データと新しく収集されたテストセットでREDEの競争力のあるパフォーマンスを実証します。', 'zh': '前多方面之事,止于领域API。 然用户或有出此 API 之请。 其重识此用户请。 此见法主于大注数预练模形之微调。 吾言学密度估计之REDE新也。 REDE可施于零射,新少于3K参数,数射而疾学高性能探测器。 展REDE于DSTC9数,与新集上之争也。', 'ru': 'Большая часть предыдущей работы над диалоговыми системами, ориентированными на задачи, ограничивается поддержкой доменных API. Однако у пользователей могут быть запросы, которые выходят за рамки этих API. Эта работа сосредоточена на выявлении таких запросов пользователей. Существующие методы для этой задачи в основном опираются на тонкую настройку предварительно обученных моделей на основе больших аннотированных данных. Мы предлагаем новый метод, REDE, основанный на адаптивном репрезентативном обучении и оценке плотности. REDE можно применить к случаям нулевого выстрела, и быстро узнает высокопроизводительный детектор только с несколькими выстрелами путем обновления менее чем 3K параметров. Мы демонстрируем конкурентоспособность REDE по данным DSTC9 и нашему вновь собранному тестовому набору.', 'hi': 'कार्य-उन्मुख संवाद प्रणालियों पर अधिकांश पूर्व कार्य डोमेन एपीआई का समर्थन करने के लिए प्रतिबंधित है। हालाँकि, उपयोगकर्ताओं के पास अनुरोध हो सकता है जो इन APIs के दायरे से बाहर हैं। यह कार्य ऐसे उपयोगकर्ता अनुरोधों की पहचान करने पर केंद्रित है। इस कार्य के लिए मौजूदा तरीके मुख्य रूप से बड़े एनोटेट किए गए डेटा पर पूर्व-प्रशिक्षित मॉडल को ठीक-ट्यूनिंग पर निर्भर करते हैं। हम अनुकूली प्रतिनिधित्व सीखने और घनत्व अनुमान के आधार पर एक उपन्यास विधि, REDE का प्रस्ताव करते हैं। REDE को शून्य-शॉट मामलों पर लागू किया जा सकता है, और जल्दी से 3K से कम पैरामीटर अपडेट करके केवल कुछ शॉट्स के साथ एक उच्च प्रदर्शन डिटेक्टर सीखता है। हम DSTC9 डेटा और हमारे नए एकत्र किए गए परीक्षण सेट पर REDE के प्रतिस्पर्धी प्रदर्शन का प्रदर्शन करते हैं।', 'ga': "Tá formhór na réamhoibre ar chórais dialóige atá dírithe ar thascanna teoranta do thacú le APIanna fearainn. Mar sin féin, d'fhéadfadh iarratais a bheith ag úsáideoirí nach bhfuil faoi raon feidhme na n-APIanna seo. Díríonn an obair seo ar iarratais úsáideoirí den sórt sin a aithint. Braitheann na modhanna atá ann cheana don tasc seo go príomha ar mhionchoigeartú samhlacha réamh-oilte ar shonraí móra anótáilte. Molaimid modh nua, REDE, bunaithe ar fhoghlaim ionadaíochta oiriúnaitheach agus meastachán dlúis. Is féidir REDE a chur i bhfeidhm ar chásanna lámhaigh nialasach, agus foghlaimíonn sé go tapa brathadóir ardfheidhmíochta gan ach cúpla shots trí pharaiméadair níos lú ná 3K a nuashonrú. Léirímid feidhmíocht iomaíoch REDE ar shonraí DSTC9 agus ar ár dtacar tástála nua-bhailithe.", 'ka': 'უფრო მხოლოდ საწინაღალდე სამუშაო დიალოგის სისტემებზე დასაჭირება დილომენის API-ს. მაგრამ, მომხმარებელი შეიძლება აქვს მოთხოვრება, რომელიც ამ API-ს არსებობით არსებობს. ეს სამუშაო მომხმარებლის მოთხოვრების განსაზღვრებისთვის დააყენება. ამ დავალებისთვის არსებობენი მეტირები უფრო მხოლოდ დარწმუნდება წინასწორებული მოდელზე დიდი ანოტაციული მონაცემებზე. ჩვენ პრომენტის მეტი, REDE, ადაპტიგური რესპეცენტაციის სწავლების და მცირეობის განსაზღვრების დაბაზეულებაში დავიწყებთ. REDE შეიძლება ჩატვირთოთ ნულ სტატის შემთხვევაში, და ძალიან გავისწავლის მარტივი გამოყენებული detektoრის მხოლოდ რამდენიმე სტატის შესაძლებელად 3K პარამეტრების ახალ ჩვენ ევმონსტრაცით REDE-ს კონპექტიური გამოყენება DSTC9 მონაცემებზე და ჩვენი ახალი კონკექტიური ტესტის ნაწილი.', 'it': "La maggior parte dei lavori precedenti sui sistemi di dialogo orientati alle attività è limitata al supporto delle API di dominio. Tuttavia, gli utenti potrebbero avere richieste che non rientrano nell'ambito di queste API. Questo lavoro si concentra sull'identificazione di tali richieste degli utenti. I metodi esistenti per questo compito si basano principalmente sulla messa a punto di modelli pre-addestrati su dati annotati di grandi dimensioni. Proponiamo un nuovo metodo, REDE, basato sull'apprendimento adattivo della rappresentazione e sulla stima della densità. REDE può essere applicato ai casi zero-shot e impara rapidamente un rilevatore ad alte prestazioni con solo pochi scatti aggiornando meno di 3K parametri. Dimostriamo le prestazioni competitive di REDE sui dati DSTC9 e sul nostro set di test appena raccolto.", 'el': 'Οι περισσότερες προηγούμενες εργασίες σχετικά με συστήματα διαλόγου προσανατολισμένα στις εργασίες περιορίζονται στην υποστήριξη των API τομέα. Ωστόσο, οι χρήστες ενδέχεται να έχουν αιτήματα που δεν εμπίπτουν στο πεδίο εφαρμογής αυτών των API. Η εργασία αυτή επικεντρώνεται στον εντοπισμό τέτοιων αιτημάτων χρηστών. Οι υπάρχουσες μέθοδοι για αυτό το έργο βασίζονται κυρίως στην τελειοποίηση προ-εκπαιδευμένων μοντέλων σε μεγάλα σχολιασμένα δεδομένα. Προτείνουμε μια νέα μέθοδο, βασισμένη στην εκμάθηση προσαρμοστικής αναπαράστασης και εκτίμηση πυκνότητας. Μπορεί να εφαρμοστεί σε περιπτώσεις μηδενικού πυροβολισμού και μαθαίνει γρήγορα έναν ανιχνευτή υψηλής απόδοσης με λίγες μόνο βολές ενημερώνοντας τις παραμέτρους λιγότερο από 3Κ. Επιδεικνύουμε την ανταγωνιστική απόδοση της στα δεδομένα και το νέο σετ δοκιμών μας.', 'hu': 'A feladatorientált párbeszédrendszerekkel végzett korábbi munka a tartományi API-k támogatására korlátozódik. A felhasználóknak azonban lehetnek olyan kérései, amelyek nem tartoznak ezen API-k hatályába. Ez a munka az ilyen felhasználói kérések azonosítására összpontosít. Ennek a feladatnak a meglévő módszerei elsősorban az előre képzett modellek finomhangolására támaszkodnak nagy jegyzetelt adatokon. Javasoljuk az adaptív reprezentációs tanuláson és a sűrűségbecslésen alapuló új módszert, a REDE-t. A REDE alkalmazható a nulla lövéses esetekre, és gyorsan megtanulja a nagy teljesítményű detektort csak néhány lövéssel, kevesebb mint 3K paraméter frissítésével. A REDE versenyképes teljesítményét a DSTC9 adatokon és az újonnan összegyűjtött tesztkészleten mutatjuk be.', 'mk': 'Повеќето претходни работи на системите за дијалог ориентирани на задачите се ограничени на поддршка на API на домените. However, users may have requests that are out of the scope of these APIs.  Оваа работа се фокусира на идентификацијата на ваквите барања за корисници. Existing methods for this task mainly rely on fine-tuning pre-trained models on large annotated data.  Предложуваме нов метод, РЕДЕ, базиран на адаптивната претстава на учењето и проценката на густината. REDE може да се примени на случаи со нула снимка, и брзо научи високо-функционален детектор со само неколку снимки со ажурирање помалку од 3K параметри. Ги демонстрираме конкурентните резултати на РЕДЕ на податоците од ДСТЦ9 и нашиот нов собран тест сет.', 'lt': "Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs.  Tačiau naudotojai gali turėti prašymus, kurie nepatenka į šių API taikymo sritį. This work focuses on identifying such user requests.  Esami šios užduoties metodai daugiausia grindžiami iš anksto parengtų modelių tobulinimu, remiantis dideliais anotuotais duomenimis. We propose a novel method, REDE, based on adaptive representation learning and density estimation.  REDE gali būti naudojamas nulinio nuotraukos atvejams ir greitai mokomas aukšto veikimo detektorius su tik keletu nuotraukų atnaujinant mažiau kaip 3K parametrus. We demonstrate REDE's competitive performance on DSTC9 data and our newly collected test set.", 'ms': "Kebanyakan kerja terdahulu pada sistem dialog oriented tugas diharamkan untuk menyokong API domain. Namun, pengguna mungkin mempunyai permintaan yang diluar skop API ini. Kerja ini fokus pada mengenalpasti permintaan pengguna tersebut. Kaedah yang wujud untuk tugas ini bergantung pada penyesuaian model pra-dilatih pada data yang dicatat besar. Kami cadangkan kaedah baru, REDE, berdasarkan penerapan adaptif belajar dan penilaian ketepatan. REDE boleh dilaksanakan pada kes-tembakan sifar, dan dengan cepat belajar pengesan berkesan tinggi dengan hanya beberapa tembakan dengan kemaskini parameter kurang dari 3K. We demonstrate REDE's competitive performance on DSTC9 data and our newly collected test set.", 'kk': 'Тапсырма бағытталған диалог жүйелеріндегі алдыңғы жұмыс доменнің APIларын қолдауға шектелген. Бірақ пайдаланушылардың бұл API масштабынан тыс сұраулары болуы мүмкін. Бұл жұмыс пайдаланушының сұрауларын анықтау үшін көздеген. Бұл тапсырманың барлық әдістері үлкен мәліметтерге арналған үлкен мәліметтерді баптау үлгілеріне тұрады. Біз жаңа әдіс, REDE, адаптикалық түсініктерді оқыту мен тұтықтығын бағалау негізінде негізделген. REDE нөл- сүрту әрекеттеріне қолданылады, және 3K параметрлерінен аз жаңарту арқылы тек бірнеше сүрту арқылы жоғары деген анықтаушысын оқылады. Біз REDE-ның DSTC9 деректерінде және жаңа жинақталған сынақтар жинақтарын көрсетедік.', 'mt': "Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs.  However, users may have requests that are out of the scope of these APIs.  This work focuses on identifying such user requests.  Il-metodi eżistenti għal dan il-kompitu jiddependu prinċipalment fuq l-irfinar ta’ mudelli mħarrġa minn qabel fuq dejta annotata kbira. We propose a novel method, REDE, based on adaptive representation learning and density estimation.  REDE jista’ jiġi applikat għal każijiet b’zero shot, u malajr jitgħallem detettur ta’ prestazzjoni għolja bi ftit shot biss billi jiġu a ġġornati parametri inqas minn 3K. We demonstrate REDE's competitive performance on DSTC9 data and our newly collected test set.", 'pl': 'Większość wcześniejszych prac nad systemami dialogu zorientowanymi na zadania ogranicza się do obsługi interfejsów API domeny. Jednakże użytkownicy mogą mieć żądania, które wykraczają poza zakres tych interfejsów API. Praca ta skupia się na identyfikacji takich żądań użytkowników. Istniejące metody do tego zadania opierają się głównie na dostrajaniu wstępnie przeszkolonych modeli na dużych adnotacjach danych. Proponujemy nowatorską metodę REDE, opartą na adaptacyjnym uczeniu się reprezentacji i szacowaniu gęstości. REDE może być stosowany do przypadków zerowych strzałów i szybko uczy się wydajnego detektora za pomocą zaledwie kilku strzałów, aktualizując parametry mniej niż 3K. Pokazujemy konkurencyjność REDE na danych DSTC9 i naszym nowo zebranym zestawie testów.', 'ro': 'Majoritatea lucrărilor anterioare privind sistemele de dialog orientate spre sarcini se limitează la sprijinirea API-urilor de domeniu. Cu toate acestea, utilizatorii pot avea solicitări care nu intră în domeniul de aplicare al acestor API-uri. Această lucrare se concentrează pe identificarea acestor solicitări ale utilizatorilor. Metodele existente pentru această sarcină se bazează în principal pe reglarea fină a modelelor pre-instruite pe date adnotate mari. Propunem o metodă nouă, REDE, bazată pe învățarea adaptivă a reprezentării și estimarea densității. REDE poate fi aplicat în cazurile zero-shot și învață rapid un detector de înaltă performanță cu doar câteva fotografii, actualizând mai puțin de 3K parametri. Demonstrăm performanța competitivă a REDE pe datele DSTC9 și setul nostru de testare recent colectat.', 'mn': 'Ажлын ориентиролт диалог системийн хамгийн өмнөх ажил домены API-г дэмжих хязгаарлагддаг. Гэхдээ хэрэглэгчид эдгээр API-ийн талаар байхгүй хүсэл байж болно. Энэ ажил хэрэглэгчийн хүсэлтэй олж мэдэхэд анхаарна. Энэ ажлын суурь арга барилгыг ихэвчлэн том анзаарсан өгөгдлийн дээр суурь сургалтын өмнө сургалтын загваруудыг тодорхойлдог. Бид шинэ арга зам, REDE, загварчлалын суралцах, жинтэй тооцоолох сургалтын үнэ цэнэтэй санал болгож байна. REDE-г 0-р шалгалтын тухай хэрэглэж болох бөгөөд 3K-аас бага параметр шинэчлэхээр хурдан өндөр ажиллагааны detektoрыг хэдэн удаа суралцаж болно. Бид REDE-ийн өрсөлдөөний үйл ажиллагааг DSTC9 өгөгдлийн талаар, шинэ цуглуулсан шалгалтын багц дээр үзүүлдэг.', 'sr': 'Najraniji rad na sistemima dijaloga orijentiranih na zadatke je ograničen na podršku domena API. Međutim, korisnici mogu imati zahteve koje nisu izvan oblasti ovih API-a. Ovaj rad se fokusira na identifikaciju takvih zahteva korisnika. Postoje metode za ovaj zadatak oslanjaju se uglavnom na predobučene modele na velike annotirane podatke. Predlažemo novu metodu, REDE, na osnovu adaptivnog učenja predstavljanja i procjene gustine. REDE se može primjenjivati na slučajeve nule pucnjave, i brzo nauči detektora visokog izvođa ča sa samo nekoliko pucnjava ažuriranjem manje od 3K parametara. Pokazujemo REDE-ovu konkurentnu izvedbu o podacima DSTC9 i našem novom skupljenom testu setu.', 'so': 'Inta badan shaqo horay ah oo ku qoran nidaamka diyaarinta shaqada waxaa laga xadeyn karaa in lagu kaalmeeyo APIs. Si kastaba ha ahaatee isticmaalayaashu waxay heli karaan codsiyooyin ay ka soo baxeen waqtigan API. Shaqodaas wuxuu ku kalsoonaadaa aqoonsiga codsiga isticmaalka. Waddooyinka joogtada ah ee shaqadaas waxay ku xiran yihiin noocyo wanaagsan oo horay loo tababaray, waxayna ku xiran yihiin macluumaad aad u baahan. Waxaynu soo jeedaynaa qaab saxda ah ee REDE, taasoo ku saleysan kara barbaarinta adag iyo qiimeynta qiimeynta uurka. REDE waxaa lagu codsan karaa xaaladaha nooca ah, dhaqso ahaanna waxaa la baran karaa dhaqso dhaqso dhaqso oo uu ku baranayo dhaqdhaqaaq wax ka yar oo ganacsi ah oo kaliya si ay u kordhiso heerarka 3K ka yar. Waxaynu muujinnaa sameynta tartanka ee REDE ee ku saabsan data DSTC9 iyo kooxda imtixaanka cusub ee la soo ururiyey.', 'no': 'Første arbeid på oppgåveorienterte dialogsystemer er begrenset til å støtta domeneAPIr. Brukarar kan likevel ha førespurnader som ikkje er i området for desse APIne. Denne arbeidet fokuserer på å identifisera slike brukarførespurnader. Det eksisterande metodane for denne oppgåva er hovudsakelig avhengig av finnstillingsføretrainingsformat modeller på stor notatet. Vi foreslår eit nytt metode, REDE, basert på adaptivt læring av representasjon og estimating av tetthet. REDE kan brukast til nullsatt tilfeller, og raskt lærer ein høg utføringsflate detektor med berre nokre strekar ved å oppdatera mindre enn 3K-parametrar. Vi demonstrerer REDE sin konkurentiv utvikling på DSTC9-data og vår nytt samla testsett.', 'ml': 'ഡൊമെയിന്\u200d എപ്പിഐസിനെ പിന്തുണക്കുന്നതിനായി ജോലി ചെയ്യുന്നതില്\u200d ഏറ്റവും മുമ്പുള്ള പണിയാണ്. എന്നാലും ഈ എപിഐസിന്റെ സ്കോപ്പില്\u200d നിന്നും പുറത്തുള്ള ഉപയോക്താക്കള്\u200dക്ക് ആവശ്യങ്ങള്\u200d ലഭ്യമാകും. ഈ ജോലി ഈ ഉപയോക്താവിന്റെ ആവശ്യങ്ങള്\u200d തിരിച്ചറിയുന്നതിനായി ശ്രദ്ധിക്കുന്നു. ഈ ജോലിയ്ക്കുള്ള നിലവിലുള്ള രീതികള്\u200d പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലു നമ്മള്\u200d ഒരു നോവല്\u200d രീതിയിലാണ് പ്രൊദ്ദേശിപ്പിക്കുന്നത്, പ്രതിനിധിയിലുള്ള പ്രതിനിധികള്\u200d പഠിക്കുന്നതിനും  REDE പൂജ്യത്തിലേക്ക് പ്രയോഗിക്കാന്\u200d സാധിക്കുന്നു. വേഗം ഒരു ഉയര്\u200dത്തിപ്പെടുന്ന ഡിക്ടറിനെ പഠിപ്പിക്കുന്നു. മുപ്പത്തില ഡിസ്റ്റിസി9 ഡേറ്റായില്\u200d നമ്മുടെ പുതിയ ടെസ്റ്റ് സെറ്റ് സെറ്റ് സെറ്റ് ചെയ്ത റെഡിയുടെ മത്സരത്തില്\u200d പ്', 'si': 'වැඩක් ප්\u200dරධාන සංවාදය පද්ධතියේ හුඟක් ප්\u200dරධාන වැඩක් සීමාවිත වෙනවා ඩොමේන් APIs සහයෝගයකට. නමුත්, ප්\u200dරයෝජකයන්ට පුළුවන් මේ API ගැන අවශ්\u200dය නැති අවශ්\u200dය වෙන්න පුළුවන්. මේ වැඩේ ප්\u200dරයෝජකයේ අවශ්\u200dය අවශ්\u200dය අවශ්\u200dය විදිහට අවධානය කරනවා. මේ වැඩසටහන් විසින් තියෙන විදියට ප්\u200dරධාන විදියට ප්\u200dරධාන විදියට ප්\u200dරධාන විදියට ප්\u200dරධාන විදියට ප්\u200d අපි නියම විධානයක් ප්\u200dරයෝජනය කරනවා, REDE, සාමාන්\u200dය ප්\u200dරයෝජනයක් ඉගෙන ගන්න සහ ගුරුත්වත්වයක් අගමාණ REDE පුළුවන් ශූන්ය විදිහට ප්\u200dරයෝජනය කරන්න, ඒ වගේම ඉක්මනින් උඩ ප්\u200dරයෝජනයක් පරීක්ෂකයෙක් ඉගෙන ගන්නවා 3K ප්\u200dරමාණය අපි පෙන්වන්නම් REDE ගේ පරීක්ෂණ ප්\u200dරශ්නයක් DSTC9 දත්ත සහ අපේ අළුත් පරීක්ෂණ සෙට් එක්ක.', 'sv': 'Det mesta tidigare arbetet med uppgiftsorienterade dialogsystem begränsas till stöd för domänAPI:er. Användarna kan dock ha förfrågningar som inte omfattas av dessa API:er. Detta arbete fokuserar på att identifiera sådana användarförfrågningar. Befintliga metoder för denna uppgift förlitar sig huvudsakligen på finjustering av färdigutbildade modeller på stora kommenterade data. Vi föreslår en ny metod, REDE, baserad på adaptiv representationsinlärning och densitetsuppskattning. REDE kan appliceras på nollskott fall och lär sig snabbt en högpresterande detektor med bara ett fåtal skott genom att uppdatera mindre än 3K parametrar. Vi visar REDE:s konkurrenskraftiga prestanda på DSTC9-data och vårt nyligen insamlade testset.', 'ta': 'Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs.  However, users may have requests that are out of this API scope. This work focuses on identifying such user requests. இந்த செயலுக்கான நடப்பு முறைமையாக முன்பயிற்சி முறைமைகளை பெரிய குறிப்பிட்ட தரவில் சார்ந்து கொள்ளும். நாம் ஒரு புதிய முறைமையை தேர்வு செய்கிறோம், பொருத்தமான பிரதிநிதிப்பு கல்வி மற்றும் தூக்கத்தின் மதிப்பி REDE பூஜ்ஜியத்திற்கு பயன்படுத்தலாம் மற்றும் விரைவில் 3K அளபுருக்களை புதுப்பிக்க முடியும் மூல சில செயல்படுத்தும் திட்டத்த நாங்கள் டிஸ்டிசி9 தரவுகள் மற்றும் எங்கள் புதிய தொகுக்கப்பட்ட சோதனை அமைப்பை REDE தேடும் செயல்பாட்டை காட்டுக', 'ur': 'ٹاکس-oriented ڈیلوگ سیسٹم پر بہت سے پہلے کام محدود ہے ڈومین APIs کی مدد کرنے کے لئے. اگرچہ، کارساز ان API کے اندازے سے بیٹھے ہوئے خواہشات مل سکتے ہیں. یہ کام ایسی کارساز کی خواہشوں کی شناسایی پر منتظر ہے۔ اس کام کے لئے موجود طریقے ہیں جو سب سے زیادہ بہت اظہار کئے ہوئے ڈیٹے پر بہت اظہار کئے جاتے ہیں۔ ہم ایک نئی طریقہ کی پیشنهاد کرتے ہیں، REDE، اڈپٹیٹ کی تعلیم اور گہری قدر پر بنیاد رکھتے ہیں. REDE صفر-شٹ کیسس پر لازم کر سکتا ہے، اور سریع ایک اچھی فعالیت ڈاکٹر سکھاتا ہے جو صرف تھوڑے شٹ کے ساتھ 3K پارامتر سے کم آدٹر کر رہا ہے. ہم ڈیس سیسی ۹ ڈیٹے اور ہمارے نئی جمع کئے تست سٹ پر REDE کا مسابقه کاربرد دکھاتے ہیں.', 'uz': "Name Lekin foydalanuvchilar bu API' ning scopedagi soʻrovlar boʻlishi mumkin. Bu ishni bu foydalanuvchi soʻrovlarini aniqlash uchun foydalanadi. @ info: whatsthis Biz o'rganish o'rganish va cheksiz qiymatning asosida bog'liq usuli REDE dasturini tahrirlash. REDE can be applied to zero-shot cases, and quickly learns a high-performing detector with only a few shots by updating less than 3K parameters.  Biz DSTC9 maʼlumotlarida REDE'ning rivojlanish imkoniyatini ko'rsatdik va yangi тўпланган sinov sohasini ko'rsatdik.", 'vi': 'Phần lớn công việc trước về hệ thống đối thoại hướng nhiệm vụ là hỗ trợ các API miền. Tuy nhiên, người dùng có thể có yêu cầu nằm ngoài phạm vi của các API. Việc này tập trung vào việc xác định yêu cầu người dùng. Phương pháp tồn tại cho nhiệm vụ này chủ yếu dựa trên các mô hình đã được sửa chữa cẩn thận. Chúng tôi đề xuất một phương pháp mới, REE, dựa trên học cách đại diện thích nghi và quy định mật độ. REE có thể được áp dụng vào trường hợp bắn không, và nhanh chóng học một máy phát hiện có siêu năng lượng chỉ với vài phát bắn bằng cách cập nhật ít hơn các tham số 3K. Chúng tôi chứng minh năng lực cạnh tranh của REE trên dữ liệu DSTC9 và bộ thử mới được thu thập.', 'da': "Det meste tidligere arbejde med opgaveorienterede dialogsystemer er begrænset til at understøtte domæne API'er. Brugere kan dog have anmodninger, der ikke falder ind under disse API'er. Dette arbejde fokuserer på at identificere sådanne brugeranmodninger. Eksisterende metoder til denne opgave er hovedsagelig afhængige af finjusterende prætrænede modeller på store annoterede data. Vi foreslår en ny metode, REDE, baseret på adaptiv repræsentationslæring og densitetsestimering. REDE kan anvendes på nulskud sager, og lærer hurtigt en højtydende detektor med kun få skud ved at opdatere mindre end 3K parametre. Vi demonstrerer REDE's konkurrencedygtige præstationer på DSTC9 data og vores nyligt indsamlede testsæt.", 'nl': "De meeste eerdere werkzaamheden aan taakgerichte dialoogsystemen zijn beperkt tot het ondersteunen van domein API's. Gebruikers kunnen echter verzoeken hebben die buiten het bereik van deze API's vallen. Dit werk richt zich op het identificeren van dergelijke gebruikersverzoeken. Bestaande methoden voor deze taak zijn voornamelijk afhankelijk van het finetunen van vooraf getrainde modellen op grote geannoteerde gegevens. We stellen een nieuwe methode voor, REDE, gebaseerd op adaptieve representatie leren en dichtheidsschatting. REDE kan worden toegepast op zero-shot gevallen en leert snel een krachtige detector met slechts een paar schoten door minder dan 3K parameters bij te werken. We demonstreren de competitieve prestaties van REDE op DSTC9 data en onze nieuw verzamelde testset.", 'hr': 'Većina prethodnog rada na sustavima dijaloga na cilju zadataka ograničena je na podršku domena API-a. Međutim, korisnici mogu imati zahtjeve koje nisu izvan opsega ovih API-a. Ovaj rad se fokusira na identifikaciju takvih zahtjeva korisnika. Postoje metode za ovaj zadatak oslanjaju se uglavnom na predobučene modele na velike annotirane podatke. Predlažemo novu metodu, REDE, na temelju adaptivnog učenja predstavljanja i procjene gustine. REDE se može primjenjivati na slučajeve nule pucnjave, a brzo uči visokog detektora s samo nekoliko pucnjava a žuriranjem manje od 3K parametara. Mi pokazujemo REDE-ov konkurentni nastup na podacima DSTC9 i našem novom skupljenom testu.', 'de': 'Die meisten bisherigen Arbeiten an aufgabenorientierten Dialogsystemen beschränken sich auf die Unterstützung von Domain-APIs. Benutzer können jedoch Anforderungen haben, die nicht in den Anwendungsbereich dieser APIs fallen. Diese Arbeit konzentriert sich auf die Identifizierung solcher Nutzeranfragen. Bestehende Methoden für diese Aufgabe basieren hauptsächlich auf der Feinabstimmung vortrainierter Modelle auf großen annotierten Daten. Wir schlagen eine neue Methode vor, REDE, basierend auf adaptivem Repräsentationslernen und Dichteschätzung. REDE kann auf Null-Schuss-Fälle angewendet werden und lernt schnell einen leistungsstarken Detektor mit nur wenigen Schüssen, indem weniger als 3K-Parameter aktualisiert werden. Wir demonstrieren die Wettbewerbsleistung von REDE mit DSTC9-Daten und unserem neu gesammelten Testset.', 'bg': 'Повечето предишни работи по задачи ориентирани диалогови системи са ограничени до поддръжка на домейн APIs. Потребителите обаче могат да имат заявки, които са извън обхвата на тези API. Тази работа се фокусира върху идентифицирането на такива потребителски заявки. Съществуващите методи за тази задача разчитат главно на фино настройване на предварително обучени модели на големи анотирани данни. Предлагаме нов метод, базиран на адаптивно представяне и оценка на плътността. Може да се приложи към случаи с нулев изстрел и бързо научава високоефективен детектор само с няколко изстрела чрез актуализиране на по-малко от 3К параметри. Ние демонстрираме конкурентното представяне на данните и новосъбрания набор от тестове.', 'id': 'Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs.  Namun, pengguna mungkin memiliki permintaan yang keluar dari jangkauan API ini. Pekerjaan ini fokus pada mengidentifikasi permintaan pengguna tersebut. Metode yang ada untuk tugas ini terutama bergantung pada fine-tuning pre-trained model pada data annotasi besar. Kami mengusulkan metode baru, REDE, berdasarkan persembahan adaptif belajar dan penilaian ketepatan. REDE dapat diaplikasikan pada kasus zero-shot, dan dengan cepat belajar detektor prestasi tinggi dengan hanya beberapa tembakan dengan memperbaharui kurang dari 3K parameter. Kami menunjukkan prestasi kompetitif REDE pada data DSTC9 dan set tes yang baru kami kumpulkan.', 'ko': '이전에 작업용 대화 시스템에 대한 대부분의 작업은 지원 분야인 API로 제한되었습니다.그러나 이러한 API 범위를 벗어나는 요청이 있을 수 있습니다.이 작업의 중점은 이런 사용자의 요구를 식별하는 것이다.기존의 이 임무의 방법은 주로 대량의 주석 데이터를 가진 예비 훈련 모델을 미세하게 조정하는 데 의존한다.우리는 적응성 표시를 바탕으로 학습과 밀도를 평가하는 새로운 방법인 REDE를 제시했다.REDE는 포제로(0) 상황에 적용할 수 있으며, 3K 미만의 매개변수를 업데이트함으로써 포제 몇 개만으로도 고성능 탐지기를 빠르게 학습할 수 있다.DSTC9 데이터와 새로 수집한 테스트 세트에서 REDE의 경쟁 성능을 보여줍니다.', 'fa': 'بیشتر کارهای پیشینه روی سیستم\u200cهای محاورۀ مشاورۀ کار محدود به پشتیبانی API دامنی است. با این حال، کاربران ممکن است درخواست\u200cهایی داشته باشند که از فضای این آبی\u200cها خارج نیستند. این کار روی شناسایی چنین خواسته\u200cهای کاربر تمرکز می\u200cکند. روش\u200cهای موجود برای این کار در اصل بر مدل\u200cهای پیش آموزش\u200cشده\u200cای که بر داده\u200cهای بزرگ نوشته شده\u200cاند استفاده می\u200cکنند. ما روش نویی را پیشنهاد می\u200cکنیم، REDE، بر اساس تعلیم آموزش و ارزیابی گوناگونی متفاوت. REDE می\u200cتواند به پرونده\u200cهای صفر شلیک کاربرد شود، و سریع یک بازرس کاربرد بالا را با فقط چند شلیک می\u200cیابد با توجه به پارامترهای کمتر از ۳ کیلومتر آغاز می\u200cکند. ما اجرای رقابتی REDE را در اطلاعات DSTC9 و مجموعه آزمایش جدید جمع شده\u200cایم نشان می\u200cدهیم.', 'af': "Mees voorheede werk op taak-orienteerde dialoog stelsels is beperk na ondersteun domein APIs. Maar, gebruikers dalk mag het versoeke wat uit die omvang van hierdie APIs is. Hierdie werk fokus op die identifiseer van sodanige gebruiker versoeke. Bestaande metodes vir hierdie taak vertrou hoofsaaklik op fyn- tuning voor- opgelei modele op groot notateerde data. Ons voorstel 'n nuwe metode, REDE, gebaseer op adaptief voorstelling leer en densiteit-estimatie. REDE kan aanwend word na nul- skoot gevalle, en vinnig leer 'n hoë- uitvoerde detektor met slegs' n paar skote deur minder as 3K parameters opdateer te word. Ons wys REDE se rekenaar uitvoering op DSTC9 data en on s nuwe versamel toets stel.", 'sw': 'Kazi nyingi za kabla katika mfumo wa mazungumzo yenye malengo ya kazi imezuiwa kuunga mkono API. Hata hivyo, watumiaji wanaweza kuwa na maombi yanayotokana na maeneo haya ya API. Kazi hii inalenga kutambua maombi ya watumiaji kama haya. Existing methods for this task mainly rely on fine-tuning pre-trained models on large annotated data.  Tunazipendekeza njia ya riwaya, REDE, kwa kutumia uwakilishi wenye upendeleo wa kujifunza na uchunguzi wa tete. REDE inaweza kutumika kwa matukio yasiyo na risasi, na kwa haraka inajifunza mtayarishaji wa juu wenye risasi michache tu kwa kupata upya vifaa vya chini ya 3,000. Tunaonyesha utendaji wa REDE wa ushindani katika data za DSTC9 na seti yetu mpya ya majaribio.', 'am': 'የቀድሞው የዶሜን API መደጋገሚያ የሚደረግ ስልጣን ሲስተም የሚደረግ ነው፡፡ ነገር ግን ተጠቃሚዎቹ ከዚህ API ክፍል ውጭ ያሉትን ጥያቄዎች ይኖራሉ፡፡ ይህ ስራ እንደዚህ ያሉ ተጠቃሚ ጥያቄዎችን ለማግኘት ትክክለኛ ነው፡፡ የአሁኑ ሥርዓት ለዚህ ስራ ማድረግ በመጠቀም በጥንታዊ ተማሪዎቹ ሞዴላዎችን በመጠቀም ላይ በመጠቀም ይታመካል፡፡ We propose a novel method, REDE, based on adaptive representation learning and density estimation.  REDE በ0-ነጥብ ጉዳዮች ላይ ሊጠቀም ይችላል፣ ፈጥኖም በ3 ሺሕ አካላንት ማሻሻል የሚያስፈልገውን አዲስ መስኮት ብቻ ይማራል፡፡ የREDE ድምፅ ድምፅ በDSTC9 ዳታ እና አዲስ የተሰበሰቡን የፍተና ጥናት እናሳየዋለን፡፡', 'tr': "Görevleriň görnöşinden öňki işi dialogy sistemlerinde tokaý APIlary desteklemek üçin mümkin edildi. Ýöne, ullançylaryň bu APIň sahypalarynyň bardygyny barlap biler. Bu işe Ullançy islegi tanamak üçin ünsüni berilýär. Bu täblisaň bar yöntemleri gaty täze-täblisaň öňe-täblisaň örän täblisaň modalaryna baglaýar. Biz REDE täze bir yöntem teklip edip, adaptiv temsil öwrenmesine we çykyşlygyna baýram. REDE nul atly ýagdaýa uygulanabilir we çalt ýokaryn detektory üçin 3K parameterlerinden az atyp öwrenip biler. REDE'iň DSTC9 maglumatymyzda ýakynlaşyk taýýarlaşyk barlygyny we täze ýygnan testimizde görkezilýäris.", 'sq': 'Shumica e punës së mëparshme në sistemet e dialogut të orientuar ndaj detyrave është e kufizuar në mbështetjen e API të domenit. Megjithatë, përdoruesit mund të kenë kërkesa që janë jashtë fushës së këtyre API-ve. Ky punë përqëndrohet në identifikimin e kërkesave të tilla të përdoruesve. Metodat ekzistuese për këtë detyrë mbështeten kryesisht në rregullimin e modeleve të paratrajnuar në të dhënat e mëdha të anotuara. Ne propozojmë një metodë të re, REDE, bazuar në përfaqësimin adaptiv të mësimit dhe vlerësimin e densitetit. REDE mund të aplikohet në raste zero-shot, dhe shpejt mëson një detektor me performancë të lartë me vetëm disa fotografi duke përditësuar më pak se 3K parametrat. Ne demonstrojmë performancën konkurruese të REDE në të dhënat DSTC9 dhe grupin tonë të sapo mbledhur.', 'az': "G√∂nd…ôril…ôn m…ôlumat sisteml…ôrind…ô …ôn …ôvv…ôlki iŇül…ôr domena APIl…ôrini d…ôst…ôkl…ôm…ôy…ô qadańüan edilir. Lakin istifad…ô√ßil…ôrin bu APIl…ôrin s…ôviyy…ôsind…ôn uzaq olan ist…ôkl…ôri olar. Bu iŇül…ôr bu istifad…ô√ßinin ist…ôkl…ôrini tanńĪmmańüa odaqlanńĪr. Bu iŇüin h…ôqiqi metodlarńĪ b√∂y√ľk n√∂qt…ôli m…ôlumatlarda g√∂z…ôl t…ôhsil edilmiŇü modell…ôr…ô t…ôv…ôkk√ľl edir. Biz yeni t…ôrzim, REDE, adaptiv t…ôrzim √∂yr…ônm…ôsi v…ô yoxluq hesablamasńĪna dayanan yeni t…ôrzim t…ôklif edirik. REDE sńĪfńĪr-vuruŇü davalarńĪna uygulanabilir, v…ô √ßabuk y√ľks…ôk-performanslńĪ detekt√∂r√ľ 3K parametrl…ôrind…ôn az g√ľncell…ônir…ôk ancaq bir ne√ß…ô vuruŇüla √∂yr…ônir. Biz REDE'nin DSTC9 veril…ônl…ôrin v…ô yeni toplanmńĪŇü s ńĪnama quruluŇüunu g√∂st…ôririk.", 'bn': 'ডোমেইন এপিআইকে সমর্থন করার জন্য ডোমেইন ডায়ালগ সিস্টেমে সবচেয়ে পূর্ববর্তী কাজ নিষিদ্ধ করা হয়েছে। তবে ব্যবহারকারীদের অনুরোধ থাকতে পারে যারা এপিআই এর স্কোপ থেকে বের হয়েছে। এই কাজ এই ধরনের ব্যবহারকারীর অনুরোধ চিহ্নিত করার জন্য মনোযোগ দিয়েছে। এই কাজের জন্য বিদ্যমান পদ্ধতি মূলত প্রশিক্ষিত পূর্ববর্তী মডেলের উপর নির্ভর করে বিশাল পরিচিত তথ্যের উপর। আমরা প্রস্তাব করছি প্রতিনিধিত্বের ভিত্তিতে প্রতিনিধিত্ব শিক্ষা এবং গভীরতা হিসেবে। শূন্য শুটের ক্ষেত্রে REDE প্রয়োগ করতে পারে এবং দ্রুত তাড়াতাড়ি শিখতে পারে একটি উচ্চকর্মী ডিটেক্টর, যার মধ্যে শুধুমাত্র কয়েকটি গুল আমরা ডিস্টিসি৯ তথ্য এবং আমাদের নতুন সংগ্রহ করা পরীক্ষা সেটে রেডির প্রতিযোগিতার প্রদর্শন করি।', 'bs': 'Većina prethodnog rada na sistemima dijaloga na cilju zadataka ograničena je na podršku domena API-a. Međutim, korisnici mogu imati zahtjeve koje nisu izvan oblasti ovih API-a. Ovaj rad se fokusira na identifikaciju takvih zahtjeva korisnika. Postoje metode za ovaj zadatak oslanjaju se uglavnom na predobučene modele na velike annotirane podatke. Predlažemo novu metodu, REDE, baziranu na adaptivnom učenju predstavljanja i procjenu gustine. REDE se može primjenjivati na slučajeve nule pucnjave, a brzo uči detektora visokog izvođa ča sa samo nekoliko pucnjava ažuriranjem manje od 3K parametara. Mi pokazujemo REDE konkurentnu predstavu na podacima DSTC9 i našem novom skupljenom testu.', 'cs': 'Většina předchozích prací na dialogových systémech orientovaných na úlohy je omezena na podporu doménových rozhraní API. Uživatelé však mohou mít požadavky mimo rozsah těchto rozhraní API. Tato práce se zaměřuje na identifikaci takových uživatelských požadavků. Stávající metody pro tento úkol spoléhají především na jemné ladění předškolených modelů na velkých anotovaných datech. Navrhujeme novou metodu REDE založenou na adaptivním učení reprezentace a odhadu hustoty. REDE lze aplikovat na případy nulových výstřelů a rychle se naučí vysoce výkonný detektor pouze s několika záběry aktualizací méně než 3K parametrů. Ukážeme konkurenční výkon společnosti REDE na datech DSTC9 a našem nově získaném testovacím sadě.', 'ca': "La majoria dels treballs anteriors en sistemes de diàleg orientats a les tasques es limita al suport d'APIs de domini. Tot i així, els usuaris poden tenir peticions que no estan al seu alcance. Aquesta feina es centra en identificar aquestes peticions d'usuari. Els mètodes existents per a aquesta tasca es basan principalment en ajustar models pré-entrenats en grans dades anotates. Proposem un mètode nou, REDE, basat en l'aprenentatge de representació adaptativa i l'estimació de la densitat. El REDE es pot aplicar a casos de fotografia zero, i ràpidament aprenen un detector de gran rendiment amb només unes poques fotografies actualitzant menys de 3K paràmetres. We demonstrate REDE's competitive performance on DSTC9 data and our newly collected test set.", 'et': 'Enamik varasemaid tööd ülesannetele orienteeritud dialoogisüsteemidega piirdub domeeni API-de toetamisega. Kuid kasutajatel võib olla taotlusi, mis ei kuulu nende API-de reguleerimisalasse. Käesolevas töös keskendutakse selliste kasutajate taotluste tuvastamisele. Olemasolevad meetodid selle ülesande jaoks tuginevad peamiselt eelnevalt koolitatud mudelite peenhäälestusele suurte märgitud andmete põhjal. Pakume välja uue meetodi REDE, mis põhineb adaptiivsel representatsiooniõppel ja tiheduse hindamisel. REDE-i saab rakendada null-shot juhtumitele ja kiiresti õpib kõrge jõudlusega detektori ainult mõne võttega, värskendades vähem kui 3K parameetreid. Näitame REDE konkurentsivõimet DSTC9 andmete ja meie äsja kogutud testikomplekti põhjal.', 'fi': 'Suurin osa aiemmista tehtävälähtöisistä dialogijärjestelmistä on rajoitettu toimialueen rajapintojen tukemiseen. Käyttäjät voivat kuitenkin saada pyyntöjä, jotka eivät kuulu näiden sovellusliittymien soveltamisalaan. Tässä työssä keskitytään tällaisten käyttäjien pyyntöjen tunnistamiseen. Nykyiset menetelmät tähän tehtävään perustuvat pääasiassa esikoulutettujen mallien hienosäätöön suurilla annotoiduilla tiedoilla. Ehdotamme uutta REDE-menetelmää, joka perustuu adaptiiviseen representaatiooppimiseen ja tiheyden arviointiin. REDE-toimintoa voidaan käyttää nollakuvaustapauksissa, ja se oppii nopeasti tehokkaan ilmaisimen, jossa on vain muutama kuva päivittämällä alle 3K parametreja. Esittelemme REDE:n kilpailukyvyn DSTC9-datalla ja äskettäin kerätyllä testisarjalla.', 'hy': 'Most prior work on task-oriented dialogue systems is restricted to supporting domain APIs.  Այնուամենայնիվ, օգտագործողները կարող են ունենալ խնդրանքներ, որոնք այս API-ների շարժումից դուրս են գալիս: Այս աշխատանքը կենտրոնանում է օգտագործողների այդպիսի խնդրանքների հայտնաբերման վրա: Existing methods for this task mainly rely on fine-tuning pre-trained models on large annotated data.  Մենք առաջարկում ենք նոր մեթոդ REDE ը, որը հիմնված է ադապտիվ ներկայացման ուսումնասիրության և խտության գնահատման վրա: REDE ը կարող է կիրառվել զրոյի նկարների դեպքում, և արագ սովորում է բարձրահատուկ դետեկտոր միայն մի քանի նկարներով, վերականգնելով 3K պարամետրերից քիչ: Մենք ցույց ենք տալիս REDE ի մրցակցության արդյունքը DST9 տվյալների և մեր նոր հավաքված փորձարկումների համար:', 'jv': 'The first job on task-Orientation dialog sistems is limited to supported domain Aps. Nanging, pengguna bisa popot kanggo nyatakake Monday Learn Mode We proposal a new method, REDES, basated on an Adjustable representation Learning and Density estemation. REDEC iso ngubah gunane karo perusahaan gunane 0, dadi kapan dadi ngubah kebuturan langkung arah sing perusahaan karo perusahaan sithik sing ngubah apa perusahaan karo perusahaan sing isiné kato tanggal 3 K parameters. Awak dhéwé éntukno REDES sing berarti barêng-barêng nggambar gambar Daftar tok', 'sk': 'Večina predhodnega dela na sistemih dialoga, usmerjenih v naloge, je omejena na podporo domenskih API-jev. Vendar pa imajo lahko uporabniki zahteve, ki niso v področju uporabe teh API-jev. To delo se osredotoča na identifikacijo takih zahtev uporabnikov. Obstoječe metode za to nalogo temeljijo predvsem na natančnem nastavitvi vnaprej usposobljenih modelov na velikih podatkih z oznakami. Predlagamo novo metodo REDE, ki temelji na prilagodljivem učenju reprezentacije in oceni gostote. REDE je mogoče uporabiti za primere brez strela in hitro se nauči visokozmogljivega detektorja z le nekaj posnetki s posodobitvijo manj kot 3K parametrov. Konkurenčno učinkovitost REDE dokazujemo na podatkih DSTC9 in na novo zbranem testnem naboru.', 'ha': "Babu mafi yawan aikin da aka samu a kan tsarin zauren akwatin bayani masu cikin aikin da aka yi fari da shi, an ƙayyade don a ƙarani da amfani da wanda ake ƙaranci ɗin applet. Haƙĩƙa, mai amfani da shi yana da tambayar su wanda ba su iya ƙayyade wannan PAI. Wannan aikin yana fokus a kan gane ba da tambayar mai amfani da wannan. @ action: button Tuna buɗa'a wata hanyor node, a kan salon da ake samu'a da abincin da ake samu'awa. Ana iya amfani da LEDA ga masu sakan da ba'a yi sifanci ba, kuma yana iya amfani da gaugãwa mai ƙididdigo mai yin amfani da sauri kaɗan kawai da wato guda da tsohon ƙayyade 3.000. Muna nuna mafarin mutane da ta samu da samun jarrabun nan nan da aka samu.", 'he': 'רוב העבודה הקודמת על מערכות דיאלוג ממוקדות למשימות מוגבלת לתמיכה APIs שטח. עם זאת, למשתמשים ייתכן שיש בקשות שלא נמצאות מחוץ לתחום של APIs אלה. העבודה הזאת מתמקדת בזיהוי בקשות משתמשים כאלה. שיטות קיימות למשימה הזאת תלויות בעיקר על התאים מודלים מאומנים מראש על נתונים גדולים מוצבעים. We propose a novel method, REDE, based on adaptive representation learning and density estimation.  REDE can be applied to zero-shot cases, and quickly learns a high-performing detector with only a few shots by updating less than 3K parameters.  אנחנו מראים את ההופעה התחרותית של REDE על נתונים DSTC9 ו קבוצת הבדיקות החדשה שלנו אוסף.', 'bo': 'task-oriented dialog systems are restricted to support domain APIs. ཡིན་ནའང་། སྤྱོད་མཁན་ལ་APIs འདི་ཚོ་གི་ཁུངས་ཚབ་ནས་བྱུང་བའི་དགོས་ཞིབ་ཡོད་པ སྤྱོད་མཁན་གྱི་ཞུ་བ་འདི་དག་རེད་སྟོན་པ་འདིའི་ནང་དུ་བློ་གཏད་འདུག Existing methods for this task mainly rely on fine-tuning pre-trained models on large annotated data. ང་ཚོས་རང་བུའི་ལམ་ལུགས་གསར་བ་ཞིག་དང་། REDE་ལྟ་བུའི་བཟོ་བཅོས་དང་མཐུན་རྩོམ་པ་ཞིག་བསམ་བྱེད། REDE can be applied to zero-shot cases, and quickly learns a high-performing detector with only a few shots by updating less than 3K parameters. ང་ཚོས་DSTC9་གནས་སྡུད་དང་དུས་མཐུན་བསྡུར་བའི་བརྟག་ཞིབ་ཀྱི་སྐྱེས་ཆེན་དུ་REDE་གི་མཐའ་འཁོར་སྐྱོད'}
