{'en': 'Individual corpora predict fast memory retrieval during reading', 'ar': 'يتنبأ الجسد الفردي باسترداد سريع للذاكرة أثناء القراءة', 'es': 'Los cuerpos individuales predicen la recuperación rápida de la memoria durante la lectura', 'pt': 'Corpora individuais preveem recuperação rápida de memória durante a leitura', 'fr': 'Les corpus individuels prédisent une récupération rapide de la mémoire pendant la lecture', 'ja': '個々のコーポラルは、読み取り中に高速なメモリ取得を予測します', 'ru': 'Отдельные тела предсказывают быстрое извлечение памяти во время чтения', 'zh': '单语料库占读取之速记检索', 'hi': 'व्यक्तिगत कॉर्पोरेट पढ़ने के दौरान तेजी से स्मृति पुनर्प्राप्ति की भविष्यवाणी', 'ga': 'Déanann corpora aonair aisghabháil chuimhne tapa a thuar le linn na léitheoireachta', 'ka': 'individual corpora predict fast memory retrieval during reading', 'hu': 'Az egyes korpuszok gyors memóriavisszakeresést jeleznek az olvasás során', 'el': 'Τα μεμονωμένα σώματα προβλέπουν γρήγορη ανάκτηση μνήμης κατά την ανάγνωση', 'mk': 'Индивидуалното тело предвидува брзо преземање на меморијата за време на читањето', 'it': 'I singoli corpi predicono il recupero rapido della memoria durante la lettura', 'kk': 'Оқу кезінде жеке корпора жылдам жады алу үшін алдын алады', 'lt': 'Kiekvienas kūnas prognozuoja greitą atminties atkūrimą skaitant', 'ml': 'വായിക്കുമ്പോള്\u200d വേഗം മെമ്മറി തിരിച്ചെടുക്കുന്നതിനെപ്പറ്റി പ്രവചിക്കുന്നു', 'ms': 'Korpora individu meramalkan pemulihan ingatan pantas semasa membaca', 'mn': 'Хүн бүрийн корпора унших үед хурдан дурсамж авах', 'no': 'Individuell korpora foregår rask minne ved lesing', 'sr': 'Individualna korpora predviða brzu povratak pamćenja tokom čitanja', 'mt': 'Korpora individwali tbassar irkupru mgħaġġel tal-memorja waqt il-qari', 'si': 'කියවන්න වෙලාවට වේගයෙන් මතකය ආරක්ෂා කරන්න පුළුවන් වෙනවා', 'pl': 'Poszczególne korpusy przewidują szybkie odzyskiwanie pamięci podczas odczytu', 'so': 'Individual corpora predict fast memory retrieval during reading', 'sv': 'Individuella kroppar förutspår snabb minneshämtning under läsning', 'ro': 'Corpurile individuale prezic recuperarea rapidă a memoriei în timpul citirii', 'ur': 'پڑھنے کے موقع سریع یاد حاصل کرنے کی پیش بینی کرتا ہے', 'ta': 'வாசிக்கும் போது தனித்த நினைவகத்தை மீட்டெடுக்கும் போது குறிப்பிடுகிறது', 'uz': 'Name', 'vi': 'Từng người dự đoán bộ lấy bộ nhớ nhanh khi đọc', 'da': 'Individuelle korpora forudsiger hurtig hukommelse hentning under læsning', 'hr': 'Individualna tijela predviđaju brzinu povratka pamćenja tijekom čitanja', 'nl': 'Individuele corpora voorspellen snel geheugen ophalen tijdens lezen', 'id': 'Korpora individu memprediksi pemulihan ingatan cepat saat membaca', 'ko': '개체 어료 라이브러리 예측 읽기 과정 중의 빠른 기억 추출', 'de': 'Einzelne Korpora sagen schnellen Speicherabruf während des Lesens voraus', 'sw': 'Kampuni ya kila aina inatabiri kupata kumbukumbu haraka wakati wa kusoma', 'fa': 'شرکت شخصی در حال خواندن سریع حافظه پیش بینی می\u200cکند', 'tr': 'Indiki bedek okarken tiz yada alymyny çaklanýar', 'af': 'Individuele korpora voorskou vinnige geheue ontvang tydens lees', 'sq': 'Korpora individuale parashikon marrjen e shpejtë të kujtesës gjatë leximit', 'bg': 'Индивидуалните корпуси предвиждат бързо възстановяване на паметта по време на четене', 'am': 'የአሁኑ ኮርፖራ በማንበብ ጊዜ የፍጥረት ማስታወስ ማድረግ ለመፍጠር', 'hy': 'Ամեն անհատական մարմն կանխատեսում է արագ հիշողության վերադարձումը կարդալու ընթացքում', 'bn': 'Individual corpora predict fast memory retrieval during reading', 'bs': 'Individualna korpora predviđaju brzu povratak pamćenja tijekom čitanja', 'az': 'ƒ∞nsanlar oxuyark…ôn hƒ±zlƒ± yad almasƒ±nƒ± t…ômin edirl…ôr', 'cs': 'Jednotlivé korpusy předpovídají rychlé načtení paměti během čtení', 'et': 'Individuaalsed korpused ennustavad kiiret mälu taastamist lugemise ajal', 'ca': 'El corpore individual prediu recuperació ràpida de la memòria durant la lectura', 'fi': 'Yksittäiset korpuset ennustavat nopeaa muistin noutoa lukemisen aikana', 'ha': 'QXml', 'sk': 'Posamezni korpusi napovedujejo hitro pridobivanje spomina med branjem', 'jv': 'bodssoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'גופורה אינדיבידיאלית צפויה שיחזור זיכרון מהיר בזמן הקריאה', 'bo': 'སྒེར་འཛུགས་ཀྱི་དབང་ཆ་སྒེར་གྱི་དྲན་འཛིན་ལ་འཛིན་པའི་སྐབས་སུ།'}
{'en': 'The  corpus , from which a  predictive language model  is trained, can be considered the experience of a semantic system. We recorded everyday reading of two participants for two months on a tablet, generating individual corpus samples of 300/500 K tokens. Then we trained word2vec models from individual corpora and a 70 million-sentence newspaper corpus to obtain individual and norm-based long-term memory structure. To test whether individual corpora can make better predictions for a cognitive task of long-term memory retrieval, we generated stimulus materials consisting of 134 sentences with uncorrelated individual and norm-based word probabilities. For the subsequent eye tracking study 1-2 months later, our  regression analyses  revealed that individual, but not norm-corpus-based word probabilities can account for first-fixation duration and first-pass gaze duration. Word length additionally affected gaze duration and total viewing duration. The results suggest that corpora representative for an individual’s  long-term memory structure  can better explain reading performance than a norm corpus, and that recently acquired information is lexically accessed rapidly.', 'ar': 'يمكن اعتبار المجموعة ، التي يتم من خلالها تدريب نموذج اللغة التنبؤية ، تجربة نظام دلالي. سجلنا القراءة اليومية لاثنين من المشاركين لمدة شهرين على جهاز لوحي ، مما أدى إلى إنشاء عينات فردية من مجموعة الرموز 300/500 ألف. ثم قمنا بتدريب نماذج word2vec من هيئات فردية ومجموعة صحفية مكونة من 70 مليون جملة للحصول على بنية ذاكرة طويلة المدى فردية وقائمة على المعايير. لاختبار ما إذا كان يمكن للمجموعة الفردية أن تقدم تنبؤات أفضل لمهمة معرفية لاسترجاع الذاكرة على المدى الطويل ، قمنا بإنشاء مواد تحفيز تتكون من 134 جملة مع احتمالات غير مرتبطة بالكلمات الفردية والقائمة على القاعدة. بالنسبة لدراسة تتبع العين اللاحقة بعد شهر إلى شهرين ، كشفت تحليلات الانحدار لدينا أن احتمالات الكلمات الفردية ، ولكن ليست القائمة على القواعد المعيارية ، يمكن أن تفسر مدة التثبيت الأول ومدة النظرة الأولى. أثر طول الكلمة أيضًا على مدة النظرة وإجمالي مدة المشاهدة. تشير النتائج إلى أن ممثل الجسم لهيكل الذاكرة طويلة المدى للفرد يمكن أن يشرح أداء القراءة بشكل أفضل من مجموعة القواعد المعيارية ، وأن المعلومات المكتسبة مؤخرًا يتم الوصول إليها بشكل معجمي بسرعة.', 'pt': 'O corpus, a partir do qual um modelo de linguagem preditivo é treinado, pode ser considerado a experiência de um sistema semântico. Registramos a leitura diária de dois participantes por dois meses em um tablet, gerando amostras de corpus individuais de 300/500K tokens. Em seguida, treinamos modelos word2vec de corpora individuais e um corpus de jornal de 70 milhões de frases para obter estrutura de memória de longo prazo individual e baseada em normas. Para testar se corpora individuais podem fazer melhores previsões para uma tarefa cognitiva de recuperação de memória de longo prazo, geramos materiais de estímulo consistindo de 134 sentenças com probabilidades de palavras individuais e baseadas em normas não correlacionadas. Para o estudo de rastreamento ocular subsequente 1-2 meses depois, nossas análises de regressão revelaram que probabilidades de palavras individuais, mas não baseadas em corpus de norma, podem explicar a duração da primeira fixação e a duração do olhar da primeira passagem. O comprimento da palavra afetou adicionalmente a duração do olhar e a duração total da visualização. Os resultados sugerem que corpora representativos da estrutura de memória de longo prazo de um indivíduo podem explicar melhor o desempenho de leitura do que um corpus normativo, e que informações adquiridas recentemente são acessadas lexicamente rapidamente.', 'fr': "Le corpus, à partir duquel un modèle de langage prédictif est formé, peut être considéré comme l'expérience d'un système sémantique. Nous avons enregistré la lecture quotidienne de deux participants pendant deux mois sur une tablette, générant des échantillons de corpus individuels de 300/500 000 jetons. Ensuite, nous avons formé des modèles word2vec à partir de corpus individuels et d'un corpus de journaux de 70 millions de phrases pour obtenir une structure de mémoire à long terme individuelle et basée sur des normes. Pour vérifier si les corpus individuels peuvent faire de meilleures prévisions pour une tâche cognitive de récupération de la mémoire à long terme, nous avons généré des matériaux de stimulation composés de 134 phrases avec des probabilités de mots individuelles et basées sur des normes non corrélées. Pour l'étude de suivi oculaire subséquente 1 à 2 mois plus tard, nos analyses de régression ont révélé que les probabilités de mots individuelles, mais non basées sur le corpus normal, peuvent expliquer la durée de la première fixation et la durée du premier passage du regard. La longueur des mots affectait également la durée du regard et la durée totale de visi Les résultats suggèrent que les corpus représentatifs de la structure de la mémoire à long terme d'un individu peuvent mieux expliquer les performances de lecture qu'un corpus standard, et que les informations récemment acquises sont rapidement accessibles lexiquement.", 'es': 'El corpus, a partir del cual se entrena un modelo de lenguaje predictivo, puede considerarse la experiencia de un sistema semántico. Grabamos la lectura diaria de dos participantes durante dos meses en una tableta, generando muestras de corpus individuales de 300/500K tokens. Luego entrenamos modelos word2vec a partir de cuerpos individuales y un corpus de periódico de 70 millones de frases para obtener una estructura de memoria a largo plazo individual y basada en normas. Para probar si los cuerpos individuales pueden hacer mejores predicciones para una tarea cognitiva de recuperación de la memoria a largo plazo, generamos materiales de estímulo que constan de 134 oraciones con probabilidades de palabras individuales y basadas en normas no correlacionadas. Para el estudio de seguimiento ocular posterior 1-2 meses después, nuestros análisis de regresión revelaron que las probabilidades de palabras individuales, pero no basadas en el cuerpo normal, pueden explicar la duración de la primera fijación y la duración de la mirada del primer paso. La longitud de la palabra también afectó a la duración de la mirada y la duración total Los resultados sugieren que los cuerpos representativos de la estructura de memoria a largo plazo de un individuo pueden explicar mejor el rendimiento de lectura que un corpus normal, y que la información adquirida recientemente se accede de forma léxica rápidamente.', 'ja': '予測言語モデルが訓練されるコーパスは、意味体系の経験とみなすことができる。 2名の参加者の日常の読み取りをタブレットに2ヶ月間記録し、300/500 Kトークンの個々のコーパスサンプルを生成しました。 そして、個々のコーパスと7000万文の新聞コーパスからWord 2 vecモデルをトレーニングして、個々のノルムベースの長期記憶構造を取得しました。 長期記憶検索の認知タスクのために個々のコーパスがより良い予測を行うことができるかどうかをテストするために、私たちは、無関係な個々のノルムベースの単語確率を持つ134の文章からなる刺激教材を作成しました。 その後の1 ～ 2ヶ月後の目追跡研究では、回帰分析により、ノルムコーパスベースではない個々の単語の確率が、最初の固定持続時間と最初のパス視線持続時間を説明できることが明らかになりました。 単語の長さは、視線の長さと合計視聴時間にさらに影響を与えます。 その結果、個人の長期記憶構造のコーポラル担当者は、ノルムコーパスよりも読み取りパフォーマンスをより良く説明でき、最近取得された情報は語彙的に迅速にアクセスされることが示唆された。', 'zh': '其训候语言模形者语料库可谓语义统之验也。 平板电脑上记两参与者两月常读,生为300/500K代币单语料库样本。 然后从单个语料库和7000万个句子的报纸语料库中训练word2vec模形,以获基于个体范的长记结构。 试个体语料库可以久记忆检索为善占,吾生为134句之激材,有不关个体范之单词概率。 于1-2月后眼动踪迹研究,归析昭著,个体之(,非规模语料库也单词概率)可解首视持续时间与初因凝视持续时间。 字长犹影响持续时间与总观持续时间。 结果表明,个体长记结构者语料库可以善于格语料库释读性能,而近得信息于词汇上可速访也。', 'hi': 'कॉर्पस, जिसमें से एक भविष्यवाणी भाषा मॉडल को प्रशिक्षित किया जाता है, को एक शब्दार्थ प्रणाली का अनुभव माना जा सकता है। हमने एक टैबलेट पर दो महीने के लिए दो प्रतिभागियों की हर रोज रीडिंग दर्ज की, जिससे 300/500K टोकन के व्यक्तिगत कॉर्पस नमूने उत्पन्न हुए। फिर हमने व्यक्तिगत कॉर्पोरेट और 70 मिलियन-वाक्य वाले समाचार पत्र कॉर्पस से वर्ड 2 वीईसी मॉडल को व्यक्तिगत और आदर्श-आधारित दीर्घकालिक स्मृति संरचना प्राप्त करने के लिए प्रशिक्षित किया। यह परीक्षण करने के लिए कि क्या व्यक्तिगत कॉर्पोरेट दीर्घकालिक स्मृति पुनर्प्राप्ति के संज्ञानात्मक कार्य के लिए बेहतर भविष्यवाणियां कर सकता है, हमने उत्तेजना सामग्री उत्पन्न की जिसमें असंबद्ध व्यक्तिगत और आदर्श-आधारित शब्द संभावनाओं के साथ 134 वाक्य शामिल हैं। बाद के आंखों पर नज़र रखने वाले अध्ययन के लिए 1-2 महीने बाद, हमारे प्रतिगमन विश्लेषण से पता चला है कि व्यक्तिगत, लेकिन आदर्श-कॉर्पस-आधारित शब्द संभावनाएं पहले-निर्धारण अवधि और पहले-पास टकटकी अवधि के लिए जिम्मेदार हो सकती हैं। Word लंबाई ने अतिरिक्त रूप से टकटकी अवधि और कुल देखने की अवधि को प्रभावित किया. परिणाम बताते हैं कि किसी व्यक्ति की दीर्घकालिक स्मृति संरचना के लिए कॉर्पोरेट प्रतिनिधि एक आदर्श कॉर्पस की तुलना में पढ़ने के प्रदर्शन को बेहतर ढंग से समझा सकता है, और हाल ही में अधिग्रहित जानकारी को लेक्सिकली रूप से तेजी से एक्सेस किया जाता है।', 'ru': 'Корпус, из которого обучается прогностическая языковая модель, можно считать опытом семантической системы. Мы записывали ежедневное чтение двух участников в течение двух месяцев на планшете, генерируя отдельные образцы тела 300/500K токенов. Затем мы обучили модели word2vec от отдельных тел и газетный корпус из 70 миллионов предложений, чтобы получить индивидуальную и нормативную структуру долговременной памяти. Чтобы проверить, могут ли отдельные тела делать лучшие прогнозы для когнитивной задачи долгосрочного извлечения памяти, мы создали стимулирующие материалы, состоящие из 134 предложений с некоррелированными индивидуальными и нормативными вероятностями слов. Для последующего исследования слежения за глазами через 1-2 месяца наш регрессионный анализ показал, что индивидуальные, но не основанные на норме и корпусе, вероятности слова могут объясняться продолжительностью первой фиксации и продолжительностью первого взгляда. Длина слова дополнительно влияет на длительность взгляда и общую продолжительность просмотра. Результаты показывают, что репрезентативные для структуры долговременной памяти индивидуума тела могут лучше объяснять эффективность чтения, чем нормальный корпус, и что недавно полученная информация имеет быстрый лексический доступ.', 'ga': 'Is féidir an corpas, óna gcuirtear oiliúint ar mhúnla teanga thuarthach, a mheas mar thaithí córais shéimeantaigh. Thaifeadamar léamh laethúil beirt rannpháirtí ar feadh dhá mhí ar thaibléad, rud a ghin samplaí corpais aonair de chomharthaí 300/500K. Ansin chuireamar oiliúint ar mhúnlaí word2vec ó chorpas aonair agus ó chorpas nuachtáin 70 milliún abairt chun struchtúr cuimhne fadtéarmach aonair agus norm-bhunaithe a fháil. Chun a thástáil an féidir le corpóra aonair tuar níos fearr a dhéanamh do thasc cognaíoch d’aisghabháil cuimhne fadtéarmach, ghineamar ábhair spreagtha ar a raibh 134 abairt le dóchúlachtaí neamhchomhghaolmhara focal aonair agus norm-bhunaithe. Maidir leis an staidéar rianaithe súl a rinneadh ina dhiaidh sin 1-2 mhí ina dhiaidh sin, léirigh ár n-anailísí aischéimniúcháin gur féidir le dóchúlachtaí focal aonair, ach nach bhfuil bunaithe ar norm-chorpais, achar an chéad shocraithe agus fad na súl céadphasála a áireamh. Chuir faid na bhfocal isteach freisin ar fhad an fhéachana agus ar an ré iomlán féachana. Tugann na torthaí le fios gur féidir le corpora atá ionadaíoch do struchtúr cuimhne fadtéarmach duine aonair feidhmíocht léitheoireachta a mhíniú níos fearr ná gnáthchorpas, agus go ndéantar rochtain thapa ar fhaisnéis a fuarthas le déanaí.', 'hu': 'A korpusz, amelyből egy prediktív nyelvi modellt képzünk, egy szemantikai rendszer tapasztalatának tekinthető. Két résztvevő napi olvasását két hónapon keresztül egy tableten rögzítettük, 300/500K tokenből álló egyedi korpuszmintákat generálva. Ezután egyéni corporákból és egy 70 millió mondatos újságkorpuszból készítettünk word2vec modelleket, hogy egyéni és normál alapú hosszú távú memória struktúrát kapjunk. Annak vizsgálatára, hogy az egyes testek képesek-e jobb előrejelzéseket tenni a hosszú távú memória visszanyerésének kognitív feladatára, 134 mondatból álló ingeranyagot generáltunk, amelyek nem összefüggő egyéni és normál alapú szóvalószínűséggel. A következő 1-2 hónappal később végzett szemkövető vizsgálat során regressziós elemzéseink kimutatták, hogy az egyéni, de nem normálcorpus alapú szóvalószínűségek magyarázhatják az első rögzítés időtartamát és az első passz tekintet időtartamát. A szó hossza továbbá befolyásolta a tekintet időtartamát és a teljes megtekintési időtartamot. Az eredmények azt sugallják, hogy az egyén hosszú távú memória struktúráját képviselő corpora jobban megmagyarázza az olvasási teljesítményt, mint egy normál corpus, és hogy a közelmúltban szerzett információk lexikailag gyorsan elérhetők.', 'kk': 'Корпус, тіл үлгісін оқыту үшін, семантикалық жүйесінің тәжірибесін қалай алады. Біз күн сайын екі қатысушы оқуға жазып, таблицада екі ай оқуға жазып, 300/500K белгілі корпус үлгілерін жасадық. Содан кейін біз әрбір корпора және 70 миллион сөздердің және норманың негізінде ұзын жады құрылғысын алу үшін сөздердің 2век моделдерін оқыдық. Жеке корпораға ұзындық жадын алу үшін көңіл тапсырманың көңіл тапсырмасының жақсы тапсырмаларын тексеру үшін біз 134 сөздердің көңіл және нормалық сөздердің маңыздылығы бар стимул материаларын құрып Келесі көздерді қадағалау зерттеулері 1-2 ай кейін регрессия анализацияларымыз бұл жеке дегенді көрсетті, бірақ нормалық корпус- негіздеген сөздердің маңыздылығы бірінші түзету ұзақтығымен бірінші қадағалау ұза Сөздің ұзындығы қосымша қарау ұзындығы мен жалпы қарау ұзындығы. Нәтижелер жеке ұзындық жады құрылымының корпорасының негізгісі нормалық корпус дегеннен оқу мүмкіндігін жақсы түсіндіре алады, жуырдағы алған мәліметтер лексикалық түрде қатынауға болад', 'it': "Il corpus, da cui viene formato un modello linguistico predittivo, può essere considerato l'esperienza di un sistema semantico. Abbiamo registrato la lettura quotidiana di due partecipanti per due mesi su un tablet, generando campioni individuali di corpus di 300/500K token. Poi abbiamo addestrato modelli word2vec da corpora individuali e da un corpus di giornali di 70 milioni di frasi per ottenere una struttura individuale e basata sulla norma della memoria a lungo termine. Per verificare se i singoli corpi possono fare previsioni migliori per un compito cognitivo di recupero della memoria a lungo termine, abbiamo generato materiali di stimolo costituiti da 134 frasi con probabilità di parola individuali e basate sulla norma non corrette. Per il successivo studio di eye tracking 1-2 mesi dopo, le nostre analisi di regressione hanno rivelato che le probabilità individuali, ma non basate sul corpus normale, possono spiegare la durata della prima fissazione e la durata dello sguardo di primo passaggio. La lunghezza della parola ha inoltre influenzato la durata dello sguardo e la durata totale della visualizzazione. I risultati suggeriscono che i corpora rappresentativi per la struttura della memoria a lungo termine di un individuo possono spiegare meglio le prestazioni di lettura rispetto a un corpus normale, e che le informazioni acquisite recentemente sono accessibili lessicamente rapidamente.", 'el': 'Το σώμα, από το οποίο εκπαιδεύεται ένα μοντέλο προγνωστικής γλώσσας, μπορεί να θεωρηθεί η εμπειρία ενός σημασιολογικού συστήματος. Καταγράψαμε την καθημερινή ανάγνωση δύο συμμετεχόντων για δύο μήνες σε ένα δισκίο, δημιουργώντας μεμονωμένα δείγματα σωμάτων από μάρκες 300/500Κ. Στη συνέχεια εκπαιδεύσαμε μοντέλα από μεμονωμένα σώματα και ένα σώμα εφημερίδων 70 εκατομμυρίων προτάσεων για να αποκτήσουμε ατομική και βασισμένη σε κανόνες δομή μακροπρόθεσμης μνήμης. Για να ελέγξουμε αν μεμονωμένα σώματα μπορούν να κάνουν καλύτερες προβλέψεις για ένα γνωστικό έργο ανάκτησης μακροπρόθεσμης μνήμης, δημιουργήσαμε υλικό ερεθίσματος που αποτελείται από 134 προτάσεις με μη διορθωμένες ατομικές και κανονικές πιθανότητες λέξεων. Για την επακόλουθη μελέτη παρακολούθησης ματιών 1-2 μήνες αργότερα, οι αναλύσεις παλινδρόμησης μας αποκάλυψαν ότι οι ατομικές πιθανότητες λέξεων, αλλά όχι βασισμένες σε κανονικό σώμα, μπορούν να εξηγήσουν τη διάρκεια της πρώτης σταθεροποίησης και τη διάρκεια του πρώτου ματιού. Το μήκος της λέξης επηρέασε επιπλέον τη διάρκεια του ματιού και τη συνολική διάρκεια προβολής. Τα αποτελέσματα δείχνουν ότι τα σώματα αντιπροσωπευτικά για τη δομή της μακροπρόθεσμης μνήμης ενός ατόμου μπορούν να εξηγήσουν καλύτερα την απόδοση ανάγνωσης από ένα κανονικό σώμα, και ότι οι πρόσφατα αποκτηθείσες πληροφορίες είναι λεξικά προσβάσιμες γρήγορα.', 'lt': 'Korpus, iš kurio mokomas prognozuojamasis kalbos model is, gali būti laikomas semantinės sistemos patirtimi. Dviejų dalyvių kasdienį skaitymą įrašėme dviejų mėnesių tablet ėje, kuriame buvo paimti atskiri 300/500K žymenų korpuso mėginiai. Tada apmokėme žodžių 2vec modelius iš atskiros korpros ir 70 milijonų sakinių laikraščių korpuso, kad gautume individualią ir normomis pagrįstą ilgalaikę atminties struktūrą. To test whether individual corpora can make better predictions for a cognitive task of long-term memory retrieval, we generated stimulus materials consisting of 134 sentences with uncorrelated individual and norm-based word probabilities.  Po 1-2 mėnesių atlikus tolesnį akių stebėjimo tyrimą, mūsų regresijos analizės parodė, kad individuali, bet ne norma pagrįsta žodžio tikimybė gali atspindėti pirmojo fiksavimo trukmę ir pirmojo žvilgsnio trukmę. žodžio ilgis papildomai paveikė žvilgsnio trukmę ir visą žvilgsnio trukmę. Rezultatai rodo, kad korporas, atstovaujantis ilgalaikės atminties struktūrai, gali geriau paaiškinti skaitymo veiksmingumą nei įprastas korpusas, ir kad neseniai įgyta informacija yra greitai prieinama lexiškai.', 'ka': 'კჲპოსჟ, ჲე კჲ£ა ვ ოპვეგთევრვლვნ ენვჟკთ მჲევლ ოჲრპვნთპან, მჲზვ ეა ბთევ ჟვმანრთფნა ჟთჟრვმანრთკა. ჩვენ ყოველდღე ორი მოთავსწავლობის წაკითხვას დავწერეთ ტაბლიტში ორი თვის, რომელიც 300/500K მონიშვნების ინდიველური კორპუსის მონაცემები შექმნა. შემდეგ ჩვენ განვიყავით სახელი 2vec მოდელები ინდივერული კორპორადან და 70 მილიონი სიტყვების კორპოსდან განვიყავით ინდივერული და ნორმადან განვითარებული დიდი სიტყვების სტრუქ განსაზღვრებული კორპორა შეიძლება უკეთესი წარმოდგენების შესაძლებლობად კონციგური მოხმარების კონციგური რაოდენობა, ჩვენ შევქმნა სტიმულური მატერიალები, რომლებიც 134 წარმოდგენების შესაძლებლობა შემდეგ შემდეგ სახელის შენახვა 1-2 თვის შემდეგ, ჩვენი რეგრესი ანალიზები გააჩვენეთ, რომ ინდივები, მაგრამ არა ნორმა-კორპუსის სიტყვების შესაძლებლობა შეიძლება პირველი დაწყება და პირველი დანახვა სიტყ სიტყვის სიგრძე დამატებით დაახლოებით დაახლოებით დანახვა სიგრძე და მთელი დანახვა სიგრძე. წარმოდგენების შესახებ, რომ კორპორის რესპენტენტი ინდივების ძლიერი მეხსიერების სტრუქტურაზე უფრო უფრო უფრო უფრო აღწერა წარმოდგენება, ვიდრე ნორმის კორპუსზე, და რომ', 'mk': 'Корпусот, од кој е обучен предвидлив јазички модел, може да се смета за искуство на семантичен систем. Ги снимивме секојдневните читања на двајца учесници за два месеци на таблета, генерирајќи индивидуални примероци на корпус од 300/500K токени. Потоа трениравме word2vec модели од индивидуална корпора и 70 милиони речени весници корпус за да добиеме индивидуална и нормална долгорочна мемориска структура. За да тестираме дали индивидуалната корпора може да направи подобри предвидувања за когнитивна задача за долгорочно преземање на меморијата, ние генериравме стимул материјали составени од 134 реченици со некорелирани индивидуални и нормални веројатности на зборови. For the subsequent eye tracking study 1-2 months later, our regression analyses revealed that individual, but not norm-corpus-based word probabilities can account for first-fixation duration and first-pass gaze duration.  Должината на зборот додатно влијае на траењето на погледот и вкупното траење на погледот. Резултатите покажуваат дека корпората претставничка за долгорочната мемориска структура на еден индивидуал може подобро да објасни читањето од нормалниот корпус, и дека неодамна добиените информации се лексично пристапуваат брзо.', 'ms': 'Korpus, dari mana model bahasa ramalan dilatih, boleh dianggap pengalaman sistem semantik. Kami merekam setiap hari pembacaan dua peserta selama dua bulan pada tablet, menghasilkan sampel corpus individu 300/500K token. Kemudian kami melatih model word2vec dari korpra individu dan korpus surat khabar 70 juta kalimat untuk mendapatkan struktur ingatan jangka panjang berdasarkan norm dan individu. Untuk menguji sama ada korpra individu boleh membuat ramalan yang lebih baik untuk tugas kognitif untuk pemulihan ingatan jangka panjang, kami menghasilkan bahan stimulus yang terdiri dari 134 kalimat dengan kebarangkalian perkataan individu dan berdasarkan norm a. Untuk kajian pengesan mata berikutnya 1-2 bulan kemudian, analisis regresi kami mengungkapkan bahawa individu, tetapi bukan kebarangkalian perkataan berdasarkan norm-corpus boleh menganggap untuk jangka pemecahan pertama dan jangka pandangan pertama-pass. Panjang perkataan tambahan mempengaruhi jangka pandangan dan total jangka pandangan. Hasilnya menunjukkan bahawa wakil corpora untuk struktur ingatan jangka panjang individu boleh menjelaskan prestasi pembacaan lebih baik daripada norm a corpus, dan bahawa maklumat yang baru-baru ini dicapai secara leksi dengan cepat.', 'ml': 'ഒരു പ്രവചിക്കുന്ന ഭാഷ മോഡല്\u200d പരിശീലിക്കപ്പെടുന്ന കോര്\u200dപ്പുസ്, ഒരു സെമാന്റിക് സിസ്റ്റത്തിന്റെ അനുഭവങ്ങള രണ്ടു മാസത്തേക്ക് രണ്ടു പങ്കാളികളുടെ വായിക്കുന്നത് ഞങ്ങള്\u200d ദിവസവും റെക്കോര്\u200dക്ക് ചെയ്തു. ഒരു ടേബിളില്\u200d വെച്ച് വെച്ച്  പിന്നെ ഞങ്ങള്\u200d വാര്\u200dഡ് 2വെക്ക് മോഡലുകള്\u200d വ്യക്തിപരമായ കോര്\u200dപ്പോരിയില്\u200d നിന്നും 70 മില്ല്യണ്\u200d പത്രത്തില്\u200d നിന്നും കോര്\u200dപ്പുസില്\u200d നിന് ദീര്\u200dഘായ മെമ്മറി വീണ്ടെടുക്കുന്നതിനുള്ള ഒരു പ്രവചനങ്ങള്\u200dക്ക് വേണ്ടി വ്യക്തിപരമായി കോര്\u200dപ്പോര കോര്\u200dപ്പറ കാര്\u200dക്ക് നല്ല പ്രവചനങ്ങള്\u200d ഉണ്ടാക്കാന്\u200d കഴിയുമോ എന പിന്നീട് 1-2 മാസത്തിനു ശേഷം കണ്ണ് ട്രാക്കിങ്ങിങ്ങ് പഠനത്തിന് നമ്മുടെ രീക്രഷന്\u200d അന്വേഷണങ്ങള്\u200d വ്യക്തമായി തെളിയിച്ചുകൊടുത്തു, പക്ഷെ സാധാരണ കോര വാക്കിന്റെ നീളം കൂടുതല്\u200d കാഴ്ചയുടെ ദീര്\u200dഘവും മൊത്തം കാണുന്ന സമയവും പ്രഭാവിച്ചു. അതിന്റെ ഫലങ്ങള്\u200dക്ക് വിശദീകരിക്കുന്നത് ഒരു വ്യക്തിയുടെ നീണ്ട നീണ്ട മെമ്മറിയുടെ സ്ഥാനത്തിന്റെ പ്രതിനിധിയാണെന്നാണ്. ഒരു സാധാരണ കോര്\u200dപ്പുസ', 'mt': 'Il-korpus, li minnu jitħarreġ mudell lingwistiku prevedibbli, jista’ jitqies bħala l-esperjenza ta’ sistema semantika. Aħna rreġistrajna qari ta’ kuljum ta’ żewġ parteċipanti għal xahrejn fuq pillola, li ġġeneraw kampjuni individwali ta’ corpus ta’ 300/500K tokens. Imbagħad inħarrġu mudelli ta’ word2vec minn korpra individwali u korpus ta’ gazzetta ta’ 70 miljun sentenza biex inkisbu struttura ta’ memorja fuq medda twila ta’ żmien individwali u bbażata fuq in-normi. Biex jiġi ttestjat jekk korpra individwali tistax tagħmel previżjonijiet a ħjar għal kompitu konjittiv ta’ rkupru tal-memorja fit-tul, iġġenerajna materjali ta’ stimolu li jikkonsistu f’134 sentenza b’probabilitajiet ta’ kliem individwali mhux korrelati u bbażati fuq in-normi. Għall-istudju sussegwenti dwar it-traċċar tal-għajnejn xahrejn wara, l-analiżi tagħna tar-rigressjoni żvelat li l-probabbiltà tal-kelma individwali, iżda mhux ibbażata fuq in-norm-corpus, tista’ tikkunsidra t-tul tal-ewwel fissazzjoni u t-tul tal-għajnejn tal-ewwel pass. Word length additionally affected gaze duration and total viewing duration.  Ir-riżultati jissuġġerixxu li korpra rappreżentattiva għall-istruttura tal-memorja fit-tul ta’ individwu tista’ tispjega a ħjar il-prestazzjoni tal-qari minn korpus normali, u li informazzjoni miksuba reċentement tiġi aċċessata b’mod lexiku malajr.', 'mn': 'Үүнээс таамаглах хэл загвар суралцагдсан корпус нь semantic системийн туршлага гэж ойлгож болно. Бид өдөр тутам хоёр оролцогчдын уншилтыг таблеткт 2 сарын турш бичиж, 300/500K тодорхойлолтын жишээ бүтээсэн. Тэгээд бид нэг корпора болон 70 сая өгүүлбэрийн сонины корпорусын 2 век загваруудыг сургалтын тулд хувийн, нормон байгуулагдсан урт хугацааны санамж бүтцийг авах боломжтой болсон. Хүн бүрийн корпора урт хугацааны санамж авахын тулд илүү сайн таамаглал хийж чадах эсэхийг шалгахын тулд бид 134 өгүүлбэрээс хамааралтай, нормын үндсэн үгний магадлалтай 134 өгүүлбэрээс бүрдсэн урам зориулалт хийсэн. Дараа нь 1-2 сарын дараа нүдний дагаварын судалгаанд бидний сэтгэл хөдлөлийн шинжилгээ нь хэн нэгнийг харуулсан, гэхдээ норм-корпус суурилсан үгний магадлал нь анхны дагаварын туршилт, анхны дагаварын дагаварын туршилтыг тооцоолж ча Үүний урттай нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг нөлөөлдөг. Үүний үр дүнд хэн нэгний урт хугацааны санамж бүтээгдэхүүний корпора захирагч нь нормын корпус эсвэл унших үйл ажиллагааг илүү сайхан тайлбарлаж чадна. Саяхан авсан мэдээлэл лексикийн хурдан ашиглана.', 'sr': 'Korpus, odakle je predviđeni jezički model obučen, može se smatrati iskustvom semantičkog sistema. Snimili smo svakodnevno čitanje dva učesnika dva mjeseca na tableti, stvarajući individualne uzorke korpusa od 300/500K znakova. Onda smo obučili rečenice 2vek modele iz individualne korporacije i 70 miliona rečenica novinskog korporacije kako bi dobili strukturu uspomene na individualnoj i normi. Da bismo testirali da li individualna korpora može napraviti bolje predviđenje za kognitivni zadatak dugoročnog povratka pamćenja, stvorili smo stimulične materijale koji se sastoje od 134 rečenica sa nesavršenim individualnim i normalnim verovatnošću riječi. Za sljedeću studiju praćenja očiju 1-2 meseci kasnije, naša analiza regresije otkrila je da je individualna, ali ne verovatnoća riječi na normu-korpusu mogla računati na trajanje prvog popravka i trajanje pogleda prvog prolaza. Dužina reči dodatno utjecana na trajanje pogleda i ukupno trajanje pogleda. Rezultati sugeriraju da predstavnik korpore za dugoročnu strukturu uspomene pojedinaca može bolje objasniti čitanje učinka nego normski korpus, a da je nedavno dobijena informacija leksički brzo pristupena.', 'si': 'කෝර්පස්, මෙතනින් ප්\u200dරශ්නයක් භාෂාව ප්\u200dරශ්නයක් තියෙන්න පුළුවන්, සෙමාන්ටික් පද්ධතියේ අභ අපි හැමදාම කියනවා මාස දෙකක් කියලා තියෙනවා කියලා ටැබ්ලේට් එකක් තියෙනවා, ප්\u200dරතිකාරයේ කොර්පුස් සැමැල්ම් 300/500K ට ඊට පස්සේ අපි ප්\u200dරතිකාර කර්පෝරා වලින් 2වෙක් මොඩේල් එකක් ප්\u200dරධානය කරලා තියෙන්නේ ප්\u200dරතිකාරිය සහ ප්\u200dරතිකාරිය සහ සාමාන පරීක්ෂණය කරන්න පුළුවන් වෙන ප්\u200dරතිකාර කරුණාවක් හොඳ ප්\u200dරශ්නයක් කරන්න පුළුවන් කියලා, දිගටම මතකය ප්\u200dරශ්නයක් ගැන, අපි ප්\u200dරශ්නයක් ලැබ පස්සේ ඇස් පරීක්ෂණා පරීක්ෂණය 1-2 මාස පස්සේ, අපේ පරීක්ෂණ විශ්ලේෂණ පරීක්ෂණය විස්තර කරන්න පුළුවන් විදිහට, ඒත් නෝර්ම් කෝපුස් පරීක @ label ප්\u200dරතිචාරය ප්\u200dරධානයක් කියනවා ප්\u200dරතිකාරයෙක්ගේ ලොකු වෙලාවේ මතක සංස්කරණයට කියවන්න පුළුවන් නෝර්ම් කෝපස් වලට වඩා වැ', 'no': 'Korpusen som ein foregåande språk-modell er trent frå, kan betra opplevelsen av eit semantisk system. Vi registrerte kvardag lesing av to deltakarar i to månader på eit tablett, og laga individuelle korpusprøver med 300/500K-teikn. Så vi trenga ord2vec-modeller frå individuelle korpora og eit 70 millioner-setningskorpus for å få enkelt og normbasert langsiktig minnet-struktur. For å prøve om individuelle korpora kan gjera betre forhåndsvising for ein kognitiv oppgåve av langsiktig minne, har vi generert stimulmateriell som inneheld 134 setningar med ukraderte individuelle og normbaserte ordsannsynringar. For den følgjande øysporingsstudien 1-2 månader seinare, våre regresjonanalyser viste at individuelle, men ikkje vanskelighetane for ord som er basert på norm-korpus, kan rekna på første fikkingsdag og første gjennomgang. Lengd på ordet er tillegg påvirka lengde på utsjånaden og heile visingslengde. Resultatet tyder på at korporreprezentatoren for ein enkelt langsiktig minne-struktur kan bedre forklare lesingsfunksjonen enn ein norm-korpus, og at nyleg oppteken informasjon er leksisk tilgang raskt.', 'so': 'The corpus, from which a predictive language model is trained, can be considered the experience of a semantic system.  Waxaan maalin walba qornay wax akhrinta labo bilood oo ka mid ah miiska, waxaana sameynay tusaalooyin gaar ah oo ah 300/500K calaamado. Markaas waxaynu tababarinnay noocyo qoraal 2vec ah oo ka yimid shirkad gaar ah iyo warqad kasta oo 70 million oo xabsi ah si aan u helno dhismaha xusuusta ee waqti dheer oo caadiga ah. Si aan u imtixaano in shirkad gaar ah uu u sameyn karo wax ka sii wanaagsan oo uu u sameeyo shaqada xusuusta oo waqti dheer lagu soo celiyo, waxaynu abuurnay alaabo dhaqdhaqaaq ah oo ka mid ah 134 xabarood, waxaana suurtagal ah in qof oo aan qof aheyn iyo hadal caadi ah ku saleysan. Baaritaanka dib ee raadinta indhaha 1-2 bilood kadib, baaritaankeenu waxay muuqatay in qof gaar ah, laakiin suurtagalka ah ee qoyska ee caadiga ah ee qoyska ayaa xisaabin kara mudada ugu horraysa iyo mudada ugu horraysa. Dhererka hadalka ayaa si dheer ah u saameysan mudada aragga iyo waqtiga aragtida oo dhan. Abaalka waxaa laga jeedaa in qofka shirkadiisu uu dhismaha xusuusta ee wakhti dheer qofka ku nool yahay uu si ka wanaagsan u caddeyn karo bandhigyada akhrinta oo ka sii fiican karo qorshaha caadiga ah, macluumaadka la soo qaatay ayaa si dhaqso ah loo isticmaali karaa.', 'pl': 'Korpus, z którego szkolony jest model języka predykcyjnego, można uznać za doświadczenie systemu semantycznego. Nagrywaliśmy codzienne odczyty dwóch uczestników przez dwa miesiące na tablecie, generując indywidualne próbki korpusów tokenów 300/500K. Następnie trenowaliśmy modele Word2vec z poszczególnych korpusów i 70-milionowego korpusu gazet, aby uzyskać indywidualną i opartą na normach strukturę pamięci długoterminowej. Aby sprawdzić, czy poszczególne ciała mogą lepiej przewidywać zadanie poznawcze odzyskiwania pamięci długoterminowej, stworzyliśmy materiały stymulujące składające się z 134 zdań o nieskorygowanych indywidualnych i opartych na normach prawdopodobieństwach słów. Dla kolejnych badań śledzenia oczu 1-2 miesiące później nasze analizy regresyjne wykazały, że indywidualne, ale nie oparte na korpusie normy prawdopodobieństwa słowa mogą uwzględniać czas trwania pierwszej fixacji i czas trwania spojrzenia pierwszego przejścia. Długość słowa dodatkowo wpływała na czas trwania spojrzenia i całkowity czas oglądania. Wyniki sugerują, że korpusy reprezentatywne dla struktury pamięci długoterminowej danej osoby mogą lepiej wyjaśnić wydajność czytania niż korpus normowy, a ostatnio uzyskane informacje są leksycznie szybko dostępne.', 'ro': 'Corpusul, din care este instruit un model de limbaj predictiv, poate fi considerat experiența unui sistem semantic. Am înregistrat citirea zilnică a doi participanți timp de două luni pe o tabletă, generând mostre individuale de corpuri de 300/500K jetoane. Apoi am instruit modele word2vec din corpore individuale și un corpus ziar de 70 de milioane de propoziții pentru a obține o structură individuală și normală de memorie pe termen lung. Pentru a testa dacă corporele individuale pot face predicții mai bune pentru o sarcină cognitivă de recuperare a memoriei pe termen lung, am generat materiale de stimulare constând din 134 de propoziții cu probabilități de cuvânt individuale și normale necorelate. Pentru studiul ulterior de urmărire oculară, 1-2 luni mai târziu, analizele noastre de regresie au arătat că probabilitățile individuale, dar nu bazate pe norm-corpus, pot explica durata primei fixări și durata privirii în primul pas. Lungimea cuvântului a afectat în plus durata privirii și durata totală a vizualizării. Rezultatele sugerează că corporele reprezentative pentru structura memoriei pe termen lung a unei persoane pot explica mai bine performanța de citire decât un corpus normal, și că informațiile recent dobândite sunt accesate rapid lexical.', 'ta': 'ஒரு மொழி மாதிரி பயிற்சி செய்யப்படும் கோர்பாஸ், அதிலிருந்து ஒரு பெம்மான்டிக் அமைப்பின் அனுபவத்தை கருத்து க நாங்கள் ஒவ்வொரு நாளும் இரண்டு பங்குதியவர்கள் படிப்பதை பதிவு செய்தோம் மேசையில் இரண்டு மாதங்கள் படிப்பது, 300/500K குறியீடு பின்னர் நாங்கள் தனிப்பட்ட நிறுவனத்தில் இருந்து வார்த்தை 2வெக் மாதிரிகளை பயிற்சி செய்தோம் மற்றும் 70 மில்லியன் வாக்கு கோப்புகள நீண்ட நினைவகத்தின் மீட்சிக்கு ஒரு சிறப்பு முன்னோட்டங்களை சோதிக்க முடியுமா என்பதை சோதிக்கவும், நாம் நீண்ட நினைவகத்திற்கு மீட்டெடுப்பதில் 134 வாக்க பின்வரும் கண் தேடுதல் படிப்பு 1-2 மாதங்களுக்கு பின்னர், எங்கள் திரும்பச் செயல்பாடுகள் தெரிவிக்கப்பட்டுள்ளது, ஆனால் வழக்கமான கோர்ப்ஸ் அடிப்படையான சொ வார்த்தை நீளம் கூடுதலாக பார்வை காலம் மற்றும் மொத்த பார்வை காட்டும் காலம். முடிவு', 'sv': 'Korpusen, från vilken en prediktiv språkmodell tränas, kan betraktas som en upplevelse av ett semantiskt system. Vi spelade in dagliga läsningar av två deltagare under två månader på en surfplatta och genererade individuella corpusprover på 300/500K tokens. Sedan tränade vi word2vec modeller från enskilda corpora och en 70 miljoner menings tidningskorpus för att få individuell och normbaserad långsiktig minnesstruktur. För att testa om enskilda kroppar kan göra bättre förutsägelser för en kognitiv uppgift av långsiktig minneshämtning genererade vi stimulansmaterial bestående av 134 meningar med okorrekterade individuella och normbaserade ordsannolikheter. För den efterföljande ögonspårningsstudien 1-2 månader senare visade våra regressionsanalyser att individuella, men inte normkorpusbaserade ordsannolikheter kan redogöra för första fixeringstiden och första passagen blickens varaktighet. Ordlängd påverkade dessutom blickens varaktighet och totala visningstid. Resultaten tyder på att corpora representativa för en individs långsiktiga minnesstruktur bättre kan förklara läsprestanda än en normkorpus, och att nyligen förvärvad information är lexikalt tillgänglig snabbt.', 'ur': 'کورپوس، جس سے ایک پیش بینی زبان مدل تعلیم کی جاتی ہے، ایک سیمانٹی سیستم کی تجربہ سمجھ سکتی ہے. ہم نے ایک ٹبلیٹ پر دو مہینے کے لئے دو مشرکین کے پڑھنے کو روزہ دکھا لیا تھا، 300/500K ٹوکنوں کے ایک شخصی کرپوس نمونے بناتے تھے. پھر ہم نے شخصی کورپورا سے 2ویک موڈل کی تعلیم دی تھی اور 70 میلیون مجلس کارپور کی کورپوس کی تھی کہ شخصی اور norm-based طویل مدت یاد ساختہ حاصل کریں۔ اس لئے کہ آزمائش کریں کہ کس شخصی کورپورا بہتر پیش بینی کرسکتا ہے کہ ایک طویل مدت کے ذکر حاصل کرنے کے لئے بہترین پیش بینی کرسکتا ہے، ہم نے 134 جماعتوں سے پیدا کیا ہے جو غیر متصل ہوئی شخصی اور عام بنیاد ہوئی کلمات کے احتمال کے ساتھ متصل ہوتے ہیں. اس کے بعد 1-2 مہینے کے بعد آنکھ ترکینگ کی مطالعہ کے لئے، ہماری بازگشت کی تحقیقات نے اس شخص کو ظاہر کیا ہے، لیکن نہ عام-corpus-based کلمات کی احتمالات پہلی سیدھی مدت اور پہلی سیدھی نظر کی مدت کے لئے حساب کر سکتی ہیں. لفظ کی لمبی اضافہ سے آنکھ کی مدت اور کامل آنکھ کی مدت۔ نتیجے کی نشانی دیتے ہیں کہ ایک شخص کی طویل مدت کی یادگاری ساختار کے لئے کورپورا رفیق ایک نورمی کورپوس سے بہتر پڑھنے کی عملی توضیح دے سکتا ہے، اور یہ اخیر معلومات لکسی طور پر تیز دسترسی کی جاتی ہے۔', 'uz': "Kopus, birinchi kutilgan tillar modeli o'rganishi mumkin, semantik tizimning tajribasini o'ylashi mumkin. Biz har kuni ikki oy o'qishni jadvaldagi ikki beboblar o'qishni o'rganishni o'rganishni o'rganib, har kuni 300/500K tegnlarining bir xil kopus misollarini yaratdik. Keyin biz oddiy kompaniya va 70 millionlab yo'l maqsadlar qo'shilgan so'zlarni o'rganish uchun oddiy va oddiy asosiy xotira tuzuvlarini o'rganish uchun. Har bir oddiy kompaniya xotira olish vazifani yaxshi tajriba qilishini tekshirish uchun biz oddiy narsalarning 134 so'zlariga ega bo'lgan narsalarni yaratdik va oddiy so'zlar asosida emas va oddiy so'zlarni yaratdik. Keyingi keyingi ko'zning taʼminlovchisi 1-2 oydan keyin, qaytarish analytiklarimiz odamni ko'rsatadi, lekin oddiy qo'rpus asosiy so'zlarining asosida emas, birinchi tayyorlash davomida va birinchi marta ko'paytirish davomida hisoblanadi. @ info: whatsthis Natijalar, bir odamning uzun xotira tuzuvlarining qismini o'rganish imkoniyatini oddiy korpusdan o'rganishni yaxshi o'rganish mumkin. Yaqinda olingan maʼlumot leksikak tez olib keladi.", 'vi': 'Cơ thể, mà từ đó được đào tạo mô hình ngôn ngữ dự đoán, có thể được xem là kinh nghiệm của một hệ thống ngữ pháp. Chúng tôi ghi âm mỗi ngày đọc hai người tham dự trong hai tháng trên máy tính, sản xuất ra từng mẫu máu của vật 300/500K. Sau đó, chúng tôi đã đào tạo ra các mô hình từ cơ thể cá nhân và một tổ chức báo chí triệu bản để có được cấu trúc trí nhớ lâu dài. Để kiểm tra xem cơ thể cá nhân có thể dự đoán tốt hơn về một nhiệm vụ nhận thức về việc lấy lại trí nhớ lâu dài không, chúng tôi tạo ra các nguyên liệu kích thích, gồm các câu 134 với các từ chắc chắn không gắn liền. Đối với nghiên cứu theo dõi mắt sau đó 1-2 tháng sau, phân tích hồi quy của chúng tôi cho thấy khả năng xác suất chữ thường, nhưng không dựa trên tiêu chuẩn có thể tính trước thời gian lưu động đầu và thời gian nhìn qua. Từ dài thêm phần trăm ảnh hưởng tới thời gian nhìn và thời gian nhìn tổng hợp. Kết quả cho thấy cơ thể đại diện cho cấu trúc trí nhớ lâu dài của một cá nhân có thể giải thích khả năng đọc tốt hơn cơ thể thông thường, và rằng thông tin mới mua được gần đây được tiếp cận nhanh chóng.', 'da': 'Korpusset, hvorfra en prædiktiv sprogmodel trænes, kan betragtes som en oplevelse af et semantisk system. Vi registrerede hverdagslæsning af to deltagere i to måneder på en tablet og genererede individuelle corpusprøver på 300/500K tokens. Derefter trænede vi word2vec modeller fra individuelle corpora og et 70 millioner sætninger aviskorpus for at opnå individuel og normbaseret langtidshukommelsesstruktur. For at teste, om individuelle korpora kan lave bedre forudsigelser for en kognitiv opgave med langtidshukommelse hentning, genererede vi stimulusmaterialer bestående af 134 sætninger med ukorregerede individuelle og norm-baserede ord sandsynligheder. For det efterfølgende eyetracking studie 1-2 måneder senere viste vores regressionsanalyser, at individuelle, men ikke norm-corpus-baserede ord sandsynligheder kan forklare første fiksering varighed og første passage blik varighed. Ordlængden påvirkede desuden blikkets varighed og samlede visningstid. Resultaterne tyder på, at corpora repræsentative for en persons langsigtede hukommelsesstruktur bedre kan forklare læseydelse end et normkorpus, og at nyligt erhvervet information er leksiksk tilgængelig hurtigt.', 'nl': "Het corpus, waaruit een voorspellend taalmodel wordt getraind, kan worden beschouwd als de ervaring van een semantisch systeem. We namen de dagelijkse lezing van twee deelnemers gedurende twee maanden op een tablet op en genereerden individuele corpussamples van 300/500K tokens. Vervolgens hebben we word2vec modellen getraind van individuele corpora's en een 70 miljoen zinnen krantencorpus om individuele en normgestuurde langetermijngeheugenstructuur te verkrijgen. Om te testen of individuele corpora betere voorspellingen kunnen maken voor een cognitieve taak van langetermijngeheugenterugwinning, genereerden we stimulusmateriaal bestaande uit 134 zinnen met ongecorreleerde individuele en op norm gebaseerde woordwaarschijnlijkheden. Voor de daaropvolgende eye tracking studie 1-2 maanden later bleek uit onze regressie analyses dat individuele, maar niet op norm-corpus gebaseerde woordwaarschijnlijkheden kunnen verklaren voor first-fixatie duur en first-pass blik duur. Woordlengte beïnvloedde bovendien de kijkduur en de totale kijkduur. De resultaten suggereren dat corpora representatief voor de langetermijngeheugenstructuur van een individu leesprestaties beter kunnen verklaren dan een normcorpus, en dat recent verworven informatie snel lexicaal toegankelijk is.", 'bg': 'Корпусът, от който се обучава прогнозиращ езиков модел, може да се счита за опит на семантична система. Записахме ежедневно четене на двама участници в продължение на два месеца на таблет, генерирайки индивидуални корпусни проби от 300/500К токена. След това обучихме модели от индивидуални корпуси и 70 милиона изречения във вестник, за да получим индивидуална и нормативно базирана дългосрочна памет структура. За да тестваме дали индивидуалните корпуси могат да направят по-добри прогнози за когнитивна задача за възстановяване на паметта в дългосрочен план, генерирахме стимулиращи материали, състоящи се от 134 изречения с некорегирани индивидуални и нормални вероятности на думата. За последващото проучване за проследяване на очите 1-2 месеца по-късно нашите регресионни анализи показаха, че индивидуалните, но не и норма-корпусни вероятности на думата могат да обяснят продължителността на първото фиксиране и продължителността на първия поглед. Дължината на думата допълнително повлиява продължителността на погледа и общата продължителност на гледане. Резултатите показват, че корпусите, представителни за структурата на дългосрочната памет на индивида, могат по-добре да обяснят ефективността на четене, отколкото нормален корпус, и че наскоро придобитата информация е лексично достъпна бързо.', 'hr': 'Korpus, od kojeg je predviđeni jezički model obučen, može se smatrati iskustvom semantičkog sustava. Snimili smo svakodnevno čitanje dva učesnika dva mjeseca na tableti, stvarajući individualne uzorke korpusa od 300/500K znakova. Onda smo obučili rečenice 2vec modele iz individualne korporacije i 70 milijuna rečenica novinskog korporacije kako bi dobili dugoročnu strukturu sjećanja na individualnoj i normi. Da bismo testirali da li individualna tijela može napraviti bolje predviđenje za kognitivni zadatak dugoročnog povratka pamćenja, stvorili smo stimulne materijale koji se sastoje od 134 rečenica sa nesavršenim individualnim i normalnim verovatnošću riječi. Za sljedeće ispitivanje praćenja očiju 1-2 mjeseci kasnije, naša analiza regresije pokazala je da je individualna, ali ne vjerojatnost riječi na normu-korpusu može računati na trajanje prvog popravka i trajanje pogleda prvog prolaza. Dužina riječi dodatno utjecana na trajanje pogleda i ukupno trajanje pogleda. Rezultati sugeriraju da predstavnik korporacije za dugoročnu strukturu sjećanja pojedinca može bolje objasniti čitanje učinka nego normski korpus, a da je nedavno dobijene informacije leksički brzo pristupljene.', 'de': 'Der Korpus, aus dem ein prädiktives Sprachmodell trainiert wird, kann als Erfahrung eines semantischen Systems betrachtet werden. Wir haben zwei Monate lang das tägliche Lesen von zwei Teilnehmern auf einem Tablet aufgezeichnet und einzelne Korpusproben von 300/500K Token generiert. Anschließend trainierten wir word2vec Modelle aus einzelnen Korpora und einem 70-Millionen-Satz Zeitungskorpus, um individuelle und normbasierte Langzeitgedächtnisstruktur zu erhalten. Um zu testen, ob einzelne Korpora bessere Vorhersagen für eine kognitive Aufgabe des Langzeitgedächtnisses machen können, erstellten wir Stimulusmaterialien bestehend aus 134 Sätzen mit unkorrelierten individuellen und normbasierten Wortwahrscheinlichkeiten. Für die anschließende Eye-Tracking-Studie 1-2 Monate später ergaben unsere Regressionsanalysen, dass individuelle, aber nicht normkorpusbasierte Wortwahrscheinlichkeiten für First-Fixation Dauer und First-Pass Blickdauer verantwortlich sein können. Die Wortlänge beeinflusste zusätzlich die Blickdauer und die gesamte Betrachtungsdauer. Die Ergebnisse deuten darauf hin, dass Korporen, die für die Langzeitgedächtnisstruktur eines Individuums repräsentativ sind, Leseleistung besser erklären können als ein Normkorpus, und dass kürzlich erworbene Informationen schnell lexikalisch abgerufen werden.', 'id': 'Korpus, dari mana model bahasa prediksif dilatih, dapat dianggap pengalaman dari sistem semantis. Kami merekam setiap hari pembacaan dua peserta selama dua bulan di tablet, menghasilkan sampel corpus individu 300/500K token. Kemudian kami melatih model word2vec dari korpra individu dan korpus koran 70 juta kalimat untuk mendapatkan struktur ingatan jangka panjang berdasarkan standar dan individu. Untuk menguji apakah corpora individu dapat membuat prediksi yang lebih baik untuk tugas kognitif untuk mengembalikan ingatan jangka panjang, kami menghasilkan bahan stimulus yang terdiri dari 134 kalimat dengan probabilitas kata individu dan berdasarkan norm a tidak terhubung. Untuk studi pelacakan mata berikutnya 1-2 bulan kemudian, analisis regresi kami mengungkapkan bahwa individu, tetapi bukan probabilitas kata berdasarkan norma-corpus dapat memperhitungkan durasi fiksasi pertama dan durasi pandangan pertama-pass. Panjang kata tambahan mempengaruhi durasi pandangan dan total durasi pandangan. Hasilnya menunjukkan bahwa wakil corpora untuk struktur ingatan jangka panjang individu dapat lebih baik menjelaskan prestasi pembacaan daripada norm a corpus, dan bahwa informasi yang baru-baru ini diakses secara lexik dengan cepat.', 'ko': '어료 라이브러리에서 예측 언어 모델을 훈련하면 어의 체계의 경험으로 볼 수 있다.우리는 태블릿PC에 두 명의 참가자가 두 달 동안 매일 읽는 양을 기록하여 300/500K 기호화폐의 개인 어료 라이브러리 샘플을 생성했다.그리고 우리는 단일 자료 라이브러리와 7000만 개의 신문 자료 라이브러리에서word2vec모델을 훈련하여 개체와 상형을 바탕으로 하는 장기적인 기억 구조를 얻는다.개체 어료 라이브러리가 장기 기억 추출의 인지 임무를 더욱 잘 예측할 수 있는지 측정하기 위해 우리는 134개의 문장으로 구성된 자극 재료를 생성했는데 이런 문장들은 관련이 없는 개체와 범수를 바탕으로 하는 단어 확률을 가지고 있다.1-2개월 후의 후속 안구 추적 연구에 대해 우리의 회귀분석에 의하면 개체가 규범화된 어료 라이브러리가 아닌 단어의 확률을 바탕으로 첫 번째 주시 지속 시간과 첫 번째 응시 지속 시간을 해석할 수 있다.단어의 길이는 주시 지속 시간과 총 관람 지속 시간에도 영향을 미친다.그 결과 개인의 장기적인 기억 구조를 대표하는 자료 라이브러리는 표준 자료 라이브러리보다 읽기 성적을 더 잘 설명할 수 있고 최근 얻은 정보는 어휘에 빠르게 방문되고 있다.', 'fa': 'کورپوس، که یک مدل پیش بینی زبان آموزش داده شده، می تواند تجربه یک سیستم semantic را به نظر بگیرد. ما هر روز از خواندن دو تا شرکت کننده برای دو ماه روی یک تبلت ضبط کردیم که نمونه\u200cهای شخصی از 300/500کیلومتر نشانه\u200cهای کورپوس را تولید می\u200cکنیم. سپس ما مدل\u200cهای دوویک کلمه\u200cای را از شرکت فردی و یک شرکت روزنامه\u200cی 70 میلیون جمله آموزش دادیم تا ساختار حافظه طولانی بر اساس فردی و نورمی برگیریم. تا امتحان کند که آیا شرکت شخصی می تواند پیش بینی بهتر برای یک کار شناخته از بازیابی حافظه طولانی انجام دهد، ما ماده\u200cهای تحریک را تولید کردیم که از 134 جمله با احتمالات کلمه\u200cهای شخصی و نورمی متصل نشده است. برای مطالعه ردیابی چشم بعدی ۱-۲ ماه بعد، تحلیل بازگشت ما نشان داد که فرد فرد، ولی احتمالات کلمه\u200cای که بر اساس روم-کورپوس هستند، نمی\u200cتوانند برای مدت اولین تنظیم و مدت اولین نگاهی را حساب کنند. طول کلمه اضافه به طول نگاه و طول تمرکز نگاه کردن تاثیر داده شده است. نتیجه\u200cها پیشنهاد می\u200cدهند که نماینده\u200cی شرکت برای ساختار حافظه طولانی یک فرد می\u200cتواند عملکرد خواندن بهتر از یک شرکت نورمی توضیح دهد، و این اطلاعات اخیراً دریافت شده به زبان سریع دسترسی می\u200cشود.', 'sw': 'Shirika hilo, ambalo ni muundo wa lugha ya kutabiri umefundishwa, unaweza kuchukuliwa na uzoefu wa mfumo wa semanti. Tumerekodi kila siku kusoma washiriki wawili kwa miezi miwili kwenye mezani, kutengeneza sampuli binafsi za viungo 300/500,000. Kisha tukafundisha mifano ya word2vec kutoka kwenye kampuni binafsi na gazeti la kifungo milioni 70 ili kupata muundo wa kumbukumbu kwa muda mrefu wa muda mrefu. Ili kujaribu kama kampuni binafsi inaweza kufanya utabiri bora kwa jukumu la kurejesha kumbukumbu kwa muda mrefu, tulitengeneza vifaa vizuri vilivyokuwa na hukumu 134 zenye uwezekano wa maneno yasiyo ya kawaida. Kwa utafiti wa ufuatiliaji wa macho baadae miezi 1-2 baadae, uchambuzi wetu wa ufuatiliaji ulionyesha kuwa mtu mmoja, lakini sio uwezekano wa maneno ya kawaida yanaweza kuchukua muda wa kurekebisha kwa mara ya kwanza na kwa muda wa kuangalia macho ya kwanza. Ukomo wa maneno uliathiri zaidi muda wa macho na muda wa kuangalia kwa ujumla. Matokeo yanapendekeza kuwa mwakilishi wa kampuni kwa muundo wa muda mrefu wa kumbukumbu wa mtu anaweza kueleza zaidi ya utendaji wa kusoma kuliko makampuni ya kawaida, na kwamba taarifa zilizopata hivi karibuni imepata kwa kasi.', 'tr': 'Korpus, haýsyndan öňünç bir dil nusgasyny okuw edilýän, semantik sistemanyň tecrübesi diýip pikir edilýär. Her gün iki ay boyunca bir tablette iki katılcı okuyorduk ve 300/500K örneklerinin örneklerini oluşturuyorduk. Sonra birnäçe korpora we 70 milliýon sözlän gazet korpusyndan biri we normaldan uzak durmuş yada strukturyny almak üçin sözlän 2vek nusgalary öwrendik. Şahsy korpora uzak durmuş yada almak üçin bilinçli täblisaň gowy tahmin edip biljekdigini barlamak üçin, 134 söz döredilmedik we norm tabanly söz mümkinçilikleri bilen şekillendirdik. Sonradan göz tazlyklarynyň 1-2 aýdan soňra, regressiýanyň analysiýalarymyz indiki hökmüni görkezildi, ýöne norm-korpusdan daşary sözlerin mümkinçilikleri ilkinji gezek taýýarlanmasy we ilkinji gezek gözlemek mümkinçilikleri üçin hesap edip biler. Kelimiň uzunlygy gözleriň uzinlygyny we jemi görkezilişiň uzinlygyny eňleýär. netijeler birnäçe kişiniň uzun wagt ýagdaýynyň strukturynyň korporatynyň eserlerini norm korpusdan gowy düşündirmegini düşündirýär we soňky aldyk maglumatlary leksiýaly çalt berilýär.', 'af': "Die korpus, waarvan 'n voorskoulike taal model onderwerp is, kan aangesien word die erfaring van 'n semantiese stelsel. Ons het elke dag die lees van twee deelnimmers vir twee maande op 'n tableet opgenereer en individuele korpus voorbeelde van 300/500K tekens genereer. Toe het ons woorde 2vec modele opgelei van individuele korpora en 'n 70 miljoen sin koerant korporus om individuele en norm-gebaseerde lang-term geheue struktuur te kry. Om te probeer of individuele korpora beter voorskou kan maak vir 'n kognitiewe taak van lang-tydelike geheue ontvang, genereer ons stimuleerde materiale wat bestaan van 134 setnings met onkorrekte individuele en norm-gebaseerde woord waarskynlikheid. Vir die volgende oog agtervolg studie 1-2 maande later, het ons regresie analiseerdes die individuele geopenbaar dat individuele, maar nie norm-corpus-gebaseerde woord waarskynlikheid kan reken vir die eerste-fasting-duur en eerste-passing kyk-duur. Woordlengte addisionaal beïnvloor aansig duur en totaal aansig duur. Die resultate stel voorstel dat korpora-reprezentant vir 'n individuele se lang-term geheue-struktuur beter kan uitduidelik lees-prestasie a s 'n norm korporus, en dat onlangs aangeneem inligting is leksies vinnig toegang.", 'sq': "Korpus, nga i cili është trajnuar një model gjuhësh parashikuese, mund të konsiderohet përvoja e një sistemi semantik. Ne regjistruam leximin e përditshëm të dy pjesëmarrësve për dy muaj në një pllakë, duke krijuar mostra individuale të trupit me 300/500K token. Pastaj trajnuam modele word2vec nga korpra individuale dhe një korpus gazetar me 70 milion fjalë për të marrë strukturën e kujtesës individuale dhe të bazuar në norm ë afat-gjatë. Për të provuar nëse korpra individuale mund të bëjë parashikime më të mira për një detyrë kognitive të marrjes së kujtesës afat-gjatë, ne krijuam materiale stimuluese që përbëhen nga 134 fjalë me probabilitete të pavërteta të fjalëve individuale dhe të bazuara në norm ë. Për studimin e ndjekjes së syve 1-2 muaj më vonë, analizat tona të regresionit zbuluan se probabilitetet e fjalës individuale, por jo të bazuara në norm ë-korpus mund të llogarisin për gjatësinë e fiksimit të parë dhe gjatësinë e shikimit të kalimit të parë. Gjatësia e fjalës ndikon shtesë në gjatësinë e shikimit dhe gjatësinë totale të shikimit. The results suggest that corpora representative for an individual's long-term memory structure can better explain reading performance than a norm corpus, and that recently acquired information is lexically accessed rapidly.", 'am': 'የቆርፓስ የቋንቋ ሞዴል የተማረ የsemantic ስርዓት መሆኑን ይመስላል፡፡ ሁለት ተጋሪዎችን በየቀኑ ሁለት ወራት በማንበብ ላይ እናነበብ ነበር፣ የቆርፓስ ምሳሌዎች 300/500 ሺሕ ምልክቶች አፈጣጠርን፡፡ ከዚህም በኋላ ቃላት 2vec ምሳሌዎችን ከብሔራዊ ኮርፖራ እና 70 ሚሊዮን የፍርድ ካርፓስ ለብቻው የረጅም የረጅም ዘመናት መታሰቢያ ሥርዓት ለማግኘት አስተማርነው ነበር፡፡ የአንዳንዱ ኮርፖርት የረጅም ዘመን ማስታወሻ ማሳየት የሚችል ትንቢት ማድረግ ማድረግ እንዲችል ለመፈትነው ነው፣ የ134 ደብዳቤዎች በተመሳሳይ የግል እና የተመሳሳይ ቃላት በተመሳሳይ እና የተመሳሳይ ቃላት የሆኑትን አነስተዋልና፡፡ በኋላው 1-2 ወር በኋላ የዓይን የመግለጫ ትምህርት ግንኙነታችን የአካባቢ ግንኙነታችን የአካባቢ ግንኙነት፣ ነገር ግን የተመሳሳይ ቃላት ሳይሆን የመጀመሪያውን ክፍለ ዘመን እና የመጀመሪያውን ክፍል ዘመን ለመቆጣጠር ይችላል፡፡ Word length additionally affected gaze duration and total viewing duration.  ፍሬዎቹ የረጅም ዘመን ማስታሰቢያ ግንኙነት የቆርፓር መልዕክተኛ ከዓለምአዊ ኮርፓስ ይልቅ ማስታወቂያውን ይሻላል፡፡', 'hy': 'Կորպուսը, որից ուսուցանվում է կանխատեսող լեզվի մոդելը, կարելի է համարել սեմանտիկ համակարգի փորձը: Մենք գրեցինք երկու մասնակիցների ամենօրյա կարդալը երկու ամիս տախտակի վրա, ստեղծում էինք 300-500K կտոնների առանձին մարմնի նմուշներ: Հետո մենք պատրաստեցինք 2Վ բառերի մոդելներ անհատական մարմնից և 70 միլիոն նախադասություն ունեցող թերթի մարմնից, որպեսզի ստանանք անհատական և նորմալ հիմնված երկարաժամկետ հիշողության կառուցվածք: Որպեսզի ստուգենք, թե անհատական մարմնի կարողանում է ավելի լավ կանխատեսել երկարաժամկետ հիշողության վերադարձման ճանաչողական խնդիրը, մենք ստեղծեցինք խթանիչ նյութեր, որոնք կազմված են 134 նախադասություններից, որոնք անկախ անկախ անհատական և նորմալ հի Հաջորդ աչքի հետևման ուսումնասիրության համար 1-2 ամիս անց մեր ռեգրեսիայի վերլուծությունները բացահայտեցին, որ անհատական, բայց ոչ նորմամալ մարմնի հիմնված բառերի հավանականությունը կարող է հաշվի առնել առաջին ֆեկցիայի տևողությունը և առաջին հայացքի տևողությունը Բառի երկարությունը նույնպես ազդում է նայի տևողության և ընդհանուր դիտարկության տևողության վրա: Արդյունքները ցույց են տալիս, որ անհատի երկարաժամկետ հիշողության կառուցվածքի մարմնի ներկայացուցիչը ավելի լավ կարող է բացատրել կարդալու արդյունքը, քան նորմալ մարմնի, և որ վերջերս ստացված ինֆորմացիան արագ հասանելի է:', 'bs': 'Korpus, od kojeg je predvidljiv jezički model obučen, može se smatrati iskustvom semantičkog sistema. Snimili smo svakodnevno čitanje dva učesnika dva mjeseca na tableti, stvarajući individualne uzorke korpusa od 300/500K znakova. Onda smo obučili rečenice 2vec modele iz individualne korporacije i 70 miliona rečenica novinskog korporacije kako bi dobili dugoročnu strukturu pamćenja na individualnoj i normi. Da bismo testirali da li individualna tijela može napraviti bolje predviđanja za kognitivni zadatak dugoročnog povratka pamćenja, stvorili smo stimulne materijale koji se sastoje od 134 rečenica sa nesavršenim individualnim i normalnim verovatnošću riječi. Za sljedeću studiju praćenja očiju 1-2 mjeseci kasnije, naša analiza regresije pokazala je da je individualna, ali ne vjerojatnost riječi na normu-korpusu može računati za trajanje prvog popravka i trajanje pogleda prvog prolaza. Dužina riječi dodatno utjecana na trajanje pogleda i ukupno trajanje pogleda. Rezultati sugeriraju da predstavnik korporacije za dugoročnu strukturu sjećanja pojedinaca može bolje objasniti čitanje učinka nego normski korpus, a da je nedavno dobijena informacija leksički brzo pristupljena.', 'bn': 'কোর্পাস, যেখান থেকে একটি ভবিষ্যৎ ভাষার মডেল প্রশিক্ষণ প্রদান করা হয়, সেমেন্টিক ব্যবস্থার অভিজ্ঞতা বিবেচনা করা  আমরা প্রতিদিন দুই মাসের জন্য টেবিলে অংশগ্রহণকারীদের পাঠ করার কথা রেকর্ড করেছিলাম। তারা ৩০০/৫০০ লক্ষ টোকের ব্যক্তিগত কোর তারপর আমরা ব্যক্তি এবং স্বাভাবিক দীর্ঘমেয়াদের স্মৃতিক কাঠামো পেতে ব্যক্তি এবং স্বাভাবিক স্মৃতিক কাঠামো প্রশিক্ষণ দিয়েছিলাম। ব্যক্তিগত কোর্পোরা দীর্ঘমেয়াদ স্মৃতি পুনরুদ্ধারের কাজের জন্য ভালো ভবিষ্যদ্বাণী করতে পারে কিনা তা পরীক্ষা করতে পারে, আমরা উৎসাহিত উপাদান তৈরি করেছি যেখানে ১ পরবর্তী চোখের ট্র্যাকিং গবেষণার পর ১-২ মাস পরে আমাদের পুনরাবৃত্তি বিশ্লেষণ প্রকাশ করেছে যে ব্যক্তিকে ব্যক্ত করে, কিন্তু স্বাভাবিক ক কোর্পাস-ভিত্ শব্দের দৈর্ঘ্য অতিরিক্ত ভাবে চোখের দৈর্ঘ্য এবং সম্পূর্ণ দেখার সময় প্রভাবিত হয়েছে। ফলাফল পরামর্শ দিয়েছে যে কোর্পোরা ব্যক্তির দীর্ঘমেয়াদী স্মৃতিক কাঠামোর প্রতিনিধিত্ব ব্যাখ্যা করতে পারে স্বাভাবিক ক কোর্পাসের চেয়ে ভালো', 'az': 'Önümüzdən bir dil modeli təhsil edilən korpus semantik sisteminin təcrübəsini düşünə bilər. Biz hər gün iki aylıq iştirakçinin oxunmasını bir tabletdə yazdıq, 300/500K möcüzələrinin indir korpus nümunələrini yaratdıq. Sonra individu korpora və 70 milyon cümləlik gazet korpusu təhsil etdik ki, individu və norm-tabanlı uzun-müddət yada qurulması üçün 2 vek modellərini təhsil etdik. Belə bir korpora uzun müddətli anı almaq üçün daha yaxşı tədbir edə biləcəyini sınağa çəkmək üçün, 134 cümlədən və norm-tabanlı kəlmə ehtimalları olan stimulus materyalları yaratdıq. Sonradan göz izləməsi 1-2 ay sonra, regresyon analizimiz individu olduğunu göstərdi, amma norm-corpus-based söz olaraq ilk fikirləmə müddəti və ilk keçmə müddətini hesab edə bilər. Sözlərin uzunluğu artıq gözləmə uzunluğunu və bütün görünüş uzunluğunu təsir edir. Sonuçlar individulərin uzun müddətli hafıza strukturunun korporası norm korpusundan daha yaxşı oxumaq performansını daha yaxşı a çıqlayabilir və bu az qala alınan məlumatların leksik olaraq tərzdə istifadə edilir.', 'ca': "El corpus, amb el qual s'entrena un model de llenguatge preditiu, es pot considerar l'experiència d'un sistema semàntic. Vam gravar la lectura quotidiana de dos participants durant dos mesos en una tabletta, generant mostres individuals de corpus de 300/500K fitxes. Then we trained word2vec models from individual corpora and a 70 million-sentence newspaper corpus to obtain individual and norm-based long-term memory structure.  Per provar si el corpore individual pot fer millors prediccions per a una tasca cognitiva de recuperació de memòria a llarg termini, vam generar materials d'estímul composts de 134 frases amb probabilitats de paraules individuals i basades en normes no correlacionades. For the subsequent eye tracking study 1-2 months later, our regression analyses revealed that individual, but not norm-corpus-based word probabilities can account for first-fixation duration and first-pass gaze duration.  La llargada de la paraula afectava addicionalment la duració de la mirada i la duració total de la mirada. Els resultats suggereixen que el corpora representant de l'estructura de memòria a llarg termini d'un individu pot explicar millor el rendiment de lectura que un corpus normal, i que la informació adquirida fa poc s'accede ràpidament a la llexica.", 'et': 'Korpust, millest õpetatakse ennustavat keelemudelit, võib pidada semantilise süsteemi kogemuseks. Salvestasime kahe osaleja igapäevast lugemist kahe kuu jooksul tahvelarvutil, genereerides individuaalsed korpusproovid 300/500K tokeniga. Seejärel koolitasime Word2vec mudeleid individuaalsetest korpustest ja 70 miljoni lausega ajalehekorpusest, et saada individuaalne ja normipõhine pikaajaline mälustruktuur. Et testida, kas individuaalsed korpused suudavad teha paremaid prognoose pikaajalise mälu taastamise kognitiivsele ülesandele, loosime stimuleerimismaterjalid, mis koosnevad 134 lausest korrigeerimata individuaalsete ja normipõhiste sõnatõenäosustega. Järgnevas silmade jälgimise uuringus 1–2 kuud hiljem näitasid meie regressioonianalüüsid, et individuaalsed, kuid mitte normkorpusel põhinevad sõnade tõenäosused võivad arvestada esmase fikseerimise kestust ja esmase pilgu kestust. Sõna pikkus mõjutas lisaks pilgu kestust ja vaatamise kogukestust. Tulemused näitavad, et üksikisiku pikaajalise mälu struktuuri esindavad korpused suudavad paremini selgitada lugemisjõudlust kui normkorpus ning et hiljuti omandatud teabele pääseb leksikaalselt kiiresti ligi.', 'cs': 'Korpus, ze kterého je trénován prediktivní jazykový model, lze považovat za zkušenost sémantického systému. Zaznamenali jsme každodenní čtení dvou účastníků po dobu dvou měsíců na tabletu a generovali jednotlivé korpusové vzorky 300/500K tokenů. Následně jsme trénovali Word2vec modely z jednotlivých korpusů a 70-milionů vět novinového korpusu, abychom získali individuální a normově založenou strukturu dlouhodobé paměti. Abychom testovali, zda jednotlivé korpusy dokážou lépe předpovědět kognitivní úlohu získávání dlouhodobé paměti, vytvořili jsme stimulační materiály sestávající z 134 vět s nekorelovanou individuální a normou pravděpodobností slov. Pro následnou eye trackingovou studii o dva měsíce později naše regresní analýzy odhalily, že individuální pravděpodobnosti slov založené na normálním korpusu mohou zohlednit délku první fixace a délku pohledu prvního průchodu. Délka slova navíc ovlivnila délku pohledu a celkovou dobu sledování. Výsledky naznačují, že korpusy reprezentativní pro strukturu dlouhodobé paměti jedince mohou lépe vysvětlit čtení výkonu než normální korpus a že nedávno získané informace jsou lexicky rychle přístupné.', 'fi': 'Korpus, josta ennakoivaa kielimallia koulutetaan, voidaan pitää semanttisen järjestelmän kokemuksena. Tallensimme kahden osallistujan jokapäiväisen lukemisen tabletilla kahden kuukauden ajan luoden yksilöllisiä korpusnäytteitä 300/500K poleteista. Tämän jälkeen koulutimme Word2vec-malleja yksittäisistä korpusista ja 70 miljoonan lauseen sanomalehtikorpusesta yksilöllisen ja normipohjaisen pitkän aikavälin muistirakenteen saamiseksi. Testataksemme, pystyvätkö yksittäiset korpuset ennustamaan paremmin pitkän aikavälin muistinpalautustehtävää, kehitimme ärsykemateriaalia, joka koostuu 134 lauseesta, joilla on korreloimattomat yksilö- ja normipohjaiset sanatodennäköisyydet. Seuraavassa silmänseurantatutkimuksessa 1–2 kuukautta myöhemmin regressioanalyysimme osoittivat, että yksilöllinen, mutta ei normikorpus-pohjainen sanatodennäköisyys voi selittää ensimmäisen kiinnityksen keston ja ensimmäisen katseen keston. Sanan pituus vaikutti lisäksi katseen kestoon ja katselun kokonaiskestoon. Tulokset viittaavat siihen, että yksilön pitkäaikaista muistirakennetta edustavat korpuset pystyvät selittämään lukusuorituskykyä paremmin kuin normikorpus ja että äskettäin hankittu tieto on lexikaalisesti nopeasti käytettävissä.', 'ha': "Corbus, wanda aka sanar da misalin harshe mai basĩri daga gare shi, za'a iya ƙayyade ni'anar wata na'urar mutane. Mun rubuta karatun karatun biyu mãsu mushiriki a kõwane yini a kan wani ajalin, kana samulin nau'i-nau'i 300/50,000. Sa'an nan kuma muka sanar da misalin word2ve daga makampuni guda da wata takarda 70 millionci na zartar da shi dõmin ka sami tsarin memorin ɗabi'a da a kan zaman shida. Dõmin ka jarraba, ko ko komaniya guda na iya samar kunyar wani aikin kwamfyuta da za'a iya kõma wa kumbarin zaman mutane, kuma mun sami abubuwa masu amfani da kuma masu kamfata 134 ne da saurarin da ba'a samu'a da saurin da ke rubutu ba. Ga da aka biyar fitina ɗin ƙaranci da aka bi aikin hanyoyi 1-2 watanni bayan, Analyyinmu na musammi ya bayyana cewa mutum guda, kuma amma, bã da yiwuwa masu yiwuwa da aka rubutu da kalmar-korbas, yana iya ƙidãya ga durar-fixi na farkon-fixi da ke ƙara kalma. @ info: whatsthis Mataimakin yana gaya cewa makampuni na ƙididdige tsarin memory na guda, zai iya fi canza karatun karatun mafiya alhẽri daga karatun nauyi na rubutu, kuma a yanzu da aka sami lãbãri, za'a iya amfani da shi ga haraka.", 'sk': 'Korpus, iz katerega se usposablja napovedni jezikovni model, se lahko šteje za izkušnjo semantičnega sistema. Dva meseca smo na tabličnem računalniku beležili vsakodnevno branje dveh udeležencev in ustvarili posamezne korpusne vzorce 300/500K žetonov. Nato smo usposobili modele word2vec iz posameznih korpusov in 70 milijonov stavkov časopisnega korpusa, da bi pridobili individualno in normalno dolgoročno spominsko strukturo. Da bi preizkusili, ali lahko posamezni korpusi bolje napovedujejo kognitivno nalogo dolgoročnega spomina, smo ustvarili dražilne materiale, sestavljene iz 134 stavkov z nepovezanimi individualnimi in normalnimi verjetnostmi besed. V naslednji študiji sledenja oči 1–2 meseca kasneje so naše regresijske analize pokazale, da lahko posamezne verjetnosti besed, ki temeljijo na normalnem korpusu, upoštevajo trajanje prve fiksacije in trajanje prvega prehoda pogleda. Dolžina besede je dodatno vplivala na trajanje pogleda in celotno trajanje ogleda. Rezultati kažejo, da lahko korpusi, reprezentativni za dolgoročno spominsko strukturo posameznika, bolje razložijo učinkovitost branja kot normni korpus in da so nedavno pridobljene informacije leksikalno dostopne hitro.', 'jv': 'Cebutuh (cara-cara), segalui kang sampeyan akeh dumadhi, iso disenyongno sistem sematik. Awak dhéwé éntuk sistem sing dibaké durung sampek durung kanggo nyelaran ning sampek bingi, nggawe sampek karo perusahaan sing katêpakan karo Token Amargi punika, awak dhéwé cara-cara sistem 2vec sing sami nggawe nguasai perusahaan lan sami punika, 75 milion dolar Jejaring Nanging ketemutan kanggo langgambar deweke sampeyan 1-2 menggang sakjane, refressi dipunangé awak dhéwé, pero perusahaan-perusahaan kuwi wis dipunangé perusahaan langgambar sabên tanggal sabên. politenessoffpolite"), and when there is a change ("assertivepoliteness Rejaleng wong-wong supayano karo bener-wong liyane kanggo nguasai perbudhakan dumadhi kapan nguasai winih dhéwé sing luwih apik bakal nguasai basa gambaran karo perbudhakan Norm, lan akeh informasi sing isin yang luwih apik dhéwé.', 'he': 'הקורפוס, ממנו מודל שפה צפוי מאומן, יכול להיחשב ניסיון של מערכת סמנטית. הקלטנו קריאה יומית של שני משתתפים במשך חודשיים על לוח, יוצרים דגימות גופוס בודדות של 300/500 אלף סימנים. ואז אימנו דוגמנים של מילים 2vec מקופורה בודדת וקופורוס עיתונאי של 70 מיליון משפטים כדי להשיג מבנה זיכרון לטווח ארוך מבוסס על נורמה. כדי לבדוק אם גופרה בודדת יכולה לעשות חזיונות טובים יותר למשימה קוגניטיבית של שיחזור זיכרון לטווח ארוך, יצרנו חומרי גירוי שמכילים 134 משפטים עם סבירות מילים אינדיבידיבידיות ובסיכויים נורמליים. למחקר אחר כך על עקבות עיניים חודשים או חודשיים לאחר מכן, ניתוח הגדרה שלנו חשף כי סיכויות מילים בודדות, אבל לא מבוססת על נורם-קורפוס יכולות לחשבון על אורך הקישור הראשון ולאורך המבט הראשון. אורך המילה משפיעה באופן נוסף על אורך המבט וכל אורך המבט. התוצאות מצביעות כי נציג הקופורה למבנה הזיכרון לטווח ארוך של אדם יכול להסביר טוב יותר ביצועי קריאה מאשר נורם קורפוס, ושמידע שנרכש לאחרונה נגיע בקסמית מהר.', 'bo': 'སྒུང་འཛིན་འདི་དག་གི་སྔོན་འཛིན་གྱི་སྐད་ཡིག་ཆའི་མ་དཔེ་གཙོ་རིམ་ཅིག་ལྟ་བུ་བཏང་ཡོད། ང་ཚོས་ཟླ་བ་གཅིག་གི་ནང་དུ་མཉམ་པའི་ཞུགས་སྐབས་རེར་བཞི་པོ་གཉིས་ཀྱི་ཀློག་འཇུག་བྲིས་ཡོད། དེ་ནས་ངེད་ཚོའི་ནང་གི་དུས་ཡོད་པའི་བརྗོད་བ་2vec མིག་གཟུགས་རིས་སྒེར་གྱི་དབུས་པ་དང་། ཚིག་ཡིག་འཕྲིན་ཡིག་ཚོགས་སྦྱོར་བ་བ To test whether individual corporations can make better predictions for a long-term memory retrieval of memory, we generated stimulus materials consisting of 134 sentences with uncorrelated individual and norm-based word probabilities. འོན་ཀྱང་། མི་ཟླ་༡་གཉིས་ཀྱི་རྗེས་སུ་གལ་བལྟ་ཀློག་གི་ནང་དུ་ང་ཚོའི་བསྡུར་བརྟན་དཔྱད་ནི། ཡི་གེའི་རིང་ཚད་ཀྱང་ཁ་སྐོར་བསྐྱེད་པའི་མཐོང་ནུས་དང་བསྡུས་ཀློག་སྟངས་ཀྱི་དུས་ཚོད། གནད་དོན་དག་འབྲས་བ་ནི་སྒེར་གྱི་རྩ་འབྲེལ་པོ་ཞིག་གི་ཚད་འཛིན་གྱི་སྒྲིག'}
{'en': 'Less is Better : A cognitively inspired unsupervised model for language segmentation', 'ar': 'الأقل هو الأفضل: نموذج مستوحى معرفيًا غير خاضع للإشراف لتجزئة اللغة', 'fr': 'Less is Better\xa0: un modèle non supervisé inspiré par la cognition pour la segmentation linguistique', 'pt': 'Menos é melhor: um modelo não supervisionado de inspiração cognitiva para segmentação de linguagem', 'es': 'Menos es mejor: un modelo no supervisado de inspiración cognitiva para la segmentación del lenguaje', 'ja': 'Less is Better ：言語セグメンテーションのための認知的にインスピレーションを受けた監督されていないモデル', 'zh': '少即是好:一受识觉之语细分无监模形', 'hi': 'कम बेहतर है: भाषा विभाजन के लिए एक संज्ञानात्मक रूप से प्रेरित असुरक्षित मॉडल', 'ru': 'Less is Better: когнитивно вдохновленная неконтролируемая модель сегментации языка', 'ga': 'Tá Lúide Is Fearr: Samhail neamh-mhaoirsithe spreagtha go cognaíoch do dheighilt teanga', 'ka': 'უფრო მეტი უფრო მეტია: კონციგურად ინტექსურებულია ენის სეგენდაციის მოდელი', 'hu': 'Kevesebb jobb: A nyelvi szegmentáció tudatosan inspirált, felügyelet nélküli modell', 'el': 'Λιγότερο είναι καλύτερο: Ένα γνωστικά εμπνευσμένο χωρίς επίβλεψη μοντέλο για γλωσσική κατάτμηση', 'it': 'Less is better: un modello non supervisionato ispirato cognitivamente per la segmentazione linguistica', 'lt': 'Mažesnis yra geresnis: pažintingai įkvėptas nepastebimas kalbų segmentacijos model is', 'mk': 'Помалку е подобро: Когнитивно инспириран ненадгледуван модел за сегментација на јазикот', 'kk': 'Кең жақсы: Тілді сегментациялау үшін көңіл түсіндірілмеген үлгі', 'ml': 'കുറഞ്ഞത് നല്ലതാണ്: ഭാഷയുടെ വിഭാഗത്തിനുള്ള സംരക്ഷണം സൂക്ഷിക്കപ്പെടാത്ത ഒരു മോഡല്\u200d ആജ്ഞാപിക്കുക', 'ms': 'Kurang lebih baik: Model tidak diawasi secara kognitif untuk segmen bahasa', 'mn': 'Хоёр бага нь илүү сайн: хэл хэлбэрийн загварын тулд мэдлэгтэй урам зориулсан загвар', 'mt': 'Inqas huwa A ħjar: Mudell mhux sorveljat ispirat b’mod konjittiv għas-segmentazzjoni tal-lingwi', 'no': 'Mindre er bedre: ein kognitivt inspirert ikkje oppretta modell for språk-segmentering', 'pl': 'Less is better: inspirowany poznawczo model segmentacji językowej bez nadzoru', 'ro': 'Mai puțin este mai bine: un model nesupravegheat inspirat cognitiv pentru segmentarea limbii', 'sr': 'Manje je bolje: kognitivno inspirisan model za segmentaciju jezika', 'si': 'පොඩ්ඩක් හොඳයි: භාෂාව සැකසුම් වෙනුවෙන් ප්\u200dරශ්නයක් නැති ප්\u200dරශ්නයක්', 'so': 'Wax ka yar waxaa ka wanaagsan: Tusaale aan aqoonta lagu soo dhiibay oo aan la ilaalin karin ee qeybinta luuqada', 'sv': 'Mindre är bättre: En kognitivt inspirerad modell för språksegmentering', 'ta': 'குறைந்தது சிறந்தது: மொழி பிரிவுப்பிற்கான ஒரு குறைந்த தெரியாத மாதிரி', 'ur': 'کم بہتر ہے: زبان سگرمینٹ کے لئے ایک معلوم طریقے سے الهام کی جاتی ہے۔', 'uz': '@ info: whatsthis', 'vi': 'Ít hơn thì tốt hơn: một mô hình không giám sát được nhận thức cho phân chia ngôn ngữ', 'bg': 'По-малко е по-добре: Когнитивно вдъхновен ненадзорен модел за езикова сегментация', 'hr': 'Manje je bolje: kognitivno inspirirani neodređeni model za segmentaciju jezika', 'da': 'Less is Better: En kognitivt inspireret model for sprogsegmentering', 'nl': 'Less is Better: Een cognitief geïnspireerd model voor taalsegmentatie zonder toezicht', 'de': 'Weniger ist besser: Ein kognitiv inspiriertes, unbeaufsichtigtes Modell für Sprachsegmentierung', 'ko': '적을수록 좋다: 인지적 계발을 받는 무감독 언어 분할 모델', 'fa': 'کوچکتر بهتر است: یک مدل غیرقابل تحریک برای جدایی زبان', 'id': 'Kurang lebih baik: Model tidak diawasi secara kognitif untuk segmen bahasa', 'sw': 'Unache ni bora zaidi: Mtindo uliohamasisha kwa ufahamu usio na uhakika wa kutengeneza lugha', 'tr': 'Biraz gowy: bilinç tertiblemek üçin agalanmaýan nusga', 'sq': 'Më pak është më mirë: Një model i frymëzuar në mënyrë kognitive pa mbikqyrje për segmentimin e gjuhës', 'af': "minder is beter: 'n Kognitief inspireer ononderwerpende model vir taal segmentasie", 'am': 'ትንሹ ይሻላል፤ ለቋንቋ segmentation ማሳየት በብልሃት ያልተማረከ ሞዴል', 'hy': 'Ավելի լավ է. ճանաչողական ոգեշնչված լեզվի սեգմենցիայի առանց վերահսկվող մոդել', 'az': 'Daha az daha yaxşıdır: Dil segmentasiyonu üçün bilikli təşkil edilməmiş modeli', 'bn': 'কম ভাল: ভাষার বিভাগের জন্য একটি অরক্ষিত মডেল অনুপ্রাণিত করা হয়েছে', 'bs': 'Manje je bolje: kognitivno inspirisan model za segmentaciju jezika', 'ca': 'Menos és millor: Un model sense supervisió, inspirat cognitivament, per a la segmentació del llenguatge', 'et': 'Vähem on parem: kognitiivselt inspireeritud järelevalveta keele segmenteerimise mudel', 'cs': 'Méně je lepší: Kognitivně inspirovaný model pro segmentaci jazyků bez dohledu', 'fi': 'Vähemmän on parempaa: Kognitiivisesti inspiroitu kontrolloimaton malli kielen segmentoinnille', 'ha': "Babba da kyakkyawan: An yi wahayi da wani misali wanda ba'a tsare wa segment da harshen ba", 'sk': 'Manj je bolje: kognitivno navdihnjen neonadzorovan model segmentacije jezika', 'he': 'פחות זה טוב יותר: מודל לא מעורר השראה קוגניטיבית', 'jv': 'Next >', 'bo': 'Less is Better: cognitively inspired model for language segmentation'}
{'en': 'Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and  linguistic levels . Although we can do such unitization / segmentation easily, its  cognitive mechanism  is still not clear. This paper proposes an  unsupervised model , Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization / segmentation. LiB follows the principle of least effort and aims to build a lexicon which minimizes the number of unit tokens (alleviating the effort of analysis) and number of unit types (alleviating the effort of storage) at the same time on any given corpus. LiB’s workflow is inspired by empirical cognitive phenomena. The design makes the mechanism of LiB cognitively plausible and the computational requirement light-weight. The lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a plausible proxy of the  mental lexicon .', 'ar': 'يعالج مستخدمو اللغة النطق من خلال تقسيمها إلى وحدات معرفية عديدة ، والتي تختلف في أحجامها ومستوياتها اللغوية. على الرغم من أنه يمكننا القيام بهذه الوحدة / التجزئة بسهولة ، إلا أن آليتها المعرفية لا تزال غير واضحة. تقترح هذه الورقة نموذجًا غير خاضع للإشراف ، أقل هو أفضل (LiB) ، لمحاكاة العملية الإدراكية البشرية فيما يتعلق بتوحيد / تجزئة اللغة. يتبع LiB مبدأ أقل جهد ويهدف إلى بناء معجم يقلل من عدد الرموز المميزة للوحدة (التخفيف من جهد التحليل) وعدد أنواع الوحدات (تخفيف جهد التخزين) في نفس الوقت على أي مجموعة معينة. إن سير عمل LiB مستوحى من الظواهر المعرفية التجريبية. يجعل التصميم آلية LiB معقولة معرفياً والمتطلبات الحسابية خفيفة الوزن. يقدم المعجم الذي تم إنشاؤه بواسطة LiB أفضل أداء بين الأنواع المختلفة من المعاجم (مثل كلمات الحقيقة الأساسية) من وجهة نظر نظرية المعلومات ووجهة نظر معرفية ، مما يشير إلى أن معجم LiB قد يكون وكيلًا معقولًا للمعجم العقلي.', 'fr': "Les utilisateurs de langues traitent les énoncés en les segmentant en plusieurs unités cognitives, dont la taille et le niveau linguistique varient. Bien que nous puissions faire une telle unitisation/segmentation facilement, son mécanisme cognitif n'est toujours pas clair. Cet article propose un modèle non supervisé, Lessis-Better (LiB), pour simuler le processus cognitif humain en ce qui concerne l'unitisation/segmentation du langage. LiB suit le principe du moindre effort et vise à créer un lexique qui minimise le nombre de jetons d'unité (allégeant l'effort d'analyse) et le nombre de types d'unités (allégeant l'effort de stockage) en même temps sur un corpus donné. Le flux de travail de LiB s'inspire de phénomènes cognitifs empiriques. La conception rend le mécanisme de LiB cognitivement plausible et l'exigence informatique légère. Le lexique généré par LiB fonctionne le mieux parmi les différents types de lexiques (par exemple, les mots de vérité de terrain) à la fois d'un point de vue théorique de l'information et d'un point de vue cognitif, ce qui suggère que le lexique LiB peut être un proxy plausible du lexique mental.", 'es': 'Los usuarios de idiomas procesan los enunciados segmentándolos en muchas unidades cognitivas, que varían en tamaño y nivel lingüístico. Aunque podemos hacer esta unificación/segmentación fácilmente, su mecanismo cognitivo aún no está claro. Este artículo propone un modelo no supervisado, Menos es mejor (LiB), para simular el proceso cognitivo humano con respecto a la unitización/segmentación del lenguaje. LiB sigue el principio del mínimo esfuerzo y tiene como objetivo construir un léxico que minimice el número de tokens de unidad (aliviando el esfuerzo de análisis) y el número de tipos de unidades (aliviando el esfuerzo de almacenamiento) al mismo tiempo en cualquier corpus dado. El flujo de trabajo de LiB se inspira en fenómenos cognitivos empíricos. El diseño hace que el mecanismo de LiB sea cognitivamente plausible y el requisito computacional sea ligero. El léxico generado por LiB funciona mejor entre los diferentes tipos de léxicos (por ejemplo, palabras de verdad básica) tanto desde una perspectiva teórica de la información como cognitiva, lo que sugiere que el léxico de LiB puede ser un sustituto plausible del léxico mental.', 'pt': 'Os usuários da linguagem processam os enunciados segmentando-os em muitas unidades cognitivas, que variam em seus tamanhos e níveis linguísticos. Embora possamos fazer essa unitização/segmentação com facilidade, seu mecanismo cognitivo ainda não está claro. Este artigo propõe um modelo não supervisionado, Less-is-Better (LiB), para simular o processo cognitivo humano no que diz respeito à unitização/segmentação da linguagem. LiB segue o princípio do menor esforço e visa construir um léxico que minimize o número de tokens de unidade (aliviando o esforço de análise) e o número de tipos de unidade (aliviando o esforço de armazenamento) ao mesmo tempo em qualquer corpus. O fluxo de trabalho do LiB é inspirado em fenômenos cognitivos empíricos. O design torna o mecanismo de LiB cognitivamente plausível e o requisito computacional leve. O léxico gerado pelo LiB tem o melhor desempenho entre os diferentes tipos de léxicos (por exemplo, palavras de verdade) tanto do ponto de vista teórico da informação quanto do ponto de vista cognitivo, o que sugere que o léxico LiB pode ser um proxy plausível do léxico mental.', 'ja': '言語使用者は、多くの認知単位に分割することによって発話を処理します。これらの単位は、そのサイズと言語レベルによって異なります。 このような単位化/セグメンテーションは容易にできるが、その認知メカニズムはまだ明確ではない。 この論文では、言語の単位化/セグメンテーションに関して人間の認知プロセスをシミュレートするための、監督されていないモデルであるLess - Is - Better （ LiB ）を提案している。 LiBは、最小努力の原則に従い、任意のコーパス上の単位トークンの数（分析の手間を軽減）と単位タイプの数（記憶の手間を軽減）を同時に最小限に抑える辞書を構築することを目的としています。 LiBのワークフローは、経験的な認知現象からインスピレーションを受けています。 LiBのメカニズムは、認知的に妥当であり、計算要件は軽量である。 LiBによって生成された辞書は、情報理論的ビューと認知的ビューの両方から異なるタイプの辞書（例えば、真実の単語）の中で最高のパフォーマンスを発揮し、これは、LiB辞書がメンタル辞書の妥当な代用であり得ることを示唆する。', 'zh': '语用户细分以处言,单元大小言语各有差。 虽易为单元化/分,其知机犹未可知。 本文设无监督模形,曰"少即即好"(LiB),以拟人言单元化/分裂之迹。 LiB循至小之道,指立一词典,兼于一给定之语料库上最小化令牌之数(轻析之功)与单之数(轻储)。 LiB事行程见知。 设LiB之机,以知为理,而计其轻量级。 以信论见角,LiB生词典异类词典(真理词)最上,明LiB词典心理词典之理也。', 'hi': 'भाषा उपयोगकर्ता उन्हें कई संज्ञानात्मक इकाइयों में विभाजित करके उच्चारण को संसाधित करते हैं, जो उनके आकार और भाषाई स्तरों में भिन्न होते हैं। यद्यपि हम इस तरह के एकीकरण / विभाजन को आसानी से कर सकते हैं, लेकिन इसका संज्ञानात्मक तंत्र अभी भी स्पष्ट नहीं है। यह पेपर भाषा एकीकरण / विभाजन के संबंध में मानव संज्ञानात्मक प्रक्रिया का अनुकरण करने के लिए एक असुरक्षित मॉडल, कम-बेहतर (LiB) का प्रस्ताव करता है। LiB कम से कम प्रयास के सिद्धांत का पालन करता है और इसका उद्देश्य एक शब्दकोश का निर्माण करना है जो किसी भी दिए गए कॉर्पस पर एक ही समय में यूनिट टोकन (विश्लेषण के प्रयास को कम करने) और इकाई प्रकारों की संख्या (भंडारण के प्रयास को कम करना) की संख्या को कम करता है। LiB का वर्कफ़्लो अनुभवजन्य संज्ञानात्मक घटनाओं से प्रेरित है। डिजाइन LiB के तंत्र को संज्ञानात्मक रूप से प्रशंसनीय और कम्प्यूटेशनल आवश्यकता को हल्के वजन का बनाता है। LiB द्वारा उत्पन्न शब्दकोश विभिन्न प्रकार के शब्दकोशों (जैसे ग्राउंड-ट्रुथ शब्द) के बीच सबसे अच्छा प्रदर्शन करता है, दोनों एक सूचना-सैद्धांतिक दृष्टिकोण और संज्ञानात्मक दृष्टिकोण से, जो बताता है कि LiB शब्दकोश मानसिक शब्दकोश का एक प्रशंसनीय प्रॉक्सी हो सकता है।', 'ru': 'Языковые пользователи обрабатывают высказывания, сегментируя их на многие когнитивные единицы, которые различаются по своим размерам и языковым уровням. Хотя мы можем легко сделать такую унификацию/сегментацию, ее когнитивный механизм все еще не ясен. В этой статье предлагается неконтролируемая модель, Less-is-Better (LiB), для моделирования когнитивного процесса человека в отношении языковой унификации/сегментации. LiB следует принципу наименьших усилий и стремится построить лексикон, который минимизирует количество токенов единиц (облегчая усилия анализа) и количество типов единиц (облегчая усилия хранения) в то же время на любом данном корпусе. Рабочий процесс LiB вдохновлен эмпирическими когнитивными явлениями. Конструкция делает механизм LiB когнитивно правдоподобным и вычислительное требование легким. Лексикон, сгенерированный LiB, выполняет лучшие среди различных типов лексиконов (например, слова, основанные на истине) как с информационно-теоретической точки зрения, так и с когнитивной точки зрения, что предполагает, что лексикон LiB может быть правдоподобным прокси-сервером ментального лексикона.', 'ga': 'Próiseálann úsáideoirí teanga cainteanna trí iad a dheighilt ina lán aonad cognaíocha, a athraíonn a méideanna agus a leibhéil teanga. Cé gur féidir linn aonadú/deighilt den sórt sin a dhéanamh go héasca, níl a mheicníocht chognaíoch soiléir fós. Molann an páipéar seo múnla gan mhaoirseacht, Níos Fearr, Níos Fearr (LiB), chun an próiseas cognaíocha daonna a insamhladh maidir le haonú/deighilt teanga. Cloíonn LiB le prionsabal na hiarrachta is lú agus tá sé mar aidhm aige foclóir a chruthú a íoslaghdaíonn líon na n-airíonna aonaid (lena laghdaítear an iarracht anailíse) agus líon na gcineálacha aonaid (a mhaolaíonn an iarracht stórála) ag an am céanna ar aon chorpas ar leith. Tá feiniméin chognaíocha eimpíreacha spreagtha ag sreabhadh oibre LiB. Déanann an dearadh meicníocht LiB sochreidte go cognaíoch agus an riachtanas ríomhaireachtúil éadrom. Feidhmíonn an foclóir a ghineann LiB an chuid is fearr i measc cineálacha éagsúla foclóir (m.sh. focail fhírinneachta) ó dhearcadh faisnéise-teoiriceach agus ó dhearcadh cognaíocha, a thugann le tuiscint go bhféadfadh an foclóir LiB a bheith ina sheachvótálaí sochreidte den fhoclóir meabhrach.', 'hu': 'A nyelvhasználók a kifejezéseket úgy dolgozzák fel, hogy számos kognitív egységre szegmentálják, amelyek méretükben és nyelvi szintükben eltérőek. Bár könnyen meg tudjuk csinálni ezt az egyesítést/szegmentációt, kognitív mechanizmusa még mindig nem világos. A tanulmány egy felügyelet nélküli modellt, a Less-is-Better (LiB) javasol az emberi kognitív folyamat szimulálására a nyelvi egység/szegmentáció tekintetében. A LiB a legkisebb erőfeszítés elvét követi, és célja egy lexikon kialakítása, amely minimálisra csökkenti az egység tokenek számát (enyhítve az elemzés erőfeszítését) és az egységtípusok számát (enyhítve a tárolás erőfeszítését) egyidejűleg bármely korpuson. A LiB munkafolyamatát empirikus kognitív jelenségek inspirálják. A dizájn a LiB mechanizmusát kognitívan valószínűvé teszi és a számítási követelmény könnyűvé. A LiB által generált lexikon a különböző típusú lexikonok (pl. alap-igazság szavak) közül a legjobban teljesíti mind információelméleti, mind kognitív nézőpontból, ami arra utal, hogy a LiB lexikon a mentális lexikon valószínűsíthető proxija lehet.', 'el': 'Οι χρήστες γλωσσών επεξεργάζονται τις εκφράσεις διαιρώντας τις σε πολλές γνωστικές μονάδες, οι οποίες ποικίλουν ως προς το μέγεθος και τα γλωσσικά τους επίπεδα. Αν και μπορούμε να κάνουμε μια τέτοια ενοποίηση/τμηματοποίηση εύκολα, ο γνωστικός μηχανισμός της δεν είναι ακόμα σαφής. Η παρούσα εργασία προτείνει ένα μοντέλο χωρίς επίβλεψη, το Λιγότερο-είναι-Καλύτερο (LiB), για την προσομοίωση της ανθρώπινης γνωστικής διαδικασίας σε σχέση με τη γλωσσική ενότητα. Ακολουθεί την αρχή της ελάχιστης προσπάθειας και στοχεύει στην κατασκευή ενός λεξικού που ελαχιστοποιεί ταυτόχρονα τον αριθμό των μονάδων (μειώνοντας την προσπάθεια ανάλυσης) και τον αριθμό των τύπων μονάδων (μειώνοντας την προσπάθεια αποθήκευσης) σε οποιοδήποτε δεδομένο σώμα. Η ροή εργασίας του είναι εμπνευσμένη από εμπειρικά γνωστικά φαινόμενα. Ο σχεδιασμός καθιστά τον μηχανισμό του γνωστικά εύλογο και την υπολογιστική απαίτηση ελαφριά. Το λεξικό που παράγεται από το LiB αποδίδει το καλύτερο μεταξύ διαφορετικών τύπων λεξικών (π.χ. λέξεις βασικής αλήθειας) τόσο από άποψη πληροφορίας όσο και από γνωστική άποψη, γεγονός που υποδηλώνει ότι το λεξικό LiB μπορεί να είναι ένας εύλογος αντιπρόσωπος του νοητικού λεξικού.', 'ka': 'ენის მომხმარებელი განსაზღვრებების გამოყენება, რომლებიც ისინი კონციენტიურ ერთეულებში განსხვავებულია, რომლებიც ისინი ზომის და ენგუმისტიური დონეში გან თუმცა ჩვენ შეგვიძლია ასეთი ერთიზაცია/სეგენდაცია ადვილად გავაკეთოთ, ის კონციგური მექანიზაცია არ არის წესი. ეს დოკუნტიური მოდელის შესაძლებელია, უფრო უკეთესია (LiB), რომ ადამიანის კონციგური პროცესის სიმულაცია ენის ერთიზაცია/სეგმენტირებაზე. LiB-ს შემდეგ მინუს წარმოდგენის პრინციპი და მიზეზია, რომ ლექსიკონის შექმნა, რომელიც მინუს წარმოდგენების რაოდენობა (ანალიზების წარმოდგენება) და წარმოდგენების რაოდენობის რაოდენობა (დამატების წარმოდგენ ლიბის სამუშაო ფენომენები იქნება იმპერიკალური კონფიციური ფენომენებით. დიზაინი იქნება LiB-ის კონციონიტურად შესაძლებელი მექანიზმის და კომპუტაციალური შესაძლებლობების სიმაღლე. LiB-ის შექმნილი ლექსიკონი ყველაზე საუკეთესო ლექსიკონის ტიპების (მაგალითად სამყარო სიტყვების სიტყვები) ინფორმაციის-ტეორეტიკური ხედავადან და კონციენტიური ხედავადან, რომელიც იტყვებს, რომ LiB ლექსიკ', 'it': "Gli utenti di lingue elaborano le parole segmentandole in molte unità cognitive, che variano nelle loro dimensioni e livelli linguistici. Anche se possiamo fare tale unificazione/segmentazione facilmente, il suo meccanismo cognitivo non è ancora chiaro. Questo articolo propone un modello non supervisionato, Less-is-Better (LiB), per simulare il processo cognitivo umano rispetto all'unità/segmentazione del linguaggio. LiB segue il principio del minimo sforzo e mira a costruire un lessico che minimizzi il numero di unità token (alleviando lo sforzo di analisi) e il numero di tipi di unità (alleviando lo sforzo di archiviazione) allo stesso tempo su un dato corpus. Il flusso di lavoro di LiB è ispirato da fenomeni cognitivi empirici. Il design rende il meccanismo di LiB cognitivamente plausibile e il requisito computazionale leggero. Il lessico generato da LiB esegue il meglio tra i diversi tipi di lessici (ad esempio parole di verità di terra) sia da un punto di vista teorico-informativo che cognitivo, il che suggerisce che il lessico LiB può essere un plausibile proxy del lessico mentale.", 'kk': 'Тілді пайдаланушылар сөздерді көптеген көптеген көптеген бірліктерге шектеп, олардың өлшемдері мен лингвистикалық деңгейінде өзгертілген. Бұл бірліктік/сегментацияны оңай жасай аламыз, бірақ оның коgnitiv механизмі білмейді. Бұл қағаз тіл бірлігіне/сегментациясына қатынау үшін адамдардың коgnitivті процесін симулизациялау үшін әсер етілмеген үлгісін ұсынады. LiB кемсіздігінің басқасына қарайды, бірлік белгілер санын (анализ және бірлік түрлерін күшейту) мен бірлік түрлерін (сақтау жұмысын күшейту) деген лексиконы құруға мақсат береді. ЛиБ жұмыс жұмыс көзі импирикалық конифициялық пайдаланулардан түсіндіреді. Құрылғы LiB механизмін күнделікті және компьютерлік қажеттерінің көмегімен көмектесетін механизмін жасайды. LiB құрылған лексикан, мәлімет теориялық көрінісінен және конитивтік көрінісінен, LiB лексиканың психикалық лексиканың жақсы прокси болуын көрсетеді.', 'ms': 'Pengguna bahasa memproses ungkapan dengan menyegmen kepada banyak unit kognitif, yang berbeza dalam saiz dan aras bahasa mereka. Walaupun kita boleh melakukan kesatuan/segmen dengan mudah, mekanisme pengetahuannya masih tidak jelas. Kertas ini mencadangkan model yang tidak diawasi, Kurang-lebih-baik (LiB), untuk simulasi proses kognitif manusia terhadap persatuan/segmen bahasa. LiB mengikut prinsip kurang usaha dan bertujuan untuk membina leksikon yang menginimumkan bilangan token unit (mengurangi usaha analisis) dan bilangan jenis unit (mengurangi usaha penyimpanan) pada masa yang sama pada mana-mana korpus yang diberi. Aliran kerja LiB diinspirasi oleh fenomena kognitif empirik. Rancangan ini membuat mekanisme LiB secara kognitif boleh dipercayai dan keperluan perhitungan ringan. Leksikon yang dihasilkan oleh LiB melaksanakan yang terbaik diantara jenis-jenis leksikon yang berbeza (cth. kata-kebenaran-tanah) kedua-dua dari paparan maklumat-teori dan paparan kognitif, yang menyarankan bahawa leksikon LiB mungkin proksi yang mudah diterima bagi leksikon mental.', 'lt': 'Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and linguistic levels.  Nors mes galime padaryti tokią vienybę ir (arba) segmentaciją lengvai, jos pažintinis mechanizmas vis dar neaiškus. Šiame dokumente siūlomas nepastebimas model is „Mažesnis – geresnis“ (LiB), kuris imituotų žmogaus pažintinį procesą kalbų suvienodinimo ir (arba) segmentacijos atžvilgiu. LiB laikomasi mažiausios pastangos principo ir siekia sukurti lexikoną, kuriuo būtų kuo labiau sumažintas vieneto žymenų skaičius (mažinamos analizės pastangos) ir vieneto tipų skaičius (mažinamos saugojimo pastangos) kiekviename korpuse. LiB darbo srautas įkvėpiamas empiriniais kognityviniais reiškiniais. Pagal projektą LiB mechanizmas yra suprantamai patikimas ir skaičiavimo reikalavimas yra lengvas. LiB sukauptas leksikonas geriausiai veikia įvairių tipų leksikonus (pvz., žodžius iš žemės tiesos) tiek informaciniu teoriniu, tiek pažintiniu požiūriu, o tai rodo, kad LiB leksikonas gali būti tikėtinas protinio leksikono proxy.', 'mk': 'Корисниците на јазикот ги процесираат изразите со сегментирање на нив во многу когнитивни единици, кои се различни во нивните големини и јазични нивоа. Иако можеме лесно да направиме ваква единизација/сегментација, нејзиниот когнитивен механизам сé уште не е јасен. Овој весник предложува ненадгледуван модел, помалку е подобро (ЛиБ), за симулирање на човечкиот когнитивен процес во однос на јазичката единизација/сегментација. ЛиБ го следи принципот на најмалку напори и има за цел да изгради лексикон кој го минимизира бројот на единички знаци (олеснување на напорите за анализа) и бројот на единички типови (олеснување на напорите за складирање) истовремено на било кој одреден корпус. Работниот поток на ЛиБ е инспириран од емпирички когнитивни феномени. Дизајнот го прави механизмот на ЛиБ когнитивно веројатен и обврските барања лесна тежина. Лексиконот генериран од LiB го изведува најдоброто меѓу различните типови на лексикони (на пример, зборови на земја-вистина) како од информациски-теоретски поглед, така и од когнитивен поглед, што сугерира дека лексиконот LiB може да биде веројатен прокси на менталниот лексикон.', 'ml': 'ഭാഷ ഉപയോക്താവുകാര്\u200d വാക്കുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അവയെ ഒരുപാട് അറിവുള്ള യൂണിറ്റിലേക്ക് വേര്\u200dതിരിക്കുന്ന ഇത്രയും എളുപ്പമായി നമുക്ക് ഒരുമിച്ചിരിക്കാം ഈ പത്രത്തില്\u200d സൂക്ഷിച്ചിട്ടില്ലാത്ത ഒരു മോഡലിനെ പ്രായശ്ചിത്തമാക്കുന്നു, കുറഞ്ഞത്- അത്യുത്തമം (ലിബി), ഭാഷയുടെ യൂണിക്കേഷന്\u200d ലിബി ഒരു ലെക്സിക്ഷന്\u200d നിര്\u200dമ്മിക്കാനുള്ള ശ്രമങ്ങളുടെ കൂട്ടത്തില്\u200d പിന്തുടരുന്നു. അതിന്റെ ലക്ഷ്യത്തില്\u200d യൂണിറ്റിന്റെ എണ്ണം കുറഞ്ഞുകൊടുക്കുന്നു (അന് ലിബിയുടെ ജോലിയുടെ പ്രവൃത്തിയില്\u200d നിന്നും പ്രചോദിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. ഈ ഡിസൈന്\u200d ലിബിയുടെ മെക്കിനസിസ്റ്റമാക്കുന്നുണ്ടാക്കുന്നു. കണക്കൂട്ടിനുള്ള ആവശ്യം ലൈറ്റ് ഭാരം. ലിബി ഉണ്ടാക്കിയ ലെക്സിക്കോണ്\u200d വ്യത്യസ്ത തരത്തിലെ ലെക്സിക്കോണുകളില്\u200d ഏറ്റവും മികച്ച വാക്കുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. വിവരങ്ങള്\u200d തിയോറിക്കല്\u200d കാഴ്ചകളില്\u200d നിന്നും ഒര', 'mt': 'L-utenti tal-lingwi jipproċessaw il-kliem billi jissegraw f’ħafna unitajiet konjittivi, li jvarjaw fid-daqsijiet u l-livelli lingwistiċi tagħhom. Għalkemm nistgħu nagħmlu tali unitizzazzjoni/segmentazzjoni faċilment, il-mekkaniżmu konjittiv tiegħu għadu mhux ċar. Dan id-dokument jipproponi mudell mhux sorveljat, Inqas Aħjar (LiB), biex jissimula l-proċess konjittiv uman fir-rigward tal-unitizzazzjoni/segmentazzjoni tal-lingwi. Il-LiB isegwi l-prinċipju tal-inqas sforz u għandu l-għan li jibni lexicon li jimminimizza n-numru ta’ tokens tal-unit à (li jtaffi l-isforz tal-analiżi) u n-numru ta’ tipi ta’ unità (li jtaffi l-isforz tal-ħżin) fl-istess ħin fuq kwalunkwe korpus partikolari. Il-fluss tax-xogħol tal-LiB huwa ispirat minn fenomeni konjittivi empiriċi. Id-disinn jagħmel il-mekkaniżmu tal-LiB konjittivament plawżibbli u r-rekwiżit tal-komputazzjoni ħafif. The lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a plausible proxy of the mental lexicon.', 'pl': 'Użytkownicy języków przetwarzają wypowiedzi dzieląc je na wiele jednostek poznawczych, które różnią się wielkością i poziomem językowym. Chociaż możemy zrobić taką jedność/segmentację łatwo, jej mechanizm poznawczy nadal nie jest jasny. W artykule zaproponowano model bez nadzoru, Less-is-Better (LiB), aby symulować ludzki proces poznawczy w odniesieniu do jedności/segmentacji języka. LiB przestrzega zasady najmniejszego nakładu i ma na celu zbudowanie leksykonu, który minimalizuje liczbę tokenów jednostkowych (zmniejszając wysiłek analizy) i liczbę typów jednostek (zmniejszając nakład przechowywania) jednocześnie na danym korpusie. Przepływ pracy LiB jest inspirowany empirycznymi zjawiskami poznawczymi. Konstrukcja sprawia, że mechanizm LiB jest poznawczo wiarygodny, a wymagania obliczeniowe są niewielkie. Wygenerowany przez LiB leksykon najlepiej sprawdza się wśród różnych rodzajów leksykonów (np. słów gruntowych) zarówno z punktu widzenia informacyjnego, jak i poznawczego, co sugeruje, że leksykon LiB może być wiarygodnym zastępcą leksykonu mentalnego.', 'mn': 'Холбооны хэрэглэгчид хэлний хэлбэрүүдийг олон мэдлэгтэй нэгжүүдэд хэлбэрүүдийн хэмжээнд, хэлний хэмжээнд өөр өөр өөр хэлбэрүүдийг хуваалцдаг. Бид ийм нэгтгэл/загвар амархан хийж чадна гэхдээ үүнийг мэдэх механизм тодорхой байхгүй. Энэ цаас хэлний нэгтгэл/загварын тухай хүний мэдлэгтэй процессийг шинэчлэх боломжгүй загварыг сануулдаг. ЛиБ бага хүч чадлын зарчмыг дагаж, нэгж тодорхойлолтыг багасгаж (шинжилгээний хүч чадлыг багасгаж) нэгж төрлийн тоо (хадгалах хүч чадлыг багасгаж) лексикон бүтээхийг зориулдаг. ЛиБийн ажлын урсгал нь эмперикийн мэдлэг үзэгдэл дээр урам зориулагддаг. Энэ загвар нь ЛиБ-ын мэдлэгтэй болон тооцооллын шаардлагатай жинг гэдэг механизм болгодог. ЛиБ-ын үүсгэсэн лексикон нь мэдээллийн теоретикийн үзэл болон мэдлэгтэй үзэлээс хамгийн шилдэг лексиконуудыг дамжуулдаг. Энэ нь ЛиБ лексикон сэтгэл санааны лексиконуудын хувьд итгэлтэй проксик байж болох юм.', 'no': 'Språkbrukarar prosesserer uttrykk ved å segmentera dei i mange kognitive einingar, som varierer i storleiken og språkbruknivåene sine. Selv om vi kan gjere slike uniteringa/segmenteringa enkelt, er den kognitiv mekanismen fremdeles ikkje klar. Denne papiren foreslår eit uverkjend modell, mindre er bedre (LiB), for å simulera menneskelige kognitivprosessen med respekt til språk-uniteringa/segmenteringa. LiB følgjer prinsippet av minste innsatt og mål å bygge ei leksikon som minimerer talet på einingstoken (å alleviare innsatsen til analysering) og talet på einingstypar (å alleviare innsatsen til lagring) samtidig på alle oppgjevne korpusar. LiB-arbeidsfløven er inspirert av empiriske kognitiv fenomen. Designen gjer mekanismen av LiB kognitivt tilgjengeleg og lett vekt på datamaskinen. Leksjonen laga av LiB utfører det best e mellom ulike typar leksikon (f.eks. bakgrunnsannhetsord) både frå ei informasjon-teoretisk vising og ein kognitivt vising, som tyder på at LiB-leksikon kan vera ein tilgjengeleg mellomtenar av den mentale leksikon.', 'ro': 'Utilizatorii de limbi străine procesează pronunțările prin segmentarea lor în mai multe unități cognitive, care variază în mărimea lor și nivelul lingvistic. Deși putem face o astfel de unitare / segmentare cu ușurință, mecanismul cognitiv nu este încă clar. Lucrarea propune un model nesupravegheat, Less-is-Better (LiB), pentru a simula procesul cognitiv uman în ceea ce privește unirea/segmentarea limbajului. LiB urmează principiul celui mai mic efort și își propune să construiască un lexicon care minimizează numărul de jetoane unitare (atenuând efortul de analiză) și numărul de tipuri de unități (atenuând efortul de stocare) în același timp pe orice corp dat. Fluxul de lucru al LiB este inspirat de fenomene cognitive empirice. Designul face ca mecanismul LiB să fie plauzibil cognitiv, iar cerința computațională să fie ușoară. Lexiconul generat de LiB realizează cel mai bine dintre diferitele tipuri de lexicoane (de exemplu, cuvinte de bază-adevăr), atât din punct de vedere informațional-teoretic, cât și din punct de vedere cognitiv, ceea ce sugerează că lexiconul LiB poate fi un proxy plauzibil al lexiconului mental.', 'so': 'Isticmaalayaasha luuqada ayaa hadal ku qoraya si ay u kala duwan yihiin heerarkooda iyo luuqadaha. In kastoo aynu si fudud u sameyn karno isku-qabsiga/qeybinta, meymiskiisa aqoonta weli ma cadna. Kanu wuxuu soo jeedaa tusaale aan la ilaalinayn, Less-is-Better (LiB), in loo simo koorasyada dadka oo ku saabsan isku-qabsashada/qeybinta luuqada. LiB wuxuu raacaa shuruudaha ugu yaraan dadaalka, wuxuuna ku talo galaa in la dhiso leksikan, kaas oo hoos u dhigi karo tirada calaamadaha kooxaha (fududeynta kalluumeynta) iyo noocyada kooxaha ah (hoosaysiinta jahaadada) isla markaasna la sameyn karo qofka la siiyey. Shaqada shaqada ee LiB waxaa lagu waxyoodaa waxyaabo ku saabsan. Shaqooyinku waxay leedahay meymiska LiB oo aqoonta ku habboon iyo baahida xisaabta oo fudud. Leksikon oo LiB soo dhashay wuxuu sameeyaa noocyo kala duduwan oo leksikan ah (tusaale ahaan hadalka runta ah) oo ka mid ah muuqashada macluumaadka theoretical iyo muuqashada aqoonta, taas oo ku jeedaysa in leksikanka LiB uu noqon karo khatarka dhimirka.', 'sr': 'Korisnici jezika procesiraju izreke segmentiranjem ih u mnoge kognitivne jedinice, koje se razlikuju u njihovim veličinama i jezičkim nivoima. Iako možemo lako da uradimo takvu jedinizaciju/segmentaciju, njegov kognitivni mehanizam još uvek nije jasan. Ovaj papir predlaže nepotrebniji model, manje je bolje (LiB), da simulira ljudski kognitivni proces u pogledu ujedinjenja jezika/segmentacije. LiB prati princip najmanjih napora i cilja izgraditi leksikon koji minimizira broj znakova jedinica (olakšavanje napora analize) i broj tipa jedinica (olakšavanje napora skladišta) u isto vreme na bilo kojem određenom korpusu. LiB radni tok inspiriše empirički kognitivni fenomeni. Dizajn čini mehanizam kognitivno uvjerljivog LiB-a i lakše težine računalnih potreba. Leksikon koji je proizveden od LiB izvodi najbolje među različitim tipovima leksiona (npr. riječi zemaljske istine) i iz informativnog teorijskog pogleda i kognitivnog pogleda, što ukazuje na to da LiB leksion može biti uvjerljiv proksi mentalnog leksiona.', 'si': 'භාෂාව ප්\u200dරයෝජකයෝ කතාව ප්\u200dරකාශ කරනවා ඔවුන්ව ගොඩක් දැනගන්න ප්\u200dරයෝජනය යුනිත් වලට, ඒක ඔවුන්ගේ ප්\u200dර අපිට එච්චර එක්කම/විශේෂණයක් ලේසියෙන් කරන්න පුළුවන් නමුත්, ඒකේ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණය මේ පැත්තේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්නේ නැහැ ප්\u200dරශ්නයක්, less-is-Better (LiB), මිනිස්සු ප්\u200dරශ්නයක් භාෂාව යුනිකරණය/සෙ Name LiB ගේ වැඩ ප්\u200dරවේශය අධ්\u200dයාත්මක පරීක්ෂණ ප්\u200dරදේශයෙන් ප්\u200dරේෂණය කරනවා. මේ සිද්ධානය LiB ගේ පරීක්ෂණය සහ පරීක්ෂණය අවශ්\u200dය පරීක්ෂණයක් ලොකු බඩුවක් තියෙනවා. LiB නිර්මාණය කළ ලෙක්සිකෝන් වෙනස් වර්ගයක් ප්\u200dරශ්නයක් වලින් හොඳම ප්\u200dරශ්නයක් කරන්නේ (වර්ගයක් ප්\u200dරශ්නයක් වගේ) තොරතුරු සාධාරණාත්මක ප්\u200dරශ්නයක', 'sv': 'Språkanvändare bearbetar yttranden genom att segmentera dem i många kognitiva enheter, som varierar i storlek och språkliga nivåer. Även om vi lätt kan göra en sådan enhet/segmentering är dess kognitiva mekanism fortfarande inte klar. Denna uppsats föreslår en oövervakad modell, Less-is-Better (LiB), för att simulera den mänskliga kognitiva processen med avseende på språkförening/segmentering. LiB följer principen om minsta ansträngning och syftar till att bygga ett lexikon som minimerar antalet enhetstokens (lindrar ansträngningen av analys) och antalet enhetstyper (lindrar ansträngningen av lagring) samtidigt på en given corpus. LiB:s arbetsflöde är inspirerat av empiriska kognitiva fenomen. Konstruktionen gör mekanismen för LiB kognitivt rimlig och beräkningskravet lätt. Det lexikon som genereras av LiB presterar bäst bland olika typer av lexikon (t.ex. grundsanningsord) både ur en informationsteoretisk synvinkel och en kognitiv synvinkel, vilket tyder på att LiB lexikon kan vara en rimlig proxy för det mentala lexikonet.', 'ta': 'மொழி பயன்படுத்துபவர் Although we can do such unitization/segmentation easily, its cognitive mechanism is still not clear.  இந்த தாள் ஒரு பாதுகாப்பாக்கப்படாத மாதிரியை பரிந்துரைக்கிறது, குறைந்தது- சிறந்தது (லிபி), மனித குறிப்பிட்ட செயலை மொழி ஒன்றிணைப்பு லிபி முயற்சியின் குறைந்தபட்ச முயற்சியைப் பின்பற்றுகிறது மற்றும் கொடுக்கப்பட்ட கோப்புகளின் எண்ணிக்கையை குறைத்து விடுகிறது. லிபியின் வேலை முறைமையில் தெரிவிக்கப்படுகிறது. வடிவமைப்பு லிபியின் முறைமையை அறிவில்லாமல் மற்றும் கணக்கீட்டு தேவைப்படும் ஒளியை எடுக்கும். லிபி உருவாக்கப்பட்ட லெக்சிகோன் மிகவும் சிறந்த வகைகளில் உள்ள லெக்சிகோனை செயல்படுத்துகிறது (உதாரணமாக, நிலத்தில் உண்மையான வார்த்தைகள்) தகவல் தொடர்பு காட்சியில் இருந்தும', 'ur': 'زبان کارساز ان کی کلمات کو بہت سی معلومات یونیٹوں میں تقسیم کرتے ہیں جو ان کے اندازے اور زبان سطح میں متفاوت ہیں. اگرچہ ہم اس طرح یونیٹی/سیگنٹی آسان کر سکتے ہیں، اس کی شناخت مکانیزی ابھی صاف نہیں ہے. یہ کاغذ ایک ناپابندی موڈل کی پیشنهاد کرتا ہے، کم-is-Better (LiB) کہ انسان کی شناخت پرسس کو زبان یونیٹیزی/سیگنٹ کے بارے میں سیمولیٹ کرے۔ LiB کم تلاش کی اصل کا اتباع کرتا ہے اور ایک لکسون بنانے کا ارادہ کرتا ہے جس نے یونیٹ ٹاکنوں کی تعداد کو کم کر دیتا ہے اور یونیٹ کی تعداد کی (ذخیره کرنے کی کوشش) کے ساتھ (ذخیره کرنے کی کوشش کو کم کر دیتا ہے) ہر جسم پر۔ لیب کا کارفول امپریسی شناخت پڑھنے کے ذریعے الهام کیا جاتا ہے. ڈیزائن LiB کی مکانیزین کو پہچان سکتا ہے اور کمپیوٹر کی ضرورت ہلکا وزن کرتا ہے. LiB سے پیدا ہوا لکسون بہترین مختلف لکسانوں میں عمل کرتا ہے (جیسے ground-truth words) دونوں معلومات-theoretical view سے اور ایک معلومات نظر سے اور ایک معلومات نظر سے۔', 'uz': "Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and linguistic levels.  Agar biz bunday birlashtirish/birlashtirishni oson qila olamiz bo'lsa, uning kognitiv mechanisligi ham toʻgʻri emas. Bu hujjat tilni birlashtirish/birlashtirish haqida qo'llanmagan modelni yaratadi. LiB bir xil jarayonlarning asosini boshlaydi va leksisini yaratish uchun qanday qiladi. Bu paytda bir xil belgining soni yaratish (analytiklash jarayonini kamaytirish) va bir xil turlari (saqlash jarayonini kamaytirish) va bir necha xil turlarini (saqlash orqali yordam qiladi). LiB ish orqali muvaffaqiyatli muvaffaqiyatli narsa bilan ishlaydi. Dizayn LiB mechanisiyasini aniqlash va hisoblash talab qilinadi. LiB yaratilgan leksisini boshqa turlar leksikaning eng eng yaxshi ko'rini bajaradi, ma'lumot teoretikal koʻrinishida va kognitiv koʻrinishida bajaradi. LiB Lekson miya leksisining playin proksi bo'lishi mumkin.", 'vi': 'Người dùng ngôn ngữ phát ngôn bằng cách phân chia họ thành nhiều đơn vị nhận thức khác nhau về kích thước và mức độ ngôn ngữ. Mặc dù chúng ta có thể dễ dàng kết hợp và phân chia, nhưng khả năng nhận thức của nó vẫn chưa rõ ràng. Tờ giấy này đề xuất một mô hình không giám sát, Bớt-được-hơn (LiB) để mô phỏng tiến trình nhận thức con người về sự thống nhất ngôn ngữ/phân chia. LiB tuân theo nguyên tắc ít nỗ lực nhất và nhằm xây dựng một ngôn ngữ có hạn chế tối thiểu số hiệu ứng đơn vị (giảm bớt nỗ lực phân tích) và số dạng đơn vị (giảm giảm bớt nỗ lực của nhà kho) cùng lúc trên một tập thể nào đó. Việc làm của LiB được truyền cảm hứng từ hiện tượng nhận thức. Thiết kế làm cơ chế của LiB có khả năng nhận thức và đòi hỏi tính trọng lượng ánh sáng. Từ ngữ được sinh ra bởi LiB thực hiện tốt nhất trong các dạng ngôn ngữ khác nhau (ví dụ như từ chân trần) cả từ một quan điểm thông tin-lý thuyết và một quan điểm nhận thức, cho thấy ngôn ngữ trói có thể là một biểu hiện hợp lý của ngôn ngữ tâm thần.', 'bg': 'Потребителите на езика обработват изказванията, като ги сегментират в много когнитивни единици, които варират по размер и езикови нива. Въпреки че можем да направим такава унитизация/сегментация лесно, нейният когнитивен механизъм все още не е ясен. В настоящата статия се предлага ненадзорен модел, който симулира човешкия когнитивен процес по отношение на езиковата унизация/сегментация. ЛиБ следва принципа на най-малко усилие и има за цел да изгради лексикон, който минимизира броя на единичните токени (облекчава усилията за анализ) и броя на типовете единици (облекчава усилията за съхранение) едновременно върху даден корпус. Работният поток на ЛиБ е вдъхновен от емпирични когнитивни явления. Дизайнът прави механизма на ЛиБ когнитивно правдоподобен, а изчислителните изисквания леки. Лексиконът, генериран от ЛиБ, се представя най-добре сред различните видове лексикони (напр. думи на основата на истината), както от информационно-теоретична гледна точка, така и от когнитивна гледна точка, което предполага, че ЛиБ лексиконът може да бъде правдоподобна проксия на психическия лексикон.', 'hr': 'Korisnici jezika obrađuju izraze segmentiranjem ih u mnoge kognitivne jedinice, koje se razlikuju u njihovim veličinama i jezičkim razinama. Iako možemo lako učiniti takvu jedinizaciju/segmentaciju, njen kognitivni mehanizam još uvijek nije jasan. Ovaj papir predlaže neodređen model, manje je-bolje (LiB), simulirati ljudski kognitivni proces u pogledu ujedinjenja jezika/segmentacije. LiB slijedi načelo najmanjih napora i cilj izgradnje leksikona koja smanjuje broj znakova jedinica (olakšavanje napora analize) i broj vrsta jedinica (olakšavanje napora skladišta) u isto vrijeme na bilo kojem određenom korpusu. LiB radni tok inspirira empirički kognitivni fenomeni. Dizajn čini mehanizam kognitivno uvjerljivog LiB i lakše težine računalnih zahtjeva. Leksikon koji je proizveden od LiB izvršava najbolje među različitim vrstama leksikona (npr. riječi zemaljske istine) i iz informativnog teorijskog pogleda i kognitivnog pogleda, što ukazuje na to da LiB leksikon može biti uvjerljiv proxy mentalnog leksikona.', 'da': "Sprogbrugere behandler udtalelser ved at segmentere dem i mange kognitive enheder, som varierer i deres størrelse og sproglige niveauer. Selvom vi nemt kan gøre sådan forening / segmentering, er dens kognitive mekanisme stadig ikke klar. Denne artikel foreslår en ikke-overvåget model, Less-is-Better (LiB), til at simulere den menneskelige kognitive proces med hensyn til sprogforening/segmentering. LiB følger princippet om mindste indsats og har til formål at opbygge et leksikon, der minimerer antallet af enhedstokens (letter indsatsen for analyse) og antallet af enhedstyper (letter indsatsen for lagring) på samme tid på en given korpus. LiB's arbejdsgang er inspireret af empiriske kognitive fænomener. Designet gør mekanismen for LiB kognitivt plausibel og beregningskravet let. Det leksikon, der genereres af LiB, udfører det bedste blandt forskellige typer af leksikoner (f.eks. jordsandhedsord) både ud fra et informationsteoretisk synspunkt og et kognitivt synspunkt, hvilket tyder på, at LiB leksikon kan være en plausibel proxy for det mentale leksikon.", 'nl': "Taalgebruikers verwerken uitspraken door ze te segmenteren in veel cognitieve eenheden, die variëren in grootte en taalniveau. Hoewel we zo'n eenheid/segmentatie gemakkelijk kunnen doen, is het cognitieve mechanisme nog steeds niet duidelijk. Deze paper stelt een onbeheerd model voor, Less-is-Better (LiB), om het menselijke cognitieve proces te simuleren met betrekking tot taalunitie/segmentatie. LiB volgt het principe van de minste inspanning en streeft naar het bouwen van een lexicon dat het aantal eenheden tokens (het verminderen van de inspanning van analyse) en het aantal eenheden types (het verminderen van de inspanning van opslag) tegelijkertijd op een gegeven corpus minimaliseert. De workflow van LiB is geïnspireerd op empirische cognitieve fenomenen. Het ontwerp maakt het mechanisme van LiB cognitief plausibel en de rekenkundige eis licht in gewicht. Het door LiB gegenereerde lexicon presteert het beste tussen verschillende soorten lexicons (bijv. grondwaarheidswoorden) zowel vanuit een informatietheoretisch als vanuit een cognitief perspectief, wat suggereert dat het LiB lexicon een plausibele proxy van het mentale lexicon kan zijn.", 'de': 'Sprachnutzer verarbeiten Äußerungen, indem sie sie in viele kognitive Einheiten unterteilen, die sich in ihrer Größe und ihrem Sprachniveau unterscheiden. Obwohl wir eine solche Vereinheitlichung/Segmentierung leicht durchführen können, ist ihr kognitiver Mechanismus immer noch nicht klar. Diese Arbeit schlägt ein unüberwachtes Modell vor, Less-is-Better (LiB), um den menschlichen kognitiven Prozess in Bezug auf Spracheinteilung/Segmentierung zu simulieren. LiB folgt dem Prinzip des geringsten Aufwands und zielt darauf ab, ein Lexikon zu erstellen, das die Anzahl der Unit-Tokens (die den Aufwand der Analyse verringern) und die Anzahl der Unit-Typen (die den Aufwand der Speicherung verringern) gleichzeitig auf einem gegebenen Korpus minimiert. Der Workflow von LiB ist inspiriert von empirischen kognitiven Phänomenen. Das Design macht den Mechanismus von LiB kognitiv plausibel und die Rechenanforderung leicht. Das von LiB generierte Lexikon schneidet unter verschiedenen Arten von Lexikonen (z.B. Ground-Truth-Wörtern) sowohl informationstheoretisch als auch kognitiv am besten ab, was darauf hindeutet, dass das LiB-Lexikon ein plausibler Proxy des mentalen Lexikons sein könnte.', 'id': 'Pengguna bahasa memproses ucapan dengan segmen mereka ke banyak unit kognitif, yang berbeda dalam ukuran dan tingkat bahasa mereka. Meskipun kita bisa melakukan unitisasi/segmentasi tersebut dengan mudah, mekanisme kognitifnya masih tidak jelas. This paper proposes an unsupervised model, Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization/segmentation.  LiB mengikuti prinsip dari paling sedikit usaha dan bermaksud untuk membangun sebuah leksikon yang mengurangi jumlah token unit (mengurangi usaha analisis) dan jumlah tipe unit (mengurangi usaha penyimpanan) pada waktu yang sama pada setiap tubuh tertentu. aliran kerja LiB diinspirasi oleh fenomena kognitif empiris. Desain membuat mekanisme LiB secara kognitif plausible dan keperluan komputasi berat ringan. Leksikon yang dihasilkan oleh LiB melakukan yang terbaik diantara jenis-jenis leksikon yang berbeda (contohnya kata-kata kebenaran-tanah) baik dari pandangan teori-informasi dan pandangan kognitif, yang menunjukkan bahwa leksikon LiB mungkin proxi yang plausible dari leksikon mental.', 'ko': '언어 사용자는 말을 많은 인지 단원으로 나누어 말을 처리하는데 이런 인지 단원의 크기와 언어 수준은 각각 다르다.비록 우리는 이런 단위화/분할을 쉽게 진행할 수 있지만 그 인지 메커니즘은 여전히 명확하지 않다.본고는 감독이 없는 언어 통일/절분 모델을 제시하여 인류가 언어 통일/절분 방면의 인지 과정을 모의하고자 한다.LiB는 최소한의 노력의 원칙에 따라 주어진 자료 라이브러리에 단원 표기 수량(분석 작업량 감소)과 단원 유형 수량(저장 작업량 감소)을 동시에 최소화하는 사전을 구축하고자 한다.LiB의 워크플로우는 경험적 인식 현상에 영감을 받습니다.이 설계는 LiB의 메커니즘을 인지적으로 합리적으로 하고 수요의 경량급을 계산할 수 있게 한다.정보 이론의 측면과 인지의 측면에서 볼 때 LiB가 생성한 어휘는 서로 다른 유형의 어휘(예를 들어 기본 사실어)에서 가장 잘 표현된다. 이것은 LiB어휘가 심리적 어휘의 합리적인 대리일 수 있음을 나타낸다.', 'fa': 'استفاده کنندگان زبان با تقسیم کردن آنها به واحدهای زیادی شناخته، که در اندازه و سطح زبان آنها متفاوت می\u200cشوند. اگرچه می\u200cتوانیم به آسانی این واحد/جدایی را انجام دهیم، مکانیسم شناختی آن هنوز روشن نیست. این کاغذ یک مدل غیرقابل تحریک پیشنهاد می\u200cکند، کمتر بهتر (LiB) برای شبیه\u200cسازی فرایند شناخته\u200cی انسان در مورد واحد/جدایی زبان. LiB از اصل کمترین تلاش پیروی می\u200cکند و هدف می\u200cکند که یک لکسیون بسازد که تعداد نشانه\u200cهای واحدی را کمترین می\u200cکند (کمترین تلاش تحلیل) و تعداد نوع واحدی را (کمترین تلاش ذخیره) در همین زمان بر هر کورپوس داده می\u200cکند. جریان کاری لیب توسط پدیده\u200cهای شناختی امپراتوری الهام می\u200cگیرد. طراحی مکانیسم LiB را به طور شناختی قابل توجه می\u200cکند و نیازهای محاسباتی را به وزن سبک می\u200cدهد. Lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a credible proxy of the mental lexicon.', 'sw': 'Watumiaji wa lugha wanaendesha hotuba kwa kuingiza katika vifaa vingi vya ujuzi, ambavyo vinatofautisha katika kiwango cha lugha na lugha. Ingawa tunaweza kufanya ushirikiano wa aina hiyo kwa urahisi, mfumo wake wa ujuzi bado si wazi. Gazeti hili linapendekeza muundo usio na ulinzi, Less-is-Bora (LiB), kuunganisha mchakato wa utambulisho wa binadamu kwa kuhusiana na umoja wa lugha/mgawanyiko wa lugha. LiB inafuata kanuni ya juhudi za chini na lengo la kutengeneza lexico ambalo linapunguza idadi ya alama za viungo (kupunguza juhudi za uchambuzi) na idadi ya aina za vifaa (kupunguza juhudi za kuhifadhi) wakati ule ule kwenye viungo vyote vilivyopewa. Maendeleo ya kazi ya LiB yanahamasishwa na hali ya uchunguzi. Mpango huu unafanya mfumo wa LiB kwa ufahamu na mahitaji ya hisabu kuwa na uzito mzito. Leksiko iliyotengenezwa na LiB inafanya vizuri zaidi miongoni mwa aina mbalimbali za lexico (kama vile maneno ya ukweli ya ardhi) kutoka kwenye mtazamo wa habari-theoretical na mtazamo wa kisiasa, inayopendekeza kuwa lexico la LiB inaweza kuwa mtazamo mzaha wa kisaikolojia wa akili.', 'af': "Taal gebruikers verwerk uitdrukkings deur hulle in baie kognitiewe eenhede te segmenteer, wat in hul grootte en lingwisiese vlakke verander. Alhoewel ons so eenheid/segmentasie maklik kan doen, is sy kognitiewe mekanisme nog nie duidelik nie. Hierdie papier voorstel 'n ononderwerpende model, minder-is-beter (LiB), om die menslike kognitiewe proses te simuleer met betrekking na taal eenigting/segmentasie. LiB volg die prinsipe van minste versoek en doel om 'n leksikon te bou wat die nommer van eenheid tokens (die verskaffing van analisie) en nommer van eenheid tipes (die verskaffing van die verskaffing van opslaan) op dieselfde tyd op enige gegewe korpus minimiseer. LiB se werksvloei is inspireer deur empiriese kognitiewe fenomene. Die ontwerp maak die mekanisme van LiB kognitief veroorsaaklik en die rekenasieverwagting liggewig. Die leksikon wat deur LiB genereer is, doen die best e onder verskillende tipes leksikone (bv. grond-waarheid woorde) beide van 'n informasie-teorieese besigtig en 'n kognitiewe besigtig, wat voorstel dat die LiB-leksikoon dalk 'n plaasbare proksie van die menslike leksikoon kan wees.", 'am': 'ቋንቋ ተጠቃሚዎች ቃላትን በቁጥር እና በቋንቋ ቋንቋ ደረጃዎች የሚለዩትን አካባቢዎች ሲያሳርፉት ነው፡፡ ምንም እንኳን እንደዚህ ብሔራዊ/መግለጫ በቀላል ማድረግ እንችላለን፣ የሚያውቀው ስልጣናው ግን አልተገለጸም፡፡ This paper proposes an unsupervised model, Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization/segmentation.  ሊቢ የደረሰባውን ክፍል የሚከተል እና በተሰጠው ኮርፓስ ላይ የአንዱን ምልክቶች ቁጥር ያጎድልበታል፡፡ የ.ቢ ሥራ ፈሳሽ በብርት ማወቅ ነገር ነው፡፡ አካባቢው የሊቢ መክፈቻ በብልሃት እና የቁጥጥር መክፈት ቀላል ነው፡፡ ሌክሲኮን በተለየ ሌክሲኮን (ምሳሌ የመሬት ቃላት) በተለየ መረጃ-theoretical ተመልከት እና የማውቀት ተመልከት፣ ሊቢ ሊክሲኖስ የልብ ሊክሲን የስህተት ፕሮክሲ እንዲሆን የሚያስታውቀው፡፡', 'sq': 'Përdoruesit e gjuhës procesojnë shprehjet duke i segmentuar ato në shumë njësi kognitive, të cilat ndryshojnë në madhësitë e tyre dhe nivelet gjuhësore. Megjithëse ne mund të bëjmë të tillë unizim/segmentim lehtë, mekanizmi i saj njohës ende nuk është i qartë. Ky dokument propozon një model të pazgjidhur, Less-is-Better (LiB), për të simuluar procesin kognitiv njerëzor lidhur me unitizimin/segmentimin e gjuhës. LiB ndjek parimin e përpjekjes së paktë dhe synon të ndërtojë një lexikon që minimalizon numrin e shenjave të njësisë (lehtësimin e përpjekjes së analizës) dhe numrin e llojeve të njësisë (lehtësimin e përpjekjes së ruajtjes) në të njëjtën kohë në çdo korpus të caktuar. Fluksi i punës i LiB është frymëzuar nga fenomenet e njohura empirike. Projekti e bën mekanizmin e LiB të besueshëm në mënyrë kognitive dhe kërkesën llogaritare të lehtë. Lexikoni i gjeneruar nga LiB kryen më të mirën midis llojeve të ndryshme të lexikonëve (për shembull fjalë tokë-të vërtetës) si nga një pamje informacioni-teorike, ashtu dhe një pamje kognitive, që sugjeron se lexikoni LiB mund të jetë një proxy i besueshëm i lexikonit mendor.', 'tr': 'Diller olaryň habarlaryny bilen pikirlenýän birimlerine bölerek sözlerini işleýärler. Olar öz ululyklarynda we lingwistiki derejesinde üýtgeşýärler. Biz beýle bir birleşme/segmentasyny aňsat edip bilýän bolsaňyz, onuň pikirimçe hala temiz däl. Bu kagyz gaýd edilmedik bir nusga, Adynyň iň gowy bir nusga (LiB), dil birleşmesi/segmentasiýa barada ynsan bilgi prosesini bejermek üçin teklip edýär. LiB iň azyndan çabalaryň prinsipine görýär we munuň bir sanyny beýleki korpuslarda azaltýan leksikon düzenlemegini amaçlaýar. LiB-iň işgäri empirik bilen tanyş fenomenlerden esinlendirilýär. Bu tasarlama LiB sistemini bilgili şeklinde düşünebilir we hesaplamak gerekli höwes gazanýar. LiB tarapyndan döredilen leksikon be ýleki türlerden iň gowy lezikonolar edýär (meseläm, ýer-gerçek sözler) hem informasiýa-teoriýa we hem tansiýa g örnöşinden hem gowy görnöşir. Bu LiB leksikonyň mental leksikonyň ýagdaýynyň ýagdaýyndan ullanýan weksiýa bolmagyny', 'hy': "Լեզվի օգտագործողները վերաբերում են արտահայտություններին' բաժանելով դրանք բազմաթիվ ճանաչողական միավորներով, որոնք տարբերվում են իրենց չափերի և լեզվաբանական մակարդակների վրա: Չնայած, որ մենք կարող ենք հեշտությամբ կատարել այդ միավորումը և սեգմետրացիան, նրա ճանաչողական մեխանիզմը դեռևս պարզ չէ: Այս հոդվածը առաջարկում է անվերահսկված մոդել, որը նվազեցնում է մարդկային ճանաչողական գործընթացը լեզվի միավորման և սեգմետրացիայի հետ կապված: ԼիԲ-ը հետևում է ամենաքիչ ջանքի սկզբունքին և նպատակում է ստեղծել լեքսիկոն, որը նվազեցնում է միավոր նշանների քանակը (վերլուծության ջանքի նվազեցնելը) և միավորի տեսակների քանակը (պահելու ջանքի նվազեցնելը) միևնույն ժամանակ ցանկացած կորպ ԼիԲի աշխատանքի հոսքը ոգեշնչվում է էմպրիկական ճանաչողական երևույթներից: Դասինը դարձնում է ԼիԲ-ի մեխանիզմը ճանաչողական հավատալի և հաշվարկների պահանջը թեթև կշիռ: ԼիԲ կողմից ստեղծված լեքսիկոնը լավագույնն է կատարում տարբեր տեսակի լեքսիկոնների (օրինակ հողի ճշմարտության բառերը) և տեղեկատվական-տեսական տեսանկյունից, և ճանաչողական տեսանկյունից, ինչը առաջարկում է, որ ԼիԲ լեքսիկոնը կարող է լինել մտավոր լեքսիկոնի հավատալի պրոքսիկոն", 'bn': 'ভাষা ব্যবহারকারীরা বিভিন্ন বিভিন্ন সংখ্যার মাধ্যমে ভাষায় কথা বলেছেন, যা তাদের আকার ও ভাষার স্তরে ভিন্ন। Although we can do such unitization/segmentation easily, its cognitive mechanism is still not clear.  এই পত্রিকাটি ভাষার একত্র/বিভাগ সম্পর্কে মানুষের প্রক্রিয়াকে সিমুলেট করার প্রস্তাব দেয়া হয়েছে। লিবি অন্তত প্রচেষ্টার নীতি অনুসরণ করেন এবং একটি লেক্সিকোর লক্ষ্য নির্মাণ করেন যেখানে ইউনিটের সংখ্যা কমিয়ে দেয় (বিশ্লেষণের প্রচেষ্টা কমিয়ে দেয়) এবং একই সাথে যে কোন ক লিবির কাজের প্রবাহ অনুপ্রাণিত হয়েছে ক্ষমতাশালী কাজের কারণে। এই ডিজাইন লিবির মেকেনিস্টেমটিকে জ্ঞানিতভাবে প্লাসিজ এবং গণনাত্রিক প্রয়োজনীয় হাল্কা ওজন। লিবি তৈরি করা লেক্সিকোন বিভিন্ন ধরনের লেক্সিকোনের মধ্যে সবচেয়ে ভালো কাজ করে (উদাহরণস্বরূপ ভূমিকার শব্দ) তথ্য-থিওরেটিক্যাল দৃষ্টিভঙ্গি এবং একটি জ্ঞানীয় দৃষ্টিভ', 'az': "Dil istifadəçilərinin sözlərini çox bilikli birliklərə bölüşdürmək üçün işləyir. Bu, onların böyüklüklərində və dil seviklərində dəyişiklikdir. Əgər biz böyük birlikləşdirmə/segmentasiya asanlıqla edə bilərik, onun bilikli mekanismi hələ də açıq deyil. Bu kağıt, dil birliklənməsi/segmentasiyası haqqında insanların bilikli prosesini simülə etmək üçün müəyyən edilməmiş bir modeli təklif edir. LiB ən az çabaların principinin ardınca gedir və bir leksikon inşa etməyə niyyət edir ki, hər bir korpus üstündə birlikdə birlikdə bir növ növünün sayını azaldır (analizi çətinliklərini azaldır) və bir növ növünün sayını (depoya çabalarını azaldır). LiB'nin çalışma akışı empirical cognitive phenomena təşkil edilir. Bu dizayn LiB'nin mehanizmini bilə-bilə inanılmaz və hesaplama şartları yüngül ağırlıq edir. LiB tarafından yaratdığı leksikon müxtəlif tərzlərin arasındakı ən yaxşı tərzlərini, həmçinin informasiyalı-teoretik g örünüş və kognitiv görünüş tərzlərindən təşkil edir ki, LiB leksikonu mental leksikonu təşkil edə bilər.", 'ca': "Els usuaris de llenguatges processen expressions segmentant-les en moltes unitats cognitives, que varien en les seves dimensions i nivells lingüístics. Encara que podem fer aquesta unització/segmentació fàcilment, el seu mecanisme cognitiu encara no és clar. Aquest paper propon un model no supervisat, Mens-is-Better (LiB), per simular el procés cognitiu humà en relació a la unització/segmentació de llenguatges. LiB segueix el principi del menys esforç i mira a construir un lexicó que minimitza el nombre de fitxes unit àries (alleviant l'esforç d'anàlisi) i el nombre de tipus unitàries (alleviant l'esforç d'emmagatzemar) al mateix temps en qualsevol cos. El flux de treball de LiB està inspirat pels fenomens cognitius empírics. El disseny fa el mecanisme de la LiB cognitivament plausible i el requisit computacional lliure. El lexicó generat per LiB fa el millor entre diferents tipus de lexicòns (per exemple paraules de veritat fonamental) tant a partir d'una vista teòrica d'informació com d'una vista cognitiva, que suggereix que el lexicòn LiB pot ser un proxy plausible del lexicòn mental.", 'cs': 'Uživatelé jazyků zpracovávají výroky segmentováním do mnoha kognitivních jednotek, které se liší velikostí a jazykovou úrovní. I když můžeme takovou sjednocení/segmentaci provést snadno, její kognitivní mechanismus stále není jasný. Tento článek navrhuje bez dozoru model Less-is-Better (LiB), který simuluje lidský kognitivní proces s ohledem na jazykovou unitizaci/segmentaci. LiB se řídí principem minimálního úsilí a usiluje o vytvoření lexikonu, který minimalizuje počet jednotkových tokenů (snižuje námahu analýzy) a počet typů jednotek (snižuje námahu skladování) současně na daném korpusu. Pracovní postup LiB je inspirován empirickými kognitivními jevy. Návrh činí mechanismus LiB kognitivně věrohodný a výpočetní požadavek je lehký. Lexikon generovaný LiB se nejlépe hodí mezi různými typy slovníků (např. slova základní pravdy) jak z informačně teoretického pohledu, tak z kognitivního pohledu, což naznačuje, že lexikon LiB může být věrohodným zástupcem mentálního lexikonu.', 'bs': 'Korisnici jezika obrađuju izraze segmentiranjem ih u mnoge kognitivne jedinice, koje se razlikuju u njihovim veličinama i jezičkim nivoima. Iako možemo lako učiniti takvu jedinizaciju/segmentaciju, njen kognitivni mehanizam još uvijek nije jasan. Ovaj papir predlaže neodređeni model, manje je bolje (LiB), da simulira ljudski kognitivni proces u pogledu ujedinjenja jezika/segmentacije. LiB prati princip najmanjih napora i cilja izgraditi leksikon koji minimizira broj znakova jedinica (olakšavanje napora analize) i broj tipa jedinica (olakšavanje napora skladišta) u isto vrijeme na bilo kojem određenom korpusu. LiB radni tok inspirira empirički kognitivni fenomeni. Dizajn čini mehanizam kognitivno uvjerljivog LiB i lakše težine računalnih zahtjeva. Leksikon koji je proizveden od LiB izvršava najbolje među različitim tipovima leksikona (npr. riječi zemaljske istine) i iz informativnog teorijskog pogleda i kognitivnog pogleda, što predlaže da LiB leksikon može biti uvjerljiv proksi mentalnog leksikona.', 'et': 'Keelekasutajad töötlevad väljendeid segmenteerides need paljudeks kognitiivseteks üksusteks, mille suurus ja keeleline tase erinevad. Kuigi me saame sellist ühendamist/segmenteerimist lihtsalt teha, ei ole selle kognitiivne mehhanism ikka veel selge. Käesolev töö pakub välja järelevalveta mudeli "Vähem on parem" (LiB), et simuleerida inimese kognitiivset protsessi seoses keele ühendamise/segmenteerimisega. LiB järgib minimaalse jõupingutuse põhimõtet ja eesmärk on luua sõnavara, mis minimeerib ühikute märkide arvu (leevendab analüüsi jõupingutust) ja ühikute tüüpide arvu (leevendab salvestamise jõupingutust) üheaegselt igal korpusel. LiB töövoog on inspireeritud empiirilistest kognitiivsetest nähtustest. Disain muudab LiB mehhanismi kognitiivselt usutavaks ja arvutusliku nõude kergeks. LiB genereeritud leksikon toimib kõige paremini eri tüüpi leksikonide hulgas (nt tõesõnad) nii infoteoreetilisest kui kognitiivsest vaatenurgast, mis viitab sellele, et LiB leksikon võib olla vaimse leksikoni usutav proxy.', 'fi': 'Kielenkäyttäjät käsittelevät sanontoja segmentoimalla ne moniin kognitiivisiin yksiköihin, jotka vaihtelevat kooltaan ja kieleltään. Vaikka voimme tehdä tällaisen yhdistämisen / segmentoinnin helposti, sen kognitiivinen mekanismi ei ole vielä selvä. Tässä työssä ehdotetaan valvomatonta mallia, Less-is-Better (LiB), joka simuloi ihmisen kognitiivista prosessia kielen yhdistämisen/segmentoinnin suhteen. LiB noudattaa pienimmän vaivan periaatetta ja pyrkii rakentamaan sanaston, joka minimoi yksikkömerkkien määrän (lievittäen analyysiponnistusta) ja yksikkötyyppien määrän (lievittäen tallennusponnistusta) samanaikaisesti tietyllä korpusella. LiB:n työnkulku perustuu empiirisiin kognitiivisiin ilmiöihin. Suunnittelu tekee LiB:n mekanismista kognitiivisesti uskottavan ja laskennallisesta vaatimuksesta kevyen. LiB:n tuottama sanasto suoriutuu parhaiten erityyppisistä sanastoista (esim. pohjatotuuden sanoista) sekä informaatioteoreettisesta että kognitiivisesta näkökulmasta, mikä viittaa siihen, että LiB:n sanasto voi olla mielellisen sanaston uskottava proxy.', 'jv': 'Language section Awak iki tentang nggawe model sing gak nggawe, Min-is-lak (LiB), nggawe ngubah perusahaan kowe saiki ingkang karo nggawe ujiane/segmentation. LiB mbuh hal penting punika dipunangé penting lan bukane nggawe leksiko sing nyerung petani sing gawe nggawe token sing unangé (ngejaraké awak dhéwé) lan nganggo perusahaan sampeyan (ngejaraké awak dhéwé nggawe aséwé) sampeyan ngono sampeyan wong iki. Bocah-bocah sing paling LiB seneng kelangan kelangan empirhik design Leksikono sing gagale LiB iso nglanggar luwih akeh tenan seneng kalaha luwih-luwih lanjut cara sing paling penyane', 'ha': "Sunan da ke amfani da harshe, za'a yi amfani da su goge su zuwa wasu jama'a masu sanyi, wanda ke sãɓã cikin girmar da linguistic. Ingawa lalle ne munã iya aikata shirin haɗiya/segment mai sauƙi, kuma ma'anarsa ba ta zama mai bayyanãwa ba. Wannan takardar da ke ƙayyade wata motsi wanda ba'a tsare shi ba, ƙari-ce-mafi alhẽri (LiB), dõmin ya daidaita aikin mutum da inganci game da shirin haɗiya/segment na harshen. LiB yana biyar kimar aikin da aka ƙara aikin da kuma ana yi amfani da ya gina wani leksisi, wanda ke ƙaranci ƙidãyar ayuka na taga (sauƙa ƙara aikin Anayi) da watin nau'i na nau'i (rarrabe aikin adanar da aka tsare) sami da lokacin da aka ba da shi. Shirin aikin LiB na ƙara wani abu na empirin kognitive. Zanin ya sanya mekaninsa na LiB da bassi da kuma ma'abũcin lissafi ya sauƙi. Leksisin wanda aka haife na LiB na aikata mafi kyaun nau'i na dabam-dabam (misali, kalmõmi-gaskiya) daga wani misalin-teoretisk da wani g an e na kognitive, mai yiwuwa ne a loksin LiB ta zama mai raɗa ɗãwa ga taƙaitori.", 'sk': 'Uporabniki jezikov obdelujejo izjave tako, da jih segmentirajo v številne kognitivne enote, ki se razlikujejo po velikosti in jezikovni ravni. Čeprav lahko takšno enotnost/segmentacijo opravimo enostavno, njegov kognitivni mehanizem še vedno ni jasen. V prispevku je predlagan nenadzorovan model, Manj je boljši (LiB), za simuliranje človeškega kognitivnega procesa v zvezi z enotnostjo/segmentacijo jezika. LiB sledi načelu najmanjšega truda in si prizadeva zgraditi leksikon, ki hkrati zmanjšuje število enotnih žetonov (olajšuje napor analize) in število tipov enot (olajšuje napor shranjevanja) na vsakem korpusu. LiB-jev potek dela je navdihnjen z empiričnimi kognitivnimi pojavi. Zaradi zasnove je mehanizem LiB kognitivno verjeten, računalniška zahteva pa lahka. Leksikon, ki ga ustvari LiB, je najboljši med različnimi vrstami leksikonov (npr. besede resnice) tako z informacijsko-teoretičnega kot kognitivnega pogleda, kar kaže, da je LiB leksikon verjeten približek mentalnega leksikona.', 'bo': 'Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and linguistic levels. ང་ཚོས་རྒྱ་ནག་གི་དབྱིབས་གཅིག་སྡུད་འདི་དག་ལས་སླ་གཏོང་བྱེད་ཆོག་ཡིན་ནའང་། ཤོག་བྱང་འདིས་ཕན་འབྲས་མེད་པའི་མ་དབྱིབས་ཞིག་དང་། Less-is-Better (LiB)ཡིན་པས། LiB follows the principle of least effort and aims to build a lexicon which minimizes the number of unit tokens (alleviating the effort of analysis) and number of unit types (alleviating the effort of storage) at the same time on any given corpus. LiB ལས་འགྲུལ་རྩོམ་པ་ནི་སྙན་རིས་ཤེས་པའི་སྣང་ཚུལ་གྱིས་འཕེལ་བསྐྱེད་ཡོད། The design makes the mechanism of LiB cognitively plausible and the computational requirement light-weight. LiB་གིས་གསར་བསྐྲུན་པའི་lexicon་དེ་ལྟ་ཀློག་སྟངས་འདྲ་མི་འདྲ་བའི་རྣམ་པ་ལས་ཕན་རྟགས་བཀལ།', 'he': 'Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and linguistic levels.  למרות שאנחנו יכולים לעשות יחידה/סגרטציה כזו בקלות, המנגנון הקיוניטיבי שלה עדיין לא ברור. העבודה הזו מציעה מודל ללא השגחה, פחות טוב יותר (LiB), כדי לסימולוג את תהליך הקונכיטיבי האנושי בנוגע לאיחודות/סגמנציה לשפה. LiB עוקב אחרי העקרון של המאמץ הכי פחות ומתכוון לבנות לקסיקון שמפחיד את מספר סימני יחידה (להקל את מאמץ הניתוח) ומספר סוגי יחידה (להקל את מאמץ האחסן) באותו הזמן על כל קורפוס מסוים. זרם העבודה של ליב מעורר השראה בתופעות קוגניטיביות אמפיריות. העיצוב הופך את המנגנון של ליב קוגניטיבית אמין והדרישה החישובית למשקל קל. הלקסיקון שנוצר ע"י LiB מבצע את הטוב ביותר בין סוגים שונים של לקסיקונים (למשל מילים אמת-קרקע) גם מנוף מידע-תיאורטי וגם נוף קוגניטיבי, מה שמציע כי הלקסיקון LiB יכול להיות פרוקסיקון אמין של הלקסיקון הנפשי.'}
{'en': 'The CogALex Shared Task on Monolingual and Multilingual Identification of Semantic Relations C og AL ex Shared Task on Monolingual and Multilingual Identification of Semantic Relations', 'ar': 'مهمة CogALex المشتركة حول تحديد العلاقات الدلالية بلغة واحدة ومتعددة اللغات', 'fr': "La tâche partagée de CogaLex sur l'identification monolingue et multilingue des relations sémantiques", 'pt': 'A Tarefa Compartilhada CogALex sobre Identificação Monolíngue e Multilíngue de Relações Semânticas', 'es': 'La tarea compartida de CogaLex sobre la identificación monolingüe y multilingüe de las relaciones semánticas', 'ja': 'セマンティックリレーションの単一言語および多言語識別に関するCogALex共有タスク', 'hi': 'CogALex शब्दार्थ संबंधों की मोनोलिंगुअल और बहुभाषी पहचान पर साझा कार्य', 'zh': 'CogALex语义之单语,与多言之共同任务', 'ru': 'Совместная задача CogALex по одноязычной и многоязычной идентификации семантических отношений', 'ga': 'Tasc Comhroinnte CogALex ar Shainaithint Aonteangach agus Ilteangach ar Chaidreamh Séimeantach', 'ka': 'CogALex shared task on Monolingual and Multilingual Identification of Semantic Relations', 'el': 'Η Κοινή Εργασία για τον Μονογλωσσικό και Πολυγλωσσικό προσδιορισμό Σημαντικών Σχέσεων', 'hu': 'A CogALex megosztott feladata a szemantikus kapcsolatok egynyelvű és többnyelvű azonosításáról', 'it': "Il compito condiviso CogALex sull'identificazione monolingue e multilingue delle relazioni semantiche", 'lt': 'CogALex bendra užduotis, susijusi su monokalbiniu ir daugiakalbiniu Semantinių santykių identifikavimu', 'kk': 'CogALex ортақ тапсырмасы бір тілді және бірнеше тілді қатынастарды анықтау', 'ms': 'Tugas Berkongsi CogALex mengenai Pengenalan Monolingual dan Berberbilang Bahasa Hubungan Semantik', 'mk': 'Соделена задача на CogALex за монолингуална и мултијазична идентификација на семантичките односи', 'ml': 'സെമാന്റിക് ബന്ധങ്ങളുടെ കോഗാലെക്സ് മോണോളില്\u200dഭാഷ, പല ഭാഷയുടെയും തിരിച്ചറിയുന്നതില്\u200d പങ്കെടുത്ത പണി', 'mt': 'Il-Kompitu Konġunt tal-CogALex dwar l-Identifikazzjoni Monolingwali u Multilingwi tar-Relazzjonijiet Semantiċi', 'no': 'CogALex-delt oppgåve på monolingsk og fleirspråk identifisering av semiantiske relasjonar', 'ro': 'Sarcina comună CogALex privind identificarea monolingvă și multilingvă a relațiilor semantice', 'mn': 'CogALex Хувь хэлний, олон хэлний харилцааны танихын тулд', 'pl': 'Wspólne zadanie CogALex dotyczące jednojęzycznej i wielojęzycznej identyfikacji relacji semantycznych', 'si': 'The CogALex shared Job on Monolingual and Multilanguage ID of semantic ties', 'so': 'Shaqada loo sharciyey CogALex oo ku saabsan aqoonsiga afka Monolingual iyo luqadaha kala duduwan ee xiriirka galmada', 'sr': 'CogALex zajednički zadatak o monolingviskoj i multijezičkoj identifikaciji semantičkih odnosa', 'sv': 'CogALex delade uppgift om enspråkig och flerspråkig identifiering av semantiska relationer', 'ta': 'CogALex பகிர்ந்த பணி', 'ur': 'The CogALex Shared Task on Monolingual and Multilingual Identification of Semantic Relations', 'uz': 'Name', 'vi': 'Công việc chia sẻ CogALex về Mật ngôn ngữ và đa ngôn ngữ', 'da': 'CogALex delte opgave om ensproget og flersproget identifikation af semantiske relationer', 'nl': 'De gezamenlijke taak van CogALex inzake eentalige en meertalige identificatie van semantische relaties', 'hr': 'CogALex zajednički zadatak o monojezičkoj i višejezičkoj identifikaciji semantičkih odnosa', 'bg': 'Споделена задача за едноезично и многоезично идентифициране на семантичните отношения', 'ko': 'CogAlex는 단어와 다중 언어의 의미 관계 식별 임무를 공유했다', 'de': 'Die gemeinsame Aufgabe von CogALex zur ein- und mehrsprachigen Identifikation semantischer Beziehungen', 'fa': 'وظیفه مشترک CogALex در مورد شناسایی یک زبان و چندین زبان رابطه\u200cهای متوسط', 'id': 'The CogALex Shared Task on Monolingual and Multilingual Identification of Semantic Relations', 'sw': 'CogALex ilishiriki kazi katika utambulisho wa lugha za KiMonolinguli na Utambulisho wa Kimataifa', 'sq': 'Detyra e përbashkët e CogALex për identifikimin monolingvist dhe shumëgjuhës të marrëdhënieve Semantike', 'tr': 'CogALex Semantik İlişkilerin Monoli Dili ve Çoklu Dilli Kimlik Görevi', 'af': 'Die CogALex Gedeelde Opdrag op Monolingueel en Veelvuldige Identifikasie van Semantiese Relasies', 'hy': 'COgALex-ի կիսված առաջադրանքը սեմանտիկ հարաբերությունների միալեզու և բազլեզու հայտնաբերման մասին', 'am': 'የCogALex ስራ በMonolingual እና Multilingual Identification of Semantic Relations', 'az': 'CogALex, Semantik ńįliŇükil…ôrin Monoli Dili v…ô √áoxlu Dili ńįliŇükil…ôrin ńįŇül…ôri', 'bn': 'কোগালেক্স সেমান্টিক সম্পর্কের সাথে মোনোলিভাল এবং বহুভাষার পরিচয় নিয়ে কোগালেক্স শেয়ার করা কাজ', 'ca': 'La tasca compartida CogALex sobre la identificació monolingüa i multilingüa de les relacions semàntiques', 'bs': 'CogALex zajednički zadatak o monojezičkoj i multijezičkoj identifikaciji semantičkih odnosa', 'et': 'CogALexi ühine ülesanne semantiliste suhete ühekeelse ja mitmekeelse tuvastamise kohta', 'cs': 'Společný úkol CogALex o jednojjazyčné a vícejazyčné identifikaci sémantických vztahů', 'fi': 'CogALexin yhteinen tehtävä semanttisten suhteiden yksiselitteisestä ja monikielisestä tunnistamisesta', 'ha': 'The CogALex Shared Task on Monolingual and Multilingual Identification of Semantic Relations', 'sk': 'Skupna naloga CogALex o enojezičnem in večjezičnem prepoznavanju semantičnih odnosov', 'he': 'המשימה המשותפת של CogALex על זיהוי מונולינגולי ומרבות שפות של יחסים סמנטיים', 'jv': 'CogAlex Sambah Taaksi kanggo Monolngual lan Multi-Linguial ID Kemerdekaan Samantar', 'bo': 'CogALex Semantic Relations ཐོག་འབྲེལ་གྱི་རྩིས་ཐོག་དང་སྐད་རིགས་དབྱེ་བའི་བྱ་བ་དེ་'}
{'en': 'The shared task of the CogALex-VI workshop focuses on the monolingual and multilingual identification of semantic relations. We provided training and validation data for the following languages :  English ,  German  and  Chinese . Given a word pair, systems had to be trained to identify which relation holds between them, with possible choices being  synonymy ,  antonymy ,  hypernymy  and no relation at all. Two test sets were released for evaluating the participating  systems . One containing pairs for each of the training languages (systems were evaluated in a monolingual fashion) and the other proposing a surprise language to test the crosslingual transfer capabilities of the systems. Among the submitted systems, top performance was achieved by a transformer-based model in both the monolingual and in the multilingual setting, for all the tested languages, proving the potentials of this recently-introduced neural architecture. The shared task description and the results are available at https://sites.google.com/site/cogalexvisharedtask/.', 'ar': 'تركز المهمة المشتركة لورشة عمل CogALex-VI على تحديد العلاقات الدلالية بلغة واحدة ومتعددة اللغات. قدمنا بيانات التدريب والتحقق من الصحة للغات التالية: الإنجليزية والألمانية والصينية. بالنظر إلى زوج من الكلمات ، كان لابد من تدريب الأنظمة على تحديد العلاقة التي تربط بينها ، مع كون الخيارات الممكنة مرادفًا ، وتضادًا ، وتضاربًا ، وعدم وجود علاقة على الإطلاق. تم إصدار مجموعتين من الاختبارات لتقييم الأنظمة المشاركة. يحتوي أحدهما على أزواج لكل لغة من لغات التدريب (تم تقييم الأنظمة بطريقة أحادية اللغة) والآخر يقترح لغة مفاجئة لاختبار قدرات النقل عبر اللغات للأنظمة. من بين الأنظمة المقدمة ، تم تحقيق أعلى أداء من خلال نموذج قائم على المحولات في كل من لغة أحادية اللغة وفي بيئة متعددة اللغات ، لجميع اللغات التي تم اختبارها ، مما يثبت إمكانات هذه البنية العصبية التي تم تقديمها مؤخرًا. يتوفر وصف المهمة المشتركة والنتائج على https://sites.google.com/site/cogalexvisharedtask/.', 'pt': 'A tarefa compartilhada do workshop CogALex-VI concentra-se na identificação monolíngue e multilíngue de relações semânticas. Fornecemos dados de treinamento e validação para os seguintes idiomas: inglês, alemão e chinês. Dado um par de palavras, os sistemas tiveram que ser treinados para identificar qual relação se mantém entre eles, com escolhas possíveis sendo sinonímia, antonímia, hipernímia e nenhuma relação. Dois conjuntos de teste foram lançados para avaliar os sistemas participantes. Um contendo pares para cada uma das línguas de treinamento (os sistemas foram avaliados de forma monolíngue) e o outro propondo uma língua surpresa para testar a capacidade de transferência entre os sistemas. Entre os sistemas apresentados, o melhor desempenho foi alcançado por um modelo baseado em transformador tanto no ambiente monolíngue quanto no multilíngue, para todos os idiomas testados, comprovando o potencial dessa arquitetura neural recém-introduzida. A descrição da tarefa compartilhada e os resultados estão disponíveis em https://sites.google.com/site/cogalexvisharedtask/.', 'es': 'La tarea compartida del taller de Cogalex-VI se centra en la identificación monolingüe y multilingüe de las relaciones semánticas. Proporcionamos datos de capacitación y validación para los siguientes idiomas: inglés, alemán y chino. Dado un par de palabras, los sistemas tenían que ser entrenados para identificar qué relación mantenía entre ellos, siendo las posibles opciones sinonimia, antonimia, hipernima y ninguna relación en absoluto. Se publicaron dos conjuntos de pruebas para evaluar los sistemas participantes. Uno contiene pares para cada uno de los idiomas de entrenamiento (los sistemas se evaluaron de manera monolingüe) y el otro propuso un idioma sorpresa para probar las capacidades de transferencia interlingüística de los sistemas. Entre los sistemas presentados, se logró el máximo rendimiento mediante un modelo basado en transformadores tanto en el entorno monolingüe como en el multilingüe, para todos los idiomas probados, lo que demuestra el potencial de esta arquitectura neuronal recientemente introducida. La descripción de la tarea compartida y los resultados están disponibles en https://sites.google.com/site/cogalexvisharedtask/.', 'fr': "La tâche partagée de l'atelier Cogalex-VI est axée sur l'identification monolingue et multilingue des relations sémantiques. Nous avons fourni des données de formation et de validation pour les langues suivantes\xa0: anglais, allemand et chinois. À partir d'une paire de mots, il a fallu entraîner les systèmes à identifier la relation qui existe entre eux, les choix possibles étant la synonymie, l'antonymie, l'hypernymie et aucune relation du tout. Deux ensembles de tests ont été publiés pour évaluer les systèmes participants. L'un contenant des paires pour chacune des langues d'apprentissage (les systèmes ont été évalués de façon monolingue) et l'autre proposant un langage surprise pour tester les capacités de transfert interlinguistique des systèmes. Parmi les systèmes soumis, les meilleures performances ont été obtenues grâce à un modèle basé sur un transformateur à la fois dans le cadre monolingue et dans le cadre multilingue, pour toutes les langues testées, prouvant le potentiel de cette architecture neuronale récemment introduite. La description partagée de la tâche et les résultats sont disponibles à l'adresse https://sites.google.com/site/cogalexvisharedtask/.", 'ja': 'CogALex - VIワークショップの共有タスクは、セマンティック関係の単語と多言語の識別に焦点を当てています。 英語、ドイツ語、中国語のトレーニングと検証データを提供しました。 単語ペアを考慮すると、システムは、どちらの関係を保持しているかを識別するようにトレーニングする必要があり、選択肢は同義語、対義語、ハイパーニミーであり、関係はまったくありません。 参加システムを評価するための2つの試験装置がリリースされた。 各トレーニング言語（システムは単一言語で評価された）のペアを含む1つの言語と、システムのクロスリンガル転送能力をテストするためのサプライズ言語を提案するもう1つの言語。 提出されたシステムの中で最高のパフォーマンスを達成したのは、単一言語と多言語の両方での変圧器ベースのモデルであり、テストされたすべての言語について、この最近導入されたニューラルアーキテクチャの可能性を証明しました。 共有タスクの説明と結果は、https://sites.google.com/site/cogalexvisharedtask/でご覧いただけます。', 'zh': 'CogALex-VI研讨会之共同任务侧重于语义关系单语多言识。 臣等具下语培训验数:英语、德语、中文。 给定一单词者,统必练而识之,或择同义词反义词,hypernymy本无伤也。 发二试集,以质其统。 一包每种训练语言的配对(系统以单语法评估),一个发一种令人惊讶的言语来测试系统的跨语移能。 凡提交之统,变压器形于单语、多言之间,尽测试语言之最善,证近引之神经架构力。 共功在 https://sites.google.com/site/cogalexvisharedtask/。', 'hi': 'CogaLex-VI कार्यशाला का साझा कार्य शब्दार्थ संबंधों की मोनोलिंगुअल और बहुभाषी पहचान पर केंद्रित है। हमने निम्नलिखित भाषाओं के लिए प्रशिक्षण और सत्यापन डेटा प्रदान किया: अंग्रेजी, जर्मन और चीनी। एक शब्द जोड़ी को देखते हुए, सिस्टम को यह पहचानने के लिए प्रशिक्षित किया जाना था कि उनके बीच कौन सा संबंध है, संभावित विकल्प पर्यायवाची, विलोम, हाइपरनीमी और कोई संबंध नहीं है। भाग लेने वाली प्रणालियों का मूल्यांकन करने के लिए दो परीक्षण सेट जारी किए गए थे। एक प्रशिक्षण भाषाओं में से प्रत्येक के लिए जोड़े (सिस्टम का मूल्यांकन मोनोलिंगुअल फैशन में किया गया था) और दूसरा सिस्टम की क्रॉसलिंगुअल ट्रांसफर क्षमताओं का परीक्षण करने के लिए एक आश्चर्यजनक भाषा का प्रस्ताव करता है। प्रस्तुत प्रणालियों में, शीर्ष प्रदर्शन मोनोलिंगुअल और बहुभाषी सेटिंग दोनों में एक ट्रांसफॉर्मर-आधारित मॉडल द्वारा प्राप्त किया गया था, सभी परीक्षण की गई भाषाओं के लिए, इस हाल ही में पेश किए गए तंत्रिका वास्तुकला की क्षमताओं को साबित करता है। साझा कार्य विवरण और परिणाम https://sites.google.com/site/cogalexvisharedtask/ पर उपलब्ध हैं।', 'ru': 'Общая задача практикума CogALex-VI заключается в одноязычной и многоязычной идентификации семантических отношений. Мы предоставили данные по обучению и валидации для следующих языков: английский, немецкий и китайский. С учетом пары слов, системы должны были быть обучены, чтобы определить, какая связь находится между ними, с возможным выбором синонимичности, антонимии, гипернимии и никакого отношения вообще. Для оценки участвующих систем были выпущены два набора тестов. Один из них содержит пары для каждого из учебных языков (системы оценивались одноязычно), а другой предлагает язык сюрпризов для проверки возможностей кросс-лингвистической передачи систем. Среди представленных систем наивысшая производительность была достигнута за счет трансформаторной модели как в одноязычной, так и в многоязычной среде, для всех протестированных языков, что доказывает потенциал этой недавно введенной нейронной архитектуры. Общее описание задачи и результаты доступны по адресу https://sites.google.com/site/cogalexvisharedtask/.', 'ga': 'Díríonn tasc comhroinnte na ceardlainne CogALex-VI ar shainaithint aonteangach agus ilteangach an chaidrimh shéimeantaigh. Chuireamar oiliúint agus sonraí bailíochtaithe ar fáil do na teangacha seo a leanas: Béarla, Gearmáinis agus Sínis. Nuair a chuirtear péire focal san áireamh, b’éigean córais a oiliúint chun an gaol atá eatarthu a aithint, agus b’iad na roghanna a d’fhéadfadh a bheith ann ná comhchiall, frithchiall, hipearainmíocht agus gan gaol ar bith. Eisíodh dhá thacar tástála chun na córais rannpháirteacha a mheas. Ceann acu ina raibh péirí do gach ceann de na teangacha oiliúna (measúnaíodh córais ar bhealach aonteangach) agus an ceann eile ag moladh teanga iontasach chun cumas aistrithe trasteangacha na gcóras a thástáil. I measc na gcóras a cuireadh isteach, baineadh an fheidhmíocht is fearr amach trí mhúnla bunaithe ar chlaochladán sa suíomh aonteangach agus ilteangach, do na teangacha go léir a tástáladh, rud a chruthaigh acmhainneacht na hailtireachta néarúla seo a tugadh isteach le déanaí. Tá cur síos ar an tasc roinnte agus na torthaí ar fáil ag https://sites.google.com/site/cogalexvisharedtask/.', 'el': 'Το κοινό έργο του εργαστηρίου επικεντρώνεται στην μονογλωσσική και πολύγλωσση ταυτοποίηση σημασιολογικών σχέσεων. Παρέχουμε δεδομένα κατάρτισης και επικύρωσης για τις ακόλουθες γλώσσες: Αγγλικά, Γερμανικά και Κινέζικα. Δεδομένου ενός ζεύγους λέξεων, τα συστήματα έπρεπε να εκπαιδευτούν για να προσδιορίσουν ποια σχέση υπάρχει μεταξύ τους, με πιθανές επιλογές να είναι συνώνυμη, αντωνυμία, υπερνυμία και καμία απολύτως σχέση. Δύο σετ δοκιμών κυκλοφόρησαν για την αξιολόγηση των συμμετεχόντων συστημάτων. Το ένα περιέχει ζεύγη για κάθε μία από τις γλώσσες εκπαίδευσης (τα συστήματα αξιολογήθηκαν μονογλωσσικά) και το άλλο προτείνει μια γλώσσα έκπληξης για να εξετάσει τις δυνατότητες διασυνοριακής μεταφοράς των συστημάτων. Μεταξύ των υποβαλλόμενων συστημάτων, η κορυφαία απόδοση επιτεύχθηκε με ένα μοντέλο βασισμένο σε μετασχηματιστή τόσο στο μονογλωσσικό όσο και στο πολυγλωσσικό περιβάλλον, για όλες τις δοκιμασμένες γλώσσες, αποδεικνύοντας τις δυνατότητες αυτής της πρόσφατα εισαγόμενης νευρωνικής αρχιτεκτονικής. Η κοινή περιγραφή εργασιών και τα αποτελέσματα είναι διαθέσιμα στη διεύθυνση https://sites.google.com/site/cogalexvisharedtask/.', 'hu': 'A CogALex-VI workshop közös feladata a szemantikai kapcsolatok egynyelvű és többnyelvű azonosítására összpontosít. Képzési és validálási adatokat nyújtottunk a következő nyelvekre: angol, német és kínai. Egy szópár alapján a rendszereket arra kellett képezni, hogy azonosítsák, melyik kapcsolat áll köztük, lehetséges választások szinonimák, antonimia, hipernímia és egyáltalán nincs kapcsolat. Két tesztkészlet került kiadásra a résztvevő rendszerek értékelésére. Az egyik párokat tartalmaz az egyes képzési nyelvekhez (a rendszereket egynyelvű módon értékelték), a másik pedig meglepetési nyelvet javasol a rendszerek nyelvi transzfer képességeinek tesztelésére. A benyújtott rendszerek közül a legjobb teljesítményt egy transzformátor alapú modell érte el mind egynyelvű, mind többnyelvű környezetben, valamennyi tesztelt nyelven, bizonyítva ennek a nemrégiben bevezetett neurális architektúrának lehetőségeit. A megosztott tevékenység leírása és az eredmények a következő oldalon érhetők el: https://sites.google.com/site/cogalexvisharedtask/.', 'ka': 'CogALex-VI სამუშაო სამუშაო დავამყოფილი დავალება მონოლენგური და მრავალენგური განსაზღვრებაზე. ჩვენ განვითარებით მონაცემები და გადაწყვეტილების მონაცემები, ანგლისური, გერმანური და ჩინეთი. სიტყვების ორიდან, სისტემები უნდა იყოს განაცნობა, რომელიც შესაძლებელი გამოყენება შორის, ანტონიმია, ჰიპერნიმია და არაფერი შესახებ. ორი ტესტის კონფიგურაცია გადასრულებული სისტემის განსაზღვრებისთვის. ერთი, რომელიც ყველა საკუთარი საკუთარი ენაზე (სისტემები მონოლენგური ფორმაში გაუმუშავებულია) და მეორე, რომელიც საკუთარი ენაზე გაუმუშავებს სისტემების კრისილენგური გადატანსტრე ჩემუშავებული სისტემების შორის უფრო მეტი კონფიგურაცია მოდელეში მონოლენგური და მრავალენგური კონფიგურაციაში, ყველა შემოწმებული ენებისთვის, რომლებიც ახლა შეიცვალოთ ამ ახლა შეიცვალობ გაყოფილი დავალების გამოსახულება და შედეგი შესაძლებელია https://sites.google.com/site/cogalexvisharedtask/.', 'lt': 'Bendra CogALex-VI seminaro užduotis sutelkiama į semantinių santykių vienkalbį ir daugiakalbį nustatymą. Pateikėme mokymo ir patvirtinimo duomenis šioms kalboms: anglų, vokiečių ir kinų. Atsižvelgiant į žodžių porą, reikėjo parengti sistemas, kad būtų galima nustatyti, koks ryšys tarp jų yra, o galimi pasirinkimai yra sinonimija, antonimija, hipernimija ir jokių ryšių. Dalyvaujančioms sistemoms įvertinti išleisti du bandymų rinkiniai. Viena, kurioje yra poros kiekvienai mokymo kalbai (sistemos buvo vertinamos vienkalbiškai), kita, kuria siūloma nustebinta kalba, kad būtų išbandyti sistemų tarpkalbiniai perdavimo gebėjimai. Iš pateiktų sistemų didžiausias veiksmingumas buvo pasiektas naudojant transformatoriumi grindžiamą model į tiek vienakalbėje, tiek daugiakalbėje aplinkoje visoms išbandytoms kalboms, įrodantį šios neseniai įdiegtos neurologinės architektūros potencialą. The shared task description and the results are available at  https://sites.google.com/site/cogalexvisharedtask/.', 'it': "Il compito condiviso del workshop CogALex-VI si concentra sull'identificazione monolingue e multilingue delle relazioni semantiche. Abbiamo fornito dati di formazione e convalida per le seguenti lingue: inglese, tedesco e cinese. Data una coppia di parole, i sistemi dovevano essere addestrati per identificare quale relazione abbia tra di loro, con possibili scelte come sinonimia, antonimia, ipernimia e nessuna relazione. Sono stati rilasciati due set di test per valutare i sistemi partecipanti. Una contiene coppie per ciascuna delle lingue di formazione (i sistemi sono stati valutati in modo monolingue) e l'altra propone una lingua a sorpresa per testare le capacità di trasferimento translinguale dei sistemi. Tra i sistemi presentati, le massime prestazioni sono state raggiunte da un modello basato su trasformatori sia in ambito monolingue che multilingue, per tutte le lingue testate, dimostrando le potenzialità di questa architettura neurale recentemente introdotta. La descrizione dell'attività condivisa e i risultati sono disponibili all'indirizzo https://sites.google.com/site/cogalexvisharedtask/.", 'mk': 'The shared task of the CogALex-VI workshop focuses on the monolingual and multilingual identification of semantic relations.  We provided training and validation data for the following languages: English, German and Chinese.  Со оглед на зборот пар, системите мораа да бидат обучени да идентификуваат која врска има меѓу нив, со можни избори да бидат синонимија, анонимија, хипернимија и воопшто без врска. Два тестови беа објавени за проценка на учествувачките системи. Еден кој содржи парови за секој од јазиците за обука (системите беа проценети на монојазичен начин) и другиот кој предлага изненадувачки јазик за тестирање на прекујазичните трансферентни способности на системите. Меѓу поднесените системи, највисоката резултат беше постигната со модел базиран на трансформатор во монојазичното и мултијазичното место, за сите тестирани јазици, докажувајќи ги потенцијалите на оваа неодамна воведена нервна архитектура. Описот на заедничката задача и резултатите се достапни на https://sites.google.com/site/cogalexvisharedtask/.', 'kk': 'CogALex-VI жұмысының ортақ тапсырмасы semantic қатынасын бірнеше тілді және бірнеше тілді идентификациясына назар береді. Біз келесі тілдер үшін оқу және тексеру деректерін келтірдік: ағылшын, неміс және қытайша. Сөздің екі сөзде, жүйелер арасындағы қай қатынас бар екенін анықтау үшін оқыту керек, мүмкін таңдаулар синоними, антоними, гиперними және қатынасыз болуы мүмкін. Қатысушылық жүйелерді бағалау үшін екі сынақтар жинақталды. Біріншісі бір тілдерге (жүйелер бірнеше тілдерге тең етілген) жүйелердің бірнеше тілдеріне аудару мүмкіндігін тексеру үшін қызықтық тілді қолданады. Келтірілген жүйелердің ортасында жоғарғы әрекеттері монолингі және көптілік параметрлерінде түрлендіруші үлгісі барлық сыналған тілдер үшін, соңғы келтірілген невралдық архитектурасының мүмкіндіктерін көрсетеді. Ортақ тапсырманың сипаттамасы мен нәтижелері бар https://sites.google.com/site/cogalexvisharedtask/.', 'ms': 'Tugas berkongsi workshop CogALex-VI fokus pada pengenalan satu bahasa dan berbilang bahasa hubungan semantik. Kami menyediakan data latihan dan pengesahihan untuk bahasa berikut: Bahasa Inggeris, Jerman dan Cina. Berikan pasangan kata, sistem perlu dilatih untuk mengenalpasti hubungan mana yang ada di antara mereka, dengan pilihan yang mungkin adalah sinonimi, antonimi, hipernimi dan tiada hubungan sama sekali. Dua set ujian dibebaskan untuk mengevaluasi sistem yang berpartisipasi. Satu mengandungi pasangan untuk setiap bahasa latihan (sistem diteliti dalam cara monobahasa) dan yang lain melaporkan bahasa kejutan untuk menguji kemampuan pemindahan salib bahasa sistem. Di antara sistem yang dihantar, prestasi terbaik dicapai oleh model berdasarkan pengubah dalam seting monobahasa dan berbilang bahasa, untuk semua bahasa yang diuji, membuktikan potensi arkitektur saraf yang baru-baru ini diperkenalkan. Huraian tugas berkongsi dan keputusan tersedia di https://sites.google.com/site/cogalexvisharedtask/.', 'mn': 'CogALex-VI хийх мэргэжлийн хуваалцааны ажил нь semantic relations-ын ганц хэл болон олон хэл хэлний тодорхойлолтыг анхаарна. Бид дараагийн хэл дээр суралцах, үнэлгээ өгүүлсэн: Англи, Герман, Хятад. Хоёр үг хэлэхэд, систем нь тэдний хоорондын хамааралтай холбоотой хамааралтай байдгийг мэдэхэд сургалтын тулд, боломжгүй сонголтууд нь синоним, антоним, гиперним, харилцаа байхгүй. Хоёр шалгалт нь оролцогчдын системийг үнэлэхэд гаргасан. Сургуулийн хэл бүрт хоёр байдаг (систем нь нэг хэл хэлбэртэй дүрслэгдсэн) бас нэг хэл нь системийн давхар хэл шилжүүлэх чадварыг шалгахад гайхалтай хэл болгож байна. Олон хэлний болон олон хэлний суурьдаа шилжүүлэгч загвар дээрх үйл ажиллагааны тухай шалгалтын бүх хэлний хувьд шилжүүлэгч загвар нь олон хэлний суурьдаа гарч ирсэн. Холбоотой ажлын тодорхойлолт болон үр дүн нь https://sites.google.com/site/cogalexvisharedtask/.', 'ml': 'കോഗാലെക്സ്-VI വര്\u200dക്ക്\u200cഷോപ്പിന്\u200dറെ പങ്കാളിയുള്ള ജോലിയാണ് സെമാന്റിക് ബന്ധങ്ങളുടെ സംബന്ധിച്ചുള്ള മോണോളില്\u200dഭാ നമ്മള്\u200d തിരഞ്ഞെടുക്കുന്ന ഭാഷകള്\u200dക്ക് പരിശീലനവും പരിശീലനവും വിവരങ്ങളും നല്\u200dകി: ഇംഗ്ലീഷ്, ജര്\u200dമ്മന്\u200d  ഒരു വാക്ക് രണ്ട് ജോട്ടുകാര്\u200d കൊണ്ട്, അവയ്ക്കിടയിലുള്ള ബന്ധം തിരിച്ചറിയാന്\u200d സിസ്റ്റത്തില്\u200d പഠിപ്പിക്കേണ്ടി വന്നിരുന്നു. സാധ്യ പങ്കുചേര്\u200dക്കുന്ന സിസ്റ്റം വിലാസപ്പെടുത്താന്\u200d രണ്ട് ടെസ്റ്റ് സെറ്റുകള്\u200d വിട്ടുപ ഓരോ ട്രെയിനിങ്ങളുടെയും ഭാഷകള്\u200dക്കും ജോടികളുണ്ട് (സിസ്റ്റമുകള്\u200d മോണോളില്\u200d ഭാഷകളില്\u200d പരിശോധിക്കപ്പെട്ടിരുന്നു) മറ്റൊരു അത്ഭുതഭാഷ പരിശോധ സമര്\u200dപ്പിക്കപ്പെട്ട സിസ്റ്റത്തില്\u200d മുകളില്\u200d പ്രകടനം മാറ്റുന്നത് മോണോളില്\u200d ഭാഷകളിലും പല ഭാഷകളിലുമുള്ള മാതൃകയാണ്. പരീക്ഷിക്കപ്പെട്ട എല്ലാ ഭാഷകള്\u200dക്കും ഈ അടു പങ്കാളിയുള്ള ജോലിയുടെ വിവരണങ്ങളും ഫലങ്ങളും ലഭ്യമാകുന്നു https://sites.google.com/site/cogalexvisharedtask/.', 'no': 'Den delte oppgåva av arbeidsområdet CogALex-VI fokuserer på monospråk og fleirspråk identifisering av semantiske forhold. Vi oppgav opplæring og validating for dei følgjande språka: engelsk, tysk og kinesisk. Gjennomsiktig eit ordpar må systemet verta trent til å identifisera kva forholdet er mellom dei, med moglege val som er synonym, antonym, hypernimum og ingen forhold. To testsett vart sletta for å evaluera deltakende systema. Ein som inneheld par for kvar av øvingsspråk (systemet er evaluert i ein monospråk) og den andre foreslår eit overraska språk for å test a dei krysspråkskapasitetene for systemet. Mellom dei sendte systema vart det oppnådd ein transformeringsbasert modell i både monospråk og i fleirspråk innstillingane, for alle teste språka, som viser potensialene for denne nyleg innførte neuralarkitekturen. Delt oppgåvebeskriving og resultatet er tilgjengeleg på https://sites.google.com/site/cogalexvisharedtask/.', 'mt': 'Il-kompitu komuni tal-workshop CogALex-VI jiffoka fuq l-identifikazzjoni monolingwi u multilingwi tar-relazzjonijiet semantiċi. Aħna pprovdejna dejta ta’ taħriġ u validazzjoni għall-lingwi li ġejjin: Ingliż, Ġermaniż u Ċiniż. Minħabba pari ta’ kliem, is-sistemi kellhom jitħarrġu biex jidentifikaw liema relazzjoni tinsab bejniethom, bl-għa żliet possibbli kienu sinonimja, antonimja, ipernimija u l-ebda relazzjoni. Ġew rilaxxati żewġ settijiet ta’ testijiet għall-evalwazzjoni tas-sistemi parteċipanti. Wieħed li fih pari għal kull waħda mil-lingwi ta’ taħriġ (is-sistemi ġew evalwati b’mod monolingwi) u l-ieħor li jipproponi lingwa sorpriża biex jittestjaw il-kapaċitajiet ta’ trasferiment translingwi tas-sistemi. Among the submitted systems, top performance was achieved by a transformer-based model in both the monolingual and in the multilingual setting, for all the tested languages, proving the potentials of this recently-introduced neural architecture.  Id-deskrizzjoni kondiviża tal-kompitu u r-riżultati huma disponibbli fuq https://sites.google.com/site/cogalexvisharedtask/.', 'pl': 'Wspólne zadanie warsztatów CogALex-VI skupia się na jednojęzycznej i wielojęzycznej identyfikacji relacji semantycznych. Dostarczyliśmy dane szkoleniowe i walidacyjne dla następujących języków: angielskiego, niemieckiego i chińskiego. Biorąc pod uwagę parę słów, systemy musiały być przeszkolone, aby zidentyfikować, która relacja istnieje między nimi, a możliwymi wyborami była synonim, antonimia, hipernimia i żadna relacja. Wydano dwa zestawy testowe do oceny uczestniczących systemów. Jeden zawierający pary dla każdego z języków szkoleniowych (systemy zostały ocenione w sposób jednojęzyczny), a drugi proponujący język niespodzianki, aby sprawdzić możliwości transferu między językami systemów. Wśród przedłożonych systemów najwyższą wydajność osiągnął model oparty na transformatorze zarówno w otoczeniu jednojęzycznym, jak i wielojęzycznym, dla wszystkich testowanych języków, potwierdzając potencjały tej niedawno wprowadzonej architektury neuronowej. Opis wspólnego zadania i wyniki są dostępne na stronie internetowej https://sites.google.com/site/cogalexvisharedtask/.', 'ro': 'Sarcina comună a atelierului CogALex-VI se concentrează pe identificarea monolingvă și multilingvă a relațiilor semantice. Am furnizat date de instruire și validare pentru următoarele limbi: engleză, germană și chineză. Având în vedere o pereche de cuvinte, sistemele trebuiau instruite pentru a identifica relația dintre ele, posibilele alegeri fiind sinonime, antonimie, hipernimie și nicio relație. Au fost lansate două seturi de teste pentru evaluarea sistemelor participante. Una conține perechi pentru fiecare dintre limbile de formare (sistemele au fost evaluate în mod monolingv) și cealaltă propune o limbă surpriză pentru a testa capacitățile de transfer translingv ale sistemelor. Printre sistemele prezentate, performanța maximă a fost obținută printr-un model bazat pe transformator atât în cadrul monolingv, cât și în cadrul multilingv, pentru toate limbile testate, dovedind potențialul acestei arhitecturi neurale recent introduse. Descrierea activității partajate și rezultatele sunt disponibile la https://sites.google.com/site/cogalexvisharedtask/.', 'so': 'Shaqooyinka koogALex-VI waxay ku qoran yihiin aqoonsiga afka hooyo iyo aqoonsiga luuqadaha kala duduwan ee xiriirka semantika. Macluumaadyada waxbarashada iyo shaqeynta waxaan u siinay luuqadaha soo socda: Ingiriis, Jarmal iyo Shiino. Sida lagu siiyo hadal labo ah, waxaa habboon in nidaamka la tababariyo si uu u ogaado xiriirka dhexdooda, oo ay doorasho suurtagal ah u yihiin synonymimo, antonimo, hypernymi iyo xiriir la’aan. Waxaa la furay laba kooxood oo imtixaan ah si loo qiimeeyo nidaamka qayb-gelinta. Mid waxaa ku jira laba noocyo oo ku qoran luqada waxbarashada (nidaamka waxaa lagu qiimeeyaa qaab af muuqasho ah) tan kalena waxaa lagu soo jeedaa luqada yaab leh in lagu imtixaamo awoodaha isbedelka nidaamka. Isticmaalka la soo dhiibay waxaa ka mid ah sameynta horumarka lagu beddelay tusaale-qaab ah oo lagu beddelay labada luuqadood oo af kala duduwan, si ay u caddayso dhammaan afka la tijaabiyey, waxayna caddeysaa awoodka dhismahan neurada ee ugu dhow la soo bandhigay. Tilmaamaha shaqada ee wadajirka ah iyo resultinta waxaa laga helaa https://sites.google.com/site/cogalexvisharedtask/.', 'sr': 'Podijeljeni zadatak radionice CogALex-VI fokusira se na monojezičku i multijezičku identifikaciju semantičkih odnosa. Mi smo pružili podatke o obuci i validaciji za sljedeće jezike: engleski, nemački i kineski. S obzirom na parove reči, sistemi su morali biti obučeni da identifikuju kakvu vezu ima između njih, sa mogućim izborima da su sinonimi, antonimi, hipernimi i uopšte bez veze. Dva testa su otpuštena za procjenu sudjelujućih sustava. Jedan koji sadrži par za svaki jezik obuke (sistemi su procjenjivani na monojezički način) a drugi predlaže iznenađeni jezik kako bi testirali sposobnosti prevođenja kroz jezik sistema. Među podignutim sistemima, vrhunska funkcija je postignuta od transformatorskog model a na monojezičkom i multijezičkom postavljanju, za sve testovane jezike, dokazujući potencijale ove nedavno uvedene neuralne arhitekture. Описане задача и резултати су доступни на https://sites.google.com/site/cogalexvisharedtask/.', 'sv': 'Den gemensamma uppgiften för CogALex-VI-workshopen fokuserar på enspråkig och flerspråkig identifiering av semantiska relationer. Vi tillhandahöll utbildnings- och valideringsdata för följande språk: engelska, tyska och kinesiska. Med tanke på ett ordpar måste system utbildas för att identifiera vilken relation som finns mellan dem, med möjliga val som synonymer, antonymi, hypernymmi och ingen relation alls. Två testset släpptes för utvärdering av de deltagande systemen. Det ena innehöll par för vart och ett av utbildningsspråken (systemen utvärderades på ett enspråkigt sätt) och det andra innehöll ett överraskningsspråk för att testa systemens transspråkliga överföringsförmåga. Bland de inlämnade systemen uppnåddes toppprestanda genom en transformatorbaserad modell i både enspråkig och flerspråkig miljö, för alla testade språk, vilket bevisade potentialen i denna nyligen introducerade neurala arkitektur. Den delade uppgiftsbeskrivningen och resultaten finns tillgängliga på https://sites.google.com/site/cogalexvisharedtask/.', 'si': 'CogALex-VI වැඩසටහන්ගේ සම්බන්ධ වැඩසටහන් එක භාෂාවක් සහ ගොඩක් භාෂාවක් සම්බන්ධ සම්බන්ධ පරීක්ෂණය සඳ අපි පස්සේ භාෂාවට ප්\u200dරශ්නය සහ විශ්ලේෂණ දත්ත දුන්නා: ඉංග්\u200dරීසි, ජර්මන් සහ චීනියා වචනයක් දෙන්න පුළුවන්, පද්ධතියක් ඔවුන්ගේ අතර කොච්චර සම්බන්ධයක් තියෙන්නේ කියලා පුළුවන් තීරණය කරනවා, පුළුවන් තීරණය සම පරීක්ෂණ සෙට් දෙකක් ප්\u200dරතික්\u200dරියාත්මක විශ්වාස කරන්න. ප්\u200dරධාන භාෂාවල් එක්කෙනෙක් සම්බන්ධ කරනවා (පද්ධතියක් එක්ක භාෂාවක් විදියට පරීක්ෂණය කරනවා) අනිත් භාෂාවක් ප්\u200dරශ්න පිළිබඳු පද්ධතිය අතර, උපරිම ක්\u200dරියාත්මක ප්\u200dරමාණයක් ප්\u200dරමාණය කරලා තියෙන්නේ එක භාෂාවක් වගේම වගේම වගේම වගේම වගේම භාෂාවක් වලින් ව සමාගත වැඩක් විස්තර සහ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිපත https://sites.google.com/site/cogalexvisharedtask/.', 'ur': 'CogALex-VI کارشاپ کا مشترک کام سیمانٹی رابطہ کی ایک زبان اور بہت زبان کی شناسایی پر تمرکز کرتا ہے. ہم نے انگلیسی، جرمن اور چینی کے لئے آموزش اور تحقیق دینے کے لئے اطلاعات دی۔ ایک کلمہ جوڑے کے ذریعہ، سیستم کی تعلیم کی جاتی تھی کہ ان کے درمیان کس تعلق ہے، اس کے ساتھ ممکن انتخاب کے ساتھ سینونیمی، آنٹنی، hypernymy اور کوئی تعلق نہیں ہے. دو امتحان سٹے شرکت سیستموں کے مطالعہ کے لئے آزاد کئے گئے۔ ایک تعلیم زبانوں کے لئے جو جوڑے ہیں (سیستموں کو ایک زبان کی روش میں مطالبہ کیا گیا تھا) اور دوسری زبان کو ایک عجیب زبان کی پیشنهاد کرتا ہے کہ سیستموں کی کروسٹ زبان ترنسیٹ قابلیت کو امتحان کرے۔ تحویل کیے گئے سیستموں کے درمیان، بالا عملکرد ایک تغییر بوسیدہ موڈل سے پہنچائی گئی، دونوں ایک زبان اور بہت سی زبان تنظیم میں، تمام آزمائش زبانوں کے لئے، اس اخیر سے پہنچائی نئورل معماری کی طاقت ثابت کر رہی تھی۔ مشترک دنیا کا سفارش اور نتیجے موجود ہیں https://sites.google.com/site/cogalexvisharedtask/.', 'ta': 'CogALex-VI பணியின் பகிர்ந்த பணி நாங்கள் பின்வரும் மொழிகளுக்கு பயிற்சி மற்றும் சரிபார்ப்பு தகவல்களை வழங்கினோம்: ஆங்கிலம், ஜெர் ஒரு வார்த்தை ஜோடி கொடுத்தால், அமைப்புகளுக்கு எந்த உறவு இடையே இருக்கிறது என்பதை கண்டுபிடி பங்கு அமைப்புகளை மதிப்பிடுவதற்காக இரண்டு சோதனை அமைப்புகள் வெளியிடப்பட்டது. One containing pairs for each of the training languages (systems were evaluated in a monolingual fashion) and the other proposing a surprise language to test the crosslingual transfer capabilities of the systems.  கொடுக்கப்பட்ட அமைப்புகளில், மேல் செயல்பாடு மாற்றும் மாதிரி மாதிரியால் மாற்றும் மாதிரி மாற்றம் மற்றும் பல மொழி அமைப்பில், அனைத்து சோதிக்கப்பட்ட மொழிகள பகிர்ந்த பணியின் விளக்கம் மற்றும் முடிவுகள் கிடைக்கும் https://sites.google.com/site/cogalexvisharedtask/.', 'uz': "The shared task of the CogALex-VI workshop focuses on the monolingual and multilingual identification of semantic relations.  Biz quyidagi tillar uchun taʼminlovchi va haqiqiqiylik maʼlumotni yaratdik: Inglizcha, Olmon va Xitoycha. Bir so'z bilan bir so'z bo'lgan bo'lsa, ularning orasidagi munosabatlarni aniqlash uchun tizimni o'rganish kerak. Signoni, antoniya, hypernemiya va hech qanday aloqa emas. @ info: whatsthis Birinchi tilning bir xil tilida (tizimlar monolik tilda qiymat qilinadi) va boshqa bir tashqi tilni tizimning qo'shish imkoniyatini sinash uchun ajoyib tilni anglatadi. Joʻnatilgan tizimlardan bir yuqori bajarish monolingual asosiy modeli va ko'plab tillar moslamalarida, hamma sinab qilingan tillar uchun, bu yaqinda ishga tushirilgan neural arxituvning imkoniyatlarini aniqlaydi. @ info: status https://sites.google.com/site/cogalexvisharedtask/.", 'vi': 'Việc chia sẻ của xưởng nghiên cứu CogALex-VI tập trung vào việc nhận dạng ngôn ngữ và đa dạng các quan hệ theo ngữ pháp. Chúng tôi cung cấp dữ liệu huấn luyện và xác nhận cho các ngôn ngữ: Anh, Đức và Trung Quốc. Dựa vào một cặp từ, hệ thống phải được huấn luyện để xác định mối quan hệ nào giữa họ, với các lựa chọn có thể là đồng nghĩa, antoonyy, Hypernymy và không có liên quan gì cả. Hai bộ thử được phát ra để đánh giá hệ thống tham gia. Một cặp chứa hợp cho mỗi ngôn ngữ huấn luyện (các hệ thống được đánh giá bằng một cách ngôn ngữ độc đáo) và một bên đề xuất một ngôn ngữ ngạc nhiên để thử khả năng truyền tải xuyên ngôn ngữ của hệ thống. Trong các hệ thống được gửi đến, khả năng cao được đạt được nhờ một mô hình người biến đổi cả ngôn ngữ và chung ngôn ngữ, cho tất cả các ngôn ngữ được thử nghiệm, cho thấy khả năng của kiến trúc thần kinh được giới thiệu gần đây. Mô tả công việc chia sẻ và kết quả có mặt tại https://sites.google.com/site/cogalexvisharedtask/.', 'bg': 'Споделената задача на семинара се фокусира върху едноезичното и многоезичното идентифициране на семантичните отношения. Предоставяме данни за обучение и валидиране на следните езици: английски, немски и китайски. Като се има предвид двойка думи, системите трябваше да бъдат обучени да идентифицират коя връзка има между тях, като възможните избори бяха синоними, антоними, хипернимия и никаква връзка. Бяха пуснати два теста за оценка на участващите системи. Единият съдържа двойки за всеки от обучителните езици (системите са оценени едноезично), а другият предлага изненадващ език за тестване на междуезичните възможности за трансфер на системите. Сред представените системи максимална производителност беше постигната чрез трансформаторен модел както в едноезична, така и в многоезична обстановка, за всички тествани езици, доказвайки потенциала на тази неотдавна въведена невронна архитектура. Описание на споделената задача и резултатите са достъпни на https://sites.google.com/site/cogalexvisharedtask/.', 'nl': 'De gezamenlijke taak van de CogALex-VI workshop richt zich op de eentalige en meertalige identificatie van semantische relaties. We hebben trainings- en validatiegegevens verstrekt voor de volgende talen: Engels, Duits en Chinees. Gezien een woordenpaar moesten systemen getraind worden om te identificeren welke relatie tussen hen bestaat, waarbij mogelijke keuzes synoniem, antoniem, hypernymie en helemaal geen relatie waren. Twee testsets werden uitgebracht voor het evalueren van de deelnemende systemen. De ene bevat paren voor elk van de trainingstalen (systemen werden in een eentalige manier geëvalueerd) en de andere stelt een verrassingstal voor om de meertalige overdrachtsmogelijkheden van de systemen te testen. Van de ingediende systemen werden topprestaties bereikt door een transformatorgebaseerd model, zowel in de eentalige als in de meertalige omgeving, voor alle geteste talen, wat de mogelijkheden van deze recent geïntroduceerde neurale architectuur aantoont. De gedeelde taakbeschrijving en de resultaten zijn beschikbaar op: https://sites.google.com/site/cogalexvisharedtask/.', 'da': 'Den fælles opgave for CogALex-VI workshop fokuserer på ensproget og flersproget identifikation af semantiske relationer. Vi leverede trænings- og valideringsdata for følgende sprog: engelsk, tysk og kinesisk. I betragtning af et ordpar måtte systemer trænes til at identificere, hvilken relation der er mellem dem, idet mulige valg var synonymer, antonymi, hypernymi og slet ingen relation. Der blev udgivet to testsæt til evaluering af de deltagende systemer. Det ene indeholder par for hvert af uddannelsessprogene (systemerne blev evalueret på ensproget måde), og det andet foreslår et overraskelsessprog for at teste systemernes tværsprogede overførselsevne. Blandt de indsendte systemer blev topydelsen opnået ved hjælp af en transformer-baseret model i både ensprogede og flersprogede omgivelser, for alle de testede sprog, hvilket beviste potentialet i denne nyligt introducerede neurale arkitektur. Beskrivelsen af den delte opgave og resultaterne er tilgængelige på https://sites.google.com/site/cogalexvisharedtask/.', 'hr': 'Zajednički zadatak radionice CogALex-VI fokusira se na monojezičku i multijezičku identifikaciju semantičkih odnosa. Mi smo pružili podatke o obuci i validaciji za sljedeće jezike: engleski, njemački i kineski. S obzirom na parove riječi, sustavi su morali biti obučeni kako bi identifikovali kakva je veza između njih, s mogućim izborima sinonim, antonimijom, hipernimum i nikakvom vezom. Dvije testne sete su objavljene za procjenu sudjelujućih sustava. Jedan koji sadrži par za svaki jezik obuke (sustavi su procijenjeni na monojezički način) a drugi predlaže iznenađenim jezikom kako bi testirali sposobnosti prevođenja preko jezika sustava. Među podanim sustavima, vrhunski učinkovit postignuo je model koji se temelji na transformaciji na monojeziku i na multijezičkom postavljanju, za sve testirane jezike, dokazujući potencijale ove nedavno uvedene neuralne arhitekture. Opis zajedničkog zadatka i rezultati su dostupni na https://sites.google.com/site/cogalexvisharedtask/.', 'id': 'Tugas berbagi dari workshop CogALex-VI fokus pada identifikasi monobahasa dan multibahasa hubungan semantis. Kami menyediakan data pelatihan dan validasi untuk bahasa berikut: Bahasa Inggris, Jerman dan Cina. Berdasarkan sepasang kata, sistem harus dilatih untuk mengidentifikasi hubungan mana antara mereka, dengan kemungkinan pilihan adalah sinonimi, antonimi, hipernimi dan tidak ada hubungan sama sekali. Dua set tes dibebaskan untuk mengevaluasi sistem yang berpartisipasi. Salah satu mengandung pasangan untuk setiap bahasa latihan (sistem diteliti dengan cara monobahasa) dan yang lain melaporkan bahasa kejutan untuk menguji kemampuan transfer saling bahasa sistem. Di antara sistem yang dihantar, prestasi terbaik dicapai oleh model berdasarkan transformer dalam kedua monobahasa dan dalam pengaturan multibahasa, untuk semua bahasa yang diuji, membuktikan potensi arsitektur saraf yang baru-baru ini diperkenalkan. Deskripsi tugas berbagi dan hasilnya tersedia di https://sites.google.com/site/cogalexvisharedtask/.', 'de': 'Die gemeinsame Aufgabe des CogALex-VI Workshops konzentriert sich auf die ein- und mehrsprachige Identifikation semantischer Beziehungen. Wir haben Trainings- und Validierungsdaten für folgende Sprachen bereitgestellt: Englisch, Deutsch und Chinesisch. Bei einem Wortpaar mussten Systeme trainiert werden, um zu erkennen, welche Beziehung zwischen ihnen besteht, wobei mögliche Entscheidungen Synonym, Antonym, Hypernymie und überhaupt keine Beziehung waren. Zur Evaluierung der teilnehmenden Systeme wurden zwei Testsets veröffentlicht. Die eine enthält Paare für jede der Ausbildungssprachen (die Systeme wurden einsprachig bewertet) und die andere schlägt eine Überraschungssprache vor, um die sprachübergreifenden Transferfähigkeiten der Systeme zu testen. Unter den eingereichten Systemen wurde die Spitzenleistung durch ein transformatorbasiertes Modell sowohl im monolingualen als auch im multilingualen Setting für alle getesteten Sprachen erreicht, das die Potenziale dieser kürzlich eingeführten neuronalen Architektur belegt. Die gemeinsame Aufgabenbeschreibung und die Ergebnisse finden Sie unter https://sites.google.com/site/cogalexvisharedtask/.', 'ko': 'CogAlex VI 워크숍의 공동 임무는 의미 관계의 단일 언어와 다중 언어 식별에 집중된다.우리는 다음과 같은 언어의 교육과 검증 데이터를 제공했다. 영어, 독일어, 중국어.한 쌍의 단어를 정하려면 시스템은 반드시 훈련을 거쳐 그들 간의 관계를 확정해야 한다. 가능한 선택은 동의어, 반의어, 초의어와 전혀 관계가 없다.참여 시스템을 평가하기 위한 두 세트의 테스트 집합을 발표했다.하나는 각 훈련 언어를 포함하는 짝짓기(시스템은 단어로 평가), 다른 하나는 깜짝 언어를 제시하여 시스템의 다중 언어 이동 능력을 테스트했다.제출된 시스템에서 모든 테스트 언어에 대해 변환기를 바탕으로 하는 모델은 단일 언어와 다중 언어 환경에서 최상의 성능을 얻었고 최근에 도입된 신경 구조의 잠재력을 증명했다.공유 작업 설명과 결과는https://sites.google.com/site/cogalexvisharedtask/.', 'fa': 'وظیفه مشترک کارگاه CogALex-VI روی شناسایی یک زبان و چندین زبان رابطه\u200cهای semantic تمرکز می\u200cکند. ما داده های آموزش و تصدیق دادیم برای زبانهای زیر: انگلیسی، آلمانی و چینی. با وجود یک جفت کلمه، سیستم\u200cها باید آموزش داده شود تا شناسایی که کدام رابطه بین آنها دارد، با انتخاب\u200cهای ممکن همسانی، آنتونی، هیپرنیمی و هیچ رابطه\u200cای ندارد. دو مجموعه آزمایش برای ارزیابی سیستم مشارکت آزاد شد. یکی که برای هر زبان آموزش (سیستم\u200cها در یک روش تک زبان ارزیابی می\u200cشوند) و دیگری که زبان سورپرایز می\u200cکند تا توانایی انتقال کل زبان\u200cهای سیستم\u200cها را امتحان کند. بین سیستم\u200cهای تحویل داده شده، عملکرد بالا توسط یک مدل تغییر دهنده در هر دو تنظیم یک زبان و یک تنظیم بسیاری زبان، برای همه زبان\u200cهای آزمایش، ثابت کردن توانایی این معماری عصبی که تازگی معرفی شده است، به دست آورده شد. توضیح کار مشترک و نتیجه\u200cها در دسترس هستند https://sites.google.com/site/cogalexvisharedtask/.', 'af': "Die gedeelde taak van die CogALex-VI werkshop fokus op die monolinglike en multilinglike identifikasie van semantiese verwantings. Ons verskaf onderwerp en geldigheidsdata vir die volgende tale: Engels, Duits en Sjinees. Omdat 'n woord paar gegee het, moet stelsels onderwerp word om te identifiseer wat verwanting tussen hulle hou, met moontlik keuses synonyme, antonyme, hypernimum en geen verwanting. Twee toets stel is verlos vir evaluering van die deelnadende stelsels. Een bevat paar vir elke van die onderwerp tale (stelsels was in 'n monolinglike modus evalueer) en die ander voorstel 'n verrassing taal om die kruistale oordrag kapabiliteite van die stelsels te toets. onder die voorgestuurde stelsels was die bo-prestasie bereik deur 'n transformeerder-gebaseerde model in beide die monolinglike en in die multilinglike opstelling, vir al die toets tale, die potensielle van hierdie onlangs-ingestelde neurale arkitektuur te bevestig. Die gedeelde taak beskrywing en die resultate is beskikbaar by https://sites.google.com/site/cogalexvisharedtask/.", 'sw': 'Kazi ya kushirikiana katika warsha ya CogALex-VI imejikita kwenye utambulisho wa lugha na lugha mbalimbali wa mahusiano ya kimapenzi. Tulifanya taarifa za mafunzo na uhakika kwa lugha ifuatayo: Kiingereza, Kijerumani na Kichina. Kutokana na neno la majina wawili, mifumo ilipaswa kufundishwa kutambua uhusiano gani kati yao, na chaguo zilizowezekana kuwa na ushirikiano, ubaguzi, ukarimu na hakuna uhusiano wowote. Mitando mawili ya majaribio yalitolewa kwa ajili ya kutathmini mfumo wa ushiriki. Mmoja ambao una ndoa kwa kila moja ya lugha za mafunzo (mifumo ilipitishwa kwa namna ya lugha ya kiutaifa) na mwingine anayependekeza lugha ya kushangaza ili kujaribu uwezo wa usafirishaji wa lugha za lugha. Miongoni mwa mifumo iliyotolewa, utendaji wa juu ulifanikiwa na muundo wa mabadiliko katika mazingira ya lugha na katika mazingira ya lugha mbalimbali, kwa lugha zote zilizojaribiwa, unaonyesha uwezekano wa ujenzi huu wa kijamii ulioanzishwa hivi karibuni. Maelezo yanayoshirikishwa na matokeo yanapatikana katika https://sites.google.com/site/cogalexvisharedtask/.', 'tr': 'CogALex-VI çalışmanyň paylaşyk işi semantik baglaýyşlaryň monodil we köp dillerini tanyşdyrmak üçin üns berýär. Biz indiki diller üçin öwrenme we taýýarlama maglumatlary berdik: Iňlisçe, Almança we Çinçe. Bir söz çift bolsa sistemalar olaryň arasyndaky haýsy baglaýyşyny tanamak üçin bilinmeli bolmaly. Mümkin seçmeler synonymy, antonimi, hipernimi we hiç hili bir baglaýyşyk ýok. Şahsy sistemleri çykmak üçin iki synag çykyldy. Eğitim dilleriniň her biri üçin çift bar (sistemalar monolingüň şeklinde deňlendirildi) we beýlekisi sistemalaryň karrolyk dillerini barlamak üçin geň bir dil teklip edýär. Iňki gönderilen sistemlerde, üst täsirler monolingüň we multilingüň düzümlerinde , üst täsirler bolan nuýral arhitekturyň mümkinçiliklerini barlap başarmady. Paýlanan täblisaň waspy we netijesi meňzeş bar https://sites.google.com/site/cogalexvisharedtask/.', 'sq': 'Detyra e përbashkët e seminarit CogALex-VI përqëndrohet në identifikimin monogjuhësor dhe shumëgjuhësor të marrëdhënieve semantike. Kemi dhënë të dhëna për trajnimin dhe vlerësimin e gjuhëve të ardhshme: anglisht, gjermanisht dhe kinez. Duke dhënë një çift fjalësh, sistemet duhej të trajnuar për të identifikuar se cili lidhje mban mes tyre, me zgjedhje të mundshme që ishin sinonimi, antonimi, hipernimi dhe asnjë lidhje fare. Dy grupe testesh u lëshuan për vlerësimin e sistemeve pjesëmarrëse. Një që përmban çifte për secilin nga gjuhët e trajnimit (sistemet u vlerësuan në një mënyrë monogjuhësore) dhe tjetri që propozon një gjuhë surprizë për të testuar aftësitë e transferimit ndërgjuhësor të sistemeve. Midis sistemeve të paraqitura, shfaqja më e lartë u arrit nga një model i bazuar në transformues si në një mjedis monogjuhës, ashtu edhe në një mjedis shumëgjuhës, për të gjitha gjuhët e testuara, duke provuar potencialet e kësaj arkitekture nervore të paraqitur kohët e fundit. Përshkrimi i detyrës së përbashkët dhe rezultatet janë në dispozicion në https://sites.google.com/site/cogalexvisharedtask/.', 'az': 'CogALex-VI çalışmalarının paylaşılan işi semantik əlaqələrinin monodil və çoxlu dil tanımasına odaqlanır. Biz indiki dillər üçün təhsil və təhsil verilən məlumatları təyin etdik: İngilizce, Alman və Çin. Bir söz çift sayılırsa, sistemlərin aralarında hansı ilişkisi olduğunu tanıtmaq üçün təhsil edilməli idi, mümkün seçimlər sinonimi, antonimi, hipernimi və heç bir ilişkisi olmayan. İki sınama qurğuları iştirak sistemlərini değerləşdirmək üçün yayınlandı. Hər təhsil dillərinin cütləri içərik (sistemləri monodil modunda değerlendirildi) və digəri sistemlərin qarşılıq dillərin transfer qabiliyyətini imtahana çəkmək üçün təəccüblü dili təklif edir. İmzalanmış sistemlərin arasında, ən yüksək performansı monodil və çoxlu dil ayarlarında transformer-tabanlı modeli ilə, müxtəlif dillər üçün, yenidən tanınmış bu nöral arhitektarının potensiallarını təsdiqləyir. Bölüşdürülən işlər təsbiqi və sonuçlar faydalanır https://sites.google.com/site/cogalexvisharedtask/.', 'hy': 'The shared task of the CogALex-VI workshop focuses on the monolingual and multilingual identification of semantic relations.  Մենք տրամադրեցինք ուսուցման և հավասարման տվյալներ հետևյալ լեզուների համար՝ անգլերեն, գերմաներեն և չինարեն: Երկու բառ պարունակելով, համակարգերը ստիպված էին ուսուցանել, որպեսզի հասկանան, թե որն է իրենց միջև կապը, և հնարավոր ընտրությունները սինոնիմիա, անտոնիմիա, հիպերնիմիա և ոչ մի կապ: Երկու փորձարկումներ արձակեցին մասնակցության համակարգերի գնահատման համար: Մեկը պարունակում է զույգեր յուրաքանչյուր ուսուցման լեզու համար (համակարգերը գնահատվել են միալեզվով) իսկ մյուսը առաջարկում է զարմանալի լեզու, որպեսզի ստուգեն համակարգերի խաչլեզվով փոխանցման ունակությունները: Հաշվի առնելու համակարգերի միջոցով լավագույն արդյունքը հասավ մեկլեզու և բազլեզու մոդելի միջոցով, բոլոր փորձարկված լեզուների համար, ապացուցելով վերջերս ներկայացված նյարդային ճարտարապետության պոտենցիալը: Համադրված խնդիրների նկարագրությունը և արդյունքները հասանելի են https://sites.google.com/site/cogalexvisharedtask/.', 'am': 'የCogALex-VI ሰርቨርስቲ ስራ በሞሎልቋንቋ እና በብዙ ቋንቋ ግንኙነት ላይ ማሳየት ነው፡፡ ለመግለጫ እና ማረጋገጫ ዳታዎችን ለመግለጫ ቋንቋዎች: እንግሊዝኛ፣ ጀርመን እና ቻይና ሰጠን፡፡ አንዲት ቃላት የተሰጠ፣ የስርዓት ግንኙነት ምን እንደሆነ ማረጋገጥ ያስተምራል ነበር፤ ምንም ግንኙነት የለውም፡፡ ሁለት የሞክራዊ ተሟጋቾች ሲስተምሩ ተፈትተዋል፡፡ አንዱ ለሁሉም ትምህርት ቋንቋዎች ሁለት ዓይነቶች የሚኖሩት (ስርዓቶች በሞላዊ ቋንቋ እንደሚሸክሙ) ሁለተኛውም የበደነቂው ቋንቋ የስርዓቱን መዘዋወር ችሎታዎችን ለመፈትነው የሚያስፈልግ ነው፡፡ በተዘጋጀው ስርዓቶች ውስጥ፣ የደረጃው ስርዓት በሞሎ ቋንቋ እና በብዙ ቋንቋ በተፈታተኑት ቋንቋዎች ሁሉ፣ ለዚህ የቀድሞው የኒጀር መሠረት ስርዓት የሚችሉትን ችሎታዎችን ያስታውቃል፡፡ የአሁኑን ፋይል አስቀምጥ https://sites.google.com/site/cogalexvisharedtask/.', 'bn': 'কগালেক্স-ভিআই কর্মশালার শেয়ার কর্মশালার দৃষ্টিভঙ্গি এবং সেমান্টিক সম্পর্কের প্রতি বহুভাষার পরিচিতির উপর মনোযোগ দিয়ে আমরা নিম্নলিখিত ভাষার জন্য প্রশিক্ষণ ও বৈধ তথ্য প্রদান করেছি: ইংরেজি, জার্মান এবং চীনা। একটি শব্দ জোড়া দিয়ে সিস্টেম চিহ্নিত করার জন্য প্রশিক্ষণ প্রদান করা উচিত ছিল যে তাদের মধ্যে কোন সম্পর্ক আছে, যেখানে সম্ভাব্য সিনোনিমি, এন্টোনি অংশগ্রহণকারী সিস্টেম মূল্যায়নের জন্য দুই পরীক্ষা সেট মুক্তি প্রদান করা হয়েছে। প্রশিক্ষণের প্রত্যেকটি ভাষার জন্য জোড়া আছে (সিস্টেম মূল্যায়ন করা হয়েছে) এবং অন্যটি ব্যবস্থার ক্রস্ভাষাভাষী পরীক্ষা করার জন্য এক বিস্ময়কর ভাষা প্ জবাব দিয়েছে সিস্টেমের মধ্যে সেরা প্রদর্শনীর মাধ্যমে একটি পরিবর্তনের ভিত্তিক মডেল দ্বারা অর্জন করা হয়েছে, যা সাম্প্রতিক পরীক্ষার জন্যে এই নিউরুল ভাষার প্রতিষ্ঠান শেয়ার করা কাজের বর্ণনা এবং ফলাফল পাওয়া যায় https://sites.google.com/site/cogalexvisharedtask/.', 'bs': 'Zajednički zadatak radionice CogALex-VI fokusira se na monojezičku i multijezičku identifikaciju semantičkih odnosa. Mi smo pružili podatke o obuci i validaciji za sljedeće jezike: engleski, nemački i kineski. S obzirom na parove riječi, sistemi su morali biti obučeni da identifikuju kakvu vezu ima između njih, s mogućim izborima da su sinonimi, antonimi, hipernimi i uopšte bez veze. Dva testa su otpuštena za procjenu sustava sudjelovanja. Jedan koji sadrži par za svaki jezik obuke (sistemi su procjenjivani na monojezički način) a drugi predlaže iznenađeni jezik kako bi testirali sposobnosti prevođenja preko jezika sustava. Među podignutim sustavima, vrhunska funkcija je ostvarila model koji se osnovao na transformaciji i na monojezičkom, i na multijezičkom setu, za sve testirane jezike, dokazujući potencijale ove nedavno uvedene neuralne arhitekture. Podijeljeni opis zadataka i rezultati su dostupni na https://sites.google.com/site/cogalexvisharedtask/.', 'ca': "La tasca compartida del taller CogALex-VI es centra en la identificació monolingüe i multilingüe de les relacions semàntiques. We provided training and validation data for the following languages: English, German and Chinese.  Dant un parell de paraules, els sistemes havien de ser entrenats per identificar quina relació hi ha entre ells, les opcions possibles eren sinonimia, antonimia, hipernimi i cap relació. Es van alliberar dos grups d'exàmens per avaluar els sistemes participants. Un contenent parells per cada una de les llengües d'entrenament (els sistemes van ser evaluats de forma monolingüa) i l'altre proposant un llenguatge sorprenent per provar les capacitats de transfer ència translingüística dels sistemes. Entre els sistemes submetits, el millor rendiment va ser aconseguit amb un model basat en transformadors en un entorn monolingüe i multilingüe, per a totes les llengües provades, demostrant el potencial d'aquesta arquitectura neuronal recentment introduïda. La descripció compartida de la tasca i els resultats estan disponibles en https://sites.google.com/site/cogalexvisharedtask/.", 'cs': 'Společný úkol workshopu CogALex-VI se zaměřuje na jednojjazyčnou a vícejazyčnou identifikaci sémantických vztahů. Poskytli jsme školení a validační údaje pro následující jazyky: angličtinu, němčinu a čínštinu. Vzhledem k páru slov bylo nutné systémy trénovat, aby identifikovaly, který vztah mezi nimi drží, přičemž možné volby byly synonymie, antonymie, hypernymie a vůbec žádný vztah. Pro hodnocení zúčastněných systémů byly vydány dva testovací sady. Jeden obsahuje páry pro každý z výcvikových jazyků (systémy byly hodnoceny jednojzyčně) a druhý navrhuje překvapivý jazyk pro otestování schopností přenosu mezi jazyky systémů. Mezi předloženými systémy bylo dosaženo špičkového výkonu modelu založeného na transformátoru v jednojzyčném i vícejazyčném prostředí pro všechny testované jazyky, což dokazuje potenciál této nedávno zavedené neuronové architektury. Popis sdíleného úkolu a výsledky jsou k dispozici na adrese https://sites.google.com/site/cogalexvisharedtask/.', 'et': 'CogALex-VI seminari ühine ülesanne keskendub semantiliste suhete ühekeelsele ja mitmekeelsele tuvastamisele. Pakkusime koolitus- ja valideerimisandmeid järgmistes keeltes: inglise, saksa ja hiina keel. Sõnade paari puhul tuli süsteeme koolitada, et teha kindlaks, milline seos nende vahel on, võimalikud valikud on sünonüümia, antonüümia, hüpernüümia ja mitte mingit seost. Osalevate süsteemide hindamiseks anti välja kaks testikomplekti. Üks sisaldab paare igale koolituskeele (süsteeme hinnati ühekeelselt) ja teine pakkus välja üllatuskeele, et testida süsteemide keeleülekande võimet. Esitatud süsteemide hulgas saavutati tipptasemel jõudlus transformaatoril põhineva mudeliga nii ühe- kui ka mitmekeelses keskkonnas kõigi testitud keelte puhul, tõestades hiljuti kasutusele võetud närviarhitektuuri potentsiaali. Ühisülesande kirjeldus ja tulemused on kättesaadavad aadressil https://sites.google.com/site/cogalexvisharedtask/.', 'fi': 'CogALex-VI -työpajan yhteinen tehtävä keskittyy semanttisten suhteiden yksikieliseen ja monikieliseen tunnistamiseen. Tarjoamme koulutus- ja validointitietoja seuraaville kielille: englanti, saksa ja kiina. Kun otetaan huomioon sanapari, järjestelmiä oli koulutettava tunnistamaan, mikä suhde niiden välillä on, ja mahdolliset valinnat ovat synonyymi, antonyymi, hypernyymi ja mitään suhdetta. Osallistuvien järjestelmien arviointia varten julkaistiin kaksi testisarjaa. Toisessa oli pareja kullekin koulutuskielelle (järjestelmät arvioitiin yksikielisesti) ja toisessa ehdotettiin yllätyskieltä järjestelmien monikielisen siirtokyvyn testaamiseksi. Esitetyistä järjestelmistä huippusuorituskyky saavutettiin muuntajapohjaisella mallilla sekä yksikielisessä että monikielisessä ympäristössä kaikilla testattavilla kielillä, mikä osoitti tämän hiljattain käyttöön otetun neuroarkkitehtuurin potentiaalit. Jaetun tehtävän kuvaus ja tulokset ovat saatavilla osoitteessa https://sites.google.com/site/cogalexvisharedtask/.', 'jv': 'Awak dhéwé nggawe gerakno CogAlex-Vl kuwi nggawe gerakno kanggo langgar sapa-langgar lan akeh langgar sampek kudu winih. Awak dhéwé ngewehke karo data nggawe kanggo langgambar kapen: Inggris, alaman lan Cines. Sing kelas telas telas, sistem diangkat ono luwih nggawe geranggap perusahaan karo perusahaan karo hal-hal iki dadi, lan akeh iso nguasai sinanyomi, antanymi, akeranim lan akeh barêng-barêng. Display Suara ing sembarang panjur kanggo sabên langga turuné (sistem kuwi nggawe gerampen karo modalité sing kotak ingkang) lan nganggep sistem sing sabên seneng pisan bangsa kanggo ujian sistem kuwi kapat kanggo tukang nggawe luwih apik. Jejaring wong https://sites.google.com/site/cogalexvisharedtask/.', 'sk': 'Skupna naloga delavnice CogALex-VI se osredotoča na enojezično in večjezično identifikacijo semantičnih odnosov. Zagotovili smo podatke o usposabljanju in potrjevanju za naslednje jezike: angleščina, nemščina in kitajščina. Glede na par besed je bilo treba sisteme usposobiti, da bi ugotovili, katera relacija je med njimi, pri čemer so možne izbire sinonimija, antonimija, hipernimija in sploh nobena relacija. Za ocenjevanje sodelujočih sistemov sta bila izdana dva testna sklopa. Eden vsebuje pare za vsak jezik usposabljanja (sistemi so bili ovrednoteni enojezično), drugi pa predlaga jezik presenečenja za testiranje zmogljivosti medjezičnega prenosa sistemov. Med predloženimi sistemi smo najboljšo zmogljivost dosegli s transformatorskim modelom v enojezičnem in večjezičnem okolju za vse preizkušene jezike, kar dokazuje potenciale te nedavno uvedene nevronske arhitekture. Opis opravila v skupni rabi in rezultati so na voljo na spletni strani https://sites.google.com/site/cogalexvisharedtask/.', 'ha': "Suna da raban aikin CogalEx-6 na fokus kan shaidar masu mutane da multilafu. Mun bãyar da data na tsari da inganci wa lugha da ke jẽre: Ingiriya, Jarman da China. Given a word pair, systems had to be trained to identify which relation holds between them, with possible choices being synonymy, antonymy, hypernymy and no relation at all.  An saka matsali biyu dõmin an evaluate tsarin shirin ayuka. Wani mai ƙunsa da nau'i biyu ga kowace harshen mafarin aiki (an evaluate system'ura cikin shirin ayuka da aka yi wa rabo) da ɗayan na'anar da wata lugha mai ban sha'awa dõmin ya jarraba abincin transfer na'urar-harshen na'ura. Daga cikin shirin ayukan da aka shigar shi, ya cika mafarinsa da wata motsi mai shawara a cikin shirin ayuka da aka bada shi, da kuma a cikin tsarin mulki-lingui, na jarraba muhimmin wannan na'urar aikin da aka farata a yanzu-yanzu. Ana samun rabon aiki da ake share da matsala da https://sites.google.com/site/cogalexvisharedtask/.", 'he': 'המשימה המשותפת של מסעדה CogALex-VI מתמקדת על זיהוי יחסים סמנטיים מונושפתיים ומרבות שפתיים. סיפקנו מידע אימון ואישור לשפות הבאות: אנגלית, גרמנית וסינית. בהתחשב בזוג מילים, מערכות נאלצו לאמן לזהות איזה קשר יש ביניהם, עם אפשרויות בחירות הן סינונימיה, אנטונימיה, היפרנימיה ולא שום קשר בכלל. שני קבוצות בדיקות שוחררו כדי להעריך את המערכות המשתתפות. One containing pairs for each of the training languages (systems were evaluated in a monolingual fashion) and the other proposing a surprise language to test the crosslingual transfer capabilities of the systems.  Among the submitted systems, top performance was achieved by a transformer-based model in both the monolingual and in the multilingual setting, for all the tested languages, proving the potentials of this recently-introduced neural architecture.  תיאור המשימה המשותף והתוצאות זמינים ב https://sites.google.com/site/cogalexvisharedtask/.', 'bo': 'CogALex-VI ལས་འགན་སྤྱོད་ཀྱི་ལས་འགན་སྤྱད་ནི་སྐད་ཡིག་དང་སྐད་ཡིག་ཆ་རྣམས་ལ་མཐུན་གཏོང་བྱེད་ཀྱི་ཡོད། ང་ཚོས་གཤམ་གྱི་སྐད་རིགས་ལ་སློབ་ཐག་གཙོ་རིམ། སྐད་རིགས། དཔེ་དབྱིན་དང་། སྐད་ཡིག་དང་། རྒྱ་ནག་ ཐ་སྙད་གཉིས་པ་ཞིག་གིས་མཐུན་དགོས་པ་ལས། མ་ལག་གིས་དེ་ཚོ་དང་མཐུན་འབྲེལ་བ་གང་འདྲ་ཡིན་མིན་ན་དགོས་པ་ལས། རྒྱལ་སྐྱོར་མ་ལག་ལ་བསྟར་པར་བརྟག་ཞིབ་གཉིས་ཀྱི་སྒྲིག་འགོད་བྱས་པ སྐད་ཡིག་ཆ་རེ་རེའི་ནང་དུ་གཉིས་ཆ་གཅིག་ལ་སྨྱུག་གཏོང་གི་ཐབས་ལམ་ལུགས་གཅིག་མཐུན་བཟོ་ཡོད། གཞན་པ་ནི་སྐད་ཡིག་གཞན་ཞིག་ལ་རང་ཉིད་ཀྱི་ས དབྱིབས་འཆར་བཀོད་ཡོད་པའི་མ་ལག་གི་ནང་དུ་མཐོ་རིམ་ལུགས་པའི་རྣམ་པ་ཞིག་ནི་ཕན་ཚུན་གཅིག་སྐད་ཡིག་དང་འདྲ་བའི་སྒྲིག་སྟངས་གཉིས་ལས་བཟོ་བཅོས མཉམ་སྤྱོད་པའི་བྱ་འགུལ་འགྲེལ་བཤད་དང་ཐོག་འབྲས་མངོན་པ https://sites.google.com/site/cogalexvisharedtask/.'}
{'en': 'CogALex-VI Shared Task : Transrelation-A Robust Multilingual Language Model for Multilingual Relation Identification C og AL ex- VI  Shared Task: Transrelation - A Robust Multilingual Language Model for Multilingual Relation Identification', 'pt': 'Tarefa Compartilhada CogALex-VI: Transrelation - Um Modelo Robusto de Linguagem Multilíngue para Identificação de Relação Multilíngue', 'ar': 'مهمة CogALex-VI المشتركة: الترابط - نموذج قوي للغة متعدد اللغات لتحديد العلاقات متعددة اللغات', 'fr': "Tâche partagée de Cogalex-VI\xa0: Transrelation - Un modèle linguistique multilingue robuste pour l'identification des relations multilingues", 'es': 'Tarea compartida de Cogalex-VI: Transrelación: un modelo lingüístico multilingüe sólido para la identificación de relaciones multilingües', 'ja': 'CogALex - VI共有タスク：トランスレレーション-多言語関係識別のための堅牢な多言語モデル', 'zh': 'CogALex-VI 共事:Transrelation - 以多言强多言', 'hi': 'CogALex-VI साझा कार्य: Transrelation - बहुभाषी संबंध पहचान के लिए एक मजबूत बहुभाषी भाषा मॉडल', 'ru': 'Общая задача CogALex-VI: Трансреляция - надежная многоязычная языковая модель для идентификации многоязычных отношений', 'ga': 'Tasc Comhroinnte CogALex-VI: Aistriú - Samhail Láidre Teangacha Ilteangacha le hAithint an Chaidrimh Ilteangaigh', 'hu': 'CogALex-VI Megosztott feladat: Transrelations - Robusztus többnyelvű nyelvi modell a többnyelvű kapcsolatok azonosításához', 'ka': 'CogALex- VI გაყოფილი დავალება: Transrelation - პრობსტი მრავალენგური ენის მოდელი მრავალენგური განსაზღვრებისთვის', 'it': "Compito condiviso CogALex-VI: Transrelazione - Un solido modello linguistico multilingue per l'identificazione delle relazioni multilingue", 'kk': 'CogALex- VI ортақтастырылған тапсырма: Қосылымы - Көптілік қатынасын идентификациялау үшін robust көптілік тіл үлгісі', 'lt': 'CogALex-VI bendra užduotis: Transrelation – tvirtas daugiakalbis daugiakalbių ryšių identifikavimo modelis', 'el': 'Κοινή εργασία: Διασύνδεση ενός εύρωστου μοντέλου πολύγλωσσης γλώσσας για τον προσδιορισμό πολύγλωσσων σχέσεων', 'mk': 'CogALex-VI заедничка задача: Трансврска - robust мултијазичен модел за идентификација на мултијазичните односи', 'ms': 'Tugas Berkongsi CogALex-VI: Transrelation - A robust Multilingual Language Model for Multilingual Relations Identification', 'mn': 'CogALex-VI хуваалтын ажил: Transrelation - A robust Multilingual Language Model for Multilingual Relation Identification', 'ml': 'കോഗാലെക്സ്- VI പങ്കെടുത്ത പണി', 'mt': 'CogALex-VI Kompitu Konġunt: Trasferazzjoni - Mudell Multilingwi robust għall-Identifikazzjoni tar-Relazzjonijiet Multilingwi', 'pl': 'Wspólne zadanie CogALex-VI: Transrelacja – solidny wielojęzyczny model językowy do identyfikacji relacji wielojęzycznych', 'no': 'CogALex-VI delt oppgåve: Transrelation – Eit robust multispråk- modell for fleirspråk- identifisering', 'si': 'CogALex-VI කොටස් වැදගත් වැඩක්: Transerlation - A Robist Multilanguage Model for Multilanguage Attendees', 'ro': 'Sarcină comună CogALex-VI: Transrelație - Un model solid de limbă multilingvă pentru identificarea relațiilor multilingve', 'sr': 'CogALex-VI podeljeni zadatak: Transrelation - robust multijezički model za identifikaciju multijezičkih odnosa', 'ur': 'CogALex-VI Shared Task: Transrelation - A robust Multilingual Language Model for Multilingual Relations Identification', 'so': 'CogALex-VI Shaqooyin la sharciyey: Rugta - A Robust Model of Language Multilingua Luqadeed', 'sv': 'CogALex-VI Delad uppgift: Transrelation - En robust flerspråkig språkmodell för identifiering av flerspråkiga relationer', 'ta': 'CogALex- VI பகிர்ந்த பணி', 'uz': 'Boʻlishilgan vazifani CogALex- VI: Transrelation - Multilingua bogʻlanish uchun muloqat tillar modeli', 'vi': 'Công việc chia sẻ CogALex-VIe: Transrelatine "A Robest ngôn ngữ đa ngôn ngữ cho sự nhận diện ngôn ngữ đa ngôn ngữ', 'bg': 'Споделена задача: Трансвръзката - здрав многоезичен езиков модел за идентификация на многоезични отношения', 'hr': 'CogALex-VI zajednički zadatak: Transrelacija - robni multijezički model za identifikaciju multijezičkih odnosa', 'nl': 'CogALex-VI Gedeelde Taak: Transrelatie naar Een Robuust Meertalig Taalmodel voor Meertalige Relatie Identificatie', 'da': 'CogALex-VI delt opgave: Transrelation - en robust flersproget sprogmodel til identifikation af flersprogede relationer', 'ko': 'CogAlex VI 공유 작업: 다중 관계 - 다중 언어 관계 식별을 위한 건장한 다중 언어 모델', 'id': 'CogALex-VI Tugas Berkongsi: Transrelation - A Robust Multilingual Language Model for Multilingual Relation Identification', 'fa': 'Task Shared CogALex-VI: Transrelation - A robust Multilingual Language Model for Multilingual Relations Identification', 'de': 'CogALex-VI Gemeinsame Aufgabe: Transrelation als robustes mehrsprachiges Sprachmodell zur Identifikation mehrsprachiger Beziehungen', 'tr': 'CogALex-VI Paýlaşmış Görev: Transrelation - A Robust Multilingual Language Model for Multilingual Relations Identification', 'sw': 'CogALex-VI', 'hy': 'COgALex-VI Համադրված առաջադրանքն է. Transnext - Մեծալեզվի բազմալեզվի ճանաչելու ուժեղ մոդել', 'af': 'CogALex- VI Gedeelde Opdrag: Transrelation - A robust Multilingual Language Model for Multilingual Relation Identification', 'sq': 'CogALex-VI Task Shared: Transrelation - A robust Multilingual Language Model for Multilingual Relation Identification', 'am': 'መግለጫ', 'bn': 'কগALex- VI শেয়ার করা কাজ: ট্রান্সলেক্ট - একটি রোবাস্ট মাল্টিভাষায় ভাষার মোডেল', 'az': 'CogALex-VI paylaşılan iş: Transrelation - A robust Multilingual Language Model for Multilingual Relations Identification', 'ca': 'CogALex-VI Task Shared: Transrelation - Un robust model de llenguatge multilingüe per identificar relacions multilingües', 'bs': 'CogALex-VI zajednički zadatak: Transrelacija - robni multijezički model za identifikaciju multijezičkih odnosa', 'cs': 'CogALex-VI Sdílená úloha: Transrelace Robustní vícejazyčný jazykový model pro identifikaci vícejazyčných vztahů', 'fi': 'CogALex-VI Jaettu tehtävä: Transrelation - vankka monikielinen kielimalli monikielisen suhteen tunnistamiseen', 'et': 'CogALex-VI ühine ülesanne: Transrelation - tugev mitmekeelne keelemudel mitmekeelsete suhete tuvastamiseks', 'he': 'CogALex-VI משימה משותפת: Transrelation - מודל שפה רב שפות חזק לזהות יחסים רבות שפות', 'sk': 'CogALex-VI Skupna naloga: Transrelacija – Robusten večjezični jezikovni model za identifikacijo večjezičnih odnosov', 'ha': 'KCharselect unicode block name', 'jv': 'CogAlex-V Sampeyan task: transfer - A Robert Multilanguage Language model for Multilanguage Relative ID', 'bo': 'CogALex-VI Shared Task: Transrelation - A Robust Multilingual Language Model for Multilingual Relation Identification'}
{'en': 'We describe our submission to the CogALex-VI shared task on the identification of multilingual paradigmatic relations building on XLM-RoBERTa (XLM-R), a robustly optimized and multilingual BERT model. In spite of several experiments with data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a  linear classifier  adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.', 'ar': 'وصفنا تقديمنا إلى مهمة CogALex-VI المشتركة بشأن تحديد العلاقات النموذجية متعددة اللغات بناءً على XLM-RoBERTa (XLM-R) ، وهو نموذج BERT مُحسَّن بقوة ومتعدد اللغات. على الرغم من التجارب العديدة مع زيادة البيانات وإضافة البيانات وطرق التجميع باستخدام شبكة سيامي ثلاثية ، Translrelation ، فإن نموذج XLM-R المصنف خطيًا يتكيف مع هذه المهمة المحددة ، كان أفضل أداء في الاختبار وحقق أفضل النتائج في التقييم النهائي من المهمة المشتركة ، حتى بالنسبة للغة غير مرئية من قبل.', 'fr': "Nous décrivons notre soumission à la tâche partagée de Cogalex-VI sur l'identification des relations paradigmatiques multilingues en s'appuyant sur XLM-Roberta (XLM-R), un modèle BERT fortement optimisé et multilingue. Malgré plusieurs expériences avec des méthodes d'augmentation de données, d'addition de données et d'ensemble avec un Siamois Triple Net, Translrelation, le modèle XLM-R avec un classificateur linéaire adapté à cette tâche spécifique, a obtenu les meilleurs résultats lors des tests et a obtenu les meilleurs résultats lors de l'évaluation finale de la tâche partagée, même pour une langue inédite.", 'pt': 'Descrevemos nossa submissão à tarefa compartilhada CogALex-VI sobre a identificação de relações paradigmáticas multilíngues com base em XLM-RoBERTa (XLM-R), um modelo BERT robusto e multilíngue otimizado. Apesar de vários experimentos com aumento de dados, adição de dados e métodos de ensemble com uma rede tripla siamesa, Translrelation, o modelo XLM-R com um classificador linear adaptado para esta tarefa específica, teve o melhor desempenho nos testes e obteve os melhores resultados na avaliação final da tarefa compartilhada, mesmo para uma linguagem inédita.', 'es': 'Describimos nuestra presentación a la tarea compartida de Cogalex-VI sobre la identificación de relaciones paradigmáticas multilingües basadas en XLM-Roberta (XLM-R), un modelo BERT multilingüe y optimizado de forma robusta. A pesar de varios experimentos con métodos de aumento de datos, adición de datos y ensamble con una Triple Red Siamesa, Translrelation, el modelo XLM-R con un clasificador lineal adaptado a esta tarea específica, obtuvo mejores resultados en las pruebas y logró los mejores resultados en la evaluación final de la tarea compartida, incluso para un lenguaje nunca antes visto.', 'ja': '堅牢に最適化された多言語BERTモデルであるXLM - RoBERTa （ XLM - R ）上で構築された多言語パラダイム関係の識別に関するCogALex - VI共有タスクへの提出について説明します。Siamese Triple Net、Translrelation、この特定のタスクに適応した線形分類子を備えたXLM - Rモデルを使用したデータ拡張、データ追加、およびアンサンブルメソッドのいくつかの実験にもかかわらず、テストで最高のパフォーマンスを発揮し、以前は見られなかった言語であっても、共有タスクの最終評価で最高の結果を達成しました。', 'hi': 'हम XLM-RoBERTa (XLM-R) पर बहुभाषी रूपात्मक संबंधों के निर्माण की पहचान पर CogaALex-VI साझा कार्य के लिए हमारे सबमिशन का वर्णन करते हैं, जो एक मजबूत रूप से अनुकूलित और बहुभाषी BERT मॉडल है। डेटा वृद्धि के साथ कई प्रयोगों के बावजूद, डेटा अतिरिक्त और एक सियामी ट्रिपल नेट, ट्रांसलरिलेशन के साथ पहनावा विधियों, इस विशिष्ट कार्य के लिए अनुकूलित एक रैखिक क्लासिफायर के साथ एक्सएलएम-आर मॉडल, परीक्षण में सबसे अच्छा प्रदर्शन किया और साझा कार्य के अंतिम मूल्यांकन में सबसे अच्छा परिणाम प्राप्त किया, यहां तक कि पहले अनदेखी भाषा के लिए भी।', 'zh': '述CogALex-VI识基于XLM-RoBERTa(XLM-R),XLM-RoBERTa(强优化与多言BERT)。 虽增数增数,数实验数至,然用暹罗三重网,TranslrelationXLM-R模形有应此特定之线性分类器,于试中最佳,而于共享之终评得其最,虽前所未见之语亦然。', 'ru': 'Мы описываем наше представление в CogALex-VI совместной задачи по идентификации многоязычных парадигматических отношений на основе XLM-RoBERTa (XLM-R), надежно оптимизированной и многоязычной модели BERT. Несмотря на несколько экспериментов с расширением данных, добавлением данных и методами ансамбля с сиамской тройной сетью, Translrelation, модель XLM-R с линейным классификатором, адаптированным к этой конкретной задаче, показала лучшие результаты в тестировании и достигла наилучших результатов в окончательной оценке общей задачи, даже для ранее невидимого языка.', 'ga': 'Déanaimid cur síos ar ár n-aighneacht do thasc roinnte CogALex-VI maidir le caidreamh paradigmatic ilteangach a aithint ag tógáil ar XLM-RoBERTa (XLM-R), samhail BERT atá optamaithe go láidir agus ilteangach. In ainneoin roinnt turgnaimh le méadú ar shonraí, d’fheidhmigh breisiú sonraí agus modhanna ensemble le Siamese Triple Net, Translrelation, an tsamhail XLM-R le haicmitheoir líneach oiriúnaithe don tasc sonrach seo, sa tástáil is fearr agus bhain sé na torthaí is fearr amach sa mheastóireacht deiridh. den tasc roinnte, fiú i gcás teanga nach bhfacthas riamh cheana.', 'it': "Descriviamo la nostra presentazione al compito condiviso CogALex-VI sull'identificazione di relazioni paradigmatiche multilingue basato su XLM-RoBERTa (XLM-R), un modello BERT fortemente ottimizzato e multilingue. Nonostante diversi esperimenti con data augmentation, data addition e ensemble metodi con una Triple Net Siamese, Translrelation, il modello XLM-R con classificatore lineare adattato a questo specifico compito, ha ottenuto i migliori risultati nella valutazione finale del compito condiviso, anche per un linguaggio precedentemente invisibile.", 'ka': 'ჩვენ ჩვენი გახსნა CogALex-VI გაყოფილი სამუშაო დავაკეთებთ XLM-RoBERTa (XLM-R), ძალიან ოპტიმიზებული და მრავალენგური BERT მოდელზე. რამდენიმე ექსპერიმენტებით მონაცემების აგგენტაციას, მონაცემების დამატება და დამატება მეტოვებით სიამური სამხოლოდ მხოლოდ, Translrelation, XLM-R მოდელი linear კლასიფიკაციური მონაცემებით, რომელიც ამ კონფიკური დავალებისთვის აეპტირებულია, და', 'el': 'Περιγράφουμε την υποβολή μας στο κοινό έργο για τον προσδιορισμό πολύγλωσσων παραδειγματικών σχέσεων βασισμένο σε ένα εύρωστα βελτιστοποιημένο και πολύγλωσσο μοντέλο BERT. Παρά τα αρκετά πειράματα με την αύξηση δεδομένων, την προσθήκη δεδομένων και τις μεθόδους συνόλου με ένα Σιαμικό Τριπλό Δίκτυο, το μοντέλο με γραμμικό ταξινομητή προσαρμοσμένο σε αυτό το συγκεκριμένο έργο, πέτυχε καλύτερα στη δοκιμή και πέτυχε τα καλύτερα αποτελέσματα στην τελική αξιολόγηση της κοινής εργασίας, ακόμη και για μια προηγουμένως αόρατη γλώσσα.', 'hu': 'Az XLM-RoBERTa (XLM-R) modellre épülő, többnyelvű paradigmatikus kapcsolatok azonosítására irányuló CogALex-VI közös feladatunk bemutatását bemutatjuk. Az adatok nagyobbításával, adatok hozzáadásával és együttes módszerekkel végzett sziámi hármas hálózattal végzett kísérletek ellenére a Translrelation, a lineáris osztályozóval rendelkező XLM-R modell a legjobban teljesítette a tesztelést, és a megosztott feladat végső értékelésében a legjobb eredményeket érte el, még egy korábban nem látott nyelven is.', 'kk': 'Біз CogALex-VI ортақ тапсырманы XLM-RoBERTa (XLM-R) үшін көптеген және көптеген BERT үлгісінің бірнеше тілдік парадигматикалық қатынасын анықтау үшін тапсырмаңызды таңдаймыз. Бірнеше деректерді көбейту, деректерді қосу және сиамалық үш түрлі желі, транслиф, XLM-R моделі, осы нақты тапсырмаға адаптацияланған сызық классификациясы бар екендігіне қарай, тексеру және ортақ тапсырманың соңғы оқиғасының ең жақсы нәтижесін жеткізіп, бі', 'ml': 'ഞങ്ങള്\u200d കോഗാലെക്സ്-VI ന്റെ സമ്മാനം വിശദീകരിക്കുന്നു. എക്സ്\u200cഎലി-റോബെര്\u200dത്ത (എക്സ്\u200cഎല്\u200dഎംഎം-R) മോഡലില്\u200d പല ഭാഷകങ്ങളുടെയും ബന്ധങ്ങളുടെയും തിരിച്ചറിയാ ഒരു സിയാമീസ് ട്രിപ്പിള്\u200d നെറ്റ്, ട്രാന്\u200dസല്\u200dബന്ധമുള്ള ഡേറ്റാ കൂട്ടിച്ചേര്\u200dക്കുന്നതിനുള്ള പല പരീക്ഷണങ്ങള്\u200dക്കുമുള്ള ശേഷം, ഡേറ്റാ ചേര്\u200dക്കുന്നതിനുമുമ്പ് ഒളിഞ്ഞ ഭാഷയിലേക്ക് മാത്രമായ', 'ms': 'Kami menggambarkan penghantaran kami kepada tugas kongsi CogALex-VI mengenai pengenalan hubungan paradigmatik berbilang bahasa bangunan XLM-RoBERTa (XLM-R), model BERT yang kuat dan berbilang bahasa. Walaupun beberapa eksperimen dengan peningkatan data, tambahan data dan kaedah ensemble dengan Jaringan Triple Siamese, Translrelation, model XLM-R dengan klasifikasi linear yang disesuaikan kepada tugas spesifik ini, dilakukan terbaik dalam ujian dan mencapai keputusan terbaik dalam penilaian akhir tugas terkongsi, walaupun untuk bahasa yang belum terlihat sebelumnya.', 'lt': 'Apibrėžiame savo pasiūlą bendrai CogALex-VI užduotims nustatyti daugiakalbius paradigminius santykius, grindžiamus XLM-RoBERTa (XLM-R), tvirtai optimizuotu ir daugiakalbiu BERT modeliu. In spite of several experiments with data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a linear classifier adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.', 'mk': 'Го опишуваме нашето поднесување на CogALex-VI заедничката задача за идентификација на мултијазичните парадигматски односи кои се градат на XLM-RoBERTa (XLM-R), robustly оптимизиран и мултијазичен модел BERT. И покрај неколку експерименти со зголемување на податоците, додавање на податоци и ансемблирање на методите со сијамската трипатна мрежа, Транслреакција, моделот XLM-R со линијарен класификатор адаптиран на оваа специфична задача, изврши најдобро во тестирањето и постигна најдобри резултати во финалната евалуација на заедничката зад', 'mn': 'Бид CogALex-VI-д олон хэл парадигматикийн харилцааны барилгыг XLM-RoBERTa (XLM-R) дээр нэмэгдүүлсэн, олон хэлний BERT загварын тодорхойлолтой ажлыг тайлбарлаж байна. Хэдэн хэдэн мэдээллийн нэмэлт, өгөгдлийн нэмэлт, мэдээллийн аргыг Сиамийн гурван салбарт, Translrelation, XLM-R загварын загвар нь энэ тодорхой ажил дээр шулуун хэлбэртэй холбогдолтой, шалгалтанд хамгийн сайн хийсэн бөгөөд хуваалцаагүй ажлын эцэст нь хамгийн сайн үр дүнг олсон ч, өмнө', 'ro': 'Descriem prezentarea noastră la sarcina comună CogALex-VI privind identificarea relațiilor paradigmatice multilingve pe baza XLM-RoBERTa (XLM-R), un model BERT optimizat robust și multilingv. În ciuda mai multor experimente cu metode de mărire a datelor, adăugare de date și ansamblare cu o rețea triplă siameză, Translrelation, modelul XLM-R cu un clasificator liniar adaptat acestei sarcini specifice, a realizat cel mai bine în testare și a obținut cele mai bune rezultate în evaluarea finală a sarcinii comune, chiar și pentru un limbaj nevăzut anterior.', 'mt': 'Aħna niddeskrivu s-sottomissjoni tagħna lill-kompitu komuni CogALex-VI dwar l-identifikazzjoni ta’ relazzjonijiet paradigmatiċi multilingwi li jibnu fuq XLM-RoBERTa (XLM-R), mudell BERT ottimizzat b’mod robust u multilingwi. Minkejja diversi esperimenti b’żieda tad-dejta, żieda tad-dejta u metodi ta’ ensemble b’Siamese Triple Net, Translrelation, il-mudell XLM-R b’klassifikatur lineari adattat għal dan il-kompitu speċifiku, imwettaq bl-a ħjar mod fl-ittestjar u kiseb l-aħjar riżultati fl-evalwazzjoni finali tal-kompitu kondiviż, anke għal lingwa li ma kinitx osservata qabel.', 'no': 'Vi beskriver vårt oppføring til CogALex-VI delt oppgåve om identifiseringa av fleirspråk paradigmatiske forhold som bygger på XLM-RoBERTa (XLM-R), ein kraftig optimalisert og fleirspråk BERT-modell. Til tross av fleire eksperimenter med data-augmentasjon, data-tillegg og ensemble metodar med ein Siamese Triple Net, Translrelation, XLM-R-modellen med ein lineær klassifisering tilpassa denne spesifikke oppgåva, utført best i testen og oppnådd dei beste resultatene i den siste evalueringa av delt oppgåva, sjølv for eit førre ukjend språk.', 'pl': 'Opisujemy nasze zgłoszenie do wspólnego zadania CogALex-VI dotyczącego identyfikacji wielojęzycznych relacji paradygmatycznych opartych na XLM-RoBERTa (XLM-R), solidnie zoptymalizowanym i wielojęzycznym modelu BERT. Pomimo kilku eksperymentów z powiększaniem danych, dodawaniem danych i metodami zespołowymi z Siamską Triple Net, Translrelation, model XLM-R z klasyfikatorem liniowym dostosowanym do tego konkretnego zadania, najlepiej sprawdził się w testowaniu i osiągnął najlepsze wyniki w końcowej ocenie wspólnego zadania, nawet dla wcześniej niewidzianego języka.', 'sr': 'Opišemo svoju predanost zajedničkom zadatku CogALex-VI o identifikaciji zgrade multijezičkih paradigmatskih odnosa na XLM-RoBERTa (XLM-R), vrlo optimiziranog i multijezičkog model a BERT-a. Uprkos nekoliko eksperimenata sa povećanjem podataka, dodavanjem podataka i ensembliranjem metoda sa Siamejskom trostrukom mrežom, translrelacijom, XLM-R model sa linearnim klasifikatorom prilagođenim ovom konkretnom zadatku, najbolje provedenom u testiranju i ostvarim najbolji rezultat konačne procjene zajedničkog zadatka, čak i za prethodno nevidljivi jezik.', 'si': 'අපි කොග්ලෙක්ස් VI විශේෂ කරනවා කොල්ලෙක්ස් එක්ක භාෂාත්මක සම්බන්ධ විශ්වාස කරනවා XLM-RoBERTa (XLM-R), ශක්තිමත් විශේෂ කරලා හා බොහොම භාෂ සියාම් ත්\u200dරිප්ල් නේට් එක්ක සියම් ත්\u200dරිප්ල් නේට් එක්ක තියෙන ප්\u200dරයෝජනයක් තියෙන්න තියෙන ප්\u200dරයෝජනයක්, XLM-R මොඩේල් එක්ක linear classifier එක්ක මේ විශේෂ කාර්යයෙන් සැකසුම් කරලා තිය', 'sv': 'Vi beskriver vårt bidrag till CogALex-VI delade uppdrag att identifiera flerspråkiga paradigmatiska relationer utifrån XLM-RoBERTa (XLM-R), en robust optimerad och flerspråkig BERT-modell. Trots flera experiment med dataaugmentering, dataaddition och ensemblemetoder med Siamesiskt Triple Net presterade Translrelation, XLM-R modellen med linjär klassificering anpassad för just denna uppgift bäst i testning och uppnådde bästa resultat i slututvärderingen av den delade uppgiften, även för ett tidigare okänt språk.', 'so': 'Waxaannu u qoraynaa warqadeena CogALex-VI oo loo qeybeeyay shaqo ku saabsan aqoonsashada dhismaha xiriirka kala duduwan ee XLM-RoBERta (XLM-R), kaas oo ah model aad u bedelatay oo luuqado kala duduwan oo BERT ah. Inta kastoo ay leedahay imtixaan badan oo ku qoran data kordhiska, macluumaadka ku darsamaysa iyo sidoo kale ku qoran Siamese Triple Net, Translrelation, modelka XLM-R oo ku qoran qori-liner oo ku habboon shaqadan gaar ah, waxay sameeyeen si wanaagsan in lagu imtixaamo oo uu gaadhay ugu wanaagsanaan matooyinkii ugu dambeeyay qiimeynta shuqulka la qaybsaday, xataa afka hore oo aan la arkayn.', 'ta': 'நாம் கோகாலெக்ஸ்-VI க்கு எங்கள் சரணங்களை விவரிக்கிறோம் எக்ஸ்எல்எம்-ராபெர்டா (XLM- R) மேல் பல மொழிக்கான பங்கீட்டு தொடர்பு கட்டுப்பாட்டின் மீது பிரி தகவல் கூட்டுதல், தகவல் சேர்த்தல் மற்றும் ஒதுங்கும் முறைமைகளுடன் சியமேசி மூன்று இணைப்பு, Translrelation, XLM- R மாதிரியில் ஒரு வரிசை வகுப்பாளர் இந்த குறிப்பிட்ட செயலுக்கு ஒப்பிட்டுள்ளது, சோதனையில் செய்த', 'ur': 'ہم نے CogALex-VI کے مشترک کام میں اپنے تسلیم کو XLM-RoBERTa (XLM-R) پر بہت سی زبان کے مطابق مشترک رابطہ کی تعریف کے بارے میں توصیف کیا ہے۔ بہت سی آزمائش کے باعث، ڈاٹ اضافہ، ڈاٹ اضافہ اور مطابق طریقوں کے ساتھ سیامی تین نٹ، ترنسیل رابطہ، XLM-R موڈل کے ساتھ ایک linear classifier کے ساتھ اس خاص تابع کے ساتھ اضافہ کیا گیا ہے، جو سب سے بہتر آزمائش کرتا ہے اور سب سے بہترین نتیجے کامل کرتا ہے جو مشترک تابع کی آخری ارزیابی میں', 'uz': "Biz XLM-RoBERTA (XLM-R) bilan bir necha tillar bilan bog'liq aloqalarni aniqlash uchun CogALex-VIga qayta ishni taʼrif qilamiz. Bu bir necha tilda ko'proq BERT modelini ko'paytirish mumkin. Siamese Triple Net, Translrelation bilan bir nechta eksport qilingan maʼlumot qoʻshish, maʼlumot qoʻshish va muvaffaqiyatli usullar bilan bir nechta taʼminlovchi boʻlsa aytganda, uning oldingi nomaʼlum tilning oxirigi qiymatiga bajarildi.", 'vi': 'Chúng tôi mô tả sự tham gia của chúng tôi vào phân công việc mà CogALex-VI đã chia sẻ về việc xác định các mối quan hệ truyền thống đa dạng trên mô hình XLM-Roerbta (XLM-R), một mô hình mang tính chất và đa dạng cất kỹ. Mặc dù nhiều thí nghiệm với việc gia tăng dữ liệu, các phương pháp cấu tạo dữ liệu cùng với một Hệ lưới Ba Tiêu, xuyên biên giới, mô hình XLM-R với một phân loại tuyến thích hợp với nhiệm vụ đặc biệt này, đã thực hiện tốt nhất trong việc thử nghiệm và đạt được kết quả tốt nhất trong việc đánh giá chung nhiệm vụ, kể cả với một ngôn ngữ chưa từng thấy.', 'bg': 'Описваме нашето подчинение на споделената задача за идентифициране на многоезични парадигматични отношения въз основа на здраво оптимизиран и многоезичен модел. Въпреки няколко експеримента с методи за увеличаване на данните, добавяне на данни и ансамбъл с сиамска тройна мрежа, моделът с линеен класификатор, адаптиран към тази конкретна задача, се представи най-добре в тестването и постига най-добри резултати в окончателната оценка на споделената задача, дори и за досега невиждан език.', 'nl': 'We beschrijven onze inzending aan de gezamenlijke taak CogALex-VI over het identificeren van meertalige paradigmatische relaties, gebaseerd op XLM-RoBERTa (XLM-R), een robuust geoptimaliseerd en meertalig BERT model. Ondanks verscheidene experimenten met data augmentatie, data additie en ensemble methodes met een Siamese Triple Net, Translrelation, presteerde het XLM-R model met een lineaire classificator aangepast aan deze specifieke taak het beste in testen en behaalde de beste resultaten in de uiteindelijke evaluatie van de gedeelde taak, zelfs voor een voorheen ongeziene taal.', 'da': 'Vi beskriver vores indlæg til CogALex-VI delte opgave om identifikation af flersprogede paradigmatiske relationer baseret på XLM-RoBERTa (XLM-R), en robust optimeret og flersproget BERT-model. På trods af flere eksperimenter med data augmentation, data addition og ensemble metoder med Siamesisk Triple Net, Translrelation, XLM-R modellen med en lineær klassificering tilpasset denne specifikke opgave, klarede sig bedst i test og opnåede de bedste resultater i den endelige evaluering af den delte opgave, selv for et tidligere uset sprog.', 'hr': 'Opisujemo svoju predanost zajedničkom zadatku CogALex-VI o identifikaciji zgrade multijezičkih paradigmatskih odnosa na XLM-RoBERTa (XLM-R), vrlo optimiziranog i multijezičkog model a BERT-a. Uprkos nekoliko eksperimenata s povećanjem podataka, dodavanjem podataka i ensembliranim metodama sa Siamese Triple Net, Translrelation, XLM-R model s linearnim klasifikatorom prilagođenim ovom specifičnom zadatku, najbolje provedenom u testiranju i postignutom najboljim rezultatima konačne procjene zajedničkog zadatka, čak i za prethodno nevidljivi jezik.', 'de': 'Wir beschreiben unsere Einreichung an die gemeinsame Aufgabe von CogALex-VI zur Identifikation mehrsprachiger paradigmatischer Beziehungen basierend auf XLM-RoBERTa (XLM-R), einem robust optimierten und mehrsprachigen BERT-Modell. Trotz mehrerer Experimente mit Datenaugmentation, Datenaddition und Ensemble-Methoden mit einem Siamesischen Triple Net, Translrelation, gelang das XLM-R Modell mit einem an diese spezifische Aufgabe angepassten linearen Klassifikator am besten im Test und erzielte die besten Ergebnisse in der abschließenden Bewertung der gemeinsamen Aufgabe, auch für eine bisher nicht gesehene Sprache.', 'id': 'Kami menggambarkan pengiriman kami ke tugas kongsi CogALex-VI mengenai identifikasi hubungan paradigma berbagai bahasa yang dibangun pada XLM-RoBERTa (XLM-R), model BERT yang sangat optimisasi dan berbagai bahasa. Meskipun beberapa eksperimen dengan peningkatan data, tambahan data dan metode ensemble dengan Siamese Triple Net, Translrelation, model XLM-R dengan klasifikasi linear yang diadaptasi untuk tugas spesifik ini, dilakukan terbaik dalam tes dan mencapai hasil terbaik dalam evaluasi akhir tugas berbagi, bahkan untuk bahasa yang belum terlihat sebelumnya.', 'fa': 'ما تسلیم کردن ما به وظیفه مشترک CogALex-VI در مورد شناسایی رابطه\u200cهای متعدد زبان بر ساختن XLM-RoBERTa (XLM-R) یک مدل بسیار بهترین و متعدد زبان BERT را توصیف می\u200cکنیم. با وجود تعدادی آزمایشات با افزایش داده ها، افزایش داده ها و روش\u200cهایی که با یک شبکه سه سه سیامی، ترنسیل، مدل XLM-R با یک راهنمایی خط\u200cشناسی که به این کار خاص adapted می\u200cشود، بهترین انجام داده در آزمایش و بهترین نتیجه\u200cهای آخرین ارزیابی کار مشترک، حتی برای یک زبان پیش ندیده است.', 'ko': '우리는 우리가 CogAlex VI에 제출한 공유 임무의 내용을 묘사했다. 이 임무는 XLM-RoBERTA(XLM-R)의 다중 언어 범례 관계를 바탕으로 하는 식별이고 XLM-R는 안정적이고 최적화된 다중 언어 BERT 모델이다.연체 삼중망Translrelation을 사용하여 몇 차례의 데이터 확장, 데이터 첨가와 집적 방법을 실험했지만 XLM-R모델(선형 분류기가 있어 특정 임무에 적용)은 테스트에서 가장 잘 나타났고 공유 임무의 최종 평가에서 이전에 보지 못했던 언어에도 가장 좋은 결과를 얻었다.', 'sw': 'Tunaelezea ujumbe wetu wa CogALex-VI uliosambaza jukumu la kutambua ujenzi wa mahusiano ya lugha mbalimbali kwenye jengo la XLM-RoBERTa (XLM-R), modeli yenye matumaini na yenye lugha mbalimbali ya BERT. Pamoja na majaribio kadhaa ya kuongeza taarifa, kuongeza takwimu pamoja na njia za uchunguzi wa mtandao wa Siamese Triple Net, Translrelation, model ya XLM-R yenye mwandishi wa mstari uliobadilishwa na kazi hii maalum, walifanya vizuri katika kujaribu na kupata matokeo bora ya mwisho ya uchaguzi wa kazi hiyo, hata kwa lugha isiyojulikana hapo awali.', 'tr': 'Biz CogALex-VI we jemgyýetimizi XLM-RoBERTa (XLM-R), güýçli optimizaly we köp dilli BERT modeliniň esaslaşdyrylmagyny tassyklaýarys. Birnäçe maglumat üsgürlemesi bilen, maglumat eklemesi we syamese Triple Net bilen birleşmegi üçin örän deneyler bilen, translrelation, XLM-R modeli çyzgyly klasifikatçy bilen bu häzirki zada uygulanan, testlerde iň gowy edildi we paylaşyk göreviniň iň gowy netijesini ýetdi, hatda öňki görmän dilde hem üçin has gowy netijesini ýetdi.', 'af': 'Ons beskryf ons onderwerp aan die CogALex-VI gedeelde taak op die identifikasie van multitaalske paradigmatiese verwantings wat gebou is op XLM-RoBERTa (XLM-R), â\x80\x99n kragtig optimaliseerde en multitaalske BERT-model. Alhoewel verskeie eksperimente met data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a linear classifier adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.', 'sq': 'Ne përshkruajmë dorëzimin tonë ndaj detyrës së përbashkët CogALex-VI mbi identifikimin e marrëdhënieve shumëgjuhësore paradigmatike që ndërtojnë mbi XLM-RoBERTa (XLM-R), një model BERT të fortë optimizuar dhe shumëgjuhës. Pavarësisht nga disa eksperimente me rritjen e të dhënave, shtimin e të dhënave dhe metodat e mbledhjes me një Siamese Triple Net, Translrelation, model in XLM-R me një klasifikues linear të përshtatur ndaj kësaj detyre specifike, kryer më së miri në testim dhe arriti rezultatet më të mira në vlerësimin përfundimtar të detyrës së përbashkët, edhe për një gjuhë të padukshme më parë.', 'hy': 'We describe our submission to the CogALex-VI shared task on the identification of multilingual paradigmatic relations building on XLM-RoBERTa (XLM-R), a robustly optimized and multilingual BERT model.  Չնայած որոշ փորձարկումներին տվյալների աճի հետ, տվյալների ավելացման և համակարգման մեթոդներին Սիամական Երկնական ցանցի, Transl-հարաբերակցության, XLM-R մոդելի միջոցով, որը գծային դասակարգման միջոցով հարմարեցված է այս հատուկ խնդրին, լավագույնը կատարվեց փորձարկումների ընթացքում և հասավ ամենալավ արդյու', 'az': 'XLM-RoBERTa (XLM-R), çoxlu dilli BERT modeli olan çoxlu paradigmatik əlaqələrinin tanımlaması haqqında CogALex-VI paylaşılan işə təsdiqlənməyimizi təsdiqləyirik. Belə ki, bir neçə məlumat artırması, məlumat əlavəsi və metodları Siamez Üç Net ilə, Translrelation, XLM-R modeli, bu məlumat üçün linear klasifikatçısı ilə uyğunlaşdırılmış, bu məlumatın ən yaxşısını imtahana çəkib paylaşılmış işlərin ən yaxşı sonuçlarını, hətta əvvəlcə görmədiyiniz dil üçün.', 'bs': 'Opišemo svoju predanost zajedničkom zadatku CogALex-VI o identifikaciji zgrade multijezičkih paradigmatskih odnosa na XLM-RoBERTa (XLM-R), vrlo optimiziranog i multijezičkog model a BERT-a. Uprkos nekoliko eksperimenata s povećanjem podataka, dodavanjem podataka i ensembliranjem metoda sa Siamejskom trostrukom mrežom, Translrelation, XLM-R model sa linearnim klasifikatorom prilagođenim ovom konkretnom zadatku, najbolje provedenom u testiranju i ostvarim najbolji rezultat konačne procjene zajedničkog zadatka, čak i za prethodno nevidljivi jezik.', 'bn': 'আমরা কোগালেক্স-VI এর প্রতি আমাদের প্রতিষ্ঠান বর্ণনা করি এক্সএলএম-রোবের্তা (এক্সএলএম-আর)-এর উপর বহুভাষী প্যারাডিমেক্যাটিক সম্পর্কের পরিচিতি নিয়ে আমাদের কাজের বেশ কয়েকটি পরীক্ষা সত্ত্বেও সিয়ামের ত্রিপল নেটনেটের সাথে ডাটা যোগাযোগ এবং অন্তর্ভুক্ত পদ্ধতি, ট্রান্সলেঙ্ক, এক্সএলএম-আর মডেল, যা এই নির্দিষ্ট কাজের সাথে পরীক্ষা করা হয়েছে, এমনকি পূর্বে অদৃশ', 'ca': 'Descrivem la nostra subministració a la tasca compartida CogALex-VI sobre la identificació de relacions paradigmàtiques multilingües basant-nos en XLM-RoBERTa (XLM-R), un model BERT fortament optimitzat i multilingüe. In spite of several experiments with data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a linear classifier adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.', 'am': 'በXLM-RoBERTA (XLM-R) ላይ በብዙ ቋንቋዎች የግንኙነት ግንኙነት አካባቢ ግንኙነታችንን ለCogALex-VI መልዕክታችንን እናሳውቃለን፡፡ ምንም እንኳን ከዳታ አጨማሪ፣ የዳታ ጨምሮ እና የስልክ ሥርዓቶች ሲያሜሲ ሦስተኛ መረብ፣ ተርጓሚ፣ የXLM-R ሞዴል ለዚህ በተለያዩ ስራ የተጠቃሚ ክፍል የተደረገ ነው፣ መፈተን እና ለመፈተን የተሻለ ፍሬዎችን አግኝቷል፣ አስቀድሞ ያልታወቀ ቋንቋ እንኳ በተለያዩ ስራ መጨረሻ ማስታወቂያውን አግኝቷል፡፡', 'et': 'Kirjeldame oma allumist CogALex-VI jagatud ülesandele mitmekeelsete paradigmaatiliste suhete tuvastamiseks, tuginedes XLM-RoBERTa (XLM-R), tugevalt optimeeritud ja mitmekeelsele BERT mudelile. Vaatamata mitmetele eksperimentidele andmete suurendamise, andmete lisamise ja ansambli meetoditega siiami kolmevõrgu Translrelatsiooniga, suutis XLM-R mudel sellele konkreetsele ülesandele kohandatud lineaarse klassifikaatoriga testida kõige paremini ja saavutas parimad tulemused jagatud ülesande lõpphindamisel isegi varem nähtamatu keele puhul.', 'cs': 'Popisujeme náš předložení společnému úkolu CogALex-VI na identifikaci vícejazyčných paradigmatických vztahů na základě XLM-RoBERTa (XLM-R), robustně optimalizovaného a vícejazyčného modelu BERT. Navzdory několika experimentům s rozšířením dat, přidáváním dat a souborovými metodami pomocí Siamské Triple Net, Translrelation, XLM-R model s lineárním klasifikátorem přizpůsobeným tomuto konkrétnímu úkolu nejlépe vykonával testování a dosáhl nejlepších výsledků při závěrečném vyhodnocení sdíleného úkolu, a to i pro dříve neviděný jazyk.', 'fi': 'Kuvaamme sitoutumistamme CogALex-VI:n yhteiseen tehtävään monikielisten paradigmaattisten suhteiden tunnistamiseen perustuen XLM-RoBERTa (XLM-R), vankasti optimoituun ja monikieliseen BERT-malliin. Huolimatta useista kokeista datan lisäys-, tiedonlisäys- ja ensemblemenetelmillä siamilaisella kolminkertaisella verkolla, Translrelationilla, XLM-R-malli suoriutui parhaiten testauksessa ja saavutti parhaat tulokset jaetun tehtävän loppuarvioinnissa, jopa aiemmin näkemättömällä kielellä.', 'he': 'אנו מתארים את ההנחה שלנו למשימה המשותפת של CogALex-VI על זיהוי מערכות יחסים פרדיגמטיות רבות שפות בניין על XLM-RoBERTa (XLM-R), מודל BERT אופטימי חזק ומרבות שפות. למרות מספר ניסויים עם גידול נתונים, תוספת נתונים ושיטות אסמבל עם רשת משולשת סיאמית, Translrelation, המודל XLM-R עם מסווג לינרי מתאים למשימה המסופרת הזו, ביצעו את התוצאות הטובות ביותר בבדיקה והשגשו את התוצאות הטובות ביותר בהערכה הסופית של המשימה המשותפת, אפילו לשפה בלתי נראית קודם.', 'ha': "Tuna bayyana musuluntmu zuwa Cogalx-6 da aka raba aikin da aka samu game da jinni'anin mutane masu mutane da ke samu'a wa XLM-RoBERTa (XLM-R), wata misãlan da aka yi faransa da mulki-harshe na BERT. In spite of several experiments with data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a linear classifier adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.", 'sk': 'Opisujemo našo predložitev CogALex-VI skupni nalogi identifikacije večjezičnih paradigmatičnih odnosov na osnovi XLM-RoBERTa (XLM-R), robustno optimiziranega in večjezičnega modela BERT. Kljub številnim eksperimentom z metodami povečanja podatkov, dodajanja podatkov in ensemble s siamsko trojno mrežo Translrelation je model XLM-R z linearnim klasifikatorjem, prilagojenim tej specifični nalogi, najboljši pri testiranju in dosegel najboljše rezultate pri končni vrednotenju skupne naloge, tudi za prej nevidni jezik.', 'jv': 'Awakdhéwé rak nglanggar nggambar barêng cogAlex-VI kesempatan barêng langgar karo hal sampek karo nggawe gerakan XLM-R BERT (XLM-R), model sing paling nggawe lan akeh barêng langgar BERT. Tenggo perbudhakan karo akeh sing sampeyan karo data ampungasi, dadi nambah data lan sekulatan podho karo Siamse Triple Network, TralRelation, XLM-R model sing kelas linear tau dianggap karo perbudhakan sing apik iki, iso disenyester nggo ndelah barêng-barêng langgar sampeyan nganggo akeh sing luwih dumadhi kapan nggo ndelah winih, dhéwé ngerasai perbudhakan tanggal gak perbudhaka', 'bo': 'ང་ཚོས་CogALex-VI ལ་འཇུག་སྣོད་ནང་དུ་XLM-RoBERTa སྔོན་མ་ཤེས་པའི་སྐད་ཡིག་ཆ་མཐུན་བཟོ་བ་ཡོད་པའི་བརྟག་ཞིབ་གསལ་བཤད་ཀྱི་ལྟ་བ་རྒྱུ་དང་།'}
{'en': 'Translating Collocations : The Need for Task-driven Word Associations', 'fr': "Traduire les collocations\xa0: le besoin d'associations de mots axées sur les tâches", 'es': 'Traducción de colocaciones: la necesidad de asociaciones de palabras impulsadas por tareas', 'ar': 'ترجمة التجميعات: الحاجة إلى اقترانات الكلمات التي تعتمد على المهام', 'pt': 'Traduzindo colocações: a necessidade de associações de palavras orientadas por tarefas', 'zh': '译搭:单词关联', 'ja': 'Collocationsの翻訳：タスク主導の単語関連付けの必要性', 'hi': 'Collocations का अनुवाद करना: कार्य-संचालित Word Associations की आवश्यकता', 'ru': 'Перевод коллокаций: необходимость ассоциаций слов, управляемых задачами', 'ga': 'Comhshuíomhanna a Aistriú: An Gá le Cumainn Focal Tascbhunaithe', 'ka': 'The need for Task-driven Word Associations', 'el': 'Μετάφραση Συνελεύσεων: Η ανάγκη για Συνελεύσεις Λέξεων που βασίζονται σε Εργασίες', 'hu': 'Kollokációk fordítása: A feladatvezérelt szótársítások szükségessége', 'it': 'Tradurre Collocazioni: la necessità di associazioni di parole basate su attività', 'mk': 'Превод на колокации: потреба од зборни асоцијации на задачи', 'lt': 'Vertimas susiejimais: darbu grindžiamų žodžių asociacijų poreikis', 'kk': 'Қосылымдарды аудару: The Need for Task- driven Word Association', 'ms': 'Translating Collocations: The Need for Task-driven Word Associations', 'mn': 'Үйлдлийг орчуулах: The Need for Task-driven Word Association', 'ml': 'പ്രവര്\u200dത്തിപ്പിക്കുന്ന വാക്കുകള്\u200d സമൂഹങ്ങള്\u200dക്ക് ആവശ്യമുണ്ട്', 'mt': 'It-Traduzzjoni tal-Kollokazzjonijiet: Il-Ħtieġa għal Assoċjazzjonijiet tal-kliem mmexxija mill-kompiti', 'no': 'The Need for Task-driven Word Associations', 'pl': 'Tłumaczenie kolokacji: potrzeba skojarzeń słów opartych na zadaniach', 'ro': 'Traducerea colocărilor: Necesitatea asocierilor de cuvinte bazate pe sarcini', 'sr': 'Превод колокација: Треба за објатење речи које је управљено на задачи', 'si': 'The Require for Job- Drived Word Associations', 'so': 'Goobaha turjumista: Ururada hadalka shaqada ee loo baahan yahay', 'ta': 'மொழிபெயர்ப்பு இடங்கள்:', 'sv': 'Översätta kollokationer: Behovet av uppgiftsdrivna ordföreningar', 'ur': 'The need for Task-driven Word Associations', 'uz': 'Tarjima qilish', 'vi': 'Dịch các địa điểm: nhu cầu hợp tác từ ngữ', 'da': 'Oversættelse af kollokationer: Behovet for opgavedrevne ordforeninger', 'bg': 'Преводачни колокации: необходимостта от ръководени от задачи словесни асоциации', 'id': 'Translating Collocations: The Need for Task-driven Word Associations', 'de': 'Übersetzen von Kollokationen: Die Notwendigkeit von aufgabengesteuerten Word Assoziationen', 'ko': '임무 구동이 필요한 어휘 연상', 'fa': 'ترجمه\u200cبندی: The Need for Task-driven Word Association', 'tr': 'Nyşanlar', 'sw': 'Tafsiri maeneo: The haja kwa Associations of Words driven Task', 'nl': 'Vertalen van collocaties: De behoefte aan taakgestuurde woordassociaties', 'hr': 'Prijevod: potreba za povezanim riječima na zadatku', 'af': 'Vertaling Versameling: The Need for Task- driven Word Associations', 'am': 'ትርጉም', 'hy': 'Translating Collocations: The Need for Task-driven Word Associations', 'bn': 'অনুবাদ করা অবস্থান: কাজ- ড্রাইভ করা শব্দ সংস্থার জন্য প্রয়োজন', 'az': 'T…ôrc√ºml…ô: The Need for Task-driven Word Associations', 'bs': 'Prevedenje kolekcija: The Need for Task-driven Word Associations', 'cs': 'Překlad kolokací: Potřeba slovních asociací řízených úkoly', 'et': 'Tõlkekollektsioonide tõlkimine: vajadus ülesandepõhiste sõnaühenduste järele', 'fi': 'Translating Collocations: Tehtävälähtöisten sanayhdistysten tarve', 'sq': 'Përkthimi i kollokacioneve: nevoja për lidhje fjalësh të kryera nga detyra', 'ca': "Traducció de col·locacions: La necessitat d'associacions de paraules basades en tasques", 'jv': 'OptionGroup', 'sk': 'Prevajanje kolokacij: potreba po nalogah usmerjenih besednih združenjih', 'ha': 'KCharselect unicode block name', 'he': 'תורגם על ידי: The Need for Task-driven Word Associations', 'bo': 'ཡིག་སྐབས་མཉམ་བསྡུས། བྱ་འགུལ་འདྲེན་བའི་ཐ་སྙད་སྡེར་དང་མཉམ་སྦྲེལ་མཐུད་དགོས་པ'}
{'en': 'Existing  dictionaries  may help collocation translation by suggesting associated words in the form of collocations,  thesaurus , and example sentences. We propose to enhance them with task-driven word associations, illustrating the need by a few scenarios and outlining a possible approach based on  word embedding . An example is given, using pre-trained word embedding, while more extensive investigation with more refined methods and resources is underway.', 'pt': 'Os dicionários existentes podem ajudar na tradução de colocações sugerindo palavras associadas na forma de colocações, dicionários de sinônimos e frases de exemplo. Propomos aprimorá-los com associações de palavras orientadas por tarefas, ilustrando a necessidade por alguns cenários e delineando uma possível abordagem baseada na incorporação de palavras. Um exemplo é dado, usando incorporação de palavras pré-treinadas, enquanto uma investigação mais extensa com métodos e recursos mais refinados está em andamento.', 'ar': 'قد تساعد القواميس الموجودة في الترجمة التجميعية عن طريق اقتراح الكلمات المرتبطة في شكل التجميعات وقاموس المرادفات والجمل النموذجية. نقترح تعزيزها بجمع الكلمات التي تحركها المهام ، مع توضيح الحاجة من خلال عدد قليل من السيناريوهات وتحديد نهج محتمل يعتمد على تضمين الكلمات. يتم إعطاء مثال ، باستخدام تضمين الكلمات المدربة مسبقًا ، بينما يتم إجراء تحقيق أكثر شمولاً باستخدام طرق وموارد أكثر دقة.', 'fr': "Les dictionnaires existants peuvent faciliter la traduction des collocations en suggérant des mots associés sous forme de collocations, de thésaurus et de phrases d'exemple. Nous proposons de les améliorer avec des associations de mots axées sur les tâches, en illustrant le besoin par quelques scénarios et en décrivant une approche possible basée sur l'intégration de mots. Un exemple est donné, utilisant l'intégration de mots pré-entraînés, tandis que des recherches plus approfondies avec des méthodes et des ressources plus raffinées sont en cours.", 'es': 'Los diccionarios existentes pueden ayudar a la traducción de colocación al sugerir palabras asociadas en forma de colocaciones, tesauros y oraciones de ejemplo. Proponemos mejorarlos con asociaciones de palabras basadas en tareas, ilustrando la necesidad en unos pocos escenarios y esbozando un posible enfoque basado en la incrustación de palabras. Se da un ejemplo, utilizando incrustación de palabras previamente entrenada, mientras se está llevando a cabo una investigación más exhaustiva con métodos y recursos más refinados.', 'ja': '既存の辞書は、コロケーション、類義語辞典、および例文の形式で関連する単語を提案することで、コロケーション翻訳を助けることができます。タスク駆動型のワードアソシエーションでそれらを強化し、いくつかのシナリオによって必要性を説明し、ワード埋め込みに基づいた可能なアプローチを概説することを提案します。事前に訓練された単語埋め込みを使用して例を示し、より洗練された方法とリソースを使用したより広範な調査が進行中です。', 'zh': '今词典得以并置、同义词库、示例句议相关单词助置译者。 请以事驱者单词联而强之,因事而言之,概述于单词嵌之法也。 与一例,用预练之词,而更广研与更精细之法、资源正在行中。', 'hi': 'मौजूदा शब्दकोशों collocations, थिसॉरस, और उदाहरण वाक्यों के रूप में संबद्ध शब्दों का सुझाव देकर collocation अनुवाद में मदद कर सकते हैं। हम उन्हें कार्य-संचालित शब्द संघों के साथ बढ़ाने का प्रस्ताव करते हैं, कुछ परिदृश्यों द्वारा आवश्यकता को दर्शाते हैं और शब्द एम्बेडिंग के आधार पर एक संभावित दृष्टिकोण को रेखांकित करते हैं। एक उदाहरण दिया गया है, पूर्व-प्रशिक्षित शब्द एम्बेडिंग का उपयोग करके, जबकि अधिक परिष्कृत तरीकों और संसाधनों के साथ अधिक व्यापक जांच चल रही है।', 'ru': 'Существующие словари могут помочь в переводе коллокаций, предлагая ассоциированные слова в виде коллокаций, тезауруса и примеров предложений. Мы предлагаем дополнить их ассоциациями слов, управляемыми задачами, проиллюстрировав необходимость несколькими сценариями и наметив возможный подход, основанный на встраивании слов. Приводится пример с использованием предварительно обученного встраивания слов, в то время как в настоящее время проводится более обширное исследование с использованием более совершенных методов и ресурсов.', 'ga': 'D’fhéadfadh foclóirí atá ann cheana féin cuidiú le haistriúchán comhlonnaithe trí fhocail ghaolmhara a mholadh i bhfoirm comhlonnaithe, teasáras, agus abairtí mar shampla. Tá sé i gceist againn iad a fheabhsú le ceangail focal tasc-tiomáinte, ag léiriú an gá i roinnt cásanna agus ag leagan amach cur chuige féideartha bunaithe ar leabú focal. Tugtar sampla, ag baint úsáide as leabú focal réamh-oilte, agus tá imscrúdú níos fairsinge ar siúl le modhanna agus acmhainní níos scagtha ar siúl.', 'el': 'Τα υπάρχοντα λεξικά μπορούν να βοηθήσουν στη μετάφραση συμπύκνωσης προτείνοντας σχετικές λέξεις με τη μορφή συμπύκνωσης, θησαυρού και παραδειγματικών προτάσεων. Προτείνουμε να τις ενισχύσουμε με ενώσεις λέξεων που βασίζονται στις εργασίες, καταδεικνύοντας την ανάγκη με μερικά σενάρια και σκιαγράφοντας μια πιθανή προσέγγιση βασισμένη στην ενσωμάτωση λέξεων. Δίνεται ένα παράδειγμα, χρησιμοποιώντας προ-εκπαιδευμένη ενσωμάτωση λέξεων, ενώ σε εξέλιξη βρίσκεται εκτενής έρευνα με πιο εκλεπτυσμένες μεθόδους και πόρους.', 'hu': 'A meglévő szótárak segíthetnek a kollokációs fordításban azáltal, hogy a kapcsolódó szavakat kollokációk, szótárak és példamondatok formájában javasolják. Javasoljuk, hogy ezeket feladatvezérelt szóasszociációkkal bővítsük, néhány forgatókönyvvel illusztrálva, és felvázolva egy lehetséges szóbeágyazáson alapuló megközelítést. Példát adunk az előre képzett szóbeágyazás alkalmazásával, miközben a kifinomult módszerekkel és erőforrásokkal kiterjedtebb vizsgálatok folyamatban vannak.', 'ka': 'არსებობს სიტყვებები შეიძლება დახმარება კოლოკაციის გადაწყვეტილების შესაძლებელია, რომლებიც კოლოკაციების, ტესაროსის და მაგალითი სიტყვების ფორმაში შესაძლებელია ჩვენ გვეძლევა, რომ ისინი უფრო მეტად გავაკეთოთ რაოდენობა სიტყვების აზოციაციებით, რომლებიც უნდა გავაკეთოთ ნომდენობა სინარიოებით და შესაძლებელი პროგრამის გარეშე მაგალითი გამოყენებულია, როგორც უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო და', 'it': "I dizionari esistenti possono aiutare la traduzione della collocazione suggerendo parole associate sotto forma di collocazioni, thesaurus e frasi di esempio. Proponiamo di valorizzarle con associazioni di parole task-driven, illustrandone la necessità attraverso alcuni scenari e delineando un possibile approccio basato sul word embedding. Un esempio è dato, utilizzando l'embedding di parole pre-addestrato, mentre sono in corso indagini più approfondite con metodi e risorse più raffinati.", 'kk': 'Бар сөздіктер біріктіру үшін біріктірілген сөздерді біріктіру, тезаурус және мысал сөздерінің түрінде көмектесе алады. Біз оларды тапсырмалар көмектесетін сөздердің бірнеше сценарияларының қажеттігін көрсету және сөздердің енгізуіне негізделген мүмкін тәсілдігін көрсету керек. Мысалы, алдын- ала оқылған сөздерді ендіру арқылы, бірақ көбірек түзетілген әдістер мен ресурстар арқылы кеңейтілген жұмыс істейді.', 'lt': 'Esami žodynai gali padėti išversti sąsajas siūlydami susijusius žodžius sąsajų, tezauro ir pavyzdžių sakinių forma. We propose to enhance them with task-driven word associations, illustrating the need by a few scenarios and outlining a possible approach based on word embedding.  Pateikiamas pavyzdys, naudojant iš anksto apmokytą žodžių įterpimą, o atliekamas išsamesnis tyrimas su patobulintais metodais ir ištekliais.', 'mk': 'Постојаните речници можат да помогнат во преводот на колокација со предложување на поврзани зборови во форма на колокации, реченици и примерни реченици. Ние предложуваме да ги зајакнеме со зборни здруженија предводени од задачи, илустрирајќи ја потребата од неколку сценарија и опишувајќи можно пристап базиран на вградување на зборови. Подаден е пример, со користење на преобучено вградување на зборови, додека во тек е поширока истрага со попрефинирани методи и ресурси.', 'ms': 'Kamus yang wujud boleh membantu terjemahan lokasi dengan menyarankan perkataan berkaitan dalam bentuk lokasi, tesaurus, dan kalimat contoh. Kami cadangkan untuk meningkatkan mereka dengan persatuan perkataan yang dipimpin tugas, memperlihatkan keperluan dengan beberapa skenario dan mendambarkan pendekatan yang mungkin berdasarkan penyembelihan perkataan. Contoh diberikan, menggunakan penyembedding perkataan terlatih-terlatih, sementara penyelidikan yang lebih luas dengan kaedah dan sumber yang lebih baik sedang berlangsung.', 'ml': 'നിലവിലുള്ള നിഘണ്ടുകള്\u200dക്ക് കോള്\u200dക്കേഷന്\u200d വാക്കുകള്\u200d, തീസറസ്, ഉദാഹരണത്തിന്റെ രീതിയിലുള്ള വാക്കുകള്\u200d ഉപദേശിക്കു കുറച്ചു സിനേറ്ററിയുടെ ആവശ്യം വ്യക്തമാക്കുകയും വാക്കുകളുടെ അടിസ്ഥാനത്തില്\u200d അടിസ്ഥാനമായ ഒരു സാധ്യതയുണ്ടാക്കുകയും ചെയ്യു ഒരു ഉദാഹരണമായി നല്\u200dകിയിരിക്കുന്നു, മുമ്പ് പരിശീലന വാക്ക് അകത്തേക്കുള്ള ഉപയോഗിച്ച്, കൂടുതല്\u200d പരിശുദ്ധീകരിച്ച രീത', 'mt': 'Existing dictionaries may help collocation translation by suggesting associated words in the form of collocations, thesaurus, and example sentences.  We propose to enhance them with task-driven word associations, illustrating the need by a few scenarios and outlining a possible approach based on word embedding.  Jingħata eżempju, bl-użu ta’ inkorporazzjoni ta’ kliem imħarreġ minn qabel, filwaqt li għaddejja investigazzjoni aktar estensiva b’metodi u riżorsi aktar raffinati.', 'mn': 'Existing dictionaries may help collocation translation by suggesting associated words in the form of collocation, thesaurus, example phrases. Бид тэднийг ажил дамжуулагдсан үгний холбоотой, хэд хэдэн хувилбаруудын хэрэгцээг илэрхийлж, мөн үгний солилцоогоор боломжтой арга замыг илэрхийлж чадна. Жишээ нь дасгал хөгжүүлсэн үгнүүдийг ашиглан илүү шинэчлэгдсэн арга болон нөөц бүтээгдэхүүнтэй илүү өргөн судалгаа өгсөн.', 'no': 'Dei eksisterande ordboka kan hjelpa om samlinga ved å foreslå tilknytte ord i form av samlingar, teorus og eksempel setningar. Vi foreslår å forbetra dei med oppgåveførte ord-tilknytingar, som illustrerer behovet av nokre scenario og omformar eit mulig tilnærming basert på ordinnbåde. Ein eksempel vert oppgjeven ved å bruka føretraininga av ordinnbygging, mens meir utvida undersøking med fleire refinerte metodar og ressursar vert undergått.', 'pl': 'Istniejące słowniki mogą pomóc w tłumaczeniu kolokacji, sugerując powiązane słowa w postaci kolokacji, tezaura i przykładowych zdań. Proponujemy wzbogacić je o skojarzenia słów oparte na zadaniach, ilustrując potrzebę kilkoma scenariuszami i nakreślając możliwe podejście oparte na osadzeniu słów. Podano przykład, wykorzystując wstępnie przeszkolone osadzanie słów, podczas gdy trwają szersze badania z bardziej dopracowanymi metodami i zasobami.', 'ro': 'Dicționarele existente pot ajuta la traducerea colocării sugerând cuvinte asociate sub formă de colocări, tezaururi și propoziții de exemplu. Propunem să le îmbunătățim cu asocieri de cuvinte bazate pe sarcini, ilustrând nevoia prin câteva scenarii și conturând o posibilă abordare bazată pe încorporarea cuvintelor. Un exemplu este dat, folosind încorporarea de cuvinte pre-instruită, în timp ce investigații mai extinse cu metode și resurse mai rafinate sunt în curs de desfășurare.', 'sr': 'Postoje rečenici mogu pomoći prevodu kolekcije sugerirajući povezane reči u obliku kolokacija, tezarusa i primjerne rečenice. Predlažemo da ih poboljšamo sa asocijacijama reèi na zadatku, ilustrujuæi potrebu nekoliko scenarija i istaknuti moguæi pristup na osnovu ukljuèenog reèi. Primjer se pruža, koristeći predobučene reči uključujući, dok se proširenija istraga sa više refinansiranih metoda i resursa nastavlja.', 'so': 'Luqadaha heysta waxay caawin karaan turjumaadda ururka lagu soo jeedo hadallo la xiriira oo u eg ururada, thesaurus iyo tusaale ahaan imtixaanka. Waxaynu soo jeedaynaa in ay ku kordhiso ururo ereyga shaqaalaha lagu sameeyo, oo aan u muujinno baahida qaar ka mid ah aragtida, waxaana soo qoraynaa qaab suurtagal ah oo ku saleysan hadal ku habboon. Tusaale ahaan waxaa lagu qoraa isticmaalka hadalka horay loo tababaray, marka baaritaanka aad u dheeraadka ah oo ku qoran qaababka iyo hantida la sawiray.', 'sv': 'Befintliga ordböcker kan hjälpa till att översätta kollokationer genom att föreslå associerade ord i form av kollokationer, tesaurus och exempelmeningar. Vi föreslår att förbättra dem med uppgiftsdrivna ordassociationer, illustrera behovet med några scenarier och skissera ett möjligt tillvägagångssätt baserat på ordinbäddning. Ett exempel ges med hjälp av förutbildad ordinbäddning, medan mer omfattande utredning med mer förfinade metoder och resurser pågår.', 'si': 'ඉතින් තියෙන්නේ භාෂකතාවල් සම්බන්ධ වාර්තාවක් උදව් කරන්න පුළුවන් සම්බන්ධ වාර්තාවක් සම්බන්ධ විදිහට,  අපි ඔවුන්ව ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ්නයක් කරනවා කාර්යයෙන් ප්\u200dරශ්නයක් කරනවා වචන සම්බන්ධ වචන සම්බන්ධයෙන්, සිද්ධාව උදාහරණයක් තියෙනවා, ප්\u200dරධානය කරලා තියෙන වචන සම්බන්ධයෙන් භාවිත කරනවා, වඩා විශාල පරීක්ෂණය සහ සම්බන්', 'ta': 'தற்போதுள்ள அகராதிகள் தொடர்புடைய வார்த்தைகள், கூட்டுக்கள் மற்றும் உதாரணமான வாக்கியங்களின் வடிவத்தில் தொடர்புடைய மொ சில காட்சிகள் மூலம் தேவையை வெளிப்படுத்துகிறோம் மற்றும் வார்த்தை உள்ளிடும் அடிப்படையில் சாத்தியமான வழியை வெளிப்படுத ஒரு உதாரணத்தை கொடுக்கப்படுகிறது, முன் பயிற்சி சொல்லின் உள்ளடக்கம் பயன்படுத்துகிறது, ஆனால் அதிக விரிவாக ஆராய்ச்சி மு', 'ur': 'Existing dictionaries may help collocation translation by suggesting associated words in the form of collocations, thesaurus, and example sentences. ہم نے ان کی پیشنهاد کرتا ہے کہ ان کی مدد کی بات شرکتوں کے ساتھ زیادہ کریں، کم سیناریوں کی ضرورت کو دکھاتے ہیں اور ایک امکان طریقہ کو دکھاتے ہیں جو کلمات میں داخل ہونے کی بنیاد ہے۔ ایک مثال دی جاتی ہے، پہلے تدریس کی لفظ مہربانی کے مطابق، حالانکہ زیادہ مہربانی کی طریقے اور سرمایہ کے مطابق بہت زیادہ تحقیق کی جاتی ہے.', 'uz': "Mavjud lugʻatlar birlashtirish uchun bogʻliq so'zlarni birlashtirish mumkin, bunday soʻzlar va misol soʻzlarning shaklida yordam beradi. Biz ularni tashkilotlar bilan ishga tushirilgan so'zlar tashkilotlari bilan oshirishni talab qilamiz, bir necha scenario'zlarining muhimligini ko'rsatamiz va bir so'zlar tuzuvga ega bo'lish mumkin. Masalan, oldin o'rganilgan so'zlarni ishlatishdan foydalanadi, ammo ko'proq qo'shilgan usullar va rasmlar bilan ko'proq qidirishni bajaradi.", 'vi': 'Các từ điển tồn tại có thể giúp dịch thuật ngữ bằng cách gợi ý các từ liên kết trong dạng thông tục, từ điển và các câu ví dụ. Chúng tôi đề nghị cải thiện chúng với các tổ chức từ ngữ dựa trên các nhiệm vụ, minh họa nhu cầu của một vài viễn cảnh và mô tả một phương pháp có thể dựa trên từ ngữ. Một ví dụ được đưa ra, sử dụng sự cấy ghép từ được đào tạo trước, trong khi đang có một cuộc điều tra rộng hơn với các phương pháp và nguồn lực tinh vi hơn.', 'bg': 'Съществуващите речници могат да помогнат за превода на колокации, като предлагат свързани думи под формата на колокации, речник и примерни изречения. Предлагаме те да бъдат подобрени с ръководени от задачи думи асоциации, илюстриращи необходимостта чрез няколко сценария и очертаващи възможен подход, базиран на вграждане на думи. Даден е пример, като се използва предварително обучено вграждане на думи, докато се провежда по-обширно разследване с по-усъвършенствани методи и ресурси.', 'da': 'Eksisterende ordbøger kan hjælpe med oversættelse af kollokationer ved at foreslå tilknyttede ord i form af kollokationer, synonymer og eksempelssætninger. Vi foreslår at forbedre dem med opgavedrevne ordforeninger, der illustrerer behovet med et par scenarier og skitserer en mulig tilgang baseret på ordindlejring. Et eksempel gives ved hjælp af forududdannet ordindlejring, mens mere omfattende undersøgelser med mere raffinerede metoder og ressourcer er i gang.', 'nl': "Bestaande woordenboeken kunnen helpen collocatie vertaling door bijbehorende woorden voor te stellen in de vorm van collocaties, thesaurus en voorbeeldzinnen. We stellen voor om ze te verbeteren met taakgestuurde woordassociaties, de noodzaak te illustreren door middel van een paar scenario's en een mogelijke aanpak te schetsen gebaseerd op woord embedding. Een voorbeeld wordt gegeven, met behulp van vooraf getrainde woord embedding, terwijl een uitgebreider onderzoek met meer verfijnde methoden en middelen aan de gang is.", 'de': 'Vorhandene Wörterbücher können die Kollokationsübersetzung unterstützen, indem sie zugehörige Wörter in Form von Kollokationen, Thesaurus und Beispielsätzen vorschlagen. Wir schlagen vor, sie mit aufgabengesteuerten Wortassoziationen zu erweitern, die Notwendigkeit durch einige Szenarien zu verdeutlichen und einen möglichen Ansatz basierend auf Worteinbettung zu skizzieren. Ein Beispiel wird anhand von vortrainierten Wort-Einbettungen gegeben, während umfangreichere Untersuchungen mit verfeinerten Methoden und Ressourcen im Gange sind.', 'id': 'Kamus yang ada mungkin membantu terjemahan kolokasi dengan menyarankan kata-kata terkait dalam bentuk kolokasi, tesaurus, dan kalimat contoh. Kami mengusulkan untuk meningkatkan mereka dengan asosiasi kata-kata yang didorong oleh tugas, menggambarkan kebutuhan dari beberapa skenario dan menggambarkan pendekatan yang mungkin berdasarkan penerbangan kata. Sebuah contoh diberikan, menggunakan penerbangan kata-kata yang terlatih-terlatih, sementara penyelidikan yang lebih ekstensif dengan metode dan sumber daya yang lebih baik sedang berlangsung.', 'ko': '기존의 사전은 조합, 동의어표와 예문의 형식으로 관련어를 건의함으로써 조합 번역을 도울 수 있다.우리는 작업 구동의 단어 관련을 통해 그것들을 강화하고 몇 가지 장면을 통해 수요를 설명하며 단어를 바탕으로 삽입할 수 있는 가능한 방법을 개괄하는 것을 권장합니다.본고는 미리 훈련된 단어를 삽입하는 동시에 더욱 정교한 방법과 자원을 사용하여 광범위한 조사를 하고 있는 예를 제시했다.', 'fa': 'لغت\u200cنامه\u200cهای موجود می\u200cتوانند به ترجمه\u200cهای همکاری کمک کنند با پیشنهاد کلمات مربوط به شکل همکاری، تزاوروس و جمله\u200cهای مثال. ما پیشنهاد می\u200cکنیم که آنها را با ارتباطات کلمات مستقل به کار افزایش دهیم، که نیازهای چند سیناریو را توضیح می\u200cدهیم و روش امکان را بر اساس کلمات داخل بیان کنیم. یک مثال با استفاده از کلمه\u200cهای پیش آموزش آموزش داده می\u200cشود، در حالی که تحقیقات بیشتری با روش\u200cهای پاک\u200cشده\u200cتر و منابع\u200cهای پاک\u200cشده\u200cتر در حال حاضر است.', 'sw': 'Dikteta zilizopo inaweza kusaidia tafsiri ya ushirikiano kwa kupendekeza maneno yanayohusiana katika namna ya mikutano, thesaurus, na hukumu za mfano. Tunazipendekeza kuongeza kwa mashirika ya maneno yanayoendeshwa na kazi, kuonyesha haja ya hali kadhaa na kuelezea njia inayowezekana kutokana na maneno yanayoingia. Mfano umewekwa, kwa kutumia neno lililofunzwa kabla, wakati uchunguzi wa kina zaidi kwa njia na rasilimali zinaendelea.', 'tr': 'Öň bar sözleriň birleşme terjimelerine, sözleriň, tesorus we örnek sözleriň şeklinde ýazmagyny maslahat edip kömek edip biler. Biz olary taýýarlanan söz baglaşyklary bilen täzelleşdirmegi teklip edip, bir näçe senaryoň gerekligini görkezmegi we kelime daşarylan mümkin bir golaýy çykarmagyny teklip edýäris. Misal berilýär, öňünden eğlenen sözler daşarylýar, we köp gelişmiş yöntemler we çeşmeler bilen golaý barlanýar.', 'am': 'የአሁኑ መዝገብ ቃላት በኮሌኮሎጂዎች፣ thesaurus እና ምሳሌ በተደረገው ቃላት በማስታወቂያ ለመረዳት ይችላል፡፡ በጥቂት ሳናተር ሲያሳዩ እና በንግግር በተደረገ የቃላት ማኅበረሰብ እናሳውቃቸዋለን፡፡ ምሳሌ ይደረጋል፡፡', 'hr': 'Postoje riječi mogu pomoći prijevozu kolekcije predložeći povezanim riječima u obliku kolekcija, thesaurusa i primjernih rečenica. Predlažemo da ih poboljšamo s udruženjima riječima na zadatku, ilustrujući potrebu nekoliko scenarija i istaknuti mogući pristup na temelju uključenog riječima. Primjer se daje, koristeći predobučene riječi uključujući, dok se proširenje istrage s više refinansiranih metoda i resursa nastavlja.', 'af': "Bestaande woordeboekvorms kan hulp kollekasie oorsetting deur die voorstel van geassosieerde woorde in die vorm van kollekasies, thesaurus en voorbeeld teikens. Ons voorstel om hulle te verbeter met opdraggedrywe woorde toesamenskappe, te illustreer die behoefte deur 'n paar scenarios en 'n moontlike toegang wat op woord inbetering gebaseer is. 'n voorbeeld is gegee, gebruik voor-opgelei woord inbêring, terwyl meer uitbreidige ondersoek met meer opgewende metodes en hulpbronne is onderwerp.", 'bn': 'বিদ্যমান অভিধান সম্পর্কে সংযোগ, থিসোরাস এবং উদাহরণের মাধ্যমে সংযুক্ত শব্দের পরামর্শ দিয়ে সাহায্য করতে পারে। আমরা তাদের কাজ-চালানো শব্দ সংস্থার মাধ্যমে বাড়িয়ে দিতে প্রস্তাব করি, কয়েকটি দৃশ্যের প্রয়োজন তুলে ধরে এবং শব্দের প্রবেশের ভি একটি উদাহরণ প্রদান করা হয়েছে, পূর্ব প্রশিক্ষিত শব্দ ব্যবহার করে আরো সংশোধনী পদ্ধতি এবং সম্পদের সাথে আরও বিস্তারিত তদন্ত চলছে।', 'az': 'Bütün sözlər, sözlər və məsəllər cümlələrinin şərikli sözləri ilə birləşdirilmiş sözlərə kömək edə bilər. Biz onları task-driven söz birlikləri ilə artırmağı təklif edirik, bir neçə scenariyaların ehtiyacını göstərir və mümkün bir yol göstəririk. Əvvəlcə təhsil edilmiş sözlər içərisində istifadə edilən məsəl çəkilir. Daha çox təhsil edilmiş metodlar və resurslar ilə daha geniş təhsil edilir.', 'sq': "Existing dictionaries may help collocation translation by suggesting associated words in the form of collocations, thesaurus, and example sentences.  Ne propozojmë t'i përmirësojmë a to me shoqata fjalësh të drejtuara nga detyra, duke ilustruar nevojën nga disa skenarë dhe duke përshkruar një qasje të mundshme bazuar në përfshirjen e fjalëve. An example is given, using pre-trained word embedding, while more extensive investigation with more refined methods and resources is underway.", 'bs': 'Postoje riječi mogu pomoći prevodu kolekcije sugerirajući povezane riječi u obliku kolokacija, tezarusa i primjerne rečenice. Predlažemo da ih poboljšamo sa udruženjima riječi na zadatku, ilustrujući potrebu nekoliko scenarija i istaknuti mogući pristup na temelju uključenog riječi. Primjer se pruža, koristeći predobučene riječi uključene, dok se proširenija istraga s više refinansiranih metoda i resursa nastavlja.', 'cs': 'Existující slovníky mohou pomoci kolokačnímu překladu navrhnout související slova ve formě kolokací, tezaura a příkladových vět. Navrhujeme jejich rozšíření o úlohově orientované asociace slov, ilustrujeme potřebu několika scénářů a nastíníme možný přístup založený na vložení slov. Je uveden příklad pomocí předškoleného vložení slov, zatímco probíhá rozsáhlejší zkoumání s rafinovanějšími metodami a zdroji.', 'et': 'Olemasolevad sõnaraamatud võivad kaasa aidata kollokatsiooni tõlkimisele, pakkudes sellega seotud sõnu kollokatsioonide, tesauruse ja näidislausete kujul. Me teeme ettepaneku neid täiustada ülesandepõhiste sõnaseoste abil, illustreerides vajadust mõne stsenaariumiga ja kirjeldades võimalikku lähenemisviisi, mis põhineb sõnaseostamisel. Esitatakse näide eelõpetatud sõnade manustamise kasutamisest ning käimas on ulatuslikum uurimine täpsemate meetodite ja ressursside abil.', 'hy': 'Գոյություն ունի բառարաններ, որոնք կարող են օգնել տեղավորման թարգմանությունը, առաջարկելով կապված բառեր տեղավորման, թեզավրուսի և օրինակի նախադասությունների տեսքով: Մենք առաջարկում ենք զարգացնել դրանք խնդիրներով հիմնված բառերի կապերի միջոցով, ներկայացնելով մի քանի սցենարների կարիքը և ներկայացնելով բառերի ներգրավման հիմնված հնարավոր մոտեցում: An example is given, using pre-trained word embedding, while more extensive investigation with more refined methods and resources is underway.', 'ca': "Els diccionaris existents poden ajudar a traduir col·locacions suggerent paraules associades en forma de col·locacions, tesaurus i frases d'exemple. Proposem millorar-les amb associacions de paraules basades en tasques, il·lustrant la necessitat en alguns escenaris i esboçant un possible enfocament basat en la integració de paraules. S'ha donat un exemple, utilitzant l'incorporació de paraules pré-entrenades, mentre està en curs una investigació més extensa amb mètodes i recursos més refinats.", 'fi': 'Olemassa olevat sanakirjat voivat auttaa kollokaation kääntämistä ehdottamalla niihin liittyviä sanoja kollokaatioiden, sanaston ja esimerkkilauseiden muodossa. Ehdotamme, että niitä tehostetaan tehtävälähtöisillä sanayhdistelmillä, havainnollistetaan tarvetta muutamalla skenaariolla ja hahmotellaan mahdollinen sanaupotukseen perustuva lähestymistapa. Esimerkkinä on käytetty ennalta koulutettua sanaupotusta, kun taas käynnissä on laajempi tutkimus ja tarkemmat menetelmät ja resurssit.', 'jv': 'Diwurator sing gona barêng Awak dhéwé nggunakake ngéwelas kuwi tindang nggawe lan arep-aké pawaran cara-cara nggawe barang kelas kuwi tindang kejahatan karo perangkat dhéwé lan ijol-ijolan balêr sample', 'sk': 'Obstoječi slovarji lahko pomagajo pri prevajanju kolokacije s predlaganjem povezanih besed v obliki kolokacij, tezavra in primerov stavkov. Predlagamo, da jih izboljšamo z nalogami usmerjenimi besednimi asociacijami, ki ponazarjajo potrebo z nekaj scenariji in opišejo možen pristop, ki temelji na vključevanju besed. Naveden je primer z uporabo vnaprej usposobljenega vključevanja besed, medtem ko poteka obsežnejša preiskava z bolj izpopolnjenimi metodami in viri.', 'he': 'המילונים הנוכחים יכולים לעזור לתרגום מקומות על ידי הצעת מילים מחוברות בצורה של מקומות מקומות, תיזאורוס, ומשפטים דוגמאים. אנו מציעים לשפר אותם עם איגודות מילים מונעות משימה, להדגים את הצורך על ידי כמה תרחישים ולצייר גישה אפשרית מבוססת על קישום מילים. נותנת דוגמא, בשימוש בתכנית מילים מאומנת מראש, בעוד חקירה רחבה יותר עם שיטות ומשאבים מעודכנים יותר נמצאת בדרך.', 'ha': '@ info: whatsthis Kayyar da Muke ƙara su da wasu mutane da ke tafiyar da magana na aikin aiki, suna bayyana haja da ɗan idãnun nan kaɗan, kuma Mu outaita wani mataimaki a kan maganar da ke shiga. An buga wani misali, a yi amfani da maganar da aka fara-tafiya da shi, kuma an goge yin ƙidãya masu ƙaranci da shiryoyin da resource mafi tsari.', 'bo': 'གནས་ཡུལ་གྱི་ཡིག་ཆ་ཚོགས་ཆ་མཉམ་སྦྲེལ་ཚོགས་ནང་དུ་འབྲེལ་བའི་ཡིག་ཆ་ཚོགས་རྣམས་མཐུན་བཟོ་བྱེད་སྲིད། ང་ཚོས་དེ་དག་ལ་ལས་ཀ་གནང་ཅན་གྱི་གནད་དོན་དག་གི་སྤྱི་ཚོགས་ཀྱི་ཆ་འབྲེལ་བ་དང་མཉམ་དུ་གཏོང་དགོས། དཔེར་ན། སྔོན་གྱིས་འཇུག་ཟམ་འཛུགས་ཀྱི་གནད་དོན་དག་གི་ཐ་སྙད་ཅིག་བྱིན་ཡོད།'}
{'en': 'Characterizing Dynamic Word Meaning Representations in the Brain', 'ar': 'توصيف المعنى الديناميكي للكلمة في الدماغ', 'pt': 'Caracterizando Representações Dinâmicas de Significado de Palavras no Cérebro', 'fr': 'Caractérisation des représentations dynamiques de la signification des mots dans le cerveau', 'es': 'Caracterización de representaciones dinámicas de significado de palabras en el cerebro', 'ja': '脳内の動的な単語の意味表現の特徴付け', 'zh': '征大脑之动单词义征也', 'hi': 'मस्तिष्क में गतिशील शब्द अर्थ प्रतिनिधित्व की विशेषता', 'ru': 'Характеристика динамических представлений о значении слов в мозге', 'ga': 'Léirithe Brí Focal Dinimiciúla san Inchinn', 'hu': 'A dinamikus szó jelentésének jellemzése Az agyban lévő reprezentációk', 'it': 'Caratterizzare le rappresentazioni dinamiche del significato delle parole nel cervello', 'ka': 'სიტყვის დინამიკური სიტყვის განსაზღვრება', 'el': 'Χαρακτηρισμός δυναμικής λέξης που σημαίνει αναπαραστάσεις στον εγκέφαλο', 'mk': 'Картеризирање на динамични претставувања на зборови во мозокот', 'kk': 'Динамикалық сөзді таңдау', 'lt': 'Characterizing Dynamic Word Meaning Representations in the Brain', 'ms': 'Aksara Perwakilan Maksud Kata Dinamik dalam Otak', 'ml': 'ബ്രെയിനിലെ പ്രതിനിധികളുടെ അര്\u200dത്ഥം ഡിനാമിക് വാക്കുകള്\u200d അക്ഷരരീതിയിലാക്കുന്നു', 'mt': 'Karatterizzar ta’ Rappreżentazzjonijiet Dinamiċi tat-tifsira tal-kliem fil-Moħħ', 'mn': 'Тархины хувьсалын үг гэсэн үг', 'no': 'Teiknar dynamiske ord som gjeld representasjonar i hjernen', 'sr': 'Karakterizirajući dinamične reči znači predstave u mozgu', 'ro': 'Caracterizarea reprezentărilor dinamice ale cuvântului în creier', 'pl': 'Charakteryzowanie dynamicznych reprezentacji znaczenia słowa w mózgu', 'si': 'බ්\u200dරේන් වල සාමාන්\u200dය වචනය අදහස් කරනවා', 'ta': 'Name', 'ur': 'دماغ میں داینامیکی کلمات کا مطلب معلوم کرتا ہے', 'so': 'Charactering Dynamic Word meaning Representations in the Brain', 'sv': 'Karakterisera dynamiska ord innebörd representationer i hjärnan', 'uz': 'Name', 'vi': 'Tạo ký hiệu từ ký tự động ở bộ não', 'bg': 'Характеризиране на динамичните представи на словото в мозъка', 'da': 'Karakterisering af dynamiske ord betydning repræsentationer i hjernen', 'nl': 'Het karakteriseren van dynamische woordbetekenis representaties in de hersenen', 'hr': 'Karakterizirajući dinamičke riječi znači predstave u mozgu', 'de': 'Charakterisierung dynamischer Wortbedeutungsdarstellungen im Gehirn', 'id': 'Mengkarakterisasi Perkataan Dinamik Artinya Perwakilan di Otak', 'ko': '대뇌 속의 동적 의미 표징을 묘사하다', 'fa': 'تعریف کردن کلمه دینامیک یعنی نمایندگان در مغز', 'sw': 'Akihalalisha neno la Dynamic linalomaanisha Representations in Brain', 'tr': 'Saýlaw Renkleri', 'af': 'Karakteriseer dynamiese woord betekende voorstellings in die Brain', 'sq': 'Characterizing Dynamic Word Meaning Representations in the Brain', 'am': 'የአሁኑን ፋይል አስቀምጥ', 'hy': 'Ուղեղի մեջ դինամիկ բառերի ներկայացումներ', 'az': 'Dinamik Kelimi Beynin 캻fad톛si', 'bn': 'ব্রেইনের প্রতিনিধির মানে ডাইনামিক শব্দ চিহ্নিত করা হচ্ছে', 'bs': 'Karakterizirajući dinamične riječi znači predstave u mozgu', 'ca': 'caracteritzar representacions dinàmiques que significan paraules al cervell', 'cs': 'Charakterizace dynamického významu slova Reprezentace v mozku', 'et': 'Dünaamiliste sõna tähenduse esinduste iseloomustamine ajus', 'fi': 'Dynaamisten sanamerkitysten esittäminen aivoissa', 'jv': 'ditorial_basic', 'he': 'מייצג מילים דינמיות משמעות מילים במוח', 'ha': 'KCharselect unicode block name', 'sk': 'Karakterizacija dinamičnih predstavitev besednega pomena v možganih', 'bo': 'ཡིག་དབྱིབས་ནང་ཡི་སྒྲ་སྐད་ཀྱི་འགྱུར་བ་དང་མཚོན་རྟགས་སྟོན་པ'}
{'en': 'During  sentence comprehension , humans adjust  word meanings  according to the combination of the concepts that occur in the sentence. This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory. In several experiments, CEREBRA is used to quantify conceptual combination effect and demonstrate that it matters to humans. Such context-based representations could be used in future  natural language processing systems  allowing them to mirror human performance more accurately.', 'ar': 'أثناء فهم الجملة ، يقوم البشر بتعديل معاني الكلمات وفقًا لمجموعة المفاهيم التي تحدث في الجملة. تقدم هذه الورقة نموذجًا للشبكة العصبية يسمى CEREBRA (سياق متوقف بمعنى REpresentation في BRAin) يوضح هذه العملية بناءً على أنماط جملة الرنين المغناطيسي الوظيفي ونظرية استياء ممثل سمة المفهوم (CAR). في العديد من التجارب ، يتم استخدام CEREBRA لتحديد تأثير المركب المفاهيمي وإثبات أنه مهم للبشر. يمكن استخدام مثل هذه التمثيلات القائمة على السياق في أنظمة معالجة اللغة الطبيعية المستقبلية مما يسمح لها بعكس الأداء البشري بشكل أكثر دقة.', 'es': 'Durante la comprensión de oraciones, los humanos ajustan el significado de las palabras de acuerdo con la combinación de los conceptos que aparecen en la oración. Este artículo presenta un modelo de red neuronal llamado CEREBRA (representación de significado dependiente del contexto en el cerebro) que demuestra este proceso basado en patrones de oraciones de IRMf y la teoría de representación de atributos conceptuales (CAR). En varios experimentos, CEREBRA se utiliza para cuantificar el efecto de combinación conceptual y demostrar que es importante para los humanos. Tales representaciones basadas en el contexto podrían usarse en futuros sistemas de procesamiento del lenguaje natural, lo que les permitiría reflejar el rendimiento humano con mayor precisión.', 'pt': 'Durante a compreensão da frase, os humanos ajustam os significados das palavras de acordo com a combinação dos conceitos que ocorrem na frase. Este artigo apresenta um modelo de rede neural chamado CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) que demonstra este processo baseado em padrões de sentenças de fMRI e na teoria Concept Attribute Rep-resentation (CAR). Em vários experimentos, o CEREBRA é usado para quantificar o efeito de combinação conceitual e demonstrar que é importante para os seres humanos. Tais representações baseadas em contexto podem ser usadas em futuros sistemas de processamento de linguagem natural, permitindo que eles espelhem o desempenho humano com mais precisão.', 'fr': "Lors de la compréhension d'une phrase, les humains ajustent le sens des mots en fonction de la combinaison des concepts qui apparaissent dans la phrase. Cet article présente un modèle de réseau neuronal appelé CEREBRA (Context-dependent Meaning Representation in the BRAIN) qui démontre ce processus basé sur des modèles de phrases IRMf et la théorie de la représentation des attributs conceptuels (CAR). Dans plusieurs expériences, CEREBRA est utilisé pour quantifier l'effet de combinaison conceptuel et démontrer son importance pour l'homme. De telles représentations contextuelles pourraient être utilisées dans de futurs systèmes de traitement du langage naturel, ce qui leur permettrait de refléter plus précisément les performances humaines.", 'zh': '句解之际,人以句之大概调单词之义。 本文发CEREBRA(BrAin中上下文-dEpendent义为REpresentation)神经网络,盖fMRI句、名Resentation(CAR)之论也。 诸实验之中,CEREBRA以量化其名,明其重于人也。 此上下文之所以系于未来之自然语言,使可以正于人者也。', 'hi': 'वाक्य समझ के दौरान, मनुष्य वाक्य में होने वाली अवधारणाओं के संयोजन के अनुसार शब्द अर्थों को समायोजित करते हैं। यह पेपर एक तंत्रिका नेटवर्क मॉडल प्रस्तुत करता है जिसे CEREBRA (संदर्भ-dEpendent अर्थ BRAin में REpresentation) कहा जाता है जो एफएमआरआई वाक्य पैटर्न और कॉन्सेप्ट एट्रिब्यूट रेप-रिसेंटेशन (सीएआर) सिद्धांत के आधार पर इस प्रक्रिया को प्रदर्शित करता है। कई प्रयोगों में, CEREBRA का उपयोग वैचारिक संयोजन प्रभाव को मापने और यह प्रदर्शित करने के लिए किया जाता है कि यह मनुष्यों के लिए मायने रखता है। इस तरह के संदर्भ-आधारित अभ्यावेदन का उपयोग भविष्य के प्राकृतिक भाषा प्रसंस्करण प्रणालियों में किया जा सकता है जो उन्हें मानव प्रदर्शन को अधिक सटीक रूप से दर्पण करने की अनुमति देता है।', 'ja': '文の理解の間、人間は文に生じる概念の組み合わせに従って単語の意味を調整します。本論文では、fMRI文パターンと概念属性表現（ CAR ）理論に基づいて、このプロセスを実証するCEREBRA （ Context - dEpendent、BRAinにおけるREpresentationの意味）と呼ばれるニューラルネットワークモデルを提示する。いくつかの実験では、CEREBRAは、概念的な組み合わせ効果を定量化し、それがヒトにとって重要であることを実証するために使用される。このようなコンテキストベースの表現は、将来の自然言語処理システムにおいて使用され得、それらがより正確に人間のパフォーマンスを反映することを可能にする。', 'ru': 'Во время понимания предложения, люди корректируют значения слов в соответствии с сочетанием понятий, которые происходят в предложении. В данной работе представлена модель нейронной сети под названием CEREBRA (Context-dependent meaning Representation in the BRAin), которая демонстрирует этот процесс на основе шаблонов предложений fMRI и теории представления атрибутов концепции (CAR). В нескольких экспериментах CEREBRA используется для количественной оценки концептуального комбинированного эффекта и демонстрации того, что он имеет значение для человека. Такие основанные на контексте представления могли бы использоваться в будущих системах обработки естественного языка, что позволило бы им точнее отражать деятельность человека.', 'ga': 'Le linn na habairte a thuiscint, déanann daoine bríonna focal a choigeartú de réir an teaglaim de na coincheapa a tharlaíonn san abairt. Cuireann an páipéar seo múnla líonra néaraigh i láthair ar a dtugtar CEREBRA (Comhthéacs-spleách ar Léiriú sa Bhriain) a thaispeánann an próiseas seo bunaithe ar phatrúin abairte fMRI agus ar theoiric Ionadaithe Tréithe Coincheapa (CAR). I roinnt turgnaimh, úsáidtear CEREBRA chun éifeacht teaglaim choincheapúil a chainníochtú agus chun a léiriú go bhfuil tábhacht leis don duine. D’fhéadfaí léirithe comhthéacs-bhunaithe den sórt sin a úsáid i gcórais phróiseála teanga nádúrtha amach anseo a cheadódh dóibh feidhmíocht dhaonna a léiriú ar bhealach níos cruinne.', 'ka': 'სიტყვების შესახებ, ადამიანები სიტყვების შესახებ, რომელიც სიტყვების შესახებ მოხდება სიტყვების შესახებ. ეს წიგნი აჩვენებს ნეიროლური ქსელის მოდელი, რომელიც CEREBRA (Context-dEpendent ნიშნავს REPresentation in the BRAin), რომელიც ამ პროცესის პროცესი fMRI წიგნის შაბლობზე და კონცექტური ატრიბუტის რერესენტაციის (CAR)  რამდენიმე ექსპერიმენტებში CEREBRA გამოყენებულია კონტექსუალური კომბიუნციური ეფექტის განსაზღვრებისთვის და გამოჩვენებს, რომ ეს ადამიანებისთ ასეთი კონტექსტური გამოსახულებები შეიძლება გამოიყენება მომავალში ნაირადი ენერგიის პროცესი სისტემებში, რომლებიც მათ უფრო მართლად ადამიანის გამოსახულ', 'hu': 'A mondatok megértése során az emberek a mondatban előforduló fogalmak kombinációjának megfelelően igazítják a szó jelentését. A tanulmány bemutatja a CEREBRA nevű neurális hálózati modellt (Context-dEpendent jelentése REprezentáció in the BRAin), amely ezt a folyamatot fMRI mondatminták és a Concept Attribute Rep-resentation (CAR) elmélet alapján mutatja be. Számos kísérletben a CEREBRA-t használják a fogalmi kombinációs hatás számszerűsítésére és annak bizonyítására, hogy ez fontos az emberek számára. Az ilyen kontextusalapú reprezentációkat a jövőbeli természetes nyelvfeldolgozó rendszerekben lehetne használni, lehetővé téve, hogy pontosabban tükrözzék az emberi teljesítményt.', 'el': 'Κατά τη διάρκεια της κατανόησης των προτάσεων, οι άνθρωποι προσαρμόζουν τις έννοιες των λέξεων σύμφωνα με το συνδυασμό των εννοιών που εμφανίζονται στην πρόταση. Η παρούσα εργασία παρουσιάζει ένα μοντέλο νευρωνικού δικτύου που ονομάζεται CEREBRA (Context-dEpendent σημαίνει REpresentation in the BRAin) που καταδεικνύει αυτή τη διαδικασία με βάση τα πρότυπα προτάσεων fMR και τη θεωρία της επανάληψης χαρακτηριστικών εννοιολογίας (CAR). Σε αρκετά πειράματα, το CEREBRA χρησιμοποιείται για να ποσοτικοποιήσει την εννοιολογική επίδραση συνδυασμού και να αποδείξει ότι έχει σημασία για τον άνθρωπο. Τέτοιες αναπαραστάσεις βασισμένες στο πλαίσιο θα μπορούσαν να χρησιμοποιηθούν σε μελλοντικά συστήματα επεξεργασίας φυσικής γλώσσας επιτρέποντας τους να αντικατοπτρίζουν με μεγαλύτερη ακρίβεια την ανθρώπινη απόδοση.', 'it': "Durante la comprensione della frase, gli esseri umani regolano i significati delle parole in base alla combinazione dei concetti che si verificano nella frase. Questo articolo presenta un modello di rete neurale chiamato CEREBRA (Context-dEpendent significant REpresentation in the BRAin) che dimostra questo processo basato sui modelli di frase fMRI e sulla teoria della rappresentazione dell'attributo concettuale (CAR). In diversi esperimenti, CEREBRA viene utilizzato per quantificare l'effetto concettuale di combinazione e dimostrare che è importante per l'uomo. Tali rappresentazioni basate sul contesto potrebbero essere utilizzate nei futuri sistemi di elaborazione del linguaggio naturale consentendo loro di rispecchiare le prestazioni umane in modo più accurato.", 'lt': 'Žmonės, suprasdami sakinius, koreguoja žodžio reikšmę pagal sakinyje esančių sąvokų derinį. Šiame dokumente pateikiamas neurologinio tinklo modelis, vadinamas CEREBRA (Context-dEpendent meaning REpresentation in the BRAin), kuris įrodo šį procesą, pagrįstą fMRI frazės modeliais ir koncepcijos požymių pakartotinės rezentacijos (CAR) teorija. Keliuose eksperimentuose CEREBRA naudojamas koncepciniam deriniam poveikiui kiekybiškai įvertinti ir įrodyti, kad jis svarbus žmonėms. Such context-based representations could be used in future natural language processing systems allowing them to mirror human performance more accurately.', 'kk': 'Сөздерді түсіндіру кезінде, адамдар сөздердің мәліметтерін сөздердің біріктіру кезінде түсіндіреді. Бұл қағаз CEREBRA деп аталатын невралдық желі үлгісін көрсетеді (Context- dEpendent - BRAin дегеннің REпрезентациясы), бұл процесті fMRI сөз үлгілеріне негізделген невралдық желі үлгісін және концептуалды атрибутты қайта қайта қайта қа Бірнеше тәжірибелерде CEREBRA концептуалды біріктіру эффектін есептеп, адамдарға маңызды дегенді көрсету үшін қолданылады. Бұл контексті негіздеген келесі табиғи тілдерді өңдеу жүйелерінде қолдануға мүмкін болады. Олар адамдардың оқиғаларын дұрыс түсінуге мүмкіндік береді.', 'mk': 'За време на разбирањето на речениците, луѓето го прилагодуваат значењето на зборот според комбинацијата на концептите кои се случуваат во реченицата. Овој документ претставува нервен мрежен модел наречен ЦЕРЕБРА (Context-dEpendent meaning REpresentation in the BRAin) кој го демонстрира овој процес базиран на моделите на реченици fMRI и теоријата на Concept Attribute Rep-resentation (CAR). Во неколку експерименти, ЦЕРЕБРА се користи за квантификација на концептуалниот комбинациски ефект и демонстрација дека е важен за луѓето. Таквите контекстни претставувања би можеле да се користат во идните системи за процес на природни јазици кои им овозможуваат да ја одразат човечката резултатност попрецизно.', 'ms': 'Semasa pemahaman kalimat, manusia menyesuaikan makna perkataan mengikut kombinasi konsep yang berlaku dalam kalimat. Kertas ini menghasilkan model rangkaian saraf yang dipanggil CEREBRA (Context-dEpendent bermakna REpresentation dalam BRAin) yang menunjukkan proses ini berdasarkan corak kalimat fMRI dan teori Pemulihan Atribut (CAR). Dalam beberapa eksperimen, CEREBRA digunakan untuk kuantifikasi kesan kombinasi konseptual dan menunjukkan bahawa ia penting bagi manusia. Perwakilan berdasarkan konteks tersebut boleh digunakan dalam sistem pemprosesan bahasa semulajadi masa depan yang membolehkan mereka mirror prestasi manusia dengan lebih tepat.', 'mt': 'Matul il-fehim tas-sentenza, il-bnedmin jaġġustaw it-tifsiriet tal-kliem skont il-kombinazzjoni tal-kunċetti li jseħħu fis-sentenza. This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory.  F’diversi esperimenti, CEREBRA jintuża biex jikkwantifika l-effett kunċettwali ta’ kombinazzjoni u juri li huwa importanti għall-bnedmin. Rappreżentazzjonijiet bħal dawn ibbażati fuq il-kuntest jistgħu jintużaw f’sistemi futuri ta’ pproċessar tal-lingwi naturali li jippermettulhom jirriflettu l-prestazzjoni umana b’mod aktar preċiż.', 'mn': 'Хүмүүс үгийг ойлгох үед өгүүлбэрт орж буй ойлголтын хоорондоо үгийг зөвшөөрүүлдэг. Энэ цаас CEREBRA (Context-dEpendent) гэдэг мэдрэлийн сүлжээний загварыг харуулдаг. Энэ үйл явцыг fMRI өгүүлбэр болон Концепт Атрибутын Rep-resentation (CAR) онолын үндсэн онол дээр харуулдаг. Хэдэн хэдэн туршилтанд CEREBRA ойлголтын нэгтгэл нөлөөг тооцоолж хүмүүст чухал гэдгийг харуулахын тулд хэрэглэгддэг. Ийм нөхцөл байдлын үндсэн үзүүлэлт ирээдүйн байгалийн хэл үйлдвэрлэлийн системд ашиглаж болно.', 'ml': 'During sentence comprehension, humans adjust word meanings according to the combination of the concepts that occur in the sentence.  ഈ പേപ്പറില്\u200d സെരെബ്രാ എന്ന പേരുള്ള ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റര്\u200d നെറ്റര്\u200d മോഡല്\u200d കാണിക്കുന്നു (ബ്രായിനിലെ കെന്റെക്സ്റ്റ്- ഡിഇപ്പെന്റെന്\u200dറ് അര്\u200dത്ഥം REpresentation) ഫിഎ കുറച്ചു പരീക്ഷണങ്ങളില്\u200d സെരെബ്രാ ഉപയോഗിക്കുന്നു ആശയകൂട്ടിയുള്ള കൂട്ടത്തിന്റെ പ്രഭാവം ക്രമീകരിക്കുന്നതി ഭാവിക ഭാഷ പ്രക്രിയഭാഷയുടെ പ്രക്രിയസ്ഥാനത്തില്\u200d ഇത്തരം പ്രതിനിധികള്\u200d ഉപയോഗിക്കുവാന്\u200d സാധ്യതയുള്ള ഭാഷ പ്രക്രിയ', 'pl': 'Podczas rozumienia zdania ludzie dostosowują znaczenia słowa zgodnie z połączeniem pojęć, które występują w zdaniu. W artykule przedstawiono model sieci neuronowej o nazwie CEREBRA (Context-dEpendent znaczący REprezentację w BRAin), który demonstruje ten proces w oparciu o wzorce zdań fMRI i teorię reprezentacji atrybutów koncepcyjnych (CAR). W kilku eksperymentach CEREBRA jest wykorzystywany do ilościowego określenia efektu pojęciowego połączenia i wykazania, że ma on znaczenie dla ludzi. Takie kontekstowe reprezentacje mogłyby być wykorzystywane w przyszłych systemach przetwarzania języka naturalnego, pozwalających im dokładniej odzwierciedlać ludzką wydajność.', 'no': 'Når setninga forstår, tilpassar menneske ordbetinger etter kombinasjonen av konseptane som skjer i setninga. Denne papiret viser eit neuralnettverksmodell kalla CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) som demonstrerer denne prosessen basert på fMRI setningsmønsterelement og «Concept Attribute Rep-resentation»-teorien. I fleire eksperimenter vert CEREBRA brukt til å kvantifisera konseptuelle kombinasjoneffekt og demonstrera at det er viktig for menneske. Desse kontekstbaserte representasjonane kunne brukast i framtidige naturspråkshandlingssystemer som let dei spegelja menneskelige utviklingar meir nøyaktig.', 'ro': 'În timpul înțelegerii propozițiilor, oamenii ajustează semnificațiile cuvintelor în funcție de combinația conceptelor care apar în propoziție. Această lucrare prezintă un model de rețea neurală numit CEREBRA (Context-dEpendent însemnând REprezentare în BRAin) care demonstrează acest proces bazat pe modelele de frază fMRI și teoria Concept Attribute Representation (CAR). În mai multe experimente, CEREBRA este folosit pentru a cuantifica efectul conceptual de combinație și a demonstra că contează pentru om. Astfel de reprezentări bazate pe context ar putea fi utilizate în viitoarele sisteme de procesare a limbajului natural permițându-le să reflecte performanța umană mai precis.', 'si': 'වාක්ය සම්බන්ධ වෙලාවේ මිනිස්සුන් වචන අදහස් සම්බන්ධ කරනවා වචන අදහස් සම්බන්ධ කරනවා වචන සම්බන්ධ ව මේ පැත්තේ CEREBRA (Contexts-dEfendent means REpresentation in the BRAin) කියලා නිර්මාණ ජාලය මොඩේලයක් පෙන්වන්න පුළුවන් වෙනවා, ඒකෙන් මේ ප්\u200dරක්\u200dරියාව fMRI වාක්ෂා පෙන්වන්න සහ සෙරෙබ්\u200dරා විශේෂ පරීක්ෂණයක් වලින් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා ඒක මිනිස්සුන්ට ප්\u200dරශ්නයක් තිය අනිවාර්ය භාෂාව ප්\u200dරශ්නයක් අනාගතයේ ස්වභාවික භාෂාව ප්\u200dරශ්නයක් වෙන්න පුළුවන් ඒවා මිනිස්සුන්', 'sv': 'Under meningsförståelsen anpassar människan ordbetydelser efter kombinationen av de begrepp som förekommer i meningen. Denna uppsats presenterar en neuralt nätverksmodell kallad CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) som demonstrerar denna process baserat på fMRI-meningsmönster och Concept Attribute Rep-resentation (CAR)-teorin. I flera experiment används CEREBRA för att kvantifiera konceptuell kombinationseffekt och visa att det är viktigt för människor. Sådana kontextbaserade representationer skulle kunna användas i framtida system för behandling av naturliga språk så att de kan spegla människans prestanda mer exakt.', 'so': 'Inta lagu jiro dhamaanshaha ereyga dadku waxay u bedeshaa hadalka si waafaqsan isku darida fikrada soo socda. Qoraalkan wuxuu keenaa model shabakad neural ah oo la yidhaahdo CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) kaas oo muujiya kooraskaas oo ku saleysan qaababka xafiiska FMRI iyo qoraalka qofka loo soo jeedo (CAR). Imtixaanka qaarkood waxaa loo isticmaalaa CEREBRA si loo qiimeeyo saameynta wadajirka ah, wuxuuna muujiyaa inay u muhiim tahay dadka. Dhaqaalahaas oo kale waxaa lagu isticmaali karaa nidaamka baaritaanka luuqada dabiicadda ah ee lagu sameeyo si si saxda ah u muujiyo tababarka dadka.', 'ur': 'فیصلہ سمجھنے کے بعد، انسانوں نے کلمہ معلومات کی تعبیر کے مطابق کلمہ کی تعبیر کے مطابق تدبیر کر دی ہے. This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory. بہت سی تجربے میں CEREBRA کا مطابق کامپیوتر اثرات کا مقدار کرنے کے لئے استعمال کیا جاتا ہے اور دکھاتا ہے کہ یہ انسانوں کے لئے اثر ہے۔ اس طرح کی کنٹنسیٹ بنیاد کی تصویر آینده طبیعی زبان پردازی سیستموں میں استعمال کر سکتے ہیں کہ ان کو انسان کے کامیابی سے زیادہ دقیق مفصل کرنا اجازت دیتے ہیں.', 'ta': 'வாக்கு சூழ்நிலையில், மனிதர்கள் வாக்கியத்தில் நடக்கும் கருத்துக்களை ஒன்று சேர்க்கும் பொருட்டு சொல்லை சரிபா This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory.  பல பரிசோதனைகளில், CEREBRA உபயோகப்படுத்தப்படுகிறது நினைவு கூட்டும் விளைவை அளவு மற்றும் மனிதர்களுக்கு முக்கியமானது என்பத இந்த சூழல் அடிப்படையான பிரதிநிதிகள் எதிர்காலத்தில் இயல்பான மொழி செயல்படுத்தல் அமைப்புகளில் பயன்படுத்தப்படும்', 'sr': 'Tokom razumijevanja rečenice, ljudi prilagođavaju značenje reči prema kombinaciji koncepta koji se događaju u rečenici. Ovaj papir predstavlja neuralni model mreže pod nazivom CEREBRA (Context-dEpendent znači REprezentacija u BRAin) koji pokazuje ovaj proces na osnovu obrazaca rečenica fMRI i teorije reverencije koncept atributa (CAR). U nekoliko eksperimenata, CEREBRA se koristi za kvantificiranje konceptualnog kombinacijskog efekta i pokazivanje da je to važno za ljude. Takve kontekstske predstave bi mogle biti upotrebljene u budućim sistemima prirodnog obrađivanja jezika koje im omogućavaju da pogledaju ljudske izvedbe tačnije.', 'uz': "Bogʻni birlashtirish davomida insonlar so'zlarni birlashtirish mumkin. Name Koʻp tajribalarda CEREBRA bir g'oya birlashtirish effektini aniqlash uchun ishlatiladi va bu insonlarning muhimligini ko'rsatish mumkin. Bu xizmatning asosiy taʼminlovchilar kelajakdagi tabiiy tillar jarayon tizimlarda ishlatiladi va ularning inson bajarishni aniqlash imkoniyatini juda muhimiy ko'rsatishga ruxsat beradi.", 'vi': 'Trong suốt sự thấu hiểu câu, con người điều chỉnh ý nghĩa từ theo sự kết hợp của các khái niệm xuất hiện trong câu. Bài báo này cung cấp một mô hình mạng thần kinh gọi là BRUM (Contact-dEpenant nghĩa là Redepict in the BRIAn) that shows this process based on fMRI mast pattern and the ConcPT thuộc ký hiệu Rep-chuô tion (CAR) theory. Trong nhiều thí nghiệm, phải dùng nó để định lượng hiệu ứng kết hợp khái niệm và chứng minh nó quan trọng với con người. Những biểu tượng dựa trên ngữ cảnh này có thể được sử dụng trong hệ thống xử lý ngôn ngữ tự nhiên tương lai, cho phép họ phản ánh tốt hơn sức khỏe con người.', 'bg': 'По време на разбирането на изречението хората коригират значението на думите според комбинацията от понятията, които се появяват в изречението. Настоящата статия представя модел на невронна мрежа, наречен ЦЕРЕБРА (контекст-dEpendent означава REpresentation in the BRAin), който демонстрира този процес въз основа на моделите на изречения на ММР и теорията за презентацията на концептуалния атрибут (КАР). В няколко експеримента ЦЕРЕБРА се използва за количествено определяне на концептуалния комбиниран ефект и демонстриране, че има значение за хората. Такива контекстни представи могат да бъдат използвани в бъдещи системи за обработка на естествени езици, позволявайки им да отразяват човешкото представяне по-точно.', 'hr': 'Tijekom razumijevanja rečenica, ljudi prilagođavaju značenje riječi prema kombinaciji koncepta koji se pojavljuju u rečenici. Ovaj papir predstavlja model neuronske mreže po imenu CEREBRA (Context-dEpendent znači REpresentation u BRAin) koji pokazuje ovaj proces na temelju obrazaca rečenica fMRI i teorije Repentacije koncept Attribute (CAR). U nekoliko eksperimenata, CEREBRA se koristi za kvantificiranje konceptualnog kombinacijskog učinka i pokazivanje da je to važno za ljude. Takve predstave na kontekstu mogle bi se koristiti u budućim sustavima prirodnog obradivanja jezika koji im omogućavaju preciznije ogledati ljudske učinke.', 'da': 'Under sætningsforfattelsen justerer mennesker ordbetydninger efter kombinationen af de begreber, der forekommer i sætningen. Denne artikel præsenterer en neural netværksmodel kaldet CEREBRA (Context-dEpendent betydning REpresentation in te BRAin), der demonstrerer denne proces baseret på fMRI sætningsmønstre og Concept Attribute Rep-resentation (CAR)-teorien. I flere forsøg bruges CEREBRA til at kvantificere konceptuel kombinationseffekt og påvise, at det betyder noget for mennesker. Sådanne kontekstbaserede repræsentationer kunne bruges i fremtidige systemer til behandling af natursprog, så de kan afspejle menneskelige præstationer mere præcist.', 'nl': 'Tijdens het begrijpen van zinnen passen mensen woordbetekenissen aan op basis van de combinatie van de concepten die in de zin voorkomen. Dit artikel presenteert een neuraal netwerkmodel genaamd CEREBRA (Context-dEpendent betekent REpresentation in the BRAin) dat dit proces demonstreert op basis van fMRI zinnenpatronen en de Concept Attribute Rep-resentation (CAR)-theorie. In verschillende experimenten wordt CEREBRA gebruikt om conceptueel combinatieeffect te kwantificeren en aan te tonen dat het belangrijk is voor de mens. Dergelijke contextgebaseerde representaties zouden kunnen worden gebruikt in toekomstige systemen voor natuurlijke taalverwerking, waardoor ze menselijke prestaties nauwkeuriger kunnen weerspiegelen.', 'de': 'Beim Satzverstehen passen Menschen Wortbedeutungen an die Kombination der Begriffe an, die im Satz vorkommen. Diese Arbeit stellt ein neuronales Netzwerkmodell namens CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) vor, das diesen Prozess anhand von fMRI Satzmustern und der Concept Attribute Rep-resentation (CAR)-Theorie demonstriert. In mehreren Experimenten wird CEREBRA verwendet, um konzeptionelle Kombinationseffekte zu quantifizieren und zu zeigen, dass sie für den Menschen wichtig sind. Solche kontextbasierten Darstellungen könnten in zukünftigen natürlichen Sprachverarbeitungssystemen verwendet werden, um menschliche Leistungen genauer zu spiegeln.', 'fa': 'در طول فهمیدن جمله، انسانها معنیات کلمه را بر اساس ترکیب مفهوم\u200cهایی که در جمله اتفاق می\u200cافتد تغییر می\u200cدهند. این کاغذ یک مدل شبکه عصبی به نام CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) را نشان می\u200cدهد که این فرایند بر اساس الگوهای جمله fMRI و نظریه بازگرداندن ویژه\u200cهای مفهوم (CAR) را نشان می\u200cدهد. در چند آزمایش، CEREBRA برای تعداد اثرات ترکیب نظریه استفاده می\u200cشود و نشان می\u200cدهد که برای انسان مهم است. این نمایش\u200cهایی که بر پایه\u200cی محیط می\u200cتوانند در سیستم\u200cهای پردازش زبان طبیعی آینده استفاده می\u200cشوند که به آنها اجازه می\u200cدهند که عملکرد انسان را دقیقاً آشکار کنند.', 'id': 'Selama pemahaman kalimat, manusia menyesuaikan arti kata sesuai dengan kombinasi konsep yang terjadi dalam kalimat. Kertas ini menunjukkan model jaringan saraf bernama CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) yang menunjukkan proses ini berdasarkan pola kalimat fMRI dan teori Atribut Rep resentation (CAR) konsep. In several experiments, CEREBRA is used to quantify conceptual combination effect and demonstrate that it matters to humans.  Perwakilan berbasis konteks tersebut dapat digunakan dalam sistem proses bahasa alam masa depan yang memungkinkan mereka untuk mirror prestasi manusia dengan lebih akurat.', 'ko': '문장을 이해하는 과정에서 사람들은 문장에 나타난 개념의 조합에 따라 단어의 뜻을 조정한다.본고는 기능자공진 영상문형과 개념적 속성 표징(CAR) 이론을 바탕으로 뇌 상하문 관련 의미 표징(CERBERA)이라는 신경 네트워크 모델을 제시했다.일부 실험에서 뇌는 개념 조합 효과를 계량화하는 데 사용되었고 인류에게 매우 중요하다는 것을 증명했다.이러한 상하문에 기초한 표시는 미래의 자연 언어 처리 시스템에서 사용할 수 있어 인류의 표현을 더욱 정확하게 반영할 수 있다.', 'sw': 'Wakati wa muhtasari wa hukumu, binadamu hubadilisha maana yake kwa mujibu wa muungano wa mawazo yanayotokea kwenye hukumu. Gazeti hili linaleta muundo wa mtandao wa neura unaoitwa CEREBRA (maana ya Context-dEpendent REpresentation in BRAin) inayoonyesha mchakato huu kwa kutumia mifano ya hukumu ya fMRI na nadharia ya Wawakilishi (CAR). Katika majaribio kadhaa, CEREBRA inatumika kuthibitisha athari ya muungano wa mawazo na kuonyesha kuwa ni muhimu kwa binadamu. Maandamano haya yanaweza kutumika katika mfumo wa utaratibu wa lugha za asili wa baadaye unaruhusu kuwaonyesha utendaji wa binadamu kwa sahihi zaidi.', 'tr': 'Sözüm anladığında, insanlar sözlerin birleşmesine göre kelime anlamlarını ayarlar. Bu kagyz CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) adlanan nuýral şebeke modelini görkezýär ki bu prosesini fMRI sözleşmeler we Maýyp Atribut Tekrarlama (CAR) teoriýasyna daýanýar. Birkaç deneyde, CEREBRA mantıklı kombinasyonun etkisini ölçülemek için kullanılır ve insanlara önemli olduğunu göstermek için kullanılır. Birnäçe daşary-taýýarlanan suratlar gelejekde tebigy dil işleýän sistemalarda ullanyp bilýär.', 'sq': 'Gjatë kuptimit të fjalës, njerëzit rregullojnë kuptimet e fjalës sipas kombinimit të koncepteve që ndodhin në fjalë. Ky dokument paraqet një model rrjeti nervor të quajtur CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) që demonstron këtë proces bazuar në modelet e fjalëve fMRI dhe teorinë e përsëritjes së atributeve koncepti (CAR). Në disa eksperimente, CEREBRA përdoret për të kuantifikuar efektin e kombinimit konceptual dhe për të demonstruar se ka rëndësi për njerëzit. Të tilla përfaqësime të bazuara në kontekst mund të përdoren në sistemet e ardhshme të procesimit natyror të gjuhës që i lejojnë ata të pasqyrojnë performancën njerëzore më saktësisht.', 'af': "Dus setinge verstaan, korrigeer mense woord betekenings volgens die kombinasie van die konsepte wat in die seting voorkom. Hierdie papier stel 'n neurale netwerk model genaamd CEREBRA (Context- dEpendent beteken REpresentation in die BRAin) wat hierdie proses vertoon gebaseer op fMRI setingspatrone en die Concept Attribute Rep- resentation (CAR) teoriee. In verskeie eksperimente word CEREBRA gebruik om konseptieële kombinasie effek te kvantifiseer en te wys dat dit vir mense aangaan. So konteksgebaseerde voorstellings kan gebruik word in toekomstige natuurlike taal verwerking stelsels wat hulle toelaat om menslike presisie te spegelaat.", 'am': 'በፍርድ ግንኙነት በተደረገ ጊዜ ሰዎች ቃልን በማስተካከል እና በፍርዱ ውስጥ የሚደረገውን አሳብ ማሰናከል፡፡ ይህ ፕሮግራም CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) በሚያሳየው የውይይት መረብ ሞዴል እና የክፍተት ምርጫዎች (CAR) ታሪዮችን በሚያሳየው የክፍተት ክፍል እና የክፍተት ምርጫዎችን ማሳየቱ ነው፡፡ በርካታ ፈተናዎች፣ CEREBRA ለሰው የሚጠቅመውን አካላዊ ጥያቄን ለማስተካከል ይጠቅማል፡፡ እንደዚህ ያሉ የሥርዓት መልዕክቶች በአፍሪካዊ ቋንቋ ፕሮጀክት ሥርዓት ውስጥ የሚጠቀሙ የሰውን ፍጥረት እንዲያሳየቁ ይችላል፡፡', 'hy': 'Փաստորերի ընկալումների ընթացքում մարդիկ հարմարեցնում են բառի իմաստը ըստ նախադասում տեղի ունեցող գաղափարների համակցության: Այս հոդվածը ներկայացնում է նյարդային ցանցի մոդել, որը կոչվում է CEREBra (Կոնտեքստ-dEpնդենտ նշանակում է REներկայացում ԲՌԷինում), որը ցույց է տալիս այս գործընթացը, որը հիմնված է fMRI նախադասության կաղապարների վրա և Կենցեպտ աբրիբիտի վերարտադրման (CAR) տեսության վրա: Շատ փորձարկումների ընթացքում CEREBra-ը օգտագործվում է կոնտեպցիոնալ համադրման էֆեկտի չափման և ցույց տալու համար, որ դա կարևոր է մարդկանց համար: Such context-based representations could be used in future natural language processing systems allowing them to mirror human performance more accurately.', 'bs': 'Tokom razumijevanja rečenice, ljudi prilagođavaju značenje riječi prema kombinaciji koncepta koji se događaju u rečenici. Ovaj papir predstavlja model neuralne mreže po imenu CEREBRA (Context-dEpendent znači REpresentation u BRAin) koji pokazuje ovaj proces na osnovu uzorka rečenica fMRI i teorije Repentacije koncept Attribute (CAR). U nekoliko eksperimenata, CEREBRA se koristi za kvantificiranje konceptualnog kombinacijskog učinka i pokazivanje da je to važno za ljude. Takve predstave na kontekstu mogu biti upotrebljene u budućim sistemima prirodnog obrazovanja jezika koje im omogućavaju preciznije ogledati ljudske učinke.', 'ca': "Durant la comprensió de frases, els humans ajusten els significats de paraula segons la combinació dels conceptes que ocorren en la frase. Aquest paper presenta un model de xarxa neural anomenat CEREBRA (Context-dEpendent meaning REpresentation at the BRAin) que demostra aquest procés basat en patrons de frases fMRI i la teoria de la Representació de Concept Attribute (CAR). En varis experiments, CEREBRA s'utilitza per quantificar l'efecte conceptual de combinació i demostrar que importa per als humans. Such context-based representations could be used in future natural language processing systems allowing them to mirror human performance more accurately.", 'az': 'Sözümün anlaşılmasında insanlar sözlərin anlaşılıqlarını sözlərdə olanların birləşdirilməsinə görə dəyişdirirlər. Bu kağıt CEREBRA adlı nöral a ğ modelini göstərir (Context-dEpendent meaning REpresentation in the BRAin) ki bu prosesini fMRI sözlə örtüklərinə və Concept Attribute Rep-resentation (CAR) teoriyasına dayanan nöral ağ modelini göstərir. Birkaç təcrübələrdə CEREBRA konsept kombinatsiyalı etkisini quantifik etmək və insanlara vacib olduğunu göstərmək üçün istifadə edilir. Bütün məlumatları təbiətli dil işləmə sistemlərində istifadə edilə bilər ki, insanların performansını daha doğru çəkməsinə imkan verir.', 'bn': 'বাক্যের সম্পূর্ণ সময় মানুষের মানে এই বাক্যের মধ্যে যে ধারণা ঘটছে তার সংযোগ অনুসারে মানুষ শব্দের সংশোধন করে। এই প্রবন্ধে একটি নিউরেল নেটওয়ার্ক মডেল উপস্থাপন করেছে যার নাম সেরেব্রা (ব্রায় বিদ্যমান বিষয়বস্তুর মানে পুনরায় উপস্থাপন) যা FMRI শাস্তি প্যাটার্মেন্ট এবং কনসেপ্টিটেট বেশ কয়েকটি পরীক্ষায় সেরেব্রা ব্যবহার করা হচ্ছে ধারণার ক্ষেত্রে যোগাযোগের প্রভাব পরিমাণের জন্য এবং প্রমাণ করা হয় যে এটা  ভবিষ্যতের প্রাকৃতিক ভাষা প্রক্রিয়ার সিস্টেমে এই ধরনের প্রতিনিধির প্রতিনিধিত্ব ব্যবহার করা যায় যাতে তাদের মানব', 'cs': 'Během porozumění větám lidé upravují významy slov podle kombinace pojmů, které se ve větě vyskytují. Tento článek představuje model neuronové sítě CEREBRA (Context-dEpendent means REpresentation in the BRAin), který demonstruje tento proces založený na fMRI větových vzorcích a teorii Concept Attribute Rep-resentation (CAR). V několika experimentech se CEREBRA používá k kvantifikaci koncepčního kombinačního efektu a k prokázání, že na něm záleží člověku. Takové kontextové reprezentace by mohly být použity v budoucích systémech zpracování přirozeného jazyka, což jim umožní přesněji odrážet lidský výkon.', 'et': 'Lause mõistmise ajal kohandavad inimesed sõna tähendust vastavalt lauses esinevate kontseptsioonide kombinatsioonile. Käesolevas töös tutvustatakse närvivõrgu mudelit nimega CEREBRA (Context-dEpendent meaning REpresentation in the BRAin), mis demonstreerib seda protsessi fMRI lausemustritel ja kontseptsiooni atribuudi esitamise teoorial (CAR). Mitmes katses kasutatakse CEREBRAt kontseptuaalse kombinatsiooni mõju kvantifitseerimiseks ja inimese jaoks olulise tähtsuse tõestamiseks. Selliseid kontekstipõhiseid esitusi saaks kasutada tulevastes looduskeelte töötlemise süsteemides, mis võimaldavad neil peegeldada inimese jõudlust täpsemalt.', 'fi': 'Lausekkeen ymmärtämisen aikana ihmiset säätävät sanan merkityksiä lauseessa esiintyvien käsitteiden yhdistelmän mukaan. Tässä työssä esitellään CEREBRA-niminen neuroverkkomalli (Context-dEpendent meaning REpresentation in the BRAin), joka osoittaa tätä prosessia fMRI-lausekuvioihin ja CAR-teoriaan perustuen. CEREBRAa käytetään useissa kokeissa kvantifioimaan käsitteellistä yhdistelmävaikutusta ja osoittamaan, että sillä on merkitystä ihmisille. Tällaisia kontekstipohjaisia esityksiä voitaisiin käyttää tulevissa luonnonkielen käsittelyjärjestelmissä, jotta ne voisivat heijastaa ihmisen suorituskykyä tarkemmin.', 'ha': "Daga wani muhimmin maganar mutum, mutum yana gyara ma'anar maganar da ke koma da zato da za'a fito cikin maganar. Wannan takardar da ke bãyar da wani motel na jerin neural wanda ke kiran CECECEBra (mai Content-dEPenent ma'anar Recobãyar da cikin Brrain) mai nuna wannan aikin da ke gaskata a kan salon da tsarin cewa na fMR da teori na CanceptAttinutive Rep (CAR). Daga cikin wasu jarrabo, CECECEBra ana amfani da shi dõmin ya ƙayyade Effekt na koma da ɗabi'a kuma ya nuna cewa yana da muhimu ga mutum. Wannan misalin wanda ke a bincike da shi, za'a iya amfani da shi a cikin tsarin zartar da harshen na'asar a gaba ɗaya, don ya yarda su yi fara ga rayuwar mazaɓan mutum mafi taƙaita.", 'sk': 'Med razumevanjem stavkov ljudje prilagajajo pomen besed glede na kombinacijo pojmov, ki se pojavljajo v stavku. V prispevku je predstavljen model nevronskega omrežja CEREBRA (Context-dEpendent meaning REpresentation in the BRAin), ki prikazuje ta proces, ki temelji na vzorcih stavkov fMRI in teoriji reprezentacije konceptnih atributov (CAR). V več poskusih se CEREBRA uporablja za kvantificiranje konceptualnega kombinacijskega učinka in dokazovanje, da je pomemben za ljudi. Takšne kontekstne predstavitve bi se lahko uporabljale v prihodnjih sistemih za obdelavo naravnega jezika, ki bi jim omogočili natančnejše odražanje človeškega delovanja.', 'he': 'במהלך הבנה משפטית, בני אדם מתאימים משמעות מילים לפי שילוב הרעיונות שמתרחשים במשפט. העבודה הזו מציגה מודל רשת עצבית שנקרא CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) שמוכיח את התהליך הזה מבוסס על דפוסי משפט fMRI ותיאוריה של השפעה מחדש של מושג מושג (CAR). במספר ניסויים, CEREBRA משתמש בכוונה השפעה של שילוב מושג והוכיח שהוא חשוב לבני אדם. מייצגים מבוססים בקשר כאלה יכולים להשתמש במערכות מעבדת שפת טבעית עתידיות שמאפשרות להם למראה את ההופעה האנושית בצורה מדויקת יותר.', 'jv': 'Mungkin nguasar perangkapan Bu peutel sistemi sungan model kelompok alat sing nambarang CeREBEA Nang akeh sing sampeyan upar, CeREBEA kang dipunangé nggambar efek nggambar barang seneng pisan seneng pisan seneng pisan dumaan kuwi dudu. Sampeyan kontèks-sistem sing diangkat dipunabah akeh iso nggambar aturan anyar tentang kanggo nguasai perusahaan langkung sampeyan ingkang sampeyan nguasai kapan uwong.', 'bo': 'མིག་གིས་ཚིག་ཚང་མས་སྐབས་བཤད་པའི་ཚིག་དག་གི་དོན་དག་གང་འདྲ་ཡིན་པ་ལྟར་བགོ་སྒྲིག་བཞིན་ཡོད། This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory. སྔོན་ལྟ་བུའི་ནང་དུ་CEREBRA་འདི་ལྟ་བུའི་མཐུན་སྒྲིག་གི་གྲངས་སྒྲིག་ཆ་རྐྱེན་བྱེད་སྐབས་སྟོན་ཐུབ། རང་བཞིན་པའི་སྐད་ཡིག་ཆ་ལས་འགུལ་སྤྱོད་ཀྱི་མ་འོངས'}
{'en': 'Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge', 'es': 'Las incrustaciones de palabras contextualizadas codifican aspectos del conocimiento del sentido de las palabras similar al humano', 'fr': "Les intégrations de mots contextualisées encodent des aspects de la connaissance du sens des mots ressemblant à l'humain", 'ar': 'ترميز الكلمات المتضمنة في سياقها جوانب من المعرفة بمعنى الكلمة الشبيهة بالإنسان', 'pt': 'Incorporações de palavras contextualizadas codificam aspectos do conhecimento do sentido de palavras humano', 'ja': '文脈化された単語埋め込みは、人間のような単語センス知識の側面をエンコードします', 'zh': '上下文词编码类人字感知者各一端', 'ru': 'Контекстуализированные вложения слов кодируют аспекты человекоподобного знания смысла слов', 'hi': 'Contextualized Word Embeddings एन्कोड मानव की तरह शब्द सेंस ज्ञान के पहलुओं', 'ga': "Leabú Focal Comhthéacsúil Ionchódaíonn Gnéithe d'Eolas ar Bhriathra Focal ar nós an Duine", 'ka': 'Comment', 'hu': 'Kontextualizált szóbeágyazások Az emberi-szerű szóérzéki ismeretek aspektusait kódolják', 'el': 'Ενσωματώσεις λέξεων στο πλαίσιο κωδικοποιούν πτυχές της γνώσης ανθρώπινης αίσθησης λέξεων', 'it': 'Incorporazioni contestualizzate di parole codificano aspetti della conoscenza umana del senso delle parole', 'kk': 'Контекстуалды сөздерді ендіру адамдар секілді сөздердің мәліметтерін кодтау', 'lt': 'Konteksualizuoti žodžių įdėjimai koduoja žmogaus panašių žodžių jausmų žinių aspektus', 'mk': 'Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge', 'ms': 'Penjelmaan Kata Konteksual Mengekod Aspekt Pengetahuan Perkataan Seperti Manusia', 'ml': 'വാക്കുകള്\u200d എംബഡിങ്ങുകള്\u200d മനുഷ്യര്\u200d പോലുള്ള വാക്കുകളുടെ അറിവിന്റെ കോഡിക്കുക', 'mt': 'L-Inkorporazzjonijiet Kuntest tal-Kliem Ikkodifikaw Aspetti ta’ Għarfien tas-Sens tal-Kliem Bniedem', 'mn': 'Хүн төрөлхтний адил үг мэдрэмжтэй мэдрэмжтэй хэлбэрүүдийг коддог.', 'no': 'Comment', 'pl': 'Kontekstualizowane osadzenia słów kodują aspekty ludzkiej wiedzy o zmysłach słowa', 'ro': 'Încorporarea contextualizată a cuvintelor codifică aspecte ale cunoașterii simțului cuvintelor asemănătoare cu oamenii', 'sr': 'Kontekstualizirani integraciji reèi kodiraju aspekte znanja èoveka sliènih reèi', 'si': 'සම්බන්ධ වචන සම්බන්ධතාවක් මිනිස් වගේ වචන සම්බන්ධතාවක් සංකේතනය', 'so': 'Encode Aspects of Human Like Word Sense Knowledge', 'sv': 'Kontextualiserade ordinbäddningar Koda aspekter av mänskligt-liknande ordsinneskunskap', 'ta': 'சூழலாக்கப்பட்ட வார்த்தை உடைந்துள்ளது', 'ur': 'Name', 'uz': 'Name', 'vi': 'Ảnh chiếu từ bao gồm các khía cạnh của ý thức từ giống người.', 'bg': 'Контекстualiзираните словни вграждания кодират аспекти на познанието за чувството на думи, подобно на човека', 'da': 'Kontekstualiserede Word Embeddings Koder aspekter af menneskelig-lignende Word Sense viden', 'nl': 'Gecontextualiseerde Word Embeddings coderen aspecten van menselijke Word Sense kennis', 'hr': 'Kontekstualizirani integraciji riječi kodiraju aspekte znanja osjećaja riječi sličnih ljudima', 'id': 'Embedding Word Konteksual Mengenkode Aspekt Pengetahuan Sense Word Seperti Manusia', 'de': 'Kontextualisierte Word-Einbettungen codieren Aspekte menschlichen Wortsinns-Wissens', 'fa': 'Comment', 'ko': '어경화된 단어는 유인 어의 지식의 각 방면을 인코딩했다', 'sw': 'Matokeo yanayotumiwa na maneno yanayotarajiwa yanakodi mitazamo ya Sense ya neno kama binadamu', 'tr': 'Kontrol Senedi Kelimler İnsan ýaly Kelimi Bilişi Ködleýär', 'af': 'Comment', 'sq': 'Përfshitjet e Fjalave të Kontekstualizuara Kodojnë Aspektet e njohurisë së Fjalave të ngjashme me njerëzit', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Կոնտեքստալ բառերի ներգրավումները կոդավորում են մարդու նման բառերի գիտելիքի հարցերը', 'bn': 'উল্লেখযোগ্য শব্দের বিদ্যমান এনকোড করা মানুষের মত শব্দের জ্ঞান', 'az': 'İnsan kimi Kelimin Bilgisini Kodlayır', 'bs': 'Kontekstualizirani integraciji riječi kodiraju aspekte znanja osjećaja riječi sličnih ljudima', 'ca': "L'incorporació de paraules contextualitzades codifica aspectes del coneixement de sentit de paraules com a humans", 'cs': 'Kontextualizované vložení slov kódují aspekty znalostí slovního smyslu podobného člověku', 'et': 'Kontekstiliseeritud sõnade põimimised kodeerivad inimese sarnaste sõnade tajumise teadmiste aspekte', 'fi': 'Kontekstulisoidut sanaupotukset koodaavat ihmisen kaltaisen sanaaistitietämyksen näkökohtia', 'jv': 'Name', 'he': 'קידום מילים מקורקסטולוגיים קודדים נקודות של ידע חוש מילים דומה לאדם', 'bo': 'Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge', 'ha': 'KCharselect unicode block name', 'sk': 'Kontekstulizirane besedne vdelave kodirajo vidike znanja človeku podobnega besednega zaznavanja'}
{'en': 'Understanding context-dependent variation in word meanings is a key aspect of  human language comprehension  supported by the lexicon. Lexicographic resources (e.g., WordNet) capture only some of this context-dependent variation ; for example, they often do not encode how closely senses, or  discretized word meanings , are related to one another. Our work investigates whether recent advances in  NLP , specifically contextualized word embeddings, capture human-like distinctions between English word senses, such as  polysemy  and  homonymy . We collect data from a behavioral, web-based experiment, in which participants provide judgments of the relatedness of multiple WordNet senses of a word in a two-dimensional spatial arrangement task. We find that participants’ judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space. Specifically, homonymous senses (e.g., bat as mammal vs. bat as sports equipment) are reliably more distant from one another in the embedding space than polysemous ones (e.g., chicken as animal vs. chicken as meat). Our findings point towards the potential utility of continuous-space representations of sense meanings.', 'pt': 'Compreender a variação dependente do contexto nos significados das palavras é um aspecto fundamental da compreensão da linguagem humana apoiada pelo léxico. Os recursos lexicográficos (por exemplo, WordNet) capturam apenas parte dessa variação dependente do contexto; por exemplo, eles geralmente não codificam o quanto os sentidos, ou significados de palavras discretizados, estão relacionados uns aos outros. Nosso trabalho investiga se os avanços recentes na PNL, especificamente embeddings de palavras contextualizadas, capturam distinções humanas entre os sentidos das palavras em inglês, como polissemia e homonímia. Coletamos dados de um experimento comportamental baseado na web, no qual os participantes fornecem julgamentos da relação de vários sentidos WordNet de uma palavra em uma tarefa de arranjo espacial bidimensional. Descobrimos que os julgamentos dos participantes sobre a relação entre os sentidos estão correlacionados com as distâncias entre os sentidos no espaço de incorporação do BERT. Especificamente, sentidos homônimos (por exemplo, morcego como mamífero versus morcego como equipamento esportivo) são mais distantes um do outro no espaço de incorporação do que os polissêmicos (por exemplo, frango como animal versus frango como carne). Nossas descobertas apontam para a utilidade potencial de representações de espaço contínuo de significados de sentido.', 'ar': 'يعد فهم الاختلاف المعتمد على السياق في معاني الكلمات جانبًا أساسيًا من فهم اللغة البشرية الذي يدعمه المعجم. الموارد المعجمية (على سبيل المثال ، WordNet) تلتقط فقط بعضًا من هذا الاختلاف المعتمد على السياق ؛ على سبيل المثال ، غالبًا لا تقوم بتشفير مدى قرب ارتباط الحواس أو معاني الكلمات المتقنة ببعضها البعض. يدرس عملنا ما إذا كانت التطورات الحديثة في البرمجة اللغوية العصبية ، وتحديداً زخرفة الكلمات السياقية ، تلتقط فروقًا شبيهة بالإنسان بين حواس الكلمات الإنجليزية ، مثل تعدد المعاني و homonymy. نقوم بجمع البيانات من تجربة سلوكية قائمة على الويب ، حيث يقدم المشاركون أحكامًا حول العلاقة بين حواس WordNet المتعددة لكلمة في مهمة ترتيب مكاني ثنائي الأبعاد. نجد أن أحكام المشاركين حول العلاقة بين الحواس مرتبطة بالمسافات بين الحواس في مساحة تضمين BERT. على وجه التحديد ، فإن الحواس المتجانسة (على سبيل المثال ، الخفافيش مثل الثدييات مقابل الخفافيش كمعدات رياضية) تكون أكثر بعدًا عن بعضها البعض في مساحة التضمين من الحواس متعددة المعاني (على سبيل المثال ، الدجاج كحيوان مقابل الدجاج كلحم). تشير النتائج التي توصلنا إليها إلى الفائدة المحتملة لتمثيل الفضاء المستمر لمعاني المعنى.', 'fr': "La compréhension de la variation de la signification des mots en fonction du contexte est un aspect clé de la compréhension du langage humain supportée par le lexique. Les ressources lexicographiques (par exemple, WordNet) ne saisissent qu'une partie de cette variation dépendante du contexte\xa0; par exemple, elles n'encodent souvent pas la relation étroite entre les sens ou les significations discrétisées des mots. Notre travail cherche à savoir si les récents progrès de la PNL, en particulier les intégrations de mots contextualisés, saisissent les distinctions humaines entre les sens des mots anglais, tels que la polysémie et l'homonymie. Nous collectons des données à partir d'une expérience comportementale basée sur le Web, au cours de laquelle les participants jugent de la relation entre plusieurs sens WordNet d'un mot dans une tâche d'arrangement spatial bidimensionnel. Nous trouvons que les jugements des participants sur la relation entre les sens sont corrélés avec les distances entre les sens dans l'espace d'intégration du BERT. Plus précisément, les sens homonymes (par exemple, chauve-souris en tant que mammifère ou chauve-souris en tant qu'équipement de sport) sont plus éloignés les uns des autres dans l'espace d'encastrement que les sens polysémiques (par exemple, poulet en tant qu'animal contre poulet en tant que viande). Nos résultats indiquent l'utilité potentielle des représentations des sens dans l'espace continu.", 'es': 'Comprender la variación dependiente del contexto en el significado de las palabras es un aspecto clave de la comprensión del lenguaje humano respaldado por el léxico. Los recursos lexicográficos (por ejemplo, WordNet) capturan solo una parte de esta variación dependiente del contexto; por ejemplo, a menudo no codifican qué tan estrechamente se relacionan entre sí los sentidos o los significados discretos de las palabras. Nuestro trabajo investiga si los avances recientes en la PNL, específicamente la incorporación de palabras contextualizadas, capturan distinciones humanas entre los sentidos de las palabras en inglés, como polisemia y homonimia. Recopilamos datos de un experimento conductual basado en la web, en el que los participantes proporcionan juicios sobre la relación de múltiples sentidos de WordNet de una palabra en una tarea de organización espacial bidimensional. Encontramos que los juicios de los participantes sobre la relación entre los sentidos están correlacionados con las distancias entre los sentidos en el espacio de incrustación del BERT. Específicamente, los sentidos homónimos (por ejemplo, murciélago como mamífero frente a murciélago como equipo deportivo) están más distantes entre sí en el espacio de inserción que los polisémicos (por ejemplo, pollo como animal frente a pollo como carne). Nuestros hallazgos apuntan hacia la utilidad potencial de las representaciones espaciales continuas de los significados de los sentidos.', 'ja': '単語の意味における文脈依存的な変化を理解することは、語彙によってサポートされる人間の言語理解の重要な側面です。 語彙リソース（例えば、WordNet ）は、この文脈に依存する変形の一部のみを取り込みます。例えば、それらは多くの場合、緊密な感覚、または離散化された単語の意味がどのように互いに関連しているかを符号化しません。 私たちの研究は、NLPの最近の進歩、特に文脈化された単語埋め込みが、多義性やホモニミーなどの英語の単語感覚間の人間のような区別を捉えているかどうかを調査します。 私たちは、Webベースの行動実験からデータを収集します。この実験では、参加者は2次元空間配置タスクで単語の複数のWordNet感覚の関連性の判断を提供します。 我々は、参加者の感覚間の関連性の判断が、BERT埋め込み空間内の感覚間の距離と相関していることを発見した。 具体的には、同名の感覚（例えば、哺乳類としてのコウモリ対スポーツ用品としてのコウモリ）は、多義的な感覚（例えば、動物としてのニワトリ対肉としてのニワトリ）よりも埋め込み空間内で互いに確実により遠い。 我々の知見は、意味の連続空間表現の潜在的な有用性を指摘している。', 'zh': '解词上下文者,词典人之一机也。 词典资源(如,WordNet)仅获此上下文之变。 故其常不能离化单词义之所编码也。 臣等考NLP最新进展,特上下文词嵌之,得英语单词义(如多义词与同音异义词)类人类之异。 臣等采数于Web行实验,当实验之中,参与者于二维空间列事单词多WordNet义相关性决之。 见参与者感官之相关性,与BERT嵌空中感官相去。 同源(官,蝙蝠为哺乳动物.bat为运动器材)嵌空以大于多义感官(,鸡为肉)。 我们的发现感动官义的连空表徵的潜在效用。', 'hi': 'शब्द अर्थों में संदर्भ-निर्भर भिन्नता को समझना शब्दकोश द्वारा समर्थित मानव भाषा की समझ का एक महत्वपूर्ण पहलू है। Lexicographic संसाधन (उदाहरण के लिए, WordNet) केवल इस संदर्भ-निर्भर भिन्नता में से कुछ को कैप्चर करते हैं; उदाहरण के लिए, वे अक्सर एन्कोड नहीं करते हैं कि कितनी बारीकी से इंद्रियों, या discretized शब्द अर्थ, एक दूसरे से संबंधित हैं। हमारा काम जांच करता है कि क्या एनएलपी में हाल ही में हुई प्रगति, विशेष रूप से संदर्भित शब्द एम्बेडिंग, अंग्रेजी शब्द इंद्रियों के बीच मानव जैसे अंतर को कैप्चर करती है, जैसे कि पॉलीसेमी और होमोनीमी। हम एक व्यवहारिक, वेब-आधारित प्रयोग से डेटा एकत्र करते हैं, जिसमें प्रतिभागी दो आयामी स्थानिक व्यवस्था कार्य में एक शब्द के कई वर्डनेट इंद्रियों की संबंधितता के निर्णय प्रदान करते हैं। हम पाते हैं कि इंद्रियों के बीच संबंधितता के प्रतिभागियों के फैसले BERT एम्बेडिंग स्पेस में इंद्रियों के बीच की दूरी के साथ सहसंबद्ध हैं। विशेष रूप से, होमोनिमस इंद्रियां (उदाहरण के लिए, खेल उपकरण के रूप में स्तनपायी बनाम.bat के रूप में चमगादड़) पॉलीसेमस लोगों की तुलना में एम्बेडिंग स्पेस में एक दूसरे से मज़बूती से अधिक दूर हैं (उदाहरण के लिए, मांस के रूप में पशु बनाम चिकन के रूप में चिकन)। हमारे निष्कर्ष अर्थों के निरंतर-अंतरिक्ष प्रतिनिधित्व की संभावित उपयोगिता की ओर इशारा करते हैं।', 'ru': 'Понимание контекстно-зависимых вариаций значений слов является ключевым аспектом понимания человеческого языка, поддерживаемого лексиконом. Лексикографические ресурсы (например, WordNet) захватывают только некоторые из этих зависящих от контекста вариаций; например, они часто не кодируют, насколько близко чувства или дискретизированные значения слов связаны друг с другом. Наша работа исследует, отражают ли недавние достижения в области NLP, в частности контекстуализированные вложения слов, человекоподобные различия между английскими смыслами слов, такими как полисемия и омонимия. Мы собираем данные из поведенческого, веб-эксперимента, в котором участники предоставляют суждения о взаимосвязи множества чувств WordNet слова в двумерной задаче пространственного расположения. Мы обнаруживаем, что суждения участников о взаимосвязи между чувствами коррелируют с расстояниями между чувствами в пространстве вложений БЕРТА. В частности, одноименные органы чувств (например, летучая мышь в качестве млекопитающего по сравнению с летучей мышью в качестве спортивного снаряжения) достоверно более удалены друг от друга в пространстве вложения, чем многочленные (например, курица в качестве животного по сравнению с курицей в качестве мяса). Наши выводы указывают на потенциальную полезность непрерывно-пространственных представлений смысловых значений.', 'ga': 'Príomhghné de thuiscint teanga an duine a thacaíonn leis an bhfoclóir is ea éagsúlacht a bhraitheann ar an gcomhthéacs a thuiscint. Ní ghlacann acmhainní foclóireachta (m.sh., WordNet) ach cuid den éagsúlacht seo a bhraitheann ar an gcomhthéacs; mar shampla, is minic nach n-ionchódaíonn siad cé chomh dlúth agus atá céadfaí, nó bríonna discréideach focal, lena chéile. Fiosraíonn ár gcuid oibre cibé an dtagann dul chun cinn le déanaí i NLP, go háirithe leabaithe focal comhthéacsaithe, le hidirdhealú daonna idir céadfaí na bhfocal Béarla, amhail polysemy agus comhainm. Bailímid sonraí ó thurgnamh iompraíochta gréasán-bhunaithe, ina dtugann rannpháirtithe breithiúnais ar choibhneasta na céadfaí iolracha WordNet d’fhocail i dtasc socrú spáis déthoiseach. Faighimid amach go bhfuil comhghaol idir breithiúnais na rannpháirtithe ar an ghaolmhaireacht idir na céadfaí agus na faid idir na céadfaí i spás neadaithe BERT. Go sonrach, tá céadfaí comhainmneach (m.sh., ialtóg mar mhamach vs. ialtóg mar threalamh spóirt) níos faide óna chéile go hiontaofa sa spás neadaithe ná na cinn ilchineálacha (m.sh. sicín mar ainmhí vs sicín mar fheoil). Díríonn ár dtorthaí ar úsáid fhéideartha léirithe spáis leanúnaigh de bhríonna céadfacha.', 'el': 'Η κατανόηση των διαφορών που εξαρτώνται από το περιβάλλον στις έννοιες των λέξεων είναι μια βασική πτυχή της κατανόησης της ανθρώπινης γλώσσας που υποστηρίζεται από το λεξικό. Λεξικό πόροι (π.χ. WordNet) καταγράφουν μόνο ορισμένα από αυτά τα εξαρτώμενα από το περιβάλλον παραλλαγές. Για παράδειγμα, συχνά δεν κωδικοποιούν πόσο στενά οι αισθήσεις, ή οι διακριτές έννοιες λέξεων, σχετίζονται μεταξύ τους. Η εργασία μας διερευνά κατά πόσον οι πρόσφατες πρόοδοι στο ΝΛΠ, ειδικά ενσωματωμένες λέξεις στο πλαίσιο, συλλαμβάνουν ανθρώπινες διακρίσεις μεταξύ των αγγλικών αισθήσεων λέξεων, όπως η πολυσημία και η ομονυμία. Συλλέγουμε δεδομένα από ένα συμπεριφορικό πείραμα βασισμένο στο διαδίκτυο, στο οποίο οι συμμετέχοντες παρέχουν εκτιμήσεις σχετικά με την συσχέτιση πολλών αισθήσεων μιας λέξης σε μια διδιάστατη εργασία χωρικής διευθέτησης. Διαπιστώνουμε ότι οι κρίσεις των συμμετεχόντων για τη σχέση μεταξύ των αισθήσεων συσχετίζονται με τις αποστάσεις μεταξύ των αισθήσεων στον χώρο ενσωμάτωσης του BERT. Συγκεκριμένα, οι ομώνυμες αισθήσεις (π.χ., νυχτερίδα ως θηλαστικό vs. νυχτερίδα ως αθλητικό εξοπλισμό) είναι αξιόπιστα πιο μακρινές μεταξύ τους στο χώρο ενσωμάτωσης από τις πολυσυναισθηματικές (π.χ., κοτόπουλο ως ζώο vs. κοτόπουλο ως κρέας). Τα ευρήματά μας δείχνουν την πιθανή χρησιμότητα των αναπαραστάσεων των αισθήσεων σε συνεχή χώρο.', 'hu': 'A szójelentések kontextusfüggő változásainak megértése kulcsfontosságú aspektusa az emberi nyelv megértésének, amelyet a lexikon támogat. A lexikográfiai erőforrások (pl. WordNet) csak néhány kontextusfüggő változatot rögzítenek; Például gyakran nem kódolják meg, hogy az érzékek, vagy diszkrét szójelentések mennyire kapcsolódnak egymáshoz. Munkánk azt vizsgálja, hogy az NLP legutóbbi előrelépései, különösen kontextuális szóbeágyazások emberszerű különbségeket fognak-e fel az angol szóérzékek között, mint például a poliszemia és a homonimia. Egy viselkedési, webalapú kísérletből gyűjtünk adatokat, amelyben a résztvevők egy kétdimenziós térbeli elrendezési feladatban ítélik meg egy szó több WordNet érzékének kapcsolatát. Úgy találjuk, hogy a résztvevők érzékek közötti kapcsolatokról szóló ítéletei korrelálódnak az érzékek közötti távolságokkal a BERT beágyazó térben. Pontosabban, a homoním érzékek (például denevér mint emlős vs denevér mint sportfelszerelés) megbízhatóan távolabb vannak egymástól a beágyazó térben, mint a poliszemuális érzékek (pl. csirke mint állat vs. csirke mint hús). Eredményeink az érzékelési jelentések folyamatos térbeli reprezentációinak potenciális hasznosságára mutatnak.', 'ka': 'კონტექსტის შესახებ განსხვავება სიტყვების შესახებ არის ადამიანის ენის გასაგების გასაგების აპექტიკონტი. Lexicographic resources (მაგალითად, WordNet) მხოლოდ ამ კონტექსტის განსაცემების ზოგიერთი გამოყენება აღმოჩენა; მაგალითად, ისინი ხშირად ვერ კოდირებენ რამდენი მხოლოდ სიტყვის, ან დისკრეტირებული სიტყვის ნიშნავების შესახებ ერთმანეთისთვის. ჩვენი სამუშაო განსხვავება, თუ ახლა NLP-ში განახლება, განსაკუთრებით კონტექსტუალური სიტყვების შემდეგ, ადამიანის განსხვავება ანგლისური სიტყვების სიტყვების შორის, როგორ ჩვენ შევქმნით მონაცემები ქცევის, საბოლოო ექსპერიმენტიდან, რომელიც მონაცემები უფრო მეტად WordNet სიგრძე სიტყვების შესახებ ექსპერიმენტიური განსაზღვრების დასაწყებაში. ჩვენ აღმოჩნეთ, რომ სენსის შესახებ შესახებ სენსის შესახებ განსხვავებების განსხვავებას, რომელიც განსხვავებულია სენსის განსხვავებას BERT-ში შესახებ სივრცე. განსაკუთრებით, ჰომონიმური სინუსები (მაგალითად, ცხოვრება როგორც ცხოვრება როგორც სპორტის განსაკუთრება) ძალიან უფრო განრყოფილი ერთმანეთიდან ერთმანეთიდან ერთმანეთიდან სხვადასხვადასხვადასხვადასხვადასხვადასხვა ჩვენი შესაძლებლობები დააწყებენ პროცენტური სამყარო მსოფლიოს გამოსახულებების პროცენტურება.', 'it': "Comprendere variazioni contestuali nei significati delle parole è un aspetto chiave della comprensione del linguaggio umano supportato dal lessico. Le risorse lessicografiche (ad esempio WordNet) catturano solo alcune di queste variazioni contestuali; Per esempio, spesso non codificano quanto strettamente i sensi, o i significati discreti delle parole, siano correlati tra loro. Il nostro lavoro indaga se i recenti progressi nel PNL, specificamente contestualizzati embedding di parole, catturino distinzioni umane tra i sensi delle parole inglesi, come polisemia e omonimia. Raccogliamo dati da un esperimento comportamentale basato sul web, in cui i partecipanti forniscono giudizi sulla relazione di più sensi WordNet di una parola in un compito di disposizione spaziale bidimensionale. Troviamo che i giudizi dei partecipanti sulla relazione tra i sensi sono correlati con le distanze tra i sensi nello spazio incorporato del BERT. Nello specifico, i sensi omonimi (ad esempio pipistrello come mammifero vs pipistrello come attrezzatura sportiva) sono attendibilmente più distanti l'uno dall'altro nello spazio di incorporazione rispetto a quelli polisemosi (ad esempio, pollo come animale vs pollo come carne). Le nostre scoperte indicano la potenziale utilità delle rappresentazioni spaziali continue dei significati sensoriali.", 'lt': 'Pagrindinis žmogaus kalbos supratimo aspektas, pagrįstas lexikonu, yra nuo konteksto priklausomas žodžių reikšmės skirtumas. Lexikografiniai ištekliai (pvz., WordNet) apima tik kai kuriuos nuo konteksto priklausomus variantus; pavyzdžiui, jie dažnai nenurodo, kaip artimi jutimai arba diskrecinės žodžių reikšmės yra tarpusavyje susijusios. Mūsų darbe tiriama, ar neseniai padaryta pažanga NLP, konkrečiai kontekstinė žodžių įtraukimas, apima žmogaus panašius skirtumus tarp anglų žodžių jutimų, pavyzdžiui, polisemijos ir homonimijos. Mes renkame duomenis iš elgesio eksperimento internetu, kuriame dalyviai pateikia sprendimus dėl kelių WordNet jutimų ryšio dviejų matmenų erdvinio susitarimo užduotyje. Matome, kad dalyvių sprendimai dėl jutimų ryšio yra susiję su nuotoliais tarp jutimų BERT įdėjimo erdvėje. Konkrečiai, homoniminiai jausmai (pvz., žiurkėnai kaip žinduoliai, o žiurkėnai kaip sporto įranga) yra patikimai tolimesni vienas nuo kito įdėjimo vietoje nei polizeiniai (pvz., viščiukai kaip gyvūnas, o viščiukai kaip mėsa). Mūsų išvados rodo galimą naudą nuolatiniams kosmoso atstovavimams, turintiems prasmę.', 'kk': 'Сөздердің мәліметтерінің контексті тәуелді айнымалылығын түсіну - лексиканың қолданылатын адамдар тілдерінің түсінікті аспекті. Лексиографиялық ресурстар (мысалы, WordNet) тек осы контекстік тәуелді айнымалылығының бірнеше ғана қабылдайды; мәліметтер Мысалы, олар қанша жақын сезімдерді, немесе сөздердің мәліметтері бір-біріне қатынасыз болатынын кодтамайды. Біздің жұмысамыз NLP-де жаңа жағдайларды зерттейді, осы түрде контекстуалды сөздерді ендіру үшін, ағылшын сөздердің сезімдерінің арасындағы адамдардың түсініктерін, мысалы полизия мен гомония Біз веб-негіздеген тәжірибеден деректерді жинақтаймыз. Қатысушылар екі- өлшемі бос орындау тапсырмасында бірнеше WordNet сезімдерінің бірнеше мәліметтерінің қатынастығын түсіндіреді. Біз қатысушылардың сезімдер арасындағы қатынасыздық тәртіптері BERT ендіру орындағы сезімдер арасындағы қашықтығымен қатынасыз келеді. Ескерту үшін, гомонимдік сезімдер (мысалы, сұхбат және сұхбат және спорт құрылғысы ретінде) полисемдіктерден бір-бірінен қашықтар (мысалы, тұхбат және тұхбат тұхбат ретінде). Біздің табуларымыз маңызды мәліметтердің тұрақтық бос орындарының мүмкіндікті утилитасына көмектеседі.', 'ms': "Memahami variasi tergantung konteks dalam makna perkataan adalah aspek kunci pemahaman bahasa manusia yang disokong oleh leksikon. Sumber Lexikografik (cth., WordNet) hanya menangkap sebahagian dari variasi tergantung pada konteks ini; Contohnya, mereka sering tidak mengekodkan betapa dekatnya perasaan, atau makna perkataan yang terperinci, berkaitan satu sama lain. Pekerjaan kami menyelidiki sama ada kemajuan baru-baru ini dalam NLP, secara khusus pembangunan perkataan kontekstualisasi, menangkap perbezaan seperti manusia antara perasaan perkataan Inggeris, seperti polisemi dan homonimi. Kami mengumpulkan data dari percubaan perilaku, berdasarkan web, yang mana peserta memberikan penghakiman mengenai hubungan beberapa perasaan WordNet dalam satu perkataan dalam tugas pengaturan ruang dua dimensi. We find that participants' judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space.  Secara khusus, perasaan homonymous (cth., kelelawar sebagai mamalia vs kelelawar sebagai peralatan sukan) adalah lebih jauh dari satu sama lain dalam ruang penyembedding daripada yang polisemous (cth., ayam sebagai haiwan vs. ayam sebagai daging). Penemuan kita menunjukkan kepada kemudahan potensi perwakilan ruang-terus makna masuk akal.", 'mk': "Разбирање на контекстно зависната варијација во значењето на зборовите е клучен аспект на разбирање на човечкиот јазик поддржан од лексиконот. Лексикографските ресурси (на пример WordNet) зафатуваат само некои од овие контекстски зависни варијации; на пример, тие често не кодираат колку блиски сетила или дискретизирани зборови се поврзани меѓусебно. Нашата работа истражува дали неодамнешните напредоци во НЛП, специфично контекстуализирани зборови вклучуваат разлики на човек меѓу англиските зборови, како што се полисемијата и хомонимијата. Ги собираме податоците од однесувачкиот, веб-базиран експеримент, во кој учесниците обезбедуваат пресуди за поврзаноста на многуте WordNet сетила на збор во дводимензионална просторна задача. We find that participants' judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space.  Специфично, хомонимните сензии (на пример, лилјак како цицач против лилјак како спортска опрема) се веројатно подалеку еден од друг во вставниот простор од полисемите (на пример, пилешко како животно против пилешко како месо). Нашите откритија покажуваат кон потенцијалната корисност на континуирани вселенски претставувања на смислено значење.", 'mt': 'Il-fehim ta’ varjazzjoni dipendenti fuq il-kuntest fit-tifsiriet tal-kliem huwa aspett ewlieni tal-fehim tal-lingwa umana appoġġjat mil-lexicon. Ir-riżorsi lexikografiċi (e ż., WordNet) jaqbdu biss xi wħud minn din il-varjazzjoni dipendenti fuq il-kuntest; pereżempju, spiss ma jikkodifikawx kemm is-sensi mill-qrib, jew it-tifsiriet diskrezzati tal-kelma, huma relatati ma’ xulxin. Ix-xogħol tagħna jinvestiga jekk l-avvanzi reċenti fil-NLP, l-inkorporazzjonijiet tal-kliem speċifikament kuntestwalizzati, jaqbdux distinzjonijiet simili għall-bniedem bejn is-sensi tal-kliem Ingliż, bħall-polisimja u l-omonimja. We collect data from a behavioral, web-based experiment, in which participants provide judgments of the relatedness of multiple WordNet senses of a word in a two-dimensional spatial arrangement task.  Aħna nsibu li s-sentenzi tal-parteċipanti dwar ir-relazzjoni bejn is-sensi huma korrelati mad-distanzi bejn is-sensi fl-ispazju tal-inkorporazzjoni BERT. B’mod speċifiku, is-sensi omonimużi (e ż., il-ħosba bħala mammifer vs. il-ħosba bħala tagħmir sportiv) huma affidabbilment aktar ’il bogħod minn xulxin fl-ispazju tal-inkorporazzjoni minn dawk poliżmużi (eż., it-tiġieġ bħala annimal kontra t-tiġieġ bħala laħam). Is-sejbiet tagħna jindikaw l-utilità potenzjali tar-rappreżentazzjonijiet kontinwi tal-ispazju ta’ tifsiriet sensittivi.', 'ml': "വാക്കിന്റെ അര്\u200dത്ഥങ്ങളില്\u200d കെന്\u200dസ്റ്റെന്റ്- ആശ്രയിക്കുന്ന മാറ്റങ്ങള്\u200d ലെക്സിക്സണ്\u200d പിന്തുണയ്ക്കുന്നത ലെക്സിക്സിക്കോഗ്രാഫിക വിഭവങ്ങള്\u200d (ഉദാഹരണമായ വാര്\u200dഡ്\u200cനെറ്റ്) ഈ കോണ്\u200dസ്റ്റ്-ആശ്രയിക്കുന്ന വേറിഷന്\u200d മാത ഉദാഹരണത്തിനുള്ള ഉദാഹരണത്തിനുള്ളില്\u200d എപ്പോഴും സൂക്ഷ്മമായ വാക്കിന്\u200dറെ അര്\u200dത്ഥം എത്ര അടുത്താണെന്നോ അതിന്\u200dറ നമ്മുടെ ജോലി അന്വേഷിക്കുന്നത് NLP-ലെ അടുത്തുള്ള മുന്\u200dഗണങ്ങളാണോ എന്ന്, പ്രത്യേകിച്ച് നിരീക്ഷിക്കപ്പെട്ട വാക്കുകള്\u200d പ്രത്യേകിച്ച്  വെബ് അടിസ്ഥാനമായ പരീക്ഷണത്തില്\u200d നിന്നുള്ള വിവരങ്ങള്\u200d ഞങ്ങള്\u200d ശേഖരിക്കുന്നു. അതില്\u200d പങ്കാളികള്\u200d പല വാര്\u200dഡ്നെറ്റിന്റെ ബന്ധങ്ങളുടെയും വിധികള്\u200d കൊട We find that participants' judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space.  പ്രത്യേകിച്ച്, പോളിസെമിസ്സിനെക്കാള്\u200d കൂടുതല്\u200d വിശ്വസ്തതയുള്ള സ്ഥലത്തുള്ള പോളിസേമിസ്സിനെക്കാള്\u200d കോഴിയെക്കാള്\u200d കൂടുതല്\u200d ദൂരെയാണ് (ഉദാഹരണമായ, മൃഗങ്ങളെക്കാ നിലനില്\u200dക്കുന്ന സ്പെയിസ് പ്രതിനിധികളുടെ സാധ്യതയുടെ ഉപയോഗങ്ങള്\u200dക്ക് നമ്മുടെ കണ്ടെത്തുന്നത് മനസ്", 'pl': 'Zrozumienie zależnych od kontekstu zmian w znaczeniach słowa jest kluczowym aspektem rozumienia języka ludzkiego wspieranego przez leksykon. Zasoby leksygraficzne (np. WordNet) obejmują tylko niektóre z tych zależnych od kontekstu zmian; Na przykład, często nie kodują, jak blisko są ze sobą powiązane zmysły lub dyskretyzowane znaczenia słów. Nasza praca bada, czy ostatnie postępy w NLP, konkretnie kontekstualizowane osadzenia słów, uwzględniają ludzkie rozróżnienia między angielskimi zmysłami słowa, takimi jak polisemia i homonimia. Gromadzimy dane z behawioralnego, internetowego eksperymentu, w którym uczestnicy oceniają związek wielu zmysłów WordNet słowa w dwuwymiarowym zadaniu aranżacji przestrzennej. Stwierdzono, że oceny uczestników związku ze zmysłami są skorelowane z odległościami między zmysłami w przestrzeni osadzającej BERT. W szczególności zmysły homonimowe (np. nietoperz jako ssak vs nietoperz jako sprzęt sportowy) są niezawodnie bardziej odległe od siebie w przestrzeni osadzenia niż te wielosemiczne (np. kurczak jako zwierzę vs. kurczak jako mięso). Nasze odkrycia wskazują na potencjalną użyteczność ciągłej przestrzeni reprezentacji znaczeń zmysłowych.', 'mn': 'Үүний утгатай харьцуулалтын тухай харьцуулалтыг ойлгох нь хүний хэл ойлголтын чухал асуудал юм. Лексикографик нөөц (жишээ нь WordNet) зөвхөн нөхцөл байдлын хамааралтай өөрчлөлтийн зарим хэсгийг барьдаг. Жишээлбэл, тэд ихэвчлэн хэр ойрхон мэдрэмж, эсвэл тодорхойлогдсон үгний утгыг хоорондоо холбогдохгүй. Бидний ажлын ажил NLP-д саяхан хөгжлийг судалж, ялангуяа нөхцөл үгний нэгдэл, Англи үгний мэдрэмжүүдийн хоорондох ялгааг хүн төрөлхтний адил ялгааг барьдаг эсэхийг судалж байна. Бид үйл ажиллагааны, веб-суурилсан туршилтаас өгөгдлийг цуглуулж, оролцогчдын хоёр хэмжээст орон зайн зохицуулалтын ажилд хэдэн WordNet-ийн мэдрэмжтэй холбоотой байдлын тухай шийдвэр гаргадаг. Бид оролцогчдын мэдрэмжүүдийн хоорондох хоорондох хоорондох хоорондох мэдрэмжүүдийн шүүмжүүд нь BERT-ын орон зайд байгаа мэдрэмжүүдийн хоорондох хоорондох хоорондох хоорондох хо Тодорхой хэлбэл, геомоним мэдрэмж (жишээ нь, тахиа, тахиа, мах гэх мэт амьтны эсвэл тахиа гэх мэт тахиа) ихэвчлэн хол зайд байдаг. Бидний ололтууд маань мэдрэмжтэй утгатай байдлын үргэлжилсэн орон зайн хэрэглээний талаар тодорхойлж байна.', 'ro': 'Înțelegerea variațiilor dependente de context în sensul cuvintelor este un aspect cheie al înțelegerii limbajului uman susținut de lexicon. Resursele lexicografice (de exemplu WordNet) captează doar o parte din această variație dependentă de context; De exemplu, adesea nu codează cât de strâns simțurile sau semnificațiile discreționate ale cuvintelor sunt legate unul de altul. Lucrarea noastră investighează dacă progresele recente în PNL, în special contextualizate încorporări de cuvinte, captează distincții asemănătoare unui om între simțurile cuvintelor engleze, cum ar fi polisemie și omonimie. Colectăm date dintr-un experiment comportamental, bazat pe web, în care participanții oferă judecăți cu privire la relația mai multor simțuri WordNet ale unui cuvânt într-o sarcină de aranjare spațială bidimensională. Observăm că judecățile participanților cu privire la relația dintre simțuri sunt corelate cu distanțele dintre simțuri în spațiul de încorporare BERT. În mod specific, simțurile omonime (de exemplu, liliac ca mamifer vs liliac ca echipament sportiv) sunt în mod fiabil mai departe unul de altul în spațiul de încorporare decât cele polisemoase (de exemplu, pui ca animal vs pui ca carne). Descoperirile noastre indică utilitatea potențială a reprezentărilor spațiale continue a semnificațiilor simțurilor.', 'no': 'Forståking av kontekstavhengige variasjonar i ordmeaningar er ein nøkkelaspekt av menneskelig språk som er støtta av leksikonet. Leksiografiske ressursar (f.eks. WordNet) får berre nokre av denne kontekstavhengige variasjonen; For eksempel, dei er ofte ikkje koda kor nærare senterer eller diskretert ordbetinger er relatert til kvarandre. Arbeidet vårt undersøker om nyleg utviklingar i NLP, spesielt kontekstualisert ordinnbygging, hentar menneskelige forskjellingar mellom engelske ordsenser, slik som polysemi og homonyme. Vi samler data frå ein atferdsbasert, nettbasert eksperiment, der deltakarar gjev avtalene av fleire WordNet-senter til eit ord i ei to-dimensjonal romlig oppgåve. Vi finn at deltakaranes sprøytebruk av relatediteten mellom senter er er korrelatert med avstandane mellom senter i BERT-innbyggingsrommet. Spesielt er homonymous sensar (f.eks. bølgjande som bølgjande mot bølgjande som sportverktøy) tiltrukkeleg meir distant frå kvarandre i innbyggingsrommet enn polysemus (f.eks. kjølgjande som dyr mot kjølgjande som kjøtt). Finningane våre viser mot det potensielle verktøyet for kontinuerleg plass-representasjonar av følelser.', 'sr': 'Razumevanje kontekstskih varijacija u značenju reči je ključni aspekt razumevanja ljudskih jezika koji podržava leksikon. Leksiografijski resursi (npr. WordNet) uhvate samo neke od ovisnog konteksta varijacije; Na primer, oni često ne kodiraju koliko blizu osećanja ili diskretno značenje riječi, vezane su jedno sa drugom. Naš rad istražuje da li nedavni napredak u NLP-u, posebno kontekstualizirani integraciji reči, uhvate razlike poput ljudskih razlika između čula engleskih reči, poput polizemije i homonimije. Skupljamo podatke iz ponašanja, web-baziranog eksperimenta, u kojem sudionici pružaju osude o povezanosti višestrukih osjećaja WordNet-a reči u zadatku o dvodimenzionalnom prostornom organizaciji. Nalazimo da sudionici osude veze između čula povezuju sa udaljenostima između čula u svemiru BERT-a. Posebno, homonimski osećaji (npr. šišmiš kao sisar protiv palice kao sportska oprema) vjerojatno su daleko od jedne od druge u ugrađenom prostoru od polizemnih (npr. piletina kao životinja protiv piletine kao meso). Naši nalazi ukazuju na potencijalnu korisnost kontinualnog svemirskog predstavljanja smisla.', 'si': 'වචන අදහස් වලට ප්\u200dරතිස්ථාවක් වෙනස් තේරුම් ගන්නේ මිනිස් භාෂාව ප්\u200dරතිස්ථානයක් ප්\u200dරතිස්ථාපනයක්  ලෙක්සිකෝග්\u200dරාෆික් උපකරණය (උදාහරණය, WordNet) මේ සංවේදනය සම්බන්ධ වෙනස් විතරයෙන් විතරයි අල්ලගන උදාහරණයෙන්, ඔවුන් සමහරවෙලාවෙන් සම්බන්ධ වෙන්නේ නෑ කොච්චර සම්බන්ධ වෙන්නේ කියලා, නැත්තම් විශ අපේ වැඩේ පරීක්ෂණය කරනවා NLP වලින් අලුත් ප්\u200dරධානයක් තියෙනවද කියලා, විශේෂයෙන් පරීක්ෂණය කරලා තියෙනවද කියලා, ඉංග්\u200dරීසි ව අපි හැසිරීමක්, වෙබ් අධාරිත පරීක්ෂණයක් නිසා දත්ත ගන්නවා, ඒ වගේම සම්බන්ධ වෙනුවෙන් වචනයක් වගේ වචනයක් වගේ වචනයක් දෙකක් අභාවි අපි හොයාගන්නවා සම්බන්ධකාරීන්ගේ විශ්වාස කරනවා සම්බන්ධතාවක් අතර සම්බන්ධතාවක් තියෙනවා කියලා, BERT සම්බන්ධ අත විශේෂයෙන්ම, හොමානිමුස් සංවේදනය (උදාහරණයෙන්, ස්පෝර්ට් උපකරණය විදියට බැට්ට් විදියට බැට්ට් විදියට) පොලිස්මෝස් වලට වඩා විශ්වාසියෙ අපේ හොයාගන්න පුළුවන් ප්\u200dරයෝජනයක් තියෙනවා තේරුම් අදහස් වලට ප්\u200dරයෝජනයක්.', 'sv': 'Att förstå kontextberoende variation i ordbetydelser är en viktig aspekt av mänsklig språkförståelse som stöds av lexikonet. Lexikografiska resurser (t.ex. WordNet) fångar endast en del av denna sammanhangsberoende variation; Till exempel kodar de ofta inte hur nära sinnen, eller diskretiserade ordbetydelser, är relaterade till varandra. Vårt arbete undersöker om de senaste framstegen inom NLP, specifikt kontextualiserade ordinbäddningar, fångar människoliknande skillnader mellan engelska ordsinnen, såsom polysemi och homonymi. Vi samlar in data från ett beteende, webbaserat experiment, där deltagarna ger bedömningar av sambandet mellan flera WordNet-sinnen i ett ord i en tvådimensionell rumslig arrangemangsuppgift. Vi finner att deltagarnas bedömningar av sambandet mellan sinnena korreleras med avstånd mellan sinnena i BERT-bäddrummet. Specifikt är homonyma sinnen (t.ex. fladdermus som däggdjur vs fladdermus som sportutrustning) tillförlitligt mer avlägsna från varandra i inbäddningsutrymmet än polyemous sinnen (t.ex. kyckling som djur vs kyckling som kött). Våra fynd pekar mot den potentiella nyttan av kontinuerliga rymdrepresentationer av sinnesvillkor.', 'so': 'Understanding context-dependent variation in word meanings is a key aspect of comprehension of human language, supported by the lexicon. Lexicographic resources (e.g., WordNet) capture only some of this context-dependent variation;  Tusaale ahaan waxyaabaha la xiriira waxyaabaha la xiriira waxyaabaha la xiriira, waxyaabaha la xiriirayo waxyaabaha la xiriira waxyaabaha ay leeyihiin. Shaqodayada ayaa baaraandegaya in horumarinta ugu dambeeyay ee NLP, si gaar ah hadalka la xiriiray, ku qabsada kala duwanaanshaha u eg ingiriisiga, tusaale ahaan polysemi iyo homonimo. Waxaynu soo ururiyaa macluumaad ka mid ah baaritaanka dabeecada ee internetka, kaas oo ay ka qeybqaadan yihiin xukummo ku saabsan xiriirka la xiriira labada sano ee WordNet ah oo eray ka mid ah xafiiska xafiiska kala duduwan. Waxaynu ognahay in xukunka dadka ka qayb qaata ee xiriirka maanaha u dhexeeya ay ku xiran yihiin meelaha u dhaxaysa kasoo baxa xiliga BERT. Si gaar ah, qalabka jimicsigu waa ka fog yihiin iskuulka isboortiga (tusaale ahaan cir ka mid ah sida xayawaanka oo kale). Helitaankeena waxaa loola jeedaa isticmaalka suurtagalka ah ee nooca joogta ah ee micneheeda maanka ah.', 'ta': 'புரிந்து கொள்வது - சார்ந்த மாறுபாடு வார்த்தைகளில் புரிந்து கொள்வது லெக்சிக்கன் ஆதரிக்கப்பட்ட மொழி சூழ் லெக்சிகிராபிக் மூலங்கள் (உதாரணமாக, WordNet) இந்த சூழல் சார்ந்த மாறுபாடு மட்டும் பிடித்துக் கொள்ளும். எடுத்துக்காட்டாக, அவர்கள் பெரும்பாலாக ஒருவருக்கொருவர் அர்த்தமான உணர்வுகளை குறியீடு செய்ய முடியாது. NLP-ல் சமீபத்தில் முன்னேற்றங்கள் என்பதை எங்கள் வேலை தீர்வு செய்கிறது, குறிப்பாக பாதிக்கப்பட்ட வார்த்தை உள்ளடக்கிய வார்த்தைகள், ஆங்கி நாம் ஒரு நடத்தையிலிருந்து தகவல்களை சேகரிக்கிறோம், வலை அடிப்படையிலிருந்து, அதில் பங்கீட்டாளர்கள் பல வார்த்தைநெட்டின் உணர்வுகளின் தீர்ப்புகள பெர்ட் உள்ளூடும் இடைவெளியில் உள்ள உணர்வுகளுக்கிடையே தூரத்துடன் இணைக்கப்பட்டுள்ளது என்பதை நாம் கண்டுபிடிக்கிறோம். குறிப்பிட்ட புலன் உணர்வுகள் (உதாரணமாக, விளையாட்டு கருவி போன்ற பாட்டு என்று பாட் என்றால் பாட்டில் இருந்து ஒருவருக்கொருவர் நம்பிக்கையாக இருக்கிறார்கள்) போலிசெம Our findings point towards the potential utility of continuous-space representations of sense meanings.', 'ur': 'کلمات کے معنی میں متوسطہ تغییر کا سمجھنا انسان کی زبان کی اصلی حصہ ہے جو لکسیکن کی مدد کی جاتی ہے۔ لکسیکوگرافیک سراسر (جیسے WordNet) صرف اس کنٹکس منتظر تغییر میں سے کچھ پکڑتے ہیں۔ مثال یہ اغلب کسی کے ساتھ کس طرح نزدیک احساسات ہیں اور کس طرح بات کی تعبیر نہیں کرتے۔ ہمارا کام تحقیق کرتا ہے کہ NLP میں اگلے اضافہ کیا جاتا ہے، مخصوصا متاثر لکھی ہوئی لغات میں، انگلیسی لغات سنس کے درمیان انسان کی طرح تفریقوں کو پکڑتے ہیں، جیسے پلیسی اور homonymy. ہم ایک رفتاری، ویب بنیاد آزمائش سے اطلاعات جمع کرتے ہیں، جہاں شرکت کرنے والوں نے ایک کلمہ دو اندازے کے فضائی ترکیب کے کام میں ایک کلمہ کی تعلق کا فیصلہ کیا ہے. ہم دیکھتے ہیں کہ شرکت کرنے والوں کے فیصلے جنہیں حسوں کے درمیان رابطہ کیا گیا ہے BERT میں ڈوبنے کی جگہ میں سینوں کے درمیان دور سے تعلق ہے. مخصوص طور پر، homonymous senses (e.g., mammal vs. bat as sport equipment) ایک دوسرے سے ایک دوسرے سے زیادہ دور ہوتے ہیں (e.g., chicken as animal vs. chicken as meat). ہمارے نتیجے سمجھ کے معنی کی ہمیشہ جگہ کے مطابق استفاده کرنے کے لئے نشان دیتے ہیں.', 'uz': "Name Leksikografik manbalari (m. g. WordNet) faqat bu context-боғлиқ ўзгаришларни qabul qiladi; Masalan, ular ko'pincha eng yaxshi hissiyotlarni kodlash mumkin, yoki cheksiz so'zlar bir-бирларига bog'liq. Bizning ishimiz NLPdagi yaqinda taʼminlovchi darajalarni o'rganadi, hususan taʼminlovchi so'zlar ichki so'zlar hisoblariga o'xshash o'zgarishlarni olib tashlaydi, polysemi va homoni kabi. Biz veb- asosiy tajribadan maʼlumotni olib tashlamiz. Bu muammolar bu bir necha so'zlar OrdNet hisobotidagi bir so'zning bir necha so'zlarining bog'liqlarini qo'llashadi. Biz o'rganamiz, hissiyotning orasidagi munosabatlar xususiyatlarini BERT ichiga keladigan hissiyotning orasidagi orasida bog'liq. Ko'rsatilgan, homiy hissiyotlar (masalan, sport huquqlari kabi o'smirlar kabi o'smirlar kabi o'zgarishga ishonch keladigan bo'lgan vaqtda bir-бирlaridan juda ham ajoyib (masalan, pul sifatida kechilik kabi). Bizning natijalarimiz haqida davom etadigan ma'lumotning xususiyatlariga ishlatiladi.", 'vi': 'Hiểu được sự khác biệt phụ thuộc vào ngữ nghĩa là một khía cạnh quan trọng của sự hiểu biết ngôn ngữ con người được hỗ trợ bởi ngôn ngữ. Tài nguyên ngôn ngữ (v.d. WordNet) chỉ thu thập được một số khác biệt phụ thuộc hoàn cảnh này; Ví dụ như, họ thường không mã hóa các giác quan chặt chẽ, hay những từ ngữ riêng biệt có liên quan đến nhau. Công việc của chúng tôi nghiên cứu liệu những tiến bộ gần đây trong ngôn ngữ Nchọc, những từ ngữ được áp bức đặc biệt, bắt được sự khác biệt con người giữa các giác quan từ Anh ngữ, như polysemy và đồng tính. Chúng tôi thu thập dữ liệu từ một thí nghiệm hành vi, dựa trên mạng, trong đó các diễn viên cung cấp các phán đoán về quan hệ của nhiều cảm giác của WordNet về một từ trong một nhiệm vụ sắp đặt vũ trụ hai chiều. Chúng tôi thấy rằng những phán đoán của những người tham gia về quan hệ giữa các giác quan phù hợp với khoảng cách giữa các giác quan trong không gian ước ao hạch. Cụ thể hơn, các giác quan đồng tính (v.d., dơi như vú đấu với dơi như dụng cụ thể thao) hoàn toàn xa cách nhau hơn ở chỗ lắp ghép hơn là các giác quan tầm thường (v.d. g à như thú vật và gà như thịt). Những phát hiện của chúng ta cho thấy sự hữu ích tiềm năng của những biểu hiện ý nghĩa không gian.', 'hr': 'Razumijevanje kontekstskih varijacija u značenju riječi je ključni aspekt razumijevanja ljudskog jezika koji podržava leksikon. Leksiografijske resurse (npr. WordNet) uhvate samo neke od ovisnih o kontekstu varijacija; Na primjer, oni često ne kodiraju koliko su bliski osjećaji ili diskretno značenje riječi povezani jedni s drugima. Naš rad istražuje je li nedavni napredak u NLP-u, posebno kontekstualizirani integraciji riječi, uhvatiti ljudske razlike između čula engleskih riječi, poput polizemije i homonimije. Skupljamo podatke iz ponašanja, internetskog eksperimenta, u kojem sudionici pružaju osude o povezanosti višestrukih osjećaja WordNet-a riječi u zadatku za dvodimenzionalno prostorno rješavanje. Nalazimo da su sudionici osuđivanja odnosa između čula povezani s udaljenostima između čula u prostoru ugrađenog BERT-a. Posebno, homonimski osjećaji (npr. šišmiš kao sisar protiv šišmiša kao sportska oprema) vjerojatno su daleko od jedne od druge u ugrađenom prostoru od polizemnih (npr. piletina kao životinja protiv piletina kao meso). Naši nalazi upućuju na potencijalnu korisnost stalnog prostora predstavljanja smisla.', 'bg': 'Разбирането на зависимите от контекста вариации в значението на думите е ключов аспект на разбирането на човешкия език, подкрепено от лексикона. Лексикографските ресурси (например WordNet) улавят само част от тази зависимост от контекста вариация; Например, те често не кодират колко тясно сетивата или дискретизираните значения на думата са свързани помежду си. Нашата работа изследва дали скорошните напредъци в НЛП, конкретно контекстуализираните словни вграждания, улавят човешки различия между английските словни сетива, като полисемия и хомонимия. Събираме данни от поведенчески, уеб-базиран експеримент, в който участниците дават преценки за връзката на множество сетива на дума в двуизмерна задача за пространствено подреждане. Установяваме, че преценките на участниците за връзката между сетивата са корелирани с разстоянията между сетивата в вграждащото пространство на БЕРТ. По-конкретно, хомонимните сетива (например прилеп като бозайник срещу прилеп като спортно оборудване) са надеждно по-отдалечени един от друг в вграденото пространство, отколкото полиемозните (например пилето като животно срещу пилето като месо). Нашите открития сочат към потенциалната полезност на непрекъснато пространствените представи на сетивните значения.', 'da': 'Forståelse af kontekst-afhængig variation i ordbetydninger er et centralt aspekt af menneskelig sprogforståelse understøttet af leksikonen. Lexikografiske ressourcer (f.eks. WordNet) indfanger kun nogle af denne kontekstafhængige variation; For eksempel koder de ofte ikke, hvor tæt sanser, eller diskretiserede ordbetydninger, er relateret til hinanden. Vores arbejde undersøger, om de seneste fremskridt inden for NLP, specielt kontekstualiserede ordindlejringer, fanger menneskelignende skelnen mellem engelske ordsanser, såsom polysemi og homonymi. Vi indsamler data fra et adfærdsmæssigt, webbaseret eksperiment, hvor deltagerne giver vurderinger af forholdet mellem flere WordNet sanser af et ord i en todimensionel rumlig arrangement opgave. Vi finder ud af, at deltagernes vurderinger af forholdet mellem sanser er korreleret med afstande mellem sanser i BERT indlejringsrummet. Specielt er homonyme sanser (f.eks. flagermus som pattedyr vs. flagermus som sportsudstyr) pålideligt mere langt fra hinanden i indlejringsrummet end polystemøse sanser (f.eks. kylling som dyr vs. kylling som kød). Vores resultater peger på den potentielle nytte af kontinuerlige rum repræsentationer af sansebetydninger.', 'nl': 'Het begrijpen van contextafhankelijke variatie in woordbetekenissen is een belangrijk aspect van menselijk taalbegrip ondersteund door het lexicon. Lexicografische bronnen (bijvoorbeeld WordNet) bevatten slechts een deel van deze contextafhankelijke variatie; Ze coderen bijvoorbeeld vaak niet hoe nauw zintuigen, of discretiseerde woordbetekenissen, met elkaar verbonden zijn. Ons werk onderzoekt of recente vooruitgang in NLP, specifiek contextualiseerde woord embeddings, menselijk onderscheid tussen Engelse woordzintuigen, zoals polysemie en homoniemie, vastleggen. We verzamelen gegevens uit een gedragsexperiment, waarbij deelnemers een oordeel geven over de verwantschap van meerdere WordNet-zintuigen van een woord in een tweedimensionale ruimtelijke ordeningstaak. We vinden dat de beoordelingen van deelnemers over de relatie tussen zintuigen gecorreleerd zijn met afstanden tussen zintuigen in de BERT-insluitruimte. Specifiek, homonieme zintuigen (bijvoorbeeld vleermuis als zoogdier vs. vleermuis als sportuitrusting) zijn betrouwbaarder van elkaar in de inbeddingsruimte dan polyemotionele zintuigen (bijvoorbeeld kip als dier versus kip als vlees). Onze bevindingen wijzen op het potentieel van continue-space representaties van zintuiglijke betekenissen.', 'de': 'Das Verständnis der kontextabhängigen Variation von Wortbedeutungen ist ein Schlüsselaspekt des menschlichen Sprachverständnisses, das durch das Lexikon unterstützt wird. Lexikographische Ressourcen (z.B. WordNet) erfassen nur einen Teil dieser kontextabhängigen Variation; Zum Beispiel kodieren sie oft nicht, wie eng Sinne oder diskretisierte Wortbedeutungen miteinander verwandt sind. Unsere Arbeit untersucht, ob jüngste Fortschritte in NLP, speziell kontextualisierte Worteinbettungen, menschenähnliche Unterschiede zwischen englischen Wortsinnen wie Polysemie und Homonymie erfassen. Wir sammeln Daten aus einem verhaltensbasierten, webbasierten Experiment, in dem Teilnehmer die Verwandtschaft mehrerer WordNet-Sinne eines Wortes in einer zweidimensionalen Raumordnungsaufgabe beurteilen. Wir finden, dass die Einschätzungen der Teilnehmer über die Verwandtschaft zwischen Sinnen mit Entfernungen zwischen Sinnen im BERT Einbettungsraum korrelieren. Konkret sind homonyme Sinne (z.B. Fledermaus als Säugetier vs. Fledermaus als Sportgerät) im Einbettungsraum zuverlässiger voneinander entfernt als polyemotionale (z.B. Huhn als Tier vs. Huhn als Fleisch). Unsere Erkenntnisse weisen auf den potenziellen Nutzen von kontinuierlichen Raum-Repräsentationen von Sinnesbedeutungen hin.', 'id': 'Memahami variasi tergantung konteks dalam arti kata adalah aspek kunci dari pemahaman bahasa manusia yang didukung oleh leksikon. Sumber daya Lexikografi (cth., WordNet) hanya menangkap beberapa variasi tergantung konteks ini; contohnya, mereka sering tidak mengkode seberapa dekat perasaan, atau arti kata yang diskret, berhubungan satu sama lain. Pekerjaan kami menyelidiki apakah kemajuan baru-baru ini di NLP, secara spesifik kontekstualisasi pembangunan kata, menangkap perbedaan seperti manusia antara sens kata Inggris, seperti polisemi dan homonimi. Kami mengumpulkan data dari eksperimen perilaku, berdasarkan web, di mana para peserta memberikan penilaian tentang hubungan dari beberapa sens WordNet dari sebuah kata dalam tugas pengaturan ruang dua dimensi. Kami menemukan bahwa penghakiman peserta tentang hubungan antara perasaan terkait dengan jarak antara perasaan di ruang BERT. Secara spesifik, senses homonymous (contohnya, kelelawar sebagai mamalia vs. kelelawar sebagai peralatan olahraga) secara kreatif lebih jauh dari satu sama lain dalam ruang penerbangan daripada yang polisemus (contohnya ayam sebagai hewan vs. ayam sebagai daging). Penemuan kita menunjukkan kepada kemudahan potensial dari persembahan ruang-terus dari arti masuk akal.', 'ko': '언어 환경과 관련된 단어의 의미 변화를 이해하는 것은 어휘가 지지하는 인류의 언어 이해의 관건적인 부분이다.사전 자원(예를 들어 WordNet)은 상하문과 관련된 변화만 포착했다.예를 들어 감각관이나 이산화된 의미 간의 연관성을 인코딩하지 않는다.우리의 업무는 NLP의 최신 진전, 특히 어경화된 단어의 삽입, 예를 들어 다의와 동음이의 간의 인류 차이를 포착했는지 조사했다.우리는 네트워크 기반의 행위 실험에서 데이터를 수집하여 이 실험에서 참가자들은 2차원 공간 배열 작업에서 한 단어의 여러 WordNet 의미의 상관성을 판단했다.우리는 참여자가 감각관 간의 관련성에 대한 판단이 공간에 박힌 감각관 간의 거리와 관련이 있다는 것을 발견했다.구체적으로 말하면 공간에 박혀 있는 동명 감각관(예를 들어 박쥐는 포유동물이나 박쥐는 운동기구로서) 사이의 거리는 다의감각관(예를 들어 닭은 동물이나 닭은 고기로서) 사이의 거리보다 훨씬 멀다.우리의 발견은 감각적 의미의 연속 공간 표징의 잠재적 효용을 가리킨다.', 'fa': 'فهمیدن تغییرات بستگی به محیط در معنی کلمات یک منظور کلید از فهمیدن زبان انسان است که توسط لکسیکون پشتیبانی می\u200cکند. منابع لکسیکوگرافی (مثال WordNet) فقط بعضی از این تغییرات بستگی به محیط می\u200cگیرند. برای مثال، آنها اغلب با یکدیگر نسبت به چقدر حس نزدیک یا معنی کلمه\u200cهای متفاوت نسبت به یکدیگر نیستند. کار ما تحقیق می\u200cکند که آیا پیشرفت اخیر در NLP، مخصوصاً کلمه\u200cهای متوسط شده، تفاوت\u200cهای مانند انسان بین حس کلمه\u200cهای انگلیسی، مانند پلیسمی و همونی است. ما اطلاعات را از یک آزمایش رفتاری، بنیاد وب جمع می\u200cکنیم، در آن شرکت\u200cکنندگان تصمیم\u200cگیری از ارتباط حس چندین WordNet از یک کلمه در یک کار مرتبط فضایی دو بعدی می\u200cدهند. ما فهمیدیم که قضاوت مشترکین رابطه بین احساسات با فاصله بین احساسات در فضای پیدا کردن BERT ارتباط دارند. به طور خاصی، حس های همنامی (مثلاً چوب به عنوان چوب به عنوان دستگاه ورزشی) به طور قابل اطمینان از یکدیگر در فضای پیدا کردن بیشتری از آن\u200cها (مثلا مرغ به عنوان حیوانات vs. مرغ به عنوان گوشت) دور می\u200cشوند. نتیجه\u200cهامون به سوی استفاده\u200cی پتانسیل\u200cهای نمایش\u200cهای فضای دائمی معنی\u200cهای حس نشان می\u200cدهند.', 'sw': "Kuelewa mabadiliko yanayotegemea mazingira katika maana ya neno ni upande muhimu wa ufahamu wa lugha ya binadamu unaomuungwa na lexico. rasilimali za Kilexico (kwa mfano, WordNet) zinachukua mabadiliko haya yanayotegemea; Kwa mfano, mara nyingi huwa hawana taarifa za karibu, au maana ya maneno yanayoeleweka, yanahusiana na wao kwa wao. Kazi yetu inachunguza kama maendeleo ya hivi karibuni katika NLP, hususani neno lililotengenezwa na utangazaji, kushika tofauti kama binadamu kati ya hisia za Kiingereza, kama vile misoloni na ushoga. Tunakusanya taarifa kutoka kwenye jaribio la tabia, lililoko mtandaoni, ambapo washiriki wanatoa hukumu za kuhusiana na hisia mbalimbali za WordNet za neno katika kazi ya mpango wa anga mbili. We find that participants' judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space.  Bila shaka, hisia za mashoga (kwa mfano, bati ya Mama na mabwawa kama vifaa vya michezo) ni mbali sana na moja kwa moja katika anga la upepo kuliko zile za kijinsia (kwa mfano, chicken kama mnyama na kama chickeni kama nyama). Matokeo yetu yanaelekeza matumizi ya uwakilishi wa anga endelevu wa maana ya maana.", 'tr': "Bir kontekst baglanyşykdan söz anlamlyklarynyň a ňsatly üýtgeşişini düşürmekdir. Leksikografik çe şmeler (meselâ, WordNet) diňe bu kontekst baglanyşygynyň käbirlerini g özükýär; Mesela, olar köplenç nähili ýakyn duýgunlary ýa-da diskrimizli söz anlamlyklary bir-birine golaýlaşýarlar. Biziň işimiz NLP'de ýakyn öňki gelişmeleri diňleýär. Özellikle diňleşen sözlerimiz, Iňlisçe söz duýgularyň arasyndaky tapawutlaryny çykarýar. Biz internet tabanly bir deneyden berilýän maglumatlary çykarýarys. Şahtyşanlar iki boyutlu uzay düzenleme zadynda bir söz duýdurmanyň barlagyny çykarýarlar. Biz duýgular arasyndaky aýratyşlyklaryň barlagynyň barlagynyň BERT baglanyşygynda duýgular arasyndaky uzaklar bilen meňzeşligi bar diýip pikir edýäris. Adatça, homonym duýgular (meselâ, süýji we süýji ýaly sport enjamlary) polisemlerden daşary ýerlerinde (meselâ, tavuk we tavuk ýaly eti ýaly) g üýçli bolup dur. Tapılarımız mantıklı anlama ifadelerinin sürekli uzay ifadelerinin mümkün kullanımına yönlendiriyor.", 'am': 'context-dependent variation in word meaning is a key aspect of human language compression by the Lexicon. Lexicographic resources (e.g., WordNet) capture only some of this context-dependent variation;  ለምሳሌ፣ ብዙ ጊዜ እውቀት ወይም የብልሃት ቃላት እርስ በርሳቸው ተያያያይተዋል፡፡ ሥራችን አዲስ የNLP ቅድሚያ ግንኙነት፣ በተለየ የግልፅ ቃላት እና የፖሊስቲም እና ኮሞኒያ የሚመስል የኢንጂልኛ ቃላት የሚመስል ትርሕተት እንዲያዛቸው ይጠይቃል፡፡ በሁለት ምናልባዊ ስፍራዊ ተግባር ውስጥ የቃላትን የብዙዎች የቃላት ነጥብ ስብሰባዎችን የሚያስብ ፍርድ እናስቀድዳለን፡፡ የአጋሪዎች ፍርድ በሲሳዊው መካከል ግንኙነት በBERT ውስጥ በመግባት ስሜት መካከል ርቀት እንዳለው እናገኛለን፡፡ በተለይም፣ የሞግዚ እውቀት (ምሳሌ አሞራዊ እና የጨዋታ ዕቃዎች መሆኑን የቦት ባትን) በተመሳሳይ ከፖሊሳም ማዕቃዎች ይልቅ እርስ በርሳቸው ይራቃሉ (ምሳሌ የእንስሳ ማህረግ እንደ ሥጋ) ነው፡፡ ፍጥረታችን የዘወትር የሰማይ ስፋት ማህበረሰብ ማድረግ ነው፡፡', 'af': "Verstaan van konteksafhangende veranderinge in woord betekening is 'n sleutel aspekt van menslike taal verstaan wat deur die lexicon ondersteun word. Leksikografiese hulpbronne (bv. WordNet) neem slegs sommige van hierdie konteksafhanklike veranderinge in te vang; byvoorbeeld, hulle dikwels kodeer nie hoe naby senses of diskreteerde woord betekenings, is verwante aan mekaar nie. Ons werk ondersoek of onlangse vorderings in NLP, spesifieke contextualiseerde woord inbêding, menslike verskillinge tussen Engelske woord senses, soos polisemie en homonimie. Ons versamel data van 'n gedrag, web-gebaseerde eksperiment, waarin deelnaders oordelings van die verwantigheid van veelvuldige WordNet senses van 'n woord in 'n twee-dimensjonale spasielle arrangering taak verskaf word. Ons vind dat deelnaders se oordelings van die verwantigheid tussen senses is korrelasieer met afstande tussen senses in die BERT inbeter ruimte. Spesifieke, homonymous senses (bv. gebruik as mammal vs. bat as sport toepassing) is vertroulik meer afstand van mekaar in die inbêderspasie as polisemus (bv. skoonkie as dier vs. skoonkie as vleis). Ons vindings wys teen die potensieele nutsprogram van voortdurende spasie verteenwoordings van sens betekening.", 'sq': 'Përkuptimi i variacionit të varur nga konteksti në kuptimet e fjalës është një aspekt kyç i kuptimit të gjuhës njerëzore mbështetur nga lexikoni. Burimet lexikografike (për shembull WordNet) kapin vetëm disa nga këto variacione të varura nga konteksti; Për shembull, ata shpesh nuk kodojnë se sa të ngushta ndjenjat, ose kuptimet e fjalës të diskretizuara, janë të lidhura me njëri-tjetrin. Puna jonë heton nëse përparimet e fundit në NLP, veçanërisht përmbajtjet e fjalëve të kontekstualizuara, kapin dallime njerëzore midis ndjenjave të fjalëve angleze, të tilla si polizimi dhe homonimia. Ne mbledhim të dhëna nga një eksperiment sjelljeje, me bazë në internet, në të cilin pjesëmarrësit japin gjykime të lidhjes së ndjenjave WordNet të shumta të një fjale në një detyrë dy-dimensionale të rregullimit hapësiror. Ne zbulojmë se gjykimet e pjesëmarrësve për lidhjen midis ndjenjave janë të lidhura me distancat midis ndjenjave në hapësirën e përfshirjes BERT. Veçanërisht, ndjenjat homonimike (për shembull, shkopin si gjimnaz vs. shkopin si pajisje sportive) janë me siguri më të largëta nga njëri-tjetri në hapësirën e përfshirjes sesa ato polisemore (për shembull, pulën si kafshë vs. pulën si mish). Our findings point towards the potential utility of continuous-space representations of sense meanings.', 'az': "Söz anlayışlarında bağlı dəyişiklikləri anlamaq insan dilinin dəyişiklik aspektidir. Lexicographic resources (e.g. WordNet) yalnız bu məlumat bağlı dəyişikliklərinin bəzisini yakalayır; Misal olaraq, onlar çox yaxın duyguları və ya müfəssəl sözlərin anlamını bir-birinə bağlı olmaqla kodlamazlar. Bizim işimiz NLP'də yeni gəlib gəlib, özlərinə müəyyən edilmiş sözləri, İngilizə söz duyguları arasındakı insanlar kimi fərqlənmələri, polizimi və homonimi kimi. Biz Davranışlıq və İnternet təcrübəsindən verilən məlumatları toplayırıq. İkisində də iştirakçilər, iki ölçülük uzay düzenleme işində bir söz hisslərinin bağlılığını təsdiqləyirlər. Biz də hisslərin arasındakı bağlılıq barəsindəki hökmünün BERT içərisində hisslərin arasındakı uzaqları ilə bağlıdır. Özellikle, homonym hissləri (həmçin in sütük-sütük kimi sütük-sütük kimi sport vasitələri) bir-birindən çoxlu hisslərdən daha uzaqlaşdırılmışdır. Bizim tapındıqlarımız həmişəlik uzay ifadələrinin istifadəsinə yönəldir.", 'bn': 'লেক্সিকোর দ্বারা সমর্থিত মানুষের ভাষা সম্পূর্ণ ভিন্ন ভিন্ন ভিন্ন বুঝতে পারে। লেক্সিকোগ্রাফিক সম্পদ (উদাহরণস্বরূপ ওয়ার্ডনেট) শুধুমাত্র এই প্রেক্ষিত-নির্ভরিত বিভিন্ন ভিন্ন ভিন্নে উদাহরণস্বরূপ, তারা প্রায়শ কতটা কাছাকাছি অনুভূতি বা বৈষম্যিক শব্দের মানে একে অপরের সাথে সম্পর্ক নেই। আমাদের কাজ অনুসন্ধান করছে এনএলপিতে সাম্প্রতিক অগ্রগতি কিনা, বিশেষ করে প্রতিযোগিতা শব্দের বিরুদ্ধে প্রতিযোগিতা করা হয়েছে, ইংরেজি শব্দের মধ আমরা একটি ওয়েব ভিত্তিক পরীক্ষা থেকে তথ্য সংগ্রহ করি, যেখানে অংশগ্রহণকারীরা দুই ধরনের স্পেশিয়াল সংগঠনের কাজে একটি শব্দের বিচারের বিচার দেয়। আমরা দেখতে পাচ্ছি যে অংশগ্রহণকারীদের বিচার বিভিন্ন সেন্সের সম্পর্কের সংশ্লিষ্ট দূরত্বের সাথে যুক্ত। বিশেষ করে, সমকামীদের অনুভূতি (যেমন মস্তিষ্কের যন্ত্র হিসেবে ব্যাটর হিসেবে ব্যাট) একে অপরের কাছ থেকে বেশি দূরে থাকে (যেমন মাংস হিসেবে মুরগির মাংস হিসেবে মুরগির মাং আমাদের আবিস্কারের উদ্দেশ্য হচ্ছে যে বুদ্ধিমান অর্থের সম্ভাব্য স্পেসের প্রতিনিধিদের ব্যবহারের প্', 'hy': 'Բառերի իմաստության կոնտեքստից կախված տարբերությունների հասկանալը մարդկային լեզվի հասկացության կարևոր ասպեկտը, որը աջակցում է լեքսիկոնի կողմից: Լեքսիկոգրաֆիկ ռեսուրսները (օրինակ WordNet) ընդունում են միայն այս կոնտեքստից կախված տարբերակները: Օրինակ, նրանք հաճախ չեն կոդավորում, թե ինչքան մոտ են զգացմունքները կամ անհստակ բառի իմաստները կապված միմյանց հետ: Մեր աշխատանքը հետազոտում է, թե արդյոք ՆԼՊ-ի վերջին զարգացումները, հատկապես կոնտեքստոլիզացված բառերի ներդրումները, վերցնում են մարդկային նման տարբերություններ անգլերեն բառերի զգացմունքների միջև, ինչպիսիք են պոլիզեմիան և Մենք հավաքում ենք տվյալներ վարքագծային, վեբ-հիմնված փորձարկումից, որտեղ մասնակիցները որոշում են WordNet բազմաթիվ զգացմունքների կապը երկչափ տարածական կառուցվածքի գործում: Մենք հայտնաբերում ենք, որ մասնակիցների դատողությունները զգացմունքների միջև կապված են զգացմունքների միջև գտնվող տարածության BER-ի զգացմունքների հետ: Մասնավորապես, համանույն զգացմունքները (օրինակ, կաթնասունների կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կողմնակի կո Մեր հայտնաբերությունները ցույց են տալիս զգայական իմաստների շարունակական տիեզերական ներկայացումների պոտենցիալ օգտակարությունը:', 'cs': 'Pochopení kontextově závislé variace slovních významů je klíčovým aspektem porozumění lidskému jazyku podporovaným slovníkem. Lexikografické zdroje (např. WordNet) zachycují pouze některé z těchto kontextově závislých variací; Například často nekódují, jak blízko smysly, nebo diskretizované slovní významy, jsou vzájemně vzájemně vztahovány. Naše práce zkoumá, zda nedávné pokroky v NLP, konkrétně kontextualizované vkládání slov, zachycují rozdíly mezi anglickými slovními smysly, jako je polysemie a homonymie. Shromažďujeme data z behaviorálního, webového experimentu, ve kterém účastníci poskytují posouzení souvislosti více WordNet smyslů slova v dvourozměrném prostorovém uspořádání úlohy. Zjišťujeme, že úsudky účastníků souvislosti mezi smysly jsou korelovány s vzdálenostmi mezi smysly v BERT vkládajícím prostoru. Konkrétně stejnojmenné smysly (např. netopýr jako savec vs netopýr jako sportovní vybavení) jsou od sebe spolehlivě vzdálenější v prostoru vkládání než polyemozní (např. kuře jako zvíře vs kuře jako maso). Naše poznatky ukazují na potenciální užitečnost kontinuálních prostorových reprezentací smyslových významů.', 'bs': 'Razumijevanje kontekstskih varijacija u značenju riječi je ključni aspekt razumijevanja ljudskog jezika koji podržava leksikon. Leksiografske resurse (npr. WordNet) uhvate samo neke od tih varijacija ovisnih o kontekstu; Na primjer, oni često ne kodiraju koliko su bliski osjećaji ili diskretno značenje riječi povezani jedni sa drugima. Naš rad istražuje je li nedavni napredak u NLP-u, posebno kontekstualizirani integraciji riječi, uhvatiti ljudske razlike između čula engleskih riječi, poput polizemije i homonimije. Skupljamo podatke iz ponašanja, web-baziranog eksperimenta, u kojem sudionici pružaju osude o povezanosti višestrukih osjećaja WordNet-a riječi u zadatku o dvodimenzionalnom prostornom organizaciji. Nalazimo da su sudionici osuđenja veze između čula povezani sa udaljenostima između čula u prostoru u BERT-u. Posebno, homonimski osjećaji (npr. šišmiš kao sisar protiv šišmiša kao sportska oprema) vjerojatno su daleko od jedne od druge u ugrađenom prostoru od polizemnih (npr. piletina kao životinja protiv piletina kao meso). Naši nalazi upućuju na potencijalnu korisnost stalnog prostora predstavljanja smisla.', 'et': 'Sõna tähenduste kontekstist sõltuva variatsiooni mõistmine on sõnavara toetatava inimkeele mõistmise võtmeaspekt. Lexikograafilised ressursid (nt WordNet) hõlmavad ainult osa sellest kontekstist sõltuvast variatsioonist; Näiteks sageli ei kodeeri nad, kui tihedalt meeled või diskreetsed sõna tähendused on omavahel seotud. Meie töö uurib, kas hiljutised edusammud NLP-s, konkreetselt kontekstiliseeritud sõnade manustamisel, põhjustavad inimlikke eristusi inglise keele sõnade meelte vahel, nagu polüseemia ja homonüümia. Kogume andmeid käitumuslikust veebipõhisest eksperimendist, kus osalejad annavad hinnanguid sõna mitme WordNeti meele seose kohta kahemõõtmelises ruumilises paigutusülesandes. Leiame, et osalejate hinnangud meeltevahelise seose kohta on korrelatsioonis meeltevahelise kaugusega BERT-ruumis. Täpsemalt on homonüümsed meeled (nt nahkhiir kui imetaja vs nahkhiir kui spordivarustus) üksteisest usaldusväärsemad kui polüseemsed meeled (nt kana kui loom vs kana kui liha). Meie tulemused viitavad tähenduste pideva ruumi representatsioonide potentsiaalsele kasulikkusele.', 'fi': 'Sanamerkitysten kontekstista riippuvan vaihtelun ymmärtäminen on keskeinen osa sanaston tukemaa ihmisen kielen ymmärtämistä. Lexikografiset resurssit (esim. WordNet) sisältävät vain osan tästä kontekstista riippuvasta vaihtelusta. Ne eivät esimerkiksi usein koodaa, kuinka läheisesti aistit tai diskreettiset sanamerkitykset liittyvät toisiinsa. Työssämme tutkitaan, onko NLP:n viimeaikainen kehitys, erityisesti kontekstualisoitu sanaupotus, havainnut ihmisen kaltaisia eroja englanninkielisten sanaaistien, kuten polysemian ja homonyymin välillä. Keräämme dataa käyttäytymiseen perustuvasta, web-pohjaisesta kokeilusta, jossa osallistujat antavat arvioita sanan useiden WordNet-aistien suhteesta kaksiulotteisessa paikkatietojärjestelytehtävässä. Havaitsemme, että osallistujien arviot aistien välisestä suhteesta korreloivat aistien välisiin etäisyyksiin BERT:n sulautumistilassa. Tarkemmin sanottuna homonyymit aistit (esim. lepakko nisäkkänä vs. lepakko urheiluvälineinä) ovat luotettavasti etäisempiä toisistaan sulautumistilassa kuin polyemoiset aistit (esim. kana eläimenä vs. kana lihana). Löydöksemme viittaavat aistimerkitysten jatkuvan tilan representaatioiden potentiaaliseen hyödyllisyyteen.', 'ca': "Entendre la variació del contexte en els significats de paraules és un aspecte clau de la comprensió del llenguatge humà sostenida pel lexicó. Els recursos lexicògrafs (per exemple WordNet) només capturen algunes d'aquestes variacions dependents del context; per exemple, sovint no codifiquen com de estrets són els sentits, o significats discrets de paraules, relacionats entre ells. La nostra feina investiga si els avanços recents en NLP, específicament contextualitzats incorporacions de paraules, capturan distincions com a humans entre sentits anglesos de paraules, com la polissima i l'homonima. Recollim dades d'un experiment comportamental, basat en la Web, en el qual els participants proporcionen judicis sobre la relació de múltiples sentits WordNet d'una paraula en una tasca d'arreglo espacial bidimensional. Trobem que els judicis dels participants sobre la relació entre els sentits estan correlacionats amb les distàncies entre els sentits a l'espai d'incorporació BERT. Concretament, els sentits homonimós (per exemple, el morceg com mamífer vs. el morceg com equipament esportiu) són fiablement més llunyans dels altres a l'espai d'incorporació que els polisemòs (per exemple, el pollastre com animal vs. el pollastre com carn). Els nostres descobriments apunten cap a l'utilitat potencial de representacions espacials contínues de sentits.", 'jv': 'Tulung Laptop" and "Desktop Ballok, wong liya kuwi ora kodeng pisan seneng kapan pangan, lan kelangan kelangan kelangan kelangan, lan kelangan langgar sampeyan. Awakdhéwé éntuk perbudhakan yakuné kapan kelas telas nang NLP, ngomong kontinuksi barêng, gambaran-gambar uwong. Awak dhéwé ngregani data sak barêng-barêng, kawula-barêng langgambar web, sing wis nguasai khititi supoyo nggawe geraksi kanggo kalagayaan karo Multi Word net senes sing berarti awak dhéwé kuwi tindakan arep sing berarti. Awak dhéwé éntuk perusahaan nggawe barang kelas pirsak meluran luwih dumateng seneng nggawe barang terusan Seneng barang BERT. ngomong Ndheke awakdhéwé kuwi nggawe mesthi apakno kanggo lagi mesthi nang kana luwih dumateng sing dikarepaké.', 'he': 'להבין שינוי תלוי בקשר במשמעות מילים הוא היבט המרכזי של הבנה של שפת האנושית שמתומך על ידי הלקסיקון. משאבים לקסיקוגרפיים (למשל WordNet) שולטים רק חלק מהשינוי הזה תלוי בקשר; לדוגמה, הם לעתים קרובות לא קודים עד כמה חושים קרובים, או משמעות מילים דיסקרטיות, קשורים אחד לשני. העבודה שלנו חוקרת אם התקדמות האחרונות ב-NLP, במיוחד תוכניות מילים קונטוקטוליזציה, לכדות הבדלים כמו בני אדם בין חושים מילים אנגליים, כמו פוליזמיה וההומונימיה. אנו אוספים נתונים מניסוי התנהגות, מבוסס באינטרנט, שבה השתתפים מספקים שיפוטים על הקשר של חושים WordNet מרובים של מילה במשימת ארגון חלל שתי מימדי. אנחנו מוצאים ששיפוטים של השתתפים על הקשר בין החושים קשורים למרחקים בין החושים בחלל ההכניסה של BERT. במיוחד, חושים הומונימיים (למשל מחבט כיונק נגד מחבט כציוד ספורט) מרוחקים אחד מהשני באופן אמין יותר בחלל ההכניסה מאשר חושים פוליזמיים (למשל עוף כחיה נגד עוף כבשר). הממצאים שלנו מצביעים לכיוון השימוש הפוטנציאלי של מייצגים חלליים ממשיכים של משמעות הגיונית.', 'sk': 'Razumevanje od konteksta odvisnih variacij besednih pomenov je ključni vidik razumevanja človeškega jezika, ki ga podpira leksikon. leksikografski viri (npr. WordNet) zajemajo le del te različice, odvisne od konteksta; Na primer, pogosto ne kodirajo, kako tesno so čutila ali diskretizirani besedni pomeni med seboj povezani. Naše delo raziskuje, ali nedavni napredek v NLP, posebej kontekstualiziranih besednih vdelavah, ujame človeku podobne razlike med angleškimi besednimi čuti, kot sta polisemija in homonimija. Zbiramo podatke iz vedenjskega, spletnega eksperimenta, v katerem udeleženci podajo presojo povezanosti več WordNet čutov besede v dvodimenzionalni prostorski ureditvi naloge. Ugotavljamo, da so presoje udeležencev o povezanosti med čuti povezane z razdaljami med čuti v prostoru BERT. Natančneje, istoimenska čutila (npr. netopir kot sesalec v primerjavi s netopirjem kot športna oprema) so zanesljivo bolj oddaljena drug od drugega v vgradnem prostoru kot poličemska (npr. piščanec kot žival v primerjavi s piščancem kot meso). Naša ugotovitev kažejo na potencialno uporabnost kontinuiranih prostorskih reprezentacij čutnih pomenov.', 'ha': "An fahimta context-deposite variant cikin magana, yana da ma'anar magana, yana da kiman aspects of language Compression na ƙarfafa da lekson. KCharselect unicode block name Misali, ko da yawa bã su kodi da jinsi sanyin nan makusanta ko maganar da aka ƙãga ƙarya, sãshensu yana danganta zuwa ga sãshe. Kayan aikinMu yana tambaya ko da za'a iya ƙara da za'a cikin NLP, mai ƙayyade maganar da aka shigar da shi, sai ka kãma diffukan mutane da misãlin maganar Ingiriya, kamar misãlin Polsemi da gayoli. Tuna sama data daga jarrabar aikin ƙwarai da aka baka web, a cikinsa mãsu shirin da ke samar da hukuncin masu husũma na masu husũma da masu yawa na danganta wa masu maganar WdNet na cikin wani aikin na takwara guda biyu. Muna gane cewa rabin mãsu haɗuwa da masu husũma a tsakanin sano sun yi danganta da nĩsa tsakanin sanyin da ke shiga filin BERT. A ƙayyade, zafi masu samofi (misali, batar da aka samu ga mutane kamar shirin jimci) sune mafi nĩsa daga ɗayansu a cikin filin mai fitarwa ko misali, kyakko ko kifi kamar raɗari. FantayinMu na pointe zuwa ga matuƙar na amfani da misalin filinaikin da ke daidai a cikin muhimmada na mantani.", 'bo': 'གསལ་བརྗོད་དང་ཁྱད་པར་རྟོགས་དང་མཉམ་དུ་རྟེན་པའི་འགྱུར་བ་དེ་ནི་མིའི་སྐད་རིགས་ཀྱི་གཙོ་ཆོག Lexicographic resources (e.g. WordNet)capture only some of this context-dependent variation; དཔེར་ན། ཁོང་ཚོས་ཀྱིས་ཇི་ལྟར་རང་ཉིད་ཀྱི་དོན་དག་གསལ་བཤད་མེད། ཡང་ན་ཕྱོགས་པའི་ཐ་སྙད་ཅིག་གསལ་བྱས་བའི་ཚོར ང་ཚོའི་ལས་ཀ་ལྟའི་ནང་དུ་NLP ནང་གི་འཕེལ་རིམ་དང་ཁྱད་པར་གསལ་བཤད་ཀྱི་ཐ་སྙད་ཅིག་རྟོགས། ང་ཚོས་བྱ་ཚིག་དང་བརྩོན་བྱས་པའི་བརྟག་ཞིག་གིས་གསལ་བཤད་པ་ཞིག་གིས། ཞུགས་སྐྱེལ་པའི་ནང་དུ་ཚོགས་ཆེན་དག་གི་སྐྱེས་ཆེན་དུ་མང་ཆོས་ཡོད་པའ ང་ཚོས་ཆེད་ཚོའི་དབར་གྱི་མཐུན་རྐྱེན་ཐད་ཀར་བ་དང་མཐུན་རྐྱེན་བྱས་ཡོད་པ་ལྟར། ཁྱད་པར་ལྡན་དགོས་པ་དེ་ཆོས་ཉིད་གཉིས་ལས་དབང་ཆ་སྤྱི་ཁྱད་པར་བྱུང་། ང་ཚོའི་རྙེད་ཚུལ་གྱིས་རྒྱུན་རིང་གི་དོན་དག་གང་དུ་ཡོད་པའི་སྤྱོད་སྟངས་མངོན་གསལ་བཤད་ཀྱི་ཡོད།'}
