{'en': 'Constructing a Bilingual Corpus of Parallel Tweets', 'ar': 'إنشاء مجموعة ثنائية اللغة من التغريدات الموازية', 'pt': 'Construindo um Corpus Bilíngue de Tweets Paralelos', 'es': 'Construir un corpus bilingüe de tuits paralelos', 'zh': '构并行推文之双语语料库', 'fr': 'Construire un corpus bilingue de tweets parallèles', 'ja': '並列ツイートのバイリンガルコーパスの作成', 'hi': 'समानांतर Tweets के एक द्विभाषी कॉर्पस का निर्माण', 'ga': 'Corpas Dátheangach de Thvuíteanna Comhthreomhara a Thógáil', 'ru': 'Построение двуязычного корпуса параллельных твитов', 'el': 'Κατασκευή ενός δίγλωσσου σώματος παράλληλων tweets', 'ka': 'Name', 'it': 'Costruire un corpus bilingue di tweet paralleli', 'lt': 'Dvikalbio lygiagrečių tweetų korpuso kūrimas', 'kk': 'Параллельді тавиттердің екі бұрышты құру', 'hu': 'Párhuzamos tweetekből álló kétnyelvű korpusz építése', 'ms': 'Membina Korpus Bilingual dari Tweet Paralel', 'mk': 'Constructing a Bilingual Corpus of Parallel Tweets', 'mt': 'Il-bini ta’ Korp Bilingwu ta’ Tweets Paraleli', 'mn': 'Дөрвөн биетийн хоёр давхар биетүүдийг бүтээх', 'ro': 'Construirea unui corpus bilingv de tweets paralele', 'pl': 'Budowanie dwujęzycznego korpusu równoległych tweetów', 'ml': 'ഒരു ബിലിങ്കുള്ള കോര്\u200dപ്പുസ് ഉണ്ടാക്കുക', 'sr': 'Izgradnja Bilingualnog korpusa Paralelnih Tweets-a', 'no': 'Konstruer eit bilete korpus av parallelle tweeter', 'sv': 'Att bygga en tvåspråkig korpus av parallella tweets', 'so': 'Construction a Bilingual Corpus of Parallel Tweets', 'ta': 'Parallel Tweets ஒரு பில்லிங் கார்ப்ஸ் கட்டமைப்பு', 'si': 'බිලින්ගුල් කෝර්පුස් හදන්න', 'ur': 'پارالی ٹیوٹ کے ایک دوسری کورپوس بنا رہا ہے', 'vi': 'Xây dựng một gò ma song song song', 'uz': 'Name', 'bg': 'Изграждане на двуезичен корпус от паралелни туитове', 'da': 'Konstruktion af et tosproget korpus af parallelle tweets', 'hr': 'Izgradnja Bilingualnog korpusa Paralelnih Tweets-a', 'nl': 'Het bouwen van een tweetalig korpus van parallelle tweets', 'de': 'Aufbau eines zweisprachigen Korpuss paralleler Tweets', 'id': 'Membangun Korpus Bilingual dari Tweets Paralel', 'ko': '이중 언어 평행 추문 자료 라이브러리 구축', 'sw': 'Kujenga Korpus ya Kiingereza ya Twita za Parallel', 'fa': 'ساختن یک کورپوس دوگانی از Tweets Parallel', 'af': "Konstrueer 'n Bilinguele Korpus van Parallele Tweets", 'sq': 'Ndërtimi i një korpusi dygjuhës të tweeteve paralele', 'am': 'የፓርላል ትዊተሮች የቢልቋንቋ ኮርፓስ መሠረት', 'tr': "Parallel Tweets'in ikinji köpüsi inşa et", 'hy': 'Constructing a Bilingual Corpus of Parallel Tweets', 'bn': 'প্যারালেল টুইটের একটি বিলিঙ্গুয়াল কোর্পাস আঁকা হচ্ছে', 'bs': 'Izgradavanje Bilingualnog korpusa Paralelnih Tweets-a', 'cs': 'Vytvoření dvojjazyčného korpusu paralelních tweetů', 'ca': 'Construir un cos bilingüe de tweets parallels', 'fi': 'Kaksikielisen rinnakkaistwiittikorpusen rakentaminen', 'et': 'Paralleelsete tweetide kahekeelse korpuse loomine', 'az': "Parallel Tweets'in İkinci Körpüsü inşaat", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Ustvarjanje dvojezičnega korpusa vzporednih tweetov', 'ha': 'KCharselect unicode block name', 'he': 'בניית גוף משולש של טוויטים Parallel', 'bo': 'གཟུགས་རིས་ཀྱི་ཟུར་བ་ཐལ་གྱི་རྩིས་འཁོར་ཞིག་བཟོ་བྱེད་པ'}
{'en': 'In a bid to reach a larger and more diverse audience, Twitter users often post parallel tweetstweets that contain the same content but are written in different languages. Parallel tweets can be an important resource for developing machine translation (MT) systems among other natural language processing (NLP) tasks. In this paper, we introduce a generic method for collecting parallel tweets. Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu. Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets. This latter information can also be useful for author profiling tasks.', 'fr': "Dans le but de toucher une audience plus large et plus diversifiée, les utilisateurs de Twitter publient souvent des tweets parallèles, c'est-à-dire des tweets qui contiennent le même contenu mais sont rédigés dans des langues différentes. Les tweets parallèles peuvent être une ressource importante pour développer des systèmes de traduction automatique (TA) parmi d'autres tâches de traitement du langage naturel (NLP). Dans cet article, nous présentons une méthode générique de collecte de tweets parallèles. Grâce à cette méthode, nous collectons un corpus bilingue de tweets parallèles anglais-arabe et une liste de comptes Twitter qui publient régulièrement des tweets anglais-arabe. Comme notre méthode est générique, elle peut également être utilisée pour collecter des tweets parallèles qui couvrent des langues moins riches comme le serbe et l'ourdou. De plus, nous annotons un sous-ensemble de comptes Twitter avec leur pays d'origine et leur sujet d'intérêt, ce qui fournit des informations sur la population qui publie des tweets parallèles. Ces dernières informations peuvent également être utiles pour les tâches de profilage des auteurs.", 'pt': 'Em uma tentativa de alcançar um público maior e mais diversificado, os usuários do Twitter costumam postar tweets paralelos – tweets que contêm o mesmo conteúdo, mas são escritos em idiomas diferentes. Os tweets paralelos podem ser um recurso importante para o desenvolvimento de sistemas de tradução automática (MT) entre outras tarefas de processamento de linguagem natural (NLP). Neste artigo, apresentamos um método genérico para coletar tweets paralelos. Usando esse método, coletamos um corpus bilíngue de tweets paralelos inglês-árabe e uma lista de contas do Twitter que postam tweets inglês-árabe regularmente. Como nosso método é genérico, ele também pode ser usado para coletar tweets paralelos que cobrem idiomas com menos recursos, como sérvio e urdu. Além disso, anotamos um subconjunto de contas do Twitter com seus países de origem e tópicos de interesse, o que fornece informações sobre a população que publica tweets paralelos. Esta última informação também pode ser útil para tarefas de criação de perfil de autor.', 'ar': 'في محاولة للوصول إلى جمهور أكبر وأكثر تنوعًا ، غالبًا ما ينشر مستخدمو Twitter تغريدات موازية - تغريدات تحتوي على نفس المحتوى ولكنها مكتوبة بلغات مختلفة. يمكن أن تكون التغريدات الموازية مصدرًا مهمًا لتطوير أنظمة الترجمة الآلية (MT) من بين مهام معالجة اللغة الطبيعية (NLP) الأخرى. في هذا البحث ، نقدم طريقة عامة لجمع التغريدات الموازية. باستخدام هذه الطريقة ، نقوم بجمع مجموعة ثنائية اللغة من التغريدات الموازية باللغتين الإنجليزية والعربية وقائمة بحسابات تويتر التي تنشر التغريدات الإنجليزية والعربية بانتظام. نظرًا لأن طريقتنا عامة ، فيمكن استخدامها أيضًا في جمع التغريدات الموازية التي تغطي لغات قليلة الموارد مثل الصربية والأردية. بالإضافة إلى ذلك ، قمنا بتعليق مجموعة فرعية من حسابات Twitter مع بلدانهم الأصلية وموضوع الاهتمام ، مما يوفر رؤى حول السكان الذين ينشرون تغريدات موازية. يمكن أن تكون هذه المعلومات الأخيرة مفيدة أيضًا لمهام تحديد ملفات تعريف المؤلف.', 'es': 'En un intento por llegar a una audiencia más amplia y diversa, los usuarios de Twitter suelen publicar tuits paralelos, es decir, tuits que contienen el mismo contenido pero están escritos en diferentes idiomas. Los tuits paralelos pueden ser un recurso importante para desarrollar sistemas de traducción automática (MT), entre otras tareas de procesamiento del lenguaje natural (NLP). En este artículo, presentamos un método genérico para recopilar tuits paralelos. Con este método, recopilamos un corpus bilingüe de tuits paralelos en inglés y árabe y una lista de cuentas de Twitter que publican tuits en inglés y árabe con regularidad. Dado que nuestro método es genérico, también se puede utilizar para recopilar tuits paralelos que cubran idiomas con menos recursos, como el serbio y el urdu. Además, hacemos anotaciones en un subconjunto de cuentas de Twitter con sus países de origen y temas de interés, lo que proporciona información sobre la población que publica tuits paralelos. Esta última información también puede ser útil para las tareas de creación de perfiles de autor.', 'hi': 'एक बड़े और अधिक विविध दर्शकों तक पहुंचने के लिए, ट्विटर उपयोगकर्ता अक्सर समानांतर ट्वीट्स पोस्ट करते हैं- ट्वीट्स जिसमें एक ही सामग्री होती है लेकिन विभिन्न भाषाओं में लिखी जाती है। समानांतर tweets अन्य प्राकृतिक भाषा प्रसंस्करण (NLP) कार्यों के बीच मशीन अनुवाद (MT) प्रणालियों के विकास के लिए एक महत्वपूर्ण संसाधन हो सकता है। इस पेपर में, हम समानांतर ट्वीट्स एकत्र करने के लिए एक सामान्य विधि पेश करते हैं। इस विधि का उपयोग करते हुए, हम अंग्रेजी-अरबी समानांतर ट्वीट्स का एक द्विभाषी कॉर्पस और ट्विटर खातों की एक सूची एकत्र करते हैं जो नियमित रूप से अंग्रेजी-अरबी ट्वीट्स पोस्ट करते हैं। चूंकि हमारी विधि सामान्य है, इसलिए इसका उपयोग समानांतर ट्वीट्स को इकट्ठा करने के लिए भी किया जा सकता है जो सर्बियाई और उर्दू जैसी कम संसाधन वाली भाषाओं को कवर करते हैं। इसके अतिरिक्त, हम अपने मूल देशों और रुचि के विषय के साथ ट्विटर खातों के एक सबसेट को एनोटेट करते हैं, जो समानांतर ट्वीट्स पोस्ट करने वाली आबादी के बारे में अंतर्दृष्टि प्रदान करता है। यह बाद की जानकारी लेखक प्रोफाइलिंग कार्यों के लिए भी उपयोगी हो सकती है।', 'ru': 'Стремясь охватить более широкую и разнообразную аудиторию, пользователи Twitter часто публикуют параллельные твиты-твиты, которые содержат один и тот же контент, но написаны на разных языках. Параллельные твиты могут быть важным ресурсом для разработки систем машинного перевода (MT) среди других задач обработки естественного языка (NLP). В этой статье мы вводим общий метод для сбора параллельных твитов. Используя этот метод, мы собираем двуязычный корпус параллельных твитов на английском и арабском языках и список аккаунтов в Twitter, которые регулярно публикуют сообщения на английском и арабском языках. Поскольку наш метод является общим, он также может использоваться для сбора параллельных твитов, которые охватывают менее обеспеченные ресурсами языки, такие как сербский и урду. Кроме того, мы аннотируем подмножество аккаунтов Twitter с указанием стран их происхождения и интересующей их тематики, что дает представление о населении, которое публикует параллельные твиты. Эта последняя информация также может быть полезна для задач профилирования автора.', 'ja': 'より多くの多様なオーディエンスにアクセスするために、Twitterユーザーは、同じコンテンツを含むが異なる言語で書かれた並行ツイートを投稿することがよくあります。並行ツイートは、他の自然言語処理（ ＮＬＰ ）タスクの中でも、機械翻訳（ Ｍ Ｔ ）システムを開発するための重要なリソースとなり得る。本稿では、並行ツイートを収集するための一般的な方法を紹介する。この方法を使用して、英語とアラビア語の並行ツイートのバイリンガルコーパスと、英語とアラビア語のツイートを定期的に投稿するTwitterアカウントのリストを収集します。私たちのメソッドは一般的なので、セルビア語やウルドゥー語などのリソースの少ない言語をカバーする並行ツイートの収集にも使用できます。さらに、私たちはTwitterアカウントのサブセットにその出身国と関心のあるトピックをアノテーションし、並行してツイートを投稿している人々についての洞察を提供します。この後者の情報は、著者のプロファイリング作業にも役立ちます。', 'zh': '所以多引更多样化之受众,Twitter 用户常发并行推文,即含同而异言推文也。 并行推文可为开发机器翻译(MT)系统及他自然语言处分(NLP)务之要资。 本文中,言收并行推文通用之法。 用此法,收英语 - 阿拉伯语并行推文双语语料库及期发英语 - 阿拉伯语推文Twitter帐户列表。 吾道通用,故其可以采涵盖少言(塞尔维亚语与乌尔都语)并行推文。 注Twitter帐户子集及原籍国感兴之题,以给平行推文人口之见。 后来一种信息对作者分职也很有用。', 'ga': "D'fhonn teacht ar lucht féachana níos mó agus níos éagsúla, is minic a phostálann úsáideoirí Twitter tweets comhthreomhara - tweets a bhfuil an t-ábhar céanna iontu ach atá scríofa i dteangacha éagsúla. Is féidir le tvuíteanna comhthreomhara a bheith ina acmhainn thábhachtach chun córais aistriúcháin mheaisín (MT) a fhorbairt i measc tascanna próiseála teanga nádúrtha eile (NLP). Sa pháipéar seo, tugaimid isteach modh cineálach chun tweets comhthreomhara a bhailiú. Agus an modh seo á úsáid againn, bailímid corpas dátheangach de thvuíteanna comhthreomhara Béarla-Araibis agus liosta de chuntais Twitter a phostálann Béarla-Araibis go rialta. Toisc gur modh cineálach é ár modh, is féidir é a úsáid freisin chun tweets comhthreomhara a bhailiú a chlúdaíonn teangacha nach bhfuil mórán acmhainní acu ar nós Seirbis agus Urdais. Ina theannta sin, déanaimid anótáil ar fho-thacar de chuntais Twitter lena dtíortha tionscnaimh agus ábhar spéise, a thugann léargas ar an daonra a phostálann tweets comhthreomhara. Féadfaidh an fhaisnéis dheireanach seo a bheith úsáideach freisin le haghaidh tascanna próifílithe údair.", 'ka': 'სხვადასხვა აუდისტურების უფრო დიდი და უფრო განსხვავებული აუდისტურების შესაძლებელად Twitter-ის მომხმარებელი tweets-tweets, რომელიც იგივე შესახებ, მაგრამ განსხვავებული ენებით Name ამ კაურაში ჩვენ დავიყენებთ პერალელური ტივიტების კოლექციის გენერიკური მეტი. ამ მეტის გამოყენებით, ჩვენ ინგლისური-აპაბიური პარალელი ტივიტების ორიენგური კორპუსს და Twitter-ის წიგნის სია, რომელიც ინგლისური-აპაბიკტივიტების რედაქტიურად დავწ ჩვენი მეთოდი ყველაფერი იყო, ეს შეიძლება გამოიყენება პარალელი რვიტების კოლექციისთვის, რომლებიც ცოტა რესურსურსური ენები, როგორც სერბი და სურდი. დამატებით, ჩვენ Twitter-ის წიგნის სესბეტის წიგნის და ინტერესტის მისამართებით, რომელსაც პოლელელი tweets-ის გადატანა მოვლენების შესახებ. ეს შემდეგ ინფორმაცია შეიძლება ასტორის პროფილირებისთვის გამოიყენება.', 'el': 'Σε μια προσπάθεια να προσεγγίσουν ένα μεγαλύτερο και πιο διαφορετικό κοινό, οι χρήστες του Twitter συχνά δημοσιεύουν παράλληλα tweets-tweets που περιέχουν το ίδιο περιεχόμενο αλλά είναι γραμμένα σε διαφορετικές γλώσσες. Τα παράλληλα tweets μπορούν να αποτελέσουν σημαντικό πόρο για την ανάπτυξη συστημάτων μηχανικής μετάφρασης (ΜΤ) μεταξύ άλλων εργασιών επεξεργασίας φυσικής γλώσσας. Σε αυτή την εργασία, εισάγουμε μια γενική μέθοδο για τη συλλογή παράλληλων tweets. Χρησιμοποιώντας αυτή τη μέθοδο, συλλέγουμε ένα δίγλωσσο σώμα από αγγλικά-αραβικά παράλληλα tweets και μια λίστα λογαριασμών που δημοσιεύουν τακτικά αγγλικά-αραβικά tweets. Δεδομένου ότι η μέθοδος μας είναι γενική, μπορεί επίσης να χρησιμοποιηθεί για τη συλλογή παράλληλων tweets που καλύπτουν γλώσσες με λιγότερους πόρους, όπως τα Σερβικά και τα Ουρντού. Επιπλέον, σχολιάζουμε ένα υποσύνολο λογαριασμών με τις χώρες προέλευσης και το θέμα ενδιαφέροντος τους, το οποίο παρέχει πληροφορίες σχετικά με τον πληθυσμό που δημοσιεύει παράλληλα tweets. Αυτές οι τελευταίες πληροφορίες μπορούν επίσης να είναι χρήσιμες για εργασίες κατάρτισης προφίλ συγγραφέα.', 'hu': 'Annak érdekében, hogy nagyobb és sokszínűbb közönséget érjenek el, a Twitter felhasználók gyakran párhuzamos tweeteket tesznek közzé, amelyek ugyanazt a tartalmat tartalmazzák, de különböző nyelveken írják. A párhuzamos tweetek fontos erőforrást jelenthetnek a gépi fordítási (MT) rendszerek fejlesztéséhez, többek között a természetes nyelvfeldolgozási (NLP) feladatok között. Ebben a tanulmányban egy általános módszert mutatunk be a párhuzamos tweetek gyűjtésére. Ezzel a módszerrel összegyűjtjük az angol-arab párhuzamos tweetekből álló kétnyelvű korpuszt, valamint azon Twitter fiókok listáját, akik rendszeresen közzétesznek angol-arabicweeteket. Mivel a módszerünk általános, használható párhuzamos tweetek gyűjtésére is, amelyek kevésbé erőforrásokkal rendelkező nyelveket fednek fel, mint például a szerb és az urdu. Továbbá a Twitter-fiókok egy részhalmazát jegyzeteljük a származási országukkal és az érdeklődési témájukkal, amely betekintést nyújt a párhuzamos tweeteket közvetítő népességről. Ez utóbbi információ a szerzői profilkészítési feladatokhoz is hasznos lehet.', 'it': "Nel tentativo di raggiungere un pubblico più ampio e diversificato, gli utenti di Twitter pubblicano spesso tweet paralleli, tweet che contengono lo stesso contenuto ma sono scritti in lingue diverse. I tweet paralleli possono essere una risorsa importante per lo sviluppo di sistemi di traduzione automatica (MT) tra le altre attività di elaborazione del linguaggio naturale (PNL). In questo articolo introduciamo un metodo generico per raccogliere tweet paralleli. Utilizzando questo metodo, raccogliamo un corpus bilingue di tweet paralleli inglese-arabo e un elenco di account Twitter che pubblicano regolarmente tweet inglese-arabo. Poiché il nostro metodo è generico, può essere utilizzato anche per raccogliere tweet paralleli che coprono lingue meno risorse come il serbo e l'urdu. Inoltre, annotiamo un sottoinsieme di account Twitter con i loro paesi di origine e l'argomento di interesse, che fornisce informazioni sulla popolazione che pubblica tweet paralleli. Queste ultime informazioni possono essere utili anche per attività di profilazione degli autori.", 'kk': 'Үлкен және көп әртүрлі аудиторияға жеткізу үшін Твиттер пайдаланушылары көбінесе бір мазмұны бар, бірақ әртүрлі тілдерде жазылады. Басқа тілдерді өңдеу (NLP) тапсырмаларындағы машинаны аудару (MT) жүйелерінің маңызды ресурсы болуы мүмкін. Бұл қағазда параллелі tweets жинау үшін жалпы әдісін таңдаймыз. Бұл әдістерді қолданып, ағылшын-араб параллелі tweets тізімін және әдетте ағылшын-Араб тізімінің ағылшын тізімінің тізімін жинақтаймыз. Біздің әдіміміз жалпы, сонымен қатар Серб және Урду секілді көп ресурс тілдерін жасайтын параллел tweets жинақтауға қолданылады. Сонымен қатар, біз Твиттер тіркелгілерінің негізгі елдері мен қызықтық нақыштары бойынша түсіндіреміз. Бұл параллел tweets жіберген адамдар туралы түсініктер береді. Бұл соңғы мәлімет автор тапсырмаларын профилдеу үшін пайдалы болады.', 'lt': 'Norėdami pasiekti platesnę ir įvairesnę auditoriją, Twitter vartotojai dažnai skelbia lygiagrečius tweetus, kuriuose yra tas pats turinys, bet kurie rašomi skirtingomis kalbomis. Paraleliniai tweetai gali būti svarbūs ištekliai mašinų vertimo (MT) sistemoms plėtoti, be kitų gamtinių kalbų apdorojimo (NLP) užduočių. Šiame dokumente įvedame bendrą lygiagrečių tweetų rinkimo metodą. Taikant šį metodą renkame dvikalbį anglų ir arabų lygiagrečių tweetų korpusą ir Twitter sąskaitų, kurios reguliariai skelbia anglų ir arabų tweetus, sąrašą. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  Be to, komentuojame Twitter sąskaitų su jų kilmės šalimis ir interesų tema pogrupį, kuriame pateikiama informacija apie gyventojus, kurie skelbia lygiagrečius tweetus. Pastaroji informacija taip pat gali būti naudinga autorių profiliavimo užduotims atlikti.', 'ms': 'Dalam tawaran untuk mencapai penonton yang lebih besar dan berbeza, pengguna Twitter sering mengepost tweet-tweet selari yang mengandungi kandungan yang sama tetapi ditulis dalam bahasa yang berbeza. tweets paralel boleh menjadi sumber penting untuk mengembangkan sistem terjemahan mesin (MT) diantara tugas pemprosesan bahasa semulajadi (NLP). Dalam kertas ini, kami memperkenalkan kaedah generik untuk mengumpulkan tweet selari. Dengan kaedah ini, kami mengumpulkan korpus dua bahasa dari tweet selari bahasa Inggeris-Arab dan senarai akaun Twitter yang mengepost secara biasa. Oleh kerana kaedah kita adalah generik, ia juga boleh digunakan untuk mengumpulkan tweet selari yang meliputi bahasa kurang sumber seperti Serbia dan Urdu. Selain itu, kami menyatakan subset akaun Twitter dengan negara asal dan topik kepentingan mereka, yang menyediakan pandangan mengenai penduduk yang mempos tweet selari. Maklumat terakhir ini juga boleh berguna untuk tugas profil penulis.', 'ml': 'കൂടുതല്\u200d വ്യത്യസ്തമായ ശ്രദ്ധാക്കള്\u200dക്ക് എത്താന്\u200d ഒരു ബോദ്ധ്യത്തില്\u200d, ടൂട്ടര്\u200d ഉപയോക്താക്കള്\u200d പലപ്പോഴും ഒരേ ഉള്ളിലുള്ള ടൂട്ടുകള്\u200d  മറ്റു സ്വാഭാവികമായ ഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനുള്ള (NLP) ജോലികള്\u200dക്കിടയില്\u200d മെഷീന്\u200d പരിഭാഷയുടെ (എംടി) സിസ്റ്റം  ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു സാധാരണമായ രീതിയില്\u200d പരാലിയല്\u200d ടൂട്ടുകള്\u200d ശേഖരിക്കാന്\u200d. ഈ രീതി ഉപയോഗിക്കുന്നത് ഇംഗ്ലീഷ്-അറബി-പാരാള്\u200dലെല്\u200d ടൂട്ടുകളുടെ രണ്ടു ഭാഷ കോര്\u200dപ്പുകള്\u200d കൂട്ടിക്കൊണ്ടുവരുന്നു. ഇംഗ്ല നമ്മുടെ രീതിയില്\u200d സാധാരണമായിരിക്കുന്നത് കൊണ്ട് സെര്\u200dബിയനും ഉര്\u200dദ്ദുവും പോലുള്ള ചെറിയ വിഭവങ്ങള്\u200d സൂക്ഷിക്കുന്നതിനാ അതുകൂടാതെ നമ്മള്\u200d ടൂട്ടര്\u200d അക്കൗണ്ടുകളുടെ അടിസ്ഥാനത്തെയും താല്\u200dപര്യമുള്ള രാജ്യങ്ങളെയും കൂട്ടിയുള്ള വിഷയങ്ങളെയും കൊണ്ട് വിവരിച് This latter information can also be useful for author profiling tasks.', 'mt': 'Fi sforz biex jilħqu udjenza akbar u aktar diversifikata, l-utenti ta’ Twitter spiss jippubblikaw tweets paralleli li fihom l-istess kontenut iżda huma miktuba f’lingwi differenti. Twitters paralleli jistgħu jkunu riżorsa importanti għall-iżvilupp ta’ sistemi ta’ traduzzjoni bil-magna (MT) fost kompiti oħra ta’ pproċessar tal-lingwi naturali (NLP). F’dan id-dokument, a ħna nintroduċu metodu ġeneriku għall-ġbir ta’ tweets paralleli. Bl-użu ta’ dan il-metodu, niġbru korpus bilingwi ta’ tweets paralleli Ingliż-Għarab u list a ta’ kontijiet ta’ Twitter li jippubblikaw l-English-Arabictweets regolarment. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  Barra minn hekk, a ħna nnotaw sottosett ta’ kontijiet ta’ Twitter mal-pajjiżi ta’ oriġini tagħhom u suġġett ta’ interess, li jipprovdi għarfien dwar il-popolazzjoni li tippubblika tweets paralleli. Din l-aħħar informazzjoni tista’ tkun utli wkoll għall-kompiti ta’ profilar tal-awtur.', 'mn': 'Твиттерийн хэрэглэгчид ихэвчлэн адилхан бүтэцтэй, гэхдээ өөр хэл дээр бичигддэг туйтуудыг ихэвчлэн бичдэг. Байгалийн tweets нь машины хөгжлийн (MT) системийг өөр байгалийн хэл процесс (NLP) ажлын хооронд хөгжүүлэх чухал нөөц болох юм. Энэ цаасан дээр бид параллел tweets цуглуулах ерөнхий аргыг тайлбарлаж байна. Энэ аргыг ашиглан бид Англи-Араб параллел tweets болон Англи-Араб хэлний хоёр хэлний корпус цуглуулдаг Твиттерийн хувилбаруудын жагсаалтыг ихэвчлэн англи-Араб хэлний хувилбаруу Бидний арга нь ерөнхий төрлийн учраас энэ нь мөн Серб болон Урду зэрэг бага хүчтэй хэлнүүдийг цуглуулахад ашиглаж болно. Мөн бид Твиттерийн хувилбаруудыг өөрсдийн эх орон болон сонирхолтой сэдэв дээр анзаарлаа хандуулдаг. Энэ нь параллел tweets хийдэг хүмүүсийн тухай ойлголт өгдөг. Энэ сүүлийн мэдээлэл мөн зохиолчдын профилийн ажиллагаанд ашигтай болно.', 'pl': 'Aby dotrzeć do większej i bardziej zróżnicowanej grupy odbiorców, użytkownicy Twittera często publikują równoległe tweety-tweety, które zawierają te same treści, ale są napisane w różnych językach. Równoległe tweety mogą być ważnym źródłem rozwoju systemów tłumaczenia maszynowego (MT) wśród innych zadań przetwarzania języka naturalnego (NLP). W artykule przedstawiamy ogólną metodę zbierania równoległych tweetów. Za pomocą tej metody zbieramy dwujęzyczny korpus angielsko-arabskich równoległych tweetów oraz listę kont Twitter, które regularnie publikują angielsko-arabskie tweety. Ponieważ nasza metoda jest ogólna, może być również wykorzystywana do zbierania równoległych tweetów, które obejmują mniej zasobów języków, takich jak serbski i urdu. Dodatkowo adnotacja podzbioru kont Twittera z ich krajami pochodzenia i tematem zainteresowania, co zapewnia wgląd na populację publikującą równoległe tweety. Te ostatnie informacje mogą być również przydatne do zadań profilowania autorów.', 'no': 'I eit bid for å nå ein større og meir ulike publikum, så Twitter-brukarar ofte sender parallelle tweets-tweets som inneheld det same innhaldet, men er skriven i ulike språk. Parallel tweets kan vera ei viktig ressurs for å utvikla maskinsomsetjingssystemer (MT) blant andre naturspråkshandsamar (NLP) oppgåver. I denne papiret introduserer vi ein generell metode for å samla parallelle tweets. Bruk denne metoden samler vi eit bilinguelt korpus av engelsk-arabiske parallelle tweets og ei liste over Twitter-kontoar som regulært post engelsk-arabisk vekt. Sidan metoden vårt er generelt, kan det også brukast for å samla parallelle tweeter som dekker mindre ressurserte språk som Serbisk og Urdu. I tillegg annoterar vi ein undergruppe av Twitter-kontoar med sine opprinnelege land og temaet med interesse, som gjev innsikt om befolkninga som post parallelle tweeter. Denne siste informasjonen kan også vera nyttig for forfattar oppgåver.', 'ro': 'Într-o încercare de a ajunge la un public mai mare și mai divers, utilizatorii Twitter postează adesea tweet-uri paralele care conțin același conținut, dar sunt scrise în limbi diferite. Tweet-urile paralele pot fi o resursă importantă pentru dezvoltarea sistemelor de traducere automată (MT) printre alte sarcini de procesare a limbajului natural (PNL). În această lucrare, introducem o metodă generică pentru colectarea tweet-urilor paralele. Folosind această metodă, colectăm un corpus bilingv de tweet-uri paralele engleză-arabă și o listă de conturi Twitter care postează în mod regulat tweet-uri engleză-arabictwet. Deoarece metoda noastră este generică, poate fi folosită și pentru colectarea de tweet-uri paralele care acoperă limbi mai puțin resurse precum sârbă și urdu. În plus, adnotăm un subset de conturi Twitter cu țările lor de origine și subiectul de interes, ceea ce oferă informații despre populația care postează tweet-uri paralele. Aceste din urmă informații pot fi utile și pentru activitățile de profilare a autorilor.', 'mk': 'Во обид да постигнат поголема и поразлична публика, корисниците на Твитер честопати објавуваат паралелни Твитери-Твитери кои содржат иста содржина, но се напишани на различни јазици. Паралелните твитови можат да бидат важен ресурс за развој на системите за машински превод (МТ) меѓу другите природни задачи за обработување јазик (НЛП). In this paper, we introduce a generic method for collecting parallel tweets.  Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly.  Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets.  This latter information can also be useful for author profiling tasks.', 'sr': 'U ponudi da dođemo do veće i raznolikosti publike, Twitter korisnici često postavljaju paralelne tweets-tweets koji sadrže isti sadržaj, ali napisani su na različitim jezicima. Paralelni tweets mogu biti važan resurs za razvoj sistema prevoda mašine (MT) među drugim zadacima prirodnog obrade jezika (NLP). U ovom papiru predstavljamo generičnu metodu za skupljanje paralelnih tweeta. Koristeći ovu metodu, skupljamo dvojezički korpus engleskog-arapskog paralelnog tweeta i listu tviterskih računa koji redovno postavljaju engleski-arapski vikt. Budući da je naš metod generičan, može se koristiti i za skupljanje paralelnih tweeta koji pokrivaju manje resursnih jezika poput Srbije i Urde. Osim toga, annotiramo podskup tviterskih računa sa svojim zemljama podrijetla i temom interesa, koja pruža uvide o populaciji koji postavljaju paralelne tweete. Ove poslednje informacije mogu biti korisne i za profiliranje zadataka autora.', 'si': 'වැඩි හා වඩා වෙනස් ප්\u200dරේක්ෂකයෙක් වෙනුවෙන් ප්\u200dරවේශකයෙක් වෙනුවෙන් ප්\u200dරවේශකයෙන්, ට්විටර් ප්\u200dරවේශකයෙන් සාමාන්\u200dය ට සමාන්\u200dය ට්විට්ස් වෙන්න පුළුවන් පද්ධතිය භාෂාව ප්\u200dරකාර (NLP) වැඩසටහන් පද්ධතිය සඳහා වැදගත් විශේෂ සම මේ පත්තරේ අපි සාමාන්\u200dය ට්විට් එක්කන්න සාමාන්\u200dය විධානයක් පෙනුම් කරනවා. මේ විධානය පාවිච්චි කරනවා, අපි ඉංග්\u200dරීසි-අරාබික් සාමාන්\u200dය ට්විට් වල දෙකක් භාෂාවක් සම්බන්ධ කරනවා වගේම තවි අපේ විධානය සාමාන්\u200dය විදියට, ඒක සමාන්\u200dය ට්විට් එකතු කරන්න පුළුවන් සර්බියාන් සහ උර්ඩු වගේ අඩුම සමාන්\u200dය භාෂාවක්  තවත් අපි ට්විටර් ගිණුම් සම්බන්ධයක් කරනවා ඔවුන්ගේ දේශ වලින් ප්\u200dරධානය සහ ප්\u200dරශ්නයක් තියෙනවා, ඒකෙන් ප්\u200dරශ්නයක් ප මේ අන්තිම තොරතුරු ලේඛකයේ වැඩක් විසින් ප්\u200dරයෝජනය කරන්න පුළුවන් වෙයි.', 'so': 'Si aad u hesho dhegaha aad u weyn iyo aad u kala duduwan, isticmaalayaasha Twitterka inta badan waxay soo bandhigaan tweeti oo isku mid ah, laakiin waxaa lagu qoraa luuqado kala duduwan. Tweetka baarlamaanka waxaa laga yaabaa in uu yahay mid muhiim ah oo horumarinta tarjumaadda machine (MT) nidaamka ah oo ka mid ah shaqooyin ka baaraandegista afka kale (NLP). Warqadan waxaan ku soo bandhignaa qaab caadi ah oo aan soo ururiyo tweetka lambarka ah. Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly.  Sida uu qaababkayagu yahay mid caadi ah, waxaa sidoo kale loo isticmaali karaa in la soo ururiyo tweetka lambarka ah oo ku daboola luqadaha aan laga karin sida Serbiyan iyo Urdu. Sidoo kale waxaynu koob ka mid ah akawnada Twitterka oo wadamadooda asalka iyo mada xiiseynaya, taas oo ka muuqata waxyaabaha ku saabsan dadka soo bandhigaya tweetka si siman. This latter information can also be useful for author profiling tasks.', 'ta': 'பெரிய மற்றும் மேலும் வித்தியாசமான பார்வையாளர்களை அடைக்க ஒரு கட்டளையில், Twitter users often post parallel tweets- tweets that contain the same content but are written in different languages. அளபுருக்கள் மற்ற இயல்பான மொழி செயல்பாடுகளில் (NLP) பணிகளில் மொழிமொழிமாற்றும் மொழிமாற்றும் அமைப்புகளை உருவாக்குவதற் இந்த காகிதத்தில், நாம் இணைய தொடர்புகளை சேகரிக்க ஒரு பொதுவான முறையை அறிவிக்கிறோம். இந்த முறையைப் பயன்படுத்தி, நாம் ஒரு இரண்டு மொழி குறியீட்டை சேகரிக்கிறோம் ஆங்கிலத்தில் அரபி இணைய இணைப்பு tweets மற்றும் ஒரு Twitter கணக்கின எங்கள் முறைமை பொதுவாக இருக்கும் போது, செர்பியன் மற்றும் Urdu போன்ற குறைந்த மொழிகளை மறைக்கும் இணைய துப்பெட்டிகளை சேகரிக் கூடுதலாக, நாம் ஒரு துணை Twitter கணக்குகளை வெளிப்படுத்துகிறோம் அவர்களின் மூலம் மற்றும் ஆர்வத்திற்கு தலைப்புடன் உள்ள நாடுகளை கொண்டு, இது இணை This latter information can also be useful for author profiling tasks.', 'sv': 'I ett försök att nå en större och mer varierad publik lägger Twitter-användare ofta upp parallella tweets – tweets som innehåller samma innehåll men är skrivna på olika språk. Parallella tweets kan vara en viktig resurs för att utveckla maskinöversättningssystem (MT) bland annat Natural Language Processing (NLP) uppgifter. I denna uppsats introducerar vi en generisk metod för att samla in parallella tweets. Med hjälp av denna metod samlar vi in en tvåspråkig korpus av engelsk-arabiska parallella tweets och en lista över Twitter-konton som publicerar engelsk-arabictwets regelbundet. Eftersom vår metod är generisk kan den också användas för att samla parallella tweets som täcker mindre resurser språk som serbiska och urdu. Dessutom kommenterar vi en del av Twitter-konton med deras ursprungsländer och ämne av intresse, vilket ger insikter om befolkningen som publicerar parallella tweets. Denna senare information kan också vara användbar för författarprofileringsuppgifter.', 'ur': 'ایک بڑے اور زیادہ مختلف اڈیونس کو پہنچ جانے کے لئے توئیٹر کارساز اکثر مشابہ ٹیوٹ-ٹیوٹ کو پوسٹ کرتے ہیں جو ایک ہی موجود موجود ہے لیکن مختلف زبانوں میں لکھی جاتی ہیں. Parallel tweets can be an important resource for developing machine translation (MT) systems among other natural language processing (NLP) tasks. اس کاغذ میں ہم ایک عمومی طریقہ مقرر کریں گے کہ parallel tweets جمع کریں۔ اس طریقہ کے مطابق ہم انگلیسی-عربی پارالل ٹیوٹ کی دو زبان کی کورپوس جمع کرتے ہیں اور ٹویٹر کی ایک لکھ جو انگلیسی-عربی ٹیوٹ کو معمولی طور پر پوسٹ کرتے ہیں۔ کیونکہ ہمارا طریقہ معمولی ہے، اسے بھی مشابل ٹیوٹ جمع کرنے کے لئے استعمال کر سکتا ہے جو کم رسسورٹ زبانوں کو چھپاتے ہیں جیسے سربی اور اردو۔ اور اضافہ، ہم نے توئیٹر کی ایک سپٹ اکائوٹ کو ان کے ملکوں کے سامنے اور علاقه کے موضوع سے نشان دیتے ہیں، جو جماعت کے بارے میں مشورہ دیتے ہیں جو مشابہ توئیٹوں کو پوسٹ کرتے ہیں. یہ آخری معلومات بھی لکھنے کے لئے استفاده کرسکتی ہے۔', 'vi': 'Trong nỗ lực đạt được những khán giả lớn hơn và đa dạng hơn, người dùng Twitter thường đăng những dòng tweet song song song có cùng một nội dung nhưng được viết bằng ngôn ngữ khác nhau. Đồng loạt tweet có thể là một tài nguyên quan trọng để phát triển hệ thống dịch thuật máy (MTV) trong các công việc xử lý ngôn ngữ tự nhiên (Nchọc) khác. Trong tờ giấy này, chúng tôi sẽ đưa ra một phương pháp tổng hợp để sưu tập tweet. Sử dụng phương pháp này, chúng tôi thu thập một tập tin hai chiều của tiếng Anh-Ả Rập những dòng tweet và một danh sách các tài khoản Twitter, những người đăng tiếng Anh-Ả Rập đều đặn. Do phương pháp của chúng ta là chung, nó cũng có thể được dùng để thu thập các tweet song song mà cung cấp các ngôn ngữ kém nguồn như Serbia và Urdu. Thêm vào đó, chúng tôi ghi chú một bộ tài khoản Twitter với quốc gia gốc và chủ đề thú vị, cung cấp thông tin về dân số đăng những dòng tweet song song. Thông tin sau này cũng có thể hữu dụng cho việc phân tích tác giả.', 'uz': "Ko'pchilik va ko'plab turli taqdimot uchun Twitter foydalanuvchilar odatda bir xil tarkibi bo'lgan Twitterlar bilan qo'llangan, lekin boshqa tillarda yozilgan. Name Bu qogʻozda, biz parallel tweetilarni birlashtirish uchun umumiy usulni anglatamiz. Bu usuldan foydalanish, biz ingliz-arab parallel tweetilarning ikkita tillar kopuslarini va Twitter hisoblarining roʻyxatini qo'yib, ular oddiy ingliz- Arabictweetlarini qo'llangan. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  Ko'pchilik, biz Twitter hisoblarining bir qismni o'zgartiraymiz, asl va qiziqarli mavzu bilan bir qanchalik Twitter hisoblarini anglatamiz. Bu o'z o'zgarishni qo'llab qo'yish xabarlarni o'rganadi. @ info", 'hr': 'U ponudi da dođemo do veće i raznolikosti publike, korisnici Twitter često postavljaju paralelne tweets-tweets koji sadrže isti sadržaj ali napisani su na različitim jezicima. Paralelni tweets mogu biti važan resurs za razvoj sustava prevoda strojeva (MT) među drugim zadacima obrade prirodnog jezika (NLP). U ovom papiru predstavljamo generičnu metodu za skupljanje paralelnih tweeta. Koristeći ovu metodu, skupljamo dvojezički korpus engleskog-arapskog paralelnog tweeta i popis tviterskih računa koji redovno postavljaju engleski-arapski vikti. Budući da je naš metod generičan, to se može koristiti i za skupljanje paralelnih tweeta koji pokrivaju manje resursnih jezika poput Srbije i Urdu. Osim toga, navodimo podskup tviterskih računa s njihovim zemljama podrijetla i temom interesa, koja pruža uvide o populaciji koji postavljaju paralelne tweets. Ove posljednje informacije mogu biti korisne i za profiliranje zadataka autora.', 'da': 'I et forsøg på at nå ud til et større og mere forskelligartet publikum sender Twitter-brugere ofte parallelle tweets-tweets, der indeholder det samme indhold, men er skrevet på forskellige sprog. Parallele tweets kan være en vigtig ressource til udvikling af maskinoversættelsessystemer (MT) blandt andre opgaver med naturlig sprogbehandling (NLP). I denne artikel introducerer vi en generisk metode til at indsamle parallelle tweets. Ved hjælp af denne metode indsamler vi et tosproget korpus af engelsk-arabisk parallelle tweets og en liste over Twitter-konti, der lægger engelsk-arabictwets regelmæssigt. Da vores metode er generisk, kan den også bruges til at indsamle parallelle tweets, der dækker mindre ressourcer sprog som serbisk og urdu. Derudover annoterer vi en del af Twitter-konti med deres oprindelseslande og emne af interesse, hvilket giver indsigt i befolkningen, der sender parallelle tweets. Sidstnævnte oplysninger kan også være nyttige til forfatterprofileringsopgaver.', 'bg': 'В опит да достигнат до по-голяма и по-разнообразна аудитория, потребителите често публикуват паралелни туитове-туитове, които съдържат едно и също съдържание, но са написани на различни езици. Паралелните туитове могат да бъдат важен ресурс за разработване на системи за машинен превод (МТ), наред с други задачи за обработка на естествения език (НЛП). В тази статия въвеждаме генеричен метод за събиране на паралелни туитове. Използвайки този метод, събираме двуезичен корпус от паралелни английски-арабски туитове и списък с акаунти, които публикуват редовно английски-арабски туитове. Тъй като методът ни е генеричен, той може да се използва и за събиране на паралелни туитове, които обхващат по-малко ресурси езици като сръбски и урду. Освен това анотираме подгрупа от акаунти в техните страни на произход и тема на интерес, което предоставя информация за населението, което публикува паралелни туитове. Тази последна информация може да бъде полезна и за задачи за профилиране на автори.', 'ko': '더 많은, 더 다양한 시청자를 유치하기 위해 트위터 사용자들은 같은 내용을 포함하지만 서로 다른 언어로 작성된 평행 트윗을 자주 올린다.기계번역(MT) 시스템과 다른 자연언어처리(NLP) 임무를 개발할 때 병행 트윗은 중요한 자원이다.본문에서 우리는 추문을 수집하고 병행하는 통용적인 방법을 소개했다.이런 방법으로 우리는 영어-아랍어 평행 트윗의 이중 언어 자료 라이브러리와 영어-아랍 트윗을 정기적으로 발표하는 트위터 계정 목록을 수집했다.우리의 방법은 통용되기 때문에 자원이 비교적 적은 언어(예를 들어 세르비아어와 우르두어)의 병행 추문을 수집하는 데도 쓰일 수 있다.또한 트위터 계정의 하위 집합에 출처국과 화제에 대한 주석을 추가해 평행 트윗을 올리는 사람들에게 견해를 제공했다.다음 정보는 저자의 분석 임무에도 유용하다.', 'id': 'Dalam tawaran untuk mencapai penonton yang lebih besar dan berbeda, pengguna Twitter sering posting tweet-tweet paralel yang mengandung isi yang sama tetapi ditulis dalam bahasa yang berbeda. Twits paralel dapat menjadi sumber daya penting untuk mengembangkan sistem terjemahan mesin (MT) antara tugas proses bahasa alam (NLP). Dalam kertas ini, kami memperkenalkan metode generik untuk mengumpulkan tweet paralel. Dengan metode ini, kami mengumpulkan tubuh dua bahasa dari tweet paralel bahasa Inggris-Arab dan daftar rekening Twitter yang mengirim internet secara regeler bahasa Inggris-Arab. Karena metode kita generik, juga dapat digunakan untuk mengumpulkan tweet paralel yang meliputi bahasa yang kurang sumber daya seperti Serbia dan Urdu. Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets.  This latter information can also be useful for author profiling tasks.', 'de': 'Um ein größeres und vielfältigeres Publikum zu erreichen, posten Twitter-Nutzer häufig parallele Tweets – Tweets, die denselben Inhalt enthalten, aber in verschiedenen Sprachen geschrieben sind. Parallele Tweets können neben anderen Aufgaben der Natural Language Processing (NLP) eine wichtige Ressource für die Entwicklung maschineller Übersetzungssysteme sein. In diesem Beitrag stellen wir eine generische Methode zum Sammeln paralleler Tweets vor. Mit dieser Methode sammeln wir einen zweisprachigen Korpus englisch-arabischer paralleler Tweets und eine Liste von Twitter-Accounts, die regelmäßig englisch-arabische Tweets posten. Da unsere Methode generisch ist, kann sie auch verwendet werden, um parallele Tweets zu sammeln, die weniger Ressourcen wie Serbisch und Urdu abdecken. Darüber hinaus kommentieren wir eine Teilmenge von Twitter-Konten mit ihren Herkunftsländern und Themen, die von Interesse sind, was Einblicke in die Bevölkerung liefert, die parallele Tweets posten. Letztere Informationen können auch für Autorenprofiling-Aufgaben nützlich sein.', 'tr': 'Birnäçe uly we daşyp dürli seçmenlere ýetmek üçin, Twitter ullançylary köplenç bir meýdança bolan, ýöne farklı dillerde ýazylýarlar. Parallel tweets maşynyň terjime (MT) sistemlerini be ýleki tebigy diller işlemegi (NLP) täzelikleri arasynda döretmek üçin wajyp çeşme bolup biler. Bu kagyzda parallel tweets toplamak üçin jeneral bir yöntem goşulýarys. Bu yöntemi ulanarak, iňlisçe-arapça parallel tweetleriniň ikinji dilli korpusyny we iňlisçe-aräpçe günlerde iňlisçe-aräpçe üýtgeden Twitter hasaplarynyň listini ýygnaýarys. Biziň yöntemimiz dowamly bolandygyna sebäbi, bu hem Serbiýa we Urdu ýa ýaly parallel tweetleri toplamak üçin ulanylýar. Hemmäçe, Twitter hasaplarynyň bir toparyny öz döwletleri we gyzyklanýan temalary bilen duýýarys. Bu soňky maglumat hem awtomatik işleri profil etmek üçin peýdaly bolup biler.', 'af': "In 'n bid om 'n groter en meer verskillende publiek te raak, stuur Twitter gebruikers dikwels parallele tweets-tweets wat dieselfde inhoud bevat maar in verskillende tale geskryf word. Parallele tweets kan 'n belangrik hulpbron wees vir ontwikkeling van masjien vertaling (MT) stelsels onder ander natuurlike taal verwerking (NLP) taak. In hierdie papier, introduseer ons 'n generieke metode vir samelering parallele tweets. Deur hierdie metode te gebruik, versamel ons 'n twee tale korpus van Engels-Arabiese parallele tweets en 'n lys van Twitter rekeninge wat gewoonlik ingelse-Arabieke post. Omdat ons metode generiek is, kan dit ook gebruik word vir samelering van parallele tweets wat minder-hulpbron taal oordek soos Serbiese en Urdu. In addition, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets. Hierdie laaste inligting kan ook nuttig wees vir outeur profileer taak.", 'sw': 'Katika pendekezo la kufikia hadhira kubwa zaidi na zaidi, watumiaji wa Twita mara nyingi huweka twiti zilizofanana na twiti zilizo na maudhui hayo lakini huandikwa kwa lugha tofauti. Twiti za Parallel zinaweza kuwa rasilimali muhimu kwa ajili ya kutengeneza mfumo wa kutafsiri mashine (MT) miongoni mwa kazi nyingine za lugha za asili (NLP). Katika karatasi hii, tunaonyesha njia ya kawaida kwa ajili ya kukusanya twiti zilizofanana. Kwa kutumia mbinu hii, tunakusanya viungo vya lugha mbili vya twiti zilizolinganishwa na Kiingereza na orodha ya akaunti za Twita ambazo mara kwa mara huweka twiti za Kiingereza na Kiarabu. Kwa kuwa njia yetu ni ya kawaida, inaweza pia kutumika kwa ajili ya kukusanya twiti zilizofanana ambazo zinazungumza lugha ndogo zenye rasilimali kama vile Serbia na Urdu. Kwa nyongeza, tunaelezea mfululizo wa akaunti za Twita na nchi zao za asili na mada ya maslahi, ambazo hutoa uelewa wa watu wanaoiweka twiti zilizofanana. Taarifa hii ya mwisho inaweza pia kuwa na manufaa kwa mwandishi wa kuelezea kazi.', 'sq': 'Në një orvatje për të arritur një audiencë më të madhe dhe më të ndryshme, përdoruesit e Twitter shpesh publikojnë tweets-tweets paralele që përmbajnë të njëjtin përmbajtje por janë shkruar në gjuhë të ndryshme. Twitter paralel mund të jetë një burim i rëndësishëm për zhvillimin e sistemeve të përkthimit të makinave (MT) midis detyrave të tjera të përdorimit natyror të gjuhës (NLP). Në këtë letër, ne paraqesim një metodë gjenerale për mbledhjen e tweeteve paralele. Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly.  Meqenëse metoda jonë është gjenerike, ajo mund të përdoret gjithashtu për mbledhjen e tweeteve paralele që mbulojnë gjuhë më pak të burimeve të tilla si serbe dhe Urdu. Përveç kësaj, ne anotojmë një nëngrup llogarish në Twitter me vendet e tyre të origjinës dhe temën e interesit, që ofron kuptime rreth popullsisë që publikon tweetet paralele. Ky informacion i fundit mund të jetë gjithashtu i dobishëm për detyrat e profilimit të autorëve.', 'nl': 'Om een groter en diverser publiek te bereiken, plaatsen Twitter-gebruikers vaak parallelle tweets-tweets die dezelfde inhoud bevatten maar in verschillende talen zijn geschreven. Parallele tweets kunnen een belangrijke bron zijn voor het ontwikkelen van machine translation (MT) systemen, naast andere natuurlijke taalverwerkingstaken (NLP). In dit artikel introduceren we een generieke methode voor het verzamelen van parallelle tweets. Met deze methode verzamelen we een tweetalig corpus van Engels-Arabische parallelle tweets en een lijst van Twitter-accounts die regelmatig Engels-Arabictweets plaatsen. Omdat onze methode generiek is, kan het ook worden gebruikt voor het verzamelen van parallelle tweets die betrekking hebben op minder beschikbare talen zoals Servisch en Urdu. Daarnaast maken we annoteren een subset van Twitter-accounts met hun land van herkomst en onderwerp van interesse, wat inzicht geeft over de bevolking die parallelle tweets plaatst. Deze laatste informatie kan ook nuttig zijn voor auteursprofileringstaken.', 'hy': 'Փորձելով հասնել ավելի մեծ և բազմազան հանդիսատեսին, Թվիթերի օգտագործողները հաճախ հրապարակում են զուգահեռ թվիթեր, որոնք պարունակում են նույն պարունակությունը, բայց գրված են տարբեր լեզուներով: Փաստավոր թվիթերը կարող են լինել կարևոր ռեսուրս մեքենային թարգմանման (MT) համակարգերի զարգացման համար այլ բնական լեզվի վերամշակումների միջև: Այս թղթի մեջ մենք ներկայացնում ենք զուգահեռ թվիթերի հավաքելու ընդհանուր մեթոդ: Օգտագործելով այս մեթոդը, մենք հավաքում ենք երկլեզու կորպուս անգլերեն-արաբական զուգահեռ թվիթերի և Թվիթերի հաշիվների ցուցակ, որոնք պարբերաբար անգլերեն-արաբական թվիթեր են հրապարակում: Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  Ավելին, մենք նկարագրում ենք Թվիթերի հաշիվների մի ենթախումբ իրենց նախնական երկրներով և հետաքրքիր թեմայով, որը պարունակում է ընկալումներ այն բնակչության մասին, ով զուգահեռ թվիթեր է հրապարակում: Այս վերջին տեղեկատվությունը կարող է նաև օգտակար լինել հեղինակի պրոֆիլիզացիայի խնդիրների համար:', 'az': 'Böyük və daha çox müxtəlif auditoriyə çatmaq üçün Twitter istifadəçiləri çox zaman eyni məlumatları barəsində paralel tweets-tweets göndərirlər, amma fərqli dillərdə yazılır. Parallel tweets başqa doğal dil işlətməsi (NLP) işləri arasında maşın çevirilməsi (MT) sistemlərinin təmizləməsi üçün vacib bir resurs olar. Bu kağızda paralel twetləri toplamaq üçün generik bir yol göstəririk. Bu metodlara istifadə edirək, İngilizə-Arapça paralelə tweetlərin iki dil korpusu və İngilizə-Arapça weetlarını düzgün səhifələrə göndərən Twitter hesablarının listesini toplayırıq. Bizim metodumuz generiki olduğu üçün, bu da Sırbistan və Urdu kimi daha az ressurslı dillərdən istifadə edilə bilər. Üstəlik, biz Twitter hesablarının subgruplarını onların məxluqatı və məlumatı ilə bildiririk ki, paralel twetləri göndərən insanlar haqqında görüş verir. Bu son məlumat də yazıcı işləri profil etmək üçün faydalı olar.', 'fa': 'برای رسیدن به تماشاگران بزرگتر و متفاوتتر، کاربران توئیتر اغلب توئیت\u200cهای متفاوتی که همان محتویات را دارند و در زبانهای متفاوتی نوشته می\u200cشوند. تویت\u200cهای پارالی می\u200cتوانند یک منبع مهم برای توسعه سیستم\u200cهای ترجمه ماشین (MT) بین کار\u200cهای پردازش زبان طبیعی (NLP) باشند. در این کاغذ، ما یک روش عمومی برای جمع کردن توئیت parallel را معرفی می کنیم. با استفاده از این روش، ما یک جسد دو زبان از tweets parallel به انگلیسی-عربی و یک لیست از حساب\u200cهای توئیتر که معمولاً انگلیسی-عربی\u200cویت\u200cها را می\u200cگذارند جمع می\u200cکنیم. به خاطر اینکه روش ما معمولی است، می تواند برای جمع کردن تویت\u200cهای متفاوتی که زبان\u200cهای کمتری منابع مانند سربی و اردو را پوشانده می\u200cشوند استفاده می\u200cشود. اضافه\u200cای از این، ما یک زیر حساب توئیتر را با کشورهای اصلی و موضوع علاقه\u200cای که در مورد جمعیت\u200cها مشاهده می\u200cکند که توئیت\u200cهای متفاوتی را بفرستند، نشان می\u200cدهیم. این اطلاعات آخرین هم می\u200cتواند برای پروفایل کردن کارهای نویسنده مفید باشد.', 'bn': 'বৃহত্তর এবং বিভিন্ন ভিন্ন দর্শকদের কাছে পৌঁছানোর একটি দায়িত্বে টুইটার ব্যবহারকারীরা প্রায়শই প্যারালেল টুইট-টুইট পোস্ট করে যা অন্যান্য প্রাকৃতিক ভাষা প্রক্রিয়া (এনএলপি) কাজের মধ্যে মেশিন অনুবাদের (এমটি) সিস্টেম উন্নয়নের জন্য প্যারালেল টুইট এই কাগজটিতে আমরা প্যারালেল টুইট সংগ্রহের জন্য একটি জেনারিক পদ্ধতি চিহ্নিত করি। এই পদ্ধতি ব্যবহার করে আমরা ইংরেজী -আরবী প্যারালেল টুইট এবং টুইটার একাউন্টের একটি তালিকা সংগ্রহ করি যারা নিয়মিত ইংরেজী আরাবিক্ট উইটগুলো  Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as Serbian and Urdu.  এছাড়াও আমরা টুইটার একাউন্টের বিভিন্ন বিষয়টিকে বিস্তারিত করি তাদের প্রজন্মের দেশ এবং আগ্রহের বিষয়ের সাথে, যারা তাদের প্যারালেল ট এই পরের তথ্য লেখক প্রোফাইল করার জন্য উপযুক্ত হতে পারে।', 'bs': 'U ponudi da dođemo do veće i raznolikosti publike, Twitter korisnici često postavljaju paralelne tweets-tweets koji sadrže isti sadržaj, ali napisani su na različitim jezicima. Paralelni tweets mogu biti važan resurs za razvoj sustava prevoda strojeva (MT) među drugim zadacima prirodnog obrade jezika (NLP). U ovom papiru predstavljamo generičnu metodu za skupljanje paralelnih tweeta. Koristeći ovu metodu, skupljamo dvojezički korpus engleskog-arapskog paralelnog tweeta i listu tviterskih računa koji redovno postavljaju engleski-arapski vikti. Budući da je naš metod generičan, može se koristiti i za skupljanje paralelnih tweeta koji pokrivaju manje resursnih jezika poput Srbije i Urdu. Osim toga, annotiramo podskup tviterskih računa sa svojim zemljama podrijetla i temom interesa, koja pruža uvide o populaciji koji postavljaju paralelne tweete. Ove poslednje informacije mogu biti korisne i za profiliranje zadataka autora.', 'am': 'በትዊተር ተጠቃሚዎች ብዙ ጊዜ በአንድ ተቃውሞ ነገር ግን በልዩ ቋንቋዎች ይጽፋሉ፡፡ የፓርላል ትዊተሮች በመፍጠር ቋንቋ ተርጓሚዎች (MT) ስርዓቶች (NLP) ስርዓቶችን ለመግለጽ የሚችል የሀብት ዕቃ መሆኑን ይችላል፡፡ በዚህ ጋዜጠኛ የባሕላዊ ትዊተቶችን ለማሰብሰብ የgeneric method እናሳውቃለን፡፡ ይህንን ሥርዓት በመጠቀም እንግሊዘኛ-አረቢያዊ ተቃውሞ የኢንጂልኛ-አረቢያዊ አካባቢ ሀገር እና በትዊተር አካባቢዎች ዝርዝር እናከማቻለን፡፡ የሥርዓታችን ዘወትር ከሆነች፣ እንደሴርቢያን እና ኡሩዲ ያሉትን የነፃነት ቋንቋዎች በሚሸፍኑት ተቃውሞ ትዊተሮች ለመሰብሰብ ይችላል፡፡ በተጨማሪም፣ ከትዊተር አካባቢዎች ጋር የመጀመሪያው እና የውጤት ጉዳይ እናሳውቃለን፡፡ This latter information can also be useful for author profiling tasks.', 'fi': 'Pyrkiessään tavoittamaan suuremman ja monipuolisemman yleisön Twitter-käyttäjät julkaisevat usein rinnakkaisia tweettejä, jotka sisältävät samaa sisältöä mutta jotka on kirjoitettu eri kielillä. Rinnakkaiset tweetit voivat olla tärkeä resurssi konekäännösjärjestelmien kehittämisessä muiden luonnollisen kielen käsittelytehtävien ohella. Tässä artikkelissa esittelemme yleisen menetelmän rinnakkaisten twiittien keräämiseen. Tämän menetelmän avulla keräämme kaksikielisen korpusen englanti-arabia rinnakkaistwiitteistä ja luettelon Twitter-tileistä, jotka julkaisevat englanti-arabictweettejä säännöllisesti. Koska menetelmämme on yleisluonteinen, sitä voidaan käyttää myös rinnakkaisten twiittien keräämiseen, jotka kattavat vähemmän resursseja omaavia kieliä, kuten serbia ja urdu. Lisäksi merkitsemme Twitter-tilien alaryhmän alkuperämaahan ja kiinnostavaan aiheeseen, mikä antaa tietoa rinnakkaisia twiittejä julkaisevasta väestöstä. Jälkimmäinen tieto voi olla hyödyllistä myös tekijän profilointitehtävissä.', 'et': 'Suurema ja mitmekesisema publikuni jõudmiseks postitavad Twitteri kasutajad sageli paralleelseid säutseid – säutseid, mis sisaldavad sama sisu, kuid on kirjutatud erinevates keeltes. Paralleelsed säutsud võivad olla oluliseks ressursiks masintõlke (MT) süsteemide arendamisel muude looduskeele töötlemise (NLP) ülesannete hulgas. Käesolevas töös tutvustame üldist meetodit paralleelsete säutsude kogumiseks. Seda meetodit kasutades kogume kahekeelse korpuse inglise-araabia paralleelsetest säutsudest ja loendi Twitteri kontodest, kes postitavad regulaarselt inglise-arabictweete. Kuna meie meetod on üldine, saab seda kasutada ka paralleelsete säutsude kogumiseks, mis hõlmavad vähem ressursse keeli, nagu serbia ja urdu. Lisaks märgistame Twitteri kontode alamhulga nende päritoluriikide ja huviteemadega, mis annab ülevaate elanikkonnast, kes postitab paralleelseid säutseid. Viimane teave võib olla kasulik ka autorite profileerimise ülesannete jaoks.', 'ca': "En un intent d'arribar a un públic més gran i més diversificat, els usuaris de Twitter sovint publiquen tweets parallels que contenen el mateix contingut però estan escrits en diferents llengües. Parallel tweets can be an important resource for developing machine translation (MT) systems among other natural language processing (NLP) tasks.  En aquest article introduim un mètode genèric per a recollir tweets paralèls. Utilitzant aquest mètode, recollim un cos bilingue de tweets paral·lels anglo-àrab i una llista de comptes de Twitter que publican periodicament els tweets anglo-àrab. Com que el nostre mètode és genèric, també pot ser utilitzat per col·leccionar tweets parallels que cobreixen llengües amb menys recursos com serbi i Urdu. Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets.  This latter information can also be useful for author profiling tasks.", 'cs': 'Ve snaze oslovit větší a rozmanitější publikum, uživatelé Twitteru často publikují paralelní tweety – tweety, které obsahují stejný obsah, ale jsou psány v různých jazycích. Paralelní tweety mohou být důležitým zdrojem pro vývoj systémů strojového překladu (MT) mezi dalšími úkoly zpracování přirozeného jazyka (NLP). V tomto článku představujeme obecnou metodu sběru paralelních tweetů. Pomocí této metody shromažďujeme dvojjazyčný korpus paralelních anglicko-arabských tweetů a seznam účtů na Twitteru, které pravidelně publikují anglicko-arabské tweety. Jelikož je naše metoda obecná, může být také použita pro sběr paralelních tweetů, které pokrývají méně zdrojové jazyky, jako je srbština a urdština. Navíc anotujeme podmnožinu Twitterových účtů s jejich zeměmi původu a tématem zájmu, což poskytuje přehled o populaci, která zveřejňuje paralelní tweety. Tyto poslední informace mohou být také užitečné pro úkoly profilování autorů.', 'jv': 'Nanging tunika kanggo sampeyan akeh dumadhi sing luwih lan akeh liyane, sampeyan Google sedhaya ngaturaken dituruti tuytes-tuytes sing ngewehi nggawe kudu dunyo sampeyan nganggep dino sampeyan liyane. Tubits Perusahaan pengguna nggawe sistem kanggo nggawe tarjamahan (MT) kang manut karo perusahaan bangsa anyar (NLP). Nang pemilih iki, kita nambah kelas sistem kanggo nggawe tuwit paralelel Ngawe ki nggambar sistem iki, kita cokot karo perusahaan langgambar ning tuytir tentang karo Perancis-arab lan nganggo sistem sing tuytir dhéwé kuwi tanggal Tuytir neng sistem sing bisa nguasai Inggris-arab. Sithik awak dhéwé kuwi kalem generic, iso dianggap kanggo nggawe tukang karo hal-tukang sing diranggawe barang pengguna kuwi dianggap, koyo sinau karo Urdu. Mungkar, kéné ngerasakno sistem sing nyelehke mrogram nang kontu Google karo perusahaan anyar tentang karo perusahaan, sing mau nggawe barang kebudhak dhéwé kuwi nggawe gerakan oleh tuwit sing oleh. Informasi sing mbukak punika dipunangé kanggo penyukat nggawe operasi kanggo nggawe juter cara nggawe', 'ha': "In a bid to reach a larger and more diverse audience, Twitter users often post parallel tweets-tweets that contain the same content but are written in different languages.  @ info: whatsthis Ga wannan takardan, za mu iya ƙara wata hanyoyi na samun mutane. Yi amfani da wannan hanyor, za'a sami kofi biyu na'urar littattafai na Ingiriya-arabu da wani jerin akan Twitter wanda ke poster littafin Ingiriya-arabu daidai. Ga da hanyoyinmu ya zama jeniya, za'a iya amfani da samun jumui-biyu masu daidaita da waɗanda ke rufe lugha masu ƙaranci-resourcewa kamar suriya da Urdu. Da haka, Munã sanar da wani rabo na akan Twitter tãre da dukansu masu na asirta da masĩfi, wanda ke ga mataimaka masu basara da wato-biyu. Wannan maɓalli na ƙarshe yana iya amfani da wa'yan aikin mai rubũtãwa.", 'sk': 'Da bi dosegli večjo in bolj raznoliko občinstvo, uporabniki Twitterja pogosto objavljajo vzporedne tweete – tweete, ki vsebujejo isto vsebino, vendar so napisani v različnih jezikih. Vzporedni tweeti so lahko pomemben vir za razvoj sistemov strojnega prevajanja (MT) med drugimi nalogami obdelave naravnega jezika (NLP). V prispevku predstavljamo generično metodo zbiranja vzporednih tweetov. Z uporabo te metode zbiramo dvojezični korpus angleško-arabskih vzporednih tweetov in seznam Twitter računov, ki redno objavljajo angleško-arabske tweete. Ker je naša metoda generična, jo lahko uporabimo tudi za zbiranje vzporednih tweetov, ki pokrivajo jezike z manj virov, kot sta srbščina in urdu. Poleg tega podnabor Twitter računov označujemo z njihovimi državami izvora in temo zanimanja, kar zagotavlja vpogled o prebivalstvu, ki objavlja vzporedne tweete. Slednje informacije so lahko uporabne tudi za opravila profiliranja avtorjev.', 'he': 'במצעה להגיע לקהל גדול יותר ויותר מגוון, משתמשים בטוויטר לעתים קרובות פורסמים טוויטרים משותפים שמכילים את אותו תוכן אבל נכתבים בשפות שונות. טוויטים פעמיים יכולים להיות משאב חשוב לפיתוח מערכות תרגום מכונות (MT) בין משימות מעבדת שפה טבעית אחרות (NLP). בעיתון הזה, אנחנו מציגים שיטה גנרית לאספת טוויטים מקבילים. באמצעות השיטה הזו, אנו אוספים קופוס שתיים-לשוני של טוויטים מקבילים אנגלי-ערביים ורשימה של חשבונות טוויטר שפורסמים טוויטים אנגלי-ערביים באופן קבוע. מכיוון שהשיטה שלנו גנרית, היא גם יכולה להשתמש באספת טוויטים מקבילים שמכילים שפות פחות משאבים כמו סרבית ואורדו. בנוסף, אנו מצביעים על תחתונה של חשבונות טוויטר עם מדינות המקור שלהם ונושא עניין, שמספק תובנות על האוכלוסיה שפורסמת טוויטרים מקבילים. המידע האחרון הזה יכול להיות שימושי גם למשימות פרופילים של כותבים.', 'bo': 'ལྟ་བ་ཞིག་གིས་འདིར་རྩོམ་པ་ཞིག་དང་འདྲ་བ་མང་པོ་ཞིག་ཏུ་འཇོག་རྒྱུ་དང་། རྫུན་བཟོ་བའི་Tweets་ནི་ལག་འཁོར་གྱི་ཡིག་སྣོད་ལ་ཆེན་པོ་ཞིག་ཡིན། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་མཐུན་བཟོ་བའི་གྲངས་སུ་མཐུན་ལམ་ཞིག་སྤྲོད་བྱེད་ཀྱི་ཡོད། འོན་ཀྱང་། ང་ཚོས་དབྱིན་ཡིག་གི་སྡོད་པ་གཉིས་ཀྱི་ཚོགས་ཁག་ཅིག་སྦྱར་བྱེད་ཀྱི་རེད། ང་ཚོའི་ལམ་ལུགས་འདི་ཁྱད་པར་ཆུང་ཚང་ཞིག་ཡིན་ལས། དེ་ཚོ་ཡང་སྤྱད་ནས་parallel tweets་ཆ་མཉམ་དུ་སྤྱོད་ཐུབ་པ་ལས། དཔེར་ན་སྤྱོད་མཁན་ འུ་ཅག་གིས་ཁོང་ཚོའི་ཕྱི་རྒྱལ་ཁབ་དང་བསམ་བློ་གཏད་ཀྱི་ཚོགས་ཁག་ཅིག་གསར་བསྐྲུན་བྱེད་ཀྱི་ཡོད། རྩོམ་པ་པོ་བརྗོད་དུ་བྱ་འགུལ་གྱི་འགྲེལ་བཤད་འདི་ཁྱད་དུ་ཕན་ཐོགས་ཆེན་ཡོད།'}
{'en': 'Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding', 'ar': 'الإنشاء التلقائي لجدول المراسلات لعلامات المعنى من قاموسين في لغة واحدة باستخدام دمج الكلمات ثنائي اللغة', 'es': 'Creación automática de etiquetas de tablas de significado de correspondencia a partir de dos diccionarios en un idioma mediante incrustación de palabras bilingüe', 'fr': "Création automatique d'une table de correspondance des balises de signification à partir de deux dictionnaires dans une langue à l'aide de l'intégration bilingue de mots", 'pt': 'Criação automática de tabela de correspondência de tags de significado de dois dicionários em um idioma usando incorporação de palavras bilíngüe', 'ja': 'バイリンガルワード埋め込みを使用した、1つの言語の2つの辞書からの意味タグの対応表の自動作成', 'zh': '用双语单词嵌自创一语二词典之义标应表', 'hi': 'द्विभाषी शब्द एम्बेडिंग का उपयोग करके एक भाषा में दो शब्दकोशों से अर्थ टैग की पत्राचार तालिका का स्वत: निर्माण', 'ru': 'Автоматическое создание таблицы соответствий тегов значений из двух словарей на одном языке с использованием двуязычного встраивания слов', 'ga': 'Cruthú Uathoibríoch Comhfhreagrais Tábla Brí na gClibeanna as Dhá Fhoclóir i dTeanga Amháin a Úsáideann Leabú Focal Dátheangach', 'hu': 'Két szótárból két szótárból egy nyelven létrehozott jelentéstáblázat automatikus létrehozása a kétnyelvű szóbeágyazás használatával', 'ka': 'მნიშვნელოვანი ტექსტის ავტომატური შექმნა ორი სიტყვებით ერთი ენაში ორი სიტყვებით გამოყენება', 'el': 'Αυτόματη δημιουργία πίνακα αντιστοιχίας σημασιολογικών ετικετών από δύο λεξικά σε μια γλώσσα χρησιμοποιώντας τη δίγλωσση ενσωμάτωση λέξεων', 'it': "Creazione automatica della tabella di corrispondenza dei tag di significato da due dizionari in una lingua utilizzando l'incorporazione bilingue di parole", 'kk': 'Екі тілдегі екі сөздік сөздерінен бір тілдегі тегтердің координациялық кестесін автоматты түрде құру', 'mk': 'Автоматско создавање на табела за соодветност со означувања од два речници во еден јазик користејќи вградување на двогласни зборови', 'lt': 'Automatinis žymenų atitikties lentelės kūrimas iš dviejų žodynų viena kalba, naudojant dvikalbį žodžių įterpimą', 'ms': 'Cipta Automatik Jadual Korespondensi Tag Maknanya dari Dua Kamus dalam Satu Bahasa Mengguna Penjelmaan Kata Bilingual', 'ml': 'ഒരു ഭാഷ ഉപയോഗിക്കുന്ന ബിലിങ്ങിങ്ങുള്ള വാക്ക് എംബെഡിങ്ങ് ഉപയോഗിക്കുന്ന രണ്ട് നിഘണ്ടുകളില്\u200d നിന്നും മാത്രം', 'mt': 'Il-ħolqien awtomatiku tat-Tabella ta’ Korrispondenza tat-Tags tat-tifsira minn Żewġ Dikjarnarji f’Lingwa Waħda bl-użu ta’ Integrazzjoni Bilingwi tal-Kliem', 'mn': 'Нэг хэл дээрх хоёр сөрөгч дээрх хоёр сөрөгч дээрх зөвхөн зөвхөн зөвшөөрөл хүснэгтийн автоматтыг бүтээх', 'no': 'Automatisk oppretting av tilsvarende tabell for merkelappar frå to ordbok i ein språk som brukar bilete ordinnlegging', 'pl': 'Automatyczne tworzenie tabeli korespondencji znaczników z dwóch słowników w jednym języku za pomocą dwujęzycznego osadzania słów', 'ro': 'Crearea automată a tabelului de corespondență al etichetelor semnificative din două dicționare într-o singură limbă utilizând încorporarea de cuvinte bilingve', 'sr': 'Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding', 'so': 'Automatic Creation of Correspondence Table of meaninging Tags from Two Dictionaries in One language using Bilingual Word Embedding', 'si': 'Name', 'sv': 'Automatisk skapande av korrespondenstabell över betydelsetaggar från två ordböcker på ett språk med tvåspråkig ordinbäddning', 'ta': 'Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding', 'ur': 'ایک زبان میں دو لفظوں سے معنی ٹاگوں کی سفارشی ٹیبل کی اتمام پیدا کرنا', 'uz': 'Name', 'vi': 'Tự động tạo ra bảng hiệu ứng ý nghĩa của hai tác phẩm trong một ngôn ngữ dùng ngôn ngữ thần giao thoa từ', 'bg': 'Автоматично създаване на таблица за кореспонденция на значения тагове от два речника на един език с помощта на двуезично вграждане на думи', 'nl': 'Automatische creatie van correspondentietabel met betekenislabels uit twee woordenboeken in één taal met behulp van tweetalige woordinsluiting', 'da': 'Automatisk oprettelse af korrespondancetabel over betydningsmærker fra to ordbøger på ét sprog ved hjælp af tosproget ordindlejring', 'hr': 'Automatski kreiranje tablice odgovornosti znakova iz dvije riječi u jednom jeziku koristeći uključenje dvostrukih riječi', 'de': 'Automatische Erstellung von Korrespondenztabellen von Bedeutungstabellen aus zwei Wörterbüchern in einer Sprache mit zweisprachiger Worteinbettung', 'id': 'Penciptaan Otomatis Tabel Korespondensi Tag Berarti dari Dua Kamus dalam Satu Bahasa Menggunakan Penambahan Kata Bilingual', 'ko': '이중 언어로 삽입된 이중 언어 사전의 의미 표기 대응표의 자동 생성', 'fa': 'آفرینش خودکار میز هماهنگی از نقاشی معنی از دو کلمات در یک زبان استفاده از انجمن کلمات دوگانه', 'sw': 'Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding', 'af': 'Outomatiese Skep van Korespondensie Tabel van Betekensing Etikette van Twee Woordeboeke in Een Taal gebruik Beelde Woord Inbetering', 'sq': 'Krijimi automatik i tabelës së korrespondencës së etiketave me kuptim nga dy fjalorë në një gjuhë duke përdorur përfshirjen e fjalëve dygjuhëse', 'tr': 'Bir dilde iki sözlemden ahmal tägleriň otomatik Bejer', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Օգտագործելով երկլեզու բառեր', 'az': '캻ki dild톛 캻ki S칬zl칲kd톛n 캻kinci S칬zl칲kd톛n 캻kinci S칬zl칲kd톛n 캻kinci S칬zl칲k Tablosunun Avtomatik Yarat캼lmas캼', 'bn': 'একটি ভাষায় বিলিঙ্গুয়েল শব্দ ব্যবহার করে দুই ভাষায় মান ট্যাগ থেকে স্বয়ংক্রিয় সংবাদ টেবিলের স্বয়ংক্রিয়ভাবে তৈর', 'bs': 'Automatski kreiranje tablice odgovornosti znakova iz dvije riječi u jednom jeziku koristeći uključenje divljih riječi', 'ca': "Creació automàtica de la taula de correspondència d'etiquetes de significat de dos diccionaris en un llenguatge utilitzant integració bilingüe de paraules", 'cs': 'Automatické vytváření korespondenční tabulky významných značek ze dvou slovníků v jednom jazyce pomocí dvojjazyčného vložení slov', 'fi': 'Merkitystunnisteiden vastaavuustaulukon automaattinen luominen kahdesta sanakirjasta yhdellä kielellä käyttäen kaksikielistä sanamuotoa', 'et': 'Tähendussildide vastavustabeli automaatne loomine kahest sõnaraamatust ühes keeles, kasutades kahekeelset sõna manustamist', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Samodejno ustvarjanje korespondenčne tabele oznak pomena iz dveh slovarjev v enem jeziku z dvojezično vdelavo besed', 'ha': '@ action', 'he': 'יצירה אוטומטית של שולחן התאמה של תוויות משני מילונים בשפה אחת', 'bo': 'སྐད་ཡིག་གཅིག་ནང་གི་Dictionaries་གཉིས་ལས་མཚུངས་རྟགས་ཀྱི་ཤོག་བྱང་ཐོག་གི་རང་འགུལ་གྱིས་གསར་འཛུགས་བྱེད་པ'}
{'en': 'In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method. To do this, we had a problem : the meaning tags do not always correspond one-to-one because the granularities of the word senses and the concepts are different from each other. Therefore, we regarded the concept tag that corresponds to a word sense the most as the correct concept tag corresponding the word sense. We used two BWE methods, a linear transformation matrix and VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison. The accuracies of the proposed methods were higher than the accuracy of the random baseline but lower than those of the MFS and corpus concatenation methods. However, because our method utilized the embedding vectors of the word senses, the relations of the sense tags corresponding to concept tags could be examined by mapping the sense embeddings to the vector space of the concept tags. Also, our methods could be performed when we have only concept or word sense embeddings whereas the MFS method requires a parallel corpus and the corpus concatenation method needs two tagged corpora.', 'fr': "Dans cet article, nous montrons comment utiliser les intégrations de mots bilingues (BWE) pour créer automatiquement un tableau correspondant des balises de signification à partir de deux dictionnaires dans une langue et examiner l'efficacité de la méthode. Pour ce faire, nous avons eu un problème\xa0: les étiquettes de signification ne correspondent pas toujours une à une parce que les granularités du mot sens et des concepts sont différentes les unes des autres. Par conséquent, nous avons considéré l'étiquette conceptuelle qui correspond le plus à un sens de mot comme la bonne étiquette conceptuelle correspondant au sens du mot. Nous avons utilisé deux méthodes BWE, une matrice de transformation linéaire et VecMap. Nous avons évalué la méthode du sens le plus fréquent (MFS) et la méthode de concaténation de corpus à des fins de comparaison. La précision des méthodes proposées était supérieure à la précision de la base aléatoire mais inférieure à celle des méthodes MFS et de concaténation de corpus. Cependant, étant donné que notre méthode utilisait les vecteurs d'intégration des sens du mot sens, les relations des étiquettes de sens correspondant aux étiquettes de concept pouvaient être examinées en mappant les incorporations de sens à l'espace vectoriel des étiquettes conceptuelles. De plus, nos méthodes peuvent être exécutées lorsque nous n'avons que des intégrations de concept ou de sens de mot alors que la méthode MFS nécessite un corpus parallèle et la méthode de concaténation de corpus nécessite deux corpus balisés.", 'es': 'En este artículo, mostramos cómo utilizar la incrustación de palabras bilingües (BWE) para crear automáticamente una tabla correspondiente de etiquetas de significado de dos diccionarios en un idioma y examinar la eficacia del método. Para ello, tuvimos un problema: las etiquetas de significado no siempre se corresponden uno a uno porque las granularidades de los sentidos de las palabras y los conceptos son diferentes entre sí. Por lo tanto, consideramos que la etiqueta de concepto que más corresponde a un sentido de palabra es la etiqueta de concepto correcta que corresponde al sentido de la palabra. Utilizamos dos métodos BWE, una matriz de transformación lineal y VecMap. Evaluamos el método de sentido más frecuente (MFS) y el método de concatenación de corpus para la comparación. Las precisiones de los métodos propuestos fueron superiores a la precisión de la línea de base aleatoria, pero inferiores a las de los métodos de concatenación de MFS y corpus. Sin embargo, debido a que nuestro método utilizó los vectores de incrustación de los sentidos de las palabras, las relaciones de las etiquetas de sentido correspondientes a las etiquetas de concepto podrían examinarse mapeando las incrustaciones de sentido al espacio vectorial de las etiquetas de concepto. Además, nuestros métodos podrían realizarse cuando solo tenemos incrustaciones de conceptos o sentidos de palabras, mientras que el método MFS requiere un corpus paralelo y el método de concatenación de corpus necesita dos cuerpos etiquetados.', 'ar': 'في هذه الورقة ، نوضح كيفية استخدام دمج الكلمات ثنائية اللغة (BWE) لإنشاء جدول مطابق لعلامات المعنى تلقائيًا من قاموسين في لغة واحدة وفحص فعالية الطريقة. للقيام بذلك ، واجهتنا مشكلة: علامات المعنى لا تتوافق دائمًا مع واحد لواحد لأن تفاصيل أحاسيس الكلمة والمفاهيم تختلف عن بعضها البعض. لذلك ، اعتبرنا علامة المفهوم التي تتوافق مع معنى الكلمة أكثر ما تكون علامة المفهوم الصحيحة المقابلة لمعنى الكلمة. استخدمنا طريقتين BWE ، مصفوفة التحويل الخطي و VecMap. قمنا بتقييم الطريقة الأكثر شيوعًا (MFS) وطريقة تسلسل الجسم للمقارنة. كانت دقة الطرق المقترحة أعلى من دقة خط الأساس العشوائي ولكنها أقل من تلك الخاصة بطريقتين MFS وسلسلة الجسم. ومع ذلك ، نظرًا لأن طريقتنا تستخدم متجهات التضمين لحواس الكلمات ، يمكن فحص العلاقات بين علامات المعنى المقابلة لعلامات المفهوم عن طريق تعيين عمليات دمج المعنى إلى مساحة المتجه لعلامات المفهوم. أيضًا ، يمكن تنفيذ طريقتنا عندما يكون لدينا فقط مفهوم أو تضمين معنى الكلمة في حين تتطلب طريقة MFS مجموعة موازية وتحتاج طريقة تسلسل الجسم إلى مجموعتين معلمتين.', 'pt': 'Neste artigo, mostramos como usar a incorporação de palavras bilíngües (BWE) para criar automaticamente uma tabela correspondente de tags de significado de dois dicionários em um idioma e examinar a eficácia do método. Para isso, tivemos um problema: as tags de significado nem sempre correspondem uma a uma porque as granularidades dos sentidos das palavras e os conceitos são diferentes entre si. Portanto, consideramos a etiqueta conceitual que corresponde ao sentido da palavra mais como a etiqueta conceitual correta correspondente ao sentido da palavra. Usamos dois métodos BWE, uma matriz de transformação linear e VecMap. Avaliamos o método de sentido mais frequente (MFS) e o método de concatenação de corpus para comparação. As acurácias dos métodos propostos foram maiores que a acurácia da linha de base aleatória, mas menores que as dos métodos MFS e de concatenação de corpus. No entanto, como nosso método utilizou os vetores de embedding dos sentidos da palavra, as relações das tags de sentido correspondentes às tags de conceito podem ser examinadas mapeando os embeddings de sentido para o espaço vetorial das tags de conceito. Além disso, nossos métodos podem ser executados quando temos apenas embeddings de conceitos ou palavras, enquanto o método MFS requer um corpus paralelo e o método de concatenação de corpus precisa de dois corpora marcados.', 'zh': '于本文中,展双语词嵌(BWE)从一言两词典自创立义标表,并检其有效性。 所以然者,义不常一对一对应,单词senses与名粒度异也。 故名词义者,正名也。 吾用二BWE,线性易矩阵VecMap。 估其最频者传感(MFS)与语料库联法较之。 所提法之精高于随机基线之精,而低于MFS与语料库连法之精。 然以吾道用词义之嵌向量,故可以映射其向量间而省其感官也。 唯其概与词义嵌时,可行吾法,而MFS法须并行语料库,而语料库联法须两标语料库。', 'ja': '本稿では，バイリンガルワード埋め込み（ BWE ）を用いて， 1つの言語の2つの辞書から対応する意味タグ表を自動的に作成し，その方法の有効性を検討する方法を示す． これを行うには、意味タグが必ずしも1対1に対応していないという問題がありました。なぜなら、単語の意味と概念の粒度が互いに異なっているからです。 そこで、最も単語センスに対応する概念タグを、単語センスに対応する正しい概念タグとみなした。 線形変換行列とＶｅｃＭａｐという２つのＢＷＥ法を用いた。 比較のために最も頻度の高いセンス（ MFS ）法とコーパス連結法を評価した。 提案された方法の精度は、ランダムベースラインの精度よりも高かったが、MFSおよびコーパス連結法の精度よりも低かった。 しかしながら、我々の方法は単語センスの埋め込みベクトルを利用したため、概念タグに対応するセンスタグの関係は、センス埋め込みを概念タグのベクトル空間にマッピングすることによって調べることができた。 また、MFSメソッドには平行コーパスが必要で、コーパス連結メソッドには2つのタグ付きコーパスが必要です。', 'hi': 'इस पेपर में, हम दिखाते हैं कि एक भाषा में दो शब्दकोशों से अर्थ टैग की एक संबंधित तालिका बनाने और विधि की प्रभावशीलता की जांच करने के लिए द्विभाषी शब्द एम्बेडिंग (बीडब्ल्यूई) का उपयोग कैसे करें। ऐसा करने के लिए, हमें एक समस्या थी: अर्थ टैग हमेशा एक-से-एक के अनुरूप नहीं होते हैं क्योंकि शब्द इंद्रियों और अवधारणाओं की ग्रैन्युलैरिटीएक-दूसरे से अलग होती है। इसलिए, हमने उस अवधारणा टैग को माना जो एक शब्द भावना से मेल खाती है, जो शब्द भावना के अनुरूप सही अवधारणा टैग के रूप में सबसे अधिक है। हमने दो BWE विधियों, एक रैखिक परिवर्तन मैट्रिक्स और VecMap का उपयोग किया। हमने तुलना के लिए सबसे लगातार भावना (एमएफएस) विधि और कॉर्पस संयोजन विधि का मूल्यांकन किया। प्रस्तावित विधियों की सटीकता यादृच्छिक आधार रेखा की सटीकता से अधिक थी, लेकिन एमएफएस और कॉर्पस संयोजन विधियों की तुलना में कम थी। हालांकि, क्योंकि हमारी विधि ने शब्द इंद्रियों के एम्बेडिंग वैक्टर का उपयोग किया है, अवधारणा टैग के अनुरूप अर्थ टैग के संबंधों की जांच अवधारणा टैग के वेक्टर स्पेस के लिए भावना एम्बेडिंग को मैप करके की जा सकती है। इसके अलावा, हमारे तरीकों को तब किया जा सकता है जब हमारे पास केवल अवधारणा या शब्द भावना एम्बेडिंग होती है जबकि एमएफएस विधि को एक समानांतर कॉर्पस की आवश्यकता होती है और कॉर्पस संयोजन विधि को दो टैग किए गए कॉर्पोरेट की आवश्यकता होती है।', 'ru': 'В данной работе показано, как использовать двуязычные вложения слов (BWE) для автоматического создания соответствующей таблицы тегов смысла из двух словарей на одном языке и изучения эффективности метода. Для этого у нас возникла проблема: теги смысла не всегда соответствуют один к одному, потому что детализации смыслов слова и понятий отличаются друг от друга. Поэтому мы рассматривали концептуальный тег, который больше всего соответствует смыслу слова, как правильный концептуальный тег, соответствующий смыслу слова. Мы использовали два метода BWE, матрицу линейных преобразований и VecMap. Мы оценили метод наиболее частого смысла (MFS) и метод конкатенации тела для сравнения. Точность предложенных методов была выше, чем точность случайной базовой линии, но ниже, чем точность методов MFS и объединения тел. Однако, поскольку в нашем методе использовались векторы вложения смыслов слова, отношения тегов смысла, соответствующие тегам понятия, можно было бы изучить, сопоставив вложения смысла с векторным пространством тегов понятия. Кроме того, наши методы могут быть выполнены, когда у нас есть только вложения в понятие или смысл слова, в то время как метод MFS требует параллельного тела, а метод конкатенации тела требует двух помеченных тегов.', 'ga': "Sa pháipéar seo, léirímid conas leabaithe focal dátheangacha (BWE) a úsáid chun tábla comhfhreagrach de chlibeanna brí a chruthú go huathoibríoch ó dhá fhoclóir in aon teanga amháin agus scrúdaítear éifeachtacht an mhodha. Chun seo a dhéanamh, bhí fadhb againn: ní i gcónaí a fhreagraíonn na clibeanna brí duine-le-duine mar go bhfuil gráinneachtaí na céadfaí focal agus na coincheapa difriúil óna chéile. Mar sin, mheasamar gurb é an chlib choincheapa a fhreagraíonn do chiall focal an chlib coincheap ceart a fhreagraíonn don chiall focal is mó. D’úsáideamar dhá mhodh BWE, maitrís claochlaithe líneach agus VecMap. Rinneamar measúnú ar an modh braite is minicí (MFS) agus ar an modh comhtháite corpais chun comparáid a dhéanamh. Bhí beachtas na modhanna molta níos airde ná beachtas na bunlíne randamach ach ní b'ísle ná iad siúd a bhaineann leis na modhanna MFS agus comh-chomhtháthaithe corpais. Mar sin féin, toisc gur bhain ár modh úsáid as veicteoirí leabú na gcéadfaí focal, d’fhéadfaí caidreamh na gclibeanna cialla a fhreagraíonn do chlibeanna coincheapa a scrúdú trí na leabú céadfaí a mhapáil le spás veicteoireach na gclibeanna coincheapa. Chomh maith leis sin, d’fhéadfaí ár modhanna a chur i bhfeidhm nuair nach bhfuil againn ach leabuithe cialla coincheapa nó focal ach teastaíonn corpas comhthreomhar leis an modh MFS agus teastaíonn dhá chorpas clibeáilte ó mhodh comhthéite an chorpais.", 'hu': 'Ebben a tanulmányban bemutatjuk, hogyan lehet kétnyelvű szóbeágyazásokat (BWE) használni, hogy automatikusan létrehozzon egy megfelelő táblázatot két szótárból egy nyelven, és megvizsgálja a módszer hatékonyságát. Ehhez problémánk volt: a jelentéscímkék nem mindig egyenként felelnek meg, mert a szó érzékszervei és fogalmai különböznek egymástól. Ezért a szóérzéknek leginkább megfelelő koncepciócímkét tekintjük a szóérzéknek megfelelő koncepciócímként. Két BWE módszert használtunk, egy lineáris transzformációs mátrixot és a VecMap-et. Az összehasonlítás céljából értékeltük a leggyakoribb szenzációs (MFS) módszert és a corpus concatenációs módszert. A javasolt módszerek pontossága nagyobb volt, mint a véletlenszerű kiindulási pontosság, de alacsonyabb, mint az MFS és a corpus concatenation módszerek. Mivel azonban módszerünk a szóérzékek beágyazási vektorait használta, a koncepciócímkéknek megfelelő érzékelési címkék viszonyát úgy lehetett vizsgálni, hogy az érzékelések beágyazását a koncepciócímkék vektortérével lehetett leképezni. Módszereinket akkor is végezhetjük, ha csak koncepció vagy szó érzék beágyazások vannak, míg az MFS módszer párhuzamos korpuszt igényel, a korpusz összekapcsolási módszerhez pedig két tagged korpuszt igényel.', 'el': 'Στην παρούσα εργασία, παρουσιάζουμε πώς μπορείτε να χρησιμοποιήσετε δίγλωσσες ενσωμάτωσης λέξεων (για να δημιουργήσετε αυτόματα έναν αντίστοιχο πίνακα σημασιολογικών ετικετών από δύο λεξικά σε μια γλώσσα και να εξετάσετε την αποτελεσματικότητα της μεθόδου. Για να το κάνουμε αυτό, είχαμε ένα πρόβλημα: οι σημασιολογικές ετικέτες δεν αντιστοιχούν πάντα ένα προς ένα επειδή οι κοκκώδεις ιδιότητες των λέξεων αισθήσεις και των εννοιών διαφέρουν μεταξύ τους. Ως εκ τούτου, θεωρήσαμε την ετικέτα έννοιας που αντιστοιχεί σε μια έννοια ως τη σωστή ετικέτα έννοιας που αντιστοιχεί στη λέξη έννοια. Χρησιμοποιήσαμε δύο μεθόδους BWE, έναν γραμμικό πίνακα μετασχηματισμού και VecMap. Αξιολογήσαμε τη μέθοδο της συχνότερης αίσθησης και τη μέθοδο της συσσώρευσης σωμάτων για σύγκριση. Οι ακρίβειες των προτεινόμενων μεθόδων ήταν υψηλότερες από την ακρίβεια της τυχαίας βάσης, αλλά χαμηλότερες από αυτές των μεθόδων MFS και των μεθόδων συσσώρευσης σωμάτων. Ωστόσο, επειδή η μέθοδος μας χρησιμοποίησε τα διανύσματα ενσωμάτωσης των αισθήσεων λέξεων, οι σχέσεις των ετικετών αισθήσεων που αντιστοιχούν σε ετικέτες εννοιών θα μπορούσαν να εξεταστούν χαρτογραφώντας τις ενσωμάτωσης αισθήσεων στον διανυσματικό χώρο των ετικετών εννοιών. Επίσης, οι μέθοδοι μας θα μπορούσαν να εκτελεστούν όταν έχουμε μόνο ενσωμάτωση εννοιών ή λέξεων ενώ η μέθοδος απαιτεί παράλληλο σώμα και η μέθοδος συσχέτισης σωμάτων χρειάζεται δύο σημαδεμένα σώματα.', 'ka': 'ჩვენ ჩვენ ჩვენ აჩვენებთ, როგორ გამოყენება ორიენგური სიტყვების ინბედინგიები (BWE) ავტომატურად შექმნა შესაძლებელი სიტყვების მნიშვნელობის მაგილას ორივე სიტყვებით ერთი ენაში და მეტი ეს გავაკეთებთ, ჩვენ გვაქვს პრობლემები: ნიშნავს, რომ ნიშნავს, რომ ნიშნავს არ ყოველთვის ერთად კონფიგურაციას, რადგან სიტყვის გრანულაციას და კონფიგურაციები ერთად გან ამიტომ, ჩვენ შევხედავთ კონცექტის ტეგექტი, რომელიც სიტყვების სიტყვების შესახებ უფრო მარტივი კონცექტის ტეგექტი, რომელიც სიტყ ჩვენ გამოყენეთ ორი BWE მეტი, ლეინური ტრანფორმაციის მარტიკი და VecMap. ჩვენ უფრო დიდი სიგრძნე (MFS) მეტი და კორპუსს შემწყვეტის მეტი შემწყვეტილობა. პროგრამების წარმოადგილება უფრო მეტი იყო შემდეგი ფესტულის წარმოადგილება, მაგრამ უფრო მეტი, რომელიც MFS და corpus წარმოადგილების წარმოადგილება. მაგრამ, რადგან ჩვენი მეტი გამოყენებულია სიტყვების სიტყვების გარეშე გვექნების შესახებ, სიტყვების ჭდეების შესახებ, რომლებიც კონცექტის ჭდეების შესახებ, შეიძლება შემოწმება, რომლებიც ჩვენი მეტი შეიძლება გავაკეთება, როდესაც ჩვენ გვაქვს მხოლოდ კონცექტი ან სიტყვის სიტყვის შემდეგ, როცა MFS მეტი მოჭირდება პარალელი კორპუსი და კორპუსს შემდეგება მეტი უნ', 'it': "In questo articolo, mostriamo come utilizzare le incorporazioni bilingue di parole (BWE) per creare automaticamente una tabella corrispondente di tag di significato da due dizionari in una lingua ed esaminare l'efficacia del metodo. Per fare questo, abbiamo avuto un problema: i tag di significato non sempre corrispondono uno a uno perché le granularità della parola sensi e i concetti sono diversi l'uno dall'altro. Pertanto, abbiamo considerato il tag concetto che corrisponde di più ad un senso di parola come il tag concetto corretto corrispondente al senso di parola. Abbiamo utilizzato due metodi BWE, una matrice di trasformazione lineare e VecMap. Abbiamo valutato il metodo dei sensi più frequenti (MFS) e il metodo della concatenazione del corpo per il confronto. L'accuratezza dei metodi proposti era superiore all'accuratezza del basale casuale, ma inferiore a quella dei metodi MFS e di concatenazione del corpo. Tuttavia, poiché il nostro metodo utilizzava i vettori di incorporazione dei sensi di parola, le relazioni dei tag di senso corrispondenti ai tag di concetto potrebbero essere esaminate mappando gli incorporamenti di senso allo spazio vettoriale dei tag di concetto. Inoltre, i nostri metodi potrebbero essere eseguiti quando abbiamo solo incorporazioni di senso concettuale o parola, mentre il metodo MFS richiede un corpus parallelo e il metodo di concatenazione del corpus necessita di due corpi taggati.", 'lt': 'Šiame dokumente parodomi, kaip naudoti dvikalbį žodžių įdėjimą (BWE), kad automatiškai sukurtume atitinkamą reikšmės žymenų lentelę iš dviejų žodynų vienoje kalboje ir išnagrinėtume metodo veiksmingumą. To do this, we had a problem: the meaning tags do not always correspond one-to-one because the granularities of the word senses and the concepts are different from each other.  Todėl manome, kad sąvokos ženklas, atitinkantis žodžio jausmą, labiausiai yra teisingas sąvokos ženklas, atitinkantis žodžio jausmą. Naudojome du BWE metodus, linijinę transformacijos matricą ir VecMap. Vertinome dažniausią jutimo (MFS) metodą ir corpus concatenation metodą palyginimui. Siūlomų metodų tikslumas buvo didesnis nei atsitiktinio pradinio lygio tikslumas, bet mažesnis nei MFS ir korpus sutraukimo metodų tikslumas. Vis dėlto, kadangi mūsų metodas naudojo žodžio jutimų įterpimo vektorius, jutimo žymenų, atitinkančių koncepcinius žymenus, santykiai galėtų būti išnagrinėti mapuojant jutimo įterpimus į koncepcinių žymenų vektorių erdvę. Be to, mūsų metodai galėtų būti atliekami, kai turime tik koncepcijos ar žodžio jutimo įdėjimus, o MFS metodas reikalauja paralelinio korpuso, o korpuso sutvirtinimo metodas reikalauja dviejų pažymėtų korprų.', 'mk': 'Во оваа хартија, покажуваме како да се користат двојјазични зборови вградени (БWE) за автоматски да се создаде соодветна табела со значење ознаки од два речници на еден јазик и да се провери ефективноста на методот. To do this, we had a problem: the meaning tags do not always correspond one-to-one because the granularities of the word senses and the concepts are different from each other.  Затоа, ние го сметавме концептскиот тег кој се совпаѓа со зборно чувство најмногу како точниот концептен тег кој се совпаѓа со зборното чувство. Користевме два методи, линијарна трансформациска матрица и ВеcMap. Го проценивме методот на најчестото чувство (МФС) и методот на корпус концентрација за споредба. Точноста на предложените методи беше повисока од точноста на случајната основа, но пониска од методите на МФС и корпус концентрација. Сепак, бидејќи нашиот метод ги искористи вградените вектори на зборовите сензии, односите на сензиите ознаки кои одговараат на концептните ознаки може да се испитаат со мапирање на сензиите вградени во векторниот простор на концептните ознаки. Исто така, нашите методи би можеле да се извршат кога имаме само концепт или зборно чувство вградени додека методот на МФС бара паралелен корпус и методот на корпус концентрација има потреба од две обележани корпуси.', 'kk': 'Бұл қағазда, бір тілде екі сөздердің тегтерін автоматты түрде құру үшін, екі сөздердің тегтерін қалай қолдануға (BWE) қолданып, әдісінің эффективностін тексеру үшін көрсетеді. Бұл істеу үшін бізде мәселе болды: мәлімет тегтері әрқашан бір-біріне сәйкес келмейді, себебі сөздің грануляриясы мен концепциялары бір-бірінен айырмалы. Сондықтан біз сөздердің сезіміне сәйкес келетін концепциялық тегті сөздердің сезіміне сәйкес келеді. Біз екі BWE әдісін қолдандық, сызық түрлендіру матрицасы және VecMap. Біз салыстыру үшін ең көптеген сезім (MFS) әдісін және корпус салыстыру әдісін бағаладық. Келтірілген әдістердің дұрыстығы кездейсоқ негізгі жолдың дұрыстығынан артық, бірақ MFS және корпус сәйкестік әдістерінен артық. Бірақ, өйткені біздің әдіміз сөздің сезімдерінің ендіру векторларын қолдану үшін, концепциялық тегтеріне сәйкес келетін сезім тегтерінің қасиеттерін тексеруге болады. Мұндай-ақ, біздің әдістеріміз тек концепция не сөз сезіміздің ендіруі болса, бірақ MFS әдісі параллелі корпус және корпус сәйкестік әдісінің екі тегтеген корпора қажет етеді.', 'ms': 'Dalam kertas ini, kita tunjukkan bagaimana menggunakan penyembedding perkataan dua bahasa (BWE) untuk secara automatik mencipta jadual yang sepadan dengan tag makna dari dua kamus dalam satu bahasa dan memeriksa kegunaan kaedah. Untuk melakukan ini, kita mempunyai masalah: tag maknanya tidak sentiasa sepadan satu dengan satu kerana granulariti perasaan perkataan dan konsep berbeza antara satu sama lain. Oleh itu, kami mempertimbangkan tag konsep yang sepadan dengan perasaan perkataan yang paling sebagai tag konsep yang betul yang sepadan dengan perasaan perkataan. Kami menggunakan dua kaedah BWE, matriks pengubahan linear dan VecMap. Kami menilai kaedah perasaan yang paling sering (MFS) dan kaedah persamaan corpus untuk perbandingan. The accuracies of the proposed methods were higher than the accuracy of the random baseline but lower than those of the MFS and corpus concatenation methods.  However, because our method utilized the embedding vectors of the word senses, the relations of the sense tags corresponding to concept tags could be examined by mapping the sense embeddings to the vector space of the concept tags.  Juga, kaedah kita boleh dilakukan apabila kita hanya mempunyai konsep atau penyelesaian perkataan sementara kaedah MFS memerlukan corpus selari dan kaedah penyelesaian corpus memerlukan dua corpora ditanda.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d രണ്ടു ഭാഷ വാക്കുകള്\u200d ഉപയോഗിക്കുന്നത് എങ്ങനെയാണെന്ന് കാണിക്കുന്നു. അതിന്റെ പ്രഭാഷയില്\u200d നിന്നും രണ്ട് നിഘണ്ടാരില്\u200d നിന്നും ഒര ഇത് ചെയ്യാന്\u200d ഞങ്ങള്\u200dക്ക് ഒരു പ്രശ്നമുണ്ടായി അതുകൊണ്ട്, ഒരു വാക്കിന് സമ്മതിക്കുന്ന കാര്യത്തിന്റെ കാര്യത്തില്\u200d ഞങ്ങള്\u200d വിചാരിച്ചു, വാക്കിന്റെ മനസ്സിന് ഏറ്റവും ശരിയ We used two BWE methods, a linear transformation matrix and VecMap.  നമ്മള്\u200d ഏറ്റവും പ്രാവശ്യം മനസ്സിന്റെ (എംഎഫ്\u200cഎസ്) രീതിയെയും കോര്\u200dപ്പൂസിന്റെ കോണ്\u200dക്കെന്റേഷന്\u200d രീതിയെയും പരിഗ നിര്\u200dദ്ദേശിക്കപ്പെട്ട മാര്\u200dഗ്ഗങ്ങളുടെ കൃത്യം കുറഞ്ഞിരിക്കുന്നതിനെക്കാള്\u200d കൂടുതല്\u200d ഉയര്\u200dന്നിരുന്നു. പക്ഷെ എംഎഫ്.എസ എന്നാലും, നമ്മുടെ രീതി വാക്കുകളുടെ ഉള്\u200dപ്പെടുത്തുന്ന വെക്റ്റര്\u200d ഉപയോഗിച്ചത് കൊണ്ടാണ്, കണ്ടിട്ടുള്ള ടാഗുകളുടെ ബന്ധങ്ങള്\u200d പരിശോധിക്കാന്\u200d സാധിക്കുന്നത നമ്മുടെ രീതികളും പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d സാധിക്കുമായിരുന്നു. നമുക്ക് ആശയം മാത്രമോ വാക്കുകള്\u200d മാത്രമോ ഉള്\u200dപ്പെടുമ്പോള്\u200d മാത്രം മാത്രം മാത്', 'mn': 'Энэ цаасан дээр бид хоёр хэл хэлний нэвтрүүлэлтийг хэрхэн ашиглах вэ гэдгийг харуулж, нэг хэл дээр хоёр сөрөгчийн нэвтрүүлэлтийг автоматаар бүтээж, арга замын үр дүнг шалгаж үзүүлж байна. Үүнийг хийхийн тулд бидэнд асуудал байсан. Яагаад гэвэл тэмдэгүүд үргэлж нэг-нэгтэй холбоотой байхгүй. Учир нь үгийн мэдрэмж, ойлголтын гранулацууд хоорондоо холбоотой. Тиймээс бид үгийн мэдрэмжтэй харьцуулдаг ойлголтын тэгшитгэлийг илүү зөв ойлголтын тэгшитгэл гэж үзсэн. Бид хоёр BWE арга, шулуун шилжүүлэлтийн матриц болон VecMap ашигласан. Бид хамгийн ихэвчлэн мэдрэмж (MFS) аргыг, харьцуулахын тулд корпус тодорхойлолтын аргыг үнэлдэг. Өөрчлөгдсөн аргын тодорхойлолт нь санамсаргүй үндсэн шугамын тодорхойлолтоос илүү өндөр, гэхдээ MFS болон Корпус тодорхойлолтын аргын тодорхойлолтоос илүү бага байсан. Гэхдээ бидний арга нь үгийн мэдрэмжийн интервентүүдийг ашиглаж байсан учир нь ойлголтын тегтэй холбоотой мэдрэмжийн тегтэй холбоотой мэдрэмжийн тегтэй холбоотой холбоотой байдал нь ойлголтын тегтэй векторын зай руу газрын зура Мөн бидний арга нь зөвхөн ойлголт эсвэл үг мэдрэмжтэй холбоотой байх үед хийж болно. Гэхдээ MFS арга нь параллел корпус болон корпус холбоотой хоёр холбоотой корпора хэрэгтэй.', 'no': 'I denne papiret viser vi korleis du skal bruka bilinguelt ordinnbygging (BWE) for å automatisk oppretta ei tilsvarande tabell med meningsmerker frå to ordbokar i eitt språk og undersøka effektiviteten av metoden. For å gjøre dette, hadde vi eit problem: betydningane er ikkje alltid samsvarande med ein til ein, fordi granularitetene av ordsensane og konseptane er ulike frå kvarandre. Det er derfor vi sett opp konseptetiketten som tilsvarar ei ordfølelse som den mest rette konseptetiketten som tilsvarar ordfølelsen. Vi brukte to BWE-metodar, ein lineær transformeringsmatris og VecMap. Vi evaluerte den mest ofte følelsesmetoden (MFS) og korpussamlingsmetoden for sammenlikning. Den første metodane er nøyaktigheten høgare enn nøyaktigheten av tilfeldige baseline, men mindre enn dei MFS- og corpus- samsvarmetodane. Men fordi metoden vårt brukte innbyggingsvektorane i ordsensane, kan forholdet til sentraletiketane som passar til konseptetiketane eksaminerast ved å kartera sentralinnbygginga til vektorplassen i konseptetiketane. Metodane våre kan også utførast når vi har berre konsept eller ordfølelse innebygging, mens MFS-metoden krev ein parallell korpus og korpussamlingsmetoden treng to merkte korpora.', 'pl': 'W niniejszym artykule pokazujemy, jak wykorzystać dwujęzyczne osadzenia słów (BWE) do automatycznego tworzenia odpowiedniej tabeli znaczników z dwóch słowników w jednym języku i zbadać skuteczność metody. Aby to zrobić, mieliśmy problem: znaczniki znaczeniowe nie zawsze odpowiadają indywidualnie, ponieważ granularność słowa zmysły i pojęcia różnią się od siebie. Dlatego też uznaliśmy tag koncepcyjny, który najbardziej odpowiada sensowi słowa, za prawidłowy tag koncepcyjny odpowiadający sensowi słowa. Zastosowaliśmy dwie metody BWE, liniową macierzę transformacji oraz VecMap. Do porównania oceniono metodę najczęstszego sensu (MFS) oraz metodę łączenia korpusów. Dokładność proponowanych metod była wyższa niż dokładność losowego wyjścia, ale niższa niż dokładność metod MFS i łączenia korpusów. Ponieważ jednak nasza metoda wykorzystała wektory osadzania zmysłów słowa, relacje znaczników sense odpowiadających tagom koncepcyjnym mogłyby być zbadane poprzez mapowanie osadzeń sense do przestrzeni wektorowej tagów koncepcyjnych. Nasze metody mogą być również wykonywane, gdy mamy tylko osadzenia koncepcyjne lub słowowe, podczas gdy metoda MFS wymaga korpusu równoległego, a metoda łączenia korpusów wymaga dwóch oznaczonych korpusów.', 'mt': 'F’dan id-dokument, a ħna nuru kif għandna nużaw l-inkorporazzjonijiet bil-kliem bilingwi (BWE) biex awtomatikament to ħloq tabella korrispondenti ta’ tikketti tat-tifsira minn żewġ dikjaraturi f’lingwa waħda u teżamina l-effettività tal-metodu. Biex nagħmlu dan, kellna problem a: it-tikketti tat-tifsira mhux dejjem jikkorrispondu wieħed għal ieħor minħabba li l-granularitajiet tas-sensi tal-kelma u l-kunċetti huma differenti minn xulxin. Għalhekk, ikkunsidrajna t-tikketta tal-kunċett li tikkorrispondi għal sens tal-kelma l-aktar bħala t-tikketta tal-kunċett korretta li tikkorrispondi għas-sens tal-kelma. Użajna żewġ metodi BWE, matriċi ta’ trasformazzjoni lineari u VecMap. Aħna evalwajna l-metodu tas-sens l-aktar frekwenti (MFS) u l-metodu ta’ konċentrazzjoni corpus għat-tqabbil. Il-preċiżjonijiet tal-metodi proposti kienu ogħla mill-preċiżjoni tal-linja bażi aleatorja iżda inqas minn dawk tal-MFS u l-metodi ta’ konċentrazzjoni corpus. Madankollu, minħabba li l-metodu tagħna uża l-vetturi tal-inkorporazzjoni tas-sensi tal-kelma, ir-relazzjonijiet tat-tags tas-sens li jikkorrispondu mat-tags tal-kunċett jistgħu jiġu eżaminati billi jiġu mmappjati l-inkorporazzjonijiet tas-sens fl-ispazju tal-vetturi tat-tags tal-kunċett. Barra minn hekk, il-metodi tagħna jistgħu jitwettqu meta jkollna biss kunċett jew inkorporazzjonijiet ta’ sens tal-kelma filwaqt li l-metodu MFS jeħtieġ korpus parallelu u l-metodu ta’ konċentrazzjoni corpus jeħtieġ żewġ korpuri bit-tikketta.', 'ro': 'În această lucrare, vom arăta cum se utilizează încorporarea bilingvă de cuvinte (BWE) pentru a crea automat un tabel corespunzător de etichete de semnificație din două dicționare într-o singură limbă și a examina eficacitatea metodei. Pentru a face acest lucru, am avut o problemă: etichetele de semnificație nu corespund întotdeauna unu-la-unu, deoarece granularitatea simțurilor cuvântului și conceptele sunt diferite una de alta. Prin urmare, am considerat eticheta conceptului care corespunde cel mai mult unui sens de cuvânt ca eticheta conceptului corect corespunzătoare cuvântului sens. Am folosit două metode BWE, o matrice de transformare liniară și VecMap. Am evaluat metoda simțului cel mai frecvent (MFS) și metoda concatenării corpului pentru comparație. Precizia metodelor propuse a fost mai mare decât acuratețea inițială aleatorie, dar mai mică decât cea a metodelor MFS și a metodelor de concatenare a corpului. Cu toate acestea, deoarece metoda noastră a utilizat vectorii de încorporare ai simțurilor cuvântului, relațiile etichetelor de simț corespunzătoare etichetelor de concept au putut fi examinate prin maparea încorporărilor de simțuri cu spațiul vectorial al etichetelor de concept. De asemenea, metodele noastre ar putea fi efectuate atunci când avem doar încorporări de sens conceptual sau cuvânt, în timp ce metoda MFS necesită un corpus paralel, iar metoda de concatenare a corpului necesită două corpuri etichetate.', 'sr': 'U ovom papiru pokazujemo kako da koristimo dvojezičke reči ugrađenje (BWE) kako bi automatski stvorili odgovarajući stol znakova znakova iz dva rečnika na jednom jeziku i pregledali učinkovitost metode. Da bismo to uradili, imali smo problem: znači znakovi ne odgovaraju uvijek jednom na drugom jer granularitija riječi čula i koncept su drugačiji od drugog. Stoga smo smatrali oznaku koncepta koja odgovara reèima najboljem kao taèni oznaku koncepta koji odgovara osjeæaju reèi. Koristili smo dve metode BWE, linearnu transformaciju matricu i VecMap. Procjenjivali smo najčešću metodu smisla (MFS) i metodu usklađenja korpusa za usporedbu. Tačnost predloženih metoda je bila veća od tačnosti nasumične početne linije, ali niže od metoda usklađenja MFS-a i korpusa. Međutim, zato što je naša metoda iskoristila ugrađene vektore riječi čula, odnosi osjećajnih znakova odgovarajućih znakovima koncepta mogli bi biti ispitani mapiranjem osećajnih ugrađenja u vektorski prostor znakova koncepta. Takoðe, naše metode bi mogle biti izvršene kada imamo samo koncept ili oseæaj reèi, dok metod MFS zahteva paralelni korpus i metod usklađenja korpusa treba dve označene korpuse.', 'so': 'Kanu warqaddan waxaan tusnaynaa sida loo isticmaalayo hadalka labada luqadood (BWE) si aan automatic u abuurno miis macnaheedka looga dhigo labada luqadood oo ku qoran isku luqad kadibna baaritaan waxqabadka qaababka. Tan darteed dhibaato baannu haysannay: marxaladda waxyaabaha ay leedahay marwalba midka kale looma dhigo, sababtoo ah xuquuqda hadalka iyo fikrada midka kale way ka duwan yihiin. Sidaa darteed waxaynu ka fiirsannay alaabta fikrada oo ku habboon hadalka, taas oo ah calaamada saxda ah oo u eg maanka ereyga. Waxaynu isticmaalnay laba qaab oo BWE ah, marrix sawir ah iyo VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison.  Heexarada qaababka la soo jeeday waxay ka sarreen saxda hoose ee habaarka, laakiin waa ka yar yihiin qaababka ku saabsan MFS iyo corpus. Si kastaba ha ahaatee, sababtoo ah qaababkayagu wuxuu isticmaali karaa qalabka waxyaabaha leh, xiriirka alaabta maandooriyaha oo u eg alaabta fikrada waxaa lagu baarayn karaa sawirada waxyaabaha ku socota goobta wadiiqooyinka. Sidoo kale waxaa la sameyn karaa qaababkayaga markaynu hayno fikrada ama hadalka oo kaliya, marka qaabka MFS uu u baahan yahay mid lambar ah iyo habka korpuska uu u baahan yahay laba korpora oo la tago.', 'sv': 'I denna uppsats visar vi hur man använder tvåspråkiga ordinbäddningar (BWE) för att automatiskt skapa en motsvarande tabell med betydelsetaggar från två ordböcker på ett språk och undersöka hur effektiv metoden är. För att göra detta hade vi ett problem: betydelsetaggarna motsvarar inte alltid en-till-en eftersom granulariteten i ordet sinnen och begreppen skiljer sig från varandra. Därför betraktade vi koncepttaggen som motsvarar en ordkänsla mest som den korrekta koncepttaggen som motsvarar ordet mening. Vi använde oss av två BWE-metoder, en linjär transformationsmatris och VecMap. Vi utvärderade den vanligaste sensmetoden (MFS) och corpus concatenation metoden för jämförelse. De föreslagna metodernas noggrannhet var högre än noggrannheten i den slumpmässiga baslinjen men lägre än metoderna för MFS och corpus concatenation. Men eftersom vår metod använde sig av inbäddningsvektorer av ordet sinnen, kunde relationerna mellan sensetaggarna motsvarande koncepttaggar undersökas genom att kartlägga sensetaggarna till vektorutrymmet hos koncepttaggarna. Våra metoder kan också utföras när vi bara har koncept- eller ordsensensinbäddningar medan MFS-metoden kräver en parallell korpus och corpuskoncentrationsmetoden kräver två taggade korpus.', 'si': 'මේ පත්තරේ අපි පෙන්වන්නේ කොහොමද දෙවල් භාෂාවක් භාෂාව (BWE) භාෂාව භාවිත කරන්නේ ස්වයංක්\u200dරමයෙන් සම්බන්ධ වෙන්න තේජ් එකක්  මේක කරන්න, අපිට ප්\u200dරශ්නයක් තිබුණා: අදහස් ටැග් හැමවෙලේම එකක් එකක් එකක් එකක් එකක් එකක් එකක් එකක් එකක් නැහැ මොකද වචනයේ අදහස් සහ අදහස ඉතින්, අපි බලාපොරොත්තු විදිහට ප්\u200dරතිචාරයක් හිතන්නේ වචනයක් වගේ විදිහට ප්\u200dරතිචාරයක් විදිහට අනුව අපි BWE විධානයක් දෙකක් භාවිතා කරනවා, ලේනියර් වෙනස් මැට්\u200dරික්ස් සහ VecMap එකක්. අපි ගොඩක් ප්\u200dරමාණයක් තේරුම් ගත්තා (MFS) විධානය සහ කොර්පස් සම්පූර්ණ විධානය සම්පූර්ණ විධ ප්\u200dරතිචාරිත විධානයේ සැකසුම් විධානයට වඩා වැඩියි, ඒත් MFS සහ කොර්පුස් සම්බන්ධ විධානයට වඩා අඩුයි. නමුත්, අපේ විධානය සම්බන්ධ වෙක්ටර් වචන සැකසුම් වලින් සම්බන්ධ වෙක්ටර් වලින් භාවිත කරලා තියෙන්නේ, සැකසුම් ටැග් වලින් සම්බන් ඒවගේම, අපේ විධානය කරන්න පුළුවන් විතරයි අපිට පරීක්ෂණයක් නැත්නම් වචනයක් තියෙනවා කියලා, ඒ වගේම MFS විධානය සමාන්\u200dය කොර්පස් එක', 'ta': 'இந்த காகிதத்தில், நாம் எவ்வாறு இரு மொழி வார்த்தையை பயன்படுத்த வேண்டும் என்பதை காட்டுகிறோம் என்பதை தானாகவே ஒரு ஒத்திரை அட்டவணை உருவாக்குவதற்காக ஒரு  இதை செய்வதற்கு, நம்மிடம் ஒரு பிரச்சனை இருந்தது: அதாவது அட்டைகள் எப்போதும் ஒன்றுக்கு ஒத்திசைக்க மாட்டார்கள் ஏனென்றால் வார்த்தையின்  எனவே, நாங்கள் ஒரு வார்த்தைக்கு ஒப்புக்கொள்ளும் கருத்து குறியீட்டை பார்த்தோம் என்று சரியான கருத்து குறியீடு சொ நாங்கள் இரண்டு BWE முறைமைகளை பயன்படுத்தினோம், ஒரு கோடு மாற்றம் மாற்றம் மத்தியில் மற்றும் வெக்வரைபடம். நாங்கள் ஒப்பிடும் முறையில் மிகவும் அதிகமான உணர்வு (MFS) முறையையும் கார்ப்ஸ் கூட்டல் முறை முன்நிர்ணயிக்கப்பட்ட முறைமைகளின் திருத்தம் குறிப்பில்லாத அடிப்படைக்கோட்டின் சரியை விட அதிகமாக இருந்தது ஆனால் MFS மற்று ஆயினும், ஏனென்றால் எங்கள் முறைமை வார்த்தைகளின் உள்ளிடும் வெக்டார்களை பயன்படுத்தி, கருத்து ஒட்டுகளுக்கு பொருந்தும் உணர்வு குறிகளின் தொடர்புகளை வரைபடத்த மேலும், நம்முடைய முறைமைகள் செயல்படுத்தலாம் நாம் மட்டும் கருத்து அல்லது வார்த்தை உணர்வு உள்ளடக்கும் போது மட்டும் அல்லது சொல்லும் பொழுது முறையி', 'ur': 'اس کاغذ میں ہم دکھاتے ہیں کہ دو زبان کی کلمات ابڈینگ (BWE) کا استعمال کیسا کرنا ہے تاکہ ایک زبان میں دو لکھنے کے ٹاگ کے مطابق مطابق کے ٹاگ بنائیں اور روش کے مطابق کی تحقیق کریں. یہ کام کرنے کے لئے، ہمارے پاس ایک مشکل تھا: معنی ٹاگ ہمیشہ ایک دوسرے کے مطابق نہیں ہے کیونکہ کلمز کے گرانولاریٹ ایک دوسرے سے مختلف ہیں۔ لہٰذا ہم نے سمجھ لیا تھا کہ ایک کلمہ کے مطابق ایک کلمہ کے مطابق بہترین سمجھ کا ٹاگ ہے جو کلمہ سمجھ کے مطابق ہے۔ ہم نے دو BWE روش استعمال کیا، ایک linear transformation matrix اور VecMap. ہم نے بہترین سمجھ (MFS) روش اور مقایسہ کے لئے corpus concatenation روش کا ارزش کیا۔ پیشنهاد کی طریقوں کی دقیقیقیت ایسی طریقوں سے زیادہ بلند تھی جن کے مطابق غیر طریقے کی دقیقیقیت سے بلند تھی لیکن MFS اور corpus concatenation طریقوں سے زیادہ کم تھی. لیکن، کیونکہ ہمارا طریقہ کلمہ سنس کے انڈینگ ویکتروں کو استعمال کیا گیا ہے، سمجھ ٹاگ کے معاملہ میں مفصل ٹاگ کے معاملہ میں مصاحب ہونے کے ذریعہ مصاحب حس انڈینگ کی جگہ پر مصاحب ہوسکتا ہے. اور ہمارے طریقے صرف نظریہ یا کلمات سمجھ کے مطابق عمل کیے جاتے ہیں حالانکہ MFS طریقے ایک parallel corpus کی ضرورت کرتی ہے اور corpus concatenation طریقے کے دو ٹاگڈ کرپور کی ضرورت ہے.', 'uz': "Bu hujjatda biz bir lugʻatdagi so'zlar (BWE) dan foydalanishni avtomatik avtomatik ikki lugʻatdan bir lugʻatdagi bog'liq taglarni yaratish va usulning effektligini tekshirish. Bunday qilish uchun bizda muammo bo'lgan: taglar har doim birga bir-бирga bog'liq emas chunki so'zlar hissiyotlari va g'oyalar bir-bir birga bir-бирga bog'liq. Shunday qilib, biz bir so'zning ma'lumotiga bog'liqchi fikr tegi so'zni o'xshash mumkin. Biz ikkita BWE usuldan foydalanamiz, liner o'zgartirish matrikasi va VecMap. Biz ko'p ko'pincha ma'lumotni (MFS) usulini ko'rib chiqardik va ko'paytirish usulini qiymatdik. Aniqlanadigan usullarning tasdiqligini tasdiqlash mumkin, ammo MFS va corpus koʻpaytirish usullarining qiymatidan kamaytirish mumkin. Lekin, chunki bizning usuli so'zning tuzilishini foydalanuvchi vektoridan foydalanadi, concept teglariga murakkab boʻlgan ma'lumotning ma'lumotlarini koʻpaytirish mumkin. Also, our methods could be performed when we have only concept or word sense embeddings whereas the MFS method requires a parallel corpus and the corpus concatenation method needs two tagged corpora.", 'vi': 'Trong tờ giấy này, chúng tôi chỉ cách sử dụng sự nhúng vào từ hai thứ hai (nghĩa trang) để tự động tạo một bảng tương ứng với các thẻ nghĩa từ hai từ điển trong một ngôn ngữ và kiểm tra hiệu quả của phương pháp. Để làm được điều này, chúng ta có một vấn đề: các thẻ nghĩa không phải luôn tương ứng một với một vì các độ hạt của các giác quan từ và các khái niệm khác nhau. Do đó, chúng tôi coi một thẻ khái niệm tương ứng với một ý nghĩa từ nhiều nhất là một thẻ khái niệm chính xác tương ứng với ý nghĩa từ. Chúng tôi đã dùng hai phương pháp BKA, một ma trận chuyển dạng tuyến và Vectron. Chúng tôi đã đánh giá phương pháp cảm nhận thường xuyên nhất (MFS) và phương pháp tập hợp để so sánh. Sự chính xác của các phương pháp đã được đề xuất còn cao hơn độ chính xác của cơ sở cơ bản ngẫu nhiên nhưng thấp hơn so với các phương pháp Sắp xếp cấu trúc nhiều nhất. Tuy nhiên, vì phương pháp của chúng tôi sử dụng các véc- tơ của các giác quan, quan hệ của các thẻ cảm giác tương ứng với các thẻ khái niệm có thể được kiểm tra bằng cách vẽ sơ đồ các sự nhúng vào chi tiết của các thẻ khái niệm. Hơn nữa, phương pháp của chúng ta có thể được thực hiện khi chúng ta chỉ có sự nhúng đầu vào ý nghĩa từ hoặc khái niệm trong khi phương pháp MFS cần một tập thể song song và phương pháp kết hợp tập thể chứa cần hai nhóm gắn thẻ.', 'bg': 'В тази статия показваме как да използвате двуезични вграждания на думи, за да създадете автоматично съответна таблица със значения тагове от два речника на един език и да изследвате ефективността на метода. За да направим това, имахме проблем: значението на таговете не винаги съответства един към един, защото гранулираността на думата сетива и понятията са различни един от друг. Ето защо разглеждаме концептуалния таг, който най-много съответства на думично значение, като правилния концепционен таг, съответстващ на думичното значение. Използвахме два метода, линейна трансформационна матрица и VecMap. Оценихме метода на най-честия смисъл (МФС) и метода на корпусната конкатенация за сравнение. Точността на предложените методи е по-висока от точността на случайната базова база, но по-ниска от тази на МФС и методите за конатенация на корпуса. Въпреки това, тъй като методът ни използва вграждащите вектори на думичните сетива, отношенията на сетивните тагове, съответстващи на концептуалните тагове, могат да бъдат изследвани чрез картографиране на сетивните вграждания към векторното пространство на концептуалните тагове. Също така, нашите методи могат да бъдат изпълнени, когато имаме само концепции или словесен смисъл, докато методът изисква паралелен корпус, а методът на корпуса конкатенация се нуждае от две маркирани корпуси.', 'nl': 'In dit artikel laten we zien hoe je tweetalige woord embeddings (BWE) gebruikt om automatisch een overeenkomstige tabel met betekenistags te maken uit twee woordenboeken in één taal en de effectiviteit van de methode te onderzoeken. Om dit te doen hadden we een probleem: de betekeningstags komen niet altijd één-op-één overeen omdat de granulariteit van het woord zintuigen en de begrippen van elkaar verschillen. Daarom beschouwden we de concepttag die het meest overeenkomt met een woordzin als de juiste concepttag die overeenkomt met de woordzin. We gebruikten twee BWE methoden, een lineaire transformatiematrix en VecMap. We evalueerden de meest frequent sense (MFS) methode en de corpus concatenation methode voor vergelijking. De nauwkeurigheid van de voorgestelde methoden was hoger dan de nauwkeurigheid van de random baseline, maar lager dan die van de MFS- en corpusaanzettingsmethoden. Omdat onze methode echter de insluitingsvectoren van de woordzintuigen gebruikte, konden de relaties van de sense tags die overeenkomen met concepttags worden onderzocht door de sense insluitingen in kaart te brengen met de vectorruimte van de concepttags. Ook kunnen onze methoden worden uitgevoerd wanneer we alleen concept of woordzin embeddingen hebben, terwijl de MFS methode een parallel corpus vereist en de corpus aaneenschakeling methode twee getaggte corpora nodig heeft.', 'da': 'I denne artikel viser vi, hvordan man bruger tosprogede ordindlejringer (BWE) til automatisk at oprette en tilsvarende tabel med betydningsmærker fra to ordbøger på ét sprog og undersøge effektiviteten af metoden. For at gøre dette havde vi et problem: Betydningsmærkerne svarer ikke altid en-til-en, fordi granulariteten af ordet sanser og begreberne er forskellige fra hinanden. Derfor betragtede vi det begrebsmærke, der svarer til en ordsans mest som det korrekte begrebsmærke, der svarer til ordet sans. Vi brugte to BWE metoder, en lineær transformationsmatrix og VecMap. Vi evaluerede den hyppigste sansemetode (MFS) og corpus concatenation metoden til sammenligning. Nøjagtigheden af de foreslåede metoder var højere end nøjagtigheden af den tilfældige baseline, men lavere end nøjagtigheden af MFS- og corpus-sammenkædningsmetoderne. Men fordi vores metode anvendte indlejringsvektorer af ordet sanser, kunne relationerne mellem sanse tags svarende til koncepttags undersøges ved at kortlægge sanse indlejringer til vektorrummet af koncepttags. Vores metoder kunne også udføres, når vi kun har begrebs- eller ordsans-indlejringer, mens MFS-metoden kræver en parallel korpus og corpus-sammenkoblingsmetoden kræver to taggede korpus.', 'de': 'In diesem Beitrag zeigen wir, wie man mithilfe zweisprachiger Worteinbettungen (BWE) automatisch aus zwei Wörterbüchern in einer Sprache eine entsprechende Tabelle von Bedeutungstabellen erstellt und die Wirksamkeit der Methode untersucht. Dazu hatten wir ein Problem: Die Bedeutungstags entsprechen nicht immer eins zu eins, weil sich die Granularitäten der Wortsinne und der Konzepte voneinander unterscheiden. Daher betrachteten wir das Concept-Tag, das einem Wortsinn am meisten entspricht, als das richtige Concept-Tag, das dem Wortsinn entspricht. Wir verwendeten zwei BWE-Methoden, eine lineare Transformationsmatrix und VecMap. Zum Vergleich haben wir die häufigste Sinnesmethode (MFS) und die Korpusverkettungsmethode evaluiert. Die Genauigkeit der vorgeschlagenen Methoden war höher als die Genauigkeit der Zufallsbasis, aber niedriger als die der MFS- und Korpusverkettungsmethoden. Da unsere Methode jedoch die Einbettungsvektoren der Wortsinne verwendete, konnten die Beziehungen der Sense-Tags untersucht werden, die Concept-Tags entsprechen, indem die Sense-Einbettungen auf den Vektorraum der Concept-Tags abgebildet werden. Außerdem könnten unsere Methoden durchgeführt werden, wenn wir nur Konzept- oder Wortsinneinbettungen haben, während die MFS-Methode einen parallelen Korpus und die Korpusverkettungsmethode zwei getaggte Korpora benötigt.', 'hr': 'U ovom papiru pokazujemo kako koristiti dvojezičke riječi ugrađenje (BWE) kako bi automatski stvorili odgovarajući stol znakova znakova iz dvije riječi na jednom jeziku i pregledali učinkovitost metode. Da bismo to učinili, imali smo problem: značenje znakova ne uvijek odgovaraju jednom na drugom jer granularitija riječi čula i koncept su drugačiji od drugog. Stoga smo smatrali oznaku koncepta koja odgovara riječi osjećaju najviše kao ispravnu oznaku koncepta koja odgovara osjećaju riječi. Koristili smo dvije metode BWE, linearnu transformaciju matricu i VecMap. Procjenjivali smo najčešću metodu osjećaja (MFS) i metodu usklađenja korpusa za usporedbu. Tačnost predloženih metoda bila je veća od tačnosti nasumičnog početnog linije, ali niže od metoda zamjene MFS-a i korpusa. Međutim, zato što je naša metoda iskoristila ugrađene vektore riječi čula, odnosi osjećajnih znakova odgovarajućih znakovima koncepta mogli bi biti ispitani mapiranjem osjećajnih ugrađenja u vektorski prostor znakova koncepta. Također, naše metode bi se mogle izvršiti kada imamo samo koncept ili osjećaj riječi, dok metod MFS zahtijeva paralelni korpus i metod usklađenja korpusa treba dvije označene korpuse.', 'id': 'Dalam kertas ini, kami menunjukkan bagaimana menggunakan pembangunan kata dua bahasa (BWE) untuk secara otomatis menciptakan tabel yang sesuai dengan tag arti dari dua kamus dalam satu bahasa dan memeriksa efektif metode. Untuk melakukan ini, kita punya masalah: tag artinya tidak selalu sesuai satu dengan satu karena granularitas dari sens kata dan konsep berbeda satu sama lain. Therefore, we regarded the concept tag that corresponds to a word sense the most as the correct concept tag corresponding the word sense.  Kami menggunakan dua metode BWE, matriks transformasi linear dan VecMap. Kami mengevaluasi metode perasaan yang paling sering (MFS) dan metode concatenation corpus untuk perbandingan. Akurati metode yang diusulkan lebih tinggi dari akurasi dasar acak tapi lebih rendah dari metode MFS dan concatenation corpus. Namun, karena metode kami menggunakan vektor penyembedding dari sensor kata, hubungan tag sensor yang sesuai dengan tag konsep dapat diperiksa dengan memetakan penyembedding sensor ke ruang vektor dari tag konsep. Juga, metode kita bisa dilakukan ketika kita hanya memiliki konsep atau kata-kata sensor embedding sementara metode MFS memerlukan corpus paralel dan metode concatenation corpus memerlukan dua corpora tagged.', 'sw': 'Katika karatasi hii, tunaonyesha jinsi ya kutumia ujumbe wa maneno ya lugha mbili (BWE) kutengeneza meza inayomilikiwa na maana ya viungo viwili vya lugha moja na kutafiti ufanisi wa njia hiyo. Ili kufanya hivyo, tulikuwa na tatizo: maana ya alama hazijadilikana mara zote kwa sababu upendo wa hisia za neno na dhana hizo tofauti tofauti. Kwa hiyo, tuliangalia alama ya dhana ambayo ina maana ya neno zaidi kama alama sahihi inayolinganisha maana ya neno. Tulitumia mbinu mbili za BWE, matrix ya mabadiliko ya mstari na VecMap. Tumepima njia ya kawaida zaidi (MFS) na njia ya ushirikiano wa makampuni kwa kulinganisha. Ukweli wa mbinu zilizopendekezwa zilikuwa juu kuliko ukweli wa msingi wa asili lakini chini ya njia za kuunganisha MFS na makampuni. Hata hivyo, kwa sababu mbinu yetu ilitumia vectors zinazoingiza kwenye hisia za neno, uhusiano wa alama za maana yanayohusiana na alama za dhana unaweza kuchunguzwa kwa kuchora hisia zinazoingia kwenye nafasi ya vector ya viungo vya dhana. Pia, mbinu zetu zinaweza kutekelezwa wakati tuna dhana au maana ya maneno tu yanayoingia wakati mbinu za MFS zinahitaji viungo vinavyofanana na njia ya ushirikiano wa makampuni hiyo inahitaji kampuni mbili.', 'ko': '본고에서 우리는 이중 언어 단어 삽입(BWE)을 사용하여 한 언어의 두 사전에서 대응하는 의미 탭표를 자동으로 만드는 방법을 보여 주고 이 방법의 유효성을 검증했다.이를 위해 우리는 의미 표기가 항상 일일이 대응하는 것은 아니다. 왜냐하면 의미와 개념의 입도가 서로 다르기 때문이다.따라서 우리는 의미와 대응하는 개념 표기는 의미와 대응하는 정확한 개념 표기라고 생각한다.우리는 선형 변환 매트릭스와 벡터 매핑 두 가지 BWE 방법을 사용했다.우리는 가장 빈번한 의미(MFS) 방법과 자료 라이브러리 연결 방법을 비교했다.제시된 방법의 정확도는 무작위 기선의 정확도보다 높지만 MFS와 자료 라이브러리 연결 방법의 정확도보다 낮다.그러나 우리의 방법은 의미의 삽입 벡터를 이용했기 때문에 의미의 삽입을 개념 표기의 벡터 공간에 비추어 개념 표기와 대응하는 의미 표기 간의 관계를 검사할 수 있다.또한 우리의 방법은 개념이나 의미만 삽입된 상황에서 실행할 수 있고 MFS 방법은 평행 자료 라이브러리가 필요하며 자료 라이브러리 연결 방법은 두 개의 표기 자료 라이브러리가 필요하다.', 'tr': 'Bu kagyzda, biz iki dilde iki sözlerden nähili ulanmalydygyny (BWE) we bir dilde nähili möhüm tägleriň täglerini otomatik bilen bejermek üçin görkeýäris we munuň täsirini barlaýarys. Muny etmek üçin problemimiz bardy: etiketler hemişe bir-birine eşit etmezler çünki kelime duýgunlaryň granularitleri we düşünceleriň birbirinden farklı. Şol sebäpli, biz kelime duýguny nädogry düşünýän düşünjäniň etiketini kelime duýguny ýaly tans etdik. Biz iki BWE yöntemi, lineer bir transformasyon matrisi ve VecMap kullandık. Biz iň sık duýgularyň (MFS) yöntemini we karşılaştyrma yöntemini çykardyk. Teklip eden metodlaryň dogrylyklary tesadüf çizginiň dogrylygyndan ýokary, ýöne MFS we korpus sampli metodlarynyň dogrylygyndan ýokary. Fakat, bu yöntemimiz kelime senslerinin içeri giren vektörleri kullandı ve mantıklı etiketlere uygun duygusal etiketlerin ilişkilerini kontrol edebilirdi. Ayrıca, biziň yönlerimiz diňe düşünjümiz ya da kelime duýgulanmamyz bolan wagtynda işlenebilir. Bu yönlerde MFS metodamyz paralel korpus gerekli we korpusyň birleşme yöntemi iki etiketli korpora ihtiyacı var.', 'fa': 'در این کاغذ، ما نشان می دهیم چگونه استفاده از ابتدایی کلمه\u200cهای دوزبانی (BWE) برای ایجاد یک میز متناسب با معنی از دو کلمه\u200cهای معنی در یک زبان استفاده کنیم و چگونه فعالیت روش را تحقیق کنیم. برای انجام این کار، ما مشکلی داشتیم: این معنی که نقاشی ها همیشه با یکدیگر تعلق نمی کنند، زیرا granularities of the word senses and the concepts are different from each other. بنابراین، ما نقاشی مفهوم را که به یک کلمه متفاوت دارد، به عنوان نقاشی مفهوم درستی که به حس کلمه متفاوت دارد، نگاه کردیم. ما از دو روش BWE استفاده کردیم، یک ماتریکس تغییر خط و VecMap. ما بهترین روش حس (MFS) را ارزیابی کردیم و روش هماهنگی کورپوس را برای مقایسه کردن. دقیقات روش پیشنهاد بالاتر از دقیقات پایین تصادفی بود ولی پایین از روش\u200cهای هماهنگ MFS و corpus بودند. ولی، زیرا روش ما از ویکتورهای داخل کردن کلمه حس استفاده کرد، رابطه های نقاشی حس که مربوط به نقاشی نقاشی حس به فضای ویکتوری نقاشی مفهوم است می توانند تحقیق کنند. همچنین، روش\u200cهایمان می\u200cتواند انجام شود وقتی تنها مفهوم یا احساس کلمه داریم، در حالی که روش MFS نیاز به یک کورپوس parallel و روش هماهنگی کورپوس به دو شرکت لازم دارد.', 'sq': 'Në këtë letër, ne tregojmë si të përdorim përfshirjet e fjalëve dygjuhëse (BWE) për të krijuar automatikisht një tabelë korrespondente me etiketa kuptimi nga dy fjalorë në një gjuhë dhe të shqyrtojmë efektshmërinë e metodës. Për ta bërë këtë, ne kishim një problem: etiketat e kuptimit nuk korrespondojnë gjithmonë njëri-tjetrit sepse granularitetet e fjalës ndjenja dhe konceptet janë ndryshe nga njëri-tjetri. Prandaj, ne e konsideruam etiketën e konceptit që korrespondonte me një fjalë ndjenjë më së shumti si etiketën e konceptit korrekt që korrespondonte me fjalën ndjenjë. Ne përdorëm dy metoda BWE, një matricë transformimi linear dhe VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison.  Saktësia e metodave të propozuara ishte më e lartë se saktësia e bazës së rastësishme por më e ulët se ato të MFS dhe metodave të konkonkonkatenimit të korpusit. Megjithatë, për shkak se metoda jonë përdori vektorët e përfshirjes së ndjenjave të fjalës, marrëdhëniet e etiketave të ndjenjave që korrespondonin me etiketat e konceptit mund të shqyrtohen duke hartuar përfshirjet e ndjenjave në hapësirën e vektorit të etiketave të konceptit. Gjithashtu, metodat tona mund të kryehen kur ne kemi vetëm koncept apo fjalë kuptim përfshirje ndërsa metoda MFS kërkon një korpus paralel dhe metoda e ndërprerjes corpus ka nevojë për dy korpra të shënuara.', 'am': 'In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method.  ይህንን ለማድረግ ጉዳይ ነበረን፤ የቃላት ስህተት እና አሳብ እርስ በርሳቸው የተለየ ነው፡፡ ስለዚህም ለቃላት የሚያስተያየው የዓይነቱ መክፈት ቃላት ቃላትን የሚያስተያየው ጥሩ መክፈት ነው ብለን አየን፡፡ ሁለትን BWE methods, linear ለውጥ matrix እና VecMap. አካሄዱን እና የኮርፓስ ክፍለ ሥርዓት አስተያየትነው፡፡ በተዘጋጀው የሥርዓት ሥርዓት ከጥቅምነት ይልቅ ከፍተኛ ነው ነገር ግን ከMFS እና ከቆርፓስ ሥርዓቶች ይልቅ ትንሽ ነው፡፡ ምንም እንኳን፣ ምክንያቱም የእነዚህ ቃላት የስሜት መቃኛዎች የሚጠቀሙትን ማሰናከል በመጠቀም ምክንያት የሐሳብ ምልክቶች ግንኙነት ወደ አካሄሪው ቦታዎች የሚደርስ ስህተት በመስመር ይችላል፡፡ እናም የMFS ሥርዓት ተግባር እና የቆርፓስ ሥርዓት ሁለት ተለይቶ ኮርፖራ ያስፈልጋል፡፡', 'hy': 'Այս թղթի մեջ մենք ցույց ենք տալիս, թե ինչպես օգտագործել երկլեզու բառերի ներգրավումներ (BWE), որպեսզի ինքնաբերաբար ստեղծենք իմաստալից տախտակներ երկու բառարանից մեկ լեզվով և ուսումնասիրենք մեթոդի արդյունավետությունը: Սա անելու համար մենք խնդիր ունեինք. նշանակության նշանները միշտ չեն համապատասխանում մեկը մյուսին, որովհետև բառի զգացմունքների և գաղափարների գրանուլյարությունները միմյանց տարբերվում են: Այդ պատճառով, մենք դիտարկեցինք գաղափարի թեգը, որը համապատասխանում է բառի զգացմունքին, որպես ճիշտ գաղափարի թեգը, որը համապատասխանում է բառի զգացմունքին: Մենք օգտագործեցինք երկու BWE մեթոդ, գծային վերափոխման մատրիքսը և ՎեքMap: Մենք գնահատեցինք ամենահաճախ զգացմունքի (ՄՖՍ) մեթոդը և կորպոս համեմատության մեթոդը համեմատության համար: Պատրաստված մեթոդների ճշգրիտությունը ավելի բարձր էր, քան պատահական հիմքի ճշգրիտությունը, բայց ավելի ցածր, քան ՄՖՍ-ի և մարմնի համեմատական մեթոդների ճշգրիտությունը: Այնուամենայնիվ, քանի որ մեր մեթոդը օգտագործում էր բառի զգացմունքների ներգրավող վեկտորները, կարելի է ուսումնասիրել զգացմունքների հարաբերությունները, որոնք համապատասխանում են հասկացած թեգերին, քարտեզագրելով զգացմունքների ներգրավված զգացմունքները հասկացած թեգե Նաև, մեր մեթոդները կարող են իրականացվել, երբ մենք ունենք միայն գաղափար կամ բառի զգացողության ներդրումներ, մինչդեռ ՄՖՍ մեթոդը պահանջում է զուգահեռ կորպոս, իսկ կորպոս կոնկրետացիայի մեթոդը պահանջում է երկու մարմնի', 'az': 'Bu kağızda, iki dildən müəyyən bir məlumat etiketlərini və metodun etkinliğini öz-özünə təsdiqləmək üçün iki sözlük etiketlərinin necə istifadə etməsini göstəririk. Bunu etmək üçün bir problemimiz vardı: məsələlər hər zaman bir-birinə uyğun deyildir, çünki sözlərin granularitələri və məsələlər bir-birindən fərqli idilər. Beləliklə, sözlərin məlumatlarına uyğun məlumatların ən düzgün məlumatlarına uyğun məlumatlarını düşündük. Biz iki BWE metodlarını, linear transformasyon matriksini və VecMapsini kullandıq. Biz ən sık hiss (MFS) metodlarını və korpus müqayisəsi metodlarını salmaq üçün değerlendirdik. Təsdiq edilmiş metodların doğruluqları rastlaşdırılmış baseline doğruluğundan daha yüksəkdir, amma MFS və corpus birləşdirilməsi metodlarından daha aşağıdır. Lakin, bizim metodumuz sözlərin içərisində olan vektörlərini istifadə etdi, məlumat etiketlərinə uyğun hiss etiketlərin ilişkilerini məlumat etiketlərinə qovuşdurmaq üçün müəyyən edilə bilər. MFS metodu paralel korpus və korpus birləşdirmək metodu iki etiketli korpora ehtiyacı var.', 'bn': 'এই কাগজটিতে আমরা দেখাচ্ছি কিভাবে দুই ভাষার শব্দ ব্যবহার করা যাতে স্বয়ংক্রিয়ভাবে দুই ভাষায় ট্যাগ তৈরি করা যায় এবং এই পদ্ধতির কার্যক্রম পরীক্ষা করা। এটা করার জন্য আমাদের সমস্যা হয়েছে: মানে ট্যাগ সবসময় একে অপরের সাথে যোগ দেয় না। কারণ শব্দের অনুভূতি এবং ধারণা একে অপরের মধ্যে ভিন্ন। Therefore, we regarded the concept tag that corresponds to a word sense the most as the correct concept tag corresponding the word sense.  আমরা দুটি বিউইউ পদ্ধতি ব্যবহার করেছি, একটি লাইনিয়ার রেখা পরিবর্তন ম্যাট্রিক্স এবং ভেসিম্যাপ। আমরা সবচেয়ে প্রায়শ অনুভূতি এবং তুলনার জন্য কোর্পাসের কন্যাক্টেশন পদ্ধতিকে মূল্যায়ন করেছি। প্রস্তাবিত পদ্ধতির সঠিকভাবে বেশি উচ্চতা ছিল কিন্তু এমএফএস এবং কোর্পাস কন্টেশন পদ্ধতির চেয়ে কম। তবে, কারণ আমাদের পদ্ধতি শব্দের বিভিন্ন ভেক্টর ব্যবহার করেছে, ধারণা ট্যাগের সাথে যোগাযোগী মানসিক ট্যাগের সম্পর্কে পরীক্ষা করা যাবে ধারণা ট্যাগের ভেক্টরের স এছাড়াও, আমাদের পদ্ধতি প্রকাশ করা যাবে যখন আমাদের কেবল ধারণা বা শব্দের ব্যাপারটি ব্যবহার করা হয়, কিন্তু এমএফএস পদ্ধতি একটি প্যারালেল কর্পুস এবং কোর্পাসে', 'bs': 'U ovom papiru pokazujemo kako koristiti dvojezičke riječi ugrađenje (BWE) kako bi automatski stvorili odgovarajući stol znakova znakova iz dvije rečnice na jednom jeziku i pregledali učinkovitost metode. Da bismo to uradili, imali smo problem: značenje znakova ne uvijek odgovara jednom na drugom jer granularitija riječi čula i koncept su drugačiji od drugog. Stoga smo smatrali oznaku koncepta koja odgovara riječima najboljem kao tačna oznaku koncepta koja odgovara osjećaju riječi. Koristili smo dvije metode BWE, linearnu transformaciju matricu i VecMap. Procijenili smo najčešću metodu osjećaja (MFS) i metodu usklađenja korpusa za usporedbu. Tačnost predloženih metoda je bila veća od tačnosti nasumičnog početnog linije, ali niže od metoda potvrđenja MFS-a i korpusa. Međutim, zato što je naša metoda iskoristila ugrađene vektore čula riječi, odnosi osjećajnih znakova odgovarajućih znakovima koncepta mogli bi biti ispitani mapiranjem osjećajnih ugrađenja u vektorski prostor znakova koncepta. Također, naše metode bi se mogle izvršiti kada imamo samo koncept ili osjećaj riječi, dok metod MFS zahtijeva paralelni korpus i metod usklađenja korpusa treba dva označena korpusa.', 'cs': 'V tomto článku ukazujeme, jak použít dvojjazyčné vložení slov (BWE) k automatickému vytvoření odpovídající tabulky značek významu ze dvou slovníků v jednom jazyce a zkoumáme efektivitu metody. K tomu jsme měli problém: významové značky ne vždy odpovídají jednomu, protože granularity slova smysly a konceptů se od sebe liší. Proto jsme považovali značku koncepce, která odpovídá slovnímu smyslu nejvíce za správnou značku koncepce odpovídající slovnímu smyslu. Použili jsme dvě BWE metody, lineární transformační matici a VecMap. Pro srovnání jsme vyhodnotili metodu nejčastějšího smyslu (MFS) a metodu řetězců korpusů. Přesnost navržených metod byla vyšší než přesnost náhodného výchozího základu, ale nižší než přesnost metod MFS a korpusových řetězců. Nicméně, protože naše metoda využívala vkládací vektory slovních smyslů, vztahy smyslových značek odpovídající koncepčním značkám by mohly být zkoumány mapováním smyslových vložek do vektorového prostoru koncepčních značek. Také naše metody by mohly být provedeny, když máme pouze vkládání konceptu nebo slovního smyslu, zatímco metoda MFS vyžaduje paralelní korpus a metoda řetězení korpusu potřebuje dva tagované korpusy.', 'ca': "En aquest article mostrem com utilitzar integracions bilingües de paraules (BWE) per crear automàticament una taula correspondent d'etiquetes de significat de dos diccionaris en un llenguatge i examinar l'eficacia del mètode. Per fer això, vam tenir un problem a: les etiquetes significatives no sempre corresponen d'una a l'altra perquè les granularitats dels sentits de paraula i els conceptes són diferents d'una a l'altra. Per tant, vam considerar l'etiqueta conceptual que correspondeix a una paraula sense més com l'etiqueta conceptual correcta que correspondeix a la paraula sense. Vam utilitzar dos mètodes BWE, una matriu de transformació linear i VecMap. Vam evaluar el mètode del sentit més freqüent (MFS) i el mètode de concatenació del cos per a la comparació. Les precisions dels mètodes proposats eren més altes que la precisió de la base aleatòria però més baixes que les de la MFS i els mètodes de concatenació corpus. Però, com que el nostre mètode va utilitzar els vectors d'incorporació dels sentits de paraula, les relacions de les etiquetes de sentit que corresponden a les etiquetes de concepte podrien ser examinades mapeant les incorporacions de sentit a l'espai vector de les etiquetes de concepte. També els nostres mètodes es poden fer quan només tenim concepte o integració de sentit de paraula mentre que el mètode MFS requereix un corpus paral·lel i el mètode concatenació del corpus necessita dos corpores etiquetats.", 'et': 'Käesolevas töös näitame, kuidas kasutada kahekeelseid sõnade manustamist (BWE), et luua automaatselt vastav tabel tähendussiltidest kahest sõnastikust ühes keeles ja uurida meetodi efektiivsust. Selleks oli meil probleem: tähendussildid ei vasta alati üksteisele, sest sõna meelte ja kontseptsioonide granulaarsus erineb üksteisest. Seetõttu pidasime sõnalisele tähendusele kõige rohkem vastavat kontseptsiooni sildiks õigeks kontseptsiooni sildiks, mis vastab sõnale. Kasutasime kahte BWE meetodit, lineaarset transformatsiooni maatriksi ja VecMap. Hindasime võrdluseks kõige sagedasemat meetodit (MFS) ja korpuse konkatenatsiooni meetodit. Kavandatud meetodite täpsus oli suurem kui juhusliku algväärtuse täpsus, kuid madalam kui MFS ja korpuse kokatenatsiooni meetodite täpsus. Kuid kuna meie meetod kasutas sõnameelte manustamise vektoreid, võiks mõistemärkidele vastavate tähendusmärkide suhteid uurida, kaardistades tähendusmärkide manustamise kontseptsioonide vektoriruumi. Samuti võib meie meetodeid teostada siis, kui meil on ainult kontseptsiooni või sõnatähenduse manustamine, samas kui MFS meetod nõuab paralleelset korpust ja korpuse konkatenatsiooni meetod vajab kahte sildistatud korpust.', 'fi': 'Tässä artikkelissa näytämme, miten kaksikielisten sanastojen (BWE) avulla luodaan automaattisesti vastaava merkitystaulukko kahdesta sanakirjasta yhdellä kielellä ja tutkitaan menetelmän tehokkuutta. Tätä varten meillä oli ongelma: merkitystunnisteet eivät aina vastaa toisiaan, koska sanan aistien ja käsitteiden rakeisuus eroavat toisistaan. Näin ollen käsitätunniste, joka vastaa eniten sanaaistia, pidettiin oikeana sanaaistia vastaavana käsitunnisteena. Käytimme kahta BWE-menetelmää, lineaarista muunnosmatriisia ja VecMap-menetelmää. Arvioimme yleisintä aistimenetelmää (MFS) ja corpus concatenation menetelmää vertailua varten. Ehdotettujen menetelmien tarkkuus oli suurempi kuin satunnaislähtötilanteen tarkkuus, mutta pienempi kuin MFS- ja korpuskonatenaatiomenetelmien tarkkuus. Koska menetelmässämme hyödynnettiin sanan aistien upotusvektoreita, käsitetunnisteita vastaavien aistitunnisteiden suhdetta voitiin tutkia kartoittamalla merkitysten upotukset käsitetunnisteiden vektoritilaan. Menetelmiämme voitaisiin käyttää myös silloin, kun meillä on vain käsite- tai sanaaistiupotuksia, kun taas MFS-menetelmä edellyttää rinnakkaista korpusta ja korpuskonatenaatiomenetelmä tarvitsee kaksi tagged korpusta.', 'af': "In hierdie papier, wys ons hoe om twee tale woord inbettings (BWE) te gebruik om outomaties 'n ooreenstemmende tabel van betekenis etikette te skep van twee woordeboeke in een taal en die effektiviteit van die metode te ondersoek. Om dit te doen, het ons 'n probleem gehad: die betekening etikette doen nie altyd een na een ooreenstem nie, omdat die granulariteite van die woord senses en die konsepte anders is van mekaar. Daarom het ons die konsepte etiket aangesien wat ooreenstem met 'n woord sin die mees as die korrekte konsepte etiket wat ooreenstem die woord sens. Ons het twee BWE metodes gebruik, 'n lineêre transformasie matriks en VecMap. Ons evalueer die mees dikwels sin metode (MFS) en die korpus samelewing metode vir vergelyking. Die presies van die voorgestelde metodes was hoër as die presisie van die willekeurige basislien, maar minder as die metodes van die MFS en corpus samelewing. Maar, omdat ons metode die inbêring vektore van die woord senses gebruik het, kan die relasies van die sens etikette wat ooreenstemmende na konseptetikette etikette oorsoek word deur die koppeling van die sens inbêdings na die vektorruimte van die konseptetikette te maak. Ook, ons metodes kan uitgevoer word wanneer ons slegs konsepte of woord sin inbêding het, terwyl die MFS metode 'n parallele korpus nodig en die korpus samelewing metode twee merkte korpora nodig.", 'ha': "In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method.  Kayya da wannan, mun da wani matsayi: matsayin tagogi ba su sami daidai a kan koda, kwani granunufafi masu sauri da zaɓen zato ba su sãɓã wa jũna ba. Saboda haka, mun ga tagon zato da ke daidai zuwa ga kalma ma ma'anarsa mafi kyauta kamar tagon da ke daidaita da ma'anar maganar. Mun yi amfani da hanyõyin biyu na BWU, wata shifo mai saɗewa matriki da kewayi. Mun ƙaddara hanyon mafiya sauri (MFS) da hanyon mutane na sami. Gaskiya na metoden da aka buƙata ta zafi tsari daga tsarin layin da ba'a randa ba, kuma mafi ƙaranci daga metoden concatenation na MFS da Corbus. A lokacin da, kwamfyutan mu yi amfani da shiryoyi masu cikin shirin maganar, za'a iya jarraba dangani ga tagogi masu daidaita da tagogi na zato, da karni na fitarwa da ke fito zuwa filin shiryori na tagogi na zato. Kayya, za'a iya cika hanyoyinmu idan ana da zato ko ma'anar maganar da ke shiga, da kuma metoden MFS yana da amfani da nau'in da ke daidaita, kuma hanyon cire-nau'i na yi amfani da komana biyu.", 'sk': 'V tem prispevku smo prikazali, kako uporabiti dvojezične besedne vdelave (BWE) za samodejno ustvarjanje ustrezne tabele pomenskih oznak iz dveh slovarjev v enem jeziku in preučiti učinkovitost metode. Da bi to naredili, smo imeli problem: pomenske oznake ne ustrezajo vedno ena na ena, ker so granulativnosti besednih čutov in konceptov drugačne. Zato smo konceptno oznako, ki najbolj ustreza besednemu smislu, obravnavali kot pravilno konceptno oznako, ki ustreza besednemu smislu. Uporabili smo dve metodi BWE, linearno transformacijsko matriko in VecMap. Za primerjavo smo ovrednotili metodo najpogostejšega smisla (MFS) in metodo konatenacije korpusa. Natančnost predlaganih metod je bila višja od natančnosti naključnega izhodišča, vendar nižja od natančnosti metod MFS in korpusne konatenacije. Ker pa naša metoda uporablja vdelane vektorje besednih čutov, bi lahko razmerja čutov, ki ustrezajo konceptnim oznakam, preučili z mapiranjem čutov v vektorski prostor konceptnih oznak. Naše metode bi lahko izvedli tudi takrat, ko imamo samo vgradnje koncepta ali besednega pomena, medtem ko metoda MFS zahteva vzporedno korpus, metoda korpusne konatenacije pa potrebuje dva označena korpusa.', 'jv': 'Awak dhéwé éntuk akeh pisan iki, kita nguasakno akeh bantuan ingkang dipunangé awak dhéwé (BWA) nggawe sistem sing beraksikno yen manut karo ditawak dhéwé Ngawe lan saiki iki, awak dhéwé nduwe kesemplan: nik kabèh, merak-merak kuwi duluran sing beraksi nik sabên-sangan kuwi mau. Nanging, awake mau ngerti nggambar kuwi nggambar luwih Kernel Awak dhéwé éntukno nggambar luwih cara nggawe seneng nggambar luwih (MWS) lan kabèh basa sampeyan karo nggambar nggawe Rasané sing dipunangé perusahaan kuwi wis luwih luwih apik kanggo diolah sing titik dadi, nik awak dhéwé sing luwih basa ngono MWS karo perusahaan karo perusahaan politenessoffpolite"), and when there is a change ("assertive Nambah, awak dhéwé wis ngerasakno kanggo awak dhéwé isih perusahaan karo winih-winih sing beraksikno ngono nggawe sistem MFs kelangan perusahaan karo perusahaan karo perusahaan sampek dewek sampek duruh dumadhi', 'he': 'בעיתון הזה, אנו מראים איך להשתמש באמצעות מילים שתיים שפתיים (BWE) כדי ליצור אוטומטית שולחן מתאים של תוויות משמעות משני מילונים בשפה אחת ולבדוק את היעילות של השיטה. כדי לעשות את זה, היתה לנו בעיה: תוויות המשמעות לא תמיד מתאימות אחד לאחד כי הגרינוליות של חושים המילים והרעיונות שונות אחד מהשני. לכן, נחשבנו בתג המושג שמתאים למילה תחושה הכי הרבה בתג המושג הנכון שמתאים למילה תחושה. We used two BWE methods, a linear transformation matrix and VecMap.  הערכנו את שיטת ההתחושה הכי תדירות (MFS) ושיטת הקורפוס משוואה לשוואה. מדויקות השיטות המוצעות היו גבוהות יותר מהמדויקות של הבסיס האקראי, אך נמוכות יותר מאלה של השיטות של MFS ו-corpus concatenation. בכל אופן, בגלל שהשיטה שלנו השתמשה בוקטורים של חושים המילים, מערכות היחסים של תוויות החוש שמתאימות לתגים מושג יכולות לבדוק על ידי מפה של תוויות החוש לחלל הוקטורים של תוויות המושג. בנוסף, השיטות שלנו יכולות להתבצע כאשר יש לנו רק מושג או מושג מילים תוקפים בזמן ששיטת MFS דורשת קורפוס מקביל ושיטת הקורפוס תוקפים זקוקה לשני גופות תווים.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཅི་ཞིག་ལ་སྐད་ཡིག་གཟུགས་པའི་ནང་དུ་ཡིག་གཟུགས་གཅིག་གི་ནང་གི་ཡིག་རྟགས་གཉིས་ལས་མཐུན་པའི་ཤོག་བྱང་ཐོག འདི་ལྟ་བྱེད་པར་ང་ཚོར་དཀའ་ངལ་ཅིག་ཡོད། དེ་ནི་ཚིག་རྟག་པར་མཚུངས་རྟགས་གཅིག་ལས་གཅིག་མཐུན་མི་སྲིད། གང་ལེགས་ཞེ་ན། བྱ་ཚིག་རྩལ་བ དེར་བརྟེན། ང་ཚོས་BWE ལམ་ལུགས་གཉིས་བེད་སྤྱད་ནས་linear་རྒྱུན་གྱི་matrix དང་VecMap གཉིས་ཀྱིས་བེད། ངེད་ཚོས་རྒྱུན་ལྡན་པའི་ཐབས་ལམ་གཙོ་བོ་དང་མཉམ་དུ་མཐུན་བཟོ་བྱེད་པའི་ཐབས་ལམ་ལ་རྩིས་མཐུན་བཟོས་ཡོད། འོན་ཀྱང་། གྲོས་འཆར་བཀོད་པའི་ཐབས་ལམ་གྱི་accuracy་འདི་གནད་སྡུད་གཞི་རིམ་པ་དེ་ལས་མཐོ་རྐྱེན་ཡོད། ཡིན་ཀྱང་། MFS་དང་སྒྲིག་དབྱེ་བཟོ་ ཡིན་ནའང་། ང་ཚོའི་ལམ་ལུགས་འདི་ལག་ལེན་བྱེད་པའི་གནས་ཚུལ་རྒྱུན་པ་དེ་ཡིན་པས། འོན་ཀྱང་། ང་ཚོའི་ཐབས་ལམ་ལ་རྟགས་པར་ང་ཚོའི་མིང་ཚིག་འཆར་ཐབས་ལམ་གཅིག་པ་ཞིག་ཡོད་པའི་སྐབས་ལྟར་ཞིབ་དཔྱད་ཐབས་ལམ་ལ་ཉེན་མཁན་དབུ'}
{'en': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ar': 'ترجمة آلية متعددة المجالات من الإنجليزية إلى الإندونيسية', 'es': 'Benchmarking Multidominio Inglés-Indonesio Traducción Automática', 'fr': 'Benchmarking Traduction Automatique Anglais-Indonésien Multidomaine', 'pt': 'Benchmarking Tradução automática multidomínio inglês-indonésio', 'ja': 'ベンチマークマルチドメイン英語-インドネシア語機械翻訳', 'hi': 'बेंचमार्किंग मल्टीडोमेन अंग्रेजी इंडोनेशियन मशीन अनुवाद', 'zh': '多域英语-印尼语机器翻译准试', 'ru': 'Сравнительный анализ многодоменного английско-индонезийского машинного перевода', 'ga': 'Tagarmharcáil Multidomain Aistriúchán Meaisín Béarla-Indinéisis', 'hu': 'Benchmarking Több domain angol-indonéz gépi fordítás', 'el': 'Αξιολόγηση πολλαπλών τομέων Αγγλικά-Ινδονησιακά Μηχανική Μετάφραση', 'ka': 'Name', 'it': 'Benchmarking Multidomain Inglese-Indonesiano Traduzione Automatica', 'mk': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'kk': 'Бірнеше домен ағылшын- Индонезиялық машинаның аудармасыName', 'lt': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ms': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ml': 'ബെന്\u200dമെന്\u200dമെല്\u200dഡൊമൈന്\u200d ഇംഗ്ലീഷ്- ഇന്തോനീഷിയന്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നു', 'mt': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'mn': 'Олон-домжтой Англи-Индонезийн машины хөгжүүлэлт', 'no': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ro': 'Benchmarking Multidomeniu engleză-indoneziană Traducere automată', 'pl': 'Porównanie wielodomienne tłumaczenia maszynowe angielsko-indonezyjski', 'sr': 'Prevod Engleskog-Indonezijskog mašine', 'si': 'Name', 'sv': 'Benchmarking Multidomain engelsk-indonesisk maskinöversättning', 'so': 'Turjumista manfaca Ingiriis-Indonesian Mashine', 'ta': 'பல்டோமென் ஆங்கிலம்- இந்தோனேசிய இயந்திரம் மொழிபெயர்ப்பு', 'ur': 'بنچم مارکینگ Multidomain English-Indonesian Machine Translation', 'uz': 'Inglizcha Inglizcha- IndonezchaName', 'vi': 'Name=Tổ chức Chuột Name', 'nl': 'Benchmarking Multidomein Engels-Indonesisch Machine Translation', 'da': 'Benchmarking Multidomæne engelsk-indonesisk maskinoversættelse', 'bg': 'Индонезийски машинен превод с множество домейни', 'hr': 'Praćenje multidomena engleskog i Indonezijskog prevoda stroja', 'de': 'Benchmarking Multidomain Maschinelle Übersetzung Englisch-Indonesisch', 'id': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ko': '다영역 영어-인도네시아 기계번역의 기준 테스트', 'fa': 'ترجمه ماشین انگلیسی و انگلیسی انگلیسی', 'sw': 'Tafsiri ya Mashine ya Kiingereza-Indonesia', 'tr': 'balance', 'af': 'Name', 'sq': 'Duke përcaktuar përkthimin e makinës anglisht-indoneziane Multidomain', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Անգլերեն-Ինդոնեզիայի մեքենայի բազմաբնական թարգմանման համեմատությունը', 'az': 'Multidomain İngiliz-Indoneziya Makinesi Çeviri', 'bn': 'মাল্টিডোমেইন ইংরেজী-ইন্দোনেশিয়ার মেশিন অনুবাদ করা হচ্ছে', 'bs': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'ca': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'cs': 'Srovnávání multidoménového strojového překladu Angličtina-Indonéština', 'et': 'Mitmedomeenilised inglise-indoneesia masintõlked', 'fi': 'Benchmarking Multidomain Englanti-Indonesian konekäännös', 'sk': 'Primerjalna analiza večdomensko-indonezijsko strojno prevajanje', 'jv': 'Bench-marking Multidomain Inggris-Manual Traverse', 'ha': 'KCharselect unicode block name', 'bo': 'Benchmarking Multidomain English-Indonesian Machine Translation', 'he': 'סימנים מיוחדים תרגום מכונת אנגלית-אינדונזית'}
{'en': 'In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains : news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them, outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available onhttps://github.com/gunnxx/indonesian-mt-data\n      ', 'ar': 'في سياق الترجمة الآلية (MT) من وإلى الإنجليزية ، تعتبر لغة البهاسا الإندونيسية لغة منخفضة الموارد ، وبالتالي فإن تطبيق الترجمة الآلية العصبية (NMT) التي تتطلب عادةً مجموعة بيانات تدريب كبيرة يثبت أنها مشكلة. في هذه الورقة ، نوضح خلاف ذلك من خلال جمع مجموعات بيانات كبيرة ومتاحة للجمهور من الويب ، والتي قسمناها إلى عدة مجالات: الأخبار ، والدين ، والعامة ، والمحادثة ، لتدريب وقياس بعض المتغيرات من نماذج NMT القائمة على المحولات عبر المجالات . نوضح باستخدام BLEU أن نماذجنا تعمل بشكل جيد عبرها ، وتتفوق في الأداء على نماذج الترجمة الآلية الإحصائية الأساسية (SMT) ، وتعمل بشكل مماثل مع Google Translate. تتوفر مجموعات البيانات الخاصة بنا (مع التقسيم القياسي للتدريب والتحقق من الصحة والاختبار) والرمز والنماذج على <https://github.com/gunnxx/indonesian-mt-data>', 'es': 'En el contexto de la traducción automática (MT) desde y hacia el inglés, el bahasa indonesio se ha considerado un idioma de pocos recursos y, por lo tanto, la aplicación de la traducción automática neuronal (NMT), que normalmente requiere grandes conjuntos de datos de capacitación, resulta problemático. En este artículo, demostramos lo contrario mediante la recopilación de grandes conjuntos de datos disponibles públicamente de la Web, que dividimos en varios dominios: noticias, religión, general y conversación, para entrenar y comparar algunas variantes de modelos de NMT basados en transformadores en todos los dominios. Al usar BLEU, demostramos que nuestros modelos funcionan bien en todos ellos, superan a los modelos de traducción automática estadística (SMT) de referencia y funcionan de manera comparable con Google Translate. Nuestros conjuntos de datos (con la división estándar para el entrenamiento, la validación y las pruebas), el código y los modelos están disponibles en < https://github.com/gunnxx/indonesian-mt-data >', 'pt': 'No contexto da tradução automática (MT) de e para o inglês, o bahasa indonésio foi considerado um idioma de poucos recursos e, portanto, a aplicação da tradução automática neural (NMT), que normalmente requer um grande conjunto de dados de treinamento, se mostra problemática. Neste artigo, mostramos o contrário coletando grandes conjuntos de dados disponíveis publicamente da Web, que dividimos em vários domínios: notícias, religião, geral e conversação, para treinar e comparar algumas variantes de modelos NMT baseados em transformadores nos domínios . Mostramos usando o BLEU que nossos modelos têm bom desempenho em todos eles , superam os modelos básicos de tradução automática estatística (SMT) e têm desempenho comparável ao do Google Tradutor. Nossos conjuntos de dados (com a divisão padrão para treinamento, validação e teste), código e modelos estão disponíveis em <https://github.com/gunnxx/indonesian-mt-data>', 'fr': "Dans le contexte de la traduction automatique (TA) de et vers l'anglais, le bahasa indonésien a été considéré comme une langue à faibles ressources. Par conséquent, l'application de la traduction automatique neuronale (NMT), qui nécessite généralement un large ensemble de données de formation, s'avère problématique. Dans cet article, nous montrons le contraire en collectant de grands ensembles de données accessibles au public sur le Web, que nous avons divisés en plusieurs domaines\xa0: actualités, religion, généralités et conversations, afin de former et de comparer certaines variantes de modèles NMT basés sur des transformateurs dans les domaines. Grâce à BLEU, nous montrons que nos modèles fonctionnent bien entre eux, surpassent les modèles SMT (Statistical Machine Translation) de référence et sont comparables à ceux de Google Translate. Nos ensembles de données (avec la répartition standard pour la formation, la validation et les tests), notre code et nos modèles sont disponibles sur < https://github.com/gunnxx/indonesian-mt-data >", 'ja': '機械翻訳（ MT ）から英語への文脈では、Bahasa Indonesiaは低資源言語と見なされており、したがって、典型的には大きなトレーニングデータセットを必要とするニューラル機械翻訳（ NMT ）を適用することは問題であることが証明されています。本稿では、ウェブから公開されている大規模なデータセットを収集することによって別の方法を示します。これは、ニュース、宗教、一般、会話のいくつかのドメインに分割され、ドメイン全体でトランスベースのNMTモデルのいくつかのバリアントをトレーニングし、ベンチマークします。BLEUを使用して、当社のモデルはそれらを横断して優れたパフォーマンスを発揮し、ベースラインの統計機械翻訳（ SMT ）モデルを上回り、Google翻訳と同等のパフォーマンスを発揮することを示しています。当社のデータセット（トレーニング、検証、およびテストのための標準的な分割を含む）、コード、およびモデルは、 <https://github.com/gunnxx/indonesian-mt-data>', 'zh': '自英语至英语之机器翻译(MT)背景,印尼语以为匮乏之言,故宜用常须大练数集神经机器翻译(NMT)证有征。 本文,从Web收大,公数集来证其他,分为数域:新闻,宗教,凡对,以训准试跨域基于变压器者NMT变体。 吾以BLEU明之,吾形于其间,优于基线计机器翻译(SMT),而性与Google译等。 臣等数集(用训练、验试拆分)、代码、模形可<https://github.com/gunnxx/indonesian-mt-data>', 'hi': 'मशीन अनुवाद (एमटी) से अंग्रेजी के संदर्भ में, बहासा इंडोनेशिया को एक कम संसाधन भाषा माना जाता है, और इसलिए न्यूरल मशीन ट्रांसलेशन (एनएमटी) को लागू करना, जिसके लिए आमतौर पर बड़े प्रशिक्षण डेटासेट की आवश्यकता होती है, समस्याग्रस्त साबित होता है। इस पेपर में, हम वेब से बड़े, सार्वजनिक रूप से उपलब्ध डेटासेट एकत्र करके अन्यथा दिखाते हैं, जिसे हम कई डोमेन में विभाजित करते हैं: समाचार, धर्म, सामान्य और वार्तालाप, डोमेन में ट्रांसफॉर्मर-आधारित एनएमटी मॉडल के कुछ रूपों को प्रशिक्षित करने और बेंचमार्क करने के लिए। हम BLEU का उपयोग करके दिखाते हैं कि हमारे मॉडल उन पर अच्छा प्रदर्शन करते हैं, बेसलाइन सांख्यिकीय मशीन अनुवाद (SMT) मॉडल को मात देते हैं, और Google अनुवाद के साथ तुलनात्मक रूप से प्रदर्शन करते हैं। हमारे डेटासेट (प्रशिक्षण, सत्यापन और परीक्षण के लिए मानक विभाजन के साथ), कोड और मॉडल <https://github.com/gunnxx/indonesian-mt-data> पर उपलब्ध हैं', 'ru': 'В контексте машинного перевода (МП) с и на английский язык, бахаса Индонезия считается языком с ограниченными ресурсами, и поэтому применение нейронного машинного перевода (НМП), который обычно требует большого набора обучающих данных, оказывается проблематичным. В этой статье мы показываем обратное, собирая большие, общедоступные наборы данных из Интернета, которые мы разделили на несколько областей: новости, религия, общие и беседы, чтобы обучить и сравнить некоторые варианты моделей НМТ на основе трансформаторов во всех областях. Используя BLEU, мы показываем, что наши модели хорошо работают по ним , превосходят базовые модели статистического машинного перевода (SMT) и работают сравнительно с Google Translate. Наши наборы данных (со стандартным разделением для обучения, проверки и тестирования), код и модели доступны на <https://github.com/gunnxx/indonesian-mt-data>', 'ga': 'I gcomhthéacs Aistriú Meaisín (MT) ó Bhéarla agus go Béarla, meastar gur teanga íseal-acmhainní í Bahasa Indonesia, agus dá bhrí sin is fadhb í an Aistriúchán Meaisín Néarthach (NMT) a éilíonn go hiondúil tacar sonraí oiliúna mór. Sa pháipéar seo, léirímid a mhalairt trí thacair shonraí mhóra atá ar fáil go poiblí a bhailiú ón nGréasán, a roinneamar i réimsí éagsúla: nuacht, reiligiún, ginearálta, agus comhrá, chun roinnt leaganacha de mhúnlaí NMT atá bunaithe ar chlaochladán a thraenáil agus a thagarmharcáil thar na réimsí. . Léirímid trí úsáid a bhaint as BLEU go n-éiríonn go maith lenár múnlaí trasna orthu , go n-éiríonn leo níos fearr ná na samhlacha bonnlíne um Aistriú Meaisín Staidrimh (SMT), agus go bhfeidhmíonn siad inchomparáide le Google Translate. Tá ár dtacar sonraí (leis an scoilt chaighdeánach maidir le hoiliúint, bailíochtú, agus tástáil), cód, agus samhlacha ar fáil ar < https://github.com/gunnxx/ indonesian-mt-data>', 'el': 'Στο πλαίσιο της μηχανικής μετάφρασης (ΜΤ) από και προς τα αγγλικά, η Bahasa Indonesia έχει θεωρηθεί γλώσσα χαμηλής περιεκτικότητας σε πόρους, και ως εκ τούτου η εφαρμογή της νευραϊκής μηχανικής μετάφρασης (NMT) η οποία συνήθως απαιτεί μεγάλο σύνολο δεδομένων κατάρτισης αποδεικνύεται προβληματική. Σε αυτή την εργασία, δείχνουμε το αντίθετο συλλέγοντας μεγάλα, δημόσια διαθέσιμα σύνολα δεδομένων από το διαδίκτυο, τα οποία χωρίζουμε σε διάφορους τομείς: ειδήσεις, θρησκεία, γενικά και συζήτηση, για να εκπαιδεύσουμε και να αξιολογήσουμε ορισμένες παραλλαγές μοντέλων βασισμένων σε μετασχηματιστές σε όλους τους τομείς. Δείχνουμε με τη χρήση του ότι τα μοντέλα μας αποδίδουν καλά σε όλα αυτά, ξεπερνούν τα μοντέλα στατιστικής μηχανικής μετάφρασης βάσης (και αποδίδουν συγκριτικά με τη μετάφραση του Google Translate. Τα σύνολα δεδομένων μας (με τον τυποποιημένο διαχωρισμό για εκπαίδευση, επικύρωση και δοκιμή), ο κώδικας και τα μοντέλα είναι διαθέσιμα στο < https://github.com/gunnxx/indonesian-mt-data >', 'hu': 'Az angolról és angolra történő gépi fordítás (MT) összefüggésében a Bahasa Indonéziát alacsony erőforrású nyelvnek tekintik, ezért problémásnak bizonyul a Neural Machine Translation (NMT) alkalmazása, amely jellemzően nagy képzési adatokat igényel. Ebben a tanulmányban nagy, nyilvánosan elérhető adatkészleteket gyűjtünk az internetről, amelyeket több területre osztunk: hírekre, vallásra, általános és beszélgetésre, hogy képezzük és összehasonlítsuk a transzformátor alapú NMT modellek néhány változatát a tartományokban. A BLEU használatával megmutatjuk, hogy modelleink jól teljesítenek mindegyikükön, felülmúlják az alapvető Statisztikai Gépi Fordítási (SMT) modelleket, és összehasonlíthatóan teljesítenek a Google Fordítóval. Adatkészleteink (az oktatáshoz, validáláshoz és teszteléshez szükséges szabványos felosztással), kódjaink és modelleink elérhetők < https://github.com/gunnxx/indonesian-mt-data >', 'ka': 'მაქსინური შეცვლის (MT) კონტექსტში ანგლისურად, ბაჰასა ინდონეციაში ცოტა რესურსის ენერგია იყო, რადგან ნეიროლური მაქსინური შეცვლის (NMT) გამოყენება, რომელიც განსაკუთრებულია დიდი შეცვლ ამ დომენში ჩვენ ჩვენ ჩვენ ჩვენ სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა დიდი,  ჩვენ გამოყენებთ BLEU-ის გამოყენებაში, რომ ჩვენი მოდელები მათგანი გავაკეთებენ, გავაკეთებთ ბაზის სტატისტიკური მაქსინური განაცვლის (SMT) მოდელები და Google Translate-ის შემდეგ გავაკეთებ < https://github.com/gunnxx/indonesian-mt-data >', 'it': "Nel contesto della traduzione automatica (MT) da e verso l'inglese, Bahasa Indonesia è stata considerata una lingua a basso contenuto di risorse, e quindi applicare la traduzione automatica neurale (NMT) che richiede tipicamente un ampio set di dati di formazione si rivela problematica. In questo articolo, mostriamo il contrario raccogliendo grandi set di dati disponibili pubblicamente dal Web, che abbiamo diviso in diversi domini: notizie, religione, generale e conversazione, per formare e confrontare alcune varianti di modelli NMT basati su trasformatori in tutti i domini. Con BLEU mostriamo che i nostri modelli funzionano bene su di essi, superano i modelli SMT (Statistical Machine Translation) di base e funzionano in modo comparabile con Google Translate. I nostri set di dati (con la divisione standard per formazione, convalida e test), codice e modelli sono disponibili su < https://github.com/gunnxx/indonesian-mt-data >", 'kk': 'Машин аудару (MT) мен ағылшын тіліне Бахаса Индонезиясы төмен ресурстар тіліне қатысты, сондықтан нейрондық машинаның аударуын (NMT) қолдану әдетте үлкен оқыту деректер жиынының мәселесі болады. Бұл қағазда, әйтпесе, біз Вебден үлкен, көпшілік қол жеткізетін деректер жинақтарын жинақтап көрсетедік. Біз бірнеше доменге бөліп, жаңалықтар, діниелер, жалпы және сұрақтар, бірнеше түрлендіруші NMT моделдерінің Біз BLEU қолданатын моделдеріміз олардың арасында жақсы жұмыс істейді, негізгі статистикалық машиналық аудару (SMT) моделдеріне арналған, Google Translate- мен салыстырылып жатқанын көрсетедік. Деректер жиындарымыз (оқыту, тексеру және сынақтау үшін стандартты бөліс), код және үлгілер < https://github.com/gunnxx/indonesian-mt-data >', 'mk': 'Во контекст на Машинската транслекција (МТ) од и на англиски, Бахаса Индонезија се смета за јазик со ниски ресурси, и затоа апликацијата на Неуралната Машинска транслекција (НМТ) која обично бара голем набор податоци за обука се покажува како проблематичен. Во овој весник покажуваме спротивно собирајќи големи, јавно достапни податоци од Веб, кои ги поделивме во неколку домени: вести, религија, генерал и разговор, за обука и споредба на некои варијанти на трансформаторски модели на НМТ низ сите домени. Ние покажуваме користејќи БЛЕУ дека нашите модели функционираат добро низ нив, ги надминуваат основните модели за статистички машински превод (СМТ), и функционираат во споредба со Google Translate. Нашите податоци (со стандардната поделба за обука, валидација и тестирање), код и модели се достапни на < https://github.com/gunnxx/indonesian-mt-data >', 'ml': 'In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.  ഈ പത്രത്തില്\u200d നമ്മള്\u200d വെബ്ബില്\u200d നിന്നും വലിയ, പ്രസിദ്ധമായ ഡേറ്റാസെറ്റുകള്\u200d സംഘടിപ്പിക്കുന്നതിനാല്\u200d വേറെയും കാണിക്കുന്നു. അതിനെ ഞങ്ങള്\u200d പല ഡൊമെയിനുകളിലേക ബിലിയു ഉപയോഗിച്ച് ഞങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ മോഡലുകള്\u200d അവയുടെ മുകളില്\u200d നല്ല പ്രവര്\u200dത്തിപ്പിക്കുന്നത്, ബെസ്റ്റിസ്റ്റിക്കല്\u200d മെഷ ഞങ്ങളുടെ ഡാറ്റാസേറ്റുകള്\u200d (പരിശീലനത്തിന്, തിരിച്ചറിയുന്നതിനുള്ള സാധാരണ വിഭജിക്കുന്നതിനും, പരീക്ഷിക്കുന https://github.com/gunnxx/indonesian-mt-data >', 'ms': 'Dalam konteks Terjemahan Mesin (MT) dari-dan-ke Inggeris, Bahasa Indonesia telah dianggap bahasa sumber rendah, dan oleh itu menerapkan Terjemahan Mesin Neural (NMT) yang biasanya memerlukan set data latihan besar membuktikan menjadi masalah. Dalam kertas ini, kita menunjukkan sebaliknya dengan mengumpulkan set data yang besar dan tersedia kepada masyarakat dari Web, yang kita pecah ke beberapa domain: berita, agama, umum, dan perbualan, untuk melatih dan benchmark beberapa varian model NMT berasaskan pengubah di seluruh domain. Kami menunjukkan menggunakan BLEU bahawa model kami berjalan dengan baik di seluruh mereka, melampaui model Statistical Machine Translation (SMT) asas, dan melaksanakan secara berbanding dengan Google Translate. Set data kami (dengan bahagian piawai untuk latihan, sahihan, dan ujian), kod, dan model tersedia pada < https://github.com/gunnxx/indonesian-mt-data >', 'mt': 'Fil-kuntest tat-Traduzzjoni tal-Makkinarju (MT) mill-Ingliż u għall-Ingliż, il-Bahasa Indoneżja tqieset bħala lingwa b’riżorsi baxxi, u għalhekk l-applikazzjoni tat-Traduzzjoni tal-Makkinarju Newrali (NMT) li tipikament teħtieġ sett ta’ dejta ta’ taħriġ kbir hija problematika. F’dan id-dokument, naraw mod ieħor billi nġabru settijiet ta’ dejta kbar u disponibbli għall-pubbliku mill-Web, li aħna maqsuma f’diversi oqsma: aħbarijiet, reliġjon, ġenerali, u konverżjoni, biex inħarrġu u nqisu xi varjanti ta’ mudelli NMT ibbażati fuq it-trasformaturi madwar l-oqsma. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate.  Our datasets (with the standard split for training, validation, and testing), code, and models are available on < https://github.com/gunnxx/indonesian-mt-data >', 'mn': 'Машин хөгжүүлэх (MT) болон Англи хэл руу багасаа Индонезийг бага баялаг хэл гэж үздэг. Иймээс мэдрэлийн машины хөгжүүлэх (NMT) хэрэглэх нь ихэвчлэн том сургалтын өгөгдлийн санг асуудалтай байдаг. Энэ цаасан дээр бид Вебээс том, нийтэд ашиглах өгөгдлийн сангуудыг олон хэсэгт хувааж үзүүлдэг: мэдээ, шашин, ерөнхий, яриа, хэлэлцээг, өөрчлөгч суурилсан NMT загваруудын төрлийн төрлийн төрлийн загваруудыг сургаж, багжуулж байна. Бид BLEU-г ашиглан бидний загварууд тэдний дунд сайн ажиллаж, үндсэн Статистикийн Машины хөгжүүлэлтийн (SMT) загваруудыг илүү хийж, Google Translate-тай харьцуулж байдаг. Бидний өгөгдлийн сангууд (сургалтын, шалгалтын, шалгалтын стандарт хуваалцах, шалгалтын тулд) код, загварууд < https://github.com/gunnxx/indonesian-mt-data >', 'lt': 'Kalbant apie mašinų vertimą (MT) iš anglų ir į anglų kalbą, Bahasa Indonezija buvo laikoma mažai išteklių turinčia kalba, todėl pasirodo, kad sunku taikyti neuronių mašinų vertimą (NMT), kuriam paprastai reikalingas didelis mokymo duomenų rinkinys. Šiame dokumente kitaip parodomi renkant didelius visuomenei prieinamus duomenų rinkinius iš tinklo, kurie suskirstomi į kelias sritis: naujienas, religiją, visuotinį ir pokalbį, kad būtų mokomi ir lyginami kai kurie transformatoriais pagrįstų NMT modelių variantai visose srityse. Naudojant BLEU parodomi, kad mūsų modeliai gerai veikia visuose juose, viršija pradinius statistinių mašinų vertimo (SMT) modelius ir veikia palyginti su Google Translate. Mūsų duomenų rinkiniai (su standartiniu mokymo, patvirtinimo ir bandymų suskirstymu), kodas ir modeliai pateikiami < https://github.com/gunnxx/indonesian-mt-data >', 'no': 'I konteksten av maskinsomsetjing (MT) frå og til engelsk er Bahasa Indonesia kalla som eit låg ressursspråk, og derfor brukar Neuralmaskinsomsetjing (NMT) som normalt krev stor opplæringsdataset viser at det er problematisk. I denne papiret viser vi ellers ved å samla store, offentlig tilgjengelege datasett frå nettet, som vi deler inn i fleire domene: nyhetar, religium, generell og samtale, for å trenga og benchmarkera nokre variantar av transformeringsbaserte NMT-modeller over domene. Vi viser med BLEU at våre modeller utfører godt over dei, utfører baseline statistiske maskinsomsetjingsmodulane (SMT) og utfører sammenlignbare med Google Translate. Datasett våre (med standard delt for trening, validating og testing), kode og modeller er tilgjengelege på < https://github.com/gunnxx/indonesian-mt-data >', 'pl': 'W kontekście tłumaczenia maszynowego (MT) z języka angielskiego Bahasa Indonesia została uznana za język o niskich zasobach, dlatego zastosowanie neuronowego tłumaczenia maszynowego (NMT), które zazwyczaj wymaga dużego zbioru danych szkoleniowych okazuje się problematyczne. W niniejszym artykule pokazujemy inaczej, zbierając duże, publicznie dostępne zbiory danych z sieci, które podzielimy na kilka dziedzin: wiadomości, religii, ogólności i konwersacji, aby szkolić i porównać niektóre warianty modeli NMT opartych na transformatorach w różnych domenach. Przy użyciu BLEU pokazujemy, że nasze modele działają dobrze w nich, przewyższają podstawowe modele statystycznego tłumaczenia maszynowego (SMT) i działają porównywalnie z Google Translate. Nasze zestawy danych (ze standardowym podziałem dla szkoleń, walidacji i testów), kod i modele są dostępne na < https://github.com/gunnxx/indonesian-mt-data >', 'ro': 'În contextul traducerii automate (MT) din și în engleză, Bahasa Indonezia a fost considerată o limbă cu resurse reduse și, prin urmare, aplicarea traducerii automate neurale (NMT) care necesită, de obicei, seturi mari de date de formare se dovedește a fi problematică. În această lucrare, arătăm altceva prin colectarea de seturi de date mari, disponibile public de pe Web, pe care le-am împărțit în mai multe domenii: știri, religie, general și conversație, pentru a instrui și compara unele variante de modele NMT bazate pe transformatori în domenii. Noi arătăm folosind BLEU că modelele noastre performează bine pe toate acestea, depășesc modelele statistice de traducere automată (SMT) de bază și performează comparabil cu Google Translate. Seturile noastre de date (cu divizarea standard pentru instruire, validare și testare), codul și modelele sunt disponibile pe < https://github.com/gunnxx/indonesian-mt-data >', 'sr': 'U kontekstu prevoda mašine (MT) od i do engleskog, Bahasa Indonezija je smatrala jezikom niskog resursa, i stoga se primjenjuje Neuralna mašina prevoda (NMT) koja obično zahteva veliku obuku podataka pokazuje da je problematična. U ovom papiru pokazujemo drugaèije skupljanjem velikih, javno dostupnih podataka sa interneta, koje smo podelili u nekoliko domena: vesti, religija, generalni i razgovor, da obuèemo i sklonimo neke variante NMT modela na transformaciji širom domena. Pokazujemo koristeći BLEU da naši modeli dobro izvršavaju preko njih, izvršavaju početne statističke tehnike prevode (SMT) modele i izvršavaju usporedno sa Google Translate. Naši podaci (sa standardnom podjelom za obuku, potvrdu i testiranje), kod i modeli su dostupni na < https://github.com/gunnxx/indonesian-mt-data - Да.', 'si': 'මැෂින් පරිවර්තනය (MT) වලින් ඉංග්\u200dරීසිය වලින්, බාහාසා ඉංඩෝනේසියාව ප්\u200dරශ්න භාෂාවක් හිතලා තියෙනවා, ඒ වගේම න්\u200dයූරාල් මැෂින්  මේ පත්තරේ අපි පෙන්වන්නේ නැත්තම් විශාල, ප්\u200dරජාතික විදිහට ප්\u200dරවේශ කරන්න බොහොම දත්ත සේට් වලින්, අපි විදිහට පෙන්වන්නේ: වාර්තාව, සාමාන්\u200dය, සමාන්\u200dය,  අපි BLUE භාවිතා කරන්න පෙන්වන්නේ අපේ මොඩල් ඔවුන්ට හොඳ වැඩ කරනවා කියලා, මූලික සංඛ්\u200dයාත්මක මැෂින් වාර්ථාව (SMT) මොඩල අපේ දත්ත සේට් (ප්\u200dරධානය, විශ්ලේෂණය, පරීක්ෂණය සහ පරීක්ෂණය සඳහා ප්\u200dරමාණය විතරයි), කෝඩ් සහ මොඩේල් ප https://github.com/gunnxx/indonesian-mt-data >', 'sv': 'Inom ramen för maskinöversättning (MT) från och till engelska har Bahasa Indonesia ansetts vara ett lågresursspråk, och därför visar det sig vara problematiskt att tillämpa Neural Machine Translation (NMT) som vanligtvis kräver stora utbildningsdata. I denna uppsats visar vi annorlunda genom att samla in stora, offentligt tillgängliga datamängder från webben, som vi delar upp i flera domäner: nyheter, religion, allmän och konversation, för att träna och jämföra vissa varianter av transformatorbaserade NMT-modeller över domänerna. Vi visar med BLEU att våra modeller presterar bra över dem, överträffar baslinjemodellerna för statistisk maskinöversättning (SMT) och presterar jämförbart med Google Translate. Våra dataset (med standarduppdelning för utbildning, validering och testning), kod och modeller finns tillgängliga på < https://github.com/gunnxx/indonesian-mt-data >', 'so': 'Xarunta tarjumaadda Machine (MT) oo ka bilaabaya- ilaa Ingiriis, Bahasa Indonesia waxaa looga tiriyey luqad hoos-resource ah, sidaas darteed waxay codsanayaan tarjumaadda Neural Machine (NMT) oo sida caadiga ah u baahan koobashada waxbarasho oo waaweyn waxay caddaan inay tahay dhibaato. Warqadan waxaynu si kale uga muujinnaa ururada macluumaadka oo waaweyn oo shabakadda laga helay, taasoo aannu u kala qaybinnay meelo kala duduwan: warar, diin, guud iyo hadal, si aan u tababarinno iyo baaritaanno noocyo kala duwan oo asalka NMT ah. Waxaynu muujinnaa isticmaalka BLEU in modelalkayagu ay si wanaagsan u sameeyaan, oo aan u sameynno modellada tarjumaadka (SMT) ee aasaasiga ah, waxaana sameynaynaa si u eg tarjumaadda Google. Taariikhdayada (oo lagu kala qeybiyay standardka waxbarashada, xaqiijinta, iyo imtixaanka), kaararka iyo modellada waxaad ka heleysaa < https://github.com/gunnxx/indonesian-mt-data >', 'ta': 'இயந்திரத்திலிருந்து மொழிபெயர்ப்பு (MT) மொழிபெயர்ப்பில், பாஹாசா இந்தோனேசியாவு ஒரு குறைந்த மூலத்தின் மொழியாக கருதப்பட்டுள்ளது, அதனால் பொதுவாக பெரிய பயிற்சி தரவ இந்த காக்கியத்தில், நாம் வலையத்திலிருந்து பெரிய, பொது கிடைக்கும் தகவல் அமைப்புகளை சேகரித்து வேறு வழியில் காட்டுகிறோம். இதை நாம் பல இடங்களாக பிரித்து விட் BLEU பயன்படுத்தி எங்கள் மாதிரிகள் அவற்றை முழுவதும் நன்றாக செயல்படுத்துகிறார்கள் என்பதை நாம் காட்டுகிறோம், அடிப்படையாளர் புள்ளிவிவரமா எங்கள் தரவு அமைப்புகள் (< https://github.com/gunnxx/indonesian-mt-data >', 'ur': 'ماشین ترجمہ (MT) سے اور انگلیسی سے، باہاسا انڈونسیا کو کم سراسر کی زبان سمجھا گیا ہے، اور اسی وجہ سے نیورال ماشین ترجمہ (NMT) کو لازم کرنا چاہتا ہے جسے معمولاً بڑی ترسین ڈیٹ سٹ کی ضرورت ہے، مشکل ہے. اس کاغذ میں ہم ایسا بھی دکھاتے ہیں کہ ویب سے بہت بڑے، عمومی طور پر موجود ڈاٹ سٹ جمع کریں، جسے ہم مختلف دامنوں میں تقسیم کرتے ہیں: خبریں، دین، عمومی، اور گفتگو، ٹرینچر اور بنچم کرنے کے لئے کچھ ٹرینچر بنیادی NMT موڈلیوں کے متواسطے ہیں۔ ہم BLEU کے استعمال سے دکھاتے ہیں کہ ہمارے موڈل ان کے درمیان اچھی طرح عمل کرتے ہیں، baseline Statistical Machine Translation (SMT) موڈل سے زیادہ عمل کرتے ہیں، اور گوگل Translate کے ساتھ برابر عمل کرتے ہیں۔ ہمارے ڈاٹ سٹ (ٹرینگ، والیڈیٹ اور آزمائش کے لئے استاندارڈ تقسیم کے ساتھ) کوڈ اور موڈل موجود ہیں <پر https://github.com/gunnxx/indonesian-mt-data >', 'uz': "Name Bu hujjatda, biz veb- sahifadagi katta, publicdagi maʼlumotlar tarkibini olib tashlash orqali boshqa narsalarni ko'rsamiz. Bu yerda biz bir nechta domanega ega bo'lgan xabar, dining, umumiy va talab qilamiz. Vazifaning asosida yaratilgan NMT modellarini o'rganish va yordam qilish uchun. Biz BLEU yordamida modellarimiz ularning orqali yaxshi bajarayotganimiz, asosiy statistik mashina tarjima modellarini bajaramiz va Google tarjima bilan moslash mumkin. Maʼlumotlar tugmalarimiz (ta'lim, toʻgʻri va sinov qilish uchun andoza boʻlishi bilan, < https://github.com/gunnxx/indonesian-mt-data >", 'vi': 'Trong ngữ cảnh Dịch Cỗ Máy (MTV) từ-và-sang-Anh, Bahamas Indonesia được coi là một ngôn ngữ ít tài nguyên, và do đó áp dụng Dịch lắp Thần máy (NMB) mà thường yêu cầu một bộ dữ liệu huấn luyện lớn cho thấy khó khăn. Trong tờ giấy này, chúng ta cho thấy khác bằng cách thu thập các dữ liệu lớn công khai từ Mạng, mà chúng ta chia thành nhiều miền: tin, tôn giáo, thông thường, và trò chuyện, để huấn luyện và tiêu điểm vài biến đổi mẫu NMT dựa trên mỗi miền. Chúng tôi cho thấy qua lòng lòng lọc một các một cách của chúng tôi hiểu rất tốt bên các một số các một cách thoát ràng, hiến thành qua một các một Sở thuật Các tập tin (với bộ chia tiêu chuẩn cho huấn luyện, huấn luyện, huấn luyện và thử nghiệm), mã, và các mô hình có sẵn trên https://github.com/gunnxx/indonesian-mt-data Language', 'da': 'I forbindelse med maskinoversættelse (MT) fra og til engelsk er Bahasa Indonesien blevet betragtet som et lavt ressourcesprog, og derfor viser det sig at være problematisk at anvende Neural Machine Translation (NMT), som typisk kræver store træningsdatasæt. I denne artikel viser vi det modsatte ved at indsamle store, offentligt tilgængelige datasæt fra internettet, som vi opdeler i flere domæner: nyheder, religion, generel og samtale, for at træne og benchmark nogle varianter af transformer-baserede NMT modeller på tværs af domænerne. Vi viser ved hjælp af BLEU, at vores modeller præsterer godt på tværs af dem, overgår de grundlæggende statistiske maskinoversættelsesmodeller (SMT) og præsterer sammenligneligt med Google Translate. Vores datasæt (med standard split for træning, validering og test), kode og modeller er tilgængelige på < https://github.com/gunnxx/indonesian-mt-data >', 'bg': 'В контекста на машинния превод (МТ) от и на английски език Бахаса Индонезия се счита за език с нисък ресурс и затова прилагането на неврален машинен превод (НМТ), който обикновено изисква голям набор от данни за обучение, се оказва проблематично. В тази статия показваме друго, като събираме големи, публично достъпни набори от данни от интернет, които разделяме на няколко области: новини, религия, общ и разговор, за да обучим и сравним някои варианти на трансформаторни модели на НМТ в отделните области. Ние показваме, че нашите модели се представят добре в тях, превъзхождат базовите модели на статистически машинен превод (SMT) и се представят сравнително с Google Translate. Нашите набори от данни (със стандартно разделяне за обучение, валидиране и тестване), код и модели са достъпни на < https://github.com/gunnxx/indonesian-mt-data >', 'hr': 'U kontekstu prevoda strojeva (MT) od i na engleski jezik, Bahasa Indonezija je smatrala niskim resursima i stoga se primjenjuje neurološki prevod strojeva (NMT) koji obično zahtijeva veliku obuku podataka pokazuje problematičnim. U ovom papiru pokazujemo drugačije skupljanjem velikih, javno dostupnih podataka sa interneta, koje smo podelili u nekoliko domena: vijesti, religija, općenito i razgovor, kako bi obučili i sklonili neke variante NMT modela na transformaciji širom domena. Pokazujemo koristeći BLEU da naši modeli dobro izvršavaju preko njih, izvršavaju početne modele prevoda statističkih strojeva (SMT) i izvršavaju usporedno s Google Translate. Naši podaci (s standardnom podjelom za obuku, potvrdu i testiranje), kod i modeli su dostupni na < https://github.com/gunnxx/indonesian-mt-data >', 'nl': 'In de context van Machine Translation (MT) van en naar Engels wordt Bahasa Indonesia beschouwd als een taal met weinig resources, en daarom blijkt het toepassen van Neural Machine Translation (NMT) die doorgaans een grote trainingsdataset vereist problematisch. In dit artikel laten we het tegendeel zien door grote, openbaar beschikbare datasets van het web te verzamelen, die we opsplitsen in verschillende domeinen: nieuws, religie, algemeen en conversatie, om enkele varianten van transformatorgebaseerde NMT-modellen over de domeinen te trainen en te benchmarken. Met BLEU laten we zien dat onze modellen overal goed presteren, beter presteren dan de basismodellen voor statistische machinevertaling (SMT) en vergelijkbaar presteren met Google Translate. Onze datasets (met de standaard split voor training, validatie en testen), code en modellen zijn beschikbaar op < https://github.com/gunnxx/indonesian-mt-data >', 'de': 'Im Kontext der maschinellen Übersetzung (MT) von und nach Englisch wurde Bahasa Indonesia als eine ressourcenarme Sprache angesehen, und daher erweist sich die Anwendung der neuronalen maschinellen Übersetzung (NMT), die typischerweise große Schulungsdaten erfordert, als problematisch. In diesem Beitrag zeigen wir das Gegenteil, indem wir große, öffentlich verfügbare Datensätze aus dem Web sammeln, die wir in mehrere Domänen unterteilen: Nachrichten, Religion, Allgemein und Konversation, um einige Varianten transformatorbasierter NMT-Modelle in den Domänen zu trainieren und zu benchmarken. Mit BLEU zeigen wir, dass unsere Modelle über sie hinweg gut abschneiden, die Basismodelle für statistische maschinelle Übersetzung (SMT) übertreffen und mit Google Translate vergleichbar sind. Unsere Datensätze (mit dem Standard Split für Training, Validierung und Testing), Code und Modelle sind verfügbar unter < https://github.com/gunnxx/indonesian-mt-data >', 'id': 'Dalam konteks Translation Mesin (MT) dari-dan-ke Inggris, Bahasa Indonesia telah dianggap bahasa sumber daya rendah, dan karena itu menerapkan Translation Mesin Neural (NMT) yang biasanya memerlukan set data latihan besar membuktikan menjadi masalah. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains.  Kami menunjukkan menggunakan BLEU bahwa model kami berjalan dengan baik di seluruh mereka, melampaui batas model Statistical Machine Translation (SMT) model, dan melakukan secara membandingkan dengan Google Translate. Set data kami (dengan pembagian standar untuk latihan, validasi, dan tes), kode, dan model tersedia di < https://github.com/gunnxx/indonesian-mt-data >', 'fa': 'در محیط ترجمه ماشین (MT) از-و-به انگلیسی، انگلیسی باهاسا انگلیسی یک زبان کم منبع به نظر گرفته می\u200cشود، و بنابراین برای تغییرات ماشین عصبی (NMT) که معمولاً نیاز دارد مجموعه داده\u200cهای بزرگ آموزش را مشکل می\u200cکند. در این کاغذ، در غیر این صورت با جمع کردن مجموعه\u200cهای داده\u200cهای بزرگ و عمومی از وب را نشان می\u200cدهیم، که ما به چند دامنه تقسیم می\u200cکنیم: اخبار، دین، عمومی، و گفتگو، تا برخی از گوناگون\u200cهای مدل\u200cهای NMT بر اساس تغییر\u200cدهنده\u200cها در سراسر دامنه\u200c ما با استفاده از BLEU نشان می دهیم که مدلهای ما در سراسر آنها خوب انجام می دهند، از مدلهای ترجمه ماشین آمریکا (SMT) پایین استفاده می کنند، و با ترجمه گوگل انجام می دهند. مجموعه\u200cهای داده\u200cهای ما (با تقسیم استاندارد برای آموزش، تصدیق و آزمایش) کد و مدل در < https://github.com/gunnxx/indonesian-mt-data >', 'ko': '영어에서 영어로 이어지는 기계번역(MT)에서 인도네시아어는 저자원 언어로 인식되기 때문에 신경기계번역(NMT)을 응용하려면 통상적으로 대량의 훈련 데이터 집합이 필요한 것이 문제가 있다.본고에서 우리는 웹에서 대형, 공개적으로 사용할 수 있는 데이터 집합을 수집하여 또 다른 상황을 보여준다. 우리는 이러한 데이터 집합을 몇 가지 분야로 나눈다. 뉴스, 종교, 일반과 대화이다. 이런 분야를 뛰어넘어transformer를 바탕으로 하는 NMT 모델의 일부 변체를 교육하고 테스트한다.BLEU 디스플레이를 사용하여 Google 모델은 베이스라인 통계기계번역(SMT) 모델보다 더 우수하고 Google Translate와 비슷하게 작동합니다.Dell의 데이터 세트(교육, 검증 및 테스트를 위한 표준 분할), 코드 및 모델은 <https://github.com/gunnxx/indonesian-mt-data>', 'sw': 'Katika mukhtadha wa Tafsiri ya Mashine (MT) kutoka-hadi-hadi Kiingereza, Bahasa Indonesia imechukuliwa kuwa lugha ndogo ya rasilimali, na kwa hiyo kutumia utafsiri wa Mashine ya Kiurali (NMT) ambayo kwa kawaida inahitaji seti kubwa ya mafunzo inaonyesha kuwa tatizo. Katika karatasi hii, tunaonyesha vinginevyo kwa kukusanya seti kubwa za taarifa zinazopatikana hadharani kutoka mtandaoni, ambazo tuligawanyika katika maeneo mbalimbali: habari, dini, jumla na mazungumzo, kufundisha na kuboresha baadhi ya mifano ya NMT yenye mabadiliko ya maeneo mbalimbali. Tunaonyesha kwa kutumia BLEU kuwa mifano yetu hufanya kazi vizuri kote, kutengeneza mifano ya Tafsiri ya Kitakwimu (SMT) ya msingi, na kufanya kazi kama ilivyo na Tafsiri ya Google. Taarifa zetu (kwa kiwango cha kawaida kwa ajili ya mafunzo, uhakika, na mtihani), na mifano inapatikana kwenye < https://github.com/gunnxx/indonesian-mt-data >', 'tr': 'Makine terjime edeniň (MT) we iňlisçe, Indoneziýanyň esasy iň az resurslar dili diýip kabul edildi we şonuň üçin Nural Makine terjime edilmesi (NMT) ýagdaýynda gaty uly okuwçylygy mümkin edýän maglumatlaryň problematik bolmagyny kanıtlaýar. Bu kagyzda, Web tarapyndan uly, publika meňzeşli veri setirlerini ýygnarak görkeýäris we olaryň birnäçe sahypa bölüşürip başladyk: täzelikler, dinimiz, umumy we sohbetlerimiz, transformer-tarapyndan NMT modelleriniň birnäçe warianatlaryny sahypa çykarmak we çykarmak üçin görkeýäris Biziň modellerimiz olaryň üstünde gowy çykýandygyny, baseline Makine terjime (SMT) nusgalaryny çykarmagyny we Google terjime bilen döwrülişýäni görünýärdik. Biziň veri setirlerimiz (okuw, barlamak we testilemek üçin standart bölümi bilen), köd we nusgalarymyz < https://github.com/gunnxx/indonesian-mt-data >', 'sq': 'Në kontekstin e Translacionit të Makinës (MT) nga dhe në Anglisht, Bahasa Indonezia është konsideruar një gjuhë me burime të ulëta dhe prandaj zbatimi i Translacionit të Makinës Neurale (NMT) që tipikisht kërkon një grup të madh të dhënash trainimit provohet të jetë problematik. Në këtë letër, ne tregojmë ndryshe duke mbledhur grupe të dhënash të mëdha publikisht të disponueshme nga rrjeti, të cilat i ndajmë në disa fusha: lajme, fe, gjenerale dhe bisedë, për të trajnuar dhe paraqitur disa variante të modeleve NMT të bazuar në transformues në të gjithë fushat. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate.  Të dhënat tona (me ndarjen standarte për trajnimin, validimin dhe testimin), kodin dhe modelet janë në dispozicion në < https://github.com/gunnxx/indonesian-mt-data >', 'af': 'In die konteks van Masjien Vertaling In hierdie papier wys ons anders deur groot, publiek beskikbaar datastelle van die Web te samel, wat ons in verskeie domeine verdeel: nuus, geloof, algemeen en gesprekslyk, om sommige variante van transformer-gebaseerde NMT-modele te tref en te benchmark oor die domeine. Ons wys gebruik van BLEU dat ons modele goed oor hulle uitvoer, uitvoer die basisline Statistiese Masjien Vertaling (SMT) modele, en uitvoer gelykbaar met Google Vertaling. Ons datastelle (met die standaard geskep vir onderwerp, geldigheid en toets), kode en modele is beskikbaar op < https://github.com/gunnxx/indonesian-mt-data >', 'am': 'በመኪን ትርጓሜ (MT) ከ-እና ወደ እንግሊዘኛ፣ ባህሳ ኢንንዶኒስያ የዋና-resource ቋንቋ ሆኖአል፣ ስለዚህም የኔural Machine ትርጓሜ (NMT) በሚያስፈልገው ትልቅ ትምህርት ማህበረሰብ ዳታ ማህበረሰብ መሆኑን ያስችላል፡፡ በዚህ ገጽ፣ ከድረ ገጽ በታላቅ፣ የግልፅ ጉዳይ የተገኘ ዳታዎችን በመሰብሰብ እናሳየዋለን፡፡ እናሳያቸዋለን በBLEU የተጠቃሚ ሞዴሎቻችን በዙሪያቸው መልካም እንዲያደርጉ፣ የመድረክ Statistical Machine ትርጉም (SMT) ሞዴላዎችን እናደርጋለን እና ጎግል ትርጓሜዎችን በመተካከል እናደርጋለን፡፡ የዳታ ሰርቨሮች (ለትምህርት፣ ማስታወቂያ እና መሞከሪያዎች ለጭማሬ የተለየ) https://github.com/gunnxx/indonesian-mt-data >', 'hy': "Մեքենայի թարգմանման (MT) կոնտեքստում անգլերենից և անգլերենից Բահասան Ինդոնեզիան համարվում է ցածր ռեսուրսների լեզու, և հետևաբար նյարդային մեքենայի թարգմանման (NMT) կիրառումը, որը սովորաբար պահանջում է մեծ ուսուցման տվյալների համա Այս թղթի մեջ մենք այլ կերպ ցույց ենք տալիս համացանցից հավաքելով մեծ, հանրային հասանելի տվյալների համակարգեր, որոնք մենք բաժանեցինք մի քանի ոլորտներով' նորությունների, կրոնի, ընդհանուր հաղորդակցության և զրույցի մեջ, որպեսզի վերապատրաստենք և համեմատենք վերափոխողների հիմնված N Մենք ցույց ենք տալիս, օգտագործելով ԲԼԵՎ-ը, որ մեր մոդելները լավ են աշխատում նրանց միջով, ավելի լավ են աշխատում, քան հիմնական վիճակագրական մեքենայի թարգմանման (SMT) մոդելները, և համեմատական են Google Translate-ի հետ: Our datasets (with the standard split for training, validation, and testing), code, and models are available on < https://github.com/gunnxx/indonesian-mt-data _", 'az': 'Makinat Çevirməsi (MT) ilə İngilizə tərəfindən baxasa Indoneziya düşük ressurs dili hesab edildi və buna görə də böyük təhsil verilməsi qurması lazım olan Neural Machine Translation (NMT) tərəfindən istifadə edildi. Bu kağızda, internetten böyük, publicly mövcud veri setlərini toplayaraq göstəririk. Biz birkaç domenə bölüşdük: xəbərlər, dini, general və müzakirə, bəzi transformer-based NMT modellərinin dəyişikliklərini dəyişdirmək və benchmark etmək üçün. Biz BLEU vasitəsilə modellərimizin onların üstündə yaxşı işlədiklərini göstəririk, baseline Statistik Makin Çeviri (SMT) modellərini daha üstün etdik və Google Translate ilə müqayisədə işlədik. Məlumatlarımız (təcrübə, təcrübə və sınama üçün standart bölüşü ilə), kodu və modellərimiz < https://github.com/gunnxx/indonesian-mt-data >', 'bn': 'মেশিন অনুবাদ (এমটি) থেকে থেকে ইংরেজী থেকে বাহাসা ইন্দোনেশিয়াকে একটি কম সম্পদ ভাষা হিসেবে বিবেচনা করা হয়েছে এবং তাই নিউরাল মেশিন অনুবাদ (এনএমটি) প্রয়োগ করা হয়েছে যা সাধ এই কাগজটিতে আমরা ওয়েব থেকে বিশাল, প্রকাশ্য প্রাপ্ত তথ্য সংগ্রহ করে অন্যভাবে প্রদর্শন করি, যা আমরা বিভিন্ন ডোমেনের মধ্যে বিভক্ত করেছি: সংবাদ, ধর্ম, সাধারণ এবং আলোচনায আমরা বিলিউ ব্যবহার করে দেখাচ্ছি যে আমাদের মডেল তাদের সারা পার্শ্বে ভালো কাজ করে, বেসেলাইন পরিসংখ্যান পরিসংখ্যান মেশিন অনুবাদ (এসএম আমাদের ডাটাসেট (প্রশিক্ষণ, বৈধ এবং পরীক্ষার মাধ্যমে স্বাভাবিক বিভক্ত, প্রশিক্ষণ, পরীক্ষা, কোড এবং মডেলে পাওয় https://github.com/gunnxx/indonesian-mt-data >', 'bs': 'U kontekstu prevoda mašine (MT) od i do engleskog jezika, Bahasa Indonezija je smatrala niskim resursima, i stoga se primjenjuje neurološki prevod mašina (NMT) koji obično zahtijeva veliku obuku podataka pokazuje problematičnim. U ovom papiru pokazujemo drugačije skupljanjem velikih, javno dostupnih podataka sa interneta, koje smo podelili u nekoliko domena: vijesti, religija, generalni i razgovor, da obučimo i sklonimo neke variante NMT modela na transformatorima širom domena. Pokazujemo koristeći BLEU da naši modeli dobro izvršavaju preko njih, izvršavaju početne modele statističkog prevoda mašina (SMT) i izvršavaju usporedno s Google Translatom. Naši podaci (sa standardnom podjelom za obuku, potvrdu i testiranje), kod i modeli su dostupni na < https://github.com/gunnxx/indonesian-mt-data -Da.', 'ca': "En el context de la traducció màquina (MT) de l'anglès a Bahasa Indonèsia s'ha considerat una llengua de baix recursos, i per tant l'aplicació de la traducció màquina neuronal (NMT), que normalment necessita un conjunt de dades d'entrenament gran, sembla ser problemàtica. En aquest article, mostram d'altra manera col·leccionant grans conjunts de dades disponibles al públic a través de la Web, que ens dividim en diversos dominis: notícies, religió, general i conversació, per entrenar i comparar algunes variants de models NMT basats en transformadors a través de tots els dominis. Utilitzant BLEU mostram que els nostres models actuen bé a través d'ells, superen els models basals de traducció de màquines estadístiques (SMT), i actuen comparablement amb Google Translate. Els nostres conjunts de dades (amb la divisió estándar de formació, validació i proves), codi i models estan disponibles en < https://github.com/gunnxx/indonesian-mt-data >", 'cs': 'V kontextu strojového překladu (MT) z angličtiny je Bahasa Indonésie považována za jazyk s nízkými zdroji, a proto se ukáže použití neuronového strojového překladu (NMT), který obvykle vyžaduje velký soubor školení, jako problematické. V tomto článku ukazujeme opak shromažďováním velkých, veřejně dostupných datových sad z webu, které jsme rozdělili do několika domén: zprávy, náboženství, obecné a konverzace, abychom trénovali a porovnali některé varianty transformátorových NMT modelů napříč doménami. Pomocí BLEU ukazujeme, že naše modely v nich výkonně fungují, překonávají základní modely SMT (Statistical Machine Translate) a že jsou srovnatelně výkonné s překladem Google. Naše datové sady (se standardním rozdělením pro školení, validaci a testování), kód a modely jsou k dispozici na < https://github.com/gunnxx/indonesian-mt-data >', 'et': 'Masintõlke (MT) kontekstis inglise keelest ja inglise keelde peetakse Bahasa Indoneesiat vähese ressursiga keeleks ning seetõttu osutub probleemseks neuroaalse masintõlke (NMT) rakendamine, mis tavaliselt nõuab suurt koolitusandmekogumit. Käesolevas artiklis näitame vastupidist, kogudes veebist suuri avalikult kättesaadavaid andmekogumeid, mille jagame mitmeks valdkonnaks: uudised, religioon, üldine ja vestlus, et koolitada ja võrrelda mõningaid transformaatoripõhiste NMT mudelite variante kõigis valdkondades. Me näitame kasutades BLEU, et meie mudelid toimivad hästi läbi nende , ületavad baasi statistilise masintõlke (SMT) mudelid ja toimivad võrreldavalt Google Translate. Meie andmekogumid (koolituse, valideerimise ja testimise standardjaotusega), kood ja mudelid on saadaval aadressil < https://github.com/gunnxx/indonesian-mt-data >', 'fi': 'Bahasa Indonesia on pidetty englanninkielisen konekäännöksen (MT) yhteydessä vähäresurssisena kielenä, ja siksi Neural Machine Translation (NMT), joka tyypillisesti vaatii suurta koulutustietoa, osoittautuu ongelmalliseksi. Tässä artikkelissa osoitamme toisin keräämällä suuria, julkisesti saatavilla olevia datakokonaisuuksia verkosta, jotka jaamme useisiin toimialoihin: uutisiin, uskontoon, yleiseen ja keskusteluun, kouluttaaksemme ja vertaillaksemme joitakin muuntajapohjaisia NMT-malleja eri toimialueilla. Osoitamme käyttämällä BLEU, että mallimme suoriutuvat hyvin niiden välillä, suoriutuvat perusaikataulun Statistical Machine Translation (SMT) malleja, ja suoriutuvat vertailukelpoisesti Google Translaten kanssa. Aineistomme (koulutus-, validointi- ja testausstandardilla), koodimme ja mallit ovat saatavilla osoitteessa < https://github.com/gunnxx/indonesian-mt-data >', 'ha': '@ label In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains.  Tuna nuna misãlai masu amfani da BLEU, su sami misãlai masu amfani da su, kuma ka sami misãlai na fassarar da Google. Shiryoyinmu da aka samar da masallatan (da aka raba tsakanin mafarin, mai tsari, da jarraba, ko da misode kan < https://github.com/gunnxx/indonesian-mt-data >', 'sk': 'V kontekstu strojnega prevajanja (MT) iz angleščine in v angleščino se Bahasa Indonesia šteje za jezik z nizkimi viri, zato se izkaže, da je problematična uporaba nevralnega strojnega prevajanja (NMT), ki običajno zahteva velik nabor podatkov o usposabljanju. V tem prispevku dokazujemo drugače z zbiranjem velikih javno dostopnih naborov podatkov iz spleta, ki smo jih razdelili na več področij: novice, religija, splošno in pogovor, da bi usposobili in primerjali nekatere različice transformatorskih modelov NMT na vseh področjih. Pokažemo z uporabo BLEU, da naši modeli delujejo dobro v njih , izboljšajo osnovno statistično strojno prevajanje (SMT) modele in delujejo primerljivo z Google Translate. Naši nabori podatkov (s standardno razdelitvijo za usposabljanje, validacijo in testiranje), kodo in modeli so na voljo na < https://github.com/gunnxx/indonesian-mt-data >', 'jv': 'Nang kontèks mengko Manculir Terjamahan Nanging mapun iki, kita maneh menehi podho gampang akeh lan nganggo perusahaan dataset sing perusahaan anyar ing web, iki dadi bingi padha pakan: balik, Dino, Rusil lan nggihusahaan, iso nglanggar sampek lan soko akeh variant sing transformer-basa model NMT seng egal dumaten. Awak dhéwé menehi nggunaké CLUE kuwi model sing bisa sak bantuan karo hal-hal, gawe nyimpen model sing dadi Stastik Device translation (SMT) nggawe tarjamahan karo Google translation. FBI https://github.com/gunnxx/indonesian-mt-data >', 'he': 'בקשר לתרגום מכונות (MT) מהאנגלית, באהאסה אינדונזיה נחשבה שפה עם משאבים נמוכים, ולכן אפליקציה לתרגום מכונות נוירות (NMT) שדורשת בדרך כלל קבוצת נתונים אימונים גדולה הוכיחה להיות בעייתית. בעיתון הזה, אנו מראים אחרת באמצעות אסוף קבוצות נתונים גדולות, זמינות לציבור מהרשת, שאנחנו מתחלקים לכמה שדות: חדשות, דת, גנרל, ושיחה, כדי לאמן ולרמז כמה שונות של דוגמנים NMT מבוססים על מעבר ברחבי השדות. אנחנו מראים באמצעות BLEU שהדוגמנים שלנו פועלים היטב ברחבי הם, פועלים על דוגמנים של התרגום של מכונות סטטיסטיות (SMT) בסיסית, וביצעו בהשוואה עם Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on < https://github.com/gunnxx/indonesian-mt-data >', 'bo': 'In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. ང་ཚོས་རང་གི་མིག་དཔེ་གཟུགས་རིས་འདི་ཚོ་ལས་འཕགས་པ་བྱས་ཡོད་པའི་ BLEU སྤྱོད་མཁན་གྱི་མིག་དཔེ་གཙོ་རིམ་གྱི་ཚད་རྩིས་འཁོར་བ་མངོན་འཕགས་ ང་ཚོའི་གནད་སྡུད་ཚན་དག་གི་ཚད་ལྡན་གྱི་སྔོན་སྒྲིག་འཛུགས་བྱེད་ཀྱི་ཆ་འཕྲིན་(རྩོམ་པ་སྒྲིག་དང་་ཞིབ་བཤེར་བྱེ https://github.com/gunnxx/indonesian-mt-data >'}
{'en': 'Reducing the Search Space for Parallel Sentences in Comparable Corpora', 'ar': 'تقليل مساحة البحث عن الجمل المتوازية في Corpora المقارنة', 'es': 'Reducir el espacio de búsqueda de oraciones paralelas en corpus comparables', 'pt': 'Reduzindo o espaço de busca por sentenças paralelas em corpora comparáveis', 'fr': "Réduire l'espace de recherche pour les phrases parallèles dans des corpus comparables", 'ja': 'Comparable Corporaの並列文の検索スペースの縮小', 'zh': '减可较语料库中平行句索空间', 'ru': 'Сокращение пространства для поиска параллельных предложений в сопоставимых телах', 'hi': 'तुलनीय कॉर्पोरेट में समानांतर वाक्यों के लिए खोज स्थान को कम करना', 'ga': 'An Spás Cuardaigh le haghaidh Pianbhreitheanna Comhthreomhara sa Chorpóra Inchomparáide a Laghdú', 'hu': 'A párhuzamos mondatok keresési területének csökkentése az összehasonlítható Corporában', 'el': 'Μείωση του χώρου αναζήτησης για παράλληλες προτάσεις σε συγκρίσιμο σώμα', 'ka': 'შემდგომარებული კორპორაში პარალელი სიტყვების ძიება', 'kk': 'Сәйкесті корпорадағы параллель сөздердің іздеу орынын азайту', 'lt': 'Palyginamosios korporos lygiagrečių sakinių paieškos erdvės mažinimas', 'it': 'Riduzione dello spazio di ricerca per frasi parallele in Corpora comparabile', 'mk': 'Го намалува просторот за пребарување за паралелни реченици во споредлива корпора', 'ml': 'തെരച്ചില്\u200d കോര്\u200dപ്പോരായിരിക്കുന്ന പാര്\u200dവല്\u200d ശിക്ഷകള്\u200d', 'mn': 'Харьцуулагч Корпора дахь параллел өгүүлбэрийн хайх орон зайг багасгах', 'no': 'Redigerer søkjemodus for parallelle teikn i kompatibelt korpora', 'mt': 'Tnaqqis tal-Ispazju ta’ Tfittxija għal Sentenzi Paraleli f’Korpora Komparabbli', 'ms': 'Mengurangi Ruang Gelintar untuk Hukuman Paralel dalam Korpora Berbanding', 'sr': 'Smanjivanje prostora za potragu za paralelnim rečenicama u usporednoj korpori', 'so': 'Reducing Space of Search for Parallel Sentences in Comparable Corpora', 'ro': 'Reducerea spațiului de căutare pentru sentințe paralele în Corpora Comparabilă', 'pl': 'Zmniejszenie przestrzeni wyszukiwania zdań równoległych w porównywalnym korpusie', 'sv': 'Minska sökutrymmet för parallella meningar i jämförbara Corpora', 'ta': 'ஒப்பீடுபடும் கோர்போரில் இணைய வாக்குகளுக்கான தேடும் இடைவெளியை குறைக்கிறது', 'si': 'Name', 'ur': 'comparable Corpora میں Parallel Sentences کے لئے جستجو جگہ کم کر رہا ہے', 'uz': 'Name', 'vi': 'Giảm vùng tìm kiếm câu nói song song trong Tập Đoàn đối tượng', 'da': 'Reducering af søgepladsen for parallelle sætninger i sammenlignelig Corpora', 'bg': 'Намаляване на пространството за търсене на паралелни изречения в сравними корпуси', 'hr': 'Smanjivanje prostora za potragu za paralelnim kaznama u usporednoj korpori', 'nl': 'Vermindering van de zoekruimte voor parallelle zinnen in vergelijkbaar korpora', 'de': 'Reduzierung des Suchraums für parallele Sätze in vergleichbaren Korpora', 'id': 'Mengurangi Ruang Pencarian untuk Hukuman Paralel dalam Korpora Berbanding', 'ko': '비교 가능한 자료 라이브러리의 평행문 검색 공간 감소', 'sw': 'Kupunguza nafasi ya kutafuta Makosa ya Parallel katika Corpora inayofanana', 'fa': 'کاهش فضای جستجو برای عبارت پارالل در کورپورا مقایسه', 'tr': 'Parallel sözler üçin Arama ýerini höwes edýär', 'af': 'Redigeer die Soektog Spasie vir Parallele Utdrukke in Vergelykbare Korpora', 'sq': 'Shkatërrimi i hapësirës së kërkimit për dënime paralele në korporë të krahasueshme', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Համեմատական Կորպորայում համեմատական նախադասությունների որոնման տարածքը կրճատելը', 'az': "Compatibility Corpora'da Parallel Sözlər üçün Arama Boşluğunu azaltır", 'bn': 'প্যারালেল শাস্তির জন্য অনুসন্ধান কমানো', 'bs': 'Smanjenje prostora za potragu za paralelnim kaznama u usporednoj korpori', 'ca': "Reducir l'espai de cerca de sentences paralleles a la Corpora Comparable", 'cs': 'Snížení prostoru pro hledání paralelních vět ve srovnatelném korpusu', 'et': 'Paralleelsete lausete otsinguruumi vähendamine võrreldavas korpuses', 'fi': 'Samanaikaisten lauseiden hakutilan vähentäminen vertailukelpoisissa korpusissa', 'jv': 'Ngubah Kebebasan Panjenengan kanggo Kemerdekaan Parall', 'sk': 'Zmanjšanje iskalnega prostora za vzporedne stavke v primerljivih korpusih', 'ha': '@ action', 'bo': 'མཉམ་བསྡུར་ཅན་གྱི་ཚིག་རྟགས་ལྡོག་པའི་བར་སྟོང་ཚོའི་ནང་དུ་འཚོལ་བཤེར་སྟོང་', 'he': 'פחות מרחב החיפוש למשפטים parallels ב Corpora שווה'}
{'en': 'This paper describes and evaluates simple techniques for reducing the research space for parallel sentences in monolingual comparable corpora. Initially, when searching for parallel sentences between two comparable documents, all the possible sentence pairs between the documents have to be considered, which introduces a great degree of imbalance between parallel pairs and non-parallel pairs. This is a problem because even with a high performing algorithm, a lot of noise will be present in the extracted results, thus introducing a need for an extensive and costly manual check phase. We work on a manually annotated subset obtained from a French comparable corpus and show how we can drastically reduce the number of sentence pairs that have to be fed to a classifier so that the results can be manually handled.', 'ar': 'تصف هذه الورقة وتقيم تقنيات بسيطة لتقليل مساحة البحث للجمل المتوازية في مجموعات قابلة للمقارنة أحادية اللغة. في البداية ، عند البحث عن جمل متوازية بين وثيقتين متشابهتين ، يجب مراعاة جميع أزواج الجمل الممكنة بين المستندات ، مما يؤدي إلى درجة كبيرة من عدم التوازن بين الأزواج المتوازية والأزواج غير المتوازية. هذه مشكلة لأنه حتى مع وجود خوارزمية عالية الأداء ، سيكون هناك الكثير من الضوضاء في النتائج المستخرجة ، مما يؤدي إلى الحاجة إلى مرحلة فحص يدوي مكثفة ومكلفة. نحن نعمل على مجموعة فرعية مشروحة يدويًا تم الحصول عليها من مجموعة قابلة للمقارنة بالفرنسية ونبين كيف يمكننا تقليل عدد أزواج الجمل التي يجب تغذيتها إلى المصنف بشكل كبير بحيث يمكن معالجة النتائج يدويًا.', 'pt': 'Este artigo descreve e avalia técnicas simples para reduzir o espaço de pesquisa para sentenças paralelas em corpora comparáveis monolíngues. Inicialmente, ao procurar sentenças paralelas entre dois documentos comparáveis, todos os pares de sentenças possíveis entre os documentos devem ser considerados, o que introduz um grande grau de desequilíbrio entre pares paralelos e pares não paralelos. Isso é um problema porque mesmo com um algoritmo de alto desempenho, muito ruído estará presente nos resultados extraídos, introduzindo assim a necessidade de uma fase de verificação manual extensa e dispendiosa. Trabalhamos em um subconjunto anotado manualmente obtido de um corpus francês comparável e mostramos como podemos reduzir drasticamente o número de pares de frases que devem ser alimentados a um classificador para que os resultados possam ser manipulados manualmente.', 'es': 'Este artículo describe y evalúa técnicas simples para reducir el espacio de investigación para oraciones paralelas en cuerpos monolingües comparables. Inicialmente, cuando se buscan oraciones paralelas entre dos documentos comparables, se deben considerar todos los pares de oraciones posibles entre los documentos, lo que introduce un gran grado de desequilibrio entre los pares paralelos y los pares no paralelos. Esto es un problema porque incluso con un algoritmo de alto rendimiento, habrá mucho ruido en los resultados extraídos, introduciendo así la necesidad de una fase de verificación manual extensa y costosa. Trabajamos en un subconjunto anotado manualmente obtenido de un corpus comparable francés y mostramos cómo podemos reducir drásticamente el número de pares de oraciones que se deben alimentar a un clasificador para que los resultados se puedan manejar manualmente.', 'fr': "Cet article décrit et évalue des techniques simples pour réduire l'espace de recherche pour des phrases parallèles dans des corpus monolingues comparables. Au départ, lors de la recherche de phrases parallèles entre deux documents comparables, toutes les paires de phrases possibles entre les documents doivent être prises en compte, ce qui introduit un fort déséquilibre entre les paires parallèles et les paires non parallèles. C'est un problème car même avec un algorithme très performant, beaucoup de bruit sera présent dans les résultats extraits, introduisant ainsi la nécessité d'une phase de vérification manuelle étendue et coûteuse. Nous travaillons sur un sous-ensemble annoté manuellement obtenu à partir d'un corpus comparable en français et montrons comment réduire considérablement le nombre de paires de phrases qui doivent être introduites dans un classificateur afin que les résultats puissent être traités manuellement.", 'ja': '本論文では、単一言語で比較可能なコーパスにおける並列文の研究空間を縮小するための単純な手法について説明し、評価する。最初に、2つの同等のドキュメント間で並列文を検索する場合、ドキュメント間で考えられるすべての文のペアを考慮する必要があり、これは並列ペアと非並列ペアの間に非常に大きな不均衡をもたらします。これは、高性能なアルゴリズムであっても、抽出された結果に多くのノイズが存在するため、広範でコストのかかる手動チェックフェーズが必要となるためである。フランスの同等のコーパスから得られた手動で注釈付けされたサブセットに取り組み、結果を手動で処理できるように、分類子にフィードする必要がある文のペアの数を大幅に減らす方法を示します。', 'zh': '本文描述并评在单语可比语料库中减平行句子研究空间的简术。 初,两文档之间搜平行句,必思文档间所有句是,此平行是非对对之大不平也。 此一事也,虽用高性能算法,取实多噪声,故博而贵手动之。 臣等考法语可较语料库中所得手动注子集,并示如何大幅减必给分类器句对之数,以便手动处理结果。', 'hi': 'यह पेपर मोनोलिंगुअल तुलनीय कॉर्पोरेट में समानांतर वाक्यों के लिए शोध स्थान को कम करने के लिए सरल तकनीकों का वर्णन और मूल्यांकन करता है। प्रारंभ में, दो तुलनीय दस्तावेजों के बीच समानांतर वाक्यों की खोज करते समय, दस्तावेजों के बीच सभी संभावित वाक्य जोड़े पर विचार किया जाना चाहिए, जो समानांतर जोड़े और गैर-समानांतर जोड़े के बीच असंतुलन की एक बड़ी डिग्री का परिचय देता है। यह एक समस्या है क्योंकि यहां तक कि एक उच्च प्रदर्शन एल्गोरिथ्म के साथ, निकाले गए परिणामों में बहुत सारे शोर मौजूद होंगे, इस प्रकार एक व्यापक और महंगे मैनुअल चेक चरण की आवश्यकता को पेश करेंगे। हम एक फ्रांसीसी तुलनीय कॉर्पस से प्राप्त मैन्युअल रूप से एनोटेट किए गए सबसेट पर काम करते हैं और दिखाते हैं कि हम वाक्य जोड़े की संख्या को कैसे कम कर सकते हैं जिन्हें क्लासिफायर को खिलाया जाना है ताकि परिणामों को मैन्युअल रूप से संभाला जा सके।', 'ru': 'В этой статье описываются и оцениваются простые методы сокращения исследовательского пространства для параллельных предложений в одноязычных сопоставимых телах. Первоначально при поиске параллельных предложений между двумя сопоставимыми документами необходимо учитывать все возможные пары предложений между документами, что вносит большую степень дисбаланса между параллельными парами и непараллельными парами. Это проблема, потому что даже при высокопроизводительном алгоритме в извлеченных результатах будет присутствовать много шума, таким образом, возникает необходимость в обширной и дорогостоящей фазе ручной проверки. Мы работаем над вручную аннотированным подмножеством, полученным из французского сопоставимого корпуса, и показываем, как мы можем резко сократить количество пар предложений, которые должны быть загружены в классификатор, чтобы результаты могли обрабатываться вручную.', 'ga': "Déanann an páipéar seo cur síos agus meastóireacht ar theicnící simplí chun an spás taighde a laghdú d’abairtí comhthreomhara i gcorpora inchomparáide aonteangacha. Ar dtús, nuair a bhíonn abairtí comhthreomhara á lorg idir dhá dhoiciméad inchomparáide, ní mór na péirí abairtí uile a d'fhéadfadh a bheith ann idir na doiciméid a mheas, rud a thugann isteach go leor éagothroime idir péirí comhthreomhara agus péirí neamh-chomhthreomhara. Is fadhb é seo mar fiú le algartam ardfheidhmíochta, beidh go leor torainn i láthair sna torthaí a bhaintear, rud a fhágann go mbeidh gá le céim sheiceála láimhe fhairsing agus chostasach. Oibrímid ar fho-thacar anótáilte de láimh a fhaightear ó chorpas inchomparáide Fraincise agus taispeánann muid conas is féidir linn laghdú suntasach a dhéanamh ar líon na bpéirí abairtí a chaithfear a thabhairt d’aicmitheoir ionas gur féidir na torthaí a láimhseáil de láimh.", 'el': 'Η παρούσα εργασία περιγράφει και αξιολογεί απλές τεχνικές για τη μείωση του ερευνητικού χώρου για παράλληλες προτάσεις σε μονόγλωσσα συγκρίσιμα σώματα. Αρχικά, κατά την αναζήτηση παράλληλων προτάσεων μεταξύ δύο συγκρίσιμων εγγράφων, πρέπει να ληφθούν υπόψη όλα τα πιθανά ζεύγη προτάσεων μεταξύ των εγγράφων, γεγονός που εισάγει μεγάλο βαθμό ανισορροπίας μεταξύ παράλληλων ζευγαριών και μη παράλληλων ζευγαριών. Αυτό αποτελεί πρόβλημα επειδή ακόμη και με έναν αλγόριθμο υψηλής απόδοσης, θα υπάρχει πολύς θόρυβος στα αποτελέσματα που εξάγονται, εισάγοντας έτσι την ανάγκη για μια εκτεταμένη και δαπανηρή φάση χειροκίνητου ελέγχου. Εργαζόμαστε σε ένα χειροκίνητα σχολιασμένο υποσύνολο που λαμβάνεται από ένα γαλλικό συγκρίσιμο σώμα και δείχνουμε πώς μπορούμε να μειώσουμε δραστικά τον αριθμό των ζευγαριών προτάσεων που πρέπει να τροφοδοτηθούν σε έναν ταξινομητή έτσι ώστε τα αποτελέσματα να μπορούν να αντιμετωπιστούν χειροκίνητα.', 'hu': 'Ez a tanulmány leírja és értékeli a párhuzamos mondatok kutatási területének csökkentését egynyelvű hasonló korpuszokban. Kezdetben két hasonló dokumentum közötti párhuzamos mondat keresésekor figyelembe kell venni a dokumentumok közötti összes lehetséges mondatpárt, ami nagyfokú egyensúlyhiányt vezet be a párhuzamos és nem párhuzamos párok között. Ez azért jelent problémát, mert még egy nagy teljesítményű algoritmus esetén is nagy zaj fog jelen lenni a kivont eredményekben, így szükségessé teszi a kiterjedt és költséges kézi ellenőrzési fázis széles körű és költséges. Egy kézzel jegyzetelt részhalmazon dolgozunk, amelyet egy francia összehasonlítható korpuszból kapunk, és megmutatjuk, hogyan lehet drasztikusan csökkenteni azon mondatpárok számát, amelyeket egy osztályozónak kell etetni, hogy az eredmények manuálisan kezelhetők legyenek.', 'it': 'Questo articolo descrive e valuta tecniche semplici per ridurre lo spazio di ricerca per frasi parallele in corpora comparabili monolingue. Inizialmente, nella ricerca di frasi parallele tra due documenti comparabili, devono essere prese in considerazione tutte le possibili coppie di frasi tra i documenti, il che introduce un grande grado di squilibrio tra coppie parallele e coppie non parallele. Questo è un problema perché anche con un algoritmo ad alte prestazioni, molto rumore sarà presente nei risultati estratti, introducendo così la necessità di una fase di controllo manuale estesa e costosa. Lavoriamo su un sottoinsieme annotato manualmente ottenuto da un corpus comparabile francese e mostriamo come possiamo ridurre drasticamente il numero di coppie di frasi che devono essere alimentate a un classificatore in modo che i risultati possano essere gestiti manualmente.', 'ka': 'ეს დოკუმენტი გამოსახულება და განსაზღვრებას მარტივი ტექნოგიები, რომლებიც მონოლენგური შემდგომარებული კოპორაში პარალელი სიტყვების პარალელი სიტ საწყისო, როდესაც ორი შემდგომარებული დოკუმენტების შორის პარალელი სიტყვების ძებნა, ყველა შესაძლებელი სიტყვები დოკუმენტების შორის უნდა იყოს, რომელიც პარალელი ზოკუმენტების და არ პარა ეს არის პრობლემა, რადგან უფრო დიდი გავაკეთებული ალგორიტიმზე უფრო სიტყვა იქნება ექსტრაქტურული შედეგი, რადგან გავაკეთებ უნდა გავაკეთება გასაკეთებელი და ძალიან მარტივი შემოწმე ჩვენ მუშაობით პირადი დაბრუნებული სესესეტი, რომელსაც ფრანგური შემდგომარებული კორპუსდან მიიღებული და ჩვენ ჩვენ ჩვენ შეგვიძლია გავაკეთოთ როგორ შეგვიძლია გავაკეთოთ რამდენიმე რაოდენობა', 'lt': 'Šiame dokumente aprašomi ir vertinami paprasti metodai, kuriais siekiama sumažinti lygiagrečių sakinių mokslinių tyrimų erdvę vienos kalbos lygiavertėje korporoje. Iš pradžių, ieškant lygiagrečių sakinių tarp dviejų palyginamų dokumentų, reikia apsvarstyti visas galimas dokumentų sakinių poras, dėl kurių atsiranda didelis lygiagrečių poros ir ne lygiagrečių poros disbalansas. Tai problem a, nes net ir naudojant aukšto lygio algoritmą gautuose rezultatuose bus daug triukšmo, todėl reikės išsamaus ir brangaus rankinio patikrinimo etapo. Mes dirbame rankiniu būdu anotuotu pogrupiu, gautu iš Prancūzijos palyginamojo korpuso, ir parodome, kaip galime drastiškai sumažinti sakinių poros skaičių, kurie turi būti tiekiami klasifikatoriui, kad rezultatai būtų tvarkomi rankiniu būdu.', 'kk': 'Бұл қағаз монолингі салыстырылатын корпораға параллель сөздер үшін зерттеу орынды азайту және оқиғаны анықтайды. Бастапқы, екі салыстырылатын құжаттардың арасындағы параллел сөздерді іздегенде, құжаттардың арасындағы барлық сөздерді қарастыру керек. Бұл параллел екі мен параллелі екі арасындағы бірнеше салыстыру деңгейі. Бұл мәселе, өйткені жоғары орындалған алгоритм арқылы, шығарылған нәтижелерде көп дыбыс болады, сондықтан қолмен жұмыс тексеру кезінде қажет болады. Біз французша салыстырылатын корпустан алған қолмен белгіленген бөлігінде жұмыс істеп, классификацияға жұмыс істеу керек сөздер санын қалай қысқарту үшін нәтижелерді қолмен өзгертуге болады.', 'ml': 'ഈ പേപ്പറിന്റെ വിശദീകരിക്കുന്നു സാധാരണ വാക്കുകള്\u200dക്ക് പരിശോധന സ്ഥലം കുറയ്ക്കുന്നതിനായി എളുപ്പമായ സാങ്കേതികവി ആദ്യം രണ്ടു തുല്യമായ രേഖകള്\u200dക്കിടയില്\u200d തെരഞ്ഞെടുക്കുമ്പോള്\u200d, രേഖകള്\u200dക്കിടയിലെ എല്ലാ സാധ്യതകള്\u200dക്കുമിടയിലുള്ള വാക്കുകളും വിചാരിക്കേണ്ടതുണ്ട്, അത ഇതൊരു പ്രശ്നമാണ്, കാരണം വളരെ പ്രവര്\u200dത്തിപ്പിക്കുന്ന ആല്\u200dഗോരിതം പോലും ഒരുപാട് ശബ്ദം പുറത്തെടുക്കപ്പെട്ട ഫലങ്ങളില്\u200d ഉണ്ടാകും. അതുകൊണ്ട് വിശ ഫ്രെഞ്ചില്\u200d നിന്നും ഒരു കോര്\u200dപ്പുസില്\u200d നിന്നും കൈകാര്യമായി വിഷമിക്കപ്പെട്ട സബ്ബട്ടില്\u200d ഞങ്ങള്\u200d ജോലി ചെയ്യുന്നു. അതിന്റെ ഫലങ്ങള്\u200d കൈകാര്യം ചെയ്യാന', 'ms': 'Kertas ini menggambarkan dan menilai teknik sederhana untuk mengurangi ruang kajian untuk kalimat selari dalam satu bahasa corpora yang boleh dibandingkan. Pada awalnya, apabila mencari kalimat selari antara dua dokumen yang boleh dibandingkan, semua pasangan kalimat yang mungkin antara dokumen perlu dianggap, yang memperkenalkan darjah besar ketidakseimbangan antara pasangan selari dan pasangan bukan selari. Ini adalah masalah kerana walaupun dengan algoritma berfungsi tinggi, banyak bunyi akan hadir dalam hasil ekstrak, sehingga memperkenalkan keperluan untuk fase pemeriksaan manual yang luas dan mahal. Kami bekerja pada subset yang dicatat secara manual yang diperoleh dari korpus yang boleh dibandingkan Perancis dan menunjukkan bagaimana kita boleh mengurangi secara drastik bilangan pasangan kalimat yang perlu diberi kepada pengklasifikasi sehingga hasilnya boleh dikendalikan secara manual.', 'mk': 'Овој документ опишува и оценува едноставни техники за намалување на истражувачкиот простор за паралелни реченици во монојазични споредливи тела. На почетокот, кога се бараат паралелни реченици помеѓу двата споредливи документи, мора да се разгледаат сите можни парови реченици помеѓу документите, што воведува голем степен на нерамнотежа помеѓу паралелните парови и непаралелните парови. Ова е проблем бидејќи дури и со високо функционален алгоритм, многу бука ќе биде присутна во извадените резултати, со што ќе се воведе потребата за екстремна и скапа фаза рачно проверка. Работиме на рачно анотиран подгруп добиен од француски споредлив корпус и покажуваме како драстично можеме да го намалиме бројот на парови на реченици кои мора да бидат пренесени на класификатор за резултатите да бидат рачно управувани.', 'mn': 'Энэ цаас нэг хэлний харьцуулагдмал корпоратын судалгааны орон зайг багасгах энгийн технологийг тайлбарлаж, үнэлдэг. Эхлээд, хоёр харьцуулагдмал баримт хоорондын параллел өгүүлбэрийг хайх үед баримт хоорондын бүх боломжтой өгүүлбэрүүдийг ойлгох хэрэгтэй. Энэ нь параллел хоёр болон параллел хоёр хоорондын маш их тэгшитгэл байдлыг илэрхий Энэ нь асуудал юм. Учир нь өндөр үйлдвэрлэлтийн алгоритм дээр ч маш олон чимээ гарсан үр дүнд гарч ирнэ. Тэгэхээр өргөн, үнэтэй шалгалтын шалгалтын шаардлагатай шаардлагатай. Бид Французтай харьцуулагдмал корпус гараараа гар давтагдсан хэсэг дээр ажиллаж, хэрхэн хэдэн өгүүлбэртэй хоёр хэсэг нь хуваалцах хэрэгтэй вэ гэдгийг харуулж байна.', 'ro': 'Această lucrare descrie și evaluează tehnici simple de reducere a spațiului de cercetare pentru propoziții paralele în corpore monolingve comparabile. Inițial, atunci când căutați propoziții paralele între două documente comparabile, trebuie luate în considerare toate perechile de propoziții posibile între documente, ceea ce introduce un grad mare de dezechilibru între perechile paralele și perechile non-paralele. Aceasta este o problemă deoarece, chiar și cu un algoritm de înaltă performanță, o mulțime de zgomot va fi prezent în rezultatele extrase, introducând astfel necesitatea unei faze extinse și costisitoare de verificare manuală. Lucrăm la un subset adnotat manual obținut dintr-un corpus comparabil francez și arătăm cum putem reduce drastic numărul de perechi de propoziții care trebuie hrănite unui clasificator astfel încât rezultatele să poată fi manipulate manual.', 'no': 'Denne papiret beskriver og evaluerer enkle teknikk for å redusera forskningsrommet for parallelle setningar i monospråk sammenlignbare korpora. I begynnelsen må alle dei moglege setningsprogrammene mellom dokumentet vera tanke ved søk etter parallelle setningar mellom to sammenlignbare dokument, som introduserer ein stor grad ulikhet mellom parallelle par og ikkje parallelle par. Dette er eit problem fordi sjølv med ein høg utføringsgoritme, vil mange støy være i utpakka resultatet, slik at du introduserer ein nødvendig måte for utvida og kostnamt manuelt sjekkfase. Vi arbeider på ei manuelt oppmerket undergruppe som er henta frå eit fransk sammenlignbar korpus og viser korleis vi kan drastisk redusera talet på setningspar som må førast til ein klassifiserer slik at resultatet kan handterast manuelt.', 'pl': 'W artykule opisano i oceniano proste techniki zmniejszania przestrzeni badawczej dla zdań równoległych w jednojęzycznych porównywalnych korpusach. Początkowo, przy poszukiwaniu zdań równoległych między dwoma porównywalnymi dokumentami, należy uwzględnić wszystkie możliwe pary zdań między dokumentami, co wprowadza duży stopień nierównowagi między parami równoległymi a parami nierównoległymi. Jest to problem, ponieważ nawet w przypadku wysokiej wydajności algorytmu dużo hałasu będzie obecne w ekstraktowanych wynikach, wprowadzając w ten sposób potrzebę obszernej i kosztownej fazy kontroli ręcznej. Pracujemy nad ręcznie adnotowanym podzbiorem uzyskanym z porównywalnego korpusu francuskiego i pokazujemy, jak możemy drastycznie zmniejszyć liczbę par zdań, które muszą być podawane do klasyfikatora, aby wyniki mogły być ręcznie obsługiwane.', 'mt': 'Dan id-dokument jiddeskrivi u jevalwa tekniki sempliċi għat-tnaqqis tal-ispazju tar-riċerka għal sentenzi paralleli f’korpura paragunabbli monolingwi. Fil-bidu, meta jkunu qed ifittxu sentenzi paralleli bejn żewġ dokumenti komparabbli, għandhom jiġu kkunsidrati l-pari kollha possibbli ta’ sentenzi bejn id-dokumenti, li jintroduċi grad kbir ta’ żbilanċ bejn pari paralleli u pari mhux paralleli. Din hija problem a għaliex anke b’algoritmu ta’ prestazzjoni għolja, ħafna storbju se jkun preżenti fir-riżultati estratti, u b’hekk tintroduċi ħtieġa għal fażi ta’ kontroll manwali estensiva u għalja. Aħna naħdmu fuq sottosett annotat manwalment miksub minn korpus komparabbli Franċiż u nuru kif nistgħu jnaqqsu drastikament in-numru ta’ pari ta’ sentenzi li jridu jiġu alimentati lil klassifikatur sabiex ir-riżultati jkunu jistgħu jiġu mmaniġġjati manwalment.', 'so': 'Warqaddan ayaa qoraalaya oo qiimeeyaa qalabka fudud ee hoos u dhigista goobta waxbarashada ee qoraalka isbarbarka ah ee korporada isku barbarashada. Bilowga, marka aad raadineysid xukunka lambarka ah oo u dhexeeya labada dukumenti ee is-barbarka ah, waa in dhammaan labada noocyo oo u suurtagal ah looga fikiraa labada dukumentiyada dhexdooda, taas oo ku soo bandhigaya sinnaan aad u badan oo u dhexeeya labada lammaanood iyo labo aan isku mid ahayn. Tani waa dhibaato, sababtoo ah xataa haddii ay leedahay algorithm aad u samaysan, codyo badan ayaa laga heli doonaa resultiyada la soo saaray, oo sidaas darteed waxay u baahan tahay fasaxa koontarooyinka dhaqdhaqaalaha iyo kharashka ah. Waxaynu ku shaqaynaynaa koob aad si rasmi ah loo isticmaalay barafka faransiiska oo isbarbarka ah, waxaana tusinaynaa sidoo kale si aad u hoosaystiro lambarka loo cuno si ay ugu dhamaado fasaxa.', 'sv': 'Denna uppsats beskriver och utvärderar enkla tekniker för att minska forskningsutrymmet för parallella meningar i enspråkiga jämförbara korpora. Inledningsvis, när man söker efter parallella meningar mellan två jämförbara dokument, måste alla möjliga meningspar mellan dokumenten beaktas, vilket medför en stor obalans mellan parallella och icke-parallella par. Detta är ett problem eftersom även med en högpresterande algoritm kommer mycket buller att finnas i de extraherade resultaten, vilket innebär ett behov av en omfattande och kostsam manuell kontrollfas. Vi arbetar med en manuellt kommenterad delmängd som erhållits från en fransk jämförbar korpus och visar hur vi drastiskt kan minska antalet meningpar som måste matas till en klassificerare så att resultaten kan hanteras manuellt.', 'si': 'මේ පත්තේ සාමාන්\u200dය භාෂාවක් සමාන්\u200dය භාෂාවක් සමාන්\u200dය භාෂාවක් වලට පරීක්ෂණාවක් අඩු කරන්න සරල ප්\u200dරකාශ ආරම්භයෙන්, සාමාන්\u200dය වාක්ය දෙකක් අතර සමාන්ය වාක්ය හොයාගන්න, සමාන්ය වාක්ය දෙකක් අතර සමාන්ය වාක්ය සහ සමාන්ය නැති දෙකක් අතර සමාන්ය ව මේක ප්\u200dරශ්නයක් තියෙන්නේ මොකද උත්සන්න ඇල්ගෝරිතම් එක්ක, ගොඩක් ශබ්දයක් ප්\u200dරශ්නයක් තියෙන්නේ අපි ප්\u200dරෑන්ස් සම්පූර්ණ කොර්පුස් එකෙන් පිළිගත්ත සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර', 'sr': 'Ovaj papir opisuje i procjenjuje jednostavne tehnike za smanjenje istraživanja prostora za paralelne rečenice u monojezičkoj usporednoj korpori. Prvo, kada tražimo paralelne rečenice između dve usporedne dokumente, moraju se razmotriti sve moguće parove rečenice između dokumenta, koje predstavljaju veliku stupnju neravnoteža između paralelnih parova i paralelnih parova. To je problem, jer čak i sa visokim izvršenim algoritmom, mnogo buke će biti prisutno u izvlačenim rezultatima, tako da će predstaviti potrebu za širokom i skupom ručnom fazom provjere. Radimo na ruèno annotiranoj subjekti dobijenoj od francuskog usporednog korpusa i pokazujemo kako možemo drastično smanjiti broj parova rečenica koje moraju biti hranjene klasifikatoru kako bi rezultati mogli biti ruèno rješeni.', 'ur': 'This paper describes and evaluates simple techniques for reducing the research space for parallel sentences in monolingual comparable corpora. آغاز سے، جب دو مقایسہ دفتروں کے درمیان parallel sentences تلاش کرتے ہیں، تمام امکان کلمز کے جوڑوں کو دفتروں کے درمیان سمجھ لینا چاہیے، جو مشابہ جوڑوں اور غیر مشابہ جوڑوں کے درمیان ایک بڑی درجہ کی عداوت پیش کرتا ہے. یہ ایک مسئلہ ہے کیونکہ اچھی عملہ الگوریتم کے ساتھ بھی بہت سی آواز نکالے ہوئے نتیجے میں موجود ہوگی، اس کے ذریعہ ایک وسیع اور مزید مزید منفی چک فاز کی ضرورت پیش کرتی ہے. ہم ایک فرنس کے مطابق قابل مقایسہ کرپوس سے حاصل ہونے والی سپٹ پر کام کرتے ہیں اور دکھاتے ہیں کہ ہم کس طرح جماعت جوڑوں کی تعداد کم کر سکتے ہیں جو ایک کلاسیر کو کھلانا چاہتے ہیں تاکہ نتیجے اپنے ہاتھ کے ساتھ سمجھ سکتے ہیں.', 'ta': 'இந்த தாள் சுலபமான தொழில்நுட்பத்தை விளக்குகிறது மற்றும் மதிப்பிடுகிறது மோனோலிங்கூட்டு ஒப்பிடும் வாக்குகளின்  முதலில், இரண்டு ஒப்பிடும் ஆவணங்களுக்கிடையில் இணைய வாக்குகளை தேடும் போது, ஆவணங்களுக்கிடையில் அனைத்து சாத்தியமான வாக்கு ஜோடிகளை கருத வேண்டும், அது இண இது ஒரு பிரச்சினையாகும் ஏனெனில் அதிக செயல்படுத்தும் ஆல்ஜிரித்துடன் கூட, வெளியிடும் முடிவுகளில் நிறைய சப்தம் இருக்கும், அதனால் விரி நாங்கள் ஒரு பிரெஞ்சு ஒப்பிடும் கார்புஸிலிருந்து கைமுறையில் வேலை செய்கிறோம் மற்றும் முடிவுகளை கைமுறையாக கைமுறைப்படுத்த வாக்கியின் ஜோ', 'uz': "Bu qogʻoz aytadi va qiymatlashi oddiy teknologiyani o'zgartirish uchun o'qituvchilarni o'zgartirish mumkin. Birinchi paytda, ikkita tenglar hujjatning orasidagi soʻzlarni qidirishda, hujjatlar orasidagi hamma maxsus soʻz qoʻllanilishi kerak. Bu hujjatning orasidagi tenglar va tenglar ikki parchalar orasidagi juda katta daraja balandligini koʻrsatish mumkin. Bu muammo, chunki juda katta bajarish algoritda, ko'p tovush natijalariga ega bo'ladi, shunday qilib katta va qiymati qoʻllanmalar tekshirish uchun kerak. Biz Fransuzning bir qo'lbola bir xil kompyuterdan ishlayapmiz va natijalarni qoʻlbola qo'llab qo'llab qo'llab qo'llab qo'llash uchun gaplar sonlarini qanday kamaytirishingiz mumkin.", 'vi': 'Tờ giấy này mô tả và đánh giá các kỹ thuật đơn giản để giảm vùng nghiên cứu cho các câu song song song trong chữ La- ngôn tương tự. Lúc đầu, khi tìm kiếm các câu tương đồng giữa hai tài liệu tương ứng, tất cả các câu có thể ghép giữa các tài liệu phải được cân nhắc, nó tạo ra một mức độ mất cân bằng lớn giữa các cặp song song và các cặp không song song. Đây là một vấn đề bởi vì ngay cả với thuật toán hiệu suất cao, sẽ có rất nhiều tiếng ồn trong kết quả được chiết xuất, nên sẽ tạo nhu cầu cho một giai đoạn kiểm tra bằng tay rộng lớn và tốn kém. Chúng tôi làm việc trên một nhóm được ghi chú bằng tay lấy từ một tập thể tương ứng Pháp và cho thấy chúng tôi có thể giảm mạnh số cặp câu cần phải đưa cho người phân loại để kết quả có thể được xử lý bằng tay.', 'bg': 'Тази статия описва и оценява прости техники за намаляване на изследователското пространство за паралелни изречения в едноезични сравними корпуси. Първоначално, при търсене на паралелни изречения между два сравними документа, трябва да се вземат предвид всички възможни двойки изречения между документите, което въвежда голяма степен на дисбаланс между паралелни и непаралелни двойки. Това е проблем, защото дори и с високоефективен алгоритъм, много шум ще присъства в извлечените резултати, като по този начин се въвежда необходимост от обширна и скъпа фаза на ръчна проверка. Работим върху ръчно анотиран поднабор, получен от сравним френски корпус и показваме как можем драстично да намалим броя на двойките изречения, които трябва да бъдат подавани на класификатор, така че резултатите да могат да бъдат ръчно обработени.', 'nl': 'Dit artikel beschrijft en evalueert eenvoudige technieken voor het verkleinen van de onderzoeksruimte voor parallelle zinnen in eentalige vergelijkbare corpora. Aanvankelijk moeten bij het zoeken naar parallelle zinnen tussen twee vergelijkbare documenten alle mogelijke zinnenparen tussen de documenten in aanmerking worden genomen, wat een grote mate van onbalans tussen parallelle paren en niet-parallelle paren tot gevolg heeft. Dit is een probleem omdat zelfs met een hoog presterend algoritme veel ruis aanwezig zal zijn in de geëxtraheerde resultaten, waardoor een uitgebreide en kostbare handmatige controlefase nodig is. We werken aan een handmatig geannoteerde subset verkregen uit een Frans vergelijkbaar corpus en laten zien hoe we het aantal zinnenparen dat naar een classificator moet worden gevoerd drastisch kunnen verminderen zodat de resultaten handmatig kunnen worden verwerkt.', 'da': 'Denne artikel beskriver og evaluerer enkle teknikker til at reducere forskningspladsen for parallelle sætninger i ensprogede sammenlignelige korpora. I første omgang, når man søger efter parallelle sætninger mellem to sammenlignelige dokumenter, skal alle de mulige sætningspar mellem dokumenterne overvejes, hvilket medfører en stor ubalance mellem parallelle par og ikke-parallelle par. Dette er et problem, fordi selv med en højtydende algoritme vil der være meget støj til stede i de udvundne resultater, hvilket indfører et behov for en omfattende og dyr manuel kontrolfase. Vi arbejder på en manuelt kommenteret delmængde, der er opnået fra et fransk sammenligneligt korpus, og viser, hvordan vi drastisk kan reducere antallet af sætningspar, der skal fodres til en klassificering, så resultaterne kan håndteres manuelt.', 'hr': 'Ovaj papir opisuje i procjenjuje jednostavne tehnike za smanjenje istraživačkog prostora za paralelne rečenice u jednojezičkom usporednom tijelu. Prvo, kada tražimo paralelne rečenice između dvije usporedne dokumente, moraju se razmotriti sve moguće parove rečenice između dokumenta, što predstavlja veliku stupnju neravnoteža između paralelnih parova i paralelnih parova. To je problem, jer čak i sa visokim izvršenim algoritmom, mnogo buke će biti prisutno u izvlačenim rezultatima, tako što će uvoditi potrebu za širokom i skupom ručnom fazom provjere. Radimo na ručno annotiranoj subjekti dobijenoj od francuskog usporednog korpusa i pokazujemo kako možemo drastično smanjiti broj parova kazne koje moraju biti hranjene klasifikatoru kako bi rezultati mogli biti rukovno rješeni.', 'de': 'Diese Arbeit beschreibt und evaluiert einfache Techniken zur Reduzierung des Forschungsraums für parallele Sätze in einsprachigen vergleichbaren Korpora. Bei der Suche nach parallelen Sätzen zwischen zwei vergleichbaren Dokumenten müssen zunächst alle möglichen Satzpaare zwischen den Dokumenten berücksichtigt werden, was zu einem großen Ungleichgewicht zwischen parallelen und nicht-parallelen Paaren führt. Dies ist ein Problem, da selbst bei einem leistungsstarken Algorithmus viel Rauschen in den extrahierten Ergebnissen vorhanden ist, wodurch eine umfangreiche und kostspielige manuelle Prüfphase erforderlich wird. Wir arbeiten an einer manuell annotierten Teilmenge aus einem französischen vergleichbaren Korpus und zeigen, wie wir die Anzahl der Satzpaare, die einem Klassifikator zugeführt werden müssen, drastisch reduzieren können, damit die Ergebnisse manuell bearbeitet werden können.', 'id': 'Kertas ini menjelaskan dan mengevaluasikan teknik sederhana untuk mengurangi ruang penelitian untuk kalimat paralel dalam corpora yang parah monobahasa. Pada awalnya, ketika mencari kalimat paralel antara dua dokumen yang dapat dibandingkan, semua mungkin pasangan kalimat antara dokumen harus dipertimbangkan, yang memperkenalkan tingkat besar ketidakseimbangan antara pasangan paralel dan pasangan non-paralel. This is a problem because even with a high performing algorithm, a lot of noise will be present in the extracted results, thus introducing a need for an extensive and costly manual check phase.  Kami bekerja pada subset yang dicatat secara manual yang diperoleh dari corpus yang dapat dibandingkan Perancis dan menunjukkan bagaimana kita dapat mengurangi secara drastis jumlah pasangan kalimat yang harus diberikan kepada klasifikasi sehingga hasilnya dapat ditangani secara manual.', 'ko': '본고는 단어가 어료 라이브러리에서 평행문 연구 공간을 줄일 수 있는 간단한 방법을 묘사하고 평가했다.처음에 두 비교 가능한 문서 사이에서 평행 문장을 검색할 때 반드시 문서 사이의 가능한 모든 문장 쌍을 고려해야 한다. 이것은 평행 쌍과 비평행 쌍 사이에 어느 정도의 불균형을 도입했다.고성능 알고리즘을 사용해도 추출된 결과에 대량의 소음이 존재하기 때문에 대량이고 비싼 수동 검사 단계가 필요하다.우리는 프랑스어 비교 자료 라이브러리에서 얻은 수동 주석 서브집합을 연구했고, 수동으로 결과를 처리하기 위해 분류기를 입력해야 하는 문장 쌍의 수량을 대폭 줄이는 방법을 보여 주었다.', 'sw': 'Gazeti hili linaelezea na kutathmini mbinu rahisi za kupunguza nafasi ya utafiti kwa ajili ya hukumu za usambazaji katika makampuni yanayofanana na lugha. Mwanzoni, wakati akitafuta hukumu za usambazaji kati ya nyaraka mbili zilizofanana, hukumu zote zinazowezekana ni lazima zichukuliwe, ambazo zinaleta kiwango kikubwa cha usawa kati ya wanandoa tofauti na wanaume wasiolinganisha. Hili ni tatizo kwa sababu hata kwa utambulisho mkubwa, kelele nyingi zitakuwa kwenye matokeo yaliyotolewa, kwa hiyo inahitaji kuangalia kiwango kikubwa na gharama kwa manufaa. Tunafanya kazi kwenye kituo cha vibaya kilichopata kutoka kwenye makampuni yanayofanana na Kifaransa na kuonyesha jinsi tunavyoweza kupunguza kwa kiasi kikubwa idadi ya wanandoa wa hukumu ambazo zinapaswa kulisha kwa mfanyakazi ili matokeo yanaweza kukabiliana kwa mikononi.', 'fa': 'این کاغذ تکنیک ساده برای کاهش فضای تحقیقات برای جمله\u200cهای متفاوتی در شرکت متقابل یک زبان توصیف می\u200cکند و ارزش می\u200cدهد. در ابتدا، وقتی جستجوی جمله\u200cهای متفاوتی بین دو سند مقایسه\u200cای، همه جفت\u200cهای جمله\u200cهای ممکن بین سند\u200cها باید به نظر بگیرند، که درجه بزرگی از نابرابری بین جفت\u200cهای متفاوتی و جفت\u200cهای متفاوتی را معرفی می\u200cکند. این یک مشکل است چون حتی با الگوریتم بالا انجام می\u200cدهد، صدای زیادی در نتیجه\u200cهای خارج شده وجود خواهد داشت، بنابراین نیازی برای یک مراحل چک دستی وسیع و ارزشمند را معرفی می\u200cکند. ما روی یک زیرزمین دستی که از یک کورپوس قابل مقایسه فرانسوی دریافت شده کار می کنیم و نشان می دهیم چگونه می توانیم به شدت تعداد جفت جمله\u200cها را کاهش دهیم که باید به یک محرمانه غذا داده شود تا نتیجه\u200cها به دست برسانند.', 'tr': 'Bu kagyz monolingüň karşılaşykly korporada araştyrma alanyny azaltmak üçin basit teknikleri tassyýar we çykýar. Ilkinji gezek, iki hoñlaýyn sened arasynda parallel sözleri gözleýände, sened arasyndaky ähli mümkin sözleýän çiftleri düşünmeli bolar. Bu paralel çiftler we paralel çiftler arasynda örän bir deňleýänlik derejesini çykarýar. Bu kynçylyk sebäbi ýokary etmän algoritm bilen gaty bir gürrüň çekiljek netijelerde bolar, şol sebäbi golaý we çylgyş süýtgetme fasasyna gerek bolar. Biz Fransuzça karşılaşýan korpusdan alan bir subutda elimizden a ýdylan bir subutda işleýäris we netijeleri elle çykyp bilsin diýip süýtgetmeli sözlän çift sanyny nähili düşürip bileris.', 'af': "Hierdie papier beskrywe en evalueer eenvoudige teknike vir die verduur van die forskingspasie vir parallele setinge in monolinglike vergelykbare korpora. Aanvanklik, wanneer soek vir parallele setings tussen twee vergelykbare dokumente, moet al die moontlike setpaars tussen die dokumente beskou word, wat 'n groot grad van onbalansie tussen parallele paar en nie-parallele paar voorsien word. Hierdie is 'n probleem, want selfs met 'n hoë uitvoerde algoritme, sal 'n baie ruis in die uitgevoerde resultate voorsien word, sodat 'n benodig vir 'n uitbreidige en kosbare hand kontrole fase voorsien word. Ons werk op 'n handaangekies subartikel wat van 'n Franse vergelykbare korpus ontvang is en wys hoe ons kan drastiese die nommer van setnings paar verminder wat na 'n klassifiseerder moet geëed word sodat die resultate hand hanteer kan word.", 'sq': 'Kjo letër përshkruan dhe vlerëson teknika të thjeshta për reduktimin e hapësirës së kërkimit për fjalime paralele në një korpër të krahasueshme monogjuhësore. Initially, when searching for parallel sentences between two comparable documents, all the possible sentence pairs between the documents have to be considered, which introduces a great degree of imbalance between parallel pairs and non-parallel pairs.  Ky është një problem sepse edhe me një algoritëm me rezultate të larta, do të ketë shumë zhurmë në rezultatet e nxjerra, duke paraqitur kështu një nevojë për një fazë të gjerë dhe të shtrenjtë kontrolli manual. Ne punojmë në një nëngrup të anotuar manualisht të fituar nga një korpus i krahasueshëm francez dhe tregojmë se si mund të reduktojmë drastikisht numrin e çifteve të dënimeve që duhet të ushqehen në një klasifikues në mënyrë që rezultatet të mund të trajtohen manualisht.', 'hy': 'Այս հոդվածը նկարագրում է և գնահատում պարզ տեխնիկաներ, որոնք նվազեցնում են զուգահեռ նախադասությունների ուսումնասիրության տարածքը միալեզու համեմատական մարմնում: Սկզբում, երկու համեմատական փաստաթղթերի միջև զուգահեռ նախադասություններ փնտրելիս, պետք է հաշվի առնենք փաստաթղթերի միջև եղած բոլոր հնարավոր նախադասությունների զուգահեռը, ինչը ներկայացնում է զուգահեռ զուգահեռ և ոչ զուգահեռ զուգա Սա խնդիր է, որովհետև նույնիսկ բարձր արտադրողականության ալգորիթմի դեպքում շատ աղմուկ կլինի ստացված արդյունքներում, այսպես ներկայացնելով էքսպանցիոն և թանկ ձեռքի ստուգելու կարիքը: Մենք աշխատում ենք ֆրանսիացի համեմատական կորպոսից ստացված ձեռքով գրված ենթահավաքածուի վրա և ցույց ենք տալիս, թե ինչպես կարելի է խիստ նվազեցնել նախադասությունների զույգերի թիվը, որոնք պետք է կերակրեն դասակարգչի մեջ, որպեսզի արդյունքները կարողանան ձեռ', 'am': 'ይህ ገጾች በሞሎንቋል ካርፓር ውስጥ ለመተካከል የፍቺው ቦታ ለማሳነስ ቀላል ስህተት እና የሚያስተምር ነው፡፡ በመጀመሪያ፣ በሁለቱ በሚያጋራው ሰነዶች መካከል በሚያስተካክሉ የሥርዓት ግንኙነት በመፈለግ ጊዜ፣ በሰነዱ መካከል የሚቻለው የሥርዓት ዓይነቶች እና በሁለቱ ባይተካከሉ መካከል ትልቅ ክፍል የሚያስፈልገውን ግንኙነት እንዲያሳየው ያስፈልጋል፡፡ ይህ ጉዳይ ነው ምክንያቱም ከፍተኛ የአልጎርቲም ቢሆን የድምፅ ድምፅ በተወጡበት ውጤቶች ውስጥ ይኖራል፡፡ ከፈረንሳይ ካርፓስ የተመሳሰለውን አካባቢ እጃችን እንሠራለን፥ ፍሬዎቹንም በእጃችን እንዲያቆሙ የፍርድ ቁጥር እንዴት እንደምናጎድል እናሳውቃለን፡፡', 'az': 'Bu kağıt, monodil kompatibil korporada paralel cümlələr üçün araştırma alanını azaltmaq üçün basit teknikləri təsbit edir və değerlendirir. İlk dəfə, iki karşılaşdırılabilir belə cümlələr arasındakı paralel cümlələr axtardığında, belə cümlələr arasındakı cümlələr arasındakı cümlələr gözləməlidirlər ki, paralel çiftlər və paralel çiftlər arasında böyük bir dərəcə müəyyənləşdirilir. Bu bir problemdir, çünki yüksək performans algoritmi ilə hətta çox səs çıxarılmış sonuçların içində olacaq, böylece böyük və dəyərli bir dəstə təşkil fəzinə ehtiyacı göstərəcək. Biz Fransızca qarşılaşdırılabilir korpusdan alınan bir subgrup üzerində işləyirik və seçmək lazım olan cümlələr çiftlərinin sayını necə dəyişdirə bilərik ki, sonuçları əllə idarə edilsin.', 'bs': 'Ovaj papir opisuje i procjenjuje jednostavne tehnike za smanjenje istraživačkog prostora za paralelne rečenice u jednojezičkoj usporednoj korpori. Prvo, kada tražimo paralelne rečenice između dvije usporedne dokumente, moraju se razmotriti sve moguće parove rečenice između dokumenta, koje predstavljaju veliku stupnju nelegalnosti između paralelnih parova i paralelnih parova. To je problem, jer čak i sa visokim izvršenim algoritmom, mnogo buke će biti prisutno u izvlačenim rezultatima, tako da će predstaviti potrebu za širokom i skupom ručnom fazom provjere. Radimo na ručno annotiranoj subjekti dobijenoj od francuskog usporednog korpusa i pokazujemo kako možemo drastično smanjiti broj parova rečenica koje moraju biti hranjene klasifikatoru kako bi rezultati mogli biti ručno rješeni.', 'ca': "Aquest paper descriu i evalua tècniques simples per reduir l'espai de recerca per frases paralleles en corpores monolingües comparables. Al principi, quan busquen frases paralleles entre dos documents comparables, s'han de considerar tots els parells de frases possibles entre els documents, que introdueix un gran grau d'desequilibri entre parells parallels i parells no parallels. Això és un problem a perquè fins i tot amb un algoritme de gran rendiment, hi haurà molt soroll als resultats extraïts, introduint així la necessitat d'una fase de control manual extensa i costosa. We work on a manually annotated subset obtained from a French comparable corpus and show how we can drastically reduce the number of sentence pairs that have to be fed to a classifier so that the results can be manually handled.", 'cs': 'Tento článek popisuje a hodnotí jednoduché techniky pro omezení výzkumného prostoru pro paralelní věty v jednojzyčných srovnatelných korpusech. Zpočátku při hledání paralelních vět mezi dvěma srovnatelnými dokumenty je třeba vzít v úvahu všechny možné větové páry mezi dokumenty, což přináší velkou míru nerovnováhy mezi paralelními a nealelními páry. To je problém, protože i při vysoce výkonném algoritmu bude v extrahovaných výsledcích přítomno hodně šumu, což přináší potřebu rozsáhlé a nákladné fáze manuální kontroly. Pracujeme na ručně anotované podmnožině získané z francouzského srovnatelného korpusu a ukazujeme, jak můžeme drasticky snížit počet větových párů, které musí být přidány do klasifikátoru, aby mohly být výsledky ručně zpracovány.', 'bn': 'এই প্রবন্ধে সাধারণ প্রযুক্তির ব্যাখ্যা এবং মূল্যায়ন করে মোনোলিভাল ভাষার সমতুল্য কর্পোরায় গবেষণার স্থান কমানোর জন্য। প্রথমত, যখন দুটি সমতুল্য নথির মধ্যে সম্ভাব্য বাক্য অনুসন্ধান করে, তথ্যগুলোর মধ্যে সম্ভাব্য সকল জোড়া বিবেচনা করা উচিত, যা পার্লেল জোড়া এবং অসম্পূর্ণ জোড়ার মধ এটা একটা সমস্যা কারণ এমনকি উচ্চ প্রদর্শনী অ্যালগরিদমের সাথেও অনেক শব্দ উপস্থিত হবে, যার ফলে বিস্তারিত এবং দামী মূল্য পরীক্ষার প্রয়োজন। আমরা একটি ফ্রেঞ্চের তুলনামূলক কোর্পাস থেকে পাওয়া সাবটের উপর কাজ করছি এবং দেখাচ্ছি কিভাবে আমরা ক্লাসিফারকে খাওয়াতে পারি যাতে ফলাফল হ্যান্ডার করা যায়।', 'et': 'Käesolev töö kirjeldab ja hindab lihtsaid meetodeid paralleelsete lausete uurimisruumi vähendamiseks ühekeelsetes võrreldavates korpustes. Algselt tuleb kahe võrreldava dokumendi paralleelsete lausete otsimisel arvesse võtta kõiki võimalikke lausepaare dokumentide vahel, mis tekitab suure tasakaalustamatuse paralleelsete ja mitteparalleelsete paaride vahel. See on probleem, sest isegi kõrge jõudlusega algoritmi korral esineb ekstraheeritud tulemustes palju müra, mis tekitab vajaduse ulatusliku ja kuluka käsitsi kontrollimise järele. Me töötame käsitsi annoteeritud alamhulgaga, mis saadakse Prantsuse võrreldavast korpusest ja näitame, kuidas me saame drastiliselt vähendada lausepaaride arvu, mis tuleb sööta klassifitseerijale, et tulemusi saaks käsitsi käsitseda.', 'fi': 'Tässä artikkelissa kuvataan ja arvioidaan yksinkertaisia tekniikoita rinnakkaislauseiden tutkimustilan vähentämiseksi monikielisissä vastaavissa korpusissa. Aluksi, kun haetaan rinnakkaisia lauseita kahden vertailukelpoisen asiakirjan välillä, on otettava huomioon kaikki mahdolliset lauseparit asiakirjojen välillä, mikä aiheuttaa suuren epätasapainon rinnakkaisten ja ei-rinnakkaisten parien välillä. Tämä on ongelma, koska jopa korkean suorituskyvyn algoritmin avulla poimituissa tuloksissa on paljon melua, mikä tuo mukanaan tarpeen kattavalle ja kalliille manuaaliselle tarkistusvaiheelle. Työskentelemme käsin annotoidulla osajoukolla, joka on saatu ranskalaisesta vertailukelpoisesta korpusesta, ja näytämme, miten voimme merkittävästi vähentää lauseparien määrää, jotka on syötettävä luokittelijalle, jotta tuloksia voidaan käsitellä manuaalisesti.', 'jv': 'Perintah iki dadine karo akeh basa bangsane perusahaan kanggo bisala perusahaan resmi kanggo nggawe barang langgar sampeyan bangsane Mulai Iki ki bobrol lak, lak ngomong nik akeh Algoritm sing bisa dianggap butine dadi, akeh sing bakal terus nyimpen butine dadi, dadi bisa ngewehke operasi sistem sing bisa diandelak hanjeh lan akeh manut. Awak dhéwé nglanggar nganggo manut lan dipunakno sing wis nguasai kapan ning acara cara sing rumangsa Perancis lan wong pada dhéwé iso nggawe nguasai winih dhéwé ngerasai winih sing bakal terus winih dhéwé, winih dhéwé iso nguasai winih dhéwé', 'ha': "Wannan takardan na bayyana kuma yana ƙaddara masu sauƙi ga ƙarai filin tafarkin da za'a sami saurin da aka daidaita saurãre cikin makampuni. Ina fara, a lokacin da za'a nẽmi tsari a tsakanin takardar biyu masu daidaita, to, an ƙayyade kulli matsayin sau biyu a tsakanin takardan, wanda ya ƙãga wani daraja mai girma da daidaita tsakanin nau'i biyu da biyu ba'a daidaita. Wannan wata masĩfa ne, dõmin kõ da wani algoriti mai girma, za'a zo da sauri masu yawa cikin matsalan da za'a fito, don haka kuma ya ƙayyade wata fassara mai shimfiɗa da mai kyauta. Tuna aiki a kan wani submarin da aka motsa daga wani nau'in French mai kama da shi hannuwansa kuma mu nuna yadda zã mu iya ƙarantar da ƙidãyar nau'in sauran da za a ci shi zuwa wani mai daraja, don a iya iya amfani da matsala.", 'sk': 'V prispevku so opisane in ocenjene preproste tehnike za zmanjšanje raziskovalnega prostora za vzporedne stavke v enojezičnih primerljivih korpusih. Na začetku je treba pri iskanju vzporednih stavkov med dvema primerljivima dokumentoma upoštevati vse možne pare stavkov med dokumenti, kar prinaša veliko neravnovesje med vzporednimi in nenavzporednimi pari. To je problem, saj bo tudi z visoko zmogljivim algoritmom prisotno veliko hrupa pri izvlečenih rezultatih, kar uvaja potrebo po obsežni in dragi fazi ročnega preverjanja. Delamo na ročno označenem podmnožici, pridobljenem iz primerljivega francoskega korpusa, in pokažemo, kako lahko drastično zmanjšamo število parov stavkov, ki jih je treba podati klasifikatorju, da lahko rezultate ročno obdelamo.', 'bo': 'ཤོག་བྱང་འདིས་གཞུང་གིས་སྔར་སྒྲིག་ཀྱི་ཐབས་ལམ་སྟབས་བདེ་བ་དེ་ཚོར་ཞིབ་འཇུག་བྱེད་པའི་བར་སྟོང་ཞིབ་དང་ འགོ་འཛུགས་བྱས་ན། ཡིག་ཆ་གཉིས་དབར་གྱི་ཚིག་ཚན་འདི་འཚོལ་བཤེར་བྱེད་སྐབས་ཡིག འདི་ནི་དཀའ་ངལ་ཞིག ང་ཚོས་རང་ཉིད་ཀྱིས་སྙན་པའི་ཚིག་རྟགས་གཅིག་གི་ནང་དུ་ཡིག་ཆའི་མཐུན་རྐྱེན་པའི་མཁན་གྱི་ལག་སྟར་གྱི་རྒྱུ་དངོས་ལ་སྤྱོད་བྱས་ནས་ང་ཚོའི་ཚིག་རྩིས་ཕུང་', 'he': 'הנייר הזה מתאר ומעריך טכניקות פשוטות כדי להפחית את מרחב המחקר למשפטים מקבילים בקופורה מונושפתית שווה. בהתחלה, כשמחפשים משפטים מקבילים בין שני מסמכים שווים, כל הזוגות המשפטים האפשריים בין המסמכים צריכים להיחשב, מה שמציג מעמד גדול של אי-איזון בין זוגות מקבילות לזוגות לא מקבילות. זו בעיה כי אפילו עם אלגוריתם ביצועים גבוהים, הרבה רעש יהיה נוכח בתוצאות הנוצאות, כך להציג צורך לשלב מבחן ידני רחב וביקר. אנו עובדים על תת-קבוצה שנמצאת בידיים ממקורפוס משווה צרפתי ונראה איך אנחנו יכולים להפחית דרסטית את מספר זוגות משפטים שנצטרך להאכיל לקליסדר כך שהתוצאות יכולות להתמודד בידיים.'}
{'en': 'TALN / LS2N Participation at the BUCC Shared Task : Bilingual Dictionary Induction from Comparable Corpora', 'ar': 'مشاركة TALN / LS2N في مهمة BUCC المشتركة: استقراء قاموس ثنائي اللغة من Corpora المقارنة', 'es': 'Participación de TALN/LS2N en la tarea compartida de BUCC: inducción de diccionarios bilingües de corpus comparables', 'fr': 'TALN/LS2N Participation à la tâche partagée BUCC\xa0: Induction au dictionnaire bilingue à partir de corpus comparables', 'pt': 'TALN/LS2N Participação na Tarefa Compartilhada BUCC: Indução de Dicionário Bilíngue de Corpora Comparáveis', 'zh': 'TALN/LS2N 预 BUCC 共同任务:比语料库双语词典归', 'ja': 'BUCC共有タスクへのTALN/LS 2 Nの参加：比較可能なコーポラルからのバイリンガル辞書紹介', 'ru': 'Участие TALN/LS2N в совместной задаче BUCC: Введение в двуязычный словарь из сопоставимых тел', 'hi': 'BUCC साझा कार्य में TALN / LS2N भागीदारी: तुलनीय कॉर्पोरेट से द्विभाषी शब्दकोश प्रेरण', 'ga': 'TALN/LS2N Rannpháirtíocht i dTasc Comhroinnte BUCC: Ionduchtú Foclóir Dhátheangach ón gCorparáid Inchomparáide', 'ka': 'TALN/LS2N მოწყობილობა BUCC საზოგადომი დავალებაში: შემდგომარებული კორპორადან მეორე სიტყვანის ინდექცია', 'el': 'Συμμετοχή στην Κοινή Εργασία: Δίγλωσση επαγωγή λεξικού από συγκρίσιμο σώμα', 'hu': 'TALN/LS2N Részvétel a BUCC Közös Feladatban: Kétnyelvű szótár indukció az összehasonlítható Corpora-tól', 'mk': 'Учеството на TALN/LS2N на заедничката задача на BUCC: Дивјазична индукција на речникот од Comparable Corpora', 'it': 'TALN/LS2N Partecipazione al BUCC Shared Task: Dizionario bilingue Induzione da Corpora Comparabile', 'lt': 'TALN/LS2N Dalyvavimas bendroje BUCC užduotyje: palyginamosios korporacijos dvikalbis žodynas', 'kk': 'TALN/LS2N BUCC ортақтастырылған тапсырманың қатынасы: Сәйкестірілген Корпорадан екі сөздік индукциясы', 'ms': 'TALN/LS2N Pesertaan dalam Tugas Berkongsi BUCC: Penginduksi Kamus Bilingual dari Korpora Berbanding', 'ml': 'TALN/LS2N BUCC പങ്കാളിയുള്ള ജോലിയില്\u200d പങ്കാളി', 'mt': 'TALN/LS2N Parteċipazzjoni fil-Ħidma Kondiviża tal-BUCC: Induzzjoni Bilingwali tad-Dikjarnarju minn Korpora Komparabbli', 'mn': 'TALN/LS2N BUCC хуваалцаагүй ажлын хувьд оролцоо: Comparable Corpora-ын хоёр дүгнэлт өгүүлбэр', 'no': 'TALN/LS2N deltakar på BUCC delt oppgåve: Bilinguell ordbokinduksjon frå kompatibelt korpora', 'pl': 'TALN/LS2N Udział w BUCC Shared Task: Indukcja dwujęzycznego słownika z porównywalnego korpusu', 'ro': 'TALN/LS2N Participarea la sarcina comună BUCC: Inducția dicționarului bilingv de la Corpora Comparabilă', 'sr': 'TALN/LS2N učestvovanje u zajedničkom zadatku BUCC: Bilingualna indikacija rečnika iz usporedne korpore', 'si': 'Name', 'so': 'TALN/LS2N Participation at the BUCC Shared Task: Bilingual Dictionary Induction from Comparable Corpora', 'sv': 'TALN/LS2N Deltagande i BUCC Delad Uppgift: Tvåspråkig ordbok Induktion från jämförbara Corpora', 'ta': 'TALN/LS2N BUCC பகிர்ந்த பணியில் பங்கீடு', 'ur': 'TALN/LS2N مشارکت بوسی شریک ٹاکس میں: مشارکت کورپور سے دوئینگ ڈیکلینگ انڈاکٹ', 'uz': '@ info: status', 'vi': 'Công việc chia sẻ BUCC: sự nghiệp sản xuất thuyết quán bar từ Tập đoàn đối chiếu.', 'bg': 'Участие в съвместната задача на БУК: двуезична индукция на речника от сравним корпор', 'da': 'TALN/LS2N Deltagelse i BUCC Fælles Opgave: Tosproget ordbog Induktion fra sammenlignelig Corpora', 'nl': 'TALN/LS2N Deelname aan de BUCC Shared Task: Tweetalige woordenboek Inductie uit Vergelijkbaar Corpora', 'hr': 'TALN/LS2N učestvovanje u zajedničkom zadatku BUCC-a: dvostruka indukcija riječnika iz usporedne korpore', 'de': 'TALN/LS2N Teilnahme am BUCC Shared Task: zweisprachige Wörterbuchinduktion aus vergleichbarem Korpora', 'ko': 'TALN/LS2NBUCC 공유 작업 참여: 비교 가능한 언어 자료 라이브러리에서 이중 언어 사전 귀납', 'fa': 'شرکت TALN/LS2N در وظیفه مشترک BUCC: فشار دوگانه\u200cای از شرکت قابل مقایسه', 'id': 'TALN/LS2N Participation at the BUCC Shared Task: Bilingual Dictionary Induction from Comparable Corpora', 'sw': 'TALN/LS2N ushiriki katika kazi ya BUCC ilishirikishwa: Ujenzi wa Kidikteta wa lugha kutoka Corpora inayofanana', 'sq': 'TALN/LS2N Pjesëmarrja në detyrën e përbashkët të BUCC: Induktimi dygjuhësor nga korpora e krahasueshme', 'tr': 'TALN/LS2N BUCC Paylaşım Görevinde Hizmet: Bilingual Sözlük Induction from Comparable Corpora', 'af': 'TALN/LS2N Deelnadering by die BUCC Gedeelde Opdrag: Bilinguele Woordeboek Induksie van Vergelykbare Korpora', 'am': 'TALN/LS2N ተጋሪዎች BUCC Shared Task: Bilingual Dictionary Induction from Comparable Corpora', 'az': "BUCC paylaşılan işdə TALN/LS2N Bölüm: Compatibile Corpora'dan İkinci Sözlük Induksyonu", 'hy': "ՏԱLN-ի և LS2N-ի մասնակցությունը ԲուԿԿ-ի ընդհանուր հանձնարարում' Երկլեզու բառարանի ինդուկցիան համեմատական Կորպորայից", 'bn': 'TALN/LS2N বিউসিসি শেয়ার কর্মসূচিতে অংশগ্রহণ: তুলনা কর্পোরা থেকে বিলিঙ্গুলি অভিভাবক নির্দেশনা', 'bs': 'TALN/LS2N učestvovanje u zajedničkom zadatku BUCC: dvostruka indukcija dizajnera iz usporedne korpore', 'ca': 'TALN/LS2N Participation at the BUCC Shared Task: Bilingual Dictionary Induction from Comparable Corpora', 'cs': 'TALN/LS2N Účast na BUCC Shared Task: dvojjazyčná indukce slovníku ze srovnatelného korpusu', 'et': 'TALN/LS2N osalemine BUCC jagatud ülesandel: kahekeelse sõnaraamatu induktsioon võrreldavatest korpustest', 'fi': 'TALN/LS2N Osallistuminen BUCC:n yhteiseen tehtävään: Kaksikielinen sanakirja Induktio vertailukelpoisesta corporasta', 'jv': 'MALN', 'sk': 'Sodelovanje TALN/LS2N na skupni nalogi BUCC: dvojezični slovar Indukcija iz primerljivih korpusov', 'ha': 'TALN/LS2N', 'he': 'TALN/LS2N משתתף במשימה המשותפת של BUCC: מילון משולש משותף', 'bo': 'TALN/LS2N Participation at the BUCC Shared Task: Bilingual Dictionary Induction from Comparable Corpora'}
{'en': 'This paper describes the TALN / LS2N system participation at the Building and Using Comparable Corpora (BUCC) shared task. We first introduce three strategies : (i) a word embedding approach based on fastText embeddings ; (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity. Then, we present the applied strategy for the shared task which consists in the combination of the embeddings concatenation and the cognates matching approaches. The covered languages are French, English, German, Russian and Spanish. Overall, our system mixing embeddings concatenation and perfect cognates matching obtained the best results while compared to individual strategies, except for English-Russian and Russian-English language pairs for which the concatenation approach was preferred.', 'ar': 'تصف هذه الورقة مشاركة نظام TALN / LS2N في المهمة المشتركة للبناء واستخدام Corpora (BUCC). نقدم أولاً ثلاث استراتيجيات: (1) نهج تضمين كلمة يعتمد على تضمين النص السريع ؛ (2) نهج التسلسل باستخدام كل من نماذج Skip-Gram والحرف CBOW ، وأخيرًا (3) نهج المطابقة المتشابه على أساس تشابه سلسلة المطابقة التامة. بعد ذلك ، نقدم الإستراتيجية المطبقة للمهمة المشتركة والتي تتكون من مزيج من تسلسل حفلات الزفاف وأساليب المطابقة المتشابهة. اللغات المشمولة هي الفرنسية والإنجليزية والألمانية والروسية والإسبانية. بشكل عام ، حصل نظامنا الذي يخلط تسلسل حفلات الزفاف والمطابقة المتشابهة المثالية على أفضل النتائج مقارنة بالاستراتيجيات الفردية ، باستثناء أزواج اللغتين الإنجليزية والروسية والإنجليزية التي كان نهج التسلسل مفضلًا لها.', 'pt': 'Este artigo descreve a participação do sistema TALN/LS2N na tarefa compartilhada Building and Using Comparable Corpora (BUCC). Primeiramente, apresentamos três estratégias: (i) uma abordagem de incorporação de palavras baseada em incorporação de fastText; (ii) uma abordagem de concatenação usando os modelos Skip-Gram de caracteres e CBOW de caracteres e, finalmente (iii) uma abordagem de correspondência de cognatos baseada em uma similaridade de cadeia de correspondência exata. Em seguida, apresentamos a estratégia aplicada para a tarefa compartilhada que consiste na combinação das abordagens de concatenação de embeddings e correspondência de cognatos. Os idiomas abrangidos são francês, inglês, alemão, russo e espanhol. No geral, nosso sistema de combinação de concatenação de embeddings e correspondência perfeita de cognatos obteve os melhores resultados em comparação com estratégias individuais, exceto para pares de idiomas inglês-russo e russo-inglês para os quais a abordagem de concatenação foi preferida.', 'fr': "Cet article décrit la participation du système TALN/LS2N à la tâche partagée Construire et utiliser des corpus comparables (BUCC). Nous introduisons d'abord trois stratégies\xa0: (i) une approche d'intégration de mots basée sur des intégrations FastText\xa0; (ii) une approche de concaténation utilisant à la fois des modèles Skip-Gram et des modèles CBOW de caractères, et enfin (iii) une approche de correspondance de noms apparentés basée sur une similitude de chaîne de correspondance exacte. Ensuite, nous présentons la stratégie appliquée pour la tâche partagée qui consiste à combiner les approches de concaténation des intégrations et de correspondance apparentées. Les langues couvertes sont le français, l'anglais, l'allemand, le russe et l'espagnol. Dans l'ensemble, notre système combinant les intégrations, la concaténation et la correspondance parfaite des apparentés a obtenu les meilleurs résultats par rapport aux stratégies individuelles, sauf pour les paires de langues anglais-russe et russe-anglais pour lesquelles l'approche de concaténation était préférée.", 'es': 'Este documento describe la participación del sistema TALN/LS2N en la tarea compartida Building and Using Comparable Corpora (BUCC). Primero introducimos tres estrategias: (i) un enfoque de incrustación de palabras basado en incrustaciones de FastText; (ii) un enfoque de concatenación que utiliza modelos de salto-grama de caracteres y CBOW de caracteres, y finalmente (iii) un enfoque de coincidencia afín basado en una similitud de cadenas de caracteres de coincidencia exacta. A continuación, presentamos la estrategia aplicada para la tarea compartida que consiste en la combinación de los enfoques de concatenación de incrustaciones y emparejamiento afín. Los idiomas cubiertos son el francés, el inglés, el alemán, el ruso y el español. En general, nuestro sistema que mezcla la concatenación de incrustaciones y el emparejamiento perfecto de cognados obtuvo los mejores resultados en comparación con las estrategias individuales, excepto para los pares de idiomas inglés-ruso y ruso-inglés para los que se prefirió el enfoque de concatenación.', 'ja': 'この論文では、比較可能なコーラ（ BUCC ）共有タスクの構築と使用におけるTALN/LS 2 Nシステムの参加について説明します。まず、(i)高速テキスト埋め込みに基づく単語埋め込みアプローチ、(ii)文字スキップ-グラムモデルと文字CBOWモデルの両方を使用する連結アプローチ、そして最後に(iii)完全に一致する文字列の類似性に基づくコグネイトマッチングアプローチの3つの戦略を紹介します。次に、埋め込み連結とコグネイトマッチングアプローチの組み合わせで構成される共有タスクの適用された戦略を提示します。対象言語はフランス語、英語、ドイツ語、ロシア語、スペイン語です。全体的に、組み込みの連結と完璧なコグネイトマッチングのシステムは、連結アプローチが好ましい英語-ロシア語とロシア語-英語のペアを除いて、個々の戦略と比較して最高の結果を得ました。', 'zh': '本文述 TALN/LS2N 统参构用,较语料库 (BUCC) 共事。 首言三策:(i)基于fastText嵌之词; (ii)用字符Skip-Gram与字符CBOW模形之法,最后(iii)基于精匹字符串相似性同源匹配之法。 然后共事之策,嵌联同源之组。 涵盖言法语,英语,德语,俄语西班牙语。 总体而言,比之单策,系统混嵌完同源匹配最佳,非首选联之英语 - 俄语与俄语 - 英语语对。', 'hi': 'यह पेपर TALN/LS2N सिस्टम भागीदारी का वर्णन करता है जो बिल्डिंग और यूजिंग कॉम्पेयरेबल कॉर्पोरेट (BUCC) साझा कार्य में है। हम पहले तीन रणनीतियों का परिचय देते हैं: (i) फास्टटेक्स्ट एम्बेडिंग के आधार पर एक शब्द एम्बेडिंग दृष्टिकोण; (ii) चरित्र स्किप-ग्राम और चरित्र सीबीओडब्ल्यू मॉडल दोनों का उपयोग करके एक संयोजन दृष्टिकोण, और अंत में (iii) एक सटीक मिलान स्ट्रिंग समानता के आधार पर एक कॉग्नेट्स मिलान दृष्टिकोण। फिर, हम साझा कार्य के लिए लागू रणनीति प्रस्तुत करते हैं जिसमें एम्बेडिंग संयोजन और कॉग्नेट्स मिलान दृष्टिकोण के संयोजन के संयोजन में शामिल होते हैं। कवर की गई भाषाएं फ्रेंच, अंग्रेजी, जर्मन, रूसी और स्पेनिश हैं। कुल मिलाकर, हमारे सिस्टम मिश्रण embeddings concatenation और सही cognates मिलान अंग्रेजी-रूसी और रूसी-अंग्रेजी भाषा जोड़े को छोड़कर, व्यक्तिगत रणनीतियों की तुलना में सबसे अच्छा परिणाम प्राप्त किया, जिसके लिए concatenation दृष्टिकोण पसंद किया गया था।', 'ru': 'В этой статье описывается участие системы TALN/LS2N в совместной задаче «Создание и использование сопоставимых корпораций» (BUCC). Сначала мы вводим три стратегии: (i) подход к встраиванию слов, основанный на встраиваниях fastText; (ii) подход к объединению с использованием как моделей символов Skip-Gram, так и моделей символов CBOW, и, наконец, (iii) подход к сопоставлению родственных символов, основанный на точном сходстве строк соответствия. Затем мы представляем прикладную стратегию для общей задачи, которая заключается в сочетании подходов конкатенации вложений и сопоставления родственных связей. Охватываемые языки: французский, английский, немецкий, русский и испанский. В целом, конкатенация вложений нашей системы и идеальное сопоставление родственных связей получили лучшие результаты по сравнению с отдельными стратегиями, за исключением английско-русской и русско-английской языковых пар, для которых предпочтительным был подход конкатенации.', 'ga': 'Déanann an páipéar seo cur síos ar rannpháirtíocht an chórais TALN/LS2N sa tasc comhroinnte um Thógáil agus Úsáid Corpora Inchomparáide (BUCC). Ar dtús tugaimid trí straitéis isteach: (i) cur chuige um leabú focal bunaithe ar leabaithe mearthéacs; (ii) cur chuige comhtháite ag baint úsáide as samhlacha carachtar Skip-Gram agus carachtar CBOW, agus ar deireadh (iii) cur chuige comhchuibhithe gaolmhar bunaithe ar chosúlacht teaghrán meaitseála beacht. Ansin, cuirimid i láthair an straitéis fheidhmeach don tasc comhroinnte atá comhdhéanta de chomhghaolú an leabaithe agus na cuir chuige meaitseála gaolmhaire. Is iad na teangacha clúdaithe Fraincis, Béarla, Gearmáinis, Rúisis agus Spáinnis. Tríd is tríd, fuair ár gcóras meascadh leabaithe comhchatánaithe agus meaitseáil ghaolmhar foirfe na torthaí is fearr agus iad i gcomparáid le straitéisí aonair, ach amháin i gcás péirí Béarla-Rúisis agus Rúisis-Béarla arbh fhearr an cur chuige comhcheangail ina leith.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή του συστήματος στο κοινό έργο οικοδόμησης και χρήσης συγκρίσιμων σωμάτων (BUCC). Πρώτα εισάγουμε τρεις στρατηγικές: (i) μια προσέγγιση ενσωμάτωσης λέξεων βασισμένη σε ενσωμάτωση γρήγορου κειμένου. (ii) μια προσέγγιση συσχέτισης χρησιμοποιώντας και τα μοντέλα Skip-Gram και CBOW χαρακτήρων, και τέλος (iii) μια προσέγγιση αντιστοίχισης βασισμένη σε μια ακριβή ομοιότητα συμβολοσειρών αντιστοίχισης. Στη συνέχεια, παρουσιάζουμε την εφαρμοζόμενη στρατηγική για την κοινή εργασία η οποία συνίσταται στον συνδυασμό των συνδέσεων ενσωμάτωσης και των προσεγγίσεων αντιστοίχισης αντιστοίχισης. Οι καλυπτόμενες γλώσσες είναι γαλλικά, αγγλικά, γερμανικά, ρωσικά και ισπανικά. Συνολικά, το σύστημά μας που αναμιγνύει τη συμπλήρωση ενσωμάτωσης και την τέλεια αντιστοίχιση κονιών απέκτησε τα καλύτερα αποτελέσματα ενώ συγκρίνεται με μεμονωμένες στρατηγικές, εκτός από τα ζεύγη αγγλικής-ρωσικής και ρωσικής-αγγλικής γλώσσας για τα οποία προτιμήθηκε η προσέγγιση συμπλήρωσης.', 'ka': 'ამ დოკუმენტი აღწერს TALN/LS2N სისტემის დამატებით დამატებით და გამოყენებას შემდგომარებული კორპორა (BUCC) დამატებით. ჩვენ პირველად სამი სტრატიგური გადავიყენებთ: i) სიტყვების გადაყენება, რომელიც FastText დაყენებულია; ii) კონფინციო პროგრამა, რომელიც გამოყენებულია სიმბოლოები Skip-Gram და სიმბოლოები CBOW მოდელების გამოყენება, და ბოლოს iii) კონფინციო კონფინციო, რომელიც კონფინციო შემდეგ ჩვენ ჩვენ გავაჩვენოთ მომხმარებული სტრატიგია საერთო დავალებისთვის, რომელიც კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციაში შექმნა და კ საკუთარი ენები არის ფრანგური, ანგლისური, გერმანური, პოსონური და სპანელი. ჩვენი სისტემის შემთხვევაში შემთხვევაში კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური კონფიგური შემთხვევაში მიიღეთ', 'hu': 'A tanulmány bemutatja a TALN/LS2N rendszer részvételét a Building and Using Comparable Corpora (BUCC) megosztott feladatban. Először három stratégiát vezetünk be: (i) egy szóbeágyazási megközelítés, amely a fastText beágyazásokon alapul; (ii) összekapcsolási megközelítés mind a Skip-Gram, mind a karakter CBOW modelleket használva, és végül (iii) egy pontos egyezési karakterlánc hasonlóságon alapuló megközelítés. Ezután bemutatjuk a megosztott feladatra vonatkozó alkalmazott stratégiát, amely a beágyazások összekapcsolódásából és a kognációs megközelítések kombinációjából áll. A lefedett nyelvek a francia, angol, német, orosz és spanyol. Összességében az egyéni stratégiákhoz képest a legjobb eredményeket értük el rendszerkeverő beágyazások összekapcsolásával és tökéletes kognátok összehasonlításával, kivéve az angol-orosz és orosz-angol nyelvpárokat, amelyeknél előnyben részesítettük az összekapcsolási megközelítést.', 'it': "Questo articolo descrive la partecipazione del sistema TALN/LS2N al compito condiviso Building and Using Comparable Corpora (BUCC). Per prima cosa introduciamo tre strategie: (i) un approccio word embedding basato su fastText embeddings; (ii) un approccio di concatenazione utilizzando entrambi i modelli di carattere Skip-Gram e CBOW, e infine (iii) un approccio di corrispondenza cognitivo basato su una somiglianza esatta delle stringhe di corrispondenza. Quindi, presentiamo la strategia applicata per il compito condiviso che consiste nella combinazione delle concatenazioni di incorporazione e degli approcci di matching cognitivi. Le lingue coperte sono francese, inglese, tedesco, russo e spagnolo. Nel complesso, il nostro sistema di miscelazione di incorporazioni concatenate e perfect cognate matching ha ottenuto i migliori risultati rispetto alle singole strategie, ad eccezione delle coppie di lingue inglese-russo e russo-inglese per le quali è stato preferito l'approccio concatenazione.", 'lt': 'Šiame dokumente aprašomas TALN/LS2N sistemos dalyvavimas bendroje pastatų ir palyginamos korporacijos (BUCC) užduotyje. Pirmiausia įvedame tris strategijas: i) žodži ų įterpimo metodą, pagrįstą greitText įterpimu; ii) sutrumpinimo metodas naudojant tiek Skip-Gram, tiek CBOW modelius ir galiausiai iii) sutrumpinimo metodas, pagrįstas tiksliu atitikties juostos panašumu. Tuomet pristatysime taikytą bendros užduoties strategiją, kurią sudaro įdėjimo sutapimo ir kognatų derinimo metodai. Apibrėžiamos prancūzų, anglų, vokiečių, rusų ir ispanų kalbos. Apskritai, mūsų sistema, kuria derinami įdėjiniai ir tobulai suderinami pažįstamieji gaminiai, pasiekė geriausius rezultatus lyginant su atskiromis strategijomis, išskyrus anglų-rusų ir rusų-anglų kalbų poras, kurioms labiausiai buvo taikomas suvienodinimo metodas.', 'kk': 'Бұл қағаз TALN/LS2N жүйесінің құрылғындағы және Сәйкестік Корпора (BUCC) ортақ тапсырмасын қолдану және қолдану үшін қатынасын анықтайды. Біз біріншіден үш стратегия келтірдік: ii) таңбалар мен CBOW үлгілерін қолданып сәйкестік тәртібі, соңында (iii) сәйкестік жолдың ұқсастығына негізделген сәйкестік тәртібін белгілейді. Содан кейін біз ортақ тапсырма үшін қолданылатын стратегияны таңдаймыз. Бұл ендірілген тапсырмалардың біріктірілімі мен сәйкес келесімдерді біріктіреді. Мұндай тілдер француз, ағылшын, неміс, руссия және испан тілдері. Жалпы, біздің жүйеміздің сәйкестігіміз сәйкестіктеріміз бір стратегиялармен салыстырып, ағылшын-русс және русс-ағылшын тілдер тілдерінің екісінің жалпы нәтижелерін түсіндіреді. Бұл', 'ms': 'This paper describes the TALN/LS2N system participation at the Building and Using Comparable Corpora (BUCC) shared task.  Kami pertama-tama memperkenalkan tiga strategi: (i) pendekatan penyembedding perkataan berdasarkan penyembedding teks pantas; (ii) pendekatan penyesalan menggunakan kedua-dua aksara Skip-Gram dan model CBOW aksara, dan akhirnya (iii) pendekatan yang sepadan berdasarkan persamaan rentetan yang tepat. Kemudian, kita memperkenalkan strategi yang dilaksanakan untuk tugas berkongsi yang terdiri dalam kombinasi penyesalan penyembedding dan pendekatan yang sepadan. Bahasa tertutup adalah Perancis, Inggeris, Jerman, Rusia dan Sepanyol. Secara keseluruhan, sistem kita mencampurkan penyelesaian penyelesaian penyelesaian dan penyelesaian penyelesaian sempurna mendapat hasil terbaik semasa dibandingkan dengan strategi individu, kecuali pasangan bahasa Inggeris-bahasa Inggeris-bahasa Inggeris-bahasa Inggeris-bahasa Inggeris yang mana pendekatan penyelesaian lebih suka.', 'mt': "Dan id-dokument jiddeskrivi l-parteċipazzjoni tas-sistema TALN/LS2N fil-kompitu kondiviż tal-Bini u l-Użu ta’ Korpora Komparabbli (BUCC). L-ewwel jintroduċu tliet strateġiji: (i) approċċ ta' inkorporazzjoni tal-kliem ibbażat fuq inkorporazzjoni rapida tat-Test; (ii) approċċ ta’ konċentrazzjoni bl-użu kemm ta’ mudelli ta’ Skip-Gram kif ukoll ta’ CBOW tal-karattru, u fl-a ħħar mill-aħħar (iii) approċċ ta’ konċentrazzjoni bbażat fuq similarità eżatta ta’ strings ta’ qbil. Imbagħad, nippreżentaw l-istrateġija applikata għall-kompitu kondiviż li tikkonsisti fil-kombinazzjoni tal-konċentrazzjoni tal-inkorporazzjonijiet u l-approċċi ta’ tqabbil tal-konġenati. Il-lingwi koperti huma Franċiż, Ingliż, Ġermaniż, Russu u Spanjol. B’mod ġenerali, is-sistema tagħna li tħallat il-konċentrazzjoni tal-inkorporazzjonijiet u l-konġenati perfetti li jaqblu kisbet l-aħjar riżultati filwaqt li tqabblu mal-istrateġiji individwali, ħlief għall-pari tal-lingwa Ingliża-Ingliża, Ingliża-Ingliża u Ingliża-Ingliża li għalihom kien ippreferut l-approċċ tal-kon", 'ml': 'ഈ പത്രത്തില്\u200d TALN/LS2N സിസ്റ്റം പങ്കുചേര്\u200dത്ത പണിയില്\u200d പങ്കുചേര്\u200dക്കുന്നതും ഉപയോഗിക്കുന്നതും പങ്കുചേര്\u200dക്കുന്ന പണി ആദ്യം നമ്മള്\u200d മൂന്നു ട്രാക്ടിക്യൂട്ടീജിനെ പരിചയപ്പെടുത്തുന്നു: (i) സ്ഥാനത്തിന്\u200dറെ അടിസ്ഥാനത്ത് വാ (ii) അക്ഷരരൂപത്തില്\u200d സ്കിപ്പ്- ഗ്രാമും സിബിയോവ് മോഡലുകളും ഉപയോഗിക്കുന്ന ഒരു സങ്കീര്\u200dണ്ണമായ നടപടിയും, അവസാനം (ഐ) ഒരു കോഗ്നേറ്റുകള്\u200d ശരിയായ പ്ര പിന്നെ നമ്മള്\u200d പങ്കുചേര്\u200dക്കുന്ന ജോലിക്കുള്ള പ്രയോഗിച്ച പ്രയോഗിച്ചുകൊണ്ടിരിക്കുന്ന പ്രയോഗിക്കുന്ന ഒരു പ്രയോഗി മൂടിയ ഭാഷകള്\u200d ഫ്രഞ്ച്, ഇംഗ്ലീഷ്, ജര്\u200dമ്മന്\u200d, റഷ്യന്\u200d, സ്പാനിഷ് എന്നിവരാണ്. എല്ലായിടത്തും നമ്മുടെ സിസ്റ്റത്തിന്റെ സംവിധാനങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുന്നതും പൂര്\u200dണ്ണമായ കോഗ്നേറ്റുകളും കൂട്ടിചേര്\u200dക്കുന്നതും നല്ല ഫലങ്ങള്\u200d ലഭിച്', 'mk': 'Овој весник го опишува учеството на системот TALN/LS2N во заедничката задача за изградба и употреба на споредлива корпора (BUCC). Прво воведуваме три стратегии: (i) пристап на вградување на зборови базиран на брзи вградувања на текст; (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity.  Потоа, ја претставуваме аплицираната стратегија за заедничката задача која се состои од комбинацијата на концентрација на вградувањата и способните пристапи на когнатите. Покриените јазици се француски, англиски, германски, руски и шпански. Вкупно, нашиот систем мешање на вградените концентрации и совршените концентрации доби најдобри резултати во споредба со индивидуалните стратегии, освен парови на англиско-руско и руско-англиско јазик за кои беше префериран концентрациониот пристап.', 'mn': 'Энэ цаас нь TALN/LS2N системийн барилга болон Comparable Corpora (BUCC) хуваалцааны ажлыг ашиглаж байгааг тайлбарладаг. Бид эхлээд гурван стратегийг танилцуулж байна: ii) харьцаа Skip-Gram болон харьцаа CBOW загваруудыг ашиглаж байдаг тодорхойлолтын арга баримтууд. Эцэст нь iii) тодорхойлолтын арга баримтуудыг тодорхойлдог стринг тодорхойлолтой байдаг. Дараа нь бид хуваалцах үйл ажиллагаанд хэрэглэгдсэн стратегийг тайлбарлаж өгдөг. Энэ нь холбогдолтын нэгтгэл, холбогдолтой ойлголтын нэгтгэл юм. Холбоотой хэл бол Француз, Англи, Герман, Орос, Испан. Ихэнх тохиолдолд бидний систем холбогдолтой холбогдолтой холбогдолтой, төгс мэдлэгтэй холбогдолтой холбогдолтой болсон. Гэхдээ хэн нэгэн стратегийг харьцуулахад хамгийн сайн үр дүнг олсон. Англи-Орос, Орос-Англ', 'no': 'Denne papiret beskriver deltakaren av TALN/LS2N-systemet på bygging og bruk kompatibelt korpora (BUCC) delt oppgåve. Vi introduserer først tre strategiar: i) eit ord innebæringstilnærming basert på fastText-innbæringar. ii) ein samsvar-tilnærming med både teikn Hopp-Gram og teikn CBOW-modeller, og til slutt (iii) kjenner ein tilnærming basert på eit nøyaktig samsvar med teikn. Så presenterer vi den tilgjengelege strategien for den delte oppgåva som inneheld i kombinasjonen av samsvar med innbøkingar og kjenner tilgjengelege tilnærmingar. Den dekke språka er fransk, engelsk, tysk, russisk og spansk. Overalt, våre systemmeldingar innebygger sammenlikning og perfekt kognisjon som passar, fikk dei beste resultatene sammenlignet med individuelle strategier, unntatt for engelsk- russisk og russisk- engelsk parer som sammenlikninga er foretrukket for.', 'pl': 'Niniejszy artykuł opisuje uczestnictwo systemu TALN/LS2N w zadaniu wspólnym Budowanie i Używanie Porównywalnych Korpusów (BUCC). Najpierw przedstawiamy trzy strategie: (i) podejście do osadzenia słów oparte na osadzeniach fastText; (ii) podejście do łączenia z wykorzystaniem zarówno modeli CBOW znaków Skip-Gram, jak i CBOW znaków, a na koniec (iii) podejście do dopasowania oparte na podobieństwie ciągu dokładnego dopasowania. Następnie przedstawiamy zastosowaną strategię dla wspólnego zadania, która polega na połączeniu łączeń osadzeń i podejść kojarzonych dopasowujących. Objęte językami są francuski, angielski, niemiecki, rosyjski i hiszpański. Ogólnie rzecz biorąc, nasz system mieszania łączeń osadzeń i perfekcyjnego dopasowania poznań uzyskał najlepsze rezultaty w porównaniu do indywidualnych strategii, z wyjątkiem par językowych angielsko-rosyjsko i rosyjsko-angielsko, dla których preferowano podejście łączenia.', 'ro': 'Această lucrare descrie participarea sistemului TALN/LS2N la sarcina comună Building and Using Comparable Corpora (BUCC). Introducem mai întâi trei strategii: (i) o abordare de încorporare a cuvintelor bazată pe încorporarea fastText; (ii) o abordare de concatenare care utilizează atât modelele de tip Skip-Gram, cât și modelele CBOW de tip caracter și, în cele din urmă (iii) o abordare de potrivire cunoaște bazată pe o similitudine exactă a șirului de potrivire. Apoi, prezentăm strategia aplicată pentru sarcina partajată care constă în combinația concatenării încorporărilor și abordărilor de potrivire a cunoașterii. Limbile acoperite sunt franceza, engleza, germana, rusa si spaniola. În general, sistemul nostru de amestecare a încorporărilor concatenate și potrivirea perfectă a cunoștințelor a obținut cele mai bune rezultate în comparație cu strategiile individuale, cu excepția perechilor de limbi engleză-rusă și rusă-engleză pentru care a fost preferată abordarea concatenării.', 'sr': 'Ovaj papir opisuje sudjelovanje TALN/LS2N sistema u zgradi i korištenju komparabilne korpore (BUCC) zajedničkog zadatka. Prvo predstavljamo tri strategije: i) reč uključujući pristup na osnovu fastText ugrađenja; ii) pristup usklađivanja koristeći i modele karaktera Skip-Gram i karakter CBOW, i konačno (iii) kogniraju odgovarajući pristup na temelju tačne sličnosti string. Onda predstavljamo prijavljenu strategiju za zajednički zadatak koji se sastoji u kombinaciji sastavljanja sastavka i kognije odgovarajućih pristupa. Pokriveni jezici su francuski, engleski, nemački, ruski i španjolski. U svemu, naš sistem miješanje integracije i savršene kognite odgovarajuće dobio je najbolji rezultat u usporedbi sa individualnim strategijama, osim parova engleskog-ruskog i ruskog-engleskog jezika za koje je predložen pristup samoporavnosti.', 'so': 'Qoraalkan waxaa lagu qoraa qayb ka qeybqaadashada nidaamka TALN/LS2N ee Building and Using Comparable Corpora (BUCC). Marka ugu horeysa waxaynu soo bandhignaynaa saddex strategiyo: (i) hadal ku habboon oo ku saleysan Text embeddings; (ii) qaab ku habboon isku mid ah oo ku isticmaalaya qoraalka Skip-Gram iyo qoraalka CBOW, ugu danbayna (iii) xiliga ku habboon isku mid ah xadhig saxda ah. Markaas waxaynu soo bandhignaa qorshaha la xiriiray shaqada la wadaajiyey oo ku jirta wadajirka xubnaha iyo qalabka la isku daro. Luqadaha qarsoon waa Faraansiis, Ingiriis, Jarmal, Ruush iyo Isbanish. Inta oo dhan, nidaamkayaga isku xiran kooxaha iyo kooxaha kaamilka ah ayaa helay resultiyada ugu wanaagsan marka la barbardhigo qoraalada gaarka ah, labada luuqada Ingiriis-Ruush iyo Ingiriis-Ingiriis-ka mooyaane, kuwaas oo ay u dooratay dhaqdhaqaaqdhaqaaq.', 'si': 'මේ පැත්තේ TALN/LS2N පද්ධතිය බිල්ඩිම් එක්ක සහ සම්පූර්ණ කෝර්පෝරාව (BUCC) භාවිත කරන්න පුළුවන් විස්තර කරන්න මුලින්ම අපි ප්\u200dරධානය තුනක් ප්\u200dරදේශ කරන්න: (i) FastText Embdings විසින් අධාරිත වචනයක්; (II) අක්ෂර ස්කිප්-ග්\u200dරෑම් සහ අක්ෂර CBOW මෝඩල් දෙන්නම් භාවිතා සම්පූර්ණ විදිහට සම්පූර්ණ විදිහට සම්පූර්ණ විදිහට ඊට පස්සේ, අපි සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සහ සම්බන්ධ වෙනු කපුරු භාෂාවල් තමයි ෆ්\u200dරෑන්ස්, ඉංග්\u200dරීසි, ජර්මන්, රුසියාන්, ස්පැනිස්. සම්පූර්ණයෙන්, අපේ පද්ධතිය මික්ස් එක්ක සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් පිළිගත්ත', 'sv': 'Denna uppsats beskriver TALN/LS2N-systemdeltagandet vid den delade uppgiften Building and Using Comparable Corpora (BUCC). Vi introducerar först tre strategier: (i) en word embedding approach baserad på fastText embeddings; (ii) ett sammanlänkat tillvägagångssätt med både tecken Skip-Gram och tecken CBOW modeller, och slutligen (iii) ett kognitivt matchande tillvägagångssätt baserat på en exakt matchsträngslikhet. Därefter presenterar vi den tillämpade strategin för den delade uppgiften som består i kombinationen av inbäddningar sammankoppling och kogates matchning tillvägagångssätt. De språk som omfattas är franska, engelska, tyska, ryska och spanska. Sammantaget uppnådde vårt system som blandar inbäddningar och perfekt kognitionsmatchning de bästa resultaten jämfört med enskilda strategier, förutom för engelsk-ryska och rysk-engelska språkpar för vilka sammanläggningsmetoden var att föredra.', 'ta': 'இந்த தாள் TALN/LS2N அமைப்பு பகிர்ந்த பணியை உருவாக்குதல் மற்றும் ஒப்பிடும் கோர்போரா (BUCC) பயன்படுத்தும் பகிர்ந்து செயலி முதலில் மூன்று திட்டங்களை குறிப்பிடுகிறோம்: (i) வார்த்தையான உரை நுழைவுகளை அடிப்படையில் உள்ளிடும் சொ (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity.  பிறகு, நாம் பகிர்ந்த பணிக்கு பயன்படுத்தப்பட்ட துறையீட்டை காண்பிக்கிறோம். அது உள்ளீடுகளை கூட்டும் மற்றும் குறியீடுகள் பொர மூடப்பட்ட மொழிகள் பிரெஞ்சு, ஆங்கிலம், ஜெர்மன், ருஷ்யன் மற்றும் ஸ்பானிஷ். மொத்தமாக, எங்கள் அமைப்பு உள்ளீடுகளை கலக்கும் மற்றும் முழுமையான குறியீடுகள் பொருத்தினால் சிறந்த முடிவுகள் பெற்றுவிட்டது, தனிப்பட்ட விளைவுகளை', 'ur': 'This paper describes the TALN/LS2N system participation in the Building and Using Comparable Corpora (BUCC) shared task. ہم پہلے تین استراتژی پیش کریں گے: i) ایک لکھی مضبوط تقریبا ہے جو fastText embeddings پر بنیاد ہے۔ (ii) ایک متقابل طریقہ ہے کہ دو شخصوں کو Skip-Gram اور Character CBOW موڈل کے مطابق، اور آخر میں (iii) ایک مطابق متقابل طریقہ پر مطابق مطابق استرینگ برابری کی بنیاد رکھتا ہے. پھر ہم مشترک کام کے لئے تقویت کی استراتژی پیش کرتے ہیں جو انبودینگ کی ملکیت میں ہے اور مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق ہے محفوظ زبانیں فرانسوی، انگلیسی، جرمن، روسی اور اسپانیایی ہیں۔ سب سے، ہماری سیستم مہینڈنگ کی مہینڈنگ کی مہینڈنگ اور کامل معلومات کی مہینڈنگ کے ساتھ بہترین نتیجے حاصل کیے گئے، مگر انگلیسی-روسی اور روسی-انگلیسی زبان جوڑوں کے علاوہ جن کے لئے مہمانت کا طریقہ پسند کیا گیا ہے', 'uz': "Bu hujjat buyruqni Buyruq va Buyruq Korpora (BUCC) bilan ishlatadigan TALN/LS2N tizimning qismini anglatadi. Birinchi so'zni uchta strategiya beramiz:(i) Soat Text embeddingi asosida yaratilgan so'z ichki bir so'z (ii) Koʻpaytirish usuli Skip- Gram va belgi CBOW modellari yordamida foydalanish va oxirida (iii) toʻgʻri mos keladigan usul bilan mos keladigan kognatlar. Keyin biz bir necha vazifa uchun qo'llangan strategiyani ko'rib chiqaramiz. Bu tashkilotlarni birlashtirish va kognatlarni birlashtirish usullari bilan birlashtirish mumkin. Bu tillar Fransuz, Ingliz, Olmoncha, Ruscha va Ispancha tili. Overall, our system mixing embeddings concatenation and perfect cognates matching obtained the best results while compared to individual strategies, except for English-Russian and Russian-English language pairs for which the concatenation approach was preferred.", 'vi': 'Tờ giấy này mô tả sự tham gia hệ thống TALN/LS2N tại tòa nhà và sử dụng một công việc chia sẻ của Corpus (BUCC). Đầu tiên chúng ta sẽ đưa ra ba chiến lược: i) một phương pháp lắp chữ dựa trên sự nhúng nhanh. Một phương pháp hợp tác dùng cả hình mẫu Skip-Gram và kí tự CBOW, và cuối cùng, III, một phương pháp khớp răng dựa trên một nét giống nhau chính xác. Sau đó, chúng tôi đưa ra chiến lược được áp dụng cho việc chia sẻ, gồm sự kết hợp của sự kết hợp giữa các cuộc họp và các phương pháp phù hợp. Những ngôn ngữ được đề cập là Pháp, Anh, Đức, Nga và Tây Ban Nha. Nói chung, sự hoà trộn hệ thống của chúng tôi thành lập và những bánh răng hoàn hảo đạt được kết quả tốt nhất so với các chiến lược cá nhân, ngoại trừ các cặp ngôn ngữ Anh-Nga và Nga-Anh mà cách tiếp cận hợp tác là thích hợp nhất.', 'bg': 'Настоящата статия описва участието на системата в споделената задача Изграждане и използване на сравним корпор (БУК). Първо въвеждаме три стратегии: (i) подход за вграждане на думи, базиран на вграждания по бърз текст; ii) подход на конкатенация, използващ както моделите Skip-Gram, така и моделите CBOW, и накрая iii) подход на съвпадение на знаците въз основа на сходство на низовете с точно съвпадение. След това представяме приложената стратегия за споделената задача, която се състои в комбинацията на вградените конатенации и познатите подходи за съвпадение. Обхванатите езици са френски, английски, немски, руски и испански. Като цяло, нашата система за смесване на вграждания конкатенация и перфектно съвпадение на конгати постигна най-добри резултати в сравнение с индивидуалните стратегии, с изключение на английски-руските и руски-английски езикови двойки, за които беше предпочитан подход на конкатенация.', 'da': 'Denne artikel beskriver TALN/LS2N-systemets deltagelse i Building and Using Comparable Corpora (BUCC) delte opgave. Vi introducerer først tre strategier: (i) en word embedding tilgang baseret på fastText embeddings; (ii) en sammenkoblingsmetode ved hjælp af både tegn Skip-Gram og tegn CBOW modeller, og endelig (iii) en kognitiv matching metode baseret på en nøjagtig match streng lighed. Derefter præsenterer vi den anvendte strategi for den fælles opgave, som består i kombinationen af indlejringer sammenkobling og cognates matchende tilgange. De dækkede sprog er fransk, engelsk, tysk, russisk og spansk. Samlet set opnåede vores system blanding af indlejringer sammenkobling og perfekt cognates matching de bedste resultater sammenlignet med individuelle strategier, undtagen for engelsk-russisk og russisk-engelsk sprogpar, hvor sammenkobling tilgang var foretrukket.', 'nl': 'Dit artikel beschrijft de TALN/LS2N systeemparticipatie bij de gezamenlijke taak Building and Using Comparable Corpora (BUCC). We introduceren eerst drie strategieën: (i) een woord embedding aanpak gebaseerd op fastText embedding; (ii) een aaneenschakelingsbenadering waarbij gebruik wordt gemaakt van zowel tekens Skip-Gram als teken CBOW modellen, en ten slotte (iii) een cognate matching benadering gebaseerd op een exacte overeenkomst string gelijkenis. Vervolgens presenteren we de toegepaste strategie voor de gedeelde taak die bestaat uit de combinatie van de embeddings aaneenschakeling en de cognates matching benaderingen. De behandelde talen zijn Frans, Engels, Duits, Russisch en Spaans. Over het algemeen behaalde ons systeem het beste resultaat in vergelijking met individuele strategieën, behalve voor Engels-Russisch en Russisch-Engels taalparen waarvoor de aaneenschakeling de voorkeur had.', 'hr': 'Ovaj papir opisuje sudjelovanje sustava TALN/LS2N u zgradi i korištenju komparabilne korpore (BUCC) zajedničkog zadatka. Prvo predstavljamo tri strategije: i) riječ uključujući pristup na osnovu fastText ugrađenja; ii) pristup usklađivanja koristeći i modele karaktera Skip-Gram i karakter CBOW, i konačno iii) kogniraju odgovarajući pristup na temelju točne sličnosti string. Onda predstavljamo prijavljenu strategiju za zajednički zadatak koji se sastoji u kombinaciji sastavljanja integracija i kognije odgovarajućih pristupa. Pokriveni jezici su francuski, engleski, nemački, ruski i španjolski. Nakon svega, naš sustav miješanja integracije i savršene kognite odgovarajuće dobio je najbolje rezultate u usporedbi s individualnim strategijama, osim parova engleskog-ruskog i ruskog-engleskog jezika za koje je preferiran pristup concatenacije.', 'de': 'Dieser Beitrag beschreibt die TALN/LS2N Systembeteiligung an der gemeinsamen Aufgabe Building and Using Comparable Corpora (BUCC). Zunächst stellen wir drei Strategien vor: (i) einen Worteinbettungsansatz basierend auf fastText Einbettungen; (ii) ein Verkettungsansatz, der sowohl Zeichen Skip-Gram als auch Zeichen CBOW Modelle verwendet, und schließlich (iii) ein kognitiver Matching Ansatz basierend auf einer exakten Übereinstimmung String Ähnlichkeit. Anschließend stellen wir die angewandte Strategie für die gemeinsame Aufgabe vor, die in der Kombination der Einbettungsverkettung und der kognitiven Matching-Ansätze besteht. Die behandelten Sprachen sind Französisch, Englisch, Deutsch, Russisch und Spanisch. Insgesamt erzielte unser System die besten Ergebnisse im Vergleich zu einzelnen Strategien, mit Ausnahme von Englisch-Russisch und Russisch-Englisch Sprachpaaren, für die der Verkettungsansatz bevorzugt wurde.', 'id': 'Kertas ini menggambarkan participasi sistem TALN/LS2N di tugas berbagi Building and Using Comparable Corpora (BUCC). Pertama kita memperkenalkan tiga strategi: (i) pendekatan penyembedding kata berdasarkan penyembedding FastText; (ii) pendekatan konatenasi menggunakan kedua karakter Skip-Gram dan karakter model CBOW, dan akhirnya (iii) sebuah pendekatan yang cocok berdasarkan persamaan string persis. Kemudian, kami mempersembahkan strategi yang diterapkan untuk tugas yang sama yang terdiri dalam kombinasi dari penyesalan embedding dan pendekatan yang cocok. Bahasa tertutup adalah bahasa Perancis, Inggris, Jerman, Rusia dan Spanyol. Secara keseluruhan, sistem kami mencampur pembangunan konatenasi dan kognat sempurna yang cocok mendapat hasil terbaik sementara dibandingkan dengan strategi individu, kecuali pasangan bahasa Inggris-Rusia dan Rusia-Inggris yang mana pendekatan konatenasi lebih memilih.', 'fa': 'این کاغذ مشارکت سیستم TALN/LS2N در ساختمان و استفاده از کار مشترک کوپرا (BUCC) را توصیف می\u200cکند. ما اول سه استراتژی را معرفی می کنیم: (i) یک دستور وارد کردن کلمه بر اساس وارد کردن FastText; (ii) یک روش هماهنگی با استفاده از مدل های قالب Skip-Gram و karakter CBOW، و بالاخره (iii) یک روش هماهنگی را بر اساس یک شباهت string دقیق مشابه می\u200cکند. سپس، ما استراتژی کاربرد برای کار مشترک را پیشنهاد می\u200cکنیم که در ترکیب ترکیب پیوند\u200cها و ترکیب\u200cهای پیوند\u200cهای مشترک است. زبان\u200cهای مخفی فرانسوی، انگلیسی، آلمانی، روسی و اسپانیایی هستند. در کل، سیستم ما که پیوند پیوند پیوند پیوند پیوند پیوند و شناخت کامل پیدا می\u200cکند، بهترین نتیجه\u200cها را در مقایسه با استراتژی\u200cهای فردی دریافت می\u200cکنند، به جز جفت زبان انگلیسی-روسی و روسی-انگلیسی که برای آن دستور پیوند', 'ko': '본고는 TALN/LS2N 시스템이 빌딩에서 참여하는 상황을 묘사하고 비교 가능한 자료 라이브러리(BUCC)를 사용하여 임무를 공유한다.우리는 먼저 세 가지 전략을 소개했다. (i) 빠른 텍스트 삽입을 바탕으로 하는 단어 삽입 방법.(ii) 문자를 사용하여Gram과 문자 CBOW 모델의 연결 방법을 건너뛰고 (iii)는 정확한 일치 문자열의 유사성을 바탕으로 동원된 일치 방법을 사용합니다.그 다음에 우리는 공유 임무의 응용 전략을 제시했는데 이 전략은 삽입된 연결과 동원 일치 방법의 조합을 포함한다.포함된 언어는 프랑스어, 영어, 독일어, 러시아어, 스페인어이다.전반적으로 개체 전략에 비해 우리는 연결과 완벽한 동원이 일치하는 시스템을 혼합하여 가장 좋은 결과를 얻었지만 영어-러시아어와 러시아어-영어 언어는 제외하고 연결 방법에 더 치우쳤다.', 'sw': 'Gazeti hili linaelezea ushiriki wa mfumo wa TALN/LS2N katika jengo na kutumia kampuni inayofanana (BUCC). Kwanza tunaanzisha mbinu tatu: (i) neno linalozungumzia kwa kutumia matokeo ya haraka; (ii) mbinu za ushirikiano kwa kutumia mbinu za mhusika Skip-Gram na maambukizi ya CBOW, na hatimaye (iii) mbinu zinazofanana na mbinu zinazolinganisha kutokana na mfumo unaofanana sahihi. Kisha, tunaweka mkakati uliotumika kwa kazi hiyo inayohusiana na kuunganisha mabango na mikakati yanayofanana na mbinu zinazofanana. Lugha zilizoandikwa ni Kifaransa, Kiingereza, Kijerumani, Urusi na Kihispania. Kwa ujumla, mfumo wetu unaohusisha mipango ya kuunganisha pamoja na mipango kamili yanayofanana ilipata matokeo bora wakati ukilinganishwa na mikakati binafsi, isipokuwa na wenzetu wa lugha ya Kiingereza na Kiingereza ambazo mbinu hizo zilipenda.', 'sq': 'Ky dokument përshkruan pjesëmarrjen e sistemit TALN/LS2N në detyrën e përbashkët të ndërtimit dhe përdorimit të Korporave të Bashkueshme (BUCC). Ne fillimisht futim tre strategji: (i) një qasje me fjalë përfshirje bazuar në përfshirje të shpejtë Teksti; (ii) një qasje bashkëkalimi duke përdorur si modelet Skip-Gram dhe CBOW të karakterit dhe më në fund (iii) një qasje bashkëkalimi bazuar në një ngjashmëri ekzakte të rreshtit të përputhjes. Pastaj, ne paraqesim strategjinë e aplikuar për detyrën e përbashkët e cila përbëhet në kombinimin e ndërtesave të ndërtesave dhe afrimeve të përshtatshme të njohur. The covered languages are French, English, German, Russian and Spanish.  Në përgjithësi, sistemi ynë përzier ndërtesat e ndërtesave dhe njohjet perfekte që përshtaten fitoi rezultatet më të mira ndërsa krahasoheshin me strategjitë individuale, me përjashtim të çifteve të gjuhës angleze-ruse dhe ruse-angleze për të cilat është preferuar metoda e ndërtesës.', 'tr': 'Bu kagyz TALN/LS2N sistemiň bina we Maýyklyklaýyn Köpüri (BUCC) tarapynda bölýän işi barlaýar. Ilkinji gezek üç strategiýany tanyşdyrýarys: (ii) Kerçek Skip-Gram we Karakter CBOW nusgalaryny ulanan bir samlap metody, we iň soňunda (iii) bir eşleşen metody täze bir kategoriň meňzeşligine daýan ýar. Sonra, biz uygulanan işi paylaşdyrmak üçin bir strategiýany çykýarys. Bu sistemi birleştirmek üçin bir birleşme we tanyş golaýlarynda bar. Gürrülen diller Fransuzça, iňlisçe, Almança, Rusça we İspanyolça. Iňlis-Rus we Rus-iňlis dilinden başga bir hereket isleýän çykyşlarymyz üçin has gowy netijesi gazandy.', 'af': 'Hierdie papier beskrywe die TALN/LS2N stelsel deel by die bou en gebruik Vergelykbare Korpora (BUCC) gedeelde taak. Ons introduseer eerste drie strategies: (i) â\x80\x99n woord inbêring toegang gebaseer op fastText inbêring; (ii) â\x80\x99n samelewing toegang gebruik beide karakter Skip-Gram en karakter CBOW-modelles, en eindelik (iii) â\x80\x99n konnekteer ooreenstemmende toegang gebaseer op â\x80\x99n presies ooreenstemmende string gelykenis. Toe voorsien ons die aanwende strategie vir die gedeelde taak wat bestaan in die kombinasie van die inbêdings samelewing en die konnekteer ooreenstemmende toegange. Die bedek tale is Frans, Engels, Duits, Russies en Spaanse. Oorsaaklik, ons stelsel gemeng inbêdings samelewing en perfekte konnekteers wat ooreenstem het, het die beste resultate ontvang terwyl vergelyk het met individuele strategies, behalwe vir Engels-Russiese en Russiese-Engelse taal pare waarvan die samelewing toegang verkies was.', 'am': 'ይህ ገጽ TALN/LS2N ስርዓት ተግባር በማንበብ እና በተቃራኒ ኮርፖራ (BUCC) በተካፈሉት ስራ ላይ ይናገራል፡፡ መጀመሪያ ሦስት ተቃውሞ እናስጠጋለን:(i) የጾም ጽሑፍ አካባቢዎች በመሠረት የሚደረገው ቃላት አቅራቢያ ነው:: (ii) የፊደል ቅርጽ-ግራም እና የCBOW ዓይነትን በመጠቀም እና በመጨረሻው (iii) የክፍለ ሥርዓት በሚያስተካክሉ ሥርዓት በመሠረት ላይ የሚተካክሉ ቀለም ከዚህም በኋላ በተካፈሉት ስራ ላይ የተጠቃሚ strategieን እናስቀራለን፡፡ የተከፈቱት ቋንቋዎች ፈረንሳይ፣ እንግሊዘኛ፣ ጀርመን፣ ራሽና ስፓኒሽ ናቸው። በጠቅላላ፣ የኢንጂልኛ-ሮሽኛ እና የንግግሊኛ ቋንቋ ተቃውሞ ካልተካክሉ የተሻለ ፍሬዎችን አግኝቷል፡፡', 'hy': 'Այս հոդվածը նկարագրում է ԹԱԼN-ի և LS2N համակարգի մասնակցությունը կառուցվածքի և համեմատական կորպորայի (ԲՈԿԿ) ընդհանուր խնդրի վրա: Առաջին հերթին մենք ներկայացնում ենք երեք ռազմավարություն. i) բառ ներգրավող մոտեցում, հիմնված արագ տեքստի ներգրավման վրա: (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity.  Այնուհետև մենք ներկայացնում ենք ընդհանուր խնդրի համար կիրառված ռազմավարությունը, որը կազմված է ներդրման համեմատության և ճանաչում համապատասխանող մոտեցումների համադրման մեջ: Գործված լեզուները ֆրանսերեն, անգլերեն, գերմաներեն, ռուսերեն և իսպաներեն են: Ամբողջ ընդհանուր առմամբ, մեր համակարգը խառնելով ներդրումների համեմատությունը և կատարյալ ճանաչողական համեմատությունը ստացավ լավագույն արդյունքները համեմատելով անհատական ռազմավարությունների հետ, բացի անգլերեն-ռուս և ռուս-անգլերեն զույգերի, որոնց', 'bn': 'এই পত্রিকাটি বিল্ডিং এবং তুলনা কর্পোরা (বিউসিসি) শেয়ার কর্মসূচিতে টাএলএন/এলএস২এন সিস্টেম অংশগ্রহণের ব্যাখ্যা করছে। আমরা প্রথমে তিনটি কৌশল পরিচয় করিয়ে দিচ্ছি: (i) ফোস্ট ট টেক্সট বিভিন্ন ভিত্তিক ভিত্তিতে একটি শব্দের বিভিন্ (ii) ক্যারেক্টার স্কিপ- গ্রাম এবং চরিত্র সিবিওউড মডেল ব্যবহার করে একটি একত্রিত পদ্ধতি ব্যবহার করে এবং শেষ পর্যন্ত (আই) সঠিক ম্যাচ স্ট্রীনের একই ধরন তারপর আমরা শেয়ার কর্মসূচীর জন্য প্রযোজ্য কৌশল উপস্থাপন করেছি যা বিভিন্ন বিভিন্ন সংগঠন এবং কোক্নেটগুলোর সাথে মিলিত উপায়ের স ভাষাগুলো ফ্রেঞ্চ, ইংরেজি, জার্মান, রুশ এবং স্প্যানিশ। সাধারণত, আমাদের সিস্টেম মিশ্রিত প্রতিষ্ঠানগুলোর সাথে মিশ্রিত এবং পুরোপুরি কোক্নেটের মিশ্রিত ফলাফল পেয়েছে যখন ব্যক্তিগত কৌশলের তুলনায়, ইংর', 'bs': 'Ovaj papir opisuje sudjelovanje sustava TALN/LS2N u zgradi i korištenju komparabilne korpore (BUCC) zajedničkog zadatka. Prvo predstavljamo tri strategije: i) reč uključujući pristup na osnovu fastText ugrađenja; ii) pristup usklađivanja koristeći i modele karaktera Skip-Gram i karakter CBOW, i konačno iii) kogniraju odgovarajući pristup na temelju točne sličnosti string. Onda predstavljamo prijavljenu strategiju za zajednički zadatak koji se sastoji u kombinaciji sastavljanja integracije i kognije odgovarajućih pristupa. Pokriveni jezici su francuski, engleski, nemački, ruski i španjolski. Nakon svega, naš sistem koji miješa integraciju i savršene kognitete koji odgovaraju dobio je najbolji rezultat u usporedbi s individualnim strategijama, osim parova engleskog-ruskog i ruskog-engleskog jezika, za koje je preferiran pristup concatenacije.', 'az': 'Bu kańüńĪt binada TALN/LS2N sisteminin paylaŇüńĪlmasńĪnńĪ v…ô Compatibile Corpora (BUCC) iŇül…ôm…ôsini t…ôsdiq edir. Biz ilk d…ôf…ô √ľ√ß strateji t…ôŇükil edirik: ii) h…ôr c√ľz…ô Skip-Gram v…ô karakter CBOW modell…ôrini istifad…ô ed…ôr…ôk m√ľxt…ôlif t…ôrzi v…ô nihay…ôt (iii) m√ľxt…ôlif t…ôrzi il…ô m√ľxt…ôlif t…ôrzi kimilińüini tanńĪyńĪr. Sonra, biz paylaŇüńĪlan iŇü √ľ√ß√ľn istifad…ô edil…ôn strateji g√∂st…ôririk ki, birl…ôŇüdirilmiŇü birl…ôŇüdirilm…ôl…ôr v…ô yaxńĪnlńĪqlarńĪn birl…ôŇüdirilm…ôsind…ôdir. √Ėzl…ônmiŇü dill…ôr FransńĪz, ńįngilizce, Alman, Rus v…ô ńįspanyoldadńĪr. ∆Źlb…ôtt…ô, sistemimiz birl…ôŇüdirilmiŇü birl…ôŇüdirilm…ôk v…ô m√ľk…ômm…ôl tanńĪyńĪŇülar, birl…ôŇüdirilm…ôk √ľ√ß√ľn ńįngilizce-Rus v…ô Rus-ńįngilizce dill…ôrin √ßiftl…ôri istisna olmaqla, indir stratejil…ôr…ô qarŇüńĪlaŇüdńĪńüńĪ …ôn yaxŇüńĪ sonu√ßlarńĪ aldńĪ.', 'ca': "Aquest paper descriu la participació del sistema TALN/LS2N en la tasca compartida Building and Using Comparable Corpora (BUCC). Primer introduïm tres estratègies: i) un enfocament d'incorporació de paraules basat en incorporacions de text ràpid; ii) un enfocament de concatenació utilitzant tant els models Skip-Gram com CBOW de caràcter, i finalment iii) un enfocament de concatenació basat en una similitud exact a de cadena de concatenació. Llavors presentem l'estratègia aplicada per a la tasca compartida que consisteix en combinar la concatenació d'incorporacions i els enfocaments equivalents. Les llengües cobertes són francès, anglès, alemany, russo i espanyol. En general, el nostre sistema combinant concatenació d'incorporacions i cognats perfectes que coincideixen va obtenir els millors resultats mentre comparats amb estratègies individuals, excepte els parells de llenguatge anglès-russo i russo-anglès per als quals preferia l'enfocament de concatenació.", 'cs': 'Tento článek popisuje účast systému TALN/LS2N na sdíleném úkolu Building and Using Comparable Corpora (BUCC). Nejprve představujeme tři strategie: (i) přístup k vložení slov založený na vložení fastText; (ii) řetězovací přístup používající jak znakové modely Skip-Gram, tak znakové CBOW modely, a nakonec (iii) kognitivní přístup založený na přesné shodě řetězců podobnosti. Následně představujeme aplikovanou strategii pro sdílený úkol, která spočívá v kombinaci řetězců vložení a přístupů odpovídajících přístupům. Zahrnutými jazyky jsou francouzština, angličtina, němčina, ruština a španělština. Celkově, náš systém míchání embeddedů řetězení a perfektní shodování koňátů dosáhl nejlepších výsledků v porovnání s jednotlivými strategiemi, s výjimkou anglicko-ruských a rusko-anglických jazykových párů, u nichž byl preferován řetězení přístup.', 'et': 'Käesolevas artiklis kirjeldatakse TALN/LS2N süsteemi osalemist võrreldavate korpuste ehitamise ja kasutamise (BUCC) jagatud ülesandes. Esiteks tutvustame kolme strateegiat: i) sõna manustamise lähenemisviis, mis põhineb fastText manustamisel; ii) konkatenatsiooni meetod, milles kasutatakse nii märkide Skip-Gram kui ka märkide CBOW mudeleid, ning lõpuks iii) kognitiivse sobitamise meetod, mis põhineb täpsel vastel stringide sarnasusel. Seejärel tutvustame rakendatud strateegiat jagatud ülesande jaoks, mis koosneb manustamise konkatenatsiooni ja kogniatide sobitamise lähenemisviiside kombinatsioonist. Kaetud keeled on prantsuse, inglise, saksa, vene ja hispaania keel. Kokkuvõttes saavutasid meie süsteemi segamise põimimiste konkatenatsioon ja täiuslik kongaatide sobitamine parimad tulemused võrreldes individuaalsete strateegiatega, välja arvatud inglise-vene ja vene-inglise keele paarid, mille puhul eelistati konkatenatsiooni lähenemist.', 'fi': 'Tässä artikkelissa kuvataan TALN/LS2N-järjestelmän osallistumista jaettuun Building and Using Comparable Corpora (BUCC) -tehtävään. Esittelemme ensin kolme strategiaa: (i) sanan upottamiseen perustuva lähestymistapa, joka perustuu fastText upotuksiin; (ii) yhdistävä lähestymistapa käyttäen sekä merkkien Skip-Gram- että merkkien CBOW-malleja, ja lopuksi (iii) kognites matching lähestymistapa perustuu tarkan match merkkijonon samankaltaisuuteen. Tämän jälkeen esittelemme jaetun tehtävän sovelletun strategian, joka koostuu upotusten yhdistämisestä ja kognites matching -lähestymistapojen yhdistelmästä. Kattavat kielet ovat ranska, englanti, saksa, venäjä ja espanja. Kokonaisuudessaan järjestelmäsekoittimien yhdistäminen ja täydellinen kognaattien täsmäytys saavuttivat parhaat tulokset verrattuna yksittäisiin strategioihin, lukuun ottamatta englannin-venäjän ja venäjän-englannin kielipareja, joiden osalta conatenaatiomenetelmä oli suositeltu.', 'ha': "@ info Kayya, ko da na farko da mataimaki uku:(i) wata magana mai embedded a kanzu a kan Fast Text embeddings; help-action Sa'an nan kuma, muna halatar da kimar da aka yi amfani da wa aikin da aka raba shi, wanda ke cikin komai da samfanin samuran samura da sami-sami masu samu'i. The covered languages are French, English, German, Russian and Spanish.  A jumla, na'asarmu da ke haɗa kokoma da kohannayen da ke kami da kamfani, ya sami mafi kyaun matsalari a lokacin da aka sammenliki takwaici masu yiwuni da takwara guda, sai fa da mazaunin Ingiriya-Ruushi da Ingirinsa-Ruushi wanda aka zaɓe hanyarwa zuwa gare su.", 'sk': 'Ta prispevek opisuje sodelovanje sistema TALN/LS2N v skupni nalogi Gradnja in uporaba primerljivih korpusov (BUCC). Najprej predstavimo tri strategije: (i) pristop vključevanja besed, ki temelji na vključevanju fastText; (ii) pristop združevanja z uporabo modelov Skip-Gram znakov in CBOW znakov in končno (iii) pristop ujemanja znakov, ki temelji na podobnosti nizov natančnega ujemanja. Nato predstavljamo uporabljeno strategijo za skupno nalogo, ki je sestavljena iz kombinacije vgradnje konatenacije in priznanih pristopov ujemanja. Zajeti jeziki so francoščina, angleščina, nemščina, ruščina in španščina. Na splošno smo v primerjavi s posameznimi strategijami dosegli najboljše rezultate v primerjavi s posameznimi strategijami, razen za angleško-ruske in rusko-angleške jezikovne pare, za katere je bil najbolj priljubljen pristop konatenacije.', 'he': 'העיתון הזה מתאר את השתתפות במערכת TALN/LS2N בבניין ושימוש בתפקיד משותף של Corpora שווה (BUCC). אנחנו קודם מכירים שלושה אסטרטגיות: (i) גישה של מילה שמבוססת על קישורים מהירים טקסט; (ii) גישה מתאימה בשימוש של דגמנים Skip-Gram ודגמנים CBOW, ולבסוף (iii) מתאימה גישה מתאימה מבוססת על דמיון מתאימה בדיוק. ואז, אנחנו מציגים את האסטרטגיה המתוקפת למשימה המשותפת שמתכתבת בשילוב של הקונקוטנציה והגישות המתאימות. השפות הכוסות הן צרפתית, אנגלית, גרמנית, רוסית וספרדית. באופן כללי, המערכת שלנו מעורבת התאמה של תוכניות ומתאימות של תוכניות מושלמות השיגה את התוצאות הטובות ביותר בהשוואה לאסטרטגיות אישיות, מלבד זוגות שפת אנגלית-רוסית-רוסית-אנגלית שהעדיפה הגישה של התאמה.', 'jv': 'Ngetong iki rambarang kelas tanggal Sistem TarLN/L2N nang nggawe Bukak lan Ngawe Perintah Kopora komparasi (BIC). Awak dhéwé éntuk tanggal telu tasari: i) dadi sing beraksi basa gambar luwih (iii) a concatenation method use the same character Skip-Gram and character IBOw modes, and last (iii) a knowns match method supported on an exact match string Simlarity. Nambah, kita ngubah Program-aplikasi kanggo nggawe gerakan nggawe gerakan karo kowe ngubah ingkang sampulan iki luwih apik lan ingkang sampeyan ingkang sampeyan ingkang sampeyan ingkang sampeyan ingkang sampeyan nggawe Kapan olèhèké wong kuwi Perancis, Inggris, German, Russ lan Spanyol. Diwong-wong, sistem nambah sing ditambang sampeyan lan alam sing perusahaan nggawe barang nggawe barang sing luwih apik dhéwé, njuk kesempatan karo sistem sing nggawe gerarané karo perusahaan- ruso karo Perusahaan-ingles karo Perusahaan-ingles sing apik dhéwé, sing uwis dino sing api', 'bo': 'ཤོག་བྱང་འདིས་བཟོ་བརྩིགས་དང་སྤྱད་ནས་མཇལ་རྩོམ་མཁན་གྱི་ལས་འགུལ་གྱི་TALN/LS2N་རིགས་འདིས་སྤྱོད་ཀྱི་ཡོད། ང་ཚོས་དང་པོ་ནས་འཛམ་གླིང་གི་ཐབས་ལམ་གསུམ་སྟོན་པ་ཡིན། (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity. འོན་ཀྱང་། ང་ཚོས་སྤྱད་སྤྱོད་པའི་ཐབས་ལམ་ལ་མཉམ་དུ་མཉམ་དུ་མཐུན་སྒྲིག ཁོང་ཡོད་པའི་སྐད་རིགས་ཚོར་ཡིག་དང་། དབྱིན་ཡིག་དང་། ཇར་མེན། རུ་ཤོས་ཡིག་དང་། སྐད་རིས། ཡིན་བཟུང་། ང་ཚོའི་མ་ལག་གི་མཉམ་སྦྲེལ་མཐུན་དང་མཐུན་རྣམས་མཐུན་རྐྱེན་ཐུབ་སྐྱེས་བ་རེད།'}
{'en': 'BUCC2020 : Bilingual Dictionary Induction using Cross-lingual Embedding', 'ar': 'BUCC2020: استقراء قاموس ثنائي اللغة باستخدام التضمين عبر اللغات', 'es': 'BUCC2020: Inducción de diccionarios bilingües mediante incrustación multilingüe', 'pt': 'BUCC2020: Indução de dicionário bilíngue usando incorporação de vários idiomas', 'fr': "BUCC2020\xa0: Induction du dictionnaire bilingue à l'aide de l'intégration multilingue", 'ja': 'BUCC 2020 ：クロスリンガル埋め込みを使用したバイリンガル辞書紹介', 'zh': 'BUCC2020:用跨语嵌双语词典归', 'hi': 'BUCC2020: क्रॉस-लिंगुअल एम्बेडिंग का उपयोग करके द्विभाषी शब्दकोश प्रेरण', 'ru': 'BUCC2020: Введение в двуязычный словарь с использованием кросс-лингвистического встраивания', 'ga': 'BUCC2020: Ionduchtú Foclóir Dátheangach ag úsáid Leabú Trastheangach', 'ka': 'BUCC2020: ძირითადი სიტყვარის ინდექცია გამოყენებული კრასენგური ინდექცია', 'hu': 'BUCC2020: Kétnyelvű szótár indukció többnyelvű beágyazással', 'el': 'Δίγλωσση επαγωγή λεξικού με χρήση της διαγώνιας ενσωμάτωσης', 'it': "BUCC2020: Induzione bilingue del dizionario utilizzando l'embedding cross-lingual", 'lt': 'BUCC2020: dvikalbis žodyno įdiegimas naudojant tarpkalbį įdiegimą', 'mk': 'BUCC2020: Дивјазична индукција на речникот со користење на меѓујазичното вградување', 'ms': 'BUCC2020: Induksi Kamus Bahasa Berbahasa menggunakan Pencampuran Selasa-Bahasa', 'kk': 'BUCC2020: Қос тілді ендіру арқылы екі сөздік индукциясы', 'ml': 'BUCC2020: ക്രോസ്- ലിന്\u200dഗുള്\u200d എംബെഡിങ്ങ് ഉപയോഗിച്ച് ബില്\u200dലിങ്ങുള്ള നിഘണ്ടുവിന്റെ നിര്\u200dണ്ണയം', 'mt': 'BUCC2020: L-Induzzjoni tad-Dikjarnarju Bilingwu bl-użu tal-Embedding Translingwu', 'mn': 'BUCC2020: Дөрвөн хэл нэвтрүүлэхийг ашиглан хоёр-хоёр үгийг зогсоох', 'pl': 'BUCC2020: Indukcja dwujęzycznego słownika przy użyciu wbudowania wielojęzycznego', 'no': 'BUCC2020: Bilinguelt ordbokinduksjon ved bruk av krysspråk innbygging', 'sr': 'BUCC2020: Bilingualna indikacija rečnika koristeći krstojezičku integraciju', 'si': 'BUCC2020 යි: ක්\u200dරොස් භාෂාවක් සම්බන්ධනය කරන්න ප්\u200dරයෝජනයෙන් බිලින්ගුල් සංකේතකය සිදුවීම', 'so': 'BUCC2020: Midhaha luqada bilowga ee lagu isticmaalayo korsashada luuqadaha', 'ro': 'BUCC2020: Inducția dicționarului bilingv folosind încorporarea interlingvă', 'sv': 'BUCC2020: Tvåspråkig ordbok Induktion med Cross-lingual Embedding', 'ur': 'BUCC2020: Cross-lingual Embedding کے مطابق دوئلینگ ڈیکلینگ انڈاکٹ', 'ta': 'BUCC2020: க்ராஸ்- மொழி உட்பொதியை பயன்படுத்தி பில்லிங்கல் அகராதி உருவாக்கம்', 'uz': 'BUCC2020: Cross- tillar embedded using Bilinglar lugʻri ishlatish', 'vi': 'Tập tin ngôn ngữ qua kênh đào chữ thập', 'da': 'BUCC2020: Tosproget ordbogsinduktion ved hjælp af tværsproget indlejring', 'nl': 'BUCC2020: Tweetalige woordenboek Inductie met behulp van Cross-lingual Embedding', 'bg': 'БУК2020: Двуезична индукция на речника с помощта на междуезично вграждане', 'hr': 'BUCC2020: Bilingualni indukcija riječnika koristeći preko jezika uključenje', 'de': 'BUCC2020: zweisprachige Wörterbuchinduktion mittels Cross-Lingual Embedding', 'sw': 'BUCC2020: Ujenzi wa Dictionary wa Kiingereza kwa kutumia Makala ya Kimataifa ya lugha', 'tr': 'BUCC2020: Çapraz dil içinde iki sözlük gaýşartma', 'ko': 'BUCC220: 다중 언어로 포함된 이중 언어 사전 구문', 'fa': 'BUCC2020: استفاده از انجمن زبان\u200cهای مختلف', 'id': 'BUCC2020: Induksi Kamus Bahasa Berbahasa menggunakan Pencampuran Selasa Bahasa', 'af': 'BUCC2020: tweede woordeboekinstruksie met gebruik van kruistale inbêding', 'sq': 'BUCC2020: Induktimi dygjuhësor duke përdorur përfshirjen ndërgjuhëse', 'am': 'BUCC2020: የቋንቋው መዝገብ ማውጣት', 'hy': 'ԲուՔ2020: Երկուլեզու բառարանի ինդուկցիան, օգտագործելով երկլեզու ներգրավումը', 'bs': 'BUCC2020: Indukcija dvostrukog rečnika koristeći preko jezika uključenje', 'ca': "BUCC2020: Inducció bilingüe del diccionari utilitzant l'integració translingüística", 'et': 'BUCC2020: Kahekeelse sõnaraamatu induktsioon keeleülese manustamise abil', 'az': 'BUCC2020: Çift dil İşləməsi ilə İkinci Sözlük İşləməsi', 'bn': 'BUCC2020: ক্রস-ভাষা এমবেডিং ব্যবহার করে বাইলিভায়ুয়াল অভিভাবক নির্মাণ', 'cs': 'BUCC2020: Indukce dvojjazyčného slovníku pomocí křížového vložení', 'fi': 'BUCC2020: Kaksikielinen sanakirja induktio käyttäen monikielistä upotusta', 'jv': 'BIC 2020: Bilingual Dilokomori Ngubah Jejaring Kros-Jejaring', 'ha': 'BUCC2020: KCharselect unicode block name', 'sk': 'BUCC2020: Dvojezična indukcija slovarja z uporabo medjezične vdelave', 'he': 'BUCC2020: תוכנית מילון משולשת בשימוש בתכנית משולשת', 'bo': 'BUCC2020: Bilingual Dictionary Induction using Cross-lingual Embedding'}
{'en': 'This paper presents a deep learning system for the BUCC 2020 shared task : Bilingual dictionary induction from comparable corpora. We have submitted two runs for this shared Task, German (de) and English (en) language pair for closed track and Tamil (ta) and English (en) for the open track. Our core approach focuses on quantifying the semantics of the language pairs, so that semantics of two different language pairs can be compared or transfer learned. With the advent of word embeddings, it is possible to quantify this. In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding. This is later used for inducting bilingual dictionary from comparable corpora.', 'ar': 'تقدم هذه الورقة نظام التعلم العميق للمهمة المشتركة BUCC 2020: تحريض القاموس ثنائي اللغة من مجموعة مماثلة. لقد قدمنا مرحلتين تشغيلتين لهذه المهمة المشتركة ، وهما اللغتان الألمانية (de) والإنجليزية (en) لكل من "المسار المغلق" والتاميل (ta) والإنجليزية (en) لـ "المسار المفتوح". يركز نهجنا الأساسي على تحديد دلالات الأزواج اللغوية ، بحيث يمكن مقارنة دلالات اثنين من الأزواج اللغوية المختلفة أو نقل ما تم تعلمه. مع ظهور حفلات الزفاف ، من الممكن قياس ذلك. في هذه الورقة ، نقترح نهج التعلم العميق الذي يستفيد من بيانات التدريب المقدمة ، لإنشاء التضمين عبر اللغات. يتم استخدام هذا لاحقًا لإدخال قاموس ثنائي اللغة من مجموعة مماثلة.', 'fr': "Cet article présente un système d'apprentissage en profondeur pour la tâche partagée BUCC 2020\xa0: Induction du dictionnaire bilingue à partir de corpus comparables. Nous avons soumis deux essais pour cette tâche partagée, la paire de langues allemand (de) et anglais (en) pour la «\xa0piste fermée\xa0» et le tamoul (ta) et l'anglais (en) pour la «\xa0piste ouverte\xa0». Notre approche de base se concentre sur la quantification de la sémantique des paires de langues, afin que la sémantique de deux paires de langues différentes puisse être comparée ou transférée apprise. Avec l'avènement des intégrations de mots, il est possible de le quantifier. Dans cet article, nous proposons une approche de deep learning qui utilise les données de formation fournies pour générer une intégration multilingue. Il est ensuite utilisé pour induire un dictionnaire bilingue à partir de corpus comparables.", 'es': 'Este artículo presenta un sistema de aprendizaje profundo para la tarea compartida de BUCC 2020: inducción de diccionarios bilingües a partir de corpus comparables. Hemos presentado dos corridas para esta tarea compartida, la combinación de idiomas alemán (de) e inglés (en) para «vía cerrada» y tamil (ta) e inglés (en) para la «vía abierta». Nuestro enfoque principal se centra en cuantificar la semántica de las parejas de idiomas, de modo que la semántica de dos pares de idiomas diferentes se pueda comparar o transferir el aprendizaje. Con la llegada de las incrustaciones de palabras, es posible cuantificar esto. En este artículo, proponemos un enfoque de aprendizaje profundo que utiliza los datos de capacitación proporcionados para generar una integración multilingüe. Esto se usa más tarde para introducir un diccionario bilingüe de corpus comparables.', 'pt': 'Este artigo apresenta um sistema de aprendizado profundo para a tarefa compartilhada do BUCC 2020: indução de dicionário bilíngue a partir de corpora comparáveis. Enviamos duas execuções para esta tarefa compartilhada, par de idiomas alemão (de) e inglês (en) para “pista fechada” e tâmil (ta) e inglês (en) para a “pista aberta”. Nossa abordagem principal se concentra em quantificar a semântica dos pares de idiomas, para que a semântica de dois pares de idiomas diferentes possa ser comparada ou transferida aprendida. Com o advento da incorporação de palavras, é possível quantificar isso. Neste artigo, propomos uma abordagem de aprendizado profundo que faz uso dos dados de treinamento fornecidos para gerar a incorporação de vários idiomas. Isso é usado posteriormente para induzir dicionário bilíngue de corpora comparáveis.', 'ja': '本稿では， BUCC 2020の共有課題：同等の組織からのバイリンガル辞書誘導のためのディープラーニングシステムを紹介する．この共有タスクには、「クローズドトラック」のドイツ語（ de ）と英語（ en ）の言語ペア、「オープントラック」のタミル語（ ta ）と英語（ en ）の2つのランが提出されています。私たちのコアアプローチは、2つの異なる言語ペアの意味論を比較したり、学習したりできるように、言語ペアの意味論を定量化することに焦点を当てています。単語埋め込みの登場により、これを定量化することが可能になった。本稿では，提供されたトレーニングデータを活用して，クロスリンガルな埋め込みを生み出す深層学習アプローチを提案する．これは後に同等のコーラからバイリンガル辞書を誘導するために使用される。', 'hi': 'यह पेपर BUCC 2020 साझा कार्य के लिए एक गहरी सीखने की प्रणाली प्रस्तुत करता है: तुलनीय कॉर्पोरेट से द्विभाषी शब्दकोश प्रेरण। हमने इस साझा कार्य के लिए दो रन प्रस्तुत किए हैं, जर्मन (डी) और अंग्रेजी (एन) भाषा जोड़ी "बंद ट्रैक" के लिए और तमिल (टीए) और अंग्रेजी (एन) "ओपन ट्रैक" के लिए। हमारा मूल दृष्टिकोण भाषा जोड़े के शब्दार्थ को मापने पर केंद्रित है, ताकि दो अलग-अलग भाषा जोड़े के शब्दार्थ की तुलना की जा सके या सीखा जा सके। शब्द एम्बेडिंग के आगमन के साथ, इसे मापना संभव है। इस पेपर में, हम एक गहरी सीखने के दृष्टिकोण का प्रस्ताव करते हैं जो क्रॉस-लिंगुअल एम्बेडिंग उत्पन्न करने के लिए आपूर्ति किए गए प्रशिक्षण डेटा का उपयोग करता है। यह बाद में तुलनीय कॉर्पोरेट से द्विभाषी शब्दकोश को शामिल करने के लिए उपयोग किया जाता है।', 'ru': 'В настоящем документе представлена система глубокого обучения для общей задачи BUCC 2020: Введение в двуязычный словарь из сопоставимых корпусов. Мы представили два прогона для этой общей задачи: немецкий (de) и английский (en) языковые пары для «закрытого трека» и тамильский (ta) и английский (en) для «открытого трека». Наш основной подход фокусируется на количественной оценке семантики языковых пар, чтобы семантика двух разных языковых пар могла сравниваться или передаваться. С появлением вложений слов, это можно количественно оценить. В этой статье мы предлагаем подход глубокого обучения, который использует предоставленные обучающие данные для генерации кросс-лингвистического встраивания. Позже он используется для индукции двуязычного словаря из сопоставимых корпусов.', 'zh': '本文为BUCC 2020者共同任务立深度学统,以归语料库双语词典。 臣等已共享二行,德语 (de) 与英语 (en) 语对以"封闭轨道",泰米尔语 (ta) 英语 (en) 用于"开轨道"。 臣等考心之法侧重于量化言语之语义,以较移两语之语义。 随词嵌出,可量化此。 本文中,我们发出一种深度学术,该用给的训练数据生成跨语嵌入。 其后以类语料库引入双语词典。', 'ga': 'Cuirtear i láthair sa pháipéar seo córas domhainfhoghlama le haghaidh tasc comhroinnte BUCC 2020: Ionduchtú foclóir dátheangach ó chorpora inchomparáide. Tá dhá rith curtha isteach againn don Tasc comhroinnte seo, Gearmáinis (de) agus Béarla (en) péire teanga le haghaidh “rian dúnta” agus Tamil (ta) agus Béarla (en) don “rian oscailte”. Díríonn ár gcur chuige lárnach ar shéimeantaic na bpéirí teanga a chainníochtú, ionas gur féidir comparáid a dhéanamh idir dhá phéire teanga éagsúla nó aistriú a fhoghlaim. Le teacht an leabaithe focal, is féidir é seo a chainníochtú. Sa pháipéar seo, molaimid cur chuige domhainfhoghlama a bhaineann úsáid as na sonraí oiliúna a chuirtear ar fáil, chun leabú tras-teanga a ghiniúint. Úsáidtear é seo níos déanaí chun foclóir dátheangach a ionduchtú ó chorpas inchomparáide.', 'ka': "ეს დოკუმენტი აჩვენებს ძალიან სწავლებელი სისტემა BUCC 2020 საერთო დავალებისთვის: შემდგომარებელი კოპორადან მეორე სიტყვანის ინდექცია. ჩვენ ამ გაყოფილი პარამეტრებისთვის, გერმანური და ანგლისური ზოგის 'დახურებული track' და 'Tamil (ta) და ინგლისური (en) ზოგისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვის გადა ჩვენი მნიშვნელოვანი პროგრამის კვანტიფიკაციაში ენის ზოგრამის სმენტიკების კვანტიფიკაციაზე დააყენება, რადგან ორი განსხვავებული ენის ზოგრამის სმენტიკების შესაბამისად შესაძლებელია ეს კონტაქტირება. ამ დოკუნში ჩვენ მინდომებით ძალიან სწავლების მიღება, რომელიც გამოიყენება მონაცემების მონაცემების გამოყენება, რომელიც უფრო მრავალური სიგრძე შე ეს შემდეგ გამოყენება ორიენგური სიტყვანის შემდგომარებელი კორპორაზე.", 'el': 'Η παρούσα εργασία παρουσιάζει ένα σύστημα βαθιάς μάθησης για την κοινή εργασία του BUCC 2020: Διγλωσσή επαγωγή λεξικού από συγκρίσιμα σώματα. Έχουμε υποβάλει δύο εκτελέσεις για αυτή την κοινή εργασία, γερμανικό (de) και αγγλικό (en) γλωσσικό ζεύγος για "κλειστή πίστα" και Ταμίλ (ta) και αγγλικά (en) για την "ανοικτή πίστα". Η βασική μας προσέγγιση εστιάζει στην ποσοτικοποίηση της σημασιολογίας των γλωσσικών ζευγαριών, έτσι ώστε η σημασιολογία δύο διαφορετικών γλωσσικών ζευγαριών να μπορεί να συγκριθεί ή να μεταφερθεί διδαγμένη. Με την έλευση των ενσωμάτωσης λέξεων, είναι δυνατόν να ποσοτικοποιηθεί αυτό. Στην παρούσα εργασία, προτείνουμε μια προσέγγιση βαθιάς μάθησης που χρησιμοποιεί τα παρεχόμενα δεδομένα κατάρτισης, για την παραγωγή γλωσσικής ενσωμάτωσης. Αυτό χρησιμοποιείται αργότερα για την εισαγωγή δίγλωσσου λεξικού από συγκρίσιμα σώματα.', 'kk': 'Бұл қағаз BUCC 2020 ортақ тапсырмасының түсінікті оқыту жүйесін көрсетеді: салыстырылатын корпорадан екі сөздік индукциясы. Біз бұл ортақтастырылған тапсырма үшін, неміс (de) және ағылшын тілінің "closed track" және "Tamil (ta) және ағылшын тілінің "open track" үшін екі жолын жібердік. Біздің негізгі тәсіліміз тілдің екі түрлі тілдің семантикалығын есептеу үшін көмектеседі, сондықтан екі әртүрлі тілдің семантикалығын салыстыру немесе үйренуге болады. Сөздерді ендіру кезінде, бұл санатты есептеу мүмкін. Бұл қағазда біз көп тілдерді ендіру үшін қолданатын көп оқыту тәсілдерін қолдануға арналады. Бұл кейін екі тіл сөздігін салыстыру үшін қолданылады.', 'lt': 'Šiame dokumente pateikiama išsamaus mokymosi sistema, skirta bendrai BUCC 2020 užduotims: dvikalbis žodyno sukūrimas iš panašios korporacijos. Mes pateikėme dvi runs šiam bendram uždaviniui: vokiečių (de) ir anglų (en) kalbų porai "uždaras kelias", o tamelių (ta) ir anglų (en) kalbų porai "atviras kelias". Mūsų pagrindinis požiūris daugiausia dėmesio skiria kalbų poros semantikos kiekybiniam įvertinimui, kad būtų galima palyginti dviejų skirtingų kalbų poros semantiką arba išmokti ją perduoti. Atsiradus žodžių įterpimui, tai galima kiekybiškai įvertinti. Šiame dokumente siūlome gilaus mokymosi metodą, kuris naudojasi pateiktais mokymo duomenimis, siekiant sukurti tarpkalbinį įtraukimą. Vėliau jis naudojamas dvikalbiam žodynui iš panašios kūno indukuoti.', 'it': 'Questo articolo presenta un sistema di deep learning per il compito condiviso BUCC 2020: l\'induzione bilingue del dizionario da corpora comparabili. Abbiamo presentato due versioni per questo task condiviso, coppia di lingue tedesco (de) e inglese (en) per "pista chiusa" e tamil (ta) e inglese (en) per la "pista aperta". Il nostro approccio di base si concentra sulla quantificazione della semantica delle coppie linguistiche, in modo che la semantica di due diverse coppie linguistiche possa essere confrontata o trasferita appresa. Con l\'avvento delle incorporazioni di parole, è possibile quantificare questo. In questo articolo, proponiamo un approccio di deep learning che utilizza i dati di formazione forniti, per generare embedding cross-lingual. Questo viene successivamente utilizzato per indurre dizionario bilingue da corpora comparabili.', 'mk': 'Овој весник претставува систем на длабоко учење за заедничката задача на БУКЦ 2020: Дивјазична индукција на речникот од споредлива корпора. Испративме две записи за оваа заедничка задача, германски (de) и англиски (en) јазички пар за „затворена трага“ и тамилски (ta) и англиски (en) за „отворена трага“. Нашиот основен пристап се фокусира на квантификацијата на семантиката на јазичките парови, за да се спореди семантиката на два различни јазички парови или да се префрли научено. Со пристигнувањето на зборови, можно е да се квантификува ова. Во овој документ, предложуваме длабоко учење пристап кој ги користи обезбедените податоци за обука, за генерирање на меѓујазични вградувања. Ова подоцна се користи за индукција на двојно јазички речник од споредлива корпора.', 'ms': "Kertas ini memperkenalkan sistem pembelajaran dalam untuk tugas berkongsi BUCC 2020: induksi kamus bilingual dari korpra yang boleh dibandingkan. We have submitted two runs for this shared Task, German (de) and English (en) language pair for 'closed track' and Tamil (ta) and English (en) for the 'open track'.  pendekatan utama kita fokus pada kuantifikasi semantik pasangan bahasa, supaya semantik dua pasangan bahasa yang berbeza boleh dibandingkan atau dipindahkan belajar. Dengan kemunculan pembenaman perkataan, ia adalah mungkin untuk kuantifikasi ini. Dalam kertas ini, kami cadangkan pendekatan pembelajaran yang mendalam yang menggunakan data latihan yang diberikan, untuk menghasilkan penerbangan saling bahasa. Ini kemudian digunakan untuk mengakibatkan kamus dua bahasa dari corpora yang sama.", 'ml': "BUCC 2020 പങ്കെടുത്ത ജോലിക്കുള്ള ആഴത്തില്\u200d പഠിക്കുന്ന സിസ്റ്റത്തിനായി ഈ പേപ്പറിന് കാണിക്കുന്നു: തുല്യമായ ക ഈ പങ്കുചേര്\u200dന്ന ടാസ്ക്, ജര്\u200dമ്മന്\u200d (de) ഇംഗ്ലീഷും (en) ഭാഷ ജോടി 'അടച്ച ട്രാക്ക്' എന്നിവര്\u200dക്കും ടാമില്\u200d (ta) ഇംഗ്ലീഷും (en) തുറന്ന ട്രാക നമ്മുടെ അടിസ്ഥാനങ്ങള്\u200d ഭാഷ ജോടികളുടെ സെമാന്റിക്ക് വ്യത്യസ്ത ഭാഷയുടെ ജോടികളുടെ സെമാന്റിക്ക് വ്യത്യസ്ത ഭാഷയുടെ രണ്ട്  വാക്കുകളുടെ അഭിപ്രായത്തില്\u200d ഇത് വിശദീകരിക്കാന്\u200d സാധ്യമല്ല. In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding.  പിന്നീട് ഇത് രണ്ടു ഭാഷകങ്ങളുടെ നിഘണ്ടിന്റെ നിര്\u200dണ്ണയത്തിനായി ഉപയോഗിക്കുന്നു.", 'hu': 'Ez a tanulmány bemutatja a BUCC 2020 közös feladat mélytanulási rendszerét: kétnyelvű szótár indukció hasonló corporákból. Két futást küldtünk be ehhez a megosztott feladathoz: német (de) és angol (en) nyelvpár "zárt sáv", tamil (ta) és angol (en) nyelvpár "nyitott sáv". Alapvető megközelítésünk a nyelvpárok szemantikájának számszerűsítésére összpontosít, így két különböző nyelvpár szemantikáját összehasonlíthatjuk vagy átvihetjük a tanultakat. A szóbeágyazások megjelenésével ezt számszerűsíthetjük. Ebben a tanulmányban olyan mélytanulási megközelítést javasolunk, amely felhasználja a szolgáltatott képzési adatokat a nyelvek közötti beágyazás létrehozására. Ezt később használják kétnyelvű szótár indukálására hasonló corporákból.', 'mn': "Энэ цаас BUCC 2020-ын хуваалцах ажлын гүн гүнзгий суралцах системийг харуулж байна: Хэрэв харьцуулагддаг Корпора-ын хоёр төрлийн үеийн үйлдвэрлэл юм. Бид хоёр даалгавар, Герман (de) болон Англи хэл хоёрыг 'closed track' болон Тамил (ta) болон Англи хэл хоёрыг 'open track' болон 'en' хэлний хувьд тавьсан. Бидний үндсэн арга зам нь хэл хоёрын семантикийг тооцоолж, тэгэхээр хоёр өөр хэл хоёрын семантикийг харьцуулж эсвэл сурсан шилжүүлж чадна. Үүнийг хэмжээгээр тооцоолж болох юм. Энэ цаасан дээр бид суралцах гүн гүнзгий арга зам өгөгдлийг ашиглаж, олон хэл оролцохын тулд хэрэглэдэг. Үүнийг дараа нь хоёр хэл үгийг харьцуулагдах корпораас сэргээх үед хэрэглэгддэг.", 'mt': "Dan id-dokument jippreżenta sistema ta’ tagħlim profond għall-kompitu kondiviż tal-BUCC 2020: L-induzzjoni tad-dikjaratorju bilinguali minn korpora komparabbli. Tbagħtejna żewġ runs għal din il-Kompitu kondiviż, il-Ġermaniż (de) u l-Ingliż (en) par lingwistiku għal 'binarju magħluq' u t-Tamil (ta) u l-Ingliż (en) għal 'binarju miftuħ'. L-approċċ ewlieni tagħna jiffoka fuq il-kwantifikazzjoni tas-semantika tal-pari lingwistiċi, sabiex is-semantika ta’ żewġ pari lingwistiċi differenti tkun tista’ titqabbel jew titgħallem it-trasferiment. Bil-preżenza ta’ inkorporazzjonijiet tal-kliem, huwa possibbli li dan jiġi kkwantifikat. F’dan id-dokument, qed nipproponu approċċ ta’ tagħlim profond li jagħmel użu mid-dejta ta’ taħriġ ipprovduta, biex niġġeneraw inkorporazzjoni translingwistika. Dan aktar tard jintuża biex jinduċi d-dikjararju bilingwi minn korpra komparabbli.", 'pl': 'W artykule przedstawiono system głębokiego uczenia się dla wspólnego zadania BUCC 2020: indukcja dwujęzycznego słownika z porównywalnych korpusów. Zgłosiliśmy dwa przebiegi dla tego wspólnego zadania: niemiecki (de) i angielski (en) dla "zamkniętego toru" oraz tamilski (ta) i angielski (en) dla "otwartego toru". Nasze podstawowe podejście koncentruje się na ilościowym określeniu semantyki par językowych, tak aby semantyka dwóch różnych par językowych była porównywana lub przenoszona. Wraz z pojawieniem się osadzeń słów możliwe jest określenie tego ilościowe. W niniejszym artykule proponujemy podejście głębokiego uczenia, które wykorzystuje dostarczone dane szkoleniowe do generowania osadzenia między językami. Jest to później używane do indukowania dwujęzycznego słownika z porównywalnych korpusów.', 'no': 'Denne papiret viser ein dyp læringssystem for delt oppgåve i BUCC 2020: Bilinguell ordbokinduksjon frå sammenlignbare korpora. Vi har sendt to køyrer for denne delte oppgåva, tysk (de) og engelsk (en) språkopla for «lukka spor» og «Tamil (ta) og engelsk (en) for «opna spor». Kjørne tilnærming vårt fokuserer på kvantifikasjon av semantikkane til språkparene, slik at semantikkane til to ulike språkparer kan sammenlignast eller overførast. Det er mogleg å kvantifika dette med innbygginga av ord. I denne papiret foreslår vi ein dyp læringstilnærming som gjer bruk av dei tilgjengelege opplæringsdata for å laga krysspråk innbygging. Dette vert seinare brukt for å indusera bilinguelt ordbok frå sammenlignbare korpora.', 'ro': 'Această lucrare prezintă un sistem de învățare profundă pentru sarcina comună BUCC 2020: Inducția dicționarului bilingv de la corpore comparabile. Am trimis două rulări pentru această sarcină partajată, perechea limbilor germană (de) și engleză (en) pentru "pista închisă" și tamilă (ta) și engleză (en) pentru "pista deschisă". Abordarea noastră de bază se concentrează pe cuantificarea semanticii perechilor de limbi, astfel încât semantica a două perechi de limbi diferite să poată fi comparată sau transferată învățată. Odată cu apariția încorporărilor de cuvinte, este posibil să se cuantifice acest lucru. În această lucrare, propunem o abordare de învățare profundă, care utilizează datele de formare furnizate, pentru a genera încorporarea translingvistică. Aceasta este folosită mai târziu pentru inducerea dicționarului bilingv din corpore comparabile.', 'sr': "Ovaj papir predstavlja duboki sistem učenja za zajednički zadatak BUCC 2020: indukcija bilingualnog rečnika iz usporednog korporacije. Predložili smo dvije trke za ovaj zajednički zadatak, njemački i engleski par za 'zatvoren trag' i Tamil (ta) i engleski (en) za 'otvoren trag'. Naš jezični pristup se fokusira na kvantificiranje semantike jezičkih parova, tako da se semantike dva različita jezička parova mogu usporediti ili naučiti transfer. Uz dolazak uređenja reèi, moguæe je to kvantificirati. U ovom papiru predlažemo duboki pristup učenja koji koristi dostavljene podatke o obuci, kako bi stvorili međujezičku integraciju. Ovo se kasnije koristi za indukciju dvojezičkog rečnika iz usporednog korporacije.", 'si': "මේ පත්තුවෙන් ගොඩක් ඉගෙනගන්න පද්ධතියක් තියෙනවා BUCC 2020යි කොටස් එක්ක වැදගත් වැඩක් වෙනුවෙන්: බිලින්ග අපි මේ වැදගත් වැඩක්, ජර්මන් (de) සහ ඉංග්\u200dරීසිය (en) භාෂාවක් ජාතිය 'වහල් ට්\u200dරැක්' සහ 'තාමිල් (ta) සහ ඉංග්\u200dරීසිය (en) සඳහා  අපේ මධ්\u200dයම ප්\u200dරමාණය ප්\u200dරමාණය කරනවා භාෂා ජෝඩාවේ සෙමැන්ටික් කිරීමට, ඉතින් වෙනස් භාෂා ජෝඩාවේ සෙමැන්ටික වචනය සම්බන්ධ වෙන්න පුළුවන් විදිහට, මේක ක්\u200dරමාණය කරන්න පුළුවන්. මේ පැත්තට, අපි ගොඩක් ඉගෙන ගන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරනවා ඒකෙන් ප්\u200dරයෝජනය කරලා තියෙන ප්\u200dරයෝජනය කරනවා  මේක පස්සේ පාවිච්චි කරලා තියෙන්න පුළුවන් කොර්පෝරා වලින් දෙවෙනි භාෂාවක් වලින්", 'ta': 'BUCC 2020 பகிர்ந்த பணி இந்த பகிர்ந்த பணி மொழி ஜோடிகளின் பாதிப்பை அளவு குறிப்பிடும் பொழுது நமது முக்கிய செயல்பாடு கவனம் செலுத்துகிறது, எனவே இரண்டு வேறு மொழி ஜோடி With the advent of word embeddings, it is possible to quantify this.  இந்த காகிதத்தில், நாம் ஒரு ஆழமான கற்றுக்கொள்ளும் செயல்பாட்டை பரிந்துரைக்கிறோம். இது கொடுக்கப்பட்ட பயிற்சி தரவை  பிறகு இது ஒப்பீட்டு கோர்போரிலிருந்து இரு மொழி அகராதியை உருவாக்க பயன்படுத்தப்படும்.', 'sv': 'Denna uppsats presenterar ett djupinlärningssystem för BUCC 2020 delad uppgift: Tvåspråkig ordbok induktion från jämförbara corpora. Vi har skickat in två omgångar för denna delade uppgift, tyska (de) och engelska (en) språkpar för "stängt spår" och tamil (ta) och engelska (en) för "öppna spår". Vår kärnstrategi fokuserar på att kvantifiera semantiken för språkparen, så att semantiken för två olika språkpar kan jämföras eller överföras lärda. Med tillkomsten av ordinbäddningar är det möjligt att kvantifiera detta. I den här uppsatsen föreslår vi en djupinlärningsmetod som använder de tillhandahållna utbildningsdata för att generera tvärspråkig inbäddning. Detta används senare för att inducera tvåspråkig ordbok från jämförbara corpora.', 'so': "Warqaddan waxaa lagu qoraa nidaamka waxbarashada aad u dheer ee BUCC 2020 oo lagu qeybeeyey shaqo: warqadda luqada bilowga ee shirkadda u eg. Waxaannu u soo dhiibnay laba jardiino oo loo sameynayo shaqooyinka la waday, Jarmal (de) iyo Ingiriis (en) labada luqadood oo loo qoray 'gaadiid xiran' iyo Tamil (ta) iyo Ingiriis (en) in lagu sameeyo 'jidka furan'. Dhaqdhaqaalahayaga hoose waxay ku qoran yihiin qiyaastii labada labo oo luqada ah, si ay u barbaran karto labada labo oo luuqadood oo kala duduwan. Waxaa suurtagal ah in aad ku qiyaasto macluumaadka hadalka. Qoraalkan waxaynu soo jeedaynaa qaab aad u dheer oo waxbarasho ah oo isticmaalaya macluumaadka waxbarashada la siiyo, si aan u soo saarno koritaanka luqada kala duwan. Tan waxaa dib looga isticmaalaa in uu ka soo bandhigo luqada labada luqadood ee shirkadda isbarbarka ah.", 'ur': "یہ کاغذ بوسی 2020 کے مشترک کام کے لئے ایک عمیق سیستم کی تعلیم دیتا ہے: مشترک کورپورا سے دوئینگل لکھنے کا انتظام۔ ہم نے اس مشترک کام کے لئے دو رونڈ ڈال دیئے ہیں، جرمانی اور انگلیسی زبان جوڑوں کے لئے 'بند ٹراک' اور 'ٹامیل' اور 'انگلیسی ٹراک' کے لئے۔ ہمارا اصلی طریقہ زبان جوڑوں کی سیمانٹیکوں کا مقدار کرنا ہے تاکہ دو مختلف زبان جوڑوں کی سیمانٹیکوں کا مقایسہ یا ترافیس سکھایا جائے کلمات کے مطابق اسے اندازہ کرنا ممکن ہے اس کاغذ میں ہم ایک عمیق سیکھنے کی طریقہ پیشنهاد کرتے ہیں جس نے تحویل دیئے گئے ترینس ڈیٹے سے استعمال کیا ہے، کروس زبان انڈیڈنگ بنانے کے لئے۔ یہ اس کے بعد دو زبان کا لکھنے کے لئے استعمال کیا جاتا ہے کہ مثال قابل شرکت سے دوسری زبان کا لکھنا ہے.", 'uz': "Bu qogʻoz BUCC 2020 bilan bogʻliq vazifani boshqa o'rganish tizimni koʻrsatiladi: Ikkita lugʻatning xizmatidan teng bo'lishi mumkin. Biz bu bir bogʻliq vazifa, Olmon (de) va ingliz tili (en) 'yopilgan yo'lak' va Tamil (ta) va Inglizcha (en) uchun ikkita ishlatilgan vazifa qoʻyilgan. Bizning asosiy usuli tilning ikkita tillar ikki xil qonlarini aniqlashga qarshi mumkin, shunday qilib, ikkita tillar qonlarining semantikasi o'rganishi mumkin yoki o'zgartirish mumkin. Buni aniqlash mumkin. Bu qogʻozda, biz bir necha tillar tarkibini yaratish uchun o'rganish muvaffaqiyatli o'rganish usulini talab qilamiz. Keyinroq bu kompaniyadan ikkita tillar lugʻatni ishga tushirish uchun ishlatiladi.", 'vi': 'Tờ giấy này cung cấp một hệ thống học sâu cho tập vụ BUC 2020 được dùng chung: từ điển giải được tạo ra từ vật thể tương tự. Chúng tôi đã đệ trình hai lần cho nhiệm vụ chia sẻ này, hai lần của Đức (de) và Anh ngữ (en) cho "đường ray đóng kín" và Tamil (ta) và Anh (en) cho "đường ray mở". Điểm mấu chốt của chúng tôi là việc định lượng ngữ pháp của các cặp ngôn ngữ, để ngữ pháp được so sánh hoặc truyền đạt. Với sự xuất hiện của sự nhúng tay từ, có thể xác định được nó. Trong tờ giấy này, chúng tôi đề nghị một phương pháp học sâu, sử dụng dữ liệu huấn luyện được cung cấp, để tạo ra sự khai thác ngôn ngữ khác nhau. Thứ này được dùng để thêm từ điển hai chiều từ hạ sĩ tương tự.', 'bg': 'Настоящата статия представя система за дълбоко обучение за споделената задача на БУК 2020: двуезична индукция на речник от сравними корпуси. Предложихме две проби за тази споделена задача, немски (де) и английски (en) езикова двойка за "затворена писта" и тамилски (та) и английски (en) за "отворена писта". Нашият основен подход се фокусира върху количествено определяне на семантиката на езиковите двойки, така че семантиката на две различни езикови двойки да може да бъде сравнена или прехвърлена научена. С появата на вграждането на думи е възможно това да се определи количествено. В настоящата статия предлагаме подход за дълбоко обучение, който използва предоставените данни за обучение, за да генерира междуезично вграждане. Това по-късно се използва за индукция на двуезичен речник от сравними корпуси.', 'hr': "Ovaj papir predstavlja duboki sustav učenja za zajednički zadatak BUCC 2020: indukcija dvostrukog rečnika iz usporednog korporacije. Predložili smo dvije trke za ovaj zajednički zadatak, njemački i engleski pair za 'zatvoren trag' i Tamil (ta) i engleski (en) za 'otvoren trag'. Naš osnovni pristup se fokusira na kvantificiranje semantike jezičkih pare, tako da se semantike dva različita jezička pare mogu usporediti ili učiti prijenos. Uz dolazak uređenja riječi, moguće je kvantificirati ovo. U ovom papiru predlažemo duboki pristup učenja koji koristi dostavljene podatke o obuci kako bi stvorili međujezičku integraciju. Ovo se kasnije koristi za indukciju dvojezičkog rečnika iz usporednog korporacije.", 'nl': "Deze paper presenteert een deep learning systeem voor de BUCC 2020 gedeelde taak: Tweetalige woordenboek inductie uit vergelijkbare corpora. We hebben twee runs ingediend voor deze gedeelde Taak, Duits (de) en Engels (en) taalpaar voor 'gesloten track' en Tamil (ta) en Engels (en) voor de 'open track'. Onze kernaanpak richt zich op het kwantificeren van de semantiek van de taalparen, zodat semantiek van twee verschillende taalparen kan worden vergeleken of overgedragen geleerd. Met de komst van woord embeddings, is het mogelijk om dit te kwantificeren. In dit artikel stellen we een deep learning aanpak voor die gebruik maakt van de geleverde trainingsdata, om cross-lingual embedding te genereren. Dit wordt later gebruikt voor het induceren van tweetalig woordenboek uit vergelijkbare corpora.", 'da': "Denne artikel præsenterer et dybt læringssystem til BUCC 2020 delte opgave: Tosproget ordbogsinduktion fra sammenlignelige corpora. Vi har indsendt to kørsler til denne delte opgave, tysk (de) og engelsk (en) sprogpar for 'lukket spor' og tamil (ta) og engelsk (en) for 'åbent spor'. Vores centrale tilgang fokuserer på at kvantificere semantikken af sprogparrene, så semantikken af to forskellige sprogpar kan sammenlignes eller overføre lært. Med fremkomsten af ordindlejringer er det muligt at kvantificere dette. I denne artikel foreslår vi en dyb læringstilgang, der gør brug af de leverede træningsdata til at generere tværsproget indlejring. Dette bruges senere til at inducere tosproget ordbog fra sammenlignelige corpora.", 'id': "Kertas ini mempersembahkan sistem belajar dalam untuk tugas berbagi BUCC 2020: induksi kamus bahasa dua dari korpora yang bisa dibandingkan. We have submitted two runs for this shared Task, German (de) and English (en) language pair for 'closed track' and Tamil (ta) and English (en) for the 'open track'.  pendekatan utama kita fokus pada kuantifikasi semantik pasangan bahasa, sehingga semantik dua pasangan bahasa yang berbeda dapat dibandingkan atau dipindahkan belajar. With the advent of word embeddings, it is possible to quantify this.  In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding.  Ini kemudian digunakan untuk menginduksi kamus dua bahasa dari corpora yang sama.", 'de': "Dieser Beitrag stellt ein Deep Learning System für die gemeinsame Aufgabe BUCC 2020 vor: zweisprachige Wörterbuchinduktion aus vergleichbaren Korpora. Wir haben zwei Runs für diese gemeinsame Aufgabe eingereicht, Deutsch (de) und Englisch (en) Sprachpaar für 'closed track' und Tamil (ta) und Englisch (en) für die 'open track'. Unser Kernansatz konzentriert sich auf die Quantifizierung der Semantik der Sprachpaare, so dass Semantik zweier unterschiedlicher Sprachpaare verglichen oder erlernt werden kann. Mit dem Aufkommen von Wort Einbettungen ist es möglich, dies zu quantifizieren. In diesem Beitrag schlagen wir einen Deep Learning Ansatz vor, der die bereitgestellten Trainingsdaten nutzt, um eine sprachübergreifende Einbettung zu generieren. Dies wird später verwendet, um zweisprachiges Wörterbuch aus vergleichbaren Korpora zu induzieren.", 'ko': "본고는 BUCC 2020 공유 임무를 위한 깊이 있는 학습 시스템을 소개한다. 비교할 수 있는 자료 라이브러리에서 이중 언어 사전을 귀납한다.우리는 이 공유 작업을 위해 독일어 (de) 와 영어 (en) 언어는 '폐쇄 궤도', 테밀어 (ta) 와 영어 (en) 는 '개방 궤도' 를 두 번 실행했다.우리의 핵심 방법은 두 가지 서로 다른 언어의 의미를 비교하거나 학습하기 위해 양적 언어의 의미를 중시하는 데 중심을 두었다.단어가 삽입됨에 따라 이것은 가능한 양적이다.본고에서 우리는 제공된 훈련 데이터를 이용하여 다중 언어를 삽입하는 깊이 있는 학습 방법을 제시했다.이것은 나중에 비교 가능한 어료 라이브러리에서 이중 언어 사전을 귀납하는 데 쓰였다.", 'fa': 'این کاغذ یک سیستم یادگیری عمیق برای کار مشترک BUCC 2020 را نشان می دهد: فعالیت دوگانی از شرکت قابل مقایسه. ما دو راه برای این کار مشترک، جفت زبان آلمانی و انگلیسی را برای «سیستم بسته» و «تامیل» و «انگلیسی» برای «سیستم باز» فرستادیم. روش اصلی ما روی مقدار تعداد سیمانتیک جفت زبان تمرکز می\u200cکند، بنابراین سیمانتیک دو جفت زبان مختلف می\u200cتواند در مقایسه یا انتقال یافته شود. با پیشرفت کلمه\u200cهایی که وارد می\u200cشوند، ممکن است این را تعداد کنیم. در این کاغذ، ما یک روش عمیق یادگیری را پیشنهاد می\u200cکنیم که از داده\u200cهای آموزش داده شده استفاده می\u200cکند، برای تولید داخل زبان\u200cهای متفاوتی. این بعدا برای تولید دوزبانی از شرکت قابل مقایسه استفاده می\u200cشود.', 'tr': "Bu kagyz BUCC 2020'yň paylaşyk görevi üçin derin öwrenme sistemini görkezýär: kelläp üçin ikinji sözlük guralýar. Biz bu paylaşyk işi, Almança (de) we iňlisçe (en) dil çiňisi üçin 'closed track' we Tamil (ta) we iňlisçe (en) gönderdik. Biziň esasy ýagdaýymyz dil çiftleriniň semantiklerini ölçüp, bu üçin iki dürli dil çiftleriniň semantikleri gurlap ýa-da öwrenip biler. Kelimeler geleninde, bunları ölçülemek mümkün. Bu kagyzda, biz çukur öwrenmek taýýarlanýan ýagdaýy teklip edip, çarpaz diller içine girmek üçin ulanýar. Bu soňra ikinji dil sözlügini komparaşdyrylýan korporadan täsir etmek üçin ulanylýar.", 'sw': "Makala hii inaonyesha mfumo wa kujifunza kwa ajili ya kazi ya BUCC 2020 iliyoshirikiana: uzalishaji wa lugha za lugha kutoka kwa kampuni inayofanana. Tumewasilisha mbili kwa ajili ya kazi hii inayosambazwa, Ujerumani (de) na Kiingereza (en) mbili kwa ajili ya 'njia ya kufungwa' na Tamil (ta) na Kiingereza (en) kwa ajili ya 'njia ya wazi'. Mfumo wetu wa msingi unajikita kwenye kupambana na mifano ya wanandoa wa lugha, ili mpango wa wanandoa wa lugha mbili tofauti unaweza kulinganisha au kuhamisha kujifunza. Kwa kutumia ujumbe wa maneno, inawezekana kutambua hili. Katika gazeti hili, tunapendekeza mbinu za kujifunza za za kina ambazo zinatumia taarifa za mafunzo zinazotumika, ili kutengeneza uwezekano wa lugha mbalimbali. Hii baadae inatumiwa kwa ajili ya kutengeneza lugha mbili kutoka kwenye makampuni yanayofanana.", 'af': "Hierdie papier stel 'n diep leersysteem voor die gedeelde taak van BUCC 2020: tweede woordeboekinduksie van vergelykbare korpora. Ons het twee hardloop voorgestuur vir hierdie gedeelde taak, Duits (de) en Engels (en) taal paar vir 'closed track' en Tamil (ta) en Engels (en) vir die 'open track'. Ons koordtoegang fokus op die kvantifikasie van die semantieke van die taal paar, sodat semantieke van twee verskillende taal paar kan vergelyk of oordrag geleer word. Met die voorkoms van woord inbêding is dit moontlik om dit te quantiëer. In hierdie papier voorstel ons 'n diep leer toegang wat gebruik maak van die verskaf onderwerp data om kruistale inbêding te genereer. Hierdie word later gebruik om tweedelingse woordeboek te indukseer van vergelykbare korpora.", 'sq': "Ky dokument paraqet një sistem mësimi të thellë për detyrën e përbashkët të BUCC 2020: induktimin e fjalorin dygjuhësor nga korpra të krahasueshme. Ne kemi dërguar dy runs për këtë Task të përbashkët, çift gjerman (de) dhe anglisht (en) gjuhë për 'track të mbyllur' dhe Tamil (ta) dhe anglisht (en) për 'track të hapur'. Përqasja jonë thelbësore përqëndrohet në kuantifikimin e semantikës së çifteve gjuhësore, në mënyrë që semantikën e dy çifteve të ndryshme gjuhësh të mund të krahasohet apo të transferohet të mësuar. Me shfaqjen e shprehjes së fjalëve, është e mundur ta quantifikojmë këtë. In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding.  Kjo përdoret më vonë për të induktuar fjalorin dy-gjuhës nga korpra të krahasueshme.", 'bn': "এই পত্রিকাটি বিউসিসি ২০২০ শেয়ার কর্মসূচির জন্য গভীর শিক্ষা ব্যবস্থা উপস্থাপন করেছে: তুলনা কর্পোরা থেকে বিলিঙ্গুয়েল অভি আমরা এই শেয়ার করা কাজ, জার্মান (ডি) এবং ইংরেজি (en) ভাষার জোয়ারের জন্য দুটি চালানো দিয়েছি 'বন্ধ ট্র্যাক' এবং তামিল (ta) এবং ইংরেজি (en) এর জন্য ' আমাদের মূল পদ্ধতি ভাষার জোড়ার সেমেন্টিক্স পরিমাপের উপর মনোযোগ দিয়েছে, যাতে দুই ভাষার জোড়ার সেমেন্টিক্সের তুলনা অথবা পরি With the advent of word embeddings, it is possible to quantify this.  এই কাগজটিতে আমরা একটি গভীর শিক্ষা পদক্ষেপ প্রস্তাব করি যা প্রযোজ্য প্রশিক্ষণের তথ্য ব্যবহার করে, যাতে ক্রিভাষাভাষায় ব পরবর্তীতে তুলনামূলক কর্পোরা থেকে দুই ভাষার অভিভাবক তৈরি করার জন্য এটি ব্যবহার করা হয়।", 'az': "Bu kağıt BUCC 2020 paylaşılan iş üçün çətin öyrənmə sistemini göstərir: Comparison corpora'dan ikinci sözlük induksyonu. Biz bu paylaşılmış işin, Almanca dillərin və İngilizce dili çiftlərini 'kapalı yol', Tamil və İngilizce dillərinin 'açıq yol' üçün iki dəfə göndərdik. Bizim ilk tərzimiz dil çiftlərinin semantikalarını quantifik etməyə odaqlanır, böylece iki müxtəlif dil çiftlərinin semantikalarını öyrənmək və ya transfer öyrənmək üçün. Sözlük inşallarının gəlib çatdığı kimi, bunu hesablamaq mümkün olar. Bu kağızda, çoxlu dillərlə birləşdirmək üçün təhsil edilmiş təhsil məlumatlarını istifadə edən derin öyrənmə metodlarını təklif edirik. Bu, daha sonra iki dilli sözlük yaratmaq üçün istifadə edilir.", 'hy': 'This paper presents a deep learning system for the BUCC 2020 shared task: Bilingual dictionary induction from comparable corpora.  Մենք ներկայացրեցինք երկու ընթացք այս ընդհանուր հանձնարարության համար, գերմաներեն (de) և անգլերեն (en) լեզվի զույգը «փակ ճանապարհ» և «թամիլ (ta) և անգլերեն (en) բաց ճանապարհ» համար: Our core approach focuses on quantifying the semantics of the language pairs, so that semantics of two different language pairs can be compared or transfer learned.  Բառերի ներդրման արդյունքում հնարավոր է չափել սա: Այս թղթի մեջ մենք առաջարկում ենք խորը ուսումնասիրության մոտեցում, որը օգտագործում է տրամադրված ուսումնասիրության տվյալները, ստեղծելու միջլեզվային ներգրավման համար: Այն ավելի ուշ օգտագործվում է երկլեզու բառարանի արտադրման համար համեմատական մարմնից:', 'bs': "Ovaj papir predstavlja duboki sistem učenja za zajednički zadatak BUCC 2020: indukcija bilingualnog rečnika iz usporednog korporacije. Predložili smo dvije trke za ovaj zajednički zadatak, njemački i engleski par za 'zatvoren trag' i Tamil (ta) i engleski (en) za 'otvoren trag'. Naš jezični pristup se fokusira na kvantificiranje semantike jezičkih parova, tako da se semantike dvije različite jezičke pare mogu usporediti ili naučiti transfer. Uz dolazak uređenja riječi, moguće je kvantificirati ovo. U ovom papiru predlažemo duboki pristup učenja koji koristi dostavljene podatke o obuci, kako bi stvorili međujezičku integraciju. Ovo se kasnije koristi za indukciju dvojezičkog rečnika iz usporednog korporacije.", 'et': 'Käesolevas töös tutvustatakse sügavõppe süsteemi BUCC 2020 jagatud ülesandeks: kahekeelse sõnastiku induktsioon võrreldavatest korpustest. Oleme esitanud selle ühise ülesande jaoks kaks sõitu: saksa (de) ja inglise (en) keelepaar suletud rajale ning tamili (ta) ja inglise (en) avatud rajale. Meie põhiline lähenemine keskendub keelepaaride semantika kvantifitseerimisele, nii et kahe erineva keelepaari semantikat saaks võrrelda või õppida edasi. Sõnade manustamise tulemusel on võimalik seda kvantifitseerida. Käesolevas dokumendis pakume välja sügavõppe lähenemisviisi, mis kasutab esitatud koolitusandmeid, et luua keeleülene manustamine. Seda kasutatakse hiljem kahekeelse sõnastiku indutseerimiseks võrreldavatest korpustest.', 'am': 'ይህ ገጽ BUCC 2020 የተለየ ስራ የጥልቅ ትምህርት ሲስተማርን አቀረበ፤ ቢልቋዊ መዝገብ መዝገብ ከኮርፖርት የተለየ ነው፡፡ ወደዚህ ተካፈለ ስራ፣ ጀርመን (de) እና እንግሊዘኛ (en) ቋንቋ ሁለት ዓይነቶች ለታሚል (ta) እና እንግሊዝኛ (en) ለክፍት መንገድ አቀረብን፡፡ የቋንቋ አካባቢነታችን የሁለት ቋንቋዎች ሁለት ዓይነቶችን ማሳየት ይችላል፡፡ የቃላት አቀማመጥ ማውጣት ይቻላል፡፡ በዚህ ካላት፣ የቋንቋ ቋንቋ መፍጠርን ለመፍጠር የሚጠቅመውን የጥልቅ ትምህርት መግለጫ እናስባለን፡፡ ከዚህም በኋላ ሁለት ቋንቋዎች መዝገብ ከመተካከል ይደረጋል፡፡', 'cs': 'Tento článek představuje systém hlubokého učení pro sdílený úkol BUCC 2020: dvojjazyčná indukce slovníku ze srovnatelných korpusů. Předložili jsme dva běhy pro tento sdílený úkol, němčina (de) a angličtina (en) jazykový pár pro "uzavřenou trať" a tamilština (ta) a angličtina (en) pro "otevřenou trať". Náš základní přístup se zaměřuje na kvantifikaci sémantiky jazykových párů, aby mohla být sémantika dvou různých jazykových párů porovnána nebo přenášena učená. S příchodem slovních vložení je možné to kvantifikovat. V tomto článku navrhujeme přístup hlubokého učení, který využívá dodaných tréninkových dat k generování cross-jazyčného vložení. To se později používá pro indukci dvojjazyčného slovníku ze srovnatelných korpusů.', 'fi': 'Tässä artikkelissa esitellään syväoppimisjärjestelmä BUCC 2020:n yhteiseen tehtävään: Kaksikielinen sanakirja-induktio vertailukelpoisista korpusista. Olemme lähettäneet tälle yhteiselle tehtävälle kaksi ajoa, saksan (de) ja englannin (en) kielipari suljetulle radalle ja tamil (ta) ja englanti (en) avoimelle radalle. Keskeinen lähestymistapamme keskittyy kieliparin semantiikan kvantifiointiin, jotta kahden eri kieliparin semantiikkaa voidaan verrata tai oppia siirtämään. Sanaupotusten myötä tämä on mahdollista kvantifioida. Tässä artikkelissa ehdotamme syväoppimista koskevaa lähestymistapaa, jossa hyödynnetään toimitettuja koulutustietoja ja luodaan monikielinen upotus. Tätä käytetään myöhemmin kaksikielisen sanakirjan indusoimiseen vastaavista korpusista.', 'ca': "Aquest paper presenta un sistema d'aprenentatge profund per a la tasca compartida BUCC 2020: inducció bilingüe del diccionari de corpora comparable. We have submitted two runs for this shared Task, German (de) and English (en) language pair for 'closed track' and Tamil (ta) and English (en) for the 'open track'.  Our core approach focuses on quantifying the semantics of the language pairs, so that semantics of two different language pairs can be compared or transfer learned.  Amb l'aparició d'incorporacions de paraules, és possible quantificar això. En aquest paper, proposem un enfocament d'aprenentatge profund que utilitzi les dades de formació proporcionades per generar integració translingüística. Això s'utilitza més tard per induir diccionari bilingüe de corpora comparable.", 'jv': "Perintah iki gunakake sistem ndhelik kanggo kelas sistem kejahatan task BOC 2020 durung: Bilingual dikondarno sing sampeyan karo perusahaan Awak dhéwé ngewehi sistem durung kanggo nggawe task, German (de) lan Inggris (en) nggo 'Clotrack' lan Tamil (ta) lan Inggris (en) kanggo 'open track' Awak dhéwé éntuk sistem sing nggawe sistem sematik nggawe geraraning winih, dadi sematik iki bangsane bisa supoyo nggawe geraraning, njuk ujaran. Dijarang winih Nang kuwi iki, awak dhéwé ngerasakno diangkat luwih apik sing nggawe ngubah data nggawe aturan sing ngewehke, kanggo nggawe akeh bantuan luwih apik. Iki iso ngejaraké kanggo kelompok uripdurung bisa-bisa kuwi bagian.", 'ha': "Wannan takardan na bãyar da wani tsari mai ƙaranci wa BUCC 2020 mai shirin aiki: dictionary induce daga kamari. Mun samar da tafiyar biyu wa wannan aikin da aka raba shi, jeruman (de) da Ingiriya (en) sau biyu zuwa 'bango' da aka rufe 'kuma Tamili (ta) da Ingiriya (en) zuwa 'bango bayyananne'. Mataimakinmu na ƙari yana ƙayyade kimar biyu na harshen, dõmin a sami mutane biyu masu cikin lingui biyu ko kuma a sami da motsi. Ga da aka shigar da takardar magana, za'a iya iya ƙayyade wannan. Ga wannan takardan, Munã bukãtar da wani matsayi mai zura da za'a yi amfani da data da aka samu, dõmin ya sami cikin lugha mai fassara. Wannan ana yi amfani da wajen nuna wata dictionary biyu daga koma sami.", 'he': 'העבודה הזו מציגה מערכת לימוד עמוקה עבור המשימה המשותפת של BUCC 2020: דליקת מילון משולשת משותפת. שלחנו שני רצויות עבור המשימה המשותפת הזו, זוג שפה גרמנית (de) ואנגלית (en) עבור "מסלול סגור" וטמיל (ta) ואנגלית (en) עבור "מסלול פתוח". הגישה העיקרית שלנו מתמקדת בכוונה של הסמנטיקה של זוגות השפה, כך שסמנטיקה של שתי זוגות שפות שונות יכולה להשוות או להעביר ללמוד. עם ההופעה של מילים, אפשר לקוות את זה. בעיתון הזה, אנו מציעים גישה למידה עמוקה שמשתמשת בנתונים האימונים המסופקים, כדי ליצור תוכנית בין שפות. זה משתמש מאוחר יותר כדי להדליק מילון שתיים שפוי מתוך גופורה שווה.', 'sk': 'V prispevku je predstavljen sistem globokega učenja za skupno nalogo BUCC 2020: Dvojezična indukcija slovarja iz primerljivih korpusov. Za to skupno nalogo smo predložili dve tekmi, jezikovni par nemščine (de) in angleščine (en) za "zaprto progo" ter tamilščine (ta) in angleščine (en) za "odprto progo". Naš osrednji pristop se osredotoča na kvantifikacijo semantike jezikovnih parov, tako da lahko semantiko dveh različnih jezikovnih parov primerjamo ali prenesemo naučeno. S prihodom besednih vdelav je to mogoče količinsko opredeliti. V tem prispevku predlagamo pristop globokega učenja, ki uporablja predložene podatke o usposabljanju za ustvarjanje medjezičnega vključevanja. To se kasneje uporablja za indukcijo dvojezičnega slovarja iz primerljivih korpusov.', 'bo': "འོག་གི་ཤོག་བྱང་འདིས་ BUCC 2020་ཡི་མཉམ་སྤྱོད་པའི་ལས་འགུལ་གྱི་ཟབ་འཛིན་གྱི་མ་ལག་ཅིག་སྟོན་པ་ཡིན། We have submitted two runs for this shared Task, German (de) and English (en)language pair for 'closed track' and Tamil (ta) and English (en)for the 'open track'. ང་ཚོའི་རྨས་གཞུང་གི་ཐབས་ལམ་དེ་སྐད་ཡིག་གི་ཆ་རྩིས་ཀྱི་རྩིས་འབྲེལ་འདི་གྲངས་སུ་འབྲེལ་བ་དང་མཐུན་རྐྱེན་ཐབས་ཤིག་འདུག ཡིག་ཆ་གསར་འཛུགས་ཀྱི་ཐ་སྙད་འདི་གྲངས་སུ་རྩིས་བཏང་བ་ཡིན། In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding. དེ་ནི་དུས་ཚོད་ལས་ སྦུང་མཐུན་ཅན་གྱི་ཡིག"}
