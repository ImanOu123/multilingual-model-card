{'en': 'Learning Curricula for Multilingual Neural Machine Translation Training', 'ar': 'مناهج تعليمية للتدريب على الترجمة الآلية العصبية متعددة اللغات', 'pt': 'Currículos de aprendizado para treinamento de tradução automática neural multilíngue', 'es': 'Currículos de aprendizaje para la capacitación en traducción automática neuronal multilingüe', 'fr': "Cursus d'apprentissage pour la formation en traduction automatique neuronale multilingue", 'ja': '多言語神経機械翻訳トレーニングのための学習カリキュラム', 'zh': '多言神经机器翻译培训之学', 'hi': 'बहुभाषी तंत्रिका मशीन अनुवाद प्रशिक्षण के लिए पाठ्यक्रम सीखना', 'ru': 'Учебные программы для обучения многоязычному нейронному машинному переводу', 'ga': 'Curaclaim Foghlama le haghaidh Oiliúint Ilteangach Néar-Aistriúcháin Meaisín', 'el': 'Εκπαιδευτικά προγράμματα εκμάθησης για την κατάρτιση πολυγλωσσικής νευρωνικής μηχανικής μετάφρασης', 'ka': 'Multilingual Neural Machine Translation Training', 'hu': 'Tanulási tanterv a többnyelvű neurális gépi fordítás képzéséhez', 'lt': 'Mokymosi kursas daugiakalbiams nervinių mašinų vertimo mokymui', 'it': 'Curricula di apprendimento per la formazione multilingue di traduzione automatica neurale', 'kk': 'Көп тілдік нейрал машинаның аудару оқыту бағдарламасы', 'ml': 'പല ഭാഷ നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷ പഠിക്കുന്ന പഠിപ്പിക്കുന്നു', 'mt': 'Kurikula għat-Tagħlim għat-Taħriġ fit-Traduzzjoni Multilingwi tal-Magni Newrali', 'mn': 'Олон хэлний мэдрэлийн машин хөгжүүлэх сургалт суралцах', 'no': 'Læring av program for fleirspråk neuralmaskinsomsetjing', 'ro': 'Curricula de învățare pentru instruirea de traducere automată neurală multilingvă', 'ms': 'Learning Curricula for Multilingual Neural Machine Translation Training', 'mk': 'Learning Curricula for Multilingual Neural Machine Translation Training', 'si': 'ගොඩක් භාෂාවක් න්\u200dයුරාල් මැෂින් වාර්තාව ප්\u200dරශ්නය සඳහා ඉගෙනගන්න', 'sv': 'Lärande läroplan för flerspråkig neural maskinöversättning utbildning', 'pl': 'Programy nauczania się wielojęzycznego tłumaczenia maszynowego neuronowego', 'sr': 'Učim program za vežbu multijezičkih neuronskih uređaja za prevod', 'so': 'Waxbarashada waxbarashada qoraalka ah ee luuqadaha kala duduwan', 'ta': 'பல மொழி நெருக்கல் இயந்திரம் மொழிபெயர்ப்பு பயிற்சி', 'ur': 'Multilingual Neural Machine Translation Training', 'vi': 'Học hành kinh phí cho đa ngôn ngữ thần kinh đào tạo dịch', 'uz': 'Name', 'da': 'Læringsplaner for flersproget neural maskinoversættelse træning', 'bg': 'Учебни програми за многоезично обучение по неврален машинен превод', 'nl': 'Leren Curricula voor meertalige neuronale machinevertaling Training', 'de': 'Lerncurricula für mehrsprachige neuronale maschinelle Übersetzung Training', 'id': 'Learning Curricula for Multilingual Neural Machine Translation Training', 'ko': '다국어 신경기계 번역 교육의 학습 과정', 'hr': 'Učenje učenja za vježbanje multijezičkih neuroloških uređaja', 'sw': 'Kujifunza Mfumo wa Tafsiri ya Mashine ya Kifaragha', 'fa': 'آموزش آموزش آموزشی برای ترجمه ماشین عصبی چندین زبان', 'am': 'ቋንቋዎች', 'hy': 'Բազլեզու նյարդային մեքենայի թարգմանման ուսումնասիրություն', 'sq': 'Mësimi i mësimeve për trajnimin e përkthimit të makinave nervore shumëgjuhëse', 'tr': 'Çoklu dilli Näral Maşynyň terjime edilmesi üçin Curricula öwrenmek', 'bn': 'বহুভাষী নিউরাল মেশিন অনুবাদ প্রশিক্ষণের জন্য কার্রিকুলা', 'af': 'Leer Program vir Multilingual Neurale Masjien Vertaling Oefening', 'cs': 'Výukové osnovy pro vícejazyčné nervové strojové překlady školení', 'et': 'Õppekavad mitmekeelse neuroaalse masintõlke koolituse jaoks', 'az': 'Çoxlu dilli nöral maşın tərcümə təhsilinin öyrənməsi', 'fi': 'Oppimisopetussuunnitelmat monikieliseen hermojen konekäännöskoulutukseen', 'bs': 'Učenje učenja za vježbanje multijezičkih neuronskih uređaja', 'ca': 'Learning Curricula for Multilingual Neural Machine Translation Training', 'jv': 'Ngawe Perintah Currikula kanggo Terjamahan kapan Neral Manus Inggal Tulungan', 'he': 'לימוד מתגלה לאימוני תרגום של מכונות נוירות רבות שפות', 'ha': 'KCharselect unicode block name', 'sk': 'Učni učni načrti za večjezično usposabljanje za strojno prevajanje nevronov', 'bo': 'སྐད་རིགས་དབྱིབས་དབྱེ་བ་དང་བསྟུན་ནས་དབྱེ་བ་གཙོ་རིམ་ལ་བསླབ་པ'}
{'en': 'Low-resource Multilingual Neural Machine Translation (MNMT) is typically tasked with improving the  translation  performance on one or more language pairs with the aid of high-resource language pairs. In this paper and we propose two simple search based curricula   orderings of the multilingual training data   which help improve  translation  performance in conjunction with existing techniques such as  fine-tuning . Additionally and we attempt to learn a  curriculum  for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits. We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.', 'ar': 'عادةً ما تُكلف الترجمة الآلية العصبية متعددة اللغات منخفضة الموارد (MNMT) بتحسين أداء الترجمة في زوج لغوي واحد أو أكثر بمساعدة أزواج اللغات عالية الموارد. في هذه الورقة ، نقترح منهجين بسيطين يعتمدان على البحث - ترتيب بيانات التدريب متعدد اللغات - مما يساعد على تحسين أداء الترجمة جنبًا إلى جنب مع التقنيات الحالية مثل الضبط الدقيق. بالإضافة إلى ذلك ، نحاول تعلم منهج لـ MNMT من البداية بالاشتراك مع تدريب نظام الترجمة باستخدام قطاع الطرق السياقي متعدد الأذرع. نوضح في مجموعة بيانات الترجمة منخفضة الموارد في FLORES أن هذه المناهج الدراسية يمكن أن توفر نقاط انطلاق أفضل لضبط وتحسين الأداء العام لنظام الترجمة.', 'fr': "La traduction automatique neuronale multilingue (MNMT) à faibles ressources est généralement chargée d'améliorer les performances de traduction sur une ou plusieurs paires de langues à l'aide de paires de langues à ressources élevées. Dans cet article, nous proposons deux programmes simples basés sur la recherche — l'ordonnancement des données de formation multilingues — qui aident à améliorer les performances de traduction en conjonction avec les techniques existantes telles que le réglage fin. De plus, nous essayons d'apprendre un programme pour le MNMT à partir de zéro en même temps que la formation du système de traduction utilisant des bandits multibras contextuels. Nous montrons sur le jeu de données de traduction à faibles ressources FLORES que ces programmes peuvent fournir de meilleurs points de départ pour affiner et améliorer les performances globales du système de traduction.", 'es': 'La traducción automática neuronal multilingüe (MNMT) de bajos recursos normalmente se encarga de mejorar el rendimiento de la traducción en una o más combinaciones de idiomas con la ayuda de combinaciones de idiomas de gran cantidad de recursos. En este artículo proponemos dos planes de estudio simples basados en búsquedas (ordenamientos de los datos de capacitación multilingües) que ayudan a mejorar el rendimiento de la traducción junto con las técnicas existentes, como el ajuste fino. Además, intentamos aprender un plan de estudios para MNMT desde cero junto con la capacitación del sistema de traducción utilizando bandidos contextuales de múltiples brazos. En el conjunto de datos de traducción de bajos recursos de FLORES mostramos que estos currículos aprendidos pueden proporcionar mejores puntos de partida para el ajuste fino y mejorar el rendimiento general del sistema de traducción.', 'pt': 'A tradução automática neural multilíngue de baixo recurso (MNMT) geralmente tem a tarefa de melhorar o desempenho da tradução em um ou mais pares de idiomas com a ajuda de pares de idiomas de alto recurso. Neste artigo, propomos dois currículos simples baseados em pesquisa – ordenação dos dados de treinamento multilíngue – que ajudam a melhorar o desempenho da tradução em conjunto com técnicas existentes, como ajuste fino. Além disso, tentamos aprender um currículo para MNMT a partir do zero em conjunto com o treinamento do sistema de tradução usando bandidos multi-braços contextuais. Mostramos no conjunto de dados de tradução de baixo recurso FLORES que esses currículos aprendidos podem fornecer melhores pontos de partida para ajuste fino e melhorar o desempenho geral do sistema de tradução.', 'hi': 'कम-संसाधन बहुभाषी तंत्रिका मशीन अनुवाद (MNMT) को आमतौर पर उच्च-संसाधन भाषा जोड़े की सहायता से एक या अधिक भाषा जोड़े पर अनुवाद प्रदर्शन में सुधार करने का काम सौंपा जाता है। इस पेपर में और हम दो सरल खोज आधारित पाठ्यक्रम का प्रस्ताव करते हैं - बहुभाषी प्रशिक्षण डेटा के आदेश - जो मौजूदा तकनीकों जैसे कि फाइन-ट्यूनिंग के साथ संयोजन के रूप में अनुवाद प्रदर्शन में सुधार करने में मदद करते हैं। इसके अतिरिक्त और हम प्रासंगिक बहु-हाथ डाकुओं का उपयोग करके अनुवाद प्रणाली के प्रशिक्षण के साथ संयुक्त रूप से खरोंच से एमएनएमटी के लिए एक पाठ्यक्रम सीखने का प्रयास करते हैं। हम FLORES कम संसाधन अनुवाद डेटासेट पर दिखाते हैं कि ये सीखा पाठ्यक्रम ठीक ट्यूनिंग के लिए बेहतर शुरुआती अंक प्रदान कर सकते हैं और अनुवाद प्रणाली के समग्र प्रदर्शन में सुधार कर सकते हैं।', 'ja': '低リソース多言語ニューラルマシン翻訳（ MNMT ）は、典型的には、高リソース言語ペアを活用して1つ以上の言語ペアの翻訳パフォーマンスを向上させることを任務とする。この論文では、微調整などの既存のテクニックと組み合わせて翻訳パフォーマンスを向上させるのに役立つ、2つの単純な検索ベースのカリキュラム（多言語トレーニングデータの順序）を提案しています。さらに、文脈上のマルチアームバンディットを使用した翻訳システムのトレーニングとともに、MNMTのカリキュラムを一から学ぼうとしています。フローレスの低リソース翻訳データセットでは、これらの学習されたカリキュラムが、微調整のためのより良い出発点を提供し、翻訳システムの全体的なパフォーマンスを向上させることができることを示しています。', 'zh': '低资源多语言神经机器翻译 (MNMT) 常务借高资言语对重译。 本文二简- 多言培训序 - 此有助于合术(如微调)重译性也。 试从头学MNMT程,用上下文多臂贼译系培训。 FLORES 低资源译数集上明,可以为微调之始,而重译统之性。', 'ru': 'Низкоресурсный многоязычный нейронный машинный перевод (MNMT), как правило, призван повысить производительность перевода на одной или нескольких языковых парах с помощью высокоресурсных языковых пар. В этой статье и мы предлагаем две простые основанные на поиске учебные программы – упорядочение многоязычных учебных данных – которые помогают улучшить эффективность перевода в сочетании с существующими методами, такими как точная настройка. Кроме того, мы пытаемся выучить учебную программу для MNMT с нуля вместе с обучением системы перевода с использованием контекстуальных многоруких бандитов. Мы показываем на наборе данных перевода с низким уровнем ресурсов FLORES, что эти изученные учебные программы могут обеспечить лучшие отправные точки для точной настройки и улучшить общую производительность системы перевода.', 'ga': 'Is gnách go gcuirtear de chúram ar Aistriúchán Inneall Néarach Ilteangach ar acmhainní íseal (MNMT) feabhas a chur ar fheidhmíocht aistriúcháin ar phéire teanga amháin nó níos mó le cabhair ó phéirí teanga ard-acmhainne. Sa pháipéar seo agus molaimid dhá churaclam cuardaigh shimplí – orduithe na sonraí oiliúna ilteangacha – a chuidíonn le feabhas a chur ar fheidhmíocht aistriúcháin i gcomhar le teicníochtaí reatha amhail mionchoigeartú. Ina theannta sin agus déanaimid iarracht curaclam don MNMT a fhoghlaim ón tús i gcomhpháirt le hoiliúint an chórais aistriúcháin ag baint úsáide as bandits comhthéacsúla illáimhe. Léirímid ar thacar sonraí aistriúcháin íseal-acmhainne FLORES gur féidir leis na curaclaim fhoghlama seo pointí tosaigh níos fearr a sholáthar le haghaidh mionchoigeartaithe agus feabhas a chur ar fheidhmíocht iomlán an chórais aistriúcháin.', 'hu': 'Az alacsony erőforrású többnyelvű idegi fordítás (MNMT) jellemzően feladata egy vagy több nyelvpár fordítási teljesítményének javítása, nagy erőforrású nyelvpárok segítségével. Ebben a tanulmányban két egyszerű keresési alapú tantervet javasolunk - a többnyelvű képzési adatok rendezését -, amelyek segítenek javítani a fordítási teljesítményt a meglévő technikákkal, például a finomhangolással együtt. Ezenkívül megpróbáljuk megtanulni az MNMT tantervét a semmiből a fordítási rendszer képzésével együtt kontextuális többkarú banditák segítségével. A FLORES alacsony erőforrású fordítási adatkészletén megmutatjuk, hogy ezek a tanult tantervek jobb kiindulópontokat nyújthatnak a fordítási rendszer finomhangolásához és általános teljesítményének javításához.', 'it': "La traduzione automatica neurale multilingue a basso contenuto di risorse (MNMT) è tipicamente incaricata di migliorare le prestazioni di traduzione su una o più coppie linguistiche con l'aiuto di coppie linguistiche ad alto contenuto di risorse. In questo articolo proponiamo due semplici curricula basati sulla ricerca - l'ordinamento dei dati di formazione multilingue - che aiutano a migliorare le prestazioni di traduzione in combinazione con tecniche esistenti come la messa a punto. Inoltre, cerchiamo di imparare un curriculum per MNMT da zero insieme alla formazione del sistema di traduzione utilizzando contestuali banditi multi-braccio. Mostriamo sul set di dati FLORES per la traduzione a basso contenuto di risorse che questi curricula appresi possono fornire migliori punti di partenza per la messa a punto e migliorare le prestazioni complessive del sistema di traduzione.", 'ka': 'მრავალენგური ნეიროლური მაქსინის განაცვლა (MNMT) ტიპულად უკეთესებულია განაცვლის მუშაობა ერთი ან მეტი ენგური ზოგებისთვის ერთი ან მეტი ენგური ზოგებისთვის მეხმარეობით ამ დოკუნეში და ჩვენ მხოლოდ საძიებო კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკური კონფიკ დამატებით და ჩვენ მოვცდილობთ MNMT-ის კონტექსტური პროგლუმის შესწავლობა, რომელიც შესწავლობა სისტემის შესწავლობა, რომელიც გამოყენება კონტექსტური მრავალ FLORES-ს ცოტა რესურსის გადაწყვეტილების მონაცემებზე ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ეს სწავლილი კურსიკულა შეუძლია უფრო მეტი გადაწყვეტილება და გადაწყვეტილება სისტემის', 'lt': 'Low-resource Multilingual Neural Machine Translation (MNMT) is typically tasked with improving the translation performance on one or more language pairs with the aid of high-resource language pairs.  In this paper and we propose two simple search based curricula - orderings of the multilingual training data - which help improve translation performance in conjunction with existing techniques such as fine-tuning.  Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits.  FLORES nedidelių išteklių vertimo duomenų rinkinyje parodome, kad šios išmoktos mokymo programos gali suteikti geresnių atskaitos taškų tobulinimui ir bendram vertimo sistemos veiksmingumui gerinti.', 'mk': 'Мал ресурс Мултијазичен неврален машински превед (MNMT) обично е задолжен со подобрување на преведувањето на еден или повеќе јазички парови со помош на парови на јазик со високи ресурси. Во овој весник и предложуваме два едноставни научни програми базирани на пребарување - наредби на податоците за мултијазична обука - кои помагаат во подобрувањето на преведувањето заедно со постојните техники како што е финетизирање. Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits.  На групата на податоци за превод со ниски ресурси на ФЛОРЕС покажуваме дека овие научени наставни планови можат да обезбедат подобри почетни точки за подобрување и подобрување на целокупната перформанса на преводниот систем.', 'ml': 'കുറഞ്ഞ വിഭവങ്ങളില്\u200d പല ഭാഷ നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷകള്\u200d (MNMT) ഒരു ഭാഷയിലോ കൂടുതല്\u200d ഭാഷ ജോടികളിലുള്ള പരിഭാഷപ്രദര്\u200dശനം മെച്ചപ്പെടുത്തുന്നതിനാല ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d രണ്ടു സാധാരണ തെരച്ചില്\u200d അടിസ്ഥാനമായ പദ്ധതിയില്\u200d നിര്\u200dദ്ദേശിക്കുന്ന രണ്ട് സാധാരണ തെരച്ചില്\u200d നിര്\u200dദ്ദേശിക്കുന്നു.  കൂടാതെ നമ്മള്\u200d MNMT-ന് ഒരു പഠിപ്പിക്കാന്\u200d ശ്രമിക്കുന്നു. നിശ്ചയമായി പല-കൈ ബാങ്കിറ്റുകള്\u200d ഉപയോഗിച്ച് ട്രാക്ക് ചെയ്യുന് ഫ്ലോറസിന്റെ കുറഞ്ഞ വിഭവങ്ങളുടെ പരിഭാഷയുടെ വിവരങ്ങളില്\u200d ഞങ്ങള്\u200d കാണിച്ചുകൊടുക്കുന്നു. ഈ പഠിച്ച കാര്\u200dക്കുള്ള വിവരങ്ങള്\u200d നല്ല ത', 'el': 'Η πολυγλωσσική νευρωνική μηχανική μετάφραση χαμηλής περιεκτικότητας σε πόρους (συνήθως έχει ως αποστολή τη βελτίωση της απόδοσης μετάφρασης σε ένα ή περισσότερα γλωσσικά ζεύγη με τη βοήθεια γλωσσικών ζευγαριών υψηλών πόρων. Στην παρούσα εργασία προτείνουμε δύο απλά προγράμματα σπουδών βασισμένα στην αναζήτηση και παραγγελίες των πολύγλωσσων δεδομένων κατάρτισης που βοηθούν στη βελτίωση της απόδοσης της μετάφρασης σε συνδυασμό με τις υπάρχουσες τεχνικές όπως ο συντονισμός. Επιπλέον και προσπαθούμε να μάθουμε ένα πρόγραμμα σπουδών για το ΜΜΤ από το μηδέν από κοινού με την εκπαίδευση του μεταφραστικού συστήματος χρησιμοποιώντας περιβαλλοντικούς πολυβραχίονες ληστές. Δείχνουμε στο σύνολο δεδομένων μετάφρασης χαμηλής περιεκτικότητας σε πόρους ότι αυτά τα μαθημένα προγράμματα σπουδών μπορούν να παρέχουν καλύτερα σημεία εκκίνησης για τον συντονισμό και τη βελτίωση της συνολικής απόδοσης του μεταφραστικού συστήματος.', 'mn': 'Маш бага боловсрол олон хэлний мэдрэлийн машины хөгжүүлэлт (MNMT) нь ихэвчлэн нэг эсвэл олон хэлний холбооны хөгжүүлэлтийг сайжруулахын тулд ажилладаг. Энэ цаасан дээр бид хоёр энгийн хайлтын сургалтын хөтөлбөр, олон хэлний сургалтын өгөгдлийн захирал, үүнийг хөгжүүлэхэд тусалдаг. Мөн бид MNMT-ийн сургалтын хөтөлбөрийг олон гарын багтаа ашиглан орчуулах системийн сургалтын тусламжтай хамтдаа суралцах гэж хичээсэн. Бид FLORES бага боловсролын хөрөнгө оруулах өгөгдлийн сан дээр харуулж байна. Эдгээр сургалтын хөрөнгө хөрөнгө хөрөнгө оруулах системийн ерөнхий үйл ажиллагааг сайжруулж чадна.', 'no': 'Låg ressurs Multispråk Neuralmaskinsomsetjing (MNMT) er vanlegvis oppgåve med å forbetra omsetjinga på eitt eller fleire språk- par med hjelp av høg- ressursspråk- par. I denne papiret foreslår vi to enkle søkebaserte program – rekkeføringar av fleirspråksøvingsdata – som hjelper å forbedra omsetjingsfunksjonen i samsvar med eksisterande teknikk som fin-tuning. I tillegg prøver vi å lære eit curriculum for MNMT frå å rulla saman med opplæringa av omsetjingssystemet ved hjelp av kontekstiske multi arm-bandar. Vi viser på FLORES låg ressursomsetjingsdata at desse lærte programmene kan gje bedre startpunkt for fylt oppsett og forbetra overalt utvikling av omsetjingssystemet.', 'pl': 'Wielojęzyczne neuronowe tłumaczenie maszynowe o niskich zasobach (MNMT) ma zazwyczaj za zadanie poprawić wydajność tłumaczenia jednej lub więcej par językowych za pomocą par językowych o dużym zasobie. W niniejszym artykule proponujemy dwa proste programy nauczania oparte na wyszukiwaniu i porządkowanie wielojęzycznych danych szkoleniowych, które pomagają poprawić wydajność tłumaczenia w połączeniu z istniejącymi technikami, takimi jak dostosowanie. Dodatkowo staramy się nauczyć programu nauczania MNMT od podstaw wraz ze szkoleniem systemu tłumaczeń przy użyciu kontekstowych wieloramiennych bandytów. Na zbiorze danych dotyczących tłumaczeń FLORES o niskich zasobach pokazujemy, że te nauczone programy nauczania mogą zapewnić lepsze punkty wyjścia do dostrojenia i poprawy ogólnej wydajności systemu tłumaczeń.', 'ro': 'Traducerea automată neurală multilingvă cu resurse scăzute (MNMT) are de obicei sarcina de a îmbunătăți performanța traducerii pe una sau mai multe perechi de limbi cu ajutorul perechilor de limbi cu resurse ridicate. În această lucrare și propunem două programe simple bazate pe căutare - ordonarea datelor de formare multilingvă - care ajută la îmbunătățirea performanței traducerii în combinație cu tehnicile existente, cum ar fi reglarea fină. În plus, încercăm să învățăm un curriculum pentru MNMT de la zero împreună cu instruirea sistemului de traducere folosind bandiți contextuali multi-braț. Aratăm pe setul de date FLORES cu resurse reduse de traducere că aceste curricula învățate pot oferi puncte de plecare mai bune pentru reglarea fină și îmbunătățirea performanței generale a sistemului de traducere.', 'kk': 'Төменгі ресурстар көптеген невралдық машинаның аударуы (MNMT) әдетте бір не бірнеше тіл жиілігін бір не бірнеше тіл жиілігін жақсарту үшін көмектеседі. Бұл қағазда екі қарапайым іздеу бағдарламасын - көптілік оқыту деректерінің реттері - бұл аудармалардың әдістерін жақсартуға көмектеседі, мысалы, қарапайым түрлендіру техникаларымен бірг Қосымша, біз MNMT бағдарламасын бірге аудару жүйесінің бақылау бағдарламасын оқытуға тырыстық. Біз FLORES ресурстардың төмен аудармалардың деректерін көрсетедік. Бұл оқылған бағдарламалар дұрыс баптау мен аудармалар жүйесінің жалпы істеу үшін жақсы бастау нүктелерін бере алады.', 'ms': 'Terjemahan Mesin Neural Berbahasa Berbahasa rendah (MNMT) biasanya ditugaskan untuk meningkatkan prestasi terjemahan pada satu atau lebih pasangan bahasa dengan bantuan pasangan bahasa-sumber tinggi. Dalam kertas ini dan kami cadangkan dua kurikulum yang berdasarkan pencarian sederhana - perintah data latihan berbilang bahasa - yang membantu memperbaiki prestasi terjemahan bersama dengan teknik yang wujud seperti penyesuaian. Lagipun dan kami cuba untuk belajar kurikulum untuk MNMT dari awal bersama dengan latihan sistem terjemahan menggunakan bandit berbilang lengan kontekstual. Kita tunjukkan pada set data terjemahan-sumber rendah FLORES bahawa kurikulum belajar ini boleh menyediakan titik permulaan yang lebih baik untuk penyesuaian dan meningkatkan prestasi keseluruhan sistem terjemahan.', 'si': 'ගොඩක් භාෂාවක් න්\u200dයූරල් මේෂින් භාෂාව (MNMT) සාමාන්\u200dය විශ්වාසයෙන් භාෂාව සඳහා භාෂාව සඳහා භාෂාව ප්\u200dරශ්නය වැඩ මේ පත්තරේ අපි සාමාන්\u200dය පරීක්ෂණය අධික පරීක්ෂණය දෙකක් ප්\u200dරයෝජනය කරනවා - බොහොම භාෂාවක් ප්\u200dරීක්ෂණය දත්තේ අණිවිධානය - ඒ අනුවෙන් අපි MNMT වෙනුවෙන් ඉගෙනගන්න උත්සාහ කරනවා සම්බන්ධයෙන් වාර්තාව පද්ධතියේ පද්ධතියේ ප්\u200dරශ්නයක් සමග විශ්වාස කරන අපි FLORES අඩු සම්බන්ධ පරිවර්තන දත්ත සූදානයට පෙන්වන්න පුළුවන් විදියට මේ ඉගෙන ගත්ත ප්\u200dරධාන පද්ධතියේ හොඳ පටන්', 'so': 'Turjumista luuqadaha hoose-resource Multiluqada Neural Machine (MNMT) waa sida caadiga ah in lagu hagaajiyo fasaxa turjumaadda oo ku qoran isku ama ka badan luqad labo with the help of labada luqada sare resource. Qoraalkan waxaynu soo jeedaynaa laba waxbarasho oo fudud ah oo ku qoran waxbarashada luuqadaha kala duduwan - kaas oo u caawinaya hagaajinta farsamada turjumidda oo la xiriira teknolojiyo heysta, tusaale ahaan hagaajinta farsamada. Sidoo kale waxaynu isku dayaynaa in aan MNMT waxbarasho ka barto iskuul wadajir ah iyo waxbarashada nidaamka turjumaadda ee ku isticmaalaya bandhigyada xilliga badan. Waxan ka muuqanaynaa macluumaadka tarjumaadda ee FLORES hoos-resource-hoose, in waxbarashadu ay baranayaan waxay heli karaan barta bilowga si wanaagsan u hagaajiya horumarinta iyo horumarinta sameynta nidaamka turjumaadda.', 'ta': 'Low-resource Multilingual Neural Machine Translation (MNMT) is typically tasked with improving the translation performance on one or more language pairs with the aid of high-resource language pairs.  இந்த காகிதத்தில் நாம் இரண்டு சுலபமான தேடல் அடிப்படையில் தேடும் தொழில்நுட்பம் - பல மொழி பயிற்சி தரவுகளின் கட்டளைகள் - இது மொழிபெயர்ப்பு செயல்ப கூடுதலாக நாம் MNMT க்கான ஒரு மார்க்கம் கற்றுக் கொள்ள முயற்சி செய்ய மொழிபெயர்ப்பு அமைப்பின் பயிற்சியை தற்காலிக பல- கைகள் பிணை FLORES குறைந்த மூலத்தை மொழிபெயர்ப்பு தகவல் அமைப்பில் நாம் காட்டுகிறோம் என்றால் இந்த கற்றுக் கொண்டுள்ள துவக்க புள்ளிகளை நன்றாக', 'mt': 'It-Traduzzjoni Multilingwi ta’ Makkinarju Newrali (MNMT) b’riżorsi baxxi tipikament għandha l-kompitu li ttejjeb il-prestazzjoni tat-traduzzjoni fuq pari lingwistiċi wieħed jew aktar bl-għajnuna ta’ pari lingwistiċi b’riżorsi għoljin. F’dan id-dokument u qed nipproponu żewġ kurrikuli sempliċi bbażati fuq it-tiftix - ordnijiet tad-dejta tat-taħriġ multilingwi - li jgħinu jtejbu l-prestazzjoni tat-traduzzjoni flimkien ma’ tekniki eżistenti bħall-aġġustament fin. Barra minn hekk u nippruvaw nitgħallmu kurrikulu għall-MNMT mill-bidu flimkien mat-taħriġ tas-sistema ta’ traduzzjoni bl-użu ta’ bandits kuntestwali b’diversi fergħat. We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.', 'sr': 'Manje resurse Multilingual Neural Machine Translation (MNMT) obično je zadužen za poboljšanje učinka prevođenja na jednom ili više jezičkih parova pomoći visokim resursnim jezičkim parovima. U ovom papiru predlažemo dve jednostavne programe za potragu - naređenje multijezičkih podataka za obuku - koje pomažu da poboljšavaju provedbu prevođenja zajedno sa postojećim tehnikama kao što su fino prilagođenje. Osim toga, pokušavamo naučiti program za MNMT iz ogrebotine zajedno sa obukom sustava prevođenja koristeći kontekstualne višestruke bandite. Pokazali smo na setu podataka o prevođenju niskih resursa FLORES-a da ova naučena nastavnica može pružiti bolje početne tačke za fino podešavanje i poboljšavanje ukupnog provedbe prevođenog sistema.', 'sv': 'Multilingual Neural Machine Translation (MNMT) har vanligtvis till uppgift att förbättra översättningens prestanda på ett eller flera språkpar med hjälp av språkpar med hög resurs. I den här uppsatsen föreslår vi två enkla sökbaserade läroplaner – beställningar av flerspråkiga utbildningsdata – som bidrar till att förbättra översättningsresultaten tillsammans med befintliga tekniker som finjustering. Dessutom försöker vi lära oss en läroplan för MNMT från grunden tillsammans med utbildningen av översättningssystemet med hjälp av kontextuella multiarms banditer. Vi visar på FLORES lågresurs översättningsdata att dessa lärda läroplaner kan ge bättre utgångspunkter för finjustering och förbättra översättningssystemets övergripande prestanda.', 'ur': 'کم-resource Multilingual Neural Machine Translation اس کاغذ میں اور ہم دو سادھے جستجوں کی بنیادی کوریکیکول کی پیشنهاد کرتے ہیں - ملتی زبان ترینینینینگ ڈیٹے کی آرزوؤں - جو موجود تکنیکوں کے ساتھ ترانینینگ کی فعالیت کو بہتر کرتی ہیں جیسے ٹھیک ترینینگ. اور ہم MNMT کے لئے ایک curriculum سکونت کرنے کی کوشش کرتے ہیں کہ متوسط multi arm bandits کے مطابق ترجمہ سیسٹم کی تعلیم کے ساتھ ملے۔ ہم FLORES کم سروسیز ترجمہ ڈیٹ سٹ پر نشان دیتے ہیں کہ یہ سیکھا گیا کرریکولا بہتر شروع پوینٹ کے لئے بہتر شروع پوینٹ دے سکتا ہے اور ترجمہ سیسٹم کی عملکرد کو بہتر کر سکتا ہے.', 'uz': "Name Bu qogʻozda biz ikkita oddiy qidirish asosida qidirish vositalarini rivojlanamiz - bir necha tillar taʼminlovchi maʼlumotlar tarjimasini bajarish imkoniyatini yordam beradi. Bu juda yaxshi bog'liq texnologiya bilan tarjima qilish imkoniyatini oshirish mumkin. Ko'p paytda, biz MNMT uchun o'rganishni bir necha qo'llangan tarjima tizim bilan bir tarjima tizim tizimini birlashtirishdan foydalanishga harakat qilamiz. Biz FLORES kamaytirish tarjima maʼlumotlarini koʻrsatimiz. Bu o'rganish maktablarni yaxshi ishga tushirish mumkin va tarjima tizimning hammasini bajarishini bajarishi mumkin.", 'vi': 'Chế độ dịch lắp đa ngôn ngữ thần kinh thấp (MPT) thường có nhiệm vụ cải thiện hiệu suất dịch cho một hay nhiều cặp ngôn ngữ với sự trợ giúp của các cặp ngôn ngữ cao cấp. Trong tờ giấy này, chúng tôi đề xuất hai chương trình đơn giản dựa trên việc tìm kiếm về các dữ liệu đào tạo đa dạng, giúp cải thiện kinh nghiệm dịch, cùng với các kỹ thuật đã có, như là độ cẩn thận. Hơn nữa, chúng tôi cố gắng học một chương trình cho MPT từ sạch, cùng với huấn luyện dịch thuật, sử dụng các vũ khí đa tay. Chúng tôi cho thấy trên tập tin dịch biến chất thấp ở FROMES rằng những chương trình học tập này có thể cung cấp điểm khởi đầu tốt hơn cho việc chỉnh sửa cẩn thận và cải thiện khả năng tổng hợp của hệ thống dịch chuyển.', 'bg': 'Многоезичният неврален машинен превод с нисък ресурс обикновено има за задача да подобри ефективността на превода на една или повече езикови двойки с помощта на езикови двойки с висок ресурс. В настоящата статия предлагаме две прости учебни програми, основани на търсене - подреждане на многоезичните данни за обучение - които спомагат за подобряване на ефективността на превода във връзка със съществуващите техники като фина настройка. Освен това се опитваме да научим учебна програма за МНМТ от нулата съвместно с обучението на преводаческата система, използвайки контекстуални многорамкови бандити. Показваме на базата данни за превод с ниски ресурси, че тези учебни програми могат да осигурят по-добри отправни точки за фина настройка и подобряване на цялостната ефективност на преводната система.', 'da': 'Multilingual Neural Machine Translation (MNMT) har typisk til opgave at forbedre oversættelseseffektiviteten på et eller flere sprogpar ved hjælp af højt ressourcebesparende sprogpar. I denne artikel foreslår vi to enkle søgebaserede læseplaner - bestilling af flersprogede uddannelsesdata - som bidrager til at forbedre oversættelsesevnen sammen med eksisterende teknikker såsom finjustering. Derudover forsøger vi at lære en læseplan for MNMT fra bunden sammen med uddannelsen af oversættelsessystemet ved hjælp af kontekstuelle multi-arm banditter. Vi viser på FLORES-datasættet med lav ressource oversættelse, at disse lærte læseplaner kan give bedre udgangspunkt for finjustering og forbedre oversættelsessystemets overordnede ydeevne.', 'nl': 'Multilingual Neural Machine Translation (MNMT) is meestal belast met het verbeteren van de vertaalprestaties op een of meer taalparen met behulp van taalparen met hoge resources. In dit artikel stellen we twee eenvoudige zoekgestuurde curricula voor die meertalige opleidingsgegevens kunnen ordenen die helpen de vertaalprestaties te verbeteren in combinatie met bestaande technieken zoals fine-tuning. Daarnaast proberen we een curriculum voor MNMT vanaf nul te leren samen met de training van het vertaalsysteem met behulp van contextuele multi-arm bandieten. Op de FLORES low-resource vertaaldataset laten we zien dat deze geleerde curricula betere uitgangspunten kunnen bieden voor finetuning en verbetering van de algehele prestaties van het vertaalsysteem.', 'de': 'Multilingual Neural Machine Translation (MNMT) ist in der Regel mit der Verbesserung der Übersetzungsleistung für ein oder mehrere Sprachpaare mit Hilfe von ressourcenintensiven Sprachpaaren beauftragt. In diesem Beitrag schlagen wir zwei einfache suchbasierte Curricula vor, die die mehrsprachigen Trainingsdaten geordnet haben, um die Übersetzungsleistung in Verbindung mit bestehenden Techniken wie Feinabstimmung zu verbessern. Zusätzlich versuchen wir, gemeinsam mit der Schulung des Übersetzungssystems mit kontextuellen Mehrarmbanditen einen Lehrplan für MNMT von Grund auf zu erlernen. Wir zeigen auf dem FLORES ressourcenarmen Übersetzungsdatensatz, dass diese erlernten Lehrpläne bessere Ansatzpunkte für die Feinabstimmung und Verbesserung der Gesamtleistung des Übersetzungssystems bieten können.', 'hr': 'Manje resurse multijezički Neuralni prevod uređaja (MNMT) obično je zadužen za poboljšanje učinka prevoda na jednom ili više jezičkih parova s pomoć višeresursnih jezičkih parova. U ovom papiru i predlažemo dvije jednostavne nastave temeljne na potrazi - naređenje podataka o multijezičkoj obuci - koje pomažu poboljšati učinkovitost prevoda zajedno s postojećim tehnikama kao što su fino navedeni. Osim toga, pokušavamo naučiti program za MNMT iz ogrebotine zajedno s obukom sustava prevoda koristeći kontekstualne višestruke grupe. Mi pokazujemo na kompletu podataka o prevodu s niskim resursima FLORES-a da te naučene nastave mogu pružiti bolje početne tačke za fino navedenje i poboljšati ukupnu provedbu prevodnog sustava.', 'fa': 'ترجمه ماشین\u200cهای عصبی (MNMT) کم منابع است که معمولاً با improving the translation performance on one or more languages with the help of high-resource language pairs. در این کاغذ و ما دو تا برنامه\u200cهای جستجوی ساده را پیشنهاد می\u200cکنیم - دستورات داده\u200cهای آموزش زیادی زبان - که کمک می\u200cکنند عملکرد ترجمه را در ارتباط با تکنیک\u200cهای موجود مانند تغییر\u200cسازی کند. و ما سعی می کنیم برنامه آموزشی برای MNMT یاد بگیریم که با آموزشی سیستم ترجمه با استفاده از باندهای زیادی دستگاهی متفاوت همراه با آموزشی سیستم ترجمه را یاد بگیریم. ما در مجموعه داده\u200cهای ترجمه\u200cهای کم منابع FLORES نشان می\u200cدهیم که این برنامه\u200cهای آموزش یاد گرفته می\u200cتوانند نقطه\u200cهای شروع بهتر برای ترجمه\u200cهای خوب و عملکرد عمومی سیستم ترجمه را بهتر دهند.', 'sw': 'Tafsiri ya Mashine ya Kifaragha (MNMT) kwa kawaida inafanya kazi kwa kuboresha ufafanuzi wa tafsiri kwa wanandoa wa lugha moja au zaidi kwa msaada wa wanandoa wa lugha za juu. Katika karatasi hii na tunapendekeza masomo mawili rahisi yenye utafutaji - amri za mafunzo ya data za lugha mbalimbali - ambayo inasaidia kuboresha ufanisi wa tafsiri kwa ushirikiano na mbinu zilizopo kama vile mafunzo mazuri. Zaidi ya hayo na tunajaribu kujifunza somo la MNMT kutokana na kutangaza kwa pamoja na mafunzo ya mfumo wa tafsiri kwa kutumia bandi za mikono mbalimbali. Tunaonyesha kwenye taarifa za tafsiri za rasilimali za chini za FLORES kwamba lugha hizi zilizojifunza zinaweza kutoa pointi bora za kuanza kwa ajili ya mafunzo mazuri na kuboresha utendaji wa mfumo wa tafsiri kwa ujumla.', 'ko': '저자원 다언어 신경기계번역(MNMT)의 임무는 보통 고자원 언어 쌍의 도움 아래 한 개 이상의 언어 쌍의 번역 성능을 향상시키는 것이다.본고에서 우리는 검색 기반의 두 가지 간단한 과정인 다중 언어 교육 데이터의 순서를 제시했는데 이것은 기존의 기술(예를 들어 마이크로스피커)을 결합시켜 번역 성능을 향상시키는 데 도움이 된다.그 밖에 우리는 0부터 MNMT 과정을 배우고 언어 환경의 도둑을 이용한 번역 시스템 교육을 결합해 보았다.FLORES 저자원 번역 데이터 세트에 표시된 이 학습 과정은 미세 조정에 더 좋은 출발점을 제공하고 번역 시스템의 전체 성능을 향상시킬 수 있습니다.', 'tr': 'Aýak-ressurs Çoklu dilli Näral Maşynyň terjimeleri (MNMT) adatça bir-da birnäçe dil çiftlerde terjime etmek üçin täsirlenýär. Bu kagyzda we biz iki basit gözleme tabanly ders taýýarlamalaryny teklip edýäris - köp dilli eğitim maglumatynyň düzenlemekleri - bu şekilde bolan meýdança tekniklerle birlikde terjime etmek üçin kömekleyär. Ayrıca MNMT üçin çizgisini birleştirmek üçin terjime sistemini örenmek üçin synanyşýarys. Biz FLORES kaynakly çevirim maglumatynda bu öwrenmeli programler gowy başlangyç noktalaryny gowy düzenlemek we terjime sisteminiň ähli netijesini gowylaşdyryp biljekdigini görkeýäris.', 'sq': 'MNMT është tipikisht i ngarkuar me përmirësimin e performancës së përkthimit në një apo më shumë çifte gjuhësh me ndihmën e çifteve gjuhësh me burime të larta. Në këtë letër dhe ne propozojmë dy kurikula të thjeshta të bazuara në kërkim - porositë e të dhënave të treinimit shumëgjuhësor - që ndihmojnë përmirësimin e performancës së përkthimit në lidhje me teknikat ekzistuese të tilla si rregullimi. Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits.  Ne tregojmë në grupin e të dhënave FLORES për përkthimin me burime të ulta se këto programe mësuese mund të ofrojnë pika fillimi më të mira për rregullimin e mirë dhe përmirësimin e performancës së përgjithshme të sistemit të përkthimit.', 'am': 'ከታች-resource Multilingual Neural Machine translation (MNMT) is typically employed with improving the translation performance on one or more language pairs with the help of high-resource language pairs. በዚህ ፕሮግራም እና ሁለትን ቀላል የመረጃ ትምህርት - የብዙ ቋንቋ-ቋንቋዎች ማህበረሰብ ዳርቻ - በተገኘው ተርጓሚን ትርጓሜ እንዲያሳድግ የሚችል ጥያቄዎችን በመስጠት ይረዳል፡፡ በተጨማሪም እና ለMNMT መምህርት ትርጓሜ ሲስተማርን በተቀናቀለ ብዙዎች-ክንድ bandits በመጠቀም ለመግለጽ እናስፈልጋለን፡፡ We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.', 'af': "Lae- hulpbron Veelvuldige Neurale Masjien Vertaling (MNMT) is tipies opgestel met die verbetering van die vertaling van die oorsetting op een of meer taal pare met die hulp van hoë- hulpbron taal pare. In hierdie papier en ons voorstel twee eenvoudige soektog gebaseerde program - ordeninge van die multilinglike onderwerking data - wat help verbeter vertaling effektuur in saam met bestaande teknike soos fine-tuning. Ons probeer ook om 'n program vir MNMT te leer vanaf die opleiding van die vertaling stelsel saam met die onderwerp van die vertaling stelsel te gebruik met contextual multi arm bandits. Ons wys op die FLORES lae-hulpbron vertaling datastel dat hierdie geleerde program beter begin punte kan verskaf vir fyn tuning en verbeter die hele prestasie van die vertaling stelsel.", 'id': 'Sumber daya rendah Multilingual Neural Machine Translation (MNMT) biasanya ditugaskan untuk meningkatkan prestasi terjemahan pada satu atau lebih pasangan bahasa dengan bantuan pasangan bahasa sumber daya tinggi. Dalam kertas ini dan kami mengusulkan dua kurikulum sederhana berdasarkan pencarian - perintah data pelatihan berbagai bahasa - yang membantu meningkatkan prestasi terjemahan bersama dengan teknik yang ada seperti penyesuaian. Selain itu dan kita mencoba untuk belajar kurikulum untuk MNMT dari nol bersama dengan latihan sistem terjemahan menggunakan bandit multilengan kontekstual. We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.', 'bn': 'নিম্নলিখিত মাল্টিভাষার নিউরেল মেশিন অনুবাদ (এমএমটি) সাধারণত ভাষায় অনুবাদ প্রদর্শন করা হয়েছে উচ্চ সম্পদের ভাষার জোড়ার সাহায্যে অনুবাদের সাহ এই কাগজটিতে আমরা দুই সাধারণ অনুসন্ধানের ভিত্তিক কার্চুলা প্রস্তাব করি- বহুভাষী প্রশিক্ষণের তথ্যের নির্দেশ - যা বিদ্যমান প্রযুক্তির স এছাড়াও আমরা এমএমটির জন্য একটি কার্কুল শিখতে চেষ্টা করছি যেখানে আমরা অনুবাদ সিস্টেমের প্রশিক্ষণের সাথে যুক্ত থেকে একাত্রে শিখতে পারি য আমরা ফ্লোরেস-এর নীচের সম্পদ অনুবাদের তথ্যের সাথে দেখাচ্ছি যে এই শিক্ষিত কার্চুলাগুলো ভালো শুরু করার বিন্দুটি দেখাতে পারে এবং অন', 'hy': 'Նվալ ռեսուրսների բազմալեզու նյարդային մեքենայի թարգմանություն (MNMT) սովորաբար առաջադրանքն է բարելավել մեկ կամ ավելի լեզվի զույգերի թարգմանությունը բարձր ռեսուրսների զույգերի օգնությամբ: Այս թղթի մեջ և մենք առաջարկում ենք երկու պարզ որոնման հիմնված ուսումնական ծրագրեր՝ բազմալեզու ուսումնասիրության տվյալների կարգավորումներ, որոնք օգնում են բարելավել թարգմանման արդյունքը միասին գոյություն ունեցող տեխնիկաների հետ, ինչպիսիք Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits.  Մենք ցույց ենք տալիս Ֆլորեսի ցածր ռեսուրսների թարգմանման տվյալների համակարգում, որ այս սովորված ուսումնական ծրագրերը կարող են ավելի լավ սկզբնական կետեր տալ թարգմանման համակարգի ընդհանուր արդյունավետության բարելավման համար:', 'bs': 'Nisko-resursno multijezičko neurološko prevodenje stroja (MNMT) obično se zadužava za poboljšanje učinka prevoda na jednom ili više jezičkih parova pomoći visokim resursnim jezičkim parovima. U ovom papiru predlažemo dva jednostavna programa za potragu - naređenja multijezičkih podataka za obuku - koja pomaže da poboljšavaju učinkovitost prevođenja zajedno sa postojećim tehnikama kao što su finalizirani. Osim toga, pokušavamo naučiti program za MNMT iz ogrebotine zajedno sa obukom sustava prevoda koristeći kontekstualne višestruke bandite. Mi pokazujemo na setu podataka o prevodu sa niskim resursima FLORES-a da ove naučene nastave mogu pružiti bolje početne tačke za fino naslovanje i poboljšati ukupnu provedbu prevodnog sistema.', 'cs': 'Vícejazyčný neurální strojový překlad s nízkými zdroji (MNMT) je obvykle úkolem zlepšit výkon překladu u jednoho nebo více jazykových párů pomocí jazykových párů s vysokými zdroji. V tomto článku navrhujeme dva jednoduché vyhledávání založené na učebních programech a uspořádání vícejazyčných školeních dat, které pomáhají zlepšit výkon překladu ve spojení se stávajícími technikami, jako je jemné ladění. Kromě toho se snažíme naučit učební osnovy pro MNMT od nuly společně se školením překladatelského systému pomocí kontextových víceramenných banditů. Na datasetu FLORES s nízkými zdroji překladu ukazujeme, že tyto učené osnovy mohou poskytnout lepší výchozí body pro jemné ladění a zlepšení celkové výkonnosti překladatelského systému.', 'ca': "La traducció multilingüe de màquines neuronals de baix recursos (MNMT) té la tasca de millorar el rendiment de la traducció en un o més parells de llenguatges amb l'ajuda de parells de llenguatges d'alts recursos. En aquest paper i proposem dos programes simples basats en la recerca - ordres de dades multilingües d'entrenament - que ajuden a millorar el rendiment de la traducció en conjunt amb tècniques existents com l'ajustament. Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits.  We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.", 'et': 'Vähese ressursiga mitmekeelse neuraalse masintõlke (MNMT) ülesanne on tavaliselt parandada tõlketõhusust ühe või mitme keelepaari puhul suure ressursiga keelepaaride abil. Käesolevas dokumendis pakume välja kaks lihtsat otsingupõhist õppekava - mitmekeelsete koolitusandmete tellimine -, mis aitavad parandada tõlketõhusust koos olemasolevate meetoditega, nagu peenhäälestus. Lisaks püüame õppida MNMT õppekava nullist koos tõlkesüsteemi koolitusega, kasutades kontekstuaalseid mitme käega bandiite. Näitame FLORES-i vähese ressursiga tõlkeandmete kogumist, et need õppekavad võivad pakkuda paremaid lähtepunkte tõlkesüsteemi täpsustamiseks ja parandada üldist tulemuslikkust.', 'fi': 'Vähävaraisen monikielisen neurokonekäännöksen (MNMT) tehtävänä on yleensä parantaa käännöksen suorituskykyä yhdellä tai useammalla kieliparilla korkean resurssin kieliparien avulla. Tässä asiakirjassa ehdotamme kahta yksinkertaista hakuun perustuvaa opetussuunnitelmaa - monikielisten koulutustietojen tilaamista - jotka auttavat parantamaan käännösten suorituskykyä nykyisten tekniikoiden, kuten hienosäätöjen, avulla. Lisäksi pyrimme oppimaan MNMT:n opetussuunnitelmaa tyhjästä yhdessä käännösjärjestelmän koulutuksen kanssa kontekstuaalisten monikäsirosvojen avulla. FLORES-käännöstietojen avulla osoitamme, että nämä opitut opetussuunnitelmat voivat tarjota parempia lähtökohtia käännösjärjestelmän hienosäätöön ja parantaa käännösjärjestelmän yleistä suorituskykyä.', 'az': 'Daha düşük çoxlu dil nöral maşın tərcüməsi (MNMT) çoxlu dil cütlərinin köməyi ilə bir ya da çoxlu dil cütlərinin tərcümünü yaxşılaşdırmaq üçün işlədilər. Bu kağızda və biz iki basit arama təhsil edilən təhsil program - çoxlu dil təhsil məlumatlarının əmrini - ki, həmin təhsil təhsil təhsil ilə birlikdə həmin təhsil təhsil təhsil ilə birlikdə təhsil etməyə kömək edir. Biz də MNMT üçün öyrənmək üçün müxtəlif çoxlu kol banditlərini istifadə edən çevirim sisteminin təhsilini birlikdə çəkməyə çalışırıq. FLORES düşük ressurs tərcümə verilən verilənlərdə göstəririk ki, bu öyrənmiş öyrənmiş öyrənmək programların daha yaxşı başlangıç noktalarını düzgün tərcümə etmək və tərcümə sisteminin bütün performansını daha yaxşılaşdıra bilər.', 'jv': 'item-set Nang pepulan iki lan nambah dhéwé ngerasah basa perusahaan sing sumulatan karo perusahaan langkung sampeyan - supoyo data yang pisan bantuan- sing bantuan njaluk bantuan kanggo ngerasah tarjamahan karo teknik sing sampeyan, koyo ngono nggawe gerakan. Mungkin daftar karo kita saiki nggambar aturan kanggo ngilangno MNMT sampeyan ngulinakake tarjamahan karo sistem itoleng nggawe barang multi-manut. FLORES mengko dataset sing paling kelas nang dibutuhke tarjamahan punika ingkang dibutuhke punika sing luwih apik lan basa sing dibutuhke sistem itolekake.', 'ha': '@ action: button Ga wannan takardan, kuma tuna goyyade karãtun karatun biyu masu sauƙi na search - an umurce wa data na tsarin multilala - wanda ke ƙarfafa mafarin fassarar da fassarar cikin haɗi da takayaikin masu jira kamar tuning. Ƙaramiwa, kuma munã jarraba karantar na MNMT don a samu da shirin taƙaita na fassarar tarjima da amfani da banditti masu hushi. Kana nuna kan data na fassarar-resource na FLUERS na ƙarƙashin-resource da aka sanar da su yana iya ƙaranci pointi na fara-gabatarwa wa gyarata mai kyau kuma ka kyautata cikakken aikin fassarar.', 'he': 'תורגם וסונכרן ע"י Qsubs מצוות בעיתון הזה ואנחנו מציעים שתי תוכניות לימודים פשוטות מבוססת חיפוש - הזמנות של נתוני האימונים הרב-שפתיים - שמעזרים לשפר את ביצועי התרגום ביחד עם טכניקות קיימות כמו התרגיל. בנוסף, אנו מנסים ללמוד תוכנית לימודים של MNMT מאפס ביחד עם האימון של מערכת התרגום באמצעות שודדים קונטקסטיים multi-arm. אנחנו מראים על קבוצת נתונים של תורגם מתרגמים נמוכים של FLORES כי תוכניות הלימודים הללו יכולות לספק נקודות התחלה טובות יותר להתאים ומשתפר ביצועים כלליים של מערכת התרגום.', 'sk': 'Naloga večjezičnega nevralnega strojnega prevajanja z nizkimi viri (MNMT) je izboljšanje učinkovitosti prevajanja enega ali več jezikovnih parov s pomočjo jezikovnih parov z visokimi viri. V tem prispevku predlagamo dva preprosta učna načrta, ki temeljita na iskanju - naročanje podatkov o večjezičnem usposabljanju -, ki pomagata izboljšati učinkovitost prevajanja v povezavi z obstoječimi tehnikami, kot je natančno nastavitev. Poleg tega se skušamo učiti učni načrt za MNMT iz nič skupaj z usposabljanjem prevajalskega sistema z uporabo kontekstualnih banditov z več rokami. Na naboru podatkov o prevajanju z nizkimi viri FLORES pokažemo, da lahko ti učni načrti zagotovijo boljše izhodišče za natančno nastavitev in izboljšajo splošno uspešnost prevajalskega sistema.', 'bo': 'རྒྱ་ཆེ་བའི་མང་ཆེ་བའི་སྐད་ཡིག འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྨན་གཞི་འཚོལ་བཤེར་གྱི་ལས་རིམ་གཉིས་སྤྲོད་ཀྱི་ཡོད། Additionally and we attempt to learn a curriculum for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits. ང་ཚོས་FLORES དང་རྫུན་ཆུང་བའི་ཡིག་ཆ་ལ་སྒྲིག'}
{'en': 'Transformers for Low-Resource Languages : Is Fidir Linn !', 'es': 'Transformers para lenguajes de bajos recursos: ¡Es Fëidir Linn!', 'ar': 'محولات للغات منخفضة الموارد: هل Fëidir Linn!', 'fr': "Transformers pour les langues à faibles ressources\xa0: c'est Fëidir Linn\xa0!", 'pt': 'Transformers para linguagens de poucos recursos: é Fëidir Linn!', 'ja': '低資源言語のトランスフォーマー： Fëidir Linnです！', 'ru': 'Трансформаторы для языков с низким уровнем ресурсов: это Fëidir Linn!', 'zh': '低资源言变形金刚:费迪尔·林恩乎!', 'hi': 'कम संसाधन भाषाओं के लिए ट्रांसफॉर्मर: Fëidir Linn है!', 'ga': 'Claochladáin do Theangacha Ísealcmhainne: Is Féidir Linn!', 'ka': 'Name', 'hu': 'Transformers for Low Resource Languages: Feidir Linn!', 'el': 'Μεταμορφωτές για γλώσσες χαμηλής περιεκτικότητας σε πόρους: Είναι ο Feidir Linn!', 'it': 'Trasformatori per lingue a basso contenuto di risorse: è Feidir Linn!', 'kk': 'Төменгі ресурс тілдерінің түрлендірушілері: Файдир сызығы!', 'ms': 'Penukar untuk Bahasa Sumber Terrendah: Adakah Feidir Linn!', 'mk': 'Transformers for Low-Resource Languages: Is Feidir Linn!', 'ml': 'കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകങ്ങള്\u200dക്കുള്ള ട്രാന്\u200dസ്ഫോര്\u200dഫര്\u200dമാര്\u200d: ഫെയിഡിര്\u200d ലിന്\u200d!', 'mt': 'Trasformaturi għal Lingwi b’Riżorsi Baxxi: Is Feidir Linn!', 'mn': 'Хоёр бага боловсролын хэл төлөвлөгч: Фэйдир Линн!', 'no': 'Transformerer for låg ressursspråk: Er feidir linje!', 'pl': 'Transformatory dla języków niskich zasobów: to Feidir Linn!', 'lt': 'Mažų išteklių kalbų transformatoriai: Is Feidir Linn!', 'sr': 'Transformeri za jezike niskog resursa: je Feidir Linn!', 'ro': 'Transformatoare pentru limbi cu resurse reduse: este Feidir Linn!', 'si': 'අඩුම සම්බන්ධ භාෂාව සඳහා වෙනස් කරනවා: Feidir Linn!', 'sv': 'Transformers för lågresursspråk: Är Feidir Linn!', 'so': 'Transformers for Low-Resource Languages: Is Feidir Linn!', 'ur': 'نیچے رسورس زبانوں کے لئے تغییر دینے والے: Is Feidir Linn!', 'ta': 'குறைந்த மூலத்தின் மொழிகளுக்கான மொழிமாற்றுபவர்கள்: Feidir Linn உள்ளது!', 'uz': 'Tillar uchun qisqa tarjima qiluvchilar: F ëidir Linn!', 'vi': 'Dịch biến hình cho các ngôn ngữ vùng thấp:', 'hr': 'Transformeri za jezike niskog resursa: je Feidir Linn!', 'bg': 'Трансформатори за нискоресурсни езици: е Фейдир Лин!', 'nl': 'Transformers voor Low Resource Talen: Is Feidir Linn!', 'da': 'Transformere til lav ressource sprog: Er Feidir Linn!', 'id': 'Transformers for Low-Resource Languages: Is Feidir Linn!', 'ko': '저자원 언어의 트랜스포머: 피디어 린입니다!', 'de': 'Transformatoren für ressourcenarme Sprachen: Ist Feidir Linn!', 'fa': 'تغییر دهنده\u200cها برای زبانهای کم منبع: فیدیر لین است!', 'sw': 'Watafsiri kwa lugha za chini za rasilimali: Je, Feidir Linn!', 'am': 'ቋንቋዎች', 'sq': 'Transformers for Low-Resource Languages: Is Feidir Linn!', 'hy': 'Արդյո՞ք Ֆեյդեր Լինը:', 'af': 'Name', 'tr': 'Diller üçin Az-Ressurat Diller: Bu gadyr Lindir!', 'bn': 'নিম্ন রিসোর্স ভাষার জন্য ট্রান্সফার্সার: ফেইডির লিন!', 'az': 'AŇüańüńĪ-Ressours Dill…ôrinin transformat√∂rl…ôri: Feidir Linn!', 'ca': 'Transformers for Low Resource Languages: Is Feidir Linn!', 'cs': 'Transformátory pro jazyky s nízkými zdroji: Je Feidir Linn!', 'bs': 'Transformeri za jezike niskog resursa: je Feidir Linn!', 'et': 'Transformerid vähese ressursiga keeltele: on Feidir Linn!', 'fi': 'Transformers for low-resource languages: Is Feidir Linn!', 'jv': 'undo-type', 'ha': 'KCharselect unicode block name', 'sk': 'Transformerji za jezike z nizkimi viri: Je Feidir Linn!', 'he': 'Transformers for Low-Resource Languages: Is Feidir Linn!', 'bo': 'རྒྱ་ཆེ་བའི་སྐད་ཡིག་ཆ་ལ་ཉུང་བའི་འགྱུར་ཆས་པ། དེ་ནི་ཕྱིར་ཉུང་བའི་གྲལ་ཐིག་ཡིན།'}
{'en': 'The Transformer model is the state-of-the-art in  Machine Translation . However and in general and neural translation models often under perform on language pairs with insufficient training data. As a consequence and relatively few experiments have been carried out using this  architecture  on low-resource language pairs. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly and the correct choice of subword model is shown to be the biggest driver of  translation  performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various  regularization techniques  and evaluating the optimal number of heads for  attention . A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline  RNN model . Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against  Google Translate  and our translation engines demonstrated significant improvements. The question of whether or not  Transformers  can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is fidir linn-yes we can.', 'ar': 'نموذج Transformer هو أحدث ما توصلت إليه الترجمة الآلية. ومع ذلك ، وبشكل عام ، غالبًا ما تكون نماذج الترجمة العصبية أقل أداءً على أزواج لغوية مع بيانات تدريب غير كافية. نتيجة لذلك ، تم إجراء عدد قليل نسبيًا من التجارب باستخدام هذه البنية على أزواج اللغات منخفضة الموارد. في هذه الدراسة ، تم تقييم تحسين المعلمة الفائقة لنماذج المحولات في ترجمة زوج اللغة الإنجليزية الأيرلندية منخفض الموارد. نثبت أن اختيار المعلمات المناسبة يؤدي إلى تحسينات كبيرة في الأداء. والأهم من ذلك ، أن الاختيار الصحيح لنموذج الكلمات الفرعية هو المحرك الأكبر لأداء الترجمة. تم تقييم نماذج SentencePiece باستخدام كل من نهج unigram و BPE. تضمنت الاختلافات في هياكل النماذج تعديل عدد الطبقات واختبار تقنيات التنظيم المختلفة وتقييم العدد الأمثل للرؤساء للاهتمام. تم استخدام مجموعة عامة 55 ألف DGT ومجموعة إداري عام في المجال 88 ألف للتقييم. أظهر النموذج المحسن للمحولات تحسنًا في درجة BLEU بمقدار 7.8 نقطة مقارنة بنموذج RNN الأساسي. تمت ملاحظة التحسينات عبر مجموعة من المقاييس بما في ذلك TER والإشارة إلى جهد التحرير اللاحق المنخفض بشكل كبير للنماذج المحسّنة من Transformer مع نماذج الكلمات الفرعية 16k BPE. تم تقييم الأداء مقابل خدمة الترجمة من Google وأظهرت محركات الترجمة لدينا تحسينات كبيرة. مسألة ما إذا كانت المحولات يمكن أن تكون كذلك أم لا\nتم استخدامها بشكل فعال في بيئة منخفضة الموارد للترجمة الإنجليزية-الأيرلندية. هل فيدير لين - نعم نستطيع.', 'fr': "Le modèle Transformer est le dernier cri en matière de traduction automatique. Cependant et en général, les modèles de traduction neuronale sont souvent sous-performants sur des paires de langues avec des données d'entraînement insuffisantes. Par conséquent, relativement peu d'expériences ont été réalisées à l'aide de cette architecture sur des paires de langues à faibles ressources. Dans cette étude, l'optimisation des hyperparamètres des modèles Transformer dans la traduction de la paire de langues anglais-irlandais à faible ressource est évaluée. Nous démontrons que le choix de paramètres appropriés permet d'améliorer considérablement les performances. Plus important encore, le choix correct du modèle de sous-mots est le principal moteur des performances de traduction. Des modèles SentencePiece utilisant à la fois des approches d'unigramme et de BPE ont été évalués. Les variations des architectures de modèles comprenaient la modification du nombre de couches, le test de diverses techniques de régularisation et l'évaluation du nombre optimal de têtes d'attention. Un corpus DGT générique de 55 000 et un corpus d'administration publique de 88 000 dans le domaine ont été utilisés pour l'évaluation. Un modèle optimisé pour Transformer a démontré une amélioration du score BLEU de 7,8 points par rapport à un modèle RNN de référence. Des améliorations ont été observées pour une gamme de mesures, y compris le TER, indiquant une réduction considérable des efforts de post-édition pour les modèles optimisés par Transformer avec des modèles de sous-mots 16k BPE. Reconnu par rapport à Google Translate et nos moteurs de traduction ont démontré des améliorations significatives. La question de savoir si Transformers peut être\nutilisé efficacement dans un environnement à faibles ressources de traduction anglais-irlandais a été abordé. Est-ce que Fëidir Linn - Oui, nous le pouvons.", 'pt': 'O modelo Transformer é o que há de mais moderno em Tradução Automática. No entanto, e em geral, os modelos de tradução neural geralmente apresentam desempenho inferior em pares de idiomas com dados de treinamento insuficientes. Como consequência e relativamente poucos experimentos foram realizados usando esta arquitetura em pares de linguagem de poucos recursos. Neste estudo, a otimização de hiperparâmetros de modelos Transformer na tradução do par de idiomas inglês-irlandês de poucos recursos é avaliada. Demonstramos que a escolha de parâmetros apropriados leva a melhorias consideráveis de desempenho. O mais importante é que a escolha correta do modelo de subpalavras é o maior impulsionador do desempenho da tradução. Modelos SentencePiece usando abordagens unigram e BPE foram avaliados. Variações nas arquiteturas de modelo incluíam modificar o número de camadas e testar várias técnicas de regularização e avaliar o número ideal de cabeças para atenção. Um corpus genérico de DGT de 55k e um corpus de administração pública de 88k no domínio foram usados para avaliação. Um modelo otimizado para Transformer demonstrou uma melhoria na pontuação BLEU de 7,8 pontos quando comparado com um modelo RNN de linha de base. As melhorias foram observadas em uma variedade de métricas, incluindo TER e indicando um esforço de pós-edição substancialmente reduzido para modelos otimizados para Transformer com modelos de subpalavras de 16k BPE. A comparação com o Google Tradutor e nossos mecanismos de tradução demonstraram melhorias significativas. A questão de saber se os transformadores podem ou não ser\nusado de forma eficaz em um ambiente de poucos recursos de tradução Inglês-Irlandês foi abordado. É fëidir linn - sim, podemos.', 'ja': 'トランスフォーマーモデルは、機械翻訳における最先端のモデルです。 しかしながら、一般的に、および神経翻訳モデルは、トレーニングデータが不十分な言語ペアで実行されることが多い。 そのため、このアーキテクチャを使用した低リソース言語ペアの実験は比較的少なく、ほとんど行われていない。 この研究では、低資源の英語とアイルランド語のペアを翻訳するトランスフォーマーモデルのハイパーパラメータ最適化を評価した。 適切なパラメータを選択することで、パフォーマンスが大幅に向上することを実証しています。 最も重要なことは、サブワードモデルの正しい選択が翻訳パフォーマンスの最大の推進力であることが示されていることです。 UnigramとBPEの両方のアプローチを使用したSentencePieceモデルを評価した。 モデルアーキテクチャのバリエーションには、レイヤーの数を変更し、様々な正規化技術をテストし、注目すべき最適なヘッド数を評価することが含まれていました。 一般的な55,000 DGTコーパスおよびドメイン内の88,000公開管理コーパスを評価に使用した。 トランスフォーマー最適化モデルは、ベースラインRNNモデルと比較した場合、7.8ポイントのBLEUスコア改善を示した。 TERを含む一連の測定基準にわたって改善が観察され、16 k BPEサブワードモデルを有するトランスフォーマー最適化モデルのポストエディットの努力が実質的に低下したことが示された。 Google翻訳にベンチマークを付け、翻訳エンジンが大幅に改善されました。 トランスフォーマーが\n英語-アイルランド語翻訳の低リソース環境で効果的に使用されている。Fëidir linnです-はい、できます。', 'es': 'El modelo Transformer es lo último en traducción automática. Sin embargo, y en general, los modelos de traducción neuronal a menudo tienen un rendimiento deficiente en pares de idiomas con datos de entrenamiento insuficientes Como consecuencia, se han llevado a cabo relativamente pocos experimentos con esta arquitectura en pares de idiomas de bajos recursos. En este estudio se evalúa la optimización hiperparamétrica de los modelos Transformer en la traducción del par de idiomas inglés-irlandés de bajos recursos. Demostramos que la elección de los parámetros adecuados conduce a mejoras considerables en el rendimiento. Lo más importante es que la elección correcta del modelo de subpalabras demuestra ser el principal impulsor del rendimiento de la traducción. Se evaluaron modelos SentencePiece que utilizaban enfoques de unigram y BPE. Las variaciones en las arquitecturas de los modelos incluyeron la modificación del número de capas y la prueba de varias técnicas de regularización y la evaluación del número óptimo de cabezales para la atención. Para la evaluación se utilizó un corpus genérico de 55 000 DGT y un corpus de administración pública en el dominio de 88 000. Un modelo optimizado por Transformer demostró una mejora en la puntuación BLEU de 7,8 puntos en comparación con un modelo RNN de referencia. Se observaron mejoras en una variedad de métricas, incluida la TER, lo que indica un esfuerzo de posedición sustancialmente reducido para los modelos optimizados para Transformer con modelos de subpalabras BPE de 16k. Las comparativas con Google Translate y nuestros motores de traducción demostraron mejoras significativas. La cuestión de si los Transformers pueden o no\nque se utiliza eficazmente en un entorno de pocos recursos de traducción inglés-irlandés. Es fëidir linn, sí podemos.', 'hi': 'ट्रांसफॉर्मर मॉडल मशीन अनुवाद में अत्याधुनिक है। हालांकि और सामान्य रूप से और तंत्रिका अनुवाद मॉडल अक्सर अपर्याप्त प्रशिक्षण डेटा के साथ भाषा जोड़े पर प्रदर्शन करते हैं। नतीजतन और कम संसाधन भाषा जोड़े पर इस वास्तुकला का उपयोग करके अपेक्षाकृत कुछ प्रयोग किए गए हैं। इस अध्ययन में और कम संसाधन अंग्रेजी-आयरिश भाषा जोड़ी का अनुवाद करने में ट्रांसफॉर्मर मॉडल के हाइपरपैरामीटर अनुकूलन का मूल्यांकन किया जाता है। हम प्रदर्शित करते हैं कि उपयुक्त पैरामीटर चुनने से काफी प्रदर्शन सुधार होता है। सबसे महत्वपूर्ण बात यह है कि सबवर्ड मॉडल का सही विकल्प अनुवाद प्रदर्शन का सबसे बड़ा चालक दिखाया गया है। यूनिग्राम और बीपीई दोनों दृष्टिकोणों का उपयोग करके वाक्यपीस मॉडल का मूल्यांकन किया गया था। मॉडल आर्किटेक्चर पर विविधताओं में परतों की संख्या को संशोधित करना और विभिन्न नियमितीकरण तकनीकों का परीक्षण करना और ध्यान देने के लिए सिर की इष्टतम संख्या का मूल्यांकन करना शामिल था। मूल्यांकन के लिए एक सामान्य 55k DGT कॉर्पस और एक इन-डोमेन 88k सार्वजनिक व्यवस्थापक कॉर्पस का उपयोग किया गया था। एक ट्रांसफॉर्मर अनुकूलित मॉडल ने बेसलाइन आरएनएन मॉडल की तुलना में 7.8 अंकों के एक BLEU स्कोर सुधार का प्रदर्शन किया। सुधार मेट्रिक्स की एक श्रृंखला में और टीईआर सहित देखा गया था और 16k BPE subword मॉडल के साथ ट्रांसफॉर्मर अनुकूलित मॉडल के लिए काफी कम पोस्ट संपादन प्रयास का संकेत। Google अनुवाद और हमारे अनुवाद इंजनों के खिलाफ बेंच-चिह्नित ने महत्वपूर्ण सुधारों का प्रदर्शन किया। ट्रांसफॉर्मर हो सकते हैं या नहीं, इस सवाल का\nअंग्रेजी-आयरिश अनुवाद की कम-संसाधन सेटिंग में प्रभावी ढंग से उपयोग किया जाता है, जिसे संबोधित किया गया है। fíidir linn है - हाँ हम कर सकते हैं.', 'ga': 'Is é an tsamhail Transformer an tsamhail is nua-aimseartha san Aistriúchán Meaisín. Mar sin féin agus go ginearálta agus samhlacha néar-aistriúcháin tearcfheidhmíocht go minic ar péirí teanga gan dóthain sonraí oiliúna. Mar thoradh air sin agus is beag turgnamh a rinneadh ag baint úsáide as an ailtireacht seo ar phéirí teangacha íseal-acmhainne. Sa staidéar seo agus déantar measúnú ar bharrfheabhsú hipearpharaiméadair ar mhúnlaí Transformer in aistriúchán an phéire Béarla-Gaeilge ar acmhainní íseal. Léirímid go dtiocfaidh feabhsuithe suntasacha ar fheidhmíocht as paraiméadair chuí a roghnú. Is é an rud is tábhachtaí ná sin agus taispeántar gurb é an rogha cheart de mhúnla fofhocail an príomhspreagthóir ar fheidhmíocht aistriúcháin. Rinneadh measúnú ar mhúnlaí SentencePiece ag úsáid cur chuige unigram agus BPE araon. I measc na n-athruithe ar ailtireachtaí samhlacha bhí mionathrú ar líon na sraitheanna agus tástáil a dhéanamh ar theicníochtaí éagsúla um rialáil agus luacháil a dhéanamh ar an líon barrmhaith cinn le haghaidh aird. Baineadh úsáid as corpas cineálach 55k DGT agus as corpas riaracháin poiblí 88k san fhearann le haghaidh meastóireachta. Léirigh samhail optamaithe Transformer feabhas scór BLEU de 7.8 pointe i gcomparáid le samhail bunlíne RNN. Breathnaíodh feabhsuithe thar raon méadrachta lena n-áirítear TER agus a léirigh iarracht iar-eagarthóireachta laghdaithe go mór do mhúnlaí optamaithe Transformer le samhlacha fo-focail 16k BPE. Tagarmharcáil in aghaidh Google Translate agus léirigh ár n-innill aistriúcháin feabhsuithe suntasacha. An cheist an féidir nó nach bhfuil Claochladáin\na úsáid go héifeachtach i suíomh acmhainní íseal d’aistriúchán Béarla-Gaeilge. Is fëidir linn - yes we can.', 'zh': 'Transformer 模者,机器翻译之先进也。 然大抵神经译模常于训练不足之言为不佳。 故低资源言用此架构者实验少。 本研低资源英语-爱尔兰语译变形金刚模形超参数优化超参数优化。 吾证择参数可以显能。 至重,正选子词模形证译性之大驱动力。 评用unigram、BPE法句。 模架构之变,包改层数、测试诸正则化术,及评估最佳头数以供意。 用通用 55k DGT 语料库及域内 88k 公共管语料库评估。 比于基线RNN,Transformer优化其得分益7.8分,BLEU。 TER 在内者指标察于改进,明于有 16k BPE 子词之 Transformer 优化,译后辑事著减也。 比谷歌译与我引擎,我得大进。 变形金刚能否\n资源匮乏英语-爱尔兰语译者已决。 fëidir linn - 也,可也。', 'ru': 'Модель трансформатора является самой современной в области машинного перевода. Однако и в целом модели нейронного перевода часто выполняются на языковых парах с недостаточными обучающими данными. Вследствие этого было проведено относительно мало экспериментов с использованием этой архитектуры на малоресурсных языковых парах. В данном исследовании и оптимизации гиперпараметров Трансформаторных моделей при переводе малоресурсной английско-ирландской языковой пары оценивается. Мы демонстрируем, что выбор подходящих параметров приводит к значительному улучшению производительности. Самое главное, и правильный выбор модели подслова показан как самый большой драйвер производительности перевода. Были оценены модели SentencePiece с использованием подходов unigram и BPE. Различия в архитектурах моделей включали изменение количества слоев и тестирование различных методов регуляризации, а также оценку оптимального количества головок, требующих внимания. Для оценки использовали дженерик 55k DGT corpus и внутридоменный 88k public admin corpus. Оптимизированная модель трансформатора продемонстрировала улучшение оценки BLEU на 7,8 пункта по сравнению с базовой моделью RNN. Улучшения наблюдались по целому ряду показателей, включая ТЭО, что свидетельствует о существенном сокращении усилий по пост-редактированию оптимизированных для трансформатора моделей с 16-километровыми подсловами BPE. Сравнение с Google Translate и нашими системами перевода продемонстрировало значительные улучшения. Вопрос о том, могут ли Трансформаторы быть\nэффективно используемые в условиях ограниченности ресурсов при переводе на английский и ирландский языки. Является ли fëidir linn - да, мы можем.', 'ka': 'ტრანფორმენტერის მოდელი არის მაქინის გასაგრძელებაში სიცოცხლე. მაგრამ და ყველაფერი და ნეიროლური შეცვლის მოდელები ზოგიერთად მუშაობით ენის ზოგებით, რომლებიც უფრო მსგავსი შეცვლის მონაცემები. როგორც შედეგი და relatively few ექსპერიმენტები გამოყენებულია ამ არქტიქტურის გამოყენებით მარტივი რესურსისურსის ზოგებით. ამ სწავლებში და ჰიპეროპარამეტრებში ტრანფორმეტრის მოდელეების ოპტიმიზაცია ინგლისური-ინერიული ენის ზოგის გადაწყვებაში. ჩვენ გამოჩვენებთ, რომ შესაძლებელი პარამეტრების ამოირჩევა მნიშვნელოვანი პროგრამეტრების შესაძლებელობას. ყველაზე მნიშვნელოვანი და სუბსიტყვანის მოდელის მარტივი არჩევა ჩვენებულია, რომ უფრო დიდი მოწყობილობის მოწყობილობა. Comment მოდელური არქტიქტურების განცვლები შეიყვანეთ სინამდვილეების რაოდენობა და განსხვავებული რეგილარიზაციის ტექნოგიების შეცვლა და დაახლოებისთვის ოპტიმალური რიცხვი 55k DGT კორპუსი და 88k ადამიანის ადამიანის კორპუსი გამოყენებულია. Name მეტრიკის განსაზღვრებით დაახლოებია, რომლებიც TER-ის განსაზღვრებით და დაახლოებით ძალიან შემცირებული პოსტის რედაქტირების ძალადობა განსაზღვრებისთვის აპტიმიზებული მოდელების 16k BPE სუბსი Name კითხვა თუ არა ტრანფორმენტებერი შეიძლება\nეფექტიურად გამოყენებული ინგლისური-ინერიული თარგმუშაობის ცვლილებაში. - ეა, მჲზვმ.', 'kk': 'Түрлендіру үлгісі - машина аудармасындағы суреттің күйі. Бірақ, жалпы және невралды аудару үлгілері көбінде тіл екеуінде жеткілікті оқыту деректері бар. Бұл архитектура көп ресурс тілдерінің екеуіне арналған және сәйкес кейбір тәжірибелер жасалған. Бұл зерттеу мен гиперпараметрлерде түрлендіруші үлгілерінің оптимизациясы ағылшын- ирландық тілдің екісін төмен ресурстарды аудару үшін бағалады. Біз дұрыс параметрлерді таңдау үшін маңызды істеу жақсартылығын көрсетеді. Ең маңызды және ішкі сөз үлгісінің дұрыс таңдау - аудармалардың ең үлкен драйвері деп көрсетіледі. Сөздігі Үлгі архитектуралардың өзгерістері қабаттардың санын өзгерту және әртүрлі түрлі түрлі түрлі түрлендіру техникаларын тексеру және бақылау үшін оқиғалардың оқиғаларының 55k DGT корпус және 88k администратор корпус оқу үшін қолданылды. Түрлендіруші оптимизацияланған үлгісі, RNN үлгісімен салыстырғанда, 7, 8 нүкте BLEU нүктесін жақсарту дегенді көрсетті. Бірнеше метрикалық аралығында жақсартулар қаралған және TER және 16k BPE ішкі сөздер үлгілерімен транформациялау үлгілерінің өзгерту жұмысын көрсетеді. Google Translate және аудармалы тетіктерімізге қарсы белгіленген белгілер үлкен жақсартуларды көрсетті. Түрлендірушілер болуы мүмкін емес пе деген сұрақ\nағылшын- Ирландиялық аудармасының төмен ресурстар баптауында қолданылады. Файдир Линн - да.', 'it': "Il modello Transformer è lo stato dell'arte nella traduzione automatica. Tuttavia, e in generale, i modelli di traduzione neurale spesso sotto funzionano su coppie linguistiche con dati di formazione insufficienti. Di conseguenza, relativamente pochi esperimenti sono stati effettuati utilizzando questa architettura su coppie linguistiche a basso contenuto di risorse. In questo studio viene valutata l'ottimizzazione iperparametrica dei modelli Transformer nella traduzione della coppia inglese-irlandese a basso contenuto di risorse. Dimostriamo che la scelta di parametri appropriati porta a notevoli miglioramenti delle prestazioni. La cosa più importante e la scelta corretta del modello di sottoparola è dimostrato essere il più grande driver delle prestazioni di traduzione. Sono stati valutati i modelli SentencePiece che utilizzano approcci unigram e BPE. Variazioni sulle architetture dei modelli includevano la modifica del numero di strati e la sperimentazione di varie tecniche di regolarizzazione e la valutazione del numero ottimale di teste per l'attenzione. Per la valutazione sono stati utilizzati un corpus generico DGT 55k e un corpus amministrativo pubblico 88k nel dominio. Un modello ottimizzato per Transformer ha dimostrato un miglioramento del punteggio BLEU di 7,8 punti rispetto a un modello RNN basale. Sono stati osservati miglioramenti in una gamma di metriche, tra cui TER, che indicano una riduzione sostanziale dello sforzo post-editing per i modelli ottimizzati per Transformer con modelli di subword 16k BPE. Bench-marked contro Google Translate e i nostri motori di traduzione hanno dimostrato miglioramenti significativi. La domanda se i Transformers possono essere\nÈ stato affrontato il problema dell'uso efficace in un contesto di traduzione inglese-irlandese a basso contenuto di risorse. È feidir linn - sì che possiamo.", 'hu': 'A Transformer modell a legkorszerűbb gépi fordítás területén. Általánosságban azonban és az idegi fordítási modellek gyakran alul teljesítenek olyan nyelvpárokon, amelyek nem elegendőek a képzési adatok. Ennek következtében viszonylag kevés kísérletet végeztek ennek az architektúrának az alacsony erőforrású nyelvpároknál. Ebben a tanulmányban a Transformer modellek hiperparaméteres optimalizálását értékeljük az alacsony erőforrású angol-ír nyelvpár fordításában. Bemutatjuk, hogy a megfelelő paraméterek kiválasztása jelentős teljesítményfejlesztést eredményez. A legfontosabb, hogy a fordítási teljesítmény legnagyobb hajtóereje az alszó modell helyes kiválasztása. A SentencePiece modelleket unigram és BPE megközelítésekkel egyaránt értékelték. A modellarchitektúrák változásai közé tartoztak a rétegek számának módosítása, a különböző regularizációs technikák tesztelése, valamint a figyelemfelkeltő fejek optimális számának értékelése. Az értékeléshez egy általános 55k DGT korpuszt és egy tartományban lévő 88k nyilvános adminisztrációs korpuszt használtak. Egy Transformer optimalizált modell 7,8 pontos BLEU pontszám javulást mutatott a kiindulási RNN modellhez képest. Javulásokat figyeltek meg számos mutatószámban, beleértve a TER-t is, és jelentősen csökkentett szerkesztési erőfeszítést jeleztek a Transformer optimalizált modellek 16 ezer BPE altword modellekkel. A Google Fordítóval és fordítómotorjainkkal összehasonlítva jelentős fejlődést mutatott. A kérdés, hogy a Transformers lehet-e vagy sem\nAz angol-ír fordítás alacsony erőforrással rendelkező környezetében hatékonyan felhasználható. Feidir Linn - igen, megtehetjük.', 'el': 'Το μοντέλο είναι η τελευταία λέξη της τεχνολογίας στη μηχανική μετάφραση. Ωστόσο και γενικά και τα μοντέλα νευρωνικής μετάφρασης συχνά δεν αποδίδουν σε γλωσσικά ζεύγη με ανεπαρκή εκπαιδευτικά δεδομένα. Ως εκ τούτου και σχετικά λίγα πειράματα έχουν πραγματοποιηθεί χρησιμοποιώντας αυτή την αρχιτεκτονική σε γλωσσικά ζεύγη χαμηλής περιεκτικότητας. Σε αυτή τη μελέτη αξιολογείται η βελτιστοποίηση υπερπαραμέτρων μοντέλων μετασχηματιστή στη μετάφραση του ζεύγους Αγγλικών-Ιρλανδικών γλωσσών χαμηλής περιεκτικότητας. Αποδεικνύουμε ότι η επιλογή κατάλληλων παραμέτρων οδηγεί σε σημαντικές βελτιώσεις απόδοσης. Το πιο σημαντικό και η σωστή επιλογή του μοντέλου υπολέξεων αποδεικνύεται ότι είναι ο μεγαλύτερος οδηγός της απόδοσης της μετάφρασης. Εκτιμήθηκαν μοντέλα που χρησιμοποιούν τόσο την προσέγγιση όσο και την προσέγγιση BPE. Οι παραλλαγές στις αρχιτεκτονικές μοντέλων περιελάμβαναν την τροποποίηση του αριθμού των στρωμάτων και τη δοκιμή διαφόρων τεχνικών κανονικοποίησης και την αξιολόγηση του βέλτιστου αριθμού κεφαλιών για προσοχή. Για την αξιολόγηση χρησιμοποιήθηκαν ένα γενικό σώμα 55k DGT και ένα σώμα δημόσιας διοίκησης 88k εντός του τομέα. Ένα βελτιστοποιημένο μοντέλο μετασχηματιστή έδειξε βελτίωση βαθμολογίας BLEU των 7.8 σημείων σε σύγκριση με ένα βασικό μοντέλο RNN. Παρατηρήθηκαν βελτιώσεις σε μια σειρά μετρήσεων και συμπεριλαμβανομένου του και υποδεικνύοντας μια σημαντικά μειωμένη προσπάθεια επεξεργασίας μετά από επεξεργασία για βελτιστοποιημένα μοντέλα μετασχηματιστών με 16υπόλογα μοντέλα BPE. Η σήμανση του πάγκου έναντι της και των μεταφραστικών μηχανών μας έδειξε σημαντικές βελτιώσεις. Το ερώτημα αν οι μετασχηματιστές μπορούν να είναι ή όχι\nΈχει αντιμετωπιστεί η αποτελεσματική χρήση της αγγλικής-ιρλανδικής μετάφρασης σε ένα περιβάλλον χαμηλής περιεκτικότητας σε πόρους. Είναι Φειδίρ Λιν, ναι μπορούμε.', 'lt': 'Transformuotojas yra mašin ų vertimo naujausias model is. Vis dėlto paprastai ir nervinių vertimų modeliai dažnai atliekami kalbų porose, kuriose nėra pakankamai mokymo duomenų. As a consequence and relatively few experiments have been carried out using this architecture on low-resource language pairs.  Šiame tyrime ir vertinamas Transformer modelių hiperparametrų optimizavimas vertant mažo išteklio anglų ir airių kalbų porą. Mes įrodome, kad pasirinkus tinkamus parametrus gerokai pagerės veiklos rezultatai. Svarbiausia yra tai, kad teisingas subžodžio modelio pasirinkimas yra didžiausias vertimo rezultatų veiksnys. SentencePiece models using both unigram and BPE approaches were appraised.  Variations on model architectures included modifying the number of layers and testing various regularization techniques and evaluating the optimal number of heads for attention.  A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation.  Optimizuotas transformatoriaus modelis parodė, kad BLEU balas pagerėjo 7,8 punkto, palyginti su pradiniu RNR modeliu. Buvo pastebėta įvairių metrinių ir įskaitant TER patobulinimų, o po redagavimo buvo gerokai sumažinta Transformer optimizuotų modelių su 16k BPE paražodžių modeliais pastanga. Palyginimas su Google Translate ir mūsų vertimo varikliais parodė reikšmingus patobulinimus. The question of whether or not Transformers can be\nused effectively in a low-resource setting of English-Irish translation has been addressed.  Is feidir linn - yes we can.', 'mk': 'Моделот Трансформер е најновиот во машинскиот превод. Сепак, и генерално и нервни преводни модели честопати се изведуваат на јазички парови со недоволни податоци за обука. As a consequence and relatively few experiments have been carried out using this architecture on low-resource language pairs.  Во оваа студија и хиперпараметралната оптимизација на трансформските модели во преводот на парот со ниски ресурси англиско-ирски јазик се проценува. Демонстрираме дека изборот на соодветни параметри води до значителни подобрувања на резултатите. Најважно е и вистинскиот избор на моделот на подзборови се покажува дека е најголемиот возач на преведувањето. SentencePiece models using both unigram and BPE approaches were appraised.  Варијациите на моделните архитектури вклучуваа модификација на бројот на слоеви и тестирање на различни техники на регуларизација и оценка на оптимален број на глави за внимание. За проценка беа искористени генерални 55k ДГТ корпус и 88k јавен административен корпус во домен. Трансформиран оптимизиран модел покажа подобрување на БЛЕУ оценката од 7,8 поени во споредба со основниот РНН модел. Подобрувањата беа забележани низ голем број метрики, вклучувајќи го и ТЕР и индицирајќи значително намален напор по уредување за оптимизираните модели на Трансформер со 16k BPE модели на подзборови. Bench-marked against Google Translate and our translation engines demonstrated significant improvements.  Прашањето дали трансформирачите можат да бидат\nе употребена ефикасно во поставување на ниски ресурси на англиско-ирски превод. Is feidir linn - yes we can.', 'ms': 'Model Transformer adalah state-of-the-art dalam Translation Machine. However and in general and neural translation models often under perform on language pairs with insufficient training data.  Sebagai konsekuensi dan sedikit eksperimen telah dilakukan menggunakan arkitektur ini pada pasangan bahasa sumber rendah. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated.  Kami menunjukkan bahawa memilih parameter yang sesuai membawa kepada peningkatan prestasi yang besar. Yang paling penting dan pilihan yang betul bagi model subkata dipaparkan sebagai pemacu terbesar prestasi terjemahan. Maklumat Variasi pada arkitektur model termasuk mengubah bilangan lapisan dan menguji berbagai teknik pengaturan dan menilai bilangan optimal kepala untuk perhatian. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation.  A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model.  Perbaikan diperhatikan melalui julat metrik dan termasuk TER dan menunjukkan usaha penyuntingan setelah dikurangkan secara mendasarkan untuk model optimisasi Transformer dengan model subkata BPE 16k. Bench-marked terhadap Google Translate dan enjin terjemahan kami menunjukkan peningkatan yang signifikan. Pertanyaan sama ada Penukar boleh atau tidak\ndigunakan secara efektif dalam tetapan sumber rendah terjemahan bahasa Inggeris-Irlandia telah ditujukan. Is feidir linn - yes we can.', 'ml': 'The Transformer model is the state-of-the-art in Machine Translation.  എന്നാലും പൊതുവായും ന്യൂറല്\u200d പരിഭാഷയുടെ മോഡലുകളും ഭാഷ ജോട്ടുകാരുടെ കീഴില്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതില ഈ ആര്\u200dക്കിച്ചിട്ടറിക്കുന്നത് കുറച്ച് പരീക്ഷണങ്ങള്\u200d കൊണ്ട് പ്രവര്\u200dത്തിപ്പിച്ചിരിക്കുന്നു. വിഭവങ്ങള്\u200d ഭാഷ @ info ശരിയായ പരാമീറ്ററുകള്\u200d തിരഞ്ഞെടുക്കുന്നത് പ്രകടന മെച്ചപ്പെടുത്തുന്നതിന് കൂടുതല്\u200d മുന്\u200dഗണന മാ ഏറ്റവും പ്രധാനപ്പെട്ടവയും സബ്\u200cവോര്\u200dഡ് മോഡലിന്റെ ശരിയായ തെരഞ്ഞെടുക്കുന്നതും പരിഭാഷപ്രകടനത്തിന്റെ ഏറ്റവും  യൂണിഗ്രാം ഉപയോഗിച്ച് വിധിപ്പിക്കുന്ന പീസ് മോഡലുകള്\u200d പരിശോധിക്കപ്പെട്ടു. മോഡല്\u200d ആര്\u200dക്ടിക്കറ്റുകളിലെ മാറ്റങ്ങള്\u200d തട്ടുകളുടെ എണ്ണം മാറ്റുന്നതും വ്യത്യസ്ത നിയന്ത്രണങ്ങള്\u200d പരീക്ഷിക്കുന്നതും ശ്രദ്ധിക് ഒരു ജനറല്\u200d 55k ഡിജിറ്റി കോര്\u200dപ്പുസും ഡൊമൈനില്\u200d 88k പൊതുവായ അഡ്മിന്\u200d കോര്\u200dപ്പുസിനും വിലയിക്കാന്\u200d ഉപയോഗിച്ചു. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model.  മെട്രിക്കങ്ങളിലൂടെ മെറ്റിക്കങ്ങള്\u200dക്ക് മുന്\u200dകൂട്ടുന്നത് കണ്ടിട്ടുണ്ടായിരുന്നു. ടെആര്\u200d ചേര്\u200dന്നുകൊണ്ടും, ട്രാന്\u200dഫോര്\u200dമാന്\u200dഫോര്\u200d ഗൂഗിളിനെതിരായി ബെന്\u200dച്ച് മാര്\u200dക്ക് ചെയ്തിരിക്കുന്നു. നമ്മുടെ പരിഭാഷ എഞ്ചിനുകള്\u200dക്കെതിരായി  ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആകുമോ എന്ന് ചോദ്യം\nഇംഗ്ലീഷ്- ഐറിഷ് പരിഭാഷകളുടെ കുറഞ്ഞ വിഭവങ്ങള്\u200d സജ്ജീകരണത്തില്\u200d ഉപയോഗിച്ചിരിക്കുന്നു. ഫെഡിര്\u200d ലിന്\u200d ആണ് - അതെ.', 'mt': 'Il-mudell Transformer huwa l-aktar avvanzat fit-Traduzzjoni tal-Magni. Madankollu u b’mod ġenerali u mudelli ta’ traduzzjoni newrali ta’ spiss qed jitwettqu fuq pari lingwistiċi b’dejta ta’ taħriġ insuffiċjenti. Bħala konsegwenza u relattivament ftit esperimenti twettqu bl-użu ta’ din l-arkitettura fuq pari lingwistiċi b’riżorsi baxxi. F’dan l-istudju u l-ottimizzazzjoni tal-parametri għoljin tal-mudelli Transformer fit-traduzzjoni tal-par ta’ lingwi Ingliż-Irlandiż b’riżorsi baxxi hija evalwata. Aħna nuru li l-għażla ta’ parametri xierqa twassal għal titjib konsiderevoli fil-prestazzjoni. L-aktar importanti u l-għażla korretta tal-mudell tas-subkelma tintwera li hija l-akbar mutur tal-prestazzjoni tat-traduzzjoni. Ġew evalwati mudelli SentencePiece li jużaw approċċi kemm unigrammi kif ukoll BPE. Variations on model architectures included modifying the number of layers and testing various regularization techniques and evaluating the optimal number of heads for attention.  Ġew użati 55k corpus tad-DĠT ġeneriku u 88k corpus amministrattiv pubbliku fid-dominju għall-evalwazzjoni. Mudell ottimizzat tat-Transformer wera titjib fil-punteġġ BLEU ta’ 7.8 punti meta mqabbel ma’ mudell ta’ RNN fil-linja bażi. Titjib ġie osservat f’firxa ta’ metriċi u inkluż TER u li jindika sforz sostanzjalment imnaqqas wara l-edizzjoni għal mudelli ottimizzati ta’ Transformer b’mudelli ta’ sottokliem ta’ 16k BPE. Meta mqabbel ma’ Google Translate u l-magni tat-traduzzjoni tagħna wrew titjib sinifikanti. Il-kwistjoni ta’ jekk it-Trasformaturi jistgħux ikunu jew le\nintuża b’mod effettiv f’ambjent ta’ riżorsi baxxi ta’ traduzzjoni Ingliż-Irlandiża ġiet indirizzata. Is feidir linn - yes we can.', 'no': 'Transformeringsmodellen er kunsttilstand i maskineomsetjinga. Men i generelle og neuraloversettelsmodeller kan ofte utførast på språkoplar med ikkje tilstrekkelege opplæringsdata. Som konsekvens og relativt få eksperimenter er er utført med denne arkitekturen på låg ressursspråk par. I denne studien og hyperparameteren blir optimalisert for transformeringsmodeller i omsetjinga av dei låge ressursane for engelsk- irske språk. Vi viser at valet av passande parametrar fører til merkelige forbetringar i utviklinga. Dei viktigste og korrekte valet på underordmodellen vert vist som den største driveren av omsetjingsfunksjonen. Comment Variasjonar på modellearkitekturar inkluderte å endra talet på lag og testa ulike reguleringsteknikk og evaluera optimal tal på hovud for oppmerksomhet. Ein generiske 55k DGT corpus og ein i domene 88k offentleg administrerkorpus ble brukt for evaluering. Ein optimalisert modell for transformering demonstrerte ein forbetring av BLEU-poeng med 7,8 punkt når det sammenlignet med ein grunnlinje RNN-modell. Forbedringar ble observert over eit rekkje av metrikar og inkludert TER og indikerer ein vanleg redusert postredigeringseffort for transformeringsoptimaliserte modeller med 16k BPE-underordmodeller. Bench-merket mot Google Translate og våre omsetjingsmotorar viste signifikante forbedringar. Spørsmålet om Transformerer kan vera eller ikkje\nbrukt effektivt i ein låg ressursinnstilling av engelsk- irske omsetjing er adressert. Er feidir linn - ja kan vi.', 'si': 'මාෂින් අවවාදයේ ප්\u200dරමාණයක් තමයි මේෂින් අවවාදයේ ස්ථානය- of- the- art. නමුත් සාමාන්\u200dය සහ න්\u200dයූරල් වාර්තාවක් අනුවාර්තාවක් භාෂාවක් සම්පූර්ණ දත්ත අනුපුරුද්ධ ප්\u200dරතිචාරයක් වගේම සම්බන්ධයෙන් පරීක්ෂණයක් ටිකක් පරීක්ෂණය කරලා තියෙනවා මේ විස්තාරය ප්\u200dරයෝජනය මේ පරීක්ෂණය සහ හැයිපර් ප්\u200dරමාණයේ ප්\u200dරමාණකර් මොඩේල්ස් එකේ අඩු ප්\u200dරමාණයක් ඉංග්\u200dරිස්-අයිරිස් භාෂා ජෝ අපි ප්\u200dරකාශ කරනවා හොඳ ප්\u200dරමාණයක් තෝරාගන්න ප්\u200dරමාණයක් ගොඩක් ප්\u200dරමාණයක් වැඩි වැඩි කරනවා. ගොඩක් වැදගත් සබ්වර්ඩ් මොඩල් එකේ හරි තෝරණය පෙන්වන්න පුළුවන් විදිහට පරිවර්තනයේ වැඩිම ද්\u200dර Comment මොඩල් ස්ථාපනයේ වෙනස් සම්පූර්ණයෙන් ස්ථාපනය සහ සාමාන්\u200dය විද්\u200dයාපනය පරීක්ෂණය සහ අවධානය සඳහා හොඳ සංඛ සාමාන්\u200dය 55k DGT කෝර්පුස් සහ 88k ජාතික ප්\u200dරධාන කෝර්පුස් විශ්වාස කරන්න භාවිත කරලා තියෙනවා. Name මෙට්\u200dරික්ස් සහ TER සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය කරන්න ප්\u200dරයෝජනය සඳහා ප්\u200d Google වාර්ථාව සහ අපේ වාර්ථාව එංජින් වලට බෙන්ච් මාර්ක් කරලා තියෙනවා. ප්\u200dරශ්නය වෙනස් කරන්න පුළුවන් නැද්ද කියලා\nඉංග්\u200dරිස්-අයිරිස් භාවිතානයට ප්\u200dරශ්නයක් ප්\u200dරමාණය කරලා තියෙන්නේ. - ඔව්, අපිට පුළුවන්.', 'so': "The Transformer model is the state-of-the-art in Machine Translation.  However and in general and neural translation models often under perform on language pairs with insufficient training data.  Sababtaas darteed waxaa la sameeyay jirrabo yar oo la isticmaalay dhismahan labada luqada hoose-resource. Waxbarashadan iyo hyperparameter optimization of models Transformer in translations of the low-resource Ingiriis-Irish labaad. Waxaynu muujinnaa in doorashada heerarka saxda ah uu ku hoggaamiyaa horumarinta tababarka aad u weyn. Inta ugu muhiimsan iyo doorasho saxda ah oo u saxda tusaale-qoraalka hoose ah waxaa looga muujiyaa kuwa ugu weynaa wadowga fasaxda turjumaadda. Tusaaladaha dhaqdhaqaalaha ee ku isticmaalaya unigram iyo BPE. Isbedelka dhismaha modellka waxaa ku jira mid beddelista tirada qasnada iyo imtixaanka qalabka la soodajiyo kala duduwan iyo qiimeynta tirada caadiga ah ee madaxa. Jardiino waxaa loo isticmaalay 55k DGT corpus oo gaarka ah ee degmada 88k oo guud ah. Tusaale turjuman optimized wuxuu tusay BLEU score kordhis 7.8 points marka la barbaranayo sameynta model RNN. Horumarinta waxaa laga arkay metric kala duduwan, kuwaas oo ku jira TER, waxaana looga muujiyey qalabka hagaajiga post-editing, tusaalaha lagu bedelay qoraalka 16k BPE subword. Bench-marked oo ka gees ah Google Translate iyo mashiinkeennada turjumiddayada waxay muujiyaan hagitaan aad u weyn. su'aalka in turjubaanku uu noqon karo iyo in kale\noo si fiican loogu isticmaalay xarunta hoos-resource ee turjumista Ingiriis-Irish waa luqada feidir - Haah, waan awoodnaa.", 'pl': 'Model Transformer jest najnowocześniejszym w tłumaczeniu maszynowym. Jednak i ogólnie modele tłumaczeń neuronowych często nie wykonują się na parach językowych z niewystarczającymi danymi treningowymi. W konsekwencji i stosunkowo niewiele eksperymentów przeprowadzono z wykorzystaniem tej architektury na parach językowych o niskich zasobach. W niniejszym opracowaniu oceniano optymalizację hiperparametrów modeli Transformera w tłumaczeniu niskiej ilości zasobów pary językowej angielsko-irlandzkiej. Pokazujemy, że dobór odpowiednich parametrów prowadzi do znacznej poprawy wydajności. Co najważniejsze, prawidłowy wybór modelu podsłów okazuje się być największym czynnikiem napędowym wydajności tłumaczenia. Oceniono modele SentencePiece wykorzystujące zarówno unigram, jak i BPE. Warianty w architekturze modeli obejmowały modyfikację liczby warstw i testowanie różnych technik regularyzacji oraz ocenę optymalnej liczby główek do uwagi. Do oceny użyto generycznego korpusu DGT 55k oraz publicznego korpusu administracyjnego 88k w domenie. Zoptymalizowany model Transformera wykazał poprawę wyniku BLEU o 7,8 punktach w porównaniu z modelem RNN podstawowym. Zaobserwowano poprawy w zakresie wskaźników, w tym TER, co wskazuje na znacznie zmniejszony nakład na edycję po modelach zoptymalizowanych przez Transformer z 16k modelami podsłów BPE. Znaczne usprawnienia wykazały znaczącą poprawę w stosunku do Google Translate i naszych silników tłumaczeniowych. Pytanie, czy transformatory mogą być\nUwzględniono skuteczne wykorzystywanie tłumaczeń angielsko-irlandzkich w niskich zasobach. To Feidir Linn. Tak, możemy.', 'sr': 'Model transformera je stanje umjetnosti u prevodu mašine. Međutim, i općenito i neuralne modele prevođenja često se ispunjavaju na jezičkim parovima sa nedovoljnim podacima obuke. Kao posledicu i relativno nekoliko eksperimenata su provedeni koristeći ovu arhitekturu na par jezika sa niskim resursima. U ovom ispitivanju i hiperparametru se procjenjuje optimizacija modela transformera u prevodu malih resursa paira engleskog-irskog jezika. Pokazujemo da biranje odgovarajućih parametara vodi do značajnih poboljšanja učinka. Najvažnije i ispravni izbor model podriječi pokazuje se da je najveći vozač izvođenja prevođenja. Određeni su modeli kazne Piece koji koriste i unigram i BPE pristupe. Varijacije modelnih arhitektura uključuju izmjenu broja slojeva i testiranje različitih regularizacijskih tehnika i procjenu optimalnog broja glava za pažnju. Za procjenu su koristili generični 55k DGT korpus i 88k javnog administracijskog korpusa. Optimizirani model transformera pokazao je poboljšanje rezultata BLEU-a od 7,8 bodova u usporedbi sa početnim RNN modelom. Poboljšanja je posmatrana preko niza metrika i uključujući TER i ukazujući na značajno smanjene napore za editiranje postova za optimizirane modele transformera sa 16k modelima podriječja BPE. Benk označen protiv Google Translate i naših prevodnih motora pokazali su značajne poboljšanja. Pitanje je da li Transformeri mogu biti ili ne\nučinkovito korišteno u postavljanju niskog resursa prevoda engleskog-irskog prevoda je adresirano. - Da, možemo.', 'ro': 'Modelul Transformer este de ultimă generație în traducerea automată. Cu toate acestea și, în general, modelele de traducere neurală și adesea sub performanță pe perechi de limbi cu date insuficiente de formare. În consecință, relativ puține experimente au fost efectuate utilizând această arhitectură pe perechi de limbi cu resurse reduse. În acest studiu este evaluată optimizarea hiperparametrelor modelelor Transformer în traducerea perechii de limbi engleză-irlandeză cu resurse reduse. Demonstrăm că alegerea parametrilor adecvați duce la îmbunătățiri considerabile ale performanței. Cel mai important și alegerea corectă a modelului de subcuvânt se dovedește a fi cel mai mare driver al performanței traducerii. Modelele SentencePiece utilizând atât abordări unigram cât și BPE au fost evaluate. Variațiile asupra arhitecturilor modelului au inclus modificarea numărului de straturi și testarea diferitelor tehnici de regularizare și evaluarea numărului optim de capete pentru atenție. Pentru evaluare au fost utilizate un corpus DGT generic de 55k și un corpus administrativ public de 88k în domeniu. Un model optimizat Transformer a demonstrat o îmbunătăţire a scorului BLEU de 7,8 puncte comparativ cu un model RNN iniţial. S-au observat îmbunătățiri într-o gamă de valori și inclusiv TER, indicând o reducere substanțială a efortului post editare pentru modelele optimizate Transformer cu modele de subcuvânt BPE 16k. Bench-marked împotriva Google Translate și motoarele noastre de traducere au demonstrat îmbunătățiri semnificative. Întrebarea dacă Transformers pot fi sau nu\na fost abordată utilizarea eficientă într-un cadru cu resurse reduse de traducere engleză-irlandeză. Este Feidir Linn - da putem.', 'sv': 'Transformermodellen är den senaste inom maskinöversättning. Men i allmänhet och neurala översättningsmodeller ofta underpresterar på språkpar med otillräckliga träningsdata. Som en följd av detta har relativt få experiment genomförts med hjälp av denna arkitektur på språkpar med låg resurs. I denna studie utvärderas och hyperparametroptimering av Transformermodeller för översättning av lågresurs engelsk-irländska språkparet. Vi visar att valet av lämpliga parametrar leder till betydande prestandaförbättringar. Viktigast av allt och rätt val av underordsmodell har visat sig vara den största drivkraften för översättningsprestanda. SentencePiece-modeller med både unigram- och BPE-metoder utvärderades. Variationer på modellarkitekturer omfattade att ändra antalet lager och testa olika regulariseringstekniker och utvärdera det optimala antalet huvuden för uppmärksamhet. En generisk 55k DGT-korpus och en 88k offentlig administrativ korpus användes för utvärdering. En Transformeroptimerad modell visade en BLEU-poängförbättring på 7,8 poäng jämfört med en RNN-modell vid baseline. Förbättringar observerades över en rad mätvärden, inklusive TER, och indikerade en avsevärt minskad efterredigering för Transformeroptimerade modeller med 16k BPE underordsmodeller. Bench-märkt mot Google Translate och våra översättningsmotorer visade betydande förbättringar. Frågan om Transformers kan vara\nMan har tagit itu med frågan om hur engelsk-irländsk översättning används effektivt i en miljö med låga resurser. Är feidir linn - ja vi kan.', 'ur': 'تغییر مترجم موڈل ماشین ترجمہ میں آهنت کی حالت ہے. اگرچہ اور عمومی اور نئورل ترجمہ موڈل کثرت وقت زبان جوڑوں پر ناکافی ترکین ڈیٹے کے ساتھ عمل کرتے ہیں. اس کے نتیجے اور نسبتا کم آزمائش کی وجہ سے یہ معماری کم منطقی زبان جوڑوں پر استعمال کیا گیا ہے۔ اس تحقیقات اور ہیپر پارامیٹ میں ترنسفور موڈلز کی آپٹمیٹ کرنا کم منبع انگلیسی-ایرلندی زبان جوڑے کو ترنسوٹ کرنا ہے. ہم دکھاتے ہیں کہ مناسب پارامیٹر انتخاب کرنا بہت اچھی عملکرد کی تدبیر کی وجہ سے ہے۔ زیادہ اہم اور سیدھا انتخاب ہے کہ سوبرویڈ موڈل کی ترجمہ کے سب سے بڑے ڈرائیور ہے۔ SentencePiece Models using both unigram and BPE approaches were evaluated. موڈل معماری کے متغیرات میں لہروں کی تعداد بدل دینے اور مختلف قانونی تخصیلیوں کی آزمائش اور سروں کی اچھی تعداد کا ارزش کرنا شامل ہوا۔ ایک عمومی 55ک DGT کورپوس اور ایک ڈومین میں 88k عمومی ادمین کورپوس کے لئے استعمال کیے گئے۔ Name متریک اور TER کے شامل بہت کم کم پوسٹ ویڈینگ کی کوشش دکھائی گئی تھی جو ترفنرسر کے لئے اچھی ماڈل بنائی گئی تھی۔ گوگل ترجمہ اور ہمارے ترجمہ انجینٹوں کے خلاف بنچ-مارک کیا گیا تھا کہ بہت اضافہ کی باتیں دکھائیں۔ سوال یہ ہے کہ کیا تغییر دینے والے ہیں یا نہیں\nانگلیسی-ایرلند ترجمہ کے اندر کم منبع سازی میں استعمال کیا گیا ہے۔ فایدر لین ہے - ہاں ہم کر سکتے ہیں.', 'ta': 'மாற்றும் மாதிரி இயந்திரம் மொழிபெயர்ப்பில் உள்ள நிலை- கலையின் நிலைமை பொதுவான மற்றும் பாதுகாப்பான மொழிமாற்ற மாதிரிகள் பெரும்பாலும் பயிற்சி தரவுடன் போதுமானது மொழி ஜ குறைந்த மூலத்தின் மொழி ஜோடியை பயன்படுத்தி சில சோதனைகள் செய்யப்பட்டுள்ளது. குறைந்த மூலத்தை மொழிபெயர்ப்பில் மாற்றும் மாதிரி மாதிரிகளின் மேம்பாட்டு மற்றும் உயரமான அளபுருவு மாற்றுதல் இந்த சரியான அளபுருக்களை தேர்ந்தெடுக்கும் என்பதை நாம் குறிப்பிடுகிறோம் என்று காட்டுகிறோம். முக்கியமானதும் சரியான தேர்வு வாக்குறுப்பு பைக்ராம் மற்றும் BPE முறைமைகளை பயன்படுத்தி பைக் மாதிரிகள் அறிவிக்கப்பட்டது. மாதிரி அடுக்குகளின் எண்ணிக்கையை மாற்றி மற்றும் பல கட்டுப்பாட்டு தொழில்நுட்பங்களை சோதிக்கும் மற்றும் கவனத்திற்கு தேர் ஒரு பொதுவான 55k டிஜிடி கார்ப்ஸ் மற்றும் ஒரு டோமைன் 88k பொது பொது நிர்வாகிய கார்ப்புஸ் மதிப்பிற்கு பயன்படுத்தப் A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model.  Name கூகுல் மொழிபெயர்ப்பு மற்றும் எங்கள் மொழிபெயர்ப்பு இயந்திரங்களுக்கு எதிரான பென்ச் குறிப்பிடப்பட் மாற்றுபவர்கள் இருக்க முடியுமா என்று கேள்வி\nஆங்கிலம்- ஐரிஷ் மொழிபெயர்ப்பின் குறைந்த மூலம் அமைப்பில் பயன்படுத்தப்பட்டது. Fedir லின் உள்ளது - ஆமாம் நாம் முடியும்.', 'mn': 'Трансформацийн загвар бол машины хөгжүүлэлтийн урлагийн төвшин юм. Гэхдээ ерөнхийдөө болон мэдрэлийн хөгжлийн загварууд хэл хоёр дээр хангалттай боловсрол өгөгдлийг хийдэг. Үүний үр дүнд, харьцангуй жижиг туршилтууд энэ архитектурыг бага боловсролын хэл хоорондоо ашиглан хийгдсэн. Энэ судалгаанд болон гиперпараметр Трансфер загварын сайхан бага баялаг Англи-Ирландын хэл хоёрыг орлуулахад үнэлдэг. Бид тохиромжтой параметрыг сонгох нь ажиллагааны сайжруулалт хүргэж чадна. Хамгийн чухал нь суб үгийн загварын зөв сонголт нь орчуулах үйл ажиллагааны хамгийн том драйвер юм. Өөр нэгж болон BPE ойлголтыг ашиглаж өгүүлбэл хэлбэрийн загварууд нь тодорхойлдог. Загварын архитектуруудын өөрчлөлт нь давхар хэмжээний тоо өөрчлөгдөж, олон жишээлбэлтийн технологийг шалгаж, анхаарал төвлөрүүлэх гол тоо шалгаж байна. 55k DGT корпус, 88k нийтийн удирдагч корпус үнэлгээнд ашиглаж байсан. Трансформаторын сайн сайжруулагдсан загвар нь БЛЕУ-ын тоо 7.8 цэгийн сайжруулалтыг харьцуулсан ДНХ загвартай харьцуулсан юм. Үнэндээ сайжруулалт олон хэмжээний метрик болон ТЕР болон ТЭР-д хамгийн багасгаж, Трансфер дээрх сайжруулагдсан загваруудыг 16k BPE суурь үгийн загвартай харуулсан. Google Translate болон орчуулах хөдөлгүүдийн эсрэг тэмдэглэгдсэн банк нь чухал сайжруулалт үзүүлсэн. Трансформацууд байж болох эсэхийг асуух нь\nАнгли-Ирландын хөрөнгө оруулалтын бага нөөц бага байгуулалт хэрэглэгддэг. Файдир Линн гэдэг нь тийм ээ.', 'uz': "Name Lekin umumiy va neyron tarjima modellari oddiy tilning ikki xil xil bilan bajarishda yetarli maʼlumot yoʻq. As a consequence and relatively few experiments have been carried out using this architecture on low-resource language pairs.  Name Biz muhim parametrlarni tanlashni ko'rsatishimiz mumkin, juda ko'p bajarish muvaffaqiyatlariga erishiladi. @ info: whatsthis Sensor Model arxituvlarida oʻzgarishlar qatlamning soni oʻzgartirish va har xil boshqaruv tugmasini sinash va taʼminlovchi sonlarning optimal soni qiymatish mumkin. Umumiy 55k DGT corpus va domen 88k public admin korpusi qiymatga ishlatiladi. Name Name Name Transformerlar\nIngliz- Irish tarjima tarjimalarining kichkina manbani ishlatilgan edi. f ëidir linn - haqida biz mumkin.", 'vi': 'The transformer model is the state-of-art in Machine Translation. Tuy nhiên, và nói chung, các mô hình dịch chuyển thần kinh thường được thực hiện trên một cặp ngôn ngữ với dữ liệu huấn luyện không đủ. Do đó, ít thí nghiệm đã được thực hiện sử dụng kiến trúc này trên các cặp ngôn ngữ ít tài nguyên. Trong nghiên cứu này và độ cẩn của siêu Tham số của mô hình transformer để dịch hai ngôn ngữ tiếng Anh-Ái ít tài nguyên đã được đánh giá. Chúng tôi chứng minh rằng lựa chọn phù hợp dẫn đến hiệu suất cải thiện đáng kể. Điều quan trọng nhất và sự chọn đúng kiểu dùng từ phụ được cho thấy là tài xế lớn nhất trong khả năng dịch chuyển. Mẫu đơn đơn đơn sử dụng cả trường đại học và các phương pháp BPE đã được đánh giá. Sự thay đổi cấu trúc mô hình bao gồm việc sửa đổi số lượng các lớp lớp và kiểm tra các kỹ thuật luân hồi khác nhau và đánh giá số lượng đầu não tối đa cần được chú ý. Một tập đoàn chứa rộng 5k DT và một công ty quản lý nội bộ 88k được dùng để đánh giá. Mô hình biến hình cho thấy tỉ lệ số lượng bắn được đã cải tiến 7.8 so với mô hình RNN cơ bản. Những tiến bộ được quan sát kỹ thuật đo bao gồm đo lường, và ngụ ý một nỗ lực chỉnh sửa sau đó đã giảm đáng kể cho các mô hình transformer tối ưu với mô hình chữ 16k BPE. Bảng điểm chống lại Google Dịch và cơ chế dịch chuyển của chúng tôi đã cải tiến đáng kể. Câu hỏi có hay không Các Transformers\nđã được sử dụng hiệu quả trong một thiết lập dịch chuyển tiếng Anh-Ái-Nhĩ Lan ít được xử lý. Đó là f235;idir Liên... vâng chúng tôi có thể.', 'de': 'Das Transformer-Modell ist der Stand der Technik in der maschinellen Übersetzung. Allerdings und generell funktionieren neuronale Übersetzungsmodelle häufig nicht auf Sprachpaaren mit unzureichenden Trainingsdaten. Infolgedessen wurden relativ wenige Experimente mit dieser Architektur an ressourcenarmen Sprachpaaren durchgeführt. In dieser Studie wird die Hyperparameter-Optimierung von Transformer-Modellen bei der Übersetzung des ressourcenarmen Englisch-Irischen Sprachpaares evaluiert. Wir zeigen, dass die Auswahl geeigneter Parameter zu erheblichen Leistungsverbesserungen führt. Am wichtigsten ist, dass die richtige Wahl des Unterwortmodells der größte Treiber für die Übersetzungsleistung ist. SentencePiece-Modelle mit Unigramm- und BPE-Ansätzen wurden bewertet. Variationen der Modellarchitekturen beinhalteten die Modifizierung der Anzahl der Schichten, das Testen verschiedener Regularisierungstechniken und die Bewertung der optimalen Anzahl der Köpfe für Aufmerksamkeit. Zur Auswertung wurden ein generischer 55k DGT-Korpus und ein in-domain 88k Public Admin-Korpus verwendet. Ein Transformer-optimiertes Modell zeigte eine BLEU-Punkteverbesserung von 7,8 Punkten im Vergleich zu einem RNN-Basismodell. Verbesserungen wurden in einer Reihe von Metriken einschließlich TER beobachtet und deuten auf einen erheblich reduzierten Nachbearbeitungsaufwand für Transformer-optimierte Modelle mit 16k BPE-Subword-Modellen hin. Benchmarking gegenüber Google Translate und unseren Übersetzungs-Engines zeigten deutliche Verbesserungen. Die Frage, ob Transformatoren\nEs wurde darauf eingegangen, dass Englisch-Irisch-Übersetzungen effektiv in einem ressourcenarmen Umfeld eingesetzt werden. Ist feidir linn. Ja, das können wir.', 'da': 'Transformer modellen er den avancerede inden for maskinoversættelse. Men generelt og neurale oversættelsesmodeller ofte under fungerer på sprogpar med utilstrækkelige træningsdata. Som følge heraf er relativt få eksperimenter blevet udført ved hjælp af denne arkitektur på sprogpar med lav ressource. I denne undersøgelse vurderes og optimeres hyperparameter af Transformer modeller i oversættelse af lav ressource engelsk-irsk sprogpar. Vi viser, at valg af passende parametre fører til betydelige forbedringer af ydeevnen. Vigtigst af alt og det korrekte valg af underordsmodel vises at være den største drivkraft for oversættelse ydeevne. SentencePiece modeller, der anvender både unigram og BPE metoder, blev vurderet. Variationer på modelarkitekturer omfattede ændring af antallet af lag og test af forskellige regulariseringsteknikker og evaluering af det optimale antal hoveder til opmærksomhed. Et generisk 55k DGT-korpus og et 88k offentligt administrationskorpus blev brugt til evaluering. En Transformer optimeret model viste en BLEU score forbedring på 7,8 point sammenlignet med en baseline RNN model. Forbedringer blev observeret på tværs af en række målinger, herunder TER, og indikerede en væsentlig reduceret efterredigeringsindsats for Transformer optimerede modeller med 16k BPE underordsmodeller. Bench-markeret mod Google Translate og vores oversættelsesmotorer viste betydelige forbedringer. Spørgsmålet om, hvorvidt Transformers kan\nDen engelsk-irske oversættelse er blevet behandlet effektivt i et miljø med ringe ressourcer. Er feidir linn - ja vi kan.', 'nl': 'Het Transformer model is de state-of-the-art in Machine Translation. Echter en in het algemeen presteren neurale vertaalmodellen vaak onder op taalparen met onvoldoende trainingsgegevens. Als gevolg hiervan zijn relatief weinig experimenten uitgevoerd met deze architectuur op taalparen met weinig resources. In deze studie en hyperparameter optimalisatie van Transformer modellen in het vertalen van het low-resource Engels-Ierse taalpaar wordt geëvalueerd. We tonen aan dat het kiezen van geschikte parameters leidt tot aanzienlijke prestatieverbeteringen. Het belangrijkste en de juiste keuze van het subwoordmodel blijkt de grootste drijfveer voor vertaalprestaties te zijn. SentencePiece modellen met zowel unigram als BPE benaderingen werden beoordeeld. Variaties op modelarchitecturen omvatten het aanpassen van het aantal lagen en het testen van verschillende regularisatietechnieken en het evalueren van het optimale aantal koppen voor aandacht. Voor de evaluatie werd gebruik gemaakt van een generiek 55k DGT corpus en een in-domain 88k public admin corpus. Een Transformer geoptimaliseerd model toonde een BLEU score verbetering van 7.8 punten in vergelijking met een baseline RNN model. Verbeteringen werden waargenomen in een reeks van metrics, waaronder TER, en wijzen op een aanzienlijk verminderde post editing inspanning voor Transformer geoptimaliseerde modellen met 16k BPE subwoordmodellen. Benchmarking ten opzichte van Google Translate en onze vertaalengines toonden aanzienlijke verbeteringen aan. De vraag of Transformers al dan niet\nEr is aandacht besteed aan de doeltreffende toepassing van Engels-Ierse vertalingen in een omgeving met weinig middelen. Is feidir linn, ja dat kunnen we.', 'bg': 'Моделът на трансформатора е най-съвременният в машинния превод. Въпреки това и като цяло и невронните преводни модели често не се изпълняват на езикови двойки с недостатъчни данни за обучение. В резултат на това са проведени сравнително малко експерименти, използващи тази архитектура върху езикови двойки с ниски ресурси. В това проучване е направена оценка на оптимизацията на хиперпараметрите на трансформаторните модели при превода на двойката английски-ирландски език с нисък ресурс. Ние демонстрираме, че изборът на подходящи параметри води до значителни подобрения на производителността. Най-важното е, че правилният избор на модел на поддума е показан като най-големият двигател на ефективността на превода. Бяха оценени модели, използващи униграм и БПЕ подходи. Вариациите в архитектурите на моделите включват модифициране на броя на слоевете и тестване на различни техники за регулиране и оценка на оптималния брой глави за внимание. За оценка бяха използвани генеричен корпус от 55к ДГТ и публичен административен корпус от 88к в областта. Оптимизиран модел за трансформатор демонстрира подобрение на резултата от 7,8 точки в сравнение с базовия модел на RNN. Наблюдавани са подобрения в редица показатели, включително ТЕР, което показва значително намалено усилие след редактиране за оптимизирани модели с 16К поддуми. Отбелязани спрямо Гугъл Преводач и нашите машини за преводи демонстрираха значителни подобрения. Въпросът дали трансформаторите могат да бъдат\nРазгледан е ефективното използване в нискоресурсна обстановка на английски-ирландски превод. Файдир Лин - да можем.', 'id': 'Model Transformer adalah state-of-the-art dalam Translation Mesin. Namun dan secara umum dan model terjemahan saraf sering dilakukan pada pasangan bahasa dengan data latihan yang tidak cukup. Sebagai konsekuensi dan relatif sedikit eksperimen telah dilakukan menggunakan arsitektur ini pada pasangan bahasa sumber daya rendah. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated.  Kami menunjukkan bahwa memilih parameter yang sesuai mengarah kepada peningkatan prestasi yang konsiderel. Most importantly and the correct choice of subword model is shown to be the biggest driver of translation performance.  Model SentencePiece menggunakan pendekatan unigram dan BPE telah dihargai. Variasi pada arsitektur model termasuk mengubah jumlah lapisan dan menguji berbagai teknik regularisasi dan mengevaluasi jumlah optimal kepala untuk perhatian. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation.  Model optimisasi Transformer menunjukkan peningkatan skor BLEU 7,8 poin ketika dibandingkan dengan model RNN dasar. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models.  Bench-marked against Google Translate and our translation engines demonstrated significant improvements.  Pertanyaan apakah Transformers dapat atau tidak\ndigunakan secara efektif dalam pengaturan sumber daya rendah terjemahan bahasa Inggris-Irlandia telah diasingkan. Apakah feidir Lin - ya kita bisa.', 'fa': 'مدل تغییر دهنده وضعیت هنری در ترجمه ماشین است. با این حال، و در کل و کل مدل ترجمه\u200cهای عصبی اغلب در جفت زبان با داده\u200cهای آموزش کافی انجام می\u200cدهند. در نتیجه و نسبتا چند آزمایش با استفاده از این معماری در جفت زبانهای کم منبع انجام شده است. در این مطالعه و هیپر پارامتر optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. ما نشان می دهیم که انتخاب پارامترهای مناسب به پیشرفت عملکرد زیادی رخ می دهد. مهمترین و درست انتخاب مدل زیر کلمه نشان داده می\u200cشود که بزرگترین راننده\u200cی اجرای ترجمه است. مدل\u200cهای وینیگرام و BPE را استفاده می\u200cکنند. تغییرات روی معماری مدل شامل تغییرات تعداد لایه ها و تغییرات تکنیک های قانونی و ارزیابی تعداد بهترین سر برای توجه است. یک کورپوس ژنرال 55ک DGT و یک کورپوس مدیریت عمومی 88k برای ارزیابی استفاده شد. یک مدل تغییر دهنده optimized demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. توسعه\u200cها در مجموعه متریک و شامل TER مشاهده شده\u200cاند و نشان می\u200cدهند تلاش\u200cهای ویرایش پست\u200cهای زیادی کاهش\u200cشده برای مدل\u200cهای بهترین ترنسفور با مدل\u200cهای زیر کلمه BPE ۱۶ کیلومتر. توسط ترجمه گوگل و موتورهای ترجمه ما بهترین شدیدی را نشان دادند. سؤال اینکه آیا تغییردهنده\u200cها می\u200cتوانند\nدر تنظیمات کمی منابع انگلیسی و ایرلندی استفاده شده است. فايدر لين ـه بله ميتونيم', 'sw': 'The Transformer model is the state-of-the-art in Machine Translation.  Hata hivyo, na kwa ujumla na mifano ya tafsiri ya uraia mara nyingi hufanya kazi kwa ajili ya wanandoa wa lugha wenye taarifa za mafunzo yasiyoshosha. Matokeo yake na majaribio machache yanafanywa kwa kutumia ujenzi huu kwenye viwili vya lugha duni vya rasilimali. Katika utafiti huu na upekezaji wa ubora wa mifano ya zamani katika kutafsiri mbili za lugha za Kiingereza na Kiirishani. Tunaonyesha kuwa kuchagua parameter sahihi zinapelekea maboresho makubwa ya utendaji. Kimuhimu zaidi na uchaguzi sahihi wa modeli ya upinzani unaonekana kuwa mwendeshaji mkubwa wa ufafanuzi wa tafsiri. Piece model kwa kutumia mbinu zote za kiunigram na BPE zilikutwa. Mabadiliko katika majengo ya model yalijumuisha kuboresha idadi ya vipande vya juu na kujaribu mbinu mbalimbali za kudhibiti na kutathmini idadi bora ya vichwa kwa ajili ya kusikiliza. Shirika la DGT la kawaida 55k na makampuni ya umma ya ndani ya ndani ya 88k yalitumiwa kwa ajili ya kutathmini. Mfano wa Transfer ulioboreshwa ulionyesha score ya BLEU kuboreshwa kwa pointi 7.8 wakati ukilinganishwa na modeli ya RNN ya msingi. Mabadiliko yalionekana katika maeneo mbalimbali ya mitindo na ikiwa ni pamoja na TER na kuonyesha jitihada za kuhariri baada ya kupungua kwa kiasi kikubwa kwa mifano bora ya Transfer yenye mifano ya chini ya maneno 16k BPE. Benki imewekwa alama dhidi ya kutafsiri Google na mashine yetu ya kutafsiri yalionyesha maboresho makubwa. Swali la kama watafsiri wanaweza kuwa\nimetumiwa kwa ufanisi katika mfumo wa rasilimali duni wa tafsiri ya Kiingereza-Irish imeelezwa. Ni lugha ya feidir - ndio tunaweza.', 'ko': 'Transformer 모형은 기계 번역에서 가장 선진적인 모형이다.그러나 전반적으로 신경 번역 모델은 훈련 데이터가 부족한 언어에 있어 좋지 않다.따라서 저자원 언어에서 이런 구조를 사용하는 실험은 상대적으로 적다.이 연구에서 저자원 영어인 아일랜드어를 번역할 때 변압기 모델에 대한 초파라미터 최적화를 평가했다.우리는 적당한 파라미터를 선택하면 성능을 현저하게 향상시킬 수 있다는 것을 증명했다.가장 중요한 것은 자사 모델의 정확한 선택이 번역 성능의 최대 구동력이다.Unigram 및 BPE 방법을 사용하는 문장 세그먼트 모델을 평가했습니다.모델 구조의 변화는 수정층의 수량, 각종 정규화 기술을 테스트하고 주의력을 평가하는 가장 좋은 머리 수량을 포함한다.통용되는 55k DGT 자료 라이브러리와 한 구역 내의 88k 공공 관리 자료 라이브러리를 사용하여 평가한다.변압기 최적화 모델의 BLEU 평점은 베이스라인 RNN 모델과 비교해 7.8점 높아졌다.TER을 포함한 일련의 지표에서 개선이 관찰되었는데 이는 16k BPE 서브단어 모델을 사용하는 Transformer 최적화 모델의 후기 편집 작업이 크게 감소했음을 나타낸다.Google Translate 및 Google 번역 엔진과 비교한 결과 크게 향상되었습니다.변압기 교환 가능 여부 문제\n영어-아일랜드어 번역의 저자원 환경에서 효과적인 사용이 해결되었다.피델 린--네, 할 수 있어요.', 'am': 'The Transformer model is the state-of-the-art in Machine Translation.  ነገር ግን በጠቅላላ እና የደዌብ ትርጉም ዓይነቶች ብዙ ጊዜ በቋንቋ ዓይነቶች ላይ በሚያስፈልጋቸው የትምህርት ዳታ አይጠቅሙም፡፡ ምሳሌ እና በሚያሳየው ጥቂት ፈተናዎች ይህ የመዝገብ መሠረት በዝናብ-resource ቋንቋ ሁለቶች ላይ ተጠቃሚ ነው፡፡ በዚህ ትምህርት እና hyperparameter የTransformer models በመtranslating the lower-resource English-Irish language pair is assessed. አካባቢ ተካራሮች መምረጥ የሚያሳየው ትክክለኛውን ትክክለኛ ማድረግ ነው፡፡ ከሁሉም አስፈላጊ እና የተዋበ የጥሩ ምርጫዎች የጥያቄ ቃላት ሞዴል ትርጉም አድራሻ መሆኑን ይገልጣል። በዩንግራም እና በBPE ጥያቄዎችን በመጠቀም የስርዓት ምሳሌዎች አሰራበታል፡፡ በሞዴል አካውንት ላይ የተለየ ምርጫዎች የደረጃዎችን ቁጥር ለማሻሻል እና የልዩ ሥርዓት እቅናቄዎችን በመፈተን እና የራሶችን ቁጥር ለመጠቀም የሚያስፈልጉት፡፡ የውጤት 55k DGT ኮርፓስ እና በ ውይይት የ88k የህዝብ አካባቢ ኮርፓስ ለመረጃ ተጠቃሚ ነበር፡፡ የመረጃ ምርጫዎች በተለየ ሜትሪክ እና TER እና ለTransformer Optimized ሞዴላዎችን ለ16k BPE ደብዳቤ አካባቢ ሞዴላዎችን የሚያሳየው የፖስታ ማቀናጃ ድጋፍ አነስተኛ ነው፡፡ ጉግል ትርጉም እና ትርጉም ኢንተርጓሜዎቻችን ላይ የቦንክ ማዕከል ታዋቂውን ትክክል ማድረግ አሳየ፡፡ መግለጫ\nበንግግሊዝና-ኢርሪክ ትርጉም ላይ በዝቅተኛ ዕቃ ውስጥ በተጠቀም ነበር፡፡ ፊዲር ሊን ነው - አዎን እንችላለን።', 'tr': 'Transformer modeli maşynyň terjimesinde resim. Ýöne hem umumy we neural terjime modelleri köplenç dil çiftlerde ýeterlik terjime etmegi bilen edip bilýärler. netijesi üçin bu arhitektura düşük-çeşme dil çiftlerde ulanylan kynçylyk deneyler çykyldy. Bu araşdyrma we hiperparameterlerde iňlis-iňlisçe dil çiftini terjime etmek üçin Transformer modelleriniň optimizasy bar. Biz uygun parametreleri saýlamak üçin täsirli ukyplaryň täzeliklerini gowurarak edip görkeýäris. Iň wajyp bolsa we subsöz nusgasynyň dogry saýlawy terjime etmek üçin iň uly sürüjili bolup görkezilýär. Sözler Model arhitekturlaryň üýtgeşmeleri takyklaryň sanyny üýtgetmek we düýtgeşmeler tekniklerini barlamak we üns berilýän kelläň optimal sanyny deňlemek üçin deňlenýärler. 55k DGT korpusu ve 88k halk admin korpusu değerlendirmek için kullanıldı. Bir terjimeçi optimizatly nusga BLEU netijesi 7.8 punktiň üýtgewini görkezildi. Gelişmeler metrikler arasında ve TER dahil edildi ve 16k BPE alt söz modelleri ile Transformer optimize modelleri üçin önemli azaltmak için post düzenleme çabalarına gösterildi. Google Terjime we terjime enjamlarymyza görkezilen çykyşlar üçin has baglanmış gelişmeler görkezildi. Soragy görkezilip bilmeýän ýa-da görkezilip bilmeýän\nIňlisçe-iňlisçe terjime edilen iňlis-iňlisçe taýýarlanmasynda ullanýar. What are you doing in Izmir?', 'hy': 'Տանֆերմերների մոդելը մեքենայի թարգմանության ամենաբարձր տեխնոլոգիան է: Այնուամենայնիվ, ընդհանուր առմամբ և նյարդային թարգմանման մոդելները հաճախ ներկայացնում են լեզվի զույգերի վրա, որոնք չունեն բավարար ուսուցման տվյալներ: Որպես հետևանք և համեմատաբար քիչ փորձեր են արվել օգտագործելով այս ճարտարապետությունը ցածր ռեսուրսների լեզվի զույգերի վրա: Այս ուսումնասիրության ընթացքում և տրանսֆորմային մոդելների հիպերպարամետրերի օպտիմացման մեջ գնահատվում է ցածր ռեսուրսների անգլերեն-իրլանդական զույգը: Մենք ցույց ենք տալիս, որ համապատասխան պարամետրերի ընտրությունը հանգեցնում է նշանակալի բարելավման: Ամենակարևոր է, որ ենթաբառի մոդելի ճիշտ ընտրությունը ցույց է տալիս, որ այն է թարգմանության ամենամեծ շարժիչը: Պատասխան Մոդելի ճարտարապետության տարբերությունները ներառում էին շերտերի թիվը փոփոխելը և տարբեր վերահսկողական տեխնիկաներ ստուգելը և ուշադրության գլխավորների լավագույն թիվը գնահատելը: Արժեքի համար օգտագործվեցին 55k-ի ընդհանուր DGT կորպուս և 88 k-ի ընդհանուր կառավարական կորպուս: Տանսֆորմերի օպտիմացված մոդելը ցույց տվեց, որ ԲԼԵՎ գնահատականը 7.8 միավորով բարելավվել է, համեմատած արտաքին ՌՆԹ մոդելի հետ: Տարբեր մետրիկների շարքում, ներառյալ TER-ի շարքում կատարվել են բարելավումներ և ցույց են տալիս, որ տրանսֆորմերի օպտիմացված մոդելների դեպքում 16 k BP ենթաբառերի մոդելներով նշանակալի նվազեցված փորձը կարելի է Google Translate-ի և մեր թարգմանման շարժիչները ցույց տվեցին նշանակալի բարելավումներ: Հարցը, թե արդյոք Transforme-ները կարող են\nարդյունավետ օգտագործվում է անգլերեն-իրերեն թարգմանման ցածր ռեսուրսների միջոցով: Is feidir linn - yes we can.', 'bn': 'ট্রান্সফ্রেন্স মডেল মেশিন অনুবাদের রাষ্ট্র-অফ-শিল্প। তবে সাধারণত এবং নিউরাল অনুবাদ মডেল প্রায়শই ভাষার জোড়ায় পর্যাপ্ত প্রশিক্ষণের তথ্য নিয়ে প্রশিক্ষণ প্রশি ফলাফল এবং আকর্ষণীয় কয়েকটি পরীক্ষা এই আর্কিটেক্কার ব্যবহার করা হয়েছে নীচের সম্পদ ভাষার জোড়ায়। এই গবেষণা এবং হাইপার্পার্পারামিটারে ট্রান্সফ্রান্সফার মডেলের অপ্রায়িমিশনের ক্ষেত্রে অনুবাদ করা হয়েছে ইংরেজি ইং আমরা প্রমাণ করছি যে যথেষ্ট প্যারামিটার বেছে নিয়ে যাওয়ার ফলে বেশী প্রভাবের উন্নয়নের কারণে প্রদর্শন করে। সবচেয়ে গুরুত্বপূর্ণ এবং সাবওয়ার্ড মডেলের সঠিক পছন্দ দেখানো হচ্ছে অনুবাদ প্রদর্শনের সবচেয়ে বড় ড্রাইভার। শাস্তি পাইক মডেল ইউনিগ্রাম এবং বিপের ক্ষেত্রে ব্যবহার করা হয়েছে। মডেল আর্কিটেক্টের বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন স্তরের সংখ্যা পরিবর্তন এবং বিভিন্ন নিয়মিত নিয়ন্ত্রণ কৌশল পরীক্ষা  একটি জেনারিক ৫৫কি ডিজিটি কোর্পাস এবং ডোমেইনে ৮৮কি জনগণের প্রশিক্ষক কর্পুস ব্যবহার করা হয়েছে মূল্যায়নের জন্য। একটি ট্রান্সফ্রান্সফারের অপেক্ষায়িত মডেল বিলু স্কোরের উন্নতি প্রদর্শন করেছে যখন একটি বেসেলাইন RNN মডেলের তুলনায়। বেশ কিছু মেট্রিকের সাথে উন্নতি দেখা গেছে এবং টেআরও রয়েছে এবং ট্রান্সফ্রেন্ডের অপ্রাপ্ত মডেলের জন্য ট্রান্সফার্নারের সাবওয়ার্ড মডে গুগল অনুবাদের বিরুদ্ধে বেঞ্চ চ চিহ্নিত এবং আমাদের অনুবাদ ইঞ্জিন গুরুত্বপূর্ণ উন্নয়ন প্রদর্শন করে। The question of whether or not Transformers can be\nইংরেজি-আইরিশ অনুবাদের নিম্নলিখিত সম্পদে কার্যকর ভাবে ব্যবহার করা হয়েছে। ফেডির লিন - হ্যাঁ আমরা পারব।', 'hr': 'Model transformera je stanje umjetnosti u prevodu stroja. Međutim, i općenito i neuralne modele prevoda često se ispunjavaju na jezičkim parovima s nedovoljnim podacima obuke. Kao rezultat i relativno malo eksperimenata provedena je koristeći ovu arhitekturu na parovima s niskim resursima. U ovom ispitivanju i hiperparametru se procjenjuje optimizacija modela transformera u prevodu malih resursa paira engleskog-irskog jezika. Pokazujemo da biranje odgovarajućih parametara dovede do značajnih poboljšanja učinka. Najvažnije i ispravni izbor model podriječi pokazuje se da je najveći vozač izvođenja prevoda. Pregledni su modeli kazne Piece koristeći i unigram i BPE pristupe. Varijacije modelnih arhitektura uključuju izmjenu broja slojeva i testiranje različitih regularizacijskih tehnika i procjenu optimalnog broja glava za pažnju. Za procjenu su koristili generični 55k DGT corpus i 88k javnog administracijskog korpusa. Optimizirani model transformera pokazao je poboljšanje rezultata BLEU-a od 7,8 bodova u usporedbi s početnim RNN modelom. Poboljšanja je primijećena u razini metrika i uključujući TER i ukazujući na značajno smanjene posturedne napore za optimizirane modele transformera s podriječjim modelima 16k BPE. Benk označen protiv Google Translate i naših prijevoznih motora pokazali su značajne poboljšanje. Pitanje da li Transformeri mogu biti ili ne\nučinkovito korišteno u postavljanju niskih resursa prevoda engleski-irski. Da, možemo.', 'bs': 'Model transformera je stanje umjetnosti u prevodu mašine. Međutim, i općenito i neuralne modele prevođenja često se ispunjavaju na jezičkim parovima sa nedovoljnim podacima o obuci. Kao posledicu i relativno malo eksperimenta provedena je koristeći ovu arhitekturu na par jezika s niskim resursima. U ovom ispitivanju i hiperparametru se procjenjuje optimizacija modela transformera u prevodu malih resursa paira engleskog-irskog jezika. Pokazujemo da biranje odgovarajućih parametara dovede do značajnih poboljšanja učinka. Najvažnije i pravi izbor model podriječi pokazuje se da je najveći vozač izvođenja prevoda. Pregledni su modeli kazne Piece koristeći i unigram i BPE pristupe. Varijacije modelnih arhitektura uključuju izmjenu broja slojeva i testiranje različitih regularizacijskih tehnika i procjenu optimalnog broja glava za pažnju. Za procjenu su koristili generični 55k DGT corpus i 88k javnog administracijskog korpusa. Optimizirani model transformera pokazao je poboljšanje rezultata BLEU-a od 7,8 bodova u usporedbi s početnim RNN modelom. Poboljšanja je posmatrana preko niza metrika i uključujući TER i ukazujući na značajno smanjene napore za editiranje postova za optimizirane modele transformera sa 16k modelima podriječja BPE. Benk označen protiv Google Translate i naših prevodnih motora pokazali su značajne poboljšanja. Pitanje je da li Transformeri mogu biti ili ne\nučinkovito korišteno u postavljanju niskih resursa prevoda engleskog-irskog jezika je adresirano. Da, možemo.', 'af': "Die Transformer model is die state- of- the- art in Masjien Vertaling. Alhoewel en in algemeen en neurale vertalingsmodelle dikwels onder uitvoer op taal pare met onvoldoende onderwerking data. As 'n gevolg en relativief paar eksperimente is uitgevoer deur hierdie arkitektuur te gebruik op lae hulpbron taal paar. In hierdie studie en hiperparameter optimaliseer van Transformer modele in die vertaling van die lae- hulpbron Engels- Irse taal paar is uitgewerk. Ons wys dat die kies van geskikte parameters lei na betekende prestasie verbeteringe. Die mees belangrik en die korrekte keuse van subwoord model is vertoon om die grootste drywer van vertaling uitvoer te wees. SentencePiece-modelles wat beide unigram en BPE toegang gebruik word, is verondersoek. Veranderinge op model arkitektuure het ingesluit om die aantal laag te verander en verskillende regularisasie teknike te testeer en die optimale aantal kop vir aandag te evalueer. 'n Algemeen 55k DGT corpus en 'n in-domein 88k publieke administreer corpus was gebruik vir evaluering. 'n Transformeerder optimaliseerde model het 'n BLEU-poeier verbetering van 7.8 punte gedemonstreer wanneer vergelyk word met 'n basisline RNN-model. Verbeterings is aangesien deur 'n reek van metries en insluitend TER en indiek 'n vaste verdubbelde post redigeringsversoek vir Transformer optimaliseerde modele met 16k BPE subwoord modele. Bench-merk teen Google Vertaling en ons vertaling masjiene het betekende verbeteringe bevestig. Die vraag van of Transformers kan wees of nie\nwat effektief gebruik word in 'n lae-hulpbron instelling van Engels-Irse vertaling is gespreek. Is feidier linn - ja, ons kan.", 'cs': 'Model Transformer je nejmodernější v oblasti strojového překladu. Nicméně a obecně i neuronové překladové modely často nedostatečně fungují na jazykových párech s nedostatečnými tréninkovými daty. V důsledku toho bylo provedeno relativně málo experimentů s využitím této architektury na jazykových párech s nízkými zdroji. V této práci je vyhodnocena hyperparametrová optimalizace transformátorových modelů při překladu nízkých zdrojů anglicko-irského jazykového páru. Dokazujeme, že volba vhodných parametrů vede ke značnému zlepšení výkonu. Nejdůležitější je, že správný výběr modelu podslov je ukázána jako největší hnací motor výkonu překladu. Byly zhodnoceny modely SentencePiece využívající unigramový i BPE přístup. Variace modelových architektur zahrnovaly úpravu počtu vrstev a testování různých regulačních technik a vyhodnocení optimálního počtu hlav pro pozornost. Pro hodnocení byl použit generický 55k DGT korpus a in-domain 88k veřejný administrativní korpus. Model optimalizovaný transformátorem prokázal zlepšení skóre BLEU o 7,8 body ve srovnání se základním RNN modelem. Zlepšení bylo pozorováno v řadě metrik, včetně TER, a naznačuje výrazně sníženou námahu po editaci u Transformeru optimalizovaných modelů s 16k BPE podslovními modely. Porovnání s překladačem Google a našimi překladači prokázalo výrazné zlepšení. Otázka, zda transformátory mohou být nebo ne\nBylo řešeno účinně používané v nízkých zdrojích prostředcích anglicko-irského překladu. Je Feidir Linn. Ano, můžeme.', 'az': 'Transformer modeli maşın çevirindəki sanatın durumu. Lakin genel və nöral tercümə modelləri çox dəyişiklik təhsil məlumatları ilə dil çiftlərdə işlədilər. Növbəti olaraq və qohum-qohum az eksperimentlər bu arhitektura düşük ressurs dillərin çiftlərinə istifadə edilmişdir. Bu təhsil və hiperParametri Transformer modellərin çoxluğu İngilizə-İrlandalı dil çiftlərini tercümə etmək üçün baxılır. Biz göstəririk ki, uyğun parametrləri seçmək böyük performanslıq düzəltmələrinə yol göstərir. Ən böyük və doğru söz modelinin seçimi, tercümə performansının ən böyük sürücüsü göstəriləcəkdir. Sentence Piece modelləri hər ikisini və BPE yaxınlıqlarını istifadə edirlər. Model arhitektürlərinin dəyişiklikləri, səviyyənin sayını dəyişdirmək və müxtəlif düzgünlük tekniklərini sınamaq və gözləmək üçün başlıqların optimal sayını değerləşdirmək içərisində idi. Növbəti 55k DGT korpusu və 88k kamu admin korpusu değerlendirmək üçün istifadə edildi. Transformer optimizləndirilmiş modeli, baz sətir RNN modeli ilə qarşılaşdığı zaman BLEU nöqtəsinin 7.8 nöqtəsini yaxşılaşdırmasını göstərdi. Üstünlüklər metriklərin bir səviyyəsində və TER də dahil edildi və XVI BPE altı söz modelləri ilə Transformer üçün çox azaltılmış post editing effort göstərildi. Google Translate və çevirim maşınlarımızın qarşısında möhkəm düzəltmələri göstərildi. Transformers mümkün olmadığını soruşmaq\nİngilis-İrlandalı tercümələrinin düşük-kaynaklı qurulmasında istifadə edilmişdir. Feidir Linn - evet biz edə bilərik.', 'sq': 'The Transformer model is the state-of-the-art in Machine Translation.  Megjithatë dhe në përgjithësi dhe modelet e përkthimit nervor shpesh shfaqen në çifte gjuhësh me të dhëna të pamjaftueshme trajnimi. Si pasojë dhe relativisht pak eksperimente janë kryer duke përdorur këtë arkitekturë në çifte gjuhësh me burime të ulëta. Në këtë studim dhe optimizmi i hiperparametrave të modeleve Transformer në përkthimin e çiftit të gjuhës anglo-irlandeze me burime të ulta është vlerësuar. Ne demonstrojmë se zgjedhja e parametrave të përshtatshëm shpie në përmirësime të konsiderueshme të performancës. Më e rëndësishmja dhe zgjedhja e saktë e modelit të nënfjalëve tregohet se është motori më i madh i shfaqjes së përkthimit. U vlerësuan modelet SentencePiece duke përdorur si unigram ashtu edhe BPE metodat. Variatat në arkitekturat e modelit përfshijnë modifikimin e numrit të shtresave dhe testimin e teknikave të ndryshme të rregullimit dhe vlerësimin e numrit optimal të kokave për vëmendje. Për vlerësim u përdorën një korpus gjeneral 55k DGT dhe një korpus administrator publik 88k në domeni. Një model i optimizuar Transformer demonstroi një përmirësim në rezultatin BLEU prej 7.8 pikë kur krahasohet me një model RNN bazë. Përmirësimet u vëzhguan nëpër një gamë metrike dhe përfshirë TER dhe tregojnë një përpjekje të reduktuar thelbësisht pas redigimit për modelet optimizuar të Transformer me modele 16 k BPE nënfjalësh. Bench-shënuar kundër Google Translate dhe motorët tonë të përkthimit treguan përmirësime të rëndësishme. Pyetja nëse Transformuesit mund të jenë apo jo\nështë përdorur efektivisht në një bazë burimesh të ulëta të përkthimit anglo-irlandez. A është Feidir Lin - po mundemi.', 'et': 'Transformeri mudel on masintõlke tipptasemel. Kuid üldiselt ja närvitõlkemudelid on sageli ebapiisavate koolitusandmetega keelepaaride puhul ebapiisavad. Selle tulemusena on seda arhitektuuri kasutades tehtud suhteliselt vähe katseid vähese ressursiga keelepaaridel. Käesolevas uuringus hinnatakse Transformeri mudelite hüperparameetrite optimeerimist madala ressursiga inglise-iiri keele paari tõlkimisel. Näitame, et sobivate parameetrite valik toob kaasa märkimisväärse jõudluse paranemise. Kõige tähtsam on see, et alamsõna mudeli õige valik on tõlke jõudluse suurim tõukejõud. Hinnati SentencePiece mudeleid, mis kasutasid nii unigrammi kui ka BPE lähenemist. Mudeliarhitektuuride variatsioonid hõlmasid kihtide arvu muutmist ja erinevate regulatsioonitehnikate katsetamist ning tähelepanu pööravate peade optimaalse arvu hindamist. Hindamiseks kasutati üldist 55k DGT korpust ja 88k avalikku halduskorpust. Transformeri optimeeritud mudel näitas BLEU skoori paranemist 7,8 punkti võrreldes algse RNN mudeliga. Parandusi täheldati mitmetes mõõdikutes, sealhulgas TER-is, ning see näitab, et Transformeri optimeeritud mudelite puhul, millel on 16k BPE alamsõnamudelid, on oluliselt vähenenud pärast redigeerimist. Google Tõlke ja meie tõlkemootorid näitasid märkimisväärseid edusamme. Küsimus, kas transformaatorid võivad olla\non käsitletud tõhusat kasutamist inglise-iiri tõlke vähese ressursiga keskkonnas. On Feidir Linn - jah me saame.', 'fi': 'Transformer-malli on konekäännöksen uusinta tekniikkaa. Yleisesti ottaen sekä neurokäännösmallit toimivat kuitenkin usein huonosti kielipareilla, joilla ei ole riittävästi harjoitustietoa. Tämän seurauksena tätä arkkitehtuuria käyttäen on tehty suhteellisen vähän kokeiluja vähäresurssisille kielipareille. Tässä tutkimuksessa arvioidaan Transformer-mallien hyperparametrioptimointia vähäresurssisen englannin ja irlantin kieliparin kääntämisessä. Osoitamme, että sopivien parametrien valitseminen johtaa huomattaviin suorituskykyparannuksiin. Mikä tärkeintä, ja oikea alasanamalli on osoitettu olevan suurin kääntämisen suorituskykyä edistävä tekijä. Arvioitiin SentencePiece-malleja käyttäen sekä unigram- että BPE-lähestymistapoja. Malliarkkitehtuurin variaatioihin kuului kerrosten määrän muokkaaminen ja erilaisten regularisointitekniikoiden testaaminen sekä optimaalisen päiden määrän arviointi huomiolle. Arvioinnissa käytettiin yleistä 55k DGT-korpusta ja 88k julkista hallintokorpusta. Transformer-optimoitu malli osoitti BLEU-pisteen parannuksen 7,8 pistettä verrattuna RNN-malliin. Parannuksia havaittiin useissa mittareissa, mukaan lukien TER, ja ne osoittivat, että Transformer-optimoiduissa malleissa, joissa on 16k BPE-alasanamalleja, oli huomattavasti vähemmän jälkimuokkaustyötä. Google Translaten ja käännösmoottoreidemme vertailu osoitti merkittäviä parannuksia. Kysymys siitä, voidaanko muuntajat olla\nTässä työssä on käsitelty tehokkaasti englannin-irlantilaisen käännöksen vähäisiä resursseja. On Feidir Linn - kyllä voimme.', 'ca': "El model Transformer és l'última en la traducció màquina. Tot i així, i en general, els models de traducció neuronal sovint són executats en parelles de llenguatges amb insuficients dades d'entrenament. Com a conseqüència i relativament pocs experiments s'han fet utilitzant aquesta arquitectura en parells de llengües de baix recursos. En aquest estudi i l'optimització hiperparamètrica dels models Transformer en la traducció del parell de llenguatge anglès-irlandès de baix recursos es valora. Demostram que escollir paràmetres adequats porta a millores consideràries en el rendiment. El més important és que l'elecció correcta del model de subparaules és el principal motor de la traducció. Es van evaluar els models SentencePiece que utilitzaven enfocaments unigram i BPE. Les variacions en arquitectures models van incloure modificar el nombre de capes i provar diverses tècniques de regularizació i evaluar el nombre optim de cabells a l'atenció. Un corps genèric de DGT 55k i un corps administratiu públic en domini 88k van ser utilitzats per a l'evaluació. Un model optimitzat de Transformer va demostrar una millora de 7,8 punts en la puntuació BLEU en comparació amb un model RNN basal. Es van observar millors a través d'una gama de mètriques, incloent TER, i indicant un esforç substancialment reduït d'edició per models optimitzats de Transformer amb models de subparaules BPE de 16k. Comparat amb Google Translate i els nostres motors de traducció van demostrar millores significatives. La qüestió de si els transformadors poden ser\ns'ha utilitzat efectivament en un entorn de baix recursos de traducció anglo-irlandès. És feidir Lin - sí que podem.", 'jv': 'Transform Kamunyatan karo hal-hal, model penting itoleh alat kuwi, nik sak nguasai pernik language karo data sing gak tentang. Rasane dadi lan nganggo perbudhakan yakuwis neng akeh operasi dadi nggambar architecture iki ning kelas-kelas barang. Nang barêng-barêng iki dadi kapan cap perusahaan Transformer model kuwi nggambar kelas-Ressource Inggris-Erse nganggep kuwi nggambar. Awak dhéwé éntuk sing beraksi Parameter sing apik dadi nggawe akeh bantuan ngono nggawe barang nggawe barang. Laptop" and "Desktop Name Variation on model architecture Una generic 58k DGT carpus lan jewel-jewel kanggo mbanjuraké babagan kanggo tahirbahi tanggal. Transformer Optimisasi model sing bisalui nggambar barang blo batar 7.8 punti nang nggawe geraraning karo model sing di ambarung DNN. word Bench-marked rabi karo Google translation karo engin terjamahan sing bisa nggambar atus neng banter sing apik. Transform\ntranslation Ing luwih luwih apik - apik dhéwé iso ngomong.', 'ha': "@ info: status @ label As a consequence and relatively few experiments have been carried out using this architecture on low-resource language pairs.  @ info: whatsthis Tuna nũna cewa, ka zãɓi parameteri masu daidai, yana iya ƙara mafarin aiki mai girma. An nuna mafi girma ga tafiyar da zaman shawarar fassarar. Piece-motel da ke amfani da both unigram and BLE hanyõyin. Gujarati masu sakan kayan daidaita misalin na include an canza tsarin layuka da aka jarraba zanen jujjuya masu buƙata kuma an ƙaddara ƙidãyar launin sunayen da za'a yi sauna. KCharselect unicode block name An nuna wata shirin Transformer da aka siffantar ta BLEU score mai kyau wa point 7.8 idan an sami da wata misali na RNN. An nuna kewayi cikin tsakanin metric da ke ƙunsa da TeR kuma an nuna wata ƙaranci da aikin hagarin bayani na taƙaita wa motel na Tsarin da aka yi amfani da 16k BLE na ƙarƙashin maganar. @ info: whatsthis Socket error code ConnectionTimeout\nhas been addressed. Ita'a Fedir linn - Na'am tuna.", 'he': 'המודל הטרנספורטר הוא המדינה המאומנת בתרגום מכונות. בכל אופן ובכלל ודוגמנים של תרגום עצבי לעתים קרובות מופיעים על זוגות שפות עם נתונים אימונים לא מספיקים. כתוצאה מכך וביחסית מעט ניסויים נעשו באמצעות הארכיטקטורה הזאת על זוגות שפות נמוכות משאבים. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated.  אנחנו מראים שבחירת פרמטרים מתאימים מובילה לשיפורים משמעותיים ביצועים. החשוב ביותר והבחירה הנכונה של מודל מתחת מילים מוצגת להיות הנהג הגדול ביותר של ביצועי התרגום. מודלים של SentencePiece שמשתמשים גם ניתוחים unigram וגם BPE הוערכו. שינויים על ארכיטקטורות דוגמניות כוללו שינוי מספר שכבות ובדיקות טכניקות רגילות שונות ובדיקות מספר האופטימלי של ראשים לשימוש לב. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation.  מודל אופטימיזם טרנספורר הראה שיפור בתוצאות BLEU של 7.8 נקודות בהשוואה לדוגמא RNN בסיסית. השיפורים נצפו באמצעות טווח של מטריקה, כולל TER, והמצביעים על מאמץ אחר העורה מופחד באופן משמעותי עבור דוגמנים אופטימיים של Transformer עם דוגמנים מתחת מילים BPE 16k. מצוין נגד Google Translate ומנועי התרגום שלנו הראו שיפורים משמעותיים. השאלה של האם מעצבים יכולים להיות\nהשתמשו באופן יעיל בסיס משאבים נמוכים של התרגום אנגלי-אירי. האם פידיר לין - כן אנחנו יכולים.', 'sk': 'Model Transformer je najsodobnejši v strojnem prevajanju. Vendar in na splošno in nevronski prevajalni modeli pogosto slabo delujejo na jezikovnih parih z nezadostnimi podatki o usposabljanju. Posledično je bilo izvedenih relativno malo eksperimentov z uporabo te arhitekture na jezikovnih parih z nizkimi viri. V tej študiji je ovrednotena optimizacija hiperparametrov transformatorskih modelov pri prevajanju angleško-irskega jezikovnega pare z nizkimi viri. Dokazujemo, da izbira ustreznih parametrov vodi do znatnih izboljšav zmogljivosti. Najpomembnejše je, da je pravilna izbira modela podbesed največja gonilna sila uspešnosti prevajanja. Ocenjeni so bili modeli SentencePiece z uporabo unigramskega in BPE pristopa. Variacije modelnih arhitektur so vključevale spreminjanje števila plasti in testiranje različnih tehnik regulacije ter ocenjevanje optimalnega števila glav za pozornost. Za vrednotenje sta bila uporabljena splošni korpus DGT 55k in javni upravni korpus 88k v domeni. Model optimiziran s transformatorjem je pokazal izboljšanje rezultata BLEU za 7,8 točke v primerjavi z izhodiščnim modelom RNN. Izboljšave so bile opažene v različnih metrikah, vključno s TER, kar kaže na bistveno zmanjšan napor po urejanju modelov optimiziranih s transformatorjem z 16k BPE podbesednimi modeli. Na primerjavi z Google Translate in našimi prevajalniki so pokazali znatne izboljšave. Vprašanje, ali lahko transformatorji\nobravnavani so bili učinkovito uporabljeni v okolju nizkih virov angleško-irskega prevoda. Je Feidir Linn - ja lahko.', 'bo': 'འགྱུར་མ་བརྒྱུད་པའི་མ་དབྱིབས་ནི་ལག་འཁྱེར་ལ་གནས་སྟངས་དང་གནས་སྟངས ཡིན་ནའང་། སྤྱིར་བཏང་དང་ནུས་ཀྱི་དཔེ་དབྱིབས་ནི་སྐད་ཡིག་ཆ་གཉིས་ཀྱིས་རྒྱུན་ལྡན་གྱི་མིང་དཔྱད་རྣམས་ལས་ཕ གནད་དོན་འབྱུང་བ་དང་འབྲེལ་བའི་སྐྱེས་ཆེན་ཉུང་བའི་སྒྲིག་འགོད་འདི་སྤྱོད་རྒྱུ་ཙམ་བྱུང་བ་རེད། In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. ཆེས་ཤོས་གལ་ཆེ་ཤོས་ཡོད་པ་དང་གདམ་ཁ་ཡིག་གི་རྣམ་པ Sentence Piece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various regularization techniques and evaluating the optimal number of heads for attention. སྤྱིར་བཏང་བའི་མཐུང་འབྲེལ་55k DGT མཁན་དང་ཁོང་གི་ཚད་ལྟར་འཛིན་པ་88k ཡིན། Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline RNN model. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Google Translate་དང་ང་ཚོའི་ཡིག དབྱིབས་སྒྱུར་ཆས་འདིས་ཡིན་མིན་དགོས་མིན་འདུག\nདབྱིན་ཡིག་དང་རྒྱལ་ཡིག་གི་སྐད་རིགས་ཆ་ཉུང་བའི་སྒྲིག་འགོད་ནང་དུ་སྤྱད་ཡོད་པ འདི་དག་ཕྱིར་མདངས་པོ་ཞིག་ཡིན།'}
{'en': 'The Effect of Domain and Diacritics in YorubaEnglish Neural Machine Translation Y oruba– E nglish Neural Machine Translation', 'ar': 'تأثير المجال وعلامات التشكيل في الترجمة الآلية العصبية اليوروبية-الإنجليزية', 'fr': "L'effet du domaine et des signes diacritiques dans la traduction automatique neuronale yoruba—anglais", 'pt': 'O efeito do domínio e diacríticos na tradução automática neural iorubá-inglês', 'es': 'El efecto del dominio y los signos diacríticos en yoruba-inglés Traducción automática neuronal', 'ja': 'ヨルバ語-英語ニューラル・マシン・トランスレーションにおけるドメインとダイアクリティックの効果', 'zh': '域变音符号在约鲁巴语-英语神经机器翻译中', 'hi': 'योरुबा-अंग्रेजी न्यूरल मशीन अनुवाद में डोमेन और डायक्रिटिक्स का प्रभाव', 'ru': 'Влияние домена и диакритических знаков в иоруба-английском нейронном машинном переводе', 'ga': 'An Éifeacht Fearainn agus Diacritics in Iarúibis–An Béarla Neural Machine Translation', 'hu': 'A tartomány és a diakritikusok hatása a yoruba-angol neurális gépi fordításban', 'it': "L'effetto del dominio e della diacritica nella traduzione automatica neurale yoruba-inglese", 'kk': 'Йоруба- ағылшын нейралық машинаның аудармасындағы доменге және диакриттердің эффекті', 'mk': 'The Effect of Domain and Diacritics in Yoruba-English Neural Machine Translation', 'ka': 'Name', 'el': 'Η επίδραση του Τομέα και των Διακριτών στην Αγγλική Νευρική Μηχανική Μετάφραση', 'ms': 'Kesan Domain dan Diakritik dalam Perjemahan Mesin Neural Yoruba-Inggeris', 'ml': 'യൊരുബാ- ഇംഗ്ലീഷ് നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതില്\u200d ഡൊമെയിനും ഡയക്രിസ്റ്റുകളുടെയും പ്', 'mn': 'Йорбу-Англи хэлний мэдрэлийн машин хөгжүүлэх домон болон диагностикуудын нөлөө', 'lt': 'Domeno ir diakritikų poveikis Yoruba-anglų vertimui nervinėmis mašinomis', 'mt': 'L-Effett tad-Dominju u d-Dijakritiċi fit-Traduzzjoni tal-Magna Newrali Yoruba-Ingliż', 'no': 'Effekt for domene og diakritikk i Yoruba- engelsk neuralmaskineomsetjing', 'sr': 'Efekt domena i dijakritika u Yoruba-engleskom neurološkom prevodu mašine', 'pl': 'Wpływ domeny i diakrytyki w językowo-angielskim neuronowym tłumaczeniu maszynowym', 'ro': 'Efectul domeniului și diacriticii în traducerea automată neurală yoruba-engleză', 'si': 'Name', 'so': 'Effect of Domain and Diacritics in Yoruba- Ingiriis Neural Machine Translation', 'sv': 'Effekten av domän och diakritiker i Yoruba-engelska neural maskinöversättning', 'ta': 'Name', 'ur': 'یوروبو-انگلیسی نیورال ماشین ترجمہ میں ڈومین اور دیاٹریک کے اثر', 'uz': 'Name', 'vi': 'The Effect of Domain and Diacritics in Yoruba-English Neural Machine Translation', 'da': 'Virkningen af domæne og diakritik i Yoruba-engelsk neural maskinoversættelse', 'nl': 'Het effect van domein en diacritica in Yoruba-Engelse neurale machinevertaling', 'bg': 'Ефектът на домейна и диакритиката в йоруба-английски неврален машинен превод', 'ko': '요르바어 영어 신경 기계 번역 중의 역과 변음 기호 효과', 'hr': 'Učinak domena i dijakreta u Yoruba- engleskom neurološkom prevodu stroja', 'de': 'Die Wirkung von Domänen und Diakritiken in Yoruba-Englisch neuronale maschinelle Übersetzung', 'fa': 'اثر دامین و دیاکریک\u200cها در ترجمه ماشین عصبی یوروبا-انگلیسی', 'tr': 'Yoruba-Iňlisçe Neural Makina terjimesinde sahypa we çykyşlaryň etkisi', 'af': 'Name', 'id': 'Efek Domain dan Diacritics dalam Perjemahan Mesin Neural Yoruba-Inggris', 'am': 'በዮሩባ- እንግሊዝኛ ነዌral ማሻሻን ትርጓሜ ውስጥ የዶሜን እና ዲያክሪካውያን ጥቅም', 'sw': 'The Effect of Domain and Diacritics in Yoruba-English Neural Machine Translation', 'hy': 'Յորուբա-անգլերեն նյարդային մեքենայի թարգմանման դեպքը', 'az': 'Yoruba-캻ngilizce N칬ral Makina 칂evirm톛sind톛ki Domain v톛 Diakritikl톛rin Etkisi', 'bn': 'ইয়রুবা- ইংরেজী নিউরাল মেশিন অনুবাদে ডোমেইন এবং ডায়ারিক্টরের প্রভাব', 'bs': 'Efekt domena i dijakreta u Yoruba-engleskom neurološkom prevodu stroja', 'cs': 'Vliv domény a diakritiky v yorubštině-anglickém neurálním strojovém překladu', 'et': 'Domeeni ja diakriitika mõju Yoruba-inglise neuraalses masintõlkes', 'sq': 'Efekti i Domenit dhe Diakritikëve në përkthimin e Makinës Neurale Joruba-Angleze', 'fi': 'Verkkotunnuksen ja diakriitikkojen vaikutus yoruba-englanti neuraalinen konekäännös', 'ca': "L'efecte de domini i diàcrítics en la traducció de la màquina neuronal yoruba-anglès", 'jv': 'Effect of domain and diacrits in', 'sk': 'Učinek domene in diakritik v yorubsko-angleškem nevralnem strojnem prevajanju', 'ha': 'Effect of Domen and Diakris in Yoruba- English Neural Machine Translate', 'he': 'השפעה של דומין ודיאבקריטים בתרגום מכונת נוירובית יורובה-אנגלית', 'bo': 'ཡོར་བ་དང་དབྱིན་ཡིག་གི་མི་རྩིས་འཁྲུལ་གྱི་འགྱུར་བ་དང་ཕྱོགས་སྐྱོན་ཆས་ཀྱི་གནོད་འགྱུར་བ།'}
{'en': 'Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs. However and these  models  are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets. In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for YorubaEnglish with standardized train-test splits for benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains. Since these pre-trained models use huge amounts of data with uncertain quality and we also analyze the effect of diacritics and a major characteristic of  Yoruba  and in the training data. We investigate how and when this training condition affects the final quality of a translation and its understandability. Our  models  outperform massively multilingual models such as Google (+8.7 BLEU) and Facebook M2 M (+9.1) when translating to  Yoruba  and setting a high quality benchmark for future research. +8.7  BLEU) and Facebook M2M ( +9.1 ) when translating to Yoruba and setting a high quality benchmark for future research.', 'ar': 'أظهرت الترجمة الآلية متعددة اللغات (MT) قدرات رائعة بما في ذلك الترجمة الصفرية والقليلة بين أزواج اللغات منخفضة الموارد. ومع ذلك ، غالبًا ما يتم تقييم هذه النماذج على اللغات عالية الموارد بافتراض أنها تعمم على اللغات منخفضة الموارد. غالبًا ما ترجع صعوبة تقييم نماذج الترجمة الآلية على الأزواج منخفضة الموارد إلى نقص مجموعات بيانات التقييم الموحدة. في هذه الورقة ، نقدم MENYO-20k وأول مجموعة موازية متعددة المجالات مع قواعد إملاء منسقة بشكل خاص لليوروبا الإنجليزية مع تقسيمات اختبار تدريب موحدة للمعايير. نحن نقدم العديد من معايير الترجمة الآلية العصبية ونقارنها بأداء نماذج الترجمة الآلية الشهيرة (متعددة اللغات على نطاق واسع) المدربة مسبقًا لكل من مجموعة الاختبار غير المتجانسة والمجالات الفرعية الخاصة بها. نظرًا لأن هذه النماذج المدربة مسبقًا تستخدم كميات هائلة من البيانات بجودة غير مؤكدة ، ونقوم أيضًا بتحليل تأثير علامات التشكيل والخصائص الرئيسية لليوروبا وفي بيانات التدريب. نتحرى كيف ومتى تؤثر حالة التدريب هذه على الجودة النهائية للترجمة ومدى قابليتها للفهم. تتفوق نماذجنا بشكل كبير على النماذج متعددة اللغات مثل Google (+8.7 BLEU) و Facebook M2M (+9.1) عند الترجمة إلى Yoruba ووضع معايير عالية الجودة للبحث في المستقبل.', 'es': 'La traducción automática (MT) masivamente multilingüe ha demostrado capacidades impresionantes e incluye una traducción cero y de pocos intentos entre pares de idiomas de bajos recursos. Sin embargo, estos modelos a menudo se evalúan en lenguajes de recursos altos con el supuesto de que se generalizan a idiomas de bajos recursos. La dificultad de evaluar los modelos de MT en pares de bajos recursos se debe a menudo a la falta de conjuntos de datos de evaluación estandarizados. En este artículo presentamos Menyo-20k y el primer corpus paralelo multidominio con una ortografía especialmente seleccionada para yoruba-inglés con divisiones estandarizadas de prueba y entrenamiento para la evaluación comparativa. Proporcionamos varios puntos de referencia de MT neuronal y los comparamos con el rendimiento de los populares modelos de MT preentrenados (masivamente multilingües) tanto para el conjunto de pruebas heterogéneas como para sus subdominios. Dado que estos modelos preentrenados utilizan enormes cantidades de datos con una calidad incierta, también analizamos el efecto de los diacríticos y una característica principal del yoruba y en los datos de entrenamiento. Investigamos cómo y cuándo esta condición de entrenamiento afecta a la calidad final de una traducción y a su comprensibilidad.Nuestros modelos superan ampliamente a los modelos multilingües como Google (+8,7 BLEU) y Facebook M2M (+9,1) al traducir al yoruba y establecer un punto de referencia de alta calidad para futuras investigaciones.', 'pt': 'A tradução automática (MT) multilíngue em massa mostrou recursos impressionantes e inclui tradução zero e poucos tiros entre pares de idiomas com poucos recursos. No entanto, esses modelos são frequentemente avaliados em linguagens de alto recurso com a suposição de que eles generalizam para linguagens de baixo recurso. A dificuldade de avaliar modelos de MT em pares de poucos recursos é muitas vezes devido à falta de conjuntos de dados de avaliação padronizados. Neste artigo apresentamos o MENYO-20k e o primeiro corpus paralelo multidomínio com uma ortografia especialmente selecionada para iorubá-inglês com divisões padronizadas de teste de treinamento para benchmarking. Fornecemos vários benchmarks de MT neural e os comparamos com o desempenho de modelos populares de MT pré-treinados (massivamente multilíngues), tanto para o conjunto de teste heterogêneo quanto para seus subdomínios. Uma vez que esses modelos pré-treinados utilizam enormes quantidades de dados com qualidade incerta e também analisamos o efeito dos diacríticos e uma das principais características dos iorubás e nos dados de treinamento. Investigamos como e quando essa condição de treinamento afeta a qualidade final de uma tradução e sua compreensão. Nossos modelos superam modelos multilíngues massivamente como Google (+8,7 BLEU) e Facebook M2M (+9,1) ao traduzir para iorubá e definir um benchmark de alta qualidade para futuras pesquisas.', 'fr': "La traduction automatique (TA) massivement multilingue a fait preuve de capacités impressionnantes, y compris la traduction zéro ou peu de temps entre des paires de langues à faibles ressources. Cependant, ces modèles sont souvent évalués sur des langues à ressources élevées en supposant qu'ils se généralisent aux langues à faibles ressources. La difficulté d'évaluer des modèles de MT sur des paires de ressources faibles est souvent due au manque de jeux de données d'évaluation normalisés. Dans cet article, nous présentons Menyo-20k et le premier corpus parallèle multi-domaines avec une orthographe spécialement conçue pour le yoruba—anglais avec des séparations de train-test standardisées pour l'étalonnage. Nous fournissons plusieurs benchmarks de TA neuronale et les comparons aux performances des modèles de TA pré-entraînés (massivement multilingues) populaires, à la fois pour l'ensemble de tests hétérogène et ses sous-domaines. Étant donné que ces modèles pré-entraînés utilisent d'énormes quantités de données dont la qualité est incertaine, nous analysons également l'effet des signes diacritiques et d'une caractéristique majeure du Yoruba et dans les données d'entraînement. Nous étudions comment et quand cette condition de formation affecte la qualité finale d'une traduction et sa compréhensibilité. Nos modèles surpassent largement les modèles multilingues tels que Google (+8,7 BLEU) et Facebook M2M (+9,1) lorsqu'ils traduisent en yoruba et établissent une référence de qualité élevée pour les recherches futures.", 'ja': '大規模な多言語機械翻訳（ MT ）は、低リソース言語ペア間のゼロおよび数ショット翻訳を含む印象的な機能を示しています。 しかしながら、これらのモデルはしばしば低リソース言語に一般化することを前提として、高リソース言語で評価される。 リソースの少ないペアでMTモデルを評価することが困難なのは、標準化された評価データセットの欠如に起因することが多い。 本稿では、MENYO -20 kと、ベンチマークのための標準化されたトレインテストスプリットを備えたヨルバ語-英語のための特別にキュレーションされた正書法を備えた最初のマルチドメイン並列コーパスを紹介します。 当社は、いくつかのニューラルMTベンチマークを提供し、異種試験器とそのサブドメインの両方について、人気のある事前訓練（大規模多言語） MTモデルのパフォーマンスと比較します。 これらの事前にトレーニングされたモデルは、品質が不確実な膨大なデータを使用しているため、ダイアクリティックの効果と、ヨルバとトレーニングデータの大きな特徴も分析しています。 このトレーニング条件が翻訳の最終的な品質とその理解性にどのように、いつ影響するかを調査します。Google （+8.7 BLEU ）やFacebook M 2 M （+9.1 ）などの多言語モデルを上回るモデルは、ヨルバ語に翻訳し、将来の研究のために高品質のベンチマークを設定する際に役立ちます。', 'hi': 'बड़े पैमाने पर बहुभाषी मशीन अनुवाद (एमटी) ने प्रभावशाली क्षमताओं को दिखाया है और कम-संसाधन भाषा जोड़े के बीच शून्य और कुछ-शॉट अनुवाद सहित। हालांकि और इन मॉडलों को अक्सर उच्च-संसाधन भाषाओं पर इस धारणा के साथ मूल्यांकन किया जाता है कि वे कम-संसाधन वाले लोगों के लिए सामान्यीकरण करते हैं। कम-संसाधन जोड़े पर एमटी मॉडल का मूल्यांकन करने की कठिनाई अक्सर मानकीकृत मूल्यांकन डेटासेट की कमी के कारण होती है। इस पेपर में और हम MENYO-20k और बेंचमार्किंग के लिए मानकीकृत ट्रेन-टेस्ट विभाजन के साथ योरुबा-अंग्रेजी के लिए विशेष रूप से क्यूरेटेड ऑर्थोग्राफी के साथ पहला बहु-डोमेन समानांतर कॉर्पस प्रस्तुत करते हैं। हम कई तंत्रिका एमटी बेंचमार्क प्रदान करते हैं और उनकी तुलना लोकप्रिय पूर्व-प्रशिक्षित (बड़े पैमाने पर बहुभाषी) एमटी मॉडल के प्रदर्शन से करते हैं, दोनों विषम परीक्षण सेट और इसके उप-डोमेन के लिए। चूंकि ये पूर्व-प्रशिक्षित मॉडल अनिश्चित गुणवत्ता के साथ बड़ी मात्रा में डेटा का उपयोग करते हैं और हम डायक्रिटिक्स के प्रभाव और योरुबा की एक प्रमुख विशेषता और प्रशिक्षण डेटा में भी विश्लेषण करते हैं। हम जांच करते हैं कि यह प्रशिक्षण स्थिति अनुवाद की अंतिम गुणवत्ता और इसकी समझ को कैसे और कब प्रभावित करती है। हमारे मॉडल बड़े पैमाने पर बहुभाषी मॉडल जैसे Google (+8.7 BLEU) और Facebook M2M (+9.1) को मात देते हैं जब योरुबा में अनुवाद करते हैं और भविष्य के शोध के लिए एक उच्च गुणवत्ता बेंचमार्क स्थापित करते हैं।', 'zh': '多言机器翻译 (MT) 已见深功,低资源言零次少转。 然常质于高资言语,假令推广低资源语。 于低资源对上评估机器翻译模形之难,常以乏标准化之评数集。 本文,言MENYO-20k与首多域并行语料库,语料库有特画之约鲁巴语 - 英语正字法,并有标准化之教拆分以准之。 给数神经机器翻译准试,与异构试集及子域流预训练(大多语言)机器翻译模形之性。 凡此诸数,变音符约鲁巴语数之大征也。 按此培训所以及何时译者,究其可解性。 吾形于翻译成约鲁巴语时优于Google(+8.7 BLEU)、Facebook M2M(+9.1)等大多言模,并为未来之论定高质量基准。', 'ru': 'Массовый многоязычный машинный перевод (МТ) показал впечатляющие возможности и включал нулевой и маломощный перевод между языковыми парами с низкими ресурсами. Однако и эти модели часто оцениваются на высокоресурсных языках с допущением, что они обобщают до низкоресурсных. Трудность оценки моделей МП на парах с низким уровнем ресурсов часто связана с отсутствием стандартизированных наборов оценочных данных. В этой статье и мы представляем MENYO-20k и первый многодоменный параллельный корпус с специально курируемой орфографией для Yoruba-English со стандартизированными разделениями поезда-теста для бенчмаркинга. Мы предоставляем несколько нейронных реперов МТ и сравниваем их с производительностью популярных предварительно обученных (массово многоязычных) моделей МТ как для гетерогенного тестового набора, так и его поддоменов. Поскольку эти предварительно обученные модели используют огромное количество данных с неопределенным качеством, мы также анализируем влияние диакритических знаков и основную характеристику Yoruba и в обучающих данных. Мы исследуем, как и когда это условие обучения влияет на конечное качество перевода и его понятность. Наши модели значительно превосходят многоязычные модели, такие как Google (+8,7 BLEU) и Facebook M2M (+9,1), при переводе на Yoruba и установлении высококачественного эталона для будущих исследований.', 'ga': 'Léirigh aistriúchán meaisín ollmhór ilteangach (MT) cumais shuntasacha lena n-áirítear aistriúchán nialasach agus cúpla seat idir péirí teangacha íseal-acmhainne. Mar sin féin agus is minic a dhéantar na samhlacha seo a mheas ar theangacha ard-acmhainne agus an toimhde go ndéantar ginearálú orthu go cinn a bhfuil acmhainní ísle acu. Is minic go mbíonn an deacracht a bhaineann le measúnú a dhéanamh ar mhúnlaí MT ar phéirí acmhainní ísle mar gheall ar easpa tacair sonraí caighdeánaithe meastóireachta. Sa pháipéar seo agus cuirimid i láthair MENYO-20k agus an chéad chorpas comhthreomhar ilfhearann a bhfuil ortagrafaíocht go háirithe coimeádta don Iarúibis-Béarla le scoilteanna tástála traenach caighdeánaithe le haghaidh tagarmharcála. Soláthraímid roinnt tagarmharcanna néaracha MT agus cuirimid i gcomparáid iad le feidhmíocht samhlacha MT réamhoilte (ollmhór ilteangach) a bhfuil tóir orthu don tacar tástála ilchineálach agus dá fhofhearainn. Ós rud é go n-úsáideann na samhlacha réamh-oilte seo méideanna ollmhóra sonraí le cáilíocht neamhchinnte agus déanaimid anailís freisin ar éifeacht diacritics agus ar shaintréith mhór Iarúibis agus sna sonraí oiliúna. Déanaimid imscrúdú ar conas agus cathain a théann an riocht oiliúna seo i bhfeidhm ar cháilíocht deiridh an aistriúcháin agus ar a intuigtheacht. Is fearr lenár múnlaí samhlacha ilteangacha ar nós Google (+8.7 BLEU) agus Facebook M2M (+9.1) agus iad ag aistriú go Yoruba agus ag leagan síos tagarmharc ardchaighdeáin. le haghaidh taighde amach anseo.', 'el': 'Η μαζική πολύγλωσση μηχανική μετάφραση (ΜΤ) έχει δείξει εντυπωσιακές δυνατότητες και περιλαμβάνει μηδενική μετάφραση και μετάφραση ελάχιστων πυροβολισμών μεταξύ γλωσσικών ζευγαριών χαμηλού πόρου. Ωστόσο και αυτά τα μοντέλα αξιολογούνται συχνά σε γλώσσες υψηλής περιεκτικότητας με την υπόθεση ότι γενικεύονται σε γλώσσες χαμηλής περιεκτικότητας. Η δυσκολία της αξιολόγησης των μοντέλων ΜΤ σε ζεύγη χαμηλών πόρων οφείλεται συχνά στην έλλειψη τυποποιημένων συνόλων δεδομένων αξιολόγησης. Στην παρούσα εργασία παρουσιάζουμε το και το πρώτο παράλληλο σώμα πολλαπλών τομέων με ειδικά επιμελημένη ορθογραφία για τα Αγγλικά με τυποποιημένα διαχωριστικά τρένων-δοκιμών για συγκριτική αξιολόγηση. Παρέχουμε διάφορα νευρωνικά ΜΤ και τα συγκρίνουμε με την απόδοση των δημοφιλών προ-εκπαιδευμένων (μαζικά πολυγλωσσικών) μοντέλων ΜΤ τόσο για το ετερογενή σύνολο δοκιμών όσο και για τους υποτομές του. Δεδομένου ότι αυτά τα προ-εκπαιδευμένα μοντέλα χρησιμοποιούν τεράστιες ποσότητες δεδομένων με αβέβαιη ποιότητα και αναλύουμε επίσης την επίδραση των διακοπτικών και ενός σημαντικού χαρακτηριστικού της Γιορούμπα και στα δεδομένα εκπαίδευσης. Ερευνούμε πώς και πότε αυτή η κατάσταση εκπαίδευσης επηρεάζει την τελική ποιότητα μιας μετάφρασης και την κατανόησή της. Τα μοντέλα μας ξεπερνούν σημαντικά τα πολύγλωσσα μοντέλα όπως το Google (+8.7 BLEU) και το Facebook M2M (+9.1) όταν μεταφράζουν στα Yoruba και θέτουν ένα υψηλό κριτήριο ποιότητας για μελλοντική έρευνα.', 'hu': 'A masszívan többnyelvű gépi fordítás (MT) lenyűgöző képességeket biztosít, beleértve az alacsony erőforrású nyelvpárok közötti zéró és néhány felvételű fordítást. Ezeket a modelleket azonban gyakran nagy erőforrású nyelveken értékelik, azzal a feltételezéssel, hogy alacsony erőforrású nyelvekre általánosítják. Az MT modellek értékelésének nehézsége alacsony erőforrás-párokra gyakran a szabványosított értékelési adatkészletek hiányának köszönhető. Ebben a tanulmányban bemutatjuk a MENYO-20k-et és az első több domain párhuzamos korpuszt, amely speciálisan kurátorozott yoruba-angol ortográfiával rendelkezik, szabványosított vonat-teszt osztásokkal a teljesítményértékeléshez. Számos neurális MT referenciaértéket biztosítunk és összehasonlítjuk azokat a népszerű, előre képzett (többnyelvű) MT modellek teljesítményével, mind a heterogén tesztkészlet, mind pedig annak aldomainjai esetében. Mivel ezek az előképzett modellek hatalmas mennyiségű, bizonytalan minőségű adatot használnak fel, elemezzük a diakritikusok hatását és a Yoruba egyik fő jellemzőjét és az edzési adatokban. Megvizsgáljuk, hogy ez a képzési feltétel hogyan és mikor befolyásolja a fordítás végső minőségét és érthetőségét. Modelljeink nagymértékben felülmúlják a többnyelvű modelleket, mint például a Google (+8,7 BLEU) és a Facebook M2M (+9,1), amikor Yoruba-ra fordítanak, és kiváló minőségi referenciaértéket állítanak elő a jövőbeli kutatások számára.', 'ka': 'მასტივიურად მრავალური მანქანის გაგრძელება (MT) გამოჩვენეთ ინტერფექციური შესაძლებლობა და ნულა და პატარა გაგრძელება სამუშაო ენის ზოგების შორის. მაგრამ ეს მოდელები ზოგიერთად იმუშაობენ მაღალი რესურსის ენაზე, რომელიც იმუშაობენ, რომ ისინი ენერალიზებულია მაღალი რესურსის ენაზე. MT მოდელების შესაბამისი რესურსის ზოგების შესაბამისი რთული იქნება, რადგან სტანდარტურებული განსაბამისი მონაცემები არსებობს. ამ დოგომაში ჩვენ MENYO-20k და პირველი მულტი-დომინური პარალელი კორპუსს ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ განვითავსებთ რამდენიმე ნეიროლური MT ბენქმარიკას და შემდგომარებით პოლიოლური პრეტრექტირებული MT მოდელების პასუხისთვის, რომლებიც ჰეტეროგენური ტესტის სენტირებისთვის და მისი ამ მოდელების წინ შესწავლობული მოდელების გამოყენება ძალიან მნიშვნელოვანი მონაცემები, რომელიც უცნობიერი კაalitესთან და ჩვენ ასევე დავაანალიზებთ დიაკრიტიკის ეფექტის და იორუბის მ ჩვენ შევხედავთ, როგორ და როცა ეს სწავლების შედეგება ატვირთებს საბოლოო კაalitეტის და მისი გაგრძნობა. ჩვენი მოდელები მასტივი მრავალენგური მოდელები, როგორც Google (+8.7 BLEU) და Facebook M2M (+9.1) იყოს, როდესაც იორუბში გადატანა და მომავალეთ სწავლებისთვის მასტივი კანქმიტური ბენქმიმარკის დაყენ', 'mk': 'Масовно мултијазичен машински превод (МТ) покажа импресивни способности и вклучувајќи нула и мал превод помеѓу парови на јазик со ниски ресурси. Сепак, овие модели честопати се проценуваат на јазици со високи ресурси со претпоставка дека тие се генерализираат на јазици со ниски ресурси. Тешкотијата за проценка на моделите на МТ на парови со ниски ресурси честопати е поради недостатокот на стандардизирани податоци за проценка. Во овој весник и го претставуваме MENYO-20k и првиот паралелен корпус со повеќето домени со специјално курирана ортографија за Јуруба-Англиски со стандардизирани поделби на воз-тест за benchmarking. Ние обезбедуваме неколку нервни МТ референтни значки и ги споредуваме со изведбата на популарните предобучени (масовно мултијазични) МТ модели, како за хетерогенскиот тест сет, така и за нејзините поддомени. Since these pre-trained models use huge amounts of data with uncertain quality and we also analyze the effect of diacritics and a major characteristic of Yoruba and in the training data.  Истражуваме како и кога оваа состојба на обука влијае на конечниот квалитет на преводот и неговата разбирливост. Нашите модели ги надминуваат масовните мултијазични модели како што се Гугл (+8,7 БлеУ) и Фејсбук M2M (+9,1) кога се преведуваат во Јуруба и поставуваат висока квалитетна референца за идното истражување.', 'kk': 'Массалық көп тілді компьютердің аударуы Бірақ бұл үлгілер көптеген ресурстар тілдерінде бағалау үшін көптеген ресурстардың төмен тілдеріне бағалады. MT үлгілерін төмен ресурстардың екеуінде бағалау қиындығы көбінде стандартты бағалау деректер қорларының жоқ болуы үшін. Бұл қағазда біз MENYO-20k және бірінші көп доменге параллелі корпус арқылы Yoruba-ағылшын тілінің ортографиясы мен стандартты желі сынақтар бөлігін көрсетедік. Біз бірнеше невралдық MT бағдарламаларын қамтамасыз және оларды алғашқы (массалық көп тілдік) MT моделдеріне тесті және оның субдомендеріне салыстырып салыстырамыз. Бұл алдыңғы оқылған үлгілер күтпеген сапасы бар көп мөлшерлерді қолданып, біз сондай-ақ Диакритикалардың және Йорuba және оқыту деректерінің негізгі қасиеттерін анализирақ. Бұл оқыту жағдайы аудармалардың соңғы сапасына және оның түсініктерін қалай және қалай әсер етеді деп зерттейміз. Өзіміздің үлгілеріміз, Google (+8.7 BLEU) және Facebook M2M (+9.1) секілді көптілік үлгілеріне аударып, келесі зерттеулер үшін сапатты сапатты бақылау үшін көпшілікті үлкен үлгілерді жаса', 'it': "La traduzione automatica multilingue di massa (MT) ha dimostrato capacità impressionanti e include la traduzione zero e pochi scatti tra coppie di lingue a basso contenuto di risorse. Tuttavia e questi modelli sono spesso valutati su linguaggi ad alta risorsa con l'ipotesi che si generalizzino a quelli a bassa risorsa. La difficoltà di valutare i modelli MT su coppie a basso contenuto di risorse è spesso dovuta alla mancanza di set di dati di valutazione standardizzati. In questo articolo presentiamo MENYO-20k e il primo corpus parallelo multi-dominio con un'ortografia appositamente curata per yoruba-inglese con suddivisioni standardizzate per test di treno per il benchmarking. Forniamo diversi benchmark MT neurali e li confrontiamo con le prestazioni dei popolari modelli MT pre-addestrati (massicciamente multilingue) sia per il set di test eterogeneo che per i suoi sottodomini. Poiché questi modelli pre-addestrati utilizzano enormi quantità di dati con qualità incerta e analizziamo anche l'effetto della diacritica e una caratteristica principale di Yoruba e nei dati di allenamento. Investighiamo come e quando questa condizione di formazione influisce sulla qualità finale di una traduzione e sulla sua comprensibilità. I nostri modelli superano i modelli multilingue di massa come Google (+8,7 BLEU) e Facebook M2M (+9,1) quando traducono in Yoruba e fissano un punto di riferimento di alta qualità per la ricerca futura.", 'lt': 'Masyviai daugiakalbis mašininis vertimas (MT) parodė įspūdingus gebėjimus, įskaitant nulinį ir nedidelį vertimą tarp mažai išteklių turinčių kalbų porų. Tačiau šie modeliai dažnai vertinami didelių išteklių kalbomis, darant prielaidą, kad jie paplitę mažai išteklių turinčioms kalboms. Dėl standartizuotų vertinimo duomenų rinkinių trūkumo dažnai sunku vertinti mažai išteklių turinčių poros MT modelius. In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for Yoruba-English with standardized train-test splits for benchmarking.  Pateikiame kelis neurologinius MT lyginamuosius rodiklius ir palyginame juos su populiarių iš anksto parengtų (masiškai daugiakalbių) MT modelių rezultatais heterogeniniame bandymų rinkinyje ir jo pogrupiuose. Kadangi šie iš anksto parengti modeliai naudoja didžiulį kiekį duomenų, kurių kokybė yra neapibrėžta, taip pat analizuojame diakritikų poveikį ir pagrindinę Yoruba savybę bei mokymo duomenise. Mes tiriame, kaip ir kada ši mokymo sąlyga daro poveikį galutinei vertimo kokybei ir supratimui. Mūsų modeliai, perkeliami į Yoruba ir nustatantys aukštos kokybės lyginamąjį rodiklį būsimiems moksliniams tyrimams, yra didesni už daugelio kalbų modelius, pvz., Google (+8,7 BLEU) ir Facebook M2M (+9,1).', 'ml': 'അധികമായി പല ഭാഷ മെഷിന്\u200d പരിഭാഷകങ്ങള്\u200d (എം- ടി) കാണിച്ചിരിക്കുന്നു ഗുണപൂര്\u200dണ്ണമായ കഴിവുകളും, കുറച്ച് വെടിവെക്കപ്പെട്ട ഭ എന്നാലും ഈ മോഡലുകള്\u200d എപ്പോഴും ഉയര്\u200dന്ന വിഭവങ്ങളുടെ ഭാഷകളില്\u200d വിലയിക്കപ്പെടുന്നുണ്ട്. അവയൊക്കെ കുറഞ്ഞ വിഭവങ്ങളിലേക കുറഞ്ഞ വിഭവങ്ങളുടെ ജോടികളില്\u200d എംടി മോഡലുകളെ വിലാസപ്പെടുത്തുന്നതിനുള്ള പ്രയാസത്തിനുള്ള പ്രയാസങ്ങള്\u200d സാധാരണ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d മെന്\u200dയോ-20 കിനെ കാണിക്കുന്നു. ആദ്യത്തെ പല-ഡൊമെയിന്\u200d പാരാളല്\u200d കോര്\u200dപ്പുസിനെയും യോരുബ- ഇംഗ്ലീഷിന്റെ പ്രത്യേകിച്ച് കുറ് നമ്മള്\u200d പല പ്രധാനപ്പെട്ട എംടി ബെന്\u200dമാര്\u200dക്കുകള്\u200d നല്\u200dകുന്നു. പ്രധാനപ്പെട്ട മുന്\u200dപരിശീലനത്തിന്\u200dറെ (വലിയ മള്\u200dഭാഷ) മോഡലുകളുടെ പ്രവര്\u200dത്തനത്തി ഈ മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലുകളില്\u200d നിന്നും തിരിച്ചറിയാത്ത വിവരങ്ങളുടെ വലിയ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനാല്\u200d നമ്മള്\u200d ഡയറക്രിക്റ്റ ഈ പരിശീലനത്തിന്റെ അവസ്ഥ എങ്ങനെയാണ് ബാധിക്കുന്നതെന്നും അതിന്റെ മനസ്സിലുള്ള അവസ്ഥ ബാധിക്കുന്നതെന്ന ഞങ്ങളുടെ മോഡലുകള്\u200d ഗൂഗിള്\u200d (+8. 7 BLEU) എന്നിട്ടും ഫേസ്ക്ക് M2M (+9. 1) എന്നിട്ട് യോരുബായിലേക്ക് പരിഭാഷപ്പെടുത്തുമ്പോള്\u200d കൂടുതല്\u200d മാന്ത്', 'mt': 'It-traduzzjoni bil-magna b’ħafna lingwi (MT) uriet kapaċitajiet impressjonanti u inkludiet traduzzjoni żero u ftit imqabbla bejn pari lingwistiċi b’riżorsi baxxi. Madankollu u dawn il-mudelli ta’ spiss jiġu evalwati fuq lingwi b’riżorsi għoljin bil-preżunzjoni li jiġġeneralizzaw għal dawk b’riżorsi baxxi. Id-diffikultà li jiġu evalwati mudelli MT fuq par ta’ riżorsi baxxi ħafna drabi hija minħabba n-nuqqas ta’ settijiet ta’ dejta standardizzati ta’ evalwazzjoni. F’dan id-dokument u nippreżentaw MENYO-20k u l-ewwel korpus parallelu multidomestiku b’ortografija kkurata b’mod speċjali għal Yoruba-English b’taqsimiet standardizzati tat-test tal-ferrovija għall-benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains.  Minħabba li dawn il-mudelli mħarrġa minn qabel jużaw ammonti kbar ta’ dejta b’kwalità in ċerta u a ħna analizzaw ukoll l-effett tad-dijakritiċi u karatteristika maġġuri ta’ Yoruba u fid-dejta tat-taħriġ. Aħna ninvestigaw kif u meta din il-kundizzjoni ta’ taħriġ taffettwa l-kwalità finali ta’ traduzzjoni u l-fehim tagħha. Il-mudelli tagħna jippreżentaw mudelli multilingwi kbar bħal Google (+8.7 BLEU) u Facebook M2M (+9.1) meta jiġu tradotti għal Yoruba u jistabbilixxu punt ta’ riferiment ta’ kwalità għolja għar-riċerka futura.', 'ms': 'Terjemahan mesin berbilang bahasa (MT) telah menunjukkan kemampuan yang mengesankan dan termasuk terjemahan sifar dan beberapa tembakan diantara pasangan bahasa sumber rendah. Namun dan model-model ini sering diteliti pada bahasa sumber-tinggi dengan asumsi bahasa-sumber-rendah yang mereka umumkan kepada sumber-rendah. Kesukaran untuk menilai model MT pada pasangan sumber rendah sering disebabkan kekurangan set data penilaian piawai. Dalam kertas ini dan kami memperkenalkan MENYO-20k dan korpus paralel multi-domain pertama dengan ortografi khusus dikurasi untuk Yoruba-English dengan pembahagian ujian kereta api standar untuk benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains.  Oleh kerana model-model yang dilatih ini menggunakan jumlah besar data dengan kualiti yang tidak pasti dan kami juga menganalisis kesan diakritik dan karakteristik utama Yoruba dan dalam data latihan. Kami menyelidiki bagaimana dan apabila keadaan latihan ini mempengaruhi kualiti akhir terjemahan dan memahaminya. Model kami melebihi model berbilang bahasa besar seperti Google (+8.7 BLEU) dan Facebook M2M (+9.1) bila diterjemahkan ke Yoruba dan menetapkan tanda referensi kualiti tinggi untuk kajian masa depan.', 'pl': 'Masowo wielojęzyczne tłumaczenie maszynowe (MT) wykazało imponujące możliwości, obejmując tłumaczenie zerowe i kilku strzałów między parami językowymi o niskich zasobach. Jednak modele te są często oceniane na językach o wysokim zasobie z założeniem, że uogólniają się na języki o niskim zasobie. Trudność z oceną modeli MT na parach o niskim zasobie często wynika z braku standaryzowanych zbiorów danych oceniających. W niniejszym artykule przedstawiamy MENYO-20k oraz pierwszy wielododomenowy korpus równoległy ze specjalnie kuratorowaną ortografią dla języka angielskiego Yoruba ze standaryzowanymi podziałami testów pociągu dla porównania. Dostarczamy kilka neuronowych referencji MT i porównujemy je z wydajnością popularnych wstępnie trenowanych (masowo wielojęzycznych) modeli MT zarówno dla heterogenicznego zestawu testów, jak i jego subdomen. Ponieważ te wstępnie przeszkolone modele wykorzystują ogromne ilości danych o niepewnej jakości, analizujemy również efekt diakrytyki i główną cechę Yoruby i danych treningowych. Badamy, w jaki sposób i kiedy ten warunek szkolenia wpływa na ostateczną jakość tłumaczenia i jego zrozumiałość. Nasze modele przewyższają masowo wielojęzyczne modele takie jak Google (+8.7 BLEU) i Facebook M2M (+9.1) podczas tłumaczenia na język Yoruba i wyznaczają wysoki standard jakości dla przyszłych badań.', 'sr': 'Masivno multijezički prevod mašine (MT) pokazao je impresivne mogućnosti i uključujući prevod nule i nekoliko snimaka između parova jezika niskih resursa. Međutim, ovi modeli često procjenjuju na jezicima visokih resursa sa pretpostavkom da generalizuju na niske resurse. Teškoća ocjenjivanja modela MT na par niskih resursa često je zbog nedostatka standardizovanih podataka za procjenu. U ovom papiru predstavljamo MENYO-20k i prvi paralelni korpus multidomenata sa posebno izloženom ortografijom za Yoruba-engleski sa standardizovanim dijelom test a vlaka za benchmarking. Mi pružamo nekoliko neuralnih MT kriterija i uspoređujemo ih sa učinkom popularnih predobučenih (masivno multijezičkih) MT modela i za heterogenezne testove i njegove poddomene. Pošto ovi predobučeni modeli koriste ogromne količine podataka sa neodređenom kvalitetom, analiziramo i učinak dijakreta i velike karakteristike Yoruba i podataka o obuci. Istražujemo kako i kada ovaj uslov obuke utiče na konačnu kvalitet prevoda i njenu razumljivost. Naši modeli iznose masivne multijezičke modele poput Google (+8.7 BLEU) i Facebook M2M (+9.1) kada se prevodimo u Yoruba i postavljamo visoke kvalitetne kritike za buduće istraživanje.', 'mn': 'Маш олон хэлний машины хөгжүүлэлт (MT) нь гайхалтай чадварыг харуулсан ба бага боловсролын хэлний хоорондын 0 болон хэдэн зурагтай хөгжүүлэлт харуулсан. Гэвч эдгээр загваруудыг ихэвчлэн өндөр ресурс хэлний хэл дээр үнэлдэг нь бага нөөцийн төвшинд нийтлэгддэг гэж үздэг. MT загварыг бага нөөцийн хоёр дээр үнэлэх хэцүү байдал нь стандарттайгаар үнэлэх өгөгдлийн сангийн бага байдлаар байдаг. Энэ цаасан дээр бид MENYO-20k болон анхны олон холбоотой параллел корпус илэрхийлдэг. Яурба-Англи хэлний хувьд стандартчилсан tren-testing хуваагдах ортографикийг харуулж байна. Бид эдгээрийг олон мэдрэлийн MT багц хангаж, олон олон хэлний өмнө сургалтын MT загварын үйлдвэрлэлтэй харьцуулдаг. Эдгээр сургалтын өмнө сургалтын загварууд тодорхойгүй чанартай маш их хэмжээний өгөгдлийг ашигладаг учраас бид мөн ихэвчлэн тэмдэглэгчийн нөлөөг, Йорбугийн, сургалтын өгөгдлийн хамгийн чухал чанарыг ши Бид энэ сургалтын нөхцөл хэрхэн, хэрхэн хөгжүүлэх нөхцөл нь хөгжүүлэх болон түүний ойлголтын төгсгөлд нөлөөлдөг. Бидний загварууд яг Google (+8.7 BLEU) болон Facebook M2M (+9.1) ихэвчлэн Yoruba руу орчуулж ирээдүйн судалгааны талаар өндөр чадвартай салбар гаргаж байдаг.', 'si': 'ගොඩක් භාෂාවක් පණිවාදය (MT) පෙන්වන්න පුළුවන් සක්ෂමතාවක් සහ ශූන්ය සහ ප්\u200dරතික්\u200dරියාත්මක භාෂාව අතර නමුත් මේ මොඩේල් සාමාන්\u200dය විශ්වාස කරනවා අධාර්ථ භාෂාවට, ඔවුන් සාමාන්\u200dය විශ්වාස කරනවා කියලා. MT මොඩල් අඩුම සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ විශ්ලේෂණය අවශ්\u200dය විශ්ලේෂණය නොහැකි න මේ පත්තරේ අපි MENYO-20k සහ පලවෙනි Multi-domain සාමාන්\u200dය කොර්පස් එක්ක යෝරුබා-ඉංග්\u200dරිසියාට විශේෂයෙන් ප්\u200dරමාණය කරලා තියෙන්නේ ප්\u200dරමාණය කර අපි න්\u200dයූරාල් MT බෙන්ච්මාර්ක් වලින් දෙන්නා ඒවා ප්\u200dරමාණයෙන් ප්\u200dරීක්ෂණිත (ලොකු භාෂාවික) MT මොඩේල් වලින් සහ ඒකේ සබ්ඩෝමේන්ස මේ ප්\u200dරධාන ප්\u200dරශ්නයක් නිර්දේශ විශේෂයෙන් ගොඩක් දත්ත පාවිච්චි කරන්න පුළුවන් විතරයි. අපි ප්\u200dරශ්නයක් සහ යෝරුබා වලින අපි පරීක්ෂණය කරනවා කොහොමද ඒ ප්\u200dරශ්නය ස්ථානයක් අන්තිම ප්\u200dරශ්නයක් අන්තිම ප්\u200dරශ්නයක් සහ ඒක ග අපේ මොඩේල් විශේෂයෙන් ගුගුල් (+8.7 BLUE) සහ ෆේස්බුක් M2M (+9.1) යෝරුබා වලට පරිවර්තනය කරන්න සහ අනාගතයේ පරීක්ෂණය සඳහා ගොඩක් වටින් ක', 'no': 'Massivt fleirspråksomsetjing av maskina (MT) har vist uttrykkelige kapasitet og inkludert null og få- skjultomsetjing mellom låg- ressursspråkspar. Men desse modelane er ofte evaluert på høg ressursspråk med assumpsjonen at dei generelliserer til låg ressursspråk. Vanskelegheten for å evaluera MT-modeller på låg ressurspar er ofte på grunn av mangling av standardiserte evalueringsdatasett. I denne papiret viser vi MENYO-20k og den første multidomene parallelle korpusen med ein spesielt korte ortografi for Yoruba-English med standardiserte trentestsplitter for benchmarking. Vi tilbyr fleire neurale MT-benchmarker og samanliknar dei med utviklinga av populære først trengte MT-modeller både for heterogeneske testsett og underdomene. Siden desse føretrengte modelane brukar store mengdar data med usikkerte kvalitet og vi også analyserer effekten av diakritikk og ein stor karakteristikk av Yoruba og i treningsdata. Vi undersøker korleis og når denne opplæringsvilkårene påvirkar den siste kvaliteten til eit omsetjing og den forstårbarheten. Modellene våre utfører massivt fleirspråk modeller som Google (+8.7 BLEU) og Facebook M2M (+9.1) når du omsetjer til Yoruba og setter ein høg kvalitetsverkt for framtidige forskning.', 'sv': 'Massively flerspråkig maskinöversättning (MT) har visat imponerande kapacitet och inkluderar noll- och få-skott översättning mellan lågresurs språkpar. Dock och dessa modeller utvärderas ofta på högresursspråk med antagandet att de generaliserar till lågresursspråk. Svårigheten att utvärdera MT-modeller på lågresurspar beror ofta på brist på standardiserade utvärderingsdata. I denna uppsats presenterar vi MENYO-20k och den första parallella korpusen med flera domäner med en särskilt kuraterad ortografi för yoruba-engelska med standardiserade tågtest splits för benchmarking. Vi tillhandahåller flera neurala MT-riktmärken och jämför dem med prestandan hos populära pre-utbildade (massivt flerspråkiga) MT-modeller både för den heterogena testuppsättningen och dess underdomäner. Eftersom dessa pre-utbildade modeller använder enorma mängder data med osäker kvalitet och vi analyserar även effekten av diakritiker och en viktig egenskap hos Yoruba och i träningsdata. Vi undersöker hur och när detta träningstillstånd påverkar översättningens slutliga kvalitet och dess förståelse. Våra modeller överträffar massivt flerspråkiga modeller som Google (+8,7 BLEU) och Facebook M2M (+9,1) när de översätter till Yoruba och sätter en hög kvalitetsstandard för framtida forskning.', 'so': "Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs.  Si kastaba ha ahaatee tusaalahan waxaa inta badan lagu qiimeeyaa luqadaha sare ee midhaha nololeed, sida ay u soo bandhigaan kuwa hoos-dhexe. Dhibaatada qiimeynta modellada MT ee labada nooc ee hoos-resource waa inta badan sabab u baahan yihiin kaartaynta qiimeynta. Warqadan ayaan ku qoraynaa MENYO-20k iyo koofurka ugu horeeyay oo kala duduwan, taasoo ay leedahay hagaajiyo oo gaar ah Yoruba-Ingiriis ku qoran jardiinada tog-test. Waxaannu siinaynaa qiyaastii neurada ee MT, waxaana la barbaranaynaa sameynta sameynta horumar-tababarida (aad u badan luuqadaha) MT sameynta imtixaanka guud iyo subdomiyada. Sida darteed qaababkan horay loo tababaray waxay isticmaalaan tiro badan oo macluumaad ah oo aan aqoon lahayn, waxaynu kaloo analyelinnaa saamaynta dhakhtarka iyo waxyaabaha muhiimka ah ee Yoruba iyo macluumaadka waxbarashada. Waxaynu baaraynaa sida iyo marka xaaladan waxbarashadu ay saameyn ku yeelato takhasuska ugu dambeeya turjumaadda iyo waxgarashada. Tusaale'yadayada waxay ka muuqataa tusaale ahaan Google (+8.7 BLEU) iyo Facebook M2M (+9.1) marka loo turjumo Yoruba oo loo sameynayo qiimo aad u weyn baaritaanka mustaqbalka.", 'ro': 'Traducerea automată multilingvă masivă (MT) a demonstrat capacități impresionante și include traducerea zero și puține fotografii între perechile de limbi cu resurse reduse. Cu toate acestea și aceste modele sunt adesea evaluate pe limbaje cu resurse ridicate cu presupunerea că ele generalizează la cele cu resurse reduse. Dificultatea evaluării modelelor MT pe perechi cu resurse reduse se datorează adesea lipsei seturilor de date standardizate de evaluare. În această lucrare și prezentăm MENYO-20k și primul corpus paralel multi-domeniu cu o ortografie specială pentru yoruba-engleză cu divizări standardizate de tren-test pentru benchmarking. Oferim mai multe criterii de referință MT neurale și le comparăm cu performanța modelelor MT pre-instruite (masiv multilingv) populare, atât pentru setul de teste eterogene, cât și pentru subdomeniile sale. Deoarece aceste modele pre-instruite folosesc cantități uriașe de date cu o calitate incertă și analizăm, de asemenea, efectul diacriticii și o caracteristică majoră a Yoruba și în datele de antrenament. Investigăm cum și când această condiție de formare afectează calitatea finală a traducerii și înțelegerea acesteia. Modelele noastre depășesc performanța masivă a modelelor multilingve precum Google (+8,7 BLEU) și Facebook M2M (+9,1) atunci când traduc în Yoruba și stabilesc un reper de înaltă calitate pentru cercetarea viitoare.', 'ta': 'பெரும்பாலாக பல மொழி இயந்திரம் மொழிமாற்றி (MT) குறைந்த மூலத்தின் ஜோடி இடையில் பூஜ்ஜியம் மற்றும் சில சுட்டி மொழிமாற்ற ம ஆனால் இந்த மாதிரிகள் அதிக மூலத்தின் மொழிகளில் பெரும்பாலாக மதிப்பிடப்படுகிறது குறைந்த மூலத்திற்கு அவர்கள் பொதுவாக் குறைந்த மூலத்தின் ஜோடிகளில் MT மாதிரிகளை மதிப்பதின் கடினம் பெரும்பாலாகவே நிலைமைப்படுத்தப்பட்ட மதிப்பின் தரவு அமை இந்த காகிதத்தில் நாம் மென்யோ-20k மற்றும் முதல் பல- டோமைன் இணைப்பு கார்புஸ் காண்பிக்கிறோம் முன்னேற்றுகிறோம் யோருபா- ஆங்கிலத்திற்கு ஒரு ச நாம் பல புதிய MT குறிப்புகளை வழங்குகிறோம் மற்றும் அதை பிரபலமான முன்பயிற்சியில் (அதிகமாக பல மொழிகள்) மாதிரிகளின் செயல்பாட்டை ஒப்பிடுகிறோம இந்த முன்பயிற்சிக்கப்பட்ட மாதிரிகளில் தெரியாத தரவுடன் மிகப்பெரிய தரவுகளை பயன்படுத்துகிறது மற்றும் நாம் விளைவுகளையும் யோருபாவின் மு நாம் எப்படி மற்றும் இந்த பயிற்சி நிலைமை எப்படி பாதிக்கும் போது மொழிபெயர்ப்பின் இறுதிய தரம் மற்றும்  எங்கள் மாதிரிகள் கூகுல் (+8. 7 BLEU) மற்றும் Facebook M2M (+9. 1) மொழிபெயர்ப்பு யோருபாவிற்கு மொழிபெயர்க்கும் போது பல மொழி மாதிரிகளை வெளியேற்று', 'ur': 'بہت زیادہ ملتی زبان مشین ترجمہ (MT) نے اثر انگیز قابلیت دکھائی ہے اور صفر اور کم شٹ ترجمہ کم رسورس زبان جوڑوں کے درمیان ہے. اگرچہ یہ موڈلے اکثر زیادہ سرمایہ کی زبانوں میں ارزش کیا جاتا ہے کہ وہ کم سرمایہ کے ساتھ عامل ہوتے ہیں۔ کم رسورس جوڑوں پر MT موڈل کا ارزیابی کرنے کا مشکل بہت سی وقت استاندارڈیز ارزیابی ڈیٹ سٹ کے ناکام ہونے کے سبب ہے. اس کاغذ میں ہم نے MENYO-20k اور پہلی multi-domain parallel corpus کو دکھایا تھا کہ یوروب-انگلیسی کے لئے ایک مخصوص کرتوٹی اورٹوگرافی کے ساتھ استاندارڈیز ٹرین-ٹیس-ٹیس ٹیس ٹیسٹ ٹیسٹ ٹیسٹ کے ساتھ بنچم مار ہم نے بہت سی نیورال ٹی بینچمٹ بنچمٹ کا سامان دیا ہے اور ان کو جمعیت پیش آموزش کی (بہت سی زبان کی) MT موڈل کے مطابق مقایسہ کر دیتے ہیں اور ان کی آزمائش مجموعے کے لئے اور اس کے نیچے دومین کے مطابق مقایسہ کر دیتے ہیں۔ اس وجہ سے کہ یہ پیش آموزش کی مدلکوں بڑے اندازے ڈاٹے ناقطی کیفیت کے ساتھ استعمال کرتے ہیں اور ہم نے بھی ڈاٹریک کے اثر اور یوروبو کی بڑی خصوصی اور ترینس ڈاٹوں میں تحقیق کرلیا ہے ہم تحقیق کرتے ہیں کہ کیسے اور جب یہ تعلیم شرط ایک ترجمہ اور اس کی سمجھنے کی آخری کیفیت پر اثر دیتی ہے۔ ہمارے مدلکوں یوروبو میں ترجمہ کرتا ہے اور آینده تحقیقات کے لئے ایک عالی کیفیت بنچم مارک مقرر کرتا ہے جیسے Google (+8.7 BLEU) اور Facebook M2M (+9.1).', 'vi': 'Dịch vụ máy to lớn, ngôn ngữ đa dạng con (MTV) đã cho thấy khả năng ấn tượng và bao gồm dịch bằng không và ít ảnh giữa các cặp ngôn ngữ ít tài nguyên. Tuy nhiên, và các mô hình này thường được đánh giá bằng ngôn ngữ giàu có với giả định rằng chúng tổng hợp thành ngôn ngữ ít nguồn. Khó khăn trong việc đánh giá các mô hình MTV về cặp tài nguyên thấp thường là do thiếu các tập tin đánh giá tiêu chuẩn. Trong tờ giấy này, chúng tôi có nhắc đến nhắc đến nhắc đến nhắc đến nhắc đến nhắc đến nhắc đến nhắc lại về hệ thống giám định vĩ đại Chúng tôi cung cấp vài tiêu chuẩn mạng lưới thần kinh và so sánh chúng với các mô hình MTV được huấn luyện rất phổ biến cả cho bộ thử nghiệm khác nhau và khu miền của nó. Bởi vì những mô hình được rèn luyện này sử dụng một lượng dữ liệu khổng lồ với chất lượng không chắc chắn và chúng tôi cũng phân tích được hiệu quả của Diacritics và một đặc trưng chính của Yorube và các dữ liệu đào tạo. Chúng tôi điều tra làm thế nào và khi nào điều kiện đào tạo này ảnh hưởng đến chất lượng cuối cùng của dịch vụ và khả năng của nó. Các mô hình của chúng ta hiện ra cách biểu tượng rộng rãi như Google (+8.7 bleU) và Facebook M2M (+9.1) khi dịch sang Yorube và thiết lập tiêu chuẩn chất lượng cao cho nghiên cứu tương lai.', 'uz': "Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs.  Lekin bu modellar ko'pincha yuqori manbalar tilida qiymatlaydi, ularning kichkina manbalarga o'zaro qilishini anglatadi. Name Bu qogʻozda, biz MENYO-20k va birinchi birinchi multi-domen parallel korpus bilan yoruba- Inglizchaga qo'shilgan ortografiya bilan ishlab chiqarish uchun standardized train test splitteri. Biz bir necha neyrolik MT parametrlarini qo'llayapmiz va ularni o'zimdan oldin o'rganish (katta tillar) MT modellariga kamaytirish mumkin. Bu oldingi taʼminlovchi modellar haqida katta maʼlumotdan foydalanadi va biz diakritiklarning effektini va Yoruba va taʼminlovchi maʼlumotlarning muhim 特点ini analyzeriz. Biz o'rganamiz, bu trening holati qanday va qanday holatiga tarjima va ta'sirning oxirgi sifatida qo'shiladi. Ularning modellarimiz Yoruba tarjima qilayotganda Google (+8.7 BLEU) va Facebook M2M (+9.1) kabi bir xil tildagi modellarni bajaradi va kelajakdagi qidirish uchun juda katta qiymatni moslash.", 'nl': 'Massively meertalige machine translation (MT) heeft indrukwekkende mogelijkheden laten zien en inclusief zero- en few-shot-vertaling tussen taalparen met weinig resources. Echter en deze modellen worden vaak geëvalueerd op high-resource talen met de veronderstelling dat ze generaliseren naar low-resource talen. De moeilijkheid van het evalueren van MT-modellen op low-resource paren is vaak te wijten aan het ontbreken van gestandaardiseerde evaluatiedatasets. In dit artikel presenteren we MENYO-20k en het eerste multi-domein parallelle corpus met een speciaal gecureerde orthografie voor Yoruba-Engels met gestandaardiseerde train-test splits voor benchmarking. We bieden verschillende neurale MT benchmarks en vergelijken deze met de prestaties van populaire voorgetrainde (massaal meertalige) MT modellen, zowel voor de heterogene testset als zijn subdomeinen. Omdat deze voorgetrainde modellen enorme hoeveelheden data gebruiken met onzekere kwaliteit en we ook het effect van diacritica en een belangrijk kenmerk van Yoruba en in de trainingsgegevens analyseren. We onderzoeken hoe en wanneer deze trainingsvoorwaarde invloed heeft op de uiteindelijke kwaliteit van een vertaling en de begrijpelijkheid ervan. Onze modellen presteren beter dan massaal meertalige modellen zoals Google (+8.7 BLEU) en Facebook M2M (+9.1) bij het vertalen naar Yoruba en het stellen van een hoge kwaliteitsstandaard voor toekomstig onderzoek.', 'da': 'Massively flersproget maskinoversættelse (MT) har vist imponerende evner og inkluderer nul og få skud oversættelse mellem lav ressource sprogpar. Men og disse modeller er ofte evalueret på høj ressource sprog med den antagelse, at de generaliserer sig til lav ressource sprog. Vanskeligheden ved at evaluere MT-modeller på par med lav ressource skyldes ofte mangel på standardiserede evalueringsdatasæt. I denne artikel præsenterer vi MENYO-20k og det første multi-domæne parallelkorpus med en særligt kurateret ortografi til yoruba-engelsk med standardiserede togtest splits til benchmarking. Vi leverer flere neurale MT benchmarks og sammenligner dem med ydeevnen af populære pre-trænede (massivt flersprogede) MT modeller både for det heterogene testsæt og dets underdomæner. Da disse prætrænede modeller bruger enorme mængder data med usikker kvalitet, analyserer vi også effekten af diakritiker og et vigtigt kendetegn ved Yoruba og i træningsdataene. Vi undersøger, hvordan og hvornår denne træningstilstand påvirker oversættelsens endelige kvalitet og forståelighed. Vores modeller overgår massivt flersprogede modeller som Google (+8,7 BLEU) og Facebook M2M (+9,1), når de oversætter til Yoruba og sætter en høj kvalitetsstandard for fremtidig forskning.', 'bg': 'Масивният многоезичен машинен превод (МТ) показа впечатляващи възможности и включва нулев и няколко изстрела превод между езикови двойки с нисък ресурс. Въпреки това и тези модели често се оценяват на езици с висок ресурс с предположението, че те обобщават към такива с нисък ресурс. Трудността при оценяването на моделите на МТ при двойки с ниски ресурси често се дължи на липсата на стандартизирани набори от данни за оценка. В настоящата статия представяме и първия многодомейн паралелен корпус със специално курирана ортография за йоруба-английски със стандартизирани влак-тестови сплитове за сравнителен анализ. Ние предоставяме няколко неврални МТ бенчмарка и ги сравняваме с представянето на популярните предварително обучени (масово многоезични) МТ модели както за хетерогенния тестов набор, така и за неговите поддомейни. Тъй като тези предварително обучени модели използват огромни количества данни с несигурно качество и анализираме ефекта на диакритиката и основната характеристика на Йоруба и в данните за обучение. Проучваме как и кога това обучително условие влияе върху окончателното качество на превода и неговата разбираемост. Нашите модели превъзхождат масивно многоезични модели като при превод на Йоруба и поставят високо качество за бъдещи изследвания.', 'de': 'Massive mehrsprachige maschinelle Übersetzung (MT) hat beeindruckende Fähigkeiten gezeigt und beinhaltet Null- und Wenig-Schuss-Übersetzungen zwischen ressourcenarmen Sprachpaaren. Diese Modelle werden jedoch häufig auf ressourcenreichen Sprachen ausgewertet, wobei davon ausgegangen wird, dass sie auf ressourcenarme Sprachen verallgemeinern. Die Schwierigkeit, MT-Modelle auf ressourcenarmen Paaren zu evaluieren, liegt häufig am Fehlen standardisierter Auswertungsdatensätze. In diesem Beitrag stellen wir MENYO-20k und den ersten multidomänen Parallelkorpus mit einer speziell kuratierten Orthographie für Yoruba-Englisch mit standardisierten Train-Test Splits für Benchmarking vor. Wir stellen mehrere neuronale MT-Benchmarks zur Verfügung und vergleichen diese mit der Leistung gängiger vortrainierter (massiv mehrsprachiger) MT-Modelle sowohl für den heterogenen Testsatz als auch für seine Subdomains. Da diese vortrainierten Modelle riesige Datenmengen mit unsicherer Qualität verwenden und wir auch die Wirkung von Diakritik und ein wesentliches Merkmal von Yoruba und in den Trainingsdaten analysieren. Wir untersuchen, wie und wann sich diese Schulungsbedingung auf die endgültige Qualität einer Übersetzung und deren Verständlichkeit auswirkt. Unsere Modelle übertreffen massiv mehrsprachige Modelle wie Google (+8.7 BLEU) und Facebook M2M (+9.1), wenn sie nach Yoruba übersetzen und einen hohen Qualitätsstandard für zukünftige Forschung setzen.', 'fa': 'ترجمه\u200cهای ماشین\u200cهای زیادی زبان (MT) توانایی\u200cهای تاثیرگذاری را نشان داده است و شامل ترجمه\u200cهای صفر و چند شلیک بین جفت زبان\u200cهای کم منبع است. با این حال، این مدلها اغلب در زبانهای منابع بالا ارزیابی می شوند، با فرض اینکه آنها به منابع کم ژنرال می شوند. مشکل ارزیابی مدل MT در جفت منابع کم اغلب به دلیل lack of standardized evaluation datasets است. در این کاغذ ما MENYO-20k و اولین کورپوس متراکمل چندین دامنه را با یک ورتوگرافی مخصوصا متراکم برای یوروبا-انگلیسی با قطعه\u200cهای آزمایش قطار استاندارد برای برچسب کردن نشان می\u200cدهیم. ما چندین نمونه\u200cهای MT عصبی را پیشنهاد می\u200cکنیم و آنها را با انجام نمونه\u200cهای MT پیش آموزش (بسیار زیادی زبان) محبوب مقایسه می\u200cکنیم، هر دو برای آزمایش مجموعه\u200cای متغیر و زیر زمینه\u200cهای آن مقایسه می\u200cکنیم. از اونجایی که این مدل های پیش آموزش داده شده از مقدار داده های بزرگی با کیفیت غیرمطمئن استفاده می کنند و همچنین تاثیر دیاکتریک ها و یک ویژگی بزرگی از یوروبا و در داده های آموزش تحلیل می کنیم. ما تحقیق می کنیم چگونه و زمانی که این شرایط آموزش به کیفیت نهایی یک ترجمه و قابلیت درک آن تأثیر می دهد. مدلهای ما مدلهای بسیار زیادی زبانی مثل گوگل (+8.7 BLEU) و فیس\u200cبوک M2M (+9.1) را در حال ترجمه به یوروبا انجام می\u200cدهند و برای تحقیقات آینده یک مقدار کیفیت بالا قرار می\u200cدهند.', 'ko': '대규모 다국어 기계번역(MT)은 저자원 언어 간의 제로 렌즈와 소량의 렌즈 번역을 포함한 인상적인 능력을 보였다.그러나 이러한 모델은 보통 고자원 언어에 대해 평가를 하고 저자원 언어로 확대될 수 있다고 가정한다.낮은 자원에서 기계 번역 모델을 평가하는 데 어려움은 일반적으로 표준화된 평가 데이터 집합이 부족하기 때문이다.본고에서 우리는 MENYO-20k와 첫 번째 다역 평행 자료 라이브러리를 소개했는데 이 자료 라이브러리는 요르바어 영어에 특별히 정확한 정자법을 제공하고 표준화된 열차 테스트 분할을 기준으로 제공했다.우리는 다국어 기계 번역과 다국어 기계 번역 테스트를 위해 다국어 기계 번역과 다국어 기계 번역 테스트를 제공했다.이러한 사전 훈련 모델은 대량의 품질이 확실하지 않은 데이터를 사용했기 때문에 우리는 음조 변화의 영향과 요르바어와 훈련 데이터 중의 주요 특징을 분석했다.우리는 이런 훈련 조건이 어떻게 번역의 최종 질과 이해성에 영향을 미치는지 연구했다.요르바어로 번역돼 미래 연구를 위한 고품질 기준을 설정할 때 구글(+8.7 BLEU)과 페이스북 M2M(+9.1)과 같은 대규모 다국어 모델보다 우수한 모습을 보였다.', 'id': 'Terjemahan mesin berbilang bahasa (MT) telah menunjukkan kemampuan yang mengesankan dan termasuk terjemahan nol dan sedikit tembakan antara pasangan bahasa sumber daya rendah. However and these models are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones.  The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets.  In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for Yoruba-English with standardized train-test splits for benchmarking.  We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains.  Karena model prapelatih ini menggunakan jumlah besar data dengan kualitas tidak pasti dan kami juga menganalisis efek diakritik dan karakteristik utama Yoruba dan dalam data pelatihan. We investigate how and when this training condition affects the final quality of a translation and its understandability. Model kami melebihi banyak model berbahasa seperti Google (+8.7 BLEU) dan Facebook M2M (+9.1) ketika diterjemahkan ke Yoruba dan menetapkan benchmark kualitas tinggi untuk penelitian masa depan.', 'af': "Massief multilinguele masjien vertaling (MT) het gewys inpresieële kapasiteite en insluitend nul en paar skoot vertaling tussen lae- hulpbron taal pare. Maar hierdie modelles word dikwels geevalueer op hoë-hulpbron tale met die aanvaar dat hulle generelliseer na lae-hulpbron een. Die moeilikheid van die evaluering van MT-modelles op lae-hulpbron paar is dikwels vanweë die ontbreek van standardiseerde evalueringsdatastel. In hierdie papier en ons voorsien MENYO-20k en die eerste multi-domein parallele korpus met 'n spesifieke korrigeerde ortografie vir Yoruba-Engels met standaard trein-toets splittings vir benchmarking. Ons verskaf verskeie neurale MT-benchmarke en vergelyk hulle met die prestasie van populêre voor-opgelei (massief multilingual) MT-modele beide vir die heterogeneese toets stel en sy subdomeine. Omdat hierdie voorafgeleerde modele groot hoeveelheid data met onverseker kwaliteit gebruik en ons ook die effek van diakrities en 'n groot karakteristiek van Yoruba en in die onderwerp data analiseer. Ons ondersoek hoe en wanneer hierdie oefening voorwaardes die eindelike kwaliteit van 'n vertaling en sy verstandigheid beïnvloor. Ons modele uitvoer massief multitaalske modele soos Google (+8. 7 BLEU) en Facebook M2M (+9. 1) wanneer vertaling na Yoruba en 'n hoë kwaliteit benchmark vir toekomstige forsoeking stel.", 'sq': 'Përkthimi masiv i makinave shumëgjuhëse (MT) ka treguar aftësi mbresëlënëse dhe përfshirë përkthimin zero dhe pak të shtëna midis çifteve gjuhësh me burime të ulëta. Megjithatë dhe këto modele shpesh vlerësohen në gjuhët me burime të larta me supozimin se ato gjeneralizohen në ato me burime të ulta. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets.  Në këtë letër dhe ne prezantojmë MENYO-20k dhe korpusin e parë paralel multi-domain me një ortografi veçanërisht kuruar për Yoruba-English me ndarje të standardizuara treni-test për paraqitjen. Ne ofrojmë disa standarte MT neuronale dhe i krahasojmë me shfaqjen e modeleve MT të popullorë të paratrajnuar (masivisht shumëgjuhës) si për grupin e testeve heterogjene, ashtu edhe për nëndomenat e tij. Meqë këto modele të paratrajnuar përdorin sasi të mëdha të dhënash me cilësi të pasigurtë dhe ne gjithashtu analizojmë efektin e diakritikëve dhe një karakteristikë të madhe të Yorubës dhe në të dhënat e trajnimit. Ne hetojmë se si dhe kur ky kusht trajnimi ndikon në cilësinë përfundimtare të një përkthimi dhe kuptueshmërinë e tij. Modelet tona ekzistojnë më tepër se modelet shumëgjuhësore të tilla si Google (+8.7 BLEU) dhe Facebook M2M (+9.1) kur përkthehen në Yoruba dhe vendosin një normë të cilësisë së lartë për kërkimet e ardhshme.', 'tr': 'Adatça köp dilli maşynyň terjimesini (MT) täsirli ukyplary görkezildi we 0 we ýene-täsirli iň kiçi-täsirli diller arasynda täsirli terjime edip görkezildi. Ýöne bu nusgalar köplenç ýokary ressurs dilinde deňlendirilýär çünki olar iň az resurslar üçin döredilýärler. MT nusgalaryny düşürmek kynçylyk ýok resurslarda çykmak kynçylyk düşürilen çykyş datasynyň ýetmegine sebäbi. Bu kagyzda we biz MENYO-20k we ilkinji multi-domenaly parallel korpusy bilen Yoruba-iňlisçe standart tren-test bölegi bilen tanyşýarys. Biz birnäçe nöral MT kriterçelerini temin edip, olaryň popüler öň-bilim sistemasy bilen tanyş edilen MT modellerini hem heterogenen testiler we alt sahypalarynyň üçin karşılaştyrýarys. Bu öňünden bilim edilen nusgalar kesinli kalitede örän uly sanlary ulanýarlar we biz hem dykritikleriň täsirini we Yoruba we eğitim maglumatynda örän möhüm tanyşlaryny çözýäris. Biz bu bilim şertlerini nädip, haçan terjime edip biljek ýagdaýynyň soňky kalitesine täsirleýäris. Biziň modellerimiz Google (+8.7 BLEU) we Facebook M2M (+9.1) Yoruba terjime edilýän we gelejek araştyrmalar üçin ýokary kalitede senaryny düzenleýärler.', 'am': 'በሁለት ቋንቋዎች መተርጓሜ (MT) እና በዝርያ-resource ቋንቋ ሁለት እና በክፍል እና ጥቂት-shot ትርጓሜ ያሳያል፡፡ ምንም እንኳን እነዚህ ምሳሌዎች ብዙ ጊዜ ከፍተኛ የክፍለ ምዕራብ ቋንቋዎች ከታናሹ ክፍለ ሀብት በሚያሳውሱት ምሳሌ ይመረምራሉ፡፡ The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets.  በዚህ ገጽ እና ማኒዮ-20k እና የመጀመሪያይቱን ብዙዎች-ዶሜን የኮርፓስ እና ለኢዮሩባ-እንግሊዝኛ የተመሳሳይ የቴርኔት ፈተና ስፋት ለbenchmarking እናቀርባለን፡፡ ብዙዎች የሆኑት የMT ቡናሌዎች አሰናብናለን እና ለወይኑ ተፈተና እና ደብዳቤዎቹን እና ለደብዳቤዎች እና ማስታወቂያውን እናሳያታለን፡፡ ከዚህ በፊት ተማርነው የነበሩ ምሳሌዎች በማይታወቅ ጥሩ የዳታ ብዛት ይጠይቃሉ እናም የዲያክራሪዎች እና የዮሩባ ትልቁ ስርዓት እና በምርጫው ዳታዎችን እናስተምር፡፡ እንዴት እና ይህ ትርጉም መጨረሻውን እና ማስታወቂያውን እንዴት እንዲያስጨንቃት እናደርጋለን፡፡ ሞዴሌዎቻችን የጎግል (+8.7 BLEU) እና ፌስቡክ M2M (+9.1) በመትረጉም እና ለኋለኛይቱ ምርመራ ከፍተኛ የብልሃት የቅርብ ቅርጽ ማረፊያ ማድረግ ማዘጋጀት ነው፡፡', 'hr': 'Masivno multijezički prevod strojeva (MT) pokazao je impresivne sposobnosti i uključujući prevod nule i nekoliko snimaka između parova jezika niskih resursa. Međutim, te modele često procjenjuju na jezicima visokih resursa s pretpostavkom da se generalizuju na niske resurse. Teškoća procjene modela MT-a na par niskih resursa često je zbog nedostatka standardiziranih podataka za procjenu. U ovom papiru predstavljamo MENYO-20k i prvi paralelni korpus multidomenata s posebno izloženom ortografijom za Yoruba-engleski s standardiziranim dijelom testiranja vlaka za mjerenje. Mi pružamo nekoliko neuralnih MT kriterija i uspoređujemo ih s učinkom popularnih predobučenih (masivno multijezičkih) MT modela i za heterogenezne testove i njegove poddomene. Budući da ovi predobučeni modeli koriste ogromne količine podataka s neodređenom kvalitetom i analiziramo učinak dijamanata i velike karakteristike Yoruba i podataka o obuci. Istražujemo kako i kada ova uvjeta obuke utječe na konačnu kvalitet prevoda i njenu razumljivost. Naši modeli iznosi masivne multijezičke modele poput Google (+8.7 BLEU) i Facebook M2M (+9.1) kada se prevodimo u Yoruba i postavljaju visoke kvalitetne kritike za buduće istraživanje.', 'sw': 'Tafsiri kubwa ya mashine ya lugha mbalimbali (MT) imeonyesha uwezo mzuri na ikiwa ni pamoja na tafsiri sifuri na chache zilizopigwa risasi kati ya wanandoa wa lugha za chini za rasilimali. Hata hivyo, na mifano hii mara nyingi huvutiwa katika lugha za rasilimali zilizo juu kwa dhana kwamba wanajumuisha rasilimali za chini. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets.  In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for Yoruba-English with standardized train-test splits for benchmarking.  Tunatoa misingi kadhaa ya MT ya kidini na kuwalinganisha na utendaji wa mitindo maarufu ya MT kwa ajili ya seti ya majaribio yenye ujasiri na mitindo yake. Tangu mifano haya ya zamani yanatumia kiasi kikubwa cha data kwa kiwango kikubwa cha ukweli na pia tunachambua athari za wagonjwa na utaalam mkubwa wa Yoruba na katika takwimu za mafunzo. Tunatachunguza namna na wakati hali hii ya mafunzo inaathiri kiwango cha mwisho cha tafsiri na ufahamu wake. Mifano yetu inaonyesha mifano ya lugha mbalimbali kama vile Google (+8.7 BLEU) na Facebook M2M (+9.1) wakati wa kutafsiri Yoruba na kuweka bendera kubwa kwa tafiti za baadaye.', 'az': "Çox çox dilli maşın çevirimi (MT) təsirli qabiliyyətləri göstərdi və sıfır və çox çəkilmiş dil çiftləri arasında sıfır və çox çəkilmiş çevirimi də göstərdi. Ancaq bu modellər çox çox çox yüksək ressurs dillərində çox çəkilirlər ki, bu modellər çox düşük ressurs dillərinə təşkil edirlər. Düşük ressurs çiftlərində MT modellərini değerləşdirmək çətinlikləri çox səbəb standardizləndirilmiş değerləşdirmə verilən qurğuları yoxdur. Bu kağızda MENYO-20k və ilk çox-domani paralel korpusu göstərdik. Yoruba-İngilizce üçün standardizləndirilmiş tren-test parçaları göstərdik. Biz bir neçə nöral MT benchmarklərini təmin edirik və onları, həmçinin heterogenel test seti və onun altdomenaları üçün qüvvətli öyrənmiş (çox dilli) MT modellərinin performansına salırıq. Bu əvvəlcə təhsil edilmiş modellerin böyük qiyməti ilə məlumatları istifadə edir və biz də diakritiklərin və Yoruba və təhsil məlumatlarının böyük qiymətini analiz edirik. Biz bu təhsil şərtlərinin necə və nə vaxt təhsil edildiyini və onun anlaşılması mümkün olduğuna görə təhsil edirik. Bizim modellərimiz Yoruba'ya dönüşündə Google (+8.7 BLEU) və Facebook M2M (+9.1) kimi çoxlu dilli modellərdən üstün gəlir və gələcək araştırmalar üçün yüksək kaliteli benchmark ayarlayır.", 'bs': 'Massivno multijezički prevod mašine (MT) pokazao je impresivne mogućnosti i uključujući prevod nule i nekoliko metaka između parova jezika niskih resursa. Međutim, ovi modeli se često procjenjuju na jezicima visokih resursa sa pretpostavkom da generalizuju na niske resurse. Teškoća ocjenjivanja modela MT-a na par niskih resursa često je zbog nedostatka standardizovanih podataka za procjenu. U ovom papiru predstavljamo MENYO-20k i prvi paralelni korpus multidomenata sa posebno izloženom ortografijom za Yoruba-engleski sa standardizovanim dijelom test a vlaka za benchmarking. Mi pružamo nekoliko neuralnih MT kriterija i uspoređujemo ih sa učinkom popularnih predobučenih (masivno multijezičkih) MT modela i za heterogenezne testove i njegove poddomene. Pošto ovi predobučeni modeli koriste ogromne količine podataka sa neodređenom kvalitetom, analiziramo i učinak dijamanata i velike karakteristike Yoruba i podataka o obuci. Istražujemo kako i kada ova uvjeta obuke utječe na konačnu kvalitet prevoda i njenu razumljivost. Naši modeli iznose masivne multijezičke modele poput Google (+8.7 BLEU) i Facebook M2M (+9.1) kada se prevodimo u Yoruba i postavljaju visoke kvalitetne kritike za buduće istraživanje.', 'ca': "La traducció màquina massivament multilingüe (MT) ha mostrat capacitats impressionants i inclou traducció de zero i pocs tiros entre parelles de llenguatges de baix recursos. Tot i així, sovint aquests models es valoren en llengües amb recursos alts, suposant que s'generalitzen a llengües amb recursos baixos. La dificultat d'evaluar models MT en parells de baixos recursos sovint es deu a la falta de conjunts de dades estandaritzats d'evaluació. En aquest article presentem MENYO-20k i el primer corpus paral·lel de múltiples dominis amb una ortografia especialment curada per Yoruba-English amb partits estandaritzats de prova de tren per comparació. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains.  Com que aquests models pré-entrenats utilitzen grans quantitats de dades amb qualitat incerta i també analitzem l'efecte dels diacrítics i una característica principal de Yoruba i en les dades d'entrenament. Investiguem com i quan aquesta condició d'entrenament afecta la qualitat final d'una traducció i la seva comprensibilitat. Els nostres models superen molts models multilingües com Google (+8,7 BLEU) i Facebook M2M (+9,1) quan es traduis a Yoruba i estableix un punt de referència d'alta qualitat per a la futura investigació.", 'cs': 'Masivní vícejazyčný strojový překlad (MT) prokázal působivé schopnosti a zahrnuje nulový a několik záběrů překladu mezi jazykovými páry s nízkými zdroji. Tyto modely jsou však často hodnoceny na jazycích s vysokými zdroji s předpokladem, že se zobecňují na jazyky s nízkými zdroji. Obtížnost hodnocení MT modelů na párech s nízkými zdroji je často způsobena nedostatkem standardizovaných hodnotících dat. V tomto článku představujeme MENYO-20k a první multi-doménový paralelní korpus se speciálně kurovanou pravopisem pro yorubu-angličtinu se standardizovanými rozděleními vlakových testů pro benchmarking. Poskytujeme několik neuronových MT benchmarků a porovnáváme je s výkonem populárních předškolených (masivně vícejazyčných) MT modelů jak pro heterogenní testovací sadu, tak pro její subdomény. Vzhledem k tomu, že tyto předškolené modely využívají obrovské množství dat s nejistotou kvalitou a analyzujeme také efekt diakritiky a hlavní charakteristiku Yoruby a v tréninkových datech. Zkoumáme, jak a kdy tato podmínka školení ovlivňuje konečnou kvalitu překladu a jeho srozumitelnost. Naše modely překonávají masivně vícejazyčné modely, jako jsou Google (+8.7 BLEU) a Facebook M2M (+9.1), při překladu do Yoruby a nastavují vysoké měřítko kvality pro budoucí výzkum.', 'et': 'Massiivselt mitmekeelselt masintõlge (MT) on näidanud muljetavaldavaid võimalusi ja hõlmanud null- ja mõnevõtteid vähese ressursiga keelepaaride vahel. Kuid neid mudeleid hinnatakse sageli suure ressursiga keeltes eeldusega, et need üldistuvad vähese ressursiga keelteks. Madalate ressurssidega paaride MT mudelite hindamise raskus on sageli tingitud standardiseeritud hindamisandmekogumite puudumisest. Käesolevas töös tutvustame MENYO-20k ja esimest mitmevaldkondlikku paralleelkorpust spetsiaalselt kureeritud ortograafiaga Yoruba-inglise keele jaoks koos standarditud rongitesti jaotustega võrdlusanalüüsi jaoks. Pakume mitmeid neuraalseid MT võrdlusnäitajaid ja võrdleme neid populaarsete eelkoolitud (massiliselt mitmekeelsete) MT mudelitega nii heterogeense testikomplekti kui ka selle alamdomeenide jaoks. Kuna need eelkoolitud mudelid kasutavad tohutuid koguseid ebakindla kvaliteediga andmeid ning analüüsime ka diakriitika mõju ja Yoruba põhiomadust ning treeninguandmeid. Uurime, kuidas ja millal see treeningtingimus mõjutab tõlke lõplikku kvaliteeti ja mõistetavust. Meie mudelid jõuavad Yorubasse tõlkimisel üle massiliselt mitmekeelsete mudelite, nagu Google (+8.7 BLEU) ja Facebook M2M (+9.1), ning seavad tulevastele uuringutele kõrge kvaliteedi võrdlusaluse.', 'bn': 'বিশেষ ভাষায় বহুভাষায় মেশিন অনুবাদ (এমটি) দেখিয়েছে আকর্ষণীয় ক্ষমতা এবং যার মধ্যে রয়েছে শূন্য এবং কয়েকটি গুলি অনুবাদ। তবে এই মডেলগুলো প্রায়শই উচ্চ মূল্য ভাষায় মূল্যায়ন করা হচ্ছে এই ধারণার মাধ্যমে যে তারা কম সম্পদের কাছে সাধারণ করে। কম-সম্পদ জোড়ায় MT মডেল মানানোর কষ্ট প্রায়শই স্ট্যান্ডারেশন ডাটাসেটের অভাবের কারণে। এই কাগজটিতে আমরা মেনইয়ো-২০ক এবং প্রথম বহুডোমেইন প্যারালেল কোর্পাসের সাথে উপস্থাপন করি যাদের বিশেষ করে ইয়রুবা- ইংরেজীর জন্য একটি কুর্দিত অর্থোগ্রাফ আমরা বেশ কয়েকটি নিউরেল এমটি বেনমার্ক দিয়েছি এবং জনপ্রিয় প্রশিক্ষণের (ব্যাপক বহুভাষায়) এমটি মডেলের তুলনায় তাদের উভয়কেই উৎপীড়নের পরীক্ষার স এই পূর্বপ্রশিক্ষিত মডেলগুলো বিশাল পরিমাণ তথ্য ব্যবহার করে নির্দিষ্ট মানের সাথে এবং আমরা ডায়ারিক্টরের প্রভাব বিশ্লেষণ করি এবং ইয়রুবার প্ We investigate how and when this training condition affects the final quality of a translation and its understandability. আমাদের মডেল গুগল (+8.7 বিলিউ) এবং ফেসবুক এম২M (+9.1) অনুবাদ করে ইয়রুবায় অনুবাদ করে ভবিষ্যত গবেষণার জন্য বেনম্যার্ক নির্ধারণ করে।', 'fi': 'Massiivisesti monikielinen konekäännös (MT) on osoittanut vaikuttavia ominaisuuksia, ja se sisältää nolla- ja muutaman laukauksen käännöksiä vähäresurssisten kieliparien välillä. Kuitenkin näitä malleja arvioidaan usein korkean resurssin kielillä olettaen, että ne yleistyvät vähäresurssisiin kieliin. Matalan resurssin parien MT-mallien arvioinnin vaikeus johtuu usein standardoitujen arviointiaineistojen puutteesta. Tässä artikkelissa esitellään MENYO-20k ja ensimmäinen moniulotteinen rinnakkaiskorpus, jossa on erityisesti kuratoitu ortografia yoruba-englantia varten standardoiduilla junatestisplit benchmarking-menetelmillä. Tarjoamme useita neuraalisia MT-vertailuarvoja ja vertaamme niitä suosittujen esikoulutettujen (massiivisesti monikielisten) MT-mallien suorituskykyyn sekä heterogeenisen testijoukon että sen aliverkkotunnusten osalta. Koska nämä esikoulutetut mallit käyttävät valtavia määriä dataa epävarmalla laadulla ja analysoimme myös diakriitikkojen vaikutusta ja Yoruban pääpiirteitä sekä harjoitusdataa. Tutkimme, miten ja milloin tämä koulutusehto vaikuttaa käännöksen lopulliseen laatuun ja ymmärrettävyyteen. Mallimme suoriutuvat valtavasti monikielisistä malleista, kuten Google (+8.7 BLEU) ja Facebook M2M (+9.1), kun ne käännetään yorubaan ja asetetaan korkealuokkainen vertailukohta tulevalle tutkimukselle.', 'hy': 'Մեծալեզվով բազմալեզվով մեքենայի թարգմանությունը (MT) ցույց է տալիս տպավորիչ հնարավորություններ, ներառյալ զրոյի և քիչ նկարների թարգմանությունը ցածր ռեսուրսների լեզվի զույգերի միջև: However and these models are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones.  Նվագ ռեսուրսների զույգերի MT մոդելների գնահատման դժվարությունը հաճախ պատճառ է ստանդարտ գնահատման տվյալների բացակայության պատճառով: Այս թղթի մեջ մենք ներկայացնում ենք Մենիո-20k-ը և առաջին բազմաբնական զուգահեռ կորպոսը, որն ունի Յորուբա-Անգլերենի համար հատկապես կորտերացված օրթոգրաֆիա, որն ունի ստանդարտ գնացքի թեստերի բաժանմունքներ համեմատական ն Մենք տրամադրում ենք մի քանի նյարդային ՄԹ հարաբերականներ և համեմատում ենք դրանք նախապատրաստված (զանգվածային բազմալեզու) ՄԹ մոդելների արտադրողության հետ, ինչպես հետերոգեն փորձարկումների համակարգի, ինչպես նաև դրա ենթադաշտերի համար: Քանի որ այս նախապատրաստված մոդելները օգտագործում են հսկայական տվյալներ անորոշակի որակով, և մենք նաև վերլուծում ենք դիակրիտիկայի ազդեցությունը և Յորուբայի հիմնական առանձնահատկությունը և ուսուցման տվյալներում: Մենք ուսումնասիրում ենք, թե ինչպես և երբ այս ուսումնասիրության պայմանը ազդում է թարգմանության վերջնական որակի վրա և դրանց հասկանալիության վրա: Մեր մոդելները զանգվածային շատ լեզվով մոդելներ են արտադրում, ինչպիսիք են Google (+8.7 Blaus) և Facebook M2M (+9.1), երբ թարգմանվում են Յորուբա և ապագա ուսումնասիրությունների համար բարձր որակի համեմատական նպատակ են սահմանում:', 'sk': 'Masivno večjezično strojno prevajanje (MT) je pokazalo impresivne zmogljivosti in vključevalo ničelne in nekaj posnetkov prevajanja med jezikovnimi pari z nizkimi viri. Vendar pa se ti modeli pogosto ocenjujejo na jezikih z visokimi viri z domnevo, da se posplošijo na jezike z nizkimi viri. Težava ocenjevanja modelov MT na parih z nizkimi viri je pogosto posledica pomanjkanja standardiziranih vrednotenjskih podatkov. V prispevku predstavljamo MENYO-20k in prvi večdomenski paralelni korpus s posebej kurirano ortografijo za yorubsko-angleščino s standardiziranimi preskusnimi deli vlakov za primerjalno analizo. Zagotavljamo več nevronskih referenčnih vrednosti MT in jih primerjamo z zmogljivostjo priljubljenih predhodno usposobljenih (množično večjezičnih) MT modelov tako za heterogen testni nabor kot njegove poddomene. Ker ti vnaprej usposobljeni modeli uporabljajo ogromne količine podatkov z negotovo kakovostjo, analiziramo tudi učinek diakritikov in glavne značilnosti Yorube ter v podatkih o treningu. Preučujemo, kako in kdaj ta pogoj usposabljanja vpliva na končno kakovost prevoda in njegovo razumljivost. Naši modeli so pri prevajanju v Yoruba izjemno večjezične modele, kot sta Google (+8.7 BLEU) in Facebook M2M (+9.1), in postavljajo visoko kakovostno merilo za prihodnje raziskave.', 'he': 'התרגום מכונות רבות לשפות (MT) הראה יכולות מרשים, כולל התרגום אפס ומספר יריות בין זוגות שפות נמוכות משאבים. עם זאת, ודוגמנים אלה לעתים קרובות הוערכים בשפות משאבים גבוהים בהנחה שהם מתפשטים לשפות משאבים נמוכים. הקשה להעריך מודלים MT על זוגות משאבים נמוכים לעתים קרובות בגלל חוסר מסמכי עריכה סטנדרטיזציונים. בעיתון הזה, ואנחנו מציגים את MENYO-20k והקופוס המקביל הראשון עם אורטוגרפיה מיוחדת מטורפת ליורובה-אנגלית עם מחלקות מבחן רכבת סטנדרטיזציונים למבחן. אנחנו מספקים מספר רמזים MT עצביים ושוואים אותם לביצוע של מודלים MT מאומנים מראש (הרבה שפתיים) פופולריים מאחר שהדוגמנים המאמנים הללו משתמשים בכמות עצומות של נתונים עם איכות לא בטוחה, ואנחנו גם מנתחים את ההשפעה של החיתולים והאופיינים העיקריים של יורובה ובנתוני האימונים. אנו חוקרים איך ומתי מצב האימון הזה משפיע על איכות הסופית של תרגום והבינה שלו. הדוגמנים שלנו יוצאים מעל דוגמנים רבות שפות באופן מסיבי כמו גוגל (+8.7 BLEU) ופייסבוק M2M (+9.1) כאשר מתרגמים ליורובה וקבועים רמז איכות גבוהה למחקר עתידי.', 'ha': "@ item: inmenu A lokacin da waɗannan misãlai ko da yawa an ƙaddara su a cikin harshen masu sarki da zato da za'a zartar da su zuwa masu ƙasƙanci. Babu zartar da yin evaluation ga misãlai na MT kan nau'in-resource ko da yawa don a ƙara da tsarin bayani na ƙaddara. Ga wannan takardan kuma munã halatar da MENYO-20k da na farkon komai da multi-Domen parallel kornas, yana da wani abu mai ƙayyade ortografi wa Yoruba-Ingiriya da kuma yana da jarrabi-jarrabi na jerin da aka yi wa bankening. Tuna samar da misalin misalin MT masu ƙaranci ko kuma Muke samfani da su ga aikin misalin misalin MT na farko da aka yi wa musamman (mai girma wa multilingulin) da sami'a ga jarrabo masu lokacin da yake ƙarami. Tana da waɗannan misãlai masu farawa suka yi amfani da yawan data mai girma da tsari ba'a sani ba kuma za mu yi anayyar amfani da matsayin diakriya da muhimmin haske na Yoruba da kuma a cikin data na ƙidãya. Munã tambaya yadda da idan wannan muhalli ya wajaba ga fassarar ta ƙarshen fassarar da garanta. Modalmala mu na samun misãlai masu cikin mulki-lingui kamar Google (+8.7 BLEU) da Facebook M2M (+9.1) idan an fassar zuwa Yoruba kuma ke daidaita wani bango mai nau'i wa research na gaba ɗaya.", 'jv': 'FullName Kamulé karo model iki dadi nyimpen langgar-akeh liyane karo perusahaan langgar kuwi duluran, nik awak dhéwé kuwi duluran ngono kuwi anake sing paling kelas. Rasane In this paper and we present MENYO-2k and the first multi-domain Paralelel corus with a special cured ortHography for Yobah-ingles with Standard Line-test Split for bench-marking. Awak dhéwé ngewehke hukum sing nggawe MT alat karo ngono nggawe gerarané karo hal-hal popular sing dumadhi podho (masawit multilenguang) MT model sing ngewehke nggawe gerarané ketekaan karo hal-hal sing suot Dino sampeyan model sing wis arep beranduh akeh dumateng kuwi, dadi awak dhéwé ngono kuwi ora ngerasakno ngono awak dhéwé ngerasakno efek diakritik lan ngerasakno kanggo ngerasakno itépakan langkung werak dhéwé ning data retèning. Awak dhéwé nyongkap piye lan pas kuwi, dengané awak dhéwé kuwi nggawe kaliwat sistêm kanggo tarjamahan lan kuwi mau ngerasakno. Awak modelus dhéwé iso nggawe akeh akeh multilenguasi model lagi Google (+.8.7 BIUE) lan Google M2M (+.9.1) nang terjamahan kanggo nyanggalih jutir kayata beka-nesaturan kanggo langkung diangkat dhéwé.', 'bo': 'འཇིག་རྟེན་མང་ཆེ་བའི་སྐད་རིགས་ཀྱི་ཡིག ཡིན་ནའང་། མིག་གཟུགས་འདི་དག་ནི་རྒྱུ་དངོས་ཐོག་ཁུངས་ཀྱི་སྐད་རིགས་མཐོ་ཤིག་ཡིན་པ་ལས་མང་པོ་ཞིག་བསྐྱེད་ཡོད། MT མིག་དཔེ་གཞུང་རྐྱེན་ཚད་ཀྱི་མཐོ་རིམ་ཆ་ཉུང་བའི་རྐྱེན་གྲངས་ཀ་འདི་རྒྱུན འོག ང་ཚོས་རང་ཉིད་ཀྱི་ཕྱོགས་འགྱུར་བའི་ཚད་གཞིའི་གྲངས་སུ་མཐུན་བཟོ་བ་ཡིན། སྔོན་གྲངས་སྒྲིག་འཛིན་གྱི་མིག་གཟུགས་འདི་དག་གིས་གནས་ཚུལ་གསལ་མེད་པའི་ཚད་ལྡན་གྱི་ཚད་ཆེ་བ་སྤྱོད་ཐབས་བྱས་ནས་ ང་ཚོས་རང་ཉིད་ལྟ་སྟངས་འཛིན་གྱི་གནས་སྟངས་འདིས་ནི་ཚོར་ཡིག་ཆའི་མཐའ་མཇུག་གི་གནས་སྟངས་དང་ལྟ་སྟངས་རྟོགས་ Our models outperform massively multilingual models such as Google (+8.7 BLEU) and Facebook M2M (+9.1) when translating to Yoruba and setting a high quality benchmark for future research.'}
{'en': 'Like Chalk and Cheese? On the Effects of Translationese in MT Training MT  Training', 'ar': 'مثل الطباشير والجبن؟ حول تأثيرات الترجمة في التدريب على مسرح ماجنت', 'pt': 'Como giz e queijo? Sobre os efeitos da tradução no treinamento de MT', 'es': '¿Cómo tiza y queso? Sobre los efectos de la traducción en la formación en MT', 'fr': 'Comme la craie et le fromage\xa0? Sur les effets du traducteur dans la formation par magnétoscopie', 'ja': 'チョークとチーズ？ MTトレーニングにおける翻訳の効果について', 'zh': '好粉笔酪乎? 浅谈译在机器翻译培训中', 'hi': 'चाक और पनीर की तरह? एमटी प्रशिक्षण में अनुवाद के प्रभावों पर', 'ru': 'Как "Мел и сыр"? О влиянии перевода на русский язык в обучении МП', 'ga': 'Cosúil le Cailc agus Cáis? Ar Éifeachtaí Aistriúcháin in Oiliúint MT', 'hu': 'Mint a Kréta és Sajt? A fordító hatásai az MT képzésben', 'el': 'Σαν κιμωλία και τυρί; Σχετικά με τις επιπτώσεις της μεταφραστικής γλώσσας στην εκπαίδευση ΜΤ', 'ka': 'კარჲ ფალკ თ ჟთპ? Comment', 'kk': 'Шалк және Шайз сияқты? MT оқытуындағы аудармалардың эффекттері', 'it': 'Come Chalk and Cheese? Gli effetti del traduttore nella formazione MT', 'mk': 'Како Чалк и Сир? На ефектите на преведувањето во MT обуката', 'lt': 'Like Chalk and Cheese?  Vertimo vertimo raštu poveikis MT mokymui', 'ms': 'Seperti Chalk dan Cheese? Pada Kesan Terjemahan dalam Latihan MT', 'ml': 'ചാള്\u200dക്കും ചീസും പോലെ? MT പരിശീലനത്തില്\u200d പരിഭാഷപ്രഭാവങ്ങളില്\u200d', 'mt': 'Bħal Chalk u Cheese? Dwar l-Effetti tat-Traduzzjoniż fit-Taħriġ MT', 'mn': 'Чалк, бяслаг шиг? MT дасгал хөгжүүлэх үйл ажиллагааны нөлөө', 'ro': 'Ca Chalk and cheese? Despre efectele traducătorului în formarea MT', 'no': 'Som Chalk og Cheese? På effektane av omsetjinga i MT- trening', 'pl': 'Jak Kreda z Serem? O wpływach tłumaczenia w szkoleniu MT', 'sr': 'Kao Chalk i Cheese? Na efekte prevode u MT obuci', 'so': 'Like Chalk and Cheese?  Effects of Translation in MT Training', 'sv': 'Som Chalk and Cheese? Om effekterna av översättare i MT-utbildning', 'ta': 'Chalk மற்றும் சீஸ் போல? MT பயிற்சியில் மொழிபெயர்ப்பு விளைவுகள்', 'si': 'චැල්ක් සහ චීස් වගේ? Name', 'ur': 'چالک اور چیز کی طرح؟ MT треنینگ میں ترجمن کے اثرات پر', 'uz': 'Chalk va Cheese kabi? Tarjima effektlari', 'vi': 'Như Chalk và Cheese à? Về phản ứng của dịch hạch trong khóa huấn luyện MTV', 'bg': 'Като креда и сирене? За ефектите на превода в обучението по МТ', 'nl': 'Zoals Chalk and Cheese? Over de effecten van Translationese in MT Training', 'hr': 'Kao Chalk i sir? Na učinak prevode u MT obuci', 'da': 'Som Chalk and Cheese? Om virkningerne af oversættelse i MT-uddannelse', 'de': 'Wie Kreide und Käse? Über die Auswirkungen von Translationese in MT Training', 'ko': '분필이랑 치즈 같은데?번역이 기계 번역 훈련에서의 작용을 논하다', 'id': 'Like Chalk and Cheese?  Pada Efek Terjemahan dalam Latihan MT', 'tr': "Kalk we Cheese ýaly? MT Training'de terjime etkisi barada", 'sw': 'Kama Chalk na Cheese? Kuhusu madhara ya Tafsiri ya Tafsiri katika mafunzo ya MT', 'fa': 'مثل چال و پنير؟ روی اثرات ترجمه در آموزش MT', 'af': 'Soos Chalk en Cheese? Op die Effekte van Vertaling in MT Oefening', 'am': 'Like Chalk and Cheese?  ትርጉም በMT ትምህርት ላይ', 'bn': 'চ্যালক আর চীজের মতো? On the Effects of Translationese in MT Training', 'hy': 'Like Chalk and Cheese?  MT-ի ուսումնասիրության թարգմանության ազդեցությունների վրա', 'az': 'Chalk və Cheese kimi? Comment', 'sq': 'Si Chalk dhe Cheese? Në efektet e translacionit në trainimin MT', 'et': 'Nagu Kriit ja Juust? Tõlkimise mõju MT koolitusel', 'cs': 'Jako Křída a sýr? O vlivech Translationese v MT školení', 'fi': 'Kuten liitu ja juusto? Kääntämisen vaikutuksista MT-koulutukseen', 'bs': 'Kao Chalk i Cheese? Na učinak prevode u MT obuci', 'ca': 'Com Chalk i Cheese? On the Effects of Translationese in MT Training', 'jv': 'Kowe Kelk karo Cheese ? Terjamahan kelambak efek dibuturaké ning acara MT', 'ha': 'Like Chalk and Cheese?  @ item Text character set', 'sk': 'Kot kreda in sir? O učinkih prevajanja v strokovnem usposabljanju', 'he': "כמו צ'אלק וגבינה? על השפעות של תרגומים באימונים MT", 'bo': 'ས་སྨྱུག་དང་རི་སྨོ། དཔེར་ན། MT Training ནང་དུ་ཡིན་སྐད་བསྒྱུར་གྱི་གནོད་འགྲུལ་གྱི་གནོད་པ'}
{'en': 'We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction : the Canadian Hansard. According to automatic metrics and we observe that using parallel data that was produced in the matching translation direction (Authentic source and translationese target) improves translation quality. In cases of data imbalance in terms of translation direction and we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.', 'ar': 'نعيد النظر في موضوع اتجاه الترجمة في البيانات المستخدمة لتدريب أنظمة الترجمة الآلية العصبية والتركيز على سيناريو العالم الحقيقي مع اتجاه الترجمة المعروف والاختلالات في اتجاه الترجمة: الكندي هانسارد. وفقًا للمقاييس التلقائية ، نلاحظ أن استخدام البيانات المتوازية التي تم إنتاجها في اتجاه الترجمة "المطابق" (مصدر أصيل وهدف الترجمة) يحسن جودة الترجمة. في حالات عدم توازن البيانات من حيث اتجاه الترجمة ، نجد أن وضع علامات على اتجاه الترجمة يمكن أن يسد فجوة الأداء. إننا نجري تقييمًا بشريًا يختلف قليلاً عن المقاييس التلقائية ولكنه مع ذلك يؤكد أنه بالنسبة لمجموعة البيانات الفرنسية الإنجليزية هذه والمعروف أنها تحتوي على ترجمات عالية الجودة ومصادر مختلطة أصلية أو ذات علامات ، تتحسن على مصدر الترجمة للتدريب.', 'fr': "Nous revoyons le sujet de la direction de la traduction dans les données utilisées pour la formation des systèmes de traduction automatique neuronale et nous nous concentrons sur un scénario réel avec une direction de traduction connue et des déséquilibres dans le sens de la traduction\xa0: le Hansard canadien. Selon les métriques automatiques, nous observons que l'utilisation de données parallèles produites dans le sens de traduction «\xa0correspondant\xa0» (source authentique et cible traduisienne) améliore la qualité de la traduction. En cas de déséquilibre des données en termes de direction de traduction, nous constatons que le balisage du sens de la traduction peut combler l'écart de performance. Nous effectuons une évaluation humaine qui diffère légèrement des métriques automatiques et confirme néanmoins que pour cet ensemble de données français-anglais qui est connu pour contenir des traductions de haute qualité et des sources mixtes authentiques ou balisées, des améliorations par rapport à la source traduisienne pour la formation.", 'pt': 'Revisitamos o tópico de direção de tradução nos dados usados para treinar sistemas de tradução automática neural e focamos em um cenário do mundo real com direção de tradução conhecida e desequilíbrios na direção de tradução: o canadense Hansard. De acordo com as métricas automáticas e observamos que o uso de dados paralelos que foram produzidos na direção de tradução “correspondente” (fonte autêntica e destino traduzido) melhora a qualidade da tradução. Em casos de desequilíbrio de dados em termos de direção de tradução e descobrimos que a marcação da direção de tradução pode fechar a lacuna de desempenho. Realizamos uma avaliação humana que difere um pouco das métricas automáticas e, no entanto, confirma que, para esse conjunto de dados francês-inglês, conhecido por conter traduções de alta qualidade e fonte mista autêntica ou marcada, melhora a fonte traduzida para treinamento.', 'es': 'Volvemos a abordar el tema de la dirección de la traducción en los datos utilizados para el entrenamiento de los sistemas de traducción automática neuronal y nos centramos en un escenario del mundo real con una dirección de traducción conocida y desequilibrios en la dirección de la traducción: el Hansard canadiense. De acuerdo con las métricas automáticas, observamos que el uso de datos paralelos que se produjeron en la dirección de traducción «coincidente» (fuente auténtica y destino de traducción) mejora la calidad de la traducción. En casos de desequilibrio de datos en términos de dirección de traducción, encontramos que el etiquetado de la dirección de traducción puede cerrar la brecha de rendimiento. Realizamos una evaluación humana que difiere ligeramente de las métricas automáticas y, sin embargo, confirma que para este conjunto de datos francés-inglés que se sabe que contiene traducciones de alta calidad y fuentes mixtas auténticas o etiquetadas mejora la fuente de traducción para la capacitación.', 'ja': '神経機械翻訳システムのトレーニングに使用されたデータの翻訳方向のトピックを再検討し、翻訳方向と翻訳方向の不均衡が知られている現実のシナリオに焦点を当てます。カナダのハンサードです。自動指標によると、「マッチング」翻訳方向（真正なソースと翻訳ターゲット）で生成された並列データを使用すると、翻訳品質が向上することがわかります。翻訳方向のデータの不均衡の場合、翻訳方向のタグ付けはパフォーマンスギャップを埋めることができます。自動指標とは若干異なる人間評価を行いますが、高品質の翻訳と本物またはタグ付けされた混合ソースを含むことで知られているこのフランス語と英語のデータセットでは、トレーニング用の翻訳ソースよりも向上することを確認しています。', 'zh': '重审神经机器翻译统之数,专注于知译方面不平之实:加拿大汉萨德。 以自指标观之,用于匹配(真源与译)并行数以重译质。 于译方数不平者,见标记缩性能差。 所行人工评估与自指标略有不同,然犹确认,于已知包含高质量译与真标混合源法语 - 英语数据集,比于训练之译源,该数集有所改进。', 'hi': 'हम न्यूरल मशीन अनुवाद प्रणालियों के प्रशिक्षण के लिए उपयोग किए जाने वाले डेटा में अनुवाद दिशा के विषय पर फिर से विचार करते हैं और अनुवाद दिशा में ज्ञात अनुवाद दिशा और असंतुलन के साथ एक वास्तविक दुनिया के परिदृश्य पर ध्यान केंद्रित करते हैं: कनाडाई हंसार्ड। स्वचालित मैट्रिक्स के अनुसार और हम देखते हैं कि समानांतर डेटा का उपयोग करना जो "मिलान" अनुवाद दिशा (प्रामाणिक स्रोत और अनुवाद लक्ष्य) में उत्पादित किया गया था, अनुवाद की गुणवत्ता में सुधार करता है। अनुवाद दिशा के संदर्भ में डेटा असंतुलन के मामलों में और हम पाते हैं कि अनुवाद दिशा की टैगिंग प्रदर्शन अंतर को बंद कर सकती है। हम एक मानव मूल्यांकन करते हैं जो स्वचालित मीट्रिक से थोड़ा अलग होता है और फिर भी पुष्टि करता है कि इस फ्रांसीसी-अंग्रेजी डेटासेट के लिए जो उच्च गुणवत्ता वाले अनुवाद और प्रामाणिक या टैग किए गए मिश्रित स्रोत को शामिल करने के लिए जाना जाता है, प्रशिक्षण के लिए अनुवादस्रोत पर सुधार करता है।', 'ru': 'Мы возвращаемся к теме направления перевода в данных, используемых для обучения систем нейронного машинного перевода и фокусируемся на реальном сценарии с известным направлением перевода и дисбалансами в направлении перевода: канадский Хансард. Согласно автоматическим метрикам и мы наблюдаем, что использование параллельных данных, которые были получены в направлении «согласования» перевода (аутентичный исходный текст и цель переводчика) улучшает качество перевода. В случаях дисбаланса данных с точки зрения направления перевода и мы находим, что тегирование направления перевода может устранить разрыв в производительности. Мы проводим человеческую оценку, которая несколько отличается от автоматических метрик и, тем не менее, подтверждает, что для этого французско-английского набора данных, который, как известно, содержит высококачественные переводы и аутентичный или помеченный смешанный источник, улучшается по сравнению с переводческим источником для обучения.', 'ga': 'Déanaimid athchuairt ar ábhar treo an aistriúcháin sna sonraí a úsáidtear chun córais néar-aistriúcháin meaisín a thraenáil agus dírímid ar chás fíor-dhomhanda a bhfuil treoir aistriúcháin ar eolas aige agus míchothromaíochtaí i dtreo an aistriúcháin: an Hansard Cheanada. De réir méadrachta uathoibríocha agus tugaimid faoi deara go bhfeabhsaítear cáilíocht an aistriúcháin trí shonraí comhthreomhara a táirgeadh sa treo aistriúcháin “meaitseála” (Fóinse barántúla agus targaid aistriúcháin). I gcásanna éagothroime sonraí i dtéarmaí treo an aistriúcháin agus feicimid gur féidir le clibeáil treo an aistriúcháin an bhearna feidhmíochta a dhúnadh. Déanaimid measúnú daonna atá beagán difriúil ó na méadrachtaí uathoibríocha agus mar sin féin dearbhaímid go bhfeabhsaítear thar an bhfoinse aistritheach don oiliúint don tacar sonraí Fraincis-Béarla seo arb eol go bhfuil aistriúcháin ardcháilíochta ann agus foinse mheasctha bharántúil nó chlibeáilte.', 'ka': "ჩვენ შევცვალოთ განსაგულისხმების მისამართი მონაცემების გარგულისხმებისთვის მონაცემების გარგულისხმებისთვის და განსაგულისხმებისთვის რეალური მსოფლიო სინარიოს გარგულისხმებისთვი ავტომატიკური მეტრიკის განმავლობაზე და ჩვენ დავხედავთ, რომ გამოყენება პარალელური მონაცემების გამოყენება, რომელიც გამოყენებულია 'matching' translation direction (Authentic source and translationese target) გასაგრძელება სინა მონაცემების განმავლობის შემთხვევაში შეგვიძლია გადაწყვეტა განმავლობა განმავლობაში და ჩვენ ვფიქრობთ, რომ გადაწყვეტა მხარეს განმავლობაში შეუძლია გადახუროთ ჩვენ ვაკეთებთ ადამიანის განსაზღვრება, რომელიც ძალიან განსხვავებულია ავტომატიკური მეტრიკის განსხვავებაზე, მაგრამ მაგრამ განსხვავებულია, რომ ამ ფრანუს ანგლისური მონაცემების კონტაქტისთვის, რომელიც უცნობიან,", 'el': 'Εξετάζουμε ξανά το θέμα της κατεύθυνσης μετάφρασης στα δεδομένα που χρησιμοποιούνται για την εκπαίδευση νευρωνικών συστημάτων μηχανικής μετάφρασης και εστιάζουμε σε ένα πραγματικό σενάριο με γνωστή κατεύθυνση μετάφρασης και ανισορροπίες στην κατεύθυνση μετάφρασης: το Καναδικό Χάνσαρντ. Σύμφωνα με τις αυτόματες μετρήσεις και παρατηρούμε ότι η χρήση παράλληλων δεδομένων που παράγονται με την κατεύθυνση "αντιστοίχισης" της μετάφρασης (αυθεντική πηγή και μεταφραστικός στόχος) βελτιώνει την ποιότητα της μετάφρασης. Σε περιπτώσεις ανισορροπίας δεδομένων όσον αφορά την κατεύθυνση μετάφρασης και διαπιστώνουμε ότι η σήμανση της κατεύθυνσης μετάφρασης μπορεί να καλύψει το χάσμα απόδοσης. Εκτελούμε μια ανθρώπινη αξιολόγηση που διαφέρει ελαφρώς από τις αυτόματες μετρήσεις και ωστόσο επιβεβαιώνει ότι για αυτό το γαλλικό-αγγλικό σύνολο δεδομένων που είναι γνωστό ότι περιέχει μεταφράσεις υψηλής ποιότητας και αυθεντική ή κωδικοποιημένη μικτή πηγή βελτιώνεται έναντι της μεταφραστικής πηγής για εκπαίδευση.', 'hu': 'Az idegi gépi fordítási rendszerek képzéséhez használt adatokban újra megvizsgáljuk a fordítási irány témáját, és egy olyan valós forgatókönyvre összpontosítunk, amelyben ismert fordítási irány és egyensúlyhiányok vannak a fordítási irányban: a kanadai Hansard. Az automatikus mérőszámok szerint megfigyeljük, hogy a "megfelelő" fordítási irányban készült párhuzamos adatok használata (hiteles forrás és fordítási cél) javítja a fordítás minőségét. A fordítási irány tekintetében felmerülő adatok egyensúlyhiánya esetén és úgy találjuk, hogy a fordítási irány címkézése csökkentheti a teljesítményhiányt. Olyan emberi értékelést végzünk, amely kissé eltér az automatikus mérőktől, de mégis megerősíti, hogy ez a francia-angol adatkészlet esetében, amely ismert, hogy magas színvonalú fordításokat és hiteles vagy címkézett vegyes forrásokat tartalmaz, javul a fordítási forráshoz képest.', 'it': "Riprendiamo il tema della direzione della traduzione nei dati utilizzati per addestrare sistemi neurali di traduzione automatica e focalizzandoci su uno scenario reale con direzione di traduzione nota e squilibri nella direzione della traduzione: il Canadian Hansard. Secondo le metriche automatiche e osserviamo che l'utilizzo di dati paralleli che sono stati prodotti nella direzione di traduzione 'matching' (fonte autentica e target translationese) migliora la qualità della traduzione. In caso di squilibrio dei dati in termini di direzione della traduzione e scopriamo che il tagging della direzione della traduzione può colmare il gap di prestazioni. Eseguiamo una valutazione umana che differisce leggermente dalle metriche automatiche e tuttavia conferma che per questo dataset francese-inglese che è noto per contenere traduzioni di alta qualità e fonti miste autentiche o taggate migliora rispetto alla fonte traduzionese per la formazione.", 'mk': "Ја прегледаме темата на насоката на преводот во податоците кои се користат за обука на системите на превод на невропските машини и се фокусираме на сценариото на реалниот свет со позната насока на преводот и нерамнотежи во насоката на преводот: Канадскиот Хансард. According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality.  Во случаите на нерамнотежа на податоците во поглед на насоката на преводот и откриваме дека означувањето на насоката на преводот може да ја затвори празнината во перформансата. Ние изведуваме човечка проценка која малку се разликува од автоматската метрика и сепак потврдува дека за овој француско-англиски податок кој е познат како содржи висококвалитетни преводи и автентичен или означен мешан извор се подобрува над изворот на превод за обука.", 'lt': 'Mes persvarstome vertimo krypties klausimą, susijusią su duomenimis, naudojamais nervinių mašin ų vertimo sistemų mokymui, ir daugiausia dėmesio skiriame realaus pasaulio scenarijui, kurio vertimo kryptis žinoma ir vertimo krypties disbalansas yra Kanados Hansardas. Remiantis automatinėmis metrijomis ir pastebime, kad panaudojant lygiagrečius duomenis, gautus "atitinkančiu" vertimo kryptimi (autentiškas šaltinis ir vertimo tikslas), pagerinama vertimo kokybė. Jei duomenų pusiausvyra vertimo krypties atžvilgiu yra disbalansuota, ir nustatome, kad vertimo krypties žymėjimas gali sumažinti veiklos spragą. Mes atliekame žmogiškąjį vertinimą, kuris šiek tiek skiriasi nuo automatinių metrijų, tačiau vis dėlto patvirtiname, kad šiame prancūzų ir anglų duomenų rinkinyje, kuriame žinoma, kad jame yra aukštos kokybės vertimai ir autentiškas arba pažymėtas mišrus šaltinis, geriau nei vertimo šaltinis mokymui.', 'kk': 'Біз невралдық компьютердің аудармалы жүйелерді оқыту үшін қолданылатын деректердің аудармалы бағыттамасын қайта қайта қарап, білетін аудармалы бағыттамасын және аудармалы бағыттамасын қалай әлемдік сценариясына на Автоматты метрикаға сәйкес, біз "сәйкес" аудармалы бағытта жасалған параллел деректерді қолдану (аудармалы көзі мен аудармалы мақсатты) сапатты жақсартып көрдік. Аудару бағытындағы деректердің бағдарламасының бағдарламасында тәуелсіздігі болса, аудару бағытындағы белгілерін жабуға болады. Біз автоматты метрикадан бірнеше айырмашылық адамның оқиғасын орындаймыз. Бірақ бірақ ағылшын- ағылшын деректер жиынының оқиғаларының жоғары сапатты аудармаларды және автоматты және белгіленген араластырылған көзінің аудармал', 'ms': "We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction: the Canadian Hansard.  Menurut metrik automatik dan kita memperhatikan bahawa menggunakan data selari yang dihasilkan dalam arah terjemahan 'sepadan' (Sumber autentik dan sasaran terjemahan) meningkatkan kualiti terjemahan. Dalam kes ketidakseimbangan data dalam terma arah terjemahan dan kita mendapati bahawa tag arah terjemahan boleh menutup ruang prestasi. Kami melakukan penilaian manusia yang sedikit berbeza dari metrik automatik dan namun tetap mengesahkan bahawa bagi set data Perancis-Inggeris ini yang diketahui mengandungi terjemahan kualiti tinggi dan sumber campuran yang sah atau ditanda meningkat lebih daripada sumber terjemahan untuk latihan.", 'mt': 'Aħna nirrevedu s-suġġett tad-direzzjoni tat-traduzzjoni fid-dejta użata għat-taħriġ tas-sistemi tat-traduzzjoni tal-magni newrali u niffokaw fuq xenarju dinji reali b’direzzjoni tat-traduzzjoni magħrufa u żbilanċi fid-direzzjoni tat-traduzzjoni: il-Canadian Hansard. Skont metriċi awtomatiċi u ninsabu li l-użu ta’ dejta parallela li ġiet prodotta fid-direzzjoni tat-traduzzjoni “tqabbil” (sors awtentiku u mira tat-traduzzjoni) itejjeb il-kwalità tat-traduzzjoni. F’każijiet ta’ żbilanċ fid-dejta f’termini ta’ direzzjoni tat-traduzzjoni u nsibu li t-tikkettar tad-direzzjoni tat-traduzzjoni jista’ jnaqqas id-distakk fil-prestazzjoni. Aħna nagħmlu evalwazzjoni umana li hija ftit differenti mill-metriċi awtomatiċi u madankollu tikkonferma li għal dan is-sett ta’ dejta Franċiż-Ingliż li huwa magħruf li fih traduzzjonijiet ta’ kwalità għolja u sors imħallat awtentiku jew ittikkettat itejjeb aktar minn sors ta’ traduzzjoni għat-taħriġ.', 'ml': "പരിഭാഷത്തിന്റെ തിരിച്ചറിയാനുള്ള വിവരങ്ങളില്\u200d ഉപയോഗിക്കുന്ന ന്യൂറല്\u200d മെഷീന്\u200d പരിശീലന സിസ്റ്റമുകള്\u200dക്ക് ഉപയോഗിക്കുന്ന വിവരങ്ങളുടെ വിവ സ്വയം മെട്രിക്കുകള്\u200d അനുസരിച്ചു് ഞങ്ങള്\u200d നോക്കുന്നുവെങ്കില്\u200d 'മത്സരം ചെയ്യുന്ന' വിഭാഷത്തിന്റെ തിരിച്ചറിയില്\u200d (ആധികാരിക സോ പരിഭാഷത്തിന്റെ തിരിച്ചറിയില്\u200d വിവരങ്ങളുടെ തീവ്രത്തില്\u200d നിലനില്\u200dക്കുന്നതിന്റെ കാര്യങ്ങളില്\u200d പരിഭാഷത് നമ്മള്\u200d ഒരു മനുഷ്യന്റെ വിലാസങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അത് സ്വയം മെട്രിക്കങ്ങളില്\u200d നിന്ന് വ്യത്യസ്തമാകുന്നു. എന്നാലും ഈ ഫ്രെഞ്ച് ഇംഗ്ലീഷ് ഡാറ്റാസറ്റേറ്", 'no': 'Vi gjenoppretter emnet på omsetjingsreksten i dataene som vert brukt for å lære neuralmaskinsomsetjingssystemet og fokuserer på ein verkeleg scenario med kjente omsetjingsrekst og ulikhet i omsetjingsreksten: Kanadansk Hansard. Før automatiske metrikar og vi observerer at med parallelle data som er produsert i « passande » omsetjingsreksten (autentiseringskjelde og translationisk mål) forbetrar omsetjingskvalitet. I tilfelle for data-imbalans i forhold til omsetjingsreksten, og vi finn at merking av omsetjingsreksten kan lukka utgangspunktet. Vi utfører ein menneskelig evaluering som er litt forskjellig frå automatiske metrikar, men likevel stadfestar at for denne fransk-engelske datasettet som er kjent å innehalda høg kvalitetsverktøyringar og autentisk eller markerte mellom kjelde forbetrar over translationiske kjelde for opplæring.', 'pl': 'Ponownie podejmujemy temat kierunku tłumaczenia w danych wykorzystywanych do treningu neuronowych systemów tłumaczenia maszynowego i skupiamy się na realnym scenariuszu ze znanym kierunkiem tłumaczenia i nierównowagami w kierunku tłumaczenia: kanadyjskim Hansardem. Według automatycznych wskaźników i obserwujemy, że wykorzystanie danych równoległych, które zostały wyprodukowane w kierunku "dopasowania" tłumaczenia (autentyczne źródło i tłumaczenie target) poprawia jakość tłumaczenia. W przypadku braku równowagi danych pod względem kierunku tłumaczenia i okazujemy się, że tagowanie kierunku tłumaczenia może zmniejszyć lukę w wydajności. Przeprowadzamy ocenę ludzką, która nieznacznie różni się od automatycznych wskaźników, ale jednak potwierdza, że dla tego francusko-angielskiego zbioru danych, który jest znany z wysokiej jakości tłumaczenia i autentycznego lub oznaczonego źródła mieszanego, poprawia się nad tłumaczeniowym źródłem do szkolenia.', 'mn': 'Бид мэдээллийн мэдээллийн дасгал хөгжүүлэх системийн тулд хэрэглэгдсэн мэдээллийн дасгал руу шинэчлэх сэдвийг дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин Автоматикийн метрикийн хувьд бид "хоорондоо хоорондоо хоорондоо хоорондоо холбогдож байгаа параллел өгөгдлийг ашиглаж байгааг анзаарлаа. Хэрэв мэдээллийн тэгш байдал нь орчуулагчийн тэгш байдалд бид орчуулагчийн тэгшитгэл нь үйл ажиллагааны ялгааг холбож болно. Бид хүн төрөлхтний оюутнуудыг автоматжуулалтын метриктаас бага зэрэг өөрчлөгдөж байдаг. Гэхдээ энэ Француз-Англи өгөгдлийн сангийн хувьд өндөр чанартай хөгжүүлэлт, шударга эсвэл холбогдсон эх үүсвэрийг суралцах эх үүсвэрээс илүү сайж', 'ro': 'Revizuim subiectul direcției traducerii în datele utilizate pentru instruirea sistemelor neurale de traducere automată și concentrându-ne pe un scenariu din lumea reală cu direcția cunoscută a traducerii și dezechilibre în direcția traducerii: Hansard canadian. Conform măsurătorilor automate și observăm că utilizarea datelor paralele care au fost produse în direcția de traducere "potrivită" (sursă autentică și țintă traducătoare) îmbunătățește calitatea traducerii. În cazurile de dezechilibru al datelor în ceea ce privește direcția traducerii și constatăm că etichetarea direcției traducerii poate reduce decalajul de performanță. Efectuăm o evaluare umană care diferă ușor de măsurătorile automate și cu toate acestea confirmă că pentru acest set de date franceză-engleză care este cunoscut pentru a conține traduceri de înaltă calitate și sursă mixtă autentică sau etichetată se îmbunătățește față de sursa traducătoare pentru formare.', 'sr': "Pregledali smo temu smjera prevođenja u podacima koji su koristili za obuku sustava prevođenja neuralnih mašin a i fokusiranje na scenario stvarnog svijeta sa poznatim smjerom prevođenja i nelibancima u pravcu prevođenja: Kanadijski Hansard. Prema automatskim metrikama i posmatramo da korištenje paralelnih podataka koji su proizvedeni u smjeru 'odgovarajućeg' prevoda (izvor autentifikacije i cilj prevoda) poboljšava kvalitet prevoda. U slučajevima nelegalnosti podataka u pogledu smjera prevođenja i smatramo da označavanje smjera prevođenja može zatvoriti prazninu izvođenja. Izvodimo ljudsku procjenu koja se malo razlikuje od automatske metrike, ali ipak potvrđuje da za ovaj francuski-engleski komplet podataka koji je poznat da sadrži kvalitetne prevode i autentične ili označene mješane izvore poboljšavaju preko translationalnog izvora za obuku.", 'so': 'Waxaynu dib u qoraynaa mada hagitaanka turjumaadda ee macluumaadka lagu isticmaalayo waxbarashada nidaamka tarjumaadda neurada ah iyo focus on a halis-world scenario with direction and imbalances known and imbalance in turjumaadda: the Kanada Hansard. Sida loo qabo isticmaalka rasmi ahaanshaha iyo waxaynu fiirinnaa in isticmaalka macluumaadka parallel ah oo lagu soo saaray hagitaanka turjumaadda (asalka rasmiga ah iyo goalka turjumaadda) uu kordhiyaa qiimaha turjumaadda. Xaaladaha kaalmada macluumaadka ku saabsan hagitaanka turjumaadda, waxaynu aragnaa in tagging turjumaanku uu xidhi karo goobta sameynta. Waxaannu sameeynaa qiimeynta biniaadamka oo si yar u kala duwan maamulka iskumarka, laakiin waxaynu xaqiijinaynaa in loo qorayo macluumaadkan afriiska-Ingiriiska oo lagu yaqaan ku qoran turjumaadda sare iyo rasmi-si ama bandhig-isticmaalay ay ay ka bedeshaa sourceed turjuman.', 'sv': 'Vi 책terkommer till 채mnet 철vers채ttningsriktning i de data som anv채nds f철r att tr채na neurala maskin철vers채ttningssystem och fokuserar p책 ett verkligt scenario med k채nd 철vers채ttningsriktning och obalanser i 철vers채ttningsriktningen: Canadian Hansard. Enligt automatiska m채tv채rden och vi observerar att anv채ndningen av parallella data som producerades i "matchande" 철vers채ttningsriktning (autentisk k채lla och translationesisk m책l) f철rb채ttrar 철vers채ttningskvaliteten. I fall av obalans i data n채r det g채ller 철vers채ttningsriktning och vi finner att m채rkning av 철vers채ttningsriktning kan minska prestandakravet. Vi utf철r en m채nsklig utv채rdering som skiljer sig n책got fr책n de automatiska m채tv채rdena men 채nd책 bekr채ftar att f철r denna fransk-engelska dataupps채ttning som 채r k채nd f철r att inneh책lla h철gkvalitativa 철vers채ttningar och autentiska eller taggade blandade k채llor f철rb채ttras j채mf철rt med translationens k채lla f철r utbildning.', 'ta': 'நாங்கள் மொழிபெயர்ப்பு திசையில் பயன்படுத்தப்பட்ட தரவுத்தளத்தின் தலைப்பை மீண்டும் திரும்பச் செய்கிறோம் மொழிபெயர்ப்பு திசையில் மொழிபெ @ info @ info: whatsthis நாம் ஒரு மனித மதிப்பீட்டை செய்கிறோம் அது தானாகவே மெட்ரிக்குகளில் இருந்து மாறுபடுகிறது ஆனாலும் இந்த பிரெஞ்சு- ஆங்கிலத்திற்கு உயர்தரமான மொழிபெயர்ப்புகள் மற்று', 'ur': "ہم نے نورول ماشین ترجمہ سیسٹم کے لئے استعمال کیا گیا ہے اور ایک حقیقی دنیاوی سینارییو پر مطلب ترجمہ سمیت اور نابرالنس کے ساتھ پہچان ہوئے ترجمہ سمیت اور ترجمہ سمیت میں استعمال کیا گیا ہے: کانادی هانسارد. آٹوٹ میٹریک کے مطابق اور ہم دیکھتے ہیں کہ پارالیل ڈاٹ کے مطابق جو 'مطابق' ترجمہ دیگر میں پیدا کیا گیا ہے (Authentic source اور translationese target) ترجمہ کیفیت کو بہتر کرتا ہے. ڈیٹا نابرالنس کے مطابق ترجمہ دہشت کے مطابق اور ہم دیکھتے ہیں کہ ترجمہ دہشت کا ٹاگ کرنا صرف فاصلہ بند کر سکتا ہے. ہم ایک انسان کی ارزیابی کریں جو آٹوٹ میٹریک سے تھوڑا تفاوت کرتی ہے اور لیکن اس طرح تصدیق کرتا ہے کہ اس فرانسوی-انگلیسی ڈاٹ سٹ کے لئے جو بہت سی کیفیت کی ترجمہ اور حقیقت یا ترجیح کے مطابق مختلف سورج کے ذریعہ ترجمہ کے سورج پر بہتر ہے۔", 'si': 'අපි පරිවර්තනය කරන්න පුළුවන් විදිහට පරිවර්තන විදිහට පරිවර්තනය කරන්න ප්\u200dරයෝජන විදිහට පරිවර්තනය කරන්න ප්\u200dරයෝජන විදිහට පරිවර්තන @ title: group දත්ත නිර්මාණයක් වෙනුවෙන් පරිවර්තන පැත්තක් වලින් අපි හොයාගන්නවා වාර්තන පැත්තක් ටැග් කරන්න පුළුවන්  අපි මිනිස්සු විශ්ලේෂණයක් කරනවා ඒ වගේම ස්වයංක්\u200dරීය මෙට්\u200dරික්ස් වලින් ටිකක් වෙනස් කරනවා ඒත් ඒ වගේම ප්\u200dරංචි ඉංග්\u200dරීසි දත්ත සෙට් විශ්වාස ක', 'uz': "@ info: whatsthis According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality.  @ info Biz bir inson qiymatlarini avtomatik metriklardan bir qiymatga bajaramiz va ammo o o'z tarjima qilish uchun eng yuqori ingliz-ingliz maʼlumotlar tarjima va shaxsiy tarjima qilish yoki minglab boʻlgan manbasiga tarjima maʼlumotlar manbasiga bajaradi.", 'vi': 'Chúng ta thăm lại vấn đề về hướng dịch chuyển trong dữ liệu được dùng để đào tạo hệ thống dịch chuyển máy thần kinh và tập trung vào một kịch bản thực tế với hướng dịch nổi tiếng và mất cân bằng trong hướng dịch: người Canada Hansart. Theo đo lường tự động và chúng tôi quan sát rằng sử dụng dữ liệu song song sản xuất trong hướng dịch chuyển "khớp (đích gốc và dung dịch) cải thiện chất lượng dịch. Trong trường hợp có mất cân bằng dữ liệu về hướng dịch chuyển và chúng tôi thấy rằng hiệu chỉnh hướng dịch chuyển có thể thu hẹp khoảng cách kinh tế. Chúng tôi thực hiện một đánh giá con người hơi khác so với âm lượng tự động, nhưng vẫn xác nhận rằng, đối với bộ dữ liệu Anh-Pháp mà được biết là chứa dịch chất lượng cao, và nguồn hòa hợp đích thực hay nhãn tốt hơn nguồn dịch chuyển để huấn luyện.', 'bg': 'Ние преразглеждаме темата за посоката на превода в данните, използвани за обучение на невронни системи за машинен превод и фокусираме върху реалния сценарий с известна посока на превода и дисбаланси в посоката на превода: канадския Хансард. Според автоматичните показатели и наблюдаваме, че използването на паралелни данни, които са произведени в "съвпадащата" посока на превода (автентичен източник и преводаческа цел) подобрява качеството на превода. В случаи на дисбаланс на данните по отношение на посоката на превода и откриваме, че маркирането на посоката на превода може да запълни пропуска в ефективността. Ние извършваме човешка оценка, която се различава леко от автоматичните показатели и въпреки това потвърждава, че за този френски-английски набор от данни, който е известен, че съдържа висококачествени преводи и автентичен или маркиран смесен източник се подобрява пред преводачески източник за обучение.', 'da': "Vi gennemgår emnet oversættelsesretning i de data, der anvendes til at træne neurale maskinoversættelsessystemer og fokusere på et virkeligt scenario med kendt oversættelsesretning og ubalancer i oversættelsesretning: den canadiske Hansard. Ifølge automatiske målinger og vi observerer, at ved hjælp af parallelle data, der blev produceret i den 'matchende' oversættelsesretning (autentisk kilde og translationesisk mål), forbedres oversættelseskvaliteten. I tilfælde af dataubalance med hensyn til oversættelsesretning, og vi finder ud af, at tagging af oversættelsesretning kan lukke præstationshullet. Vi udfører en menneskelig evaluering, der adskiller sig lidt fra de automatiske målinger, men alligevel bekræfter, at for dette fransk-engelske datasæt, der er kendt for at indeholde oversættelser af høj kvalitet og autentiske eller taggede blandede kilder forbedres i forhold til translationesisk kilde til træning.", 'hr': "Pregledali smo temu smjera prevođenja u podacima koji su koristili za obuku sustava prevođenja neuralnih strojeva i fokusiranje na scenario stvarnog svijeta s poznatim smjerom prevođenja i nelibancima u smjeru prevođenja: Kanadijski Hansard. Prema automatskim metrikama i posmatramo kako korištenje paralelnih podataka koji su proizvedeni u smjeru 'odgovarajućeg' prevoda (izvor autentičnog i translationalnog cilja) poboljšava kvalitet prevoda. U slučajevima nelegalnosti podataka u smislu smjera prevođenja i smatramo da označavanje smjera prevođenja može zatvoriti prazninu učinka. Mi izvršavamo ljudsku procjenu koja se malo razlikuje od automatske metrike, ali ipak potvrđuje da za ovaj francuski-engleski komplet podataka koji je poznat da sadrži prevod visokokvalitete i autentični ili označeni mješani izvor poboljšava se preko translationalnog izvora za obuku.", 'nl': "We herhalen het onderwerp vertaalrichting in de gegevens die worden gebruikt voor het trainen van neurale machinevertaalsystemen en focussen ons op een real-world scenario met bekende vertaalrichting en onevenwichtigheden in vertaalrichting: de Canadese Hansard. Volgens automatische metrics en we zien dat het gebruik van parallelle gegevens die in de 'matching' vertaalrichting zijn geproduceerd (Authentic source en translationese target) de vertaalkwaliteit verbetert. In geval van data onbalans in termen van vertaalrichting en we merken dat tagging van vertaalrichting de prestatiekloof kan dichten. We voeren een menselijke evaluatie uit die enigszins afwijkt van de automatische metrics en toch bevestigt dat voor deze Frans-Engelse dataset die bekend staat om hoogwaardige vertalingen en authentieke of getaggte gemengde broncode verbetert ten opzichte van translationese bron voor training.", 'fa': 'ما موضوع ترجمه در اطلاعات که برای آموزش سیستم ترجمه\u200cهای ماشین عصبی استفاده می\u200cشود را تغییر می\u200cدهیم و تمرکز می\u200cکنیم روی سیناریو دنیای واقعی با مسیر ترجمه\u200cهای شناخته شده و نابرالانس در مسیر ترجمه: کانادی هانسار. بر اساس متریک\u200cهای خودکار و ما مشاهده می\u200cکنیم که با استفاده از داده\u200cهای parallel که تولید شده\u200cاند در مسیر ترجمه\u200cهای « هماهنگ » (منبع شناسایی و هدف ترجمه) کیفیت ترجمه را بهتر می\u200cکند. در مورد نابرابری داده\u200cها در مورد مسیر ترجمه و پیدا می\u200cکنیم که نقاشی مسیر ترجمه می\u200cتواند فاصله عملکرد را بسته کند. ما یک ارزیابی انسان را انجام می دهیم که کمی از متریک اتوماتیک متفاوت تفاوت می کند، ولی با این حال تصدیق می کند که برای این مجموعه داده های فرانسوی-انگلیسی که شناخته می شود تحویل\u200cدهنده\u200cهای کیفیت بالا و منبع مختلف یا ترکیب شده بر منبع ترکیبی برای آموزش بهتر می\u200cشود', 'de': 'Wir greifen das Thema Übersetzungsrichtung in den Daten, die für das Training neuronaler maschineller Übersetzungssysteme verwendet werden, erneut auf und konzentrieren uns auf ein reales Szenario mit bekannter Übersetzungsrichtung und Ungleichgewichten in Übersetzungsrichtung: den kanadischen Hansard. Nach automatischen Metriken und wir beobachten, dass die Verwendung paralleler Daten, die in der "passenden" Übersetzungsrichtung (Authentic source und translationese target) erstellt wurden, die Übersetzungsqualität verbessert. In Fällen von Datenungleichgewichten in Bezug auf die Übersetzungsrichtung und wir finden, dass Tagging der Übersetzungsrichtung die Leistungslücke schließen kann. Wir führen eine menschliche Bewertung durch, die sich leicht von den automatischen Metriken unterscheidet und dennoch bestätigt, dass sich für diesen französisch-englischen Datensatz, der dafür bekannt ist, qualitativ hochwertige Übersetzungen und authentische oder getaggte gemischte Quellen enthält, gegenüber translationesischen Quellen für Schulungen verbessert.', 'id': "Kami mengulangi topik arah terjemahan dalam data yang digunakan untuk melatih sistem terjemahan mesin saraf dan fokus pada skenario dunia nyata dengan arah terjemahan yang dikenal dan ketidakseimbangan dalam arah terjemahan: Hansard Kanada. Menurut metrik otomatis dan kami memperhatikan bahwa menggunakan data paralel yang diproduksi dalam arah terjemahan 'cocok' (Sumber asli dan sasaran terjemahan) meningkatkan kualitas terjemahan. Dalam kasus ketidakseimbangan data dalam terma arah terjemahan dan kami menemukan bahwa tagging arah terjemahan dapat menutup ruang prestasi. Kami melakukan evaluasi manusia yang sedikit berbeda dari metrik otomatis dan bagaimanapun mengkonfirmasi bahwa untuk set data Perancis-Inggris ini yang dikenal untuk mengandung terjemahan kualitas tinggi dan sumber campuran otomatis atau tagged meningkat lebih dari sumber terjemahan untuk latihan.", 'ko': "우리는 신경기계 번역 시스템을 훈련하는 데 사용되는 데이터에서 번역 방향의 주제를 재토론하고 현실 세계에서 이미 알고 있는 번역 방향과 번역 방향이 불균형한 장면인 캐나다 회의 기록에 중점을 두었다.자동 도량에 따라 우리는'일치'번역 방향(실제 출처와 번역 목표)을 사용하여 발생하는 병행 데이터를 사용하면 번역의 질을 향상시킬 수 있음을 관찰했다.번역 방향 데이터가 불균형한 상황에서 우리는 번역 방향 표시가 성능 격차를 줄일 수 있다는 것을 발견했다.우리는 자동 도량과 약간 다른 인공 평가를 실시했지만, 이 프랑스어-영어 데이터 집합에 대해 이미 알고 있는 고품질 번역과 진실 또는 표기를 포함하는 혼합원은translationese-source보다 교육에 더 적합하다는 것을 확인했다.", 'sw': 'Tunapitia mada ya muelekeo wa tafsiri katika taarifa zinazotumiwa kwa ajili ya mafunzo ya mfumo wa kutafsiri mashine ya neurali na kuhusiana na hali halisi ya dunia yenye mwelekeo wa tafsiri na ukosefu wa usawa katika mwelekeo wa tafsiri: Kanada Hansard. Kwa mujibu wa mbinu za kujitegemea na tunaona kwamba kwa kutumia taarifa za usambazaji zilizotengenezwa kwenye mwelekeo wa utafsiri (chanzo cha asili na lengo la utafsiri) linaboresha kiwango cha tafsiri. Katika matukio ya ukosefu wa taarifa kwa mujibu wa mwelekeo wa tafsiri na tunagundua kuwa wimbo wa muelekeo wa tafsiri unaweza kufunga upande wa utendaji. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.', 'tr': "Biz Nural maşynyň terjime sistemalarynda ullanýan terjime yönünde üýtgetmek üçin ullanýan we dünýädäki senaryony bilinen terjime yönünde we täsirlenmeleri bilen üns berdik: Kanada Hansard a. Otomatik metriklere görä we görkezilişimiz, bu paralel maglumatlary 'Işleýän' terjime yönünde üretilenýän (Sahypa çeşme we terjime maksady) terjime kwalitesini bejerýär. Terjime edilişi görkezilýän ýagdaýynda maglumat täbalance bolmagy we terjime edilişi görkezilýän ýagdaýynyň gapysyny ýapabilir. Biz adamlary awtomatik metrikanyň biraz üýtgeşik hasaplamasyny ýerine ýetirýäris we ýöne-de bu fransuz-iňlis datu kopaty üçin ýokary kwalitet terjimeleri we awtomatik we çagalan çeşmeleri üçin terjime etmäge tanaýarlar.", 'am': "We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction: the Canadian Hansard.  በ'matching' ትርጉም ማቀናጃ (Authentic source and translation target) የተዘጋጀውን ተርጓሚን ጥሩ ያሳድጋል፡፡ የዳታ ክፍሎች በትርጉም ማቀናኘት እና ትርጉም መንገድ ማግኘት የጥያቄውን ክፍል መዝገብ እንደሚችል እናገኛለን፡፡ ከሰው ማውጣት በጥቂት ካለየ አውቶማቲክ የሚለየውን እና ግን ለትርጓሜዎችን ለማግኘት ለሚታወቀው ለዚህ ፈረንሳይ-እንግሊዘኛ ዳታ ማተርጓሜዎችን እና ማረጋገጥ ወይም የተቀማጠለ መልዕክት ለመተማርየት ማድረግ ማድረግ ይሻላል፡፡", 'af': "Ons hersien die onderwerp van vertaling rigting in die data gebruik word vir die onderwerp van neurale masjien vertaling stelsels en fokus op 'n reël- wêreld scenario met bekende vertaling rigting en onbalanse in vertaling rigting: die Kanadese Hansard. Volgens outomatiese metries en ons observer dat gebruik parallele data wat in die 'ooreenstemmende' vertaling rigting geproduseer is (Geldigheidsbron en translationese doel) vertaling kwaliteit verbeter. In gevalle van data-imbalans in terms of translation direction and we find that tagging of translation direction can close the performance gap. Ons doen 'n menslike evaluering wat minnig verskil van die outomatiese metriek en maar tog bevestig dat vir hierdie Frans-Engelse dataset wat bekend is om hoë-kwaliteit vertalings en outentiese of gemengde bron te bevat verbeter oor translationese bron vir onderwerp.", 'sq': "Ne përsërisim temën e drejtimit të përkthimit në të dhënat e përdorura për trajnimin e sistemeve të përkthimit të makinave nervore dhe përqëndrohemi në një skenar botërore reale me drejtimin e njohur të përkthimit dhe disbalancat në drejtimin e përkthimit: Kanadanët Hansard. According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality.  Në rastet e paekuilibrit të të dhënave në lidhje me drejtimin e përkthimit dhe gjejmë se etiketat e drejtimit të përkthimit mund të mbyllin dallimin e performancës. Ne kryejmë një vlerësim njerëzor që ndryshon pak nga metrika automatike dhe megjithatë konfirmon se për këtë set të dhënash francez-angleze që është e njohur që përmban përkthime të cilësisë së lartë dhe burim i përzier autentik apo të etiketuar përmirësohet mbi burimin e përkthimit për trajnimin.", 'bn': "অনুবাদের দিকে পরিচিত অনুবাদ এবং বিভিন্ন অনুবাদের দিকে নির্বাচনের জন্য ব্যবহার করা নিউরেল মেশিন অনুবাদ সিস্টেম প্রশিক্ষণের জন্য আমরা তথ্যের দিকে অন স্বয়ংক্রিয় মেট্রিক অনুসারে আমরা দেখতে পাচ্ছি যে প্যারালেল ডাটা ব্যবহার করা হয়েছে 'মিল্যাটিং' অনুবাদের দিকে (অনুবাদের সূত্র এবং অনু অনুবাদের দিকের মাধ্যমে তথ্য বৈষম্য এবং আমরা অনুবাদের দিকের ট্যাগিং পাওয়া যাচ্ছি যে অনুবাদের দিকে প্রদর্শনের প আমরা একটি মানুষের মূল্য চালু করি যা স্বয়ংক্রিয় মেট্রিক থেকে কিছুটা আলাদা করে কিন্তু তা নিশ্চিত করি যে এই ফরাসী ইংরেজী ডাটাসেটের জন্য যারা উচ্চ মানের অনুবাদ এবং অনুবা", 'hy': 'Մենք վերադառնում ենք թարգմանման ուղղության թեման այն տվյալներում, որոնք օգտագործվում են նյարդային մեքենայի թարգմանման համակարգերի ուսումնասիրելու համար և կենտրոնացնում ենք իրական աշխարհի սցենարիայի վրա, որտեղ թարգմանման ուղղությունը հայտնի է և անհավ Ըստ ավտոմատիկ մետրիկայի և մենք նկատում ենք, որ զուգահեռ տվյալներ օգտագործելը, որոնք ստեղծվել են թարգմանման ուղղությամբ (Աստվական աղբյուր և թարգմանման նպատակ) բարելավում է թարգմանման որակը: Տվյալների անհավասարակշռության դեպքերում թարգմանման ուղղության տեսանկյունից և մենք հայտնաբերում ենք, որ թարգմանման ուղղության նշանները կարող են փակել արդյունավետության տարբերությունը: Մենք կատարում ենք մարդկային գնահատականներ, որոնք թեթևս տարբերվում են ավտոմատիկ մետրիկայից, բայց չնայած դրան, հաստատում ենք, որ այս ֆրանսերեն-անգլերեն տվյալների համակարգի համար, որը հայտնի է, որ պարունակում է բարձր որակի թարգմանություններ և ճշգրիտ կամ նշանակված խառնված', 'bs': "Pregledali smo temu smjera prevođenja u podacima koji su koristili za obuku sustava prevođenja neuralnih strojeva i fokusiranje na scenario stvarnog svijeta sa poznatim smjerom prevođenja i nelibancima u smjeru prevođenja: Kanadijski Hansard. Prema automatskim metrikama i posmatramo da korištenje paralelnih podataka koji su proizvedeni u smjeru 'odgovarajućeg' prevoda (izvor autentičnog i translationalnog cilja) poboljšava kvalitet prevoda. U slučajevima nelegalnosti podataka u smislu smjera prevođenja i smatramo da označavanje smjera prevođenja može zatvoriti prazninu učinka. Mi izvršavamo ljudsku procjenu koja se malo razlikuje od automatske metrike, ali ipak potvrđuje da za ovaj francuski-engleski komplet podataka koji je poznat da sadrži prevode kvalitete i autentične ili označene mješane izvore poboljšavaju se preko translationalnog izvora za obuku.", 'az': "Biz nöral maşın çeviri sistemlərinin təhsil etmək üçün istifadə edilən məlumatların çeviri yönünü yenidən dəyişdiririk və həqiqət dünya senaryosuna tanınan çeviri yönəltməsi və dəyişiklik yönəltməsi: Kanada Hansard a. Avtomatik metriklərə görə və baxıb ki, paralel məlumatları istifadə etmək üçün 'eyni' tercümə yönündə ürəklənən məlumatları (Authentic source və translation target) tercümə keyfiyyətini daha yaxşılaşdırır. Məlumatların dəyişiklik müqabiliyyəti tərcümə yönündə və tərcümə yönündə etiketlənməsi performans boşluğunu yaxalayabilir. Biz bir insan değerlendirməsini təsdiqləyirik ki, avtomatik metriklərdən biraz fərqli olar, amma bu Fransız-İngilizə verilən qurğuları təsdiqləyir ki, yüksək kaliteli təkrarlama və həqiqət və ya etiketli karışıq kaynaqlar təkrarlama mənbəsinin üstündə təkrarlanması üçün daha yaxşılaşır.", 'cs': 'Opět se zabýváme tématem směru překladu v datech používaných pro trénink neuronových strojových překladových systémů a zaměřujeme se na reálný scénář se známým směrem překladu a nerovnováhou ve směru překladu: kanadský Hansard. Podle automatických metrik a pozorujeme, že použití paralelních dat, která byla vytvořena ve směru "odpovídajícího" překladu (autentický zdroj a translationský cíl) zlepšuje kvalitu překladu. V případě nerovnováhy dat z hlediska směru překladu a zjišťujeme, že tagování směru překladu může uzavřít mezeru výkonu. Provádíme lidské vyhodnocení, které se mírně liší od automatických metrik, ale nicméně potvrzuje, že u této francouzsko-anglické datové sady, která je známo, že obsahuje vysoce kvalitní překlady a autentický nebo označený smíšený zdroj, se zlepšuje oproti překladatelskému zdroji pro školení.', 'fi': 'K채채nt채misen suuntaa tarkastellaan uudelleen neurokonek채채nn철sj채rjestelmien kouluttamiseen k채ytetyss채 aineistossa ja keskityt채채n todelliseen skenaarioon, jossa k채채nn철ssuunta tunnetaan ja k채채nn철ssuunnassa on ep채tasapainoja: kanadalaiseen Hansardiin. Automaattisten mittareiden mukaan n채emme, ett채 samansuuntainen tieto, joka on tuotettu "matching"-k채채nn철ssuuntaan (Authentic source ja translationese target) parantaa k채채nn철ksen laatua. Jos k채채nn철ssuuntaan liittyy ep채tasapainoa, huomaamme, ett채 k채채nn철ssuuntaan merkitseminen voi kaventaa suoritusvajetta. Suoritamme inhimillisen arvioinnin, joka poikkeaa hieman automaattisista mittareista ja joka kuitenkin vahvistaa, ett채 t채m채 ranska-englanti aineisto, jonka tiedet채채n sis채lt채v채n korkealaatuisia k채채nn철ksi채 ja autenttinen tai tagged mixed source parantaa k채채nt채misen l채hdett채 koulutukseen.', 'ca': "We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction: the Canadian Hansard.  According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality.  En casos d'desequilibri de dades en termes de direcció de traducció i descobrim que etiquetar la direcció de traducció pot encerrar la diferència de rendiment. Fem una evaluació human a que difereix ligerament de les mètriques automàtiques i, no obstant això, confirma que per aquest conjunt de dades franco-anglès que és conegut que conté traduccions d'alta qualitat i font mixta autèntica o etiquetada millora sobre la font de traducció per formació.", 'et': 'Tõlkesuundamise teemat vaadatakse uuesti läbi neuraalsete masintõlkesüsteemide koolitamiseks kasutatavates andmetes ning keskendutakse reaalsele stsenaariumile, millel on teadaolev tõlkesuunda ja tõlkesuunade tasakaalustamatus: Kanada Hansard. Vastavalt automaatsetele mõõdikutele ja täheldame, et paralleelsete andmete kasutamine, mis on toodetud "sobivas" tõlkesuunas (autentne allikas ja tõlke sihtmärk), parandab tõlkekvaliteeti. Andmete tasakaalustamatuse korral tõlkesuunas ja leiame, et tõlkesuunade märgistamine võib tulemuslikkuse lõhe vähendada. Me teeme inimliku hindamise, mis erineb veidi automaatsetest mõõdikutest, kuid kinnitab siiski, et selle prantsuse-inglise andmekogumi puhul, mis sisaldab teadaolevalt kvaliteetseid tõlkeid ja autentset või sildistatud segaallikat, paraneb tõlkeallikast koolituse allikast võrreldes.', 'ha': "@ info: whatsthis @ action: button @ info: whatsthis Tuna tafiyar da kima wanda ke sãɓã wa kodi daga metrikan farat ɗaya, kuma amma yana tabbatar da cewa, wa'adin nan na faransa-Ingiriya wanda ana sani ana ƙunsa da fassarar masu nau'i da inganci, da gaskiyar ko kuma da aka tago kilowan da aka haɗa shi yana mafiya kyau a kan zance wa fassarori na fassarci.", 'he': "אנחנו מחדשים את הנושא של כיוון התרגום במידע שנמשך לאימון מערכות התרגום של מכונות עצביות ומתמקדים בתרחיש עולם אמיתי According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality.  במקרים של אי-איזון נתונים במונחים של כיוון התרגום ואנחנו מוצאים שסימנים של כיוון התרגום יכולים לסגור את הפער ביצועי. אנו מבצעים עריכה אנושית שמשונה מעט מהמטריקה האוטומטית, אך בכל זאת מאשר כי עבור קבוצת נתונים צרפתית-אנגלית זו הידועה מכילה תרגומות איכות גבוהה ומקור מעורבב אוטומטי או מסומן משתפר מעל מקור תרגום לאימונים.", 'sk': "Temo smeri prevajanja ponovno obravnavamo v podatkih, ki se uporabljajo za usposabljanje sistemov nevronskega strojnega prevajanja in se osredotočamo na realni scenarij z znano smer prevajanja in neravnovesji v smeri prevajanja: kanadski Hansard. Glede na avtomatske meritve opažamo, da uporaba vzporednih podatkov, ki so bili proizvedeni v 'ujemajoči' smeri prevajanja (Authentic source in translationese target), izboljšuje kakovost prevajanja. V primeru neravnovesja podatkov v smislu smeri prevajanja in ugotavljamo, da označevanje smeri prevajanja lahko zapolni vrzel v uspešnosti. Izvajamo človeško vrednotenje, ki se rahlo razlikuje od avtomatskih meritev, vendar kljub temu potrjuje, da se za ta francosko-angleški nabor podatkov, ki vsebuje visokokakovostne prevode in avtentičen ali označen mešani vir, izboljša kot prevajalski vir za usposabljanje.", 'bo': "ང་ཚོས་ཚོའི་གནས་ཚུལ་གྱི་གནས་ཚུལ་འདིའི་གནད་དོན་ཕྱོགས་ཀྱི་གནས་ཚུལ་གསལ་བཤད་ཀྱི་ཐབས་ལམ་ལ་བསླབ་སྟེ། According to automatic metrics and we observe that using parallel data that was produced in the 'matching' translation direction (Authentic source and translationese target) improves translation quality. In the case of data imbalance in terms of translation direction, we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.", 'jv': 'Awak dhéwé éntuk tarjamahan kanggo tarjamahan kanggo nggambar urip kuwi informasi nggawe sistem tarjamahan e mengkar nggawe barang nggawe barang kelas-munit kanggo ngerasakno tarjamahan lan balanci kanggo ngerasakno tarjamahan: uga, bantuan nggo Kanadian. translation quality translation Awak dhéwé éntuk éntuk barêng-barêng wong sing mengko karo Metika sing butas nang otomatik lan mangkane supoyo nggawe barang nggawe barang kanggo dataset Frans-Inggris iki diangkat dhéwé, sing paling dhéwé kuwi arep terjamahan karo sesuk-uripé, awak dhéwé sing berarti basa sing berarti bantêr nggo'}
{'en': 'Investigating Softmax Tempering for Training Neural Machine Translation Models', 'ar': 'التحقيق في تقسية Softmax لتدريب نماذج الترجمة الآلية العصبية', 'pt': 'Investigando a têmpera Softmax para treinar modelos de tradução automática neural', 'fr': 'Étude du tempérage Softmax pour la formation de modèles de traduction automatique neuronale', 'es': 'Investigación del templado de Softmax para el entrenamiento de modelos de traducción automática neuronal', 'ja': '神経機械翻訳モデルのトレーニングのためのソフトマックステンパリングの調査', 'zh': '研练神经机器翻译模之 Softmax 回火', 'ru': 'Изучение темперирования Softmax для обучающих моделей перевода нейронных машин', 'hi': 'प्रशिक्षण तंत्रिका मशीन अनुवाद मॉडल के लिए Softmax तड़के की जांच', 'ga': 'Imscrúdú Softmax Tempering le haghaidh Oiliúna Múnlaí Néar-Aistriúcháin Meaisín', 'hu': 'Softmax edzés vizsgálata neurális gépi fordítási modellekhez', 'el': 'Ερευνώντας τη μετρίαση για την κατάρτιση νευρωνικών μοντέλων μηχανικής μετάφρασης', 'kk': 'Невралдық машинаны аудару үлгілерінің Softmax тегістерін зерттеу', 'lt': 'Investigating Softmax Tempering for Training Neural Machine Translation Models', 'mk': 'Истражување на температура за софтмакс за обука на модели за преведување на неврални машини', 'ms': 'Menyelidiki Tempering Softmax untuk melatih Model Terjemahan Mesin Neural', 'ka': 'Name', 'mt': 'Investigazzjoni tat-Temporar Softmax għat-Taħriġ ta’ Mudelli ta’ Traduzzjoni ta’ Magni Newrali', 'ml': 'പരിശീലിപ്പിക്കുന്ന നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള സോഫ്റ്റ്മാക്സ് പരിശോധിക്കു', 'it': "Indagine della tempra Softmax per l'addestramento dei modelli di traduzione automatica neurale", 'ro': 'Investigarea temperaturii Softmax pentru instruirea modelelor de traducere a mașinilor neurale', 'sr': 'Istraživanje Softmax Temperatura za obuku modela neurološkog prevoda mašine', 'si': 'Name', 'mn': 'Сургуулийн мэдрэлийн машины хөгжүүлэх загварын Softmax Температурын судалгаа', 'pl': 'Badanie temperowania Softmax dla treningu neuronowych modeli tłumaczenia maszynowego', 'so': 'Baaritaanka dhamaadka Softmax ee Waxbarashada Maamulka neurada', 'no': 'Name', 'sv': 'Undersökning av Softmax härdning för träning Neural Machine Translation Modeller', 'ta': 'பயிற்சி புதிய இயந்திரத்தை மொழிபெயர்ப்பு மாதிரிகளுக்கான மென்பெக்ஸ் வேகம்', 'ur': 'ترین نیورال ماشین ترجمہ موڈل کے لئے Softmax Tempering کی تحقیق کی جاتی ہے', 'vi': 'Điều tra về mềm dẻo Thời gian huấn luyện Cơ chế thần kinh dịch mẫu', 'uz': 'Tarjima qilish', 'bg': 'Изследване на закаление за обучение на модели на неврален машинен превод', 'da': 'Undersøgelse af Softmax hærdning til træning Neurale maskinoversættelsesmodeller', 'hr': 'Istraživanje Softmax Temperatura za obrazovanje modela neurološkog prevoda stroja', 'nl': 'Het onderzoeken van Softmax Tempering voor het Trainen van Neurale Machine Translation Modellen', 'id': 'Menyelidiki Temperasi Softmax untuk melatih Model Translation Mesin Neural', 'ko': 'Softmax 회전 훈련 신경 기계 번역 모형 연구', 'fa': 'تحقیق مدل\u200cهای ترجمه ماشین عصبی Softmax برای تمرین کردن مدل\u200cهای ترجمه ماشین عصبی', 'de': 'Untersuchung der Softmax-Temperierung für das Training neuronaler maschineller Übersetzungsmodelle', 'sw': 'Kuchunguza Softmax kwa ajili ya Kufundisha Mashine ya Tafsiri', 'tr': 'Ewez etmek üçin Softmax Wagtlaýyn', 'sq': 'Hetimi i temporizimit të Softmax për trajnimin e modeleve të përkthimit të makinave nervore', 'af': 'Name', 'am': 'ምርጫዎች', 'hy': 'Նյարդային մեքենաների թարգմանման մոդելների ուսումնասիրությունը', 'bn': 'নিউরেল মেশিন অনুবাদ মোডেলের প্রশিক্ষণের জন্য সফটম্যাক্স টেম্পেরিং অনুসন্ধান করা হচ্ছে', 'az': 'N칬ral Makin 칂eviri Modell톛ri t톛hsil etm톛k 칲칞칲n Softmax Temperatura S톛fl톛t', 'ca': 'Investigar la temperació de Softmax per entrenar models de traducció de màquines neuronals', 'et': 'Softmax karastamise uurimine neuroaalsete masinatõlke mudelite koolitamiseks', 'cs': 'Vyšetřování Softmax Tempering pro trénink neuronových strojových překladů modelů', 'bs': 'Istraživanje Softmax Temperatura za obuku modela neurološkog prevoda mašine', 'fi': 'Softmax karkaisun tutkiminen neuromaisten konekäännösmallien harjoitteluun', 'sk': 'Preiskava Softmax kaljenja za trening nevralnih modelov strojnega prevajanja', 'he': 'Investigating Softmax Tempering for Training Neural Machine Translation Models', 'ha': 'Ana ƙidãya', 'jv': 'yatigating Softmaximum templing kanggo Tarjamahan Neral Majin Terjamahan', 'bo': 'Investigating Softmax Temperature for Training Neural Machine Translation Models'}
{'en': 'Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels. In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using  logits  approaches the gold label distribution. Although label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a  temperature coefficient  greater than one and forcing the softmax distribution to be smoother during training. This makes it harder for the  model  to quickly over-fit. In our experiments on 11 language pairs in the low-resource Asian Language Treebank dataset and we observed significant improvements in translation quality. Our analysis focuses on finding the right balance of label smoothing and softmax tempering which indicates that they are orthogonal methods. Finally and a study of softmax entropies and gradients reveal the impact of our method on the internal behavior of our NMT models.', 'ar': 'يتم تدريب نماذج الترجمة الآلية العصبية (NMT) عادةً باستخدام خسارة softmax cross-entropy حيث تتم مقارنة توزيع softmax مع الملصقات الذهبية. في سيناريوهات الموارد المنخفضة ، تميل نماذج NMT إلى الأداء السيئ لأن تدريب النموذج يتقارب بسرعة إلى نقطة حيث يقترب توزيع softmax المحسوب باستخدام السجلات من توزيع الملصقات الذهبية. على الرغم من أن تجانس الملصق هو حل معروف لمعالجة هذه المشكلة ، فإننا نقترح أيضًا تقسيم السجلات على معامل درجة حرارة أكبر من واحد وإجبار توزيع softmax على أن يكون أكثر سلاسة أثناء التدريب. هذا يجعل من الصعب على النموذج أن يصلح بسرعة. في تجاربنا على 11 زوجًا من اللغات في مجموعة بيانات Treebank للغة الآسيوية منخفضة الموارد ، ولاحظنا تحسينات كبيرة في جودة الترجمة. يركز تحليلنا على إيجاد التوازن الصحيح لتنعيم الملصق وتلطيف softmax مما يشير إلى أنها طرق متعامدة. أخيرًا ، كشفت دراسة انتروبيا softmax والتدرجات عن تأثير طريقتنا على السلوك الداخلي لنماذج NMT الخاصة بنا.', 'pt': 'Os modelos de tradução automática neural (NMT) são normalmente treinados usando uma perda de entropia cruzada softmax, em que a distribuição softmax é comparada com os rótulos dourados. Em cenários de poucos recursos e modelos NMT tendem a ter um desempenho ruim porque o treinamento do modelo converge rapidamente para um ponto em que a distribuição softmax calculada usando logits se aproxima da distribuição de rótulo ouro. Embora a suavização de rótulos seja uma solução bem conhecida para resolver esse problema, propomos ainda dividir os logits por um coeficiente de temperatura maior que um e forçar a distribuição softmax a ser mais suave durante o treinamento. Isso dificulta o ajuste rápido do modelo. Em nossos experimentos em 11 pares de idiomas no conjunto de dados do Asian Language Treebank de poucos recursos, observamos melhorias significativas na qualidade da tradução. Nossa análise se concentra em encontrar o equilíbrio certo entre suavização de rótulo e têmpera softmax, o que indica que são métodos ortogonais. Finalmente e um estudo de entropias e gradientes softmax revelam o impacto do nosso método no comportamento interno dos nossos modelos NMT.', 'fr': "Les modèles de traduction automatique neuronale (NMT) sont généralement entraînés à l'aide d'une perte d'entropie croisée softmax où la distribution softmax est comparée aux étiquettes de référence. Dans les scénarios à faibles ressources et les modèles NMT ont tendance à mal fonctionner parce que l'entraînement du modèle converge rapidement vers un point où la distribution softmax calculée à l'aide de logits se rapproche de la distribution Gold Label. Bien que le lissage des étiquettes soit une solution bien connue pour résoudre ce problème, nous proposons également de diviser les logits par un coefficient de température supérieur à un et de forcer la distribution softmax à être plus lisse pendant l'entraînement. Cela rend plus difficile le surajustement rapide du modèle. Lors de nos expériences sur 11 paires de langues dans le jeu de données Asian Language Treebank à faibles ressources, nous avons observé des améliorations significatives de la qualité de la traduction. Notre analyse se concentre sur la recherche du bon équilibre entre le lissage des étiquettes et la trempe softmax, ce qui indique qu'il s'agit de méthodes orthogonales. Enfin, une étude des entropies et des gradients softmax révèle l'impact de notre méthode sur le comportement interne de nos modèles NMT.", 'es': 'Los modelos de traducción automática neuronal (NMT) generalmente se entrenan utilizando una pérdida de entropía cruzada softmax donde la distribución softmax se compara con las etiquetas de oro. En escenarios de bajos recursos y los modelos NMT tienden a funcionar mal porque el entrenamiento del modelo converge rápidamente hasta un punto en el que la distribución softmax calculada mediante logits se acerca a la distribución de etiqueta dorada. Aunque el suavizado de etiquetas es una solución bien conocida para abordar este problema, también proponemos dividir los logits por un coeficiente de temperatura mayor que uno y forzar la distribución softmax a ser más suave durante el entrenamiento. Esto hace que sea más difícil que el modelo se ajuste demasiado rápidamente. En nuestros experimentos con 11 pares de idiomas en el conjunto de datos Asian Language Treebank de escasos recursos, observamos mejoras significativas en la calidad de la traducción. Nuestro análisis se centra en encontrar el equilibrio correcto entre el suavizado de etiquetas y el templado softmax, lo que indica que son métodos ortogonales. Finalmente, un estudio de las entropías y gradientes softmax revela el impacto de nuestro método en el comportamiento interno de nuestros modelos NMT.', 'ja': '神経機械翻訳（ ＮＭＴ ）モデルは、典型的には、ソフトマックスクロスエントロピー損失を使用して訓練され、ソフトマックス分布は、金ラベルと比較される。 低リソースのシナリオでは、モデルトレーニングがロジットを使用して計算されたソフトマックス分布がゴールドラベル分布に近づく点にすばやく収束するため、NMTモデルはパフォーマンスが悪い傾向がある。 ラベルスムージングはこの問題に対処するための有名なソリューションであるが、当社はさらに、トレーニング中にロジットを1より大きい温度係数で分割し、ソフトマックス分布をより滑らかにすることを提案している。 これにより、モデルがすぐにオーバーフィットしにくくなります。 低リソースのアジア言語ツリーバンクデータセットの11の言語ペアの実験では、翻訳品質の大幅な改善を観察しました。 当社の分析は、ラベル平滑化とソフトマックステンピングの適切なバランスを見つけることに焦点を当てており、それらが直交法であることを示しています。 最後に、ソフトマックスエントロピーと勾配の研究は、NMTモデルの内部挙動に対する当社の方法の影響を明らかにします。', 'ru': 'Модели нейронного машинного перевода (НМП) обычно обучаются с использованием перекрестной энтропии softmax, где распределение softmax сравнивается с золотыми метками. В сценариях с низкими ресурсами и моделях NMT, как правило, работают плохо, потому что обучение модели быстро сходится до точки, когда распределение softmax, рассчитанное с использованием логики, приближается к распределению золотой метки. Хотя сглаживание меток является хорошо известным решением этой проблемы, мы также предлагаем разделить логиты на температурный коэффициент, превышающий единицу, и заставить распределение softmax быть более плавным во время обучения. Это затрудняет быстрое перегибание модели. В наших экспериментах на 11 языковых парах в малоресурсном наборе данных Asian Language Treebank мы наблюдали значительное улучшение качества перевода. Наш анализ фокусируется на поиске правильного баланса сглаживания меток и отпусков softmax, что указывает на то, что они являются ортогональными методами. Наконец, исследование энтропий и градиентов softmax выявляет влияние нашего метода на внутреннее поведение наших моделей NMT.', 'hi': 'तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल को आमतौर पर एक सॉफ्टमैक्स क्रॉस-एन्ट्रॉपी हानि का उपयोग करके प्रशिक्षित किया जाता है जहां सॉफ्टमैक्स वितरण की तुलना सोने के लेबल के खिलाफ की जाती है। कम संसाधन परिदृश्यों और NMT मॉडल में खराब प्रदर्शन करते हैं क्योंकि मॉडल प्रशिक्षण जल्दी से एक बिंदु पर converges जहां logits का उपयोग कर गणना softmax वितरण सोने लेबल वितरण दृष्टिकोण. यद्यपि लेबल स्मूथिंग इस मुद्दे को संबोधित करने के लिए एक प्रसिद्ध समाधान है और हम आगे लॉगिट को एक से अधिक तापमान गुणांक द्वारा विभाजित करने का प्रस्ताव करते हैं और प्रशिक्षण के दौरान सॉफ्टमैक्स वितरण को चिकनी होने के लिए मजबूर करते हैं। यह मॉडल के लिए जल्दी से ओवर-फिट करने के लिए कठिन बनाता है। कम संसाधन एशियाई भाषा Treebank डेटासेट में 11 भाषा जोड़े पर हमारे प्रयोगों में और हम अनुवाद की गुणवत्ता में महत्वपूर्ण सुधार देखा. हमारा विश्लेषण लेबल स्मूथिंग और सॉफ्टमैक्स टेम्परिंग के सही संतुलन को खोजने पर केंद्रित है जो इंगित करता है कि वे ऑर्थोगोनल तरीके हैं। अंत में और softmax एन्ट्रोपी और gradients के एक अध्ययन से हमारे NMT मॉडल के आंतरिक व्यवहार पर हमारी विधि के प्रभाव का पता चलता है।', 'zh': '神经机器翻译 (NMT) 模常用 softmax 交熵损失训练,其 softmax 分布与金标签相较。 资源匮乏之场,NMT 模往往不佳,盖其教急敛于用 logits 计者 softmax 近金标也。 虽标平滑者,众所周知解决方案也,请更议以 logits 大于 1 温度系数,而强制训练以平 softmax 。 此使模形难速拟合。 于我乏资亚洲言树库数集11言实验,观译质之显重。 论重者,得标签平softmax回火之正衡,明其正交法也。 最后,对软大熵梯度之论,吾道动于NMT内部行为。', 'ga': 'Is gnách go gcuirtear oiliúint ar mhúnlaí néaraistriúcháin meaisín (NMT) ag baint úsáide as caillteanas tras-eantrópachta softmax nuair a chuirtear dáileadh softmax i gcomparáid leis na lipéid óir. I gcásanna íseal-acmhainne agus samhlacha NMT is gnách go bhfeidhmíonn siad go dona toisc go dtagann oiliúint na samhla le chéile go tapa go pointe ina bhfuil an dáileadh softmax á ríomh ag baint úsáide as logits ag druidim le dáileadh an lipéid óir. Cé gur réiteach aithnidiúil é smúdáil lipéad chun aghaidh a thabhairt ar an tsaincheist seo agus molaimid freisin na logits a roinnt le comhéifeacht teochta níos mó ná a haon agus an dáileadh softmax a bhrú chun bheith níos míne le linn na hoiliúna. Déanann sé seo níos deacra don mhúnla ró-fheistiú go tapa. Inár dturgnaimh ar 11 phéire teanga sa tacar sonraí Áise Language Treebank ar acmhainní íseal agus chonaiceamar feabhsuithe suntasacha ar cháilíocht an aistriúcháin. Díríonn ár n-anailís ar chothromaíocht cheart smúdála lipéad agus faghartha softmax a aimsiú a thugann le fios gur modhanna orthogonal iad. Ar deireadh agus léiríonn staidéar ar eantrópaí agus grádáin softmax an tionchar atá ag ár modh ar iompar inmheánach ár samhlacha NMT.', 'hu': 'A neurális gépi fordító (NMT) modelleket általában softmax kereszt-entrópia veszteséggel tanítják, ahol a softmax eloszlást összehasonlítják az arany címkékkel. Alacsony erőforrásokkal rendelkező forgatókönyvekben és NMT modellek általában rosszul teljesítenek, mert a modellképzés gyorsan konvergál egy olyan pontig, ahol a logits segítségével kiszámított softmax eloszlás megközelíti az arany címke eloszlást. Bár a címke simítása jól ismert megoldás ennek a problémának a megoldására, javasoljuk továbbá, hogy a logitek elosztását egynél nagyobb hőmérsékleti együtthatóval osszák meg, és kényszerítsék a softmax eloszlást edzés közben. Ez megnehezíti a modell számára, hogy gyorsan túlférjen. 11 nyelvpáron végzett kísérleteink során az alacsony erőforrású ázsiai nyelvű Treebank adatkészletben jelentős javulást figyeltünk meg a fordítási minőségben. Elemzésünk arra összpontosít, hogy megtaláljuk a megfelelő egyensúlyt a címke simítás és a softmax temperálás között, ami arra utal, hogy ezek ortogonális módszerek. Végül a softmax entrópiák és gradiensek vizsgálata feltárja módszerünk hatását NMT modelleink belső viselkedésére.', 'el': 'Τα μοντέλα νευρωνικής μηχανικής μετάφρασης (NMT) εκπαιδεύονται συνήθως χρησιμοποιώντας μια απώλεια διασταυρούμενης εντροπίας όπου η κατανομή του softmax συγκρίνεται με τις χρυσές ετικέτες. Σε σενάρια χαμηλών πόρων και μοντέλα τείνουν να αποδίδουν κακή απόδοση επειδή η εκπαίδευση μοντέλων συγκλίνει γρήγορα σε ένα σημείο όπου η κατανομή softmax που υπολογίζεται χρησιμοποιώντας λογικά προσεγγίζει τη διανομή χρυσών ετικετών. Αν και η εξομάλυνση ετικετών είναι μια γνωστή λύση για την αντιμετώπιση αυτού του ζητήματος και προτείνουμε περαιτέρω να διαιρέσουμε τα λογικά με έναν συντελεστή θερμοκρασίας μεγαλύτερο του ενός και να αναγκάσουμε την κατανομή να είναι ομαλότερη κατά τη διάρκεια της εκπαίδευσης. Αυτό καθιστά δυσκολότερο για το μοντέλο να προσαρμοστεί γρήγορα. Στα πειράματά μας σε έντεκα γλωσσικά ζεύγη στο σύνολο δεδομένων χαμηλής περιεκτικότητας στην Ασιατική Γλώσσα και παρατηρήσαμε σημαντικές βελτιώσεις στην ποιότητα της μετάφρασης. Η ανάλυσή μας επικεντρώνεται στην εύρεση της σωστής ισορροπίας της λείανσης ετικετών και της μετρίασης που δείχνει ότι είναι ορθογώνιες μέθοδοι. Τέλος και μια μελέτη των εντροπίων και των κλίσεων αποκαλύπτει την επίδραση της μεθόδου μας στην εσωτερική συμπεριφορά των μοντέλων μας.', 'ka': 'ნეიროლური მანქანის გადაწყვეტილება (NMT) მოდელები ტიპოლურად განსწავლებიან მანქანი კრესენტროპური დაკავშირის გამოყენებით, სადაც softmax გადაწყვეტილება დამატებული Gold Lab მცირე რესურსის სინარიოში და NMT მოდელში ცოტა შემდეგ გავაკეთებენ, რადგან მოდელური შემწყვება ძალიან დაბრუნდება, სადაც softmax გაყოფილება გამოყენებული ლოგიების გამოყენებაში მოდის მოდელური მაგრამ ჩვენ უფრო ცნობიერი პრობლემის გადაწყვეტილება ამ პრობლემის შესახებ და ჩვენ უფრო დავწევთ ლოგიკების გაყოფილი ტემპერაციის კოეფიციენტით, რომელიც ერთზე უფრო მეტია და მარტიმესი ეს უფრო რთული იქნება მოდელის მარტივი გადასრულება. ჩვენი ექსპერიმენტებში 11 ენათა ზოგების მარტივი რესურსის აზიანური ენაბანკის დეტატატის სამყაროში და ჩვენ შევხედავთ მნიშვნელოვანი გაუკეთესებ ჩვენი ანალიზია კონუქტირებულია მარჯვენა ბალანზაციის და softmax ტემპერიზაციის მოძებნა, რომელიც აჩვენებს, რომ ისინი ორტოდონალური მეტივები. საბოლოოდ და სწავლობა softmax entropies და gradients განსაზღვრებულია ჩვენი მედიოდის შედეგი NMT მოდელების ინტერული ქცევაზე.', 'it': "I modelli NMT (Neural Machine Translation) sono tipicamente addestrati utilizzando una perdita di entropia incrociata softmax dove la distribuzione softmax viene confrontata con le etichette dorate. Negli scenari a basso consumo di risorse e i modelli NMT tendono a performare male perché la formazione dei modelli converge rapidamente a un punto in cui la distribuzione softmax calcolata utilizzando logits si avvicina alla distribuzione gold label. Sebbene lo smoothing delle etichette sia una soluzione ben nota per affrontare questo problema, proponiamo inoltre di dividere i logits per un coefficiente di temperatura maggiore di uno e forzando la distribuzione softmax ad essere più fluida durante l'allenamento. Questo rende più difficile per il modello adattarsi rapidamente. Nei nostri esperimenti su 11 coppie linguistiche nel set di dati Treebank Asian Language a basso contenuto di risorse abbiamo osservato miglioramenti significativi nella qualità della traduzione. La nostra analisi si concentra sul trovare il giusto equilibrio tra lisciatura delle etichette e tempra softmax che indica che si tratta di metodi ortogonali. Infine, uno studio di entropie e gradienti softmax rivela l'impatto del nostro metodo sul comportamento interno dei nostri modelli NMT.", 'lt': 'Neuraliniai mašinų vertimo (NMT) modeliai paprastai mokomi naudojant softmax kryžminį entropijos praradimą, kai softmax pasiskirstymas lyginamas su aukso etiketėmis. Mažai išteklių turinčiais scenarijais ir NMT modeliais paprastai vyksta blogai, nes modelio mokymas greitai konvergencija į tašką, kai naudojant logitus apskaičiuotas softmax paskirstymas artėja prie aukso ženklo paskirstymo. Although label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a temperature coefficient greater than one and forcing the softmax distribution to be smoother during training.  Dėl to modeliui sunkiau greitai pereiti. Mūsų eksperimentuose su 11 kalbų poromis mažai išteklių turinčiame Azijos kalbų medžio banko duomenų rinkinyje ir pastebėjome reikšmingą vertimo kokybės pagerėjimą. Mūsų analizėje daugiausia dėmesio skiriama tinkamos etiketės sklandavimo ir minkštųjų švelnių temperatūros pusiausvyros nustatymui, o tai rodo, kad jos yra ortogoniniai metodai. Galiausiai ir softmax entropijų ir gradientų tyrimas atskleidžia mūsų metodo poveikį mūsų NMT modelių vidaus elgesiui.', 'kk': 'Нейрондық машинаны аудару (NMT) үлгілері әдетте алтын жарлықтарымен салыстырылған салыстырылып, бағдарламалық үлестірімі алтын жарлықтарымен салыстырылады. Төменгі ресурс сценариясында және NMT үлгілерінде жарамсыз істеу әдімгі жеткізеді, себебі үлгілер оқыту үлгілері алтын белгілерді үлестіру үшін логиттермен есептелген softmax үлестірім Бұл мәселені шешу үшін белгілерді таңдау керек шешімі болса да, және біз жұмыс істеу кезінде логияларды температураның коэффициенті бірден артық бөлу үшін және бағдарламаның максималдық үлестірі Бұл үлгісінің тез жақсы болу үшін қиын болады. Азия тілінің ағаш бағытты деректер жиынында 11 тіл екі тәжірибелерімізде және аудармалардың сапасында маңызды жақсартуларын көрдік. Біздің анализиямыз белгілердің оң балансын табуға көмектеседі. Олар ортогоналдық әдістерін көрсетеді. Соңында және бағдарламалық ентропияларды және градиенттерді зерттеу NMT үлгілеріміздің ішкі әрекетінің нәтижесін көрсетеді.', 'ms': 'Model terjemahan mesin saraf (NMT) biasanya dilatih menggunakan kerugian salib entropi softmax di mana distribusi softmax dibandingkan dengan label emas. Dalam skenario sumber rendah dan model NMT cenderung untuk melakukan buruk kerana latihan model cepat menuju ke titik dimana distribusi softmax dikira menggunakan logits mendekati distribusi label emas. Walaupun penyelesaian label adalah penyelesaian yang diketahui untuk mengatasi isu ini dan kami melanjutkan untuk membahagi logit dengan koeficien suhu yang lebih besar daripada satu dan memaksa distribusi softmax menjadi lebih laju semasa latihan. Ini membuat ia lebih sukar untuk model untuk cepat over-fit. Dalam eksperimen kami pada 11 pasangan bahasa dalam set data Pangkalan Bahasa Asia yang mempunyai sumber rendah dan kami memperhatikan peningkatan yang signifikan dalam kualiti terjemahan. Analisis kami fokus pada mencari keseimbangan yang betul dari peluncuran label dan temperamen softmax yang menunjukkan bahawa mereka adalah kaedah ortogonal. Akhirnya dan kajian entropi softmax dan gradien mengungkapkan kesan kaedah kita pada perilaku dalaman model NMT kita.', 'ml': 'ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ (NMT) മോഡലുകള്\u200d സാധാരണ പരിശീലിക്കപ്പെടുന്നു. സ്വര്\u200dണ്ണ ലേബെല്ലുകള്\u200dക്കെതിരായി മെഫ്റ്റ് ക്രിസ്റ്റ്-എ കുറഞ്ഞ വിഭവങ്ങളിലും NMT മോഡലുകളിലും പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d സാധിക്കുന്നുണ്ട്. കാരണം മോഡല്\u200d പരിശീലനം വേഗത്തില്\u200d മാറുന്നു. ലോഗ്റുകള്\u200d ഉപയോഗ ഈ പ്രശ്നത്തെ വിശദീകരിക്കുന്നതിനുള്ള ഒരു നല്ല പരിഹാരമാണെങ്കിലും ലോഗ്റ്റുകളെ വിഭാഗിക്കാന്\u200d ഞങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു. ഒരാളെക്കാള്\u200d ഉ ഇത് പെട്ടെന്ന് മോഡലിന് പ്രയാസകരമാക്കുന്നു. ഞങ്ങളുടെ പരീക്ഷണങ്ങളില്\u200d ആഷ്യഭാഷ വിഭവങ്ങളിലെ 11 ഭാഷ ജോട്ടുകാരില്\u200d നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d ഞങ്ങള്\u200d പരിശോധിക്കുന്നു. പരിഭാ നമ്മുടെ അന്വേഷണം ലേബിളിന്റെ ശരിയായ തുലാസിനെ കണ്ടെത്തുന്നതിനെക്കുറിച്ച് ശ്രദ്ധിച്ചിരിക്കുന്നു. അതിന്റെ മോ അവസാനം സോഫ്റ്റ്മാക്സ് എന്\u200dട്രോപ്പികളുടെയും ഗ്രേഡെന്\u200dറുകളുടെയും ഒരു പഠനം നമ്മുടെ രീതിയില്\u200d നമ്മുടെ ആന്തരീക പ്രവര്\u200dത്ത', 'mt': 'Il-mudelli tat-traduzzjoni tal-magni newrali (NMT) huma tipikament imħarrġa bl-użu ta’ telf ta’ cross-entropy softmax fejn id-distribuzzjoni softmax titqabbel mat-tikketti tad-deheb. F’xenarji b’riżorsi baxxi u mudelli NMT għandhom it-tendenza li jwettqu prestazzjoni ħa żina minħabba li t-taħriġ tal-mudell jikkonverġi malajr għal punt fejn id-distribuzzjoni softmax ikkalkulata bl-użu ta’ logits tilħaq id-distribuzzjoni tat-tikketta tad-deheb. Għalkemm it-tqaxxir tat-tikketta huwa soluzzjoni magħrufa sew biex tiġi indirizzata din il-kwistjoni u qed nipproponu wkoll li l-logits jinqasmu b’koeffiċjent tat-temperatura akbar minn wieħed u li tiġi mġiegħla d-distribuzzjoni tat-softmax tkun aktar bla xkiel matul it-taħriġ. Dan jagħmilha aktar diffiċli għall-mudell biex jitwaħħal malajr wisq. Fl-esperimenti tagħna fuq 11-il par lingwistiku fis-sett tad-dejta tal-Banek tal-Lingwa Asjatika b’riżorsi baxxi u osservajna titjib sinifikanti fil-kwalità tat-traduzzjoni. L-analiżi tagħna tiffoka fuq is-sejba tal-bilanċ it-tajjeb tal-lixxjar tat-tikketta u t-temperament tal-soft tmax li jindika li huma metodi ortogonali. Fl-a ħħar nett u studju ta’ entropiji u gradjenti softmax jiżvela l-impatt tal-metodu tagħna fuq l-imġiba interna tal-mudelli NMT tagħna.', 'mk': 'Моделите за нервен машински превод (НМТ) се обично обучени користејќи софтмакс крстоентропија загуба каде што дистрибуцијата на софтмакс се споредува со златните етикети. Во сценаријата со ниски ресурси и моделите на НМТ имаат тенденција да се извршат лошо бидејќи обуката на моделот брзо се приближува до точка каде што дистрибуцијата на softmax компјутирана со користење на логити се приближува до дистрибуцијата на златната етикета Иако разликувањето на етикетите е добро познато решение за решавање на ова прашање и понатаму предлагаме да ги поделиме логитите со температурен коефициент поголем од еден и да ја принудиме дистрибуцијата на софтмакс да биде полесна за време на обуката. Ова го отежнува моделот да се превклопи. Во нашите експерименти на 11 јазички парови во базата на податоци со ниски ресурси на азискиот јазик и набљудувавме значителни подобрувања во квалитетот на преводот. Нашата анализа се фокусира на пронаоѓањето на вистинската рамнотежа на лизгањето на етикетата и температурата на мек макс што покажува дека се ортогонални методи. Конечно и студијата на ентропиите и градиентите на софтмаксот го откриваат влијанието на нашиот метод на внатрешното однесување на нашите НМТ модели.', 'mn': 'Ньюрал машины хөгжүүлэлт (NMT) загварууд ихэвчлэн алтын etiketтэй харьцуулахад савны максимум эсрэг энтропийн алдагдлыг ашиглан сургалт хийгддэг. Бага баялаг болон NMT загварын хувилбаруудын хувилбарууд нь буруу байдаг. Учир нь загварын дасгал хөдөлгөөн хувилбарууд алтын загварын хуваалцлыг ашиглаж тооцоолж байгаа softmax хуваалцлын цэг руу хуваалцаж Энэ асуудлыг бодохын тулд сайн мэддэг шийдэл гэхдээ бид логикийг нэгээс их температурын коэффициентээр хувааж, дасгал хөгжүүлэх үед илүү бага зэрэг хувааж чадна. Энэ загварыг хурдан давхарлах нь хэцүү болгодог. Азийн хэл морь банкны өгөгдлийн сангийн 11 хэл хоёр туршилтын туршилтын дотор бид орчуулах чанарын чухал сайжруулалтыг анзаарсан. Бидний шинжилгээний талаар тэмдэглэгдэхийн зөв баланс олох нь төвлөрөгдөж байна. Энэ нь тэдгээрийг ортогон арга гэдгийг харуулдаг. Эцэст нь бидний NMT загварын доторх үйл ажиллагааны нөлөө үзүүлдэг.', 'pl': 'Modele neuronowego tłumaczenia maszynowego (NMT) są zazwyczaj trenowane przy użyciu straty krzyżowej entropii softmax, gdzie rozkład softmax jest porównywany ze złotymi etykietami. W scenariuszach o niskich zasobach i modele NMT mają tendencję do słabego działania, ponieważ szkolenie modeli szybko zbiega się do punktu, w którym dystrybucja softmaksu obliczona za pomocą logitów zbliża się do dystrybucji złotej etykiety. Chociaż wygładzanie etykiet jest dobrze znanym rozwiązaniem rozwiązania tego problemu i proponujemy podzielenie logitów przez współczynnik temperatury większy niż jeden i wymuszenie płynniejszego rozkładu softmaksu podczas treningu. Utrudnia to szybkie dopasowanie modelu. W naszych eksperymentach na 11-ciu parach językowych w niskim zasobowym zbiorze danych Asian Language Treebank obserwowaliśmy znaczącą poprawę jakości tłumaczeń. Nasza analiza skupia się na znalezieniu właściwej równowagi między wygładzaniem etykiet i odpuszczaniem softmax, co wskazuje, że są to metody ortogonalne. Wreszcie badanie entropii i gradientów softmaksu ujawnia wpływ naszej metody na wewnętrzne zachowanie naszych modeli NMT.', 'ro': 'Modelele de traducere automată neurală (NMT) sunt de obicei instruite folosind o pierdere softmax cross-entropie, unde distribuția softmax este comparată cu etichetele aurii. În scenariile cu resurse reduse și modelele NMT tind să performeze slab, deoarece instruirea modelului converge rapid într-un punct în care distribuția softmax calculată folosind logits se apropie de distribuția de etichete aurii. Deși netezirea etichetelor este o soluție bine cunoscută pentru a aborda această problemă și propunem în continuare să împărțim logits-urile cu un coeficient de temperatură mai mare decât unul și să forțăm distribuția softmax să fie mai lină în timpul antrenamentului. Acest lucru face mai greu pentru modelul să se suprapotrivească rapid. În experimentele noastre pe 11 perechi de limbi din setul de date cu resurse reduse Asian Language Treebank am observat îmbunătățiri semnificative în calitatea traducerii. Analiza noastră se concentrează pe găsirea echilibrului corect între netezirea etichetelor și temperarea softmax, ceea ce indică faptul că acestea sunt metode ortogonale. În cele din urmă, un studiu al entropiilor și gradienților softmax dezvăluie impactul metodei noastre asupra comportamentului intern al modelelor noastre NMT.', 'no': '@ info I låg ressursscenarioar og NMT-modeller har tendens å utføra slik dårlig, fordi modellen øving raskt konverterer til eit punkt der softmax-distribusjonen rekna ut med logikk nærar gull-merkelapportering. Selv om merkelappeløysing er ein godt kjent løysing for å handtera dette problemet, og vi foreslår meir å dele logikane med ein temperaturkoaeffisient større enn ein, og forandra at måkmaksfordelinga skal vera gladde under opplæring. Dette gjer det vanskeleg for å modellen raskt overpassa. I våre eksperimenter på 11 språk par i den lavressursen Asian Language Treebank-dataset og vi observerte signifikante forbedringar i omsetjingskvalitet. Analysen vårt fokuserer på å finna høgre balanse av merkelappen for å glansera og maksimale temperaturen som viser at dei er orthogonale metodar. Ein studie av softmax entropier og fargeovergangar viser effekten av metoden vårt på den interne atferden av NMT-modellen våre.', 'so': 'Tilmaamaha gaadiidka (NMT) waxaa sida caadiga ah loo tababariyaa isticmaalka khasaarada dhakhtarka ah ee korontopy, meesha lagu barbaranayo qaybinta dhakhtarka ah oo la barbaranayo alaabta dahabka ah. Xaaladaha hoose-resource iyo modelalka NMT waxey u baahan yihiin inay sameeyaan baas, sababtoo ah waxbarashada modellka ayaa dhaqso u beddelaya goobta lagu xisaabiyay qaybinta ugu hooseeya isticmaalka injiilku wuxuu u dhowaadaa qaybinta alaabta dahabka. In kastoo layxaliga lagu simi karo waa xal aad u yaqaan in ay arrintan ka qabsato, waxaynu u soo jeedaynaa in qoraalka lagu kala qaybin karo faa’iidada daboolka ah oo ka weyn mid iyo in lagu qasbo qaybinta dhakhtarka si ay u fududaato marka lagu baranayo. Tani waxay u adagtaa in tusaale dhaqso u sii habboon. Imtixaanadeena 11 luqada ah oo ku qoran kooxda macluumaadka ee hoose ee Aasiya Treebank, waxaynu aragnay hagaajino aad u weyn oo ku qoran tijaabada turjumaadda. Analyskayagu wuxuu ku kalsoonaa in la helo balanciga saxda ah oo siman iyo daboolka jilicsan, taasoo looga jeedaa in ay yihiin qaababka habboon. Finally and a study of softmax entropies and gradients reveal the impact of our method on the internal behavior of our NMT models.', 'si': 'න්\u200dයූරල් මැෂින් වාර්ථාව (NMT) මොඩේල් සාමාන්\u200dය විදියට ප්\u200dරශ්නයක් වෙනවා සමහර විශ්වාසය සමහර විශ්වාසය සඳහා සෝ අඩුම සම්බන්ධ සිනාරියෝ සහ NMT මොඩේල් වලින් වැරදි වෙන්න පුළුවන් වෙනවා මොඩේල් ප්\u200dරේෂණය ඉක්මනින් ඉක්මනින් සම්බන්ධ වෙන්න ප මේ ප්\u200dරශ්නයක් විස්තර කරන්න ලේබුල් සුදුසුම් කිරීම හොඳින් දන්න ප්\u200dරශ්නයක් තියෙනවා නමුත් අපි තව ප්\u200dරශ්නයක් එකට වඩා වැඩි උෂ්ණ ක මේක තරම් අමාරුවෙන් ඉක්මනින් වැඩියෙන් ඉක්මනින් වෙන්න පුළුවන් වෙනවා. අපේ පරීක්ෂණාවට භාෂාවක් 11 දෙකක් තියෙන්නේ අඩු අසියානු භාෂාවක් ට්\u200dරීබෑක් තොරතුරු සම්පූර්ණයෙන්  අපේ විශ්ලේෂණය පරීක්ෂණය කරනවා ලේබුල් සුදුසුම් සුදුසුම් සුදුසුම් සුදුසුම් සුදුසුම් සුදුසුම් සුදුසුම අන්තිමේදී අපේ NMT මෝඩේල් එකේ ඇතුළු භාවිතාවට ප්\u200dරශ්නයක් පේනවා.', 'sv': 'Neural Machine Translation (NMT) modeller tränas vanligtvis med hjälp av en softmax korsentropiförlust där softmax-fördelningen jämförs med guldetiketterna. I lågresursscenarier och NMT-modeller tenderar att prestera dåligt eftersom modellutbildningen snabbt konvergerar till en punkt där softmax-fördelningen beräknad med logits närmar sig guldetikettfördelningen. Även om etikettutjämning är en välkänd lösning för att ta itu med denna fråga föreslår vi vidare att dela logits med en temperaturkoefficient större än en och tvinga softmax-fördelningen att bli jämnare under träning. Detta gör det svårare för modellen att snabbt överpassa. I våra experiment på 11 språkpar i den resurssnåla Asian Language Treebank datauppsättningen observerade vi betydande förbättringar i översättningskvaliteten. Vår analys fokuserar på att hitta rätt balans mellan etikettutjämning och softmax härdning vilket indikerar att de är ortogonala metoder. Slutligen och en studie av softmax entropier och gradienter avslöjar effekten av vår metod på det interna beteendet hos våra NMT-modeller.', 'sr': 'Modeli neuronskog prevoda (NMT) tipično se obučavaju koristeći softmax cross-entropijski gubitak u kojem se softmax distribucija uspoređuje s zlatnim etiketama. U scenarijima niskih resursa i model a NMT-a se tendencija loše izvršavati, jer model obuka brzo se konverzuje na tačku gde se softmax distribucija izračunala sa logicama približava distribuciji zlatnih etiketa. Iako je rešenje etikete dobro poznato rješenje za rješenje ovog pitanja i dalje predlažemo da podijelimo logike koeficijentom temperature većim od jednog i prisiljavamo softmax distribuciju da bude glatko tokom treninga. To je teže da model brzo prestane. U našim eksperimentima o 11 jezičkih parova u podacima podataka Azijskog jezika Treebank i promatrali smo značajne poboljšanje kvalitete prevoda. Naša analiza se fokusira na pronalaženje pravog ravnoteža glatkovanja etiketa i softmax temperature koja ukazuje na to da su ortogonalne metode. Konačno i studija softmax entropija i gradienta otkrivaju uticaj našeg metoda na unutrašnje ponašanje našeg NMT modela.', 'ta': 'நெருக்கர் இயந்திர மொழிபெயர்ப்பு (NMT) மாதிரிகள் வழங்கப்பட்ட மென்மென்பொருள் குறியீட்டு இழப்பை பயன்படுத்தும் மென்பொருள் விரி குறைந்த resource scenarios மற்றும் NMT மாதிரிகள் தோல்வியை செய்யும். ஏனென்றால் மாதிரி பயிற்சி விரைவாக மாறும் புள்ளி Although label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a temperature coefficient greater than one and forcing the softmax distribution to be smoother during training.  இது மாதிரியில் விரைவாக மேலே பொருத்துவதற்கு கடினமாக செய்கிறது. குறைந்த மூலம் ஆசியா மொழி ட்ரீபாங் தரவு அமைப்பில் 11 மொழி ஜோடி சோதனைகளில் நாம் மொழிபெயர்ப்பு தரவில் முக்கியமான முன நம்முடைய ஆய்வு விளக்கச்சீட்டின் சரியான நிலையை கண்டுபிடிக்கும் மற்றும் மென்பொருள் வெப்பநிலையை கண்டுபிடிக கடைசியாக மற்றும் மென்பொருள் நுழைவுகள் மற்றும் கிரேட்டர்களின் ஒரு படிப்பியல் நம் முறைமையின் தாக்கத்தை எங்கள் NMT மாதிர', 'ur': 'نئورل ماشین ترجمہ (NMT) موڈل معمولاً نرم مکس کرسٹ انتروپی کے خسارہ کے مطابق تطابق کیے جاتے ہیں جہاں نرم مکس تقسیم سونے لابل سے مقایسہ کیا جاتا ہے. نیچے منبع سناریوں اور NMT نمڈلوں میں برا کام کرنا چاہتے ہیں کیونکہ نمڈلوں کی آموزش سریع ایک نقطہ تک پہنچ جاتی ہے جہاں لوجیٹ کے استعمال سے نرم ماکس تقسیم کی گئی ہے سونے لابل تقسیم کے قریب آتی ہے. اگرچہ لیبل ہلاکت یہ مسئلہ کے بارے میں بہتر معلوم حل ہے اور ہم اس سے زیادہ پیشنهاد کرتے ہیں کہ لوجیٹ کو ایک سے زیادہ تولید کے ذریعہ تقسیم کریں اور نرم مہربانی تقسیم کے ذریعہ تدریس کے وقت ہلاکت کریں۔ یہ موڈل کے لئے بہت ہی سخت ہوتا ہے کہ سریع مفید ہو جائے۔ ہمارے 11 زبان جوڑوں کی آزمائش میں آسیا کی زبان تری بانک ڈیٹ سٹ میں اور ہم نے ترجمہ کیفیت میں بہت اچھے سوداگری دیکھی۔ ہماری تحقیقات لیبل ہلاکت اور نرم ترمئنٹ کی درست ترمئنٹ پیدا کرنے پر تمرکز کرتی ہے جو نشان دیتا ہے کہ یہ اورٹوگونال طریقے ہیں آخر میں اور نرم مکس انٹروپی اور گریڈینٹ کی تحقیق ہمارے طریقے کے درمیان NMT موڈلوں کی داخلی رفتار پر اثر ظاہر کرتا ہے.', 'uz': "Name In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using logits approaches the gold label distribution.  Ikki yorliq cheksiz bu muammolarni boshqarish uchun yaxshi yo'q va biz yozuvchilarni birdan ortiq darajaga ajratishni istaysizmi va ta'lim paytidagi dastur soʻzni boshqalarga o'zgartirishni qanday qilamiz. Bu modelni tez o'zgartirish qiyin qiladi. Asiy tillar Treebank maʼlumotlari haqida 11 tillar qon tajribalarimizda biz tarjima sifatida juda muhim o'zgarishni ko'rsatdik. Analytikiz, yorliqning toʻgʻri balandligini o'rganish va dasturdagi darajada o'xshash o'rganish mumkin. Ular ortokon usullar. Oxirgi va dastur entropi va gradientlarning o'qituvchisi NMT modellarimizning ichki xususiyatlarimizni ko'rsatadi.", 'vi': 'Mẫu dịch máy thần kinh (NMB) thường được đào tạo nhờ một sự mất mát liên tế tế tế tế tế phòng khi phân phối đa dạng mềm được so sánh với nhãn vàng. Trong các kịch bản ít tài nguyên và mẫu NMT có xu hướng hoạt động kém bởi vì cuộc huấn luyện mô hình nhanh chóng hội tụ đến một điểm nơi phân phối đa dạng mềm được tính to án bằng giải thích với hệ thống sơn vàng. Mặc dù sự làm mịn nhãn là một giải pháp được biết đến để giải quyết vấn đề này và chúng tôi đề nghị chia giải pháp bằng cách sử dụng hệ số nhiệt độ lớn hơn so với một hệ số và ép độ phân phối đa dạng mềm phải làm mịn hơn khi được huấn luyện. Việc này khiến người mẫu khó vượt mức quá mức. Trong các thí nghiệm về ngôn ngữ 11 nối với hệ thống dữ liệu Châu Á về cây ngân hà ít tài nguyên và chúng tôi thấy những cải tiến đáng kể trong chất lượng dịch. Phân tích của chúng tôi tập trung vào việc tìm đúng cán cân làm mịn nhãn và nhiệt độ mềm cho thấy đó là phương pháp theo chuẩn. Cuối cùng, và một nghiên cứu về lượng cánh tả và dốc độ nghiêng tiết lộ tác động của phương pháp này lên hành vi nội bộ của các mô hình NMB.', 'bg': 'Моделите за неврален машинен превод (НМТ) обикновено се обучават с помощта на загуба на кръстосана ентропия, където разпределението на софтмакс се сравнява със златните етикети. При сценарии с ниски ресурси и моделите са склонни да се представят зле, тъй като обучението на модела бързо се сближава до точка, където разпределението на софтмакс, изчислено чрез логити, се доближава до разпределението на златния етикет. Въпреки че изглаждането на етикети е добре известно решение за решаване на този проблем и ние предлагаме допълнително да се разделят логитите на температурен коефициент по-голям от един и да се принуди разпределението на софтмакс да бъде по-гладко по време на тренировка. Това прави модела по-трудно бързо да се побере. В нашите експерименти с 11 езикови двойки в нискоресурсния набор от данни от азиатски езикови дървета наблюдавахме значителни подобрения в качеството на превода. Нашият анализ се фокусира върху намирането на правилния баланс между изглаждане на етикети и закаляване, което показва, че те са ортогонални методи. Накрая и проучване на софтмакс ентропии и градиенти разкрива влиянието на нашия метод върху вътрешното поведение на нашите модели.', 'nl': "Neural Machine Translation (NMT) modellen worden meestal getraind met behulp van een softmax cross-entropieverlies waarbij de softmax distributie wordt vergeleken met de gouden labels. In scenario's met weinig resources presteren NMT-modellen vaak slecht omdat de modeltraining snel convergeert tot een punt waarop de met logits berekende softmax-distributie de gouden label-distributie benadert. Hoewel het gladstrijken van etiketten een bekende oplossing is om dit probleem aan te pakken, stellen we verder voor om de logits te verdelen door een temperatuurcoëfficiënt groter dan één en te dwingen de softmax verdeling soepeler te zijn tijdens de training. Dit maakt het moeilijker voor het model om snel over-fit. In onze experimenten met 11-taalparen in de low-resource Asian Language Treebank dataset zagen we significante verbeteringen in de vertaalkwaliteit. Onze analyse richt zich op het vinden van de juiste balans tussen labelgladstrijken en softmax temperen, wat aangeeft dat het orthogonale methoden zijn. Tot slot en een studie van softmax entropies en gradiënten onthullen de impact van onze methode op het interne gedrag van onze NMT modellen.", 'da': 'Neural machine translation (NMT) modeller trænes typisk ved hjælp af et softmax cross-entropi tab, hvor softmax-fordelingen sammenlignes med guldetiketterne. I scenarier med lav ressource og NMT modeller har tendens til at yde dårligt, fordi modeltræningen hurtigt konvergerer til et punkt, hvor softmax-fordelingen beregnet ved hjælp af logits nærmer sig guldmærkefordelingen. Selvom mærkeudjævning er en velkendt løsning til at løse dette problem, foreslår vi yderligere at dividere logits med en temperaturkoefficient større end én og tvinge softmax-fordelingen til at være glattere under træning. Dette gør det sværere for modellen at hurtigt overfit. I vores eksperimenter med 11 sprogpar i det lave ressource Asian Language Treebank datasæt og vi observerede betydelige forbedringer i oversættelseskvaliteten. Vores analyse fokuserer på at finde den rigtige balance mellem etiketudjævning og softmax tempering, hvilket indikerer, at de er ortogonale metoder. Endelig og en undersøgelse af softmax entropier og gradienter afslører effekten af vores metode på den interne adfærd af vores NMT modeller.', 'hr': 'Modeli neurološkog prevoda (NMT) obično se obučavaju koristeći softmax cross-entropijski gubitak u kojem se softmax distribucija uspoređuje s zlatnim etiketama. U scenarijima niskih resursa i modelima NMT-a tendencija se loše izvršavaju jer se model obuka brzo konverzuje na to čku gdje se softmax distribucija izračunala s logicama približava distribuciji zlatnih etiketa. Iako je glatkovanje etiketa dobro poznato rješenje za rješavanje ovog pitanja i dalje predlažemo da podijelimo logike koeficijentom temperature većem od jedne i tjeramo mekačku distribuciju glatko tijekom treninga. To je teže da model brzo preklapa. U našim eksperimentima o 11 jezičkih parova u podacima podataka o zemljim resursima azijskog jezika Treebank i promatrali smo značajne poboljšanje kvalitete prevoda. Naša analiza se fokusira na pronalaženje pravog ravnoteža glatkovanja etiketa i softmax temperature koja ukazuje na to da su ortogonalne metode. Konačno i ispitivanje softmax entropija i gradienta pokazuje utjecaj našeg metoda na unutarnje ponašanje našeg NMT modela.', 'fa': 'مدلهای ترجمه ماشین عصبی (NMT) معمولاً با استفاده از دست دادن نرم\u200cترجمه\u200cای از انتروپی آموزش داده می\u200cشوند که تقسیم نرم\u200cترجمه با نرم\u200cترجمه\u200cهای نرم\u200cترجمه با نقاشی طلا مقایسه می\u200cشود. در سیناریو های کم منبع و مدل NMT به بدی عمل می کنند، زیرا آموزش مدل سریع به نقطه ای که تقسیم نرم\u200cماکس محاسبه شده با استفاده از logic به تقسیم لیبل طلا نزدیک می شود. اگرچه آرامش نقاشی یک راه حل شناخته شده برای حل این مسئله است و ما پیشنهاد می\u200cدهیم که منطقه\u200cها را با یک مقدار دما بیشتر از یک تقسیم کنیم و مجبور می\u200cکنیم تقسیم نرم\u200cترین نرم\u200cترین نرم در طول تمرین ساده\u200cتر باشد. این برای مدل خیلی سخت تر است که سریع زیادی قابل تفاوت باشد. در آزمایشات ما در جفت زبان ۱۱ در مجموعه داده\u200cهای درخت درخت زبان آسیا کم منبع است و ما در کیفیت ترجمه\u200cها بهترین ترجمه\u200cها را مشاهده کردیم. تحلیل ما روی پیدا کردن تعادل درستی از نقاشی و ترمز نرم و نرم که نشان می دهد که آنها روش\u200cهای متغیر هستند. بالاخره و مطالعه\u200cای از انتروپی\u200cهای نرم\u200cافزار و گرادینت\u200cهای نرم\u200cافزار تاثیر روش\u200cهای ما بر رفتار داخلی مدل\u200cهای NMT ما را نشان می\u200cدهد.', 'ko': '신경기계번역(NMT)모델은 보통 softmax 교차엔트로피 손실을 사용하여 훈련을 하는데 그 중에서 softmax의 분포와 황금 라벨을 비교한다.낮은 자원 상황에서 NMT 모델은 왕왕 좋지 않다. 왜냐하면 모델 훈련은 한 점으로 신속하게 수렴되기 때문이다. 즉logits로 계산된softmax분포는 황금 라벨분포에 가깝기 때문이다.비록 라벨이 매끄러운 것이 이 문제를 해결하는 모두가 알고 있는 해결 방안이지만, 우리는logits를 1보다 큰 온도계수로 나누고, 훈련 기간에softmax의 분포를 더욱 매끄럽게 하는 것을 강제로 권장한다.이 때문에 모형이 빨리 맞추기 어렵다.저자원 아시아 언어 라이브러리 데이터가 집중된 11가지 언어에 대한 실험에서 우리는 번역의 질이 현저히 개선된 것을 관찰했다.우리의 분석은 라벨이 매끄럽고 소프트웨어 회화의 정확한 균형을 찾는 데 중심을 두었는데 이것은 그들이 정교한 방법임을 나타낸다.마지막으로softmax엔트로피와 사다리에 대한 연구를 통해 우리의 방법이 NMT모델 내부 행위에 미친 영향을 제시했다.', 'id': 'Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels.  Dalam skenario sumber daya rendah dan model NMT cenderung untuk berkembang buruk karena pelatihan model cepat konvergensi ke titik dimana distribusi softmax dikomputerkan menggunakan logits mendekati distribusi label emas. Meskipun penyelesaian label adalah solusi yang terkenal untuk mengatasi masalah ini dan kami melanjutkan untuk membagi logit dengan koeficient suhu yang lebih besar dari satu dan memaksa distribusi softmax menjadi lebih laju selama latihan. Ini membuatnya lebih sulit untuk model untuk cepat over-fit. Dalam eksperimen kami pada 11 pasangan bahasa dalam dataset bahasa Asia Treebank sumber rendah dan kami memperhatikan peningkatan signifikan dalam kualitas terjemahan. Analisi kami fokus pada menemukan keseimbangan yang tepat dari penyelesaian label dan temperamen softmax yang menunjukkan bahwa mereka adalah metode ortogonal. Akhirnya dan sebuah studi entropi softmax dan gradien mengungkapkan dampak dari metode kita pada perilaku internal model NMT kita.', 'de': 'Neuronale Machine Translation (NMT) Modelle werden typischerweise mit einem softmax Kreuzentropieverlust trainiert, bei dem die softmax Verteilung mit den Goldetiketten verglichen wird. In ressourcenarmen Szenarien und NMT-Modellen neigen dazu, schlechte Ergebnisse zu erzielen, da das Modelltraining schnell zu einem Punkt konvergiert, an dem sich die mit Logits berechnete Softmax-Verteilung der Gold-Label-Verteilung annähert. Obwohl Etikettengleichung eine bekannte Lösung ist, um dieses Problem zu lösen, schlagen wir vor, die Logits durch einen Temperaturkoeffizienten zu teilen, der größer als einer ist und die softmax-Verteilung während des Trainings gleichmäßiger zu gestalten. Das macht es für das Modell schwieriger, schnell zu überpassen. In unseren Experimenten an 11-Sprachpaaren im ressourcenarmen Asian Language Treebank Datensatz konnten wir signifikante Verbesserungen der Übersetzungsqualität beobachten. Unsere Analyse konzentriert sich darauf, die richtige Balance zwischen Etikettenglättung und Softmax-Temperierung zu finden, was darauf hindeutet, dass es sich um orthogonale Methoden handelt. Schließlich und eine Studie von Softmax Entropien und Gradienten zeigen den Einfluss unserer Methode auf das interne Verhalten unserer NMT Modelle.', 'sw': 'Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels.  Katika mitindo ya rasilimali chini na miundo mbinu ya NMT huenda kufanya vibaya kwa sababu mafunzo ya model yanabadilika haraka na kuelekea kwenye pointi ambapo usambazaji wa programu uliohesabiwa kwa kutumia ujumbe unakaribia usambazaji wa alama ya dhahabu. Ingawa alama yenye vurugu ni suluhisho linalofahamika kutatua suala hili na tunapendekeza zaidi kuwagawanya logini kwa ufanisi wa joto zaidi ya moja na kuilazimisha usambazaji wa hali ya kawaida kuwa mzuri zaidi wakati wa mafunzo. Hii inafanya kuwa vigumu kwa mtindo wa haraka kupata nafasi. Katika majaribio yetu ya wanaume wa lugha 11 katika seti ya taarifa za lugha za Asia Treebank na tuliona maboresho makubwa katika kiwango cha tafsiri. Uchambuzi wetu unajikita katika kutafuta usawa sahihi wa mabadiliko yenye uchunguzi na hali ya ukame unaoonyesha kuwa ni njia za upasuaji. Mwisho na utafiti wa maoni na wasomi wa ubora unaonyesha athari ya njia yetu kuhusu tabia za ndani ya mifano yetu ya NMT.', 'am': 'የኔural machine translation (NMT) models are usually trained using softmax cross-entropy tap where softmax distribution is compared to gold labels. በዝቅተኛ resource scenarios እና የNMT ሞዴላዎች ድህነትን ለማድረግ ይጠቅማሉ፤ ምክንያቱም ሞዴል ተማሪ ፈጥኖ የሶፍትክ ክፍተት በመጠቀም ማሰናከል የሚቆጠርበት ቦታ በወርቅ መክፈቻ ይደርሳል፡፡ ምንም እንኳን የጽሑፍ ማቀናቀል የዚህን ጉዳይ ለማቀናኘት የተወሰነ መፍትሄ ነው፣ እናም ሌሎቹን በሙቀት ክፍተት ከአንዱ የበለጠ እና የሶፍትክ ክፍተቶችን በማስተካከል እናስገድዳለን፡፡ ይህም ምሳሌውን ፈጥኖ ለመፍጠር ይጨመርበታል፡፡ በአስያ ቋንቋ Treebank ዳታተር ውስጥ 11 ቋንቋዎች ሁለት ሁለት በሚያነሱ ፈተናችን እና ትርጓሜ ጥሩ ትርጓሜ እና ትርጓሜ ጥናት ታይተዋል፡፡ ትምህርታችን የባሕላዊ ሚዛን መቀናኛ እና የሶፍትኮት ትኩረት ማግኘት ነው፡፡ በመጨረሻው እና የሶፍትኮች እና ቀዳማጆች የሥርዓታችንን የNMT ዓይነቶች ውስጥነት ላይ የሚደረገውን ጥያቄ ያሳያል፡፡', 'tr': 'NMT nuýun makina terjimeleri (iň.MT) modelleri adatça ýumulty cross-entropi ýitilmegini ulanyp bilinýär. iň ýumulty bölümi altyn etiketlere garşylanýar. Aýak kaynaklar senaryoda we NMT nusgalarynda erbet işleýär, sebäbi model okuwçylygy çalt bir ýere çarpýar. Ýagtymsal daýratylygy ulanan logikler bilen altyn etiket daýratyndan yaklaýar. etiket ýuwmanyň bu meseleni çözmek üçin gowy bilinen çözüm bolsa hem biz ýöne logikaňy temperature koefisytçisi birden köp bölmek üçin teklip edip, ýöne ýuw daýlamagyny okuwçysda ýuw etmegi üçin tertibleýäris. Bu nusga çalt yzarlamak üçin kynlaşdyrýar. Biz 11 dil çift deneylerimizde Aziýa dil baglany sanatynda örän köp gelişmeleri gözledik. Bizim analizimiz etiketlerin düzgün derecelerini çözmek ve yumuşak sıcaklığın sağlam derecelerini bulmak üzere odaklandyrýar. Bu, ortogonal yöntemlerdir. Soňunda we iň ýokaryk ýokaryk entropiýasy we gradientýalaryň bardygyny NMT modellerimiziň içindeki hereketlerimiziň täsirini görkezýär.', 'af': "Neurale masjien vertaling (NMT) modele word tipies onderwerp met 'n sagte maksimum kruisentropie verlies waar die sagte maksimum verspreiding vergelyk word teen die goue etikette. In lae hulpbron-scenarios en NMT-modelles tendeer na verkeerd uitvoer, omdat die model onderwerking vinnig verbind na 'n punt waar die softmax-verspreiding bereken word deur logies te gebruik, naby die goue etiket verspreiding. Alhoewel die etiket gelukkig is 'n goed bekend oplossing om hierdie probleem te adres en ons verder voorstel om die logiese te deel deur 'n temperatuur koeffisient groter as een en die sagte maksimum verspreiding te verdruk om gelukkiger te wees tydens onderwerp. Dit maak dit harder vir die model om vinnig oor-pas te maak. In ons eksperimente op 11 taal paar in die lae-hulpbron Asies Taal Boom bank dataset en ons het betekeurige verbeteringe in vertaling kwaliteit aangesien. Ons analisie fokus op die regterbalance van etiket gelukkig en softmaksimum tempering wat wys dat hulle orthogonale metodes is. Eindelik en 'n studie van softmax entropies en gradiente vertoon die effek van ons metode op die interne gedrag van ons NMT modelle.", 'sq': 'Modelet e përkthimit të makinave nervore (NMT) janë tipikisht të trajnuar duke përdorur një humbje të ndër-entropisë softmax ku shpërndarja e softmax krahasohet me etiketat e artë. In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using logits approaches the gold label distribution.  Megjithëse lehtësimi i etiketës është një zgjidhje e njohur për të trajtuar këtë çështje dhe ne propozojmë më tej të ndajmë logjet me një koeficient temperature më të madh se një dhe të detyrojmë shpërndarjen e softmax të jetë më e lehtë gjatë trajnimit. Kjo e bën më të vështirë që modeli të përshtatet shpejt. Në eksperimentet tona në 11 çifte gjuhësh në bazën e të dhënave të gjuhës aziatike me burime të ulëta dhe kemi vëzhguar përmirësime të rëndësishme në cilësinë e përkthimit. Analiza jonë përqëndrohet në gjetjen e balancës së duhur të lehtësimit të etiketës dhe temperamentit të softmax që tregon se ato janë metoda ortogonale. Më në fund dhe një studim i entropive dhe gradientëve të softmax zbulon ndikimin e metodës sonë në sjelljen e brendshme të modeleve tona NMT.', 'hy': 'Նյարդային մեքենայի թարգմանման (NMT) մոդելները սովորաբար վարժեցվում են օգտագործելով թեթմաքսի խաչը էնտրոպիայի կորստ, որտեղ թեթմաքսի տարածումը համեմատում է ոսկու պիտակների հետ: Նվազ ռեսուրսներ ունեցող սցենարներում և NMT մոդելներում հակված են վատ աշխատել, որովհետև մոդելը վարժեցնում է արագ մոտենում այն կետին, որտեղ ծրագրավորված ծրագրավորումը հաշվարկվում է լոգիտների օգնությամբ, մոտենում Չնայած, որ պիտակների հավասարակշռումը լավ հայտնի լուծում է այս խնդիրը լուծելու համար, և մենք նաև առաջարկում ենք բաժանել լոգիտները մեկից ավելի մեծ ջերմաստիճանի կոեֆեյցիոն և ստիպել soft-hmax տարածումը ավելի հավասարակշռության ժամանակ: Սա դժվարանում է մոդելի արագ չափից շատ հարմարվել: Մեր փորձարկումներում 11 լեզու զույգերի վրա ցածր ռեսուրսներ ունեցող ասիացի լեզուների ծառի տվյալների համակարգում և մենք նկատեցինք թարգմանության որակի կարևոր բարելավումներ: Մեր վերլուծությունը կենտրոնանում է պիտակների ճիշտ հավասարակշռության գտնելուն, որը նշանակում է, որ դրանք օրթոգոնալ մեթոդներ են: Finally and a study of softmax entropies and gradients reveal the impact of our method on the internal behavior of our NMT models.', 'bn': 'নিউরেল মেশিন অনুবাদ (এনএমটি) মডেল সাধারণত একটি সফটম্যাক্স ক্রস-এন্ট্রোপি ক্ষতির মাধ্যমে প্রশিক্ষণ প্রদান করা হয় যেখানে সোনার লেব নিম্ন সম্পদের পরিস্থিতি এবং এনএমটি মডেল খারাপ কাজ করে যায় কারণ মডেল প্রশিক্ষণ দ্রুত একটি বিন্দুতে যেখানে লগট ব্যবহার করে সফটম্যাক্স বিতরণ ব্যবহা যদিও লেবেলেট ধূমপাত হচ্ছে এই বিষয়টি নিয়ে সুপরিচিত সমাধান এবং আমরা আরো প্রস্তাব করছি লেগুলোকে তাপমাত্রার কার্যক্রমে বিভক্ত করে এবং প্রশিক্ষণের সময় সফটম্ এটা মডেলের জন্য কঠিন করে দ্রুত প্রস্থানের জন্য। এশিয়ার ভাষা ট্রিবাঙ্কের ডাটাসেটে ১১ ভাষার জোড়ার পরীক্ষায় আমরা অনুবাদের মানে গুরুত্বপূর্ণ উন্নয়ন দেখেছি। আমাদের বিশ্লেষণের দৃষ্টিভঙ্গি লেবেলের ধূমপাত্র এবং সফটম্যাক্সের তাপমাত্রা খুঁজে বের করার প্রতি মনোযোগ প্রদান শেষ পর্যন্ত সফটম্যাক্স এন্ট্রোপি এবং গ্রেডেন্টের একটি গবেষণা আমাদের এনএমটি মডেলের আভ্যন্তরীণ আচরণের উপর আমাদের পদ্ধতির প্রভ', 'az': 'NMT modelleri altın etiketlərlə qarşılaşdırılır. Düşük ressurs senaryosunda və NMT modellərdə pis işlər görür, çünki modeli təhsil tezliklə qızıl etiketi dağıtılışına yaxınlaşır. Lakin etiket düzəltməsi bu meseleyi çəkmək üçün çox tanınmış bir çətinlikdir və biz daha çox logikləri bir sıcaklıq koeficienti ilə bölmək və təhsil sırasında yumuşaqlıq dağıtımı daha düzəldirmək üçün təklif edirik. Bu modeli tezliklə uyğunlaşdırmaq üçün daha zorlaşdırır. 11 dil çift təcrübələrimizdə Aziya dil ağacı bankası verilənlərinin düşük mənbələrində və tercümə keyfiyyətində möhkəm uzlaşmaları gördük. Bizim analizimiz etiketlərin düzgün balanını və yumuşaqlıq sıxıntısını tapmaq üçün odaqlanır ki, onlar orthogonal metodlarındır. Sonunda, yumuşaq entropilər və gradientlərin təcrübəsini NMT modellərinin iç davranışlarına göstərir.', 'cs': 'Modely neuronového strojového překladu (NMT) jsou obvykle trénovány pomocí ztráty křížové entropie softmaxu, kde je distribuce softmaxu porovnána se zlatými etiketami. Ve scénářích s nízkými zdroji a NMT modely mají tendenci výkony špatně, protože trénink modelu rychle konverguje do bodu, kdy distribuce softmaxu vypočítaná pomocí logitů přibližuje distribuci zlatých štítků. Přestože vyhlazování etiket je známým řešením tohoto problému a dále navrhujeme rozdělit logity teplotním koeficientem větším než jeden a nutit distribuci softmaxu během tréninku hladší. Tím je pro model těžší rychle přesahovat. V našich experimentech s jedenácti jazykovými páry v datové sadě Asian Language Treebank jsme pozorovali výrazné zlepšení kvality překladu. Naše analýza se zaměřuje na nalezení správné rovnováhy mezi vyhlazováním etiket a temperováním softmax, což naznačuje, že jde o ortogonální metody. Na závěr a studie softmaksových entropií a gradientů odhaluje vliv naší metody na vnitřní chování našich NMT modelů.', 'fi': 'Neuroiden konekäännösmalleja (NMT) koulutetaan tyypillisesti käyttämällä softmax cross-entropia lossia, jossa softmax-jakaumaa verrataan kultatarrojen kanssa. Vähävaraisissa skenaarioissa ja NMT-malleissa on taipumus suoriutua huonosti, koska mallikoulutus lähentyy nopeasti pisteeseen, jossa logiitteilla laskettu softmax-jakauma lähestyy kultamerkintäjakaumaa. Vaikka etikettien tasoitus on tunnettu ratkaisu tämän ongelman ratkaisemiseen, ehdotamme logittien jakamista lämpötilakertoimella, joka on suurempi kuin yksi ja pakottaa softmax-jakauman olemaan tasaisempi harjoittelun aikana. Tämä tekee mallista vaikeamman sovittaa nopeasti yli. Kokeissamme 11 kieliparilla vähäresurssisen Asian Language Treebankin aineistossa havaittiin merkittäviä parannuksia käännöslaadussa. Analyysimme keskittyy oikean tasapainon löytämiseen etikettien tasoituksessa ja softmax-karkaisussa, mikä osoittaa, että ne ovat ortogonaalisia menetelmiä. Lopuksi softmax entroopien ja gradienttien tutkimus paljastaa menetelmämme vaikutuksen NMT-mallien sisäiseen käyttäytymiseen.', 'bs': 'Modeli neuronskog prevoda (NMT) tipično se obučavaju koristeći softmax cross-entropijski gubitak u kojem se softmax distribucija uspoređuje s zlatnim etiketama. U scenarijima niskih resursa i model a NMT-a se tendencija loše izvršavati, jer model obuka brzo se konverzuje na to čku gdje se softmax distribucija izračunala s logicama približava distribuciji zlatnih etiketa. Iako je glatkovanje etiketa dobro poznato rješenje za rješavanje ovog pitanja i dalje predlažemo da podijelimo logike koeficijentom temperature većem od jednog i tjeramo softmax distribuciju da bude glatko tijekom treninga. To je teže da model brzo preskoči. U našim eksperimentima o 11 jezičkih parova u podacima podataka o zemljim resursima azijskog jezika Treebank i promatrali smo značajne poboljšanje kvalitete prevoda. Naša analiza se fokusira na pronalaženje pravog ravnoteža glatkovanja etiketa i softmax temperature koja ukazuje na to da su ortogonalne metode. Konačno i studija softmax entropija i gradienta otkrivaju utjecaj našeg metoda na unutrašnje ponašanje našeg NMT modela.', 'ca': "Els models de traducció neural de màquines (NMT) s'entrenen normalment fent servir una pèrdua de transentropia softmax on la distribució softmax es compara amb les etiquetes d'or. En escenaris de baix recursos i models NMT tendeixen a desempenyar-se malament perquè l'entrenament del model convergeix ràpidament fins a un punt on la distribució softmax calculada utilitzant logits s'apropa a la distribució de l'etiqueta d'or. Encara que l'alliniament de l'etiqueta és una solució ben coneguda per abordar aquest tema i també proposem dividir els lògics per un coeficient de temperatura més gran que un i forçar la distribució del softmax a ser més llògica durant l'entrenament. Això dificulta que el model s'ajusti ràpidament. En els nostres experiments en 11 parells de llengües en el conjunt de dades de baix recursos de la Banca Asiàtica de Llingues i vam observar millores significatives en la qualitat de la traducció. La nostra anàlisi es centra en trobar l'equilibri correcte entre l'alliniament de l'etiqueta i la temperació de la màxida suau, que indica que són mètodes ortogonals. Finalment, un estudi d'entròpies i gradients del softmax revela l'impacte del nostre mètode en el comportament intern dels nostres models NMT.", 'et': 'Neuraalse masintõlke (NMT) mudeleid koolitatakse tavaliselt softmax ristentroopia kadu kasutades, kus softmax jaotust võrreldakse kuldsete etikettidega. Vähese ressursiga stsenaariumide ja NMT mudelite puhul kipuvad tulema halvasti, sest mudeli koolitus läheneb kiiresti punktini, kus logitide abil arvutatud softmax jaotus läheneb kuldsildi jaotusele. Kuigi etiketi silumine on tuntud lahendus selle probleemi lahendamiseks, teeme lisaks ettepaneku jagada logitid temperatuurikoefitsiendiga, mis on suurem kui üks ja sundida softmax jaotus olema sujuvam treeningu ajal. Seetõttu on mudelil raskem kiiresti üle paigaldada. Meie eksperimentides 11 keelepaariga madala ressursiga Aasia Keele Puupank andmekogumis täheldasime olulist tõlkekvaliteedi paranemist. Meie analüüs keskendub õige tasakaalu leidmisele etiketi silumise ja pehme karastamise vahel, mis näitab, et need on ortogonaalsed meetodid. Lõpuks ja softmax entroopiate ja gradientide uuring näitab meie meetodi mõju meie NMT mudelite sisemisele käitumisele.', 'jv': '@item Text character set Nejer-jejer model sing paling-jejer model NMT tentang nggawe barang nggawe nguasai model sing ditambah sing nyimpen mruput nêmêng nêmêng nggawe gerarané sistem software macem sing isin nambah logit ngesaboh tanggal nambah etikete segala saiki. politenessoffpolite"), and when there is a change ("assertive Ere ngomong susahe kanggo model kuwi bisa mbelak. Nanging kapan-kapan ning 11 langa sing dirangkat kuwi tindang kuwi, dadi nggawe barang Asya Language Kernel FindOK', 'he': 'דוגמנים של מכונות נוירויות (NMT) מתאמנים בדרך כלל באמצעות אובדן קרוז-אנטרופיה של softmax שבו ההפצה של softmax משוואה עם תוויות הזהב. בתנאים עם משאבים נמוכים ודוגמנים NMT נוטים לבצע רע כי האימונים של הדוגמנים מתקרבים במהירות לנקודה שבה פיצוץ softmax מחשב באמצעות לוגיטים מתקרב לפיצוץ תווית זהב. למרות שמחלקת התווים היא פתרון ידוע היטב להתמודד עם הנושא הזה ואנחנו גם מציעים לחלק את הלוגיטים על ידי קופיקטיב טמפרטורה גדול יותר מאחד ולהכריח את פיצול המקס הרך להיות חלק יותר במהלך האימונים. זה מקשה למודל להתאים מהר יותר מדי. In our experiments on 11 language pairs in the low-resource Asian Language Treebank dataset and we observed significant improvements in translation quality.  הניתוח שלנו מתמקד במצוא את האיזון הנכון של התווית המחלקת והטמפרטוגן של "soft tmax", מה שמוכיח שהם שיטות אורטוגוניות. סוף סוף, ומחקר של אנטרופיות וסדרדיינטים של "soft tmax" חושף את השפעה של השיטה שלנו על ההתנהגות הפנימית של דוגמני NMT שלנו.', 'sk': 'Modeli nevralnega strojnega prevajanja (NMT) so običajno usposobljeni z uporabo izgube navzkrižne entropije softmax, kjer se porazdelitev softmax primerja z zlatimi etiketami. V scenarijih z nizkimi viri in modelih NMT običajno slabo delujejo, saj se usposabljanje modela hitro konvergira v točko, ko se porazdelitev softmax, izračunana z logiti, približa porazdelitvi zlate oznake. Čeprav je glajenje etiket dobro znana rešitev za reševanje tega vprašanja, nadalje predlagamo razdelitev logitov s temperaturnim koeficientom, večjim od enega in prisilitev, da je porazdelitev softmax med vadbo gladka. Zaradi tega je model težje hitro preveč prilegati. V naših eksperimentih na 11 jezikovnih parov v nizkih virov Azijske jezikovne banke Treebanke smo opazili pomembno izboljšanje kakovosti prevodov. Naša analiza se osredotoča na iskanje pravega ravnovesja glajenja etiket in softmax kaljenja, kar kaže, da gre za pravokotne metode. Nazadnje in študija softmax entropij in gradientov razkriva vpliv naše metode na notranje vedenje naših NMT modelov.', 'ha': "Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels.  In ƙayyade-resource da misãlai na NMT, misãlai masu amfani da shi na zartar da haske, kwani wa'adin ayuka na motel yana bada haraka zuwa wani point wanda aka lissafa buƙatan daraja da aka lissafa kafin a yi amfani da matsayin ayuka, yana kusa su sami zuwa rabon layin gulla. Ingawa mai daidaita label yana da sulfin mai sani wa masu shirya wa wannan masu al'amarin, kuma ko da ƙari tuna buɗa ɗe matsayin su rarraba matsayin da matsayin hotur mafi girma daga guda kuma za'a lazimta raba buƙatan matsayin da za'a sami da mutane a lokacin da za'a yi amfani da shi. Wannan yana kasa ƙaranci ga shirin ka yi haraka ga fitarwa. Daga jarrabayanmu masu samun nau'i 11 cikin tsarin littafin Asian Lugha Treebank kuma mun ga mafarinsa masu ƙaranci cikin sifar fassarar. AnaloyinMu yana muhimmin ka gane balancin daidaita wa label mai kiyaye da kwanan kwanan kwanan kwanan wata na matsayi da kwamfyuta, wanda yana gaya cewa, su ne metoden orthogonal. Haƙara da wani fitina na na misãlai masu ƙaranci da daraja sun nuna matsayin hanyoyinmu kan aikin da ke cikin misalin mu na NMT.", 'bo': 'Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels. In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using logits approaches the gold label distribution. label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a temperature coefficient greater than one and forcing the soft distribution to be smoother during training. འདིས་མ་དབྱིབས་དང་མཉམ་དུ་མཐུན་འགྱུར་བ་སྤྱོད་པར་ལས་ཀར་བ་ཞིག་ཡོད། ང་ཚོའི་སྐད་རིགས་ཀྱི་ཆ་རྐྱེན་གཅིག་ལས་མཐུན་རྐྱེན་བཟོ་བྱས་པར་ཨ་རིའི་སྐད་རིགས་དབྱིབས་ཀྱི་གནས་སྟངས་གཞི་བཙུགས་ཀྱི་མཐུ Our analysis focuses on finding the right balance of label smoothing and softmax tempering which indicates that they are orthogonal methods. མཐའ་མར་མ་ཟད་འཛིན་ཐུབ་པའི་འགྱུར་བ་དང་གླེང་སྒྲུང་གི་ཕྱོགས་སྣང་ཚོའི་ནང་གི་བྱ་སྟངས་ལ་གསལ་བཤད་ཀྱི་ཡོད།'}
{'en': 'Scrambled Translation Problem : A Problem of Denoising UNMT UNMT', 'ar': 'مشكلة الترجمة المختلطة: مشكلة تقليل الضوضاء UNMT', 'pt': 'Problema de Tradução Embaralhada: Um Problema de Denoising UNMT', 'es': 'Problema de traducción cifrada: un problema de eliminación de ruido de la UNMT', 'fr': 'Problème de traduction brouillée\xa0: un problème de débruitage UNMT', 'zh': '達쐗싐:謄뾧NMT', 'ja': 'スクランブル翻訳問題： UNMTを騒がせる問題', 'hi': 'Scrambled अनुवाद समस्या: UNMT Denoising की एक समस्या', 'ru': 'Проблема зашифрованного перевода: проблема подавления шума', 'ga': 'Fadhb Aistriúcháin Scrofa: Fadhb le UNMT a shéanadh', 'el': 'Πρόβλημα της ανακατεμένης μετάφρασης: Ένα πρόβλημα της αποκήρυξης του UNMT', 'ka': 'პრობლემა გადაწყვეტილება: UNMT- ის დენოიზაციის პრობლემა', 'hu': 'Zavart fordítási probléma: probléma az UNMT megnevezésével', 'kk': 'Аудару мәселесі: UNMT деносингінің мәселесі', 'it': 'Problema di traduzione scarabocchiata: un problema di denunciare UNMT', 'lt': 'Išsamios vertimo problemos: UNMT atmetimo problema', 'mk': 'Проблем со превод: Проблем со одбивањето на УНМТ', 'ms': 'Masalah Terjemahan Dirosakkan: Masalah Menolak UNMT', 'ml': 'സ്ക്രാമ്പിള്\u200d ചെയ്ത പരിഭാഷപ്പെടുത്തുന്ന പ്രശ്നം: ഡെനിയോസിങ് യുന്\u200dഎംടിയുടെ പ്രശ്നം', 'pl': 'Zamieszany problem tłumaczenia: problem denoisingu UNMT', 'mn': 'Шингэлтэй орчуулах асуудал: UNMT-ын Denoising асуудал', 'ro': 'Problemă de traducere încurcată: o problemă de denunțare a UNMT', 'sr': 'Problem sa prevodom: Problem Denoising UNMT-a', 'si': 'ස්ක්\u200dරැම්බල් වාර්ථාව ප්\u200dරශ්නයක්: UNMT ඩෙනොයිස් එකේ ප්\u200dරශ්නයක්', 'so': 'Dhibaatooyinka turjumista: Dhibaatooyinka Denoising UNMT', 'mt': 'Problema ta’ Traduzzjoni Scrambled: Problema ta’ Denoising UNMT', 'ta': 'வரிசைப்படுத்தப்பட்ட மொழிபெயர்ப்பு பிரச்சனை: UNMT டெனியோஸிங் சிக்கல்', 'no': 'Problem med skrammert omsetjing: Eit problem med UNMT- gjennomsetjing', 'ur': 'ٹرنگل مشکل: UNMT ڈنویس کا مشکل', 'sv': 'Problem med skrubbad översättning: Ett problem med att förneka UNMT', 'uz': 'Tarjima tarjima muammosi: UNMT toĘ»gĘ»rilash muammosi', 'vi': 'Phất ơ dịch: Một vấn đề về việc hoãn bỏ mặc con tin', 'bg': 'Проблем с бъркания превод: Проблем с денонизирането на ЮНМТ', 'hr': 'Problem prijevoza: Problem Denoising UNMT-a', 'da': 'Problem med oversættelse: Et problem med at afvise UNMT', 'nl': 'Scrambled Translation Problem: een probleem van het denoiseren van UNMT', 'de': 'Ein Problem bei der Denoisierung der UNMT', 'ko': '질문: UNMT 소음 제거', 'id': 'Masalah Terjemahan Terhancur: Sebuah Masalah Menolak UNMT', 'fa': 'مشکل ترجمه\u200cهای مختلف: مشکل دانوئیس UNMT', 'sw': 'Tatizo la Tafsiri la Tafsiri: Tatizo la Kukataa UNMT', 'tr': 'Ewez Et', 'af': "Skrambleerde Vertaling Problem: ' n Problem van Denoising UNMT", 'am': 'መግለጫ', 'az': 'T…ôrc√ºm…ô Problemi: UNMT Denoising Problemi', 'hy': 'Փոխառնված թարգմանման խնդիր. UNMT-ի մերժման խնդիր', 'bn': 'স্ক্র্যাম্প্লেড অনুবাদের সমস্যা: ডেনোজিং ইউনিএমটির একটি সমস্যা', 'ca': "Problema de traducció: Un problema de negar l'UNMT", 'bs': 'Problem prijevoza: Problem Denoising UNMT-a', 'cs': 'Problém zamíchaného překladu: problém denoisace UNMT', 'fi': 'Scrambled Translation Problem: A Problem of Denoising UNMT', 'et': 'Segatud tõlke probleem: probleem denoiseerimine UNMT', 'sq': 'Problemi i përkthimit të gabuar: Problemi i mohimit të UNMT', 'sk': 'Težava z mešanim prevajanjem: težava z označevanjem UNMT', 'he': 'Scrambled Translation Problem: A Problem of Denoising UNMT', 'ha': 'KCharselect unicode block name', 'jv': 'Jejaring Panjenengan Senegal: iso nggawe Denoying UNMT', 'bo': 'འདར་བཀོད་ཡོད་པའི་ཚིག་ཡིག་སྐད་ཀྱི་དཀའ་ངལ་བསམ：Denoising UNMT་ཡི་དཀའ་ངལ་ཅིག'}
{'en': 'In this paper and we identify an interesting kind of error in the output of Unsupervised Neural Machine Translation (UNMT) systems like Undreamt1. We refer to this error type as Scrambled Translation problem. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases. As a result and words of the translated sentence look scrambled and resulting in decreased  BLEU . We hypothesise that the reason behind scrambled translation problem is’ shuffling noise’ which is introduced in every input sentence as a  denoising strategy . To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy. We stop the training of the Denoising UNMT model after a pre-decided number of iterations and resume the training for the remaining iterations- which number is also pre-decided- using original sentence as input without adding any noise. Our proposed  solution  achieves significant performance improvement UNMT models that train conventionally. We demonstrate these performance gains on four language pairs and viz. and English-French and English-German and English-Spanish and Hindi-Punjabi. Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.', 'ar': 'في هذا البحث ، حددنا نوعًا مثيرًا للاهتمام من الخطأ في إخراج أنظمة الترجمة الآلية العصبية غير الخاضعة للإشراف (UNMT) مثل Undreamt1. نشير إلى نوع الخطأ هذا على أنه مشكلة ترجمة مختلطة. نلاحظ أن نماذج UNMT التي تستخدم تشويشًا عشوائيًا للكلمات (كما في حالة Undreamt) يمكن أن تولد كلمات صحيحة ولكنها تفشل في تجميعها معًا لتكوين عبارات. ونتيجة لذلك ، تبدو كلمات الجملة المترجمة مختلطة مما أدى إلى انخفاض BLEU. نحن نفترض أن السبب وراء مشكلة الترجمة المختلطة هو "خلط الضوضاء" الذي يتم تقديمه في كل جملة إدخال كاستراتيجية لتقليل الضوضاء. لاختبار فرضيتنا ونقوم بالتجربة من خلال إعادة تدريب نماذج UNMT باستراتيجية إعادة تدريب بسيطة. نوقف تدريب نموذج Denoising UNMT بعد عدد محدد مسبقًا من التكرارات ونستأنف التدريب على التكرارات المتبقية - وهو الرقم أيضًا محدد مسبقًا - باستخدام الجملة الأصلية كمدخلات دون إضافة أي ضوضاء. يحقق حلنا المقترح تحسينًا ملحوظًا في أداء نماذج UNMT التي تتدرب بشكل تقليدي. نظهر مكاسب الأداء هذه على أربعة أزواج لغوية. والإنجليزية - الفرنسية والإنجليزية - الألمانية والإنجليزية - الإسبانية والهندية - البنجابية. يُظهر تحليلنا النوعي والكمي أن استراتيجية إعادة التدريب تساعد في تحقيق محاذاة أفضل كما لوحظ من خلال مخطط حرارة الانتباه وترجمة أشباه الجمل بشكل أفضل وتؤدي إلى تحسن مهم إحصائيًا في درجات BLEU.', 'es': 'En este artículo identificamos un tipo de error interesante en la salida de sistemas de traducción automática neuronal no supervisada (UNMT) como Undreamt1. Nos referimos a este tipo de error como problema de traducción cifrada. Observamos que los modelos de la UNMT que utilizan ruido aleatorio de palabras (como en el caso de Undreamt) pueden generar palabras correctas pero no las unen para formar frases. Como resultado, las palabras de la oración traducida se ven mezcladas y dan como resultado una disminución de BLEU. Presumimos que la razón detrás del problema de la traducción confusa es el «ruido de barajar» que se introduce en cada frase de entrada como una estrategia de eliminación de ruido. Poner a prueba nuestra hipótesis y experimentamos reentrenando los modelos de la UNMT con una estrategia de reentrenamiento simple. Paramos el entrenamiento del modelo UNMT de eliminación de ruido después de un número predeterminado de iteraciones y reanudamos el entrenamiento para las iteraciones restantes, cuyo número también está predecidido, utilizando la oración original como entrada sin añadir ningún ruido. Nuestra solución propuesta logra una mejora significativa del rendimiento de los modelos de la UNMT que se entrenan de manera convencional. Demostramos estas mejoras de rendimiento en cuatro pares de idiomas, a saber, inglés, francés e inglés, alemán e inglés y inglés y español e hindi-punjabi. Nuestro análisis cualitativo y cuantitativo muestra que la estrategia de reentrenamiento ayuda a lograr una mejor alineación observada por el mapa de calor de atención y una mejor traducción de frases, lo que conduce a una mejora estadísticamente significativa en las puntuaciones de BLEU.', 'pt': "Neste artigo, identificamos um tipo interessante de erro na saída de sistemas de tradução automática neural não supervisionada (UNMT) como o Undreamt1. Referimo-nos a este tipo de erro como problema de tradução codificada. Observamos que os modelos UNMT que usam ruído de embaralhamento de palavras (como no caso de Undreamt) podem gerar palavras corretas, mas falham em juntá-las para formar frases. Como resultado, as palavras da frase traduzida parecem embaralhadas e resultam em BLEU diminuído. Nossa hipótese é que a razão por trás do problema de tradução embaralhada é o 'ruído de embaralhamento' que é introduzido em cada sentença de entrada como uma estratégia de redução de ruído. Para testar nossa hipótese e experimentamos retreinando modelos UNMT com uma estratégia simples de retreinamento. Paramos o treinamento do modelo Denoising UNMT após um número pré-definido de iterações e retomamos o treinamento para as iterações restantes - cujo número também é pré-definido - usando a sentença original como entrada sem adicionar nenhum ruído. Nossa solução proposta alcança melhorias significativas de desempenho em modelos UNMT que treinam convencionalmente. Demonstramos esses ganhos de desempenho em quatro pares de idiomas e viz. e Inglês-Francês e Inglês-Alemão e Inglês-Espanhol e Hindi-Punjabi. Nossa análise qualitativa e quantitativa mostra que a estratégia de retreinamento ajuda a alcançar um melhor alinhamento, conforme observado pelo mapa de atenção e melhor tradução frasal, levando a uma melhoria estatisticamente significativa nas pontuações do BLEU.", 'fr': "Dans cet article, nous identifierons un type d'erreur intéressant dans la sortie de systèmes de traduction automatique neuronale non supervisée (UNMT) tels que Undreamt1. Ce type d'erreur est appelé «\xa0problème de traduction brouillée\xa0». Nous observons que les modèles UNMT qui utilisent le bruit de mélange de mots (comme dans le cas d'Undreamt) peuvent générer des mots corrects mais ne parviennent pas à les assembler pour former des phrases. En conséquence, les mots de la phrase traduite semblent brouillés, ce qui entraîne une diminution de l'UEBL. Nous supposons que la raison du problème de traduction brouillée est le «\xa0bruit de mélange\xa0» qui est introduit dans chaque phrase saisie comme stratégie de réduction du bruit. Pour tester notre hypothèse et expérimenter en recyclant des modèles UNMT avec une stratégie de recyclage simple. Nous arrêtons l'entraînement du modèle Denoising UNMT après un nombre prédéterminé d'itérations et reprenons l'entraînement pour les itérations restantes - dont le nombre est également prédéterminé - en utilisant la phrase originale comme entrée sans ajouter de bruit. La solution que nous proposons permet d'améliorer considérablement les performances des modèles UNMT qui s'entraînent de manière conventionnelle. Nous démontrons ces gains de performance sur quatre paires de langues, à savoir l'anglais-français et l'anglais-allemand et l'anglais-espagnol et l'hindi-pendjabi. Notre analyse qualitative et quantitative montre que la stratégie de recyclage permet d'obtenir un meilleur alignement tel qu'observé par la carte thermique de l'attention et une meilleure traduction des phrases, ce qui conduit à une amélioration statistiquement significative des scores UEBL.", 'ja': '本稿では、Undreamt 1のような無監督神経機械翻訳（ UNMT ）システムの出力における興味深いエラーを特定します。 このエラータイプをスクランブル翻訳問題と呼びます。 私たちは、（ Undreamtの場合のように）単語シャッフルノイズを使用するUNMTモデルは、正しい単語を生成することができますが、フレーズを形成するためにそれらを縫い合わせることができないことを観察します。 その結果、翻訳された文章の単語や表現がスクランブルに見え、結果としてBLEUが減少する。 スクランブル翻訳問題の背後にある理由は、すべての入力文に非騒音戦略として導入されている「シャッフルノイズ」であると仮定しています。 私たちの仮説を検証するために、単純な再訓練戦略でUNMTモデルを再訓練して実験します。 事前に決められた回数の反復の後、雑音除去UNMTモデルのトレーニングを停止し、ノイズを追加せずに元の文章を入力として、残りの反復のトレーニングを再開します。 当社の提案するソリューションは、従来のトレーニングを行うUNMTモデルのパフォーマンスを大幅に向上させます。 私たちは、4つの言語ペア、すなわち英語、フランス語、英語、ドイツ語、英語、スペイン語、ヒンディー語、プンジャビ語でこれらのパフォーマンスの向上を実演します。 当社の定性的および定量的分析によると、再トレーニング戦略は、注意ヒートマップとより良いフレーズ翻訳によって観察されるように、より良いアライメントを達成し、BLEUスコアの統計的に有意な改善につながることが示されています。', 'hi': "इस पेपर में और हम Unsupervised Neural Machine Translation (UNMT) सिस्टम जैसे Undreamt1 के आउटपुट में एक दिलचस्प प्रकार की त्रुटि की पहचान करते हैं। हम इस त्रुटि प्रकार को Scrambled अनुवाद समस्या के रूप में संदर्भित करते हैं। हम देखते हैं कि यूएनएमटी मॉडल जो शब्द शफल शोर का उपयोग करते हैं (जैसा कि अनड्रेमट के मामले में) सही शब्द उत्पन्न कर सकते हैं और वाक्यांशों को बनाने के लिए उन्हें एक साथ सिलाई करने में विफल रहते हैं। नतीजतन और अनुवादित वाक्य के शब्द स्क्रैम्बल दिखते हैं और जिसके परिणामस्वरूप BLEU में कमी आई है। हम परिकल्पना करते हैं कि तले हुए अनुवाद समस्या के पीछे का कारण 'फेरबदल शोर' है जिसे हर इनपुट वाक्य में एक डिनोइज़िंग रणनीति के रूप में पेश किया जाता है। हमारी परिकल्पना का परीक्षण करने के लिए और हम एक सरल retraining रणनीति के साथ UNMT मॉडल retraining द्वारा प्रयोग करते हैं। हम पुनरावृत्तियों की एक पूर्व-निर्धारित संख्या के बाद यूएनएमटी मॉडल के प्रशिक्षण को रोकते हैं और शेष पुनरावृत्तियों के लिए प्रशिक्षण को फिर से शुरू करते हैं- जो संख्या भी पूर्व-निर्धारित है- बिना किसी शोर को जोड़े इनपुट के रूप में मूल वाक्य का उपयोग करके। हमारा प्रस्तावित समाधान महत्वपूर्ण प्रदर्शन सुधार यूएनएमटी मॉडल प्राप्त करता है जो पारंपरिक रूप से प्रशिक्षित करते हैं। हम इन प्रदर्शन लाभों को चार भाषा जोड़े और अर्थात् अंग्रेजी-फ्रेंच और अंग्रेजी-जर्मन और अंग्रेजी-स्पेनिश और हिंदी-पंजाबी पर प्रदर्शित करते हैं। हमारे गुणात्मक और मात्रात्मक विश्लेषण से पता चलता है कि retraining रणनीति बेहतर संरेखण प्राप्त करने में मदद करती है जैसा कि ध्यान हीटमैप और बेहतर phrasal अनुवाद द्वारा मनाया जाता है और BLEU स्कोर में सांख्यिकीय रूप से महत्वपूर्ण सुधार के लिए अग्रणी है।", 'zh': '本文中,见无监督神经机器翻译(UNMT)系统(如Undreamt1)输中一趣之误。 此误为"加扰译"。 吾观之,用单词随机噪声之UNMT(如Undreamt之情)可以成正单词,而不能与之拼接短语。 译句之单词乱,至于BLEU减。 吾设之,乱译者,洗牌噪音也,以为噪策入句。 试我之设,约而教之UNMT实验之。 先定迭代数之后,停对去噪UNMT模样,并复余迭代 - 其数亦预定 - 用原始句为输而不加噪音。 吾言解决方案成常 UNMT 形性显著。 四言而升,英语-法语、英语-德语、英语-西班牙语、印地语-旁遮普语。 吾定性定量分析明,练策有益热图善短语译者齐,BLEU分数之数显矣。', 'ru': 'В этой статье и мы идентифицируем интересный вид ошибки в выводе систем неконтролируемого нейронного машинного перевода (UNMT), таких как Undreamt1. Мы называем этот тип ошибки проблемой со скремблированным переводом. Мы отмечаем, что модели ЮНМТ, в которых используется шум тасования слов (как в случае Undreamt), могут генерировать правильные слова и не сшивать их вместе для формирования фраз. В результате слова переведенного предложения выглядят запутанными и приводят к уменьшению BLEU. Мы предполагаем, что причиной проблемы с зашифрованным переводом является «перетасовка шума», которая вводится в каждое входное предложение в качестве стратегии подавления шума. Чтобы проверить нашу гипотезу, мы экспериментируем с переподготовкой моделей UNMT с помощью простой стратегии переподготовки. Мы прекращаем обучение модели Денуаризации ЮНМТ после заранее определенного количества итераций и возобновляем обучение для оставшихся итераций - число которых также заранее определено - используя исходное предложение в качестве входных данных без добавления какого-либо шума. Наше предлагаемое решение обеспечивает значительное повышение эффективности моделей ЮНМТ, которые тренируются традиционно. Мы демонстрируем эти успехи на четырех языковых парах и, а именно, на английском-французском и английском-немецком, а также на английском-испанском и хинди-пунджаби. Наш качественный и количественный анализ показывает, что стратегия переподготовки помогает достичь лучшего выравнивания, что видно по тепловой карте внимания и лучшему фразеологическому переводу, и приводит к статистически значимому улучшению показателей BLEU.', 'ga': 'Sa pháipéar seo agus aithnímid earráid de chineál suimiúil in aschur na gcóras Aistriúcháin Meaisín Néaracha Gan Mhaoirseacht (UNMT) mar Undreamt1. Déanaimid tagairt don chineál earráide seo mar fhadhb Aistriúcháin Scrofa. Tugaimid faoi deara gur féidir le samhlacha UNMT a úsáideann torann suaitheadh focal (mar atá i gcás Undreamt) focail chearta a ghiniúint agus ach go dteipeann orthu iad a ghreamú le chéile chun frásaí a dhéanamh. Mar thoradh air sin agus tá cuma scrofa ar fhocail na habairte aistrithe agus laghdaítear BLEU dá bharr. Tugaimid hipitéis gurb é an chúis atá taobh thiar d’fhadhb an aistriúcháin scrofa ná ‘torann suaitheadh’ a thugtar isteach i ngach abairt ionchuir mar straitéis shéanta. Chun ár hipitéis a thástáil agus déanaimid triail trí mhúnlaí UNMT a athoiliúint le straitéis shimplí oiliúna. Stopaimid le hoiliúint mhúnla Denoising UNMT tar éis roinnt atriallta réamhchinnte agus cuirimid arís ar an oiliúint do na hathrialuithe eile - cén uimhir atá réamhchinnte freisin - ag baint úsáide as an abairt bhunaidh mar ionchur gan aon torann a chur leis. Baineann an réiteach atá molta againn amach samhlacha UNMT feabhsaithe feidhmíochta a thraenálann go hiondúil. Léirímid na gnóthachain feidhmíochta seo ar cheithre phéire teanga agus viz. agus Béarla-Fraincis agus Béarla-Gearmáinis agus Béarla-Spáinnis agus Hiondúis-Puinseáibis. Léiríonn ár n-anailís cháilíochtúil agus chainníochtúil go gcabhraíonn an straitéis athoiliúna le ailíniú níos fearr a bhaint amach mar a bhreathnaítear sa léarscáil teasa aird agus aistriúchán frása níos fearr agus as a dtagann feabhas suntasach go staitistiúil ar scóir BLEU.', 'ka': "ამ გვერდიში და ჩვენ განვიცნობით ინტერესური სახის შეცდომა, როგორც Undreamt1 სისტემების გადაწყვეტილებაში. ჩვენ ამ შეცდომა ტიპის შესახებ, როგორც სკრამბულია გადაწყვანა პრობლემა. ჩვენ შევხედავთ, რომ UNMT მოდელები, რომლებიც გამოყენებენ სიტყვის შუფლის სიტყვის (როგორც Undreamt-ის შემთხვევაში) შეუძლია წარმოადგენოთ მარტივი სიტყვის და არ შეუძლია მათ გადაწყვეტილი სიტყვების შედეგი და სიტყვების შემდეგი გადაწყვეტილია და შემდეგ გადაწყვეტილია BLEU. ჩვენ ჰიპოტესურებთ, რომ მიზეზი, რომელიც გადაწყენებული პრობლემა გადაწყენება, არის 'შუფლიური ხმა', რომელიც ყოველ გადაწყენებული სიტყვებში გადაწყენება რო ჩვენი ჰიპოტეზა და ჩვენ ექსპერიმენტის მოდელების შეცვლით, რომლებიც უკეთესი სტრატიფიკაციის შეცვლით. ჩვენ დავწყებთ UNMT მოდელის განაკეთებას, რომელიც წინ გადაწყვეტილი რიცხვის შემდეგ და გადავიწყებთ განაკეთებას დასრულებული განაკეთებას - რომელიც რიცხვი უბრალოდ გადაწყვეტილია - რომელიც იგივე დასრ ჩვენი წარმოიდგინული გარეშე უფრო მნიშვნელოვანი გარეშე UNMT მოდელები, რომლებიც კონტუნციურად გარეშე. ჩვენ გამოჩვენებთ ეს პროცექტის გასაღება 4 ენაზე და viz-ზე. და ინგლისური-ფრანგური, ანგლისური-გერმანური, ანგლისური-სპანელი და ჰინდი-ონჯაბი. ჩვენი კვალიტატიური და კოლუტატიური ანალიზი გამოჩვენება, რომ სტრატიფიკაციის გარეშე სტრატიგია უფრო უფრო სწორება, როგორც აჩვენებულია ინტერნეციის გარეშე და უფრო უფრო სტრას", 'el': 'Σε αυτή την εργασία και εντοπίζουμε ένα ενδιαφέρον είδος σφάλματος στην παραγωγή συστημάτων Μη εποπτευόμενης Νευρικής Μηχανικής Μετάφρασης (UNMT) όπως το Undramt1. Αναφερόμαστε σε αυτόν τον τύπο σφάλματος ως πρόβλημα ανακατεμένης μετάφρασης. Παρατηρούμε ότι τα μοντέλα που χρησιμοποιούν θόρυβο ανάμειξης λέξεων (όπως στην περίπτωση του Αδιαφανούς) μπορούν να δημιουργήσουν σωστές λέξεις και δεν μπορούν να τις ράψουν μαζί για να σχηματίσουν φράσεις. Ως αποτέλεσμα και οι λέξεις της μεταφρασμένης πρότασης φαίνονται μπερδεμένες και καταλήγουν σε μειωμένη BLEU. Υποθέτουμε ότι ο λόγος πίσω από το πρόβλημα της κωδικοποιημένης μετάφρασης είναι ο "θόρυβος ανακατεύοντας", ο οποίος εισάγεται σε κάθε πρόταση εισαγωγής ως μια αποκωδικοποιητική στρατηγική. Για να δοκιμάσουμε την υπόθεσή μας και να πειραματιστούμε επανεκπαίδευση μοντέλων με μια απλή στρατηγική επανεκπαίδευσης. Σταματάμε την εκπαίδευση του μοντέλου μετά από έναν προκαθορισμένο αριθμό επαναλήψεων και συνεχίζουμε την εκπαίδευση για τις υπόλοιπες επαναλήψεις -ο αριθμός είναι επίσης προκαθορισμένος- χρησιμοποιώντας την αρχική πρόταση ως εισαγωγή χωρίς να προσθέσουμε κανένα θόρυβο. Η προτεινόμενη λύση επιτυγχάνει σημαντική βελτίωση της απόδοσης μοντέλα που εκπαιδεύονται συμβατικά. Επιδεικνύουμε αυτά τα κέρδη απόδοσης σε τέσσερα γλωσσικά ζεύγη και συγκεκριμένα. και Αγγλικά-Γαλλικά και Αγγλικά-Γερμανικά και Αγγλικά-Ισπανικά και Χίντι-Παντζάμπι. Η ποιοτική και ποσοτική ανάλυση μας δείχνει ότι η στρατηγική επανεκπαίδευσης συμβάλλει στην επίτευξη καλύτερης ευθυγράμμισης, όπως παρατηρείται από τον Heatmap προσοχής και την καλύτερη φραστική μετάφραση και οδηγεί σε στατιστικά σημαντική βελτίωση των βαθμολογιών BLEU.', 'hu': 'Ebben a tanulmányban egy érdekes hibát azonosítunk a Felügyeletlen Neural Machine Translation (UNMT) rendszerek kimenetében, mint például az Undreamt1. Ezt a hibatípust Scrambled Translation problémának nevezzük. Megfigyeljük, hogy azok az UNMT modellek, amelyek szókeverési zajt használnak (mint az Undreamt esetében), helyes szavakat generálnak, de nem tudják összefűzni őket kifejezésekké. Ennek eredményeként a fordított mondat szavai zavarosnak tűnnek, ami csökkent BLEU-t eredményez. Feltételezzük, hogy a zavaros fordítási probléma oka a "keverési zaj", amelyet minden bemeneti mondatban jelölési stratégiáként vezetünk be. A hipotézisünket teszteljük és kísérletezünk UNMT modellek átképzésével egy egyszerű átképzési stratégiával. Előre meghatározott számú iteráció után leállítjuk a Denoising UNMT modell képzését, és folytatjuk a képzést a fennmaradó iterációkra - melyek száma szintén előre meghatározott -, eredeti mondatot használva bevitel nélkül zaj hozzáadása nélkül. Javasolt megoldásunk jelentős teljesítményjavítást ér el, amely hagyományosan képződik. Ezeket a teljesítménynövekedéseket négy nyelvpáron és nevezetesen mutatjuk be. és angol-francia és angol-német és angol-spanyol és hindi-pundzsábi. Kvalitációs és kvantitatív elemzésünk azt mutatja, hogy az átképzési stratégia segít a figyelemhőtérkép és a jobb szövegfordítás által megfigyelt jobb összehangolás elérésében, és statisztikailag szignifikáns javulást eredményez a BLEU pontszámok.', 'kk': 'Бұл қағазда және біз Undreamt1 секілді нейралық машинаны аудару (UNMT) жүйелердің шығысында қызықты қатенің түрін анықтаймыз. Бұл қате түріне Скрамблетті аудару мәселесі ретінде сәйкес береміз. Біз UNMT үлгілері сөздерді шешу дыбыстарын қолданатын (түсінбеген болса) дұрыс сөздерді құрып, бірақ оларды сөздерді құру үшін біріктіруге болмайды. Аударылатын сөздердің нәтижесі мен сөздері өзгертілген және BLEU дегенді азайтады. Біз аудармалардың артындағы мәселесінің себебі - әрбір енгізу сөздерінде таңдау стратегиясы ретінде көрсетіледі. Гипотезиямызды тексеру үшін және біз UNMT үлгілерін қарапайым қайталау стратегиясы арқылы тәжірибеп тұрамыз. Біз UNMT үлгісін бақылау үшін алдын- шешілген қайталау санынан кейін тоқтатып, қалдырған қайталау үшін оқытуды қайталадық. Бұл санды алдын- алдын- алдын- ала шешілген сөзді қолдану үшін, бастапқы сөзді қолдану Біздің таңдалған шешіміміз UNMT үлгілерін кәдімгі ретінде жетілдіреді. Біз бұл жылдамдықтарды төрт тіл және визуалды көрсету үшін көрсетедік. ағылшын-француз, ағылшын-неміс, ағылшын-испан және хинди-Пунджаби. Біздің квалификациялық және санативтік анализ бақылау стратегиясы, назардағы жылу картасы мен жақсы фразаларды аударып, BLEU нәтижелерінде статистикалық үлкен жақсы жақсарту үшін көмектеседі.', 'lt': 'Šiame dokumente ir mes nustatome įdomią klaidą, susijusią su nepastebimų neurologinių mašin ų vertimo (UNMT) sistemų, pavyzdžiui, Undreamt1, rezultatais. Šis klaidų tipas vadinamas Skrambinto vertimo problema. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  Dėl to vertimo sakinio žodžiai atrodo sutrumpinti ir dėl to sumažėja BLEU. Mes darome prielaidą, kad priežastis, dėl kurios susiduriama su triukšmo vertimo problem a, yra "triukšmo maišymas", kuris kiekviename įvadiniame sakinyje pateikiamas kaip denoising strategija. To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy.  Mes nutraukiame UNMT Denoising modelio mokymą po iš anksto nuspręsto kartojimų skaičiaus ir tęsime mokymą likusioms kartojimams - kuris numeris taip pat yra iš anksto nuspręstas - naudojant pradinį sakinį kaip įrašą be jokio triukšmo. Mūsų siūlomas sprendimas labai pagerina JT MT modelius, kurie paprastai rengiami. Mes demonstruojame šiuos rezultatus keturiose kalbų porose ir t. y. anglų, prancūzų, anglų, vokiečių, anglų, ispanų ir hindžabinų. Mūsų kokybinė ir kiekybinė analizė rodo, kad perkvalifikavimo strategija padeda pasiekti geresnį suderinimą, kaip nustatyta dėmesio šilumos žemėlapyje, geresnį frazių vertimą ir statistiškai reikšmingą BLEU rezultatų pagerėjimą.', 'it': 'In questo articolo identifichiamo un interessante tipo di errore nell\'output di sistemi Unsupervised Neural Machine Translation (UNMT) come Undreamt1. Ci riferiamo a questo tipo di errore come problema Scrambled Translation. Osserviamo che i modelli UNMT che utilizzano il rumore della parola mescolata (come nel caso di Undreamt) possono generare parole corrette e non riescono a cucirle insieme per formare frasi. Come risultato e le parole della frase tradotta sembrano confuse e con conseguente diminuzione del BLEU. Ipotizziamo che la ragione dietro il problema della traduzione criptata sia il "rumore di mescolamento" che viene introdotto in ogni frase di input come strategia di denoising. Per testare la nostra ipotesi e sperimentare riqualificando modelli UNMT con una semplice strategia di riqualificazione. Interrompiamo l\'allenamento del modello Denoising UNMT dopo un numero prestabilito di iterazioni e riprendiamo l\'allenamento per le iterazioni rimanenti, il cui numero è anche prestabilito, usando la frase originale come input senza aggiungere alcun rumore. La nostra soluzione proposta consente di migliorare significativamente le prestazioni dei modelli UNMT che si allenano convenzionalmente. Dimostriamo questi guadagni di performance su quattro coppie linguistiche e cioè. e inglese-francese e inglese-tedesco e inglese-spagnolo e hindi-punjabi. La nostra analisi qualitativa e quantitativa mostra che la strategia di riqualificazione aiuta a raggiungere un migliore allineamento come osservato dalla heatmap dell\'attenzione e una migliore traduzione frasale, portando a un miglioramento statisticamente significativo dei punteggi BLEU.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഒരു രസകരമായ പിശക് കണ്ടുപിടിക്കുന്നു. നിരീക്ഷിക്കപ്പെടാത്ത നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതില്\u200d  ഞങ്ങള്\u200d ഈ പിശക് ടൈപ്പിനെ സ്ക്രാമ്പിള്\u200d ചെയ്ത പരിഭാഷപ്രശ്നം എന്ന് വിളിക്കുന്നു. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  പരിഭാഷപ്പെടുത്തിയ വാക്കുകളുടെ ഫലവും വാക്കുകളുടെ കാരണം ബിലിയൂ നമ്മള്\u200d വിചാരിക്കുന്നു എല്ലാ അകത്തുള്ള വാക്കുകളിലും പ്രശ്നത്തിന്റെയും പിന്നിലുള്ള കാരണമെന്താണെന്ന്. അതിന്റെ പ്രശ്നം  നമ്മുടെ ഹൈപ്പിറ്റസിസ്സിനെ പരീക്ഷിക്കാനും നമ്മള്\u200d പരീക്ഷിക്കുന്നത് യുന്\u200dഎമ്ടി മോഡലുകള്\u200d പുനരുത്തുന് മുമ്പ് തീരുമാനിക്കപ്പെട്ട സംഖ്യകളുടെ എണ്ണത്തിനുശേഷം ഡെനോയിങ്ങ് യുന്\u200dഎമ്ടി മോഡലിന്\u200dറെ പരിശീലം നിര്\u200dത്തി ബാക്കിയുള്ള വസ്തുക്കള്\u200dക്ക് പരിശ നമ്മുടെ പ്രൊദ്ദേശിച്ചിരിക്കുന്ന പരിഹാരം യുന്\u200dഎംടി മോഡലുകള്\u200dക്ക് പ്രധാനപ്പെടുത്തുന്നത് പ്ര നാലു ഭാഷകളിലും വിസ്സിലും ഈ പ്രവര്\u200dത്തനങ്ങളുടെ സമ്പാദം നമ്മള്\u200d കാണിക്കുന്നു. ഇംഗ്ലീഷ്-ഫ്രെഞ്ച്, ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d, ഇംഗ്ലീഷ്-സ്പാനിഷ്, ഹിന്ദി-പുഞ്ചാബി. നമ്മുടെ ക്വാലിട്ടീവിക വിശേഷവും കാണിച്ചുകൊണ്ടിരിക്കുന്നു വീണ്ടും തിരിച്ചുപോകുന്ന സാങ്കേതം കൂടുതല്\u200d മെച്ചപ്പെടുത്തുന്നതിന് സഹായിക്', 'mk': 'Во овој весник и идентификуваме интересен вид на грешка во излезот на системите на Ненадгледувана Неурална машина преведување (УНМТ) како Undreamt1. Го нарекуваме овој тип грешка како проблем со преводот. Ние забележуваме дека моделите на УНМТ кои користат бучава на зборови (како во случајот на Незапишано) можат да генерираат правилни зборови и но не успеваат да ги зашијат заедно за да формираат фрази. Како резултат на тоа и зборовите од преведената реченица изгледаат збунети и резултираат со намалување на БЛЕ. Ние хипотезираме дека причината зад проблемот со преводот е „мешање на бучава“ која е воведена во секоја вводна реченица како стратегија за одбивање. Да ја тестираме нашата хипотеза и да експериментираме со претренирање на моделите на УНМТ со едноставна стратегија за претренирање. Прекинуваме со обуката на моделот Деноизирање на УНМТ по предодлучен број на итерации и продолжуваме со обуката за преостанатите итерации- кој број е исто така предодлучен- користејќи го оригиналната реченица како влог без додавање бука. Нашето предложено решение постигнува значително подобрување на резултатите на моделите на УНМТ кои се обучуваат конвенционално. Ги демонстрираме овие придобивки во изведувањето на четири јазички парови и виз. and English-French and English-German and English-Spanish and Hindi-Punjabi.  Нашата квалитетна и квантитивна анализа покажува дека стратегијата за ретренирање помага да се постигне подобро прилагодување, како што се набљудува од топлината мапа на вниманието и подобар фразален превод и води до статистички значително подобрување на оценкит', 'mn': 'Энэ цаасан дээр бид "Undreamt1" шиг мэдрэлийн мэдрэлийн хөгжлийн системийн үр дүнд сонирхолтой алдаа олж мэднэ. Бид энэ алдаа хэлбэрийг Шкрамбл орчуулах асуудал гэж үздэг. Бид UNMT загварууд үгийг хөдөлгөөн дуу ашиглан зөв үгийг бий болгодог гэдгийг анзаарлаа. Үүний үр дүнд, хөрөнгө оруулсан өгүүлбэрийн үгсийн үр дүнд БЛЕУ-ын багасгаж харагдаж байна. Бид өөрсдийгөө хуваалцах асуудлын ардын шалтгаан нь "чимээгүй чимээгүй" гэдгийг ойлгож байна. Энэ нь бүх өгүүлбэрийг хуваалцах стратеги болгон танилцуулагддаг. Өөрсдийнхөө таамаглалыг шалгахын тулд бид UNMT загваруудыг энгийн шилжүүлэх стратегийг дахин хийж туршиж үзсэн. Бид UNMT загварын дасгал хөдөлгөөнийг өмнө шийдвэрлэсэн хэмжээний дараа зогсоод үлдсэн дасгал хөдөлгөөнийг дахин үргэлжлүүлнэ. Бидний санал өгсөн шийдэл UNMT-ийн загваруудыг ихэвчлэн сайжруулдаг. Бид эдгээр үйл ажиллагааг 4 хэл хоёр болон виз дээр харуулж байна. Англи-Француз, Англи-Герман, Англи-Испан, Хинди-Панджаби. Манай чадвартай, хэмжээний шинжилгээ нь харуулж байгаа нь анхаарлын дулаарлын газрын зураг, илүү сайхан хэлбэрийг хөгжүүлж, BLEU оноо дээр статистикийн түвшинд маш чухал хөгжүүлэхэд тусалдаг.', 'mt': "F’dan id-dokument u nidentifikaw tip interessanti ta’ żball fl-output ta’ sistemi ta’ Traduzzjoni ta’ Magni Newrali Mhux Sorveljati (UNMT) bħal Undreamt1. We refer to this error type as Scrambled Translation problem.  We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  Bħala riżultat u l-kliem tas-sentenza tradotta jidhru mċajpra u jirriżultaw fi tnaqqis fil-BLEU. Aħna niipotesizzaw li r-raġuni wara l-problem a tat-traduzzjoni mċajpra hija 'l-istorbju ta' ċaqliq' li jiġi introdott f'kull sentenza ta' dħul bħala strateġija li tiċħad. Biex jittestjaw l-ipoteżi tagħna u a ħna nistsperimentaw billi nħarsu mill-ġdid il-mudelli tal-UNMT bi strateġija sempliċi ta’ taħriġ mill-ġdid. Aħna nwaqqfu t-taħriġ tal-mudell UNMT ta' Denoising wara numru ta' iterazzjonijiet deċiżi minn qabel u nibdew it-taħriġ għall-iterazzjonijiet li jifdal - liema numru huwa wkoll deċiż minn qabel - billi nużaw is-sentenza oriġinali bħala input mingħajr ma jżidu l-ebda storbju. Is-soluzzjoni proposta tagħna tikseb titjib sinifikanti fil-prestazzjoni tal-mudelli tal-UNMT li jitħarrġu b’mod konvenzjonali. Jiġu murija dawn il-kisbiet fil-prestazzjoni fuq erba’ pari lingwistiċi u vizz. and English-French and English-German and English-Spanish and Hindi-Punjabi.  Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.", 'no': 'I denne papiret og vi identifiserer ein interessant type feil i utdata av ikkje- spesifiserte neuralmaskinsomsetjingssystemer (UNMT) som Undreamt1. Vi refererer til denne feiltypen som skjramblert omsetjingsfeil. Vi observerer at UNMT-modeller som brukar ord-shuffle-støy (som i tilfelle for Undreamt) kan laga korrekte ord, men feil å setja dei sammen for å forma frasar. Som resultat og ord av den omsetjende setninga ser ut skrammert og resultat i nedgang av BLEU. Vi hypotiserer at grunnen bak omsetjingspunktet er «shuffling noise» som vert introdusert i kvar innsetjingspunkt som ein indikator strategi. For å test a hypotesien vårt og vi eksperimenterer ved å gjenoppretta UNMT-modeller med ein enkel retraining strategi. Vi stopper opplæring av UNMT-modellen Denoising etter eit før avgjørte tal gjentakingar og hald fram opplæringa for dei reste gjentakingane. Kva tal er også før avgjørte, brukar originalt setning som inndata utan å leggja til ein støy. Vårt foreslått løsning gjer signifikante forbedringar av utviklingar i UNMT-modeller som treng konvensjonelt. Vi viser at disse utviklingane går på fire språkpar og viz. og engelsk-fransk og engelsk-tysk og engelsk-spansk og hindi-punjabi. Vårt kvalitativ og kvantitativ analyse viser at strategien for gjenoppretting hjelper til å oppnå bedre innstillingar som blir observert av oppmerkskartet og bedre frasalomsetjing og fører til statistisk betydelig forbedring i BLEU-poeng.', 'pl': 'W niniejszym artykule zidentyfikowano interesujący rodzaj błędu w wyjściu systemów nienadzorowanego tłumaczenia maszynowego (UNMT), takich jak Undreamt1. Ten typ błędu określamy jako problem z tłumaczeniem zamieszanym. Obserwujemy, że modele UNMT, które używają szumu słowa shuffle (jak w przypadku Undreamt), mogą generować poprawne słowa i nie potrafią ich zszywać w formę fraz. W rezultacie i słowa przetłumaczonego zdania wyglądają zaszyfrowane i skutkują zmniejszeniem BLEU. Zakładamy hipotezę, że przyczyną problemu zakodowanego tłumaczenia jest "szum mieszania", który jest wprowadzany w każdym zdaniu wejściowym jako strategia denoisingu. Aby przetestować naszą hipotezę i eksperymentować poprzez przekwalifikowanie modeli UNMT z prostą strategią przekwalifikowania. Przerywamy trening modelu Denoising UNMT po ustalonej liczbie iteracji i wznowiamy trening dla pozostałych iteracji – która liczba jest również wstępnie ustalona – używając oryginalnego zdania jako wejścia bez dodawania żadnego hałasu. Proponowane przez nas rozwiązanie osiąga znaczną poprawę wydajności modeli UNMT, które trenują konwencjonalnie. Wykazujemy te wzrosty wydajności na czterech parach językowych i mianowicie. i angielsko-francuski i angielsko-niemiecki i angielsko-hiszpański i hindi-pundżabi. Nasza analiza jakościowa i ilościowa pokazuje, że strategia przekwalifikowania pomaga osiągnąć lepsze dostosowanie, co obserwowane przez heatmap uwagi i lepsze tłumaczenie fraz, a także prowadzi do statystycznie istotnej poprawy wyników BLEU.', 'ms': "In this paper and we identify an interesting kind of error in the output of Unsupervised Neural Machine Translation (UNMT) systems like Undreamt1.  Kami rujuk kepada jenis ralat ini sebagai masalah Terjemahan Tersulit. Kami memperhatikan bahawa model UNMT yang menggunakan bunyi penggabungan perkataan (seperti dalam kes Undreamt) boleh menghasilkan perkataan yang betul dan tetapi gagal menjahit mereka bersama-sama untuk membentuk frasa. As a result and words of the translated sentence look scrambled and resulting in decreased BLEU.  Kami hipotesis bahawa sebab di belakang masalah terjemahan terganggu ialah 'bunyi penggembiraan' yang diperkenalkan dalam setiap kalimat masukan sebagai strategi menolak. Untuk menguji hipotesis kita dan kita eksperimen dengan melatih semula model UNMT dengan strategi latihan semula mudah. We stop the training of the Denoising UNMT model after a pre-decided number of iterations and resume the training for the remaining iterations- which number is also pre-decided- using original sentence as input without adding any noise.  Solusi kami mencapai peningkatan prestasi yang signifikan model UNMT yang berlatih secara konvensional. Kami menunjukkan perkembangan prestasi ini pada empat pasangan bahasa dan viz. Inggeris-Perancis, Inggeris-Jerman, Inggeris-Sepanyol dan Hindi-Punjabi. Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.", 'ro': 'În această lucrare identificăm un tip interesant de eroare în rezultatul sistemelor de traducere automată neurală nesupravegheată (UNMT) precum Undreamt1. Ne referim la acest tip de eroare ca fiind problema Traducerii Scrambled. Observăm că modelele UNMT care folosesc zgomotul de amestecare a cuvintelor (ca în cazul Undreamt) pot genera cuvinte corecte și nu reușesc să le coase împreună pentru a forma fraze. Ca rezultat și cuvintele propoziției traduse par amestecate și rezultă în scăderea BLEU. Ipotezăm că motivul din spatele problemei de traducere criptată este "zgomotul amestecării", care este introdus în fiecare propoziție introdusă ca o strategie de denoising. Pentru a testa ipoteza noastră și experimenta prin recalificarea modelelor UNMT cu o strategie simplă de recalificare. Oprim antrenamentul modelului Denoising UNMT după un număr prestabilit de iterații și reluăm antrenamentul pentru iterațiile rămase – număr care este, de asemenea, prestabilit – folosind propoziția originală ca input fără a adăuga niciun zgomot. Soluția noastră propusă realizează îmbunătățirea semnificativă a performanței modelelor UNMT care se antrenează convențional. Demonstrăm aceste câștiguri de performanță pe patru perechi de limbi și anume. şi engleză-franceză şi engleză-germană şi engleză-spaniolă şi hindi-punjabi. Analiza noastră calitativă și cantitativă arată că strategia de recalificare ajută la obținerea unei alinieri mai bune, așa cum se observă prin harta de căldură a atenției și o traducere frazală mai bună, conducând la o îmbunătățire semnificativă statistic a scorurilor BLEU.', 'sr': 'U ovom papiru i identifikujemo zanimljivu vrstu greške u izlazu neodređenih neuroloških sustava prevoda mašina (UNMT) poput Undreamt1. Smatramo ovaj tip greške kao problem sa prevodom. Primećujemo da UNMT modeli koji koriste buku šupljanja reči (kao u slučaju Nesnova) mogu stvoriti prave reči i ne mogu ih zajedno šivati kako bi formirali fraze. Kao rezultat i reči prevedene rečenice izgledaju okrenuti i rezultat smanjenog BLEU-a. Pretpostavljamo da je razlog iza prevodnog problem a "bučna šuljanja", koji se uvede u svaku uložnu rečenicu kao strategija za indiciranje. Da bismo testirali našu hipotezu i eksperimentirali povratak UNMT modela jednostavnom strategijom povratka. Zaustavljamo obuku UNMT model a Denoising nakon predodlučenog broja iteracija i nastavimo obuku za ostale iteracije - koja je broj takođe predodlučena - koristeći originalnu rečenicu kao ulaz bez dodanja buke. Naše predloženo rješenje postiže značajno poboljšanje učinkovitosti UNMT modela koji konvencionalno voze. Pokazujemo da dobijamo ove predstave na četiri jezičke parove i viz. i engleski francuski, engleski-nemački, engleski-španjolski i hindi-punjabi. Naša kvalitativna i kvantitativna analiza pokazuje da strategija povlačenja pomaže ostvariti bolju usklađenost kao što je promatrana pažnjom toplinom mapom i boljom prevodom frazala i dovela do statistički značajnog poboljšanja rezultata BLEU-a.', 'sv': 'I denna uppsats och vi identifierar en intressant typ av fel i output av Unsupervised Neural Machine Translation (UNMT) system som Undreamt1. Vi hänvisar till denna feltyp som Scrambled Translation problem. Vi observerar att UNMT-modeller som använder ord shuffle brus (som i fallet med Undreamt) kan generera korrekta ord men misslyckas med att sy ihop dem för att bilda fraser. Som ett resultat och ord i den översatta meningen ser förvirrade ut och resulterar i minskad BLEU. Vi utgår från att orsaken till det förvrängda översättningsproblemet är "shuffling brus" som introduceras i varje inmatning som en denoising strategi. För att testa vår hypotes och experimentera genom att omskola UNMT modeller med en enkel omskolningsstrategi. Vi stoppar träningen av Denoising UNMT-modellen efter ett förutbestämt antal iterationer och återupptar träningen för de återstående iterationerna, vilket också är förutbestämt, med hjälp av originalmeningen som inmatning utan att lägga till något brus. Vår föreslagna lösning uppnår betydande prestandaförbättring av UNMT-modeller som tränar konventionellt. Vi visar dessa prestationsvinster på fyra språkpar och det vill säga. och engelsk-franska och engelsk-tyska och engelsk-spanska och hindi-punjabi. Vår kvalitativa och kvantitativa analys visar att omskolningsstrategin bidrar till bättre anpassning som observerats av uppmärksamhetens värmekarta och bättre frasöversättning och leder till statistiskt signifikant förbättring av BLEU-poäng.', 'so': "Qoraalkan waxaynu ku garanaynaa qalabka xiiso leh oo ka soo baxaya soo saaridda aan la ilaalinayn tarjumaadda neural machine (UNMT) nidaamka Undredrem1. Waxan looga jeedaa nooca qaladka sida dhibaatada turjumaadda. Waxaan fiirinaynaa in tusaalaha UNMT ee isticmaalaya codka burburka (sida marka lagu jiro riyooyinku) uu soo saari karo hadal saxda ah, laakiin aan u baaqan karin inay dhammaantood u sameyn karto hadal saxda ah. Sababta iyo erayada lagu turjumay ayaa looga jeedaa mid la wareegsan yahay islamarkaasna sababtooda ku yaraaday BLEU. Waxaynu u malaynaynaa in sababta dhibaatada turjumaadda ka dambeeya waa 'qaylada burburinaya' oo lagu soo bandhigay xaraf kasta oo lagu qoray qoraal daboolaya. si aan u imtixaano labawejiilkeena iyo waxaynu ku tijaabin jirrabnaa samooyinka UNMT si fudud u soo celinta qoraal cusub. Waxaynu joojinaynaa waxbarashada modelka UNMT ee diidinta ka dib marka aad horay u qoran karto tiro lamid ah kadib waxbarashada wax ka soo hadhay- kaas oo lambarkaasna horay u go'an yahay- isticmaalaya ereyga asalka ah oo aan cod ku dareyn. Our proposed solution achieves significant performance improvement UNMT models that train conventionally.  Waxaynu muujinnaa faa'iidadan oo ku saabsan afarta luqadood oo labo iyo viz. iyo Ingiriis-Faraansiis iyo Ingiriis-Jarmal iyo Ingiriis-Isbanish iyo Hindi-Punjabi. Analyadaada qiimeynta iyo qiyaastiisa waxay muuqataa in qorshaha dib u soo celinta ayaa caawinaya in la gaadho simbir wanaagsan sida loo arko dhejiga heating iyo turjumidda afka wanaagsan, waxaana sababtaa horumarinta kooxaha BLEU.", 'si': "මේ පත්තරේ අපි හොයාගන්නේ අසුපුරුද්ධ නිර්මාණ විද්\u200dයාපනය (UNMT) පද්ධතිය අසුරුද්ධ පද්ධතියේ ප්\u200dරතිකාරයක් වගේ  අපි මේ වැරදි වර්ගය ස්ක්\u200dරැම්බල් වාර්ථාව ප්\u200dරශ්නයක් විදියට ප්\u200dරශ්නය කරනවා. අපි බලාපොරොත්තු කරනවා UNMT මෝඩේල් වචනය සම්පූර්ණ ශබ්දය භාවිත කරන්න පුළුවන් වචනය නිර්මාණය කරන්න, ඒත් ඔවුන්ව එකට සම්පූර ප්\u200dරතිචාරයක් සහ වචනයක් විදිහට පරික්ෂා වෙන්න පුළුවන් වගේ වචනයක් ලැබෙනවා ඒ වගේම පරික්ෂා  අපි හිතන්නේ විශ්වාස කරපු වාර්තම ප්\u200dරශ්නයක් පිටිපස්සේ හේතුව 'ශුෆ්ලින් ශුද්ධ' කියලා හැම ඇතුළු වාක අපේ විශ්වාස පරීක්ෂා කරන්න සහ අපි පරීක්ෂා කරනවා UNMT මොඩේල්ස් එක්ක සාමාන්\u200dය ආරක්ෂාවක් සමඟ. අපි දනෝයිස් UNMT මොඩල් එකේ ප්\u200dරියෝජනය නවත්තන්න පුළුවන් තීර්ණාකරණ සංඛ්යාවක් පස්සේ ප්\u200dරයෝජනය නවත්තන්න සහ ඉතිරික්ෂණ ප්\u200dරයෝ අපේ ප්\u200dරශ්නයක් විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ වෙන්න අපි පෙන්වන්නම් මේ ප්\u200dරමාණයක් භාෂාවක් හතරක් සහ විස්තරයෙන් ප්\u200dරමාණය කරනවා. ඉංග්\u200dරිස්-ෆ්\u200dරෑන්ස්, ඉංග්\u200dරිස්-ජර්මන්, ඉංග්\u200dරිස්-ස්පැනිස් සහ හින්දි-පුන්ජ අපේ ක්\u200dරියාත්මක සහ ප්\u200dරමාණික විශ්ලේෂණය පෙන්වන්නේ ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණය පෙන්වන්න පුළුවන් විදිහට පරීක්ෂණය හොඳ", 'ta': "இந்த தாளில் மற்றும் நாம் ஒரு சுவாரசியமான பிழையை கண்டுபிடிக்கும் போது கண்டுபிடிக்கப்படாத நியூரால் இயந்திர மொழிபெயர்ப்ப நாம் இந்த பிழை வகை வரையறுக்கப்பட்ட மொழிபெயர்ப்பு பிரச்சனையை குறிக்கும். நாம் UNMT மாதிரிகளை பார்க்கிறோம் அது வார்த்தையின் சுழல் ஒலியை பயன்படுத்துகிறது (கனவு இல்லையென்றால்) சரியான வார்த்தைகளை உருவாக் மொழிபெயர்ப்பு வாக்கியத்தின் முடிவு மற்றும் வார்த்தைகள் பிலியு குறைந்தது பார்க்கிறது. We hypothesise that the reason behind scrambled translation problem is 'shuffling noise' which is introduced in every input sentence as a denoising strategy.  எளிய முடிவு திட்டத்தை மீண்டும் திரும்ப முடியும் பொருட்டு UNMT மாதிரிகளை மீண்டும் முயற்சிக்க. நாம் முன் தீர்மானிக்கப்பட்ட எண்ணிக்கைகளுக்கு பயிற்சியை நிறுத்தி மீண்டும் மீண்டும் மீண்டும் பயிற்சியை திரும்ப தொடங்குகிறோம் - எந்த ஒலிக் எங்கள் முன்னோக்கப்பட்ட தீர்வு வழக்கமாக பயிற்சி செய்யும் UNMT மாதிரிகள் முக்கியமான செயல்பாடு முன்ன நாங்கள் நான்கு மொழி ஜோடி மற்றும் விஸ் மீது இந்த செயல்பாட்டு பெறுவதை காண்பிக்கிறோம். ஆங்கிலம் பிரெஞ்சு மற்றும் ஆங்கிலம் ஜெர்மன் மற்றும் ஆங்கிலம்- ஸ்பானிஷ் மற்றும் ஹின்டி- புஞ்சாபி எங்கள் குறிப்பிட்ட மற்றும் அளவிற்கு ஆராய்ச்சி காண்பிக்கிறது திரும்ப முடியும் திட்டமிடுதல் திட்டத்திற்கு மேலும் சிறந்த ஒழுங்குபடுத்தலை உதவுக", 'ur': "اس کاغذ میں اور ہم نے Undreamt1 جیسے غیرقابل غیرقابل نائرل ماشین ترجمہ (UNMT) سیستموں کے نتائج میں ایک جالب طرح کی خطا پہچان لیا ہے. ہم اس خطا کے ٹائپ کو اسکرامبل ترجمہ مسئلہ کے طور پر منظور کرتے ہیں. ہم دیکھ رہے ہیں کہ UNMT نمونے جو کلمات کے ذریعہ ہنسی آواز استعمال کرتے ہیں (غیر خواب کی حالت میں) درست کلمات پیدا کر سکتے ہیں اور لیکن ان کو ایک دوسرے کے ساتھ ٹکڑے ٹکڑے میں شکست نہیں دیتے۔ تبدیل ہونے کے نتیجے اور کلمات کی وجہ سے BLEU کم ہونے کے نتیجے میں لگتے ہیں۔ ہم سمجھتے ہیں کہ پیچھے پھیرے ہوئے ترجمہ مسئلہ کا دلیل یہ ہے کہ 'شوفلنگ غږ' جو ہر ورودی جماعت میں ایک تفصیل استراتژی کے طور پر پیش کیا جاتا ہے. ہمارے فرضی کی آزمائش کے لئے اور ہم UNMT موڈلوں کو ایک ساده پیچھے پھیرنے کی استراتژی کے ساتھ آزمائش کریں۔ ہم نے UNMT موڈل کی تعلیم کو ایک پہلے تصمیم کی تعلیم کے بعد بند کر دیا اور باقی رہنے والوں کے لئے تدریس کی تدریس کو دوباره متوقف کر دیا - جس کی تعلیم پہلے تصمیم کیا گیا ہے - اصلی جماعت کو اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپن ہمارا پیشنهاد حل بڑی عملکرد کے ساتھ UNMT موڈلوں کی تحقیق پہنچتی ہے جو معمولی طرح ٹرین کرتی ہیں۔ ہم نے چار زبان جوڑوں اور viz پر ان کامیابی کو دکھایا ہے اور انگلیسی-فرانسوی اور انگلیسی-جرمنی اور انگلیسی-اسپانیایی اور ہندی-پنجابی۔ ہماری کیلوٹیٹی اور منطقی تحلیل دکھاتی ہے کہ پیچھے پھیرنے کا استراتژی بہتر تفریق پہنچانے کی مدد کرتا ہے جیسا توجه گرم مپ اور بہتر فریزل ترجمہ کی وجہ سے دیکھا گیا ہے اور BLEU اسکوروں میں آمار سے زیادہ اہم تفریق کی", 'uz': "Bu qogʻozda, biz Bekor qilmagan Neural Mashine tarjima (UNMT) tizimning natijasida qiziqarli turli xatolarni aniqlashimiz mumkin. Bu xato turini Scrambled tarjima muammosi deb ataymiz. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  Name Biz o'ylaymiz, tarjima tarjima muammolarning bakida sababni 'yomon' deb o'ylaymiz, har bir input so'zlarida qo'yish strategiya deb o'ylaydi. Biz hypoteyasizni tekshirish uchun, biz UNMT modellarini qayta olish uchun foydalanamiz. Biz bir avval tashkilotlar soni qo'shishdan keyin UNMT modelini o'rganishni toʻxtatishni toʻxtatimiz va keyingi tashkilotlar uchun ishlatishni qaytadan qaytadi- bu raqam oldin o'ylangan soʻzni kiritish deb o'ylaymiz. Mavzu qilingan suluhimiz UNMT modellarini o'zgartirishga muhim imkoniyatli bajaradi. Biz bu amalni to'rt tillar va viz sohasida ko'rsatumiz. ingliz tilida Fransuz va Inglizcha ingliz tili, ingliz tili ispancha va Hindi-Punjabi. Bizning kvalifik va qualitativ analytikimizni ko'rsatishimiz mumkin. Qaytarish strategiya taqlashni o'zgartirishga yordam beradi. Tovushlik va yaxshi lugʻri tarjima qilishni va BLEU scorlarida statistik muhim yaxshi yaxshi o'zgarishga yordam beradi.", 'vi': 'Trong tờ giấy này, chúng tôi xác định một dạng lỗi thú vị trong kết xuất của các hệ thống dịch lắp Thần kinh (UNMT) như bất động cơ. Chúng tôi coi dạng lỗi này như vấn đề Dịch rải rác. Chúng tôi lưu ý rằng mô hình UNMTV dùng tiếng xào bài (như trong trường hợp bất động) có thể tạo ra từ chính xác và không khâu chúng lại thành một đoạn văn. Kết quả và các từ trong câu đã dịch nhìn như bị xáo trộn và dẫn đến sự giảm nguyên tắc. Chúng tôi giả định rằng lý do đằng sau vấn đề dịch chuyển nhầm là "xào bài ồn" được đưa vào mỗi câu đầu tư như một chiến lược mô tả. Để thử nghiệm giả thuyết của chúng ta và thử nghiệm bằng việc tái tạo các mô hình UNMTV với một chiến lược đơn giản. Chúng ta dừng việc huấn luyện mô hình Denoising UNMTV sau một số lần lặp lại đã quyết định trước và tiếp tục đào tạo cho các phiên bản còn lại, số lượng này cũng được quyết định sử dụng từ nguyên bản như là đồ nhập mà không cần thêm nhiễu. Cách giải quyết đề nghị đạt đến hiệu suất tiến bộ đáng kể trong mô- đun con sóng. Chúng tôi chứng minh khả năng đạt được với bốn cặp ngôn ngữ và viz. và Anh-French, Anh-German, English-Spanish và Hindi-Punjabi. Phân tích về chất lượng và chất lượng của chúng ta cho thấy chiến lược tái tạo giúp cải tạo sự thích hợp tốt hơn theo cách nhìn nhận của bản đồ nóng tập trung và cách dịch thành ngữ tốt hơn và dẫn đến một tiến bộ số đạt được.', 'bg': 'В тази статия идентифицираме интересен вид грешка в изхода на системи за невронен машинен превод (UNMT) като Undream1. Ние се отнасяме към този тип грешка като проблем с разбъркан превод. Наблюдаваме, че моделите на ЮНМТ, които използват шум от разбъркване на думи (както в случая на Несънувано), могат да генерират правилни думи, но не успяват да ги зашият заедно, за да образуват фрази. В резултат на това думите на преведеното изречение изглеждат объркани и водят до намаляване на БЛЮ. Ние предполагаме, че причината за проблема с бъркането на превода е "шум от разбъркване", който се въвежда във всяко въведено изречение като стратегия за обозначаване. За да тестваме хипотезата си, експериментираме чрез преквалификация на моделите с проста стратегия за преквалификация. Спираме обучението на модела на Деноизинг след предварително определен брой итерации и възобновяваме обучението за останалите итерации - чийто номер също е предварително решен - като използваме оригиналното изречение като вход, без да добавяме никакъв шум. Предложеното ни решение постига значително подобрение на производителността модели, които тренират конвенционално. Ние демонстрираме тези постижения на четири езикови двойки и визи. и английски-френски и английски-немски и английски-испански и хинди-пенджаби. Нашият качествен и количествен анализ показва, че стратегията за преквалификация спомага за постигането на по-добро съответствие, наблюдавано от топлинната карта на вниманието и по-добър превод на фрази и води до статистически значимо подобрение на оценките.', 'nl': "In dit artikel en we identificeren een interessant soort fout in de output van Unsupervised Neural Machine Translation (UNMT) systemen zoals Undreamt1. We verwijzen naar dit fouttype als Scrambled Translation probleem. We zien dat UNMT modellen die gebruik maken van woord shuffle ruis (zoals in het geval van Undreamt) correcte woorden kunnen genereren en ze niet aan elkaar kunnen hechten om zinnen te vormen. Hierdoor zien woorden van de vertaalde zin er verward uit en resulteren in verminderde BLEU. We veronderstellen dat de reden achter een versleuteld vertaalprobleem 'shuffling noise' is, dat in elke invoerzin wordt geïntroduceerd als een ontkennende strategie. Om onze hypothese te testen en experimenteren we met het herscholen van UNMT modellen met een eenvoudige herscholingsstrategie. We stoppen de training van het Denoising UNMT model na een vooraf bepaald aantal iteraties en hervatten de training voor de resterende iteraties – welk nummer ook vooraf bepaald is – met behulp van de oorspronkelijke zin als input zonder enige ruis toe te voegen. Onze voorgestelde oplossing bereikt aanzienlijke prestatieverbetering UNMT-modellen die conventioneel trainen. We demonstreren deze prestatiewinst op vier taalparen en viz. en Engels-Frans en Engels-Duits en Engels-Spaans en Hindi-Punjabi. Onze kwalitatieve en kwantitatieve analyse toont aan dat de herscholingsstrategie helpt bij het bereiken van een betere afstemming zoals waargenomen door aandacht heatmap en betere frasumlatie en leidt tot statistisch significante verbetering van BLEU scores.", 'hr': "U ovom papiru i identificiramo zanimljivu vrstu greške u izlazu neodređenih neuroloških sustava prevoda strojeva (UNMT) poput Undreamt1. Smatramo ovaj tip greške kao problem sa prevodom. Primijetimo da UNMT modeli koji koriste zvuk šupljanja riječi (kao u slučaju Nesnova) mogu stvoriti prave riječi i ne mogu ih zajedno šivati kako bi formirali fraze. Kao rezultat i riječi prevedene rečenice izgledaju okrenuti i rezultat smanjenog BLEU-a. Pretpostavljamo da je razlog iza prevodnog problem a 'šupljanje buke' koji se uvodi u svaku uložnu rečenicu kao strategiju za indiciranje. Da bismo testirali našu hipotezu i eksperimentirali povratak UNMT modela jednostavnom strategijom povratka. Mi zaustavljamo obuku UNMT model a Denoising nakon predodlučnog broja iteracija i nastavimo obuku za ostale iteracije - koja je broj također predodlučena - koristeći originalnu rečenicu kao ulaz bez dodavanja buke. Naše predloženo rješenje postiže značajno poboljšanje učinkovitosti UNMT modela koji konvencionalno vladaju. Pokazujemo da dobijamo ove predstave na četiri jezičke parove i viz. i engleski francuski i engleski-njemački i engleski-španjolski i hindi-punjabi. Naša kvalitativna i kvantitativna analiza pokazuje da strategija povlačenja pomaže ostvariti bolju usklađenost kako je promatrana pažnjom toplinom mapom i boljom prevodom frazala i dovela do statistički značajnog poboljšanja rezultata BLEU-a.", 'da': 'I denne artikel identificerer vi en interessant form for fejl i output af Unsupervised Neural Machine Translation (UNMT) systemer som Undreamt1. Vi henviser til denne fejltype som Scrambled Translation problem. Vi bemærker, at UNMT modeller, der bruger ordblandingsstøj (som i tilfælde af Undreamt) kan generere korrekte ord, men undlader at sy dem sammen til at danne sætninger. Som et resultat og ord i den oversatte sætning ser sammenblandet ud og resulterer i nedsat BLEU. Vi antager, at årsagen til problemer med oversættelse er "blandingsstøj", som indføres i hver input sætning som en denoising strategi. For at teste vores hypotese og eksperimentere ved at omskole UNMT modeller med en simpel omskolingsstrategi. Vi stopper træningen af Denoising UNMT modellen efter et forudbestemt antal iterationer og genoptager træningen for de resterende iterationer - hvilket tal også er forudbestemt - ved hjælp af original sætning som input uden at tilføje nogen støj. Vores foreslåede løsning opnår betydelige ydelsesforbedringer UNMT modeller, der træner konventionelt. Vi demonstrerer disse præstationsgevinster på fire sprogpar og nemlig. og engelsk-fransk og engelsk-tysk og engelsk-spansk og hindi-punjabi. Vores kvalitative og kvantitative analyse viser, at omskolingsstrategien hjælper med at opnå bedre tilpasning som observeret af opmærksomheds varmekort og bedre frasal oversættelse og fører til statistisk signifikant forbedring i BLEU scores.', 'id': "Dalam kertas ini dan kami mengidentifikasi semacam kesalahan menarik dalam keluaran sistem Translation Machine Neural Unsupervised (UNMT) seperti Undreamt1. Kami merujuk ke tipe kesalahan ini sebagai masalah terjemahan. Kami memperhatikan bahwa model UNMT yang menggunakan suara penggabungan kata (seperti dalam kasus Undreamt) dapat menghasilkan kata-kata yang benar dan tetapi gagal menjahit mereka bersama-sama untuk membentuk frasa. Sebagai hasil dan kata-kata dari kalimat terjemahan terlihat kacau dan menghasilkan menurun BLEU. We hypothesise that the reason behind scrambled translation problem is 'shuffling noise' which is introduced in every input sentence as a denoising strategy.  Untuk menguji hipotesis kita dan kita eksperimen dengan melatih ulang model UNMT dengan strategi pelatihan ulang sederhana. Kami menghentikan pelatihan model UNMT Denoising setelah jumlah iterasi yang telah ditentukan dan memulai pelatihan untuk iterasi yang tersisa- yang jumlah juga telah ditentukan- menggunakan kalimat asli sebagai input tanpa menambahkan suara apapun. Solusi yang diusulkan kita mencapai peningkatan prestasi yang signifikan model UNMT yang berlatih konvensional. Kami menunjukkan pertunjukan ini pada empat pasangan bahasa dan viz. dan Inggris-Perancis, Inggris-Jerman, Inggris-Spanyol dan Hindi-Punjabi. Analisis kualitatif dan kuantitatif kami menunjukkan bahwa strategi pelatihan ulang membantu mencapai penyesuaian yang lebih baik seperti yang diperhatikan oleh peta panas perhatian dan terjemahan frasa yang lebih baik dan menyebabkan peningkatan statistik signifikan pada skor BLEU.", 'de': 'In diesem Beitrag identifizieren wir eine interessante Art von Fehlern in der Ausgabe von Unsupervised Neural Machine Translation (UNMT)-Systemen wie Undreamt1. Wir beziehen uns auf diesen Fehlertyp als Problem der Scrambled Translation. Wir beobachten, dass UNMT-Modelle, die Wort-Shuffle-Rauschen verwenden (wie im Fall von Undreamt), korrekte Wörter generieren können, diese aber nicht zu Phrasen zusammenfügen. Als Ergebnis und Wörter des übersetzten Satzes sehen durcheinander aus und führen zu einer verringerten BLEU. Wir gehen davon aus, dass der Grund für das Problem der verschlüsselten Übersetzung "Shuffling Noise" ist, das in jedem Eingabesatz als denoisierende Strategie eingeführt wird. Um unsere Hypothese zu testen, experimentieren wir mit der Umschulung von UNMT-Modellen mit einer einfachen Umschulungsstrategie. Wir stoppen das Training des Denoising UNMT-Modells nach einer vorgegebenen Anzahl von Iterationen und setzen das Training für die verbleibenden Iterationen – welche Zahl ebenfalls im Voraus festgelegt ist – fort, indem wir den Originalsatz als Eingabe verwenden, ohne irgendwelche Geräusche hinzuzufügen. Unsere vorgeschlagene Lösung erreicht eine signifikante Leistungssteigerung UNMT-Modelle, die konventionell trainiert werden. Diese Leistungszuwächse zeigen wir an vier Sprachpaaren und zwar. und Englisch-Französisch und Englisch-Deutsch und Englisch-Spanisch und Hindi-Punjabi. Unsere qualitative und quantitative Analyse zeigt, dass die Umschulungsstrategie dazu beiträgt, eine bessere Ausrichtung zu erreichen, wie durch Aufmerksamkeits-Heatmap und eine bessere Phrasal-Übersetzung beobachtet und zu statistisch signifikanten Verbesserungen der BLEU-Scores führt.', 'ko': "본고에서 우리는 무감독신경기계번역(UNMT)시스템(예를 들어 Undreamt1)의 출력에서 재미있는 오류를 발견했다.우리는 이런 잘못된 유형을 혼란 번역 문제라고 부른다.우리는 UNMT 모델이 단어 클렌징 소음(예를 들어 Undreamt)을 사용하면 정확한 단어를 생성할 수 있으나 그것들을 한데 봉합하여 짧은 단어를 만들 수 없다는 것을 관찰했다.이 때문에 번역 문장의 단어가 뒤죽박죽으로 보이면서 BLEU가 줄어들었다.우리는 번역 혼란 문제의 배후 원인이'혼성 소음'이라고 가정한다. 이것은 소음 제거 전략으로 모든 입력 문장에 도입된다.우리의 가설을 검증하기 위해 우리는 간단한 재교육 전략을 이용하여 UNMT 모델을 재교육한다.미리 정해진 교체 횟수 후에 우리는 소음 제거 UNMT 모델의 훈련을 멈추고 원시 문장을 입력으로 사용하여 어떠한 소음도 첨가하지 않은 상황에서 나머지 교체 훈련을 회복한다(이 횟수도 미리 정해진 것이다).우리가 제시한 해결 방안은 일반적인 훈련의 UNMT 모델에서 현저한 성능 개선을 실현했다.우리는 네 가지 언어 대조에서 이러한 성능 향상, 즉영어 프랑스어, 영어 독일어, 영어 스페인어와 인디언 방차포어.우리의 정성과 정량 분석에 의하면 재교육 전략은 더 좋은 일치성을 실현하는 데 도움이 된다. 열도와 더 좋은 짧은 단어 번역에 주의한 바와 같이 BLEU 점수가 통계학적으로 현저히 높아졌다.", 'fa': 'در این کاغذ و ما یک نوع خطای جالبی در نتیجه سیستم\u200cهای ترجمه\u200cی ماشین عصبی غیرقابل تحویل (UNMT) مانند Undreamt1 شناسایی می\u200cکنیم. ما به این نوع خطا به عنوان مشکل ترجمه اسکرم ارائه می\u200cدهیم. ما مشاهده می\u200cکنیم که مدل\u200cهای UNMT که استفاده از صوت\u200cهای غیرخواب کلمه\u200cها می\u200cتوانند کلمه\u200cهای درست را تولید کنند و ولی شکست نمی\u200cدهند که آنها را با هم به صورت عبارت بسازند. به نتیجه و کلمات جمله ترجمه به نظر می رسد و به نتیجه BLEU کاهش می رسد. ما فرض می\u200cکنیم که دلیل پشت مشکل ترجمه\u200cهای ترجمه\u200cای است که در هر جمله\u200cی ورودی به عنوان استراتژی\u200cهای جدایی معرفی می\u200cشود. برای آزمایش فرضیه\u200cهای ما و ما با بازگشت مدل\u200cهای UNMT با استراتژی ساده بازگشت آزمایش می\u200cکنیم. ما آموزش مدل UNMT دانوئیس را بعد از تعداد تکرار پیش از تصمیم گرفتن متوقف می\u200cکنیم و آموزش برای تکرار باقی مانده را دوباره ادامه می\u200cدهیم- که تعداد قبل از تصمیم گرفتن است- از جمله اصلی به عنوان ورودی بدون اضافه صدا استفاده می\u200cکند. راه حل پیشنهاد ما به پیشرفت مدل\u200cهای UNMT که به طور معمولی آموزش می\u200cدهند بهتر عملکرد بزرگی می\u200cرسد. ما این عملکرد را بر چهار جفت زبان و viz نشان می دهیم. و انگلیسی-فرانسوی و انگلیسی-آلمانی و انگلیسی-اسپانیایی و هندی-پنجابی. تحلیل کیفیت و تعداد مقداری ما نشان می دهد که استراتژی بازگشتی کمک می کند که با توجه به نقشه گرم توجه و ترجمه\u200cهای عبارت بهتر و به بهترین توجه به نقشه\u200cهای BLEU به بهترین توجه رساند.', 'tr': 'Bu kagyzda we biz Undreamt1 ýaly garaşylmadyk Neural Makin Çeviri (UNMT) sistemlerinde gyzykly bir ýaly hata tanyýarys. Biz bu hata hilini döredik terjime meselesi ýaly çaklaýarys. UNMT nusgalary üýtgetmek üçin (arzuw edilmedik ýaly) sözleri dogry döredip bilmeýän we olary bir arada sözler biçirmek üçin üýtgedip bilenokdygyny gözleýäris. Çaltylyk sözleriniň netijesi we sözleriniň üýtgedişi we netijesi düşürildi. Iňleýän terjime meselesiniň arkasyndaky sebäbi "gürrüňlemek" diýip pikir edip otyrýarys. Bu her girdi sözlemde bir strategiýa bilen tanyşdyrylýar. Öň hipotezymyzy barlamak üçin we UNMT nusgalaryny ýene-de ýeňil gaýd etmek üçin synanyşýarys. Biz UNMT nusgasyny öňünden karar berýän sanyndan soň Daniýasyny taýýarlap, gaýd edilen tekrarlaryň eğitimi taýýarlap başladyk. Bu sany hem öňünden karar berýän. Öňki sözlemi hiç hili gürrüňsiz gaýd etmäge ulandyk. Biziň teklip eden çözgümiz UNMT nusgalaryny düzgün şekilde otlaýan çözgütlerniň üstünliklerini ýetip bilýär. Biz bu zadyň dört dil çift we üýtgedendigini görkeýäris we iňlisçe-fransuzça we iňlisçe-Almança we iňlisçe-ispanyça we hindi-punjabi. Bizim hökmümiz we kvantitytyýa çözümleşmelerimiz, yzarlamak stratejiýasynyň üns kartlary tarapyndan gözleýän şekilde gowy çözümlenmesine kömek edip, BLEU notlarynda statistik bilen önemli gelişmelere yol açar.', 'sw': "Katika karatasi hii na tunatambua aina ya makosa ya kusisimua katika matokeo ya utafsiri wa Mashine ya Kifaransa (UNMT) kama vile Undream1. Tunaandikia aina hii ya makosa kama tatizo la Tafsiri la Tafsiri. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  Matokeo yake na maneno ya hukumu iliyotafsiriwa yanaonekana kuchanganyikiwa na kusababisha kupungua BLEU. Tunafikiri kuwa sababu nyuma ya tatizo la kutafsiri lililotolewa ni 'kupiga kelele ya kelele' ambayo inaonyesha katika kila hukumu ya inzani kama mkakati wa kupiga kura. Ili kujaribu nadharia yetu na tunajaribu kwa kurudisha mifano ya UNMT kwa mkakati mzuri wa upya. Tunaacha mafunzo ya modeli ya UNMT ya Kukataa Kukataa kufuatia idadi ya vitu vya awali vilivyoamuliwa na kurudisha mafunzo ya vitu vilivyobaki – namba ambavyo pia ni ya awali – kwa kutumia hukumu ya awali kama input bila kuongeza sauti yoyote. suluhisho letu lililopendekezwa linafanikiwa kuongezeka kwa uboreshaji wa utendaji wa UNMT unaofanya mafunzo kwa kawaida. Tunaonyesha mafanikio haya yanayotokana na wanaume wanne wa lugha na viz. na Kiingereza na Kiingereza na Kiingereza na Kiingereza na Kihispania na Kihindi-Punjabi. Uchambuzi wetu wa kipimo na kiasi kinaonyesha kuwa mkakati wa kurudisha upya unasaidia kupata nafasi bora kama ilivyoonekana kwa kutangazwa kwa utafsiri wa hali ya hewa na tafsiri bora na kusababisha kuboreshwa kwa takwimu kubwa katika vipindi vya BLEU.", 'af': "In hierdie papier en ons identifiseer 'n interessante soort fout in die uitvoer van Ononderwerpende Neurale Masjien Vertaling (UNMT) stelsels soos Undreamt1. Ons verwys na hierdie fout tipe as Skrambleerde Vertaling probleem. Ons bewaar dat UNMT-modelles wat woord shuffle noise gebruik (soos in geval van Undreamt) korrekte woorde kan genereer en maar misluk om hulle saam te stel om frase te formeer. As 'n resultaat en woorde van die vertaalde seting lyk gemaak en resultaat in verklein BLES. Ons hipotesis dat die rede agter geskrammel vertaling probleem is 'shuffling noise' wat in elke invoer seting as 'n belangrike strategie ingestel word. Om ons hipotees te testeer en ons te eksperimenteer deur UNMT-modele te herhaal met 'n eenvoudige herhaal strategie. Ons ophou die onderwerp van die Denoising UNMT model na 'n voor-besluit aantal iterasies en hervat die onderwerp vir die oorblyfsel iterasies - wat getal is ook voor-besluit - gebruik oorspronklike seting as invoer sonder om enige geluid te voeg. Ons voorgestelde oplossing bereik betekende prestasie verbetering van UNMT-modele wat konvensionale trein. Ons wys hierdie prestasie verkry op vier taal paar en viz. en Engels-Frans en Engels-Duits en Engels-Spaanse en Hindi-Punjabi. Ons kvalitatiewe en kvantitatiewe analisie wys dat die terugteling strategie help beter alignering te bereik soos aandag van die warmkaart en beter frasaloorsetting aangesien is en tot statistiese beter verbetering in BLEU-punte.", 'sq': "Në këtë letër dhe identifikojmë një lloj gabimi interesant në daljen e sistemeve të Translacionit të Makinës Neurale të Pambikqyrur (UNMT) si Undreamt1. Ne e referojmë këtë lloj gabimi si problem të përkthimit të shkruajtur. Ne vëzhgojmë se modelet e UNMT-së që përdorin zhurmën e fjalëve të përziera (si në rastin e Undreamt) mund të gjenerojnë fjalë të sakta dhe por nuk mund t'i bashkojnë për të formuar fraza. Si rezultat dhe fjalët e fjalës së përkthyer duken të ngatërruara dhe rezultojnë në rënie të BLEU. Ne hipotezojmë se arsyeja pas problemeve të përkthimit të ngatërruar është 'zhurma e ngatërrimit' që futet në çdo fjalim të hyrjes si një strategji mohuese. To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy.  Ne ndalojmë trajnimin e modelit UNMT që mohon pas një numri të përsëritjeve të paravendosur dhe rinisim trajnimin për përsëritjet e mbetura- cila numër është gjithashtu e paravendosur- duke përdorur fjalën origjinale si hyrje pa shtuar zhurmë. Zgjidhja jonë e propozuar arrin përmirësim të rëndësishëm të performancës modele UNMT që trajnojnë tradicionalisht. Ne demonstrojmë këto fitime në katër çifte gjuhësh dhe viz. dhe Anglisht-Francez, Anglisht-Gjerman, Anglisht-Spanjoll dhe Hindi-Punjabi. Analiza jonë kualitative dhe kuantitative tregon se strategjia e rindërtimit ndihmon në arritjen e përshtatjes më të mirë siç është vëzhguar nga harta e vëmendjes dhe përkthimi më i mirë i frazëve dhe që çon në përmirësim statistikisht të rëndësishëm në rezultatet e BLEU.", 'am': 'በዚህ ካላት እና በአጠቃሚ ስህተት እና እንደማይታወቅ የኔural Machine ትርጉም (UNMT) ስርዓቶች (UNMT) ሲሞክር እናውቃለን፡፡ ይህን የስህተት ዓይነት እንደ Scrambled ትርጉም ጉዳይ እናስባለን፡፡ የUNMT ምሳሌዎች ቃላትን የሸፋፊ ድምፅ የሚጠይቁ (እንደገና ሕልሞች) እውነተኛ ቃላትን እንዲወስድ እና ቃላትን በመጠቀም አይችሉም፡፡ በተርጉም የንግግር ቃላት እና ቃላት በጭብጥ እና በBLEU የሚያጎድል ነው፡፡ እናስታውቃለን፡፡ በተለየ ትርጓሜ መከራ በኋላ የተደረገው ምክንያት “የድምፅ ድምፅ” ነው፡፡ To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy.  ከቀድሞ በተወሰነ ቁጥር በኋላ የዩንቨርስቲ ሞዴል ማስተማርን እናቆማለን እና የቀረውን ድርጅቶች ማስተማርን እናደጋግማለን - ቁጥር ደግሞ አስቀድሞ የተወሰነ - እንደምትጠቀም አዲስ ድምፅ ያለ ድምፅ ሳይጨምር ጥያቄን እናስቀምጣለን፡፡ በተዘጋጀው መፍትረታችን የዩንኤምቴን አካባቢ አካባቢ ማድረግ አግኝቷል፡፡ ይህንን የስርዓት ግንኙነት በአራት ቋንቋ ሁለት እና ቪዛ እናሳያቸዋለን፡፡ እንግሊዘኛ-ፈረንሳይ እና እንግሊዝኛ-ጀርመን እና እንግሊዘኛ-ስፓኒሽ እና ኪንዲ-ፓንጃብ በተግባራዊ እና በሚያስተካክል ትርጓሜያችን የሚያሳየው የኢንተርኔት ትክክል እና የተሻለ የንግግር ትርጓሜ እና በBLEU scores ውስጥ ትክክል ትክክል የሚያደርገውን ትክክል ማድረግ ይረዳል፡፡', 'hy': 'Այս թղթի մեջ մենք հայտնաբերում ենք մի հետաքրքիր սխալ անվերահսկված նյարդային մեքենայի թարգմանման (UNMT) համակարգերի արդյունքում, ինչպիսին է "Անթարգմանման" 1: Մենք անվանում ենք սխալ տիպի որպես Scrabbled Translate խնդիր: Մենք նկատում ենք, որ UNMT-ի մոդելները, որոնք օգտագործում են բառերի խառնման աղմուկ (ինչպես անձայնագրված դեպքում) կարող են ճիշտ բառեր ստեղծել, բայց չեն կարողանում միացնել դրանք, որպեսզի ձևավորեն արտահայտություններ: Արդյունքում, թարգմանված նախադասության բառերը խառնված են և հանգեցնում են նվազեցող բլեուզ: Մենք ենթադրում ենք, որ խառնված թարգմանման խնդիրների պատճառը խառնված աղմուկ է, որը ներկայացվում է յուրաքանչյուր ներկայացված նախադասության մեջ որպես մերժող ռազմավարություն: Մեր հիպոթեզը փորձելու համար մենք փորձում ենք UNMT մոդելների վերադասավորման միջոցով պարզ վերադասավորման ռազմավարության միջոցով: Մենք դադարեցնում ենք UNMT-ի փորձարկումը նախընտրված բազմաթիվ կրկնօրինակումների հետո և վերադառնում ենք կրկնօրինակումը մնացած կրկնօրինակումների համար, որը նույնպես նախընտրված է, օգտագործելով որպես ներմուծք առանց ավելացնելու աղմուկ: Մեր առաջարկած լուծումը նշանակալի բարելավում է UNMT մոդելները, որոնք սովորաբար վարժվում են: Մենք ցույց ենք տալիս այս արտադրողականությունը չորս լեզվի զույգերի և այլն: և անգլերեն-ֆրանսերեն, անգլերեն-գերմաներեն, անգլերեն-իսպաներեն և հինդի-պունջաբի: Մեր որակային և քանակական վերլուծությունը ցույց է տալիս, որ վերադասավանդման ռազմավարությունը օգնում է ավելի լավ հարմարեցվել, ինչպես հետևում է ուշադրության տաքարտեզի և ավելի լավ արտահայտությունների թարգմանման վրա և հանգեցնում է վիճակագրական նշանակալի', 'ca': "En aquest article i identifiquem un error interessant en la producció de sistemes de traducció de màquines neurals no supervisades (UNMT) com Undreamt1. Nosaltres referim a aquest tipus d'error com a problema de traducció rotunda. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases.  Com a resultat i les paraules de la frase traduïda semblen confuses i resulten en una disminució de la BLEU. Suposem que la raó darrere del problem a de traducció desconcertat és el 'soroll desconcertant' que es introdueix en cada frase d'entrada com una estratègia de negació. Per provar la nostra hipòtesi i experimentarem per reenvolupar els models de l'UNMT amb una estratègia simple de reenvolupament. Detenem l'entrenament del model de Denoising UNMT després d'un nombre predecis de repeticions i continuem l'entrenament per a les repeticions restants, que nombre també és predecis, utilitzant la frase original com entrada sense afegir soroll. La nostra solució proposta aconsegueix millorar significativament els models de la UNMT que entrenen convencionalment. Demonstrem aquests guanys en quatre parells de llenguatges i viz. i anglès-francès, anglès-alemany, anglès-espanyol i Hindi-Punjabi. La nostra anàlisi qualitativa i quantitativa mostra que l'estratègia de reestructuració ajuda a aconseguir una millor allinjament tal i com es observa en el mapa de calor de l'atenció i una millor traducció de frases i porta a una millora estadísticament significativa en les puntuacions BLEU.", 'az': 'Bu kağızda və biz Undreamt1 kimi müəyyən edilməmiş Neural Machine Translation (UNMT) sistemlərin çıxışında ilginç bir xətasını tanıyırıq. Biz bu xəta növünü Scrambled Translation problemi kimi göstəririk. Biz gözləyirik ki, UNMT modelləri sözləri sıxıştırmaq səsi ilə istifadə edirlər (heç bir rüyada gəlməz kimi) düzgün sözləri yarada bilər və onları birlikdə sözləri yaratmaq üçün sıxışdırırlar. Tərcümləndirilən cümlənin sonuçları və sözlərin dəyişməsi olaraq BLEU azaldı. Biz hər giriş sözlərində müəyyən bir strateji olaraq daxil olunan çəkişmə problem in in arxasındakı səbəbi "çəkişmə səsi" idik. Bizim hipotezimizi sınamaq üçün və UNMT modellərini basit bir geri qaytarma stratejisi ilə təcrübə edirik. Biz Denoising UNMT modelinin təhsil edilməsini əvvəlcə karar verilmiş bir neçə təhsil etdik və geri qalan təhsil üçün təhsil edilməsini yenidən başladıq - bu sayı da əvvəlcə karar verilmədi - əsl cümləni heç bir səs əlavə etmədən istifadə etdik. Bizim təklif etdiyimiz çətinliklərimiz UNMT modellərini düzgün tələb edir. Biz bu performansı dörd dil çift və viz ilə göstəririk. İngilizce-Fransız, İngilizce-Almanca, İngilizce-İspanyolca və Hindi-Punjabi. Bizim qabiliyyətimiz və kvantitatlı analizimiz göstərir ki, geri alma stratejisi, gözləmə qızması kartı ilə daha yaxşı tərəfləndirilməyə kömək edər, daha yaxşı phrasal tərəfləndirilməsinə və BLEU nöqtələrində statistik olaraq möhkəm tərəfləndirilməsinə kömə', 'bs': 'U ovom papiru i identificiramo zanimljivu vrstu greške u izlazu neodređenih nervnih sustava prevoda (UNMT) poput Undreamt1. Smatramo ovaj tip greške kao problem sa prevodom. Primećujemo da UNMT modeli koji koriste zvuk šupljanja riječi (kao u slučaju Nesnova) mogu stvoriti prave riječi i ne mogu ih zajedno šivati kako bi formirali fraze. Kao rezultat i riječi prevedene rečenice izgledaju okrenuti i rezultat smanjenog BLEU-a. Pretpostavljamo da je razlog iza problem a sa prevođenjem "bučna šuljanja", koji se uvede u svaku uložnu rečenicu kao strategija za indiciranje. Da bismo testirali našu hipotezu i eksperimentirali povratak UNMT modela jednostavnom strategijom povratka. Mi zaustavljamo obuku UNMT model a Denoising nakon predodlučnog broja iteracija i nastavimo obuku za ostale iteracije - koja je broj takođe predodlučena - koristeći originalnu rečenicu kao ulaz bez dodanja buke. Naše predloženo rješenje postiže značajno poboljšanje učinkovitosti UNMT modela koji konvencionalno voze. Pokazujemo da dobijamo ove predstave na četiri jezičke parove i viz. i engleski francuski, engleski-nemački, engleski-španjolski i hindi-punjabi. Naša kvalitativna i kvantitativna analiza pokazuje da strategija povlačenja pomaže ostvariti bolju usklađenost kao što je promatrana pažnjom građevinom i boljom prevodom frazala i dovelo do statistički značajnog poboljšanja rezultata BLEU-a.', 'cs': 'V tomto článku identifikujeme zajímavý druh chyby ve výstupu systémů UNMT (Undreamt1). Tento typ chyby označujeme jako problém se šroubovaným překladem. Zjišťujeme, že UNMT modely, které používají šum smíchání slov (jako v případě Undreamt), mohou generovat správná slova, ale nedokážou je spojit do frází. V důsledku toho i slova přeložené věty vypadají zamíchaná a vedou k snížení BLEU. Předpokládáme hypotézu, že důvodem kódovaného překladu je "míchání šumu", který je zaveden v každé vstupní větě jako denoisační strategie. Chceme-li otestovat naši hypotézu a experimentovat rekvalifikací UNMT modelů s jednoduchou strategií rekvalifikace. Zastavíme trénink modelu Denoising UNMT po předem určeném počtu iterací a pokračujeme v tréninku zbývajících iterací – které číslo je také předem rozhodnuto- pomocí původní věty jako vstupu bez přidání jakéhokoliv šumu. Naše navržené řešení dosahuje výrazného zlepšení výkonu modelů UNMT, které trénují konvenčně. Tento výkon demonstrujeme na čtyřech jazykových párech a to na čtyřech jazykových párech. a anglicky-francouzština a anglicky-němčina a anglicky-španělština a hindi-paňdžábština. Naše kvalitativní a kvantitativní analýza ukazuje, že strategie rekvalifikace pomáhá dosáhnout lepší sladění, jak je pozorováno pozorností heatmap a lepším frazálním překladem a vede ke statisticky významnému zlepšení skóre BLEU.', 'bn': "এই কাগজটিতে আমরা আনন্দিত নিউরাল মেশিন অনুবাদ (ইউএনএমটি) সিস্টেমের আউটপুটের মধ্যে একটি মজার ধরনের ত্রুটি চিহ্নিত করি। আমরা এই সমস্যার ধরন স্ক্রাম্প্লেড অনুবাদের সমস্যা হিসেবে উল্লেখ করি। আমরা দেখতে পাচ্ছি যে ইউনিএমটি মডেল যেখানে শব্দ শ্যাফিল শব্দ ব্যবহার করে (যেমন আদ্দীনের ক্ষেত্রে) সঠিক শব্দ তৈরি করতে পারে এবং কিন্ত অনুবাদের বাক্যের ফলাফল এবং শব্দ দেখা যাচ্ছে বিলিউ কমে যাচ্ছে। আমরা বিশ্বাস করি যে অনুবাদের পেছনে কারণ হচ্ছে 'আঘাত হামলা' যা প্রত্যেক ইনপুটের কারাদণ্ডের কৌশল হিসেবে চিহ্নিত করা হয়। আমাদের হাইপিথিসিস পরীক্ষা করার জন্য এবং আমরা ইউনিএমটি মডেল পুনরায় পরীক্ষা করি একটি সাধারণ পুনরুদ্ধার কৌশল দিয়ে। পূর্ব সিদ্ধান্ত নির্ধারিত সংখ্যার পর আমরা ডেনোজিং ইউনিএমটি মডেলের প্রশিক্ষণ বন্ধ করি এবং বাকি বিষয়বস্তুর জন্য প্রশিক্ষণ পুনরায় প্রশিক্ষণ প্রদান করি- যা সি আমাদের প্রস্তাবিত সমাধানে ইউনিএমটি মডেলের গুরুত্বপূর্ণ উন্নতি পেতে পারে, যা সাধারণত ট্রেনে প্রশিক্ আমরা চার ভাষা জোড়া এবং ভিজের উপর এই প্রদর্শনীর অর্জন প্রদর্শন করি। এবং ইংরেজী ফরাসি এবং ইংরেজী জার্মান এবং ইংরেজী স্প্যানিশ এবং হিন্দি পাঞ্জাবি। Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.", 'et': 'Käesolevas töös tuvastame huvitava vea järelevalveta neuraalse masintõlke (UNMT) süsteemide (Undreamt1) väljundis. Me viitame sellele veatüübile kui segatud tõlke probleemile. Me täheldame, et UNMT mudelid, mis kasutavad sõna segamise müra (nagu näiteks Undreamt puhul), võivad genereerida õigeid sõnu, kuid ei õmble neid kokku fraaside moodustamiseks. Selle tulemusena näevad tõlgitud lause sõnad välja segatud ja tulemusena väheneb BLEU. Hüpoteesime, et segatud tõlkeprobleemi põhjuseks on segatud müra, mida kasutatakse igas sisendlauses märgistamisstrateegiana. Et testida oma hüpoteesi ja me katsetame UNMT mudeleid lihtsa ümberõppestrateegia abil. Peatame Denoising UNMT mudeli treeningu pärast eelnevalt otsustatud arvu iteratsioone ja jätkame treeningut ülejäänud iteratsioonide jaoks, mille arv on samuti eelnevalt otsustatud, kasutades sisendina algset lauset ilma müra lisamata. Meie pakutud lahendus saavutab olulise jõudluse parandamise UNMT mudelid, mis treenivad tavapäraselt. Näitame neid tulemuslikkuse kasvu neljal keelepaaril ja viz. ja inglise-prantsuse ja inglise-saksa ja inglise-hispaania ja hindi-punjabi. Meie kvalitatiivne ja kvantitatiivne analüüs näitab, et ümberõppestrateegia aitab saavutada parema kooskõla, mida täheldatakse tähelepanu soojuskaardi ja parema fraasitõlke abil ning viib BLEU skooride statistiliselt olulise paranemiseni.', 'fi': 'Tässä artikkelissa tunnistamme mielenkiintoisen virheen Undreamt1-kaltaisten Undreamt1-kaltaisten Unservized Neural Machine Translation (UNMT) -järjestelmien tulosteessa. Viittaamme tähän virhetyyppiin Scrambled Translation ongelmana. Havaitsemme, että UNMT-mallit, jotka käyttävät sanaa sekoittavaa melua (kuten Undreamt-tapauksessa), voivat tuottaa oikeita sanoja, mutta eivät yhdistä niitä muodostaakseen lauseita. Tämän seurauksena käännetyn lauseen sanat näyttävät sekaisin, mikä johtaa BLEU:n vähenemiseen. Hypoteesimme, että käännösprobleemin taustalla on "sekoituskoina", joka otetaan käyttöön jokaisessa syöttölauseessa denoisointistrategiana. Testataksemme hypoteesiamme ja kokeilemme uudelleenkouluttamalla UNMT-malleja yksinkertaisella uudelleenkoulutusstrategialla. Pysäytämme Denoising UNMT -mallin harjoittelun ennalta määrätyn iteraatiomäärän jälkeen ja jatkamme harjoittelua jäljellä oleville iteraatioille – jonka numero on myös ennalta päätetty – käyttämällä alkuperäistä lausetta syötteenä ilman melua. Ehdotetulla ratkaisulla saavutetaan merkittäviä suorituskyvyn parannuksia UNMT-malleissa, jotka harjoittelevat perinteisesti. Osoitamme nämä suorituskykyedut neljällä kieliparilla ja viz. ja englanti-ranska ja englanti-saksa ja englanti-espanja ja hindi-punjabi. Laadullinen ja kvantitatiivinen analyysimme osoittaa, että uudelleenkoulutusstrategia auttaa saavuttamaan paremman yhdenmukaisuuden huomiolämpökartan ja paremman sanamuodon avulla ja johtaa tilastollisesti merkitsevään parannukseen BLEU-pisteissä.', 'ha': "In this paper and we identify an interesting kind of error in the output of Unsupervised Neural Machine Translation (UNMT) systems like Undreamt1.  Munã bincike wa wannan nau'in ɓata kamar matabbata ta Tsararre. Tuna ganin misãlai na UNMT da ke amfani da saurin shuffle (kamar idan da ke cikin Bayor Farawiya) za'a ƙãga magana masu gaske kuma amma ba za'a iya ƙara su sami zuwa tsarin magana. Faramata da maganar da aka fassar ta yi tsurin da kuma ya ƙara BLEU. Tuna gaskata cewa saba bakin mai fassarar da aka samu ta zama 'sautin shuffurin' wanda aka shiga cikin kõwane salon da aka shigar da shi kamar wani ƙulli na danne. Dõmin ya jarraba misalinmu da kuma za mu jarraba kwamfyutan a sami misalin UNMT da wani taki mai saukarwa. Tuna goge yin shirin misalin UNMT da aka Denoise ko kuma za'a sake shirin wa abun da ke baka - tare da ƙidãya na rubutun da aka yi amfani da shi a matsayin kwance kamar a shigar da shi kuma ba da ƙara wani sauni ba. Zuwa da aka buɗa shi, ya sami muhimmin mafarinta na UNMT da misãlai masu yin kõri da kawaici. Muna nũna wannan mataimaki a kan nau'i huɗu harshe da zafi. @ item Spelling dictionary Anarari da baƙaitaccenmu na iya ƙayyade, yana nũna cewa muhimmin da za'a taimake shi da mafiya daidaita kamar yadda aka taɓa wa nauyi da fassarar-nau'i da mafi alhẽri na fassarar magana, kuma yana ƙara domin improve a statistically significant score na BLEU.", 'sk': 'V tem prispevku smo ugotovili zanimivo vrsto napake pri izhodu sistemov Undreamt1, ki niso nadzorovani nevralni strojni prevodi (UNMT). To vrsto napake imenujemo težava z mešanim prevodom. Ugotavljamo, da lahko modeli UNMT, ki uporabljajo šum besednega mešanja (kot v primeru Undreamt), ustvarijo pravilne besede, vendar jih ne morejo združiti v oblikovanje fraz. Zaradi tega besede prevedenega stavka izgledajo zmešane in zmanjšajo BLEU. Predpostavljamo hipotezo, da je razlog za problemom pomešanega prevajanja "mešanje hrupa", ki je uveden v vsakem vhodnem stavku kot strategijo označevanja. Da bi preizkusili našo hipotezo, eksperimentiramo s preusposabljanjem modelov UNMT s preprosto strategijo preusposabljanja. Usposabljanje modela Denoizing UNMT ustavimo po vnaprej določenem številu iteracij in nadaljujemo usposabljanje za preostale iteracije – katera številka je tudi vnaprej določena – z uporabo izvirnega stavka kot vhoda brez dodajanja hrupa. Naša predlagana rešitev dosega znatno izboljšanje zmogljivosti modelov UNMT, ki usposabljajo konvencionalno. Te izboljšave uspešnosti prikazujemo na štirih jezikovnih parih in viz. in angleško-francosko in angleško-nemško in angleško-špansko in hindijsko-pundžabi. Naša kvalitativna in kvantitativna analiza kaže, da strategija preusposabljanja pomaga doseči boljšo usklajenost, ki jo opazujejo toplotni karti pozornosti in boljši frazalni prevod, kar vodi do statistično značilnega izboljšanja rezultatov BLEU.', 'he': "בעיתון הזה ואנחנו מזהה סוג מעניין של טעות בתוצאה של מערכות התרגום של מכונות נוירוליות ללא השגחה (UNMT) כמו Undreamt1. We refer to this error type as Scrambled Translation problem.  אנו מסתכלים על דוגמנים UNMT אשר משתמשים ברעש המילים (כמו במקרה של Undreamt) יכולים ליצור מילים נכונות אבל לא לתפור אותם יחד כדי ליצור ביטויים. כתוצאה מכך ומילים של המשפט המתורגם נראים מעורבות ובתוצאה מכך BLEU נפל. אנו מניחים שהסיבה מאחורי בעיית התרגום מעורבת היא 'רעש מעורבב' שהופיע בכל משפט הכניסה כאסטרטגיה מכחישה. כדי לבדוק את ההיפתוזה שלנו וננסה על ידי שיחזור לימוד דוגמנים UNMT עם אסטרטגיה פשוטה של שיחזור לימוד. אנו מפסיקים את האימונים של מודל UNMT Denoising לאחר מספר מחדש החלטה של חזרות ולהמשיך את האימונים לשאר החזרות - איזה מספר גם מחדש החלטה - להשתמש במשפט המקורי ככניסה בלי להוסיף שום רעש. הפתרון המוצע שלנו משיג שיפור משמעותי ביצועים מודלים UNMT שמאמנים באופן קונבנסיונלי. אנחנו מראים את ההופעות האלה על ארבעה זוגות שפות וייץ. ואנגלית-צרפתית, אנגלית-גרמנית, אנגלית-ספרדית ופונג'בי הינדי. ניתוח איכותי וקוונטיבי שלנו מראה שהאסטרטגיה של שיפור הכישורים עוזרת להשיג התאמה טובה יותר כפי שנראה על ידי מפת תשומת לב ותרגום מילים טובה יותר ומובילה לשיפור סטטיסטי משמעותי בתוצאות BLEU.", 'bo': "འོག ང་ཚོས་རྒྱབ་སྐྱོར་ཡོད་པའི་སྐད་རིགས་འདི་ལ་བརྗོད་བྱེད་ཀྱི་ཡོད་པ ང་ཚོས་UNMT་དཀྲོག་ཅིག་གནད་སྤེལ་བའི་མིག་དཔེ་དབྱེ་བ་ལྟར་བཀོད་ཡོད། དབྱིབས་ཡོད་པའི་ཚིག་རྐང་ཀྱི་གནད་སྡུད་དང་བརྗོད་པ་དེ་ཚོ་ཉུང་ཕུད་ཡོད། We hypothesise that the reason behind scrambled translation problem is 'shuffling noise' which is introduced in every input sentence as a denomination strategy. To test our hypothesis and experiment by retraining UNMT models with a simple retraining strategy. We stop the training of the Denoising UNMT model after a pre-decided number of iterations and resume the training for the remaining iterations- which number is also pre-decided- using original sentence as input without adding any noise. ང་ཚོའི་འཆར་བཀོད་པའི་ཐབས་ཤེས་དུ་རྐྱེན་ཚད་ལྡན་པའི་སྣེ་ཚོགས་ཉེན་མཁན་ཉེན་ཁ་འབྱུང་བ་རེད། ང་ཚོས་སྐྱེས་ཆེན་འདི་དག་འབྲས་ཅན་གྱི་སྐད་ཡིག་གཟུགས་དང་གྲངས་ཀ་གཉིས་རུ་བར་བཤད་པ་ཡིན། དབྱིན་ཡིག་དང་སྐད་ཡིག་དང་དབྱིན་ཡིག་དང་དབྱིན་ཡིག་དང་སྐད་ཡིག་དང་། རྒྱ་ནག་གི་པོན་ཇེ་བི། Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.", 'jv': 'Nang mapir iki lan kita sampeyan kelas perkaraan sing dibutungane ning gambar ng kelas nang mulai sistem Neral yang terjamahan (UNMT) sing koyo Unsongt1. Awakdhéwé nggawe kaliwat iki dibutuhke nung Jejaraké Tulung Awak dhéwé éntuk sistem UNMT sing bisa nguasai perbudhakan uwis (kaya sakjane Ungé) iso nggawe pawaran adalah lan nguasai paké, iso nggawe ujian karo perusahaan banget nggawe ujian. Bilih mbujal lan kelas mburusak terjamahan Awak dhéwé ngerti, ngrusak-seneng babagan kelas mbutuhak pertualisan luwih \' Ngawe ujian seneng sumepe-seneng karo awak dhéwé éntuk mulai model UNMT karo akeh basa sing bisa nguasai layanan sitilah. Awak dhéwé wis depasai aturan tambah nggawe Denoying UNMT model luwih saben kelas kotak nggawe gerakan seneng pisan Rong Bapaké nggawe ngubah Rasané awak dhéwé éntuk sistem sing gawe akeh operasi nggawe model UNMT sing berarti segala saiki. Awak dhéwé ngomongke perusahaan kanggo ngerasakno apat kanggo ngerasakno karo "s" karo Inggris-Perancis karo Iking-Perancis lan Iking-Perancis lan Iking-Pispan lan Iking-Punjabi. Awak dhéwé kaliterasi lan kantarno kuwi nggawe geraksi dadi bener pancene nggawe gerakan luwih apik sing luwih nggawe gerakan karo mapan ingkang dipatensak karo terjamahan sing luwih apik lan ingkang dipatensak sing luwih dumadhi kanggo nggawe gerakan sampek dadi nggawe gerakan dadi'}
{'en': 'On nature and causes of observed MT errors MT  errors', 'ar': 'عن طبيعة وأسباب أخطاء الترجمة الآلية المرصودة', 'es': 'Sobre la naturaleza y las causas de los errores MT observados', 'fr': 'Sur la nature et les causes des erreurs MT observées', 'pt': 'Sobre a natureza e as causas dos erros de MT observados', 'ja': '観察されたMTエラーの性質と原因について', 'hi': 'प्रकृति और मनाया एमटी त्रुटियों के कारणों पर', 'ru': 'О характере и причинах наблюдаемых ошибок МП', 'zh': '观其机器翻译谬之性也', 'ga': 'Ar nádúr agus cúiseanna na n-earráidí MT breathnaithe', 'hu': 'A megfigyelt MT hibák jellegéről és okairól', 'ka': 'MT შეცდომების მიზეზები და მიზეზები', 'el': 'Για τη φύση και τις αιτίες των παρατηρηθέντων σφαλμάτων ΜΤ', 'it': 'Sulla natura e le cause degli errori MT osservati', 'kk': 'MT қатесінің табиғаты мен себептері', 'mk': 'On nature and causes of observed MT errors', 'lt': 'Pastebėtų MT klaidų pobūdis ir priežastys', 'ml': 'എംടി തെറ്റുകളുടെ പ്രകൃതിയും കാരണങ്ങളും', 'mt': 'Dwar in-natura u l-kawżi ta’ żbalji MT osservati', 'mn': 'МТ алдааны байгаль болон шалтгаануудын тухай', 'pl': 'O charakterze i przyczynach obserwowanych błędów MT', 'no': 'På natur og grunn av observerte MT- feil', 'ms': 'Pada sifat dan penyebab ralat MT yang dilihat', 'sr': 'O prirodi i uzrocima promatranih MT grešaka', 'ro': 'Cu privire la natura și cauzele erorilor MT observate', 'so': 'dabiicadda iyo sababaha lagu arko qaladka MT', 'si': 'MT වැරදිලි ස්වභාවය සහ හැකියාවට', 'ta': 'On nature and causes of observed MT errors', 'ur': 'مٹی غلطی کی طبیعت اور دلیل پر', 'sv': 'Om arten och orsakerna till observerade MT-fel', 'uz': 'MT xatolarining tabiiy va sabablari', 'vi': 'Về nguyên nhân và nguyên nhân lỗi tổ chức MTV', 'nl': 'Over de aard en oorzaken van waargenomen MT-fouten', 'da': 'Om arten og årsagerne til observerede MT-fejl', 'de': 'Art und Ursachen der beobachteten MT-Fehler', 'bg': 'За естеството и причините за наблюдаваните грешки в МТ', 'hr': 'O prirodi i uzrocima promatranih MT grešaka', 'fa': 'در طبیعت و دلایل اشتباهی MT مشاهده شده', 'sw': 'Kwa asili na sababu za makosa yanayotazama MT', 'af': 'Op natuur en oorsaak van observeerde MT foute', 'tr': 'MT hatalarynyň tebigaty we sebäpleri barada', 'id': 'Pada alam dan penyebab kesalahan MT yang dilihat', 'am': 'በሥርዓት እና የMT ስህተት ምክንያት', 'ko': '관측 오차의 성질과 원인을 논하다', 'hy': 'ՄԹ սխալների բնույթի և պատճառների մասին,', 'bs': 'O prirodi i uzrocima promatranih MT grešaka', 'az': 'MT x톛talar캼n캼n t톛bi톛ti v톛 s톛b톛bi bar톛sind톛', 'bn': 'প্রকৃতি এবং দেখা যায় MT ভুলের কারণে', 'ca': 'En la naturalesa i les causes dels errors observats de MT', 'cs': 'O povaze a příčinách pozorovaných chyb MT', 'fi': 'Havaittujen MT-virheiden luonne ja syyt', 'sq': 'Për natyrën dhe shkaqet e gabimeve MT të vëzhguara', 'et': 'Täheldatud MT vigade laad ja põhjused', 'ha': '@ item license (short name)', 'jv': 'Nang bumi lan erakan panjenengan kelalahan MT', 'sk': 'O naravi in vzrokih opaženih napak v MT', 'bo': 'མཐོང་སྣང་དང་རྒྱུ་མཚན་ནི་MT ནོར་འཁྲུལ་ལ་', 'he': 'על הטבע והסיבות של טעויות MT'}
{'en': 'This work describes analysis of nature and causes of MT errors observed by different evaluators under guidance of different quality criteria :  adequacy  and  comprehension  and and a not specified generic mixture of  adequacy  and  fluency . We report results for three language pairs and two domains and eleven MT systems. Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems : rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations. Furthermore and we show that the quality criterion also has impact on error perception. Our findings indicate that  comprehension  and adequacy can be assessed simultaneously by different evaluators and so that  comprehension  and as an important quality criterion and can be included more often in human evaluations.', 'pt': 'Este trabalho descreve a análise da natureza e das causas dos erros de TA observados por diferentes avaliadores sob a orientação de diferentes critérios de qualidade: adequação e compreensão e uma mistura genérica não especificada de adequação e fluência. Relatamos resultados para três pares de idiomas e dois domínios e onze sistemas de TA. Nossos achados indicam que, apesar do fato de que alguns dos fenômenos identificados dependem do domínio e/ou idioma e o seguinte conjunto de fenômenos pode ser considerado geralmente desafiador para os sistemas modernos de TA: reformular grupos de palavras e tradução de palavras-fonte ambíguas e traduzir frases nominais e e erros de tradução. Além disso, mostramos que o critério de qualidade também tem impacto na percepção do erro. Nossos achados indicam que a compreensão e a adequação podem ser avaliadas simultaneamente por diferentes avaliadores e, portanto, a compreensão e como um importante critério de qualidade e podem ser incluídas com mais frequência nas avaliações humanas.', 'ar': 'يصف هذا العمل تحليل طبيعة وأسباب أخطاء الترجمة الآلية التي لاحظها مقيمون مختلفون بتوجيه من معايير جودة مختلفة: الكفاية والفهم وخليط عام غير محدد من الملاءمة والطلاقة. نقوم بالإبلاغ عن نتائج لثلاثة أزواج لغوية ومجالين وأحد عشر نظامًا من أنظمة الترجمة الآلية. تشير النتائج التي توصلنا إليها إلى أنه على الرغم من حقيقة أن بعض الظواهر المحددة تعتمد على المجال و / أو اللغة ، فإن مجموعة الظواهر التالية يمكن اعتبارها تحديًا بشكل عام لأنظمة الترجمة الآلية الحديثة: إعادة صياغة مجموعات الكلمات وترجمة الكلمات المصدر الغامضة والترجمة عبارات الاسم والترجمات الخاطئة. علاوة على ذلك ، نظهر أن معيار الجودة له تأثير أيضًا على إدراك الخطأ. تشير النتائج التي توصلنا إليها إلى أنه يمكن تقييم الفهم والكفاية في وقت واحد من قبل مقيمين مختلفين ، وبالتالي فإن الفهم وكمعيار هام للجودة ويمكن إدراجه في كثير من الأحيان في التقييمات البشرية.', 'fr': "Ce travail décrit l'analyse de la nature et des causes des erreurs MT observées par différents évaluateurs en fonction de différents critères de qualité\xa0: adéquation et compréhension et un mélange générique non spécifié d'adéquation et de fluidité. Nous présentons les résultats pour trois paires de langues et deux domaines et onze systèmes de traduction automatique. Nos résultats indiquent que, malgré le fait que certains des phénomènes identifiés dépendent du domaine et/ou de la langue, l'ensemble de phénomènes suivant peut être considéré comme un défi général pour les systèmes de TA modernes\xa0: reformuler des groupes de mots et traduire des mots sources ambigus et traduire un nom phrases et erreurs de traduction. De plus, nous montrons que le critère de qualité a également un impact sur la perception des erreurs. Nos résultats indiquent que la compréhension et l'adéquation peuvent être évaluées simultanément par différents évaluateurs et que la compréhension est un critère de qualité important et peut être incluse plus souvent dans les évaluations humaines.", 'es': 'Este trabajo describe el análisis de la naturaleza y las causas de los errores de MT observados por diferentes evaluadores bajo la guía de diferentes criterios de calidad: adecuación y comprensión y una mezcla genérica no especificada de adecuación y fluidez. Presentamos los resultados de tres pares de idiomas y dos dominios y once sistemas de traducción automática. Nuestros hallazgos indican que, a pesar del hecho de que algunos de los fenómenos identificados dependen del dominio y/o el idioma, el siguiente conjunto de fenómenos puede considerarse un desafío general para los sistemas modernos de traducción automática: reformulación de grupos de palabras y traducción de palabras fuente ambiguas y traducción de sustantivos frases y errores de traducción. Además, demostramos que el criterio de calidad también tiene un impacto en la percepción de errores. Nuestros hallazgos indican que la comprensión y la adecuación pueden ser evaluadas simultáneamente por diferentes evaluadores y, por lo tanto, la comprensión y como un criterio de calidad importante y pueden incluirse más a menudo en las evaluaciones humanas.', 'ja': 'この研究では、異なる品質基準のガイダンスの下で異なる評価者が観察したMTエラーの性質と原因の分析について説明しています：妥当性と理解、および妥当性と流暢性の特定されていない一般的な混合物。3つの言語ペア、2つのドメイン、11のMTシステムの結果を報告します。我々の調査結果は、特定された現象のいくつかがドメインおよび／または言語に依存しているという事実にもかかわらず、以下の一連の現象は、現代のMTシステムにとって一般的に挑戦的であると見なすことができることを示している：単語のグループを言い換え、あいまいな語源の単語の翻訳を行い、名詞句および誤訳を翻訳する。さらに、品質基準はエラー認識にも影響を及ぼすことを示しています。私たちの調査結果は、理解と妥当性が異なる評価者によって同時に評価され、理解と重要な品質基準として、人間の評価に含めることができることを示しています。', 'zh': '其言异质量标准者,机器翻译非其性,充分性知性及未指定之充分性,流畅性之通用混合物。 告三言、二域、十一机器翻译统。 臣等论结果表明,虽已识在领/语言,以下常视为今世机器翻译系统有挑战性:改作单词组和译模棱两可之源词,译名词短语误译。 此外,明质量标准亦有所感于错误感知也。 吾之论结果表明,知充分性可以同时,故知与为重质量标准,可频含于人。', 'hi': 'यह काम विभिन्न गुणवत्ता मानदंडों के मार्गदर्शन में विभिन्न मूल्यांकनकर्ताओं द्वारा देखी गई एमटी त्रुटियों की प्रकृति और कारणों के विश्लेषण का वर्णन करता है: पर्याप्तता और समझ और पर्याप्तता और प्रवाह का एक निर्दिष्ट सामान्य मिश्रण नहीं। हम तीन भाषा जोड़े और दो डोमेन और ग्यारह एमटी सिस्टम के लिए परिणामों की रिपोर्ट करते हैं। हमारे निष्कर्षों से संकेत मिलता है कि और इस तथ्य के बावजूद कि कुछ पहचानी गई घटनाएं डोमेन और / या भाषा पर निर्भर करती हैं और घटनाओं के निम्नलिखित सेट को आधुनिक एमटी प्रणालियों के लिए आम तौर पर चुनौतीपूर्ण माना जा सकता है: शब्दों के समूहों को फिर से तैयार करना और अस्पष्ट स्रोत शब्दों का अनुवाद करना और संज्ञा वाक्यांशों और गलत अनुवादों का अनुवाद करना। इसके अलावा और हम दिखाते हैं कि गुणवत्ता मानदंड का त्रुटि धारणा पर भी प्रभाव पड़ता है। हमारे निष्कर्षों से संकेत मिलता है कि समझ और पर्याप्तता का मूल्यांकन विभिन्न मूल्यांकनकर्ताओं द्वारा एक साथ किया जा सकता है और ताकि समझ और एक महत्वपूर्ण गुणवत्ता मानदंड के रूप में और मानव मूल्यांकन में अधिक बार शामिल किया जा सके।', 'ru': 'Эта работа описывает анализ характера и причин ошибок МП, наблюдаемых различными оценщиками под руководством различных критериев качества: адекватности и понимания, а также неуказанного общего сочетания адекватности и беглости. Мы сообщаем результаты для трех языковых пар и двух доменов и одиннадцати систем MT. Наши выводы показывают, что и несмотря на то, что некоторые из выявленных явлений зависят от домена и/или языка и следующий набор явлений можно считать в целом сложным для современных систем МТ: перефразирование групп слов и перевод неоднозначных исходных слов и перевод именных фраз и и неправильные переводы. Кроме того, и мы показываем, что критерий качества также влияет на восприятие ошибок. Наши выводы показывают, что понимание и адекватность могут оцениваться одновременно различными специалистами по оценке, и поэтому понимание и как важный критерий качества могут чаще включаться в оценки человека.', 'ga': 'Déanann an obair seo cur síos ar anailís ar nádúr agus ar chúiseanna na n-earráidí MT a bhreathnaíonn meastóirí éagsúla faoi threoir critéar cáilíochta éagsúla: leordhóthanacht agus tuiscint agus meascán cineálach neamhshonraithe de leorgacht agus líofacht. Tuairiscímid torthaí do thrí phéire teanga agus dhá fhearann agus aon chóras MT déag. Léiríonn ár dtorthaí, agus ainneoin go bhfuil cuid de na feiniméin aitheanta ag brath ar fhearann agus/nó ar theanga agus gur féidir an tsraith feiniméin seo a leanas a mheas mar dhúshlán i gcoitinne do chórais MT nua-aimseartha: grúpaí focal a athfhrású agus focail foinse débhríoch a aistriú agus a aistriú. frásaí ainmfhocail agus agus míaistriúcháin. Ina theannta sin agus léirímid go bhfuil tionchar ag an gcritéar cáilíochta ar earráidí a bhrath. Léiríonn ár dtorthaí gur féidir le meastóirí éagsúla tuiscint agus leorgacht a mheas go comhuaineach agus ionas gur féidir tuiscint agus mar chritéar cáilíochta tábhachtach a áireamh níos minice i meastóireachtaí daonna.', 'el': 'Η παρούσα εργασία περιγράφει την ανάλυση της φύσης και των αιτίων των σφαλμάτων ΜΤ που παρατηρούνται από διαφορετικούς αξιολογητές υπό την καθοδήγηση διαφορετικών κριτηρίων ποιότητας: επάρκεια και κατανόηση και ένα μη καθορισμένο γενικό μείγμα επάρκειας και ευκρίνειας. Αναφέρουμε αποτελέσματα για τρία γλωσσικά ζεύγη και δύο τομείς και έντεκα συστήματα ΜΤ. Τα ευρήματά μας δείχνουν ότι και παρά το γεγονός ότι ορισμένα από τα εντοπιζόμενα φαινόμενα εξαρτώνται από τον τομέα ή/και τη γλώσσα και το ακόλουθο σύνολο φαινομένων μπορεί να θεωρηθεί γενικά προκλητικό για τα σύγχρονα συστήματα ΜΤ: αναδιατύπωση ομάδων λέξεων και μετάφραση αμφιλεγόμενων λέξεων προέλευσης και μετάφραση ουσιαστικών φράσεων και εσφαλμένων μεταφράσεων. Επιπλέον και αποδεικνύουμε ότι το κριτήριο ποιότητας έχει επίσης αντίκτυπο στην αντίληψη σφαλμάτων. Τα ευρήματά μας δείχνουν ότι η κατανόηση και η επάρκεια μπορούν να αξιολογηθούν ταυτόχρονα από διαφορετικούς αξιολογητές και έτσι η κατανόηση και ως σημαντικό κριτήριο ποιότητας και μπορούν να συμπεριληφθούν συχνότερα στις ανθρώπινες αξιολογήσεις.', 'hu': 'Ez a munka leírja a különböző értékelők által megfigyelt MT hibák természetének és okainak elemzését különböző minőségi kritériumok irányítása mellett: megfelelőség és megértés, valamint a megfelelőség és folyékonyság nem meghatározott általános keveréke. Három nyelvpár, két domain és tizenegy MT rendszer eredményeit jelentjük. Eredményeink azt mutatják, hogy és annak ellenére, hogy az azonosított jelenségek egy része tartománytól és/vagy nyelvtől függ, és a következő jelenségcsoportok tekinthetők általános kihívásnak a modern MT rendszerek számára: szócsoportok átfogalmazása, kétértelmű forrásszavak fordítása, főnévkifejezések és félreértések fordítása. Ezenkívül megmutatjuk, hogy a minőségi kritérium hatással van a hibaészlelésre is. Eredményeink azt mutatják, hogy a megértés és a megfelelőség egyidejűleg értékelhető a különböző értékelők által, így a megértés és minőségi kritérium fontos, és gyakrabban bevonható az emberi értékelésekbe.', 'ka': 'ეს სამუშაო აღწერა MT შეცდომების ანალიზაციის და მიზეზების ანალიზაცია, რომელიც განსხვავებული განსხვავებული კაalitეტის კრიტერიების მიზეზით დააჩვენებული განსხვავებული განსხვავებული განსხვავებული განსხვავ ჩვენ შეგვიყვანეთ შედეგი სამუშაო წიგნის და ორი დომენის და 11 MT სისტემას. ჩვენი შესაძლებლობები აჩვენებენ, რომ და მაგრამ ფაქტის, რომ რამდენიმე განსაზღვრებული ფენომენები დემომინი და/ან ენაზე დაახლოდება და შემდეგი ფენომენების ნაწილი ნაწილის ნაწილის ნაწილის ნაწილის შესაძლებელია, როგორც მხოლოდ მომდინარე MT სი დამატებით და ჩვენ ჩვენ აჩვენებთ, რომ კრიტერიაში კრიტერიაც შეცდომის აღმოჩენისათვის შეცდომის აღმოჩენისათვის. ჩვენი შესაძლებლობები აჩვენებენ, რომ სწორედ განსხვავებული განსაზღვრებელების შესაძლებლობა და მარტივის შესაძლებლობა შეიძლება ერთადერთად განსაზღვრება განსხვავებული განსაზღვრებელებით და ამიტომ, რომ სწორედ და გა', 'it': "Questo lavoro descrive l'analisi della natura e delle cause degli errori MT osservati da diversi valutatori sotto la guida di diversi criteri di qualità: adeguatezza e comprensione e una miscela generica non specificata di adeguatezza e fluidità. Riportiamo i risultati per tre coppie linguistiche e due domini e undici sistemi MT. I nostri risultati indicano che e nonostante il fatto che alcuni dei fenomeni identificati dipendono dal dominio e/o dalla lingua e i seguenti fenomeni possono essere considerati generalmente impegnativi per i moderni sistemi MT: riformulare gruppi di parole e tradurre parole sorgente ambigue e tradurre frasi sostantive e traduzioni errate. Inoltre, dimostriamo che il criterio di qualità ha un impatto anche sulla percezione degli errori. I nostri risultati indicano che la comprensione e l'adeguatezza possono essere valutate simultaneamente da diversi valutatori e quindi la comprensione e come criterio di qualità importante e possono essere incluse più spesso nelle valutazioni umane.", 'kk': 'Бұл жұмыс MT қателерінің табиғаттығын және себептерінің анализациясын түрлі сапаттық критерияларының бағытталған түрлі бағалаушыларының қатесін анықтайды: адекциялық, түсінікті және келтірілмеген жалп Біз үш тіл екі, екі доменге және 11 MT жүйесінің нәтижесін хабарлаймыз. Біздің іздегеніміз, кейбір таңдалған пайдаланулардың доменге мен/немесе тіліне тәуелді және келесі пайдаланулардың бірнеше бағдарламалардың кәдімгі MT жүйелеріне қатысты деп қарай алады: сөздер топтарын қайта-фразируі және көзгертілмеген сөздерді ау Сонымен қайталап, сапаттың критериясы қателерді қалай түсінуге әсер етеді деп көрсетеді. Біздің тапсырмамыз түсініктерді және адамдарды бір-бірінен түсініктіру және адамдардың оқиғаларының түсініктері болып, түсініктері және маңызды сапаттың критериясы ретінде, көбірек адамдардың о', 'ms': 'Kerja ini menggambarkan analisis sifat dan penyebab ralat MT yang dilihat oleh penilai berbeza dibawah petunjuk kriteria kualiti yang berbeza: keperluan dan pemahaman dan campuran generik tidak dinyatakan keperluan dan keterlaluan. Kami laporkan hasil untuk tiga pasangan bahasa dan dua domain dan 11 sistem MT. Penemuan kami menunjukkan bahawa dan walaupun beberapa fenomena yang dikenali bergantung pada domain dan/atau bahasa dan set fenomena berikut boleh dianggap sebagai secara umum mencabar bagi sistem MT modern: mengubah kumpulan perkataan dan terjemahan perkataan sumber yang ambiguh dan terjemahan frasa nama dan salah terjemahan. Lagipun dan kami menunjukkan bahawa kriteria kualiti juga mempunyai kesan pada perasaan ralat. Kesemuan kami menunjukkan bahawa pemahaman dan keperluan boleh diukur secara bersamaan oleh penilai yang berbeza dan sehingga pemahaman dan sebagai kriteria kualiti yang penting dan boleh disertai lebih sering dalam penilaian manusia.', 'mt': 'Dan ix-xogħol jiddeskrivi analiżi tan-natura u l-kawżi ta’ żbalji MT osservati minn evalwaturi differenti taħt gwida ta’ kriterji ta’ kwalità differenti: adegwatezza u fehim u taħlita ġenerika mhux speċifikata ta’ adegwatezza u fluwenza. Aħna nirrappurtaw riżultati għal tliet pari lingwistiċi u żewġ oqsma u ħdax-il sistema MT. Is-sejbiet tagħna jindikaw li u minkejja l-fatt li wħud mill-fenomeni identifikati jiddependu fuq id-dominju u/jew il-lingwa u s-sett ta’ fenomeni li ġejjin jista’ jitqies bħala ġeneralment ta’ sfida għal sistemi MT moderni: it-tfassil mill-ġdid ta’ gruppi ta’ kliem u t-traduzzjoni ta’ kliem tas-sors ambigwi u t-traduzzjoni ta’ frażijiet u traduzzjonijiet ħażina ta Furthermore and we show that the quality criterion also has impact on error perception.  Is-sejbiet tagħna jindikaw li l-komprensjoni u l-adegwatezza jistgħu jiġu vvalutati simultanjament minn evalwaturi differenti u sabiex il-komprensjoni u bħala kriterju ta’ kwalità importanti jkunu jistgħu jiġu inklużi aktar spiss fl-evalwazzjonijiet tal-bniedem.', 'ml': 'വ്യത്യസ്ത്രീയത്തിന്റെ മാര്\u200dഗദര്\u200dശനത്തില്\u200d വ്യത്യസ്ത വിവിധികള്\u200d കാണിച്ചിരിക്കുന്ന MT പിശകുകളുടെയും കാരണങ്ങളുടെയും വിശദീകരണവും ഈ പ്രവര്\u200dത്തിയ മൂന്നു ഭാഷ ജോടികള്\u200dക്കും രണ്ടു ഡൊമൈനുകള്\u200dക്കും 11 എംടി സിസ്റ്റമുകള്\u200dക്കും ഫലങ്ങള്\u200d ഞങ്ങള്\u200d റിപ്പോര്\u200d Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations.  കൂടുതല്\u200d നമ്മള്\u200d കാണിക്കുന്നത് തെറ്റിന്\u200dറെ കാര്യത്തിലും പ്രഭാവം ഉണ്ടെന്നാണ്. നമ്മുടെ കണ്ടുപിടികള്\u200d വ്യത്യസ്തമായ വിവിധ വിവിധികളാല്\u200d പരിഗണിക്കുന്നതും പരിപാലിക്കുന്നതും അതുകൊണ്ട് പരിഗണിക്കുന്നതും പ്രധാനപ്പെട്ട ഗുണവി', 'lt': 'Šiame darbe aprašoma įvairių vertintojų pagal skirtingus kokybės kriterijus stebėtų MT klaidų pobūdžio ir priežasčių analizė: tinkamumas ir supratimas bei nenurodytas bendras tinkamumo ir lankstumo mišinys. We report results for three language pairs and two domains and eleven MT systems.  Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations.  Be to, rodome, kad kokybės kriterijus taip pat daro poveikį klaidų suvokimui. Mūsų išvados rodo, kad skirtingi vertintojai gali vienu metu įvertinti supratimą ir tinkamumą, kad supratimas ir kaip svarbus kokybės kriterijus galėtų būti dažniau įtraukti į žmogaus vertinimus.', 'mn': 'Энэ ажлын талаар MT алдааны шалгалтыг өөр өөр чанарын шалгалтын тухай дүрслэгчид харуулсан өөр өөр үнэлгээчийн шалгалтын шалгалтыг тайлбарлаж байна: адилхан, ойлголтын тухай, мөн адилхан, шингэний ерөнхий төвөгтэй хол Бид 3 хэл хоёр, 2 газрын, 11 MT системийн үр дүн гаргаж байна. Бидний олж мэдсэн зүйл нь зарим тодорхойлогдсон үйл явдал холбооны, эсвэл хэл, дараагийн үйл явдал орчин үеийн MT системийн төлөө төвөгтэй гэж үздэг гэдгийг харуулж байна: үгнүүдийн, хэмжээсгүй эх үүсвэрийн үгнүүдийн, нэр хэлбэрүүдийн, буруу орчуулалтын хэлбэрээс хамааралтай гэ Мөн бид чанарын шалтгаан нь алдааны ойлголтын нөлөөлдөг гэдгийг харуулж байна. Бидний ололтууд нь ойлголт болон зөвхөн адилхан байдлыг өөр өөр оюутнуудын хувьд ойлгох, үнэ цэнэтэй хэмжээний хувьд илүү ихэвчлэн хүн төрөлхтний оюутнуудад дүгнэж болно гэдгийг харуулж байна.', 'pl': 'W niniejszej pracy opisano analizę charakteru i przyczyn błędów MT obserwowanych przez różnych oceniających pod kierunkiem różnych kryteriów jakości: adekwatności i zrozumienia oraz nieokreślonej ogólnej mieszanki adekwatności i płynności. Raportujemy wyniki dla trzech par językowych i dwóch domen oraz jedenastu systemów MT. Nasze ustalenia wskazują, że pomimo faktu, iż niektóre z zidentyfikowanych zjawisk zależą od domeny i/lub języka, a następujący zestaw zjawisk może być uznany za ogólne wyzwanie dla nowoczesnych systemów MT: przeformułowanie grup słów i tłumaczenie dwujednoznacznych słów źródłowych oraz tłumaczenie fraz rzeczowników i błędnych tłumaczeń. Ponadto pokazujemy, że kryterium jakości ma również wpływ na postrzeganie błędów. Nasze ustalenia wskazują, że zrozumienie i adekwatność mogą być oceniane jednocześnie przez różnych oceniających, a tym samym zrozumienie i jako ważne kryterium jakości i mogą być częściej uwzględniane w ocenach ludzi.', 'mk': 'Оваа работа ја опишува анализата на природата и причините на грешките на МТ кои ги набљудуваат различните евалуатори под водство на различни квалитетни критериуми: адекватност и разбирање и неопределена генерална мешавина на адекватност и течност. Ние известуваме резултати за три јазички парови и два домени и 11 МТ системи. Нашите откритија покажуваат дека и покрај фактот дека некои од идентификуваните феномени зависат од доменот и/или јазикот и следниот набор феномени може да се сметаат за генерално предизвикувачки за модерните МТ системи: рефразирање групи зборови и превод на двогледни изворни зборови и превод на фрази и погрешни преводи. Furthermore and we show that the quality criterion also has impact on error perception.  Our findings indicate that comprehension and adequacy can be assessed simultaneously by different evaluators and so that comprehension and as an important quality criterion and can be included more often in human evaluations.', 'no': 'Denne arbeidet beskriver analysen av natur og grunner av MT-feil som er observert av forskjellige evaluatorar under retningar av forskjellige kvalitetkriterier: adekvitet og forståelse og ikkje spesifisert generiske blanding av adekvitet og fluktet. Vi rapporterer resultatet for tre språkopar og to domene og elleve MT-systemer. Finningane våra tyder på at, selv om det faktum at nokre av dei identifiserte fenomena avhengig av domene og/eller språk, og følgjande set av fenomena kan gjerast som vanskeleg for moderne MT-systemer: å rephrasera grupper av ord og omsetjinga av avgjengelege kjeldeord og omsetja namn fraser og feil omsetjingar. I tillegg viser vi at kvalitetkriterien også har påvirkning på feiloppfatting. Finningane våre tyder på at forståelse og adekvitet kan vurderes samtidig av forskjellige evaluatorar og slik at forståelse og som viktig kvalitetkritering og kan inkluderast meir ofte i menneske evalueringar.', 'ro': 'Această lucrare descrie analiza naturii și cauzelor erorilor MT observate de diferiți evaluatori sub îndrumarea diferitelor criterii de calitate: adecvarea și înțelegerea și un amestec generic nespecificat de adecvare și fluență. Raportăm rezultatele pentru trei perechi de limbi și două domenii și unsprezece sisteme MT. Rezultatele noastre indică faptul că și în ciuda faptului că unele dintre fenomenele identificate depind de domeniu și/sau limbă și următoarele set de fenomene pot fi considerate ca fiind în general provocatoare pentru sistemele MT moderne: reformularea grupurilor de cuvinte și traducerea cuvintelor sursă ambigue și traducerea frazelor substantive și traducerea greșită. Mai mult decât atât, demonstrăm că criteriul calității are impact și asupra percepției erorilor. Rezultatele noastre indică faptul că înțelegerea și caracterul adecvat pot fi evaluate simultan de către diferiți evaluatori și astfel încât înțelegerea și ca criteriu important de calitate pot fi incluse mai des în evaluările umane.', 'sr': 'Ovaj rad opisuje analizu prirode i uzroka grešaka MT-a koji su promatrali različiti procjenatori pod vodstvom različitih kriterija kvalitete: adekvatnost i razumijevanje i neprecizano generičko mješanje adekvatnosti i tekućine. Prijavljujemo rezultate za tri jezičke parove i dve domene i 11 MT sistema. Naši nalazi ukazuju na to da i uprkos činjenici da neki od identifikovanih fenomena zavise od domena i/ili jezika i sljedećeg seta fenomena mogu biti smatrani općenito izazovnim za moderne MT sisteme: rephrasiranje grupa reči i prevod ambigućih izvorskih reči i prevod imenskih fraza i pogrešnih prevoda. Osim toga, pokazujemo da kriterij kvalitete takođe utječe na percepciju grešaka. Naši nalazi ukazuju na to da razumijevanje i adekvatnost mogu istovremeno proceniti različiti procenatori i tako da razumijevanje i kao važan kriterij kvalitete i da se mogu češće uključiti u ljudske procjene.', 'sv': 'Detta arbete beskriver analys av natur och orsaker till MT-fel observerade av olika utvärderare under ledning av olika kvalitetskriterier: adekvat och förståelse och en icke specificerad generisk blandning av adekvat och flytande. Vi rapporterar resultat för tre språkpar och två domäner samt elva MT-system. Våra resultat tyder på att och trots att vissa av de identifierade fenomenen är beroende av domän och/eller språk och följande fenomen kan betraktas som generellt utmanande för moderna MT-system: omformulering av ordgrupper och översättning av tvetydiga källord samt översättning av substantivfraser och felöversättningar. Dessutom visar vi att kvalitetskriteriet också påverkar feluppfattningen. Våra resultat indikerar att förståelse och lämplighet kan bedömas samtidigt av olika utvärderare och att förståelse och som ett viktigt kvalitetskriterium kan inkluderas oftare i mänskliga utvärderingar.', 'ta': 'இந்த வேலை வேறு மதிப்பும் தரவுகளின் வழிகாட்டியில் பார்க்கப்பட்டுள்ள முனைய பிழைகளின் ஆய்வு மற்றும் காரணங்களை விளக்குகிறது: சரியான மற்றும் க மூன்று மொழி ஜோடி மற்றும் இரண்டு தளங்கள் மற்றும் 11 MT அமைப்புகளுக்கு முடிவுகளை அறிவிக்கிறோம். Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations.  மேலும் நாம் காண்பிக்கிறோம் தரமான மதிப்பும் பிழையான பார்வையில் பாதிக்கும். நம்முடைய கண்டுபிடிப்புகள் குழுக்கம் மற்றும் தேவையான மதிப்பெண்களை ஒரே நேரத்தில் மதிப்பிட முடியும் என்பதை குறிப்பிடுகிறது எனவே சூழ்ச்சி மற்', 'ur': 'یہ کام مختلف کیفیت کے مقداروں کی ہدایت کے مطابق مختلف ارزش کرنے والوں کے ذریعہ متفرق MT خطاؤں کی تحقیق اور اختلاف کی وجہ سے توصیح کرتا ہے: اچھی طرح اور سمجھ اور اچھی طرح کا مشخص نہیں کیا گیا۔ ہم تین زبان جوڑوں اور دو ڈومین اور eleven MT سیستم کے نتائج گزارتے ہیں۔ ہمارے نتیجے نشان دیتے ہیں کہ اور بغیر اس حقیقت کے کہ بعض معلوم ہونے والی اتفاقات دامین اور/یا زبان پر اعتماد رکھتے ہیں اور نیچے اتفاقات کا مجموعہ موجود MT سیستم کے لئے مشکل سمجھ سکتے ہیں: کلمات کی گروہوں کو دوبارہ دفع کرنا اور غلط سراسر کلمات کی ترجمہ کرنا اور نام کلمات اور غلط ترجمہ کرنا اور ہم دکھاتے ہیں کہ کیفیت کریٹریٹر بھی گمراہی کی نظر پر اثر دیتا ہے۔ ہمارے نتیجے نشان دیتے ہیں کہ سمجھ اور adequacy ایک دفعہ مختلف ارزیابی کرنے والوں کے ذریعہ ایک دفعہ کی آزمائش کر سکتے ہیں اور اس لئے کہ سمجھ اور ایک اہم کیفیت کریٹریر کے طور پر اور بہت زیادہ وقت انسان کی ارزیابی میں شامل ہو سکتے ہیں.', 'si': 'මේ වැඩේ ස්වභාවයේ විශ්ලේෂණය සහ MT වැරදි අවස්ථාවක් වලින් විවිධ විශ්ලේෂණය සඳහා විවිධ විශේෂකයෙන් බලන්න පුළුවන් විශේෂ අපි භාෂාව තුනක් සහ ඩෝමේන් දෙකක් සහ MT පද්ධතියක් 11ක් වෙනුවෙන් ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප අපේ හොයාගන්න පෙන්වන්න පුළුවන් වෙන්නේ ඒ වගේම අනිවාර්ය වෙනුවෙන් සමහර දේවල් පරීක්ෂණය සහ/භාෂාව සමහර වෙනුවෙන් පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා සාමාන්\u200dය MT පද්ධත තවත් අපි පෙන්වන්නේ කියලා කියලා ක්\u200dරියාත්මක විශේෂතාවට ප්\u200dරතිකාරයක් තියෙනවා කියලා දෝෂා අපේ හොයාගන්න පුළුවන් කියලා තේරුම් ගන්න පුළුවන් වෙනස් විශේෂකයෝ වලින් විශේෂකයෝ වලින් පරීක්ෂණය කරන්න පුළුවන් කියලා, ඒ වග', 'so': "Shaqodankaas waxaa ku qoran baaritaanka dabiicadda iyo sababaha qaladka MT ee lagu arko qiimeeyayaasha kala duduwan oo lagu hagayo kaararka qiimaha kala duduwan: saxda iyo kooxa iyo mid aan la caddeyn isku xiriirka saxda iyo faa'iidada. We report results for three language pairs and two domains and eleven MT systems.  Faahritaankeenu waxay muuqanayaan in kastoo ay xaqiiqsan qaar ka mid ah waxyaabaha la aqoonsaday ku xiran domain iyo/ama luqada, waxaas soo socdana waxaa looga tirin karaa mid caadi ah dhibaato u eg nidaamka MT-yada modern: dib u celinta koox hadal iyo turjumidda hadallada sourceed oo caqli ah iyo turjumidda hadal aan quraan ahayn iyo wax turjuman. Furthermore waxaynu muujinnaa in qiimeynta qiimo ahaanshahana ay saameyn ku leedahay aragtida qaladka. Shaqooyinkayada waxaa loola jeedaa in lagu qiimeyn karo hoos-dhigista iyo isku qiimeynta qiimeeyayaasha kala duduwan, sidaas darteed hoos-dhigista iyo qiimeynta muhiimka ah, waxaana lagu qori karaa inta badan qiimeynta dadka.", 'uz': "Bu ishni taʼminlashtirish va boshqa qiymatlarning turli holatdagi turli qiymatlar uchun MT xatolarni va sabablarni anglatadi: taxsillik va kompaniston va taxsiylik va ajoyib boʻlmaydi. Biz uchta tillar ikki domen va 11 MT tizimi uchun natijalarini hisoblash mumkin. Bizning murojaatlarimiz aytishimiz mumkin, aniqlangan narsalar domen va/yoki tillarda murakkab bo'lganligini va quyidagi narsalar yangi doim MT tizimlarga qismi deb hisoblanadi. Bu so'zlarni qayta tarjima qilish va yolg'on suhbatlarni tarjima qilish va yolg'on so'zlar va xato tarjimalarni tarjima qilish mumkin. Furthermore and we show that the quality criterion also has impact on error perception.  Bizning murojaatlarimiz shunday paytda bir xil qiymatlar bilan qiymatlashi mumkin va muhim сифат sifatida qiymatlashtirish mumkin va odamning qiymatlarida ko'pincha qo'llaniladi.", 'vi': 'Nhiệm vụ này miêu tả phân tích chất lượng và nguyên nhân của lỗi tổ chức màn đêm theo dõi bởi các nhà đánh giá khác nhau dưới sự hướng dẫn của các tiêu chuẩn chất lượng khác nhau: đủ và thấu hiểu, và một hỗn hợp không được chỉ định là đủ và khéo léo. Chúng tôi báo cáo kết quả ba cặp ngôn ngữ và hai miền và mười một hệ thống MTV. Những phát hiện của chúng tôi cho thấy, và mặc dù một số hiện tượng đã xác định phụ thuộc vào miền và/hay ngôn ngữ, và những hiện tượng sau có thể được xem là đầy đủ thách thức với các hệ thống MTV hiện đại: thuật lại các nhóm ngôn từ và dịch thuật của các từ không rõ ràng và dịch chuyển các cụm từ danh từ và sai từ. Hơn nữa, chúng tôi cho thấy tiêu chuẩn cũng ảnh hưởng tới nhận thức lỗi. Những nghiên cứu của chúng tôi cho thấy khả năng thấu hiểu và phù hợp có thể được đánh giá đồng thời bởi các chuyên gia đánh giá khác nhau, và sự thấu hiểu và là một tiêu chuẩn chất lượng quan trọng và có thể được tính toán thường xuyên.', 'bg': 'Настоящата работа описва анализ на естеството и причините за грешките в МТ, наблюдавани от различни оценители, под ръководството на различни критерии за качество: адекватност и разбиране и неизяснена обща смес от адекватност и плавност. Докладваме резултати за три езикови двойки и два домейна и единадесет МТ системи. Нашите констатации показват, че и въпреки факта, че някои от идентифицираните явления зависят от домейн и/или език, следните явления могат да се считат за общо предизвикателство за съвременните системи на МТ: рефразиране на групи от думи и превод на двусмислени изходни думи и превод на съществителни фрази и грешни преводи. Освен това показваме, че критерият за качество оказва влияние и върху възприемането на грешки. Нашите констатации показват, че разбирането и адекватността могат да бъдат оценени едновременно от различни оценители и така разбирането и като важен критерий за качество могат да бъдат включени по-често в оценките на хората.', 'hr': 'Ovaj rad opisuje analizu prirode i uzroka grešaka MT-a koje su promatrale različiti procjenatori pod uputstvom različitih kriterija kvalitete: adekvatnost i razumijevanje i ne određena generična mješavina adekvatnosti i tekućine. Prijavljujemo rezultate za tri jezička parova i dva domena i 11 MT sustava. Naši nalazi ukazuju na to da i uprkos činjenici da neki od identificiranih fenomena zavise od domena i/ili jezika i sljedećeg skupa fenomena mogu smatrati općenito izazovnim za moderne MT sustave: rephrasiranje grupa riječi i prevod ambigućih izvornih riječi i prevod imenskih fraza i pogrešnih prevoda. Osim toga, pokazujemo da kriterij kvalitete također utječe na percepciju grešaka. Naši nalazi ukazuju na to da razumijevanje i adekvatnost mogu istovremeno procijeniti različiti procjenitelji i tako da razumijevanje i kao važan kriterij kvalitete i može se češće uključiti u ljudske procjene.', 'da': 'Dette arbejde beskriver analyse af natur og årsager til MT fejl observeret af forskellige evaluatorer under vejledning af forskellige kvalitetskriterier: tilstrækkelighed og forståelse og og en ikke specificeret generisk blanding af tilstrækkelighed og flydenhed. Vi rapporterer resultater for tre sprogpar og to domæner og elleve MT-systemer. Vores resultater indikerer, at og trods det faktum, at nogle af de identificerede fænomener afhænger af domæne og/eller sprog, og følgende sæt af fænomener kan betragtes som generelt udfordrende for moderne MT-systemer: omformulering af ordgrupper og oversættelse af tvetydige kildeord og oversættelse af substantivsætninger og og fejloversættelser. Desuden viser vi, at kvalitetskriteriet også har indflydelse på fejlopfattelsen. Vores resultater indikerer, at forståelse og tilstrækkelighed kan vurderes samtidig af forskellige evaluatorer og således forståelse og som et vigtigt kvalitetskriterium og oftere kan medtages i menneskelige evalueringer.', 'nl': 'Dit werk beschrijft de analyse van aard en oorzaken van MT-fouten waargenomen door verschillende beoordelaars onder begeleiding van verschillende kwaliteitscriteria: toereikendheid en begrip en een niet gespecificeerde generieke mix van toereikendheid en vloeiendheid. We rapporteren resultaten voor drie taalparen en twee domeinen en elf MT-systemen. Onze bevindingen wijzen erop dat, ondanks het feit dat sommige van de geïdentificeerde fenomenen afhankelijk zijn van domein en/of taal, de volgende reeks fenomenen als algemeen uitdagend kunnen worden beschouwd voor moderne MT-systemen: herformuleren van woordgroepen en vertaling van dubbelzinnige bronwoorden en het vertalen van zelfstandige zinnen en en verkeerde vertalingen. Verder laten we zien dat het kwaliteitscriterium ook invloed heeft op de foutperceptie. Onze bevindingen wijzen erop dat begrip en adequaatheid gelijktijdig door verschillende beoordelaars kunnen worden beoordeeld en dat begrip als belangrijk kwaliteitscriterium en vaker in menselijke evaluaties kan worden opgenomen.', 'de': 'Diese Arbeit beschreibt die Analyse der Natur und Ursachen von MT-Fehlern, die von verschiedenen Bewertern unter Anleitung verschiedener Qualitätskriterien beobachtet wurden: Angemessenheit und Verständnis und eine nicht spezifizierte generische Mischung aus Angemessenheit und Fluenz. Wir berichten Ergebnisse für drei Sprachpaare und zwei Domänen und elf MT-Systeme. Unsere Ergebnisse deuten darauf hin, dass einige der identifizierten Phänomene von Domänen und/oder Sprache abhängen und dass die folgenden Phänomene für moderne MÜ-Systeme als allgemein herausfordernd angesehen werden können: Umformulieren von Wortgruppen und Übersetzung von mehrdeutigen Quellwörtern und Übersetzen von Substantivphrasen und fehlerhaften Übersetzungen. Darüber hinaus zeigen wir, dass das Qualitätskriterium auch Einfluss auf die Fehlerwahrnehmung hat. Unsere Ergebnisse zeigen, dass Verständnis und Angemessenheit von verschiedenen Bewertern gleichzeitig beurteilt werden können und somit Verständnis als wichtiges Qualitätskriterium und häufiger in menschliche Bewertungen einbezogen werden kann.', 'id': 'Kerja ini menggambarkan analisis alam dan penyebab kesalahan MT yang diperhatikan oleh evaluasi yang berbeda di bawah petunjuk dari kriteria kualitas yang berbeda: keperluan dan pemahaman dan campuran generik yang tidak dinyatakan keperluan dan lengkap. Kami melaporkan hasil untuk tiga pasangan bahasa dan dua domain dan 11 sistem MT. Penemuan kami menunjukkan bahwa dan meskipun beberapa fenomena yang dikenal bergantung pada domain dan/atau bahasa dan set fenomena berikut dapat dianggap sebagai secara umum menantang untuk sistem MT modern: mengubah frasa kelompok kata dan terjemahan dari kata sumber yang ambiguh dan menerjemahkan frasa nama dan salah terjemahan. Furthermore and we show that the quality criterion also has impact on error perception.  Penemuan kami menunjukkan bahwa pengertian dan keperluan dapat diperiksa secara bersamaan oleh evaluasi yang berbeda dan sehingga pengertian dan sebagai kriteria kualitas yang penting dan dapat termasuk lebih sering dalam evaluasi manusia.', 'fa': 'این کار تحلیل طبیعت و دلایل اشتباهی MT که توسط ارزیابکنندگان متفاوت در طبیعت مقدار کیفیت متفاوت مشخص می\u200cشود: قابلیت و درک و ترکیبی و ترکیب ژنرالی مشخص نیست. ما نتیجه\u200cهای سه جفت زبان و دو دومین و 11 سیستم متی گزارش می\u200cدهیم. نتیجه\u200cهای ما نشان می\u200cدهند که و با وجود این که بعضی از پدیده\u200cهای شناسایی بر دومین و/یا زبان بستگی دارند و مجموعه\u200cی پدیده\u200cهای زیر می\u200cتوانند به عنوان عمومی برای سیستم\u200cهای MT مدرن سخت بگیرند: مجموعه\u200cهای کلمات و ترجمه\u200cهای کلمات منبع بی\u200cنظیر و ترجمه\u200cهای اسم و ترجمه\u200cهای اشتبا علاوه بر این، ما نشان می دهیم که مقدار کیفیت همچنین بر نظر خطاها تاثیر می دهد. نتیجه\u200cهای ما نشان می\u200cدهند که درک و مناسب با همزمان توسط ارزیابی\u200cکنندگان مختلف می\u200cتواند ارزیابی کند و تا درک و یک مقدار کیفیت مهم باشد و اغلب در ارزیابی\u200cهای انسان شامل شود.', 'tr': 'Bu çalışma farklı kalite kriterilerinin doğruluğu altında observerilen MT hatalarının doğal ve nedenlerini tanımlıyor: yeteneklilik, anlama ve uyumluluk ve aklılık karıştırmayan bir jeneral karıştırımı. Biz üç dil çift we iki saha we on bir MT sistemasyna netijeleri baglaýarys. Biziň tapylyklarymyz şol diýip görkezilýän fenomenleriň käbirleri domena we/ýa dilinde baglanýandygyny we aşağıdaki fenomenleriň dünýä MT sistemalary üçin has baglanýar: sözlerniň toparyny täzeden, be ýiksiz çeşme sözleriniň terjimesini we aýry sözlerniň terjimesini we ýalňyş terjime edip bilýär. Munuň üçin ýöne hasaplanyň kriteriýasynyň ýalňyşlyk görnüşine etjek bolandygyny görkez. Çözgülerimiz düşünme we uyumluluğu farklı değerlendiriciler tarafından bir arada değerlendirilebilir diye düşünme ve önemli keyfiyet kriteriji hökmünde ve insan değerlendirmelerinde köplenç dahil edilebilir.', 'sw': 'Kazi hii inaelezea uchambuzi wa asili na sababu za makosa ya MT yaliyotajwa na watafiti tofauti kwa uongozi wa vigezo tofauti: usawa na ufanisi na tofauti usiotarajiwa na mchanganyiko wa kawaida wa usawa na ufanisi. Tunatoa taarifa matokeo kwa matatu ya lugha tatu na maeneo mawili na mfumo wa MT kumi na moja. Matokeo yetu yanaonyesha kuwa na licha ya ukweli kwamba baadhi ya mambo yaliyotambuliwa yanategemea ndani na/au lugha na mfululizo ifuatayo wa mambo yanaweza kuchukuliwa kama changamoto kwa mfumo wa hivi karibuni wa MT: kuvuruga makundi ya maneno na kutafsiri maneno yasiyo na matafsiri yasiyo ya kibiashara. Zaidi ya hayo na tunaonyesha kwamba kiwango cha ubora pia kinaathiri mtazamo wa makosa. Matokeo yetu yanaonyesha kuwa uhakika na usawa unaweza kuchunguzwa kwa wakati ule na watafiti tofauti na ili kuendelewa na kuwa kiwango muhimu cha ubora na unaweza kuingizwa mara nyingi katika tathmini za binadamu.', 'af': "Hierdie werk beskrywe analiseer van natuur en oorsaak van MT foute wat deur verskillende evalueerders aangesien word onder gids van verskillende kwaliteit kriteriërs: adekuasie en verstandigheid en 'n nie gespesifiseer generiese gemeng van adekuasie en fluiditeit. Ons rapporteer resultate vir drie taal paar en twee domeine en elf MT stelsels. Ons gevinde wys dat en ten ag van die feit dat sommige van die geïdentifiseerde fenomene afhang van domein en/of taal en die volgende stel van fenomene as gewoonlik pragtige vir moderne MT stelsels kan wees aangesien as gewoonlik pragtige vir moderne MT stelsels: herhaal groepe van woorde en vertaling van onbekende bron woorde en vertaling van noume frase en misvertalings. Verder en ons wys dat die kwaliteit kriterie ook invloek het op fout aanhouding. Ons bevestings wys dat verstandigheid en adekuateit kan eenmaal deur verskillende evalueerders uitgewerk word en sodat verstandigheid en as 'n belangrike kwaliteit kriterie en kan meer dikwels in menslike evalueringe ingesluit word.", 'sq': 'Ky punë përshkruan analizën e natyrës dhe shkakave të gabimeve të MT të vëzhguara nga vlerësuesit e ndryshëm nën udhëzimin e kritereve të ndryshme të cilësisë: përshtatshmërisë dhe kuptimit dhe një përzierje gjenerale jo të specifikuar të përshtatshmërisë dhe fluencës. Ne raportojmë rezultatet për tre çifte gjuhësh dhe dy fusha dhe 11 sisteme MT. Zbulimet tona tregojnë se dhe pavarësisht nga fakti se disa nga fenomenet e identifikuara varen nga domenia dhe/ose gjuha dhe grupi tjetër i fenomeneve mund të konsiderohen si përgjithësisht sfidues për sistemet moderne MT: rifreshimi i grupeve të fjalëve dhe përkthimi i fjalëve të burimit të dyshimtë dhe përkthimi i frazave dhe keqpërkthimeve të emrave. Përveç kësaj dhe ne tregojmë se kriteri i cilësisë ka ndikim gjithashtu në perceptimin e gabimeve. Zbulimet tona tregojnë se kuptimi dhe përshtatja mund të vlerësohen njëkohësisht nga vlerësues të ndryshëm dhe kështu që kuptimi dhe si një kriter i rëndësishëm cilësie dhe mund të përfshihet më shpesh në vlerësimet njerëzore.', 'ko': '이 작업은 서로 다른 품질 기준의 지도 아래 서로 다른 평가자가 관찰한 기계 번역 오류의 성질과 원인에 대한 분석: 충분성과 이해성, 그리고 충분성과 유창성의 비특정 통용 혼합을 묘사했다.우리는 세 쌍의 언어, 두 분야, 그리고 열한 개의 기계 번역 시스템의 결과를 보고했다.우리의 연구 결과에 의하면 이미 식별된 일부 현상은 분야와/또는 언어에 의존하지만 다음과 같은 현상은 현대 기계 번역 시스템에 있어 보통 도전적이다. 어구의 재해석, 잘못된 의미의 원어의 번역, 명사단어와 오역의 번역이다.그 밖에 우리는 품질 기준이 잘못된 감지에도 영향을 미치는 것을 발견했다.우리의 연구 결과에 따르면 이해와 충분성은 서로 다른 평가자가 동시에 평가할 수 있기 때문에 이해와 충분성은 중요한 품질 기준이 되고 인류 평가에 더 많이 포함될 수 있다.', 'hy': 'Այս աշխատանքը նկարագրում է MT սխալների բնույթի վերլուծությունը և պատճառները, որոնք հետևում են տարբեր գնահատողների կողմից տարբեր որակային հանգամանքների ուղղությամբ. հարմարավետությունը և հասկացությունը, ինչպես նաև բավարարության և հեղության առանց նշված ընդ Մենք զեկուցում ենք արդյունքներ երեք լեզվի զույգերի, երկու տիեզերքի և տասնմեկ MT համակարգի համար: Մեր հայտնաբերությունները ցույց են տալիս, որ և չնայած այն փաստին, որ որոշ հայտնաբերված երևույթներ կախված են տիեզերքից և (կամ) լեզվից, և հետևյալ երևույթները կարող են համարվում որպես ընդհանուր մարտահրավեր ժամանակակից MT համակարգերի համար. բառերի խմբերի վերաձևավորումը և երկիմաստ աղբյուր բառերի թարգ Furthermore and we show that the quality criterion also has impact on error perception.  Մեր հայտնաբերությունները ցույց են տալիս, որ հասկացությունը և բավարարությունը կարող են միաժամանակ գնահատվել տարբեր գնահատողների կողմից, որպեսզի հասկացությունը և որպես կարևոր որակի հանգամանք կարողանան ավելի հաճախ ներառվել մարդկային գնահատումներում:', 'az': 'Bu işlər müxtəlif keyfiyyət kriterilərinin doğruluğu altında MT xətalarının təbiəti və səbəblərinin analizini təsdiqləyir: uyğunluğu, anlaşılma və müəyyən edilməyən müxtəlif təsirlərin və təsirlərin qarışmasını təsdiqləyir. Biz üç dil çift, iki domen və on birinci MT sistemlərinin sonuçlarını bildiririk. Bizim tapındıqlarımız belə göstərir ki, bəzi tanınmış fenomenlərin domena və/ya dilə bağlı olduğu və indiki fenomenlərin dünya MT sistemlərinə çox çətin hesab edilir: sözlərin dəyişdirməsi, dəyişiklik mənbə sözlərin dəyişdirməsi və ismi sözlərin və yanlış tercümələrin dəyişdirməsi və dəyişikliklərin dəyişikliklərinə və yanlış tə Biz də xəta gözləməsinə səbəb olan keyfiyyət kriterisinin də etkisini göstəririk. Bizim tapılarımız belə göstərir ki, anlaşılma və uyğunluğu bir-birindən müxtəlif değerlendirənlər tərəfindən təmin edilə bilər və böyük ki, anlaşılma və möhüm keyfiyyət kriterisi olaraq insan değerlendirmələrinə daha çox daxil olar.', 'bn': 'এই কাজের বিভিন্ন মান নির্দেশের নির্দেশে বিভিন্ন মান নির্দেশের মাধ্যমে MT ত্রুটির বিশ্লেষণ এবং কারণের বিশ্লেষণের বর্ণনা করেছে: যথাযথ এবং সম্ আমরা তিন ভাষার জোড়া এবং দুই ডোমেন এবং ১১ এমটি সিস্টেমের ফলাফল রিপোর্ট করি। Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations.  এছাড়াও আমরা দেখাচ্ছি যে মানের মূল্যের মূল্য ত্রুটি দৃষ্টিভঙ্গিতে প্রভাব ফেলেছে। আমাদের আবিস্কার নির্দেশ দেয়া হয়েছে যে বিভিন্ন মূল্যবোধকারীদের একই সাথে সম্পূর্ণ এবং যথাযথভাবে মূল্যায়ন করা যাবে এবং যাতে তারা সম্পূর্ণ মান', 'bs': 'Ovaj rad opisuje analizu prirode i uzroke grešaka MT-a koje su promatrale različiti procjenatori pod uputstvom različitih kriterija kvalitete: adekvatnost i razumijevanje i ne određena generična mješavina adekvatnosti i tekućine. Prijavljujemo rezultate za tri jezička parova i dva domena i 11 MT sustava. Naši nalazi ukazuju na to da i uprkos činjenici da neki od identificiranih fenomena zavise od domena i/ili jezika i sljedećeg seta fenomena mogu smatrati općenito izazovnim za moderne MT sisteme: rephrasiranje grupa riječi i prevod ambigućih izvorskih riječi i prevod imenskih fraza i pogrešnih prevoda. Osim toga, pokazujemo da kriterij kvalitete također utječe na percepciju grešaka. Naši nalazi ukazuju na to da razumijevanje i adekvatnost mogu istovremeno procijeniti različiti procjenitelji i tako da razumijevanje i kao važan kriterij kvalitete i može se češće uključiti u ljudske procjene.', 'ca': "Aquesta feina descriu l'anàlisi de la naturalesa i les causes dels errors de MT observats per diferents evaluadors sota orientació de diferents criteris de qualitat: adequació i comprensió i una mezcla genèrica no especificada d'adequació i fluïtat. Informem resultats per tres parells de llengües, dos dominis i onze sistemes MT. Els nostres descobriments indiquen que, malgrat el fet que alguns dels fenomens identificats depenen del domini i/o del llenguatge, i que el següent conjunt de fenomens es poden considerar generalment desafiants per als sistemes MT moderns: reesformar grups de paraules i traduir paraules ambigues d'origen, traduir frases de nom i incorrectes traduccions. A més, i demostram que el criteri de qualitat també té impacte en la percepció d'errors. Els nostres descobriments indican que la comprensió i l'adequació poden ser evaluades simultàneament pels diferents evaluadors, de manera que la comprensió i com un criteri de qualitat important i que es pugui incloure més sovint en les evaluacions humanes.", 'et': 'Käesolevas töös kirjeldatakse erinevate hindajate poolt täheldatud MT vigade olemuse ja põhjuste analüüsi erinevate kvaliteedikriteeriumide järgi: piisavus ja arusaamine ning täpsustamata üldine piisavus ja sujuvus segu. Raporteerime kolme keelepaari ja kahe domeeni ning üheteistkümne MT süsteemi tulemused. Meie tulemused näitavad, et hoolimata asjaolust, et mõned tuvastatud nähtused sõltuvad domeenist ja/või keelest, võib tänapäevaste MT süsteemide jaoks üldiselt keeruliseks pidada järgmisi nähtusi: sõnarühmade ümbersõnastamine ja ebaselgete lähtesõnade tõlkimine ning substantiivlausete ja valetõlkimine. Lisaks näitame, et kvaliteedikriteerium mõjutab ka vigade tajumist. Meie tulemused näitavad, et mõistmist ja piisavust saavad hinnata samaaegselt erinevad hindajad ning et mõistmist ja olulist kvaliteedikriteeriumi saab sagedamini kaasata inimeste hindamistesse.', 'cs': 'Tato práce popisuje analýzu povahy a příčin chyb MT pozorovaných různými hodnotiteli pod vedením různých kritérií kvality: adekvátnosti a porozumění a neuvedené obecné směsi adekvátnosti a plynulosti. Podáváme výsledky pro tři jazykové páry a dvě domény a jedenáct MT systémů. Naše zjištění ukazují, že i přes skutečnost, že některé z identifikovaných jevů závisí na doméně a/nebo jazyce a následující soubor jevů lze považovat za obecně náročnou pro moderní MT systémy: přeformulování skupin slov a překlad nejednoznačných zdrojových slov a překlad podstatných frází a chybných překladů. Dále ukazujeme, že kritérium kvality má vliv i na vnímání chyb. Naše zjištění ukazují, že porozumění a adekvátnost mohou být posuzovány současně různými hodnotiteli, a tak porozumění a jako důležité kritérium kvality a mohou být častěji zahrnuty do hodnocení lidí.', 'am': 'ይህ ሥራ የሥርዓት እና የMT ስህተቶችን በማስተካከል በተለያዩ ብልሃት ክፍተቶችን በሚገልጹ አካባቢዎች፣ ትክክል እና ትክክል እና የተለየ የብሔራዊ ግንኙነት እና ፍጥረት ያላቸው የውጤት ግንኙነት ነው፡፡ የሦስት ቋንቋ ሁለት ዶሜን እና አሥራ አንድ MT ስርዓቶች ፍሬዎችን እናስታውሳለን፡፡ ፍላጎታችን እና ምንም እንኳን የተታወቁት ነገር ከዶሜን እና/ወይም ቋንቋ ላይ ተደላደዋል፣ እና በሚከተሉት የአሁኑን አዲስ ጉዳይ የMT ስርዓቶች መቆጣጠር ይችላል፡፡ ከዚህም በላይ እናሳያቸዋለን፡፡ ፍጥረታችን በተለያዩ አስተዋዮች እና የጥቅልነት ማሰናከል እንዲችል እና ማሰናከል ትክክለኛ ጥያቄ እንዲሆን እና ብዙ ጊዜ በሰው ማስታወቂያ ውስጥ እንዲጨመር ይችላል፡፡', 'fi': 'Tässä työssä kuvataan eri arvioijien havaitsemien MT-virheiden luonnetta ja syitä erilaisten laatukriteerien perusteella: riittävyys ja ymmärtäminen sekä määrittelemätön yleinen sekoitus riittävyyttä ja sujuvuutta. Raportoimme tulokset kolmesta kieliparista ja kahdesta verkkotunnuksesta sekä yhdestätoista MT-järjestelmästä. Löydöksemme osoittavat, että vaikka osa tunnistetuista ilmiöistä riippuu toimialueesta ja/tai kielestä, seuraavat ilmiöt voidaan pitää yleisesti haastavina nykyaikaisille MT-järjestelmille: sanaryhmien uudelleenmuotoileminen ja moniselitteisten lähdesanojen kääntäminen sekä substantiivilausumien ja käännösten kääntäminen. Lisäksi osoitamme, että laatukriteerillä on vaikutusta myös virheiden havaitsemiseen. Tuloksemme osoittavat, että eri arvioijat voivat arvioida ymmärrystä ja riittävyyttä samanaikaisesti ja että ymmärrys ja tärkeä laatukriteeri voidaan sisällyttää useammin ihmisten arviointeihin.', 'jv': 'Ngomongé iki dadi ngabah dadi pancening pribadia karo akeh pancening akeh MT sing paling nggawe barang nggawe dolanan karo akeh cualiter sing dipenekno: adalah karo akeh luwih apik lan akeh sampeyan karo akeh werak nggawe ketemus Awak dhéwé ngertukno sistem telu kanggo kelas karo saben karo sistem sing luwih MT. Kita mbubuturan punika dipuangkap lan nganggep nglanggar sapa kerung ing langgar sampeyan ginaluk tentang karo domain lan/obang langgar sampeyan nganggep sistem sing beraksi yang karo nggawe sistem MT modèrn: winih dhuwur kapungkur ketoleh nggawe kelangan kelangan lan tarjamahan kelangan langgar sampeyan ingkang berarti. Label Awak dhéwé éngak dhéwé ngerasah akeh luwih lan kabèh dumadhi iki dadi, nik awak dhéwé éngak dhéwé kuwi nggawe geraksé perusahaan lan alam-alam sing dikarak kalite wajén lan iso dianggawe nguasah luwih apik dhéwé.', 'sk': 'V delu je opisana analiza narave in vzrokov napak v MT, ki so jih opazili različni ocenjevalci pod vodstvom različnih meril kakovosti: ustreznosti in razumevanja ter nedoločene splošne mešanice ustreznosti in tekočosti. Poročamo rezultate za tri jezikovne pare in dve domeni ter enajst sistemov MT. Naše ugotovitve kažejo, da so nekateri od ugotovljenih pojavov odvisni od domene in/ali jezika, naslednji sklop pojavov pa je za sodobne sisteme MT na splošno izziv: preoblikovanje skupin besed in prevajanje dvoumnih izvornih besed ter prevajanje samostalnih stavkov in napačnih prevodov. Poleg tega pokažemo, da merilo kakovosti vpliva tudi na zaznavanje napak. Naše ugotovitve kažejo, da lahko razumevanje in ustreznost ocenjujejo hkrati različni ocenjevalci, tako da je razumevanje in kot pomembno merilo kakovosti mogoče pogosteje vključiti v ocenjevanje ljudi.', 'ha': "Wannan aikin yana bayyana anayyar masu natsuwa da sababin errors na MT da aka gani dabam-evaluated daban a shiryarwa masu nau'i daban-nau'i: daidaici da Compression da kuma wata ba'a ƙayyade komai mai daidaita da fassara. Munã sanar da matsala ta ga nau'i uku cikin harshen sau biyu da sau biyu da tsarin MT guda gõma. FantayinMu na nuna cewa, kuma kõ da da gaske da wasu abu wanda aka gane ta yana dõgara kan duk da ke da/ko harshen, da kuma an gane wasu abubuwa da ke ƙaranci kamar wata ƙulli wa tsarin MT na yanzu: re-haramtar jama'a na magana da translation of sources ambiguous sources and translate non-magana and mistranslation. Furan haka, ko da Muke nũna cewa tsakanin gaskiya sun shagala kan gannai ɓata. FantayinMu na bayani kawai, za'a iya ƙaddara Compression da gwargwadon su sami da waɗan can mãsu ƙaddara, sabõda haka, Compression da kima mai muhimu, kuma za a shigar da su a ƙari mafi yawa a cikin ƙaddara mutum.", 'bo': 'This work describes analysis of nature and causes of MT errors observed by different evaluators under guidance of different quality criteria: adequacy and comprehension and a not specified generic mixture of adequacy and fluency. ང་ཚོས་སྐད་ཡིག་གི་ཆ་གཅིག་དང་ཆ་མཚུངས་གཉིས་དང་མ་ལག་འཁྱེར་བཅུ་གཅིག་གཅིག་གི་གྲངས་འབོར་བ་རེད། Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and mistranslation. ད་དུང་། ང་ཚོས་རང་བཞིན་གནས་སྟངས་ལ་རྐྱེན་ཚད་ཀྱང་ནོར་འཁྲུལ་བསམ་བྱེད་སྐབས་ཀྱང་ཡོད། ང་ཚོའི་མཐོང་སྣང་གིས་ཡོད་ཚད་ལྡན་རིམ་པ་མི་འདྲ་བ་གཉིས་ཀྱིས་ཕལ་རྟོན་བྱེད་ན།', 'he': 'העבודה הזאת מתארת ניתוח של הטבע והסיבות של טעויות MT שמוצאות על ידי מערכים שונים תחת ההנחה של קריטורים איכותיים שונים: מתאימות והבינה ולערבות גנרלית לא מוגדרת של מתאימות ונוזלת. We report results for three language pairs and two domains and eleven MT systems.  Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems: rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations.  בנוסף, ואנחנו מראים שהקריטוריון האיכות גם משפיע על התפיסה של טעויות. הממצאים שלנו מצביעים שהבינה והמתאימות יכולות להעריך באותו זמן על ידי מערכים שונים וכך הבנה וכקריטוריון איכות חשוב ויכול להיות כולל לעתים קרובות יותר בערכות אנושיות.'}
{'en': 'Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation', 'ar': 'دراسة تأثير سياق مستوى المستند على الترجمة الآلية العصبية المتزامنة', 'es': 'Estudio del impacto del contexto a nivel de documento en la traducción automática neuronal simultánea', 'fr': "Étude de l'impact du contexte au niveau du document sur la traduction automatique neuronale simultanée", 'pt': 'Estudando o impacto do contexto em nível de documento na tradução automática neural simultânea', 'ja': '同時神経機械翻訳における文書レベルの文脈の影響の研究', 'zh': '治文档级上下文同声神经机器翻译', 'ru': 'Изучение влияния контекста на уровне документа на синхронный нейронный машинный перевод', 'hi': 'एक साथ तंत्रिका मशीन अनुवाद पर दस्तावेज़-स्तर के संदर्भ के प्रभाव का अध्ययन करना', 'ga': 'Staidéar ar Thionchar Comhthéacs Leibhéal Doiciméad Ar Aistriú Inneall Néarach Comhuaineach', 'ka': 'Comment', 'hu': 'Dokumentumszintű kontextus hatásának tanulmányozása az egyidejű neurális gépi fordításra', 'el': 'Μελέτη του αντίκτυπου του πλαισίου σε επίπεδο εγγράφου στην ταυτόχρονη νευρωνική μηχανική μετάφραση', 'it': "Studio dell'impatto del contesto a livello di documento sulla traduzione automatica neurale simultanea", 'lt': 'Dokumentų lygmens konteksto poveikio vienu metu vertimui nervinėmis mašinomis tyrimas', 'kk': 'Құжат деңгейіндегі контексті бірнеше неврал машинаның аудармасында оқу', 'ml': 'ഒരേ സമയത്ത് നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതില്\u200d രേഖന- നിലപാടിന്റെ പ്രഭാവം പഠിക്കുന്നു', 'mt': 'Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation', 'mn': 'Документын түвшинд нөлөө үзүүлэлтийг судалж байлаа.', 'no': 'Studerer kontekst for dokumentnivået «Impact of Document Level» på simultane neural machine translation', 'pl': 'Badanie wpływu kontekstu na poziomie dokumentu na jednoczesne tłumaczenie maszynowe neuronowe', 'ro': 'Studiul impactului contextului la nivel de document asupra traducerii automate neurale simultane', 'sr': 'Proučavajući utjecaj na nivo dokumenta na istovremeno neurološki prevod', 'mk': 'Истражување на влијанието на контекстот на нивото на документот на симултанеозна превод на неврална машина', 'si': 'Name', 'so': 'Waxbarashada The Impact of Document-level Context On Simultaneous Neural machine Translation', 'ms': 'Mempelajari Kesan Konteks Aras Dokumen Pada Terjemahan Mesin Neural Sementara', 'sv': 'Studier av konsekvenserna av dokument-nivå kontext på samtidig neural maskinöversättning', 'ta': 'Comment', 'ur': 'سنگت-سطح کانٹکسٹ کے اثرات کا تحقیق کرتا ہے سیمالٹ نائرل ماشین ترجمہ پر', 'uz': 'Name', 'vi': 'Nghiên cứu Tác dụng của ngữ cảnh Tài liệu về phiên dịch thần kinh đồng thời', 'nl': 'Onderzoek naar de impact van context op documentniveau op simultaane neuronale machinevertaling', 'hr': 'Proučavajući utjecaj na razinu dokumenta na istodobno neurološkom prevodu strojeva', 'da': 'Undersøgelse af konsekvenserne af dokumentniveau kontekst på samtidig neural maskinoversættelse', 'bg': 'Изследване на въздействието на контекста на ниво документ върху едновременния неврален машинен превод', 'id': 'Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation', 'sw': 'Kusoma Impact of Document-level On Simultaneous Mashine ya Neural Translation', 'de': 'Untersuchung der Auswirkungen von Kontext auf Dokumentenebene auf simultane neuronale maschinelle Übersetzung', 'ko': '문서급 언어 환경이 신경 네트워크 기계 번역에 미친 영향을 연구하다', 'fa': 'تحقیق اثر سطح سند در ترجمه ماشین عصبی شبیه', 'af': 'In studeer die Impact van Dokument- vlak Konteks op Simuleerde Neurale Masjien Vertaling', 'sq': 'Studimi i ndikimit të kontekstit të nivelit të dokumentit në përkthimin e njëkohëshëm të makinës nervore', 'tr': 'Sened derejesiniň etkisini öwrenýär', 'bn': 'একই সাথে নিউরেল মেশিন অনুবাদে ডকুমেন্ট- স্তরের প্রভাব পড়া হচ্ছে', 'hy': 'Հետազոտությունը փաստաթղթի մակարդակի կոնտեքստի ազդեցության վրա', 'bs': 'Proučavajući utjecaj na nivo dokumenta na istovremeno neurološki prevod', 'am': 'Document-level Context On Simultaneous Neural Machine translation', 'az': 'D…Щst…Щ s…Щviyy…Щsinin Impact of Document-level Context On Similar Neural Machine Translation', 'cs': 'Studium vlivu kontextu na úrovni dokumentů na simultánní neuronový strojový překlad', 'fi': 'Asiakirjatason kontekstin vaikutuksen tutkiminen samanaikaiseen neurokääntämiseen', 'ca': "Estudiar l'impacte del context a nivell de documentació en la traducció simultànea de màquines neurones", 'et': 'Dokumenditaseme konteksti mõju uurimine samaaegsele neuroaalsele masintõlkele', 'jv': 'Ngawe Iwuh-ingkang The Effect of document-evel context Nang Simultaneous Neral Mas Terjamahan', 'ha': 'KCharselect unicode block name', 'sk': 'Preučevanje vpliva konteksta na ravni dokumenta na sočasno nevronsko strojno prevajanje', 'bo': 'རྩོམ་ལ་ཞིབ་བྱེད་ཀྱི་ཡིག་ཆ་གྱི་གནས་ཚུལ་ཁོངས་དང་བསྟུན་ནས་བློ་གཏོང་བ', 'he': 'Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation'}
{'en': 'In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality. In simultaneous translation settings and the context from previous sentences should be even more critical. To this end and in this paper and we propose wait-k simultaneous document-level NMT where we keep the context encoder as it is and replace the source sentence encoder and target language decoder with their wait-k equivalents. We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality. We then perform an analysis of the translations obtained using our models by focusing on sentences that should benefit from the context where we found out that the model does and in fact and benefit from context but is unable to effectively leverage it and especially in a low-resource setting. This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'ar': 'في إعداد الترجمة الفورية في الوقت الفعلي ونماذج الترجمة الآلية العصبية (NMT) تبدأ في إنشاء رموز اللغة المستهدفة من جمل لغة المصدر غير المكتملة وتجعلها أكثر صعوبة في الترجمة مما يؤدي إلى ضعف جودة الترجمة. أظهر البحث السابق أن NMT على مستوى المستند ويتألف من ترميز الجملة والسياق ووحدة فك ترميز ويستفيد من السياق من الجمل المجاورة ويساعد على تحسين جودة الترجمة. في إعدادات الترجمة الفورية والسياق من الجمل السابقة يجب أن يكون أكثر أهمية. تحقيقا لهذه الغاية وفي هذه الورقة ، نقترح NMT على مستوى المستند المتزامن الانتظار k حيث نحتفظ بمشفر السياق كما هو ونستبدل مشفر الجملة المصدر وفك تشفير اللغة الهدف بمكافئات الانتظار k. نجرب إعدادات الموارد المنخفضة والعالية باستخدام مجموعة ALT و OpenSubtitles2018 وحيث نلاحظ تحسينات طفيفة في جودة الترجمة. نقوم بعد ذلك بتحليل الترجمات التي تم الحصول عليها باستخدام نماذجنا من خلال التركيز على الجمل التي يجب أن تستفيد من السياق حيث اكتشفنا أن النموذج يستفيد من السياق ولكنه في الواقع غير قادر على الاستفادة منه بشكل فعال وخاصة في إعداد الموارد. وهذا يدل على أن هناك حاجة لمزيد من الابتكار في الطريقة التي يتم بها تحديد السياق المفيد والاستفادة منه.', 'fr': "Dans un environnement de traduction simultanée en temps réel et de traduction automatique neuronale (NMT), les modèles commencent à générer des jetons de langue cible à partir de phrases de langue source incomplètes, ce qui les rend plus difficiles à traduire et entraîne une mauvaise qualité de traduction. Des recherches antérieures ont montré que la NMT au niveau du document, composée de codeurs de phrases et de contextes et d'un décodeur, exploite le contexte des phrases voisines et contribue à améliorer la qualité de la traduction. Dans les configurations de traduction simultanée et le contexte des phrases précédentes devraient être encore plus critiques. À cette fin et dans cet article, nous proposons la NMT simultanée wait-k au niveau du document où nous conservons l'encodeur de contexte tel qu'il est et remplaçons l'encodeur de phrase source et le décodeur de langue cible par leurs équivalents wait-k. Nous expérimentons des paramètres de ressources faibles et élevées à l'aide des corpus ALT et OpenSubtitles2018 et nous observons des améliorations mineures de la qualité de la traduction. Nous effectuons ensuite une analyse des traductions obtenues à l'aide de nos modèles en nous concentrant sur les phrases qui devraient bénéficier du contexte dans lequel nous avons découvert que le modèle le fait et qu'il bénéficie effectivement du contexte mais qu'il est incapable de l'exploiter efficacement, en particulier dans un environnement à faibles ressources. Cela montre qu'il est nécessaire d'innover davantage dans la manière dont le contexte utile est identifié et exploité.", 'pt': 'Em uma configuração de tradução simultânea em tempo real e os modelos de tradução automática neural (NMT) começam a gerar tokens de idioma de destino a partir de frases incompletas do idioma de origem e dificultam a tradução e levam a uma má qualidade de tradução. Pesquisas anteriores mostraram que o NMT em nível de documento e composto por codificadores de frases e contexto e um decodificador aproveita o contexto de frases vizinhas e ajuda a melhorar a qualidade da tradução. Em configurações de tradução simultânea e o contexto de frases anteriores deve ser ainda mais crítico. Para este fim e neste artigo propomos NMT em nível de documento simultâneo wait-k onde mantemos o codificador de contexto como está e substituímos o codificador de sentença de origem e o decodificador de idioma de destino por seus equivalentes wait-k. Experimentamos configurações de recursos baixos e altos usando os corpora ALT e OpenSubtitles2018 e observamos pequenas melhorias na qualidade da tradução. Em seguida, realizamos uma análise das traduções obtidas usando nossos modelos, focando em frases que deveriam se beneficiar do contexto onde descobrimos que o modelo o faz e de fato e se beneficia do contexto, mas é incapaz de aproveitá-lo efetivamente e especialmente em um configuração de recursos. Isso mostra que há necessidade de mais inovação na forma como o contexto útil é identificado e aproveitado.', 'es': 'En una configuración de traducción simultánea en tiempo real y los modelos de traducción automática neuronal (NMT) comienzan a generar tokens de idioma de destino a partir de oraciones incompletas en el idioma de origen, lo que dificulta su traducción y conduce a una mala calidad de traducción. Investigaciones anteriores han demostrado que la NMT a nivel de documento y que comprende codificadores de oraciones y contexto y un decodificador, aprovecha el contexto de las oraciones vecinas y ayuda a mejorar la calidad de la traducción. En los entornos de traducción simultánea y el contexto de las oraciones anteriores debería ser aún más crítico. Con este fin y en este artículo, proponemos wait-k simultaneo NMT a nivel de documento donde mantenemos el codificador de contexto como está y reemplazamos el codificador de oraciones fuente y el decodificador del idioma de destino por sus equivalentes wait-k. Experimentamos con configuraciones de recursos altos y bajos utilizando los corpus ALT y OpenSubtitles2018 y observamos mejoras menores en la calidad de la traducción. Luego realizamos un análisis de las traducciones obtenidas utilizando nuestros modelos, centrándonos en oraciones que deberían beneficiarse del contexto en el que descubrimos que el modelo sí lo hace y, de hecho, se beneficia del contexto, pero no puede aprovecharlo de manera efectiva y especialmente en un entorno de bajos recursos. Esto demuestra que es necesaria una mayor innovación en la forma en que se identifica y se aprovecha el contexto útil.', 'ja': 'リアルタイムの同時翻訳設定では、ニューラル機械翻訳（ NMT ）モデルは、不完全なソース言語文からターゲット言語トークンを生成し始め、翻訳を難しくし、翻訳品質を低下させます。 以前の研究では、文書レベルのNMTは、文およびコンテキストエンコーダとデコーダから構成され、隣接する文からのコンテキストを活用し、翻訳品質の向上に役立つことが示されています。 同時翻訳設定では、前の文章からのコンテキストがさらに重要になるはずです。 そのために、そして本稿では、コンテキストエンコーダをそのまま保持し、ソース文エンコーダとターゲット言語デコーダをそのWait - k相当物に置き換える、wait - k同時ドキュメントレベルのNMTを提案する。 ALTおよびOpenSubtitles 2018コーラを使用して低および高リソース設定を実験し、翻訳品質のわずかな改善を観察しました。 次に、モデルが実際に存在し、文脈から恩恵を受けているはずの文に焦点を当てて、モデルを使用して得られた翻訳の分析を行いますが、特に低資源環境では効果的に活用することができません。 これは、有用なコンテキストが特定され、活用される方法にさらなる革新が必要であることを示しています。', 'zh': '实时同声传译设神经机器翻译(NMT)模形中,始生于不完之源语言句,使译者更难而译者差。 前论明白,文档级NMT句上下文编码器及解码器,因邻句之上下文,助重译质。 同声传译置中,前数句上下文宜益要。 是以wait-k同时文档级NMT,上下文编码器其故,以源句编码器与言解码器易其wait-k等效项。 试ALT、OpenSubtitles2018语料库低资源、高资,观译者之量稍重。 然后因上下文之句以析其所得之译,见其诚而实受其上下文,而无效而用之,尤在匮乏之间。 明于定用有用之方,须更创新。', 'hi': 'एक वास्तविक समय में एक साथ अनुवाद सेटिंग और तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल अपूर्ण स्रोत भाषा वाक्यों से लक्ष्य भाषा टोकन उत्पन्न करना शुरू करते हैं और उन्हें अनुवाद करने के लिए कठिन बनाते हैं और खराब अनुवाद की गुणवत्ता के लिए अग्रणी होते हैं। पिछले शोध से पता चला है कि दस्तावेज़-स्तर एनएमटी और वाक्य और संदर्भ एन्कोडर और एक डिकोडर और पड़ोसी वाक्यों से संदर्भ का लाभ उठाता है और अनुवाद की गुणवत्ता में सुधार करने में मदद करता है। एक साथ अनुवाद सेटिंग्स में और पिछले वाक्यों से संदर्भ और भी अधिक महत्वपूर्ण होना चाहिए। इस अंत में और इस पेपर में और हम प्रतीक्षा-कश्मीर एक साथ दस्तावेज़-स्तर एनएमटी का प्रस्ताव करते हैं जहां हम संदर्भ एन्कोडर को रखते हैं और स्रोत वाक्य एन्कोडर और लक्ष्य भाषा विकोडक को उनके प्रतीक्षा-के समकक्षों के साथ बदलते हैं। हम ALT और OpenSubtitles2018 corpora का उपयोग करके कम और उच्च संसाधन सेटिंग्स के साथ प्रयोग करते हैं और जहां हम अनुवाद की गुणवत्ता में मामूली सुधार देखते हैं। फिर हम उन वाक्यों पर ध्यान केंद्रित करके अपने मॉडल का उपयोग करके प्राप्त अनुवादों का विश्लेषण करते हैं जो उस संदर्भ से लाभान्वित होना चाहिए जहां हमें पता चला कि मॉडल करता है और वास्तव में और संदर्भ से लाभ उठाता है लेकिन प्रभावी ढंग से इसका लाभ उठाने में असमर्थ है और विशेष रूप से कम संसाधन सेटिंग में। इससे पता चलता है कि उपयोगी संदर्भ की पहचान और लाभ उठाने के तरीके में आगे नवाचार की आवश्यकता है।', 'ru': 'В режиме реального времени одновременная настройка перевода и модели нейронного машинного перевода (НМП) начинают генерировать токены целевого языка из неполных предложений на исходном языке, что затрудняет их перевод и приводит к низкому качеству перевода. Предыдущие исследования показали, что NMT на уровне документа, состоящий из кодировщиков предложений и контекста и декодера, использует контекст из соседних предложений и помогает улучшить качество перевода. В условиях синхронного перевода и контекст из предыдущих предложений должен быть еще более критичным. С этой целью и в этой статье и мы предлагаем wait-k одновременно на уровне документа NMT, где мы сохраняем кодировщик контекста в его нынешнем виде и заменяем кодировщик исходного предложения и декодер целевого языка их эквивалентами wait-k. Мы экспериментируем с низкими и высокими настройками ресурсов с помощью корпусов ALT и OpenSubtitles2018, где мы наблюдаем незначительные улучшения в качестве перевода. Затем мы выполняем анализ переводов, полученных с использованием наших моделей, сосредоточиваясь на предложениях, которые должны извлекать выгоду из контекста, в котором мы обнаружили, что модель действительно и на самом деле извлекает выгоду из контекста, но не в состоянии эффективно использовать его, и особенно в условиях ограниченных ресурсов. Это свидетельствует о необходимости дальнейших инноваций в том, как определяется и используется полезный контекст.', 'ga': 'I suíomh fíor-ama aistriúcháin chomhuainigh agus samhlacha néar-aistriúcháin meaisín (NMT) tosaíonn ag giniúint comharthaí sprioctheanga ó abairtí neamhiomlána sa teanga foinse agus é a dhéanamh níos deacra iad a aistriú agus a mbíonn droch-chaighdeán aistriúcháin mar thoradh orthu. Tá sé léirithe ag taighde a rinneadh roimhe seo go bhfuil NMT ag leibhéal doiciméad comhdhéanta d’ionchódóirí abairtí agus comhthéacs agus díchódóir agus go n-úsáidtear comhthéacs ó abairtí comharsanacha agus go gcuidíonn sé le cáilíocht an aistriúcháin a fheabhsú. I suíomhanna aistriúcháin chomhuainigh agus ba cheart go mbeadh an comhthéacs ó abairtí roimhe seo níos tábhachtaí fós. Chuige sin agus sa pháipéar seo agus molaimid wait-k comhuaineach leibhéal doiciméad NMT áit a gcoimeádaimid an t-ionchódóir comhthéacs mar atá sé agus a chur in ionad an ionchódóra abairt foinse agus díchódóir sprioctheanga lena coibhéisí fanacht-k. Déanaimid tástáil ar shocruithe acmhainní ísle agus ard ag baint úsáide as corpora ALT agus OpenSubtitles2018 agus áit a bhreathnaímid ar mhionfheabhsuithe ar cháilíocht an aistriúcháin. Déanaimid ansin anailís ar na haistriúcháin a fhaightear ag baint úsáide as ár múnlaí trí dhíriú ar abairtí ar cheart leas a bhaint as an gcomhthéacs ina bhfuaireamar amach go mbaineann an tsamhail agus go deimhin agus go mbaineann sé leas as comhthéacs ach nach bhfuil sé in ann í a ghiaráil go héifeachtach agus go háirithe i gcomhthéacs íseal. socrú acmhainní. Léiríonn sé seo go bhfuil gá le tuilleadh nuálaíochta maidir leis an mbealach a shainaithnítear agus a ghiaráiltear comhthéacs úsáideach.', 'hu': 'A valós idejű szimultán fordítási beállítás és az idegi gépi fordítás (NMT) modellek elkezdenek célnyelvi tokeneket generálni a hiányos forrásnyelvi mondatokból, és nehezebbé teszik a fordításukat, és rossz fordítási minőséghez vezetnek. Korábbi kutatások kimutatták, hogy dokumentumszintű NMT, amely mondat- és kontextuskódolókból és dekódolókból áll, és kihasználja a kontextust a szomszédos mondatokból, és segít javítani a fordítási minőséget. Az egyidejű fordításban a beállításoknak és az előző mondatok kontextusának még kritikusabbnak kell lenniük. Ebből a célból és ebben a tanulmányban javasoljuk a wait-k egyidejű dokumentumszintű NMT-t, ahol a kontextuskódolót így tartjuk meg, és a forráskódolót és a célnyelv dekódolót a wait-k egyenértékűekkel cseréljük ki. Alacsony és magas erőforrás-beállításokkal kísérletezünk az ALT és az OpenSubtitles2018 korpusokkal, ahol kisebb javulást figyelünk meg a fordítási minőségben. Ezután elemzést végzünk a modelleinkkel kapott fordításokról azzal, hogy olyan mondatokra összpontosítunk, amelyeknek hasznosnak kell lenniük abban a kontextusban, ahol kiderült, hogy a modell valójában és hasznosnak kell lenniük a kontextusból, de nem képes hatékonyan kihasználni azt, különösen alacsony erőforrásokkal rendelkező környezetben. Ez azt mutatja, hogy további innovációra van szükség a hasznos összefüggések azonosításának és kihasználásának módjában.', 'el': 'Σε μια ρύθμιση ταυτόχρονης μετάφρασης σε πραγματικό χρόνο και μοντέλα νευρωνικής μηχανικής μετάφρασης (ΝΜΤ) αρχίζουν να παράγουν μάρκες γλώσσας-στόχου από ελλιπείς προτάσεις γλώσσας προέλευσης, καθιστώντας τις πιο δύσκολες στη μετάφραση και οδηγώντας σε κακή ποιότητα μετάφρασης. Προηγούμενες έρευνες έχουν δείξει ότι το NMT σε επίπεδο εγγράφου και αποτελείται από κωδικοποιητές προτάσεων και περιβάλλοντος και έναν αποκωδικοποιητή και αξιοποιεί το πλαίσιο από γειτονικές προτάσεις και συμβάλλει στη βελτίωση της ποιότητας της μετάφρασης. Στην ταυτόχρονη μετάφραση οι ρυθμίσεις και το πλαίσιο από προηγούμενες προτάσεις θα πρέπει να είναι ακόμα πιο κρίσιμες. Για το σκοπό αυτό και σε αυτή την εργασία και προτείνουμε να κρατήσουμε τον κωδικοποιητή περιβάλλοντος όπως είναι και να αντικαταστήσουμε τον κωδικοποιητή πρότασης πηγής και τον αποκωδικοποιητή γλώσσας προορισμού με τα ισοδύναμά τους wait-k. Πειραματιζόμαστε με χαμηλές και υψηλές ρυθμίσεις πόρων χρησιμοποιώντας τα σώματα και παρατηρούμε μικρές βελτιώσεις στην ποιότητα της μετάφρασης. Στη συνέχεια, διενεργούμε μια ανάλυση των μεταφράσεων που αποκτήθηκαν χρησιμοποιώντας τα μοντέλα μας εστιάζοντας σε προτάσεις που θα πρέπει να ωφεληθούν από το πλαίσιο όπου διαπιστώσαμε ότι το μοντέλο το κάνει και στην πραγματικότητα ωφελείται από το πλαίσιο αλλά δεν είναι σε θέση να το αξιοποιήσει αποτελεσματικά και ειδικά σε ένα περιβάλλον με χαμηλούς πόρους. Αυτό δείχνει ότι υπάρχει ανάγκη για περαιτέρω καινοτομία στον τρόπο με τον οποίο προσδιορίζεται και αξιοποιείται το χρήσιμο πλαίσιο.', 'ka': 'სინამდვილეში სინამდვილეში ერთადერთი განგორმაცია და ნეიროლური მანქანის განგორმაცია (NMT) მოდელები დავიწყებენ მისაწყარო ენის სინამდვილეების სინამდვილეების შექმნა, რომლებიც არაფრძ წინა შესწავლობა გამოჩვენეთ, რომ დოკუმენტის დოკუმენტის NMT და კონტექსტის კონტექსტის კონტექსტის კონტექსტის შესახებ და კონტექსტის კონტექსტის გამოყ ერთადერთი შეტყობინებების პარამეტრებში და წინა შეტყობინებების კონტექსტი უფრო კრიტიკური უნდა იყოს. ამ დასავლეთში და ამ დოკუმენტში და ჩვენ დავიწყებთ wait-k სუმრანური დოკუმენტის NMT დოკუმენტის კონტექსტის კოდენტიკოდერს, როგორც ის არის, და დავცვლეთ წიგნის კოდენტიკოდერს და მისავლელი ჩვენ ექსპერიმენტისთვის მარტივი და მარტივი რესურსის პარამეტრებით, რომელიც ALT და OpenSubtitles2018 კოპორაში გამოყენებთ და რომელიც ჩვენ დავხედავთ ცოტა უფრო შემდეგ ჩვენ ვაკეთებთ მოდელების გამოყენებით ანალიზი, რომლებიც კონტექსტიდან უნდა გამოიყენება, რომლებიც მოდელი იქნება და ფაქტიურად და კონტექსტიდან გამოიყენება, მაგრამ არ შეიძლება ეფექტიურად ამო ეს ჩვენებს, რომ უფრო მნიშვნელოვანი კონტექსტის გამოყენება და გამოყენება უფრო მნიშვნელოვანი ინონოციაცია.', 'it': "In un'impostazione di traduzione simultanea in tempo reale e modelli di traduzione automatica neurale (NMT) iniziano a generare token della lingua di destinazione da frasi incomplete della lingua di origine, rendendole più difficili da tradurre e portando a una scarsa qualità della traduzione. Ricerche precedenti hanno dimostrato che NMT a livello di documento, composto da encoder di frasi e contesto e da un decoder, sfrutta il contesto dalle frasi vicine e aiuta a migliorare la qualità della traduzione. Nelle impostazioni di traduzione simultanea e il contesto delle frasi precedenti dovrebbe essere ancora più critico. A tal fine e in questo articolo proponiamo NMT simultaneo a livello di documento wait-k dove teniamo l'encoder di contesto così com'è e sostituiamo l'encoder di frase sorgente e il decoder della lingua di destinazione con i loro equivalenti wait-k. Sperimentiamo con impostazioni di risorse basse e alte utilizzando i corpora ALT e OpenSubtitles2018 e dove osserviamo piccoli miglioramenti nella qualità della traduzione. Eseguiamo quindi un'analisi delle traduzioni ottenute utilizzando i nostri modelli concentrandoci su frasi che dovrebbero beneficiare del contesto in cui abbiamo scoperto che il modello fa e di fatto beneficia del contesto ma non è in grado di sfruttarlo efficacemente e soprattutto in un contesto a basso consumo di risorse. Ciò dimostra la necessità di ulteriori innovazioni nel modo in cui viene identificato e valorizzato il contesto utile.", 'kk': 'Шын уақытта бірдей аудару параметрлері мен невралдық компьютердің аударуы (NMT) үлгілерінде нақты тіл белгілерін толық тіл сөздерінен құрып, оларды аудару және аудару сапатына көп қысқартуға болады. Алдыңғы зерттеу NMT құжат деңгейіндегі және мәтін, контексті кодерлердің, соңғы сөздерден контексті декодерлеу және деңгейіндегі мәтінді жасап, аудармалардың сапатын жақсарту Бірақ аудармалы параметрлерде және алдыңғы сөздердің контексті артық болу керек. Бұл соңында және осы қағаздың күту-k деңгейінде NMT құжаттың деңгейінде контексті кодтамасын қалдырып, көзі сөздің кодтамасын және мақсатты тілдің кодтамасын күту-k эквиваленттерімен алмастырып, кү Біз ALT және OpenSubtitles 2018 корпорасын қолдану үшін төмен және жоғары ресурс параметрлерін тәжірибелеміз. Ол жерде аудармалардың сапасында кішкентай жақсартуларын қараймыз. Содан кейін, моделдерімізді қолдану үлгілерімізде алған аудармаларды анализ істеп, үлгісінің көмегінен шындықтан және контекстіктен шындықтан шындықтан жұмыс істейтін мәліметтерге назар аударып, өзгертілген мәліметтер Бұл пайдалы контексті анықтау және қолдану үшін қосымша инновациялардың қажет болуын көрсетеді.', 'lt': 'In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality.  Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality.  Tuo pačiu metu vertimo ir ankstesnių sakinių kontekstas turėtų būti dar kritiškesnis. Šiuo tikslu ir šiame dokumente siūlome palaukti-k vienu metu dokumentų lygmens NMT, kur mes išsaugosime konteksto kodatorių taip, kaip jis yra, ir pakeisti pradinio sakinio kodatorių ir tikslinės kalbos kodatorių jų laukimo-k ekvivalentais. We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality.  Tada atliksime vertimų, gautų naudojant savo modelius, analizę, sutelkdami dėmesį į sakinius, kurie turėtų būti naudingi atsižvelgiant į aplinkybes, kuriose mes sužinojome, kad model is yra naudingas ir iš tikrųjų naudingas iš konteksto, bet negali veiksmingai jį panaudoti, ypač mažai išteklių turint. Tai rodo, kad reikia toliau diegti inovacijas nustatant ir naudojant naudingus kontekstus.', 'mk': 'Во реално време симултантно поставување на превод и нервен машински превод (НМТ) моделите почнуваат да генерираат знаци на јазик на мета од некомплетни реченици на извор јазик и ги потешкуваат преводот и водат до лош квалитет на превод. Претходното истражување покажа дека НМТ на ниво на документ и содржи кодери на реченици и контекст и декодер и влијае на контекст од соседните реченици и помага во подобрувањето на квалитетот на превод. In simultaneous translation settings and the context from previous sentences should be even more critical.  За оваа цел и во оваа хартија и предлагаме Чекај-к истовремено на ниво на документ НМТ каде што го задржуваме контекстниот кодер како што е и го замениме кодерот на изворната реченица и кодерот на јазикот на целта со нивните еквиваленти Чекај-к. Експериментираме со ниски и високи поставувања на ресурси користејќи го ALT и OpenSubtitles 2018 corpora и каде набљудуваме мали подобрувања во квалитетот на превод. Потоа спроведуваме анализа на преводите добиени користејќи ги нашите модели со фокусирање на речениците кои би требало да имаат корист од контекстот каде што дознавме дека моделот има и фактично и има корист од контекстот, но не може ефикасно да го искористи и особено во системот со ниски ресурси. This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'ml': 'ഒരു യഥാര്\u200dത്ഥ സമയത്തും ഒരേ സമയത്തും ഒരേ പരിഭാഷയുടെ സജ്ജീകരണങ്ങളിലും, ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷകളില്\u200d (NMT) മോഡലുകളില്\u200d മുഴുവന്\u200d സോര്\u200dസ് ഭാഷ വാക്കുകളില്\u200d നിന്ന മുമ്പുള്ള പരിശോധന കാണിച്ചിരിക്കുന്നു, രേഖയുടെ നില NMT എന്നും വാക്കിന്റെയും കോണ്ടെക്സ്കോഡിന്റെയും കൂട്ടിച്ചേര്\u200dക്കു ഒരേ സമയത്ത് അനുവാദ സജ്ജീകരണങ്ങളിലും മുമ്പുള്ള വാക്കുകളില്\u200d നിന്നുള്ള സജ്ജീകരണങ്ങളിലും കൂടുതല്\u200d പരിഗ ഈ അവസാനത്തിനും ഈ പത്രത്തിലും നമ്മള്\u200d കാത്തിരിക്കുന്ന രേഖയുടെ നില NMT പ്രാര്\u200dത്ഥിക്കുന്നു. അവിടെ നമ്മള്\u200d സംസ്ഥാനത്തിന്റെ കോണ്\u200dട്ടെക്സ്റ്റോക് We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality.  പിന്നീട് നമ്മുടെ മോഡലുകള്\u200d ഉപയോഗിച്ച് നമ്മുടെ പരിഭാഷകളുടെ അന്വേഷണങ്ങള്\u200d നാം പ്രവര്\u200dത്തിപ്പിക്കുന്നു. മോഡല്\u200d ചെയ്യുന്നു എന്നും പ്രത്യേകിച്ചും കുറഞ്ഞ വിഭ ഇത് കാണിക്കുന്നുവെങ്കില്\u200d ഉപയോഗിക്കുന്ന സംസ്ഥാനത്തിനും കൂടുതല്\u200d പ്രധാനപ്പെടുത്തേണ്ട ആവശ്യമുണ്ട', 'ms': 'In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality.  kajian terdahulu telah menunjukkan bahawa NMT aras dokumen dan mengandungi pengekod kalimat dan konteks dan pengekod dan penghalang konteks dari kalimat jiran dan membantu memperbaiki kualiti terjemahan. Dalam tetapan terjemahan bersamaan dan konteks dari kalimat terdahulu patut lebih kritik. Untuk tujuan ini dan dalam kertas ini dan kami cadangkan tunggu-k bersamaan document-level NMT di mana kami menyimpan pengekod konteks seperti ia dan menggantikan pengekod kalimat sumber dan dekoder bahasa sasaran dengan ekvivalen tunggu-k mereka. Kami eksperimen dengan tetapan sumber rendah dan tinggi menggunakan korpra ALT dan OpenSubtitles2018 dan di mana kami mengamati peningkatan kecil dalam kualiti terjemahan. Kemudian kami melakukan analisis terjemahan yang diperoleh menggunakan model kami dengan fokus pada kalimat yang seharusnya berguna dari konteks di mana kami mendapati bahawa model lakukan dan sebenarnya dan berguna dari konteks tetapi tidak dapat menggunakannya secara efektif dan terutama dalam tetapan sumber rendah. Ini menunjukkan bahawa terdapat kebutuhan untuk inovasi lanjut dalam cara konteks berguna dikenali dan digunakan.', 'mt': 'F’setting ta’ traduzzjoni simultanja f’ħin reali u mudelli ta’ traduzzjoni bil-magna newrali (NMT) jibdew jiġġeneraw tokens tal-lingwa fil-mira minn sentenzi mhux kompleti tal-lingwa tas-sors u jagħmluhom aktar diffiċli biex jiġu tradotti u jwasslu għal kwalità baxxa ta’ traduzzjoni. Ir-riċerka preċedenti wriet li l-NMT fil-livell tad-dokument u li tinkludi kodifikaturi tas-sentenzi u tal-kuntest u dekoder u ingranaġġ tal-kuntest minn sentenzi ġirien u jgħin biex titjieb il-kwalità tat-traduzzjoni. F’ambjenti simultanji ta’ traduzzjoni u l-kuntest minn sentenzi preċedenti għandhom ikunu aktar kritiċi. To this end and in this paper and we propose wait-k simultaneous document-level NMT where we keep the context encoder as it is and replace the source sentence encoder and target language decoder with their wait-k equivalents.  Aħna ninsperimentaw b’ambjenti ta’ riżorsi baxxi u għoljin bl-użu tal-korpra ALT u OpenSubtitles2018 u fejn ninsabu titjib minuri fil-kwalità tat-traduzzjoni. We then perform an analysis of the translations obtained using our models by focusing on sentences that should benefit from the context where we found out that the model does and in fact and benefit from context but is unable to effectively leverage it and especially in a low-resource setting.  Dan juri li hemm bżonn għal aktar innovazzjoni fil-mod kif jiġi identifikat u sfruttat il-kuntest utli.', 'mn': 'Үнэн цаг хугацаанд орчуулалт болон мэдрэлийн машин орчуулалт (NMT) загварууд нь зориулагдсан хэл хэлний тодорхойлолтуудыг бүтээмжгүй эх үүсвэрийн хэл өгүүлбэрээс гаргаж, тэднийг илүү хэцүү болгож, ядуу орчуулалт чанар Өмнөх судалгаагаар NMT-ийн баримт түвшин, өгүүлбэр, контекст кодчууд, хөршүүн өгүүлбэрээс хамааралтай байдлыг нэмэгдүүлж, хөршүүн өгүүлбэрээс илүү сайжруулж чаддаг гэдгийг харуулсан. Эхний өгүүлбэрээс илүү чухал байх ёстой. Энэ төгсгөлд, энэ цаасан дээр бид wait-k баримт-түвшинд NMT-г санал дэвшүүлнэ. Харин нөхцөл хэлбэрийн коддогч байдаг бөгөөд эх үүсвэрийн өгүүлбэрийн коддогч болон зориулагдсан хэлний коддогч нь wait-k тэнцүү байдаг. Бид ALT болон OpenSubtitles2018 корпора ашиглан бага болон өндөр баялаг нөөц төлөвлөгөөтэй туршилт хийдэг. Бид хэдэн бага хөгжлийн сайжруулалтыг харж байгаа. Тэгээд бид загварыг ашиглаж, загварыг ашиглаж, үнэндээ ашиглаж, нөхцөл байдлаас ашиглаж, ялангуяа бага нөхцөлд ашиглаж чадахгүй гэдгийг ойлгосон үлгэрүүдийн талаар шинжилгээ хийдэг. Энэ нь хэрэгтэй нөхцөл байдлыг тодорхойлж, хэрэглэгдэх арга хэмжээнд нэмэлт шинэчлэлүүд хэрэгтэй гэдгийг харуулж байна.', 'no': 'I eit verkeleg tidspunkt-innstillingar for omsetjing og neuralmaskinsomsetjing (NMT) startar å laga målspråk-teikn frå ikkje komplette kjeldespråk-setningar og gjera dei vanskeleg å omsetja og føra til dårlige omsetjingskvalitet. Førre forskning har vist at dokumentnivå NMT og inneheld setningar og kontekstkodar og dekoder og leverer kontekst frå nabo setningar og hjelper til å forbetra omsetjingskvalitet. I samtidig omsetjingsinnstillingar og konteksten frå førre setningar bør vera meir kritisk. Til denne slutten og i denne papiret foreslår vi wait-k samtidig dokumentnivå NMT der vi held kontekstkoderen som det er og erstattar kjeldesetkoderen og målspråkkkoderen med sitt wait-k-ekvivalent. Vi eksperimenterer med låg og høg ressursinnstillingar med ALT og OpenSubtitles2018 korpora og der vi observerer mindre forbetringar i omsetjingskvalitet. Vi utfører derfor ein analyse av omsetningane som er henta med modeller våre ved å fokusera på setningar som skal nyttast frå konteksten der vi funne at modellen gjer og faktisk fordel frå kontekst, men ikkje kan effektivt levera det og spesielt i ei låg ressursinnstilling. Dette viser at det er nødvendig for fleire inovasjonar på måten nyttig kontekst er identifisert og levert.', 'pl': 'W czasie rzeczywistym modele tłumaczenia symultanicznego i neuronowego tłumaczenia maszynowego (NMT) zaczynają generować tokeny języka docelowego z niekompletnych zdań języka źródłowego i utrudniają je tłumaczenie, co prowadzi do złej jakości tłumaczenia. Wcześniejsze badania wykazały, że NMT na poziomie dokumentu składający się z koderów zdań i kontekstów oraz dekodera i wykorzystuje kontekst z sąsiednich zdań i pomaga poprawić jakość tłumaczenia. W tłumaczeniu symultanicznym ustawienia i kontekst z poprzednich zdań powinny być jeszcze bardziej krytyczne. W tym celu i w niniejszym artykule proponujemy NMT na poziomie dokumentu wait-k jednoczesnym, gdzie utrzymujemy koder kontekstu taki, jaki jest i zastąpimy koder zdań źródłowych i dekoder języka docelowego ich odpowiednikami wait-k. Eksperymentujemy z niskimi i wysokimi ustawieniami zasobów za pomocą korpusów ALT i OpenSubtitles2018 i obserwujemy drobne poprawy jakości tłumaczenia. Następnie przeprowadzamy analizę tłumaczeń uzyskanych za pomocą naszych modeli, skupiając się na zdaniach, które powinny korzystać z kontekstu, w którym dowiedzieliśmy się, że model ma i w rzeczywistości korzysta z kontekstu, ale nie jest w stanie go skutecznie wykorzystać, a zwłaszcza w warunkach niskich zasobów. Pokazuje to, że istnieje potrzeba dalszych innowacji w zakresie identyfikacji i wykorzystania przydatnego kontekstu.', 'ro': 'Într-o setare de traducere simultană în timp real și modelele de traducere automată neurală (NMT) încep să genereze jetoane de limbă țintă din propoziții incomplete în limba sursă, făcându-le mai greu de tradus și ducând la o calitate slabă a traducerii. Cercetările anterioare au arătat că NMT la nivel de document și cuprinzând codificatoare de propoziții și context și un decodor și valorifică contextul din propozițiile vecine și ajută la îmbunătățirea calității traducerii. În setările de traducere simultană și contextul propozițiilor anterioare ar trebui să fie și mai critice. În acest scop și în această lucrare și propunem NMT simultan la nivel de document wait-k unde păstrăm codificatorul contextual așa cum este și înlocuim codificatorul de propoziție sursă și decodorul limbajului țintă cu echivalentul lor wait-k. Experimentăm setări de resurse mici și mari folosind corpurile ALT și OpenSubtitles2018 și unde observăm îmbunătățiri minore ale calității traducerii. Apoi efectuăm o analiză a traducerilor obținute folosind modelele noastre concentrându-ne pe propoziții care ar trebui să beneficieze de contextul în care am aflat că modelul are și de fapt beneficiază de context, dar nu este capabil să-l valorifice eficient și mai ales într-un cadru cu resurse reduse. Acest lucru arată că este necesară o inovare suplimentară în ceea ce privește identificarea și valorificarea contextului util.', 'sr': 'U stvarnom vremenu, istovremenom postavljanju prevoda i modeli neuronskog prevoda (NMT) počinju stvarati znakove za ciljanje jezika iz nepotpunih rečenica jezika izvora i otežavaju ih prevoditi i dovesti do lošeg kvaliteta prevoda. Prethodno istraživanje pokazalo je da NMT na nivou dokumenta i sastavlja od kodera rečenice i konteksta i dekodera i utiče na kontekst od susjednih rečenica i pomaže da poboljša kvalitet prevoda. U istovremenim nastavama prevoda i kontekst iz prethodnih rečenica treba biti još kritičniji. Za ovaj cilj i u ovom papiru i predlažemo da čekamo k istovremenom nivou dokumenta NMT gde držimo kontekstni koder kao što je i zamijenimo koder izvorne rečenice i dekoder jezika sa njihovim ekvivalentima čeka-k. Eksperimentiramo sa niskim i visokim nastavama resursa koristeći korporaciju ALT i OpenSubtitles2018 i gde posmatramo manje poboljšanja kvalitete prevoda. Tada izvedemo analizu prevoda koji su dobili koristeći naše modele fokusiranjem na rečenice koje bi trebale da koriste iz konteksta u kojem smo saznali da je model čini i zapravo i koristi od konteksta, ali nije u mogućnosti efektivno uticati na to, posebno u nizim resursima. To pokazuje da postoji potreba za daljnjim inovacijama na način da se identifikuje i utiče na korisni kontekst.', 'sv': 'I en simultan 철vers채ttningsinst채llning i realtid och neurala maskin철vers채ttningsmodeller (NMT) b철rjar generera m책lspr책ks tokens fr책n ofullst채ndiga k채llspr책ksskrifter och g철r dem sv책rare att 철vers채tta och leder till d책lig 철vers채ttningskvalitet. Tidigare forskning har visat att NMT p책 dokumentniv책 best책r av mening- och kontextkodare och en avkodare och utnyttjar kontext fr책n n채rliggande meningar och bidrar till att f철rb채ttra 철vers채ttningskvaliteten. Vid samtidig 철vers채ttning b철r inst채llningarna och sammanhanget fr책n tidigare meningar vara 채nnu mer kritiska. F철r detta 채ndam책l och i denna uppsats f철resl책r vi samtidig wait-k dokumentniv책 NMT d채r vi beh책ller kontextkodaren som den 채r och ers채tter k채llmeningskodaren och m책lspr책kskodaren med deras wait-k ekvivalenter. Vi experimenterar med l책ga och h철ga resursinst채llningar med hj채lp av korporan ALT och OpenSubtitles2018 och d채r vi observerar mindre f철rb채ttringar i 철vers채ttningskvaliteten. Vi g철r sedan en analys av de 철vers채ttningar som erh책llits med hj채lp av v책ra modeller genom att fokusera p책 meningar som b철r dra nytta av det sammanhang d채r vi fick reda p책 att modellen g철r och faktiskt drar nytta av sammanhanget men inte kan utnyttja det effektivt och s채rskilt i en l책gresursmilj철 milj철. Detta visar att det finns ett behov av ytterligare innovation n채r det g채ller hur anv채ndbara sammanhang identifieras och utnyttjas.', 'so': "In a real-time-simultaneous translation setting and neural machine translation (NMT) models begin to generate signs of target language from incomplete source sentences and make them harder to translate and leading to poor translation quality. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality.  Xiliga turjumaadda islamarkaasna waa in aad ka sii muhiimsan tahay qoraalka hore. Taas dhammaadkeeda iyo warqaddaas waxaynu u soo jeedaynaa sugta-k oo sameynta heerka dukumentiga ee NMT, kaas oo aynu ku hayno kooxda kooxda kooxda kooxda iyo kooxda ereyga iyo kaadhka luqada ee ku hagaajinta si u eg suga-k. Waxaynu ku jirrabnaa korporada ALAT iyo OpenSubtitles2018, halkaas oo aad u fiirinno horumarinta wax yar oo lagu beddelo tusaale ahaan turjumista. Markaas waxaynu sameynaa baaritaanka turjumidda lagu isticmaali karo modellkayaga, si a an ugu kalsoonaanno hadallada ay faa'iido u leedahay marka aan ogaanay in modelku sameeyo iyo in dhaqdhaqaaq iyo faa'iido laga sameeyo, laakiin ma awoodin inuu si faa’iido leh u isticmaalo, gaar ahaan habka hoose-nololeed. Tan waxaa loola jeedaa in loo baahan yahay wax cusub oo kale, sida loo aqoonsado oo la faa’iido leh.", 'si': 'ඇත්ත- කාලයක් සමාන්\u200dය වාර්තාව සැකසුම් සහ න්\u200dයූරාල් මැෂින් වාර්තාව (NMT) මොඩේල් ඉලක්ෂ භාෂාව ටොකෙන්ස් නිර්මාණය කරන්න පටන් ග කලින් පරීක්ෂණය පෙන්වන්න පුළුවන් විදියට වාක්ය සහ සම්බන්ධ සංකේතකය සහ සංකේතකය සම්බන්ධය සම්බන්ධය සම්බන්ධය සඳහ එකම වාර්තාවක් වාර්තාව සැකසුම් සහ කලින් වාර්තාවෙන් තව ගොඩක් වැදගත් වෙන්න ඕනි. මේ අවසානය සහ මේ පැත්තට, අපි ප්\u200dරතිචාර කරනවා Wait-k එක්කෙන් ලේවල් ලේවල් NMT කියලා, අපි ප්\u200dරතිචාර කෝඩාරය තියාගෙන ඉන්නේ ඒ වගේම ප්\u200dරතිචාර අපි පරීක්ෂණය කරන්නේ අඩුම සහ උත්සත්වය සැකසුම් සමග ALT සහ OpenSubtitle 2018 කොර්පෝරාව භාවිත කරන්න, ඒ වගේම අපි පරීක්ෂණයේ ප්\u200dරම අපි පස්සේ අපේ මොඩේල් භාවිතා කරන්න පුළුවන් වාර්ථාවක් විශ්ලේෂණයක් කරන්න පුළුවන් විශ්ලේෂණය කරනවා අපි හොයාගත්තේ මොඩේල් කරන්න හා ඇත්තටම සහ ප්\u200dර මේක පෙන්වන්නෙ වැඩිය අවස්ථාවක් නිර්මාණය කරන්න අවශ්\u200dයයක් තියෙනවා වගේම ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය', 'ta': 'ஒரு உண்மையான- நேரத்தில் அதே நேரத்தில் மொழிபெயர்ப்பு அமைப்புகளில் மற்றும் புதிய இயந்திர மொழிமொழிமொழியின் சொல்லிலிருந்து இலக்கு குறிகளை உரு @ info அதே நேரத்தில் மொழிபெயர்ப்பு அமைப்புகள் மற்றும் முந்தைய வாக்கியங்களிலிருந்து மொழிபெயர்ப்புகள்  இந்த முடிவுக்கும் இந்த காகிதத்திலும் நாம் காத்திருக்கும் ஒரே நேரத்தில் NMT ஆவணம்- மட்டத்திற்கு பரிந்துரைக்கிறோம் அது போன்ற நாம் சூழல் குறி ALT மற்றும் OpenSubtitles2018 நிறுவனத்தை பயன்படுத்தி குறைந்த மற்றும் உயர்ந்த மூலங்கள் அமைப்புகளைக் கொண்டு நாம் பரிசோதிக்கிறோம்.  பிறகு நாம் எங்கள் மாதிரிகளைப் பயன்படுத்தி மொழிபெயர்ப்புகளை ஆராய்ச்சி செய்கிறோம். மாதிரி செய்வது உண்மையில் இருந்து பயனுள்ளது என்று கண்டுபிடித்துள்ளது என இது காண்பிக்கப்பட்டுள்ள பயனுள்ள சூழல் அடையாளம் மற்றும் கொடுக்கப்படும் வழியில் இன்னும் புதுப்பாக்க வேண', 'ur': 'اور نیورل ماشین کی ترجمہ (NMT) موڈل میں نشان کی زبان ٹوکنوں کو ناپول سراسر زبان جماعتوں سے پیدا کرنا شروع کرتا ہے اور ان کی ترجمہ اور بدترین ترجمہ کی کیفیت کے لئے زیادہ مشکل کر دیتا ہے. پہلے کی تحقیقات نے دکھائی ہے کہ دکھانے والی سطح NMT اور جماعت اور کنٹکس کوڈر اور ایک ڈیکوڈر اور کنٹکس کوڈر کے ساتھ پیچھے کی جماعت سے کامل کرتا ہے اور ترجمہ کی کیفیت بہتر کی مدد کرتا ہے. ایک دفعہ ترجمہ سیٹیوں میں اور اگلے جماعتوں سے متصلہ بہت اہم ہونا چاہیے۔ اس کے لئے اور اس کاغذ میں اور ہم ایک دفعہ کے لئے wait-k-level NMT کی پیشنهاد کرتے ہیں جہاں ہم کنٹکس کوڈر کو اس طرح رکھتے ہیں اور سورس ویڈر کوڈر اور موجود زبان کے دکوڈر کو ان کے انتظار-k برابر سے بدل دیتے ہیں. ہم کم اور بلند سراسر سیٹیوں کے ساتھ آزمائش کرتے ہیں ALT اور OpenSubtitles 2018 کورپورا کے مطابق اور جہاں ہم ترجمہ کیفیت میں تھوڑی سیٹیوں کو دیکھتے ہیں. پھر ہم نے اپنی مدل کے مطابق استعمال کی ترجمہ کی ایک تحلیل کر دی ہے جس میں ہم نے معلوم ہوا کہ مدل کرتا ہے اور حقیقت میں اور منصوبت سے فائدہ دیتا ہے لیکن اس کو اثبات کے ساتھ استعمال نہیں کرسکتا اور مخصوصاً کم منصوبت کے تنظیم میں۔ یہ دکھاتا ہے کہ اس طرح مفید کنٹنسٹ کی تعریف اور استعمال کی طرح اضافہ تغییرات کے لئے ضرورت ہے.', 'uz': "@ info: whatsthis @ info In simultaneous translation settings and the context from previous sentences should be even more critical.  Bu oxiriga va bu qogʻozda biz bir xil hujjat darajasi NMT kutib chiqarishni talab qilamiz. Bu yerda biz kontekst kodlash imkoniyatini hosil qilamiz va manba maxfiy soʻzning kodvalini oʻzgartirish va qidirish uchun tilni kodlash imkoniyatini boshqaramiz. Biz ALT va OpenSubtitles2018 kompaniya yordamida yaratgan va eng yuqori resource moslamalarini tajriba qilamiz va biz tarjima sifatida kichkina yaxshi o'zgarishni ko'radimiz. Keyin biz modellarimizdan foydalanilgan tarjima tarjimalarni bajaramiz. Bu holatda model qo'shiladi va aslida ham foydalanishi mumkin deb o'rganish mumkin, lekin buni amalga oshirib boʻlmaydi. Bu ko'rsatish mumkin, foydalanuvchi darajada aniqlangan va ishlab chiqarish kerak.", 'vi': 'Trong thời gian thực, các mẫu dịch chuyển đồng thời và dịch chuyển máy thần kinh (NMB) bắt đầu tạo ra những thẻ ngôn ngữ của mục tiêu từ các câu từ ngôn ngữ chưa hoàn chỉnh và làm chúng khó dịch chuyển và dẫn đến chất lượng dịch kém. Những nghiên cứu trước đã cho thấy công nghệ NMT cấp tài liệu gồm mã hóa bản án và ngữ cảnh và một ngữ cảnh giải mã và phù hợp từ các câu lân cận và giúp cải thiện chất lượng dịch. Trong thiết lập dịch đồng thời và bối cảnh từ câu trước nên rất quan trọng. Mục đích này và trong tờ giấy này, chúng tôi đề nghị công nghệ NMT cùng thời gian chờ đợi, nơi chúng tôi giữ bộ mã hóa ngữ cảnh như nó và thay thế mã hóa câu phát mã và mã giải ngôn ngữ đích bằng ngôn ngữ đợi. Chúng tôi thí nghiệm với thiết lập thấp và chất lượng cao bằng cách dùng ALT và OpenSubtQuery và ở đó chúng tôi quan sát những cải tiến nhỏ trong chất lượng dịch. Sau đó chúng tôi phân tích những bản dịch đạt được bằng cách tập trung vào những câu nên có lợi từ ngữ cảnh mà chúng tôi phát hiện ra rằng mô hình này có và thực tế và có lợi từ ngữ ngữ cảnh nhưng không thể sử dụng nó hiệu quả và đặc biệt trong một môi trường ít tài nguyên. Điều này cho thấy là cần phải có thêm sự phát triển trong cách nhận dạng và thúc đẩy phù hợp.', 'nl': 'In een real-time simultaan translation setting en neural machine translation (NMT) modellen beginnen doeltaaltokens te genereren uit onvolledige zinnen in de brontaal, waardoor ze moeilijker te vertalen zijn en leiden tot een slechte vertaalkwaliteit. Eerder onderzoek heeft aangetoond dat NMT op documentniveau bestaat uit zin- en contextencoders en een decoder en gebruikt context uit naburige zinnen en helpt de vertaalkwaliteit te verbeteren. Bij simultane vertaling moeten instellingen en de context uit eerdere zinnen nog kritischer zijn. Om dit doel en in deze paper en we stellen wait-k simultane document-level NMT voor waarbij we de context encoder zoals hij is houden en de bronzin encoder en doeltaal decoder vervangen door hun wait-k equivalenten. We experimenteren met lage en hoge resource instellingen met behulp van de ALT en OpenSubtitles2018 corpora en waar we kleine verbeteringen in de vertaalkwaliteit waarnemen. Vervolgens voeren we een analyse uit van de vertalingen verkregen met behulp van onze modellen door ons te concentreren op zinnen die zouden moeten profiteren van de context waarbij we ontdekten dat het model dat doet en in feite profiteert van context, maar die niet effectief kan benutten en vooral in een omgeving met weinig middelen. Dit toont aan dat er behoefte is aan verdere innovatie in de manier waarop nuttige context wordt geïdentificeerd en benut.', 'hr': 'U stvarnom vremenu, istovremenom postavljanju prevoda i modeli neuronskog prevoda stroja (NMT) počinju stvarati znakove ciljnog jezika iz nepotpunih jezičkih rečenica i činiti ih težim prevoditi i dovesti do lošeg kvaliteta prevoda. Prethodno istraživanje pokazalo je da NMT na razini dokumenta koji sastoji od kodera rečenica i konteksta, dekodera i utječe na kontekst od susjednih rečenica i pomaže poboljšati kvalitet prevoda. U istovremenim nastavama prevoda i kontekst iz prethodnih rečenica treba biti još kritičniji. Za ovaj cilj i u ovom papiru i predlažemo ček-k istodobno razinu dokumenta NMT gdje držimo kontekstni koder kao što je i zamijenimo koder izvorne rečenice i dekoder jezika sa njihovim ekvivalentima ček-k. Eksperimentiramo s niskim i visokim nastavima resursa koristeći korporaciju ALT i OpenSubtitles2018 i gdje promatramo manje poboljšanja kvalitete prevoda. Tada ćemo analizirati prevode koje su dobile koristeći naše modele usredotočiti se na rečenice koje bi trebale koristiti iz konteksta gdje smo saznali da model čini i zapravo i koristi od konteksta, ali nije u stanju učinkovito utjecati na njega i posebno u nizim resursima. To pokazuje da postoji potreba za daljnjim inovacijama na način kako se identificira i primjenjuje korisni kontekst.', 'bg': 'В реално време моделите за симултанен превод и неврален машинен превод (НМТ) започват да генерират токени за целеви езици от непълни изречения на изходния език, което ги прави по-трудни за превеждане и води до лошо качество на превода. Предишни изследвания показват, че НМТ на ниво документ и включващ кодери на изречения и контекст и декодер и използва контекста от съседните изречения и помага за подобряване качеството на превода. В настройките за симултанен превод и контекстът от предишни изречения трябва да бъде още по-критичен. За тази цел и в настоящата статия предлагаме едновременно НМТ на ниво документ, където запазваме контекстния кодер такъв, какъвто е и заменяме кодера на изречения източник и декодера на целевия език с техните еквиваленти. Експериментираме с ниски и високи ресурсни настройки, използвайки корпоративните клаузи и където наблюдаваме малки подобрения в качеството на превода. След това извършваме анализ на преводите, получени с помощта на нашите модели, като се фокусираме върху изречения, които трябва да се възползват от контекста, в който установихме, че моделът има и всъщност и се възползва от контекста, но не е в състояние ефективно да го използва и особено в среда с ниски ресурси. Това показва, че са необходими допълнителни иновации по отношение на начина, по който се идентифицира и използва полезният контекст.', 'da': 'I en real-time simultan oversættelse indstilling og neurale maskinoversættelsesmodeller (NMT) begynder at generere målsprog tokens fra ufuldstændige kildesprogssætninger og gøre dem sværere at oversætte og føre til dårlig oversættelseskvalitet. Tidligere forskning har vist, at dokumentniveau NMT består af sætning- og kontekstkodere og en dekoder og udnytter kontekst fra nærliggende sætninger og hjælper med at forbedre oversættelseskvaliteten. I samtidig oversættelse bør indstillingerne og konteksten fra tidligere sætninger være endnu mere kritisk. Til dette formål og i denne artikel foreslår vi wait-k samtidig dokumentniveau NMT, hvor vi beholder kontekstkoderen som den er og erstatter kildesætningskoderen og målsprogskoderen med deres wait-k ækvivalenter. Vi eksperimenterer med lave og høje ressourceindstillinger ved hjælp af ALT og OpenSubtitles2018 korpora, og hvor vi observerer mindre forbedringer i oversættelseskvaliteten. Derefter foretager vi en analyse af de oversættelser, der er opnået ved hjælp af vores modeller, ved at fokusere på sætninger, der bør drage fordel af den kontekst, hvor vi fandt ud af, at modellen gør og faktisk drager fordel af konteksten, men ikke er i stand til effektivt at udnytte den og især i en lav ressource-ramme. Dette viser, at der er behov for yderligere innovation i den måde, hvorpå nyttige kontekst identificeres og udnyttes.', 'ko': '실시간 동시통역 환경에서 신경기계통역(NMT) 모델은 불완전한 원시 언어 문장에 목표 언어 표기를 생성하여 번역하기 어렵게 하고 번역의 질을 떨어뜨리기 시작한다.이전의 연구에 의하면 문서급 NMT는 문장과 상하문 인코더와 디코더로 구성되어 서로 인접한 문장의 상하문을 이용하여 번역의 질을 향상시키는 데 도움이 된다고 한다.동시통역 환경에서 앞의 몇 마디의 언어 환경이 더욱 중요해야 한다.이를 위해 본고에서 우리는wait-k 동기화 문서급 NMT를 제시했다. 우리는 상하문 인코더의 원형을 유지하고 그들의 wait-k 등가물로 원문 인코더와 목표 언어 인코더를 대체한다.우리는 Alt와 OpenSubtitles 2018 어료 라이브러리를 이용하여 저자원 설정과 고자원 설정을 실험하고 번역의 질이 미세하게 개선된 것을 관찰했다.그 다음에 우리는 우리의 모델을 사용하여 얻은 번역을 분석하고 언어 환경에서 이익을 얻어야 하는 문장에 중점을 두었다. 우리는 모델이 언어 환경에서 이익을 얻고 사실상 언어 환경에서 이익을 얻지만 언어 환경, 특히 저자원 환경에서 효과적으로 이용할 수 없다는 것을 발견했다.이것은 상하문을 식별하고 이용하는 방식에 있어서 더욱 혁신이 필요하다는 것을 나타낸다.', 'sw': 'Katika kituo cha kutafsiri kwa wakati ule na utafsiri wa mashine ya asili (NMT) wanaanza kutengeneza alama za lugha zenye lengo kutoka hukumu za lugha isiyo milikiwa na kufanya hivyo vigumu kutafsiri na kuongoza kiwango cha tafsiri duni. Utafiti uliopita umeonyesha kuwa kiwango cha dokumentari cha NMT na kinajumuisha hukumu na taratibu za muktadha na muktadha wa kodi na utulivu kutoka hukumu za jirani na kusaidia kuboresha kiwango cha tafsiri. Katika mazingira ya tafsiri wakati ule na mazingira ya hukumu zilizopita yanapaswa kuwa muhimu zaidi. Kwa mwisho huu na katika karatasi hii na tunapendekeza kusubiri kwa kiwango cha dokumu cha NMT ambapo tunaweka kodi ya muktadha kama ilivyokuwa na kubadilisha kodi ya chanzo cha hukumu na kupunguza lugha kwa kiwango cha kusubiri. Tunajaribu na mazingira ya rasilimali ya chini na ya juu kwa kutumia kampuni ya ALT na OpenSubtitles 2018 na ambapo tunaangalia maboresho madogo kwa kiwango cha tafsiri. Kisha tunafanya uchambuzi wa tafsiri zilizopatikana kwa kutumia mifano yetu kwa kuangalia sentensi ambazo zinapaswa kunufaika na muktadha ambapo tuligundua kuwa muundo huo unafanya na kwa kweli na unafaa na muktadha lakini hauwezi kuitumia vizuri na hususani katika mazingira ya rasilimali duni. This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'fa': 'در یک تنظیم ترجمه و ترجمه ماشین عصبی (NMT) زمان واقعی شروع می\u200cکنند که نشانه\u200cهای زبان هدف را از جمله\u200cهای زبان منبع ناکامل ایجاد می\u200cکند و آنها را به ترجمه و رهبری به کیفیت ترجمه\u200cای بد سخت می\u200cکند. تحقیقات قبلی نشان داده است که سطح سند NMT و از جمله\u200cهای زبان و محیط\u200cکننده\u200cها و محیط\u200cکننده\u200cها و محیط\u200cها را از جمله\u200cهای محله\u200cی محله\u200cی محله\u200cی محله\u200cای تأثیر می\u200cدهد و به بهتر کیفیت ترجمه کم در تنظیمات ترجمه\u200cهای همزمان و محیط از جمله\u200cهای قبلی باید بیشتر مهمتر باشد. برای این پایان و در این کاغذ و ما پیشنهاد می\u200cکنیم که یک سطح سند-k همزمان انتظار کنیم NMT جایی که محیط را همان طور نگه می\u200cداریم و محیط رمز منبع و رمز زبان هدف را با برابر انتظار-k نگه می\u200cداریم. ما با تنظیمات منابع پایین و بالا با استفاده از شرکت ALT و OpenSubtitles 2018 آزمایش می کنیم و جایی که ما بهترین کمی در کیفیت ترجمه را مشاهده می کنیم. سپس یک تحلیل از ترجمه\u200cها که با استفاده از مدل\u200cهای ما گرفته شده با تمرکز به جمله\u200cهایی که باید از محیط آن سود بگیرند انجام می\u200cدهیم که مدل انجام می\u200cدهد و در حقیقت سود می\u200cدهد و در حقیقت از محیط ولی نمی\u200cتواند موثرت\u200cپذیرش کند و مخصوصا در تنظیم منابع این نشان می دهد که نیازی برای نوآوری بیشتری در راه شناسایی و استفاده از محیط مفید وجود دارد.', 'af': "In 'n reël- tyd gelyktyd vertaling instelling en neurale masjien vertaling (NMT) modele begin genereer doel taal tokens van onvolledige bron taal setings en maak hulle harder om te vertaal en lei na arm vertaling kwaliteit. Vorige ondersoek het vertoon dat dokumentvlak NMT en wat van seting en kontekskoders en 'n dekoder en verskaf konteks van nabygende setings en help om vertalingskwaliteit te verbeter. In eenvoudige vertalingsinstellings en die konteks van vorige setings moet nog meer krities wees. Na hierdie einde en in hierdie papier en ons voorstel wait-k simultaneous document-vlak NMT waar ons die kontekskoder hou as dit is en vervang die bronkoder en doel taal dekoder met hul wait-k ekvivalente. Ons eksperimenteer met lae en hoë hulpbron instellings wat gebruik die ALT en OpenSubtitles2018 korpora en waar ons die klein verbeteringe in vertaling kwaliteit aanhou. Ons doen dan 'n analiseer van die vertalings wat ontvang word deur ons modele te gebruik deur fokus te maak op setinge wat van die konteks moet voordeel word waar ons uitgevind het dat die model doen en in werklikheid en voordeel van konteks, maar is nie moontlik om dit te effektief, en veral in 'n lae hulpbron instelling te verwy Hierdie wys dat daar 'n benodig is vir verdere inomasie op die manier wat gebruiklik konteks is identifiseer en verplig.", 'tr': "Häzirki wagt içinde bir terjime düzümleri we näyral maşynyň terjime etmesi (NMT) nusgalarynda maksady dil täbliklerinden döredilip, olary terjime etmek we erbet terjime etmek üçin kynlaşdyrýarlar. Öňki araştırmalar NMT senediň derejesini görkezildi we sözlem we kontekst ködlemelerini daşarylýan we goňşy sözlemlerden konteksti çykarýan we terjime kwalitesini bejermek üçin kömek edip görkezildi. Durum terjime düzümleri we öňki sözleriň konteksti has möhüm bolmaly. Bu soňra we şu kagyzda we biz bir-k sened derejesi NMT'i garaş teklif edip, başlangyç sözlerini kodeýän we maksady dil kodeýäni garaş-k ekvivalentleri bilen almagyny teklif edip görýäris. Biz ALT we OpenSubtitles 2018 corpora ullanýän ýokary we ýokary resursu düzümlerini test edip, terjime etmek howplygynda azajyk gelişmeleri gözleýäris. Sonra modellerimizi ulanyp alan terjimeleriň analyzasyny çykarýarys. Şahlerimizi we nusgalaryň bardygyny bilýän, nusgalaryň bardygyny we bardygyny düşünýän, ýöne muny etkinleýän şekilde etmäge mümkin däldir we ýöne-de a şak resurslar düzümlerinde etmäge mümk Bu ýagdaýda gerekli kontekst tanyşdyrylyp we etmäge rugsat berilýän şeklinde daşyrak täzeden täzelikler gerek bolandygyny görkezýär.", 'sq': "Në një rregullim të përkthimit të njëkohëshëm në kohë reale dhe modelet e përkthimit të makinave nervore (NMT) fillojnë të gjenerojnë shenjat e gjuhës objektive nga fjalimet e jo të plota të gjuhës së burimit dhe t'i bëjnë a to më të vështira për të përkthyer dhe duke shpjerë në cilësi të dobët përkthimi. Kërkimi i mëparshëm ka treguar se niveli i dokumentit NMT dhe përfshirë koduesit e fjalëve dhe kontekstit dhe një dekoder dhe përdorë kontekstin nga fjalët fqinjë dhe ndihmon përmirësimin e cilësisë së përkthimit. In simultaneous translation settings and the context from previous sentences should be even more critical.  Për k ëtë qëllim dhe në këtë letër dhe ne propozojmë prit-k të njëjtën nivel dokumenti NMT ku mbajmë koduesin e kontekstit siç është dhe zëvendësojmë koduesin e fjalëve burimore dhe dekoderin e gjuhës objektiv me ekvivalentët e tyre prit-k. Eksperimentojmë me rregullime të ulëta dhe të larta të burimeve duke përdorur korprën ALT dhe OpenSubtitles2018 dhe ku vëzhgojmë përmirësime të vogla në cilësinë e përkthimit. Ne pastaj kryejmë një analizë të përkthimeve të fituara duke përdorur modelet tona duke u përqëndruar në fjalët që duhet të përfitojnë nga konteksti ku zbuluam se modeli bën dhe në fakt përfiton nga konteksti por nuk është në gjendje të nxjerrë efektivisht atë dhe veçan ërisht në një vështirësi me burime të ulëta. Kjo tregon se ka nevojë për inovacione të mëtejshme në mënyrën se si përdoret dhe identifikohet konteksti i dobishëm.", 'id': 'Dalam seting terjemahan simultan pada waktu nyata dan model terjemahan mesin saraf (NMT) mulai menghasilkan token bahasa sasaran dari kalimat bahasa sumber yang tidak lengkap dan membuat mereka lebih sulit untuk terjemahan dan menyebabkan kualitas terjemahan yang buruk. Penelitian sebelumnya telah menunjukkan bahwa document-level NMT dan terdiri dari pengkode kalimat dan konteks dan dekoder dan leverage konteks dari kalimat tetangga dan membantu meningkatkan kualitas terjemahan. Dalam pengaturan terjemahan simultan dan konteks dari kalimat sebelumnya seharusnya lebih kritis. Untuk tujuan ini dan di kertas ini dan kami mengusulkan menunggu-k simultan document-level NMT di mana kita menyimpan konteks pengekode seperti ini dan menggantikan pengkode kalimat sumber dan dekode bahasa sasaran dengan ekvivalent tunggu-k mereka. Kami eksperimen dengan pengaturan sumber daya rendah dan tinggi menggunakan korpra ALT dan OpenSubtitles2018 dan di mana kami mengamati peningkatan kecil dalam kualitas terjemahan. Kemudian kami melakukan analisis terjemahan yang diperoleh dengan menggunakan model kami dengan fokus pada kalimat yang seharusnya berguna dari konteks di mana kami menemukan bahwa model itu berhasil dan pada kenyataannya dan berguna dari konteks tetapi tidak dapat menggunakannya secara efektif dan terutama dalam pengaturan sumber daya rendah. This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'am': 'በreal-time simultaneous translation settings and neural machine translation (NMT) models generate target language tokens from incomplete source language sentences and make them harder to translate and leading to poor translation quality. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality.  በተሰዓት ትርጉም ማስተካከል እና ቀድሞው ንግግር ከቀድሞ ንግግር የተደረገው ግንኙነት በጣም አሰቃሚ ሊሆን ይገባዋል፡፡ ለዚህ መጨረሻ እና በዚህ ገጽ እና በተሰለ ሰነድ-ደረጃዎች NMT እናስቀድማለን የሆኑን የክፍተት ኮድ እና የኩነቶች የክፍተት የፊደል ኮድ እና የቋንቋውን የክዳት አካባቢ በመስጠት በተስፋታቸው መጠቀም እናደርጋለን፡፡ የALAT እና የOpenSubtitles2018 ኮፖሪያን በመጠቀም እና ትርጓሜ ጥናት ትንሽ ሽፋን እናደርጋለን፡፡ በኋላም ሞዴላዎቻችንን በመጠቀም የሚጠቅመውን የግንኙነታችንን አስተያየት እናደርጋለን፤ ሞዴል እና እውነተኛውን እና የሚጠቅመውን እና እንጠቅማለን፡፡ ይህ የሚታየው ጥያቄ እና የተጠቃሚ ግንኙነት በሚታወቅበት መንገድ ላይ ሌላ አዲስ ፍጥረት ያስፈልጋል፡፡', 'bn': 'একই সাথে একই সাথে অনুবাদ বৈশিষ্ট্য এবং নিউরেল মেশিন অনুবাদ (এনএমটি) মডেলের মোডেল অসম্পূর্ণ সোর্স ভাষার বাক্য থেকে লক্ষ্যের লক্ষ্য তৈরি করে এবং  পূর্ববর্তী গবেষণা প্রদর্শন করেছে যে ডকুমেন্ট-স্তর এনএমটি এবং বাক্য এবং কন্টেক্সটেক্সডেন্ড আর প্রতিবেশী শাস্তি থেকে কোডার এবং ল একই সাথে অনুবাদের বৈশিষ্ট্য এবং পূর্ববর্তী বাক্যের প্রেক্ষাপটের বৈশিষ্ট্য আরো গুরুত্বপূর্ণ এই শেষ এবং এই কাগজটিতে আমরা অপেক্ষা করি একই সাথে অপেক্ষা করা নথি-স্তরের এনএমটি প্রস্তাব করি যেখানে আমরা কন্টেক্সট এনকোডার রাখি এবং সূর্সোর্সের বাক্যে আমরা এলাট এবং ওপেন সাবটাইটেল ২০১৮ কোর্পোরা ব্যবহার করে কম এবং উচ্চমূল্যের বৈশিষ্ট্য নিয়ে পরীক্ষা করছি এবং যেখানে আমরা অনুবাদের মা তারপর আমরা আমাদের মডেল ব্যবহার করে অনুবাদের বিশ্লেষণ করি বিশ্লেষণের মাধ্যমে যে বাক্যের দিকে মনোযোগ দিয়ে মনোযোগ দিচ্ছি যেখানে আমরা জানতে পারি যে মডেলের কাজ করে এবং  This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'az': "Həmçinin həmçinin tərcümə qurğuları və nöral maşın tərcüməsi (NMT) modelleri tamamlanmış mənbə dil sözlərindən məqsəd dil işaretlərini yaratmağa başlar və onları tərcümə etmək və yoxsulluq tərcümə keyfiyyətinə yol a çar. Əvvəlki araştırma belə göstərdi ki, döküm seviyyəsi NMT və sözlər, kontekst kodlayıcıların, yaxın sözlərdən bir dekoder və məlumatların məlumatlarını təmizləyir və tercümə keyfiyyətini yaxşılaşdırmağa kömək edir. Əvvəlki cümlələrdən tərcümə qurğuları və məlumatların daha kritik olması lazımdır. Bu səhifədə və bu kağızda wait-k belə bir dök üm seviyesi NMT'i təklif edirik ki, məlumat kodlayıcısı olduğu kimi saxlayacağıq və mənbə cümlənin kodlayıcını və məqsəd dili kodlayıcını wait-k ekvivalentləri ilə dəyişdiririk. Biz ALT və OpenSubtitles 2018 corpora vasitəsilə düşük və yüksək ressurs ayarları ilə imtahana çəkirik və çevirin keyfiyyətində kiçik düzəltmələri görmürük. Sonra modellərimizi istifadə edərək, modellərin istifadə edilən təkrarların analizi çəkirik, modellərin istifadə etdiyini və həqiqətən də məlumatların faydalandığını öyrəndiyimiz məlumatların üstünə təsirlənməsi və özlərinə də a şağı ressurs qurmasında istifadə edə bilməz. Bu göstərir ki, mənfəətli məlumatların tanıdılması və tələb edilməsi üçün daha çox yenilənmə ehtiyacı var.", 'ca': "En un entorn de traducció simultànea en temps real i els models de traducció neural màquina (NMT) comencen a generar fitxes de llenguatge destinatari a partir de frases incompletes de llenguatge de font i dificultant la traducció i portant a una mala qualitat de traducció. La recerca anterior ha demostrat que la NMT a nivell de documentos, que consisteix en codificadors de frases i context, i un descodificador i aprofita el context de frases veïnes i ajuda a millorar la qualitat de la traducció. En les configuracions simultànies de traducció i el context de les frases anteriors haurien de ser encara més crítics. Per això i en aquest paper i proposem Wait-k NMT simultàny a nivell de document on mantenim el codificador de context com és i substituïm el codificador de frases fonts i el codificador de llenguatges alvo amb els seus equivalents Wait-k. Experimentem amb configuracions de recursos baixos i alts fent servir la corpora ALT i OpenSubtitles2018 i on observem petites millores en la qualitat de la traducció. Després fem una an àlisi de les traduccions obtingudes fent servir els nostres models centrant-nos en frases que haurien de beneficiar del context on vam descobrir que el model ho fa i, de fet, beneficia del context però no és capaç d'aprofitar-lo efectivament i especialment en un entorn de baix recursos. Això demostra que hi ha una necessitat de més innovació en la manera en què s'identifiquen i aprofiten els contextos útils.", 'bs': 'U realnom trenutku, istovremenom postavljanju prevoda i modeli neuronskog prevoda (NMT) počinju stvarati znakove ciljnog jezika iz nepotpunih jezičkih rečenica i činiti ih težim prevoditi i dovesti do lošeg kvaliteta prevoda. Prethodno istraživanje pokazalo je da NMT na nivou dokumenta koji sastoji od kodera rečenice i konteksta i dekodera i utiče na kontekst od susjednih rečenica i pomaže da poboljša kvalitet prevoda. U istovremenim nastavama prevoda i kontekst iz prethodnih rečenica treba biti još kritičniji. Za ovaj cilj i u ovom papiru i predlažemo ček-k istovremenom nivou dokumenta NMT gdje držimo kontekstni koder kao što je i zamijenimo koder izvorne rečenice i dekoder jezika sa njihovim ekvivalentima ček-k. Eksperimentiramo sa niskim i visokim nastavacima resursa koristeći korporu ALT i OpenSubtitles2018 i gdje posmatramo manje poboljšanja kvalitete prevoda. Tada izvedemo analizu prevoda koje su dobile koristeći naše modele usredotočenim na rečenice koje bi trebale koristiti iz konteksta u kojem smo saznali da model čini i zapravo i koristi od konteksta, ali nije u mogućnosti učinkovito uticati na njega, posebno u nizim resursima. To pokazuje da postoji potreba za daljnjim inovacijama na način kako se identificira i utiče na korisni kontekst.', 'et': 'Reaalajas sünkroontõlke ja neuromasintõlke (NMT) mudelid hakkavad looma sihtkeele märke mittetäielikest lähtekeele lausetest ja muudavad neid raskemaks tõlkida ning põhjustavad halva tõlkekvaliteedi. Varasemad uuringud on näidanud, et dokumenditasemel NMT, mis koosneb lause- ja kontekstikodeerijatest ning dekooderist, kasutab konteksti naaberlausetest ja aitab parandada tõlkekvaliteeti. Sünkroontõlke seadetes ja eelmiste lausete kontekst peaks olema veelgi kriitilisem. Selleks ja käesolevas töös pakume välja wait-k samaaegse dokumendi tasemel NMT, kus me hoiame kontekstikodeerijat sellisena nagu see on ja asendame lähtelause kodeerija ja sihtkeele dekooderi nende wait-k ekvivalentidega. Me eksperimenteerime madala ja suure ressursi seadetega ALT ja OpenSubtitles2018 korpuste abil ning jälgime tõlkekvaliteedi väikest paranemist. Seejärel analüüsime oma mudelite abil saadud tõlkeid, keskendudes lausetele, mis peaksid saama kasu kontekstist, kus me avastasime, et mudel on ja tegelikult ja kasu kontekstist, kuid ei suuda seda tõhusalt kasutada ja eriti vähese ressursiga keskkonnas. See näitab, et kasuliku konteksti kindlaksmääramisel ja võimendamisel on vaja täiendavat innovatsiooni.', 'cs': 'V nastavení simultánního překladu v reálném čase a modely neuronového strojového překladu (NMT) začínají generovat tokeny cílového jazyka z neúplných vět zdrojového jazyka, což ztěžuje jejich překlad a vede ke špatné kvalitě překladu. Předchozí výzkum ukázal, že NMT na úrovni dokumentů obsahuje věty a kontextové kodéry a dekodéry a využívá kontext ze sousedních vět a pomáhá zlepšit kvalitu překladu. Při simultánním překladu by mělo být nastavení a kontext z předchozích vět ještě kritičtější. Za tímto účelem a v tomto článku navrhujeme simultánní NMT na úrovni dokumentů wait-k, kde udržíme kontextový kodér tak, jak je a nahradíme kodér zdrojové věty a dekodér cílového jazyka jejich ekvivalenty wait-k. Experimentujeme s nízkými a vysokými nastaveními zdrojů pomocí korpusů ALT a OpenSubtitles2018 a pozorujeme drobné zlepšení kvality překladu. Následně provádíme analýzu překladů získaných pomocí našich modelů zaměřením se na věty, které by měly mít prospěch z kontextu, kde jsme zjistili, že model ano a ve skutečnosti má prospěch z kontextu, ale není schopen ho efektivně využít a zejména v prostředí s nízkými zdroji. To ukazuje, že existuje potřeba dalších inovací ve způsobu identifikace užitečného kontextu a jeho využití.', 'fi': 'Reaaliaikaisessa simultaanik채채nn철sasetussa ja neurokonek채채nn철smallit alkavat tuottaa kohdekielimerkkej채 ep채t채ydellisist채 l채hdekielilauseista, mik채 vaikeuttaa k채채nt채mist채 ja johtaa huonoon k채채nn철slaatuun. Aiemmat tutkimukset ovat osoittaneet, ett채 dokumenttitason NMT, joka koostuu lause- ja kontekstiandureista ja dekooderista, hy철dynt채채 viereisten lauseiden kontekstia ja auttaa parantamaan k채채nn철ksen laatua. Simultaanik채채nn철sasetuksissa ja edellisten lauseiden kontekstissa tulisi olla viel채 kriittisempi채. T채t채 varten ja t채ss채 ty철ss채 ehdotamme wait-k samanaikaista dokumenttitason NMT:t채, jossa pid채mme kontekstitundikooderin sellaisena kuin se on ja korvaamme l채hdelauseenkooderin ja kohdekielen dekooderin niiden wait-k-ekvivalenteilla. Kokeilemme matalan ja korkean resurssin asetuksia ALT- ja OpenSubtitles2018-korpusilla ja havaitsemme pieni채 parannuksia k채채nn철sten laadussa. T채m채n j채lkeen teemme analyysin malleistamme saaduista k채채nn철ksist채 keskittym채ll채 lauseisiin, joiden pit채isi hy철ty채 kontekstista, jossa huomasimme, ett채 malli hy철tyy kontekstista ja itse asiassa hy철tyy kontekstista, mutta ei pysty tehokkaasti hy철dynt채m채채n sit채 eik채 etenk채채n v채h채resurssisessa ymp채rist철ss채. T채m채 osoittaa, ett채 tarvitaan lis채채 innovaatioita siin채 mieless채, miten hy철dyllinen konteksti tunnistetaan ja hy철dynnet채채n.', 'de': 'In einer Echtzeit-Simultanübersetzung und NMT-Modellen (Neuronal Machine Translation) werden aus unvollständigen Quellsprachensätzen Target Language Tokens generiert, die die Übersetzung erschweren und zu einer schlechten Übersetzungsqualität führen. Bisherige Untersuchungen haben gezeigt, dass NMT auf Dokumentenebene, bestehend aus Satz- und Kontextencodern und einem Decoder, Kontext aus benachbarten Sätzen nutzt und die Übersetzungsqualität verbessert. In der Simultanübersetzung sollten Einstellungen und der Kontext früherer Sätze noch kritischer sein. Zu diesem Zweck und in diesem Beitrag und wir schlagen wait-k simultane Dokument-Ebene NMT vor, wo wir den Kontext Encoder so halten, wie er ist und den Quellsatz Encoder und Zielsprache Decoder durch ihre wait-k Äquivalente ersetzen. Wir experimentieren mit niedrigen und hohen Ressourceneinstellungen mit den Korpora ALT und OpenSubtitles2018 und beobachten kleinere Verbesserungen in der Übersetzungsqualität. Anschließend führen wir eine Analyse der mit unseren Modellen erhaltenen Übersetzungen durch, indem wir uns auf Sätze konzentrieren, die aus dem Kontext profitieren sollten, in dem wir herausgefunden haben, dass das Modell tatsächlich vom Kontext profitiert, aber nicht in der Lage ist, ihn effektiv zu nutzen, insbesondere in einem ressourcenarmen Umfeld. Dies zeigt, dass bei der Identifizierung und Nutzung nützlicher Kontexte weitere Innovationen erforderlich sind.', 'hy': 'Իրական ժամանակում միաժամանակ թարգմանման և նյարդային մեքենայի թարգմանման (NMT) մոդելներում սկսում են ստեղծել նպատակային լեզվի նշաններ ոչ ամբողջական աղբյուր լեզվի նախադասություններից և դարձնել դրանք ավելի դժվար թարգմանել և հանգեցնել վա Անցյալ հետազոտությունները ցույց են տվել, որ փաստաթղթի մակարդակի NMT-ը, որը կազմված է նախադասությունների և կոնտեքստի կոդերներից, և կոնտեքստի կոնտեքստից և օգնում է բարելավել թարգմանման որակը: Միևնույն թարգմանման սահմաններում և նախորդ նախադասությունների կոնտեքստը պետք է ավելի կարևոր լինեն: Այս նպատակով և այս թղթի մեջ մենք առաջարկում ենք սպասել-k միաժամանակ փաստաթղթի մակարդակի NMT, որտեղ մենք պահպանում ենք կոնտեքստի կոդերը այնպես, ինչպես այն կա, և փոխարինում ենք աղբյուր նախադասությունների կոդերը և նպատակային լեզվի կոդերը իրենց սպասե Մենք փորձում ենք ցածր և բարձր ռեսուրսների միջոցով օգտագործելով ALT-ը և Openենթատերլս2018-ի կոպորան, որտեղ մենք հետևում ենք թարգմանության որակի փոքր բարելավումներին: Այնուհետև մենք վերլուծում ենք թարգմանությունները, որոնք ստացվել են օգտագործելով մեր մոդելները, կենտրոնացնելով նախադասությունների վրա, որոնք պետք է օգտագործեն կոնտեքստից, որտեղ մենք հայտնաբերեցինք, որ մոդելը օգտագործում է և իրականում օգտագործում է կոնտեքստից, բայց չի կարող արդյունավե Սա ցույց է տալիս, որ կարիք ունի ավելի շատ նորարարություններ, որպեսզի օգտակար կոնտեքստը հայտնաբերվի և օգտագործվի:', 'ha': "In a real-time translation settings and neural translation (NMT) motels za'a start to manufacture alãmõmi na harshen aimakin daga maganar harshen na cikakken source and make su harshen to translate and led to poorly translate value. @ info: whatsthis @ info: whatsthis Ga wannan ƙarani da kuma cikin wannan takardar, kuma muna goyyade jinkiri-k da takardar-daraja guda na NMT, inda za mu tsare kode kodi na mazaɓa kamar shi kuma mu musanya kodi na maganar kwanan da za'a yi amfani da kwamfyutan-k. Tuna jarrabi da kewayi masu ƙaranci da kuma sarki masu amfani da haske na AIAT da Open Subtitles2018, da kuma a inda muna gani ƙarami kodi cikin sifar fassarar. Sa'an nan kuma, za mu yi anarrai ga fassarar da aka motsar da misãlai da za'a yi makõma ga sauri, wanda ya fi amfani da shi daga mazaɓa, a lokacin da muka gane cewa, misalin shi na sami da amfani daga mazaɓa, kuma amma bã ya iya iya amfani da shi da amfani da kuma haske a cikin tsarin wuri-wuri. This shows that there is a need for further innovation in the way useful context is identified and leveraged.", 'sk': 'V realnem času simultanega prevajanja in nevronskega strojnega prevoda (NMT) modeli začnejo ustvarjati žetone ciljnega jezika iz nepopolnih izvornih stavkov, zaradi česar jih je težje prevajati in povzročiti slabo kakovost prevodov. Prejšnje raziskave so pokazale, da NMT na ravni dokumenta, ki je sestavljen iz kodirnikov stavkov in konteksta ter dekoderja, izkorišča kontekst iz sosednjih stavkov in pomaga izboljšati kakovost prevoda. V nastavitvah simultanega prevajanja in kontekst iz prejšnjih stavkov bi morali biti še bolj kritični. V ta namen in v tem prispevku predlagamo simultano NMT na ravni dokumenta wait-k, kjer ohranimo kontekstni kodir takšen kot je in nadomestimo kodirnik izvornih stavkov in dekodirnik ciljnega jezika z njihovimi ekvivalenti wait-k. Z uporabo korpusov ALT in OpenSubtitles2018 eksperimentiramo z nizkimi in visokimi viri ter opazujemo manjše izboljšave kakovosti prevodov. Nato analiziramo prevode, pridobljene z uporabo naših modelov, tako da se osredotočimo na stavke, ki bi morali koristiti od konteksta, kjer smo ugotovili, da model ima in dejansko koristi od konteksta, vendar ga ne more učinkovito izkoristiti, zlasti v okolju z nizkimi viri. To kaže, da so potrebe po nadaljnjih inovacijah na način opredelitve koristnega konteksta in vzvoda.', 'he': 'במערכת התרגום באופן מזמני בזמן אמיתי ודוגמנים של מכונות עצביות (NMT) מתחילים ליצור סימני שפת מטרה משפטים מקורי לא מלאים ולעשות אותם קשים יותר לתרגם ולהוביל לאיכות התרגום גרועה. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality.  בתקנות התרגום באותו זמן והקשר משפטים הקודמים צריך להיות אפילו יותר קריטי. למטרה זו ובנייר הזה ואנחנו מציעים חכה-k באותו זמן רמת מסמכים NMT שבו אנחנו שומרים על הקונקסט קודמון כפי שהוא ולהחליף את קודם המשפט המקורי וקודר שפת המטרה עם שוויון חכה-k שלהם. We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality.  ואז אנו מבצעים ניתוח של התרגשות שנקבלו באמצעות הדוגמנים שלנו על ידי התמקדות במשפטים שעליהם להרוויח מהקשר שבו גילינו שהדוגמנים עושים ולמעשה וירוויחים מהקשר אבל הוא לא מסוגל להשתמש באופן יעיל בו ובמיוחד במצב משאבים נמוכים. This shows that there is a need for further innovation in the way useful context is identified and leveraged.', 'jv': 'Taning Rasané awak dhéwé nambah ing NMT dokumen lan gambar kelompok nggambar kapan koder karo ditambah lan pakan kelompok nggambar kapan kelompok nggambar kapan kanggo nggawe kapan ginarané sampeyan nglanggar kuwi kapan tarjamahan. translation Sampeyan nganggo kuwi mau lan nganggo mapani kuwi sampeyan kelas telas NMT sampeyan siji supoyo koder Awak dhéwé éntuk éntuk karo kalem nggambar lan akeh-kalem nganggo gambar aturan alT karo Open Subtitles2013 karo ingkang dibutuhke kita nguasai perusahaan anyar bantuan kanggo kaliwat itoleh. Awak dhéwé beraksi kanggo tarjamahan kanggo tarjamahan sing nggambar model awak dhéwé nguasai winih sing kudu nggawe barang nggambar aturan sing nyebuté awak dhéwé ngerasai model lan ngono efes karo kontèks liyane karo iso nggawe ngubah dhéwé beraksi lan tambah kuwi nggawe barang kelas nêmên. Ngerungke iki bakal ono kudu nggawe nyatakakno luwih dumadhi kanggo sampek kang dipatengan lan nggawe nyimpen.', 'bo': 'In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality. སྔོན་གྱི་འཚོལ་ཞིབ་ཀྱིས་ཡིག་ཆ་ལྡོག་པའི་NMT དང་། ཚིག་ཡིག་དང་ཁུངས་ཡུལ་ཀྱི་གསལ་རྟགས་པ་ཚོ་དང་ཕྱོགས་སྒྲིག་གཏོང་མཁན་ཚོགས དུས་ཚོད་འདིའི་སྔོན་གྱི་ཚིག་རྟགས་དང་སྒྲིག་འགོད་ཀྱི་ཚིག་རྟགས་མང་དུ་གཏོང་དགོས་པ end་འདི་དང་ཤོག་བྱང་འདི་ནང་གི་ལྟ་བུའི་ནང་དུ་wait-k ཡིག་ཆ་འདུག NMT་དང་མཉམ་དུ་འཇོག་སྣོད་ཀྱི་ཁ་ཡིག ང་ཚོས་ALT དང་OpenSubtitles 2018 མཐུན་སྒྲིག་འཛུགས་ཀྱི་ཉུང་བའི་རྒྱུ་དངོས་མཐོ་རིམ་མཐུན་པས་བརྟན་ཞིབ་ཕྱོགས་པ་དང་མཐུན་སྒྲིག་འགོད་པ་ཚོར་ འོན་ཀྱང་། ང་ཚོའི་མིག་རྩལ་ལག་ལེན་བྱེད་པའི་སྐད་ཡིག འདིས་ཕན་ཐོག་གནས་ཚུལ་རྟོགས་དང་བསྐྱུར་བའི་ཐབས་ལམ་ལ་གསར་གཏོད་གཞན་དགོས་པ་ཡིན་པས།'}
{'en': 'Attainable Text-to-Text Machine Translation vs.  Translation  : Issues Beyond Linguistic Processing', 'ar': 'الترجمة الآلية التي يمكن تحقيقها من نص إلى نص مقابل الترجمة: مشكلات تتجاوز المعالجة اللغوية', 'es': 'Traducción automática de texto a texto alcanzable frente a traducción: cuestiones más allá del procesamiento lingüístico', 'ja': '達成可能なテキスト間機械翻訳対翻訳：言語処理を超えた問題', 'pt': 'Tradução automática de texto para texto alcançável vs. tradução: questões além do processamento linguístico', 'fr': 'Traduction automatique texte-texte réalisable par rapport à la traduction\xa0: des enjeux au-delà du traitement linguistique', 'zh': '文本至文本机器翻译与译:语处外', 'ru': 'Достижимый машинный перевод с текстом на текст против перевода: вопросы, выходящие за рамки лингвистической обработки', 'ga': 'Aistriúchán Meaisín Insroichte Téacs-go-Téacs vs. Aistriúchán: Saincheisteanna Thar Phróiseáil Teangeolaíoch', 'hi': 'प्राप्य पाठ-से-पाठ मशीन अनुवाद बनाम अनुवाद: भाषाई प्रसंस्करण से परे मुद्दे', 'ka': 'შესაძლებელი ტექსტის ტექსტის მაქსინის თავისტრუქცია vs. თავისტრუქცია: ლინგისტიკური პროცესის გარეშე', 'hu': 'Elérhető szöveg-szöveg gépi fordítás vs. fordítás: a nyelvi feldolgozáson túli kérdések', 'el': 'Δυνατότητα μηχανικής μετάφρασης κειμένου σε κείμενο έναντι μετάφρασης: θέματα πέρα από τη γλωσσική επεξεργασία', 'it': "Traduzione automatica da testo a testo realizzabile contro traduzione: problemi al di là dell'elaborazione linguistica", 'lt': 'Tinkamas teksto į teksto vertimas, palyginti su vertimu: klausimai ne kalbinio apdorojimo atžvilgiu', 'kk': 'Қолданатын мәтін- мен мәтін машинасының аударуы против аударуы: Linguistic Processing', 'mk': 'Привлечен превод од текст до текст против превод: прашања надвор од јазичкиот процес', 'ms': 'Terjemahan Mesin Teks- ke- Teks Boleh Terjemahan vs. Terjemahan: Persaingan Melalui Pemprosesan Bahasa', 'ml': 'പദാവലി- ലേഖന്\u200d - ടെക്സ്റ്റ്- ലേഖന്\u200d മെഷീന്\u200d പരിഭാഷ vs. പരിഭാഷ: ലിങ്ഗിസ്റ്റിക് പ്രവര്\u200dത്തനങ്ങള്\u200d', 'mt': 'Traduzzjoni Attainabbli tal-Makkinarju Tekst-Tekst vs. Traduzzjoni: Kwistjonijiet lil hinn mill-Ipproċessar Lingwistiku', 'no': 'Tilgjengelege omsetjing av tekst- til- tekstmaskin mot omsetjing: Utgår enn linguistisk prosessering', 'mn': 'Хэрэглэгч Текст-ээс-Текст Машины хөгжлийн хөгжлийн эсрэг хөгжлийн хөгжлийн эсрэг хөгжлийн хөгжлийн дараа асуудал', 'ro': 'Traducere automată text-în-text realizabilă vs. traducere: probleme dincolo de procesarea lingvistică', 'pl': 'Tłumaczenie maszynowe i tłumaczenie tekstu na tekst: problemy poza przetwarzaniem językowym', 'sr': 'Prihvatljivi prevod teksta na tekst mašine protiv prevoda: Problemi iznad lingvističkog procesa', 'si': 'ප්\u200dරයෝජනය පාළුවන් පණිවිඩයෙන් පණිවිඩයෙන් පණිවිඩය විරුද්ධ විරුද්ධ විරුද්ධ විදිහට:', 'sv': 'Uppnå text-till-text maskinöversättning vs översättning: frågor bortom språklig bearbetning', 'so': 'Turjumista Text-to-Text Machine vs. Turjumidda: Issues Beyond Linguistic Processing', 'ta': 'Attainable Text-to-Text Machine Translation vs. Translation: Issues Beyond Linguistic Processing', 'ur': 'متن سے متن متن مشین ترجمہ مقابلہ ترجمہ: لینگ گیسٹی پرسس کے علاوہ نکالے جاتے ہیں', 'uz': '@ info: whatsthis', 'vi': 'Máy dịch văn bản đạt được kiện dịch: Câu hỏi vượt qua chế độ ngôn ngữ', 'hr': 'Prihvatljivi prevod stroja teksta na tekst protiv prevoda: Problemi iznad lingvističkog procesa', 'nl': 'Bereikbare tekst-naar-tekst machinevertaling versus vertaling: kwesties buiten taalkundige verwerking', 'da': 'Opnåelig tekst-til-tekst maskinoversættelse vs. oversættelse: problemer ud over sproglig behandling', 'de': 'Maschinelle Übersetzung von Text zu Text vs. Übersetzung: Fragen jenseits der sprachlichen Verarbeitung', 'bg': 'Машинен превод от текст в текст срещу превод: проблеми отвъд лингвистичната обработка', 'id': 'Teks-ke-Teks Terjemahan Mesin Terserah vs. Terjemahan: Masalah Diluar Proses Linguistik', 'ko': '언어 처리 이외의 문제', 'tr': 'Elýeterli Metin-tä-Metin Maşynyň Terjime vs. terjime: Hat işlemden başga mesele', 'fa': 'ترجمه دستگاه متن به متن نسبت به ترجمه: مشکلات بیرون پردازش لینگ', 'af': 'Aangaande teks na- teks Masjien Vertaling teen Vertaling: Utgaande Linguistiese Verwerking', 'sq': 'Tekst-tek-tekst i pranueshëm Translation Machine vs. Translation: Issues Beyond Linguistic Processing', 'sw': 'Tafsiri ya Kiteknolojia na Kiteknolojia dhidi ya Tafsiri: Makosa ya Utafiti wa Kilinguistic', 'az': 'Yaxınlaşılabilir Metin-Metin Makinesi Tərcümə vs. Tərcümə: Linguistik İşləmənin Önündə Məsələlər', 'am': 'text-to-text machine translation vs. ትርጉም: Issues Beyond Linguistic Processing', 'bn': 'টেক্সট- থেকে টেক্সট মেশিন অনুবাদ বিরুদ্ধে অনুবাদ: লিঙ্গিস্টিক প্রক্রিয়া', 'ca': 'Traducció de màquina de text a text aconseguible vs. Traducció: qüestions més enllà del processament lingüístic', 'bs': 'Prihvatljiva prevoda teksta na tekst protiv prevoda: Problemi iznad lingvističkog procesa', 'cs': 'Strojový překlad textu na text vs. překlad: problémy mimo jazykové zpracování', 'hy': 'Comment', 'fi': 'Saavutettava teksti tekstiksi konekäännös vs. käännös: kielellisen käsittelyn lisäksi ongelmia', 'et': 'Saadaval tekstist tekstiks masintõlge vs. tõlkimine: keeletöötlusest väljapoole jäävad probleemid', 'jv': 'Attribute', 'ha': 'Attainable Text-to-Text Machine Translation vs. Translation: Issues Beyond Linguistic Processing', 'bo': 'Attainable Text-to-Text Machine Translation vs. Translation: Issues Beyond Linguistic Processing', 'he': 'תורגם וסונכרן ע"י Qsubs מצוות', 'sk': 'Dosežljiv strojni prevod besedila v besedilo v primerjavi s prevajanjem: težave, ki presegajo jezikovno obdelavo'}
{'en': 'Existing approaches for machine translation (MT) mostly translate given text in the source language into the target language and without explicitly referring to information indispensable for producing proper  translation . This includes not only information in other textual elements and modalities than texts in the same document and but also extra-document and non-linguistic information and such as  norms  and  skopos . To design better translation production work-flows and we need to distinguish translation issues that could be resolved by the existing text-to-text approaches and those beyond them. To this end and we conducted an analytic assessment of MT outputs and taking an English-to-Japanese news translation task as a case study. First and examples of  translation issues  and their revisions were collected by a two-stage post-editing (PE) method : performing minimal PE to obtain  translation  attainable based on the given textual information and further performing full PE to obtain truly acceptable  translation  referring to any information if necessary. Then and the collected revision examples were manually analyzed. We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and and reference documents and delineating a clear distinction between  translation  and what text-to-text MT can ultimately attain.', 'fr': "Les approches existantes de traduction automatique (TA) traduisent principalement un texte donné dans la langue source vers la langue cible et sans faire explicitement référence aux informations indispensables à la production d'une traduction correcte. Cela inclut non seulement les informations dans d'autres éléments textuels et modalités que les textes du même document, mais également les informations extra-documentaires et non linguistiques, telles que les normes et les skopos. Afin de concevoir de meilleurs flux de travail de production de traduction, nous devons distinguer les problèmes de traduction qui pourraient être résolus par les approches texte-texte existantes et ceux qui en découlent. À cette fin, nous avons mené une évaluation analytique des sorties de traduction automatique et pris une tâche de traduction de nouvelles de l'anglais vers le japonais comme étude de cas. Tout d'abord, des exemples de problèmes de traduction et de leurs révisions ont été recueillis par une méthode de post-édition (PE) en deux étapes\xa0: effectuer un PE minimal pour obtenir une traduction réalisable sur la base des informations textuelles données et effectuer une PE complète pour obtenir une traduction vraiment acceptable se référant à toute information si nécessaire. Ensuite, les exemples de révision collectés ont été analysés manuellement. Nous avons révélé des problèmes dominants et des informations indispensables pour les résoudre, tels que des spécifications de style et une terminologie précises, des connaissances spécifiques au domaine et des documents de référence, et en délimitant une distinction claire entre la traduction et ce que la traduction automatique de texte peut finalement atteindre.", 'es': 'Los enfoques existentes para la traducción automática (MT) traducen principalmente un texto dado en el idioma de origen al idioma de destino y sin hacer referencia explícita a la información indispensable para producir una traducción adecuada. Esto incluye no solo información en otros elementos y modalidades textuales distintos de los textos del mismo documento, sino también información extradocumental y no lingüística, como normas y skopos. Para diseñar mejores flujos de trabajo de producción de traducción, necesitamos distinguir los problemas de traducción que podrían resolverse con los enfoques de texto a texto existentes y los que están más allá de ellos. Con este fin, realizamos una evaluación analítica de los resultados de MT y tomamos una tarea de traducción de noticias del inglés al japonés como estudio de caso. En primer lugar, se recopilaron ejemplos de problemas de traducción y sus revisiones mediante un método de postedición (PE) de dos etapas: realizar PE mínima para obtener una traducción alcanzable en función de la información textual dada y realizar además PE completa para obtener una traducción verdaderamente aceptable que se refiera a cualquier información si necesario. Luego, los ejemplos de revisión recopilados se analizaron manualmente. Revelamos los problemas dominantes y la información indispensable para resolverlos, como especificaciones de estilo y terminología minuciosas, conocimientos específicos del dominio y documentos de referencia, y delineamos una clara distinción entre la traducción y lo que la traducción automática de texto a texto puede lograr en última instancia.', 'pt': 'As abordagens existentes para tradução automática (TA) traduzem principalmente determinado texto no idioma de origem para o idioma de destino e sem se referir explicitamente a informações indispensáveis para produzir uma tradução adequada. Isso inclui não apenas informações em outros elementos e modalidades textuais que não os textos no mesmo documento, mas também informações extradocumentais e não linguísticas, como normas e skopos. Para projetar melhores fluxos de trabalho de produção de tradução, precisamos distinguir os problemas de tradução que podem ser resolvidos pelas abordagens texto-a-texto existentes e aquelas além delas. Para isso, realizamos uma avaliação analítica dos resultados da TA e tomamos como estudo de caso uma tarefa de tradução de notícias de inglês para japonês. O primeiro e os exemplos de problemas de tradução e suas revisões foram coletados por um método de pós-edição (PE) de dois estágios: realizando PE mínimo para obter tradução alcançável com base nas informações textuais fornecidas e realizando PE completo para obter tradução verdadeiramente aceitável referente a qualquer informações se necessário. Em seguida, os exemplos de revisão coletados foram analisados manualmente. Revelamos questões dominantes e informações indispensáveis para resolvê-las, como especificações de estilo refinadas e terminologia e conhecimento específico de domínio e documentos de referência e delineando uma distinção clara entre tradução e o que a TA texto-a-texto pode alcançar.', 'ar': 'تؤدي الأساليب الحالية للترجمة الآلية (MT) في الغالب إلى ترجمة نص معين في اللغة المصدر إلى اللغة الهدف ودون الإشارة صراحةً إلى المعلومات التي لا غنى عنها لإنتاج الترجمة المناسبة. وهذا لا يشمل فقط المعلومات الموجودة في العناصر والطرائق النصية الأخرى غير النصوص الموجودة في نفس الوثيقة ولكن أيضًا المعلومات الإضافية والغير لغوية مثل القواعد و skopos. لتصميم تدفقات عمل أفضل لإنتاج الترجمة ، نحتاج إلى التمييز بين مشكلات الترجمة التي يمكن حلها من خلال مناهج تحويل النص إلى نص الحالية وتلك التي تتجاوزها. تحقيقًا لهذه الغاية ، أجرينا تقييمًا تحليليًا لمخرجات الترجمة الآلية وأخذنا مهمة ترجمة الأخبار من الإنجليزية إلى اليابانية كدراسة حالة. تم جمع أول وأمثلة لقضايا الترجمة ومراجعاتها بطريقة التحرير اللاحق المكونة من مرحلتين: أداء الحد الأدنى من PE للحصول على الترجمة التي يمكن تحقيقها بناءً على المعلومات النصية المقدمة وإجراء المزيد من PE الكامل للحصول على ترجمة مقبولة حقًا تشير إلى أي المعلومات إذا لزم الأمر. ثم تم تحليل أمثلة المراجعة التي تم جمعها يدويًا. لقد كشفنا عن القضايا والمعلومات السائدة التي لا غنى عنها لحلها ، مثل مواصفات الأسلوب الدقيق والمصطلحات والمعرفة الخاصة بالمجال والوثائق المرجعية وتحديد تمييز واضح بين الترجمة وما يمكن أن يحققه الترجمة الآلية من نص إلى نص في النهاية.', 'ja': '機械翻訳（ MT ）の既存のアプローチは、ほとんどの場合、適切な翻訳を作成するために不可欠な情報を明示的に参照することなく、ソース言語のテキストをターゲット言語に翻訳します。 これには、同じ文書内のテキスト以外の他のテキスト要素やモダリティの情報だけでなく、規範やスコポなどの文書外および非言語情報も含まれます。 より良い翻訳制作ワークフローを設計するには、既存のテキスト間アプローチで解決できる翻訳の問題と、それを超えた問題を区別する必要があります。 そのために、MTのアウトプットを分析的に評価し、英語から日本語へのニュース翻訳タスクをケーススタディとして行いました。 翻訳の問題とその改訂の最初の例は、2段階のポストエディット（ PE ）方法によって収集されました：与えられたテキスト情報に基づいて達成可能な翻訳を取得するために最小限のPEを実行し、必要に応じて任意の情報を参照して真に許容可能な翻訳を取得するために完全なPEをさらに実行しました。 そして、収集した改訂例を手動で分析した。 私たちは、それらを解決するために不可欠な支配的な問題と情報、例えば、細かいスタイルの仕様と用語、ドメイン固有の知識、および参照文書を明らかにし、翻訳とテキストツーテキストMTが最終的に達成できるものとの間の明確な区別を明確にしました。', 'zh': '今机器翻译(MT)法多以源语给定文本翻译成语言,而未明引成正译不可或缺信息。 非唯文本要素与式中信息也,又文外非言语信息,规模skopos也。 为计善译生业流行,须分别现在文本到文本法可以解释的译法和越他们的方法。 为析机器翻译评估,以英语日语新闻翻译事为例。 先是,译者示例因两译而辑(PE)法:最小者PE以得给定本信息之译,更行全PE以得真受之译,参考信息。 然后示例手动析之。 明乎不可或缺之大要,细粒度乎风术语,特定乎知参文档,明乎译本机器翻译终可致也。', 'hi': 'मशीन अनुवाद (एमटी) के लिए मौजूदा दृष्टिकोण ज्यादातर स्रोत भाषा में दिए गए पाठ को लक्ष्य भाषा में अनुवादित करते हैं और उचित अनुवाद के उत्पादन के लिए अनिवार्य जानकारी का स्पष्ट रूप से उल्लेख किए बिना। इसमें न केवल एक ही दस्तावेज़ में ग्रंथों की तुलना में अन्य पाठ्य तत्वों और तौर-तरीकों में जानकारी शामिल है, बल्कि अतिरिक्त-दस्तावेज़ और गैर-भाषाई जानकारी और जैसे मानदंड और स्कोपोस भी शामिल हैं। बेहतर अनुवाद उत्पादन कार्य-प्रवाह को डिजाइन करने के लिए और हमें अनुवाद के मुद्दों को अलग करने की आवश्यकता है जिन्हें मौजूदा टेक्स्ट-टू-टेक्स्ट दृष्टिकोण और उनसे परे उन लोगों द्वारा हल किया जा सकता है। इस अंत तक और हमने एमटी आउटपुट का एक विश्लेषणात्मक मूल्यांकन किया और एक मामले के अध्ययन के रूप में अंग्रेजी-से-जापानी समाचार अनुवाद कार्य लिया। अनुवाद के मुद्दों और उनके संशोधनों के पहले और उदाहरणों को दो-चरण पोस्ट-एडिटिंग (पीई) विधि द्वारा एकत्र किया गया था: दी गई पाठ्य जानकारी के आधार पर प्राप्य अनुवाद प्राप्त करने के लिए न्यूनतम पीई का प्रदर्शन करना और यदि आवश्यक हो तो किसी भी जानकारी का उल्लेख करते हुए वास्तव में स्वीकार्य अनुवाद प्राप्त करने के लिए पूर्ण पीई का प्रदर्शन करना। फिर और एकत्र किए गए संशोधन उदाहरणों का मैन्युअल रूप से विश्लेषण किया गया था। हमने प्रमुख मुद्दों और जानकारी को हल करने के लिए अपरिहार्य रूप से प्रकट किया और जैसे कि ठीक-ठाक शैली विनिर्देशों और शब्दावली और डोमेन-विशिष्ट ज्ञान और और संदर्भ दस्तावेजों और अनुवाद के बीच एक स्पष्ट अंतर को चित्रित करना और पाठ-से-पाठ एमटी अंततः प्राप्त कर सकता है।', 'ru': 'Существующие подходы к машинному переводу (МП) в основном переводят данный текст на исходном языке на целевой язык без прямой ссылки на информацию, необходимую для обеспечения надлежащего перевода. Это включает не только информацию в других текстовых элементах и условиях, помимо текстов в том же документе, но и внедокументарную и неязыковую информацию, такую как нормы и скопос. Для разработки более качественных рабочих процессов по подготовке переводов нам необходимо различать вопросы перевода, которые могут быть решены с помощью существующих межтекстовых подходов и тех, которые выходят за их рамки. С этой целью мы провели аналитическую оценку результатов MT и взяли в качестве примера задачу перевода новостей с английского на японский язык. Первый и примеры проблем с переводом и их исправления были собраны с помощью двухэтапного метода постредактирования (PE): выполнение минимального PE для получения перевода, достижимого на основе данной текстовой информации, и дальнейшее выполнение полного PE для получения действительно приемлемого перевода со ссылкой на любую информацию, если это необходимо. Затем и собранные примеры ревизий были проанализированы вручную. Мы выявили доминирующие вопросы и информацию, необходимые для их решения, такие как тонкозернистые спецификации стилей и терминология, а также знания и справочные документы по конкретным областям, и определили четкое различие между переводом и тем, чего в конечном итоге может достичь текстовый МП.', 'ga': 'Aistríonn cineálacha cur chuige atá ann cheana féin maidir le haistriúchán meaisín (MT) téacs tugtha sa teanga fhoinseach go dtí an sprioctheanga den chuid is mó agus gan tagairt shainráite a dhéanamh d’eolas atá riachtanach chun aistriúchán cuí a dhéanamh. Áirítear leis sin ní hamháin faisnéis atá in eilimintí agus i módúlachtaí téacsacha eile seachas téacsanna sa doiciméad céanna, ach freisin faisnéis sheach-dhoiciméid agus neamhtheangeolaíoch agus amhail noirm agus skopos. Chun sreafaí oibre táirgthe aistriúcháin níos fearr a dhearadh agus ní mór dúinn idirdhealú a dhéanamh idir saincheisteanna aistriúcháin a d’fhéadfaí a réiteach leis na cineálacha cur chuige téacs-go-téacs atá ann cheana féin agus iad siúd lasmuigh díobh. Chuige sin agus rinneamar measúnú anailíseach ar aschuir MT agus rinneamar tasc aistriúcháin nuachta Béarla go Seapáinis mar chás-staidéar. Bailíodh an chéad agus samplaí de cheisteanna aistriúcháin agus a n-athbhreithnithe trí mhodh iar-eagarthóireachta dhá chéim (PE): PE íosta a dhéanamh chun aistriúchán insroichte a fháil bunaithe ar an bhfaisnéis téacsúil a tugadh agus PE iomlán a dhéanamh tuilleadh chun aistriúchán fíor-inghlactha a fháil ag tagairt d’aon. eolas más gá. Ansin agus rinneadh anailís de láimh ar na samplaí athbhreithnithe a bailíodh. Nochtamar príomhcheisteanna agus faisnéis nach bhfuil riachtanach chun iad a réiteach, mar shampla sonraíochtaí agus téarmaíocht mhínghlanta stíle agus eolas agus doiciméid thagartha a bhaineann go sonrach leis an bhfearann agus idirdhealú soiléir a dhéanamh idir aistriúchán agus an méid is féidir le MT téacs-go-téacs a bhaint amach sa deireadh.', 'ka': 'მხოლოდ მაქსინის გარგულისხმებისთვის (MT) მხოლოდ მივიღეთ ტექსტის მსოფლიო ენაში მინიშვნელოვანი ენაში გარგულისხმებით და გარგულისხმებით ინფორმაციის შესაძლებელად და ეს არა მხოლოდ სხვა ტექსტულ ელემენტებში და მოდილიტებში ინფორმაცია, ვიდრე ერთი დოკუმენტში ტექსტის და ასევე ექსტრე-დოკუმენტის და არ-ლენგუმენტიური ინფორმაცია და როგ შემდეგ უფრო ძალიან გადაწყვეტილებელი სამუშაო სამუშაო წყვეტილება და ჩვენ უნდა განსხვავოთ გადაწყვეტილებელი პრობლემები, რომელიც შეიძლება გადაწყვეტილება სექ ჩვენ MT შემდეგ ანალიტიკური გავაკეთებდით და ინგლისურად იაპონურად ახალგაზრულების გადაწყვეტა დავაკეთებდით. პირველი და მაგალითები შეცვლის პრობლემების და მათი რედაქტირების შემდეგ ორ ფაეჯის მორედაქტირების (PE) მეტიდან შექმნა: მინიმალური PE-ს გამოყენება, რომელიც მივიღეთ ტექსტულური ინფორმაციის ბაზაზე მივიღეთ შეცვლის შემდეგ და დამატე შემდეგ კოლექცირებული რევისუციის მაგალითები ხელსახურად ანალიზებულია. ჩვენ განვიხსნა დომინტური პრობლემენტები და ინფორმაცია, რომელიც მათ გადაწყვეტილებისთვის უნდა უნდა გავაკეთოთ და როგორც კონფიკური სტილის სპეციფიკაციები და ტერმინოლოგია და დიომინური კონფიკური ცოდნენები', 'hu': 'A gépi fordításra vonatkozó meglévő megközelítések leginkább a forrásnyelven adott szöveget fordítanak a célnyelvre, anélkül, hogy kifejezetten hivatkoznának a megfelelő fordítás előállításához elengedhetetlen információkra. Ez nem csak az ugyanabban a dokumentumban szereplő szövegeken és módokon kívüli információkat tartalmazza, hanem a dokumentumon kívüli és nem nyelvű információkat, például a normákat és a skopost is. A jobb fordításgyártási munkafolyamatok kialakítása érdekében, és meg kell különböztetnünk azokat a fordítási problémákat, amelyeket a meglévő szöveg-szöveg megközelítéssel lehetne megoldani és azokon túl. Ennek érdekében elvégeztük az MT kimeneteinek analitikus értékelését, és esettanulmányként vettünk egy angol-japán hírfordítási feladatot. Az első és a fordítási problémákra és azok módosítására vonatkozó példákat egy kétlépcsős szerkesztési (PE) módszerrel gyűjtöttük össze: minimális PE elvégzése az adott szöveges információk alapján elérhető fordítás elérése érdekében, és további teljes PE elvégzése annak érdekében, hogy valóban elfogadható fordítást kapjunk, szükség esetén bármilyen információra hivatkozva. Ezután az összegyűjtött verziós példákat manuálisan elemeztük. Feltártuk a megoldásukhoz elengedhetetlen domináns kérdéseket és információkat, mint például a finom szemű stílusspecifikációk és terminológia, valamint a tartományspecifikus ismeretek és referenciadokumentumok, valamint a fordítás és a szöveg-szöveg közötti egyértelmű különbséget határoztunk meg.', 'el': 'Οι υπάρχουσες προσεγγίσεις για τη μηχανική μετάφραση (ΜΤ) μεταφράζουν ως επί το πλείστον το συγκεκριμένο κείμενο στη γλώσσα προέλευσης στη γλώσσα-στόχο και χωρίς να αναφέρονται ρητά σε πληροφορίες απαραίτητες για την παραγωγή σωστής μετάφρασης. Αυτό περιλαμβάνει όχι μόνο πληροφορίες σε άλλα κειμενικά στοιχεία και λεπτομέρειες από τα κείμενα στο ίδιο έγγραφο, αλλά και πληροφορίες εκτός εγγράφων και μη γλωσσικές, όπως οι κανόνες και οι συνοδοί. Για να σχεδιάσουμε καλύτερες ροές εργασίας παραγωγής μετάφρασης και πρέπει να διακρίνουμε ζητήματα μετάφρασης που θα μπορούσαν να επιλυθούν από τις υπάρχουσες προσεγγίσεις κειμένου σε κείμενο και εκείνα πέραν αυτών. Για το σκοπό αυτό πραγματοποιήσαμε μια αναλυτική αξιολόγηση των αποτελεσμάτων της ΜΤ και αναλάβαμε μια εργασία μετάφρασης ειδήσεων από τα αγγλικά προς τα ιαπωνικά ως μελέτη περίπτωσης. Πρώτον και παραδείγματα μεταφραστικών ζητημάτων και των αναθεωρήσεων τους συλλέχθηκαν με μια μέθοδο δύο σταδίων μετά την επεξεργασία (ΠΕ): την εκτέλεση ελάχιστων ΠΕ για να επιτευχθεί η μετάφραση με βάση τις δεδομένες πληροφορίες κειμένου και την περαιτέρω εκτέλεση πλήρους ΠΕ για την απόκτηση πραγματικά αποδεκτής μετάφρασης που θα αναφέρεται σε οποιαδήποτε πληροφορία εάν είναι απαραίτητο. Στη συνέχεια και τα συλλεγμένα παραδείγματα αναθεώρησης αναλύθηκαν χειροκίνητα. Αποκαλύφαμε κυρίαρχα ζητήματα και πληροφορίες που είναι απαραίτητες για την επίλυσή τους, όπως λεπτομερείς προδιαγραφές ύφους και ορολογία και γνώσεις ειδικού τομέα και έγγραφα αναφοράς και οριοθετήσαμε μια σαφή διάκριση μεταξύ της μετάφρασης και του τι μπορεί τελικά να επιτύχει η ΜΤ από κείμενο σε κείμενο.', 'it': "Gli approcci esistenti per la traduzione automatica traducono per lo più un dato testo nella lingua di origine nella lingua di destinazione e senza fare esplicito riferimento alle informazioni indispensabili per produrre una traduzione corretta. Ciò include non solo informazioni in altri elementi e modalità testuali rispetto ai testi dello stesso documento, ma anche informazioni extra-documentali e non linguistiche e come norme e skopos. Per progettare migliori flussi di lavoro per la produzione di traduzioni e dobbiamo distinguere i problemi di traduzione che potrebbero essere risolti dagli approcci text-to-text esistenti e quelli al di là di essi. A tal fine abbiamo condotto una valutazione analitica dei risultati MT e prendendo come caso studio un compito di traduzione di notizie dall'inglese al giapponese. Il primo e gli esempi di problemi di traduzione e le loro revisioni sono stati raccolti con un metodo post-editing (PE) in due fasi: eseguire PE minime per ottenere traduzioni raggiungibili sulla base delle informazioni testuali fornite e eseguire ulteriormente PE complete per ottenere traduzioni realmente accettabili facendo riferimento a qualsiasi informazione, se necessario. Poi e gli esempi di revisione raccolti sono stati analizzati manualmente. Abbiamo rivelato questioni dominanti e informazioni indispensabili per risolverli, come specifiche di stile e terminologia a grana fine, conoscenze e documenti di riferimento specifici per il settore e delineando una chiara distinzione tra traduzione e ciò che MT testo a testo può raggiungere in definitiva.", 'mk': 'Постојаните пристапи за машински превед (MT) претежно преведуваат даден текст на изворниот јазик на јазикот на целта и без експлицитно да се однесуваат на информации неопходни за производство на соодветен превед. Ова вклучува не само информации во други текстуални елементи и моделитети отколку тексти во истиот документ, туку и екстра-документални и нејазични информации, како што се норми и скоpos. За да дизајнираме подобри производства на превод и мораме да ги разликуваме преводните прашања кои би можеле да се решат со постојните пристапи од текст до текст и оние надвор од нив. За ова и спроведовме аналитичка проценка на излезите од МТ и земавме задача за превод на вести од англиски до јапонски како случајна студија. First and examples of translation issues and their revisions were collected by a two-stage post-editing (PE) method: performing minimal PE to obtain translation attainable based on the given textual information and further performing full PE to obtain truly acceptable translation referring to any information if necessary.  Then and the collected revision examples were manually analyzed.  Откривме доминантни прашања и информации кои се неопходни за решавање на нив, како што се спецификациите за фин стил и терминологијата и знаењето специфично за доменот и референтните документи и дефинирање јасна разлика помеѓу преводот и она што текст-текст MT може на крајот да го постигне.', 'kk': 'Компьютерді аудару (MT) үшін барлық арқылы көпшілік көзінде келтірілген мәтін көзінде мақсатты тіліне аудару және дұрыс аудару үшін керек мәліметтерге аудару керек емес. Бұл тексті бір құжаттың мәтіндерінен басқа мәтіндер мен әдістерде емес, сондай-ақ қосымша құжат және лингвистикалық емес мәліметтер және нормалар және skopos секілді. Жақсы аудармаларды жасау үшін жұмыс жұмыс бағдарламаларын құрастыру үшін жұмыс істеу мәселелерін жасау үшін біз оның артындағы мәтіннен келесі және оның артындағы аудармаларды Бұл соңында MT шығысын аналитикалық оқиға және ағылшын-жапон жаңалық аудару тапсырмасын оқиға ретінде алдық. Алғашқы және аудармалардың мәселелері және олардың редакциялары екі- этап өңдеу (PE) әдісімен жинақталды: керек мәтіннің мәліметіне негізделген аудармаларды орындау үшін төменгі PE жұмыс істеу және керек болса, қабылданатын аудармаларды қа Біріктірілген редакциялардың мысалдары қолмен анализияланды. Біз оларды шешу үшін доминистік мәселелерді және мәліметті шешуге мүмкіндік емес, мәліметті жасап, терминология және доменге ерекше білім және сілтеме құжаттарды көрсеттік. Мәтінде MT-ге қандай мәтінде қай', 'ms': 'pendekatan yang wujud untuk terjemahan mesin (MT) kebanyakan terjemahan teks yang diberikan dalam bahasa sumber ke bahasa sasaran dan tanpa rujuk secara jelas kepada maklumat yang tidak diperlukan untuk menghasilkan terjemahan yang betul. Ini termasuk bukan sahaja maklumat dalam unsur teks dan modaliti lain selain teks dalam dokumen yang sama dan juga maklumat ekstra-dokumen dan bukan-bahasa dan seperti norm dan skopos. Untuk merancang aliran kerja produksi terjemahan yang lebih baik dan kita perlu membezakan isu terjemahan yang boleh diselesaikan oleh pendekatan teks-ke-teks yang wujud dan yang diluar mereka. Untuk ini dan kami melakukan penilaian analitik output MT dan mengambil tugas terjemahan berita bahasa Inggeris-Jepun sebagai kajian kes. Pertama dan contoh isu terjemahan dan revisi mereka dikumpulkan dengan kaedah kedua-tahap selepas-edisi (PE): melaksanakan PE minimal untuk mendapatkan terjemahan yang boleh dicapai berdasarkan maklumat teks yang diberikan dan melanjutkan melaksanakan PE penuh untuk mendapatkan terjemahan yang benar-benar diterima merujuk kepada mana-mana maklumat jika perlu. Kemudian contoh revisi yang dikumpulkan diuji secara manual. Kami mengungkapkan isu-isu dominan dan maklumat yang tidak diperlukan untuk memecahkan mereka dan seperti spesifikasi gaya yang sempurna dan terminologi dan pengetahuan-spesifik domain dan dokumen rujukan dan membatasi perbezaan jelas antara terjemahan dan apa yang MT teks-ke-teks akhirnya boleh mencapai.', 'ml': 'മെഷീന്\u200d പരിഭാഷയ്ക്കുള്ള നിലവിലുള്ള വഴികള്\u200d (എംടി) മിക്കവാറില്\u200d മിക്കവാറും നല്\u200dകപ്പെട്ട ട ടെക്സ്റ്റ് ഭാഷയില്\u200d ലക്ഷ്യഭാഷയിലേക്ക്  ഒരേ രേഖയിലെ പദാവലികളെക്കാള്\u200d വേറെയും പദാവലികളിലും വേറെ പദാവലികളിലും വിവരങ്ങള്\u200d മാത്രമല്ല, കൂടുതല്\u200d രേഖയും ഭാഷിക വിവരങ്ങളും പോലെയുള്ള സ്കോ നിലവിലുള്ള ടെക്സ്റ്റ് ടെക്സ്റ്റ് മാറ്റുന്നതിന്റെയും പുറത്തുള്ള മറ്റുള്ളവരുടെയും അടിസ്ഥാനങ്ങളാല്\u200d പരിശോധിക്കുന്നതിന ഈ അവസാനത്തിനു വേണ്ടി ഞങ്ങള്\u200d എംടി പുട്ടികളുടെ അന്വേഷണം നടത്തി ഒരു കേസ് പഠനത്തിനായി ഇംഗ്ലീഷില്\u200d നിന്നും ജപ്പാനീസിലെ  @ info: status പിന്നെ സംഘടിപ്പിക്കപ്പെട്ട പരിശോധന ഉദാഹരണങ്ങള്\u200d കൈകാര്യം പരിശോധിക്കപ്പെട്ടു. അവയെ തീരുമാനിക്കാന്\u200d ആവശ്യമില്ലാത്ത പ്രശ്നങ്ങളെയും വിവരങ്ങളെയും നാം വെളിപ്പെടുത്തിയിരിക്കുന്നു. അതുപോലെ നല്ല കൃത്രിമമായ രീതിയിലെ വിശദീകരണങ്ങളെയും ടെര്\u200d', 'mt': 'Approċċi eżistenti għat-traduzzjoni bil-magna (MT) l-aktar jittraduċu t-test mogħti fil-lingwa tas-sors fil-lingwa fil-mira u mingħajr ma jirreferu espliċitament għal informazzjoni indispensabbli għall-produzzjoni ta’ traduzzjoni xierqa. Dan jinkludi mhux biss informazzjoni f’elementi u modalitajiet testwali oħra għajr testi fl-istess dokument u wkoll informazzjoni extra-dokument u mhux lingwistika u bħan-normi u skopos. Biex niddisinjaw flussi tax-xogħol ta’ produzzjoni ta’ traduzzjoni aħjar u jeħtieġ li niddistingwu kwistjonijiet ta’ traduzzjoni li jistgħu jiġu solvuti bl-approċċi eżistenti minn test għal test u dawk lil hinn minnhom. Għal dan il-għan għamilna valutazzjoni analitika tal-outputs MT u ħadna kompitu ta’ traduzzjoni tal-a ħbarijiet Ingliż-Ġappuniż bħala studju ta’ każ. L-ewwel u eżempji ta’ kwistjonijiet ta’ traduzzjoni u r-reviżjonijiet tagħhom inġabru permezz ta’ metodu ta’ żewġ stadji wara l-edizzjoni (PE): il-prestazzjoni ta’ PE minimu biex tinkiseb traduzzjoni li tista’ tinkiseb abbażi tal-informazzjoni testwali mogħtija u l-prestazzjoni ulterjuri ta’ PE sħiħ biex tinkiseb traduzzjoni verament a ċċettabbli li tirreferi għal kwalunkwe informazzjoni jekk meħtieġ. Imbagħad u l-eżempji ta’ reviżjoni miġbura ġew analizzati manwalment. We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and and reference documents and delineating a clear distinction between translation and what text-to-text MT can ultimately attain.', 'no': 'Det eksisterande tilnærmingar for maskinsomsetjing (MT) oversetter hovudsakelig oppgitt tekst i kjeldespråket til målspråket, og utan uttrykk refererer til informasjon som kan vera uttrykkbar for å produsera rett omsetjing. Dette inneheld ikkje berre informasjon i andre tekstelementer og modaliteter enn tekstar i det same dokumentet, men også ekstra dokument og ikkje-lingvisk informasjon, slik som norm og skopos. For å utforme betre omsetjingsverktøyar og må vi forskjere omsetjingsverktøyar som kan løysa av dei eksisterande tilnærmingane for tekst til tekst og dei etter dei. I denne slutten vedførte vi ein analysk vurdering av MT-utgåver og ta eit omsetjingsprogram på engelsk til japansk som tilfelle. Første og eksemplar av omsetjingsproblasjonar og revisjonane sine vart samla med ein to stadig postredigeringsmetode (PE): å utføra minimal PE for å få omsetjing som er tilgjengeleg basert på den oppgjevne tekstinformasjonen og framleis utføra fullstendig PE for å få sannsynleg akseptabel omsetjing som refererer til nokon informasjon dersom nødvendig. Og eksemplane for samlinga av revisjonar vart manuelt analysert. Vi oppdaga dominære problemer og informasjon som er indispensabil for å løysa dei og slik som fin-kornerte stilspesifikasjonar og terminologikk og domenespesifikke kunnskap og referansdokument og delinisering av ein klart skilnad mellom omsetjing og kva tekst-til-tekst MT kan til slutt nå oppnå.', 'mn': 'Машин хөрөнгө оруулах (MT) арга барилгууд ихэнхдээ эх үүсвэрийн хэл дээр өгөгдсөн текст зориулагдсан хэл рүү орчуулдаг ба зөв хөрөнгө оруулах хэрэгтэй мэдээллийг тодорхой харуулахгүй. Энэ нь зөвхөн нэг баримт бичсэн текстээс илүү бусад текст элементүүд болон хувилбаруудын тухай мэдээлэл биш, мөн нэмэлт баримт, хэлний бус мэдээлэл болон нормууд, сургууль мэт. Бид илүү сайн хөгжлийн үйлдвэрлэлийн ажлын урсгалыг зохион байгуулахын тулд оршиж байгаа текст болон текст руу шийдвэрлэх боломжтой орших асуудлыг тодорхойлох хэрэгтэй. Энэ төгсгөлд бид MT үр дүнг шинжилгээ хийж, Англи-Японы мэдээллийн хөрөнгө оруулах үйлдлийг нэг судалгаа болгосон. Эхлээд орчуулагчийн асуудлын жишээ болон түүний шинэчлэлүүдийг хоёр этап эцэст (PE) загвараар цуглуулсан. Хэрвээ хэрэгтэй бол ямар ч мэдээллийг хүлээн зөвхөн хүлээн зөвшөөрөх боломжтой байх боломжтой байх боломжтой мэдээлэл гаргах боломжтой PE-г ба Дараа нь цуглуулсан шинэчлэлийн жишээ гараар шинжилгээ хийгдсэн. Бид тэднийг шийдвэрлэх шаардлагатай асуудлуудыг, мэдээллийг харуулсан. Жишээлбэл сайхан хэлбэрийн тодорхойлолт, терминологи, домены тодорхойлолт мэдлэг, сэтгэл баримтууд, хөрөнгө баримтууд, орчуулалт болон текст-текст MT-д юу болох', 'pl': 'Istniejące podejścia do tłumaczenia maszynowego (MT) głównie tłumaczą dany tekst z języka źródłowego na język docelowy i nie odnoszą się wyraźnie do informacji niezbędnych do wykonania prawidłowego tłumaczenia. Obejmuje to nie tylko informacje zawarte w innych elementach tekstowych i modyfikacjach niż teksty w tym samym dokumencie, ale także informacje pozadokumentowe i niejęzykowe, takie jak normy i skopos. Aby zaprojektować lepsze przepływy robocze w zakresie produkcji tłumaczeń i musimy rozróżnić kwestie tłumaczeniowe, które mogłyby zostać rozwiązane przez istniejące podejście tekstowo-tekstowe i te poza nimi. W tym celu przeprowadziliśmy analityczną ocenę wyników MT oraz podjęliśmy zadanie tłumaczenia wiadomości z języka angielskiego na japoński jako studium przypadku. Pierwsze i przykłady problemów tłumaczeniowych oraz ich korekty zebrano za pomocą dwuetapowej metody post-edycji (PE): wykonanie minimalnego PE w celu uzyskania możliwego do osiągnięcia tłumaczenia na podstawie danych informacji tekstowych oraz dalsze wykonanie pełnego PE w celu uzyskania rzeczywiście akceptowalnego tłumaczenia odnoszącego się do wszelkich informacji w razie potrzeby. Następnie i zebrane przykłady wersji zostały ręcznie analizowane. Ujawniliśmy dominujące kwestie i informacje niezbędne do ich rozwiązania, takie jak precyzyjne specyfikacje stylu i terminologię oraz wiedzę i dokumenty referencyjne oraz wyraźne rozróżnienie między tłumaczeniem a tym, co MT ostatecznie może osiągnąć.', 'ro': 'Abordările existente pentru traducerea automată (MT) traduc în principal textul dat în limba sursă în limba țintă și fără a face trimitere explicită la informațiile indispensabile pentru producerea unei traduceri adecvate. Aceasta include nu numai informații din alte elemente și modalități textuale decât textele din același document, ci și informații extradocumentare și non-lingvistice, precum norme și skopos. Pentru a concepe fluxuri de lucru mai bune de producție a traducerilor și trebuie să distingem problemele de traducere care ar putea fi rezolvate prin abordările text-text existente și cele dincolo de acestea. În acest scop, am realizat o evaluare analitică a rezultatelor MT și am luat ca studiu de caz o sarcină de traducere a știrilor din engleză în japoneză. În primul rând și exemple de probleme de traducere și revizuiri ale acestora au fost colectate printr-o metodă post-editare în două etape (PE): efectuarea PE minimă pentru a obține traduceri realizabile pe baza informațiilor textuale date și efectuarea PE completă pentru a obține traduceri cu adevărat acceptabile referitoare la orice informație, dacă este necesar. Apoi și exemplele de revizie colectate au fost analizate manual. Am dezvăluit probleme dominante și informații indispensabile pentru rezolvarea acestora, precum specificațiile de stil fine și terminologia și cunoștințele specifice domeniului și documentele de referință și delimitarea unei distincții clare între traducere și ceea ce MT poate obține în cele din urmă.', 'so': 'Tilmaamaha joogtada ee turjumista machine (MT) ugu badnaan ku turjuma text in sourceed language in to the language of target and without explicit referring to information indispensable for producing proper translation. Taas waxaa ku jira macluumaad kale oo ku saabsan elementada qoraalka iyo qaababka kale oo aan qoraalka ku qornayn qoraalkaas oo kaliya, waxaase sidoo kale ku qoran macluumaad dheeraad ah iyo macluumaad aan luuqad lahayn iyo tusaale ahaan caadooyinka iyo skopos. Si aan u qorno ubaxyo ka wanaagsan oo turjumista shaqada, waxaana u baahan nahay in aan kala soocno arimaha turjumidda oo ay u xalli karto qaababka qoraalka-qoriga ah iyo kuwa ka dambeeya. Taas darteed waxaynu sameynay qiimeyn analyaal ah oo ku saabsan soo baxayaasha MT, waxaana qaadanay shaqada turjumista Ingiriis-to-Japanese sida waxbarasho. Marka ugu horeysa iyo tusaale ahaan arimaha turjumaadda iyo beddelinkooda waxaa lagu soo ururiyey qaab labo marxaladood ah oo lagu qorayo (PE) si aad u hesho turjumaadda ugu yaraan PE si aad u hesho macluumaadka qoraalka ah iyo si aad u sameyneyso buuxda PE si aad u hesho turjumaadka aad u aqbali karto si ay u hesho macluumaad haddii loo baahdo. Markaas waxaa lagu qeybiyay tusaalayaasha bedelka la soo ururiyey. Waxaan soo dejinay arimaha maamulka ah iyo macluumaad aan loo baahnayn in loo xalaalo, tusaale ahaan qalabka dhaqdhaqaalaha, garsooridda iyo aqoonta deegaanka iyo warqadaha qaabka ah iyo farsamada, iyo si cad u kala duwan turjumista iyo maxay ugu dambaysta u heli karto MT.', 'lt': 'Existing approaches for machine translation (MT) mostly translate given text in the source language into the target language and without explicitly referring to information indispensable for producing proper translation.  Tai apima ne tik informaciją tekstiniais elementais ir būdais, išskyrus tekstus tame pačiame dokumente, bet ir papildomą ir ne kalbinę informaciją, pavyzdžiui, normas ir skopos. Siekiant sukurti geresnius vertimo raštu gamybos darbo srautus ir turime išskirti vertimo klausimus, kurie galėtų būti išspręsti taikant esamus teksto į teksto metodus ir tuos, kurie yra už jų ribų. Šiuo tikslu atlikome MT rezultatų analizę ir kaip atvejų tyrimą ėmėme vertimo žodžiu anglų kalba į japonų kalbą užduotį. Pirmasis ir vertimo klausimų pavyzdžiai ir jų pataisymai buvo surinkti dviejų etapų po redakcijos (PE) metodu: atliekant minimal ų PE vertimą, kuris būtų įmanomas remiantis pateikta tekstine informacija, ir toliau atliekant visą PE vertimą, siekiant gauti iš tikrųjų priimtiną vertimą, prireikus nurodant bet kokią informaciją. Tuomet surinkti peržiūros pavyzdžiai buvo analizuojami rankiniu būdu. Mes atskleidėme dominuojančius klausimus ir informaciją, būtiną juos išspręsti, pavyzdžiui, smulkių grūdų stilių specifikacijas ir terminologiją bei konkrečiai sričiai būdingas žinias bei etaloninius dokumentus, taip pat aiškiai apibrėžėme vertimo ir teksto MT skirtumą.', 'sv': 'Befintliga metoder för maskinöversättning översätter mestadels viss text på källspråket till målspråket och utan att uttryckligen hänvisa till information som är nödvändig för att åstadkomma korrekt översättning. Detta omfattar inte bara information i andra textelement och former än texter i samma dokument, utan även extradokument och icke-språklig information och såsom normer och skopos. För att utforma bättre arbetsflöden för översättningsproduktion måste vi skilja på översättningsfrågor som kan lösas genom befintliga text-till-text-metoder och dem utanför dem. För detta ändamål genomförde vi en analytisk bedömning av MT-resultat och tog en engelsk-japansk nyhetsöversättningsuppgift som fallstudie. För det första och exempel på översättningsfrågor och deras revideringar samlades in med hjälp av en tvåstegs efterredigeringsmetod (PE): utföra minimal PE för att uppnå översättning baserad på den givna textinformationen och ytterligare utföra fullständig PE för att få verkligt godtagbar översättning med hänvisning till all information om nödvändigt. Därefter analyserades de insamlade versionsexemplen manuellt. Vi avslöjade dominerande frågor och information som är oumbärlig för att lösa dem, såsom finkorniga stilspecifikationer och terminologi och domänspecifika kunskaper och referensdokument och definierade en tydlig skillnad mellan översättning och vad text-till-text MT i slutändan kan uppnå.', 'ta': 'கணினி மொழிபெயர்ப்புக்கான தற்போதைய வழிமுறைகள் (MT) பெரும்பாலாக கொடுக்கப்பட்ட உரையின் மூல மொழியில் சேர்க்கப்பட்ட மொழியில் மொழ இது ஒரே ஆவணத்தில் உள்ள உரைகளை விட உரைகளை வெறும் உரைகளில் மற்றொரு நிரல் உறுப்புகளில் மட்டும் தகவல் சேர்க்கவில்லை மற்றும் அதிக ஆவணம் மற்றும் மொழிய சிறந்த மொழிபெயர்ப்பு உருவாக்குதல் வேலை பூக்கங்களை வடிவமைக்க நாம் மொழிப்பெயர்ப்பு பிரச்சனைகளை வேறுபடுத்த வேண்டும் இருக இந்த முடிவிற்கு நாங்கள் MT வெளியீடுகளை ஆராய்ச்சி செய்தோம் மற்றும் ஒரு செய்தி படிப்பாட்டில் ஒரு ஆங்கிலம்- மேலும் ஜ First and examples of translation issues and their revisions were collected by a two-stage post-editing (PE) method: performing minimal PE to obtain translation attainable based on the given textual information and further performing full PE to obtain truly acceptable translation referring to any information if necessary.  பின்னர் சேகரிக்கப்பட்ட மீட்சி உதாரணங்கள் கைமுறையாக ஆராய்ந்தது. நாம் முக்கிய பிரச்சனைகளையும் தகவலையும் தீர்வு செய்ய வேண்டாம் மற்றும் போன்ற நல்ல பாணி குறிப்பிட்ட குறிப்பிட்ட குறிப்பிட்ட பாணி குறிப்பிட்ட அறிவு', 'ur': 'ماشین ترجمہ (MT) کے لئے موجود موجود طریقے ہیں جو اکثر سمجھ کی زبان میں دی گئی متخصت کو موجود زبان میں ترجمہ کرتے ہیں اور بغیر صریح طور پر مطلوبہ اطلاعات کی نسبت جو مناسب ترجمہ پیدا کرنے کے لئے ضروری نہیں ہے۔ یہ صرف ایک ہی دکھانے میں لکھنے کے بغیر اور بغیر لکھنے کے عنصروں اور موڈلیتوں میں معلومات میں شامل نہیں ہوتی، بلکہ اضافہ دکھانے والے اور غیر زبانی معلومات اور جیسے norms اور skopos. بہترین ترجمہ پیدائش کار-flows کی طراحی کے لئے اور ہمیں ترجمہ کے مسئلہ مختلف کرنے کی ضرورت ہے جو موجود پیدائش پر اور ان کے علاوہ کے مسئلہ سے حل کر سکتے ہیں. اس کے لئے ہم نے MT آئٹپوٹ کا تحلیل کیا اور ایک انگلیسی-ژاپنی خبروں کی ترجمہ کا کام کیسی مطالعہ کے طور پر لے لیا۔ پہلی اور مثالیں ترجمہ مسئلہ اور ان کی ترجمہ دو مرحلہ کے بعد ویڈینگ (PE) طریقے سے جمع کیے گئے: کم PE کو ترجمہ حاصل کرنے کے لئے مطابق دیے گئے textual معلومات پر بنیاد حاصل کرنے کے لئے اور پورا PE کو کام کرنے کے لئے مطابق قبول کرنے والے ترجمہ حاصل کرنے کے لئے جتنی معلومات کے ذریعہ سے مت اس کے بعد جمع کئے ہوئے روشن مثالیں manually analyzed گئیں۔ ہم نے ان کو حل کرنے کے لئے ضرورت کے مسئلہ اور معلومات نازل کیا ہے اور جیسے پاکیزہ دانے کی طرح کی تعریفیں اور ترمینلوژی اور دامین کی تعریف کے علم اور سند سند اور ترمینٹ کے درمیان واضح تفریق کرنے کے لئے اور کس طرح متن پر متن متن متن پہنچ سکتے ہیں۔', 'si': 'යන්ත්\u200dරය භාෂයේ ප්\u200dරභාවිත භාෂයේ ප්\u200dරභාවිත වාර්තාව සඳහා ප්\u200dරශ්නයක් නැති තොරතුරු සඳහා ප්\u200dරශ්නයක් නැති තොරතුරු අවශ මේක තරම් ලිපින්තුවට වඩා විතරයි අනිත් ලිපින්තුවක් සහ ප්\u200dරමාණය සඳහා විතරයි තොරතුරු සහ භාෂාවික තොරතුරු සහ නිර්මාණය සහ හොඳ වාර්තාව නිර්මාණය කරන්න විදිහට, අපිට වාර්තාව ප්\u200dරශ්නයක් විශේෂ කරන්න ඕනි විදිහට, ඒ වගේම තියෙන්න පුළුවන් පා මේ අවසානයෙන් අපි MT ප්\u200dරතිචාරය ගැන විශ්ලේෂණ විශ්ලේෂණයක් කරලා ඉංග්\u200dරීසිය-ජාපානික් වල ජාපානික් ව පළමු සහ උදාහරණ ප්\u200dරශ්ණය සහ ඔවුන්ගේ ප්\u200dරශ්ණය සම්බන්ධය සම්බන්ධ විදිහට පස්සේ ප්\u200dරශ්ණය (PE) විදිහයෙන් සම්බන්ධ වුනා: ප්\u200dරශ්ණය අවශ්\u200dය විදිහට පස්සේ ප ඊට පස්සේ සම්පූර්ණ විශේෂණ උදාහරණ වලින් පරීක්ෂණය කරලා තියෙනවා. අපි ප්\u200dරධාන ප්\u200dරශ්නයක් හා තොරතුරු ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ ඔවුන්ව විශ්නය කරන්න සහ හොඳ විශේෂ විශේෂය සහ විශේෂ විශේෂය සහ විශේෂ', 'sr': 'Postoje pristupi za prevod mašine (MT) uglavnom prevode određeni tekst na jezik izvora na ciljni jezik i bez objašnjenja na informacije koje je neophodno za proizvodnju pravih prevoda. To uključuje ne samo informacije u drugim tekstualnim elementima i modalitetima nego tekstove u istom dokumentu, nego i dodatne dokumente i ne-jezičke informacije, kao što su norme i skopos. Da bismo dizajnirali bolje proizvodnje proizvodnje radnih toka i moramo da razlikujemo pitanja prevođenja koje bi mogle rešiti postojećim pristupima teksta na tekst i onima izvan njih. Za taj cilj smo proveli analitičku procenu ishoda MT-a i uzeli posao za prevod vesti engleskog na japanski kao studiju slučajeva. Prvi i primjeri pitanja prevoda i njihovih revizija su sakupljeni putem metode posledišnjeg redakcije (PE): izvršavanje minimalnog PE za dobivanje prevoda dostupnih na temelju određenih tekstualnih informacija i daljnje izvršavanje punog PE za dobivanje stvarno prihvatljivog prevoda koji se odnosi na bilo koju informaciju, ako je potrebno. Onda su prikupljeni primjeri revizije ručno analizirani. Otkrili smo dominantne pitanja i informacije koje su neophodne za rešavanje njih, kao što su specifikacije finog zrnca stila i terminologija i znanja i referentnih dokumenta specifičnih domena i razmjenjivanje jasne razlike između prevoda i onoga što MT na kraju može postići tekstom do teksta.', 'vi': 'Các phương pháp truyền dịch máy (MTV) hiện hữu chủ yếu là dịch được văn bản chỉ ra bằng ngôn ngữ nguồn vào ngôn ngữ đích mà không trích dẫn những thông tin cần thiết để tạo ra bản dịch chính xác. Đây không chỉ chứa thông tin trong các chi tiết và phương thức văn bản khác ngoài những văn bản trong cùng một tài liệu, mà còn cả tài liệu và thông tin ngôn ngữ khác, như là các quy tắc và vở kịch. Để thiết kế một luồng tác phẩm dịch chuyển tốt hơn, chúng ta cần phải phân biệt các vấn đề dịch chuyển có thể giải quyết bằng các phương pháp văn bản và các phương pháp khác. Và chúng tôi đã phân tích kết xuất kênh MTV và thực hiện một nhiệm vụ dịch chuyển tin tức bằng tiếng Anh-Nhật như một nghiên cứu ca bệnh. Đầu tiên và ví dụ về các vấn đề dịch chuyển và các phiên bản thay đổi của họ được thu thập bằng một phương pháp gấp đôi: thực hiện thể hình tối thiểu để có được dịch dựa trên các thông tin cấu hình và thực hiện thêm các thể hoạt động hoàn chỉnh để có được sự chấp nhận dịch về bất kỳ thông tin nào nếu cần thiết. Sau đó, và các mẫu sửa chữa được thu thập được phân tích bằng tay. Chúng tôi phát hiện những vấn đề chủ chốt và những thông tin cần thiết để giải quyết chúng, như các đặc điểm theo phong cách, các thuật ngữ, các kiến thức và các tài liệu về mặt miền, và phân biệt rõ ràng giữa dịch ngữ và những gì cơ quan con đường văn bản đạt được.', 'uz': "@ info Bu yerda bitta hujjatdagi matnning matn elementlaridan faqat maʼlumot va usullarda maʼlumot mavjud emas, balki qoʻshimcha hujjat va lugʻlik maʼlumot va qoidalar va skopos kabi qoʻshish maʼlumot. @ info Va bu hozirga biz MT tashkilotlarini analytiklashni bajardik va bir kashfa o'rganish uchun ingliz-japoncha news tarjima vazifani olib bordik. @ info Keyin olingan taʼminlovchi misollar qo'lbola tarjima qilishdi. Биз уларни ҳал этиш учун мажбур muammolar ва маълумотларни нозил қилдик, мисоли яхши gramma uslublarning xususiyatlarini, terminologi, domen илм, ошкора ҳужжатларни ва фойдаланиш ҳужжатларини нозил қилдик ва таркиб қилиш ва matn-matn MT охирига қандай етишини аниқ тафсилотлаш мумкин.", 'da': 'Eksisterende metoder til maskinoversættelse (MT) oversætter for det meste en given tekst på kildesproget til målsproget og uden udtrykkeligt at henvise til oplysninger, der er nødvendige for at producere korrekt oversættelse. Dette omfatter ikke kun oplysninger i andre tekstelementer og fremgangsmåder end tekster i samme dokument, men også ekstra-dokument og ikke-sproglige oplysninger og såsom normer og skopos. For at designe bedre oversættelsesproduktionsarbejdsgange, og vi er nødt til at skelne mellem oversættelsesspørgsmål, der kunne løses ved hjælp af de eksisterende tekst-til-tekst-tilgange og dem uden for dem. Til dette formål gennemførte vi en analytisk vurdering af MT output og tog en engelsk-japansk nyhedsoversættelsesopgave som casestudie. For det første og eksempler på oversættelsesspørgsmål og revisioner heraf blev indsamlet ved hjælp af en to-trins efterredigeringsmetode (PE): udførelse af minimal PE for at opnå oversættelse baseret på de givne tekstinformationer og yderligere udførelse af fuld PE for at opnå virkelig acceptabel oversættelse med henvisning til eventuelle oplysninger om nødvendigt. Derefter og de indsamlede revisionseksempler blev manuelt analyseret. Vi afslørede dominerende spørgsmål og oplysninger, der er uundværlige for at løse dem, såsom finkornede stilspecifikationer og terminologi og domænespecifikke viden og referencedokumenter og skitserede en klar sondring mellem oversættelse og hvad tekst-til-tekst MT i sidste ende kan opnå.', 'nl': 'Bestaande benaderingen voor machinevertaling (MT) vertalen meestal bepaalde tekst in de brontaal naar de doeltaal en zonder expliciet te verwijzen naar informatie die onmisbaar is voor het produceren van een goede vertaling. Dit omvat niet alleen informatie in andere tekstelementen en modaliteiten dan teksten in hetzelfde document, maar ook informatie buiten het document en niet-taalkundige informatie, zoals normen en skopos. Om betere vertaalproductieworkflows te ontwerpen en we moeten onderscheid maken tussen vertaalproblemen die kunnen worden opgelost door de bestaande tekst-naar-tekst benaderingen en die daarbuiten. Hiertoe hebben we een analytische evaluatie van MT-outputs uitgevoerd en een Engels-naar-Japans nieuwsberichtvertaaltaak als casestudy genomen. De eerste en voorbeelden van vertaalproblemen en de herzieningen daarvan werden verzameld door middel van een tweefasige post-editing (PE)-methode: het uitvoeren van minimale PE om een vertaling te verkrijgen die mogelijk is op basis van de gegeven tekstinformatie en het verder uitvoeren van volledige PE om werkelijk aanvaardbare vertaling te verkrijgen met verwijzing naar alle informatie indien nodig. Vervolgens werden de verzamelde revisievoorbeelden handmatig geanalyseerd. We hebben dominante kwesties en informatie onthuld die onmisbaar is om deze op te lossen, zoals verfijnde stijlspecificaties en terminologie en domeinspecifieke kennis en referentiedocumenten en een duidelijk onderscheid maken tussen vertaling en wat tekst-naar-tekst MT uiteindelijk kan bereiken.', 'hr': 'Postoje pristupi za prevod strojeva (MT) uglavnom prevodi određeni tekst na izvornom jeziku na ciljni jezik i bez objašnjenja na informacije koje je neophodno za proizvodnju odgovarajućeg prevoda. To uključuje ne samo informacije u drugim tekstualnim elementima i modalima nego tekstove u istom dokumentu, nego i dodatne dokumente i ne-jezičke informacije, kao što su norme i skopos. Da bismo dizajnirali bolji protok proizvodnje proizvodnje rada i moramo razlikovati pitanja prevođenja koje bi mogle riješiti postojećim pristupima teksta na tekst i onima izvan njih. Za taj cilj smo proveli analitičku procjenu ishoda MT-a i uzimali posao prevoda na englesko-japanski novine kao studiju slučaja. Prvi i primjeri pitanja prevoda i njihovih revizija prikupljeni su metodom dva stupnja nakon redakcije (PE): izvršavajući minimalnu PE za dobivanje prevoda dostupnih na temelju određenih tekstualnih informacija i daljnje izvršavajući punu PE za dobivanje istinski prihvatljivog prevoda koji se odnosi na bilo koje informacije, ako je potrebno. Onda su prikupljeni primjeri revizije ručno analizirani. Otkrili smo dominantne pitanja i informacije koje su neophodne za rješavanje njih, kao što su specifikacije vrhunskog stila i terminologija i znanja i referentnih dokumenta specifičnih domena i razmjenjavanje jasne razlike između prevoda i koje tekst-na-tekst MT konačno može postići.', 'bg': 'Съществуващите подходи за машинен превод (МТ) превеждат най-вече даден текст на изходния език на целевия език и без изрично да се позовават на информация, необходима за изготвянето на подходящ превод. Това включва не само информация в други текстови елементи и модификации, различни от текстовете в същия документ, но и извъндокументна и нелингвистична информация и като норми и скопи. За да създадем по-добри работни потоци за производство на преводи, трябва да разграничим проблемите с превода, които могат да бъдат решени от съществуващите подходи текст-текст, и тези извън тях. За тази цел проведохме аналитична оценка на резултатите от МТ и взехме задача за превод на новини от английски на японски език като казус. Първи и примери за преводни въпроси и техните ревизии бяха събрани по двуетапен метод на пост-редактиране (ПЕ): извършване на минимален ПЕ, за да се получи постижим превод въз основа на дадената текстова информация, и по-нататъшно извършване на пълен ПЕ, за да се получи наистина приемлив превод, отнасящ се до всякаква информация, ако е необходимо. След това и събраните примери за ревизия бяха анализирани ръчно. Разкрихме доминиращи въпроси и информация, необходими за тяхното решаване, като например фини стилови спецификации и терминологични и специфични за областта знания и референтни документи и очертаване на ясно разграничение между превода и това, което текст-в-текст МТ може да постигне в крайна сметка.', 'de': 'Bestehende Ansätze für maschinelle Übersetzung (MT) übersetzen Texte in der Ausgangssprache meist in die Zielsprache und ohne explizite Bezugnahme auf Informationen, die für eine korrekte Übersetzung unerlässlich sind. Dazu gehören nicht nur Informationen in anderen Textelementen und Modalitäten als Texten im selben Dokument, sondern auch außerdokumentarische und nichtsprachliche Informationen wie Normen und Skopos. Um bessere Arbeitsabläufe für die Übersetzungsproduktion zu entwerfen, müssen wir Übersetzungsprobleme unterscheiden, die durch die bestehenden Text-zu-Text-Ansätze gelöst werden könnten und diejenigen, die darüber hinausgehen. Zu diesem Zweck haben wir eine analytische Bewertung der MT-Outputs durchgeführt und eine englisch-japanische Nachrichtenübersetzungsaufgabe als Fallstudie genommen. Erstens und Beispiele für Übersetzungsprobleme und deren Revisionen wurden mit einer zweistufigen Post-Editing-Methode (PE) gesammelt: minimales PE durchführen, um eine Übersetzung zu erhalten, die auf der Grundlage der gegebenen Textinformationen erreichbar ist, und weiter vollständige PE durchführen, um bei Bedarf wirklich akzeptable Übersetzungen zu erhalten, die sich auf alle Informationen beziehen. Anschließend wurden die gesammelten Revisionsbeispiele manuell analysiert. Wir haben dominante Fragen und Informationen aufgedeckt, die für deren Lösung unerlässlich sind, wie feingranulare Stilspezifikationen und Terminologie sowie domänenspezifisches Wissen und Referenzdokumente und eine klare Unterscheidung zwischen Übersetzung und dem, was Text-zu-Text MT letztendlich erreichen kann.', 'id': 'Pendekatan yang ada untuk terjemahan mesin (MT) kebanyakan terjemahan teks yang diberikan dalam bahasa sumber ke bahasa sasaran dan tanpa secara eksplicit merujuk kepada informasi yang tidak diperlukan untuk memproduksi terjemahan yang tepat. Ini tidak hanya termasuk informasi dalam elemen teks dan modalitas lain selain teks dalam dokumen yang sama dan juga informasi ekstra-dokumen dan bukan-bahasa dan seperti norma dan skopos. Untuk merancang produksi terjemahan yang lebih baik aliran kerja dan kita perlu membedakan masalah terjemahan yang dapat diselesaikan oleh pendekatan teks ke teks yang ada dan yang di luar mereka. Untuk tujuan ini dan kami melakukan penilaian analitis dari hasil MT dan mengambil tugas terjemahan berita bahasa Inggris-Jepang sebagai studi kasus. Pertama dan contoh-contoh masalah terjemahan dan revisi mereka dikumpulkan dengan metode dua tahap setelah edisi (PE): melakukan PE minimal untuk mendapatkan terjemahan yang dapat mencapai berdasarkan informasi teks yang diberikan dan melakukan lebih lanjut PE penuh untuk mendapatkan terjemahan yang benar-benar diterima referensi kepada informasi apapun jika perlu. Kemudian dan contoh revisi yang dikumpulkan secara manual diuji. We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and and reference documents and delineating a clear distinction between translation and what text-to-text MT can ultimately attain.', 'ko': '기존의 기계번역(MT) 방법은 대부분 원본 언어 중의 주어진 텍스트를 목표 언어로 번역하지만 정확한 번역을 만드는 데 필요한 정보를 명확하게 언급하지 않았다.이것은 같은 파일의 텍스트 이외의 다른 텍스트 요소와 형식의 정보를 포함할 뿐만 아니라, 규범과 목적 같은 추가 파일과 비언어적인 정보도 포함한다.더 좋은 번역 작업 절차를 설계하기 위해서 우리는 기존의 텍스트가 텍스트 방법과 다른 방법으로 해결할 수 있는 번역 문제를 구분해야 한다.이를 위해 우리는 기계 번역의 출력에 대해 분석 평가를 하고 영어에서 일본어까지의 뉴스 번역 임무를 중심으로 연구를 진행했다.우선, 두 단계의 후기 편집(PE) 방법을 통해 번역 문제와 수정된 실례를 수집한다. 주어진 텍스트 정보에 따라 최소한의 PE를 실행하여 얻을 수 있는 번역을 얻고 완전한 PE를 실행하여 진정으로 받아들일 수 있는 번역을 얻는다. 필요하면 어떠한 정보도 참고한다.그런 다음 수집된 개정 예제를 수동으로 분석합니다.우리는 이런 문제들을 해결하는 데 필요한 주요 문제와 정보, 예를 들어 세립도의 풍격 규범과 용어, 특정 분야의 지식과 참고 문헌을 제시하고 번역과 텍스트를 텍스트 기계 번역이 최종적으로 달성할 수 있는 목적을 명확하게 구분했다.', 'fa': 'نزدیک\u200cهای موجود برای ترجمه ماشین (MT) بیشتر متن داده شده را در زبان منبع به زبان هدف ترجمه می\u200cکند و بدون توضیح به اطلاعات بی\u200cنیاز برای تولید ترجمه\u200cی مناسب ارائه می\u200cدهد. این شامل اطلاعات نه تنها در بعضی عناصر متن و modalities دیگر از متن\u200cها در یک سند، بلکه اطلاعات اضافه\u200cای و غیر زبان\u200cشناسی و مانند نرم\u200cها و اسکوپوها است. برای طراحی جریان تولید کارهای بهتر تولید کنیم و ما باید مشکلات ترجمه را جدا کنیم که می توانند توسط نزدیک\u200cهای متن به متن موجود باشند و آن\u200cها که فراتر از آنها هستند حل شوند. برای این قسمت، ما یک ارزیابی تحلیل از نتیجه های MT و یک کار ترجمه خبری انگلیسی به ژاپن به عنوان یک مطالعه انجام دادیم. اولین و مثالها از مسائل ترجمه و تغییرات آنها با یک روش بعد از ویرایش (PE) دو مرحله جمع می\u200cشوند: انجام PE minimal برای پیدا کردن ترجمه\u200cای که بر اساس اطلاعات متن داده می\u200cشود قابل تحویل یافته می\u200cشود و اجرا کردن PE کامل برای گرفتن ترجمه\u200cای که واقعاً قابل قبول است به هر اطلاعات ار سپس مثالهای تغییرات جمع شده به دست تحلیل شد. ما مسائل فرمانروایی و اطلاعات را نازل کردیم که لازم نیست برای حل آنها و مطالعه\u200cهای سبک پاکیزه\u200cای و دانش\u200cشناسی و مدارک\u200cهای مربوط به دامنه\u200cها و تفاوتی مشخصی بین ترجمه\u200cها و آنچه متن به متن متن می\u200cتواند به پایان رسید.', 'sw': 'Matokeo yanayopo kwa ajili ya kutafsiri mashine (MT) kwa kiasi kikubwa utafsiri wa maandishi yaliyopewa katika lugha ya msingi katika lugha ya lengo na bila kutangaza wazi taarifa zinazohitajika kwa ajili ya kutengeneza tafsiri sahihi. Hii inajumuisha taarifa pekee katika vipengele vingine vya maandishi na aina nyingine zaidi ya maandishi katika nyaraka hiyo na pia taarifa za ziada na taarifa za lugha na kama vile utamaduni na skopo. Ili kutengeneza mafanikio mazuri ya kutafsiri na tunahitaji kutofautisha masuala ya kutafsiri ambayo yanaweza kutatua kwa njia zilizopo kwenye maandishi ya simu za mkononi na wale wengine zaidi yao. Kwa mwisho huu na tulifanya uchambuzi wa matokeo ya MT na kuchukua kazi ya kutafsiri habari za Kiingereza-hadi Japani kama utafiti wa kesi. Kwanza na mifano ya masuala ya kutafsiri na mabadiliko yao yalikusanywa na njia ya kuhariri baada ya hatua mbili: kufanya tafsiri ya chini ya PE ili kupata tafsiri inayofanikiwa kwa msingi wa taarifa zilizopewa na ujumbe mkubwa wa PE ili kupata tafsiri halisi inayohusu taarifa zote zinazohitajika. Kisha mifano ya mabadiliko yaliyokusanyika yalichapishwa kwa mikononi. Tulifanya masuala muhimu na taarifa yasiyohitajika kwa kutatua hizo na kama maelezo mazuri, maarifa maalum ya kimataifa na maarifa na maonesho ya ndani na kwa namna ya kutangaza tofauti wazi kati ya tafsiri na ujumbe wa simu za mkononi kwa ujumbe wa simu za mkononi.', 'tr': 'Makin terjime üçin bar ejazalar (MT) köplenç çeşme dilinde berilen metin bejerilip maksady diline terjime etmek we dogry terjime etmek üçin mümkin däldir maglumatlara söz etmek. Bu senediň metinlerinden başga metin elementlerde we modlerde diňe bilgi ýok, hatda hatda ekstra-sened we dilli bolmadyk maglumatlary we normaller we skoposlar ýaly daşary dahil etmedi. Iň gowy terjime etmek üçin işe çeşmelerini tasarlamak üçin we bize bolan metin we daşyndaky ýakynlaşylar tarapyndan çözmeli terjime etmek gerek. Bu sebäpä biz MT netijelerini analytik çözümleşdirdik we habarlar bilen iňlisçe-japonça täzelikleri jalam etdik. Ilkinji we terjime meseleleriniň örnekleri we olaryň revisiýalaryny 2-staýdan soňra editlemek (PE) yöntemi tarapyndan jemgyldi: berilen tekst maglumatynda tapylýan üçin az PE täsir etmek we PE täsir etmek üçin ullanýan terjime etmek üçin ullanýan terjime etmek üçin ullanýan terjime etmek üçin ullanýar. Sonra toplanýan çykyş örnekleri elle çözüldi. Biz olary çözmek üçin dominant meseleleri we maglumatlary çözmek üçin gerekli hökmü görkezildik, ýöne süýtgeli stil spesifikatlary we terminologiýa we domena spesifikaly bilgi we Reference senedleri bilen terjime-täze we metin-täze metin MT-iň soňunda ýetip biljek zadyň tapawutlaryny çykyp berdik.', 'af': "Bestaande toegang vir masjien vertaling (MT) meestal vertaling gegewe teks in die bron taal in die doel taal en sonder uitduidelik verwys na inligting onverwagbare vir produksie van regte vertaling. Hierdie insluit nie slegs inligting in ander teks-elemente en modaliteite as teks in dieselfde dokument en ook ekstra-dokument en nie-lingvisiese inligting en soos norme en skopos. Om beter oorspronklike produksie-werk-vloei te ontwerp en ons nodig om oorspronklike probleme te ontwerp wat kan opgelos word deur die bestaande teks-na-teks toekoms en die buite hulle. Tot hierdie einde het ons 'n analitiese oordeling van MT uitvoerdes gedoen en 'n Engels-na-Japanse nuusvertalingstaak as 'n geval studie neem. Eerste en voorbeelde van vertaling probleme en hulle hersieninge is versamel deur 'n twee- stadige post- redigeering (PE) metode: uitvoer minimale PE om vertaling ontvangbare te kry gebaseer op die gegewe tektuele inligting en verdere uitvoer volle PE om regtig aanvaarbare vertaling te kry wat verwyder na enige inligting indien nodig is. Dan is die versamel hersieningvoorbeelde hand analiseer. Ons het domineerde probleme en inligting onbehoerlik geopenbaar vir hulle oplossing en soos fyn-graad styl spesifikasie en terminologie en domein-spesifieke kennis en verwysing dokumente en 'n duidelike verskil tussen vertaling en wat teks-na-teks MT eindelik kan kry.", 'hy': 'Գոյություն ունի մեքենայի թարգմանման (MT) գոյություն ունեցող մոտեցումներ, որոնք հիմնականում թարգմանում են տվյալ տեքստը աղբյուր լեզվով դեպի նպատակային լեզու և առանց բացատրաբար նշելու տեղեկատվություն, որը ան Սա ներառում է ոչ միայն տեղեկատվությունը միևնույն փաստաթղթի տեքստերից բացի այլ տեքստային տարրերի և մեթոդների մեթոդներում, այլ նաև ավելին փաստաթղթեր և ոչ լեզվաբանական տեղեկատվություն, ինչպիսիք են նորմերը և սկոպոսները: Գործելու համար ավելի լավ թարգմանման արտադրողական հոսքեր ստեղծելու համար և մենք պետք է տարբերենք թարգմանման խնդիրները, որոնք կարող են լուծվել գոյություն ունեցող տեքստի-տեքստի մոտեցումներով և դրանից դուրս գալիս: Այսպիսով, մենք կատարեցինք ՄԹ-ի արտադրությունների վերլուծության վերլուծություն և անգլերեն-ճապոներեն նորությունների թարգմանման խնդիր ընդունեցինք որպես դեպքի ուսումնասիրություն: First and examples of translation issues and their revisions were collected by a two-stage post-editing (PE) method: performing minimal PE to obtain translation attainable based on the given textual information and further performing full PE to obtain truly acceptable translation referring to any information if necessary.  Այնուհետև հավաքված վերլուծության օրինակները ձեռքով վերլուծվեցին: Մենք բացահայտեցինք գերիշխող խնդիրներ և տեղեկատվություն, որոնք անհրաժեշտ են դրանց լուծման համար, ինչպես օրինակ գեղեցիկ ոճի նշանակությունները, տերմինոլոգիան, բնագավառի մասնավոր գիտելիքները և հաղորդակցման փաստաթղթերը, և բացատրեցինք թարգմանման և տեքստի MT-ի միջ', 'sq': 'Përkthimet ekzistuese për përkthimin e makinave (MT) përkthimin kryesisht të tekstit të dhënë në gjuhën e burimit në gjuhën e objektivit dhe pa u referuar shprehur në informacion të domosdoshëm për prodhimin e përkthimit të duhur. Kjo përfshin jo vetëm informacion në elemente tekstuale dhe modalitete të tjera përveç teksteve në të njëjtin dokument dhe gjithashtu informacion ekstra-dokument dhe jo-gjuhësor dhe të tilla si normat dhe skopos. Për të dizajnuar rrjedhje më të mira të prodhimit të përkthimit dhe ne duhet të dallojmë çështjet e përkthimit që mund të zgjidhen nga metodat ekzistuese tekst-tekst dhe ato përtej tyre. Për këtë qëllim dhe kemi kryer një vlerësim analitik të rezultateve të MT dhe duke marrë një detyrë përkthimi të lajmeve angleze-japoneze si një studim rasti. I pari dhe shembujt e çështjeve të përkthimit dhe revizionet e tyre u mblodhën me një metodë dy-faze pas-edicionit (PE): kryerje e PE minimale për të marrë përkthimin e arritshëm bazuar në informacionin tekstual të dhënë dhe kryerje të mëtejshme të PE të plotë për të marrë përkthimin me të vërtetë të pranueshëm që referohet në çdo informacion në rast se është e nevo Pastaj dhe shembujt e revisionit të mbledhur u analizuan manualisht. Ne zbuluam çështje dominuese dhe informacione të domosdoshme për zgjidhjen e tyre dhe të tilla si specifikimet e stilit të hollë dhe terminologjia dhe njohuritë specifike për domenin dhe dokumentet e referimit dhe përshkrimi i një dallimi të qartë midis përkthimit dhe çfarë teksti-teksti MT mund të arrijë në fund.', 'am': 'የአሁኑ ደረጃዎች ለመmachine translation (MT) አብዛኛውን የተሰጠውን text in the source language in to the target language and without explicit referring to information indispensable for producing proper translation. በዚህ ሰነድ ውስጥ ከጽሑፎች በቀር ሌሎች የጽሑፍ አካላት እና በሥርዓቶች ውስጥ መረጃ ብቻ አይደለም፣ ነገር ግን አብዛኛው ሰነድ እና የቋንቋዊ መረጃ እና እንደ ትምህርት እና ስኮፕዎስ ደግሞ ነው፡፡ የበለጠ ትርጉም አካባቢ ሥራ-አበባ ለመግለጽ እና በተገኘው ጽሑፍ-ወደ-ጽሑፍ ማቀናቀል እና ከዚያም በላይ ያሉትን ትርጉም ጉዳዮች ለመለየት ያስፈልጋል፡፡ ለዚህም መጨረሻ እና የMT ውጤቶች አስተያየት እና የኢንግሊዝኛ-ወደ ጃፓን የዜና ትርጓሜ ትርጓሜ አድራጊ እንደምትል ትምህርት መግለጫ አደረግን፡፡ መጀመሪያ እና ምሳሌዎች የትርጉም ጉዳዮች እና ማስተካከላቸው በሁለት ደረጃዎች በኋላ-አስተካክል (PE) method የተሰበሰቡ ናቸው፤ በተሰጠው የጽሑፍ መረጃ በማግኘት የተመዘጋጀውን ትርጓሜ ለማግኘት እና በሙሉ PE ለማግኘት እውነተኛ የተቀበል ትርጓሜ ማግኘት ማግኘት በማንኛውም መረጃ ማግኘት ያስፈልጋል፡፡ ከዚህም በኋላ የተሰበሰቡት ማስታወሻ በእጃቸው ተመረመሩ፡፡ የሥልጣን ጉዳዮችን እና መረጃዎችን ለመፈጸም የማይችሉትን እና እንደጥሩ የሥርዓት ግንኙነት እና ተርሚናሎጂ እና የውይይት እና የውይይት እውቀት እና መልዕክት ሰነዶች እና የትርጉም እና የጽሑፍ-ወደ-ጽሑፍ ማግኘት ምን እንዲችል ግልጽን እና ምን እንደሆነ አስተያየትነናል፡፡', 'az': 'Makinat tercüməsi (MT) üçün daha çox mənbə dilində verilən metinləri məqsəd dilinə çevirir və doğru tercümə etmək üçün münasib olmayan məlumatlara açıq-aydın danışmazlar. Bu, həmçin in eyni dökümədə yazılmış mətnlərdən başqa mətnlərdə və modalitlərdə sadəcə bir məlumat və həmçinin çox-dökümt və dili olmayan məlumatlarda istifadə edir. Daha yaxşı tərcümə ürətmə çalışmalarını tasarlamaq üçün və həmin mətn-mətn tərəfindən və ondan ötrü olanların çəkiləcəyi tərcümə məsələlərini ayırmalıyıq. Buna görə də MT sonuçlarını analitik təcrübə etdik və İngilizə-Japonca haqq-əvvəlki məlumatı tərcümə etdik. İlk dəfə dəyişiklik məsələlərinin və dəyişikliklərinin nümunələri iki dəfə sonra editing (PE) metodu ilə toplanmışdır: verilən textual məlumatlarına dayanan qurğulama üçün minimal PE performing for minimal PE performing to obtain obtainable translation based on the given text information and further performing full PE to obtain truly acceptable translation referring to any information if necessary. Sonra toplanmış yenilənmə misalları öz əlində analiz edildi. Biz onları çəkmək üçün münasibətli məsələlər və məlumatlar, məsələlər, terminoloji, domena münasibətli bilgi və məlumatlar, tercümə və metin-məlumatların arasındakı a çıq bir fərqləndirmək üçün vəhy etdik.', 'bn': 'মেশিন অনুবাদ (MT) বেশীরভাগ সোর্স ভাষায় প্রাপ্ত টেক্সট অনুবাদ করা হয়েছে লক্ষ্য ভাষায় এবং স্পষ্ট ভাষায় তথ্য উল্লেখ করার জন্য ব্যবস্থ এই তথ্য একই নথিতে টেক্সটের চেয়ে লেখা এবং অন্যান্য টেক্সচুয়াল উপাদান এবং মোডিয়েটের মধ্যে শুধুমাত্র তথ্য রয়েছে না, এবং এছাড়াও অতিরিক্ত ত আরো ভালো অনুবাদ প্রযুক্তির কাজ-ফুল গঠনের জন্য এবং বিদ্যমান টেক্সট থেকে টেক্সট প্রাপ্ত বিষয়গুলোকে বিচ্ছিন্ন করা দরকার য এই শেষ পর্যন্ত আমরা এমটি আউটপুটের বিশ্লেষণের বিশ্লেষণ করেছি এবং একটি কেস গবেষণা হিসেবে ইংরেজি থেকে জাপানী সংবাদ অনুবাদের কা অনুবাদ বিষয়গুলোর প্রথম এবং উদাহরণ এবং তাদের পরিবর্তন সংগ্রহ করেছে দুই মাত্রা পর্যন্ত সম্পাদনার (পি) পদ্ধতি: প্রয়োজনীয় টেক্সচুয়াল তথ্যের ভিত্তিতে অনুবাদ পাওয়া য তারপর সংগ্রহিত সংস্করণের উদাহরণ হাতে বিশ্লেষণ করা হয়। আমরা তাদের সমাধানের জন্য ক্ষমতাশীল বিষয় এবং তথ্য প্রকাশ করেছি যেমন সুন্দর স্টাইলের বিশেষ বিশেষ জ্ঞান এবং ডোমেইন-নির্দিষ্ট জ্ঞান এবং রেফারেন্সের নথি এবং অনুবাদের মধ', 'bs': 'Postoje pristupi za prevod mašine (MT) uglavnom prevode određeni tekst na jezik izvora na ciljni jezik i bez objašnjenja na informacije koje je neophodno za proizvodnju pravih prevoda. To uključuje ne samo informacije u drugim tekstualnim elementima i modalitetima osim tekstova u istom dokumentu, nego i dodatne dokumente i ne-jezičke informacije, kao što su norme i skopos. Da bismo dizajnirali bolji protok proizvodnje proizvodnje i moramo razlikovati pitanja prevođenja koje bi mogle riješiti postojećim pristupima teksta na tekst i onima izvan njih. Za taj cilj smo proveli analitičku procjenu ishoda MT-a i uzimali posao prevođenja na engleski-japanski novi kao studiju slučajeva. Prvi i primjeri pitanja prevođenja i njihovih revizija su prikupljeni metodom dva stupnja nakon redakcije (PE): izvršavajući minimalnu PE za dobivanje prevođenja dostupnih na temelju određenih tekstualnih informacija i daljnje izvršavajući punu PE za dobivanje istinski prihvatljivog prevođenja koji se odnosi na bilo koju informaciju, ako je potrebno. Onda su prikupljeni primjeri revizije ručno analizirani. Otkrili smo dominantne pitanja i informacije koje su neophodne za rješavanje njih, kao što su specifikacije finozgrađenog stila i terminologija i znanja i referentnih dokumenta specifičnih domena i razmjenjivanje jasne razlike između prevoda i onoga što MT na kraju može postići tekstom do teksta.', 'ca': "Els enfocaments existents per a la traducció màquina (MT) tradueixen en gran part el text dada en la llengua d'origen a la llengua alvo i sense referir-se explícitament a la informació indispensable per a produir una traducció adequada. Això inclou no només informació en altres elements textuals i modalitats que els textos del mateix document, sinó també informació extradocumental i no lingüística, com normes i skopos. Per dissenyar millors fluxos de treball de producció de traducció i hem de distingir les qüestions de traducció que podrien resoldre els enfocaments existents entre text i text i aquells més enllà d'ells. Per això vam fer una evaluació analítica dels resultats de MT i vam agafar una tasca de traducció de notícies anglès-japonès com a estudi de cas. El primer i exemples de qüestions de traducció i les seves revisions van ser recollits per un mètode post-edició en dos etapes: fer un PE mínim per aconseguir traducció aconseguible basada en la informació textual dada i seguir fent un PE complet per aconseguir traducció realment acceptable referint-se a qualsevol informació si és necessària. Llavors els exemples de revisió recollits van ser analitzats manualment. Vam revelar problemes dominants i informació indispensables per resoldre-los, com especificacions d'estil fins i grans, terminologia i coneixements específics per domini i documents de referència i definir una distinció clara entre la traducció i el que MT de text a text pot aconseguir finalment.", 'cs': 'Stávající přístupy pro strojový překlad (MT) převážně překládají daný text ve zdrojovém jazyce do cílového jazyka a bez výslovného odkazu na informace nezbytné pro výrobu správného překladu. To zahrnuje nejen informace v jiných textových prvcích a způsobech než texty ve stejném dokumentu, ale také mimodokumentové a nejazykové informace, jako jsou normy a skopos. Chceme-li navrhnout lepší pracovní postupy překladatelské výroby a musíme rozlišovat otázky překladu, které by mohly být vyřešeny stávajícími přístupy text-to-text a problémy mimo ně. Za tímto účelem jsme provedli analytické zhodnocení výstupů MT a jako případovou studii jsme vzali úlohu překladu zpráv z angličtiny do japonštiny. První a příklady překladatelských problémů a jejich revizí byly shromážděny dvoustupňovou posteditační metodou: provedení minimálního PE pro získání dosažitelného překladu na základě daných textových informací a dále provedení plného PE pro získání skutečně přijatelného překladu odkazujícího na jakékoli informace v případě potřeby. Následně a shromážděné příklady revizí byly ručně analyzovány. Odhalili jsme dominantní otázky a informace nezbytné pro jejich řešení, jako jsou jemně zraněné stylové specifikace a terminologie a doménové znalosti a referenční dokumenty a vymezení jasného rozlišení mezi překladem a čím může MT nakonec dosáhnout.', 'fi': 'Nykyiset konekäännösmenetelmät kääntävät pääosin tietyn tekstin lähdekielellä kohdekielelle viittaamatta nimenomaisesti tietoihin, jotka ovat välttämättömiä asianmukaisen käännöksen tuottamiseksi. Tämä ei koske ainoastaan tietoja muissa tekstielementeissä ja -muodoissa kuin saman asiakirjan teksteissä, vaan myös asiakirjoja ja ei-kielisiä tietoja ja kuten normeja ja skopos. Jotta voitaisiin suunnitella parempia käännöstuotannon työnkulkuja, meidän on erotettava toisistaan käännöskysymykset, jotka voitaisiin ratkaista olemassa olevilla tekstiin perustuvilla lähestymistavoilla ja niiden ulkopuolella. Tätä varten teimme analyyttisen arvioinnin MT-tuotoksista ja otimme tapaustutkimuksena englannin-japanin uutiskäännöksen. Ensimmäinen ja esimerkkejä käännösasioista ja niiden revisioista kerättiin kaksivaiheisella jälkimuokkausmenetelmällä (PE): minimaalisen PE:n suorittaminen käännöksen saamiseksi saavutettavissa annetuista tekstitiedoista ja edelleen täydellinen PE:n suorittaminen todella hyväksyttävän käännöksen saamiseksi mahdollisista tiedoista tarvittaessa. Tämän jälkeen ja kerätyt versioesimerkit analysoitiin manuaalisesti. Paljastimme hallitsevia kysymyksiä ja tietoja, jotka ovat välttämättömiä niiden ratkaisemiseksi, kuten hienojakoisia tyylispesifikaatioita ja terminologiaa sekä toimialoittaista tietoa ja viiteasiakirjoja sekä selkeän eron kääntämisen ja sen välillä, mitä tekstistä tekstiin -menetelmällä voidaan lopulta saavuttaa.', 'et': 'Olemasolevad masintõlke lähenemisviisid tõlgivad peamiselt teatud teksti lähtekeeles sihtkeelde, viidamata selgesõnaliselt nõuetekohase tõlke saamiseks hädavajalikule teabele. See ei hõlma mitte ainult teavet muudes tekstielementides ja -viisides kui samas dokumendis sisalduvad tekstid, vaid ka dokumentidevälist ja keelelist teavet ning näiteks normid ja skopos. Tõlketootmise paremate töövoogude kujundamiseks tuleb eristada tõlkeküsimusi, mida saaks lahendada olemasolevate tekstivaheliste lähenemisviiside abil, ja neid väljaspool. Selleks viisime läbi MT väljundite analüütilise hindamise ning võtsime juhtumiuuringuna inglise-jaapani uudiste tõlkimise ülesande. Esimene ja näited tõlkeküsimustest ja nende parandustest koguti kaheastmelise järeltöötlusmeetodi abil: minimaalse koolituse teostamine, et saada tõlge, mis on kättesaadav antud tekstiinfo põhjal, ning täieliku koolituse teostamine, et saada tõeliselt vastuvõetav tõlge, mis viitab vajaduse korral mis tahes teabele. Seejärel analüüsiti käsitsi kogutud versiooni näiteid. Avastasime domineerivad küsimused ja teabe, mis on nende lahendamiseks hädavajalikud, näiteks täpsed stiilispetsifikatsioonid, terminoloogia ja valdkonnapõhised teadmised ja viitedokumendid ning selge eristuse tõlke ja selle vahel, mida tekstist tekstini MT lõppkokkuvõttes saavutada võib.', 'jv': 'buddy Iki ora jeneng informasi sing nggo eleman textual karo modalité sing gak nggambar teks ning dokumen sing dumadhi, lan uga basa-dokumen lan informasi sing ora nggawe luwih-luwih karo kno lan kelangan banggal. kanggo nggawe akeh luwih-luwih kanggo nggawe lanang-luwih ingkang sampeyan kanggo ngerasai perusahaan kanggo nggawe gerakan seneng nggawe gerakan seneng berauga teks-kanggo-teks bisa teka lan seneng berarti langga kuwi. Mbok iki bakal ono trus nyong ngewehi nyong nyong pancene tarjamahan kanggo nggawe barang MT lan nganggo mulai tarjamahan kanggo Japang . Pirem lan balik sing berarti perusahaan keljamahan karo perusahaan anyar tentang karo perusahaan nggawe tarjamahan iki-kateng After-editing (PI) : iso nggawe minimal PI nggawe tarjamahan sing bisa teka nggawe informasi sing apik trus nggawe Perusahaan langgar sampeyan nganggep sistem sing berarti Pet sing apik tur angel nggawe oleh terjamahan. When this is the first time, it Cendelok karo akeh akeh pisan anyari, dadi kapan manut karo ditambahak manut. We expanded domain-special points and information informationindentable for Resolutioning their and like Fine-cered style Specitions and terminal logies and domain-special knowings and reference documents and Dellicing a Clear Distion amongst translation and the text-to-text MT can end up at the Attain.', 'sk': 'Obstoječi pristopi za strojno prevajanje (MT) večinoma prevajajo določeno besedilo v izvornem jeziku v ciljni jezik in brez izrecnega sklicevanja na informacije, ki so nujne za ustvarjanje ustreznega prevoda. To ne vključuje le informacij v drugih besedilnih elementih in modalitizacijah kot besedila v istem dokumentu, temveč tudi ekstradokumentne in nejezikovne informacije ter kot so norme in skopos. Za oblikovanje boljših delovnih tokov za produkcijo prevodov moramo razlikovati prevajalska vprašanja, ki bi jih bilo mogoče rešiti z obstoječimi pristopi besedila v besedilo, in tiste, ki jih ni mogoče rešiti. V ta namen smo izvedli analitično oceno rezultatov MT in prevajanje novic iz angleščine v japonščino kot študijo primera. Prvi in primeri prevajalskih težav in njihovih revizij so bili zbrani z dvostopenjsko metodo po urejanju (PE): izvedba minimalne PE za pridobitev prevoda, ki je mogoče doseči na podlagi danih besedilnih informacij, in nadaljnja izvedba popolne PE za pridobitev resnično sprejemljivega prevoda, ki se nanaša na kakršne koli informacije, če je to potrebno. Nato smo ročno analizirali zbrane primere revizij. Razkrili smo prevladujoča vprašanja in informacije, ki so nujno potrebne za njihovo reševanje, kot so natančne slogovne specifikacije, terminologija in domensko znanje ter referenčni dokumenti ter jasno razlikovanje med prevajanjem in tistim, kar lahko doseže MT besedila v besedilo.', 'ha': "@ action: button Wannan yana ƙunsa da information kawai cikin ƙanshi na rubutu da tsaro masu cikin matsayi da tsaro masu cikin takardar da shi duk aikin kuma amma yana da data masu ƙaranci da linguistic da kamar shiryoyin da skopo. Ga ka ƙayyade mafiya alhẽri na fassarar-manunufi masu aikin aiki-na'urar kuma ana buƙata masu fassarar da za'a karɓi ta da hanyõyin text-zuwa-text da wanda ke gaba gare su. Haƙĩƙa, zuwa wannan, muka sami wani analyci na matsayin MT da kuma muka karɓi wani aikin fassarar lãbãri na Ingiriya-zuwa-japane kama a case-research. @ info: whatsthis Kuma aka buga misãlai ga waɗanda aka tãra su da hannuwansu. Mun saukar da masu muhimmi da information wanda bã ya da bukãta da su, kuma kamar misãlan misãlai mai kyau na tsari da bakwai da ilmi da mazaɓa da takardar mala'a da kuma, Mun rarraba rarrabẽwa tsakanin fassarar da ma'abũcin-zuwa-matsayin MT kan ta ƙara.", 'he': 'גישות קיימות לתרגום מכונות (MT) בעיקר מתרגמות טקסט מסוים בשפה המקור לשפה המטרה ובלי להתייחס באופן ברור למידע בלתי נחוץ לייצור התרגום הנכון. זה כולל לא רק מידע באלימנטים וסקסטיים אחרים מאשר טקסטים באותו מסמך, אלא גם מידע מחוץ למסמך ולא לשונים, כמו נורמות וסקופוס. כדי לעצב זרימות עבודת התרגום טובות יותר ואנחנו צריכים להבדיל את בעיות התרגום שאפשר לפתור על ידי גישות טקסט לטקסט קיימות ואלה מעבר להם. למטרה זו ועשינו עריכה אנליטית של תוצאות MT ולקחת משימה התרגום חדשות אנגלית ליפנית בתור מחקר מקרים. ראשון ודוגמאות של בעיות התרגום והשיפורים שלהם נאספו על ידי שיטת שתי שלבים לאחר העורה (PE): ביצוע מינימלי PE כדי להשיג התרגום אפשרי בהתבסס על המידע הטקסטלי הנתון ולביצוע עוד PE מלא ואז דוגמאות הריזוציה שנאספו נבדקו ידנית. חשפנו בעיות ודיוונים דומיננטיים בלתי חשובים לפתור אותם, וכמו ספציפיציות סגנון צפופונות, טמינולוגיה, ידע ספציפי לתחום, מסמכי התייחסות, ומסגרת הבדל ברור בין התרגום לאיזה טקסט לטקסט MT יכול להשיג בסופו של דבר.', 'bo': 'Existing approaches for machine translation (MT) mostly translate given text in the source language in to the target language and without explicitly referring to information indispensable for producing proper translation. འདིས་ཡིག་གེ་ནང་དུ་ཡིག་གེ་དང་ཐིག་སྙད་པའི་གནས་ཚུལ་དང་ཐབས་ལམ་གཞན་པའི་ནང་དུ་མིན་ཁོ་ན་ཡིན་པ་ལས་ཀྱང་ཡིག་ཆ་ཁོ་ན་དང་སྐད་རིགས་མིན To design better translation production work-flows and we need to distinguish translation issues that can be resolved by the existing text-to-text approaches and those beyond them. To design better translation work-flows. མཇུག་གི་དོན་ལ་ང་ཚོས་MT འི་གནད་སྡུད་བྱ་ཚིག་ལ་དབྱེ་ཞིབ་བྱས་པ་ཞིག་རྒྱུ་རེད། First and examples of translation issues and their revisions were collected by a two-stage post-editing (PE) method: performing minimal PE to obtain translation attainable based on the given textual information and further performing full PE to obtain truly acceptable translation referring to any information if necessary. དེ་ནས་བསྡུས་བྱས་པའི་དཔེ་བརྗོད་པར་ལག་བཟོས་ཞིབ་བྱས་པ་ཡིན། We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and reference documents and delineating a clear distinction between translation and what text-to-text MT can ultimately attain.'}
{'en': 'Modeling Target-side Inflection in Placeholder Translation', 'fr': "Modélisation de l'inflexion côté cible dans la translation de l'espace réservé", 'ar': 'نمذجة انعكاس الجانب المستهدف في ترجمة العنصر النائب', 'es': 'Modelado de inflexión del lado del objetivo en la traducción de marcadores', 'pt': 'Modelando a inflexão do lado do alvo na tradução de espaço reservado', 'ja': 'プレースホルダー翻訳におけるターゲット側のインフレのモデリング', 'ru': 'Моделирование перегиба целевой стороны при переводе заполнителя', 'zh': '占位符译者侧词形变建模', 'hi': 'प्लेसहोल्डर अनुवाद में मॉडलिंग लक्ष्य-पक्ष इन्फ्लेक्शन', 'ga': 'Samhaltú Infhilleadh ar Thaobh an Sprice in Aistriúchán Sealbhóir Áite', 'ka': 'Name', 'hu': 'A céloldali infláció modellezése a helyőrző fordításban', 'el': 'Μοντελοποίηση εκτροπής στην πλευρά του στόχου στη μετάφραση κράτησης θέσης', 'kk': 'Мақсатты жағындағы инфлекциясын орындардың аудармасында үлгілеу', 'it': "Modellazione dell'influenza lato bersaglio nella traduzione del segnaposto", 'lt': 'Modeliuoti tikslinę įtaką paveikimo vietoje vertimui', 'mk': 'Моделирање на инфлекција на страната на целта во преводот на местоводителот', 'ms': 'Memodel Infleksi Sisi Sasaran dalam Terjemahan Pemegang Ganti', 'ml': 'സ്ഥലത്തുള്ള പരിഭാഷയില്\u200d മോഡോളിങ്ങ് ലക്ഷ്യം ഭാഗത്തുള്ള ഇന്\u200dഫ്ലെക്ഷന്\u200d', 'mt': 'L-Immudellar tal-Influżjoni fuq in-naħa tal-mira fit-Traduzzjoni tad-Detentur tal-Post', 'mn': 'Загвар-талын инфлекцийг загварчлах Placeholder Translation', 'no': 'Modellerer målside- infleksjon i omsetjing av plassholdar', 'ro': 'Modelarea fluxului lateral țintă în traducerea plasatorului', 'sr': 'Modeliranje Inflekcije ciljne strane u prevodu lokalnih držača', 'si': 'Name', 'so': 'Waxbarashada dhinaca hagitaanka ee dalbashada', 'sv': 'Modellera målsidans böjning i platshållarens översättning', 'ta': 'இடப்பொறி மொழிபெயர்ப்பில் மாதிரியான சேருமிடத்தின் பக்கத்தில் உள்ள பிளக்கம்', 'ur': 'مکان هولڈر ترجمہ میں موڈل- سائڈ انفلکس', 'pl': 'Modelowanie odchylenia po stronie docelowej w tłumaczeniu ustawień miejscowych', 'uz': 'Name', 'vi': 'Chế độ Dịch đối tượng', 'bg': 'Моделиране на влиянието на целевата страна в превода на контейнера', 'hr': 'Modeliranje Inflekcije ciljne strane u prevodu mjesta držača', 'da': 'Modellering af målside-påvirkning i pladsholder oversættelse', 'nl': 'Modelen van target-side inflectie in plaatsaanduiding vertaling', 'de': 'Modellierung der zielseitigen Abweichung in der Platzhalterübersetzung', 'id': 'Modeling Target-side Inflection in Placeholder Translation', 'sw': 'Usafiri wa Mpango wa Mpango katika Tafsiri', 'ko': '자리 차지 문자 번역 중의 목표 측 굴절 모델링', 'fa': 'نمودار تغییر سمت هدف در ترجمه جایگاهholder', 'am': 'መግለጫ', 'sq': 'Modelimi i përfshirjes në anën e objektivit në përkthimin e zëvendësuesit', 'az': 'M톛qs톛d-t톛r톛fd톛n Infleksiyonu Placeholder Terc칲m톛sind톛 Modell톛ndirir', 'af': 'Name', 'tr': 'Mazmunlar tarapyny terjime etmek üçin nusgala', 'bn': 'Name', 'hy': 'Մոդելավորել նպատակային կողմի ազդեցությունը տեղաշարժիչ թարգմանության մեջ', 'et': 'Sihtkülje mõju modelleerimine kohahoidja tõlkes', 'fi': 'Kohdepuolen vaikutuksen mallintaminen paikkamerkin käännöksessä', 'ca': "Modelar l'influència de l'objectiu en la traducció del titular", 'bs': 'Modeliranje Inflekcije ciljne strane u prevodu lokalnih držača', 'cs': 'Modelování deformace na straně cíle v překladu umístěných symbolů', 'jv': 'Layout', 'sk': 'Modeliranje vpliva ciljne strani pri prevajanju prostora', 'ha': '@ action', 'he': 'מודל השפעה בצד המטרה בתרגום מחזיק', 'bo': 'གནས་ཡུལ་holder་ཡིག་སྐད་ནང་མ་དབྱིབས་དམིགས་ཡུལ་ཕྱོགས་ཀྱི་གནོད་སྤེལ་བ'}
{'en': 'Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token. However and this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output and which is unknown before the translation. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the  grammatical construction  of the output sentence. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and and show our model can incorporate specified terms in a correct form more successfully than other comparable models.', 'ar': 'تتيح أنظمة ترجمة العناصر النائبة للمستخدمين تحديد كيفية ترجمة عبارة معينة في الجملة الناتجة. يتم تدريب النظام على إخراج الرموز المميزة الخاصة بالعناصر النائبة ويتم حقن المصطلح المحدد من قبل المستخدم في المخرجات من خلال الاستبدال الخالي من السياق لرمز العنصر النائب. ومع ذلك ، قد ينتج عن هذا النهج جمل غير نحوية لأنه غالبًا ما يحتاج المصطلح المحدد إلى تصريف وفقًا لسياق الإخراج وهو أمر غير معروف قبل الترجمة. لمعالجة هذه المشكلة ، نقترح طريقة جديدة لترجمة العنصر النائب يمكن أن تعكس المصطلحات المحددة وفقًا للبناء النحوي للجملة الناتجة. نقوم بتوسيع بنية seq2seq باستخدام وحدة فك ترميز على مستوى الحرف تأخذ ليمما للمصطلح المحدد من قبل المستخدم والكلمات التي تم إنشاؤها من وحدة فك التشفير على مستوى الكلمة لإخراج شكل منحني صحيح من lemma. نقوم بتقييم نهجنا مع مهمة ترجمة من اليابانية إلى الإنجليزية في مجال الكتابة العلمية ونبين أن نموذجنا يمكن أن يدمج المصطلحات المحددة في شكل صحيح بنجاح أكبر من النماذج الأخرى المماثلة.', 'fr': "Les systèmes de traduction d'espace réservé permettent aux utilisateurs de spécifier comment une phrase spécifique est traduite dans la phrase de sortie. Le système est entraîné à générer des jetons d'espace réservé spéciaux et le terme spécifié par l'utilisateur est injecté dans la sortie par le remplacement sans contexte du jeton d'espace réservé. Cependant, cette approche peut entraîner des phrases non grammaticales car il arrive souvent que le terme spécifié doive être infléchi en fonction du contexte de la sortie et qui est inconnu avant la traduction. Pour résoudre ce problème, nous proposons une nouvelle méthode de traduction d'espace réservé qui peut infléchir des termes spécifiques en fonction de la construction grammaticale de la phrase de sortie. Nous étendons l'architecture seq2seq avec un décodeur de niveau caractère qui prend le lemme d'un terme spécifié par l'utilisateur et les mots générés par le décodeur de niveau mot pour produire une forme fléchie correcte du lemme. Nous évaluons notre approche avec une tâche de traduction du japonais vers l'anglais dans le domaine de la rédaction scientifique et montrons que notre modèle peut intégrer des termes spécifiques sous une forme correcte avec plus de succès que d'autres modèles comparables.", 'pt': 'Os sistemas de tradução de espaço reservado permitem que os usuários especifiquem como uma frase específica é traduzida na sentença de saída. O sistema é treinado para produzir tokens de espaço reservado especiais e o termo especificado pelo usuário é injetado na saída por meio da substituição livre de contexto do token de espaço reservado. No entanto, essa abordagem pode resultar em sentenças não gramaticais, porque muitas vezes o termo especificado precisa ser flexionado de acordo com o contexto da saída e que é desconhecido antes da tradução. Para resolver este problema, propomos um novo método de tradução de espaço reservado que pode flexionar termos especificados de acordo com a construção gramatical da sentença de saída. Estendemos a arquitetura seq2seq com um decodificador de nível de caractere que pega o lema de um termo especificado pelo usuário e as palavras geradas a partir do decodificador de nível de palavra para produzir uma forma flexionada correta do lema. Avaliamos nossa abordagem com uma tarefa de tradução de japonês para inglês no domínio da escrita científica e mostramos que nosso modelo pode incorporar termos especificados de forma correta com mais sucesso do que outros modelos comparáveis.', 'es': 'Los sistemas de traducción de marcadores de posición permiten a los usuarios especificar cómo se traduce una frase específica en la oración de salida. El sistema está entrenado para generar tokens de marcador de posición especiales y el término especificado por el usuario se inyecta en la salida mediante el reemplazo sin contexto del token de marcador de posición. Sin embargo, este enfoque podría dar lugar a oraciones no gramaticales porque a menudo el término especificado necesita ser flexionado de acuerdo con el contexto de la salida y que se desconoce antes de la traducción. Para abordar este problema, proponemos un método novedoso de traducción de marcadores de posición que puede flexionar términos específicos de acuerdo con la construcción gramatical de la oración de salida. Ampliamos la arquitectura seq2seq con un decodificador a nivel de caracteres que toma el lema de un término especificado por el usuario y las palabras generadas desde el decodificador a nivel de palabra para generar una forma flexionada correcta del lema. Evaluamos nuestro enfoque con una tarea de traducción del japonés al inglés en el dominio de la escritura científica y demostramos que nuestro modelo puede incorporar términos específicos de forma correcta con más éxito que otros modelos comparables.', 'hi': 'प्लेसहोल्डर अनुवाद सिस्टम उपयोगकर्ताओं को यह निर्दिष्ट करने में सक्षम करते हैं कि आउटपुट वाक्य में किसी विशिष्ट वाक्यांश का अनुवाद कैसे किया जाता है। सिस्टम को विशेष प्लेसहोल्डर टोकन आउटपुट करने के लिए प्रशिक्षित किया जाता है और उपयोगकर्ता-निर्दिष्ट शब्द को प्लेसहोल्डर टोकन के संदर्भ-मुक्त प्रतिस्थापन के माध्यम से आउटपुट में इंजेक्ट किया जाता है। हालांकि और इस दृष्टिकोण के परिणामस्वरूप अव्याकरणिक वाक्य हो सकते हैं क्योंकि यह अक्सर ऐसा मामला होता है कि निर्दिष्ट शब्द को आउटपुट के संदर्भ के अनुसार inflected करने की आवश्यकता होती है और जो अनुवाद से पहले अज्ञात है। इस समस्या को हल करने के लिए और हम प्लेसहोल्डर अनुवाद की एक उपन्यास विधि का प्रस्ताव करते हैं जो आउटपुट वाक्य के व्याकरणिक निर्माण के अनुसार निर्दिष्ट शब्दों को शामिल कर सकता है। हम एक चरित्र-स्तर विकोडक के साथ seq2seq आर्किटेक्चर का विस्तार करते हैं जो उपयोगकर्ता-निर्दिष्ट शब्द के लेम्मा को लेता है और शब्द-स्तर विकोडक से उत्पन्न शब्दों को लेमा के एक सही इनफ्लेक्टेड रूप को आउटपुट करने के लिए। हम वैज्ञानिक लेखन डोमेन में जापानी-से-अंग्रेजी अनुवाद कार्य के साथ अपने दृष्टिकोण का मूल्यांकन करते हैं और दिखाते हैं कि हमारा मॉडल अन्य तुलनीय मॉडलों की तुलना में अधिक सफलतापूर्वक सही रूप में निर्दिष्ट शब्दों को शामिल कर सकता है।', 'ja': 'プレースホルダー翻訳システムを使用すると、ユーザーは出力文で特定のフレーズをどのように翻訳するかを指定できます。 システムは、特別なプレースホルダートークンを出力するようにトレーニングされ、ユーザーが指定した用語は、コンテキストフリーのプレースホルダートークンの置き換えを通じて出力に挿入されます。 しかしながら、このアプローチは、指定された用語が出力の文脈に応じて屈折する必要があり、翻訳前に不明である場合が多いため、文法的でない文章をもたらす可能性がある。 この問題に対処するために、出力文の文法構成に応じて指定された用語を屈折させることができる、プレースホルダ翻訳の新しい方法を提案します。 ユーザーが指定した用語のレマと、ワードレベルデコーダから生成された単語を使用して、レマの正しい屈折形式を出力する文字レベルのデコーダを使用して、seq 2 seqアーキテクチャを拡張します。 私たちは、科学的な執筆領域における日本語から英語への翻訳タスクでアプローチを評価し、他の同等のモデルよりも正しい形で指定された用語を組み込むことができることを示します。', 'zh': '占位符译系统使用户能指定如何输出句中特定短语。 统经训练以输异占位符标记,且因上下文无关占位符代用户指定者术语注输中。 然此法或致不合语法句,盖指术语须随所输上下文屈,且于译前未之知也。 新占位符译法,可随句语法造屈折指定术语。 余以字符级解码器广 seq2seq 架构,当解码器用用户指定项引理及从字级解码器生成之单词,以输引理之正折。 科学域之日语英语翻译,以正吾法,以正吾法术语。', 'ru': 'Системы перевода заполнителей позволяют пользователям указать, как конкретная фраза переводится в выходном предложении. Система обучена выводить специальные маркеры-заполнители, и заданный пользователем термин вводится в вывод через контекстно-свободную замену маркера-заполнителя. Однако и этот подход может привести к неграмматическим предложениям, потому что часто бывает так, что указанный термин должен быть изменен в соответствии с контекстом вывода и который неизвестен до перевода. Для решения этой проблемы мы предлагаем новый метод перевода заполнителя, который может переливать определенные термины в соответствии с грамматической конструкцией выходного предложения. Мы расширяем архитектуру seq2seq декодером на уровне символов, который принимает лемму заданного пользователем термина и слова, сгенерированные декодером на уровне слов, чтобы вывести правильную перевернутую форму леммы. Мы оцениваем наш подход с японско-английской задачей перевода в области научного письма и показываем, что наша модель может включать определенные термины в правильной форме более успешно, чем другие сопоставимые модели.', 'ga': 'Cuireann córais aistriúcháin ionadsealbhóirí ar chumas na n-úsáideoirí a shonrú conas a aistrítear frása ar leith san abairt aschuir. Tá an córas oilte chun comharthaí coinneála áite speisialta a aschur agus déantar an téarma a shonraítear don úsáideoir a instealladh isteach san aschur trí chomhartha an choinneálaí áite a chur in ionad saor ó chomhthéacs. Mar sin féin agus d’fhéadfadh abairtí neamhghramadaí a bheith mar thoradh ar an gcur chuige seo mar is minic gur gá an téarma sonraithe a infhilleadh de réir chomhthéacs an aschuir agus nach bhfuil ar eolas roimh an aistriúchán. Chun aghaidh a thabhairt ar an bhfadhb seo agus molaimid modh núíosach d’aistriúchán ionadsealbhóra a fhéadfaidh téarmaí sonraithe a infhilleadh de réir leagan gramadaí na habairte aschuir. Leathnaímid an ailtireacht seq2seq le díchódóir leibhéal carachtair a thógann an leama de théarma atá sonraithe ag an úsáideoir agus na focail a ghintear ón díchódóir leibhéal focal chun foirm cheart infhillte den lema a aschur. Déanaimid measúnú ar ár gcur chuige maidir le tasc aistriúcháin Seapáinis-go-Béarla i bhfearann na scríbhneoireachta eolaíochta agus taispeánann muid gur féidir lenár múnla téarmaí sonraithe a ionchorprú i bhfoirm cheart ar bhealach níos rathúla ná samhlacha inchomparáide eile.', 'hu': 'A helyőrző fordítási rendszerek lehetővé teszik a felhasználók számára, hogy meghatározzák, hogyan fordítsák le egy adott kifejezést a kimeneti mondatban. A rendszert speciális helyőrző tokenek kibocsátására képezik, és a felhasználó által megadott kifejezés a helyőrző tokenek kontextusmentes cseréjével kerül a kimenetbe. Ez a megközelítés azonban keretlen mondatokat eredményezhet, mert gyakran előfordul, hogy a meghatározott kifejezést a kimenet kontextusának megfelelően kell befolyásolni, és ami a fordítás előtt ismeretlen. A probléma megoldására új helyőrző fordítási módszert javasolunk, amely a kimeneti mondat nyelvtani szerkezetének megfelelően befolyásolhatja a meghatározott kifejezéseket. A seq2seq architektúrát egy karakterszintű dekódolóval bővítjük, amely egy felhasználó által megadott kifejezés lemmáját és a szószintű dekódolóból generált szavakat veszi fel a lemma megfelelő inflexált formáját. Megközelítésünket japán-angol fordítási feladatokkal értékeljük a tudományos írási területen, és megmutatjuk, hogy modellünk sikeresebben tud meghatározott kifejezéseket helyes formában beépíteni, mint más hasonló modellek.', 'ka': 'სისტემის გადაწყვეტილების სისტემის შესაძლებლობა მომხმარებელი განსაზღვრება როგორ განსაზღვრებული ფრაზა გადაწყვეტილია. Name მაგრამ ამ პროგრამის შესაძლებლობა შეიძლება გავაკეთოთ ანგრამეტური სიტყვები, რადგან ეს ხშირად იყო, რომ განსაზღვრებული სიტყვები უნდა იქნება გამოყენების კონტექსტის შესახებ ამ პრობლემას გადაწყვეტისთვის და ჩვენ დავიწყებთ პლასექონტების გადაწყვეტის პრობლემატიკური მეტი, რომელიც შეიძლება განსაზღვრებული სიტყვების გადაწყვეტის ჩვენ seq2seq არქტიქტურაციას ახალგაზრდებით სიმბოლოების დონეზე დეკოდირებით, რომელიც მომხმარებელი განსაზღვრებული სიმბოლოების ლიმმა და სიმბოლოების დეკოდირებით გაქმნილი სიმბოლოების ჩვენ ვაკეთებთ ჩვენი პროგრამის წაპონიურ-ანგლისურ გაგრძელების რაოდენობით მეცნიერო წერილის დიომინში და ჩვენი მოდელის შესაძლებელია დააყენებული სიტყვები სწორედ ფორმაში', 'el': 'Τα συστήματα μετάφρασης κράτησης θέσης επιτρέπουν στους χρήστες να καθορίσουν πώς μεταφράζεται μια συγκεκριμένη φράση στην πρόταση εξόδου. Το σύστημα εκπαιδεύεται να παράγει ειδικά σήματα κράτησης θέσης και ο όρος που καθορίζεται από το χρήστη εγχέεται στην έξοδο μέσω της αντικατάστασης του συμβολαίου κράτησης θέσης χωρίς πλαίσιο. Ωστόσο και αυτή η προσέγγιση θα μπορούσε να οδηγήσει σε μη γραμματικές προτάσεις επειδή συχνά συμβαίνει ότι ο συγκεκριμένος όρος πρέπει να στραφεί ανάλογα με το πλαίσιο της παραγωγής και το οποίο είναι άγνωστο πριν από τη μετάφραση. Για την αντιμετώπιση αυτού του προβλήματος προτείνουμε μια νέα μέθοδο μετάφρασης κράτησης θέσης που μπορεί να επηρεάσει συγκεκριμένους όρους σύμφωνα με τη γραμματική κατασκευή της πρότασης εξόδου. Επεκτείνουμε την αρχιτεκτονική με έναν αποκωδικοποιητή επιπέδου χαρακτήρων που παίρνει το λέμμα ενός όρου που καθορίζεται από τον χρήστη και τις λέξεις που παράγονται από τον αποκωδικοποιητή επιπέδου λέξεων για να παράγει μια σωστή καμπυλωτή μορφή του λέμματος. Αξιολογούμε την προσέγγισή μας με μια μεταφραστική εργασία ιαπωνικά-αγγλικά στον τομέα της επιστημονικής γραφής και δείχνουμε ότι το μοντέλο μας μπορεί να ενσωματώσει συγκεκριμένους όρους σε σωστή μορφή με μεγαλύτερη επιτυχία από άλλα συγκρίσιμα μοντέλα.', 'kk': 'Орындаушылар аудару жүйелері пайдаланушылардың шығыс сөзде нақты сөзді қалай аударылатынын анықтауға мүмкіндік береді. Жүйе арнаулы орындаушы белгілерін шығару үшін оқылған және пайдаланушының келтірілген термині орындаушы белгісінің орындаушы белгілерін орындау үшін шығысына ендіріледі. Бірақ бұл тәртібі неграмматикалық сөздерге нәтижеледі, себебі келтірілген сөздердің шығыс контекстіне сәйкес келтіру керек болып, аудармасынан алдында беймәлім болуы керек. Бұл мәселеге шешу үшін, шығыс сөздің грамматикалық құрылымына сәйкес келтірілген сөздерді жаңа аудару әдісін таңдаймыз. Біз seq2seq архитектурасын, пайдаланушының келтірілген терминдің лиммасын және сөз деңгейінен құрылған сөздерді лимма деңгейінің дұрыс түрін шығару үшін, таңбалардың деңгейіндегі декодерімен кеңейту. Біз өзімізді жапон-ағылшын тілінен аудару тапсырмасын ғылыми жазу доменінде бағалап, өзіміздің үлгіміздің келтірілген терминдерді басқа сәйкес келетін үлгілерден сәтті түрде қосуға', 'lt': 'Vietos turėtojo vertimo sistemos leidžia naudotojams nurodyti, kaip konkreti frazė vertiama išėjimo sakinyje. Sistema apmokoma išleisti specialius placeholder ženklus, o naudotojui nurodytas terminas suleidžiamas į išėjimą, pakeičiant placeholder ženklą be konteksto. Vis dėlto ir dėl šio požiūrio gali atsirasti nereikalingi sakiniai, nes dažnai reikia nurodytą term in ą skirti atsižvelgiant į išvesties kontekstą ir kuris iki vertimo nežinomas. Siekiant išspręsti šią problem ą ir pasiūlome naują pakeitimo turėtojo vertimo metodą, kuris gali sukelti konkrečius terminus pagal gramatinę išėjimo sakinio konstrukciją. Mes pratęsiame sek2seq architektūrą su simbolio lygio dekoderiu, kuris paima naudotojui nurodyto termino limą ir žodžius, gautus iš žodžio lygio dekoderio, kad būtų išvesta teisinga lemos form a. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and and show our model can incorporate specified terms in a correct form more successfully than other comparable models.', 'it': "I sistemi di traduzione segnaposto consentono agli utenti di specificare come una frase specifica viene tradotta nella frase di output. Il sistema è addestrato a produrre token segnaposto speciali e il termine specificato dall'utente viene iniettato nell'output attraverso la sostituzione senza contesto del token segnaposto. Tuttavia e questo approccio potrebbe portare a frasi non grammaticali perché spesso è il caso che il termine specificato debba essere inflessionato in base al contesto dell'output e che è sconosciuto prima della traduzione. Per affrontare questo problema proponiamo un nuovo metodo di traduzione segnaposto che può influenzare termini specifici in base alla costruzione grammaticale della frase di output. Estendiamo l'architettura seq2seq con un decoder a livello di carattere che prende il lemma di un termine specificato dall'utente e le parole generate dal decoder a livello di parola per produrre una forma corretta del lemma. Valutiamo il nostro approccio con un compito di traduzione giapponese-inglese nel campo della scrittura scientifica e mostriamo che il nostro modello può incorporare termini specificati in una forma corretta con maggiore successo rispetto ad altri modelli comparabili.", 'mk': 'Системите за превод на местоводители им овозможуваат на корисниците да спецификуваат како се преводи специфична фраза во излезната реченица. Системот е обучен за издавање специјални знаци за замена и терминот специфициран од корисникот е инјектиран во излезот преку замена без контекст на знакот за замена. Сепак, овој пристап би можел да резултира со неграматични реченици бидејќи често е случајот што специфицираниот термин треба да биде привлечен според контекстот на излезот и што е непознато пред преводот. За да го решиме овој проблем и предложиме нов метод на превод на местоводителот кој може да привлече специфицирани термини според граматичката изградба на излезната реченица. Ја прошируваме архитектурата seq2seq со декодер на ниво на знаци кој ја зема лимата од терминот специфициран од корисникот и зборовите генерирани од декодерот на ниво на зборови за да излезе точна привлечена форма на лимата. Ние го проценуваме нашиот пристап со задача на јапонски на англиски превод во научниот домен на пишување и покажуваме дека нашиот модел може да вклучи специфицирани термини во точна форма поспешно од другите споредливи модели.', 'ms': 'Sistem terjemahan pemegang ganti membolehkan pengguna menyatakan bagaimana frasa tertentu diterjemahkan dalam kalimat output. Sistem dilatih untuk keluarkan token pemegang ganti istimewa dan terma yang dinyatakan pengguna disuntik ke dalam output melalui penggantian token pemegang ganti tanpa konteks. Namun dan pendekatan ini boleh menghasilkan kalimat tidak rammatik kerana ia adalah kadang-kadang kes bahawa istilah yang dinyatakan perlu ditambah mengikut konteks output dan yang tidak diketahui sebelum terjemahan. Untuk mengatasi masalah ini dan kami cadangkan kaedah baru untuk terjemahan pemegang ganti yang boleh mengalir terma tertentu mengikut pembangunan grammatik kalimat output. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma.  Kami menilai pendekatan kami dengan tugas terjemahan Jepun-ke-Inggeris dalam domain tulisan saintifik dan menunjukkan model kami boleh memasukkan terma tertentu dalam bentuk yang betul lebih berjaya daripada model yang lain yang boleh dibandingkan.', 'mt': 'Is-sistemi tat-traduzzjoni tad-detentur tal-post jippermettu lill-utenti jispeċifikaw kif frażi speċifika tiġi tradotta fis-sentenza tal-ħruġ. Is-sistema hija mħarrġa biex to ħroġ tokens speċjali ta’ sostituzzjoni u t-terminu speċifikat mill-utent jiġi injettat fil-ħruġ permezz ta’ sostituzzjoni mingħajr kuntest tat-token ta’ sostituzzjoni. Madankollu u dan l-approċċ jista’ jirriżulta f’sentenzi mhux grammatiċi minħabba li spiss ikun il-każ li t-terminu speċifikat jeħtieġ li jiġi influtt skont il-kuntest tal-output u li mhuwiex magħruf qabel it-traduzzjoni. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence.  Aħna jestendu l-arkitettura seq2seq b’dekoder fil-livell tal-karattri li jieħu l-limma ta’ terminu speċifikat mill-utent u l-kliem iġġenerat mid-dekoder fil-livell tal-kliem biex joħroġ form a korretta influtta tal-limma. Aħna jevalwaw l-approċċ tagħna b’kompitu ta’ traduzzjoni Ġappuniża-Ingliż fid-dominju tal-kitba xjentifika u nuru li l-mudell tagħna jista’ jinkorpora termini speċifikati f’forma korretta b’aktar suċċess minn mudelli komparabbli oħrajn.', 'ml': 'സ്ഥലത്തുള്ള പരിഭാഷ സിസ്റ്റം പുറത്തുള്ള വാക്കില്\u200d എങ്ങനെ ഒരു പ്രത്യേക വാക്ക് പരിഭാഷപ്പെടുത്തുന്നു സിസ്റ്റത്തില്\u200d പ്രത്യേക സ്ഥലപ്പെടുത്തുന്ന അടയാളങ്ങള്\u200d പുറത്തുവരുത്താന്\u200d പഠിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. ഉപയോക്താവ എന്നാലും ഈ നടപടിയില്\u200d യുങ്രാംമാറ്റല്\u200d വാക്കുകള്\u200dക്ക് ഫലം വരുത്താന്\u200d സാധിക്കുന്നു. കാരണം നിര്\u200dണ്ണയിക്കപ്പെട്ട വെക്കേറ്റ് പ് ഈ പ്രശ്നം വിശദീകരിക്കുവാനും പ്ലാസ്റ്റര്\u200d പരിഭാഷപ്പെടുത്താനുള്ള ഒരു നോവല്\u200d രീതിയില്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു. അത്  ഒരു ഉപയോക്താവിന്റെ നിശ്ചിത അവധിയുടെ ലിമ്മ എടുക്കുന്ന അക്ഷരത്തിലെ സെക്ക്\u200c2സെക്ക് ആര്\u200dക്ടിക്ടെക്ട്രെക്റ്റര്\u200d കൊണ്ട് നാം വികസിപ്പിക്കുന് ശാസ്ത്ര രേഖയുടെ ഡൊമെയിനില്\u200d ജാപ്പനീസില്\u200d നിന്നും ഇംഗ്ലീഷിലേക്കുമുള്ള പരിഭാഷണത്തിന്റെ പ്രവൃത്തിയുമായി നമ്മുടെ നടപടിയെ വിലാസപ്പ', 'mn': 'Placeholder translation systems enable the users to specify how specific phrase is translated in the output sentence. Систем нь ялангуяа оролцогчдын тодорхойлолтуудыг гаргах боломжтой бөгөөд хэрэглэгчийн тодорхойлолтын тодорхойлолтуудын оролцоогоор гаргах боломжтой. Гэхдээ энэ арга нь буруу үг бий болж чадна. Учир нь энэ тодорхой үг нь үр дүнд гаргах боломжтой байдаг. Энэ үг нь орчуулахын өмнө мэдэгдэхгүй. Энэ асуудлыг бодохын тулд бид шинэ арга загвар өгүүлэх үгийг грамматикийн бүтээмжээнд нөлөөлж чадна. Бид seq2seq архитектурыг хэрэглэгчийн тодорхойлогдсон утгын лиммаас, үгний түвшингээс гаргасан үгнүүдийг лиммаас зөв нөлөөлдөг хэлбэрээр нэмэгдүүлнэ. Бид шинжлэх ухааны бичих зохиолынхаа япон-англи хэлний хөрөнгө даалгаварыг үнэлдэг. Бидний загварын загвар нь бусад харьцуулагдмал загвараас илүү амжилттай хэлбэрээр тодорхойлж чадна.', 'pl': 'Systemy tłumaczeń typu placeholder umożliwiają użytkownikom określenie, w jaki sposób dana fraza jest tłumaczona w zdaniu wyjściowym. System jest przeszkolony do wydawania specjalnych tokenów zastępczych, a określony przez użytkownika termin jest wstrzykiwany do wyjścia poprzez bezkontekstową zastępczą token zastępczy. Jednak i takie podejście może skutkować zdaniami nieramatycznymi, ponieważ często zdarza się, że określony termin musi być przekształcony zgodnie z kontekstem wyjścia i który jest nieznany przed tłumaczeniem. Aby rozwiązać ten problem, proponujemy nową metodę tłumaczenia zastępczego, która może zmienić określone terminy zgodnie z konstrukcją gramatyczną zdania wyjściowego. Rozszerzamy architekturę seq2seq o dekoder na poziomie znaków, który przyjmuje lemmę określonego przez użytkownika terminu oraz słowa generowane z dekodera na poziomie słowa, aby wygenerować poprawną formę lemmy. Oceniamy nasze podejście z zadaniem tłumaczenia japońsko-angielskiego w dziedzinie pisania naukowego i pokazujemy, że nasz model może włączyć określone terminy w poprawnej formie skuteczniej niż inne porównywalne modele.', 'no': 'Omsetjingssystemet for plasshaldarar slår brukarar på å spesifisera korleis ein spesifikk frase vert omsetta i utsetjinga. Systemet er trent til å utføra spesielle plasshaldarar- teikn, og brukarappgjeven uttrykk vert injisert inn i utdata gjennom kontekstfri utbytting av plasshaldarar- teiknet. Denne tilnærminga kan imidlertid føre til ungrammatiske setningar, fordi det ofte er tilfellet at det oppgjevne uttrykket må påvirka etter konteksten av utdata og som er ukjent før omsetjinga. For å setja opp dette problemet, og vi foreslår eit nytt metode for omsetjinga av plassholdar som kan påvirka spesifiserte vilkår etter det grammatiske konstruksjonen av utdatasetninga. Vi utvidar arkitekturen seq2seq med eit teikneverkodekoder som tar lemma av eit brukarspesifisert uttrykk og ord som er generert frå ordnivådekoderen for å utføra eit rett influsert form av lemma. Vi evaluerer tilnærminga vårt med eit omsetjing på japansk til engelsk i den vitenskapelige skrivedomenet og viser modellen vårt kan inkludere spesifiserte vilkåra i eit rett form meir suksessfull enn andre sammenlignbare modeller.', 'ro': 'Sistemele de traducere a plasatorului permit utilizatorilor să specifice modul în care o anumită frază este tradusă în propoziția de ieșire. Sistemul este instruit să emită token-uri speciale substituente, iar termenul specificat de utilizator este injectat în ieșire prin înlocuirea fără context a token-ului substituent. Cu toate acestea și această abordare ar putea duce la propoziții ungrammatice deoarece adesea este cazul că termenul specificat trebuie să fie inflectat în funcție de contextul rezultatului și care este necunoscut înainte de traducere. Pentru a aborda această problemă, propunem o metodă nouă de traducere substituentă care poate influența termenii specificați în funcție de construcția gramaticală a propoziției de ieșire. Extindem arhitectura seq2seq cu un decodor la nivel de caractere care ia lemma unui termen specificat de utilizator și cuvintele generate de decodorul la nivel de cuvânt pentru a obține o formă corectă inflectată a lemmei. Evaluăm abordarea noastră cu o sarcină de traducere japoneză-engleză în domeniul scrierii științifice și arătăm că modelul nostru poate încorpora termenii specificați într-o formă corectă mai cu succes decât alte modele comparabile.', 'si': 'Placeholder භාවිත පද්ධතිය ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙ @ info: tooltip නමුත් මෙම විදියට ප්\u200dරතිචාරයක් නැති වචනයක් වෙන්න පුළුවන් විදියට, මොකද ඒක සාමාන්\u200dය විදියට ප්\u200dරතිචාරයක් වෙන්න ඕනේ නි මේ ප්\u200dරශ්න විධානය කරන්න සහ අපි ප්ලේස් හෝල්ඩර් වාර්තාවක් නිර්මාණය කරන්න පුළුවන් ප්\u200dරශ්න විධානය සඳහා විශ් අපි seq2seq ස්ථාපනය විස්තර කරනවා ප්\u200dරයෝජකයෙන් තියෙන්න ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ලි අපි ජාපාන් වල ඉංග්\u200dරීසි වලින් භාෂාවක් එක්ක අපේ විධානය විශ්වාස කරන්න පුළුවන් විද්\u200dයාත්මක විද්\u200dයාපිත විද්\u200dයාපිත වි', 'so': 'Isticmaalayaasha turjumaadda waxaa lagu qaban karaa si ay u caddeyso sida luqad gaar ah looga turjumo qeybta soo baxa. Isticmaalka waxaa lagu baraa in uu soo bixiyo calaamado gooni ah oo ay isticmaalayaashu ku qoran yihiin warqad uu isticmaalayo waxaa lagu soo saxeeyaa dibadda looga beddelo calaamada qoyska. Si kastaba ha ahaatee arinkan waxay sabab u noqon karaan erayo aan dhaqdhaqaaq ahayn, sababtoo ah inta badan waa in lagu saabsan karo xiliga soo baxashada iyo aan la aqoon turjumidda ka hor. Si aan u qabsado dhibaatadan, waxaynu soo jeedinnaa qaab saxda ah oo turjumista shaqaalaha ah, kaas oo saameyn ku yeelan kara qoraal gaar ah sida dhismaha dhaqaalaha. Waxaynu dhismaha saqafka seq2seq ku fidinnaa xarafta darajada, kaasoo qaadaya limma oo ku qoran xiliga cayiman iyo hadallada ka soo baxay qoraalka kordhiska saxda ah, si aan u soo bixino foomka saxda ah oo saxda ah. Waxaynu ku qiimeynaynaa qabashada turjumista ee japaniya-ilaa-Ingiriis ku qoran gudaha qoraalka cilmiga ah, waxaana tusnaynaa qaababka uu ku qori karo qoraalka saxda ah oo ku liibaan karo noocyada kale oo isbarbarbarka ah.', 'sv': 'Platshållare översättningssystem gör det möjligt för användarna att ange hur en specifik fras översätts i utmatningssatsen. Systemet utbildas för att mata ut speciella platshållarkonoker och den användarspecificerade termen injiceras i utmatningen genom att kontextfritt ersätta platshållarkonoken. Men och detta tillvägagångssätt kan resultera i oremmatiska meningar eftersom det ofta är så att den angivna termen behöver böjas enligt kontexten för output och som är okänd före översättningen. För att ta itu med detta problem föreslår vi en ny metod för platshållare översättning som kan influera angivna termer enligt den grammatiska konstruktionen av utmatningsmeningen. Vi utökar sek2seq-arkitekturen med en teckenivå avkodare som tar lemma av en användarspecificerad term och orden som genereras från ordnivåavkodaren för att ge en korrekt böjd form av lemma. Vi utvärderar vårt tillvägagångssätt med en japansk-engelsk översättningsuppgift inom det vetenskapliga skrivområdet och visar att vår modell kan införliva angivna termer i en korrekt form mer framgångsrikt än andra jämförbara modeller.', 'ur': 'Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. سیسٹم ویسی پلیس هولڈر ٹوکنز کے لئے تربیت کی جاری کی جاتی ہے اور کارساز کی تعریف کی ٹوکنس کے بغیر منفی بدلنے کے ذریعہ اپوٹ پیٹ میں تزریق کی جاتی ہے. لیکن اس طریقہ کا نتیجہ غیر قابل ہوتا ہے کیونکہ یہ بہت زیادہ موقع ہے کہ مقرر کی توریت کا انتظام کے مطابق ضرورت ہے اور جو ترجمہ سے پہلے غیر معلوم ہوتا ہے۔ اس مسئلہ کو حل کرنے کے لئے اور ہم ایک نئی طریقہ پیشنهاد کریں گے کہ پلیس هولڈر کی ترجمہ کی تاویل کرتی ہے جس کے مطابق مقررہ شرایط کو اپوٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ ہم سq2seq معماری کو ایک شخص-سطح ڈیکوڈر کے ساتھ پھیلاتے ہیں جو ایک کارساز کے مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق ہے اور کلمات لکھنے کے لئے لکھنے کے لئے لکھنے کے لئے لکھنے لگتے ہیں۔ ہم نے اپنے طریقے کو ایک جاپانی سے انگلیسی ترجمہ کا تابع کے ساتھ سمجھ لیا ہے اور ہمارے موڈل کو دکھا سکتے ہیں کہ مطابق مطابق مطابق مطابق مطابق بقیہ موڈل سے زیادہ مطابق مطابق مطابق مطابق مطابق', 'sr': 'Sisteme prevoda lokalnih država omogućavaju korisnike da specifikuju kako se prevodi određena fraza u izlaznoj rečenici. Sistem je obučen da izvede posebne znakove placeholdera i određeni termin korisnika injicira se u izlaz kroz bezkontekstno zamjenu znakova placeholdera. Međutim, taj pristup bi mogao rezultirati neprammatičnim rečenicama jer je često slučaj da se određeni term in mora uticati u skladu sa kontekstom izlaza i koji je nepoznat pre prevoda. Da bi riješili ovaj problem i predložili smo novu metodu prevoda placeholder a koja može uticati na određene uslove prema gramatičkoj izgradnji izlazne rečenice. Proširimo arhitekturu seq2seq sa dekoderom na nivou karaktera koji uzima limu određenog termina korisnika i reči koje su proizvedene iz dekodera na nivou riječi da izvedemo pravi uticajan oblik lime. Procjenjujemo naš pristup sa zadatkom za prevod japanskog na engleskom jeziku u znanstvenom domenu pisanja i pokazujemo da naš model može uključiti određene uslove u pravom obliku uspješniji od drugih usporednih model a.', 'ta': 'வெளியீட்டு வாக்கியத்தில் எப்படி ஒரு குறிப்பிட்ட சொற்றொடர் மொழிபெயர்ப்பு செய்யப்பட்டுள்ளது என்பதை குறிப் The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token.  @ info இந்த பிரச்சனையை முகவரிப்பதற்கு, நாம் வெளியீட்டு வாக்கியத்தை பொருத்தி குறிப்பிட்ட வரிசைகளை பாதிக்கும் பொருட்டு ஒரு  நாம் ஒரு எழுத்து நிலை குறிமுறையாக்கி விரிவாக்குகிறோம். இது பயனர் குறிப்பிட்ட குறிப்பிட்ட காலத்தின் லிம்மா எடுக்கும் மற்றும் வார்த்தை- மட்டத நாங்கள் அறிவியல் எழுதும் தளத்தில் எங்கள் செயல்பாட்டை ஜாப்பானியில் இருந்து ஆங்கிலம் மொழிபெயர்ப்பு பணியை மதிப்பிட வேண்டும் மற்றும் நாம் எங', 'vi': 'Dịch đối tượng cho phép người dùng xác định cách dịch một cụm từ đặc biệt trong câu phát ra. Hệ thống được huấn luyện để sản xuất những thẻ giữ chỗ đặc biệt và thuật ngữ đã xác định người dùng được tiêm vào kết xuất qua vật thể thay thế không ràng buộc ở chỗ. Tuy nhiên, và cách tiếp cận này có thể dẫn đến các câu to án học, bởi vì thường là trường hợp cần phải nhập vào từ xác định theo ngữ cảnh của kết xuất và chưa rõ ràng trước khi dịch. Để giải quyết vấn đề này và chúng tôi đề nghị một phương pháp dịch chuyển mới của người giữ chỗ có thể sửa đổi các thuật ngữ xác định theo cấu trúc của câu cuối xuất. Chúng tôi mở rộng kiến trúc seq2seq với một bộ giải mã cấp ký tự chứa biểu tượng của một thuật ngữ đã xác định người dùng và từ được tạo ra từ mật mã từ cấp độ từ để xuất ra một dạng uốn cong chính xác của lemma. Chúng tôi đánh giá phương pháp của chúng tôi với một nhiệm vụ dịch chuyển bằng tiếng Nhật-Anh trong lĩnh vực viết khoa học và cho thấy mô hình của chúng tôi có thể áp dụng các thuật ngữ rõ ràng hơn các mô hình tương tự.', 'uz': "@ info: whatsthis Name @ info: whatsthis To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence.  @ info: whatsthis Biz ilmiy yozuvlar domain bilan Japoniya- Ingliz tilidan tarjima qilish vazifasini qiymatmiz va modelimizni ko'rsatish mumkin va boshqa modellardan ko'proq muvaffaqiyatli o'zgartirish mumkin.", 'bg': 'Системите за превод на място позволяват на потребителите да определят как конкретна фраза се превежда в изходното изречение. Системата е обучена да издава специални символи за контекст и определеният от потребителя термин се инжектира в изхода чрез заместване без контекст на символа за контекст. Този подход обаче може да доведе до неграматични изречения, тъй като често е така, че определеният термин трябва да бъде променен в зависимост от контекста на изхода и който е неизвестен преди превода. За да се справим с този проблем, предлагаме нов метод за превод на контейнери, който може да влияе на определени термини според граматическата конструкция на изходното изречение. Разширяваме архитектурата с декодер на ниво символ, който взема лемата на зададен от потребителя термин и думите, генерирани от декодера на ниво дума, за да извлече правилна наклонена форма на лемата. Ние оценяваме нашия подход със задача за превод от японско на английски език в областта на научното писане и показваме, че нашият модел може да включва определени термини в правилна форма по-успешно от други сравними модели.', 'da': 'Placeholder oversættelsessystemer gør det muligt for brugerne at angive, hvordan en bestemt sætning oversættes i outputsætningen. Systemet er uddannet til at udsende specielle pladsholder tokens, og det brugerspecificerede term injiceres i output gennem kontekstfri erstatning af pladsholder tokens. Men og denne fremgangsmåde kan resultere i ukrammatiske sætninger, fordi det ofte er tilfældet, at det angivne udtryk skal bøjes i henhold til konteksten af output, og som er ukendt før oversættelsen. For at løse dette problem, og vi foreslår en ny metode til pladsholder oversættelse, der kan påvirke bestemte termer i henhold til den grammatiske konstruktion af output sætning. Vi udvider sek2seq-arkitekturen med en karakter-niveau dekoder, der tager lemma af et brugerdefineret term og ordene genereret fra ordniveau dekoder til at udsende en korrekt bøjet form af lemma. Vi evaluerer vores tilgang med en japansk-til-engelsk oversættelsesopgave i det videnskabelige skrivedomæne og viser, at vores model kan indarbejde bestemte termer i en korrekt form mere vellykket end andre sammenlignelige modeller.', 'de': 'Platzhalter-Übersetzungssysteme ermöglichen es den Benutzern festzulegen, wie eine bestimmte Phrase im Ausgabesatz übersetzt wird. Das System ist auf die Ausgabe spezieller Platzhalter-Token geschult und der benutzerdefinierte Begriff wird durch den kontextfreien Ersatz des Platzhalter-Tokens in die Ausgabe injiziert. Dieser Ansatz könnte jedoch zu ungrammatischen Sätzen führen, da es oft der Fall ist, dass der angegebene Begriff entsprechend dem Kontext der Ausgabe gebeugt werden muss und was vor der Übersetzung unbekannt ist. Um dieses Problem anzugehen, schlagen wir eine neue Methode der Platzhalterübersetzung vor, die bestimmte Begriffe entsprechend der grammatischen Konstruktion des Ausgangssatzes verfälschen kann. Wir erweitern die seq2seq Architektur um einen Zeichendekoder, der das Lemma eines benutzerdefinierten Terms und die vom Wortdekoder generierten Wörter verwendet, um eine korrekte gebeugte Form des Lemmas auszugeben. Wir evaluieren unseren Ansatz mit einer Übersetzungsaufgabe aus dem Japanisch-ins-Englisch im wissenschaftlichen Schreibbereich und zeigen, dass unser Modell bestimmte Begriffe in korrekter Form erfolgreicher integrieren kann als andere vergleichbare Modelle.', 'id': 'Sistem terjemahan pengganti memungkinkan pengguna untuk menentukan bagaimana frasa spesifik diterjemahkan dalam kalimat keluaran. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token.  Namun dan pendekatan ini bisa menyebabkan kalimat tidak rammatik karena sering terjadi bahwa istilah tertentu perlu disebabkan konteks output dan yang tidak diketahui sebelum terjemahan. Untuk mengatasi masalah ini dan kami mengusulkan metode baru untuk terjemahan pemilik tempat yang dapat mengakibatkan istilah tertentu menurut konstruksi grammatik kalimat keluaran. Kami memperluas arsitektur seq2seq dengan dekoder tingkat karakter yang mengambil lemma dari istilah yang ditentukan oleh pengguna dan kata-kata yang dihasilkan dari dekoder tingkat kata untuk mengeluarkan bentuk lemma yang benar. Kami mengevaluasi pendekatan kami dengan tugas terjemahan bahasa Jepang-bahasa Inggris dalam domain tulisan ilmiah dan menunjukkan model kami dapat memasukkan istilah tertentu dalam bentuk yang benar lebih sukses dari model yang lain yang dapat dibandingkan.', 'nl': 'Met plaatshouders vertaalsystemen kunnen gebruikers specificeren hoe een bepaalde zin in de uitvoerzin wordt vertaald. Het systeem is getraind om speciale placeholder tokens uit te voeren en de door de gebruiker opgegeven term wordt geïnjecteerd in de output door de contextvrije vervanging van de placeholder token. Deze aanpak kan echter resulteren in niet-grammatische zinnen omdat het vaak zo is dat de gespecificeerde term moet worden gebogen volgens de context van de output en die voor de vertaling onbekend is. Om dit probleem aan te pakken stellen we een nieuwe methode voor plaatsaanduiding vertaling voor die specifieke termen kan buigen volgens de grammaticale constructie van de uitvoerzin. We breiden de seq2seq architectuur uit met een decoder op tekenniveau die het lemma van een door de gebruiker opgegeven term en de woorden gegenereerd uit de woorddecoder neemt om een correcte gebogen vorm van het lemma uit te voeren. We evalueren onze aanpak met een Japans-naar-Engels vertaaltaak in het wetenschappelijke schrijfdomein en laten zien dat ons model gespecificeerde termen in een correcte vorm succesvoller kan verwerken dan andere vergelijkbare modellen.', 'hr': 'Sistemi prevođenja mjesta drža ča omogućavaju korisnike da specifikuju kako se prevodi određena fraza u izlaznoj rečenici. Sistem je obučen za izlaganje posebnih znakova placeholdera i određeni izraz korisnika injicira se u izlaz kroz zamjenu znakova placeholdera bez konteksta. Međutim, taj pristup bi mogao rezultirati neprammatskim rečenicama jer je često slučaj da se određeni izraz mora utjecati u skladu s kontekstom izlaza i koji je nepoznat prije prevoda. Za rješavanje ovog problem a i predlažemo novu metodu prevoda placeholdera koja može utjecati na određene uvjete prema gramatičkoj izgradnji izlazne rečenice. Mi proširimo arhitekturu seq2seq sa dekoderom na nivou karaktera koji uzima limu određenog izraza korisnika i riječi koje su proizvedene iz dekodera na nivou riječi kako bi proizveli ispravan uticajan oblik lime. Procjenjujemo naš pristup sa zadatkom za prevod japanskog na engleskom jeziku u znanstvenom domenu pisanja i pokazujemo da naš model može uključiti određene uvjete u pravom obliku uspješniji od drugih usporedbenih model a.', 'ko': '자리 표시자 번역 시스템은 사용자가 출력 문장에서 특정한 단어를 번역하는 방식을 지정할 수 있도록 합니다.트레이닝 시스템은 특수한 자리 표시자를 출력하고, 상하문이 없는 자리 표시자를 교체하여 사용자가 지정한 용어를 출력에 주입합니다.그러나 이런 방법은 문법에 부합되지 않는 문장을 초래할 수 있다. 왜냐하면 통상적으로 지정된 용어는 출력의 상하문에 따라 굴절되고 번역하기 전에 알 수 없기 때문이다.이 문제를 해결하기 위해 우리는 새로운 점위자 번역 방법을 제시하여 출력 문장의 문법 구조에 따라 특정한 용어를 바꿀 수 있다.우리는 문자급 디코더를 사용하여 seq2seq시스템 구조를 확장합니다. 이 디코더는 사용자가 지정한 용어의 인용과 단어급 디코더에서 생성된 단어를 사용하여 정확한 인용 굴절 형식을 출력합니다.우리는 과학 창작 분야의 일본어부터 영문 번역 임무에서 우리의 방법을 평가하고 우리의 모델이 다른 유사한 모델보다 정확한 형식으로 특정 용어를 포함시키는 데 성공할 수 있음을 나타냈다.', 'sw': 'Mfumo wa utafsiri wa Placeholder unawezesha watumiaji kutangaza jinsi neno maalum linavyotafsiriwa kwenye hukumu ya output. Mfumo umefundishwa kutoa ishara maalum za kuweka alama na muhula wa mtumiaji uliotumiwa umeingizwa kwenye matokeo kwa kupitia mabadiliko yasiyo ya kibinafsi ya alama ya eneo hilo. Hata hivyo, mbinu hii inaweza kusababisha hukumu zisizo za kiungwana kwa sababu mara nyingi ni suala ambalo muhula uliopaswa kuathiriwa kwa muktadha wa matokeo na ambayo haijulikani kabla ya tafsiri. Ili kukabiliana na tatizo hili na tunapendekeza njia ya riwaya ya tafsiri ya kuweka nafasi ambayo inaweza kuhusisha vipengele maalum kwa mujibu wa ujenzi wa kigrammatiki wa hukumu ya output. Tunaendelea ujenzi wa sekq2seq kwa kiwango cha alama kinachochukua nyama ya muhula maalumu wa mtumiaji na maneno yaliyozaliwa kutoka kwa kupunguza kiwango cha maneno ili kutoa aina sahihi inayoathirika kwa chumvi. Tutathmini mbinu yetu kwa kazi ya tafsiri ya Kijapani-hadi Kiingereza katika maeneo ya kuandika sayansi na kuonyesha mtindo wetu unaweza kuingiza vipengele maalum katika mfumo sahihi zaidi ya mifano mingine inayofanana.', 'tr': 'Saýlawçy terjime sistemleri ullançylaryň çykyş sözlerinde nähili takyklaýandygyny bejermek üçin mümkin edýär. Bu sistem spesial ýerleşçi işaretçilerini çizdirmek üçin eğitilýär we ullanyşylar spesif edilen sözleri çizgisine süýtgedilýär. Ýöne bu ýagdaý wajyp bolup bilmez sözleriň netijesi bolup biler, sebäbi bu terjime etmekden öň bilinmeyen sözleriň netijesi köplenç edilen ýagdaýda täsirli sözleri etmäge mümkin edýär. Bu meseleyi çözmek üçin we çykyş sözleriniň gramatik inşawlaryna görä belirtilen terjime etmek üçin bir täze täze teklip edip bileris. Biz seq2seq arhitektegi ullanycıň belirtilen sözlerini we kelime dekoderinden oluşan sözleri lemmynyň dogry edilen şeklini çykarmak üçin ullanýarys. Biz öz ýaryşymyzy bilim ýazma domaýynda japonça-iňlis terjimeleri bilen deňleýäris we modelimiz belirlenýän terjimeleri başga örneklerden üstün bir şekilde düzgün bir şekilde daýlayabiler.', 'fa': 'سیستم\u200cهای ترجمه\u200cدهنده جایگزینی اجازه می\u200cدهد کاربر را برای مشخص کردن چگونه یک عبارت خاص در جمله خروجی ترجمه می\u200cشود. سیستم برای خروج نشانه\u200cهای جایگاهی ویژه آموزش داده می\u200cشود و term مشخص شده به کاربر در خروج از طریق جایگاهی جایگاهی خالی نشان جایگاهی را تزریق می\u200cکند. ولی این دستور ممکن است به جمله\u200cهای غیرقابل توجه کند چون اغلب این مورد است که کلمه مشخص باید بر اساس محیط خروج تحت تاثیر قرار گیرد و قبل از ترجمه ناشناخته شود. برای حل این مشکل و پیشنهاد می\u200cکنیم روش نوی ترجمه\u200cهای جایگزینی که می\u200cتواند بر اساس ساختن گراماتیکی از جمله\u200cهای خروج تحت تاثیر قرار دهد. ما معماری seq2seq را با یک dekoder سطح شخصیت می\u200cافزاییم که لیما را از یک کلمه مشخص به کاربر می\u200cگیرد و کلمه\u200cهای تولید شده از سطح کلمه\u200cها تا یک شکل درست تاثیر داده\u200cای از لیما خارج می\u200cکند. ما روش خود را با یک کار ترجمه ژاپن به انگلیسی در دامنۀ نوشتن علمی ارزیابی می کنیم و نمودیم که مدل ما می تواند شرایط مشخص را در یک شکل درست به موفقیت بیشتر از مدل های قابل مقایسه ترجمه جمع کند.', 'af': "Placeholder vertaling stelsels aktiveer die gebruikers om te spesifiseer hoe 'n spesifieke frase in die uitset seting vertaling word. Die stelsel is opgelei na uitvoer spesiale plekhouer tekens en die gebruiker- gespesifiseerde term is ingevoer in die uitvoer deur die konteks- vry vervanging van die plekhouer teken. Maar hierdie toegang kon in onrammatiese setnings resulteer omdat dit dikwels die geval is dat die gespesifiseerde term moet geïnfekteer word volgens die konteks van die uitset en wat is onbekende voor die vertaling. Om hierdie probleem te adres en ons voorstel 'n nuwe metode van plekhouer vertaling wat spesifiseerde terme kan inflek volgens die grammatiese konstruksie van die uitset seting. Ons uitbrei die seq2seq-arkitektuur met 'n karaktervlak dekoder wat neem die lemma van 'n gebruiker-gespesifiseerde term en die woorde genereer van die woord-vlak dekoder om 'n korrek inflekke vorm van die lemma uit te voer. Ons evalueer ons toegang met 'n Japanse-na-Engelse vertaling taak in die wetenskaplike skryfdomein en wys ons model kan spesifiseerde terme in 'n korrekte vorm meer suksesvol as ander vergelykbare modele inkorpreer.", 'hy': 'Տեղադրական թարգմանման համակարգերը թույլ են տալիս օգտագործողներին նշել, թե ինչպես է որոշակի արտահայտությունը թարգմանվում արտադրյալ նախադասում: Համակարգը վարժեցվում է արտադրելու հատուկ տեղաշարժման նշաններ, և օգտագործողի նշանները ներարկվում են արտադրման մեջ տեղաշարժման նշանի անկոնտեքստի փոխարինման միջոցով: However and this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output and which is unknown before the translation.  Այս խնդիրը լուծելու համար և մենք առաջարկում ենք տեղափոխման նոր մեթոդ, որը կարող է որոշ տերմիններ ազդել ըստ արտադրյալ նախադասության գրամատիկական կառուցվածքի: Մենք ընդլայնում ենք հետևյալ 2Sex ճարտարապետությունը բնավորության մակարդակի դեկոդերով, որը վերցնում է օգտագործողի կոնկրետ տերմինի լեմման և բառերը, որոնք ստեղծվում են բառերի մակարդակի դեկոդերով, որպեսզի Մենք գնահատում ենք մեր մոտեցումը ճապոներեն-անգլերեն թարգմանման խնդրի հետ գիտական գրության ոլորտում և ցույց ենք տալիս, որ մեր մոդելը կարող է ներառել որոշ տերմիններ ճիշտ ձևով ավելի հաջողությամբ, քան այլ համեմատական մոդելները:', 'sq': 'Sistemet e përkthimit të zëvendësuesve lejojnë përdoruesit të përcaktojnë se si përkthimi i një fraze specifike është në frazën e daljes. Sistemi është trajnuar për të dalë token e posaçme të zëvendësimit dhe termi i specifikuar nga përdoruesi injektohet në dalje nëpërmjet zëvendësimit pa kontekst të token e zëvendësimit. Megjithatë dhe kjo qasje mund të rezultojë në fjalë jo-grammatike sepse shpesh është rasti që termi i përcaktuar duhet të sillet sipas kontekstit të daljes dhe që është e panjohur përpara përkthimit. Për të trajtuar këtë problem dhe ne propozojmë një metodë të re të përkthimit të zëvendësuesit që mund të sjellë terma të caktuara sipas ndërtimit gramatik të fjalës së daljes. Ne zgjerojmë arkitekturën seq2seq me një dekoder të nivelit të karakterit që merr limën e një termi të specifikuar nga përdoruesi dhe fjalët e gjeneruara nga dekoderi i nivelit të fjalëve për të dalë një form ë korrekte të përdorur të limës. Ne vlerësojmë qasjen tonë me një detyrë përkthimi japonez-anglez në domenin shkencore shkencore dhe tregojmë se modeli ynë mund të përfshijë terma të caktuara në një form ë të saktë më me sukses se modele të tjera të krahasueshëm.', 'bn': 'স্থানীয় অনুবাদ সিস্টেম আউটপুটের বাক্যে কিভাবে একটি নির্দিষ্ট বাক্য অনুবাদ করা হয়েছে তা ব্যবহারকারীদের উল্ল সিস্টেম প্রশিক্ষণ করা হয় বিশেষ প্লেসেভারের চিহ্ন আউটপুট করতে এবং ব্যবহারকারী নির্দিষ্ট মেয়াদের প্লেসেভারের অক্ষরের মাধ্ তবে এই পদক্ষেপের ফলে ইঙ্গ্রাম্যাটিক্যাল বাক্যের ফলাফল হতে পারে কারণ প্রায়শই এই বিষয়টি আউটপুটের প্রেক্ষিত অনুবাদের আগে নির্দি এই সমস্যাকে ঠিকানা করার জন্য এবং আমরা প্লেসেভারের অনুবাদের একটি নোভেল পদ্ধতি প্রস্তাব করি যা আউটপুটের গ্রাম্যাটিক্যাল বাণীর অন আমরা এক অক্ষর-স্তরের ক্ষেত্রে সেক্স২সেক আর্কিটার বাড়িয়ে দিই যা ব্যবহারকারীর নির্দিষ্ট মেয়াদের লেমা নিয়ে যায় এবং লেম্মার সঠিক প্রভাবিত ফর্ম উৎপা আমরা বৈজ্ঞানিক লেখা ডোমেইনে জাপানী থেকে ইংরেজি অনুবাদের কাজের মাধ্যমে আমাদের প্রতিযোগিতা মূল্যায়ন করি এবং আমাদের মডেল দেখাই যে সঠিক পদ্ধতি', 'am': 'ቦታ ቦታ ምንም እንኳን፣ ይህም ሥርዓት የውጤት ግንኙነት እና ከማይተርጉም በፊት ያልታወቀ ግንኙነት እንዲቀበል ይችላል፡፡ ይህንን ጉዳይ ለመቀበል እና የውጤት ፍርድ እንደተካፈለ የግንኙነት ግንኙነትን ለመቀበል የሚችል የአሁኑን መዘርጋት የቦታ ትርጉም ማቀናጃ እናስጀጋለን፡፡ የseq2seq መሠረት አካባቢውን በጽሑፍ-ደረጃ አካባቢ እናሳድጋለን፤ የኢሜይል ጉዳይ እና ቃላት ከቃላት-ደረጃ ቁጥጥር የተደረገውን የኢሜሊም መልክ ለመውጣት እናስጠጋለን፡፡ የጃፓን-ወደ እንግሊዘኛ ትርጉም አድራጊያችንን በሳይንቀሳዊ ጽሑፍ ድራሻ ውስጥ እናሳውቃለን እና ሞዴሌያችንን በተካፈሉ ሞዴላዎች ላይ በተለየ ክፍል በሚያሳየው ጽሑፎችን እናሳውቃለን፡፡', 'az': 'Placeholder tercümə sistemləri istifadəçilərin çıxış cümləsində növbəsini növbəsinin tercümə edildiyini belirtməsini qabilleştirir. Sistem xüsusi yeri tutucu işaretlərini çıxartmaq üçün təhsil edilir və istifadəçi belirtilmiş termini dağıtmaq üçün yer tutucu işaretini bağsız yerə qoyur. Ancaq bu tərzim çox dəyişiklik cümlələrə bənzər olar, çünki bu tərzim, tərzimdən əvvəl bilinmədən əvvəl belə yazılmış cümlələr təsirlənməsi lazımdır. Bu problemi çəkmək üçün və biz yeni bir tərzim təklif edirik ki, belə yazılmış şartları çıxış cümləsinin gramatik inşallarına görə müəyyən edə bilər. Biz seq2seq arhitektarını bir karakter səviyyəsi dekoderiylə genişləyirik ki, istifadəçinin belə yazılmış terminin limmini və söz səviyyəsindən yaratdığı sözlər limminin doğru təsirli formunu çıxartmaq üçün. Biz həyatımızı elmi yazmaq domeinində Japon-İngilizə çevirilmiş işləri ilə değerləşdiririk və modellərimiz belə yazılmış şəkillərə başqa kompatibil modellərdən daha müvəffəqiyyətli bir şekilde birləşdirir.', 'bs': 'Sistemi prevoda lokalnih država omogućavaju korisnike da specifikuju kako se prevodi određena fraza u izlaznoj rečenici. Sistem je obučen za izlazak posebnih znakova placeholdera i određeni termin korisnika injicira se u izlazak kroz bezkontekstnu zamjenu znakova placeholdera. Međutim, taj pristup bi mogao rezultirati neprammatičnim rečenicama jer je često slučaj da se određeni term in mora uticati u skladu sa kontekstom izlaza i koji je nepoznat prije prevoda. Da riješimo ovaj problem i predlažemo novu metodu prevoda placeholder a koja može utjecati na specifične uvjete prema gramatičkoj izgradnji presude za izlaz. Proširimo arhitekturu seq2seq sa dekoderom na nivou karaktera koji uzima limmu određenog termina korisnika i riječi koje su proizvedene iz dekodera na nivou riječi da izvede pravi utjecan oblik lime. Procjenjujemo naš pristup sa zadatkom za prevod japanskog na engleskom jeziku u znanstvenom domenu pisanja i pokazujemo da naš model može uključiti određene uslove u pravom obliku uspješniji od drugih usporedbenih model a.', 'fi': 'Paikkamerkkien k채채nn철sj채rjestelmien avulla k채ytt채j채t voivat m채채ritt채채, miten tietty lause k채채nnet채채n tuloslauseessa. J채rjestelm채 on koulutettu tuottamaan erityisi채 paikkamerkkimerkkej채 ja k채ytt채j채n m채채ritt채m채 termi injektoidaan l채ht철철n paikkamerkkitunnuksen kontekstittoman korvaamisen kautta. T채m채 l채hestymistapa voi kuitenkin johtaa sanattomiin lauseisiin, koska usein tietty채 termi채 on muokattava tuotoksen kontekstin mukaan ja se on tuntematon ennen k채채nn철st채. T채m채n ongelman ratkaisemiseksi ehdotamme uutta paikkamerkkik채채nn철smenetelm채채, joka voi vaikuttaa tiettyihin termeihin tuloslauseen kieliopillisen rakenteen mukaisesti. Laajennamme seq2seq-arkkitehtuuria merkkitason dekooderilla, joka ottaa k채ytt채j채n m채채ritt채m채n termin lemman ja sanatason dekooderista generoidut sanat tuottamaan oikean taivutetun muodon lemmasta. Arvioimme l채hestymistapaamme japani-englanti-k채채nn철steht채v채ll채 tieteellisen kirjoittamisen alalla ja osoitamme, ett채 mallimme pystyy sis채llytt채m채채n tietyt termit oikeassa muodossa menestyksekk채채mmin kuin muut vastaavat mallit.', 'ca': "Els sistemes de traducció de substitució permeten als usuaris especificar com es tradueix una frase específica a la frase de sortida. El sistema està entrenat a produir fitxes especials de sostitució i el terme especificat per l'usuari s'injecta a la producció a través de la substitució sense contest de la fitxa de sostitució. Però aquest enfocament podria resultar en frases ungrammàtiques perquè sovint és el cas que el terme especificat ha de ser infligit segons el context de la producció i que és desconegut abans de la traducció. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence.  Estendem l'arquitectura seq2seq amb un decodificador de nivell de caràcter que agafa el llem d'un terme especificat per l'usuari i les paraules generades del decodificador de nivell de paraules per produir una form a correcta influïda del llem. Evaluam el nostre enfocament amb una tasca de traducció japonès a anglès en el domini de l'escriptura científica i demostram que el nostre model pot incorporar termes especificats d'una forma correcta amb més èxit que altres models comparables.", 'cs': 'Umístěné překladové systémy umožňují uživatelům určit, jak je konkrétní fráze přeložena ve výstupní větě. Systém je trénován na výstup speciálních zástupných tokenů a uživatelem určený termín je vstřikován do výstupu prostřednictvím bezkontextové nahrazení zástupného tokenu. Tento přístup by však mohl vést k negrammatickým větám, protože je často tak, že zadaný termín musí být definován podle kontextu výstupu a který je před překladem neznámý. Pro řešení tohoto problému navrhujeme novou metodu překladu zástupných symbolů, která může definovat specifikované termíny podle gramatické konstrukce výstupní věty. Rozšiřujeme architekturu seq2seq o dekodér na úrovni znaků, který bere lemma uživatelem určeného termínu a slova generovaná z dekodéru úrovně slova k výstupu správné zkloněné formy lemmy. Hodnotíme náš přístup s japonsko-anglickým překladem v oblasti vědeckého psaní a ukážeme, že náš model dokáže začlenit specifikované termíny ve správné podobě úspěšněji než ostatní srovnatelné modely.', 'et': 'Kohahoidja tõlkesüsteemid võimaldavad kasutajatel määrata, kuidas konkreetne fraas väljundlauses tõlgitakse. Süsteem on koolitatud väljastama spetsiaalseid kohatäitetunnuseid ja kasutaja määratud terminit süstitakse väljundisse kohatäitetunnuse kontekstivaba asendamise kaudu. Selline lähenemisviis võib aga põhjustada mittekrammatilisi lauseid, sest sageli tuleb määratud terminit painutada vastavalt väljundi kontekstile ja mis on enne tõlkimist tundmatu. Selle probleemi lahendamiseks pakume välja uue kohatäitjate tõlke meetodi, mis võib mõjutada määratud termineid vastavalt väljundlause grammatilisele konstruktsioonile. Laiendame seq2seq arhitektuuri märgitasemel dekoodriga, mis võtab kasutaja määratud termini lemma ja sõnatasemel dekoodrist genereeritud sõnad, et väljastada lemma õige painutatud vorm. Hindame oma lähenemisviisi jaapani-inglise tõlkeülesandega teadusliku kirjutamise valdkonnas ning näitame, et meie mudel suudab konkreetseid termineid õigel kujul edukamalt kasutada kui teised võrreldavad mudelid.', 'jv': 'Laptop" and "Desktop Sistem dadi kelompok nggo ngwalih \'token\' sing dibutuhke dadi mesthi, nganggo gambar kelompok nggawe nyimpen winih politenessoffpolite"), and when there is a change ("assertive Nyong ngomong alam iki ning aram sing dibutuhke batir sistem ning tarjamahan Awak dhéwé ngewat architecture seq2seq karo ndedekorahan kelompok character-nambah sing ngewehke limma kelompok nggambar kelompok nggambar kelompok kuwi nambah gambar uwong We assert us method with a japanese-to-englesi translation task in the Sayensi writing domain and show the model we can insert selected terms in a rect format, with the same success as the second parable.', 'ha': "@ action: button An sanar da shi na'urar wa ya fito alama masu hushi na ɗabi'a da aka shigar da shi wa'urar da aka ƙayyade shi a cikin fitarwa don a bãyar da musanya na'urar-da-matsayin wurin. Babu kuma wannan hanyor zai iya ƙara ga cewa masu ungramati, kwani ko da yawa, za'a yi amfani da muhalli wanda aka ƙayyade shi daidai da mazaunin zartar da kuma da abin da ba'a sani ba a gaba ga fassarar. Domin da za'a yi amfani da wannan muammãni, kuma mu buƙata wata hanyoyi na fassarar fassarar-wurin da za'a yi amfani da ƙayyade ƙayyade, kamar da aka gina na grammati da cewa na fitarwa. Mu shimfiɗa matsayin seq2seq da wani kode-daraja mai daidaita, mai ɗauki limma na mai amfani da shi wanda aka ƙayyade maɓallin amfani da kuma magana wanda aka ƙãga daga dioder-daraja zuwa ya fito wani tsari mai inganci na rubutu. Tuna ƙaddara hanyarmu da wani aikin fassarar-Ingiriya ya wajen jama'a-zuwa-Ingiriya a cikin shekaran littafin da aka sani kuma za mu nuna misalinmu yana iya shigar da shi cikin tsarin da aka daidaita, mafaniki ko wasu misãlai masu kamata.", 'sk': 'Sistemi prevajanja označevalnika mesta omogočajo uporabnikom, da določijo, kako je določena fraza prevedena v izhodnem stavku. Sistem je usposobljen za izdajanje posebnih žetonov označbe mesta, uporabnikov določen izraz pa se vbrizga v izhod z zamenjavo žetona označbe mesta brez konteksta. Vendar pa bi ta pristop lahko povzročil ungrammatične stavke, saj je pogosto treba določeni izraz upogibati glede na kontekst izpisa in ki pred prevodom ni znan. Za reševanje tega problema predlagamo novo metodo prevajanja označb mesta, ki lahko vpliva na določene izraze glede na slovnično konstrukcijo izhodnega stavka. Arhitekturo seq2seq razširimo z dekoderjem na ravni znakov, ki uporabniku določenega izraza in besedami, generiranimi iz dekoderja na ravni besed, ki izdajajo pravilno upognjeno obliko lemme. Naš pristop ocenjujemo s prevajanjem iz japonščine v angleščino na področju znanstvenega pisanja in pokažemo, da lahko naš model vključuje določene izraze v pravilni obliki uspešneje kot drugi primerljivi modeli.', 'he': 'מערכות התרגום של מחזיקים מאפשרות למשתמשים לקבוע איך משפט ספציפי מתרגם במשפט ההוצאה. המערכת מאומנת להוציא סימנים מיוחדים של מחזיקי המקום והמונח המוגדר על ידי המשתמש מוזרק לתוך ההוצאה דרך החליפה ללא הקשר של סימני מחזיקי המקום. עם זאת, והגישה הזאת יכולה לגרום למשפטים לא גרמטיים, כי לעתים קרובות זה המקרה שהמונח המוגדר צריך להיגרם לפי הקשר של ההוצאה והוא לא ידוע לפני התרגום. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence.  אנו ממשיכים את הארכיטקטורה seq2seq עם מפענח רמת אופיים שמוציא את הלמה של מונח מסוים למשתמש והמילים שנוצרו מהמפענח רמת המילים כדי להוציא צורה נכונה של הלמה. אנו מעריכים את הגישה שלנו עם משימה התרגום יפנית לאנגלית בתחום הכתיבה המדעי ולהראות שהמודל שלנו יכול להכיל תנאים מוגדרים בצורה נכונה יותר בהצלחה ממודלים שווים אחרים.', 'bo': 'Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token. ཡིན་ནའང་། ཐབས་ལམ་འདི་ནི་ཚིག་རྐང་མ་ལག To address this problem and we propose a new method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and show our model can incorporate specified terms in a correct form more successfully than other comparable models.'}
{'en': 'Neural Machine Translation with Inflected Lexicon', 'es': 'Traducción automática neuronal con léxico flexionado', 'fr': 'Traduction automatique neuronale avec lexique infléchi', 'ar': 'الترجمة الآلية العصبية مع المعجم المنعكس', 'pt': 'Tradução automática neural com léxico flexionado', 'hi': 'तंत्रिका मशीन अनुवाद Inflected शब्दकोश के साथ', 'ru': 'Нейронный машинный перевод с инфлектированным лексиконом', 'zh': '用屈词典之神经机器翻译', 'ja': 'Inflected Lexiconによる神経機械翻訳', 'ga': 'Aistriúchán Meaisín Néarthach le Foclóir Infhillte', 'hu': 'Neurális gépi fordítás inflektált lexikonnal', 'el': 'Νευρική μηχανική μετάφραση με διεστραμμένο λεξικό', 'ka': 'Name', 'it': 'Traduzione automatica neurale con lessico influenzato', 'lt': 'Name', 'mk': 'Name', 'ms': 'Name', 'mt': 'Traduzzjoni tal-Magna Newrali bil-Lexicon Inflett', 'kk': 'Инфекцияланған лексиканың нейрондық машинаның аудармасыName', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുക Infleated Lexicon കൊണ്ട്', 'no': 'Name', 'pl': 'Neurologiczne tłumaczenie maszynowe z odwróconym słownikiem', 'sr': 'Neuralna mašina prevoda sa inficiranom leksijum', 'mn': 'Цөмийн механикийн шинжлэх ухаан сэтгэл хөдлөл', 'si': 'Name', 'so': 'Turjumista Neural machine with Infleated Lexicon', 'ta': 'Name', 'ro': 'Traducere automată neurală cu Lexicon influențat', 'sv': 'Neural maskinöversättning med influerad Lexikon', 'ur': 'نئورل ماشین ترجمه', 'vi': 'Dịch sang thần kinh với ngôn ngữ', 'uz': 'Name', 'nl': 'Neurale machinevertaling met geïnflecteerd lexicon', 'hr': 'Neuralna strojna prevoda s inflekcijom', 'da': 'Neural maskinoversættelse med influeret Lexicon', 'ko': '어형 변화의 신경', 'id': 'Translation Mesin Neural dengan Lexicon TerInfleksi', 'de': 'Neurale maschinelle Übersetzung mit dem abgelenkten Lexikon', 'sw': 'Tafsiri ya Mashine ya Njerumani na Lexico', 'bg': 'Нервен машинен превод с наклонен лексикон', 'af': 'Nural Masjien Vertaling met InfleksieName', 'am': 'ትርጉም', 'fa': 'ترجمه ماشین عصبی با لکسیسون غیرفعال', 'tr': 'Infleksiýan bilen näyral Maşynyň terjime edilmesi', 'sq': 'Përkthimi i Makinës Neurale me Leksikon Inflektuar', 'bn': 'ইনফ্লেকেট লেক্সিকোর সাথে নিউরাল মেশিন অনুবাদ', 'bs': 'Neuralna mašina prevoda sa inflekcijom', 'hy': 'Նյարդային մեքենայի թարգմանություն ներխուժված լեքսիկոնի օգնությամբ', 'az': 'N칬ral Makinat T톛rc칲m톛si', 'et': 'Neuraalne masintõlge mõjutatud leksikoniga', 'fi': 'Neuronen konekäännös, jossa on taipuvainen Lexicon', 'ca': 'Traducció de màquines neuronals amb Lexicon influït', 'cs': 'Neurální strojový překlad s deflektovaným Lexikonem', 'ha': 'translation', 'he': 'תרגום מכונת עצבית עם לקסיקון מושפע', 'sk': 'Živčni strojni prevod z upognjenim leksikonom', 'bo': 'Inflected Lexicon དང་སྦྲེལ་བའི་ལག་འཁྱེར་གྱི་ཚོར་བརྗོད་པ', 'jv': 'Manejer Perintah Njuar karo Leksion sing dibutuhke'}
{'en': 'The paper presents experiments in  neural machine translation  with  lexical constraints  into a  morphologically rich language . In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture. To evaluate its effectiveness and we carry out experiments in two different scenarios : general and domain-specific. We compare our  method  with baseline translation and i.e. translation without  lexical constraints  and in terms of translation speed and  translation quality . To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.', 'pt': 'O artigo apresenta experimentos de tradução automática neural com restrições lexicais em uma linguagem morfologicamente rica. Em particular e introduzimos um método baseado em decodificação restrita e que trata as formas flexionadas de entradas lexicais e não requer nenhuma modificação nos dados de treinamento ou na arquitetura do modelo. Para avaliar sua eficácia e realizamos experimentos em dois cenários diferentes: geral e específico de domínio. Comparamos nosso método com a tradução de linha de base e, ou seja, a tradução sem restrições lexicais e em termos de velocidade e qualidade da tradução. Para avaliar quão bem o método lida com as restrições e propomos novas métricas de avaliação que levam em conta a presença e colocação e duplicação e correção flexional de termos lexicais na sentença de saída.', 'es': 'El artículo presenta experimentos de traducción automática neuronal con restricciones léxicas en un lenguaje rico morfológicamente. En particular, introducimos un método basado en la decodificación restringida y que maneja las formas flexionadas de las entradas léxicas y no requiere ninguna modificación de los datos de entrenamiento o la arquitectura del modelo. Para evaluar su eficacia, realizamos experimentos en dos escenarios diferentes: general y específico del dominio. Comparamos nuestro método con la traducción de referencia y, por ejemplo, con la traducción sin restricciones léxicas y en términos de velocidad y calidad de traducción. Para evaluar qué tan bien el método maneja las restricciones y proponemos nuevas métricas de evaluación que tengan en cuenta la presencia y la ubicación y la duplicación y la corrección inflexional de los términos léxicos en la oración de salida.', 'ar': 'تقدم الورقة تجارب في الترجمة الآلية العصبية مع القيود المعجمية إلى لغة غنية شكليًا. على وجه الخصوص ، نقدم طريقة تعتمد على فك التشفير المقيد والتي تتعامل مع الأشكال المنعكسة من المدخلات المعجمية ولا تتطلب أي تعديل على بيانات التدريب أو بنية النموذج. لتقييم فعاليتها ونقوم بإجراء تجارب في سيناريوهين مختلفين: عام وآخر خاص بالمجال. نحن نقارن طريقتنا مع الترجمة الأساسية أي الترجمة بدون قيود معجمية ومن حيث سرعة الترجمة وجودة الترجمة. لتقييم مدى تعامل الطريقة مع القيود بشكل جيد ، نقترح مقاييس تقييم جديدة تأخذ في الاعتبار التواجد والموضع والازدواجية وصحة التصريف للمصطلحات المعجمية في الجملة الناتجة.', 'fr': "L'article présente des expériences de traduction automatique neuronale avec des contraintes lexicales dans un langage morphologiquement riche. En particulier, nous introduisons une méthode basée sur le décodage contraint et qui gère les formes fléchies des entrées lexicales et ne nécessite aucune modification des données d'apprentissage ou de l'architecture du modèle. Pour évaluer son efficacité, nous menons des expériences dans deux scénarios différents\xa0: général et spécifique au domaine. Nous comparons notre méthode avec la traduction de base, c'est-à-dire la traduction sans contraintes lexicales et en termes de vitesse de traduction et de qualité de traduction. Pour évaluer dans quelle mesure la méthode gère les contraintes, nous proposons de nouvelles mesures d'évaluation qui tiennent compte de la présence, du placement et de la duplication et de l'exactitude flexionnelle des termes lexicaux dans la phrase de sortie.", 'ja': '論文は、形態論的に豊かな言語への語彙的制約を伴うニューラル機械翻訳における実験を提示している。特に、私たちは、制約されたデコードに基づいた方法を導入し、これは、語彙エントリの屈折形式を扱い、トレーニングデータまたはモデルアーキテクチャへのいかなる修正も必要としない。その有効性を評価するために、一般的なシナリオとドメイン固有のシナリオの2つの異なるシナリオで実験を行います。私たちは、私たちの方法をベースライン翻訳と比較します。すなわち、語彙的制約なしに、翻訳速度と翻訳品質の観点から翻訳します。メソッドが制約をどの程度うまく処理しているかを評価するために、出力文の語彙の存在と配置、重複と屈折の正しさを考慮した新しい評価指標を提案します。', 'zh': '本文引词汇约神经机器翻译实验,转为形容丰语。 凡入约束解码法,处理词屈折,不须训练数体体系结构修改。 为评其有效性,实验于两途,凡特定领域。 以我等法较基线译,即无词汇限译,及译速译质。 凡评约束之能,新评指标,指标思输句词汇术语存位重屈正确性。', 'ru': 'В статье представлены эксперименты по нейронному машинному переводу с лексическими ограничениями на морфологически богатый язык. В частности, мы вводим метод, основанный на ограниченном декодировании, который обрабатывает перекошенные формы лексических записей и не требует каких-либо изменений в обучающих данных или архитектуре модели. Чтобы оценить его эффективность, мы проводим эксперименты в двух различных сценариях: общих и предметно-ориентированных. Мы сравниваем наш метод с базовым переводом и то есть переводом без лексических ограничений, а также с точки зрения скорости и качества перевода. Чтобы оценить, насколько хорошо метод справляется с ограничениями, мы предлагаем новые оценочные показатели, которые учитывают наличие и размещение, а также дублирование и инфлексивную корректность лексических терминов в выходном предложении.', 'hi': 'पेपर एक रूपात्मक रूप से समृद्ध भाषा में लेक्सिकल बाधाओं के साथ तंत्रिका मशीन अनुवाद में प्रयोगों को प्रस्तुत करता है। विशेष रूप से और हम एक विधि पेश करते हैं और विवश डिकोडिंग के आधार पर और जो लेक्सिकल प्रविष्टियों के इनफ्लेक्टेड रूपों को संभालता है और प्रशिक्षण डेटा या मॉडल आर्किटेक्चर में किसी भी संशोधन की आवश्यकता नहीं है। इसकी प्रभावशीलता का मूल्यांकन करने के लिए और हम दो अलग-अलग परिदृश्यों में प्रयोग करते हैं: सामान्य और डोमेन-विशिष्ट। हम बेसलाइन अनुवाद के साथ हमारी विधि की तुलना करते हैं और यानी लेक्सिकल बाधाओं के बिना और अनुवाद की गति और अनुवाद की गुणवत्ता के संदर्भ में अनुवाद करते हैं। यह मूल्यांकन करने के लिए कि विधि बाधाओं को कितनी अच्छी तरह से संभालती है और हम नए मूल्यांकन मैट्रिक्स का प्रस्ताव करते हैं जो आउटपुट वाक्य में लेक्सिकल शब्दों की उपस्थिति और प्लेसमेंट और दोहराव और इन्फ्लेक्शनल शुद्धता को ध्यान में रखते हैं।', 'ga': 'Cuireann an páipéar i láthair turgnaimh in aistriúchán meaisín néarach le srianta foclóireachta go teanga saibhir ó thaobh moirfeolaíochta de. Go háirithe agus tugaimid isteach modh atá bunaithe ar dhíchódú srianta agus a láimhseálann foirmeacha infhillte na n-iontrálacha foclóireachta agus nach gá aon mhodhnú ar na sonraí oiliúna nó ailtireacht na samhla. Chun a éifeachtúlacht a mheas agus déanaimid turgnaimh in dhá chás éagsúla: ginearálta agus sainiúil don fhearann. Déanaimid ár modh a chur i gcomparáid le haistriúchán bonnlíne agus i.e. aistriúchán gan srianta foclóireachta agus i dtéarmaí luas an aistriúcháin agus cáilíocht an aistriúcháin. Chun a mheas cé chomh maith agus a láimhseálann an modh na srianta agus molaimid méadracht mheastóireachta nua a chuireann san áireamh láithreacht agus socrúchán agus dúbailt agus cruinneas infhillte na dtéarmaí foclóireachta san abairt aschuir.', 'hu': 'A tanulmány lexikai korlátozásokkal rendelkező neurális gépi fordítási kísérleteket mutat be morfológiailag gazdag nyelvre. Különösen egy olyan módszert vezetünk be, amely korlátozott dekódoláson alapul, és amely kezeli a lexikai bejegyzések inflexált formáit, és nem igényel semmilyen módosítást a képzési adatokban vagy a modell architektúrájában. Hatékonyságának értékelése és kísérleteket végezünk két különböző forgatókönyvben: általános és tartományspecifikus. Módszerünket összehasonlítjuk az alapfordítással, azaz lexikai korlátozások nélküli fordítással, a fordítási sebesség és a fordítási minőség tekintetében. Annak értékelésére, hogy a módszer milyen jól kezeli a korlátozásokat, és új értékelési mutatókat javasolunk, amelyek figyelembe veszik a lexikai kifejezések jelenlétét és elhelyezését, duplikálását és inflexuális korrektségét a kimeneti mondatban.', 'el': 'Η εργασία παρουσιάζει πειράματα νευρολογικής μηχανικής μετάφρασης με λεξικούς περιορισμούς σε μια μορφολογικά πλούσια γλώσσα. Ειδικότερα και εισάγουμε μια μέθοδο βασισμένη στην περιορισμένη αποκωδικοποίηση και η οποία χειρίζεται τις καμπυλωμένες μορφές λεξικών καταχωρήσεων και δεν απαιτεί καμία τροποποίηση στα δεδομένα εκπαίδευσης ή την αρχιτεκτονική μοντέλου. Για να αξιολογήσουμε την αποτελεσματικότητά του και διεξάγουμε πειράματα σε δύο διαφορετικά σενάρια: γενικό και συγκεκριμένο τομέα. Συγκρίνουμε τη μέθοδο μας με τη μετάφραση βάσης και δηλαδή τη μετάφραση χωρίς λεξικούς περιορισμούς και όσον αφορά την ταχύτητα και την ποιότητα της μετάφρασης. Για να αξιολογήσουμε πόσο καλά η μέθοδος χειρίζεται τους περιορισμούς και προτείνουμε νέες μετρήσεις αξιολόγησης που λαμβάνουν υπόψη την παρουσία και τοποθέτηση και την επικάλυψη και την καμπυλωτή ορθότητα των λεξικών όρων στην πρόταση εξόδου.', 'ka': 'დაახლოები ექსპერიმენტებს ნეიროლური მაქსინის გაგრძელებაში ლექსიკალური ზომილებები მოპოროლოგიურად ღარიბული ენაში. განსაკუთრებულია და ჩვენ შევცვალოთ მეტი და დავუდგინეთ დარწმუნებული სკოდირებაზე და რომელიც ლექსიკალური ჩანაწერების შემდეგ გამოყენებული ფორმების გამოყენება და არ უნდა შეცვალობა მო ჩვენ ექსპერიმენტების ექსპერიმენტები გავაკეთებთ ორი განსხვავებული სინარიოში: ჯერნალური და დიომინური განსხვავებული. ჩვენ ჩვენი მეთოდის გადასწორება ფესლინის გადასწორებას და, მაგალითად, ლექსიკალური გადასწორებას და გადასწორება სიჩქარე და გადასწორება. როგორც მეტი უფრო კარგი გამოყენებს შესაძლებლობების შესახებ და ჩვენ გვეძლება ახალი შესახებ მეტრიკების შესახებ, რომლებიც აღმოჩნენ ლექსიკალური სიტყვების შესახებ და დაწყენება და ე', 'it': "L'articolo presenta esperimenti di traduzione automatica neurale con vincoli lessicali in un linguaggio morfologicamente ricco. In particolare introduciamo un metodo basato sulla decodifica vincolata e che gestisce le forme inflesse di voci lessicali e non richiede alcuna modifica ai dati formativi o all'architettura del modello. Per valutarne l'efficacia e condurre esperimenti in due diversi scenari: generale e dominio-specific. Confrontiamo il nostro metodo con la traduzione di base e cioè la traduzione senza vincoli lessicali e in termini di velocità e qualità di traduzione. Per valutare quanto bene il metodo gestisca i vincoli e proponiamo nuove metriche di valutazione che tengano conto della presenza e posizionamento e duplicazione e della correttezza inflessionale dei termini lessicali nella frase di output.", 'kk': 'Қағаз невралдық компьютердің аудармасында лексикалық шектеулерді морфологиялық бағатты тілде тәжірибелерді көрсетеді. Әрине біз шектелген декодтамасына негізделген әдісті таңдап, лексикалық жазулардың түрлерін өзгертіп, оқыту деректеріне не үлгі архитектурасына өзгерту керек емес. Өзінің эффективнігін бағалау үшін, екі түрлі сценариясында тәжірибелерді жасаймыз: жалпы және доменге арналған. Біз әдімімізді негізгі жолдың аудармасын және, мысалы, лексикалық шектері болмаса, аудармасының жылдамдығын және аудармасының сапасына салыстырып салыстырамыз Әдіс шектеулерді қанша жақсы шектеу үшін оқу үшін, жаңа оқу метрикаларын есептеп береміз. Бұл кезде шығыс сөзінде лексикалық терминдердің қайталау, қайталау, қайталау және қайталау және қайталау', 'lt': 'Dokumente pateikiami eksperimentai, susiję su nervinių mašin ų vertimu su leksiniais apribojimais į morfologiškai turtingą kalbą. In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture.  To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific.  Palyginame savo metodą su pradiniu vertimu, t. y. vertimu be leksinių apribojimų, vertimo greičio ir vertimo kokybės atžvilgiu. Siekiant įvertinti, kaip gerai metodas tvarko apribojimus, ir siūlome naujus vertinimo rodiklius, kuriuose būtų atsižvelgiama į egzistavimą ir įdiegimą bei dubliavimą bei įspūdinį lexinių terminų teisingumą išėjimo sakinyje.', 'ms': 'Kertas ini menghasilkan eksperimen dalam terjemahan mesin saraf dengan keterangan leksikal ke dalam bahasa yang kaya secara morfologik. Secara khususnya dan kami memperkenalkan kaedah dan berdasarkan penyahkodan terhalang dan yang mengendalikan bentuk-bentuk masukan leksikal yang disebabkan dan tidak memerlukan sebarang perubahan pada data latihan atau arkitektur model. Untuk menilai keefektivitasnya dan kita melakukan eksperimen dalam dua skenario yang berbeza: umum dan domain-spesifik. Kita membandingkan kaedah kita dengan terjemahan dasar dan iaitu terjemahan tanpa keterangan leksik dan dalam terma kelajuan terjemahan dan kualiti terjemahan. Untuk menilai betapa baik kaedah mengendalikan keterangan dan kami cadangkan metrik penilaian baru yang mempertimbangkan kehadiran dan kedudukan dan duplikasi dan ketepatan pendapatan terma leksikal dalam kalimat output.', 'ml': 'പേപ്പറിന്റെ പരീക്ഷണങ്ങള്\u200d ന്യൂറല്\u200d യന്ത്രത്തിന്റെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു. ലെക്സിക്കല്\u200d നിര്\u200dബന്ധങ്ങള്\u200d മൊര പ്രത്യേകിച്ചും നിര്\u200dബന്ധിതമായ കോഡിങ്ങിന്\u200dറെ അടിസ്ഥാനത്തും നാം ഒരു രീതിയില്\u200d പരിചയപ്പെടുത്തുന്നു. അത് ലെക്സിക്കല്\u200d ഇന്\u200dട്രികളുടെ മാറ്റം കൈകാര് അതിന്റെ പ്രവർത്തിയെ വിലാസപ്പെടുത്തുവാനും, രണ്ടു വ്യത്യസ്ത പരീക്ഷണങ്ങളില്\u200d നാം പരീക്ഷണങ്ങള്\u200d നടത്തുന്നതും, ജനറ നമ്മുടെ രീതിയെ ബെസ്ലൈനിലെ പരിഭാഷക്കുമായി തുല്യമാക്കുന്നു. അതായത് ലെക്സിക്കല്\u200d നിര്\u200dബന്ധങ്ങള്\u200d ഇല്ലാതെ പരിഭാഷപ് To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.', 'mk': 'Документот претставува експерименти во превод на невровни машини со лексички ограничувања во морфолошки богат јазик. Посебно и воведуваме метод и базиран на ограничено декодирање и кој ги управува привлечените форми на лексикални записи и не бара никаква модификација на податоците за обука или моделната архитектура. To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific.  Ние го споредуваме нашиот метод со основниот превод и, т.е. превод без лексични ограничувања и во поглед на брзината на преводот и квалитетот на преводот. За да процениме колку добро методот се справува со ограничувањата и предложуваме нови метрики за проценка кои го земаат предвид присуството и поставувањето и дупликацијата и инфекционалната коректност на лексикалните термини во излезната реченица.', 'mt': 'Id-dokument jippreżenta esperimenti fit-traduzzjoni tal-magni newrali b’restrizzjonijiet lexiċi f’lingwa morfoloġikament rikka. B’mod partikolari u nintroduċu metodu u bbażat fuq id-dekodifikazzjoni ristretta u li jimmaniġġja l-forom influwenti ta’ entrati lexiċi u ma jeħtieġ l-ebda modifika fid-dejta tat-taħriġ jew l-arkitettura mudell. To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific.  Aħna nqabblu l-metodu tagħna mat-traduzzjoni fil-linja bażi u jiġifieri t-traduzzjoni mingħajr restrizzjonijiet lexiċi u f’termini ta’ veloċità tat-traduzzjoni u kwalità tat-traduzzjoni. Biex jiġi evalwat kemm il-metodu jimmaniġġja tajjeb ir-restrizzjonijiet u nipproponu metriċi ġodda ta’ evalwazzjoni li jqisu l-preżenza u l-pożizzjoni u d-duplikazzjoni u l-korrettezza inflezzjonali tat-termini lexiċi fis-sentenza tal-ħruġ.', 'pl': 'W artykule przedstawiono eksperymenty neuronowego tłumaczenia maszynowego z ograniczeniami leksykalnymi na język bogaty morfologicznie. W szczególności wprowadzamy metodę opartą na dekodowaniu ograniczonym, która obsługuje przekształcone formy wpisów leksykalnych i nie wymaga modyfikacji danych treningowych czy architektury modelu. Aby ocenić jego skuteczność, przeprowadzamy eksperymenty w dwóch różnych scenariuszach: ogólnym i domenowym. Porównujemy naszą metodę z tłumaczeniem podstawowym, tj. tłumaczeniem bez ograniczeń leksykalnych oraz pod względem szybkości i jakości tłumaczenia. Aby ocenić, jak dobrze metoda radzi sobie z ograniczeniami, proponujemy nowe wskaźniki oceny, które uwzględniają obecność i umieszczenie oraz powielanie oraz poprawność flexikalną terminów w zdaniu wyjściowym.', 'mn': 'Энэ цаас сэтгэл хөдлөлийн мэдрэлийн машины хөгжлийн туршилтуудыг морфологийн баян хэл болгон харуулдаг. Ялангуяа, бид хязгаарлагдсан загвар дээр суурилуулсан аргыг танилцуулдаг. Энэ нь лексикийн нэвтрүүдийн нөлөөлдөг хэлбэрүүдийг удирддаг. Сургуулийн өгөгдлийг, загварын архитектурыг өөрчлөх шаардлагагүй. Үүний үр дүнг үнэлэхэд бид хоёр өөр хувилбарт туршилт хийдэг: ерөнхий болон тодорхой холбоотой. Бид өөрсдийгөө суурь шугам хөрөнгө оруулах, яг л хэлний хязгааргүйгээр, хөрөнгө оруулах хурдтай харьцуулж байна. Энэ арга нь хязгаарлалтыг хэрхэн сайн удирдах вэ гэдгийг тодорхойлдохын тулд бид шинэ дүгнэлтийн метрикийг санал болгож байна. Энэ нь үгнэлтийн үгнэлтийн байр суурилуулалт, хуваалцах, нөлөөлөлтийн зөв байдал юм.', 'no': 'Papiret viser eksperimenter i neuralmaskinsomsetjinga med leksiske begrensningar til ein morfologisk rikt språk. I særskilt, introduserer vi ein metode og basert på begrensede dekoding og som handterer dei influserte formane av leksiske oppføringar og treng ikkje nokon endring til opplæringsdata eller modellearkitekturen. For å evaluera effektiviteten og vi gjer eksperimenter i to ulike scenarior: general og domain-specific. Vi samanliknar metoden vårt med baselinjesomsetjing og omsetjing utan leksiske begrensningar og med omsetjingsfart og omsetjingskvalitet. For å evaluera kor godt metoden handterar begrensningane, og vi foreslår nye evalueringsmetrikar som tar inn i bruk tilstand og plassering og duplikasjon og effektiv rettighet på leksiske begrensningar i utsetninga.', 'sr': 'Papir predstavlja eksperimente u prevodu neuralne mašine sa leksičkim ograničenjima u morfološki bogat jezik. Posebno predstavljamo metodu i baziranu na ograničenom dekodiranju i koji se bavi utjecajnim oblicima leksičkih ulaska i ne zahteva nikakve modifikacije podataka obuke ili modelne arhitekture. Da bi procenili njegovu efikasnost i proveli smo eksperimente u dva različita scenarija: općenito i specifično domene. Upoređujemo našu metodu sa početnim prevodom i prevodom bez leksičkih ograničenja i u smislu brzine prevoda i kvalitete prevoda. Da bi procenili kako dobro metod vodi ograničenja i predlažemo nove procjene metrike koje uzimaju u obzir prisutnost i stavljanje i duplikaciju i uticajnu korekciju leksičkih termina u izlaznoj rečenici.', 'ro': 'Lucrarea prezintă experimente în traducerea automată neurală cu constrângeri lexicale într-un limbaj bogat din punct de vedere morfologic. În special, introducem o metodă bazată pe decodare constrânsă și care gestionează formele inflectate de intrări lexicale și nu necesită nicio modificare a datelor de instruire sau a arhitecturii modelului. Pentru a evalua eficiența acesteia și efectuăm experimente în două scenarii diferite: general și domeniu specific. Comparăm metoda noastră cu traducerea de bază și anume traducerea fără constrângeri lexicale și în ceea ce privește viteza traducerii și calitatea traducerii. Pentru a evalua cât de bine metoda gestionează constrângerile și propunem noi măsurători de evaluare care iau în considerare prezența și plasarea și duplicarea și corectitudinea inflexională a termenilor lexicali în propoziția de ieșire.', 'si': 'The papers presents examples in neural machine translation with lexic Restraints in a form rich language. විශේෂයෙන් අපි පද්ධතියක් පෙනුම් කරනවා ඒ වගේම ප්\u200dරශ්නයක් සිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද්ධ විසිද් අපි වෙනස් සිද්ධාවක් දෙකට පරීක්ෂණය කරනවා: සාමාන්\u200dය සහ ඩොමේන් විශේෂයි. අපි අපේ විධානය අධාර්\u200dය වාර්ථාව සහ භාවිතාව සඳහා භාවිතාව සඳහා භාවිතාවක් නැති විධානය සහ භාවිතාව ස විධානය කොච්චර හොඳ විදිහට ප්\u200dරතිචාර කරනවා කියලා අපි අළුත් විශ්ලේෂණ මෙට්\u200dරික්ස් ප්\u200dරතිචාර කරනවා කියලා බලන්න, ස්ථාපනය,', 'so': 'Qoraalka warqaddu wuxuu ku soo bandhigaa imtixaamo ku qoran turjumidda maskaxda ee neurada ah oo qasabka leksikada ah ku qoran luqada hodanka ah. Si gaar ah, waxaynu soo bandhignaynaa qaab, taas oo ku saabsan noocyada la xiriiray ee laga soo galo leksikal, mana baahna in loo beddelo macluumaadka waxbarashada ama dhismaha qaababka modellka. Si aan u qiimeyno effekteeda, waxaynu ku sameynaa imtixaamo labo cudur oo kala duduwan: guud iyo deegaan gaar ah. We compare our method with baseline translation and i.e. translation without lexical constraints and in terms of translation speed and translation quality.  Si aan u qiimeeyo sida aad u habboon u qabsato qasabka, waxaynu soo jeedaynaa qaababka cusub oo qiimeynaya, kuwaas oo ku xisaabta joogitaanka iyo meelaha la dhigo iyo dubaarka iyo hagaajinta xarunta leksiga.', 'sv': 'Studien presenterar experiment inom neural maskinöversättning med lexikala begränsningar till ett morfologiskt rikt språk. I synnerhet introducerar vi en metod baserad på begränsad avkodning och som hanterar böjda former av lexikala poster och inte kräver någon ändring av utbildningsdata eller modellarkitektur. För att utvärdera dess effektivitet och vi utför experiment i två olika scenarier: generellt och domänspecifikt. Vi jämför vår metod med grundläggande översättning och dvs översättning utan lexikala begränsningar och vad gäller översättningshastighet och översättningskvalitet. För att utvärdera hur väl metoden hanterar begränsningarna och vi föreslår nya utvärderingsmetoder som tar hänsyn till förekomst och placering och dubblering samt böjlig korrekthet av lexikala termer i utmatningssatsen.', 'ta': 'இந்த காகிதத்தில் புதிய கணினி மொழிபெயர்ப்பில் பரிசோதனைகளைக் காண்பிக்கிறது மோர்போலியலில் பணக்கூடிய மொழி குறிப்பிட்ட மற்றும் நாம் ஒரு முறையைக் குறிப்பிட்ட மற்றும் அடிப்படையில் கொண்டு வருகிறது மற்றும் அது பாதிக்கப்பட்ட முறைமைகளை கையாளும் மற்ற அதன் விளைவை மதிப்பிட வேண்டும் மற்றும் நாம் இரண்டு வித்தியாசமான காட்சிகளில் சோதனைகளை செய்ய வேண்டும்: பொத @ info வெளியீட்டு வாக்கியத்தில் இருக்கும் இடத்திலும் இருக்கும் மற்றும் இருமுறை மற்றும் பெருக்கல் திருத்தம் மற்றும் வெளியீட்டு வாக்கியத்தில் உள்', 'ur': 'The paper presents experiments in neural machine translation with lexical constraints into a morphology rich language. مخصوصاً ہم ایک طریقہ معرفی کرتے ہیں اور محدودہ ڈیکوڈینگ پر بنیاد رکھتے ہیں اور جو لکسیکل آنٹروں کی تاثیر کے فرموں کو ادارہ کرتا ہے اور تدریس ڈیٹا یا مدل معماری کے لئے کوئی بدلنے کی ضرورت نہیں ہے۔ اس کے فعالیت کا ارزش کرنا اور ہم دو مختلف سناریوں میں آزمائش کریں: عمومی اور ڈومین خاص. ہم اپنے طریقے کو بنیاس لین ترجمہ اور یعنی ترجمہ کے بغیر لکسیکل محدودیت اور ترجمہ गत اور ترجمہ کیفیت کے مطابق مقایسہ کرتے ہیں. یہ طریقہ کس طرح محدودیت کو اچھی طریقہ کے مطابق تحقیق کرتا ہے اور ہم نے نو تحقیق میٹریک کی پیشنهاد کرتا ہے جس کے ذریعہ اور موقعیت اور دوپیٹ کرنا اور آئوٹ جماعت میں لکسیکل کی اصلاح کے مطابق اضافہ کرتا ہے۔', 'uz': "Qogʻoz qogʻoz murakkablarini morfologik taxminan tilga tarjima qiladi. Shunday qilib, biz cheksiz kodlash usulini ko'rsatumiz va bu leksikal yozuvlarini boshqarish mumkin va taʼminlovchi maʼlumot yoki model arxituvchiga o'zgarishni kerak emas. Ularning effektini qiymatlashga va biz ikki boshqa bir scenarida jarayonlarni bajaramiz: umumiy va domen muhit. @ info: whatsthis Bu usulni qanday yaxshi qo'llashni qiymatish uchun yangi qiymatlar metriklarini qiymatlashni istaysizmi va natijada leksikal so'zlarining mavjud, joylashishini va ikkinchi marta bog'lash va cheksizlik imkoniyatini tasavvur qilishini istaysizmi.", 'vi': 'Tờ giấy này đưa ra các thí nghiệm trong phiên dịch máy thần kinh với giới hạn từ học thành ngôn ngữ có độ phong phú. Chúng tôi đưa ra một phương pháp dựa trên việc giải mã bị hạn chế và xử lý các dạng chữ viết ngẫu hứng và không cần thay đổi dữ liệu đào tạo hay kiến trúc mẫu. Để đánh giá hiệu quả của nó và chúng tôi thực hiện thí nghiệm trong hai tình huống khác nhau: chung và miền-đặc biệt. Chúng tôi so sánh phương pháp của chúng tôi với dịch thuật cơ bản và đó là dịch thuật không có hạn chế ngôn ngữ và chất lượng dịch chuyển. Để đánh giá phương pháp xử lý các ràng buộc tốt thế nào và chúng tôi đề xuất các con số đánh giá mới, để cân nhắc sự hiện diện, vị trí và việc lặp lại và tính toán đúng ngôn ngữ từ ngữ trong câu đầu ra.', 'hr': 'Papir predstavlja eksperimente u prevodu neuralnih strojeva sa leksičkim ograničenjima u morfološki bogat jezik. Posebno predstavljamo metodu i temeljito na ograničenoj dekodiranju i koji se bavi utjecajnim oblicima leksičkih ulaska i ne zahtijeva nikakve modifikacije podataka o obuci ili modelnoj arhitekturi. Da bi procijenili njegovu učinkovitost i provodili smo eksperimente u dva različita scenarija: općenito i specifično domene. Upoređujemo našu metodu s početnim prevodom i tj. prevodom bez leksičkih ograničenja i s obzirom na brzinu prevoda i kvalitetu prevoda. Da bi procijenili kako dobro metod rješava ograničenja i predlažemo nove procjene metrike koje uzimaju u obzir prisutnost i stavljanje i duplikacija i učinkovito ispravnost leksičkih termina u izlaznoj rečenici.', 'bg': 'Статията представя експерименти в невронния машинен превод с лексикални ограничения на морфологично богат език. По-специално въвеждаме метод, базиран на ограничено декодиране и който обработва наклонените форми на лексикални записи и не изисква промяна в данните за обучение или архитектурата на модела. За да оценим ефективността му, провеждаме експерименти в два различни сценария: общ и специфичен за областта. Сравняваме метода си с базовия превод и т.е. превод без лексикални ограничения и по отношение на скоростта на превода и качеството на превода. За да се оцени колко добре методът се справя с ограниченията и предлагаме нови измервателни показатели, които отчитат наличието и разположението и дублирането и коректността на лексикалните термини в изходното изречение.', 'da': 'Artiklen præsenterer eksperimenter i neural maskinoversættelse med leksikologiske begrænsninger til et morfologisk rigt sprog. Især introducerer vi en metode baseret på begrænset afkodning, som håndterer de bøjede former for leksikalske poster og ikke kræver nogen ændring af træningsdata eller modelarkitektur. For at vurdere dens effektivitet, og vi udfører eksperimenter i to forskellige scenarier: generel og domænespecifik. Vi sammenligner vores metode med basisoversættelse og dvs. oversættelse uden leksikologiske begrænsninger og med hensyn til oversættelseshastighed og oversættelseskvalitet. For at vurdere, hvor godt metoden håndterer begrænsningerne, og vi foreslår nye evalueringsmetrics, der tager hensyn til tilstedeværelse og placering og duplikation og bøjningsrigtighed af lexikale termer i outputsætningen.', 'de': 'Der Beitrag stellt Experimente zur neuronalen maschinellen Übersetzung mit lexikalischen Einschränkungen in eine morphologisch reiche Sprache vor. Insbesondere führen wir eine Methode ein, die auf eingeschränkter Dekodierung basiert und die die gebeugten Formen lexikalischer Einträge handhabt und keine Modifikationen der Trainingsdaten oder Modellarchitektur erfordert. Um seine Wirksamkeit zu bewerten, führen wir Experimente in zwei verschiedenen Szenarien durch: allgemein und domänenspezifisch. Wir vergleichen unsere Methode mit der Basisübersetzung und d.h. Übersetzung ohne lexikalische Einschränkungen und hinsichtlich Übersetzungsgeschwindigkeit und Übersetzungsqualität. Um zu beurteilen, wie gut die Methode mit den Einschränkungen umgeht, schlagen wir neue Bewertungsmetriken vor, die das Vorhandensein und die Platzierung sowie die Duplikation und Flexionskorrektheit von lexikalischen Begriffen im Ausgabesatz berücksichtigen.', 'ko': '본고는 어휘적 제약을 가진 신경기계를 형태가 풍부한 언어로 번역하는 실험을 소개한다.특히 우리는 제약 디코딩을 바탕으로 하는 방법과 이 방법은 단어의 굴절 형식을 처리하고 훈련 데이터나 모델 구조에 대해 어떠한 수정도 할 필요가 없다.그것의 유효성을 평가하기 위해 우리는 두 가지 다른 장면에서 유니버설과 특정 분야를 실험했다.우리는 우리의 방법과 기본 번역과 어휘 제한이 없는 번역을 비교하고 번역 속도와 번역의 질에 대해 비교했다.이 방법의 제약 처리 능력을 평가하기 위해 우리는 새로운 평가 지표를 제시했는데 그 중에서 출력 문장에 있는 어휘의 존재, 위치, 중복과 굴절의 정확성을 고려했다.', 'fa': 'این کاغذ آزمایشات در ترجمه ماشین عصبی با محدودیت زبانی به زبان مورفولوژیک ثروتمند را نشان می دهد. به خصوص، ما یک روش را معرفی می کنیم و بر اساس دکوندن محدودیت، و آن فرم\u200cهای تاثیر\u200cگیری از ورودهای زبانی را تحت نظر می\u200cگیرد و هیچ تغییری برای داده\u200cهای آموزش یا معماری مدل نیاز ندارد. برای ارزیابی فعالیت آن و ما آزمایش\u200cها را در دو سناریو متفاوت انجام می\u200cدهیم: عمومی و ویژه\u200cای. ما روش خودمان را با ترجمه\u200cهای پایین خط مقایسه می\u200cکنیم، یعنی ترجمه بدون محدودیت\u200cهای زبانی و به عنوان سرعت ترجمه و کیفیت ترجمه. برای ارزیابی که این روش چقدر خوب با محدودیت کنترل می\u200cشود و ما پیشنهاد می\u200cکنیم متریک ارزیابی جدید که با وجود وجود و وضعیت و دوباره\u200cسازی و درستی\u200cهای زبان\u200cشناسی در جمله\u200cی خروج به حساب می\u200cگیرند.', 'sw': 'Gazeti hilo linaonyesha majaribio katika tafsiri ya mashine ya ubongo yenye vizuizi vya lexico katika lugha yenye utajiri wa kimaadilojia. In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture.  Kupitia ufanisi wake na tunafanya majaribio katika mitazamo miwili tofauti: jumla na mahsusi ya ndani. Tunafananisha njia yetu na tafsiri ya msingi na yaani tafsiri bila vikwazo vya lexico na kwa mujibu wa kiwango cha tafsiri na kiwango cha kutafsiri. Ili kutathmini namna mbinu hiyo inavyodhibiti vikwazo na tunapendekeza mbinu mpya za uchunguzi ambazo zinazingatia uwepo na kuweka pamoja na upatikanaji na uhakika wa maneno ya lexico katika hukumu ya utoaji.', 'nl': "Het artikel presenteert experimenten in neurale machinevertaling met lexicale beperkingen in een morfologisch rijke taal. In het bijzonder introduceren we een methode die gebaseerd is op beperkte decodering en die de geïnfecteerde vormen van lexicale vermeldingen behandelt en geen aanpassing van de trainingsgegevens of modelarchitectuur vereist. Om de effectiviteit ervan te evalueren voeren we experimenten uit in twee verschillende scenario's: algemeen en domein-specifiek. We vergelijken onze methode met baseline vertaling en dat wil zeggen vertaling zonder lexicale beperkingen en qua vertaalsnelheid en vertaalkwaliteit. Om te evalueren hoe goed de methode omgaat met de beperkingen en we stellen nieuwe evaluatiestatistieken voor die rekening houden met de aanwezigheid en plaatsing en duplicatie en flexionele correctheid van lexicale termen in de uitvoerzin.", 'af': "Name In spesifieke en ons introduseer 'n metode en gebaseer op beheinde dekodering en wat die inflekke vorms van leksiese inskrywings hanteer en nie nodig enige veranderinge aan die onderwerp data of model architecture nie. Om sy effektiviteit te evalueer en ons eksperimente in twee verskillende scenarios uitvoer: algemeen en domein-spesifieke. Ons vergelyk ons metode met basisline vertaling en bv. vertaling sonder leksiese beheinings en terwyl vertaling spoed en vertaling kwaliteit. Om te evalueer hoe goed die metode die beheinings hanteer en ons voorstel nuwe evaluasie metries wat die voorsiening en plaatsing en duplikasie en infleksionele regverdigheid van leksiese terme in die uitset seting in rekening neem.", 'tr': 'Bu kagyz neural maşynyň terjimesinde leksiýaly çykyşlar bilen morpholojik baý dile üýtgedýär. We esasy görä biz çykarylyş kodlemegine dayanan we çykarylyş taýýarlanan bir yöntem tanyşdyrýarys we bu läsiýetli girişlerin etkinleýän şekilleri çykarýar we okuwçy maglumaty ýa-da nusgaty arhitekturyna hiç hili üýtgetme Etkinliğini değerlendirmek üçin we iki farklı senaryoda deneyler çözeriz: umumy we domena hökmünde. Biz öz taryhymyzy baseline terjime bilen we mysal terjime edilýän çykyşymyz we terjime edilýän çykyşymyz bilen görýäris. Çarpçylyklaryň nähili gowy çykandygyny çözmek üçin we çykyş sözlerinde, ýerleşdirmek we ýerleşdirmek üçin täze deňlenme metriklerini maslahat berýäris.', 'am': 'የፕሬዝዳንቱ ፈተና በናውሬል መሣሪያን ትርጓሜ ላይ በሌክሲካዊ ግንኙነት በሞሮፎሎጂ ባለጠጋ ቋንቋ ውስጥ ያቀርባል፡፡ በተለይም እና የተከለከለውን የክፍል እና የሌክሲካዊ ግንኙነትን የሚቆጥረን እና ለትምህርት ዳታ ወይም የሞዴል መሠረት ማሻሻሻል አያስፈልግም፡፡ ፍጥረቱን ለማስተካከል እና በተለየ ሁለት ዓይነቶች ውስጥ ፈተናዎችን እናደርጋለን፡፡ ጥያቄያችንን በመስመር ላይ እናስተያየዋለን፡፡ የሥርዓት ግንኙነትን እንዴት ያህል እንዲቆርጥ እና ውጤቱን እና ቦታዎችን እና ቁስል እና የሌክሲካዊ ግንኙነትን ማቀናቀል እና አዲስ ማስታወቂያውን ማሰናከል እና አዲስ ማስታወቂያ ማድረጊያውን እና ማሰናከል፡፡', 'id': 'The paper presents experiments in neural machine translation with lexical constraints into a morphologically rich language.  Terutama dan kami memperkenalkan sebuah metode dan berdasarkan dekoding terbatas dan yang menangani bentuk-bentuk yang disebabkan dari masukan leksik dan tidak membutuhkan modifikasi apapun pada data latihan atau arsitektur model. Untuk mengevaluasi efektivitasnya dan kami melakukan eksperimen dalam dua skenario yang berbeda: umum dan domain-spesifik. Kami membandingkan metode kami dengan tradukti dasar dan i.e. tradukti tanpa batasan leksik dan dalam terma kecepatan tradukti dan kualitas tradukti. Untuk mengevaluasi betapa baik metode menangani batasan dan kami mengusulkan metrik evaluasi baru yang mempertimbangkan kehadiran dan menempatkan dan duplikasi dan ketepatan infleksional dari istilah leksik dalam kalimat keluaran.', 'bn': 'এই পত্রিকাটি নিউরুল মেশিন অনুবাদে পরীক্ষার পরীক্ষা উপস্থাপন করেছে যেখানে লেক্সিক্যাল নিয়ন্ত্রণের সাথে মানু বিশেষ করে আমরা একটি পদ্ধতি চিহ্নিত করি এবং নিষিদ্ধ কোডিং ভিত্তিতে ভিত্তিক এবং যা লেক্সিক্যাল এন্ট্রির প্রভাবিত ফার্মগুলো নিয়ন্ত্রণ করে এবং প্রশিক এর কার্যকর্ষতা মূল্য করার জন্য এবং আমরা দুই ভিন্ন দৃশ্যে পরীক্ষা করি: জেনারেল এবং ডোমেইন নির্দিষ্ট পরীক্ষা। আমরা আমাদের পদ্ধতিকে বেস্লাইন অনুবাদের সাথে তুলনা করি এবং যেমন লেক্সিক্যাল বৈধ ছাড়া অনুবাদ এবং অনুবাদের গতি এবং অনুবাদের ম মূল্যায়ন করার জন্য এই পদ্ধতি কতটা ভালোভাবে নিয়ন্ত্রণ করে এবং আমরা নতুন মূল্যবোধ মেটিক প্রস্তাব করি যা আউটপুটের শাস্তির উপস্থিতি এবং অবস্থান এবং দুই বার্তা', 'sq': 'Gazeta paraqet eksperimente në përkthimin nervor të makinave me kufizime lexike në një gjuhë morfologjikisht të pasur. In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture.  Për të vlerësuar efektshmërinë e saj dhe ne kryejmë eksperimente në dy skenarë të ndryshme: gjenerale dhe specifike në domeni. Ne krahasojmë metodën tonë me përkthimin bazë dhe përkthimin pa kufizime lexike dhe në terma të shpejtësisë së përkthimit dhe cilësisë së përkthimit. Për të vlerësuar se sa mirë metoda trajton kufizimet dhe ne propozojmë metrika të reja vlerësimi që marrin parasysh praninë dhe vendosjen dhe dyfishimin dhe korrektësinë e paraqitjeve lexike në fjalimin e daljes.', 'az': 'Kağıt nöral maşına çevirilməsindəki təcrübələrdə leksik müəyyənləşdirilmələri morfolojik zəngin dilə göstərir. Özellikle də biz müəyyən edilmiş dekodinə dayanan bir metod tanıyırıq və bu, təhsil verilənlərin və modellərin dəyişikliklərinə istifadə edir. Onun etkinliğini değerləşdirmək üçün və iki müxtəlif senaryoya təcrübə edirik: genel və domain-specific. Biz metodlarımızı, həmçin in dəyişiklik dəyişiklikləri olmadan, tercümə sürəti və tercümə kaliteti ilə qarşılaşdırırıq. Metodan çətinlikləri necə yaxşı idarə edəcəyini təmin etmək üçün yeni değerlendirmə metriklərini təbliğ edirik ki, çətinliklərin məlumatı, yerinə qoyulması, duplikasyonu və təsirli tərzlərin istifadə edilməsini gözləyir.', 'bs': 'Papir predstavlja eksperimente u prevodu neuralne mašine sa leksičkim ograničenjima u morfološki bogat jezik. Posebno predstavljamo metodu i temeljito na ograničenom dekodiranju i koji se bavi utjecenim oblicima leksičkih ulaska i ne zahtijeva nikakve modifikacije podataka obuke ili modelne arhitekture. Da bi procenili njegovu učinkovitost i proveli smo eksperimente u dva različita scenarija: općenito i specifično domene. Upoređujemo našu metodu sa početnim prevodom i prevodom bez leksičkih ograničenja i u smislu brzine prevoda i kvalitete prevoda. Da bi procenili kako dobro metod vodi ograničenja i predlažemo nove procjene metrike koje uzimaju u obzir prisutnost i stavljanje i duplikacija i uticajnu ispravnost leksičkih termina u izlaznoj rečenici.', 'cs': 'Příspěvek prezentuje experimenty v neuronovém strojovém překladu s lexikálními omezeními do morfologicky bohatého jazyka. Zejména představujeme metodu založenou na omezeném dekódování, která zpracovává zkřivené formy lexikálních záznamů a nevyžaduje žádnou úpravu tréninkových dat či modelové architektury. Pro zhodnocení jeho účinnosti provádíme experimenty ve dvou různých scénářích: obecných a doménově specifických. Naši metodu porovnáváme s překladem základního překladu a tedy s překladem bez lexikálních omezení a z hlediska rychlosti překladu a kvality překladu. Pro zhodnocení toho, jak dobře metoda zvládá omezení, navrhujeme nové hodnotící metriky, které zohlední přítomnost a umístění a duplikaci a flexiální správnost lexikálních termínů ve výstupní větě.', 'et': 'Töös tutvustatakse eksperimente neuromasintõlkes leksikaalsete piirangutega morfoloogiliselt rikkasse keelde. Eelkõige tutvustame piiratud dekodeerimisel põhinevat meetodit, mis käsitleb leksikaalsete kirjete paindlikke vorme ning ei nõua koolitusandmete ega mudeli arhitektuuri muutmist. Selle efektiivsuse hindamiseks teostame katseid kahes erinevas stsenaariumis: üldises ja valdkonnaspetsiifilises. Me võrdleme oma meetodit algtõlkega ehk leksikaalsete piiranguteta tõlkega ning tõlkekiiruse ja tõlkekvaliteedi poolest. Hindamaks, kui hästi meetod piiranguid käsitleb, pakume välja uued hindamismeetodid, mis võtavad arvesse leksikaalsete terminite olemasolu ja paigutust ning dubleerimist ning paindlikkust väljundlauses.', 'fi': 'Työssä esitellään kokeita neurokonekäännöksessä leksikaalisilla rajoituksilla morfologisesti rikkaaseen kieleen. Erityisesti otamme käyttöön rajoitettuun dekoodaamiseen perustuvan menetelmän, joka käsittelee sanastomerkintöjen taivutettuja muotoja eikä vaadi muutoksia koulutusdataan tai malliarkkitehtuuriin. Arvioidaksemme sen tehokkuutta teemme kokeiluja kahdessa eri skenaariossa: yleisessä ja toimialoittaisessa. Vertaamme menetelmäämme peruskäännökseen eli käännökseen ilman sanastorajoituksia sekä käännösnopeuden ja käännöksen laadun suhteen. Arvioidaksemme kuinka hyvin menetelmä käsittelee rajoitteet ja ehdotamme uusia arviointimittareita, jotka ottavat huomioon sanastotermien läsnäolon ja sijoittelun sekä päällekkäisyyden ja taivutuskorjallisuuden tuloslauseessa.', 'ca': "El paper presenta experiments en traducció neural de màquines amb restriccions lècsiques a un llenguatge morfològicament ric. En particular i introduïm un mètode basat en una descodificació restringida i que maneja les formes influïdes d'entrades lècsiques i no necessita cap modificació a les dades d'entrenament o arquitectura model. To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific.  Comparem el nostre mètode amb la traducció basal, és a dir, la traducció sense restriccions lècsiques i en termes de velocitat de traducció i qualitat de traducció. Per avaluar com de bé el mètode gestiona les restriccions i proposem nous mètrics d'avaluació que tenen en compte la presença, el lloc, la duplicació i la correctesa inflexional dels termes lèxics en la frase de sortida.", 'hy': "Այս թղթին ներկայացնում է նյարդային մեքենայի թարգմանման փորձեր, որոնք ունեն լեքսիկական սահմանափակումներ մորֆոլոգիապես հարուստ լեզու: Հատկապես, մենք ներկայացնում ենք մի մեթոդ, որը հիմնված է սահմանափակ կոդավորման վրա և որը վերահսկում է լեքսիկական գրքերի առաջացած ձևերը և չի պահանջում որևէ փոփոխություն կրթության տվյալների կամ մոդելի ճարտարապետության համար: Որպեսզի գնահատենք դրա արդյունավետությունը, մենք կատարում ենք փորձեր երկու տարբեր սցենարներում' ընդհանուր և բնագավառի մասնավոր: Մենք համեմատում ենք մեր մեթոդը հիմնական թարգմանության հետ, այսինքն թարգմանության առանց լեքսիկական սահմանափակումների, թարգմանության արագության և թարգմանության որակի առումով: To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.", 'jv': 'Laptop" and "Desktop Slackfree To assess their effectness and we take out pilings in 2 new sc챕nares: General and domain-special. Tulung Ngawe Perintah dh챕w챕 kuwi nggawe Perintah dh챕w챕 bakal ngewehke gerakan nguasai winih dh챕w챕, ng챕w챕 kuwi nggawe Kemerdekaan sistem sing gawe n챗m챗n, terusahaan karo ng챕w챕, duplikasi lan akeh langgar-langgar aturan luwih langgar-langgar kuwi ng챕w챕.', 'sk': 'V prispevku so predstavljeni eksperimenti nevronskega strojnega prevajanja z leksikalnimi omejitvami v morfološko bogat jezik. Predvsem uvajamo metodo, ki temelji na omejenem dekodiranju in obravnava upognjene oblike leksikalnih vnosov in ne zahteva nobene spremembe podatkov o usposabljanju ali arhitekture modela. Za oceno njegove učinkovitosti izvajamo eksperimente v dveh različnih scenarijih: splošnem in domenskem specifičnem. Našo metodo primerjamo z osnovnim prevajanjem, tj. prevajanjem brez leksikalnih omejitev in glede na hitrost prevajanja in kakovost prevajanja. Da bi ocenili, kako dobro metoda obravnava omejitve, predlagamo nove ocenjevalne meritve, ki upoštevajo prisotnost in postavitev ter podvajanje ter inflekcijsko korektnost leksikalnih izrazov v izhodnem stavku.', 'ha': "Kanarin na bãyar da jarrabo cikin translation of neural mashine with lex-ƙudures to a morfologically rich language. Yana da amfani da shi, kuma ko da yake a kan kodi da aka ƙunsa da shi, kuma wanda ke yi amfani da tsari na shiga cikin mazaɓa na leksisi kuma ba ya buƙata wani gyare zuwa matsayin tsarin da aka tsare data ko misalin ayuka. Ga ka ƙaddara aikinta kuma mu sami jarrabi cikin sauti biyu dabam-dabam: General and Domen-Specific. @ info: whatsthis To, dõmin ka ƙaddara yadda alheri metric za'a yi amfani da kanuni kuma mu buƙata misalin juyi-metric da za'a yi amfani da shi a cikin cewa na fitarwa.", 'he': 'The paper presents experiments in neural machine translation with lexical constraints into a morphologically rich language.  במיוחד ואנחנו מציגים שיטה ומבוססת על פיקוד מוגבל ומטפל בצורות השופעות של הכניסות הלקסיות ולא דורש שינוי למידע האימונים או ארכיטקטורה דוגמנית. To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific.  אנחנו משווה את השיטה שלנו עם התרגום הבסיסי, כלומר התרגום ללא מגבלות לקסיות ובנושא מהירות התרגום ואיכות התרגום. כדי להעריך עד כמה השיטה מתמודדת היטב עם ההגבלות ואנחנו מציעים מטריות עריכה חדשות אשר לוקחות בחשבון את הנוכחות והעמדה והכפילות והתקנות הפליקסית של התנאים הלקסיים במשפט ההוצאה.', 'bo': 'ཤོག་བུ་དེ་ནི་སྒེར་གྱི་རྩིས་འཁོར་གྱི་སྐད་ཡིག་ཆའི་ནང་དུ་བརྟག་ཞིབ་བྱེད་དུ་འཇུག་སྲིད། In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture. To evaluate its effectiveness and we carry out experiments in two different scenarios: general and domain-specific. We compare our method with baseline translation and i.e. translation without lexical constraints and in terms of translation speed and translation quality. To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.'}
