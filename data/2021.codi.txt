{'en': 'Developing Conversational Data and Detection of Conversational Humor in ', 'es': 'Desarrollo de datos conversacionales y detección del humor conversacional en telugu', 'pt': 'Desenvolvendo Dados Conversacionais e Detecção de Humor Conversacional em Telugu', 'ja': 'テルグ語での会話データの開発と会話ユーモアの検出', 'ar': 'تطوير بيانات المحادثة والكشف عن الفكاهة التخاطبية في التيلجو', 'fr': "Développement de données conversationnelles et détection de l'humour conversationnel en télougou", 'zh': '发泰卢固语语数与会话默检', 'ru': 'Развитие разговорных данных и обнаружение разговорного юмора в Телугу', 'hi': 'तेलुगु में संवादात्मक डेटा और संवादी हास्य का पता लगाना विकसित करना', 'ga': 'Sonraí Comhrá a Fhorbairt agus Humor Comhráite a Bhrath i Teileagúis', 'hu': 'Beszélgetési adatok fejlesztése és a beszélgetési humor felismerése Telugu', 'el': 'Ανάπτυξη δεδομένων συνομιλίας και ανίχνευση του χιούμορ συνομιλίας στο Τελούγκου', 'ka': 'ტელუგუში კონტაქციონალური მონაცემები და კონტაქციონალური ჰუმორის განვითარება', 'it': "Sviluppo di dati di conversazione e rilevamento dell'umorismo di conversazione in Telugu", 'kk': 'Телугудағы қатынау мәліметін жасау және қатынау мәліметін табу', 'mk': 'Developing Conversational Data and Detection of Conversational Humor in Telugu', 'ml': 'ടെലുഗ്വിലെ സംസാരിക്കുന്നതിനുള്ള വിവരങ്ങളും ഡേറ്റാവും പരിചയപ്പെടുത്തുന്നു', 'mn': 'Телугу-д ярилцлагын өгөгдлийн болон ярилцлагын хүмүүсийн мэдээллийг хөгжүүлэх', 'lt': 'Konversinių duomenų kūrimas ir konversinio humoro aptikimas Telugėje', 'no': 'Utviklar samtaledata og oppdaging av samtaleHumor i Telugu', 'ms': 'Membangun Data Perbualan dan Pengesanan Humor Perbualan di Telugu', 'pl': 'Rozwój danych konwersacyjnych i wykrywanie humoru konwersacyjnego w Telugu', 'ro': 'Dezvoltarea datelor conversaționale și detectarea umorului conversațional în Telugu', 'mt': 'Żvilupp ta’ Dejta Konversazzjonali u Sejbien ta’ Humor Konversazzjonali f’Telugwu', 'sr': 'Razvoj razgovornih podataka i otkrivanje razgovornog Humora u Telugu', 'si': 'තෙලුගුවයේ කතාවාසික දත්ත සහ කතාවාසික හුමෝර් හොයාගන්න', 'so': 'Developing data conversational and detection of conversational Humor in Telugu', 'sv': 'Utveckling av konversationsdata och upptäckt av konversationshumor i Telugu', 'ta': 'Name', 'ur': 'ٹیلوگو میں مکالمانی ہمور کا ڈیٹا اور پیدا کرنا', 'uz': 'Name', 'vi': 'Phát triển dữ liệu đối thoại và phát hiện giọng nói', 'bg': 'Разработване на разговорни данни и откриване на разговорния хумор в Телугу', 'nl': 'Ontwikkeling van Conversational Data en Detectie van Conversational Humor in Telugu', 'hr': 'Razvoj razgovornih podataka i otkrivanje razgovornog Humora u Telugu', 'de': 'Entwicklung von Konversationsdaten und Erkennung von Konversationshumor in Telugu', 'id': 'Mengembangkan Data Percakapan dan Deteksi Humor Percakapan di Telugu', 'sw': 'Kuendeleza Takwimu za mazungumzo na Kugundua Binadamu wa mazungumzo nchini Telugu', 'ko': '테루고어에서 회화 데이터 개발과 회화 유머 탐지', 'da': 'Udvikling af samtaledata og detektering af samtalehumor i Telugu', 'fa': 'توسعه داده های مکالمه و کشف خطر مکالمه در تلوگو', 'tr': 'Qonuşma Maglumaty we Maglumaty Ýüklemek', 'hy': 'Խոսակցության տվյալների զարգացումը և Խոսակցության հոմորի հայտնաբերումը Թելուգույում', 'az': "Telugu'da QonuŇüma M…ôlumatńĪ v…ô QonuŇüma Humor'un keŇüfetm…ôsi", 'af': 'Ontwikkeling van Gespraakte Data en Opdekking van Gespraakte Humor in Telugu', 'bn': 'Developing Conversational Data and Detection of Conversational Humor in Telugu', 'am': 'አቀማመጥ', 'sq': 'Zhvillimi i të dhënave konversacionale dhe zbulimi i humorit konversacional në Telugu', 'cs': 'Vývoj konverzačních dat a detekce konverzačního humoru v Telugu', 'et': 'Vestlusandmete arendamine ja vestlushuumori tuvastamine Telugus', 'bs': 'Razvoj razgovornih podataka i otkrivanje razgovornog Humora u Telugu', 'fi': 'Keskustelutietojen kehittäminen ja keskusteluhuumorin havaitseminen Telugussa', 'ca': 'Desenvoltar dades conversacionals i detectar humor conversacional a Telugu', 'jv': 'Ngubah Daftar Konversihaan lan detection of conversations Heror in telu', 'sk': 'Razvoj pogovornih podatkov in odkrivanje pogovornega humorja v Teluguju', 'ha': 'KCharselect unicode block name', 'bo': 'རྒྱལ་སྤྲོད་ཀྱི་གཏམ་གླེང་ཆེན་གཉིས་ཀྱི་ཆ་འཕྲིན་དང་བསམ་བློ་གཏོང་གི་ཆ་འཕྲིན་ལ།', 'he': 'פיתוח נתונים משיחתיים וגילוי ההומור השיחתי בטלוגו'}
{'en': 'In the field of humor research, there has been a recent surge of interest in the sub-domain of Conversational Humor (CH). This study has two main objectives. (a) develop a conversational (humorous and non-humorous) dataset in ', 'ar': 'في مجال أبحاث الفكاهة ، كان هناك زيادة في الاهتمام مؤخرًا في المجال الفرعي لفكاهة المحادثة (CH). هذه الدراسة لها هدفان رئيسيان. (أ) تطوير مجموعة بيانات محادثة (روح الدعابة وغير روح الدعابة) في التيلجو. (ب) اكتشاف الميثان في مجموعة البيانات المجمعة. في هذه الورقة ، تم توضيح التحديات التي تمت مواجهتها أثناء جمع البيانات والتجارب التي تم إجراؤها. يتم تنفيذ تقنيات التعلم الانتقالي والتعلم غير التحويلي من خلال استخدام النماذج المدربة مسبقًا مثل دمج كلمات FastText ونماذج لغة BERT و Text GCN ، والتي تتعلم كلمة وتوثيق حفلات الزفاف في وقت واحد للمجموعة المعطاة. تمت ملاحظة أحدث النتائج بدقة 99.3٪ و 98.5٪ f1 نتيجة BERT.', 'ja': 'ユーモア研究の分野では、最近、会話型ユーモア（ CH ）のサブドメインへの関心が高まっています。この研究には、2つの主な目的があります。(a) Teluguで会話的（ユーモラスで非ユーモラスな）データセットを開発します。(b)コンパイルされたデータセットでCHを検出します。本稿では，データ収集と実験を行いながら直面する課題を解明した。転送学習と非転送学習技術は、FastTextワード埋め込み、BERT言語モデル、およびテキストGCNなどの事前にトレーニングされたモデルを利用して実装され、与えられたコーパスのワードとドキュメント埋め込みを同時に学習します。最先端の結果は、BERTによって達成された99.3%の精度および98.5%のf 1スコアで観察される。', 'pt': 'No campo da pesquisa do humor, houve um recente aumento de interesse no subdomínio do Humor Conversacional (CH). Este estudo tem dois objetivos principais. (a) desenvolver um conjunto de dados de conversação (com e sem humor) em Telugu. (b) detectar CH no conjunto de dados compilado. Neste artigo, são elucidados os desafios enfrentados durante a coleta dos dados e os experimentos realizados. As técnicas de aprendizagem por transferência e aprendizagem sem transferência são implementadas utilizando modelos pré-treinados, como incorporação de palavras FastText, modelos de linguagem BERT e GCN de texto, que aprende a incorporação de palavras e documentos simultaneamente do corpus fornecido. Resultados de última geração são observados com uma precisão de 99,3% e uma pontuação f1 de 98,5% alcançada pelo BERT.', 'es': 'En el campo de la investigación del humor, ha habido un reciente aumento de interés en el subdominio del humor conversacional (CH). Este estudio tiene dos objetivos principales. (a) desarrollar un conjunto de datos conversacional (humorístico y no humorístico) en telugu. (b) detectar CH en el conjunto de datos compilado. En este artículo, se aclaran los desafíos a los que se enfrentan al recopilar los datos y los experimentos realizados. Las técnicas de aprendizaje por transferencia y aprendizaje sin transferencia se implementan mediante el uso de modelos previamente entrenados, como incrustaciones de palabras FastText, modelos de lenguaje BERT y Text GCN, que aprenden las incrustaciones de palabras y documentos simultáneamente del corpus dado. Los resultados más avanzados se observan con una precisión del 99,3% y una puntuación f1 del 98,5% alcanzada por BERT.', 'zh': '幽人对幽(CH)子领激增。 此论有二要。 (a)于泰卢固语中开一对语(幽默与非幽默)数据集。 (b) 于编译数集检测 CH。 本文,明聚数实验所临挑战。 迁学、非迁学,因豫练以成之,如FastText词嵌,BERT言语、文本GCN,兼学给定语料库单词、文档嵌之。 BERT 以 99.3% 之准确率, 98.5% 之 f1 ,察其最先进也。', 'fr': "Dans le domaine de la recherche sur l'humour, il y a eu récemment un regain d'intérêt pour le sous-domaine de l'humour conversationnel (CH). Cette étude poursuit deux objectifs principaux. (a) développer un ensemble de données conversationnelles (humoristiques et non humoristiques) en télougou. (b) détecter le CH dans l'ensemble de données compilé. Dans cet article, les défis rencontrés lors de la collecte des données et des expériences réalisées sont élucidés. Les techniques d'apprentissage par transfert et d'apprentissage sans transfert sont mises en œuvre en utilisant des modèles pré-entraînés tels que les intégrations de mots FastText, les modèles de langage BERT et Text GCN, qui apprend le mot et les intégrations de documents simultanément du corpus donné. Des résultats de pointe sont observés avec une précision de 99,3\xa0% et un score f1 de 98,5\xa0% obtenu par BERT.", 'hi': 'हास्य अनुसंधान के क्षेत्र में, संवादी हास्य (सीएच) के उप-डोमेन में रुचि की एक हालिया वृद्धि हुई है। इस अध्ययन के दो मुख्य उद्देश्य हैं। (ए) तेलुगु में एक संवादी (विनोदी और गैर-विनोदी) डेटासेट विकसित करना। (b) संकलित डेटासेट में CH का पता लगाना। इस पत्र में, डेटा एकत्र करने और किए गए प्रयोगों को एकत्र करते समय सामना की जाने वाली चुनौतियों को स्पष्ट किया गया है। ट्रांसफर लर्निंग और नॉन-ट्रांसफर लर्निंग तकनीकों को पूर्व-प्रशिक्षित मॉडल जैसे फास्टटेक्स्ट वर्ड एम्बेडिंग, बर्ट भाषा मॉडल और टेक्स्ट जीसीएन का उपयोग करके लागू किया जाता है, जो दिए गए कॉर्पस के साथ-साथ शब्द और दस्तावेज़ एम्बेडिंग सीखता है। अत्याधुनिक परिणाम 99.3% सटीकता और BERT द्वारा प्राप्त 98.5% f1 स्कोर के साथ देखे जाते हैं।', 'ru': 'В области исследования юмора в последнее время наблюдается всплеск интереса к поддомену разговорного юмора (CH). Данное исследование преследует две основные цели: а) разработка набора разговорных (юмористических и несюмористических) данных на языке телугу; b) обнаружение СН в собранном наборе данных. В настоящем документе разъясняются проблемы, с которыми приходится сталкиваться при сборе данных и проведении экспериментов. Методы трансферного и непередаточного обучения реализуются путем использования предварительно обученных моделей, таких как вставки слов FastText, языковые модели BERT и Text GCN, которые изучают вложения слов и документов одновременно из заданного корпуса. Современные результаты наблюдаются с точностью 99,3% и баллом 98,5% f1, достигнутым БЕРТОМ.', 'ga': 'I réimse an taighde ghrinn, tá borradh spéise le déanaí i bhfo-fhearann na Humour Conversational (CH). Tá dhá phríomhchuspóir ag an staidéar seo. (a) tacar sonraí comhráiteach (greannmhar agus neamhghreannmhar) a fhorbairt i dTeileagúis. (b) Braithim CH sa tacar sonraí tiomsaithe. Sa pháipéar seo, déantar na dúshláin atá le sárú agus na sonraí a bhailiú agus na turgnaimh a rinneadh a shoiléiriú. Cuirtear foghlaim aistrithe agus teicnící foghlama neamhaistrithe i bhfeidhm trí leas a bhaint as samhlacha réamh-oilte mar leabú focal FastText, samhlacha teanga BERT agus Téacs GCN, a fhoghlaimíonn leabú focal agus doiciméad ag an am céanna den chorpas a thugtar. Breathnaítear na torthaí úrscothacha le cruinneas 99.3% agus scór f1 de 98.5% bainte amach ag BERT.', 'hu': 'A humorkutatás területén a közelmúltban növekedett az érdeklődés a Conversational Humor (CH) alterülete iránt. Ennek a tanulmánynak két fő célja van. a) beszélgetési (humoros és nem humoros) adatkészlet kidolgozása Telugu-ban. b) CH kimutatása az összeállított adatkészletben. Ebben a tanulmányban tisztázzuk az adatgyűjtés és az elvégzett kísérletek során felmerülő kihívásokat. A transzfertanulási és nem transzfertanulási technikákat előre képzett modellek, például FastText szóbeágyazások, BERT nyelvi modellek és Text GCN alkalmazásával valósítják meg, amelyek egyidejűleg megtanulják a korpusz szó és dokumentum beágyazását. A legkorszerűbb eredményeket 99,3%-os pontossággal és 98,5%-os f1 pontszámmal figyelték meg a BERT.', 'el': 'Στον τομέα της έρευνας για το χιούμορ, υπήρξε μια πρόσφατη αύξηση του ενδιαφέροντος για τον υποτομέα του συζητητικού χιούμορ (CH). Η μελέτη αυτή έχει δύο κύριους στόχους. (α) ανάπτυξη ενός συνόλου δεδομένων συνομιλίας (χιούμορ και μη χιούμορ) στο Telugu. β) ανιχνεύει την CH στο συγκεντρωμένο σύνολο δεδομένων. Στην παρούσα εργασία, αναλύονται οι προκλήσεις που αντιμετωπίζει η συλλογή των δεδομένων και τα πειράματα που διεξάγονται. Οι τεχνικές μάθησης μεταφοράς και μη μεταφοράς εφαρμόζονται με τη χρήση προ-εκπαιδευμένων μοντέλων όπως οι ενσωμάτωση λέξεων FastText, τα γλωσσικά μοντέλα BERT και το κείμενο το οποίο μαθαίνει την ενσωμάτωση λέξεων και εγγράφων ταυτόχρονα του δοσμένου σώματος. Τα τελευταία αποτελέσματα παρατηρούνται με ακρίβεια 99,3% και βαθμολογία 98,5% f1 που επιτυγχάνεται από τον BERT.', 'ka': 'ჰუმორის განსწავლებების პანელში, ახალი ინტერესტის გარჩევა კონტაქციონალური ჰუმორის (CH) ქვემომინში. ეს სწავლება აქვს ორი მნიშვნელოვანი მიზეზი. a) ტელუგუში კონტაქციონალური (ჰუმორიური და არ ჰუმორიური) მონაცემები განვითარება. (b) კომპიუალური მონაცემების სამყაროში CH- ს განახლება. ამ დომენტში გამოცდილებები, რომლებიც გამოყენებული მონაცემები და ექსპერიმენტები შემდეგ გამოყენებულია. Transfer learning and non-transfer learning techniques are implemented by using pre-trained models such as FastText words embedding, BERT language models and text GCN, which learns the word and document embedding simultaneously of the given corpus. სურათის წარმოდგენება 99,3% წარმოდგენა და 98,5% f1 წარმოდგენა BERT-ზე.', 'kk': 'Хумор зерттеулерінің өрісінде жаңа жұмыс ішінде (CH) Конвертациялық Хумор доменінің ішінде қызықтық көмектесу болды. Бұл зерттеу екі негізгі мақсаттар бар. (a) Телугудағы (хумориялық және хумориялық емес) деректер қорын жасау. (b) компиляцияланған деректер жиында CH- ді табу. Бұл қағазда, жасалған деректерді және тәжірибелерді жинау кезінде әсер етілген мәселелер күтпейді. Жылдамды мәтін ендіру, BERT тіл үлгілері және GCN мәтін, сөзді және құжатты бірдей келтірілген корпустың ендіру үлгілерін қолдану үшін аудару оқыту және аудару жоқ техникаларын орындайды. Күй- жай нәтижелері 99, 3% деген дұрыс және BERT жеткізген 98, 5% f1 нәтижелері бар.', 'it': "Nel campo della ricerca sull'umorismo, c'è stato un recente aumento di interesse nel sottodominio dell'Humor Conversazionale (CH). Questo studio ha due obiettivi principali. (a) sviluppare un set di dati conversazionali (umoristici e non umoristici) in Telugu. b) rilevare CH nel set di dati compilato. In questo articolo vengono illustrate le sfide affrontate durante la raccolta dei dati e gli esperimenti effettuati. Le tecniche di apprendimento del trasferimento e di apprendimento non-trasferimento sono implementate utilizzando modelli pre-formati come incorporazioni di parole FastText, modelli di linguaggio BERT e Text GCN, che apprendono le incorporazioni di parole e documenti simultaneamente del corpus dato. Risultati all'avanguardia sono osservati con una precisione del 99,3% e un punteggio f1 del 98,5% ottenuto da BERT.", 'ml': 'തമാശയുടെ പരിശോധനത്തിന്റെ പ്രദേശത്ത്, സംസാരിക്കുന്ന ഹുമോറിന്റെ സബ് ഡോമെയിനില്\u200d ഒരു താല്\u200dപര്യമുണ്ട്. ഈ പഠനത്തില്\u200d രണ്ടു പ്രധാന ലക്ഷ്യങ്ങളുണ്ട്. (a) ടെലുഗുവില്\u200d സംസാരിക്കുന്ന (തമാശയും തമാശയുമില്ലാത്ത) ഡാറ്റാസെറ്റ് നിര്\u200dമ്മിക്കുക. (b) കൂട്ടിചേര്\u200dത്ത ഡാറ്റാസറ്റില്\u200d CH കണ്ടുപിടിക്കുക. ഈ പത്രത്തില്\u200d, ഡേറ്റായും പരീക്ഷണങ്ങളും സംഘടിപ്പിക്കുമ്പോള്\u200d വിലാസങ്ങള്\u200d വിശദീകരിക്കുന്നു. പഠിക്കുന്നതും മാറ്റുന്നതും പഠിപ്പിക്കാത്ത വിദ്യാഭ്യാസത്തിന്റെ സാങ്കേതികവിദ്യ ഉപയോഗിക്കുന്നതും ഫാസ്റ്റ് ടെക്സ്റ്റ് വാക്ക് അംഗീകരിക്കുന്ന മോഡലുകള State-of-the-art results are observed with a 99.3% accuracy and a 98.5% f1 score achieved by BERT.', 'lt': 'In the field of humor research, there has been a recent surge of interest in the sub-domain of Conversational Humor (CH).  Šiuo tyrimu siekiama dviejų pagrindinių tikslų. a) plėtoti pokalbių (humorinių ir ne humorinių) duomenų rinkinį Telugėje. b) aptikti CH surinktame duomenų rinkinyje. Šiame dokumente paaiškinami iššūkiai, su kuriais susiduriama renkant duomenis ir atliekant eksperimentus. Perdavimo mokymosi ir neperdirbto mokymosi metodai įgyvendinami naudojant iš anksto parengtus modelius, pavyzdžiui, FastText žodžių įdėjimą, BERT kalbos modelius ir Text GCN, kurie tuo pačiu metu mokosi žodžių ir dokumentų įdėjimą iš nurodyto korpuso. Naujausi rezultatai pastebimi 99,3 % tikslumu ir 98,5 % f1 rezultatu pagal BERT.', 'ms': 'Dalam bidang kajian humor, terdapat meningkat kepentingan baru-baru ini dalam sub-domain Humor Perbualan (CH). kajian ini mempunyai dua tujuan utama. (a) mengembangkan set data percakapan (kelakar dan tidak kelakar) di Telugu. (b) mengesan CH dalam set data berkumpil. Dalam kertas ini, cabaran yang dihadapi semasa mengumpulkan data dan eksperimen yang dilakukan adalah jelas. Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given.  Keputusan state-of-the-art diperhatikan dengan ketepatan 99.3% dan skor 98.5% f1 dicapai oleh BERT.', 'mk': 'Во областа на истражувањето за хуморот, неодамна се зголеми интересот за поддоменот на Конверзационалниот хумор. Оваа студија има две главни цели. (a) develop a conversational (humorous and non-humorous) dataset in Telugu.  (b) детектирај CH во компилираниот датотек. Во овој документ, предизвиците со кои се соочуваат додека се собираат податоците и експериментите спроведени се објасни. Техниките за пренос на учење и не-пренос на учење се имплементираат со користење на предобучени модели како што се вградувањата на зборовите FastText, моделите на јазикот BERT и Text GCN, кои го научија зборот и документот вградувањата истовремено на дадениот корпус. Стандардните резултати се набљудуваат со 99,3 отсто точност и 98,5 отсто оценка f1 постигната од БЕРТ.', 'pl': 'W dziedzinie badań humoru nastąpił ostatni wzrost zainteresowania poddomeną humoru konwersacyjnego (CH). Badanie to ma dwa główne cele. (a) opracowanie zbioru danych konwersacyjnych (humorycznych i niehumorycznych) w telugu. b) wykryć CH w skompilowanym zbiorze danych. W niniejszym artykule wyjaśniono wyzwania stojące przed gromadzeniem danych i przeprowadzonymi eksperymentami. Techniki uczenia się transferowego i nietransferowego wdrażane są poprzez wykorzystanie wstępnie przeszkolonych modeli, takich jak osadzenia słów FastText, modele językowe BERT i Text GCN, które uczy się osadzeń słowa i dokumentu jednocześnie danego korpusu. Najnowocześniejsze wyniki obserwowane są z dokładnością 99,3% oraz wynikiem 98,5% f1 osiągniętym przez BERT.', 'no': 'I humoreforskningsfeltet har det blitt nyleg oppløyst av interesse i underdomenet av samtale Humor (CH). Denne studien har to hovudmål. a) utvikla eit samtale dataset i Telugu (humorous and non-humorous). (b) finn CH i kompilerte datasettet. I denne papiret er utfordringane som oppstod ved samling av data og eksperimentet utførte utfordringane utvikla. Overføringsslæring og ikkje-overføringsslæringsteknikk er implementert ved å bruka føretrainerte modeller slik som FastText- ordinnbygging, BERT- språk- modeller og GCN- tekst, som lærer ordet og dokumentinnbygging samtidig av den oppgjevne korpusen. Resultatet av kunsten er observert med ein 99,3% nøyaktig og ein 98,5% f1- score oppnådd av BERT.', 'mt': 'Fil-qasam tar-riċerka dwar l-humor, kien hemm żieda reċenti ta’ interess fis-sottodominju tal-Humor Konversazzjonali (CH). Dan l-istudju għandu żewġ għanijiet ewlenin. (a) develop a conversational (humorous and non-humorous) dataset in Telugu.  (b) jidentifika CH fis-sett ta’ dejta kkompilat. F’dan id-dokument, l-isfidi ffaċċjati waqt il-ġbir tad-dejta u l-esperimenti mwettqa huma ċċarati. It-tagħlim tat-trasferiment u t-tekniki tat-tagħlim mhux tat-trasferiment huma implimentati billi jintużaw mudelli mħarrġa minn qabel bħall-inkorporazzjoni tal-kliem FastText, il-mudelli tal-lingwa BERT u l-GCN tat-Test, li jitgħallmu l-inkorporazzjoni tal-kliem u d-dokument fl-istess ħin tal-korpus mogħti. Ir-riżultati l-aktar avvanzati huma osservati b’eżattezza ta’ 99.3% u punteġġ f1 ta’ 98.5% miksub mill-BERT.', 'mn': 'Хуморын судалгааны талаар саяхан харилцааны Хумор (CH) дотор сонирхолтой болсон. Энэ судалгаанд хоёр гол зорилго байна. (a) Телугу дахь ярианы (хямрал болон хямрал биш) өгөгдлийн санг хөгжүүлнэ. (b) цуглуулсан өгөгдлийн санд CH-г ол. Энэ цаасан дээр хийсэн өгөгдлийн болон туршилтуудыг цуглуулахад тулгарсан сорилтууд таамаглалтай. Трансфер суралцах болон шилжүүлэхгүй суралцах технологиуд FastText үгийг нэмж, BERT хэл загвар болон GCN үгийг суралцах болон баримт өгөгдсөн корпус гэх мэт урд суралцагдсан загваруудыг ашиглаж ашигладаг. Урлагийн үндсэн үр дүнг 99.3% зөв байдалтай харагдаж байна. БЕРТ-ын 98.5% f1 оноо.', 'ro': 'În domeniul cercetării umorului, a existat o creștere recentă a interesului în subdomeniul Umorului Conversațional (CH). Acest studiu are două obiective principale. (a) dezvoltă un set de date conversaționale (umoristice și non-umoristice) în Telugu. (b) detectează CH în setul de date compilat. În această lucrare sunt elucidate provocările cu care se confruntă colectarea datelor și experimentele efectuate. Tehnicile de învățare a transferului și de învățare non-transfer sunt implementate prin utilizarea de modele pre-instruite, cum ar fi încorporarea cuvintelor FastText, modelele lingvistice BERT și Text GCN, care învață simultan încorporarea cuvintelor și documentelor din corpul dat. Rezultatele de ultimă generaţie sunt observate cu o precizie de 99,3% şi un scor f1 de 98,5% obţinut de BERT.', 'sr': 'U oblasti istraživanja humor a, nedavno se pojavilo interesovanje u poddomenu razgovornog humora (CH). Ova studija ima dva glavna cilja. a) razvijaju razgovorni (humorni i ne-humorni) podaci u Telugu. b) открити CH у компилираним податима. U ovom papiru su izazovi sa kojima se suočavaju pri skupljanju izvršenih podataka i eksperimenata. Učenje prijenosa i tehnike učenja bez prijenosa provedene su korištenjem predobučenih modela kao što su FastText reči integracija, BERT jezičkih modela i teksta GCN, koji uči reč i dokument uključuju istovremeno prijenos datog korpusa. Rezultati države umjetnosti primećuju sa preciznošću 99,3% i 98,5% f1 rezultat koji je postigao BERT.', 'so': 'Ballanka baaritaanka jimicsiga waxaa la jiray mid aad u xiiseysan karo xiliga hoos-hoose deegaanka la xidhiidha Humurka (CH). Waxbarashadan waxay leedahay laba goal oo muhiim ah. (a) horumarinta macluumaad la hadlo (fudud oo aan fududeyn) oo ku qoran Telugu. (b) Aqoonso CH oo ku qoran macluumaadka koobsan. Warqaddan waxaa lagu caddeeyaa dhibaatooyin ay ka hor jeedaan marka la soo ururiyo macluumaadka iyo imtixaanka la sameeyo. Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given.  Midhaha farshaxanka waxaa lagu arkayaa 99.3% saxda iyo koox 98.5% f1 oo BERT soo gaadhay.', 'si': 'හිස්මෝර් පරීක්ෂණයේ ක්\u200dෂේත්රයේ, සංවාදය හුමෝර් (CH) ගැන ප්\u200dරශ්නයක් තියෙනවා. මේ පරීක්ෂණයේ ප්\u200dරධාන අරමුණ දෙකක් තියෙනවා. (a) ටෙලුගුවට ප්\u200dරවාද කරන්න පුළුවන් වාර්තාවක් සහ හෝ විහිළුවක් නැහැ. (b) සම්පාය කරපු දත්ත සැටේ CH හොයාගන්න. මේ පත්තරයේ ප්\u200dරශ්නයක් සම්බන්ධ වෙලා තියෙන්නේ දත්ත සහ පරීක්ෂණය සම්බන්ධ වෙලා තියෙන්නේ. Transfer learnt and non-Transfer learnt tecnologies are exerted by pre-Trained Models, e.g. FastText word Embdings, BERT language Models and Text GCN, that learns the word and Documentation Embdings at the co-empowered body. රාජ්\u200dයත්වයේ ක්\u200dරියාත්මක ප්\u200dරතිචාරයක් 99.3% සිද්ධතාවක් සහ 98.5% f1 ප්\u200dරතිචාරයක් BERT එකෙන් ලබාගත්තා.', 'sv': 'Inom humorforskningen har intresset ökat på senare tid inom delområdet Conversational Humor (CH). Denna studie har två huvudmål. a) utveckla en konversationsdata (humoristisk och icke-humoristisk) i Telugu. b) upptäcka CH i den sammanställda datauppsättningen. I denna uppsats belyses de utmaningar som ställs inför vid insamlingen av data och experiment som utförts. Tekniker för överföringsinlärning och icke-överföringsinlärning implementeras genom att använda sig av förberedda modeller som FastText-ordinbäddningar, BERT-språkmodeller och Text GCN, som lär sig ord- och dokumentinbäddningar samtidigt av den givna korpusen. Toppmoderna resultat observeras med 99,3% noggrannhet och 98,5% f1-poäng uppnåtts av BERT.', 'ta': 'வேடிக்கையான ஆராய்ச்சியின் புலத்தில், சமீபத்தில் ஒரு வட்டி இருந்தது பேச்சு மனிதனின் துணை களத்தில் உள்ளது. இந்த ஆராய்ச்சியில் இரண்டு முக்கிய பொருள்கள் உள்ளன. (a) develop a conversational (humorous and non-humorous) dataset in Telugu.  (b) தொகுக்கப்பட்ட தரவுத்தளத்தில் CH கண்டுபிடிக்கவும். இந்த காகிதத்தில், தகவல் மற்றும் சோதனைகளை சேகரிக்கும் போது சவால்கள் எதிர்பார்க்கப்பட்டுள்ளது என்பது தெரிவ கற்றல் மற்றும் மாற்ற முன்பயிற்சி மாதிரிகள் பயன்படுத்தப்பட்ட மாதிரிகளைப் போன்ற FastText word embeddings, BERT மொழி மாதிரிகள் மற்றும் உரை GCN, அது கொடுக்கப்பட்ட கோப்புகளின் சொல்லையு மாநிலை- கலை முடிவுகள் 99. 3% சரியாக பார்க்கப்பட்டுள்ளது மற்றும் BERT மூலம் அடைந்த 98. 5% F1 மதிப்புகள் பார்க்கப்படுகிறது.', 'ur': 'ہمور تحقیقات کے مطابق، مکالمانی ہمور (CH) کے sub-domain میں اچھی طرح کی علاقه کا اضافہ ہوا ہے۔ اس مطالعہ میں دو اصلی موجود ہیں۔ (a) ٹیلوگو میں ایک مذاق و غیر ہنسی ڈیٹ سٹ کی تخلیق کرتی ہے۔ (b) کامپیل کیا گیا ڈاٹ سٹ میں CH پتہ لگائیں۔ اس کاغذ میں چلنے والے چلنے والے چلنے والی چلنے والے ڈیٹا اور تجربے جمع کرنے کے بعد آزاد ہوتے ہیں Transfer learning and non-transfer learning techniques are implemented by using pre-trained models such as FastText word embeddings, BERT language models and text GCN, which learns the word and document embedding simultaneously of the given corpus. ایٹیٹ کے نتیجے 99.3% دقیق کے ساتھ دیکھے جاتے ہیں اور 98.5% f1 اسکو BERT کے ذریعہ پہنچایا جاتا ہے.', 'uz': "Tashqi taʼminotlar davrida, yaqinda muloqat Humor (CH) sohasida qiziqarli narsa bo'lgan edi. Bu o'qituvchida ikki asosiy maqola bor. Name (b) Kompyuterga nusxa olingan CH'ni aniqlash. Bu qogʻozda maʼlumot va jarayonlarni olishda murakkablar yordam beradi. Comment Sana natijasi 99. 3% аниқ ва BERT'ning 98.5% f1 scori bilan keladi.", 'vi': 'Trong lĩnh vực nghiên cứu hài hước, đã có một sự tăng vọt quan tâm đến tiểu vùng của đối thoại Humor (CH). Nghiên cứu này có hai mục tiêu chính. (a) phát triển dữ liệu để trò chuyện (khôi hài và không khôi hài) ở Telug. B) phát hiện CH trong b ộ dữ liệu soạn thảo. Trong tờ giấy này, thử thách phải đối mặt khi thu thập dữ liệu và thí nghiệm được thực hiện. Tập tin truyền tải và các kỹ thuật học không chuyển nhượng được thực hiện bằng cách sử dụng các mẫu được huấn luyện trước như sự nhúng vào từ khóa, các mẫu ngôn ngữ của BERT và chưa bao giờ học về cấu trúc văn bản cùng nhau của tập đoàn được đưa ra. Trình độ chính xác chuẩn 99.3. và một số tài sản 97.5.f1 được thực hiện bởi BERT.', 'bg': 'В областта на хуморните изследвания наскоро се наблюдава нарастване на интереса към поддомейна "Разговорен хумор". Това проучване има две основни цели. а) разработва разговорен (хумористичен и нехуморен) набор от данни на телугу. б) открива CH в съставения набор от данни. В настоящата статия са изяснени предизвикателствата, пред които са изправени при събирането на данните и проведените експерименти. Техниките за трансферно обучение и нетрансферно обучение се реализират чрез използване на предварително обучени модели като вграждане на думи, Езикови модели и Текст, които изучават едновременно вграждането на дума и документи на дадения корпус. Най-съвременните резултати се наблюдават с 99,3% точност и 98,5% ф1 резултат, постигнат от BERT.', 'nl': 'Op het gebied van humoronderzoek is er een recente toename van de interesse in het subdomein Conversational Humor (CH). Deze studie heeft twee hoofddoelstellingen. (a) het ontwikkelen van een conversationele (humoristische en niet-humoristische) dataset in Telugu. b) detecteren van CH in de gecompileerde dataset. In dit artikel worden de uitdagingen voor het verzamelen van de gegevens en de uitgevoerde experimenten toegelicht. Transfer learning en non-transfer learning technieken worden geïmplementeerd door gebruik te maken van vooraf getrainde modellen zoals FastText woord embeddings, BERT taalmodellen en Text GCN, die de woord en document embeddings tegelijkertijd van het gegeven corpus leert. State-of-the-art resultaten worden waargenomen met een 99,3% nauwkeurigheid en een 98,5% f1 score behaald door BERT.', 'id': 'Dalam bidang penelitian humor, baru-baru ini ada tumbuhan tertarik pada sub-domain Humor Konversional (CH). Studi ini memiliki dua tujuan utama. (a) mengembangkan dataset percakapan (humor dan tidak humor) di Telugu. (b) mendeteksi CH dalam set data yang dikompilasi. Dalam kertas ini, tantangan yang dihadapi saat mengumpulkan data dan eksperimen yang dilakukan adalah jelas. Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given.  Hasil terbaik diperhatikan dengan akurasi 99,3% dan skor f1 98,5% yang dicapai oleh BERT.', 'da': 'Inden for humor forskning har der for nylig været en stigning i interessen i underdomænet Conversational Humor (CH). Denne undersøgelse har to hovedmål. a) udvikle et samtaledatasæt (humoristisk og ikke-humoristisk) i Telugu. b) påvise CH i det samlede datasæt. I denne artikel belyses de udfordringer, der står overfor under indsamling af data og eksperimenter, der er udført. Overførsels- og ikke-overførsels-læringsteknikker implementeres ved hjælp af prætrænede modeller såsom FastText-ordindlejringer, BERT-sprogmodeller og Text GCN, som lærer ord- og dokumentindlejringer samtidig af det givne korpus. State-of-the-art resultater observeres med en 99,3% nøjagtighed og en 98,5% f1 score opnået af BERT.', 'hr': 'U području istraživanja humor a, nedavno se pojavljuje interesovanje u poddomenu razgovornog Humora (CH). Ova studija ima dva glavna cilja. a) razvijati razgovorni (humorni i ne-humorni) podaci u Telugu. b) otkriti CH u kompilacijskoj seti podataka. U ovom papiru izazovi s kojima se suočavaju pri skupljanju izvršenih podataka i eksperimenata su izlučeni. Učenje prijenosa i tehnike učenja bez prijenosa provedene su koristeći predobučene modele poput prijenosa FastText riječi, BERT jezičkih modela i teksta GCN-a, koji uči riječ i dokument uključuju istovremeno prijenos datog korpusa. Rezultati iz države umjetnosti primjećuju se s preciznošću 99,3% i rezultat od 98,5% f1 postignut BERT-om.', 'de': 'Im Bereich der Humorforschung gibt es in jüngster Zeit einen Anstieg des Interesses an der Subdomain Conversational Humor (CH). Diese Studie verfolgt zwei Hauptziele. (a) Entwicklung eines konversativen (humorvollen und nicht humorvollen) Datensatzes in Telugu. (b) CH im kompilierten Datensatz erkennen. In diesem Beitrag werden die Herausforderungen der Datenerhebung und der durchgeführten Experimente aufgezeigt. Transferlernen und Nicht-Transfer-Lerntechniken werden implementiert, indem vortrainierte Modelle wie FastText-Worteinbettungen, BERT-Sprachmodelle und Text-GCN verwendet werden, die die Wort- und Dokumenteinbettungen gleichzeitig des gegebenen Korpuss erlernen. Modernste Ergebnisse werden mit 99,3% Genauigkeit und einem 98,5% f1 Score von BERT beobachtet.', 'sw': 'In the field of humor research, there has been a recent surge of interest in the sub-domain of Conversational Humor (CH).  Utafiti huu una malengo makuu mawili. (a) kutengeneza taarifa za mazungumzo (ya kuchekesha na isiyo na kuchekesha) nchini Telugu. (b) kugundua CH kwenye seti ya taarifa zilizojumuishwa. Katika karatasi hii, changamoto zinazokabiliwa wakati wa kukusanya taarifa na majaribio yaliyofanyika zimepunguzwa. Kubadilisha mbinu za kujifunza na kutokuwepo na uhamishaji zinatekelezwa kwa kutumia mifano ya mafunzo ya zamani kama vile vile maneno ya FastText yanayofungwa, mifano ya lugha ya BERT na Mradi wa GCN, ambayo hujifunza neno na nyaraka zinazoingia katika vifaa vilivyopewa. Matokeo ya sanaa yanaonekana kwa asilimia 99.3 sahihi na score 98.5 f1 zilizopatikana na BERT.', 'fa': 'در زمینه تحقیقات شوخی، اخیراً افزایش علاقه\u200cای در زیر حوصله\u200cی گفتگوی (CH) وجود دارد. این مطالعه دو هدف اصلی دارد. (a) یک مجموعه داده\u200cهای مکالمانی (خنده\u200cآور و غیر خنده\u200cآور) در تلوگو توسعه می\u200cدهد. (b) CH را در مجموعه داده\u200cهای کامپیوتر شناسایی کنید. در این کاغذ، چالش\u200cهایی که در زمان جمع داده\u200cها و آزمایش\u200cها انجام شده\u200cاند با وجود روشن می\u200cشوند. تکنیک یادگیری و یادگیری غیر تغییر تغییر تغییر دادن با استفاده از مدلهای پیش آموزش شده مانند استفاده کردن کلمه FastText، مدلهای زبان BERT و متن GCN، که کلمه و سند را به همزمان از کورپوس داده می داند. نتیجه\u200cهای ایالت هنری با دقیق 99.3 درصد و نمونه\u200cی 98.5 درصد f1 که توسط BERT به دست آورده می\u200cشوند.', 'af': "In die veld van humor ondersoek, is daar 'n onlangse verhoeging van belang in die subdomein van Gespraakte Humor (CH). Hierdie studie het twee hoofde objekte. (a) ontwikkel 'n gesprekslyklike (humorese en non-humorese) datastel in Telugu. (b) beskry CH in die samelekteerde datastel. In hierdie papier, die uitdagings wat gesig is terwyl die data en eksperimente wat uitgevoer is, versamel word. Oordragte leer en nie-oordragte leer teknike word geïmplementeer deur die gebruik van voor-onderwerpende modele soos FastText woord inbêring, BERT taal modele en Teks GCN, wat leer die woord en dokument inbêring samekoms van die gegewe korpus. State-of-the-art resultate is observed with a 99.3% accuracy and a 98.5% f1 score achieved by BERT.", 'ko': '유머 연구 분야에서 회화 유머의 하위 분야가 최근 붐을 일으키고 있다.이 연구는 두 가지 주요 목표가 있다.(a) 테루고어로 대화(유머와 비유머) 데이터 집합을 개발한다.(b) 컴파일된 데이터에서 CH를 집중적으로 검사합니다.본고는 데이터를 수집하고 실험을 할 때 직면하는 도전을 밝히고 있다.이동 학습과 비이동 학습 기술은 미리 훈련된 모델을 사용하여 이루어진다. 예를 들어FastText 단어 삽입, BERT 언어 모델과 텍스트 GCN은 정어료 라이브러리에 있는 단어와 문서 삽입을 동시에 배울 수 있다.최신 결과의 정확도는 99.3%, 비트의 f1 성적은 98.5%였다.', 'sq': 'Në fushën e kërkimit të humorit, ka pasur një rritje të fundit interesi në nëndomeninë e humorit konversacional (CH). Ky studim ka dy objektiva kryesore. (a) të zhvillojë një grup të dhënash për bisedë (humor dhe jo humor) në Telugu. (b) zbuloj CH në grupin e të dhënave të kompiliuara. Në këtë letër, sfidat që ndeshen ndërsa mbledhin të dhënat dhe eksperimentet e kryera janë të qarta. Teknikët e mësimit të transferimit dhe të mësimit të jo-transferimit zbatohen duke përdorur modele të paratrajnuar të tilla si përfshirjet e fjalëve FastText, modelet e gjuhës BERT dhe teksti GCN, që mësojnë përfshirjet e fjalëve dhe dokumenteve në të njëjtën kohë të korpusit të dhënë. State-of-the-art results are observed with a 99.3% accuracy and a 98.5% f1 score achieved by BERT.', 'hy': 'Հումորի ուսումնասիրության ոլորտում վերջերս հետաքրքրություններ են առաջացել Հումորի հակառակցման (CH) ենթաբնագավայրում: Այս ուսումնասիրությունը ունի երկու հիմնական նպատակ: a) զարգացնել Թելուգույում խոսակցական (հումորային և ոչ հումորային) տվյալների համակարգ: b) հայտնաբերել CH-ը համակարգված տվյալների համակարգում: In this paper, the challenges faced while collecting the data and experiments carried out are elucidated.  Հաշվի առնելու ուսումնասիրությունը և ոչ հաշվի առնելու ուսումնասիրությունը իրականացվում են օգտագործելով նախապատրաստված մոդելներ, ինչպիսիք են արագ տեքստի բառերի ներդրումը, BER լեզվի մոդելները և Text GNC-ը, որոնք միաժամանակ սովորում են կորպուսի ներդրումը բա Ավելի լավագույն արդյունքները հետևում են 99.3 տոկոսի ճշգրտությամբ և 98.5 տոկոսի f1 գնահատականով:', 'tr': "Üýtgeşik araştırmalaryň sahypasynda, soňky wagt duşuşyk Humor (CH) sub-domynda gyzyklanma ukyby bar. Bu studiýada iki esasy maksady bar. (a) Teluguda gürrüň gürrüňli hatlary döreýär. (b) Dereje edilen veri setinde CH'i taplaň. Bu kagyzda çykyp biljek maglumatlary we synaglary toplamak wagtynda çözilýän kynçylyklar çözilýär. Öňlerden öwrenmek we aktarmak öwrenmek teknikleri, tiz tekst söz integrasyny, BERT dil modelleri we GCN metini ullanýan örpüsü bilen öwrenýär. Surat netijesi 99,3% dogry bilen bellenilýär we BERT tarapyndan ýetip bilen 98,5% f1 nokady.", 'bn': 'হাস্যকর গবেষণার ক্ষেত্রে সাম্প্রতিক কালে কথোপকথনাল হিউমারের সাব ডোমেইনের (চিচি) সাব ডোমেইনে আগ্রহের ব্যাপারে আগ্ এই গবেষণায় দুই প্রধান উদ্দেশ্য আছে। (a) টেলুগুয়াতে একটি আলোচনার (হাস্যকর এবং হাস্যকর) ডাটাসেট তৈরি করুন। (b) কমপিট ডাটাসেটে CH সনাক্ত করুন। এই কাগজটিতে তথ্য এবং পরীক্ষা সংগ্রহ করার সময় চ্যালেঞ্জের মুখোমুখি হয়েছে তা বিস্তারিত করা হয়েছে। Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given.  রাষ্ট্র-অফ-শিল্পের ফলাফল ৯৯. ৩% সঠিকভাবে দেখা যাচ্ছে এবং বের্টি দ্বারা অর্জন করা ৯৮. ৫% এফ১ স্কোর।', 'am': 'በሐሳብ ትምህርት እርሻ፣ የቀድሞው የአንቀሳቀስ የአንቀሳቀስ አካባቢ (CH) አካባቢ አካባቢ ድረ ገበታ የሚጠቅምበት ውጤት ተደርጎአል፡፡ ይሄ ትምህርት ሁለት ዋና አቃላቢዎች አላቸው (a) በቴልጉግ የሚኖረውን የውይይት (ማሳሰቢያ እና የማሰራበት) ዳታዎችን ማሳየት፡፡ (b) አዲስ ዶሴ ፍጠር በዚህ ገጽ የዳታዎችን እና ፈተናዎችን በማከማከማቸት ጊዜ የሚቃወሙት ውጤቶች ይታወቃል፡፡ ትምህርት እና ለመለወጥ ያልተማረ ስልጣናዎች እንደ FastText word embedding, BERT ቋንቋ models እና ጽሑፍ GCN በመጠቀም ይደረጋሉ፡፡ የ-የ-አርእስት ውጤቶች በ99.3 በመቶ እርግጠኛ እና በBERT የተደረገ የ98.5 በመቶ F1 ነጥብ ነው፡፡', 'bs': 'U području istraživanja humor a, nedavno se pojavljuje interesovanje u poddomenu razgovornog humora (CH). Ova studija ima dva glavna cilja. a) razvijaju razgovorni (humorni i ne-humorni) podaci u Telugu. b) otkriti CH u kompilacijskoj seti podataka. U ovom papiru su izazovi sa kojima se suočavaju pri skupljanju izvršenih podataka i eksperimenata. Pravljene su tehnike učenja prijenosa i učenja bez prijenosa koristeći predobučene modele kao što su FastText riječi integracije, BERT jezičke modele i tekst GCN, koji uči riječ i dokument uključuju istovremeno prijenos datog korpusa. Rezultati države umjetnosti primjećuju se sa preciznošću 99,3%, a rezultat od 98,5% f1 postignut od BERT.', 'az': "Şübhəsiz ki, humor araştırmalarının sahəsində, Konuşuşuşaq Humor (CH) altındakı səviyyədə çox az bir məlumat var idi. Bu təhsil iki ana məqsədi var. (a) Telugu'da müzakirçi (gülümsüz və gülümsüz) verilən məlumat qurmasını təhsil edir. (b) birləşdirilmiş veri qutusunda CH'i tapın. Bu kağızda işlədilən məlumatları və eksperimentləri toplayarkən üz çevrilən çətinliklər çəkilir. Öyrənmək öyrənmək və qeyd olmayan öyrənmək tekniklərini FastText sözlərini, BERT dillərin modellərini və GCN metini öyrənmək üçün təhsil edilmiş modellərin istifadəsi ilə istifadə edilir. Sanat sonuçları 99,3% ədalətlə və BERT tarafından başa çatdığı 98,5% f1 nöqtəsi ilə gözləyir.", 'et': 'Huumoriuuringute valdkonnas on hiljuti tekkinud huvi vestlushuumori (CH) alamdomeeni vastu. Uuringul on kaks peamist eesmärki. (a) töötada välja vestluslik (humoorne ja mittehumoorne) andmekogum Telugu keeles. b) tuvastada koostatud andmekogumis CH. Käesolevas töös selgitatakse väljakutseid, mis seisavad silmitsi andmete kogumisel ja läbiviidud katsetel. Transpordiõppe ja mittesiirdeõppe tehnikaid rakendatakse eelõpetatud mudelite abil, nagu FastText sõna manustamine, BERT keelemudelid ja Text GCN, mis õpib sõna- ja dokumendimanustamist samaaegselt antud korpusega. Tehnoloogilisi tulemusi täheldatakse 99,3% täpsusega ja BERT-iga saavutatud 98,5% f1 skooriga.', 'ca': "En el camp de la recerca sobre l'humor, hi ha hagut un augment recent d'interès en el subdomini de l'humor conversacional (CH). Aquest estudi té dos objectius principals. a) desenvolupar un conjunt de dades conversacionals (humorós i no humorós) a Telugu. b) detectar CH en el conjunt de dades compilat. En aquest paper, els reptes que s'enfronten mentre recollen les dades i els experiments que es fan són elucidats. Les tècniques d'aprenentatge de transfer ència i d'aprenentatge sense transferència s'implementan utilitzant models pré-entrenats com l'incorporació de paraules FastText, els models de llenguatge BERT i Text GCN, que aprenen l'incorporació de paraules i documents simultàneament del corpus dado. Els resultats més avançats són observats amb una precisió del 99,3% i una puntuació f1 del 98,5% aconseguida per BERT.", 'fi': 'Huumoritutkimuksen alalla kiinnostus Conversational Humor (CH) on viime aikoina lisääntynyt. Tällä tutkimuksella on kaksi päätavoitetta. (a) kehittää keskusteluaineisto (humoristinen ja ei-humoristinen) Telugussa. b) havaita CH kootussa aineistossa. Tässä työssä selvitetään aineiston keräämiseen ja kokeisiin liittyviä haasteita. Siirto- ja non-transfer-oppimistekniikoita toteutetaan hyödyntämällä esikoulutettuja malleja, kuten FastText-sanaupotuksia, BERT-kielimalleja ja Text GCN, joka oppii sanan ja asiakirjan upotuksia samanaikaisesti annetusta korpusesta. Uusimmat tulokset on havaittu 99,3%:n tarkkuudella ja BERT:llä 98,5%:n f1-pisteellä.', 'cs': 'V oblasti humoru v poslední době došlo k nárůstu zájmu o subdoménu konverzačního humoru (CH). Tato studie má dva hlavní cíle. (a) vytvořit konverzační (humorní i ne humorní) datovou sadu v telugu. b) detekuje CH ve sestaveném datovém souboru. V tomto článku jsou objasněny výzvy, kterým čelí při sběru dat a prováděných experimentů. Techniky transferového učení a netransferového učení jsou implementovány pomocí předškolených modelů, jako jsou FastText vložení slov, BERT jazykové modely a Text GCN, které se učí slovo a dokument vložení současně daného korpusu. Nejmodernější výsledky jsou sledovány s přesností 99,3% a skóre 98,5% f1 dosažené BERT.', 'sk': 'Na področju humorskih raziskav se je v zadnjem času povečalo zanimanje za poddomeno pogovornega humorja (CH). Ta študija ima dva glavna cilja. (a) razvijati pogovorni (humorni in nehumorni) nabor podatkov v Teluguju. (b) zazna CH v zbranem naboru podatkov. V prispevku so pojasnjeni izzivi, s katerimi se soočajo pri zbiranju podatkov in izvedenih poskusov. Tehnike prenosnega učenja in neprenosnega učenja se izvajajo z uporabo vnaprej usposobljenih modelov, kot so vgradnje besed FastText, jezikovni modeli BERT in Text GCN, ki se uči vgradnje besed in dokumentov hkrati v danem korpusu. Najsodobnejše rezultate opazujemo z 99,3-odstotno natančnostjo in 98,5-odstotno oceno f1, doseženo z BERT.', 'ha': "In field of research of humor, there has been an sami wata cuta na riba wa the sub-Domen of Conversation Hurum (Cha). Wannan littafin yana da abu biyu masu ƙaranci. (a) ka sami wani danne na haɗuwa (na yi na sha'awi da kuma bã da fara'awa) cikin telego. (b) ka gane Cha cikin tsarin da aka lissafa. A cikin wannan takardan, za'a bayyana musamman idan an sami data da jarrabori waɗanda aka aikata. @ info: whatsthis Ana nuna fassaran-sanar da 99.3% na tsari kuma an cika score 98.5% f1 da BERT.", 'jv': 'Nang kapan-kapan dumadhi istrawih dumadhi, Advanci kapan dumadhi podho sing nganggep nggawe winih dumadhi kapan (HH). Genjer-genjer iki dadi pancen pangan kuwi. (a) Daftar nggawe Daftar aturan (susahe lan nganggo-susahe) ning telu. (b) FindOK Nang mapan iki, aku sawar biasane sampeyan neng ngregani data karo éntuk sing berarti dadi lan ujaran. Layaran mbukak karo teknik sing ora nggawe penting nggawe layar lan banter-tekan sing dirangkat liyane ing model sing wis banter podho lagi banter (fast-Text word embedding), model sing langgar BERT lan model sing teks GKAN, sing yelaran kelas lan dokumen sing sampeyan mruput. Punika-punika sing paling-punika dipolehake kanggo sabanjuré karang nggawe Ning-Ning, 3% lan dokumen-puku f1 sing dirampake singular sabanjuré BERT.', 'he': 'בשטח מחקר ההומור, היה התעלות של עניין לאחרונה בתחום ההומור השיחתי (CH). למחקר הזה יש שני מטרות ראשיות. (a) לפתח קבוצת מידע שיחה (הומורית ולא הומורית) בטלוגו. (b) לגלות CH בסט הנתונים המאוסף. בעיתון הזה, האתגרים שנמצאים בזמן שאספת המידע והניסויים שנעשו מוברחים. טכניקות לימוד העברה ולא העברה מתפקדות על ידי השימוש בדוגמנים מאומנים מראש, כמו מילים מהירה טקסט, דוגמנים לשפה BERT וטקסט GCN התוצאות המאומנות מתבוננות עם מדויקת 99.3% ו-98.5% נקודת f1 שנקבלה על ידי BERT.', 'bo': 'འོད་ཀྱང་འཚོལ་ཞིབ་སྐྱེད་པའི་ལྟ་བུའི་ནང་དུ་ཚོར་བ་སྐྱེས་པའི་མཐུན་རྐྱེན་དུ་བྱུང་བ་ཡིན། ལྟ་བུའི་ནང་དུ་རྩ་བའི་དམིགས་ཡུལ་གཉིས་ཡོད་པས་རེད། (a) ཊེ་ལུ་གུ་ཡི་ནང་དུ་གཏམ་གླེང་སྐད་ཀྱི་གནད་དོན་ཡིག་ཆ་ཞིག་ཆགས། (b) compiled dataset་ནང་དུ་CH་རྙེད་བྱེད་པ ཤོག་བྱང་འདིའི་ནང་དུ་ཡོད་པའི་གདོང་ལེན་བྱེད་ཀྱི་དཀའ་ངལ་དགོས་བྱུང་། Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given. State-of-the-art results are observed with a 99.3% accuracy and a 98.5% f1 score achieved by BERT.'}
{'en': 'Comparison of methods for explicit discourse connective identification across various domains', 'ar': 'مقارنة بين طرق تحديد الخطاب الصريح الضام عبر مختلف المجالات', 'fr': "Comparaison des méthodes d'identification de la connectivité du discours explicite dans divers domaines", 'pt': 'Comparação de métodos para identificação conectiva de discurso explícito em vários domínios', 'es': 'Comparación de métodos para la identificación explícita de la conexión del discurso en varios dominios', 'ja': 'さまざまなドメインにわたる明示的な話題の結合的識別のための方法の比較', 'zh': '跨域显式语接识方较', 'ru': 'Сравнение методов явно выраженной дискурсной соединительной идентификации в различных доменах', 'hi': 'विभिन्न डोमेन में स्पष्ट प्रवचन संयोजी पहचान के लिए विधियों की तुलना', 'ga': 'Comparáid idir modhanna chun nasc-aithint sainráite dioscúrsa thar réimsí éagsúla', 'ka': 'განსხვავებული დიომენტების გამოყენება', 'el': 'Σύγκριση μεθόδων για τον ρητό συνδετικό προσδιορισμό λόγου σε διάφορους τομείς', 'it': "Confronto dei metodi per l'identificazione connettiva esplicita del discorso attraverso vari domini", 'kk': 'Түрлі домендер арасында таңдалған дискурстың қосылымды идентификациялау әдістерін салыстыру', 'lt': 'Aiškaus diskursinio jungiamojo identifikavimo įvairiose srityse metodų palyginimas', 'mk': 'Comparison of methods for explicit discourse connective identification across various domains', 'ms': 'Comparison of methods for explicit discourse connective identification across various domains', 'hu': 'Az explicit diskurzus kötő azonosítás módszereinek összehasonlítása különböző területeken', 'ml': 'വ്യത്യസ്ത സംസാരം ബന്ധപ്പെടുത്തുന്ന തിരിച്ചറിയാനുള്ള രീതികളുടെ താല്\u200dപര്യത്തിനു് വ്യക്തമായ', 'mt': 'Tqabbil ta’ metodi għall-identifikazzjoni konġuntiva ta’ diskors espliċita f’diversi oqsma', 'mn': 'Төрсөн ярианы холбоотой холбоотой тодорхойлолтын аргын харьцуулалт', 'pl': 'Porównanie metod wyraźnej identyfikacji łączności dyskursowej w różnych dziedzinach', 'ro': 'Compararea metodelor de identificare conjunctivă explicită a discursului în diferite domenii', 'si': 'විවිදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට පරීක්ෂණය', 'sr': 'Uspoređenje metoda za eksplicitnu identifikaciju veznih diskursa u raznim domenama', 'so': 'Isbarbarbardhigga qaababka aqoonsiga xiriirka hadalka ee goobaha kala duduwan', 'ur': 'مختلف دامنوں میں مشخص صحبت کے طریقوں کا مقایسہ', 'no': 'Samanlikning av metodar for eksplisitt diskurs- samband- identifikasjon over ulike domene', 'sv': 'Jämförelse av metoder för explicit diskursbindningsidentifiering mellan olika domäner', 'ta': 'வெளிப்படையான பேச்சு இணைப்பு அடையாளத்திற்கான முறைகளை ஒப்பிடு', 'uz': 'Name', 'vi': 'Sự so sánh của các phương pháp nhận dạng liên kết trong nhiều lĩnh vực khác nhau', 'bg': 'Сравнение на методите за изрична дискурсна свързваща идентификация в различни области', 'hr': 'Uspoređenje metoda za izraženu identifikaciju vezivanja diskusija u raznim domenama', 'nl': 'Vergelijking van methoden voor expliciete discoursconnectieve identificatie over verschillende domeinen', 'de': 'Vergleich von Methoden zur expliziten diskursbezogenen Identifikation über verschiedene Domänen hinweg', 'da': 'Sammenligning af metoder til eksplicit diskursidentifikation på tværs af forskellige domæner', 'id': 'Comparison of methods for explicit discourse connective identification across various domains', 'fa': 'Comparison of methods for explicit discourse connective identification across different domains', 'ko': '서로 다른 분야의 외현식 문장 연결 식별 방법의 비교', 'tr': 'Açık diskler baglaýyşynyň dürli sahypalarda görkezilişi', 'af': 'Vergelyking van metodes vir eksplisiese diskursie verbindingsidentifikasie oor verskeie domeine', 'am': 'የንግግር ግንኙነት ግንኙነት ግንኙነት ለመተካከል በተለያዩ አካባቢዎች መካከል', 'sw': 'Kulinganisha na mbinu za kutambua wazi mazungumzo yanayohusiana katika maeneo mbalimbali', 'az': 'Müxtəlif domenlər arasında açıq danışma üçün bağlantı kimliğinin metodlarının qarşılaşdırması', 'sq': 'Krahasimi i metodave për identifikimin eksplicit të diskursit lidhës nëpërmjet domeneve të ndryshme', 'bs': 'Uspoređenje metoda za izraženu veznu identifikaciju diskusija u raznim domenama', 'ca': "Comparació de mètodes d'identificació connectiva explícita del discurs en diversos dominis", 'bn': 'বিভিন্ন ডোমেইনের বিভিন্ন সংযোগ পরিচিতির জন্য পরিষ্কার করার পদ্ধতির তুলনা', 'fi': 'Eri toimialojen eksplisiittisen diskurssin yhdistävän tunnistamisen menetelmien vertailu', 'hy': 'Համեմատությունը տարբեր բնագավառներում արտահայտված խոսակցության միասնական հայտնաբերման մեթոդների', 'et': 'Erinevate valdkondade selgesõnalise diskursuse sidevahelise identifitseerimise meetodite võrdlus', 'cs': 'Porovnání metod explicitní identifikace diskurzních vazeb napříč různými doménami', 'jv': 'string" in "context_BAR_stringLink', 'sk': 'Primerjava metod eksplicitne diskurzivne vezivne identifikacije med različnimi področji', 'he': 'השוואה של שיטות לזיהוי חיבורי דיבור מובן ברחבי שדות שונים', 'ha': 'Farawa na hanyoyin wa shaidar da ke haɗuwa da magana mai bayyanãwa a kowane wurãre', 'bo': 'གསལ་བཤད་སྒེར་སྡུད་དང་སྦྲེལ་མཐུད་དམིགས་འཛུགས་ཀྱི་ཐབས་ལམ་དང་མཉམ་དུ་བཅུག་པ'}
{'en': 'Existing parse methods use varying approaches to identify explicit discourse connectives, but their performance has not been consistently evaluated in comparison to each other, nor have they been evaluated consistently on text other than newspaper articles. We here assess the performance on explicit connective identification of three parse methods (PDTB e2e, Lin et al., 2014 ; the winner of CONLL2015, Wang et al., 2015 ; and DisSent, Nie et al., 2019), along with a simple heuristic. We also examine how well these systems generalize to different datasets, namely written newspaper text (PDTB), written scientific text (BioDRB), prepared spoken text (TED-MDB) and spontaneous spoken text (Disco-SPICE). The results show that the e2e parser outperforms the other ', 'es': 'Los métodos de análisis existentes utilizan diferentes enfoques para identificar los conectivos explícitos del discurso, pero su desempeño no se ha evaluado consistentemente en comparación entre sí, ni se ha evaluado consistentemente en textos que no sean artículos periodísticos. Aquí evaluamos el rendimiento en la identificación conectiva explícita de tres métodos de análisis (PDTB e2e, Lin et al., 2014; el ganador de CONLL2015, Wang et al., 2015; y DisSent, Nie et al., 2019), junto con una heurística simple. También examinamos qué tan bien se generalizan estos sistemas a diferentes conjuntos de datos, a saber, texto de periódico escrito (PDTB), texto científico escrito (BioDRB), texto hablado preparado (TED-MDB) y texto hablado espontáneo (Disco-spice). Los resultados muestran que el analizador e2e supera a los demás métodos de análisis en todos los conjuntos de datos. Sin embargo, el rendimiento cae significativamente del PDTB a todos los demás conjuntos de datos. Proporcionamos un análisis más detallado de las diferencias de dominio y las conectivas que resultan difíciles de analizar, con el fin de resaltar las áreas en las que se pueden obtener beneficios.', 'pt': 'Os métodos de análise existentes usam abordagens variadas para identificar conectivos de discurso explícito, mas seu desempenho não foi avaliado de forma consistente em comparação entre si, nem foi avaliado de forma consistente em textos que não sejam artigos de jornal. Avaliamos aqui o desempenho na identificação conectiva explícita de três métodos de análise sintática (PDTB e2e, Lin et al., 2014; o vencedor do CONLL2015, Wang et al., 2015; e DisSent, Nie et al., 2019), juntamente com um heurística simples. Também examinamos o quão bem esses sistemas se generalizam para diferentes conjuntos de dados, a saber, texto escrito de jornal (PDTB), texto científico escrito (BioDRB), texto falado preparado (TED-MDB) e texto falado espontâneo (Disco-SPICE). Os resultados mostram que o analisador e2e supera os outros métodos de análise em todos os conjuntos de dados. No entanto, o desempenho cai significativamente do PDTB para todos os outros conjuntos de dados. Fornecemos uma análise mais detalhada das diferenças de domínio e conectivos que se mostram difíceis de analisar, a fim de destacar as áreas onde os ganhos podem ser obtidos.', 'ar': 'تستخدم طرق التحليل الحالية طرقًا مختلفة لتحديد روابط الخطاب الصريح ، ولكن لم يتم تقييم أدائها بشكل ثابت مقارنة ببعضها البعض ، ولم يتم تقييمها باستمرار على نص آخر غير المقالات الصحفية. نقوم هنا بتقييم الأداء على التحديد الضام الصريح لثلاث طرق تحليل (PDTB e2e ، Lin et al. ، 2014 ؛ الفائز في CONLL2015 ، Wang et al. ، 2015 ؛ و DisSent ، Nie et al. ، 2019) ، جنبًا إلى جنب مع إرشادية بسيطة. ندرس أيضًا مدى تعميم هذه الأنظمة على مجموعات البيانات المختلفة ، أي نص الجريدة المكتوبة (PDTB) ، والنص العلمي المكتوب (BioDRB) ، والنص المنطوق المُعد (TED-MDB) والنص المنطوق التلقائي (Disco-SPICE). توضح النتائج أن المحلل اللغوي e2e يتفوق في الأداء على طرق التحليل الأخرى في جميع مجموعات البيانات. ومع ذلك ، ينخفض الأداء بشكل كبير من PDTB لجميع مجموعات البيانات الأخرى. نحن نقدم تحليلاً أكثر دقة لاختلافات المجال والوصلات التي يصعب تحليلها ، من أجل تسليط الضوء على المجالات التي يمكن تحقيق المكاسب فيها.', 'fr': "Les méthodes d'analyse existantes utilisent différentes approches pour identifier les connecteurs explicites du discours, mais leurs performances n'ont pas été évaluées de manière cohérente les unes par rapport aux autres, ni évaluées de manière cohérente sur des textes autres que des articles de journaux. Nous évaluons ici les performances sur l'identification conjonctive explicite de trois méthodes d'analyse (PDTB e2e, Lin et al., 2014\xa0; le gagnant du CONLL2015, Wang et al., 2015\xa0; et DisSent, Nie et al., 2019), ainsi qu'une heuristique simple. Nous examinons également dans quelle mesure ces systèmes se généralisent à différents ensembles de données, à savoir le texte de journal écrit (PDTB), le texte scientifique écrit (BioDRB), le texte parlé préparé (TED-MDB) et le texte parlé spontané (Disco-SPICE). Les résultats montrent que l'analyseur e2e surpasse les autres méthodes d'analyse dans tous les ensembles de données. Cependant, les performances chutent de manière significative entre le PDTB et tous les autres ensembles de données. Nous fournissons une analyse plus fine des différences de domaines et des connectives qui s'avèrent difficiles à analyser, afin de mettre en évidence les domaines où des gains peuvent être réalisés.", 'zh': '今解析用异术以识显式语连接词,然其性不相较者,亦不于报纸文之外文本一也。 论三解析之法(PDTB e2e,Lin等,2014;CONLL2015,Wang等,2015与DisSent,Nie等,2019)之获胜者,及简启发式之法。 又考其系统对异数所推,即书面报纸文本(PDTB),书面科学文本(BioDRB),备口语文本(TED-MDB)及自发口语文本(Disco-SPICE)。 结果表明,e2e 解析器于诸数集者优于他解析。 然自 PDTB 至诸数集,性能显降。 异解析难连接词,细粒度以显益。', 'ja': '既存の構文解析法は、明示的な言説の結びつきを特定するためにさまざまなアプローチを使用しているが、それらのパフォーマンスは互いに比較して一貫して評価されておらず、新聞記事以外のテキストでも一貫して評価されていない。 ここでは、単純なヒューリスティックとともに、３つの解析方法（ PDTB e 2 e, Lin et al., 2014; CONLL 2015の受賞者、Wang et al., 2015;およびDisSent, Nie et al., 2019 ）の明示的な結合識別に関するパフォーマンスを評価する。 また、これらのシステムが、新聞テキスト（ PDTB ）、科学テキスト（ BioDRB ）、準備されたスポークンテキスト（ TED - MDB ）、および自発的スポークンテキスト（ Disco - SPICE ）といった異なるデータセットにどの程度よく一般化しているかを検討します。 結果は、e 2 e構文解析器がすべてのデータセットで他の構文解析方法よりも優れていることを示しています。 しかし、パフォーマンスはPDTBから他のすべてのデータセットに大幅に低下します。 私たちは、利得を得ることができる領域を強調するために、解析が困難であることが証明されているドメインの違いと接続のより細かい分析を提供します。', 'hi': 'मौजूदा पार्स विधियां स्पष्ट प्रवचन संयोजी की पहचान करने के लिए अलग-अलग दृष्टिकोणों का उपयोग करती हैं, लेकिन उनके प्रदर्शन का एक-दूसरे की तुलना में लगातार मूल्यांकन नहीं किया गया है, न ही उन्हें समाचार पत्र के लेखों के अलावा अन्य पाठ पर लगातार मूल्यांकन किया गया है। हम यहां तीन पार्स विधियों (पीडीटीबी ई 2 ई, लिन एट अल, 2014) की स्पष्ट संयोजी पहचान पर प्रदर्शन का आकलन करते हैं; CONLL2015, वांग एट अल। हम यह भी जांचते हैं कि ये प्रणालियां विभिन्न डेटासेट, अर्थात् लिखित समाचार पत्र पाठ (पीडीटीबी), लिखित वैज्ञानिक पाठ (BioDRB), तैयार किए गए बोले गए पाठ (TED-MDB) और सहज बोले गए पाठ (डिस्को-स्पाइस) के लिए कितनी अच्छी तरह से सामान्यीकृत होती हैं। परिणाम बताते हैं कि e2e पार्सर सभी डेटासेट में अन्य पार्स विधियों को मात देता है। हालांकि, प्रदर्शन PDTB से अन्य सभी डेटासेट के लिए काफी गिर जाता है। हम डोमेन मतभेदों और संयोजी का अधिक बारीक विश्लेषण प्रदान करते हैं जो पार्स करना मुश्किल साबित होता है, ताकि उन क्षेत्रों को उजागर किया जा सके जहां लाभ कमाया जा सकता है।', 'ru': 'Существующие методы синтаксического анализа используют различные подходы для идентификации явных соединений дискурса, но их эффективность не оценивалась последовательно по сравнению друг с другом, и они не оценивались последовательно по тексту, отличному от газетных статей. Здесь мы оцениваем эффективность явной соединительной идентификации трех методов синтаксического анализа (PDTB e2e, Lin et al., 2014; победитель CONLL2015, Wang et al., 2015; и DisSent, Nie et al., 2019) наряду с простой эвристикой. Мы также изучаем, насколько хорошо эти системы обобщают различные наборы данных, а именно письменный газетный текст (PDTB), письменный научный текст (BioDRB), подготовленный устный текст (TED-MDB) и спонтанный устный текст (Disco-SPICE). Результаты показывают, что анализатор e2e превосходит другие методы синтаксического анализа во всех наборах данных. Тем не менее, производительность значительно падает от PDTB ко всем другим наборам данных. Мы проводим более детальный анализ различий в доменах и связующих элементов, которые трудно проанализировать, с тем чтобы выявить области, в которых можно добиться положительных результатов.', 'ga': 'Úsáideann modhanna parsála atá ann faoi láthair cineálacha éagsúla cur chuige chun naisc dhioscúrsa follasacha a aithint, ach ní dhearnadh measúnú comhsheasmhach ar a bhfeidhmíocht i gcomparáid lena chéile, agus níor measadh go comhsheasmhach iad ar théacs seachas ailt nuachtáin. Déanaimid measúnú anseo ar fheidhmíocht sainaitheanta nascach trí mhodh parsála (PDTB e2e, Lin et al., 2014; buaiteoir CONLL2015, Wang et al., 2015; agus DisSent, Nie et al., 2019), mar aon le a heuristic simplí. Scrúdaímid freisin cé chomh maith agus a ghineann na córais seo le tacair shonraí éagsúla, eadhon téacs scríofa nuachtáin (PDTB), téacs scríofa eolaíoch (BioDRB), téacs labhartha ullmhaithe (TED-MDB) agus téacs labhartha spontáineach (Disco-SPICE). Léiríonn na torthaí go sáraíonn an parsálaí e2e na modhanna parsála eile i ngach tacar sonraí. Mar sin féin, titeann feidhmíocht go suntasach ón PDTB go dtí gach tacar sonraí eile. Cuirimid anailís níos míne ar fáil ar dhifríochtaí fearainn agus ar naisc atá deacair a pharsáil, chun aird a tharraingt ar na réimsí inar féidir gnóthachain a bhaint amach.', 'ka': 'არსებობს პარასის მეტოვები გამოყენება განსხვავებული დახმარებების განსაზღვრებისთვის გამოყენება განსხვავებული დისკურსების კავშირების განსაზღვრებისთვის, მაგრამ მათი გამოყენება ერთმანეთისთვის შედგომარებით არ უნ ჩვენ აქ განსაზღვრებთ სამი პანსტის მეტოვების გამოყენება (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; და DisSent, Nie et al., 2019), რომლებიც ერთად უკეთესი heuristic. ჩვენ შევხედავთ თუ რამდენია ეს სისტემები განსხვავებული მონაცემების ტექსტი (PDTB), წერილი მეცნიერო ტექსტი (BioDRB), წარმოიდგინე ტექსტი (TED-MDB) და სპონტანური წერილი ტექსტი (Disco-SPICE). წარმოდგენები ჩვენებს, რომ e2e პანელიზერი უფრო მეორე პანელიზაცია ყველა მონაცემებში. მაგრამ, პროცესიტემა PDTB-დან ყველა სხვა მონაცემების კონფიგურაციას მნიშვნელოვანია. ჩვენ უფრო დიომინის განსხვავებების და კავშირების ანალიზაციას, რომლებიც გამოწვებას ძალიან რთულია პარალიზაციას, რომ გააღწეროთ საზოგადოებები, სადაც შეიძლება გავა', 'el': 'Οι υπάρχουσες μέθοδοι ανάλυσης χρησιμοποιούν διαφορετικές προσεγγίσεις για τον προσδιορισμό ρητών συνδέσμων λόγου, αλλά η απόδοσή τους δεν έχει αξιολογηθεί με συνέπεια σε σύγκριση μεταξύ τους, ούτε έχουν αξιολογηθεί με συνέπεια σε κείμενα εκτός από άρθρα εφημερίδων. Εδώ αξιολογούμε την απόδοση στον σαφή συνδετικό προσδιορισμό τριών μεθόδων ανάλυσης (και ο νικητής των CONLL2015, Wang et al., 2015, και DisSent, Nie et al., 2019), μαζί με μια απλή Heuristik. Εξετάζουμε επίσης πόσο καλά αυτά τα συστήματα γενικεύονται σε διαφορετικά σύνολα δεδομένων, δηλαδή γραπτό κείμενο εφημερίδας (PDTB), γραπτό επιστημονικό κείμενο (BioDRB), προετοιμασμένο προφορικό κείμενο (TED-MDB) και αυθόρμητο προφορικό κείμενο (Disco-SPICE). Τα αποτελέσματα δείχνουν ότι ο αναλυτής e2e ξεπερνά τις άλλες μεθόδους ανάλυσης σε όλα τα σύνολα δεδομένων. Ωστόσο, η απόδοση μειώνεται σημαντικά από το PDTB σε όλα τα άλλα σύνολα δεδομένων. Παρέχουμε μια πιο λεπτή ανάλυση των διαφορών τομέα και των συνδετικών στοιχείων που αποδεικνύονται δύσκολο να αναλυθούν, προκειμένου να επισημάνουμε τους τομείς όπου μπορούν να γίνουν κέρδη.', 'hu': 'A meglévő elemzési módszerek különböző megközelítéseket alkalmaznak az explicit diskurzus kapcsolatok azonosítására, de teljesítményüket nem értékelték következetesen egymással összehasonlítva, és ezeket nem értékelték következetesen újságcikkeken kívül. Itt értékeljük a három elemzési módszer explicit kötő azonosításának teljesítményét (PDTB e2e, Lin et al., 2014; a CONLL2015, Wang et al., 2015; és a DisSent, Nie et al., 2019), valamint egy egyszerű heurisztikát. Azt is vizsgáljuk, hogy ezek a rendszerek milyen jól általánosítanak a különböző adatkészletekre, nevezetesen az írott újságszövegekre (PDTB), az írott tudományos szövegekre (BioDRB), az előkészített beszélt szövegekre (TED-MDB) és a spontán beszélt szövegekre (Disco-SPICE). Az eredmények azt mutatják, hogy az e2e elemző minden adathalmazban felülmúlja a többi elemzési módszert. A teljesítmény azonban jelentősen csökken a PDTB-ról az összes más adatkészletre. A nehezen értelmezhetőnek bizonyuló domain különbségek és összekötők finomabb elemzését nyújtjuk annak érdekében, hogy kiemeljük azokat a területeket, ahol nyereséget lehet elérni.', 'it': "I metodi di analisi esistenti utilizzano approcci diversi per identificare i connettivi espliciti del discorso, ma le loro prestazioni non sono state valutate coerentemente tra loro rispetto, né sono state valutate coerentemente su testi diversi dagli articoli di giornale. Qui valutiamo le prestazioni sull'identificazione connettiva esplicita di tre metodi di analisi (PDTB e2e, Lin et al., 2014; il vincitore di CONLL2015, Wang et al., 2015; e DisSent, Nie et al., 2019), insieme ad una semplice euristica. Esaminiamo anche come questi sistemi si generalizzino a diversi set di dati, vale a dire testo scritto di giornale (PDTB), testo scientifico scritto (BioDRB), testo parlato preparato (TED-MDB) e testo parlato spontaneo (Disco-SPICE). I risultati mostrano che il parser e2e supera gli altri metodi di analisi in tutti i set di dati. Tuttavia, le prestazioni diminuiscono significativamente dal PDTB a tutti gli altri set di dati. Forniamo un'analisi più fine delle differenze di dominio e dei connettivi che si rivelano difficili da analizzare, al fine di evidenziare le aree in cui è possibile ottenere guadagni.", 'kk': 'Бар талдау әдістері түсінікті дискурстар қосылымдарын анықтау үшін түрлі әдістер қолданылады, бірақ олардың әдістері бір-біріне салыстырып тұрмайды, және олар қағаз мақалаларынан басқа мәтінде тұрақты бағаламайды. Мұнда біз үш талдау әдістерін (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; және DisSent, Nie et al., 2019) және қарапайым геуристік арқылы түсінікті қосылу әдістерін бағалаймыз. Біз сондай-ақ бұл жүйелер әртүрлі деректер қорларына қанша жақсы түрлендірілген, мысалы жазылған қағаз мәтін (PDTB), жазылған ғылыми мәтін (BioDRB), сөйленген мәтін (TED-MDB) және спонтан сөйленген мәтін Нәтижелер e2e талдаушысы барлық деректер қорларында басқа талдау әдістерін жасайды. Бірақ әрекеттер PDTB- ден басқа деректер жиындарына маңызды ұстайды. Біз доменнің айырмашылықтарын және қосылымдарды талдау қиын болатын аумақтарды таңдау үшін көптеген анализ береміз.', 'mk': 'Постојаните методи за анализирање користат различни пристапи за идентификување на експлицитни дискурсни поврзувања, но нивната перформанса не е константно оценета во споредба меѓусебно, ниту биле оценети константно на текст освен на весниците. Овде ја проценуваме изведбата на експлицитната конективна идентификација на три методи за анализирање (PDTB e2e, Lin и ал., 2014; победникот на CONLL2015, Wang и ал., 2015; и DisSent, Nie и ал., 2019), заедно со едноставен хеористик. Исто така, ги испитуваме и овие системи како се генерализираат на различни податоци, имено пишаниот весник текст (PDTB), пишаниот научен текст (BioDRB), подготвен говорен текст (TED-MDB) и спонтан говорен текст (Disco-SPICE). Резултатите покажуваат дека e2e анализаторот ги надминува другите методи на анализа во сите датотеки. However, performance drops significantly from the PDTB to all other datasets.  Ние обезбедуваме пофина анализа на разликите во домените и врските кои се покажуваат тешко да се анализираат, со цел да се истакнат областите каде може да се постигнат добивки.', 'lt': 'Esami analizavimo metodai naudoja skirtingus metodus aiškiai diskursiniams jungiamiesiems jungiamiesiems ryšiams nustatyti, tačiau jų veiksmingumas nebuvo nuosekliai vertinamas lyginant vienas su kitu, ir jie nebuvo nuosekliai vertinami kitame tekste, išskyrus laikraščių straipsnius. Čia vertiname trijų analizės metodų (PDTB e2e, Lin et al., 2014; CONLL2015 laimėtojas, Wang et al., 2015; DisSent, Nie et al., 2019) ir paprastą heuristiką. Taip pat nagrinėjame, kaip šios sistemos gerai paplitusios įvairiems duomenų rinkiniams, būtent rašytiniam laikraščio tekstui (PDTB), rašytiniam moksliniam tekstui (BioDRB), parengtam kalbėtam tekstui (TED-MDB) ir spontaniškam kalbėtam tekstui (Disco-SPICE). Rezultatai rodo, kad e2e analizatorius visuose duomenų rinkiniuose atlieka daugiau kaip kitus analizavimo metodus. Tačiau rezultatai gerokai mažėja nuo PDTB iki visų kitų duomenų rinkinių. Pateikiame išsamesnę srities skirtumų ir jungčių, kurie tampa sunku išanalizuoti, analizę, siekiant pabrėžti sritis, kuriose galima pasiekti naudos.', 'ml': 'നിലവിലുള്ള പാര്\u200dസ് രീതികള്\u200d വ്യക്തമായി സംസാരിക്കുന്ന ബന്ധങ്ങള്\u200d തിരിച്ചറിയാന്\u200d വ്യത്യസ്തമായ വഴികള്\u200d ഉപയോഗിക്കുന്നു. പക്ഷെ അവയുടെ പ്രവര്\u200dത്തനങ്ങള്\u200d പരസ്പരം തുല് മൂന്നു പാര്\u200dസ് രീതികളുടെ പ്രകടനം വ്യക്തമായി ബന്ധപ്പെടുത്തുന്നതിനെപ്പറ്റി ഞങ്ങള്\u200d ഇവിടെ വിചാരിക്കുന്നുണ്ട്(പിഡിടിബി e2e, ലിന്\u200d എറ്റ് അല്\u200d; 2014; കോണ്\u200dഎല്\u200d2015, വാങ്ങ് അല്\u200d We also examine how well these systems generalize to different datasets, namely written newspaper text (PDTB), written scientific text (BioDRB), prepared spoken text (TED-MDB) and spontaneous spoken text (Disco-SPICE).  @ info: status എന്നാലും പ്രകടനം പിഡിടിബിയില്\u200d നിന്നും മറ്റെല്ലാ ഡാറ്റാസറ്റുകളിലേക്കും പ്രധാനപ്പെടുത്തു ഡൊമെയിന്\u200d വ്യത്യാസങ്ങളെയും ബന്ധങ്ങളെയും കൂടുതല്\u200d നല്ല പരിശോധന നല്\u200dകുന്നു. പാര്\u200dസ് ചെയ്യാന്\u200d ബുദ്ധിമുട്ടുന്ന സ്ഥലങ്ങള്\u200d പ്രദര്\u200d', 'ms': 'Kaedah hurai yang wujud menggunakan pendekatan yang berbeza untuk mengenalpasti sambungan diskors secara eksplicit, tetapi prestasi mereka tidak secara konsisten diteliti dalam perbandingan antara satu sama lain, dan juga tidak diteliti secara konsisten pada teks selain artikel kertas khabar. Kami di sini menilai prestasi mengenai pengenalan sambungan eksplicit tiga kaedah penghuraian (PDTB e2e, Lin et al., 2014; pemenang CONLL2015, Wang et al., 2015; dan DisSent, Nie et al., 2019), bersama dengan heuristik sederhana. Kami juga memeriksa bagaimana sistem ini menyebarkan kepada set data yang berbeza, iaitu teks surat khabar tertulis (PDTB), teks saintifik tertulis (BioDRB), teks bercakap disediakan (TED-MDB) dan teks bercakap spontan (Disco-SPICE). Hasil menunjukkan bahawa penghurai e2e melampaui kaedah hurai lain dalam semua set data. Namun, prestasi turun secara signifikan dari PDTB ke semua set data lain. Kami menyediakan analisis yang lebih baik bagi perbezaan domain dan sambungan yang membuktikan sukar untuk dihurai, untuk menentukan kawasan di mana keuntungan boleh dibuat.', 'mt': 'Il-metodi ta’ analiżi eżistenti jużaw approċċi varji biex jidentifikaw konnettivi ta’ diskors espliċiti, iżda l-prestazzjoni tagħhom ma ġietx evalwata b’mod konsistenti meta mqabbla ma’ xulxin, u lanqas ma ġew evalwati b’mod konsistenti fuq test għajr artikoli tal-gazzetta. Hawnhekk nistmaw il-prestazzjoni dwar l-identifikazzjoni konnettiva espliċita ta’ tliet metodi ta’ analiżi (PDTB e2e, Lin et al., 2014; ir-rebbieħa tal-CONLL2015, Wang et al., 2015; u DisSent, Nie et al., 2019), flimkien ma’ ħewristika sempliċi. Aħna teżamina wkoll kemm dawn is-sistemi jiġġeneralizzaw tajjeb għal settijiet differenti ta’ dejta, jiġifieri t-test bil-miktub tal-gazzetta (PDTB), it-test xjentifiku bil-miktub (BioDRB), it-test bil-miktub ippreparat (TED-MDB) u t-test bil-miktub spontanju (Disco-SPICE). Ir-riżultati juru li l-analizzatur e2e jaqbeż il-metodi l-oħra tal-analizzazzjoni fis-settijiet tad-dejta kollha. Madankollu, il-prestazzjoni tonqos b’mod sinifikanti mill-PDTB għas-settijiet tad-dejta l-oħra kollha. Aħna nipprovdu analiżi aktar fina tad-differenzi fid-dominju u tal-konnettivi li huma diffiċli biex jiġu analizzati, sabiex nibqgħu enfasizzati ż-żoni fejn jista’ jsir il-qligħ.', 'mn': 'Existing parsing methods use different approaches to identify explicit discourse connections, but their performance has not been consistently evaluated in comparison to each other, nor are they continued on text other than newspaper articles. Бид энд гурван ажиллах аргын тодорхой холбоотой холбоотой тодорхой тодорхой тодорхой тодорхой тодорхойлолтын үйл ажиллагааг үнэлдэг (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; DisSent, Nie et al., 2019), энгийн хэмжээний холбоотой. Бид мөн эдгээр системүүд өөр өөр өгөгдлийн санд хэр сайн нийтлэгддэг вэ гэвэл сонины текст (PDTB), бичигдсэн шинжлэх ухааны текст (BioDRB), ярианы текст (TED-MDB) болон сэтгэл хангалттай ярианы текст (Disco-SPICE) гэдгийг судалж байна. Үүний үр дүнд e2e хуваагч бүх өгөгдлийн санд бусад хуваагдах аргыг илүү хийдэг. Гэхдээ үйл ажиллагаа PDTB-ээс бусад өгөгдлийн сангууд хүртэл маш чухал доошлогддог. Бид холбоотой ялгаа болон холбоотой холбоотой талаар илүү сайхан шинжилгээ өгдөг. Энэ нь хуваалцах хэцүү байдаг.', 'no': 'Det eksisterande tolkingsmetodane brukar ulike tilnærmingar for å identifisera eksplisitt diskurssambandar, men utviklinga sine er ikkje konsekvent evaluert i sammenligning med kvarandre, eller har dei blitt konsekvent evaluert på teksten enn arkivartiklar. Vi vurderer utviklinga på eksplisitt tilkopling av tre tolkingsmetoder (PDTB e2e, Lin et al., 2014; vinner av CONLL2015, Wang et al., 2015; og DisSent, Nie et al., 2019), saman med ein enkel heuristisk. Vi undersøker også kor godt disse systemene genereliserer til ulike datasett, t.d. skriven tekst på bakgrunnen (PDTB), skriven vitenskapelig tekst (BioDRB), forberedt tekst (TED-MDB) og spontan tekst (Disco-SPICE). Resultatet viser at e2e- tolkaren utfører dei andre tolkingsmetodane i alle datasetta. Men utviklinga slipper betydelig frå PDTB til alle andre datasett. Vi tilbyr ein meir fint analyse av domeneforskjeller og tilkoplingar som viser vanskeleg for å tolka, for å markere områda der vinn kan gjerast.', 'pl': 'Istniejące metody parsowania wykorzystują różne podejścia do identyfikacji jednoznacznych łączników dyskursu, ale ich wydajność nie była konsekwentnie oceniana w porównaniu ze sobą, ani też konsekwentnie oceniana na tekście innym niż artykuły gazetowe. Oceniamy tutaj wydajność przy wyraźnej identyfikacji łączności trzech metod parsowania (PDTB e2e, Lin et al., 2014; zwycięzca CONLL2015, Wang et al., 2015; oraz DisSent, Nie et al., 2019), wraz z prostą heurystyką. Badamy również, jak dobrze systemy te uogólniają się na różne zbiory danych, a mianowicie pisany tekst gazety (PDTB), pisany tekst naukowy (BioDRB), przygotowany tekst mówiony (TED-MDB) i spontaniczny tekst mówiony (Disco-SPICE). Wyniki pokazują, że parser e2e przewyższa inne metody parsowania we wszystkich zbiorach danych. Jednak wydajność znacznie spada z PDTB do wszystkich innych zbiorów danych. Zapewniamy bardziej precyzyjną analizę różnic domen i łączności, które okazują się trudne do analizy, aby podkreślić obszary, w których można osiągnąć zyski.', 'ro': 'Metodele existente de analiză utilizează abordări diferite pentru a identifica conexiunile discursului explicit, dar performanța lor nu a fost evaluată în mod consecvent în comparație cu cealaltă și nici nu a fost evaluată în mod consecvent pe alte texte decât articolele de ziar. Aici evaluăm performanța privind identificarea conjunctivă explicită a trei metode de analizare (PDTB e2e, Lin et al., 2014; câștigătorul CONLL2015, Wang et al., 2015; și DisSent, Nie et al., 2019), împreună cu un euristic simplu. De asemenea, examinăm cât de bine generalizează aceste sisteme diferite seturi de date, și anume textul scris din ziar (PDTB), textul științific scris (BioDRB), textul vorbit pregătit (TED-MDB) și textul vorbit spontan (Disco-SPICE). Rezultatele arată că parserul e2e depășește celelalte metode de parsare din toate seturile de date. Cu toate acestea, performanța scade semnificativ de la PDTB la toate celelalte seturi de date. Oferim o analiză mai fină a diferențelor de domenii și a conectivelor care se dovedesc dificil de analizat, pentru a evidenția zonele în care se pot realiza câștiguri.', 'sr': 'Postoje metode analize koriste različite pristupe da identifikuju pojasne veze s diskusijama, ali njihov učinkovit nije konsekventno procjenjen u usporedbi jedni sa drugima, niti su konsekventno procjenjivani na tekstu osim novinskih članaka. Ovde procjenjujemo izvedbu o eksplicitnoj veznoj identifikaciji tri metode analize (PDTB e2e, Lin et al., 2014; pobednik CONLL2015, Wang et al., 2015; i DisSent, Nie et al., 2019), zajedno s jednostavnim heurističkim. Takođe pregledamo kako dobro se ovi sistemi generalizuju na različite datasete, to je napisani tekst novina (PDTB), napisani naučni tekst (BioDRB), pripremljeni tekst (TED-MDB) i spontanski govorni tekst (Disco-SPICE). Rezultati pokazuju da e2e analizator iznosi druge metode analizacije u svim podacima. Međutim, izvedba značajno pada od PDTB do svih ostalih podataka. Mi obezbeđujemo detaljniju analizu razlika i veza domena koje dokazuju da je teško analizirati, kako bi naglasili područje gdje se može ostvariti dobitak.', 'si': 'ඉතින් විශ්ලේෂණ විධානය විවිධ විදිහට ප්\u200dරවිධියක් භාවිත කරන්න පුළුවන් විදිහට කතාවක් සම්බන්ධයක් තියෙන්න, ඒත් ඔවුන්ගේ විධානය ඔවුන අපි මෙහෙ ප්\u200dරශ්නය සම්බන්ධ විදිහට පරීක්ෂා විදිහට සම්බන්ධ විදිහට පරීක්ෂා කරන්න පුළුවන් විදිහට පරීක්ෂා කරනවා (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; සහ DisSen අපි පරීක්ෂණය කරනවා මේ පද්ධතිය වෙනස් දත්ත සේට් වලට කොච්චර හොඳ සාමාන්\u200dය විදියට, ලියපු විද්\u200dයාත්මක පාළ (PDTB), ලියපු විද්\u200dයාත්මක පාළ (BioDRB), ක ප්\u200dරතිචාරය පෙන්වන්නේ e2e විශාලකය හැම දත්ත සේට් වල අනිත් විශාලනය විධානය කරනවා කියලා. නමුත්, ප්\u200dරභාවය PDTB වලින් අනිත් දත්ත සේට වලින් විශේෂයෙන් ප්\u200dරශ්නය වෙනවා. අපි විවිධානය සහ සම්බන්ධ විවිධ විශේෂයක් සම්බන්ධ කරනවා ඒ වගේම අමාරුයි විශේෂ කරන්න, ප්\u200dරශ්නයක් කරන්න පුළුව', 'so': "Heeganka baarlamaanku waxay isticmaalaan qaabooyin kala duduwan si ay u caddeeyaan xiriirka hadalka, laakiin sameyntooda lama qiimeynayn si siman isbarbarka qaarkood, lamana qiimeeyo qoraal kale oo aan ahayn warqadaha wargeyska. Halkan waxaynu qiimeynaynaa muuqashada aqoonsiga furan ee saddex qaab baarlamaha (PDTB e2e, Lin et al., 2014; guul u baahan CONLL2015, Wang et al., 2015; iyo DisSent, Nie et al., 2019), iyo sahlan heuristic. Sidoo kale waxaynu baaritaynaa si wanaagsan nidaamkan u soo bandhigaan sawirada kala duduwan, tusaale ahaan taariikhda qoran (PDTB), qoran sayniska cilmiga ah (BioDRB), qoran text la hadlay (TED-MDB) iyo text spontaney la hadlay (Disco-SPICE). Abaalku wuxuu muujiyaa in e2e baaritaanku uu sameeyo qaababka kale ee baaritaanka oo dhan. Si kastaba ha ahaatee muuqashada ayaa si muhiim ah uga soo bixinaya PDTB ilaa dhammaan sawirada kale. Anagaa sameynaya baaritaanka kala duwan ee deegaanka iyo xiriirka, taasoo ku cadaynaya inay ku adag tahay baaritaanka, si aan loo caddeeyo meelaha laga heli karo faa'iidada.", 'sv': 'Befintliga tolkningsmetoder använder olika tillvägagångssätt för att identifiera explicita diskurskopplingar, men deras prestanda har inte utvärderats konsekvent i jämförelse med varandra, och de har inte heller utvärderats konsekvent på annan text än tidningsartiklar. Här utvärderar vi resultatet på explicit bindningsidentifiering av tre parsningsmetoder (PDTB e2e, Lin et al., 2014; vinnaren av CONLL2015, Wang et al., 2015; och DisSent, Nie et al., 2019), tillsammans med en enkel heuristisk. Vi undersöker också hur väl dessa system generaliserar till olika datauppsättningar, nämligen skriven tidningstext (PDTB), skriven vetenskaplig text (BioDRB), förberedd talad text (TED-MDB) och spontan talad text (Disco-SPICE). Resultaten visar att e2e-parsern presterar bättre än de andra analysmetoderna i alla datauppsättningar. Prestandan sjunker dock avsevärt från PDTB till alla andra datauppsättningar. Vi ger en mer finkornig analys av domänskillnader och kopplingar som visar sig svåra att tolka, för att belysa de områden där vinster kan göras.', 'ta': 'Existing parse methods use varying approaches to identify explicit discourse connectives, but their performance has not been consistently evaluated in comparison to each other, nor have they been evaluated consistently on text other than newspaper articles.  நாம் இங்கே வெளிப்படையான இணைப்பு அடையாளம் மூன்று தொகுதி முறைகளின் (PDTB e2e, Lin et al., 2014; CONLL2015, வாங்க் et al., 2015; மற்றும் DisSent, Nie et al., 2019), சுலபமான ஹூரிஸ்டுடன் சேர்த்து. இந்த கணினிகள் வேறு தரவுத்தளங்களுக்கு எவ்வாறு பொதுவாக்குகிறது என்பதை நாம் சோதிக்கவும், எழுதப்பட்ட அறிவியல் உரை (பிடிடிபி), எழுதப்பட்ட அறிவியல் உரை (பியோடிஆர்பி), பேச் முடிவு ஆனால், செயல்பாடு PDTB லிருந்து மற்ற எல்லா தரவுத் தளங்களுக்கும் முக்கியமாக குறைகிறது. தளம் வேறுபாடுகளையும் இணைப்புகளையும் நாம் ஒரு மிகவும் நன்றாக பிரித்துக் கொண்டிருக்கிறோம். அது பிரித்துக்கொள்ள கடினமான', 'ur': 'Existing parse methods use various approaches to identify explicit discourse connections, but their performance is not consistently evaluated in comparison to each other, nor are they consistently evaluated on text other than newspaper articles. ہم یہاں تین پارس طریقوں کی صریح اتصال کی شناسایی پر کامپیوتر کی آزمائش کریں (PDTB e2e, Lin et al., 2014; CONLL2015 کا غالب، Wang et al., 2015; اور DisSent, Nie et al., 2019) ایک ساده ہوریست کے ساتھ۔ ہم نے بھی دیکھا کہ یہ سیسٹم کس طرح مختلف ڈاٹ سٹ پر آسان کر رہے ہیں، یعنی نوشتہ کاغذ کے پیغام (PDTB), نوشتہ علمی پیغام (BioDRB)، کلام کی پیغام (TED-MDB) اور اسپانیٹ کلام کی پیغام (Disco-SPICE)۔ نتیجے دکھاتے ہیں کہ e2e پارچر تمام ڈاٹ سٹ میں دوسرے پارچس طریقے کو اضافہ کرتا ہے۔ However, performance falls significantly from the PDTB to all other datasets. ہم ڈومین کے اختلاف اور اتصال کے بارے میں بہت اچھے دانے کا تحلیل دیتے ہیں جو پارس کرنے کے لئے مشکل ہے، اس لئے کہ جہاں غنیمتیں حاصل کئے جائیں ان منطقیوں کو ہدایت کریں۔', 'uz': "Name Bu yerda biz uchta parcha usullar (PDTB e2e, Lin et al., 2014; CONLL2015'ning muvaffaqiyati, Wang et 2015, va DisSent, Nie et al., 2019) va oddiy heuristik bilan ishlab chiqaramiz. Biz shu tizimlar boshqa maʼlumot tarkiblariga qanday yaxshi narsa yaratishni aniqlamiz, yozuvgan, ilmiy matn (BioDRB), gapiradigan matn (TED-MDB) va avtomatik gapiradigan matn (Disco-SPICE). Name Lekin, bajarishni PDTB'dan boshqa maʼlumotlar tarkibiga kamaytirish mumkin. Биз доменинг ўзгаришларини ва алоқаларни аниқлаб кўрсатамиз. Қўшиш мумкин бўлган жойларни кўрсатиш учун қийинчиликда мумкин.", 'vi': 'Các phương pháp phân tích tồn tại sử dụng các phương pháp khác nhau để xác định các liên kết ngôn luận trực tiếp, nhưng khả năng của chúng không được đánh giá liên tục so sánh với nhau, và chúng cũng không được đánh giá liên tục trên văn bản ngoài các bài báo. Chúng tôi ở đây đánh giá khả năng nhận diện kết nối rõ ràng của ba phương pháp phân tách (PDTB e2e, Lin et al., 204, người chiến thắng của COLEL25, Vương et al., 205 và DisSent, Niel et al., 209), cùng với một thần kinh đơn giản. Chúng tôi cũng xem những hệ thống này tổng hợp tốt thế nào với các bộ dữ liệu khác nhau, cụ thể là văn bản báo chí đã viết (PDTB), văn bản khoa học chữ viết (BioDRB), văn bản đã soạn thảo (DID-MDB) và văn bản phát ngôn tự phát (Disco-SPICE). Kết quả cho thấy rằng ô E2e phân tách còn hoàn thiện các phương pháp phân tách khác trong mọi bộ dữ liệu. Tuy nhiên, khả năng giảm đáng kể từ PDA trở thành tất cả các bộ dữ liệu khác. Chúng tôi cung cấp một phân tích tốt hơn về sự bất kích đạo của đánh vị đạo đạo trong tình huống trường này khó phân tính, để tốt nhật được những khu vực co', 'bg': 'Съществуващите методи за анализ използват различни подходи за идентифициране на експлицитни дискурсни съединения, но тяхното представяне не е последователно оценявано в сравнение един с друг, нито са оценявани последователно върху текст, различен от вестникарски статии. Тук оценяваме ефективността при изрична съединителна идентификация на три метода за анализ (ПДТБ e2e, Лин и др., 2014; победителят на CONLL2015, Уанг и др., 2015; и DisSent, Ни и др., 2019), заедно с проста евристика. Проучваме и колко добре тези системи обобщават различни набори от данни, а именно писмен вестникарски текст (ПДТБ), писмен научен текст (БиоДРБ), подготвен говорим текст (TED-MDB) и спонтанен говорим текст (Диско-SPICE). Резултатите показват, че анализаторът превъзхожда другите методи за анализ във всички набори от данни. Въпреки това производителността намалява значително от всички останали набори от данни. Ние предлагаме по-фин анализ на различията в домейните и съединенията, които се оказват трудни за анализ, за да се подчертаят областите, в които могат да се постигнат печалби.', 'da': 'Eksisterende fortolkningsmetoder bruger forskellige tilgange til at identificere eksplicitte diskursforbindelser, men deres præstation er ikke konsekvent evalueret i forhold til hinanden, og de er heller ikke konsekvent evalueret på anden tekst end avisartikler. Her vurderer vi resultaterne på eksplicit bindende identifikation af tre analysemetoder (PDTB e2e, Lin et al., 2014; vinderen af CONLL2015, Wang et al., 2015; og DisSent, Nie et al., 2019), sammen med en simpel heuristik. Vi undersøger også, hvor godt disse systemer generaliserer sig til forskellige datasæt, nemlig skriftlig avistekst (PDTB), skriftlig videnskabelig tekst (BioDRB), forberedt taletekst (TED-MDB) og spontan taletekst (Disco-SPICE). Resultaterne viser, at e2e-fortolkeren overgår de andre fortolkningsmetoder i alle datasæt. Men ydeevnen falder betydeligt fra PDTB til alle andre datasæt. Vi leverer en mere finkornet analyse af domæneforskelle og forbindelser, der viser sig vanskelige at fortolke, for at fremhæve de områder, hvor gevinster kan opnås.', 'hr': 'Postoje metode analize koriste različite pristupe za identifikaciju pojasnih veza s diskusijama, ali njihov učinkovit nije konsekventno procjenjen u usporedbi jedni s drugima, niti su konsekventno procjenjivani na tekstu osim novinskih članaka. Ovdje procjenjujemo izvedbu na pojasnoj veznoj identifikaciji tri metode analize (PDTB e2e, Lin et al., 2014; pobjednik CONLL2015, Wang et al., 2015; i DisSent, Nie et al., 2019), zajedno s jednostavnim heurističkim. Također istražujemo kako dobro se ovi sustavi generaliziraju na različite podatke, to je napisani tekst novina (PDTB), napisani znanstveni tekst (BioDRB), pripremljeni tekst (TED-MDB) i spontanski govorni tekst (Disco-SPICE). Rezultati pokazuju da e2e analizač iznosi druge metode analizacije u svim podacima. Međutim, izvedba značajno pada od PDTB do svih ostalih podataka. Mi pružamo detaljniju analizu razlika domena i veza koje se dokazuju teško analizirati kako bi osvjetlili područje gdje se može ostvariti dobit.', 'nl': 'Bestaande parse methodes gebruiken verschillende benaderingen om expliciete discoursconnectieven te identificeren, maar hun prestaties zijn niet consistent geëvalueerd in vergelijking met elkaar, noch consistent geëvalueerd op andere teksten dan krantenartikelen. We beoordelen hier de prestaties op expliciete connectieve identificatie van drie parse methoden (PDTB e2e, Lin et al., 2014; de winnaar van CONLL2015, Wang et al., 2015; en DisSent, Nie et al., 2019), samen met een eenvoudige heuristiek. We onderzoeken ook hoe goed deze systemen generaliseren naar verschillende datasets, namelijk geschreven krantentekst (PDTB), geschreven wetenschappelijke tekst (BioDRB), voorbereide gesproken tekst (TED-MDB) en spontane gesproken tekst (Disco-SPICE). De resultaten tonen aan dat de e2e parser de andere parsermethoden in alle datasets overtreft. De prestaties dalen echter aanzienlijk van de PDTB naar alle andere datasets. We bieden een fijnmazige analyse van domeinverschillen en connectieven die moeilijk te parsen blijken te zijn, om de gebieden te benadrukken waar winst kan worden gemaakt.', 'de': 'Bisherige Parse-Methoden verwenden unterschiedliche Ansätze, um explizite Diskursverbindungen zu identifizieren, aber ihre Leistung wurde weder konsistent im Vergleich zueinander bewertet noch konsistent auf anderen Texten als Zeitungsartikeln bewertet. Wir bewerten hier die Leistungsfähigkeit von drei Parse-Methoden (PDTB e2e, Lin et al., 2014; Gewinner von CONLL2015, Wang et al., 2015; und DisSent, Nie et al., 2019), zusammen mit einer einfachen Heuristik. Wir untersuchen auch, wie gut diese Systeme auf verschiedene Datensätze verallgemeinern, nämlich geschriebenen Zeitungstext (PDTB), geschriebenen wissenschaftlichen Text (BioDRB), aufbereiteten gesprochenen Text (TED-MDB) und spontanen gesprochenen Text (Disco-SPICE). Die Ergebnisse zeigen, dass der e2e Parser die anderen Parse-Methoden in allen Datensätzen übertrifft. Allerdings sinkt die Leistung vom PDTB auf alle anderen Datensätze signifikant. Wir bieten eine detailliertere Analyse von Domänenunterschieden und Konnektiven, die sich als schwierig zu analysieren erweisen, um die Bereiche aufzuzeigen, in denen Gewinne erzielt werden können.', 'fa': 'روش\u200cهای تحلیل موجود از طریق\u200cهای متفاوتی برای شناسایی ارتباط\u200cهای صحبت مشخص استفاده می\u200cکنند، ولی عملکرد\u200cهای آنها در مقایسه با یکدیگر دائمی ارتباط نمی\u200cشود، و آنها در متن غیر از مقاله\u200cهای روزنامه\u200cها دائمی ارتباط نمی\u200cشوند. ما در اینجا عملکرد روی شناسایی ارتباطی توضیح سه روش بررسی (PDTB e2e, Lin et al., 2014; برنده CONLL2015, Wang et al., 2015; و DisSent, Nie et al., 2019) را با یک هوریستیک ساده ارتباط می\u200cدهیم. ما همچنین تحقیق می\u200cکنیم که این سیستم\u200cها چقدر به مجموعه\u200cهای داده\u200cهای مختلف، یعنی متن روزنامه نوشته شده (PDTB), متن علمی نوشته (BioDRB), متن صحبت شده (TED-MDB) و متن صحبت\u200cکننده (Disco-SPICE) آماده می\u200cشوند. نتیجه\u200cها نشان می\u200cدهند که پاداش\u200cدهنده e2e روش\u200cهای جدایی دیگر را در تمام مجموعه\u200cهای داده\u200cها انجام می\u200cدهد. با این حال، عملکرد از PDTB به تمام مجموعه\u200cهای داده\u200cهای دیگر بسیار اضافه می\u200cشود. ما تحلیل دانه\u200cهای زیبایی بیشتری از تفاوت\u200cها و ارتباطات دامنی را پیشنهاد می\u200cکنیم که برای بررسی کردن منطقه\u200cها سخت است.', 'id': 'Metode analisis yang ada menggunakan pendekatan yang berbeda untuk mengidentifikasi konektif diskors eksplisit, tetapi prestasi mereka tidak secara konsisten diteliti dibandingkan satu sama lain, dan tidak pernah diteliti konsisten pada teks selain artikel koran. Kami di sini mempertimbangkan prestasi pada identifikasi konektif eksplicit dari tiga metode analisis (PDTB e2e, Lin et al., 2014; pemenang CONLL2015, Wang et al., 2015; dan DisSent, Nie et al., 2019), bersama dengan heuristik sederhana. We also examine how well these systems generalize to different datasets, namely written newspaper text (PDTB), written scientific text (BioDRB), prepared spoken text (TED-MDB) and spontaneous spoken text (Disco-SPICE).  Hasilnya menunjukkan bahwa parser e2e melebihi metode parse lainnya dalam semua set data. Namun, prestasi menurun secara signifikan dari PDTB ke semua set data lainnya. Kami menyediakan analisis yang lebih baik dari perbedaan domain dan konektif yang membuktikan sulit untuk dihapus, untuk mempertimbangkan daerah di mana keuntungan dapat dibuat.', 'ko': '기존의 문법 분석 방법은 서로 다른 방법으로 명확한 말 연결어를 식별하지만 그들의 표현은 일치된 평가를 받지 못했고 신문 기사 이외의 텍스트에서도 일치된 평가를 받지 못했다.여기서 우리는 세 가지 해석 방법(PDTB e2e, 임 등, 2014년, CONLL 2015의 우승자, 왕 등, 2015년, 이견, 녜 등, 2019년)이 현식 연결 식별에 있어서의 성능과 간단한 계발식 방법을 평가했다.서면신문텍스트(PDTB), 서면과학텍스트(BioDRB), 구어텍스트(TED-MDB)와 자발적인 구어텍스트(Disco SPICE)를 준비하는 시스템도 연구했다.결과에 따르면 e2e해상기는 모든 데이터 집중에서 다른 해석 방법보다 우수하다.그러나 PDTB에서 다른 모든 데이터 세트에 이르기까지 성능이 크게 저하됩니다.우리는 해석하기 어려운 영역 차이와 연결어를 더욱 세밀하게 분석해 수익을 얻을 수 있는 영역을 강조했다.', 'sw': 'Utawala wa bunge unatumia mbinu tofauti za kutambua muungano wa mazungumzo ya wazi, lakini utendaji wao haujavutiwa kwa ujumla ukilinganishwa na wao, wala hawajapitiwa kwa ujumla katika makala mengine ya magazeti. Tuna tathmini utendaji wa utambulisho wa njia tatu za bunge (PDTB e2e, Lin et al., 2014; mshindi wa CONLL2015, Wang et al., 2015; na DisSent, Nie et al., 2019), pamoja na heuristi rahisi. Pia tunachunguza namna mifumo hii inavyotengeneza kwenye seti tofauti za taarifa, yaani maandishi ya magazeti yaliyoandikwa (PDTB), maandishi ya kisayansi (BioDRB), yaliyoandaa ujumbe wa mazungumzo yanayozungumzwa (TED-MDB) na maandishi yanayozungumzwa kwa wenyewe (Disco-SPICE). Matokeo yanaonyesha kuwa mchambuzi wa e2e anafanya mbinu nyingine za parse katika seti zote za data. Hata hivyo, utendaji unapungua kwa kiasi kikubwa kutoka PDTB hadi seti nyingine zote. Tunatoa uchambuzi mzuri zaidi wa tofauti na viungo vya ndani ambavyo vinashiria kuwa vigumu kujengwa, ili kuonyesha maeneo ambayo mafanikio yanaweza kufanywa.', 'tr': "Öň bar analyz yöntemleri açık sözleri baglaýyşyny tanyşdyrmak üçin farklı golaýlary ulanýar, ýöne olaryň netijesi bir-birine degişişişinde deňlenmedi we olar gazet makalaryndan başga metinde dury deňlenmedi. Biz bu ýerde üç pars yöntemlerini (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; we DisSent, Nie et al., 2019) ýeňiji bir heuristik bilen takyklaýarys. Biz hem bu sistemleriň beýleki sanat setirlerine nähili gowy döredilýändigini barlaýarys, hem ýazylýan gazete metini (PDTB), ýazylýan ylmy metini (BioDRB), gepleşýän metini (TED-MDB) we hem spontane gepleşýän metini (Disco-SPICE). Netijeler e2e tansçysyň başga tansçylyk yöntemlerini hem datasetlerde çykarýar. Ýöne çykyş PDTB'den başga hatlaryň düzümlerine has baglanýar. Biz domenyň farklygynyň we bağlantılaryň a ňsatlyk bilen çykyp biljek bölgelerini ýagtylaşdyrmak üçin biraz daha düzgün bir analizi bererik.", 'af': "Die bestaande verwerking metodes gebruik verskillende toegange om eksplisiese diskursie verbindings te identifiseer, maar hulle prestasie is nie konsistentlik in vergelyking met mekaar te evalueer nie, of hulle is konsistentlik geevalueer op teks ander as koerant artikels. Ons hier vurk die prestasie op eksplisiese koppelvlakkende identifikasie van drie verwerking metodes (PDTB e2e, Lin et al., 2014; die wen van CONLL2015, Wang et al., 2015; en DisSent, Nie et al., 2019), saam met 'n eenvoudige heuristiese. Ons ondersoek ook hoe goed hierdie stelsels genereer word tot verskillende datastelle, dit is geskryf nuuspapier teks (PDTB), geskryf wetenskaplike teks (BioDRB), voorbereid gespreek teks (TED-MDB) en spontanee gespreek teks (Disco-SPICE). Die resultate vertoon dat die e2e ontleerder die ander verwerking metodes in alle datastelle uitvoer. Maar, prestasie drup betekeurig van die PDTB na alle ander datastelle. Ons verskaf 'n meer fyn-koring analisie van domein verskille en verbindings wat moeilik bevestig om te verwerk, om die gebied waar verkrywings kan maak word te verlig.", 'sq': 'Metodat ekzistuese të analizimit përdorin metoda të ndryshme për të identifikuar lidhjet e shprehura të diskursit, por performanca e tyre nuk është vlerësuar vazhdimisht në krahasim me njëri-tjetrin dhe as nuk janë vlerësuar vazhdimisht në tekst përveç artikujve të gazetës. We here assess the performance on explicit connective identification of three parse methods (PDTB e2e, Lin et al., 2014; the winner of CONLL2015, Wang et al., 2015; and DisSent, Nie et al., 2019), along with a simple heuristic.  Ne gjithashtu shqyrtojmë se sa mirë këto sisteme gjeneralizohen në grupe të dhënash të ndryshme, veçanërisht tekstin e gazetës së shkruar (PDTB), tekstin shkruar shkencore (BioDRB), tekstin e përgatitur të folur (TED-MDB) dhe tekstin spontan të folur (Disco-SPICE). Rezultatet tregojnë se analizuesi e2e kryen metodat e tjera të analizimit në të gjitha grupet e të dhënave. Megjithatë, performanca bie ndjeshëm nga PDTB në të gjitha të dhënat e tjera. Ne ofrojmë një analizë më të hollë të dallimeve në domeni dhe lidhjeve që janë të vështira për të analizuar, me qëllim që të theksojmë fushat ku mund të bëhen fitime.', 'am': 'የአሁኑ የፓርላማ ሥርዓት ግንኙነትን ለመግለጽ የተለየ የንግግር ግንኙነቶችን ለመግለጽ የሚጠይቁ ደረጃዎች ይጠይቃሉ፤ ነገር ግን ፍቃዳቸው እርስ በርሳቸው በሚተካከል አይታወቁም፥ ከጋዜጠኞቹም ጽሑፎች በቀር በጽሑፍ አይታሰቡም፡፡ በዚህ ላይ በሦስት የፓርላማ ሥርዓት (PDTB e2e, Lin et al., 2014); CONLL2015 ድጋፍ አሸነፈው፤ እና ዲስኬን እና ኒ ኤል., 2019) እና ቀላል ሀሪስቲ ጋር ነው፡፡ እና እነዚህን ስርዓቶች ለልዩ ዳታተሮች እንዴት ያህል እንዲያስተካክሉ እናምረዋለን፤ የጋዜጠኛ ገጽ ጽሑፍ (PDTB)፣ የተጻፈ የሳይንስ ጽሑፍ (BioDRB)፣ የተናገረውን ጽሑፍ (TED-MDB) እና የተዘጋጀውን ጽሑፍ (Disco-SPICE)፡፡ The results show that the e2e parser outperforms the other parse methods in all datasets.  ነገር ግን የድምፅ ውጤት ከPDTB ወደ ሌሎች ዳታተሮች ሁሉ በኩል ያሳርፋል፡፡ የዶሜን ልዩነት እና ግንኙነቶችን ለመፍጠር የሚችሉትን አካባቢ እናደርጋለን፡፡', 'az': 'Existing analiz metodları açıq danışma bağlantılarını tanımlamaq üçün dəyişiklik tərzlərini istifadə edir, amma onların performansları bir-birinə qarşılaşdırmaq üçün sürəkli tərzlərində təmin edilmədi və onlar gazet məktublarından başqa məktubların üstündə müəyyən edilmədi. Biz burada üç analiz metodların a çıq-aydın bağlantılı tanımlaması haqqında performansını təmin edirik (PDTB e2e, Lin et al., 2014; CONLL2015, Wang et al., 2015; və DisSent, Nie et al., 2019), basit bir heuristik ilə birlikdə. Biz həmçinin bu sistemlər müxtəlif verilən qurbanlara, yazılmış gazeteci mətnə (PDTB), yazılmış bilimsel mətnə (BioDRB), danışmış mətnə (TED-MDB) və spontane danışmış mətnə (Disco-SPICE) necə yaxşı tərzdə tədarüklənirik. Sonuçlar e2e ayırıcının bütün veri qurularında digər ayırış metodlarını daha üstün etdiyini göstərir. Ancaq performans PDTB-dən başqa verilən qurğulara möhkəm düşər. Biz domain fərqləşmələrini və bağlantılarının daha münasibətli analizi təmin edirik ki, qazanılabilir bölgelerini işıqlandırmaq üçün çətin göstərir.', 'hy': 'Գոյություն ունի վերլուծության մեթոդներ, որոնք օգտագործում են տարբեր մոտեցումներ բացատրական խոսակցային կապերի հայտնաբերելու համար, բայց նրանց արտադրությունը միմյանց հետ համեմատած համեմատական չափով չի գնահատվել, կամ էլ դրանք համեմատական չափով են գնահատվել թեքստի Այստեղ մենք գնահատում ենք երեք վերլուծության մեթոդների (PDTB e2e, Lin et al., 2014 թվականը, հաղթողը, 2015 թվականը, Վանգ et al., 2015 թվականը, և Դիսենթը, Նեյի et al., 2019 թվականը), միասին պարզ հորիստիկ: Մենք նաև ուսումնասիրում ենք, թե ինչքան լավ են այս համակարգերը ընդհանրացվում տարբեր տվյալների համակարգերի վրա, հատկապես թերթի գրված տեքստի (PDTB), գրված գիտական տեքստի (ԲիոԴՌԲ), պատրաստված խոսված տեքստի (TED-MDB) և ինքնաբուխ խոսված տեքստի Արդյունքները ցույց են տալիս, որ e2e-ի վերլուծումը գերազանցում է բոլոր տվյալների համակարգերի մյուս վերլուծության մեթոդները: Այնուամենայնիվ, արտադրողությունը նշանակալիորեն նվազում է PDTB-ից մինչև բոլոր այլ տվյալների համակարգերը: Մենք տրամադրում ենք ավելի գեղեցիկ վերլուծություն բնագավառի տարբերությունների և կապերի մասին, որոնք դժվար են վերլուծում, որպեսզի նշենք այն հատվածները, որտեղ շահույթ կարող է անել:', 'bn': 'বর্তমান পার্সের পদ্ধতি ব্যবহার করে সুস্পষ্ট কথোপকথনের সংযোগ চিহ্নিত করার জন্য বিভিন্ন উপায় ব্যবহার করে, কিন্তু তাদের কর্মকাণ্ড একে অপরের সাথে তুলনায় পরিণত করা হয়নি, আর স আমরা এখানে তিনটি পার্স পদ্ধতির প্রকাশ্য যোগাযোগ চিহ্নিত করার প্রদর্শনের বিষয়টি মূল্যায়ন করছি (পিডিটিবি e2e, লিন এনেট আল, ২০১৪; কনএল ২০১৫-এর বিজয়ী, ওয়াং এল, ২০১৫; এবং ডিসেন্ট ন আমরা এছাড়াও পরীক্ষা করি যে এই ব্যবস্থা বিভিন্ন তথ্য সংক্রান্ত টেক্সট (পিডিটিবি), লিখিত বৈজ্ঞানিক লেখা (বিওডিআরবি), কথা বলা টেক্সট (টেড-এমডিবি) এবং স্বতঃস্ ফলাফল দেখা যাচ্ছে যে e2e প্যারাস্টার সকল ডাটাসেটে অন্যান্য পার্স পদ্ধতি প্রদর্শন করে। তবে পিডিটিবি থেকে অন্যান্য তথ্য সংক্রান্ত প্রদর্শনীর ক্ষেত্রে গুরুত্বপূর্ণ ভাবে ফেলবে। We provide a more fine-grained analysis of domain differences and connectives that prove difficult to parse, in order to highlight the areas where gains can be made.', 'cs': 'Stávající metody parse používají různé přístupy k identifikaci explicitních diskurzních vazeb, ale jejich výkonnost nebyla ve srovnání s sebou důsledně hodnocena, ani nebyla důsledně hodnocena na jiných textech než na novinových článcích. Zde hodnotíme výkonnost při explicitní pojivové identifikaci tří parsových metod (PDTB e2e, Lin et al., 2014; vítěz CONLL2015, Wang et al., 2015; a DisSent, Nie et al., 2019) spolu s jednoduchou heuristikou. Dále zkoumáme, jak dobře se tyto systémy zobecňují na různé datové sady, konkrétně psaný novinový text (PDTB), psaný vědecký text (BioDRB), připravený mluvený text (TED-MDB) a spontánní mluvený text (Disco-SPICE). Výsledky ukazují, že parser e2e předčí ostatní parsovací metody ve všech datových sadách. Výkon však výrazně klesá z PDTB na všechny ostatní datové sady. Poskytujeme jemnější analýzu doménových rozdílů a konektiv, které se ukáží jako obtížné analyzovat, abychom zdůraznili oblasti, kde lze dosáhnout zisku.', 'bs': 'Postoje metode analize koriste različite pristupe za identifikaciju pojasnih veza s diskusijama, ali njihov učinkovit nije konsekventno procjenjen u usporedbi jedni drugima, niti su konsekventno procjenjivani na tekstu osim novinskih članaka. Ovdje procjenjujemo izvedbu na pojasnoj veznoj identifikaciji tri metode analize (PDTB e2e, Lin et al., 2014; pobjednik CONLL2015, Wang et al., 2015; i DisSent, Nie et al., 2019), zajedno s jednostavnim heurističkim. Također istražujemo kako dobro se ovi sistemi generalizuju na različite datasete, to je napisani tekst novina (PDTB), napisani naučni tekst (BioDRB), pripremljeni tekst (TED-MDB) i spontanski govorni tekst (Disco-SPICE). Rezultati pokazuju da e2e analizator iznosi druge metode analizacije u svim podacima. Međutim, izvedba značajno pada od PDTB do svih ostalih podataka. Mi pružamo detaljniju analizu razlika domena i veza koje dokazuju teško analizirati, kako bi osvjetlili područje gdje se može dobiti.', 'ca': "Els mètodes d'analització existents utilitzen enfocaments diferents per identificar connexions de discurs explícits, però el seu rendiment no s'ha evaluat constantment en comparació amb els altres, ni s'han evaluat constantment en text que no sigui en articles de diari. Aquí evaluem el desempeny en la identificació connectiva explícita de tres mètodes d'analització (PDTB e2e, Lin et al., 2014; el guanyador de CONLL2015, Wang et al., 2015; i DisSent, Nie et al., 2019), juntament amb una heurística simple. També examinem com s'generalitzen aquests sistemes a diferents conjunts de dades, a saber, text escrit en diari (PDTB), text científic escrit (BioDRB), text parlat preparat (TED-MDB) i text parlat espontànic (Disco-SPICE). Els resultats mostran que l'analitzador e2e supera els altres mètodes d'analització en tots els conjunts de dades. Però el rendiment disminueix significativament des de la PDTB a tots els altres conjunts de dades. Oferecem una anàlisi més fina de diferències de domini i connexions que resulten difícils d'analitzar, per destacar les àrees on es poden aconseguir guanys.", 'et': 'Olemasolevad parsimismeetodid kasutavad erinevaid lähenemisviise selgesõnaliste diskursuse sidemete tuvastamiseks, kuid nende tulemuslikkust ei ole üksteisega võrreldes järjekindlalt hinnatud, samuti ei ole neid järjekindlalt hinnatud muude tekstide peale ajaleheartiklite. Siin hindame kolme parsimismeetodi (PDTB e2e, Lin et al., 2014; CONLL2015 võitja, Wang et al., 2015; DisSent, Nie et al., 2019) tulemuslikkust koos lihtsa heuristikuga. Samuti uurime, kui hästi need süsteemid üldistavad erinevaid andmekogumeid, nimelt kirjalikku ajaleheteksti (PDTB), kirjalikku teaduslikku teksti (BioDRB), ettevalmistatud kõnelevat teksti (TED-MDB) ja spontaanset kõnelevat teksti (Disco-SPICE). Tulemused näitavad, et e2e parser on kõigis andmekogumites parem kui teised parsimismeetodid. Siiski langeb jõudlus PDTB-lt märkimisväärselt kõigile teistele andmekogumitele. Pakume põhjalikumat analüüsi domeenide erinevustest ja sidemetest, mida on raske analüüsida, et rõhutada valdkondi, kus kasu saab saavutada.', 'fi': 'Nykyiset jäsennysmenetelmät käyttävät erilaisia lähestymistapoja eksplisiittisten diskurssiyhteyksien tunnistamiseen, mutta niiden suorituskykyä ei ole arvioitu johdonmukaisesti toisiinsa verrattuna, eikä niitä ole arvioitu johdonmukaisesti muilla teksteillä kuin sanomalehtiartikkeleilla. Tässä arvioimme kolmen analyysimenetelmän (PDTB e2e, Lin et al., 2014; CONLL2015 voittaja, Wang et al., 2015; DisSent, Nie et al., 2019) suorituskykyä ja yksinkertaista heuristiikkaa. Tutkimme myös, miten hyvin nämä järjestelmät yleistyvät erilaisiin aineistoihin, kuten kirjoitettuun sanomalehtitekstiin (PDTB), kirjoitettuun tieteelliseen tekstiin (BioDRB), valmisteltuun puhuttuun tekstiin (TED-MDB) ja spontaaniin puhuttuun tekstiin (Disco-SPICE). Tulokset osoittavat, että e2e-jäsentäjä on kaikkien aineistojen muita jäsennysmenetelmiä parempi. Suorituskyky laskee kuitenkin merkittävästi PDTB:stä kaikkiin muihin tietokokonaisuuksiin. Tarjoamme yksityiskohtaisemman analyysin toimialueen eroista ja yhteyksistä, joita on vaikea tulkita, jotta voimme korostaa alueita, joilla voidaan saavuttaa tuloksia.', 'he': 'שיטות בדיקת קיימות משתמשות באמצעות גישות שונות לזהות קשרים דיבורים ברורים, אך ביצועיהם לא הוערכו באופן קבוע בהשוואה זה לזה, ולא הוערכו באופן קבוע על טקסט חוץ מאמרי עיתונים. אנחנו כאן מעריכים את ההופעה על זיהוי חיבורי ברור של שלוש שיטות בדיקת (PDTB e2e, Lin et al., 2014; המנצח של CONLL2015, Wang et al., 2015; DisSent, Nie et al., 2019), יחד עם heuristic פשוט. אנחנו גם בודקים כיצד המערכות האלה מתפשטות למערכות נתונים שונות, כלומר טקסט עיתון כתוב (PDTB), טקסט מדעי כתוב (BioDRB), טקסט דובר מוכן (TED-MDB) וטקסט דובר ספונטני (Disco-SPICE). התוצאות מראות שהמעבד e2e מוביל את שיטות ההעברה האחרות בכל קבוצות נתונים. עם זאת, ההופעה נופלת באופן משמעותי מהPDTB לכל קבוצות נתונים אחרות. אנו מספקים ניתוח מעולה יותר של הבדלים בתחום וקשרים שמוכיחים שקשה להעביר, כדי להדגיש את האזורים שבו ניתן לעשות רווחים.', 'sk': 'Obstoječe metode razčlenjanja uporabljajo različne pristope za prepoznavanje eksplicitnih diskurznih povezav, vendar njihova uspešnost ni bila dosledno ocenjena v primerjavi med seboj, niti niso bile dosledno ocenjene na besedilih, razen časopisnih člankih. Tukaj ocenjujemo uspešnost eksplicitne vezivne identifikacije treh metod razdeljevanja (PDTB e2e, Lin et al., 2014; zmagovalec CONLL2015, Wang et al., 2015; in DisSent, Nie et al., 2019), skupaj s preprosto heuristiko. Preučujemo tudi, kako dobro se ti sistemi posplošujejo na različne nabore podatkov, in sicer na pisno časopisno besedilo (PDTB), pisno znanstveno besedilo (BioDRB), pripravljeno govorjeno besedilo (TED-MDB) in spontano govorjeno besedilo (Disco-SPICE). Rezultati kažejo, da razčlenjevalnik e2e presega druge metode razčlenjevanja v vseh naborih podatkov. Vendar pa se zmogljivost znatno zmanjša s PDTB na vse druge nabore podatkov. Zagotavljamo bolj natančno analizo domenskih razlik in povezav, ki jih je težko razčleniti, da bi poudarili področja, kjer je mogoče doseči dobiček.', 'ha': "Yi amfani da shiryoyin parse da ke gaba, hanyõyi daban-daban dõmin a gane masu haɗi da magana masu bayyani, kuma amma ba a iya ƙaddara su daidai da jũna ba, kuma ba a ƙaddara su daidai a kan matsayin da ba'an da takardar magazine. Tuna kana kafin bayani da ke iya gane wasu hanyõyi uku (PDTB e2e, Lin et al., 2014; mai rinjãya wa CONLL2015, Wang et al., 2015; kuma Dissent, Nie et al., 2019), sami da wani haƙƙi mai sauƙi. Kamar haka, Muke jarraba cewa da waɗannan na'ura suna cikin tsari daban-daban, kamar rubũtin littãfin takardar da aka rubũta (PDTB), littãfin da aka sani (BioDRB), da aka yi tattalin littãfin da aka faɗa (TeD-MDB) da littãfin da aka faɗa (Disco-SPICE). Mataimakin ya nuna cewa parser e2e na samar da wasu hanyõyin parse cikin duk tsari. Amma, zaman shawarar da ke ƙara bayan daga PDTB zuwa duk tsari na daban. Munã samar da rabo mafi kyakkyawan masu farin ciki da haɗi waɗand a ke iya samun mutane da ke samun su da kuma don ka sami mutane da za'a yi ƙunci ga parse, dõmin ya nuna filayen da za'a iya samu.", 'jv': 'Jucah paten Awak dhéwé karo hal-hal ngerasakno kanggo Ketokani nggawe barang kelas telu method (PNT B e2e, Lin et al, 2013; bah dhéwé uristik dhéwé, Wang et al, 2013; lan DisSent, NI et al, 2011), lan akeh sistem heuristik. Awak dhéwé éntuk maneh sing sistem iki dadi nggawe dataset yang segala, sampeyan gambaran seneng kaper perintah (PNT B), seneng saiki-seneng pisan (BiDroB), gambaran seneng kaper (TID-MDB) lan kelangan seneng sak wis arep (Disk-SpaCIE). text Laptop" and "Desktop Awak dhéwé ngewehke tanggal akeh luwih dumadhi kanggo kalagayaan karo konnek sing nggawe barang nggawe, nggo nggawe barang nggawe barang kelas kapan kanggo dianggawe', 'bo': 'Existing parse methods use different approaches to identify explicit discourse connections, but their performance has not been consistently evaluated in comparison to each other, nor have they been evaluated consistently on text other than newspaper articles. ང་ཚོས་འདིར་སྔོན་ཕྱོགས་པའི་སྦྲེལ་མཐུད་ལམ་གསུམ་གྱི་ངོ་འཕྲད་འདི་གསལ་བཤད་ཀྱི་ཐབས་ལམ་ལ་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ཟིན་བྲིས་ཀྱི་མ་ལག་འདི་དག་གི་དོན་ཚན་གྱིས་ཡིག་ཆ་གསར་པའི་ཡིག་ཆ་ལ་ཇི་ལྟར་བསྟར་གསོག་ཏེ། e2ནི་དབྱེ་སྟངས་གནད་སྡུད་ཚན་ནང་གི་དབྱེ་སྟངས་གཞན་མིན་སྒྲིག་འགོད་བྱེད་ཀྱི་ཡོད་པ་ཤར་བ ཡིན་ནའང་། གྲུབ་སྐྱོད་འདི་PDTB ལས་གནད་སྡུད་གཞི་སྒྲིག་ཚན་གཞན་ཞིག་ལ་འགྱུར་འགྲོ We provide a more fine-grained analysis of domain differences and connectives that prove difficult to parse, in order to highlight the areas where gains can be made.'}
{'en': 'Revisiting Shallow Discourse Parsing in the PDTB-3 : Handling Intra-sentential Implicits', 'ar': 'إعادة النظر في تحليل الخطاب الضحل في PDTB-3: معالجة التداعيات البينية', 'pt': 'Revisitando a Análise de Discurso Raso no PDTB-3: Lidando com Implícitos Intra-sentenciais', 'es': 'Revisitando el análisis superficial del discurso en el PDTB-3: manejo de los implícitos intra-sentenciales', 'fr': "Revisiter l'analyse superficielle du discours dans le PDTB-3\xa0: gérer les implicites intra-sententiels", 'ja': 'PDTB -3における浅い話題の解析の再検討：意味内の扱い', 'zh': '重审PDTB-3中浅层语解析:处内感内隐', 'hi': 'PDTB-3 में उथले प्रवचन पार्सिंग पर पुनर्विचार करना: इंट्रा-सेवेंशियल Implicits को संभालना', 'ru': 'Повторное изучение неглубокого анализа дискурса в PDTB-3: устранение внутрипредметных последствий', 'ga': 'Athchuairt ar Pharsáil Dioscúrsa Éadomhain sa PDTB-3: Impleachtaí Idir-bhreithe a Láimhseáil', 'hu': 'Alacsony beszéd feldolgozása a PDTB-3-ban: Intra-sententiális implicitások kezelése', 'it': "Revisione dell'analisi del discorso superficiale nel PDTB-3: gestione degli impliciti intrasentimentali", 'ka': 'PDTB- 3- ში რევისტირება ჩართული დისკურსების პანელიზაცია: ინტერესენტიალური იმპლიციტების გასაკეთება', 'kk': 'PDTB- 3 дегенде теңдеу жалғыз дискурстарды талдау', 'el': 'Επανεξέταση της ανάλυσης ρηχόυ λόγου στο PDTB-3: χειρισμός ενδο-νοητικών συνεπειών', 'lt': 'Peržiūrėti PDTB-3 „Netinkamo diskurso analizavimą“: baudžiamojo pobūdžio pasekmių tvarkymas', 'ml': 'Revisiting Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits', 'mn': 'PDTB-3-д шинэчлэлтийг дахин ярилцаж байна: Интернет-өгүүлбэрийн шинжлэх ухаан', 'ms': 'Mengubahsuai Penghuraian Sekolah Gelap dalam PDTB-3: Mengurus Impliciti Dalam Perkataan', 'mt': 'Reviżjoni tal-Analiżi tad-Diskussjoni Mxekkla fil-PDTB-3: L-Immaniġġjar tal-Impliċitajiet Intra-Sentenzjali', 'ro': 'Revizuirea discursului superficial Parsing în PDTB-3: Manipularea implicărilor intrasentimentale', 'mk': 'Ревизирање на анализирањето на слободниот дискурс во PDTB-3: Работење со внатрешни речениции', 'pl': 'Ponowna analiza płytkiego dyskursu w PDTB-3: Postępowanie z implikatami wewnątrz-sentencjalnymi', 'no': 'Revisering av skal opplesing tolking i PDTB- 3: handtering av internsentensielle implementitet', 'si': 'PDTB- 3 වල ප්\u200dරවර්තනය කරන්න ශාලෝ හොයාගන්න', 'sr': 'Revizija Shallow Discourse Analyzing in the PDTB-3: Handling Intra-sentencial Implicits', 'so': 'Baadiyeynta baaritaanka Shallow Discourse in the PDTB-3: Handling Intra-sentential Implicits', 'sv': 'Revidering av grundligt diskurs Parsing i PDTB-3: Hantering av intra-sententiella implikationer', 'ta': 'PDTB- 3- ல் மஞ்சள் விஷயங்கள் பாசிங்களை மீள்நோக்குகிறது: முழுமையான செயல்பாடுகளை கையாளுகிறது', 'ur': 'PDTB-3 میں شالوئ ڈرسکورس پارسینگ دوباره کررہا ہے: انٹر-سنٹنسیل اثبات تحمل کررہا ہے', 'uz': 'Name', 'vi': 'Revising Shalow Discourse Parsing in the PDTB-3: handling Intra-sentency implicting', 'bg': 'Преразглеждане на плиткото обсъждане на дискурса в ПДТБ-3: справяне с вътресентенциални имплицити', 'hr': 'Revizija Shallow Discourse Analyzing in the PDTB-3: Handling intrsentencial Implicits', 'nl': 'Het opnieuw bekijken van ondiepe discoursanalyse in de PDTB-3: Behandeling van intrasententiele impliciten', 'da': 'Revidering af grundig diskurs Parsing i PDTB-3: Håndtering af intra-sentimentale implikationer', 'fa': 'بازگرداندن سخنرانی شالی در PDTB-3: تحمل عملکرد عملکرد داخلی', 'de': 'Revisiting Shallow Discourse Parsing in der PDTB-3: Umgang mit intrasentiellen Implikaten', 'id': 'Revising Shallow Discourse Analysis in the PDTB-3: Handling Intra-sentential Implicits', 'ko': '재론 PDTB-3 중의 얕은 문장 분석: 문장 내 은유 처리', 'sw': 'Kupitia mabadiliko ya Mazungumzo yenye rangi nyekundu katika PDTB-3: Kukabiliwa na matatizo ya kihisia', 'af': 'Hersiening Skaal Ontvaring Ontvaring in die PDTB- 3: Behandeling van Intersentensiele Inligtings', 'sq': 'Revisiting Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits', 'tr': 'PDTB-3 içinde janlaşdyrylýan Soňky Hatlary Çözümleme', 'am': 'ምስሉን በሌላ ስም አስቀምጥ', 'hy': 'PDTB-3-ի մեջ «Կարճ քննարկումներ» վերանայելը. Կարճ նախադասությունների ներսում հետևանքների վերաբերյալ', 'az': 'PDTB-3 içində Qıldırma Diskusiyalarını yeniləndirir: İçin Sözü İşləndirir', 'bn': 'Revisiting Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits', 'bs': 'Reviciranje Shallow Discourse Parsing in the PDTB-3: Handling intrsentencial Implicits', 'cs': 'Opakování analýzy mělkých diskusí v PDTB-3: manipulace s intrasentiálními implicity', 'et': 'Väikse diskursuse parsimise läbivaatamine PDTB-3-s: sensentiaalsete implitsiitide käsitlemine', 'ca': 'Revision Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits', 'fi': 'Pinnallisen diskurssin uudelleentarkastelu PDTB-3:ssa: Intra-sentential Implicits', 'jv': 'Name', 'he': 'Revising Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits', 'ha': 'KCharselect unicode block name', 'sk': 'Reviziranje plitvega razpravljanja v PDTB-3: obravnavanje posledic znotraj sententialnih', 'bo': 'Revisiting Shallow Discourse Parsing in the PDTB-3: Handling Intra-sentential Implicits'}
{'en': 'In the PDTB-3, several thousand implicit discourse relations were newly annotated within individual sentences, adding to the over 15,000 implicit relations annotated across adjacent sentences in the PDTB-2. Given that the position of the arguments to these intra-sentential implicits is no longer as well-defined as with inter-sentential implicits, a discourse parser must identify both their location and their sense. That is the focus of the current work. The paper provides a comprehensive analysis of our results, showcasing ', 'ar': 'في PDTB-3 ، تم التعليق حديثًا على عدة آلاف من علاقات الخطاب الضمني داخل الجمل الفردية ، مما أضاف إلى أكثر من 15000 من العلاقات الضمنية المشروحة عبر الجمل المجاورة في PDTB-2. بالنظر إلى أن موقف الحجج لهذه الآثار الضمنية لم يعد معرّفًا جيدًا كما هو الحال مع التضمينات بين الحواس ، يجب على المحلل اللغوي للخطاب تحديد موقعها وإحساسها. هذا هو محور العمل الحالي. تقدم الورقة تحليلاً شاملاً لنتائجنا ، وتعرض أداء النموذج في ظل سيناريوهات مختلفة ، وتشير إلى القيود وتلاحظ الاتجاهات المستقبلية.', 'fr': "Dans le PDTB-3, plusieurs milliers de relations de discours implicites ont été récemment annotées dans des phrases individuelles, s'ajoutant aux plus de 15 000 relations implicites annotées dans des phrases adjacentes dans le PDTB-2. Étant donné que la position des arguments de ces implicites intra-sententiels n'est plus aussi bien définie que celle des arguments implicites inter-sententiels, un analyseur de discours doit identifier à la fois leur emplacement et leur sens. C'est le point central des travaux actuels. Le document fournit une analyse complète de nos résultats, en présentant les performances du modèle dans différents scénarios, en soulignant les limites et en notant les orientations futures.", 'pt': 'No PDTB-3, vários milhares de relações discursivas implícitas foram recentemente anotadas em sentenças individuais, somando-se às mais de 15.000 relações implícitas anotadas em sentenças adjacentes no PDTB-2. Dado que a posição dos argumentos para esses implícitos intra-sentenciais não é mais tão bem definida quanto para os implícitos inter-sentenciais, um analisador de discurso deve identificar tanto sua localização quanto seu sentido. Esse é o foco do trabalho atual. O artigo fornece uma análise abrangente de nossos resultados, mostrando o desempenho do modelo em diferentes cenários, apontando limitações e apontando direções futuras.', 'es': 'En el PDTB-3, se anotaron varios miles de relaciones discursivas implícitas en oraciones individuales, lo que se suma a las más de 15.000 relaciones implícitas anotadas en oraciones adyacentes en el PDTB-2. Dado que la posición de los argumentos de estos implícitos intra-sentenciales ya no está tan bien definida como con los implícitos intersentenciales, un analizador del discurso debe identificar tanto su ubicación como su sentido. Ese es el objetivo del trabajo actual. El documento proporciona un análisis exhaustivo de nuestros resultados, que muestra el rendimiento del modelo en diferentes escenarios, señala las limitaciones y señala las direcciones futuras.', 'zh': 'PDTB-3 中,于单句新注数千隐式语,增 PDTB-2 中邻句注之 15,000 余隐式。 鉴此隐式之参数,非复句隐式之明,语解析器必识其位义。 此当前工作之重也。 详析异体,指局限性指方来。', 'ja': 'PDTB -3では、数千の暗黙の言説関係が個々の文の中で新たに注釈され、PDTB -2で隣接する文にわたって注釈された15,000を超える暗黙の関係に追加された。これらの文内暗示に対する引数の位置が、文間暗示と同様に十分に定義されていないことを考えると、トークン構文解析器は、それらの位置とそれらの感覚の両方を識別しなければならない。それが今の仕事の焦点です。この論文では、私たちの結果の包括的な分析を提供し、さまざまなシナリオでモデルのパフォーマンスを示し、限界を指摘し、将来の方向性を指摘します。', 'hi': 'पीडीटीबी -3 में, कई हजार अंतर्निहित प्रवचन संबंधों को व्यक्तिगत वाक्यों के भीतर नए एनोटेट किया गया था, जो पीडीटीबी -2 में आसन्न वाक्यों में एनोटेट किए गए 15,000 से अधिक अंतर्निहित संबंधों को जोड़ते थे। यह देखते हुए कि इन इंट्रा-सेवेंशियल implicits के लिए तर्कों की स्थिति अब अंतर-सेंटेन्शियल implicits के साथ अच्छी तरह से परिभाषित नहीं है, एक प्रवचन पार्सर को उनके स्थान और उनकी भावना दोनों की पहचान करनी चाहिए। यही वर्तमान कार्य का केन्द्र है। पेपर हमारे परिणामों का एक व्यापक विश्लेषण प्रदान करता है, विभिन्न परिदृश्यों के तहत मॉडल प्रदर्शन का प्रदर्शन करता है, सीमाओं को इंगित करता है और भविष्य की दिशाओं को नोट करता है।', 'ru': 'В PDTB-3 несколько тысяч неявных отношений дискурса были недавно аннотированы в отдельных предложениях, добавляя к более чем 15 000 неявных отношений, аннотированных между смежными предложениями в PDTB-2. С учетом того, что позиция аргументов в отношении этих внутрисущественных импликаций более не столь четко определена, как в отношении межсущественных импликаций, анализатор дискурса должен идентифицировать как их местоположение, так и их смысл. Именно в этом состоит суть нынешней работы. В документе представлен всесторонний анализ наших результатов, демонстрируется эффективность модели при различных сценариях, указываются ограничения и отмечаются будущие направления.', 'ga': 'Sa PDTB-3, rinneadh na mílte caidreamh dioscúrsa intuigthe a anótáil as an nua laistigh de phianbhreitheanna aonair, ag cur leis an mbreis agus 15,000 caidreamh intuigthe atá anótáilte thar phianbhreitheanna cóngaracha sa PDTB-2. Ós rud é nach bhfuil suíomh na n-argóintí i leith na n-intuigeachtaí inbhreithe seo chomh sainmhínithe a thuilleadh agus atá le hintuigthe idir-abairtí, ní mór do pharsálaí dioscúrsa a suíomh agus a gciall a shainaithint. Sin é fócas na hoibre reatha. Soláthraíonn an páipéar anailís chuimsitheach ar ár dtorthaí, ag taispeáint feidhmíocht samhail faoi chásanna éagsúla, ag cur in iúl teorainneacha agus ag tabhairt faoi deara treo na todhchaí.', 'ka': 'PDTB-3-ში, რამდენიმე ათესობით ინფლიციტური დისკურსების შესახებ ახალი ინფლიციური სიტყვებში დამატებული 15 000 ინფლიციტური შესახებ, რომელიც PDTB-2-ში დამატებული ახალი სიტყვების შესახებ. აღმოჩნეთ, რომ არგუმენტების პოციაცია ამ ინტერესენციალური ინფლიციტისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვი ეს არის მიმდინარე სამუშაოს ფონსკური. ჩვენი შედეგების ყველაფერი ანალიზია, რომელიც ჩვენი მოდეგების გამოსახულება განსხვავებული სინარიოში, რომელიც განსხვავებული სინარიოში დააჩვენება განსხვავებულებები და მომავალეობის', 'el': 'Στο PDTB-3, αρκετές χιλιάδες σιωπηρές σχέσεις λόγου σχολιάστηκαν πρόσφατα μέσα σε μεμονωμένες προτάσεις, προσθέτοντας στις πάνω από 15.000 σιωπηρές σχέσεις που σχολιάστηκαν σε γειτονικές προτάσεις στο PDTB-2. Δεδομένου ότι η θέση των επιχειρημάτων σε αυτά τα ενδονοητικά υπονοούμενα δεν είναι πλέον τόσο καλά καθορισμένη όσο με τα ενδονοητικά υπονοούμενα, ένας αναλυτής λόγου πρέπει να προσδιορίσει τόσο τη θέση τους όσο και την αίσθηση τους. Αυτό είναι το επίκεντρο της τρέχουσας εργασίας. Η εργασία παρέχει μια ολοκληρωμένη ανάλυση των αποτελεσμάτων μας, παρουσιάζοντας την απόδοση του μοντέλου σε διαφορετικά σενάρια, επισημαίνοντας περιορισμούς και σημειώνοντας μελλοντικές κατευθύνσεις.', 'hu': 'A PDTB-3-ban több ezer implicit diskurzus kapcsolatot jelentettek újonnan az egyes mondatokban, ami hozzáadta a PDTB-2 szomszédos mondatainak közötti több mint 15 000 implicit kapcsolatot. Tekintettel arra, hogy az érvek álláspontja ezekkel az érzékenységi implicitekkel szemben már nem olyan jól definiált, mint az érzékenységi implicitekkel szemben, a diskurzus elemzőnek azonosítania kell helyüket és érzéküket. Ez a jelenlegi munka középpontjában áll. A tanulmány átfogó elemzést nyújt eredményeinkről, bemutatja a modell teljesítményét különböző forgatókönyvek között, rámutat a korlátokra és megjegyzi a jövőbeli irányokat.', 'kk': 'PDTB-3 дегенде бірнеше мұнда белгілі сөйлемелерде жаңа сөйлемелерді жаңа белгілеп, PDTB-2 дегенде 15 000 артық белгілі қатынастарды қосу үшін. Аргументтердің орналасуы бұл ішкі сөздердің имплициттерінің орналасуы болса, бұл сөздердің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің мәлімет Бұл назардағы жұмысының назары. Қағаз нәтижелерімізді толық анализ береді, түрлі сценариялардың істеу үлгісін көрсетеді, шектерді көрсетеді және болашақ бағыттарды көрсетеді.', 'it': "Nel PDTB-3, diverse migliaia di relazioni implicite di discorso sono state recentemente annotate all'interno di singole frasi, aggiungendo alle oltre 15.000 relazioni implicite annotate tra frasi adiacenti nel PDTB-2. Dato che la posizione degli argomenti a questi impliciti intra-sentenziali non è più ben definita come con impliciti inter-sentenziali, un parser di discorso deve identificare sia la loro posizione che il loro senso. Questo è il fulcro del lavoro in corso. Il documento fornisce un'analisi completa dei nostri risultati, mostrando le prestazioni del modello in diversi scenari, indicando limitazioni e prendendo nota delle direzioni future.", 'mk': 'Во ПДТБ-3, неколку илјади имплицитни дискурсни односи беа ново анотирани во рамките на индивидуалните реченици, додавајќи на над 15.000 имплицитни односи анотирани во соседните реченици во ПДТБ-2. Со оглед на тоа што позицијата на аргументите за овие внатрешни имплицити не е веќе толку добро дефинирана како и за меѓу речениците имплицити, дискурсниот анализатор мора да ја идентификува нивната локација и нивната смисла. Тоа е фокусот на сегашната работа. Документот обезбедува комплетна анализа на нашите резултати, покажува резултати на моделот под различни сценарија, истакнува ограничувања и забележува идни насоки.', 'lt': 'PDTB-3 keletas tūkstančių netiesioginių diskursinių santykių buvo naujai užfiksuoti atskiruose sakiniuose, papildant daugiau kaip 15 000 netiesioginių santykių, užfiksuotų gretimuose PDTB-2 sakiniuose. Atsižvelgiant į tai, kad argumentų, susijusių su šiais tarpsakiniais implicitais, pozicija jau nėra taip gerai apibrėžta kaip ir tarpsakiniais implicitais, diskurso analizatorius turi nustatyti ir jų vietą, ir jų prasmę. Tai yra dabartinio darbo esmė. Dokumente pateikiama išsami mūsų rezultatų analizė, modelio rezultatai parodomi įvairiais scenarijais, nurodomi apribojimai ir nurodomos būsimos kryptys.', 'ms': 'Dalam PDTB-3, beberapa ribu hubungan percakapan secara implicit baru dicatat dalam kalimat individu, menambah kepada lebih dari 15,000 hubungan implicit yang dicatat melalui kalimat bersebelahan dalam PDTB-2. Oleh kerana kedudukan argumen untuk implicit intra-kalimat ini tidak lagi ditakrif dengan baik seperti dengan implicit inter-kalimat, penghurai diskors mesti mengenalpasti kedua-dua lokasi dan rasa mereka. Itulah fokus kerja semasa. Kertas ini menyediakan analisis meliputi keputusan kita, menunjukkan prestasi model di bawah skenario yang berbeza, menunjukkan keterangan dan memperhatikan arah masa depan.', 'ml': 'പിഡിറ്റിബി-3-ല്\u200d, പിഡിറ്റിബി-2-ലെ അടുത്തുള്ള വാക്കുകളില്\u200d പ്രഖ്യാപിക്കപ്പെട്ടിരിക്കുന്ന വാക്കുകളില്\u200d പല ആയിരം സംസാര ബന്ധങ്ങള്\u200d പുതുതായ ഇത്തരം വാദ്യാഭ്യത്തിന്റെ സ്ഥാനം ഇനി വിശദീകരിച്ചിരിക്കുന്നില്ലെന്ന് തോന്നിയാല്\u200d ഒരു സംസാരിക്കുന്ന സ്ഥാനം അവരുടെ സ്ഥാനത്തെയും മനസ്സിലെ അതാണ് ഇപ്പോഴത്തെ ജോലിയുടെ ശ്രദ്ധ. ഈ പത്രത്തില്\u200d നമ്മുടെ ഫലങ്ങളുടെ പൂര്\u200dണ്ണമായ പരിശോധന നല്\u200dകുന്നു, വ്യത്യസ്തമായ കാഴ്ചകളില്\u200d മോഡല്\u200d പ്രകടനം കാണിക്കുന്നു. അതിരുകള്\u200d', 'mt': 'In the PDTB-3, several thousand implicit discourse relations were newly annotated within individual sentences, adding to the over 15,000 implicit relations annotated across adjacent sentences in the PDTB-2.  Minħabba li l-pożizzjoni tal-argumenti għal dawn l-impliċiti intrasentenzjali ma għadhiex definita tajjeb daqs ma’ impliċiti intersentenzjali, analizzatur ta’ diskors għandu jidentifika kemm il-post tagħhom kif ukoll is-sens tagħhom. Dan huwa l-fokus tax-xogħol attwali. Id-dokument jipprovdi analiżi komprensiva tar-riżultati tagħna, juri l-prestazzjoni tal-mudell taħt xenarji differenti, jindika l-limitazzjonijiet u jinnota d-direzzjonijiet futuri.', 'pl': 'W PDTB-3, kilka tysięcy domyślnych relacji dyskursowych zostało nowo adnotacjonowanych w poszczególnych zdaniach, dodając do ponad 15.000 domyślnych relacji adnotacji w sąsiednich zdaniach PDTB-2. Biorąc pod uwagę, że pozycja argumentów wobec tych domniemanych wewnątrz-sentencjalnych nie jest już tak dobrze zdefiniowana jak w przypadku domniemanych między-sentencjalnych, parser dyskursu musi zidentyfikować zarówno ich lokalizację, jak i sens. Na tym skupia się obecna praca. Artykuł zawiera kompleksową analizę naszych wyników, przedstawiając wydajność modelu w różnych scenariuszach, wskazując ograniczenia i wskazując kierunki przyszłości.', 'ro': 'În PDTB-3, câteva mii de relații implicite de discurs au fost adnotate recent în cadrul propozițiilor individuale, adăugând la cele peste 15.000 de relații implicite adnotate în propozițiile adiacente din PDTB-2. Având în vedere că poziția argumentelor față de acești impliciti intra-sentințiali nu mai este la fel de bine definită ca și în cazul implicitelor inter-sentințiale, un parser de discurs trebuie să identifice atât locația, cât și simțul lor. Acesta este punctul central al activităţii actuale. Lucrarea oferă o analiză cuprinzătoare a rezultatelor noastre, prezentând performanța modelului în diferite scenarii, subliniind limitările și menționând direcțiile viitoare.', 'sr': 'U PDTB-3, nekoliko hiljada implicitnih diskurskih odnosa su novo annotirane unutar individualnih rečenica, dodajući preko 15.000 implicitnih odnosa koje su annotirane preko susjednih rečenica u PDTB-2. S obzirom na to da položaj argumenata ovim intra-sentencijalnim implicitima više nije dobro definisan kao i sa međusentencijalnim implicitima, analizator diskursa mora da identifikuje njihovu lokaciju i njihov smisao. To je fokus trenutnog posla. U novinama pruža sveobuhvatnu analizu naših rezultata, pokazujući modelnu funkciju u različitim scenarijama, ukazujući na ograničenja i primjećujući buduće upute.', 'so': 'PDTB-3 waxaa cusboonaysiiyey muddo gaar ah, waxaana lagu daray 15,000 oo ka badan xiriir ku saabsan xiliga PDTB-2. Sida darteed qofka muran ku haysta waxyaabaha ay ku haystaan waxyaabaha uu ku haysto marna looma yaqaan sida loo yaqaan waxyaabaha kale ee maandooriyaha dhexe, waa in loo caddeeyaa meesha ay joogto iyo garashada. taasi waa muhiimka shaqada hada. Qoraalku wuxuu sameynayaa fashihiisa oo dhan, wuxuuna tusaa muuqashada muusikada oo ka hooseeya aragtida kala duduwan, wuxuuna tusaa xaduudaha iyo hagitaanka mustaqbalka.', 'mn': 'PDTB-3 дахь хэдэн мянга мянган ярианы харилцаа нь хувийн өгүүлбэр дотор шинэ нээлттэй болж, PDTB-2 дахь ойролцоогоор 15,000 гаруй харилцаа нэмэгдсэн. Эдгээр дотоод өгүүлбэртэй аргументын байр суурь нь илүү олон өгүүлбэртэй адилхан тодорхойлдоггүй учраас ярианы хуваарч нь тэдний байр суурь болон мэдрэмж хоёуланг тодорхойлж чадна. Энэ бол одоогийн ажлын төвлөрөл. Энэ цаас бидний үр дүний бүрэн шинжилгээг гаргаж, загварын үйл ажиллагааг өөр төрлийн хувилбаруудын дотор харуулж, хязгаарлалтыг харуулж, ирээдүйн замаар анзаарч байна.', 'sv': 'I PDTB-3 kommenterades flera tusen implicita diskursrelationer nyligen inom enskilda meningar, vilket adderade till de över 15 000 implicita relationerna kommenterade över angränsande meningar i PDTB-2. Med tanke på att argumentets ställning till dessa intrasentimentala implicit inte längre är lika väl definierad som med inter-sentimentala implicit, måste en diskurstolkare identifiera både deras läge och deras känsla. Det är det aktuella arbetets fokus. Uppsatsen ger en omfattande analys av våra resultat, visar modellprestanda under olika scenarier, pekar på begränsningar och noterar framtida riktningar.', 'no': 'I PDTB-3 vart fleire tusen implisitte diskursrelasjonar nytt notata i individuelle setningar, og legg til over 15 000 implisitte relasjonar som er notata over tilhøyrande setningar i PDTB-2. Given at posisjonen av argumentene til desse innsentanselle implisitetene er ikkje lenger så godt definert som med intersentanselle implisiteten, må ein diskursanalyser identifisera både sitt plassering og sin følelse. Dette er fokusen på gjeldande arbeid. Papiret gjev eit komplett analyse av resultatene våre, viser modellen i ulike scenarior, viser avgrensingar og merker framtidige retningar.', 'ta': 'PDTB-3-ல், பல ஆயிரம் உடைய பேச்சு தொடர்புகள் தனித்தனியாக வாக்கியங்களில் புதிதாக துக்கப்பட்டது, மேலும் 15,000 அணுகார வாக்கியங்களில் உள்ள வாக்குகள் மூலம்  இந்த இடைவெளிப்பாடுகளுக்கான வார்ப்புகளின் நிலையில் இப்போது விவரிக்கப்படவில்லை என்றால், ஒரு பேச்சு விளக்கம் தங்கள் இடத்தையும் அவர்கள் உணர்வையும இது தற்போதைய வேலையின் கவனம். காகிதத்தில் எங்கள் முடிவுகளின் முழுமையான ஆய்வு, வேறு காட்சிகளின் கீழ் மாதிரி செயல்பாட்டை காட்டுகிறது, எல்லைகளை குறி', 'si': 'PDTB-3 වලින්, සම්පූර්ණ සංවිධානය සම්බන්ධයක් වෙනුවෙන් වෙනුවෙන් වෙනුවෙන් ප්\u200dරතිකාර කතා කරනවා, සම්බන්ධ වෙනුවෙන් ප්\u200dරතිකාර කතා කර Given that the location of the argment to this intra-senserial implicits is no more as well-definition as with inter-senserial implicits, a Talk Parzer must ID both its location and its senses. ඒක තමයි දැන් වැඩේ අවධානය. පත්තුරේ අපේ ප්\u200dරතිචාර විශ්ලේෂණයක් පෙන්වන්නේ, වෙනස් සිද්ධ විදියට පෙන්වන්න මඩේල් ප්\u200dරතිචාරයක් පෙන්වන්න', 'ur': 'PDTB-3 میں چند ہزار مستحکم گفتگو رابطہ شخصی جماعت کے اندر نئی دکھائی گئی تھی، اور پانچ ہزار مستحکم رابطہ کے ساتھ PDTB-2 کے نزدیک جماعتوں میں اضافہ کی گئی تھی۔ اس وجہ سے کہ ان اندر-سنٹنسیول کے معاملات کی موقعیت ان کے معاملات کے ساتھ اس طرح اچھی طرح معلوم نہیں ہوتی، ایک گفتگو پارٹر کو ان کی موقعیت اور ان کی سمجھ کا معلوم کرنا چاہیے۔ یہ موجود کام کا منظور ہے۔ یہ کاغذ ہمارے نتائج کا ایک محکم تحقیق دیتا ہے، مختلف سناریوں کے اندر موڈل کی عمدگی دکھاتا ہے، محدودیت کو دکھاتا ہے اور مستقبل طریقوں کو دکھاتا ہے۔', 'uz': "PDTB-3 yilda, bir necha minglab ma'lum munosabatlar bir xil so'zlar ichida yangi bir so'zlar ichida yangilangan, PDTB-2 sohasida keladigan 15 ming mingdan ortiq munosabatlar qo'shiladi. Given that the position of the arguments to these intra-sentential implicits is no longer as well-defined as with inter-sentential implicits, a discourse parser must identify both their location and their sense.  Bu joriy ishning fokusi. Qogʻoz natijalarimizning natijalarimizni muhimiy analyzer qiladi, boshqa holatda model bajarishni ko'rsatadi, chegaralarni ko'rsatadi va kelajakdagi tizimlarni ko'rsatadi.", 'vi': 'Trong PDTB-3, hàng ngàn mối quan hệ ngôn ngữ ngầm được chú ý mới trong các câu cá nhân, thêm vào mức độ mười nghìn quan hệ ngầm được chú ý qua các câu tiếp theo trong PDTB-2. Do quan điểm của những đối tượng này không bị ảnh hưởng bởi những hình ảnh nội bộ. Nó không còn được xác định rõ ràng như là có ảnh hưởng liên kết, nên người phân tích phải xác định cả địa điểm và cảm xúc của họ. Đó là tiêu điểm của công việc hiện tại. Tờ giấy cung cấp một phân tích toàn diện về kết quả của chúng ta, hiển thị hiệu ứng mô hình dưới các tình huống khác nhau, chỉ ra giới hạn và ghi chú hướng dẫn tương lai.', 'da': 'I PDTB-3 blev flere tusinde implicitte diskursrelationer nykommenteret inden for enkelte sætninger, hvilket tilføjede de over 15.000 implicitte relationer kommenteret på tværs af tilstødende sætninger i PDTB-2. I betragtning af at argumenternes position til disse intra-sententielle implicitter ikke længere er så veldefineret som med inter-sententielle implicitter, skal en diskursfortolker identificere både deres placering og deres sans. Det er fokus for det nuværende arbejde. Artiklen giver en omfattende analyse af vores resultater, viser modellens ydeevne under forskellige scenarier, peger på begrænsninger og noterer fremtidige retninger.', 'bg': 'В PDTB-3 няколко хиляди имплицитни дискурсни отношения са нанесени в отделните изречения, добавяйки към над 15 000 имплицитни връзки, анотирани в съседните изречения в PDTB-2. Като се има предвид, че позицията на аргументите към тези вътресентенциални имплицити вече не е толкова добре дефинирана, колкото при междусентенциалните имплицити, дискурсният анализатор трябва да идентифицира както тяхното местоположение, така и техния смисъл. Това е фокусът на настоящата работа. Статията предоставя изчерпателен анализ на нашите резултати, показвайки представянето на модела при различни сценарии, посочвайки ограниченията и отбелязвайки бъдещите насоки.', 'nl': "In de PDTB-3 werden enkele duizenden impliciete discoursrelaties nieuw geannoteerd binnen individuele zinnen, wat bijdraagt aan de meer dan 15.000 impliciete relaties die geannoteerd zijn over aangrenzende zinnen in de PDTB-2. Aangezien de positie van de argumenten ten opzichte van deze intra-sententiele implicieten niet langer zo goed gedefinieerd is als bij intersententiele implicieten, moet een discoursparser zowel hun locatie als hun betekenis identificeren. Dat is de focus van het huidige werk. Het artikel geeft een uitgebreide analyse van onze resultaten, toont modelprestaties onder verschillende scenario's, wijst beperkingen aan en geeft toekomstrichtingen aan.", 'de': 'In der PDTB-3 wurden mehrere tausend implizite Diskursbeziehungen innerhalb einzelner Sätze neu annotiert, was zu den über 15.000 impliziten Beziehungen hinzufügte, die über benachbarte Sätze im PDTB-2 annotiert wurden. Da die Position der Argumente zu diesen intrasentiellen Impliziten nicht mehr so genau definiert ist wie bei intersentiellen Impliziten, muss ein Diskursparser sowohl ihren Standort als auch ihren Sinn identifizieren. Das ist der Schwerpunkt der aktuellen Arbeit. Das Papier bietet eine umfassende Analyse unserer Ergebnisse, zeigt die Modellleistung unter verschiedenen Szenarien auf, weist auf Einschränkungen und zukünftige Richtungen hin.', 'id': 'Dalam PDTB-3, beberapa ribu hubungan diskors implicit baru saja dicatat dalam kalimat individu, menambah pada lebih dari 15.000 hubungan implicit yang dicatat di dalam kalimat dekat di PDTB-2. Karena posisi argumen untuk implicit intra-kalimat ini tidak lagi terdefinisi dengan baik seperti dengan implicit inter-kalimat, penganalis diskors harus mengidentifikasi kedua lokasi dan rasa mereka. Itulah fokus pekerjaan saat ini. The paper provides a comprehensive analysis of our results, showcasing model performance under different scenarios, pointing out limitations and noting future directions.', 'ko': 'PDTB-3에서는 단일 문장에 수천 개의 내은어편 관계를 새로 주석했고, PDTB-2에서는 인접 문장에 1천500여개의 내은어편 관계를 주석했다.이 문장 안에 숨겨진 논점의 위치가 문장 사이에 숨겨진 논점처럼 명확하지 않기 때문에 문장 분석기는 반드시 그들의 위치와 의미를 식별해야 한다.이것은 현재 업무의 중점이다.본고는 우리의 결과를 전면적으로 분석하여 모델이 서로 다른 장면에서의 성능을 보여주고 한계성을 지적하며 미래의 방향을 제시했다.', 'fa': 'در PDTB-3، تعداد هزار رابطه\u200cهای سخنرانی معمولی در مجازات جدید در مجازات جدید مشخص شده\u200cاند، و با اضافه بیش از ۱۵ هزار رابطه\u200cهای معمولی که در مجازات نزدیک در PDTB-2 مشخص شده\u200cاند. با توجه به اینکه موقعیت arguments به این احساسات داخل احساسات دیگر همانطور با احساسات بین احساسات تعریف شده نیست، یک مشترک گفتگو باید موقعیت و احساسات آنها را شناسایی کند. این تمرکز کار فعلی است. این کاغذ یک تحلیل کامل از نتیجه\u200cهایمان را پیشنهاد می\u200cکند، نمایش نمونه\u200cهای مختلف در سیناریو\u200cهای مختلف، نشان می\u200cدهد محدودیت\u200cها و توجه به مسیرهای آینده.', 'tr': "PDTB-3'de, PDTB-2'de birnäçe müň ilat sözleriň içinde täze sözleriň ýüzüne golaýlaýardy. Çünkü şu intra-sentencial sylaglaryň ýerini hem beýleki sylaglary bilen tanymaly däldir. Bir diskurs tanyşçysy hem olaryň ýerini hem olaryň duýgyny tanymaly. Häzirki işiň fokusy. Kagyzyň netijelerimiziň daňlap çözümlerini saýlaýar, dürli senaryýalaryň içine nusgalary görkez we gelejek yönlerini görkez.", 'hr': 'U PDTB-3, nekoliko tisuća implicitnih veza s diskusijama novo je navedeno unutar pojedinačnih kazna, dodajući preko 15.000 implicitnih odnosa koje su navedene preko susjednih kazna u PDTB-2. S obzirom da položaj argumenata ovim uvjetnim implicitima više nije dobro definiran kao i sa međusentencijalnim implicitima, razmatrač diskusija mora identificirati njihovu lokaciju i njihov smisao. To je fokus trenutnog posla. U novinama se pruža sveobuhvatna analiza naših rezultata, pokazuje model učinkovitost u različitim scenarijama, ukazujući na ograničenja i primjećujući buduće upute.', 'af': "In die PDTB-3 was verskeie duisend inplisite diskursieverhoudings nuwe in individuele setings aangeteken, toe by die meer 15,000 inplisite verhoudings aangeteken deur aankomstige setings in die PDTB-2. As die posisie van die argumente tot hierdie intra-sentenciale implosies nie meer as goed gedefinieerd soos met inter-sentenciale implosies nie, moet 'n diskursie ontwerker beide hul ligging en hul sens identifiseer nie. Dit is die fokus van die huidige werk. Die papier verskaf 'n kompleksitele analisie van ons resultate, wys model prestasie onder verskillende scenarios, wys beperkeninge en aanmerk toekomstige rigtings.", 'sq': 'Në PDTB-3, disa mijëra marrëdhënie diskursore implicite u shënuan sapo brenda fjalëve individuale, duke shtuar mbi 15,000 marrëdhënie implicite të shënuara nëpërmjet fjalëve të afërta në PDTB-2. Duke pasur parasysh se pozicioni i argumenteve ndaj këtyre impliciteteve brenda-dënimeve nuk është më i përcaktuar siç është me implicitetet ndër-dënime, një analizues diskursi duhet të identifikojë si vendndodhjen e tyre ashtu edhe kuptimin e tyre. Kjo është fokusi i punës aktuale. Gazeta ofron një analizë tërësore të rezultateve tona, duke treguar performancën e modelit në skenarë të ndryshme, duke vënë në dukje kufizimet dhe duke vënë në dukje drejtimet e ardhshme.', 'am': 'በPDTB-3 ውስጥ ብዙ ሺህ የውይይት ግንኙነት በአካባቢው ፍርድ ውስጥ አዲስ ግንኙነት አሰቃየዋል፡፡ በተመለከተ ጊዜ የእነዚህ ተቃዋሚዎች ስሜት እና ስሜታቸውን ማረጋገጥ እና ማሰናከል እና ማሰናከል የሚችሉበት የግንኙነት ተቃዋሚ ግንኙነት ግንኙነት ማረጋገጥ ያስፈልጋል፡፡ ይሄ የአሁኑ ሥራ ምሳሌ ነው:: የፕሬዝቡ ፍሬዎቻችንን ሙሉ የሚያሳውቅ ትምህርት የሚያደርግ፣ በተለየ ባሕላዊ ሁኔታዎችን የሚያሳየው ሞዴል ድምፅ፣ ግንኙነቶችን እና የቀድሞውን መንገድ የሚያሳየው ነው፡፡', 'sw': 'Katika chama cha PDTB-3, mahusiano ya mazungumzo elfu kadhaa ya watu maarufu yaliguswa ndani ya hukumu binafsi, na kuongeza mahusiano ya watu zaidi ya 15,000 yanayotangazwa katika hukumu za karibuni katika PDTB-2. Kutokana na kuwa msimamo wa hoja kwa matatizo haya yanayohusiana na mambo yanayohusiana na mambo yanayohusiana na mambo yanayohusiana, mjadala wa mazungumzo lazima kutambua sehemu zao na hisia zao. Hiyo ndiyo lengo la kazi ya sasa. Gazeti hilo linatoa uchambuzi wa kina wa matokeo yetu, kuonyesha performance of model chini ya mitazamo tofauti, ikionyesha vizuizi na kuonyesha maelekezo ya baadaye.', 'bn': 'পিডিটিবি-৩-এ পিডিটিবি-২-এ প্রায় ১৫,০০০ জনেরও বেশি প্রকাশিত যোগাযোগ সম্পর্ক নতুন ব্যক্তিগত কারাদণ্ডের মধ্যে নতুন বিরক্তিকর হয়েছে, যার মধ্যে পি যেহেতু এই বিষয়গুলোর প্রতি বিতর্কের অবস্থান এখনো সুন্দর বিষয়টি নির্ধারণ করা যায় না যেহেতু সেন্টেন্টিলের মধ্যে বিষয়বস্তুর সাথে, একটি কথোপকথন প্যার এটাই বর্তমান কাজের মনোযোগ। এই পত্রিকাটি আমাদের ফলাফলের সম্পর্কে বিস্তারিত বিশ্লেষণ প্রদান করেছে, বিভিন্ন দৃশ্যের নীচে মডেল প্রদর্শন করা হয়েছে, যারা সীমাবদ', 'az': 'PDTB-3 içində, PDTB-2 içində yaxın sözlərdə bildirilmiş neçə min müəyyən müzakirə əlaqələri yeni təbliğ edildi. Bu iç-sentenci implisitlərə olan argumentlərin posisiyası artıq müxtəlif implisitlərlə eyni qədər tanımlı deyildir, danışma ayırıcısı onların yerini və hissini tanımlı olmalı. Şimdiki işin fokusu budur. Kağıt sonuçlarımızın müxtəlif analizisini, modellərin performansını müxtəlif scenariyaların altında göstərir, hədləri göstərir və gələcək yönəltmələri nəzərdə edir.', 'bs': 'U PDTB-3, nekoliko tisuća implicitnih odnosa o diskusijama novo je navedeno unutar pojedinačnih kazna, dodajući preko 15.000 implicitnih odnosa koje su navedene u susjednim kaznama u PDTB-2. S obzirom na to da položaj argumenata ovim intra-sentencijalnim implicitima više nije dobro definisan kao i sa međusentencijalnim implicitima, razmatrač diskursa mora identificirati njihovu lokaciju i njihov smisao. To je fokus trenutnog posla. U novinama pruža sveobuhvatnu analizu naših rezultata, pokazivanje modelnih učinka pod različitim scenarijama, ukazivanje ograničenja i primjećujući buduće upute.', 'ca': 'A la PDTB-3, unes milers de relacions de discurs implícites van ser anotats recentment dins frases individuals, afegint a més de 15.000 relacions implícites anotats en frases adjacents a la PDTB-2. Given that the position of the arguments to these intra-sentential implicits is no longer as well-defined as with inter-sentential implicits, a discourse parser must identify both their location and their sense.  Aquest és el foc de la feina actual. El paper proporciona una anàlisi completa dels nostres resultats, mostrant el rendiment del model en diferents escenaris, apuntant limitacions i observant direccions futures.', 'cs': 'V PDTB-3 bylo nově anotováno několik tisíc implicitních diskurzních vztahů v jednotlivých větách, což přidalo k více než 15.000 implicitním vztahům anotovaným napříč sousedními větami v PDTB-2. Vzhledem k tomu, že postavení argumentů k těmto intra-sentenciálním implicitům již není tak dobře definováno jako u intersentenciálních implicitů, musí diskurzní parser identifikovat jak jejich umístění, tak jejich smysl. Na to se současná práce zaměřuje. Příspěvek poskytuje komplexní analýzu našich výsledků, ukazuje výkonnost modelu v různých scénářích, upozorňuje na omezení a zaznamenává budoucí směry.', 'et': 'PDTB-3-s märgiti üksikutes lausetes äsja tuhandeid kaudseid diskursussuhteid, lisades PDTB-2-s kõrvalseisvates lausetes märgitud üle 15 000 kaudse seose. Arvestades, et argumentide positsioon nendele sentitsiaalsetele implitsiitidele ei ole enam nii hästi määratletud kui sentitsiaalsete implitsiitide puhul, peab diskursuse parser tuvastama nii nende asukoha kui ka mõistuse. See on praeguse töö keskmes. Töös esitatakse põhjalik analüüs meie tulemustest, näidatakse mudeli tulemuslikkust erinevates stsenaariumides, tuuakse välja piirangud ja märgitakse tulevased suunad.', 'fi': 'PDTB-3:ssa useita tuhansia implisiittisiä diskurssisuhteita kirjoitettiin hiljattain yksittäisiin lauseisiin, mikä lisäsi yli 15 000 implisiittistä suhdetta, jotka merkittiin vierekkäisiin lauseisiin PDTB-2:ssa. Kun otetaan huomioon, että argumenttien sijainti näihin sententiaalisiin implisiittiin ei ole enää yhtä hyvin määritelty kuin sententiaalisiin implisiittiin, diskurssin jäsentäjän on tunnistettava sekä niiden sijainti että niiden merkitys. Tämä on nykyisen työn painopiste. Tutkimus tarjoaa kattavan analyysin tuloksistamme, esittelee mallin suorituskykyä eri skenaarioissa, osoittaa rajoituksia ja huomioi tulevaisuuden suunnat.', 'hy': 'In the PDTB-3, several thousand implicit discourse relations were newly annotated within individual sentences, adding to the over 15,000 implicit relations annotated across adjacent sentences in the PDTB-2.  Եթե հաշվի առնենք, որ այս ներս նախադասությունների ենթարկված բանավեճերի դիրքը այլևս այդքան լավ չի սահմանվում, ինչպես նախադասությունների ներս ենթարկված բանավեճերի դեպքում, խոսքի վերլուծումը պետք է հայտնաբերի նրանց դիրքը և զգացմունքը: Սա ներկայիս աշխատանքի կենտրոնն է: Այս թղթին ներկայացնում է մեր արդյունքների ամբողջական վերլուծությունը, ցույց է տալիս մոդելի արդյունքները տարբեր սցենարների ընթացքում, նշելով սահմանափակումներ և նկատելով ապագա ուղղություններ:', 'jv': 'Nang PNT-3, akeh liyane sing beraksi hukum gak bener Tanggal wong liyane permaneh akeh argument kewatirno inplisiten sanga-Sensitil iki dadi ora dadi nyimpen lagi ngono nggo inter-Sensitil, sampek awak dhéwé Iki kuwi nggawe perspek karo uwong. Awak dhéwé ngewehke akeh akeh antasi akeh dhéwé, iso nggawe model sing ngomong nik sekènari sing itéwangan, itékat kuwi tindakan kanggo ngerasah tarjamahan lan ngerasah tarjamahan kanggo ngerti', 'ha': "A cikin PDTB-3, aka sanar da wasu dubu masu husũma ma ma'abũcin magana a yanzu a cikin birane guda, sunã ƙara da mafi 15,000 ga muhimmada wanda aka sanar da shi a cikin gargaɗin da aka halatar da shi a PDTB-2. Gida cẽwa wurin da aka faɗi wa wannan masu cikin-cental ba za'a ƙayyade shi ba a sa bayan da aka ƙayyade shi a tsakanin tsakanin-tsakanin, ma'anar da mazaɓa sai ya ƙayyade wurin da ke so. Wannan ne fanikin aikin da ke kai yanzu. Gagon takarda yana gaya fassarar amfani da fassararmu, yana nuna muhimmin misalin misãlai a ƙarƙasan da ke cikin zangaren dabam-dabam, yana nuna tsari da kuma yana nuna shiryarwa masu gabani.", 'he': 'ב-PDTB-3, מספר אלפי יחסי דיבור מרושעים נכתבו חדש בתוך משפטים בודדים, הוסיפו למעלה מ-15,000 יחסים מרושעים נכתבו במשפטים סמוכים ב-PDTB-2. בהתחשב בעמדה של הטיעונים לתוך המשפט המשמעותיים הללו כבר לא מוגדר היטב כמו עם משפטים בין משפטים משמעותיים, מעבד דיבורים חייב לזהות את מיקומו וגם את תחושתם. זה המרכז של העבודה הנוכחית. העיתון מספק ניתוח מקצוע של התוצאות שלנו, מציג ביצועים מודל תחת תרחישים שונים, מצביע על הגבלות ולשמות לב לכיוונים עתידים.', 'sk': 'V PDTB-3 je bilo več tisoč implicitnih diskurznih relacij na novo označenih znotraj posameznih stavkov, kar je dodalo več kot 15.000 implicitnih relacij, označenih v sosednjih stavkih v PDTB-2. Glede na to, da položaj argumentov za te intrasententialne implicite ni več tako dobro opredeljen kot pri intersententialnih implicitih, mora razčlenjevalec diskurza identificirati njihovo lokacijo in njihov smisel. To je osredotočenost sedanjega dela. Prispevek vsebuje celovito analizo naših rezultatov, prikazuje uspešnost modela v različnih scenarijih, opozarja na omejitve in opozarja na prihodnje smeri.', 'bo': 'PDTB-3 ནང་གི་སྐྱོན་བརྗོད་དུ་གཏན་ཁེལ་བའི་འབྲེལ་མི་སྟོང་མང་པོ་ཞིག་ཡིན་པས་ཚིག་རྣམས་སྔར་སྐྱོན་བརྗོད་བྱུང་། Given that the position of the arguments to these intra-sentential implicits is not longer as well-defined as with inter-sentential implicits, a discourse parser must identify both their location and their sense. འདི་ནི་ད་ལྟོའི་ལས་ཀ་གནད་དོན་མཚམས་ཡིན། ཤོག་བྱང་གིས་ང་ཚོའི་གནད་སྡུད་ཡོད་མི་ཡོད་ཚད་ལ་ཡོངས་བསྡུར་མི་མངོན་འཆར་བྱེད་ཀྱི་ཡོད།'}
{'en': 'discopy : A Neural System for Shallow Discourse Parsing', 'fr': "discopy\xa0: Un système neuronal pour l'analyse superficielle du discours", 'pt': 'discopy: um sistema neural para análise superficial do discurso', 'es': 'discopy: Un sistema neuronal para el análisis superficial del discurso', 'ar': 'discopy: نظام عصبي لتحليل الخطاب الضحل', 'ja': 'discopy:浅い話題の解析のためのニューラルシステム', 'hi': 'discopy: उथले प्रवचन पार्सिंग के लिए एक तंत्रिका प्रणाली', 'zh': 'discopy:浅层语解析神经系统', 'ru': 'дископия: Нейронная система для неглубокого анализа дискурса', 'ga': 'dioscúrsa: Córas Néarach um Parsáil Dioscúrsa Éadomhain', 'ka': 'Name', 'hu': 'diszkópia: Idegrendszer a sekély diskurzus értelmezésére', 'lt': 'diskopija: Neuralinė sistema, skirta šešėliniam diskursui analizuoti', 'el': 'Δισκόπι: Νευρικό Σύστημα για την ανάλυση ρηχόυ λόγου', 'it': "Discopy: Un sistema neurale per l'analisi superficiale del discorso", 'ml': 'തണുത്ത ഡിസ്കോര്\u200dസ് പാര്\u200dസിങ്ങിനുള്ള ഒരു നെയുറല്\u200d സിസ്റ്റം', 'kk': 'дископиясы: Жұлдыз дискурстарды талдау нейралы жүйесі', 'mn': 'Дископи: Түүний ярианы шинжилгээний мэдрэлийн систем', 'mt': 'skopja: Sistema Newrali għall-Analiżi tad-Diskors Bix-Xgħir', 'mk': 'Name', 'pl': 'discopy: Układ neuronowy do płytkiego analizowania dyskusji', 'no': 'discopy: Eit neiralsystemet for tolking av skal diskursar', 'ro': 'discopie: Un sistem neural pentru analizarea discursului superficial', 'sr': 'diskopija: Neuralni sistem za analizu slobodnih diskusija', 'ms': 'diskopi: Sistem Neural untuk Menghurai Sekolah Gelap', 'sv': 'diskopi: Ett neuralt system för grundligt diskurstolkning', 'so': 'Ceymiska naafada ee jardiinada qashinka', 'ta': 'வடிவம்:', 'ur': 'Description', 'si': 'Description', 'uz': 'Name', 'vi': 'Sự xáo trộn: một hệ thần kinh cho sự khám phá Shales', 'bg': 'дископия: Неврална система за плитко дискурсно анализиране', 'da': 'diskopi: Et neuralt system til grundig diskursfortolkning', 'nl': 'discopy: Een neuraal systeem voor ondiepe discours Parsing', 'hr': 'diskopija: Neuralni sustav za razmatranje laganih diskusija', 'de': 'discopy: Ein neuronales System für flaches Diskursparsing', 'fa': 'discopy: یک سیستم عصبی برای تحلیل سخنرانی نرم', 'id': 'diskopi: Sebuah Sistem Neural untuk Penganalis Berlebihan', 'sw': 'kugundua: Mfumo wa Neural kwa ajili ya Kuchapisha Mazungumzo mazito', 'af': "discopy: ' n Neurale Stelsel vir Skaal Ontvaring", 'tr': 'diskpi', 'am': 'A Neural System for Shallow Discourse Parsing', 'sq': 'diskopi: A Neural System for Shallow Discourse Parsing', 'hy': 'Դոսկոպիա: A Նյարդային համակարգ for Shallow Discurse', 'bs': 'diskopija: Neuralni sistem za razmatranje slatkih diskusija', 'bn': 'নিউরেল সিস্টেম', 'az': 'discopy: A Neural System for Shallow Discourse Parsing', 'ko': 'discopy: 얕은 문장 분석에 사용되는 신경 계통', 'cs': 'discopy: Neurální systém pro analýzu mělkých diskusí', 'et': 'diskopia: närvisüsteem madala diskursuse parsimiseks', 'fi': 'diskopia: Neurojärjestelmä matalan diskurssin parsaukseen', 'ca': "discopia: Un sistema neuronalper l'analització del discurs buit", 'jv': 'Coverage', 'he': 'Diskopy: A Neural System for Shallow Discourse Parsing', 'ha': 'KCharselect unicode block name', 'sk': 'diskopija: Živčni sistem za plitvo razpravo diskurza', 'bo': 'discopy: A Neural System for Shallow Discourse Parsing'}
{'en': 'This paper demonstrates discopy, a novel framework that makes it easy to design components for end-to-end shallow discourse parsing. For the purpose of demonstration, we implement recent neural approaches and integrate contextualized word embeddings to predict explicit and non-explicit discourse relations. Our proposed neural feature-free system performs competitively to systems presented at the latest Shared Task on Shallow Discourse Parsing. Finally, a ', 'pt': 'Este artigo demonstra o discopy, uma nova estrutura que facilita o design de componentes para análise de discurso superficial de ponta a ponta. Para fins de demonstração, implementamos abordagens neurais recentes e integramos incorporações de palavras contextualizadas para prever relações de discurso explícitas e não explícitas. Nosso sistema neural sem recursos proposto tem um desempenho competitivo em relação aos sistemas apresentados na última Tarefa Compartilhada em Análise de Discurso Raso. Por fim, é mostrado um front end web que simplifica a inspeção de documentos anotados. O código-fonte, a documentação e os modelos pré-treinados são acessíveis publicamente.', 'fr': "Cet article présente Discopy, un nouveau cadre qui facilite la conception de composants pour l'analyse de discours superficiel de bout en bout. À des fins de démonstration, nous mettons en œuvre des approches neuronales récentes et intégrons des intégrations de mots contextualisées pour prédire les relations de discours explicites et non explicites. Notre système sans caractéristiques neuronales proposé est compétitif par rapport aux systèmes présentés lors de la dernière Shared Task on Shallow Discourse Parsing. Enfin, un frontal Web est présenté qui simplifie l'inspection des documents annotés. Le code source, la documentation et les modèles préentraînés sont accessibles au public.", 'ar': 'توضح هذه الورقة البحثية ، وهو إطار عمل جديد يجعل من السهل تصميم مكونات لتحليل الخطاب الضحل من طرف إلى طرف. لغرض العرض التوضيحي ، نقوم بتنفيذ مناهج عصبية حديثة ودمج تزوير الكلمات السياقية للتنبؤ بعلاقات الخطاب الصريحة وغير الصريحة. يعمل نظامنا المقترح الخالي من الميزات العصبية بشكل تنافسي على الأنظمة المقدمة في أحدث مهمة مشتركة حول تحليل الخطاب الضحل. أخيرًا ، يتم عرض واجهة الويب الأمامية التي تبسط فحص المستندات المشروحة. شفرة المصدر والوثائق والنماذج المدروسة متاحة للجمهور.', 'es': 'Este artículo demuestra discopy, un marco novedoso que facilita el diseño de componentes para el análisis superficial del discurso de extremo a extremo. Con fines de demostración, implementamos enfoques neuronales recientes e integramos incrustaciones de palabras contextualizadas para predecir relaciones discursivas explícitas y no explícitas. Nuestro sistema sin características neuronales propuesto funciona de manera competitiva con los sistemas presentados en la última tarea compartida sobre análisis superficial del discurso. Finalmente, se muestra una interfaz web que simplifica la inspección de documentos anotados. El código fuente, la documentación y los modelos previamente entrenados son de acceso público.', 'ja': 'この論文は、エンドツーエンドの浅い話題構文解析のためのコンポーネントを簡単に設計できる新規のフレームワークであるディスコピーを実証している。デモンストレーションの目的のために、私たちは最近のニューラルアプローチを実装し、明示的および非明示的な話題関係を予測するために文脈化された単語埋め込みを統合します。当社が提案するニューラルフィーチャーフリーシステムは、最新のShallow Discourse解析に関する共有タスクで提示されたシステムと競争的に機能します。最後に、注釈付き文書の検査を簡素化するウェブフロントエンドを示します。ソースコード、ドキュメント、および事前に訓練されたモデルは、公開されています。', 'zh': '本文演discopy,此一新框架,可轻设端浅层语解析之组件。 为演近神经,整合上下文词嵌,以占显式非显式语。 臣等所陈无神经特征系统与最新浅层语解析共享之系统,比于竞争力。 最后,显示了一个 Web 端,简化了对带注文档的检校。 源代码、文档、预训练可公访。', 'hi': 'यह पेपर डिस्कोपी को दर्शाता है, एक उपन्यास ढांचा जो एंड-टू-एंड उथले प्रवचन पार्सिंग के लिए घटकों को डिजाइन करना आसान बनाता है। प्रदर्शन के उद्देश्य के लिए, हम हाल के तंत्रिका दृष्टिकोण को लागू करते हैं और स्पष्ट और गैर-स्पष्ट प्रवचन संबंधों की भविष्यवाणी करने के लिए प्रासंगिक शब्द एम्बेडिंग को एकीकृत करते हैं। हमारी प्रस्तावित तंत्रिका सुविधा-मुक्त प्रणाली उथले प्रवचन पार्सिंग पर नवीनतम साझा कार्य में प्रस्तुत प्रणालियों के लिए प्रतिस्पर्धी प्रदर्शन करती है। अंत में, एक वेब फ्रंट एंड दिखाया गया है जो एनोटेट किए गए दस्तावेज़ों के निरीक्षण को सरल बनाता है। स्रोत कोड, प्रलेखन, और pretrained मॉडल सार्वजनिक रूप से सुलभ हैं।', 'ru': 'Эта статья демонстрирует дископию, новую структуру, которая позволяет легко проектировать компоненты для сквозного неглубокого анализа дискурса. С целью демонстрации мы реализуем недавние нейронные подходы и интегрируем контекстуализированные вложения слов для прогнозирования явных и неявных отношений дискурса. Наша предлагаемая нейронная система без признаков выполняет конкурентоспособные функции по отношению к системам, представленным на последней Общей задаче по неглубокому анализу дискурса. Наконец, показан веб-интерфейс, который упрощает проверку аннотированных документов. Исходный код, документация и предварительно подготовленные модели являются общедоступными.', 'ga': 'Léiríonn an páipéar seo discóip, creat nua a éascaíonn comhpháirteanna a dhearadh le haghaidh parsáil dioscúrsa éadomhain ó cheann go ceann. Ar mhaithe le léiriú, cuirimid cuir chuige néaracha le déanaí i bhfeidhm agus comhtháthímid leabaithe comhthéacsúla focal chun caidreamh dioscúrsa follasach agus neamhfhollasaí a thuar. Feidhmíonn ár gcóras néarchóras saor ó shaintréithe atá beartaithe go hiomaíoch do chórais a chuirtear i láthair ag an Tasc Comhroinnte is déanaí maidir le Parsáil Dioscúrsa Éadomhain. Ar deireadh, taispeántar foirceann tosaigh gréasáin a shimplíonn iniúchadh doiciméad anótáilte. Tá rochtain ag an bpobal ar an gcód foinseach, ar an gcáipéisíocht agus ar na samhlacha réamhoilte.', 'hu': 'Ez a tanulmány bemutatja a diszkópiát, egy új keretrendszert, amely megkönnyíti az összetevők tervezését a végtől végig sekély diskurzus elemzéshez. Demonstráció céljából újabb idegi megközelítéseket alkalmazunk és kontextuális szóbeágyazásokat integrálunk az explicit és nem explicit diskurzusi kapcsolatok előrejelzésére. Javasolt neurális funkciómentes rendszerünk versenyképesen teljesít a legújabb Shared Task on Shallow Discourse Parsing rendszerekkel szemben. Végezetül egy webes front end jelenik meg, amely egyszerűsíti a jegyzetelt dokumentumok ellenőrzését. A forráskód, a dokumentáció és az előkészített modellek nyilvánosan hozzáférhetők.', 'el': 'Αυτή η εργασία παρουσιάζει ένα νέο πλαίσιο που καθιστά εύκολο να σχεδιάσει συστατικά για την ανάλυση ρηχών συζητήσεων από το τέλος σε το τέλος. Για σκοπούς επίδειξης, εφαρμόζουμε πρόσφατες νευρωνικές προσεγγίσεις και ενσωματώνουμε ενσωματωμένες λέξεις στο πλαίσιο για να προβλέψουμε ρητές και μη ρητές σχέσεις συζήτησης. Το προτεινόμενο νευρικό σύστημα χωρίς χαρακτηριστικά λειτουργεί ανταγωνιστικά με τα συστήματα που παρουσιάζονται στην τελευταία κοινή εργασία για την ανάλυση ρηχών συζητήσεων. Τέλος, παρουσιάζεται ένα μπροστινό άκρο ιστού που απλοποιεί την επιθεώρηση των σχολιασμένων εγγράφων. Ο πηγαίος κώδικας, η τεκμηρίωση και τα προ-εκπαιδευμένα μοντέλα είναι προσβάσιμα στο κοινό.', 'it': "Questo articolo dimostra discopy, un nuovo framework che rende facile progettare componenti per l'analisi del discorso superficiale end-to-end. A scopo dimostrativo, implementiamo approcci neurali recenti e integriamo incorporazioni di parole contestualizzate per predire relazioni di discorso esplicite e non esplicite. Il nostro sistema neurale senza funzioni neurali proposto funziona in modo competitivo rispetto ai sistemi presentati all'ultimo task condiviso sull'analisi del discorso superficiale. Infine, viene mostrato un web front end che semplifica l'ispezione dei documenti annotati. Il codice sorgente, la documentazione e i modelli pre-addestrati sono accessibili pubblicamente.", 'lt': 'This paper demonstrates discopy, a novel framework that makes it easy to design components for end-to-end shallow discourse parsing.  Demonstracijos tikslais įgyvendiname naujausius nervinius metodus ir integruojame kontekstinius žodžių įterpimus, kad būtų galima prognozuoti aiškius ir neaiškius diskursinius santykius. Mūsų pasiūlyta neuralinė sistema be savybių veikia konkurencingai su sistemomis, pateiktomis ne vėliau kaip bendra užduotis dėl nuotolinio diskurso analizavimo. Galiausiai rodoma interneto sąsaja, kuri supaprastina užrašytų dokumentų patikrinimą. Šaltinis kodas, dokumentai ir išankstinio mokymo modeliai yra prieinami visuomenei.', 'kk': 'Бұл қағаз дископия дегенді көрсетеді. Соңғы- соңғы кеңісті дискурстарды талдау үшін компоненттерді құрастыру оңай болады. Демонстрацияның мақсатында, біз жаңа невралдық қатынастарын іске асырып, контекстуалды сөздерді ендіру үшін түсінікті және түсінікті емес дискурстардың қатынасын таңдау үшін біріктіреміз. Біздің келтірілген невралдық қасиеттер бос жүйесіміз соңғы ортақ тапсырмалар талдауындағы жүйелерге конкурентті орындалады. Соңында, белгіленген құжаттарды тексеруді қарапайым көмектеседі. Бастапқы код, құжаттамасы және өзгертілген үлгілер көпшілікті қатынауға болады.', 'ka': 'ეს დოკუმენტი დემონსპია, რომელიც პრომენტის ფრამეტრი, რომელიც მართლად გავაკეთება კომპონენტების დასაწყისათვის დასაწყისათვის კომპონენტები და ევმონსტრაციის მიზეზისთვის, ჩვენ ახალი ნეიროლური მიზეზების გამოყენება და კონტექსტუალური სიტყვების შემდეგ ინტერგურაცია, რომელიც გამოწვება განსხვავებული და არ გამოწვებ ჩვენი წარმოიდგინეთ ნეიროლური ფუნქციების თავისუფალი სისტემაში კონტეპექტიურად გავაკეთება სისტემაში, რომელიც ახლა ახალგაზრულად გაყოფილი საქმე და საბოლოოდ, საბოლოო ფორნენტი ჩვენებულია, რომელიც ახლა გამოყენებული დოკუმენტების ინსპექციის გამოყენება. ფოსტური კოდიმაცია, დოკუმენტაცია და საკუთარი მოდელები ადგილურად შესაძლებელია.', 'mk': 'Оваа хартија демонстрира дископија, нова рамка која овозможува да се дизајнираат компоненти за крај до крај ниско анализирање на дискурси. За цел на демонстрација, спроведуваме неодамнешни неурални пристапи и интегрираме контекстуални зборови вградени за да предвидеме експлицитни и неексплицитни дискурсни односи. Нашиот предложен систем без нервни карактеристики функционира конкурентно со системите презентирани најпоследната заедничка задача за анализирање на темниот дискурс. Конечно, се покажува веб- интерфејс кој ја поедноставува инспекцијата на анотираните документи. The source code, documentation, and pretrained models are publicly accessible.', 'ms': 'Kertas ini menunjukkan diskopi, kerangka baru yang memudahkan untuk merancang komponen untuk penghuraian diskors rendah akhir-akhir. Untuk tujuan demonstrasi, kami melaksanakan pendekatan saraf baru-baru ini dan mengintegrasikan penyambungan perkataan kontekstualisasi untuk meramalkan hubungan diskors yang jelas dan tidak jelas. Sistem neural bebas ciri-ciri kami dilakukan secara kompetitif kepada sistem yang dihadapkan pada Tugas Berkongsi terbaru mengenai Penghuraian Sekolah Gelap. Akhirnya, bahagian depan web dipaparkan yang mempermudahkan pemeriksaan dokumen yang dicatat. Kod sumber, dokumen, dan model yang dilatih dahulu boleh diakses secara awam.', 'ml': 'This paper demonstrates discopy, a novel framework that makes it easy to design components for end-to-end shallow discourse parsing.  പ്രതിഷേധത്തിന് വേണ്ടിയാണ്, നമ്മള്\u200d അടുത്ത പുതിയ ന്യൂറലിന്റെ സമ്മാനങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. പ്രത്യക്ഷമായ വാക്കുകള്\u200d പ്രവചിക്കു നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട ന്യൂറല്\u200d സ്വാതന്ത്ര്യ സിസ്റ്റം പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അടുത്തുതന്നെ പങ്കുചേര്\u200dത് അവസാനം, വെബ് മുന്\u200dഭാഗത്തുള്ള ഒരു അവസാനം കാണിച്ചിരിക്കുന്നു. പ്രഖ്യാപിക്കപ്പെട്ട രേഖകളുടെ പരിശോധന എ സോര്\u200dസ്സ് കോഡ്, രേഖപ്പെടുത്തുന്നത്, പ്രത്യേകിച്ചിരിക്കുന്ന മോഡലുകള്\u200d പ്രസിദ്ധമായി ലഭ്യ', 'mt': 'Dan id-dokument juri skopja, qafas ġdid li jagħmilha faċli li jiġu ddisinjati komponenti għall-analizzazzjoni tad-diskors baxx minn tarf sa tarf. Għall-finijiet tad-dimostrazzjoni, nimplimentaw approċċi newrali reċenti u nintegraw inkorporazzjonijiet ta’ kliem kuntestwalizzati biex nipprojbixxu relazzjonijiet ta’ diskors espliċiti u mhux espliċiti. Our proposed neural feature-free system performs competitively to systems presented at the latest Shared Task on Shallow Discourse Parsing.  Fl-a ħħar nett, jintwera faċċata tal-internet li tissimplifika l-ispezzjoni tad-dokumenti annotati. Il-kodiċi tas-sors, id-dokumentazzjoni u l-mudelli mħarrġa minn qabel huma aċċessibbli għall-pubbliku.', 'pl': 'W artykule przedstawiono discopy, nowatorski framework, który ułatwia projektowanie komponentów do kompleksowego parsowania płytkiego dyskursu. W celu demonstracji wdrażamy najnowsze podejścia neuronowe i integrujemy kontekstualizowane osadzenia słów w celu przewidywania wyraźnych i niewyraźnych relacji dyskursowych. Nasz proponowany system neuronowy bez funkcji działa konkurencyjnie w stosunku do systemów prezentowanych na najnowszym wspólnym zadaniu na płytkim dyskursie. Wreszcie pokazano web front end, który upraszcza kontrolę dokumentów z adnotacjami. Kod źródłowy, dokumentacja i wstępnie przeszkolone modele są publicznie dostępne.', 'ro': 'Această lucrare demonstrează discopia, un cadru nou care facilitează proiectarea componentelor pentru analizarea discursului superficial end-to-end. În scopul demonstrării, implementăm abordări neurale recente și integrăm încorporări de cuvinte contextualizate pentru a prezice relațiile de discurs explicite și neexplicite. Sistemul nostru fără caracteristici neurale propus funcționează competitiv cu sistemele prezentate la cea mai recentă sarcină partajată privind analizarea discursului slab. În cele din urmă, este prezentat un front end web care simplifică inspecția documentelor adnotate. Codul sursă, documentația și modelele pre-instruite sunt accesibile publicului.', 'sr': 'Ovaj papir pokazuje diskopiju, novi okvir koji olakšava dizajnirati komponente za analizu plitkih diskursa do kraja. Za svrhu demonstracije, implementiramo nedavne neurološke pristupe i integriramo kontekstualizovane rečenice za predviđanje eksplicitnih i ne-eksplicitnih odnosa diskusija. Naš predloženi sistem bez neuralnih funkcija izvodi konkurentno na sisteme koji su predstavljeni na najnovijem zajedničkom zadatku o razmatranju otvorenih diskusija. Konačno se pokazuje internetski front da jednostavlja inspekciju annotiranih dokumenta. Izvorni kodeks, dokumentacija i pretkivni modeli su javno dostupni.', 'si': 'මේ පත්තර ප්\u200dරකාශ කරනවා විකාශයක්, අවසානයෙන් අවසානයෙන් අවසානයෙන් අවසානය කරන්න පුළුවන් විකාශයක් වෙන්න. ප්\u200dරදර්ශනය සඳහා අපි අලුත් න්\u200dයූරාල් අවස්ථාවක් සම්බන්ධ කරනවා, සම්බන්ධ විදියට ප්\u200dරශ්නය සහ නොප්\u200dරශ්නය කතාවක් සම්බන අපේ ප්\u200dරයෝජනය විශ්වාස නිදහස් පද්ධතිය සම්පූර්ණයෙන් ප්\u200dරයෝජනය කරනවා පද්ධතියට අන්තිම සම්පූර්ණ වැඩක අන්තිමේදි, වෙබ් ඉදිරියට පෙන්වන්න පුළුවන් විදිහට පරීක්ෂණය කරන්න පුළුවන්. ප්\u200dරභාව කෝඩ්, ලිපින්තුරු සහ ප්\u200dරභාවිත විදිහට ප්\u200dරවේශ කරන්න පුළුවන්.', 'mn': 'Энэ цаас гайхалтай, шинэ хэлбэрүүдийг эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь хэцүү хэлбэрүүдийг хуваалцахын тулд амархан загвар Дүрслэлийн зорилго дээр бид саяхан мэдрэлийн ойлголтыг дамжуулж, тодорхой, тайлбарлалтгүй ярианы харилцааны тухай тодорхойлох үед тодорхойлдог үгийг нэгтгэдэг. Бидний санал дэвшүүлсэн сэтгэл хөдлөл үнэгүй систем шинэ хуваалтын ажил дээр дэвшүүлсэн системүүдэд өрсөлдөг байдаг. Эцэст нь, нэг веб-н урд төгсгөл нь анзаарсан баримтуудын шалгалтыг хялбарчилж байна. Мөн эх үүсвэрийн код, баримт баримтууд болон сайхан загварууд нийтэд ашиглах боломжтой.', 'ta': 'இந்த தாள் கண்டுபிடிப்பு, ஒரு புதிய சட்டத்தை காட்டுகிறது, அது முடிவில் இருந்து முடிவு பேச்சு பாடலுக்கு எளிதாக வடிவமைப நாம் சமீபத்தில் புதிய புதிய அணுகுகளை செயல்படுத்தி பாதிக்கப்பட்ட வார்த்தைகளை ஒன்று சேர்க்க, வெளிப்படையாக மற்றும் வெளிப்படையான பேச் எங்கள் பரிந்துரைக்கப்பட்ட புதிய குணங்கள் இலவச அமைப்பு தற்போதைய பகிர்ந்த பணியில் அலங்காரமாக செயல்படுத்துகிறது. இறுதியில், ஒரு வலை முன் முன்னோட்டம் காட்டப்படும் அது அறிவிக்கப்பட்ட ஆவணங்களின் பரிசோதனையை எளிதாக்கும். மூல குறியீடு, ஆவணம், மற்றும் முன்னோக்கப்பட்ட மாதிரிகள் பொதுவாக அணுகலாம்.', 'so': 'Warqaddan wuxuu muujiyaa ceeb, sawir warqadeed oo u fududaysa in loo sawiro kooxda dhammaadka dhamaadka dhamaadka baaritaanka hadalka cibaadada. Tan darteed waxaynu sameynaa qaabab neurada ah ee ugu dambeeyay, waxaana la wada qabsanaynaa warqada la soo qoray si aan u sii sheegno xiriir cad iyo si cad ah. Isticmaalkaan la soo jeeday nidaamka neurada oo lacag la’aanta ah wuxuu si competan u sameeyaa nidaamka loo soo bandhigay shaqada ugu dambeysay ee la sharciyey jardiinada Shallow Discourse. Ugu dambaysta waxaa la muujiyaa dhamaadka internetka, kaas oo fududeeya baaritaanka dukumentiyada la sharciyey. Qoidaha asalka ah, dukumentiyada iyo noocyada la soo daabacay waxay si bayaan ah u heli karaan.', 'sv': 'Denna uppsats visar diskopi, ett nytt ramverk som gör det enkelt att utforma komponenter för ytlig diskurstolkning. I demonstrationssyfte implementerar vi nya neurala tillvägagångssätt och integrerar kontextualiserade ordinbäddningar för att förutsäga explicita och icke-explicita diskursrelationer. Vårt föreslagna neurala funktionsfria system presterar konkurrenskraftigt mot system som presenteras vid den senaste Shared Task on Shallow Discourse Parsing. Slutligen visas en webbfront som förenklar inspektionen av kommenterade dokument. Källkoden, dokumentationen och förklädda modeller är allmänt tillgängliga.', 'no': 'Name For målet av demonstrasjon, implementerer vi nyleg neiraltilnærmingar og integrerer kontekstualiserte ordinnbygging for å foregå eksplisitt og ikkje-eksplisitt diskursrelasjonar. Vårt foreslått neuralfri systemet utfører konkurrentivt til systemet som er presentert i den siste delte oppgåva om tolking av skalådiskursar. Ein nettfronten vert vist til slutt som forenklar inspeksjonen av merkte dokument. Kjeldekode, dokumentasjon og pretrende modeller er offentlig tilgjengeleg.', 'ur': 'یہ کاغذ دیسکوپی کو دکھاتا ہے، ایک نئی فرمود جس نے اخر و پایان کے اندر اندھیرے سخنرانی پارسینگ کے لئے اجزاء کو طراحی کے لئے آسان بنا دیا ہے. دکھانے کے لئے، ہم اچھے نئورل طریقے کے مطابق لائق کرتے ہیں اور متوجہ شدہ کلمات کے مطابق مخصوص اور غیر صریح گفتگو کے ارتباط کی پیش بینی کرنے کے لئے متصل کرتے ہیں. ہماری پیشنهاد نائورل فوئرل-فائرٹ سیسٹم نے سیسٹم کے بارے میں سب سے اچھے شریک ٹاکس پر پیش کیا ہے۔ بالآخر، ایک ویب فورنڈ انڈ دکھائی جاتی ہے کہ انٹیٹ دکھائی کے تحقیق کو آسان کر دیتا ہے. سورس کوڈ، ڈکومکینٹ، اور پرٹرینڈ موڈل ظاہر طور پر دسترسی حاصل کرنے والے ہیں.', 'vi': 'Tờ giấy này thể hiện sự xáo trộn, một hệ thống mới tinh vi khiến việc thiết kế các thành phần dễ dàng cho các bài giảng cạn. Để thể hiện, chúng tôi triển khai các phương pháp thần kinh gần đây và kết hợp các từ ngữ định để dự đoán các quan hệ đàm luận rõ ràng và không trực tiếp. Hệ thống thần kinh tự do hoạt động cạnh tranh với các hệ thống được trình bày gần nhất "Việc chia sẻ" Cuối cùng, một đầu trang web được hiển thị một cách đơn giản hóa việc kiểm tra tài liệu ghi chú. Các mẫu nguồn, tài liệu và các mẫu trước đã được công khai.', 'uz': "Bu qogʻoz ajoyib chiqqani ko'rsatadi. Bu novel freymi yordam qiladi. Ularning oxiriga oʻtish oxirgi gapirishning qismlarini yaratishga oson qiladi. Koʻrsatish uchun biz yaqinda yangi neyrolik usullarini bajaramiz va taʼminlov qilingan so'zlarni birlashtiramiz va taʼminlovchi suhbat aloqalarini tahrirlash mumkin. Bizning talab qilingan neyrolik boʻsh tizimimizning eng oxirgi boʻlishilgan vazifa sariq disk qilish vazifasidagi tizimga rivojlanadi. Oxirgi, veb- sahifa chegarasi koʻrsatiladi, annotated hujjatlarni tekshirishni oddiy qiladi. @ info", 'bg': 'Тази статия демонстрира нова рамка, която улеснява проектирането на компоненти за повърхностно анализиране на дискурсите от край до край. За целите на демонстрацията ние прилагаме неотдавнашни невронни подходи и интегрираме контекстуализирани словесни вграждания за предсказване на изрични и неексплицитни дискурсни отношения. Нашата предложена невронна система без функции работи конкурентно на системите, представени в последната Споделена задача за плитко дискурсно анализиране. И накрая, показва се уеб фронт енд, който опростява проверката на анотираните документи. Изходният код, документацията и предварително обучените модели са публично достъпни.', 'hr': 'Ovaj papir pokazuje diskopiju, novi okvir koji olakšava dizajnirati komponente za analizu plitkih diskursa do kraja. Za svrhu demonstracije, implementiramo nedavne neurološke pristupe i integriramo kontekstualizirane rečenice za predviđanje pojasnih i neobjašnjih veza s diskusijama. Naš predloženi sistem bez neuroloških funkcija konkurentno izvodi na sustave predstavljene na najnovijem zajedničkom zadatku o razmatranju otvorenih diskusija. Konačno se pokazuje internetski front da pojednostavlja inspekciju navedenih dokumenta. Izvorni kod, dokumentacija i pretkišni modeli su javno dostupni.', 'da': 'Denne artikel demonstrerer diskopi, en ny ramme, der gør det nemt at designe komponenter til end-to-end overfladisk diskursanalyse. Med henblik på demonstration implementerer vi nye neurale tilgange og integrerer kontekstualiserede ord indlejringer for at forudsige eksplicitte og ikke-eksplicitte diskursrelationer. Vores foreslåede neurale funktionsfrie system fungerer konkurrencedygtigt til systemer præsenteret på den seneste delte opgave om grundig diskursanalyse. Endelig vises en web front end, der forenkler inspektionen af noterede dokumenter. Kildekoden, dokumentationen og forudtrænede modeller er offentligt tilgængelige.', 'ko': '본고는discopy를 보여 주었는데 이것은 새로운 구조로 처음부터 끝까지 얕은 문장 분석의 구성 요소를 편리하게 설계할 수 있다.시범을 보이기 위해 우리는 최신의 신경 방법을 채택하고 어경화된 단어를 결합시켜 현성과 비현성의 언어 관계를 예측했다.우리가 제시한 무특징 신경계는 얕은 문장 분석의 최신 공유 임무에서 경쟁력을 가진다.마지막으로, 주석 문서가 있는 검사를 간소화하는 웹 전단을 보여 줍니다.원본 코드, 문서, 사전 훈련을 거친 모델은 공개적으로 접근할 수 있다.', 'de': 'Dieser Beitrag demonstriert discopy, ein neuartiges Framework, das es einfach macht, Komponenten für End-to-End flache Diskursparsing zu entwerfen. Zur Demonstration implementieren wir neurale Ansätze und integrieren kontextualisierte Worteinbettungen, um explizite und nicht-explizite Diskursbeziehungen vorherzusagen. Unser vorgeschlagenes neuronales funktionsfreies System funktioniert wettbewerbsfähig zu Systemen, die auf der neuesten Shared Task on Shallow Discourse Parsing vorgestellt wurden. Abschließend wird ein Web-Frontend gezeigt, das die Inspektion kommentierter Dokumente vereinfacht. Der Quellcode, die Dokumentation und die vortrainierten Modelle sind öffentlich zugänglich.', 'fa': 'این کاغذ، یک چهارچوب رمانی را نشان می\u200cدهد که برای پایان و پایان سخنرانی کوچک طراحی بخش\u200cهایی را آسان می\u200cسازد. برای هدف نمایش، ما روش\u200cهای عصبی اخیر را اجرای می\u200cکنیم و برای پیش\u200cبینی رابطه\u200cهای مشخصی و غیر مشخصی کلمه\u200cهای متفاوت را جمع می\u200cکنیم. سیستم آزادی عصبی پیشنهاد ما با مسابقه با سیستم\u200cهایی که در آخرین وظیفه\u200cی مشترک\u200cشده در مورد تحلیل سخنرانی\u200cهای شلوغ نشان داده می\u200cشود اجرا می\u200cکند. بالاخره، یک پایان پیشینه وب نشان داده می\u200cشود که بازرسی سند یادآوری را ساده می\u200cکند. رمز منبع، مدل\u200cهای سند و مدل\u200cهای پیش\u200cفرض به طور عمومی دسترسی دارند.', 'sw': 'Gazeti hili linaonyesha kusikitishwa, mfumo wa riwaya unaosababisha kuunda vifaa vya kutengeneza mazungumzo mabaya ya mwisho. For the purpose of demonstration, we implement recent neural approaches and integrate contextualized word embeddings to predict explicit and non-explicit discourse relations.  Mfumo wetu uliopendekezwa kuwa hauna uwezo wa kijinsia unafanya kwa ushindani kwa mifumo iliyotolewa kwenye kazi ya hivi karibuni iliyoambatana kwenye Kuchapisha Uchunguzi wa Nyongo. Mwisho, mwisho wa mbele ya mtandaoni unaonyesha kuwa inasahihirisha uchunguzi wa nyaraka zilizotajwa. Kodi la vyanzo, nyaraka, na mifano iliyopigwa zinapatikana hadharani.', 'tr': 'Bu kagyz diskripi, bir roman çerçevesini soňra-soňra ýeňli diskusiýa ayırmak üçin a ňsat döredir. Demostrasiýanyň maksady üçin, oňki näyral ýakynlaşyklary implemente we düzgün sözler guralşyny çaklamak üçin sözler guralýarys. Biziň teklip eden näral özelliklerimizi boş sistemimiz Shallow Discourse Analyzasynda Soňky Paýlaşan Görevlerde üýtgeden sistemlere duşuşykly çykýar. Soňunda, täze senedlerin barlanmasyny kolaylaştyrýan bir web ön uçruny görkezildi. Çeşme kody, dökümentleg we ýalňyş nusgalar publika elýeterli bar.', 'nl': 'Dit artikel demonstreert discopy, een nieuw framework dat het gemakkelijk maakt om componenten te ontwerpen voor end-to-end ondiepe discoursparsing. Voor demonstratie implementeren we recente neurale benaderingen en integreren we contextualiseerde woordembeddingen om expliciete en niet-expliciete discoursrelaties te voorspellen. Ons voorgestelde neurale functie-vrije systeem presteert concurrerend met systemen gepresenteerd op de nieuwste Shared Task on Shallow Discourse Parsing. Tot slot wordt een web front end getoond die de inspectie van geannoteerde documenten vereenvoudigt. De broncode, documentatie en vooraf getrainde modellen zijn openbaar toegankelijk.', 'id': 'Kertas ini menunjukkan diskopi, sebuah cadangan baru yang memudahkan untuk merancang komponen untuk analisis diskors rendah akhir-akhir. Untuk tujuan demonstrasi, kami menerapkan pendekatan saraf baru-baru ini dan mengintegrasikan pembangunan kata kontekstualisasi untuk memprediksi hubungan diskors eksplicit dan tidak eksplicit. Sistem neural yang diusulkan kita tanpa fitur berfungsi secara kompetitif dengan sistem yang diperkenalkan pada Tugas Berkongsi terbaru tentang Penganalisan Diskursi Gelombang. Akhirnya, bagian depan web ditunjukkan yang menyederhanakan inspeksi dokumen yang dicatat. Kode sumber, dokumentasi, dan model terlatih secara publik tersedia.', 'am': 'ይህ ገጽ መደነቂያ፣ የረኀብ ፍሬማር ለፍጻሜ ለመጨረሻ ለጥሩ ንግግር ማዘጋጀት የሚያስቀናው ነው፡፡ For the purpose of demonstration, we implement recent neural approaches and integrate contextualized word embeddings to predict explicit and non-explicit discourse relations.  የተዘጋጀው የባሕላዊ ምርጫዎች ነጻ ሲስተም በቅርብ ዘመን በተለየ ጥቁር ስራዎችን በጥቁር ስርዓት ላይ በሚያሳየው ስርዓቶች በተቃውሞ ይሠራል፡፡ በመጨረሻው የዌብ መጨረሻ የመረጃ ዳርቻ የሚታየው የሰነዱ ሰነዶች ማቅናጃ እንዲያስቀምጥ ነው፡፡ የኩነቶች ኮድ፣ ሰነድ እና የተለየ ምሳሌዎች በህዝብ የተገኙ ናቸው፡፡', 'hy': 'This paper demonstrates discopy, a novel framework that makes it easy to design components for end-to-end shallow discourse parsing.  Որպեսզի ցուցադրենք, մենք կիրառում ենք վերջին նյարդային մոտեցումները և ինտեգրում ենք կոնտեքստիալ բառերի ներդրումները, որպեսզի կանխատեսենք բացահայտ և ոչ բացահայտ քննարկումների հարաբերությունները: Our proposed neural feature-free system performs competitively to systems presented at the latest Shared Task on Shallow Discourse Parsing.  Վերջապես, ցույց է տալիս վեբ ինտերնետային էջը, որը պարզաբանում է գրված փաստաթղթերի վերահսկումը: Առաջին կոդը, փաստաթղթերը և նախադասավորված մոդելները հասանելի են հանրային առումով:', 'bn': 'এই পত্রিকাটি দেখাচ্ছে, একটি উপন্যাসের ফ্রেক্রেম যা শেষ পর্যন্ত শেষ পর্যন্ত অল্প কথোপকথন পার্সিং এর জন্য সহজ করে তৈরি করে। বিক্ষোভের উদ্দেশ্যের জন্য আমরা সাম্প্রতিক নিউরুলের ক্ষেত্রে বাস্তবায়ন করি এবং প্রতিযোগিতা শব্দগুলোকে একত্রিত করি স্পষ্ট এবং বিস্তার আমাদের প্রস্তাবিত নিউরেল ফ্রি ব্যবস্থা শেয়ার করার সাম্প্রতিক শেয়ার কর্মসূচীতে প্রতিযোগিতায় প্রদর্শন করে। অবশেষে, একটি ওয়েব সামনের প্রান্ত প্রদর্শন করা হয়েছে যে বিরক্তিকর নথিপত্রের পরীক্ষা সহজ করে দেখা যায়। উৎস কোড, নথিপত্র এবং প্রেমিক মডেল প্রকাশ্যে প্রবেশ করা যাচ্ছে।', 'af': "Hierdie papier vertoon diskopie, 'n roman raamwerk wat dit maklik maak om komponente te ontwerp vir end- to- end slag diskurse verwerking. Vir die doel van demonstrasie, implementeer ons onlangse neurale toegang en integreer kontekstualiseerde woord inbêdings om eksplisiese en nie-eksplisiese diskurse relasies te voorskou. Ons voorgestelde neurale funksie-vry stelsel uitvoer konkursief na stelsels wat voorgestel is by die nuutste deelde taak op die Skaal Speletjie Ontlegging. Eindelik word 'n web voorkant vertoon wat die inspeksie van notateerde dokumente vereenvoudig. Die bronkode, dokumentasie en voorrekende modele is openlik toeganklik.", 'sq': 'Kjo letër demonstron diskopi, një kuadër të ri që e bën të lehtë dizajnimin e komponenteve për analizimin e diskursit të poshtëm nga fundi në fund. Për qëllimin e demonstrimit, ne zbatojmë qasjet e fundit neuronale dhe integrojmë përfshirjet e fjalëve kontekstuale për të parashikuar marrëdhënie të shprehura dhe jo të shprehura diskurse. Sistemi ynë i propozuar pa karakteristika nervore funksionon në mënyrë konkurruese me sistemet e paraqitura në detyrën e fundit të përbashkët për analizimin e diskursave të hijshme. Më në fund, një faqe interneti shfaqet që thjeshton inspektimin e dokumenteve të anotuara. Kodi burimi, dokumentacioni dhe modelet e paratrajnuara janë publikisht të mundshëm.', 'cs': 'Tento článek demonstruje discopy, nový rámec, který usnadňuje navrhování komponent pro komplexní mělkou diskurzní analýzu. Pro účely demonstrace implementujeme nejnovější neuronové přístupy a integrujeme kontextualizované vložení slov k predikci explicitních a neinexplicitních diskurzních vztahů. Náš navržený neuronový systém bez funkcí funguje konkurenčně vůči systémům prezentovaným na nejnovějším Shared Task on Shallow Discourse Parsing. Nakonec je ukázán web front end, který zjednodušuje kontrolu anotovaných dokumentů. Zdrojový kód, dokumentace a předtrénované modely jsou veřejně přístupné.', 'az': 'Bu kağıt diskopiyi, yeni framework ü göstərir ki, sona qədər çox çətin diskusiya ayırmaq üçün komponentləri tasarlamaq asanlaşdırır. Gördüyünüz məqsədilə, biz yeni nöral tərzlərini uygulayıq və müxtəlif sözlərin istifadə etmək üçün müxtəlif və açıq-aydın sözlərin əlaqələrini təmin edirik. Bizim təbliğ etdiyimiz nöral özgürlük sistemimiz ən son Paylaşdırılmış Gözmə ilə müqayisədə istifadə edir. Sonunda, a ğ ön uçuş göstərilir ki, nöqtələnmiş dökümələrin inspekcijini asanlaşdırır. Qaynaq kodu, dökümləndirici və əvvəlki modellər açıq-aşkar faydalanır.', 'et': 'Käesolevas töös tutvustatakse diskopiat, uudset raamistikku, mis muudab lihtsaks komponentide kujundamise otsast otsani madala diskursuse parsimiseks. Demonstreerimise eesmärgil rakendame hiljutisi neuraalseid lähenemisviise ja integreerime kontekstilised sõnade põimimised, et ennustada selgesõnalisi ja mittesõnalisi diskursussuhteid. Meie väljapakutud närvifunktsioonideta süsteem toimib konkurentsivõimeliselt süsteemidega, mis on esitatud viimasel Shared Task on Shallow Discuurse Parsing. Lõpuks näidatakse veebiversiooni, mis lihtsustab märgitud dokumentide kontrollimist. Lähtekood, dokumentatsioon ja eeltreenitud mudelid on avalikult kättesaadavad.', 'bs': 'Ovaj papir pokazuje diskopiju, novi okvir koji olakšava dizajnirati komponente za analizu plitkih diskursa. Za svrhu demonstracije, implementiramo nedavne neurološke pristupe i integriramo kontekstualizovane riječi za predviđanje eksplicitnih i ne-eksplicitnih veza s diskusijama. Naš predloženi sistem bez neuralnih funkcija izvodi konkurentno na sisteme koji su predstavljeni na najnovijem zajedničkom zadatku o razmatranju otvorenih diskursa. Konačno se pokazuje internetski fronten da pojednostavlja inspekciju annotiranih dokumenta. Izvorni kodeks, dokumentacija i pretkišeni modeli su javno dostupni.', 'fi': 'TÃĪssÃĪ artikkelissa esitellÃĪÃĪn diskopia, uutta kehystÃĪ, jonka avulla on helppo suunnitella komponentteja pÃĪÃĪstÃĪ pÃĪÃĪhÃĪn matalaa diskurssin jÃĪsentÃĪmistÃĪ varten. Demonstrointia varten toteutamme viimeaikaisia neurolÃĪhestymistapoja ja integroimme kontekstualisoituja sanaupotuksia ennustamaan eksplisiittisiÃĪ ja ei-eksplisiittisiÃĪ diskurssisuhteita. Ehdotettu neuro-ominaisuusvapaa jÃĪrjestelmÃĪmme toimii kilpailevasti jÃĪrjestelmien kanssa, jotka esiteltiin viimeisimmÃĪssÃĪ Shared Task on Shallow Discuurse Parsing. Lopuksi esitetÃĪÃĪn web-front-end, joka yksinkertaistaa merkintÃķihin merkittyjen asiakirjojen tarkastusta. LÃĪhdekoodi, dokumentaatio ja esikoulutetut mallit ovat julkisesti saatavilla.', 'ca': 'Aquest paper demostra discopia, una nova estructura que fa fàcil dissenyar components per analitzar discursos baixos de final a final. Per tal de demostrar, implementam enfocaments neuronals recents i integram integracions de paraules contextualitzades per predir relacions de discurs explícites i no explícites. El nostre sistema neurològic proposat sense característiques funciona competitivament als sistemes presentats al més recent Shared Task on Shallow Discourse Parsing. Finalment, es mostra una interface web que simplifica la inspecció de documents anotats. The source code, documentation, and pretrained models are publicly accessible.', 'ha': "Wannan takardan na nuna cewa, wani firam na nowaya mai sauƙi da za'a iya ƙayyade ƙanshi wa mazaɓa na ƙari-zuwa-ƙari. For the purpose of demonstration, we implement recent neural approaches and integrate contextualized word embeddings to predict explicit and non-explicit discourse relations.  Tsarin da aka buɗa wajen wata na'urar neural, yana aiki guda zuwa na'ura da aka bai wa aikin wanda aka raba shi a yanzu a Filin Shared Aiki na Killow. Ga ƙarshe, an nuna ƙarin bayani na web, don ya sauƙa ƙe inspection of takardun takardar da aka faɗa. Suna iya samun kodi, takardar aiki da kuma misãlai da aka ƙayyade shi bayani.", 'sk': 'Ta prispevek predstavlja diskopijo, nov okvir, ki omogoča enostavno oblikovanje komponent za plitvo razčlenjanje diskurza od konca do konca. Za namen demonstracije uporabljamo novejše nevronske pristope in integracijo kontekstualiziranih besednih vdelav za napovedovanje eksplicitnih in neeksplicitnih diskurznih odnosov. Naš predlagani nevronski sistem brez funkcij deluje konkurenčno kot sistemi, predstavljeni v najnovejši skupni nalogi o plitvem razporejanju diskurza. Nazadnje je prikazana spletna frontend, ki poenostavlja pregled dokumentov z oznakami. Izvorna koda, dokumentacija in predtrenirani modeli so javno dostopni.', 'he': 'הנייר הזה מראה דיסקופיה, מסגרת חדשה שמקלה לעצב רכיבים עבור בדיקת דיבורים גבוהה בסוף לסוף. למטרה של ההדגמה, אנו ממשיכים גישות עצביות לאחרונה ולהשתלב מערכות מילים קונטקסטולוגיות כדי לחזות יחסים דיבורים ברורים ולא ברורים. Our proposed neural feature-free system performs competitively to systems presented at the latest Shared Task on Shallow Discourse Parsing.  Finally, a web front end is shown that simplifies the inspection of annotated documents.  The source code, documentation, and pretrained models are publicly accessible.', 'jv': 'Awak-awak iki diputara nesaturan karo Diskripi, akeh tur okyandik sing ngethi gampang penting komputer kanggo nyuggo nggawe barang kejahatan. Saiki wis aplikasi, kita luwih akeh pawaran Neral sing gak bakal terus ngono ingkang dipulangan word contextual Kita supoyatan sistem sing dibutuhke perusahaan-perusahaan anyar sampeyan kanggo sistem sing nyimpen nang sampeyan Kasama Atari Gak dhéwé operasi nyeangke sing gawe dalian nyeangke user Coverage', 'bo': 'ཤོག འུ་ཅག་གིས་ཉེ་ཆར་ཡོད་པའི་འཆར་བརྗོད་ཀྱི་དམིགས་ཡུལ་ལ་ངེད་ཚོས་ཉེ་ཆར་ཡུལ་གྱི་ཉེན་ཁ་གཟུགས་དང་གསལ་བཤད་མེད་པའི་སྦྲེལ་བཤད་ལ་ Our proposed neural feature-free system performs competitively to systems presented at the latest Shared Task on Shallow Discourse Parsing. མཐའ་མར་དུ། དྲ་རྒྱའི་མཐའ་མཇུག་གི་ཡིག་ཆ་རྣམས་ལྟ་ཞིབ་བཤེར་སྟངས་གཏོང་བ་མངོན་འཆར་ཡོད། ཐོག་མའི་ཨང་རིགས། ཡིག་ཆ་དང་སྔོན་ལྟར་བཀོད་པའི་དཔེ་དབྱིབས་སྤྱིར་བཏང་ནུས་མེད་པར།'}
{'en': 'Capturing document context inside sentence-level neural machine translation models with self-training', 'ar': 'التقاط سياق المستند داخل نماذج الترجمة الآلية العصبية على مستوى الجملة مع التدريب الذاتي', 'pt': 'Capturando o contexto do documento dentro de modelos de tradução automática neural em nível de sentença com autotreinamento', 'fr': 'Capture du contexte du document dans des modèles de traduction automatique neuronale au niveau de la phrase avec auto-apprentissage', 'es': 'Captura del contexto del documento dentro de modelos de traducción automática neuronal a nivel de oración con autoaprendizaje', 'ja': 'セルフトレーニングで文章レベルのニューラル機械翻訳モデル内の文書コンテキストをキャプチャする', 'zh': '自练句级神经机器翻译模形中获文档上下文', 'hi': 'आत्म-प्रशिक्षण के साथ वाक्य-स्तरीय तंत्रिका मशीन अनुवाद मॉडल के अंदर दस्तावेज़ संदर्भ कैप्चर करना', 'ru': 'Захват контекста документа внутри моделей нейронного машинного перевода НА уровне предложений С самообучением', 'ga': 'Comhthéacs doiciméad a ghabháil taobh istigh de mhúnlaí néaraistriúcháin ag leibhéal na habairte le féin-oiliúint', 'ka': 'დოკუმენტის კონტექსტის ჩატვირთვა სიტყვების ნეიროლური მაქინის გადატვირთვა მოდელების შორის', 'el': 'Καταγραφή του πλαισίου εγγράφων μέσα σε μοντέλα νευρολογικής μηχανικής μετάφρασης σε επίπεδο προτάσεων με αυτοεκπαίδευση', 'hu': 'Dokumentumkontextus rögzítése mondatszintű neurális gépi fordítási modelleken belül önképzéssel', 'kk': 'Құжаттың контексті сөз деңгейіндегі невралдық компьютердің аудару үлгілерін автооқытумен түсіру', 'it': "Catturare il contesto del documento all'interno di modelli di traduzione automatica neurale a livello di frase con auto-allenamento", 'lt': 'Dokumento konteksto sugavimas sakinių lygio nervinių mašinų vertimo modeliuose su savarankišku mokymu', 'mk': 'Земање на контекст на документот во моделите за превод на невропска машина на ниво на реченици со самообука', 'ms': 'Menangkap konteks dokumen didalam model terjemahan mesin saraf tahap kalimat dengan latihan-sendiri', 'mt': 'Il-qbid tal-kuntest tad-dokument fil-mudelli tat-traduzzjoni tal-magni newrali fil-livell tas-sentenza b’taħriġ awtonomu', 'ml': 'വാക്ക്- ന്യൂറല്\u200d മെഷീന്\u200d പരിശീലനത്തിന്റെ ഉള്ളിലുള്ള രേഖപ്രകൃതിയെ പിടികൂടുന്നു', 'mn': 'Өөрийгөө сургалтын тусламжтай баримтуудын тусламжтайгаар баримтуудын тусламжтайгаар', 'no': 'Hentar dokumentkontekst inni setningnivået neuralmaskineomsetjingsmodular med selvøving', 'ro': 'Capturarea contextului documentelor în interiorul modelelor de traducere automată neurală la nivel de frază cu auto-instruire', 'pl': 'Przechwytywanie kontekstu dokumentu wewnątrz neuronowych modeli tłumaczenia maszynowego na poziomie zdań z samodzielnym treningiem', 'sr': 'Uhvaćenje konteksta dokumenta unutar modela prevođenja neuralnih mašina na nivou rečenica sa samouvježbom', 'ta': 'தானே பயிற்சியுடன் வாக்கி- மட்டத்தின் உள்ளே நெருக்கல் இயந்திரம் மொழிபெயர்ப்பு மாதிரிகளை பிடித்', 'so': 'Isku qabsashada qoraalka hoose-heer neural tarjumista machine-neural models with self-training', 'sv': 'FĂ¥nga dokumentkontext inuti neurala maskinĂ¶versĂ¤ttningsmodeller pĂ¥ meningsnivĂ¥ med sjĂ¤lvtrĂ¤ning', 'si': 'වාක්ය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සඳහා වාක්ය සම්පූර්ණය සඳහා වාක්ය න්\u200dයූරාල', 'ur': 'مجازات-سطح نیورل ماشین ترجمہ موڈل کے اندر دفتر کا کنٹکس کاٹ کر رہا ہے', 'uz': 'Name', 'vi': 'Nhận bối cảnh tài liệu bên trong các mô hình dịch máy thần kinh cấp bản án', 'bg': 'Заснемане на контекста на документа в моделите на невронен машинен превод на ниво изречение със самообучение', 'da': 'Optagelse af dokumentkontekst inde i neurale maskinoversættelsesmodeller på sætningsniveau med selvtræning', 'nl': 'Documentcontext vastleggen in neurale machinevertaalmodellen op zinsniveau met zelftraining', 'id': 'Menangkap konteks dokumen di dalam model terjemahan mesin saraf tingkat kalimat dengan latihan sendiri', 'ko': '자체 훈련을 바탕으로 하는 문장급 신경기계 번역 모델에서 문서 상하문 포획', 'hr': 'Uhvaćenje konteksta dokumenta unutar modela prevoda neuralnih strojeva na razini rečenica sa samouvježbom', 'de': 'Erfassung von Dokumentenkontext in neuronalen maschinellen Übersetzungsmodellen auf Satzebene mit Selbsttraining', 'tr': 'Sened derejesi näyral maşynyň terjime modelleri özi-okuw bilen taýýarlar', 'af': 'Opneem dokument konteks binne sentralvlak neurale masjien vertaling modele met self-oefening', 'fa': 'حاضر کردن محیط سند در مدل ترجمه\u200cهای ماشین عصبی سطح جمله با آموزش خودش', 'sw': 'Kuchukua muktadha wa dokumenta ndani ya kiwango cha sentence-level neural translation models with self-training', 'hy': 'Capturing document context inside sentence-level neural machine translation models with self-training', 'sq': 'Duke kapur kontekstin e dokumentit brenda modeleve të përkthimit të makinave nervore me vetëtrajnimin', 'am': 'አዲስ ዶሴ ፍጠር', 'az': 'Sözlük seviyyətində nöral maşın çevirilməsi modellərinin içində döküm məlumatını özünü təhsil edir', 'bs': 'Uhvaćanje konteksta dokumenta unutar modela prevoda neuralnih strojeva na razini rečenica sa samouvježbom', 'ca': 'Capturing document context inside sentence-level neural machine translation models with self-training', 'cs': 'Zachycení kontextu dokumentů v neuronových strojových překladatelských modelech na úrovni vět s vlastním tréninkem', 'et': 'Dokumendikonteksti jäädvustamine lausetaseme neuromasintõlke mudelites eneseõppega', 'fi': 'Asiakirjakontekstin kaappaaminen lausetason neurokonek√§√§nn√∂smalleissa itseharjoittelulla', 'bn': 'স্বয়ংক্রিয় প্রশিক্ষণের মাধ্যমে শব্দ-স্তরের নিউরাল মেশিন অনুবাদ মডেলের ভেতরে নথির প্রেক্ষাপট', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'מציאת קשר מסמך בתוך דוגמני התרגום של מכונות עצביות ברמה של משפט עם אימון עצמי', 'ha': 'An kãma mazaɓa na takardar aiki guda da zane-daraja neural fassarar maɓallin neural da amfani da masu yin amfani da kansu', 'bo': 'ཡིག་ཆའི་སྐོར་ཡུག་ཅིག་ནང་དུ་ཚིག་ཆས་ཀྱི་ནུས་པ་དང་རང་ཉིད་ལྟ་བུ་ཡིན་པ', 'sk': 'Zajemanje konteksta dokumentov znotraj modelov nevronskega strojnega prevajanja na ravni stavka s samousposabljanjem'}
{'en': 'Neural machine translation (NMT) has arguably achieved human level parity when trained and evaluated at the ', 'ar': 'يمكن القول إن الترجمة الآلية العصبية (NMT) قد حققت التكافؤ على المستوى البشري عند تدريبها وتقييمها على مستوى الجملة. لقد حظيت الترجمة الآلية العصبية على مستوى الوثيقة باهتمام أقل وتأخرت عن نظيرتها على مستوى الجملة. تبحث غالبية الأساليب المقترحة على مستوى المستند في طرق تكييف النموذج على عدة جمل مصدر أو هدف لالتقاط سياق المستند. تتطلب هذه الأساليب تدريب نموذج NMT متخصص من البداية على هيئة وثيقة على مستوى مواز. نقترح نهجًا لا يتطلب تدريب نموذج متخصص على هيئة مستندات موازية ويتم تطبيقه على نموذج NMT على مستوى الجملة في وقت فك التشفير. نعالج المستند من اليسار إلى اليمين عدة مرات ونقوم بالتدريب الذاتي على نموذج مستوى الجملة على أزواج من الجمل المصدر والترجمات المُنشأة. يعزز نهجنا الاختيارات التي يقوم بها النموذج ، مما يزيد من احتمالية اتخاذ نفس الخيارات في جمل أخرى في المستند. نقوم بتقييم نهجنا على ثلاث مجموعات بيانات على مستوى المستندات: NIST الصينية-الإنجليزية ، WMT19 الصينية-الإنجليزية و OpenSubtitles الإنجليزية-الروسية. نثبت أن نهجنا لديه درجة أعلى من BLEU وتفضيل بشري أعلى من خط الأساس. يُظهر التحليل النوعي لنهجنا أن الاختيارات التي يتم إجراؤها حسب النموذج متسقة عبر المستند.', 'pt': 'A tradução automática neural (NMT) alcançou a paridade no nível humano quando treinada e avaliada no nível da sentença. A tradução automática neural em nível de documento recebeu menos atenção e fica atrás de sua contraparte em nível de sentença. A maioria das abordagens de nível de documento propostas investigam maneiras de condicionar o modelo em várias frases de origem ou destino para capturar o contexto do documento. Essas abordagens exigem o treinamento de um modelo NMT especializado a partir do zero em corpora em nível de documento paralelo. Propomos uma abordagem que não requer o treinamento de um modelo especializado em corpora em nível de documento paralelo e é aplicada a um modelo NMT em nível de sentença treinado no momento da decodificação. Processamos o documento da esquerda para a direita várias vezes e treinamos o modelo de nível de sentença em pares de sentenças de origem e traduções geradas. Nossa abordagem reforça as escolhas feitas pelo modelo, tornando mais provável que as mesmas escolhas sejam feitas em outras frases do documento. Avaliamos nossa abordagem em três conjuntos de dados em nível de documento: NIST chinês-inglês, WMT19 chinês-inglês e OpenSubtitles inglês-russo. Demonstramos que nossa abordagem tem maior pontuação BLEU e maior preferência humana do que a linha de base. A análise qualitativa de nossa abordagem mostra que as escolhas feitas por modelo são consistentes em todo o documento.', 'es': 'Se puede decir que la traducción automática neuronal (NMT) ha alcanzado la paridad a nivel humano cuando se entrena y se evalúa a nivel de oración. La traducción automática neuronal a nivel de documento ha recibido menos atención y va a la zaga de su contraparte a nivel de oración. La mayoría de los enfoques propuestos a nivel de documento investigan formas de condicionar el modelo en varias oraciones de origen o destino para capturar el contexto del documento. Estos enfoques requieren la capacitación de un modelo NMT especializado desde cero en corpus paralelos a nivel de documento. Proponemos un enfoque que no requiere entrenar un modelo especializado en corpus paralelos a nivel de documento y que se aplica a un modelo NMT entrenado a nivel de oración en el momento de la decodificación. Procesamos el documento de izquierda a derecha varias veces y entrenamos automáticamente el modelo a nivel de oración en pares de oraciones fuente y traducciones generadas. Nuestro enfoque refuerza las elecciones realizadas por el modelo, lo que hace más probable que se tomen las mismas decisiones en otras frases del documento. Evaluamos nuestro enfoque en tres conjuntos de datos a nivel de documento: chino-inglés del NIST, chino-inglés WMT19 y OpenSubtitles inglés-ruso. Demostramos que nuestro enfoque tiene una puntuación BLEU más alta y una preferencia humana más alta que la línea base. El análisis cualitativo de nuestro enfoque muestra que las elecciones realizadas por modelo son consistentes en todo el documento.', 'fr': "La traduction automatique neuronale (NMT) a sans doute atteint la parité au niveau humain lorsqu'elle est entraînée et évaluée au niveau de la phrase. La traduction automatique neuronale au niveau du document a reçu moins d'attention et est en retard par rapport à son homologue au niveau de la phrase. La majorité des approches proposées au niveau du document étudient les moyens de conditionner le modèle sur plusieurs phrases sources ou cibles afin de saisir le contexte du document. Ces approches nécessitent la formation d'un modèle NMT spécialisé à partir de zéro sur des corpus parallèles au niveau du document. Nous proposons une approche qui ne nécessite pas de formation d'un modèle spécialisé sur des corpus parallèles au niveau du document et qui est appliquée à un modèle NMT au niveau de la phrase entraîné au moment du décodage. Nous traitons le document de gauche à droite plusieurs fois et nous auto-entraînons le modèle au niveau de la phrase sur des paires de phrases sources et des traductions générées. Notre approche renforce les choix faits par le modèle, ce qui augmente la probabilité que les mêmes choix soient faits dans d'autres phrases du document. Nous évaluons notre approche sur trois ensembles de données au niveau du document\xa0: NIST chinois-anglais, WMT19 chinois-anglais et OpenSubtitles anglais-russe. Nous démontrons que notre approche a un score UEBL plus élevé et une préférence humaine plus élevée que le niveau de référence. L'analyse qualitative de notre approche montre que les choix faits par modèle sont cohérents dans l'ensemble du document.", 'hi': 'तंत्रिका मशीन अनुवाद (एनएमटी) ने वाक्य-स्तर पर प्रशिक्षित और मूल्यांकन किए जाने पर यकीनन मानव स्तर की समानता हासिल की है। दस्तावेज़-स्तर के तंत्रिका मशीन अनुवाद को कम ध्यान दिया गया है और अपने वाक्य-स्तर के समकक्ष से पीछे है। प्रस्तावित दस्तावेज़-स्तर के अधिकांश दृष्टिकोण दस्तावेज़ संदर्भ को कैप्चर करने के लिए कई स्रोतों या लक्ष्य वाक्यों पर मॉडल को कंडीशनिंग करने के तरीकों की जांच करते हैं। इन दृष्टिकोणों को समानांतर दस्तावेज़-स्तर के कॉर्पोरेट पर खरोंच से एक विशेष एनएमटी मॉडल को प्रशिक्षित करने की आवश्यकता होती है। हम एक ऐसे दृष्टिकोण का प्रस्ताव करते हैं जिसके लिए समानांतर दस्तावेज़-स्तर के कॉर्पोरेट पर एक विशेष मॉडल को प्रशिक्षित करने की आवश्यकता नहीं होती है और इसे डिकोडिंग समय पर एक प्रशिक्षित वाक्य-स्तरीय एनएमटी मॉडल पर लागू किया जाता है। हम दस्तावेज़ को बाएं से दाएं कई बार संसाधित करते हैं और स्रोत वाक्यों और उत्पन्न अनुवादों के जोड़े पर वाक्य-स्तर के मॉडल को स्वयं प्रशिक्षित करते हैं। हमारा दृष्टिकोण मॉडल द्वारा किए गए विकल्पों को मजबूत करता है, इस प्रकार यह अधिक संभावना बनाता है कि दस्तावेज़ में अन्य वाक्यों में समान विकल्प बनाए जाएंगे। हम तीन दस्तावेज़-स्तरीय डेटासेट पर हमारे दृष्टिकोण का मूल्यांकन करते हैं: NIST चीनी-अंग्रेजी, WMT19 चीनी-अंग्रेजी और OpenSubtitles अंग्रेजी-रूसी। हम प्रदर्शित करते हैं कि हमारे दृष्टिकोण में बेसलाइन की तुलना में उच्च BLEU स्कोर और उच्च मानव वरीयता है। हमारे दृष्टिकोण के गुणात्मक विश्लेषण से पता चलता है कि मॉडल द्वारा किए गए विकल्प दस्तावेज़ में सुसंगत हैं।', 'zh': '神经机器翻译(NMT)于句级训练,可谓成人伦矣。 文档级神经机器译所关注较少,且后句级译。 大抵议者文档级法皆究数源句或趋句调模以获文档上下文法。 其法须并行档级语料库上从头始练专 NMT 。 臣等条上不须并行档级语料库上专用模形之法,并于解码时应用句级 NMT 模。 我从左到右屡理文档,并于源句成译自练。 吾道化模形,文档句更可同。 予于三文档级数据集上评估:NIST中文 - 英语,WMT19中文 - 英语OpenSubtitles英语 - 俄语。 吾证与基线比,吾道有更高BLEU分数与更高之人偏好。 吾道之定性分析明,以形为一文档。', 'ja': 'ニューラル・マシン・トランスレーション（ NMT ）は、文レベルで訓練され評価されると、人間レベルのパリティを達成したと言える。 文書レベルのニューラル機械翻訳はあまり注目されておらず、文レベルの対応よりも遅れています。 提案されている文書レベルのアプローチの大部分は、文書のコンテキストをキャプチャするために、いくつかのソースまたはターゲット文にモデルを条件付けする方法を調査する。 これらのアプローチでは、並列ドキュメントレベルのコーパスで専門的なNMTモデルを一からトレーニングする必要があります。 我々は、並列文書レベルのコーラに関する専門モデルのトレーニングを必要とせず、デコード時に訓練された文レベルのNMTモデルに適用されるアプローチを提案します。 文書を左から右に複数回処理し、ソース文と生成された翻訳のペアについて文レベルのモデルをセルフトレーニングします。 私たちのアプローチは、モデルによって行われた選択を強化するため、ドキュメントの他の文で同じ選択が行われる可能性が高くなります。 NIST Chinese - English、WMT 19 Chinese - English、OpenSubtitles English - Russianの3つの文書レベルのデータセットに関するアプローチを評価します。 我々のアプローチは、ベースラインよりも高いBLEUスコアと高いヒトの好みを有することを実証している。 私たちのアプローチの定性的分析は、モデルによる選択が文書全体で一貫していることを示しています。', 'ru': 'Нейронный машинный перевод (НМП), возможно, достиг паритета человеческого уровня при обучении и оценке на уровне предложения. Нейронный машинный перевод на уровне документа получил меньше внимания и отстает от своего аналога на уровне предложения. Большинство предлагаемых подходов на уровне документа изучают способы обусловленности модели несколькими исходными или целевыми предложениями для отражения контекста документа. Эти подходы требуют обучения специализированной модели НМТ с нуля на параллельных корпусах на уровне документов. Мы предлагаем подход, который не требует обучения специализированной модели на параллельных корпусах на уровне документа и применяется к обученной модели NMT на уровне предложения во время декодирования. Мы обрабатываем документ слева направо несколько раз и самостоятельно обучаем модель на уровне предложений на парах исходных предложений и сгенерированных переводов. Наш подход усиливает выбор, сделанный моделью, тем самым повышая вероятность того, что такой же выбор будет сделан в других предложениях документа. Мы оцениваем наш подход на трех наборах данных на уровне документов: NIST Chinese-English, WMT19 Chinese-English и OpenSubtitles English-Russian. Мы демонстрируем, что наш подход имеет более высокий балл BLEU и более высокие предпочтения человека, чем исходный уровень. Качественный анализ нашего подхода показывает, что выбор, сделанный моделью, согласуется по всему документу.', 'ga': 'D’fhéadfaí a áitiú go bhfuil paireacht leibhéal daonna bainte amach ag an néaraistriúchán meaisín (NMT) nuair a cuireadh oiliúint air agus nuair a dhéantar é a mheas ag leibhéal na pianbhreithe. Is lú aird a tugadh ar aistriúchán meaisín néarach ag leibhéal doiciméad agus tá sé chun deiridh ar a mhacasamhail de phianbhreith. Iniúchann formhór na gcur chuige atá beartaithe ar leibhéal doiciméad bealaí chun an tsamhail a riochtú ar roinnt abairtí foinsí nó sprioc-abairtí chun comhthéacs doiciméad a ghabháil. Éilíonn na cineálacha cur chuige seo múnla speisialaithe NMT a oiliúint ón tús ar chorpas comhthreomhar ar leibhéal doiciméad. Molaimid cur chuige nach n-éilíonn múnla speisialaithe a oiliúint ar chorpora comhthreomhar leibhéal doiciméad agus a chuirtear i bhfeidhm ar mhúnla NMT oilte ar leibhéal pianbhreithe ag am díchódaithe. Déanaimid an doiciméad a phróiseáil ó chlé go deas arís agus arís eile agus déanaimid féin-thraenáil ar an múnla leibhéal na habairte ar phéirí abairtí foinse agus aistriúcháin ghinte. Treisíonn ár gcur chuige na roghanna a dhéanann an tsamhail, rud a fhágann gur dóichí go ndéanfar na roghanna céanna in abairtí eile sa doiciméad. Déanaimid measúnú ar ár gcur chuige maidir le trí thacar sonraí ar leibhéal doiciméad: NIST Sínis-Béarla, WMT19 Sínis-Béarla agus OpenSubtitles Béarla-Rúisis. Léirímid go bhfuil scór BLEU níos airde ag ár gcur chuige agus tosaíocht dhaonna níos airde ná an bhunlíne. Léiríonn anailís cháilíochtúil ar ár gcur chuige go bhfuil na roghanna a dhéantar de réir samhail comhsheasmhach ar fud an doiciméid.', 'hu': 'A neurális gépi fordítás (NMT) vitathatóan elérte az emberi szintű egyenlőséget mondatszinten történő kiképzés és értékelés során. A dokumentum szintű neurális gépi fordítás kevesebb figyelmet kapott és lemarad a mondatszintű megfelelője mögött. A javasolt dokumentumszintű megközelítések többsége azt vizsgálja, hogy miként lehet a modell több forrás- vagy célmondatra történő kondicionálását a dokumentum kontextusának rögzítése érdekében. Ezek a megközelítések szükségessé teszik egy speciális NMT modellt a semmiből, párhuzamos dokumentumszintű korpuszokon. Olyan megközelítést javaslunk, amely nem igényel speciális modellt párhuzamos dokumentumszintű corporákra vonatkozóan, és amelyet a dekódolás időpontjában egy képzett mondatszintű NMT modellre alkalmaznak. A dokumentumot balról jobbra többször is feldolgozzuk, és a mondatszintű modellt önként edzünk forrásként és generált fordításokon. Megközelítésünk megerősíti a modell által hozott döntéseket, így nagyobb valószínűséggel bír, hogy ugyanezeket a döntéseket a dokumentum más mondataiban is meghozzák. Megközelítésünket három dokumentumszintű adatkészleten értékeljük: NIST kínai-angol, WMT19 kínai-angol és OpenSubtitles angol-orosz. Bemutatjuk, hogy megközelítésünk magasabb BLEU pontszámmal és magasabb emberi preferenciával rendelkezik, mint a kiindulási érték. A megközelítésünk minőségi elemzése azt mutatja, hogy a modell szerinti döntések következetesek az egész dokumentumban.', 'ka': 'ნეიროლური მანქანის გადაწყვეტილება (NMT) ადამიანის დონეზე დასრულებულია, როდესაც მანქანა და გაუმუშავებულია სიტყვების დონეში. დოკუმენტის დოკუმენტის ნეიროლური მანქანის გაგრძელება უფრო მეტად აღმოჩენა და მისი სიტყვის დოკუმენტის გაგრძელება. პირველი დოკუმენტის უფრო დისკუმენტის დოკუმენტის შესახებ მოდელის შესახებ რამდენიმე მსოფლიოს ან მისახებ წესების შესახებ დოკუმენტის კო ამ მიზეზების შესაძლებლობად სპეციალური NMT მოდელის შესაბამისი პერალელური დოკუმენტის კოპორაციაზე მოჭირდება. ჩვენ გვეძლევა პროგრამა, რომელიც არ მოჭირდება სპეციალური მოდელს პარალელური დოკუმენტის კოპორაციაზე და გამოყენება განსწავლებული სიტყვების NMT მოდელში. ჩვენ ვაპროცესებთ დოკუმენტის მარცხნიდან მარცხნიდან რამდენიმე პარამეტრებით და თავისუფალურად მოდელის მარცხნის მოდელის მარცხნიდან და შექმნა ჩვენი პროგორმა მოდელზე გავაკეთება მონიშნულებების შესაძლებლობა, რადგან უფრო შესაძლებელია, რომ იგივე მონიშნულება კოკუმენტის სხვადასხვადასხვადასხვადასხვადასხვ ჩვენ მივიღებთ სამი დოკუმენტის მონაცემების შესახებ: NIST ჩინეთი- ანგლისური, WMT19 ჩინეთი- ანგლისური და OpenSubtitles ინგლისური- პროსური. ჩვენ გამოჩვენებთ, რომ ჩვენი წარმოდგენა უფრო მეტი BLEU წარმოდგენა და უფრო მეტი ადამიანის წარმოდგენება, ვიდრე ბაზილინაზე. ჩვენი წარმოდგენის კვალიტატიური ანალიზია, რომ მოდელზე გავაკეთებული არჩევა კონსტენტიური დოკუმენტში.', 'it': "La traduzione automatica neurale (NMT) ha probabilmente raggiunto la parità di livello umano quando addestrato e valutato a livello di frase. La traduzione automatica neurale a livello di documento ha ricevuto meno attenzione e rimane indietro rispetto alla sua controparte a livello di frase. La maggior parte degli approcci proposti a livello di documento indaga modi di condizionare il modello su diverse frasi di origine o destinazione per catturare il contesto del documento. Questi approcci richiedono la formazione di un modello NMT specializzato da zero su corpi paralleli a livello di documento. Proponiamo un approccio che non richiede la formazione di un modello specializzato su corpora a livello di documento parallelo e che viene applicato a un modello NMT addestrato a livello di frase al momento della decodifica. Elaboriamo il documento da sinistra a destra più volte e autoaddestriamo il modello a livello di frase su coppie di frasi sorgente e traduzioni generate. Il nostro approccio rafforza le scelte fatte dal modello, rendendo così più probabile che le stesse scelte vengano fatte in altre frasi del documento. Valutiamo il nostro approccio su tre set di dati a livello documentale: NIST cinese-inglese, WMT19 cinese-inglese e OpenSubtitles inglese-russo. Dimostriamo che il nostro approccio ha un punteggio BLEU più alto e una preferenza umana più elevata rispetto al basale. L'analisi qualitativa del nostro approccio mostra che le scelte fatte per modello sono coerenti in tutto il documento.", 'mk': "Неуралниот машински превод (НМТ) веројатно постигна паричност на човечко ниво кога е обучен и оценет на ниво на реченица. Неуралниот превод на машина на ниво на документ доби помалку внимание и останува зад својот колега на ниво на реченица. Повеќето од предложените пристапи на ниво на документ истражуваат начини за условување на моделот на неколку реченици од извор или мета за зафатување на контекст на документот. Овие пристапи бараат обука на специјализиран модел на НМТ од нула на паралелна корпора на документно ниво. We propose an approach that doesn't require training a specialized model on parallel document-level corpora and is applied to a trained sentence-level NMT model at decoding time.  We process the document from left to right multiple times and self-train the sentence-level model on pairs of source sentences and generated translations.  Нашиот пристап ги зајакнува изборите направени од моделот, со што ќе биде поверојатно истите избори да бидат направени во другите реченици во документот. Го проценуваме нашиот пристап на три податоци на ниво на документи: NIST кинески-англиски, WMT19 кинески-англиски и OpenSubtitles англиски-руски. Демонстрираме дека нашиот пристап има повисока оценка БЛЕУ и повисока човечка преференција од основната. Квалитативната анализа на нашиот пристап покажува дека изборите направени по моделот се константни низ целиот документ.", 'ml': 'വാക്ക് നിലയില്\u200d പരിശീലിക്കുകയും വിലയിക്കുകയും ചെയ്തപ്പോള്\u200d നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയിരിക്കുന്നു. രേഖപ്രകാരം- ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ കുറഞ്ഞ ശ്രദ്ധ കിട്ടിയിട്ടുണ്ട്. വാക്ക്- നില വിഭാഗത്തിന്റെ പിന് പ്രൊദ്ദേശിക്കപ്പെട്ട രേഖയുടെ നില മിക്കവേറെ രേഖയില്\u200d രേഖപ്രകൃതിയെ പിടിച്ചെടുക്കുന്നതിനായി മോഡലിന്റെ നില ഈ സമ്പാദ്യങ്ങള്\u200d നമ്മള്\u200d ഒരു നിര്\u200dദ്ദേശം നിര്\u200dദ്ദേശിക്കുന്ന ഒരു പ്രത്യേക മോഡലിനെ പരിശീലനത്തിന് ആവശ്യമില്ലാത്ത മാതൃകയാണ് പ്രദര്\u200dശിപ്പിക്കുന്നത്. പാരാ ഇടത്തുനിന്നും വലതുവശത്തുനിന്നും രേഖയെ ഞങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. സ്വയം വാക്ക്-നില മോഡല്\u200d സ്വയം പരിശീലിപ്പിക നമ്മുടെ അടുത്തേക്ക് മാതൃകയുടെ തെരഞ്ഞെടുക്കുന്ന തെരഞ്ഞെടുപ്പുകള്\u200d ശക്തിപ്പെടുത്തുന്നു. അതുകൊണ്ട് രേഖയില്\u200d മറ് ഞങ്ങള്\u200d മൂന്നു രേഖകളുടെ നിലവിലെ ഡാറ്റാസറ്റുകളില്\u200d നമ്മുടെ പ്രോഗത്തെ വിലയിച്ചുകൊടുക്കുന്നു. NIST ചൈനീസ്-ഇംഗ്ലീഷ്,  നമ്മുടെ അടുത്തുള്ള അടിസ്ഥാനത്തിനെക്കാള്\u200d ഉയര്\u200dന്ന ബില്ലൂ സ്കോര്\u200d ഉണ്ടെന്നും മുന്\u200dഗണന മനുഷ്യന്റെ മു നമ്മുടെ പ്രോഗത്തിന്റെ കൂട്ടത്തിലുള്ള വിശദീകരണവും കാണിക്കുന്നു മോഡല്\u200d ചെയ്ത ത തിരഞ്ഞെടുക്കകള്\u200d ര', 'el': 'Η νευρωνική μηχανική μετάφραση (NMT) έχει αναμφίβολα επιτύχει ισότητα σε ανθρώπινο επίπεδο όταν εκπαιδεύεται και αξιολογείται σε επίπεδο πρότασης. Η νευρολογική μηχανική μετάφραση σε επίπεδο εγγράφου έχει λάβει λιγότερη προσοχή και υστερεί πίσω από το αντίστοιχο της σε επίπεδο πρότασης. Η πλειονότητα των προτεινόμενων προσεγγίσεων σε επίπεδο εγγράφων διερευνά τρόπους προσαρμογής του μοντέλου σε διάφορες προτάσεις πηγής ή στόχου για να συλλάβει το πλαίσιο του εγγράφου. Αυτές οι προσεγγίσεις απαιτούν την εκπαίδευση ενός εξειδικευμένου μοντέλου από την αρχή σε παράλληλα σώματα επιπέδου εγγράφων. Προτείνουμε μια προσέγγιση που δεν απαιτεί εκπαίδευση εξειδικευμένου μοντέλου σε παράλληλα σώματα σε επίπεδο εγγράφων και εφαρμόζεται σε ένα εκπαιδευμένο μοντέλο σε επίπεδο πρότασης σε χρόνο αποκωδικοποίησης. Επεξεργαζόμαστε το έγγραφο από αριστερά προς τα δεξιά πολλές φορές και εκπαιδεύουμε το μοντέλο σε επίπεδο πρότασης σε ζεύγη προτάσεων προέλευσης και δημιουργημένων μεταφράσεων. Η προσέγγισή μας ενισχύει τις επιλογές που κάνει το μοντέλο, καθιστώντας έτσι πιο πιθανό να γίνουν οι ίδιες επιλογές και σε άλλες προτάσεις του εγγράφου. Αξιολογούμε την προσέγγισή μας σε τρία σύνολα δεδομένων σε επίπεδο εγγράφων: Κινέζικα-Αγγλικά, Κινέζικα-Αγγλικά και Αγγλικά-Ρωσικά. Αποδεικνύουμε ότι η προσέγγισή μας έχει υψηλότερη βαθμολογία και υψηλότερη ανθρώπινη προτίμηση από τη βασική. Η ποιοτική ανάλυση της προσέγγισής μας δείχνει ότι οι επιλογές που γίνονται ανά μοντέλο είναι συνεπείς σε όλο το έγγραφο.', 'ms': 'Terjemahan mesin saraf (NMT) mungkin telah mencapai pariti aras manusia bila dilatih dan diteliti pada aras kalimat. Terjemahan mesin saraf aras dokumen telah menerima kurang perhatian dan tertinggal di belakang kontrak aras kalimat. Kebanyakan pendekatan aras-dokumen yang diusulkan menyelidiki cara untuk menguatkan model pada beberapa kalimat sumber atau sasaran untuk menangkap konteks dokumen. Pendekatan ini memerlukan latihan model NMT khusus dari awal pada korpra aras dokumen selari. Kami cadangkan pendekatan yang tidak memerlukan latihan model khusus pada korpra aras dokumen selari dan dilaksanakan pada model NMT aras kalimat terlatih pada masa penyahkodan. We process the document from left to right multiple times and self-train the sentence-level model on pairs of source sentences and generated translations.  Pendekatan kami menguatkan pilihan yang dibuat oleh model, sehingga ia lebih mungkin pilihan yang sama akan dibuat dalam kalimat lain dalam dokumen. Kami menilai pendekatan kami pada tiga set data aras dokumen: NIST Chinese-English, WMT19 Chinese-English dan OpenSubtitles English-Russian. Kami menunjukkan bahawa pendekatan kita mempunyai skor BLEU yang lebih tinggi dan keutamaan manusia yang lebih tinggi daripada asas. Analisis kualitif pendekatan kita menunjukkan bahawa pilihan yang dibuat oleh model adalah konsisten di seluruh dokumen.', 'lt': "Nervų mašinų vertimas (NMT) tikriausiai pasiekė žmogaus lygio lygybę mokant ir vertinant bausmės lygiu. Dokumentų lygmens nervinių mašinų vertimas gauna mažiau dėmesio ir atsilieka nuo jo atsakymo lygio. Daugumoje pasiūlytų dokumentų lygmens metodų nagrinėjami būdai, kaip model į suderinti su keliais šaltiniais arba tiksliniais sakiniais, kad būtų galima nustatyti dokumentų kontekstą. Šiems metodams iš pradžių reikia parengti specializuotą NMT model į lygiagrečiai dokumentų lygiu veikiančiame korpore. We propose an approach that doesn't require training a specialized model on parallel document-level corpora and is applied to a trained sentence-level NMT model at decoding time.  Mes tvarkome dokumentą iš kairės į dešinę kelis kartus ir savarankiškai treniruojame sakinių lygio model į pora pradinių sakinių ir sukauptais vertimais. Mūsų požiūris sustiprina modelio pasirinkimus ir taip padidina tikimybę, kad tie patys pasirinkimai bus daromi kituose dokumento sakiniuose. Vertiname savo požiūrį pagal tris dokumentų lygmens duomenų rinkinius: NIST Kinijos-anglų, WMT19 Kinijos-anglų ir OpenSubtitles anglų-rusų. Mes įrodome, kad mūsų požiūris turi didesnį BLEU rezultatą ir didesnį žmogaus pirmenybę nei pradinis. Mūsų požiūrio kokybinė analizė rodo, kad pasirinkimai pagal model į yra nuoseklūs visame dokumente.", 'mt': 'Neural machine translation (NMT) has arguably achieved human level parity when trained and evaluated at the sentence-level.  It-traduzzjoni tal-magna newrali fil-livell tad-dokument irċeviet inqas attenzjoni u għadha lura mill-kontroparti tagħha fil-livell tas-sentenza. Il-maġġoranza tal-approċċi proposti fil-livell tad-dokument jinvestigaw modi kif il-mudell jiġi kkundizzjonat fuq diversi sentenzi tas-sors jew fil-mira biex jinqabad il-kuntest tad-dokument. Dawn l-approċċi jeħtieġu taħriġ ta’ mudell speċjalizzat ta’ NMT mill-bidu fuq korpra parallel a fil-livell tad-dokument. Aħna nipproponu approċċ li ma jeħtieġx t a ħriġ mudell speċjalizzat dwar korpra parallel a fil-livell tad-dokument u li jiġi applikat għal mudell NMT imħarreġ fil-livell tas-sentenza fil-ħin tad-dekodifikazzjoni. Aħna nipproċessaw id-dokument minn xellug għal lemin diversi drabi u nħarrġu lilna nnifisna l-mudell fil-livell tas-sentenza fuq pari ta’ sentenzi tas-sors u traduzzjonijiet iġġenerati. L-approċċ tagħna jsaħħaħ l-għażliet magħmula mill-mudell, u b’hekk jagħmilha aktar probabbli li l-istess għażliet isiru f’sentenzi oħra fid-dokument. Aħna jevalwaw l-approċċ tagħna fuq tliet settijiet ta’ dejta fil-livell ta’ dokumenti: NIST Ċiniż-Ingliż, WMT19 Ċiniż-Ingliż u OpenSubtitles Ingliż-Russu. Aħna nuru li l-approċċ tagħna għandu punteġġ BLEU ogħla u preferenza umana ogħla mil-linja bażi. Analiżi kwalitattiva tal-approċċ tagħna turi li l-għażliet magħmula skont il-mudell huma konsistenti fid-dokument kollu.', 'mn': 'Цөмийн мэдрэлийн машин хөрөнгө оруулалт (NMT) нь хүн төрөлхтний түвшинд суралцаж, шалгалтын түвшинд үнэлэх үед хүн төрөлхтний төвшинд хүргэсэн байдаг. Документын түвшинд мэдрэлийн машины хөрөнгө оруулалт анхаарлыг багасгаж, өгүүлбэр-түвшинд хамааралтай байдаг. Өөрчлөгдсөн баримт түвшингийн ихэнх нь баримт орчиныг барьж авах хэдэн эх үүсвэр эсвэл зорилготой өгүүлбэр дээр загварыг шалгаж байдаг. Эдгээр арга баримтууд параллел баримтуудын төвшин корпора дээр төрлийн NMT загварыг суралцах шаардлагатай. Бид параллел документийн түвшинд мэргэжлийн загварыг суралцах шаардлагагүй арга загварыг санал дэвшүүлнэ. NMT хэмжээнд суралцагдсан өгүүлбэрийн түвшинд суралцагддаг. Бид баруун тийш баруун тийш баруун тийш баруун тийш бичсэн баримтуудыг олон удаа үйлдвэрлэж өгүүлбэрийн хэлбэрийг эх үүсвэрийн өгүүлбэртэй хоёр хэлбэрээр суралцдаг. Бидний арга баримт загвараар хийсэн сонголтуудыг нэмэгдүүлдэг. Тиймээс баримт дахь ижил сонголтуудыг өөр өгүүлбэрт хийх боломжтой болгодог. Бид гурван баримт түвшинд өгөгдлийн сангийн аргыг үнэлэх: NIST Хятад-Англи, WMT19 Хятад-Англи, OpenSubtitles English-Russian. Бид өөрсдийн ойлголтыг багш шугамнаас илүү өндөр БЛУ оноо болон хүн төрөлхтний дуртай гэдгийг харуулж байна. Бидний арга хэмжээний сайн талаар загвараар хийсэн сонголтууд баримт дээр байдаг.', 'pl': 'Neuronalne tłumaczenie maszynowe (NMT) prawdopodobnie osiągnęło parytet na poziomie człowieka podczas treningu i oceny na poziomie zdania. Neuronowe tłumaczenie maszynowe na poziomie dokumentów zyskało mniejszą uwagę i pozostaje w tyle za swoim odpowiednikiem na poziomie zdań. Większość proponowanych podejść na poziomie dokumentu bada sposoby uwarunkowania modelu na kilka zdań źródłowych lub docelowych w celu uchwycenia kontekstu dokumentu. Podejścia te wymagają szkolenia specjalistycznego modelu NMT od podstaw na równoległych korpusach na poziomie dokumentów. Proponujemy podejście, które nie wymaga szkolenia specjalistycznego modelu na równoległych korpusach dokumentów i jest stosowane do przeszkolonego modelu NMT na poziomie zdań w czasie dekodowania. Wielokrotnie przetwarzamy dokument od lewej do prawej i samodzielnie trenujemy model na poziomie zdań na parach zdań źródłowych i generowanych tłumaczeń. Nasze podejście wzmacnia wybory dokonywane przez model, co zwiększa prawdopodobieństwo, że te same wybory zostaną dokonane w innych zdaniach dokumentu. Nasze podejście oceniamy na trzech zbiorach danych na poziomie dokumentów: NIST chińsko-angielski, WMT19 chińsko-angielski i OpenSubtitles angielsko-rosyjski. Wykazujemy, że nasze podejście ma wyższy wynik BLEU i wyższe preferencje ludzkie niż podstawowe. Analiza jakościowa naszego podejścia pokazuje, że wybory dokonywane według modelu są spójne w całym dokumencie.', 'sv': 'Neural machine translation (NMT) har utan tvekan uppnått mänsklig nivå paritet när de tränas och utvärderas på meningsnivå. Neural maskinöversättning på dokumentnivå har fått mindre uppmärksamhet och släpar efter sin motsvarighet på meningsnivå. Majoriteten av de föreslagna strategierna på dokumentnivå undersöker sätt att konditionera modellen på flera käll- eller målmeningar för att fånga dokumentsammanhang. Dessa tillvägagångssätt kräver utbildning av en specialiserad NMT-modell från grunden på parallella dokumentnivå corpora. Vi föreslår ett tillvägagångssätt som inte kräver utbildning av en specialiserad modell på parallella dokument-nivå corpora och tillämpas på en utbildad meningsnivå NMT modell vid avkodning tid. Vi bearbetar dokumentet från vänster till höger flera gånger och självtränar meningsnivåmodellen på par källmeningar och genererade översättningar. Vårt tillvägagångssätt förstärker modellens val, vilket gör det mer sannolikt att samma val kommer att göras i andra meningar i dokumentet. Vi utvärderar vårt tillvägagångssätt på tre dokumentnivå datauppsättningar: NIST kinesiska-engelska, WMT19 kinesiska-engelska och OpenSubtitles engelska-ryska. Vi visar att vårt tillvägagångssätt har högre BLEU-poäng och högre mänsklig preferens än baslinjen. Kvalitativ analys av vårt tillvägagångssätt visar att val som görs per modell är konsekventa över hela dokumentet.', 'ro': 'Traducerea automată neurală (NMT) a atins, probabil, paritatea nivelului uman atunci când este instruită și evaluată la nivelul propozițiilor. Traducerea automată neurală la nivel de document a primit mai puțină atenție și rămâne în urma omologului său la nivel de propoziție. Majoritatea abordărilor propuse la nivel de document investighează modalități de condiționare a modelului pe mai multe propoziții sursă sau țintă pentru a surprinde contextul documentelor. Aceste abordări necesită instruirea unui model NMT specializat de la zero pe corpuri paralele la nivel de documente. Propunem o abordare care nu necesită instruirea unui model specializat pe corpore paralele la nivel de documente și care este aplicată unui model NMT instruit la nivel de frază la momentul decodării. Procesăm documentul de la stânga la dreapta de mai multe ori și autoantrenăm modelul de nivel de propoziție pe perechi de propoziții sursă și traduceri generate. Abordarea noastră consolidează alegerile făcute de model, făcând astfel mai probabil ca aceleași alegeri să fie făcute și în alte propoziții din document. Evaluăm abordarea noastră pe trei seturi de date la nivel de document: NIST chineză-engleză, WMT19 chineză-engleză și OpenSubtitles engleză-rusă. Demonstrăm că abordarea noastră are un scor BLEU mai mare și preferințe umane mai mari decât valoarea de referință. Analiza calitativă a abordării noastre arată că alegerile făcute pe model sunt coerente în întregul document.', 'no': '@ info Comment Dei fleste av den foreslåde dokumentnivået tilnærmer å undersøke måtar å betinge modellen på fleire kjelde eller målsettingar for å henta dokumentkontekst. Desse tilnærmingane krev opplæring av ein spesialisert NMT-modell frå rulling på parallelle dokumentnivåkorpora. Vi foreslår ein tilnærming som ikkje krev å trenga ei spesialisert modell på parallelle dokumentnivåkorpora og vert brukt til eit trengt setningsnivå NMT-modell ved dekoding av tid. Vi handterar dokumentet frå venstre til høgre fleire gonger og selv treng setningsnivået på par kjeldesetningar og laga omsetjingar. Tilnærminga vårt styrer vala som er lagt av modellen, slik at dei same vala blir lagt i andre setningar i dokumentet. Vi evaluerer tilnærming vårt på tre dokumentnivådataset: NIST kinesisk-engelsk, WMT19 kinesisk-engelsk og OpenSubtitles engelsk-russisk. Vi viser at tilnærminga vårt har høgare BLEU-poeng og høgare menneskelige innstillingar enn baseline. Kvalitativ analyse av tilnærminga vårt viser at vala lagt av modell er konsistent over dokumentet.', 'so': 'Turjumista machine neural (NMT) wuxuu si dhab ah u gaadhay barbaarinta dadka marka lagu tababaray oo lagu qiimeeyo heerka sentenceka. Turjumista qoraalka neurada ee dukumentigu wuxuu helay mid ka yar islamarkaasna wuxuu dib uga dhigay mid ka gees ah qoraalka. Inta badan waxaa soo baaraya qaabab sameynta sameynta noocyada ku qoran noocyada ay ku qoran yihiin noocyo badan oo ay ku qoran yihiin noocyo ama qoraal aad u baahan tahay in lagu qabsado qoraalka. Waxqabadkaasu waxay u baahan yihiin in aad sameyneyso muusiko gaar ah oo NMT ah oo laga sameynayo shirkadda sameynta qoraalka. Waxaannu soo jeedaynaa qaab a an u baahnayn qaab gaar ah oo ku saabsan shirkadda qoraalka oo lambarka ah, waxaana lagu codsadaa model shahaadada qoraalka ah oo la tababariyey marka la deynto. Dukumentaada waxaan ka baaraandegaynaa bidixda ilaa midigta marar badan, iskana baaraandegaa modelka ereyga si aad u taqaanid noocyo noocyo ah, waxaana soo saaray turjubaan. Dhaqdhaqaalkayaga ayaa xoogaysa doorashooyinka modellka lagu sameeyo, sidaas darteed waxaa laga yaabaa in la sameeyo doorashooyin isku mid ah oo ku qoran qoraalka kale. Waxaannu qiimeynaynaa qaababkayaga ku qoran saddex taarif-heer: NIST Shiino-Ingiriis, WMT19 Shiino-Ingiriis iyo OpenSubtitles Ingiriis-Ruush. Waxaynu muujinnaa in dhaqdhaqaalahayagu ay leedahay qiimaha BLEU-ka sarreeya iyo horumarinta biniaadamka. Shahaadada takhasuska ah ee dhaqdhaqaalahayaga waxay muuqataa in doorashooyinka modellka lagu sameeyo ay ku siman yihiin dukumentiga oo dhan.', 'sr': 'Neuralni prevod mašine (NMT) je u pravu postigao paritet na ljudskom nivou kada je obučena i procjenjena na nivou rečenica. Prijevod neuralne mašine na nivou dokumenta dobio je manje pažnje i ostaje iza svog kolega na nivou rečenice. Većina predloženih pristupa nivou dokumenta istražuje načine uvođenja modela na nekoliko izvora ili ciljnih rečenica za uhvativanje konteksta dokumenta. Ovi pristupi zahtevaju obuku specijalizovanog NMT model a od ogrebotine na paralelnom korporaciji na nivou dokumenta. Predlažemo pristup koji ne zahteva obuku specijalizovanog model a o korporaciji na paralelnom nivou dokumenta i primjenjuje se na trenirani model NMT-a na nivou rečenica na vrijeme dekodiranja. Proveravamo dokument sa lijeve do desne više puta i samopovežbamo model rečenice na par izvornih rečenica i proizvedenih prevoda. Naš pristup pojača odluke koji su napravljeni modelom, tako da je verovatnije da će isti izbor biti napravljen u drugim rečenicama u dokumentu. Procjenjujemo naš pristup na tri nivoa podataka dokumenta: NIST kineski-engleski, WMT19 kineski-engleski i OpenSubtitles engleski-ruski. Pokazujemo da naš pristup ima veći rezultat BLEU-a i više ljudske preferencije od početne linije. Kvalitativna analiza našeg pristupa pokazuje da su izbori koji su napravljeni modelom konsistentni u širom dokumenta.', 'kk': 'Нейрондық компьютердің аударуы (NMT) сөйлеменің деңгейінде оқылған және оқылғанда адамның деңгейінің паритетін жетілді. Құжат деңгейіндегі невралдық компьютердің аударуы сөздің деңгейіндегі партнерінің артында артық болды. Келтірілген құжат деңгейінің көпшілігі құжаттың контексті алу үшін бірнеше көзі не мақсатты сөйлемелердің үлгісін шарттыру арқылы іздейді. Бұл жағдайлар параллел құжат деңгейіндегі корпораға арнаулы NMT үлгісін бақылау керек. Біз параллель құжат деңгейіндегі корпораға арнаулы үлгілерді оқыту керек болмайтын әдістерін жұмыс істеп, NMT деңгейіндегі кезде оқыту үлгісіне қолданылады. Біз құжатты сол жақтан оң жақтан бірнеше рет өзгертеміз және мәтін деңгейінің үлгісін көзі сөздер мен құрылған аудармалардың екі жолымен өзгертеміз. Біздің тәсіліміз үлгінің таңдауларын құрастырады, сондықтан құжаттың басқа сөздерінде бір таңдауларды көмектеседі. Біз үш құжат деңгейіндегі деректер жиындарына қатынасыз: NIST қытайша- ағылшын, WMT19 қытайша- ағылшын және OpenSubtitles ағылшын- руссия. Біз өзіміздің тәсіліміміздің BLEU нәтижесін жоғары және адамдардың негізгі жолынан артықшылығын көрсетедік. Біздің қасиеттеріміздің сапатты анализ үлгі арқылы таңдау құжаттың көзінде тұрақтығын көрсетеді.', 'si': 'ප්\u200dරශ්නයක් පද්ධතිය පද්ධතිය (NMT) ප්\u200dරශ්නයක් විදිහට මිනිස්සු ස්තූතිය ප්\u200dරශ්නයක් ලැබුණා වගේ ප්\u200dර වාර්තාව- ලේවල් න්\u200dයුරෝල් මැෂින් වාර්තාව අවධානය අඩුයි අවධානය සහ වාර්තාව පිටිපස්සේ පිට ප්\u200dරශ්න විදිහට ලිපින්ත- ස්තූතියේ බොහෝ මොඩල් සිද්ධ විදිහට පරීක්ෂා කරන්න ප්\u200dරයෝජනය විදිහට පරීක්ෂා  මේ විදිහට විශේෂ NMT මොඩේලයක් අවශ්\u200dය වෙන්න ඕනේ සමාන්\u200dය විදිහට ලොකුණු ස්ථානය සමාන්\u200dය විදිහට ප අපි ප්\u200dරශ්නයක් කරනවා ඒ විශේෂ ප්\u200dරශ්නයක් අවශ්\u200dය නැති විශේෂ ප්\u200dරශ්නයක් සමාන්\u200dය විදියට විශේෂ ප්\u200dරශ්නයක් ලැබෙ අපි දකුණු පැත්තෙන් දකුණු පැත්තෙන් දකුණු පැත්තෙන් සහ ස්වයංග්\u200dරහයෙන් වාක්ය ස්වයංග්\u200dරහය ප්\u200dරකාශ අපේ විදියට මොඩල් එකෙන් කරපු තීරණය විශ්වාස කරන්න පුළුවන් වෙනවා, ඒ වගේම ඒක තරම් තීරණය විශ්වාස කරන්න පුළුවන් ව අපි දත්ත තුනක් ලේවල් දත්ත සැටියුම් තුනක් විශ්වාස කරනවා: NIST චීනි-ඉංග්\u200dරීසි, WMT19 චීනි-ඉංග්\u200dරීසි සහ Open අපි පෙන්වන්නේ අපේ ප්\u200dරවේශනය බ්ලූයුස් ප්\u200dරමාණය වඩා වැඩියි මිනිස්සුන්ගේ ප්\u200dරවේශනය වඩා වඩා වැඩ අපේ ප්\u200dරවේශන විශ්ලේෂණය පෙන්වන්නේ මොඩේල් වලින් කරන තෝරාගන්න පුළුවන් විසිද්ධ විශ්ලේෂණය', 'ta': 'நியூரால் இயந்திரம் மொழிபெயர்ப்பு (NMT) பயிற்சி மற்றும் வாக்கி மட்டத்தில் மனித நிலை பார்வையை பெற்றுவிட்டது. ஆவண- மட்டத்தில் நரம்பு இயந்திரம் மொழிபெயர்ப்பு குறைந்த கவனத்தை பெற்றுள்ளது மற்றும் அதன் வாக்கி- மட்டத்தின் எத திருத்தப்பட்ட ஆவண- மட்டத்தில் பெரும்பாலானவர்கள் ஆவணத்தின் மூலம் அல்லது இலக்கு வாக்கியங்களை பிடிக்க முடியும் மாதிரியை  இந்த முன்னேற்றங்கள் இணைய ஆவண- நிலை நிறுவனத்திலிருந்து சிறப்பு NMT மாதிரியை பயிற்சி தேவைப்படுகிறது. நாம் ஒரு செயல்பாட்டிற்கு ஒரு சிறப்பு மாதிரியை பயிற்சி செய்ய வேண்டாம் என்று பரிந்துரைக்கிறோம். இணைய ஆவண- நிலை நிலை நிறுவனத்தில் பயி நாம் இடது புறத்திலிருந்து பல முறை வலப்புறத்தில் இருந்து ஆவணத்தை செயல்படுத்துகிறோம் மற்றும் மூல வாக்கியங்களில் இருந் எங்கள் அணுகல் மாதிரி செய்த தேர்வுகளை அதிகரிக்கும், அதனால் அதே தேர்வு We evaluate our approach on three document-level datasets: NIST Chinese-English, WMT19 Chinese-English and OpenSubtitles English-Russian.  நாங்கள் எங்கள் நெருக்கம் BLEU மதிப்பு அதிக மற்றும் அடிப்படை கோட்டை விட மனித மேன்முன்னுரிமை உள்ளது என்று க எங்கள் செயல்பாட்டின் தரமான ஆராய்ச்சி தெரியும் மாதிரியால் செய்யப்பட்ட தேர்வு', 'ur': 'نیورال ماشین کی ترجمہ (NMT) جب مجلس سطح پر آموزش کی اور ارزش کی جاتی ہے تو انسان سطح کی پاریٹی کو قابل طور پر پہنچ گیا ہے. دلیل-سطح نیورل ماشین ترجمہ کم توجه حاصل کیا گیا ہے اور اس کے sentence-level counterpart کے پیچھے چھوڑ دیا گیا ہے. پیشنهاد کی اکثریت دفتر-سطح کے مطابق مطابق طریقے کی تحقیق کرتی ہے کہ مدل کو چند سورس یا موقع کے مطابق لکھنے کے لئے منصوبہ کے مطابق کانڈیس کرنے کی طریقے ہیں. ان طریقے کی تعلیم کی ضرورت ہے کہ ایک مختلف دفتر-سطح کورپور پر اسکرے سے ایک مخصوص NMT موڈل کی تعلیم کرے۔ ہم ایک طریقہ پیشنهاد کرتے ہیں جس کی تعلیم مشابہ دکھانے کے لائق نہیں ہے ایک مختلف دکھانے کے لائق کے قانون کے لئے اور ایک تدریس کیے ہوئے sentence-level NMT موڈل کو دکھانے کے لائق ہے. ہم بائیں سے دائیں دفعہ تک دفعہ تک دفعہ پیدائش کرتے ہیں اور سئورس جماعتوں کے جوڑوں اور ترجمہ پیدا کئے جاتے ہیں۔ ہمارا تقریبا مدل کے ذریعہ اختیار کرنے والوں کو مضبوط کر رہا ہے، اس طرح اسے بہت زیادہ شانس بنا رہا ہے کہ اسی طرح ایک ہی اختیار دکھانے میں دوسرے جماعتوں میں کیا جائے گا۔ ہم تین دفتر سطح ڈیٹ سٹ پر اپنے طریقے کا ارزش کرتے ہیں: NIST چینی-انگلیسی، WMT19 چینی-انگلیسی اور OpenSubtitles انگلیسی-روسی. ہم دکھاتے ہیں کہ ہماری طریقہ سے بلیوس سکوٹ اور انسان کی ترجیح baseline سے زیادہ ہے۔ ہمارے دستور کی کیلوٹیٹی تحلیل دکھاتا ہے کہ موڈل کے ذریعہ اختیار کی وجہ سے دکھانے میں ثابت ہوتی ہے.', 'vi': 'Dịch về máy thần kinh (NMB) có thể đạt được sự bình đẳng của con người khi được huấn luyện và đánh giá ở mức án. Dịch cỗ máy thần kinh cấp tài liệu đã nhận ít sự chú ý và chậm hơn so với bản sao cấp bản án. Hầu hết các phương pháp trên mức tài liệu đề xuất nghiên cứu cách điều chỉnh mô hình trên nhiều nguồn hay mục tiêu để nắm bắt bối cảnh tài liệu. Những phương pháp này cần phải được đào tạo một mô hình NMT chuyên nghiệp trên giấy tờ song song. Chúng t ôi đề xuất một phương pháp không cần phải đào tạo một mô hình đặc biệt trên hạ sĩ song tài, và được áp dụng vào một mô hình NMB được huấn luyện trong thời gian giải mã. Chúng tôi xử lý tài liệu từ trái sang phải nhiều lần và tự đào tạo mô hình cung cấp chữ cho các cặp câu từ đầu và các bản dịch đã tạo ra. Cách tiếp cận của chúng ta củng cố những lựa chọn của mô hình, và làm cho nó có khả năng hơn là những lựa chọn tương tự sẽ được đưa ra trong các câu khác trong tài liệu. Chúng tôi đánh giá phương pháp của chúng tôi trên ba tập tin mẫu tài liệu: NIST China-English, WRT19 China-English và OpenSubtitles English-Nga. Chúng tôi chứng minh cách tiếp cận của chúng ta có tỉ lệ bắn trúng đại tự động cao hơn và ưu tiên con người hơn so với cơ sở. Năng lượng phân tích phương pháp của chúng ta cho thấy các lựa chọn theo phương pháp đều phù hợp trong toàn bộ tài liệu.', 'uz': "Name Name Koʻpchilik qoʻllanilgan hujjatning darajasi qoidalari hujjatni qabul qilish uchun foydalanuvchining bir necha manba yoki qanday maxfiy soʻzlarda modelni qidirish. These approaches require training a specialized NMT model from scratch on parallel document-level corpora.  Biz parallel hujjatning darajasida foydalanish kerak emas, bu usulni tahrirlash kerak emas, va vaqtni kodlash uchun o'rganish soʻzning darajasida NMT modeliga qoʻllaniladi. Biz hujjatni chap tomondan ikki marta boshqa marta harakat qilamiz va bir xil soʻzlar bilan bir xil maxfiy soʻzlar bilan so'zni boshqarish va tarjimalar yaratish mumkin. Бизнинг қонун усулимиз model томонидан танланган сақламаларимизни қувватлади. Шундай қилиб, у ҳужжатда бир қисм саҳифаларга ўзгартириш имкониятларида у мосларни бажаришга етказади. Biz uchta hujjatning darajasi maʼlumotlarimizni qiymatimiz: NIST Xitoycha- Inglizcha, WMT19 Xitoycha- Inglizcha va OpenSubtitles Inglizcha RuschaQuery Biz buning qiymatlarimizning BLEU qiymatlarimiz asosiy satridan eng yuqori va odamning eng yuqori darajaga ega bo'ladi. Bizning qiymatimizning kvalitatiy analyzeri model bilan yaratilgan tanlanganni hujjatning hammasida davom etishi mumkin.", 'bg': 'Невровият машинен превод (НМТ) е постигнал равенство на човешкото ниво, когато е обучен и оценен на ниво изречение. Неврологичният машинен превод на ниво документ е получил по-малко внимание и изостава от аналога на ниво изречение. По-голямата част от предложените подходи на ниво документ изследват начини за привеждане на модела към няколко източника или целеви изречения, за да улови контекста на документа. Тези подходи изискват обучение на специализиран модел от нулата върху паралелни корпуси на ниво документи. Предлагаме подход, който не изисква обучение на специализиран модел на паралелни корпуси на ниво документ и се прилага към трениран модел на ниво изречение по време на декодиране. Обработваме документа от ляво на дясно няколко пъти и самообучаваме модела на ниво изречение на двойки изходни изречения и генерирани преводи. Нашият подход подсилва изборите, направени от модела, като по този начин прави по-вероятно същите избори да бъдат направени в други изречения в документа. Оценяваме подхода си на три набора от данни на ниво документ: китайски-английски, китайски-английски и английски-руски. Ние демонстрираме, че нашият подход има по-висок резултат и по-високи човешки предпочитания от базовия. Качественият анализ на нашия подход показва, че изборите, направени по модел, са последователни в целия документ.', 'nl': "Neuronale machine translation (NMT) heeft waarschijnlijk een pariteit op menselijk niveau bereikt wanneer getraind en geëvalueerd op zinnenniveau. De neurale machinevertaling op documentniveau heeft minder aandacht gekregen en loopt achter op de tegenhanger op zinsniveau. Het merendeel van de voorgestelde benaderingen op documentniveau onderzoekt manieren om het model te conditioneren op verschillende bron- of doelzinnen om documentcontext vast te leggen. Deze benaderingen vereisen het trainen van een gespecialiseerd NMT-model vanaf nul op parallelle corpora op documentniveau. We stellen een aanpak voor die geen gespecialiseerde training vereist op parallelle corpora's op documentniveau en toegepast wordt op een getraind NMT-model op zinsniveau tijdens decoderingstijd. We verwerken het document meerdere keren van links naar rechts en trainen het zinnenmodel zelf op paren bronzinnen en gegenereerde vertalingen. Onze aanpak versterkt de keuzes die het model maakt, waardoor het waarschijnlijker wordt dat dezelfde keuzes in andere zinnen in het document worden gemaakt. We evalueren onze aanpak op drie datasets op documentniveau: NIST Chinees-Engels, WMT19 Chinees-Engels en OpenSubtitles Engels-Russisch. We tonen aan dat onze aanpak een hogere BLEU score en een hogere menselijke voorkeur heeft dan de baseline. Kwalitatieve analyse van onze aanpak toont aan dat keuzes gemaakt per model consistent zijn in het hele document.", 'da': 'Neural maskinoversættelse (NMT) har uden tvivl opnået lighed på menneskeligt niveau, når de er trænet og evalueret på sætningsniveau. Neural maskinoversættelse på dokumentniveau har fået mindre opmærksomhed og halter bagefter sin modpart på sætningsniveau. De fleste af de foreslåede tilgange på dokumentniveau undersøger måder at konditionere modellen på flere kilde- eller målsætninger for at fange dokumentkontekst. Disse tilgange kræver træning af en specialiseret NMT model fra bunden på parallelle dokumentniveau corpora. Vi foreslår en tilgang, der ikke kræver træning af en specialiseret model på parallelle dokumentniveau corpora og anvendes på en trænet sætningsniveau NMT model på afkodningstidspunktet. Vi behandler dokumentet fra venstre mod højre flere gange og selvtræner sætningsniveau modellen på par kildesætninger og genererede oversættelser. Vores fremgangsmåde styrker modellens valg og gør det derfor mere sandsynligt, at de samme valg vil blive truffet i andre sætninger i dokumentet. Vi evaluerer vores tilgang på tre dokumentniveau datasæt: NIST kinesisk-engelsk, WMT19 kinesisk-engelsk og OpenSubtitles engelsk-russisk. Vi demonstrerer, at vores tilgang har højere BLEU score og højere menneskelige præferencer end baseline. Kvalitativ analyse af vores tilgang viser, at de valg, der træffes efter model, er konsekvente på tværs af dokumentet.', 'hr': 'Neuralni prevod strojeva (NMT) je dokazno postigao paritet na ljudskoj razini kada je obučena i procjenjena na razini rečenica. Prijevod neuralnog stroja na razini dokumenta dobio je manje pažnje i ostaje iza svog kolega na razini rečenice. Većina predloženih pristupa razini dokumenta istražuje načine uvođenja modela na nekoliko izvora ili ciljnih rečenica za uhvaćenje konteksta dokumenta. Ovi pristupi zahtijevaju obuku specijaliziranog NMT model a od ogrebotine na paralelnom korporaciji na razini dokumenta. Predlažemo pristup koji ne zahtijeva obuku specijaliziranog model a za korporaciju paralelne razine dokumenta i primjenjuje se na trenirani model NMT razine kazne na vrijeme dekodiranja. Proobrađujemo dokument s lijeve do desne više puta i samopovježbamo model razine rečenica na par izvornih rečenica i proizvedenih prevoda. Naš pristup pojačava odluke iz modela, tako čini vjerojatnijim da će se isti izbori donijeti u drugim rečenicama u dokumentu. Procjenjujemo naš pristup na tri razine podataka dokumenta: NIST kineski-engleski, WMT19 kineski-engleski i OpenSubtitles engleski-ruski. Pokazujemo da naš pristup ima veći rezultat BLEU-a i višu ljudsku preferenciju nego početnu liniju. Kvalitativna analiza našeg pristupa pokazuje da su izbori iz modela konsistentni u širom dokumenta.', 'de': 'Neuronale maschinelle Übersetzung (NMT) hat wohl eine Parität auf menschlicher Ebene erreicht, wenn sie auf Satzebene trainiert und bewertet wird. Neuronale maschinelle Übersetzung auf Dokumentenebene hat weniger Aufmerksamkeit erhalten und bleibt hinter ihrem Gegenstück auf Satzebene zurück. Die meisten der vorgeschlagenen Ansätze auf Dokumentenebene untersuchen Möglichkeiten, das Modell auf mehrere Quell- oder Zielsätze zu konditionieren, um den Dokumentenkontext zu erfassen. Diese Ansätze erfordern das Training eines spezialisierten NMT-Modells von Grund auf auf parallelen Korpora auf Dokumentenebene. Wir schlagen einen Ansatz vor, der keine Ausbildung eines spezialisierten Modells auf parallelen Korpora auf Dokumentenebene erfordert und auf ein trainiertes NMT-Modell auf Satzebene zur Dekodierungszeit angewendet wird. Wir verarbeiten das Dokument mehrmals von links nach rechts und trainieren das Satzmodell auf Ausgangssätzen und generierten Übersetzungen selbst. Unser Ansatz verstärkt die Entscheidungen des Modells und macht es wahrscheinlicher, dass dieselben Entscheidungen auch in anderen Sätzen des Dokuments getroffen werden. Wir evaluieren unseren Ansatz anhand von drei Datensätzen auf Dokumentenebene: NIST Chinesisch-Englisch, WMT19 Chinesisch-Englisch und OpenSubtitles Englisch-Russisch. Wir zeigen, dass unser Ansatz einen höheren BLEU-Score und eine höhere menschliche Präferenz als die Baseline aufweist. Die qualitative Analyse unseres Ansatzes zeigt, dass die nach Modell getroffenen Entscheidungen im gesamten Dokument konsistent sind.', 'id': 'Terjemahan mesin saraf (NMT) mungkin telah mencapai paritas tingkat manusia ketika dilatih dan diteliti di tingkat kalimat. Terjemahan mesin saraf tingkat dokumen telah menerima kurang perhatian dan tertinggal di belakang counterpart tingkat kalimat. Kebanyakan pendekatan tingkat dokumen yang diusulkan menyelidiki cara kondisi model pada beberapa kalimat sumber atau sasaran untuk menangkap konteks dokumen. Pendekatan ini membutuhkan pelatihan model NMT khusus dari nol pada korpora tahap dokumen paralel. Kami mengusulkan pendekatan yang tidak membutuhkan pelatihan model khusus pada korpora tingkat dokumen paralel dan diterapkan pada model NMT tingkat kalimat terlatih pada waktu dekodifikasi. Kami memproses dokumen dari kiri ke kanan beberapa kali dan melatih sendiri model tingkat kalimat pada pasangan kalimat sumber dan menghasilkan terjemahan. pendekatan kita memperkuat pilihan yang dibuat oleh model, sehingga membuat lebih mungkin bahwa pilihan yang sama akan dibuat dalam kalimat lain dalam dokumen. Kami mengevaluasi pendekatan kami pada tiga set data tingkat dokumen: NIST Chinese-English, WMT19 Chinese-English dan OpenSubtitles English-Russian. Kami menunjukkan bahwa pendekatan kita memiliki nilai BLEU yang lebih tinggi dan keutamaan manusia yang lebih tinggi dari dasar. Analisis kualitatis pendekatan kita menunjukkan bahwa pilihan yang dibuat oleh model konsisten di seluruh dokumen.', 'fa': 'ترجمه ماشین عصبی (NMT) در حالی که آموزش و ارزیابی در سطح جمله\u200cی انسان را رسید. ترجمه\u200cهای دستگاه عصبی سطح سند کمتر توجه یافت و پشت همکاری سطح جمله\u200cاش باقی مانده است. اکثریت سطح سند پیشنهاد پیشنهاد به راه\u200cهای تحقیق کردن مدل در چندین منبع یا جمله\u200cهای هدف برای گرفتن محیط سند تحقیق می\u200cکند. این روش\u200cها نیاز به آموزش یک مدل NMT متخصص از خروج در شرکت سطح سند متفاوت است. ما پیشنهاد می کنیم یک روش که نیاز به آموزش یک مدل متخصص در شرکت سطح سند متخصص نیست و در زمان decoding به مدل NMT طبقه آموزش داده می شود. ما سند را از چپ به راست چند بار فرایند می\u200cکنیم و مدل سطح جمله را به جفت جمله\u200cهای منبع و ترجمه\u200cهای تولید می\u200cکنیم. دستور ما انتخاب\u200cهایی را که توسط مدل انجام می\u200cدهند، نیرومند می\u200cشود، بنابراین این انتخاب را بیشتر احتمال می\u200cدهد که همان انتخاب\u200cها در جمله\u200cهای دیگر در سند انجام می\u200cشوند. ما روش خود را در سه مجموعه داده\u200cهای سطح سند ارزیابی می\u200cکنیم: NIST Chinese-English, WMT19 Chinese-English and OpenSubtitles English-Russian. ما نشان می دهیم که دسترسی ما امتیاز BLEU بالاتر و ترجیح انسان بالاتر از خط پایین دارد. تحلیل کیفیتی از طریق ما نشان می دهد که انتخاب\u200cهایی که از طریق مدل ساخته می\u200cشوند بر روی سند موجود است.', 'af': "Neurale masjien vertaling (NMT) het waarskynlik menslike vlak pariteit bereik wanneer onderwerp en evalueer by die setvlak. Name Die meeste van die voorgestelde dokumentvlak het toegang tot ondersoek maniere om die model op verskeie bron of doel teikens te vervang om dokumentkonteks te vang. Hierdie toegang benodig om 'n spesialiseerde NMT-model te onderwerp vanaf skrewe op parallele dokumentvlak korpora. Ons voorstel 'n toegang wat nie 'n spesialiseerde model benodig nie op parallele dokumentvlak korpora en word toegewend na 'n gevorderde setvlak NMT model by dekodering tyd. Ons proses die dokument van links na regs veelvuldige maal en self-trein die setvlak model op paar bron setings en genereerde vertalings. Ons toegang versterk die keuses wat deur die model gemaak is, sodat dit meer waarskynlik maak dat dieselfde keuses in ander setings in die dokument sal gemaak word. Ons evalueer ons toegang op drie dokumentvlak datastelle: NIST Sjinese-Engels, WMT19 Sjinese-Engels en OpenSubtitles Engels-Russe. Ons bevestig dat ons toegang het hoër BLEU-punt en hoër menslike voorkeure as die basilyn. Kvalitatiewe analiseer van ons toegang vertoon dat keuses gemaak deur model is konsistent oor die dokument.", 'sq': 'Ndoshta përkthimi i makinave nervore (NMT) ka arritur paritetin e nivelit njerëzor kur është trajnuar dhe vlerësuar në nivelin e dënimit. Përkthimi i makinës nervore në nivel të dokumentit ka marrë më pak vëmendje dhe mbetet prapa homologut të tij të nivelit të dënimit. Shumica e afrimeve të nivelit të dokumentit të propozuar hetojnë mënyra për kushtëzimin e modelit në disa fjalë burimi apo objektiv për të kapur kontekstin e dokumentit. Këto qasje kërkojnë trajnimin e një modeli të specializuar NMT nga zero në korpra paralele në nivel dokumentesh. Ne propozojmë një qasje që nuk kërkon trajnimin e një modeli t ë specializuar mbi korprën paralele të nivelit të dokumentit dhe është aplikuar në një model të trajnuar të nivelit të dënimit NMT në kohën e dekodimit. We process the document from left to right multiple times and self-train the sentence-level model on pairs of source sentences and generated translations.  Përqasja jonë përforcon zgjedhjet e bërë nga modeli, duke e bërë më të mundshme që të njëjtat zgjedhje të bëhen në fjalë të tjera në dokument. Ne vlerësojmë qasjen tonë në tre grupe të dhënash të nivelit të dokumentit: NIST Chinese-English, WMT19 Chinese-English dhe OpenSubtitles English-Russian. Ne demonstrojmë se qasja jonë ka rezultate më të larta BLEU dhe preferim më të lartë njerëzor se baza. Analiza kualitative e qasjes sonë tregon se zgjedhjet e bërë nga modeli janë konsistente anembanë dokumentit.', 'tr': 'NMT sened derejesinde bilinmeli we çözümlendirilýän zaman adamlaryň derejesi bardyr. Sened derejesi näral maşynyň terjimesine has az üns berip, sözlemek derejesini boýunça alyp gitdi. Sened derejesiniň köp bölegi golaýlaýar. Sened kontekstini ýazmak üçin modi syýahat etmek üçin nusgasyny barlaýar. Bu ýagdaýlar parallel sened derejesinden bir NMT nusgasyny öwretmek gerek. Biz parallel sened derejesinde bir nusga gerek däl öwrenmemeýän bir nusga teklip edip, okuwçylan sözlem derejesinde NMT nusga kodlamak üçin uygulandyrylýarys. Biz senedi soldan saga çenli gezek işleýäris we sözlem derejesini çeşme sözlemleriň çift çeşitlerinde özüne öwredýäris we üretildik terjimeler. Biziň ýaryşymyz nusga tarapyndan saýlanan saýlawlary güýçleştirip, şonuň üçin bu senediň başga sözlerinde bir saýlawy be ýleki sözlerde edip biler. Biz özümiziň ýaryşymyzy üç düzede sanat setirinde deňleýäris: NIST Çinçe-Iňlisçe, WMT19 Çinçe-Iňlisçe we OpenSubtitles English-Rusça. Biz özümiziň ýaryşymyzyň basetden ýokary BLEU अंतर we adamlaryň üstünliklerini görkezýäris diýip kanıtlaýarys. Biziň ýaryşymyzyň kaliwatli analýşimiz nusga tarapyndan saýlanan saýlawlary senediň içine bir şekilde däldir.', 'ko': '문장 차원에서 훈련하고 평가할 때 신경기계번역(NMT)은 인간 차원의 대등을 이뤘다고 할 수 있다.문서급 신경기계 번역은 관심이 적고 문장급 번역보다 뒤떨어진다.대부분의 제안된 문서급 방법은 몇 개의 원본 문장이나 목표 문장에 따라 모델을 어떻게 조정하여 문서의 상하문을 포착하는지를 연구한다.이러한 방법은 병행문급 어료 라이브러리에서 처음부터 전문적인 NMT 모델을 훈련해야 한다.우리는 병행문급 어료 라이브러리에서 전문 모델을 훈련할 필요가 없는 방법을 제시했고 디코딩을 할 때 훈련을 받은 문장급 NMT 모델에 응용했다.우리는 왼쪽에서 오른쪽으로 여러 번 문서를 처리하고 쌍을 이루는 원어구와 생성된 번역에 따라 문장급 모델에 대해 자기 훈련을 한다.우리의 방법은 모델이 하는 선택을 강화하여 문서의 다른 문장들이 같은 선택을 할 수 있도록 한다.NIST 중국어-영어, WMT19 중국어-영어, OpenSubtitles 영어-러시아어 등 세 가지 문서급 데이터 세트에서 Dell의 접근 방식을 평가했습니다.베이스라인보다 우리의 접근법이 더 높은 BLEU 점수와 더 높은 인간 선호도를 갖고 있음을 증명한다.우리의 방법에 대한 정성 분석에 따르면 모델이 한 선택은 전체 문서에서 일치한다.', 'sw': 'Tafsiri ya mashine ya kiserikali (NMT) imefanikiwa kwa kiasi kikubwa kikuu cha binadamu wakati wa mafunzo na kutathmini kiwango cha hukumu. Tafsiri ya mashine yenye kiwango cha dokumentari kimepatikana vibaya na kubaki nyuma ya upinzani wake wa ngazi ya hukumu. Wengi wa watengenezaji wa kiwango cha dokumentari kinachopendekezwa kutafuta njia za namna ya hali ya mazingira katika chanzo kadhaa au sentensi za lengo ili kukamata muktadha wa nyaraka. Hatua hizi zinahitaji mafunzo ya muundo maalumu wa NMT kutoka kwenye vifaa vinavyotengenezwa kwenye kampuni ya kiwango cha nyaraka. Tunazipendekeza mbinu ambazo hazihitaji mafunzo ya modeli maalumu kuhusu kampuni ya kiwango cha dokumentari na inatumika kwa mtindo wa mafunzo wa kiwango cha enzi cha NMT wakati wa kupunguza muda. Tunafanya nyaraka kuanzia kushoto hadi kulia mara kadhaa na kujifunza mwenyewe kwa mtindo wa kiwango cha hukumu juu ya hukumu mbili za vyanzo na kuzalisha tafsiri. Hatua yetu inaongeza uchaguzi uliofanywa na muundo, kwa hiyo inaweza kufanya uwezekano wa kuwa chaguo hizo zitafanya katika sentensi nyingine za nyaraka. Tutathmini mbinu yetu kwenye seti za taarifa tatu za nyaraka: NIST-China-English, WMT19-Kichina-Kiingereza na OpenSubtitles-Urusi. Tunaonyesha kwamba mbinu yetu ina thamani kubwa ya BLEU na bora ya binadamu kuliko msingi. Uchambuzi wa kiwango cha mbinu zetu unaonyesha kuwa chaguo zilizofanywa na modeli zimeendelea katika nyaraka zote.', 'am': 'የኔural machine ትርጉም (NMT) በተማረ ጊዜ የሰው ደረጃ ፓርቲ በተማረ እና በተመሳሳይ ደረጃ ላይ አግኝቷል፡፡ ሰነድ-ደረጃ የናውሬል መሣሪያን ትርጓሜ ጥቂት ትኩረት ተቀብሎአል፡፡ የተዘጋጁ የሰነድ ደረጃዎች አካባቢዎች የሰነድ አካል ማሰናከል እና በክፍለ መልዕክቶች ላይ እና የዓይነቶች ክፍሎች ለመያዝ የሚችሉትን የሥርዓት ሥርዓቶች የሚያስተካክሉ መንገዶች ይፈልጋሉ፡፡ እነዚህም ደረጃዎች የNMT ሞዴል በማስተካከል ሰነድ-ደረጃ ኮርፖርት ላይ እንዲያስተምር ያስፈልጋል። በተለየ ሰነድ-ደረጃ ኮርፖራ ላይ የተለየ የፊደል ክፍል-ደረጃ የNMT ሞዴል በተጠቃሚ ጊዜ እንዲያስፈልገው እንደማያስፈልገውን መግለጫ እናዘጋጅታለን፡፡ ሰነዱን ከግራ ወደ ቀኝ ብዙ ጊዜ እናስተማርናለን የቁልፉን ደረጃዎች በሁለት ዓይነት የክፍሎች እና ትርጓሜዎችን እናስተማርናለን፡፡ የዓይነታችን መግለጫ በዓይነቱ የተደረገውን ምርጫዎች ያበረታል፤ ይህም የተጨማሪውን ምርጫዎች በሰነዱ ውስጥ በአንድ ፈቃድ እንዲደረጉ ይችላል፡፡ We evaluate our approach on three document-level datasets: NIST Chinese-English, WMT19 Chinese-English and OpenSubtitles English-Russian.  መግለጫ የቢልዩን ትክክል እና የሰው ብሔራዊ ሽልማት መሆኑን እናስታውቃለን፡፡ የሥርዓታችንን አስተያየት ሞዴል የተደረገው ምርጫዎች በሰነዱ ሁሉ ላይ ይተካከላሉ፡፡', 'bn': 'নিউরেল মেশিন অনুবাদ (এনএমটি) যুক্তিভাবে প্রশিক্ষণ ও মূল্যায়ন করার সময় মানুষের স্তরের পারিটি অর্জন করেছে। ডকুমেন্ট- স্তরের নিউরেল মেশিন অনুবাদ কম মনোযোগ পেয়েছে এবং তার বাক্য-স্তরের পিছনে রেখে আছে। প্রস্তাবিত নথি-স্তরের বেশীরভাগ প্রস্তাবিত তথ্যের কাছে তদন্ত করা হয়েছে কয়েকটি উৎস অথবা টার্গেটের বাক্যে নথিপত্রের প্রত এই প্রযুক্তিগুলোর প্যারালেল ডকুমেন্ট-স্তর কর্পোরা থেকে একটি বিশেষ NMT মডেল প্রশিক্ষণের প্রয়োজন। আমরা একটি উপায় প্রস্তাব করি যা প্যারালেল ডকুমেন্ট-স্তর কোর্পোরায় একটি বিশেষ মডেল প্রশিক্ষণ প্রয়োজন নেই এবং ডিকোডিং সময়ে প্রশিক্ষিত শাস্তি স্তরে আমরা বাম থেকে বাম থেকে ডান দিক থেকে এই নথিটি প্রক্রিয়া করি এবং স্বয়ংক্রিয়ভাবে সূত্রের দায়িত্বের বিভিন্ন স্তরের মো আমাদের প্রতিযোগিতা মডেলের নির্বাচনে শক্তিশালী করে দেয়, যার ফলে এটাকে আরো সম্ভবত নথির অন্যান্য বাক্যে একই পছন্দ করা হবে। আমরা তিনটি ডকুমেন্ট-স্তরের ডাটাসেটে আমাদের প্রতিক্রিয়া মূল্যায়ন করি: এনআইএসটি চীন-ইংরেজী, WMT19 চীন-ইংরেজী এবং ওপেন স আমরা প্রমাণ করছি যে আমাদের প্রতিক্রিয়া বিলু স্কোর আর মানুষের চেয়ে বেশী পছন্দ আছে। আমাদের পদক্ষেপের সমান বিশ্লেষণ দেখাচ্ছে যে মডেল দ্বারা নির্বাচন করা হয়েছে তা নথির সারা বিভিন্ন সারা', 'bs': 'Neuralni prevod mašine (NMT) je, vjerojatno, postigao paritu na ljudskoj razini kada je obučena i procjenjena na razini rečenica. Prijevod neuralne strojeve na nivou dokumenta dobio je manje pažnje i ostaje iza svog kolega na nivou kazne. Većina predloženih pristupa nivou dokumenta istražuje načine uvođenja modela na nekoliko izvora ili ciljnih rečenica da uhvati kontekst dokumenta. Ovi pristupi zahtijevaju obuku specijaliziranog NMT model a od ogrebotine na paralelnom korporaciji na nivou dokumenta. Predlažemo pristup koji ne zahtijeva obuku specijalizovanog model a za korporaciju paralelnog nivoa dokumenta i primjenjuje se na trenirani model NMT-a na nivou kazne u vrijeme dekodiranja. Proveravamo dokument sa lijeve do desne više puta i sami treniramo model rečenice na par izvornih rečenica i proizvedenih prevoda. Naš pristup pojačava izbore koje je napravio model, tako da će biti vjerojatnije da će isti izbori biti doneseni u drugim rečenicama u dokumentu. Procjenjujemo naš pristup na tri razine podataka dokumenta: NIST kineski-engleski, WMT19 kineski-engleski i OpenSubtitles engleski-ruski. Pokazujemo da naš pristup ima veći rezultat BLEU-a i višu ljudsku preferenciju od početne linije. Kvalitativna analiza našeg pristupa pokazuje da su izbori iz modela konsistentni u širom dokumenta.', 'hy': "Նյարդային մեքենայի թարգմանությունը (NMT) հավանաբար հասել է մարդկային մակարդակի հավասարակշռությանը, երբ նախադասության մակարդակում ուսուցանված և գնահատված է: Թղթերի մակարդակի նյարդային մեքենայի թարգմանությունը ավելի քիչ ուշադրություն է ստացել և հետևում է նախադասության մակարդակի հակառակը: Առաջարկված փաստաթղթի մակարդակի մոտեցումների մեծամասնությունը ուսումնասիրում է մոդելը բազմաթիվ աղբյուրների կամ նպատակային նախադասությունների պայմանավորման ձևերը փաստաթղթի կոնտեքստի նկատ Այս մոտեցումները անհրաժեշտ են NMT-ի մասնագիտական մոդելի կրթություն զրոյից զուգահեռ փաստաթղթի մակարդակի կոպորա վրա: Մենք առաջարկում ենք մի մոտեցում, որը չի պահանջում մասնագիտական մոդել վարժեցնել զուգահեռ փաստաթղթի մակարդակի օրգանիզմի վրա և որը կիրառվում է NMT-ի մակարդակի վարժեցված նախադասությունների մակարդակի մոդելի վրա Մենք վերլուծում ենք փաստաթղթին ձախ դեպի աջ բազմաթիվ անգամ և ինքնավարժում ենք նախադասության մակարդակի մոդելը սկզբնական նախադասությունների և ստեղծված թարգմանությունների զույգերի վրա: Մեր մոտեցումը խրախուսում է մոդելի ընտրությունները, այնպես դարձնելով ավելի հավանական, որ նույն ընտրությունները կատարվեն փաստաթղթի այլ նախադասություններում: Մենք գնահատում ենք մեր մոտեցումը երեք փաստաթղթի մակարդակի տվյալների համակարգերի վրա' ՆԻՍՏ Չինաստանի-Անգլերենի, ՈւՄԹ19 Չինաստանի-Անգլերենի և Open We demonstrate that our approach has higher BLEU score and higher human preference than the baseline.  Մեր մոտեցումների որակային վերլուծությունը ցույց է տալիս, որ մոդելի միջոցով ընտրված ընտրությունները համապատասխանում են փաստաթղթի մեջ:", 'az': "NMT insan seviyyəti təhsil edildiyi və təhsil seviyyətində təhsil edildiyi zaman nürol maşına çevirildi. Dökümət səviyyəsi nöral maşına çevirilməsi daha az dikkatini alır və cümlənin səviyyəsi ilə qardaşının arxasında saxlanır. Tərcümə səviyyəsinin çoxunun modelini bir neçə mənbə və məqsəd cümlələrində tutmaq üçün məcburiyyət məsələlərinə istifadə etmə yollarını incidir. Bu tərzlərin paralel səviyyə korporasında xüsusiyyətli NMT modeli təhsil etməsi lazımdır. Biz paralel səviyyə korporasında xüsusiyyətli modeli t əhsil etməyə ehtiyacı olmayan və təhsil edilmiş cümlələr səviyyəsinə NMT modeli dekodin vaxtında istifadə edilir. Biz səhifəni soldan sağdan çoxlu dəfə təhsil edirik və cümlənin səviyyəsini mənbə cümlələrinin çift və təhsil cümlələrini təhsil edirik. Bizim yaxınlığımız modellə etdiyi seçimləri gücləndirir, beləliklə bu seçimləri belə daha çox mümkün edər ki, beləliklə, beləliklə, səhifələrin başqa cümlələrdə də eyni seçimlər yaranacaqlar. Üç səviyyə veri quruluğumuza tərzim veririk: NIST Çin-İngilizce, WMT19 Çin-İngilizce və OpenSubtitles İngilizce-Rusça. Bizim tərəfimizin BLEU nöqtəsi yüksək və insan seçimləri baseline'dən daha yüksək olduğunu göstəririk. Bizim tərəfimizin qabiliyyətli analizi modellərlə yapılan seçimlər belə yazılmışdır.", 'ca': "La traducció de màquines neuronals (NMT) ha aconseguit la paritat del nivell humà quan es treina i es valora a nivell de frases. La traducció de màquines neurals a nivell de documents ha rebut menys atenció i es queda darrere de la seva contrapartida en nivell de frases. La majoria dels enfocaments proposats a nivell documental investiga maneres de condicionar el model en diverses frases d'origen o d'objectiu per capturar el context documental. Aquests enfocaments requereixen formar un model especialitzat de NMT des de zero en corpora paral·lela a nivell de documents. Proposem un enfocament que no requereix formació d'un model especialitzat en corpora paral·lela a nivell de documentos i que s'aplica a un model NMT de nivell de frases entrenat en temps de decodificació. Procesem el document de l'esquerra a la dreta múltiples vegades i autoentrenem el model de nivell de frases en parells de frases d'origen i les traduccions generades. El nostre enfocament reforça les eleccions fetes pel model, fent més probable que les mateixes es siguin fetes en altres frases del document. Evaluam el nostre enfocament en tres conjunts de dades de nivell documental: NIST Chino-English, WMT19 Chino-English i OpenSubtitles English-Russian. Demonstrem que el nostre enfocament té una puntuació BLEU més alta i una preferència humana més alta que la basa. L'anàlisi qualitativa del nostre enfocament mostra que les eleccions fetes per model són coherents a través del document.", 'et': 'Neuraalne masintõlge (NMT) on väidetavalt saavutanud inimese tasandi pariteedi, kui seda koolitatakse ja hinnatakse lausetasemel. Dokumenditasemel neuromasintõlge on saanud vähem tähelepanu ja jääb lausetasemel vastavast maha. Enamik kavandatud dokumenditasandi lähenemisviisidest uurib võimalusi mudeli konditsioneerimiseks mitme lähte- või sihtlausega dokumendikonteksti jäädvustamiseks. Need lähenemisviisid nõuavad spetsialiseerunud NMT mudeli koolitamist nullist paralleelsete dokumentide tasemel korpustega. Pakume välja lähenemisviisi, mis ei nõua spetsialiseerunud mudeli koolitamist paralleelsetel dokumenditasemel korpustel ja mida rakendatakse väljaõpetatud lausetasemel NMT mudelile dekodeerimise ajal. Töötleme dokumenti vasakult paremale mitu korda ja treenime ise lausetaseme mudelit lähtelausete paaride ja genereeritud tõlkete põhjal. Meie lähenemisviis tugevdab mudeli tehtud valikuid, muutes seega tõenäolisemaks, et samad valikud tehakse ka teistes dokumendi lausetes. Hindame oma lähenemist kolmes dokumenditasemel andmekogumis: NIST hiina-inglise, WMT19 hiina-inglise ja OpenSubtitles inglise-vene. Näitame, et meie lähenemisviisil on kõrgem BLEU skoor ja suurem inimeste eelistus kui algtasemel. Meie lähenemisviisi kvalitatiivne analüüs näitab, et mudelite kaupa tehtud valikud on kogu dokumendis järjepidevad.', 'fi': 'Neuroiden konekäännös (NMT) on todennäköisesti saavuttanut ihmisen tason pariteetin, kun sitä koulutetaan ja arvioidaan lausetasolla. Dokumenttitason neurokonekäännös on saanut vähemmän huomiota ja jäänyt lausetasosta jäljelle. Suurin osa ehdotetuista dokumenttitason lähestymistavoista tutkii tapoja ehdollistaa malli useisiin lähde- tai kohdelauseisiin dokumentin kontekstin tallentamiseksi. Nämä lähestymistavat edellyttävät erikoistuneen NMT-mallin kouluttamista tyhjästä rinnakkaisiin dokumenttitason korpusiin. Ehdotamme lähestymistapaa, joka ei vaadi erikoistuneen mallin kouluttamista rinnakkaisiin dokumenttitason korpusiin ja jota sovelletaan koulutettuun lausetason NMT-malliin dekoodauksen aikana. Käsittelemme dokumentin vasemmalta oikealle useita kertoja ja opetamme lausetason mallin itse lähdelauseiden parien ja luotujen käännösten perusteella. Lähestymistapamme vahvistaa mallin tekemiä valintoja, jolloin on todennäköisempää, että samat valinnat tehdään asiakirjan muissa lauseissa. Arvioimme lähestymistapaamme kolmella dokumenttitasolla: NIST kiina-englanti, WMT19 kiina-englanti ja OpenSubtitles englanti-venäjä. Osoitamme, että lähestymistapamme on korkeampi BLEU-pistemäärä ja korkeampi ihmisten mieltymys kuin lähtötilanteessa. Lähestymistapamme laadullinen analyysi osoittaa, että mallikohtaiset valinnat ovat johdonmukaisia koko asiakirjassa.', 'cs': 'Neurální strojový překlad (NMT) pravděpodobně dosáhl parity lidské úrovně při tréninku a hodnocení na úrovni věty. Neuronový strojový překlad na úrovni dokumentů získal menší pozornost a zaostává za svým protějškem na úrovni věty. Většina navržených přístupů na úrovni dokumentů zkoumá způsoby, jak podmínit model na několik zdrojových nebo cílových vět pro zachycení kontextu dokumentu. Tyto přístupy vyžadují od začátku trénink specializovaného NMT modelu na paralelních korpusech na úrovni dokumentů. Navrhujeme přístup, který nevyžaduje trénink specializovaného modelu na paralelních korpusech dokumentů a je aplikován na trénovaný NMT model na úrovni věty v době dekódování. Zpracováváme dokument zleva doprava několikrát a sami trénujeme model na úrovni věty na párech zdrojových vět a generovaných překladů. Náš přístup posiluje volby modelu, čímž je pravděpodobnější, že stejná volba bude učiněna v jiných větách dokumentu. Náš přístup hodnotíme na třech datových sadách na úrovni dokumentů: NIST čínsko-anglicky, WMT19 čínsko-anglicky a OpenSubtitles anglicky-rusky. Dokazujeme, že náš přístup má vyšší BLEU skóre a vyšší lidské preference než základní hodnota. Kvalitativní analýza našeho přístupu ukazuje, že volby podle modelu jsou konzistentní v celém dokumentu.', 'sk': 'Nevralni strojni prevod (NMT) je verjetno dosegel enakost človeške ravni pri usposabljanju in ocenjevanju na ravni kazni. Nevronsko strojno prevajanje na ravni dokumenta je prejelo manj pozornosti in zaostaja za svojim primerom na ravni stavka. Večina predlaganih pristopov na ravni dokumenta raziskuje načine pogojevanja modela na več izvornih ali ciljnih stavkov za zajem konteksta dokumenta. Ti pristopi zahtevajo usposabljanje specializiranega modela NMT iz nič na vzporednih korpusih na ravni dokumentov. Predlagamo pristop, ki ne zahteva usposabljanja specializiranega modela na vzporednih korpusih na ravni dokumentov in se uporablja za usposobljen model NMT na ravni stavka v času dekodiranja. Dokument večkrat obdelujemo z leve proti desni in samousposabljamo model stavka na parih izvornih stavkov in generiranih prevodov. Naš pristop krepi odločitve modela in tako povečuje verjetnost, da bodo iste odločitve sprejete v drugih stavkih dokumenta. Naš pristop ocenjujemo na treh nivojih podatkov na ravni dokumentov: NIST kitajsko-angleščina, WMT19 kitajsko-angleščina in OpenSubtitles angleščina-ruska. Dokazujemo, da ima naš pristop višji rezultat BLEU in višji človeški preferenci kot izhodišče. Kvalitativna analiza našega pristopa kaže, da so odločitve po modelu dosledne v celotnem dokumentu.', 'he': 'תורגם ע"י מכונת נוירות (NMT) בטח השיג שוויון ברמה אנושית כשהוא מאמן ומעריך ברמה המשפטים. תרגום מכונת עצבית ברמה של מסמכים קיבל פחות תשומת לב ונשאר מאחורי השותף שלה ברמת המשפט. רוב גישות רמת המסמכים המוצעות חוקרות דרכים לתאים את המודל על מספר משפטים מקורים או מטרה כדי לתפוס קשר מסמכים. גישות אלה דורשות אימון מודל NMT מיוחד מאפס על קבורה במקביל רמה מסמכים. אנו מציעים גישה שלא דורשת אימון מומחה על גופורה מקצועית רמת מסמכים ומשתמשת על מודל NMT רמת משפטים מאומנת בזמן הפענוח. אנחנו מעבדים את המסמך משמאל לימין פעמים רבות ואימונים עצמיים את דוגמנית רמת המשפטים על זוגות משפטים מקורים ויוצרו תרגומות. הגישה שלנו מחזקת את הבחירות שנעשו על ידי המודל, כך הופך את זה יותר סביר שאותות הבחירות ייעשו במשפטים אחרים במסמך. אנחנו מעריכים את הגישה שלנו על שלושה קבוצות נתונים ברמה מסמכים: NIST סיני-אנגלי, WMT19 סיני-אנגלי ו OpenSubtitles אנגלי-רוסי. אנו מראים שלגישתנו יש נקודת BLEU גבוהה יותר והעדיפות האנושית גבוהה יותר מהתחילה. ניתוח איכותי של הגישה שלנו מראה שהבחירות שנעשו על ידי דוגמנית תואמות בכל המסמך.', 'ha': "translation @ action: button Babu mafi yawanci da aka buƙata hanyoyin takardar-daraja ɗin da aka sake su zartar da shiryoyin ayuka masu tsari kan motel a kan masu manyan kwanan ko kuma da saurari masu yiwuwa wa ya kãma mazaɓan takardar. Wannan durowa na ƙayyade yin tafiyar da wani misali na NMT mai ƙayyade daga taɓa kan takardar takardar-daraja. Tuna goyyar da wata hanyor da ba t a buƙata yin ƙidãya da wani misali mai ƙayyade kan shirin takardar-daraja na daidaita kuma za'a yi amfani da shi ga misalin-daraja na NMT idan na yi amfani da lokaci. Kana tafiyar da takardar aiki daga hagu zuwa dama sau sau biyu masu ƙari kuma muna tafiyar da misalin maganar-daraja farat ɗaya kan sonar-sau biyu da aka ƙãga fassarori. Tsarakanmu yana ƙara wa zaɓen misali, don haka sai ya fi kusa za'a sami zaɓen su cikin wasu takardar. @ item license (short name) Tuna nũna cewa hanyarmu yana da mafiya kyauta BLEU da mafiya daraja ga mutum daga basin. Ana ƙayyade baƙaitaccen hanyarmu ya nuna cewa zaɓallin zaɓen a sami duk takardar.", 'bo': 'རང་ཉིད་ཀྱི་མིའི་ལག་འཁྱེར་གྱི་སྐད་ཡིག་ཆ(NMT)ནི་ཚིག་གྲངས་སྒྲིག་དང་ཚིག་རྟགས་ལྟར་བསམ་བློ་གཏོང ཡིག གྲོས་འཆར་བཀོད་ཡོད་པའི་ཡིག་ཆའི་གྲངས་ཀ་ཆེ་ཆུང These approaches require training a specialized NMT model from scratch on parallel document-level corpora. ང་ཚོས་རང་ཉིད་ཀྱི་ཐབས་ལམ་དེ་ལ་སྒྲིག་ཐད་ཀར་ཡོད་པའི་མིག་གཟུགས་རིས་ཀྱི་ལས་འགན་སྐོར་བྱེད་མི་དགོས་པའི་ལས་འགན་སྒྲིག་ཡོད་པའི་ཚི ང་ཚོས་ཡིག ང་ཚོའི་གདམ་གས་ཀྱིས་མ་དཔེ་དབྱིབས་བེད་སྤྱད་པར་གདམ་གསེས་དེ་གཉིས་ཀྱིས་ཡིག་ཆ་གཞན་ཞིག་བྱེད་སྲིད། ང་ཚོས་རང་གི་ཐབས་ལམ་ལ་ཡིག་ཆའི་གནས་སྟངས་གསུམ་ཀྱི་གནད་དོན་འགན་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་རང་གི་ཐབས་ལམ་ལ་ཡོད་ཚད་ལྡན་སྔོན་གྲངས་ཀ་དང་། མི་རིགས་ཀྱི་རང་མོས་སྒྲིག ང་ཚོའི་གདམ་གས་ཀྱི་མཐུན་ཐག་གི་དབྱེ་ཞིབ་དཔྱད་ནི་མ་དབྱིབས་བཟོ་བྱེད་པའི་གདམ་གསེས་ཡིག', 'jv': 'Where am I Laptop" and "Desktop Laptop" and "Desktop Name Awak dhéwé nggunakake ditambah sing ora nggawe layakno model sing perusahaan banget nggo kuwi cadeh, dadi nggo modèl NMT kuwi nggo ndelok ujaran. Awak dhéwé ngeremus dokumen nang kayané nang lunga sampek dadi lan autora sampek modèl kuwi nggawe barang kelas kuwi tindahan kanggo ngirim barang Awak dhéwé nglanggar aturan pilihan sing gak dhéwé ning model, dadi iki dadi bisa langgar sing gak pilihan liyane kabèh wong liyane wis dipunakno ning acara awak dhéwé ning dokumen. Awak dhéwé éntuk dhéwé nggawe barang telu dataset sing teka-tanggal dokumen: NIRT Cino-Inggris, WTT19 Cino-Inggris lan Open Subtitles Inggris-Russ. Awak dhéwé éntuk éntukno awak dhéwé nggawe gerakan sing luwih basa sing luwih klebu lan sing paling nggambar uwong. Samsul kaliwati kanggo diandelak dhéwé ngerasakno dadi kawit milih sing gawe model kuwi sampeyan ngono kuwi nggawe dokumen.'}
{'en': 'Anaphora Resolution in Dialogue : Description of the DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'ar': 'حل الجناس في الحوار: وصف نظام DFKI-TalkingRobots لـ CODI-CRAC 2021 Shared-Task', 'fr': "Résolution sur l'anaphore en dialogue\xa0: Description du système de robots parlants DFKI pour la tâche partagée CODI-CRAC 2021", 'pt': 'Resolução Anáfora em Diálogo: Descrição do Sistema DFKI-TalkingRobots para a Tarefa Compartilhada CODI-CRAC 2021', 'es': 'Resolución anáfora en diálogo: descripción del sistema DFKI-TalkingRobots para la tarea compartida CODI-CRAC 2021', 'ja': 'Anaphora Resolution in Dialogue: CODI - CRAC 2021共有タスクのためのDFKI - TalkingRobotsシステムの説明', 'zh': 'å…¶Anaphoraè®®æ›°:CODI-CRAC 2021å…±äº‹è€…DFKI-Talkingæœºå™¨äººç»Ÿä¹Ÿ', 'hi': 'संवाद में Anaphora संकल्प: CODI-CRAC 2021 साझा-कार्य के लिए DFKI-TalkingRobots सिस्टम का विवरण', 'ru': 'Anaphora Resolution in Dialogue: Description of the DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'ga': 'Rún Anaphora in Agallamh: Cur síos ar an gCóras DFKI-TalkingRobots le haghaidh Tasc Comhroinnte CODI-CRAC 2021', 'ka': 'დიალოგიში ანაფორის რეზიოციო: CODI-CRAC 2021 shared-Task სისტემა DFKI-საუბრობის განსაზღვრება', 'el': 'Ψήφισμα Ανάφορας στον Διάλογο: Περιγραφή του Συστήματος Μιλώντας Ρομπότ για την Κοινή Εργασία', 'hu': 'Anaphora megoldás párbeszédben: A DFKI-TalkingRobots rendszer leírása a CODI-CRAC 2021 megosztott feladathoz', 'it': 'Risoluzione Anaphora in dialogo: Descrizione del sistema DFKI-TalkingRobots per il compito condiviso CODI-CRAC 2021', 'kk': 'Диалогтың Anaphora Айырымдылығы: CODI-CRAC 2021 ортақтастырылған тапсырманың DFKI-TalkingRobots жүйесінің сипаттамасы', 'mk': 'Anaphora Resolution in Dialogue: Description of the DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'ms': 'Resolusi Anafora dalam Dialog: Keterangan Sistem Robot-Bercakap DFKI untuk Tugas Berkongsi CODI-CRAC 2021', 'lt': 'Anaforos pertvarkymas dialoge: DFKI-TalkingRobots sistemos CODI-CRAC 2021 bendros užduoties aprašymas', 'mt': 'Anaphora Resolution in Dialogue: Description of the DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'no': 'Anaforoppløysing i dialogvindauget: Beskrivelse av DFKI-talkingrobotsystemet for CODI-CRAC 2021 delt oppgåve', 'ro': 'Rezoluția Anaphora în dialog: Descrierea sistemului DFKI-TalkingRobots pentru sarcina partajată CODI-CRAC 2021', 'pl': 'Rozwiązanie anafory w dialogu: Opis systemu DFKI-TalkingRobots dla CODI-CRAC 2021 Shared-Task', 'ml': 'ഡയലോഗിലെ അനാഫോറ റ റിസ്റ്റല്\u200d: Description of the DFKI- Talking Robots System for the CODI- CRAC 2021 Shared- Task', 'sr': 'Anafora Rezolucija u dijalogu: opis DFKI-govornog robotskog sustava za CODI-CRAC 2021 podeljeni zadatak', 'mn': 'CODI-CRAC 2021 хуваалтын ажлын DFKI-ярианы робот системийн тодорхойлолт', 'si': 'සංවාදයේ Anaphora resolution: CODI-CRAC 2021 සමාගත වැඩක් විස්තර DFKI-TalkingRobots පද්ධතිය', 'ta': 'Anaphora Resolution in Dialogue: Description of the DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'ur': 'ڈیلوگو میں آنافورا ریزیزول: CODI-CRAC 2021 شریک-ٹاکس کے لئے DFKI-Talking روبوٹ سیسٹم کی توصیح', 'so': 'Description of the DFKI-Talking Robots System for the CODI-CRAC 2021 Shared-Task', 'sv': 'Anaphora Resolution in Dialogue: Beskrivning av DFKI-TalkingRobots System för CODI-CRAC 2021 Shared-Task', 'uz': 'Robots System for the CODI- CRAC 2021 Shared- Task', 'vi': 'phân giải Anaphora trong phần tử: mô tả hệ thống Mô tả Bo Tử nằm vùng cho CODI-CRAC 2021, đã chia sẻ-Task', 'bg': 'Резолюция на анафората в диалог: Описание на системата за говорещи роботи за споделената задача', 'hr': 'Anafora Rezolucija u dijalogu: opis DFKI-govornog robotskog sustava za CODI-CRAC 2021. zajednički zadatak', 'nl': 'Anafora Resolutie in Dialoog: Beschrijving van het DFKI-TalkingRobots Systeem voor de CODI-CRAC 2021 Shared-Task', 'de': 'Anaphora Resolution im Dialog: Beschreibung des DFKI-TalkingRobots Systems für den CODI-CRAC 2021 Shared-Task', 'ko': '대화의 반지름 해석: CODI-CRAC 2021 공유 작업에 사용되는 DFKI Talking Robots 시스템 설명', 'id': 'Resolusi Anafora dalam Dialog: Deskripsi sistem robot DFKI-TalkingRobots untuk CODI-CRAC 2021 Shared-Task', 'fa': 'Resolution Anaphora in Dialog: Description of the DFKI-Talking Robots System for the CODI-CRAC 2021 Shared-Task', 'sw': 'Tafsiri ya Mfumo wa DFKI-Talking Robots kwa ajili ya CODI-CRAC 2021', 'sq': 'Rezolucioni i anaforës në dialog: Përshkrimi i Sistemit DFKI-TalkingRobots për CODI-CRAC 2021-Task-Shared', 'am': 'Robots System for the CODI-CRAC 2021 Shared-Task', 'da': 'Anaphora Resolution in Dialogue: Beskrivelse af DFKI-TalkingRobots System til CODI-CRAC 2021 Shared-Task', 'az': 'Dialogda Anafora Çözünürlük: CODI-CRAC 2021 paylaşılmış-Task sisteminin DFKI-TalkingRobots Sisteminin tərzi', 'tr': 'CODI-CRAC 2021 Mazmunlar-Taýgynyň DFKI-Gürüş Robotlaryň Waspy', 'bn': 'ডায়ালগে আনাফোরা রিসুলেশন: DFKI- Talking Robots সিস্টেমের Description of the DFKI- Talking Robots System for the CODI-CRAC 2021 Shared-Tasks', 'af': 'Anafora Resolusie in Dialoog: Beskrywing van die DFKI- Praat- Robots Stelsel vir die CODI- CRAC 2021 Gedeelde- Opdrag', 'bs': 'Anafora Rezolucija u dijalogu: opis DFKI-govornog robotskog sustava za CODI-CRAC 2021.', 'ca': "Resolució d'anafòra en Diàleg: Descripció del sistema DFKI-TalkingRobots del CODI-CRAC 2021", 'cs': 'Anaforické řešení v dialogu: Popis systému DFKI-TalkingRobots pro CODI-CRAC 2021 Shared-Task', 'hy': 'Անաֆորայի վերլուծություն դասախոսում. COD-Crac 2021-ի ընդհանուր հանձնարարության DFKI-Talking ռոբոտների համակարգի նկարագրությունը', 'et': 'Anafoora lahendamine dialoogis: DFKI-TalkingRobots süsteemi kirjeldus CODI-CRAC 2021 jagatud ülesande jaoks', 'fi': 'Anafora Resolution in Dialogue: Kuvaus DFKI-TalkingRobots-järjestelmästä CODI-CRAC 2021 Shared-Task', 'ha': 'Description of the DFKI-Talk', 'sk': 'Reševanje anafore v dialogu: Opis sistema DFKI-TalkingRobots za CODI-CRAC 2021 Shared-Task', 'he': 'פתרון אנאפורה בדיולוג: תיאור של מערכת רובוטים מדברים DFKI עבור משימה משותפת CODI-CRAC 2021', 'bo': 'Anaphora Resolution in Dialog: DFKI-TalkingRobots System for the CODI-CRAC 2021 Shared-Task', 'jv': 'Anaphora Resolution Teko Dialog: Gambaran DFKi-TalkingJobot System kanggo cordi-criterion 2020 1 shared-task'}
{'en': 'We describe the system developed by the DFKI-TalkingRobots Team for the CODI-CRAC 2021 Shared-Task on anaphora resolution in dialogue. Our system consists of three subsystems : (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics ; (2) the Mention-to-Mention (M2 M) coreference resolution system pairs same entity mentions ; (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs. WCS achieved F1-score of 55.6 % averaged across the evaluation test sets, ', 'ar': 'نحن نصف النظام الذي طوره فريق DFKI-TalkingRobots لـ CODI-CRAC 2021 Shared-Task بشأن دقة الجاذبية في الحوار. يتكون نظامنا من ثلاثة أنظمة فرعية: (1) يقوم نظام Coreference الخاص بمساحة العمل (WCS) بتجميع الإشارات بشكل تدريجي باستخدام التشابه الدلالي المستند إلى حفلات الزفاف جنبًا إلى جنب مع الاستدلال على السمات المعجمية ؛ (2) أزواج نظام حل المرجع من الإشارة إلى الإشارة (M2M) التي ذكرها نفس الكيان ؛ (3) يستخدم نظام Discourse Deixis Resolution (DDR) شبكة سيامية لاكتشاف أزواج الخطاب السابقات والجانبي. حققت WCS درجة F1 بنسبة 55.6٪ في المتوسط عبر مجموعات اختبار التقييم ، وحققت M2M 57.2٪ وحققت DDR 21.5٪.', 'pt': 'Descrevemos o sistema desenvolvido pela equipe DFKI-TalkingRobots para o CODI-CRAC 2021 Shared-Task sobre resolução de anáfora em diálogo. Nosso sistema consiste em três subsistemas: (1) o Workspace Coreference System (WCS) agrupa menções incrementalmente em clusters usando similaridade semântica baseada em embeddings combinados com heurísticas de recursos lexicais; (2) o sistema de resolução de correferência Menção-a-Menção (M2M) emparelha as mesmas menções de entidade; (3) o sistema Discourse Deixis Resolution (DDR) emprega uma rede siamesa para detectar pares anáfora-antecedentes de discurso. WCS alcançou F1-score de 55,6% em média nos conjuntos de testes de avaliação, M2M alcançou 57,2% e DDR alcançou 21,5%.', 'es': 'Describimos el sistema desarrollado por el equipo DFKI-TalkingRobots para la tarea compartida del CODI-CRAC 2021 sobre la resolución de anáforas en el diálogo. Nuestro sistema consta de tres subsistemas: (1) el Sistema de Correferencia del Espacio de Trabajo (WCS) agrupa de forma incremental las menciones usando similitud semántica basada en incrustaciones combinadas con heurística de características léxicas; (2) el sistema de resolución de correferencia Mención a mención (M2M) empareja menciones de la misma entidad; (3) el Discurso El sistema Deixis Resolution (DDR) emplea una red siamesa para detectar pares de anáfora-antecedente del discurso. El WCS obtuvo una puntuación F1 del 55,6% promediada en todos los conjuntos de pruebas de evaluación, M2M alcanzó el 57,2% y DDR alcanzó el 21,5%.', 'fr': "Nous décrivons le système développé par l'équipe DFKI-TalkingRobots pour la tâche partagée CODI-CRAC 2021 sur la résolution des anaphores en dialogue. Notre système se compose de trois sous-systèmes\xa0: (1) le système de coréférence de l'espace de travail (WCS) regroupe de manière incrémentielle les mentions en utilisant la similarité sémantique basée sur des intégrations combinées à des heuristiques de caractéristiques lexicales\xa0; (2) le système de résolution de coréférence Mention-to-Mention (M2M) associe les mêmes mentions d'entité\xa0; (3) le Discourse Le système Deixis Resolution (DDR) utilise un réseau siamois pour détecter les couples anaphre-antécédent de discours. WCS a obtenu un score F1 de 55,6\xa0% en moyenne sur l'ensemble des ensembles de tests d'évaluation, M2M a obtenu 57,2\xa0% et DDR 21,5\xa0%.", 'ja': 'DFKI - TalkingRobotsチームがCODI - CRAC 2021 Shared - Taskのために開発した対話型アナフォラ解決システムについて説明します。当社のシステムは、次の3つのサブシステムで構成されています。（ 1 ） Workspace Coreference System （ WCS ）は、語彙特徴ヒューリスティックと組み合わせた埋め込みに基づいて、セマンティックの類似性を使用してクラスタを増分的に言及します。（ 2 ） M 2 M （ M 2 M ）コアファレンスレゾリューションシステムは、同じエンティティが言及したペアをペアにします。（ 3 ） Discourse Deixis Resolution （ DDR ）システムは、Siamese Networkを使用して、発話の類推前置ペアを検出します。ＷＣＳは、評価試験セット全体で平均５ ５ ． ６ ％のＦ １スコアを達成し、Ｍ ２ Ｍは５ ７ ． ２ ％、ＤＤＲは２ １ ． ５ ％を達成した。', 'zh': '言DFKI-TalkingRobots团队为CODI-CRAC 2021共事,当系于言anaphora。 臣等统由三子系统:(1)事区协同系统(WCS)用基于嵌入语义相似性与词汇特征启发式法,增量聚类提及。 (2)提及提及(M2M)共推理解析系统将同实体提及配对; (3)语Deixis Resolution(DDR)统用暹罗网络检语前验是。 WCS估会之均F1分为55.6%,M2M及57.2%,DDR及21.5%。', 'hi': 'हम DFKI-TalkingRobots टीम द्वारा CODI-CRAC 2021 साझा-कार्य के लिए विकसित प्रणाली का वर्णन करते हैं जो संवाद में एनाफोरा रिज़ॉल्यूशन पर है। हमारे सिस्टम में तीन उपप्रणालियों होते हैं: (1) वर्कस्पेस कोरेफेरेंस सिस्टम (डब्ल्यूसीएस) वृद्धिशील रूप से क्लस्टर लेक्सिकल फीचर ह्यूरिस्टिक्स के साथ संयुक्त एम्बेडिंग के आधार पर शब्दार्थ समानता का उपयोग करके उल्लेख करता है; (2) उल्लेख-से-उल्लेख (M2M) coreference संकल्प प्रणाली जोड़े एक ही इकाई का उल्लेख करता है; (3) प्रवचन Deixis संकल्प (DDR) प्रणाली प्रवचन anaphor-पूर्ववर्ती जोड़े का पता लगाने के लिए एक सियामी नेटवर्क नियोजित करता है। डब्ल्यूसीएस ने मूल्यांकन परीक्षण सेटों में औसतन 55.6% का एफ 1-स्कोर हासिल किया, एम 2 एम ने 57.2% और डीडीआर ने 21.5% हासिल किया।', 'ru': 'Мы описываем систему, разработанную командой DFKI-TalkingRobots для совместной задачи CODI-CRAC 2021 по разрешению анафоры в диалоге. Наша система состоит из трех подсистем: (1) система Workspace Coreference System (WCS) постепенно упоминает семантическое сходство, основанное на вложениях в сочетании с лексической эвристикой признаков; (2) система разрешения ядра «Упоминание - Упоминание» (M2M) сочетает в себе одно и то же упоминание сущности; (3) система Discourse Deixis Resolution (DDR) использует сиамскую сеть для обнаружения пар анафора-антецедент дискурса. WCS достигла показателя F1 в 55,6%, усредненного по оценочным наборам испытаний, M2M достигла 57,2%, а DDR достигла 21,5%.', 'ga': 'Déanaimid cur síos ar an gcóras a d’fhorbair Foireann DFKI-TalkingRobots le haghaidh Tasc Comhroinnte CODI-CRAC 2021 ar réiteach anafóra san idirphlé. Tá trí fhochóras inár gcóras: (1) luann an Córas Croíthagartha Spás Oibre (WCS) go hincriminteach úsáid a bhaint as cosúlacht shéimeantach bunaithe ar leabaithe in éineacht le heuristics gnéithe foclóireachta; (2) a luann an t-aonán céanna sa chóras réitigh croí-luaite um Lua go Lua (M2M); (3) Fostaíonn an córas um Réiteach Dioscúrsa Deixis (DDR) Líonra Siamese chun péirí anaphor-réamhtheachtaí dioscúrsa a bhrath. Ghnóthaigh WCS scór F1 de 55.6% ar an meán thar na tacair tástála meastóireachta, ghnóthaigh M2M 57.2% agus ghnóthaigh DDR 21.5%.', 'ka': 'ჩვენ სისტემა, რომელიც DFKI-საუბრობო პრობოტების ჯგუფის განვითარებული CODI-CRAC 2021-ის განსაზღვრებული დავალება ანაფორის განსაზღვრებით დიალოგიში. ჩვენი სისტემა არის სამი სპესტისტემები: (1) სამუშაო სამუშაო სამუშაო კორეფერენციის სისტემა (WCS) ინტერემენტალურად კლასტერების გამოყენება სმენტიკური similarity გამოყენება, რომელიც ლე (2) Mention-to-Mention (M2M) coreference resolution system pairs are the same entity mentioned; and (3) Discourse Deixis Resolution (DDR) სისტემა სიამის ქსელის გამოყენება დისკურსის ანაფორ- ანტეცენტის პარამეტრების გამოყენება. WCS მიიღეთ განსაზღვრებული ტესტის განსაზღვრებით 55,6%-ის განსაზღვრებით, M2M მიიღეთ 57,2% და DDR მიიღეთ 21,5%.', 'hu': 'Leírjuk a DFKI-TalkingRobots Team által a CODI-CRAC 2021 Shared-Task számára kifejlesztett rendszert az anafóra megoldására párbeszédben. Rendszerünk három alrendszerből áll: (1) a Workspace Coreference System (WCS) növekményesen említi a klasztereket beágyazásokon alapuló szemantikai hasonlóság használatával kombinált lexikai jellemzők heurisztikájával; (2) a Mention-to-Mention (M2M) coreferencia szanálási rendszer ugyanazokat a jogalanyokat párosítja; (3) A Discourse Deixis Resolution (DDR) rendszer egy sziámi hálózatot alkalmaz a diskurzus anafór-előző párok felismerésére. A WCS 55,6%-os F1 pontszámot ért el az értékelő tesztkészletek átlagában, az M2M 57,2%-ot, a DDR 21,5%-ot ért el.', 'el': 'Περιγράφουμε το σύστημα που αναπτύχθηκε από την Ομάδα Μιλώντας Ρομπότ για την Κοινή Εργασία για την επίλυση της αναφορής σε διάλογο. Το σύστημά μας αποτελείται από τρία υποσυστήματα: (1) το Σύστημα Συγκέντρωσης Χώρου Εργασίας (Το Σύστημα Συγκέντρωσης Εργασιακού Χώρου (Το Σύστημα Συγκέντρωσης Εργασιακού Χώρου (Το Σύστημα Συγκέντρωσης Εργασιακού Χώρου) αναφέρει βαθμιαία τη χρήση σημασιολογικής ομοιότητας βασισμένης σε ενσωματώσεις σε συνδυασμό με λεξική heuristική χαρακτηριστικών. (2) το σύστημα εξυγίανσης συναρτήσεων μεταξύ αναφοράς (M2M) ζευγαρώνει την ίδια οντότητα, (3) το σύστημα Επίλυσης της Διξίδας Λόγου χρησιμοποιεί ένα Σιαμέζικο Δίκτυο για την ανίχνευση αναφορών-προγενέστερων ζευγαριών λόγου. Το WCS πέτυχε F1-βαθμολογία 55,6% κατά μέσο όρο στα σύνολα δοκιμών αξιολόγησης, το M2M πέτυχε 57,2% και το DDR πέτυχε 21,5%.', 'kk': 'Біз DFKI-TalkingRobots тобы (CODI-CRAC 2021) диалогындағы анафора айырмашылығында ортақ тапсырмалар үшін жасалған жүйені таңдадық. Біздің жүйеміз үш ішкі жүйелерден тұрады: (1) Жұмыс жерлерді баптау жүйесі (WCS) лексикалық функциялармен біріктірілген ендірімдерге негізделген семантикалық ұқсастықтығын қолданады. (2) Мәзірден мәзірге (M2M) мәзірдегі айырмашылық жүйесінің екеуі бір нәтижесін айтылады; NAME OF TRANSLATORS (3) Дискурстардың Дейкс Айырымдылығы (DDR) жүйесі дискурстардың анафор- антецедентті екеуін анықтау үшін сиамез желіне қолданылады. WCS бағалау сынақтарында орташа 55,6% F1 деңгейін жетті, M2M 57,2% және DDR 21,5% дегенді жетті.', 'it': "Descriviamo il sistema sviluppato dal team DFKI-TalkingRobots per il CODI-CRAC 2021 Shared-Task sulla risoluzione anafora in dialogo. Il nostro sistema è composto da tre sottosistemi: (1) il Workspace Coreference System (WCS) menziona incrementalmente cluster utilizzando somiglianze semantiche basate su incorporazioni combinate con euristica lessicale; (2) il sistema di risoluzione della coreferenza Mention-to-Mention (M2M) accoppia le stesse menzioni dell'entità; (3) il sistema Discourse Deixis Resolution (DDR) impiega una Rete Siamese per rilevare coppie anafore-antecedenti del discorso. WCS ha ottenuto il punteggio F1 del 55,6% medio tra i set di test di valutazione, M2M ha raggiunto il 57,2% e DDR il 21,5%.", 'mk': 'Го опишуваме системот развиен од страна на ДФКИ-Зборувачкиот Роботски тим за CODI-CRAC 2021 Соделена задача за решавање на анафората во дијалогот. Our system consists of three subsystems: (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics;  (2) системот за резолуција на соодветната резолуција на споменувањето (M2M) ги споменува истите ентитети; (3) Системот за резолуција на дискорската дексија (ДДР) користи сијамска мрежа за детектирање на парови од дискорска анафора. WCS achieved F1-score of 55.6% averaged across the evaluation test sets, M2M achieved 57.2% and DDR achieved 21.5%.', 'lt': 'Mes apibūdiname sistemą, kurią parengė DFKI-TalkingRobots grupė CODI-CRAC 2021 bendrai užduotims dėl anaforos pertvarkymo dialoge. Mūsų sistemą sudaro trys posistemiai: 1) darbo erdvės koreferencijos sistema (WCS) palaipsniui minima grupių, naudojančių semantinį panašumą, pagrįstą įterptimis kartu su leksiniais bruožais heuristika; (2) paminėjimo į paminėjimą (M2M) koreferencijos pertvarkymo sistema paminėja tą patį subjektą; (3) diskurso deiksijos pertvarkymo (DDR) sistema naudoja Siamo tinklą diskurso anaforos ankstesnių porų aptikimui. WCS achieved F1-score of 55.6% averaged across the evaluation test sets, M2M achieved 57.2% and DDR achieved 21.5%.', 'ms': 'Kami menggambarkan sistem yang dikembangkan oleh Pasukan Robot DFKI-TalkingRobots untuk Tugas Berkongsi CODI-CRAC 2021 pada resolusi anafora dalam dialog. Our system consists of three subsystems: (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics;  (2) sistem resolusi keterangan-ke-keterangan (M2M) pasangan entiti yang sama disebut; (3) Sistem Resolusi Deiks Perhubungan (DDR) menggunakan Rangkaian Siama untuk mengesan pasangan anafora-sebelumnya. WCS mencapai skor-F1 55.6% rata-rata dalam set ujian penilaian, M2M mencapai 57.2% dan DDR mencapai 21.5%.', 'ml': 'ഡിഎഫ്\u200cകി-സംസാരിക്കുന്ന റോബോട്ട് ടീം നിര്\u200dമ്മിച്ചിരിക്കുന്ന സിസ്റ്റം ഞങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. കോഡിഐ-CRAC 2021- ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d മൂന്നു സബ്സിസ്റ്റമുണ്ട്: (1) വേര്\u200dപ്പ് കോര്\u200dഫെന്\u200dസ് സിസ്റ്റം (WCS) ലെക്സിക്കല്\u200d ഗുണഗണങ്ങളുടെ കൂടെ കൂട്ടിചേര്\u200dത്ത്  (2) മെനെന്നേഷന്\u200d - മെനെന്\u200d- മെന്\u200dഷന്\u200d (M2M) കോര്\u200dഫെന്\u200dസ് റിസ്റ്റേഷന്\u200d സിസ്റ്റം ഒരേ വസ്തുവിന്റെ പേരുകള്\u200d; (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs.  വിവില പരീക്ഷണത്തിന്റെ സജ്ജീകരണങ്ങളിലൂടെ എഫ്\u200cഎസിസില്\u200d 55. 6% എഫ്\u200c1 സ്കോര്\u200d എത്തി. എം2M 57. 2% പ്രാപിച്ചു. DDR 21.5%.', 'mn': 'Бид CODI-CRAC 2021-ийн DFKI-ярианы Роботын багийнхаа хөгжсөн системийг анафора шийдвэрлэлийн талаар хуваалцан ажлыг тайлбарлаж байна. Бидний систем гурван субсистем байдаг: (1) Ажиллалтын орон зайд хамгийн их хэмжээний систем (WCS) нь лексикийн хувьцааны хэмжээний хюристик холбогдолтоос багтаж байгаа семантик төстэй байдал ашигладаг. (2) Mention-to-Mention (M2M) сайхан шийдвэрлэлтийн системийн хоёр нь ижил нэгж хэлж байна. (3) Дэйксис шийдвэрлэл (DDR) систем нь ярианы алдартай хоёрыг олохын тулд Сиамийн сүлжээний сүлжээг ашигладаг. WCS шалгалтын туршилтын дундаж 55.6% нь F1 оноо хүртсэн. M2M 57.2% болон DDR 21.5% хүртсэн.', 'mt': 'Aħna niddeskrivu s-sistema żviluppata mit-Tim DFKI-TalkingRobots għall-CODI-CRAC 2021 Kompitu Konġunt dwar ir-riżoluzzjoni tal-anafora fid-djalogu. Is-sistema tagħna tikkonsisti minn tliet sottosistemi: (1) is-Sistema ta’ Koreferenza fl-Ispazju tax-Xogħol (WCS) issemmi inkrementalment raggruppamenti bl-użu ta’ similarità semantika bbażata fuq inkorporazzjonijiet ikkombinati ma’ ġewristiċi ta’ karatteristiċi lexiċi; (2) is-sistema tar-riżoluzzjoni tal-korreferenza Menzzjoni-Menzzjoni (M2M) tissemma l-istess entità; (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs.  WCS kiseb punteġġ F1 ta’ 55.6% medju fis-settijiet tat-testijiet ta’ evalwazzjoni, M2M kiseb 57.2% u DDR kiseb 21.5%.', 'pl': 'Opisujemy system opracowany przez zespół DFKI-TalkingRobots dla CODI-CRAC 2021 Shared-Task na temat rozwiązywania anafory w dialogu. Nasz system składa się z trzech podsystemów: (1) przyrostowo klastrów Workspace Coreference System (WCS) wymienia wykorzystując podobieństwo semantyczne oparte na osadzeniach w połączeniu z heurystyką cech leksykalnych; (2) system rozwiązywania współreferencji współreferencyjnej (M2M) paruje wspomniane wymienienia podmiotów; (3) System Discurse Deixis Resolution (DDR) wykorzystuje sieć syjamską do wykrywania par anaforowo-poprzednich dyskursów. WCS osiągnął wynik F1 55,6% uśredniony w zestawach testowych oceniających, M2M 57,2% i DDR 21,5%.', 'si': 'අපි DFKI-TalkingRobots කණ්ඩායමේ පද්ධතිය විස්තර කරනවා CODI-CRAC 2021 සඳහා අනාෆෝරා විස්තරයේ සංවාදයේ සමාගත විස්තර කරනවා. අපේ පද්ධතිය සබ් පද්ධතිය තුනක් තියෙන්නේ: (1) වැඩක්ෂේත්\u200dර කොරෙෆෙරෙන්ස් පද්ධතිය (WCS) විශේෂයෙන් සැමැන්තික සමාන්\u200dයතාවය භාවිත කරන්න ප (2) Mention-to-Mention (M2M) කෝරෙෆරෙන්ස් විශේෂණ පද්ධතිය සමහර අයිතියක් කියන්න; (3) සියාමිස් ජාලය පද්ධතියේ විස්තර දෙයික්ස් විශේෂණය (DDR) පද්ධතිය සියාමිස් ජාලය ප්\u200dරයෝජනය කරනවා කතාවක් අනා WCS පරීක්ෂණ පරීක්ෂණ සෙට්ටුවෙන් සාමාන්\u200dයය 55.6% කුණු F1-ප්\u200dරමාණය ලබාගත්තා, M2M එක 57.2% සහ DDR එක 21.5% ලබාගත්තා.', 'so': 'Waxaynu qoraynaa nidaamka oo u soo hormariyey DFKI-Talking Robots Team for the CODI-CRAC 2021 Shared-Task on resolution anaphora dialogue. nidaamka waxaa ka mid ah saddex hoos-dumiyeed: (1) Isticmaalka shaqaalaha (WCS) oo si kordha ah u soo bandhigaa xujooyinka lagu isticmaalayo isku mid ahaanshaha semantika oo ku saleysan meelaha la isku mid ah ee la xiriira xeryaha lexicka; (2) Isticmaalka isbedelka kooxaha (M2M) ee isbedelka nidaamka isku wasakhda ah oo isku mid ah; (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs.  WCS waxay gaadhay iskuul F1 oo ah 55.6% oo ku dhexaysay kooxda imtixaanka qiimeynta, M2M wuxuu gaadhay 57.2% iyo DDR waxay gaadhay 21.5%.', 'ro': 'Descriem sistemul dezvoltat de echipa DFKI-TalkingRobots pentru sarcina partajată CODI-CRAC 2021 privind rezolvarea anaforei în dialog. Sistemul nostru este format din trei subsisteme: (1) Sistemul de Coreferență a Spațiului de lucru (WCS) menționează treptat clusterele folosind similaritatea semantică bazată pe încorporări combinate cu euristica caracteristicilor lexicale; (2) sistemul de rezoluție a corefențelor menționate (M2M) cuplează aceleași mențiuni ale entității; (3) Sistemul de rezoluție a discursului Deixis (DDR) utilizează o rețea siameză pentru a detecta perechile anafore-antecedente ale discursului. WCS a obținut un scor F1 de 55,6% mediu în seturile de teste de evaluare, M2M a obținut 57,2% și DDR a obținut 21,5%.', 'sv': 'Vi beskriver det system som utvecklats av DFKI-TalkingRobots Team för CODI-CRAC 2021 Shared-Task om anaforalösning i dialog. Vårt system består av tre delsystem: (1) Workspace Coreference System (WCS) nämner stegvis kluster med hjälp av semantisk likhet baserad på inbäddningar kombinerade med lexikal funktionsheuristik; (2) Koreferensresolutionssystemet Mention-to-Mention (M2M) parar ihop samma företag som nämns. (3) Diskurse Deixis Resolution (DDR) systemet använder ett siamesiskt nätverk för att upptäcka diskursanafora-föregångare par. WCS uppnådde F1-poäng på 55,6% i genomsnitt över utvärderingstesten, M2M uppnådde 57,2% och DDR uppnådde 21,5%.', 'sr': 'Opišemo sistem razvijen od strane DFKI-govornog robotskog tima za CODI-CRAC 2021. podeljeni zadatak o rezoluciji anafore u dijalogu. Naš sistem se sastoji od tri podsustava: (1) sustav korisnosti radnog prostora (WCS) povećavajući skupove koristeći semantičku sličnost na osnovu ugrađenja kombinacije sa heuristikom leksičkih karakteristika; (2) Par sistema rezolucije dobrodošlosti (M2M) spominje isto područje; (3) Sistem diskursa Deixis Resolution (DDR) koristi Siamejsku mrežu za otkrivanje parova anafora-antecedent a diskursa. WCS je postigao srednji rezultat F1 od 55,6% u razdoblju testova za procjenu, M2M je postigao 57,2% i DDR je postigao 21,5%.', 'ta': 'CODI-CRAC 2021 க்கான DFKI-Talking Robots குழு உருவாக்கப்பட்ட முறைமையை நாம் விவரிக்கிறோம் பேச்சில் ஒளிக்கோடு தெளிவுத்திறன் மீது. எங்கள் அமைப்பு மூன்று துணை அமைப்புகளில் உள்ளது: (1) வேலை விளையாட்டு முறைமை அமைப்பு (WCS) கூடுதலாக குறிப்புகளை ஒத்திசைப்படுத்தும் பொருள்களை மூலம்  (2) குறிப்பு தெளிவுத்திறன் அமைப்பு ஜோடி ஒன்று பொருள் குறிப்புகள்: (3) வடிவமைப்பு டிக்ஸ் திரைத்திறன் (DDR) அமைப்பு சியமர் பிணையத்தை கண்டுபிடிக்கும் பேச்சு anaphor- antecedent ஜோடிகளை பயன்படுத்தும். WCS மதிப்பு சோதனைக்கு முழுவதும் 55. 6% சராசரியான F1- score அடைந்தது, M2M 57. 2% அடைந்தது DDR 21. 5%.', 'ur': 'ہم نے سیسٹم کو DFKI-Talking روبوٹ تیم کے ذریعہ توصیح دیتے ہیں CODI-CRAC 2021 کے لئے آنفورا ریزیولوشن کے ذریعہ شریک ٹاکس کے لئے۔ ہمارے سیستم میں تین سوسسٹیموں کا سامان ہے: (1) کارسپیس کورفرنس سیستم (WCS) اضافہ کلسٹر مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید مزید لکسیکل فوجیٹ ہوریستیک کے ساتھ (2) Mention-to-Mention (M2M) coreference resolution system pairs same entity mentions; (3) ڈیکسس ریزیزول (DDR) سیسٹم ایک سیامی نیٹورک کا استعمال کرتا ہے کہ صحبت نافور-آنٹیسڈینٹ جوڑوں کو پہچان سکے۔ WCS نے 55.6% کے F1-اسکور کو آزمائش تست سٹوں میں متوسط کیا، M2M 57.2% تک پہنچ گیا اور DDR 21.5% تک پہنچ گیا۔', 'no': 'Vi beskriver systemet utvikla av DFKI-TalkingRobots-gruppa for CODI-CRAC 2021 Delt oppgåve på anaforoppløysing i dialogen. Sistemet vårt inneheld tre undersystemer: (1) Arbeidsområde- koreferens- systemet (WCS) minner aukande grupper med semantisk likning basert på innbygging kombinert med hekuristisk funksjonar i teksten. (2) menyen-til-menyen (M2M) oppløysingssystemet for oppløysingssystemet gjev samme oppløysingssystemet; og (3) Discourse Deixis Resolution (DDR) systemet brukar ein Siamese Nettverk for å oppdaga diskursar anaforantesentant par. WCS har oppnådd F1- poeng med 55,6% gjennomsnittlig i evalueringstestsettet, M2M har oppnådd 57,2% og DDR har oppnådd 21,5%.', 'uz': "Biz muloqat oynasidagi anafora resolution uchun CODI-CRAC 2021 bo'lgan vazifa DFKI-Talking Robots jamoasi yaratgan tizimni anglatamiz. Bizning tizimimizda uchta sub-tizim bo'ladi: (1) Ish vazifa koreference tizimi (WCS) davomida, lektikal imkoniyatlar heuritik bilan bir qanday bog'liq bo'lgan paytlarni qo'yish uchun semantik bir xil qo'llanmalar bilan ishlatiladi; (2) Tashkilot (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs.  Comment", 'vi': 'Chúng tôi mô tả hệ thống được tạo ra bởi Đội Mô Tử Xà cho CODI-CRAC 2021 sẻ chia sẻ Nhiệm vụ giải quyết Anaphora trong cuộc đối thoại. Hệ thống của chúng ta gồm ba hệ thống: 1) Hệ thống Điều tra phòng không Việc làm (WCS) liên tục nhắc đến việc sử dụng nét giống nhau theo ngữ pháp kết hợp với thần mạch chữ. (2) Hệ thống giải quyết khả năng hạn chế (M2M) cặp với một thực thể cùng nhắc đến; (3) Hệ thống phân giải Discourse Deixis (DDR) sử dụng một mạng lưới Xiêm để phát hiện các cặp ngôn ngữ. Kết quả WCS đã đạt được con số F1 của 505.6 quá cao hơn so với số thử nghiệm, M22M đã đạt được 57.2=. và DDR đã đạt được 21.5 Name', 'hr': 'Opišemo sustav razvijen od strane DFKI-govornog robotskog tima za CODI-CRAC 2021. zajednički zadatak o rezoluciji anafore u dijalogu. Naš sustav se sastoji od tri podsustava: (1) sustav korisnosti radnog prostora (WCS) povećavajući skupine koristeći semantičku sličnost na osnovu ugrađenja kombiniranih s hekurističkim funkcijama. (2) Pari sustava za rješavanje pristojnosti (M2M) spominju isto područje;  (3) sustav diskursa Deixis Resolution (DDR) koristi Siamejsku mrežu za otkrivanje parova anafora-antecedent a diskursa. WCS je postigao srednji rezultat F1 od 55,6% u razdoblju testova za procjenu, M2M je postigao 57,2% i DDR postigao 21,5%.', 'bg': 'Описваме системата, разработена от екипа на Говорещите роботи за Споделена задача за решаване на анафора в диалог. Нашата система се състои от три подсистеми: (1) Системата за кореференция на работното пространство (WCS) постепенно клъстери споменават, използващи семантична сходство въз основа на вграждания, комбинирани с лексикална характеристика евристика; (2) системата за преструктуриране на съвместни референции (М2M) се свързва с едно и също предприятие; (3) системата за резолюция на дискурсния деиксис (ДДР) използва сиамска мрежа за откриване на дискурсните анафорни двойки. WCS постига средна оценка от 55,6% във всички тестови комплекти за оценка, M2M постига 57,2% и DDR достига 21,5%.', 'da': 'Vi beskriver systemet udviklet af DFKI-TalkingRobots Team til CODI-CRAC 2021 Shared-Task om anaphora løsning i dialog. Vores system består af tre delsystemer: (1) Workspace Coreference System (WCS) trinvist nævner klynger ved hjælp af semantisk lighed baseret på indlejringer kombineret med leksikalsk funktionsheuristik; (2) Mention-to-Mention (M2M) coreferenceafviklingssystemet parrer samme enhedsnævnelser (3) Diskurse Deixis Resolution (DDR) systemet anvender et siamesisk netværk til at detektere diskursanaphor-foregående par. WCS opnåede F1-score på 55,6% i gennemsnit på tværs af evalueringstestsættene, M2M opnåede 57,2% og DDR opnåede 21,5%.', 'id': 'Kami menggambarkan sistem yang dikembangkan oleh Tim Robot DFKI-Talkinguntuk CODI-CRAC 2021 Shared-Task tentang resolusi anafora dalam dialog. Sistem kita terdiri dari tiga subsistem: (1) Sistem Koreferensi Ruang Kerja (WCS) secara incremental menyebutkan kumpulan menggunakan similaritas semantis berdasarkan embedding berkombinan dengan karakteristik lexik heuristik; (2) sistem resolusi koreferensi Mention-to-Mention (M2M) sepasang entitas yang sama menyebutkan; (3) Sistem Resolusi Deiksi Disors (DDR) menggunakan Jaringan Siama untuk mendeteksi pasangan anafora-sebelumnya diskors. WCS mencapai skor F1 55,6% rata-rata di seluruh set tes evaluasi, M2M mencapai 57,2% dan DDR mencapai 21,5%.', 'nl': 'We beschrijven het systeem ontwikkeld door het DFKI-TalkingRobots Team voor de CODI-CRAC 2021 Shared-Task over anafora resolutie in dialoog. Ons systeem bestaat uit drie subsystemen: (1) het Workspace Coreference System (WCS) incrementele clusters vermeldt semantische gelijkenis gebaseerd op embeddings gecombineerd met lexicale feature heuristics; (2) het systeem voor coreferentieresolutie tussen verwijzingen en verwijzingen (M2M) koppelt dezelfde entiteitsvermeldingen; (3) het Discourse Deixis Resolution (DDR) systeem maakt gebruik van een Siamees Netwerk om discoursanafore-antecedent paren te detecteren. WCS behaalde F1-score van 55,6% gemiddeld over de evaluatietestsets, M2M bereikte 57,2% en DDR bereikte 21,5%.', 'ko': 'DFKI Talking Robots팀이 CODI-CRAC 2021 대화에서 공유 임무를 분석하기 위해 개발한 시스템을 설명합니다.우리의 시스템은 세 개의 서브시스템으로 구성된다. (1) 작업공간 공지시스템(WCS)은 삽입된 의미의 유사성을 바탕으로 어휘특징 계발법을 결합하여 언급을 증량 분류한다.(2) 언급 언급(M2M)은 모두 해소 시스템이 같은 실체에 대한 언급을 가리킨다.(3) 언어 지시 해소(DDR) 시스템은 연결 네트워크를 이용하여 말의 반지 선행어 쌍을 측정한다.WCS는 전체 평가 테스트가 집중된 F1에서 평균 55.6%, M2M 57.2%, DDR 21.5%의 점수를 받았다.', 'sw': 'Tunaelezea mfumo uliotengenezwa na timu ya DFKI-Talking Robots kwa ajili ya CODI-CRAC 2021 Kushirikiana na jukumu la upasuaji wa picha katika mazungumzo. Mfumo wetu unajumuisha mifumo mitatu ya chini: (1) Mfumo wa Shirika la Kazini (WCS) unaongezea kuongezeka kwa kutaja tamaa kwa kutumia usawa wa kimapenzi kwa kutumia vifaa vinavyoungana na vizuri vya lexico; (2) Mfumo wa suluhisho linalohusiana na Mention-to-Mention (M2M) utambulisho wa mfumo wa suluhisho wa majina yanayofanana; (3) Mfumo wa Utetezi Deixis Hudumu (DDR) unatumia Mtandao wa Siamese kutambua mazungumzo yanayozungumzia wanandoa. WCS ilipata kiwango cha F1 cha wastani wa asilimia 55.6 katika seti za uchunguzi, M2M ilipata asilimia 57.2 na DDR ilipata asilimia 21.5.', 'de': 'Wir beschreiben das vom DFKI-TalkingRobots Team entwickelte System für den CODI-CRAC 2021 Shared-Task zur Anaphora-Auflösung im Dialog. Unser System besteht aus drei Subsystemen: (1) Das Workspace Coreference System (WCS) nennt inkrementelle Cluster, die semantische Ähnlichkeit basierend auf Einbettungen in Kombination mit lexikalischen Merkmalsheuristiken verwenden; (2) das M2M-Coreferenz-Resolutionssystem (Mention-to-Mention) paart dieselben Entitätenangaben; (3) Das Diskurse Deixis Resolution (DDR) System verwendet ein Siamesisches Netzwerk, um Diskursanalaphor-antecedente Paare zu erkennen. WCS erzielte einen F1-Score von 55,6% gemittelt über die Evaluationstestsätze, M2M erreichte 57,2% und DDR erreichte 21,5%.', 'fa': 'ما سیستم توسط تیم DFKI-Talking Robots برای CODI-CRAC 2021 مشخص می\u200cکنیم، که توسط تیم مشخص\u200cکننده روبات\u200cهای مشخص شده است. سیستم ما از سه سیستم زیر سیستم است: (۱) سیستم تغییرات فضای کاری (WCS) با استفاده از شباهت semantic based on embeddings combined with lexical features heuristics را یاد می\u200cکند. (۲) سیستم حل رضایت یادآوری به یادآوری (M2M) جفتهای همان شرکت را یادآوری می\u200cکند. (۳) سیستم حل Deixis (DDR) گفتگو یک شبکه سیامی را برای شناسایی جفت\u200cهای پیش\u200cبینی سخنرانی استفاده می\u200cکند. WCS با نمونه\u200cهای F1 از 55.6% متوسط در مجموعه\u200cهای امتحان ارزیابی رسید، M2M به 57.2% رسید و DDR به 21.5% رسید.', 'sq': 'Ne e përshkruajmë sistemin e zhvilluar nga ekipi DFKI-TalkingRobots për CODI-CRAC 2021-Task-Shared mbi zgjidhjen e anaforës në dialog. Sistemi ynë përbëhet nga tre nënsisteme: (1) grupet e Sistemit të Koreferencës në hapësirën e Punës (WCS) përmendin në mënyrë graduale duke përdorur ngjashmërinë semantike bazuar në përfshirje të kombinuara me heoristikën e karakteristikave lexike; (2) Sistemi i zgjidhjes së përkujtimit (M2M) përmend të njëjtën njësi; (3) Sistemi i Rezolucionit të Deksisit të Diskutit (DDR) përdorë një rrjet Siamese për të zbuluar çifte anaforike të diskursit. WCS arriti një rezultat F1 prej 55.6% mesatar në të gjithë grupet e testimeve të vlerësimit, M2M arriti 57.2% dhe DDR arriti 21.5%.', 'tr': "Biz sistemi CODI-CRAC 2021'iň anafora çözümlenmesi barada döwletlenmiş Biziň sistemimiz üç alt sistemlerden olup: (1) Iş ýerleşdirim sistemasy (WCS) iň köp görnüşler semantik ýaly çykyşlyklar bilen birleştirilýän guramlardan daşarylýar. (2) Mensiýet-tä Mensiýet (M2M) karýeterlik sistemi çözümlenmesi üçin bir eşit agzalaýar; (3) Gezgini Deixis Çözümleri (DDR) sistemi sözlerini anafür-öňkili çiftleri a ňlamak üçin bir syamy aňlap işleýär. WCS deňlenme testiň arasynda F1 अंश 55,6% tapdy, M2M 57,2% we DDR 21,5% tapdy.", 'am': 'የCODI-CRAC 2021 የክፍለ ሥርዓት በናፎራ ውይይት ላይ የተሰራጨውን ስርዓት እናሳውቃለን፡፡ (1) የWorkspace Coreference System (2) ምርጫዎች (3) የDiscourse Deixis Resolution የWCS ቁጥር 55.6 በመቶ ቁጥር አግኝቷል፤ M2M 57.2 በመቶ አግኝቷል፤ DDR 21.5 በመቶ አግኝቷል።', 'hy': 'Մենք նկարագրում ենք համակարգը, որը ստեղծվել է DFKI-Talking Ռոբոտների թիմի կողմից CODKI-Crac 2021 թվականի համագործակցային հանձնարարությունը անաֆորայի լուծման համար: Our system consists of three subsystems: (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics;  (2) Միշել-մինչև-Միշել (M2M) համակարգը հարաբերությունների լուծման համակարգը զուգավորում է նույն անհատականությունը: (3) Դեքսուրս Դեքսի Ռեզոլուցիայի (DDD) համակարգը օգտագործում է սիամական ցանց, որպեսզի հայտնաբերի խոսքի անաֆորային նախկին զույգեր: ՀՀԿ-ն հասավ 55.6 տոկոսի F1-ի արդյունքի, որը հաշվի առկա էր գնահատման փորձարկումների ընթացքում, M2M-ը հասավ 57.2 տոկոսի, իսկ DDD-ը հասավ 21.5 տոկոսի:', 'az': 'Biz CODI-CRAC 2021 üçün DFKI-Talking Robot Takımı təhsil etdiyi sistemi anafora çözünürlüyü barəsində paylaşır. Bizim sistemimiz üç altsistem içindədir: (1) İş alanı Koreferens Sistemi (WCS) çox çox çox soxurlar, leksik özellikləri heuristik ilə birləşdirilmiş inbinglərə dayanan semantik similarlığı istifadə edir; (2) Mention-to-Mention (M2M) mərhəmət çəkişmə sisteminin cütləri istifadə edir; (3) Diskusiya Deixis Resolution (DDR) sistemi söhbətləri anafori-antezident çiftləri keşfetmək üçün Siamlı Ağ istifadə edir. WCS değerləşdirmə sınaqları arasında ortalama 55,6% F1 dəyişdi, M2M 57,2% və DDR 21,5% oldu.', 'af': "Ons beskrywe die stelsel wat deur die DFKI-Praat-Robots-Skep ontwikkeld is vir die CODI-CRAC 2021 Gedeelde-Opdrag op anafora-resolusie in dialoog. Ons stelsel bestaan van drie substelsels: (1) die Werkskerm Koreferensie Stelsel (WCS) inkremensielik klassters met gebruik van semantiese gelykenis gebaseer op inbêdings gekombineer met leksiese funksie heuristiek; ons stelsel bestaan van drie substelsels: (2) die Kieslys-na-Kieslys (3) die Discourse Deixis Resolution (DDR) stelsel gebruik 'n Siamese Netwerk om diskursie anaphor- antecedent paar te ontdek. WCS het F1- telling van 55. 6% gemiddeld deur die evaluering toets stel, M2M het 57. 2% en DDR 21. 5% bereik.", 'bn': 'ডিএফকিআই-ট্যাকিং রোবট ট টিম দ্বারা উন্নয়নের সিস্টেমের বর্ণনা করেছি কোডিআই-CRAC ২০২১ সালের বিভিন্ন সিস্টেমের বিভিন্ন ড আমাদের সিস্টেমের মধ্যে তিনটি সাবসিস্টেম রয়েছে: (১) কার্যস্পেস কোরিফারেন্স সিস্টেম (উইডিসি) বাড়তে থাকে সেমেন্টিক সমতা ব্যবহার করে লেক্সিক্সি (2) মেনুষ- থেকে মেনুন (M2M) কোরেফেন্স সিস্টেমের রিলেশন সিস্টেমের জোড়া একই বস্তুর উল্লেখ; (3) ডিস্কোর্স ডেইক্সিস রিপলেশন (ডিডিআর) সিয়ামের নেটওয়ার্ক ব্যবস্থা চালাচ্ছে যাতে কথোপকথন ব্যানাফার-এন্টেসেডেন্ট জ উইএসএস মূল্য পরীক্ষা সেটের মধ্যে ৫৫. ৬% স্কোর অর্জন করেছে, এম২এম ৫৭. ২% অর্জন করেছে এবং ডিডিআর ২১.', 'bs': 'Opišemo sistem razvijen od strane DFKI-govornog robotskog tima za CODI-CRAC 2021. zajednički zadatak o rezoluciji anafore u dijalogu. Naš sistem se sastoji od tri podsustava: (1) sustav korisnosti radnog prostora (WCS) povećavajući skupove upotrebljavajući semantičku sličnost na osnovu ugrađenja kombiniranih sa heurističkim funkcijama leksičke funkcije; (2) Par sustava za rješavanje pristojnosti (M2M) koji se spominju isto područje; (3) Sistem diskursa Deixis Resolution (DDR) koristi Siamejsku mrežu za otkrivanje parova anafora-antecedent a diskursa. WCS je postigao srednji rezultat F1 od 55,6% u razdoblju testova za procjenu, M2M je postigao 57,2% i DDR postigao 21,5%.', 'ca': "Descrivem el sistema desenvolupat per l'equip DFKI-TalkingRobots del CODI-CRAC 2021 Task Shared on anaphora resolution en diàleg. El nostre sistema consisteix en tres subsistemes: (1) el Sistema de Coreferència de l'espai de treball (WCS) menciona incrementalment agrupaments fent servir similitud semàntica basada en incorporacions combinades amb heurística de característiques lècsiques; (2) el sistema de resolució de coreferència Menció a Menció (M2M) es parella amb la mateixa entitat; (3) el sistema de resolució del deix de discurs (DDR) utilitza una xarxa siamese per detectar parells anafòrics. La WCS va aconseguir una puntuació F1 del 55,6% mitjana en els conjunts de tests d'evaluació, el M2M va aconseguir un 57,2% i el DDR va aconseguir un 21,5%.", 'cs': 'Popisujeme systém vyvinutý DFKI-TalkingRobots Team pro CODI-CRAC 2021 Shared-Task na řešení anafory v dialogu. Náš systém se skládá ze tří subsystémů: (1) systém Workspace Coreference System (WCS) inkrementálně shlukuje zmínky za použití sémantické podobnosti založené na vložení kombinované s lexikální heuristikou prvků; (2) systém řešení koreferencí mezi zmínkami (M2M) páruje stejnou entitu zmínku; (3) Diskurse Deixis Resolution (DDR) systém využívá siamskou síť k detekci párů anafory a předcházejících diskursů. WCS dosáhl F1 skóre 55,6% průměrného v hodnotících testovacích sadách, M2M dosáhl 57,2% a DDR 21,5%.', 'et': 'Kirjeldame DFKI-TalkingRobots Team poolt CODI-CRAC 2021 jagatud ülesande jaoks välja töötatud süsteemi anafoori lahendamiseks dialoogis. Meie süsteem koosneb kolmest alamsüsteemist: (1) tööruumi koreferensi süsteem (WCS) järjestikuselt klastrid märgivad semantilist sarnasust, mis põhineb manustamisel kombineeritud leksikaalsete omaduste heuristikal; (2) märkimisväärse kriisilahenduse süsteem (M2M) paarides sama üksuse mainib; (3) Diskursuse Deixis Resolution (DDR) süsteem kasutab diskursuse anafoori-eelnevate paaride tuvastamiseks Siiami võrgustikku. WCS saavutas F1-skoori 55,6%, M2M saavutas 57,2% ja DDR 21,5%.', 'fi': 'Kuvaamme DFKI-TalkingRobots -tiimin CODI-CRAC 2021 Shared-Task -ohjelmalle kehitt瓣m瓣瓣 j瓣rjestelm瓣瓣 anaforan ratkaisuun dialogissa. J瓣rjestelm瓣mme koostuu kolmesta osaj瓣rjestelm瓣st瓣: (1) Workspace Coreference System (WCS) ker瓣瓣 vaiheittain mainintoja k瓣ytt瓣en semanttista samankaltaisuutta, joka perustuu upotuksiin yhdistettyn瓣 leksikaaliseen ominaisuusheuristiikkaan; (2) Mainittu-maininnalle (M2M) -yhteisferenssikriisinratkaisuj瓣rjestelm瓣 parittaa saman yksik繹n maininnat; (3) Diskursse Deixis Resolution (DDR) -j瓣rjestelm瓣 k瓣ytt瓣瓣 siamilaista verkostoa diskurssianaforin ja edelt瓣vien parien havaitsemiseen. WCS saavutti F1-pisteen 55,6% kaikissa arviointitestisarjoissa, M2M saavutti 57,2% ja DDR 21,5%.', 'he': 'אנחנו מתארים את המערכת שפותחת על ידי צוות רובוטים מדברים DFKI עבור משימה משותפת CODI-CRAC 2021 על פתרון אנפורה בדיולוג. Our system consists of three subsystems: (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics;  (2) מערכת פתרון התאמה הזכרה-לזכרה (M2M) זוגות את אותה יחידה הזכרה; (3) מערכת פיתרון דיסקרס דיקסי (DDR) משתמשת ברשת סיאמית כדי לגלות זוגות anaphor-קודמות דיסקרס. WCS achieved F1-score of 55.6% averaged across the evaluation test sets, M2M achieved 57.2% and DDR achieved 21.5%.', 'sk': 'Opisujemo sistem, ki ga je razvila ekipa DFKI-TalkingRobots za skupno nalogo CODI-CRAC 2021 o reševanju anafore v dialogu. Naš sistem je sestavljen iz treh podsistemov: (1) sistem delovnega prostora Coreference System (WCS) postopoma združuje omembe z uporabo semantične podobnosti, ki temelji na vdelavah v kombinaciji z leksikalno funkcijsko heuristiko; (2) sistem reševanja jedrske reference z omenjanjem (M2M) je naveden v paru istega subjekta; (3) sistem Diskurze Deixis Resolution (DDR) uporablja siamsko mrežo za odkrivanje diskurznih anaforskih parov. WCS je dosegel rezultat F1 55,6% v povprečju med vrednotenjskimi preskusnimi sklopi, M2M 57,2% in DDR 21,5%.', 'jv': 'Awakdhéwé ngerwih sistem nggawe Daftar DFKi-TalkingJobot Group nggawe cordi-crit 2020 1 Joined-task nang resolusi anaphora neng dialog Sistem awak dhéwé mulai telu babaran.(1) Workspace corefensi System (2) Mention-to-Mention (M2M) corefection System Resolution (3) Sistem Diskurasi Dextir Resolusi (DDra) kang sistem sistem sistem gunakake Siamsi Network nggawe perintah kejahatan anaphor-antacedent. Where', 'ha': "Tuna bayyana na'urar da aka buɗe na DFKI-Talkin Robot Team wa the CODA-CRac 2021 Shared-Tafiyar da yin fassarar masu motsi cikin zauren akwatin bayani. Tsarinmu na ƙunsa da nau'i uku:(1) Shirin Ayuka na Shirin aiki (WSA) na ƙara ƙaranci da ake amfani da sunan-zane ta zama daidaici da kwamfyutan da aka haɗa da takardar heuristics; (2) Babbar-mazaɓa-zuwa-mazaɓa (M2M) sunayen sunayen ayuka na'ura masu nau'in abun ɗaya; (3) Cikakken Bayanci na Deikis (DDR) na amfani da Shiamese ɗin zai iya gano nau'in-biyu. WSA ya kai F1-score na 55.6% mai tsakanin kowace a matsayin evaluation, M2M ya kai 57.2% kuma DDR ya kai 21.5%.", 'bo': 'ང་ཚོས་མ་ལག་གི་དབྱིབས་DFKI-TalkingRobots Team་ལ་སྤྱོད་པའི་རྩིས་ཐོག་གླེང་སྒྲོམ་ནང་དུ་CODI-CRAC 2021 Shared-Task སྒྲིག་གཏོང་བ Our system consists of three subsystems: (1) the Workspace Coreference System (WCS) incrementally clusters mentions using semantic similarity based on embeddings combined with lexical feature heuristics; and (2) འདེམས་ཐོག་ལས་འདེམས་ཐོག་གནང་བའི་དབྱིབས་སྒྲིག་གི་མ་ལག་གི་མཐུན་གྲངས་ཀ་གཅིག་མཚུངས་ཡིན། (3) the Discourse Deixis Resolution (DDR) system employs a Siamese Network to detect discourse anaphor-antecedent pairs. WCS achieved F1-score of 55.6% averaged across the evaluation test sets, M2M achieved 57.2% and DDR achieved 21.5%.'}
{'en': 'The CODI-CRAC 2021 Shared Task on ', 'ar': 'المهمة المشتركة CODI-CRAC 2021 حول حل الجناس ، الجسور ، وخطاب Deixis في الحوار: تحليل مشترك بين الفريق', 'es': 'La tarea compartida del CODI-CRAC 2021 sobre la resolución de Deixis anáfora, puente y discurso en diálogo: un análisis entre equipos', 'fr': "La tâche partagée CODI-CRAC 2021 sur l'anaphore, le pontage et la résolution de Deixis du discours en dialogue\xa0: une analyse inter-équipes", 'pt': 'A Tarefa Compartilhada CODI-CRAC 2021 sobre Anáfora, Ponte e Resolução de Deixis Discurso em Diálogo: Uma Análise entre Equipes', 'zh': 'CODI-CRAC 2021对语之Anaphora,Bridging与DisponseDeixis议之共同任务:跨团队析', 'ja': '対話におけるアナフォラ、ブリッジング、およびディスコースデイキシスの解決に関するCODI - CRAC 2021共有タスク：クロスチーム分析', 'ru': 'Совместная задача CODI-CRAC 2021 по анафоре, наведению мостов и разрешению деиксиса дискурса в диалоге: межгрупповой анализ', 'ga': 'Tasc Comhroinnte CODI-CRAC 2021 ar Anaphora, Idirlinne, agus Rún Dioscúrsa Deixis san Idirphlé: Anailís Trasfhoirne', 'hi': 'CODI-CRAC 2021 संवाद में Anaphora, ब्रिजिंग, और प्रवचन Deixis संकल्प पर साझा कार्य: एक क्रॉस-टीम विश्लेषण', 'ka': 'CODI-CRAC 2021 წევრებული დავალება ანაფორა, ბრიზიგი და დიალოგში განსაზღვრება დეიკსის განსაზღვრება', 'hu': 'A CODI-CRAC 2021 közös feladat az anafóra, az áthidalás és a beszéd Deixis megoldásáról a párbeszédben: egy csapatközi elemzés', 'it': "Il compito condiviso CODI-CRAC 2021 su anafora, ponte e risoluzione del discorso Deixis nel dialogo: un'analisi trasversale", 'el': 'Η Κοινή Εργασία για την Ανάφορα, τη Γέφυρα και τη Διακριτική Επίλυση της Δεξιάς στο Διάλογο: Μια Διευρωπαϊκή Ανάλυση', 'ms': 'Comment', 'ml': 'ഡയലോഗിലെ കോഡിഇ- CRAC 2021 പങ്കാളിയായ ജോലി', 'kk': 'CODI- CRAC 2021 Анафора, Бридж және Диалогтың Диксис айырмашылығының ортақтастырылған тапсырмасы: Бірнеше топ анализациясы', 'mn': 'CODI-CRAC 2021 Anaphora, Bridging, and Discourse Deixis Resolution in Dialog: A Cross-Team Analysis', 'mk': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis', 'no': 'CODI-CRAC 2021 delt oppgåve om Anafora, bridging og diskurs av desikseoppløysing i dialogen: ein kryss-gruppeanalyse', 'pl': 'Wspólne zadanie CODI-CRAC 2021 dotyczące anafory, pomostowania i dyskursu w dialogu: analiza między zespołami', 'ro': 'Sarcina comună CODI-CRAC 2021 privind anafora, legătura și rezolvarea discursului Deixis în dialog: o analiză între echipe', 'sr': 'CODI-CRAC 2021. zajednički zadatak o Anafori, Bridging i diskusiji o rezoluciji Deixisa u dijalogu: Analiza prekršnog tima', 'si': 'CODI-CRAC 2021 අනාෆෝරා, බ්\u200dරිජින්ග්, හා සංවාදයේදී ඩික්සිස් විශේෂණ විශේෂණය ගැන සමාගත වැඩක්: ක්\u200dරොස් කණ්ඩාය', 'so': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialog: A Cross-Team Analysis', 'ta': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis', 'sv': 'CODI-CRAC 2021 delad uppgift om anafora, överbryggning och diskurslösning Deixis i dialog: En gruppövergripande analys', 'ur': 'CODI-CRAC 2021 انفاورا، بریجنگ اور ڈیکسس روشنی کے بارے میں مشترک ٹاکس: ایک کرس-ٹیم تحلیل', 'lt': 'CODI-CRAC 2021 bendra užduotis anaforos, ryšių ir diskurso problemų sprendimo klausimais dialoge: tarpgrupinė analizė', 'mt': 'Il-kompitu konġunt CODI-CRAC 2021 dwar ir-Riżoluzzjoni tad-Deissija dwar l-Anafora, l-Bridging u d-Diskussjoni fid-Djalogu: Analiżi bejn it-Timijiet', 'vi': 'Kế hoạch chia sẻ về Anaphora, Bridgit, và Discourse Deixis trong Phần thoại: A Cross-Team Analysis', 'uz': 'Name', 'bg': 'Споделена задача за анафора, свързване и дискурсна резолюция на деиксис в диалог: междуекипен анализ', 'hr': 'CODI-CRAC 2021. zajednički zadatak o Anafori, Bridging i diskusiji o rezoluciji Deixisa u dijalogu: Analiza prekršnog tima', 'nl': 'De CODI-CRAC 2021 Gedeelde Taak over Anafora, Overbruggen en Discours Deixis Resolutie in Dialoog: Een Cross-Team Analyse', 'da': 'CODI-CRAC 2021 delte opgave om anaphora, brobygning og diskurs Deixis løsning i dialog: En tværgående analyse', 'de': 'CODI-CRAC 2021 Gemeinsame Aufgabe zu Anaphora, Brückenbildung und Diskursendixis-Auflösung im Dialog: Eine teamübergreifende Analyse', 'ko': 'CODI-CRAC 2021 대화에서 반지름, 브리지와 언어 지시 해소의 공동 임무: 크로스 그룹 분석', 'fa': 'کاری مشترک CODI-CRAC 2021 در مورد انافورا، بریج\u200cگیری و گفتگو درباره\u200cی حل\u200cسازی Deixis در محاوره: یک تحلیل گروه\u200cهای متوسط', 'id': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis', 'sw': 'CODI-CRAC 2021 ilishiriki kazi ya Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: Analysis of Cross-Team', 'af': "Die Kodi-CRAC 2021 Gedeelde Opdrag op Anafora, Bridging en Ontvang Deixis Resolusie in Dialoog: ' n Kruis-Skep Analisie", 'sq': 'Detyra e përbashkët CODI-CRAC 2021 mbi anaforën, rrëzimin dhe diskutimin e zgjidhjes së deiksit në dialog: një analizë ndër-ekipe', 'am': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging and Discourse Deixis Resolution in Dialog: A Cross-Team Analysis', 'tr': 'CODI-CRAC 2021 Anaphora, Bridging, and Discourse Deixis Resolution in Dialog: A Cross-Team Analysis', 'hy': 'COD-Crac 2021-ի համագործակցած խնդիրը անաֆորայի, կամուրջների և քննարկման վերաբերյալ', 'az': 'CODI-CRAC 2021 Anafora, Bridging və Dixis Çözünürlüyü Dialogda paylaşılan iş', 'bn': 'ডায়ালগে কোডিও-CRAC ২০২১ শেয়ার করা কাজ আনাফোরা, ব্রাইডিং এবং ডিকোর্স ডেইক্সিস রিসুলেশন: একটি ক্রস-দল বিশ্লেষণ', 'bs': 'CODI-CRAC 2021. zajednički zadatak o Anafori, Bridging i diskusiji o rezoluciji Deixisa u dijalogu: Analiza prekršnog tima', 'ca': 'El CODI-CRAC 2021 Compartit Task on Anaphora, Bridging and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis', 'cs': 'CODI-CRAC 2021 Sdílený úkol o anaforě, přemostění a diskursní deixisové řešení v dialogu: analýza mezi týmy', 'et': 'CODI-CRAC 2021. aasta ühine ülesanne anafoori, sildumise ja diskursuse deixis resolutsiooni kohta dialoogis: rühmadevaheline analüüs', 'fi': 'CODI-CRAC 2021 Yhteinen tehtävä Anaforan, Silitysten ja Discursin Deixis Resolution dialogissa: Cross-Team Analysis', 'jv': 'The cordi-CIOC 2020 1 shared task on Anaphora, Bredging, and Diskure Dexts Resolution in Dialog: A', 'sk': 'CODI-CRAC 2021 Skupna naloga o anafori, povezovanju in reševanju deixis diskurza v dialogu: medskupinska analiza', 'ha': 'KCharselect unicode block name', 'he': 'המשימה המשותפת של CODI-CRAC 2021 על אנפורה, גשר, ויסקורס פיתרון דיקסי בדיולוג: ניתוח צוות צלב', 'bo': 'The CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis Resolution in Dialogue: A Cross-Team Analysis'}
{'en': 'The CODI-CRAC 2021 shared task is the first shared task that focuses exclusively on ', 'ar': 'المهمة المشتركة CODI-CRAC 2021 هي المهمة المشتركة الأولى التي تركز حصريًا على دقة الجاذبية في الحوار وتوفر ثلاثة مسارات ، وهي حل مرجع الكيان ، وقرار التجسير ، وقرار deixis الخطاب. نقوم بإجراء تحليل متعدد المهام للأنظمة التي شاركت في المهمة المشتركة في كل من هذه المسارات.', 'pt': 'A tarefa compartilhada CODI-CRAC 2021 é a primeira tarefa compartilhada que se concentra exclusivamente na resolução da anáfora no diálogo e fornece três faixas, ou seja, resolução de correferência de entidade, resolução de ponte e resolução de deixis de discurso. Realizamos uma análise cross-task dos sistemas que participaram da tarefa compartilhada em cada uma dessas faixas.', 'ja': 'CODI - CRAC 2021共有タスクは、対話におけるアナフォラ解決のみに焦点を当てた最初の共有タスクであり、エンティティコアリファレンス解決、橋渡し解決、および対話deixis解決の3つのトラックを提供します。これらの各トラックの共有タスクに参加したシステムのクロスタスク分析を行います。', 'zh': 'CODI-CRAC 2021共享者,先anaphora解决方案共之,三道者,实体共谋解决方案,桥接解决方案语deixis解决方案。 我们对每个轨道中的共享的职务。', 'es': 'La tarea compartida del CODI-CRAC 2021 es la primera tarea compartida que se centra exclusivamente en la resolución de anáforas en el diálogo y proporciona tres vías, a saber, la resolución de correferencia de la entidad, la resolución de puentes y la resolución de deixis del discurso. Realizamos un análisis de tareas cruzadas de los sistemas que participaron en la tarea compartida en cada una de estas pistas.', 'fr': "La tâche partagée CODI-CRAC 2021 est la première tâche partagée qui se concentre exclusivement sur la résolution des anaphores dans le dialogue et fournit trois pistes, à savoir la résolution de coréférence d'entité, la résolution de pontage et la résolution de deixis du discours. Nous effectuons une analyse multitâche des systèmes qui ont participé à la tâche partagée dans chacune de ces pistes.", 'ru': 'Совместная задача CODI-CRAC 2021 - это первая совместная задача, которая фокусируется исключительно на разрешении анафоры в диалоге и обеспечивает три направления, а именно разрешение ядра сущности, разрешение моста и разрешение deixis дискурса. Мы выполняем кросс-задачный анализ систем, которые участвовали в общей задаче по каждому из этих треков.', 'hi': 'CODI-CRAC 2021 साझा कार्य पहला साझा कार्य है जो विशेष रूप से संवाद में एनाफोरा रिज़ॉल्यूशन पर केंद्रित है और तीन ट्रैक प्रदान करता है, अर्थात् एंटिटी कोरेफेरेंस रिज़ॉल्यूशन, ब्रिजिंग रिज़ॉल्यूशन और प्रवचन deixis रिज़ॉल्यूशन। हम इन पटरियों में से प्रत्येक में साझा कार्य में भाग लेने वाले सिस्टम का एक क्रॉस-टास्क विश्लेषण करते हैं।', 'ga': 'Is é tasc comhroinnte CODI-CRAC 2021 an chéad tasc comhroinnte a dhíríonn go heisiach ar réiteach anafóra san idirphlé agus a sholáthraíonn trí rian, eadhon réiteach croíchomhdhála eintitis, réiteach idirlinne, agus réiteach dioscúrsa deixis. Déanaimid anailís tras-tascanna ar na córais a ghlac páirt sa tasc roinnte i ngach ceann de na rianta seo.', 'ka': 'CODI-CRAC 2021 გაყოფილი დავალება არის პირველი გაყოფილი დავალება, რომელიც დიალოგიში ანაფორის რეჟოლუციაზე მხოლოდ კონუკურებულია და სამი სინაცემები, ანაფორის რესოლუციაზე, ანაფორის რესოლუციაზე, ანაფ ჩვენ გავაკეთებთ სისტემების კონფიგური ანალიზი, რომელიც გავაკეთებთ ყველა ამ მონაცემებში.', 'hu': 'A CODI-CRAC 2021 közös feladat az első olyan közös feladat, amely kizárólag az anafóra feloldására összpontosít a párbeszédben, és három pályát biztosít: entitáskoreferencia feloldás, áthidaló feloldás és diskurzus deixis feloldás. Mindegyik pályán keresztfeladat elemzést végzünk azokról a rendszerekről, amelyek részt vettek a megosztott feladatban.', 'it': "Il compito condiviso CODI-CRAC 2021 è il primo compito condiviso che si concentra esclusivamente sulla risoluzione dell'anafora nel dialogo e fornisce tre tracce, vale a dire la risoluzione della coreferenza dell'entità, la risoluzione di ponte e la risoluzione della deixis del discorso. Eseguiamo un'analisi cross-task dei sistemi che hanno partecipato all'attività condivisa in ciascuna di queste tracce.", 'lt': 'CODI-CRAC 2021 bendra užduotis yra pirmoji bendra užduotis, kurioje dialoge daugiausia dėmesio skiriama išimtinai anaforos pertvarkymui ir kurioje pateikiami trys keliai, būtent subjekto koreferencijos pertvarkymas, tarpinis pertvarkymas ir diskurso deiksijos pertvarkymas. Atliekame kompleksinę sistemų, kurios dalyvavo bendroje užduotyje kiekviename iš šių kelių, analizę.', 'el': 'Η κοινή εργασία είναι η πρώτη κοινή εργασία που επικεντρώνεται αποκλειστικά στην ανάλυση αναφορών στο διάλογο και παρέχει τρεις διαδρομές, δηλαδή την επίλυση της συναπόφασης οντοτήτων, την επίλυση γεφυρώματος και την επίλυση της δήξης του λόγου. Πραγματοποιούμε μια ανάλυση των συστημάτων που συμμετείχαν στην κοινή εργασία σε κάθε ένα από αυτά τα κομμάτια.', 'kk': 'CODI-CRAC 2021 ортақ тапсырмасы - диалогта anafora айырымдылығына ғана аударып, үш жолды, бұл бөлінген тапсырма, бөлінген айырымдылығы және дексис айырымдылығын түсіндіріп, бөлінген бірінші ортақ тапсырмас Біз бұл жолдарда ортақ тапсырманың жүйелердің бірнеше тапсырмаларын анализ істейміз.', 'mt': 'The CODI-CRAC 2021 shared task is the first shared task that focuses exclusively on anaphora resolution in dialogue and provides three tracks, namely entity coreference resolution, bridging resolution, and discourse deixis resolution.  Għandna nagħmlu analiżi trasversali tas-sistemi li pparteċipaw fil-kompitu kondiviż f’kull waħda minn dawn il-binarji.', 'ml': 'CODI-CRAC 2021 പങ്കാളിയുള്ള ജോലിയാണ് ആദ്യത്തെ പങ്കാളിയുള്ള പ്രവര്\u200dത്തിയാകുന്നത്. സംസാരിക്കുന്നതിനെ സംബന്ധിച്ച് മൂന്നു ട്രാക്കുകള്\u200d ശ്രദ്ധിച ഈ ട്രാക്കുകളില്\u200d പങ്കെടുത്ത ജോലിയില്\u200d പങ്കുചേര്\u200dന്ന സിസ്റ്റത്തിന്റെ ക്രിസ്റ്റ് ജോലി അന്വേഷണം നമ്', 'mn': 'CODI-CRAC 2021-ийн хуваалцагдсан ажил бол анхны хуваалцагдсан ажил, диалогт анафора шийдвэрлэлт дээр анхаарлаа хандуулж, гурван шугам хандуулдаг, тэгэхээр entity-ын зөвшөөрөл шийдвэрлэлт, шийдвэрлэлт, хэлбэрийн шийдвэрлэлт. Бид эдгээр загвар бүрт хуваалцах ажил дээр оролцсон системийн олон ажлын шинжилгээг хийдэг.', 'no': 'Det delte oppgåva CODI-CRAC 2021 er den første delte oppgåva som fokuserer eksklusivt på anaforoppløysing i dialogvindauget og tilbyr tre spor, som er oppløysing av entitetskorferanse, oppløysing av brøk og diskurs av deikseoppløysing. Vi utfører ei kryss-oppgåve analyse av systema som delta i delt oppgåve i kvar av desse spora.', 'pl': 'Wspólne zadanie CODI-CRAC 2021 jest pierwszym wspólnym zadaniem, które koncentruje się wyłącznie na rozwiązywaniu anafory w dialogu i zapewnia trzy ścieżki, a mianowicie rozwiązywanie współdziałalności jednostek, rozwiązanie pomostowe i rozwiązanie deixis dyskursu. W każdym z tych ścieżek przeprowadzamy analizę cross-tasking systemów, które uczestniczyły w wspólnym zadaniu.', 'ro': 'Sarcina comună CODI-CRAC 2021 este prima sarcină comună care se concentrează exclusiv pe rezoluția anaforei în dialog și oferă trei piste, și anume rezoluția corefenței entităților, rezoluția de punte și rezoluția deixisului discursului. Efectuăm o analiză cross-task a sistemelor care au participat la sarcina partajată în fiecare dintre aceste piese.', 'sr': 'CODI-CRAC 2021. zajednièki zadatak je prvi zajednièki zadatak koji se fokusira exclusivno na rezoluciju anafore u dijalogu i pruža tri traga, a to je rezolucija pristojnosti entiteta, rezolucija bridžanja i diskursija o rezoluciji deiksa. Izvodimo prekršnu analizu sistema koji su sudjelovali u zajedničkom zadatku u svakom od ovih tragova.', 'so': "CODI-CRAC 2021 waa shaqada ugu horeeyay oo kaliya ku cusbooneysa heshiiska sawirada dialogue, wuxuuna bixiyaa saddex waddooyin, taas oo ah xafiiska kooxaha, saxda bridge, iyo go'aanka deixis. Anagaa sameynaya baaritaanka shaqada ee nidaamka ka qayb galay shaqada qayb-qayb ah oo kooban wadooyinkaas.", 'si': 'CODI-CRAC අපි මේ පද්ධතියේ සාමාන්\u200dය විශ්ලේෂණයක් කරනවා මේ පද්ධතියේ සාමාන්\u200dය වැඩක් විස්තර කරන්න.', 'sv': 'Den delade uppgiften CODI-CRAC 2021 är den första delade uppgiften som fokuserar uteslutande på anaforalösning i dialog och ger tre spår, nämligen entitetscoreference resolution, överbryggande resolution och diskursdeixis resolution. Vi utför en tväruppgiftsanalys av de system som deltog i den delade uppgiften i vart och ett av dessa spår.', 'ta': 'CODI- CRAC 2021 பகிர்ந்த பணி ஒவ்வொரு தடங்களிலும் பங்கிடப்பட்ட பணியில் பங்கிடப்பட்டு', 'mk': 'The CODI-CRAC 2021 shared task is the first shared task that focuses exclusively on anaphora resolution in dialogue and provides three tracks, namely entity coreference resolution, bridging resolution, and discourse deixis resolution.  Ние спроведуваме крстозадачна анализа на системите кои учествуваа во заедничката задача на секоја од овие траги.', 'ms': 'Tugas terkongsi CODI-CRAC 2021 adalah tugas terkongsi pertama yang fokus eksklusif pada resolusi anafora dalam dialog dan menyediakan tiga trek, iaitu resolusi koreferensi entiti, resolusi jembatan, dan resolusi deiksi diskors. Kami melakukan analisis tugas salib sistem yang berpartisipasi dalam tugas berkongsi dalam setiap trek ini.', 'ur': 'CODI-CRAC 2021 مشترک کام پہلی مشترک کام ہے جو صرف انفورا ریزیولو پر تمرکز کرتا ہے اور تین ٹریک پیدا کرتا ہے، یعنی انٹیٹی رفیق ریزیولو، براڈینگ ریزیولو، اور ڈیکسس ریزیولو کی بات کرتا ہے. ہم ان سیسٹموں کی ایک کرس ٹائس تحلیل کرتے ہیں جو ہر ٹائک میں مشترک کام میں شریک ہوتے ہیں۔', 'uz': "CODI-CRAC 2021 boĘ»lishilgan vazifa - muloqat oynasida faqat anaphora resolution bilan birinchi birinchi boĘ»lishilgan vazifa va uchta yoĘ»l, bu bogĘ»liq oĘ»lchami, murojaat oĘ»lchami, va suhbat deksis oĘ»lchami. Biz har bir necha yo'nalishga ega vazifani o'rganish tizimlarni bajaramiz.", 'vi': 'Kế hoạch chia sẻ của CODI-CRAC 2021 là nhiệm vụ chia sẻ đầu tiên chỉ tập trung vào giải pháp Anaphora trong cuộc đối thoại và cung cấp ba dấu vết, là thực thể hay hạn giải quyết, giải quyết kết nối, và giải quyết từ giới hạn. Chúng tôi thực hiện một cuộc phân tích chéo các hệ thống đã tham gia vào các nhiệm vụ chia sẻ trong mỗi đường ray này.', 'bg': 'Споделената задача е първата споделена задача, която се фокусира изключително върху решаването на анафората в диалог и предоставя три песни, а именно решаване на корпоративната референция на субектите, мостовата резолюция и дискурсната резолюция. Извършваме кръстосан анализ на системите, участвали в споделената задача във всяка от тези писти.', 'da': 'CODI-CRAC 2021 delte opgave er den første delte opgave, der udelukkende fokuserer på anaphora opløsning i dialog og giver tre spor, nemlig entity coreference opløsning, broløsning og diskurs deixis opløsning. Vi udfører en cross-task analyse af de systemer, der deltog i den delte opgave i hvert af disse spor.', 'nl': 'De CODI-CRAC 2021 gedeelde taak is de eerste gedeelde taak die zich uitsluitend richt op anafora resolutie in dialoog en biedt drie sporen, namelijk entiteitscoreference resolutie, bridging resolution en discours deixis resolutie. We voeren een cross-task analyse uit van de systemen die hebben deelgenomen aan de gedeelde taak in elk van deze tracks.', 'hr': 'Podijeljeni zadatak CODI-CRAC 2021 je prvi zajednički zadatak koji se usredotoči samo na rezoluciju anafore u dijalogu i pruža tri traga, a to je rezolucija pristojnosti subjekta, rezolucija prekidanja i rezolucija deksije diskursa. Izvodimo prekršnu analizu sustava koji su sudjelovali u zajedničkom zadatku u svakom od ovih tragova.', 'de': 'Die gemeinsame Aufgabe CODI-CRAC 2021 ist die erste gemeinsame Aufgabe, die sich ausschließlich auf Anaphora-Auflösung im Dialog konzentriert und drei Spuren bereitstellt, nämlich Entity Coreference Resolution, Bridging Resolution und Diskurs Deixis Resolution. Wir führen eine aufgabenübergreifende Analyse der Systeme durch, die an der gemeinsamen Aufgabe in jedem dieser Tracks teilgenommen haben.', 'id': 'Tugas terbagi CODI-CRAC 2021 adalah tugas terbagi pertama yang fokus eksklusif pada resolusi anafora dalam dialog dan menyediakan tiga trek, yaitu resolusi koreferensi entitas, resolusi jembatan, dan resolusi deiksi diskors. Kami melakukan analisis tugas salib dari sistem yang berpartisipasi dalam tugas bersama dalam setiap jejak ini.', 'ko': 'CODI-CRAC 2021 공유 임무는 대화에서 회지해소를 전문적으로 주목하는 첫 번째 공유 임무로 실체 공지해소, 교접해소와 언어지시해소 등 세 가지 경로를 제공했다.우리는 모든 궤도에서 공유 임무에 참여하는 시스템에 대해 크로스 임무 분석을 한다.', 'fa': 'وظیفه مشترک CODI-CRAC 2021 اولین وظیفه مشترک است که تنها روی حل\u200cسازی آنفورا در محاوره تمرکز می\u200cکند و سه رد را می\u200cدهد، یعنی حل\u200cسازی رضایت\u200cسازی، حل\u200cسازی\u200cسازی\u200cسازی و حل\u200cسازی\u200cسازی\u200cسازی ما یک تحلیل متفاوتی از سیستم\u200cها را انجام می\u200cدهیم که در کار مشترک در هر یک از این ردها شرکت می\u200cکنند.', 'tr': 'CODI-CRAC 2021 b철l체nen i힊i, dijalogda anafora 챌철z체mleme di흫e fokus eden ilkinji b철l체nen i힊dir we 체챌 챌철z체mler t채sir ed첵채r, yani tek ta첵첵arlar 챌철z체mleme, 챌철z체mleme we deixis 챌철z체mleme g체rr체흫de첵채r Biz bu 첵olary흫 her tarapynda payla힊yk g철revidi흫 sistemalaryny흫 birn채챌e i힊i 챌ykaryp bar첵arys.', 'sw': 'Kazi ya kushirikiana na CODI-CRAC 2021 ni jukumu la kwanza la kushirikiana ambalo linalenga pekee kwenye suluhisho la simu katika mazungumzo na kutoa njia tatu, yaani suluhisho la msingi, suluhisho la daraja, na suluhisho la mazungumzo. Tunafanya uchambuzi wa mifumo inayoshiriki kazi hiyo katika kila njia hii.', 'af': "Die CODI-CRAC 2021 gedeelde taak is die eerste gedeelde taak wat eksklusief fokus op anafora-oplossing in dialoog en verskaf drie snitte, bedoel entiteite koreferensie-oplossing, bruiding-oplossing en diskursie deixis-oplossing. Ons doen 'n kruistaak analiseer van die stelsels wat in die gedeelde taak in elke van hierdie snitte gedeel het.", 'sq': 'Detyra e përbashkët e CODI-CRAC 2021 është detyra e parë e përbashkët e cila përqëndrohet ekskluzivisht në zgjidhjen e anaforës në dialog dhe ofron tre gjurmë, veçanërisht zgjidhjen e bashkëdrejtimit të njësisë, zgjidhjen e urës dhe zgjidhjen e deiksit diskursor. Ne kryejmë një analizë ndërdetyrash të sistemeve që morën pjesë në detyrën e përbashkët në secilin nga këto gjurmë.', 'hy': 'COD-Crac 2021-ի ընդհանուր խնդիրն առաջին ընդհանուր խնդիրն է, որը կենտրոնանում է միայն անաֆորային լուծումների վրա երկխոսում և առաջարկում է երեք ճանապարհ, հատկապես առանձնահատուկ լուծումների, կամուրջների լուծումների և քննադատական դիաքսի լու Մենք կատարում ենք համակարգերի, որոնք մասնակցել են այս ամենի ընդհանուր խնդիրներին, խաչընդհանուր վերլուծությունը:', 'am': 'የCODI-CRAC 2021 የተካፈለ ስራ የፊደኛው ክፍል ነው፤ በጥያቄ አካባቢ ውጤት ላይ በጥያቄ እና በጥያቄ ላይ የተማመነ እና ሦስት መንገዶች፣ አካባቢው የኮርፌንስ ውጤት፣ ቅድሚያ ውጤት እና ንግግር ዴክስ ፍትሕት ነው፡፡ በሁሉም መንገዶች ላይ በተካፈሉት ስርዓቶች ላይ የስርዓቶችን መተርጓሚን እናደርጋለን፡፡', 'az': 'CODI-CRAC 2021 paylaşılmış iş ilk paylaşılmış işdir ki, diyalədəki anafora çözünürlüyünü təkcə odaqlayır və üç parça təklif edir, yani entitə mərhəmət çözünürlüyü, bridging çözünürlüyü və deixis çözünürlüyünü danışır. Biz bu yolların hər birində paylaşılan işlərdə iştirak edən sistemlərin çox asanlıqlarını çəkirik.', 'bs': 'CODI-CRAC 2021. zajednički zadatak je prvi zajednički zadatak koji se fokusira samo na rezoluciju anafore u dijalogu i pruža tri traga, a to je rezolucija pristojnosti entitata, rezolucija prekidanja i diskusija o rezoluciji deiksa. Izvodimo prekršnu analizu sustava koji su sudjelovali u zajedničkom zadatku u svakom od ovih tragova.', 'bn': 'CODI-CRAC ২০২১ শেয়ার করা কাজ হচ্ছে প্রথম শেয়ার কর্মসূচি যারা ডায়ালগে বিশেষভাবে নিজেদের নিজেদের দৃষ্টিভঙ্গি করে এবং তিনটি ট্র্যাক দিয়েছে, যার মধ্য আমরা এই প্রত্যেক ট্র্যাকে অংশ নিয়েছিলাম যে সমস্ত সিস্টেমের ব্যাপারে অংশ নিয়েছিল তার বিশ্লেষণ করি।', 'ca': "La tasca compartida CODI-CRAC 2021 és la primera tasca compartida que s'enfoca exclusivament en la resolució de l'anàfora en el diàleg i proporciona tres pistes, a saber, la resolució de la coreferença de l'entitat, la resolució de pont i la resolució del deixis del discurs. We perform a cross-task analysis of the systems that participated in the shared task in each of these tracks.", 'cs': 'Sdílený úkol CODI-CRAC 2021 je první sdílený úkol, který se zaměřuje výhradně na anaforické řešení v dialogu a poskytuje tři stopy, konkrétně řešení společnosti entity, přemostění řešení a diskurzní deixis řešení. V každé z těchto tratí provádíme cross-task analýzu systémů, které se podílely na sdíleném úkolu.', 'et': 'CODI-CRAC 2021 jagatud ülesanne on esimene jagatud ülesanne, mis keskendub ainult anafoori lahendamisele dialoogis ja pakub kolme rada, nimelt üksuse ühise resolutsiooni lahendamine, sillalahendus ja diskursuse deiksise lahendamine. Teostame ülesannetevahelise analüüsi süsteemidest, mis osalesid ühises ülesandes igal rajal.', 'fi': 'CODI-CRAC 2021 yhteinen tehtävä on ensimmäinen jaettu tehtävä, joka keskittyy yksinomaan anaforan ratkaisuun dialogissa ja tarjoaa kolme raitaa, eli entiteetin yhteispäätösratkaisun, sillanratkaisun ja diskurssideiksisen ratkaisun. Suoritamme ristikkäisen analyysin järjestelmistä, jotka osallistuivat jaettuun tehtävään kussakin näistä kappaleista.', 'jv': 'The cordi-criterion 2020 1 Awak dhéwé ngerti cara-task karo sistem sing nyelaraké ning gagal gawe ngulinakake karo nganggo track iki', 'sk': 'Skupna naloga CODI-CRAC 2021 je prva skupna naloga, ki se osredotoča izključno na reševanje anafore v dialogu in zagotavlja tri smeri, in sicer reševanje koreference entitete, premostitveno reševanje in diskurzno deiksiso reševanje. Izvajamo mednalogo analize sistemov, ki so sodelovali pri deljeni nalogi na vsaki od teh skladb.', 'ha': 'QUnicodeControlCharacterMenu We perform a cross-task analysis of the systems that participated in the shared task in each of these tracks.', 'bo': 'The CODI-CRAC 2021 shared task is the first shared task that focuses exclusively on anaphora resolution in dialog and provides three tracks, namely entity coreference resolution, bridging resolution, and discourse deixis resolution. ང་ཚོས་རྣམས་གླེང་རྡེབ་འདི་རེ་རེའི་ནང་དུ་དབྱེ་སྤྱོད་མིའི་ལས་འགུལ་ལྡན་ཞིབ་བྱས་པ་ཡིན།', 'he': 'המשימה המשותפת של CODI-CRAC 2021 היא המשימה הראשונה המשותפת שמתמקדת בלעדית על פיתרון אנפורה בדיאלוג ומספקת שלושה עקבות, כלומר פיתרון תואמת היחידות, פיתרון גשר, ופתרון דיקסי דיסקרס. אנחנו מבצעים ניתוח משימה צלב של המערכות שהשתתפו במשימה המשותפת בכל מסלול אלה.'}
