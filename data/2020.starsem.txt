{'en': 'Semantic Structural Decomposition for Neural Machine Translation', 'ar': 'التحلل الهيكلي الدلالي لترجمة الآلة العصبية', 'fr': 'Décomposition structurale sémantique pour la traduction automatique neuronale', 'es': 'Descomposición estructural semántica para la traducción automática neuronal', 'pt': 'Decomposição Estrutural Semântica para Tradução Automática Neural', 'ja': '神経機械翻訳のための意味論的構造分解', 'hi': 'तंत्रिका मशीन अनुवाद के लिए शब्दार्थ संरचनात्मक अपघटन', 'ru': 'Семантическое структурное разложение для нейронного машинного перевода', 'zh': '用于神经机器翻译者语义结构分解', 'ga': 'Dianscaoileadh Séimeantach Struchtúrtha le haghaidh Aistriúchán Meaisín Néarach', 'ka': 'Name', 'hu': 'Szemantikus strukturális bontás a neurális gépi fordításhoz', 'el': 'Σημαντική δομική αποσύνθεση για τη νευρωνική μηχανική μετάφραση', 'it': 'Decomposizione strutturale semantica per la traduzione automatica neurale', 'lt': 'Semantinis struktūrinis sklaidos sklaida, skirta neurologiniam mašinų vertimui', 'kk': 'Нейрондық машинаның аудармасының семантикалық структуралық декомпозициясы', 'mk': 'Семантичка структурна декомпозиција за превод на неврални машини', 'ms': 'Semantic Structural Decomposition for Neural Machine Translation', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷക്കുള്ള സെമാന്റിക് സ്ട്രാക്ട്രോക്ടറില്\u200d ഡെക്കോമ്പോസ്റ്റ്', 'mt': 'Dekompożizzjoni Strutturali Semantika għat-Traduzzjoni tal-Magna Newrali', 'mn': 'Цөмийн машины хөгжлийн Semantic Structureural Decomposition for Neural Machine Translation', 'no': 'Name', 'pl': 'Semantyczny rozkład strukturalny dla neuronowego tłumaczenia maszynowego', 'ro': 'Decompoziție structurală semantică pentru traducerea automată neurală', 'sr': 'Semantička strukturalna dekompozicija za neurološki prevod mašine', 'si': 'සෙමැන්ටික් සංවිධානය සංවිධානය නිර්මාණය සඳහා', 'so': 'Semantic structural Decomposition for Neural machine Translation', 'sv': 'Semantisk strukturell nedbrytning för neural maskinöversättning', 'ta': 'புதிய இயந்திரம் மொழிபெயர்ப்புக்கான செமான்டிக் கட்டுப்பாட்டு குறைப்பு', 'ur': 'نیورال ماشین ترجمہ کے لئے سیمنٹی ساخترال ناکامپوسٹ', 'uz': 'Name', 'vi': 'Phân chia thành phần mềm cho máy móc thần kinh', 'bg': 'Семантично структурно разлагане за неврален машинен превод', 'da': 'Semantisk strukturel nedbrydning til neural maskinoversættelse', 'nl': 'Semantische structurele decompositie voor neurale machinevertaling', 'hr': 'Semantička strukturna dekompozicija za neuronski prevod strojeva', 'de': 'Semantische strukturelle Dekomposition für neuronale maschinelle Übersetzung', 'id': 'Semantic Structural Decomposition for Neural Machine Translation', 'ko': '신경 기계 번역 중의 의미 구조 분해', 'sw': 'Udhibiti wa Miundombinu kwa Tafsiri ya Mashine ya Nguvu', 'tr': 'Neural Maşynyň terjimesine görkezilen çykyş', 'af': 'Name', 'fa': 'تعادل ساختار ساختاری سیماتیک برای ترجمه ماشین عصبی', 'am': 'position for neural machine translation', 'hy': 'Semantic Structural Decomposition for Neural Machine Translation', 'az': 'Nöral Makin Çeviri üçün Semantik Struktural Dekompozisyon', 'bs': 'Semantička strukturna dekompozicija za neuronski prevod mašine', 'bn': 'নিউরাল মেশিন অনুবাদের জন্য সেম্যান্টিক ক্ষেত্রের ডিমোম্পোস্ট', 'cs': 'Sémantická strukturní dekompozice pro neuronový strojový překlad', 'et': 'Semantiline struktuuriline lagunemine neuroaalse masintõlke jaoks', 'fi': 'Semanttinen rakenteellinen hajoaminen hermojen konekääntämiseen', 'sq': 'Dekompozicioni strukturor Semantik për Translation Neural Machine', 'ca': 'Semantic Structural Decomposition for Neural Machine Translation', 'jv': 'Ngucap Samantar', 'ha': 'position for translation', 'sk': 'Semantna strukturna razgradnja za strojno prevajanje nevronov', 'bo': 'སྤྱིར་བཏང་བའི་དབྱིབས་རྩིས་གཞུང་གི་མཐའ་འཁོར་བརྗོད་ཀྱི་', 'he': 'התפרצות מבנה סמנטית לתרגום מכונות נוירות'}
{'en': 'Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5 M sentence pairs, while retaining comparable adequacy. We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.', 'fr': "En nous appuyant sur les récents progrès en matière d'analyse sémantique et de simplification de texte, nous étudions l'utilisation de la division sémantique de la phrase source comme prétraitement pour la traduction automatique. Nous expérimentons un modèle Transformer et l'évaluons à l'aide d'expériences de crowdsourcing à grande échelle. Les résultats montrent une augmentation significative de la fluidité des phrases longues dans un contexte anglo-français avec un corpus d'entraînement de 5 millions de paires de phrases, tout en conservant une adéquation comparable. Nous effectuons également une analyse manuelle qui explore le compromis entre adéquation et fluidité dans le cas où toutes les longueurs de phrase sont prises en compte.", 'ar': 'بناءً على التطورات الحديثة في التحليل الدلالي وتبسيط النص ، فإننا نتحرى عن استخدام التقسيم الدلالي للجملة المصدر كتجهيز مسبق للترجمة الآلية. نقوم بتجربة نموذج Transformer وتقييمه باستخدام تجارب التعهيد الجماعي واسعة النطاق. تظهر النتائج زيادة ملحوظة في الطلاقة في الجمل الطويلة في بيئة من الإنجليزية إلى الفرنسية مع مجموعة تدريب مكونة من 5 ملايين أزواج من الجمل ، مع الحفاظ على كفاية مماثلة. نقوم أيضًا بإجراء تحليل يدوي يستكشف المفاضلة بين الكفاية والطلاقة في الحالة التي يتم فيها أخذ جميع أطوال الجملة في الاعتبار.', 'pt': 'Com base nos avanços recentes na análise semântica e simplificação de texto, investigamos o uso da divisão semântica da frase fonte como pré-processamento para tradução automática. Experimentamos um modelo Transformer e avaliamos usando experimentos de crowdsourcing em larga escala. Os resultados mostram um aumento significativo na fluência em frases longas em um ambiente de inglês para francês com um corpus de treinamento de 5 milhões de pares de frases, mantendo uma adequação comparável. Também realizamos uma análise manual que explora o tradeoff entre adequação e fluência no caso em que todos os comprimentos das frases são considerados.', 'es': 'Sobre la base de los avances recientes en el análisis semántico y la simplificación del texto, investigamos el uso de la división semántica de la oración fuente como preprocesamiento para la traducción automática. Experimentamos con un modelo Transformer y evaluamos mediante experimentos de crowdsourcing a gran escala. Los resultados muestran un aumento significativo de la fluidez en frases largas en un entorno de inglés a francés con un corpus de entrenamiento de 5 millones de pares de oraciones, manteniendo una adecuación comparable. También realizamos un análisis manual que explora el equilibrio entre la adecuación y la fluidez en el caso de que se tengan en cuenta todas las longitudes de oración.', 'ja': 'セマンティック構文解析とテキスト簡略化の最近の進歩に基づいて、機械翻訳の前処理としてのソース文のセマンティック分割の使用を調査します。トランスフォーマーモデルを実験し、大規模なクラウドソーシング実験を使用して評価します。結果は、同等の妥当性を維持しながら、5 Mの文章ペアのトレーニングコーパスを持つ英語からフランス語の設定で、長文の流暢性が大幅に向上したことを示しています。また、すべての文の長さを考慮した場合の妥当性と流暢性のトレードオフを探る手動分析も行います。', 'zh': '盖语义解析文简化之最新进展,研用源句之语义,分为机器翻译预处理。 Transformer以实验,大众包实验以质。 结果显示在英语法语中,长句流利,教语料库为5M句,兼保比充分性。 执手动析之,穷思句端,充分性流畅性之权衡。', 'hi': 'शब्दार्थ पार्सिंग और पाठ सरलीकरण में हाल की प्रगति पर निर्माण, हम मशीन अनुवाद के लिए preprocessing के रूप में स्रोत वाक्य के शब्दार्थ विभाजन के उपयोग की जांच करते हैं। हम एक ट्रांसफॉर्मर मॉडल के साथ प्रयोग करते हैं और बड़े पैमाने पर भीड़-सोर्सिंग प्रयोगों का उपयोग करके मूल्यांकन करते हैं। परिणाम 5M वाक्य जोड़े के प्रशिक्षण कॉर्पस के साथ एक अंग्रेजी-से-फ्रांसीसी सेटिंग पर लंबे वाक्यों पर प्रवाह में महत्वपूर्ण वृद्धि दिखाते हैं, जबकि तुलनीय पर्याप्तता को बनाए रखते हैं। हम एक मैनुअल विश्लेषण भी करते हैं जो उस मामले में पर्याप्तता और प्रवाह के बीच ट्रेडऑफ की पड़ताल करता है जहां सभी वाक्य लंबाई पर विचार किया जाता है।', 'ru': 'Основываясь на последних достижениях в семантическом разборе и упрощении текста, мы исследуем использование семантического разделения исходного предложения в качестве предварительной обработки для машинного перевода. Экспериментируем с трансформаторной моделью и оцениваем с помощью крупномасштабных краудсорсинговых экспериментов. Результаты показывают значительное увеличение беглости в длинных предложениях в англо-французской среде с обучающим корпусом из 5 пар предложений при сохранении сопоставимой адекватности. Мы также проводим ручной анализ, который исследует компромисс между адекватностью и беглостью в случае, когда учитываются все длины предложений.', 'ga': 'Ag tógáil ar an dul chun cinn a rinneadh le déanaí i bparsáil shéimeantach agus i simpliú téacs, déanaimid imscrúdú ar úsáid scoilteadh shéimeantach na habairte foinse mar réamhphróiseáil d’aistriúchán meaisín. Déanaimid turgnamh le samhail Trasfhoirmeoir agus déanaimid meastóireacht ag baint úsáide as turgnaimh slua-fhoinsithe ar scála mór. Léiríonn torthaí méadú suntasach ar líofacht ar abairtí fada ar shuíomh Béarla-go-Fraincis le corpas oiliúna de phéirí abairtí 5M, agus leordhóthanacht inchomparáide á choinneáil ag an am céanna. Déanaimid anailís láimhe freisin a dhéanann iniúchadh ar an gcomhbhabhtáil idir leordhóthanacht agus líofacht sa chás go ndéantar gach abairt a mheas.', 'hu': 'A szemantikai elemzés és a szövegegyszerűsítés legutóbbi előrehaladásaira építve vizsgáljuk a forráskód szemantikai felosztásának használatát a gépi fordítás előfeldolgozásaként. Kísérletezünk egy Transformer modellel, és nagyszabású közösségi források kísérletekkel értékeljük. Az eredmények azt mutatják, hogy a hosszú mondatok folyékonyságának jelentős növekedése angol-francia nyelvű környezetben 5 millió mondatpárból álló képzéssel, miközben hasonló megfelelőséget biztosítanak. Kézi elemzést is végezünk, amely feltárja a megfelelőség és a folyékonyság közötti megkülönböztetést abban az esetben, amikor az összes mondathosszt figyelembe vesszük.', 'ka': 'სემონტიკური პარასტის და ტექსტის განსხვავებაზე, ჩვენ განსხვავებთ სემონტიკური პარასტის გამოყენების გამოყენების გამოყენება, როგორც მაქსინის განსხვავლებისთვის პრეპროცესი. ჩვენ რენსპერიმენტებერის მოდელზე ექსპერიმენტებით გავაკეთებთ და გამოყენებთ დიდი მანძილური crowd-sourcing ექსპერიმენტებით. შედეგი გამოჩვენება მარტივი ფრანგულისთვის განმავლობაში სიგრძნობის გაზრძელება, რომელიც მარტივი მარტივის 5M კოსტატის კოსტატის კოსტატის განმავლობაში, როცა მარტი ჩვენ ასევე ვაკეთებთ ხელსახური ანალიზაცია, რომელიც განსხვავებს შესაძლებლობა და ფუნქციის განმავლობაში, რომელიც ყველა სიტყვების განმავლობა იყოს.', 'el': 'Με βάση τις πρόσφατες εξελίξεις στη σημασιολογική ανάλυση και την απλοποίηση κειμένου, ερευνούμε τη χρήση της σημασιολογικής διάσπασης της πρότασης προέλευσης ως προεπεξεργασία για τη μηχανική μετάφραση. Πειραματιζόμαστε με ένα μοντέλο μετασχηματιστή και αξιολογούμε χρησιμοποιώντας πειράματα μεγάλης κλίμακας. Τα αποτελέσματα δείχνουν σημαντική αύξηση της ευκρίνειας σε μεγάλες προτάσεις σε ένα περιβάλλον αγγλικά-γαλλικού με εκπαιδευτικό σώμα από ζεύγη προτάσεων 5Μ, διατηρώντας παράλληλα συγκρίσιμη επάρκεια. Επίσης, διεξάγουμε μια χειρωνακτική ανάλυση που διερευνά το συμβιβασμό μεταξύ επάρκειας και ευκρίνειας στην περίπτωση που λαμβάνονται υπόψη όλα τα μήκη των προτάσεων.', 'it': "Basandoci sui recenti progressi nell'analisi semantica e nella semplificazione del testo, esaminiamo l'uso della divisione semantica della frase sorgente come preprocessing per la traduzione automatica. Sperimentiamo un modello Transformer e valutiamo utilizzando esperimenti di crowd-sourcing su larga scala. I risultati mostrano un significativo aumento della fluidità sulle frasi lunghe in un ambiente inglese-francese con un corpus di formazione di 5M coppie di frasi, pur mantenendo un'adeguatezza comparabile. Eseguiamo anche un'analisi manuale che esplora il compromesso tra adeguatezza e fluidità nel caso in cui tutte le lunghezze delle frasi siano considerate.", 'lt': 'Remdamiesi neseniai padaryta pažanga semantinio analizavimo ir teksto supaprastinimo srityje, mes tiriame semantinio pradinio sakinio padalijimo naudojimą kaip parengiamąjį procesą mašininiam vertimui. Eksperimentuojame su Transformer modeliu ir vertiname naudojant didelio masto visuomenės išteklių eksperimentus. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy.  We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.', 'kk': 'Семантикалық талдау және мәтін қарапайымдастыру үшін жаңа жағдайларды қолдану үшін біз көзінің семантикалық бөлігін машина аудару үшін алдын- ала түзету үшін зерттеуді зерттеуді. Біз түрлендіру үлгісімен тәжірибе және үлкен көпшілік көпшілік көпшілікті тәжірибелерді қолдануға болады. Нәтижелер 5M мәтінінің жұмыс корпус арқылы ағылшын және французша сөздерінің ұзындық сөздерінің көбіректігін көрсетеді, салыстыруға мүмкін. Біз сондай-ақ қолмен анализ істейміз. Бүкіл сөйлеменің ұзындығын қарастыру үшін адекциялық мен жылдамдықтық арасындағы тәртіпсіздігін зерттеді.', 'mk': 'Користејќи се на неодамнешните напредоци во семантичното анализирање и поедноставувањето на текстот, ние ја истражуваме употребата на семантичното поделба на изворната реченица како преработка за машински превод. Експериментираме со трансформен модел и проценуваме користејќи големи експерименти за публички извори. Резултатите покажуваат значителен зголемување на течноста на долгите реченици на англиско-француско место со обука на парови од 5 милиони реченици, при што се задржува споредлива адекватност. Исто така, спроведуваме рачна анализа која ја истражува разликата помеѓу соодветноста и течноста во случајот кога се разгледуваат сите должини на речениците.', 'ml': 'സെമാന്റിക് പാര്\u200dസിങ്ങിലും ടെക്സ്റ്റ് എളുപ്പമാക്കുന്നതിലും അടുത്തുള്ള മുന്\u200dഗണങ്ങള്\u200d നിര്\u200dമ്മിക്കുന്നു, മെഷിന്\u200d പരിഭാഷയ്ക്കു നമ്മള്\u200d ഒരു ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റര്\u200d മോഡല്\u200d കൊണ്ട് പരീക്ഷിക്കുകയും, വലിയ പ്രാപ്റ്റ് സോര്\u200dസിങ് പരീക്ഷണങ്ങള്\u200d ഉപ അന്ത്യഫലങ്ങള്\u200d ഒരു ഇംഗ്ലീഷില്\u200d നിന്നും ഫ്രെഞ്ചില്\u200d നീണ്ട വാക്കുകളില്\u200d നീണ്ട വാക്കുകളില്\u200d ഫ്രെഞ്ചില്\u200d നീണ്ട വാക്കുകള്\u200d കൂടുതല്\u200d വലുതാ എല്ലാ വാക്കുകളുടെയും നീളം വിചാരിക്കുന്ന കാര്യത്തില്\u200d നമ്മള്\u200d ഒരു കൈകാര്യ അന്യായം പ്രവര്\u200dത്തിപ്പിക്കുന്നു.', 'mn': 'Сүүлийн үеийн шинжлэх ухаан болон текст хялбарчлалын тулд бид эх үүсвэрийн өгүүлбэрийг машин орчуулахын тулд анхны үйлдвэрлэхийг судалж байна. Бид Трансформерийн загвартай туршилт хийж, олон нийтийн эх үүсвэрийн туршилтыг ашиглан үнэлэх болно. Үүний үр дүнд англи болон французтай холбоотой урт өгүүлбэрүүдийн тухай 5M өгүүлбэрийн холбоотой сургалтын корпус дээр ихэвчлэн ихэвчлэн байна. Мөн бид бүх өгүүлбэрийн урт нь тодорхойлогдож байгаа тохиолдлыг судлах гарын шинжилгээ хийдэг.', 'no': 'For å bygge på nyleg avansert i semantisk tolking og tekstforenkling, så undersøker vi bruken av semantisk deleting av kjeldesetninga som forhandtering for maskineoversettelse. Vi eksperimenterer med ein transformeringsmodell og evaluerer med stor masseskaler- eksperimenter. Resultater viser ein signifikant økning i flukt på lange setningar på ein engelsk- til- fransk innstilling med opplæringskorpus med 5M setningar, mens det beholder sammenlignbare adekvitet. Vi utfører også ein handbokanalyse som utforskar utviklinga mellom adekvitet og fluktet i tilfellet der alle setningane vert betrakte.', 'pl': 'Opierając się na ostatnich postępach w parsowaniu semantycznym i uproszczeniu tekstu, badamy zastosowanie semantycznego podziału zdania źródłowego jako wstępnego przetwarzania do tłumaczenia maszynowego. Eksperymentujemy z modelem Transformera i oceniamy za pomocą dużych eksperymentów crowdsourcingowych. Wyniki wskazują na znaczący wzrost płynności w długich zdaniach w otoczeniu angielsko-francuskim z korpusem treningowym 5M par zdań, przy zachowaniu porównywalnej adekwatności. Przeprowadzamy również analizę ręczną, która bada kompromis między adekwatnością a płynnością w przypadku, gdy uwzględnia się wszystkie długości zdania.', 'ro': 'Bazându-ne pe progresele recente în analizarea semantică și simplificarea textului, investigăm utilizarea divizării semantice a propoziției sursă ca preprocesare pentru traducerea automată. Experimentăm cu un model Transformer și evaluăm utilizând experimente de crowdsourcing la scară largă. Rezultatele arată o creștere semnificativă a fluenței propozițiilor lungi într-un cadru engleză-franceză cu un corpus de formare de 5M perechi de propoziții, păstrând în același timp o adecvare comparabilă. De asemenea, efectuăm o analiză manuală care explorează compromisul dintre adecvare și fluență în cazul în care sunt luate în considerare toate lungimile propozițiilor.', 'sr': 'Na osnovu nedavnog napreda semantičkog analiza i pojednostavljanja teksta, istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Mi eksperimentiramo sa modelom transformera i procjenjujemo koristeći velike većine eksperimenata koji izvode gomilu. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju sa treninganskim korpusom od par rečenica od 5M, dok zadržavaju usporednu adekvatnost. Takoðe izvršavamo ruènu analizu koja istražuje trgovinu izmeðu adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.', 'so': 'Buildida horumarinta ugu dambeeya baaritaanka semantika iyo sahlisashada qoraalka, waxaynu baaraynaa isticmaalka kala soocminta qoraalka asalka ah oo loo baaraandegayo turjumidda machine. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments.  Midhaha la’aanta waxaa ka muuqda faa’iido aad u korodhsan dhegaha dhaadheer ee ku qoran af Ingiriis-ilaa-Faraansiis, iyadoo haysta mid u eg labada xabsi 5M. Anagu waxaynu sameynaa baaritaanka dhakhtarka, kaasoo baaraya dhibaatada u dhexeeya saxda iyo faa’iidada marka lagu tiriyo dhererka xukunka oo dhan.', 'mt': 'Filwaqt li nibnu fuq avvanzi reċenti fl-analiżi semantika u s-simplifikazzjoni tat-test, ninvestigaw l-użu tal-qsim semantiku tas-sentenza tas-sors bħala proċessar minn qabel għat-traduzzjoni bil-magna. Aħna ninsperimentaw b’mudell ta’ Transformer u nivvalutaw bl-użu ta’ esperimenti ta’ crowd sourcing fuq skala kbira. Ir-riżultati juru żieda sinifikanti fil-fluwenza fuq sentenzi twal fuq ambjent Ingliż-Franċiż b’korpus ta’ taħriġ ta’ pari ta’ sentenzi ta’ 5M, filwaqt li tinżamm adegwatezza komparabbli. Għandna nagħmlu wkoll analiżi manwali li tesplora l-kompromess bejn l-adegwatezza u l-fluwenza fil-każ fejn it-tul kollu tas-sentenza jiġi kkunsidrat.', 'ms': 'Membangun pada kemajuan baru-baru ini dalam penghuraian semantik dan pemudahan teks, kami menyelidiki penggunaan pemisahan semantik kalimat sumber sebagai pemprosesan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan menilai menggunakan eksperimen crowd-sourcing skala besar. Hasil menunjukkan peningkatan yang signifikan pada kalimat panjang pada tetapan Inggeris-Perancis dengan korpus latihan pasangan kalimat 5M, sementara menyimpan keperluan yang boleh dibandingkan. Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keseluruhan dalam kes di mana semua panjang kalimat dianggap.', 'si': 'සෙමැන්ටික් විශ්ලේෂණය සහ පාළුව සරලේෂණය සඳහා අලුත් ප්\u200dරධානය සඳහා නිර්මාණය කරනවා, අපි පරීක්ෂණය කරන්නේ මුළු වාක්ෂණය අපි පරීක්ෂණය කරන්නේ ත්\u200dරාණ්පර් මොඩේල් එකක් සමග විශාල පරීක්ෂණය සඳහා ලොකු ප්\u200dරමාණයක් ප්\u200dරයෝජනය ප්\u200dරතිචාරය පෙන්වන්නේ ඉංග්\u200dරීසියට- ෆ්\u200dරෑන්සියට ප්\u200dරශ්නයක් 5M වාක්ෂාවක් ජෝඩියට ප්\u200dරශ්නයක් තියෙන්නේ ලොක අපි පුළුවන් විශ්ලේෂණයක් කරනවා ඒ වගේම සේරම වාක්ය විශ්ලේෂණයක් පරීක්ෂණය කරනවා කියලා සේරම වාක්ය විශ්', 'sv': 'Utifrån de senaste framstegen inom semantisk tolkning och textförenkling undersöker vi användningen av semantisk uppdelning av källmeningen som förbehandling för maskinöversättning. Vi experimenterar med en Transformer modell och utvärderar med hjälp av storskaliga crowdsourcing-experiment. Resultaten visar en signifikant ökning av flytande på långa meningar i en engelsk-fransk miljö med en träningskorpus på 5M meningspar, samtidigt som jämförbar tillräcklighet bibehålls. Vi utför också en manuell analys som undersöker avvägningen mellan lämplighet och flytande i de fall där alla meningslängder beaktas.', 'ur': 'سیمنٹی پارسینگ اور ٹیکسٹ سادگی میں اچھی پیشرفت پر بنا رہے ہیں، ہم نے ماشین ترجمہ کے لئے پیش پردازی کے طور پر سیمنٹی پاٹینٹ کے استعمال کا تحقیق کیا ہے. ہم ایک ٹرانسفور موڈل کے ساتھ آزمائش کرتے ہیں اور بڑی اسکیل جماعت سورسینگ آزمائش کے مطابق ارزش کرتے ہیں. نتیجے ایک انگلیسی سے فرانسوی سٹینٹ پر طویل جماعت پر بہت اضافہ ہونے کے لئے 5M جماعت جوڑوں کی تدریس کورپوس کے ساتھ دکھائے جاتے ہیں، جبکہ برابری کے ساتھ قائم رہتے ہیں. ہم نے بھی ایک مہمانی تحلیل کرتا ہے جس میں ہر جماعت کی طول کی نظر کی جاتی ہے اس موقع میں کہ adequacy اور fluency کے درمیان تجارت کا تحقیق کرتا ہے.', 'ta': 'பெமான்டிக் பாசிங் மற்றும் உரை எளிதாக்கத்தில் சமீபத்தில் முன்னேற்றங்களை உருவாக்குதல் மூலத்தின் பிரிப்பு வாக்கியத்தின் முன் நாங்கள் ஒரு மாற்று மாதிரி முறைமையைக் கொண்டு பரிசோதிக்கிறோம் மற்றும் பெரிய அளவு கூட்டத்தின் மூல மூலம்  @ info: whatsthis நாம் ஒரு கைமுறை ஆராய்ச்சி செய்கிறோம். அது தேவையான மற்றும் விளைவுகளுக்கிடையே இடையேயுள்ள இடைவெளிப்பாட்டை தெரிய', 'uz': "@ info: whatsthis Biz Transformer model bilan tizimiz qilamiz va katta ko'pchilik jamoatlar tizimini ishlatish mumkin. @ info: whatsthis Biz qoʻlbola analyzerni bajaramiz va hamma maxsus soʻzni tasavvur qilinadigan holatda yetarli narsalarni o'rganadi.", 'vi': 'Dựa trên những tiến bộ gần đây về phân tích ngữ pháp và việc đơn giản văn bản, chúng tôi điều tra việc sử dụng chữ thập theo ngữ pháp như việc xử lý trước phiên bản máy. Chúng tôi thử nghiệm với một mô hình transformer và đánh giá bằng cách thí nghiệm buôn lậu diện rộng. Kết quả cho thấy khả năng cao của các án dài trên một trường hợp Anh-Pháp với tập thể huấn của các cặp án 5M, đồng thời giữ mức độ phù hợp tương xứng. Chúng tôi cũng làm một phân tích bằng tay để tìm hiểu sự thỏa thuận giữa sự phù hợp và khéo léo trong trường hợp mọi độ dài các câu nói được xem xét.', 'bg': 'Въз основа на скорошните постижения в семантичното анализиране и опростяването на текста, изследваме използването на семантично разделяне на изходното изречение като предварителна обработка за машинен превод. Експериментираме с модел на трансформатор и оценяваме с помощта на мащабни експерименти за групово снабдяване. Резултатите показват значително увеличение на владеенето на дълги изречения в английско-френска обстановка с тренировъчен корпус от 5 милиона двойки изречения, като същевременно се запазва сравнима адекватност. Извършваме и ръчен анализ, който изследва компромиса между адекватност и плавност в случая, когато се вземат предвид всички дължини на изреченията.', 'da': 'Med udgangspunkt i de seneste fremskridt inden for semantisk parsing og tekstforenkling undersøger vi brugen af semantisk opdeling af kildesætningen som forbehandling til maskinoversættelse. Vi eksperimenterer med en Transformer model og evaluerer ved hjælp af store crowd-sourcing eksperimenter. Resultaterne viser en betydelig stigning i flydenhed på lange sætninger på en engelsk-fransk indstilling med et træningskorpus på 5M sætningspar, samtidig med at de bevarer tilsvarende tilstrækkelighed. Vi udfører også en manuel analyse, der undersøger afvigelsen mellem tilstrækkelighed og flydende i tilfælde, hvor alle sætningslængder tages i betragtning.', 'nl': 'Voortbouwend op recente ontwikkelingen in semantische parsing en tekstvereenvoudiging, onderzoeken we het gebruik van semantische splitsing van de bronzin als voorbewerking voor machinevertaling. We experimenteren met een Transformer model en evalueren met behulp van grootschalige crowdsourcing experimenten. De resultaten tonen een significante toename van de vloeibaarheid van lange zinnen in een Engels-Frans setting met een trainingscorpus van 5M zinnenparen, met behoud van vergelijkbare adequaatheid. We voeren ook een handmatige analyse uit die de afweging tussen adequaatheid en vloeiendheid onderzoekt in het geval dat alle zinnenlengtes worden overwogen.', 'hr': 'Na temelju nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo upotrebu semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod strojeva. Eksperimentiramo s modelom Transformer a i procjenjujemo koristeći velike prometne eksperimente. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju s obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se razmatra dužin a kazne.', 'de': 'Aufbauend auf den jüngsten Fortschritten in der semantischen Parsing und Textvereinfachung untersuchen wir die Verwendung der semantischen Aufteilung des Ausgangssatzes als Vorverarbeitung für maschinelle Übersetzung. Wir experimentieren mit einem Transformer-Modell und evaluieren diese mithilfe von groß angelegten Crowdsourcing-Experimenten. Die Ergebnisse zeigen einen signifikanten Anstieg der Fließfähigkeit von langen Sätzen in einem Englisch-Französisch Setting mit einem Trainingskorpus aus 5M Satzpaaren bei gleichbleibender Angemessenheit. Wir führen auch eine manuelle Analyse durch, die den Kompromiss zwischen Angemessenheit und Fluency untersucht, wenn alle Satzlängen berücksichtigt werden.', 'sw': 'Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  Tunajaribu kwa mtindo wa Transformer na kutathmini kwa kutumia majaribio makubwa yanayotumiwa na vyanzo vya umma. Matokeo yanaonyesha kuongezeka kwa ufanisi mkubwa katika hukumu ndefu juu ya kitendo cha Kiingereza-hadi Kifaransa kinachotumiwa na kikundi cha mafunzo cha kifungo cha wanandoa 5M, wakati wakiendelea kuwa na usawa wa kutosha. Pia tunafanya uchambuzi wa mkono unaoelezea hali ya kutokea kati ya usawa na ufanisi katika kesi ambapo hukumu zote zinachukuliwa kwa muda mrefu.', 'ko': '의미 분석과 텍스트 간소화의 최신 진전을 바탕으로 우리는 원어구의 의미 분해를 기계 번역의 예처리로 연구했다.우리는 변압기 모형을 사용하여 실험을 하고 대규모의 패키지 실험을 사용하여 평가를 한다.그 결과 영어-프랑스어 환경에서 500만 개의 문장이 맞는 훈련 어료 라이브러리를 사용하면 긴 문장의 유창도가 현저히 높아지고 상당한 충분성을 유지한 것으로 나타났다.우리는 모든 문장의 길이를 고려할 때 적절성과 유창성 간의 균형을 수동적으로 분석했다.', 'id': 'Berdasarkan kemajuan baru-baru ini dalam penghuraian semantis dan penyimplifikasi teks, kami menyelidiki penggunaan pemisahan semantis dari kalimat sumber sebagai persiapan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan mengevaluasi menggunakan eksperimen crowd-sourcing skala besar. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy.  Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keterlaluan dalam kasus di mana semua panjang kalimat dianggap.', 'fa': 'بر اساس پیشرفت های اخیر در تجزیه\u200cسازی و ساده\u200cسازی متن، ما استفاده از تقسیم\u200cسازی از جمله منبع به عنوان پیش\u200cپردازی برای ترجمه\u200cسازی ماشین تحقیق می\u200cکنیم. ما با یک مدل تغییر دهنده آزمایش می کنیم و با استفاده از آزمایش\u200cهای سرمایه\u200cگذاری جمعیت بزرگ ارزیابی می\u200cکنیم. نتیجه\u200cها اضافه\u200cای بزرگی بر جمله\u200cهای طولانی در یک تنظیم انگلیسی به فرانسوی با یک جفت آموزشی از جفت\u200cهای جمله 5M نشان می\u200cدهند، در حالی که قابلیت قابل مقایسه نگه می\u200cدارند. ما همچنین یک تحلیل دستی انجام می دهیم که تجارت بین عدالت و مایع در مورد هر طول جمله به نظر می رسد، تحقیق می کند.', 'sq': 'Duke u mbështetur në përparimet e fundit në analizimin semantik dhe thjeshtimin e tekstit, ne hetojmë përdorimin e ndarjes semantike të fjalës së burimit si përgatitje për përkthimin e makinave. Ne eksperimentojmë me një model Transformer dhe vlerësojmë duke përdorur eksperimente të madhe crowd-sourcing. Rezultatet tregojnë një rritje të rëndësishme në fluencën e dënimeve të gjata në një ambient anglez-në-francez me një korpus trajnimi të çifteve të dënimeve 5M, duke mbajtur përshtatshmërinë e krahasueshme. Ne kryejmë gjithashtu një analizë manuale që eksploron kompromisin midis përshtatshmërisë dhe fluencës në rastin ku të gjitha gjatësitë e dënimit konsiderohen.', 'am': 'Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  በተመሳሳይ የብዙው የድምፅ ጉዳይ ፈተና እናረጋግጣለን፡፡ ፍጥረቶቹ በይንግልዝኛ-ወደ ፈረንሳይኛ የ5M ፍርድ ክፍል የረጅም ፈቃድ ውርደት ያሳያል፡፡ የሥርዓት ዕድሜ በሚቆጠሩበት ወቅት መካከል የሚያስፈልገውን ግጭት እናሳውቃለን፡፡', 'tr': 'Semantik anal첵힊inde we metin bejerilmesinde 첵okary geli힊melere 첵체ze 챌yky힊 edip, ma힊yny흫 terjime 체챌in 철흫체nden i힊len첵채n semantik s철zl채ni ulanmagyny barla첵arys. Biz bir Transformer modeli bilen synany힊첵arys we uly 철l챌ekli k철p sourcing deneylerini ulanyp de흫le첵채ris. Netijenler 5M s철zlem 챌ift sanynda u흫 s철zlemler i흫lis챌e- fransuz챌a d체z체mlenme 체챌in 철r채n k철pr채k 체첵tge첵채r, me흫ze힊li 첵erlilikde durul첵ar. Biz hem el analizi yapar캇z. Bu durumda, b체t체n s철zlerin uzunlu휓u d체힊체n체len durumda, adetleik we akyllyk aras캇ndaki ticareti ke힊fetmesini 챌철zer.', 'af': "By gebou van onlangse vorderings in semantiese verwerking en teks vereenvoudiging, ondersoek ons die gebruik van semantiese verdeeling van die bron seting as voorafverwerking vir masjien vertaling. Ons eksperimenteer met 'n Transformer model en evalueer met groot-skaal skaal-sourcing eksperimente. Resultate wys 'n betekende versterking in fluiditeit op lange setnings op 'n Engels- na- Frans instelling met 'n oefening korpus van 5M setnings paar, terwyl die vergelykbare adekuasie hou. Ons doen ook 'n handaandeling wat die verkrywing tussen adekuasie en fluiditeit ondersoek in die geval waar al die setlengte beskou word.", 'hy': 'Հիմնվելով սեմանտիկ վերլուծության և տեքստի պարզեցման վերջին առաջընթացների վրա, մենք ուսումնասիրում ենք, թե ինչպես է օգտագործվում աղբյուր նախադասության սեմանտիկ բաժանելը որպես մեքենայի թարգմանման նախամշակում: Մենք փորձում ենք տրանֆորմային մոդելի միջոցով և գնահատում ենք, օգտագործելով մեծ մասշտաբով ժողովրդավար փորձեր: Արդյունքները ցույց են տալիս, որ երկար նախադասությունների ճկունության մեծ աճ է անգլերեն-ֆրանսիացի միջավայրում 5M նախադասությունների զույգերի ուսումնասիրության կորպոսի հետ, մինչդեռ համեմատությունը պահպանվում է: We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.', 'bn': 'Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  আমরা একটি ট্রান্সফ্রান্সফার মডেল দিয়ে পরীক্ষা করি এবং বিশাল মানুষ-সোর্সিং পরীক্ষা ব্যবহার করে মূল্যায়ন করি। ফলাফল দেখা যাচ্ছে একটি ইংরেজি থেকে ফ্রেঞ্চ ব্যবহারের উপর দীর্ঘ শাস্তিতে প্রভাব বৃদ্ধি প্রদর্শন করা হয়েছে, যার প্রশিক্ষণ ৫ এম কারাদণ্ডের জোড় আমরা একই সাথে একটি হাতিয়াল বিশ্লেষণ করি যা যথাযথ এবং প্রভাবের মধ্যে ব্যাপারটি বিশ্লেষণ করে যেখানে সকল বাক্যের দীর্ঘ সময় বিবেচন', 'az': 'Semantik ayırma və metin basitləşdirməsi üçün yeni ilerləşmələri in şa etdik, maşın tercüməsi üçün ilk işləmə üçün mənbə cümləsinin semantik ayırmasını araşdırırıq. Biz bir Transformer modeli ilə təcrübə edirik və böyük ölçüdə qüvvətli təcrübələr vasitəsilə təcrübə edirik. Sonuçlar 5 M cümləlik çiftlərinin təhsil korpusu ilə İngilizə-Fransızca təhsil edilməsi üçün uzun cümlələr üzərində böyüklük artırmağı göstərər, müqayisədə uyğunluğu saxlayaraq. Biz həmçin in bütün cümlələrin uzunluğunu düşündüyü təqdirdə adeqliyyat və fərqliyyat arasındakı ticarəti keşfetən əlavə analizi çəkirik.', 'bs': 'Na osnovu nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Eksperimentiramo sa modelom Transformer a i procjenjujemo koristeći velike gomilu-izvorenje eksperimenata. Rezultati pokazuju značajno povećanje tečnosti na dugim rečenicama na engleskom i francuskom postavljanju sa obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.', 'cs': 'Na základě nedávných pokroků v oblasti sémantického parsování a zjednodušení textu zkoumáme využití sémantického rozdělení zdrojové věty jako předzpracování pro strojový překlad. Experimentujeme s transformátorovým modelem a hodnotíme pomocí rozsáhlých crowdsourcingových experimentů. Výsledky ukazují výrazný nárůst plynulosti dlouhých vět v anglicko-francouzském prostředí s výcvikovým korpusem 5M větových párů při zachování srovnatelné adekvátnosti. Dále provádíme manuální analýzu, která zkoumá kompromis mezi adekvátností a plynulostí v případě, kdy jsou zohledněny všechny délky věty.', 'ca': "Construïnt-nos en avanços recents en l'analització semàntica i la simplificació del text, investigam l'ús de la divisió semàntica de la frase fontcom a preparació per a la traducció automàtica. Experimentem amb un model Transformer i evaluem fent servir experiments de crowd sourcing a gran escala. Els resultats mostren un augment significatiu de fluència en frases llargues en un entorn anglès-francès amb un cos d'entrenament de parells de frases de 5M, mantenint la adequació comparable. També fem una anàlisi manual que explora el compromís entre adequació i fluïtat en el cas en què es consideren totes les llargues de frases.", 'et': 'Tuginedes hiljutistele edusammudele semantilises parsimises ja teksti lihtsustamises, uurime lähtelause semantilise jagamise kasutamist masintõlke eeltöötlusena. Me eksperimenteerime Transformeri mudeliga ja hindame suuremahuliste ühishankimise katsete abil. Tulemused näitavad, et pikkade lausete sujuva oskuse märkimisväärne suurenemine inglise-prantsuse keeles, kus koolituskorpus koosneb 5 miljonist lausepaarist, säilitades samas võrreldava piisavuse. Samuti teostame käsitsi analüüsi, mis uurib kompromisse piisavuse ja sujuvuse vahel juhul, kui arvestatakse kõiki lausepikkusi.', 'fi': 'Seminttisen jäsentämisen ja tekstin yksinkertaistamisen viimeaikaisen kehityksen pohjalta tutkimme lähdelauseen semanttisen jakamisen käyttöä konekäännöksen esikäsittelyssä. Kokeilemme Transformer-mallia ja arvioimme sen laajamittaisilla joukkohankintakokeiluilla. Tulokset osoittavat, että pitkien lauseiden sujuvuus lisääntyi merkittävästi englanti-ranska-ympäristössä, kun koulutuskorpus oli 5 miljoonaa lauseparia. Teemme myös manuaalisen analyysin, jossa selvitetään riittävyyden ja sujuvuuden välistä kompromissia siinä tapauksessa, että kaikki lauseen pituudet otetaan huomioon.', 'jv': 'Daerah ono nggawe advances in semanti karo semanti karo perusahaan teks semanti, kita yatênggunaé perusahaan semanti nggawe aturan kelompok nggawe barang kelompok nggawe sistem tarjamahan. Awak dhéwé éntuk karo model Transformer kuwi nggawe nyimpen banter-kalaha ujaran. Pamita puteh ngomong kedhanan langkung dolanan kapan-dolanan nganggo dolanan ingkang karo- Perancis Awak dhéwé éntuk manut karo hal-manut sing bisa mlebu nggawe gerakan gambar deweke karo kapan kanggo ngilanggar kuwi kesempatan kanggo nggawe barang langgar kuwi.', 'he': 'בניין על התקדמות האחרונות באבחן סמנטי ופשטות טקסט, אנו חוקרים את השימוש בהחלקה סמנטית של המשפט המקורי כהתהליך לתרגום מכונות. אנו מנסים עם מודל טרנספורר ומעריכים בשימוש ניסויים במקורי קהל גדולים. התוצאות מראות עלייה משמעותית במשפטים ארוכים במצב אנגלי-צרפתי עם גוף אימון של זוגות משפטים של 5 מיליון, בזמן שמירה מתאימה שווה. אנו גם מבצעים ניתוח ידני שמחקר את ההחלטה בין התאימות לבין השקטות במקרה שבו כל אורך המשפט נחשב.', 'ha': "Tsarin da aka samu masu ƙara cikin parse na semantic da mai sauƙin matsayi, za'a yi ƙidãya wa amfani da cutarwa na semantic ko pre-zartar da fassarar maɓalli. Za jarraba da wani misali mai Transformer kuma tuna hakar jarrabo masu girma ga mutane-sourcen. Mataimakin na nuna significant ƙari ga furuci a kan sauran da aka daidaita na Ingiriya-zuwa-French mai daidaita da wani shirin cire-nau'in 5 M, kuma yana retain daidai. Tuna sami wani anayyar da hannun aiki wanda ke jarraba fatauci tsakanin da kuma ma'ishi idan an yi bincike da duk cire.", 'sk': 'Na podlagi nedavnega napredka semantičnega razčlenjanja in poenostavitve besedila raziskujemo uporabo semantičnega razdelitve izvornega stavka kot predobdelave za strojno prevajanje. Eksperimentiramo s transformatorskim modelom in ocenjujemo z uporabo obsežnih množičnih eksperimentov. Rezultati kažejo znatno povečanje tekočosti pri dolgih stavkih v angleško-francoskem okolju s korpusom usposabljanja 5 M parov stavkov, ob ohranjanju primerljive ustreznosti. Izvajamo tudi ročno analizo, ki raziskuje kompromis med ustreznostjo in tekočostjo v primeru, ko upoštevamo vse dolžine stavka.', 'bo': 'Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. ང་ཚོས་གཞུང་བཟོ་བྱེད་པའི་མ་དབུགས་ཞིག་གིས་བརྟག་དཔྱད་བྱེད་ཀྱི་ཡོད་ཚད་ཆེན་པོ་ཞིག་གིས་ གྲུབ་འབྲས་གཞི་ལྟ་བུའི་ཚིག་རྐང་ཐག་གཅིག་ལས་དབྱིན་ཡིག་གཟུགས་འགྱུར་བ་སྐྱེལ་ཅན་ཏུ་མངོན་གསལ་གཏོང་། ང་ཚོས་དུས་མཐུན་དང་དཔྱད་དབར་གྱི་བཟོ་བཅོས་ལ་ལག་བཟོས་དཔྱད་ཞིག་བྱེད་ཀྱི་ཡོད་པ་ཞིག་གནང་བ་རེད།'}
{'en': 'On the Systematicity of Probing Contextualized Word Representations : The Case of Hypernymy in BERT', 'es': 'Sobre la sistematicidad del sondeo de representaciones verbales contextualizadas: el caso de la hipernemia en el BERT', 'fr': "Sur la systématicité de l'exploration des représentations textuelles contextualisées\xa0: le cas de l'hypernymie dans le BERT", 'ar': 'حول منهجية التحقيق في تمثيلات الكلمات السياقية: حالة Hypernymy في BERT', 'pt': 'Sobre a sistematicidade da sondagem de representações de palavras contextualizadas: o caso da hipernímia no BERT', 'ja': '文脈化された単語表現の探索の体系性について： BERTにおけるハイパーニミーの事例', 'zh': '论寻语境化词表征系统性:BERT中Hypernymy例', 'ru': 'О системности зондирующих контекстуализированных словопредставлений: случай гипернимии в БЕРТ', 'hi': 'Contextualized Word Representations की जांच की Systematicity पर: BERT में Hypernymy का मामला', 'ga': 'Ar an gCórasacht a bhaineann le Léirithe Focal Comhthéacsúla a Scrúdú: Cás na hIarainmheice in BERT', 'ka': 'კონტექსტუალური სიტყვების გამოყენება: ჰიპერნიმიის შემთხვევა BERT-ში', 'el': 'Για τη συστηματικότητα της διερεύνησης περιεχομένων αναπαραστάσεων λέξεων: Η περίπτωση της υπερνυμίας στο BERT', 'hu': 'A kontextualizált szóreprezentációk szisztematikájáról: A hipernímia esete a BERT-ben', 'lt': 'Apie kontekstinių žodžių reprezentacijų bandymo sistemingumą: hipernimijos atvejis BERT', 'it': "Sulla sistematica delle rappresentazioni contestualizzate delle parole: il caso dell'ipernimia in BERT", 'mk': 'Во врска со систематичноста на проверка на контекстуалните репрезентации на зборови: случајот на хипернимија во БЕРТ', 'kk': 'Контекстуалды сөздерді зерттеу жүйесінде: BERT- де гипернимнің әріптері', 'ms': 'Pada Sistematik Pengujian Perwakilan Kata Berkonteks: Kasus Hipernimi dalam BERT', 'no': 'På systematiteten av forsøk av kontekstualiserte ordrepresentasjonar: Storleiken på hypernymen i BERT', 'pl': 'O systematyczności sondowania kontekstualizowanych reprezentacji słowa: przypadek hipernimii w BERT', 'ml': 'പ്രോബിങ്ങിന്റെ സിസ്റ്റമിറ്റിയില്\u200d വാക്ക് പ്രതിനിധികള്\u200d: ബെര്\u200dട്ടിലെ ഹൈപ്പര്\u200dനിമിയുടെ കേസ്റ്റ്', 'mt': 'Dwar is-Sistematiċità ta’ Probar ta’ Rappreżentazzjonijiet Kuntest tal-Kliem: Il-Każ ta’ Ipernimja fil-BERT', 'mn': 'Судалгааны байдлын систематикийн тухай: BERT-ын Хипернимийн тухай', 'ro': 'Despre sistematicitatea proiectării reprezentărilor contextualizate ale cuvintelor: cazul hiperinimiei în BERT', 'sr': 'O sistematskoj ispitivanju kontekstualiziranih reči predstavljanja: slučaj hipernimi u BERT-u', 'si': 'පරීක්ෂණය සම්පූර්ණ වචන ප්\u200dරතිස්ථාපනයේ පරීක්ෂණය ගැන: The case of Hypernymy in BERT', 'so': 'Xafiiska jardiinada la soo wareejiyo erayga la soo celinayo: Case of Hypernymy in BERT', 'sv': 'Om systematiken hos kontextualiserade ordrepresentationer: Fallet med hypernymi i BERT', 'ta': 'வார்த்தையின் முறைமையில் பிரிப்பிங் செய்யப்பட்ட முறைமையில்: BERT யில் ஹைப்பர்னிமியின் விஷயம்', 'ur': 'آزمائش کی سیستماتیٹی کے بارے میں بات کی نمایش: BERT میں آزمائش کی کیس', 'uz': 'Name', 'vi': 'Về bệnh viện liên hệ của Diễn văn văn văn văn văn tự định sẵn: Trường hợp Hypernymy ở Berlin', 'hr': 'O sistematičnosti ispitivanja kontekstualiziranih riječi: slučaj hipernimu u BERT-u', 'bg': 'За систематичността на изследването на контекстуализираните словесни представи: случаят на хипернимията в БЕРТ', 'da': 'Om systematisk undersøgelse af kontekstualiserede ordrepræsentationer: Tilfældet med hypernymi i BERT', 'nl': 'Over de systematischheid van het onderzoeken van contextualiseerde woordrepresentaties: het geval van hyperniemie in BERT', 'de': 'Zur Systematik kontextualisierter Wortdarstellungen: Der Fall der Hypernymie in BERT', 'id': 'Pada Sistematik Pengujian Perwakilan Kata Konteksual: Kasus Hipernimi dalam BERT', 'ko': '논어경계화 어휘 표징 탐색의 체계성 - 에서 초어 현상을 예로 들다', 'fa': 'بر اساس سیستماتیک تحقیق معجزات کلمه متوسط: Case of Hypernymy in BERT', 'sw': 'Kuhusu Mfumo wa Kudhibiti Hadithi ya Utinzani: Mashtaka ya Hypernymy huko BERT', 'tr': "BERT'deki Hypernimi'nin Sistemsel Denemesi", 'sq': 'Në Sistematicitetin e Probimit të Përfaqjeve të Fjalëve Kontekstuale: rasti i hipernimisë në BERT', 'af': 'Op die Sistematiteit van Probeer Konteksualiseerde Woord voorstellings: Die Kas van Hypernymy in BERT', 'am': 'የ ቃላት ተሟጋቾች በሚያሳየው ስርዓት ላይ: BERT የHypernymy ጉዳይ', 'az': "Sözünü Sözünün Sistemsallığı: BERT'da Hypernymy Case", 'hy': 'Բառերի կոնտեքստալիզացված ներկայացումների համակարգչային փորձարկումների մասին.', 'bn': 'সিস্টেমিটি অফ প্রোবিনিং শব্দের প্রতিনিধিত্ব: বার্টে হাইপার্নিমির মামলা', 'bs': 'O sistematskoj ispitivanju kontekstualiziranih riječi: slučaj hipernimi u BERT-u', 'ca': "En la Sistematicitat de Probar Representacions Contextualitzades de paraules: El cas d'hipernimia a BERT", 'cs': 'O systematice sondování kontextualizovaných slovních reprezentací: Případ hypernymie v BERT', 'et': 'Kontekstuliseeritud sõnaesinduste proovimise süstemaatilisus: hüpernüümia juhtum BERT-is', 'fi': 'Kontekstualisten sanaesitysten systeemisestä probingista: Hypernyymin tapaus BERT:ssä', 'jv': "Mungkin Sistem Sistem Daerahing Kontextual 'Word representation: The Case of Typerny in BERT", 'ha': 'KCharselect unicode block name', 'sk': 'O sistematičnosti prodiranja kontekstualiziranih besednih predstavitev: primer hipernimije v BERT', 'bo': 'ཞིབ་དཔྱད་ལྟ་བུའི་ནང་དུ་ཚོད་ལྟ་བུའི་ཐོག་ལས་', 'he': 'על המערכת של חקירת מילים מקורקסטולוגיות: מקרה היפרנימיה ב-BERT'}
{'en': 'Contextualized word representations have become a driving force in NLP, motivating widespread interest in understanding their capabilities and the mechanisms by which they operate. Particularly intriguing is their ability to identify and encode conceptual abstractions. Past work has probed BERT representations for this competence, finding that BERT can correctly retrieve noun hypernyms in cloze tasks. In this work, we ask the question : do probing studies shed light on systematic knowledge in BERT representations? As a case study, we examine hypernymy knowledge encoded in BERT representations. In particular, we demonstrate through a simple consistency probe that the ability to correctly retrieve hypernyms in cloze tasks, as used in prior work, does not correspond to systematic knowledge in BERT. Our main conclusion is cautionary : even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT ‘understands’ a concept, and it can not be expected to systematically generalize across applicable contexts.do probing studies shed light on systematic knowledge in BERT representations? As a case study, we examine hypernymy knowledge encoded in BERT representations. In particular, we demonstrate through a simple consistency probe that the ability to correctly retrieve hypernyms in cloze tasks, as used in prior work, does not correspond to systematic knowledge in BERT. Our main conclusion is cautionary: even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT ‘understands’ a concept, and it cannot be expected to systematically generalize across applicable contexts.', 'ar': 'أصبحت تمثيلات الكلمات السياقية قوة دافعة في البرمجة اللغوية العصبية ، مما يحفز الاهتمام على نطاق واسع بفهم قدراتهم والآليات التي يعملون من خلالها. ومما يثير الاهتمام بشكل خاص قدرتها على تحديد وترميز التجريدات المفاهيمية. بحث العمل السابق في تمثيلات BERT لهذه الكفاءة ، ووجد أن BERT يمكنه استرداد الأسماء التشعبية بشكل صحيح في مهام cloze. في هذا العمل ، نطرح السؤال التالي: هل تلقي الدراسات الاستقصائية الضوء على المعرفة المنهجية في تمثيلات بيرت؟ كدراسة حالة ، قمنا بفحص المعرفة المفرطة للتسمم المشفرة في تمثيلات BERT. على وجه الخصوص ، نوضح من خلال مسبار تناسق بسيط أن القدرة على استرداد Hypernyms بشكل صحيح في مهام cloze ، كما هو مستخدم في العمل السابق ، لا تتوافق مع المعرفة المنهجية في BERT. استنتاجنا الرئيسي تحذيري: حتى إذا أظهر BERT دقة استقصاء عالية لكفاءة معينة ، فإنه لا يتبع بالضرورة أن BERT "يفهم" مفهومًا ، ولا يمكن توقع تعميمه بشكل منهجي عبر السياقات القابلة للتطبيق.', 'es': 'Las representaciones de palabras contextualizadas se han convertido en una fuerza impulsora de la PNL, lo que ha motivado un interés generalizado en la comprensión de sus capacidades y los mecanismos por los que funcionan. Especialmente intrigante es su capacidad para identificar y codificar abstracciones conceptuales. El trabajo anterior ha investigado las representaciones de BERT para esta competencia, encontrando que BERT puede recuperar correctamente los hiperónimos de los sustantivos en tareas cloze. En este trabajo, nos hacemos la pregunta: ¿arrojan luz los estudios de sondeo sobre el conocimiento sistemático en las representaciones BERT? Como estudio de caso, examinamos el conocimiento de la hipernemia codificado en las representaciones de BERT. En particular, demostramos a través de una simple sonda de consistencia que la capacidad de recuperar correctamente hiperónimos en tareas cloze, como se usa en trabajos anteriores, no corresponde al conocimiento sistemático en BERT. Nuestra principal conclusión es cautelosa: incluso si BERT demuestra una alta precisión de sondeo para una competencia en particular, no se deduce necesariamente que BERT «entienda» un concepto, y no se puede esperar que generalice sistemáticamente en todos los contextos aplicables.', 'fr': "Les représentations textuelles contextualisées sont devenues une force motrice de la PNL, suscitant un intérêt général pour la compréhension de leurs capacités et des mécanismes par lesquels elles fonctionnent. Leur capacité à identifier et à coder des abstractions conceptuelles est particulièrement intéressante. Des travaux antérieurs ont étudié les représentations BERT pour cette compétence, et ont découvert que BERT peut récupérer correctement les hyperonymes de noms dans des tâches rapprochées. Dans ce travail, nous posons la question suivante\xa0: les études de sondage mettent-elles en lumière la connaissance systématique des représentations BERT\xa0? Dans le cadre d'une étude de cas, nous examinons les connaissances en hypernymie codées dans les représentations BERT. En particulier, nous démontrons par une simple sonde de cohérence que la capacité à récupérer correctement des hyperonymes dans des tâches rapprochées, comme dans des travaux antérieurs, ne correspond pas à une connaissance systématique en BERT. Notre principale conclusion est prudente\xa0: même si le BERT fait preuve d'une grande précision de palpage pour une compétence particulière, cela ne signifie pas nécessairement que le BERT «\xa0comprend\xa0» un concept, et on ne peut pas s'attendre à ce qu'il généralise systématiquement dans les contextes applicables.", 'pt': 'As representações de palavras contextualizadas tornaram-se uma força motriz na PNL, motivando um interesse generalizado em entender suas capacidades e os mecanismos pelos quais operam. Particularmente intrigante é sua capacidade de identificar e codificar abstrações conceituais. Trabalhos anteriores sondaram as representações do BERT para essa competência, descobrindo que o BERT pode recuperar corretamente hiperônimos nominais em tarefas de cloze. Neste trabalho, fazemos a pergunta: os estudos de sondagem lançam luz sobre o conhecimento sistemático nas representações do BERT? Como estudo de caso, examinamos o conhecimento de hipernímia codificado em representações de BERT. Em particular, demonstramos através de uma sonda de consistência simples que a capacidade de recuperar corretamente hiperônimos em tarefas de cloze, conforme usado em trabalhos anteriores, não corresponde ao conhecimento sistemático em BERT. Nossa principal conclusão é cautelosa: mesmo que o BERT demonstre alta precisão de sondagem para uma competência específica, isso não significa necessariamente que o BERT "entende" um conceito, e não se pode esperar que ele generalize sistematicamente em contextos aplicáveis.', 'ja': '文脈化された単語表現は、NLPの原動力となり、その能力と動作するメカニズムを理解することへの広範な関心を動機づけています。 特に興味深いのは、概念的抽象を識別し、エンコードする能力です。 過去の研究では、このコンピテンシーのためにBERT表現を探索し、BERTがクローズタスクで名詞の超ニームを正しく取り出すことができることを発見しました。 この研究では、私たちは質問をします。探索研究はBERT表現の体系的な知識を明らかにしますか？ ケーススタディとして、BERT表現で符号化されたハイパーニミー知識を検討します。 特に、単純な一貫性プローブを通じて、以前の作業で使用されたクローズタスクで超ニームを正しく取得する能力が、BERTにおける体系的な知識に対応していないことを実証します。 私たちの主な結論は警告的です。BERTが特定のコンピテンシーについて高い探索精度を示したとしても、BERTが概念を「理解」しているとは限らず、適用可能な文脈全体で体系的に一般化することは期待できません。', 'hi': "संदर्भित शब्द प्रतिनिधित्व एनएलपी में एक प्रेरक शक्ति बन गया है, जो उनकी क्षमताओं और उन तंत्रों को समझने में व्यापक रुचि को प्रेरित करता है जिनके द्वारा वे काम करते हैं। विशेष रूप से पेचीदा वैचारिक अमूर्तताओं की पहचान करने और एन्कोड करने की उनकी क्षमता है। पिछले काम ने इस क्षमता के लिए BERT अभ्यावेदन की जांच की है, यह पाते हुए कि BERT सही ढंग से क्लोज़ कार्यों में संज्ञा hypernyms को पुनः प्राप्त कर सकता है। इस काम में, हम सवाल पूछते हैं: क्या जांच अध्ययन BERT प्रतिनिधित्व में व्यवस्थित ज्ञान पर प्रकाश डालते हैं? एक मामले के अध्ययन के रूप में, हम BERT अभ्यावेदन में एन्कोडेड hypernymy ज्ञान की जांच करते हैं। विशेष रूप से, हम एक सरल स्थिरता जांच के माध्यम से प्रदर्शित करते हैं कि क्लोज़ कार्यों में हाइपरनिम्स को सही ढंग से पुनर्प्राप्त करने की क्षमता, जैसा कि पहले के काम में उपयोग किया जाता है, BERT में व्यवस्थित ज्ञान के अनुरूप नहीं है। हमारा मुख्य निष्कर्ष चेतावनी है: भले ही BERT किसी विशेष क्षमता के लिए उच्च जांच सटीकता प्रदर्शित करता है, यह जरूरी नहीं है कि BERT एक अवधारणा को 'समझता है' का पालन करता है, और इसे लागू संदर्भों में व्यवस्थित रूप से सामान्यीकृत करने की उम्मीद नहीं की जा सकती है।", 'zh': '语境化者单词已为NLP驱动力,激人广注其机。 特有趣者,其知编码概也。 往事已探BERT此力,见BERT可塞正检名词。 考之BERT统乎? 为例考之,BERT示中编码之超识也。 特以一简之一致性探针验,前事所用于 cloze 务,检超名之能,与 BERT 之统识不符。 大抵戒性者,虽BERT高特定准确性,未必BERT解一名,不可望于上下文系统地广也。', 'ru': 'Контекстуализированные представления слов стали движущей силой в NLP, мотивируя широкий интерес к пониманию их возможностей и механизмов, с помощью которых они работают. Особенно интригует их способность идентифицировать и кодировать концептуальные абстракции. Прошлые работы исследовали представления БЕРТА для этой компетенции, обнаружив, что БЕРТА может правильно извлекать существительные гипернимы в задачах закрытия. В этой работе мы задаемся вопросом: проливают ли исследования зондирования свет на систематические знания в представлениях БЕРТА? В качестве примера мы рассматриваем гипернимические знания, закодированные в представлениях BERT. В частности, мы демонстрируем с помощью простого зонда согласованности, что способность правильно извлекать гипернимы в задачах закрытия, как использовано в предыдущей работе, не соответствует систематическим знаниям в BERT. Наш главный вывод предостерегает: даже если БЕРТ демонстрирует высокую точность зондирования для конкретной компетенции, это не обязательно означает, что БЕРТ «понимает» концепцию, и от него нельзя ожидать систематического обобщения в применимых контекстах.', 'ga': "Tá léirithe comhthéacsúla focal ina fhórsa tiomána in NLP, rud a spreagann suim fhorleathan i dtuiscint ar a gcumas agus ar na meicníochtaí trína bhfeidhmíonn siad. Is díol spéise ar leith é a gcumas astarraingtí coincheapúla a aithint agus a ionchódú. Rinne obair a rinneadh san am a chuaigh thart léiriúcháin BET don inniúlacht seo a thaiscéaladh, fuarthas amach gur féidir le BET hipearainmneacha ainmfhocail a aisghabháil i gceart i dtascanna cloze. Sa saothar seo, cuirimid an cheist: an dtugann staidéir scrúdaithe solas ar eolas córasach i léiriúcháin CRET? Mar chás-staidéar, scrúdaímid eolas hipearnach atá ionchódaithe i n-ionadaíochtaí CRET. Léirímid go háirithe trí thaiscéalaí comhsheasmhachta simplí nach ionann an cumas hipirtainmneacha i dtascanna cloze a aisghabháil i gceart, mar a úsáideadh in obair roimhe seo, d'eolas córasach in BERT. Is é ár bpríomhchonclúid aireach: fiú má léiríonn CRET cruinneas ard fiosrúcháin maidir le hinniúlacht ar leith, ní gá go leanann sé go dtuigeann CRET coincheap, agus ní féidir a bheith ag súil go ndéanfaidh sé ginearálú córasach ar fud na gcomhthéacsanna infheidhmithe.", 'el': 'Οι αναπαραστάσεις λέξεων έχουν γίνει κινητήρια δύναμη στο ΝΛΠ, κινητοποιώντας το ευρύ ενδιαφέρον για την κατανόηση των δυνατοτήτων τους και των μηχανισμών με τους οποίους λειτουργούν. Ιδιαίτερα ενδιαφέρουσα είναι η ικανότητά τους να εντοπίζουν και να κωδικοποιούν εννοιολογικές αφηγήσεις. Οι προηγούμενες εργασίες έχουν διερευνήσει τις αναπαραστάσεις του BERT για αυτή την ικανότητα, διαπιστώνοντας ότι ο BERT μπορεί να ανακτήσει σωστά τα υπερνύματα ουσιαστικών σε εργασίες cloze. Σε αυτή την εργασία, θέτουμε το ερώτημα: οι ερευνητικές μελέτες ρίχνουν φως στη συστηματική γνώση στις αναπαραστάσεις του BERT; Ως μελέτη περίπτωσης, εξετάζουμε τη γνώση υπερνύμων κωδικοποιημένη σε αναπαραστάσεις BERT. Ειδικότερα, καταδεικνύουμε μέσω ενός απλού καθετήρα συνέπειας ότι η ικανότητα ορθής ανάκτησης υπερνύμων σε εργασίες κλεισίματος, όπως χρησιμοποιήθηκε σε προηγούμενες εργασίες, δεν αντιστοιχεί στη συστηματική γνώση του BERT. Το κύριο συμπέρασμά μας είναι προειδοποιητικό: ακόμη και αν ο BERT επιδεικνύει υψηλή ακρίβεια ανίχνευσης για μια συγκεκριμένη ικανότητα, δεν συνεπάγεται απαραίτητα ότι ο BERT "κατανοεί" μια έννοια, και δεν μπορεί να αναμένεται να γενικεύσει συστηματικά σε όλα τα ισχύοντα πλαίσια.', 'hu': 'A kontextualizált szóreprezentációk hajtóerővé váltak az NLP-ben, és széles körű érdeklődést indítottak a képességeik és a működésük mechanizmusainak megértése iránt. Különösen érdekes a fogalmi absztrakciók azonosítására és kódolására irányuló képességük. A korábbi munkák megvizsgálták a BERT reprezentációit e kompetenciával kapcsolatban, és megállapították, hogy a BERT helyesen tudja visszaszerezni a főnévhipernímeket a lezárási feladatokban. Ebben a munkában azt a kérdést teszük fel, hogy vajon a mérővizsgálati tanulmányok világítanak-e a BERT reprezentációinak szisztematikus ismereteire? Esettanulmányként vizsgáljuk a BERT reprezentációkban kódolt hipernímia ismereteket. Különösen egy egyszerű következetességi vizsgálat segítségével bizonyítjuk, hogy az előző munkák során használt hipernímek helyes visszanyerésének képessége nem felel meg a BERT szisztematikus ismereteinek. Fő következtetésünk figyelmeztető: még ha a BERT egy adott kompetencia tekintetében is nagy mérési pontosságot mutat, nem feltétlenül következik, hogy a BERT "megért" egy koncepciót, és nem várható el, hogy rendszeresen általánosítsa az alkalmazandó kontextusokat.', 'ka': "კონტექსტუალური სიტყვების გამოსახულებები NLP-ში მოტივირთებული სიტყვების ძალია, რომელიც მუშაობენ უფრო დიდ ინტერესტის შესაძლებლობას და მექანესების გამოსახულებ სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა. პირველი სამუშაო მუშაო BERT-ს გამოყენება ამ კომპენტებისთვის, რომელიც BERT-ს შეუძლია წესიერად მიიღოთ სამუშაო ჰიპერნიმები კოლოზის დავალებში. ამ სამუშაოში, ჩვენ კითხვაზე ვკითხებთ: პრობენტის სწავლებაში სისტემატიკური ცნობიერება BERT-ს გამოსახულებაში იქნება? როგორც სწავლად, ჩვენ ვხედავთ ჰიპერნიმური ცოდნა, რომელიც BERT-ში კოდირებულია. განსაკუთრებულია, ჩვენ განვიცნობით საუკეთესო კონსტენსტიური პრობენტის გამოყენება, რომ საუკეთესო კონსტენმის შესაძლებლობა, როგორც საუკეთესო სამუშაოში გამოყენებული, არ ჩვენი მნიშვნელოვანი გადასრულება იქნება: თუ BERT-ს განსაკუთრებული კონტექსტისთვის უფრო დიდი პრობენტის სიმართლეობა, ის არ უნდა გადასრულება, რომ BERT-ს `უნდა გასრულებს' კონტექსტის შესახებ, და არ შეი", 'it': 'Le rappresentazioni contestualizzate delle parole sono diventate una forza trainante nel PNL, motivando un interesse diffuso nella comprensione delle loro capacità e dei meccanismi con cui operano. Particolarmente intrigante è la loro capacità di identificare e codificare astrazioni concettuali. Il lavoro passato ha sondato le rappresentazioni BERT per questa competenza, scoprendo che BERT è in grado di recuperare correttamente gli ipernomi dei sostantivi nelle attività di cloze. In questo lavoro, ci poniamo la domanda: gli studi sondanti fanno luce sulla conoscenza sistematica nelle rappresentazioni BERT? Come caso di studio, esaminiamo la conoscenza dell\'ipernimia codificata nelle rappresentazioni BERT. In particolare, dimostriamo attraverso una semplice sonda di coerenza che la capacità di recuperare correttamente gli ipernimi nelle attività di cloze, come utilizzato nei lavori precedenti, non corrisponde alla conoscenza sistematica in BERT. La nostra conclusione principale è cautelare: anche se BERT dimostra un\'elevata precisione di prova per una particolare competenza, non ne consegue necessariamente che BERT "capisce" un concetto e non ci si può aspettare che generalizzi sistematicamente in tutti i contesti applicabili.', 'kk': "Контекстуалды сөздерді түсіндіру күшін NLP-де жұмыс істеу күшін болды, олардың мүмкіндіктерін және жұмыс істеу механизмтерін түсіндіру үшін көпшілікті қызықты түсіндіреді Олардың концептуалды абстракцияларды анықтау және кодтау мүмкіндігі. Бірінші жұмыс БЕРТ деген көмекшілік үшін берттеулерді тексерді, BERT тапсырмаларды қалау тапсырмаларында атау гипернимдерді дұрыс алуға болады. Бұл жұмыста біз сұрақ береміз: зерттеу зерттеулері BERT келтірімдерінде жүйелік білім туралы жарықтығын жасайды ба? Бір жағдай зерттеу үшін біз BERT дегенде кодталған гипернимнің білімін тексереміз. Әрине біз өткен жұмыстың алдыңғы жұмысында қолданылған сияқты білімге сәйкес келмейді. Біздің негізгі шешіміміз - ескертуіміз: егер BERT белгілі көмектесу үшін жоғары тәжірибесінің дұрыстығын көрсетілсе де, BERT 'түсінеміз' деген концепциясын қабылдамайды, жүйелікті жалпы тәжірибелерді жалпы тү", 'mk': 'Контекстуалните претставувања на зборови станаа движечка сила во НЛП, мотивирајќи го широкиот интерес за разбирање на нивните способности и механизмите со кои тие функционираат. Особено интересно е нивната способност да идентификуваат и кодираат концептуални апстракции. Претходната работа ги провери претставувањата на БЕРТ за оваа надлежност, откривајќи дека БЕРТ може правилно да ги врати имените хиперними во завршувањето на задачите. Во оваа работа, го поставуваме прашањето: дали истражувањето на студиите објаснува систематско знаење во претставувањата на БЕРТ? Како случајна студија, го испитуваме знаењето за хипернимија кодирано во BERT претставувања. Посебно, ние демонстрираме преку едноставна константна истрага дека способноста за правилно обезбедување хиперними во завршувањето на задачите, како што се користи во претходната работа, не одговара на систематското знаење во БЕРТ. Нашиот главен заклучок е претпазливо: дури и ако БЕРТ покаже висока прецизност на истражување за одредена надлежност, не мора да следи дека БЕРТ „разбира“ концепт, и не може да се очекува систематски да се генерализира во соодветните контексти.', 'lt': 'Sudėtinis žodžių atstovavimas tapo NLP varomąja jėga ir paskatino plačiai susidomėti jų gebėjimais ir mechanizmais, kuriais jie veikia. Ypač įdomi jų gebėjimas nustatyti ir koduoti koncepcines abstrakcijas. Past work has probed BERT representations for this competence, finding that BERT can correctly retrieve noun hypernyms in cloze tasks.  Šiame darbe užduodame klausimą: ar tyrimai rodo sistemines žinias BERT atstovybėse? Kaip atvejų tyrimas, mes išnagrinėjame hipernimijos žinias, koduotas BERT atstovybėse. Visų pirma per paprastą nuoseklumo sondą įrodome, kad gebėjimas tinkamai surinkti hiperinimus užduodant užduotis, kaip buvo naudojama ankstesniame darbe, neatitinka sisteminių žinių BERT srityje. Mūsų pagrindinė išvada yra atsargi: net jei BERT įrodo didelį konkrečios kompetencijos tyrimo tikslumą, nebūtinai atsiranda dėl to, kad BERT „supranta“ koncepciją, ir negalima tikėtis, kad ji sistemingai apskritai apskritai bus taikoma.', 'ms': "Perwakilan perkataan konteks telah menjadi kekuatan pemandu dalam NLP, yang mendorong kepentingan luas dalam memahami kemampuan mereka dan mekanisme yang mereka beroperasi. Terutama menarik adalah kemampuan mereka untuk mengenalpasti dan mengekodkan abstraksi konseptual. Kerja lepas telah menguji perwakilan BERT untuk kemampuan ini, mencari bahawa BERT boleh mendapatkan nama hipernim dengan betul dalam tugas penutup. Dalam kerja ini, kami bertanya soalan: adakah penyelidikan kajian memberi cahaya kepada pengetahuan sistemik dalam perwakilan BERT? Sebagai kajian kes, kami memeriksa pengetahuan hipernimi yang dikodifikasi dalam perwakilan BERT. Secara khususnya, kita menunjukkan melalui sond kesistensi sederhana bahawa kemampuan untuk mendapatkan hipernim dengan betul dalam tugas penutup, seperti yang digunakan dalam kerja sebelumnya, tidak sepadan dengan pengetahuan sistemik dalam BERT. Kesimpulan utama kami adalah peringatan: walaupun BERT menunjukkan ketepatan penyelidikan tinggi untuk keterampilan tertentu, ia tidak perlu mengikut bahawa BERT `faham' konsep, dan ia tidak boleh dijangka untuk secara sistematik menyeluruh konteks yang berlaku.", 'mt': "Ir-rappreżentazzjonijiet tal-kliem kuntestwalizzati saru forza ta’ xprun fl-NLP, li jimmotivaw interess mifrux fil-fehim tal-kapaċitajiet tagħhom u l-mekkaniżmi li bihom joperaw. Partikolarment interessanti hija l-kapaċità tagħhom li jidentifikaw u jikkodifikaw l-astrazzjonijiet kunċettwali. Xogħol fil-passat eżamina r-rappreżentazzjonijiet tal-BERT għal din il-kompetenza, u sab li l-BERT jista’ jirkupra b’mod korrett l-iperinimi ta’ l-ismijiet f’kompiti ta’ għeluq. F’din il-ħidma, nistaqsu l-mistoqsija: jekk l-istudji dwar is-sonda jagħtux dawl fuq l-għarfien sistematiku fir-rappreżentazzjonijiet tal-BERT? Bħala studju ta’ każ, jeżaminaw l-għarfien dwar l-ipernimija kkodifikat fir-rappreżentazzjonijiet BERT. B’mod partikolari, nagħmlu evidenza permezz ta’ sonda sempliċi ta’ konsistenza li l-kapaċità li tinkiseb b’mod korrett iperinimi f’kompiti ta’ għeluq, kif użat f’xogħol preċedenti, ma tikkorrispondix ma’ għarfien sistematiku fil-BERT. Our main conclusion is cautionary: even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT `understands' a concept, and it cannot be expected to systematically generalize across applicable contexts.", 'ml': "വാക്കുകളുടെ പ്രതിനിധികള്\u200d NLP യില്\u200d ഒരു ഡ്രൈവിങ്ങ് ശക്തിയായി തീര്\u200dന്നിരിക്കുന്നു. അവരുടെ കഴിവും അവര്\u200d പ്രവര്\u200dത്തിക്കുന്ന മെക്കിന പ്രത്യേകിച്ച് ആശ്ചര്യപ്പെടുത്തുന്നത് അവരുടെ ആശയം കണ്ടുപിടിക്കാനും കോഡിപ്പിക്കാനും കഴിവാണ്. കഴിഞ്ഞ ജോലിയില്\u200d ബെര്\u200dട്ടിന്റെ പ്രതിനിധികള്\u200d ഈ അധികാരത്തിനുള്ള പ്രതിനിധികള്\u200d നിര്\u200dണ്ണയിച്ചിരിക്കുന്നു. ബെര്\u200dട്ടിന്  ഈ ജോലിയില്\u200d നമ്മള്\u200d ചോദ്യം ചോദിക്കുന്നു: പഠനങ്ങള്\u200d പരിശോധിക്കുന്നത് ബെര്\u200dട്ടിയുടെ പ്രതിനിധികളില്\u200d സിസ് ഒരു കേസിന്റെ പഠനത്തില്\u200d ഞങ്ങള്\u200d ബെര്\u200dട്ടി പ്രതിനിധികളില്\u200d ഉള്ള ഹൈപ്പരെനിമി അറിവ് പരിശോധിക്കുന്നു. പ്രത്യേകിച്ച്, നമ്മള്\u200d ഒരു സാധ്യതയുള്ള പരീക്ഷണത്തിലൂടെ കാണിച്ചുകൊണ്ടിരിക്കുന്നു, ക്ലോസ് ജോലികളില്\u200d ഹൈപ്പെര്\u200dണിമിനെ ശരിയായി വീണ്ടെടു നമ്മുടെ പ്രധാനപരിഹാരം മുന്നറിയിപ്പാണ്: ബെര്\u200dട്ടി പ്രത്യേകിച്ചുള്ള അധികാരത്തിന് ഉയരത്തില്\u200d കൂടുതല്\u200d പരിശോധിപ്പിക്കുന്നുവെങ്കിലും, ബെര്\u200dട്ടിയുടെ 'ബെര്\u200dട", 'mn': 'Төвчнөөс илэрхийлэгдсэн үг нь NLP-д маш хөдөлгөөнтэй хүч болж, тэдний үйлдвэрлэх чадвар болон механизмуудыг ойлгохын тулд их сонирхолтой болсон. Ялангуяа сонирхолтой нь тэдний ойлголтын алдагдлыг тодорхойлох боломжтой. Өмнөх ажил нь БЕРТ-ын өрсөлдөөнийг судалсан бөгөөд БЕРТ-ын дарааллын гиперним ажиллагаанд зөв хэвлэх боломжтой гэдгийг олж мэдсэн. Энэ ажил дээр бид асуулт асууж байна: Судалгааны судалгаа БЕРТ-ын систематикийн мэдлэг дээр гэрэл гаргаж байна уу? Жишээлбэл бид BERT-ын илтгэлийн шинжлэх ухааныг судалж байна. Ялангуяа бид өмнөх ажлын хувьд хэрэглэгдсэн шиг систематикийн мэдлэгтэй холбоотой гэдгийг энгийн тогтвортой тодорхойлолтоор харуулж байна. Бидний хамгийн гол шалтгаан нь ухамсартай: БЕРТ тодорхой чадварын тулд өндөр судалгааны тодорхойлолтыг харуулж байгаа ч, БЕРТ "ойлгох" тодорхойлолтыг дагах ёстой биш, мөн энэ тодорхойлолтой байдлаар систематик ерөнхийлөгчилж чадахгүй.', 'no': 'Kontekstualiserte ordrepresentasjonar har blitt ein kjøringskraft i NLP, som motiverer breidde interesse for å forstå dei kapasitetene og mekanismene dei fungerer med. Spesielt interessant er at dei kan identifisera og koda konseptuelle abstraksjonar. Følgjande arbeid har prøvd BERT-representasjonar for denne kompetansen, og finn at BERT kan rett henta namn hypernymar i klose oppgåver. I denne arbeiden spør vi spørsmålet: Skal proberingsstudier gjere lys på systematisk kunnskap i BERT-representasjonar? Som ein tilfeldige studie undersøker vi hypernymisk kunnskap kodert i BERT-representasjonar. I særskilt viser vi gjennom ein enkel konsistensingsprobe at kapasiteten til å henta riktig hypernim i klose oppgåver, som brukt i førre arbeid, ikkje tilsvarar systematisk kunnskap i BERT. Vår hovudkonklusjon er varslig: selv om BERT viser høg proberingsakkurat for ein bestemt kompetanse, følgjer det ikkje nødvendig at BERT «forstår» ein konsept, og det kan ikkje forventast å systematisk generalisere gjennom tilgjengelege kontekstar.', 'pl': 'Kontekstualizowane reprezentacje słów stały się siłą napędową NLP, motywując szerokie zainteresowanie zrozumieniem ich możliwości i mechanizmów działania. Szczególnie intrygująca jest ich zdolność identyfikowania i kodowania abstrakcji koncepcyjnych. Poprzednie prace badały reprezentacje BERT dla tej kompetencji, stwierdzając, że BERT może poprawnie pobierać hipernimy rzeczownika w zadaniach cloze. W niniejszej pracy zadajemy pytanie: czy badania sondowe rzucają światło na systematyczną wiedzę w reprezentacjach BERT? W ramach studium przypadku badamy wiedzę hipernimii zakodowaną w reprezentacjach BERT. W szczególności poprzez prostą sondę konsystencyjną wykazujemy, że zdolność prawidłowego pobierania hipernimów w zadaniach cloze, jak wykorzystywana w poprzednich pracach, nie odpowiada systematycznej wiedzy w BERT. Nasz główny wniosek jest ostrzeżeniem: nawet jeśli BERT wykazuje wysoką dokładność sondowania dla konkretnej kompetencji, niekoniecznie oznacza to, że BERT "rozumie" koncepcję i nie można oczekiwać, że będzie systematycznie uogólniał się we wszystkich stosownych kontekstach.', 'ro': 'Reprezentările cuvintelor contextualizate au devenit o forță motrice în PNL, motivand interesul larg în înțelegerea capacităților și mecanismelor prin care operează. În mod deosebit de intrigant este capacitatea lor de a identifica și codifica abstracțiile conceptuale. Lucrările anterioare au verificat reprezentările BERT pentru această competență, constatând că BERT poate recupera corect hipernimele substantivelor în activitățile de blocare. În această lucrare, ne punem întrebarea: studiile sondării pun lumină asupra cunoștințelor sistematice în reprezentările BERT? Ca studiu de caz, examinăm cunoștințele de hipernimie codificate în reprezentările BERT. În special, demonstrăm printr-o simplă sondă de consistență că capacitatea de a recupera corect hipernime în sarcinile de blocare, așa cum este folosită în lucrările anterioare, nu corespunde cunoștințelor sistematice din BERT. Concluzia noastră principală este atenționată: chiar dacă BERT demonstrează o precizie ridicată a sondării pentru o anumită competență, nu rezultă neapărat că BERT "înțelege" un concept și nu se poate aștepta să generalizeze sistematic în contextele aplicabile.', 'so': "Aqoonshaha hadalka la xiriiray waxay noqdeen xoog wadista NLP, kaasoo ku hagaya xiiso aad u ballaadhan inaad fahanto awoodooda iyo meymisyada ay ku shaqeeyaan. Si gaar ah waxyaabaha aad xiiseyso waa awooddooda ay aqoonsadaan oo ay koobi karto go'aanka fikrada. Shaqo dambe wuxuu soo bandhigay wakiilada BERT ee aqoontan, wuxuuna ogaanayaa in BERT si hagaagsan ugu soo celin karo hawlaha qabsashada. Shuqulkaas waxaynu su'aalaha ka weydiinaa: Waxbarashada baaritaanka ma fududeeyaa aqoonta systemiga ah ee ku qoran xarumaha BERT? As a case study, we examine hypernymy knowledge encoded in BERT representations.  Si gaar ah, waxaynu muujinnaa caddeynta ku sahlan in awoodka aad si saxda ah u soo qaadan karto shaqooyinka kooxaha, sida horay loo isticmaalay, uusan u dhigin aqoonta nidaamka ah ee BERT. Qoraalka ugu horeeya waa digtoonaan: xitaa haddii BERT uu muujiyo saxda aad u saxda aqoonta gaar ah, ma raaco qasab ah in BERT `ay fahantaa fikrada, kamana suurtowdo in si koox ah loo soo bandhiyo xilliyada lagu habboon.", 'sr': 'Kontekstualizirani predstavnici reči postali su vozačka snaga u NLP-u, motivirajući široki interes u razumijevanju njihovih sposobnosti i mehanizma s kojim oni rade. Posebno interesantno je njihova sposobnost da identifikuju i kodiraju konceptualne apstrakcije. Poslednji rad je probao predstave BERT-a za ovu kompetenciju, otkrivajući da BERT može ispravno izvesti hipernimu imena u zadatku kloziranja. U ovom poslu postavljamo pitanje: da li ispitivanje istraživanja proizvodi svjetlo sistematsko znanje u predstavljanju BERT-a? Kao studija slučajeva, pregledamo hipernimu znanje kodirano u predstavljanju BERT-a. Posebno, mi pokazujemo prostom sondom konsistencije da sposobnost da ispravno uzmemo hipernimu u kloziranim zadacima, kao što je koristila u prethodnom poslu, ne odgovara sistematskim znanjem u BERT-u. Naš glavni zaključak je pažljiv: čak i ako BERT pokaže veliku tačnost istraživanja za određenu kompetenciju, ne mora da prati da BERT "razumije" koncept, i ne može se očekivati da će sistematički generalizirati u prikladnim kontekstima.', 'sv': 'Kontextualiserade ordrepresentationer har blivit en drivkraft i NLP, vilket motiverar ett brett intresse för att förstå deras förmåga och mekanismer genom vilka de arbetar. Särskilt intressant är deras förmåga att identifiera och koda konceptuella abstraktioner. Tidigare arbete har undersökt BERT-representationer för denna kompetens och funnit att BERT korrekt kan hämta substantivhypernymer i cloze-uppgifter. I detta arbete ställer vi oss frågan: belyser sondstudier systematisk kunskap i BERT-representationer? Som fallstudie undersöker vi hypernymykunskaper kodade i BERT-representationer. I synnerhet visar vi genom en enkel konsekvenssond att förmågan att korrekt hämta hypernymer i cloze uppgifter, som används i tidigare arbete, inte motsvarar systematisk kunskap i BERT. Vår huvudsakliga slutsats är försiktig: även om BERT visar hög noggrannhet för en viss kompetens, följer det inte nödvändigtvis att BERT "förstår" ett koncept, och det kan inte förväntas systematiskt generalisera över tillämpliga sammanhang.', 'si': 'සම්බන්ධ වචන ප්\u200dරතිනිධානයක් NLP වල ප්\u200dරතිනිධානයක් වෙලා තියෙනවා, ඔවුන් ප්\u200dරතිනිධානය කරනවා ඔවුන්ගේ සක්ෂමතාවක විශේෂයෙන්ම ප්\u200dරශ්නයක් තමයි ඔවුන්ගේ ප්\u200dරශ්නයක් පරික්ෂා කරන්න සහ සංකේතනය කරන්න. පස්සේ වැඩේ BERT ප්\u200dරතිනිධානයක් මේ ප්\u200dරයෝජනය වෙනුවෙන් පරීක්ෂා කරලා තියෙනවා, BERT එක හොයාගන්න පුළුවන් හැකියාව හ මේ වැඩේ අපි ප්\u200dරශ්නයක් අහනවා: පරීක්ෂණය බෙර්ට් ප්\u200dරශ්නයේ පද්ධතිය දන්නවල් පරීක්ෂණයේ ආලෝකය ප්\u200d කේස් පරීක්ෂණයක් විදියට, අපි බර්ට් ප්\u200dරතිනිධානයක් තියෙන්නේ හායිපර්නිමි දැනගන්න. විශේෂයෙන්, අපි ප්\u200dරකාශ කරනවා සරල සාමාන්\u200dය සාමාන්\u200dය සංවේදනයක් නිසා ක්\u200dලෝස් වැඩේ හායිපර්නිම් ප්\u200dරකාශ කරගන්න පුළුවන් කියලා අපේ ප්\u200dරධාන අවස්ථාවක් අවස්ථාවක්: BERT විශේෂ ප්\u200dරධානයක් විශේෂ විශේෂ විශේෂ වෙනුවෙන් හොඳ ප්\u200dරධානයක් පෙන්වන්නත්, ඒක අවස්ථාවක් නෑ BE', 'ta': "சூழலாக்கப்பட்ட வார்த்தை பிரதிநிர்வாக்குகள் NLP ல் ஒரு இயக்கி சக்தி ஆகிவிட்டது, அகலமான வட்டியை புரிந்து கொள்ளும் அவர்கள் செயல்படும குறிப்பாக சுவாரஸ்யம் அவர்களுடைய கண்டுபிடிப்பு மற்றும் குறியீட்டு செய்ய அவர்களுடைய சக்தி முந்தைய வேலை இந்த தொகுதிக்கான பிரெட் பிரிட் பிரதிநிதிகளை குறிக்கிறது, BERT சரியாக முடியும் என்று கண்டுபிடித்து கொண் இந்த வேலையில் நாம் கேள்வியை கேட்கிறோம்: படிப்புகள் பரிசோதித்து BERT குறிப்பிடுகளில் அமைப்பில் அறிவு  ஒரு விஷயத்தின் படிப்பாடு என்றால், நாம் BERT பிரதிநிதிகளில் குறிப்பிடப்பட்ட உயர்ந்த அறிவை பரிசோதிக் குறிப்பிட்டு, நாம் ஒரு சுலபமான ஒற்றைப்படையான தெளிவாக்கி காட்டுகிறோம் என்றால், குளோஸ் பணிகளில் சரியாக மீட்டெடுக்க முடியும் ஆற்றல் மூலம எங்கள் முக்கிய முடிவு எச்சரிக்கையாகும்: பிரெட் குறிப்பிட்ட திட்டத்திற்கு உயர்நிலையை காட்டுகிறது என்றாலும் அது பிரெட் 'புரிந்து கொள்ளும்' என்று பின்பற்றா", 'ur': "ان کے قابلیت اور مکانیزوں کو سمجھنے کے لئے زیادہ وسیع علاقه مند ہونے کے لئے NLP میں چلنے والی قوت ہوگئی ہے۔ مخصوصاً اہم بات یہ ہے کہ ان کے قابل پہچان کرنا اور کوڈ کرنا ہے. اگلے کام نے BERT کی نمونات کو اس کام کے لئے تحقیق کر دیا ہے، اس کے پیدا ہونے کے لئے BERT کو سیدھی طرح اپنا نوم ہیرنیم حاصل کرسکتا ہے۔ ہم اس کام میں سوال کرتے ہیں: کیا تحقیقات کی تحقیقات بتائی گئی ہے کہ BERT کی سیستمائی علم پر روشنی ہے؟ ایک مطالعہ کے طور پر، ہم نے BERT نمونات میں سیدھا علم تحقیق کیا ہے. مخصوصاً ہم ایک سادھی سادھی ثابت کے ذریعے دکھاتے ہیں کہ کلوز کے کاموں میں ہیرنیم کو درست اٹھانے کی قابلیت، جیسا پہلے کام میں استعمال کیا گیا ہے، BERT میں سیستمی علم کے مطابق نہیں ہے. ہماری اصلی نتیجہ حفاظت کرنے والی ہے: اگرچہ BERT ایک مخصوص مستقل کے لئے بلند محبوب دقیق دکھائے گی، اس کا اتباع نہیں کرتا کہ BERT 'سمجھتا' ایک منظور ہے، اور اس کا انتظار نہیں ہوتا کہ اسے سیستماتیک طور پر قابل تحقیق کرے۔", 'uz': 'Name Ko\'rinishini ham qiziqarish bu fikrlarni aniqlash va kodlash qobiliyati. Oxirgi vazifa bu vazifalarga BERT tashkilotlarini aniqlash mumkin. BERT toʻgʻri vazifalarga hech qanday hypernimni olib tashlashi mumkin. Bu vazifanda, biz savol qilamiz: o\'qituvchilarni tizim qilish BERT tashkilotlaridagi tizim ilimni ko\'rsatadi? Masalan o\'rganishda biz BERT tashkilotlarida ko\'paytirilgan hypernity aniqlarni ko\'rib chiqaramiz. Ko\'rsatganda, biz oddiy birlik tizim haqida ko\'rsatganimiz mumkin, boshqa vazifani to ʻgʻri aniqlash imkoniyatini o\'zgartirish imkoniyatini hozir qildik, avval ishda ishlatilganligini saqlash imkoniyatini bajarishimiz mumkin, BERT\'da tizim maʼlumot ber Bizning asosiy muvaffaqiyatlarimiz taqdimiz: agar BERT foydalanuvchi darajasida juda yaxshi tizimni ko\'rsatadi, balki bu "BERT" g\'oyaniga tushunishi kerak emas, va bu tizimda qo\'llab boʻladigan xizmatlarni boshqarishi mumkin emas.', 'vi': 'Các biểu hiện từ ngữ được sắp xếp đã trở thành một lực thúc đẩy trong lập trường New York, thúc đẩy sự quan tâm phổ biến về khả năng của họ và các cơ chế mà họ hoạt động. Đặc biệt hấp dẫn là khả năng xác định và mã hóa các trừu tượng. Quá khứ đã thăm dò các biểu tượng của BERT cho năng lực này, phát hiện ra rằng BERT có thể lấy lại các tên gọi trong các nhiệm vụ Cloze. Trong công việc này, chúng tôi đặt câu hỏi là: nghiên cứu thăm dò có làm sáng tỏ kiến thức có hệ thống ở các diễn biến BERT không? Để nghiên cứu các trường hợp, chúng tôi nghiên cứu các học thức siêu nữ được mã hóa ở các biểu tượng BERT. Chúng tôi đặc biệt chứng minh qua một điều tra độ sánh đơn giản rằng khả năng lấy các siêu mê trong các công việc đồng tính, được dùng trong các công việc trước, không tương ứng với kiến thức có hệ thống ở BERT. Kết luận quan trọng của chúng ta là cảnh báo: ngay cả khi BERT thể hiện sự chính xác sâu sắc trong khả năng đặc biệt, nó không nhất thiết phải hiểu được một khái niệm, và không thể diễn ra liên tục rộng rãi trong mọi tình huống phù hợp.', 'bg': 'Контекстualiзираните словни представи се превърнаха в движеща сила в НЛП, мотивирайки широк интерес към разбирането на техните способности и механизми, чрез които те работят. Особено интригуваща е способността им да идентифицират и кодират концептуални абстракции. Миналата работа изследва представителствата на BERT за тази компетентност, като установява, че BERT може правилно да извлича хиперними на съществителни в задачите за блокиране. В тази работа задаваме въпроса: пробните изследвания хвърлят ли светлина върху систематичното знание в представителствата на БЕРТ? Като казус изследваме знанието за хипернимията, кодирано в репрезентациите на БЕРТ. По-специално, ние демонстрираме чрез проста консистенция сонда, че способността за правилно извличане на хиперними при задачи по клозиране, както е използвана в предишна работа, не съответства на систематичните знания в БРТ. Основното ни заключение е предупредително: дори ако BERT демонстрира висока точност на сондиране за определена компетентност, не следва непременно, че BERT "разбира" дадена концепция и не може да се очаква систематично да се обобщава в приложимите контексти.', 'hr': 'Kontekstualizirani predstavnici riječi postali su vozačka snaga u NLP-u, motivirajući široki interes u razumijevanju njihovih sposobnosti i mehanizma s kojim oni rade. Posebno interesantno je njihova sposobnost identificiranja i kodiranja konceptualnih apstrakcija. Posljednji rad je ispitivao predstave BERT-a za ovu kompetenciju, otkrivajući da BERT može ispravno izvući hipernimu imena u zadatku kloziranja. U ovom poslu postavljamo pitanje: da li ispitivanje ispitivanja proizvodi svjetlo sistematsko znanje u predstavljanju BERT-a? Kao istraživanje slučajeva, pregledamo hipernimu znanje kodirano u predstavljanju BERT-a. Posebno, mi pokazujemo jednostavnom sondom konsistencije da sposobnost ispravno povlačenja hipernima u zadatkima kloziranja, kao što se koristi u prethodnom poslu, ne odgovara sistematskim znanjem u BERT-u. Naš glavni zaključak je pažljiv: čak i ako BERT pokazuje veliku to čnost istraživanja za određenu kompetenciju, ne mora se morati pratiti da BERT "razumije" koncept, a ne može se očekivati da će sistematski generalizirati u primjenjivim kontekstima.', 'nl': "Gecontextualiseerde woordrepresentaties zijn uitgegroeid tot een drijvende kracht in NLP, die wijdverbreide belangstelling wekt voor het begrijpen van hun capaciteiten en de mechanismen waarmee ze werken. Bijzonder intrigerend is hun vermogen om conceptuele abstracties te identificeren en te coderen. In het verleden zijn BERT-representaties onderzocht voor deze competentie, waarbij werd geconstateerd dat BERT-hyperniemen correct kan ophalen in cloze-taken. In dit werk stellen we de vraag: werpen soning studies licht op systematische kennis in BERT representaties? Als casestudy onderzoeken we hyperniemiekennis gecodeerd in BERT-representaties. Met name laten we aan de hand van een eenvoudige consistentiesonde zien dat de mogelijkheid om hyperniemen correct op te halen in cloze taken, zoals gebruikt in eerdere werkzaamheden, niet overeenkomt met systematische kennis in BERT. Onze belangrijkste conclusie is waarschuwend: zelfs als BERT een hoge meetnauwkeurigheid voor een bepaalde competentie aantoont, betekent dit niet noodzakelijkerwijs dat BERT een concept 'begrijpt', en kan niet worden verwacht dat het systematisch generaliseert in alle toepasselijke contexten.", 'da': 'Kontekstualiserede ordrepræsentationer er blevet en drivkraft i NLP, der motiverer udbredt interesse i at forstå deres evner og mekanismer, hvormed de opererer. Særligt spændende er deres evne til at identificere og kode konceptuelle abstraktioner. Tidligere arbejde har undersøgt BERT repræsentationer for denne kompetence og fundet ud af, at BERT korrekt kan hente substantivhypernymer i cloze opgaver. I dette arbejde stiller vi spørgsmålet: kaster sonderingsundersøgelser lys over systematisk viden i BERT-repræsentationer? Som et casestudie undersøger vi hypernymi viden kodet i BERT-repræsentationer. Især demonstrerer vi gennem en simpel konsistensprove, at evnen til korrekt at hente hypernymer i cloze opgaver, som anvendes i tidligere arbejde, ikke svarer til systematisk viden i BERT. Vores hovedkonklusion er forsigtig: Selv om BERT viser høj sonderingsnøjagtighed for en bestemt kompetence, følger det ikke nødvendigvis, at BERT forstår et koncept, og det kan ikke forventes systematisk at generalisere på tværs af relevante sammenhænge.', 'de': 'Kontextualisierte Wortdarstellungen sind zu einer treibenden Kraft in NLP geworden und wecken ein breites Interesse daran, ihre Fähigkeiten und Mechanismen zu verstehen, mit denen sie arbeiten. Besonders faszinierend ist ihre Fähigkeit, konzeptuelle Abstraktionen zu identifizieren und zu kodieren. Vergangene Arbeiten haben BERT-Repräsentationen für diese Kompetenz untersucht und festgestellt, dass BERT Substantivhypernyme in Cloze-Aufgaben korrekt abrufen kann. In dieser Arbeit stellen wir die Frage: Erheben Sondierungsstudien Licht auf systematisches Wissen in BERT-Repräsentationen? Als Fallstudie untersuchen wir Hypernymiewissen, das in BERT-Darstellungen kodiert ist. Insbesondere zeigen wir durch eine einfache Konsistenzsonde, dass die Fähigkeit, Hypernyme in Cloze-Aufgaben korrekt abzurufen, wie sie in früheren Arbeiten verwendet wurden, nicht mit systematischem Wissen in BERT übereinstimmt. Unsere wichtigste Schlussfolgerung ist warnend: Auch wenn BERT eine hohe Messgenauigkeit für eine bestimmte Kompetenz aufweist, bedeutet dies nicht notwendigerweise, dass BERT ein Konzept "versteht", und es kann nicht erwartet werden, dass es systematisch über anwendbare Kontexte hinweg verallgemeinert wird.', 'id': "Perwakilan kata kontekstualisasi telah menjadi kekuatan mendorong di NLP, memotivasi ketertarikan luas dalam memahami kemampuan mereka dan mekanisme dengan mana mereka beroperasi. Terutama menarik adalah kemampuan mereka untuk mengidentifikasi dan mengkode abstraksi konseptual. Pekerjaan yang lalu telah memeriksa represensi BERT untuk kompetensi ini, menemukan bahwa BERT dapat dengan benar mengambil nama hypernym dalam tugas penutup. In this work, we ask the question: do probing studies shed light on systematic knowledge in BERT representations?  Sebagai penelitian kasus, kami memeriksa pengetahuan hipernim yang dikodeksi dalam representation BERT. Terutama, kita menunjukkan melalui probe konsistensi sederhana bahwa kemampuan untuk mendapatkan hipernim dengan benar dalam tugas penutup, seperti yang digunakan dalam pekerjaan sebelumnya, tidak sesuai dengan pengetahuan sistematis di BERT. Kesimpulan utama kami adalah peringatan: bahkan jika BERT menunjukkan akurasi penyelidikan tinggi untuk kompetensi tertentu, tidak perlu mengikuti bahwa BERT `mengerti' konsep, dan tidak dapat diharapkan untuk secara sistematis menyeluruhkan dalam konteks yang berlaku.", 'fa': 'نمایش\u200cنمایش\u200cهای کلمه متوسط به عنوان نیروی رانندگی در NLP تبدیل شده\u200cاند، که به سودی گسترده در درک توانایی\u200cهایشان و مکانیزم\u200cهایی که آنها با آن کار می\u200cکنند انگیز می\u200cکنند. خصوصاً علاقه\u200cمند کننده توانایی آنها برای شناسایی و رمزگذاری مفهوم است. کار گذشته نمایش\u200cهای BERT برای این مسابقه تحقیق کرده است، و پیدا کرده است که BERT می\u200cتواند به درستی هیپرنیم\u200cهای اسم را در وظیفه\u200cهای کلاه برگیرد. در این کار، ما سوال را می پرسیم: آیا تحقیقات تحقیقات روشنی بر روی علم سیستماتیک در نمایش های BERT است؟ به عنوان یک مطالعه پرونده، ما دانش hypernymy را در نمایش\u200cهای BERT تحقیق می\u200cکنیم. مخصوصا، ما از طریق یک امتحان ساده اتفاقی نشان می دهیم که توانایی به درستی بررسی hypernyms در وظیفه\u200cهایی که در کار قبلی استفاده می\u200cشود، با دانش سیستماتی در BERT ارتباط ندارد. نتیجه اصلی ما هشدار دهنده است: حتی اگر BERT دقیقات تحقیقات بالا را برای یک مسئله خاص نشان دهد، لازم نیست که BERT یک مفهوم درک کند، و نمی تواند انتظار داشته باشد که در موقعیت های موجود عمومی به صورت سیستماتیک تغییر دهد.', 'ko': '어경화 어휘 표징은 이미 NLP의 구동력이 되어 사람들이 그의 능력과 운영 메커니즘을 이해하는 데 광범위한 흥미를 불러일으켰다.특히 흥미로운 것은 그들이 개념을 식별하고 인코딩하는 추상적인 능력이다.과거의 연구는 이러한 능력의 베르토 표징을 탐색하여 베르토가 완형충전 임무에서 명사 초어를 정확하게 검색할 수 있음을 발견하였다.이 작업에서 우리는 탐구적 연구가 베르토 표징 중의 체계적인 지식을 밝히는 데 도움이 될 수 있느냐는 문제를 제기했다.사례 연구로서, 우리는 버트가 표시한 초어 지식을 인코딩하는 것을 연구했다.특히, 우리는 간단한 일치성 조사를 통해 완형 빈칸 채우기 작업에서 초어를 정확하게 검색하는 능력이 이전 작업에서 사용한 것처럼 BERT의 시스템 지식에 부합되지 않는다는 것을 증명하였다.우리의 주요 결론은 신중하다는 것이다. 설령 버트가 특정한 능력에 대해 높은 탐측 정확성을 나타낸다 하더라도, 버트가 하나의 개념을 이해했다는 것을 의미하는 것은 아니며, 그것이 적용되는 언어 환경에서 체계적으로 개괄되기를 기대할 수도 없다.', 'sw': 'Maandamano ya maneno yanayohusishwa yamekuwa nguvu ya ubadilishaji nchini NLP, yanayohamasisha maslahi makubwa ya kuelewa uwezo wao na mfumo ambao wanafanya kazi. Tafsiri ya kusisimua ni uwezo wao wa kutambua na kuingilia mawazo ya kujitegemea. Kazi za mwisho imeweka bayana wawakilishi wa BERT kwa ajili ya ushirikiano huu, na kutambua kuwa BERT anaweza kupata vifaa vya kutosha vizuri katika kazi za kufunga. Katika kazi hii, tunauliza swali: tafiti zinazothibitisha mwanga wa maarifa ya mfumo katika uwakilishi wa BERT? Kama utafiti wa kesi, tunachunguza maarifa ya juu yaliyojumuisha katika wakilishi wa BERT. Kwa hakika, tunaonyesha kupitia ushahidi rahisi unaoendelea kuwa uwezo wa kupata mipango sahihi katika kazi za mapumziko, kama ilivyotumiwa kabla, haujajibu maarifa ya mfumo huko BERT. Matokeo yetu ya msingi ni tahadhari: hata kama BERT inaonyesha ukweli wa juu kwa utawala maalum, haina lazima kufuatia dhana ya ‘BERT’ inayoelewa, na haiwezi kutarajiwa kuzalisha kwa mfumo mzima katika matatizo yanayotumika.', 'tr': "NLP'de bölegi görkezilýän sözler ýagdaýda sürüjili güýçli bolup geçdi we olaryň işleýän mekanizmalaryny düşünmekde gaty gyzyklanýar. Aýratyn bilen nähili gyzykly görnüş ýüzlerini tanamak we kodlamak ukypdyr. BERT'iň öňki işi bu terjime üçin BERT suratlaryny bardyr. BERT'iň takyk işlerinde isim hipernimi dogry almagy mümkin edip biler. Bu işte soruyoruz: araştırmalar BERT'deki sistematik bilgi üzerinde ışık yaratır mı? BERT ködlemelerinde kodlanýan hipernimi bilgileri bardyk. Öňki işde ullanýan ýaly hipernimiň kloz täbliklerinde dogry alma ukyplaryny görkezýäris. BERT'da sistematik bilgiňe täsirli däl. Biziň esasy çözümlerimiz duýdury: BERT has be ýleki çykyşymyz üçin ýokary synaglamasynyň dogrylygyny görkezän bolsa bile, BERT 'düşünýän' bir düşünjegiňi boýun getirmeýän däldir we olar sistematik ýagdaýda işlenýän şartlaryň içine ýokary däldir.", 'sq': "Përfaqësuesit e fjalëve të kontekstuar janë bërë një forcë nxitëse në NLP, duke motivuar interesin e përhapur në kuptimin e aftësive të tyre dhe mekanizmave me të cilat ata veprojnë. Veçanërisht interesante është aftësia e tyre për të identifikuar dhe koduar abstrakcionet konceptuale. Puna e kaluar ka vëzhguar përfaqësimet e BERT për këtë kompetencë, duke gjetur se BERT mund të marrë saktësisht emra hiperinime në detyrat e mbylljes. Në këtë punë, ne bëjmë pyetjen: a studimet tregojnë dritë mbi njohuritë sistematike në përfaqësimet e BERT? Si një studim rasti, ne shqyrtojmë njohurinë e hipernimisë të koduar në përfaqësimet BERT. Në veçanti, ne demonstrojmë nëpërmjet një sonde të thjeshtë konsistence se aftësia për të marrë korrekt hipernimet në detyrat e mbylljes, siç përdoret në punën e mëparshme, nuk korrespondon me njohurinë sistematike në BERT. Our main conclusion is cautionary: even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT `understands' a concept, and it cannot be expected to systematically generalize across applicable contexts.", 'am': 'የግል ቃላት መልዕክቶች NLP የነጋዴ ኃይል ሆነዋል፤ ኃይላቸውን እና የሚሠራውን አካሄድን ለማስተዋል ስልጣኑን ለማስተዋል የስፋት ጉዳይ ነው፡፡ በተለየ ማጠቃለያ የሐሳቡን ውጤቶች ማወቅ እና ማወቅ ስልጣን ነው፡፡ ባለፈው ሥራ BERT-ን ለዚህ ባለሥልጣናት መልዕክቶች አግኝቷል፤ BERT በክፍለ ስራቶች ውስጥ ክፍተትን ማግኘት እንደሚችል አግኝቷል፡፡ በዚህ ሥራ ጠያቂውን እንጠይቃለን፡፡ የጉዳዩ ትምህርት፣ የBERT መልዕክቶች የፊርማዊ እውቀትን እንመርምራለን፡፡ በተለይም፣ ቀላል ብሔራዊ መሆኑን ማሳየት እናስታውቃለን፡፡ የዋነታችን ፍጻሜ አስጠነቀቀ ነው፤ ቢሬት ቢሆንም ለብቻው ትክክለኛ ማስረጃ ቢገልጽ እንኳን BERT ‘ማስተዋል’ አካሄዱን አያስፈልግም፣ በተጠቃሚ ጉዳዮች በሙሉ ማወቅ አይችልም፡፡', 'hy': 'Կոնտեքստալ բառերի ներկայացումները դարձան ՆԼՊ-ի շարժիչ ուժ, որը խրախուսում է տարածված հետաքրքրություն հասկանալու համար իրենց ունակությունները և մեխանիզմները, որոնց միջոցով նրանք գործում են: Հատկապես հետաքրքիր է, որ նրանք կարողանում են ճանաչել և կոդավորել գաղափարական վերացականությունները: Անցյալ աշխատանքը ուսումնասիրել է BER-ի ներկայացումները այս ունակության համար, բացահայտելով, որ BER-ը կարող է ճիշտ վերցնել անվանումներ փակցված աշխատանքներում: Այս աշխատանքի ընթացքում մենք հարցնում ենք. արդյո՞ք ուսումնասիրությունների ուսումնասիրությունները լուսավորում են BER-ի ներկայացումների սիստեմատիկ գիտելիքները: Որպես դեպքի ուսումնասիրություն, մենք ուսումնասիրում ենք հիպերնիմիային գիտելիքները, որոնք կոդավորված են BER-ի ներկայացումներում: Մենք հատկապես ցույց ենք տալիս պարզ համապատասխանատվության ուսումնասիրության միջոցով, որ հնարավորությունը ճիշտ վերցնել հիպերնիմները փակցված խնդիրներում, ինչպես օգտագործվում է նախորդ աշխատանքում, չի համապատասխանում BER-ի սիստեմատիկ գիտելիքներին: Մեր հիմնական եզրակացությունը զգույշ է: Նույնիսկ եթե BER-ը ցույց է տալիս, որ որոշակի հմտությունների համար հսկայական ճշգրիտություն է ուսումնասիրում, այն պարտադիր չի հետևում, որ BER-ը հասկանում է գաղափարը, և չի կարելի ակնկալել, որ այն համակարգչաբար ընդհան', 'af': "Kontekstualiseerde woord voorstellings het 'n driefkrag in NLP geword, motiveer uitbreidige belang in verstaan hul kapasiteite en die mekanisme waarmee hulle werk. Spesiaal intriging is hulle moontlik om konseptieële abstraksies te identifiseer en te kodeer. Verlede werk het BERT verteenwoordighede vir hierdie kompetensie probeer, om te vind dat BERT korrek die noume hypernyme kan ontvang in klose opdragte. In hierdie werk vra ons die vraag: Doen probeering studies lig op systematiese kennis in BERT-voorstellings uitgelei het? As 'n geval studie, ondersoek ons hipernies kennis wat in BERT-voorstellings gekodeer is. Spesifieke, ons wys deur 'n eenvoudige konsistensiehouer dat die moontlikheid om korrek hipernimus te ontvang in klose opdragte, soos gebruik word in voorree werk, ooreenstemmel nie aan sistematiese kennis in BERT nie. Ons hoofde conclusie is waarskuwing: selfs as BERT die hoë proberingspresisie vir 'n bepaalde kompetisie bevestig, doen dit nie noodsaaklik volg dat BERT 'n konsepte verstaan' n verstaan nie, en dit kan nie verwag word om te systematies genereer oor toepassiende konteks.", 'bn': 'প্রতিনিধিত্বিত শব্দের প্রতিনিধিত্ব এনএলপিতে গাড়ি চালানোর একটি শক্তি হিসেবে পরিণত হয়েছে, যার ফলে তারা তাদের ক্ষমতা এবং কার্যকলাপ বিশেষ করে মজার বিষয়টি হচ্ছে তাদের চিন্তা ও এনকোড করার ক্ষমতা। পূর্ববর্তী কাজ এই ক্ষমতার জন্য বিআরটি প্রতিনিধিত্ব প্রদান করেছে, তারা খুঁজে পেয়েছে যে বিবের্ট ক্লোজের কাজে সঠিকভাবে কোন In this work, we ask the question: do probing studies shed light on systematic knowledge in BERT representations?  কেসের গবেষণা হিসেবে আমরা বের্টি প্রতিনিধিত্বে হাইপারেনিমির জ্ঞান পরীক্ষা করি। বিশেষ করে, আমরা একটি সাধারণ সংশ্লিষ্ট প্রমাণের মাধ্যমে প্রদর্শন করি যে ক্লোজ কাজে হাইপারেনিমের ক্ষমতা সঠিকভাবে পুনরুদ্ধার করতে পারে, যেমনটা আগের কাজে  আমাদের প্রধান সমাপ্তি সতর্কতার সাথে: যদিও বিবের্ট বিশেষ ক্ষমতার জন্য উচ্চ পরীক্ষার বিষয়টি প্রদর্শন করে থাকে, তবে তা অনুসরণ করে না যে বার্টি ‘বুঝতে পারে’ একটি ধারণা, আর এটি ব্যবস্থা', 'az': 'NLP-də müxtəlif sözlər göstərilmələri sürücü qüvvət oldular, onların yetkinliklərini və işlədikləri mehanizmiləri anlamaq üçün genişləndirirlər. Özellikle ilginçək onların düşüncəli abstraksyonları tanıtmaq və kodlamaq bacarığıdır. Əvvəlki işdə BERT bu təhsil üçün göstərilmələri təsdiq etdi, BERT\'nin kloz işlərində ismi hipernimlərini düzgün alması mümkündür. Bu işdə, biz sual soruşuruq: təhsil etmək, BERT təhsil göstəricilərində sistematik bilgi haqqında işıq yaradırmı? Beləliklə, BERT göstəricilərində kodlanmış hipernimik elmi incidirik. Özellikle, biz çox basit bir sürəkliyi təsdiqləyici olaraq göstəririk ki, əvvəlki işdə istifadə edilmiş kimi hipernimləri düzgün təsdiqləmə qabiliyyəti BERT-də sistematik bilgi ilə uyğun deyildir. Əsas sonuğumuz təhlükəsizlidir: BERT təhlükəsizlik üçün yüksək sonuğun doğruluğunu göstərsə də, BERT\'nin "anladığı" fikrinə uyması lazımdır, və bu sistematik olaraq uyğun müxtəliflərdə generalizasyon edilməsini gözləməz.', 'ca': 'Representacions de paraules contextuals s\'han convertit en una força motora en NLP, motivant un interès generalitzat en entendre les seves capacitats i els mecanismes amb els quals funcionen. Particularment intrigant és la seva habilitat d\'identificar i codificar abstraccions conceptuals. El treball passat ha investigat representacions de BERT per aquesta competència, descobrint que BERT pot recuperar correctament noms hipernims en tasques de cloze. En aquesta feina, fem la pregunta: els estudis revelen el coneixement sistemàtic en representacions BERT? Com a estudi de cas, examinem el coneixement de l\'hipernimi codificat en representacions BERT. En particular, demostram a través d\'una simple sonda de consistencia que l\'habilitat de recuperar correctament hipernims en tasques de clozament, com es va utilitzar en treball anterior, no correspon al coneixement sistemàtic en BERT. La nostra conclusió principal és cautelar: fins i tot si el BERT demostra una alta precisió d\'investigació d\'una competència específica, no necessariament segueix que el BERT "entengui" un concepte, i no es pot esperar que s\'generalitze sistemàticament en els contextos aplicables.', 'bs': "Kontekstualizirani predstavnici riječi postali su vozačka snaga u NLP-u, motivirajući široki interes u razumijevanju njihovih sposobnosti i mehanizma s kojim oni rade. Posebno interesantno je njihova sposobnost identificiranja i kodiranja konceptualnih apstraktacija. Posljednji rad je probao predstave BERT-a za ovu kompetenciju, otkrivajući da BERT može ispravno izvući hipernimu imena u zadatku kloziranja. U ovom poslu postavljamo pitanje: da li ispitivanje istraživanja proizvodi svjetlo sistematsko znanje u predstavljanju BERT-a? Kao studija slučajeva, pregledavamo hipernimu znanje kodirano u predstavljanju BERT-a. Posebno, mi pokazujemo kroz jednostavnu sondu konsistencije da sposobnost ispravno povlačenja hipernima u zadatkima kloziranja, kao što je koristljena u prethodnom poslu, ne odgovara sistematskim znanjem u BERT-u. Naš glavni zaključak je pažljiv: čak i ako BERT pokazuje veliku tačnost istraživanja za određenu kompetenciju, ne mora se morati pratiti da BERT 'razumije' koncept, a ne može se očekivati da će sistematski generalizirati u međuvremenu primjenjivih konteksta.", 'cs': 'Kontextualizované reprezentace slov se staly hnací silou NLP, motivující široký zájem o pochopení jejich schopností a mechanismů, kterými fungují. Zvláště zajímavá je jejich schopnost identifikovat a kódovat konceptuální abstrakce. V minulé práci byly zkoumány BERT reprezentace pro tuto kompetenci a zjištěny, že BERT dokáže správně načíst podstatná hypernyma v cloze úlohách. V této práci klademe otázku: vrhají sondovací studie světlo na systematické znalosti v BERT reprezentacích? Jako případová studie zkoumáme znalosti hypernymií kódované v BERT reprezentacích. Zejména prostřednictvím jednoduché konzistentní sondy demonstrujeme, že schopnost správně načítat hypernymy v cloze úlohách, jak byla použita v předchozí práci, neodpovídá systematickým znalostem v BERT. Náš hlavní závěr je varovný: i když BERT prokáže vysokou přesnost sondování pro konkrétní kompetenci, nemusí nutně vyplývat z toho, že BERT "rozumí" konceptu a nelze očekávat, že se systematicky zobecňuje napříč aplikovanými kontextemi.', 'et': 'Kontekstuliseeritud sõnaesindused on saanud NLP liikumapanevaks jõuks, motiveerides laialdast huvi mõista nende võimeid ja mehhanisme, mille abil nad töötavad. Eriti intrigeeriv on nende võime tuvastada ja kodeerida kontseptuaalseid abstraktsioone. Varasemad tööd on uurinud BERTi esindusi selle pädevuse kohta, leides, et BERT suudab õigesti hankida nimisõnade hüpernüüme klopeerimise ülesannetes. Käesolevas töös esitame küsimuse: kas prooviuuringud valgustavad süstemaatilisi teadmisi BERT esindustes? Juhtumiuuringuna uurime BERTi esindustes kodeeritud hüpernüümiateadmisi. Eelkõige näitame lihtsa järjepidevuse analüüsi kaudu, et võime õigesti hüpernüümide kättesaamiseks cloze ülesannetes, nagu seda kasutati eelnevates töödes, ei vasta BERT-i süstemaatilistele teadmistele. Meie peamine järeldus on hoiatav: isegi kui BERT näitab konkreetse pädevuse jaoks kõrget uurimistäpsust, ei järgne see tingimata sellele, et BERT mõistab mõistet, ning see ei saa eeldada süstemaatiliselt üldistamist kohaldatavates kontekstides.', 'fi': 'Kontekstulisoiduista sanaesityksistä on tullut NLP:n liikkeellepaneva voima, joka on herättänyt laajaa kiinnostusta ymmärtää niiden kykyjä ja mekanismeja, joilla ne toimivat. Erityisen kiehtova on niiden kyky tunnistaa ja koodata käsitteellisiä abstraktioita. Aiempi työ on tutkinut BERT:n esityksiä tämän osaamisen suhteen ja havainnut, että BERT voi hakea substantiivinen hypernyymit oikein cloze-tehtävissä. Tässä työssä esitämme kysymyksen: valottavatko luotaustutkimukset systemaattista tietoa BERT-representaatioissa? Tapaustutkimuksena tarkastelemme BERT-esityksiin koodattua hypernyymitietoa. Erityisesti osoitamme yksinkertaisella johdonmukaisuusluotaimella, että aikaisemmassa työssä käytetty kyky hakea hypernyymejä oikein cloze-tehtävissä ei vastaa BERT:n systemaattista tietoa. Tärkein johtopäätöksemme on varoittava: vaikka BERT osoittaakin suurta mittaustarkkuutta tietyn osaamisen osalta, siitä ei välttämättä seuraa, että BERT "ymmärtää" käsitettä, eikä sen voida olettaa yleistyvän järjestelmällisesti kaikissa sovellettavissa yhteyksissä.', 'sk': "Kontekstulizirane besedne reprezentacije so postale gonilna sila NLP, ki spodbuja široko zanimanje za razumevanje njihovih zmožnosti in mehanizmov, s katerimi delujejo. Posebej zanimiva je njihova sposobnost prepoznavanja in kodiranja konceptualnih abstrakcij. V preteklem delu so preučili predstavitve BERT za to kompetenco in ugotovili, da lahko BERT pravilno pridobi hipernime samostalnikov pri opravilih cloze. V tem delu postavljamo vprašanje: ali raziskovalne študije osvetljujejo sistematično znanje v BERT reprezentacijah? Kot študija primera preučujemo hipernimsko znanje, kodirano v BERT reprezentacijah. Zlasti s pomočjo enostavne analize doslednosti dokazujemo, da sposobnost pravilnega pridobivanja hipernimov pri opravilih cloze, kot je bila uporabljena v predhodnem delu, ne ustreza sistematičnemu znanju v BERT. Naš glavni sklep je opozorilen: čeprav BERT dokazuje visoko natančnost preiskovanja za določeno kompetenco, ne sledi nujno, da BERT ‚razume' koncept, in ni mogoče pričakovati, da se bo sistematično posplošil v vseh veljavnih kontekstih.", 'he': 'נציגות מילים מקורקסטולוגיות הפכו לכוח המנהיג ב-NLP, ומניע עניין מרוחק להבין את היכולות שלהם והמנגנונים שבהם הם פועלים. במיוחד מעניין הוא היכולת שלהם לזהות ולקוד אסטראקציות מושגיות. Past work has probed BERT representations for this competence, finding that BERT can correctly retrieve noun hypernyms in cloze tasks.  בעבודה הזו, אנחנו שואלים את השאלה: האם חקירת מחקרים משפיעה אור על ידע מערכתי ביציגות BERT? בתור מחקר מקרים, אנחנו בודקים ידע היפרנימיה מוצפנת בתצוגות BERT. במיוחד, אנו מראים באמצעות חוקר קבילות פשוט כי היכולת להשיג היפרנימות בצורה נכונה במשימות כיסוי, כפי שהשתמשו בעבודה קודמת, לא מתאימה לידע שיטתי ב-BERT. המסקנה העיקרית שלנו היא זהירות: אפילו אם BERT מראה מדויקת חקירה גבוהה למיומנות מסויימת, זה לא בהכרח עוקב כי BERT "מבין" מושג, ולא ניתן לצפות לזה להתפשט באופן שיטתי ברחבי הקשר הנאמן.', 'ha': "An sami maganar da aka haɗa shi har ya kasance wani ƙarfi mai tafiyar da shi a NLP, mai kwaɗaitarwa da interesse mai faɗi ga fahimta abincinsu da mekanin da suke aiki da shi. Particularly intriguing is their ability to identify and encode conceptual abstractions.  QUnicodeControlCharacterMenu Daga wannan aikin, Munã tambayar su: Shin, jarrabo karatun za ta yi haske a kan ilmi na'ura na BERT? Kama wani littãfi, za'a jarraba sanin giya da aka kodi a cikin mabarancin BERT. Kuma da ƙayyade, za mu nuna bayan wani abu mai saukarwa na sami cẽwa ma'abũcin ya iya motsa surori a cikin aikin rufe, kamar da aka yi amfani da shi a gabani, bai daidai da ilmi na kasansa a BERT. Bayanmu ƙaranci yana da taƙo: kuma kõ dã BERT ya nuna korrekin tsari ga wani awon da aka ƙayyade, bã ya lazima ta bi cewa da zaɓen `BERT' yana fahimta, kuma bã za a iya ƙayyade shi a daidaita kowacan matsayin da ake amfani da.", 'jv': "word representation langgar-langgar sapa nguasai kapan anyar nggarap nggambar lan kode nggo ngerasai y Nang trabah iki, kita takon seujuhi cejane: Iso ngerasar barang kelas nang ngerasar sistem kanggo saboh barang BERT ? Mungkin kelompok dadi, kita jewis ranjenengan kelompok nggawe barang kelompok nggo BERT. Juara-Juara, kéné sumulakno ngono perusahaan sampeyan nguasakno sing bisa kapan karo hal-hal nganggo perusahaan winih(close tasks), kaya nguasakno karo perusahaan langgar sampeyan ingkang BERT. Sampeyan akeh sing dipun gulakno iku: bah saben BERT sumulakno akeh operasi sing titimpen kanggo kompatistik dhéwé, kuwi ora deweke nggunakake BERT 'ngerasakno' sampeyan, ate ora iso diandelok sistematik tau nguasakno sing apik dhéwé.", 'bo': 'ཞུགས་སྣང་གི་གསལ་བརྗོད་པ་དེ་ནི་NLP ནང་གི་སྒུལ་ཆས་ཤིག་ཆགས་པ་ཞིག་ཆགས་ཡོད། དམིགས་གསལ་བསམ་བློ་གཏོང་ནི་ཁོང་ཚོའི་ཆོས་ཉིད་དེ་དམིགས་འཛུགས་དང་གསལ་འདྲེན་བྱེད་རྒྱུ་དེ་རེད། སྔོན་ལྟ་བུའི་ནང་དུ་BERT སྒྲིག་འགོད་ཀྱི་གསལ་བརྗོད་ཞིག་བྱས་ཡོད། BERT སྒྲིག་འགོད་ཀྱི་ལས་ཀ་གསལ་གྲངས་ཀ་ལྟ་བུ་སྟོན་ཐུབ་པ་དང་། འོན་ཀྱང་སྒྲུབ་འདིའི་ནང་གི་ང་ཚོས་དྲི་ཚིག་ལས་ང་ཚོས་གནས་ཚུལ་ལྟར་བསམ་བློ་གཏོང། ལྟ་ཞིབ་དཔྱད་ཞིབ ལྟ་བུའི་ནང་དུ་ང་ཚོས་བློ་གཏོང་ཁང་གི་དབུལ་རིག་གི་མཐོང་རིམ་དཔྱད་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་རང་ཉིད་ཀྱིས་སྔོན་གྱི་ལས་འགན་འགྱུར་བ་ཞིག་གིས་མཐུན་རྐྱེན་ཚད་ལྟར་བདེ་ཞིག་ཏུ་བཀྲམ་སྟོན་ན། ང་ཚོའི་རྩ་བའི་conclusion་ནི་དོ་སྣང་དགོས་བརྗོད་པ་ཞིག་ཡིན། BERT དེ་རང་ཉིད་ཀྱི་ཁྱོད་རང་ཉིད་པར་ངོ་བའི་གསལ་བཤད་ཚད་དཀའ་བ་ཞིག་དང་།'}
{'en': 'PISA : A measure of Preference In Selection of Arguments to model verb argument recoverability', 'ar': 'PISA: مقياس التفضيل في اختيار الحجج لنمذجة استرجاع حجة الفعل', 'es': 'PISA: Una medida de preferencia en la selección de argumentos para modelar la capacidad de recuperación de argumentos verbales', 'pt': 'PISA: Uma medida de preferência na seleção de argumentos para modelar a recuperabilidade de argumentos verbais', 'fr': "PISA\xa0: une mesure de la préférence dans la sélection d'arguments pour modéliser la récupérabilité des arguments verbaux", 'ja': 'PISA ：引数の選択における優先度の尺度-動詞の引数の回復可能性をモデル化する', 'zh': 'PISA曰:择参数以动词参数可恢复性建模偏善之度', 'ru': 'PISA: мера предпочтения при выборе аргументов для моделирования восстанавливаемости аргументов глагола', 'hi': 'PISA: मॉडल क्रिया तर्क पुनर्प्राप्ति के लिए तर्क के चयन में वरीयता का एक उपाय', 'ga': 'PISA: Tomhas Tosaíochta i Roghnú Argóintí chun inghnóthaitheacht argóint na mbriathra a shamhaltú', 'ka': 'PISA: აპგუმენტების არჩევაში მონიშნულების მოდელური ვერბის არგუმენტების განახლება', 'el': 'Ένα μέτρο προτίμησης στην επιλογή επιχειρημάτων για να μοντελοποιηθεί η ανάκτηση ορίσματος ρήματος', 'hu': 'PISA: A preferencia mértéke az ige argumentumok helyreállíthatóságának modellezéséhez szükséges argumentumok kiválasztásában', 'it': 'PISA: Una misura della preferenza nella selezione degli argomenti per modellare la recuperabilità degli argomenti verbali', 'lt': 'PISA: Argumentų pasirinkimo pirmenybės priemonė, palyginti su žodžio argument ų atsigavimo modeliu', 'kk': 'PISA: Аргументтерді таңдау үшін аргументтердің параметрлерінің өлшемі', 'mk': 'Name', 'ms': 'PISA: Ukuran Keutamaan Dalam Pemilihan Argumen untuk pemulihan argumen verb model', 'mt': 'PISA: Miżura ta’ Preferenza fl-Għażla tal-Argumenti għall-mudell tal-irkupru tal-argument verbali', 'ml': 'PISA: വെര്\u200dബ് ആര്\u200dഗ്യുമെന്\u200dറുകളുടെ തെരഞ്ഞെടുക്കുന്നതിനുള്ള മുന്\u200dഗണന മാതൃകയുടെ ഒരു അളവു്', 'no': 'PISA: Eit mål av innstillingar i utvalet av argumenter for å gjenoppretta verb argument', 'mn': 'PISA: Аргументүүдийн сонголтын тааламжтай хэмжээ нь verb аргументын загварын сэргээгдэх чадвар', 'pl': 'PISA: Miara preferencji w wyborze argumentów do modelowania odzyskiwalności argumentów czasownikowych', 'ro': 'PISA: O măsură de preferință în selectarea argumentelor pentru modelarea recuperabilității argumentelor verbale', 'sr': 'PISA: Mjera preferencije u odabiru argumenata za model oporavljivosti verbalnih argumenata', 'so': 'PISA: A measure of Preference In Selection of Arguments to model verb argument recoverability', 'si': 'PISA: ප්\u200dරතිස්ථානයක් ප්\u200dරතිස්ථානයක් තෝරාගන්න ප්\u200dරතිස්ථානයක්', 'sv': 'PISA: Ett mått på preferens i val av argument för att modellera verbargumentets återvinningsbarhet', 'ta': 'PISA: விருப்பத்தேர்வுகளின் தேர்ந்தெடுப்பில் முன்னுரிமையின் அளவு', 'ur': 'PISA: ایک اندازہ آرکوم کے انتخاب میں ترجیح کے اندازے پر ویربی آرکوم کی بازگشت قابلیت کے لئے', 'uz': 'Name', 'vi': 'PIA: Một thước đo của Sự ưa thích trong khi chọn biện pháp về các biện pháp để mô hình lẽ phải xác định', 'bg': 'Мярка за предпочитание при избора на аргументи за моделиране на възвръщаемост на аргументите на глагола', 'da': 'PISA: Et mål for præference i udvælgelse af argumenter til modellering af verbargumenter genoprettelse', 'nl': 'PISA: Een maatstaf voor preferentie bij selectie van argumenten om verbeargumenten herstelbaarheid te modelleren', 'hr': 'PISA: Mjera preferencije u odabiru argumenata za obnovljivost verbalnih argumenata', 'de': 'PISA: Ein Ma횩 f체r Pr채ferenz bei der Auswahl von Argumenten zur Modellierung der Wiederherstellungsf채higkeit von Verbargumenten', 'id': 'PISA: Sebuah ukuran keutamaan Dalam Pemilihan Argumen untuk model argumen verb pemulihan', 'ko': 'PISA: 동사 매개변수의 복구 가능성을 시뮬레이션하기 위한 매개변수 선택 선호도 측정', 'fa': 'PISA: اندازه\u200cای از ترجیح در انتخاب آرژومی برای مدل بازسازی آرژومی اصطلاح', 'sw': 'PISA: A measure of Preference In Selection of Arguments to model verb argument recoverability', 'tr': 'unit-format', 'af': 'Pisa: A measure of Preferences in Selection of Arguments to model verb argument recoverability', 'sq': 'PISA: Një masë preferimi në zgjedhjen e argumenteve për të modeluar ripërtëritjen e argumenteve të verb ëve', 'am': 'verb argument recoverable', 'hy': 'ՓիՍԱ. Արգենտների ընտրության մեջ նախընտրված չափսը բայերի վերականգնելիության մոդելավորման համար', 'az': 'PISA: Argumentl톛rin se칞ilm톛si 칲칞칲n bir 칬l칞칲 Preference', 'bn': 'পিআইএসএ: আর্গুমেন্ট নির্বাচনের একটি পছন্দের মাপ', 'bs': 'PISA: Mjera preferencije u odabiru argumenata za model oporavljivosti verbalnih argumenata', 'ca': "PISA: Una mesura de preferència en la selecció d'arguments per modelar la recuperabilitat d'arguments de verbs", 'cs': 'PISA: Měřítko preference při výběru argumentů k modelování obnovitelnosti argumentů slovesa', 'et': 'PISA: Eelistuse mõõt argumentide valimisel verbi argumentide taastamise modelleerimiseks', 'fi': 'PISA: Määritelmä argumenttien valinnassa verbiaargumentin palautuvuuden mallintamiseksi', 'jv': 'PILA: A measurement of preferences In Select of argument to model verb argument', 'sk': 'PISA: Merilo preference pri izbiri argumentov za modeliranje obnovljivosti argumentov glagola', 'he': 'PISA: מידה של העדיפות בבחירה של התווכחות', 'ha': 'KCharselect unicode block name', 'bo': 'PISA: A measure of Preference In Selection of Arguments to model verb argument recoverability'}
{'en': 'Our paper offers a computational model of the semantic recoverability of verb arguments, tested in particular on direct objects and Instruments. Our fully distributional model is intended to improve on older taxonomy-based models, which require a lexicon in addition to the training corpus. We computed the selectional preferences of 99 transitive verbs and 173 Instrument verbs as the mean value of the pairwise cosines between their arguments (a weighted mean between all the arguments, or an unweighted mean with the topmost k arguments). Results show that our model can predict the recoverability of objects and Instruments, providing a similar result to that of taxonomy-based models but at a much cheaper computational cost.', 'ar': 'تقدم ورقتنا نموذجًا حسابيًا للاسترداد الدلالي لوسائل الفعل ، تم اختباره بشكل خاص على الأشياء والأدوات المباشرة. يهدف نموذج التوزيع الكامل الخاص بنا إلى تحسين النماذج القديمة القائمة على التصنيف ، والتي تتطلب معجمًا بالإضافة إلى مجموعة التدريب. قمنا بحساب التفضيلات الانتقائية لـ 99 فعل متعد و 173 فعل أداة باعتبارها القيمة المتوسطة لجيب التمام المزدوج بين وسيطاتهم (متوسط مرجح بين جميع الوسائط ، أو متوسط غير مرجح مع أعلى وسيطات k). تظهر النتائج أن نموذجنا يمكن أن يتنبأ بإمكانية استرداد الكائنات والأدوات ، مما يوفر نتيجة مماثلة لتلك الخاصة بالنماذج القائمة على التصنيف ولكن بتكلفة حسابية أرخص بكثير.', 'fr': 'Notre article propose un modèle informatique de la récupérabilité sémantique des arguments verbaux, testé en particulier sur des objets directs et des instruments. Notre modèle entièrement distributionnel vise à améliorer les anciens modèles basés sur la taxonomie, qui nécessitent un lexique en plus du corpus de formation. Nous avons calculé les préférences de sélection de 99 verbes transitifs et de 173 verbes instruments comme valeur moyenne des cosinus deux à deux entre leurs arguments (une moyenne pondérée entre tous les arguments, ou une moyenne non pondérée avec les k arguments les plus élevés). Les résultats montrent que notre modèle peut prédire la récupérabilité des objets et des instruments, fournissant un résultat similaire à celui des modèles basés sur la taxonomie, mais à un coût de calcul beaucoup moins élevé.', 'es': 'Nuestro artículo ofrece un modelo computacional de la recuperabilidad semántica de los argumentos verbales, probado en particular en objetos e instrumentos directos. Nuestro modelo totalmente distributivo está destinado a mejorar los modelos más antiguos basados en taxonomía, que requieren un léxico además del corpus de capacitación. Calculamos las preferencias de selección de 99 verbos transitivos y 173 verbos de instrumento como el valor medio de los cosenos por pares entre sus argumentos (una media ponderada entre todos los argumentos o una media no ponderada con los k argumentos más altos). Los resultados muestran que nuestro modelo puede predecir la capacidad de recuperación de objetos e instrumentos, proporcionando un resultado similar al de los modelos basados en taxonomía, pero a un costo computacional mucho más económico.', 'pt': 'Nosso artigo oferece um modelo computacional da recuperabilidade semântica de argumentos verbais, testado em particular em objetos diretos e instrumentos. Nosso modelo totalmente distribucional visa melhorar os modelos mais antigos baseados em taxonomia, que exigem um léxico além do corpus de treinamento. Calculamos as preferências de seleção de 99 verbos transitivos e 173 verbos de instrumento como o valor médio dos cossenos pares entre seus argumentos (uma média ponderada entre todos os argumentos ou uma média não ponderada com os k argumentos mais altos). Os resultados mostram que nosso modelo pode prever a recuperabilidade de objetos e Instrumentos, fornecendo um resultado semelhante ao dos modelos baseados em taxonomia, mas com um custo computacional muito mais barato.', 'ja': '私たちの論文は、特に直接のオブジェクトと器具でテストされた動詞引数の意味的回復可能性の計算モデルを提供します。当社の完全分布モデルは、トレーニングコーパスに加えて辞書を必要とする古い分類法ベースのモデルを改善することを意図しています。我々は、99個の経過動詞と173個の計器動詞の選択嗜好を、それらの引数間のペアワイズコサインの平均値（すべての引数間の加重平均、または最上位のk引数を持つ加重されていない平均）として計算した。結果は、当社のモデルがオブジェクトや機器の回復可能性を予測し、分類法ベースのモデルと同様の結果を提供しますが、計算コストがはるかに低くなっていることを示しています。', 'zh': '臣等论文动词参数语义可恢复性算模形,特试之于直器。 全布模旨改进较旧的基于分类的模样,这模形除训练语料库之外还要一个词典。 计99传动词与173乐器动词择偏善,以为之参数之间余弦者平均值(凡参数之加权平均值,或有顶层k参数之未加权平均值)。 结果表明吾形可以占器之可恢复性,与分类法相似者,计算成本宜多矣。', 'ru': 'Наша работа предлагает вычислительную модель семантической восстанавливаемости глагольных аргументов, протестированную, в частности, на прямых объектах и инструментах. Наша полностью дистрибутивная модель предназначена для улучшения старых моделей, основанных на таксономии, которые требуют лексикона в дополнение к обучающему корпусу. Мы вычислили выборочные предпочтения 99 переходных глаголов и 173 глаголов инструмента как среднее значение парных косинусов между их аргументами (взвешенное среднее между всеми аргументами или невзвешенное среднее с самыми верхними k аргументами). Результаты показывают, что наша модель может предсказывать возможность восстановления объектов и инструментов, обеспечивая результат, аналогичный результату моделей, основанных на таксономии, но с гораздо более дешевой вычислительной стоимостью.', 'hi': 'हमारा पेपर क्रिया तर्कों की शब्दार्थ पुनर्प्राप्ति का एक कम्प्यूटेशनल मॉडल प्रदान करता है, विशेष रूप से प्रत्यक्ष वस्तुओं और उपकरणों पर परीक्षण किया जाता है। हमारे पूरी तरह से वितरण मॉडल का उद्देश्य पुराने वर्गीकरण-आधारित मॉडल में सुधार करना है, जिसे प्रशिक्षण कॉर्पस के अलावा एक शब्दकोश की आवश्यकता होती है। हमने 99 सकर्मक क्रियाओं और 173 इंस्ट्रूमेंट क्रियाओं की चयन प्राथमिकताओं की गणना उनके तर्कों के बीच युग्मवार कोसाइन के औसत मूल्य के रूप में की (सभी तर्कों के बीच एक भारित माध्य, या शीर्षतम के तर्कों के साथ एक अनवेटेड माध्य)। परिणाम बताते हैं कि हमारा मॉडल वस्तुओं और उपकरणों की पुनर्प्राप्ति की भविष्यवाणी कर सकता है, वर्गीकरण-आधारित मॉडल के समान परिणाम प्रदान करता है, लेकिन बहुत सस्ती कम्प्यूटेशनल लागत पर।', 'ga': 'Cuireann ár bpáipéar múnla ríomhaireach ar fáil d’in-aisghabhálacht shéimeantach argóintí na mbriathra, a tástáladh go háirithe ar réada díreacha agus Ionstraimí. Tá sé mar aidhm ag ár múnla dáilte iomlán feabhas a chur ar mhúnlaí níos sine atá bunaithe ar thacsanomaíocht, a dteastaíonn foclóir uathu sa bhreis ar an gcorpas oiliúna. Rinneamar na roghanna roghnaithe de 99 briathar trasdultach agus 173 briathar Ionstraim a ríomh mar mheánluach na gcosnaí pairwise idir a n-argóintí (meán ualaithe idir na hargóintí go léir, nó meán neamhualaithe leis na hargóintí is airde). Léiríonn torthaí gur féidir lenár múnla in-aisghabhálacht réad agus Ionstraimí a thuar, ag soláthar toradh cosúil le samhlacha tacsanomaíochta ach ar chostas ríomhaireachta i bhfad níos saoire.', 'ka': 'ჩვენი წიგნის კომპუტაციალური მოდელი გვერბალური არგუმენტების სიმენტიკური განახლებელობის, განსაკუთრებით განახლებული პირადი ობიექტებზე და ინსტრუმენტებზე. ჩვენი ყველაფერი განსაზღვრებული მოდელი უფრო მეტი რაკონომიკური მოდელზე უფრო მეტია, რომელიც საჭირო ლექსიკონის დამატებით სტრუნქციის კოპუსს. ჩვენ დავწერეთ 99 გადატანტიგური გერბის და 173 ინსტრუმენტის გერბების სულ მნიშვნელობა, როგორც მათი არგუმენტების შორის კოსინტების შორის შორის შორის მნიშვნელობა (ყველა არგუმენტების შორის მნიშვნელობა,  წარმოდგენები ჩვენი მოდელის შესაძლებელია გადაწყვეტა სახელსაწყისი და ინსტრუმენტების შესაძლებლობა, რაკონომიკური მოდელის შესაძლებლობა, მაგრამ უფრო მარტივი კომპუტერ', 'hu': 'Tanulmányunk az ige argumentumok szemantikai helyreállíthatóságának számítási modelljét kínálja, különösen közvetlen objektumokon és instrumentumokon tesztelve. Teljes körűen eloszlási modellünk célja a régebbi taxonómiai alapú modellek fejlesztése, amelyek a tréningkorpuszon kívül lexikont igényelnek. 99 átmeneti igék és 173 instrumentum igék kiválasztási preferenciáit az argumentumaik közötti páros koszinusok középértékének számítottuk ki (az összes argumentum súlyozott középértéke, vagy a legfelső k argumentumok közötti súlyozatlan középérték). Az eredmények azt mutatják, hogy modellünk meg tudja jósolni az objektumok és műszerek helyreállíthatóságát, hasonló eredményt nyújtva a taxonómiai modellekhez, de sokkal olcsóbb számítási költséggel.', 'el': 'Η εργασία μας προσφέρει ένα υπολογιστικό μοντέλο της σημασιολογικής ανάκτησης των ορίων ρήματος, δοκιμασμένο ειδικά σε άμεσα αντικείμενα και όργανα. Το πλήρως κατανεμητικό μοντέλο μας έχει ως στόχο να βελτιώσει τα παλαιότερα μοντέλα που βασίζονται στην ταξινομία, τα οποία απαιτούν ένα λεξικό εκτός από το εκπαιδευτικό σώμα. Υπολογίσαμε τις επιλεκτικές προτιμήσεις των 99 μεταβατικών ρήμων και 173 ρήμων οργάνων ως τη μέση τιμή των ζευγαριών συνηϊνών μεταξύ των ορίων τους (σταθμισμένος μέσος όρος μεταξύ όλων των ορίων, ή μη σταθμισμένος μέσος όρος με τα ανώτατα ορίσματα k). Τα αποτελέσματα δείχνουν ότι το μοντέλο μας μπορεί να προβλέψει την ανάκτηση αντικειμένων και οργάνων, παρέχοντας ένα παρόμοιο αποτέλεσμα με αυτό των ταξινομικών μοντέλων αλλά με πολύ φθηνότερο υπολογιστικό κόστος.', 'it': 'Il nostro articolo offre un modello computazionale della recuperabilità semantica degli argomenti verbali, testato in particolare su oggetti diretti e strumenti. Il nostro modello completamente distributivo è destinato a migliorare i vecchi modelli basati sulla tassonomia, che richiedono un lessico oltre al corpus formativo. Abbiamo calcolato le preferenze selettive di 99 verbi transitivi e 173 verbi strumentali come valore medio dei cosini a coppia tra i loro argomenti (una media ponderata tra tutti gli argomenti, o una media non ponderata con gli argomenti k più alti). I risultati mostrano che il nostro modello può prevedere la recuperabilità di oggetti e strumenti, fornendo un risultato simile a quello dei modelli basati sulla tassonomia ma ad un costo computazionale molto più economico.', 'mk': 'Нашиот весник нуди компјутативен модел на семантичната обновливост на јазичните аргументи, тестирани особено на директни објекти и инструменти. Нашиот целосен дистрибуционален модел има за цел подобрување на постарите модели базирани на таксономија, кои бараат лексикон покрај обуката корпус. We computed the selectional preferences of 99 transitive verbs and 173 Instrument verbs as the mean value of the pairwise cosines between their arguments (a weighted mean between all the arguments, or an unweighted mean with the topmost k arguments).  Резултатите покажуваат дека нашиот модел може да ја предвиде обновливоста на објектите и инструментите, обезбедувајќи сличен резултат со оној на моделите базирани на таксономија, но со многу поевтина компјутациска цена.', 'lt': 'Mūsų dokumente pateikiamas skaičiavimo modelis, pagal kurį galima semantiškai atkurti žodžių argumentus, visų pirma išbandytus tiesioginiais objektais ir prietaisais. Mūsų visiškai paskirstymo model is yra skirtas pagerinti senus taksonomijos modelius, kuriems reikalingas ne tik mokymo korpusas, bet ir leksikonas. Apskaičiavome atrankines 99 tranzitinių žodžių ir 173 instrumentinių žodžių parių kosinusų vidutinę vertę tarp jų argumentų (svertinis visų argumentų vidurkis arba svertinis vidurkis su viršutiniais k argumentais). Rezultatai rodo, kad mūsų modelis gali prognozuoti objektų ir priemonių susigrąžinamumą ir duoti panašų rezultatą į taksonomija pagrįstų modelių rezultatą, tačiau už daug pigesnes skaičiavimo sąnaudas.', 'ms': 'Kertas kami menawarkan model pengiraan kemampuan pemulihan semantik argumen verb, diuji terutama pada objek langsung dan Instrumen. Model pengeluaran penuh kami adalah bertujuan untuk meningkatkan pada model berdasarkan taksonomi lama, yang memerlukan leksikon selain korpus latihan. Kami menghitung keutamaan pemilihan 99 verb transitif dan 173 verb Instrument sebagai nilai rata-rata kosinus pasangan diantara argumen mereka (rata-rata berat diantara semua argumen, atau rata-rata tidak berat dengan argumen atas k). Hasil menunjukkan bahawa model kita boleh meramalkan kemampuan pulih objek dan Instrumen, menyediakan hasil yang sama dengan hasil model berdasarkan taksonomi tetapi dengan biaya pengiraan yang jauh murah.', 'kk': 'Біздің қағаздың симантикалық аргументтердің есептеу үлгісін ұсынады. Бұл әдетте тікелей нысандар мен құрылғылар үшін тексерілген. Біздің толық тарату үлгіміз ескі таксономия негіздеген үлгілерді жақсарту үшін болады. Бұл үлгілерді бақылау корпуса қосымша лексикан талап етеді. Біз 99 жылжытатын верболардың таңдау параметрлерін және 173 Instrument верболардың аргументтерінің орташа косинуттардың (барлық аргументтер арасындағы тең орташа немесе ең жоғары k аргументтерінің орташа тең орташа деп есептедік). Нәтижелер біздің моделіміз нысандар мен инструменттердің қайталау мүмкіндігін көрсетеді. Таксономиялық моделдердің ұқсас нәтижесін көрсетеді, бірақ есептеу бағасы артық.', 'ml': 'ഞങ്ങളുടെ പത്രത്തില്\u200d നേരിട്ടുള്ള വസ്തുക്കളെയും ഉപകരണങ്ങളെയും പരീക്ഷിക്കുന്നതിന്റെ സെമാന്റിക്ക് വീണ്ടെടുക്കാനുള നമ്മുടെ പൂര്\u200dണ്ണമായ വിതരണ മോഡല്\u200d പഴയ ടാക്സോനോമി അടിസ്ഥാനമായ മോഡലുകളില്\u200d മെച്ചപ്പെടുത്താന്\u200d ഉദ്ദേശിക്കുന്നു. അതിന് പര 99 ട്രാന്\u200dസിഫ് വാര്\u200dബുകളുടെയും 173 ഇന്\u200dസ്റ്റൌണ്ട് വാര്\u200dപ്പുകളുടെയും തെരഞ്ഞെടുക്കുന്ന മുന്\u200dഗണനം ഞങ്ങള്\u200d എണ്ണിച്ചിരിക്കുന്നു. അവയുടെ വാക്കുകള്\u200dക്കിടയില ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് നമ്മുടെ മോഡല്\u200d വസ്തുക്കളുടെയും ഉപകരണങ്ങളുടെയും സുരക്ഷിതമാണെന്ന് പ്രവചിക്കാന്\u200d കഴിയും, ടാക്സോനോമിയുട', 'mt': 'Id-dokument tagħna joffri mudell komputattiv tal-irkupru semantiku tal-argumenti verbali, ittestjat b’mod partikolari fuq oġġetti u Strumenti diretti. Il-mudell ta’ distribuzzjoni sħiħa tagħna huwa maħsub biex itejjeb fuq mudelli antiki bbażati fuq it-tassonomija, li jeħtieġu lexicon minbarra l-korpus ta’ taħriġ. Ikkalkulajna l-preferenzi selettivi ta’ 99 verb tranżittiv u 173 verb tal-Istrument bħala l-valur medju tal-kożini b’żewġ naħat bejn l-argumenti tagħhom (medja peżata bejn l-argumenti kollha, jew medja mhux peżata bl-aktar argumenti k). Ir-riżultati juru li l-mudell tagħna jista’ jipprevedi l-irkuprabbiltà ta’ oġġetti u Strumenti, li jipprovdi riżultat simili għal dak ta’ mudelli bbażati fuq it-tassonomija iżda bi spiża komputattiva ħafna irħas.', 'mn': 'Бидний цаасан нь хэлний аргументын semantic recoverability загварын тооцоололт загвар өгч, ялангуяа шууд объект болон хэрэгсэл дээр шалгалтан байдаг. Бидний бүхэл хуваарилцааны загвар нь дасгал хөгшин татакономийн суурь загваруудыг сайжруулахын тулд зориулагдсан. Энэ нь сургалтын корпус дээр нэмэх лексикон хэрэгтэй. Бид 99 шилжүүлэгч үгийн сонголт сонголтын сонголтуудыг, 173 аргументын хоорондын хоорондын косинуудын дундаж утгыг тооцоолж (бүх аргументын хоорондын жинтэй дундаж, эсвэл хамгийн их k аргументын дундаж жинтэй дундаж гэсэн утгыг тооцоолж байна). Үүний үр дүнд бидний загвар нь объект болон хэрэгсэл дахин сэргээгдэх чадварыг тодорхойлж чадна. Таксономийн үндсэн загваруудын төстэй үр дүнг гаргаж чадна. Гэхдээ маш хямд тооны зардалтай.', 'pl': 'W artykule przedstawiono model obliczeniowy semantycznej odzyskiwalności argumentów czasownikowych, testowany w szczególności na obiektach bezpośrednich i instrumentach. Nasz model w pełni dystrybucyjny ma na celu ulepszenie starszych modeli opartych na taksonomii, które wymagają leksykonu oprócz korpusu szkoleniowego. Obliczyliśmy preferencje selekcyjne czasowników przejściowych 99 i 173 czasowników instrumentowych jako średnią wartość kosynów parowych między ich argumentami (średnia ważona między wszystkimi argumentami lub średnia nieważona z najwyższymi argumentami k). Wyniki pokazują, że nasz model potrafi przewidzieć możliwość odzyskiwania obiektów i instrumentów, zapewniając podobny wynik do modeli opartych na taksonomii, ale przy znacznie tańszych kosztach obliczeniowych.', 'no': 'Papiret vårt tilbyr ein datamaskin modell av semantiske gjenopprettbehandlingar av verbargumenter, testert spesielt på direkte objekt og instrumentar. Vårt fullstendig distribusjonsmodell er for å forbetra eldre taksonomisbaserte modeller, som krev ein leksikon i tillegg til øvingskorpusen. Vi rekna ut valfri innstillingane av 99 transversjonsverber og 173 Instrumentverber som gjennomsnittverdien av de parvis kosinusene mellom argumentene sine (ein vekt gjennomsnittverdi mellom alle argumentene, eller ein uvekt gjennomsnittverdi med de toppeste k argumentene). Resultater viser at modellen vårt kan foregå gjenopprettingsfeiligheten av objekt og instrumentar, som tilbyr ein liknande resultat til taksonomisbaserte modeller, men med mykje billige datakostnader.', 'sr': 'Naš papir nudi kompjuterski model semantičke oporavnosti verbalnih argumenata, posebno testiranog na direktnim objektima i instrumentima. Naš potpuno distribucijski model je nameravan da poboljšamo stare taksonomičke modele, koji zahtevaju leksikon u dodatnom korpusu obuke. Izračunali smo selektivne preferencije 99 tranzivnih verba i 173 Instrumentnih verba kao srednju vrijednost parovog kosina između njihovih argumenta (težina srednja između svih argumenta, ili netežina srednja srednja sa najvećim argumentima). Rezultati pokazuju da naš model može predvidjeti oporavnost objekata i instrumenta, pružajući sličan rezultat taksonomičkih model a, ali na mnogo jeftinijoj računalnoj cijeni.', 'ro': 'Lucrarea noastră oferă un model computațional al recuperabilității semantice a argumentelor verbale, testat în special pe obiecte directe și instrumente. Modelul nostru complet distribuțional este menit să îmbunătățească modelele mai vechi bazate pe taxonomie, care necesită un lexicon în plus față de corpul de formare. Am calculat preferințele selecționale ale 99 de verbe tranzitive și 173 de verbe instrumentale ca valoare medie a cosenelor perechi între argumentele lor (o medie ponderată între toate argumentele, sau o medie necântărită cu argumentele k cele mai sus). Rezultatele arată că modelul nostru poate prezice recuperabilitatea obiectelor și instrumentelor, oferind un rezultat similar cu cel al modelelor bazate pe taxonomie, dar la un cost computațional mult mai ieftin.', 'so': 'Warqaddayadu wuxuu bixiyaa tusaale xisaab ah oo u soo celin kara qiimaha qoraalka, si gaar ah loogu tijaabiyey alaabta tooska ah iyo waxyaabaha hagaajiya. Tusaale-qaybintayada oo dhan waxaa loogu talagalay in lagu hago tusaalooyin waayeel ah oo ku saleysan canshuuraha, kaas oo u baahan yahay leksikan ka sokow koobka waxbarashada. We computed the selectional preferences of 99 transitive verbs and 173 Instrument verbs as the mean value of the pairwise cosines between their arguments (a weighted mean between all the arguments, or an unweighted mean with the topmost k arguments).  Resultiyada waxay muuqan karaan in modellkayagu uu sii sheegi karo soo bogsashada alaabta iyo qalabka, kaasoo sabab u dhigi kara tusaalaha canshuuraha ee ku saleysan, laakiin kharashka xisaabta qiimo jaban.', 'si': 'අපේ පත්තුර පරීක්ෂණය සහ උපකරණය සඳහා පරීක්ෂණය කරලා තියෙනවා. අපේ සම්පූර්ණයෙන්ම විදුලි නිර්මාණයක් තියෙන්නේ පරණ පරීක්ෂණ විද්\u200dයාත්මක විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාප අපි විශ්වාස කරන්නේ 99 වාර්තාවක් සහ 173 වාර්තාවක් විශ්වාස කරන්නේ ඔවුන්ගේ වාර්තාවක් අතර කොසින්ස් අතර කොසින්ස් අතර ක්\u200dරියාත්මක විශ්වාස කරනවා. ප්\u200dරතිචාරය පෙන්වන්නේ අපේ මොඩල් ප්\u200dරශ්නයක් පුළුවන් ප්\u200dරශ්නයක් සහ උපකරණයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් කියලා, ටැක්', 'sv': 'Vår uppsats erbjuder en beräkningsmodell av verbargumentens semantiska återvinningsförmåga, testad i synnerhet på direkta objekt och instrument. Vår helt distribuerade modell är avsedd att förbättra på äldre taxonomiska modeller, som kräver ett lexikon utöver träningskorpusen. Vi beräknade de selektiva preferenserna för 99 transitiva verb och 173 instrumentverb som medelvärdet för de parvisa cosinerna mellan argumenten (ett viktat medelvärde mellan alla argument, eller ett ovikt medelvärde med de översta k argumenten). Resultaten visar att vår modell kan förutsäga återvinningen av objekt och instrument, vilket ger ett liknande resultat som för taxonomiska modeller men till en mycket billigare beräkningskostnad.', 'ur': 'ہماری کاغذ ایک کمپیوٹریشن موڈل ہے جو ویروں کی آرمانٹیوں کی سیمانٹی بازیابی قابلیت ہے، مخصوصاً مستقیم objectوں اور ابزاروں پر آزمائش کی گئی ہے. ہماری پوری طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طر ہم نے ۹۹ ٹرنسیٹیو ویربز اور 173 ٹرنسیٹیو ویربز کی انتخاب کی ترجیح کی تعداد کو ان کے معاملات کے درمیان مزید مقدار کے طور پر محاسبہ کیا ہے (ایک تول کا معاملہ تمام arguments کے درمیان ہے یا ایک تول کا معاملہ بالاترین k arguments کے ساتھ ہے)۔ نتیجے دکھاتے ہیں کہ ہماری مدل موجود چیزوں اور ابزاروں کی بازیابی کی قابلیت کی پیش بینی کر سکتی ہے، تاکسونومنی بنیادی موڈل کے ساتھ ایک جیسا نتیجہ دے سکتی ہے لیکن بہت کم کم کمپیوٹر کے قیمت پر۔', 'ta': 'எங்கள் தாள் ஒரு கணக்கீட்டு மாதிரியை வழங்குகிறது, வெர்ப் தருமதிப்புகளின் பெம்மான்டிக் மீட்டெடுப்பு, குறிப்பாக நே Our fully distributional model is intended to improve on older taxonomy-based models, which require a lexicon in addition to the training corpus.  99 மாற்றும் எழுத்துக்கள் மற்றும் 173 கருவிகளின் தேர்ந்தெடுப்பு முன்னுரிமைகளை நாம் கணக்கிட்டோம் அவர்கள் வார்ப்புகளுக்கிடையே இரண்டு விளக்கமான கோசைன்களின முடிவுகள் காட்டுகிறது நம் மாதிரி பொருட்கள் மற்றும் கருவிகளின் மீண்டும் செல்ல முடியும் என்பதை முன்வாக்க முடியும்.', 'uz': "Qogʻozimizning qismlarining semantik raqamli qismlarining qismlarini o'zgartirish modelini beradi. Hullas tasdiqlangan obʼektlar va vositalar bilan ishlatilgan. Bizning butun tarqatish modelimiz esa eski taxonom asosida modellarni o'zgartirishga ega bo'ladi, bu ta'lim qo'shlarini qo'shishga qo'shish kerak. Biz 99 transitor vositalarning tanlangan parametrlarini va 173 dastur verblarining qiymatini o'z argumentlarining orasidagi ikkita xil kosining qiymati deb hisoblandik (hamma argumentlar orasidagi qiymati yoki eng kichkina argumentlar orasidagi qiymati mumkin). Natijalar ko'rsatadi, bizning modelimiz obʼektlar va vositalarning olib tashkilotlarini oldin oladi, va taxonom asosida o'xshash natijaga ega bo'lishi mumkin, lekin kompyuterning qiymatida juda cheksiz qiymatdir.", 'vi': 'Tờ giấy của chúng tôi đề nghị một mô hình tính cách thu hồi ngữ pháp các đối số được kiểm tra, đặc biệt về vật dụng và vật dụng trực tiếp. Hệ thống phân phối hoàn to àn của chúng tôi nhằm cải thiện các mô hình thuế cũ, cần phải có từ ngữ, thêm vào tập thể huấn. Chúng tôi đã tính toán các khẩu phần chọn của các động từ bắc 99 và 173 Các động từ theo cấu trúc như là giá trị trung bình của đôi cosin giữa các đối tượng của họ (một giá trị được cân bằng giữa tất cả các đối số, hoặc một mức chưa tám với các đối số trên cùng. Kết quả cho thấy mô hình của chúng ta có thể dự đoán khả năng phục hồi vật thể và bộ điều khiển, cung cấp kết quả tương tự như của các mô hình dựa trên taxonomy, nhưng với giá trị tính to án rẻ hơn nhiều.', 'bg': 'Нашата статия предлага изчислителен модел на семантичната възстановяемост на глаголни аргументи, тестван по-специално върху директни обекти и инструменти. Нашият напълно разпределителен модел има за цел да подобри по-старите таксономични модели, които изискват лексикон в допълнение към учебния корпус. Изчислихме селекционните предпочитания на 99 преходни глаголи и 173 инструментални глаголи като средна стойност на двойки косинуси между техните аргументи (претеглена средна стойност между всички аргументи, или неопретеглена средна стойност с най-горните аргументи). Резултатите показват, че нашият модел може да предвиди възстановяемостта на обекти и инструменти, осигурявайки подобен резултат на този на таксономични модели, но на много по-евтина изчислителна цена.', 'nl': 'Onze paper biedt een computationeel model van de semantische herstelbaarheid van werkwoorden argumenten, met name getest op directe objecten en instrumenten. Ons volledig distributiemodel is bedoeld om oudere op taxonomie gebaseerde modellen te verbeteren, die naast het trainingscorpus een lexicon vereisen. We berekenden de selectievoorkeuren van 99 transitieve werkwoorden en 173 Instrument werkwoorden als de gemiddelde waarde van de parenwise cosinus tussen hun argumenten (een gewogen gemiddelde tussen alle argumenten, of een ongewogen gemiddelde met de hoogste k argumenten). De resultaten tonen aan dat ons model de herstelbaarheid van objecten en instrumenten kan voorspellen, wat een vergelijkbaar resultaat oplevert als dat van taxonomie-gebaseerde modellen, maar tegen een veel lagere rekenkosten.', 'hr': 'Naš papir nudi računalni model semantičke oporavljivosti verbalnih argumenata, ispitivan posebno na direktnim objektima i instrumentima. Naš potpuno distribucijski model je namjeren poboljšati starije modele na taksonomiji, koji zahtijevaju leksikon u dodatnoj obuci. Izračunali smo selektivne preferencije 99 tranzičnih verba i 173 Instrumentnih verba kao srednju vrijednost parovog kosina između njihovih argumenta (težina srednja između svih argumenta ili neutežina srednja s najvećim argumentima). Rezultati pokazuju da naš model može predvidjeti oporavak objekata i instrumenta, pružajući sličan rezultat taksonomičkim modelima, ali na mnogo jeftinijim računalnim cijenima.', 'da': 'Vores artikel tilbyder en beregningsmodel for semantisk genvindelighed af verber argumenter, testet især på direkte objekter og instrumenter. Vores fuldt fordelingsmodel har til formål at forbedre ældre taksonomibaserede modeller, der kræver et leksikon ud over træningskorpusset. Vi beregnede de valgte præferencer for 99 overgangsverber og 173 instrumentverber som gennemsnitsværdien af de parvise cosiner mellem deres argumenter (et vægtet gennemsnit mellem alle argumenterne, eller et uvægtet gennemsnit med de øverste k argumenter). Resultaterne viser, at vores model kan forudsige genvindingsevnen af objekter og instrumenter, hvilket giver et resultat svarende til resultatet af taksonomi-baserede modeller, men til en meget billigere beregningsomkostning.', 'de': 'Unser Beitrag bietet ein computergestütztes Modell der semantischen Wiedergewinnbarkeit von Verbargumenten, das insbesondere an direkten Objekten und Instrumenten getestet wurde. Unser Vollverteilungsmodell soll ältere taxonomiebasierte Modelle verbessern, die zusätzlich zum Trainingskorpus ein Lexikon benötigen. Wir haben die Selektionspräferenzen von 99 transitiven Verben und 173 Instrumentenverben als Mittelwert der paarweisen Cosinus zwischen ihren Argumenten berechnet (ein gewichteter Mittelwert zwischen allen Argumenten oder ein ungewichteter Mittelwert mit den obersten k Argumenten). Die Ergebnisse zeigen, dass unser Modell die Wiederherstellungsfähigkeit von Objekten und Instrumenten vorhersagen kann und ein ähnliches Ergebnis wie bei taxonomiebasierten Modellen liefert, jedoch zu einem viel günstigeren Rechenkosten.', 'ko': '우리의 논문은 동사 매개 변수의 의미를 회복할 수 있는 계산 모델을 제공했고 특히 직접 목적어와 도구에서 테스트를 실시했다.우리의 완전 분포 모델은 기존의 분류법을 바탕으로 한 모델을 개선하는 데 목적을 둔다. 이런 모델은 언어 자료 라이브러리를 훈련하는 것 외에 사전도 필요하다.우리는 99개의 물동사와 173개의 도구동사의 선택 선호도를 계산하여 그것들의 매개 변수 사이에 여현의 평균값(모든 매개 변수 간의 가중평균값, 또는 맨 윗부분 k개 매개 변수의 가중평균값)을 만들었다.결과에 따르면 우리의 모델은 물체와 기기의 회복성을 예측할 수 있고 분류를 바탕으로 하는 모델과 유사한 결과를 제공할 수 있으나 계산 원가가 훨씬 낮다.', 'id': 'Kertas kami menawarkan model komputasi pemulihan semantis argumen verb, diuji terutama pada objek langsung dan Instrumen. Model distribusi kita sepenuhnya bertujuan untuk meningkatkan pada model yang lebih tua berdasarkan taksonomi, yang membutuhkan leksikon selain korpus latihan. Kami menghitung keutamaan selektif dari 99 verb transitif dan 173 verb Instrument sebagai nilai rata-rata kosinus sepasang antara argumen mereka (rata-rata berat antara semua argumen, atau rata-rata tidak berat dengan argumen topmost k). Hasil menunjukkan bahwa model kita dapat memprediksi kemudahan pemulihan objek dan Instrumen, menyediakan hasil yang sama dengan hasil dari model berdasarkan taksonomi tetapi dengan biaya komputasi yang jauh lebih murah.', 'sw': 'Gazeti letu linatoa mtindo wa hisabati wa kuboresha upya wa mijadala ya maneno, yakijaribiwa hasa kwenye vitu na vifaa vya moja kwa moja. Mradi wetu wa usambazaji mzima unakusudia kuboresha mifano ya zamani yenye msingi wa taxonomy, ambayo inahitaji lexico zaidi ya mashindano ya mafunzo. Tumekadiria chaguo la kurasa za maneno 99 ya mpito na zana 173 kama thamani ya maana ya cosini hizo mbili za kigeni kati ya hoja zao (maana yenye uzito kati ya hoja zote, au maana yasiyoeleweka na hoja za juu). Matokeo yanaonyesha kuwa muundo wetu unaweza kutabiri uwezekano wa upya wa vitu na vifaa, na kutoa matokeo yanayofanana na mifano inayotokana na utamaduni lakini kwa gharama rahisi za hisabati.', 'fa': 'کاغذ ما یک مدل محاسباتی از بازیابی semantic arguments verb را پیشنهاد می\u200cدهد، مخصوصاً در مورد اشیاء و ابزار مستقیم آزمایش شده است. مدل کامل توزیع ما قصد دارد بر مدل های قدیمی بر پایه تاکسونومی بهتر شود که در addition to the training corpus نیاز به یک لکسین دارد. ما ترجیح\u200cهای انتخابی ۹۹ کلمه تغییرات و 173 کلمه\u200cهای ابزار را به عنوان ارزش متوسط کاسین\u200cهای جفت\u200cگونه بین ارزش\u200cهای آنها محاسبه کردیم (معنی وزن بین تمام ارزش\u200cها یا معنی وزن\u200cگونه\u200cای با بالاترین ارزش\u200cهای k). نتیجه\u200cها نشان می\u200cدهند که مدل ما می\u200cتواند قابلیت بازیابی وسیله\u200cها و وسیله\u200cها را پیش\u200cبینی کند، و نتیجه\u200cای مشابه به مدل\u200cهای پایه\u200cی تاکسونوم می\u200cدهد، ولی با هزینه\u200cهای کامپیوتری ارزون تر است.', 'af': "Ons papier bied 'n rekenaarsie model van die semantiese herstelbaarheid van verb argumente, in besonderhede toets op direkte objekte en Instrumente. Ons volledige verspreidingsmodel is bedoel om op ouer taksonomie-gebaseerde modele te verbeter, wat 'n leksikon benodig in addition to the training corpus. Ons het die seleksiese voorkeure van 99 tranzitiewe verbe en 173 Instrument verbe bereken as die gemiddelde waarde van die paarswyse cosine tussen hulle argumente ( 'n geweegte middel tussen al die argumente, of 'n ongeweegte middel met die boonste k argumente). Resultate wys dat ons model kan voorskou die herstelbaarheid van voorwerpe en instrumente, wat 'n gelyke result a at verskaf aan wat van taksonomie-gebaseerde modele, maar op 'n baie skadelike rekenaar koste.", 'sq': 'Gazeta jonë ofron një model llogaritës të ripërtëritjes semantike të argumenteve të verb ëve, të testuar në veçanti në objekte të drejtpërdrejta dhe Instrumente. Modeli ynë plotësisht shpërndarës ka për qëllim të përmirësohet në modelet më të vjetra bazuar në taksonomi, që kërkojnë një lexikon përveç korpusit të stërvitjes. Ne llogaritëm preferimet zgjedhore të 99 verbëve tranzitive dhe 173 verbëve të Instrumentit si vlerën mesatare të kosinujve të palëvizshëm midis argumenteve të tyre (një mesatare të peshuar midis të gjitha argumenteve, ose një mesatare të papeshuar me argumentet më të larta k). Rezultatet tregojnë se modeli ynë mund të parashikojë ripërtëritjen e objekteve dhe instrumenteve, duke ofruar një rezultat të ngjashëm me at ë të modeleve bazuar në taksonomi por me një kosto shumë më të lirë llogaritare.', 'am': 'Our paper offers a computational model of the semantic recoverability of verb arguments, tested in particular on direct objects and Instruments.  የሙሉ አካባቢ ሞዴላታችን በሽማግሌ የመካነ ምርጫዎች ላይ ማሻሻል ነው፡፡ የ99 ትርጉም ቃላት እና 173 የኢንተርኔት ቃላት የተመረጠውን ምርጫዎች በአካባቢዎቹ መካከል የሁለት ጥበብ ኮኮኖችን ዋጋ እንደሚመስል ቆጠርን (በአካባሮች ሁሉ መካከል ሚዛን ወይም በላይኛው ክርክሮች ላይ የማይሰፍር ማሰናከል ነው፡፡ ፍጥረቶቹ ሞዴል አካባቢዎችን እና መሣሪያዎችን ለመቀበል የሚችል እንደሆነ እና እንደዚህ በሚያሳየው የስክስኖም ዓይነቶች ግን እጅግ በጣም ቀላል ቁጥጥር ዋጋ እንዲሰጥ ይችላል፡፡', 'tr': 'Biziň kagyzymyz semantik wersiýa argümentleriniň hasaplanjak nusgasyny teklip edýär, düzgün zadlar we Instrumentler barada testedilen. Biziň doly daýlamak nusgasymyz uly taksowoniň tabanly nusgalaryny gowlamak üçin maksady edildi. Bu nusgasymyz köpüsi üçin leksikon gerek. Biz 99 geçici verblerniň seçeneklerini ve 173 Instrument verblerniň orta değeri olaryň argumlaryň arasynda (bütün argumlar arasynda çəkilmiş orta değeri, ya da iň yüksek argumlar arasynda çəkilmedik orta değeri) hesapladık. Netijenler biziň modelimizin zadlaryň we Instrumentlaryň ýetip biljek ukyplaryny tahmin edip biljek bolýandygyny görkezip, taksiýaly tabanly nusgalaryň ýaly bir netijesi bar, ýöne has örän uc sanat hasaplamada.', 'hy': 'Մեր թղթին առաջարկում է բայերի հաշվարկման մոդել, որը նշանակում է բայերի վերականգնելիությունը, հատկապես ուղղակի առարկաների և գործիքների վրա: Մեր ամբողջ բաշխման մոդելը նպատակով է բարելավել ավելի հին տաքսոնոմիայով հիմնված մոդելները, որոնք պահանջում են լեքսիկոն, ավելին վարժեցման կորպոսին: Մենք հաշվարկեցինք 99 տրանզինցիոն բայի ընտրական նախընտրությունները և 173 գործիքի բայերը որպես զույգչափ կոսինների միջին արժեքը իրենց փաստարկների միջև (բոլոր փաստարկների միջև կեշտրված միջին արժեքը, կամ անկեշտրված միջին ամենաբարձր k փաստարկների միջև): Արդյունքները ցույց են տալիս, որ մեր մոդելը կարող է կանխատեսել օբյեկտների և գործիքների վերականգնելիությունը, տաքսոնոմիայով հիմնված մոդելների նմանատիպ արդյունք տալով, բայց շատ ավելի էժան հաշվարկման գնով:', 'bs': 'Naš papir nudi kompjuterski model semantičke oporavnosti verbalnih argumenata, posebno testiranog na direktnim objektima i instrumentima. Naš potpuno distribucijski model je namjeren poboljšati stare modele na taksonomiji, koji zahtijevaju leksikon u dodatnom korpusu obuke. Izračunali smo selektivne preferencije 99 tranzičnih verba i 173 Instrumentnih verba kao srednju vrijednost parovog kosina između njihovih argumenta (težina srednja između svih argumenta, ili neutežina srednja srednja sa najvećim argumentima). Rezultati pokazuju da naš model može predvidjeti oporavnost objekata i instrumenta, pružajući sličan rezultat taksonomičkih model a, ali na mnogo jeftinijoj računalnoj cijeni.', 'bn': 'আমাদের পত্রিকাটি ভার্ব যুক্তি পুনরুদ্ধারের সামান্যিক মডেল প্রদান করেছে, বিশেষ করে সরাসরি বস্তু এবং ইনস্টিমেন্টের উপর পর আমাদের পুরোপুরি বিতরণ মডেলের উদ্দেশ্য হচ্ছে পুরোনো ট্যাক্সোনোমি ভিত্তিক মডেলের উপর উন্নতি করার, যা প্রশিক্ষণ কোর্পাস ছ আমরা ৯৯৯ টি ট্রান্সপ্রান্সিভ ভ ভার্ভ এবং ১৭৩ ইনস্টোমেন্ট ভার্ভের নির্বাচিত পছন্দ হিসেবে গণনা করেছি তাদের যুক্তির মধ্যে দুই জ্ঞানী কসিনের মানে (যে  ফলাফল দেখা যাচ্ছে যে আমাদের মডেল জিনিসপত্র এবং ইনস্ট্রোমেন্টের পুনরুদ্ধার বিষয়টি ভবিষ্যদ্বাণী করতে পারে, যার ফলে ট্যাক্সোনোমির ভিত্তিক', 'az': 'Bizim kańüńĪzńĪmńĪz verb argumentl…ôrin semantik geri qaytarńĪlmasńĪ modelini t…ôklif edir, √∂zl…ôrin…ô d…ô dońüru objektl…ôr v…ô Instruments bar…ôsind…ô imtahana edilmiŇüdir. Bizim tamamil…ô dańüńĪtńĪlma modelimiz yaŇülńĪ taxonomiya tabanlńĪ modell…ôr…ô yaxŇüńĪlaŇüdńĪrmaq m…ôqs…ôdildir ki, t…ôhsil korpusu il…ô birlikd…ô leksik lazńĪmdńĪr. Biz 99 ke√ßici verbl…ôrin se√ßimli se√ßiml…ôri v…ô 173 Instrument verbl…ôrini onlarńĪn argumentl…ôrin arasńĪndakńĪ orta qiym…ôti kimi hesabladńĪq (b√ľt√ľn argumentl…ôrin arasńĪnda √ß…ôkilmiŇü orta qiym…ôti, yaxud …ôn y√ľks…ôk argumentl…ôrin arasńĪnda √ß…ôkilm…ômiŇü orta qiym…ôti). Sonu√ßlar g√∂st…ôrir ki modell…ôrimiz objektl…ôrin v…ô InstrumentolarńĪn geri qaytarńĪlmasńĪnńĪ t…ômin ed…ô bil…ôr, taxonomiya tabanlńĪ modell…ôrin istifad…ôsin…ô b…ônz…ôr bir sonu√ß verir, amma daha ucuz hesap maliyy…ôtin…ô g√∂r…ô.', 'ca': "El nostre article ofereix un model computacional de la recuperabilitat semàntica dels arguments de verbs, testats en particular en objectes directs i Instruments. El nostre model de distribució està destinat a millorar els models basats en taxonomia més vells, que requereixen un lèxic a més del cos d'entrenament. Vam calcular les preferències selectives de 99 verbs transitoris i 173 verbs d'Instrument com el valor mitjà dels cosins per parell entre els seus arguments (una mitjana ponderada entre tots els arguments, o una mitjana no ponderada amb els arguments k més alt). Els resultats demostren que el nostre model pot predir la recuperabilitat d'objectes i Instruments, proporcionant un result at similar al dels models basats en la taxonomia, però a un cost calculatiu molt més barat.", 'cs': 'Náš článek nabízí výpočetní model sémantické obnovitelnosti slovesových argumentů, testovaný zejména na přímých objektech a přístrojích. Náš plně distribuční model je určen ke zlepšení starších modelů založených na taxonomii, které vyžadují kromě výcvikového korpusu lexikon. Vypočítali jsme selekční preference 99 přechodných sloves a 173 nástrojových sloves jako průměrnou hodnotu párových kosinusů mezi jejich argumenty (vážený průměr mezi všemi argumenty, nebo nevážený průměr s nejvyššími argumenty k). Výsledky ukazují, že náš model dokáže předpovídat obnovitelnost objektů a přístrojů, což poskytuje podobný výsledek jako u modelů založených na taxonomii, ale za mnohem levnější výpočetní náklady.', 'et': 'Meie töö pakub arvutuslikku mudelit verbiargumentide semantilise taastamise kohta, mida on testitud eelkõige otseselt objektidel ja instrumentidel. Meie täielikult jaotusmudel on mõeldud vanemate taksonoomiliste mudelite täiustamiseks, mis vajavad lisaks koolituskorpusele sõnavara. Arvutasime 99 transitiivse tegusõna ja 173 Instrumendi tegusõna valikulised eelistused nende argumentide vahel paariühiste koosiinuste keskmise väärtusena (kaalutud keskmine kõigi argumentide vahel või kaalumata keskmine ülemise k argumentidega). Tulemused näitavad, et meie mudel suudab prognoosida objektide ja instrumentide taastamist, andes sarnase tulemuse taksonoomial põhinevate mudelitega, kuid palju odavama arvutuskuluga.', 'fi': 'Tutkimuksemme tarjoaa laskennallisen mallin verbiaargumenttien semanttisesta palautuvuudesta, jota on testattu erityisesti suorilla objekteilla ja instrumenteilla. Täysin jakautumismallimme on tarkoitettu parantamaan vanhempia taksonomiaan perustuvia malleja, jotka edellyttävät koulutuskorpusen lisäksi sanastoa. Laskettiin 99 transitiivisen verbin ja 173 instrumenttivernin valinnaiset valinnat niiden argumenttien väliseksi parikohtaiseksi koosiiniksi (painotettu keskiarvo kaikkien argumenttien välillä tai painottamaton keskiarvo ylimmällä k argumentilla). Tulokset osoittavat, että mallimme pystyy ennustamaan kohteiden ja instrumenttien talteenottokykyä, mikä antaa samanlaisen tuloksen kuin taksonomiaan perustuvilla malleilla, mutta paljon halvemmalla laskennallisella kustannuksella.', 'jv': 'Awakdhéwé éntuk sistem sistem sing sematik perusahaan kelompok, dadi nguasar barang kelompok object lan Instrument Awak dhéwé, model Distribution sing dipunangé luwih nggawe mobil nang sampek model sing wis ana dadi, kudu supoyo perusahaan tambah bantuan ngono nggawe cara-cara. Awak dhéwé kalem nggawe bener sing dibutuhke ning perbudhakan benih (dino sing dibutuhke karo perbudhakan ingkang dipun dadi) sing berarti 1 Ngomongé wong-wong kuwi model sing bisa supoyo perusahaan anyar karo Instrument, supoyo barang sampek karo model sing dadi tho, dadi kaé karo model sing basa tah maning, ngono akeh dolang teluktan karo akeh dumadhi', 'ha': "Kayan takardu na bãyar da wani misali na ƙidãya na canza cewa mai canza mazaɓa na verb, da aka jarraba, haske da masu shirya da Shirin Ayuka. Misalinmu cikakken rabon, aka yi nufin ya kyautata misãlai na tsohon taxnomi, wanda yana buƙata wani leksisi da kuma a ƙara kowaci. Mun ƙidãya zaɓa ɓen takardar verbs 99 ta shige da a k an aiki 173 kamar kiman nau'in kokain biyu tsakanin argument (mai nauyi tsakanin duk argument, ko kuma wata nau'in da ba'a yi shi ba da matsayin rubutun sarki). Matamakon za'a nuna cewa misalinmu yana iya ƙididdige masu abubuwa da shiryoyin ayuka, da ya sami matsayin misalin taxnomi, kuma amma yana da akan kashi mai sauƙi.", 'sk': 'Naš prispevek ponuja računalniški model semantične obnovljivosti glagolnih argumentov, preizkušen zlasti na neposrednih objektih in instrumentih. Naš popolnoma distribucijski model je namenjen izboljšanju starejših taksonomijskih modelov, ki poleg korpusa usposabljanja zahtevajo leksikon. Izračunali smo selekcijske preference 99 prehodnih glagolov in 173 instrumentnih glagolov kot povprečno vrednost parnih kozinusov med njihovimi argumenti (tehtano srednjo vrednost med vsemi argumenti ali neotehtano srednjo vrednost z zgornjimi k argumenti). Rezultati kažejo, da lahko naš model napove obnovljivost objektov in instrumentov, kar zagotavlja podoben rezultat kot pri taksonomijskih modelih, vendar z veliko cenejšimi računalniškimi stroški.', 'he': 'העיתון שלנו מציע מודל מחשבי של היכולת לשחזר סמנטית של ויכוחי אלברים, מבחנים במיוחד על חפצים ישירים והכלים. מודל ההפצה המלאה שלנו נועד לשפר על מודלים מבוססים על טקסונומיה ישנים, שדורשים לקסיקון בנוסף לקורפוס האימון. חישבנו את ההעדיפות הבחירות של 99 אלברים מעבר 173 אלברים כלים כערך הממוצע של קוזינים זוגות בין הטיעונים שלהם (ממוצע משקל בין כל הטיעונים, או ממוצע לא משקל עם הטיעונים העליונים k). התוצאות מראות שמודל שלנו יכול לחזות את היכולת לחזור של חפצים ומכשירים, לספק תוצאה דומה למודלים מבוססים במקסונומיה, אך בעלות מחשב הרבה יותר זולה.', 'bo': 'ང་ཚོའི་ཤོག་བྱང་གིས་བྱ་ཚིག་གི་སྔོན་སྒྲིག་ཀྱི་རྩིས་འཁོར་གྱི་མ་དཔེ་གཞི་སྤྲོད་དུ་བྱེད་སྤྲོད་ཀྱི་རྣམ་པ་དང་སྒྲུབ་ར ང་ཚོའི་ཆ་ཚང་བར་དབྱིབས་ཆེན་སྤྲོད་ཀྱི་མ་དབུགས་དེ་ལས་རྒྱལ་ཁབ་ཀྱི་དཔེ་རིགས་ལ་རྙིང་བ་དང་མཐུན་སྒྲིག་ཀྱི་དཔེ་རིགས་ལ་ཡར་ ང་ཚོས་བརྗོད་ཟིན་པའི་བྱ་ཚིག་དང་བསྒྲགས་སྐབས་ཀྱི་རང་མོས་སྒྲིག གྲུབ་འབྲས་བ་དེ་ནི་ང་ཚོའི་མ་དབྱིབས་གཟུགས་རིས་དང་སྒྲིག་ཆས་ཀྱི་རྐྱེན་སྐྱེན་རིས་སྔོན་ལྟ་བུ་བཏུབ་ཡོད།'}
{'en': 'Learning Negation Scope from Syntactic Structure', 'ar': 'تعلم مجال النفي من البنية النحوية', 'pt': 'Escopo de Negação de Aprendizagem da Estrutura Sintática', 'es': 'Aprender el alcance de la negación de la estructura sintáctica', 'fr': 'Apprendre la portée de négation à partir de la structure syntaxique', 'zh': '从句法结构学否', 'ja': '構文構造からネガティブスコープを学ぶ', 'ru': 'Область отрицания обучения на основе синтаксической структуры', 'hi': 'वाक्यात्मक संरचना से नकारात्मकता क्षेत्र सीखना', 'ga': 'Scóip Diúltaithe Foghlama ó Struchtúr Comhréire', 'ka': 'სინტექტიკური სტრუქტურაციის განსხვავება', 'hu': 'A negatív hatókör tanulása a szintaktikus struktúrából', 'el': 'Μάθηση Αρνητικού πεδίου από τη Συντακτική Δομή', 'it': 'Learning Negation Scope from Syntactic Structure', 'kk': 'Синтактикалық құрылғыдан сөздеу сәйкестігін үйрену', 'lt': 'Mokymosi neigiamo poveikio sritis pagal sintaktinę struktūrą', 'mk': 'Учење на областа на негативност од синтактичката структура', 'ms': 'Pelajaran Skop Negasi dari Struktur Sintaktik', 'ml': 'സിന്റാക്റ്റിക് സ്ട്രാക്ട്രിക്കില്\u200d നിന്നുള്ള നേഗസ്കോപ്പ് പഠിക്കുന്നു', 'mt': 'L-ambitu tan-Negazzjoni tat-Tagħlim mill-Istruttura Sintattika', 'mn': 'Синтактик бүтээгдэхүүнээс хамааралтай өргөн суралцах', 'no': 'Læring av negasjonsområde frå syntaktisk struktur', 'sr': 'Naučenje Negacije iz sintaktičke strukture', 'pl': 'Uczenie się zakresu negacji ze struktury syntaktycznej', 'ro': 'Domeniul de învățare al negării din structura sintattică', 'si': 'සංවිධානය සංවිධානයෙන් ප්\u200dරතික්\u200dරීය ස්කෝප් ඉගෙනගන්න', 'so': 'Barid Negation Scope from Syntactic Structure', 'sv': 'Att lära sig Negation Scope från syntaktisk struktur', 'ta': 'ஒத்திசைவு கட்டுப்பாட்டிலிருந்து நேஜியன் ஸ்கோப்பை கற்றுக்கொண்டிருக்கிறது', 'ur': 'سینٹکسٹیک ساختاری سے ناگزاری سکوپ سیکھا جاتا ہے', 'uz': 'Name', 'vi': 'Học địa chỉ thao tác từ cấu trúc Y pháp', 'nl': 'Negatiebereik leren van syntactische structuur', 'bg': 'Обхват на изучаване на отрицанието от синтактичната структура', 'hr': 'Naučenje Negacije iz sintaktičke strukture', 'da': 'Læring af Negation Scope fra syntaktisk struktur', 'de': 'Lernen des Negationsbereichs aus syntaktischer Struktur', 'fa': 'یاد گرفتن محدوده\u200cی منحصر از ساختار سنتاکتیک', 'ko': '문법 구조에서 부정 범위를 배우다', 'id': 'Learning Negation Scope from Syntactic Structure', 'af': 'Leer Negasie Skep van Sintaktika Struktuur', 'sw': 'Kujifunza Sehemu ya Mawasiliano kutoka Mfumo wa Syntactic', 'sq': 'Mësimi i fushës së refuzimit nga struktura sintaktike', 'tr': 'Sintaktik strukturdan Ýagtylamak Derjesini öwrenmek', 'hy': 'Սինտակտիկ կառուցվածքից բացասական տարբերակ սովորելը', 'am': 'Learning Negation Scope from Syntactic Structure', 'bn': 'Learning Negation Scope from Syntactic Structure', 'cs': 'Rozsah učení negativního rozsahu ze syntaktické struktury', 'az': 'Sintaktik Yapılandırması', 'bs': 'Naučenje Negacije iz sintaktičke strukture', 'fi': 'Kieltämisen oppiminen synteettisestä rakenteesta', 'et': 'Negatiivsuse õppimise ulatus süntaktilisest struktuurist', 'ca': "Aprendre l'àmbit de negatió a partir de l'estructura sintàctica", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'לימוד גוף שלילה מהמבנה סינטקטי', 'sk': 'Obseg učenja negacije iz sintetične strukture', 'ha': 'KCharselect unicode block name', 'bo': 'Learning Negation Scope from Syntactic Structure'}
{'en': 'We present a semi-supervised model which learns the semantics of negation purely through analysis of syntactic structure. Linguistic theory posits that the semantics of negation can be understood purely syntactically, though recent research relies on combining a variety of features including part-of-speech tags, word embeddings, and semantic representations to achieve high task performance. Our simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the syntax and semantics of negation.', 'ar': 'نقدم نموذجًا شبه خاضع للإشراف يتعلم دلالات النفي تمامًا من خلال تحليل البنية النحوية. تفترض النظرية اللغوية أن دلالات النفي يمكن فهمها بشكل نحوي بحت ، على الرغم من أن الأبحاث الحديثة تعتمد على الجمع بين مجموعة متنوعة من الميزات بما في ذلك علامات جزء من الكلام ، وتضمينات الكلمات ، والتمثيلات الدلالية لتحقيق أداء مهام عالي. يعود نموذجنا المبسط إلى النظرية النحوية ويحقق أداءً متطورًا في مهمة اكتشاف نطاق النفي مع إظهار العلاقة الوثيقة بين بناء الجملة ودلالات النفي.', 'fr': "Nous présentons un modèle semi-supervisé qui apprend la sémantique de la négation uniquement par l'analyse de la structure syntaxique. La théorie linguistique pose que la sémantique de la négation peut être comprise de façon purement syntaxique, bien que des recherches récentes reposent sur la combinaison d'une variété de caractéristiques, y compris les balises de parties du discours, les incorporations de mots et les représentations sémantiques pour obtenir des performances élevées. Notre modèle simplifié revient à la théorie syntaxique et atteint des performances de pointe sur la tâche de détection de portée de négation tout en démontrant la relation étroite entre la syntaxe et la sémantique de la négation.", 'es': 'Presentamos un modelo semi-supervisado que aprende la semántica de la negación únicamente a través del análisis de la estructura sintáctica. La teoría lingüística postula que la semántica de la negación se puede entender puramente sintácticamente, aunque investigaciones recientes se basan en combinar una variedad de características que incluyen etiquetas de parte del discurso, incrustaciones de palabras y representaciones semánticas para lograr un alto rendimiento en las tareas. Nuestro modelo simplificado vuelve a la teoría sintáctica y logra un rendimiento de vanguardia en la tarea de detección del alcance de la negación, al tiempo que demuestra la estrecha relación entre la sintaxis y la semántica de la negación.', 'pt': 'Apresentamos um modelo semi-supervisionado que aprende a semântica da negação puramente por meio da análise da estrutura sintática. A teoria linguística postula que a semântica da negação pode ser entendida puramente sintaticamente, embora pesquisas recentes se baseiem na combinação de uma variedade de recursos, incluindo tags de parte da fala, incorporação de palavras e representações semânticas para obter alto desempenho na tarefa. Nosso modelo simplificado retorna à teoria sintática e alcança desempenho de última geração na tarefa de detecção de escopo de negação, ao mesmo tempo em que demonstra a estreita relação entre a sintaxe e a semântica da negação.', 'ja': '純粋に構文構造の分析を通じて否定の意味論を学習する半監督モデルを提示する。言語理論では、否定の意味論は純粋に構文的に理解できると仮定しているが、最近の研究では、高いタスクパフォーマンスを達成するために、音声の一部のタグ、単語の埋め込み、意味論的表現などのさまざまな機能を組み合わせることに依存している。簡略化されたモデルは構文理論に戻り、否定の構文と意味論の間の緊密な関係を実証しながら、ネガティブスコープ検出のタスクで最先端のパフォーマンスを実現します。', 'hi': 'हम एक अर्ध-पर्यवेक्षित मॉडल प्रस्तुत करते हैं जो वाक्यात्मक संरचना के विश्लेषण के माध्यम से विशुद्ध रूप से नकार के शब्दार्थ को सीखता है। भाषाई सिद्धांत यह मानता है कि निषेध के शब्दार्थ को विशुद्ध रूप से वाक्यात्मक रूप से समझा जा सकता है, हालांकि हाल के शोध उच्च कार्य प्रदर्शन को प्राप्त करने के लिए भाग-भाषण टैग, शब्द एम्बेडिंग और शब्दार्थ प्रतिनिधित्व सहित विभिन्न प्रकार की विशेषताओं के संयोजन पर निर्भर करते हैं। हमारा सरलीकृत मॉडल वाक्यात्मक सिद्धांत पर लौटता है और निषेध के वाक्यविन्यास और शब्दार्थ के बीच तंग संबंधों का प्रदर्शन करते हुए नेगेशन स्कोप डिटेक्शन के कार्य पर अत्याधुनिक प्रदर्शन प्राप्त करता है।', 'zh': '建一个半监模,析句法以学非语义。 语言学理以为非语义可纯解于句法,虽近者究依于合,兼词性标签、词嵌、语义,以成高任。 吾徒反句法之论,而致先进之能,申其语法语义之密。', 'ru': 'Представляем полунадзорную модель, которая изучает семантику отрицания чисто через анализ синтаксической структуры. Лингвистическая теория утверждает, что семантика отрицания может быть понята чисто синтаксически, хотя недавние исследования опираются на сочетание множества функций, включая теги части речи, вложения слов и семантические представления для достижения высокой производительности задачи. Наша упрощенная модель возвращается к синтаксической теории и достигает самой современной производительности по задаче обнаружения области отрицания, демонстрируя при этом тесную связь между синтаксисом и семантикой отрицания.', 'ga': 'Cuirimid múnla leath-mhaoirsithe i láthair a fhoghlaimíonn séimeantaic an diúltaithe trí anailís a dhéanamh ar struchtúr comhréire amháin. Deartar ar theoiric na teangeolaíochta gur féidir an shéimeantaic diúltaithe a thuiscint go comhréir amháin, cé go mbraitheann taighde le déanaí ar éagsúlacht gnéithe a chomhcheangal lena n-áirítear clibeanna cuid cainte, leabaithe focal, agus léirithe shéimeantacha chun ardfheidhmíocht tascanna a bhaint amach. Filleann ár múnla simplithe ar theoiric chomhréire agus baintear amach feidhmíocht úrscothach ar an tasc a bhaineann le Brath Scóip Diúltaithe agus ag an am céanna léiríonn sé an gaol daingean idir an chomhréir agus an tséimeantaic an diúltaithe.', 'ka': 'ჩვენ ვიყვანეთ ნახევარჯერი მოდელს, რომელიც დავისწავლის ნედაციის სიმენტიკების განსხვავებას უბრალოდ სინტაქტიული სტრუქტურის ანალიზაციით. ლთნდვისტიკური თეორია პოზიცის, რომ ნედაციის სიმენტიკები უბრალოდ სინტაქტიურად შეიძლება გავიგოთ, თუმცა ახალი სწავლად სწავლად განსხვავებული ფუნქციების შესაბამისთვის შესაბამისთვის განსხვავებული ფუნქციები ჩვენი განსხვავებული მოდელი სინტაქტიული ტეორიაში გადაბრუნდება და მიიღება სინტაქსის და სიმენტიკის განსხვავების საქმე, რომელიც განსხვავებული განსხვავების საქმე დასაწყება.', 'hu': 'Egy félig felügyelt modellt mutatunk be, amely tisztán a szintaktikus struktúra elemzésével tanulja meg a negatív szemantikáját. A nyelvelmélet azt állítja, hogy a negatív szemantikája tisztán szintaktikusan érthető, bár a legújabb kutatások számos funkciót kombinálnak, beleértve a beszédrész címkéket, a szóbeágyazásokat és a szemantikai reprezentációkat a nagy feladatteljesítmény elérése érdekében. Egyszerűsített modellünk visszatér a szintaktikai elmélethez, és korszerű teljesítményt ér el a negatív hatókör detektálás feladatában, miközben bemutatja a negatív szintaxis és szemantika közötti szoros kapcsolatot.', 'el': 'Παρουσιάζουμε ένα ημι-εποπτευμένο μοντέλο που μαθαίνει τη σημασιολογία της άρνησης καθαρά μέσα από την ανάλυση της συντακτικής δομής. Η γλωσσολογική θεωρία υποστηρίζει ότι η σημασιολογία της άρνησης μπορεί να κατανοηθεί καθαρά συντακτικά, αν και η πρόσφατη έρευνα βασίζεται στο συνδυασμό ποικίλων χαρακτηριστικών, συμπεριλαμβανομένων των ετικετών τμημάτων ομιλίας, των ενσωμάτωσης λέξεων και των σημασιολογικών αναπαραστάσεων για να επιτευχθεί υψηλή απόδοση εργασίας. Το απλοποιημένο μοντέλο μας επιστρέφει στη συντακτική θεωρία και επιτυγχάνει την υπερσύγχρονη απόδοση στο έργο της ανίχνευσης πεδίου άρνησης ενώ καταδεικνύει τη στενή σχέση μεταξύ της σύνταξης και της σημασιολογίας της άρνησης.', 'it': "Presentiamo un modello semi-supervisionato che apprende la semantica della negazione esclusivamente attraverso l'analisi della struttura sintattica. La teoria linguistica sostiene che la semantica della negazione può essere compresa puramente sintatticamente, anche se la ricerca recente si basa sulla combinazione di una varietà di caratteristiche tra cui tag part-of-speech, embedding di parole e rappresentazioni semantiche per ottenere prestazioni elevate dei compiti. Il nostro modello semplificato ritorna alla teoria sintattica e raggiunge prestazioni all'avanguardia sul compito di Negation Scope Detection dimostrando allo stesso tempo la stretta relazione tra sintassi e semantica della negazione.", 'lt': 'Mes pristatome pusiau prižiūrėtą model į, kuris mokosi neigiamos semantikos tik analizuojant sintaksinę struktūrą. Linguistinė teorija rodo, kad neigiamos semantikos galima suprasti tik sintetiškai, nors neseniai atlikti moksliniai tyrimai grindžiami įvairių savybių derinimu, įskaitant kalbos dalis, žodžių įdėjimus ir semantinius atstovavimus, kad būtų pasiekti aukšti užduočių rezultatai. Mūsų supaprastintas modelis grįžta į sintaksinę teoriją ir pasiekia pažangiausius rezultatus uždaviniui nustatyti neigiamo masto nustatymą, kartu parodant glaudų santykius tarp sintaksinės ir semantikos neigiamo masto nustatymo.', 'kk': 'Біз синтактикалық құрылғының анализациясы арқылы негативдің семантикалығын білдіреді. Лингистикалық теориясы негативдің семантикалығын тек синтактикалық түсініп, бірақ соңғы зерттеулері тапсырмаларды жоғары істеу үшін бірнеше түрлі мүмкіндіктерді біріктіруге көмектеседі. Біздің қарапайым үлгіміз синтактикалық теориясына қайтарады және негативдің синтаксисі мен семантикалық қатынасын көрсетеді.', 'mk': 'Презентираме полунадгледуван модел кој ја научи семантиката на негативноста чисто преку анализа на синтактичката структура. Лингвистичката теорија покажува дека семантиката на негативноста може да се разбере чисто синтактички, иако неодамнешното истражување се потпира на комбинација на различни карактеристики вклучувајќи дел од говорот, зборови вградени и семантични претставувања за да се постигне висока извршност на задачите. Нашиот поедноставен модел се враќа на синтактичката теорија и постигнува најсовремена изведба на задачата на Детектирање на Негација, при што ја демонстрира тесната врска помеѓу синтаксијата и семантиката на негијата.', 'ms': 'Kami memperkenalkan model setengah-mengawasi yang mempelajari semantik negatif hanya melalui analisis struktur sintaktik. Teori bahasa menyatakan bahawa semantik negatif boleh dipahami secara pura-pura sintaktik, walaupun kajian baru-baru ini bergantung pada menggabungkan berbagai ciri termasuk tag-bahagian-ucapan, penyambungan perkataan, dan perwakilan semantik untuk mencapai prestasi tugas tinggi. Model mudah kami kembali ke teori sintaktik dan mencapai prestasi state-of-the-art pada tugas Pengesanan Skop Negasi semasa menunjukkan hubungan ketat antara sintaks dan semantik negatif.', 'ml': 'നമ്മള്\u200d ഒരു സെമി നിരീക്ഷിക്കപ്പെട്ട മോഡല്\u200d കൊണ്ടുവരുന്നു. അത് നെഗന്റിന്റെ സെമാന്റിക്ക് പഠിക്കുന്നു. സിനി Linguistic theory posits that the semantics of negation can be understood purely syntactically, though recent research relies on combining a variety of features including part-of-speech tags, word embeddings, and semantic representations to achieve high task performance.  നമ്മുടെ എളുപ്പമുള്ള മോഡല്\u200d സിന്റാക്റ്റിക്ക് തിയോറിയിലേക്ക് തിരിച്ചുവരുന്നു. നെഗേഷന്\u200d സ്കോപ്പ് ഡിറ്ററിഷന്\u200dറെ ജോലിയിലേക്ക് രാജ്യത്തി', 'mt': 'Aħna nippreżentaw mudell semisuperviż li jitgħallem is-semantika tan-negazzjoni purament permezz ta’ analiżi tal-istruttura sintattika. It-teorija lingwistika tippreżenta li s-semantika tan-negazzjoni tista’ tinftiehem purament b’mod sintetiku, għalkemm ir-riċerka riċenti tiddependi fuq il-kombinazzjoni ta’ varjetà ta’ karatteristiċi inklużi tikketti ta’ parti mid-diskors, inkorporazzjonijiet ta’ kliem, u rappreżentazzjonijiet semantiċi biex jinkiseb prestazzjoni għolja ta’ kompitu. Il-mudell simplifikat tagħna jirritorna għat-teorija sintattika u jikseb prestazzjoni avvanzata fuq il-kompitu tad-Detezzjoni tal-Ambitu tan-Negazzjoni filwaqt li juri r-relazzjoni stretta bejn is-sintaks u s-semantika tan-negazzjoni.', 'mn': 'Бид шинжлэх ухааны синтактикийн бүтээгдэхүүний шинжлэх ухаанаар хагас хяналттай загварыг сурдаг. Шинжлэх ухааны онол нь зөвхөн синтактик байдлаар ойлгох боломжтой гэж үздэг. Гэхдээ саяхан судалгааны ажлын үйлдвэрлэлд өндөр ажлын үйлдвэрлэлд олон төрлийн сонирхолтуудыг нэгтгэх боломжтой. Бидний хялбар загвар нь синтактик онол руу буцаж, урлагийн үйл ажиллагааг харуулж, сөрөг байдлын синтаксик болон семантик хоорондын хатуу холбоотой байдлыг харуулж байна.', 'pl': 'Przedstawiamy model pół-nadzorowany, który uczy się semantyki negacji wyłącznie poprzez analizę struktury składni. Teoria językowa zakłada, że semantykę negacji można zrozumieć czysto składnie, choć ostatnie badania opierają się na łączeniu różnych cech, w tym znaczników części mowy, osadzenia słów i reprezentacji semantycznych, aby osiągnąć wysoką wydajność zadań. Nasz uproszczony model powraca do teorii składni i osiąga najnowocześniejszą wydajność w zakresie wykrywania zakresu negacji, demonstrując jednocześnie ścisły związek między składnią a semantyką negacji.', 'ro': 'Prezentăm un model semi-supravegheat care învață semantica negației pur prin analiza structurii sintactice. Teoria lingvistică presupune că semantica negației poate fi înțeleasă pur sintactic, deși cercetările recente se bazează pe combinarea unei varietăți de caracteristici, inclusiv etichete de parte a vorbirii, încorporări de cuvinte și reprezentări semantice pentru a obține performanțe ridicate ale sarcinilor. Modelul nostru simplificat revine la teoria sintactică și obține performanțe de ultimă generație în ceea ce privește sarcina de detectare a scopului negației, demonstrând în același timp relația strânsă dintre sintaxă și semantica negației.', 'no': 'Vi presenterer eit semioversikt modell som lærer semantikken av negasjon purt gjennom analysen av syntaktiske struktur. Lingvistiske teorie posisjonar at semantikkane av negasjon kan forstårast ganske syntaksisk, men nyleg forskning er avhengig av å kombinere fleire funksjonar, inkludert ein del av talemerker, ordinnbygging og semantiske representasjonar for å oppnå høg oppgåve. Vårt forenkla modell returnerer til syntaksiske teorie og oppnår oppgåva av negasjonsområde i tilstand til kunsten, mens det viser styrke forhold mellom syntaksen og semantikk av negasjon.', 'sr': 'Predstavljamo polu-nadzorni model koji nauči semantiku negacije čisto kroz analizu sintaktičke strukture. Lingistička teorija ukazuje na to da se semantike negacije mogu razumjeti čisto sintaktično, iako nedavno istraživanje oslanja na kombinaciju različitih karakteristika uključujući dijelogovorne etikete, uloženje riječi i semantičke predstave kako bi postigli visoke funkcije zadataka. Naš jednostavan model se vraća u sintaktičku teoriju i postiže stanje umjetnosti na zadatku otkrivanja negativnih oblasti dok pokazuje čvrstu vezu između sintaksa i semantike negacije.', 'si': 'අපි ප්\u200dරදේශයක් ප්\u200dරදේශ කරනවා සම්බන්ධ විශ්ලේෂණයක් නිර්මාණය කරනවා. ලින්ග්විස්ටික් සීමාන්තික ප්\u200dරශ්නයක් තේරුම් ගන්න පුළුවන් කියලා, නමුත් අලුත් සීමාන්තික ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සම්බන්ධ වෙනුවෙන් විවිධ අපේ සරල ප්\u200dරමාණය සංකේතික සිද්ධියෙන් ආරම්භ වෙනවා ඒ වගේම නැගැනීම් ස්කෝප් හොයාගන්න වැඩේ ස්ථිතිය සහ නැගැනීම් සම්බන්ධයෙන් ප', 'so': 'Tusaale la ilaaliyey semi-ka ah oo baranaya qayb-aragnimo oo kaliya baaritaanka dhismaha syntactika. Taariikhda luqada waxaa loola jeedaa in la garan karo qaybaha negativka oo kaliya, inkastoo waxbarashada la soo dhowaaday waxay ku xiran tahay ku ururista faahfaahin kala duduwan, kuwaas oo ah qeyb ka mid ah warqadaha hadalka, hadalka ku soo bandhigga iyo qayb ka mid ah, si loo sameeyo sameynta shaqada sare. Tusaalkayaga sahlan ayaa dib u noqon kara fikrada la-syntactic, wuxuuna gaadhi karaa sameynta arimaha farshaxanka ee la xiriira baaritaanka qasabka qasabka, marka uu muujiyo xiriirka aad u adag ee u dhexeeya qasabka iyo qeybta baahida.', 'sv': 'Vi presenterar en halvövervakad modell som lär sig negationens semantik enbart genom analys av syntaktisk struktur. Lingvistisk teori hävdar att negationens semantik kan förstås rent syntaktiskt, även om den senaste forskningen bygger på att kombinera en mängd olika funktioner, inklusive delar av tal taggar, ord inbäddningar och semantiska representationer för att uppnå hög uppgifts prestanda. Vår förenklade modell återgår till syntaktisk teori och uppnår state-of-the-art prestanda på uppgiften Negation Scope Detection samtidigt som den demonstrerar det snäva förhållandet mellan syntax och semantik av negation.', 'ta': 'நாம் ஒரு பாதி கண்காணிக்கப்பட்ட மாதிரியை கொண்டு வருகிறோம். அது எதிர்மறையின் பாதிப்பு கற்று கொள்கிறது. ஒத்திசைப் நீங்கள் புரிந்து கொள்ள வேண்டும் என்று கூறுகிறது, நீங்கள் புரிந்து கொள்ள வேண்டும் என்றாலும், சமீபத்தில் ஆராய்ச்சி பேச்சு குறிப்புகளை கூட்டும் பல பண்புகளை சே Our simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the syntax and semantics of negation.', 'ur': 'ہم ایک نصف نظارت والی موڈل کو پیش کرتے ہیں جو منفی سیمانٹیک ساختار کی تحلیل کے ذریعہ صرف سیکھتا ہے۔ لینگویسٹی تئوری کو معلوم کرتا ہے کہ منفی سیمانٹیکس کو صرف سینٹاکٹی طور پر سمجھ سکتی ہے، اگرچہ اچھی تحقیقات نے بہت سی فکرتوں کو جمع کرنے کے لئے ایک قسم کی بات ٹاگ، کلمات ابڈینگ اور سیمانٹی معلومات کی وجہ سے ہے۔ ہمارے سادھے موڈل سینٹکتیک نظریہ کی طرف پلٹ جاتا ہے اور نائگانی سینٹکس اور سیمنٹیکس کے درمیان مضبوط رابطہ دکھاتا ہے۔', 'uz': "Biz bir semiz taʼminlovchi modelni o'rganamiz, bu narsalarning semantikasini faqat syntactik tuzuvlarini aniqlash orqali o'rganadi. Lingvistika tezasi esa, negatika semantikasi faqat syntikk qila oladi. Yaqinda taʼminlovchilar bir xil xossalarni birlashtirishga ishlatadi. Bu so'zlarning bir qismlarini, soʻzni ajratish, va yuqori vazifani bajarish uchun semantik tashkilotlarini birlashtirishga ishlatadi. Bizning soddalik modelimizni birlashtirilgan teoriga qaytadi va xabarlarning holatini aniqlash vazifasini amalga oshirish va Negash Skope Detection vazifasini bajaradi va negatika va semantika orasidagi katta aloqalarni ko'rsatadi.", 'vi': 'Chúng tôi đưa ra một mô hình bán giám sát mà học ngữ pháp của sự cấm đoán thuần túy qua phân tích cấu trúc cú pháp. Giả thuyết ngôn ngữ khẳng định rằng ngữ pháp của sự cấm đoán có thể hiểu được hoàn to àn theo kiểu y tế, mặc dù nghiên cứu gần đây dựa trên sự kết hợp các yếu tố, gồm các thẻ bài phát biểu, sự ghép lời, và các biểu hiện theo ngữ nghĩa để đạt được hiệu suất cao. Cách mô hình đơn giản của chúng ta quay trở lại với lý thuyết pháp thuật và đạt được trình độ hiện đại trong nhiệm vụ trinh sát Phạm vi thao tác thao tác không khai thác, đồng thời cho thấy mối quan hệ chặt chẽ giữa syntax và ngữ pháp của sự cấm đoán.', 'da': 'Vi præsenterer en semi-overvåget model, der lærer semantikken af negation udelukkende gennem analyse af syntaktisk struktur. Linguistisk teori påstår, at semantikken af negation kan forstås rent syntaktisk, selvom nyere forskning er afhængig af at kombinere en række funktioner, herunder del-of-speech tags, ord indlejringer og semantiske repræsentationer for at opnå høj opgave ydeevne. Vores forenklede model vender tilbage til syntaktisk teori og opnår state-of-the-art præstation på opgaven Negation Scope Detection samtidig med at demonstrere det tætte forhold mellem syntaks og semantik af negation.', 'bg': 'Представяме полунадзорен модел, който изучава семантиката на отрицанието чисто чрез анализ на синтактичната структура. Лингвистичната теория предполага, че семантиката на отрицанието може да бъде разбрана чисто синтактично, въпреки че последните изследвания разчитат на комбиниране на различни характеристики, включително част от речта тагове, вграждане на думи и семантични изображения, за да се постигне висока производителност на задачите. Нашият опростен модел се връща към синтактичната теория и постига най-съвременни резултати по задачата за откриване на обхвата на отрицанието, като същевременно демонстрира тясната връзка между синтаксиса и семантиката на отрицанието.', 'nl': 'We presenteren een semi-supervised model dat de semantiek van negatie leert louter door analyse van syntactische structuur. Taaltheorie stelt dat de semantiek van negatie puur syntactisch kan worden begrepen, hoewel recent onderzoek steunt op het combineren van een verscheidenheid van functies, waaronder part-of-speech tags, woord embeddings en semantische representaties om hoge taakverprestaties te bereiken. Ons vereenvoudigde model keert terug naar syntactische theorie en bereikt state-of-the-art prestaties op de taak van Negation Scope Detection terwijl de nauwe relatie tussen de syntaxis en semantiek van negatie wordt aangetoond.', 'hr': 'Predstavljamo pola nadzornog model a koji nauči semantiku negacije čisto kroz analizu sintaktičke strukture. Lingistička teorija ukazuje na to da se semantike negacije mogu razumjeti čisto sintaktično, iako nedavno istraživanje oslanja na kombinaciju različitih karakteristika uključujući dijelogovorne etikete, ugrađenje riječi i semantičke predstave kako bi postigli visoke funkcije zadataka. Naš pojednostavljeni model se vraća sintaktičkoj teoriji i postiže postupak umjetnosti na zadatku otkrivanja Negacijskih oblasti dok pokazuje čvrst odnos između sintaksije i semantike negacije.', 'de': 'Wir präsentieren ein halbüberwachtes Modell, das die Semantik der Negation allein durch Analyse syntaktischer Strukturen erlernt. Die linguistische Theorie geht davon aus, dass die Semantik der Negation rein syntaktisch verstanden werden kann, obwohl neuere Forschung darauf beruht, eine Vielzahl von Funktionen zu kombinieren, einschließlich Teil-of-Speech-Tags, Wort-Einbettungen und semantische Repräsentationen, um eine hohe Aufgabenleistung zu erreichen. Unser vereinfachtes Modell kehrt zur syntaktischen Theorie zurück und erreicht State-of-the-Art Leistung bei der Aufgabe der Negation Scope Detection und demonstriert gleichzeitig die enge Beziehung zwischen Syntax und Semantik der Negation.', 'fa': 'ما یک مدل نیمه تحت نظر قرار می دهیم که سیمانتیک منفی را از طریق تحلیل ساختار سنتاکتیک یاد می دهد. تئوری لینگیست می\u200cگوید که سیمانتیک\u200cهای منفی به طور کامل متوجه می\u200cشوند، اگرچه تحقیقات اخیرا بر ترکیب یک گونه ویژه\u200cهای مختلف از ویژه\u200cها، شامل برچسب\u200cهای سخنرانی، جمع\u200cآوری\u200cهای کلمه و نمایش\u200cهای سیمانتیک برای رسیدن عملکرد عملکرد بالا بستگی دارد مدل ساده\u200cمون به نظریه\u200cی سنتاکتیک برمی\u200cگردد و به عملکرد موقعیت هنری در کار بازرسی محدودیت در زمان نشان دادن رابطه\u200cی محکم بین سنتاکس و سنتانسیک\u200cهای منفی برمی\u200cگردد.', 'id': 'We present a semi-supervised model which learns the semantics of negation purely through analysis of syntactic structure.  Teori lingwistik berposisi bahwa semantik negati dapat dipahami secara pura-pura sintaks, meskipun penelitian baru-baru ini bergantung pada kombinasi berbagai ciri-ciri termasuk tags-bagian-dari-pidato, embedding kata, dan representation semantik untuk mencapai prestasi tugas tinggi. Model sederhana kami kembali ke teori sintaks dan mencapai prestasi state-of-the-art pada tugas Deteksi Skop Negasi sementara menunjukkan hubungan ketat antara sintaks dan semantik negati.', 'af': "Ons stel 'n semi-ondersoekte model wat leer die semantieke van negasie net deur analiseer van sintaktieke struktuur. Linguistiese teorie positeer dat die semantieke van negasie net sintaktiek verstaan kan word, alhoewel onlangse ondersoek verlig op die kombinasie van 'n verskillende funksies insluitend deel van spraak etikette, woord inbetering en semantiese voorstellings om hoë taak-prestasie te bereik. Ons eenvoudige model gee terug na sintaksie teorie en bereik staat-van-die-kuns-prestasie op die taak van Negatiese omvang Opdekking terwyl die sterk verhouding tussen die sintaks en semantieke van negasie vertoon word.", 'ko': '우리는 반감독 모델을 제시했는데 이 모델은 순전히 문법 구조를 분석함으로써 부정적인 의미를 배운다.언어학 이론에 의하면 부정적인 의미는 완전히 문법적으로 이해할 수 있다고 주장한다. 비록 최근의 연구는 각종 특징을 결합시키는 데 의존하지만 어성 표기, 단어 삽입과 의미 표징을 포함하여 높은 임무 성능을 실현하는 데 의존한다.우리의 간소화 모델 회귀 문법 이론은 부정 범위 검측 임무에서 가장 선진적인 성능을 실현했고 부정의 문법과 의미 간의 긴밀한 관계를 보여 주었다.', 'tr': 'Semantikleri sintaktik yapıların analizi ile yarı kontrol edilen bir modeli gösteriyoruz. Lingüistik teoriýa negatif semantikleri syntaktik bilen düşünebilir diýip bilýär. Ýakyndaky araştırmalar, söz etiketleri, söz etiketleri we semantik täzeliklerini yüksek görev eserini ýetirmek üçin birnäçe çeşitli özellikleri birleştirmek üçin üýtgedir. Basitleştirilen modelimiz sintaktik teoriýa dönüp, Negatik Manzara Tahminiň görevi üzerinde sanat eserini ýetir ve negatif semantikleri arasındaki güçlü ilişkileri gösterir.', 'sw': 'Tunaweza kutengeneza modeli inayofuatiliwa na nusu inayojifunza mifano ya hasira pekee kwa uchambuzi wa muundo wa pamoja. nadharia ya lugha inamaanisha kuwa mifano ya hasi yanaweza kuelewa kwa ushirikiano tu, ingawa utafiti wa hivi karibuni unategemea kuunganisha vipengele mbalimbali ikiwa ni pamoja na sehemu ya viungo vya hotuba, maneno yanayoonyesha, na uwakilishi wa sekunde kwa ajili ya kutekeleza kazi za juu. Mradi wetu mwepesi unarudi tena kwenye nadharia ya ushirikiano na kupata utendaji wa hali ya sanaa katika jukumu la Kuchunguza Mawasiliano wakati wakionyesha uhusiano mzito kati ya kodi na mifumo ya mabaya.', 'am': 'በሲንተቲካዊ አካባቢ ማስተምር የተለየውን የንቀፍ ምሳሌ እናስተምረዋለን፡፡ Linguistic ታሪክ የንቀፍ ስምናቄ በተለየ ተሟጋቾች ብቻ እንዲያስተውሉ ነው፣ ምንም እንኳን የቀድሞው ምርመራ የንግግር መክፈቻ፣ የንግግር መክፈቻ፣ የንግግር ግንኙነት እና የስራ ትክክል ማድረግ እንዲደርስ የሚታመን የልዩ ምርጫዎችን በመጠቀም ነው፡፡ ቀላል ሞዴላታችን ወደ Syntactic ታሪክ ይመለሳል እና የ-የ-የ-የ-art አካሄዱን በሥርዓት ላይ አግኝቷል፡፡', 'sq': 'Ne paraqesim një model gjysmë-mbikqyrur i cili mëson semantikën e negativës vetëm nëpërmjet analizës së strukturës sintaktike. Teoria gjuhësore thekson se semantika e negativit mund të kuptohet thjesht sintaktikisht, megjithëse kërkimet e fundit mbështeten në kombinimin e një shumëllojshmërie të karakteristikave duke përfshirë etiketat pjesë-të-fjalës, përfshirjet e fjalëve dhe përfaqësimet semantike për të arritur performancën e lartë të detyrës. Modeli ynë i thjeshtë kthehet në teorinë sintaktike dhe arrin shfaqjen më të lartë në detyrën e Detektimit të Shkupit të Negacionit ndërsa demonstron marrëdhëniet e ngushta midis sintaksit dhe semantikës së negacionit.', 'hy': 'We present a semi-supervised model which learns the semantics of negation purely through analysis of syntactic structure.  Լեզվաբանական տեսությունը ցույց է տալիս, որ բացասական սեմանտիկան կարելի է հասկանալ միայն սինտակտիկ կերպով, չնայած որ վերջին հետազոտությունները հիմնված են բազմաթիվ հատկությունների համադրման վրա, ներառյալ խոսքի մասերի, բառերի ներառման և սեմանտիկ ներկայացումների վրա բարձր գործողությունների հաս Մեր պարզաբանված մոդելը վերադառնում է սինտակտիկ տեսության և հասնում է ամենաբարձր արդյունքներին՝ բացասական մասի հայտնաբերման խնդրի վրա, ցույց տալով միաժամանակ բացասական սինտաքսի և սեմանտիկայի հարաբերությունները:', 'bn': 'আমরা একটি সেমি পর্যবেক্ষক মডেল উপস্থাপন করি যা নেতিবেশনের সেম্যান্টিক্স শিক্ষা দিয়েছে শুধুমাত্র সিন্ট্যাকটিক কা লিঙ্গিস্টিক তত্ত্বাবধান করেছে যে নেতিবাচকের সেমেন্টিক্স শুধুমাত্র সিন্টিক্যালিকভাবে বুঝতে পারে, যদিও সাম্প্রতিক গবেষণা নির্ভর করে বিভিন্ন বৈশিষ্ট্ আমাদের সহজ মডেল সিন্ট্যাক্টিক তত্ত্বের কাছে ফিরে যায় এবং নেগেশন স্কোপ ডিটেক্টরের কাজে রাষ্ট্রীয়-শিল্পের কাজ অর্জন করে, যখন তারা নেতেজেক্স এবং সে', 'bs': 'Predstavljamo pola nadzornog model a koji nauči semantiku negacije čisto kroz analizu sintaktičke strukture. Lingistička teorija ukazuje na to da se semantike negacije mogu razumjeti čisto sintaktično, iako nedavno istraživanje oslanja na kombinaciju različitih karakteristika uključujući dijelogovorne etikete, ugrađenje riječi i semantičke predstave za postizanje visoke funkcije zadataka. Naš jednostavan model se vraća u sintaktičku teoriju i postiže izvedbu stanja umjetnosti na zadatku otkrivanja negativnih oblasti dok pokazuje čvrstu vezu između sintaksa i semantike negacije.', 'az': 'Biz yarı-gözləyirik modeli göstəririk ki, sintaktik quruluşun analizi ilə negativ semantiklərini öyrənir. Lingüistik teoriyanın sonrakı simantik sintaktik olaraq anlanabilir, lakin son araştırmalar yüksək iş performansını yerinə yetirmək üçün çoxlu fərqli tərzlərin birləşdirilməsinə təvəkkül edir. Bizim basit modelimiz sintaktik teoriyə qayıda bilər və negasyonun sintaksi və semantik arasındakı sərt ilişkisini göstərərək Negation Scope Detection işini başa çatdırır.', 'ca': 'We present a semi-supervised model which learns the semantics of negation purely through analysis of syntactic structure.  La teoria lingüística afirma que la semàntica de la negatió pot ser entendida purament sinàcticament, tot i que la recent recerca es basa en combinar una varietat de característiques, incloent etiquetes de part de la xerrada, incorporacions de paraules i representacions semàntiques per aconseguir un desempeny elevat. Our simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the syntax and semantics of negation.', 'cs': 'Představujeme semi-supervisovaný model, který se učí sémantiku negace čistě analýzou syntaktické struktury. Jazyková teorie předpokládá, že sémantika negace lze chápat čistě syntakticky, ačkoli nedávný výzkum spoléhá na kombinaci různých funkcí, včetně značek části řeči, vložení slov a sémantických reprezentací, aby bylo dosaženo vysokého výkonu úkolů. Náš zjednodušený model se vrací k syntaktické teorii a dosahuje nejmodernějšího výkonu v oblasti detekce rozsahu negace a demonstruje úzký vztah mezi syntaxí a sémantikou negace.', 'et': 'Esitame pooljuhitava mudeli, mis õpib negatsiooni semantikat puhtalt süntaktilise struktuuri analüüsi kaudu. Keelteooria on seisukohal, et negatsiooni semantikat saab mõista puhtalt süntaktiliselt, kuigi hiljutised uuringud tuginevad mitmesuguste omaduste kombineerimisele, sealhulgas kõneosade sildid, sõnade manustamine ja semantilised representatsioonid, et saavutada kõrge tulemuslikkus. Meie lihtsustatud mudel naaseb süntaktilise teooria juurde ja saavutab nüüdisaegse jõudluse negatsiooni ulatuse tuvastamise ülesandel, näidates samas tihedat seost negatsiooni süntaksi ja semantika vahel.', 'fi': 'Esitämme puolivalvotun mallin, joka oppii kieltämisen semantiikan puhtaasti syntaktisen rakenteen analysoimalla. Kieliteorian mukaan kieltämisen semantiikkaa voidaan ymmärtää puhtaasti syntaktisesti, vaikka viimeaikaiset tutkimukset perustuvat erilaisten ominaisuuksien yhdistämiseen, kuten puheen osa-tunnisteiden, sanaupotusten ja semanttisten representaatioiden saavuttamiseksi korkean suorituskyvyn saavuttamiseksi. Yksinkertaistettu mallimme palaa syntaktiseen teoriaan ja saavuttaa viimeisintä suorituskykyä Negation Scope Detection -tehtävässä osoittaen samalla, että negatiivisen syntaksin ja semantiikan välinen suhde on tiukka.', 'jv': 'Awakdhéwé éntuk sistem semi-super-model sing nyelaran semanti kuwi nggawe barang langgar ngegambar perkaran winih dadi winih dhéwé ngerasakno sitik dadi. Linguistik theore supoyo kuwi sematik dhéwé wis ngerasakno akeh luwih-luwih hayo, nik awak dhéwé seneng pisan bakal nguasai perusahaan akeh sampeyan karo paké: Nèng model sing semplisé nyimpen bakal seneng sistem sing bisa diutag-seneng pisan karo hal-kalungot nggawe barang seneng Ngucap Universi yang dipunangé perusahaan seneng sawasar kelangan seneng winih lan semanti kuwi wis ngucap.', 'sk': 'Predstavljen je pol-nadzorovan model, ki se s pomočjo analize sintaktične strukture uči semantiko negacije. Jezikovna teorija predpostavlja, da je semantiko negacije mogoče razumeti zgolj sintaktično, čeprav se nedavne raziskave zanašajo na združevanje različnih značilnosti, vključno z oznakami dela govora, vgradnjo besed in semantičnimi reprezentacijami, da bi dosegli visoko uspešnost nalog. Naš poenostavljeni model se vrača k sintaktični teoriji in dosega najsodobnejšo uspešnost pri nalogi zaznavanja obsega negacije, hkrati pa dokazuje tesno povezavo med sintakso in semantiko negacije.', 'ha': "Tuna halatar da wani misalin wanda aka tsare shi na ƙari, wanda yana sanar da ma'anar bakwai na bakin haske kawai, a kan anayyar da bakin da ake yi na haɗi. Tayinin linguistic na gaskata cewa ana iya fahimta semantikken nega ne kawai da syntactic, kuma kõ da yaushe, watafiti na ƙara yana dõgara a haɗa wasu fasihi masu haske, kamar rabon tagogi na faɗi, da masu gauraya da semantic dõmin ya isa aikin aikin sarki. Modelinmu da ke sauƙi, yana kõma zuwa zagon na syntactic kuma yana sãmu mai aikin-halin-sanar a kan aikin da za'a Shirin Zabur Najigon Kugaro na Negus alhãli kuwa yana nuna muhimmi mai ƙunci tsakanin synkassi da semantiki na haske.", 'he': 'אנחנו מציגים מודל חצי-מפקח שלמד את הסמנטיקה של השליטה רק באמצעות ניתוח של מבנה סינטקטי. תיאוריה לינגולית מתייחסת שהסמנטיקה של השליטה יכולה להבין באופן טהור סינטקטי, למרות המחקר האחרון סומך על שילוב מגוון של תכונות כולל תוויות חלק מהנאום, תוויות מילים, ויציגות סמנטיות כדי להשיג ביצוע משימה גבוה. המודל הפשוט שלנו חוזר לתיאוריה סינטאקטית ומשיג ביצועים חדשים במשימה של גילוי גוף השלילות בזמן שהוכיח את מערכת היחסים הדוקה בין הסינטקס לסמנטיקה של השלילה.', 'bo': 'ང་ཚོས་བྱ་རིམ་ལྟ་རྣམ་པ་ཞིག་འཇུག་བྱེད་ཀྱི་མིག་རྩལ་གྱི་semantics་དེ་གིས་དབྱེ་སྟངས་དབྱེ་ཞིབ Linguistic theory posits that the semantics of negation can be understood purely syntactically, though recent research relies on combining a variety of features including part-of-speech tags, word embeddings, and semantic representations to achieve high task performance. ང་ཚོའི་simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the syntax and semantics of negation.'}
