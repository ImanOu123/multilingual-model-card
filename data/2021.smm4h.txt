{'en': 'View Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data', 'ar': 'عرض التقطير ببيانات غير مصنفة لاستخراج التأثيرات الضارة للأدوية من البيانات التي ينشئها المستخدم', 'fr': "Afficher la distillation avec des données non étiquetées pour extraire les effets indésirables d'un médicament à partir de données générées", 'es': 'Vea la destilación con datos sin etiqueta para extraer los efectos adversos de los medicamentos de los datos generados por el usuario', 'pt': 'Visualizar destilação com dados não rotulados para extrair efeitos adversos de medicamentos de dados gerados pelo usuário', 'ja': 'ユーザーが生成したデータから有害な薬物効果を抽出するための未標識データによる蒸留を表示', 'ru': 'Просмотр результатов дистилляции с использованием немаркированных данных для извлечения нежелательных лекарственных эффектов из пользовательских данных', 'zh': '视未标数之蒸馏,以取药于用户生之数不良反应', 'hi': 'उपयोगकर्ता-जनित डेटा से प्रतिकूल दवा प्रभाव निकालने के लिए अनलेबल डेटा के साथ आसवन देखें', 'ga': 'Féach ar Dhriogadh le Sonraí Neamhlipéadaithe chun Éifeachtaí Díobhálacha Drugaí a Bhaint as Sonraí a Ghintear ag Úsáideoirí', 'el': 'Προβολή απόσταξης με μη επισημασμένα δεδομένα για την εξαγωγή δυσμενών επιδράσεων φαρμάκων από δεδομένα που παράγονται από τον χρήστη', 'hu': 'Címke nélküli adatokkal történő desztilláció megtekintése a káros gyógyszerhatások felhasználói által generált adatokból történő kivonásához', 'it': "Visualizza la distillazione con dati non etichettati per estrarre effetti avversi della droga dai dati generati dall'utente", 'lt': 'Rodyti distiliaciją su nenurodytais duomenimis, kad būtų galima ištraukti nepageidaujamus vaisto poveikius iš vartotojo sukauptų duomenų', 'mk': 'Преглед дистилација со неозначени податоци за екстракција на негативни ефекти на лековите од податоци генерирани од корисникот', 'ms': 'Lihat Distillasi dengan Data Tidak Ditanda untuk Ekstrak Kesan Narkoba Dari Data Yang Dijana oleh Pengguna', 'kk': 'Пайдаланушылар жасалған деректерден қарсы наркотикалық эффекттерді тарқату үшін келтірілмеген деректерді көрсету', 'ka': 'Name', 'mn': 'View Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data', 'mt': 'Ara Distillazzjoni b’Dejta Mhux Tikkettata għall-Estrazzjoni tal-Effetti Avversi tal-Mediċina minn Dejta Ġenerata mill-Utent', 'ro': 'Vizualizați distilarea cu date nelimitate pentru extragerea efectelor adverse ale medicamentelor din datele generate de utilizatori', 'pl': 'Zobacz destylację z nieoznakowanymi danymi do wydobycia niepożądanych skutków leków z danych generowanych przez użytkownika', 'ml': 'ഉപയോക്താവ് സൃഷ്ടിച്ച വിവരങ്ങളില്\u200d നിന്നും പുറത്തെടുക്കുന്നതിനുള്ള ഉപയോക്താവിന്റെ പ്രഭാവങ്ങള്\u200d പുറത്തെടുക്', 'so': 'Fiiri Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data', 'sv': 'Visa Destillation med obemärkta data för extraktion av negativa läkemedelseffekter från användargenererade data', 'sr': 'Погледај дистилацију с необелезеним данима за извађење непрепоредних эффекта наркотика из извађених данима', 'si': 'Name', 'ta': 'பயனர் உருவாக்கப்பட்ட தரவுகளிலிருந்து வெளியேற்ற முனைய விளைவுகளுக்கான திரைவுகளை பார்க்கவும்', 'ur': 'Name', 'no': 'Name', 'uz': 'Name', 'vi': 'Chế độ phân tách với dữ liệu chưa được dán để chiết xuất phản ứng gây tác động trái phép từ dữ liệu người dùng', 'nl': 'Bekijk destillatie met ongelabelde gegevens voor het extraheren van nadelige geneesmiddeleffecten uit door gebruikers gegenereerde gegevens', 'de': 'Anzeigen der Destillation mit nicht gekennzeichneten Daten zur Extraktion unerwünschter Arzneimittelwirkungen aus nutzergenerierten Daten', 'bg': 'Дестилация с незабелязани данни за извличане на нежелани лекарствени ефекти от генерирани от потребителите данни', 'da': 'Vis destillation med usædvanlige data til udvinding af bivirkninger fra brugergenererede data', 'id': 'Tampilkan Distillasi dengan Data Tidak Berlebar untuk Ekstraksi Efek Narkoba Dari Data Yang Digenerasikan oleh Pengguna', 'hr': 'Pogledajte Distilaciju s neizbiljnim podacima za izvlačenje nuspojavnih učinka droge iz podataka generiranih korisnika', 'ko': '사용자가 생성한 데이터에서 약물 불량 반응을 추출할 수 있도록 표시되지 않은 데이터를 포함하는 증류를 확인하다', 'fa': 'نمایش حفاظت با داده\u200cهای غیرقابل نوشته برای اثرات مواد مخالف از داده\u200cهای تولید کاربر', 'sw': 'Tatizo la Kutokana na Takwimu zisizo na Utoaji kwa ajili ya Kutoa Tatizo za Madawa kutoka kwa Mtumiaji-Generated Data', 'af': 'Name', 'sq': 'Shfaq Distillimin me të dhëna pa etiketë për nxjerrjen e efekteve të dëmshme të drogës nga të dhënat e gjeneruara nga përdoruesi', 'hy': 'Տեսագրել դիստիլացիան օգտագործելով անսահմանափակ տվյալներ օգտագործողի կողմից ստեղծված տվյալներից հանելու համար', 'tr': 'Ullançy Maglumatdan Üýtgedik Maglumaty Açmak üçin ýazylmaz Maglumaty bilen Görkez', 'am': 'image-action', 'bn': 'Name', 'az': 'İstifadəçi Məlumatlarından Dönüş Uyuq Efektlərini Çıqarmaq üçün Qeyd edilməmiş Məlumatları ilə Görün', 'bs': 'Pogledajte Distilaciju sa neoznačenim podacima za izvlačenje nuspojavnih učinka droge iz podataka Generiranih korisnika', 'ca': "Veu la destilació amb dades no etiquetades per extrair efectes adversos de medicaments de dades generades per l'usuari", 'cs': 'Zobrazit destilaci s neoznačenými daty pro extrakci nežádoucích účinků léčiv z dat generovaných uživateli', 'et': 'Destilleerimine märgistamata andmetega kõrvaltoimete ekstraheerimiseks kasutaja loodud andmetest', 'fi': 'Näytä tislaus merkitsemättömillä tiedoilla lääkkeiden haittavaikutusten erottamiseksi käyttäjien luomista tiedoista', 'jv': 'Name', 'ha': '@ action', 'sk': 'Oglejte si destilacijo z neoznačenimi podatki za ekstrakcijo neželenih učinkov zdravila iz podatkov, ki jih ustvarijo uporabniki', 'bo': 'Extracting Adverse Drug Effects from User-Generated Data', 'he': 'תצוג דיסטילציה עם נתונים ללא סימנים להוציא תופעות תרופות הלא רצויות ממידע שנוצר ע"י המשתמש'}
{'en': 'We present an  algorithm  based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a  classifier  is trained on each view to label a set of unlabeled documents to be used as an initializer for a new  classifier  in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our  model  in the largest publicly available ADR dataset. The experiments testify that our  model  significantly outperforms the transformer-based models pretrained on domain-specific data.', 'ar': 'نقدم خوارزمية تعتمد على محولات متعددة الطبقات لتحديد التفاعلات الدوائية الضارة (ADR) في بيانات الوسائط الاجتماعية. يعتمد نموذجنا على خصائص المشكلة وخصائص تضمين الكلمات السياقية لاستخراج وجهتي نظر من الوثائق. ثم يتم تدريب المصنف على كل عرض لتسمية مجموعة من المستندات غير المسماة لاستخدامها كأداة تهيئة لمصنف جديد في طريقة العرض الأخرى. أخيرًا ، يتم تدريب المصنف المبدئي في كل عرض بشكل أكبر باستخدام أمثلة التدريب الأولية. قمنا بتقييم نموذجنا في أكبر مجموعة بيانات ADR متاحة للجمهور. تشهد التجارب أن نموذجنا يتفوق بشكل كبير على النماذج القائمة على المحولات التي تم اختبارها مسبقًا على البيانات الخاصة بالمجال.', 'pt': 'Apresentamos um algoritmo baseado em transformadores multicamadas para identificar reações adversas a medicamentos (RAM) em dados de mídia social. Nosso modelo se baseia nas propriedades do problema e nas características de embeddings de palavras contextuais para extrair duas visualizações de documentos. Em seguida, um classificador é treinado em cada visão para rotular um conjunto de documentos não rotulados a serem usados como inicializador para um novo classificador na outra visão. Finalmente, o classificador inicializado em cada visão é treinado usando os exemplos de treinamento inicial. Avaliamos nosso modelo no maior conjunto de dados de ADR disponível publicamente. Os experimentos comprovam que nosso modelo supera significativamente os modelos baseados em transformador pré-treinados em dados específicos de domínio.', 'es': 'Presentamos un algoritmo basado en transformadores multicapa para identificar reacciones adversas a medicamentos (ADR) en los datos de las redes sociales. Nuestro modelo se basa en las propiedades del problema y las características de la incrustación de palabras contextuales para extraer dos puntos de vista de los documentos. A continuación, se entrena a un clasificador en cada vista para etiquetar un conjunto de documentos sin etiqueta que se utilizarán como inicializador de un nuevo clasificador en la otra vista. Por último, el clasificador inicializado de cada vista se entrena aún más utilizando los ejemplos de entrenamiento iniciales. Evaluamos nuestro modelo en el mayor conjunto de datos de ADR disponible públicamente. Los experimentos demuestran que nuestro modelo supera significativamente a los modelos basados en transformadores previamente entrenados en datos específicos del dominio.', 'fr': "Nous présentons un algorithme basé sur des transformateurs multicouches pour identifier les effets indésirables des médicaments (ADR) dans les données des réseaux sociaux. Notre modèle s'appuie sur les propriétés du problème et sur les caractéristiques des intégrations contextuelles de mots pour extraire deux vues de documents. Ensuite, un classificateur est formé sur chaque vue pour étiqueter un ensemble de documents non étiquetés à utiliser comme initialiseur pour un nouveau classificateur dans l'autre vue. Enfin, le classificateur initialisé dans chaque vue est entraîné davantage à l'aide des exemples de formation initiale. Nous avons évalué notre modèle dans le plus grand ensemble de données ADR accessible au public. Les expériences démontrent que notre modèle surpasse de manière significative les modèles basés sur des transformateurs préentraînés sur des données spécifiques à un domaine.", 'ja': 'ソーシャルメディアデータ内の薬物有害反応（ ADR ）を識別するための多層変圧器に基づくアルゴリズムを提示します。私たちのモデルは、ドキュメントから2つのビューを抽出するために、問題のプロパティとコンテキストワード埋め込みの特性に依存しています。次に、各ビューで分類子が訓練され、他方のビューで新しい分類子の初期化子として使用されるラベル付けされていないドキュメントのセットにラベルを付ける。最後に、各ビューの初期化された分類子は、初期訓練例を使用してさらに訓練される。公開されている最大のADRデータセットでモデルを評価しました。実験では、当社のモデルは、ドメイン固有のデータで事前に訓練された変圧器ベースのモデルを大幅に上回っていることが証明されています。', 'zh': '立变压器算法,以识社交媒体药不良反应(ADR)。 吾道赖之,与上下文词嵌之征,取二视图于文档。 然后教视图一器,以表未记之文档,以为视图中新器之初始值设定项。 最后以初教示例更练视图中初始化分器。 我于大公 ADR 数集吾形。 实验验之,明优于特定域之数,先练于转换器者也。', 'hi': 'हम सोशल मीडिया डेटा में प्रतिकूल दवा प्रतिक्रियाओं (एडीआर) की पहचान करने के लिए बहु-परत ट्रांसफार्मर पर आधारित एक एल्गोरिथ्म प्रस्तुत करते हैं। हमारा मॉडल समस्या के गुणों और दस्तावेजों से दो विचारों को निकालने के लिए प्रासंगिक शब्द एम्बेडिंग की विशेषताओं पर निर्भर करता है। फिर एक क्लासिफायर को प्रत्येक दृश्य पर प्रशिक्षित किया जाता है ताकि अन्य दृश्य में एक नए क्लासिफायर के लिए एक प्रारंभिक के रूप में उपयोग किए जाने वाले अनलेबल किए गए दस्तावेज़ों के एक सेट को लेबल किया जा सके। अंत में, प्रत्येक दृश्य में प्रारंभ किए गए क्लासिफायर को प्रारंभिक प्रशिक्षण उदाहरणों का उपयोग करके प्रशिक्षित किया जाता है। हमने सबसे बड़े सार्वजनिक रूप से उपलब्ध एडीआर डेटासेट में अपने मॉडल का मूल्यांकन किया। प्रयोगों की गवाही है कि हमारा मॉडल डोमेन-विशिष्ट डेटा पर पूर्वनिर्धारित ट्रांसफॉर्मर-आधारित मॉडल को काफी बेहतर बनाता है।', 'ru': 'Мы представляем алгоритм, основанный на многослойных трансформаторах, для идентификации нежелательных лекарственных реакций (НЛР) в данных социальных сетей. Наша модель опирается на свойства проблемы и характеристики контекстных вложений слов для извлечения двух представлений из документов. Затем классификатор обучается на каждом представлении для маркировки набора немаркированных документов, которые будут использоваться в качестве инициализатора для нового классификатора в другом представлении. Наконец, инициализированный классификатор в каждом представлении дополнительно обучается с использованием первоначальных обучающих примеров. Мы оценили нашу модель в самом большом общедоступном наборе данных НЛР. Эксперименты свидетельствуют о том, что наша модель значительно превосходит модели на основе трансформаторов, предварительно подготовленные на основе данных, относящихся к определенной области.', 'ga': 'Cuirimid i láthair algartam bunaithe ar chlaochladáin ilchiseal chun Frithghníomhartha Díobhálacha i nDrugaí (ADR) a shainaithint i sonraí meán sóisialta. Braitheann ár múnla ar airíonna na faidhbe agus ar shaintréithe leabaithe focal comhthéacsúla chun dhá radharc a bhaint as doiciméid. Ansin cuirtear oiliúint ar aicmitheoir ar gach amharc chun sraith doiciméad neamhlipéadaithe a lipéadú le húsáid mar thúsaitheoir d’aicmitheoir nua sa radharc eile. Ar deireadh, cuirtear oiliúint bhreise ar an aicmitheoir tosaigh i ngach radharc ag baint úsáide as na samplaí oiliúna tosaigh. Rinneamar measúnú ar ár múnla sa tacar sonraí ADR is mó atá ar fáil go poiblí. Léiríonn na turgnaimh go sáraíonn ár múnla go suntasach na samhlacha atá bunaithe ar chlaochladán agus a réamhoiliúint ar shonraí a bhaineann go sonrach leis an bhfearann.', 'el': 'Παρουσιάζουμε έναν αλγόριθμο βασισμένο σε πολυστρωματικούς μετασχηματιστές για τον εντοπισμό ανεπιθύμητων αντιδράσεων φαρμάκων (ADR) σε δεδομένα κοινωνικών μέσων. Το μοντέλο μας βασίζεται στις ιδιότητες του προβλήματος και στα χαρακτηριστικά των περιεχομένων ενσωμάτωσης λέξεων για να εξαγάγει δύο απόψεις από έγγραφα. Στη συνέχεια, ένας ταξινομητής εκπαιδεύεται σε κάθε προβολή για να επισημάνει ένα σύνολο εγγράφων χωρίς ετικέτα που θα χρησιμοποιηθούν ως αρχικοποιητής για ένα νέο ταξινομητή στην άλλη προβολή. Τέλος, ο αρχικός ταξινομητής σε κάθε προβολή εκπαιδεύεται περαιτέρω χρησιμοποιώντας τα παραδείγματα αρχικής εκπαίδευσης. Αξιολογήσαμε το μοντέλο μας στο μεγαλύτερο κοινό διαθέσιμο σύνολο δεδομένων ADR. Τα πειράματα μαρτυρούν ότι το μοντέλο μας ξεπερνά σημαντικά τα μοντέλα με βάση τον μετασχηματιστή που έχουν προετοιμαστεί σε συγκεκριμένα δεδομένα τομέα.', 'hu': 'Többrétegű transzformátorokon alapuló algoritmust mutatunk be a közösségi média adataiban a mellékhatások (ADR) azonosítására. Modellünk a probléma tulajdonságaira és a kontextuális szóbeágyazások jellemzőire támaszkodik, hogy két nézetet vonjunk ki a dokumentumokból. Ezután minden nézetben egy osztályozót képeznek arra, hogy címkézéssel nem rendelkező dokumentumokat címkézzenek, amelyeket egy új osztályozó inicializálójaként használnak a másik nézetben. Végül az inicializált osztályozó minden nézetben továbbképzésre kerül az alapképzési példák segítségével. Modellünket a legnagyobb nyilvánosan elérhető ADR adatkészletben értékeltük. A kísérletek tanúsítják, hogy modellünk jelentősen felülmúlja a domain-specifikus adatokra előkészített transzformátor alapú modelleket.', 'it': "Presentiamo un algoritmo basato su trasformatori multistrato per identificare le reazioni avverse alla droga (ADR) nei dati dei social media. Il nostro modello si basa sulle proprietà del problema e sulle caratteristiche delle incorporazioni contestuali di parole per estrarre due visualizzazioni dai documenti. Quindi un classificatore viene addestrato su ogni vista per etichettare un insieme di documenti non etichettati da utilizzare come inizializzatore per un nuovo classificatore nell'altra vista. Infine, il classificatore inizializzato in ogni vista viene ulteriormente addestrato utilizzando gli esempi di formazione iniziale. Abbiamo valutato il nostro modello nel più grande set di dati ADR disponibile pubblicamente. Gli esperimenti dimostrano che il nostro modello supera significativamente i modelli basati su trasformatori pre-addestrati su dati specifici del dominio.", 'lt': 'Pateikiame algoritmą, pagrįstą daugiasluoksniais transformatoriais, kad socialinių žiniasklaidos duomenų metu būtų galima nustatyti nepageidaujamas narkotikų reakcijas. Mūsų modelis grindžiamas problemos savybėmis ir kontekstinių žodžių įterpimo charakteristikomis, kad ištrauktų dvi nuomones iš dokumentų. Tada kiekviename vaizdo vaizde klasifikatorius mokomas pažymėti pažymėtų dokumentų rinkinį, kuris bus naudojamas kaip naujo klasifikatoriaus inicializatorius kitame vaizdo vaizde. Galiausiai kiekvienoje nuomonėje inicijuotas klasifikatorius toliau mokomas naudojant pradinio mokymo pavyzdžius. Vertinome savo model į didžiausiu viešai prieinamu GAS duomenų rinkiniu. Eksperimentai rodo, kad mūsų modelis gerokai viršija transformatoriumi pagrįstus modelius, parengtus iš anksto pagal konkrečius srities duomenis.', 'mk': 'We present an algorithm based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data.  Нашиот модел се потпира на сопственостите на проблемот и карактеристиките на контекстните зборови вградени за да извадат два погледи од документите. Потоа класификатор е обучен на секој поглед за да означи набор неозначени документи кои ќе се користат како иницијализатор за нов класификатор во другиот поглед. Конечно, иницијализираниот класификатор во секој поглед е понатамошно обучен користејќи ги примерите на иницијалната обука. Го проценивме нашиот модел во најголемиот јавно достапен АДР податок. Експериментите сведочат дека нашиот модел значително ги надминува моделите базирани на трансформатори претренирани на податоци специфични за доменот.', 'ms': 'Kami memperkenalkan algoritma berdasarkan pengubah berbilang lapisan untuk mengenali tindakan balas dadah (ADR) dalam data media sosial. Model kami bergantung pada ciri-ciri masalah dan ciri-ciri penyampaian kata kontekstual untuk mengekstrak dua pandangan dari dokumen. Kemudian pengklasifikasi dilatih pada setiap paparan untuk label set dokumen tidak berlebihan yang digunakan sebagai penginisialisasi untuk pengklasifikasi baru dalam paparan lain. Akhirnya, pengukur awal dalam setiap paparan dilatih lebih lanjut menggunakan contoh latihan awal. Kami menilai model kami dalam set data ADR terbesar yang tersedia publik. Eksperimen-eksperimen menyatakan bahawa model kita secara signifikan melebihi model berasaskan pengubah yang dilatih pada data khusus domain.', 'mt': 'Aħna nippreżentaw algoritmu bbażat fuq trasformaturi multisaffi għall-identifikazzjoni tar-Reazzjonijiet Avversi tal-Mediċini (ADR) fid-dejta tal-midja soċjali. Il-mudell tagħna jiddependi fuq il-karatteristiċi tal-problema u l-karatteristiċi tal-inkorporazzjonijiet tal-kliem kuntestwali biex jiġu estratti żewġ fehmiet mid-dokumenti. Imbagħad klassifikatur jitħarreġ fuq kull vista biex tikketta sett ta’ dokumenti mingħajr tikketta li għandhom jintużaw bħala inizjalizzatur għal klassifikatur ġdid fil-vista l-oħra. Fl-aħħar nett, il-klassifikatur inizjalizzat f’kull fehma huwa mħarreġ aktar bl-użu tal-eżempji tat-taħriġ inizjali. Aħna evalwajna l-mudell tagħna fl-akbar sett ta’ dejta disponibbli pubblikament dwar l-ADR. L-esperimenti jixhdu li l-mudell tagħna jwassal b’mod sinifikanti għall-mudelli bbażati fuq it-trasformaturi mħarrġa minn qabel fuq dejta speċifika għad-dominju.', 'kk': 'Көпқабатты түрлендірушерге негізделген алгоритм (ADR) әлеуметтік медиа деректерінде қарсы наркотикалық реакцияларын анықтау үшін. Біздің үлгіміз мәселенің қасиеттеріне, құжаттардан екі көрініс тарқату үшін контексті сөздің ендіру қасиеттеріне тәуелді. Келесі кезде, әрбір көрініс бойынша жаңа классификатор үшін бастау үшін қолданылатын құжаттардың жиынын белгілеу үшін классификаторы әрбір көрініс бойынша оқылған. Соңында, әрбір көріністің бастапқы классификациясы бастапқы оқыту мысалдарын қолдануға болады. Біз моделімізді ADR деректер қорларының ең үлкен жалғастырып тұрдық. Тәжірибелер біздің моделіміз доменге арналған деректерге аударып тұратын үлгілер үлгілерін көмектеседі.', 'mn': 'Бид нийгмийн мэдээлэл дээр эсрэг наркотийн урвалыг олж мэдэхэд олон давхар шилжүүлэгчид дээр суурилсан алгоритмыг тайлбарлаж байна. Бидний загвар нь асуудал болон орчин үг бичиг баримтуудаас хоёр үзэл авахын тулд асуудлын өөрчлөлтийг хамаарна. Дараа нь нэг ангилагч бусад үзэл дээр шинэ ангилагчдын хувьд ашиглах шаардлагагүй баримтуудыг загварлах боломжтой болно. Эцэст нь, анхны дасгалын жишээг ашиглаж эхэлсэн ангилалын хуваалцагч нь илүү дасгал суралцагдсан. Бид өөрсдийн загварыг хамгийн их олон нийтийн ADR өгөгдлийн санд үнэлгээд үзсэн. Эдгээр туршилтууд бидний загвар нь тодорхой мэдээлэл дээр шилжүүлэгч дээр суурилсан загваруудыг илүү их ашигладаг гэдгийг харуулдаг.', 'pl': 'Przedstawiamy algorytm oparty na transformatorach wielowarstwowych służący identyfikacji działań niepożądanych (ADR) w danych mediów społecznościowych. Nasz model opiera się na właściwościach problemu i charakterystyce kontekstowych osadzeń słów, aby wyodrębnić dwa widoki z dokumentów. Następnie klasyfikator jest szkolony na każdym widoku, aby oznaczać zestaw nieoznakowanych dokumentów, które mają być użyte jako inicjalizator dla nowego klasyfikatora w drugim widoku. Wreszcie, zainicjowany klasyfikator w każdym widoku jest dalej trenowany przy użyciu przykładów szkolenia wstępnego. Oceniliśmy nasz model w największym publicznie dostępnym zbiorze danych ADR. Eksperymenty świadczą o tym, że nasz model znacznie przewyższa modele oparte na transformatorach wstępnie przeszkolone na danych specyficznych dla domeny.', 'no': 'Vi presenterer ein algoritme basert på fleire lag-transformatorar for å identifisera motsetjingar av narkotika-reaksjonar (ADR) i sosiale media-data. Modellen vårt er avhengig av eigenskapane til problemet og eigenskapane til kontekstlege ordinnbygging for å pakka ut to vising frå dokument. Deretter vert ei klassifiserer trent på kvar vising for å merke eit sett med uklassifiserte dokument som skal brukast som oppstartar for ein ny klassifiser i den andre visinga. Til slutt er den oppstarta klassifiseringen i kvar vising lenger trent ved hjelp av eksemplane for opplæring. Vi evaluerte modellen vårt i den største tilgjengelege ADR-datasettet. Eksperimentane viser at modellen vårt er betydelig enn å utføra transformeringsbaserte modelane som er pretraint på domenespesifikke data.', 'ka': 'ჩვენ მრავალური ტრანფორმეტრების განსაზღვრებისთვის ალგორიტიმს გამოყენებთ სოციალური მედიაში მონაცემების განსაზღვრებისთვის. ჩვენი მოდელი იყოს პრობლემენტის განსაზღვრებით და კონტექსტური სიტყვების განსაზღვრებების განსაზღვრებით, რომ დოკუმენტიდან ორი ხედის გამოკლება. შემდეგ კლასიფიკაცია ყოველ ხედავზე განსწავლია, რომ საკუთარი ხედავში ახალი კლასიფიკაციატორისთვის გამოყენებული დოკუმენტების კონფიკაციას დანიშნოთ. საბოლოოდ, ყოველ ხედავში инициаლურად კლასიფიკაციული კლასიფიკაცია უფრო მეტად განსწავლია პირველი განსწავლების მაგალითად. ჩვენ ჩვენი მოდელს უფრო დიდი ადამიანის სახელსაწვდომით ADR მონაცემების სახელსაწვდომაში გავამუშავეთ. ექსპერიმენტები უკავშირებენ, რომ ჩვენი მოდელი მნიშვნელოვანად უფრო გავაკეთებს ტრანფორმენტების მოდელები, რომლებიც დიომინის სპექტიფიკური', 'ro': 'Vă prezentăm un algoritm bazat pe transformatoare multistrat pentru identificarea reacțiilor adverse la medicament (ADR) în datele social media. Modelul nostru se bazează pe proprietățile problemei și caracteristicile încorporărilor contextuale de cuvinte pentru a extrage două vizualizări din documente. Apoi, un clasificator este instruit pe fiecare vizualizare pentru a eticheta un set de documente neetichetate pentru a fi utilizate ca inițializator pentru un nou clasificator în cealaltă vizualizare. În cele din urmă, clasificatorul inițializat în fiecare vizualizare este instruit în continuare folosind exemplele de formare inițială. Am evaluat modelul nostru în cel mai mare set de date ADR disponibil public. Experimentele demonstrează că modelul nostru depășește semnificativ modelele bazate pe transformator pre-instruite pe date specifice domeniului.', 'so': 'Waxaynu soo bandhignaa algoritm ku saleysan bedelka kala duduwan si aan u aqoonsanno jawaabayaasha dawooyinka kala duwan (ADR) ee macluumaadka bulshada. Tusaalkayagu wuxuu ku xiran yahay xuquuqda dhibaatada iyo xuquuqda hadalka joogtada ah ee soo saara labada arag oo ka soo saara dukumentiyada. Markaas waxaa la tababarayaa fasax kasta si uu u qoro qoraal a an la aqoon in looga isticmaalo mid bilowga fasax cusub. Finally, the initialized classifier in each view is further trained using the initial training examples.  Tusaalkayagii waxan ku qiimeynay sawirada macluumaadka ADR ee ugu weyn. Imtixaanka waxaa ku maraya in modellkayagu uu si muhiim ah u sameeyo modelalka beddelka oo lagu soo beddelay macluumaadka gaarka ah ee domain.', 'ml': 'നമ്മള്\u200d ഒരു ആല്\u200dഗോരിതം സാമൂഹിക മാധ്യമങ്ങളുടെ വിവരങ്ങളില്\u200d നിരീക്ഷിക്കുന്നതിനായി പല-layer മാറ്റങ്ങള്\u200d അടിസ്ഥാനമാക്കി നമ്മുടെ മോഡല്\u200d പ്രശ്നത്തിന്റെ ഗുണഗണങ്ങളില്\u200d ആശ്രയിക്കുന്നു. രേഖകളില്\u200d നിന്ന് രണ്ടു കാഴ്ചകള്\u200d പുറത്തെടുക്കാന്\u200d ഉള്\u200d പിന്നീട് ഓരോ കാഴ്ചയിലും ഒരു ക്ലാസ്ഫിഫയര്\u200d പരിശീലിക്കപ്പെടുന്നു. മറ്റൊരു കാഴ്ചയില്\u200d പുതിയ ക്ലാസ്ഫിഫയര്\u200d ആയി ഉപയോഗിക്കാന്\u200d ഒരു  അവസാനം, ഓരോ കാഴ്ചയിലും ആദ്യ പരിശീലനത്തിന്റെ ഉദാഹരണങ്ങള്\u200d ഉപയോഗിച്ച് തുടങ്ങിയ ക്ലാസ്ഫിഫറിന് കൂടുതല്\u200d പരി നമ്മുടെ മോഡല്\u200d നമ്മുടെ ഏറ്റവും വലിയ പ്രധാനപ്പെട്ട എഡിആര്\u200d ഡാറ്റാസറ്റില്\u200d വിലയിച്ചു. പരീക്ഷണങ്ങള്\u200d സാക്ഷ്യം വഹിക്കുന്നു നമ്മുടെ മോഡല്\u200d മാറ്റങ്ങള്\u200d അടിസ്ഥാനത്തുള്ള മോഡലുകള്\u200d ഡൊമെയിന്\u200d പ്രത്യേക വിവ', 'sv': 'Vi presenterar en algoritm baserad på flerlagers transformatorer för att identifiera biverkningar (ADR) i sociala medier data. Vår modell bygger på problemets egenskaper och egenskaperna hos kontextuella ordinbäddningar för att extrahera två vyer från dokument. Sedan utbildas en klassificerare i varje vy för att märka en uppsättning omärkta dokument som ska användas som initialisator för en ny klassificerare i den andra vyn. Slutligen utbildas den initialiserade klassificeraren i varje vy vidare med hjälp av de grundläggande utbildningsexemplen. Vi utvärderade vår modell i den största allmänt tillgängliga ADR-datauppsättningen. Experimenten vittnar om att vår modell avsevärt överträffar de transformatorbaserade modellerna som tidigare tränats på domänspecifika data.', 'ta': 'We present an algorithm based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data.  எங்கள் மாதிரி பிரச்சனையின் பண்புகளை நம்புகிறது மற்றும் தற்போதைய வார்த்தையின் தன்மைகளை ஆவணங்களிலிருந்து இரண்டு காட் பின்னர் ஒவ்வொரு பார்வையிலும் வகுப்பாளர் பயிற்சி செய்யப்படுகிறது மற்ற காட்சியில் புதிய வகுப்பாளருக்கு ஒரு புதிய வகுப்பா இறுதியில், ஒவ்வொரு காட்சியிலும் துவக்கப்பட்ட வகுப்பாளர் முதல் பயிற்சி உதாரணங்களை பயன்படுத்தி மேலும்  பெரிய பொதுவான ADR தரவுத்தளத்தில் எங்கள் மாதிரியை மதிப்பிட்டோம். பரிசோதனைகள் சாட்சி கூறுகிறார்கள் என்றால் எங்கள் மாதிரி முக்கியமாக மாற்றம் அடிப்படையில் உள்ள மாற்றம் மாதிரிகளை மா', 'ur': 'ہم ایک الگوریٹم کو اجتماعی میڈیا ڈیٹا میں آواز ڈراگ رکتیوں (ADR) کی شناسایی کرنے کے لئے multi layer transformers پر بنیاد رکھتے ہیں. ہمارا مدل مسئلہ کے خصوصے پر اور مسئلہ کے خصوصے پر باقی رہتا ہے کہ دو دفتروں سے دو نظر اٹھائے۔ اس کے بعد ہر نظر پر ایک کلاسیر کی تدریس کی جاتی ہے کہ دوسری نظر میں ایک نئی کلاسیر کے لئے استعمال کیا جائے گا۔ آخر میں، ہر نظر میں شروع کیا گیا کلاسیر آغاز کی تعلیم مثال کے مطابق اضافہ کی تعلیم کی جاتی ہے. ہم نے اپنے مدل کو سب سے زیادہ اڈر ڈیٹسٹ میں ارزش کیا۔ آزمائش کی گواہی دیتی ہے کہ ہمارا موڈل معلوم ہوتا ہے کہ تغییر دینے والی موڈل کو دکھائی ہوئی ڈیٹ پر زیادہ اثر دیتا ہے۔', 'sr': 'Predstavljamo algoritam baziran na višeslojnim transformatorima za identifikaciju nuspojavnih reakcija droge (ADR) u podacima društvenih medija. Naš model se oslanja na vlasništva problema i karakteristike kontekstualne reèi za ukljuèenje dva pogleda iz dokumenta. Onda je klasifikator obučen na svakom pogledu kako bi označio setu neopisivanih dokumenta koji se koristi kao inicijalizator za novi klasifikator u drugom pogledu. Na kraju, inicijalizirani klasifikator u svakom pogledu je dodatno obučen koristeći primjere početne obuke. Procjenili smo naš model u najvećem javno dostupnom setu podataka ADR-a. Eksperimenti svjedočavaju da naš model značajno iznosi modele na transformaciji koji su pretrenuli na specifične podatke domena.', 'si': 'අපි සමාජික මිඩියාවේ ප්\u200dරතික්\u200dරියාත්මක (ADR) තොරතුරු අඳුරගන්න ගොඩක් ස්ථානයක් තියෙන්න ඇල්ගෝරිධම් එකක් ප අපේ මොඩේල් ප්\u200dරශ්නයේ විශේෂතාවය සහ ප්\u200dරශ්නයේ වචන සම්බන්ධතාවයේ විශේෂතාවය සම්බන්ධ විශේෂතාවය ලිප ඊට පස්සේ විශේෂකයෙක් හැම දිහා ප්\u200dරශ්නයක් ලේබල් කරන්න, අනිත් දිහා විශේෂකයෙන් අලුත් විශේෂකයෙන් ප්\u200dරශ්නය කරන් අන්තිමේදි, හැම ප්\u200dරකාරයෙක්ම පටන් ගත්ත විශේෂකයෙක්ම පටන් ගත්ත විශේෂකය විදිහට පටන් ගත්තා  අපි අපේ මෝඩේල් විශ්වාස කරලා තියෙන්නේ ලොකු සාමාජික ADR දත්ත සූද්ධතාවට. පරීක්ෂණය සාක්ෂි කරනවා අපේ මොඩල් විශේෂයෙන් විශේෂයෙන් ප්\u200dරවර්තනය කරනවා කියලා.', 'uz': "Biz jamiyat media maʼlumotida bir necha qatlamlar o'zgarishlarni aniqlash uchun algoritni ko'plab-darajaga asoslangan. Bizning modelimiz muammolar xossalariga va har xil so'zlarini qoʻllash uchun ikkita ko'rini hujjatdan chiqarish mumkin. Name Oxiri, har bir koʻrinishida boshlangan sinfga birinchi taʼminlovchi boshlanadi. Biz juda katta shaxsiy tilgan ADR maʼlumotlar sohasida modelimizni qiymatdik. Imtizolar bu modelmiz domen-specific maʼlumotga o'zgartirish asosiy modellarini aniqlaydi.", 'vi': 'Chúng tôi đưa ra một thuật toán dựa trên máy biến đổi đa lớp để xác định phản ứng phụ phản ứng phản ứng phụ (AD) trong dữ liệu phương tiện truyền thông xã hội. Mẫu của chúng tôi dựa vào tính chất của vấn đề và tính chất của sự nhúng vào các từ ngữ ngữ ngữ ngữ để lấy hai tư liệu. Sau đó một người phân loại được đào tạo trên mỗi ô xem để dán nhãn một chuỗi các tài liệu chưa được dán (lô) để được dùng làm người khởi đầu cho một người phân loại mới trong ô xem khác. Cuối cùng, một phân mật đã được huấn luyện thêm dưới những thành sự sở dạy. Chúng tôi đã đánh giá mẫu của chúng tôi trong bộ dữ liệu dị ứng cao nhất. Các thí nghiệm cho thấy mẫu vật của chúng ta vượt trội hơn các mẫu máy biến hình trước khi dựa vào dữ liệu miền.', 'bg': 'Представяме алгоритъм, базиран на многослойни трансформатори за идентифициране на нежелани лекарствени реакции (АРР) в социалните медии. Нашият модел разчита на свойствата на проблема и характеристиките на контекстуалните вграждания на думи, за да извлече два изгледа от документи. След това класификатор се обучава за всеки изглед да етикетира набор от незабелязани документи, които да се използват като инициализатор за нов класификатор в другия изглед. Накрая инициализираният класификатор във всеки изглед се обучава допълнително, като се използват примерите за първоначално обучение. Оценихме нашия модел в най-големия обществено достъпен набор от данни за АРС. Експериментите свидетелстват, че нашият модел значително превъзхожда моделите, базирани на трансформатори, предварително обучени върху специфични за домейна данни.', 'da': 'Vi præsenterer en algoritme baseret på flerlagstransformatorer til identificering af bivirkninger (ADR) i sociale medier data. Vores model er afhængig af problemets egenskaber og karakteristika ved kontekstuelle ordindlejringer for at udtrække to visninger fra dokumenter. Derefter trænes en klassificerer i hver visning til at mærke et sæt ikke-mærkede dokumenter, der skal bruges som initialisator for en ny klassificerer i den anden visning. Endelig uddannes den initialiserede klassificering i hver visning yderligere ved hjælp af eksemplerne på grunduddannelse. Vi evaluerede vores model i det største offentligt tilgængelige ADR datasæt. Eksperimenterne vidner om, at vores model betydeligt overgår transformatorbaserede modeller forudtrænet på domænespecifikke data.', 'nl': 'We presenteren een algoritme gebaseerd op meerlaagse transformatoren voor het identificeren van bijwerkingen (ADR) in social media data. Ons model baseert zich op de eigenschappen van het probleem en de kenmerken van contextuele woordinsluitingen om twee weergaven uit documenten te extraheren. Vervolgens wordt een classificator getraind op elke weergave om een reeks niet-gelabelde documenten te labelen die worden gebruikt als initializer voor een nieuwe classificator in de andere weergave. Ten slotte wordt de geïnitialiseerde classificator in elke weergave verder getraind aan de hand van de initiële trainingsvoorbeelden. We hebben ons model geëvalueerd in de grootste publiekelijk beschikbare ADR-dataset. De experimenten getuigen dat ons model aanzienlijk beter presteert dan de transformatorgebaseerde modellen die vooraf zijn getraind op domeinspecifieke gegevens.', 'de': 'Wir stellen einen Algorithmus vor, der auf mehrschichtigen Transformatoren basiert, um unerwünschte Arzneimittelreaktionen (ADR) in Social Media Daten zu identifizieren. Unser Modell stützt sich auf die Eigenschaften des Problems und die Eigenschaften kontextueller Worteinbettungen, um zwei Ansichten aus Dokumenten zu extrahieren. Anschließend wird ein Klassifikator für jede Ansicht trainiert, eine Reihe von nicht beschrifteten Dokumenten zu kennzeichnen, die als Initialisierer für einen neuen Klassifikator in der anderen Ansicht verwendet werden sollen. Abschließend wird der initialisierte Klassifikator in jeder Ansicht anhand der Erstausbildungsbeispiele weiter trainiert. Wir haben unser Modell im größten öffentlich zugänglichen ADR-Datensatz evaluiert. Die Experimente belegen, dass unser Modell die transformatorbasierten Modelle, die auf domänenspezifischen Daten vortrainiert wurden, deutlich übertrifft.', 'hr': 'Predstavljamo algoritam baziran na multislojnim transformatorima za identifikaciju nuspojavnih reakcija droge (ADR) u podacima društvenih medija. Naš model se oslanja na vlasništva problema i karakteristike kontekstualne riječi uključene kako bi izvukao dva pogleda iz dokumenta. Onda se klasifikator obučava na svakom pogledu kako bi označio skup neopisivanih dokumenta koji se koristi kao inicijalizator za novi klasifikator u drugom pogledu. Konačno je inicijalizirani klasifikator u svakom pogledu dodatno obučen koristeći primjere početne obuke. Procijenili smo naš model u najvećem javno dostupnom sastavu podataka ADR-a. Eksperimenti svjedočavaju da naš model značajno nadmašuje modele na transformaciji koji su se pretvarali na specifične podatke domena.', 'id': 'Kami mempersembahkan algoritma berdasarkan transformator berbilang lapisan untuk mengidentifikasi Reaksi Narkoba (ADR) dalam data media sosial. Model kita bergantung pada properti masalah dan karakteristik dari pembangunan kata kontekstual untuk mengekstrak dua pandangan dari dokumen. Then a classifier is trained on each view to label a set of unlabeled documents to be used as an initializer for a new classifier in the other view.  Akhirnya, klassifikasi inisialisasi dalam setiap pandangan dilatih lebih lanjut menggunakan contoh pelatihan awal. Kami mengevaluasi model kami dalam set data ADR terbesar yang tersedia publik. Eksperimen-eksperimen menyaksikan bahwa model kita secara signifikan melebihi model berdasarkan transformer yang dilatih di data spesifik domain.', 'ko': '소셜미디어 데이터에서 약물 불량반응(ADR)을 식별하기 위한 다중 변압기 기반 알고리즘을 제시했다.우리의 모델은 문제의 성질과 상하문 단어가 삽입된 특징에 의존하여 문서에서 두 개의 보기를 추출한다.그리고 모든 보기에서 분류기를 훈련시켜 표시하지 않은 문서를 다른 보기에서 새 분류기의 초기 값으로 설정합니다.마지막으로 초기 훈련 예시를 사용하여 각 보기의 초기화 분류기를 더욱 훈련한다.우리는 가장 큰 공개ADR 데이터에서 우리의 모델을 집중적으로 평가했다.실험은 우리의 모델이 특정 분야의 데이터를 바탕으로 미리 훈련한 변압기 모델보다 현저히 우수하다는 것을 증명했다.', 'sw': 'Tunaweza kutoa orodha inayohusiana na mabadiliko ya viwanja vingi kwa ajili ya kutambua miitikio ya dawa tofauti (ADR) katika taarifa za mitandao ya kijamii. Mfano wetu unategemea utamaduni wa tatizo na utaalam wa neno la kisasa linaloingia ili kutengeneza maoni mawili kutoka kwenye nyaraka. Kisha mfanyakazi anafundishwa kwa kila mtazamo wa kuandika mfululizo wa nyaraka zisizoeleweka ili kutumika kama mwanzaji wa darasa mpya katika mtazamo mwingine. Mwisho, mwandishi wa mwanzo katika kila mtazamo anafundishwa zaidi kwa kutumia mifano ya mafunzo ya mwanzo. Tumepima mfano wetu katika seti kubwa ya taarifa za ADR zinazopatikana hadharani. Majaribio yanashuhudia kuwa mifano yetu inaonyesha mifano ya mabadiliko yanayotokana na taarifa maalum za ndani.', 'fa': 'ما الگوریتم را بر اساس تغییردهندگان چند طبقه برای شناسایی واکنش مواد مخالفت (ADR) در داده\u200cهای رسانه\u200cهای اجتماعی نشان می\u200cدهیم. مدل ما بر ویژه\u200cهای مشکل و ویژه\u200cهای کلمه\u200cهای متوسطی برای اخراج دو دیده از سند بستگی دارد. سپس یک گروهی روی هر نمایش آموزش داده می شود تا یک مجموعه از سند غیرقابل استفاده شود که برای یک گروهی جدید در نمایش دیگر استفاده شود. بالاخره، محرمانه\u200cی آغاز شده در هر دیدگاه از طریق مثالهای آموزش آغاز بیشتر آموزش یافته می\u200cشود. ما مدل خود را در بزرگترین مجموعه داده های ADR در دسترس عمومی ارزیابی کردیم. آزمایش ها گواهی می دهند که مدل ما خیلی بیشتر از مدل های تغییر دهنده بر روی داده های ویژه ویژه دارد.', 'af': "Ons stel 'n algoritme gebaseer op multilaag transformeerders vir die identifiseer van Adverse Drug Reactions (ADR) in sosiale media data. Ons model lig op die eienskappe van die probleem en die eienskappe van contextual word inbêding om twee aansigte uit dokumente uit te pak. Dan is 'n klassifiseerder onderwerp op elke aansig om 'n stel van ongeabelde dokumente te etiket wat gebruik word as 'n inisialiseerder vir' n nuwe klassifiseerder in die ander aansig. Eindelik is die geïnisialiseerde klassifiseerder in elke aansig verder onderwerp deur die aanvanklike onderwerp voorbeelde te gebruik. Ons het ons model in die grootste publiek beskikbaar ADR datastel evalueer. Die eksperimente getuig dat ons model betekeurig uitvoer die transformer-gebaseerde modele wat op domein-spesifieke data gevorm het.", 'tr': 'Biz sosial mediýa maglumatynda "Adverse Drug Reactions (ADR)" diýmek üçin birnäçe-katly transformatçylara daýan ýan bir algoritmus görkeýäris Biziň modelimiz meseläniň häsiýetlerini we senediň içine girişinden iki görnöş hasaplaryndan boşaýar. Sonra bir klassifir başga bir senediň başlançysy üçin ullanýan täze bir klassifir üçin ullanylýan täze bir sened bejer. Soňunda, her görnöşinde başlançyly klasifikatçy başlangyç okuw örneklerini ulanyp öňünde eğitilýär. Biz nusgamyzy iň uly adam içinde bar ADR veri setirinde deňlendirdik. Deneyler bizim modelimiz, domun özel verilerine basılan transformer tabanlı modellerinin önemli şekilde etkilendiğini ifade ediyor.', 'sq': 'Ne paraqesim një algoritëm bazuar në transformuesit me shumë nivele për identifikimin e Reaksioneve të Pafavorshme të Drogëve (ADR) në të dhënat e medias sociale. Modeli ynë mbështetet në pronësitë e problemit dhe karakteristikat e përfshirjes kontekstuale të fjalëve për të nxjerrë dy pamje nga dokumentet. Pastaj një klasifikues është trajnuar në çdo pamje për të etiketuar një sërë dokumentesh pa etiketë që do të përdoren si një inicializues për një klasifikues të ri në pamjen tjetër. Më në fund, klasifikuesi i inicializuar në çdo pamje është trajnuar më tej duke përdorur shembujt e trajnimit fillestar. Kemi vlerësuar model in tonë në grupin më të madh të të dhënave ADR në dispozicion publik. The experiments testify that our model significantly outperforms the transformer-based models pretrained on domain-specific data.', 'am': 'በአማኅበራዊ ሚዲያ ዳታዎችን ለማግኘት በብዙ ደረጃዎች ለውጦች ላይ የተመሳሳይ አሌጎሪትምን እናቀርባለን፡፡ ሞዴሌያችን የችግሩን ምርጫዎች እና ሁለተኛውን ቃላት ከሰነዶች ሁለት ተመልከትን ለማውጣት ነው፡፡ ከዚህም በኋላ ሁኔታ ማሰናከል በሁለተኛው ተመልከት ላይ ያልታወቀ ሰነዱን ለማሳየት የሚጠቀሙት አዲስ መግለጫ ለመጠቀም ያስተምራል፡፡ በመጨረሻው የመጀመሪያው ክፍል መፍጠር በሁሉም ተመልከት የመጀመሪያው ትምህርት ምሳሌዎችን በመጠቀም ይጨምረዋል፡፡ አዲስ ዳታ ማድረጊያውን በተለጠቀው ትልቁ የሆኑን ሞዴሌዎቻችንን አስተዋልነው፡፡ ፈተናዎቹ ሞዴላዎቻችን በዶሜን-በተለወጠው ዳታዎች ላይ የተለየውን የለውጠውን ምሳሌዎች እንዲያሳየው ይመሰክራሉ፡፡', 'hy': 'Մենք ներկայացնում ենք մի ալգորիթմ, որը հիմնված է բազմաշերտ վերափոխողների վրա, որպեսզի հասարակական լրատվամիջոցների տվյալներում հայտնաբերենք թմրադեղերի կողմնակալ արձագանքները: Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents.  Հետո դասակարգիչը յուրաքանչյուր տեսանկյունին սովորեցվում է նշել մի շարք աննշան փաստաթղթեր, որոնք օգտագործվում են որպես նոր դասակարգիչը մյուս տեսանկյունին: Վերջապես, յուրաքանչյուր տեսանկյունից սկզբնական դասակարգիչը ավելին է վարժեցնում օգտագործելով սկզբնական վարժեքի օրինակները: Մենք գնահատեցինք մեր մոդելը ամենամեծ հանրային ADR տվյալների համակարգում: Փորձարկումները վկայում են, որ մեր մոդելը նշանակալիորեն գերազանցում է վերափոխողների հիմնված մոդելները, որոնք նախադասում են բնագավառի կոնկրետ տվյալների վրա:', 'az': 'Biz sosyal media məlumatlarında Adverse Drug Reactions (ADR) təsdiqlənmək üçün çoxlu katlı transformatorlarına dayanan bir algoritm göstəririk. Bizim modellərimiz problemin özelliklərinə və müxtəlif sözlərin xüsusiyyətlərinə təvəkkül edir. Sonra hər görünüş üzərində bir klasifikatçı başqa görünüşdə yeni klasifikatçı üçün istifadə ediləcək müəyyən edilməmiş belələrin qeydəsini etiketləmək üçün təhsil edilir. Sonunda, hər görünüşdə ilk təhsil örnəkləri ilə başlanğıç təhsil edilən klasifikatçı daha çox təhsil edilir. Bizim modelimizi ən böyük nümunə verilən ADR veri qutusunda değerləşdirdik. Testlər bizim modelimiz dəyişdirilmiş modelləri domain-specific məlumatlarına təsirlənmiş olduğuna şahidlik edirlər.', 'bn': 'সামাজিক প্রচার মাধ্যমের তথ্যে ড্রাগ প্রতিক্রিয়া চিহ্নিত করার জন্য আমরা বহু স্তরের পরিবর্তনের উপর ভিত্তিক অ্যালগরিদম উপস্থ আমাদের মডেল সমস্যার বৈশিষ্ট্যের উপর নির্ভর করে এবং নথিপত্র থেকে দুটি দৃষ্টিভঙ্গি বের করার জন্য বৈশিষ্ট্য শব্দের বৈশি তারপর প্রত্যেক দৃষ্টিতে একটি শ্রেণীপ প্রশিক্ষণ প্রদান করা হয় অন্য দৃশ্যে একটি নতুন শ্রেণীবিভাষক হিসেবে ব্যবহার করার জন্য একটি অল্প লেব শেষ পর্যন্ত প্রত্যেক দৃষ্টিভঙ্গিতে প্রথম প্রশিক্ষণের উদাহরণ ব্যবহার করে প্রশিক্ষণ প্রদান করা হয়েছে। আমরা বৃহত্তম প্রকাশিত এডিআর ডাটাসেটে আমাদের মডেল মূল্য করেছি। এই পরীক্ষাগুলো সাক্ষ্য দেয় যে আমাদের মডেল গুরুত্বপূর্ণ পরিবর্তনের ভিত্তিক মডেল ডোমেইন-নির্দিষ্ট তথ্যের প্রত', 'bs': 'Predstavljamo algoritam baziran na multislojnim transformatorima za identifikaciju nuspojavnih reakcija droge (ADR) u podacima o društvenim medijima. Naš model se oslanja na vlasništva problema i karakteristike kontekstualne riječi uključenih da izvučemo dva pogleda iz dokumenta. Onda je klasifikator obučen na svakom pogledu kako bi označio setu neizbiljnih dokumenta koji se koristi kao inicijalizator za novi klasifikator u drugom pogledu. Na kraju, inicijalizirani klasifikator u svakom pogledu je dodatno obučen koristeći primjere početne obuke. Procijenili smo naš model u najvećem javno dostupnom setu podataka ADR-a. Eksperimenti svjedočavaju da naš model značajno iznosi modele na transformaciji koji su pretrenuli na specifične podatke domena.', 'ca': "Presentam un algoritme basat en transformadors de múltiples capes per identificar les reaccions adversas a medicaments (ADR) a les dades dels mitjans socials. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents.  Un classificador està entrenat en cada vista per etiquetar un conjunt de documents no etiquetats que s'utilitzen com a inicializador per a un nou classificador en l'altra vista. Finalment, el classificador inicializat en cada vista està més entrenat fent servir els exemples d'entrenament inicial. Vam evaluar el nostre model en el conjunt de dades ADR més gran disponible al públic. Els experiments testimonien que el nostre model supera significativament els models basats en transformadors pré-entrenats en dades específices per domini.", 'cs': 'Představujeme algoritmus založený na vícevrstvých transformátorech pro identifikaci nežádoucích léčivých účinků (ADR) v datech sociálních médií. Náš model se opírá o vlastnosti problému a charakteristiky kontextových vložení slov k extrakci dvou pohledů z dokumentů. Poté je klasifikátor trénován na každém pohledu, aby označil sadu neoznačených dokumentů, které mají být použity jako inicializátor pro nový klasifikátor v druhém zobrazení. Nakonec je inicializovaný klasifikátor v každém pohledu dále trénován na příkladech počátečního školení. Náš model jsme hodnotili v největším veřejně dostupném datovém souboru ADR. Experimenty svědčí o tom, že náš model výrazně překonává modely založené na transformátorech předtrénované na doménově specifických datech.', 'et': 'Esitleme mitmekihilistel transformaatoritel põhinevat algoritmi kõrvaltoimete tuvastamiseks sotsiaalmeedia andmetes. Meie mudel tugineb probleemi omadustele ja kontekstipõhiste sõnade manustamise omadustele, et eraldada dokumentidest kaks vaadet. Seejärel koolitatakse klassifitseerijat iga vaate kohta märgistama märgistamata dokumentide komplekti, mida kasutatakse uue klassifitseerija initsialiseerijana teises vaates. Lõpuks koolitatakse igas vaates initsialiseeritud klassifitseerijat, kasutades algkoolituse näiteid. Hindasime oma mudelit suurimas avalikult kättesaadavas vaidluste kohtuvälise lahendamise andmekogumis. Katsed kinnitavad, et meie mudel on märkimisväärselt parem kui domeenispetsiifilistel andmetel eeltreenitud trafopõhised mudelid.', 'fi': 'Esitämme monikerroksisiin muuntajiin perustuvan algoritmin haittavaikutusten tunnistamiseksi sosiaalisen median datassa. Mallimme perustuu ongelman ominaisuuksiin ja kontekstuaalisten sanaupotusten ominaisuuksiin saadakseen dokumenteista kaksi näkymää. Sitten luokittelija koulutetaan jokaisessa näkymässä merkitsemään joukko merkitsemättömiä asiakirjoja, joita käytetään uuden luokittelijan alustajana toisessa näkymässä. Lopuksi kussakin näkymässä olevaa alustallista luokittelijaa koulutetaan edelleen käyttämällä peruskoulutuksen esimerkkejä. Arvioimme malliamme suurimmassa julkisesti saatavilla olevassa ADR-aineistossa. Kokeet todistavat, että mallimme suoriutuu merkittävästi paremmin kuin domain-spesifisellä datalla esikoulutetut muuntajapohjaiset mallit.', 'jv': 'We present an Algorithm basic on multi-layer transformer for ID Advrse Drog Activations (AdR) in media data. model kita nguasai nggawe perusahaan anyar ing boten lan karcis sing dibutuhke gambarang contextual politenessoffpolite"), and when there is a change ("assertivepoliteness Tulung, kaliteras tualisis seneng langgar sapa seneng pisan seneng sak luwih tukang mulai nggawe bisa sapa seneng tukang mulai. Awak dhéwé éntuk model dhéwé ing nggawe dataset DNR sing luwih dumadhan The testing testing testing that we model badly output the transformer-basic modeles prespied on domain-special data.', 'he': 'אנחנו מציגים אלגוריתם מבוסס על משתנים רבים שכבות לזהות תגובות תרופות רעות (ADR) במידע התקשורת החברתית. המודל שלנו סומך על תכונות הבעיה והתכונות של קישור מילים קונטקסטיים כדי להוציא שני צופים ממסמכים. לאחר מכן מקליסן מאומן על כל נוף כדי לתייג קבוצה של מסמכים ללא סימנים שימשמשו בתור מתחיל לקליסן חדש בנוף השני. Finally, the initialized classifier in each view is further trained using the initial training examples.  הערכנו את המודל שלנו במערכת הנתונים הגדולה ביותר שזמינה לציבור. הניסויים מעדיפים שהדוגמא שלנו יוצאת משמעות יותר ממודלים מבוססים על המעבר שמתאימים מראש על נתונים ספציפיים לתחום.', 'sk': 'Predstavljamo algoritem, ki temelji na večplastnih transformatorjih za identifikacijo neželenih učinkov zdravil (ADR) v podatkih družbenih omrežij. Naš model temelji na lastnostih problema in značilnostih kontekstne vdelave besed, da iz dokumentov izvlečemo dva pogleda. Nato se za vsak pogled usposobi klasifikator, da označi nabor neoznačenih dokumentov, ki se uporabljajo kot inicializator za nov klasifikator v drugem pogledu. Nazadnje se inicializirani klasifikator v vsakem pogledu nadaljnje usposablja z uporabo primerov začetnega usposabljanja. Naš model smo ocenili v največjem javno dostopnem naboru podatkov ADR. Poskusi pričajo, da je naš model bistveno boljši od transformatorskih modelov, ki so bili predtrenirani na podlagi domenskih podatkov.', 'ha': "Tuna halatar da algoritm a kan canza transformers masu yawa wa gane wa Cikakken Narci (ADR) cikin data na jamii. Misalinmu yana dõgara kan tayari na matabbata da ke cikin maganar da ke cikin a ƙunsa, dõmin ya fito sautin biyu daga takardar. Sa'an nan an sanar da wani mai rarraba cikin kõwace idãnun ya yi amfani da wasu takardar takardar da ba'a yi ba da amfani da shi kamar mai gabatar da wani mai tsari na daban cikin wani misalin. Na ƙarami, ana ƙara wa mai fara-rabo cikin kowace misãlai na farko. Mun ƙaddara misalinmu cikin tsarin da ake samu da bayani na ADR. Kayan jarrabai sun shaidar cẽwa misalinmu yana ƙara zafi masu motsi da aka danna a kan canza a kan danne-bayani.", 'bo': 'ང་ཚོས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནང་དུ་གླེང་སྒྲུང་གཏོང་མཁན་མཐུན་རྐྱེན་བཟོ་བ་ཞིག་སྟོན་པ། ང་ཚོའི་མ་དབྱིབས་དཔེ་དབྱིབས་དཀའ་ངལ་གྱི་ངོ་བོའི་རྒྱུ་དངོས་ཡུལ་གྱི་ཁྱད་ཆོས་ཚོའི་ཁྱད་ཆོས འོན་ཀྱང་། དབྱེ་བ་ཞིག་ནི་ཀློག་སྟངས་རེ་རེར་སུ་ཤོག་བྱས་མེད་པའི་ཡིག མཇུག་རྫོགས་ན། ལྟ་སྟངས་རེ་རེའི་ནང་གི་འགོ་འཛུགས་བྱས་པའི་དབྱེ་རིགས་ནི་འགོ་འཛུགས་པའི་དཔེར་བརྗོད་འདི་སྤྱོད་ནས་ ང་ཚོས་རྒྱ་ནག་གི་མིག་དཔེ་དབྱིབས་མང་ཆེ་བའི་སྤྱོད་པའི་ADR གནད་སྡུད་ཆ་ཚན་ནང་གི་མིག་གཟུགས The experiments testify that our model significantly outperforms the transformer-based models pretrained on domain-specific data.'}
{'en': 'The ProfNER shared task on automatic recognition of occupation mentions in  social media  : systems, evaluation, guidelines, embeddings and corpora P rof NER  shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora', 'ar': 'شارك ProfNER في مهمة التعرف التلقائي على المهنة المذكورة في وسائل التواصل الاجتماعي: الأنظمة ، والتقييم ، والمبادئ التوجيهية ، وحفلات الزفاف ، والشركات', 'es': 'El ProFner compartió la tarea sobre el reconocimiento automático de menciones de ocupación en las redes sociales: sistemas, evaluación, directrices, incrustaciones y corpora', 'pt': 'O ProfNER compartilhou tarefa sobre reconhecimento automático de menções de ocupação em mídias sociais: sistemas, avaliação, diretrizes, embeddings e corpora', 'fr': 'Le ProFner a partagé la tâche sur la reconnaissance automatique des mentions professionnelles dans les médias sociaux\xa0: systèmes, évaluation, directives, intégrations et corpus', 'ja': 'ProfNERは、ソーシャルメディアでの職業への言及の自動認識に関するタスクを共有しました：システム、評価、ガイドライン、埋め込み、およびコーパス', 'zh': 'ProfNER于自动识别社交媒体中提及职业者共同任务:系统,评估,指南,嵌和语料库', 'ru': 'ProfNER поделился задачей по автоматическому распознаванию упоминаний профессии в социальных сетях: системы, оценка, руководящие принципы, встраивания и корпорации', 'hi': 'ProfNER ने सोशल मीडिया में उल्लेख किए गए व्यवसाय की स्वचालित मान्यता पर कार्य साझा किया: सिस्टम, मूल्यांकन, दिशानिर्देश, एम्बेडिंग और कॉर्पोरेट', 'ga': 'Roinn an tOllamh ProfNER tasc maidir le haitheantas uathoibríoch do lua gairm bheatha sna meáin shóisialta: córais, meastóireacht, treoirlínte, leabaithe agus corpora', 'ka': 'პროფინარები სოციალური მედიაში განსახულებული საქმენტის ავტომატურად აღმოჩნევის დასახულება: სისტემები, განსახულება, პროფინარები, ინბედინგი და კოპორაში', 'el': 'Η κοινή εργασία για την αυτόματη αναγνώριση των αναφορών επαγγέλματος στα μέσα κοινωνικής δικτύωσης: συστήματα, αξιολόγηση, κατευθυντήριες γραμμές, ενσωμάτωση και σώματα', 'hu': 'A ProfNER közös feladata a foglalkozási említések automatikus felismerésével a közösségi médiában: rendszerek, értékelés, iránymutatások, beágyazások és corpora', 'it': 'Il compito condiviso da ProfNER sul riconoscimento automatico delle menzioni professionali nei social media: sistemi, valutazione, linee guida, embedding e corpora', 'kk': 'Профессор қосымша мәліметтерді автоматты түрде анықтауға арналған тапсырма: жүйелер, оқу, бағыттау жолдары, ендіру және корпора', 'lt': 'ProfNER bendra užduotis automatiškai pripažinti profesiją social in ėje žiniasklaidoje: sistemos, vertinimas, gairės, įkūrimas ir korporas', 'mk': 'Профинер ја сподели задачата за автоматско признавање на окупацијата споменува во социјалните медиуми: системи, евалуација, насоки, вгради и корпора', 'ml': 'The ProfNER shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora', 'ms': 'ProfNER berkongsi tugas mengenai pengenalan automatik bagi sebutan pekerjaan dalam media sosial: sistem, penilaian, panduan, penyelesaian dan korpra', 'mt': 'Il-kompitu kondiviż tal-ProfNER dwar ir-rikonoxximent awtomatiku tal-impjiegi jissemma fil-midja soċjali: sistemi, evalwazzjoni, linji gwida, inkorporazzjonijiet u korporazzjoni', 'no': 'ProfNER-delt oppgåve om automatisk gjenkjenning av oppgåver i sosiale medier: systemet, evaluering, retningslinjer, innbygging og korpora', 'pl': 'ProfNER współdzielił się zadaniem automatycznego rozpoznawania wzmianek zawodowych w mediach społecznościowych: systemów, oceny, wytycznych, osadzeń i korpusów', 'mn': 'ProfNER нь нийгмийн хэвлэлийн ажиллагааны автоматжуулалтын хүлээн зөвшөөрөх үйл ажиллагааг хуваалцсан: систем, үнэлгээ, удирдлага, хөрөнгө оруулалт, корпора', 'ro': 'Activitatea comună a ProfNER privind recunoașterea automată a mențiunilor de ocupație în rețelele sociale: sisteme, evaluare, ghiduri, încorporări și corporații', 'sr': 'ProfNER je podijelio zadatak o automatskoj priznanju okupacije spominjanih u društvenim medijima: sisteme, procjena, uputstva, integracija i korporacija', 'si': 'සාමාජික මාධ්\u200dයානයේ ස්වයංක්\u200dරියාව අඳුරන්න ස්වයංක්\u200dරියාවක් ගැන සැකසුම් වැඩසටහන් කරනවා: පද්ධතිය, වි', 'sv': 'ProfNER delade uppgift om automatiskt erkännande av yrkesomnämnanden i sociala medier: system, utvärdering, riktlinjer, inbäddningar och corpora', 'ur': 'The ProfNER shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora', 'ta': 'தானாகவே தொழில்நுட்ப குறிப்புகளை தொடர்ந்து கொள்ள வேண்டும் பொருளில் பிரொப்பென்னர் பகிர்ந்த பணி', 'so': 'Macluumaadka bulshada ee sooshaalka: nidaamka, qiimeynta, hagitaanka, hogaamiyada iyo shirkadaha', 'uz': 'The ProfNER shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora', 'vi': 'Giáo sư chia sẻ nhiệm vụ nhận công việc tự động đề cập đến các phương tiện truyền thông xã hội: hệ thống, đánh giá, hướng dẫn, sự nhúng tay và nhóm', 'da': 'ProfNER delte opgave om automatisk anerkendelse af beskæftigelsesomtaler i sociale medier: systemer, evaluering, retningslinjer, indlejringer og corpora', 'bg': 'ПрофНЕР сподели задачата за автоматично разпознаване на споменавания за професии в социалните медии: системи, оценка, насоки, вграждания и корпори', 'nl': 'De ProfNER gedeelde taak over automatische herkenning van beroepen vermeldingen in sociale media: systemen, evaluatie, richtlijnen, embeddings en corpora', 'hr': 'ProfNER zajednički zadatak o automatskom priznanju okupacije spominjanih u društvenim medijima: sustavi, procjena, uputstva, ugrađenja i korpora', 'id': 'ProfNER berbagi tugas mengenai pengakuan otomatis dari pekerjaan menyebutkan di media sosial: sistem, evaluasi, panduan, embedding dan corpora', 'de': 'Die gemeinsame Aufgabe des ProfNER zur automatischen Erkennung von Berufsbezeichnungen in sozialen Medien: Systeme, Evaluation, Richtlinien, Einbettungen und Korpora', 'sw': 'ProfNER ilishiriki jukumu la kutambua maarufu binafsi ya kazi katika mitandao ya kijamii: mifumo, uchunguzi, miongozo, makubaliano na kampuni', 'ko': 'ProfNER는 소셜 미디어에서 직업 언급이 자동으로 식별되는 임무를 공유했다. 시스템, 평가, 안내서, 삽입과 자료 라이브러리', 'fa': 'عملیات پروفNER در مورد شناسایی خودکار شغل در رسانه\u200cهای اجتماعی مشترک شده است: سیستم، ارزیابی، هدایت\u200cنمایی، انجمن\u200cسازی و شرکت', 'af': 'Die ProfNER gedeelde taak op outomatiese herkening van occupasie bepaalde in sosiale media: stelsels, evaluering, gidsline, inbettings en korpora', 'sq': 'ProfNER e përbashkët detyrën mbi njohjen automatike të punës përmend në mediat shoqërore: sistemet, vlerësimin, drejtimin, përfshirjen dhe korprën', 'am': 'የፕሮጀኔር ሥርዓት በማኅበራዊ ሚዲያ ውስጥ ባለስብሰባዊ ስብሰባዎችን ማውቀት በራሱ ማውቀት ላይ ሰርቷል፡፡ ስርዓት፣ ማስታወቂያ፣ መሪ መሪ፣ መግለጫ እና ኮርፖርት', 'hy': 'ProfNet-ը համագործակցել է սոցիալական լրատվամիջոցներում մասնագիտության ավտոմատիկ ճանաչելու խնդիրը՝ համակարգեր, գնահատում, ուղղություններ, ներդրումներ և կապորա', 'az': 'ProfNER, sosyal mediyalarda idxal edil…ônl…ôrin avtomatik tanńĪnmasńĪ haqqńĪnda paylaŇüńĪr: sisteml…ôr, deńüerlendirm…ôl…ôr, dońüru yollar, in Ňüallar v…ô korpora.', 'bn': 'সামাজিক প্রচার মাধ্যমে স্বয়ংক্রিয় কর্মসূচির কথা স্বীকৃতির উপর প্রফেনার কাজ শেয়ার করেছে: সিস্টেম, মূল্যায়ন, নির্দেশ, প', 'ca': "La tasca compartida de ProfNER sobre el reconeixement automàtic de l'ocupació menciona als mitjans socials: sistemes, evaluació, directrices, incorporacions i corpora", 'cs': 'ProfNER sdílel úkol na automatickém rozpoznávání zmínek o povolání v sociálních médiích: systémy, hodnocení, pokyny, vložení a korpusy', 'tr': 'ProfNER sosyal medýýatlarda aýlanyşyň otomatik tanamasynda işi paýlaşýar: sistemler, deňleme, düzlemler, guramlar we korpora', 'et': 'ProfNERi ühine ülesanne sotsiaalmeedias kutsealaste märkuste automaatsel tunnustamisel: süsteemid, hindamine, suunised, manustamine ja korpused', 'fi': 'ProfNERin yhteinen tehtävä ammattimainintojen automaattisesta tunnistamisesta sosiaalisessa mediassa: järjestelmät, arviointi, ohjeet, upotukset ja korpuset', 'bs': 'ProfNER je podijelio zadatak o automatskom priznanju okupacije spominjanih u društvenim medijima: sustavi, procjena, uputstva, ugrađenja i korpora', 'jv': 'User:', 'ha': 'The profNER na share aikin bayani na gane sunan aiki farat ɗaya a cikin mitandan jamii: system, evaluation, guidelin, embedded and firma', 'sk': 'ProfNER si je delil nalogo avtomatičnega prepoznavanja omenjenih poklicev v družbenih omrežjih: sistemi, vrednotenje, smernice, vdelave in korpusi', 'he': 'המשימה המשותפת של פרופניר על זיהוי אוטומטי של זיכרונות מקצועים בתקשורת חברתית', 'bo': 'ProfNER ཡིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནང་གི་ཁོང་གིས་གནས་ཚུལ་གྱིས་རང་འགུལ་གྱིས་ཤེས་ཀྱི་ལས་འགན་གཅིག་མཐུན་བཟོ་བ་ཡིན། མ'}
{'en': 'Detection of occupations in texts is relevant for a range of important application scenarios, like  competitive intelligence , sociodemographic analysis, legal NLP or health-related occupational data mining. Despite the importance and heterogeneous data types that mention  occupations ,  text mining  efforts to recognize them have been limited. This is due to the lack of clear annotation guidelines and high-quality Gold Standard corpora. Social media data can be regarded as a relevant source of information for real-time monitoring of at-risk occupational groups in the context of  pandemics  like the COVID-19 one, facilitating intervention strategies for occupations in direct contact with infectious agents or affected by mental health issues. To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in  Spanish  and  English , an occupation gazetteer, a machine-translated version of  tweets , and FastText embeddings. Out of 35 registered teams, 11 submitted a total of 27 runs. Best-performing participants built  systems  based on recent  NLP technologies  (e.g. transformers) and achieved 0.93  F-score  in Text Classification and 0.839 in  Named Entity Recognition . Corpus : https://doi.org/10.5281/zenodo.4309356', 'fr': "La détection des professions dans les textes est pertinente pour une série de scénarios d'application importants, tels que la veille concurrentielle, l'analyse sociodémographique, la PNL juridique ou l'exploration de données professionnelles liées à la santé. Malgré l'importance et les types de données hétérogènes qui mentionnent des professions, les efforts d'exploration de texte pour les reconnaître ont été limités. Cela est dû à l'absence de directives d'annotation claires et de corpus Gold Standard de haute qualité. Les données des réseaux sociaux peuvent être considérées comme une source d'information pertinente pour le suivi en temps réel des groupes professionnels à risque dans le contexte de pandémies comme celle de la COVID-19, facilitant les stratégies d'intervention pour les professions en contact direct avec des agents infectieux ou touchées par des problèmes de santé mentale. Pour évaluer les méthodes actuelles de PNL et générer des ressources, nous avons organisé la piste ProFner au SMM4H 2021, fournissant aux participants ProFner un corpus Gold Standard de tweets annotés manuellement (IAA humain de 0,919) suivant les directives d'annotation disponibles en espagnol et en anglais, un version traduite automatiquement des tweets et intégration FastText. Sur 35 équipes inscrites, 11 ont soumis un total de 27 descentes. Les participants les plus performants ont construit des systèmes basés sur des technologies NLP récentes (par exemple des transformateurs) et ont obtenu un score F de 0,93 pour la classification de texte et 0,839 pour la reconnaissance d'entités nommées. Corpus\xa0: https://doi.org/10.5281/zenodo.4309356", 'ar': 'يعد اكتشاف المهن في النصوص وثيق الصلة بمجموعة من سيناريوهات التطبيق المهمة ، مثل الذكاء التنافسي ، والتحليل الاجتماعي الديموغرافي ، ومعالجة اللغات الطبيعية القانونية أو التنقيب عن البيانات المهنية المتعلقة بالصحة. على الرغم من أهمية أنواع البيانات غير المتجانسة التي تشير إلى المهن ، إلا أن جهود التنقيب عن النصوص للتعرف عليها كانت محدودة. ويرجع ذلك إلى عدم وجود إرشادات واضحة للتعليقات التوضيحية وجودة عالية الجودة للمعايير الذهبية. يمكن اعتبار بيانات وسائل التواصل الاجتماعي مصدرًا ذا صلة للمعلومات للرصد في الوقت الفعلي للمجموعات المهنية المعرضة للخطر في سياق الأوبئة مثل COVID-19 ، مما يسهل استراتيجيات التدخل للمهن التي تتلامس مباشرة مع العوامل المعدية أو المتأثرة بالعقلية. مشاكل صحية. لتقييم أساليب البرمجة اللغوية العصبية الحالية ولتوليد الموارد ، قمنا بتنظيم مسار ProfNER في SMM4H 2021 ، لتزويد المشاركين في ProfNER بمجموعة قياسية ذهبية من التغريدات المشروحة يدويًا (IAA البشري 0.919) باتباع إرشادات التعليقات التوضيحية المتوفرة باللغتين الإسبانية والإنجليزية ، معجم مهنة ، نسخة مترجمة آليًا من التغريدات ، وحفلات الزفاف بالنص السريع. من بين 35 فريقًا مسجلاً ، قدم 11 فريقًا إجمالي 27 جولة. قام المشاركون الأفضل أداءً ببناء أنظمة تعتمد على تقنيات البرمجة اللغوية العصبية الحديثة (مثل المحولات) وحققوا 0.93 درجة F في تصنيف النص و 0.839 في التعرف على الكيانات المسماة. كوربوس: https://doi.org/10.5281/zenodo.4309356', 'es': 'La detección de ocupaciones en los textos es relevante para una serie de escenarios de aplicación importantes, como la inteligencia competitiva, el análisis sociodemográfico, la PNL legal o la minería de datos ocupacionales relacionados con la salud. A pesar de la importancia y los tipos de datos heterogéneos que mencionan las ocupaciones, los esfuerzos de extracción de textos para reconocerlas han sido limitados. Esto se debe a la falta de pautas de anotación claras y de corpus Gold Standard de alta calidad. Los datos de las redes sociales pueden considerarse una fuente de información relevante para el monitoreo en tiempo real de los grupos ocupacionales en riesgo en el contexto de pandemias como la de COVID-19, lo que facilita las estrategias de intervención para ocupaciones en contacto directo con agentes infecciosos o afectadas por problemas de salud mental. Para evaluar los métodos actuales de PNL y generar recursos, hemos organizado la pista ProFner en SMM4H 2021, proporcionando a los participantes de ProFner un corpus Gold Standard de tuits anotados manualmente (IAA humano de 0,919) siguiendo las pautas de anotación disponibles en español e inglés, un nomenclátor de ocupación, un versión traducida automáticamente de tuits e incrustaciones de FastText. De 35 equipos registrados, 11 presentaron un total de 27 carreras. Los participantes con mejor desempeño construyeron sistemas basados en tecnologías recientes de PNL (por ejemplo, transformadores) y obtuvieron una puntuación F de 0.93 en la clasificación de textos y 0.839 en el reconocimiento de entidades nombradas. Corpus: https://doi.org/10.5281/zenodo.4309356', 'pt': 'A detecção de ocupações em textos é relevante para uma série de cenários de aplicação importantes, como inteligência competitiva, análise sociodemográfica, PNL legal ou mineração de dados ocupacionais relacionados à saúde. Apesar da importância e dos tipos de dados heterogêneos que mencionam ocupações, os esforços de mineração de texto para reconhecê-los têm sido limitados. Isso se deve à falta de diretrizes de anotação claras e corpora Gold Standard de alta qualidade. Os dados das redes sociais podem ser considerados como uma fonte de informação relevante para o acompanhamento em tempo real de grupos profissionais de risco no contexto de pandemias como a COVID-19, facilitando estratégias de intervenção para ocupações em contacto direto com agentes infecciosos ou afetadas por doenças mentais. problemas de saúde. Para avaliar os métodos atuais de PNL e gerar recursos, organizamos a trilha ProfNER no SMM4H 2021, fornecendo aos participantes do ProfNER um corpus Gold Standard de tweets anotados manualmente (IAA humano de 0,919) seguindo diretrizes de anotação disponíveis em espanhol e inglês, um diário de ocupação , uma versão traduzida por máquina de tweets e embeddings FastText. Das 35 equipes inscritas, 11 enviaram um total de 27 corridas. Os participantes com melhor desempenho construíram sistemas baseados em tecnologias PNL recentes (por exemplo, transformadores) e alcançaram 0,93 F-score em Classificação de texto e 0,839 em Reconhecimento de entidade nomeada. Corpus: https://doi.org/10.5281/zenodo.4309356', 'hi': 'ग्रंथों में व्यवसायों का पता लगाना प्रतिस्पर्धी खुफिया, सामाजिक-सामाजिक विश्लेषण, कानूनी एनएलपी या स्वास्थ्य से संबंधित व्यावसायिक डेटा खनन जैसे महत्वपूर्ण अनुप्रयोग परिदृश्यों की एक श्रृंखला के लिए प्रासंगिक है। महत्व और विषम डेटा प्रकारों के बावजूद जो व्यवसायों का उल्लेख करते हैं, उन्हें पहचानने के लिए पाठ खनन प्रयास सीमित हैं। यह स्पष्ट एनोटेशन दिशानिर्देशों और उच्च गुणवत्ता वाले गोल्ड स्टैंडर्ड कॉर्पोरेट की कमी के कारण है। सोशल मीडिया डेटा को कोविड -19 जैसी महामारियों के संदर्भ में जोखिम वाले व्यावसायिक समूहों की वास्तविक समय की निगरानी के लिए जानकारी के एक प्रासंगिक स्रोत के रूप में माना जा सकता है, जो संक्रामक एजेंटों के साथ सीधे संपर्क में या मानसिक स्वास्थ्य के मुद्दों से प्रभावित व्यवसायों के लिए हस्तक्षेप रणनीतियों की सुविधा प्रदान करता है। वर्तमान एनएलपी विधियों का मूल्यांकन करने और संसाधनों को उत्पन्न करने के लिए, हमने SMM4H 2021 में ProfNER ट्रैक का आयोजन किया है, जो ProfNER प्रतिभागियों को मैन्युअल रूप से एनोटेटेड ट्वीट्स (0.919 का मानव IAA) के गोल्ड स्टैंडर्ड कॉर्पस के साथ प्रदान करता है, स्पेनिश और अंग्रेजी में उपलब्ध एनोटेशन दिशानिर्देशों का पालन करता है, एक व्यवसाय गजेटियर, ट्वीट्स का एक मशीन-अनुवादित संस्करण, और FastText एम्बेडिंग। 35 पंजीकृत टीमों में से, 11 ने कुल 27 रन प्रस्तुत किए। सर्वश्रेष्ठ प्रदर्शन करने वाले प्रतिभागियों ने हाल ही में एनएलपी प्रौद्योगिकियों (जैसे ट्रांसफॉर्मर) के आधार पर सिस्टम का निर्माण किया और पाठ वर्गीकरण में 0.93 एफ-स्कोर और नामित इकाई मान्यता में 0.839 प्राप्त किया। कॉर्पस: https://doi.org/10.5281/zenodo.4309356', 'ja': 'テキスト内の職業の検出は、競合情報、社会人口学的分析、法的NLP、または健康に関連する職業データのマイニングなど、さまざまな重要なアプリケーションシナリオに関連しています。 職業に言及する重要性と異種データタイプにもかかわらず、それらを認識するためのテキストマイニングの努力は限られています。 これは、明確な注釈ガイドラインと高品質のゴールドスタンダードのコーラが欠如しているためです。 ソーシャルメディアデータは、COVID -19のようなパンデミックの文脈でリスクのある職業グループをリアルタイムで監視するための関連情報源と見なすことができ、感染性因子に直接接触する職業または精神的健康問題の影響を受ける職業に対する介入戦略を促進します。 現在のNLP方法を評価し、リソースを生成するために、SMM 4 H 2021でProfNERトラックを整理し、スペイン語と英語で利用可能な注釈ガイドライン、職業地名集、機械翻訳版のツイート、およびFastText埋め込みに従って、手動で注釈を付けたツイートのゴールドスタンダードのコーパス（人間のIAAは0.919 ）をProfNER参加者に提供しました。 登録された35チームのうち、11チームが計27回の出走を提出した。 最高のパフォーマンスを発揮する参加者は、最近のNLPテクノロジー（変圧器など）に基づいてシステムを構築し、テキスト分類で0.93 Fスコア、名前付きエンティティ認識で0.839 Fスコアを達成しました。コーパス： https://doi.org/10.5281/zenodo.4309356', 'zh': '文业之检,系于要场,如竞情报,世人统计分析,法NLP康强之业数据挖掘。 虽言职之要异构数据类型,而文本掘知之力有限。 此乏明注指南、高质量黄金准语料库也。 社交媒体数可以为COVID-19大行背景下实时监测高危业群息所由来,为直接传染性病原体心理健康之业以干策。 质NLP以成资,结ProfNER分会场于SMM4H 2021,为ProfNER参与者给之手动注推文黄金之准语料库(人IAA为0.919),循西班牙语、英语之指南,业地名词典,推文之机器翻译版本、FastText嵌。 在35个注册团队中,有11个团队共提交了27次行。 至参与者基于近NLP之术(如变压器)构统,而分文本为0.93 F,名实为0.839。 语料库: https://doi.org/10.5281/zenodo.4309356', 'ru': 'Обнаружение профессий в текстах актуально для целого ряда важных сценариев применения, таких как конкурентный интеллект, социально-демографический анализ, юридический NLP или анализ профессиональных данных, связанных со здоровьем. Несмотря на важность и разнородность типов данных, в которых упоминаются профессии, усилия по их распознаванию в области разработки текстов были ограниченными. Это связано с отсутствием четких инструкций по аннотированию и высококачественных корпусов Gold Standard. Данные социальных сетей можно рассматривать как актуальный источник информации для мониторинга в режиме реального времени профессиональных групп риска в контексте пандемий, таких как COVID-19, способствуя стратегиям вмешательства для профессий, находящихся в прямом контакте с инфекционными агентами или затронутых проблемами психического здоровья. Чтобы оценить текущие методы NLP и генерировать ресурсы, мы организовали дорожку ProfNER на SMM4H 2021, предоставив участникам ProfNER корпус золотого стандарта с ручными аннотациями твитов (человеческий IAA 0,919) в соответствии с руководящими принципами аннотаций, доступными на испанском и английском языках, справочником географических названий профессий, машинопереведенной версией твитов и вложениями FastText. Из 35 зарегистрированных команд 11 представили в общей сложности 27 заездов. Лучшие участники создали системы, основанные на последних технологиях NLP (например, трансформаторы) и достигли 0,93 F-балла в классификации текста и 0,839 в распознавании именованных сущностей. Корпус: https://doi.org/10.5281/zenodo.4309356', 'ga': 'Tá braite gairmeacha i dtéacsanna ábhartha do raon cásanna feidhmithe tábhachtacha, amhail faisnéis iomaíoch, anailís shochdhéimeagrafach, NLP dlíthiúil nó mianadóireacht sonraí ceirde a bhaineann le sláinte. In ainneoin na tábhachta agus na cineálacha sonraí ilchineálacha a luann gairmeacha, tá iarrachtaí mianadóireachta téacs teoranta chun iad a aithint. Is é is cúis leis seo ná easpa treoirlínte soiléire anótála agus corpora ardchaighdeáin an Chaighdeáin Óir. Is féidir breathnú ar shonraí na meán sóisialta mar fhoinse ábhartha faisnéise chun faireachán fíor-ama a dhéanamh ar ghrúpaí ceirde atá i mbaol i gcomhthéacs paindéimí cosúil leis an gceann COVID-19, lena n-éascaítear straitéisí idirghabhála do ghairmeacha a bhíonn i dteagmháil dhíreach le gníomhairí ionfhabhtaíocha nó a mbíonn tionchar ag meabhair orthu. saincheisteanna sláinte. Chun modhanna reatha NLP a mheas agus chun acmhainní a ghiniúint, tá rian ProfNER eagraithe againn ag SMM4H 2021, ag soláthar Corpas Caighdeánach Óir de thvuíteanna anótáilte de láimh (IAA daonna de 0.919) do rannpháirtithe ProfNER ag leanúint treoirlínte anótála atá ar fáil i Spáinnis agus i mBéarla, gazetteer gairm bheatha. , leagan meaisín-aistrithe de thíteanna, agus leabaithe FastText. As 35 fhoireann chláraithe, chuir 11 isteach 27 rith san iomlán. Thóg na rannpháirtithe is fearr feidhmíochta córais bunaithe ar theicneolaíochtaí NLP le déanaí (m.sh. claochladáin) agus bhain siad amach 0.93 scór F in Aicmiú Téacs agus 0.839 in Aithint Aonáin Ainmnithe. Corpas: https://doi.org/10.5281/zenodo.4309356', 'el': 'Η ανίχνευση επαγγελμάτων σε κείμενα είναι σχετική για μια σειρά σημαντικών σεναρίων εφαρμογής, όπως η ανταγωνιστική νοημοσύνη, η κοινωνικοοικονομική ανάλυση, η νομική ΝΛΠ ή η εξόρυξη επαγγελματικών δεδομένων που σχετίζονται με την υγεία. Παρά τη σημασία και τους ετερογενείς τύπους δεδομένων που αναφέρουν επαγγέλματα, οι προσπάθειες εξόρυξης κειμένου για την αναγνώριση τους έχουν περιοριστεί. Αυτό οφείλεται στην έλλειψη σαφών κατευθυντήριων γραμμών σχολιασμού και υψηλής ποιότητας Corpora Gold Standard. Τα δεδομένα των μέσων κοινωνικής δικτύωσης μπορούν να θεωρηθούν ως μια σχετική πηγή πληροφοριών για την παρακολούθηση σε πραγματικό χρόνο επαγγελματικών ομάδων που κινδυνεύουν στο πλαίσιο πανδημιών όπως αυτή του διευκολύνοντας στρατηγικές παρέμβασης για επαγγέλματα που βρίσκονται σε άμεση επαφή με μολυσματικούς παράγοντες ή επηρεάζονται από ζητήματα ψυχικής υγείας. Για να αξιολογήσουμε τις τρέχουσες μεθόδους και να δημιουργήσουμε πόρους, έχουμε οργανώσει το κομμάτι στο SMM4H 2021, παρέχοντας στους συμμετέχοντες του ένα χρυσό πρότυπο σώμα χειροκίνητα σχολιασμένων tweets (ανθρώπινο IAA 0.919) σύμφωνα με τις οδηγίες σχολιασμού που είναι διαθέσιμες στα ισπανικά και αγγλικά, ένα ενημερωτικό δελτίο επαγγέλματος, μια μηχανομεταφρασμένη έκδοση tweets και ενσωματώσεις FastText. Από τις 35 εγγεγραμμένες ομάδες, 11 κατέθεσε συνολικά 27 γύρους. Οι καλύτεροι συμμετέχοντες κατασκεύασαν συστήματα βασισμένα σε πρόσφατες τεχνολογίες (π.χ. μετασχηματιστές) και πέτυχαν 0.93 βαθμολογία στην ταξινόμηση κειμένου και 0.839 στην αναγνώριση ονομαστικής οντότητας. Σώμα: https://doi.org/10.5281/zenodo.4309356', 'hu': 'A foglalkozások felismerése szövegekben számos fontos alkalmazási forgatókönyv szempontjából releváns, mint például a versenyintelligencia, a szocidemográfiai elemzés, a jogi NLP vagy az egészségügyi adatbányászat. Annak ellenére, hogy fontos és heterogén adattípusok említik a foglalkozásokat, a szövegbányászati erőfeszítések azok felismerésére korlátozottak voltak. Ez annak köszönhető, hogy nincs egyértelmű jegyzetelési irányelv és kiváló minőségű Gold Standard corpora. A közösségi média adatai releváns információforrásnak tekinthetők a kockázatnak kitett foglalkozási csoportok valós idejű nyomon követéséhez olyan járványok összefüggésében, mint a COVID-19, és megkönnyítik az intervenciós stratégiákat a fertőző kórokozókkal közvetlenül érintkező vagy mentális egészségügyi problémák által érintett foglalkozások esetében. A jelenlegi NLP-módszerek értékelése és erőforrások generálása érdekében megszerveztük a ProfNER pályát az SMM4H 2021-en, amely a ProfNER résztvevőinek Gold Standard korpuszt biztosít manuálisan jegyzetelt tweetekből (humán IAA 0,919), a spanyol és angol nyelven elérhető jegyzetelési irányelveket követve, a foglalkozási lapot, a tweetek géppel lefordított változatát és a FastText beágyazásokat. A 35 regisztrált csapat közül 11 nyújtott be összesen 27 futást. A legjobb teljesítményű résztvevők a legújabb NLP technológiák (pl. transzformátorok) alapján építettek rendszereket, és 0,93 F pontszámot értek el a szövegosztályozásban és 0,839 a Nevezett entitások felismerésében. Corpus: https://doi.org/10.5281/zenodo.4309356', 'ka': 'ტექსტის კომპუციაციების განსახულება მნიშვნელოვანი პროგრამების სენარიოსთვის, როგორც კომპუცირებული ინტელექცია, სოციოდემოგრაფიური ანალიზი, ლექციური NLP ან სოციონალურ მნიშვნელოვანი და ჰეტეროგენური მონაცემების ტიპებისთვის, რომლებიც ამბობენ კოკუმენტები, ტექსტის მინიღების ძალადობა, რომლებიც მათ განაცნობას,  ეს იქნება წარმოდგენელი მონიშნულების მიზეზი და უფრო კარგად დოლანე სტანდარტური კოპორაზე. სოციალური მედიაში მონაცემები შეიძლება იყოს შესახებ ინფორმაციის შესახებ რეალური დროის მონაცემებისთვის პროცემების კონტექსტში, როგორც COVID-19 ერთი, რომელიც ინტერფენციის სტრატიგიები კონტაქციებისთვის პირადი კო მიმდინარე NLP მეტოვები და რესურსების შექმნა, ჩვენ SMM4H 2021-ში პროფენერების ტრაკუსს დავყენეთ, პროფენერების გარეშე სტანდარტური კორპუსს, რომელიც პროფენერების გარეშე სტანდარტურული ტვიტები (0.919-ის ადამიანის IAA) სპონუალურ და ინგლისური წეგნის შემდეგ, კო 35 რეგისტრირებული ჯგუფიდან, 11 წლის 27 წლის შესახებ. საუკეთესო მომხმარებელი მომხმარებელი შექმნა სისტემი, რომელიც NLP ტექნოლოგიების (მაგალითად ტრანფორმეტრებით) დაბაზიან და 0.93 F-score ტექსტის კლასიფიკაციაში და 0.839-ს სახელი ინტერტი კოპუს: https://doi.org/10.5281/zenodo.4309356', 'it': "La rilevazione delle professioni nei testi è rilevante per una serie di importanti scenari applicativi, come l'intelligenza competitiva, l'analisi sociodemografica, la PNL legale o l'estrazione di dati professionali correlati alla salute. Nonostante l'importanza e i tipi di dati eterogenei che menzionano le occupazioni, gli sforzi di text mining per riconoscerle sono stati limitati. Ciò è dovuto alla mancanza di chiare linee guida di annotazione e corpora Gold Standard di alta qualità. I dati sui social media possono essere considerati una fonte di informazione rilevante per il monitoraggio in tempo reale dei gruppi professionali a rischio nel contesto di pandemie come quella COVID-19, facilitando strategie di intervento per le professioni a contatto diretto con agenti infettivi o colpite da problemi di salute mentale. Per valutare gli attuali metodi NLP e generare risorse, abbiamo organizzato la traccia ProfNER a SMM4H 2021, fornendo ai partecipanti ProfNER un corpus Gold Standard di tweet annotati manualmente (IAA umano di 0,919) seguendo le linee guida di annotazione disponibili in spagnolo e inglese, un gazetter di occupazione, una versione tradotta automaticamente dei tweet e incorporazioni FastText. Su 35 squadre iscritte, 11 hanno presentato un totale di 27 gare. I partecipanti con le migliori prestazioni hanno costruito sistemi basati sulle recenti tecnologie NLP (ad esempio trasformatori) e hanno ottenuto un punteggio F di 0,93 nella classificazione testuale e 0,839 nel riconoscimento delle entità nominate. Corpus: https://doi.org/10.5281/zenodo.4309356", 'kk': 'Мәтіндерде жұмыс істеуді анықтау үшін бірнеше маңызды қолданбаның сценариясына, мысалы, конкурсивті интеллекті, социодографиялық анализ, жариялық NLP не саулық жұмыс деректерді балау үшін әсер ете Мәтіндіктерді түсіну үшін маңызды және гетероген деректер түрлері шектелген. Бұл таңдау бағыттамаларының жоғары мен сапатты алтын стандартты корпорасының жоғары жоғарының себебі. Америкалық медиа деректері COVID-19 секілді пандемиялық тәжірибелі топтарды шын уақытта қамтамасыз топтарды бақылау үшін мәліметтің көзі ретінде қатынауға болады, сондай-ақ, инфекциялық агенттермен немесе психикалық саулық мәселе Қолданыстағы NLP әдістерін оқу және ресурстарды құру үшін, біз SMM4H 2021 жылы ProfNER жолын баптап, профенерлерді қолмен белгіленген тейтеттердің Gold Стандартты корпуса (0,919 адамдар IAA) арқылы испан және ағылшын тілінде қол жеткізетін белгілер бағыттауларын, механикалық жұмыс және Fas 35 жазылған топтардан 11 жалпы 27 орынды жіберді. Жуырдағы NLP технологияларына негізделген жүйелерді құру үшін ең жақсы қатысушылар (мысалы, түрлендірушілер) және аталған нысандарды анықтау үшін 0. 93 F- нәтижесін жеткізді. Корпус: https://doi.org/10.5281/zenodo.4309356', 'lt': 'Tekstinių profesijų nustatymas yra svarbus įvairiems svarbiems taikymo scenarijams, pavyzdžiui, konkurencinei žvalgybai, socialinei demografinei analizei, teisinei NLP arba su sveikatos apsauga susijusiems profesiniams duomenims kasyti. Nepaisant svarbos ir įvairiapusių duomenų tipų, kuriuose minimos profesijos, tekstų kasybos pastangos juos pripažinti buvo ribotos. Tai yra dėl to, kad nėra aiškių anotacijų gairių ir aukštos kokybės aukso standarto korpora. Social in ės žiniasklaidos duomenys gali būti laikomi svarbiu informacijos šaltiniu, skirtu pavojingoms profesinėms grupėms realiuoju laiku stebėti tokiomis pandemijomis kaip COVID-19, palengvinant intervencines strategijas profesijoms, tiesiogiai susiduriančioms su infekciniais veiksniais arba paveiktoms psichikos sveikatos klausimais. Siekdami įvertinti dabartinius NLP metodus ir kurti išteklius, organizavome ProfNER maršrutą SMM4H 2021 m., pateikdami ProfNER dalyviams rankiniu būdu anotuotų tweetų (žmogiškojo IAA 0,919) aukso standartinį korpusą, vadovaudamiesi Ispanijos ir anglų kalbomis pateiktomis anotacijos gairėmis, profesiniu laikraščiu, automatiškai išversta tweetų versija ir FastText įterpimais. Iš 35 registruotų komandų 11 iš viso pateikė 27 runs. Geriausiai veikiantys dalyviai sukūrė sistemas, pagrįstas naujausiomis NLP technologijomis (pvz., transformatoriais) ir pasiekė 0,93 F balas teksto klasifikacijoje ir 0,839 vardinio subjekto pripažinime. Korpus: https://doi.org/10.5281/zenodo.4309356', 'ml': 'ടെക്സ്റ്റിലുള്ള ജോലികള്\u200d കണ്ടുപിടിക്കുന്നത് പ്രധാനപ്പെട്ട പ്രയോഗത്തിന്റെ വിഭാഗങ്ങള്\u200dക്ക് വേണ്ടി പ്രധാനപ്പെട്ട പ്രയോഗത്തിന്റെ വ പ്രധാനപ്പെട്ട വിവരങ്ങളുടെയും പ്രധാനപ്പെട്ട വിവരങ്ങളുടെയും തരത്തില്\u200d പ്രധാനപ്പെട്ടാലും അവയെ തിരിച്ചറിയ ഇത് വ്യക്തമായ വിവരങ്ങളും ഉയര്\u200dന്ന സ്വര്\u200dണ്ണത്തിലെ സ്റ്റാന്\u200dഡാര്\u200dഡ് കോര്\u200dപ്പോരിയുടെ കാരണമാണ്. സാമൂഹ്യ മീഡിയ വിവരങ്ങള്\u200d കോവിഡി-19 പോലുള്ള പാനഡമിക്കുകളുടെ പ്രധാനപ്പെട്ട വിവരങ്ങളുടെ ശരിക്കും സമയം നിരീക്ഷിക്കുന്നതിനുള്ള വിവരങ്ങളുടെ വിവരങ്ങളായി വിവരങ്ങളായി  To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in Spanish and English, an occupation gazetteer, a machine-translated version of tweets, and FastText embeddings.  35 രേഖപ്പെടുത്തിയ ടീമില്\u200d നിന്ന് 11 മൊത്തം 27 റൂണ്\u200d കൊടുത്തു. അടുത്ത NLP ടെക്നോളജികള്\u200d അടിസ്ഥാനമായി ഏറ്റവും മികച്ച പങ്കാളികള്\u200d നിര്\u200dമ്മിച്ചിരിക്കുന്നു കോര്\u200dപ്പസ്: https://doi.org/10.5281/zenodo.4309356', 'mt': 'Is-sejba ta’ impjiegi fit-testi hija rilevanti għal firxa ta’ xenarji importanti ta’ applikazzjoni, bħall-intelliġenza kompetittiva, l-analiżi soċjodemografika, il-NLP legali jew it-tħaffir ta’ dejta okkupazzjonali relatata mas-saħħa. Minkejja l-importanza u t-tipi ta’ dejta eteroġeniċi li jsemmu l-okkupazzjonijiet, l-isforzi tat-tħaffir tat-testi għall-għarfien tagħhom kienu limitati. Dan huwa minħabba n-nuqqas ta’ linji gwida ċari ta’ annotazzjoni u korpora Standard tad-Deheb ta’ kwalità għolja. Id-dejta tal-midja soċjali tista’ titqies bħala sors rilevanti ta’ informazzjoni għall-monitoraġġ f’ħin reali ta’ gruppi okkupazzjonali f’riskju fil-kuntest ta’ pandemiji bħall-COVID-19, li tiffaċilita strateġiji ta’ intervent għal okkupazzjonijiet f’kuntatt dirett ma’ a ġenti infettivi jew affettwati minn kwistjonijiet ta’ saħħa mentali. To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in Spanish and English, an occupation gazetteer, a machine-translated version of tweets, and FastText embeddings.  Minn 35 tim reġistrat, 11 ippreżentaw total ta’ 27 runs. Il-parteċipanti bl-aħjar prestazzjoni nbnew sistemi bbażati fuq teknoloġiji reċenti tal-NLP (pereżempju trasformaturi) u kisbu punteġġ F ta’ 0.93 fil-Klassifikazzjoni tat-Test u 0.839 fir-Rikonoxximent tal-Entità Ismija. Korpus: https://doi.org/10.5281/zenodo.4309356', 'mk': 'Детектирањето на окупациите во текстите е релевантно за голем број важни сценарија за апликација, како што се конкурентната интелигенција, социодемографска анализа, законска НЛП или минирање на докупционални податоци поврзани со здравството. И покрај важноста и хетерогенските видови на податоци кои споменуваат окупации, напорите за минирање текст за да ги препознае се ограничени. Ова е поради недостатокот на јасни насоки за анотација и висококвалитетни златни стандардни корпора. Податоците на социјалните медиуми може да се сметаат за релевантен извор на информации за мониторинг во реално време на опасни групи во контекст на пандемии како што е КоВИД-19, олеснувајќи ги интервенциските стратегии за опасностите во директен контакт со инфекционери или погодени од праш За да ги процениме актуелните методи на НЛП и да генерираме ресурси, ја организиравме трагата на Профинер на СММ4Х 2021 година, обезбедувајќи им на учесниците на Профинер златен стандарден корпус на рачно анотирани твитови (човечки ИАА од 0,919) по насоките за анотација достапни на шпански и англиски јазик, окупциски газетер, машинска верзија на твит Од 35 регистрирани тимови, 11 поднесоа вкупно 27 трки. Најдобрите учесници изградија системи базирани на неодамнешните технологии на НЛП (np. трансформатори) и постигнаа 0,93 Ф-оценка во текстовата класификација и 0,839 во препознавањето на именуваниот ентитет. Корпус: https://doi.org/10.5281/zenodo.4309356', 'ms': 'Pengesanan pekerjaan dalam teks adalah berkaitan untuk julat skenario aplikasi penting, seperti kecerdasan kompetitif, analisis sosiodemografik, NLP undang-undang atau perlombongan data pekerjaan berkaitan kesehatan. Despite the importance and heterogeneous data types that mention occupations, text mining efforts to recognize them have been limited.  Ini disebabkan kekurangan panduan anotasi yang jelas dan kualiti tinggi Gold Standard Corpra. Data media sosial boleh dianggap sebagai sumber maklumat yang relevan untuk pengawasan masa sebenar kumpulan pekerjaan dalam bahaya dalam konteks pandemi seperti COVID-19, memudahkan strategi intervensi untuk pekerjaan dalam hubungan langsung dengan agen jangkitan atau diserang oleh isu kesehatan mental. Untuk menilai kaedah NLP semasa dan untuk menghasilkan sumber, kami telah mengatur trek ProfNER di SMM4H 2021, menyediakan peserta ProfNER dengan korpus piawai emas tweet yang dicatat secara manual (IAA manusia 0.919) mengikut arahan anotasi yang tersedia dalam bahasa Sepanyol dan Inggeris, gazet pekerjaan, versi terjemahan mesin tweet, dan penyembedding FastText. Dari 35 pasukan terdaftar, 11 menghantar total 27 larian. Peserta berpengaruh terbaik membina sistem berdasarkan teknologi NLP yang baru-baru ini (contohnya pengubah) dan mencapai skor-F 0.93 dalam Klasifikasi Teks dan 0.839 dalam Pengenalan Entiti bernama. Corpus: https://doi.org/10.5281/zenodo.4309356', 'pl': 'Wykrywanie zawodów w tekstach jest istotne dla szeregu ważnych scenariuszy zastosowań, takich jak inteligencja konkurencyjna, analiza socjodemograficzna, prawna NLP czy eksploracja danych zawodowych związanych ze zdrowiem. Pomimo znaczenia i heterogenicznych typów danych, które wymieniają zawody, wysiłki eksploracji tekstu mające na celu ich rozpoznanie były ograniczone. Wynika to z braku jasnych wytycznych adnotacyjnych i wysokiej jakości korpusów Gold Standard. Dane mediów społecznościowych mogą być uznane za istotne źródło informacji do monitorowania w czasie rzeczywistym grup zawodowych zagrożonych w kontekście pandemii, takich jak COVID-19, ułatwiające strategie interwencyjne dla zawodów mających bezpośredni kontakt z czynnikami zakaźnymi lub dotkniętymi problemami zdrowia psychicznego. Aby ocenić obecne metody NLP i generować zasoby, zorganizowaliśmy ścieżkę ProfNER na SMM4H 2021, dostarczając uczestnikom ProfNER korpus ręcznie adnotacyjnych tweetów (ludzka IAA 0.919) zgodnie z wytycznymi adnotacyjnymi dostępnymi w języku hiszpańskim i angielskim, gazetter zawodowy, maszynowo tłumaczoną wersję tweetów oraz osadzenia FastText. Spośród 35 zarejestrowanych drużyn 11 zgłosiło łącznie 27 biegów. Najlepiej wydajni uczestnicy zbudowali systemy oparte na najnowszych technologiach NLP (np. transformatorach) i osiągnęli 0.93 F-score w klasyfikacji tekstu oraz 0.839 w rozpoznawaniu nazwanych podmiotów. Korpus: https://doi.org/10.5281/zenodo.4309356', 'no': 'Oppdaging av profesjonar i tekstar er relevant for eit rekkje av viktige program-scenarioar, som konkurenten intelligens, sosialodemografisk analyse, juridiske NLP eller helsetjende profesjonale data mining. Til tross viktigheten og heterogenere datatypar som mener oppgåver, har tekstminingsforsøk for å gjenkjenne dei begrenset. Dette er på grunn av mangelse av tydelige innmerkingslinjer og høg kvalitet gull standard korpora. Samfunnsmedia-data kan verta kalla til eit relevant kjelde for informasjon om sikkertidig overvåking av arbeidsgrupper som er på risiko i konteksten av pandemikk som COVID-19, som gjer tilgjengeleg intervensjonsstrategi for oppgåver i direkte kontakt med infeksjonsgrupper eller påvirka av psykiske helseproblemer. For å evaluera gjeldande NLP-metodar og for å laga ressursar, har vi organisert ProfNER-sporet på SMM4H 2021, og tilbyr ProfNER-deltakarar med ein Gold Standard Corpus av manuelt annotaterte tweets (menneske IAA av 0,919) etter hjelpelinjer for annotasjonar som er tilgjengelege på spansk og engelsk, ei okupacjonsgråder, ei maskin-omsett versjon av tweets og FastText-innbygging. Av 35 registrerte grupper sendte 11 totalt 27 køyr. Best e deltakarar bygde systemer basert på nyleg NLP-teknologiar (f.eks. transformatorar) og oppnådd 0,93 F-poeng i tekstklassifikasjon og 0,839 i namnet entitetskjenning. Korpus: https://doi.org/10.5281/zenodo.4309356', 'ro': 'Detectarea ocupațiilor în texte este relevantă pentru o serie de scenarii importante de aplicare, cum ar fi inteligența competitivă, analiza socio-demografică, PNL legal sau extragerea datelor profesionale legate de sănătate. În ciuda importanței și a tipurilor eterogene de date care menționează ocupații, eforturile de extragere a textului pentru a le recunoaște au fost limitate. Acest lucru se datorează lipsei unor orientări clare de adnotare și corpore Gold Standard de înaltă calitate. Datele rețelelor sociale pot fi considerate ca o sursă relevantă de informații pentru monitorizarea în timp real a grupurilor profesionale expuse riscului în contextul pandemiilor precum cea COVID-19, facilitând strategiile de intervenție pentru ocupațiile aflate în contact direct cu agenți infecțioși sau afectate de probleme de sănătate mintală. Pentru a evalua metodele actuale de PNL și pentru a genera resurse, am organizat pista ProfNER la SMM4H 2021, oferind participanților ProfNER un corpus Gold Standard de tweet adnotate manual (IAA umană de 0,919) în urma ghidurilor de adnotare disponibile în spaniolă și engleză, un ziar de ocupație, o versiune tradusă automată a tweet-urilor și încorporări FastText. Din 35 de echipe înregistrate, 11 au depus un total de 27 de runde. Participanții cu cele mai bune performanțe au construit sisteme bazate pe tehnologii recente NLP (de exemplu transformatoare) și au obținut 0,93 punctaj F în clasificarea textelor și 0,839 în recunoașterea entităților denumite. Corpus: https://doi.org/10.5281/zenodo.4309356', 'so': 'Dalbashada xirfadaha qoraalka waxaa muhiim ah in la xiriiro xaaladaha codsiga ee muhiimka ah, tusaale ahaan cilmiga iskaashatada, baaritaanka bulshada, shahaadada sharciga ah ee NLP ama koontaha danbiyada shaqaalaha ee la xiriira caafimaadka. Inta kastoo ay muhiim u tahay iyo noocyada macluumaadka la xiriira ee ku saabsan shaqada, waxaa la xadgudbay hawlaha qoraalka ee laga aqoonsado. Tan sababtoo ah baahida hagitaanka caddeysan iyo korporada guntiga ah ee dahabka ah. Macluumaadka bulshada ee bulshada waxaa looga tirin karaa macluumaad muhiim ah oo ku saabsan maamulka kooxaha halista ah ee shaqaalaha, sida COVID-19 oo kale, taas oo ku caawinaya qorshaha heshiiska shaqaalaha si toos ula xiriira dhakhaatiirta ama saameyn ku yeelata arimaha caafimaadka dhimirka. Si a an u qiimeyno awoodaha NLP ee joogtada ah iyo in aan maalgelino, waxaynu qabannay ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard Corpus oo manually annotated tweets (human IAA of 0.919), following hagooyinka annoannotation available luqada Ispanish iyo Ingiriis, kaas oo ah qoraal-xiriir, kaas oo ah qoraal-machine-translated tweets, iyo FastText embeddings. Waxaa ka mid ah 35 koox diiwaangeliyey 11 waxay soo dhiibeen dhamaan 27 jardiino. Shaqaalaha ugu wanaagsan ayaa dhisay nidaam ku saleysan Teknolojiyo-xirfadeedka NLP (tusaale ahaan transformations) wuxuuna helay 0.93 F-score oo ku qoran fasaxa qoraalka iyo 0.839 oo magaca Entity Recognition. Korpus: https://doi.org/10.5281/zenodo.4309356', 'sr': 'Otkrivanje okupacija u tekstima je važno za niz važnih scenarija aplikacije, poput konkurentne inteligencije, sociodemografske analize, pravne NLP-a ili rudarstva profesionalnih podataka vezane za zdravlje. Uprkos važnim i heterogenenim tipovima podataka koji spominju okupacije, napori na rudarstvo teksta za prepoznavanje njih su ograničeni. To je zbog nedostatka jasnih uputstva za annotaciju i visokokvalitetnog zlatnog standardnog korpora. Podaci o društvenim medijima mogu se smatrati relevantnim izvorom informacija za praćenje realnog vremena profesionalnih grupa u kontekstu pandemije kao što je COVID-19, olakšavajući strategije intervencije za okupacije u direktnom kontaktu sa infekcijskim agentima ili na probleme mentalnog zdravlja. Da bi procenili trenutne metode NLP i da bi stvorili resurse, organizovali smo trag ProfNER na SMM4H 2021, pružajući učesnike ProfNER sa zlatnim standardnom korpusom ručno annotiranih tweeta (ljudska IAA od 0,919) nakon uputstva za annotaciju dostupnih na španjolskom i engleskom jeziku, okupacijskom novinarima, kompanijskom verzijom tweeta i FastText ugrađenja. Od 35 registriranih timova 11 je podnio ukupno 27 trka. Najbolji učesnici izgradili su sisteme na temelju nedavnih tehnologija NLP-a (npr. transformatora) i postigli 0,93 F-rezultata u klasifikaciji teksta i 0,839 u priznanju imenovanih entiteta. Korpus: https://doi.org/10.5281/zenodo.4309356', 'si': 'පාළුවේ වැඩසටහන් හොයාගන්න වැඩසටහන් වැඩසටහන් වැඩසටහන් වැඩසටහන් වැඩසටහන් වැඩසටහන් වෙනුවෙන්, සාමාජික විශ්ලේෂණය, නීත ගොඩක් වැදගත් සහ හැම වැදගත් තොරතුරු වර්ගයක් තියෙනවා නමුත්, ඔවුන්ව අඳුරගන්න පැත්තක් ප්\u200dරයෝජනය සීමා මේක නිසා පැහැදිලි කිරීම් මාර්ගය සහ ගොල්ඩ් ස්ටැන්ඩර් කොර්පෝරා නැති විදියට. සාමාජික මාධ්\u200dයමාධ්\u200dයම දත්ත පුළුවන් හිතන්නේ ඇත්තකාලේ පරීක්ෂණය සඳහා සම්බන්ධ තොරතුරු සඳහා ඇත්තකාලේ පරීක්ෂණය සම්බන්ධ කණ්ඩායම් කණ්ඩායම්  To evalute the ongoing NLP ways and to nerate avatars, we have Organised the ProfessNER track at SMM4H 2021, preserving ProfessNER partipartipartipartipartipartipartipartipartipartints with a Gold standard Corpus of handly adverted tweets (Human IAA of 0.919) after anntion guilines Avail in Sphere and English, an Busation Gaztleer, a machine-translation Version of tweets, and FastText Embdings. ලියාස්තුරු කණ්ඩායම් 35 වලින්, 11 කුණු 27 කුණු සිටියා. හොඳම සම්පූර්ණ සම්පූර්ණයෙන් නිර්මාණය කරපු පද්ධතිය නිර්මාණය කරපු NLP තාක්ෂණය (උදාහරණයෙන්) සහ 0.93 F-score පද්ධතිය පද්ධතිය සහ 0. Corpus: https://doi.org/10.5281/zenodo.4309356', 'mn': 'Текст дээрх ажиллагааны тодорхойлолт нь өрсөлдөөний ухаан, социодомографик шинжилгээ, хуулийн НLP эсвэл эрүүл мэндийн хамааралтай ажиллагааны өгөгдлийн хөрөнгө оруулалт зэрэг олон чухал хэрэглээний хувилбарууды Хэрэв ажиллагааны тухай ярьж байгаа үнэ цэнэтэй, олон төрлийн мэдээллийн төрлүүд ч тэднийг хүлээн зөвшөөрөх текст хөрөнгө оруулах хичээл хязгаарлагддаг. Энэ нь тайлбарлах загварууд болон өндөр чанартай алтын стандарт корпора байхын тулд байдаг. Нийгмийн хэвлэлийн мэдээллийн мэдээллийг COVID-19 зэрэг эрсдэлтэй ажиллах бүлгүүдийн бодит цаг хугацаанд ажиллах боломжтой мэдээллийн эх үүсвэр гэж үзэж болно. Энэ нь халдвар авсан агентай эсвэл сэтгэл санааны эрүүл мэндийн асуудлын нөлөөлдөг ажиллах төлөвлөг Одоогийн NLP аргыг үнэлэхээр, нөөц бүтээмж үүсгэхийн тулд бид SMM4H 2021 онд ProfNER-ын загварыг зохион байгуулж, ProfNER-ын оролцогчдын алт стандарт корпус (0.919 хүн төрөлхтний IAA) хувилбаруудыг ашиглаж, Испан болон Англи хэлний хэлбэрээр ашиглах загварын дараа, ажиллах журнал, машин орчуул 35 бүртгэгдсэн багийнхаа нэгээс 11 бүртгэл 27 даалгавар өгсөн. Хамгийн шилдэг оролцогчид саяхан NLP технологи (жишээ нь шилжүүлэгчид) дээр суурилсан системүүд бүтээсэн бөгөөд нэрлэгдсэн Объект Recognition-д 0.93 F-score олсон. Үзэг: https://doi.org/10.5281/zenodo.4309356', 'sv': 'Upptäckt av yrken i texter är relevant för en rad viktiga applikationsscenarier, som konkurrensanalys, sociodemografisk analys, juridisk NLP eller hälsorelaterad yrkesdatautvinning. Trots betydelsen och heterogena datatyper som nämner yrken, har textmining ansträngningar för att känna igen dem varit begränsade. Detta beror på bristen på tydliga noteringsriktlinjer och högkvalitativa Gold Standard corpora. Sociala mediedata kan betraktas som en relevant informationskälla för realtidsövervakning av utsatta yrkesgrupper i samband med pandemier som COVID-19, vilket underlättar interventionsstrategier för yrken i direkt kontakt med smittämnen eller som påverkas av psykiska hälsoproblem. För att utvärdera nuvarande NLP-metoder och generera resurser har vi organiserat ProfNER-spåret på SMM4H 2021, vilket ger ProfNER-deltagare en Gold Standard-korpus med manuellt kommenterade tweets (mänsklig IAA på 0,919) enligt kommenteringsriktlinjer tillgängliga på spanska och engelska, en sysselsättningsguide, en maskinöversatt version av tweets och FastText-inbäddningar. Av 35 anmälda lag skickade 11 in totalt 27 löpningar. De mest presterande deltagarna byggde system baserade på den senaste NLP-tekniken (t.ex. transformatorer) och uppnådde 0,93 F-poäng i textklassificering och 0,839 i Named Entity Recognition. Corpus: https://doi.org/10.5281/zenodo.4309356', 'ta': 'உரைகளில் உள்ள பணிகளை கண்டுபிடிப்பது முக்கியமான பயன்பாட்டு காட்சிகளுக்கு முக்கியமானது, போராடியான புத்தகம், சமோடியோமோகிராபிக் ஆய்வு, சட்டம் N வேலைகளை குறிப்பிடும் முக்கியம் மற்றும் அடர்த்திய தரவு வகைகள் போன்றாலும், அறிந்து கொள்ள உரை சிறு முயற்சி எல்லா This is due to the lack of clear annotation guidelines and high-quality Gold Standard corpora.  COVID-19 போன்ற துன்பாக்கியங்களின் பிரச்சனைகளின் மூலம் உண்மையான நேரம் தேடும் குழுக்களுக்கு தகவல் மூலமாக கருதப்படும் சமூக ஊடகங்கள் தகவல்கள் என்பது COVID-19 போன்ற தொழில்நேரம் கண் தற்போதைய NLP முறைகளை evaluation and to generate resources, நாங்கள் SMM4H 2021 ல் ப்ரொப்னெர் தடத்தை அமைத்துள்ளோம், பிரொப்னெர் பங்காரர்களுக்கு கைமுறையாக வெளிப்படுத்தப்பட்ட செய்திகளுடன் கொடுத்துள்ள தங்க நிலைமையான கார்ப்புகள் (0. 919 யில் மனி 35 பதிவு செய்யப்பட்ட குழுக்களில் 11 மொத்தமான 27 ஓட்டுகள் கூட்டினார். சமீபத்தில் NLP தொழில்நுட்பத்தை அடிப்படையாக சிறந்த செயல்படுத்துபவர்கள் அமைப்புகளை உருவாக்கி உரை வகைப்பாட்டில் 0. 93 F- மதிப்பு பெற்று பெயரிடப்பட்ட செயல் கார்புஸ்: https://doi.org/10.5281/zenodo.4309356', 'ur': 'پیغام میں کاروبار کا تلاش کرنا بہت اہم کاروبار سیناریوں کے لئے اہم ہے، جیسے رقابت انگلیسی، سوسیوڈ موگرافیک تحلیل، قانونی NLP یا سلامتی رابطہ دار کاروبار ڈیٹ منینگ. اہل اور غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر اہل و غیر یہ صریح یادآوری راہنمائی اور بالکل گولڈ استاندارڈ کرپورا کی ناکامی کے سبب ہے. سوسیلی میڈیا ڈیٹا کو سی کوویڈ-19 کی سی موضوع میں ریسک کارسازی گروپ کی حقیقی زمان کی مواظب کرنے کے لئے معلومات کا مواظب بنا کر سمجھ سکتا ہے، اس طرح مصنوعی اگنٹوں کے مسئلہ میں سفارشی استراتژی کے لئے سفارشی کرتا ہے یا ذهنی سلامتی مسئلہ کے ذری اس لئے ہم نے موجود NLP طریقے کا ارزش کرنا اور منابع پیدا کرنے کے لئے SMM4H 2021 میں پروفنر ٹراک کا سازمان کیا ہے، پروفنر کے حضور ایک گولڈ استاندارڈ کورپوس (0.919 کے انسان IAA) کے مطابق اسپانیایی اور انگلیسی میں موجود نوٹ ہدایت لینڈ کے پیچھے، ایک مشغول گریزٹر، ایک ماشین ترجمہ ٹویٹ کی نسخہ اور FastText ایمبڈینگ 35 راجستر ٹیموں میں سے 11 جمع 27 رونڈ کے ساتھ ملا گئے۔ بہترین عمل کرنے والے شرکت کرنے والے نے اچھی NLP ٹیکنالوجی (جیسے تبدیل کرنے والے) پر بنیاد رکھی اور 0.93 F-score کو پاکستان کلاسیفی میں پہنچایا اور 0.839 نام کی اینٹیٹی شناخت میں پہنچایا۔ Corpus: https://doi.org/10.5281/zenodo.4309356', 'uz': "Matnlarning vazifalarini aniqlash muhim dastur scenarioslari uchun juda muhim muhim. Masalan juda qiziqarli intellekt, jamodografik analyzeri, sharciga NLP yoki tibbiy bog'liq taʼminlovchi taʼminotlar qiymatiga ega. Vazifalar tajribalarini tahrirlash uchun muhim va katta maʼlumot turlari bo'lsa, ularni aniqlash uchun matn mining jarayonlari chegara. Bu shaxsiy taʼminot qoidalari va juda katta qiymati Gold Standard kompaniyasi yoʻq sababi. Name Name 35 yozib olingan guruhdan 11 bir necha 27 ishlab chiqaradi. Name Korpus: https://doi.org/10.5281/zenodo.4309356", 'vi': 'Việc phát hiện các việc làm trong văn bản là liên quan đến một loạt các tình huống áp dụng quan trọng, như tình báo cạnh tranh, phân tích xã hội phân tích xã hội, lập pháp Nhất. Mặc cho tầm quan trọng và các loại dữ liệu khác nhau đề cập đến các công việc, các nỗ lực khai thác văn bản đã bị hạn chế. Do thiếu hướng dẫn ghi chú rõ ràng và hạ sĩ chuẩn Vàng chất lượng cao. Dữ liệu phương tiện truyền thông xã hội có thể được coi là nguồn thông tin liên quan cho việc giám sát thời gian thực của những nhóm công nghiệp đang gặp nguy hiểm trong trường hợp có đại dịch như COVID-19, giúp đỡ chiến lược can thiệp vào các loại việc tiếp xúc trực tiếp với các đặc vụ truyền nhiễm hay bị ảnh hưởng bởi các vấn đề sức khỏe thần kinh. Để đánh giá phương pháp Njala hiện thời và để tạo nguồn tài nguyên, chúng tôi đã tổ chức một đội điền kinh ProfNER tại SMM44H 2021, cung cấp cho những người tham dự dự dự dự chương Gold Standards của những dòng tweet tự ghi chú (IAA man of 0.919) theo hướng dẫn ghi chú có sẵn ở Tây Ban Nha và Anh, một người quan công việc, một phiên bản dịch cổ máy của tweet, và tổ chức Cắm Văn bản. Bên ngoài 35, nhóm đã được đăng ký, 11 đã nộp một số mạng gần 202. Những diễn viên có trình độ cao nhất đã xây dựng hệ thống dựa trên các công nghệ gLP (v. d. chuyển hóa) và hoàn thành 0.93 F- ghi điểm trong Hạng Văn bản và 0.839 in Named Entity recognition. Xác. https://doi.org/10.5281/zenodo.4309356', 'bg': 'Откриването на професии в текстове е от значение за редица важни сценарии на приложение, като конкурентно разузнаване, социологичен анализ, правно НЛП или извличане на данни, свързани със здравето. Въпреки важността и хетерогенните типове данни, които споменават професиите, усилията за извличане на текстове за тяхното разпознаване са ограничени. Това се дължи на липсата на ясни указания за анотация и висококачествени корпуси от Златен стандарт. Данните в социалните медии могат да се разглеждат като уместен източник на информация за мониторинг в реално време на рискови професионални групи в контекста на пандемии като тази, улеснявайки стратегиите за интервенция за професии в пряк контакт с инфекциозни агенти или засегнати от психични проблеми. За да оценим настоящите методи на НЛП и да генерираме ресурси, организирахме песента на участниците в НЛП корпус Златен стандарт от ръчно анотирани туитове (човешки ИАА от 0,919), следвайки указанията за анотация, налични на испански и английски език, бюлетин за заетост, машинно преведена версия на туитове и вграждания на ФастТекст. От 35 регистрирани отбора 11 подадоха общо 27 проби. Най-добре представящите се участници изградиха системи въз основа на последните технологии на НЛП (напр. трансформатори) и постигнаха 0,93 оценка в класификацията на текста и 0,839 в разпознаването на наименовани субекти. Корпус: https://doi.org/10.5281/zenodo.4309356', 'nl': "De detectie van beroepen in teksten is relevant voor een reeks belangrijke toepassingsscenario's, zoals competitive intelligence, sociodemografische analyse, juridische NLP of gezondheidsgerelateerde arbeidsdata mining. Ondanks het belang en de heterogene gegevenstypen die beroepen vermelden, zijn de inspanningen om ze te herkennen beperkt gebleven. Dit komt door het ontbreken van duidelijke annotatierichtlijnen en hoogwaardige Gold Standard corpora's. Social media data kunnen worden beschouwd als een relevante bron van informatie voor realtime monitoring van risicogroepen in de context van pandemies zoals de COVID-19, waardoor interventiestrategieën worden vergemakkelijkt voor beroepen die rechtstreeks contact hebben met infectieagenten of die worden getroffen door psychische gezondheidsproblemen. Om de huidige NLP-methoden te evalueren en middelen te genereren, hebben we de ProfNER-track georganiseerd op SMM4H 2021, waarbij ProfNER-deelnemers een Gold Standard-corpus van handmatig geannoteerde tweets (menselijke IAA van 0.919) krijgen volgens annotatierichtlijnen beschikbaar in het Spaans en Engels, een bezettingsgazetter, een machine-vertaalde versie van tweets en FastText-embeddings. Van de 35 geregistreerde teams leverde 11 in totaal 27 runs in. De best presterende deelnemers bouwden systemen op basis van recente NLP-technologieën (bijv. transformatoren) en behaalden 0.93 F-score in Tekst Classificatie en 0.839 in Named Entity Recognition. Korpus: https://doi.org/10.5281/zenodo.4309356", 'da': 'Detektion af erhverv i tekster er relevant for en række vigtige anvendelsesscenarier, såsom konkurrencedygtig intelligens, sociodemografisk analyse, juridisk NLP eller sundhedsrelateret erhvervsdata mining. På trods af betydningen og de heterogene datatyper, der nævner erhverv, har tekstmining bestræbelser på at genkende dem været begrænsede. Dette skyldes manglen på klare noteringsretningslinjer og høj kvalitet Gold Standard corpora. Data fra sociale medier kan betragtes som en relevant informationskilde til realtidsovervågning af udsatte erhvervsgrupper i forbindelse med pandemier som COVID-19, der letter interventionsstrategier for erhverv i direkte kontakt med smitsomme agenser eller påvirket af psykiske sundhedsproblemer. For at evaluere nuværende NLP-metoder og generere ressourcer har vi organiseret ProfNER-sporet på SMM4H 2021, hvor ProfNER-deltagerne får et Gold Standard korpus af manuelt kommenterede tweets (human IAA på 0,919) efter noteringsretningslinjer tilgængelige på spansk og engelsk, en beskæftigelsesgazetter, en maskinoversat version af tweets og FastText-indlejringer. Ud af 35 registrerede hold indsendte 11 i alt 27 løb. De bedste deltagere byggede systemer baseret på nyere NLP-teknologier (f.eks. transformere) og opnåede 0,93 F-score i tekstklassifikation og 0,839 i Named Entity Recognition. Corpus: https://doi.org/10.5281/zenodo.4309356', 'hr': 'Otkrivanje okupacija u tekstima relevantno je za niz važnih scenarija primjene, poput konkurentne inteligencije, sociodemografske analize, pravne NLP-ove ili zdravstvene rudarstva podataka. Uprkos važnim i heterogenenim tipovima podataka koji spominju okupacije, napori na rudarstvo teksta kako bi ih prepoznali su ograničeni. To je zbog nedostatka jasnih uputstva za annotaciju i visokokvalitetnog zlatnog standardnog korpora. Podaci o društvenim medijima mogu se smatrati relevantnim izvorom informacija za praćenje realnog vremena profesionalnih skupina u kontekstu pandemije poput COVID-19, olakšavanje strategija intervencije za okupacije u direktnom kontaktu s infekcijskim agentima ili utjecavanje na probleme mentalnog zdravlja. Da bi procijenili trenutne metode NLP-a i proizveli resurse, organizovali smo trag ProfNER-a na SMM4H 2021., pružajući učesnike ProfNER sa zlatnim standardnom korpusom ručno annotiranih tweets (ljudske IAA od 0,919) nakon uputstva za annotaciju dostupnih na španjolskom i engleskom jeziku, okupacijskom novinarima, uređajem prevedenom na stroj verziju tweets i FastText ugrađenja. Od 35 registriranih timova 11 je podnio ukupno 27 trka. Najbolji učesnici izgradili su sustave na temelju nedavnih tehnologija NLP-a (npr. transformatora) i postigli 0,93 F-rezultata u klasifikaciji teksta i 0,839 u priznanju imenovanih podataka. Korpus: https://doi.org/10.5281/zenodo.4309356', 'de': 'Die Erfassung von Berufen in Texten ist für eine Reihe wichtiger Anwendungsszenarien relevant, wie Competitive Intelligence, soziodemografische Analysen, rechtliche NLP oder gesundheitsbezogenes betriebliches Data Mining. Trotz der Wichtigkeit und heterogenen Datentypen, die Berufe erwähnen, sind die Bemühungen im Text Mining, diese zu erkennen, begrenzt. Dies liegt am Fehlen klarer Annotationsrichtlinien und qualitativ hochwertiger Gold Standard Korpora. Social-Media-Daten können als relevante Informationsquelle für die Echtzeitüberwachung von gefährdeten Berufsgruppen im Kontext von Pandemien wie der COVID-19 angesehen werden, die Interventionsstrategien für Berufe erleichtern, die in direktem Kontakt mit Infektionserregern stehen oder von psychischen Problemen betroffen sind. Um aktuelle NLP-Methoden zu evaluieren und Ressourcen zu generieren, haben wir den ProfNER-Track auf der SMM4H 2021 organisiert, der den ProfNER-Teilnehmern ein Gold Standard-Korpus manuell kommentierter Tweets (human IAA von 0.919) nach Annotationsrichtlinien in Spanisch und Englisch, ein Berufsblatt, eine maschinell übersetzte Version von Tweets und FastText-Einbettungen zur Verfügung stellt. Von 35 registrierten Teams reichte 11 insgesamt 27 Läufe ein. Die leistungsstärksten Teilnehmer bauten Systeme auf Basis aktueller NLP-Technologien (z.B. Transformatoren) und erreichten 0.93 F-Score in der Textklassifikation und 0.839 in der Named Entity Recognition. Korpus: https://doi.org/10.5281/zenodo.4309356', 'id': 'Deteksi pekerjaan dalam teks relevan untuk berbagai skenario aplikasi penting, seperti kecerdasan kompetitif, analisis sosiodemografis, NLP hukum atau pengembangan data pekerjaan berkaitan dengan kesehatan. Meskipun penting dan tipe data heterogene yang menyebutkan pekerjaan, usaha penambangan teks untuk mengenalinya telah terbatas. Ini karena kekurangan arah anotasi yang jelas dan Kopora Standard Emas berkualitas tinggi. Social media data can be regarded as a relevant source of information for real-time monitoring of at-risk occupational groups in the context of pandemics like the COVID-19 one, facilitating intervention strategies for occupations in direct contact with infectious agents or affected by mental health issues.  Untuk mengevaluasi metode NLP saat ini dan untuk menghasilkan sumber daya, kami telah mengatur trek ProfNER di SMM4H 2021, menyediakan para peserta ProfNER dengan korpus Standard Emas dari tweet yang dicatat secara manual (IAA manusia 0,919) mengikuti petunjuk annotasi yang tersedia dalam bahasa Spanyol dan Inggris, seorang gazeter pekerjaan, versi terjemahan mesin dari tweet, dan FastText embedding. Dari 35 tim terdaftar, 11 mengirim total 27 runs. Peserta yang berpengaruh terbaik membangun sistem berdasarkan teknologi NLP baru-baru ini (contohnya transformer) dan mencapai skor F 0,93 dalam Klasifikasi Teks dan 0,839 dalam Pengenalan Entitas bernama. Corpus: https://doi.org/10.5281/zenodo.4309356', 'sw': 'Kugundua kazi katika maandishi ni muhimu kwa ajili ya maeneo muhimu ya matumizi, kama vile uelewa wa ushindani, uchambuzi wa kijamii, sheria ya NLP au uchimbaji wa taarifa za kazi za afya. Pamoja na umuhimu wa aina za takwimu za kijeshi ambazo zinataja kazi, juhudi za madini za madini za kutambua hizo zimekuwa vigumu. Hii ni kwa sababu ya ukosefu wa maelekezo wazi ya matangazo na kampuni yenye kiwango kikubwa cha dhahabu. Takwimu za mitandao ya kijamii zinaweza kuchukuliwa kama chanzo muhimu cha taarifa kwa ajili ya kufuatilia makundi ya watu walio na hatari katika muktadha wa magonjwa kama COVID-19, na kusaidia mikakati ya kuingilia kazi kwa ajili ya kuwasiliana moja kwa moja na maafisa wenye maradhi au yanaathirika na masuala ya afya ya ya akili. Ili kutathmini mbinu za sasa za NLP na kutengeneza rasilimali, tumeandaa mfuko wa ProfNER katika SMM4H 2021, kwa kuwapa washiriki wa ProfNER na makampuni ya dhahabu ya Standard ya twiti zilizotangazwa kwa manufaa (IAA ya 0.919) kufuatia maelekezo yanayopatikana kwa lugha ya Kihispania na Kiingereza, gazeti la occupation, toleo la twiti zilizotafsiriwa na mfumo wa FastText. Katika timu 35 zilizoandikishwa, 11 walitoa jumla ya mbio 27. Washiriki wanaotengeneza vizuri vilijenga mfumo wa teknolojia za hivi karibuni za NLP (kwa mfano mabadiliko) na kupata vipindi 0.93 F katika Makala ya Maandishi na 0.839 katika Tambulisho la Ujumbe. Corpus: https://doi.org/10.5281/zenodo.4309356', 'ko': '텍스트에서 직업의 검측은 경쟁 정보, 사회 인구 분석, 법률 NLP 또는 건강과 관련된 직업 데이터 발굴 등 일련의 중요한 응용 장면과 관련이 있다.직업의 중요성과 이구 데이터 유형을 언급하지만 직업을 식별하는 텍스트 발굴 노력은 한계가 있다.명확한 주석 지침과 질 좋은 금표준 어료고가 부족하기 때문이다.소셜미디어 데이터는 코로나(예를 들어 코로나) 상황에서 위험직군과 관련한 정보를 실시간으로 모니터링하는 원천으로 볼 수 있으며, 전염원이나 심리적 건강 문제에 직접 노출되는 직업에 대한 관여 전략을 세우는 데 도움이 된다.현재의 NLP 방법을 평가하고 자원을 생성하기 위해 우리는 SMM4H 2021에서 ProfNER 추적을 조직하여 ProfNER 참여자에게 금 표준의 수동 주석 추문 자료 라이브러리(인간 IAA는 0.919)를 제공하고 스페인어와 영어의 주석 지침, 직업지 명록, 추문의 기계 번역 버전과FastText를 따라 삽입했다.등록 팀 35개 중 11개 팀이 모두 27점을 얻었다.가장 잘 표현된 참여자는 최신 NLP 기술(예를 들어transformers)을 바탕으로 시스템을 구축했고 텍스트 분류와 명명 실체 식별에서 각각 0.93F점과 0.839점을 얻었다.자료 라이브러리:https://doi.org/10.5281/zenodo.4309356', 'tr': "Metinlerde işlenmeleri gözlemek wajyp görnüş senaryo ýaly, täsirli intelleksiýa, sosodomografiýa analýusiýa, kanun NLP ýa-da saglykly baglanyşykly işlenýän maglumatlary taýýarlamak üçin wajypdyr. Meşgullary diýip ýazylan wajyp we onçakly maglumat türlerine rağmen, metin köçürmek çabalary tanamak üçin çykardy. Bu sebäbi açyk duýdurma düzgünleriniň we ýokary kwalitet Altyn Standart korpora ýok bolandygyna sebäbi. Sosyal medýdançalar maglumatlary COVID-19 ýaly çykyş gruplaryň hakyky wagt gözlemegi üçin möhüm sebäpli maglumatlaryň çeşmesi hasaplanýar Häzirki NLP yöntemlerini deňlemek we çeşmeleri döretmek üçin, biz SMM4H 2021'de ProfNER hatlaryny düzenledik we ProfNER'iň iştirakçilerini el bellenýän tweets (adam IAA of 0.919) bilen el bellenýän täzelikleriň (adam IAA of 0.919) duşurmek üçin, espanyol we iňlisçe işläp görkezilýän çykyşlaryň, maşynyň terjime edilen tweets we 35 rakamdan bölegi, 11 jemi 27 runs gaýd edildi. Öňki NLP tehnologiýasyna daýan edilen iň gowy hereket eden çykyşlyklar diýip 0.93 F sany tapyldy we 0.839 diýilip atlandyryldy. Korpus: https://doi.org/10.5281/zenodo.4309356", 'fa': 'شناسایی شغل\u200cهای متن برای مجموعه\u200cای از سیناریو\u200cهای کاربرد مهم، مثل اطلاعات رقابتی، تحلیل اجتماعی\u200cموگرافی، NLP قانونی یا خرید داده\u200cهای شغلی مربوط به سلامتی است. با وجود اینکه نوع داده های مهم و متفاوتی که به شغل اشاره می کنند، تلاش های مصنوعی متن برای شناختن آنها محدود شده است. این بخاطر lack of clear annotation guidelines and high-quality Gold Standard corpora است. داده\u200cهای رسانه\u200cهای اجتماعی می\u200cتوانند به عنوان منبع مربوط به اطلاعات برای تماشا کردن گروه\u200cهای شغل در زمان واقعی در محیط پاندمیک\u200cهای مانند COVID-19 یک نظر بگیرند، که استراتژی\u200cهای استراتژی برای شغل\u200cهای مستقیم در ارتباط مستقیم با ماموران\u200cهای عفونت یا مسائل سلامت رو برای ارزیابی روش NLP فعلی و تولید منابع، مسیر پروفNER را در SMM4H 2021 سازمان کرده ایم، که مشتریان پروفNER را با یک کورپوس استاندارد طلا از توئیت های دستی (IAA انسانی از 0.919) آشکار می\u200cکنیم، بعد از رهبری\u200cهای اظهار دسترسی در اسپانیایی و انگلیسی دسترسی کرده ایم، نوشته\u200cکننده\u200cی کارسازی، نسخه\u200cی توئیت\u200c از ۳۵ تیم ثبت شده ۱۱ جمعیت ۲۷ فرایند را ارسال کرد. بهترین مشترک\u200cکننده\u200cها سیستم\u200cهای ساخته شده بر اساس تکنولوژی\u200cهای NLP اخیر (مثال تغییردهنده\u200cها) ساخته شده\u200cاند و 0.93 امتیاز F در کلاس\u200cشناسی متن و 0.839 در شناسایی نامیده\u200cای رسیده\u200cاند. کورپ: https://doi.org/10.5281/zenodo.4309356', 'hy': 'Տեքստներում մասնագիտությունների հայտնաբերումը կարևոր է մի շարք կարևոր կիրառման սցենարների համար, ինչպիսիք են մրցակցության ինտելեկտիվությունը, սոցիոդեմոգրաֆիկ վերլուծությունը, օրինական ՆԼՊ-ը կամ առողջության հետ կապված մաս Չնայած կարևորության և տարբեր տվյալների տեսակներին, որոնք նշում են մասնագիտությունները, տեքստի հանքային ջանքերը դրանք ճանաչելու համար սահմանափակ են: Սա պարզ annoտացիայի ուղղությունների բացակայության պատճառով է և բարձր որակային Ոսկու Ստանդարտ կոպորա: Սոցիալական լրատվամիջոցների տվյալները կարելի է համարվել տեղեկատվության կարևոր աղբյուր ռիսկային մասնագիտական խմբերի իրական ժամանակում հետևելու համար այնպիսի համատեքստում, ինչպիսիք են COVID-19-ը, ինչպես օրինակ համալրատվամիջոցները, խրախուսելով միջամտերությունները մասնագիտությունների համար, որոնք ան Որպեսզի գնահատենք ներկայիս ՆԼՊ մեթոդները և ստեղծենք ռեսուրսներ, մենք կազմակերպեցինք ProfNet-ի հետևանքը SMM4H 2021-ում, տրամադրելով ProfNet-ի մասնակիցներին ձեռքով annoted թվիթերի ոսկու ստանդարտ կորպուս (մարդկային IԱ-ն՝ 0.919), ըստ իսպաներեն և անգլերենում հասանելի annoտացիայի ուղղությունների, աշխատանքային ժամացույ 35 խմբից 11-ը ներկայացրեց 27 վազքեր: Լավագույն արդյունքում ունեցող մասնակիցները կառուցեցին համակարգեր, հիմնված ՆԼՊ-ի վերջին տեխնոլոգիաների վրա (օրինակ վերափոխողները) և հասան 0.93 Ֆ-գնահատականի տեքստի դասակարգում և Կորպուս. https://doi.org/10.5281/zenodo.4309356', 'af': "Opdekking van occupasies in tekste is relevant vir 'n reek van belangrike aansoek scenarios, soos gemeenskap inteligensie, sosialodemografiese analisie, wetlike NLP of gesondig verwante occupasionale data mining. Terwyl die belangrikheid en onheilige data tipes wat occupasies bepaal het, het teks mining versoekte om hulle te herken beperk. Hierdie is vanweë die ontbreek van duidelike annotasie-gidsels en hoë-kwaliteit Goud Standaard Korpora. Soziale media data kan aangesien word as 'n relevante bron van inligting vir reël-tyd-monitoring van die op-risiko occupasionale groepe in die konteks van pandemieke soos die COVID-19 een, wat intervensie strategies vir occupasies in direk kontak met infeksiese agente of wat deur mentale gesondsverkte be ïnvloor word. Om huidige NLP metodes te evalueer en hulpbronne te genereer, het ons die ProfNER snit op SMM4H 2021 organiseer, verskaf ProfNER deelnaders met 'n Goud Standaard Korpus van Hand aangetekende tweete (menslike IAA van 0. 919) volgens aangetekende gidsline beskikbaar in Spaanse en Engels, 'n opbuiting gazetteer, 'n masjien-oorselde weergawe van tweete en FastText inbettings. Uit 35 registreerde teams, 11 het 'n totaal van 27 loop ingestuur. Best e uitvoerde deelnaders gebou stelsels gebaseer op onlangse NLP-teknologies (bv. transformeerders) en het 0.93 F-telling in Teks Klassifikasie en 0.839 in Gebenaamde Eenheidwerkening bereken. Korpus: https://doi.org/10.5281/zenodo.4309356", 'sq': "Zbulimi i punëve në tekste është i rëndësishëm për një gamë skenarësh të rëndësishëm aplikimi, si inteligjenca konkurruese, analiza sociodemografike, NLP ligjore apo miniera e të dhënave profesionale të lidhura me shëndetin. Megjithë rëndësinë dhe llojet e të dhënave heterogjene që përmendin punët, përpjekjet e minierave të tekstit për t'i njohur ato janë të kufizuara. Kjo është për shkak të mungesës së udhëzimeve të qarta të anotacionit dhe korporatës së cilësisë së lartë të Gold Standard. Të dhënat e medias sociale mund të konsiderohen si një burim i rëndësishëm informacioni për mbikqyrjen në kohë reale të grupeve profesionale në rrezik në kontekstin e pandemikave si COVID-19, duke lehtësuar strategjitë ndërhyrjeje për punët në kontakt të drejtpërdrejtë me agjentët infektues ose të prekur nga çështjet e shëndetit psikologjik. Për të vlerësuar metodat e tanishme të NLP dhe për të gjeneruar burime, ne kemi organizuar gjurmën ProfNER në SMM4H 2021, duke ofruar pjesëmarrësve të ProfNER një korpus Gold Standard të tweeteve të anotuara manualisht (human IAA of 0.919) pas udhëzimeve të anotacionit në dispozicion në spanjoll dhe anglisht, një gazetar profesionist, një version të përkthyer nga makina të tweeteve dhe përfshirjeve të FastText. Nga 35 ekipe të rregjistruara, 11 paraqitën një total prej 27 vrapimesh. Pjesëmarrësit me rezultate më të mira ndërtuan sisteme bazuar në teknologjitë e fundit të NLP (për shembull transformuesit) dhe arritën 0.93 pikë F në klasifikimin e tekstit dhe 0.839 në njohjen e emëruar të njësisë. Korpus: https://doi.org/10.5281/zenodo.4309356", 'am': 'በጽሑፎች ውስጥ የሚኖሩት የሥራ ማግኘት በተጨማሪው የፕሮግራም ማስታወቂያው፣ እንደተቃዋሚ ማስታወቂያ፣ ሕግ የNLP ወይም የጤናዊ የዳታ ማህበረሰብ ማህበረሰብ ግንኙነት ነው፡፡ ምንም እንኳን የሀብት እና የሥልጣን ዳታ ዓይነቶች ቢገልጹ፣ የጽሑፍ ማውቀት ጉዳይ ግንኙነት ነው፡፡ ይህ ምክንያት የግልጹ የአውቀት መሪ እና ከፍተኛ የወርቅ የኮርፖር ግንኙነት ስላልጎደለው ነው፡፡ ማኅበራዊ ሚዲያዎች ዳታዎችን እንደ COVID-19 በክፍለ ግጭት ውስጥ የደካማ የሥራ ሠራዊት ክፍተቶችን በመግኘት ወይም በmental ጤና ጉዳዮች ላይ የሚጎትቱት የሥርዓት ስርዓት ማቅናቄ የሚያስፈልጋቸው የሥልጣን ጥቅረት ማግኘት ይችላል፡፡ የአሁኑን NLP ሥርዓት ለማስተካከል እና ሀብትን ለመፍጠር፣ በSM4H 2021 SM4H (SMM4H 2021) የፕሮጀኔር ድርጅት አሰናብተናል፡፡ ፕሮጀኔር ተጋሪዎችን በጅማት የተመሳሳይ የወርቅ Standard ካርፓስ (0.919 የኢ.አ.አ.አ. በስፓኒሽ እና እንግሊዘኛ) በተገኘ የኢንጂንግል ማስታወቂያ መግለጫ፣ የኢኮኖት ጋዜጠኛ፣ የመሻሻሻዊ ትዊት እና የፋ ከ35 የተገቡ ቡድን 11 ሙሉ 27 ሮኖች አቀረቡ፡፡ የአሁኑ የNLP ቴክኖሎጂ (ለምሳሌ ለውጦች) የተጠቃሚ ተጋሪዎች የጽሑፍ መግለጫ እና በስም የስብሰባ ማውቀት 0.93 F-score አግኝተዋል፡፡ ቆርፓስ https://doi.org/10.5281/zenodo.4309356', 'ca': "La detecció de ocupacions en els textos és rellevant per a una gamma d'escenaris importants d'aplicació, com la intel·ligència competitiva, l'anàlisi sociodemogràfica, el NLP legal o la mineria de dades ocupacionals relacionades amb la salut. Malgrat la importància i els tipus heterogenis de dades que mencionen ocupacions, els esforços de mineria de text per reconèixer-les han estat limitats. Això és degut a la falta de directrices clares d'anotació i de corpora d'Or Standard d'alta qualitat. Social media data can be regarded as a relevant source of information for real-time monitoring of at-risk occupational groups in the context of pandemics like the COVID-19 one, facilitating intervention strategies for occupations in direct contact with infectious agents or affected by mental health issues.  Per avaluar els mètodes actuals del NLP i generar recursos, hem organitzat la pista ProfNER a SMM4H 2021, proporcionant als participants del ProfNER un corpus Gold Standard de tweets anotats manualment (IAA humana de 0,919) segons les directrices d'anotació disponibles en espanyol i anglès, un periodista d'ocupació, una versió traduïda per màquina de tweets i incorporacions de FastText. De 35 equips registrats, 11 van presentar un total de 27 carreres. Els millors participants van construir sistemes basats en tecnologies recents del NLP (per exemple transformadors) i van aconseguir 0,93 puntuació F en la classificació de text i 0,839 en la reconeixement d'entitats anomenades. Corpus: https://doi.org/10.5281/zenodo.4309356", 'az': 'Mətnlərdə çalışmaların tanıması mühüm istifadə senaryosu kimi, müəllif istihbarat, sosyolodemografik analizi, yasal NLP və sağlamlıq əlaqəsində olan məlumat maddə məlumatları üçün məxsusdur. Məşğullarını xatırlayan möhümlük və müxtəlif məlumatlar növlərinə baxmayaraq, məlumatların məlumatlarını tanıtmaq üçün məlumatların qurbanlıqları müəyyən edilmişdir. Bu açıq bildiriş doğruluqlarının və yüksək kaliteli Altın Standardlı Korpora olmasına görədir. Sosyal media məlumatları COVID-19 kimi pandemik məlumatlarında həqiqət vaxtlı işlər qrupların gözləməsi üçün məlumatların məlumatları olaraq hesab edilə bilər, infeksiya a ģentləri və ya mental sağlığı məlumatlarından təsirlənən məlumatların müddətli əlaqələrində intervenci stratejilərini olaraq tələsirlər. Hazırkı NLP metodlarını değerləşdirmək və resurslar ürəklənmək üçün, SMM4H 2021-də ProfNER yolunu düzəltdik. ProfNER iştirakçılarına, İspanyol və İngilizce dilində mövcud olan məlumatların doğruluqlarına uyğun İspanyol və İngilizce dilində olan qızıl Standardlı korpusu ilə istifadə etdik, maşın tərcümləndirilən tweets versiyası və FastText in şalları ilə istifadə etdik. 35 müəyyən dəstədən 11 müəyyən edildi. Son NLP teknolojilərinə dayanan ən yaxşı iştirakçilər in şa etdilər və İsmim Entity Recognition üçün 0.93 F-score tapdılar. Corpus: https://doi.org/10.5281/zenodo.4309356', 'bn': 'টেক্সটে কাজ করার জন্য গুরুত্বপূর্ণ অ্যাপ্লিকেশনের দৃশ্যের জন্য গুরুত্বপূর্ণ, যেমন প্রতিযোগিতায় গুরুত্বপূর্ণ গোয়েন্দা, সামাজিক গ্ গুরুত্বপূর্ণ এবং উজ্জ্বল তথ্যের ধরন সত্ত্বেও, কাজের কথা উল্লেখ করে, তাদের স্বীকার করার জন্য টেক্সট খনির চেষ্ট এটা পরিষ্কার বিজ্ঞাপনের নীতি এবং উচ্চমান সোনার্ড স্ট্যান্ডার্ড কর্পোরার অভাবের কারণে। সামাজিক প্রচার মাধ্যমের তথ্যের সূত্র হিসেবে বিবেচনা করা যাচ্ছে যে কোভিডি-১৯ এর মত বিপর্যয়ের প্রেক্ষাপটে বিপদজনক পেশাদারী গ্রুপের বাস্তবতা পর্যবেক্ষণের জন্য বাস To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in Spanish and English, an occupation gazetteer, a machine-translated version of tweets, and FastText embeddings.  ৩৫ টি নিবন্ধনী দলের মধ্যে ১১ টি মোট ২৭ টি রান জমা দিয়েছে। সাম্প্রতিক এনএলপি প্রযুক্তির উপর ভিত্তিক ভিত্তিক অংশগ্রহণকারীরা সেরা শ্রেষ্ঠ অংশগ্রহণকারীদের সিস্টেম তৈরি করেছে এবং টেক্সট ক্লাসিফিকেশন কোর্পাস: https://doi.org/10.5281/zenodo.4309356', 'bs': 'Otkrivanje okupacija u tekstima je važno za niz važnih scenarija primjene, poput konkurentne inteligencije, sociodemografske analize, pravne NLP-a ili rudarstva profesionalnih podataka vezane za zdravlje. Uprkos važnim i heterogenenim tipovima podataka koji spominju okupacije, napori na rudarstvo teksta kako bi ih prepoznali su ograničeni. To je zbog nedostatka jasnih uputstva za annotaciju i visokokvalitetnog zlatnog standardnog korpora. Podaci o društvenim medijima mogu se smatrati relevantnim izvorom informacija za praćenje realnog vremena profesionalnih grupa u kontekstu pandemije poput COVID-19, olakšavanje strategija intervencije za okupacije u direktnom kontaktu sa infekcijskim agentima ili utjecavanje na probleme mentalnog zdravlja. Da bi procijenili trenutne metode NLP i proizveli resurse, organizovali smo trag ProfNER na SMM4H 2021, pružajući učesnicima ProfNER sa zlatnim standardnom korpusom ručno annotiranih tweets (ljudske IAA od 0,919) nakon uputstva za annotaciju dostupnih na španjolskom i engleskom jeziku, okupacijskom novinaru, automatskom prevedenom verzijom tweeta i FastText ugrađenja. Od 35 registriranih timova 11 je podnio ukupno 27 trka. Najbolji učesnici izgradili su sisteme na temelju nedavnih tehnologija NLP-a (npr. transformatora) i postigli 0,93 F-rezultata u klasifikaciji teksta i 0,839 u priznanju imenovanih entiteta. Corpus: https://doi.org/10.5281/zenodo.4309356', 'cs': 'Detekce povolání v textech je relevantní pro řadu důležitých aplikačních scénářů, jako je konkurenční inteligence, sociodemografická analýza, právní NLP nebo těžba pracovních dat souvisejících se zdravím. Navzdory důležitosti a heterogenním datovým typům, které zmiňují povolání, snahy o jejich rozpoznání byly omezené. Je to způsobeno nedostatkem jasných anotací pokynů a vysoce kvalitními korpusy Gold Standard. Data sociálních médií lze považovat za relevantní zdroj informací pro monitorování ohrožených profesních skupin v reálném čase v kontextu pandemie, jako je COVID-19, což usnadňuje intervenční strategie pro profese v přímém kontaktu s infekčními činiteli nebo postižené problémy duševního zdraví. Pro vyhodnocení současných metod NLP a generování zdrojů jsme zorganizovali stopu ProfNER na SMM4H 2021, která poskytla účastníkům ProfNER korpus manuálně anotovaných tweetů (lidská IAA 0.919) podle pokynů pro anotaci dostupných ve španělštině a angličtině, profesní gazetter, strojově přeloženou verzi tweetů a vložení FastText. Ze 35 registrovaných týmů jedenáct předložilo celkem 27 běhů. Nejlepší účastníci vytvořili systémy založené na nejnovějších technologiích NLP (např. transformátory) a dosáhli 0.93 F-skóre v klasifikaci textu a 0.839 v rozpoznávání jmenovaných entit. Korpus: https://doi.org/10.5281/zenodo.4309356', 'et': 'Ametikohtade tuvastamine tekstides on oluline mitmete oluliste rakendusstsenaariumide puhul, nagu konkurentsiarendus, sotsiaaldemokraatiline analüüs, õiguslik NLP või tervisega seotud tööandmete kaevandamine. Vaatamata tähtsusele ja heterogeensetele andmetüüpidele, mis viitavad ametitele, on tekstikaevandamise jõupingutused nende tuvastamiseks olnud piiratud. See on tingitud selgete märkuste juhiste ja kvaliteetsete Gold Standard korpuste puudumisest. Sotsiaalmeedia andmeid võib pidada asjakohaseks teabeallikaks riskirühmade reaalajas jälgimiseks selliste pandeemiate kontekstis nagu COVID-19, hõlbustades sekkumisstrateegiaid kutsealadel, kes on otseses kontaktis nakkusetekitajatega või vaimse tervise probleemidega mõjutatud. Praeguste NLP meetodite hindamiseks ja ressursside loomiseks oleme korraldanud ProfNERi raja SMM4H 2021. aastal, pakkudes ProfNERi osalejatele hispaania ja inglise keeles kättesaadavaid annotatsioonijuhiseid järgiva kuldstandardi korpuse käsitsi annoteeritud säutsudest (inimese IAA 0,919), ametialane väljaanne, masintõlgitud versioon säutsudest ja FastTexti manustamised. 35 registreeritud võistkonnast esitasid 11 kokku 27 jooksu. Parimate tulemustega osalejad ehitasid süsteeme, mis põhinesid hiljutistel NLP tehnoloogiatel (nt trafod), ning saavutasid 0,93 F-skoori tekstiklassifikatsioonis ja 0,839 Nimetatud üksuste tunnustamises. Corpus: https://doi.org/10.5281/zenodo.4309356', 'fi': 'Ammattien havaitseminen teksteissä on tärkeää monille tärkeille sovellusskenaarioille, kuten kilpailuälylle, sosiodemografiselle analyysille, oikeudelliselle NLP:lle tai terveyteen liittyvälle työtietojen louhimiselle. Huolimatta ammattien merkityksestä ja heterogeenisistä tietotyypeistä niiden tunnistaminen on ollut vähäistä tekstilouhintaan. Tämä johtuu siitä, että selkeitä merkintöjä koskevia ohjeita ja korkealaatuisia Gold Standard -korpusia ei ole. Sosiaalisen median dataa voidaan pitää merkittävänä tietolähteenä riskialttiiden työryhmien reaaliaikaiseen seurantaan COVID-19-pandemian kaltaisen pandemian yhteydessä, mikä helpottaa toimintastrategioita ammateissa, jotka ovat suorassa kosketuksessa tartunnan aiheuttajien kanssa tai joilla on mielenterveysongelmia. Arvioidaksemme nykyisiä NLP-menetelmiä ja tuottaaksemme resursseja olemme järjestäneet ProfNER-radan SMM4H 2021 -tapahtumassa, tarjoten ProfNER-osallistujille Gold Standard -korpusen manuaalisesti merkittyjä tweettejä (ihmisen IAA 0,919) espanjaksi ja englanniksi saatavilla olevien huomautusohjeiden mukaisesti, ammattilehden, konekäännetyn version tweeteistä ja FastText-upotuksia. Rekisteröidyistä 35 joukkueesta 11 teki yhteensä 27 juoksua. Parhaiten menestyneet osallistujat rakensivat viimeisimpiin NLP-teknologioihin perustuvia järjestelmiä (esim. muuntajat) ja saavuttivat 0,93 F-pisteen tekstiluokituksessa ja 0,839 Nimettyjen yhteisöjen tunnistuksessa. Korpus: https://doi.org/10.5281/zenodo.4309356', 'he': 'גילוי מקצועים בטקסטים הוא רלוונטי לטווח של תרחישים חשובים של שימוש, כמו אינטליגנציה תחרותית, ניתוח סוציודמוגרפי, NLP חוקי או מכירת נתונים מקצועיים קשורים לבריאות. למרות החשיבות וסוגי נתונים היטרוגניים שמזכירים מקצועים, מאמצי מכרות טקסטים כדי להכיר אותם הוגבלו. זה בגלל חוסר מדריכי ציונים ברורים וקופורה סטנדרטית זהב של איכות גבוהה. נתוני התקשורת החברתית יכולים להיחשב כמקור רלוונטי של מידע למעקב בזמן אמיתי של קבוצות מקצועיות מסוכנות בקשר לפנדמיות כמו COVID-19, להקל אסטרטגיות התערבות למקצועים במגע ישיר עם סוכנים מדבקים או מושפעים על ידי בעיות בריאות נפשית. כדי להעריך שיטות NLP הנוכחיות וליצור משאבים, ארגנו את מסלול ProfNER ב SMM4H 2021, מספקים לשתתפים ProfNER גופוס זהב סטנדרטי של טוויטים מצויינים ידנית (IAA אנושית של 0.919) בעקבות מדריכי ציונים זמינים בספרדית ואנגלית, עיתונאי מקצועי, גרסה מתרגמת מכונות של טוויטים, וקריות טקסט מהיר. מתוך 35 קבוצות רשומות, 11 שלחו בסך הכל 27 רצויות. השתתפים הטובים ביותר בנו מערכות מבוססות על טכנולוגיות NLP לאחרונה (למשל משתנים) והשגשו 0.93 נקודת F בקליפסיה טקסטית ו-0.839 בקליפסיה של איכות בשם. קורפוס: https://doi.org/10.5281/zenodo.4309356', 'jv': "Awak dhéwé éntuk perusahaan ing textil sing dikanggambar kanggo kalaha gambar neng akeh operasi sing dikanggambar, koyo nggambar obang-ingkang dipolehasan, NdLP hukum kanggo mbalkuripun operasi sing berarti online. Gak dhéwé seneng nglanggar wigatining lan akeh operasi dadi sing menehi pergunakake Iki lak buwis nggo nganggo dolanan popolahan sing gak bener nggawe barang gambar luwih-luwih 'gol Standard Body' Daftar online Ngawe Perintah NLP sing nggawe perusahaan nggawe dolanan karo nggawe perusahaan, kita wis nguasai nggawe barang profiNeR nang SMM4H 2020 1, supoyo barang-perusahaan ne perusahaan gol Standard corpus sing nganggep tanggal uwis (Human IBA of 0.9) sing dadi ndherengkat nganggep kuwi padha Kasal karo ingkang, ndherengkat kuwi kapan pangan, gambar, perusahaan-terusahaan versi tuwit, lan fast Text embedding. Mulai Siji-perusahaan sing wis luhur perusahaan nggawe sistem sing basa oleh NLP teknôlogi (bah sing transformer) lan wis aswih 0. structural navigation https://doi.org/10.5281/zenodo.4309356", 'ha': "Ana gane masu aikin littãfin na da muhimma wa misãlai na shiryoyin ayuka, kamar shirin hankali masu motsi, Ana yi fasihi na jamodemographi, sharci na NLP ko kunnufi na danna danna da aka yi wa da shi a cikin aikin da za'a yi amfani da. Babu da muhimmin da nau'in data masu faɗar aiki, sai an ƙayyade aikin maduka da za'a sani su. Wannan saba da ba'a da shiryarwa bayyananne da koronar Gold na sifanci. Data na mitandai da jamii za'a gane shi kamar kilogi na muhimmin wa tsari wa halin-lokaci wa jama'a masu haske da jama'a a cikin mazaunin bukarin, kamar COCOV-19 na, ko kuma yana amfani da tunikin ajira wa shuqulori idan an haɗa su dira da mataimaki masu kashewa ko kuwa yana da zartar da su. To evaluate metoden NLP yanzu kuma ta ƙiƙiro resource, mun organize the profNER trace at SMM4H 2021, kuma mun bã profNER mãsu shirin zama da profNER tãre da wata takardar Gold Andari na da hannayen sanarwa (humani IAA of 0.919) daga bayan shiryarwa na takardar da ke iya cikin spanish da Ingiriya, wani jaron-karatun, wani version na-fastText embeddings. Daga jama'a 35 wanda aka rubuta, 11 ya wasiyya da jumla 27 runs. @ info: whatsthis KCharselect unicode block name https://doi.org/10.5281/zenodo.4309356", 'sk': 'Odkrivanje poklicev v besedilih je pomembno za vrsto pomembnih scenarijev uporabe, kot so konkurenčna inteligenca, sociodemografska analiza, pravni NLP ali rudarjenje podatkov o delu, povezano z zdravjem. Kljub pomembnosti in heterogenim vrstam podatkov, ki omenjajo poklice, so bila prizadevanja za pridobivanje besedila omejena. To je posledica pomanjkanja jasnih smernic za označevanje in visokokakovostnih korpusov Gold Standard. Podatki o družbenih medijih se lahko obravnavajo kot pomemben vir informacij za spremljanje ogroženih poklicnih skupin v realnem času v kontekstu pandemij, kot je COVID-19, kar olajšuje intervencijske strategije za poklice v neposrednem stiku z povzročitelji nalezljivosti ali prizadete zaradi težav z duševnim zdravjem. Za oceno trenutnih metod NLP in ustvarjanje virov smo na SMM4H 2021 organizirali sled ProfNER, ki udeležencem ProfNER zagotavlja korpus zlatega standarda ročno označenih tweetov (človeški IAA 0,919) po smernicah za označevanje, ki so na voljo v španščini in angleščini, poklicni list, strojno prevedeno različico tweetov in vdelave FastText. Od 35 registriranih ekip jih je 11 oddalo skupaj 27 tekov. Najbolj uspešni udeleženci so zgradili sisteme, ki temeljijo na novejših tehnologijah NLP (npr. transformatorji), dosegli 0,93 F-oceno pri klasifikaciji besedila in 0,839 pri prepoznavanju imenovanih subjektov. Corpus: https://doi.org/10.5281/zenodo.4309356', 'bo': 'ཡི་གེའི་ནང་གི་ལས་འགན གལ་ཆེན་དང་མི་རྒྱུན་ལྡན་གྱི་གནད་དོན་དག་གི་དབྱེ་བ་དག་གི་ཡིག་ཆ་སྐྱེན་དུ་བསླབས་ཡོད་པ་ལས། ཡིག་གེ་བསམ་བློ་ འདི་ནི་བསམ་བློ་གཏོང་གི་སྔོན་ལྟར་ཉེན་བརྗོད་གཏོང་འབྲེལ་བ་དང་མཐོ་རིམ་མཐོ་བརྩོན་པ། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ཆ་འཕྲིན་དེ་ཚོར་བ་དང་གནས་ཚུལ་གྱི་རྒྱུ་དངོས་ཐོག་ཏུ་ཉར་བཅོས་ཐབས་བྱེད་སྟངས་དང་། To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in Spanish and English, an occupation gazetteer, a machine-translated version of tweets, and FastText embeddings. The following annotation guidelines available in Spanish and English are: བྲིས་འཛིན་པའི་གནད་དོན་35ལས་འགོད་པ་དེ་འགྲོ་བཞིན་པའི་གནད་སྡུད་༡༡༡་ནི་གནད་སྡུད་༧༧ Best-performing participants built systems based on recent NLP technologies (e.g. transformers) and achieved 0.93 F-score in Text Classification and 0.839 in Named Entity Recognition. རྩིས་མཁས་: https://doi.org/10.5281/zenodo.4309356'}
{'en': 'Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets', 'ar': 'التعلم متعدد المهام المستند إلى المحولات لتحليل الإشارة السلبية في التغريدات', 'fr': "Apprentissage multitâche basé sur un transformateur pour l'analyse des mentions d'effets indésirables dans les tweets", 'pt': 'Aprendizado multitarefa baseado em transformador para análise de menção de efeito adverso em tweets', 'es': 'Aprendizaje multitarea basado en transformadores para el análisis de menciones de efectos adversos en tweets', 'ja': 'ツイートにおける有害作用分析のための変圧器ベースのマルチタスク学習', 'zh': '盖转换器之多任务学,推文之不利也', 'hi': 'Tweets में प्रतिकूल प्रभाव उल्लेख विश्लेषण के लिए ट्रांसफॉर्मर-आधारित बहु-कार्य सीखना', 'ru': 'Многозадачное обучение на основе трансформатора для анализа упоминания неблагоприятных эффектов в твитах', 'ga': 'Foghlaim Ilthasc Trasfhoirmeoir-bhunaithe le haghaidh Anailíse ar Mhionéifeacht Dhíobhálach in Tweets', 'ka': 'Name', 'el': 'Μάθηση πολλαπλών εργασιών με βάση μετασχηματιστή για ανάλυση αναφορών ανεπιθύμητων επιπτώσεων σε tweets', 'hu': 'Transzformátor alapú többfeladatos tanulás a negatív hatások említésének elemzéséhez Tweetekben', 'it': "Apprendimento multi-task basato su trasformatori per l'analisi delle menzioni degli effetti avversi nei tweet", 'kk': 'Твиттерде қарсы эффекттер мәзірін талдау үшін көптеген тапсырмаларды оқыту', 'lt': 'Daugiauždavinio mokymasis, pagrįstas transformatoriais, nepageidaujamo poveikio paminėjimo analizei Tweetuose', 'ms': 'Pembelajaran Tugas Berberasasi-Transformer untuk Analisis Menerima Kesan Gangguan dalam Tweets', 'mk': 'Трансформирано мултизадачно учење за анализа на спомените за негативни ефекти на твитови', 'ml': 'ടൂട്ടുകളില്\u200d പ്രഭാവപ്രഭാവ വ വിവരങ്ങള്\u200dക്കുള്ള വിശദീകരണത്തിനായി പരിശോധിക്കുന്ന പല പണിയിട പഠിപ്പി', 'mt': 'Tagħlim Multikompiti bbażat fuq trasformaturi għal Analiżi tal-Menzjoni ta’ Effetti Avversi fit-Tweets', 'mn': 'Твитт дээр эсрэг эффект санааны шинжилгээний талаар шинжилгээгчийн үндсэн олон-үйл ажиллагааны суралцах', 'pl': 'Wielozadaniowe uczenie się oparte na transformatorze dla analizy wzmianek o niekorzystnych skutkach w tweetach', 'ro': 'Învățare multi-sarcină bazată pe transformator pentru analiza menționării efectelor adverse în Tweets', 'no': 'Transformeringslæring av fleire oppgåver for omvendte effektmenylyser i tweets', 'sr': 'Naučenje multizadataka na transformaciji za analizu mišljenja protivnih efekta u Tweets-u', 'si': 'Name', 'ur': 'ٹرانسفور-بنیاد Multi-Task Learning for Adverse Effect Mention Analysis in Tweets', 'so': 'Analysis ku qoran Tweets', 'ta': 'முன்னோக்கி விளைவு பட்டியல் விளைவு விளக்கம்', 'sv': 'Transformarbaserat Multi-Task Learning för analys av negativa effekter i tweets', 'uz': 'Name', 'vi': 'Mô hình biến hình nền đa công việc học về kết quả xấu trong Tweet', 'bg': 'Обучение с множество задачи, базирано на трансформатори, за анализ на споменаването на неблагоприятни ефекти в туитове', 'da': 'Transformer-baseret Multi-Task Learning for Adverse Effect Mention Analyse i Tweets', 'hr': 'Naučenje multizadataka na transformaciji za analizu mišljenja nuspojava u Tweets-ima', 'nl': 'Transformer-based Multi-Task Learning voor analyse van negatieve effecten in Tweets', 'id': 'Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets', 'de': 'Transformatorbasiertes Multi-Task-Lernen zur Analyse von unerwünschten Effekten in Tweets', 'ko': 'Transformer 기반의 멀티태스킹 학습은 트위터의 좋지 않은 영향 언급 분석에 사용', 'fa': 'یادگیری بسیاری از کار\u200cهای تغییر\u200cپذیر برای تحلیل یادگیری اثرات مخالف در Tweets', 'tr': 'Tweets', 'sw': 'Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets', 'af': 'Name', 'sq': 'Mësimi Multi-Task për Analizën e përmendimit të Efekteve të Pafavorshme me bazë në Transformues në Tweets', 'am': 'የፊደል-based Multi-Task Learn for Adverse Effects Menu Analysis in Tweets', 'hy': 'Թվիթերում բազմախնդիրներով հիմնված բազմախնդիրների ուսումնասիրությունը կորցված ազդեցությունների մասին վերլուծության համար', 'az': 'Tövidlərdə Dönüş Efekt Menüsü Analizi üçün Transformer-tabanlı Multi-Task Öyrənməsi', 'bn': 'টুইটে ভিত্তিক ভিত্তিক অনেক কাজ শিক্ষার্থী', 'bs': 'Naučenje na transformaciji multi-zadataka za analizu mišljenja na nuspojavama u Tweets-ima', 'ca': "Aprendiment multitascat basat en transformadors per a l'anàlisi de la menció d'efectes adversos en tuits", 'cs': 'Multiúlohové učení založené na transformátoru pro analýzu nežádoucích účinků zmínění ve tweetech', 'et': 'Transformer-põhine mitme ülesandega õppimine kahjuliku mõju mainimise analüüsi jaoks tweetides', 'fi': 'Muuntajapohjainen monitehtäväoppiminen haittavaikutusten mainitsemisen analysointiin twieteissä', 'jv': 'Transformer-basic Multi-task Learning for Advrse Effect Mention Resolution', 'ha': 'Analyze cikin Twitter', 'sk': 'Učenje več opravil na podlagi transformatorjev za analizo omenjanja škodljivih učinkov v tweetih', 'he': 'למידת משימות רבות מבוססת בטרנספורסם לניתוח זיכרון השפעות הלא-רציניות בטוויטים', 'bo': 'Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets'}
{'en': 'This paper presents our contribution to the  Social Media Mining  for Health Applications Shared Task 2021. We addressed all the three subtasks of Task 1 : Subtask A (classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (adverse effects resolution). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the  robustness  of the prediction. Our system ranked first at Subtask B with 0.51 F1 score, 0.514  precision  and 0.514 recall. For Subtask A we obtained 0.44  F1 score , 0.49  precision  and 0.39 recall and for Subtask C we obtained 0.16  F1 score  with 0.16  precision  and 0.17 recall.', 'pt': 'Este artigo apresenta nossa contribuição para a Tarefa Compartilhada de Mineração de Mídias Sociais para Aplicativos de Saúde 2021. Abordamos todas as três subtarefas da Tarefa 1: Subtarefa A (classificação de tweets contendo efeitos adversos), Subtarefa B (extração de trechos de texto contendo efeitos adversos) e Subtarefa C (resolução de efeitos adversos). Exploramos vários modelos de linguagem baseados em transformadores pré-treinados e nos concentramos em uma arquitetura de treinamento multitarefa. Para a primeira subtarefa, também aplicamos técnicas de aumento adversarial e formamos conjuntos de modelos para melhorar a robustez da previsão. Nosso sistema ficou em primeiro lugar na Subtarefa B com pontuação F1 de 0,51, precisão de 0,514 e recall de 0,514. Para a Subtarefa A obtivemos 0,44 F1 score, 0,49 precisão e 0,39 recall e para a Subtarefa C obtivemos 0,16 F1 score com 0,16 precisão e 0,17 recall.', 'ar': 'تقدم هذه الورقة مساهمتنا في المهمة المشتركة لتعدين الوسائط الاجتماعية للتطبيقات الصحية 2021. لقد تناولنا جميع المهام الفرعية الثلاثة للمهمة 1: المهمة الفرعية أ (تصنيف التغريدات التي تحتوي على تأثيرات ضارة) والمهمة الفرعية ب (استخراج فترات نصية تحتوي على تأثيرات ضارة) و المهمة الفرعية C (تحليل الآثار الضارة). استكشفنا العديد من نماذج اللغة المعتمدة على المحولات المدربة مسبقًا وركزنا على بنية تدريب متعددة المهام. بالنسبة للمهمة الفرعية الأولى ، طبقنا أيضًا تقنيات زيادة الخصومة وشكلنا مجموعات نموذجية من أجل تحسين متانة التنبؤ. احتل نظامنا المرتبة الأولى في Subtask B بدرجة 0.51 F1 و 0.514 من الدقة و 0.514 في الاسترجاع. بالنسبة إلى Subtask A ، حصلنا على 0.44 درجة F1 ودقة 0.49 واسترجاع 0.39 وبالنسبة إلى Subtask C حصلنا على 0.16 درجة F1 بدقة 0.16 واسترجاع 0.17.', 'fr': "Cet article présente notre contribution au Social Media Mining for Health Applications Shared Task 2021. Nous avons abordé les trois sous-tâches de la Tâche 1\xa0: Sous-tâche A (classification des tweets contenant des effets indésirables), Sous-tâche B (extraction de plages de texte contenant des effets indésirables) et Sous-tâche C (résolution des effets indésirables). Nous avons exploré divers modèles de langage pré-formés basés sur des transformateurs et nous nous sommes concentrés sur une architecture de formation multitâche. Pour la première sous-tâche, nous avons également appliqué des techniques d'augmentation contradictoire et nous avons formé des ensembles de modèles afin d'améliorer la robustesse de la prédiction. Notre système s'est classé premier dans la sous-tâche B avec un score F1 de 0,51, une précision de 0,514 et un rappel de 0,514. Pour la sous-tâche A, nous avons obtenu un score F1 de 0,44, une précision de 0,49 et un rappel de 0,39 et pour la sous-tâche C, un score F1 de 0,16 avec une précision de 0,16 et un rappel de 0,17.", 'es': 'Este artículo presenta nuestra contribución a la tarea compartida de minería de redes sociales para aplicaciones de salud 2021. Abordamos las tres subtareas de la Tarea 1: Subtarea A (clasificación de tuits que contienen efectos adversos), Subtarea B (extracción de espacios de texto que contienen efectos adversos) y Subtarea C (resolución de efectos adversos). Exploramos varios modelos lingüísticos preentrenados basados en transformadores y nos centramos en una arquitectura de capacitación multitarea. Para la primera subtarea, también aplicamos técnicas de aumento contradictorio y formamos conjuntos de modelos para mejorar la solidez de la predicción. Nuestro sistema ocupó el primer lugar en la subtarea B con una puntuación F1 de 0.51, precisión de 0.514 y recuperación de 0.514. Para la subtarea A obtuvimos una puntuación F1 de 0,44, una precisión de 0,49 y una recuperación de 0,39, y para la subtarea C obtuvimos una puntuación de 0,16 F1 con una precisión de 0,16 y una recuperación de 0,17.', 'ja': '本稿では、ソーシャルメディアマイニングfor Health Applications Shared Task 2021への貢献を紹介します。タスク1の3つのサブタスク：サブタスクA （有害作用を含むツイートの分類）、サブタスクB （有害作用を含むテキストスパンの抽出）、サブタスクC （有害作用の解決）に対処した。事前に訓練された変圧器ベースのさまざまな言語モデルを探求し、マルチタスク訓練アーキテクチャに焦点を当てました。最初のサブタスクでは、対立増強テクニックも適用し、予測の堅牢性を向上させるためにモデルアンサンブルを形成しました。私たちのシステムは、0.51 F 1スコア、0.514精度、および0.514リコールでサブタスクBで1位でした。サブタスクＡについては、０ ． ４ ４ Ｆ１スコア、０ ． ４ ９精度及び０ ． ３ ９リコールを取得し、サブタスクＣについては、０ ． １ ６精度及び０ ． １ ７リコールで０ ． １ ６ Ｆ１スコアを取得した。', 'zh': '本文引我2021年康强社交媒体发掘同功。 凡三子 1 事:子职 A(包不良影响推文之类)、子职 B(取不良影响之文跨度)与子职 C(不良反应决)。 探诸预练之基于转换器言,而专注于多任务架构。 先用对抗性术,以成模融,以成其鲁棒性。 子职B第一,F1分为0.51,精为0.514,召还率为0.514。 子职A,吾得0.44 F1数,0.49精0.39召率,于子C,吾得0.16 F1得分,精为0.16,召率为0.17。', 'hi': 'यह पेपर स्वास्थ्य अनुप्रयोगों साझा कार्य 2021 के लिए सोशल मीडिया खनन में हमारे योगदान को प्रस्तुत करता है। हमने कार्य 1 के सभी तीन उप-कार्यों को संबोधित किया: सबटास्क ए (प्रतिकूल प्रभाव वाले ट्वीट्स का वर्गीकरण), सबटास्क बी (प्रतिकूल प्रभाव वाले पाठ स्पैन का निष्कर्षण) और सबटास्क सी (प्रतिकूल प्रभाव समाधान)। हमने विभिन्न पूर्व-प्रशिक्षित ट्रांसफॉर्मर-आधारित भाषा मॉडल का पता लगाया और हमने एक बहु-कार्य प्रशिक्षण वास्तुकला पर ध्यान केंद्रित किया। पहले subtask के लिए, हम भी प्रतिकूल वृद्धि तकनीकों को लागू किया और हम आदेश में भविष्यवाणी की मजबूती में सुधार करने के लिए मॉडल ensembles का गठन किया. हमारा सिस्टम 0.51 F1 स्कोर, 0.514 परिशुद्धता और 0.514 याद के साथ Subtask बी में पहले स्थान पर है। Subtask A के लिए हमने 0.44 F1 स्कोर, 0.49 परिशुद्धता और 0.39 याद प्राप्त किया और Subtask C के लिए हमने 0.16 परिशुद्धता और 0.17 याद के साथ 0.16 F1 स्कोर प्राप्त किया।', 'ru': 'В этом документе мы представляем наш вклад в совместную задачу «Майнинг социальных сетей для приложений здравоохранения» на 2021 год. Мы рассмотрели все три подзадачи задачи 1: подзадача A (классификация твитов, содержащих неблагоприятные эффекты), подзадача B (извлечение текстовых пролетов, содержащих неблагоприятные эффекты) и подзадача C (разрешение неблагоприятных эффектов). Мы изучили различные предварительно обученные языковые модели на основе трансформаторов и сосредоточились на многозадачной обучающей архитектуре. Для первой подзадачи мы также применили техники состязательного усиления и сформировали модельные ансамбли, чтобы повысить надежность прогноза. Наша система заняла первое место в подзадаче B с оценкой 0,51 F1, точностью 0,514 и отзывом 0,514. Для подзадачи A мы получили оценку 0,44 F1, точность 0,49 и отзыв 0,39, а для подзадачи C мы получили оценку 0,16 F1 с точностью 0,16 и отзыв 0,17.', 'ga': 'Cuireann an páipéar seo i láthair ár rannchuidiú leis an Tasc Comhroinnte um Mhianadóireacht ar na Meáin Shóisialta le haghaidh Feidhmchláir Sláinte 2021. Thugamar aghaidh ar na trí fhothasc go léir de Thasc 1: Fothasc A (aicmiú tweets ina bhfuil éifeachtaí díobhálacha), Fothasc B (asbhaint raonta téacs ina bhfuil éifeachtaí díobhálacha) agus Fothasc C (taifeach éifeachtaí díobhálacha). Rinneamar iniúchadh ar mhúnlaí éagsúla teanga réamh-oilte bunaithe ar chlaochladán agus dhíríomar ar ailtireacht oiliúna il-tasc. Don chéad fhothasc, chuireamar teicníochtaí méadaithe sáraíochta i bhfeidhm freisin agus bhunaíomar samhail-ensembles chun stóinseacht an tuar a fheabhsú. Bhí ár gcóras rangaithe ar dtús ag Fothasc B le 0.51 scór F1, 0.514 beachtas agus 0.514 aisghairm. I gcás Fothasc A fuaireamar 0.44 scór F1, 0.49 beachtas agus 0.39 aisghairm agus le haghaidh Fothasc C fuaireamar 0.16 scór F1 le 0.16 beachtas agus 0.17 aisghairm.', 'ka': 'ეს დოკუმენტი ჩვენი დამატება 2021 წლის სოციალური მედიაში გადამატებული საზოგადოებელი პროგრამებისთვის. ჩვენ ყველა სამუშაო სამუშაო სამუშაო სამუშაო დავწერეთ: A სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო ჩვენ განვიკეთებეთ განსხვავებული პრეტრანსტრენსტრიქტური ენის მოდელები და ჩვენ მრავალური სამუშაო სამუშაო აქტიქტურაციაზე დავყენეთ. პირველი საკითხებისთვის, ჩვენ ასევე გამოყენებდით ნოტერარიალური აგგენტიკაციის ტექნოგიები და ჩვენ შექმნა მოდელის ანსტემბლის შესაძლებელად გავამუშავოთ წინასწორ ჩვენი სისტემა პირველი სამუშაო B წერტილი 0.51 F1 წერტილი, 0.514 წერტილი და 0.514 წერტილი. Subtask A მივიღეთ 0.44 F1 წერტილი, 0.49 წერტილი და 0.39 წერტილი და Subtask C წერტილი მივიღეთ 0.16 F1 წერტილი 0.16 წერტილი და 0.17 წერტილი.', 'el': 'Η παρούσα εργασία παρουσιάζει τη συμβολή μας στην Κοινή Εργασία Εξόρυξης Κοινωνικών Μέσων για Εφαρμογές Υγείας 2021. Εξετάσαμε και τις τρεις δευτερεύουσες εργασίες της εργασίας 1: Υποεργασία Α (ταξινόμηση tweets που περιέχουν δυσμενείς επιπτώσεις), Υποεργασία Β (εξαγωγή περιόδων κειμένου που περιέχουν δυσμενείς επιπτώσεις) και Υποεργασία Γ (επίλυση δυσμενών επιπτώσεων). Ερευνήσαμε διάφορα προ-εκπαιδευμένα μοντέλα γλώσσας βασισμένα σε μετασχηματιστές και εστιάσαμε σε μια αρχιτεκτονική κατάρτισης πολλαπλών εργασιών. Για την πρώτη υποταγή εφαρμόσαμε επίσης τεχνικές αντιπαραβολής και διαμορφώσαμε σύνολα μοντέλων προκειμένου να βελτιωθεί η ανθεκτικότητα της πρόβλεψης. Το σύστημά μας κατατάχθηκε πρώτος στην Υποεργασία Β με βαθμολογία 0.51, ακρίβεια 0.514 και ανάκληση 0.514. Για την Υποεργασία Α πήραμε 0.44 βαθμολογία F1, 0.49 ακρίβεια και 0.39 ανάκληση και για την Υποεργασία Γ πήραμε 0.16 βαθμολογία F1 με 0.16 ακρίβεια και 0.17 ανάκληση.', 'hu': 'Ez a tanulmány bemutatja hozzájárulásunkat a Social Media Mining for Health Applications Shared Task 2021-ben. Az 1. feladat mindhárom alcsoportjával foglalkoztunk: A. altfeladat (káros hatásokat tartalmazó tweetek osztályozása), B. altfeladat (káros hatásokat tartalmazó szövegtartományok kivonása) és C. altfeladat (káros hatások megoldása). Különböző előre képzett transzformátor alapú nyelvi modelleket vizsgáltunk fel, és egy többfeladatos képzési architektúrára összpontosítottunk. Az első részfeladat során ellenfél nagyítási technikákat is alkalmaztunk, és modellegyütteseket alakítottunk ki a jóslat robusztusságának javítása érdekében. Rendszerünk az első helyen állt a B alfeladatban 0,51 F1 pontszámmal, 0,514 pontossággal és 0,514 visszahívással. Az A. alfeladat esetében 0,44 F1 pontszámot, 0,49 pontosságot és 0,39 visszahívást kaptunk, a C. alfeladat esetében pedig 0,16 F1 pontszámot kaptunk 0,16 pontossággal és 0,17 visszahívással.', 'it': "Questo articolo presenta il nostro contributo al Social Media Mining for Health Applications Shared Task 2021. Abbiamo affrontato tutte e tre le sottoattività del Task 1: Sottoattività A (classificazione dei tweet contenenti effetti avversi), Sottoattività B (estrazione di intervalli di testo contenenti effetti avversi) e Sottoattività C (risoluzione degli effetti avversi). Abbiamo esplorato vari modelli linguistici pre-addestrati basati su trasformatori e ci siamo concentrati su un'architettura di formazione multi-task. Per il primo sottotask, abbiamo applicato anche tecniche di augmentazione avversaria e abbiamo formato gruppi di modelli al fine di migliorare la robustezza della previsione. Il nostro sistema si è classificato primo al Subtask B con punteggio F1 0,51, precisione 0,514 e richiamo 0,514. Per Subtask A abbiamo ottenuto 0,44 punti F1, 0,49 precisione e 0,39 richiamo e per Subtask C abbiamo ottenuto 0,16 punti F1 con 0,16 precisione e 0,17 richiamo.", 'kk': 'Бұл қағаз 2021 жылы Ортақ тапсырмалар үшін социалдық медиа балауына қатынасыз береді. Біз 1- тапсырманың үш ішкі суреттерін адрестік: A- тапсырманың субтапсырмасы (қарсы эффекттер бар tweets классификациясы), B- тапсырмасы Біз көптеген алдын- оқылған түрлендіруші тіл үлгілерін зерттеп, көптеген тапсырмаларды оқыту архитектурасына көптеген. Бірінші субсұрақ үшін, біз басқа қарсы жақсы жақсы жасау техникаларын қолдандық және біз үлгісін жасадық. Біздің жүйеміз B Subtask- де 0,51 F1 нүктесі, 0,514 дәл және 0,514 нүктесі бар. Subtask A үшін 0,44 F1 нәтижесін, 0,49 дұрыс және 0,39 нәтижесін қайталадық. Біз C Subtask үшін 0,16 F1 нәтижесін 0,16 дұрыс және 0,17 нәтижесін қайталадық.', 'ml': 'ഈ പത്രത്തില്\u200d സോഷ്യല്\u200d മീഡിയ മിനിങ്ങിന് ഞങ്ങളുടെ പങ്ക് കൊടുക്കുന്നു. ആശ്വാസപ്രയോഗങ്ങള്\u200dക്ക് വേണ്ടി ഞങ്ങള ടാസ്ക് 1-ലെ മൂന്നു സബ്ജുകള്\u200d എല്ലാം ഞങ്ങള്\u200d വിശദീകരിച്ചു: സബ്ബ്ബര്\u200d A (വിരോധപ്രഭാവങ്ങള്\u200d ഉള്\u200dക്കൊള്ളുന്ന ടൂട്ടുകളുടെ വിഭാഗങ്ങള്\u200d), സബ്ബര്\u200dബ്  We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture.  ആദ്യത്തെ സബ്ജിസിന് വേണ്ടി നമ്മളും വിരോധമായ കൂട്ടുവാനുള്ള സാങ്കേതികവിദ്യകള്\u200d പ്രയോഗിച്ചു. പ്രവചനം മുന്\u200dകൂട്ടുവാന്\u200d മോ ഞങ്ങളുടെ സിസ്റ്റം ആദ്യം സുബ്ബ്ബോഗ് ബില്\u200d റെഞ്ച് ചെയ്തു. 0. 51 F1 സ്കോര്\u200d കൊണ്ട്, 0. 514 പ്രിസിഷനും 0. 514 ഓർമ്മ സുബ്ബസ്സ് A-ന് ഞങ്ങള്\u200d 0. 44 F1 സ്കോര്\u200d ലഭിച്ചു, 0. 49 പ്രിസിഷനും 0. 39 ഓര്\u200dമ്മിക്കുന്നു, സുബ്ബസ്സ് സിക്ക് വേണ്ടി 0. 16 F1 സ്കോര്\u200d കിട്ടി', 'mk': 'Овој документ го претставува нашиот придонес за Социјалните медиуми за минирање за здравствени апликации споделена задача 2021 година. Ние ги решивме сите три потпрашања на задачата 1: Субзадача А (класификација на твитови кои содржат негативни ефекти), Субзадача Б (екстракција на текстови кои содржат негативни ефекти) и Субзадача Ц (резолуција на негативни ефекти). Истражувавме различни предобучени јазички модели базирани на трансформатори и се фокусиравме на мултизадачна архитектура за обука. За првата подпрашање, исто така ги применивме техниките на противно зголемување и формиравме моделни ансембли со цел да ја подобриме силноста на предвидувањето. Нашиот систем се рангираше прв на Субзадача Б со 0,51 Ф1 оценка, 0,514 прецизност и 0,514 повлекување. За Субзадача А добивме 0,44 Ф1 оценка, 0,49 прецизност и 0,39 повлекување и за Субзадача Ц добивме 0,16 Ф1 оценка со 0,16 прецизност и 0,17 повлекување.', 'ms': 'This paper presents our contribution to the Social Media Mining for Health Applications Shared Task 2021.  Kami menjalankan semua tiga sub-tanya Tugas 1: Sub-tugas A (klasifikasi tweet yang mengandungi kesan negatif), Sub-tugas B (ekstraksi jangkauan teks yang mengandungi kesan negatif) dan Sub-tugas C (resolusi kesan negatif). Kami mengeksplorasi berbagai-bagai model bahasa berdasarkan pengubah terlatih dan kami fokus pada arkitektur latihan berbilang-tugas. Untuk pertanyaan pertama, kami juga melaksanakan teknik peningkatan musuh dan kami membentuk kumpulan model untuk meningkatkan ketakutan ramalan. Sistem kita berturut-turut di Subtask B dengan skor 0.51 F1, 0.514 ketepatan dan 0.514 pengingatan. For Subtask A we obtained 0.44 F1 score, 0.49 precision and 0.39 recall and for Subtask C we obtained 0.16 F1 score with 0.16 precision and 0.17 recall.', 'mn': 'Энэ цаас 2021 оны Нийгмийн мэдээлэл хөрөнгө оруулалт болон эрүүл мэндийн хэрэглээний хуваалтын ажил дээр бидний нөлөөлөл үзүүлдэг. Бид бүх 3 давхар сургуулиудыг тайлбарласан: Subtask A (сайн нөлөөлөлт дүүрэн буй tweets), Subtask B (сайн нөлөөлөлт дүүрэн текст зай) болон Subtask C (сайн нөлөөлөлт шийдвэрлэлт). Бид сургалтын өмнө сургалтын шилжүүлэгчийн хэл загварыг судалж, олон ажлын сургалтын архитектур дээр төвлөрсөн. Эхний суурь асуултын хувьд бид эсрэг нэмэлт технологийг ашиглаж, таамаглалын хүчтэй байдлыг сайжруулахын тулд загвар бүтээсэн. Бидний систем эхлээд Subtask B-д 0.51 F1 оноо, 0.514 тодорхой, 0.514 тодорхой санагдаж байлаа. Subtask A-д бид 0.44 F1 оноо, 0.49 тодорхой, 0.39 оноо авсан. Subtask C-д 0.16 F1 оноо 0.16 тодорхой, 0.17 оноо авсан.', 'mt': 'Dan id-dokument jippreżenta l-kontribut tagħna għall-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa Kompitu Konġunt 2021. A ħna indirizzajna t-tliet sottomistoqsijiet kollha tal-Kompitu 1: Subkompitu A (klassifikazzjoni ta’ tweets li fihom effetti negattivi), Subkompitu B (estrazzjoni ta’ firxiet ta’ testi li fihom effetti negattivi) u Subkompitu C (riżoluzzjoni ta’ effetti negattivi). Esplorajna diversi mudelli lingwistiċi bbażati fuq trasformaturi mħarrġa minn qabel u ffukajna fuq arkitettura ta’ taħriġ b’ħafna kompiti. Għall-ewwel sottomistoqsija, applikajna wkoll tekniki ta’ żieda avversarja u ffurmajna ġabra ta’ mudelli sabiex itejbu r-robustezza tat-tbassir. Is-sistema tagħna kklassifikat l-ewwel fis-Subtask B b’punteġġ F1 ta’ 0.51, preċiżjoni ta’ 0.514 u rappurtar ta’ 0.514. Għas-Subkompitu A kisbet punteġġ F1 ta’ 0.44, preċiżjoni ta’ 0.49 u ġbid lura ta’ 0.39 u għas-Subkompitu C kisbet punteġġ F1 ta’ 0.16 bi preċiżjoni ta’ 0.16 u ġbid lura ta’ 0.17.', 'pl': 'Niniejszy artykuł przedstawia nasz wkład w realizację wspólnego zadania eksploatacji mediów społecznościowych dla aplikacji zdrowotnych 2021. Zajęliśmy się wszystkimi trzema podzadaniami Zadania 1: Podzadaniem A (klasyfikacja tweetów zawierających efekty niepożądane), Podzadaniem B (ekstrakcja rozdziałów tekstowych zawierających efekty niepożądane) oraz Podzadaniem C (rozwiązywanie efektów niepożądanych). Zbadaliśmy różne wstępnie przeszkolone modele językowe oparte na transformatorach i skupiliśmy się na wielozadaniowej architekturze szkoleniowej. W pierwszym podzadaniu zastosowaliśmy również techniki powiększania przeciwnego oraz tworzyliśmy zespoły modeli w celu poprawy solidności prognozy. Nasz system zajął pierwszy miejsce w podzadaniu B z wynikiem 0.51 F1, precyzją 0.514 i odwołaniem 0.514. Dla podzadania A uzyskaliśmy 0.44 F1 wynik, 0.49 precyzję i 0.39 recall, a dla podzadania C uzyskaliśmy 0.16 F1 wynik z 0.16 precyzją i 0.17 recall.', 'lt': 'Šiame dokumente pristatomas mūsų indėlis į socialinės žiniasklaidos kasybos, skirtos bendroms sveikatos priežiūros paraiškoms, užduotis 2021 m. Mes aptarėme visus tris 1 užduoties papunkčius: A papunktį (tweetų klasifikavimas su nepageidaujamu poveikiu), B papunktį (teksto intervalų ištrauka su nepageidaujamu poveikiu) ir C papunktį (nepageidaujamo poveikio rezoliucija). Mes ištyrėme įvairius iš anksto parengtus transformatoriais pagrįstus kalbų modelius ir sutelkėme dėmesį į daugiafunkcinę mokymo architektūrą. Pirmajam paklausimui taip pat pritaikėme prieštaringo padidinimo metodus ir sukūrėme modelių rinkinius, kad pagerintume prognozės patikimumą. Our system ranked first at Subtask B with 0.51 F1 score, 0.514 precision and 0.514 recall.  Subužduoties A atveju gavome 0,44 F1 tašką, 0,49 tikslumą ir 0,39 atšaukimą, o Subužduoties C atveju gavome 0,16 F1 tašką su 0,16 tikslumu ir 0,17 atšaukimą.', 'ro': 'Această lucrare prezintă contribuția noastră la Social Media Mining for Health Applications Shared Task 2021. Am abordat toate cele trei subsarcini ale Sarcinii 1: Subsarcina A (clasificarea tweeturilor care conțin efecte adverse), Subsarcina B (extragerea intervalelor de text care conțin efecte adverse) și Subsarcina C (rezolvarea efectelor adverse). Am explorat diferite modele lingvistice pre-instruite bazate pe transformatori și ne-am concentrat pe o arhitectură de formare multi-sarcină. Pentru prima subactivitate, am aplicat și tehnici de augmentare adversară și am format ansambluri de modele pentru a îmbunătăți robustețea predicției. Sistemul nostru s-a clasat pe primul loc la Subsarcina B cu scor F1 0.51, precizie 0.514 și rechemare 0.514. Pentru Subsarcina A am obținut 0,44 punctaj F1, 0,49 precizie și 0,39 rechemare, iar pentru Subsarcina C am obținut 0,16 punctaj F1 cu 0,16 precizie și 0,17 rechemare.', 'no': 'Denne papiret viser vårt bidrag til den sosiale mediamineringen for helseprogrammet delt oppgåve 2021. Vi adressere alle tre underspørjingane i oppgåve 1: Subtask A (klassifisering av tweets som inneheld negativ effektar), Subtask B (utpakking av tekstområde som inneheld negativ effektar) og Subtask C (oppløysing av negativ effektar). Vi undersøkte ulike forskjellige språk- modeller som er basert på føretrainerte transformasjonar og vi fokuserte på ein fleire oppgåver- opplæringsarkitektur. For den første underspørjinga, brukte vi også adversariale augmentasjonsteknologikar og vi formerte modellen ensembler for å forbetra kraftigheten av forhåndsvisinga. Systemet vårt rekna først på Subtask B med 0,51 F1- poeng, 0,514- presisjon og 0,514- rekning. For Subtask A fikk vi 0,44 F1- poeng, 0,49- presisjon og 0,39- rekninga og for Subtask C fikk vi 0,16 F1- poeng med 0,16- presisjon og 0,17- rekninga.', 'so': 'Kanu warqaddaas waxay noogu gudbinaysaa daryeelka caafimaadka ee daryeelka caafimaadka ee shaqada 2021. Shaqoyinka 1: Subtask A (fasax of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Sub-task C (adverse effects resolution). Waxaannu baaraannay qaabab kala duduwan oo luuqada isbedelka ee horumarinta ah, waxaynu ku kalsoonaannay dhismaha waxbarashada shaqada badan. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the robustness of the prediction.  Systemkeeni waxay marka ugu horeysay sub-task B with 0.51 F1 score, 0.514 sax iyo 0.514 xusuus. Submission A ayaannu helnay score 0.44 F1, 0.49 sax iyo 0.39 xasuus iyo sub-fudud C ayaannu helnay 0.16 F1 score 0.16 saxda iyo 0.17 xusuus.', 'sr': 'Ovaj papir predstavlja naš doprinos rudarstvu socijalnih medija za zdravstvene aplikacije zajedničkom zadatku 2021. Odrešili smo sve tri podataka zadatka 1: Subtask A (klasifikacija tweeta koji sadrže nuspojave), Subtask B (izvlačenje tekstnih prostora koje sadrže nuspojave) i Subtask C (rezolucija nuspojava). Istražili smo razne predobučene jezičke modele na transformaciji i fokusirali smo se na multi task obuku arhitekture. Za prvi podpitanje, takođe smo primjenjivali i neprijateljske tehnike povećanja i formirali model ensemble kako bi poboljšali robotu predviđanja. Naš sistem je prvi red na Subtask B sa 0,51 F1 rezultata, 0,514 preciznosti i 0,514 sećanja. Za Subtask A dobili smo 0,44 F1 rezultat, 0,49 preciznost i 0,39 sećanja i za Subtask C dobili smo 0,16 F1 rezultat sa 0,16 preciznosti i 0,17 sećanja.', 'sv': 'Denna uppsats presenterar vårt bidrag till Social Media Mining for Health Applications Shared Task 2021. Vi behandlade alla tre underuppgifterna i Uppgift 1: Underuppgift A (klassificering av tweets som innehåller negativa effekter), Underuppgift B (extraktion av textintervall som innehåller negativa effekter) och Underuppgift C (lösning av negativa effekter). Vi utforskade olika förklädda transformatorbaserade språkmodeller och fokuserade på en multi-task utbildningsarkitektur. För den första deluppgiften tillämpade vi även motstridiga augmentationstekniker och bildade modellenensembler för att förbättra förutsägelsens robusthet. Vårt system rankades först på Subtask B med 0,51 F1 poäng, 0,514 precision och 0,514 återkallelse. För Subtask A fick vi 0,44 F1 poäng, 0,49 precision och 0,39 återkallelse och för Subtask C fick vi 0,16 F1 poäng med 0,16 precision och 0,17 återkallelse.', 'si': 'මේ පත්තු අපේ සමාජික මිඩියාව ප්\u200dරධානයේ සාමාජික විද්\u200dයාපකයේ සාමාන්\u200dය විද්\u200dයාපකයේ කාර්ය 2021 වැ අපි සියළුම වැඩ 1 ගැන සියළුම තුනක් ප්\u200dරශ්නයක් ලැබුනා: Subjob A (classification of tweets with adverse Efects), Subjob B (extraction of text spans with adverse Efects) and Subjob C (adverse Efects resolution). අපි විවිදිහට ප්\u200dරශ්නයක් කරලා තියෙන්නේ ප්\u200dරශ්නයක් විදිහට භාෂා මොඩල් කරලා අපි ගොඩක් වැඩි වැඩි වැඩි  මුලින්ම ප්\u200dරශ්නයක් වෙනුවෙන්, අපි විරෝධ විශ්වාසික විද්\u200dයාප්\u200dරශ්නයක් පරීක්ෂණය කරලා තියෙන්නේ. අපි ප්\u200dරශ අපේ පද්ධතිය මුලින්ම ප්\u200dරධාන B වල ස්ථානය කරන්නේ 0.51 F1 ප්\u200dරධානය, 0.514 ප්\u200dරධානය සහ 0.514 මතකයි. Sub-job A වෙනුවෙන් අපිට 0.44 F1 ස්කෝර් ගත්තා, 0.49 ස්කෝරිස් සහ 0.39 ස්කෝර් ගත්තා, සබ් වැඩ C වෙනුවෙන් අපිට 0.16 F1 ස්කෝර් ගත්තා, 0.16 ස්කෝ', 'ta': 'இந்த காகிதத்தில் எங்கள் செயல்பாடு 2021 பகிர்ந்து செய்யப்பட்டுள்ளது சாலிக ஊடகங்கள் நினைவு கூறுகிறது. பணியின் மூன்று துணை பணிகளையும் நாம் முகவரியிட்டோம் 1: Subtask A (எதிர்மறை விளைவுகள் உள்ள Tweets containing வகைப்படுத்தல்), Subtask B (எதிர்மறை விளைவுகள் உள்ள உரை இடைவெளிய நாங்கள் முன்பயிற்சி மாற்றும் மொழி மாற்றும் மாதிரிகளை கண்டறிந்தோம் மற்றும் நாங்கள் பல பணிகள் பயிற்சி அமைப்பு  முதல் துணை பணிக்கு, நாங்கள் எதிரியான மேம்படுத்தல் தொழில்நுட்பத்தை பயன்படுத்தி மாதிரி குறிப்புகளை மேம்படுத்தினோம். 0. 51 F1 மதிப்பு, 0. 514 துல்லியம் மற்றும் 0. 514 நினைவு A துணை பணிக்கு 0. 44 F1 மதிப்பெண்ணை பெற்றோம், 0. 49 துல்லியம் மற்றும் 0. 39 நினைவு மற்றும் துணை செயல் C நாம் 0. 16 F1 மதிப்பு 0. 16 துல்லியம் மற்', 'ur': 'یہ کاغذ 2021 کے شریک ٹاکس کے لئے سوسیل میڈیا مینینگ کے ذریعے ہمارا حصہ پیش کرتا ہے. ہم نے Task 1 کے تمام تین سوٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ س ہم نے مختلف پیش آموزش کی تغییر دینے والی زبان کی مدل کی مطالعہ کی اور ہم نے ایک multi-task تغییر معماری پر تمرکز کیا۔ پہلی دفتر پوچھنے کے لئے ہم نے بھی مخالف افزایش تکنیک کاروبار کیا اور ہم نے مدل بنایا تاکہ پیش بینی کی قوت کو بہتر کریں۔ ہمارا سیستم اول سرٹاکس B میں 0.51 F1 سکوٹ، 0.514 دقیق اور 0.514 یاد کرنا تھا. Subtask A کے لئے ہم نے 0.44 F1 اسکور، 0.49 دقیق اور 0.39 دقیق حاصل کی اور Subtask C کے لئے ہم نے 0.16 F1 اسکور کو 0.16 دقیق اور 0.17 دقیق حاصل کی۔', 'uz': "Bu sahifa 2021 Vazifani boshqarishga yordam beradigan jamiyat media xizmatiga qarang. Biz Vazifaning uchta vazifalarning hammasini boshqardik 1: Subtask A (toʻliq effektlar bilan Twitterlarni classifash), Subtask B (toʻgʻri effektlar bilan matn spanlarni chiqarish) va Subtask C (toʻliq effektlar toʻplami). Biz bir necha taʼminlovchi o'zgarishni o'rganishdan oldin o'zgartirish modellarini qidirib, va biz bir necha vazifa ta'minlovchi arkitektikasiga foydalandik. Birinchi tub vazifa uchun biz qo'shish tugmalarini qo'llab berdik va biz kutilgan hozirga o'zgartirish uchun model foydalanishni yaratdik. Our system ranked first at Subtask B with 0.51 F1 score, 0.514 precision and 0.514 recall.  Ushbu vazifa A uchun 0.44 F1 scori, 0.49 murakkab va 0.39 xotira topdik va Bu vazifa C uchun 0.16 F1 scori 0.16 murakkab va 0.17 xotira topdik.", 'vi': 'Tờ giấy này giới thiệu sự đóng góp của chúng ta cho tổ chức Tư liệu sức khỏe chia sẻ Nhiệm vụ 2021. Chúng tôi đã xem qua ba phần nhỏ của Nhiệm vụ 1: Tinh yêu A (phân loại các tweet có các hiệu ứng tiêu cực), Tinh cầu B (khai thác các chi tiết văn bản có các hiệu ứng tiêu cực) và Tinh cầu C (giải quyết các hiệu ứng tiêu cực). Chúng tôi đã tìm hiểu các mô hình ngôn ngữ cơ bản đã được huấn luyện trước và tập trung vào kiến trúc đào tạo đa nhiệm. Đối với yêu cầu đầu tiên, chúng tôi cũng áp dụng các kỹ thuật gia tăng ngược nhau và chúng tôi thành lập các kết hợp mô hình để cải thiện tính bền vững của dự đoán. Hệ thống của chúng ta được xếp hạng đầu tiên ở Subask B với 0.51 F1 score, 0.514 accurance và 0.514 recreation. Đối với Subask A chúng tôi thu được 0.44 F1 số lượng, 0.42 chính xác và 0.39 còn gọi lại và cho giấu C chúng tôi thu được 0.16 số F1 với 0.16 chính xác và ghi lại 0.17.', 'bg': 'Настоящата статия представя нашия принос към съвместната задача "Социални медии за здравни приложения 2021". Разгледахме трите подзадачи на задача 1: Подзадача А (класификация на туитове, съдържащи нежелани ефекти), Подзадача Б (извличане на текстови интервали, съдържащи нежелани ефекти) и Подзадача В (разрешаване на нежеланите ефекти). Проучихме различни предварително обучени езикови модели, базирани на трансформатори, и се фокусирахме върху многофункционална архитектура за обучение. За първата подзадача приложихме и техники на контрагентарно усилване и образувахме моделни ансамбли, за да подобрим здравината на прогнозирането. Нашата система се класира на първо място в Подзадача Б с 0,51 оценка Ф1, 0,514 прецизност и 0,514 отзоваване. За подзадача А получихме 0,44 оценка Ф1, 0,49 прецизност и 0,39 повторение, а за подзадача С получихме 0,16 оценка Ф1 с точност 0,16 и повторение 0,17.', 'da': 'Denne artikel præsenterer vores bidrag til Social Media Mining for Health Applications Shared Task 2021. Vi behandlede alle tre underopgaver i Opgave 1: Underopgave A (klassificering af tweets indeholdende bivirkninger), Underopgave B (udtrækning af tekstspænder indeholdende bivirkninger) og Underopgave C (opløsning af bivirkninger). Vi udforskede forskellige prætrænede transformer-baserede sprogmodeller og fokuserede på en multi-task træningsarkitektur. Til den første underopgave anvendte vi også adversarial augmentation teknikker og vi dannede model ensembler for at forbedre robustheden af forudsigelsen. Vores system rangerede første på Subtask B med 0,51 F1 score, 0,514 præcision og 0,514 tilbagekaldelse. For subopgave A opnåede vi 0,44 F1 score, 0,49 præcision og 0,39 tilbagekaldelse og for subopgave C opnåede vi 0,16 F1 score med 0,16 præcision og 0,17 tilbagekaldelse.', 'hr': 'Ovaj papir predstavlja naš doprinos rudarstvu društvenih medija za zajednički zadatak 2021. godine. Objavili smo sve tri podataka zadatka 1: Podataka A (klasifikacija tweets sadržajući nuspojave), podzadatak B (izvlačenje tekstnih mjesta sadržajući nuspojave) i podzadatak C (rezolucija nuspojava). Istražili smo razne predobučene jezičke modele na transformaciji i fokusirali smo se na multizadatačnu arhitekturu obuke. Za prvi podpitanje, također smo primjenjivali neprijateljske tehnike povećanja i formirali model ensemble kako bi poboljšali robotu predviđanja. Naš sustav je prvi red na subtask B sa 0,51 F1 rezultata, 0,514 preciznosti i 0,514 sjećanja. Za Subtask A dobili smo 0,44 F1 rezultat, 0,49 preciznost i 0,39 sjećanja i za Subtask C dobili smo 0,16 F1 rezultat sa 0,16 preciznosti i 0,17 sjećanja.', 'nl': 'Deze paper presenteert onze bijdrage aan de Social Media Mining for Health Applications Shared Task 2021. We hebben alle drie de subtaken van Taak 1 behandeld: Subtaak A (classificatie van tweets met bijwerkingen), Subtaak B (extractie van tekstsegmenten met bijwerkingen) en Subtaak C (oplossing van bijwerkingen). We hebben verschillende vooraf getrainde transformatorgebaseerde taalmodellen onderzocht en ons gefocust op een multi-task trainingsarchitectuur. Voor de eerste subtaak hebben we ook adversaire augmentatietechnieken toegepast en modellensembles gevormd om de robuustheid van de voorspelling te verbeteren. Ons systeem scoorde als eerste bij Subtask B met 0.51 F1 score, 0.514 precisie en 0.514 recall. Voor Subtaak A kregen we 0.44 F1 score, 0.49 precisie en 0.39 recall en voor Subtaak C kregen we 0.16 F1 score met 0.16 precisie en 0.17 recall.', 'de': 'Dieser Beitrag stellt unseren Beitrag zum Social Media Mining for Health Applications Shared Task 2021 vor. Wir haben alle drei Teilaufgaben von Aufgabe 1 angesprochen: Teilaufgabe A (Klassifizierung von Tweets mit negativen Auswirkungen), Teilaufgabe B (Extraktion von Textabschnitten mit negativen Auswirkungen) und Teilaufgabe C (Auflösung von Nebenwirkungen). Wir untersuchten verschiedene vortrainierte transformatorbasierte Sprachmodelle und konzentrierten uns auf eine Multi-Task-Trainingsarchitektur. Für den ersten Teilauftrag haben wir auch adversariale Augmentationstechniken angewendet und Modellensembles gebildet, um die Robustheit der Vorhersage zu verbessern. Unser System rangierte bei Subtask B mit 0.51 F1 Score, 0.514 Präzision und 0.514 Rückruf an erster Stelle. Für Subtask A erhielten wir 0.44 F1 Score, 0.49 Präzision und 0.39 Rückruf und für Subtask C 0.16 F1 Score mit 0.16 Präzision und 0.17 Rückruf.', 'id': 'Kertas ini memperlihatkan kontribusi kami ke Media Sosial Menjemainkan untuk Aplikasi Kesehatan Bersama Tugas 2021. Kami mengatasi semua tiga subtasks dari Tugas 1: Subtask A (klasifikasi tweet yang mengandung efek negatif), Subtask B (ekstraksi jangkauan teks yang mengandung efek negatif) dan Subtask C (resolusi efek negatif). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture.  For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the robustness of the prediction.  Our system ranked first at Subtask B with 0.51 F1 score, 0.514 precision and 0.514 recall.  Untuk Subtask A kami mendapatkan skor 0.44 F1, 0.49 presisi dan 0.39 recall dan untuk Subtask C kami mendapatkan skor 0.16 F1 dengan 0.16 presisi dan 0.17 recall.', 'ko': '본고는 2021년 건강 응용 공유 미션인 소셜미디어 발굴에 기여한 바를 소개한다.우리는 임무 1의 세 가지 하위 임무: 하위 임무 A(부정적인 영향을 포함하는 추문 분류), 하위 임무 B(부정적인 영향을 포함하는 텍스트 범위 추출)와 하위 임무 C(부정적인 영향 해결)를 해결했다.우리는 각종 미리 훈련된transformer 기반의 언어 모델을 탐색하고 다중 임무 훈련 체계 구조에 전념했다.첫 번째 하위 임무에 대해 우리는 대항성 강화 기술을 응용하고 모델 집합을 형성하여 예측의 안정성을 높였다.우리 시스템은 하위 퀘스트 B에서 1위를 차지했고 F1은 0.51점, 정확도는 0.514, 리콜률은 0.514였다.하위 작업 A의 경우 0.44 F1 점수, 0.49 정밀도와 0.39 리콜율을 얻었고, 하위 작업 C의 경우 0.16 F1 점수, 0.16 정밀도와 0.17 리콜율을 얻었습니다.', 'fa': 'این کاغذ مشترک ما را به وزارت رسانه\u200cهای اجتماعی برای کارهای مشترک سلامتی 2021 نشان می\u200cدهد. ما تمام سه پاسپاسهای کار ۱ را درباره\u200cی پاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاسپاس ما مدل\u200cهای زبان\u200cهای پیش آموزش آموزش\u200cهای مختلف را کشف کردیم و روی یک معماری آموزش زیادی از کار تمرکز کردیم. برای اولین سوپرسی، ما نیز تکنیک افزایش دشمنی را اجرا کردیم و مدل را برای افزایش قوت پیش بینی ساختیم. سیستم ما اولین بار در Subtask B با امتیاز 0.51 F1، دقیق 0.514 و یادآوری 0.514 بود. برای Subtask A امتیاز 0.44 F1، دقیق 0.49 و یادآوری 0.39 و برای Subtask C امتیاز 0.16 F1 را با دقیق 0.16 و یادآوری 0.17 دریافت کردیم.', 'sw': 'Makala hii inaonyesha mchango wetu wa Vyombo vya Habari vya kijamii kwa ajili ya matumizi ya Afya ilishirikishwa kazi 2021. Tulijadili kazi tatu za Kazi 1: Subtask A (classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (resolution adverse effects). Tuligundua mifano mbalimbali ya mabadiliko ya lugha yenye msingi wa zamani na tulijikita kwenye ujenzi wa mafunzo ya kazi nyingi. Kwa jukumu la kwanza, pia tulitumia mbinu za kuongeza upinzani na tukatengeneza mifano ili kuboresha ubora wa utabiri. Mfumo wetu ulikuwa wa kwanza kwenye kazi B yenye score 0.51 F1, sawa 0.514 na kumbukumbu 0.514. Kwa kazi A tulipata score 0.44 F1, sahihi 0.49 na kumbukumbu 0.39 na kwa ajili ya Ujumbe C tulipata score 0.16 F1 yenye urefu 0.16 na kukumbuka 0.17.', 'tr': "Bu häzir soýunlar Medýdançalary Saýlaw Uyglamalary Saýlaw Görevi 2021-nji ýylda gurnaklarymyzy görkezýär. Biz 1 görev üç sütünleri adrese etdik: Subtask A (negatif eserler içeren tweets klasifikasyonu), Subtask B (negatif eserler içeren metin sütünlerini) ve Subtask C (negatif eserler çözümlemesi). Biz birnäçe öň-bilim terjime edilen dil nusgalaryny keşfetdik we bir multi-täbli arhitektura üns berdik. Ilkinji alt soragy üçin, biz hem tehdit wajyplaşma teknikleri uyguladyk we öngörümdeki güýçligi geliştirmek üçin örnek düzenledik. Biziň sistemimiz Subtask B'de ilkinji gezek 0.51 F1 अ, 0.514 dogry we 0.514 ýadyň. Subtask A üçin 0.44 F1 अ, 0.49 takyk we 0.39 we Subtask C üçin 0.16 F1 अ'y 0.16 we 0.17 ýatlamak üçin aldık.", 'am': 'ይህም ገጽ ለጤና ፕሮግራሞች ለጤናዊ ፕሮግራሞች ለስራ 2021 የተሳካ ማኅበራዊ ሚዲያ አካባቢነታችንን ያቀርባል፡፡ የስራ ሁሉ ሦስቱን ደብዳቤዎች አቀረብን፡፡ የቀድሞው ተማሪዎች የቋንቋ ምሳሌዎችን መረመርን እናም በብዙ ስራ ማህበረሰብ አካባቢ ላይ አየን፡፡ ለመጀመሪያው ደብዳቤ፣ በተቃዋሚ አካባቢ ስልጣናዎችን እና የትንቢት ሽፋን እንዲያበጅል ሞዴል ምሳሌዎችን አሠራን፡፡ ስርዓታችን በመጀመሪያ በመስኮት B በ0.51 F1 score, 0.514 ትክክለኛ እና 0.514 ማስታወስ ነው፡፡ ለSubmission A score 0.44 F1 score, 0.49 ትክክለኛ እና 0.39 ማስታወስ አግኝተናል ለSubmission C 0.16 F1 score በ0.16 ትክክለኛ እና 0.17 ማስታወስ አግኝተናል።', 'af': "Hierdie papier stel ons bydraag aan die sosiale media-mining vir gesondige toepassings gedeelde taak 2021. Ons het al die drie subtaske van Taak 1 adreseer: Subtask A (klasifikasie van tweets bevat nuwe effekte), Subtask B (uitpakking van teks spans bevat nuwe effekte) en Subtask C (nuwe effekte oplossing). Ons het verskeie vooraf-onderwerp transformeerder-gebaseerde taal modele uitgesoek en ons fokus op 'n multi-taak-onderwerp-arkitektuur. Vir die eerste subvraag, het ons ook teëstanderse vergroot teknike aangewend en ons formeer model ensembles om die kragtigheid van die voorskou te verbeter. Ons stelsel het eerste rangeer by Subtaak B met 0. 51 F1 telling, 0. 514 presisie en 0. 514 reken. Vir Subtask A het ons 0.44 F1 telling ontvang, 0.49 presisie en 0.39 rekening en vir Subtask C het ons 0.16 F1 rekening ontvang met 0.16 presisie en 0.17 rekening.", 'sq': 'Ky dokument paraqet kontributin tonë në Minierën e Mediave Sociale për Aplikatat e Përbashkëta të Shëndetësisë 2021. Ne i kemi trajtuar të tre nëndetyrat e Task 1: Subtask A (klasifikimi i tweeteve që përmban efekte të dëmshme), Subtask B (nxjerrje e intervaleve teksti që përmban efekte të dëmshme) dhe Subtask C (zgjidhje e efekteve të dëmshme). Kemi eksploruar modele të ndryshme gjuhësh të trajnuara në bazë të transformuesve dhe u përqëndruam në një arkitekturë trajnimi me shumë detyra. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the robustness of the prediction.  Sistemi ynë u rendit i pari në Subtask B me 0.51 rezultat F1, 0.514 saktësi dhe 0.514 tërheqje. Për Subtask A kemi marrë 0.44 rezultat F1, 0.49 saktësi dhe 0.39 tërheqje dhe për Subtask C kemi marrë 0.16 rezultat F1 me 0.16 saktësi dhe 0.17 tërheqje.', 'bs': 'Ovaj papir predstavlja naš doprinos rudarstvu društvenih medija za zajednički zadatak 2021. godine. Objavili smo se svim tri podataka zadatka 1: Subtask A (klasifikacija tweets sadržajući nuspojave), Subtask B (izvlačenje tekstnih prostora sadržajući nuspojave) i Subtask C (rezolucija nuspojava). Istražili smo razne predobučene jezičke modele na transformaciji i fokusirali smo se na multi task obuku arhitekture. Za prvi podpitanje, također smo primjenjivali neprijateljske tehnike povećanja i formirali model ensemble kako bi poboljšali robotu predviđanja. Naš sistem je prvi red na subtask B sa 0,51 F1 rezultata, 0,514 preciznosti i 0,514 sjećanja. Za Subtask A dobili smo 0,44 F1 rezultat, 0,49 preciznost i 0,39 sjećanja i za Subtask C dobili smo 0,16 F1 rezultat sa 0,16 preciznosti i 0,17 sjećanja.', 'hy': "Այս աշխատանքը ներկայացնում է մեր ներդրումը 2021 թվականին ընդհանուր առողջապահության ծրագրերի սոցիալական լրատվամիջոցների հանքագործման համար: Մենք դիտարկեցինք առաջադրանքի բոլոր երեք ենթախնդիրները' ենթախնդիր Ա (թվիթերի դասակարգման, որը պարունակում է բացասական ազդեցություններ), ենթախնդիր Բ Մենք ուսումնասիրեցինք տարբեր նախապատրաստված լեզվային մոդելներ, որոնք հիմնված են վերափոխողների վրա և կենտրոնացանք բազմախնդիրների ուսումնասիրության ճարտարապետության վրա: Առաջին ենթահարցի համար մենք նաև կիրառեցինք հակառակ աճի տեխնիկաներ և ձևավորեցինք մոդելներ, որպեսզի բարելավենք կանխատեսման ուժեղությունը: Մեր համակարգը առաջինը դասակարգում էր Բ-ի ենթախնդրի մեջ՝ 0.51 F1 գնահատականով, 0.514 ճշգրտությամբ և 0.514 հիշեցումներով: Սենթախնդիր A-ի համար մենք ստացանք 0.44 F1 գնահատականներ, 0.49 ճշգրտություն և 0.39 հիշեցումներ, իսկ Սենթախնդիր C-ի համար մենք ստացանք 0.16 F1 գնահատականներ 0.16 ճշգրտությամբ և 0.17 հիշեցումներ:", 'ca': "Aquest paper presenta la nostra contribució a la tasca compartida de la mineria dels mitjans socials per aplicacions sanitàries 2021. Vam abordar totes les tres subtaskes de la tasca 1: Subtasca A (classificació de tweets que contenen efectes adversos), Subtasca B (extracció de textos que contenen efectes adversos) i Subtasca C (resolució d'efectes adversos). Vam explorar diversos models de llenguatge pré-entrenats basats en transformadors i ens vam centrar en una arquitectura de formació multitasca. Per la primera subterrània, també vam aplicar tècniques d'augmentació adversaria i vam formar conjunts de models per millorar la robustet de la predicció. El nostre sistema es va classificar primer a la Subtasca B amb 0,51 puntuació F1, 0,514 precisió i 0,514 recuperacions. For Subtask A we obtained 0.44 F1 score, 0.49 precision and 0.39 recall and for Subtask C we obtained 0.16 F1 score with 0.16 precision and 0.17 recall.", 'bn': 'এই পত্রিকাটি স্বাস্থ্য অ্যাপ্লিকেশনের জন্য সামাজিক মিডিয়া মিনিয়ায় আমাদের অবদান প্রদান করেছে ২০২১ সালে শ আমরা কাজের সকল তিনটি সাবটাকাজের কথা আলোচনা করেছি: সাবটাস এ (বিভিন্ন প্রভাব রয়েছে টুইটের বিভিন্ন বিভিন্ন বিভিন্ন টুইট), সাবটাব বি (বিভিন্ন প্রভাব রয় আমরা বিভিন্ন প্রশিক্ষণের পূর্ব পরিবর্তনের ভিত্তিক ভাষার মডেল খুঁজে বের করেছি এবং আমরা বহুকাজের প্রশিক্ষণের কাঠামোর প্রথম সাবট্যাকাজের জন্য আমরা বিরোধী প্রযুক্তি প্রযুক্তি প্রয়োগ করেছি এবং ভবিষ্যতের রাস্তা উন্নত করার জন্য আমরা মডেল বানিয়েছি। আমাদের সিস্টেম প্রথম সাবাক্ষাৎকার বিতে প্রাথমিক স্কোর, 0. 514 পলিসিটি এবং 0. 514 স্মৃতি স্মরণ করে। For Subtask A we obtained 0.44 F1 score, 0.49 precision and 0.39 recall and for Subtask C we obtained 0.16 F1 score with 0.16 precision and 0.17 recall.', 'cs': 'Tento článek představuje náš příspěvek k těžbě sociálních médií pro zdravotní aplikace Shared Task 2021. Řešili jsme všechny tři podúkoly Úkolu 1: Podúkol A (klasifikace tweetů obsahujících nežádoucí účinky), Podúkol B (extrakce textových rozpětí obsahujících nežádoucí účinky) a Podúkol C (řešení nežádoucích účinků). Prozkoumali jsme různé předškolené jazykové modely založené na transformátorech a zaměřili jsme se na víceúkolovou architekturu školení. Pro první dílčí úkol jsme také aplikovali techniky adversariální augmentace a vytvořili modelové soubory, abychom zlepšili robustnost predikce. Náš systém se v Subtasku B dostal na první místo s 0.51 F1 skóre, 0.514 přesností a 0.514 stažení. Pro Subúlohu A jsme získali 0.44 F1 skóre, 0.49 přesnost a 0.39 stažení a pro Subúlohu C jsme získali 0.16 F1 skóre s 0.16 přesností a 0.17 stažení.', 'et': 'Käesolevas artiklis tutvustatakse meie panust sotsiaalmeedia kaevandamisse tervishoiu rakenduste jagatud ülesandeks 2021. Käsitlesime 1. ülesande kõiki kolme alamülesannet: alamülesanne A (kõrvaltoimeid sisaldavate säutsude klassifitseerimine), alamülesanne B (kõrvaltoimeid sisaldavate tekstivahemike ekstraheerimine) ja alamülesanne C (kõrvaltoimeid sisaldavate tekstivahemike lahendamine). Uurisime erinevaid eelnevalt koolitatud transformaatoril põhinevaid keelemudeleid ja keskendusime mitmeülesandelisele koolituse arhitektuurile. Esimese alamülesande puhul rakendasime ka vastastikuse suurendamise tehnikaid ja moodustasime mudeliansembleid, et parandada prognoosi stabiilsust. Meie süsteem sai alaülesandes B esimese koha 0,51 F1 skooriga, 0,514 täpsusega ja 0,514 tagasikutsumisega. Alaülesande A puhul saime 0,44 F1 skoori, 0,49 täpsuse ja 0,39 tagasikutsumise ning alaülesande C puhul saime 0,16 F1 skoori täpsusega 0,16 ja tagasikutsumisega 0,17.', 'fi': 'Tässä artikkelissa esitellään panoksemme sosiaalisen median kaivostoimintaan terveyssovellusten yhteiseen tehtävään 2021. Käsittelimme kaikkia tehtävän 1 kolmea alatehtävää: alatehtävä A (haitallisia vaikutuksia sisältävien twiittien luokitus), alatehtävä B (haitallisia vaikutuksia sisältävien tekstialueiden erottaminen) ja alatehtävä C (haitallisten vaikutusten ratkaisu). Tutkimme erilaisia esikoulutettuja muuntajapohjaisia kielimalleja ja keskityimme monitehtävän koulutusarkkitehtuuriin. Ensimmäisessä osatehtävässä sovelsimme myös kontrastiaalisia augmentaatiotekniikoita ja muodostimme mallikokonaisuuksia ennustuksen kestävyyden parantamiseksi. Järjestelmämme sijoittui ensimmäiseksi alatehtävässä B 0,51 F1 pisteellä, 0,514 tarkkuudella ja 0,514 takaisinkutsulla. Alatehtävässä A saavutimme 0,44 F1-pisteen, 0,49 tarkkuuden ja 0,39 takaisinkutsun ja alatehtävässä C saavutimme 0,16 F1-pisteen tarkkuudella ja 0,17 takaisinkutsun.', 'az': "Bu kağıt 2021. ilə paylaşılmış iş Sosyal Media Mining üçün Sağlamlıq Uygulamaları üçün bizim işimizi göstərir. Biz bütün 3 Sub-askerləri 1-ni təsdiqlədik: Subtask A (təsirli etkiler içərisində olan tweets klasifikasyonu), Subtask B (təsirli etkiler içərisində metin alanları çıxardırmaq) və Subtask C (təsirli etkiler çəkilməsi). Biz müxtəlif əvvəl təhsil edilmiş transformer dili modellərini keşfetmişdik və çoxlu işin təhsil edici arhitektura odaklandıq. İlk dəyişiklik üçün, həmçin in düşmənçilik artırma tekniklərini də uyguladıq və tədbirlərin gücünü artırmaq üçün modellər yaratdıq. Sistemimiz ilk dəfə Subtask B'də 0,51 F1 dəfə, 0,514 dəfə və 0,514 yada saldı. Subtask A üçün 0.44 F1 nöqtəsi, 0.49 nöqtəsi və 0.39 nöqtəsi qəbul etdik və Subtask C üçün 0.16 F1 nöqtəsi 0.16 nöqtəsi və 0.17 nöqtəsi qəbul etdik.", 'jv': 'Perintah iki bakal nggawe bener menyang kamu nggawe Ngubah Media Media Minggu kanggo Aplikasi kanggo Sak Jaakan Taaksi 2020 1 task 1 Awak dhéwé éntuk akeh akeh sistem sing sampeyan luwih transformer-sampeyan ugar lan gepeke nggawe barang sistem multi-task atuaman. Awak dhéwé éntuk aksi perusahaan, kita nguasai tékno aksi ngono nggawe model model sing apik dhéwé nggawe ngubah aturan sing beraksi padha apik dhéwé. Sistem dhéwé wis digawe perusahaan ing Subtask B karo 0.31 F1 puntuan, 0.14 puntuan lan 0.14 puntuan Terus Subtask A we luwih dumaten 0.4 F1 puntuan, 0.49 dadi lan 0.49 dadi gawe lan para Subtask C kita terus 0.16 F1 puntuan karo 0.16 dadi apik lan 0.16 dadi gawe ngupakan.', 'ha': "Wannan takardan na gauraya mataimakanmu zuwa al'amarin na Jamii Media Mining for Header Applikations Shared Takar 2021. Mun yi addu'a da duk takardan aikin aikin 1: Subaikin A (classified Twitter mai ƙunsa da haske-aiki), Subaikin B (fitarwa matsayin da ke ƙunsa da haske-aiki) da Subaikin C (rabo-fassarar aiki). Ba mu sami misãlai masu yin ta'urar da za'a samar da shi a gabãni, kuma muka yi makini a kan matsayin mulki-aikin. Ga na farkon aikin na farko, za'a yi amfani da takwiki masu motsi kuma muka sami misalin misãlai dõmin ya kyautata surori na bayani. Tsarinmu ya ranar ta farkon a Subaikin B da 0.51 F1 score, 0.514 taƙala da 0.514 daidai. Ga Subaikin A, mun sãmu score 0.44 F1, 0.49 taƙaitacce da 0.39 tunar kuma dõmin Subaikin C, mun sãmi score 0.16F1 da 0.16taƙalumiya da 0.17 za'a tuna.", 'sk': 'Ta prispevek predstavlja naš prispevek k skupni nalogi socialnih medijev rudarjenja za zdravstvene aplikacije 2021. Obravnavali smo vse tri podnaloge naloge 1: podnaloga A (klasifikacija tweetov, ki vsebujejo neželene učinke), podnaloga B (ekstrakcija besedilnih razponov, ki vsebujejo neželene učinke) in podnaloga C (reševanje neželenih učinkov). Raziskovali smo različne vnaprej usposobljene transformatorske jezikovne modele in se osredotočili na večopravilno arhitekturo usposabljanja. Za prvo podnalogo smo uporabili tudi kontradikatne tehnike avgmentacije in oblikovali modelne ansambele, da bi izboljšali robustnost napovedi. Naš sistem se je uvrstil na prvo mesto v podnalogo B z rezultatom 0,51 F1, natančnostjo 0,514 in odpoklicem 0,514. Za podnalogo A smo dobili 0,44 oceno F1, 0,49 natančnost in 0,39 odpoklic, za podnalogo C pa smo dobili 0,16 oceno F1 z 0,16 natančnostjo in 0,17 odpoklic.', 'he': 'העיתון הזה מציג את התרומה שלנו למכרת התקשורת החברתית לתוכניות בריאות משותפת משימה 2021. התייחסנו לכל שלושת השאלות של משימה 1: Subtask A (שיעור של טוויטים שמכילים תופעות שליליות), Subtask B (חיפוש של שטח טקסט שמכיל תופעות שליליות) ו Subtask C (פיתרון תופעות שליליות). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture.  לשאלה הראשונה, שימשנו גם טכניקות גידול יריבית ויצרנו אסמבלים דוגמנים כדי לשפר את החזקה של החזוי. המערכת שלנו התייצבה ראשונה ב Subtask B עם 0.51 נקודת F1, 0.514 מדויקה ו 0.514 חזרה. עבור Subtask A השגנו 0.44 ציון F1, 0.49 מדויק ו 0.39 חזרה ובעבור Subtask C השגנו 0.16 ציון F1 עם 0.16 מדויק ו 0.17 חזרה.', 'bo': 'ཤོག ང་ཚོས་Task 1:Subtask A(classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (adverse effects resolution). ང་ཚོས་སྔོན་གྲངས་སྒྲིག་འཛིན་གྱི་འགྱུར་བ་མིན་པའི་སྐད་ཡིག་གཟུགས་རྩལ་བ་མང་ཙམ་ལ་བསླབ་པའི་སྒྲིག་འགོད་ལ་བ ང་ཚོས་དང་པོ་མཇུག་གི་རྗེས་སུ་འབྲི་བར་ན། འུ་ཅག་གིས་ཟུར་བ་ཆ་རྐྱེན་གྱི་ཐབས་ལམ་ལ་ཉེན་སྤྱོད་བྱས་པ་དང་ངེད་ཚོས་རྐྱེ ང་ཚོའི་མ་ལག་གི་ཚད་ལྡན་པ་དང་པོ་རྣམས་Subtask B་ལ་འཇུག་ཡོད། 0.51 F1 རིམ་པ་དང་ 0.514 ཁྱབ་ཚད་དང་ 0.514 དྲན་འཛུགས་ཡོད། Subtask A འུ་ཅག་གིས་0.44 F1 རིམ་དང་། 0.49 རིམ་ཐང་དང་། 0.39 རིམ་དཔྱད་སྐོར་ཡོད། Subtask C ཞིག་ལ་0.16 F1 རིམ་ཐང་དང་། 0.16 རིམ་ཐང་དང་། 0.17 དྲན་འཛིན་ཡོད།'}
{'en': 'UACH-INAOE at SMM4H : a BERT based approach for classification of COVID-19 Twitter posts UACH - INAOE  at  SMM 4 H : a  BERT  based approach for classification of  COVID -19  T witter posts', 'ar': 'UACH-INAOE at SMM4H: نهج قائم على BERT لتصنيف مشاركات Twitter الخاصة بـ COVID-19', 'fr': 'UACH-INAOE au SMM4H\xa0: une approche basée sur le BERT pour la classification des publications Twitter COVID-19', 'es': 'UACH-INAOE en SMM4H: un enfoque basado en BERT para la clasificación de las publicaciones de Twitter sobre COVID-19', 'pt': 'UACH-INAOE no SMM4H: uma abordagem baseada em BERT para classificação de postagens no Twitter COVID-19', 'ja': 'SMM 4 HのUACH - INAOE ：新型コロナウイルスのTwitter投稿の分類のためのBERTベースのアプローチ', 'hi': 'SMM4H में UACH-INAOE: कोविड -19 ट्विटर पोस्ट के वर्गीकरण के लिए एक BERT आधारित दृष्टिकोण', 'ru': 'UACH-INAOE на SMM4H: основанный на BERT подход к классификации сообщений в Twitter о COVID-19', 'zh': 'UACH-INAOEåœ¨SMM4H:ä¸€åŸºäºŽBERTCOVID-19 Twitterå¸–åˆ†ç±»æ–¹æ³•', 'ga': 'UACH-INAOE ag SMM4H: cur chuige bunaithe ar BERT chun postálacha Twitter COVID-19 a aicmiú', 'ka': 'UACH-INAOE SMM4H: COVID-19 Twitter პოსტის კლასიფიკაციისთვის BERT-დაბათი პროგრამა', 'el': 'UACH-INAOE στη SMM4H: μια προσέγγιση βασισμένη στο BERT για την ταξινόμηση των δημοσιεύσεων στο Twitter', 'it': 'UACH-INAOE a SMM4H: un approccio BERT per la classificazione dei post Twitter COVID-19', 'lt': 'UACH-INAOE SMM4H vietoje: BERT grindžiamas metodas COVID-19 Twitter postų klasifikavimui', 'mk': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'ms': 'UACH-INAOE di SMM4H: pendekatan berdasarkan BERT untuk kelasukan pos Twitter COVID-19', 'ml': 'SMM4H-ലെ UACH-INAOE: COVID-19 ടൂട്ടര്\u200d പോസ്റ്റുകളുടെ ക്ലാസിഫേഷനുള്ള ബെര്\u200dട്ടിന്റെ അടിസ്ഥാനമായ ഒരു ബെര്\u200dട്ട് അടി', 'mt': 'UACH-INAOE fl-SMM4H: approċċ ibbażat fuq BERT għall-klassifikazzjoni ta’ postijiet ta’ Twitter COVID-19', 'hu': 'UACH-INAOE az SMM4H-nál: BERT alapú megközelítés a COVID-19 Twitter bejegyzések osztályozására', 'mn': 'SMM4H-ийн UACH-INAOE: COVID-19 Twitter-ийн хувилбарын BERT суурилсан арга зам', 'kk': 'UACH- INAOE at SMM4H: a BERT based approach for classification of COVID- 19 Twitter posts', 'ro': 'UACH-INAOE la SMM4H: o abordare bazată pe BERT pentru clasificarea postărilor Twitter COVID-19', 'sr': 'UACH-INAOE na SMM4H: BERT-bazirani pristup klasifikaciji COVID-19 Twitter postova', 'pl': 'UACH-INAOE na SMM4H: podejście oparte na BERT do klasyfikacji COVID-19 postów Twitter', 'si': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter post', 'so': 'UACH-INAOE SMM4H: A BERT approach based on classification of COVID-19 posts', 'no': 'UACH-INAOE på SMM4H: ein BERT-basert tilnærming for klassifisering av COVID-19 Twitter-postar', 'sv': 'UACH-INAOE på SMM4H: ett BERT-baserat tillvägagångssätt för klassificering av COVID-19 Twitter-inlägg', 'ur': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'ta': 'SMM4H-ல் UACH-INAOE: COVID-19 Twitter posts வகைப்படுத்தலுக்கு ஒரு பெர்ட் அடிப்படையான வழிமுறை', 'uz': "SMM4H'da UACH-INAOE: COVID-19 Twitter postlarini classification uchun BERT asosida", 'vi': 'Trình theo dõi UACH-INeaE tại SMM4H: một phương pháp BERT phân loại những bài viết trên Twitter của COVID-19.', 'bg': 'УАХ-ИНАЕ в СММ4Х: базиран на Берт подход за класификация на публикациите в Туитър', 'nl': 'UACH-INAOE op SMM4H: een BERT-gebaseerde aanpak voor classificatie van COVID-19 Twitter posts', 'hr': 'UACH-INAOE na SMM4H: pristup baziran na BERT-u za klasifikaciju COVID-19 Twitter postova', 'da': 'UACH-INAOE på SMM4H: en BERT baseret tilgang til klassificering af COVID-19 Twitter-indlæg', 'fa': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'ko': 'SMM4H의 UACH-INAOE: BERT 기반 코로나 트위터 게시물 분류 방법', 'de': 'UACH-INAOE auf der SMM4H: ein BERT-basierter Ansatz zur Klassifizierung von COVID-19 Twitter Posts', 'id': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'sw': 'UACH-INAOE kwenye SMM4H: mbinu yenye msingi wa BERT kwa kutangaza makala za Twita za COVID-19', 'sq': 'UACH-INAOE në SMM4H: një qasje bazuar në BERT për klasifikimin e postimeve të Twitter COVID-19', 'af': 'UACH-INAOE by SMM4H: 芒聙聶n BERT gebaseerde toegang vir klasifikasie van COVID-19 Twitter-pos', 'tr': 'UACH-INAOE at SMM4H: COVID-19 Twitter postlaryň klasifikasyýasy üçin BERT tabanly metody', 'am': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'az': "SMM4H'də UACH-INAOE: COVID-19 Twitter postalarının klasifikasyonu üçün BERT tabanlı tərzi", 'hy': 'UACH-INAOE-ը SMM4H-ում. BERT-ի հիմնված մոտեցում COVID-19 թվիթերի դիրքերի դասակարգման համար', 'bn': 'SMM4H-এ সুইক-ইনাও: কভিড-১৯ টুইটার পোস্টের ক্লাসাফিকেশনের জন্য বিবের্ট ভিত্তিক একটি পদক্ষেপ', 'bs': 'UACH-INAOE na SMM4H: BERT-bazirani pristup klasifikaciji COVID-19 Twitter postova', 'cs': 'UACH-INAOE na SMM4H: přístup založený na BERT pro klasifikaci COVID-19 Twitter příspěvky', 'et': 'UACH-INAOE SMM4H-s: BERT-põhine lähenemisviis COVID-19 Twitter postituste klassifitseerimiseks', 'ca': 'UACH-INAOE a SMM4H: un enfocament basat en BERT per classificar els posts de Twitter COVID-19', 'fi': 'UACH-INAOE SMM4H:ssa: BERT-pohjainen lähestymistapa COVID-19-viestien luokitteluun', 'sk': 'UACH-INAOE na SMM4H: BERT-ov pristop za klasifikacijo COVID-19 objav na Twitterju', 'ha': 'SMM4H', 'jv': 'Una BERT basa dumadhi kanggo Kelaseki DEL-19', 'bo': 'UACH-INAOE at SMM4H: a BERT based approach for classification of COVID-19 Twitter posts', 'he': 'UACH-INAOE ב SMM4H:'}
{'en': 'This work describes the participation of the Universidad Autnoma de Chihuahua-Instituto Nacional de Astrofsica, ptica y Electrnica team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task. Our team participated in task 5 and 6, both focused on the automatic classification of Twitter posts related to COVID-19. Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19. Task 6 objective was to classify tweets containing COVID-19 symptoms. For both tasks we used  models  based on bidirectional encoder representations from transformers (BERT). Our objective was to determine if a  model  pretrained on a corpus in the domain of interest can outperform one trained on a much larger general domain corpus. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.', 'ar': 'يصف هذا العمل مشاركة Universidad Autönoma de Chihuahua - Instituto Nacional de Astrofísica ، فريق Öptica y Electrönica في مهمة مشتركة لتعدين الوسائط الاجتماعية للتطبيقات الصحية (SMM4H) 2021. شارك فريقنا في المهمتين 5 و 6 ، وركز كلاهما على التصنيف التلقائي لمشاركات Twitter المتعلقة بـ COVID-19. كانت المهمة 5 موجهة إلى حل مشكلة التصنيف الثنائي ، في محاولة لتحديد تغريدات الإبلاغ الذاتي عن الحالات المحتملة لـ COVID-19. كان هدف المهمة 6 هو تصنيف التغريدات التي تحتوي على أعراض COVID-19. لكلتا المهمتين ، استخدمنا نماذج تستند إلى تمثيلات المشفر ثنائية الاتجاه من المحولات (BERT). كان هدفنا هو تحديد ما إذا كان نموذج تم اختباره مسبقًا في مجموعة في مجال الاهتمام يمكن أن يتفوق على نموذج تم تدريبه على مجموعة مجال عام أكبر بكثير. كانت نتائج F1 مشجعة ، 0.77 و 0.95 للمهمة 5 و 6 على التوالي ، بعد أن حققت أعلى درجة بين جميع المشاركين في الأخيرة.', 'pt': 'Este trabalho descreve a participação da equipe da Universidad Autönoma de Chihuahua - Instituto Nacional de Astrofísica, Öptica y Electrönica na tarefa compartilhada Social Media Mining for Health Applications (SMM4H) 2021. Nossa equipe participou da tarefa 5 e 6, ambas focadas na classificação automática de postagens do Twitter relacionadas ao COVID-19. A tarefa 5 foi orientada a resolver um problema de classificação binária, tentando identificar tweets de autorrelato de casos potenciais de COVID-19. O objetivo da tarefa 6 era classificar os tweets contendo sintomas de COVID-19. Para ambas as tarefas foram utilizados modelos baseados em representações de encoders bidirecionais de transformadores (BERT). Nosso objetivo foi determinar se um modelo pré-treinado em um corpus no domínio de interesse pode superar um treinado em um corpus de domínio geral muito maior. Nossos resultados na F1 foram animadores, 0,77 e 0,95 para a tarefa 5 e 6 respectivamente, tendo alcançado a pontuação mais alta entre todos os participantes nesta última.', 'es': 'Este trabajo describe la participación del equipo de la Universidad Autónoma de Chihuahua - Instituto Nacional de Astrofísica, Óptica y Electrónica en la tarea compartida Social Media Mining for Health Applications (SMM4H) 2021. Nuestro equipo participó en las tareas 5 y 6, ambas centradas en la clasificación automática de las publicaciones de Twitter relacionadas con COVID-19. La Tarea 5 se orientó a resolver un problema de clasificación binaria, tratando de identificar tuits de autorreporte de casos potenciales de COVID-19. El objetivo de la tarea 6 era clasificar los tuits que contenían síntomas de COVID-19. Para ambas tareas utilizamos modelos basados en representaciones de codificadores bidireccionales de transformadores (BERT). Nuestro objetivo era determinar si un modelo previamente entrenado en un corpus en el dominio de interés puede superar a uno entrenado en un corpus de dominio general mucho más grande. Nuestros resultados de F1 fueron alentadores, 0,77 y 0,95 para las tareas 5 y 6 respectivamente, habiendo logrado la puntuación más alta entre todos los participantes en esta última.', 'fr': "Ce travail décrit la participation de l'équipe de l'Universidad Autönoma de Chihuahua - Instituto Nacional de Astrofísica, Öptica y Electrönica à la tâche partagée Social Media Mining for Health Applications (SMM4H) 2021. Notre équipe a participé aux tâches 5 et 6, toutes deux axées sur la classification automatique des publications Twitter liées à la COVID-19. La tâche 5 était axée sur la résolution d'un problème de classification binaire, en essayant d'identifier les tweets auto-déclarés de cas potentiels de COVID-19. L'objectif de la tâche 6 était de classer les tweets contenant des symptômes de la COVID-19. Pour les deux tâches, nous avons utilisé des modèles basés sur des représentations de codeurs bidirectionnelles provenant de transformateurs (BERT). Notre objectif était de déterminer si un modèle préformé sur un corpus dans le domaine d'intérêt peut surpasser un modèle formé sur un corpus de domaine général beaucoup plus vaste. Nos résultats en F1 étaient encourageants, 0,77 et 0,95 pour les tâches 5 et 6 respectivement, ayant obtenu le score le plus élevé parmi tous les participants de cette dernière.", 'ja': 'この作品では、2021年のソーシャルメディア・マイニング・フォー・ヘルス・アプリケーションズ（ SMM 4 H ）の共有タスクへのチワワ大学-国立アストロフィシカ、エプチカ、エレクトロニカ研究所チームの参加について説明しています。私たちのチームは、新型コロナウイルスに関連するTwitter投稿の自動分類に焦点を当てたタスク5と6に参加しました。タスク5は、新型コロナウイルス感染症（ COVID -19 ）の潜在的症例の自己報告ツイートを特定しようとするバイナリ分類問題の解決に向けられていました。タスク6の目的は、COVID -19の症状を含むツイートを分類することでした。両方のタスクでは、変圧器（ BERT ）からの双方向エンコーダ表現に基づくモデルを使用しました。私たちの目的は、関心のあるドメインのコーパスで事前に訓練されたモデルが、はるかに大きな一般的なドメインコーパスで訓練されたモデルよりも優れたパフォーマンスを発揮できるかどうかを判断することでした。F 1の結果は、タスク5と6でそれぞれ0.77と0.95であり、後者のすべての参加者の中で最高のスコアを達成しました。', 'hi': 'यह काम Universidad Autönoma de Chihuahua - Instituto Nacional de Astrofísica, Öptica y Electrönica टीम की भागीदारी का वर्णन करता है, जो सोशल मीडिया माइनिंग फॉर हेल्थ एप्लीकेशन्स (SMM4H) 2021 साझा कार्य में है। हमारी टीम ने टास्क 5 और 6 में भाग लिया, दोनों ने कोविड-19 से संबंधित ट्विटर पोस्ट के स्वचालित वर्गीकरण पर ध्यान केंद्रित किया। कार्य 5 एक बाइनरी वर्गीकरण समस्या को हल करने पर उन्मुख था, जो कोविड -19 के संभावित मामलों के स्व-रिपोर्टिंग ट्वीट्स की पहचान करने की कोशिश कर रहा था। कार्य 6 का उद्देश्य कोविड -19 के लक्षणों वाले ट्वीट्स को वर्गीकृत करना था। दोनों कार्यों के लिए हमने ट्रांसफॉर्मर (BERT) से द्विदिश एन्कोडर प्रतिनिधित्व के आधार पर मॉडल का उपयोग किया। हमारा उद्देश्य यह निर्धारित करना था कि क्या ब्याज के डोमेन में एक कॉर्पस पर पूर्वनिर्धारित एक मॉडल एक बहुत बड़े सामान्य डोमेन कॉर्पस पर प्रशिक्षित एक को मात दे सकता है। हमारे F1 परिणाम उत्साहजनक थे, क्रमशः कार्य 5 और 6 के लिए 0.77 और 0.95, बाद में सभी प्रतिभागियों के बीच उच्चतम स्कोर हासिल किया।', 'zh': '述奇瓦瓦自治大学 - 国天文研究所,Öptica y Electrönica团队与2021年社交媒体康强采(SMM4H)之任。 臣等团队预事 5 6,两者专注 COVID-19 Twitter 帖自类。 务5决二元之类,图识COVID-19潜于病例者自告推文。 任6者,COVID-19之推文也。 二者,吾用转换器(BERT)之双向编码器也。 吾之所向,定于兴域之语料库,先练之形,可以优于大域语料库。 吾F1成绩令人鼓舞,5与6为0.770.95,取最高分于后者之参与者。', 'ru': 'Эта работа описывает участие команды Автономного университета Чиуауа - Национального института астрофизики, оптики и электроники в совместной задаче «Майнинг социальных сетей для применения в здравоохранении» (SMM4H) 2021 года. Наша команда участвовала в задачах 5 и 6, которые были посвящены автоматической классификации постов в Twitter, связанных с COVID-19. Задача 5 была ориентирована на решение задачи бинарной классификации, пытаясь выявить твиты с самостоятельным сообщением о потенциальных случаях COVID-19. Задача 6 заключалась в классификации твитов, содержащих симптомы COVID-19. Для обеих задач мы использовали модели, основанные на двунаправленных представлениях кодового датчика положения от трансформаторов (BERT). Наша цель состояла в том, чтобы определить, может ли модель, предварительно обученная на корпусе в интересующей области, превосходить модель, обученную на гораздо большем корпусе общей области. Наши результаты F1 были обнадеживающими, 0,77 и 0,95 для задачи 5 и 6 соответственно, достигнув самого высокого балла среди всех участников в последнем.', 'ga': 'Déanann an obair seo cur síos ar rannpháirtíocht fhoireann Universidad Autönoma de Chihuahua - Instituto Nacional de Astrofísica, Öptica agus Electrönica ag Mianadóireacht Meáin Shóisialta le haghaidh Feidhmchláir Sláinte (SMM4H) 2021. Ghlac ár bhfoireann páirt i dtasc 5 agus 6, agus dhírigh an dá cheann acu ar aicmiú uathoibríoch post Twitter a bhaineann le COVID-19. Bhí Tasc 5 dírithe ar fhadhb aicmithe dhénártha a réiteach, ag iarraidh tvuíteanna féintuairiscithe a shainaithint maidir le cásanna féideartha de COVID-19. Ba é cuspóir Thasc 6 tweets a rangú a raibh airíonna COVID-19 iontu. Don dá thasc d’úsáideamar samhlacha bunaithe ar uiríll déthreoracha ó chlaochladáin (BERT). Ba é an cuspóir a bhí againn ná a fháil amach an bhféadfadh múnla a réamhoilíodh ar chorpas i réimse an leasa a bheith níos fearr ná an tsamhail atá oilte ar chorpas fearainn ginearálta i bhfad níos mó. Bhí ár dtorthaí F1 spreagúil, 0.77 agus 0.95 do thasc 5 agus 6 faoi seach, tar éis an scór ab airde a bhaint amach i measc na rannpháirtithe go léir sa dara ceann.', 'ka': 'ამ სამუშაო აღწერს სუციალური მედიაში ავტონომა დე ფიჰსასა - ინსტუტიო ნაციონალური დე ატროფიციკა, ოპტიკა y ელექტრონიკას ჯგუფი სოციალური მედიაში საზოგადოებო პროგრამებისთვის (SMM4 ჩვენი ჯგუფი ხუთი და შვიდი სამუშაოში მოთავსებულია, ორივე მოთავსებულია კონსტიფიკაციაში Twittersის სამუშაო წერტილებების შესახებ COVID-19. დავალება 5 იყო ორიენტიური კლასიფიკაციის პრობლემების გადაწყვებაზე, რომელიც COVID-19 პრობლემების პრობლემების გადაწყვეტილების თავიდან გადაწყვეტილება. მისამართი 6 მისამართი იყო COVID-19 სიმპტომების კლასიფიკაცია. ორივე დავალებისთვის ჩვენ გამოიყენეთ მოდელები, რომლებიც ტრანფორმეტრებისგან გამოყენებულია მედირექციონალური კოდერის გამოსახულებაზე. ჩვენი მიზეზი იყო განსაზღვრება, თუ მოდელი, რომელიც ინტერესტის დიომინში კორპოსზე გადარჩენა, შეუძლია გავაკეთოთ ერთი მეტი დიომინური კორპოსში. ჩვენი F1 წარმოდგენები იყენებენ, 0,77 და 0,95, 5 და 6 დავამუშავებენ, რომლებიც შემდეგ ყველა სხვადასხვა მომხმარებელი შორის უფრო დიდი წარმოდგენა.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή της ομάδας του Ινστιτούτου Ναcional de Astrofisica, Optica y Electronica στο κοινό έργο των Κοινωνικών Μέσων Εξόρυξης για Εφαρμογές Υγείας (SMM4H). Η ομάδα μας συμμετείχε στο έργο 5 και 6, και οι δύο επικεντρώθηκαν στην αυτόματη ταξινόμηση των δημοσιεύσεων που σχετίζονται με το COVID-19. Η εργασία 5 επικεντρώθηκε στην επίλυση ενός προβλήματος δυαδικής ταξινόμησης, προσπαθώντας να εντοπίσει αυτοαναφερθέντα tweets για πιθανές περιπτώσεις COVID-19. Στόχος του έργου 6 ήταν η ταξινόμηση των tweets που περιέχουν συμπτώματα COVID-19. Και για τις δύο εργασίες χρησιμοποιήσαμε μοντέλα βασισμένα σε αμφίδρομες αναπαραστάσεις κωδικοποιητών από μετασχηματιστές (BERT). Στόχος μας ήταν να προσδιορίσουμε αν ένα μοντέλο προ-εκπαιδευμένο σε ένα σώμα στον τομέα ενδιαφέροντος μπορεί να ξεπεράσει ένα μοντέλο εκπαιδευμένο σε ένα πολύ μεγαλύτερο γενικό σώμα τομέα. Τα αποτελέσματα της F1 ήταν ενθαρρυντικά, 0.77 και 0.95 για την εργασία 5 και 6 αντίστοιχα, έχοντας επιτύχει την υψηλότερη βαθμολογία μεταξύ όλων των συμμετεχόντων στο τελευταίο.', 'hu': 'Ez a munka bemutatja az Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica csapat részvételét a Social Media Mining for Health Applications (SMM4H) 2021 megosztott feladatban. Csapatunk részt vett az 5. és 6. feladatban, mindkettő a COVID-19-hez kapcsolódó Twitter bejegyzések automatikus osztályozására összpontosított. Az 5. feladat egy bináris osztályozási probléma megoldására irányult, megpróbálta azonosítani a potenciális COVID-19 esetek önjelentő tweetjeit. A 6. feladat célja a COVID-19 tüneteket tartalmazó tweetek osztályozása volt. Mindkét feladathoz transzformátorok (BERT) kétirányú útmérő reprezentációján alapuló modelleket használtunk. Célunk annak megállapítása volt, hogy egy korpuszra előkészített modell az érdeklődési területen felülmúlhat-e egy sokkal nagyobb általános korpuszra készített modell. Az F1 eredményeink biztatóak voltak, 0,77 és 0,95 az 5. és 6. feladat esetében, mivel az utóbbi résztvevők között a legmagasabb pontszámot értük el.', 'kk': 'Бұл жұмыс 2021 жылы Саултық қолданбалар (SMM4H) социалдық медиа бағыттау бағдарламаларының ортақ тапсырмасындағы Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica командасының қатынасын анықтайды. Біздің командамыз 5 және 6 тапсырмасына қатысу үшін, екеуі COVID-19 дегенмен байланысты Twitter жіберушілерді автоматты түрде салыстырып тұрды. 5- тапсырма COVID- 19 мүмкіндік жағдайлардың өзіңізді хабарлау үшін бинарлық классификациялау мәселесін шешу үшін бағытталды. 6- тапсырманың мақсаты COVID- 19 симптомаларды таңдау. Екі тапсырмалар үшін біз үлгілерді түрлендірушілерден (BERT) негізінде қолдандық. Біздің мақсатымыз, көмектесу доменіндегі корпус үшін үлгі көмектесу үшін көмектесілген домендің корпус үшін бір оқыту үшін болады. F1 нәтижесіміз 5 және 6 тапсырма үшін 0,77 және 0,95 және соңғы қатысушылардың ең жоғары нәтижесін жеткіздік.', 'lt': 'Šiame darbe aprašomas Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica komandos dalyvavimas Socialinės žiniasklaidos kasybos sveikatos srityje (SMM4H) 2021 m. bendrame uždavinyje. Mūsų komanda dalyvavo 5 ir 6 užduotyse, abu daugiausia dėmesio skyrė automatinei su COVID-19 susijusių Twitter postų klasifikacijai. 5 užduotis buvo orientuota į dviejų rūšių klasifikavimo problemos sprendimą, siekiant nustatyti galimų COVID-19 atvejų savarankiškus pranešimus. 6 užduotis buvo klasifikuoti tweetus, kuriuose yra COVID-19 simptomų. Abiem užduotims naudojome modelius, pagrįstus dvikryptiniais transformatorių kodatoriais (BERT). Mūsų tikslas buvo nustatyti, ar iš anksto apmokytas korpuso interesų srities modelis gali būti didesnis už tą, kuris apmokytas daug didesnio bendrojo domeno korpuso. Mūsų F1 rezultatai buvo skatinantys, atitinkamai 0,77 ir 0,95 5 ir 6 užduočių atveju, pasiekę didžiausią visų pastarųjų dalyvių rezultatą.', 'mk': 'Оваа работа го опишува учеството на Универзитетот Автонома де Чихуа - Институтот Национален на астрофизика, Оптика и Електроника во Социјалните медиуми за здравствени апликации (СМ4Х) 2021 заедничка задача. Our team participated in task 5 and 6, both focused on the automatic classification of Twitter posts related to COVID-19.  Задачата 5 беше ориентирана на решавање на бинарниот проблем со класификацијата, обидувајќи се да се идентификуваат твитови за потенцијалните случаи на COVID-19. Целта на задачата 6 беше да се класификуваат твитови кои содржат симптоми од COVID-19. За двете задачи употребивме модели базирани на двоправни претставувања на кодерот од трансформаторите (БЕРТ). Нашата цел беше да утврдиме дали моделот претрениран на корпус во доменот на интерес може да го надмине оној трениран на многу поголем генерален корпус на доменот. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.', 'ms': 'Kerja ini menggambarkan participasi Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tim di Social Media Mining for Health Applications (SMM4H) 2021 tugas berkongsi. Pasukan kami berpartisipasi dalam tugas 5 dan 6, kedua-dua fokus pada kelasukan automatik pos Twitter berkaitan dengan COVID-19. Tugas 5 ditujukan pada penyelesaian masalah kelasukan binari, cuba mengenalpasti tweet melaporkan diri terhadap kes-kes yang berpotensi COVID-19. Tugas 6 adalah untuk mengklasifikasikan tweet yang mengandungi gejala COVID-19. For both tasks we used models based on bidirectional encoder representations from transformers (BERT).  Tujuan kami adalah untuk menentukan jika model yang dilatih di atas korpus dalam domain kepentingan boleh melatih satu yang dilatih pada korpus domain umum yang jauh lebih besar. Hasil F1 kami menyeronokkan, 0.77 dan 0.95 untuk tugas 5 dan 6 respectively, telah mencapai skor tertinggi di antara semua peserta di akhirat.', 'mt': 'Dan ix-xogħol jiddeskrivi l-parteċipazzjoni tal-Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tim fil-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (SMM4H) 2021 kompitu komuni. It-tim tagħna pparteċipa fil-kompitu 5 u 6, it-tnejn iffukaw fuq il-klassifikazzjoni awtomatika tal-postijiet ta’ Twitter relatati mal-COVID-19. Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19.  L-għan tal-kompitu 6 kien li jiġu kklassifikati tweets li fihom is-sintomi ta’ COVID-19. Għaż-żewġ kompiti użajna mudelli bbażati fuq rappreżentazzjonijiet tal-kodifikatur bidirezzjonali minn trasformaturi (BERT). L-għan tagħna kien li niddeterminaw jekk mudell imħarreġ minn qabel fuq korpus fid-dominju ta’ interess jistax jaqbeż wieħed imħarreġ fuq korpus ta’ dominju ġenerali ħafna akbar. Ir-riżultati F1 tagħna kienu inkoraġġanti, 0.77 u 0.95 għall-kompitu 5 u 6 rispettivament, wara li kisbu l-ogħla punteġġ fost il-parteċipanti kollha f’dan tal-aħħar.', 'mn': 'Энэ ажил 2021 оны Нийгмийн Media Mining for Health Applications (SMM4H) болон Австрофизик Институтын Автома де Чихууа университетийн оролцоог тайлбарладаг. Бидний баг 5, 6 ажил дээр оролцсон. Хоёулаа COVID-19-тэй холбоотой Twitter-ийн хуваалцааны автоматически хуваалцааныг анхаарлаа хандуулсан. 5 даалгавар нь хоёр дахь хуваалтын асуудлыг шийдэхэд зориулсан. COVID-19-ын боломжтой тохиолдолд өөрийгөө мэдээллийн tweets-г тодорхойлох гэж оролдсон. 6 даалгаварын зорилго нь COVID-19 шинж тэмдэглэгддэг tweets-г ангилах байсан. Бид хоёр даалгаварын хувьд загварыг өөрчлөгчийн (BERT) кодчуудын төлөөлөлт дээр ашигласан. Бидний зорилго гэвэл сонирхолтой холбоотой корпус дээр загвар нь илүү том нийтийн корпус дээр сургалтын нэгийг хийж чадна. F1 үр дүн нь 5, 6 ажил дээр 0.77, 0.95 хүртэл хамгийн өндөр оноо гарч ирсэн.', 'no': 'Dette arbeidet beskriver deltaket av Universidad Autonoma de Chihuahua – Instituto Nacional de Astrofisica, Optica y Electronica team at the Social Media Mining for Health Applications (SMM4H) 2021 delt oppgåve. Gruppen vårt delta i oppgåve 5 og 6, både fokuserte på automatisk klassifisering av Twitter-postar relaterte til COVID-19. Oppgåve 5 vart orientert på å løysa eit binær klassifikasjonsfeil, prøver å identifisera sjølvrapporteringsverdiar av potensielle tilfelle COVID-19. Mål på oppgåve 6 var å klassifisera tweets som inneheld COVID-19-simptomer. For begge oppgåver brukte vi modeller basert på bidireksjonal koderingsrepresentasjonar frå transformatorar (BERT). Målet vårt var å bestemme om eit modell som er pretraint på ein korpus i Internettdomenet kan utføre ein treng på ein mykje større generell domenekorpus. F1-resultatet våre vart stimulert, 0,77 og 0,95 for oppgåve 5 og 6, og har oppnådd den høgste poeng blant alle deltakarane i siste.', 'pl': 'Niniejsza praca opisuje udział zespołu Universidad Autonoma de Chihuahua oraz Instituto Nacional de Astrofisica, Optica y Electronica we wspólnym zadaniu Social Media Mining for Health Applications (SMM4H). Nasz zespół uczestniczył w zadaniu 5 i 6, obie skupiały się na automatycznej klasyfikacji postów na Twitterze związanych z COVID-19. Zadanie 5 ukierunkowane było na rozwiązanie problemu klasyfikacji binarnej, próbując zidentyfikować samopowiadające się tweety potencjalnych przypadków COVID-19. Zadaniem 6 była klasyfikacja tweetów zawierających objawy COVID-19. Do obu zadań wykorzystaliśmy modele oparte na dwukierunkowych reprezentacjach koderów z transformatorów (BERT). Naszym celem było określenie, czy model wstępnie przeszkolony na korpusie znajdującym się w domenie zainteresowania może przewyższyć model przeszkolony na znacznie większym korpusie domeny ogólnej. Nasze wyniki F1 były zachęcające, odpowiednio 0.77 i 0.95 dla zadania 5 i 6, osiągając najwyższy wynik wśród wszystkich uczestników tego ostatniego.', 'it': "Questo lavoro descrive la partecipazione del team Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica al compito condiviso Social Media Mining for Health Applications (SMM4H) 2021. Il nostro team ha partecipato ai task 5 e 6, entrambi focalizzati sulla classificazione automatica dei post su Twitter relativi al COVID-19. Il task 5 era orientato alla risoluzione di un problema di classificazione binaria, cercando di identificare tweet auto-reporting di potenziali casi di COVID-19. L'obiettivo del Task 6 era quello di classificare i tweet contenenti sintomi COVID-19. Per entrambe le attività abbiamo utilizzato modelli basati su rappresentazioni bidirezionali di encoder da trasformatori (BERT). Il nostro obiettivo era determinare se un modello pre-addestrato su un corpus nel dominio di interesse può superare uno addestrato su un corpus di dominio generale molto più ampio. I nostri risultati in F1 sono stati incoraggianti, rispettivamente 0,77 e 0,95 per il compito 5 e 6, avendo ottenuto il punteggio più alto tra tutti i partecipanti in quest'ultimo.", 'ro': 'Această lucrare descrie participarea echipei Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica la sarcina comună Social Media Mining for Health Applications (SMM4H) 2021. Echipa noastră a participat la sarcinile 5 și 6, ambele axate pe clasificarea automată a postărilor Twitter legate de COVID-19. Sarcina 5 a fost orientată spre rezolvarea unei probleme de clasificare binară, încercând să identifice tweet-uri auto-raportate ale potențialelor cazuri de COVID-19. Obiectivul sarcinii 6 a fost clasificarea tweeturilor care conțin simptome COVID-19. Pentru ambele sarcini am folosit modele bazate pe reprezentări bidirecționale de la transformatoare (BERT). Obiectivul nostru a fost să determinăm dacă un model pre-instruit pe un corpus în domeniul de interes poate depăși cel instruit pe un corpus general mult mai mare. Rezultatele noastre F1 au fost încurajatoare, 0.77 și 0.95 pentru sarcina 5 și respectiv 6, obținând cel mai mare scor dintre toți participanții la aceasta din urmă.', 'sr': 'Ovaj rad opisuje sudjelovanje Univerziteta Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tima za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) 2021. godine. Naš tim je sudjelovao u zadatku 5 i 6, oboje su se fokusirali na automatsku klasifikaciju Twitter postova povezanih sa COVID-19. Цел 5 је ориентиран на решање бинарног проблема класификације, покушавајући да идентифицирамо самоизвеђајуће твите потенциалних случаја COVID-19. Цел 6 је био да класифицирамо твите со симптомима COVID-19. Za obe zadatke smo koristili modele na osnovu predstavljanja bidirektivnog kodera od transformatora (BERT). Naš cilj je bio da utvrdimo da li model koji se pretvorio na korpusu u domenu interesa može izvršiti veći trening na mnogo većem domenu korpusu. Naši rezultati F1 su bili ohrabrujući, 0,77 i 0,95 za zadatak 5 i 6, postigli su najveći rezultat među svim sudionicima poslednjih.', 'si': 'මේ වැඩේ විශ්වාස කරනවා Universdade autonohua de Chihuahua - Insto Najonal de Astrophsica, Optica y Electricronica කණ්ඩායමේ සමාජික මාධ්\u200dය මිනිස් ස්වාස්ත්\u200dය වැඩසටහන (SMM4H) 2021 භාගිත වැඩසට අපේ කණ්ඩායම 5 හා 6 වැඩේ සම්බන්ධ වුනා, දෙන්නම ස්වයංක්\u200dරියාත්මක විශ්වාස කරලා තියෙන්නේ ට්විටර් පොස් 5 ක්\u200dරියාව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විස්තර කරන්න පුළුවන්, COVID-19 ප්\u200dරශ්නයක් ස්වයංගත වාර්තාවෙන්න පුළුවන් ව ක්\u200dරියාව 6 අරක්\u200dෂාව තමයි COVID-19 සංඥාවක් තියෙන ට්විට් වලින් විශේෂ කරන්න. අපි දෙන්නම් වැඩක් වෙනුවෙන් මොඩල් භාවිතා කරලා තියෙන්නේ (BERT) වෙනුවෙන් ප්\u200dරතිරූපකයෙන් අධිරූ අපේ අරමුණ තමයි විශ්වාස කරන්න පුළුවන් කොර්පස් එකක් ප්\u200dරතිකාරයක් ප්\u200dරතිකාරයක් වෙන්න පුළුවන් කියලා. අපේ F1 ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරමාණයක් තිබුනා, 0.77 සහ 0.95 වැඩක් 5 සහ 6 වැඩක් වෙනුවෙන්, අන්තිම ප්\u200dරතිප්\u200dරතිප්\u200dරති', 'ml': 'ഈ പ്രവര്\u200dത്തിക്കുന്നത് യൂണിവിവർണിഡഡ് ഓട്ടോമാമ ഡി ചിഹുവയുടെ പങ്കെടുപ്പിനെ വിശദീകരിക്കുന്നു - ഇന്റിസ്റ്റിട്ടോ നാസിയോള്\u200d ഡി ആസ്ട്രോഫിക്ക, ഓപ്റ്റോക്ക ഞങ്ങളുടെ ടീം 5-6 ജോലിയില്\u200d പങ്കാളികളായിരുന്നു. കോവിഡി-19 ക്ലാസ്പോസ്റ്ററിന്റെ സ്വയം വിശ്വാസിക്കുന്നതിനെ  കോവിഡി-19 സാധ്യമായ കേസുകളുടെ സ്വയം റിപ്പോര്\u200dട്ട് ചെയ്യാന്\u200d ശ്രമിക്കുന്നതില്\u200d ജോലി 5 ന്റെ മുന്നില്\u200d തിരിച്ചറിഞ്ഞു കോവിഡി-19 അടയാളങ്ങള്\u200d ഉള്ള ടൂട്ടുകള്\u200d ക്ലാസിഫിക്കല്\u200d ചെയ്യുന്നതായിരുന്നു ജോലി 6 ലക്ഷ്യം. ഈ രണ്ട് ജോലികള്\u200dക്കും ഞങ്ങള്\u200d മോഡലുകള്\u200d ഉപയോഗിച്ചു മാറ്റങ്ങളില്\u200d നിന്നും മാറ്റങ്ങളില്\u200d നിന്നും പ്രതിനിധികള്\u200d ബ നമ്മുടെ ലക്ഷ്യത്തില്\u200d ഒരു മോഡല്\u200d തീരുമാനിക്കുന്നത് താല്\u200dപര്യമുള്ള ഒരു കോര്\u200dപ്പുസിന്\u200dറെ മേല്\u200d ഒരു മാതൃകയാണെങ്കില്\u200d ഒരു വലിയ ജനറല്\u200d ഡ നമ്മുടെ F1 ഫലങ്ങള്\u200d നിര്\u200dണ്ണയിക്കുന്നത് 5, 6 ജോലിക്ക് 0. 77, 0. 95 എന്നിട്ടാണ്. അവസാനത്തെ എല്ലാ പങ്കാളികളിലും ഏറ്റവും ഉയര്\u200dന്ന സ്കോ', 'sv': 'Detta arbete beskriver deltagandet av Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica-teamet vid Social Media Mining for Health Applications (SMM4H) 2021 delade uppgift. Vårt team deltog i uppgift 5 och 6, båda fokuserade på automatisk klassificering av Twitter-inlägg relaterade till COVID-19. Uppgift 5 var inriktad på att lösa ett binärt klassificeringsproblem, försöka identifiera självrapporterande tweets om potentiella fall av COVID-19. Uppgift 6 mål var att klassificera tweets som innehöll COVID-19-symtom. För båda uppgifterna använde vi modeller baserade på tvåriktade encoderrepresentationer från transformatorer (BERT). Vårt mål var att avgöra om en modell som är färdigtränad på en korpus inom intresseområdet kan överträffa en som är tränad på en mycket större allmän domänkorpus. Våra F1-resultat var uppmuntrande, 0,77 respektive 0,95 för uppgift 5 respektive 6, efter att ha uppnått högsta poäng bland alla deltagare i den senare.', 'ur': 'اس کام نے Universidad Autonoma de Chihuahua کی مشارکت کی تعریف کی ہے - Instituto Nacional de Astrofisica, Optica y Electronica Team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task. ہماری تیم نے کام 5 اور 6 میں شریک ہوا، دونوں کو COVID-19 کے ساتھ رابطہ دار توئیٹر پوسٹوں کی اتماماٹی کلاسپیٹ پر تمرکز کیا۔ ٹاکس ۵ ایک دوئناری کلاسیفون مسئلہ حل کرنے پر منظور ہوا تھا، COVID-19 کے امکانات کاسٹوں کے ٹویٹوں کو جاننے کی کوشش کرتی تھی. Task 6 objective was to classify tweets containing COVID-19 symptoms. ہم نے دونوں کاموں کے لئے مدل استعمال کیا ہے جو ٹوریفٹر (BERT) سے دوسری طریقہ کے انڈیر کوڈر کی روشنی پر بنیاد رکھتے ہیں۔ ہمارا مقصد یہ تھا کہ مقرر کرنا چاہیے کہ ایک مدل سود کے ڈمین میں ایک کورپوس پر پرٹرین کیا گیا ہے ایک بہت بڑے ڈمین کورپوس پر آموزش کی جاتی ہے۔ ہمارے F1 نتیجے 5 اور 6 دنیا کے لئے 0.77 اور 0.95 پیغام دینے والے تھے، اور آخرین مشرکوں میں سب سے زیادہ بالا نمونہ پہنچ چکے تھے.', 'ta': 'இந்த வேலை தானியங்கி டி சிஹுவா - நாசியன் டி வாஸ்ட்ரோபிசிகா நிறுவனம், ஆப்டிகா y மினெக்ட்ரோனிகா குழுவின் வழங்குவத்தை விளக்குகிறது வழங்கப்பட்ட சாலிக பயன்பாடு எங்கள் குழு 5 மற்றும் 6 பணியில் பங்கிடப்பட்டது, இருவரும் COVID-19 தொடர்புடைய தானியங்கி வகைப்படுத்தல் Twitter posts மீது கவனம் கொண்ட செயல் 5 ஒரு இரு வகுப்பு பிரச்சினையை தீர்வு செய்யும் போது, COVID-19 சாத்தியமான நிகழ்வுகளின் தன்னை அறிவிக்கும் தொடர்புகளை கண் செயல் 6 குறிப்புகள் COVID-19 குறிப்புகளைக் கொண்டிருக்கும் Twittes வகைப்படுத்தலாம். இரு பணிகளுக்கும் மாற்றங்களிலிருந்து மாற்றங்களை அடிப்படையில் நாம் மாதிரிகளை பயன்படுத்தினோம். எங்கள் இலக்கு ஒரு மாதிரி வட்டியின் களத்தில் ஒரு கோர்ப்புஸ் மீது பெரிய பயிற்சி செய்யப்பட்டுள்ளதா என்பதை தீர்மானிக்க வேண்டும 5 மற்றும் 6 பணிக்கு 0. 77 மற்றும் 0. 95 நம் F1 முடிவுகள் பிற்காலத்தில் பங்கீட்டாளர்களில் அதிக மதிப்பெண்டு அடைந்தது.', 'so': 'Shaqadan ayaa ka qeybqaadashada jaamacadda Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica team at the Social Media Mining for Applications Health (SMM4H) 2021 shared task. Timaheenu waxay ka qeybqaaday shaqada 5 iyo 6, labadoodaba waxay ku kalsoonaacdeen fasax bilowga ah oo la xiriira COVID-19. Shaqo 5 waxaa la soo jeeday in uu xalliyo dhibaato ku saabsan fasaxa labaad, wuxuuna isku dayay in uu soo caddeeyo tweetka arimaha suurtagalka ah ee COVID-19. Shaqada 6 waxaa loo baahan yahay in uu ku qoro Tweetka oo ku jira calaamado COVID-19. Shaqooyinka labadooda ayaannu ku isticmaalnay modelal ku saleysan kooxaha hab-qasabka ee looga jeedo bedelka (BERT). Ujeedkeennu waa in ay ogaato in tusaale lagu soo daajiyey qofka xiisaha ku jira uu ka shaqeyn karo mid lagu tababaray qofka guud ee deegaanka ka weyn. Fashihiisa F1 waxay u dhiirranaayeen, si kastoo ah 0.77 iyo 0.95 shaqada 5 iyo 6, waxayna gaadheen qiimaha ugu sarreeya dadka ugu dambeeyay oo dhan.', 'uz': "Bu ish Universidad Autonoma de Chihuahua - Astrofisa Instituto Nacional de Astrofisika - Optica y Electronica Team for Health Applications (SMM4H) 2021 o'ylangan vazifani o'zgartirish. Bizning guruhimiz 5 va 6 vazifasiga ega bo'lgan, икковлари COVID-19 bilan bog'liq Twitter postlarining автоматик таркибидаги. 5 vazifa COVID-19 oddiy haqida o'z haqida xabar berish uchun ikkita darajalashtirish muammolarini aniqlashni istadi. 6 Ish maqsadi COVID-19 symptomlari bilan foydalanadigan Twittlarni classifash uchun edi. Biz ikkita vazifalar uchun biz transformatorlar (BERT) bilan bir xil kodlash asosida yaratilgan modellardan foydalanamiz. Bizning maqsadimizni aniqlashimiz mumkin, qiziqaruvchining domen'da bir necha katta umumiy domen korpusida o'rganishni o'rganish mumkin. F1 natijalarimiz har xil 5 va 6 vazifa uchun 0.77 va 0.95 ishlarimizga yetarli edi. Keyingi bo'lgan hamma participlarning eng eng kichkina darajaga erishadi.", 'vi': 'Chương trình này mô tả sự tham gia của Universidad Autonoma de Chihuahua - Instuto Nacio de Astrofisica, Opica y y Electronica, ở the Social Media khai thác sức khỏe (SMM24H) 2021 chia sẻ nhiệm vụ. Nhóm của chúng tôi tham gia nhiệm vụ 5 và 6, đều tập trung vào việc phân loại các bài viết trên Twitter liên quan đến COVID-19. Nhiệm vụ 5 được hướng dẫn giải quyết vấn đề phân loại nhị phân, cố gắng xác định các tweet tự báo cáo về các trường hợp có thể của COVID-19. Nhiệm vụ 6 là phân loại tweet có triệu chứng COVID-19. Cho cả hai nhiệm vụ chúng tôi dùng mẫu dựa trên các biểu tượng mã hóa hai trực tiếp từ máy biến đổi (BERT). Mục tiêu của chúng tôi là xác định nếu một mô hình được đưa ra trước một tập đoàn trong lĩnh vực của lợi ích có thể vượt qua một tập đoàn được huấn luyện trên một lĩnh vực rộng lớn hơn nhiều. Kết quả F1 đã được khuyến khích, 0.77 và 0.95 dành cho nhiệm vụ 5 và 6, sau khi đạt được điểm cao nhất giữa tất cả các đối thủ.', 'bg': 'Тази работа описва участието на екипа на Университет Автонома де Чихуахуа - Институт Национален Астрофисик, Оптика и Електроника в споделената задача за Социалните медии Минно дело за здравни приложения (СММ4Х) 2021. Екипът ни участва в задача 5 и 6, и двете фокусирани върху автоматичната класификация на публикациите в Туитър, свързани с КОВИД-19. Задача 5 беше насочена към решаване на двоичен проблем с класификацията, опитвайки се да се идентифицират самодокладващи туитове на потенциални случаи на КОВИД-19. Целта на задача 6 беше да се класифицират туитове, съдържащи симптоми на КОВИД-19. За двете задачи използвахме модели, базирани на двупосочни кодиращи изображения от трансформатори (БЕРТ). Нашата цел беше да определим дали модел, предварително обучен върху корпус в областта на интерес, може да надмине този, обучен върху много по-голям корпус от общ домейн. Нашите резултати бяха окуражаващи, съответно 0,77 и 0,95 за задача 5 и 6, като постигнаха най-висок резултат сред всички участници в последната.', 'da': 'Dette arbejde beskriver deltagelsen af Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica team på Social Media Mining for Health Applications (SMM4H) 2021 delte opgave. Vores team deltog i opgave 5 og 6, begge fokuserede på automatisk klassificering af Twitter-indlæg relateret til COVID-19. Opgave 5 var rettet mod at løse et binært klassifikationsproblem og forsøge at identificere selvrapporterende tweets om potentielle tilfælde af COVID-19. Opgave 6 mål var at klassificere tweets indeholdende COVID-19 symptomer. Til begge opgaver anvendte vi modeller baseret på bidirectional encoder repræsentationer fra transformere (BERT). Vores mål var at afgøre, om en model, der er forudtrænet på et korpus inden for interesseområdet, kan overgå en model, der er trænet på et meget større generelt domænekorpus. Vores F1 resultater var opmuntrende, 0,77 og 0,95 for henholdsvis opgave 5 og 6, efter at have opnået den højeste score blandt alle deltagerne i sidstnævnte.', 'hr': 'Ovaj rad opisuje sudjelovanje Univerziteta Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tima za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) 2021. godine. Naš tim je sudjelovao u zadatku 5 i 6, obje su se fokusirali na automatsku klasifikaciju Twitter postova povezanih s COVID-19. Cilj 5 je bio usmjeren na rješavanje problem a sa binarnom klasifikacijom, pokušavajući identificirati samopojavljive tweets potencijalnih slučajeva COVID-19. Cilj zadataka 6 bio je klasifikacija tweets koji sadrže simptome COVID-19. Za oba zadatka koristili smo modele na temelju predstavljanja bidirektivnog kodera od transformatora (BERT). Naš cilj je bio utvrditi da li se model preokrenuo na korpusu u domenu interesa može izvršiti jednu obučenu na mnogo većem domenu korpusu. Naši rezultati F1 su poticali, odnosno 0,77 i 0,95 za zadatak 5 i 6, postigli su najveći rezultat među svim sudionicima u posljednjim.', 'nl': 'Dit werk beschrijft de deelname van het Universidad Autonoma de Chihuahua-Instituto Nacional de Astrofisica, Optica y Electronica team aan de gedeelde taak Social Media Mining for Health Applications (SMM4H). Ons team nam deel aan taak 5 en 6, beide gericht op de automatische classificatie van Twitter-berichten gerelateerd aan COVID-19. Taak 5 was gericht op het oplossen van een binair classificatieprobleem, waarbij geprobeerd werd zelfrapporterende tweets van potentiële gevallen van COVID-19 te identificeren. Task 6 doelstelling was tweets te classificeren die COVID-19 symptomen bevatten. Voor beide taken gebruikten we modellen gebaseerd op bidirectionele encoderrepresentaties van transformatoren (BERT). Ons doel was om te bepalen of een model dat vooraf getraind is op een corpus in het domein van interesse beter kan presteren dan een model dat getraind is op een veel groter algemeen domeincorpus. Onze F1 resultaten waren bemoedigend, respectievelijk 0.77 en 0.95 voor taak 5 en 6, met de hoogste score onder alle deelnemers aan de laatste.', 'id': 'Pekerjaan ini menggambarkan pesertaan dari Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tim di Social Media Mining for Health Applications (SMM4H) 2021 tugas berbagi. Tim kami berpartisipasi dalam tugas 5 dan 6, berdua fokus pada klasifikasi otomatis pos Twitter berkaitan dengan COVID-19. Tugas 5 berusaha menyelesaikan masalah klasifikasi binari, mencoba untuk mengidentifikasi Twit melaporkan diri dari kasus potensial COVID-19. Tugas 6 tujuan adalah mengklasifikasi tweet yang mengandung gejala COVID-19. For both tasks we used models based on bidirectional encoder representations from transformers (BERT).  Tujuan kami adalah untuk menentukan apakah model terlatih di sebuah korpus dalam domain kepentingan dapat melanjutkan satu terlatih di sebuah korpus domain umum yang jauh lebih besar. Hasil F1 kami mendorong, 0,77 dan 0,95 untuk tugas 5 dan 6 respectively, telah mencapai skor tertinggi di antara semua peserta di akhir.', 'de': 'Diese Arbeit beschreibt die Teilnahme des Teams der Universidad Autonoma de Chihuahua.Instituto Nacional de Astrofisica, Optica y Electronica an der gemeinsamen Aufgabe Social Media Mining for Health Applications (SMM4H). Unser Team nahm an der Aufgabe 5 und 6 teil, beide konzentrierten sich auf die automatische Klassifizierung von Twitter-Beiträgen im Zusammenhang mit COVID-19. Aufgabe 5 war darauf ausgerichtet, ein binäres Klassifizierungsproblem zu lösen, indem versucht wurde, selbstberichtende Tweets potenzieller Fälle von COVID-19 zu identifizieren. Aufgabe 6 war es, Tweets mit COVID-19 Symptomen zu klassifizieren. Für beide Aufgaben wurden Modelle verwendet, die auf bidirektionalen Encoderdarstellungen von Transformatoren (BERT) basieren. Unser Ziel war es herauszufinden, ob ein Modell, das auf einem Korpus im Interessenbereich vortrainiert wurde, ein Modell, das auf einem viel größeren allgemeinen Domänenkorpus trainiert wurde, übertreffen kann. Unsere F1-Ergebnisse waren ermutigend, 0.77 und 0.95 für Aufgaben 5 bzw. 6, nachdem sie die höchste Punktzahl unter allen Teilnehmern erreicht haben.', 'ko': '이 사업은 치와바 자치대-국립천문연구소 광학·전자팀이 2021년 건강앱 소셜미디어 발굴(SMM4H) 공유 임무에 참여하는 상황을 기술했다.우리 팀은 코로나와 관련된 트위터 게시물의 자동 분류에 집중하는 미션 5와 미션 6에 참여했다.미션 5는 이원 분류 문제를 해결하고 잠재적 코로나 사례를 식별하려는 자기보고 트윗을 시도하는 것이 목표다.미션 6의 목표는 코로나 증상이 담긴 트윗을 분류하는 것이다.이 두 가지 임무에 대해 우리는 모두 변압기(BERT)를 기반으로 하는 양방향 인코더 표시 모델을 사용했다.우리의 목표는 관심 분야의 원료 라이브러리에서 미리 훈련하는 모델이 더 큰 일반 분야의 원료 라이브러리에서 훈련하는 모델보다 우수한지 확인하는 것이다.우리의 F1 성적은 고무적이다. 임무 5와 6의 성적은 각각 0.77과 0.95로 후자의 모든 참여자 중에서 가장 높았다.', 'fa': 'این کار مشترک مشارکت دانشگاه Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task. تیم ما در وظیفه ۵ و ۶ شرکت می\u200cکردند، هر دو روی برنامه\u200cهای اتوماتیک توئیتر مربوط به COVID-۱۹ تمرکز می\u200cکردند. وظیفه ۵ بر حل یک مشکل راهنمایی دوگانه، سعی می\u200cکند توئیت\u200cهای خود گزارش دهنده از پرونده\u200cهای پتانسیل COVID-19 را شناسایی کند. هدف ۶ این بود که توئیت\u200cها را با علائم COVID-۱۹ تشکیل دهیم. برای هر دو وظیفه ما از مدل\u200cها استفاده کردیم که بر اساس نمایش\u200cهایی از تغییر\u200cدهندگان (BERT) قانون\u200cدهنده\u200cهای کودهر دومین\u200cترکیب استفاده می\u200cکنیم. هدف ما این بود که تصمیم بگیریم آیا یک مدل روی یک کورپوس در دامنه علاقه می\u200cتواند یکی را بر یک کورپوس عمومی بزرگتر آموزش داده شود. نتیجه\u200cهای F1 ما به طور مستقل، 0.77 و 0.95 برای وظیفه 5 و 6 تحریک می\u200cکردند، که بالاترین نتیجه بین همه\u200cی شرکتگران آخرین را به دست آورده\u200cاند.', 'sw': 'Kazi hii inaelezea ushiriki wa Chuo Kikuu cha Autonoma de Chihuahua - Taasisi ya Nacional de Astrofisica, timu ya Optica y Electronica katika Vyombo vya Habari vya kijamii kwa ajili ya matumizi ya Afya (SMM4H) 2021 ilishiriki kazi. Timu yetu ilishiriki katika kazi ya 5 na 6, wote wakijikita kwenye kutafsiri makala za Twita zinazohusiana na COVID-19. Kazi 5 ilielekezwa katika kutatua tatizo la kutangaza darasa la mbili, kwa kujaribu kutambua twiti za matukio yanayowezekana ya COVID-19. Lengo la kazi 6 lilikuwa kuwasilisha twiti zenye dalili za COVID-19. Kwa kazi zote mbili tulitumia mifano kwa kutumia mifano inayohusiana na kuweka maoni ya mabadiliko (BERT). Lengo letu lilikuwa ni kuamua kama mfano ulioanguka kwenye vifaa vyenye maslahi kunaweza kufanya mafunzo ya moja kwa moja kwenye makampuni makubwa ya ndani. Matokeo yetu ya F1 yalikuwa yanahamasisha, 0.77 na 0.95 kwa ajili ya kazi 5 na 6, baada ya kuwa wamepata kiwango kikubwa zaidi miongoni mwa washiriki wote.', 'tr': "Bu iş 2021-nji ýylyň Uniwersitet Autonoma de Chihuawa guralşygyny (SMM4H) bardyr. Biziň toparymyz 5 we 6-nji görevimizde, ikimiz hem COVID-19 bilen baglanýan Twitter postlaryň otomatik klasifikasyna üns berdiler. 5-nji işi COVID-19'yň mümkin durumlarynyň tweetlerini çözmek üçin bir ikili klasifikasyon meselesini çözmekte guruldy. 6 Görev Görevi COVID-19 simptomlary bar týuterleri barlamak boldy. Iki zadyň üçin ikinji ködleme ködlemelerinde daýanýan nusgalary ulandyk (BERT). Bizim amacımız, ilgi alandaki bir korpus üzerinde örnek pretrained edilmiş bir örnek daha büyük bir domun korpusu üzerinde eğitilmiş olup olmadığını belirlemektir. F1 netijesimiz 5 we 6 görevimiz üçin 0,77 we 0,95-de, soňky hemme iştirakçileriň iň üst depesini başarmadyk.", 'sq': 'Ky punë përshkruan pjesëmarrjen e Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica team në Social Media Mining for Health Applications (SMM4H) 2021. Ekipi ynë mori pjesë në detyrën 5 dhe 6, të dy përqëndruar në klasifikimin automatik të postimeve të Twitter lidhur me COVID-19. Detyra 5 ishte e orientuar në zgjidhjen e një problemi të klasifikimit binar, duke u përpjekur të identifikojë vetë-raportimin e tweeteve të rasteve të mundshme të COVID-19. Objektivi i misionit 6 ishte të klasifikonte tweetet që përmbajnë simptomet COVID-19. Për të dy detyrat ne përdorëm modele bazuar në përfaqësime dy-drejtuese të koduesit nga transformuesit (BERT). Objektivi ynë ishte të përcaktojmë nëse një model i stërvitur në një korpus në fushën e interesit mund të kalojë një të stërvitur në një korpus shumë më të madh në fushën e përgjithshme. Rezultatet tona të F1 ishin inkurajuese, 0.77 dhe 0.95 për detyrën 5 dhe 6 respektivisht, duke arritur rezultatin më të lartë midis të gjithë pjesëmarrësve në të fundit.', 'af': "Hierdie werk beskrywe die deelnadering van die Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica-team by die Sosiale Media Mining vir gesondige toepassings (SMM4H) 2021 deel taak. Ons span het gedeel in taak 5 en 6, beide fokus op die outomatiese klasifikasie van Twitter-pos wat met COVID-19 verwante is. Opdrag 5 was orienteer op die oplossing van 'n binêre klasifikasie probleem, probeer om selfraporteerde tweets van potensiele gevalle van COVID-19 te identifiseer. Opdrag 6 is om tweets te klassifiseer wat COVID-19 simptome bevat. Vir beide opdragte gebruik ons model gebruik wat gebaseer is op bidirectional enkoder voorstellings van transformers (BERT). Ons doel was om te bepaal of 'n model op 'n korpus in die domein van belang uitgevoer kan een wat op 'n baie groter algemene domein korpus opgelei is. Ons F1 resultate was bevestig, 0.77 en 0.95 vir taak 5 en 6 respectively, met die hoogste aantal onder al die deelnaders in die laaste bereik.", 'hy': 'Այս աշխատանքը նկարագրում է Համալսարանի Ատոնոմա դե Չիհուա մասնակցությունը 2021 թվականին ընդհանուր հանձնարարության Ինստիտուտո Նացիոնալ Աստրոֆիզիկայի, Օպտիկայի և Էլեկտրոնիկայի անդամներից: Մեր թիմը մասնակցեց 5-ին և 6-ին, երկուսն էլ կենտրոնացրեցին COVID-19-ի հետ կապված Թվիթերի դիրքերի ավտոմատիկ դասակարգման վրա: Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19.  Վեցերորդ հանձնարարության նպատակը COVID-19 ախտանիշներ պարունակող թվիթերի դասակարգելն էր: Երկու առաջադրանքների համար մենք օգտագործեցինք մոդելներ, որոնք հիմնված են երկու ուղղությամբ կոդերի ներկայացումների վրա վերափոխողներից (BER). Մեր նպատակն էր որոշել, թե արդյոք շատերի ոլորտում մարմնի վրա նախապատրաստված մոդելը կարող է գերազանցել մեկը, որը պատրաստված է շատ ավելի մեծ ընդհանուր ոլորտում մարմնի վրա: Մեր F1 արդյունքները խրախուսափելի էին, 0.77 և 0.95 հանձնարարության համար, համեմատաբար 5 և 6 հանձնարարություններում, հաջորդ հանձնարարության բոլոր մասնակիցների մեջ ամենաբարձր գնահատականը հասնելով:', 'bn': 'এই কাজের বিশ্ববিদ্যালয়ের স্বাস্থ্য অ্যাপ্লিকেশনের জন্য (এমএম৪এইচ) ২০১১ সালে অংশগ্রহণ করা হয়েছে সোশ্যাল মিডিয়া মিনিয়া মিনিং এর (এসএমএম৪এইচ) ২০১১ সালে অংশগ্ আমাদের দল ৫ এবং ৬ কাজে অংশগ্রহণ করেছে, দুজনেই কভিড-১৯ এর সাথে যুক্ত টুইটার পোস্টের স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয় ব টাস্ক ৫ বাইনারি শ্রেণীবিভাগের সমস্যা সমাধান করার জন্য দৃষ্টিভঙ্গি হয়েছিল, কোভিড-১৯ সম্ভাব্য কেসের টুইটের সম্ভাব্য ট কাজের ৬ উদ্দেশ্য ছিল কভিড-১৯ সংক্রান্ত টুইটের মাধ্যমে। দুটো কাজের জন্য আমরা মডেল ব্যবহার করেছি বিবেরেট থেকে প্রতিনিধিত্বের উপর ভিত্তিক কোডার ব্যবহার করেছি। আমাদের উদ্দেশ্য ছিল সিদ্ধান্ত নির্ধারণ করার জন্য যে একটি মডেল স্বাভাবিক স্বার্থের কোর্পাসের উপর ভাষায় প্রযুক্তি প্রদান করা হয়ে আমাদের এফ১ ফলাফল প্রত্যেক ভাবে ৫ এবং ৬ কাজের জন্য উৎসাহিত, ০. ৭৭ এবং ০. ৯৫, পরের সব অংশগ্রহণকারীদের মধ্যে সর্বোচ্চ স্কোর অর্', 'az': 'Bu iŇüin Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica takńĪmńĪnńĪn 2021-ci Sańülam UygulamalarńĪnńĪn (SMM4H) paylaŇüńĪlmńĪŇü iŇüi il…ô birl…ôŇüdirilm…ôsini t…ôsdiq edir. Bizim ekibimiz 5 v…ô 6 iŇü…ô katńĪldńĪ. ńįkisi d…ô COVID-19 il…ô bańülńĪ Twitter postlarńĪn otomatik klasifikasiyasńĪna odaqlandńĪ. ńįkilik klasifikasiya problemini √ß…ôkm…ôk √ľ√ß√ľn 5. iŇüi COVID-19 olaraq m√ľmk√ľn olaraq bildiril…ôn twetl…ôrin √∂z√ľn√ľ t…ôsdiql…ôm…ôy…ô √ßalńĪŇüńĪrdńĪ. G√∂z…ôl 6 m…ôqs…ôdi COVID-19 simptomlarńĪ bar…ôsind…ôki tweetl…ôri se√ßm…ôk idi. ńįki iŇül…ôr √ľ√ß√ľn ikinci kodlayńĪcńĪlarńĪn (BERT) g√∂st…ôrilm…ôl…ôrin…ô dayanan modell…ôr istifad…ô etdik. Bizim m…ôqs…ôdimiz bel…ô idi ki, maraqlńĪ bir korpus √ľst√ľnd…ô bir modeli daha b√∂y√ľk bir domena korpusu √ľst√ľnd…ô t…ôhsil edil…ôn birini t…ôhsil edir. F1 sonu√ßlarńĪmńĪz 5 v…ô 6 iŇü…ô g√∂r…ô 0,77 v…ô 0,95 n…ôtic…ôsini t…ôŇükil edirdi, sonrakńĪ iŇütirak√ßil…ôrin …ôn y√ľks…ôk n√∂qt…ôsini q…ôbul etdil…ôr.', 'bs': 'Ovaj rad opisuje učestvovanje Univerziteta Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica tim za rudarstvo socijalnih medija za zdravstvene aplikacije (SMM4H) 2021. Naš tim je sudjelovao u zadatku 5 i 6, oboje su se fokusirali na automatsku klasifikaciju Twitter postova povezanih sa COVID-19. zadatak 5 je bio usmjeren na rješavanje problem a sa binarnom klasifikacijom, pokušavajući identificirati samopojavljive tweets potencijalnih slučajeva COVID-19. Cilj zadataka 6 je bio klasifikacija tweeta koji sadrže simptome COVID-19. Za obe zadatke smo koristili modele na osnovu predstavljanja bidirektivnog kodera od transformatora (BERT). Naš cilj je bio da utvrdimo da li model koji se pretvarao na korpusu u domenu interesa može izvršiti veći trening na mnogo većem domenu korpusu. Naši rezultati F1 su poticali, odnosno 0,77 i 0,95 za zadatak 5 i 6, postigli su najviši rezultat među svim sudionicima u posljednjoj.', 'am': 'ይህ ሥራ የዩንቨርስቲቪዲድ አውቶማሜ de ኪhuahua - ኢንስቲቲቲው ናሲዮን de አስtrofisica፣ የኢሌክቶኒካ ኢሌክትሮኒካ የማኅበራዊ ሚዲያዎች ለጤና ፕሮግራሞች ማሳየት (SMM4H) በ2021 የተካፈሉ ስራ ነው፡፡ የጦማሪያችን ሥራ 5 እና 6 ተጋጠሙ፣ ሁለቱም ከCOVID-19 ጋር የተደረገውን በትዊተር ድምጾችን በራሱ ትዊተር ክፍተት ላይ አዋጁ፡፡ ስራው 5 የሀብያዊ መግለጫ ጉዳይ በመፍታት ላይ ተገናኝቷል፤ የCOVID-19 ምናልባት ጉዳዮች የራሳቸውን አዋጅ ትዊት ለማግኘት ይፈልጋል፡፡ የስራ 6 አቃውሞ COVID-19 ምልክቶች ውስጥ ያሉትን በትዊተሮች ለመግለጽ ነው፡፡ ለሁለቱ ስራ ምሳሌዎችን ከtransformers (BERT) በተመሳሳይ አካባቢ ሆኖ በመሠረት ላይ ተጠቀምን፡፡ አካሄዳችን በመጠቀም አካባቢ ኮፕስ ላይ የተዘጋጀ ምሳሌ በተለጠፈ ትልቅ የኮሜኔን ኮምፕስ ላይ የተማረከ አንዱን እንደሆነ ማረጋገጥ ነው፡፡ የF1 ውጤታችን በኋለኞቹ ተጋሪዎች ሁሉ መካከል ከፍተኛ ደረጃ ደረጃ ደረሱ፡፡', 'fi': 'Tässä työssä kuvataan Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica -tiimin osallistumista Social Media Mining for Health Applications (SMM4H) 2021 jaettuun tehtävään. Tiimimme osallistui tehtäviin 5 ja 6, jotka molemmat keskittyivät COVID-19:een liittyvien Twitter-viestien automaattiseen luokitteluun. Tehtävä 5 suuntautui binaariluokitusongelman ratkaisemiseen, jossa yritettiin tunnistaa itse raportoivia tweettejä mahdollisista COVID-19-tapauksista. Tehtävän 6 tavoitteena oli luokitella COVID-19-oireita sisältävät tweetit. Molemmissa tehtävissä käytimme malleja, jotka perustuvat muuntajien kaksisuuntaisiin enkooderiesityksiin (BERT). Tavoitteenamme oli selvittää, voiko kyseessä olevalle corpukselle esikoulutettu malli suoriutua paljon suuremmalla yleisellä corpuksella koulutetusta mallista. F1-tuloksemme olivat rohkaisevia, 0,77 ja 0,95 tehtävässä 5 ja 6, saavuttaen korkeimmat pisteet kaikista jälkimmäisessä osallistujista.', 'cs': 'Tato práce popisuje účast týmu Universidad Autonoma de Chihuahua, Instituto Nacional de Astrofisica, Optica y Electronica na sdíleném úkolu Sociálních médií Mining for Health Applications (SMM4H). Náš tým se podílel na úkolech 5 a 6, oba se zaměřili na automatickou klasifikaci Twitterových příspěvků souvisejících s COVID-19. Úkol 5 byl zaměřen na řešení problému binární klasifikace, snahou identifikovat samozřejmé tweety potenciálních případů COVID-19. Cílem šesti úkolů bylo klasifikovat tweety obsahující symptomy COVID-19. Pro obě úkoly jsme použili modely založené na obousměrných snímačích reprezentacích transformátorů (BERT). Naším cílem bylo zjistit, zda model předtrénovaný na korpusu v oblasti zájmu může překonat model trénovaný na mnohem větším obecném doménovém korpusu. Naše výsledky F1 byly povzbuzující, 0,77 a 0,95 pro úkol 5 a 6, které dosáhly nejvyššího skóre ze všech účastníků druhého.', 'et': 'Käesolevas töös kirjeldatakse Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica meeskonna osalemist sotsiaalmeedia kaevandamise tervishoiu rakendusteks (SMM4H) 2021. aasta jagatud ülesandes. Meie meeskond osales ülesandes 5 ja 6, mõlemad keskendusid COVID-19-ga seotud Twitteri postituste automaatsele liigitamisele. Ülesanne 5 oli suunatud binaarse klassifikatsiooni probleemi lahendamisele, püüdes tuvastada enesest teatavaid säutseid võimalikest COVID-19 juhtudest. 6. ülesande eesmärk oli klassifitseerida COVID-19 sümptomeid sisaldavaid säutseid. Mõlema ülesande jaoks kasutasime mudeleid, mis põhinevad kahesuunalistel kodeerijate esitustel trafodelt (BERT). Meie eesmärk oli kindlaks teha, kas huvivaldkonnas korpusele eelnevalt treenitud mudel suudab ületada oluliselt suurema üldplaneeritud mudeli. Meie F1 tulemused olid julgustavad, vastavalt 0,77 ja 0,95 ülesande 5 ja 6 puhul, olles saavutanud kõigi viimase osalejate seas kõrgeima skoori.', 'ca': "This work describes the participation of the Universidad Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task.  Our team participated in task 5 and 6, both focused on the automatic classification of Twitter posts related to COVID-19.  Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19.  La tasca 6 va ser classificar els tweets que contenien símptomes COVID-19. For both tasks we used models based on bidirectional encoder representations from transformers (BERT).  El nostre objectiu era determinar si un model pré-entrenat en un cos en el domini d'interès pot superar un entrenat en un cos de domini general molt més gran. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.", 'he': "העבודה הזו מתארת את השתתפות של האוניברסיטה אוטונומה דה צ'יוואווה - Instituto Nacional de Astrofisica, Optica y Electronica צוות במכרת מדיה חברתית לתוכניות בריאות (SMM4H) 2021 משימה משותפת. הצוות שלנו השתתף במשימה 5 ו-6, שניהם התמקדו בהקליטה אוטומטית של עמדות טוויטר שקשורות לקוביד-19. Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19.  מטרה 6 הייתה להקליף טוויטים שמכילים תסמינים COVID-19. לשני המשימות השתמשנו בדוגמנים מבוססים על ייצוגי קודד שתי כיוונים ממעברים (BERT). המטרה שלנו היתה לקבוע אם דוגמנית מתאמנת מראש על קורפוס בתחום האינטרס יכולה להעביר את אחד מאומן על קורפוס בתחום כללי הרבה יותר גדול. תוצאות F1 שלנו היו מעודדות, 0.77 ו-0.95 למשימה 5 ו-6, בהתאם, אחרי שהשגנו את התוצאה הגבוהה ביותר בין כל השתתפים במשימה האחרונה.", 'sk': 'To delo opisuje sodelovanje ekipe Univerze Autonoma de Chihuahua - Instituto Nacional de Astrofisica, Optica y Electronica v skupni nalogi Družbenih medijev Mining for Health Applications (SMM4H) 2021. Naša ekipa je sodelovala pri nalogi 5 in 6, obe pa sta se osredotočili na samodejno klasifikacijo Twitterjevih objav, povezanih s COVID-19. Naloga 5 je bila usmerjena v reševanje problema binarne klasifikacije, poskušanje identificirati samoporočajoče tweete potencialnih primerov COVID-19. Cilj naloge 6 je bil razvrstiti tweete, ki vsebujejo simptome COVID-19. Za obe nalogi smo uporabili modele, ki temeljijo na dvosmernih predstavitvah kodirnikov iz transformatorjev (BERT). Naš cilj je bil ugotoviti, ali lahko model, ki je bil predhodno treniran na korpusu na interesnem področju, presega model, ki je bil usposobljen na veliko večjem korpusu splošne domene. Naši rezultati F1 so bili spodbudni, 0,77 oziroma 0,95 za nalogo 5 oziroma 6, saj smo dosegli najvišjo oceno med vsemi udeleženci v slednjem.', 'ha': 'Wannan aikin yana describe the role of the Universidad Automa de Chuhu - Instituo Nacional de Asstrofisica, Optica y Electronica team at the social Media Mining for Head Applications (SMM4H) 2021 Shared job. Teachenmu sun yi shirin aikin 5 da 6, dukansu sun yi makirci ga classifori farat ɗaya na makala na Twitter masu husũma da COV-19. Kayan aiki 5 aka juyi wa sola wa wata mataimaki na fassarar da dubu, kuma ana jarraba ka gane ta wajen yin juma-jumawa na takardar-da-kanzu. Kijan aikin 6 ya kasance ana rarraba jumuita ta cikin kayan haɗi cikin Symboli na COKID-19. Ga duk aikin da muka yi amfani da misãlai a kan kode-kode masu motsi daga transformation (BERT). Gayinmu ne ya ƙayyade idan wata misali ya yi late a kan korus a cikin duk marubucin, yana iya ƙara wani wanda aka yi wa aikin ya fi girma a matsayin komai. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.', 'jv': 'Olèhku iki nggawe barang urip nggambar ndi Universidadi autoNom de Kijuana - Insto National de AstrOfsika, Optia y electronika nang kelompok Media Minng kanggo Kebebasan Aplikasi ora Olèhku (SMM4H) 2020 1 nggawe barang nggawe Awakdhéwé éntuk nggambar 5 lan 6, éwé wis dipolet nang automatik dipolehasun nyenengaké Google-19. Job 5 task6 Daerah sing ditambah sing ditambah model sing bisa basa ning sampeyan akeh koder kuchasil (BERT). We goal was to define If a model preshined on a bodus in the domain of intermediate can output one F1 sing paling nggambar, 0.', 'bo': 'སྤྱི་ཚོགས་འདིས་རྒྱལ་ཁབ་གྱི་སྤྱི་ཚོགས་ཁང་ཆེན་གྱི་ནང་དུ་ཚོགས ང་ཚོའི་ཕྱོགས་ཁང་གིས་དྲ་རྒྱའི་ནང་དུ་འགྲོ་ཞིབ་བྱས་པ་ལས་ ༥དང་༦། གཉིས་ཀྱིས་རང་འགུལ་གྱིས་ཌིས་ཌིར་ཡོད་པའི་གནས་ཡུ ལྡོག་གྲངས་༥་ནི་གཉིས་པ་དབྱེ་རིམ་གྱི་དཀའ་ངལ་བཤད་ཀྱི་ཐབས་འཇུག་བྱེད་སྐབས་གནད་དོན་དག་ཚད་འཛིན་བྱེད་ཀྱི་ཡོད། Görev 6 དམིགས་ཡུལ་ནི་COVID-19 ཡིག་ཆ་མཚོན་རྟགས་ཡོད་པའི་Tweets་གླེང་སྒྲུབ་བྱེད་དགོས་པ ང་ཚོས་བྱ་འགུལ་གཉིས་པ་ལ་སྤྱོད་པའི་མིག་དཔེ་གཟུགས་རིས་བཀོད་པ་ལས་བཟོ་བཅོས་བྱེད་སྣང་བྱེད་དགོས། Our objective is to determine if a model pretrained on a corpus in the domain of interest can outperform one trained on a much larger general domain corpus. ང་ཚོའི་F1 གི་འབྲས་འབྲས་ནི་ཚོར་བ་སྐྱེན་ཚད་གཅིག་པུ་དང་། ལས་འགུལ་བཞིན་པའི་འགྲོ་སྟངས་༥། ༦།'}
{'en': 'Word Embeddings,  Cosine Similarity  and  Deep Learning  for Identification of Professions & Occupations in Health-related Social Media', 'ar': 'تضمين كلمة ، تشابه جيب التمام والتعلم العميق لتحديد المهن والمهن في وسائل التواصل الاجتماعي المتعلقة بالصحة', 'fr': "Intégration de mots, similarité cosinus et apprentissage approfondi pour l'identification des professions et des professions dans les médias sociaux liés à la santé", 'pt': 'Incorporações de palavras, semelhança de cossenos e aprendizado profundo para identificação de profissões e ocupações em mídias sociais relacionadas à saúde', 'es': 'Incorporación de palabras, similitud de coseno y aprendizaje profundo para la identificación de profesiones y ocupaciones en las redes sociales relacionadas con la salud', 'zh': '词嵌,余弦相似性深学,以识康强社交媒体业', 'ja': '医療関連ソーシャルメディアにおける職業の識別のための単語埋め込み、余弦類似性、および深層学習', 'hi': 'शब्द एम्बेडिंग, कोसाइन समानता और स्वास्थ्य से संबंधित सोशल मीडिया में व्यवसायों और व्यवसायों की पहचान के लिए गहरी शिक्षा', 'ru': 'Внедрение слов, сходство косинусов и глубокое обучение для идентификации профессий и занятий в социальных сетях, связанных со здоровьем', 'ga': 'Leabú Focal, Cosúlacht Cósine agus Foghlaim Dhomhain chun Gairmeacha & Slite Beatha a Aithint sna Meáin Shóisialta a Bhaineann le Sláinte', 'ka': 'სიტყვების შებეჭდვა, კოსინური სინამდვილეობა და ძალიან სწავლება პროფეციების და საკუთოსოციაციის განსაზღვრებისთვის სოციალური მედიაში', 'hu': 'Szóbeágyazások, kozmus hasonlóság és mélytanulás a szakmák és foglalkozások azonosítására az egészségügyi kapcsolatokkal kapcsolatos közösségi médiában', 'el': 'Ενσωματώσεις λέξεων, οικιστική ομοιότητα και βαθιά μάθηση για τον προσδιορισμό επαγγέλματος', 'mk': 'Вклучување на зборови, косинска сличност и длабоко учење за идентификација на професии и работи во социјалните медиуми поврзани со здравството', 'kk': 'Сөздерді ендіру, косину ұқсас және түсінікті оқыту және саулық медиаға сәйкес келген әріптерді идентификациялау үшін', 'it': "Embedding di parole, somiglianza cosina e deep learning per l'identificazione di professioni e professioni nei social media correlati alla salute", 'lt': 'žodžių įtraukimas, kozino panašumas ir gilus mokymasis, siekiant nustatyti profesijas ir profesijas su sveikata susijusioje socialinėje žiniasklaidoje', 'ml': 'വാക്ക് എംബെഡിങ്ങുകള്\u200d, കോസിന്\u200d സമമാകുന്നു, ആഴത്തില്\u200d പഠിക്കുന്ന വാക്കുകള്\u200d സോഷ്യല്\u200d മെഡിയയില്\u200d ആശ്വാസവും തിരിച്ചറ', 'mt': 'Embedding Words, Cosine Similarity and Deep Learning for Identification of Professions & Occupations in Health-related Social Media', 'ms': 'Pencampuran Perkataan, Kesamaan Cosine dan Belajar Dalam Untuk Pengenalan Profesion & Kerja dalam Media Sosial Berkaitan Kesehatan', 'mn': 'Үнэндээ нэмж, Косин тэнцүү байдал болон гүн гүнзгий суралцах нь мэргэжил болон ажиллагааны мэдээлэл болон эрүүл мэндийн холбоотой нийгмийн мэдээлэл', 'ro': 'Încorporarea cuvintelor, similaritatea cosină și învățarea profundă pentru identificarea profesiilor și ocupațiilor în rețelele sociale legate de sănătate', 'sr': 'Izveštanje reči, sličnost kosina i duboko učenje za identifikaciju profesija i profesija u socijalnim medijima povezanim sa zdravstvom', 'no': 'Ordinnbygging, kosinuslingslikning og dyppa læring for identifisering av profesjonar og profesjonar i helsetjende sosiale mediar', 'pl': 'Wkładanie słów, podobieństwo kosynowe i głębokie uczenie się do identyfikacji zawodów w mediach społecznościowych związanych ze zdrowiem', 'sv': 'Word Embeddings, Cosin Likhed och Deep Learning för identifiering av yrken och yrken i hälsorelaterade sociala medier', 'so': 'Heeganka, Sinnaanta iyo Waxbarashada deegaanka ee aqoonsashada xirfadaha iyo shaqaalaha ee macluumaadka bulshada caafimaadka', 'ta': 'வார்த்தை உட்பொதிகள், கோசைன் ஒற்றும் மற்றும் ஆழமான கற்றுக்கொண்டு தொழில்நுட்பம் மற்றும் தொழில்நுட்ப சமூக ஊடகங்களில்', 'ur': 'Word Embeddings, Cosine Similarity and Deep Learning for Identification of Professions & Occupations in Health-related Social Media', 'si': 'Word Embeading, Cosine Simility and Deep learning for ID of Professions & Jobs in Health-සමාජික මාධ්\u200dයමය', 'uz': 'Name', 'vi': 'Ý tưởng Nhúng chữ, Cosin trùng khớp và phát triển sâu để nhận dạng các chuyên gia... "Việc làm trong môi trường xã hội y học."', 'bg': 'Вградени думи, косинусна прилика и задълбочено обучение за идентифициране на професии и професии в социалните медии, свързани със здравето', 'hr': 'Usporavanje riječi, sličnost kosina i duboko učenje za identifikaciju profesija i profesija u socijalnim medijima povezanim s zdravstvenom sredstvima', 'nl': 'Word Embeddings, Cosine Similarity en Deep Learning voor het identificeren van beroepen in Gezondheidsgerelateerde sociale media', 'da': 'Word Embeddings, Cosine lighed og dyb læring til identifikation af erhverv og erhverv i sundhedsrelaterede sociale medier', 'id': 'Penampilan kata, Similaritas Cosine dan Belajar Dalam Untuk Identifikasi Profesion & Perkerjaan dalam Media Sosial Berkaitan Kesehatan', 'fa': 'ابتدایی کلمات، شبیه کاسین و یادگیری عمیق برای شناسایی کارهای و شغل در رسانه های اجتماعی مربوط به سلامت', 'de': 'Word Embeddings, Cosine Ähnlichkeit und Deep Learning zur Identifikation von Berufen in gesundheitsbezogenen Social Media', 'ko': '단어 삽입, 여현 유사성과 심도 있는 학습은 건강 관련 소셜 미디어의 직업을 식별하는 데 쓰인다', 'sw': 'Matambo ya Mazungumzo, Kasini sawa na Ufunzi wa Kideep kwa ajili ya Kutambua Tafsiri na Kazi katika Mitandao ya Kijamii yanayohusiana na Afya', 'af': 'Woord Inbêding, Cosine Similarity en Deep Leer vir Identifikasie van Professions & Occupations in Health-Related Social Media', 'sq': 'Përmbajtja e fjalëve, ngjashmëria kosine dhe mësimi i thellë për identifikimin e profesioneve dhe punëve në mediat sociale të lidhura me shëndetin', 'am': 'Word Embedding, Cosine Similarity and Deep Learn for Identification of Professions and Occupations in Health related social media', 'hy': 'Բառերի ներգրավումը, Կոզինի նմանությունը և խորը սովորելը առողջության հետ կապված սոցիալական մեդիայի մասնագիտությունների և մասնագիտությունների հայտնաբերման համար', 'tr': 'Word Embeddings, Cosine Similarity and Deep Learning for Identification of Professions & Occupations in Health-related Social Media', 'bn': 'স্বাস্থ্য সামাজিক মিডিয়াতে স্বাস্থ্য সংক্রান্ত পেশাদা এবং চাকুরীর পরিচয় চিহ্নিত করার জন্য শব্দ বিদ্যমান, কোসিন সমতা', 'bs': 'Uvedenje riječi, sličnost kosina i duboko učenje za identifikaciju profesija i profesija u socijalnim medijima povezanim s zdravstvenom sredstvu', 'ca': 'Embedding Words, Cosine Similarity and Deep Learning for Identification of Professions & Occupations in Health-related Social Media', 'cs': 'Vložení slov, cosine podobnost a hluboké učení pro identifikaci profesí v sociálních médiích souvisejících se zdravím', 'az': 'Sözlük İfadələri, Kosin Simiları və Profesiyonların və İşyalarının İfadəsi İfadəsi və Səfəlik İfadələrində', 'fi': 'Sanaupotukset, Cosine-samankaltaisuus ja syväoppiminen ammattien ja ammattien tunnistamiseen terveysalan sosiaalisessa mediassa', 'et': 'Sõnade põimimine, koosinuse sarnasus ja sügavõpe kutsealade ja kutsealade tuvastamiseks tervishoiuga seotud sotsiaalmeedias', 'sk': 'Vključevanje besed, kozmejna podobnost in globoko učenje za identifikacijo poklicev in poklicev v socialnih medijih, povezanih z zdravjem', 'jv': 'Word embedding, kosine Similrity and deep Learning for ID of Jobs and Jobs in Public Media', 'he': 'קידום מילים, דמיון קוזין וללמוד עמוק לזהות מקצועים ומקצועים במדיה חברתית קשורה לבריאות', 'ha': 'KCharselect unicode block name', 'bo': 'Word Embeddings, Cosine Similarity and Deep Learning for Identification of Professions & Occupations in Health-related Social Media'}
{'en': 'ProfNER-ST focuses on the recognition of professions and occupations from  Twitter  using Spanish data. Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism. Finally, our best score achieved an F1-measure of 0.823 in the official test set.', 'ar': 'يركز ProfNER-ST على الاعتراف بالمهن والمهن من Twitter باستخدام البيانات الإسبانية. تستند مشاركتنا إلى مجموعة من حفلات الزفاف على مستوى الكلمات ، بما في ذلك BERT الإسبانية المدربة مسبقًا ، بالإضافة إلى تشابه جيب التمام المحسوب على مجموعة فرعية من الكيانات التي تعمل كمدخلات لهندسة فك التشفير مع آلية الانتباه. أخيرًا ، حققت أفضل درجاتنا مقياس F1 عند 0.823 في مجموعة الاختبار الرسمية.', 'fr': "Profner-ST se concentre sur la reconnaissance des professions et des professions à partir de Twitter à l'aide de données espagnoles. Notre participation est basée sur une combinaison d'intégrations au niveau des mots, y compris le BERT espagnol pré-entraîné, ainsi que la similarité cosinus calculée sur un sous-ensemble d'entités qui servent d'entrée pour une architecture encodeur-décodeur avec mécanisme d'attention. Enfin, notre meilleur score a obtenu une mesure F1 de 0,823 dans l'ensemble de test officiel.", 'pt': 'ProfNER-ST se concentra no reconhecimento de profissões e ocupações do Twitter usando dados espanhóis. Nossa participação é baseada em uma combinação de embeddings em nível de palavra, incluindo BERT em espanhol pré-treinado, bem como similaridade de cosseno calculada sobre um subconjunto de entidades que servem como entrada para uma arquitetura de codificador-decodificador com mecanismo de atenção. Finalmente, nossa melhor pontuação alcançou uma medida F1 de 0,823 no conjunto de testes oficial.', 'es': 'Profner-ST se centra en el reconocimiento de profesiones y ocupaciones de Twitter utilizando datos españoles. Nuestra participación se basa en una combinación de incrustaciones a nivel de palabras, que incluyen BERT español previamente entrenado, así como la similitud de coseno calculada sobre un subconjunto de entidades que sirven como entrada para una arquitectura de codificador-decodificador con mecanismo de atención. Finalmente, nuestra mejor puntuación logró una medida F1 de 0,823 en el conjunto de pruebas oficiales.', 'ja': 'ProfNER - STは、スペイン語のデータを使用してTwitterから職業や職業を認識することに焦点を当てています。私たちの参加は、事前にトレーニングを受けたスペイン語のBERTを含むワードレベルの埋め込みと、注意を払うメカニズムを備えたエンコーダーデコーダーアーキテクチャの入力として機能するエンティティのサブセットで計算されたコサインの類似性の組み合わせに基づいています。最後に、私たちのベストスコアは、公式テストセットで0.823のF 1メジャーを達成しました。', 'zh': 'ProfNER-ST专于用西班牙语数知Twitter业。 臣等参单词嵌组,预训之西班牙语BERT,及于实体子集上算之余弦相似性,以为注意机编码器 - 解码器架构之输。 最后,我们的最高考绩在官方测试集到了0.823的F1测量值。', 'hi': 'ProfNER-ST स्पेनिश डेटा का उपयोग करके ट्विटर से व्यवसायों और व्यवसायों की मान्यता पर केंद्रित है। हमारी भागीदारी शब्द-स्तर के एम्बेडिंग के संयोजन पर आधारित है, जिसमें पूर्व-प्रशिक्षित स्पेनिश BERT शामिल है, साथ ही साथ कोसाइन समानता संस्थाओं के सबसेट पर गणना की जाती है जो ध्यान तंत्र के साथ एन्कोडर-डिकोडर आर्किटेक्चर के लिए इनपुट के रूप में काम करती है। अंत में, हमारे सर्वश्रेष्ठ स्कोर ने आधिकारिक परीक्षण सेट में 0.823 का एक F1-माप प्राप्त किया।', 'ru': 'ProfNER-ST фокусируется на признании профессий и занятий из Twitter с использованием испанских данных. Наше участие основано на комбинации вложений на уровне слов, включая предварительно обученный испанский BERT, а также сходства косинусов, вычисленного на подмножестве сущностей, которые служат в качестве входных данных для архитектуры кодер-декодер с механизмом внимания. Наконец, наш лучший результат достиг показателя F1 0,823 в официальном тестовом наборе.', 'ga': "Díríonn ProfNER-ST ar ghairmeacha agus gairmeacha a aithint ó Twitter ag baint úsáide as sonraí Spáinnise. Tá ár rannpháirtíocht bunaithe ar mheascán de leabú ag leibhéal na bhfocal, lena n-áirítear BERT Spáinnis réamh-oilte, chomh maith le cosúlacht cósine a ríomhtar thar fho-thacar eintiteas a fheidhmíonn mar ionchur d'ailtireacht ionchódóra-díchódóra le meicníocht aird. Ar deireadh, bhain ár scór is fearr amach beart F1 de 0.823 sa tsraith oifigiúil tástála.", 'ka': 'პროფენერ-ST იყენებს პროფექციების და კოკექციების განაცნობაზე Twitter-დან სპანელი მონაცემების გამოყენებაზე. ჩვენი დაწყვეტილება სიტყვების კომბინეციების კომბინეციაზე დაბაზიან, რომლებიც პრე დაწყვეტილი სპანელი BERT, და კოსინური განსხვავება, რომლებიც მომხმარებული ინტერციების სპესტი, რომელიც კოდირების კოდე ნაი-კპაწ, ნაქთწრ ნაი-ეჲბყპ ოჲლსფაი ეჲჟრигნა F1-მაზა 0,823 გ ჲტთუთალნთწ რვჟრ ჟვრჟ.', 'hu': 'A ProfNER-ST a szakmák és foglalkozások Twitter-ről történő elismerésére összpontosít spanyol adatok segítségével. Részvételünk a szószintű beágyazások kombinációján alapul, beleértve az előre képzett spanyol BERT-t, valamint az entitások egy részhalmazán keresztül kiszámított koszinusz hasonlóságot, amelyek bemenetként szolgálnak egy kódoló-dekóder architektúrához figyelemmechanizmussal. Végül a legjobb pontszámunk F1-es mértéket ért el a hivatalos tesztkészletben.', 'it': "ProfNER-ST si concentra sul riconoscimento di professioni e professioni da Twitter utilizzando dati spagnoli. La nostra partecipazione si basa su una combinazione di incorporazioni a livello di parola, tra cui BERT spagnolo pre-addestrato, così come somiglianza coseno calcolata su un sottoinsieme di entità che servono da input per un'architettura encoder-decoder con meccanismo di attenzione. Infine, il nostro miglior punteggio ha raggiunto una misura F1 di 0,823 nel set di test ufficiale.", 'el': 'Το ProfNER-ST επικεντρώνεται στην αναγνώριση επαγγελμάτων και επαγγέλμάτων από το Twitter χρησιμοποιώντας ισπανικά δεδομένα. Η συμμετοχή μας βασίζεται σε συνδυασμό ενσωμάτωσης σε επίπεδο λέξεων, συμπεριλαμβανομένων των προ-εκπαιδευμένων Ισπανικών καθώς και ομοιότητας συνημίου που υπολογίζεται σε ένα υποσύνολο οντοτήτων που χρησιμεύουν ως εισαγωγή για μια αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή με μηχανισμό προσοχής. Τέλος, η καλύτερη βαθμολογία μας πέτυχε ένα μέτρο F1 0.823 στο επίσημο σετ δοκιμών.', 'kk': 'Профессор- ST Твиттердің профессионалдарын және мәселелерді испан деректерін қолдану арқылы түсініп тұрады. Біздің қатынасыз сөздер деңгейіндегі ендірудің біріктіріміне негізделген, бұл біріктірілген испан BERT- тің біріктіріміне, сондай-ақ қатынасыз архитектурасы кодерлеу архитектурасы үшін ендіру үшін косину ұқсастығы Соңында, біздің ең жақсы нәтижеміз официалдық сынақтағы 0,823 өлшеміне жеткізді.', 'lt': 'ProfNER-ST focuses on the recognition of professions and occupations from Twitter using Spanish data.  Mūsų dalyvavimas grindžiamas žodžių lygmens įdėjinių deriniu, įskaitant iš anksto apmokytą Ispanijos BERT, taip pat kosino panašumu, apskaičiuotu pagal subjektų pogrupį, kuris naudojamas kaip įdėjimas į kodavimo dekoderių architektūrą su dėmesio mechanizmu. Galiausiai, mūsų geriausias rezultatas oficialiojo bandymo rinkinio F1 rodiklis buvo 0,823.', 'mk': 'ProfNER-ST се фокусира на признавањето на професиите и окупациите од Твитер користејќи шпански податоци. Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism.  Finally, our best score achieved an F1-measure of 0.823 in the official test set.', 'ml': 'സ്പാനിഷ് ഡാറ്റ ഉപയോഗിച്ച് ടൂട്ടറില്\u200d നിന്നും തൊഴിലുകളുടെ തിരിച്ചറിയുന്നതിനെയും പ്രൊഫനെര്\u200d-എസ് Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism.  അവസാനം, നമ്മുടെ ഏറ്റവും നല്ല സ്കോര്\u200d ഓഫീസിലെ പരീക്ഷണസെറ്റില്\u200d 0.823 അളവില്\u200d എത്തി.', 'mt': 'ProfNER-ST jiffoka fuq ir-rikonoxximent ta’ professjonijiet u okkupazzjonijiet minn Twitter bl-użu ta’ dejta Spanjola. Il-parteċipazzjoni tagħna hija bbażata fuq kombinazzjoni ta’ inkorporazzjonijiet fil-livell tal-kliem, inkluż BERT Spanjol imħarreġ minn qabel, kif ukoll similarità kożina kkalkulata fuq sottosett ta’ entitajiet li jservu bħala input għal arkitettura ta’ kodifikatur-dekoder b’mekkaniżmu ta’ attenzjoni. Fl-aħħar nett, l-aħjar punteġġ tagħna kiseb kejl F1 ta’ 0.823 fis-sett uffiċjali tat-test.', 'mn': 'ProfNER-ST нь Твиттерээс мэргэжил болон ажиллах ажиллагааг Испанийн мэдээллийг ашиглан анхаарлаа хандуулдаг. Бидний оролцоо нь хэлний түвшинд суурилсан испан БЕРТ болон анхаарлын механизм дээр косинус төстэй байгууллагуудын нэгдэл дээр тооцоолж байгаа нэгэн бүтээгдэхүүний нэгдэл дээр суурилсан. Эцэст нь бидний хамгийн сайн оноо нь официйн шалгалтын багтаа 0.823-ийн F1 хэмжээтэй хүртсэн.', 'ms': 'ProfNER-ST fokus pada pengenalan profesi dan pekerjaan dari Twitter menggunakan data Spanyol. Pesertaan kami berdasarkan kombinasi pelengkapan aras perkataan, termasuk BERT Spanyol yang dilatih-dilatih, serta persamaan kosinus dikira melalui subset entiti yang berkhidmat sebagai input untuk arkitektur pengekod-dekoder dengan mekanisme perhatian. Akhirnya, skor terbaik kita mencapai ukuran F1 0.823 dalam set ujian rasmi.', 'pl': 'ProfNER-ST koncentruje się na rozpoznawaniu zawodów i zawodów z Twittera przy użyciu danych hiszpańskich. Nasz udział opiera się na połączeniu osadzeń na poziomie słowa, w tym wstępnie przeszkolonych hiszpańskich BERT, a także podobieństwa cosinusowego obliczanego na podzbiorze podmiotów, które służą jako wejście do architektury kodera-dekodera z mechanizmem uwagi. Wreszcie, nasz najlepszy wynik osiągnął F1 miarę 0.823 w oficjalnym zestawie testowym.', 'sr': 'ProfNER-ST se fokusira na priznanje profesija i okupacija iz Twitter koristeći španjolske podatke. Naša sudjelovanje je bazirana na kombinaciji integracija na nivou reči, uključujući predobučenu španjolsku BERT, kao i kosinu sličnost računalo na podskupu entiteta koje služe kao ulaz za arhitekturu kodera sa pažnjom. Na kraju, naš najbolji rezultat je postigao mjeru F1 od 0,823 u službenom setu testova.', 'si': 'Name අපේ සම්බන්ධ විදියට පස්සේ පස්සේ ස්පැනිස් BERT සම්බන්ධ විදියට පස්සේ සම්බන්ධ විදියට පරීක්ෂණය කරලා තියෙන්නේ පස්සේ සම්බන්ධ විදියට සම්බන් අන්තිමේදි, අපේ හොඳම ප්\u200dරමාණයක් පරීක්ෂණ සූදානමේ F1-මාපයක් 0,823 ක් තියෙනවා.', 'ro': 'ProfNER-ST se concentrează pe recunoașterea profesiilor și ocupațiilor de pe Twitter folosind date spaniole. Participarea noastră se bazează pe o combinație de încorporări la nivel de cuvinte, inclusiv BERT spaniol pre-instruit, precum și pe similaritatea cosinului calculată pe un subset de entități care servesc ca intrare pentru o arhitectură codificator-decodor cu mecanism de atenție. În cele din urmă, cel mai bun scor al nostru a obținut o măsură F1 de 0,823 în setul oficial de test.', 'ta': 'ProfNER-ST தொழில்நுட்பங்கள் மற்றும் தொழில்நுட்பங்கள் மற்றும் தொழில்நுட்பத்தை தெரிந்து கொள்கிறது ஸ Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism.  இறுதியில், எங்கள் சிறந்த மதிப்பெண்கள் அரசியல் சோதனை அமைப்பில் 0.823-ன் F1-அளவை அடைந்தது.', 'sv': 'ProfNER-ST fokuserar på erkännande av yrken och yrken från Twitter med hjälp av spanska data. Vårt deltagande baseras på en kombination av inbäddningar på ordnivå, inklusive förkunskaps spanska BERT, samt cosinus likhet beräknad över en delmängd entiteter som fungerar som indata för en kodare-dekoder arkitektur med uppmärksamhetsmekanism. Slutligen uppnådde vår bästa poäng ett F1-mått på 0,823 i den officiella testuppsättningen.', 'ur': 'پروفنر-اس.ٹ.ٹ.ٹ. سے پروفسशन اور کارسازی کی پہچان پر تمرکز کیا جاتا ہے اسپانیایی ڈیٹا کے مطابق۔ ہمارا حصہ لفظ سپانیایی BERT کے شامل ایک جمع پر بنیاد ہے، اور کاسین برابری بھی ایک ایستیوں کے سپسٹ پر کامپیوتر کی گئی ہے جو توجه کی مکانیزی کے ساتھ ایک کوڈر-ڈکور-ڈیکوڈر معماری کے لئے اپنا اپنا اپنا اپنا اپنا اپنا معمار بناتے ہیں. آخر میں، ہمارے سب سے بہترین اسکور 0.823 کی F1 اندازہ پہنچا گئے۔', 'no': 'ProfNER-ST fokuserer på gjenkjenning av profesjonar og opptekningar frå Twitter med spanske data. Partisjonen vårt er basert på eit kombinasjon av ordnivåinnbygging, inkludert før- trenga spansk BERT, og kosinusliteten rekna ut over ein undergruppe av einingar som tjener som inndata for ein koderingsarkitektur med oppmerksmekanisme. Finally, our best score achieved an F1-measure of 0,823 in the official test set.', 'so': 'ProfNER-ST wuxuu ku kalsoonaadaa aqoonsashada xirfadaha iyo xirfadaha Twitterka isticmaalka macluumaadka Isbanishka. Sharcigayagu waxay ku saleysan tahay qalabka heerka ee hadalka, kuwaas oo ku qoran qoraalka Isbanish BERT, sidoo kale kooxinta waxaa lagu xisaabiyay mid ka mid ah waxyaabaha ay u adeegaan sida input u adeegaan qoraal-decoder architecture with attention mechanism. Ugu dambaysta, qiimahayaga ugu wanaagsan waxay gaadhay qiyaastii F1 qiyaasta 0.823 oo ku qoran tijaabada rasmiga ah.', 'vi': 'Giáo sư NER-ST tập trung vào việc nhận biết các nghề nghiệp và giáo dục qua Twitter bằng tài liệu Tây Ban Nha. Sự tham gia của chúng ta dựa trên một sự kết hợp của sự nhúng tay từ cấp, bao gồm hỗn xược Tây Ban Nha được đào tạo, cũng như sự giống nhau cosin được tính toán trên một nhóm các thực thể phục vụ như một phần nhập cho cấu trúc mã hóa với cơ chế tập trung. Cuối cùng, điểm số tốt nhất của chúng ta đạt được một cỡ F1 của 0.83 trong bộ thử chính thức.', 'uz': "Name Bizning qismlarimiz Ispanchadan oldin o'rganish BERT kabi so'zlar tarkibini birlashtirishga asosida, va koksin huddi ishlatilgan narsalarning qismlarini qodqod-dekoder maktablari mekanisme bilan ishlaydigan qismlarga hisoblanadi. Bizning eng yaxshi scorimiz rasm sinov sohasida 0.823ning 0.823ning 0.823 qismiga erishildi.", 'hr': 'ProfNER-ST se fokusira na priznanje profesija i okupacija iz Twitter koristeći španjolske podatke. Naša sudjelovanje je temeljena na kombinaciji integracija na razini riječi, uključujući predobučene španjolske BERT, kao i kosinske sličnosti računalo na podskupini entitata koji služe kao ulaz za arhitekturu kodera s pažnjom. Na kraju, naš najbolji rezultat postigao je mjeru F1 od 0,823 u službenom setu testova.', 'nl': 'ProfNER-ST richt zich op de erkenning van beroepen en beroepen van Twitter met behulp van Spaanse data. Onze deelname is gebaseerd op een combinatie van embeddings op woordniveau, waaronder voorgetrainde Spaanse BERT, evenals cosinus gelijkenis berekend over een subset van entiteiten die dienen als input voor een encoder-decoder architectuur met aandachtsmechanisme. Tot slot behaalde onze beste score een F1-maat van 0.823 in de officiële testset.', 'bg': 'ПрофНЕР-СТ се фокусира върху признаването на професии и професии от Туитър, използвайки испански данни. Участието ни се основава на комбинация от вграждания на ниво дума, включително предварително обучени испански както и косинусова прилика, изчислена върху поднабор от обекти, които служат като вход за архитектура на кодер-декодер с механизъм на внимание. Най-добрият ни резултат постигна мярка от 0.823 в официалния тест комплект.', 'da': 'ProfNER-ST fokuserer på anerkendelse af erhverv og erhverv fra Twitter ved hjælp af spanske data. Vores deltagelse er baseret på en kombination af indlejringer på ordniveau, herunder forududdannet spansk BERT, samt cosinus lighed beregnet over en delmængde enheder, der tjener som input til en encoder-dekoder arkitektur med opmærksomhedsmekanisme. Endelig opnåede vores bedste score et F1-mål på 0,823 i det officielle testsæt.', 'de': 'ProfNER-ST konzentriert sich auf die Anerkennung von Berufen und Berufen aus Twitter anhand spanischer Daten. Unsere Teilnahme basiert auf einer Kombination von Einbettungen auf Wortebene, einschließlich vortrainierter spanischer BERT, sowie Cosinus-Ähnlichkeit, die über eine Teilmenge von Entitäten berechnet wird, die als Eingabe für eine Encoder-Decoder-Architektur mit Aufmerksamkeitsmechanismus dienen. Schließlich erzielte unser bestes Ergebnis im offiziellen Testset ein F1-Maß von 0.823.', 'id': 'ProfNER-ST fokus pada pengakuan profesi dan pekerjaan dari Twitter menggunakan data Spanyol. Pesertakaan kami berdasarkan kombinasi pembangunan tingkat kata, termasuk BERT Spanyol yang terlatih sebelumnya, serta persamaan kosinus yang dihitung melalui subset entitas yang layak sebagai input untuk arsitektur decoder-encoder dengan mekanisme perhatian. Akhirnya, skor terbaik kita mencapai ukuran F1 0,823 dalam set tes resmi.', 'fa': 'پروفNER-ST روی شناسایی کارهای و شغل های توئیتر با استفاده از داده اسپانیایی تمرکز می کند. مشارکت ما بر اساس ترکیب ابتدایی\u200cهای سطح کلمات است، که شامل BERT اسپانیایی پیش آموزش شده است، و همچنین شبیه کاسین\u200cها بر اساس زیر گروهی از گروهی که به عنوان ورودی برای یک معماری کودکور با مکانیسم توجه می\u200cکنند. بالاخره، بهترین امتیاز ما در مجموعه آزمایش رسمی به اندازه F1 0.823 رسیده است.', 'sw': 'ProfNER-ST focuses on the recognition of professions and occupations from Twitter using Spanish data.  Ushiriki wetu umejikita na muunganiko wa ujumbe wa ngazi za maneno, ikiwa ni pamoja na mafunzo ya zamani ya Kihispania BERT, pamoja na kosini yalikadiriwa na suala la vitu ambavyo vinatumika kama input kwa ajili ya ujenzi wa kuandika kodi kwa mfumo wa kutoa hisia. Mwisho, score yetu bora ilipata kipimo cha F1 cha 0.823 katika seti rasmi ya jaribio.', 'tr': "ProfNER-ST Ispanýol maglumaty ulanan professiýalary we işlemlerini Twitter'yň tanamagyna üns berýär. Biziň chikanchasymyz kelime derejesi ekleýän bir birleşigine daýan ýar, öňden öňden öňden öňden öňden öňden öňden öňden öňden ispanyol BERT we Kosin ýaly bir toparynda hasaplanýar. Soňunda, iň gowy synpymyz resmi synagda 0,823 düýbünde F1-ölçüsi tapdy.", 'ko': 'ProfNER ST는 스페인 데이터를 사용하여 트위터에서 전문성과 직업을 식별하는 데 전념하고 있다.우리의 참여는 단어급 삽입의 조합을 바탕으로 미리 훈련된 스페인어 BERT와 실체 서브집합에서 계산된 여현 유사도를 포함하는데 이러한 실체는 주의 메커니즘을 가진 인코더-디코더 체계 구조의 입력으로 사용된다.마지막으로 우리의 최고 성적은 공식 테스트에서 F1의 0.823점에 달했다.', 'sq': 'ProfNER-ST përqëndrohet në njohjen e profesioneve dhe profesioneve nga Twitter duke përdorur të dhënat spanjolle. Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism.  Më në fund, rezultati ynë më i mirë arriti një matje F1 prej 0.823 në grupin zyrtar të testit.', 'hy': 'ProfNet-S կենտրոնանում է Թվիթերի մասնագիտությունների և մասնագիտությունների ճանաչման վրա՝ օգտագործելով իսպաներեն տվյալներ: Մեր մասնակցությունը հիմնված է բառերի մակարդակի ներդրումների համադրման վրա, ներառյալ նախապատրաստված իսպանական BER-ը, ինչպես նաև տիեզերական նմանության վրա, որը հաշվարկվում է անհատականությունների մի ենթախումբի վրա, որոնք ծառայում են որպես ներդրում կոդեր-կոդեր ճարտարապետության Finally, our best score achieved an F1-measure of 0.823 in the official test set.', 'am': 'ፕሮጀኔር-ST የስፓኒሽ ዳታዎችን በመጠቀም ከትዊተር የprofessional እና የሥራ ማወቅ ላይ ያሳያል፡፡ ተግባራችን አስቀድሞ ተማሪ የስፓኒሽ ብኤርቴን እና ቀድሞ ተማሪዎችን የድምፅ አካባቢ አካባቢ አካባቢ እና ኮኮሲን በመስጠት የሆኑትን አካባቢዎች የድምፅ አካባቢ አካውንስነትን በመስጠት ይቆጥራል፡፡ በመጨረሻም የዋነታችን ቁጥር በሥልጣን ፈተና ውስጥ የ0.823 መስፈሪያ አግኝቷል፡፡', 'az': 'ProfNER-ST ńįspanyol m…ôlumatlarńĪnńĪ istifad…ô ed…ôr…ôk Twitter-d…ôn profesyonlarńĪn v…ô iŇül…ôrin tanńĪmasńĪna odaqlanńĪr. Bizim iŇütirańüńĪmńĪz, …ôvv…ôlc…ô t…ôhsil edilmiŇü ńįspanyol BERT, v…ô kosinun b…ônz…ôriliyi, √ľnsiyy…ôt mehńĀnismi il…ô kodlayńĪcńĪ-dekoder arhitektarńĪnńĪn giriŇüi kimi hesablanmńĪŇü bir hiss…ôsinin s…ôviyy…ôsin…ô dayandńĪrńĪlńĪr. Sonunda, …ôn yaxŇüńĪ n√∂qt…ôl…ôrimiz resmi sńĪnama qutusunda 0,823 f1 √∂l√ß√ľs√ľn√ľ q…ôbul etdi.', 'af': "ProfNER-ST fokus op die herken van profesies en occupasies van Twitter deur Spaanse data te gebruik. Ons deelnadering is gebaseer op 'n kombinasie van woord-vlak inbettings, insluitend voor-onderwerp Spaanse BERT, en kosinus gelykenis wat bereken is oor' n subartikel van entiteite wat dien as invoer vir 'n enkoder-dekoder-arkitektuur met aandag mekanisme. Eindelik het ons beste aantal 'n F1-maat van 0,823 in die offisiele toets stel bereik.", 'bn': 'ProfNER-ST focuses on the recognition of professions and occupations from Twitter using Spanish data.  আমাদের অংশগ্রহণের ভিত্তিতে একটি শব্দ-স্তরের ক্ষেত্রে ভিত্তিত, যার মধ্যে পূর্বে প্রশিক্ষিত স্প্যানিশ বিবেরেট এবং একই সাথে কসিন একই ধরনের বস্তুর বিভাগে বিভিন্ন সং অবশেষে, আমাদের সবচেয়ে ভালো স্কোর অফিসিয়াল পরীক্ষার সেটে ০.', 'cs': 'ProfNER-ST se zaměřuje na uznávání profesí a povolání z Twitteru pomocí španělských dat. Naše účast je založena na kombinaci vložení na úrovni slov, včetně předškoleného španělského BERT, stejně jako kosinusové podobnosti vypočítané na podmnožině entit, které slouží jako vstup pro architekturu kodéru-dekódu s mechanismem pozornosti. Nakonec naše nejlepší skóre dosáhlo F1 míry 0,823 v oficiálním testovacím setu.', 'bs': 'ProfNER-ST se fokusira na priznanje profesija i okupacija iz Twitter koristeći španjolske podatke. Naša sudjelovanje je bazirana na kombinaciji integracija na nivou riječi, uključujući predobučenu španjolsku BERT, kao i kosinu sličnost računalo na podskupu entitata koja služe kao ulaz za arhitekturu kodera sa pažnjom. Na kraju, naš najbolji rezultat je postigao mjeru F1 od 0,823 u službenom setu testova.', 'et': 'ProfNER-ST keskendub kutsealade ja kutsealade tunnustamisele Twitterist Hispaania andmete abil. Meie osalemine põhineb sõnatasemel manustamiste kombinatsioonil, sealhulgas eelnevalt koolitatud hispaania BERT, samuti koosinuse sarnasusel, mis arvutatakse üksuste alamhulgal, mis on sisendiks kodeerija-dekooder arhitektuurile tähelepanumehhanismiga. Lõpuks saavutas meie parim tulemus ametlikus testikomplektis F1-mõõdu 0,823.', 'fi': 'ProfNER-ST keskittyy ammattien ja ammattien tunnustamiseen Twitteristä espanjalaisen datan avulla. Osallistuminen perustuu sanatason upotusten yhdistelmään, mukaan lukien esikoulutettu espanjalainen BERT, sekä cosinuksen samankaltaisuuteen, joka lasketaan entiteettien alaryhmän päälle, jotka toimivat syötteenä kooderi-dekooderiarkkitehtuurille huomiomekanismilla. Lopulta paras tuloksemme saavutti virallisen testisarjan F1-mittarin 0,823.', 'ca': "ProfNER-ST es centra en el reconeixement de professions i ocupacions a Twitter utilitzant dades espanyoles. La nostra participació es basa en una combinació d'incorporacions de nivell de paraules, incloent BERT espanyol pré-entrenat, i la similitud cosínica calculada sobre un subconjunt d'entitats que serveixen com entrada per una arquitectura codificadora-decoderadora amb mecanisme d'atenció. Finalment, la nostra millor puntuació va aconseguir una mesura F1 de 0,823 en el conjunt oficial de proves.", 'he': 'ProfNER-ST מתמקד בזיהוי מקצועים ומקצועים מטוויטר באמצעות נתונים ספרדיים. השתתפות שלנו מבוססת על שילוב של תוספות ברמה מילים, כולל BERT ספרדית מאומנת מראש, כמו גם דומות קוסינוס מחשבות על תחתונה של יחידות ששימשות כתוצאה לארכיטקטורה של קודור-קודור עם מנגנון תשומת לב. סוף סוף, התוצאה הטובה ביותר שלנו השיגה F1-מדידה של 0.823 בסט הבדיקות הרשמיים.', 'jv': 'profiNeR-RT iku dipoleh kanggo ngerasakno karo perusahaan karo perusahaan YouTube nggambar data Spanish Jejaring Saiki, sampeyan sing paling dhéwé iso nggawe F1-kaling 0.8-3 ning ujian sing resmi.', 'ha': "profNER-SA yana fokus ga ganin aikin da kuma akan aiki daga Twitter, yanã amfani da data na spanish. Rankinmu na sami a kan komai da maganar-daraja da aka shigar da shi, tare da wanda aka yi wa zaman-haƙƙin Isbanish BERT, da kuma kosin da aka lissafa kamar wani ƙanshi na abubuwa wanda ke amfani da matsayin kodkoder da aikin muhalli. Gani, ma'anarmu mafi kyauta ya sami matsayin F1 na 0.823 a cikin jarraba rasa.", 'sk': 'ProfNER-ST se osredotoča na priznavanje poklicev in poklicev iz Twitterja z uporabo španskih podatkov. Naše sodelovanje temelji na kombinaciji besednih vdelav, vključno s predhodno usposobljenim španskim BERT-om, kot tudi na kosinusovi podobnosti, izračunani na podmnožici entitet, ki služijo kot vhod za arhitekturo kodirnika-dekoderja z mehanizmom pozornosti. Naš najboljši rezultat je dosegel merilo F1 0,823 v uradnem testnem nizu.', 'bo': 'ProfNER-ST ཡིས་སྒེར་གྱི་གནས་ཚུལ་དང་ལས་འཆར་འདོན་གྱི་ངོས་འཛིན་བྱེད་ཀྱི་འདུག་སྟེ། ང་ཚོའི་མཉམ་དུ་འཇུག་སྡུད་ཀྱི་ཁྱད་ཆོས་ཀྱི་སྒྲིག་སྟངས་ཕྱོགས་ཀྱི་ནང་དུ་ཡོད། མཐའ་མར་རང་གི་ཚད་ལྟར་ཤོས་ཡོད་ཚད་གཞུང་གི་བརྟག་དཔྱད་ནང་ཚད་F1-ཚད་0.823 ཡིན་པས།'}
{'en': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021 SMM 4 H  2021', 'fr': "Une approche de formation conjointe pour la classification des tweets et l'extraction et la normalisation des effets indésirables pour SMM4H 2021", 'pt': 'Uma abordagem de treinamento conjunto para classificação de tweets e extração e normalização de efeitos adversos para SMM4H 2021', 'zh': 'SMM4H 2021之推文类不良反应取与归一化合训练方法', 'ar': 'نهج تدريبي مشترك لتصنيف التغريدات واستخراج التأثير الضار والتطبيع لـ SMM4H 2021', 'es': 'Un enfoque de entrenamiento conjunto para la clasificación de tuits y la extracción y normalización de efectos adversos para SMM4H 2021', 'ru': 'Совместный тренировочный подход к классификации твитов и извлечению и нормализации нежелательных эффектов для SMM4H 2021', 'ja': 'SMM 4 H 2021のためのツイート分類と有害作用抽出と正規化のための共同トレーニングアプローチ', 'hi': 'SMM4H 2021 के लिए वर्गीकरण और प्रतिकूल प्रभाव निष्कर्षण और सामान्यीकरण ट्वीट करने के लिए एक संयुक्त प्रशिक्षण दृष्टिकोण', 'ga': 'Cur Chuige Comhpháirteach Oiliúna maidir le hAicmiú Tweet agus Eastóscadh agus Normalú Tionchair Dhíobhálacha do SMM4H 2021', 'ka': 'Name', 'el': 'Μια κοινή εκπαιδευτική προσέγγιση για την ταξινόμηση και την εξαγωγή δυσμενών επιπτώσεων και την ομαλοποίηση για το SMM4H 2021', 'hu': 'Közös képzési megközelítés a Tweet osztályozására és a negatív hatások kivonására és normalizálására az SMM4H 2021-ben', 'kk': 'SMM4H 2021 бағдарламасының жалпы оқыту жағдайы Tweet классификациясы және қарсы эффекттерді тарқату және нормализациясы', 'lt': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'it': "Un approccio formativo congiunto per la classificazione dei Tweet e l'estrazione e la normalizzazione degli effetti avversi per SMM4H 2021", 'mk': 'Заеднички пристап на обука за класификација на Твит и екстракција и нормализација на негативни ефекти за SMM4H 2021', 'mt': 'Approċċ Konġunt tat-Taħriġ għall-Klassifikazzjoni tat-Tweet u l-Estrazzjoni u n-Normalizzazzjoni tal-Effetti Avversi għall-SMM4H 2021', 'ms': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'no': 'Name', 'ml': 'SM4H 2021-ന് വേണ്ടി ടൂട്ടിക്ലാസിക്ഷനും പ്രഭാവം പുറത്തെടുക്കുന്നതിനും നോര്\u200dമാലിഷഷനിലേക്കും ഒരു യൂണ്ട് പരിശീലിയുട', 'mn': 'SMM4H 2021 оны тусламжтайгаар хуваалцах, эсрэг нөлөө гаргах, нормализацийн тусламжтайгаар', 'pl': 'Wspólne podejście szkoleniowe do klasyfikacji Tweet oraz ekstrakcji i normalizacji skutków niepożądanych dla SMM4H 2021', 'ro': 'O abordare comună de formare pentru clasificarea Tweet și extragerea și normalizarea efectelor adverse pentru SMM4H 2021', 'so': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'sr': 'Joint Training Approach to Tweet Classification and Adverse Effects Extraction and Normalization for SMM4H 2021', 'si': 'Name', 'ta': 'Name', 'sv': 'En gemensam utbildningsmetod för tweetklassificering och extraktion av negativa effekter och normalisering för SMM4H 2021', 'ur': 'Name', 'uz': 'Name', 'vi': 'A Liên kết huấn luyện tiếp cận chắp vá và hiệu ứng xấu cho khí cao su', 'bg': 'Съвместен обучителен подход за класификация и извличане и нормализиране на неблагоприятни ефекти за СММ4Х 2021', 'da': 'En fælles uddannelsesmetode til tweetklassificering og ekstraktion og normalisering af negative virkninger for SMM4H 2021', 'nl': 'Een gezamenlijke trainingsaanpak voor tweetclassificatie en extractie en normalisatie van nadelige effecten voor SMM4H 2021', 'hr': 'Zajednički pristup obuke klasifikaciji i izvlačenju nuspojava i normalizaciji SMM4H 2021', 'id': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'sw': 'Mafunzo ya pamoja ya Kupata Makosoleo ya Twita na Kutokana na Utoa na Uhalifu kwa SMM4H 2021', 'fa': 'Name', 'de': 'Ein gemeinsamer Trainingsansatz zur Tweet Klassifizierung und Extraktion und Normalisierung von unerwünschten Wirkungen für SMM4H 2021', 'af': 'Name', 'tr': 'SMM4H 2021', 'ko': 'SMM4H 2021 트위터 분류, 악영향 추출 및 표준화된 합동훈련 방법', 'sq': 'Një metodë e përbashkët stërvitjeje për klasifikimin e Tweet-it dhe nxjerrjen dhe normalizimin e efekteve të dëmshme për SMM4H 2021', 'hy': 'SMM4H 2021', 'am': 'A Joint Training Approach to Twitter Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'az': 'SMM4H 2021 üçün Tövyt Klasifikasyonu və Tövrat Etkinlik Extraction və Normalizasyonu', 'bs': 'Zajednički pristup treninga za klasifikaciju i izvlačenje nuspojava i normalizaciju SMM4H 2021', 'bn': 'এসএমএম৪হ ২০২১ এর জন্য টুইট ক্লাসিকেশন এবং প্রভাব বহিস্কার এবং স্বাভাবিক প্রশিক্ষণের একটি যুক্ত প্রশিক্ষণ', 'cs': 'Společný tréninkový přístup k klasifikaci tweetů a extrakci a normalizaci nežádoucích účinků pro SMM4H 2021', 'et': 'SMM4H 2021 ühine koolitusmeetod Tweet klassifitseerimiseks ja kahjuliku mõju ekstraheerimiseks ja normaliseerimiseks', 'ca': "Un enfocament conjunt de formació a la classificació de Tweet i extracció i normalització d'efectes adversos per SMM4H 2021", 'fi': 'Yhteinen koulutusmenetelmä twiittien luokitteluun ja haitallisten vaikutusten poistoon ja normalisointiin SMM4H 2021', 'ha': 'A Join Training Approach to Twitter Classification and Adverse Effect Extration and Namalization for SMM4H 2021', 'sk': 'Skupni pristop usposabljanja za klasifikacijo Tweet ter ekstrakcijo in normalizacijo škodljivih učinkov za SMM4H 2021', 'bo': 'A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021', 'jv': 'Name', 'he': 'גישה משותפת לאימונים לציוד טוויט והוציאה והנורמליזציה של SMM4H 2021'}
{'en': 'In this work we describe our submissions to the Social Media Mining for Health (SMM4H) 2021 Shared Task. We investigated the effectiveness of a joint training approach to Task 1, specifically classification, extraction and normalization of Adverse Drug Effect (ADE) mentions in English tweets. Our approach performed well on the normalization task, achieving an above average f1 score of 24 %, but less so on  classification  and extraction, with f1 scores of 22 % and 37 % respectively. Our experiments also showed that a larger dataset with more negative results led to stronger results than a smaller more balanced dataset, even when both datasets have the same positive examples. Finally we also submitted a tuned BERT model for Task 6 : Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96 %.', 'fr': "Dans ce travail, nous décrivons nos soumissions à la tâche partagée Social Media Mining for Health (SMM4H) 2021. Nous avons étudié l'efficacité d'une approche de formation conjointe pour la tâche 1, en particulier la classification, l'extraction et la normalisation des mentions des effets indésirables des médicaments (ADE) dans les tweets en anglais. Notre approche a donné de bons résultats sur la tâche de normalisation, obtenant un score f1 supérieur à la moyenne de 24\xa0%, mais moins pour la classification et l'extraction, avec des scores f1 de 22\xa0% et 37\xa0% respectivement. Nos expériences ont également montré qu'un ensemble de données plus important avec des résultats plus négatifs conduisait à des résultats plus solides qu'un ensemble de données plus petit et plus équilibré, même lorsque les deux ensembles de données contiennent les mêmes exemples positifs. Enfin, nous avons également soumis un modèle BERT adapté pour la tâche 6\xa0: Classification des tweets Covid-19 contenant des symptômes, qui a obtenu un score f1 supérieur à la moyenne de 96\xa0%.", 'ar': 'في هذا العمل ، نصف تقديماتنا إلى المهمة المشتركة للتعدين على وسائل التواصل الاجتماعي من أجل الصحة (SMM4H) 2021. لقد حققنا في فعالية نهج التدريب المشترك للمهمة 1 ، وتحديداً تصنيف واستخراج وتطبيع تأثيرات الأدوية الضارة (ADE) المذكورة في التغريدات الإنجليزية. كان أداء مقاربتنا جيدًا في مهمة التطبيع ، حيث حققت درجة F1 أعلى من المتوسط بنسبة 24 ٪ ، ولكن أقل من ذلك في التصنيف والاستخراج ، مع درجات f1 بنسبة 22 ٪ و 37 ٪ على التوالي. أظهرت تجاربنا أيضًا أن مجموعة بيانات أكبر ذات نتائج سلبية أكثر أدت إلى نتائج أقوى من مجموعة بيانات أصغر وأكثر توازناً ، حتى عندما تحتوي كلتا مجموعتي البيانات على نفس الأمثلة الإيجابية. أخيرًا ، قدمنا أيضًا نموذج BERT مضبوطًا للمهمة 6: تصنيف تغريدات Covid-19 التي تحتوي على أعراض ، والتي حققت درجة أعلى من المتوسط بنسبة 96 ٪.', 'pt': 'Neste trabalho descrevemos nossas submissões para a Tarefa Compartilhada Social Media Mining for Health (SMM4H) 2021. Investigamos a eficácia de uma abordagem de treinamento conjunto para a Tarefa 1, especificamente classificação, extração e normalização de menções de Efeitos Adversos de Drogas (ADE) em tweets em inglês. Nossa abordagem teve um bom desempenho na tarefa de normalização, alcançando uma pontuação f1 acima da média de 24%, mas menos na classificação e extração, com pontuações f1 de 22% e 37%, respectivamente. Nossos experimentos também mostraram que um conjunto de dados maior com mais resultados negativos levou a resultados mais fortes do que um conjunto de dados menor e mais balanceado, mesmo quando ambos os conjuntos de dados têm os mesmos exemplos positivos. Por fim, também enviamos um modelo BERT ajustado para a Tarefa 6: Classificação de tweets Covid-19 contendo sintomas, que alcançou uma pontuação f1 acima da média de 96%.', 'es': 'En este trabajo describimos nuestras presentaciones a la Tarea Compartida Minería de Redes Sociales para la Salud (SMM4H) 2021. Investigamos la eficacia de un enfoque de entrenamiento conjunto para la Tarea 1, específicamente la clasificación, extracción y normalización de las menciones de los efectos adversos de los medicamentos (ADE) en los tuits en inglés. Nuestro enfoque tuvo un buen desempeño en la tarea de normalización, logrando una puntuación f1 superior a la media del 24%, pero menos en clasificación y extracción, con puntuaciones f1 del 22% y 37% respectivamente. Nuestros experimentos también mostraron que un conjunto de datos más grande con resultados más negativos condujo a resultados más sólidos que un conjunto de datos más pequeño y equilibrado, incluso cuando ambos conjuntos de datos tienen los mismos ejemplos positivos. Finalmente, también presentamos un modelo BERT ajustado para la Tarea 6: Clasificación de los tuits de Covid-19 que contienen síntomas, que logró una puntuación f1 superior a la media del 96%.', 'ja': 'この作業では、ソーシャルメディア・マイニング・フォー・ヘルス（ SMM 4 H ） 2021シェアードタスクへの提出物について説明します。私たちは、タスク1への共同トレーニングアプローチ、特に英語のツイートでの有害薬物効果（ ADE ）の分類、抽出、および正規化の有効性を調査しました。私たちのアプローチは正規化タスクでうまく機能し、平均以上のf 1スコア24 ％を達成しましたが、分類と抽出ではそれほど高くなく、f 1スコアはそれぞれ22 ％と37 ％でした。私たちの実験では、ネガティブな結果が多い大きなデータセットは、両方のデータセットが同じポジティブな例を持っている場合でも、より小さくバランスの取れたデータセットよりも強力な結果をもたらすことも示されました。最後に、私たちはまた、タスク6 ：症状を含むCovid -19ツイートの分類のための調整されたBERTモデルを提出しました。これは、平均f 1スコア96 ％を上回る成績を達成しました。', 'zh': '于兹之事,述我于社交媒体(SMM4H)2021共其材。 按1合训练方法之有效性,特英语推文中药物不良反应(ADE)之类,提取标准化。 吾道见善于归一化,f1得分高于平均水平24%,而取类则下,f1得分为22%37%。 吾实验犹明,多负面之数集比小而衡,虽两数同正示例亦如之。 为任6取一BERT:含其Covid-19推文,其f1得分高于平均水平96%。', 'hi': 'इस काम में हम स्वास्थ्य के लिए सोशल मीडिया माइनिंग (SMM4H) 2021 साझा कार्य के लिए हमारी प्रस्तुतियों का वर्णन करते हैं। हमने कार्य 1 के लिए एक संयुक्त प्रशिक्षण दृष्टिकोण की प्रभावशीलता की जांच की, विशेष रूप से वर्गीकरण, निष्कर्षण और प्रतिकूल दवा प्रभाव (एडीई) के सामान्यीकरण का उल्लेख अंग्रेजी ट्वीट्स में किया गया है। हमारे दृष्टिकोण ने सामान्यीकरण कार्य पर अच्छा प्रदर्शन किया, 24% के ऊपर के औसत f1 स्कोर को प्राप्त किया, लेकिन वर्गीकरण और निष्कर्षण पर कम, क्रमशः 22% और 37% के f1 स्कोर के साथ। हमारे प्रयोगों से यह भी पता चला है कि अधिक नकारात्मक परिणामों के साथ एक बड़े डेटासेट ने एक छोटे से अधिक संतुलित डेटासेट की तुलना में मजबूत परिणाम दिए, भले ही दोनों डेटासेट में समान सकारात्मक उदाहरण हों। अंत में हमने टास्क 6 के लिए एक ट्यून किए गए BERT मॉडल को भी प्रस्तुत किया: लक्षणों वाले कोविद -19 ट्वीट्स का वर्गीकरण, जिसने 96% के औसत से ऊपर का औसत f1 स्कोर हासिल किया।', 'ru': 'В этой работе мы описываем наши материалы для совместной задачи «Майнинг в социальных сетях для здоровья» (SMM4H) 2021 года. Мы исследовали эффективность совместного тренировочного подхода к Задаче 1, а именно классификацию, извлечение и нормализацию упоминаний о неблагоприятном воздействии препарата (ADE) в английских твитах. Наш подход показал хорошие результаты при выполнении задачи нормализации, достигнув выше среднего балла f1 24%, но в меньшей степени при классификации и экстракции, с баллами f1 22% и 37% соответственно. Наши эксперименты также показали, что больший набор данных с более отрицательными результатами привел к более сильным результатам, чем меньший более сбалансированный набор данных, даже если оба набора данных имеют одинаковые положительные примеры. Наконец, мы также представили настроенную модель BERT для Задачи 6: Классификация твитов о Covid-19, содержащих симптомы, которая достигла выше среднего балла f1 96%.', 'ga': 'San obair seo déanaimid cur síos ar ár n-aighneachtaí don Tasc Comhroinnte um Mhianadóireacht ar na Meáin Shóisialta le haghaidh Sláinte (SMM4H) 2021. Rinneamar imscrúdú ar éifeachtúlacht cur chuige comhoiliúna i leith Tasc 1, go sonrach aicmiú, asbhaint agus normalú tagairtí i dtvuíteanna Béarla a bhaineann le Éifeacht Dhíobhálach Drugaí (ADE). D’fheidhmigh ár gcur chuige go maith ar an tasc normalaithe, ag baint amach scór f1 os cionn an mheáin de 24%, ach ní ba lú ná sin maidir le haicmiú agus asbhaint, le scóir f1 de 22% agus 37% faoi seach. Léirigh ár dturgnaimh freisin gur tháinig torthaí níos láidre as tacar sonraí níos mó le torthaí níos diúltaí ná tacar sonraí níos lú níos cothroime, fiú nuair a bhíonn na samplaí dearfacha céanna ag an dá thacar sonraí. Mar fhocal scoir chuireamar isteach freisin múnla tiúnta BERT le haghaidh Tasc 6: Aicmiú tvuíteanna Covid-19 ina bhfuil airíonna, a bhain amach scór f1 os cionn an mheáin de 96%.', 'ka': 'ამ სამუშაოში ჩვენ 2021 წლის სოციალური მედიაში საზოგადოება (SMM4H) სხვა სამუშაო სამუშაო სამუშაო დავალებათ. ჩვენ განსხვავით ერთადერთი განსწავლების პროგრამის ეფექტიკურობას, განსაკუთრებით კლასიფიკაცია, ექსტრექცია და ნორმალიზაცია ინგლისური tweets-ში. ჩვენი პროგორმაცია ნორმალიზაციის რაოდენობაში კარგი გავაკეთებულია, რომელიც უფრო მეორე f1 წოდენობა 24%-ის, მაგრამ უფრო მეორე კლასიფიკაცია და ექსტრაქცია, რომელიც f1 წოდენობა 22 ჩვენი ექსპერიმენტები ასევე გამოჩვენეთ, რომ უფრო დიდი მონაცემების კონფიგურაცია, რომელიც უფრო მინდა უფრო დიდი მონაცემების კონფიგურაცია, უფრო მცირე ბა საბოლოოდ ჩვენ ასევე გადავიტანეთ განსხვავებული BERT მოდელი 6-ის დავალებისთვის: Covid-19 tweets-ის კლასიფიკაცია, რომლებიც სიმპტომები აქვს, რომელიც საშუალოდ მეტი f1 მოდელი 96%.', 'hu': 'Ebben a munkában bemutatjuk a Közösségi Média Bányászat az Egészségért (SMM4H) 2021 Megosztott Feladatához való beadványainkat. Megvizsgáltuk az 1. feladat közös képzési megközelítésének hatékonyságát, különösen a mellékhatás (ADE) besorolását, extrakcióját és normalizálását angol tweetekben. Megközelítésünk jól teljesített a normalizációs feladatban, 24%-os átlag feletti f1 pontszámot ért el, de kevésbé osztályozást és extrakciót, 22%-os, illetve 37%-os f1 pontszámot. Kísérleteink azt is mutatták, hogy egy nagyobb, negatív eredményekkel rendelkező adatkészlet erősebb eredményeket eredményezett, mint egy kisebb, kiegyensúlyozottabb adatkészlet, még akkor is, ha mindkét adatkészlet ugyanazon pozitív példával rendelkezik. Végezetül benyújtottunk egy hangolt BERT modellt a 6. feladathoz: A tüneteket tartalmazó Covid-19 tweetek osztályozása, amely az átlag feletti f1 pontszámot érte el 96%.', 'el': 'Σε αυτή την εργασία περιγράφουμε τις υποβολές μας στην Κοινή Εργασία Κοινωνικών Μέσων Εξόρυξης για την Υγεία (Κοινή Εργασία). Ερευνήσαμε την αποτελεσματικότητα μιας κοινής εκπαιδευτικής προσέγγισης στην εργασία 1, συγκεκριμένα την ταξινόμηση, εξαγωγή και ομαλοποίηση των αναφορών ανεπιθύμητων φαρμάκων (ADE) στα αγγλικά tweets. Η προσέγγισή μας πέτυχε καλά στο έργο ομαλοποίησης, επιτυγχάνοντας μια ανώτερη βαθμολογία f1 24%, αλλά λιγότερο στην ταξινόμηση και εξαγωγή, με βαθμολογίες f1 22% και 37% αντίστοιχα. Τα πειράματά μας έδειξαν επίσης ότι ένα μεγαλύτερο σύνολο δεδομένων με περισσότερα αρνητικά αποτελέσματα οδήγησε σε ισχυρότερα αποτελέσματα από ένα μικρότερο πιο ισορροπημένο σύνολο δεδομένων, ακόμα και όταν και τα δύο σύνολα δεδομένων έχουν τα ίδια θετικά παραδείγματα. Τέλος, υποβάλαμε επίσης ένα συντονισμένο μοντέλο για την εργασία 6: Ταξινόμηση tweets που περιέχουν συμπτώματα, το οποίο πέτυχε μια ανώτερη από τον μέσο όρο βαθμολογία των 96%.', 'kk': 'Бұл жұмыста 2021 жылы Ортақ тапсырманың социалдық медиа балауына (SMM4H) жіберімізді таңдаймыз. Біз 1- тапсырма үшін біріктірілген оқыту тәсілдігін зерттедік, осындай-ағылшын tweets тізімінде айтылатын қарсы наркотикалық эффекттерді (ADE) тарқату және нормализациялау. Біздің қасиетіміз нормализациялау тапсырмасында жақсы орындалды, орташа f1 нүктесі 24% деп жеткізді, бірақ қасиетті және тарқатуға арналған, f1 нүктесі 22% мен 37% деп жеткізді. Біздің тәжірибеміз сондай-ақ кейбір негативті нәтижелерден үлкен деректер жинағы бірнеше нәтижелерді балансирован деректер жинағынан күш нәтижелерді көрсетуге болады. Екі дер Соңында біз сондай-ақ 6- тапсырма үшін BERT үлгісін жібердік: Covid-19 tweets классификациясы бар симптомдар бар, ол орташа f1 деңгейіндегі 96% деңгейінде жеткізді.', 'it': "In questo lavoro descriviamo i nostri contributi al Social Media Mining for Health (SMM4H) 2021 Shared Task. Abbiamo esaminato l'efficacia di un approccio formativo congiunto al Task 1, in particolare classificazione, estrazione e normalizzazione delle menzioni di effetti avversi della droga (ADE) nei tweet inglesi. Il nostro approccio ha funzionato bene nel compito di normalizzazione, raggiungendo un punteggio f1 superiore alla media del 24%, ma meno sulla classificazione e l'estrazione, con punteggi f1 rispettivamente del 22% e del 37%. I nostri esperimenti hanno anche dimostrato che un set di dati più ampio con risultati più negativi ha portato a risultati più forti di un set di dati più piccolo e bilanciato, anche quando entrambi i set di dati hanno gli stessi esempi positivi. Infine abbiamo presentato anche un modello BERT sintonizzato per Task 6: Classificazione dei tweet Covid-19 contenenti sintomi, che ha raggiunto un punteggio superiore alla media di f1 del 96%.", 'lt': 'Šiame darbe apibūdiname savo pareiškimus Socialinės žiniasklaidos kasybos sveikatos srityje (SMM4H) 2021 m. bendrai užduočiai. We investigated the effectiveness of a joint training approach to Task 1, specifically classification, extraction and normalization of Adverse Drug Effect (ADE) mentions in English tweets.  Mūsų metodas gerai atliko normalizacijos užduotį, pasiekti didesnį nei vidutinis f1 balas 24 %, bet mažiau klasifikacijos ir ekstrakcijos atveju, o f1 balai atitinkamai 22 % ir 37 %. Mūsų eksperimentai taip pat parodė, kad didesnis duomenų rinkinys su labiau neigiamais rezultatais sukėlė didesnius rezultatus nei mažesnis labiau subalansuotas duomenų rinkinys, net jei abu duomenų rinkiniai turi tokių pačių teigiamų pavyzdžių. Galiausiai taip pat pateikėme pritaikytą BERT model į 6 uždaviniui: Covid-19 tweetų klasifikavimas su simptomais, kurie pasiekė didesnį nei vidutinis f1 balas 96 %.', 'ml': 'ഈ ജോലിയില്\u200d നമ്മുടെ സോഷ്യല്\u200d മീഡിയ മിനിങ്ങിന്\u200dറെ കീഴടങ്ങള്\u200d ഞങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. ആശ്വാസത്തിന്\u200dറെ മിനിങ് ടാസ്ക് 1-ലേക്കുള്ള യൂട്ട് ട്രെയിനിലേക്കുള്ള പരിശീലനത്തിന്റെ പ്രവർത്തികമാണ് ഞങ്ങള്\u200d അന്വേഷിച്ചു. പ്രത്യേകിച്ച് വിശേഷം വിവരങ് നമ്മുടെ സമ്പാദ്യം സാധാരണ പ്രവര്\u200dത്തിക്കുന്നതില്\u200d നന്നായി പ്രവര്\u200dത്തിച്ചു. ശരാരം എഫ്\u200c1 സ്കോര്\u200d 24 ശതമാനത്തിന് മീതെ എത്തുന്നതാണ്, പക്ഷെ ക്ലാസ്ഫി നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് കൂടുതല്\u200d നെഗേറ്റീവ് ഫലങ്ങളുള്ള വലിയ ഡാറ്റാസറ്റുകള്\u200d കൂടുതല്\u200d ശക്തമായ ഫലങ്ങള്\u200d കാ Finally we also submitted a tuned BERT model for Task 6: Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96%.', 'ms': 'Dalam kerja ini kami menggambarkan penghantaran kami kepada Media Sosial Menyembah Kesehatan (SMM4H) 2021 Tugas Berkongsi. Kami menyelidiki kegunaan pendekatan latihan bersama untuk Tugas 1, secara khusus klasifikasi, ekstraksi dan normalisasi kesan dadah (ADE) disebut dalam tweet Inggeris. Pendekatan kami berjalan dengan baik pada tugas normalisasi, mencapai skor f1 di atas rata-rata 24%, tetapi kurang pada klasifikasi dan ekstraksi, dengan skor f1 22% dan 37% respectively. Our experiments also showed that a larger dataset with more negative results led to stronger results than a smaller more balanced dataset, even when both datasets have the same positive examples.  Akhirnya, kami juga menghantar model BERT yang sesuai untuk Tugas 6: Pengklasifikasi tweet Covid-19 yang mengandungi gejala, yang mencapai skor f1 di atas rata-rata 96%.', 'mn': 'Энэ ажлын хувьд бид 2021 оны нийгмийн мэдээллийн салбарын багасгал хөрөнгө оруулалтыг тайлбарлаж байна. Бид 1-р ажил дээр хамтдаа сургалтын үр дүнг судалж, ялангуяа англи хэлний tweets дээр хэлж байгаа эсрэг наркотийн эффект (ADE) нэмэгдүүлэх, хадгалах болон нормализацийг судалсан. Бидний арга хэмжээний ажил дээр сайн ажиллаж байлаа. Дунд дундаж f1 хувь нь 24%-той хүртэл, гэхдээ хэмжээний хувьд, хадгалах нь бага байлаа. f1 хувьд 22%-37%-той бага байлаа. Бидний туршилтууд мөн илүү сөрөг үр дүнтэй том өгөгдлийн санг баланслагдсан өгөгдлийн санаас илүү хүчтэй үр дүнг үзүүлсэн. Хоёр өгөгдлийн санг ижил эерэг жишээлүүд байсан ч гэсэн. Эцэст нь бид мөн ажил 6-ын BERT загварыг дамжуулсан: Covid-19 tweets-ийн классификацийн шинж тэмдэгтийг агуулсан бөгөөд энэ нь дундаж f1 оноо 96% гарсан.', 'mk': 'Во оваа работа ги опишуваме нашите поднесувања на Социјалните медиуми за здравство (SMM4H) 2021 заедничка задача. Ја истражувавме ефикасноста на заедничкиот пристап на обука кон задачата 1, специфично класификација, екстракција и нормализација на спомените на Негативниот ефект на дрогата (АДЕ) на англиски твитови. Our approach performed well on the normalization task, achieving an above average f1 score of 24%, but less so on classification and extraction, with f1 scores of 22% and 37% respectively.  Нашите експерименти, исто така, покажаа дека поголем компјутер податоци со поголеми негативни резултати доведоа до посилни резултати отколку помал побалансиран компјутер податоци, дури и кога двата компјутери податоци имаат исти позит Конечно, исто така, поднесовме приспособен модел БЕРТ за задачата 6: Класификација на твитовите Covid-19 кои содржат симптоми, кој постигна над просечната оценка f1 од 96 отсто.', 'ro': 'În această lucrare descriem depunerile noastre la Social Media Mining for Health (SMM4H) 2021 Shared Task. Am investigat eficacitatea unei abordări comune de instruire a sarcinii 1, în special clasificarea, extragerea și normalizarea mențiunilor de efect advers al medicamentului (ADE) în tweeturile în limba engleză. Abordarea noastră s-a descurcat bine în sarcina de normalizare, obținând un scor f1 peste medie de 24%, dar mai puțin în clasificare și extracție, cu scoruri f1 de 22% și respectiv 37%. Experimentele noastre au arătat, de asemenea, că un set de date mai mare cu rezultate mai negative a dus la rezultate mai puternice decât un set de date mai mic, mai echilibrat, chiar și atunci când ambele seturi de date au aceleași exemple pozitive. În cele din urmă, am prezentat, de asemenea, un model BERT reglat pentru Sarcina 6: Clasificarea tweeturilor Covid-19 conținând simptome, care a obținut un scor f1 peste medie de 96%.', 'pl': 'W niniejszej pracy opisujemy nasze zgłoszenia do Social Media Mining for Health (SMM4H) 2021 Shared Task. Badaliśmy skuteczność wspólnego podejścia szkoleniowego do zadania 1, w szczególności klasyfikacji, ekstrakcji i normalizacji wzmianek o niepożądanym efekcie leku (ADE) w angielskich tweetach. Nasze podejście sprawdziło się dobrze w zadaniu normalizacyjnym, osiągając ponadśredni wynik f1 24%, ale mniej w klasyfikacji i ekstrakcji, z wynikami f1 odpowiednio 22% i 37% . Nasze eksperymenty wykazały również, że większy zbiór danych z większymi negatywnymi wynikami prowadził do silniejszych wyników niż mniejszy bardziej zrównoważony zbiór danych, nawet jeśli oba zbiory danych mają te same pozytywne przykłady. Na koniec przedstawiliśmy również dostrojony model BERT dla zadania 6: Klasyfikacja tweetów Covid-19 zawierających objawy, który osiągnął ponadśredni wynik f1 96%.', 'no': 'I denne arbeiden beskriver vi våre søknader til den sosiale mediamining for helse (SMM4H) 2021 delte oppgåva. Vi undersøkte effektiviteten av ein samanlig treningstilnærming til oppgåve 1, spesifikke klassifisering, ekstrahering og normalisering av Adverse Drug Effect (ADE) som er avgjeven i engelsk tweets. Nærminga vårt utførte godt på normaliseringsdata, og når det gjennomsnittlig f1- poeng på 24%, men mindre så på klassifikasjon og utpakking, med f1- poeng på 22% og 37%. Eksperimentane våre viste også at ein større dataset med meir negativ resultat førte til sterke resultat enn ein mindre meir balansert dataset, sjølv når begge dataset har samme positiv eksemplar. I slutt har vi også sendt ein tunert BERT-modell for oppgåve 6: Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96%.', 'mt': 'F’din il-ħidma niddeskrivu s-sottomissjonijiet tagħna lill-Minjieri tal-Midja Soċjali għas-Saħħa (SMM4H) 2021 Kompitu Konġunt. Investigajna l-effikaċja ta’ approċċ konġunt ta’ taħriġ għall-Kompitu 1, speċifikament klassifikazzjoni, estrazzjoni u normalizzazzjoni ta’ msemmija fl-Effett Avversi tal-Mediċin a (ADE) fit-tweets bl-Ingliż. L-approċċ tagħna wettaq tajjeb fuq il-kompitu ta’ normalizzazzjoni, u kiseb punteġġ f1 ogħla mill-medja ta’ 24%, iżda inqas hekk fuq il-klassifikazzjoni u l-estrazzjoni, b’punteġġi f1 ta’ 22% u 37% rispettivament. L-esperimenti tagħna wrew ukoll li sett ta’ dejta akbar b’riżultati aktar negattivi wassal għal riżultati aktar b’saħħithom minn sett ta’ dejta iżgħar aktar ibbilanċjat, anki meta ż-żewġ settijiet ta’ dejta jkollhom l-istess eżempji pożittivi. Finally we also submitted a tuned BERT model for Task 6: Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96%.', 'sr': 'U ovom poslu opisujemo svoje podatke za rudarstvo socijalnih medija za zdravlje (SMM4H) 2021. zajedničkom zadatku. Istražili smo učinkovitost zajedničkog pristupa obuke zadatku 1, posebno klasifikaciji, ekstrahaciji i normalizaciji nuspojava na engleskim tweetima. Naš pristup je dobro obavljen na normalizacijskom zadatku, ostvario iznad prosječnog f1 rezultata od 24%, ali manje na klasifikaciji i izvlačenju, sa f1 rezultatima od 22% i 37%. Naši eksperimenti su takođe pokazali da je veća kompleta podataka sa više negativnih rezultata dovela do jača rezultata od manje balanciranije kompleta podataka, čak i kada oba kompleta podataka imaju isti pozitivni primer. Na kraju smo takođe predali i napravljeni model BERT za zadatak 6: klasifikacija Covid-19 tweets koji sadrže simptome, koji je postigao iznad prosječnog f1 rezultata od 96%.', 'si': 'මේ වැඩේ අපි 2021 සාමාජික මිඩියාව ස්වාස්ථ්\u200dය විධානය (SMM4H) වෙනුවෙන් අපේ පිළිබඳින් විස්තර කරනවා. අපි පරීක්ෂණය කළා සාමාන්\u200dය ප්\u200dරශ්නයක් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන්, ප්\u200dරශ්නයක් සහ සාමාන්\u200dය ව්\u200dයාප්\u200dති අපේ ප්\u200dරමාණය සාමාන්\u200dය වැඩේ හොඳයි, සාමාන්\u200dය වැඩි වැඩිය f1 ප්\u200dරමාණයක් 24%, නමුත් වැඩිය සහ ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා f1 අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විශාල දත්ත සෙට් එක්ක වඩා විශාල ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති අන්තිමේදී අපි අන්තිමේදී වැඩ 6 වෙනුවෙන් සම්පූර්ණ BERT මොඩේලයක් පිළිගත්තා: කෝවිඩ්-19 ට්විට් වලට සංකේතයක් තියෙන්න', 'sv': 'I det här arbetet beskriver vi våra bidrag till Social Media Mining for Health (SMM4H) 2021 Shared Task. Vi undersökte effektiviteten av en gemensam utbildningsmetod för uppgift 1, specifikt klassificering, extraktion och normalisering av Adverse Drug Effect (ADE) omnämningar i engelska tweets. Vårt tillvägagångssätt presterade bra på normaliseringsuppgiften och uppnådde en f1-poäng över genomsnittet på 24%, men mindre på klassificering och extraktion, med f1-poäng på 22% respektive 37%. Våra experiment visade också att en större datamängd med mer negativa resultat ledde till starkare resultat än en mindre mer balanserad datamängd, även när båda datauppsättningarna har samma positiva exempel. Slutligen lämnade vi också in en justerad BERT-modell för Uppgift 6: Klassificering av Covid-19 tweets innehållande symtom, som uppnådde en poäng över genomsnittet f1 på 96%.', 'so': 'Shaqadan ayaannu ku qoraynaa hoosaysiintayada daryeelka caafimaadka bulshada (SMM4H) 2021 Shaqada la sharciyey. Waxaannu baaraynay waxyaabaha ay u leedahay qaabka iskuulka waxbarashada wadajirka ah ee shaqada 1, si gaar ah u kala soocaynta, soo bixinta iyo caadooyinka arimaha dawooyinka ee afka Ingiriiska. Dhaqdhaheenna waxay si wanaagsan u sameeyeen shaqada caadiga ah, waxayna gaadheen qiimaha ugu badnaan iskuulka f1 oo ah 24%, laakiin wax ka yar fasaxa iyo ka bixinta, iskuulka f1 ee ugu dhexeeya 22% iyo 37 boqolkiiba. Imtixaankayada ayaa sidoo kale muujiyey in kooban macluumaad ka weyn oo ay ku jiraan matooyin wax ka badan, waxay sababtay resulto ka sii xoogaysan in ka sii yar sameynta macluumaadka, xataa marka labada database ay haystaan tusaalooyin isku mid ah. Ugu dambaysta waxaan sidoo kale u soo dhiibnay Tusaale BERT oo loo qoray shaqo 6: Kalajarida qoraalka Covid-19 oo ku jira calaamado, taasoo gaadhay iskuul ka badan f1 boqolkiiba 96 boqolkiiba.', 'ur': 'اس کام میں ہم نے 2021 شریک ٹاکس کے لئے سوسیل میڈیا مینینگ (SMM4H) کے ذریعے اپنے مسائل کو توصیح دیتے ہیں. ہم نے تاسک ۱ کے ساتھ ایک جوڑ ترینسی طریقے کے مطابق تحقیق کی، مخصوصاً کلاسیفوں، اخراج اور عاملی انگلیسی ٹویٹوں میں ذکر کی۔ ہمارا طریقہ عامل کرنے کے کام پر بہت اچھا کام کیا گیا تھا، ایک متوسط f1 اسکو 24% کی پہنچ رہا تھا، لیکن بہت کم طریقہ اور اخراج کے ذریعہ، اور f1 اسکو 22% اور 37% کے ذریعہ. ہماری آزمائش نے بھی دکھائی کہ بہت بڑے ڈاٹ سٹ کے ساتھ بہت منفی نتیجے کے ساتھ ایک چھوٹے برالیس ڈاٹ سٹ سے زیادہ قوی نتیجے پہنچائے، اگرچہ دونوں ڈاٹ سٹ ایک مثبت مثال ملے آخر میں ہم نے ٹاکس 6 کے لئے ایک تنظیم BERT موڈل بھیجا تھا: Covid-19 ٹویٹ کے کلاسیفٹ کے ذریعہ نشانیاں حامل ہوئے ہیں، جو ایک متوسط f1 اسکور 96 درصد تک پہنچ گئے۔', 'ta': 'இந்த வேலையில் நாம் எங்கள் சமூக ஊடகத்திற்கு ஒப்புக்கொள்ள விவரிக்கிறோம் சோதனைக்கு (SMM4H) 2021 பகிர்ந்த பணியை கூட்ட நாங்கள் செயல் 1 க்கு ஒரு இணைய பயிற்சி செயல்பாட்டின் விளைவுகளை ஆய்வு செய்தோம், குறிப்பாக வகுப்பு, பிரித்தல் மற்றும் இயல்பான விளைவு நம்முடைய செயல்பாடு வழக்கமான செயல்பாட்டில் நன்றாக செய்தது, சராசரியான F1 புள்ளிகள் 24% மேல் அடைந்தது, ஆனால் வகுப்பில் மற்றும் பிரிப்பு பெறுவதி மேலும் எதிர்மறை முடிவுகளுடன் பெரிய தரவுத்தளத்தை காண்பித்துள்ளோம். இரு தரவுத் தளங்களும் அதே நேர்ம உதாரணங்கள் இருக்கும் போதும்  இறுதியில் நாம் செயல் 6 க்கு ஒரு குறிப்பிட்ட BERT மாதிரியை கூட்டினோம்: குவிட்-19 குறியீடுகள் உள்ள வகைப்படுத்தல், அது சராசரி f1 புள்ளி', 'uz': "Bu vazifanda, 2021 yordamida qo'shilgan vazifa haqida jamiyat media ta'minlovchimizni anglatamiz. Biz Vazifani 1'ga birlashtirish usulining effektini o'rganib ko'rib chiqardik, boshqa narsalar Effektlarini ajratish va oddiylikni ingliz Twitter tilida tahrirlash imkoniyatini o'rganamiz. Bizning fikrimiz oddiylik vazifasini bajaradi, o'rtacha soni 24%'dan ortiq f1 scorini topish, lekin darajalashtirish va chiqarish bilan bir xil f1 scorida 22% va 37% darajaga ega bo'lgan. Bizning tajribalarimiz esa ko'proq negativ natijalar bilan katta maʼlumotlar tarkibini ko'rsatadi va ikkita maʼlumotlar sonlarida bir yaxshi misol bor. Oxirgi biz Vazifani 6 uchun bir bir bir bir bir BERT modelini qoʻllab berdik: Koid-19 xabarlarni taqlash imkoniyatlari bilan imkoniyatlash va u 96 foizdan ortiq f1 foiz topdi.", 'vi': 'Trong công việc này, chúng tôi mô tả những kiến nghị của chúng tôi cho công việc chia sẻ cán bộ truyền thông xã hội (SMM44H) 2021. Chúng tôi đã điều tra tính hiệu quả của một phương pháp huấn luyện chung cho Nhiệm vụ 1, đặc biệt phân loại, chiết xuất và tổng hợp các hiệu ứng thuốc trái phép (ADE) được nhắc đến trên Twitter của người Anh. Cách tiếp cận của chúng tôi thực hiện rất tốt trong nhiệm vụ bình thường, đạt được một điểm trên trung bình f1 của 24=, nhưng ít hơn là về phân loại và trích xuất, với điểm f1 trên 2297=. và 37=. Các thí nghiệm của chúng tôi cũng cho thấy rằng một tập tin lớn với kết quả tiêu cực nhiều hơn đã có kết quả mạnh hơn một bộ dữ liệu nhỏ hơn so với một tập tin nhỏ hơn, ngay cả khi cả hai bộ dữ liệu đều có cùng một ví dụ tích cực. Cuối cùng chúng tôi cũng đưa ra một mô hình thực phẩm thiếu sót cho Task 6: Classification of Covid-19 đã cho thấy triệu chứng cao hơn so với trung bình Điểm F1 của 96=.', 'nl': 'In dit werk beschrijven we onze inzendingen aan de Social Media Mining for Health (SMM4H) 2021 Shared Task. We onderzochten de effectiviteit van een gezamenlijke trainingsaanpak voor Task 1, met name classificatie, extractie en normalisatie van ADE vermeldingen in Engelse tweets. Onze aanpak presteerde goed bij de normalisatietaak, waarbij we een bovengemiddelde f1 score van 24%, bereikten, maar minder op classificatie en extractie, met f1 scores van respectievelijk 22% en 37% . Onze experimenten toonden ook aan dat een grotere dataset met meer negatieve resultaten resulteerde in sterkere resultaten dan een kleinere meer gebalanceerde dataset, zelfs als beide datasets dezelfde positieve voorbeelden hebben. Tot slot hebben we ook een getuned BERT model ingediend voor Task 6: Classificatie van Covid-19 tweets met symptomen, die een bovengemiddelde f1 score van 96%.', 'hr': 'U ovom poslu opisujemo svoje podatke za rudarstvo socijalnih medija za zdravlje (SMM4H) 2021. zajedničkom zadatku. Istražili smo učinkovitost zajedničkog pristupa obuke zadatku 1, posebno klasifikaciji, ekstrakciji i normalizaciji nuspojavnih učinka droge (ADE) spomenuti na engleskim tweetima. Naš pristup je dobro obavljen na normalizacijskom zadatku, ostvario iznad prosječnog f1 rezultata od 24%, ali manje na klasifikaciji i izvlačenju, s f1 rezultatima od 22% i 37%. Naši eksperimenti su također pokazali da je veća kompleta podataka s negativnijim rezultatima dovela do jača rezultata nego manja kompleta balanciranih podataka, čak i kada oba kompleta podataka imaju isti pozitivni primjer. Konačno smo također predali i napravljeni model BERT za zadatak 6: klasifikacija Covid-19 tweets sadržajućih simptoma, koji je postigao iznad prosječnog f1 rezultata od 96%.', 'id': 'Dalam pekerjaan ini kami menggambarkan pengiriman kami ke Social Media Mining for Health (SMM4H) 2021 Shared Task. Kami menyelidiki efektivitas pendekatan pelatihan bersama untuk Tugas 1, khususnya klasifikasi, ekstraksi dan normalisasi efek obat (ADE) disebutkan dalam tweet Inggris. Pendekatan kami berhasil dalam tugas normalisasi, mencapai skor f1 di atas rata-rata 24%, tetapi kurang begitu pada klasifikasi dan ekstraksi, dengan skor f1 22% dan 37% respectively. Eksperimen kami juga menunjukkan bahwa set data yang lebih besar dengan hasil yang lebih negatif menyebabkan hasil yang lebih kuat daripada set data yang lebih seimbang, bahkan ketika kedua set data memiliki contoh positif yang sama. Akhirnya kami juga mengirim model BERT tuned untuk Task 6: Klasifikasi tweet Covid-19 yang mengandung gejala, yang mencapai nilai F1 di atas rata-rata 96%.', 'ko': '이 작업에서 우리는 소셜미디어 건강발굴(SMM4H) 2021 공유 임무에 대한 제출을 묘사했다.우리는 임무 1에 대한 공동 교육 방법의 유효성, 특히 영어 트윗에서 언급한 약물불량반응(ADE)의 분류, 추출과 표준화에 대해 조사했다.우리의 방법은 표준화 임무에서 양호했다. f1의 득점은 평균 수준인 24%보다 높았지만 분류와 추출에 있어서 비교적 좋지 않았다. f1의 득점은 각각 22%와 37%였다.우리의 실험은 두 데이터 집합이 모두 같은 긍정적인 예를 가지고 있어도 더 큰 데이터 집합은 더 많은 부정적인 결과를 낳고 더 작고 균형 잡힌 데이터 집합보다 더 강한 결과를 낳는다는 것을 보여 주었다.마지막으로 우리는 임무 6에 최적화된 버트 모델을 제출했다. 증상을 포함하는 코로나 트윗을 분류한 결과 f1의 점수가 평균 96% 보다 높았다.', 'de': 'In dieser Arbeit beschreiben wir unsere Beiträge zum Social Media Mining for Health (SMM4H) 2021 Shared Task. Wir untersuchten die Effektivität eines gemeinsamen Trainingsansatzes für Task 1, insbesondere Klassifizierung, Extraktion und Normalisierung von unerwünschten Medikamenteneffekten (ADE) Erwähnungen in englischen Tweets. Unser Ansatz hat sich bei der Normalisierungsaufgabe gut bewährt und einen überdurchschnittlichen f1-Score von 24%, aber weniger bei Klassifizierung und Extraktion erzielt, wobei f1-Score von 22% bzw. 37% beträgt. Unsere Experimente zeigten auch, dass ein größerer Datensatz mit mehr negativen Ergebnissen zu stärkeren Ergebnissen führte als ein kleinerer, ausgewogenerer Datensatz, selbst wenn beide Datensätze die gleichen positiven Beispiele haben. Schließlich haben wir auch ein abgestimmtes BERT-Modell für Task 6: Klassifizierung von Covid-19-Tweets mit Symptomen eingereicht, das einen überdurchschnittlichen f1-Score von 96%.', 'sw': 'Katika kazi hii tunaelezea ujumbe wetu wa Vyombo vya Habari vya Kijamii wa Kumbukumbu kwa Afya (SMM4H) 2021. Tulichunguza ufanisi wa mbinu za mafunzo ya pamoja kwa Task 1, hususani usambazaji, utekelezaji na utaratibu wa Tamko za Utawala (ADE) katika twiti za Kiingereza. Hatua yetu ilifanya vizuri katika kazi ya kawaida, kutekeleza kiwango cha wastani wa f1 cha asilimia 24, lakini kidogo sana kwa usambazaji na utekelezaji, na vipande vya f1 kwa asilimia 22 na 37. Majaribio yetu pia yalionyesha kuwa taarifa kubwa zaidi yenye matokeo hasi yalisababisha matokeo yenye nguvu zaidi ya seti ndogo ya data yenye usawa, hata pale taarifa zote hizo zina mifano nzuri. Mwisho pia tuliwasilisha mfano wa BERT kwa ajili ya kazi 6: Kutangaza ujumbe wa twiti za Covid-19 zilizo na dalili, ambazo zilipata kiwango cha wastani f1 cha asilimia 96.', 'fa': 'در این کار ما تحویل\u200cهای خود را به وزارت رسانه\u200cهای اجتماعی برای سلامت (SMM4H) 2021 مشخص می\u200cکنیم. ما تحقیق کرده\u200cایم فعالیت یک روش آموزش مشترک برای تابع ۱، مخصوصاً کلی\u200cسازی، استخراج و عامل\u200cسازی اثر مواد مخالف مواد مخالف (ADE) را در تویت\u200cهای انگلیسی بیان می\u200cکند. دسترسی ما در کار عادی انجام داده بود، تا یک امتیاز f1 متوسط بالاتر از ۲۴ درصد رسید، اما کمتر از آن در دسترسی و استخراج، با امتیاز f1 از ۲۲ درصد و ۳۳ درصد. آزمایشات ما هم نشان دادند که یک مجموعه داده بزرگ با نتایج منفی بیشتری به نتایج قوی تر از یک مجموعه داده های متناسب تر، حتی وقتی هر دو مجموعه داده ها مثل مثال مثبت دارند. بالاخره ما همچنین یک مدل BERT تنظیم برای Task 6 را فرستادیم: کلاسیف توئیت Covid-19 که شامل علائم است، که در میانگین نمونه f1 از 96 درصد بالا رسید.', 'tr': 'Bu işde 2021-nji Beýik Taýramyzy Sosyal Medýdanlaryň Haýgylygyny Taýýarlamak üçin (SMM4H) sahypalarymyzy tassyklaýarys. Biz 1-nji Görev 1-nji ýarym taýramçylygynyň etkinliýetini bardyk. Özellikle döwlet sanlarynda "Adverse Drug Effect (ADE)" diýip ýazylýar. Bizim yaklaşımız normalizasyon görevinde, ortalama f1 noktası 24% üstünde ulaştı, fakat bu şekilde klasifikasyon ve çıkarma üzerinde f1 noktası 22 ve 37% olmuştu. Biziň deneylerimiz hem köp daty setirini negatif netijeleri bilen kiçi baýlanan daty setirinden has güýçli netijelere getirdi. Hem iki daty setirini hem bir positif mysal bolsa hem. Sonunda da görev 6 için ayarlanmış BERT modeli gönderdik:', 'sq': 'Në këtë punë ne përshkruajmë paraqitjet tona në Social Media Mining for Health (SMM4H) 2021 Task Shared. Ne hetuam efektshmërinë e një qasje të përbashkët trainimi për detyrën 1, veçanërisht klasifikimin, nxjerrjen dhe normalizimin e përmendimeve të efektit të dëmshëm të drogës (ADE) në tweetet angleze. Përqasja jonë kryei mirë në detyrën e normalizimit, duke arritur një rezultat mbi mesataren e f1-së prej 24%, por më pak në klasifikimin dhe nxjerrjen, me rezultatet e f1-së prej 22% dhe 37% respektivisht. Eksperimentet tona treguan gjithashtu se një grup më i madh i të dhënave me rezultate më negative çoi në rezultate më të forta sesa një grup më i vogël i të dhënave më të balancuara, edhe kur të dy grupet e të dhënave kanë të njëjtat shembuj pozitiv. Më në fund ne dërguam gjithashtu një model të përshtatur BERT për detyrën 6: Klasifikimi i tweeteve Covid-19 që përmbajnë simptomë, që arritën një rezultat mbi mesataren e f1 prej 96%.', 'af': "In hierdie werk beskrywe ons onderskrifte aan die sosiale media-mining vir gesondheid (SMM4H) 2021 Gedeelde taak. Ons het die effektiviteit van 'n joint oefening toegang tot taak 1, spesifieke klasifikasie, uitpakking en normalisering van Adverse Drug Effekte (ADE) in Engelske tweets bepaal. Ons toegang het goed uitgevoer op die normalisering taak, tot 'n bo gemiddelde f1 telling van 24%, maar minder so op klasifikasie en uittrekking, met f1 telling van 22% en 37% respectively. Ons eksperimente het ook wys dat 'n groter datastel met meer negatiewe resultate gelei het na sterker resultate as 'n kleiner meer balanse datastel, selfs wanneer beide datastel dieselfde positiewe voorbeelde het. Eindelik het ons ook 'n aangestuurde BERT model vir Taak 6 aangestuur: Klassifikasie van Covid-19 tweets wat simptome bevat het, wat 'n boonste gemiddelde f1 punt van 96%.", 'hy': 'Այս աշխատանքում մենք նկարագրում ենք մեր ներկայացումները 2021 թվականի Սոցիալական լրատվամիջոցների առողջապահության (SMM4H) հանքահանգում: Մենք ուսումնասիրեցինք 1-րդ խնդրի ընդհանուր ուսումնասիրության արդյունավետությունը, հատկապես անգլերենի թվիթերում հայտարարված անգամ թմրանյութերի թերաֆեկտի դասակարգումը, վերացումը և նորմալիզացիան: Մեր մոտեցումը լավ կատարեց նորմալիզացիայի խնդիրը, հասնելով 24 տոկոսի բարձր միջին f1 գնահատականը, սակայն ավելի քիչ՝ դասակարգման և դուրս բերման համար, f1 գնահատականը 22 տոկոսի և 37 տոկոսի: Մեր փորձարկումները նաև ցույց տվեցին, որ ավելի մեծ տվյալների համակարգը, որն ավելի բացասական արդյունքներ ուներ, հանգեցրեց ավելի ուժեղ արդյունքների, քան ավելի փոքր հավասարակշռություն ունեցող տվյալների համակարգը, նույնիսկ երբ երկու տվ Վերջապես մենք նաև ներկայացրեցինք BER-ի համակարգված մոդել 6-ի համար. Covit-19 թվիթերի դասակարգման, որոնք պարունակում էին ախտանիշներ, որոնք հասան 96 տոկոսի բարձր միջին f1 գնահատականի:', 'am': 'በዚህ ሥራ 2021 የተሰራጨውን ስራ ለማኅበራዊ ሚዲያ የጤና አሳብ አሳብ (SMM4H) እናሳውቃለን፡፡ በንግግሊዝኛ ትዊተሮች ላይ የተለየ የበይነመረ የሕንጻ አካሄድ (ADE) ማስታወቂያውን፣ ለመለየት እና የመጠቀምን የግል ትምህርት ማቀናቀፍ እና ትምህርት ማድረጊያውን መረመርን፡፡ የተለመደው ሥርዓታችን በተለየ ጠቅላላ F1 score 24 በመቶ ላይ እንዲደርስ ነው፤ ነገር ግን በትክክል እና ለመውጣት በጣም ጥቂት ነው፡፡ ፈተናዎቻችን ደግሞ፣ የዳታ መስመር አንድ መልካም ምሳሌ ባለበት ጊዜ ከታናሹ የዳታ ክፍሎች የበለጠ ትልቁ ፍሬዎችን እንዲያበረታባቸው ነው፡፡ በመጨረሻም ለስራ 6 የBERT ሞዴል አቀረብነው፡፡ ምልክቶች የሚኖሩበት ቁጥር-19 ትዊተሮችን መግለጫ፣ የ96 በመቶ የበለጠ የF1 score አግኝቷል፡፡', 'az': 'Bu iŇüd…ô 2021-ci il…ô paylaŇüńĪlmńĪŇü iŇü Sosyal Media Mining for Health (SMM4H) m…ôlumatńĪmńĪzńĪ t…ôsdiql…ôyirik. Biz 1. Task √ľ√ß√ľn birlikd…ô t…ôhsil edil…ôn t…ôhsil t…ôhsil t…ôhsil edilm…ôsini araŇüdńĪrdńĪq. √Ėzellikle ńįngilizci tweetl…ôrd…ô "Adverse Drug Effect (ADE)" s√∂yl…ôdikl…ôri, se√ßm…ôk v…ô normalizasyon. Bizim yaxńĪnlńĪńüńĪmńĪz normalizasyon iŇüind…ô yaxŇüńĪ iŇül…ôdi, ortalama f1 d…ôr…ôc…ôsini 24%-d…ôn artńĪrdńĪ, lakin bu d…ôr…ôc…ônin klasifikasyonu v…ô √ßńĪxartmasńĪ √ľ√ß√ľn f1 d…ôr…ôc…ôsini 22%-d…ôn v…ô 37%-d…ôn az etdi. Bizim eksperimentl…ôrimiz d…ô bel…ô g√∂st…ôrdi ki, daha negatif sonu√ßlarńĪ il…ô daha b√∂y√ľk veril…ôn veril…ôn qurńüular daha ki√ßik balanslńĪ veril…ôn qurńüulardan daha q√ľvv…ôtli sonu√ßlar olardńĪ, h…ôtta h…ôr iki veril…ôn qurńüularńĪ eyni pozitif n√ľmun…ôl…ôr olsa Sonunda biz d…ô 6. Task √ľ√ß√ľn m√ľ…ôyy…ôn bir BERT modeli t…ôblińü etdik: Covid-19 tweets klasifikasyonu simptomlar i√ß…ôrik, bu da ortalama f1 d…ôr…ôc…ôsi 96%-d…ôn √ľst√ľn oldu.', 'bn': 'এই কাজে আমরা সামাজিক মিডিয়ার স্বাস্থ্যের জন্য মিনিং (এসএমএফ৪হ) ২০১১ শেয়ার করা কাজের কাজে আমাদের প্রতিপাদক বর্ণনা কর আমরা টাস্ক ১-এ যৌথ প্রশিক্ষণের কার্যক্রম তদন্ত করেছি, বিশেষ করে ইংরেজী টুইটে বিভিন্ন ভাষায় অ্যাডভার্স মাদক প্রভাবের (এডি) উল্লেখ করা যা আমাদের পদক্ষেপ স্বাভাবিক কাজের উপর ভালো করেছে, গড়ে ২৪% ফি১ স্কোর পাওয়া যাচ্ছে, কিন্তু শ্রেণীবিভক্ত এবং বের করে নেওয়ার ব্যাপারে কম, যার ফলে  আমাদের পরীক্ষাও দেখা যাচ্ছে যে আরো নেতিবাচক ফলাফলের একটি বড় ডাটাসেটের ফলাফল বেশী শক্তিশালী হয়েছে, এমনকি যদি দুটো ডাটাসেটও একই পজিটিভ উদ Finally we also submitted a tuned BERT model for Task 6: Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96%.', 'bs': 'U ovom poslu opisujemo svoje podatke na ministarstvo socijalnih medija za zdravlje (SMM4H) 2021. zajednički zadatak. Istražili smo učinkovitost zajedničkog pristupa obuke zadatku 1, posebno klasifikaciji, ekstrakciji i normalizaciji nuspojava na engleskim tweetima. Naš pristup je dobro obavljen na normalizacijskom zadatku, ostvario iznad prosječnog f1 rezultata od 24%, ali manje na klasifikaciji i izvlačenju, sa f1 rezultatima od 22% i 37%. Naši eksperimenti su također pokazali da je veća kompleta podataka sa više negativnih rezultata dovela do jača rezultata od manje balanciranije kompleta podataka, čak i kada oba kompleta podataka imaju isti pozitivni primjer. Konačno smo također predali i napravljeni model BERT za zadatak 6: klasifikacija Covid-19 tweets koji sadrže simptome, koji je postigao iznad prosječnog f1 rezultata od 96%.', 'ca': "En aquesta feina descrivim les nostres presentacions a la Social Media Mining for Health (SMM4H) 2021 Shared Task. Vam investigar l'eficacia d'un enfocament de formació conjunta a la tasca 1, específicament la classificació, l'extracció i la normalització de les mencions d'efecte advers de medicaments (ADE) en tweets anglès. El nostre enfocament va funcionar bé en la tasca de normalització, aconseguint una puntuació f1 superior a la mitjana del 24%, però menys en la classificació i l'extracció, amb puntuacions f1 del 22% i 37%, respectivament. Els nostres experiments també van demostrar que un conjunt de dades més gran amb resultats més negatius va portar a resultats més forts que un conjunt de dades més petit equilibrat, fins i tot quan ambdós conjunts de dades tenen els mateixos exemples positius. Finalment també vam presentar un model de BERT ajustad per a la tasca 6: Classificació de tweets Covid-19 contenent símptomes, que van aconseguir una puntuació f1 superior a la mitjana del 96%.", 'cs': 'V této práci popisujeme naše příspěvky na Social Media Mining for Health (SMM4H) 2021 Shared Task. Zkoumali jsme účinnost společného tréninkového přístupu k úkolu 1, konkrétně klasifikace, extrakce a normalizace zmínek o nežádoucím léčivém efektu (ADE) v anglických tweetech. Náš přístup se v normalizačním úkolu vedl dobře, dosáhl nadprůměrného f1 skóre 24%, ale méně v klasifikaci a extrakci, s f1 skóre 22% a 37% respektive. Naše experimenty také ukázaly, že větší datová sada s více negativními výsledky vede k silnějším výsledkům než menší vyváženější datová sada, i když obě datové sady mají stejné pozitivní příklady. Nakonec jsme také předložili vyladěný BERT model pro Úkol 6: Klasifikace Covid-19 tweetů obsahujících symptomy, který dosáhl nadprůměrného f1 skóre 96%.', 'et': 'Selles töös kirjeldame oma esitusi sotsiaalmeedia kaevandamiseks tervisele (SMM4H) 2021. aasta jagatud ülesandele. Uurisime ühise koolituse meetodi efektiivsust ülesandele 1, täpsemalt inglise keeles kõrvaltoimete klassifitseerimist, ekstraheerimist ja normaliseerimist. Meie lähenemisviis sai normaliseerimise ülesandes hästi hakkama, saavutades keskmisest suurema f1 skoori 24%, kuid vähem klassifitseerimisel ja ekstraheerimisel, f1 skooriga vastavalt 22% ja 37%. Meie eksperimendid näitasid ka, et suurem negatiivsete tulemustega andmekogum viis suuremate tulemusteni kui väiksem tasakaalustatud andmekogum, isegi kui mõlemal andmekogumil on samad positiivsed näited. Lõpuks esitasime ka häälestatud BERT mudeli ülesandele 6: Covid-19 sümptomeid sisaldavate säutsude klassifitseerimine, mis saavutas keskmisest kõrgema f1 skoori 96%.', 'fi': 'Tässä työssä kuvailemme ehdotuksia Social Media Mining for Health (SMM4H) 2021 Shared Task -ohjelmaan. Tutkimme yhteisen koulutusmenetelmän tehokkuutta tehtävään 1, erityisesti englanninkielisten twiittien haittavaikutusten luokittelua, ekstraktiota ja normalisointia. Lähestymistapamme suoriutui hyvin normalisointitehtävässä saavuttaen keskimääräistä suuremman f1-pisteen 24%, mutta vähemmän luokittelussa ja ekstraktiossa, f1-pisteet 22% ja 37%. Kokeet osoittivat myös, että suurempi negatiivisempi aineisto johti vahvempiin tuloksiin kuin pienempi tasapainoisempi aineisto, vaikka molemmissa aineistoissa olisi samat positiiviset esimerkit. Lopuksi toimitimme myös viritetyn BERT-mallin tehtävään 6: oireita sisältävien Covid-19-twiittien luokitus, joka saavutti keskimääräisen f1-pisteen 96%.', 'bg': 'В тази работа описваме нашите предложения към Споделена задача за Социалните медии Минно дело за здраве (СММ4Х) 2021. Изследвахме ефективността на съвместния тренировъчен подход към задача 1, по-специално класификация, екстракция и нормализиране на споменаваните в английски туитове нежелани лекарствени ефекти (АДД). Подходът ни се представи добре при задачата за нормализиране, като постигна над средния резултат от 24%, но по-малко при класификацията и екстракцията, със съответно 22% и 37%. Нашите експерименти също показаха, че по-голям набор от данни с повече отрицателни резултати води до по-силни резултати от по-малък, по-балансиран набор от данни, дори когато и двата набора от данни имат едни и същи положителни примери. Накрая представихме и настроен модел за задача 6: Класификация на туитове съдържащи симптоми, които постигнаха над средния резултат от 96%.', 'da': 'I dette arbejde beskriver vi vores indlæg til Social Media Mining for Health (SMM4H) 2021 Shared Task. Vi undersøgte effektiviteten af en fælles træning tilgang til opgave 1, specielt klassificering, ekstraktion og normalisering af Adverse Drug Effect (ADE) omtaler i engelske tweets. Vores tilgang klarede sig godt på normaliseringsopgaven og opnåede en f1 score over gennemsnittet på 24%, men mindre på klassificering og ekstraktion, med f1 score på henholdsvis 22% og 37%. Vores eksperimenter viste også, at et større datasæt med mere negative resultater førte til stærkere resultater end et mindre mere afbalanceret datasæt, selv når begge datasæt har de samme positive eksempler. Endelig indsendte vi også en tunet BERT model til opgave 6: Klassificering af Covid-19 tweets indeholdende symptomer, som opnåede en f1 score over gennemsnittet på 96%.', 'sk': 'V tem delu opisujemo naše prispevke k skupni nalogi za rudarjenje v socialnih medijih za zdravje (SMM4H) 2021. Raziskovali smo učinkovitost skupnega pristopa usposabljanja k nalogi 1, zlasti klasifikacija, ekstrakcija in normalizacija omenjenih neželenih učinkov zdravil (ADE) v angleških tweetih. Naš pristop se je dobro izkazal pri nalogi normalizacije, saj je dosegel nadpovprečno oceno f1 24%, manj pa pri klasifikaciji in ekstrakciji, z oceno f1 22% oziroma 37%. Naši poskusi so pokazali tudi, da je večji nabor podatkov z večjimi negativnimi rezultati vodil do močnejših rezultatov kot manjši bolj uravnoteženi nabor podatkov, tudi če imata obe nabori enake pozitivne primere. Na koncu smo predložili tudi prilagojen BERT model za nalogo 6: Klasifikacija tvitov Covid-19, ki vsebujejo simptome, ki je dosegel nadpovprečno oceno f1 96%.', 'ha': "A cikin wannan aikin da Muke describe musuluntu zuwa the Socic Media Mining for Heatherhood (SMM4H) 2021 Shared Takar. Haƙĩƙa, Mun ƙidãya mafiya aikin haɗiya zuwa Tafiyar 1, hasa'a, classified, fitarwa da kuma normal wa sunayen Effekt na Narci (ADU) cikin Ingiriya. Our approach performed well on the normalization task, achieving an above average f1 score of 24%, but less so on classification and extraction, with f1 scores of 22% and 37% respectively.  Kayan jarrabayenmu suka nuna cewa, samun danne mafi girma da matsalan negative sun ƙara matsala mafi ƙaranci daga samun da aka daidaita, kuma kõ dã sami biyu na danganta sun sami misãlai masu daidai. Ga ƙarshen, mun sami wani misali na BERT wa aikin 6: Tsariya na Kwamf1-19 mai ƙunsa da ayukan ayukan, wanda ya sami ƙarami wata f1-score na 96%.", 'jv': 'Nang trabah iki, kita ngubah ngerasai tanggal nggawe barang urip nggawe barang-urip ning resuran Digital Media (SMM4H) 2020 1 Tarjamahan sing berarti Anyone here Ndoleh-Ndoleh sing wis ngerasai bener tentang kanggo kalagayaan nggawe gerakan kelas telu, dadi f1 sing ditambah 24%, dadi mper dadi kapan kelas telu, dadi f1 sing ditambah 22% lan 31%. section Tulungi, nggambar nggambar sistem menehi nggawe BERT model nggo task 6: Kelaseki Covideo-19 tuyte sing dikanggambar barang sembaran, sing wis aswih sabên kotang nggawe mentegan f1 sing uwong de Nine%.', 'bo': 'ང་ཚོས་སྤྱི་ཚོགས་ཀྱི་གནས་སྟངས་འདིའི་ནང་དུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནག་གི་དབར་སྤྲོད་ཀྱི་གནས་སྟངས་ལ་བཤད་ཀྱི་ཡོད། ང་ཚོས་མཐུན་གྱི་གོ་སྐབས་ཡིག་གཟུགས་ཐད་མིན་དུ་ལས་གནོད་ཐད་ཚོར་ཞིབ་བྱས་པ་ཡིན། ང་ཚོའི་བཟོ་ཚིག་ནི་རྒྱུན་ལྡན་བཟོ་བྱེད་ཀྱི་ལས་ཀ་ཡིན་ཚད་ལྡན་གྱིས་མཐུན་རྐྱེན་སྟངས་ཀྱང་ཚད་གཅིག་ལས་མཐུན་སྒྲིག་འགོད་པ་ཡིན། ང་ཚོའི་བརྟག་ཞིག་ཀྱང་ཕྱོགས་སྡུད་ཚན་ཆེ་བའི་ཚད་རྐྱེན་པས་བྱས་ཟུར་བ་མང་ཙམ་བྱུང་བ་ཡིན་པས་རྐྱེན་སྒྲིག་ཆ་གཞི་རྩན་འབྲེལ་བ མཐའ་མཇུག་དུ་འུ་ཚོས་ཀྱིས་ཞིབ་དཔྱད་སྒྲུབ་གྱི་དབྱེ་རིམ་གྱི་དཔེ་བརྗོད་པ་ཞིག་འཇུག་བྱས།', 'he': 'בעבודה הזו אנחנו מתארים את ההעבדות שלנו למכרת מדיה חברתית לבריאות (SMM4H) משימה משותפת 2021. חקרנו את היעילות של גישת אימון משותפת למשימה 1, במיוחד מסווג, חולץ ונורמליזציה הגישה שלנו ביצעה היטב במשימת הנורמליזציה, השיגה נקודת f1 מעל ממוצע ממוצע של 24%, אך פחות ככה בקשר להקליטה ולחטיפה, עם נקודות f1 של 22% ו-37% בהתאם. Our experiments also showed that a larger dataset with more negative results led to stronger results than a smaller more balanced dataset, even when both datasets have the same positive examples.  סוף סוף שלחנו גם מודל BERT מתאים למשימה 6: שיגור של טוויטים Covid-19 שמכילים סימפטומים, אשר השיג נקודת F1 מעל ממוצע ממוצע של 96%.'}
{'en': 'Identification of profession & occupation in Health-related Social Media using tweets in Spanish S panish', 'es': 'Identificación de profesión y ocupación en las redes sociales relacionadas con la salud mediante tuits en español', 'pt': 'Identificação de profissão e ocupação em mídias sociais relacionadas à saúde usando tweets em espanhol', 'ar': 'تحديد المهنة والوظيفة في وسائل التواصل الاجتماعي ذات الصلة بالصحة باستخدام التغريدات باللغة الإسبانية', 'fr': "Identification de la profession et de la profession dans les médias sociaux liés à la santé à l'aide de tweets en", 'ja': 'スペイン語のツイートを使用して、健康関連のソーシャルメディアでの職業と職業の識別', 'zh': '用西班牙语推文相关于健康社交媒体中识专业', 'hi': 'स्पेनिश में tweets का उपयोग कर स्वास्थ्य से संबंधित सोशल मीडिया में पेशे और व्यवसाय की पहचान', 'ru': 'Идентификация профессии и занятия в социальных сетях, связанных со здоровьем, с использованием твитов на испанском языке', 'ga': 'Gairm agus slí bheatha a shainaithint sna Meáin Shóisialta a bhaineann le Sláinte trí úsáid a bhaint as tweets i Spáinnis', 'ka': 'სოციალური მედიაში პროფეციის და კომპოციაციის განსაზღვრება სოციალური მედიაში', 'hu': 'Szakma és foglalkozás azonosítása az egészségügyi közösségi médiában spanyol tweetek segítségével', 'it': "Identificazione della professione e dell'occupazione nei Social Media correlati alla salute tramite tweet in spagnolo", 'el': 'Ταυτοποίηση του επαγγέλματος και του επαγγέλματος στα κοινωνικά μέσα υγείας με χρήση tweets στα ισπανικά', 'kk': 'Испан тіліндегі tweets қолданатын саулық медиаға қатысты профессионалық және мәселелердің идентификациясы', 'ml': 'സ്പാനിഷിലെ ടൂട്ടുകള്\u200d ഉപയോഗിച്ച് സ്പാനിഷ് ലൈറ്റുകള്\u200d ഉപയോഗിച്ച് സ്പാനിഷ് സോഷ്യല്\u200d മീഡിയയില്\u200d ആശ്', 'mt': 'Identifikazzjoni tal-professjoni u tax-xogħol fil-Midja Soċjali relatata mas-Saħħa bl-użu ta’ tweets bl-Ispanjol', 'lt': 'Su sveikata susijusios socialinės žiniasklaidos profesijos ir profesijos nustatymas naudojant tweetus ispanų kalba', 'mn': 'Эрүүл мэндийн холбоотой нийгмийн мэдээллийн ажил болон ажиллагааны тодорхойлолт Испан хэлний', 'no': 'Identifikasjon av profesjon og okupacjon i helsetjende sosiale medier med tweets i spansk', 'ms': 'Pengenalan profesi & pekerjaan dalam Media Sosial Berkaitan Kesehatan menggunakan tweet dalam bahasa Sepanyol', 'mk': 'Идентификација на професијата и окупацијата во социјалните медиуми поврзани со здравството користејќи твитови на шпански', 'pl': 'Identyfikacja zawodu i zawodu w mediach społecznościowych związanych ze zdrowiem za pomocą tweetów w języku hiszpańskim', 'sr': 'Identifikacija profesije i okupacije u socijalnim medijima vezanim za zdravlje koristeći tweets na španjolskom', 'so': 'Aqoonsiga xirfadda iyo xirfadda ee ku saabsan macluumaadka bulshada caafimaadka ee isticmaalka tweetka Isbanishka', 'ro': 'Identificarea profesiei și ocupației în rețelele sociale legate de sănătate folosind tweet-uri în limba spaniolă', 'si': 'Name', 'ta': 'ஸ்பானிஷில் தொடர்புடைய சார்ந்த சமூக ஊடகங்களில் தொழில்நுட்பம் மற்றும் தொழில்நுட்பம் அடையாளம்', 'sv': 'Identifiering av yrke och yrke i hälsorelaterade sociala medier med hjälp av tweets på spanska', 'ur': 'اسپانیایی میں ٹویٹ کے استعمال سے سلامتی کے متعلق ہونے والی سوسیل میڈیا میں پروفسوسی اور مشغول کی شناسایی', 'uz': 'Name', 'vi': 'Nhận dạng nghề nghiệp... nghề nghiệp trên phương tiện y tế dùng Twitter bằng tiếng Tây Ban Nha.', 'bg': 'Идентификация на професията и професията в свързаните със здравето социални медии чрез туитове на испански език', 'nl': 'Identificatie van beroep en beroep in Gezondheidsgerelateerde sociale media met behulp van tweets in het Spaans', 'da': 'Identifikation af erhverv og erhverv i sundhedsrelaterede sociale medier ved hjælp af tweets på spansk', 'hr': 'Identifikacija profesije i okupacije u socijalnim medijima povezanim s zdravstvenom zdravlju koristeći tweets na španjolskom', 'ko': '스페인어 트윗으로 건강 관련 소셜미디어의 직업 식별', 'de': 'Identifikation von Beruf und Beruf in Gesundheitsbezogenen Social Media mittels Tweets auf Spanisch', 'id': 'Identifikasi profesi & pekerjaan dalam Medi Sosial Berkaitan Kesehatan menggunakan tweet dalam bahasa Spanyol', 'fa': 'شناسایی شغل و شغل در رسانه های اجتماعی مربوط به سلامت با استفاده از tweets در اسپانیایی', 'tr': 'Ispanýol dilinde tweets ulanan işlerin we emelleriniň kimligi', 'af': 'Identifikasie van profesie en occupasie in gesondheidsverwante sosiale media gebruik tweets in Spaanse', 'sw': 'Identification of profession & occupation in Health-related Social Media using tweets in Spanish', 'am': 'በስፓኒሽ ትዊተሮችን በመጠቀም በጤናዊ ማኅበራዊ ሚዲያ ውስጥ ባለሞያ እና ስራ ማህበረሰብ ማረጋገጥ', 'sq': 'Identifikimi i profesionit dhe profesionit në Mediat Shoqërore të Lidhura me Shëndetësinë duke përdorur tweetet në spanjoll', 'hy': 'Առողջության հետ կապված սոցիալական լրատվամիջոցների մասնագիտության և մասնագիտության հայտնաբերումը օգտագործելով թվիթեր իսպաներեն', 'az': 'ńįspanyolca tweets vasit…ôsil…ô sańülamlńĪq m…ôlumatńĪnńĪn t…ôŇükil edilm…ôsini v…ô m…ôŇüńüul t…ôŇükil etm…ôsini', 'ca': 'Identificació de la profession i ocupació en els mitjans socials relacionats amb la salut utilitzant tweets en espanyol', 'cs': 'Identifikace povolání a povolání v sociálních médiích souvisejících se zdravím pomocí tweetů ve španělštině', 'fi': 'Ammatin ja ammatin tunnistaminen terveysalan sosiaalisessa mediassa espanjankielisten twiittien avulla', 'bs': 'Identifikacija profesije i okupacije u socijalnim medijima vezanim za zdravlje koristeći tweets na španjolskom', 'bn': 'স্বাস্থ্য সামাজিক মিডিয়াতে স্বাস্থ্য সংক্রান্ত পেশাদার এবং কর্মসূচীর পরিচয় ব্যবহার করে স্বাস্থ্য', 'et': 'Kutseala ja kutseala tuvastamine tervishoiuga seotud sotsiaalmeedias hispaaniakeelsete säutsude abil', 'sk': 'Identifikacija poklica in poklica v zdravstvenih družbenih medijih z uporabo tweetov v španščini', 'jv': 'ID de manungsa karo perbudhakan lan kelas ing resuran-barêng ning resuran Media sing digawe podho tutet ing Spanish', 'ha': 'Suna gane profession & job in Heatherly-related Socket uses Twitter in spanish', 'bo': 'སྤྲོད་ཀྱི་གནས་སྟངས་དང་ལས་འགའ་བྱ་འབྲེལ་དག་གི་གནས་སྟངས་དང་འབྲེལ་བའི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྟངས་ལ་ཤ', 'he': 'זיהוי מקצוע ומקצוע במדיה חברתית קשורה לבריאות באמצעות טוויטים בספרדית'}
{'en': 'In this paper we present our approach and system description on Task 7a in ProfNer-ST : Identification of profession & occupation in Health related Social Media. Our main contribution is to show the effectiveness of using BETO-Spanish BERT as a model based on transformers pretrained with a Spanish Corpus for classification tasks. In our experiments we compared several  architectures  based on  transformers  with others based on classical  machine learning algorithms . With this  approach , we achieved an F1-score of 0.92 in the evaluation process.', 'fr': "Dans cet article, nous présentons notre approche et la description du système de la tâche 7a dans Profner-ST\xa0: Identification de la profession et de la profession dans les médias sociaux liés à la santé. Notre principale contribution est de montrer l'efficacité de l'utilisation du BERT BETO-espagnol comme modèle basé sur des transformateurs préformés avec un corpus espagnol pour les tâches de classification. Dans nos expériences, nous avons comparé plusieurs architectures basées sur des transformateurs avec d'autres basées sur des algorithmes d'apprentissage automatique classiques. Grâce à cette approche, nous avons obtenu un score F1 de 0,92 dans le processus d'évaluation.", 'es': 'En este artículo presentamos nuestro enfoque y la descripción del sistema en la Tarea 7a de Profner-ST: Identificación de profesión y ocupación en las redes sociales relacionadas con la salud. Nuestra principal contribución es demostrar la eficacia del uso del BERT BETO-español como modelo basado en transformadores preentrenados con un Corpus español para tareas de clasificación. En nuestros experimentos comparamos varias arquitecturas basadas en transformadores con otras basadas en algoritmos clásicos de aprendizaje automático. Con este enfoque, logramos una puntuación F1 de 0.92 en el proceso de evaluación.', 'ar': 'في هذه الورقة ، نقدم نهجنا ووصف نظامنا في المهمة 7 أ في ProfNer-ST: تحديد المهنة والوظيفة في وسائل التواصل الاجتماعي المتعلقة بالصحة. تتمثل مساهمتنا الرئيسية في إظهار فعالية استخدام BETO-Spanish BERT كنموذج يعتمد على المحولات التي تم اختبارها مسبقًا مع مجموعة إسبانية لمهام التصنيف. في تجاربنا ، قارنا العديد من البنى القائمة على المحولات مع البنى الأخرى بناءً على خوارزميات التعلم الآلي الكلاسيكية. من خلال هذا النهج ، حققنا درجة F1 قدرها 0.92 في عملية التقييم.', 'pt': 'Neste artigo apresentamos nossa abordagem e descrição do sistema na Tarefa 7a no ProfNer-ST: Identificação de profissão e ocupação em mídias sociais relacionadas à saúde. Nossa principal contribuição é mostrar a eficácia do uso do BETO-Espanhol BERT como modelo baseado em transformadores pré-treinados com um Corpus Espanhol para tarefas de classificação. Em nossos experimentos comparamos várias arquiteturas baseadas em transformadores com outras baseadas em algoritmos clássicos de aprendizado de máquina. Com essa abordagem, obtivemos uma pontuação F1 de 0,92 no processo de avaliação.', 'hi': 'इस पेपर में हम ProfNer-ST में टास्क 7a पर हमारे दृष्टिकोण और सिस्टम विवरण प्रस्तुत करते हैं: स्वास्थ्य से संबंधित सोशल मीडिया में पेशे और व्यवसाय की पहचान। हमारा मुख्य योगदान वर्गीकरण कार्यों के लिए एक स्पेनिश कॉर्पस के साथ पूर्वनिर्धारित ट्रांसफॉर्मर के आधार पर एक मॉडल के रूप में BETO-स्पेनिश BERT का उपयोग करने की प्रभावशीलता को दिखाना है। हमारे प्रयोगों में हमने शास्त्रीय मशीन लर्निंग एल्गोरिदम के आधार पर दूसरों के साथ ट्रांसफॉर्मर के आधार पर कई आर्किटेक्चर की तुलना की। इस दृष्टिकोण के साथ, हमने मूल्यांकन प्रक्रिया में 0.92 का एफ 1-स्कोर हासिल किया।', 'ja': 'この論文では、ProfNer - ST ： Health関連ソーシャルメディアにおける職業と職業の識別におけるタスク7 aに関するアプローチとシステム説明を紹介します。当社の主な貢献は、分類タスクのためにスペインのコーパスで事前に訓練された変圧器に基づいて、BETO - Spanish BERTをモデルとして使用することの有効性を示すことです。私たちの実験では、変圧器に基づくいくつかのアーキテクチャを、古典的な機械学習アルゴリズムに基づく他のアーキテクチャと比較しました。このアプローチにより、評価プロセスでF 1スコア0.92を達成しました。', 'zh': '本文,我们在ProfNer-ST中介绍了我们对任7a的方法和系统描述:健康相关社交媒体中职业的知识。 凡贡用BETO-西班牙语BERT基于西班牙语语料库转换器之有效性,用于分职。 于我实验中,将几种基于转换器架构与基于经典机器学算法的他架构较较。 以此得之,0.92F1分数。', 'ru': 'В этой статье мы представляем наш подход и описание системы по Задаче 7a в ProfNer-ST: Идентификация профессии и занятия в связанных со здоровьем социальных сетях. Наш основной вклад заключается в том, чтобы показать эффективность использования BETO-Spanish BERT в качестве модели на основе трансформаторов, предварительно подготовленных с испанским корпусом для задач классификации. В наших экспериментах мы сравнили несколько архитектур, основанных на трансформаторах, с другими архитектурами, основанными на классических алгоритмах машинного обучения. При таком подходе мы достигли показателя F1 0,92 в процессе оценки.', 'ga': 'Sa pháipéar seo cuirimid i láthair ár gcur chuige agus ár gcur síos ar an gcóras ar Thasc 7a in ProfNer-ST: Gairm agus slí bheatha a aithint sna Meáin Shóisialta a bhaineann le Sláinte. Is é an príomh-rannchuidiú atá againn a thaispeáint cé chomh héifeachtach is atá úsáid BETO-Spáinnis BERT mar shamhail bunaithe ar chlaochladáin réamhoilte le Corpas Spáinneach le haghaidh tascanna aicmithe. Inár dturgnaimh chuireamar i gcomparáid le roinnt ailtireachtaí bunaithe ar chlaochladáin le cinn eile a bhí bunaithe ar algartam foghlama meaisín clasaiceach. Leis an gcur chuige seo, bhaineamar amach scór F1 de 0.92 sa phróiseas meastóireachta.', 'el': 'Στην παρούσα εργασία παρουσιάζεται η προσέγγισή μας και η περιγραφή του συστήματος σχετικά με την εργασία 7α στο Προσδιορισμός επαγγέλματος και επαγγέλματος στα σχετικά με την υγεία κοινωνικά μέσα ενημέρωσης. Η κύρια συμβολή μας είναι να δείξουμε την αποτελεσματικότητα της χρήσης του ως μοντέλου βασισμένου σε μετασχηματιστές προ-εκπαιδευμένους με Ισπανικό Σώμα για εργασίες ταξινόμησης. Στα πειράματά μας συγκρίναμε αρκετές αρχιτεκτονικές βασισμένες σε μετασχηματιστές με άλλες βασισμένες σε κλασικούς αλγόριθμους μηχανικής μάθησης. Με αυτή την προσέγγιση, πετύχαμε μια βαθμολογία F1 0.92 στη διαδικασία αξιολόγησης.', 'hu': 'Jelen tanulmányban bemutatjuk a 7a feladat megközelítését és rendszerleírását a ProfNer-ST: Szakma és foglalkozás azonosítása az egészségügyi kapcsolatokkal kapcsolatos közösségi médiában. Fő hozzájárulásunk annak bemutatása, hogy milyen hatékony a BETO-Spanyol BERT mint egy spanyol korpussal előkészített transzformátorok modellje az osztályozási feladatokhoz. Kísérleteink során több transzformátoron alapuló architektúrát hasonlítottunk össze klasszikus gépi tanulási algoritmusokkal. Ezzel a megközelítéssel F1 pontszámot értünk el az értékelési folyamat során.', 'ka': 'ამ დოკუმენტში ჩვენ ჩვენი პროფესია და სისტემის გამოსახულება პროფესენერ-ST-ში: პროფესიის და კოკუმენციის განსახულება სოციალური მედიაში. ჩვენი მნიშვნელოვანი დამატება არის BETO-სპანელი BERT-ის გამოყენების ეფექტიურობის ჩვენება როგორც მოდელია, როგორც ტრანფორმეტრების დაბაზეული სპანელი კორპოსთან კლასიფიკაცი ჩვენი ექსპერიმენტებში რამდენიმე არქტიქტურების განმავლობაზე გადავუდგენეთ კლასიკური მაქინის სწავლების ალგორიტებზე. ამ პროცემის შესახებ, ჩვენ მივიღეთ 0,92 წერტილის F1 წერტილის პროცესიში.', 'kk': 'Бұл қағазда 7.a тапсырмасының арқылы мен жүйеңіздің сипаттамасын профессор-ST: Медициялық саулық медиақтарындағы профессионалық және мәселелердің идентификациясы. Біздің негізгі қатынасыз - BETO- Испан BERT бағдарламасының шектеу тапсырмалары үшін Испан корпус арқылы түрлендірушілеріне негізделген үлгісін көрсету. Біздің тәжірибемізде бірнеше архитектураларды классикалық машина оқыту алгоритмдеріне негізделген түрлендірушеріне салыстырып тұрдық. Бұл тәсілім менен, оқу процесінде F1- нәтижесін 0, 92 деп жеткіздік.', 'it': "In questo articolo presentiamo il nostro approccio e la descrizione del sistema sul Task 7a in ProfNer-ST: Identificazione della professione e dell'occupazione nei Social Media correlati alla salute. Il nostro contributo principale è quello di dimostrare l'efficacia di utilizzare BETO-spagnolo BERT come modello basato su trasformatori pre-addestrati con un corpo spagnolo per le attività di classificazione. Nei nostri esperimenti abbiamo confrontato diverse architetture basate su trasformatori con altre basate su algoritmi classici di machine learning. Con questo approccio, abbiamo ottenuto un punteggio F1 di 0,92 nel processo di valutazione.", 'lt': 'Šiame dokumente pristatome savo požiūrį ir sistemos aprašymą dėl 7a užduoties ProfNer-ST: profesijos ir profesijos nustatymas su sveikata susijusioje socialinėje žiniasklaidoje. Mūsų pagrindinis indėlis yra įrodyti BETO-Ispanijos BERT veiksmingumą kaip model į, pagrįstą transformatoriais, kurie iš anksto mokomi su Ispanijos korpusu klasifikavimo užduotims atlikti. Mūsų eksperimentuose palyginome keletą architektūrų, grindžiamų transformatoriais, su kitais, grindžiamais klasikiniais mašinų mokymosi algoritmais. Taikant šį metodą vertinimo procese pasiekėme F1 rezultatą 0,92.', 'mk': 'Во овој документ го претставуваме нашиот пристап и системски опис на задачата 7a во ProfNer-ST: Идентификација на професијата и окупацијата во социјалните медиуми поврзани со здравството. Нашиот главен придонес е да ја покажеме ефикасноста на користењето на БЕТО-Шпанското БЕРТ како модел базиран на трансформатори претренирани со Шпански корпус за класификациски задачи. Во нашите експерименти споредивме неколку архитектури базирани на трансформатори со други базирани на класични алгоритми за машинско учење. Со овој пристап, постигнавме оценка F1 од 0,92 во процесот на проценка.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d പ്രൊഫനെര്\u200d-എസ്റ്റിലെ ടാസ്ക് 7a-നെ കുറിച്ച് നമ്മുടെ സിസ്റ്റം വിവരണങ്ങളും കാണിച്ചുകൊടുക്കുന്നു. സ നമ്മുടെ പ്രധാനപ്പെട്ടത് ബെട്ടോ-സ്പാനിഷ് ബെര്\u200dട്ടി ഉപയോഗിക്കുന്നതിന്റെ പ്രധാനപ്രകാരം കാണിക്കാനാണ്. സ്പാനിഷ് കോര്\u200dപ്പുസിന നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d ക്ലാസിക്കല്\u200d യന്ത്രങ്ങള്\u200d പഠിക്കുന്ന ആല്\u200dഗോരിത്മുകള്\u200d അടിസ്ഥാനത്തില്\u200d നമ്മള്\u200d പല ആര്\u200dക്കിട് ഈ പ്രക്രിയയില്\u200d നമ്മള്\u200d എഫ്1 സ്കോര്\u200d 0.92 പ്രക്രിയയില്\u200d എത്തി.', 'ms': 'Dalam kertas ini kami memperkenalkan pendekatan dan keterangan sistem kami pada Tugas 7a dalam ProfNer-ST: Identifikasi profesi & pekerjaan dalam Media Sosial berkaitan Kesehatan. Kontribusi utama kita adalah untuk menunjukkan keefektivitas menggunakan BETO-Spanish BERT sebagai model berdasarkan pengubah yang dilatih dengan Spanish Corpus untuk tugas klasifikasi. Dalam eksperimen kami kami membandingkan beberapa arkitektur berdasarkan pengubah dengan yang lain berdasarkan algoritma pembelajaran mesin klasik. Dengan pendekatan ini, kami mencapai nilai F1 0.92 dalam proses penilaian.', 'mt': 'F’dan id-dokument nippreżentaw l-approċċ u d-deskrizzjoni tas-sistema tagħna dwar il-Kompitu 7a fil-ProfNer-ST: Identifikazzjoni tal-professjoni u x-xogħol fil-Midja Soċjali relatata mas-Saħħa. Il-kontribut ewlieni tagħna huwa li nuru l-effettività tal-użu tal-BETO-Spanish BERT bħala mudell ibbażat fuq trasformaturi mħarrġa minn qabel ma’ Spanish Corpus għal kompiti ta’ klassifikazzjoni. Fl-esperimenti tagħna qabblu diversi arkitetturi bbażati fuq trasformaturi ma’ oħrajn ibbażati fuq algoritmi klassiċi tat-tagħlim tal-magni. B’dan l-approċċ, kisbet punteġġ F1 ta’ 0.92 fil-proċess ta’ evalwazzjoni.', 'mn': 'Энэ цаасан дээр бид 7.a ажил дээр ажиллах болон системийн тодорхойлолтыг профессор-ST: Эрүүл мэндийн хамааралтай нийгмийн мэдээллийн мэргэжил болон ажиллагааны тодорхойлолтыг тайлбарлаж байна. Бидний гол зорилго бол BETO-Испан БЕРТ-ын хэрэглэх үйл ажиллагааг хуваалцах Испан Корпус дээр шилжүүлэгчдийн загвар болгон загвар болгон ашиглах үйл ажиллагааг харуулах юм. Бидний туршилтанд олон архитектуруудыг өөрчлөгчид дээр харьцуулсан. Классик машины суралцах алгоритмыг үндсэн. Энэ арга хэмжээгээр бид үнэлгээний процесс дээр F1-ийн 0.92 оноо гаргасан.', 'sr': 'U ovom papiru predstavljamo naš pristup i opis sistema o zadatku 7a u ProfNer-ST: Identifikacija profesije i okupacije u socijalnim medijima povezanim sa zdravstvom. Naš glavni doprinos je da pokažemo učinkovitost korištenja BETO-španjolskog BERT kao model na osnovu transformatora koji se pretvaraju sa španjolskim korpusom za klasifikacijske zadatke. U našim eksperimentima usporedili smo nekoliko arhitektura baziranih na transformatorima sa drugima baziranim na klasičnim algoritmima učenja mašine. S ovim pristupom, postigli smo F1 rezultat od 0,92 u procesu procjene.', 'ro': 'În această lucrare prezentăm abordarea și descrierea sistemului nostru privind Task 7a în ProfNer-ST: Identificarea profesiei și ocupației în Social Media legate de sănătate. Contribuția noastră principală este de a demonstra eficiența utilizării BETO-spaniolă BERT ca model bazat pe transformatoare pre-instruite cu un Corpus spaniol pentru sarcini de clasificare. În experimentele noastre am comparat mai multe arhitecturi bazate pe transformatoare cu altele bazate pe algoritmi clasici de machine learning. Cu această abordare, am obținut un scor F1 de 0,92 în procesul de evaluare.', 'pl': 'W niniejszym artykule przedstawiamy nasze podejście i opis systemu zadania 7a w ProfNer-ST: Identyfikacja zawodu i zawodu w mediach społecznościowych związanych ze zdrowiem. Naszym głównym wkładem jest pokazanie skuteczności wykorzystania BETO-Spanish BERT jako modelu opartego na transformatorach wstępnie przeszkolonych korpusem hiszpańskim do zadań klasyfikacyjnych. W naszych eksperymentach porównaliśmy kilka architektur opartych na transformatorach z innymi opartymi na klasycznych algorytmach uczenia maszynowego. Dzięki temu podejściu osiągnęliśmy w procesie oceny wynik F1 0,92.', 'si': 'මේ පත්තරේ අපි අපේ ප්\u200dරවේශනය සහ පද්ධතිය විස්තර විස්තර 7a වැඩේ ප්\u200dරොෆේන්ර්-ST: සාමාජික මාධ්\u200dයමයේ ව්\u200dයාපාර සහ ව්\u200d අපේ ප්\u200dරධාන ප්\u200dරයෝජනය තමයි BETO-ස්පැනිස් BERT භාවිතා කරන්න ප්\u200dරයෝජනයක් පෙන්වන්නේ ස්පැනිස් කෝර්පුස් එක්ක පරික්ෂ අපේ පරීක්ෂණාවට අපි විශ්වාස කරන්නේ අනිත් අනිත් අධාරිත්වයෙන් වෙනස් කරන්න අනිත් අනිත් අනිත් අනිත් අ මේ විදිහට, අපි පරීක්ෂණ ප්\u200dරවෘත්තියේ F1-ප්\u200dරමාණයක් 0.92 වෙනුවෙන් ලැබුනා.', 'so': 'Warqadan waxaynu ku soo bandhignaa qoraalkayaga iyo qoraalka nidaamka ee shaqada 7a ee ProfNer-ST: Aqoonsiga xirfadda iyo xirfadda ku saabsan macluumaadka bulshada caafimaadka. Kharashadanada ugu horeysa waa in lagu tuso effektada isticmaalka BETO-Spanish BERT sida model ku saleysan beddelashada lagu soo delayso shaqada fasaxka Isbanish. Imtixaanadeena ayaannu isbarbareynay dhawr dhismo oo ku saleysan isbedelyo iyo kuwo kale oo ku saleysan kalkaaliska machadka barashada algorithm. Markaas waxan ku jirtay, waxaynu gaadhnay koox F1 oo ah 0.92 xiliga qiimeynta.', 'ta': 'இந்த காகிதத்தில் நாம் பணி 7a பற்றி எங்கள் வழிமுறையையும் கணினியின் விவரங்களையும் கொண்டு வருகிறோம் பிரொப்னெர்-ST: உடல் சோத எங்கள் முக்கிய பங்கு பிடோ-ஸ்பானிஷ் பெர்ட் பயன்படுத்தும் விளைவை பார்த்துக் கொள்ள வேண்டும் வகுப்பு பணிகளுக்கு பிஸ்பானிஷ் கார்ப எங்கள் சோதனைகளில் நாங்கள் பல அடிப்படையாளர் இந்த செயல்பாட்டில், நாம் மதிப்பு செயல்பாட்டில் 0.92-ன் F1-score அடைந்தோம்.', 'no': 'I denne papiret presenterer vi tilnærminga og systemskildring vårt på oppgåve 7a i ProfNer-ST: Identifikasjon av profesjon og oppgåve i helsetjende sosiale medier. Vårt hovudbidrag er å visa effektiviteten til å bruka BETO-spansk BERT som eit modell basert på transformerande som er område med eit spansk korpus for klassifikasjonsprogram. I eksperimentene våre sammenlignet vi fleire arkitektur basert på transformatorar med andre basert på klassiske maskinelæringsalgoritme. Med denne tilnærminga har vi oppnådd eit F1-poeng med 0,92 i evalueringsprosessen.', 'sv': 'I denna uppsats presenterar vi vårt tillvägagångssätt och systembeskrivning på Uppgift 7a i ProfNer-ST: Identifiering av yrke och yrke i hälsorelaterade sociala medier. Vårt huvudsakliga bidrag är att visa hur effektivt det är att använda BETO-spanska BERT som modell baserad på transformatorer som är förberedda med en spansk korpus för klassificeringsuppgifter. I våra experiment jämförde vi flera arkitekturer baserade på transformatorer med andra baserade på klassiska maskininlärningsalgoritmer. Med detta tillvägagångssätt uppnådde vi en F1-poäng på 0,92 i utvärderingsprocessen.', 'ur': 'ہم اس کاغذ میں اپنے طریقہ اور سیستم کی تعریف کو پروفنر-ST میں پروفنر 7a کے بارے میں نشان دیتے ہیں: سلامتی میڈیا کے معاملہ میں پروفسशन اور مشغول کی تعریف. ہمارا اصلی حصہ یہ ہے کہ BETO-Spanish BERT کا استعمال کرنا ایک موڈل بنا کر اسپانیایی کورپوس کے ساتھ تغییرات کرنے والوں پر بنیاد رکھنے کے لئے اثرات دکھائے۔ ہمارے آزمائش میں ہم نے بہت سی معماری تغییر کرنے والوں پر بنیاد رکھی ہے اور دوسروں سے کلاسیک ماشین یادگاری الگوریتم پر بنیاد رکھی ہے۔ اس طریقے سے، ہم نے 0.92 کی F1-score کو ارزیابی پروسس میں پہنچا۔', 'uz': "Bu hujjatda biz ProfNer-STda Vazifaning 7a haqida tizim taʼriflarimizni koʻrsatimiz: Proner-STda saqlab bogʻliq jamiyat medyayasida taʼminlovchi va vazifani aniqlash. Bizning asosiy qandaydir BETO-Spanish BERT (BETO-Spanish BERT) yordamida o'zgarishlarni tashkilotning tashkilotlari uchun o'zgarishga asoslangan model sifatida ko'rsatish mumkin. Bizning tajribalarimizda biz bir necha arkitekalarni o'rganish algoritlarga o'zgarishga asoslangan boshqalar bilan o'rganish asosida ko'plab o'zgarishlar bilan kamaytdik. Bu usuli bilan biz qiymatning jarayonini 0.92 qiymatga F1 scori topdik.", 'vi': 'Trong tờ giấy này chúng tôi giới thiệu phương pháp và mô tả hệ thống về Nhiệm vụ 7a ở Giáo sư Nero-ST: Nhận dạng nghề nghiệp dựa trên các phương tiện liên quan đến y tế. Phần đóng góp chính của chúng tôi là cho thấy hiệu quả sử dụng BET-Tây Ban Nha BERT làm mô hình dựa trên máy biến thế trước khi sử dụng một Tập đoàn Tây Ban Nha để phân loại các công tác. Trong các thí nghiệm, chúng tôi so sánh các kiến trúc dựa trên máy biến đổi với các loại khác dựa trên thuật toán học máy cổ điển. Với cách tiếp cận này, chúng ta đã đạt được điểm số F1 của 0.92 trong quá trình đánh giá.', 'nl': 'In dit artikel presenteren we onze aanpak en systeembeschrijving over Taak 7a in ProfNer-ST: Identificatie van beroep en beroep in Gezondheidsgerelateerde sociale media. Onze belangrijkste bijdrage is het aantonen van de effectiviteit van het gebruik van BETO-Spanish BERT als model gebaseerd op transformatoren voorgetraind met een Spaans Corpus voor classificatietaken. In onze experimenten hebben we verschillende architecturen op basis van transformatoren vergeleken met andere op basis van klassieke machine learning algoritmes. Met deze aanpak bereikten we een F1-score van 0.92 in het evaluatieproces.', 'bg': 'В настоящата статия представяме нашия подход и системно описание на задача 7а в Профнер-СТ: Идентификация на професията и професията в здравните социални медии. Нашият основен принос е да покажем ефективността на използването на БЕТО-Испански БЕРТ като модел, базиран на трансформатори, предварително обучени с испански корпус за класификационни задачи. В нашите експерименти сравнихме няколко архитектури, базирани на трансформатори, с други базирани на класически алгоритми за машинно обучение. С този подход постигнахме резултат от 0,92 в процеса на оценяване.', 'id': 'In this paper we present our approach and system description on Task 7a in ProfNer-ST: Identification of profession & occupation in Health related Social Media.  Kontribusi utama kita adalah menunjukkan efektivitas menggunakan BETO-Spanyol BERT sebagai model berdasarkan transformer yang dilatih dengan Spanish Corpus untuk tugas klasifikasi. Dalam eksperimen kami kami membandingkan beberapa arsitektur berdasarkan transformer dengan yang lain berdasarkan algoritma belajar mesin klasik. Dengan pendekatan ini, kami mencapai nilai F1 0,92 dalam proses evaluasi.', 'de': 'In diesem Beitrag stellen wir unseren Ansatz und unsere Systembeschreibung zu Task 7a in ProfNer-ST vor: Identifikation von Beruf und Beruf in Gesundheitsbezogenen Social Media. Unser Hauptbeitrag ist es, die Effektivität des Einsatzes von BETO-Spanish BERT als Modell auf Basis von Transformatoren zu zeigen, die mit einem spanischen Korpus vortrainiert wurden. In unseren Experimenten haben wir verschiedene Architekturen auf Basis von Transformatoren mit anderen auf Basis klassischer Algorithmen des maschinellen Lernens verglichen. Mit diesem Ansatz erreichten wir im Bewertungsprozess einen F1-Score von 0,92.', 'hr': 'U ovom papiru predstavljamo naš pristup i opis sustava o zadatku 7a u ProfNer-ST: Identifikacija profesije i okupacije u socijalnim medijima povezanim s zdravstvenim sredstvima. Naš glavni doprinos je pokazati učinkovitost korištenja BETO-španjolskog BERT kao model baziran na transformatorima koji se pretvaraju s španjolskim korpusom za klasifikacijske zadatke. U našim eksperimentima usporedili smo nekoliko arhitektura baziranih na transformatorima s drugima baziranim na klasičnim algoritmima učenja strojeva. S tim pristupom, postigli smo F1 rezultat od 0,92 u procesu procjene.', 'sw': 'Katika karatasi hii tunaweka mbinu na maelezo ya mfumo kuhusu kazi ya 7a katika ProfNer-ST: Kutambua utaalamu wa utaalamu na kazi katika mitandao ya kijamii yanayohusiana na afya. Mchango wetu mkuu ni kuonyesha ufanisi wa kutumia BETO-Uhispania BERT kama mfano wa mabadiliko yaliyotolewa na Corpus ya Kihispania kwa ajili ya kazi za usambazaji. In our experiments we compared several architectures based on transformers with others based on classical machine learning algorithms.  Kwa njia hii, tulipata kipindi cha F1 cha 0.92 katika mchakato wa tathmini.', 'da': 'I denne artikel præsenterer vi vores tilgang og systembeskrivelse på opgave 7a i ProfNer-ST: Identifikation af erhverv og erhverv i sundhedsrelaterede sociale medier. Vores vigtigste bidrag er at vise effektiviteten af at bruge BETO-spansk BERT som model baseret på transformatorer fortrænet med et spansk korpus til klassifikationsopgaver. I vores eksperimenter sammenlignede vi flere arkitekturer baseret på transformere med andre baseret på klassiske maskinlæringsalgoritmer. Med denne tilgang opnåede vi en F1-score på 0,92 i evalueringsprocessen.', 'ko': '본고에서 우리는 ProfNer ST에서 임무 7a의 방법과 시스템 묘사를 소개했다. 건강과 관련된 소셜 미디어에서 직업과 직업을 식별하는 것이다.우리의 주요 공헌은 BETO-spanish-BERT를 모델로 사용하는 유효성을 보여주는 것이다. 이 모델은 스페인어 어료 라이브러리와 미리 훈련된 변형 금강을 바탕으로 분류 임무에 사용된다.우리의 실험에서 우리는 몇 가지 변압기 기반의 구조와 다른 고전적인 기계 학습 알고리즘 기반의 구조를 비교했다.이런 방법을 통해 우리는 평가 과정에서 0.92의 F1 점수를 얻었다.', 'af': "In hierdie papier voorsien ons toegang en stelsel beskrywing op taak 7a in ProfNer-ST: Identifikasie van profesie en occupasie in gesondheid verwante sosiale media. Ons hoofbydraai is om die effektiviteit te wys van BETO-Spaanse BERT as 'n model gebaseer op transformeerders wat met 'n Spaanse Korpus aangestel is vir klassifikasie taak. In ons eksperimente vergelyk ons verskeie arkitektuure gebaseer op transformers met ander gebaseer op klassieke masjien leer algoritme. Met hierdie toegang het ons 'n F1-telling van 0,92 in die evalueringsproses bereik.", 'tr': "Bu kagyzda ProfNer-ST: ProfNer-ST'da Profesyonyň we mesleksiýasynda saglygy bilen ilgili ýagdaýlaryň kimligi we mesleksiýalaryň bardygyny aýdýarys. Biziň esasy teklipimiz BETO-Ispanýolça BERT'yň barlygyny klasifikasiýa görerler üçin süýtgeden transformatçylara daýanýan bir nusga görkezmädir. Biziň deneylerimizde klasik maşyny öwrenmek algoritmalara daýanýan bir näçe arhitektura guruldyk. Bu ýagdaýda çykyş prosesynda F1-score 0,92 bardyk.", 'fa': 'در این کاغذ ما دستور و توضیح سیستم\u200cمون را در مورد کاری 7a در پروفنر-ST: شناسایی شغل و شغل در رسانه\u200cهای اجتماعی مربوط به سلامت نشان می\u200cدهیم. اعضای اصلی ما این است که فعالیت استفاده از BETO-Spanish BERT به عنوان یک مدل بر اساس تغییر دهندگان که با یک کورپوس اسپانیایی برای کارهای مختلف تغییر داده می شوند نشان دهیم. در آزمایشات ما چند معماری را بر اساس تغییردهندگان با بقیه بر اساس الگوریتم یادگیری ماشین کلاسیک مقایسه کردیم. با این روش، ما به یک امتیاز F1 در فرایند ارزیابی 0.92 رسیدیم.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք մեր մոտեցումը և համակարգի նկարագրությունը Prof-Net-S-ի 7a խնդրի մասին. Առողջապահության հետ կապված սոցիալական լրատվամիջոցների մասնագիտության և մասնագիտության հայտնաբերումը: Մեր հիմնական ներդրումն այն է, որ ցույց տանք BETo-իսպաներեն BERT-ի արդյունավետությունը որպես մոդել, որը հիմնված է իսպաներեն Կորպուսի հետ նախապատրաստված վերափոխողների վրա դասակարգումների համար: Մեր փորձարկումներում մենք համեմատեցինք մի քանի ճարտարապետություններ, որոնք հիմնված են վերափոխողների և մյուսների հետ, որոնք հիմնված են դասական մեքենային ուսումնասիրության ալգորիթմների վրա: With this approach, we achieved an F1-score of 0.92 in the evaluation process.', 'bn': 'In this paper we present our approach and system description on Task 7a in ProfNer-ST: Identification of profession & occupation in Health related Social Media.  আমাদের প্রধান অবদান হচ্ছে বিটো-স্প্যানিশ বিবের্ট ব্যবহারের কার্যক্রম দেখানোর জন্যে স্প্যানিশ কোর্পাসের কাজের জন্য বিভিন্ন পরিবর্তন আমাদের পরীক্ষায় আমরা ক্লাসিক্যাল মেশিনের শিক্ষা অ্যালগরিদমের উপর ভিত্তিক পরিবর্তনের ভিত্তিতে বেশ কিছু আর্কিটেক এই পদ্ধতির মাধ্যমে আমরা মূল্য প্রক্রিয়ায় একটি ফি১ স্কোর অর্জন করেছি।', 'am': 'በዚህ ገጽ በፕሮፌኔር-ST ላይ የስራ ስራዎችን እና የስርዓቱን ዝርዝር እናቀርባለን፤ በአዳም ማኅበራዊ ሚዲያ ባለው የprofessional እና ስራ ማረጋገጥ እናደርጋለን፡፡ የዋነታችን አካሄድ BETO-ስፓኒሽ BERT በመጠቀም የስፓኒሽ ኮርፓስ ለክፍል ስርዓት የተደረገውን ለውጦች በመጠቀም ምሳሌ ማሳየት ነው፡፡ በተፈተናችን ውስጥ ከሌሎቹ ጋር በመለወጥ የክላሲካዊ መሳሪያን በማስተማር ላይ የተመሳሳይን ብዙዎችን የመዝገብ አካውንት እናሳያታለን፡፡ በዚህም ሥርዓት የ0.92 ነጥብ አግኝተናል፡፡', 'az': "Bu kağızda 7.a Taski barəsində tərzim və sistem təfsilərimizi ProfNer-ST: Sağlamlıq məlumatının təşkil edilməsi və məşğulluğunu təsdiqləyirik. Bizim ən böyük qismətimiz BETO-İspanyol BERT'u klasifikasiya görevləri üçün İspanyol korpusu ilə təkrarlanan transformatörlərə dayanan bir model olaraq istifadə etmək idi. Bizim təcrübələrimizdə bir neçə arhitektür, klasik maşın öyrənməsi algoritmi ilə başqalarına dayanan transformatörlərlə qarşılaşdıq. Bu tərzdə, değerlendirmə sürətində F1 dəyişikliyi 0,92 dəyişdik.", 'cs': 'V tomto článku představujeme náš přístup a popis systému k Úkolu 7a v ProfNer-ST: Identifikace profese a povolání v sociálních médiích souvisejících se zdravím. Naším hlavním příspěvkem je ukázat efektivitu využití BETO-Spanish BERT jako modelu založeného na transformátorech předtrénovaných španělským korpusem pro klasifikační úkoly. V našich experimentech jsme porovnali několik architektur založených na transformátorech s jinými založenými na klasických algoritmech strojového učení. Tímto přístupem jsme v procesu hodnocení dosáhli F1 skóre 0,92.', 'bs': 'U ovom papiru predstavljamo naš pristup i opis sistema o zadatku 7a u ProfNer-ST: Identifikacija profesije i okupacije u socijalnim medijima vezanim za zdravlje. Naš glavni doprinos je pokazati učinkovitost korištenja BETO-španjolskog BERT kao model baziran na transformatorima koji se pretvaraju sa španjolskim korpusom za klasifikacijske zadatke. U našim eksperimentima usporedili smo nekoliko arhitektura baziranih na transformatorima sa drugima baziranim na klasičnim algoritmima učenja mašine. S ovim pristupom, postigli smo F1 rezultat od 0,92 u procesu procjene.', 'fi': 'Tässä artikkelissa esittelemme lähestymistapamme ja järjestelmäkuvauksemme tehtävään 7a ProfNer-ST: Ammatin ja ammatin tunnistaminen terveysalan sosiaalisessa mediassa. Pääasiallinen panoksemme on osoittaa BETO-Spanish BERT:n käytön tehokkuuden mallina, joka perustuu espanjalaisella korpusella esikoulutettuihin muuntajiin luokitustehtävissä. Kokeissamme vertasimme useita muuntajiin perustuvia arkkitehtuureja muihin klassisiin koneoppimisalgoritmeihin perustuviin arkkitehtuureihin. Tällä lähestymistavalla saavutimme arviointiprosessissa F1-pisteen 0,92.', 'et': 'Käesolevas artiklis tutvustame oma lähenemisviisi ja süsteemi kirjeldust ülesandele 7a ProfNer-ST: kutseala ja kutseala identifitseerimine tervisega seotud sotsiaalmeedias. Meie peamine panus on näidata BETO-Spanish BERT-i kasutamise efektiivsust mudelina, mis põhineb Hispaania korpusega eeltreenitud trafodel klassifitseerimisülesannete jaoks. Oma eksperimentides võrdlesime mitmeid transformaatoritel põhinevaid arhitektuure teistega, mis põhinevad klassikalistel masinõppe algoritmidel. Selle lähenemisviisiga saavutasime hindamisprotsessis F1-skoori 0,92.', 'ca': "En aquest paper presentem el nostre enfocament i descripció del sistema sobre la tasca 7a a ProfNer-ST: Identificació de la profession i ocupació en els mitjans socials relacionats amb la salut. La nostra contribució principal és mostrar l'eficacia d'utilitzar BETO-Spanish BERT com un model basat en transformadors pré-entrenats amb un Corpus espanyol per tasques de classificació. En els nostres experiments vam comparar diverses arquitectures basades en transformadors amb altres basades en algoritmes d'aprenentatge clàssic de màquines. With this approach, we achieved an F1-score of 0.92 in the evaluation process.", 'sq': 'In this paper we present our approach and system description on Task 7a in ProfNer-ST: Identification of profession & occupation in Health related Social Media.  Our main contribution is to show the effectiveness of using BETO-Spanish BERT as a model based on transformers pretrained with a Spanish Corpus for classification tasks.  In our experiments we compared several architectures based on transformers with others based on classical machine learning algorithms.  With this approach, we achieved an F1-score of 0.92 in the evaluation process.', 'he': 'בעיתון הזה אנחנו מציגים את הגישה והתיאור המערכת שלנו על משימה 7a בפרופינר-סט: זיהוי מקצוע & מקצוע במדיה חברתית קשורה לבריאות. התרומה העיקרית שלנו היא להראות את היעילות של השימוש של BETO-ספרדית BERT כדוגמנית מבוססת על משתנים מאומנים מראש עם קורפוס ספרדי למשימות מסווג. בניסויים שלנו השוונו כמה ארכיטקטורות מבוססות על משתנים עם אחרים מבוססים על אלגוריתמים ללמוד מכונות קלאסיים. עם גישה זו, השגנו נקודת F1 של 0.92 בתהליך הערכה.', 'ha': "Ga wannan karatun, Munã halatar da shiryarwa da fassarar na'ura a kan Tafiyar 7a a cikin profNer-St: Yayyar da aikin & akan da aikin da ke cikin Shirin Jamii da aka sani. Madaidaici na nuna mafiya amfani da BETO-spanish BERT kamar wata motel a kan canza transformers wanda aka baka da Corbus na Kispanishi. A cikin jarrabõyinmu, muka samfani wasu matsayi masu da aka danne shi da wasu mutane, a kan karatun karatun masu karatun karatun kalsiki. Ga wannan hanyarwa, mun sami wata F1-score na 0.92 a cikin jararin evaluation.", 'sk': 'V prispevku predstavljamo naš pristop in sistemski opis naloge 7a v ProfNer-ST: Identifikacija poklica in poklica v socialnih medijih, povezanih z zdravjem. Naš glavni prispevek je pokazati učinkovitost uporabe BETO-Spanish BERT kot modela, ki temelji na transformatorjih, predtreniranih s španskim korpusom za klasifikacijske naloge. V naših eksperimentih smo primerjali več arhitektur, ki temeljijo na transformatorjih, z drugimi, ki temeljijo na klasičnih algoritmih strojnega učenja. S tem pristopom smo v procesu ocenjevanja dosegli rezultat F1 0,92.', 'jv': 'Nang paper iki, kita nggawe dadi aturan karo sistem nambah ning Job 7 Awakdhéwé nggawe barang pengguna kuwi nggawe efekat kanggo ngubah BETo-Spanish BERT ngangge model sing basa supoyo transformer sing isin katêpakan karo kelompok Spanish Anyone Ngkang diangkat iki, kita sampeyan F1 kalih 0.2 dumadhi kanggo ngerasakno', 'bo': 'ང་ཚོའི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོའི་གནད་སྡུད་དང་མ་ལག་གི་འགྲེལ་བཤད་ཀྱི་ལས་འགན་7a ་་སྒྲུབ་ཚོགས་ST:ལས་འགན་སྐྱོང་དང ང་ཚོའི་རྩ་བའི་གོ་སྤྲོད་ནི་BETO-Spanish BERT སྤྱོད་མཁན་གྱི་ལས་འཕགས་བ་སྟོན་ནི་ཡིན་པ་ཞིག་ཡིན། ང་ཚོའི་ལག་འཁྱེར་སྟངས་ནང་དུ་ང་ཚོས་རྩིས་གཞི་མང་པོ་ཞིག་གིས་བཟོ་བཅོས་བྱེད་པའི་བཟོ་རྩིས་གཞི་འདྲ་བ་དང་གཞན་པོ་ཞི འདི་ལྟར་བྱ་ཚིག་དང་། ང་ཚོས་0.92 རིམ་པ་ཞིག་གི་ཚད་ལྟར་འཛིན་བྱུང་།'}
{'en': 'UoB at ProfNER 2021 : Data Augmentation for Classification Using  Machine Translation U o B  at  P rof NER  2021: Data Augmentation for Classification Using Machine Translation', 'fr': 'UoB au salon ProfNer 2021\xa0: augmentation des données pour la classification par traduction automatique', 'ar': 'UoB في ProfNER 2021: زيادة البيانات من أجل التصنيف باستخدام الترجمة الآلية', 'pt': 'UoB no ProfNER 2021: Aumento de dados para classificação usando tradução automática', 'es': 'La UoB en ProFner 2021: Aumento de datos para la clasificación mediante traducción automática', 'zh': 'UoB at ProfNER 2021:用机器翻译益数', 'ja': 'ProfNER 2021のUoB ：機械翻訳を使用した分類のためのデータ拡張', 'ru': 'UoB на ProfNER 2021: Расширение данных для классификации с использованием машинного перевода', 'hi': 'ProfNER 2021 पर UoB: मशीन अनुवाद का उपयोग करके वर्गीकरण के लिए डेटा संवर्धन', 'ga': 'UoB ag ProfNER 2021: M챕ad첬 Sonra챠 le haghaidh Aicmithe ag 횣s찼id Aistri첬ch찼n Meais챠n', 'hu': 'UOB a ProfNER 2021-en: Adatbővítés a gépi fordítás használatával történő besoroláshoz', 'el': 'Το UoB στο ΠροfNER 2021: Αύξηση δεδομένων για ταξινόμηση με χρήση μηχανικής μετάφρασης', 'ka': 'Comment', 'it': 'UOB a ProfNER 2021: Aumento dei dati per la classificazione utilizzando la traduzione automatica', 'kk': 'UoB профиNER 2021: Классификациялау үшін деректерді өзгерту', 'lt': 'UoB ProfNER 2021: Duomenų didinimas klasifikacijai naudojant mašinų vertimą', 'mk': 'UoB на ProfNER 2021: Агментација на податоците за класификација со превод на машина', 'ms': 'UoB di ProfNER 2021: Pembesaran Data untuk Pengklasifikasi Mengguna Terjemahan Mesin', 'ml': 'പ്രൊഫനെര്\u200d 2021- ലെ UoB: മെഷീന്\u200d പരിഭാഷ ഉപയോഗിക്കുന്നതിനുള്ള ഡാറ്റാ ഓഗ്മെന്റേഷന്\u200d', 'mt': 'UoB fil-ProfNER 2021: Aġġustament tad-dejta għat-Traduzzjoni tal-Klassifikazzjoni bl-Użu tal-Magna', 'mn': 'UoB at ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'no': 'UoB ved ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'ro': 'UOB la ProfNER 2021: Augmentarea datelor pentru clasificare folosind traducerea automată', 'pl': 'UoB na ProfNER 2021: Rozszerzenie danych dla klasyfikacji przy użyciu tłumaczenia maszynowego', 'so': 'UoB at ProfNER 2021: Augmentation of data for classification using machine translation', 'sv': 'UOB på ProfNER 2021: Dataförstärkning för klassificering med maskinöversättning', 'sr': 'UoB na ProfNER 2021: Augmentacija podataka za klasifikaciju korištenje prevoda mašine', 'si': 'UoB at ProfessNER 2021: Data Agmentation for Classication Using machine translation', 'ta': 'ProfNER 2021-ல் UoB: இயந்திரம் மொழிபெயர்ப்பை பயன்படுத்தி தரவு ஒப்பிடுதல்', 'ur': 'پروفنر 2021 میں UoB: کلاسیفٹ کے لئے ڈاٹ اگنٹمنٹ ڈیٹ اگنٹمنٹ', 'uz': 'Comment', 'vi': 'Phụ đề bây giờ tại Giáo sư nằm vùng 2021: Tăng bậc dữ liệu cho việc sử dụng máy móc', 'bg': 'УОБ в ПрофНЕР 2021: Увеличаване на данните за класификация чрез машинен превод', 'da': 'UoB på ProfNER 2021: Dataudvidelse til klassificering ved hjælp af maskinoversættelse', 'hr': 'UoB na ProfNER 2021: povećanje podataka za klasifikaciju korištenje prevoda stroja', 'nl': 'UoB op ProfNER 2021: Data Augmentation voor Classificatie met Machine Translation', 'de': 'UoB auf der ProfNER 2021: Datenerweiterung zur Klassifizierung mittels maschineller Übersetzung', 'ko': 'UoB ProfNER 2021: 기계 번역을 사용한 분류 데이터 확장', 'id': 'UoB di ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'fa': 'UoB در پروفNER ۲۰۱۱: افزایش داده\u200cها برای شناسایی استفاده از ترجمه ماشین', 'af': 'UoB by ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'sw': 'UoB katika ProfNER 2021: Uunganishaji wa data kwa ajili ya kutangazwa kwa kutumia Tafsiri ya Mashine', 'tr': 'UoB at ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'sq': 'UoB at ProfNER 2021: Data Incrementation for Classification Using Machine Translation', 'am': 'በ ፕሮግራም 2021:', 'hy': 'UoB-ը ProfNOR 2021 թվականին. Մեքենայի թարգմանման օգտագործման դասակարգման տվյալների աճը', 'az': "ProfNER 2021'dÉ™ UoB: Klasifikasyon ĂĽĂ§ĂĽn mÉ™lumatlar UÄźultmasÄ±", 'bn': 'প্রফেনার ২০২১-এ ইউআইবি: মেশিন অনুবাদ ব্যবহার করার জন্য ডাটা অ্যাগমেন্টেশন', 'bs': 'UoB na ProfNER 2021: Augmentacija podataka za klasifikaciju korištenje prevoda stroja', 'ca': 'UoB a ProfNER 2021: Aumentació de dades per a la classificació de traducció de màquines', 'cs': 'UoB na ProfNER 2021: Rozšíření dat pro klasifikaci pomocí strojového překladu', 'et': 'UoB ProfNER 2021: andmete täiendamine masintõlke abil klassifitseerimiseks', 'fi': 'UoB ProfNER 2021: Tietojen lisääminen konekäännöksen avulla tapahtuvaan luokitteluun', 'jv': 'UOB at Profile NeR 2020 1: data AGments for CLSSIification Using Device translation', 'ha': '@ info: whatsthis', 'sk': 'UoB na ProfNER 2021: Povečanje podatkov za klasifikacijo s strojnim prevajanjem', 'bo': 'UoB at ProfNER 2021: Data Augmentation for Classification Using Machine Translation', 'he': 'UoB at ProfNER 2021: Data Augmentation for Classification Using Machine Translation'}
{'en': 'This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a. The  task  was aimed at detecting the mention of professions in social media text. Our team experimented with two methods of improving the performance of pre-trained models : Specifically, we experimented with  data augmentation  through  translation  and the merging of multiple language inputs to meet the objective of the task. While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using  back-translation , the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through  back-translation and bilingual data .', 'es': 'Este artículo describe la participación del equipo UOB-NLP en la subtarea compartida 7a de Profner-ST. La tarea tenía como objetivo detectar la mención de profesiones en el texto de las redes sociales. Nuestro equipo experimentó con dos métodos para mejorar el rendimiento de los modelos previamente entrenados: Específicamente, experimentamos con el aumento de datos a través de la traducción y la fusión de entradas de múltiples idiomas para cumplir con el objetivo de la tarea. Si bien el modelo de mejor rendimiento en los datos de prueba consistió en mBert ajustado con precisión en datos aumentados mediante retrotraducción, la mejora es menor, posiblemente porque los modelos multilingües preentrenados, como mBert, ya tienen acceso al tipo de información proporcionada a través de la retrotraducción y los datos bilingües.', 'fr': "Cet article décrit la participation de l'équipe UOB-NLP à la sous-tâche partagée Profner-ST 7a. La tâche visait à détecter la mention de professions dans le texte des réseaux sociaux. Notre équipe a expérimenté deux méthodes pour améliorer les performances des modèles pré-entraînés\xa0: Plus précisément, nous avons expérimenté l'augmentation des données par la traduction et la fusion de plusieurs entrées linguistiques pour atteindre l'objectif de la tâche. Alors que le modèle le plus performant sur les données de test consistait à affiner mBERt sur des données augmentées à l'aide de la rétro-traduction, l'amélioration est peut-être mineure parce que les modèles pré-entraînés multilingues tels que mBerT ont déjà accès au type d'informations fournies par la rétro-traduction et les données bilingues.", 'ar': 'تصف هذه الورقة مشاركة فريق UoB-NLP في المهمة الفرعية المشتركة 7a لـ ProfNER-ST. كانت المهمة تهدف إلى الكشف عن ذكر المهن في نصوص وسائل التواصل الاجتماعي. جرب فريقنا طريقتين لتحسين أداء النماذج المدربة مسبقًا: على وجه التحديد ، جربنا زيادة البيانات من خلال الترجمة ودمج مدخلات اللغات المتعددة لتحقيق هدف المهمة. في حين أن النموذج الأفضل أداءً في بيانات الاختبار يتكون من mBERT الذي تم ضبطه بدقة على البيانات المعززة باستخدام الترجمة العكسية ، فمن المحتمل أن يكون التحسين طفيفًا لأن النماذج متعددة اللغات المدربة مسبقًا مثل mBERT لديها بالفعل إمكانية الوصول إلى نوع المعلومات المقدمة من خلال الخلفية. -الترجمة والبيانات ثنائية اللغة.', 'pt': 'Este artigo descreve a participação da equipe UoB-NLP na subtarefa compartilhada 7a do ProfNER-ST. A tarefa teve como objetivo detectar a menção de profissões em texto de mídia social. Nossa equipe experimentou dois métodos para melhorar o desempenho de modelos pré-treinados: especificamente, experimentamos o aumento de dados por meio da tradução e da fusão de entradas de vários idiomas para atender ao objetivo da tarefa. Enquanto o modelo com melhor desempenho nos dados de teste consistiu em mBERT ajustado em dados aumentados usando tradução reversa, a melhoria é pequena, possivelmente porque modelos pré-treinados multilíngues, como mBERT, já têm acesso ao tipo de informação fornecida por meio de retrotradução. -tradução e dados bilíngües.', 'ja': 'ProfNER - ST共有サブタスク7 aへのUoB - NLPチームの参加について説明する。このタスクは、ソーシャルメディアのテキストでの職業への言及を検出することを目的としていました。私たちのチームは、事前にトレーニングされたモデルのパフォーマンスを改善する2つの方法を実験しました。具体的には、タスクの目的を達成するために、翻訳によるデータ拡張と複数の言語入力のマージを実験しました。テストデータの最高のパフォーマンスを発揮するモデルは、バック翻訳を使用して拡張データに微調整されたmBERTで構成されていたが、mBERTなどの多言語事前トレーニングモデルは、既にバック翻訳およびバイリンガルデータを介して提供された種類の情報にアクセスできるため、改善はわずかである可能性がある。', 'zh': '本文述UoB-NLP团队在ProfNER-ST共享子职7a中参预。 其旨在检测社交媒体文本提及职业。 吾团队试二法:具体来说吾译并多种语言输试数增强,以足其任。 虽测试数据上体用回溯译增数微mBERT,其改进甚小,或以多言预练模形(如mBERT)已可访以反双语之数。', 'hi': 'यह पेपर ProfNER-ST साझा सबटास्क 7a में UoB-NLP टीम की भागीदारी का वर्णन करता है। कार्य का उद्देश्य सोशल मीडिया पाठ में व्यवसायों के उल्लेख का पता लगाना था। हमारी टीम ने पूर्व-प्रशिक्षित मॉडल के प्रदर्शन में सुधार के दो तरीकों के साथ प्रयोग किया: विशेष रूप से, हमने अनुवाद के माध्यम से डेटा वृद्धि और कार्य के उद्देश्य को पूरा करने के लिए कई भाषा इनपुट के विलय के साथ प्रयोग किया। जबकि परीक्षण डेटा पर सबसे अच्छा प्रदर्शन करने वाले मॉडल में बैक-ट्रांसलेशन का उपयोग करके संवर्धित डेटा पर mBERT ठीक-ट्यून किया गया था, सुधार संभवतः मामूली है क्योंकि mBERT जैसे बहुभाषी पूर्व-प्रशिक्षित मॉडल के पास पहले से ही बैक-अनुवाद और द्विभाषी डेटा के माध्यम से प्रदान की गई जानकारी तक पहुंच है।', 'ru': 'Эта бумага описывает участие команды UoB-NLP в общей подзадаче 7a ProfNER-ST. Задача была направлена на обнаружение упоминания профессий в тексте социальных медиа. Наша команда экспериментировала с двумя методами улучшения производительности предварительно обученных моделей: В частности, мы экспериментировали с расширением данных посредством перевода и слияния нескольких языковых входов для достижения цели задачи. Хотя наиболее эффективная модель на тестовых данных состояла из mBERT, доработанного на дополненных данных с использованием обратного перевода, улучшение является незначительным, возможно, потому, что многоязычные предварительно обученные модели, такие как mBERT, уже имеют доступ к типу информации, предоставляемой посредством обратного перевода и двуязычных данных.', 'ga': "Déanann an páipéar seo cur síos ar rannpháirtíocht fhoireann UoB-NLP i bhfothasc comhroinnte ProfNER-ST 7a. Bhí an tasc dírithe ar lua gairmeacha i dtéacs na meán sóisialta a bhrath. Bhain ár bhfoireann triail as dhá mhodh chun feidhmíocht na múnlaí réamhoilte a fheabhsú: Go sonrach, rinneamar turgnaimh le méadú sonraí trí aistriúchán agus trí ionchur teangacha iolracha a chumasc chun cuspóir an taisc a chomhlíonadh. Cé gur éard a bhí sa tsamhail is fearr feidhmíochta ar na sonraí tástála ná mBERT mionchoigeartaithe ar shonraí méadaithe ag baint úsáide as aisaistriúchán, is beag an feabhas b'fhéidir toisc go bhfuil rochtain cheana féin ag samhlacha ilteangacha réamhoilte ar nós mBERT ar an gcineál faisnéise a chuirtear ar fáil trí ais. -aistriúchán agus sonraí dátheangacha.", 'hu': 'Ez a tanulmány bemutatja az UOB-NLP csapat részvételét a ProfNER-ST 7a megosztott alterhelésben. A feladat célja, hogy felismerje a szakmák említését a közösségi média szövegében. Csapatunk két módszerrel kísérletezett az előkészített modellek teljesítményének javítására: konkrétan fordítással és több nyelvi bemenet egyesítésével kísérleteztünk a feladat céljának elérése érdekében. Míg a tesztadatok legjobb teljesítményű modellje a kiegészített adatokra finomhangolt mBERT-ből állt, a fejlődés valószínűleg kisebb, mert a többnyelvű előképzett modellek, mint például az mBERT már hozzáférnek a visszafordítással és a kétnyelvű adatokkal szolgáltatott információkhoz.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή της ομάδας UoB-NLP στην κοινή υποταγή 7α του ProfNER-ST. Το έργο είχε ως στόχο την ανίχνευση της αναφοράς των επαγγελμάτων στο κείμενο των μέσων κοινωνικής δικτύωσης. Η ομάδα μας πειραματίστηκε με δύο μεθόδους βελτίωσης της απόδοσης των προ-εκπαιδευμένων μοντέλων: Συγκεκριμένα, πειραματιστήκαμε με την αύξηση δεδομένων μέσω της μετάφρασης και τη συγχώνευση πολλαπλών γλωσσικών εισόδων για την επίτευξη του στόχου της εργασίας. Ενώ το μοντέλο με τις καλύτερες επιδόσεις στα δεδομένα δοκιμής συνίστατο στο mBERT που συντονίστηκε σε ενισχυμένα δεδομένα με χρήση της αντίστροφης μετάφρασης, η βελτίωση είναι μικρή πιθανώς επειδή τα πολυγλωσσικά προ-εκπαιδευμένα μοντέλα όπως το mBERT έχουν ήδη πρόσβαση στο είδος των πληροφοριών που παρέχονται μέσω της αντίστροφης μετάφρασης και των δίγλωσσων δεδομένων.', 'ka': 'ეს დომენტი აღწერს UoB-NLP ჯგუფის დაწყვეტილებას პროფენერ-ST-ს გაყოფილი სტკითხვის 7a-ში. დავალების მიზეზი იყო სოციალური მედია ტექსტის პროფეციების შესახებ. ჩვენი ჯგუფი ექსპერიმენტირებულია ორი მეტისთვის, რომელიც უფრო უფრო მეტადებული მოდელების გამოყენება: განსაკუთრებულიად, ჩვენ მონაცემენტის აგექსპერიმენტირებულია მონაცემენტის მაგრამ ტესტის მონაცემების უკეთესი მოდელი, რომელიც mBERT-ის შესაძლებელია მონაცემების შესაძლებელად დააყენებული მონაცემების შესაძლებელად, შესაძლებელია შესაძლებელია, რადგან მრავალენგური წინატვირთვის მოდელები, როგორც mBERT, უ', 'it': "Questo articolo descrive la partecipazione del team UOB-NLP alla sottomissione condivisa ProfNER-ST 7a. Il compito era volto a rilevare la menzione delle professioni nei testi dei social media. Il nostro team ha sperimentato due metodi per migliorare le prestazioni di modelli pre-formati: nello specifico, abbiamo sperimentato l'aumento dei dati attraverso la traduzione e la fusione di input linguistici multipli per raggiungere l'obiettivo del compito. Mentre il modello più performante sui dati di prova consisteva in mBERT perfezionato su dati aumentati utilizzando back-translation, il miglioramento è minore probabilmente perché modelli plurilingue pre-addestrati come mBERT hanno già accesso al tipo di informazioni fornite attraverso back-translation e dati bilingui.", 'lt': 'Šiame dokumente aprašomas UoB-NLP grupės dalyvavimas bendroje ProfNER-ST paklausoje 7a. Šios užduoties tikslas buvo nustatyti profesijų paminėjimą social in ės žiniasklaidos tekste. Mūsų komanda eksperimentavo su dviem iš anksto parengtų modelių veiksmingumo gerinimo metodais: konkrečiai eksperimentavome su duomenų didinimu vertimo ir daugelio kalbų įnašų sujungimo būdu siekiant užduoties tikslo. Nors geriausiai veikiantį bandymų duomenų model į sudarė mBERT, tiksliai pritaikytas prie padidintų duomenų, naudojant grįžtamąjį vertimą, pagerėjimas galbūt yra nedidelis, nes daugiakalbiai iš anksto parengti modeliai, pavyzdžiui, mBERT, jau turi galimybę susipažinti su informacija, teikiama grįžtamajame vertime ir dvikalbiais duomenimis.', 'ms': 'Kertas ini menggambarkan participasi pasukan UoB-NLP dalam subtanya berkongsi ProfNER-ST 7a. Tugas ini ditujukan untuk mengesan sebutan profesi dalam teks media sosial. Pasukan kami eksperimen dengan dua kaedah untuk memperbaiki prestasi model yang dilatih-dilatih: secara khusus, kami eksperimen dengan peningkatan data melalui terjemahan dan gabungan input bahasa berbilang untuk memenuhi tujuan tugas. Sementara model yang berfungsi terbaik pada data ujian terdiri daripada mBERT disesuaikan dengan baik pada data ditambah menggunakan terjemahan-belakang, peningkatan mungkin sedikit kerana model pralatih berbilang bahasa seperti mBERT sudah mempunyai akses kepada jenis maklumat yang diberikan melalui data terjemahan-belakang dan dua bahasa.', 'kk': 'Бұл қағаз UoB- NLP тобының ішкі сұраныс 7a-ның ProfNER- ST бөлімінің қатынасын анықтайды. Тапсырма әлеуметтік медиағандағы профессияларды анықтау мақсаты болды. Біздің командамыз алдын- оқыту үлгілерін жақсарту әдістерімен екі әдістер туралы тәжірибедік: Мәселен, біз деректерді аудару мен бірнеше тілдерді біріктіру үшін тапсырманың мақсатына жеткізу үшін те Тест деректерінің ең жақсы істеу үлгісі артқа аударылған деректерге көмектесілген mBERT мәліметті жақсы баптау үшін, жақсарту мүмкін, өйткені mBERT секілді көп тілді алдын- ала оқылған моделдерлері, қайта аударылған және екі тілді деректермен бер', 'ml': 'ഈ പത്രത്തില്\u200d UOB-NLP ടീമിലെ പങ്കെടുക്കുന്നത് പ്രൊഫനെര്\u200d-എസ്റ്റില്\u200d പങ്കെടുത്ത ഉപാധി 7a-ല്\u200d പങ്കുചേര്\u200d The task was aimed at detecting the mention of professions in social media text.  ഞങ്ങളുടെ ടീം മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലുകളുടെ പ്രഭാവം മുന്\u200dകൂട്ടുവാനുള്ള രണ്ട് രീതിയില്\u200d പരീക്ഷിച്ചു. പ്രത്യേകിച്ച്, വിവരങ്ങള്\u200d കൂട്ടിചേര്\u200dക ടെസ്റ്റ് ഡേറ്റായിട്ടുള്ള ഏറ്റവും നല്ല പ്രവര്\u200dത്തിപ്പിക്കുന്ന മോഡല്\u200d മാതൃകയായിരിക്കുമ്പോള്\u200d ബാക്ക്- ടാര്\u200dഷന്\u200d ഉപയോഗിച്ച് കൂട്ടിച്ചേര്\u200dത്ത വിവരങ്ങളില്\u200d എംബെര്\u200dട്ടിന', 'mk': 'Овој весник го опишува учеството на тимот UoB-NLP во заедничката потпрашање 7a на ProfNER-ST. Оваа задача имаше за цел откривање на споменувањето на професиите во текстот на социјалните медиуми. Нашиот тим експериментираше со два методи за подобрување на резултатите на предобучените модели: Специфично, експериментиравме со зголемување на податоците преку превод и спојување на повеќето јазички влози за да ја исполниме целта на задачата. Иако најдобриот модел на тестовите податоци се состои од mBERT фино прилагоден на зголемените податоци користејќи назад-превод, подобрувањето е мало, веројатно бидејќи мултијазичните предобучени модели како mBERT веќе имаат пристап до видот на информации обезбедени преку назад-превод и двојјазични податоци.', 'pl': 'Niniejszy artykuł opisuje udział zespołu UoB-NLP w podzadaniu wspólnym ProfNER-ST 7a. Zadanie miało na celu wykrycie wzmianki o zawodach w tekście mediów społecznościowych. Nasz zespół eksperymentował z dwoma metodami poprawy wydajności wstępnie przeszkolonych modeli: W szczególności eksperymentowaliśmy z powiększaniem danych poprzez tłumaczenie oraz łączeniem wielu wejść językowych, aby osiągnąć cel zadania. Podczas gdy najlepiej wydajny model danych testowych składał się z mBERT dostrojonego na danych rozszerzonych za pomocą tłumaczenia wstecznego, poprawa jest niewielka, prawdopodobnie dlatego, że wielojęzyczne modele wstępnie przeszkolone, takie jak mBERT, mają już dostęp do informacji dostarczanych poprzez tłumaczenie wsteczne i dane dwujęzyczne.', 'mn': 'Энэ цаас профеNER-ST-д хуваалцах дотоод 7a-ын UoB-NLP багийн оролцоог тайлбарладаг. Үүний зорилго нь нийгмийн медиа хэвлэлийн мэргэжлийн хэвлэлийг олох зорилго байсан. Бидний баг дасгал хөгжүүлсэн загварын үйлдлийг сайжруулахын тулд хоёр арга туршилттай туршилт хийсэн. Ялангуяа бид өгөгдлийн нэмэгдүүлэлтэй туршилт хийсэн. Бид олон хэл өгөгдлийн хөгжүүлэлт хийсэн ажлын зорилго олохын тулд Тест өгөгдлийн хамгийн сайн үйлдвэрлэх загвар нь мBERT-ын хувьд хэлэлцээгээр нэмэгдсэн өгөгдлийг ашиглаж байдаг ч, сайжруулах нь бага боломжтой. Учир нь mBERT шиг олон хэлний урд сургалтын загвар аль хэдийнээ back-translation болон хоёр хэлний өгөгдлийн аргаар өгөгдсөн мэд', 'no': 'Denne papiret beskriver deltakaren av UoB-NLP-gruppa i ProfNER-ST delt underspørjing 7a. Oppgåva vart målt å finna minninga av profesjonar i sosiale media-teksten. Gruppen vårt eksperimenterte med to metodar for å forbetra utviklinga av føretrainerte modeller: Spesielt, vi eksperimenterte med data økning gjennom omsetjing og samlinga av fleire språk-inndata for å oppfylle målet på oppgåva. Mens det beste utføringsmodulet på test data best år av mBERT fint opp på augmenterte data ved hjelp av tilbakeomsetjing, er forbetringa mindre sannsynlegvis fordi fleire språksprøvinge modeller som mBERT allereie har tilgang til informasjonen som er gjennom tilbakeomsetjingsdata og bilinguelt data.', 'ro': 'Această lucrare descrie participarea echipei UOB-NLP la subactivitatea comună ProfNER-ST 7a. Sarcina a avut ca scop detectarea menționării profesiilor în textul social media. Echipa noastră a experimentat două metode de îmbunătățire a performanțelor modelelor pre-instruite: În special, am experimentat cu mărirea datelor prin traducere și fuzionarea mai multor intrări lingvistice pentru a îndeplini obiectivul sarcinii. În timp ce modelul cel mai performant privind datele de testare a constat în mBERT reglat fin pe date augmentate utilizând traducerea în spate, îmbunătățirea este minoră, probabil, deoarece modelele preinstruite în mai multe limbi precum mBERT au deja acces la tipul de informații furnizate prin traducerea în spate și datele bilingve.', 'sr': 'Ovaj papir opisuje sudjelovanje UoB-NLP tima u podpitanju ProfNER-ST. Taj zadatak je bio cilj otkrivanja spomena profesija u tekstu društvenih medija. Naš tim je eksperimentirao sa dvije metode poboljšanja provedbe predobučenih modela: Posebno, eksperimentirali smo sa povećanjem podataka kroz prevod i skupljanjem višestrukih jezičkih ulaganja kako bi ispunili cilj zadatka. Iako je najbolji model za provedbu podataka koji se sastoji od mBERT-a koji je napravljen na povećanim podacima korištenjem prevoda nazad, poboljšanje je manje vjerojatno zato što su multijezički predobučeni modeli kao što su mBERT već imali pristup vrsti informacija koje su pružene kroz podaci prevoda i dvojezičkih podataka.', 'si': 'මේ පත්තුව පැහැදිලි කණ්ඩායමේ UoB-NLP කණ්ඩායමේ සම්බන්ධය 7a වලින්. සාමාජික මධ්\u200dයමාධ්\u200dයම පාළුවේ ව්\u200dයාපාරය ගැන පරීක්ෂණය හොයාගන්න ක්\u200dරියාව හොයාගන්න. අපේ කණ්ඩායම ප්\u200dරශ්නයක් දෙකක් තියෙනවා ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන්: විශේෂ විශේෂයෙන්, අපි දත්ත විශ පරීක්ෂණ දත්තේ හොඳම ප්\u200dරමාණය කරනවා නමුත් පරීක්ෂණයේ දත්තේ සඳහා mBERT විශාලනය කරලා තියෙන්නේ පස්සේ පස්සේ පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණ', 'so': 'Warqaddan waxaa ku qoran qayb ka qeybqaadashada kooxda UoB-NLP ee ProfNER-ST lagu qaybiyey subaxda 7a. Shaqada waxaa loogu talogalay in la ogaado magaca xirfadaha ku qoran warqada shabakadda bulshada. Timigayaga ayaa ku baaraandegay laba qaab oo uu ku hagaajiyo sameynta qaababka hore-tababarida: si gaar ah, waxaan ku tijaabiyey kordhinta macluumaadka kordhinta tarjumaadka iyo ururka luuqadaha kala duduwan si aan u gaadhno goalka shaqada. Markii sameynta ugu wanaagsan ee lagu sameynayo macluumaadka imtixaanka waxaa ka mid ah mBERT fine-tuned oo ku qoran macluumaadka lagu kordhiyey isticmaalka dib-turjumista, horumarinta waxaa laga yaabaa in yar, sababtoo ah modellada afka badan oo la tababaray, tusaale ahaan mBERT waxay horay u heli karaan macluumaad cayiman ah oo lagu soo qoray dib-translation iyo labada luqadood.', 'sv': 'Denna uppsats beskriver UOB-NLP-gruppens deltagande i ProfNER-ST delade underuppgift 7a. Syftet med uppgiften var att upptäcka omnämnandet av yrken i sociala medier text. Vårt team experimenterade med två metoder för att förbättra prestandan hos pre-utbildade modeller: Specifikt experimenterade vi med dataförstärkning genom översättning och sammanslagning av flera språkindata för att uppfylla uppgiftens mål. Den bästa modellen för testdata bestod av att mBERT finjusterades på utökade data med hjälp av bakåtöversättning, men förbättringen är liten troligen eftersom flerspråkiga förkunskapsmodeller som mBERT redan har tillgång till den typ av information som tillhandahålls genom bakåtöversättning och tvåspråkig data.', 'ta': 'இந்த தாள் UoB-NLP குழுவின் பகிர்ந்த துணை செயல் 7a யில் பங்கிட்டதை விளக்குகிறது. இந்த செயல் சமூக ஊடக உரையில் தொழில்நுட்பங்களை கண்டுபிடிக்கும் பொருட்களுக்கு எதிராக உள்ளது. எங்கள் குழு முன் பயிற்சி மாதிரிகளின் செயல்பாட்டை மேம்படுத்துவதற்கான இரண்டு முறைகளால் சோதனைக்கப்பட்டுள்ளது: குறிப்பிட்டு, மொழிபெயர்ப்பாட்டில் தரவ While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using back-translation, the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through back-translation and bilingual data.', 'mt': 'This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a.  The task was aimed at detecting the mention of professions in social media text.  It-tim tagħna esperimenta b’żewġ metodi biex itejjeb il-prestazzjoni ta’ mudelli mħarrġa minn qabel: Speċifikament, esperimentajna b’żieda fid-dejta permezz tat-traduzzjoni u l-amalgamazzjoni ta’ inputs multipli tal-lingwa biex jintlaħaq l-għan tal-kompitu. Filwaqt li l-mudell bl-aħjar prestazzjoni tad-dejta tat-test kien jikkonsisti f’mBERT aġġustat finament fuq dejta miżjuda bl-użu ta’ traduzzjoni lura, it-titjib huwa minuri possibbilment minħabba li mudelli multilingwi mBERT imħarrġa minn qabel diġà għandhom aċċess għat-tip ta’ informazzjoni pprovduta permezz ta’ traduzzjoni lura u dejta bilingwi.', 'ur': 'This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a. اس کام کا مطابق سوسیل میڈیا ٹیکسٹ میں پروفس کا ذکر تلاش کرنے کے لئے تھا۔ ہمارے تیم نے دو طریقے سے آزمائش کی کہ پہلے تربین کی موڈل کی عمدگی کو بہتر کرے: ویسے ہی ہے کہ ہم نے ڈاٹ کے افزایش سے آزمائش کی اور بہت سی زبانوں کی اینپوٹ کی جمع کرنا کام کی موضوع کو پورا کرنے کے لئے۔ جبکہ آزمائش ڈاٹوں پر بہترین نمونڈل مBERT کے ذریعہ مزید ترکیب کے مطابق مزید ترکیب دیے گئے ہیں، اس کا بہترین ترکیب بہت کم ہے کیونکہ بہت سی زبان پیش ترکیب دیے گئے نمونڈل جیسے mBERT پہلے سے پشت ترکیب اور دوزبانی ڈاٹوں کے ذریعہ سے پہنچا چکا ہے۔', 'uz': "Bu qogʻoz ProfNER-ST'ning UoB-NLP guruhi 7a bilan bogʻliq vazifaning qismini anglatadi. Bu vazifani social media matnning taʼminotlarini aniqlashga ega bo'ladi. Biz guruhimizning oldingi taʼminlovchi modellarning bajarishni bajarish uchun ikkita usuli bilan imtiyozlashni o'rganadi: Ko'rsatilgan, biz bir necha tillar ichidagi tarjimalarni birlashtirish va vazifaning maqsadini topish uchun bir necha tillar tarjimalarini birlashtirish mumkin. Name", 'vi': 'Tờ giấy này mô tả sự tham gia của nhóm UoS-NLP trong phần mềm của Giáo sư.......ST. Nhiệm vụ là phát hiện tên tuổi tác trong văn bản truyền thông xã hội. Đội của chúng tôi đã thử qua hai phương pháp cải thiện hiệu quả của các mô hình được huấn luyện. Cụ thể, chúng tôi đã thử nghiệm với việc gia tăng dữ liệu bằng cách dịch chuyển và hợp nhất các nội dung ngôn ngữ để đạt được mục tiêu của nhiệm vụ. Trong khi mô hình thành công tốt nhất trên dữ liệu thử nghiệm bao gồm mBERT đã chỉnh chỉnh lại các dữ liệu được tăng trưởng bằng cách dịch lại, nhưng tiến bộ thì nhẹ hơn, có thể vì các mô hình được dạy nhiều ngôn ngữ, như mBERT đã có quyền truy cập vào loại thông tin này thông qua dịch lại và mật.', 'bg': 'Настоящата статия описва участието на екипа на НЛО в подзадача 7а на ПрофНЕР-СТ. Задачата беше насочена към откриване на споменаването на професии в текста на социалните медии. Екипът ни експериментира с два метода за подобряване на производителността на предварително обучени модели: по-конкретно експериментирахме с увеличаване на данните чрез превод и сливане на множество езикови входове, за да постигнем целта на задачата. Макар че най-добре представящият модел на данните от теста се състои от mBERT фина настройка на разширени данни с помощта на обратен превод, подобрението е незначително, вероятно защото многоезичните предварително обучени модели като mBERT вече имат достъп до вида информация, предоставена чрез обратен превод и двуезични данни.', 'hr': 'Ovaj papir opisuje sudjelovanje UoB-NLP tima u podpitanju ProfNER-ST-a. Taj zadatak je bio cilj otkrivanja spomena profesija u tekstu društvenih medija. Naš tim je eksperimentirao sa dvije metode poboljšanja učinka predobučenih modela: Posebno smo eksperimentirali povećanjem podataka kroz prevod i skupljanje višestrukih jezičkih ulaganja kako bi ispunili cilj zadatka. Iako je najbolji provedbeni model na ispitivanjima podacima sastavljen od mBERT-a koji je napravljen na povećanim podacima koristeći povratni prevod, poboljšanje je vjerojatno manje jer multijezički predobučeni modeli poput mBERT već imaju pristup vrsti informacija koje su pružene kroz podaci povratnog prevoda i dvojezičkog podataka.', 'nl': 'Dit artikel beschrijft de deelname van het UoB-NLP team aan de gedeelde deeltaak 7a van ProfNER-ST. De taak was gericht op het opsporen van de vermelding van beroepen in sociale media tekst. Ons team experimenteerde met twee methoden om de prestaties van voorgetrainde modellen te verbeteren: we experimenteerden met data augmentatie door middel van vertaling en het samenvoegen van meerdere taalinvoer om het doel van de taak te bereiken. Hoewel het best presterende model op de testgegevens bestond uit mBERT die verfijnd was op augmented data met behulp van back-translation, is de verbetering gering, mogelijk omdat meertalige voorgetrainde modellen zoals mBERT al toegang hebben tot het soort informatie dat wordt verstrekt door back-translation en tweetalige data.', 'da': 'Denne artikel beskriver UOB-NLP-holdets deltagelse i ProfNER-ST delte underopgave 7a. Opgaven havde til formål at opdage omtale af erhverv i sociale medier tekst. Vores team eksperimenterede med to metoder til forbedring af prætrænede modeller: Vi eksperimenterede specifikt med dataforstørrelse gennem oversættelse og sammenlægning af flere sproginput for at opfylde opgavens mål. Mens den bedst ydende model på testdataene bestod af mBERT finjusteret på forstærkede data ved hjælp af back-translation, er forbedringen muligvis mindre, fordi flersprogede præuddannede modeller som mBERT allerede har adgang til den slags oplysninger, der leveres gennem back-translation og tosprogede data.', 'id': 'Kertas ini menggambarkan pesertaan tim UoB-NLP dalam Subask 7a yang dibagi ProfNER-ST. Tugas itu ditujukan untuk mendeteksi menyebutkan profesi dalam teks media sosial. Tim kami bereksperimen dengan dua metode untuk meningkatkan prestasi model yang dilatih-dilatih: secara khusus, kami bereksperimen dengan peningkatan data melalui terjemahan dan gabungan masukan berbagai bahasa untuk memenuhi tujuan tugas. Sementara model yang paling berhasil pada data ujian terdiri dari mBERT fine-tuned pada data meningkat menggunakan terjemahan belakang, peningkatan mungkin sedikit karena model multi-bahasa pra-dilatih seperti mBERT sudah memiliki akses ke jenis informasi yang diberikan melalui data terjemahan belakang dan dua bahasa.', 'ko': '이 문서에서는 UoB NLP 팀이 ProfNER ST 공유 하위 임무 7a에 참여하는 상황을 설명합니다.이 임무는 소셜 미디어에 언급된 직업을 탐지하는 데 목적을 두고 있다.우리 팀은 두 가지 예비 훈련 모델의 성능을 향상시키는 방법을 시험했다. 구체적으로 말하자면 우리는 번역과 여러 언어의 입력을 통합함으로써 임무 목표의 데이터 강화를 실현하는 것을 시험했다.테스트 데이터에서 가장 잘 표현된 모델은 mBERT로 구성되어 있지만 이 모델은 번역을 사용하여 증강 데이터를 미세하게 조정했지만 이러한 개선은 매우 작을 수 있다. 왜냐하면 mBERT와 같은 여러 언어의 예비 훈련 모델은 번역과 이중 언어 데이터로 제공된 정보를 방문할 수 있기 때문이다.', 'de': 'Dieser Beitrag beschreibt die Beteiligung des UoB-NLP-Teams am ProfNER-ST Shared Subtask 7a. Ziel der Aufgabe war es, die Erwähnung von Berufen in Social Media Texten zu erkennen. Unser Team experimentierte mit zwei Methoden, um die Leistung von vortrainierten Modellen zu verbessern: Konkret experimentierten wir mit der Datenaugmentation durch Übersetzung und dem Zusammenführen mehrerer Spracheingaben, um das Ziel der Aufgabe zu erreichen. Während das leistungsstärkste Modell für die Testdaten aus mBERT bestand, das auf Augmented Data mittels Back-Translation fein abgestimmt wurde, ist die Verbesserung möglicherweise gering, da mehrsprachige vortrainierte Modelle wie mBERT bereits Zugang zu Informationen haben, die durch Rückübersetzung und zweisprachige Daten bereitgestellt werden.', 'fa': 'این کاغذ مشارکت تیم UoB-NLP را توصیف می\u200cکند که در زیر سوال 7a از پروفNER-ST مشترک شده است. این وظیفه هدف گرفته شد که در متن رسانه\u200cهای اجتماعی یادآوری حرفه\u200cای را تشخیص دهد. تیم ما با دو روش آزمایش کردند که عملکرد مدل های پیش آموزش داده شده: به طور خاص، ما با افزایش داده ها با ترجمه کردن و جمع کردن ورودهای متعدد زبان برای انجام هدف این کار آزمایش کردیم. در حالی که بهترین مدل انجام دادن داده\u200cهای آزمایش از داده\u200cهای آزمایش mBERT با استفاده از ترجمه\u200cهای پشتی تحویل داده شده بود، بهترین مدل\u200cهای پیش آموزش چندین زبان، مانند mBERT، قبلاً دسترسی به نوع اطلاعاتی که از طریق ترجمه\u200cهای پشتی و دو زبان داده شده\u200cاند، کمتر است.', 'tr': 'Bu kagyz ProfNER-ST 7-a subt soragynda UoB-NLP toparyň chikanchasyny tassyýar. Bu zada sosial mediýanyň metinde professiýalaryň habaryny tapmaklygy amaçlandy. Biziň toparymyz öňünden bilim beren nusgalaryň etkinleşigini gowlaşdyrmak üçin iki ýoly bilen synanyşdyrdyk: Munuň ýagdaýynda, data üpjürmegi terjime eden we bu işiň maksadyny yerine getirmek üçin birnäçe dil girişi bilen synanyşdyrdyk. Testler maglumatynda iň gowy etjek nusga mBERT yzyna terjime eden maglumatdan ullanýan bolsa, gelişme örän kiçi bir däldir çünki mBERT ýaly multi-dilli öňe eğlenen nusga eýýäm arka terjime we iki dil maglumatdan berilýan maglumatdan erişip bar.', 'sq': 'Ky dokument përshkruan pjesëmarrjen e ekipit UoB-NLP në nënpyetjen e përbashkët të ProfNER-ST 7a. Detyra kishte për qëllim zbulimin e përmendimit të profesioneve në tekstin e medias sociale. Ekipi ynë eksperimentoi me dy metoda për përmirësimin e performancës së modeleve të paratrajnuar: specifikisht, ne eksperimentuam me rritjen e të dhënave nëpërmjet përkthimit dhe bashkimit të të dhënave të shumta gjuhësh për të përmbushur objektivin e detyrës. Ndërsa modeli me rezultate më të mira në të dhënat e testit përbëhej nga mBERT i përshtatur në të dhënat e rritura duke përdorur përkthimin mbrapa, përmirësimi është i vogël ndoshta sepse modelet shumëgjuhësore të paratrajnuar si mBERT tashmë kanë akses në llojin e informacionit të ofruar nëpërmjet përkthimit mbrapa dhe të dhënave dygjuhësore.', 'af': 'Hierdie papier beskrywe die deelnadering van die UoB-NLP-span in die ProfNER-ST deel subvraag 7a. Die taak was doel om die bepaal van professies in sosiale media teks te vind. Ons span het deur twee metodes geeksperimenteer om die prestasie van voorafgevorderde modele te verbeter: Spesifieke, ons het geeksperimenteer met data augmentasie deur vertaling en die samelewing van veelvuldige taal inputs om die doel van die taak te ontmoet. Alhoewel die beste uitvoerde model op die toets data bestaan het van mBERT fyn-tuned op vergroot data gebruik terug-vertaling, is die verbetering minder moontlik omdat multi-tale voor-onderwerp modele soos mBERT reeds toegang tot die soort van inligting verskaf deur terug-vertaling en twee-tale data.', 'sw': 'Gazeti hili linaelezea ushiriki wa timu ya UoB-NLP katika ProfNER-ST ilishirikisha jukumu la 7. Kazi hiyo ilikuwa na lengo la kugundua utambulisho wa shughuli katika maandishi ya mitandao ya kijamii. Timu yetu ilijaribu kwa njia mbili za kuboresha utendaji wa mifano ya awali: Kwa hakika, tulijaribu kuongezeka kwa takwimu kupitia tafsiri na kuunganisha kwa lugha mbalimbali ili kukutana na lengo la kazi hiyo. Wakati mifano bora ya kutengeneza takwimu za jaribio lilijumuisha mBERT yenye ujumbe mzuri kwa kutumia taarifa zilizoongezwa kwa kutumia tafsiri ya nyuma, maboresho ni ndogo kwa sababu mifano ya lugha nyingi zilizojifunza kama vile mBERT tayari ina upatikanaji wa taarifa zinazotolewa kupitia tafsiri za nyuma na data za lugha mbili.', 'hy': 'Այս հոդվածը նկարագրում է UoB-NSP թիմի մասնակցությունը ProfNet-S-ի կիսված 7a ենթահարցում: Այս խնդիրը նպատակով էր հայտնաբերել սոցիալական լրատվամիջոցների տեքստում մասնագիտությունների նշումը: Մեր թիմը փորձարկում էր երկու մեթոդով, որպեսզի բարելավենք նախապատրաստված մոդելների արդյունքը. հատկապես, մենք փորձարկում էինք տվյալների աճի հետ թարգմանման և բազմաթիվ լեզվի ներմուծների միավորման միջոցով, որպեսզի Մինչդեռ փորձարկումների տվյալների լավագույն արդյունավետությունը կազմված էր mBER-ից, որը բարելավված է աճեցված տվյալների վրա, օգտագործելով վերջնական թարգմանություն, զարգացումը, հավանաբար, փոքր է, որովհետև շատ լեզվով նախապատրաստված մոդելները, ինչպիսիք են mBER-ը, արդեն ունեն', 'az': 'Bu kağıt ProfNER-ST-nin 7.a apartsualının UoB-NLP takımının paylaşılmasını təsdiq edir. Bu işin sosyal media mətnlərində profesyonlarının yadına salmaq məqsədilə nişan edildi. Bizim ekibimiz əvvəlcə təhsil edilmiş modellərin performansını yaxşılaşdırmaq üçün iki yolla təcrübə etdi: Özellikle, məlumatların çoxluğu ilə dəyişdirilməsi və işlərin məqsədini yerinə yetirmək üçün çoxlu dil inputlərin birləşdirilməsi üçün təcrübə etdi Sınama verilənlərin ən yaxşı modeli, geri çevirilə yüksək verilən məlumatlardan mBERT ilə müəyyən edilmiş halda, düzəltmə çox az olaraq, çünki mBERT kimi çox dilli öyrənmiş modellər artıq geri çevirilən və ikidilli məlumatlar vasitəsilə verilən məlumatlara erişir.', 'bn': 'এই পত্রিকাটি প্রফেনের-এসটিতে ইউএবি-এনএলপি দলের অংশগ্রহণের বিষয়টি বর্ণনা করেছে যে সাবটাবাজ ৭এ শেয়ার করা হয়ে এই কাজের উদ্দেশ্য হচ্ছে সামাজিক প্রচার মাধ্যমের লেখায় পেশাদের উল্লেখ করা যায়। আমাদের দল পূর্ব প্রশিক্ষিত মডেলের ভার্যকে উন্নত করার দুটি পদ্ধতি দিয়ে পরীক্ষা করেছে: বিশেষ করে আমরা অনুবাদের মাধ্যমে তথ্য যোগ করার পরীক্ষা করেছি এবং কাজের লক্ষ্ While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using back-translation, the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through back-translation and bilingual data.', 'bs': 'Ovaj papir opisuje sudjelovanje UoB-NLP tima u podpitanju ProfNER-ST-a. Taj zadatak je bio cilj otkrivanja spomena profesija u tekstu društvenih medija. Naš tim je eksperimentirao sa dvije metode poboljšanja učinka predobučenih modela: Posebno, eksperimentirali smo sa povećanjem podataka kroz prevod i skupljanjem višestrukih jezičkih ulaganja kako bi ispunili cilj zadatka. Iako je najbolji izvršni model na testovim podacima sastavljen od mBERT-a na povećanim podacima koristeći povratni prevod, poboljšanje je vjerojatno manje jer multijezički predobučeni modeli poput mBERT već imaju pristup vrsti informacija pruženih kroz podaci povratnog prevoda i dvojezičkog podataka.', 'am': 'ይህ ገጽ የUOB-NLP ቡድን በፕሮጀኔር-ST ደብዳቤ 7a የተካፈለ ተግባር ተግባር ይናገራል፡፡ ስራው ማኅበራዊ ሚዲያ ጽሑፎች ውስጥ የባለሞሎችን ማስታወቂያ ማግኘት ነው፡፡ የጦማሪያችን የፊተኛውን ተማሪ ሞዴላዎችን ለማድረግ በሁለት ዓይነት ሞክራችንን ሞክረናል፡፡ በተለይም፣ የዳታ አካባቢ በማድረግ እና የስራውን አቃውሞ ለመገናኘት እና በብዙ ቋንቋዎች የደረጃዎችን ማቀናቀል ፈተናን፡፡ በመፈተናው ዳታ ላይ የተሻለ የድምፅ ሞዴል በመስመር ውስጥ mBERT በተጨማሪው ዳታ በመጠቀም በጥሩ-ትርጉም ላይ የተሰኘ መልካም-tuned ሲሆን፣ ማስጠንቀቂያው ትንሽ ምናልባት ምክንያት MBERT እንደምትሆን በብዙ ቋንቋዎች በፊት-trained ሞዴላዎች በጀርባ-translation እና በሁለት ቋንቋ ዳታ የተሰጠውን መረጃ ማግኘት አግኝቷል፡፡', 'cs': 'Tento článek popisuje účast týmu UoB-NLP na sdíleném podúkolu ProfNER-ST 7a. Úkol byl zaměřen na zjištění zmínek o profesích v textu sociálních médií. Náš tým experimentoval se dvěma metodami zlepšení výkonnosti předškolených modelů: Konkrétně jsme experimentovali s rozšířením dat prostřednictvím překladu a sloučením více jazykových vstupů pro splnění cíle úkolu. Zatímco nejlépe výkonný model testovacích dat byl mBERT vyladěn na rozšířených datech pomocí zpětného překladu, zlepšení je nepatrné, možná proto, že vícejazyčné předškolené modely, jako je mBERT, již mají přístup k informacím poskytovaným prostřednictvím zpětného překladu a dvojjazyčných dat.', 'ca': "Aquest paper descriu la participació de l'equip UoB-NLP en la subpregunta compartida 7a de ProfNER-ST. La tasca va mirar a detectar la menció de professions en el text dels mitjans socials. El nostre equip va experimentar amb dos mètodes de millorar el rendiment de models pré-entrenats: específicament, vam experimentar amb augmentació de dades a través de la traducció i la fusió de múltiples entrades de llenguatge per aconseguir l'objectiu de la tasca. Mentre que el model de millor rendiment de les dades de prova consistia en mBERT ajustad finament en dades augmentates utilitzant traducció posterior, la millora és minor, potser perquè models multillengües pré-entrenats com mBERT ja tenen accés al tipus d'informació proporcionada a través de la traducció posterior i les dades bilingües.", 'et': 'Käesolevas artiklis kirjeldatakse UoB-NLP meeskonna osalemist ProfNER-ST jagatud alaülesandes 7a. Ülesande eesmärk oli tuvastada kutsealade mainimist sotsiaalmeedia tekstis. Meie meeskond eksperimenteeris kahte meetodit eelkoolitud mudelite jõudluse parandamiseks: konkreetselt eksperimenteerisime andmete suurendamist tõlkimise kaudu ja mitme keelelise sisendi ühendamise kaudu, et saavutada ülesande eesmärk. Kuigi kõige paremini tulemuslikum mudel katseandmete puhul koosnes mBERT-ist, mis oli täpsustatud täiendatud andmetele tagantõlke abil, on paranemine väike võimalik, et mitmekeelsetel eelõpetatud mudelitel, nagu mBERT, on juba juurdepääs tagantõlke ja kakskeelsete andmete kaudu edastatavale teabele.', 'fi': 'Tässä artikkelissa kuvataan UoB-NLP-tiimin osallistumista ProfNER-ST:n yhteiseen alatehtävään 7a. Tehtävän tavoitteena oli tunnistaa ammattimaininta sosiaalisen median tekstissä. Tiimimme kokeili kahta menetelmää esikoulutettujen mallien suorituskyvyn parantamiseksi: erityisesti kokeilimme datan lisäämistä kääntämällä ja yhdistämällä useita kielisyötteitä tehtävän tavoitteen saavuttamiseksi. Parhaiten suoriutuva malli testiaineistossa koostui lisättyyn dataan tarkennetusta mBERT-järjestelmästä jälkikäännöksen avulla, mutta parannus on vähäinen mahdollisesti siksi, että monikielisillä esikoulutetuilla malleilla, kuten mBERT-mallilla, on jo pääsy jälkikäännöksen ja kaksikielisen datan kautta saatavaan tietoon.', 'sk': 'V prispevku je opisano sodelovanje ekipe UoB-NLP v skupni podnalogi ProfNER-ST 7a. Naloga je bila namenjena odkrivanju omenjanja poklicev v besedilu družbenih medijev. Naša ekipa je eksperimentirala z dvema metodama za izboljšanje učinkovitosti predhodno usposobljenih modelov: posebej smo eksperimentirali s povečanjem podatkov s prevajanjem in združevanjem več jezikovnih vnosov, da bi dosegli cilj naloge. Medtem ko je bil najbolje uspešen model na podlagi preskusnih podatkov natančno prilagojen mBERT na povečane podatke z uporabo nazaj prevajanja, je izboljšanje majhno, ker imajo večjezični predhodno usposobljeni modeli, kot je mBERT, že dostop do vrste informacij, zagotovljenih prek nazaj prevajanja in dvojezičnih podatkov.', 'he': 'This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a.  The task was aimed at detecting the mention of professions in social media text.  הצוות שלנו ניסה עם שתי שיטות לשפר את ההפעלה של דוגמנים מאומנים מראש: במיוחד ניסינו עם גידול נתונים דרך התרגום ומיזוג של תוכניות שפות רבות כדי להשיג את המטרה של המשימה. למרות שהמודל המפעיל ביותר בנתונים המבחנים כולל mBERT מעודף על נתונים מגדלים באמצעות התרגום מאחור, השיפור הוא קטן, אולי בגלל מודלים רבים שפות מאומנים מראש כמו mBERT כבר יש גישה לסוג המידע שנוסף דרך נתונים מאחור ותרגום שתיים שפות.', 'ha': "Wannan takardan na bayyana shirin jumuin UoB-NLP cikin the profNER-St da aka share sub-aikin 7a. Kayan aiki na aimar a gane su sunan aikin da ke cikin matsayin mitandaki na jamii. Team na jarraba su da hanyoyin biyu biyu wajen improve performance of misãlai masu tsari a gabãni: Akwai na ƙayyade, za'a jarraba ƙaramako da data a bayan fassarar turjuya da kuma ta haɗa masu cikin harshen dabam-dabam dõmin a haɗe abun aikin. Waka da mafi kyaun gyarata a kan data na jarraba ta ƙunsa da mBERT-tuned fin-tuned a kan data da aka yi amfani da baka-translation, mai gyare yana kasa ƙaranci, ko kuwa misãlai masu yin amfani da mulki-linguin zaman-tsari kamar mBERT ya riga ya sami tsari ga nau'in information wanda aka bãyar da bayan-translation da data na lugha biyu.", 'bo': 'ཤོག་བྱང་འདིས་ProfNER-ST མཉམ་དུ་སྤྱི་ཚོགས་ཀྱི་རྒྱབ་སྐྱོར་7a་ནང་གི་UoB-NLP མིའི་མཉམ་དུ་འགྲེལ་བཤད་ཀྱི་ཡོད། བྱ་འགུལ་འདི་ལ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཡིག་གི་ནང་གི་ལས་འགན་གྱི་གཏམ་བཤད་རྟོགས་བྱེད་རྒྱུ་དང་། ང་ཚོའི་མི་དབར་གྱི་ཐབས་ལམ་གཉིས་ཀྱིས་སྔོན་གྲངས་བསྒྲིག་པའི་མིག་གཟུགས་རིས་ལ་ཡར་རྒྱས་གཏོང་བ་དང་། ཁྱད་པར་ན་ང་ཚོས་གནས་ཚུལ While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using back-translation, the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through back-translation and bilingual data.', 'jv': 'Pesene iki rambarang nggawe karo nganggo sing UOB-NLP ning acara Profile-RT didasai basa 7 a . Sampeyan iki lak ono nggoleki ngerasakno kanggo ngerasakno piro perusahaan ning teks media sotiki. Awak dhéwé éntuk éntuk karo sistem sing gawe perusahaan nggawe model sing bisa cara-cara sing bisa supoyatan: Genjer sampeyan sing paling nggambar model nang data test sing ditambah mBERT kang dadi sing apik batar nggambar, dadi sing perusahaan mulai ke terjamahan, supaya kang kelangan lak dhéwé kuwi model sing sampeyan multi-lenguang tapi, akhar mBERT iso diandelak akses karo informasi sing dadi nyong terjamahan karo ibut-terjamahan karo ibut-ingkang.'}
{'en': 'PAII-NLP at SMM4H 2021 : Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets PAII - NLP  at  SMM 4 H  2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'ar': 'PAII-NLP في SMM4H 2021: الاستخراج المشترك وتطبيع الإشارات إلى تأثيرات العقاقير الضارة في التغريدات', 'pt': 'PAII-NLP no SMM4H 2021: Extração conjunta e normalização de menções de efeitos adversos de medicamentos em tweets', 'es': 'PAII-NLP en SMM4H 2021: extracción conjunta y normalización de menciones de efectos adversos de medicamentos en tuits', 'fr': "PAII-NLP au SMM4H 2021\xa0: Extraction conjointe et normalisation des mentions d'effets indésirables des médicaments dans les tweets", 'ja': 'SMM 4 H 2021におけるPAII - NLP ：ツイートにおける有害薬物効果の関節抽出と正常化', 'ru': 'PAII-NLP на SMM4H 2021: Совместное извлечение и нормализация упоминаний о неблагоприятном воздействии препарата в твитах', 'hi': 'SMM4H 2021 में PAII-NLP: ट्वीट्स में प्रतिकूल दवा प्रभाव का संयुक्त निष्कर्षण और सामान्यीकरण उल्लेख', 'zh': 'SMM4H 2021上PAII-NLP:推文中药物不良反应合提正常化', 'ga': 'PAII-NLP ag SMM4H 2021: Comh-eastóscadh agus Normalú ar Éifeacht Dhíobhálach Drugaí a luaitear in Tweets', 'ka': 'PAII-NLP SMM4H 2021-ში: ერთადერთი ექსტრაქცია და ნორმალიზაცია სამუშაო ექსტრექტის მენოციების შესახებ Tweets-ში', 'hu': 'PAII-NLP az SMM4H 2021-en: A káros gyógyszerhatások említéseinek közös extrakciója és normalizálása tweetekben', 'el': 'ΠΑΙΙ-ΝΛΠ στο SMM4H 2021: Κοινή εξαγωγή και κανονικοποίηση αναφορών ανεπιθύμητης επίδρασης φαρμάκων στα tweets', 'it': 'PAII-NLP a SMM4H 2021: Estrazione congiunta e normalizzazione delle menzioni sugli effetti avversi dei farmaci nei tweet', 'kk': 'PAII- NLP SMM4H 2021: Твиттерде қарсы наркотикалық эффекттер мәзірлерін тарқату мен нормализациялау', 'mk': 'PAII-NLP на SMM4H 2021: Заедничка екстракција и нормализација на спомените за негативни ефекти на дрогата на Твитови', 'lt': 'PAII-NLP SMM4H 2021 m.: Bendras nepageidaujamo narkotikų poveikio paminėjimų ekstrahavimas ir normalizavimas Tweetuose', 'ms': 'PAII-NLP di SMM4H 2021: Ekstraksi Berkongsi dan Normalisasi Menanggil Kesan Ubat Alamat dalam Tweet', 'ml': 'SMM4H 2021-ല്\u200d പാള്\u200d- NLP: ടൂട്ടുകളില്\u200d കൂട്ടിചേര്\u200dക്കുക', 'mn': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'no': 'PAII-NLP på SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'mt': 'PAII-NLP fl-SMM4H 2021: Estrazzjoni Konġunta u Normalizzazzjoni ta’ Menzjonijiet dwar l-Effetti Avversi tal-Mediċina fit-Tweets', 'sr': 'PAII-NLP na SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'pl': 'PAII-NLP na SMM4H 2021: Ekstrakcja i normalizacja wspomnień o niepożądanym działaniu leków w tweetach', 'ro': 'PAII-NLP la SMM4H 2021: Extracția comună și normalizarea mențiunilor efectelor adverse ale medicamentelor în Tweets', 'si': 'PAII-NLP at SMM4H 2021: JOINT Extraction and Normallization of Aveerse Drug Effect Ments in Tweets', 'sv': 'PAII-NLP vid SMM4H 2021: Gemensam extraktion och normalisering av negativa läkemedelseffekter omnämningar i tweets', 'so': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'ta': 'SMM4H 2021-ல் PAII- NLP: முன்னோட்டு மருந்து விளைவுகள் பட்டியல்', 'ur': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'uz': 'Name', 'vi': 'PAII-NLP tại SMR4H 2021: Phát tán và hoá chỉnh các hiệu ứng phản ứng phản ứng phụ trong Tweet', 'bg': 'ПАИЛ-НЛП на СММ4Х 2021: Съвместно извличане и нормализиране на споменаването на нежелани лекарствени ефекти в туитове', 'hr': 'PAII-NLP na SMM4H 2021: zajednička izvlačenja i normalizacija pamćenja nuspojavnih učinka droge u Tweets-u', 'nl': 'PAII-NLP op SMM4H 2021: Gezamenlijke Extractie en Normalisatie van Vermeldingen over Bijwerkend Drug Effect in Tweets', 'da': 'PAII-NLP på SMM4H 2021: Fælles ekstraktion og normalisering af bivirkninger af lægemidler i tweets', 'de': 'PAII-NLP bei SMM4H 2021: Gemeinsame Extraktion und Normalisierung von Nebenwirkungen in Tweets', 'ko': 'SMM4H 2021의 PAII-NLP: 트윗에서 언급한 약물 불량 반응의 공동 추출과 표준화', 'id': 'PAII-NLP di SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'fa': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effects in Tweets', 'sw': 'PAII-NLP kwenye SMM4H 2021: Kutoa pamoja na Uwekezaji wa Tamko za Utawala wa Utawala katika Twita', 'am': 'በSM4H 2021: Joint Extraction and Normalization of Adverse Drug Effects Mentions in Tweets', 'tr': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'af': 'PAII-NLP by SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'az': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'hy': '2021 թվականին SMM4H-ում պայմանավորված պայմանավորվածություն է, որը նշանակում է, որ թվիթերում գտնվող թմրանյութերի անհաջորդ էֆեկտի նշանները միասին վերացնում և նորմալիզացվում են', 'bs': 'PAII-NLP na SMM4H 2021: zajednička izvlačenja i normalizacija pamćenja nuspojavnih učinka droge u Tweets-u', 'sq': 'PAII-NLP në SMM4H 2021: Zgjidhja e përbashkët dhe normalizimi i përmendimeve të efektit të keq të drogës në Tweets', 'bn': 'SMM4H ২০২১-এ প্যাল-এনএলপি: টুইটারে যুক্ত করা এবং স্বাভাবিক মাদক প্রভাবের মেনুষগুলোর সাথে যুক্ত করা', 'ca': "PAII-NLP a SMM4H 2021: Extracció conjunta i normalització de les mencions d'efecte advers de medicaments en tweets", 'cs': 'PAII-NLP na SMM4H 2021: Společná extrakce a normalizace zmínek o nežádoucích léčivých účincích ve tweetech', 'et': 'PAII-NLP SMM4H 2021: Kõrvaltoime märkuste liigesekstraheerimine ja normaliseerimine tweetides', 'fi': 'PAII-NLP SMM4H 2021: Haittavaikutusten mainintojen yhteisuuttaminen ja normalisointi twieteissä', 'jv': 'PAll-NLP at SMM4H 2020 1: Joint extract and Normalialization of Advrse Drog Effect Mentions in Two', 'sk': 'PAII-NLP na SMM4H 2021: Sklepna ekstrakcija in normalizacija omenitev škodljivih učinkov zdravil v tweetih', 'he': 'PAII-NLP ב SMM4H 2021: Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'bo': 'PAII-NLP at SMM4H 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets', 'ha': 'PAII-NLP at SMM4H 2021: Join Extraction and Natmalization of Adverse Murug Effects Menions in Twitter'}
{'en': 'This paper describes our system developed for the subtask 1c of the sixth Social Media Mining for Health Applications (SMM4H) shared task in 2021. The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs. Our system is based on a neural transition-based joint model, which is to perform  recognition  and  normalization  simultaneously. Our final two submissions outperform the average F1 score by 1-2 %.', 'fr': "Cet article décrit notre système développé pour la sous-tâche 1c de la sixième tâche partagée Social Media Mining for Health Applications (SMM4H) en 2021. L'objectif de la sous-tâche est de reconnaître les mentions d'effet indésirable du médicament (ADE) dans les tweets et de normaliser les mentions identifiées avec leurs identifiants de termes préférés MedDRA. Notre système est basé sur un modèle d'articulation basé sur la transition neuronale, qui consiste à effectuer simultanément la reconnaissance et la normalisation. Nos deux dernières soumissions surpassent le score moyen de F1 de 1 à 2\xa0%.", 'pt': 'Este artigo descreve nosso sistema desenvolvido para a subtarefa 1c da sexta tarefa compartilhada Social Media Mining for Health Applications (SMM4H) em 2021. O objetivo da subtarefa é reconhecer as menções de efeitos adversos de medicamentos (ADE) de tweets e normalizar as menções identificadas aos seus IDs de termo preferidos do MedDRA de mapeamento. Nosso sistema é baseado em um modelo conjunto baseado em transição neural, que é realizar o reconhecimento e a normalização simultaneamente. Nossas duas submissões finais superam a pontuação média da F1 em 1-2%.', 'ar': 'تصف هذه الورقة نظامنا الذي تم تطويره للمهمة الفرعية 1 ج للمهمة المشتركة السادسة لتعدين الوسائط الاجتماعية للتطبيقات الصحية (SMM4H) في عام 2021. والهدف من المهمة الفرعية هو التعرف على تأثير الدواء الضار (ADE) الذي يذكر من التغريدات وتطبيع الإشارات المحددة لتعيين معرفات مصطلح MedDRA المفضل. يعتمد نظامنا على نموذج مشترك قائم على الانتقال العصبي ، والذي يقوم بالتعرف والتطبيع في وقت واحد. تفوق التقديمان الأخيران لدينا على متوسط درجة F1 بنسبة 1-2٪.', 'es': 'Este documento describe nuestro sistema desarrollado para la subtarea 1c de la sexta tarea compartida de Social Media Mining for Health Applications (SMM4H) en 2021. El objetivo de la subtarea es reconocer las menciones del efecto adverso de los medicamentos (ADE) de los tuits y normalizar las menciones identificadas para mapear los ID de los términos preferidos de MedDRA. Nuestro sistema se basa en un modelo de articulación basado en la transición neuronal, que consiste en realizar el reconocimiento y la normalización simultáneamente. Nuestras dos últimas presentaciones superan la puntuación media de F1 en un 1-2%.', 'ja': '本稿では、2021年の第6のソーシャルメディアマイニングフォーヘルスアプリケーション（ SMM 4 H ）共有タスクのサブタスク1 cのために開発されたシステムについて説明します。サブタスクの目的は、ツイートからの有害薬物効果（ ADE ）の言及を認識し、同定された言及をそれらのMedDRAの好ましい用語IDのマッピングに正規化することです。私たちのシステムは、認識と正規化を同時に行うニューラル・トランジション・ベースのジョイント・モデルに基づいています。F 1の平均スコアを1 ～ 2 ％上回る成績を残しました。', 'zh': '本文引我为2021年第六健社交媒体掘(SMM4H)共享子务1c开发之统。 子职者,识推文之药不良反应(ADE)及已识之规范化为映射MedDRA首选术语ID。 统者,神之关节也,将以同时而知归一化。 最后两交,比F1之均得分出于1-2%。', 'hi': 'यह पेपर 2021 में स्वास्थ्य अनुप्रयोगों (SMM4H) साझा कार्य के लिए छठे सोशल मीडिया माइनिंग के उप-कार्य के लिए विकसित हमारे सिस्टम का वर्णन करता है। Subtask का उद्देश्य tweets से उल्लिखित प्रतिकूल दवा प्रभाव (एडीई) को पहचानना और उनके मानचित्रण MedDRA पसंदीदा शब्द आईडी के लिए पहचाने गए उल्लेखों को सामान्य करना है। हमारा सिस्टम एक तंत्रिका संक्रमण-आधारित संयुक्त मॉडल पर आधारित है, जो एक साथ मान्यता और सामान्यीकरण करना है। हमारे अंतिम दो सबमिशन औसत F1 स्कोर को 1-2% से बेहतर बनाते हैं।', 'ru': 'В этой статье описывается наша система, разработанная для подзадачи 1c шестой совместной задачи «Майнинг социальных сетей для приложений здравоохранения» (SMM4H) в 2021 году. Целью подзадачи является распознавание упоминаний о нежелательном действии лекарственного препарата (ADE) из твитов и нормализация идентифицированных упоминаний в соответствии с их идентификаторами предпочтительных терминов MedDRA. Наша система основана на нейронной модели суставов на основе переходного процесса, которая заключается в одновременном выполнении распознавания и нормализации. Наши последние две заявки опережают средний балл F1 на 1-2%.', 'ga': 'Déanann an páipéar seo cur síos ar ár gcóras a forbraíodh don fhothasc 1c den séú tasc comhroinnte um Mhianadóireacht Meáin Shóisialta le haghaidh Feidhmchláir Sláinte (SMM4H) in 2021. Is é aidhm an fhothasc ná an éifeacht dhochrach drugaí (ADE) a luaitear ó thíteanna a aithint agus na tagairtí aitheanta a normalú. chuig a n-aitheantais téarma tosaíochta MedDRA mapála. Tá ár gcóras bunaithe ar chomhshamhail néar-bhunaithe trasdultach, is é sin aithint agus normalú a dhéanamh go comhuaineach. Sáraíonn an dá aighneacht deiridh an meánscór F1 1-2%.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημά μας που αναπτύχθηκε για το δευτερεύον έργο 1γ της έκτης κοινής εργασίας εξόρυξης κοινωνικών μέσων για εφαρμογές υγείας (το 2021). Ο στόχος της υποταγής είναι να αναγνωρίσει τις αναφορές για την ανεπιθύμητη δράση φαρμάκων (ADE) από τα tweets και να ομαλοποιήσει τις προσδιορισμένες αναφορές στην χαρτογράφηση των προτιμώμενων όρων τους. Το σύστημά μας βασίζεται σε ένα μοντέλο αρθρώσεων που βασίζεται στη νευρική μετάβαση, το οποίο είναι να εκτελεί την αναγνώριση και την ομαλοποίηση ταυτόχρονα. Οι τελευταίες δύο αιτήσεις μας ξεπερνούν το μέσο σκορ F1 κατά 1-2%.', 'hu': 'Ez a tanulmány ismerteti a 2021-es hatodik közösségi média bányászati alkalmazásokért (SMM4H) megosztott feladat 1c részfeladatához fejlesztett rendszerünket. A részfeladat célja, hogy felismerje a tweetekből származó mellékhatásokat (ADE) és normalizálja az azonosított említéseket a MedDRA preferált kifejezés azonosítóira. Rendszerünk egy neurális átmeneti alapú ízületi modellre épül, amelynek célja a felismerés és normalizálás egyidejűleg történő végrehajtása. Az utolsó két beadványunk 1-2%-kal felülmúlja az F1 átlagos pontszámot.', 'it': "Questo articolo descrive il nostro sistema sviluppato per la sottomissione 1c del sesto compito condiviso Social Media Mining for Health Applications (SMM4H) nel 2021. Lo scopo del sottotask è quello di riconoscere le menzioni degli effetti avversi del farmaco (ADE) da tweet e normalizzare le menzioni identificate ai loro ID di riferimento MedDRA. Il nostro sistema si basa su un modello articolare basato sulla transizione neurale, che è quello di eseguire il riconoscimento e la normalizzazione contemporaneamente. Le nostre ultime due proposte superano il punteggio medio F1 dell'1-2%.", 'kk': 'Бұл қағаз 2021 жылы ортақ тапсырманың алтыншы социалдық медиа бағалау қолданбаларының (SMM4H) 1c- сының ішкі сұрауына жасалған жүйемізді таңдайды. Ішкі сұраныстың мақсаты - таңдау үшін қарсы наркотикалық эффектін (ADE) таңдау және олардың келтірілген мәліметтерін MedDRA картасына қалаған термин идентификаторларына кәдімгілеу. Біздің жүйеміз невралдық ауыстыру негізінде біріктіру мен нормализациялау үлгісіне негізделген. Біздің соңғы екі жіберіміз орташа F1 нәтижесін 1-2% деп аталады.', 'lt': 'Šiame dokumente aprašoma mūsų sistema, sukurta 2021 m. pagal šeštą socialinės žiniasklaidos kasybos programų sveikatos srityje (SMM4H) užduoties 1c papunktį. Subpaklausos tikslas – atpažinti nepageidaujamą vaisto poveikį (ADE), paminėtą tweetuose, ir normalizuoti nustatytus paminėjimus, nurodytus pagal MedDRA rekomenduojamą terminą. Mūsų sistema grindžiama jungtiniu modeliu, pagrįstu neurologiniu pereinamuoju laikotarpiu, kuris yra vienu metu atliekamas pripažinimas ir normalizacija. Our final two submissions outperform the average F1 score by 1-2%.', 'mk': 'Овој весник го опишува нашиот систем развиен за подпрашањето 1c од шестата Социјална медиумска минирање за здравствени апликации (SMM4H) заедничка задача во 2021 година. Целта на подпрашањето е да се препознае негативниот ефект на лековите (АДЕ) споменува од твитовите и да се нормализира идентификуваната спомена на нивното мапирање на преферираниот термин ИД на MedDRA. Нашиот систем е базиран на заеднички модел базиран на нервна транзиција, кој е да изврши признавање и нормализација истовремено. Нашите последни две поднесувања го надминуваат просечниот резултат на F1 за 1-2 отсто.', 'ms': 'Kertas ini menggambarkan sistem kami yang dikembangkan untuk subtanya 1c dari Media Sosial Keenam Perlombongan untuk Aplikasi Kesehatan (SMM4H) berkongsi tugas pada tahun 2021. Tujuan sub-tanya adalah untuk mengenali kesan dadah (ADE) disebut dari tweet dan normalisasi sebutan yang dikenalpasti kepada peta mereka ID terma yang disukai MedDRA. Sistem kita berdasarkan model kongsi berasaskan transisi saraf, yang adalah untuk melakukan pengenalan dan normalisasi secara bersamaan. Dua penerimaan terakhir kita melebihi nilai F1 rata-rata dengan 1-2%.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ സിസ്റ്റത്തെ വിവരിച്ചുകൊണ്ടിരിക്കുന്നത് നമ്മുടെ ആറാമത്തെ സോഷ്യല്\u200d മീഡിയയുടെ ആദ്യത്തെ സാമൂഹ്യ മിനിങ തുടര്\u200dച്ചയില്\u200d നിന്നുള്ള വിരോധമായ മയക്കുമരുന്ന് പ്രഭാവങ്ങള്\u200d തിരിച്ചറിയാനും തിരിച്ചറിയപ്പെട്ട പ്രഖ്യാപങ്ങള്\u200d അവരുടെ മെഡ്ഡിRA ഇ നമ്മുടെ സിസ്റ്റത്തിന്റെ സംവിധാനത്തിന്റെ അടിസ്ഥാനത്താണ് ന്യൂറല്\u200d മാറ്റങ്ങള്\u200d അടിസ്ഥാനമായിരിക്കുന്നത്. അത് ഒരേ  നമ്മുടെ അവസാനത്തെ രണ്ടു കീഴ്പ്പെടുത്തിയ രണ്ടുപേര്\u200d എഫ്\u200c1 സ്കോര്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. 1-2', 'mt': 'Dan id-dokument jiddeskrivi s-sistema tagħna żviluppata għas-sotto-mistoqsija 1c tas-sitt ħidma kondiviża tal-Minjieri tal-Midja Soċjali għall-Applikazzjonijiet tas-Saħħa (SMM4H) fl-2021. L-għan tas-sottotalba huwa li jiġi rikonoxxut l-effett avvers tal-mediċina (ADE) li jsemmi minn tweets u li jiġu normalizzati s-sejħiet identifikati għall-immappjar tagħhom tal-ID tat-terminu ppreferut MedDRA. Is-sistema tagħna hija bbażata fuq mudell konġunt ibbażat fuq tranżizzjoni newrali, li għandu jwettaq rikonoxximent u normalizzazzjoni fl-istess ħin. Iż-żewġ sottomissjonijiet finali tagħna jaqbżu l-punteġġ medju F1 b’1-2%.', 'pl': 'Niniejszy artykuł opisuje nasz system opracowany dla podzadania 1c szóstego wspólnego zadania Mining for Health Applications (SMM4H) w latach 2021. Celem podzadania jest rozpoznanie wzmianek o działaniu niepożądanym leku (ADE) z tweetów i normalizacja zidentyfikowanych wzmianek do ich mapowania preferowanych terminów MedDRA. Nasz system opiera się na modelu stawu opartego na przejściu neuronowym, który ma jednocześnie wykonywać rozpoznawanie i normalizację. Nasze ostatnie dwa zgłoszenia przewyższają średni wynik F1 o 1-2%.', 'ro': 'Această lucrare descrie sistemul nostru dezvoltat pentru subsarcina 1c a celei de-a șasea sarcini partajate Social Media Mining for Health Applications (SMM4H) în 2021. Scopul subactivității este de a recunoaște mențiunile referitoare la efectul advers al medicamentului (ADE) din tweet-uri și de a normaliza mențiunile identificate la ID-urile cu termen preferat MedDRA. Sistemul nostru se bazează pe un model comun bazat pe tranziție neurală, care este de a efectua recunoașterea și normalizarea simultan. Ultimele două depuneri depășesc scorul mediu F1 cu 1-2%.', 'ka': 'ამ დოკუმენტი ჩვენი სისტემის განვითარებულია 2021 წლის შვიდი სოციალური მედიახის მიღებაზე (SMM4H) საზოგადოებული სამუშაო სამუშაო სამუშაო მომხმა სტკითხვის მისამართი არის დააცნობა განსაზღვრებული ნაპექტის ეფექტის (ADE) განსაზღვრება და ნორმალიზება განსაზღვრებული განსაზღვრებულებების მისამართების მისამართებით MedDRA მონიშნული ტემინ ჩვენი სისტემა ნეიროლური გადაწყვეტილების ერთადერთი მოდელზე ბაზიან, რომელიც ერთადერთად განაცნობა და ნორმალიზაცია. ჩვენი საბოლოო ორი წინასწარმოდგენება უფრო გავაკეთებთ განსხვავებული F1 წინასწარმოდგენება 1-2%.', 'no': 'Denne papiret beskriver systemet vårt utviklet for underspørjinga 1c av den seste sosiale mediene-mining for helseprogramma (SMM4H) delte oppgåva i 2021. Målet på underspørjinga er å gjenkjenna den nedanlege narkotikaffekten (ADE) som mener frå tweet og normalisera dei identifiserte oppgjevnadene til kartlegginga av MedDRA-prefererte uttrykk ID-ar. Sistemet vårt er basert på eit neuralovergang-basert joint model, som er å utføra gjenkjenning og normalisering samtidig. Våre siste to oppføringar utfører gjennomsnittlig F1- poeng med 1 - 2 %.', 'so': 'Kanu wuxuu ku qoran karaa nidaamkan u horumariyey sub-qasnada 1c ee lixda macluumaadka sooshalka ee daryeelka caafimaadka (SMM4H) shaqada loo qaybiyey 2021. Ujeedada shabakaddu waa in la aqoonsado saamaynta dawooyinka caadiga ah (ADE) ee looga soo jeedo Twitteetka iyo si caadi ah looga dhigo macluumaadka la aqoonsaday ee sawirkooda lagu qoray MedDRA oo la doortay macluumaadka aqoonsan. nidaamkayagu wuxuu ku saleysan yahay model wadajir ah oo ku saleysan dabeecada neurada, kaas oo ah in la sameeyo aqoonsashada iyo la caadi ahaan. Labadayada ugu dambaysta ah waxay bixisaa qiimaha F1 qiimaha ugu dhexeeya 1-2 boqolkiiba.', 'sv': 'Denna uppsats beskriver vårt system utvecklat för underuppgiften 1c i den sjätte delade uppgiften Social Media Mining for Health Applications (SMM4H) 2021. Syftet med underuppgiften är att känna igen adverse drug effect (ADE) omnämnanden från tweets och normalisera de identifierade omnämnandena till deras kartläggning MedDRA föredragna term ID. Vårt system bygger på en neural övergångsbaserad ledmodell, som är att utföra igenkänning och normalisering samtidigt. Våra sista två bidrag överträffar den genomsnittliga F1-poängen med 1-2%.', 'mn': 'Энэ цаас 2021 онд бидний системийг 6-р нийгмийн Media Mining for Health Applications (SMM4H) холбоотой ажлын 1.c-ын дотоод асуултыг тайлбарладаг. Хамгийн гол асуултын зорилго нь тэдний төлөвлөгөө MedDRA-ын төлөвлөгөөний нэртэй эм нөлөөг (ADE) тодорхойлох ба тэдний төлөвлөгөөний нэртэй нэртэй нэртэй нэртэй нэр тодорхойлох юм. Бидний систем мэдрэлийн шилжилт дээр нийлбэр загвар дээр суурилсан. Энэ нь одоогоор хүлээн зөвшөөрөх болон нормализацийг хийх юм. Бидний сүүлийн хоёр давталт нь дундаж F1 оноо нь 1-2%.', 'si': 'මේ පැත්තේ අපේ පද්ධතිය ප්\u200dරවේශනය කරනවා 2021 දී සාමාජික මිඩියාව විශ්වාසයෙන් විශ්වාසය කරලා තියෙන්නේ. සබ්ප්\u200dරශ්නයේ ඉලක්කය තමයි විරෝද්ධ ව්\u200dයාප්\u200dරශ්නය (ADE) ට්විට් වලින් කියන විරෝද්ධ ව්\u200dයාප්\u200dරශ්නයක් අඳුරන්න සහ ඔවුන් අපේ පද්ධතිය සාමාන්\u200dය වෙනුවෙන් සාමාන්\u200dය වෙනුවෙන් සාමාන්\u200dය වෙනුවෙන් අධාරණය කරනවා, ඒක තමයි සාමාන්\u200dය විද අපේ අන්තිම පිළිගන්න දෙකක් සාමාන්\u200dය F1 ප්\u200dරමාණය 1-2% විතරයි.', 'sr': 'Ovaj papir opisuje naš sistem razvijen za podpitanje 1c od šestog socijalnog medijskog rudarstva za zdravlje aplikacije (SMM4H) zajedničkog zadatka 2021. godine. Cilj podpitanja je prepoznati nužni efekt lijeka (ADE) koji se spominje iz tweeta i normalizirati identifikovane spomena svojim mapiranjem predviđenim terminovima identifikacije MedDRA-e. Naš sistem je zasnovan na zajedničkom modelu na neuralnoj transiciji, koji je da istovremeno izvedemo priznanje i normalizaciju. Naša poslednja dva podnošenja iznosi prosječni rezultat F1 za 1-2%.', 'ta': 'இந்த தாள் எங்கள் கணினியை உருவாக்கிய துணை பணிக்காக விளக்குகிறது 2021-ல் ஆறு சமூக ஊடகங்களின் சார்பு பயன்பாடுகளுக்கான சார்பு நினை இந்த துணை பணியின் இலக்கு தான் இருந்து குறிப்புகளை குறிப்பிட வேண்டும் மற்றும் குறிப்பிட்ட குறிப்புகளை வரைபடத்தில் மேட்டிரா விர எங்கள் அமைப்பு ஒரு புதிய மாற்றம் சார்ந்த இணைய மாதிரியை அடிப்படையாக இருக்கிறது, அது ஒரே நேரத்தில் அடிப்படையாக அடிப்படைய எங்கள் இறுதியில் இரண்டு சரணங்கள் சராசரி F1 மதிப்பெண்கள் 1-2%.', 'ur': 'This paper describes our system developed for the subtask 1c of the sixth Social Media Mining for Health Applications (SMM4H) shared task in 2021. Subask کے مطابق یہ ہے کہ ٹیوٹ سے مخالف داروغ اثر (ADE) کو پہچان لیں اور ان کے مکاپینگ میں پہچان ہوئے مطابق کے مطابق پہچان لیں۔ ہمارا سیستم ایک نئورل تغییر پر بنیاد ہے جو ایک جولنٹ موڈل پر ہے جو ایک دفعہ پہچان اور عامل کرنا ہے ہماری آخری دو مسلمانوں نے متوسط F1 اسکو 1-2%.', 'uz': "Bu sahifa 2021 yilda shifoy dasturlari (SMM4H) bo'lgan sakkiz jamiyat medya (SMM4H) vazifasini yaratish uchun birinchi marta ishlatilgan tizimmizni anglatadi. Ushbu vazifaning maqsadi Twitterdan tashqi narsalar (ADE) qoidalarini aniqlash va aniqlangan narsalarning MedDRA yaxhshi suhbat ID'lariga qoʻllash mumkin. Bizning tizimmiz neyrolik tarkibi bir bir bir bir bir modelga asosida, bu bir xil paytida tasdiqlash va oddiylikni bajarish mumkin. Bizning oxirgi ikkita imkoniyatlarni 1-2%'ga o'rtacha F1'ning o'rtacha foydalanadi.", 'vi': 'Tờ giấy này mô tả hệ thống của chúng tôi được phát triển cho kỹ thuật yêu cầu X. của bộ phận Tư liệu Xã hội thứ sáu về ngành sức khỏe (SMR4H) chia sẻ nhiệm vụ ở 2021. Mục đích của màn hình phụ đề là nhận diện hiệu ứng tiêu cực (ADE) được nhắc đến từ tweet và làm bình thường các đề cập xác định được xác định với danh sách mà MedDracula yêu cầu. Hệ thống của chúng ta dựa trên một mô hình liên kết dựa trên sóng thần kinh, đó là tiến hành nhận thức và bình thường cùng lúc. Lần cuối của chúng tôi hoàn thành điểm F1 với 1-2 Name', 'bg': 'Настоящата статия описва нашата система, разработена за подзадачата 1в на шестата споделена задача за Социалните медии Минно дело за здравни приложения (СММ4Х) през 2021 г. Целта на подзадачата е да се разпознаят споменаванията за нежелания лекарствен ефект (АДЕ) от туитове и да се нормализират идентифицираните споменавания към тяхното картографиране предпочитаните термини по МедДРА. Нашата система се основава на невронен преходен модел на ставите, който е да извършва разпознаване и нормализиране едновременно. Последните две предложения надминават средния резултат с 1-2%.', 'nl': "Dit artikel beschrijft ons systeem ontwikkeld voor de subtaak 1c van de zesde gedeelde taak Social Media Mining for Health Applications (SMM4H) in 2021. Het doel van de subtaak is om de ADE-vermeldingen van tweets te herkennen en de geïdentificeerde vermeldingen te normaliseren naar hun MedDRA voorkeursterm ID's. Ons systeem is gebaseerd op een op neurale overgang gebaseerd gewrichtsmodel, dat gelijktijdig herkenning en normalisatie moet uitvoeren. Onze laatste twee inzendingen overtreffen de gemiddelde F1 score met 1-2%.", 'hr': 'Ovaj papir opisuje naš sustav razvijen za podpitanje 1c od šestog rudarstva socijalnih medija za zdravlje aplikacije (SMM4H) zajedničkog zadatka 2021. godine. Cilj podpitanja je prepoznati nuspojavni učinak lijeka (ADE) spomenuti iz tweeta i normalizirati identificirane spojeve svojoj mapiranju predviđene pojedinačne identifikacije MedDRA-a. Naš sustav je zasnovan na zajedničkom modelu na osnovu neurološkog prijenosa, koji je da istovremeno izvedemo priznanje i normalizaciju. Naša posljednja dva podnosa iznosi prosječni rezultat F1 za 1-2%.', 'da': "Denne artikel beskriver vores system udviklet til underopgaven 1c i den sjette delte opgave for Social Media Mining for Health Applications (SMM4H) i 2021. Formålet med underopgaven er at genkende bivirkningen (ADE) nævnelser fra tweets og normalisere de identificerede nævnelser til deres kortlægning MedDRA foretrukne term ID'er. Vores system er baseret på en neural overgangsbaseret ledmodel, som er at udføre anerkendelse og normalisering samtidig. Vores sidste to indsendelser overgår den gennemsnitlige F1 score med 1-2%.", 'de': 'Dieser Beitrag beschreibt unser System, das für den Teilauftrag 1c der sechsten gemeinsamen Aufgabe Social Media Mining for Health Applications (SMM4H) in 2021 entwickelt wurde. Ziel des Subtasks ist es, die Erwähnungen von unerwünschten Medikamenteneffekten (ADE) aus Tweets zu erkennen und die identifizierten Erwähnungen zu ihren MedDRA bevorzugten Term IDs zu normalisieren. Unser System basiert auf einem neuronalen Übergangsmodell, das Erkennung und Normalisierung gleichzeitig durchführen soll. Unsere letzten beiden Einreichungen übertreffen die durchschnittliche F1-Punktzahl um 1-2%.', 'ko': '본고는 2021년 제6차 건강 응용 소셜미디어 발굴(SMM4H) 공유 임무를 위한 하위 임무 1c를 개발한 시스템을 기술한다.이 하위 임무는 트윗에 언급된 약물불량반응(ADE)을 식별하고, 식별된 언급을 매핑된 MedDRA 선호 용어 ID로 표준화하기 위한 것이다.우리의 시스템은 신경 전환을 바탕으로 하는 연합 모델을 바탕으로 이 모델은 식별과 규범화를 동시에 집행한다.우리가 마지막으로 두 번 제출한 성적은 F1 평균 성적보다 1-2% 높다.', 'id': 'Kertas ini menjelaskan sistem kami yang dikembangkan untuk subtask 1c dari enam Media Sosial Menjemahan untuk Aplikasi Kesehatan (SMM4H) tugas berbagi pada tahun 2021. Tujuan dari subtask adalah untuk mengenali efek obat negatif (ADE) yang disebutkan dari tweet dan normalisasi menyebutkan yang dikenal untuk peta mereka MedDRA terma ID yang lebih suka. Sistem kita berdasarkan model kongsi yang berdasarkan transisi saraf, yang adalah untuk melakukan pengenalan dan normalisasi secara bersamaan. Dua pengiriman terakhir kita melebihi nilai F1 rata-rata 1-2%.', 'fa': 'این کاغذ سیستم ما را توسعه می\u200cدهد که در سال ۲۰۱۱ برای پایین\u200cپرس ۱c از ششمین وزن رسانه\u200cهای اجتماعی برای کاربردهای سلامتی (SMM4H) مشترک شده است. هدف زیر سوال این است که اثر مخالف مواد مخالف (ADE) از توئیت\u200cها اشاره می\u200cکند و این اشاره\u200cهای شناسایی را به نقشه\u200cگذاری مدDRA، شناسایی کنید. سیستم ما بر اساس یک مدل مشترک بر اساس تغییر عصبی است که همزمان اجرای شناسایی و طبیعی است. آخرین دو تسلیم\u200cهای ما در میانگین امتیاز F1 با 1-2 درصد بیشتر است.', 'sw': 'Gazeti hili linaelezea mfumo wetu ulioandaliwa kwa jukumu la 1c la Tatu la Mitandao ya kijamii Kufuatilia Mitandao ya Afya (SMM4H) lililoshirikishwa na kazi mwaka 2021. Lengo la jukumu hili ni kutambua matokeo mabaya ya madawa (ADE) yanayotajwa kutoka kwenye twiti na kurekebisha taja zilizotambuliwa kwenye ramani zao zilizopendelea Idadi ya UKIMWI. Mfumo wetu una msingi wa muundo wa mpito wa neura, ambao ni kwa ajili ya kutekeleza kutambua na utaratibu kwa wakati mmoja. Mawasiliano yetu mawili ya mwisho yanafanya wastani wa F1 kwa asilimia 1-2.', 'tr': 'Bu kagyz sistemimizi 2021-nji ýylda orta zady paýlaşýar. Alt soragynyň amasy tweetlerden soňra näsir ilat täsirini tanamak we olaryň MedDRA görkezilýän termynlarynyň IDlerini düzenlemekdir. Bizim sistemimiz näyral geçişimiň daýanýan bir birlik nusga daýanýar. Bu hem tanyş we normalizasyon çykarmakdır. Son iki sorumluluğumuz ortalama noktaları 1-2 oranla uğraşıyor.', 'af': "Hierdie papier beskryf ons stelsel ontwikkeld vir die subvraag 1c van die sesde sosiale media mining vir gesondige toepassings (SMM4H) gedeelde taak in 2021. Die doel van die subvraag is om die noodsaaklike narkotikasieffekt (ADE) van tweets te herken en die identifiseerde bepaalde bepaalde aan hul mapering MedDRA voorkeur term IDs te herken. Ons stelsel is gebaseer op 'n neurale oorgang-gebaseerde joint model, wat is om herken en normalisering simultaan te doen. Ons eindelike twee onderskrifte uitvoer die gemiddelde F1 telling deur 1-2%.", 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգը, որը զարգացել է 2021 թվականին կիսված աշխատանքի 6-րդ սոցիալական լրատվամիջոցների հանքագործման (SMM4H) ենթահարցի 1c-ին: The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs.  Մեր համակարգը հիմնված է նյարդային հատվածի մոդելի վրա, որը նշանակում է միաժամանակ արել ճանաչման և նորմալիզացիա: Մեր վերջին երկու ներկայացումները գերազանցում են F1 միջին գնահատականը 1-2 տոկոսով:', 'sq': 'Ky artikull përshkruan sistemin tonë të zhvilluar për nënpyetjen 1c të detyrës së gjashtë të Social Media Mining for Health Applications (SMM4H) në 2021. Qëllimi i nënpyetjes është të njohësh efektin e dëmshëm të drogës (ADE) që përmendet nga tweetet dhe të normalizojë përmendimet e identifikuara në hartimin e tyre të termit të preferuar MedDRA. Sistemi ynë është i bazuar në një model të përbashkët me tranzicion nervor, i cili është të kryejë njohjen dhe normalizimin në të njëjtën kohë. Our final two submissions outperform the average F1 score by 1-2%.', 'am': 'ይህ ገጽ ለስድስተኛው ማኅበራዊ ሚዲያ አካባቢ ለጤና ፕሮግራሞች (SMM4H) ስድስት ስራ (SMM4H) የተካፈለውን ስራ ያሳያል፡፡ አዋጅ ስራው ከTwitteets የሚቆጠሩትን (ADE) ማስታወቂያውን ማወቅ እና የተታወቁትን ማስታወቂያ ማድረግ ማድDRA በተወደደው የአድራሻ ቃላት ID እንዲያሳውቅ ነው፡፡ ሲስተካከላችን በሁለተኛው ክፍል ላይ የተመሳሳይ እና የተመሳሰለውን እና በተጨማሪነት ለመፈለግ ነው፡፡ የመጨረሻይቱ ሁለታችን የF1 ነጥብ በ1-2 በመቶ ያሳያል፡፡', 'az': 'Bu kağıt bizim sistemimizi 2021-ci ildə paylaşdığı Sağlıq Uygulamalarını (SMM4H) altıncı sosyal Media Mining Programlarından 1.c-dən təmizləndirildiyini təsbit edir. Alt-soruşmağın məqsədi, Tövtlərdən söylədikləri münafiq uyuşturucu etkisini tanımmaq və müəyyən edilmiş məqsədiləri MedDRA-nın seçilmiş termin IDlərinə normal etmək. Sistemimiz nöral dəyişiklik tərəfindən istifadə edilən joint modellərə dayanılır, bu da bir-birinə tanınmaq və normalizasyon etməkdir. Əvvəlki iki təkliflərimiz ortalama F1 nöqtəsini 1-2 ilə dəyişdirir.', 'bs': 'Ovaj papir opisuje naš sistem razvijen za podpitanje 1c od šestog socijalnog medijskog rudarstva za zdravlje aplikacije (SMM4H) zajedničkog zadatka 2021. godine. Cilj podpitanja je prepoznati nužni učinak lijeka (ADE) koji se spominje iz tweeta i normalizirati identificirane spojeve na njihove mapiranje preferirane pojedinačne identifikacije MedDRA-a. Naš sistem je zasnovan na zajedničkom modelu na neuralnoj transiciji, koji je da istovremeno izvedemo priznanje i normalizaciju. Naša poslednja dva podnosa iznosi prosječni rezultat F1 za 1-2%.', 'bn': 'এই পত্রিকাটি ২০১২ সালে স্বাস্থ্য অ্যাপ্লিকেশনের (এমএমএফ৪) ভাগাভাগি করা কাজের জন্য আমাদের সাবাক্ষাৎকারের জন্য সাবাক্ষ সাবকাজের উদ্দেশ্য হচ্ছে টুইট থেকে মাদক প্রভাবের উল্লেখের বিরুদ্ধে স্বীকৃতি প্রদান করা এবং তাদের মেডডিরা পছন্দের মেয়েদের আইডির কাছ আমাদের সিস্টেম একটি নিউরুল প্রবেশের ভিত্তিক যৌথ মডেলের উপর ভিত্তিক, যা একই সাথে স্বীকৃতি এবং স্বাভাবিক স্বীকৃত আমাদের চূড়ান্ত দুই প্রতিক্রিয়ায় ১-২ শতাংশের সাধারণ F1 স্কোর প্রদান করে।', 'cs': 'Tento článek popisuje náš systém vyvinutý pro podúkol 1c šestého sdíleného úkolu Social Media Mining for Health Applications (SMM4H) v roce 2021. Cílem podúkolu je rozpoznat zmínky o nežádoucím léčivém účinku (ADE) z tweetů a normalizovat identifikované zmínky do jejich mapování preferovaných termínů MedDRA. Náš systém je založen na neuronovém přechodovém modelu kloubů, který má provádět rozpoznávání a normalizaci současně. Naše poslední dvě příspěvky překonávají průměrné skóre F1 o 1-2%.', 'et': 'Käesolevas artiklis kirjeldatakse meie süsteemi, mis töötati välja kuuenda sotsiaalmeedia kaevandamise tervise rakenduste jaoks (SMM4H) jagatud ülesande 1c jaoks 2021. aastal. Alaülesande eesmärk on tuvastada kõrvaltoime (ADE) märke säutsudest ja normaliseerida tuvastatud märke nende kaardistamisel MedDRA eelistatud terminite ID. Meie süsteem põhineb närviüleminekul põhineval liigesmudelil, mis sooritab samaaegselt äratundmist ja normaliseerimist. Meie kaks viimast avaldust ületavad keskmise F1 skoori 1-2%.', 'ca': "Aquest article descriu el nostre sistema desenvolupat per la subtema 1c de la sexta tasca compartida de mineria social per aplicacions sanitàries (SMM4H) al 2021. The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs.  El nostre sistema es basa en un model conjunt basat en transició neuronal, que és fer reconeixement i normalització simultàneament. Les nostres dues últimes proposicionssuperen la mitjana de puntuació F1 d'un 1-2%.", 'fi': 'Tässä artikkelissa kuvataan järjestelmäämme, joka kehitettiin kuudennen Sosiaalisen median terveyssovellusten louhinta (SMM4H) -tehtävän alatehtävään 1c vuonna 2021. Alatehtävän tavoitteena on tunnistaa tweeteistä annetut haittavaikutukset ja normalisoida tunnistetut maininnat niiden MedDRA-termien kartoitukseen. Järjestelmämme perustuu hermosiirtymään perustuvaan nivelmalliin, jonka tarkoituksena on suorittaa tunnistus ja normalisointi samanaikaisesti. Viimeiset kaksi julkaisua suoriutuvat 1-2% keskimääräisestä F1-tuloksesta.', 'jv': 'Perintah iki diperawan sistem awak dhéwé nggawe nggawe 1c sing katêpakan ning sesuk Media Ming kanggo Aplikasi kanggo Sak Saasaan (SMM4H) sing berarti task nang 2020 1. Aparipen nggunakake tarjamahan punika ingkang ngerasakno Panjenengan langgar oleh dumadhi gambar nggawe Jabungan ingkang dipolet kanggo ngerayakno Sistem-sistem sing digawe ning model sing digawe, kiye wis saben piye aturan karo model sing dadi, kudu dumadhi kejahatan karo Normal. Awak dhéwé sistem sing ditambah sing dikarepaké F1 rambarang 1-2%.', 'ha': "Wannan takardan na describe system developed for the sub-job 1c of the 6-month SMM4H Shared job in 2021. Gana wa wannan aikin ni sani sunan bayan aikin madawara (ADE) daga Twitter, kuma ka daidaita wa sunan da aka gane su zuwa raɗin da aka fi son shaidar shaidar mutane. GafuyinMu na ɗauki a kan wani misali mai haɗi da neura, wanda za'a yi amfani da ganin da kuma a tsaye da shi sami ɗaya. Ga duk musulunci biyu na ƙarshen su ƙara ga nau'in F1 da asilimi 1-2.", 'sk': 'Ta prispevek opisuje naš sistem, razvit za podnalogo 1c šeste skupne naloge rudarjenja v družbenih medijih za zdravstvene aplikacije (SMM4H) leta 2021. Cilj podnaloge je prepoznati omembe neželenih učinkov zdravila (ADE) iz tweetov in normalizirati identificirane omembe v njihovo kartiranje MedDRA preferenčnih izrazov ID. Naš sistem temelji na živčnem prehodnem modelu sklepa, ki naj bi hkrati izvajal prepoznavanje in normalizacijo. Naši zadnji dve prispevki presegata povprečni rezultat F1 za 1-2%.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི་དོན་ལ་སྤྱི་ཚོགས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་གྱི་ཉེར་སྤྱོད་ལ་འཇུག The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs. ང་ཚོའི་མ་ལག ང་ཚོའི་མཐའ་མཇུག་གི་གནས་སྡུད་གཉིས་ཀྱིས་རྒྱ་ནག་གི་ཚད་F1 རིམ་པ་དེ་ལས་ཉུང་བར་འགོད་ཡོད།', 'he': 'העיתון הזה מתאר את המערכת שלנו שפותחת לתת השאלה 1c של המכרות החברתית השישית לתוכניות בריאות (SMM4H) המשימה המשותפת בשנת 2021. המטרה של השאלה התחתונה היא לזהות את השפעה הרעילה של התרופות (ADE) הזכרות מתוך טוויטים ולנורמליז את הזכרות הזהות למפות שלהם את המונח המועדף על MedDRA. המערכת שלנו מבוססת על מודל משותף מבוסס על מעבר עצבי, שהוא לבצע זיהוי ונורמליזציה באותו זמן. שתי ההצגות האחרונות שלנו מעליפות את הציון הממוצע של F1 ב-1-2%.'}
