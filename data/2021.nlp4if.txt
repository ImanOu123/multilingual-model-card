{'en': 'Identifying Automatically Generated Headlines using Transformers', 'ar': 'تحديد العناوين التي تم إنشاؤها تلقائيًا باستخدام المحولات', 'fr': "Identifier les titres générés automatiquement à l'aide de", 'es': 'Identificación de titulares generados automáticamente mediante Transformers', 'pt': 'Identificando títulos gerados automaticamente usando transformadores', 'ja': 'トランスフォーマーを使用して自動生成された見出しを識別する', 'zh': '用变形金刚识自生标题', 'hi': 'ट्रांसफॉर्मर का उपयोग करके स्वचालित रूप से जेनरेट की गई हेडलाइंस की पहचान करना', 'ru': 'Идентификация автоматически сгенерированных заголовков с помощью трансформаторов', 'ga': 'Ceannlínte a Ghintear go Uathoibríoch a Aithint ag úsáid Claochladáin', 'ka': 'Name', 'hu': 'Automatikusan generált címsorok azonosítása transzformátorokkal', 'el': 'Αναγνώριση αυτόματα δημιουργημένων κεφαλίδων χρησιμοποιώντας μετασχηματιστές', 'it': 'Identificazione delle intestazioni generate automaticamente tramite Transformer', 'lt': 'Automatiškai generuotų antraščių nustatymas naudojant transformatorius', 'mk': 'Идентификување автоматски генерирани наслови користејќи трансформери', 'ms': 'Mengenalpasti Tajuk Yang Dijana secara Automatik menggunakan Penukar', 'kk': 'Трансферлерді қолданып автоматты түрде жасалған айдарларды анықтау', 'ml': 'ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ഉപയോഗിച്ച് സ്വയം സൃഷ്ടിച്ച തലക്കെട്ടിളുകള്\u200d തിരിച്ചറിയുക', 'mn': 'Автоматтыг өөрчлөгдсөн толгой шулуунуудыг өөрчлөгдөх', 'pl': 'Identyfikowanie automatycznie generowanych nagłówek za pomocą transformatorów', 'no': 'Identifiserer automatisk genererte hovudlinjer med transformerer', 'ro': 'Identificarea titlurilor generate automat utilizând Transformers', 'si': 'Name', 'sr': 'Identifikacija automatski generirane glavne linije koristeći transformatore', 'so': 'Identifying Automatically Generated Headlines using Transformers', 'ta': 'தானாகவே உருவாக்கப்பட்ட தலைப்புகளை உருவாக்கு', 'sv': 'Identifiera automatiskt genererade rubriker med hjälp av transformatorer', 'ur': 'Name', 'mt': 'L-identifikazzjoni tal-Intestaturi Ġenerati Awtomatikament bl-użu tat-Trasformatituri', 'vi': 'Nhận diện đầu dòng tự động dùng tạo hình', 'uz': 'Transformerlar bilan avto- aniqlash', 'bg': 'Идентифициране на автоматично генерирани заглавия с помощта на трансформатори', 'hr': 'Identifikacija automatski generirane glavne linije koristeći transformere', 'da': 'Identificering af automatisk genererede overskrifter ved hjælp af transformatorer', 'nl': 'Automatisch gegenereerde kopteksten identificeren met behulp van transformers', 'de': 'Identifizieren automatisch generierter Überschriften mithilfe von Transformern', 'id': 'Identifikasi Tajuk Digenerkan secara Otomatis menggunakan Transformers', 'fa': 'شناسایی سرخط\u200cهای خودکار تولید شده با استفاده از تبدیل\u200cکنندگان', 'sw': 'Kutambua Video vilivyotengenezwa Automatically By using Transformers', 'tr': 'Ullançylar ullanýan Otomatik Bejer Çizikler', 'af': 'Name', 'sq': 'Identifikimi i titujve të gjeneruar automatikisht duke përdorur transformuesit', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Անշուշտ ստեղծված գլխագծեր հայտնաբերելը՝ օգտագործելով վերափոխողներ', 'az': 'Transformers vasit…ôsil…ô Avtomatik √únvan BaŇülńĪqlarńĪ', 'bn': 'ট্রান্সফর্মার ব্যবহার করে স্বয়ংক্রিয়ভাবে তৈরি শীর্ষচরণ পরিচয় করা হবে', 'bs': 'Identifikacija automatski generirane glavne linije koristeći transformere', 'ca': 'Identificar titulars generats automàticament amb transformadors', 'cs': 'Identifikace automaticky generovaných nadpisů pomocí transformátorů', 'ko': '변압기를 사용하여 자동으로 생성된 제목을 식별하다', 'et': 'Automaatselt genereeritud pealkirjade tuvastamine transformaatorite abil', 'fi': 'Automaattisesti luotujen otsikoiden tunnistaminen muuntajien avulla', 'jv': 'string" in "context_BAR_stringLink', 'ha': '@ action', 'bo': 'བཟོ་བཅོས་པ་བེད་སྤྱོད་བཞིན་པའི་རང་འགུལ་གྱིས་རང་འགུལ་གྱིས་བཟོ་བརྒྱུད་པའི་མགོ་ཡིག་གྲངས', 'sk': 'Identifikacija samodejno ustvarjenih naslovov s pretvorniki', 'he': 'Identifying Automatically Generated Headlines using Transformers'}
{'en': 'False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8 % of the cases. However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7 %, indicating that content generated from language models can be filtered out accurately.', 'es': 'La información falsa difundida a través de Internet y las redes sociales influye en la opinión pública y la actividad de los usuarios, mientras que los modelos generativos permiten generar contenido falso de forma más rápida y económica de lo que antes era posible. En un futuro no muy lejano, la identificación del contenido falso generado por los modelos de aprendizaje profundo desempeñará un papel clave en la protección de los usuarios de la desinformación. Con este fin, se creó un conjunto de datos que contenía titulares generados por humanos y por computadora y un estudio de usuarios indicó que los humanos solo podían identificar los titulares falsos en el 47,8% de los casos. Sin embargo, el enfoque automático más preciso, los transformadores, logró una precisión general del 85,7%, lo que indica que el contenido generado a partir de modelos de lenguaje se puede filtrar con precisión.', 'ar': 'تؤثر المعلومات الزائفة المنتشرة عبر الإنترنت ووسائل التواصل الاجتماعي على الرأي العام ونشاط المستخدم ، بينما تتيح النماذج التوليدية إنشاء المحتوى المزيف بشكل أسرع وبتكلفة أقل مما كان ممكنًا في السابق. في المستقبل غير البعيد ، سيلعب تحديد المحتوى المزيف الناتج عن نماذج التعلم العميق دورًا رئيسيًا في حماية المستخدمين من المعلومات المضللة. ولهذه الغاية ، تم إنشاء مجموعة بيانات تحتوي على عناوين رئيسية تم إنشاؤها بواسطة الإنسان والكمبيوتر ، وأشارت دراسة مستخدم إلى أن البشر كانوا قادرين فقط على تحديد العناوين المزيفة في 47.8٪ من الحالات. ومع ذلك ، فإن النهج الأوتوماتيكي الأكثر دقة ، المحولات ، حقق دقة إجمالية بلغت 85.7٪ ، مما يشير إلى أنه يمكن تصفية المحتوى الناتج من نماذج اللغة بدقة.', 'pt': 'Informações falsas espalhadas pela internet e mídias sociais influenciam a opinião pública e a atividade do usuário, enquanto os modelos generativos permitem que o conteúdo falso seja gerado de forma mais rápida e barata do que era possível anteriormente. Em um futuro não tão distante, a identificação de conteúdo falso gerado por modelos de aprendizado profundo desempenhará um papel fundamental na proteção dos usuários contra desinformação. Para isso, foi criado um conjunto de dados contendo manchetes geradas por humanos e por computador e um estudo com usuários indicou que os humanos só conseguiram identificar as manchetes falsas em 47,8% dos casos. No entanto, a abordagem automática mais precisa, os transformadores, alcançou uma precisão geral de 85,7%, indicando que o conteúdo gerado a partir de modelos de linguagem pode ser filtrado com precisão.', 'fr': "Les fausses informations diffusées via Internet et les réseaux sociaux influencent l'opinion publique et l'activité des utilisateurs, tandis que les modèles génératifs permettent de générer du faux contenu plus rapidement et à moindre coût qu'auparavant. Dans un avenir proche, l'identification du faux contenu généré par les modèles de deep learning jouera un rôle clé dans la protection des utilisateurs contre la désinformation. À cette fin, un ensemble de données contenant des titres humains et générés par ordinateur a été créé et une étude d'utilisateurs a indiqué que les humains n'étaient capables d'identifier les faux titres que dans 47,8\xa0% des cas. Cependant, l'approche automatique la plus précise, les transformateurs, a atteint une précision globale de 85,7\xa0%, ce qui indique que le contenu généré à partir de modèles linguistiques peut être filtré avec précision.", 'ja': 'インターネットやソーシャルメディアを介した虚偽の情報の拡散は、世論やユーザーの活動に影響を与え、生成モデルは、偽のコンテンツを以前よりも速く、より安価に生成することを可能にします。そう遠くない将来、ディープラーニングモデルによって生成された偽のコンテンツを特定することは、ユーザーを誤った情報から保護する上で重要な役割を果たすでしょう。この目的のために、ヒトおよびコンピュータが生成した見出しを含むデータセットが作成され、ユーザー調査では、ヒトは47.8 ％の症例で偽の見出ししか識別できなかったことが示された。しかし、最も正確な自動アプローチである変圧器は85.7 ％の全体的な精度を達成し、言語モデルから生成されたコンテンツを正確にフィルタリングできることを示しています。', 'zh': '互联网社交媒体虚信,动公论用户,而成虚速于前,为便于前。 未几之后,识深学虚,将保用户免错误信息害关键作用。 故创一人计算机之数,一用户研明,人识虚47.8%之例。 然至正自变压器,致85.7%之精,言模成而理漉也。', 'ru': 'Ложная информация, распространяемая через Интернет и социальные сети, влияет на общественное мнение и активность пользователей, в то время как генеративные модели позволяют создавать фальшивый контент быстрее и дешевле, чем это было возможно ранее. В не столь отдаленном будущем выявление фальшивого контента, генерируемого моделями глубокого обучения, будет играть ключевую роль в защите пользователей от дезинформации. С этой целью был создан набор данных, содержащий человеческие и компьютерные заголовки, и исследование пользователей показало, что люди смогли идентифицировать поддельные заголовки только в 47,8% случаев. Тем не менее, наиболее точный автоматический подход, трансформаторы, достиг общей точности 85,7%, что указывает на то, что контент, генерируемый языковыми моделями, может быть точно отфильтрован.', 'hi': 'इंटरनेट और सोशल मीडिया के माध्यम से फैली झूठी जानकारी सार्वजनिक राय और उपयोगकर्ता गतिविधि को प्रभावित करती है, जबकि उत्पादक मॉडल नकली सामग्री को पहले की तुलना में तेजी से और अधिक सस्ते में उत्पन्न करने में सक्षम बनाते हैं। इतने दूर के भविष्य में, गहरी सीखने के मॉडल द्वारा उत्पन्न नकली सामग्री की पहचान करना उपयोगकर्ताओं को गलत जानकारी से बचाने में महत्वपूर्ण भूमिका निभाएगा। इसके लिए, मानव और कंप्यूटर-जनित सुर्खियों वाला एक डेटासेट बनाया गया था और एक उपयोगकर्ता अध्ययन ने संकेत दिया कि मनुष्य केवल 47.8% मामलों में नकली सुर्खियों की पहचान करने में सक्षम थे। हालांकि, सबसे सटीक स्वचालित दृष्टिकोण, ट्रांसफॉर्मर, ने 85.7% की समग्र सटीकता हासिल की, यह दर्शाता है कि भाषा मॉडल से उत्पन्न सामग्री को सटीक रूप से फ़िल्टर किया जा सकता है।', 'ga': 'Bíonn tionchar ag faisnéis bhréagach a scaiptear ar an idirlíon agus ar na meáin shóisialta ar thuairim an phobail agus ar ghníomhaíocht úsáideoirí, agus cuireann samhlacha giniúna ar chumas ábhar bréige a ghiniúint níos tapúla agus níos saoire ná mar a bhí indéanta roimhe seo. Sa todhchaí nach bhfuil i bhfad i gcéin, beidh ról lárnach ag sainaithint ábhar falsa arna ghiniúint ag samhlacha domhainfhoghlama maidir le húsáideoirí a chosaint ar mhífhaisnéis. Chuige sin, cruthaíodh tacar sonraí ina raibh ceannlínte daonna agus ríomhaire agus léirigh staidéar úsáideora nach raibh daoine in ann na ceannlínte bréige a shainaithint ach i 47.8% de na cásanna. Mar sin féin, bhain an cur chuige uathoibríoch is cruinne, claochladáin, cruinneas foriomlán 85.7% amach, rud a léiríonn gur féidir ábhar a ghintear ó mhúnlaí teanga a scagadh go cruinn.', 'hu': 'Az interneten és a közösségi médián keresztül terjedő hamis információk befolyásolják a közvéleményt és a felhasználói tevékenységet, míg a generációs modellek lehetővé teszik, hogy hamis tartalmak gyorsabban és olcsóbban generálódjanak, mint korábban lehetett volna. A nem túl távoli jövőben a mélytanulási modellek által létrehozott hamis tartalom azonosítása kulcsfontosságú szerepet játszik majd a felhasználók téves információktól való védelmében. Ennek érdekében emberi és számítógép által generált főcímeket tartalmazó adatkészletet hoztak létre, és egy felhasználói tanulmány azt mutatta, hogy az emberek csak az esetek 47,8%-ában tudták azonosítani a hamis főcímeket. A legpontosabb automatikus megközelítés azonban a transzformátorok 85,7%-os pontosságot értek el, ami azt jelzi, hogy a nyelvi modellekből keletkezett tartalom pontosan kiszűrhető.', 'el': 'Οι ψεύτικες πληροφορίες που διαδίδονται μέσω του διαδικτύου και των μέσων κοινωνικής δικτύωσης επηρεάζουν την κοινή γνώμη και τη δραστηριότητα των χρηστών, ενώ τα παραγωγικά μοντέλα επιτρέπουν την παραγωγή ψεύτικου περιεχομένου γρηγορότερα και πιο φτηνά από ό,τι ήταν δυνατό στο παρελθόν. Στο όχι τόσο μακρινό μέλλον, ο εντοπισμός ψεύτικου περιεχομένου που παράγεται από μοντέλα βαθιάς μάθησης θα διαδραματίσει βασικό ρόλο στην προστασία των χρηστών από παραπληροφόρηση. Για το σκοπό αυτό, δημιουργήθηκε ένα σύνολο δεδομένων που περιείχε τίτλους από ανθρώπους και υπολογιστές και μια μελέτη χρηστών έδειξε ότι οι άνθρωποι ήταν σε θέση να εντοπίσουν τους ψεύτικους τίτλους μόνο σε 47,8% των περιπτώσεων. Ωστόσο, η πιο ακριβής αυτόματη προσέγγιση, οι μετασχηματιστές, πέτυχε μια συνολική ακρίβεια 85.7%, υποδεικνύοντας ότι το περιεχόμενο που παράγεται από γλωσσικά μοντέλα μπορεί να φιλτράρεται με ακρίβεια.', 'it': "Le false informazioni diffuse su Internet e sui social media influenzano l'opinione pubblica e l'attività degli utenti, mentre i modelli generativi consentono di generare contenuti falsi più velocemente e a basso costo di quanto fosse stato possibile in precedenza. In un futuro non così lontano, identificare i contenuti falsi generati da modelli di deep learning giocherà un ruolo chiave nel proteggere gli utenti dalla disinformazione. A tal fine, è stato creato un set di dati contenente titoli umani e generati dal computer e uno studio degli utenti ha indicato che gli esseri umani sono stati in grado di identificare i titoli falsi solo nel 47,8% dei casi. Tuttavia, l'approccio automatico più accurato, i trasformatori, ha raggiunto una precisione complessiva dell'85,7%, indicando che i contenuti generati dai modelli linguistici possono essere filtrati con precisione.", 'lt': 'Neteisėta informacija internetu ir socialine žiniasklaida daro įtaką visuomenės nuomonei ir vartotojų veiklai, o generaciniai modeliai leidžia kurti padirbtą turinį greičiau ir pigiau nei anksčiau buvo įmanoma. Netolimoje ateityje nustatant suklastotą turinį, susidariusį naudojant gilaus mokymosi modelius, bus svarbus vaidmuo apsaugant vartotojus nuo klaidingos informacijos. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8% of the cases.  Tačiau tiksliausias automatinis metodas, transformatoriai, pasiekė bendrą tikslumą 85,7 %, ir tai rodo, kad iš kalbų modelių gautas turinys gali būti tiksliai filtruojamas.', 'ka': 'შეცდომა ინტერნეტი და სოციალური მედიაზე გაფართებული ინფორმაცია მომხმარებელი აღმოჩენებს და მომხმარებელი აღმოჩენებს, როცა გენერაციური მოდელები ძალიან ძალიან და უფრო მარ არა რამდენიმე განსხვავებული მომავალში, მარტივი შესახებ მოდელეების გამოიყენება ძალიან სწავლებელი მოდელეებისთვის გასაკეთებელი პროლია იყოს გამოიყენებელი არასწ ეს მიზეზით, მონაცემების სექტი, რომელიც ადამიანის და კომპიუტერის შექმნილი თარიღები შექმნილია, და მომხმარებელი სწავლის შესწავლია, რომ ადამიანები შეუძლია მხოლოდ 47.8%  მაგრამ, ყველაზე წესიერი ავტომატიკური პროგრამი, ტრანფორმეტრები, 85,7%-ის უფრო წესიერებას მიიღეთ, რომელიც მუშაობა, რომ ენის მოდელებიდან შეიქმნა შესაძლებელია წესიერ', 'mk': 'Лажни информации ширени преку интернет и социјалните медиуми влијаат на јавното мислење и корисничката активност, додека генерациските модели овозможуваат лажна содржина да се генерира побрзо и поевтино отколку што претходно беше можн Во недалечната иднина идентификувањето на лажната содржина генерирана од моделите за длабоко учење ќе има клучна улога во заштитата на корисниците од погрешни информации. За оваа цел, се создаде компјутерски нацрт на податоци кој содржи човекови и компјутерски генерирани наслови и студијата на корисниците покажа дека луѓето можеле да ги идентификуваат лажните наслови само во 47,8 отсто од случаите. Сепак, најточниот автоматски пристап, трансформаторите, постигна вкупна точност од 85,7 отсто, што индицира дека содржината генерирана од јазичките модели може да се филтрира точно.', 'ml': 'ഇന്റര്\u200dനെറ്റിലും സോഷ്യല്\u200d മീഡിയിലൂടെയും വ്യാജവിവരങ്ങള്\u200d പരത്തിയിരിക്കുന്നത് പൊതുവായ അഭിപ്രായത്തിനും ഉപയോക്താവിന്റെ പ്രവര്\u200dത്തനവ ഇത്രയും ദൂരെയുള്ള ഭാവിയില്\u200d, ആഴത്തെ പഠിക്കുന്ന മോഡലുകള്\u200d ഉണ്ടാക്കിയ വ്യാജവസ്തുക്കള്\u200d തിരിച്ചറിയുന്നതാണ് ഉപയോക് ഈ അവസാനത്തിനായി മനുഷ്യനും കമ്പ്യൂട്ടര്\u200d ജനിപ്പിക്കപ്പെട്ട തലക്കെട്ടുകളുമുള്ള ഒരു ഡാറ്റാസറ്റ് ഉണ്ടാക്കിയിരിക്കുന്നു. ഒരു ഉപയോക്താവ്  എന്നാലും, ഏറ്റവും കൃത്യമായ സ്വയമായ വഴിപാട്, മാറ്റം വരുത്തുന്നത്, 85.', 'kk': 'Интернет және социалдық медиақтар арқылы жалғыз мәліметтер көпшілік ойлау мен пайдаланушылардың белсенділіктеріне әсер етеді, бірақ жалғыз үлгілер жалғыз мазмұның алдындағыдан те Бірақ қашықтық болашақта, дұрыс оқыту үлгілерінен құрылған жалғыз мазмұнын анықтау пайдаланушыларды дұрыс түрлендіруден қорғау үшін негізгі роль ойлайды. Бұл үшін адамдар мен компьютер құрылған айдарлар бар деректер жинағы құрылды, және пайдаланушының зерттеулері, адамдар тек 47, 8% жалғыз айдарларды анықтай алады деп белгіледі. Бірақ ең дұрыс автоматты түрлендірушілер 85,7% деген жалпы дұрыс түрлендіру үшін тіл үлгілерінен құрылған мазмұнын дұрыс сүзгіледі.', 'ms': 'Maklumat palsu disebarkan melalui internet dan media sosial mempengaruhi pendapat awam dan aktiviti pengguna, sementara model generatif membolehkan kandungan palsu dijana lebih cepat dan murah daripada yang sebelumnya. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation.  Untuk tujuan ini, set data yang mengandungi tajuk utama yang dihasilkan oleh manusia dan komputer dicipta dan kajian pengguna menunjukkan bahawa manusia hanya mampu mengenalpasti tajuk utama palsu dalam 47.8% kes. Namun, pendekatan automatik yang paling tepat, pengubah, mencapai ketepatan umum 85.7%, menunjukkan bahawa kandungan yang dijana dari model bahasa boleh ditapis dengan tepat.', 'no': 'Feil informasjon som er spredt gjennom Internett og sosialmedia påvirkar offentlig mening og brukaraktivitet, mens genererige modeller kan laga falske innhald raskare og levere enn det førre var mogleg. I det ikkje så langt framtida vil det spela ein nøkkelrolle i å beskytta brukarar frå feil formatering ved å identifisera falske innhald som er generert av dype læringsmodeller. I denne slutten vart det oppretta ein dataset som inneheld menneske og datamaskinelaga hovudlinjer, og ein brukarstudie vist at menneske bare kunne identifisera falske hovudlinjer i 47,8 % av tilfellene. Den mest nøyaktige automatiske tilnærming, transformatorane, har imidlertid noko noko nøyaktig 85,7%, som tyder på at innhaldet generert frå språk-modeller kan filterast ut nøyaktig.', 'mn': 'Интернет болон нийгмийн мэдээллийн хэрэглэгчдийн бодлоор, хэрэглэгчдийн үйл ажиллагаанд хуурамч мэдээллийг нэмэгдүүлэхэд нөлөөлдөг. Эдгээр загварууд нь өмнө нь боломжтой байснаас хуурамч, хуурамч бү Ирээдүйд тийм хол биш, гүн гүнзгий суралцах загвараар гаргасан хуурамч бүтээгдэхүүнийг тодорхойлох нь хэрэглэгчийг буруу хэлбэрээс хамгаалах чухал үүрэг болно. Энэ төгсгөлд хүн болон компьютер үүсгэсэн удирдах өгөгдлийн санг бүтээсэн бөгөөд хэрэглэгчийн судалгаа нь хүмүүс зөвхөн хуурамч удирдах хуурамч удирдах боломжтой гэдгийг харуулсан. Гэхдээ хамгийн тодорхой автоматический арга зам, шилжүүлэгчид 85.7%-ын тодорхойлолт гарч ирсэн бөгөөд хэл загвараас гаргасан бүтээгдэхүүнийг зөв шилжүүлж чадна.', 'ro': 'Informațiile false răspândite prin internet și social media influențează opinia publică și activitatea utilizatorilor, în timp ce modelele generative permit generarea conținutului fals mai rapidă și mai ieftină decât fusese posibil anterior. În viitorul nu atât de îndepărtat, identificarea conținutului fals generat de modele de învățare profundă va juca un rol cheie în protejarea utilizatorilor de dezinformare. În acest scop, a fost creat un set de date conținând titluri umane și generate de calculator și un studiu utilizator a indicat că oamenii au fost capabili să identifice titlurile false doar în 47,8% din cazuri. Cu toate acestea, cea mai precisă abordare automată, transformatoarele, a atins o precizie generală de 85,7%, indicând faptul că conținutul generat din modelele lingvistice poate fi filtrat cu precizie.', 'sr': 'Lažne informacije koje se šire preko interneta i društvenih medija utiču na javno mišljenje i aktivnost korisnika, dok generativni modeli omogućavaju da lažni sadržaj bude proizveden brže i jeftinije nego što je prije bilo moguće. U ne tako dalekoj budućnosti, identifikacija lažnog sadržaja proizvedenog modelima dubokog učenja igraće ključnu ulogu u zaštiti korisnika od nepravde informacije. Za taj cilj je stvorena grupa podataka koja sadrži ljudske i kompjuterske naslove, a istraživanje korisnika ukazalo je da su ljudi samo u stanju identificirati lažne naslove u 47,8% slučajeva. Međutim, najprecizniji automatski pristup, transformatori, ostvarili su ukupnu tačnost od 85,7%, ukazujući na to da se sadržaj proizveden iz jezičkih modela može precizno filtrirati.', 'pl': 'Fałszywe informacje rozpowszechniane przez internet i media społecznościowe wpływają na opinię publiczną i aktywność użytkowników, natomiast modele generacyjne umożliwiają szybsze i taniej generowanie fałszywych treści niż było to możliwe wcześniej. W niedalekiej przyszłości identyfikacja fałszywych treści generowanych przez modele głębokiego uczenia odgrywa kluczową rolę w ochronie użytkowników przed dezinformacją. W tym celu stworzono zbiór danych zawierający nagłówki generowane przez ludzi i komputery, a badanie użytkowników wskazało, że ludzie byli w stanie zidentyfikować fałszywe nagłówki tylko w 47,8% przypadków. Jednak najbardziej dokładne podejście automatyczne, transformatory, osiągnęły ogólną dokładność 85,7%, wskazując, że treści generowane z modeli językowych mogą być dokładnie filtrowane.', 'so': 'Macluumaad been ah oo ku faafiyey internetka iyo shabakadda bulshada ayaa saameyn ku yeelan kara aragtida dadweynaha iyo waxqabadka isticmaalayaasha, marka lagu sameeyo qaababka dhaqaalaha ee wax been ah, waxaa suurtogal ah in la sameeyo si dhaqso iyo si ka fudud inta horay u suurtowday. Halkan mustaqbalka aan aad u fog ahayn, in la caddeeyo waxyaabaha been ah oo muusikada waxbarashada mool dheer ku soo dhashay, wuxuu qayb muhiim ah ku ciyaarayaa in uu isticmaalayaasha ka badbaadiyo macluumaad khalad ah. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8% of the cases.  Si kastaba ha ahaatee qaabka ugu saxda ee si saxda ah ee dhaqdhaqaaqyada, isbedelka, waxay gaadhay saxda rasmiga ah 85,7 boqolkiiba, wuxuuna tusinayaa in ku qori karo kooxda qaababka luuqada ka soo baxay si saxda ah.', 'si': 'අන්තර්ජාලය සහ සාමාජික මිඩියාවෙන් වැරදි තොරතුරු ප්\u200dරශ්නය කරනවා සාමාජික විශ්වාස සහ ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය සක්\u200dරි මෙච්චර දුරස්ථ අනාගතයේ නැහැ, ගොඩක් ඉගෙනීම් මොඩේල් වලින් නිර්මාණය කරපු බොරු සාමාන්\u200dය සංරක්ෂණයෙන් ප්\u200dර මේ අවසානයෙන්, මිනිස්සු සහ පරිගණකයෙන් නිර්මාණය කරලා තියෙන දත්ත සෙට් එකක් නිර්මාණය කරලා තියෙන්නේ, පරිගණකයෙන් ප්\u200dරශ්ණ නමුත්, ස්වයංක්\u200dරීය ස්වයංක්\u200dරීය විදියට, වෙනස් කරුණාකරුවන්, 85.7% ගැන සාමාන්\u200dයතාවක් ලැබුනා, භාෂා මොඩේල් වලින් නි', 'sv': 'Falsk information sprids via internet och sociala medier påverkar den allmänna opinionen och användaraktiviteten, medan generativa modeller gör det möjligt att generera falskt innehåll snabbare och billigare än tidigare varit möjligt. Inom en inte så avlägsen framtid kommer identifiering av falskt innehåll som genereras av djupinlärningsmodeller att spela en nyckelroll för att skydda användare från felaktig information. För detta ändamål skapades en datauppsättning innehållande mänskliga och datorgenererade rubriker och en användarstudie visade att människor bara kunde identifiera de falska rubrikerna i 47,8% av fallen. Den mest exakta automatiska metoden, transformatorer, uppnådde dock en total noggrannhet på 85,7%, vilket indikerar att innehåll som genereras från språkmodeller kan filtreras ut exakt.', 'ta': 'False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.  மிகவும் தூரத்தில் இல்லாத எதிர்காலத்தில், ஆழமான கற்றல் மாதிரிகளால் உருவாக்கப்பட்ட பொய் உள்ளடக்கங்களை கண்டுபிடிக்கும் ப இந்த முடிவிற்கு, மனிதன் மற்றும் கணினி உருவாக்கப்பட்ட தலைப்புகள் உள்ள தகவல் அமைப்பு உருவாக்கப்பட்டது மற்றும் ஒரு பயனர் படிப்பு அறிவிக்கப்பட்டது பொய் தல ஆனால், மொழி மாதிரிகளிலிருந்து உருவாக்கப்பட்ட உள்ளடக்கங்களை சரியாக வடிகட்டி முடியும் என்பதை குறிப்பிடுகிறது.', 'ur': 'انٹرنیٹ اور سوسیل میڈیا کے ذریعے پھیلا ہوا غلط معلومات، عمومی نظر اور کارساز کی فعالیت پر اثر دیتی ہے، حالانکہ جنرائیٹ موڈلیوں نے غلط منصوبات کو پہلے موجود سے زیادہ سریع اور زیادہ آسان بنایا ہے. اس طرح دور آیندہ میں نہیں، درجے کی تعلیم مدل کے ذریعہ جوڑے ہوئے غلط منصوبات کی شناسایی کرتی ہے، سویروں کو غلط تعلیم سے محفوظت کرنے کے لئے ایک کلی رول کھائے گی. یہاں تک، انسان اور کمپیوٹر کے پیدا کئے ہوئے ہڈلائین کے ساتھ ایک ڈیٹ سٹ پیدا کیا گیا ہے اور ایک کارساز تحقیر نے دکھایا کہ انسان صرف 47.8% میں جھوٹی ہڈلائین کو پہچان سکتا تھا۔ However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.', 'mt': 'False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.  Fil-futur mhux daqshekk distanti, l-identifikazzjoni ta’ kontenut falz iġġenerat minn mudelli ta’ tagħlim profond se jkollha rwol ewlieni fil-protezzjoni tal-utenti minn informazzjoni ħa żin a. Għal dan il-għan, in ħoloq sett ta’ dejta li fih l-intestaturi umani u ġġenerati mill-kompjuter u studju tal-utent indika li l-bnedmin setgħu jidentifikaw biss il-intestaturi foloz f’47.8% tal-każijiet. Madankollu, l-aktar approċċ awtomatiku preċiż, it-trasformaturi, kiseb preċiżjoni globali ta’ 85.7%, li tindika li l-kontenut iġġenerat minn mudelli lingwistiċi jista’ jiġi ffiltrat b’mod preċiż.', 'vi': 'Thông tin sai được lan truyền qua Internet và các phương tiện xã hội ảnh hưởng đến công luận và hoạt động của người dùng, trong khi các mô hình tạo hóa giả giúp tạo ra các nội dung giả nhanh hơn và rẻ hơn mức có thể. Trong một tương lai không xa, việc xác định nội dung giả tạo từ những mẫu học sâu sẽ đóng vai trò quan trọng trong việc bảo vệ người dùng khỏi thông tin sai lầm. Cho nên, một tập tin chứa các trang nhất của con người và máy tính, và một nghiên cứu người dùng cho thấy con người chỉ có thể xác định được các trang nhất giả trong 478.8. Tuy nhiên, cách tiếp cận tự động chính xác nhất, máy biến, đạt được độ chính xác tổng quát của 85.7=, ngụ ý là nội dung tạo ra từ các mô hình ngôn ngữ có thể được lọc chính xác.', 'uz': "False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.  Keyingi kelajada, eng o'rganish modellari yaratilgan falsk tarkibini aniqlash uchun foydalanuvchilarni xato maʼlumotdan himoyalash uchun muhim roli oʻynaladi. Bu yerda, inson va kompyuterning yaratilgan sarlavhasi bilan maʼlumotlar tarkibi yaratildi va foydalanuvchi tahrirchi odamlar hodisalarning 47.8% ichida xato sarlavhasini aniqlashga imkoniyat beradi. Lekin, eng yaxshi aniqlangan avtomatik usuli, ўзгартириш, 85.7%'ning umumiy imkoniyatini topish mumkin, tilning modellaridan yaratilgan tarkibini toʻgʻri filterlashi mumkin.", 'bg': 'Фалшивата информация, разпространявана чрез интернет и социалните медии, влияе върху общественото мнение и активността на потребителите, докато генеративните модели позволяват фалшивото съдържание да се генерира по-бързо и по-евтино, отколкото е било възможно преди. В не толкова далечно бъдеще идентифицирането на фалшиво съдържание, генерирано от модели за дълбоко обучение, ще играе ключова роля за защитата на потребителите от дезинформация. За тази цел беше създаден набор от данни, съдържащ заглавия от хора и компютърно генерирани, а проучване на потребителите показа, че хората са могли да идентифицират фалшивите заглавия само в 47,8% от случаите. Въпреки това, най-точният автоматичен подход, трансформаторите, постигна обща точност от 85,7%, което показва, че съдържанието, генерирано от езикови модели, може да бъде филтрирано точно.', 'hr': 'Lažne informacije širene preko interneta i društvenih medija utjecaju na javno mišljenje i aktivnost korisnika, dok generativni modeli omogućavaju da se lažni sadržaj proizvede brže i jeftinije nego što je prije bilo moguće. U ne tako dalekoj budućnosti, identifikacija lažnog sadržaja proizvedenog dubokim modelima učenja će imati ključnu ulogu u zaštiti korisnika od pogrešne informacije. Za taj cilj je stvorena kompleta podataka koja sadrži naslove ljudskih i računala, a ispitivanje korisnika pokazalo je da su ljudi samo u stanju identificirati lažne naslove u 47,8% slučajeva. Međutim, najprecizniji automatski pristup, transformatori, ostvarili su ukupnu točnost od 85,7%, ukazujući na tačno filtriranje sadržaja proizvedenog iz jezičkih modela.', 'nl': 'Valse informatie verspreid via internet en sociale media beïnvloedt de publieke opinie en gebruikersactiviteit, terwijl generatieve modellen het mogelijk maken om valse content sneller en goedkoper te genereren dan voorheen mogelijk was. In de niet zo verre toekomst zal het identificeren van nepcontent gegenereerd door deep learning modellen een belangrijke rol spelen bij het beschermen van gebruikers tegen verkeerde informatie. Daartoe werd een dataset gemaakt met menselijke en computergegenereerde koppen en uit een gebruikersstudie bleek dat mensen de nepkoppen alleen in 47,8% van de gevallen konden identificeren. De meest nauwkeurige automatische benadering, transformatoren, bereikte echter een algehele nauwkeurigheid van 85,7%, wat aangeeft dat inhoud gegenereerd uit taalmodellen nauwkeurig kan worden gefilterd.', 'da': 'Falsk information spredt via internettet og sociale medier påvirker den offentlige mening og brugeraktiviteten, mens generative modeller gør det muligt at generere falsk indhold hurtigere og billigere end tidligere. I en ikke så fjern fremtid vil identificering af falsk indhold genereret af deep learning modeller spille en central rolle i beskyttelsen af brugerne mod misinformation. Til dette formål blev der oprettet et datasæt med menneskelige og computergenererede overskrifter, og en brugerundersøgelse viste, at mennesker kun var i stand til at identificere de falske overskrifter i 47,8% af tilfældene. Men den mest nøjagtige automatiske tilgang, transformere, opnåede en samlet nøjagtighed på 85,7%, hvilket indikerer, at indhold genereret fra sprogmodeller kan filtreres præcist ud.', 'de': 'Falsche Informationen, die über das Internet und die sozialen Medien verbreitet werden, beeinflussen die öffentliche Meinung und Nutzeraktivität, während generative Modelle es ermöglichen, gefälschte Inhalte schneller und kostengünstiger als bisher zu generieren. In nicht allzu ferner Zukunft wird die Identifizierung gefälschter Inhalte, die durch Deep Learning-Modelle generiert werden, eine Schlüsselrolle beim Schutz der Nutzer vor Fehlinformationen spielen. Zu diesem Zweck wurde ein Datensatz mit menschlichen und computergenerierten Überschriften erstellt und eine Nutzerstudie ergab, dass Menschen die gefälschten Überschriften nur in 47,8% der Fälle identifizieren konnten. Der genaueste automatische Ansatz, Transformatoren, erreichte jedoch eine Gesamtgenauigkeit von 85,7%, was bedeutet, dass Inhalte, die aus Sprachmodellen generiert werden, genau herausgefiltert werden können.', 'id': 'Informasi palsu disebar melalui internet dan media sosial mempengaruhi pendapat publik dan aktivitas pengguna, sementara model generasi memungkinkan konten palsu untuk dihasilkan lebih cepat dan murah dari sebelumnya. Dalam masa depan yang tidak begitu jauh, mengidentifikasi isi palsu yang dihasilkan oleh model belajar dalam akan bermain peran kunci dalam melindungi pengguna dari salah informasi. Untuk tujuan ini, sebuah set data yang mengandung berita utama yang dihasilkan oleh manusia dan komputer dibuat dan sebuah studi pengguna menunjukkan bahwa manusia hanya mampu mengidentifikasi berita utama palsu dalam 47,8% kasus. Namun, pendekatan otomatis yang paling akurat, transformer, mencapai akurasi umum 85,7%, yang menunjukkan bahwa isi yang dihasilkan dari model bahasa dapat ditulis dengan akurasi.', 'fa': 'اطلاعات غلط توسط اینترنت و رسانه\u200cهای اجتماعی تأثیر فعالیت عمومی و فعالیت کاربر می\u200cکند، در حالی که مدل\u200cهای ژنتریفی محتوای غلط را به سرعت و ارزونتر تولید می\u200cکند تا از قبل ممکن باشد. در آینده خیلی دور نیست، شناسایی محتوای دروغگویی که توسط مدل های یادگیری عمیق تولید شده است، نقش کلید در حفاظت از کاربران از غلط سازی بازی می کند. برای این قسمت، یک مجموعه داده\u200cای که شامل سرخط\u200cهای انسان و کامپیوتر تولید شده است، ایجاد شد و یک مطالعه کاربر نشان داد که انسان تنها قادر به شناسایی سرخط\u200cهای دروغگویی در 47.8% از پرونده\u200cها بوده است. با این حال، بهترین دستور خودکار، تغییردهنده\u200cها، دقیقات کلی 85.7 درصد را به دست آوردند، نشان می\u200cدهند که محتوای تولید شده از مدل زبان می\u200cتواند دقیقاً فیلتر داده شود.', 'sw': 'Taarifa za uongo zinasambazwa kupitia mtandao wa intaneti na mitandao ya kijamii zinaathiri maoni na shughuli za watumiaji, wakati mifano ya kijamii inawezesha kujengwa maudhui bandia kwa haraka na rahisi kuliko ilivyowezekana. Katika mustakabali wa mbali sana, kutambua maudhui ya uongo yaliyotengenezwa na modeli za kujifunza za ndani yatacheza jukumu la msingi katika kuwalinda watumiaji kutokana na taarifa zisizo sahihi. Kwa mwisho huu, seti ya taarifa yenye vichwa vya habari vya binadamu na kompyuta vilitengenezwa na utafiti wa mtumiaji ulionyesha kuwa binadamu walikuwa na uwezo wa kutambua vichwa vya habari bandia katika asilimia 47.8 ya kesi hizo. Hata hivyo, mbinu sahihi zaidi za kujitegemea, mabadiliko, zilipata uhakika wa asilimia 85.7, ikionyesha kwamba maudhui yaliyotengenezwa kutoka kwa mifano ya lugha yanaweza kuchujwa kwa urahisi.', 'tr': 'Ýalňyş maglumat internet we sosial mediýaly ýüzünden geçirilýän maglumatlaryň halkara pikirleri we ullançylaryň etkinligine täsirleýär. Döwrülen nusgalar öňki mümkinçilikden has ýalňyş maklumatlary döretmäge çalt we uňsat döretm Ullançylary ýalňyş şekilde üýtgeden gelejek üçin ýalňyş maksadyny tanamak üçin ullançylary ýalňyş şeklinden goramak üçin wajyp roli oýnap bilýär. Bu nedenle insan ve bilgisayar üretilen başlıkları içeren veri seti oluşturdu ve kullanıcı araştırmaların insanların sadece sahte başlıkları 47.8% halinde tanımlayabildiğini gösterdi. Ýöne iň dogry awtomatik taýýarlar, üýtgewçiler 85.7%-yň bütin dogrylygyny ýetdi, dil nusgalaryndan döredilen maksadyň dogry filtere edilip görkezilip bilýärler.', 'af': "Verkeerde inligting wat deur die internet en sosiale media versprei het, be ïnvloor publieke opisie en gebruikeraktiviteit, terwyl genereerbare modele duidelike inhoud aktiveer om vinniger en korrek te genereer as voorheen moontlik te word. In die nie so afgeleë toekoms sal 'n sleutel rol speel om gebruikers te beskerm van verkeerde formasie te identifiseer falske inhoud wat deur diep leer modele genereer word nie. Na hierdie einde was 'n datastel bevat menslike en rekenaar genereerde koplyne geskep en 'n gebruiker studie aandui dat mense slegs die falske koplyne in 47.8% van die gevalle kon identifiseer. Maar die mees presies outomatiese toegang, transformeerders, het 'n heeltemal presisie van 85.7%, aanduidelik dat inhoud genereer van taal modelles presies kan filtereer word.", 'sq': 'Informacioni i gabuar i shpërndarë nëpërmjet internetit dhe medias sociale ndikon në opinionin publik dhe veprimtarinë e përdoruesit, ndërsa modelet gjenerative lejojnë përmbajtjen e rreme të gjenerohen më shpejt dhe më lirisht sesa ishte e mundur më parë. Në të ardhmen jo aq të largët, identifikimi i përmbajtjeve të rreme të gjeneruara nga modelet e mësimit të thellë do të luajë një rol kyç në mbrojtjen e përdoruesve nga informatat e gabuara. Për këtë qëllim, u krijua një sërë të dhënash që përmban titujt njerëzor dhe të gjeneruar nga kompjuteri dhe një studim i përdoruesve tregoi se njerëzit ishin në gjendje të identifikojnë titujt e rreme në 47.8% të rasteve. Megjithatë, qasja më e saktë automatike, transformuesit, arritën një saktësi të përgjithshme prej 85.7%, duke treguar se përmbajtja e gjeneruar nga modelet gjuhësore mund të filtrohet me saktësi.', 'am': 'የውሸት መረጃ በИнтернет እና ማኅበራዊ ሚዲያ የህዝብ አሳብ እና የተጠቃሚውን ተግባር ያጥቃቸዋል፤ ምንም እንኳ የውሸት ዓይነቶች ከቀድሞው ይልቅ ፈጥኖ ይችላል፡፡ ከሩቅ ፍጻሜ አይደለም፣ ጥልቅ ትምህርት ሞዴል የተፈጠረውን የሐሰት ጥያቄ ማድረግ በተጠቃሚዎች ከስህተት መረጃ በመጠበቅ የሚታወቅ የቁልፎ ሚዛን ይጫወታል፡፡ ወደዚህ ምክንያት የሰውና የኮምፒውተር አናት የያዘው ዳታተር ተፈጠረ እና ተጠቃሚው ትምህርት በ47.8 በመቶዎቹ የሐሰት አናት ማረጋገጥ ብቻ ይችላል፡፡ ነገር ግን የቋንቋ ምሳሌዎች የሚወለደውን ትክክለኛ ማድረግ በሙሉ ቁጥር 85.7 በመቶ አግኝቷል፡፡', 'hy': 'Ինտերնետի և սոցիալական լրատվամիջոցների միջոցով տարածված սխալ տեղեկատվությունը ազդում է հասարակական կարծիքին և օգտագործողների գործունեությունին, մինչդեռ սերունդային մոդելները հնարավորություն են տալիս կեղծ պարունակությունը ստեղծել ավելի արա Չայնքան հեռու ապագայում կեղծ պարունակությունը, որը ստեղծվում է խորը ուսումնասիրության մոդելների միջոցով, կխաղա կարևոր դեր օգտագործողների պաշտպանության մեջ սխալ տեղեկատվության դեպքում: Այս պատճառով ստեղծվել է մարդկային և համակարգչի կողմից ստեղծված գլխարկներ պարունակող տվյալների համակարգ, և օգտագործողների ուսումնասիրությունը ցույց տվեց, որ մարդիկ կարողացան միայն հայտնաբերել կեղծ գլխարկները դեպքերի 47.8 տոկո Այնուամենայնիվ, ամենաճշգրիտ ավտոմատիկ մոտեցումը, վերափոխողները, հասավ 85.7 տոկոսի ընդհանուր ճշգրիտության, ինչը ցույց է տալիս, որ լեզվի մոդելներից ստեղծված պարունակությունը ճշգրիտ կարող է ֆիլտրվել', 'az': 'ńįnternet v…ô sosyal media vasit…ôsil…ô yayńĪlmńĪŇü haqsńĪz m…ôlumat halkńĪ fikirl…ôri v…ô istifad…ô√ßi f…ôaliyy…ôtl…ôrini t…ôsir edir, lakin generativ modell…ôr sahte m…ôlumatlarńĪ …ôvv…ôlc…ô m√ľmk√ľn olduńüundan daha hńĪzlńĪ v…ô daha ucuz olaraq yaratmańüa qadir edirl…ôr. Bu q…ôd…ôr uzaq g…ôl…ôc…ôkd…ô, d…ôrin √∂yr…ônm…ô modell…ôrind…ôn yaratdńĪńüńĪ sahte m…ôlumatńĪ t…ôsdiql…ôm…ôk istifad…ô√ßil…ôri yanlńĪŇü informasiyadan qorumaq √ľ√ß√ľn anahtar rol√ľ oynayacaq. Bu s…ôb…ôbd…ô insan v…ô kompjuter yaratdńĪńüńĪ baŇülńĪqlar bar…ôsind…ôki veril…ôn quruluŇü yaradńĪldńĪ v…ô istifad…ô√ßi t…ôcr√ľb…ôsi insanlarńĪn yalnńĪz sahte baŇülńĪqlarńĪnńĪ 47.8% i√ßind…ô tanńĪdńĪqlarńĪnńĪ g√∂st…ôrdi. Lakin …ôn d√ľzg√ľn avtomatik t…ôrzim, transformat√ßńĪlar 85,7%-in b√ľt√ľn dońüruluńüuna nail oldular, dil modellerind…ôn √ľr…ôkl…ôn…ôn m…ôlumatlarńĪn d√ľzg√ľn filtrl…ônm…ôsini g√∂st…ôrir.', 'bn': 'ইন্টারনেট এবং সামাজিক প্রচার মাধ্যমের মাধ্যমে মিথ্যা তথ্য ছড়িয়ে পড়া হয়েছে জনগণের মতামত এবং ব্যবহারকারীদের কার্যক্রমের প্রভাব ফেলে দেয়, যদিও জে এই ভবিষ্যতে অনেক দূরবর্তী নয়, গভীর শিক্ষা মডেল দ্বারা তৈরি মিথ্যা বিষয়বস্তুকে চিহ্নিত করা হবে ভুল তথ্য থেকে ব্যবহারকার এই পর্যন্ত মানুষ এবং কম্পিউটার উৎপাদন করা শিরোনামের একটি ডাটাসেট তৈরি করা হয়েছে এবং একটি ব্যবহারকারী গবেষণা নির্দেশ দিয়েছে যে মানুষের মধ্যে ৪৭. তবে, সবচেয়ে সঠিক স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয় পদক্ষেপ, পরিবর্তন, ৮৫. ৭ শতাংশের সম্পূর্ণ সঠিকভাবে অর্জন করেছে, যারা নির্দেশ দেয় যে ভা', 'bs': 'Lažne informacije koje se šire preko interneta i društvenih medija utiču na javno mišljenje i aktivnost korisnika, dok generativni modeli omogućavaju da se lažni sadržaj proizvede brže i jeftinije nego što je prije bilo moguće. U ne tako dalekoj budućnosti, identifikacija lažnog sadržaja proizvedenog modelima dubokog učenja će imati ključnu ulogu u zaštiti korisnika od pogrešne informacije. Za taj cilj je stvorena grupa podataka koja sadrži ljudske i kompjuterske naslove, a studija korisnika ukazala na to da su ljudi samo u stanju identificirati lažne naslove u 47,8% slučajeva. Međutim, najprecizniji automatski pristup, transformatori, ostvarili su ukupnu tačnost od 85,7%, ukazujući na to da se sadržaj proizveden iz jezičkih modela može precizno filtrirati.', 'ca': "La falsa informació difundida a través d'Internet i els mitjans socials influeix en l'opinió pública i l'activitat dels usuaris, mentre que els models generadors permeten generar continguts falsos més ràpid i barat que abans. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation.  Per això, es va crear un conjunt de dades que contenia titulars humans i generats per ordinador i un estudi d'usuari va indicar que els humans només podien identificar els titulars falsos en un 47,8% dels casos. Però l'enfocament automàtic més precis, els transformadors, va aconseguir una precisió global del 85,7%, indicant que el contingut generat a partir de models lingüístics pot ser filtrat de manera precisa.", 'ko': '인터넷과 소셜 미디어를 통해 전파되는 허위 정보는 대중 여론과 사용자 활동에 영향을 미칠 수 있고 생성성 모델은 허위 내용의 생성 속도를 더욱 빠르고 원가를 낮춘다.멀지 않은 미래에 심도 있는 학습 모델이 생성한 허위 내용을 식별하는 것은 사용자가 잘못된 정보의 영향을 받지 않도록 보호하는 데 관건적인 역할을 발휘할 것이다.이를 위해 인공과 컴퓨터가 제목을 생성하는 데이터 집합을 만들었는데 한 사용자 연구에 따르면 47.8%의 사례에서 인류는 가짜 제목만 식별할 수 있다고 한다.그러나 가장 정확한 자동 방법인transformers의 전체 정확도는 85.7%로 언어 모델에서 생성된 내용이 정확하게 필터될 수 있음을 나타낸다.', 'cs': 'Falešné informace šířené prostřednictvím internetu a sociálních médií ovlivňují veřejné mínění a aktivitu uživatelů, zatímco generativní modely umožňují vytvářet falešný obsah rychleji a levněji, než bylo dříve možné. V nedaleké budoucnosti bude identifikace falešného obsahu generovaného modely hlubokého učení hrát klíčovou roli při ochraně uživatelů před dezinformací. Za tímto účelem byla vytvořena datová sada obsahující lidské a počítačově generované titulky a uživatelská studie ukázala, že lidé byli schopni identifikovat falešné titulky pouze v 47,8% případů. Nicméně nejpřesnější automatický přístup transformátory dosáhl celkové přesnosti 85,7%, což znamená, že obsah generovaný z jazykových modelů lze přesně odfiltrovat.', 'et': 'Interneti ja sotsiaalmeedia kaudu leviv vale teave mõjutab avalikku arvamust ja kasutajate tegevust, samas kui generatiivsed mudelid võimaldavad võltsitud sisu genereerida kiiremini ja odavamalt kui varem oli võimalik. Mitte nii kaugel tulevikus mängib sügavõppemudelite loodud võltsitud sisu tuvastamine võtmerolli kasutajate kaitsmisel valeteabe eest. Selleks loodi inim- ja arvutipõhiseid pealkirju sisaldav andmekogum ning kasutajauuring näitas, et inimesed suutsid valepealkirju tuvastada ainult 47,8% juhtudest. Kuid kõige täpsem automaatne lähenemine, trafod, saavutas üldise täpsuse 85,7%, mis näitab, et keelemudelitest loodud sisu saab täpselt filtreerida.', 'fi': 'Internetissä ja sosiaalisessa mediassa levitetty väärä tieto vaikuttaa yleiseen mielipiteeseen ja käyttäjien toimintaan, kun taas generatiiviset mallit mahdollistavat väärennetyn sisällön tuottamisen nopeammin ja edullisemmin kuin aiemmin oli ollut mahdollista. Ei niin kaukaisessa tulevaisuudessa syväoppimismallien tuottaman väärennetyn sisällön tunnistaminen on avainasemassa käyttäjien suojaamisessa vääriltä tiedoilta. Tätä varten luotiin aineisto, joka sisälsi ihmisten ja tietokoneiden tuottamia otsikoita, ja käyttäjätutkimus osoitti, että ihmiset pystyivät tunnistamaan väärennetyt otsikot vain 47,8 prosentissa tapauksista. Tarkin automaattinen lähestymistapa, muuntajat, saavutti kuitenkin 85,7 prosentin kokonaistarkkuuden, mikä osoittaa, että kielimallien tuottama sisältö voidaan suodattaa tarkasti.', 'he': 'False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible.  בעתיד לא כל כך רחוק, זיהוי תוכן מזויף שנוצר על ידי דוגמני למידה עמוקה ישחק תפקיד מפתח להגן על המשתמשים מפני מידע לא נכון. למטרה זו, קבוצת נתונים שמכילה כותרות בני אדם ומחשב יוצרים, וחקר משתמש מצביע על כך שבני אדם הצליחו לזהות רק את הכותרות המזויפות ב-47.8% מהמקרים. בכל אופן, הגישה האוטומטית המדויקת ביותר, משתנים, השיגה מדויקת כללית של 85.7%, שמצביעה כי תוכן שנוצר מדוגמני שפה יכול להיות מסנן בדיוק.', 'ha': '@ info: status Daga gabanin da ba ta nĩsa ba, zai gane maɓallin ƙarya wanda aka ƙãga da misãlai masu sani na ƙari, zai yi amfani da maɓalli cikin tsari ga masu amfani da tsari daga tsarin information na ɓata. To, zuwa wannan, an halitta wani danganta mai ƙunsa da zanen tsari na mutum da kwamfyuta wanda aka haife shi na mutum kuma an ƙididdige shi na wani matsayi mai amfani da shi, yana nũna cewa mutane sun iya iya gane kichin ƙarya ne cikin 47.8% daga kashẽwa. A lokacin da aka gaskata mafarin hanyor farat-farat ɗaya, masu shige, na sami taƙaitar rasmi na 85,7%, kuma yana nuna cewa an filtera maɓallin tsarin da aka ƙãga daga misalin ayuka na harshe kafin.', 'sk': 'Lažne informacije, ki se širijo prek interneta in družbenih medijev, vplivajo na javno mnenje in uporabniško aktivnost, generativni modeli pa omogočajo hitrejše in poceni ustvarjanje lažnih vsebin, kot je bilo mogoče prej. V ne tako daljni prihodnosti bo identifikacija lažnih vsebin, ki jih ustvarijo modeli globokega učenja, igrala ključno vlogo pri zaščiti uporabnikov pred napačnimi informacijami. V ta namen je bil ustvarjen nabor podatkov, ki vsebuje človeške in računalniško ustvarjene naslovnice, študija uporabnikov pa je pokazala, da so ljudje lahko prepoznali lažne naslovnice le v 47,8% primerov. Vendar pa je najbolj natančen avtomatski pristop, transformatorji, dosegel splošno natančnost 85,7%, kar kaže, da je vsebino, ustvarjena iz jezikovnih modelov, mogoče natančno filtrirati.', 'jv': 'default:LTR Jejaring Mbok iki, sampeyan dataset sing nganggo perusahaan lan komputer bukalih basa sing nggawe ngubah basa sing dirangkat wong liyane, wong ke wong liyane wis nguasai perusahaan iso nggawe barang langgar sampeyan tuku nambah sing oleh dumateng, ning 75.8% Kasunyatan. politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'False information spread through the Internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and cheaper than had been previously possible. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation. མཇུག་གི་དུས་ལ། མིང་དང་རྩིས་འཁོར་གྱི་བཟོ་བརྗོད་ཀྱི་མགོ་ཡིག ཡིན་ནའང་། རང་འགུལ'}
{'en': 'Improving Cross-Domain Hate Speech Detection by Reducing the False Positive Rate', 'es': 'Mejorar la detección de discursos de odio entre dominios mediante la reducción de la tasa de falsos positivos', 'pt': 'Melhorando a detecção de discurso de ódio entre domínios reduzindo a taxa de falsos positivos', 'ar': 'تحسين اكتشاف الكلام الذي يحض على الكراهية عبر المجالات من خلال تقليل المعدل الإيجابي الكاذب', 'fr': 'Améliorer la détection des discours haineux interdomaines en réduisant le taux de faux positifs', 'hi': 'गलत सकारात्मक दर को कम करके क्रॉस-डोमेन हेट स्पीच डिटेक्शन में सुधार', 'ja': '偽陽性率の低減によるクロスドメインヘイトスピーチ検出の改善', 'ru': 'Улучшение междоменного обнаружения ненавистнической речи за счет снижения ложноположительной частоты', 'zh': '因降误报率改进跨域仇言检测', 'ga': 'Brath Caint na Fuathach Tras Fearainn a Fheabhsú tríd an Ráta Bréagach Dearfach a Laghdú', 'hu': 'A tartományok közötti gyűlölet beszédfelismerésének javítása a hamis pozitív arány csökkentésével', 'el': 'Βελτίωση της ανίχνευσης μίσους μεταξύ των τομέων με τη μείωση του ψευδούς θετικού ποσοστού', 'it': 'Miglioramento della rilevazione vocale di odio tra domini riducendo il tasso di falsi positivi', 'kk': 'Қос- доменге қарсы тілі анықтау үшін жарамсыз позитивті жылдамдығын азайтып', 'lt': 'Gerinti neapykantos kalbos aptikimą įvairiuose domeniuose mažinant klaidingą teigiamą lygį', 'mk': 'Подобрување на детектирањето на говорот за омраза во меѓудомените со намалување на лажната позитивна стапка', 'ml': 'ക്രോസ്- ഡോമെന്\u200d വെറുപ്പുള്ള സംസാരം ഡിറ്ററിറ്റീഷന്\u200d മുന്\u200dകൂട്ടുന്നു', 'ms': 'Perbaikan Pengesanan Ucapan Kebencian Salib Domain dengan Mengurangi Kadar Positif Salah', 'mt': 'Titjib fid-Detezzjoni ta’ Kellem ta’ Mibegħda Cross-Domain billi titnaqqas ir-Rata Falsa Pożittiva', 'mn': 'Хөгжлийн дулаарлын хэлэлцээг сайжруулж буруу эерэг дүнг багасгаж', 'no': 'Å forbetra oppdaging av trykk- domene ved å redusera feil positivt verdi', 'pl': 'Poprawa wykrywania mowy nienawiści między domenami poprzez zmniejszenie częstotliwości fałszywie dodatniej', 'ro': 'Îmbunătățirea detectării discursului de ură între domenii prin reducerea ratei de fals pozitive', 'sr': 'Poboljšanje otkrivanja reči mržnje preko domena smanjujući lažnu pozitivnu stopu', 'si': 'ක්\u200dරොස්- ඩෝමේන් විරෝධ කතාව හොයාගන්න බොරු විරෝධ විරෝධ විශ්ලේෂණය වැඩ කරන්න', 'so': 'Improvement Cross-Domain Hate Speech by reducing the False Positive Rate', 'sv': 'Förbättra detektering av hat över domäner genom att minska den falska positiva frekvensen', 'ur': 'کرس-ڈومین عداوت کی بات شناسایی کی عمدہ کرتی ہے', 'ta': 'பொய் நேர விகிதத்தை குறைக்கும் மூலம் கிருஸ்- டோமைன் வெறுப்பு பேச்சு கண்டுபிடிப்பை மேம்படுத்து', 'ka': 'უფრო მეტი დომინის წარმოადგენების განსახულების განსახულების გასაკეთება, შემცირებით False Positive Rate', 'uz': 'Name', 'vi': 'Tăng cường độ phát hiện ghét miền chéo bằng cách giảm tỷ lệ dương sai', 'da': 'Forbedring af registrering af had på tværs af domæner ved at reducere den falske positive frekvens', 'nl': 'Verbetering van de detectie van haatspraak tussen domeinen door het verminderen van de valse positieve frequentie', 'id': 'Menembangkan Deteksi Bicara Benci Cross-Domain Dengan Mengurangi Kadar Positif Salah', 'de': 'Verbesserung der domänenübergreifenden Hate Speech Erkennung durch Reduzierung der False Positive Rate', 'hr': 'Poboljšanje otkrivanja razgovora o mržnji preko domena smanjujući lažnu pozitivnu stopu', 'fa': 'توسط کاهش میزان مثبت غلط', 'ko': '오보율을 낮추어 전역 증오 음성 검사를 개선하다', 'bg': 'Подобряване на междудомейнното откриване на реч на омразата чрез намаляване на честотата на фалшивите позитивни', 'sw': 'Kuboresha Kuchukia Hotuba ya Kuzungumza na Kupunguza kiwango cha uongo', 'af': 'Verbeter Kruis- Domein Hate Spraak Opdekking deur die Verkeerde Positive Rate te verminder', 'sq': 'Duke përmirësuar zbulimin e fjalëve të urrejtjes në mes të domeneve duke reduktuar normën e gabuar pozitive', 'hy': 'Խոսքի ատելության բացահայտումների բարելավումը կեղծ դրական մակարդակի նվազեցնելով', 'az': '壉饴愠偯穩瑩瘠仃뙱獡湬쒱쒟쒱⁋쎼쎧쎼歬즙湤楲즙渠壉饴愠䑯浥湡⁓쎶竃뱮쎼⁋旅齦整淉饳椊', 'bs': 'Poboljšanje otkrivanja razgovora o mržnji preko domena smanjujući lažnu pozitivnu stopu', 'tr': 'Ýalňyş Pozitiwleri azaltyp, çokdan Hata sözlerini gowlaşdyrmak', 'ca': 'Improving Cross-Domain Hate Speech Detection by Reducing the False Positive Rate', 'am': 'የውሸት ስህተት አካሄዱን በማጎድል የቆጣጠር ቃላትን አቀማመጥ', 'cs': 'Zlepšení detekce nenávisti mezi různými doménami snížením falešně pozitivní míry', 'fi': 'Parannetaan verkkotunnusten välistä vihapuheentunnistusta vähentämällä väärien positiivisten tulosten määrää', 'et': 'Domeenidevahelise vihakõne tuvastamise parandamine valepositiivsete esinemissageduse vähendamise teel', 'bn': 'মিথ্যা পজিটিভ হার কমানোর মাধ্যমে ক্রস-ডোমেইন বাক বক্তৃতাকে ঘৃণা করা হয়েছে', 'jv': 'ProgressBarUpdates', 'sk': 'Izboljšanje meddomenskega zaznavanja sovražnega govora z zmanjšanjem deleža lažnih pozitivnih', 'ha': 'KCharselect unicode block name', 'he': 'שיפור את גילוי השנאה במערכת השטח על ידי שינוי מעצב חיובי שגוי', 'bo': 'Cross-Domain Hate Speech Detection by Reducing the False Positive Rate'}
{'en': 'Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results. One of the challenges of such automated approaches   namely recent deep learning models   is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention. We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble. The improvement is mainly due to a reduction of the false positive rate.', 'fr': "La détection des discours haineux est un domaine de recherche en pleine expansion avec une variété d'approches récemment proposées qui ont permis de pousser les résultats les plus récents. L'un des défis de ces approches automatisées, à savoir les modèles récents de deep learning, est le risque de faux positifs (c'est-à-dire de fausses accusations), qui peuvent entraîner un blocage excessif ou la suppression de contenus de réseaux sociaux inoffensifs dans les applications nécessitant peu d'intervention des modérateurs. Nous évaluons les modèles d'apprentissage profond à la fois dans des conditions de détection de discours haineux dans le domaine et interdomaines, et nous introduisons une approche SVM qui permet d'améliorer considérablement les résultats de pointe lorsqu'elle est combinée aux modèles d'apprentissage profond par le biais d'un ensemble simple de vote majoritaire. L'amélioration est principalement due à la réduction du taux de faux positifs.", 'ar': 'يعد اكتشاف الكلام الذي يحض على الكراهية مجالًا متناميًا للبحث مع مجموعة متنوعة من الأساليب المقترحة مؤخرًا والتي سمحت بدفع أحدث النتائج. تتمثل إحدى تحديات مثل هذه الأساليب الآلية - أي نماذج التعلم العميق الحديثة - في خطر الإيجابيات الكاذبة (أي الاتهامات الكاذبة) ، والتي قد تؤدي إلى الإفراط في حظر أو إزالة محتوى الوسائط الاجتماعية غير الضار في التطبيقات مع تدخل بسيط من الوسيط. نقوم بتقييم نماذج التعلم العميق تحت ظروف الكشف عن الكلام الذي يحض على الكراهية داخل المجال وعبر المجالات ، ونقدم نهج SVM الذي يسمح بتحسين النتائج الحديثة بشكل كبير عند دمجها مع نماذج التعلم العميق من خلال أغلبية بسيطة فرقة التصويت. يرجع التحسن بشكل أساسي إلى انخفاض المعدل الإيجابي الخاطئ.', 'es': 'La detección del discurso de incitación al odio es un campo de investigación en crecimiento activo con una variedad de enfoques recientemente propuestos que permitieron impulsar los resultados más avanzados. Uno de los desafíos de estos enfoques automatizados, es decir, los modelos recientes de aprendizaje profundo, es el riesgo de falsos positivos (es decir, falsas acusaciones), que pueden conducir a un bloqueo excesivo o a la eliminación de contenido inofensivo de redes sociales en aplicaciones con poca intervención del moderador. Evaluamos los modelos de aprendizaje profundo tanto en condiciones de detección de discurso de odio dentro del dominio como entre dominios, e introducimos un enfoque de SVM que permite mejorar significativamente los resultados de vanguardia cuando se combina con los modelos de aprendizaje profundo a través de un conjunto simple de votación por mayoría. La mejora se debe principalmente a una reducción de la tasa de falsos positivos.', 'pt': 'A detecção de discurso de ódio é um campo de pesquisa em crescimento ativo com uma variedade de abordagens propostas recentemente que permitiram impulsionar os resultados de última geração. Um dos desafios de tais abordagens automatizadas – ou seja, modelos recentes de deep learning – é o risco de falsos positivos (ou seja, falsas acusações), que podem levar ao bloqueio excessivo ou remoção de conteúdo de mídia social inofensivo em aplicativos com pouca intervenção do moderador. Avaliamos os modelos de deep learning sob condições de detecção de discurso de ódio no domínio e entre domínios e introduzimos uma abordagem SVM que permite melhorar significativamente os resultados de última geração quando combinados com os modelos de deep learning por meio de uma simples maioria- conjunto votante. A melhora deve-se principalmente à redução da taxa de falsos positivos.', 'zh': '恨言检测是一切研究领域,近发诸方,可以推动最先进。 此自动化法者(近之深学模形)之一误报(即虚指)之险,庶几于几于无执事之间,沮损应用程序之社交媒体也。 域内与跨域仇言相参,而引入一SVM,其法可以简易者多投票合而用之时显改善最先进也。 此改善者,误报率之降也。', 'ru': 'Обнаружение ненавистнической речи является активно растущей областью исследований с различными недавно предложенными подходами, которые позволили подтолкнуть к современным результатам. Одной из проблем таких автоматизированных подходов, а именно недавних моделей глубокого обучения, является риск ложноположительных (т.е. ложных обвинений), которые могут привести к чрезмерной блокировке или удалению безвредного контента социальных сетей в приложениях с небольшим вмешательством модератора. Мы оцениваем модели глубокого обучения как в условиях внутридоменного, так и междоменного распознавания ненавистнической речи, а также внедряем подход виртуальной машины защиты, который позволяет значительно улучшить современные результаты в сочетании с моделями глубокого обучения за счет простого мажоритарного ансамбля. Улучшение в основном связано со снижением уровня ложноположительных результатов.', 'ja': 'ヘイトスピーチ検出は、最新の結果を推し進めることができる様々な最近提案されたアプローチを備えた、積極的に成長する研究分野です。このような自動化されたアプローチ、すなわち最近の深層学習モデルの課題の1つは、モデレーターの介入がほとんどないアプリケーションの無害なソーシャルメディアコンテンツのオーバーブロックまたは削除につながる可能性のある誤検知（すなわち、誤検知）のリスクです。私たちは、ドメイン内およびクロスドメインの両方のヘイトスピーチ検出条件下でディープラーニングモデルを評価し、単純な多数決アンサンブルを介してディープラーニングモデルと組み合わせると、最先端の結果を大幅に改善することができるSVMアプローチを導入します。改善は主に偽陽性率の低下によるものである。', 'hi': 'हेट स्पीच डिटेक्शन हाल ही में प्रस्तावित दृष्टिकोणों की एक किस्म के साथ अनुसंधान का एक सक्रिय रूप से बढ़ता क्षेत्र है जिसने अत्याधुनिक परिणामों को धक्का देने की अनुमति दी है। इस तरह के स्वचालित दृष्टिकोणों की चुनौतियों में से एक - अर्थात् हाल के गहरे सीखने के मॉडल - झूठे सकारात्मक (यानी, झूठे आरोप) का जोखिम है, जो छोटे मॉडरेटर हस्तक्षेप के साथ अनुप्रयोगों में हानिरहित सोशल मीडिया सामग्री को ओवर-ब्लॉकिंग या हटाने का कारण बन सकता है। हम इन-डोमेन और क्रॉस-डोमेन हेट स्पीच डिटेक्शन स्थितियों दोनों के तहत गहरे सीखने के मॉडल का मूल्यांकन करते हैं, और एक एसवीएम दृष्टिकोण पेश करते हैं जो एक साधारण बहुमत-मतदान पहनावा के माध्यम से गहरे सीखने के मॉडल के साथ संयुक्त होने पर अत्याधुनिक परिणामों में काफी सुधार करने की अनुमति देता है। सुधार मुख्य रूप से झूठी सकारात्मक दर में कमी के कारण है।', 'ga': 'Is réimse taighde atá ag fás go gníomhach é braiteadh fuatha cainte le cineálacha cur chuige éagsúla a moladh le déanaí a cheadaigh torthaí úrscothacha a bhrú chun cinn. Ceann de na dúshláin a bhaineann le cineálacha cur chuige uathoibrithe den sórt sin – is iad sin múnlaí domhainfhoghlama le déanaí – is ea an baol go mbeidh rudaí bréagacha dearfacha (i.e. líomhaintí bréagacha), as a d’fhéadfadh ró-bhlocáil nó baint a bhaint as ábhar meán sóisialta neamhdhíobhálach i bhfeidhmchláir ar bheagán idirghabhála modhnóra. Déanaimid measúnú ar mhúnlaí domhainfhoghlama faoi choinníollacha braite fuathchainte in-fhearainn agus tras-fearainn, agus tugtar isteach cur chuige SVM a cheadaíonn feabhas suntasach a chur ar na torthaí úrscothacha nuair a chuirtear iad le chéile leis na samhlacha foghlama domhain trí thromlach simplí-. ensemble vótála. Tá an feabhas go príomha mar gheall ar laghdú ar an ráta dearfach bréagach.', 'ka': 'მყვარების განახლება აკრძალურად განვითარებულია სწორედ განვითარებული პასუხი, რომელიც მხოლოდ განახლებელია განსხვავებული მიზეზები, რომელიც შესაძლებელია გაუძლებელია ასეთი ავტომატიკური მოწყობილობის ერთი წინაწყვეტი – მართლაც ახლა ძალიან ძალიან სწავლების მოდელები – არის მარტივი პოზიტიგების (მაგალითად, მართლაც მარტივი დაკავშირებების) რისიკი, რომელიც შეიძლება გადაბლოკურებ ჩვენ ძალიან სწავლებელი მოდელების შესახებ დემომინში და კრესი დემომინის განსახულების შესახებ და SVM მოწყობილობა, რომელიც მნიშვნელოვანად შეუძლებელია გაუკეთოთ სწავლებელი მოდელების შესახებ, როდესაც ძალიან გაუკეთებ უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფ', 'it': "Il rilevamento del discorso d'odio è un campo di ricerca in crescita attiva con una varietà di approcci recentemente proposti che hanno permesso di spingere i risultati all'avanguardia. Una delle sfide di tali approcci automatizzati – vale a dire i recenti modelli di deep learning – è il rischio di falsi positivi (cioè false accuse), che possono portare a sovraccarico o rimozione di contenuti innocui dei social media in applicazioni con scarso intervento da parte dei moderatori. Valutiamo modelli di deep learning sia in-domain che cross-domain hate speech detection, e introduciamo un approccio SVM che consente di migliorare significativamente i risultati all'avanguardia quando combinati con i modelli di deep learning attraverso un semplice ensemble di voto a maggioranza. Il miglioramento è dovuto principalmente ad una riduzione del tasso di falsi positivi.", 'kk': 'Жуырдағы сөздерді анықтау - жуырдағы жуырдағы әртүрлі арқылы зерттеу өрісі. Бұл әртүрлі әртүрлі әртүрлі арқылы зерттеу өрісі. Бұл автоматты түрлендірілген жағдайдың бірі - бұл жаңа түсінік оқыту үлгілері - жалғыз оқыту үлгілерінің (т.е. жалғыз жағдайдың тәртібі), бұл қолданбаларда қауіпсіз социалдық медиақтар мазмұнын бұға Біз домендегі және көпшілік домендегі және көпшілік сөйлесу шарттарының алдындағы үлкен оқыту үлгілерін бағалаймыз, және SVM жағдайын таңдаймыз, ол үлкен оқыту үлгілерімен қарапайым көпшілік дауыс Жақсарту - негізінде дұрыс оң жақсы жылдамдығын азайту үшін.', 'lt': 'Neapykantos kalbos aptikimas yra aktyviai auganti mokslinių tyrimų sritis su įvairiais neseniai pasiūlytais metodais, leidžiančiais paskatinti naujausius rezultatus. Vienas i š tokių automatizuotų metodų iššūkių – būtent naujausių gilaus mokymosi modelių – yra klaidingų teigiamų reiškinių (t. y. klaidingų kaltinimų) rizika, dėl kurios gali būti pernelyg blokuojamas arba pašalinamas žalingas social in ės žiniasklaidos turinys taikant maža i vidutinio poveikio priemones. Vertiname gilaus mokymosi modelius tiek dominuojančiomis, tiek tarpdominuojančiomis neapykantos kalbos aptikimo sąlygomis, ir įgyvendiname SVM metodą, kuris leidžia gerokai pagerinti pažangiausius rezultatus, derinant juos su gilaus mokymosi modeliais per paprastą balsavimo dauguma rinkinį. Šis pagerėjimas daugiausia susijęs su klaidingo teigiamo rodiklio sumažėjimu.', 'hu': 'A gyűlölet beszédfelismerés egy aktívan növekvő kutatási terület, amely különböző nemrégiben javasolt megközelítésekkel rendelkezik, amelyek lehetővé tették a legkorszerűbb eredmények előmozdítását. Az ilyen automatizált megközelítések egyik kihívása – nevezetesen a legújabb mélytanulási modellek – a hamis pozitívumok (azaz hamis vádak) kockázata, amely az ártalmatlan közösségi média tartalmak túlzott blokkolásához vagy eltávolításához vezethet olyan alkalmazásokban, amelyekben kevés moderátor beavatkozás van. Mélytanulási modelleket értékelünk mind a domain belüli, mind a domain közötti gyűlöletbeszédfelismerési körülmények között, és olyan SVM megközelítést vezetünk be, amely lehetővé teszi, hogy jelentősen javítsuk a legkorszerűbb eredményeket, ha kombináljuk a mélytanulási modellekkel egy egyszerű többségi szavazási együttesen keresztül. A javulás elsősorban a hamis pozitív arány csökkenésének köszönhető.', 'mk': 'Детектирањето на говорот на омраза е активно растечко поле на истражување со различни неодамна предложени пристапи кои дозволија да ги притиснат најсовремените резултати. One of the challenges of such automated approaches – namely recent deep learning models – is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention.  Ние ги проценуваме моделите на длабоко учење како под условите за детекција на говорот на омраза во домен, така и во крстодомен, и воведуваме пристап на СВМ кој овозможува значително подобрување на најновите резултати кога се комбинира со моделите на длабоко учење преку едноставен ансембл со мноз Подобрувањето е главно поради намалувањето на лажната позитивна стапка.', 'ms': 'Pengesanan ucapan benci adalah bidang penyelidikan yang berkembang secara aktif dengan pelbagai pendekatan yang diusulkan baru-baru ini yang dibenarkan untuk mendorong keputusan-keputusan-state-of-the-art. Salah satu cabaran pendekatan automatik seperti in i - iaitu model belajar yang mendalam yang baru-baru ini - adalah risiko positif palsu (iaitu tuduhan palsu), yang mungkin menyebabkan penghalangan berlebihan atau pembuangan kandungan media sosial yang tidak berbahaya dalam aplikasi dengan intervensi moderator sedikit. Kami menilai model pembelajaran dalam kedua-dua dalam kondisi pengesan ucapan kebencian dalam domain dan cross-domain, dan memperkenalkan pendekatan SVM yang membolehkan meningkatkan keputusan state-of-the-art secara signifikan apabila digabungkan dengan model pembelajaran dalam melalui kumpulan pemilihan kebanyakan sederhana. Perbaikan terutama disebabkan pengurangan kadar positif palsu.', 'mt': 'Id-detezzjoni tad-diskors tal-mibegħda hija qasam ta’ riċerka li qed jikber b’mod attiv b’varjetà ta’ approċċi proposti reċentement li ppermettew li jimbuttaw ir-riżultati l-aktar avvanzati. Waħda mill-isfidi ta’ approċċi awtomatizzati bħal dawn – jiġifieri mudelli riċenti ta’ tagħlim profond – hija r-riskju ta’ pożittivi foloz (jiġifieri akkużi foloz), li jistgħu jwasslu għal imblukkar żejjed jew tneħħija ta’ kontenut tal-midja soċjali bla ħsara f’applikazzjonijiet b’intervent moderatur żgħir. Aħna jevalwaw mudelli ta’ tagħlim profond kemm f’kundizzjonijiet ta’ detezzjoni tad-diskors ta’ mibegħda fid-dominju kif ukoll f’kundizzjonijiet ta’ detezzjoni tad-diskors ta’ mibegħda f’diversi dominji, u nintroduċu approċċ SVM li jippermetti li jittejbu b’mod sinifikanti r-riżultati l-aktar avvanzati meta kkombinati mal-mudelli ta’ tagħlim profond permezz It-titjib huwa prinċipalment dovut għal tnaqqis fir-rata pożittiva foloz.', 'ml': 'Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results.  ഇത്തരം സ്വതന്ത്രീകരിക്കപ്പെട്ട സാമൂഹ്യത്തിന്റെ ചോദ്യങ്ങളില്\u200d ഒരു വിലാസങ്ങളില്\u200d- അടുത്തുതന്നെ ആഴത്തില്\u200d പഠിക്കുന്ന മോഡല്\u200d- അസത്യസ്ഥാനങ്ങള്\u200dക്കുള്ള അപകടം ആണ ആഴത്തെ പഠിപ്പിക്കുന്ന മോഡലുകളെയും ക്രിസ്റ്റമെന്\u200d വാക്ക് കണ്ടുപിടിക്കുന്ന അവസ്ഥയ്ക്ക് കീഴില്\u200d നിന്നും നമ്മള്\u200d വിലയിക്കുന്നു. എസ്\u200cവിഎമിന്റെ പ്രോഗത്തില്\u200d നിന്ന മെച്ചപ്പെടുത്തുന്നത് പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു തെറ്റായ പ്രേതികമായ വില കുറച്ച', 'mn': 'Харамсалтай яриаг олох нь саяхан олон санал өгсөн арга барилгуудтай ажилладаг судалгааны талбар юм. Ийм автоматжуулсан ойлголтын нэг асуудал нь - нэрлэдэг нь саяхан гүн гүнзгий суралцах загваруудын нэг нь буруу эерэг байдал (яг л буруу шүүмжлэг) болох эрсдэл юм. Энэ нь бага зэрэгцүүлэгч оролцох хэрэгслээр хохиромжгүй нийгмийн Бид гүн гүнзгий суралцах загваруудыг холбоотой, холбоотой хэлэлцүүлэх нөхцөл байдлын доор холбоотой, мөн ихэнх хэлэлцүүлэх нөхцөл байдлын доор холбоотой, үндсэн суралцах загваруудыг ашиглах боломжтой SVM арга Хамгийн сайжруулалт нь буруу эерэг хурдыг багасгах учраас юм.', 'no': 'Oppdaging av hatt-tale er eit aktivt vekst forskningsfelt med fleire nyleg foreslått tilnærmingar som tillater å trykke kunsttilstanden. Ein av utfordringane av slike automatiske tilnærmingar – i det siste tidlegare dyppa læringsmodeller – er e in risiko for falske positiv (t.d. falske akusasjonar), som kan føre til overblokkering eller fjerning av skadelige sosiale media-innhaldet i programmer med lite moderatorintervensjon. Vi evaluerer dype læringsmodeller både under inndomene og krysdomene hater taleoppdagingsvilkåra, og introduserer ein SVM-tilnærming som tillater å betydelig forbedra kunstengstilstanden når det kombinerer med dei dype læringsmodelane gjennom ein enkel største stemmingsensemble. Forbetringa er hovudsakelig på grunn av å redusera feil positivt rate.', 'pl': 'Wykrywanie mowy nienawiści jest aktywnie rozwijającą się dziedziną badań z różnorodnymi ostatnio proponowanymi podejściami, które pozwoliły na osiągnięcie najnowocześniejszych wyników. Jednym z wyzwań takich zautomatyzowanych podejść – czyli najnowszych modeli głębokiego uczenia – jest ryzyko fałszywych pozytywnych (tzn. fałszywych oskarżeń), które mogą prowadzić do nadmiernego blokowania lub usunięcia nieszkodliwych treści mediów społecznościowych w aplikacjach z małą interwencją moderatora. Oceniamy modele głębokiego uczenia zarówno w warunkach wykrywania mowy nienawiści wewnątrz domeny, jak i między domenami oraz wprowadzamy podejście SVM, które pozwala znacząco poprawić najnowocześniejsze wyniki w połączeniu z modelami głębokiego uczenia poprzez prosty zespół głosowania większością. Poprawa wynika głównie ze zmniejszenia wskaźnika fałszywie dodatniego.', 'ro': 'Detectarea discursului de ură este un domeniu de cercetare în creștere activă, cu o varietate de abordări propuse recent, care au permis să împingă rezultatele de ultimă oră. Una dintre provocările unor astfel de abordări automatizate – și anume modelele recente de învățare profundă – este riscul de fals pozitive (de exemplu, acuzații false), care pot duce la blocarea sau eliminarea conținutului inofensiv al rețelelor de socializare în aplicații cu o intervenție redusă a moderatorului. Evaluăm modele de învățare profundă atât în condiții de detectare a discursului la ură în domeniu, cât și în condiții cross-domeniu și introducem o abordare SVM care permite îmbunătățirea semnificativă a rezultatelor de ultimă oră atunci când sunt combinate cu modelele de învățare profundă printr-un ansamblu simplu de vot majoritar. Îmbunătățirea se datorează în principal reducerii ratei fals pozitive.', 'el': 'Η ανίχνευση της ομιλίας μίσους είναι ένα ενεργό αναπτυσσόμενο πεδίο έρευνας με μια ποικιλία προσφάτως προτεινόμενων προσεγγίσεων που επέτρεψαν να προωθήσουν τα αποτελέσματα τελευταίας τεχνολογίας. Μια από τις προκλήσεις τέτοιων αυτοματοποιημένων προσεγγίσεων – δηλαδή των πρόσφατων μοντέλων βαθιάς μάθησης – είναι ο κίνδυνος ψευδών θετικών (δηλ. ψευδών κατηγοριών), οι οποίες μπορεί να οδηγήσουν σε υπερβολικό αποκλεισμό ή αφαίρεση ακίνδυνου περιεχομένου κοινωνικών μέσων σε εφαρμογές με ελάχιστη παρέμβαση συντονιστή. Αξιολογούμε μοντέλα βαθιάς μάθησης τόσο υπό συνθήκες ανίχνευσης ρητορικής μίσους εντός όσο και μεταξύ τομέων και εισάγουμε μια προσέγγιση που επιτρέπει να βελτιωθούν σημαντικά τα αποτελέσματα τελευταίας τεχνολογίας όταν συνδυαστούν με τα μοντέλα βαθιάς μάθησης μέσω ενός απλού συνόλου ψηφοφορίας πλειοψηφίας. Η βελτίωση οφείλεται κυρίως στη μείωση του ψευδώς θετικού ποσοστού.', 'si': 'Hate කතා පරීක්ෂණය තමයි ක්\u200dරියාත්මක විශ්වාසයෙන් පරීක්ෂණයේ ප්\u200dරමාණයක් තියෙන්නේ විවිධ ප්\u200dරවිධානයක් තියෙන්නේ  මේ ස්වයංක්\u200dරියාත්මක විධානයේ අවශ්\u200dයයෙන් එක්ක - අන්තිමට ගොඩක් ඉගෙන ගන්න ප්\u200dරමාණයක් - බොරු විධානයක් අවශ්\u200dයයක් (ඉතින්, බොරු විධානයක්), ඒකෙන අපි ගොඩක් ඉගෙනීම් මොඩල් අඩුයුම් සහ ක්\u200dරිස්ඩෝමින් විරුද්ධ කතාව හොයාගන්න අවස්ථාවක් පරීක්ෂණය සඳහා ගොඩක් ඉගෙනීම් මොඩල් එක්ක සම්පූර්ණ බොහ වැඩි වැඩේ වැඩි වැඩේ වැඩි වැඩේ වැඩි වැඩේ නිසා.', 'so': "Hadal nacayb ah waa beer aad u koraysa waxbarasho, kaas oo la soo jeeday qaabab badan oo la soo jeeday, kuwaas oo u ogolaaday in lagu wado arimaha farshaxanka. Mid ka mid ah dhibaatooyin ka mid ah qaababka iskuulka e e aan waxqaban karin - tusaalaha waxbarashada moolka dheer - waa khatar khatar ah (tusaale ahaan culaabta beenta ah), taas oo ka hor dhigi kara ama la saari karo waxyaabaha ku jira macluumaadka bulshada ee aan waxyeellada lahayn codsiga aad u heshiisan. Tusaalada waxbarashada aad u weyn ee gudaha gudaha iyo xaalada baahida ee codsiga ee gudaha ku jira ayaannu qiimeynaynaa, waxaana soo bandhignaynaa qaabab SVM ah oo aad u hagaajiya xaalada farshaxanka marka lagu isku daro modellada waxbarashada mool dheer ee codka fudud. Horumarinta waxaa marka ugu horeysa la'aanta qiimaha beenta ah.", 'sr': 'Otkrivanje govora mržnje je aktivno rastuće područje istraživanja sa različitim nedavno predloženim pristupima koje dozvoljavaju da guraju rezultate države umjetnosti. Jedan od izazova takvih automatskih pristupa – a to je nedavno duboko učenje modela – je rizik od lažnih pozitivnih optužbi (tj. lažnih optužbi), koji može dovesti do preko blokiranja ili uklanjanja bezopasnog sadržaja socijalnih medija u aplikacije sa malom moderatorskom intervencijom. Procjenjujemo duboke modele učenja i pod uvjetima otkrivanja govora u domenu i preko domena mržnje, i predstavljamo pristup SVM-a koji omogućava značajno poboljšati rezultate stanja umjetnosti kada se kombiniraju sa dubokim modelima učenja kroz jednostavno glasanje većine. Poboljšanje je uglavnom zbog smanjenja lažne pozitivne stope.', 'sv': 'Hattalsdetektering är ett aktivt växande forskningsområde med en mängd nyligen föreslagna tillvägagångssätt som gjorde det möjligt att driva på de senaste resultaten. En av utmaningarna med sådana automatiserade tillvägagångssätt – nämligen de senaste djupinlärningsmodellerna – är risken för falska positiva (dvs. falska anklagelser), vilket kan leda till överblockering eller borttagning av ofarligt innehåll i sociala medier i applikationer med liten moderator ingripande. Vi utvärderar djupinlärningsmodeller både under domänöverskridande och gränsöverskridande hattalsdetekteringsförhållanden, och introducerar en SVM-strategi som gör det möjligt att avsevärt förbättra de senaste resultaten när de kombineras med djupinlärningsmodellerna genom en enkel majoritetsbeslutningsensemble. Förbättringen beror främst på en minskning av den falska positiva andelen.', 'ta': 'வெறுப்பு பேச்சு கண்டுபிடிப்பது ஒரு செயல்படுத்தப்பட்ட ஆராய்ச்சியின் புலத்தில் உள்ளது சமீபத்தில் பரிந்துரைக்கப்பட்ட பல முன் இத்தகைய தானியங்கிய நேர்வுகளில் ஒரு சவால்கள் - சமீபத்தில் ஆழமான கற்றுக்கொள்ள மாதிரிகள் - பொய் சொல்லும் நேர்ந்த சிக்கல்களின் ஆபத்தானது (அதாவது பொய் கூறுகிறார்) அது  நாம் ஆழமான கற்றல் மாதிரிகளை மதிப்பிடுகிறோம் களம் மற்றும் இடைமுறையில் வெறுப்பு பேச்சு கண்டுபிடிப்பு நிலைகளுக்குள் இருக்கும், மற்றும் ஒரு SVM செயல்பாட்டை முயற்சிக்கு முன்னேற்றம் பெரும்பாலாக தவறான விகிதத்தின் காரணம்.', 'ur': 'نفرت کی بات شناسایی ایک فعال پھیلانے کی کھیتی ہے جو اچھی طرح سے پیش کیا گیا ہے اور بہت سی طرح کی تقریبیں ہیں جن کی اجازت یہ ہے کہ آرت کا نتیجہ دھوپ کرے۔ اس طرح کی آٹوٹی طریقے کی ایک چال ہے - یعنی اچھی عمیق سیکھنے کی مدل - یہ جھوٹی مثبت کی خطر ہے (یعنی جھوٹی باتیں) جو بہت زیادہ بلوک کرنے یا ہٹانے کے لئے بہت خطرناک سوسیل میڈیا موڈیوں کے منصوبات کو بہت کم مدیراتر کے ساتھ اضافہ کرنے کے لئے۔ ہم عمیق تعلیم مدلکوں کو ڈومین میں اور کرس ڈومین میں اور کرس ڈومین میں نفرت کی بات شناسایی شرایط کے ذریعہ مطالبہ کرتے ہیں، اور ایک SVM طریقے کو معلوم کرتے ہیں جو ان کی حالت کا نتیجہ اضافہ کرتا ہے جبکہ عمیق تعلیم مدلکوں کے ساتھ ایک ساده اکثریت-ویٹنگ کے سوداگری اکثر غلط مثبت رخصت کے ذریعہ سے ہے.', 'uz': "Hat so'zni aniqlashni tasavvur qilish shunday taʼminlov sohalarini aktiv ko'proq o'rganish va yaqinda ishlatilgan bir necha taklif qilingan qo'llanmalar bilan ishlatish imkoniyatlarini boshlashga ruxsat beradi. Bu yerda avtomatik o'rganish usullardan biri qiyinchalar - yangi eng yaqin o'rganish modellaridan - yolg'on joylarning xavflidir (balki yolg'on qo'llanmalar), bu qo'llanmalar qo'shish yoki o'chirib chiqarishi mumkin, balki o'zgarishdan kichkina foydalanish mumkin. Biz domenning ichki o'rganish modellarini qiymatimiz va cross-domen ichki kuch'ining holatini aniqlash holatini qiymatimiz va SVM usulini ishga tushirish imkoniyatini o'rganish imkoniyatlarini juda muhim o'zgartirish mumkin. Ko'pchilik voting modellari bilan o'rganish modellarini birlashtirish mumkin. Mavjud yaxshi ko'rib chiqishni ko'rsatadi.", 'vi': 'Nhận diện ngôn ngữ thù ghét là một lĩnh vực nghiên cứu tích cực đang phát triển với nhiều phương pháp mới nhất đã được đề xuất để thúc đẩy kết quả hiện đại. Một trong những thử thách của các phương pháp tự động như thế này từ cao 8111: các mô hình mới được biết tới từ cao độ nguy hiểm từ những đi ều không chính xác (tức là những lời buộc tội sai trái), có thể dẫn tới việc chặn hoặc xóa bỏ các nội dung vô hại của các phương tiện xã hội trong ứng dụng với sự can thiệp nhỏ. Chúng tôi đánh giá các mô hình học sâu, cả trong lãnh vực và trong lãnh thổ bị phát hiện bằng ngôn ngữ ghét, và áp dụng một phương pháp SVM để có thể cải thiện đáng kể các kết quả hiện đại khi kết hợp với các mô hình học sâu bằng một kết hợp bầu cử đa số đơn giản. Sự cải tiến này chủ yếu là do giảm tỷ lệ sai tích.', 'bg': 'Откриването на речта на омразата е активно нарастваща област на изследвания с различни наскоро предложени подходи, които позволиха да се тласнат най-съвременните резултати. Едно от предизвикателствата на такива автоматизирани подходи - а именно последните модели на дълбоко обучение - е рискът от фалшиви позитиви (т.е. фалшиви обвинения), което може да доведе до свръхблокиране или премахване на безвредно съдържание в социалните медии в приложения с малка намеса на модератора. Ние оценяваме моделите на дълбоко обучение както при условия за откриване на реч на омраза, така и при условия на междудомейн, и въвеждаме подход, който позволява значително подобряване на най-съвременните резултати, когато се комбинират с моделите на дълбоко обучение чрез прост ансамбъл с мнозинство. Подобрението се дължи главно на намаляване на процента на фалшиви положителни.', 'da': 'Detektering af hadefulde taler er et aktivt voksende forskningsområde med en række nyligt foreslåede tilgange, der gjorde det muligt at skubbe de state-of-the-art resultater. En af udfordringerne ved sådanne automatiserede tilgange - nemlig nyere deep learning modeller - er risikoen for falske positive (dvs. falske beskyldninger), som kan føre til overblokering eller fjernelse af uskadeligt indhold på sociale medier i applikationer med ringe moderators indgriben. Vi evaluerer deep learning modeller både under in-domain og cross-domain hate speech detection forhold, og introducerer en SVM tilgang, der gør det muligt at forbedre state-of-the-art resultater betydeligt, når kombineret med deep learning modeller gennem et simpelt flertal-stemme ensemble. Forbedringen skyldes hovedsagelig en reduktion af den falske positive sats.', 'nl': 'Hate speech detection is een actief groeiend onderzoeksveld met een verscheidenheid aan recent voorgestelde benaderingen die toelaten om de state-of-the-art resultaten te pushen. Een van de uitdagingen van dergelijke geautomatiseerde benaderingen, namelijk recente deep learning modellen, is een risico op false positieven (d.w.z. valse beschuldigingen), die kunnen leiden tot overmokkeling of verwijdering van onschadelijke social media content in applicaties met weinig tussenkomst van de moderator. We evalueren deep learning modellen zowel onder in-domain als cross-domain haatspraak detectie omstandigheden en introduceren een SVM benadering die toelaat om de state-of-the-art resultaten aanzienlijk te verbeteren in combinatie met de deep learning modellen door middel van een eenvoudige meerderheidsstemming ensemble. De verbetering is voornamelijk te wijten aan een verlaging van het vals positieve percentage.', 'de': 'Hate Speech Detection ist ein aktiv wachsendes Forschungsfeld mit einer Vielzahl von kürzlich vorgeschlagenen Ansätzen, die es ermöglichten, die neuesten Ergebnisse voranzutreiben. Eine der Herausforderungen solcher automatisierten Ansätze ist das Risiko falscher Positive (d.h. falscher Anschuldigungen), die zu einer Überblockung oder Entfernung harmloser Social Media Inhalte in Anwendungen mit wenig Moderatoreingriff führen können. Wir evaluieren Deep-Learning-Modelle sowohl unter domain- als auch domain-übergreifenden Hassrede-Erkennungsbedingungen und führen einen SVM-Ansatz ein, der es ermöglicht, die State-of-the-Art-Ergebnisse in Kombination mit den Deep-Learning-Modellen durch ein einfaches Mehrheitsstimmensemble signifikant zu verbessern. Die Verbesserung ist hauptsächlich auf eine Verringerung der falsch positiven Rate zurückzuführen.', 'id': 'Deteksi pidato benci adalah bidang penelitian yang berkembang secara aktif dengan berbagai pendekatan yang baru-baru ini diusulkan yang memungkinkan untuk mendorong hasil state-of-the-art. One of the challenges of such automated approaches - namely recent deep learning models - is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention.  We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble.  Perbaikan terutama karena pengurangan tingkat positif palsu.', 'fa': 'کشف سخنرانی از نفرت یک منطقه فعالی از تحقیقات با مختلف دستورات پیشنهاد اخیر است که اجازه می دهد نتیجه\u200cهای هنری را فشار دهد. یکی از چالش\u200cهایی از این دسترسی\u200cهای خودکار - یعنی مدل\u200cهای یادگیری عمیق اخیر - خطری از مثبت\u200cهای غلط است (یعنی اتهامات غلط) که می\u200cتواند به عنوان بسیار بلوک\u200cگذاری یا حذف محتوای رسانه\u200cهای اجتماعی بی\u200cضرر در کاربردهای با مدیراتور کوچک باشد ما مدل\u200cهای یادگیری عمیق را ارزیابی می\u200cکنیم که هر دو در دامنه\u200cای و در شرایط کشف سخنرانی متنفر است، و یک روش SVM را معرفی می\u200cکنیم که اجازه می\u200cدهد نتیجه\u200cهای وضعیت هنری را به طور معنی بهتر کند، وقتی با مدل\u200cهای یادگیری عمیق با یک مدل ساده\u200cای از انتخاب پیشرفت عموما به خاطر کاهش نرخ مثبت غلط است.', 'tr': 'Ýuklanjaň sözlerini tanamak ýagdaýynda ýakynlaşýan bir araştyrma sahypasy. Ýakynda näçe görnüş gelen ýagdaýyny süýtgetmek üçin mümkin däldir. Öň ýaly awtomatik hereketleriň bir kynçylygy - hem edil soňky derin öwrenmek nusgalarynyň biri - ýalňyş positibleriň töwekilidir (ýalňyş sözleşmeleri), hem bu nusgalaryň uygulamalarynda i ň ýalňyşsyz mediýalyň maksadyny çykarmagyna sebep bolup biler. Biz derin öwrenme modellerini dominiň altynda we cross-domain öwrenme çykyş şertleri gözden ýigrenýäris we SVM metodlaryny çykarýarys. Bu şekilde derin öwrenme modelleri bilen basit bir çokda ses çykyş bilen üýtgetmek üçin önüne getirilýär. Gelişik adatça ýalñyş möhüm ýigrendigine sebäbi.', 'hr': 'Otkrivanje govora mržnje je aktivno rastuće područje istraživanja s različitim nedavno predloženim pristupima koje omogućavaju gurati rezultate stanja umjetnosti. Jedan od izazova takvih automatskih pristupa - a to je nedavni model dubokog učenja - rizik od lažnih pozitivnih optužbi (tj. lažnih optužbi), koji može dovesti do preko blokiranja ili uklanjanja bezopasnog sadržaja društvenih medija u prijavama s malim moderator intervencijom. Procjenjujemo duboke modele učenja i pod uvjetima otkrivanja govora mržnje u domenu i preko domena i uvođujemo pristup SVM-a koji omogućava značajno poboljšati rezultate stanja umjetnosti kada se kombiniraju s dubokim modelima učenja kroz jednostavno glasački ensemble. Poboljšanje je uglavnom zbog smanjenja lažne pozitivne stope.', 'af': "Hatte spraak beskrywing is 'n aktief groei veld van ondersoek met 'n verskeie van onlangs voorgestelde toegang wat toegelaat het om die staat van die kuns resultate te druk. Een van die uitdagings van sodanige outomatiese toegang - namely nuutste diep leer modele - is 'n risiko van valse positiewe (t.d. valse opdragte), wat dalk kan lei na meer blokkering of verwyder van skarmose sosiale media inhoud in toepassings met klein moderator intervensie. Ons evalueer diep leer modele beide onder in- domein en kruis- domein haat spraak beskrywing voorwaardes, en introduseer 'n SVM toegang wat toelaat om betekeurig die state- of- the- art resultate te verbeter wanneer gekombineer word met die diep leer modele deur 'n eenvoudige meerderheid- stem ensemble. Die verbetering is heeltemal vanweë 'n reduksie van die valse positiewe tempo.", 'ko': '원한 음성 검출은 현재 적극적으로 발전하고 있는 연구 분야로 최근에 각종 방법을 제시하여 가장 선진적인 결과를 추진할 수 있다.이런 자동화 방법(즉 최근의 심도 있는 학습 모델)이 직면한 도전 중 하나는 오보(즉 허위 고발)가 발생할 위험이다. 이는 응용 프로그램의 무해한 소셜 미디어 내용을 과도하게 차단하거나 삭제할 수 있고 판주가 관여하는 경우는 드물다.우리는 역내와 전역 증오 음성 검측 조건에서 깊이 있는 학습 모델을 평가하고 지원 벡터 기법을 도입했다. 간단한 다수결 투표 통합과 깊이 있는 학습 모델을 결합하면 이 방법은 가장 선진적인 결과를 현저하게 개선할 수 있다.개선은 주로 가양성률이 낮아졌기 때문이다.', 'sq': 'Zbulimi i fjalimit të urrejtjes është një fushë në rritje aktive kërkimi me një shumëllojshmëri metodash të propozuara kohët e fundit që lejuan të shtyjnë rezultatet më të larta. One of the challenges of such automated approaches - namely recent deep learning models - is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention.  Ne vlerësojmë modelet e mësimit të thellë si sipas kushteve të zbulimit të fjalimit të urrejtjes në domeni, ashtu edhe sipas domenit, dhe futim një qasje SVM që lejon të përmirësojë ndjeshëm rezultatet më të larta kur kombinohen me modelet e mësimit të thellë nëpërmjet një ansambli të thjeshtë të shumicës së votave. Përmirësimi është kryesisht për shkak të reduktimit të normës së rreme pozitive.', 'hy': 'Խոսքի ատելության հայտնաբերումը ակտիվ աճող հետազոտությունների ոլորտ է, որը վերջերս առաջարկել է տարբեր մոտեցումներ, որոնք թույլ են տալիս շարժել ամենաբարձր արդյունքները: Այսպիսի ավտոմատիկ մոտեցումների մարտահրավերներից մեկը, հատկապես վերջին խորը ուսումնասիրության մոդելներից, կեղծ դրական վտանգ է (այսինքն՝ կեղծ հայտարարություններ), ինչը կարող է հանգեցնել անվտանգավոր սոցիալական լրատվամիջոցների պարունակության չափազանցումներին կամ հեռացնելու Մենք գնահատում ենք խորը ուսումնասիրության մոդելները նաև տիեզերքում, նաև տիեզերքում գտնվող ատելության խոսքի հայտնաբերման պայմաններում, և ներկայացնում ենք ՎԻԱՄ մոտեցում, որը հնարավորություն է տալիս կարևոր բարելավել ամենահետաքրքիր արդյունքները, երբ համադրվում են խորը ուսումնասիրության մո Այս բարելավումը հիմնականում սխալ դրական արագության կրճատման պատճառով է:', 'sw': 'Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results.  Moja ya changamoto za mbinu hizo za kujitegemea –hivi karibuni, modeli za kujifunza za ndani –ni hatari ya vizuri vya uongo (yaani tuhuma za uongo), ambazo zinaweza kusababisha kuzuia au kuondoa maudhui ya mitandao ya kijamii isiyo na madhara katika matumizi yenye hatua ndogo ya kati. Tunatathmini mifano ya kujifunza za ndani na hali ya uchunguzi wa chuki ya hotuba za ndani, na kutengeneza mbinu za SVM ambazo zinaruhusu kuboresha hali ya matokeo ya sanaa ikiwa imeunganishwa na modeli za kujifunza za ndani kupitia mfumo rahisi wa kura. Mabadiliko yanasababisha kupunguza kiwango chanya cha uongo.', 'am': 'ጥላቻ ንግግር አግኝቷል፡፡ እንደነዚህ ባለ አካባቢ ጥልቅ ትምህርት ዓይነቶች የሚደረገው የሐሰት አካባቢዎች (ምናልባት የሐሰት ክስ) መከራ ነው፡፡ ይህ በጥቂት ማቀናቀል በተግባር ውስጥ ያለ ጉዳይ የማኅበራዊ ሚዲያ ማኅበራዊ ጥናት ማቀናቀል ወይም ማጥፋት ይችላል፡፡ ጥልቅ ትምህርት ምሳሌዎችን እና በዲሞናዊ እና በጥልቅ ድምፅ ግንኙነትን እናስረዳለን፡፡ የውሸት ጉዳይ የሚያሳስል ነው፡፡', 'bs': 'Otkrivanje govora mržnje je aktivno rastuće područje istraživanja s različitim nedavno predloženim pristupima koje omogućavaju gurati rezultate države umjetnosti. Jedan od izazova takvih automatskih pristupa - a to je nedavni model dubokog učenja - je rizik od lažnih pozitivnih optužbi (tj. lažnih optužbi), koji može dovesti do preko blokiranja ili uklanjanja bezopasnog sadržaja socijalnih medija u aplikacije s malom moderatorskom intervencijom. Procjenjujemo duboke modele učenja i pod uvjetima otkrivanja govora u domenu i preko domena mržnje, i predstavljamo pristup SVM-a koji omogućava značajno poboljšati rezultate stanja umjetnosti kada se kombiniraju sa dubokim modelima učenja kroz jednostavno glasanje većine. Poboljšanje je uglavnom zbog smanjenja lažne pozitivne stope.', 'bn': 'ঘৃণা ভাষণের আবিষ্কার হচ্ছে একটি সক্রিয় গবেষণার ক্ষেত্র যা সম্প্রতি প্রস্তাবিত বিভিন্ন ক্ষেত্রে প্রস্তাবিত প্রস্তাব করা হয়েছে  এই ধরনের স্বয়ংক্রিয় পদ্ধতির একটি চ্যালেঞ্জ - সম্প্রতি গভীর শিক্ষা মডেল - মিথ্যা পটিভিসের ঝুঁকির ঝুঁকি (যেমন মিথ্যা অভিযোগ), যার ফলে আপ্লিকেশনে ক্ষতিকর সামাজি আমরা ডোমেইনের নীচে গভীর শিক্ষা মডেলের মূল্য মূল্য দিচ্ছি এবং সংখ্যাগরিষ্ঠ ভোট প্রদানের মাধ্যমে ক্রিস্টোমেইনের ঘৃণা ভাষণের পরিস্থিতি আবিষ্কার করার জন্য একটি এসভিএম পদ্ধতি ত এই উন্নয়ন মূলত ভুল পজিটিভ হার কমানোর কারণে।', 'ca': 'Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results.  One of the challenges of such automated approaches - namely recent deep learning models - is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention.  We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble.  La millora es deu principalment a una reducció de la tasa falsa positiva.', 'et': 'Vihakõne tuvastamine on aktiivselt kasvav uurimisvaldkond, kus on mitmesugused hiljuti välja pakutud lähenemisviisid, mis võimaldasid kaasaegseid tulemusi tõsta. Selliste automatiseeritud lähenemisviiside – nimelt hiljutiste sügavõppe mudelite – üks väljakutseid on valepositiivsete (st valesüüdistuste) oht, mis võib viia kahjutu sotsiaalmeedia sisu üleblokeerimiseni või eemaldamiseni rakendustes, kus moderaator sekkub vähe. Hindame sügavõppe mudeleid nii domeenisisestel kui ka valdkondadevahelistel vihakõne tuvastamise tingimustel ning tutvustame SVM-lähenemisviisi, mis võimaldab oluliselt parandada kaasaegseid tulemusi, kui neid kombineeritakse sügavõppe mudelitega lihthäälteenamusega ansambli kaudu. Paranemine tuleneb peamiselt valepositiivsete näitajate vähenemisest.', 'fi': 'Vihanpuheen havaitseminen on aktiivisesti kasvava tutkimusala, jossa on useita hiljattain ehdotettuja lähestymistapoja, joiden avulla voidaan työntää viimeisimpiä tuloksia. Yksi tällaisten automatisoitujen lähestymistapojen haasteista – erityisesti tuoreiden syväoppimismallien – on väärien positiivisten tulosten (eli väärien syytösten) riski, joka voi johtaa vaarattoman sosiaalisen median sisällön liialliseen estoon tai poistamiseen sovelluksissa, joissa moderaattori puuttuu vähän. Arvioimme syväoppimisen malleja sekä sisäisissä että monialaisissa vihapuheentunnistusolosuhteissa ja otamme käyttöön SVM-lähestymistavan, jonka avulla voidaan merkittävästi parantaa viimeisimpiä tuloksia yhdistettynä syväoppimisen malleihin yksinkertaisen enemmistöäänestyksen kautta. Paraneminen johtuu pääasiassa väärien positiivisten tulosten vähenemisestä.', 'cs': 'Detekce nenávistné řeči je aktivně rostoucí oblastí výzkumu s řadou nedávno navržených přístupů, které umožnily posunout nejmodernější výsledky. Jednou z výzev těchto automatizovaných přístupů konkrétně nedávných modelů hlubokého učení je riziko falešně pozitivních (tj. falešných obvinění), které může vést k nadměrnému blokování nebo odstranění neškodného obsahu sociálních médií v aplikacích s malým zásahem moderátora. Hodnotíme modely hlubokého učení jak za podmínek detekce nenávistné řeči v doméně, tak za podmínek detekce nenávistné řeči mezi doménami a představujeme přístup SVM, který umožňuje výrazně zlepšit nejmodernější výsledky v kombinaci s modely hlubokého učení prostřednictvím jednoduchého souboru hlasování většinou. Zlepšení je způsobeno především snížením falešně pozitivní míry.', 'az': 'Nefr…ôt s√∂zl…ôrini keŇüfetm…ôk, yenid…ôn t…ôklif edil…ôn t…ôrzl…ôrin m√ľxt…ôlif t…ôrzl…ôrini t…ôŇükil etm…ôy…ô izin veril…ôn t…ôrzl…ôrin f…ôaliyy…ôtli olaraq b√ľy√ľy…ôn bir araŇütńĪrma sah…ôsidir. Bu avtomatik t…ôrzl…ôrin √ß…ôtinlikl…ôrind…ôn biri - h…ôm√ßin in son d…ôrin √∂yr…ônm…ô modell…ôrinin - yalan pozitivl…ôrin riskidir (h…ôm√ßinin yalan t…ôkzibl…ôrin, yalan t…ôkzibl…ôrin riskidir), ki bu proqramlarda z…ôr…ôrli sosyal media m…ôlumatńĪnńĪn √ßox bloklamasńĪna v…ô ya √ß…ôkilm…ôsin…ô yol a √ßar. Biz d…ôrin √∂yr…ônm…ô modell…ôrini domain altńĪnda v…ô √ßox domain nefret s√∂zl…ôrini keŇüfetm…ô ŇüartlarńĪ il…ô deńüerl…ôŇüdiririk, v…ô bir SVM metodlarńĪnńĪ t…ôŇükil edirik ki, √ßoxluńüu s…ôsl…ôrin vasit…ôsil…ô d…ôrin √∂yr…ônm…ô modell…ôri il…ô √ßoxluńüu il…ô birl…ôŇüdirilm…ôsi m√ľmk√ľn olur. ńįyileŇüm…ôk …ôslind…ô yalan pozitif d…ôr…ôc…ônin azaltmasńĪna g√∂r…ôdir.', 'jv': 'Attribute Omah mengko karo hal-hal sing beraksi akeh automobil- nambah model sing nguasai luwih dumadhi - kuwi nggawe sistem sing gak bener podho We assess deep Learn modes gan unders in-domain and inter-domain mrisage language detection conditions, and insert an SVM method that enables to badly advance the state-of-the-arts output when combed with the deep Learn modes through a Simple plural-Voting ensamble. Progress', 'he': 'זיהוי נאום שנאה הוא שדה מחקר שגדל באופן פעיל עם מגוון של גישות מוצעות לאחרונה שאפשר לדחוף את התוצאות המאומנות. אחת האתגרים של גישות אוטומטיות כאלה - במיוחד דוגמני למידה עמוקה לאחרונה - היא סיכון של חיוביות שווא (כלומר האשמות שוויות), אשר עלול להוביל לחסום יתר או להסיר את תוכן התקשורת החברתית חסר מזיק בתוכניות עם התערבות מודרתית קטנה. We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble.  השיפור הוא בעיקר בגלל הפחות של הקצב החיובי השגוי.', 'ha': 'Haƙĩƙa na gane shi wata firam mai fara-tsirarwa na research da wasu shiryoyi masu yiwuwa da aka buƙata ta a yanzu ta yarda da su ƙara fassarar-the-art. Babu wani daga muramman hanyoyin wannan - misãlai masu ƙari da aka sanar da su a yanzu-yanzu, yana da risiko ga masu ƙarya (misali, misãlan kunnuwa), wanda za ta yi kusa ya rufe ko ta tafiyar da maɓallin mitandaki masu da wata cũta a cikin shiryoyin ayuka da ke da intake mai mutumci kaɗan. Tuna ƙaddara misãlai masu ƙaranci da ke cikin-Domen da ke samun kunna-bayani, kuma Mu ƙara wata hanyor SvM wanda ke yarda da shi mai girma ga gyãra halin-fassarar-sanar idan ta sami da misãlai masu ƙaranci a sami-sami, a shekarar sauri mai sauri. Bayani da ya kyautata shi ne mainli don a ƙara tsakanin ƙarya.', 'sk': 'Odkrivanje sovražnega govora je aktivno rastoče področje raziskav z različnimi nedavno predlaganimi pristopi, ki so omogočili spodbujanje najsodobnejših rezultatov. Eden od izzivov takšnih avtomatiziranih pristopov – namreč nedavnih modelov globokega učenja – je tveganje lažnih pozitivnih (tj. lažnih obtožb), kar lahko privede do prekomernega blokiranja ali odstranitve neškodljivih vsebin družbenih omrežij v aplikacijah z malo posredovanja moderatorja. Ocenjujemo modele globokega učenja pod domenskimi in meddomenskimi pogoji zaznavanja sovražnega govora ter uvedemo pristop SVM, ki omogoča bistveno izboljšanje najsodobnejših rezultatov v kombinaciji z modeli globokega učenja prek enostavnega ansambla glasovanja z večino. Izboljšanje je predvsem posledica zmanjšanja stopnje lažnih pozitivnih pozitivnih.', 'bo': 'Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allow you to push the state-of-the-art results. One of the challenges of such automated approaches - namely recent deep learning models - is a risk of false positives (i.e. false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention. We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble. ཡར་རྒྱས་འགྲོ་བ་དེ་རྒྱ་ཆེ་མཐོང་ནུས་མེད་པས་རང་ཉིད་ཀྱི་གནས་ཚུལ་གང་རྐྱེན་པས།'}
{'en': 'Leveraging Community and Author Context to Explain the Performance and Bias of Text-Based Deception Detection Models', 'ar': 'الاستفادة من سياق المجتمع والمؤلف لشرح الأداء والتحيز لنماذج الكشف عن الخداع القائمة على النص', 'es': 'Aprovechar el contexto de la comunidad y del autor para explicar el rendimiento y el sesgo de los modelos de detección de engaños basados en texto', 'fr': "Exploiter le contexte de la communauté et de l'auteur pour expliquer les performances et les biais des modèles de détection de tromperie basés sur du texte", 'pt': 'Aproveitando o contexto da comunidade e do autor para explicar o desempenho e o viés dos modelos de detecção de engano baseados em texto', 'ja': 'コミュニティと著者のコンテキストを活用して、テキストベースの欺瞞検出モデルのパフォーマンスとバイアスを説明する', 'ru': 'Использование контекста сообщества и автора для объяснения производительности и предвзятости текстовых моделей обнаружения обмана', 'hi': 'पाठ-आधारित धोखे का पता लगाने मॉडल के प्रदर्शन और पूर्वाग्रह की व्याख्या करने के लिए समुदाय और लेखक संदर्भ का लाभ उठाना', 'zh': '因社区与作者上下文以释其欺检之性差也', 'ga': 'Comhthéacs Pobal agus Údair a Ghiaráil chun Feidhmíocht agus Laofacht Múnlaí Braite Meabhlaireachta Téacsbhunaithe a Mhíniú', 'el': 'Αξιοποίηση του πλαισίου κοινότητας και συγγραφέων για να εξηγήσει την απόδοση και τις προκαταλήψεις των μοντέλων ανίχνευσης εξαπάτησης βάσει κειμένου', 'ka': 'საზოგადოებო და ავტორის კონტექსტის შესაძლებლობა ტექსტის განახსნა მოდელების პერფორმაცია და ბიოების განახსნა', 'hu': 'Közösségi és szerzői kontextus kihasználása a szövegalapú megtévesztési modellek teljesítményének és elhárításainak magyarázására', 'lt': 'Bendrijos ir autorių konteksto stiprinimas siekiant paaiškinti teksto pagrindu pagrįstų apgaulės nustatymo modelių veiksmingumą ir pažeidimus', 'it': 'Sfruttare il contesto comunitario e autore per spiegare le prestazioni e i bias dei modelli di rilevamento degli inganni basati sul testo', 'kk': 'Жалпы мәтін негіздеген шешімдерді анықтау үлгілерінің жұмысын және қайталау үлгілерін түсіндіру үшін Компания мен Автор контексті жасау', 'mk': 'Разголемување на контекстот на заедницата и авторот за објаснување на резултатите и непријатностите на моделите за детектирање на измама на текст', 'ms': 'Menyerangkan Konteks Komuniti dan Penulis untuk Jelaskan Performance and Bias of Text-Based Deception Models', 'mn': 'Нийгмийн болон зохиолчдын төлөвлөгөө нь Текст суурилсан санааны үйл ажиллагаа болон Bias-г тодорхойлох боломжтой байдал', 'mt': 'It-tisħiħ tal-Kuntest Komunitarju u tal-Awtur biex jispjega l-Prestazzjoni u l-Bias tal-Mudelli ta’ Detezzjoni ta’ Deċezzjoni bbażati fuq it-Test', 'ml': 'പദാവലി അടിസ്ഥാനമായ ഡിസ്റ്റീഷന്\u200d ഡിക്റ്റീഷന്\u200d മോഡലുകള്\u200d വ്യക്തമാക്കുവാനുള്ള സജ്ജീകരണവും രചയിതാവിന്റെ ഉള്ളടക്കം', 'pl': 'Wykorzystanie kontekstu społeczności i autorów do wyjaśnienia skuteczności i uprzedzeń modeli wykrywania oszustw opartych na tekstach', 'sr': 'Uspoređujući kontekst zajednice i autora za objašnjavanje učinkovitosti i bija modela otkrivanja odluke na tekstu', 'ro': 'Utilizarea contextului comunitar și al autorilor pentru a explica performanța și erorile modelelor de detectare a decepțiilor bazate pe text', 'si': 'ලේවර් සමාජය සහ ලේඛක සම්බන්ධය ප්\u200dරශ්නය කරන්න පුළුවන් විස්තර කරන්න පුළුවන්', 'sv': 'Utnyttja gemenskaps- och f철rfattarsammanhang f철r att f철rklara prestanda och bias hos textbaserade bedr채geridetekteringsmodeller', 'ta': 'உரை அடிப்படையான தேர்வு கண்டுபிடிப்பு மாதிரிகளின் செயல்பாடு மற்றும் பியாஸ் விளக்க வேண்டிய எழுத்துரு சமுதாயத்து', 'ur': 'کمپنٹی اور لائٹر کنٹکسٹ کے ذریعہ تفصیل اور دوئس کی تعریف کرنے کے لئے', 'no': 'Leveraging Community- og autokontekst for å forklare utviklinga og utviklinga av tekstbaserte dekeptasjonsmodular', 'so': 'Qoraalka ku qoran qoraalka ku qoran iyo qoraalka ku qoran qoraalka', 'uz': 'Comment', 'vi': 'Đánh giá Cộng đồng và tác giả ngữ cảnh để giải thích trình độ và biểu hiện của các mô hình nhận dạng văn bản', 'bg': 'Използване на контекста на общността и авторите за обясняване на ефективността и наклоненията на моделите за откриване на измама, базирани на текст', 'nl': 'Gebruik maken van community- en auteurscontext om de prestaties en vooroordelen van tekstgebaseerde misleidingsdetectiemodellen uit te leggen', 'da': 'Udnyttelse af fællesskabs- og forfattersammenhæng til at forklare ydeevnen og fordelene ved tekstbaserede modeller til detektering af bedrageri', 'hr': 'Kontekst usvajanja zajednice i autora za objašnjenje učinkovitosti i objašnjenja modela otkrivanja odluke na temelju teksta', 'de': 'Nutzung des Community- und Autorenkontextes zur Erklärung der Leistung und Vorurteile textbasierter Täuschungsmodelle', 'fa': 'محیط اجتماعی و نویسندگان برای توضیح عملکرد و دوگانه\u200cهای مدل\u200cهای شناسایی تصمیم\u200cگیری بر پایه\u200cی متن', 'id': 'Meningkatkan Konteks Komunitas dan Penulis untuk menjelaskan Performance and Bias of Text-Based Deception Models', 'ko': '지역사회와 저자의 배경을 이용하여 텍스트 기반의 사기 검측 모델의 성능과 편차를 해석하다', 'sw': 'Utamaduni wa Jumuiya na Mazungumzo ya Mwandishi wa Kuelezea Utamaduni na Bias wa Modeli za Kuchungua Utamuzi', 'tr': 'jemgyýet we Awtomatik Konteksti Metin Başlygdan Çykyş Modelleri', 'sq': 'Leveraging Community and Author Context to Explain the Performance and Bias of Text-Based Deception Detection Models', 'hy': 'Leveraging Community and Author Context to Explain the Performance and Bias of Text-Based Deception Detection Models', 'bn': 'লেভারেজিং কমিউনিটি এবং লেখকের বিষয়বস্তু ব্যাখ্যা করার জন্য লেভারেজিং করা হচ্ছে', 'am': 'የጽሑፍ ምርጫዎች', 'az': 'Mətn-tabanlı Deçmə Modellərinin İşləndirməsi və Sözünün İşləndirməsi', 'cs': 'Využití komunitního a autorského kontextu k vysvětlení výkonnosti a předsudků textových modelů detekce klamů', 'ca': "Ampliar el contexte comunitari i d'autor per explicar el rendiment i els inconvenients dels models de detecció de la decepció basada en text", 'bs': 'Uspoređenje konteksta zajednice i autora za objašnjavanje učinkovitosti i objašnjenja modela otkrivanja odluke na temelju teksta', 'et': 'Kogukonna ja autori konteksti kasutamine tekstipõhiste pettuste tuvastamise mudelite tulemuslikkuse ja kallakute selgitamiseks', 'fi': 'Yhteisö- ja tekijäkontekstin hyödyntäminen tekstipohjaisten petosten tunnistusmallien suorituskyvyn ja vinoutumisen selittämiseksi', 'af': 'Verspreiding gemeenskap en Outeur Konteks om die Performasie en Bias van Teksbaseerde besluit beskrywing Modelle te verduidelik', 'ha': 'KCharselect unicode block name', 'jv': 'Ngawe Delokan Kontext Komunitas lan Pengarang Pangan kanggo Keurakno Menu', 'sk': 'Izkoriščanje konteksta skupnosti in avtorjev za pojasnitev učinkovitosti in pristranskosti modelov za zaznavanje prevare na podlagi besedila', 'he': 'מעדכן קשר קהילתי וכותב כדי להסביר את ההפעלה והסביבות של דוגמני גילוי החליפה מבוססים בטקסט', 'bo': 'Leveraging Community and Author Context to Explain the Performance and Bias of Text-Based Deception Detection Models'}
{'en': 'Deceptive news posts shared in online communities can be detected with NLP models, and much recent research has focused on the development of such models. In this work, we use characteristics of online communities and authors   the context of how and where content is posted   to explain the performance of a neural network deception detection model and identify sub-populations who are disproportionately affected by model accuracy or failure. We examine who is posting the content, and where the content is posted to. We find that while author characteristics are better predictors of deceptive content than community characteristics, both characteristics are strongly correlated with model performance. Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.', 'fr': "Les articles de presse trompeurs partagés dans les communautés en ligne peuvent être détectés avec des modèles de PNL, et de nombreuses recherches récentes se sont concentrées sur le développement de tels modèles. Dans ce travail, nous utilisons les caractéristiques des communautés en ligne et des auteurs — le contexte de la façon dont le contenu est publié et de l'endroit où le contenu est publié — pour expliquer les performances d'un modèle de détection de tromperie de réseau neuronal et identifier les sous-populations qui sont affectées de manière disproportionnée par la précision ou la défaillance du modèle. Nous examinons qui publie le contenu et où le contenu est publié. Nous avons constaté que, bien que les caractéristiques de l'auteur soient de meilleurs prédicteurs du contenu trompeur que les caractéristiques de la communauté, les deux caractéristiques sont fortement corrélées avec les performances du modèle. Les mesures de performance traditionnelles telles que le score F1 peuvent ne pas saisir les mauvaises performances du modèle sur des sous-populations isolées telles que des auteurs spécifiques, et par conséquent, une évaluation plus nuancée des modèles de détection de tromperie est essentielle.", 'ar': 'يمكن اكتشاف المنشورات الإخبارية الخادعة التي يتم مشاركتها في المجتمعات عبر الإنترنت باستخدام نماذج البرمجة اللغوية العصبية ، وقد ركزت الكثير من الأبحاث الحديثة على تطوير مثل هذه النماذج. في هذا العمل ، نستخدم خصائص المجتمعات والمؤلفين عبر الإنترنت - سياق كيفية ومكان نشر المحتوى - لشرح أداء نموذج اكتشاف خداع الشبكة العصبية وتحديد المجموعات السكانية الفرعية التي تتأثر بشكل غير متناسب بدقة النموذج أو الفشل. نحن نفحص من ينشر المحتوى ، وأين يتم نشر المحتوى. وجدنا أنه في حين أن خصائص المؤلف هي تنبئ أفضل للمحتوى المخادع من خصائص المجتمع ، فإن كلا الخاصيتين مرتبطان ارتباطًا وثيقًا بأداء النموذج. قد تفشل مقاييس الأداء التقليدية مثل درجة F1 في التقاط أداء النموذج الضعيف على مجموعات فرعية معزولة مثل مؤلفين محددين ، وعلى هذا النحو ، فإن التقييم الأكثر دقة لنماذج الكشف عن الخداع أمر بالغ الأهمية.', 'pt': 'Postagens de notícias enganosas compartilhadas em comunidades online podem ser detectadas com modelos de PNL, e muitas pesquisas recentes se concentraram no desenvolvimento de tais modelos. Neste trabalho, usamos características de comunidades online e autores — o contexto de como e onde o conteúdo é postado — para explicar o desempenho de um modelo de detecção de engano de rede neural e identificar subpopulações que são desproporcionalmente afetadas pela precisão ou falha do modelo. Examinamos quem está postando o conteúdo e para onde o conteúdo é postado. Descobrimos que, embora as características do autor sejam melhores preditores de conteúdo enganoso do que as características da comunidade, ambas as características estão fortemente correlacionadas com o desempenho do modelo. Métricas de desempenho tradicionais, como a pontuação F1, podem falhar em capturar o desempenho insatisfatório do modelo em subpopulações isoladas, como autores específicos e, como tal, uma avaliação mais sutil dos modelos de detecção de engano é fundamental.', 'es': 'Las publicaciones de noticias engañosas que se comparten en las comunidades en línea se pueden detectar con los modelos de PNL, y muchas investigaciones recientes se han centrado en el desarrollo de tales modelos. En este trabajo, utilizamos las características de las comunidades y los autores en línea (el contexto de cómo y dónde se publica el contenido) para explicar el rendimiento de un modelo de detección de engaños de redes neuronales e identificar subpoblaciones que se ven afectadas de manera desproporcionada por la precisión o el fracaso del modelo. Examinamos quién publica el contenido y dónde se publica el contenido. Descubrimos que, si bien las características del autor predicen mejor el contenido engañoso que las características de la comunidad, ambas características están fuertemente correlacionadas con el rendimiento del modelo. Las métricas de rendimiento tradicionales, como la puntuación F1, pueden no captar el rendimiento deficiente del modelo en subpoblaciones aisladas, como autores específicos, y por lo tanto, es fundamental una evaluación más matizada de los modelos de detección de engaños.', 'ja': 'オンラインコミュニティで共有されている欺瞞的なニュース投稿は、NLPモデルで検出することができ、最近の研究はそのようなモデルの開発に焦点を当てています。この研究では、ニューラルネットワーク欺瞞検出モデルのパフォーマンスを説明し、モデルの精度や障害の影響を不釣り合いに受けているサブ集団を特定するために、オンラインコミュニティと著者の特徴（コンテンツが投稿される方法と場所の文脈）を使用します。私たちは、誰がコンテンツを投稿しているのか、コンテンツがどこに投稿されているのかを調べます。私たちは、著者の特徴はコミュニティの特徴よりも欺瞞的なコンテンツのより良い予測因子であるが、両方の特徴はモデルのパフォーマンスと強く相関していることを発見しました。Ｆ１スコアなどの従来のパフォーマンスメトリクスは、特定の著者などの孤立したサブ集団上の不十分なモデルパフォーマンスを捕捉することができない可能性があり、したがって、欺瞞検出モデルのより微妙な評価が重要である。', 'ru': 'Публикации обманчивых новостей, распространяемые в онлайн-сообществах, могут быть обнаружены с помощью моделей NLP, и многие недавние исследования были сосредоточены на разработке таких моделей. В этой работе мы используем характеристики онлайн-сообществ и авторов — контекст того, как и где размещается контент — для объяснения производительности модели обнаружения обмана нейронной сети и выявления субпопуляций, на которые непропорционально влияет точность или неудача модели. Мы проверяем, кто размещает контент и где он размещается. Мы обнаружили, что, хотя характеристики автора являются лучшими предикторами обманчивого контента, чем характеристики сообщества, обе характеристики сильно коррелируют с эффективностью модели. Традиционные показатели эффективности, такие как оценка F1, могут не отражать низкую эффективность модели в изолированных субпопуляциях, таких как конкретные авторы, и поэтому более детальная оценка моделей обнаружения обмана имеет решающее значение.', 'zh': '在线社区中共享欺骗性新闻帖可因NLP模检得,近者众集于此。 于是用在线社区、作者之征-发义位之上下文-以说神经网络欺检之性,定准确性败不成比例之人。 吾能省发者及其位。 虽胜社区欺骗性,皆关于模。 古之性能指标(F1 分数)或不能孤立子群体(若特定作者)差,故欺检至重。', 'hi': 'ऑनलाइन समुदायों में साझा किए गए भ्रामक समाचार पोस्ट को एनएलपी मॉडल के साथ पता लगाया जा सकता है, और हाल के शोध ने ऐसे मॉडलों के विकास पर ध्यान केंद्रित किया है। इस काम में, हम ऑनलाइन समुदायों और लेखकों की विशेषताओं का उपयोग करते हैं - कैसे और कहां सामग्री पोस्ट की जाती है, इसका संदर्भ - एक तंत्रिका नेटवर्क धोखे का पता लगाने वाले मॉडल के प्रदर्शन की व्याख्या करने और उप-आबादी की पहचान करने के लिए जो मॉडल सटीकता या विफलता से असमान रूप से प्रभावित होते हैं। हम जांच करते हैं कि सामग्री कौन पोस्ट कर रहा है, और सामग्री कहां पोस्ट की गई है। हम पाते हैं कि जबकि लेखक की विशेषताएं समुदाय की विशेषताओं की तुलना में भ्रामक सामग्री के बेहतर भविष्यवाणियों हैं, दोनों विशेषताएं मॉडल प्रदर्शन के साथ दृढ़ता से सहसंबद्ध हैं। पारंपरिक प्रदर्शन मीट्रिक जैसे कि F1 स्कोर विशिष्ट लेखकों जैसे अलग-थलग उप-आबादी पर खराब मॉडल प्रदर्शन को कैप्चर करने में विफल हो सकता है, और इस तरह, धोखे का पता लगाने वाले मॉडल का अधिक सूक्ष्म मूल्यांकन महत्वपूर्ण है।', 'ga': 'Is féidir postálacha nuachta mealltacha a roinntear i bpobail ar líne a bhrath le samhlacha NLP, agus díríodh go leor taighde le déanaí ar fhorbairt samhlacha den sórt sin. Sa saothar seo, bainimid úsáid as saintréithe na bpobal agus na n-údair ar líne — comhthéacs conas agus cá háit a phostáiltear ábhar — chun feidhmíocht samhail braite mheabhlaireachta líonra néaraigh a mhíniú agus chun fo-dhaonra a aithint a bhfuil tionchar díréireach ag cruinneas nó teip na samhla orthu. Scrúdaímid cé atá ag postáil an ábhair, agus cá háit a gcuirtear an t-ábhar sa phost. Faighimid amach, cé gur tuar níos fearr iad saintréithe údair ar ábhar mealltach ná ar shaintréithe pobail, go bhfuil comhghaol láidir idir an dá thréith agus feidhmíocht na samhla. D’fhéadfadh go dteipfeadh ar mhéadracht feidhmíochta traidisiúnta ar nós scór F1 drochfheidhmíocht na samhla a ghabháil ar fhodhaonraí iargúlta amhail údair shonracha, agus mar sin, tá sé ríthábhachtach meastóireacht níos nua a dhéanamh ar mhúnlaí braite meabhlaireachta.', 'el': 'Οι παραπλανητικές δημοσιεύσεις ειδήσεων που μοιράζονται σε διαδικτυακές κοινότητες μπορούν να ανιχνευθούν με μοντέλα και πολύ πρόσφατη έρευνα έχει επικεντρωθεί στην ανάπτυξη τέτοιων μοντέλων. Σε αυτή την εργασία, χρησιμοποιούμε χαρακτηριστικά διαδικτυακών κοινοτήτων και συγγραφέων στο πλαίσιο του πώς και πού δημοσιεύεται περιεχόμενο για να εξηγήσουμε την απόδοση ενός μοντέλου ανίχνευσης εξαπάτησης νευρωνικών δικτύων και να εντοπίσουμε υποπληθυσμούς που επηρεάζονται δυσανάλογα από την ακρίβεια ή αποτυχία του μοντέλου. Εξετάζουμε ποιος δημοσιεύει το περιεχόμενο και πού δημοσιεύεται το περιεχόμενο. Διαπιστώνουμε ότι ενώ τα χαρακτηριστικά του συγγραφέα είναι καλύτεροι παράγοντες πρόβλεψης παραπλανητικού περιεχομένου από τα χαρακτηριστικά της κοινότητας, και τα δύο χαρακτηριστικά συσχετίζονται έντονα με την απόδοση του μοντέλου. Οι παραδοσιακές μετρήσεις απόδοσης, όπως η βαθμολογία F1, ενδέχεται να αποτύχουν να αποτυπώσουν την κακή απόδοση του μοντέλου σε απομονωμένους υποπληθυσμούς, όπως συγκεκριμένους συγγραφείς, και ως εκ τούτου, η πιο διαφοροποιημένη αξιολόγηση των μοντέλων ανίχνευσης εξαπάτησης είναι κρίσιμη.', 'hu': 'Az online közösségekben megosztott megtévesztő hírek észlelhetők NLP modellekkel, és a legújabb kutatások az ilyen modellek fejlesztésére összpontosítottak. Ebben a munkában az online közösségek és szerzők jellemzőit használjuk fel - a tartalom közzétételének és helyének kontextusát -, hogy elmagyarázzuk egy neurális hálózati megtévesztési modell teljesítményét és azonosítsuk azokat az alpopulációkat, amelyeket aránytalanul befolyásolnak a modell pontossága vagy hiba. Megvizsgáljuk, hogy ki teszi közzé a tartalmat, és hol teszi közzé a tartalmat. Úgy találjuk, hogy bár a szerzői jellemzők jobban előrejelzik a megtévesztő tartalmat, mint a közösségi jellemzőket, mindkét jellemző erősen korrelálódik a modell teljesítményével. A hagyományos teljesítménymutatók, mint például az F1 pontszám, nem tudnak gyenge modellteljesítményt rögzíteni az elszigetelt alcsoportok, például egyes szerzők esetében, és mint ilyen, kritikus fontosságú a megtévesztés észlelési modellek árnyalatosabb értékelése.', 'ka': 'ევკეპტიგური ინფორმაციის პოსტი, რომელიც ინტერნეტიური საზოგადოებში გაყოფილი შესაძლებელია NLP მოდელებით განახლება, და ბევრი ახალგაზომის შესწავლება ასეთი მოდე ამ სამუშაოში, ჩვენ ინტერნეტური საზოგადოებების და ავტორების პროგრამეტრების გამოყენება - როგორ და სადაც მუშაობის მონაცემების კონტექტიკური გამოყენება - რომ განახსნათ ნეიროლური ქსელის მოდელის გამოყენებ ჩვენ შევხედავთ ვინ შეექმნა და სად შეექმნა გადატანა. ჩვენ აღმოჩნეთ, რომ საზოგადოებო პროგრატიკები უკეთესი პროგრატიკებია, როცა საზოგადოებო პროგრატიკებისგან, ორივე პროგრატიკები ძალიან კოლე ტრადიციონალური გამოსახულება მეტრიკები, როგორც F1 წერტილი, შეიძლება არ შეუძლებელია წარმოიდგინოთ ცოტა მოდელური გამოსახულებაზე, როგორც სპეციფიკური ავტორები, და როგორც ასე, უფრო', 'lt': 'Naudojant NLP modelius galima nustatyti apgaulingus žinių postus internetinėse bendruomenėse, o daugelis neseniai atliktų mokslinių tyrimų metu daugiausia dėmesio skiriama tokių modelių kūrimui. Šiame darbe naudojame internetinių bendruomenių ir autorių charakteristikas - turinio pateikimo kontekstą ir vietą - paaiškinti neurologinio tinklo apgaulės nustatymo modelio veikimą ir nustatyti subpopuliacijas, kurios yra neproporcingai paveiktos modelio tikslumu arba nesėkme. Mes nagrinėjame, kas skelbia turinį ir kur jis skelbiamas. Mes manome, kad nors autorių savybės yra geresni apgaulingo turinio prognozuotojai nei bendruomenės savybės, abi savybės labai koreliuojamos su modelio savybėmis. Tradiciniai veikimo rodikliai, pavyzdžiui, F1 balas, gali nesugebėti nustatyti blogų modelio veikimo izoliuotose subpopuliacijose, pavyzdžiui, konkrečiuose autoriuose, ir todėl labai svarbu nuodugniau įvertinti apgaulės nustatymo modelius.', 'kk': 'Интернетте ортақтастырылған жаңалық пошталар NLP үлгілерімен байқауға болады, жуырдағы зерттеулер осы үлгілерді жасау үшін көптеген. Бұл жұмыс ішінде, онлайн жиындар мен авторлардың қалай жіберілген контексті және қайда жазылған қасиеттерін қолданамыз, невралдық желіліктерді табу үлгісін түсіндіру үшін және үлгісінің дұрыс не жаңылыс қасиеттерінің ішкі Біз мазмұнын кім жіберетін және мазмұнын қайда жіберетінін тексереміз. Автордың қасиеттері қоғамдылық қасиеттерінен артықшылық мазмұнын таңдау үшін, екеуі қасиеттері үлгілікті істеу үшін қасиеттермен қатысты. F1 нүктесі секілді традиционалдық істеу метрикалары, бұл жерде бөлікті аутентификациялардың, мысалы, аутентификацияларды анықтау үлгілерінің көп үлгісін қабылдау мүмкін емес.', 'it': "I post di notizie ingannevoli condivisi nelle comunità online possono essere rilevati con modelli NLP, e molte ricerche recenti si sono concentrate sullo sviluppo di tali modelli. In questo lavoro, utilizziamo le caratteristiche delle comunità e degli autori online - il contesto di come e dove il contenuto viene pubblicato - per spiegare le prestazioni di un modello di rilevamento dell'inganno della rete neurale e identificare le sottopopolazioni che sono sproporzionatamente influenzate dall'accuratezza del modello o dal fallimento. Esaminiamo chi sta pubblicando il contenuto e dove viene pubblicato il contenuto. Troviamo che mentre le caratteristiche dell'autore sono migliori predittori di contenuti ingannevoli rispetto alle caratteristiche della comunità, entrambe le caratteristiche sono fortemente correlate con le prestazioni del modello. Le metriche tradizionali delle prestazioni, come il punteggio F1, potrebbero non riuscire a catturare le scarse prestazioni dei modelli su sottopopolazioni isolate, come autori specifici, e come tale, una valutazione più sfumata dei modelli di rilevamento degli inganni è fondamentale.", 'mk': 'Деeptивни вести постови споделени во онлајн заедниците може да се детектираат со моделите на НЛП, а многу неодамнешните истражувања се фокусираа на развојот на вакви модели. Во оваа работа, ги користиме карактеристиките на онлајн заедниците и авторите - контекстот на тоа како и каде се поставува содржината - за да ја објасниме извршноста на моделот за детекција на невронската мрежа за измама и да ги идентификуваме подпопулациите кои се непропорционално влијаени од точноста на модел Го испитуваме кој ја поставува содржината и каде се поставува содржината. Најдовме дека иако карактеристиките на авторот се подобри предвидувачи на измамна содржина отколку на карактеристиките на заедницата, двете карактеристики се силно поврзани со производството на моделот. Традиционалните метрики на перформанса како што е оценката F1 можеби не можат да ја зафатат лошата перформанса на моделот на изолираните подпопулации како што се специфичните автори, и како такво, поконуанцираната оценка на моделите за детективирање на измами е критична.', 'ml': 'ഓണ്\u200dലൈന്\u200d സമൂഹത്തില്\u200d പങ്കുചേര്\u200dക്കുന്ന വാര്\u200dത്തകളുടെ പോസ്റ്റുകള്\u200d NLP മോഡലുകളുമായി കണ്ടുപിടിക്കാന്\u200d സാധിക്കുന്നു.  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, ഞങ്ങള്\u200d ഓണ്\u200dലൈന്\u200d സമൂഹത്തിന്\u200dറെയും രചയിതാക്കളുടെയും സ്വഭാവങ്ങള്\u200d ഉപയോഗിക്കുന്നു- എങ്ങനെയാണ് ഉള്ളടക്കം പോസ്റ്റ് ചെയ്യപ്പെടുന്നത്- ന്യൂറല്\u200d നെറ്റോ ഉള്ളടക്കം ആരാണ് പോസ്റ്റ് ചെയ്യുന്നതെന്ന് നമ്മള്\u200d പരിശോധിക്കുന്നു, അതിലെ ഉള്ളടക്കം എവിടേക് ഞങ്ങള്\u200d കണ്ടെത്തുന്നുണ്ടെങ്കില്\u200d രചയിതാവിന്റെ വ്യക്തിത്വങ്ങള്\u200d സമൂഹത്തിനെക്കാള്\u200d വഞ്ചിക്കുന്ന വസ്തുക്കളുടെ പ്രവചനങ്ങള എഫ്\u200c1 സ്കോര്\u200d പോലുള്ള പാഠമായ പ്രവര്\u200dത്തനങ്ങള്\u200d പിടികൂടാന്\u200d പരാജയപ്പെടുന്നു', 'ms': 'Pos berita penipuan berkongsi dalam komuniti online boleh dikesan dengan model NLP, dan kajian baru-baru ini telah fokus pada pembangunan model tersebut. Dalam kerja ini, kami menggunakan ciri-ciri komuniti dan penulis online - konteks bagaimana dan di mana kandungan ditempatkan - untuk menjelaskan prestasi model pengesan penipuan rangkaian saraf dan mengenalpasti sub-populasi yang tidak proporsional terpengaruh oleh ketepatan model atau kegagalan. Kami memeriksa siapa yang memposting kandungannya, dan di mana kandungannya diposting. Kami mendapati bahawa walaupun ciri-ciri penulis lebih baik memprediksi kandungan penipu daripada ciri-ciri komuniti, kedua-dua ciri-ciri berkorrelasi dengan kuat dengan prestasi model. Metrik prestasi tradisional seperti skor F1 mungkin gagal menangkap prestasi model yang buruk pada sub-populasi terisolasi seperti penulis spesifik, dan sebagaimana itu, penilaian lebih nuansi model pengesan penipuan adalah kritikal.', 'mt': 'Postijiet ta’ aħbarijiet deċettivi kondiviżi f’komunitajiet onlajn jistgħu jiġu skoperti b’mudelli NLP, u riċerka ħafna riċenti ffukat fuq l-iżvilupp ta’ mudelli bħal dawn. F’dan ix-xogħol, a ħna nużaw karatteristiċi tal-komunitajiet u l-awturi onlajn - il-kuntest ta’ kif u fejn jiġi ppubblikat il-kontenut - biex jispjegaw il-prestazzjoni ta’ mudell ta’ detezzjoni ta’ ingannament fin-netwerk newrali u jidentifikaw sottopopolazzjonijiet li huma affettwati b’mod sproporzjonat mill-preċiżjoni tal-mudell jew mill-falliment. Aħna jeżaminaw lil min qed jippubblika l-kontenut, u fejn il-kontenut jiġi ppubblikat. Aħna nsibu li filwaqt li l-karatteristiċi tal-awtur jipprevedu kontenut qarrieqi aħjar mill-karatteristiċi tal-komunità, iż-żewġ karatteristiċi huma korrelati b’mod qawwi mal-prestazzjoni tal-mudell. Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.', 'ro': 'Postările de știri înșelătoare partajate în comunitățile online pot fi detectate cu modele PNL, iar multe cercetări recente s-au concentrat pe dezvoltarea unor astfel de modele. În această lucrare, folosim caracteristicile comunităților și autorilor online - contextul modului și unde este postat conținutul - pentru a explica performanța unui model de detectare a înșelăciunii rețelei neurale și pentru a identifica subpopulațiile care sunt afectate disproporționat de acuratețea sau eșecul modelului. Examinăm cine publică conținutul și unde este postat conținutul. Considerăm că, în timp ce caracteristicile autorului sunt predictori mai buni ai conținutului înșelător decât caracteristicile comunității, ambele caracteristici sunt puternic corelate cu performanța modelului. Valorile tradiționale de performanță, cum ar fi scorul F1, pot să nu reușească să surprindă performanța slabă a modelului pe subpopulații izolate, cum ar fi autorii specifici, și, ca atare, evaluarea mai nuanțată a modelelor de detectare a înșelăciunii este esențială.', 'sr': 'Deceptivni novinski posti koji su dijelili u internetskim zajednicama mogu se otkriti sa modelima NLP, a mnogo nedavnih istraživanja se fokusiralo na razvoj takvih modela. U ovom poslu koristimo karakteristike internetske zajednice i autora - konteksta kako i gdje se stavlja sadržaj - kako bi objasnili učinkovitost model a detekcije neuralne mreže i identifikovali podpopulacije koje su neproporciono uticale na model tačnost ili neuspjeh. Ispitujemo ko postavlja sadržaj i gde je sadržaj postavljen. Nalazimo da, iako su karakteristike autora bolji predviđači prevaranta sadržaja od karakteristike zajednice, obje karakteristike su jako povezani sa modelom performancom. Tradicionalne metrike izvedbe poput rezultata F1 možda ne mogu uhvatiti loše modelne izvedbe na izoliranim podpopulacijama poput specifičnih autora, a kao što je takva, važnija je više procjena modela detekcije prevare.', 'si': 'ඇන්ලයින් සමාජිකයේදී සංවිධානයෙන් වෙනුවෙන් ප්\u200dරතිචාර පොස්ට්ස් එක්ක NLP මොඩේල් එක්ක හොයාගන්න පුළුව මේ වැඩේ අපි ඇන්ලයින් සමාජය සහ ලේඛකයන්ගේ විශේෂතාවක් භාවිත කරනවා - කොහොමද හා කොහොමද සාමාජිකය පැත්ත කරලා තියෙන්නේ - න්\u200dයුරල් ජාල විශ්වාසික අපි පරීක්ෂා කරනවා කවුද සාමාන්ය පොස්ටල් කරන්නේ, ඒ වගේම සාමාන්ය පොස්ටල් කරන්නේ. අපිට හොයාගන්න පුළුවන් විශේෂතාවක් සමාජ විශේෂතාවක් වඩා හොඳ සාමාජික විශේෂතාවක් වඩා විශේෂතාවක් ව සාමාන්\u200dය ප්\u200dරවේශනය මෙට්\u200dරික්ස් වගේ F1 ස්කෝර් වලට අපරාධ වෙන්න පුළුවන් අපරාධ වෙන්නේ අපරාධ විශේෂ ප්\u200dරවේශනය සමහර විශේෂ ල', 'mn': 'Интернет нийгэмд хуваалцах шинэ мэдээлэл NLP загваруудын хувьд нээлттэй болно. Саяхны судалгаа ийм загваруудыг хөгжүүлэхэд төвлөрсөн. Энэ ажил дээр бид онлайн нийгмийн болон зохиолчдын өөрчлөлтийг ашиглаж, хэрхэн болон хаана бүтээгдэхүүний нөхцөл байдлыг тайлбарлаж, мэдрэлийн сүлжээний шийдвэрлэлийн загварыг тодорхойлж, загварын зөв эсвэл алдагдлын нөлөөлдөг суб Бид хэн бүтээгдэхүүнийг залгаж байгааг, хаана бүтээгдэхүүнийг залгаж байгааг судалж байна. Бид зохиолч чанар нь нийгмийн чанараас илүү хуурамч бүтээгдэхүүний тодорхойлогч байхад хоёр чанар загварын үйлдэлтэй холбоотой байдаг. F1 оноо шиг уламжлалтын үйл ажиллагааны метрик нь тодорхой зохиолчид зөвхөн загварын үйл ажиллагааг ашиглаж чадахгүй байж болно.', 'no': 'Deceptive news posts shared in online communities can be found with NLP models, and much recent research has focused on the development of such models. I denne arbeida bruker vi karakteristika av nettverkssamfunn og utviklarar - konteksten av korleis og kor innhaldet vert postet - for å forklare utviklinga av ein neuralnettverksoppdagingsmodell og identifisere underpopulasjonar som er motsatt påvirka av modellen nøyaktig eller feil. Vi undersøker kva som sender innhaldet og kor innhaldet vert sendt til. Vi finn at mens utviklareigenskapane er bedre forhåndsvisingar av vilkårleg innhald enn fellesske karakteristikk, både karakteristika er sterkt korrelatert med modellen. Tradisjonale utviklingsmeterikk som F1-poeng kan ikkje henta dårlige modelleutviklingar på isolerte underpopulasjonar som spesifikke utviklarar, og slik er det kritisk meir nuanced evaluering av modeller for oppdaging av deltak.', 'pl': 'Oszukujące posty informacyjne udostępniane w społecznościach internetowych można wykryć za pomocą modeli NLP, a wiele ostatnich badań skupiło się na rozwoju takich modeli. W niniejszej pracy wykorzystujemy cechy społeczności internetowych i autorów w kontekście sposobu i gdzie treści są publikowane do wyjaśnienia wydajności modelu wykrywania oszustw sieci neuronowej oraz identyfikacji podpopulacji, które są nieproporcjonalnie wpływane poprawnością lub awarią modelu. Badamy, kto publikuje treść i gdzie jest publikowana. Stwierdzono, że chociaż cechy autora są lepszymi predyktorami zwodniczych treści niż cechy społeczności, obie cechy są silnie skorelowane z wydajnością modelu. Tradycyjne wskaźniki wydajności, takie jak wynik F1, mogą nie pokazać słabej wydajności modelu w izolowanych podpopulacjach, takich jak konkretni autorzy, dlatego bardziej niuansowana ocena modeli wykrywania oszustw ma kluczowe znaczenie.', 'sv': 'Bedrägeriska nyhetsinlägg som delas i onlinegrupper kan upptäckas med NLP-modeller, och mycket ny forskning har fokuserat på utvecklingen av sådana modeller. I detta arbete använder vi egenskaper hos onlinecommunities och författare – kontexten för hur och var innehåll publiceras – för att förklara prestandan hos en modell för detektering av neurala nätverk och identifiera underpopulationer som påverkas oproportionerligt av modellnoggrannhet eller misslyckande. Vi undersöker vem som publicerar innehållet och var innehållet publiceras till. Vi finner att även om författaregenskaper är bättre prediktorer för vilseledande innehåll än community karakteristika, är båda karakteristika starkt korrelerade med modellprestanda. Traditionella prestandamätningar som F1-poäng kan misslyckas med att fånga dålig modellprestanda på isolerade delpopulationer, till exempel specifika författare, och därför är mer nyanserad utvärdering av modeller för identifiering av bedrägerier avgörande.', 'so': 'Bogagga warbixinta ee ku saabsan shabakada internetka waxaa la ogaan karaa samooyin NLP ah, waxbarasho badan oo ugu dambeysayna waxay ku kalsoonaaday horumarinta modelladan oo kale. Shaqadan, waxaynu isticmaalnaa takhasusyada bulshada internetka iyo qoraalka - kooxada iyo meesha lagu soo bandhigi karo - si aan u caddeyno muuqashada khiyaanada shabakadda neurada ah iyo sidoo kale ayaynu aqoonsanaynaa dadka hoos-tirada ah oo si aan u filnayn u saameyn ku yeelan tusaale saxda ama failed. Waxaynu imtixaannaa qofka ku qoraya waxyaabaha iyo meesha waxyaabaha lagu qoro. Waxaynu ognahay in, inta ay tayada qoraalku leeyihiin ay ka wanaagsan yihiin wax ku qoraya waxyaabaha khiyaanada, labadoodaba waxaa si adag loola xiriiraa sameynta modellka. Qiimeynta farsamada ah, tusaale ahaan kooxaha F1 waxaa suurtogal ah inuu ku qabsado bandhigyada muusikada miskiinka ah oo ku qoran kooxaha hoose-degmada, sida qoraalka gaarka ah, iyo tusaale ahaan qiimeynta qalabka khiyaanada waa muhiim.', 'ta': 'இணைய சமூகத்தில் பகிர்ந்த செய்திகளின் குறிப்புகள் NLP மாதிரிகளுடன் கண்டுபிடிக்க முடியும், மற்றும் அண்மையில் பல ஆராய்ச இந்த வேலையில், நாம் ஆசிரியர்கள் மற்றும் ஆசிரியர்களின் தன்மைகளை பயன்படுத்துகிறோம் - எப்படி மற்றும் உள்ளடக்கங்கள் புதுப்பிக்கப்பட்டிருக்கிறது- புதிய வலைப்பின்னல் பிழை த நாம் உள்ளடக்கத்தை யார் அனுப்புகிறார் என்பதை பரிசோதிக்க வேண்டும், மற்றும் உள்ளடக்கங்கள் எங்கே அனுப நாம் கண்டுபிடிக்கும் என்று நினைக்கிறோம் என்றால் எழுத்தாளரின் தன்மைகள் மாதிரி செயல்பாட்டுடன் மாதிரி செயல்பாட்டில் ம F1 மதிப்பெண்கள் போன்ற பாரமான செயல்முறைகள் சில குறிப்பிட்ட எழுத்தாளர்கள் போன்ற தனிப்பட்ட துணை மக்களில் ஏழை மாதிரி செயல்பாட்டை பிடிக்க இயலாது, போன்ற,', 'ur': 'نالین کمونٹیوں میں تقسیم ہونے والی خبر پوسٹ NLP موڈلوں کے ساتھ آگاہ کر سکتے ہیں، اور بہت اگلے تحقیق ایسے موڈلوں کی توسعہ پر تمرکز کیا گیا ہے. اس کام میں ہم آنلاین کمونٹیوں اور لکھنے والوں کی خصوصیات استعمال کرتے ہیں - کیسے اور کہاں منصوبہ پوسٹ کیے جاتے ہیں - ایک نیورال نیٹ ورک کی دھوکہ کے موڈل کی فعالیت کو توضیح دینے کے لئے اور سو-جماعت کو معلوم کرنے کے لئے جو موڈل دھوکہ یا غلطی سے غیر من اور ہم دیکھتے ہیں کہ وہ کس کی طرف راضی ہوتی ہے اور وہ کس کی طرف راضی ہوتی ہے ہمیں معلوم ہے کہ جب لکھنے کی ویژگی کمونٹی ویژگی سے زیادہ دھوکے کے منصوبات کی پیشگو کرنے والے ہیں، دونوں ویژگی موڈل کی عمدگی سے مضبوط تعلق ہیں. غیر قابل تحقیق متریک جیسے F1 سکوٹ کمزور موڈل کی فعالیت کے ذریعے غیر قابل ہو سکتی ہے، یعنی مخصوص لکھنے والے، اور جیسے، بہت زیادہ دھوکہ ڈیٹ ڈیٹ ڈیٹ موڈل کی تحقیق ضروری ہے.', 'uz': "Name Bu ishda, biz online jamiyatlar va mualliflarning xususiyatlaridan foydalanamiz - tarmoq qanday va qanday mavzu joʻnatilgan holatda - neyrol tarmoqning cheksizlik modelini aniqlash va model tashkilotlarini ko'proq tashkilotga tashkilgan sub-popularni aniqlash uchun. Biz tarkibini qayerda joʻnatishni va tarkibini qayerda joylashtirishni tekshirimiz. Biz o'ylaymiz, mualliflar xususiyatlari jamiyat xususiyatlaridan yaxshi o'xshash o'quvchilar, ikkita xususiyatlar model xususiyatlarida juda katta bog'liq. Anʼanaviy bajarish metriklari F1 scori kabi oddiy mualliflarning bir xil mualliflarni o'zgartirib boʻlmaydi mumkin. Bunday holatda ko'proq qiymatni o'zgartirish modellarini qiymatish muhim.", 'vi': 'Những tin đồn giả dối được chia sẻ trong các cộng đồng trực tuyến có thể được phát hiện bằng các mô hình NMB, và nhiều nghiên cứu gần đây đã tập trung vào việc phát triển các mô hình như vậy. Trong công trình này, chúng tôi sử dụng các đặc trưng của cộng đồng trực tuyến và các tác giả... bối cảnh về cách và nơi chứa nội dung được dán... để giải thích hiệu quả của mô hình phát hiện lừa dối mạng thần kinh và xác định các dân số nằm vùng bị ảnh hưởng lớn bởi độ chính xác hoặc thất bại của mô hình. Chúng tôi sẽ kiểm tra xem ai sẽ đăng nội dung, và nơi chứa nội dung. Chúng tôi thấy rằng mặc dù tác dụng có khả năng dự đoán nội dung ảo tốt hơn tính chất cộng đồng, cả hai đặc tính đều gắn liền với khả năng mô hình. Truyền thống thước đo trình độ, như điểm F1, có thể không ghi được hiệu suất của mô hình kém trên bề mặt bị tách biệt như các tác giả cụ thể, và như thế, đánh giá mơ hồ hơn về các mô hình nhận dạng lừa dối là rất quan trọng.', 'da': 'Bedragende nyhedsindlæg, der deles i online fællesskaber, kan opdages med NLP-modeller, og meget nyere forskning har fokuseret på udviklingen af sådanne modeller. I dette arbejde bruger vi karakteristika ved online fællesskaber og forfattere - konteksten for, hvordan og hvor indhold bliver lagt op - til at forklare ydeevnen af en neuralt netværk bedrageri detektion model og identificere underpopulationer, der er uforholdsmæssigt påvirket af modelnøjagtighed eller fejl. Vi undersøger, hvem der lægger indholdet op, og hvor indholdet lægges op til. Vi finder ud af, at selvom forfatterens karakteristika er bedre forudsigere for vildledende indhold end fællesskabskarakteristika, er begge karakteristika stærkt korreleret med modellens ydeevne. Traditionelle præstationsmålinger som f.eks. F1-score kan ikke registrere dårlig modelpræstation på isolerede delpopulationer, f.eks. specifikke forfattere, og derfor er mere nuanceret evaluering af modeller til detektering af bedrageri afgørende.', 'bg': 'С моделите на НЛП могат да бъдат открити измамни новинарски постове, споделяни в онлайн общности, и много скорошни изследвания са фокусирани върху разработването на такива модели. В тази работа използваме характеристики на онлайн общности и автори - контекста на това как и къде се публикува съдържанието - за да обясним ефективността на модела за откриване на измама на невронната мрежа и да идентифицираме подпопулации, които са непропорционално засегнати от точността или неуспеха на модела. Ние проверяваме кой публикува съдържанието и къде е публикувано съдържанието. Установяваме, че макар характеристиките на автора да са по-добри предсказатели за измамно съдържание, отколкото характеристиките на общността, и двете характеристики са силно свързани с производителността на модела. Традиционните показатели за ефективност, като например оценката може да не успеят да уловят лошото представяне на модела при изолирани подпопулации, като конкретни автори, и като такава, по-нюансирана оценка на моделите за откриване на измама е от решаващо значение.', 'nl': 'Deceptieve nieuwsberichten die worden gedeeld in online communities kunnen worden gedetecteerd met NLP modellen, en veel recent onderzoek heeft zich gericht op de ontwikkeling van dergelijke modellen. In dit werk gebruiken we kenmerken van online communities en auteurs in de context van hoe en waar content wordt gepost om de prestaties van een neuraal network deception detection model uit te leggen en subpopulaties te identificeren die onevenredig worden beïnvloed door model nauwkeurigheid of falen. We onderzoeken wie de content plaatst en waar de content naartoe wordt gepost. Hoewel auteurskenmerken betere voorspellers zijn van misleidende inhoud dan gemeenschapskenmerken, zijn beide kenmerken sterk gecorreleerd met de prestaties van het model. Traditionele prestatiestatistieken, zoals de F1-score, kunnen slechte modelprestaties op geïsoleerde subpopulaties, zoals specifieke auteurs, niet vastleggen. Daarom is een meer genuanceerde evaluatie van fraudedetectiemodellen van cruciaal belang.', 'id': 'Pos berita yang mengecewakan berbagi di komunitas online dapat dideteksi dengan model NLP, dan penelitian baru-baru ini telah fokus pada pengembangan model tersebut. Dalam pekerjaan ini, kami menggunakan karakteristik komunitas dan penulis online - konteks bagaimana dan dimana isi ditempatkan - untuk menjelaskan prestasi model deteksi penipuan jaringan saraf dan mengidentifikasi sub-populasi yang tidak proporsional terpengaruh oleh akurasi model atau kegagalan. Kami memeriksa siapa yang posting isi, dan di mana isi posting. Kami menemukan bahwa meskipun karakteristik penulis adalah prediksor yang lebih baik dari karakteristik komunitas penipu, kedua karakteristik terkait dengan prestasi model. Metrik prestasi tradisional seperti skor F1 mungkin gagal menangkap prestasi model buruk pada sub-populasi terisolasi seperti penulis spesifik, dan sebagai seperti itu, evaluasi lebih nuansi dari model deteksi penipuan adalah kritis.', 'fa': 'پوستهای اخبار منطقی که در جامعه های آنلاین مشترک شده\u200cاند می\u200cتوانند با مدل NLP آشنا شوند، و تحقیقات اخیرا روی توسعه چنین مدل تمرکز کرده\u200cاند. در این کار، ما از ویژگی\u200cهای جامعه\u200cهای آنلاین و نویسندگان استفاده می\u200cکنیم - محتوای چگونه و کجا محتوای قرار داده می\u200cشود - برای توضیح عملکرد یک مدل شناسایی شبکه عصبی و شناسایی زیر جمعیت\u200cها که با دقیق یا شکست مدل غیرقابل تأثیر داده می\u200cشوند. ما امتحان می\u200cکنیم که کدام یک محتویات را می\u200cفرستد و کجا محتویات را می\u200cفرستد. ما متوجه می\u200cشویم که در حالی که ویژگی\u200cهای نویسنده بهتر پیش\u200cبینی\u200cکننده\u200cهای محتوای فریب\u200cگیری از ویژگی\u200cهای جامعه هستند، هر دو ویژگی\u200cها با عملکرد مدل به شدت ارتباط دارند. متریک عملکرد سنتی مثل امتیاز F1 ممکن است از دست دادن عملکرد مدل فقیری در جمعیت\u200cهای زیر\u200cجمعیت\u200cهای مخصوص مانند نویسندگان خاص، و مانند این، ارزیابی بیشتری از مدل\u200cهای شناسایی فریب\u200cگیری مهم است.', 'hr': 'Deceptivne vijesti podijeljene u internetskim zajednicama mogu se otkriti s modelima NLP-a, a mnogo nedavnih istraživanja usredotočilo se na razvoj takvih modela. U tom poslu koristimo karakteristike internetskih zajednica i autora - konteksta kako i gdje se stavlja sadržaj - kako bi objasnili učinkovitost model a detekcije neuralne mreže i identificirali podpopulacije koje su neproporciono utjecale na model preciznost ili neuspjeh. Provjeravamo tko postavlja sadržaj i gdje je sadržaj postavljen. Pronašli smo da, iako su karakteristike autora bolji predviđači prevaranta sadržaja nego karakteristike zajednice, obje karakteristike su čvrsto povezani s modelom učinkovitosti. Tradicionalne mjere učinkovitosti poput rezultata F1 možda ne mogu uhvatiti loše učinkovitost modela na izoliranim podpopulacijama poput posebnih autora, te kao što je takva, kritična je više nuancirana procjena modela otkrivanja prevare.', 'sw': 'Posti za habari zilizowekwa kwenye jamii ya mtandaoni zinaweza kutambuliwa na mifano ya NLP, na utafiti wa hivi karibuni umejikita kwenye maendeleo ya mifano hiyo. Katika kazi hii, tunatumia sifa za jamii za mtandaoni na waandishi - mukhtadha wa namna na jinsi ambavyo maudhui yanavyowekwa - kuelezea ufanisi wa modeli wa udanganyifu wa mtandao wa kijamii na kutambua watu wa chini ambao huathirika kwa uhakika au kushindwa. Tunajaribu ni nani anayeandika maudhui hayo, na ambapo maudhui yanachapishwa. Tunapata kwamba wakati maarifa ya mwandishi ni bora zaidi ya watabiri wa maudhui ya udanganyifu kuliko tabia za jamii, tabia hizo mbili zinaunganishwa sana na utendaji wa mifano. Utawala wa utendaji wa kawaida kama vile vipimo vya F1 vinaweza kushindwa kushindwa kuchukua utendaji wa mifano maskini kwenye idadi ya watu wa vidogo tofauti kama vile waandishi maalum, na kwa mfano, uchunguzi wa mifano ya kudanganya ni muhimu.', 'tr': 'NLP modelleri bilen üýtgedilýän düşünjeli baglaýyşlar online jemgyýetlerde bölünýän ýagdaýlar tapylyp biler. Ýakynda köp araştyrma şeýle modelleriň gelişmesine üns berdi. Bu işde, internet jemgyýetleriniň we awtorlaryň özelliklerini ulanýarys - nähili we nirede daşarylygy goýulýandygynyň konteksti - nähili netwarel şebekeň deňleýänlik nusgasyny tanyşdyrmak üçin we nusgasy bilen nähili derejesi ýa-da netijesi bilen täsirleýän ilatyny Biz maksadyny kimiň goýandygyny we maksadyny nirede goýandygyny barýarys. Munuň pikirimçe awtor karakterlerini jemgyýet karakterlerinden aldatyş maksadynyň has gowydygyny çaklaýan bolsa hem ikisi hem karakterleriň örän netijesi bilen güýçli döwletlidir. F1 अंश ýaly Däpli Görniş Metrici ýaly ýene-täk ilat sanlarynda garyp nusgasy çykyp bilmez bolup biler. Şöyle ýaly, aldatma nusgasyny tanyş modelleriniň has möhüm.', 'sq': 'Deceptive news posts shared in online communities can be detected with NLP models, and much recent research has focused on the development of such models.  Në këtë punë, ne përdorim karakteristikat e komuniteteve online dhe autorëve - kontekstin e sesi dhe ku përmbajtja është publikuar - për të shpjeguar performancën e një modeli të zbulimit të mashtrimit në rrjetin nervor dhe për të identifikuar nënpopullsitë që janë të prekura në mënyrë të pakufizuar nga saktësia e modelit apo dështimi. We examine who is posting the content, and where the content is posted to.  We find that while author characteristics are better predictors of deceptive content than community characteristics, both characteristics are strongly correlated with model performance.  Metrikat tradicionale të performancës të tilla si rezultati F1 mund të dështojnë të kapin performancën e dobët të modelit në nënpopullsitë e izoluara të tilla si autorë specifikë dhe si të tillë, vlerësimi më i nuansuar i modeleve të zbulimit të mashtrimit është kritik.', 'am': 'በይነመረብ ማኅበረሰቦች ውስጥ የተካፈሉት የውይይት ዜና ጽሑፎች ከNLP ዓይነቶች ጋር ማግኘት ይችላል፡፡ በዚህ ሥራ፣ የበይነመረብ ማኅበረሰብ እና ጸሐፊዎች - የጠቅላዊ መረብ ማሳየት ሞዴል እንዴት እና እንዴት እንደተጻፈ እና እንዴት እንደተጻፈ እና የትኛውን ቦታዎች እና በሞዴል ውስጥነት ወይም ስህተት የጎደለውን ደብዳቤዎችን ለማግኘት እና የደብዳቤ ሕዝብ አካባቢ እናውቃለን፡፡ የሆኑን ነገር የሚያስቆም የሆኑንም ወዴት እንዲሰጥ እንፈትናለን። We find that while author characteristics are better predictors of deceptive content than community characteristics, both characteristics are strongly correlated with model performance.  የባሕላዊ የድምፅ ሥርዓት፣ F1 score የሚመስል ድሀ ሞዴል አድራጊዎችን እንደተለያዩ ደብዳቤዎችን በመያዝ አይችልም፣ እንደዚህም፣ የሽንገላ ግንኙነት ማረጋገጫ የሽንገላ ዓይነቶች አዋቂ ነው፡፡', 'de': 'Täuschende Nachrichten, die in Online-Communities geteilt werden, können mit NLP-Modellen entdeckt werden, und viele aktuelle Forschungen haben sich auf die Entwicklung solcher Modelle konzentriert. In dieser Arbeit verwenden wir Merkmale von Online-Communities und Autoren im Kontext, wie und wo Inhalte gepostet werden, um die Leistung eines Betrugserkennungsmodells neuronaler Netzwerke zu erklären und Subpopulationen zu identifizieren, die überproportional von Modellgenauigkeit oder -ausfall betroffen sind. Wir prüfen, wer die Inhalte veröffentlicht und wo die Inhalte gepostet werden. Während Autorenmerkmale bessere Prädiktoren für irreführende Inhalte sind als Community-Merkmale, sind beide Merkmale stark mit der Modellleistung korreliert. Herkömmliche Leistungsmetriken wie der F1-Score erfassen möglicherweise keine schlechte Modellleistung bei isolierten Subpopulationen wie bestimmten Autoren. Daher ist eine differenziertere Bewertung von Betrugserkennungsmodellen von entscheidender Bedeutung.', 'ko': '온라인 커뮤니티에 공유된 사기성 뉴스 게시물은 NLP 모델을 통해 검출할 수 있는데, 최근의 많은 연구들이 이런 모델의 개발에 집중되고 있다.이 작업에서 우리는 온라인 커뮤니티와 저자의 특징인 내용 발표 방식과 장소를 이용하여 신경 네트워크 사기 검측 모델의 성능을 설명하고 모델의 정확성이나 실패의 영향을 가장 많이 받는 하위 그룹을 확정한다.우리는 누가 내용을 발표하고 어디에 발표하는지 검사한다.우리는 저자의 특징이 지역사회 특징보다 사기성 내용을 더 잘 예측하지만 이 두 가지 특징은 모두 모델 성능과 밀접한 관계를 가진다는 것을 발견했다.전통적인 성능 지표(예를 들어 F1점수)는 고립된 서브그룹(예를 들어 특정 작가)의 불량 모델 성능을 포착하지 못할 수 있기 때문에 사기 검측 모델에 대해 더욱 세밀한 평가를 하는 것이 중요하다.', 'af': "Deeptiewe nuuspos gedeel in onlinese gemeenskappe kan ontdek word met NLP-modele, en baie nuutste ondersoek het gefokus op die ontwikkeling van sodanige modele. In hierdie werk, gebruik ons karakteristieke van online gemeenskappe en outeurs - die konteks van hoe en waar inhoud gestuur is - om die prestasie van 'n neurale netwerk verskrikking model te verduidelik en subpopulasie te identifiseer wat onverskillende beïnvloor word deur model presies of mislukking. Ons ondersoek wie die inhoud stuur en waar die inhoud gestuur word. Ons vind dat terwyl outeur karakteristieke beter voorskouers is van bedrog inhoud as gemeenskap karakteristieke, is beide karakteristieke sterk verbreek met model prestasie. Tradisjoneel prestasie metries soos F1 telling dalk mag misluk om arme model prestasie op isolateerde subpopulasie soos spesifieke outeure te vang, en soos sodanige, meer nuanced evaluering van verleiding-opdekking modele is kritiese.", 'hy': 'Օնլայն համայնքներում տարածված խաբեցնող լրատվական տեղադրությունները կարող են հայտնաբերվել ՆԼՊ մոդելների հետ, և շատ վերջին հետազոտություններ կենտրոնացել են նման մոդելների զարգացման վրա: Այս աշխատանքում մենք օգտագործում ենք առցանց համայնքների և հեղինակների առանձնահատկությունները՝ պարունակության տեղադրման կոնտեքստը, բացատրելու համար նյարդային ցանցի խաբեության հայտնաբերման մոդելի արտադրողությունը և հայտնաբերելու համար ենթաբնակչություններ, որոնք անչափ ազդում են մոդելի ճշգր Մենք ուսումնասիրում ենք, թե ով է տեղադրում պարունակությունը և որտեղ է տեղադրվում պարունակությունը: Մենք հայտնաբերում ենք, որ մինչ հեղինակի հատկանիշները ավելի լավ կանխատեսում են խաբեցող պարունակությունը, քան համայնքի հատկանիշները, երկու հատկանիշները ուժեղ կապված են մոդելի արդյունքների հետ: Հավանդական արդյունավետության չափումները, ինչպիսիք են F1 գնահատականը, կարող են ձախողվել նվազում մոդելների վատ արդյունավետությունը մեկուսացված ենթաբնակչության վրա, ինչպիսիք են հատուկ հեղինակները, և որպես այդպիսի, խաբեության հայտնաբերման մոդելների ավելի', 'ca': "Les publicacions de notícies deceptives compartides en comunitats on-line es poden detectar amb models NLP, i molta recent investigació s'ha centrat en el desenvolupament d'aquests models. En aquesta feina, utilitzem característiques de comunitats i autors en línia - el context de com i on es publica el contingut - per explicar el desempeny d'un model de detecció d'enganys en la xarxa neural i identificar subpoblacions que són afectades desproporcionatament per la precisió o el fracàs del model. Examinem qui està publicant el contingut i on està publicat el contingut. Trobem que, mentre que les característiques de l'autor són millors preditors del contingut enganyat que les de la comunitat, les dues característiques estan fortament correlacionades amb el rendiment del model. Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.", 'cs': 'Klamavé zpravodajské příspěvky sdílené v online komunitách lze detekovat pomocí NLP modelů a mnoho nedávných výzkumů se zaměřuje na vývoj těchto modelů. V této práci využíváme charakteristiky online komunit a autorů v kontextu, jak a kde je obsah publikován, abychom vysvětlili výkonnost modelu detekce klamu neuronové sítě a identifikovali subpopulace, které jsou nepřiměřeně ovlivněny přesností nebo selháním modelu. Zkoumáme, kdo obsah zveřejňuje a kam je obsah zveřejněn. Zjišťujeme, že zatímco autorské charakteristiky jsou lepšími prediktory klamavého obsahu než komunitní charakteristiky, obě charakteristiky jsou silně korelovány s výkonností modelu. Tradiční výkonnostní metriky, jako je skóre F1, nemusí zachytit špatný výkon modelu u izolovaných subpopulací, jako jsou konkrétní autoři, a proto je důležitější vyhodnocení modelů detekce klamů.', 'bn': 'অনলাইন সম্প্রদায়ে প্রকাশিত সংবাদ পোস্টগুলো এনএলপি মডেলের সাথে সনাক্ত করা যাবে এবং সাম্প্রতিক গবেষণা এরকম মডেলের উন্নয়নের এই কাজে আমরা অনলাইন সম্প্রদায় এবং লেখকদের চরিত্র ব্যবহার করি- কিভাবে এবং কোথায় বিষয়বস্তু পোস্ট করা হয়- একটি নিউরেল নেটওয়ার্কের প্রতারণার মডেল ব্যাখ্যা করার জন্য এবং সাবজনসংখ্যা  আমরা পরীক্ষা করি বিষয়বস্তু কে পোস্ট করেছে, আর বিষয়বস্তু কোথায় পোস্ট করা হয়েছে। আমরা খুঁজে পাচ্ছি যে যদিও লেখকের চরিত্র সম্প্রদায়ের চরিত্রের চেয়ে ভালো প্রতারণাকারীরা সম্প্রদায়ের প্রতারণাকারীদের চেয়ে  Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.', 'fi': 'Verkkoyhteisöissä jaettuja harhaanjohtavia uutispostauksia voidaan havaita NLP-malleilla, ja paljon tuoretta tutkimusta on keskittynyt tällaisten mallien kehittämiseen. Tässä työssä käytämme verkkoyhteisöjen ja -tekijöiden ominaisuuksia - kontekstia siitä, miten ja missä sisältöä julkaistaan - selittämään neuroverkon petoksen havaitsemismallin suorituskykyä ja tunnistamaan alapopulaatioita, joihin mallin tarkkuus tai epäonnistuminen vaikuttaa suhteettomasti. Tutkimme, kuka julkaisee sisältöä ja mihin sisältö on lähetetty. Havaitsemme, että vaikka tekijän ominaisuudet ennustavat paremmin harhaanjohtavaa sisältöä kuin yhteisön ominaisuudet, molemmat ominaisuudet korreloivat vahvasti mallin suorituskykyyn. Perinteiset suorituskykymittarit, kuten F1-pisteet, eivät välttämättä onnistu kuvaamaan huonoa mallin suorituskykyä yksittäisillä alapopulaatioilla, kuten tietyillä tekijöillä, ja siksi petosten havaitsemismallien monivivahteisempi arviointi on kriittistä.', 'az': 'NLP modelləri ilə paylaşdığı qətiyyətli xəbər məktubları keşf edə bilər və bu modellərin təhsil edilməsinə çox son dərhal təhsil edilir. Bu işdə, onlayn ümmətlərin və yazıcıların özelliklərini - məlumatın necə və hansı məlumatın yayınlanması - nöral a ğ aldatması modelinin təsdiqlənməsini və modellərin doğruluğuna və başarısızlığına müvafiq təsirlərini təsdiq etmək üçün istifadə edirik. Biz məlumatları kimin yolladığını və məlumatların haraya göndərildiyini təsdiqləyirik. Əgər yazıcı özellikləri toplum özelliklərindən daha yaxşı müəyyənləşdirirlərsə, hər ikisi də modeli performans ilə çox bağlıdır. F1 nöqtəsi kimi sadiq performans metriklərinin bənzəri, bənzəri təkrar yazıcılar kimi təkrar-təkrar üzərində zəif modellərin performansını yakalaması imkansız olar, və bənzəri, yalançılıq tanımlama modellərinin daha nuancı değerlendirməsi kritik olar.', 'bs': 'Deceptivni novinski posti koji su dijelili u internetskim zajednicama mogu se otkriti s modelima NLP, a mnogo nedavnih istraživanja se fokusiralo na razvoj takvih modela. U ovom poslu koristimo karakteristike online zajednica i autora - konteksta kako i gdje se stavlja sadržaj - kako bi objasnili učinkovitost model a detekcije neuralne mreže i identifikovali podpopulacije koje su neproporciono uticale na model preciznost ili neuspjeh. Istražujemo ko postavlja sadržaj i gdje je sadržaj postavljen. Pronašli smo da, iako su karakteristike autora bolji predviđači prevaranta sadržaja nego karakteristike zajednice, obje karakteristike su čvrsto povezani s modelom performansijom. Tradicionalne metrike funkcionalnosti poput rezultata F1 možda ne mogu uhvatiti loše modelne funkcije na izoliranim podpopulacijama poput specifičnih autora, te kao što je takva, kritična je više nuancirana procjena modela detekcije prevare.', 'et': 'NLP mudelitega saab tuvastada veebikogukondades jagatud pettuslikke uudistepostitusi ja paljud hiljutised uuringud on keskendunud selliste mudelite arendamisele. Käesolevas töös kasutame veebikogukondade ja autorite omadusi - sisu postitamise konteksti - selleks, et selgitada neurovõrgu pettuse tuvastamise mudeli toimimist ja tuvastada alampopulatsioone, keda mudeli täpsus või rike ebaproportsionaalselt mõjutab. Me uurime, kes sisu postitab ja kuhu sisu postitatakse. Leiame, et kuigi autori omadused ennustavad paremini petlikku sisu kui kogukonna omadusi, on mõlemad omadused tugevalt korrelatsioonis mudeli jõudlusega. Traditsioonilised jõudlusnäitajad, näiteks F1 skoor, ei pruugi jäädvustada mudeli halba jõudlust üksikute alampopulatsioonide puhul, näiteks konkreetsete autorite puhul, ja seetõttu on pettuse tuvastamise mudelite nüanssidega hindamine kriitilise tähtsusega.', 'ha': "Ana iya gane maimailsayen da aka shara su cikin jamii masu mitandaki na Intanet, kuma zan yi amfani da zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane a ƙara shekara masu motsi kamar wannan. Daga wannan aikin, Munã amfani da masu hushi na jamii da ma'abũta-mazaɓa na samun mutane - muhimmin da aka poste maɓallin - dõmin ya bayyana mafarin misãlai na dangani wa dangani na jerin neurar-tarayya kuma mu gane sub-popular waɗanda bã da daidaici ba na yi musamman da tsarin misãlai ko kuma ba'a yi ɓarna ba. Kuma dõmin Mu jarraba wane ne zai jinkirta cikin takardan da za a saka gudan. Tune gane cewa, a lokacin da marubuci masu amfani da matsayi sun fi zama mafiya alhẽri ga mãsu bashirin abin da ke cikin dukkan jama'a, masu hususanta biyu suna da mai ƙarfin sami'a. Taimaki na zaman shawarar da aka kama sifar F1, mai yiwuwa ya yi kusa ta kãma mai misalin misalin misali a kan subpopular da aka rarraba, kamar misãlan mutane masu ƙayyade, kuma, yana da muhimmi ga ƙidãya wa misãlai za'aɓa.", 'jv': 'Daftar winih sing dibenakake nang komunitas online iso diantedekake karo model NLP, lan akeh barêng-barêng sing tek gawe ngulok akeh model sing dumadhi iki. Nang gunggo iki, kéné gambar cara-cara sing nggawe komunitas online lan autor - sampek kontribusi kapan karo hal kudu penting nggawe kudu nggawe barang nggawe sistem netwisan karo modèl dadi nambah sing nguasai perbudhakan winih dhéwé Awak dhéwé éntuk ané sing ngubah nggambar barang-barang. Awak dhéwé luwih akeh cara-cara sing luwih apik dhéwé nang ngerasahan perbudhakan winih sing luwih dumadhi, akeh dhéwé cara-cara ngono ngono akeh modèl Traditional', 'he': 'פוסטים חדשות משותפים בקהילות באינטרנט יכולים לגלות עם דוגמנים NLP, ומחקר הרבה לאחרונה התמקד בפיתוח של דוגמנים כאלה. בעבודה הזו, אנו משתמשים במאפיינים של קהילות וסופרים באינטרנט - הקשר של איך והיכן תוכן מופיע - כדי להסביר את ההופעה של מודל זיהוי רשת עצבית רמות רמות ונזיהה את הת-אוכלוסיות שמשפעות באופן לא פרופורציוני על ידי מדויקת מודל או כישלון. אנחנו בודקים מי פורסם את התוכן, ואיפה התוכן פורסם. אנו מוצאים שלמרות שהאופיינים של הסופרים הם חזיקים טובים יותר של תוכן הונאי מאשר אופיינים של הקהילה, שני האופיינים קשורים חזק לביצוע מודל. Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.', 'sk': 'Zavajajoče objave novic, ki jih delijo spletne skupnosti, je mogoče zaznati z modeli NLP, številne nedavne raziskave pa so se osredotočile na razvoj takih modelov. V tem delu uporabljamo značilnosti spletnih skupnosti in avtorjev - kontekst kako in kje je vsebina objavljena - za pojasnitev delovanja modela za zaznavanje prevare nevronskega omrežja in identificiranje podpopulacij, ki jih nesorazmerno vpliva natančnost ali okvara modela. Preučimo, kdo objavlja vsebino in kam je vsebina objavljena. Ugotovili smo, da so značilnosti avtorjev boljši napovedniki zavajajoče vsebine kot značilnosti skupnosti, obe značilnosti pa sta močno povezani z uspešnostjo modela. Tradicionalne meritve učinkovitosti, kot je rezultat F1, morda ne bodo zajele slabe učinkovitosti modela pri izoliranih podpopulacijah, kot so določeni avtorji, zato je ključnega pomena bolj natančno ocenjevanje modelov zaznavanja prevar.', 'bo': 'དྲ་བའི་ཚོགས་སྡེའི་ནང་དུ་དམིགས་འཛུགས་ཀྱི་བརྡ་ཞིག་བྱས་པ་དེ་ནི་NLP དཔེ་དབྱིབས་རྟོགས་ཐུབ་པ་དང་ཉེ་ཆར་བརྗོད་ཀྱི་ལྟ་སྟངས་འདི་དག་གི་ ང་ཚོས་དྲ་རྒྱའི་སྤྱི་ཚོགས་དང་རྩོམ་པ་ཚོའི་ཁྱད་ཆོས་ཀྱི་ཁྱད་ཆོས་ཀྱི་རྣམ་པ་སྤྱད་ནས། ང་ཚོས་ནང་དོན་ཡིག་ཆ་འདྲ་བཤུ་བྱེད་མི་འདུག ང་ཚོར་རྩོམ་པ་གྱི་ཁྱད་ཆོས་ཉིད་དེ་ཚོ་སྤྱི་ཚོགས་ཀྱི་ཁྱད་ཆོས་མང་པོ་ཡིན་པའི་སྔོན་སྒྲིག་ཆོས་རྣམས་མེད་པའི་ནང་དོན་ Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.'}
{'en': 'DamascusTeam at NLP4IF2021 : Fighting the Arabic COVID-19 Infodemic on Twitter Using AraBERT', 'ar': 'فريق دمشق في NLP4IF2021: محاربة الوباء المعلوماتي لـ COVID-19 العربي على Twitter باستخدام AraBERT', 'fr': "L'équipe de Damascus au NLP4IF2021\xa0: Lutter contre l'infodémie COVID-19 en arabe sur Twitter à l'aide d'AraBert", 'pt': 'DamascusTeam no NLP4IF2021: Combatendo a infodemia árabe COVID-19 no Twitter usando AraBERT', 'es': 'El equipo de Damasco en NLP4IF2021: Luchando contra la infodemia árabe de COVID-19 en Twitter con AraBert', 'ja': 'NLP 4 IF 2021のダマスカスチーム： AraBERTを使用したTwitterでのアラビア語新型コロナウイルス感染症の流行との戦い', 'zh': '大马士革团队于NLP4IF2021:用AraBERT拒疾于Twitter阿拉伯语COVID-19信息', 'hi': 'NLP4IF2021 में दमिश्कटीम: AraBERT का उपयोग करके ट्विटर पर अरबी कोविड -19 इन्फोडेमिक से लड़ना', 'ru': 'ДамаскКоманда на NLP4IF2021: Борьба с арабской инфодемией COVID-19 в Twitter с помощью AraBERT', 'ga': 'Foireann Damaisc ag NLP4IF2021: Infodemic Araibis COVID-19 a Chomhrac ar Twitter Ag Úsáid AraBERT', 'el': 'Ομάδα Δαμασκού στο NLP4IF2021: Καταπολέμηση του αραβικού ενημερωτικού δελτίου στο Twitter χρησιμοποιώντας το AraBERT', 'ka': 'DamascusTeam at NLP4IF2021: Fighting the Arabic COVID-19 Infodemic on Twitter using AraBERT', 'hu': 'Damaszkuscsapat az NLP4IF2021-en: Az arab COVID-19 Infodemic elleni harc a Twitteren AraBERT segítségével', 'kk': 'NLP4IF2021 деген Дамаск тобы: Твиттерде АраBERT қолдану араб COVID-19 мәліметтеріне қарсы', 'mk': 'Дамаскус тим на NLP4IF2021: Борба против арапскиот COVID-19 инфодемик на Твитер користејќи го AraBERT', 'it': "DamascusTeam a NLP4IF2021: Combattere l'infodemic arabo COVID-19 su Twitter utilizzando AraBERT", 'lt': 'Damasko komanda NLP4IF2021: Kova su Arabų COVID-19 informademika Twitter naudojant AraBERT', 'ml': 'NLP4IF2021-ലെ ദമാസ്സുസ് ടീം: അരാബെര്\u200dട്ടിയെ ഉപയോഗിക്കുന്നതില്\u200d അറബി കോവിഡി-19 വിവരങ്ങള്\u200d യുദ്ധം ചെയ്യുന്നു', 'mt': 'Tim ta’ Damasku f’NLP4IF2021: Il-ġlieda kontra l-COVID-19 Infodemic Għarbi fuq Twitter bl-użu ta’ AraBERT', 'ms': 'Pasukan Damaskus di NLP4IF2021: melawan COVID-19 Infodemic Arab di Twitter menggunakan AraBERT', 'mn': 'NLP4IF2021 оны Дамаск баг: Твиттерт Араберт ашиглаж Араб-19 мэдээллийн тухай тулалдаг.', 'pl': 'DamaszkuZespół na NLP4IF2021: Walka z arabską infodemią COVID-19 na Twitterze za pomocą AraBERT', 'no': 'DamaskusTeam at NLP4IF2021: Figur med den arabiske COVID-19 Infodemiske på Twitter Bruk AraBERT', 'ro': 'DamascTeam la NLP4IF2021: Lupta cu infodemicul arab COVID-19 pe Twitter folosind AraBERT', 'si': 'ඩැම්ස්කුස් කණ්ඩායමය NLP4IF2021: අරාබිර්ට් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා අරාබිර්ට්', 'ta': 'DamascusTeam at NLP4IF2021: Fighting the Arabic COVID-19 Infodemic on Twitter Using AraBERT', 'sr': 'Damaskus tim na NLP4IF2021: borba protiv arapske informademije COVID-19 na Twitter Koristeći AraBERT', 'so': 'DamascusTeam at NLP4IF2021: Fighting Arabic COVID-19 Infodemic on Twitter using AraBERT', 'sv': 'DamaskusTeam på NLP4IF2021: Bekämpa den arabiska COVID-19 Infodemic på Twitter med AraBERT', 'ur': 'ڈامسک تیم NLP4IF2021 میں: ٹویٹر پر عربی COVID-19 Infodemic سے لڑنے کی', 'uz': 'Name', 'vi': 'Tổ chức Damascus ở NLLL4IF2021: đấu lại COVID-19 Infodemus trên Twitter qua AraBERT.', 'bg': 'Отбор от Дамаск на НЛП4ИФ2021: Борба с арабската инфодемия в Туитър с помощта на Арабер', 'hr': 'DamascusTeam na NLP4IF2021: borba protiv arapske informademije COVID-19 na Twitter Koristeći AraBERT', 'nl': 'DamascusTeam op NLP4IF2021: Vechten tegen de Arabische COVID-19 Infodemic op Twitter met AraBERT', 'da': 'DamaskusTeam på NLP4IF2021: Bekæmpelse af den arabiske COVID-19 Infodemic på Twitter ved hjælp af AraBERT', 'fa': 'تیم داماسک در NLP4IF2021: مبارزه با اطلاعات عربی COVID-19 در توئیتر با استفاده از آراBERT', 'ko': 'NLP4IF2021 콘퍼런스에서의 다마스쿠스: 아라비트를 이용해 트위터에서 아랍 코로나에 맞서 싸우다', 'de': 'DamaskusTeam auf der NLP4IF2021: Kampf gegen die arabische COVID-19 Infodemic auf Twitter mit AraBERT', 'sw': 'Timu ya Damascus katika NLP4IF2021: Kupigana na taarifa za Kiarabu COVID-19 kwenye mtandao wa Twita kwa kutumia AraBERT', 'af': 'DamaskusTeam by NLP4IF2021: Geveg van die Arabiese KoVID-19 Inligtingsdemie op Twitter deur AraBERT te gebruik', 'tr': 'DamaskusTeam at NLP4IF2021: Fighting the Arabic COVID-19 Infodemic on Twitter Using AraBERT', 'sq': 'Ekipi i Damaskut në NLP4IF2021: Lufta kundër informacionit arab COVID-19 në Twitter duke përdorur AraBERT', 'hy': 'Դամասկուսային թիմը (ՆԼՊ4IF2021-ում): Արաբական COVID-19 ինֆոդեմիայի դեմ պայքարելը Արաբերթ օգտագործելով Թվիթերում', 'am': 'ደማስቆስ Team (NLP4IF2021: Arabic COVID-19 Infodemic) በትዊተር ተጠቃሚ AraBERT', 'bs': 'Damaskus tim na NLP4IF2021: borba protiv arapske informademije COVID-19 na Twitter Koristeći AraBERT', 'bn': 'এনএলপি4IF2021-এ দামেস্ক দল: আরবী কোভিড-১৯ তথ্যের সংগ্রামে টুইটারে আরাবেরেট ব্যবহার করে লড়াই করে', 'az': "NLP4IF2021'd…ô DamascusTeam: AraBERT istifad…ôsi il…ô Twitter'd…ô …ôr…ôbc…ô COVID-19 Infodemisi il…ô vuruŇümaq", 'ca': "L'equip de Damascus a NLP4IF2021: Luctar contra l'àrab COVID-19 Infodemic a Twitter utilitzant AraBERT", 'cs': 'Damaškový tým na NLP4IF2021: Boj proti arabskému infodemii COVID-19 na Twitteru pomocí AraBERT', 'et': 'DamascusTeam NLP4IF2021: Araabia COVID-19 infodeemikuga võitlemine Twitteris AraBERTi abil', 'id': 'Tim Damaskus di NLP4IF2021: Melawan Infodemic COVID-19 Arab di Twitter Menggunakan AraBERT', 'fi': 'DamascusTeam NLP4IF2021: Taistelee arabialaista COVID-19-infodemiikkaa Twitterissä AraBERTin avulla', 'sk': 'DamascusTeam na NLP4IF2021: Boj proti arabskemu COVID-19 Infodemiku na Twitterju z uporabo AraBERT', 'he': 'צוות דמסקוס ב-NLP4IF2021: להילחם באינפודמיקה הערבית COVID-19 בטוויטר בשימוש באראברט', 'ha': 'DamascusTeam at NLP4IF2021: Fighting the Arabic COVID-19 Infodemic on Twitter Using AraBERT', 'jv': 'Ramasaké', 'bo': 'DamascusTeam at NLP4IF2021: Fighting the Arabic COVID-19 Infodemic on Twitter Using AraBERT'}
{'en': 'The objective of this work was the introduction of an effective approach based on the AraBERT language model for fighting Tweets COVID-19 Infodemic. It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label. The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning ; (2) available plain text corpora are larger than tweet-only ones, allowing for better performance.', 'pt': 'O objetivo deste trabalho foi a introdução de uma abordagem eficaz baseada no modelo de linguagem AraBERT para combater Tweets COVID-19 Infodemia. Ele foi organizado na forma de um pipeline de duas etapas, onde a primeira etapa envolveu uma série de procedimentos de pré-processamento para transformar o jargão do Twitter, incluindo emojis e emoticons, em texto simples, e a segunda etapa explorou uma versão do AraBERT, que foi pré-treinado em texto simples, para ajustar e classificar os tweets em relação ao seu rótulo. O uso de modelos de linguagem pré-treinados em textos simples em vez de tweets foi motivado pela necessidade de abordar duas questões críticas evidenciadas pela literatura científica, a saber (1) modelos de linguagem pré-treinados estão amplamente disponíveis em muitos idiomas, evitando o tempo -treinamento de modelo consumidor e intensivo de recursos diretamente em tweets do zero, permitindo focar apenas em seu ajuste fino; (2) os corpora de texto simples disponíveis são maiores do que os apenas tweets, permitindo um melhor desempenho.', 'fr': "L'objectif de ce travail était l'introduction d'une approche efficace basée sur le modèle linguistique AraBert pour lutter contre l'infodémie COVID-19 sur les Tweets. Il a été organisé sous la forme d'un pipeline en deux étapes, la première étape impliquant une série de procédures de prétraitement pour transformer le jargon Twitter, y compris les émoticônes et les émoticônes, en texte brut, et la seconde étape a exploité une version d'AraBert, qui a été préformée sur du texte brut, pour affiner et classer les tweets relatifs à leur étiquette. L'utilisation de modèles linguistiques pré-entraînés sur des textes simples plutôt que sur des tweets a été motivée par la nécessité d'aborder deux problèmes critiques mis en évidence par la littérature scientifique, à savoir (1) les modèles linguistiques préformés sont largement disponibles dans de nombreuses langues, évitant ainsi le modèle fastidieux et gourmand en ressources formation directement sur les tweets à partir de zéro, ce qui permet de se concentrer uniquement sur leur peaufinage\xa0; (2) les corpus en texte brut disponibles sont plus volumineux que les corpus de tweets uniquement, ce qui permet de meilleures performances.", 'ar': 'كان الهدف من هذا العمل هو تقديم نهج فعال يعتمد على نموذج لغة AraBERT لمكافحة التغريدات حول وباء المعلومات COVID-19. تم ترتيبه في شكل خط أنابيب من خطوتين ، حيث تضمنت الخطوة الأولى سلسلة من إجراءات المعالجة المسبقة لتحويل مصطلحات Twitter ، بما في ذلك الرموز التعبيرية والرموز التعبيرية ، إلى نص عادي ، والخطوة الثانية استغلت نسخة من AraBERT ، والتي تم تدريبه مسبقًا على نص عادي لضبط التغريدات وتصنيفها فيما يتعلق بتسميتها. كان الدافع وراء استخدام نماذج اللغة المدربة مسبقًا على النصوص العادية بدلاً من التغريدات هو ضرورة معالجة قضيتين حاسمتين تظهرهما الأدبيات العلمية ، وهما (1) النماذج اللغوية المدربة مسبقًا متوفرة على نطاق واسع في العديد من اللغات ، مع تجنب الوقت - تدريب نموذجي كثيف الاستهلاك للموارد ومباشر على التغريدات من البداية ، مما يسمح بالتركيز فقط على صقلها ؛ (2) تكون المجموعات النصية العادية المتاحة أكبر من مجموعات التغريدات فقط ، مما يسمح بأداء أفضل.', 'es': 'El objetivo de este trabajo fue la introducción de un enfoque eficaz basado en el modelo de lenguaje araBert para combatir los Tweets Infodemic COVID-19. Se organizó en forma de una canalización de dos pasos, donde el primer paso implicó una serie de procedimientos de preprocesamiento para transformar la jerga de Twitter, incluidos emojis y emoticonos, en texto sin formato, y el segundo paso aprovechó una versión de ARaBert, que estaba previamente entrenada en texto sin formato, para afinar y clasificar los tuits con respecto a su Etiqueta. El uso de modelos lingüísticos previamente entrenados en textos sin formato en lugar de tuits estuvo motivado por la necesidad de abordar dos cuestiones críticas mostradas en la literatura científica, a saber, (1) los modelos lingüísticos previamente entrenados están ampliamente disponibles en muchos idiomas, evitando el modelo que consume mucho tiempo y recursos entrenar directamente en los tweets desde cero, lo que permite centrarse solo en su ajuste fino; (2) los corpus de texto sin formato disponibles son más grandes que los de solo tuits, lo que permite un mejor rendimiento.', 'ja': 'この研究の目的は、新型コロナウイルス感染症(COVID -19)と闘うためのAraBERT言語モデルに基づいた効果的なアプローチの導入でした。これは2段階のパイプラインの形で配置され、最初のステップでは、絵文字や絵文字を含むTwitterの専門用語をプレーンテキストに変換するための一連の前処理手順が含まれ、2番目のステップでは、プレーンテキストで事前にトレーニングされたAraBERTのバージョンを利用して、彼らのラベルに関してツイートを微調整し、分類しました。ツイートではなくプレーンテキストで事前にトレーニングされた言語モデルの使用は、科学文献によって示された2つの重要な問題に対処する必要性から動機づけられた。つまり、（ 1 ）事前トレーニングされた言語モデルは、多くの言語で広く利用可能であり、一からツイートに直接集中することを可能にする、時間とリソースのかかるモデルトレーニングを回避し、（ 2 ）利用可能なプレーンテキストのコーラは、ツイートのみのものよりも大きく、より良いパフォーマンスを可能にする。', 'zh': '其引入一本于AraBERT言模之法以抗推文COVID-19信流行。 其二步管,其一步及预处理程序,将Twitter术语(表情符号、表情符号)转为纯文本,第二步用AraBERT版本,该本预练于纯文本,以微调类推文标。 用之纯文本,非推文之先训言语模型动机必决科学文献之二关键问题,即(1)预训之言形于众语之中广可用,免于从头直于推文上耗时与资源密集型者,止许专注其微调。 (2)可用纯文本语料库比仅推文语料库大,可以得善。', 'ru': 'Целью данной работы было внедрение эффективного подхода на основе языковой модели AraBERT для борьбы с твитами COVID-19 Infodemic. Она была организована в виде двухэтапного конвейера, где первый этап включал в себя серию процедур предварительной обработки для преобразования жаргона Twitter, включая эмодзи и эмотиконы, в простой текст, а второй этап использовал версию AraBERT, которая была предварительно обучена на обычном тексте, для тонкой настройки и классификации твитов в отношении их Метки. Использование языковых моделей, предварительно подготовленных по простым текстам, а не по твитам, было мотивировано необходимостью решения двух важнейших вопросов, показанных в научной литературе, а именно: (1) предварительно подготовленные языковые модели широко доступны на многих языках, избегая трудоемкой и ресурсоемкой модели обучения непосредственно по твитам с нуля, позволяя сосредоточиться только на их тонкой настройке; (2) доступные простые текстовые корпуса больше, чем только твиты, что позволяет улучшить производительность.', 'hi': 'इस काम का उद्देश्य ट्वीट्स कोविड -19 इन्फोडेमिक से लड़ने के लिए अराबर्ट भाषा मॉडल पर आधारित एक प्रभावी दृष्टिकोण की शुरुआत करना था। इसे दो-चरणीय पाइपलाइन के रूप में व्यवस्थित किया गया था, जहां पहले चरण में ट्विटर शब्दजाल को बदलने के लिए पूर्व-प्रसंस्करण प्रक्रियाओं की एक श्रृंखला शामिल थी, जिसमें इमोजी और इमोटिकॉन्स शामिल थे, सादे पाठ में, और दूसरे चरण ने अराबर्ट के एक संस्करण का शोषण किया, जिसे सादे पाठ पर पूर्व-प्रशिक्षित किया गया था, ताकि उनके लेबल के संबंध में ट्वीट्स को ठीक किया जा सके और वर्गीकृत किया जा सके। ट्वीट्स के बजाय सादे ग्रंथों पर पूर्व-प्रशिक्षित भाषा मॉडल का उपयोग वैज्ञानिक साहित्य द्वारा दिखाए गए दो महत्वपूर्ण मुद्दों को संबोधित करने की आवश्यकता से प्रेरित था, अर्थात् (1) पूर्व-प्रशिक्षित भाषा मॉडल कई भाषाओं में व्यापक रूप से उपलब्ध हैं, समय लेने वाले और संसाधन-गहन मॉडल प्रशिक्षण से बचने के लिए सीधे खरोंच से ट्वीट्स पर, केवल उनके ठीक-ट्यूनिंग पर ध्यान केंद्रित करने की अनुमति देते हैं; (2) उपलब्ध सादे पाठ कॉर्पोरेट ट्वीट-केवल लोगों की तुलना में बड़े हैं, जो बेहतर प्रदर्शन की अनुमति देते हैं।', 'ga': 'Ba é cuspóir na hoibre seo ná cur chuige éifeachtach a thabhairt isteach bunaithe ar mhúnla teanga AraBERT chun tweets COVID-19 Infodemic a chomhrac. Socraíodh é i bhfoirm píblíne dhá chéim, inar bhain an chéad chéim le sraith nósanna imeachta réamhphróiseála chun béarlagair Twitter, lena n-áirítear emojis agus straoiseoga, a athrú go gnáth-théacs, agus sa dara céim leasaíodh leagan de AraBERT, a réamh-oilte ar ghnáth-théacs, chun na tvuíteanna a mhionchoigeartú agus a rangú maidir lena Lipéad. Spreagadh úsáid na múnlaí teanga réamh-oilte ar ghnáth-théacsanna seachas ar thvuíteanna mar gheall ar an ngá aghaidh a thabhairt ar dhá shaincheist ríthábhachtacha a léirigh an litríocht eolaíoch, is iad sin (1) samhlacha teanga réamhoilte ar fáil go forleathan ina lán teangacha, ag seachaint an ama. - oiliúint eiseamláireach atá íditheach agus dian ar acmhainní go díreach ar thíteanna ón tús, rud a fhágann gur féidir díriú ar a gcuid mionchoigeartaithe amháin; (2) go bhfuil corparáidí gnáth-théacs atá ar fáil níos mó ná na cinn tweet-amháin, rud a cheadaíonn feidhmíocht níos fearr.', 'hu': 'A munka célja az AraBERT nyelvi modelljén alapuló hatékony megközelítés bevezetése volt a COVID-19 Infodemic tweetek elleni küzdelemre. Egy kétlépcsős csővezeték formájában került kialakításra, ahol az első lépés egy sor előfeldolgozási eljárást tartalmazott, amelyek a Twitter zsargonját, beleértve az emojikat és hangulatjeleket, egyszerű szöveggé alakították, a második lépés pedig az AraBERT egy olyan verzióját használta, amelyet előre képzettek a sima szövegre, hogy finomhangolják és osztályozzák a tweeteket a címkéjük tekintetében. Az egyszerű szövegekre, nem tweetekre képzett nyelvi modellek használatát a tudományos szakirodalom által megmutatott két kritikus kérdés kezelésének szükségessége motiválta, nevezetesen (1) az előképzett nyelvi modellek széles körben elérhetők számos nyelven, elkerülve az időigényes és erőforrás-igényes modellképzést közvetlenül a tweeteken a semmiből, lehetővé téve, hogy csak finomhangolásukra összpontosítsunk; (2) A rendelkezésre álló egyszerű szöveges korpuszok nagyobbak, mint a csak tweet-ek, ami jobb teljesítményt tesz lehetővé.', 'ka': 'ამ სამუშაოს მიზეზი იყო ეფექტიური პროგრამის შესახებ, რომელიც AraBERT ენის მოდელისთვის გადაწყენება, რომელიც კოVID-19 ინფორემეტისთვის ბოლობად. ეს იყო ორ-კვადრატის ფორმაში, სადაც პირველი კვადრატი წინაპროცესების წინაპროცესების სერია, რომელიც Twitter-ის წინაპროცესების შეცვლა, რომელიც ემოიზები და ემოტიკონები, სწორი ტექსტიში, და მეორე კვადრატი აპაბერტის ვერსია, რომელიც საუკეთესო ტექს ენის მოდელების გამოყენება, რომლებიც საკუთარ ტექსტში უფრო საკუთარ ტექსტში, უფრო საკუთარ ტექსტში, იყო მოტივიტურებული, რომლებიც მეცნიერო ლიტებერტიაში გამოჩენა ორი კრიტიკური პრობლემა, ანუ (1) საკუთარ საკუთარი ენის მოდელები მსგავსია, რაც მრავა (2) უფრო მეტი ტექსტის კოპორა უფრო დიდია, ვიდრე მხოლოდ ტექსტის კოპორა, რომელიც უფრო მეტი გამოყენება.', 'el': 'Στόχος αυτής της εργασίας ήταν η εισαγωγή μιας αποτελεσματικής προσέγγισης βασισμένης στο γλωσσικό μοντέλο AraBERT για την καταπολέμηση των tweets COVID-19 Infodemic. Διοργανώθηκε με τη μορφή ενός αγωγού δύο βημάτων, όπου το πρώτο βήμα περιελάμβανε μια σειρά διαδικασιών προεπεξεργασίας για τη μετατροπή της ορολογίας του Twitter, συμπεριλαμβανομένων των emoticons και των emoticons, σε απλό κείμενο, και το δεύτερο βήμα εκμεταλλεύτηκε μια έκδοση του AraBERT, η οποία ήταν προ-εκπαιδευμένη σε απλό κείμενο, για να ρυθμίσει και να ταξινομήσει τα tweets σε σχέση με την ετικέτα τους. Η χρήση γλωσσικών μοντέλων προεκπαίδευσης σε απλά κείμενα και όχι σε tweets παρακινούνταν από την ανάγκη να αντιμετωπιστούν δύο κρίσιμα ζητήματα που αποδεικνύονται από την επιστημονική βιβλιογραφία, δηλαδή (1) τα προ-εκπαιδευμένα γλωσσικά μοντέλα είναι ευρέως διαθέσιμα σε πολλές γλώσσες, αποφεύγοντας την χρονοβόρα και δαπανηρή εκπαίδευση μοντέλων απευθείας σε tweets από την αρχή, επιτρέποντας να επικεντρωθεί μόνο στη βελτιστοποίηση τους· (2) τα διαθέσιμα σώματα απλού κειμένου είναι μεγαλύτερα από αυτά μόνο για tweet, επιτρέποντας την καλύτερη απόδοση.', 'it': "L'obiettivo di questo lavoro è stato l'introduzione di un approccio efficace basato sul modello linguistico AraBERT per combattere i Tweet COVID-19 Infodemic. È stato organizzato sotto forma di pipeline in due fasi, dove il primo passo prevedeva una serie di procedure di pre-elaborazione per trasformare il gergo di Twitter, tra cui emoji ed emoticon, in testo semplice, e il secondo passo ha sfruttato una versione di AraBERT, pre-addestrata sul testo semplice, per perfezionare e classificare i tweet rispetto alla loro Label. L'uso di modelli linguistici pre-formati su testi semplici piuttosto che su tweet è stato motivato dalla necessità di affrontare due questioni critiche evidenziate dalla letteratura scientifica, vale a dire (1) modelli linguistici pre-formati sono ampiamente disponibili in molte lingue, evitando la formazione dei modelli che richiede tempo e risorse direttamente su tweet da zero, consentendo di concentrarsi solo sulla loro messa a punto; (2) i corpi di testo semplice disponibili sono più grandi di quelli solo tweet, consentendo migliori prestazioni.", 'kk': 'Бұл жұмысының мақсаты - AraBERT тіл үлгісіне негізделген эффективті тәртібін келтіру - COVID-19 Infodemic Tweets моделіне негізделген. Бұл екі қадам қабырғының түрінде орнатылды. Бірінші қадам Твиттердің жаргоны, көңіл күй белгілері мен көңіл белгілерін түрлендіру үшін Твиттердің алдын- ала өзгерту процедурлерінің бірінші қадамысы, кәдімгі мәтініне түрлендіру үшін, екінші қадамысы Ара Твиттерді алдын- ала кәдімгі мәтіндер үлгілерін қолдану үшін ғылым литературасынан көрсетілген екі нақты мәселелерді шешу үшін көп тіл үлгілері көп тілде қол жеткізілген, көп тілде уақыт пайдалану және ресурстардың көмектесу үлгілерін тәртіпті tweets- тізімін (2) Қолданатын кәдімгі мәтін корпорасы тек tweet- ғана үлкен, жақсы жұмыс істеуге мүмкіндік береді.', 'lt': 'Šio darbo tikslas buvo sukurti veiksmingą metodą, pagrįstą AraBERT kalbos modeliu kovojant su Tweets COVID-19 Infodemic. Jis buvo surengtas dviejų etapų vamzdyno pavidalu, kuriame pirmasis etapas buvo susijęs su keliomis išankstinio apdorojimo procedūromis, kuriomis Twitter žargonas, įskaitant emodžius ir emotikonus, paverčiamas paprastu tekstu, o antrasis etapas išnaudojo AraBERT versiją, kuri buvo išankstinio apdorojimo paprastu tekstu, siekiant tiksliai pritaikyti ir klasifikuoti tweetus atsižvelgiant į jų ženklą. Naudojant kalbų modelius, iš anksto apmokytus paprastuose tekstuose, o ne tweetuose, buvo motyvuota būtinybe spręsti du mokslinių literatūrų parodytus svarbius klausimus, būtent (1) iš anksto apmokyti kalbų modeliai yra plačiai prieinami daugeliu kalbų, išvengiant laiko ir ištekliams imlaus modelio mokymo tiesiogiai tweetuose iš pradžių, leidžiant sutelkti dėmesį tik į jų patobulinimą; (2) prieinamos paprastos teksto korporai yra didesni nei tik tweeto korporai, leidžiantys užtikrinti geresnius rezultatus.', 'mk': 'Целта на оваа работа беше воведувањето на ефикасен пристап базиран на јазичкиот модел на Араберт за борба против Твит Ковид-19 Инфодемиќ. Таа беше организирана во форма на двочекорен гасовод, каде што првиот чекор вклучуваше серија процедури на преобработување за трансформирање на џаргонот на Твитер, вклучително и емоџии и емотикони, во обичен текст, а вториот чекор ја искористи верзијата на АраБЕРТ, која беше преобучена на обичен текст, за да ги пофинира и класификува твитовите во одн Користењето на јазичките модели предобучени на обични тексти наместо на твитови беше мотивирано од неопходноста да се решат две критични прашања покажани од научната литература, имено (1) предобучени јазички модели се широко достапни на многу јазици, избегнувајќи го времето потрошувачкиот и ресурсно интензивниот модел обука директно на твитови од нула, овозмож (2) достапните едноставни текстови корпора се поголеми од оние кои се само за твит, овозможувајќи подобра перформанса.', 'ml': 'ഈ പ്രവര്\u200dത്തിക്കുന്നതിന്റെ ലക്ഷ്യം അറബെര്\u200dട്ടി ഭാഷ മോഡലിനെ അടിസ്ഥാനപ്പെടുത്തിക്കൊണ്ടുള്ള ഒരു പ്രവർത്തികമായ പ്രാ ഒരു രണ്ടു പടി പൈപ്പെലിന്\u200dറെ രീതിയില്\u200d നിര്\u200dണയിക്കപ്പെട്ടിരുന്നു. അവിടെ ഒന്നാമത്തെ പട്ടിയില്\u200d ടൂട്ടറില്\u200d പ്രവര്\u200dത്തിക്കുന്ന ഒരു സിരിക്കല്\u200d പ്രക്രിയകള്\u200d ചേര്\u200dന്നു. ഇമോജിക്കും ഇമോട്ടിക്കോണുകളും സാധാരണ വാചകം  The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning;  (2) ലഭ്യമായ ടെക്സ്റ്റ് കോര്\u200dപ്പോരാ ടൂട്ടില്\u200d മാത്രമേ വലുതാണ്, നല്ല പ്രദര്\u200dശനത്തിന് അനുവദിക്കുന്നത്.', 'no': 'Målet på denne arbeiden var innføring av ein effektiv tilnærming basert på AraBERT språk-modellen for å kjempe med tweets COVID-19 informasjon. Det vart ordna i form av ei to steg-røyr, der den første stegen inkluderte ei serie førehandsamingsprosedyrar for å transformera Twitter-jargon, inkludert emojis og emotikon, til vanleg tekst, og den andre stegen eksploderte ein versjon av AraBERT, som var førehandsamt på vanleg tekst, for å finne opp og klassifisera tweetene med respekt til etiketten sin. Bruk språk-modeller som er forelært på enkle tekstar i staden for tweeter var motivert av nødvendigheten for å handtera to kritiske problemar viste av vitenskapelige literatur, som er 1) forelærte språk-modeller vast tilgjengelege i mange språk, for å unngå opplæring av tidsbruk og ressursintensiv modeller direkte på tweeter frå rulla, som kan berre fokusera på dei finnstillingane sine. (2) tilgjengelege vanleg tekstkorpora er større enn berre tweet-korporane, som tillater bedre utvikling.', 'mn': 'Энэ ажлын зорилго нь АраBERT хэл загварын үндсэн үр дүнтэй арга загварын танилцуулалт юм. Твитт COVID-19 мэдээллийн загвартай тэмцэх зорилго юм. Энэ нь хоёр давхар хоолойн шугам хэлбэрээр зохион байгуулагдсан. Эхний алхам нь Твиттерийн жаргон болон сэтгэл хөдлөлүүдийг зөв текст руу шилжүүлэх хэлбэрээр туслагдсан. Хоёр дахь алхам нь АраBERT-ын хувилбарыг ашигласан. Энэ нь энгийн текст дээр сургалтын өмнө сургалтыг зохион байгуулсан, тэ Шинжлэх ухааны уран зохиолын хоёр чухал асуудлыг шийдэх шаардлагатай хэл загваруудыг олон хэл дээр ашиглаж, цаг хугацааны хэрэглэх болон нөөц загварын сургалтыг шууд шинжлэх ухааны зохиолын тухай бодох шаардлагатай байлаа. (2) Дэлхийн текст корпора нь зөвхөн tweet-ээс илүү том, илүү сайн үйл ажиллагаанд хүргэж чадна.', 'pl': 'Celem niniejszej pracy było wprowadzenie skutecznego podejścia opartego na modelu językowym AraBERT do walki z Tweetami COVID-19 Infodemic. Został on ułożony w formie dwuetapowego pipeline, w którym pierwszy krok obejmował serię procedur wstępnego przetwarzania żargonu Twittera, w tym emotiki i emotikony, w zwykły tekst, a drugi krok wykorzystał wersję AraBERT, która została wstępnie przeszkolona na zwykłym tekście, do dostrojenia i klasyfikacji tweetów w odniesieniu do ich etykiety. Zastosowanie modeli językowych przeszkolonych na zwykłych tekstach a nie na tweetach było motywowane koniecznością rozwiązania dwóch kluczowych kwestii wykazanych w literaturze naukowej, mianowicie (1) wstępnie przeszkolone modele językowe są powszechnie dostępne w wielu językach, unikając czasochłonnych i zasobochłonnych szkoleń modelowych bezpośrednio na tweetach od podstaw, co pozwala skupić się wyłącznie na ich dostosowaniu; (2) dostępne korpusy zwykłego tekstu są większe niż te tylko tweety, co pozwala na lepszą wydajność.', 'ro': 'Obiectivul acestei lucrări a fost introducerea unei abordări eficiente bazate pe modelul lingvistic AraBERT pentru combaterea Tweetelor COVID-19 Infodemic. Acesta a fost aranjat sub forma unei conducte în două etape, în care primul pas a implicat o serie de proceduri de pre-procesare pentru a transforma jargonul Twitter, inclusiv emoji-uri și emoticoane, în text simplu, iar al doilea pas a exploatat o versiune a AraBERT, care a fost pre-instruită pe text simplu, pentru a regla fin și clasifica tweeturile în raport cu eticheta lor. Utilizarea modelelor lingvistice pre-instruite pe texte simple, mai degrabă decât pe tweet-uri a fost motivată de necesitatea de a aborda două aspecte critice prezentate de literatura științifică, și anume (1) modelele lingvistice pre-instruite sunt disponibile pe scară largă în multe limbi, evitând formarea modelelor consumatoare de timp și utilizatoare de resurse direct pe tweet-uri de la zero, permițând să se concentreze numai pe ajustarea lor fină; (2) Corpurile de text simplu disponibile sunt mai mari decât cele doar pentru tweet, permițând o performanță mai bună.', 'mt': 'L-għan ta’ dan ix-xogħol kien l-introduzzjoni ta’ approċċ effettiv ibbażat fuq il-mudell tal-lingwa AraBERT għall-ġlieda kontra t-Tweets COVID-19 Infodemic. It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label.  The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning;  (2) il-korpra b’test sempliċi disponibbli huma akbar minn dawk li jintużaw biss fuq it-twitter, li jippermettu prestazzjoni aħjar.', 'sr': 'Cilj ovog rada bio je uvođenje efikasnog pristupa na osnovu AraBERT jezičkog modela za borbu protiv Tweets COVID-19 Infodemije. Postavljeno je u obliku dva koraka cijevi, gdje je prvi korak uključio seriju procedura pre obrade za transformaciju tviterskog žargona, uključujući emoje i emotike, u obični tekst, a drugi korak je iskoristio verziju AraBERT-a, koja je bila predobučena na običnom tekstu, kako bi ispravljala i klasifikovala tweete u pogledu njihovog etiketa. Koristenje jezičkih modela predobučenih na običnim tekstima umjesto na tweets motiviralo je potrebnost da se riješi dva kritična pitanja koje je pokazala naučna literatura, a to je (1) predobučenih jezičkih modela široko dostupni na mnogim jezicima, izbjegavajući trening vremenskog potrošnja i intenzivnog modela direktno na tweets iz ogrebotine, omogućavajući da se fokusiraju samo na njihove finalne nastave; (2) dostupna prosta tekstska korpora su veća od samo tujtova, omogućavajući bolju izvedbu.', 'si': 'මේ වැඩේ අලක්ෂාව තමයි අරාබෙර්ට් භාෂාවයේ අධාරිත විදියට පරීක්ෂා කරනවා ට්විට් COVID-19 තොරතුරු පරීක්ෂණය ස ඒක දෙකක් පායිප්ලයින් වර්ගයේ සැකසුම් කරලා තියෙන්නේ, මුලින් පැත්තේ ප්\u200dරධාන පරික්ෂාව සම්බන්ධ කරලා තියෙන්නේ ටිව්ටර් ජාර්ගෝන් වර්ගය, emoji සහ emoticons වර්ගය, සාමාන්ය පාළුවක්  The use of language Model pre-Trained on plain texts Rather than on tweets is stimed by the needed to address 2 vital challenges show by the science Litteratura, namily (1) pre-Trained language Model are vast in a lot of language, escape the time-exploding and source-Intent Model Training right on tweets from scrath, allowing to focus just on them Fine-tuning; and (2) පුළුවන් පැහැදිලි පාළුවන් පාළුවන් කොර්පෝරා තවිට් විතරයි වඩා වැඩියි, හොඳ ප්\u200dරමාණය', 'ms': 'The objective of this work was the introduction of an effective approach based on the AraBERT language model for fighting Tweets COVID-19 Infodemic.  It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label.  Penggunaan model bahasa yang dilatih-dilatih pada teks biasa daripada pada tweet adalah disebabkan keperluan untuk mengatasi dua isu kritik yang dipaparkan oleh literatur saintifik, iaitu (1) model bahasa yang dilatih-dilatih tersedia secara luas dalam banyak bahasa, menghindari pelatihan model yang memakan masa dan memaksa sumber secara langsung pada tweet dari awal, membolehkan fokus hanya pada penyesuaian mereka; (2) corpora teks biasa yang tersedia lebih besar daripada yang hanya tweet, membolehkan prestasi yang lebih baik.', 'so': "Ujeedada shaqadaas waa soo saarista qaab faa’iido leh oo ku saleysan qaabka afka AraBERT ee looga diriro Tweets COVID-19 Infodemic. Waxaa loo soo bandhigay qoraal labaad oo baabuur ah, halkaas oo jaranjarada ugu horraysay ay ku wareejiyaan jardiinada Twitterka, including emojiska iyo emoticons, si ay u beddelaan qoraal cad, halka labaadna waxaa loo isticmaalay warqada AraBERT, taasoo horay loogu baray qoraalka saxda ah, si uu u qoro qoraalka si fiican loona qoro tweetka ee la xiriira Labelkooda. Isku isticmaalka modelalka afka ee hore oo lagu tababaray qoraalka fudud ee aan ku isticmaalin tweetka waxaa lagu motimotiyey in la hadlo laba su'aalood oo muhiim ah oo la muujiyo qoraalka cilmiga leh, tusaale ahaan (1) qaababka afka hore oo lagu baray waxaa si badan looga helaa luuqado kala duduwan, iyadoo ka fogaada koorsooyinka wakhtiga la isticmaalayo iyo waxbarashada dabiicadda nolosha ee rasmiga ah oo toos u ah Twitteetka, kaas oo ku raadsan karta oo kaliya si loo fiiriyo si aad u (2) Shirkadda qoraalka ee fudud ee ay heli karaan waa ka weyn yihiin noocyo oo kaliya, waxayna heli karaan sameynta wanaagsan.", 'sv': 'Målet med detta arbete var att införa ett effektivt tillvägagångssätt baserat på AraBERT språkmodell för att bekämpa Tweets COVID-19 Infodemic. Det arrangerades i form av en pipeline i två steg, där det första steget omfattade en rad förbehandlingsprocedurer för att omvandla Twitter jargong, inklusive emojis och uttryckssymboler, till vanlig text, och det andra steget utnyttjade en version av AraBERT, som var förberett på vanlig text, för att finjustera och klassificera tweets med avseende på deras etikett. Användningen av språkmodeller som tränats i förväg på enkla texter snarare än på tweets motiverades av behovet av att ta itu med två kritiska frågor som visas i den vetenskapliga litteraturen, nämligen (1) förkunskaperade språkmodeller är allmänt tillgängliga på många språk, vilket undviker den tidskrävande och resurskrävande modellutbildningen direkt på tweets från grunden, vilket gör det möjligt att endast fokusera på finjusteringen. (2) tillgängliga textkorpor är större än tweet-bara, vilket möjliggör bättre prestanda.', 'ur': 'اس کام کا مقصد یہ تھا کہ آراBERT زبان کی مدل پر مبارزه کرنے کے لئے ٹویٹ COVID-19 Infodemic کے لئے ایک عمدہ طریقہ کا پہنچانا ہے. یہ ایک دو سپے پائپ لین کی شکل میں ٹھہرایا گیا تھا جہاں پہلی سپے نے ٹویٹر کے جارگن کو تبدیل کرنے کے لئے ایک سری پیش پردازی کی پردازشیوں میں شامل کیا تھا، جیسے emojis اور emoticons، صریح متن میں، اور دوسری سپے نے آرابرٹ کی ایک نسخہ مفسد کی، جو صریح متن پر پہلے آموزش کی گئی تھی، تائیٹوں کو ان کے لابل کے بارے میں د زبان کی مدلکوں کی استعمال صریح پیغام پر پیش آموزش کی جاتی ہے بغیر ٹیوٹوں پر جہاد کی جاتی ہے کہ ان دونوں ضروری مسائل کے بارے میں جہاد کرنے کی ضرورت تھی، یعنی (1) پیش آموزش کی زبان کی مدلکوں کی بہت سی زبانوں میں موجود ہیں، جو ٹیوٹوں کے بارے میں سیدھے ٹیوٹوں کے ذریعہ وقت مصرف کرنا اور منزل مضبوط موڈل کی تر (2) موجود پاک ٹیکسٹ کوپرا صرف ٹیوٹ سے بڑے ہیں، جو بہتر عمل کے لئے اجازت دیتے ہیں.', 'ta': 'இந்த வேலையின் குறிப்பு என்னவென்றால் ஆர்பெர்ட் மொழி மாதிரியை அடிப்படையில் செயல்படுத்தும் செயல்படுத்தல் செயல்படுத்தல் த இது ஒரு இரண்டு படி குப்பையை வடிவத்தில் அமைக்கப்பட்டது, அங்கு முதல் படி Twitter ஜார்க்னை மாற்ற வேண்டிய முன் செயல்படுத்தப்பட்டுள்ளது, அதில் உணர்வு மற்றும் உணர்வுகள் உள்ளன, வெறும் உரையாக மாற்றும், இரண்டாவது படி சாதாரண உரையின் பதிப அறிவியல் எழுத்தால் காட்டப்படும் இரண்டு முக்கியமான பிரச்சனைகளை நிர்ணயிக்க வேண்டிய மொழி மாதிரிகளின் பயன்பாடு முன்பயிற்சிக்கப்பட்ட மாதிரிகள் பல மொழிகளில் கிடைக்கும், நேரத்தை பயன்படுத்துதல் மற்றும் மூலத்தின் ம (2) கிடைக்கும் வெறும் உரை நிறுவனத்தில் இருந்து மட்டுமே இருக்கும், சிறந்த செயல்பாட்டை அனுமதிக்கும்.', 'uz': "The objective of this work was the introduction of an effective approach based on the AraBERT language model for fighting Tweets COVID-19 Infodemic.  Birinchi qadam Twitter jargonini o'zgartirish uchun bir necha birinchi qadam qo'llangan bir necha darajaga kiritilgan edi. Bu birinchi qadam Twitter jargonini, emojis va emotixonaslarni oddiy matnlariga aylantirish uchun oddiy matnning birinchi darajada araBERT versiyasi ishlatilgan, bu oddiy matnning birinchi marta o'rganilgan xabarlarni yaxshi o'rganish uchun xabarlarni qo'llangan va yorliq bilan birlashtirish uchun. Ilmiy literatorining 2 muhim muammolarini boshqarish muhim muammolari uchun bir necha tillar modellaridan foydalanishdan oldin o'rganadigan foydalanuvchidan foydalanish imkoniyat edi. Bu fan ilmiy littatidagi ikki muhim muammolarni (1) o'rganilgan tillar modellari juda ko'p tillardan juda qulay mavjud, vaqt foydalanish va resource-intensive modeldan foydalanish imkoniyatlaridan foydalanadi. (2) Mavjud boʻlgan oddiy matn korporiyasi faqat tweetidan katta, bajarish uchun yaxshi ishga ruxsat beradi.", 'vi': 'Mục tiêu của việc này là áp dụng một phương pháp hiệu quả dựa trên mô hình ngôn ngữ AraBERT để chiến đấu trong phim Tweet COVID-19 Infodemic. Nó được sắp xếp bằng một đường ống hai bước, nơi bước đầu tiên liên quan tới một loạt các thủ tục xử lý tiền chế để chuyển đổi thuật ngữ trên Twitter, bao gồm biểu tượng và biểu tượng, thành những dòng chữ bình thường, và bước thứ hai khai thác một phiên bản của AraBERT được đào tạo sẵn trên bản thường, hiệu chỉnh và phân loại những dòng tweet theo dấu hiệu của chúng. Việc sử dụng các mô hình ngôn ngữ được đào tạo trước trên các bản thảo nguyên bản chứ không phải trên Twitter được thúc đẩy bởi sự cần thiết đối phó với hai vấn đề quan trọng được ghi nhận bởi các tài liệu khoa học, là(1) những mô hình ngôn ngữ được đào tạo trước rất rộng rãi trong nhiều ngôn ngữ, tránh việc lạm dụng thời gian và thu nhập trực tiếp trên Twitter, cho phép chỉ tập trung vào việc chỉnh sửa chữa; (2) Những chữ hạ có sẵn còn lớn hơn những chữ bình thường chỉ dùng mỗi tweet, cho phép hiệu suất tốt hơn.', 'da': 'Formålet med dette arbejde var at indføre en effektiv tilgang baseret på AraBERT sprogmodel til bekæmpelse af tweets COVID-19 Infodemic. Det blev arrangeret i form af en to-trins pipeline, hvor det første trin involverede en række forhåndsbehandlingsprocedurer for at omdanne Twitter jargon, herunder emojis og humørikoner, til almindelig tekst, og det andet trin udnyttede en version af AraBERT, som var forhåndsuddannet i almindelig tekst, til at finjustere og klassificere tweets i forhold til deres Label. Anvendelsen af sprogmodeller, der er forududdannet på almindelige tekster snarere end på tweets, var motiveret af nødvendigheden af at løse to kritiske spørgsmål, som den videnskabelige litteratur viser, nemlig (1) forududdannede sprogmodeller er bredt tilgængelige på mange sprog, hvilket undgår den tidskrævende og ressourcekrævende modeltræning direkte på tweets fra bunden, hvilket gør det muligt kun at fokusere på deres finjustering. (2) tilgængelige almindelig tekst corpora er større end tweet-only dem, hvilket giver bedre ydeevne.', 'bg': 'Целта на тази работа беше въвеждането на ефективен подход, базиран на езиковия модел за борба с Туитс Инфодемик. Тя беше организирана под формата на двустепенен тръбопровод, където първата стъпка включваше серия от процедури за предварително обработване на жаргона на Туитър, включително емотикони и емотикони, в обикновен текст, а втората стъпка използваше версия на AraBERT, която беше предварително обучена за обикновен текст, за фина настройка и класификация на туитовете по отношение на техния етикет. Използването на езикови модели, предварително обучени върху обикновени текстове, а не върху туитове, е мотивирано от необходимостта да се разгледат два критични въпроса, показани от научната литература, а именно: (1) предварително обучените езикови модели са широко достъпни на много езици, като се избягва отнемащото време и ресурсоемко обучение директно върху туитове от нулата, което позволява да се съсредоточи само върху тяхното фино настройване; (2) наличните корпуси с обикновен текст са по-големи от тези, които позволяват по-добра производителност.', 'nl': "Het doel van dit werk was de introductie van een effectieve aanpak gebaseerd op het AraBERT taalmodel voor het bestrijden van Tweets COVID-19 Infodemic. Het werd opgezet in de vorm van een tweestaps pipeline, waarbij de eerste stap bestond uit een reeks pre-processing procedures om Twitter jargon, inclusief emoticons en emoticons, om te zetten in platte tekst, en de tweede stap gebruikte een versie van AraBERT, die vooraf was getraind op platte tekst, om de tweets te finetunen en te classificeren met betrekking tot hun Label. Het gebruik van taalmodellen die vooraf zijn opgeleid op platte teksten in plaats van op tweets werd gemotiveerd door de noodzaak om twee kritische kwesties aan te pakken die uit de wetenschappelijke literatuur blijken, namelijk (1) voorgetrainde taalmodellen zijn op grote schaal beschikbaar in vele talen, waardoor tijdrovende en resourceintensieve modeltraining direct op tweets van nul wordt vermeden, waardoor alleen de nadruk kan worden gelegd op de verfijning ervan; (2) beschikbare platte tekst corpora's zijn groter dan alleen tweets, wat zorgt voor betere prestaties.", 'hr': 'Cilj ovog rada bio je uvođenje učinkovitog pristupa na temelju AraBERT jezičkog modela za borbu protiv Tweets COVID-19 informademije. Postavljeno je u obliku dva koraka cijevi, gdje je prvi korak uključio niz procedura predobrazovanja kako bi transformirao tviterski žargon, uključujući emoje i emotike, u obični tekst, a drugi korak je iskoristio verziju AraBERT-a, koja je bila predobučena na običnom tekstu, kako bi se ispravljala i klasifikirala tweet s obzirom na njihovu etiketu. Korištenje jezičkih modela predobučenih na običnim tekstima umjesto na tweets motiviralo je potrebnost rješavanja dva kritična pitanja koje je pokazala naučna literatura, a to je (1) predobučenih jezičkih modela široko dostupni na mnogim jezicima, izbjegavajući trening vremena potrošnje i intenzivnog modela s resursima direktno na tweets iz ogrebotine, omogućavajući se fokusirati samo na njihove ispravne prilike; (2) dostupna obična tekstna tijela su veća od samo tweet-a, omogućavajući bolju izvršnost.', 'de': 'Ziel dieser Arbeit war die Einführung eines effektiven Ansatzes basierend auf dem AraBERT Sprachmodell zur Bekämpfung von Tweets COVID-19 Infodemic. Es wurde in Form einer zweistufigen Pipeline angeordnet, in der der erste Schritt eine Reihe von Vorverarbeitungsverfahren umfasste, um Twitter-Jargon einschließlich Emojis und Emoticons in Klartext umzuwandeln, und im zweiten Schritt wurde eine Version von AraBERT, die auf Klartext vortrainiert wurde, genutzt, um die Tweets hinsichtlich ihres Labels zu verfeinern und zu klassifizieren. Die Verwendung von Sprachmodellen, die auf Klartexten statt auf Tweets vortrainiert wurden, wurde durch die Notwendigkeit motiviert, zwei kritische Fragen anzugehen, die aus der wissenschaftlichen Literatur hervorgehen, nämlich (1) vortrainierte Sprachmodelle sind in vielen Sprachen weit verbreitet, wodurch zeitaufwändige und ressourcenintensive Modellschulungen direkt auf Tweets von Grund auf vermieden werden konnten, so dass man sich nur auf deren Feinabstimmung konzentrieren konnte. (2) verfügbare Klartext-Korpora sind größer als reine Tweets, was eine bessere Leistung ermöglicht.', 'ko': '이 사업의 목표는 코로나 정보 전파에 대항하기 위해 아라벳 언어 모델을 기반으로 한 효과적인 방법을 도입하는 것이다.2단계 파이프라인 형식으로 배정된다. 첫 번째 단계는 일련의 예처리 프로그램과 관련된다. 트위터 용어(이모티콘과 이모티콘 포함)를 순수한 텍스트로 변환하고, 두 번째 단계는 아라비트의 한 버전을 이용한다. 이 버전은 순수한 텍스트 예훈련을 거쳐 추문 라벨에 따라 추문을 미세하게 조정하고 분류한다.추문이 아닌 순수한 텍스트에서 미리 훈련된 언어 모델을 사용하는 것은 과학 문헌에 나타난 두 가지 관건적인 문제를 해결하는 필요성에서 비롯된 것이다. 즉, (1) 미리 훈련된 언어 모델은 많은 언어에서 널리 사용되고 처음부터 추문에 직접적으로 시간을 소모하고 자원 집약적인 모델 훈련을 피하며 미조에만 집중할 수 있다.(2) 사용할 수 있는 순수한 텍스트 자료 라이브러리는 순수한 추문 자료 라이브러리보다 크고 더 좋은 성능을 허용한다.', 'sw': 'Lengo la kazi hii lilikuwa kuanzisha mbinu yenye ufanisi kulingana na modeli ya lugha ya AraBERT kwa kupigana na Twita COVID-19 Infodemic. Ilikuwa imeandaliwa kwa namna ya pipeline ya hatua mbili, ambapo hatua ya kwanza ilihusisha mfululizo wa mchakato wa kabla wa kuchukua hatua za Twita ili kubadilisha jarida la Twita, ikiwa ni pamoja na hisia za hisia na mawazo, na hatua ya pili ilitumia toleo la AraBERT, ambalo lilifundishwa kwa ujumbe mfupi wa simu za wazi, ili kubadilisha ujumbe mzuri na kutangaza twita kwa kuheshimu Label zao. The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning;  (2) Kampuni ya simu za mkononi zinazopatikana ni kubwa kuliko zile tu za twita, zinazoruhusu kufanya kazi bora zaidi.', 'fa': 'هدف این کار معرفی یک دستور موثری بود که بر اساس مدل زبان AraBERT برای مبارزه با توئیت COVID-19 Infodemic بود. آن در شکل یک لوله دو قدم ترتیب داده شد، جایی که اولین قدم یک سری پردازش پیش\u200cپردازش برای تغییر جارگان توئیتر، شامل احساسات و احساسات، به متن معمولی، و دومین قدم یک نسخه آراBERT را استفاده کرد، که پیش از آموزش بر متن معمولی بود، برای تغییر و تغییر کردن توئیت\u200cها با احترام برچسب\u200cشان. استفاده از مدل\u200cهای زبان پیش آموزش داده شده بر متن\u200cهای معمولی به جای تویت\u200cها به نیازی برای حل دو مسئله مهم\u200cتری که توسط ادبیات علمی نشان داده شده بود، به عنوان (۱) مدل\u200cهای پیش آموزش زبان\u200cها در بسیاری زبان فراوان موجود می\u200cشوند، و از تمرین مدل\u200cهای زمان سوختن و منبع\u200cintensive مستقیماً روی تویت\u200cها از تویت\u200cها از (۲) شرکت متن معمولی که در دسترس دارند بیشتر از آن\u200cها است که تنها توئیت\u200cها می\u200cتوانند انجام بهتر باشند.', 'af': "Die doel van hierdie werk was die inligting van 'n effektief toegang gebaseer op die AraBERT taal model vir die oorlog van Tweets COVID-19 Inligting. Dit is in die vorm van 'n twee-stappe pyplyn geregtig, waar die eerste stap 'n reeks van voorafverwerking prosedure ingesluit het om Twitter-jargon te transformeer, insluitend emojies en emotikone, na eenvoudige teks, en die tweede stap het 'n weergawe van AraBERT uitgebruik, wat vooraf veroefen was op eenvoudige teks, om die tweete te fin-tun en klassifiseer met respek na hul etiket. Die gebruik van taal modele wat vooraf opgelei is op eenvoudige teks eerder as op tweets is motiveer deur die noodsaaklikheid om twee kritiese probleme te adres wat deur die wetenskaplike literatur vertoon word, naamlik (1) vooraf opgelei taal modele is vaste beskikbaar in baie tale, wat die tyd-gebruik en hulpbron-intensiewe model opgelegging direk op tweete van skrap, toelaat om slegs op hulle fin-tuning te fokus;  (2) beskikbaar eenvoudige teks korpora is groter as tweet-slegs een wat toelaat vir beter prestasie.", 'tr': "Bu i힊i흫 maksady AraBERT dili nusgasyna g철r채 챌ykmak 체챌in t채sirli bir 첵agda첵 giri힊idi. Bu iki ad캇m pipetin 힊eklinde d체zenlendi. Ilkinji ad캇m Twitter 탑argony 체첵tgetmek 체챌in bir s체ri 철흫체nden i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n i힊le첵채n 첵erde, emoji we emotikony d체z metin채 체첵tgedildi we ikinji ad캇m AraBERT'y흫 bir wersi첵asyny ulandy. Bu 첵erde d체z metin 체st체nde 철흫체nden okuw캇lan, etiket Tweetlerde 철흫-철흫체nde bilim edebi첵aty tarapyndan g철rkezilen iki kriti첵a mesele 챌철zmek 체챌in, di흫e (1) 철흫-철흫체nde bilim modalarynda k철p dilde hem me흫ze힊 bar, terjime eden wagt we 챌oklu nusga d체z체mlenmesinden 챌ykarmakdan 챌ykar, di흫e gowy d체z체mlenmelerine 체ns bermek 체챌in rugsat beril첵채r; (2) Me흫ze힊 첵erli metin korporasy di흫e tweet-den uly, gowy etm채ge rugsat ber첵채r.", 'am': 'የዚህ ሥራ አቃውሞ የCOVID-19 የኢንተርሚክ ትዊተሮች ለመዋጋት በAraBERT ቋንቋ ሞዴል ላይ የተደረገው ጥሩ ልውጤት ማግኘት ነው፡፡ በሁለት ደረጃዎች ላይ በተለወጠው የፊተኛይቱ ደረጃዎች ትዊተር ጃርጎን፣ ኢሜጂ እና ኢሜስኮኖችን እና አካባቢዎችን ለመለወጥ የሁለት ደረጃ ፕሮግራም መልዕክት በተደረገ ነበር፤ ሁለተኛውም ደረጃዎች በሜዳ ጽሑፍ ላይ የተማረከውን የAraBERT ጽሑፍ ለመቀበል እና በተዊተኞቹን ለላባሎቻቸው ለመለዋወጥ ተጠቃሚ ነበር። የቋንቋ ምሳሌዎች በተጠቃሚ ጽሑፎች ላይ ከመጠቀም ይልቅ በትዊተር ላይ ሳይሆን የሳይንቀሳዊ littሕተት የሚያሳየውን ሁለት የክሕተት ጉዳዮች ለመቀበል ያስፈልጋል፤ ይህ (1) በፊት ተማሪ የቋንቋ ሞዴል በብዙ ቋንቋዎች ላይ በተለየ ቋንቋዎች ይኖራል፣ የዘመኑን ተጠቃሚ እና የዕቃ-ጠቅላዊ ሞዴል ትዊተር ላይ አስተማርቷል፡፡ (2) የተገኘ ጥሩ የጽሑፍ ኮርፖርት ትዊተር ብቻ ትልቅ ነው፡፡', 'sq': 'Objektivi i kësaj pune ishte futja e një qasje efektive bazuar në modelin e gjuhës AraBERT për luftën kundër Tweets COVID-19 Infodemic. Ajo u organizua në form ën e një tubacioni dy-hapash, ku hapi i parë përfshinte një seri procedurash paraprocesuese për të transformuar xhargonin e Twitter, duke përfshirë emoxhe dhe emotikona, në tekst të thjeshtë, dhe hapi i dytë shfrytëzoi një version të AraBERT, i cili ishte paratrajnuar në tekst të thjeshtë, për të përshtatur dhe klasifikuar tweetet lidhur me Etiketën e tyre. Përdorimi i modeleve gjuhësore të paratrajnuar në tekste të thjeshta sesa në tweete u motivua nga nevoja për të trajtuar dy çështje kritike të treguara nga letratura shkencore, veçanërisht (1) modelet gjuhësore të paratrajnuar janë gjerësisht në dispozicion në shumë gjuhë, duke shmangur trajnimin e modelit të konsumuar kohë dhe të intensivuar në burime drejtpërdrejt në tweete nga zero, duke lejuar që të përqëndrohen vetëm në rregullimin e tyre; (2) corpora teksti i thjeshtë në dispozicion janë më të mëdha se ato vetëm për tweet, duke lejuar për performancë më të mirë.', 'az': 'Bu işin məqsədi, AraBERT dili modeli COVID-19 Infodemic ilə döyüşən Tweets COVID-19 ilə dayanan effektiv bir metodların tanışması idi. İki adım boru çizgisinin formu ilə təyin edildi. İlk adım, Twitter jargonu, emoji və emotikonu, düzgün metinə çevirmək üçün ilk işləmə prosedürlərini birlikdə təyin etdi. İkinci adım, düzgün metinlə əvvəl təhsil edilmiş AraBERT versiyasını təyin etdi, etiketlərini düzgün təyin etmək və tövetlərini etiketlərinə yönəltmək üçün təyin etdi. Tövtlərdən əvvəl təhsil edilmiş dil modellərinin istifadəsi, bilimsi edebiyatı ilə göstərilən iki kritik məsələ çəkilmək üçün tədbir edilmişdir. Bu məsələn (1) əvvəl təhsil edilmiş dil modellərinin çoxlu dillərdə genişliyi faydalanır, zamanı istifadə etmək və çoxlu modellərin təhsil edilməsindən çəkinməsindən təhsil edilməsindən çəkinməsindən istifadə edilmişdir, yal (2) Mö ’ min düzgün mətn korporası yalnız twet-dən böyükdür, daha yaxşı performans üçün müvəffəq edər.', 'id': 'Tujuan pekerjaan ini adalah memperkenalkan pendekatan yang efektif berdasarkan model bahasa AraBERT untuk melawan Tweets COVID-19 Infodemic. Ini diatur dalam bentuk pipa dua langkah, di mana langkah pertama melibatkan serangkaian prosedur pra-proses untuk mengubah jargon Twitter, termasuk emoji dan emotikon, menjadi teks biasa, dan langkah kedua mengeksploitasi versi AraBERT, yang telah dilatih pada teks biasa, untuk memperbaiki dan mengklasifikasi tweet dengan berhubungan dengan Label mereka. Penggunaan model bahasa yang dilatih-dilatih-dilatih pada teks-teks sederhana daripada pada tweet adalah motivasi oleh kebutuhan untuk mengatasi dua masalah kritis yang diperlihatkan oleh literatur ilmiah, yaitu (1) model bahasa yang dilatih-dilatih tersedia secara luas dalam banyak bahasa, menghindari pelatihan model yang memakan waktu dan memanfaatkan sumber daya langsung pada tweet dari nol, memungkinkan fokus hanya pada penyesuaian mereka; (2) corpora teks biasa yang tersedia lebih besar dari yang hanya tweet, memungkinkan prestasi yang lebih baik.', 'hy': 'The objective of this work was the introduction of an effective approach based on the AraBERT language model for fighting Tweets COVID-19 Infodemic.  Այն կազմակերպված էր երկու քայլի խողովակաշարի տեսքով, որտեղ առաջին քայլը ներառում էր մի շարք նախավերաշարժման գործընթացներ, որոնք օգտագործում էին Թվիթերի ժարգոնը, ներառյալ էմոզիաները և էմոցիկոնները, պարզ տեքստի վերածելու համար, և երկրորդ քայլը օգտագործում էր Արաբերտի տարբերակը, որը նախապատրաստված էր պարզ տեքստի վրա,  Լեզու մոդելների օգտագործումը, որոնք նախապատրաստված են պարզ տեքստերի վրա, ոչ թե թվիթերի վրա, դրդապատճառված էր գիտական գրականության երկու կարևոր խնդիրների լուծման կարիքով, այն է (1) նախապատրաստված լեզու մոդելները շատ լեզուներում լայնորեն հասանելի են, խուսափելով ժամանակ պահանջող և ռեսուրսներով ինտենսիվ մոդելների ուսումնասիրությունից անմիջապ (2) հասանելի պարզ տեքստի կառուցվածքները ավելի մեծ են, քան միայն թվիթերի կառուցվածքները, ինչը թույլ է տալիս ավելի լավ արդյունք ունենալ:', 'bn': 'এই কাজের উদ্দেশ্য ছিল আরবের্ট ভাষার মডেলের ভিত্তিতে কার্যকর একটি কার্যকর পদ্ধতি তুলে ধরা যায়। টুইটার কোভিড-১৯ তথ্যেমিকে  এটি একটি দুই ধাপ পাইপেলাইনের রূপে আয়োজন করা হয়েছিল, যেখানে প্রথম ধাপ টুইটার প্রক্রিয়ার বিভিন্ন প্রক্রিয়ার একটি সিরিজ প্রক্রিয়ায় ছিল, যার মধ্যে ইমোজি এবং emoticon সাধারণ টেক্সটে পরিবর্তন করা হয়েছিল এবং দ্বিতীয় ধাপ সা বৈজ্ঞানিক সাহিত্যের দ্বারা দুটি গুরুত্বপূর্ণ বিষয় নিয়ে টুইটের পরিবর্তে ভাষার মডেল ব্যবহারের পূর্ব প্রশিক্ষণ প্রশিক্ষিত হয়েছিল, যেমন (১) পূর্ব প্রশিক্ষিত ভাষার মডেল অনেক ভাষায় ব্যাপকভাবে পাওয়া যায়, যার (২) সাধারণ টেক্সট কর্পোরা টুইট-শুধুমাত্র টুইটের চেয়ে বড়, যারা ভালো কাজের জন্য অনুমতি দেয়।', 'ca': "L'objectiu d'aquesta feina va ser la introducció d'un enfocament efectiu basat en el model de llenguatge AraBERT per combatre Tweets COVID-19 Infodemic. It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label.  L'ús de models de llenguatge pré-entrenats en textos senzills en comptes de tweets va ser motivat per la necessitat de tractar dos temes crítics demostrats per la literatura científica, a saber (1) els models de llenguatge pré-entrenats estan disponibles en moltes llenguatges, evitant l'entrenament del model que consumeix temps i consumeix recursos directament en tweets des de zero, permetent centrar-se només en el seu ajustament; (2) els corpores de text senzill disponibles són més grans que els que només fan tweet, permetent millor rendiment.", 'et': 'Töö eesmärgiks oli kasutusele võtta AraBERT keelemudelil põhinev efektiivne lähenemisviis Tweets COVID-19 Infodemic võitlemiseks. See korraldati kaheastmelise torujuhtmena, kus esimene samm hõlmas mitmeid eeltöötlusprotseduure Twitteri žargooni (sh emojid ja emotikonid) muutmiseks lihtsaks tekstiks ning teine samm kasutas AraBERTi versiooni, mis oli eelnevalt väljaõpetatud lihtsaks tekstiks, et täpsustada ja klassifitseerida säutseid vastavalt nende märgisele. Keelemudelite kasutamist, mis on eelnevalt koolitatud lihtsatele tekstidele mitte säutsudele, motiveeris vajadus käsitleda kaht teaduskirjandusest ilmnenud kriitilist küsimust, nimelt 1) eelnevalt koolitatud keelemudelid on paljudes keeltes laialdaselt kättesaadavad, vältides aeganõudvat ja ressursimahukat mudelikoolitust otse säutsudele nullist, võimaldades keskenduda ainult nende täpsustamisele; (2) saadaval tavalise teksti korpused on suuremad kui ainult tweet-i korpused, võimaldades paremat jõudlust.', 'fi': 'Tämän työn tavoitteena oli ottaa käyttöön AraBERT-kielimalliin perustuva tehokas lähestymistapa Tweets COVID-19 Infodemicin torjuntaan. Se järjestettiin kaksivaiheisen putken muodossa, jossa ensimmäinen vaihe sisälsi joukon esikäsittelymenettelyjä Twitter-jargonin, mukaan lukien hymiöt ja hymiöt, muuntamiseksi yksinkertaiseksi tekstiksi, ja toisessa vaiheessa hyödynnettiin AraBERT-versiota, joka oli ennalta koulutettu yksinkertaiseen tekstiin, tweettien hienosäätämiseksi ja luokittelemiseksi niiden Label-merkinnän suhteen. Kielimallien käyttöä, joka on ennalta koulutettu tavallisiin teksteihin eikä twiitteihin, motivoi tarve käsitellä kahta tieteellisen kirjallisuuden osoittamaa kriittistä kysymystä: 1) esikoulutettuja kielimalleja on laajalti saatavilla monilla kielillä, jolloin vältetään aikaa vievä ja resursseja vaativa mallikoulutus suoraan twiitteihin tyhjästä käsin, jolloin voidaan keskittyä vain niiden hienosäätöön. (2) saatavilla olevat yksinkertaiset tekstikorpuset ovat suurempia kuin vain tweet, mikä mahdollistaa paremman suorituskyvyn.', 'bs': 'Cilj ovog rada bio je uvođenje efikasnog pristupa na temelju AraBERT jezičkog modela za borbu protiv Tweets COVID-19 Infodemije. Postavljena je u obliku dva koraka cijevi, gdje je prvi korak uključio seriju procedura predobrazovanja kako bi transformirao tviterski žargon, uključujući emoje i emotike, u obični tekst, a drugi korak je iskoristio verziju AraBERT-a, koja je bila predobučena na običnom tekstu, kako bi se ispravljala i klasifikovala tweete u pogledu njihovog etiketa. Korištenje jezičkih modela predobučenih na prostim tekstima umjesto na tweetovima motivirano je neophodnošću rješavanja dva kritična pitanja koje je pokazala naučna literatura, a to je (1) predobučenih jezičkih modela široko dostupni na mnogim jezicima, izbjegavajući trening vremenskog potrošnja i intenzivnog modela direktno na tweetovima iz ogrebotine, omogućavajući se fokusirati samo na njihove dobre prilike; (2) dostupna prosta tekstska tijela su veća od samo tweet-ova, omogućavajući bolju izvedbu.', 'cs': 'Cílem této práce bylo zavedení efektivního přístupu založeného na jazykovém modelu AraBERT pro boj s Tweety COVID-19 Infodemic. Byl uspořádán ve formě dvoustupňového potrubí, kde první krok zahrnoval řadu postupů předzpracování pro transformaci Twitterového žargonu, včetně emotikonů a emotikonů, do prostého textu, a druhý krok využil verzi AraBERT, která byla předškolena na prostý text, k jemnému ladění a klasifikaci tweetů s ohledem na jejich Label. Používání jazykových modelů předškolených na obyčejných textech spíše než na tweetech bylo motivováno nutností řešit dvě kritické otázky ukazující vědeckou literaturu, jmenovitě (1) předškolené jazykové modely jsou široce dostupné v mnoha jazycích, čímž se vyhnout časově náročnému a zdrojově náročnému modelovému školení přímo na tweety od začátku, což umožňuje zaměřit se pouze na jejich jemné ladění; (2) dostupné korpusy prostého textu jsou větší než korpusy pouze pro tweety, což umožňuje lepší výkon.', 'ha': "Ganiyan wannan aikin na kasance an introduce wani takwara mai amfani da shi a kan misalin harshen AraBERT wa yin yãƙi da COV-19. An organisera shi cikin tsarin wata pipilin biyu, inda ta farko ta haɗa wasu jargon na farko da za'a shige jergon na Twitter, ikin mutane da hisoyi da shiryoyi, zuwa littãfin rubutu, kuma ta ƙara na biyu, ta yi amfani da version na AraBERT, wanda aka yi wa kwance-wa'azi a kan littãfin plain, dõmin ya sami-tun da kuma ya rarraba Twitter game da alama. Yin amfani da misãlai na harshe na zaman aka yi wa amfani da shi a kan littafan rubutu masu haske ko da haske a kan Twitter aka yi amfani da shi, ana da muhimma wa su address masu muhimmi biyu wanda aka nuna na littafan littafan da sani, a yanzu (1) misalin misalin harshen da aka yi amfani da shi da yawa, yana nĩsantar wa mai amfani da lokacin da kuma ma'anar-ƙaranci, yana yarda su yi zura ido a kan fasalinsu kawai; (2) Shirin mutane na da amfani da matsayin rubutu sun fi girma daga jumun-jumui kawai, kuma yana yarda da mafiya kyãwo.", 'he': "המטרה של העבודה הזו היתה ההצגה של גישה יעילה מבוססת על מודל שפת AraBERT להילחם טוויטים COVID-19 Infodemic. הוא הוארגן בצורה של צינור שתי צעדים, שבו הצעד הראשון כולל סדרה של תהליכים לפני העבודה כדי להפוך ג'ארגון טוויטר, כולל emojis ואמוטיקונים, לטקסט פשוט, והצעד השני ניצל גרסה של AraBERT, שהייתה מאומנת מראש על טקסט פשוט, כדי להתאים ולקליфіק את הטוויטרים בנוגע לתוויט שלהם. השימוש של דוגמני שפה מאומנים מראש על טקסטים פשוטים במקום על טוויטים היה מוטיבציה על ידי הצורך להתמודד עם שני בעיות קריטיות שהופעו על ידי הספרות המדעית, כלומר (1) דוגמני שפה מאומנים מראש זמינים באופן רחב בשפות רבות, הממנע את האימון של דוגמני שימוש זמן וממשאבים אינטנסיביים ישירות על טוויטים מראש, מאפשר (2) גופורה טקסט פשוט זמינה גדולה יותר מאחד שטוויט בלבד, מאפשר להופעה טובה יותר.", 'sk': 'Cilj tega dela je bil uvedba učinkovitega pristopa, ki temelji na jezikovnem modelu AraBERT za boj proti Tweets COVID-19 Infodemic. Urejen je bil v obliki dvostopenjskega plinovoda, kjer je prvi korak vključeval vrsto postopkov predhodne obdelave za pretvorbo Twitterjevega žargona, vključno z emojiji in emotikoni, v navadno besedilo, drugi korak pa je izkoristil različico AraBERT, ki je bila vnaprej usposobljena za navadno besedilo, za natančno nastavitev in razvrstitev tweetov glede na njihovo oznako. Uporabo jezikovnih modelov, ki so bili predhodno usposobljeni za navadna besedila in ne za tweete, je spodbudila potreba po obravnavi dveh kritičnih vprašanj, ki jih pokaže znanstvena literatura, in sicer (1) predhodno usposobljeni jezikovni modeli so široko dostopni v številnih jezikih, pri čemer se je izognilo dolgotrajnemu in z viri intenzivnemu usposabljanju modelov neposredno na tweete iz nič, kar omogoča osredotočanje le na njihovo fino nastavitev; (2) razpoložljivi korpusi navadnega besedila so večji od korpusov samo tweet, kar omogoča boljšo učinkovitost.', 'bo': 'ལས་ཀ་འདིའི་དམིགས་ཡུལ་ནི་AraBERT སྐད་ཡིག་ཆ་གི་མ་དཔེ་གཏོང་རྩོད་བྱེད་ཀྱི་འགྲོ་སྤྲོད་ཀྱི་ཐབས་ལམ་ཞིག་ཡིན། It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label. The first step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label. The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning; and (2) འདུག', 'jv': 'Tarjamahan kanggo nggunakake iki dadi nunggira dadi nggawe layar kang basa ning modèl araBERT kanggo nggunakake tarjamahan iki-19 Info Awak dhéwé éntuk ning kelas telas nang sampek durung, nêmên sing perusahaan karo sistem sing gawe ngupakan mrogram sing arep banter to transform mrogram, gambar e mungkin karo emusi lan emusi, lan akeh sing wis segondi bisa tteks nggawe versi araBERT, sing wis arep banter sampek, nggawe layakno lan kelas nggawe etiket karo Label. Ngawe ngubah model sing sampeyan luwih akeh bantuan, gambar kuwi nggambar kelangan seneng pisan, ditambah kuwi kesempatan kanggo ngerasakno dhéwé kesempatan dhéwé. ngerasakno (1) model sing arep bantuan karo akeh langkung sampeyan, bisa ndherekei nggawe sistem kut kesempatan lan modèl-ingkang dianggap, iso disenyongi nggawe tuwit suku akeh nggambar obah-obahan; iso dianggawe (2) Perusahaan kelas telas telas nang sampeyan luwih dumateng tuwit-kotak juara, iso nggawe akeh sing luwih apik.'}
{'en': 'NARNIA at NLP4IF-2021 : Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'ar': 'NARNIA في NLP4IF-2021: تحديد المعلومات المضللة في تغريدات COVID-19 باستخدام BERTweet', 'es': 'NARNIA en NLP4IF-2021: Identificación de desinformación en tuits de COVID-19 mediante BERTweet', 'fr': "NARNIA au NLP4IF-2021\xa0: identification de la désinformation dans les tweets COVID-19 à l'aide de BerTweet", 'pt': 'NARNIA no NLP4IF-2021: Identificação de desinformação em tweets COVID-19 usando BERTweet', 'hi': 'NLP4IF-2021 में NARNIA: BERTweet का उपयोग करके कोविड-19 ट्वीट्स में गलत जानकारी की पहचान', 'ja': 'NARNIA at NLP 4 IF -2021 ： BERTweetを使用したCOVID -19ツイートにおける誤った情報の特定', 'zh': 'NARNIA‰∫éNLP4IF-2021:Áî®BERTweetËØÜCOVID-19Êé®Êñá‰πãÈîôËØØ‰ø°ÊÅØ', 'ru': 'НАРНИЯ на NLP4IF-2021: выявление ложной информации в твитах о COVID-19 с использованием BERTweet', 'ga': 'NARNIA ag NLP4IF-2021: Mífhaisnéis a Aithint in Tweetanna COVID-19 ag Úsáid BERTweet', 'ka': 'NARNIA NLP4IF', 'el': 'NARNIA στο NLP4IF-2021: Προσδιορισμός παραπληροφόρησης σε tweets χρησιμοποιώντας το BERTweet', 'hu': 'NARNIA az NLP4IF-2021-en: A félreértések azonosítása a COVID-19 tweetekben a BERTweet segítségével', 'it': 'NARNIA a NLP4IF-2021: Identificazione della disinformazione nei tweet COVID-19 utilizzando BERTweet', 'kk': 'NARNIA at NLP4IF- 2021: COVID- 19 Tweets Use BERTweet', 'mk': 'NARNIA на NLP4IF-2021: Идентификација на грешни информации на Твитовите COVID-19 користејќи BERTweet', 'lt': 'NARNIA NLP4IF-2021: klaidingos informacijos nustatymas COVID-19 Tweets naudojant BERTweet', 'ms': 'NARNIA di NLP4IF-2021: Pengenalan maklumat salah dalam Tweets COVID-19 Menggunakan BERTweet', 'ml': 'NLP4IF-2021-ലെ നാര്\u200dനിയ: ബെര്\u200dട്ട്വീറ്റ് ഉപയോഗിച്ച് കോവിഡ്-19 ടൂട്ടുകളില്\u200d തെറ്റായ വിവരങ്ങളുടെ തിരിച്ചറിയാന്\u200d', 'mt': 'NARNIA f’NLP4IF-2021: Identifikazzjoni ta’ Informazzjoni Mhux korretta f’Tweets COVID-19 li jużaw BERTweet', 'mn': 'NARNIA at NLP4IF-2021: COVID-19 Tweets Use BERTweet', 'no': 'NARNIA på NLP4IF-2021: Identifikasjon av feilinformasjon i COVID-19 Tweets Bruk BERTweet', 'pl': 'NARNIA na NLP4IF-2021: Identyfikacja błędnych informacji w tweetach COVID-19 za pomocą BERTweet', 'ro': 'NARNIA la NLP4IF-2021: Identificarea dezinformării în tweeturile COVID-19 folosind BERTweet', 'sr': 'NARNIA na NLP4IF-2021: Identifikacija pogrešnih informacija u COVID-19 Tweets Koristeći BERTweet', 'si': 'NARNIA at NLP4IF-2021: COVID-19 Tweets Use BERTwitt', 'so': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets using BERTweet', 'sv': 'NARNIA på NLP4IF-2021: Identifiering av felaktig information i COVID-19 tweets med hjälp av BERTweet', 'ta': 'NLP4IF- 2021-ல் NARNIA: COVID- 19 Tweets using BERTweet', 'ur': 'NLP4IF-2021 میں NARNIA: COVID-19 ٹویٹ میں غلط معلومات کی شناسایی', 'uz': 'Comment', 'vi': 'Đuổi theo thông tin sai trong COVID-19 Twelves Sử dụng BERTweet.', 'hr': 'NARNIA na NLP4IF-2021: Identifikacija pogrešnih informacija u COVID-19 Tweets Koristeći BERTweet', 'bg': 'НАРНИЯ на НЛП4ИФ-2021: Идентифициране на погрешна информация в туитове с помощта на БРТуит', 'da': 'NARNIA på NLP4IF-2021: Identifikation af misinformation i COVID-19 tweets ved hjælp af BERTweet', 'de': 'NARNIA auf der NLP4IF-2021: Identifizierung von Fehlinformationen in COVID-19 Tweets mithilfe von BERTweet', 'nl': 'NARNIA op NLP4IF-2021: Identificatie van Misinformatie in COVID-19 Tweets met behulp van BERTweet', 'id': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'ko': 'NLP4IF-2021의 나니아: BERTweet을 사용하여 코로나 트윗의 오류 정보 식별', 'fa': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'sw': 'NARNIA kwenye mtandao wa NLP4IF-2021: Kutambua taarifa zisizo na taarifa katika Twita za COVID-19 kwa kutumia Twita ya BERTwita', 'sq': 'NARNIA në NLP4IF-2021: Identifikimi i informacionit të gabuar në COVID-19 Tweets duke përdorur BERTweet', 'tr': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'am': 'NARNIA በNLP4IF-2021: BERTweet በመጠቀም በCOVID-19 ትዊተር ውስጥ የስህተት ማወቃት', 'af': 'NARNIA by NLP4IF-2021: Identifikasie van Misinligting in COVID-19 Tweets gebruik BERTweet', 'hy': 'NARIA-ն ՆԼP4IF-2021 թվականին. COVID-19 թվիթերում սխալ տեղեկատվության հայտնաբերումը BERWit-ի օգտագործման միջոցով', 'az': "NLP4IF-2021'də NARNIA: COVID-19 Tweets'də Misinformation Identification of BERTweet Using", 'bn': 'NLP4IF-2021-এ নার্নিয়া: বার্টুইট ব্যবহার করে কভিড-১৯ টুইটে অজুহাতের পরিচয়', 'bs': 'NARNIA na NLP4IF-2021: Identifikacija pogrešnih informacija u COVID-19 Tweets Koristeći BERTweet', 'cs': 'NARNIA na NLP4IF-2021: Identifikace dezinformací v tweetech COVID-19 pomocí BERTweet', 'ca': "NARNIA a NLP4IF-2021: Identificació d'informació errònia en tweets COVID-19 Utilitzant BERTweet", 'et': 'NARNIA NLP4IF-2021: valeinformatsiooni tuvastamine COVID-19 tweetides BERTweet abil', 'fi': 'NARNIA NLP4IF-2021: Väärinkäytön tunnistaminen COVID-19-tweeteissä BERTweet', 'ha': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'jv': 'NAME OF TRANSLATORS', 'sk': 'NARNIA na NLP4IF-2021: identifikacija napačnih informacij v tweetih COVID-19 z uporabo BERTweet', 'bo': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet', 'he': 'NARNIA at NLP4IF-2021: Identification of Misinformation in COVID-19 Tweets Using BERTweet'}
{'en': 'The spread of COVID-19 has been accompanied with widespread misinformation on social media. In particular, Twitterverse has seen a huge increase in dissemination of distorted facts and figures. The present work aims at identifying tweets regarding COVID-19 which contains harmful and false information. We have experimented with a number of Deep Learning-based models, including different word embeddings, such as Glove, ELMo, among others. BERTweet model achieved the best overall F1-score of 0.881 and secured the third rank on the above task.', 'es': 'La propagación de la COVID-19 ha ido acompañada de una desinformación generalizada en las redes sociales. En particular, Twitterverse ha visto un enorme aumento en la difusión de datos y cifras distorsionados. El presente trabajo tiene como objetivo identificar los tuits relacionados con COVID-19 que contienen información dañina y falsa. Hemos experimentado con varios modelos basados en Deep Learning, que incluyen diferentes incrustaciones de palabras, como Glove, eLMO, entre otros. El modelo BerTweet logró la mejor puntuación general de F1 de 0.881 y aseguró el tercer puesto en la tarea anterior.', 'ar': 'رافق انتشار كوفيد -19 معلومات خاطئة واسعة النطاق على وسائل التواصل الاجتماعي. على وجه الخصوص ، شهد Twitterverse زيادة هائلة في نشر الحقائق والأرقام المشوهة. يهدف العمل الحالي إلى تحديد التغريدات المتعلقة بـ COVID-19 والتي تحتوي على معلومات ضارة وكاذبة. لقد جربنا عددًا من النماذج المستندة إلى التعلم العميق ، بما في ذلك تضمين الكلمات المختلفة ، مثل Glove و ELMo وغيرها. حقق نموذج BERTweet أفضل نتيجة إجمالية في F1 بلغت 0.881 وحصل على المرتبة الثالثة في المهمة المذكورة أعلاه.', 'fr': "La propagation de la COVID-19 s'est accompagnée d'une désinformation généralisée sur les réseaux sociaux. En particulier, Twitterverse a connu une énorme augmentation de la diffusion de faits et de chiffres déformés. Le présent travail vise à identifier les tweets concernant la COVID-19 qui contiennent des informations nuisibles et fausses. Nous avons expérimenté un certain nombre de modèles basés sur le Deep Learning, y compris différents intégrations de mots, tels que Glove, ElMo, entre autres. Le modèle BerTweet a obtenu le meilleur score global F1 de 0,881 et a obtenu le troisième rang sur la tâche ci-dessus.", 'pt': 'A disseminação do COVID-19 foi acompanhada de desinformação generalizada nas mídias sociais. Em particular, o Twitterverse viu um grande aumento na disseminação de fatos e números distorcidos. O presente trabalho visa identificar tweets sobre a COVID-19 que contenham informações nocivas e falsas. Experimentamos vários modelos baseados em Deep Learning, incluindo diferentes incorporações de palavras, como Glove, ELMo, entre outros. O modelo BERTweet alcançou a melhor pontuação geral da F1 de 0,881 e garantiu o terceiro lugar na tarefa acima.', 'ja': '新型コロナウイルスの感染拡大に伴い、ソーシャルメディアでは誤った情報が広がっています。特にTwitterverseでは、歪んだ事実や数字の発信が大幅に増加しています。本作は、有害かつ虚偽の情報を含む新型コロナウイルスに関するツイートを特定することを目的としています。Glove、ELMoなど、さまざまな単語の埋め込みを含む、ディープラーニングベースのモデルを数多く実験しました。BERTweetモデルは、総合F 1スコア0.881を達成し、上記のタスクで3位を確保しました。', 'zh': 'COVID-19传随社交媒体普遍存在错误信息。 尤是,Twitterverse见证枉事及数传大幅增益。 今之务在识COVID-19之推文,其有害虚信。 已试规模深度,异词嵌手套,ELMo等。 BERTweet于F1上得0.881最总分,而于此为第三。', 'ru': 'Распространение COVID-19 сопровождалось широкой дезинформацией в социальных сетях. В частности, Twitterverse стал свидетелем резкого увеличения распространения искаженных фактов и цифр. Настоящая работа направлена на выявление твитов о COVID-19, которые содержат вредную и ложную информацию. Мы экспериментировали с рядом моделей, основанных на глубоком обучении, включая различные вложения слов, такие как Glove, ELMo и другие. Модель BERTweet достигла лучшего общего показателя F1 - 0,881 и заняла третье место по вышеуказанной задаче.', 'hi': 'कोविड-19 के प्रसार के साथ सोशल मीडिया पर व्यापक गलत सूचनाएं दी गई हैं। विशेष रूप से, ट्विटरवर्स ने विकृत तथ्यों और आंकड़ों के प्रसार में भारी वृद्धि देखी है। वर्तमान कार्य का उद्देश्य कोविड -19 के बारे में ट्वीट की पहचान करना है जिसमें हानिकारक और झूठी जानकारी शामिल है। हमने कई डीप लर्निंग-आधारित मॉडलों के साथ प्रयोग किया है, जिसमें विभिन्न शब्द एम्बेडिंग शामिल हैं, जैसे कि ग्लोव, ईएलएमओ, दूसरों के बीच। BERTweet मॉडल ने 0.881 का सर्वश्रेष्ठ समग्र F1-स्कोर हासिल किया और उपरोक्त कार्य पर तीसरा स्थान हासिल किया।', 'ga': 'In éineacht le scaipeadh COVID-19 tá faisnéis mhícheart forleathan ar na meáin shóisialta. Go háirithe, tá méadú mór tagtha ar Twitterverse i scaipeadh fíricí agus figiúirí as a riocht. Tá sé mar aidhm ag an obair reatha tweets a aithint maidir le COVID-19 ina bhfuil faisnéis dhochrach agus bhréagach. Táimid tar éis triail a bhaint as roinnt samhlacha Deep Learning-bhunaithe, lena n-áirítear leabaithe focal éagsúla, mar Glove, ELMo, i measc cinn eile. Bhain samhail BERTweet an scór F1 iomlán is fearr de 0.881 amach agus fuair sé an tríú céim ar an tasc thuas.', 'ka': 'COVID-19-ის გაფართლება სოციალური მედიაში უფრო გაფართებულია. განსაკუთრებით, Twitterverse ხედავთ ძალიან დიდი გაზრდილობა განსხვავებული ფექტურების და რიცხვების განსხვავებაში. მიმდინარე სამუშაო სამუშაო იდენტიფიკაცია COVID-19-ზე, რომელიც აქვს სხვადასხვა და ცოტა ინფორმაცია. ჩვენ ექსპერიმენტირებდით მრავალ ძალიან სწავლის მოდელებით, რომელიც განსხვავებული სიტყვები, როგორც Glove, ELMo, სხვების შორის. BERTweet მოდელი 0.881-ის ყველაზე საუკეთესო F1-სოფლიო დასრულდა და მესამე სოფლიოს დასრულება.', 'hu': 'A COVID-19 terjedését a közösségi médiában széles körben elterjedt félrevezetés kísérte. Különösen a Twitterverse óriási növekedést tapasztalt a torz tények és számok terjesztésében. Jelen munka célja a COVID-19-re vonatkozó tweetek azonosítása, amelyek káros és hamis információkat tartalmaznak. Számos Deep Learning alapú modellel kísérleteztünk, beleértve a különböző szóbeágyazásokat, mint például a Glove, az ELMo, stb. A BERTweet modell elérte a legjobb teljes F1 pontszámot, 0,881-et, és a fenti feladat során harmadik helyet ért el.', 'el': 'Η εξάπλωση του συνοδεύεται από εκτεταμένες παραπληροφορίες στα μέσα κοινωνικής δικτύωσης. Ειδικότερα, το Twitterverse έχει δει μια τεράστια αύξηση στη διάδοση διαστρεβλωμένων γεγονότων και αριθμών. Η παρούσα εργασία στοχεύει στον εντοπισμό tweets σχετικά με το COVID-19 που περιέχουν επιβλαβείς και ψευδείς πληροφορίες. Έχουμε πειραματιστεί με μια σειρά από μοντέλα βασισμένα στη βαθιά μάθηση, συμπεριλαμβανομένων διαφορετικών ενσωμάτωσης λέξεων, όπως Γάντι, ΕΛMo, μεταξύ άλλων. Το μοντέλο πέτυχε την καλύτερη συνολική βαθμολογία του 0.881 και εξασφάλισε την τρίτη θέση στην παραπάνω αποστολή.', 'it': 'La diffusione del COVID-19 è stata accompagnata da una diffusa disinformazione sui social media. In particolare, Twitterverse ha visto un enorme aumento nella diffusione di fatti e cifre distorte. Il presente lavoro mira a identificare tweet riguardanti COVID-19 che contengono informazioni dannose e false. Abbiamo sperimentato una serie di modelli basati sul Deep Learning, tra cui diverse incorporazioni di parole, come Glove, ELMo, tra gli altri. Il modello BERTweet ha ottenuto il miglior punteggio complessivo F1 di 0,881 e si è assicurato il terzo posto nel compito sopra indicato.', 'lt': 'COVID-19 paplitimą papildė plačiai paplitusi neteisinga socialinės žiniasklaidos informacija. Visų pirma Twitterverse pastebėjo didelį iškraipytų faktų ir skaičių sklaidos padidėjimą. The present work aims at identifying tweets regarding COVID-19 which contains harmful and false information.  Eksperimentavome su daugeliu modelių, pagrįstų giliavandeniu mokymusi, įskaitant skirtingus žodžių įterpimus, pvz., pirštines, ELMo, be kita ko. BERTweet modelis pasiekė geriausią bendrą F1 tašką – 0,881 ir užtikrino trečiąjį tašką pirmiau minėtoje užduotyje.', 'mk': 'The spread of COVID-19 has been accompanied with widespread misinformation on social media.  Посебно, Твитерверсот виде огромно зголемување на ширењето на искорените факти и бројки. Сегашната работа има за цел идентификување на твитови во врска со COVID-19, кои содржат штетни и лажни информации. Експериментиравме со голем број модели базирани на длабоко учење, вклучително и различни зборови, како што се Ракавицата, ЕЛМО, меѓу другите. Моделот BERTweet го постигна најдобриот целокупен резултат F1 од 0,881 и го обезбеди третиот ранг на наведената задача.', 'kk': 'COVID-19 деген тарату социалдық медиақтар үлкен жалғастырылған. Әсіресе, Твиттерверлер бөліп тұрған шындықтар мен мәліметтерді тарату үшін үлкен көптеген. Қазіргі жұмыс COVID- 19 туралы жарамсыз және жарамсыз мәліметі бар tweets- тізбектерін анықтау мақсаты. Біз бірнеше қалыпты оқыту негізделген үлгілерді тәжірибедік. Басқалардың арасында Glove, ELMo секілді әртүрлі сөздерді ендіру үлгілерімен тәжірибедік. BERTweet үлгісі 0, 881 деген ең жалпы F1- нүктесін жетті және жоғары тапсырманың үшінші жолдарын қорғау үшінші жолдарын қорғады.', 'ml': 'കോവിഡി-19 വിതരണം സാമൂഹിക മാധ്യമങ്ങളില്\u200d വിശാലമായ തെറ്റായ വിവരം കൂടിയിരിക്കുന്നു. പ്രത്യേകിച്ച്, ടൂട്ടിവെര്\u200dവര്\u200dസ് വ്യത്യസ്ത കാര്യങ്ങളെയും സംഖ്യകളെയും വ്യത്യസ്തമാക്കുന്നതില്\u200d വലിയ കൂടുതല്\u200d  ഇപ്പോഴത്തെ ജോലിയുടെ ലക്ഷ്യം COVID-19 ക്കുറിച്ച് ടൂട്ടുകള്\u200d തിരിച്ചറിയുവാന്\u200d ഉദ്ദേശിക്കുന്നു. അതി ആഴത്തെ പഠിക്കുന്നതിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d നിന്നും കുറച്ച് മോഡലുകള്\u200d ഞങ്ങള്\u200d പരീക്ഷിച്ചിട്ടുണ്ട്. വ്യത്യസ്ത വാക്കുകള്\u200d ഉള്\u200d ബെര്\u200dട്ട്വീറ്റ് മോഡല്\u200d 0. 881-ന്റെ ഏറ്റവും മികച്ച എഫ്1 സ്കോര്\u200d എത്തി. മുകളിലുള്ള ജോലിയില്\u200d മൂന്നാം സ്ഥാനത്ത് സുരക്', 'mn': 'COVID-19-ын тархалт нийгмийн мэдээлэл дээр нийтлэг буруу хэлбэртэй хамтран байна. Ялангуяа, Твиттервийн хүмүүс өөрчлөгдсөн жинхэнэ болон тоонуудын тархалтын их нэмэлт харсан. Одоо байгаа ажлын зорилго нь COVID-19-ын хувьд хохиромжтой, худлаа мэдээлэл агуулдаг tweets-г олж мэдэх зорилго юм. Бид олон гүнзгий суралцах сургалтын үндсэн загваруудыг туршиж үзсэн. Глов, ЭлМо гэх мэт өөр үгнүүдийг нэмсэн. БЕРТУИТ загварын загвар нь 0.881-ийн хамгийн шилдэг F1 оноо олж, дээрх ажил дээрх гуравдах хэмжээг хамгаалдаг.', 'ms': 'Penyebarkan COVID-19 telah disertai dengan salah maklumat yang tersebar pada media sosial. Terutama, Twitterverse telah melihat peningkatan besar dalam penyebaran fakta dan angka terganggu. Kerja ini bertujuan untuk mengenalpasti tweet mengenai COVID-19 yang mengandungi maklumat berbahaya dan palsu. Kami telah eksperimen dengan sejumlah model yang berdasarkan Belajar Dalam Dalam, termasuk pembangunan perkataan yang berbeza, seperti Sarung tangan, ELMo, antara lain. Model BERTweet mencapai nilai F1 keseluruhan terbaik 0.881 dan selamatkan peringkat ketiga pada tugas di atas.', 'mt': 'It-tixrid tal-COVID-19 kien akkumpanjat minn informazzjoni ħażina mifruxa dwar il-midja soċjali. B’mod partikolari, Twitterverse wera żieda kbira fit-tixrid ta’ fatti u ċifri mfixkla. Il-ħidma preżenti għandha l-għan li tidentifika tweets dwar COVID-19 li fihom informazzjoni dannuża u foloz. Esperimentajna b’għadd ta’ mudelli bbażati fuq it-Tagħlim fil-fond, inklużi inkorporazzjonijiet ta’ kliem differenti, bħall-Glove, l-ELMo, fost oħrajn. Il-mudell BERTweet kiseb l-aħjar punteġġ F1 globali ta’ 0.881 u kiseb it-tielet grad fuq il-kompitu ta’ hawn fuq.', 'no': 'Spriedet av COVID-19 er lagt med breidde feilinformasjon på sosiale medier. I særskilt har Twitterverse sett ein stor økning i disseminasjonen av forskjerte faktoar og figurer. Det gjeldande arbeidet må identifisera tweeter om COVID-19 som inneheld skadelig og falsk informasjon. Vi har eksperimentert med mange dyppa læringsbaserte modeller, inkludert ulike ordinnbygging, som Glove, ELMo, blant andre. BERTweet-modellen oppnådd den beste generelle F1-poeng med 0,881 og sikker den tredje rekninga på oppgåva over.', 'pl': 'Rozprzestrzenianiu się COVID-19 towarzyszyły powszechne dezinformacje w mediach społecznościowych. W szczególności Twitterverse zauważył ogromny wzrost rozpowszechniania zniekształconych faktów i liczb. Celem niniejszej pracy jest identyfikacja tweetów dotyczących COVID-19, które zawierają szkodliwe i fałszywe informacje. Eksperymentowaliśmy z wieloma modelami opartymi na Deep Learning, w tym różnymi osadzeniami słów, takimi jak Glove, ELMo, między innymi. Model BERTweet osiągnął najlepszy ogólny wynik F1 0.881 i zdobył trzecie miejsce w powyższym zadaniu.', 'ro': 'Răspândirea COVID-19 a fost însoțită de dezinformare pe scară largă pe rețelele sociale. În special, Twitterverse a văzut o creștere imensă a diseminării faptelor și cifrelor distorsionate. Prezenta lucrare își propune identificarea tweet-urilor referitoare la COVID-19 care conțin informații dăunătoare și false. Am experimentat cu o serie de modele bazate pe Deep Learning, inclusiv diferite încorporări de cuvinte, cum ar fi Glove, ELMo, printre altele. Modelul BERTweet a obținut cel mai bun scor general F1 de 0,881 și a asigurat locul al treilea în sarcina de mai sus.', 'so': 'Bogga COVID-19 waxaa lagu darsaday macluumaad khalad ah oo ballaadhan oo ku saabsan shabakadda bulshada. Si gaar ah Twitterka waxaa arkay kordhiska badan oo kala firdhiya waxyaabaha qalloocan iyo lambarada kala duwan. Shaqo joogtada ah waxaa ku qoran qoraal ku saabsan COVID-19 oo ku qoran macluumaad waxyeello ah iyo been ah. Waxaannu ku tijaabiyey tusaalooyin badan oo ku saleysan waxbarashada mool dheer, kuwaas oo ka mid ah hadal kala duduwan sida Glove, ELMo oo kale. Tusaale-BERTweet wuxuu gaadhay dhamaankii ugu wanaagsan ee F1-scor 0.881, wuxuuna ilaaliyey darajada saddexaad ee shaqada sare.', 'sv': 'Spridningen av COVID-19 har åtföljts av omfattande missinformation på sociala medier. Framför allt har Twitterverse sett en enorm ökning av spridningen av förvrängda fakta och siffror. Detta arbete syftar till att identifiera tweets om COVID-19 som innehåller skadlig och falsk information. Vi har experimenterat med ett antal Deep Learning-baserade modeller, inklusive olika ordinbäddningar, såsom Glove, ELMo, bland andra. BERTweet-modellen uppnådde den bästa totala F1-poängen på 0,881 och säkrade tredje rankingen på ovanstående uppgift.', 'sr': 'Proširenje COVID-19 praćeno je širom širom pogrešne informacije na društvenim medijima. Posebno, Twitterversi su vidjeli ogromno povećanje širenja iskrivljenih činjenica i brojeva. Sadašnji rad je cilj identifikacije tweeta u vezi COVID-19 koja sadrži štetne i lažne informacije. Eksperimentirali smo sa mnogim modelima na temelju dubokog učenja, uključujući različite reči, kao što su Glove, ELMo, među drugima. BERTweet model je postigao najbolji ukupni F1 rezultat od 0,881 i osigurao treći red na iznad zadatka.', 'si': 'COVID-19 ගේ විස්තරය සමාජික මධ්\u200dයමාධ්\u200dයමයේ විස්තර වැරදිලි වැරදිලි විස්තරයක් සමග සමග විස්තර විශේෂයෙන්, ට්විට්ටර්වර්ස් දැකලා තියෙනවා විනාශ කරපු ඇත්ත සහ සංඛාණාවල් විශාල විශාලයක්. මේ වැඩේ අල්ලගන්නවා COVID-19 ගැන ට්විට් අඳුරගන්න, ඒ වගේම අනතුරු සහ වැරදි තොරතුරු තියෙනවා. අපි ගොඩක් ගොඩක් ඉගෙන ගන්න ප්\u200dරමාණයක් සමග පරීක්ෂණය කරලා තියෙනවා, වෙනස් වචනයක් සම්බන්ධ කරලා තියෙනවා, ජෝලෝව BERTwitt මොඩේල් එකේ හොඳම F1-ස්කෝර් 0.881 වලින් සුළුවන් වුණා, ඒ වගේම උඩින් වැඩේ තුන්වෙනි ස්කෝර් එක ආරක්', 'ta': 'COVID-19 விரிவாக்கம் சேர்க்கப்பட்டுள்ளது சமூக ஊடகங்களில் விரிவான தவறான தகவல்களுடன். குறிப்பிட்டு, இருப்பவர்கள் குறிப்பிட்ட காரணங்கள் மற்றும் இலக்கங்களை விரிவாக்கத்தில் அதிகப்பெரிய அதிகரிப் தற்போதைய வேலை COVID-19 பற்றிய tweets குறிப்பிடும் தெரியும். இது காயப்படுத்தல் மற்றும் பொய் தகவல் உள்ளது. நாங்கள் சோதித்துள்ளோம் ஆழமான கற்றல் மாதிரிகளால், வேறு வார்த்தைகள் உள்ளீடுகள், போன்ற கிளேவ், ELMo, மற்றவர்களுக்கும். BERTweet மாதிரி சிறந்த மொத்தமான F1- மதிப்பு 0. 881 பெற்றுவிட்டது மற்றும் மேலேயுள்ள பணியில் மூன்றாவது நிலை பாதுகா', 'ur': 'COVID-19 کے پھیلانے کے ساتھ سوسیل میڈیاں میں وسیع غلط اطلاعات کے ساتھ ہے۔ مخصوصاً Twitterverse نے دیکھا ہے کہ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹیٹ ٹ اس کام کا مطابق ہے کہ COVID-19 کے بارے میں ٹویٹ پہچان کریں جس میں نقصان اور غلط معلومات ہے. ہم نے بہت سی عمیق تعلیم کی بنیاد کی مدل کے ساتھ آزمائش کی ہے، ایک دوسرے کے ساتھ مختلف کلمات انڈینگ، جیسے گلوف، المو۔ BERTweet Model achieved the best overall F1-score of 0.881 and secured the third rank on the above task.', 'uz': "COVID-19 kengaytmasi jamiyat media bilan juda ko'p xatolik maʼlumot bilan birlashadi. Ko'pchilik, Twitterning foydalanuvchilari haqiqat va raqamlarni ajratishga katta ko'paydi. The present work aims at identifying tweets regarding COVID-19 which contains harmful and false information.  Biz ko'pchilik o'rganish modellari bilan ko'p so'zlarni o'rganib ko'rib chiqqan so'zlarni boshqa so'zlar bilan, Glove, ELMo kabi. BERTwitt modeli 0. 881 uchun eng yaxshi bir necha F1 scori topadi va yuqori vazifaning 3 darajaga qaramadi.", 'vi': 'Việc lan rộng COVID-19 đã kèm theo thông tin sai lầm phổ biến trên các phương tiện xã hội. Đặc biệt, Twittervũ đã thấy nhiều phát triển phát tán các dữ liệu và nhân vật bị méo mó. Công việc hiện nay nhằm mục đích xác định tweet về COVID-19, cung cấp thông tin có hại và giả. Chúng tôi đã thử nghiệm với một số mô hình dựa trên Deep Theo, bao gồm những từ mới ghép, như Glove, ElMo, một số khác. Kết quả thử nghiệm của BERTweet đã hoàn thành tốt nhất số F1 trong số 0.881 và đảm bảo cấp thứ ba trong nhiệm vụ này.', 'bg': 'Разпространението на COVID-19 е съпроводено с широко разпространена дезинформация в социалните медии. По-специално Туитървърс е видял огромно увеличение на разпространението на изкривени факти и цифри. Настоящата работа има за цел да идентифицира туитове относно КоVID-19, които съдържат вредна и невярна информация. Експериментирали сме с редица модели, базирани на дълбоко обучение, включително различни вграждания на думи, като Ръкавица, ЕЛМО и др. Моделът постигна най-добрия общ резултат от 0.881 и осигури третия ранг на горната задача.', 'hr': 'Proširenje COVID-19 praćeno je širom širom pogrešne informacije na društvenim medijima. Posebno, Twitterverse su vidjeli ogromno povećanje širenja iskrivljenih činjenica i brojeva. Sadašnji rad je cilj identificiranja tweeta u vezi COVID-19 koja sadrži štetne i lažne informacije. Eksperimentirali smo s brojem modela na temelju dubokog učenja, uključujući različite riječi ugrađenja, poput Glove, ELMo, među drugima. BERTweet model je postigao najbolji ukupni rezultat F1 od 0,881 i osigurao treći red na iznad zadatka.', 'da': 'Spredningen af COVID-19 er blevet ledsaget af udbredt misinformation på sociale medier. Især Twitterverse har oplevet en enorm stigning i formidlingen af forvrængede fakta og tal. Dette arbejde sigter mod at identificere tweets vedrørende COVID-19, som indeholder skadelige og falske oplysninger. Vi har eksperimenteret med en række Deep Learning-baserede modeller, herunder forskellige ord embeddings, såsom Glove, ELMo, blandt andre. BERTweet-modellen opnåede den bedste samlede F1-score på 0,881 og sikrede sig tredje rang på ovenstående opgave.', 'nl': 'De verspreiding van COVID-19 gaat gepaard met wijdverspreide misinformatie op sociale media. Met name Twitterverse heeft een enorme toename van verspreiding van vervormde feiten en cijfers gezien. Het huidige werk heeft tot doel tweets over COVID-19 te identificeren die schadelijke en valse informatie bevatten. We hebben geëxperimenteerd met een aantal op Deep Learning gebaseerde modellen, waaronder verschillende woord embeddings, zoals Glove, ELMo, onder andere. BERTweet behaalde de beste algemene F1-score van 0.881 en behaalde de derde plaats op bovenstaande taak.', 'de': 'Die Ausbreitung von COVID-19 ging mit weitverbreiteten Fehlinformationen in sozialen Medien einher. Insbesondere Twitterverse hat eine enorme Zunahme der Verbreitung verzerrter Fakten und Zahlen beobachtet. Die vorliegende Arbeit zielt darauf ab, Tweets zu COVID-19 zu identifizieren, die schädliche und falsche Informationen enthalten. Wir haben mit einer Reihe von Deep Learning-basierten Modellen experimentiert, einschließlich verschiedener Worteinbettungen, wie Glove, ELMo, unter anderem. BERTweet erzielte die beste F1-Gesamtwertung von 0.881 und sicherte sich den dritten Rang bei der oben genannten Aufgabe.', 'id': 'Penyebar COVID-19 telah disertai dengan misinformasi luas di media sosial. Terutama, Twitterverse telah melihat peningkatan besar dalam penyebaran fakta dan angka terganggu. Pekerjaan ini bertujuan untuk mengidentifikasi tweet mengenai COVID-19 yang mengandung informasi berbahaya dan palsu. Kami telah eksperimen dengan sejumlah model yang berdasarkan Belajar Dalam Dalam, termasuk kata-kata yang berbeda, seperti Glove, ELMo, diantara yang lain. Model BERTweet mencapai nilai F1 yang terbaik dari 0,881 dan mengamankan rangka ketiga dalam tugas di atas.', 'fa': 'گسترش COVID-19 در رسانه\u200cهای اجتماعی با وسیله\u200cی غلطی گسترده شده است. مخصوصا، ترویتر ها افزایش بزرگی در انتشار حقیقت و تصاویر شکسته را دیدند. کاری که در حال حاضر انجام می\u200cدهد، هدف یافتن توئیت در مورد COVID-19 که اطلاعات خطرناک و دروغ دارد است. ما با تعدادی از مدل\u200cهای عمیق یادگیری را آزمایش کرده\u200cایم، شامل انجمن کلمه\u200cهای مختلف، مثل گلوف، المو، در میان بقیه. مدل BERTweet بهترین نقاط F1 در حدود 0.881 به دست آورد و درجه سوم در کار بالا امن داد.', 'ko': '코로나 확산에는 소셜미디어에서 광범위한 잘못된 정보가 수반된다.특히 트위터 버스는 왜곡된 사실과 숫자의 전파가 크게 증가하는 것을 보았다.유해·허위 정보가 담긴 코로나 관련 트윗을 식별하기 위한 사업이다.우리는 장갑, ELMo 등 다양한 단어의 삽입을 포함한 깊이 있는 학습 모델을 많이 시도했다.BERTweet model은 베스트 F1 총점 0.881을 획득했으며 이 중 3위에 올랐다.', 'sw': 'Kusambazwa kwa COVID-19 umekuwa pamoja na taarifa mbalimbali kuhusu mitandao ya kijamii. Kwa hakika, watumiaji wa Twita wameona ongezeko kubwa la kusambaza ukweli na takwimu zinazochanganyika. Kazi ya sasa inalenga kutambua twiti kuhusu COVID-19 ambayo ina taarifa za uongo na za uongo. Tumejaribu kwa baadhi ya mifano yenye msingi wa elimu ya ndani, ikiwa ni pamoja na maneno tofauti yaliyoandikwa kama vile Glove, ELMo, miongoni mwa wengine. Mfano wa Twita wa BERTwita ulifanikiwa kiwango kikubwa cha F1 cha 0.881 na ulihakikisha nafasi ya tatu katika kazi ya juu.', 'tr': "COVID-19'yň daşyrylyky soýdaly medialarda ýalňyş döwletlendir. Özellikle, Twittersler, dağıtılan gerçekleri ve şekiller dağıtılmasında büyük bir artış gördüler. Häzirki işi COVID-19 barada agyrly we ýalňyş maglumaty barlag tweetleri tanamak maksady. Birnäçe derin öwrenmek tabanly nusgalary bilen synanyşdyrdyk. Glob, ELMo ýaly başga sözler bilen üýtgeden çykypdyk. BERTWET nusgasyny 0.881'iň iň gowy görkezilen we üstündeki zadyň üçünji sahypasyny gordy.", 'af': "Die verspreiding van COVID-19 is gevolg met verspreidige misformasie op sosiale media. In besonderhede het Twitterverse 'n groot vergroting gesien in verspreiding van verstrooide fakte en figure. Die huidige werk doel om tweets te identifiseer aangaande COVID-19 wat skadelike en valse inligting bevat. Ons het eksperimenteer met 'n aantal diep leer-gebaseerde modele, insluitend verskillende woorde inbêding, soos Glove, ELMo, onder ander. BERTweet model het die beste heeltemal F1- telling van 0. 881 bereik en die derde rank op die bo-taak geskerm.", 'sq': 'Përhapja e COVID-19 është shoqëruar me informacion të gjerë të gabuar mbi mediat sociale. Në veçanti, Twitterverse ka parë një rritje të madhe në përhapjen e fakteve dhe shifrave të shtrembëruara. Puna e tanishme synon të identifikojë tweetet lidhur me COVID-19 që përmban informacion të dëmshëm dhe të rreme. Kemi eksperimentuar me një numër modelesh bazuar në mësim të thellë, duke përfshirë përfshirje fjalësh të ndryshme, si Glove, ELMo, midis të tjerëve. Modeli BERTweet arriti rezultatin më të mirë të përgjithshëm F1 prej 0.881 dhe siguroi rendin e tretë në detyrën e lartë.', 'am': 'የCOVID-19 ስፋት በማኅበራዊ ሚዲያ ላይ በተሰፋው ስህተት ላይ ነው፡፡ በተለይም ትዊተር ሰራዊቶች የጥላቻውን ውሸትና የሥልጣናት ትልቅ እጥፍ አየ፡፡ The present work aims at identifying tweets regarding COVID-19 which contains harmful and false information.  የጥልቅ ትምህርት ምሳሌዎች፣ በተለየ ቃላት አካባቢዎች፣ እንደ Glove፣ ELMo፣ ሌሎችም ናቸው፡፡ BERTweet-model የF1-score በ0.881 ውጤት አግኝቷል፡፡', 'hy': 'COVID-19-ի տարածումը ուղեկցված է սոցիալական լրատվամիջոցների մասին տարածված սխալ տեղեկատվության հետ: Որպես հատկապես, Թվիթերվերեսը տեսել է խռովության փաստերի և թվերի տարածման մեծ աճ: Այս աշխատանքի նպատակն է հայտնաբերել COVID-19-ի մասին թվիթերը, որոնք պարունակում են վնասավոր և կեղծ տեղեկատվություն: We have experimented with a number of Deep Learning-based models, including different word embeddings, such as Glove, ELMo, among others.  BER-վիթ մոդելը հասավ 0.88-ի լավագույն ընդհանուր F1-գնահատականին և երրորդ գնահատականը հասավ վերևի խնդրի վրա:', 'az': "COVID-19 yayılması sosyal mediyalarında çox yayılmış xətalarla birlikdə idi. Özellikle, Twitterverse, fərqli həqiqətləri və şəkilləri dağıtmaq üçün böyük bir artıq gördü. Şimdiki işin COVID-19 barəsindəki tweetləri təsdiqləmək məqsədilə bədbəxt və yalan məlumatlar barəsində yazılmışdır. Biz bir çox derin öyrənmə tabanlı modellərlə imtahana çəkdik, bəlkə Glove, ELMo kimi fərqli sözlər içərisində. BERTweet modeli 0.881'in ən yaxşı F1-score qəbul etdi və üstündəki iş üçüncü dərəcəsini təhlükəsiz etdi.", 'bn': 'সামাজিক প্রচার মাধ্যমের বিস্তারিত ভুল তথ্যের সাথে কভিড-১৯ এর ছড়িয়ে পড়েছে। বিশেষ করে টুইটার ব্যবহারকারীরা বিভ্রান্ত তথ্য এবং সংখ্যার বিভিন্ন বিভিন্ন বৃদ্ধি প্রদান করেছে। বর্তমান কাজের লক্ষ্য হচ্ছে COVID-19 সম্পর্কে টুইট চিহ্নিত করা যার মধ্যে ক্ষতিগ্রস্ত এবং মিথ্যা তথ্য রয়েছে। আমরা বেশ কয়েকটি গভীর শিক্ষা ভিত্তিক মডেল দিয়ে পরীক্ষা করেছি, যার মধ্যে বিভিন্ন শব্দ বিভিন্ন ভিন্ন শব্দ, যেমন গ্লোভ, এলমো অন্ BERTweet model achieved the best overall F1-score of 0.881 and secured the third rank on the above task.', 'cs': 'Šíření COVID-19 bylo doprovázeno rozšířenými dezinformacemi na sociálních médiích. Zejména Twitterverse zaznamenal obrovský nárůst šíření zkreslených faktů a čísel. Cílem této práce je identifikovat tweety týkající se COVID-19, které obsahují škodlivé a nepravdivé informace. Experimentovali jsme s řadou modelů založených na Deep Learning, včetně různých vložení slov, jako jsou Glove, ELMo, mimo jiné. Model BERTweet dosáhl nejlepšího celkového F1 skóre 0.881 a zajistil třetí místo na výše uvedeném úkolu.', 'ca': "La difusió de COVID-19 ha estat acompanyada d'una gran difícil informació dels mitjans socials. En particular, Twitterverse ha vist un gran augment en la difusió de fets i cifres distorsionats. La feina actual mira a identificar tweets sobre COVID-19 que contén informació nociva i falsa. Hem experimentat amb alguns models basats en aprenentatge profund, incloent diferents integracions de paraules, com Glove, ELMo, entre altres. El model BERTweet va aconseguir la millor puntuació F1 global de 0,881 i va aconseguir el tercer rang de la tasca anterior.", 'et': 'COVID-19 levikuga on kaasnenud sotsiaalmeedias laialdane valeteave. Eriti on Twitterverse näinud moonutatud faktide ja arvude levitamise tohutut kasvu. Käesoleva töö eesmärk on tuvastada kahjulikku ja valeteavet sisaldavaid säutseid COVID-19 kohta. Oleme katsetanud mitmeid sügavõppel põhinevaid mudeleid, sealhulgas erinevaid sõnade manustamist, nagu Glove, ELMo jne. BERTweet mudel saavutas parima üldise F1-skoori 0,881 ja saavutas eespool nimetatud ülesandel kolmanda koha.', 'bs': 'Proširenje COVID-19 praćeno je širom širom pogrešne informacije na društvenim medijima. Posebno, Twitterversi su vidjeli ogromno povećanje širenja iskrivljenih činjenica i brojeva. Sadašnji rad je cilj identifikacije tweeta u vezi COVID-19 koja sadrži štetne i lažne informacije. Eksperimentirali smo sa mnogim modelima na temelju dubokog učenja, uključujući različite rečenice, kao što su Glove, ELMo, među drugima. BERTweet model je postigao najbolji ukupni F1 rezultat od 0,881 i osigurao treći red na iznad zadatka.', 'fi': 'COVID-19:n leviämiseen on liittynyt laaja-alaista väärää tietoa sosiaalisessa mediassa. Erityisesti Twitterverse on nähnyt vääristyneiden faktojen ja lukujen levittämisen valtavaa kasvua. Tämän työn tavoitteena on tunnistaa COVID-19:ää koskevia tweettejä, jotka sisältävät haitallista ja väärää tietoa. Olemme kokeilleet useita Deep Learning -pohjaisia malleja, kuten erilaisia sanaupotuksia, kuten Glove, ELMo, jne. BERTweet-malli saavutti parhaan F1-pisteen 0,881 ja varmisti kolmannen sijan edellä mainitussa tehtävässä.', 'ha': 'Kirar COV-19 ya sami baya-bayani na zane-zane kan mitandai masu ƙarami. In particular, Twitterverse has seen a huge increase in dissemination of distorted facts and figures.  Yin aikin da ake kai yanzu ya gane jumuiya masu husũma na COV-19 wanda yana da takardar da kuma ƙarya. Haƙĩƙa, Mun jarraba wasu misãlai masu da aka sanar da Deptu, kamar da aka shigar da wasu kalmõmi dabam-dabam, kamar, Gani, ELMo, da wasu. @ info: whatsthis', 'jv': 'Tanggal sing katol-19, corid-19 sedhaya akeh lan akeh informasi siji-perusahaan neng media sotiki. Genjer-Genjer, sithik 2 Workspace Names Awak dhéwé éntuk éntuk karo akeh akeh model sing nggawe deep-Learning, tambah akeh embedding word sampeyan, kaya Global, elMo, sak wigat. jer', 'sk': 'Širjenje COVID-19 je spremljalo razširjeno napačno informacijo na družbenih omrežjih. Zlasti Twitterverse je videl veliko povečanje širjenja izkrivljenih dejstev in številk. Cilj tega dela je identificirati tweete v zvezi s COVID-19, ki vsebujejo škodljive in lažne informacije. Eksperimentirali smo s številnimi modeli, ki temeljijo na globljem učenju, vključno z različnimi besednimi vdelavami, kot so Glove, ELMo, med drugim. Model BERTweet je dosegel najboljšo skupno oceno F1 0,881 in zagotovil tretjo mesto na zgornji nalogi.', 'he': 'התפשטות של COVID-19 הולידה עם מידע שגוי מפורסם על תקשורת חברתית. במיוחד, טוויטרווירס ראה עלייה עצומה בהפיצה של עובדות ודמות מעוות. העבודה הנוכחית מתכוונת לזהות טוויטים בנוגע לקוביד-19 שמכילים מידע מזיק ושגוי. ניסונו עם מספר דוגמנים מבוססים על למידה עמוקה, כוללים מילים שונות, כמו כפפות, ELMo, בין אחרים. מודל BERTweet השיג את הציון הכי טוב של F1 של 0.881 והבטיח את הדרגה השלישית על המשימה הנגדית.', 'bo': 'COVID-19ཡི་འགྱུར་བརྗོད་དེ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ཆེན་པོ་ཞིག་དང་མཉམ་དུ་འགྱུར་བ་ཡིན། དམིགས་བསལ་ན། དྲ་དམངས་ཚོས་ཟིན་བྲིས་བ་མང་ཙམ་རྒྱ་བསྐྱེད་ཡོད་པ་རེད། The present work aims to identify tweets regarding COVID-19 which contains harmful and false information. ང་ཚོས་རྗེས་སྦྱོར་བའི་སྨྲ་བ་གཞི་རྩོལ་བའི་མིག་པ་མང་པོ་ཞིག་གིས་བརྟན་དཔེར་ན། BERTweet model achieved the best overall F1-score of 0.881 and secured the third rank on the above task.'}
{'en': 'iCompass at NLP4IF-2021Fighting the COVID-19 Infodemic', 'pt': 'iCompass no NLP4IF-2021 – Combatendo a Infodemia COVID-19', 'ar': 'iCompass في NLP4IF-2021 - محاربة فيروس COVID-19 Infodemic', 'es': 'iCompass en NLP4iF-2021: Luchando contra la infodemia de COVID-19', 'fr': "iCompass au salon NLP4IF-2021 — Lutter contre l'infodémie COVID-19", 'zh': 'iCompass at NLP4IF-2021 ŌĆōµŗÆCOVID-19õ┐ĪĶĪīń¢Š', 'ja': 'iCompass at NLP 4 IF -2021 - COVID -19インフォデミックとの戦い', 'ru': 'iCompass на выставке NLP4IF-2021 - Борьба с инфодемией COVID-19', 'hi': 'NLP4IF-2021 में iCompass- कोविड-19 Infodemic से लड़ना', 'ga': 'iCompass ag NLP4IF-2021 - An Infodemic COVID-19 a Chomhrac', 'ka': 'Comment', 'hu': 'Az iCompss az NLP4IF-2021-en – A COVID-19 Infodemic elleni küzdelem', 'el': 'iCompass στο NLP4IF-2021-Καταπολέμηση της πληροφορικής του COVID-19', 'kk': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'it': "iCompass a NLP4IF-2021-Combattere l'Infodemic COVID-19", 'mk': 'iCompass на NLP4IF-2021-Fighting the COVID-19 Infodemic', 'lt': 'iCompass NLP4IF-2021-Kova su COVID-19 Infodemic', 'ms': 'iCompass di NLP4IF-2021-Fighting the COVID-19 Infodemic', 'ml': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'mt': 'iCompass f’NLP4IF-2021-Ġlieda kontra l-COVID-19 Infodemic', 'pl': 'iCompass na NLP4IF-2021 – Walka z COVID-19 Infodemic', 'ro': 'iCompass la NLP4IF-2021-Combaterea Infodemicului COVID-19', 'mn': 'NLP4IF-2021-д COVID-19 мэдээллийн тулалдаг iCompass', 'so': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'sv': 'iCompass på NLP4IF-2021-Bekämpa COVID-19 Infodemic', 'ta': 'Comment', 'ur': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'no': 'iCompass på NLP4IF-2021-Fighting med COVID-19 informasjon', 'si': 'iCompass at NLP4IF-2021-fighting the COVID-19 Info', 'sr': 'iCompass u NLP4IF-2021-borbi protiv COVID-19 Infodemije', 'uz': 'Name', 'vi': 'Hợp lý tại NLLLL4NF-2021-Chống lại COVID-19 Infodemic', 'bg': 'ИКомпас на НЛП4ИФ-2021-Борба с инфодемик', 'da': 'iCompass på NLP4IF-2021-Bekæmpelse af COVID-19 Infodemic', 'nl': 'iCompass op NLP4IF-2021-Vechten tegen COVID-19 Infodemic', 'de': 'iCompass auf der NLP4IF-2021-Bekämpfung der COVID-19 Infodemic', 'id': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'ko': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'fa': 'iCompass در NLP4IF-2021-Fighting the COVID-19 Infodemic', 'sw': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'af': 'Comment', 'am': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'tr': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'hr': 'iCompass na NLP4IF-2021-borbi protiv COVID-19 informademije', 'hy': 'iCմպասը ՆԼՊ4IF-2021-ում COVID-19 Ինֆոդեմիկ պայքարելու համար', 'sq': 'iCompass në NLP4IF-2021-Fighting the COVID-19 Infodemic', 'bn': 'NLP4IF-2021- COVID-19 তথ্যের সংগ্রামে iCompassName', 'cs': 'iCompass na NLP4IF-2021 – Boj proti COVID-19 Infodemic', 'az': 'NLP4IF-2021-Fighting the COVID-19 Infodemic at iCompass', 'bs': 'iCompass u NLP4IF-2021-borbi protiv COVID-19 Infodemije', 'fi': 'iCompass NLP4IF-2021-COVID-19 Infodemicin torjunnassa', 'et': "iCompass NLP4IF-2021-Võitlus COVID-19 Infodemic'iga", 'ca': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'he': 'iCompass ב NLP4IF-2021-להילחם באינפודמיק COVID-19', 'jv': 'iCompasse nang NLP4IB-2020 1-combining the CoVD-19 Infodrom', 'bo': 'iCompass at NLP4IF-2021-Fighting the COVID-19 Infodemic', 'sk': 'iCompass na NLP4IF-2021-Boj proti COVID-19 Infodemicu', 'ha': 'iComposite at NLP4IF-2021- Combating the COV-19 information'}
{'en': 'This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021. This task is accomplished using a variety of techniques. We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand. ARBERT, MARBERT, AraBERT, Arabic ALBERT and BERT-base-arabic were used. According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.', 'es': 'Este documento proporciona una descripción detallada del sistema y sus resultados, que se produjeron como parte de la tarea compartida de NLP4IF para combatir la infodemia de COVID-19 en NAACL 2021. Esta tarea se lleva a cabo mediante una variedad de técnicas. Utilizamos modelos de representación de texto contextualizados de última generación que se ajustaron para la tarea posterior en cuestión. Se utilizaron ARBERT, MARBERT, ARABERT, Arabic ALBERT y BERT-base-Arabic. Según los resultados, Bert-base-Arabic tuvo la puntuación más alta de 0.784 F1 en el conjunto de pruebas.', 'fr': "Ce document fournit un aperçu détaillé du système et de ses résultats, qui ont été produits dans le cadre de la tâche partagée NLP4IF sur la lutte contre l'infodémie COVID-19 à la NAACL 2021. Cette tâche est accomplie à l'aide de diverses techniques. Nous avons utilisé des modèles de représentation textuelle contextualisée de pointe qui ont été affinés pour la tâche en aval en cours. ARBERT, MARBERT, ARABert, arabe ALBERT et BERT-BASE-Arabic ont été utilisés. Selon les résultats, Bert-base-Arabic a obtenu le score F1 le plus élevé de 0,784 sur le plateau de test.", 'ar': 'تقدم هذه الورقة نظرة عامة مفصلة عن النظام ونتائجه ، والتي تم إنتاجها كجزء من مهمة NLP4IF المشتركة حول مكافحة وباء المعلومات COVID-19 في NAACL 2021. ويتم إنجاز هذه المهمة باستخدام مجموعة متنوعة من التقنيات. استخدمنا أحدث نماذج تمثيل النص السياقي التي تم ضبطها بدقة لمهمة المصب في متناول اليد. تم استخدام ARBERT و MARBERT و AraBERT و ALBERT العربية و BERT-base-arabic. وفقًا للنتائج ، حصلت BERT-base-arabic على أعلى درجة 0.784 F1 في مجموعة الاختبار.', 'ja': '本稿では、NAACL 2021におけるCOVID -19インフォデミックとの戦いに関するNLP 4 IF共有タスクの一部として作成されたシステムとその結果の詳細な概要を提供します。このタスクは、様々なテクニックを使用して達成されます。最先端のコンテキスト化されたテキスト表現モデルを使用し、手元の下流タスク用に微調整しました。ＡＲＢＥＲＴ、ＭＡＲＢＥＲＴ、ＡｒａＢＥＲＴ、Ａｒａｂｅｒｔｉｃ ＡＬＢＥＲＴ及びＢＥＲＴ － ｂａｓｅ － ａｒａｂｉｃを使用した。結果によると、ＢＥＲＴ －ベースアラビックは、試験セット上で最も高い０ ． ７ ８ ４ Ｆ１スコアを有した。', 'pt': 'Este documento fornece uma visão geral detalhada do sistema e seus resultados, que foram produzidos como parte da Tarefa Compartilhada NLP4IF de Combate à Infodemia COVID-19 na NAACL 2021. Essa tarefa é realizada usando uma variedade de técnicas. Usamos modelos de representação de texto contextualizados de última geração que foram ajustados para a tarefa de downstream em mãos. ARBERT, MARBERT,AraBERT, árabe ALBERT e BERT-base-árabe foram usados. De acordo com os resultados, o BERT-base-árabe teve a pontuação F1 mais alta de 0,784 no conjunto de teste.', 'hi': 'यह पेपर सिस्टम और इसके परिणामों का एक विस्तृत अवलोकन प्रदान करता है, जिसे NAACL 2021 में कोविड -19 इन्फोडेमिक से लड़ने पर NLP4IF साझा कार्य के हिस्से के रूप में उत्पादित किया गया था। यह कार्य विभिन्न तकनीकों का उपयोग करके पूरा किया जाता है। हमने अत्याधुनिक संदर्भित पाठ प्रतिनिधित्व मॉडल का उपयोग किया जो हाथ में डाउनस्ट्रीम कार्य के लिए ठीक-ठाक थे। ARBERT, MARBERT, AraBERT, अरबी ALBERT और BERT-base-arabic का उपयोग किया गया था। परिणामों के अनुसार, BERT-base-arabic में टेस्ट सेट पर उच्चतम 0.784 F1 स्कोर था।', 'ru': 'В настоящем документе представлен подробный обзор системы и ее результатов, которые были подготовлены в рамках совместной задачи NLP4IF по борьбе с инфодемией COVID-19 в NAACL 2021. Эта задача выполняется с использованием различных методов. Мы использовали ультрасовременные контекстуализированные модели текстового представления, которые были доработаны для выполнения задачи ниже по потоку. Использовались ARBERT, MARBERT, AraBERT, Arab ALBERT и BERT-base-arabic. По результатам BERT-base-arabic имела наивысший балл 0,784 F1 на тестовом наборе.', 'zh': '本文详言系统及其终始,以为NAACL 2021上抗COVID-19流行病者NLP4IF共其一也。 此用百术成也。 我用最先进的上下文化文本表示模样,这些模形针对手头的下流务微调。 用ARBERT,MARBERT,ARABERT,阿拉伯语ALBERTBERT-base-arabic。 BERT-base-arabic得最高集上0.784 F1分。', 'ga': 'Tugann an páipéar seo forbhreathnú mionsonraithe ar an gcóras agus ar thorthaí an chórais, a cuireadh le chéile mar chuid de Thasc Roinnte NLP4IF ar Infodemic COVID-19 a Chomhrac ag NAACL 2021. Cuirtear an tasc seo i gcrích trí úsáid a bhaint as teicnící éagsúla. D’úsáideamar samhlacha ionadaíochta téacs comhthéacsaithe den scoth a bhí mionchoigeartaithe don tasc iartheachtacha a bhí idir lámha. Baineadh úsáid as ARBERT, MARBERT, Arabach, ALBERT, agus BERT-bonn-Araibis. De réir na dtorthaí, bhí an scór 0.784 F1 ab airde ag BERT-bonn-Arabais ar an tacar tástála.', 'ka': 'ეს დოკუნტი განახლება სისტემის და მისი შედეგების განსაზღვრება, რომლებიც NLP4IF გაყოფილი საზოგადომის ნაწილის ნაწილის ნაწილის გარეშე COVID-19 ინფორემიკაში NAACL 2021-ში. ეს დავალება განსხვავებული ტექნოგიების გამოყენება. ჩვენ გამოყენეთ კონტექსტუალური ტექსტის გამოსახულებული მოდელები, რომლებიც ჩემი ხელში დაკავშირებული მოდელებით. აპბვპრ, მაპბვპრ, აპაბვპრ, აპაბვპრ, ალბვპრ თ ბვპრ-ბაჱ-აპაბთკ ჟვ თჱოჲლჱგაჳა. შემდეგ, BERT-base-arabic იყო უფრო დიდი 0,784 F1 წერტილი ტესტის სეტში.', 'hu': 'Ez a tanulmány részletes áttekintést nyújt a rendszerről és annak eredményeiről, amelyeket a NAACL 2021-en a COVID-19 Infodemic leküzdésével foglalkozó NLP4IF megosztott feladat részeként készítettek. Ezt a feladatot különböző technikákkal végezzük el. Korszerű kontextuális szövegreprezentációs modelleket használtunk, amelyeket finomhangoltunk a folyamatban lévő feladathoz. ARBERT, MARBERT, AraBERT, arab ALBERT és BERT-bázis-arab nyelvet használtak. Az eredmények szerint a BERT-bázis-arab volt a legmagasabb 0,784 F1 pontszám a tesztkészleten.', 'el': 'Η παρούσα εργασία παρέχει μια λεπτομερή επισκόπηση του συστήματος και των αποτελεσμάτων του, τα οποία δημιουργήθηκαν στο πλαίσιο της κοινής εργασίας για την καταπολέμηση του COVID-19 στο NAACL 2021. Αυτό το έργο επιτυγχάνεται χρησιμοποιώντας μια ποικιλία τεχνικών. Χρησιμοποιήσαμε υπερσύγχρονα μοντέλα αναπαράστασης κειμένου που ήταν τελειοποιημένα για την επόμενη εργασία. Χρησιμοποιήθηκαν ARBERT, MARBERT, AraBERT, αραβικά ALBERT και BERT-base-arabic. Σύμφωνα με τα αποτελέσματα, το BERT-base-arabic είχε την υψηλότερη βαθμολογία 0.784 F1 στο σετ δοκιμής.', 'it': "Questo articolo fornisce una panoramica dettagliata del sistema e dei suoi risultati, che sono stati prodotti come parte del compito condiviso NLP4IF sulla lotta contro l'infodemic COVID-19 a NAACL 2021. Questo compito è svolto utilizzando una varietà di tecniche. Abbiamo utilizzato modelli di rappresentazione testuale contestualizzati all'avanguardia che sono stati perfezionati per l'attività downstream in corso. Sono stati utilizzati ARBERT, MARBERT, AraBERT, arabo ALBERT e BERT-base-arabo. Secondo i risultati, BERT-base-arabic ha avuto il punteggio più alto di 0,784 F1 nel set di test.", 'kk': 'Бұл қағаз жүйенің және оның нәтижелерін егжей- тегжейі қарау береді. Бұл NLP4IF ортақ тапсырманың бөлігі болып, NAACL 2021 жылы COVID- 19 мәлімет деңгейінде қалаған тапсырманың бөлігі бол Бұл тапсырма бірнеше түрлі техникаларды қолданады. Біз төменгі тапсырма үшін дұрыс түзетілген мәтін түзету үлгілерін қолдандық. АРБЕРТ, МАРБЕРТ, АРБЕРТ, Араб АЛБЕРТ және Берт- негізгі араб араб қолданылды. Нәтижелеріне сәйкес, BERT- негізгі араб тізімінде ең жоғары 0, 784 F1 нәтижесі бар.', 'lt': 'This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021.  This task is accomplished using a variety of techniques.  We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand.  Buvo naudojami ARBERT, MARBERT, AraBERT, Arabų ALBERT ir BERT bazinis arabų. Remiantis rezultatais, BERT-base-arabic buvo didžiausias 0,784 F1 balas bandymų rinkinyje.', 'mk': 'Овој документ обезбедува детално преглед на системот и неговите резултати, кои беа произведени како дел од заедничката задача на НЛП4ИФ за борбата против КоВИД-19 Инфодемиќ на НААЦЛ 2021 година. Оваа задача е завршена со користење на различни техники. Користевме најсовремени модели за контекстуално претставување на текстот кои беа фино прилагодени за долната задача во рака. ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used.  Според резултатите, БЕРТ-база-арабиќ имаше највисока оценка од 0,784 Ф1 на тестот.', 'ms': 'This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021.  Tugas ini dilakukan menggunakan berbagai teknik. We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand.  ARBERT, MARBERT, AraBERT, Arab ALBERT dan BERT-base-arab digunakan. Menurut keputusan, BERT-base-arabic mempunyai skor 0.784 F1 tertinggi pada set ujian.', 'ml': 'ഈ പത്രത്തില്\u200d സിസ്റ്റത്തെയും അതിന്റെ ഫലങ്ങളെയും വിശദീകരിച്ചുകൊടുക്കുന്നു. നായാക്സില്\u200d 2021 യുദ്ധം പൊരുതുന്നതിന്റെ കോവിഡി-19 വിവരങ്ങള്\u200d നി വിവിധ സാങ്കേതികവിദ്യകള്\u200d ഉപയോഗിച്ച് ഈ ജോലി പൂര്\u200dത്തിയാക്കിയിരിക്കുന്നു. നമ്മള്\u200d ആലോചിക്കപ്പെട്ട ട ടെക്സ്റ്റ് പ്രതിനിധികളുടെ അവസ്ഥ ഉപയോഗിച്ചിരുന്നു. അത് താഴെ നദിയുടെ ജോലിക്കായി നല്ല ആര്\u200dബെര്\u200dട്ട്, മാര്\u200dബെര്\u200dട്ട്, അരാബെര്\u200dട്ട്, അറബി അല്\u200dബെര്\u200dട്ട്, ബെര്\u200dട്ട്-ബേസ്-അറബിക്ക് ഉപയോഗിച്ചു. According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.', 'mt': 'This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021.  Dan il-kompitu jitwettaq permezz ta’ varjetà ta’ tekniki. Aħna użajna mudelli ta’ rappreżentazzjoni tat-testi l-aktar avvanzati fil-kuntest li ġew aġġustati bir-reqqa għall-kompitu downstream li hemm. ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used.  Skont ir-riżultati, il-BERT-base-arabic kellu l-ogħla punteġġ ta’ 0.784 F1 fis-sett tat-test.', 'pl': 'Niniejszy artykuł zawiera szczegółowy przegląd systemu i jego wyników, które zostały opracowane w ramach wspólnego zadania NLP4IF w zakresie zwalczania COVID-19 Infodemic na NAACL 2021. Zadanie to jest realizowane przy użyciu różnych technik. Użyliśmy najnowocześniejszych kontekstualizowanych modeli reprezentacji tekstu, które zostały dostosowane do dalszego zadania. Zastosowano ARBERT, MARBERT, AraBERT, arabski ALBERT i BERT-bazowy arabski. Według wyników BERT-baza arabska miała najwyższy wynik 0.784 F1 na zestawie testowym.', 'ro': 'Această lucrare oferă o imagine de ansamblu detaliată a sistemului și a rezultatelor acestuia, care au fost produse în cadrul misiunii partajate NLP4IF privind combaterea informațiilor COVID-19 la NAACL 2021. Această sarcină se realizează folosind o varietate de tehnici. Am folosit modele de reprezentare a textului contextualizate de ultimă generație, care au fost reglate fin pentru activitatea din aval în mână. Au fost folosite ARBERT, MARBERT, AraBERT, arabă ALBERT și BERT-bază-arabă. Conform rezultatelor, BERT-base-arabic a avut cel mai mare scor F1 de 0,784 pe setul de test.', 'mn': 'Энэ цаас нь NAACL 2021 оны COVID-19 мэдээллийн эмч тэмцэх тухай NLP4IF хуваалцааны нэг хэсэг болсон системийн талаар нарийвчлалтай харагдаж байна. Энэ ажил олон технологи ашиглан бүтэн. Бид доорх үйл ажиллагаанд сайхан дүрслэгдсэн үлгэрийн төлөвлөгөө загварыг ашигласан. АРБЕРТ, МАРБЕРТ, ААБЕРТ, Араб АЛБЕРТ, БЕРТ-суурь Араб хэрэглэгдсэн. Үүний үр дүнд, БЕРТ-суурь Араб шалгалт дээр хамгийн өндөр 0,784 F1 оноо байсан.', 'no': 'Denne papiret gjev ei detaljert oversikt over systemet og resultatet, som ble produsert som del av NLP4IF-delt oppgåve om å kjempe med COVID-19-informasjon på NAACL 2021. Denne oppgåva er fullført med ein del teknikk. Vi brukte kontekstualiserte tekstrepresentasjonsmodular for state-of-the-art som vart fint oppsett for nedstrømmeoppgåva i hand. ArBERT, MARBERT, AraBERT, arabisk ALBERT og BERT- basearabisk vart brukt. Etter resultatet har BERT-basearabisk det høgste 0,784 F1- poeng på testsettet.', 'so': 'Warqaddan wuxuu ka helaa qoraal detailed oo ka sii jeeda nidaamka iyo resultiyadiisa, kaas oo loo sameeyay sida qayb ka mid ah shaqada la wadaajiyey NALP4IF oo la dagaallamay COVID-19 Infodemic at NAACL 2021. Shaqadan waxaa lagu dhameeyaa isticmaalka teknikado kala duduwan. Waxaynu isticmaalnay tusaalaha xarunta qoraalka la soo jeedo oo aad u samaysay shaqada hoose. ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used.  Sida uu fasaxu qabto, BERT-basec-arabic waxay lahaayeen score ugu sarreeya 0.784 F1 marka lagu sameeyo imtixaanka.', 'sv': 'Denna uppsats ger en detaljerad översikt över systemet och dess resultat, som togs fram som en del av NLP4IF Shared Task on Fighting the COVID-19 Infodemic vid NAACL 2021. Denna uppgift utförs med hjälp av en mängd olika tekniker. Vi använde state-of-the-art kontextualiserade textrepresentationsmodeller som finjusterades för den efterföljande uppgiften. ARBERT, MARBERT, AraBERT, arabiska ALBERT och BERT-basarabiska användes. Enligt resultaten hade BERT-bas-arabic den högsta 0,784 F1-poängen på testset.', 'ta': '@ info இந்த செயல் பல்வேறு தொழில்நுட்பங்களை பயன்படுத்தி முடிந்தது. நாங்கள் சிந்திக்கப்பட்ட உரை குறிப்பிடும் மாதிரிகளை பயன்படுத்தினோம் அது கீழே நீர் பணிக்கு நன்றாக முடிந்தது. அர்பெர்ட், மார்பெர்ட், அராபெர்ட், அரபி அல்பெர்ட் மற்றும் பெர்ட்- அடிப்படை அரபி பயன்படுத்தப்பட்டது. முடிவுகள் பிரெட்- அடிப்படை அரபிக் சோதனை அமைப்பில் அதிக 0. 784 F1 மதிப்பு இருந்தது.', 'ur': 'This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on fighting COVID-19 Infodemic at NAACL 2021. یہ کام مختلف تکنیک کے مطابق پورا ہوا ہے۔ ہم نے ایست-of-the-art contextualized text representation models used that were fine tuned for the downstream task in hand. آربرت، ماربرت، آربرت، عربی آلبرت اور برت-بن-عربی استعمال کیے گئے۔ نتائج کے مطابق، BERT-base-arabic کے پاس امتحان سٹ پر سب سے بالا 0.784 F1 اسکور تھا.', 'sr': 'Ovaj papir pruža detaljni pregled sistema i njegovih ishoda, koji su proizvedeni kao deo zajedničkog zadatka NLP4IF-a o borbi protiv COVID-19 informademije na NAACL 2021. Ovaj zadatak je postignut koristeći razne tehnike. Koristili smo modele predstavljanja teksta koji su ispravno ispravljeni za zadatak u ruci. Koristili su ARBERT, MARBERT, AraBERT, Arapski ALBERT i BERT-baza arapski. Prema rezultatima, BERT-baza-arapski je imao najviši 0,784 F1 rezultat na testu.', 'si': 'මේ පැත්තේ පද්ධතිය සහ ඒකේ ප්\u200dරතිචාරය ගැන විස්තර ප්\u200dරදේශයක් පෙනුම් කරනවා, ඒක NLP4IF සමාගත වැඩක් වලින් නිර්මාණය කරලා තියෙන්නේ NAACL 202 මේ වැඩක් විවිධ ප්\u200dරකාරයක් භාවිතා කරනවා. අපි පාවිච්චි විදිහට පරිස්සම් විදිහට පෙන්වන්න පෙන්වන්න පෙන්වන්න ප්\u200dරමාණයක් භාවිතා කරලා තියෙනවා. අර්බෙර්ට්, මාර්බෙර්ට්, අරාබෙර්ට්, අරාබික් ඇල්බෙර්ට් සහ බෙර්ට්-බේස්-අරාබික් භාවිතා කරලා ති පරීක්ෂණාවට අනුවෙන්, BERT-base-arabic එක්ක පරීක්ෂණා සෙට්ටුවේ උඩ 0,784 F1 ස්කෝර් තිබුනා.', 'vi': 'Tờ giấy này cung cấp một thông tin chi tiết về hệ thống và kết quả của nó, được sản xuất như một phần của Nhiệm vụ chia sẻ NLL4NNF về Chiến đấu với COVID-19 Infodemic tại NAACL 2021. Nhiệm vụ này được hoàn thành bằng nhiều kỹ thuật khác nhau. Chúng tôi đã sử dụng các mô hình văn bản hiện đại và hoàn chỉnh cho các nhiệm vụ xuôi dòng. ARBERT, MABERT, AraBERT, ALBERT Ả Rập và BERT cùng lớp vỏ Ả Rập. Theo kết quả, BERT-căn-Ả-rập đã có ghi số 0.784 F1 cao nhất trong tập thử nghiệm.', 'uz': "Bu qogʻoz NAACL 2021 yildagi COVID-19 maʼlumot bilan dirish uchun NLP4IF shartlangan vazifaning bir qismiga yaratiladi. Bu vazifa turli teknikalar yordamida tugatadi. Biz yordamchi matn taʼminlovchisi modellaridan foydalanamiz. Ushbu ishni qo'llab chiqish uchun juda yaxshi o'xshash bo'lgan. ARBERT, MARBERT, AraBERT, Arab ALBERT va BERT asosiy arabcha ishlatilgan. Natijalar davomida, BERT-asosiy arabda sinov satrida eng yuqori 0.784 F1 scori bor.", 'da': 'Dette dokument giver et detaljeret overblik over systemet og dets resultater, som blev produceret som en del af NLP4IF Shared Task on Fighting te COVID-19 Infodemic på NAACL 2021. Denne opgave udføres ved hjælp af en række teknikker. Vi brugte state-of-the-art kontekstualiserede tekstrepræsentationsmodeller, der blev finjusteret til downstream-opgaven i hånden. Der blev anvendt ARBERT, MARBERT, AraBERT, arabisk ALBERT og BERT-base-arabisk. Ifølge resultaterne havde BERT-base-arabic den højeste 0,784 F1 score på testsættet.', 'hr': 'Ovaj papir pruža detaljni pregled sustava i njenih ishoda, koji su proizvedeni kao dio zajedničkog zadatka NLP4IF-a o borbi protiv COVID-19 informademije na NAACL 2021. Ovaj zadatak se postigne koristeći razne tehnike. Koristili smo modele predstavljanja teksta koji su dobro određeni za nedavni zadatak u ruci. Koristili su ARBERT, MARBERT, AraBERT, Arapski ALBERT i BERT-baza arapski. Prema rezultatima, BERT-baza-arabički su imali najviši 0,784 F1 rezultat na testu.', 'nl': 'Dit document geeft een gedetailleerd overzicht van het systeem en de resultaten ervan, die zijn geproduceerd als onderdeel van de NLP4IF Shared Task on Fighting the COVID-19 Infodemic op NAACL 2021. Deze taak wordt uitgevoerd met behulp van een verscheidenheid van technieken. We gebruikten state-of-the-art contextualiseerde tekstrepresentatiemodellen die waren afgestemd op de downstream taak in de hand. ARBERT, MARBERT, AraBERT, Arabisch ALBERT en BERT-base-arabic werden gebruikt. Volgens de resultaten had BERT-base-arabic de hoogste 0.784 F1 score op de testset.', 'bg': 'Настоящата статия предоставя подробен преглед на системата и нейните резултати, които бяха изготвени като част от Споделената задача за борба с инфодемиката на НААКЛ 2021. Тази задача се изпълнява с помощта на различни техники. Използвахме най-съвременни контекстуализирани модели за представяне на текст, които бяха фино настроени за текущата задача надолу по веригата. Използвани са ARBERT, MARBERT, AraBERT, Arabic ALBERT и BERT-base-arabic. Според резултатите BERT-base-arabic е имал най-висок резултат 0.784 във Формула 1 в тестовия комплект.', 'de': 'Dieses Papier gibt einen detaillierten Überblick über das System und seine Ergebnisse, die im Rahmen der NLP4IF Shared Task on Fighting the COVID-19 Infodemic bei NAACL 2021 erstellt wurden. Diese Aufgabe wird mit einer Vielzahl von Techniken erfüllt. Wir verwendeten modernste kontextualisierte Textdarstellungsmodelle, die für die jeweilige nachgelagerte Aufgabe fein abgestimmt wurden. Es wurden ARBERT, MARBERT, AraBERT, Arabisch ALBERT und BERT-Basisarabic verwendet. Nach den Ergebnissen hatte BERT-base-arabic die höchste 0,784 F1 Punktzahl im Testset.', 'ko': '본고는 이 시스템과 그 성과를 상세히 요약하는데 이러한 성과는 2021년 NAACL에서 NLP4IF의 코로나 저항 정보 전파 공유 임무의 일부분이다.이 임무는 여러 가지 기술로 완성한 것이다.우리는 가장 선진적인 상하 문화 텍스트 표시 모델을 사용했는데 이런 모델은 수중의 하류 임무에 대해 미세하게 조정했다.ARBERT, MARBERT, AraBERT, Arabic ALBERT 및 BERT base Arabic을 사용합니다.시험 결과에 따르면 BERT base arabic은 시험집중 F1에서 0.784점으로 가장 높은 성적을 냈다.', 'fa': 'این کاغذ یک نظر جزئیات از سیستم و نتیجه\u200cاش را پیشنهاد می\u200cکند که بخشی از کار مشترک NLP4IF در مورد مبارزه با اطلاعات COVID-19 در NAACL 2021 تولید شده است. این کار با استفاده از تکنیک\u200cهای مختلف انجام می\u200cشود. ما از مدل نمایش\u200cنمایش\u200cهای متن محدوده\u200cی حالت هنر استفاده کردیم که برای کار پایین\u200cترین دستگیر شده\u200cاند. آربرت، ماربرت، آربرت، آلبرت عربی و برت-پایگاه عربی استفاده می\u200cکردند. بر اساس نتیجه\u200cها، BERT-base-arabic بالاترین نمونه\u200cهای 0.784 F1 در مجموعه آزمایش داشت.', 'sw': 'Gazeti hili linatoa mtazamo wa kina wa mfumo na matokeo yake, ambalo lilitengenezwa kama sehemu ya kazi ya NLP4IF inayoshirikisha kupigana na taarifa za COVID-19 huko NAACL 2021. Kazi hii imetimizwa kwa kutumia mbinu mbalimbali. We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand.  ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used.  Kwa mujibu wa matokeo hayo, Kiarabu mwenye asili ya BERT alikuwa na kiwango kikubwa cha 0.784 F1 kwenye seti ya jaribio.', 'af': "Hierdie papier verskaf 'n gedetale oorskou van die stelsel en sy uitgaande, wat geproduseer word as deel van die NLP4IF Gedeelde Opdrag op geveg van die COVID-19 Inligting by NAACL 2021. Hierdie taak is vervul deur 'n verskeie tekniks te gebruik. Ons gebruik state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand. ARBERT, MARBERT, AraBERT, Arabiese ALBERT en BERT-base-arabiese word gebruik. Volgens die resultate het BERT-base-arabic die hoogste 0,784 F1 telling op die toets stel gehad.", 'am': 'ይህ ፕሮግራም የኮVID-19 መረጃዎች በNAACL 2021 ላይ ለመዋጋት የNLP4IF የታሰረ ስራ ክፍል ሆኖ የተዘጋጀ የሲስተም እና ፍጻሜውን ያሳያል፡፡ ይሄ ስራው በተለያዩ ስልጣናዎች ተፈጸመ፡፡ የድምፅ አካባቢ ሥርዓት የተጠቃሚ የጽሑፍ መልዕክት አካባቢ እናደርጋለን፡፡ አርቢት፣ ማርብሬት፣ አርቢርት፣ ዐረብኛ ዓረባዊ ዓረባዊ According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.', 'hy': 'Այս փաստաթղթին պարունակում է մանրամասն համակարգի և դրա արդյունքների վերաբերյալ, որոնք արտադրվել են որպես NAACL 2021-ի համագործակցած ՆԼՊ4IF-ի համագործակցած հանձնարարության մաս COVID-19 Ինֆոդեմիկի պայքարելու համար: Այս խնդիրը կատարվում է տարբեր մեթոդներ օգտագործելով: Մենք օգտագործեցինք ամենաբարձր տեքստի ներկայացման մոդելներ, որոնք լավագույն կարգավորված էին ձեռքի ներքևի գործի համար: Օգտագործվեցին Արբերթը, Մարբերթը, Արաբերթը, Արաբերթը և Արաբերթը: Արդյունքների համաձայն, BER-հիմնական-արաբական ունի թեստերի համակարգում ամենաբարձր 0.784 F1 գնահատականը:', 'sq': 'Ky dokument ofron një përmbledhje të hollësishme të sistemit dhe rezultateve të tij, të cilat u prodhuan si pjesë e detyrës së përbashkët të NLP4IF për luftën kundër COVID-19 Infodemic në NAACL 2021. Kjo detyrë kryehet duke përdorur një shumëllojshmëri teknikash. Ne përdorëm modele të përfaqësimit të tekstit më të lartë të kontekstualizuar që ishin të rregulluar për detyrën poshtë në dorë. U përdorën ARBERT, MARBERT, AraBERT, Arabic ALBERT dhe BERT-base-arabic. Sipas rezultateve, BERT-base-arabic kishte rezultatin më të lartë 0.784 F1 në grupin e testit.', 'bn': 'এই পত্রিকাটি সিস্টেম এবং এর ফলাফলের বিস্তারিত পর্যবেক্ষণ প্রদান করেছে, যা নায়াকিল ২০১২-এ কোভিড-১৯ তথ্যের বিরুদ্ধে লড়াই করার জন্য এনএলপি৪আইফ বিভিন্ন প্রযুক্তি ব্যবহার করে এই কাজ সম্পূর্ণ হয়েছে। আমরা প্রতিযোগিতায় প্রতিনিধিত্বিত টেক্সট প্রতিনিধিত্ব মডেল ব্যবহার করেছিলাম যেগুলো হাতে নিচের নদীর কাজের জন্য ভা ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used.  According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.', 'id': 'Kertas ini memberikan pandangan rendah-rendah sistem dan hasilnya, yang diproduksi sebagai bagian dari NLP4IF Shared Task on Fighting the COVID-19 Infodemic di NAACL 2021. This task is accomplished using a variety of techniques.  Kami menggunakan model persembahan teks kontekstualisasi yang terbaik yang disesuaikan untuk tugas turun di tangan. ARBERT, MARBERT, AraBERT, Arab ALBERT dan BERT-base-arab digunakan. Menurut hasilnya, BERT-base-arabic memiliki skor F1 tertinggi 0,784 pada set tes.', 'az': "Bu kağıt, NAACL 2021'də COVID-19 Infodemic müharibəsində olan NLP4IF paylaşılmış işin bir parças ı olaraq ürəklənmiş sistemin və sonuçlarının detalı görünüşünü verir. Bu iş müxtəlif tekniklərdən istifadə edilir. Biz müxtəlif məlumat göstəricisi modellərini istifadə etdik ki, düşük işin əlində düzgün düzəltdi. ARBERT, MARBERT, AraBERT, ərəbcə ALBERT və BERT-base-arabic işlədilər. Sonuçlarına görə, BERT-base-arabic test qutusunda ən yüksək 0,784 F1 nöqtəsi vardır.", 'bs': 'Ovaj papir pruža detaljni pregled sustava i njenih ishoda, koji su proizvedeni kao dio zajedničkog zadatka NLP4IF-a o borbi protiv COVID-19 informademije na NAACL 2021. Ovaj zadatak se postigne koristeći razne tehnike. Koristili smo modele predstavljanja teksta koji su ispravno napravljeni za zadatak u ruci. Koristili su ARBERT, MARBERT, AraBERT, Arapski ALBERT i BERT-baza arapski. Prema rezultatima, BERT-baza-arabički su imali najviši 0,784 F1 rezultat na testu.', 'tr': "Bu kagyz sistemiň we netijeleriniň detayly görnüşi we NLP4IF'iň COVID-19 maglumaty tarapyndan çykyp bolan işiň bir parçasy bolup görünýär. Bu zady birnäçe tekniklerden ullanýar. Biz suçsuz durum-of-the-art contextualized metin tanyşma modellerini elimizde düzeltmek üçin saýlandyrdyk. ARBERT, MARBERT,AraBERT, Arabça ALBERT we BERT-basesi arabça ulanyldylar. Netijenlere görä, BERT-basesi arabça test düzeninde iň yüksek 0,784 F1 sany bardy.", 'et': 'Käesolevas dokumendis antakse üksikasjalik ülevaade süsteemist ja selle tulemustest, mis on koostatud NAACL 2021. aastal COVID-19-vastase võitluse ühise ülesande raames. See ülesanne on täidetud erinevate tehnikate abil. Kasutasime kaasaegseid kontekstualiseeritud teksti esitamise mudeleid, mis olid täpselt häälestatud käesoleva ülesande jaoks. Kasutati ARBERT, MARBERT, AraBERT, araabia ALBERT ja BERT-baasraabia keelt. Tulemuste kohaselt oli BERT-baasraablane suurim 0,784 F1 skoor testikomplektis.', 'cs': 'Tento článek poskytuje podrobný přehled systému a jeho výsledků, které byly vytvořeny v rámci sdíleného úkolu NLP4IF v boji proti COVID-19 Infodemic na NAACL 2021. Tento úkol je splněn pomocí různých technik. Použili jsme nejmodernější kontextualizované modely reprezentace textu, které byly vyladěny pro následné úkoly. Byly použity ARBERT, MARBERT, AraBERT, arabské ALBERT a BERT-base-arabic. Podle výsledků měl BERT-base-arabic nejvyšší skóre 0,784 F1 na testovací sadě.', 'fi': 'Tämä artikkeli tarjoaa yksityiskohtaisen yleiskatsauksen järjestelmästä ja sen tuloksista, jotka on tuotettu osana NLP4IF Shared Task on Fighting the COVID-19 Infodemic -ohjelmaa NAACL 2021:ssä. Tämä tehtävä suoritetaan käyttämällä erilaisia tekniikoita. Käytimme viimeisintä tekniikkaa hyödyntäviä kontekstualisoituja tekstiesitysmalleja, jotka hiottiin kulloinkin käsiteltävää loppupään tehtävää varten. Käytettiin ARBERT, MARBERT, AraBERT, arabialainen ALBERT ja BERT-pohja-arabia. Tulosten mukaan BERT-base-arabic sai testisarjan korkeimmat 0,784 F1-pisteet.', 'ca': 'Aquest paper proporciona una visió detallada del sistema i dels seus resultats, que van ser produïts com part de la tasca compartida de NLP4IF sobre la lluita contra la COVID-19 Infodemic a NAACL 2021. This task is accomplished using a variety of techniques.  Vam utilitzar models contextualitzats de representació de text actualitzats que estaven ajustats per a la tasca downstream a mà. Es van utilitzar ARBERT, MARBERT, AraBERT, ALBERT àrab i BERT-base-àrab. According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.', 'jv': 'Awak iki ngewehke akeh banter nggawe sistem lan barang nggawe sawini, sing ngejaraké akèh NLP4IB ngejaraké Mesang Habangsane kanggo nggunggo CVD-19 Infodrom nang Nara ATKL 2020. Sampeyan iki lak wis rampung akeh pisan teknik. Ngawe nambah state-of-the-arts contextual text representation modeler ARBERT, MARBERT, araBERT, ARBERT lan BERT-basic-arab iki dipunanggé. Sumangga punika, BERT-basic-arab sing paling dhuwur 0.584 F1 sing paling dhuwur kéné tentang.', 'ha': 'Wannan takardar ta bãyar da wani surmisi na kasar da fassararsa, wanda aka buɗe shi kamar rabon aiki na NLP4IF Shared on yin yãƙi da COCOCOV-19 Maɓalli a NAacL 2021. @ info: whatsthis Mun yi amfani da halin-the-art-traditionalised misãlai masu wakilishi matsayin da aka samun-tuned wa aikin da ke ƙarami. QUnicodeControlCharacterMenu Li gori da matsalan, BERT-base-arabu na da kyauta mafi girma wa 0.784 F1 kan tsarin jarraba.', 'sk': 'Ta prispevek vsebuje podroben pregled sistema in njegovih rezultatov, ki so bili pripravljeni v okviru skupne naloge NLP4IF za boj proti COVID-19 Infodemik na NAACL 2021. Ta naloga se izvaja z uporabo različnih tehnik. Uporabili smo najsodobnejše kontekstualizirane modele predstavitve besedila, ki so bili natančno prilagojeni za nadaljnje opravilo. Uporabljeni so bili ARBERT, MARBERT, AraBERT, arabski ALBERT in BERT-bazni arabski. Po rezultatih rezultatov je BERT-base-arabic imel najvišji 0,784 F1 rezultat na testnem nizu.', 'he': 'העבודה הזו מספקת תצוגה מפורטת של המערכת והתוצאות שלה, שנוצרו כחלק מהמשימה המשותפת של NLP4IF על הילחם באינפודמיקה COVID-19 ב NAACL 2021. המשימה הזאת מושלמת באמצעות מגוון טכניקות. השתמשנו בדוגמנים של מייצג טקסט מוקדם במצב הקונקסט שנמצאים למשימה המאוחרת ביד. השתמשו בארברט, מרברט, ארברט, אלברט ערבי וברט-בסיס-ערבי. לפי התוצאות, לברט-בסיס-ערבית היה נקודת F1 הגבוהה ביותר בסט המבחנים.', 'bo': 'ཤོག བྱ་འགུལ་འདི་ལ་རྒྱུས་ལྡན་རྩོལ་བ་སྤྱོད་མི་འདུག ང་ཚོས་རང་ཉིད་ཀྱི་གནས་སྟངས་བཀོད་པའི་མིང་རྣམས་ཡོད་པའི་གནས་སྟངས་བཀོད་པའི་མིང་ཚིག་ལག་ལེན་འཐབ་བྱེད་ཀྱི་ཡོད། ARBERT, MARBERT, AraBERT, Arabic ALBERT ve BERT-base-arabic kullanıldılar. གྲུབ་འབྲས་ཐོག་ལས་ BERT-base-arabic ཡིག་གཟུགས་ཀྱི་ཚད་སྒྲིག་ཚད་ཐོག་མའི་མཐོ་ཚད་0.784 F1་ཡོད།'}
