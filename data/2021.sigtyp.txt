{'en': 'OTEANN : Estimating the Transparency of Orthographies with an  Artificial Neural Network OTEANN : Estimating the Transparency of Orthographies with an Artificial Neural Network', 'ar': 'OTEANN: تقدير شفافية الهجاء باستخدام شبكة عصبية اصطناعية', 'pt': 'OTEANN: Estimando a transparência de ortografias com uma rede neural artificial', 'fr': "OTEANN\xa0: Estimation de la transparence des orthographes à l'aide d'un réseau neuronal artificiel", 'es': 'OTEANN: Estimación de la transparencia de las ortografías con una red neuronal artificial', 'ja': 'OTEANN ：人工ニューラルネットワークによる正書法の透明性の推定', 'zh': 'OTEANN:用人工神经网络度正字法透明度', 'ru': 'OTEANN: Оценка прозрачности ортографий с искусственной нейронной сетью', 'hi': 'OTEANN: एक कृत्रिम तंत्रिका नेटवर्क के साथ ऑर्थोग्राफी की पारदर्शिता का अनुमान लगाना', 'ga': 'OTEANN: Trédhearcacht na Ortagrafaíochta a Mheas le Líonra Néaróg Saorga', 'ka': 'OTEANN: არტიფიკალური ნეიროლური ქსელის სამყაროება', 'kk': 'БАЙТАН: Ортографиялардың мөлдірлігін мақсатты невралдық желімен байланыстыру', 'el': 'ΟΤΕΑΝ: Εκτίμηση της Διαφάνειας των Ορθογραφιών με Τεχνητό Νευρικό Δίκτυο', 'lt': 'OTEANN: Ortografijų skaidrumo su dirbtiniu neurologiniu tinklu vertinimas', 'hu': 'OTEANN: Az ortográfia átláthatóságának becslése mesterséges ideghálózattal', 'it': 'OTEANN: Stimare la trasparenza delle ortografie con una rete neurale artificiale', 'ms': 'OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network', 'mt': 'OTEANN: Stima tat-Trasparenza tal-Ortografiji b’Netwerk Newrali Artifikali', 'ml': 'ഓട്ടെയാന്\u200d: ഒരു ആര്\u200dട്ടിഫിക്കല്\u200d നെയുറല്\u200d നെറ്റ്\u200cവര്\u200dക്ക് കൊണ്ട് ഓര്\u200dട്ടോഗ്രാഫികളുടെ സ്വതന്ത്ര്യം എണ്ണ', 'no': 'Constellation name (optional)', 'mk': 'ОТЕН: Проценка на транспарентноста на правописите со уметничка неурална мрежа', 'mn': 'ОТЕАН: Урлагийн сэтгэл зүй сүлжээтэй Orthographies-ын тодорхойлолт', 'sr': 'Procjenjivanje transparentnosti pravoslovne mreže', 'si': 'OTEANN: ක්\u200dරියාත්මක නිර්මාණික ජාලය සමග පාර්ශණාවත්වය', 'pl': 'OTEANN: Ocena przejrzystości ortografii za pomocą sztucznej sieci neuronowej', 'ro': 'OTEANN: Estimarea transparenței ortografiilor cu o rețea neurală artificială', 'so': 'OTEANN: Qiimeynta daaranka Ortoographics with a shabakadda farshaxanka', 'sv': 'OTEANN: Uppskattning av öppenheten hos ortografi med ett artificiellt neuralt nätverk', 'ta': 'OTEANN: ஆர்டிகல் நெயுரல் வலைப்பின்னல்', 'ur': 'اوٹینٹن: آرٹوگرافی کی روشنی کا ارتفاع کرنا ایک مصنوعی نیورل نیورک کے ساتھ', 'vi': 'OTEANNN: ước tính trong suốt các loại ngôn ngữ với một mạng thần kinh nhân tạo', 'uz': 'OTEANN: Aniqlik Neural tarmoqni tasdiqlash', 'bg': 'ОТЕАН: Оценка на прозрачността на ортографиите с изкуствена неврална мрежа', 'da': 'OTEANN: Vurdering af gennemsigtigheden af ortografier med et kunstigt neuralt netværk', 'hr': 'OTEANN: Procjenjivanje transparentnosti pravosuđa s umjetnom neuronskom mrežom', 'nl': 'OTEANN: De transparantie van orthografieën schatten met een kunstmatig neuraal netwerk', 'id': 'OTEANN: Menghargai Transparensi Ortografi dengan Rangkaian Neural Artificial', 'ko': 'OTEANN: 인공 신경 네트워크로 정자법의 투명도를 추정하다', 'tr': 'OTEANN: Bir Yap Näral Ağ ile Ortograflaryň Durumluluğunu Taýşartma', 'de': 'OTEANN: Abschätzung der Transparenz von Orthographien mit einem künstlichen neuronalen Netzwerk', 'fa': 'تحقیقات Transparency of Orthographies with an artificial Neural Network', 'sw': 'OTEANN: Kuhitimisha Uwazi wa Orthography kwa Mtandao wa Kisanaa Neural', 'sq': 'OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network', 'am': 'ኦቴANN: የኦሮቶግራፊዎች ነፃነት በዐርስተኛ ኔural መረብ በመቁጠር', 'hy': 'ՕՏԵՆ՝ Արտագործական նյարդային ցանցի օգնությամբ արտահայտված նյարդագրությունների թափանցիկության գնահատումը', 'az': 'OTEANN: Ortografiya Şəfəqiliyini Yaxşı Nöral Ağı ilə təşkil etmək', 'af': 'Constellation name (optional)', 'bn': 'অটেন: একটি শিল্প নিউরাল নেটওয়ার্ক দিয়ে অর্থোগ্রাফিকের স্বচ্ছতা গণনা করা হচ্ছে', 'bs': 'Procjenjivanje transparentnosti pravoslovne mreže s umjetnim neurom', 'ca': 'OTEANN: Estima la transparència de les ortografies amb una xarxa neuronal artificial', 'fi': 'OTEANN: Ortografian läpinäkyvyyden arviointi keinotekoisella hermoverkostolla', 'cs': 'OTEANN: Odhad transparentnosti ortografií s umělou neuronovou sítí', 'et': 'OTEANN: Ortograafiate läbipaistvuse hindamine kunstliku neurovõrgu abil', 'jv': 'text', 'ha': 'KCharselect unicode block name', 'he': 'אוטיאן: הערכה של התבררות של אורתוגרפיות עם רשת נוירולית מלאכותית', 'sk': 'OTEANN: Ocena preglednosti ortografij z umetnim živčnim omrežjem', 'bo': 'OTEANN: རྒྱུན་འབྲེལ་བའི་སྐོར་དང་ཐོག་ལས་སྒྱུར་བའི་ཡིག་རྒྱུན་ལྡན་'}
{'en': 'To transcribe  spoken language  to  written medium , most  alphabets  enable an unambiguous sound-to-letter rule. However, some  writing systems  have distanced themselves from this simple concept and little work exists in  Natural Language Processing (NLP)  on measuring such distance. In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. The scores obtained on 17  orthographies  were in line with the estimations of other studies. Interestingly, the  model  also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.', 'pt': 'Para transcrever a linguagem falada para o meio escrito, a maioria dos alfabetos permite uma regra inequívoca de som para letra. No entanto, alguns sistemas de escrita se distanciaram desse conceito simples e existem poucos trabalhos em Processamento de Linguagem Natural (PLN) para medir tal distância. Neste estudo, utilizamos um modelo de Rede Neural Artificial (RNA) para avaliar a transparência entre palavras escritas e sua pronúncia, daí o nome Orthographic Transparency Estimation with an ANN (OTEANN). Com base em conjuntos de dados derivados de dicionários da Wikimedia, treinamos e testamos esse modelo para pontuar a porcentagem de previsões falsas em tarefas de tradução de fonema para grafema e grafema para fonema. Os escores obtidos em 17 ortografias estavam de acordo com as estimativas de outros estudos. Curiosamente, o modelo também forneceu informações sobre erros típicos cometidos por alunos que consideram apenas a regra fonêmica na leitura e na escrita.', 'es': 'Para transcribir el lenguaje hablado a un medio escrito, la mayoría de los alfabetos permiten una regla inequívoca de sonido a letra. Sin embargo, algunos sistemas de escritura se han distanciado de este simple concepto y hay poco trabajo en el procesamiento del lenguaje natural (NLP) para medir esa distancia. En este estudio, utilizamos un modelo de Red Neural Artificial (ANN) para evaluar la transparencia entre las palabras escritas y su pronunciación, de ahí su nombre Orthographic Transparency Estimation with an ANN (OTEANN). Basándonos en conjuntos de datos derivados de diccionarios de Wikimedia, entrenamos y probamos este modelo para puntuar el porcentaje de predicciones falsas en las tareas de traducción de fonema a grafema y grafema a fonema. Las puntuaciones obtenidas en 17 ortografías estaban en línea con las estimaciones de otros estudios. Curiosamente, el modelo también proporcionó información sobre los errores típicos cometidos por los estudiantes que solo consideran la regla fonémica en la lectura y la escritura.', 'ar': 'لنسخ اللغة المنطوقة إلى وسيط مكتوب ، تتيح معظم الحروف الهجائية قاعدة صوت إلى حرف لا لبس فيها. ومع ذلك ، نأت بعض أنظمة الكتابة بنفسها عن هذا المفهوم البسيط ولا يوجد سوى القليل من العمل في معالجة اللغة الطبيعية (NLP) لقياس هذه المسافة. في هذه الدراسة ، نستخدم نموذج الشبكة العصبية الاصطناعية (ANN) لتقييم الشفافية بين الكلمات المكتوبة ونطقها ، ومن هنا جاء اسمها تقدير الشفافية الهجائية باستخدام ANN (OTEANN). استنادًا إلى مجموعات البيانات المستمدة من قواميس ويكيميديا ، قمنا بتدريب هذا النموذج واختبرناه لتسجيل النسبة المئوية للتنبؤات الخاطئة في مهام الترجمة من الصوت إلى الحروف و grapheme إلى الصوت. كانت الدرجات التي تم الحصول عليها على 17 من قواعد الإملاء متوافقة مع تقديرات الدراسات الأخرى. ومن المثير للاهتمام ، أن النموذج قدم أيضًا نظرة ثاقبة للأخطاء النموذجية التي يرتكبها المتعلمون الذين لا يأخذون سوى قاعدة الصوتيات في القراءة والكتابة.', 'fr': "Pour transcrire la langue parlée sur un support écrit, la plupart des alphabets autorisent une règle du son à la lettre sans ambiguïté. Cependant, certains systèmes d'écriture se sont éloignés de ce concept simple et peu de travail existe dans le traitement du langage naturel (NLP) sur la mesure de cette distance. Dans cette étude, nous utilisons un modèle de réseau neuronal artificiel (ANN) pour évaluer la transparence entre les mots écrits et leur prononciation, d'où son nom Orthographic Transparency Estimation with an ANN (OTEANN). Sur la base d'ensembles de données dérivés des dictionnaires Wikimedia, nous avons formé et testé ce modèle pour évaluer le pourcentage de fausses prédictions dans les tâches de traduction phonème en graphème et graphème en phonème. Les scores obtenus sur 17 orthographes étaient conformes aux estimations d'autres études. Fait intéressant, le modèle a également permis de mieux comprendre les erreurs typiques commises par les apprenants qui ne tiennent compte que de la règle phonémique en lecture et en écriture.", 'zh': '为将口语转录为书媒,大抵字母表皆持明发音至字母法。 然书统已远其概,自然语言处(NLP)中殆无测者。 以此论之,吾以人工神经网络(ANN)质书面单词与其发音之透明度,故谓之用ANN之正交透明度度(OTEANN)。 基于维基媒体词典派生之数集,吾等练习而试之,以音素至字素及音素译误占者百分比评分之。 于17次正字法上所得分数与他计同。 有趣者,模形供其典刑,学者惟思读作音素法。', 'hi': 'बोली जाने वाली भाषा को लिखित माध्यम में ट्रांसक्राइब करने के लिए, अधिकांश वर्णमाला एक स्पष्ट ध्वनि-से-अक्षर नियम को सक्षम करती है। हालांकि, कुछ लेखन प्रणालियों ने खुद को इस सरल अवधारणा से दूर कर लिया है और इस तरह की दूरी को मापने पर प्राकृतिक भाषा प्रसंस्करण (एनएलपी) में बहुत कम काम मौजूद है। इस अध्ययन में, हम लिखित शब्दों और उनके उच्चारण के बीच पारदर्शिता का मूल्यांकन करने के लिए एक कृत्रिम तंत्रिका नेटवर्क (एएनएन) मॉडल का उपयोग करते हैं, इसलिए इसका नाम एएनएन (ओटीईएएनएन) के साथ ऑर्थोग्राफिक ट्रांसपेरेंसी अनुमान है। विकिमीडिया शब्दकोशों से व्युत्पन्न डेटासेट के आधार पर, हमने फोनमे-टू-ग्राफेम और ग्राफीम-टू-फोनेम अनुवाद कार्यों में झूठी भविष्यवाणियों के प्रतिशत को स्कोर करने के लिए इस मॉडल को प्रशिक्षित और परीक्षण किया। 17 ऑर्थोग्राफी पर प्राप्त स्कोर अन्य अध्ययनों के अनुमानों के अनुरूप थे। दिलचस्प बात यह है कि मॉडल ने शिक्षार्थियों द्वारा की गई विशिष्ट गलतियों में अंतर्दृष्टि भी प्रदान की, जो केवल पढ़ने और लिखने में फोनमिक नियम पर विचार करते हैं।', 'ja': '口語を書かれた媒体に文字起こしするには、ほとんどのアルファベットが明確なサウンドツーレタールールを有効にします。しかし、いくつかの書き込みシステムは、この単純な概念から距離を置いており、そのような距離を測定するための自然言語処理（ NLP ）にはほとんど作業が存在しない。この研究では、人工ニューラルネットワーク（ ANN ）モデルを使用して、書かれた単語とその発音との間の透明性を評価します。したがって、ANN （ OTEANN ）を使用したオルソグラフィー透明性推定という名前を使用します。ウィキメディア辞書から派生したデータセットに基づいて、私たちはこのモデルを訓練し、テストして、音素間翻訳タスクと音素間翻訳タスクにおける誤った予測の割合を採点しました。17個のオーソグラフィーで得られたスコアは、他の研究の推定値と一致していた。興味深いことに、このモデルはまた、読み書きにおける音韻規則のみを考慮する学習者が犯した典型的な間違いについての洞察を提供した。', 'ru': 'Чтобы транскрибировать разговорный язык на письменный носитель, большинство алфавитов включают однозначное правило «звук в букву». Тем не менее, некоторые системы письма дистанцировались от этой простой концепции, и в Natural Language Processing (NLP) существует мало работы по измерению такого расстояния. В этом исследовании мы используем модель искусственной нейронной сети (ИНС) для оценки прозрачности между написанными словами и их произношением, отсюда и ее название Orthographic Transparency Estimation with an ANN (OTEANN). Основываясь на наборах данных, полученных из словарей Викимедиа, мы обучили и протестировали эту модель, чтобы оценить процент ложных прогнозов в задачах перевода с фонемы на графему и с графемы на фонему. Оценки, полученные на 17 ортографиях, соответствовали оценкам других исследований. Интересно, что эта модель также дала представление о типичных ошибках, допущенных учащимися, которые учитывают фонематическое правило только при чтении и написании.', 'ga': 'Chun teanga labhartha a thras-scríobh go meán scríofa, cumasaíonn formhór na n-aibítrí riail fuaime-go-litir gan athbhrí. Mar sin féin, tá roinnt córais scríbhneoireachta tar éis iad féin a scaradh ón gcoincheap simplí seo agus is beag obair atá ar bun in Natural Language Processing (NLP) ar an bhfad sin a thomhas. Sa staidéar seo, bainimid úsáid as samhail Líonra Néarach Saorga (ANN) chun an trédhearcacht idir focail scríofa agus a bhfuaimniú a mheas, agus mar sin a ainm Orthographic Transparency Meastachán le ANN (OTEANN). Bunaithe ar thacair sonraí a fuarthas ó fhoclóirí Wikimedia, rinneamar an múnla seo a thraenáil agus a thástáil chun céatadán na dtuartha bréagacha a scóráil i dtascanna aistriúcháin fóinéime-go-graifim agus graifim-go-fóinéim. Bhí na scóir a fuarthas ar 17 ortagrafaíocht ag teacht le meastacháin staidéir eile. Díol spéise é gur thug an tsamhail léargas freisin ar ghnáthbhotúin a dhéanann foghlaimeoirí nach ndéanann ach an riail fhóinéimeach a mheas sa léitheoireacht agus sa scríbhneoireacht.', 'hu': 'A beszélt nyelv írásos médiumra történő átírásához a legtöbb ábécé egyértelmű hang-betű szabályt tesz lehetővé. Egyes írási rendszerek azonban eltávolodtak ettől az egyszerű koncepciótól, és kevés munka létezik a Natural Language Processing (NLP) területén az ilyen távolság mérésére. Ebben a tanulmányban egy Artificial Neural Network (ANN) modellt használunk az írott szavak és kiejtésük közötti átláthatóság értékelésére, innen annak neve Orthographic Transparency Estimation with an ANN (OTEANN). A Wikimédia szótárakból származó adatkészletek alapján kiképeztük és teszteltük ezt a modellt, hogy pontosítsuk a hamis előrejelzések százalékos arányát a fonema-graféma és graféma-phonéma fordítási feladatokban. A 17 ortográfián kapott pontszámok összhangban voltak más vizsgálatok becsléseivel. Érdekes módon a modell betekintést nyújtott azokba a tipikus hibákba is, akik csak olvasás és írás során veszik figyelembe a fonemikus szabályt.', 'ka': 'საუკეთესო საუკეთესო სიტყვის წერტილი მედიაში, უფრო მეტი ალტაბეტები შეუძლებელია წერტილი სიტყვის შესაძლებელია. მაგრამ, ზოგიერთი წერილის სისტემები ამ საუკეთესო კონცექტიდან გადარჩენა და პატარა სამუშაო სამუშაო ენის პროცესში (NLP) იქნება ამ განტოლებას ამ კვლევაში ჩვენ გამოყენებთ არტიფიკალური ნეიროლური ქსელი (ANN) მოდელს, რომელიც წერილი სიტყვების და მათი გამოსახულების შორის წინასწორება, ამიტომ მისი სახელი Orthographic Transparency Estimation with an N (OTEANN). ვიკიმედია დიქტორიებიდან მომხმარებული მონაცემების დაბაზებით, ჩვენ ამ მოდელის შესწავლობა და ტესტირება, რომ ფონემე-სა-გრაფიმე და გრაფიმე-სა-ფონემე განმხმარების პროცენტის გადაწყ 17 ორტოგრაფიაში მიღებული მონაცემები იყო სხვა სწავლებების განსაზღვრებით. თნრვპვჟნჲ ვ, მჲევლყრ ჟყღჲ ოპვეოჲლჲზთ რთონთრვ დპვქკთ, ოპაგვნთ ჲრ ნასფთრვლთრვ, კჲთრჲ ჟამჲ პაჱდლვზეარ ტჲნვმთფვრჲ ოპაგთლჲ ოპაგთლჲ გ ფვრვნვ თ', 'el': 'Για να μεταγραφεί η προφορική γλώσσα σε γραπτό μέσο, τα περισσότερα αλφάβητα επιτρέπουν έναν ξεκάθαρο κανόνα ήχου-γράμματος. Ωστόσο, ορισμένα συστήματα γραφής έχουν αποστασιοποιηθεί από αυτή την απλή έννοια και υπάρχει μικρή δουλειά στην επεξεργασία φυσικής γλώσσας (NLP) για τη μέτρηση αυτής της απόστασης. Στην παρούσα μελέτη, χρησιμοποιούμε ένα μοντέλο τεχνητού νευρωνικού δικτύου (ANN) για την αξιολόγηση της διαφάνειας μεταξύ γραπτών λέξεων και προφοράς τους, εξ ου και το όνομά του Ορθογραφική Εκτίμηση Διαφάνειας με ANN (OTEANN). Βασιζόμενοι σε σύνολα δεδομένων που προέρχονται από λεξικά εκπαιδεύσαμε και δοκιμάσαμε αυτό το μοντέλο για να βαθμολογήσουμε το ποσοστό των ψευδών προβλέψεων στις εργασίες μετάφρασης φωνήματος-σε-γραφεμέ και γραφεμέ-σε-φωνεμέ. Οι βαθμολογίες των 17ων ορθογραφικών ήταν σύμφωνες με τις εκτιμήσεις άλλων μελετών. Ενδιαφέρον είναι ότι το μοντέλο παρείχε επίσης γνώση των τυπικών λαθών που έγιναν από μαθητές που λαμβάνουν υπόψη μόνο τον φωνητικό κανόνα στην ανάγνωση και τη γραφή.', 'lt': 'Norint transkripti kalbą rašytinėje laikmenoje, dauguma raidžių leidžia vienareikšmišką garso–raidės taisyklę. Tačiau kai kurios rašymo sistemos atsiskyrė nuo šios paprastos koncepcijos ir gamtinės kalbos apdorojimo procese (NLP) nedaug dirba matuojant tokį atstumą. Šiame tyrime naudojame dirbtinio neurologinio tinklo (ANN) model į rašytinių žodžių ir jų išraiškos skaidrumui įvertinti, taigi jo pavadinimas Ortografinis skaidrumo vertinimas su ANN (OTEANN). Remiantis Wikimedia žodynų duomenų rinkiniais, mes apmokėme ir išbandėme šį model į, kad įvertintume klaidingų prognozių procentinę dalį fonemo-grafimo ir grafimo-fonemo vertimo užduotyse. 17 ortografijų rezultatai atitiko kitų tyrimų vertinimus. Įdomu, kad modelis taip pat parodė tipines klaidas, kurias padarė mokiniai, kurie skaitydami ir rašydami atsižvelgia tik į foneminę taisyklę.', 'kk': 'Тілді жазылған медиаға аудару үшін әріптердің көпшілігі дыбыс мен әріптердің ережесін рұқсат ету үшін. Бірақ кейбір жазу жүйелері осы қарапайым концепциясынан қашыққан жұмыс істейді. Бұл қашықтығын өлшеу үшін Nature Language Processing (NLP) дегенде кішкентай жұмыс бар. Бұл зерттеулерде біз жазылған сөздер мен олардың сөздерінің мөлдірлігін бағалау үшін Бұлдық нейралық желі (ANN) үлгісін қолданамыз, сондықтан оның атауы ANN (OTEANN) дегенмен ортографикалық мөлдірлік мөлдір Викимедиа сөздіктерінен келтірілген деректер жиындарына негізделген, біз бұл үлгісін оқыдық және тексердік, фонемде-графимде және графимде-фонемде аударатын тапсырмалардың пайызын жарамсыз алдын- ала алдын 17 ортографикалық сандары басқа зерттеулердің бағалауына сәйкес келді. Бұл үлгі оқу және жазу үшін тек фонемикалық ережелерді оқу және жазуға қарайтын оқытушылардың көпшілікті қателеріне түсіндіреді.', 'it': 'Per trascrivere la lingua parlata su supporto scritto, la maggior parte degli alfabeti abilita una regola inequivocabile suono-lettera. Tuttavia, alcuni sistemi di scrittura si sono allontanati da questo semplice concetto e poco lavoro esiste nel Natural Language Processing (NLP) per misurare tale distanza. In questo studio, utilizziamo un modello di Rete Neurale Artificiale (ANN) per valutare la trasparenza tra le parole scritte e la loro pronuncia, da qui il suo nome Orthographic Transparency Estimation with an ANN (OTEANN). Basandoci su set di dati derivati dai dizionari Wikimedia, abbiamo addestrato e testato questo modello per segnare la percentuale di false previsioni nelle attività di traduzione fonema-grafema e grafema-fonema. I punteggi ottenuti su 17 ortografie erano in linea con le stime di altri studi. È interessante notare che il modello ha fornito anche informazioni sugli errori tipici commessi dagli studenti che considerano la regola fonemica solo nella lettura e nella scrittura.', 'mk': 'За да се транспира говорен јазик на пишан медиум, повеќето алфабити овозможуваат едноставно правило од звук до буква. Сепак, некои системи за пишување се оддалечија од овој едноставен концепт и малку работа постои во процесот на природен јазик (НЛП) за мерење на ваква оддалеченост. In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN).  Базирани на податоци од вечниците на Викимедија, го трениравме и тестиравме овој модел за да го оценуваме процентот на лажни предвидувања во задачите на превод од фонет до графем и графем до фонет. Резултатите добиени на 17 ортографии беа во согласност со проценките на другите студии. Интересно е, моделот, исто така, обезбеди сфаќање за типичните грешки направени од учениците кои го сметаат само фонемичкото правило во читањето и пишувањето.', 'mt': 'Biex jiġi trasskritt il-lingwa mitkellma għal mezz bil-miktub, il-biċċa l-kbira tal-alfabeti jippermettu regola bla ambigwità bejn il-ħoss u l-ittra. Madankollu, xi sistemi tal-kitba distanzaw ruħhom minn dan il-kunċett sempliċi u ftit xogħol jeżisti fl-Ipproċessar tal-Lingwi Naturali (NLP) dwar il-kejl ta’ tali distanza. F’dan l-istudju, aħna nużaw mudell tan-Netwerk Newrali Artifikali (ANN) biex jevalwaw it-trasparenza bejn il-kliem bil-miktub u l-pronunzja tagħhom, u għalhekk isimhom Stima tat-Trasparenza Ortografika b’ANN (OTEANN). Abbażi ta’ settijiet ta’ dejta derivati mid-dikjararji tal-Wikimedia, aħna mħarrġin u ttestjajna dan il-mudell biex inqabblu l-perċentwal ta’ tbassir falz f’kompiti ta’ traduzzjoni minn fonem għal grafem u grafem għal fonem. Il-punteġġi miksuba fuq 17-il ortografija kienu konformi mal-istimi ta’ studji oħra. Interessanti, il-mudell ipprovda wkoll għarfien dwar żbalji tipiċi magħmula minn studenti li jikkunsidraw biss ir-regola fonemika fil-qari u l-kitba.', 'ms': 'Untuk menyalin bahasa bercakap ke medium tertulis, kebanyakan alfabet membolehkan peraturan bunyi-ke-huruf yang tidak jelas. Namun, beberapa sistem menulis telah menjauhkan diri dari konsep sederhana ini dan sedikit kerja wujud dalam Proses Bahasa Alami (NLP) untuk mengukur jarak tersebut. Dalam kajian ini, kami menggunakan model Rangkaian Neural Artificial (ANN) untuk menilai kelutsinaran antara kata-kata tertulis dan pernyataan mereka, oleh itu namanya Estimation Kelutsinaran Ortografik dengan ANN (OTEANN). Berdasarkan set data yang berasal dari kamus Wikimedia, kami melatih dan menguji model ini untuk mencetak peratus ramalan palsu dalam tugas terjemahan phoneme-to-grapheme dan grapheme-to-phoneme. Skor yang diperoleh pada 17 ortografi adalah sesuai dengan perhitungan kajian lain. Menarik, model juga memberikan pengetahuan tentang kesilapan biasa yang dilakukan oleh pelajar yang hanya mempertimbangkan peraturan fonemik dalam membaca dan menulis.', 'pl': 'Aby przepisać język mówiony na nośnik pisany, większość alfabetów umożliwia jednoznaczną regułę dźwięku-litery. Jednak niektóre systemy pisania zdystansowały się od tej prostej koncepcji i w Natural Language Processing (NLP) istnieje niewiele pracy nad pomiarem takiej odległości. W niniejszym opracowaniu wykorzystujemy model sztucznej sieci neuronowej (ANN), aby ocenić przejrzystość między słowami pisanymi a ich wymową, stąd jego nazwa Orthografic Transparency Estimation with an ANN (OTEANN). Na podstawie zbiorów danych pochodzących ze słowników Wikimedia, przeszkololiśmy i przetestowaliśmy ten model, aby ocenić procent fałszywych przewidywań w zadaniach tłumaczenia fonem-na-grafem i grafem-na-fonem. Wyniki uzyskane na 17-tej ortografii były zgodne z szacunkami innych badań. Co ciekawe, model dał również wgląd w typowe błędy popełniane przez uczniów, którzy uwzględniają tylko regułę fonemiczną w czytaniu i pisaniu.', 'no': 'For å overskriva talespråk til skriven medium, slår dei fleste alfabetene på ein ugjennomsiktig lyd- til- bokstavregl. Nokre skrivesystemer har imidlertid distancert seg frå denne enkle konsepten, og liten arbeid finst i naturleg språk-handtering (NLP) ved å måla slike avstanden. I denne studien bruker vi eit teknisk neuralnettverk (ANN) modell for å evaluera gjennomsikten mellom skrivne ord og uttalen, slik at namnet sitt Ortografisk gjennomsiktig vurdering med ein ANN (OTEANN). Basert på datasett fra Wikimedia- ordbokstavar, vi trenga og testa denne modellen for å scorera prosent av falske forhåndsvising i phoneme- to- grapheme og grapheme- to- phoneme- omsetjingsprogrammer. Poeng som er fått på 17 ortografikk er i line med estimeren av andre studier. Interesant er at modellen også gjev innsikt i typiske feil som lærarar gjer, som berre ser på phonemiske regelen i lesing og skriving.', 'mn': 'Холбоотой хэл бичигдсэн медиа руу шилжүүлэхийн тулд ихэнх алфабритууд дуу болон захиа руу шилжүүлэх боломжтой болдог. Гэхдээ зарим бичих системүүд энэ энгийн ойлголтын тухай өөрсдийгөө холдог. Байгалийн хэл процесс (NLP) дээр ийм зай хэмжээнд жижиг ажил байдаг. Энэ судалгаанд бид уран бүтээлч мэдрэлийн сүлжээ (ANN) загварыг ашиглаж бичсэн үг болон түүний хэлэлцүүлэх хоорондын тодорхой байдлыг үнэлэх зорилго ашигладаг. Иймээс үүний нэр Orthographic Transparency Estimation with an ANN (OTEANN). Викимедиа өгөгдлийн санаас гарсан өгөгдлийн сануудын үндсэн учраас, бид энэ загварыг phoneme-to-grapheme, grapheme-to-phoneme хөрөнгө оруулах үйлдлийн хувь хувь хугацааны таамаглалтын хувьд шалгаж үзсэн. 17 ортографик дээр авсан тоонууд бусад судалгаануудын тооцоололтой байлаа. Хамгийн сонирхолтой нь энэ загвар нь уншиж, бичиж байхдаа зөвхөн фонемик дүрэм гэж боддог сурагчид зөвхөн энгийн алдаа гаргасан.', 'sr': 'Da bi prepisala govorni jezik pisanom mediju, većina alfabeta omogućava nepromišeno pravilo zvuka do pisma. Međutim, neki pisaćni sistemi su se udaljili od ovog jednostavnog koncepta i mali rad postoji u procesu prirodnog jezika (NLP) za mjerenje takve udaljenosti. U ovom ispitivanju koristimo umjetnu neuronsku mrežu (ANN) model kako bi procenili transparentnost između pisanih reči i njihovih izjava, stoga se zove pravografska procjena transparentnosti sa ANN (OTEANN). Na osnovu podataka iz Wikimedia diktorija, obučili smo i testirali ovaj model kako bi postigli procenat lažnih predviđanja u funkcijama prevođenja telefona-to-grafima i grafima-to-foneme. Rezultati koji su dobili na 17 ortografija bili su u skladu sa procjenama drugih ispitivanja. Zanimljivo je da je model takođe predstavio uvid u tipične greške koje su naučili koji smatraju samo telefonskim pravilima čitanjem i pisanjem.', 'ml': 'സംസാരിക്കപ്പെട്ട ഭാഷ എഴുതുന്നതിനായി എഴുതുന്നതിനായി മിക്കവാറും ആല്\u200dഫാബെറ്റുകള്\u200dക്ക് ഒരു ശബ്ദം പ്രാവര്\u200d എന്നാലും ചില എഴുതുന്ന സിസ്റ്റം ഈ സാധാരണ ആശയത്തില്\u200d നിന്നും അകന്നുപോയിരിക്കുന്നു. സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയയില്\u200d ചില In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN).  വിക്കിമീഡിയയുടെ നിഘണ്ടികങ്ങളില്\u200d നിന്നുള്ള ഡാറ്റാസറ്റുകള്\u200d അടിസ്ഥാനത്തില്\u200d ഞങ്ങള്\u200d ഈ മോഡലിനെ പരിശീലിപ്പിച്ചു പരിശോധിച്ചു. ഫോണിമോ മുതല്\u200d ഗ്ര 17 ഓര്\u200dടോഗ്രാഫികളില്\u200d കിട്ടിയ സ്കോര്\u200dകള്\u200d മറ്റു പഠനത്തിന്റെ വിചാരണ കൊണ്ടായിരുന്നു. ചിലപ്പോള്\u200d മോഡല്\u200d സാധാരണ തെറ്റുകള്\u200d ചെയ്തു കൊണ്ടിരിക്കുന്നു. വായിക്കുകയും എഴുതുകയും ചെയ്യുന്ന ഫോണിഫിമിക്ക്', 'so': 'Si loo qoro luqada lagu hadlo oo loogu qoro qoraal dhexe, kuwa badan alphabetka waxay qaban karaan sharci aan cod lahayn oo qoraal ah. Si kastaba ha ahaatee nidaamka qoraalka qaarkood waxay ka fogaadeen fikradan fudud, shaqo yarna waxay ku jiraan baaritaanka afka asalka ah (NLP) qiyaastiisa meeshaas oo kale. Waxbarashadan waxaynu isticmaalnaa qaab shabakadda neurada ee farshaxanka ah (ANN) si aan u qiimeyno muuqashada u dhexeeya hadalka qoran iyo ogeysiiska, sababtaas darteed magaceeda waxaa lagu magacaabaa xisaabta qaabilaadda u dhexeeya ANN (OTEANN). Sida lagu saleyn karo sawirada oo ka soo baxay dictionaries Wikimedia, waxan ku tababarinnay oo tijaabinnay noocyadan si aan u koobanno boqolkiiba wax khiyaano ah oo ku saabsan safaarada telefoonka-to-grapheme iyo safem-to-phonetka. Jardiinooyinka 17-bandhigyada lagu helay waxaa lagu soo bandhigay qiimeynta waxbarasho kale. Waxaa xittaa dhaqdhaqaaqi, tusaale ahaan waxaa sidoo kale ka dhigay aragtida khaladda caadiga ah ee ay ardayda sameeyeen oo kaliya ka fiirsada sharciga telefoonka ee akhriska iyo qoraalka.', 'si': 'භාෂාව ලියපු මාධ්\u200dයමයෙන් ලියපු භාෂාව ලැබීමට, ගොඩක් ඇල්ෆේබ්ට් අවශ්\u200dය ශබ්ද නීතියක් සක්\u200dරිය ක නමුත්, සමහර ලියණ පද්ධතියක් මේ සාමාන්\u200dය අදහස් වලින් ඔවුන්ව දුර්වල් කරලා තියෙනවා, සමාන්\u200dය භාෂාව ප්\u200dරකාර ( මේ පරීක්ෂණයේදී, අපි ප්\u200dරවෘත්තිය නිර්මාණ ජාලය (ANN) මොඩේලයක් භාවිත කරනවා ලියපු වචන සහ ඔවුන්ගේ ප්\u200dරවෘත්තිය අතර පරීක්ෂණය සඳහා පාරදේ විකිමිඩියාව භාවිතයෙන් පිළිගත්ත දත්ත සේට් වලින්, අපි මේ මොඩේලය පරීක්ෂා කරලා පරීක්ෂා කරලා ෆෝනේම් ට්-ග්\u200dරාෆේම් වලින් ග්\u200d අනිත් අභ්\u200dයාසයේ විශ්ලේෂණ 17 වලින් ගත්ත ප්\u200dරමාණයක් තියෙනවා. ප්\u200dරශ්නයෙන්ම, මොඩේල් එක්ක ප්\u200dරශ්නයක් තියෙනවා කියවන්න හා ලියවන්න සාමාන්\u200dය වැරදි විදියට ප්\u200dරශ්නයක් කරනවා', 'ro': 'Pentru a transcrie limba vorbită pe mediul scris, majoritatea alfabetelor permit o regulă sunet-literă fără echivoc. Cu toate acestea, unele sisteme de scriere s-au distanțat de acest concept simplu și există puține lucrări în procesarea limbajului natural (PNL) pentru măsurarea acestei distanțe. În acest studiu, folosim un model de Rețea Neurală Artificială (ANN) pentru a evalua transparența dintre cuvintele scrise și pronunția lor, de unde numele său Orthographic Transparency Estimation with an ANN (OTEANN). Pe baza seturilor de date derivate din dicționarele Wikimedia, am instruit și testat acest model pentru a scora procentul de predicții false în sarcinile de traducere fonem-graf și graf-la-fonem. Scorurile obţinute pe 17 ortografii au fost în concordanţă cu estimările altor studii. Interesant, modelul a oferit, de asemenea, o perspectivă asupra greșelilor tipice făcute de elevii care iau în considerare regula fonemică doar în citire și scriere.', 'ur': 'لکھی ہوئی میڈی پر کلام کی زبان لکھنے کے لئے اکثر الفبائٹ ایک غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance. اس مطالعہ میں ہم ایک مطالعہ نیورل نیورک (ANN) موڈل استعمال کرتے ہیں تاکہ لکھی ہوئی کلمات اور ان کی تعلیم کے درمیان پورشیدگی کا مطالعہ کریں، اسی وجہ سے اس کا نام Orthographic Transparency Estimation ANN (OTEANN) کے ساتھ ہے. ویکیمیڈیا ڈیٹ سٹ پر بنیاد ہے جو ویکیمیڈیا دیکتوریوں سے پائی جاتی ہے، ہم نے اس موڈل کو تدریس کیا اور آزمائش کی تاکہ phoneme-to-grapheme اور grapheme-to-phoneme ترجمہ کے تابعوں میں غلط پیش بینی کا فیصد فیصلہ کریں. 17 اورٹوگرافی پر حاصل کئے گئے اسکور دوسرے مطالعہ کے مطالعہ سے ملے گئے۔ علاقمند ہے کہ مدل نے بھی معلوم ہوا کہ سیکھنے والوں نے صرف پڑھنے اور لکھنے کے ذریعہ فونیمیک قانون کو سمجھ لیا ہے۔', 'ta': 'பேச்ச மொழியை நடுத்தரமாக எழுத, பெரும்பாலான ஆல்பாபெட்கள் ஒரு தேவைப்படாத ஒலி எழுத்து விதியை செயல்படுத்து. ஆனால், சில எழுதும் அமைப்புகள் இந்த சுலபமான கருத்திலிருந்து தொலைவில் இருந்து தூரமாக இருக்கின்றன மற்றும் சிறிய வேலை இயல்பான இந்த ஆராய்ச்சியில், நாம் ஒரு சிறந்த நெயுரல் வலைப்பின்னல் மாதிரியை பயன்படுத்தி எழுதப்பட்ட வார்த்தைகளுக்கும் அவர்கள் வெளியீட்டுக்கும் இடையேயும் மதிப்ப விகிமிடியா அகராதிகளிலிருந்து வரையப்பட்ட தகவல் அமைப்புகளை அடிப்படையில், நாங்கள் இந்த மாதிரியை பயிற்சி சோதித்து போலி முதல் வரைபடம் மற்றும் வரைப்படம் ம 17 புள்ளிகளில் கிடைக்கப்பட்ட மதிப்புகள் மற்ற ஆய்வுகளின் மதிப்புகளுடன் வரிசையில் உள்ளது. சுவாரசியமாக, மாதிரி படித்துக் கொண்டு எழுதும் தொலைபேசி விதிமுறையை மட்டும் கருதுகிறார்கள்.', 'sv': 'För att transkribera talat språk till skrivet medium möjliggör de flesta alfabeten en entydig ljud-till-bokstavsregel. Vissa skrivsystem har dock distanserat sig från detta enkla koncept och lite arbete finns i Natural Language Processing (NLP) med att mäta ett sådant avstånd. I denna studie använder vi en Artificial Neural Network (ANN) modell för att utvärdera transparensen mellan skrivna ord och deras uttal, därav dess namn Orthographic Transparency Estimation with an ANN (OTEANN). Baserat på datauppsättningar som härrör från Wikimedias ordböcker, tränade och testade vi denna modell för att få poäng på procentandelen falska förutsägelser i fonem-till-grafem och grafem-till-fonem översättningsuppgifter. Poängen från 17 ortografier överensstämde med uppskattningarna från andra studier. Intressant nog gav modellen också insikt i typiska misstag som begåtts av elever som endast beaktar fonemisk regel i läsning och skrivning.', 'uz': "Koʻpchilik alphabetlar yozib qoʻllanilmaydi. However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance.  Bu tadqida, biz yozilgan so'zlar va tahrirlarining orasidagi shaffoflikni qiymatish uchun Artifitikal Neural Tarmoqni (ANN) modeldan foydalanamiz, shunday qilib uning nomini OTEANN (OTEANN) bilan ajratish uchun. Wikimediya lugʻatlaridan yaratilgan maʼlumotlar satrlari asosida, biz bu modelni o'rganish va foydalanuvchi va grafik- to-phone tarjima vazifalarining foiz foydalanuvchisining foiz foydalanuvchisining foiz foiz foydalanuvchisining foizligini qidirish uchun foydalanamiz. 17 ortografiklarda olingan scorlar boshqa o'qituvchilarning qiymatlari bilan birlashgan. Shunday qiziqarli, model o'quvchilar o'quvchi va yozishni faqat o'qish va o'rganish qoidasini o'rganadigan xatolarga ko'rinishini yaratadi.", 'vi': 'Để chép ngôn ngữ nói sang ký tự, hầu hết các chữ cái đều cho phép một nguyên tắc rõ ràng. Tuy nhiên, một số hệ thống viết lách đã tránh xa khỏi khái niệm đơn giản này và có rất ít tác dụng trong Quá trình hóa ngôn ngữ tự nhiên (NLP) về việc đo khoảng cách. Trong nghiên cứu này, chúng tôi sử dụng một mô hình thần kinh nhân tạo (ANN) để đánh giá sự trong suốt giữa chữ viết và phát âm của nó, do đó tên nó là Sơ tán trong suốt trong suốt với một con ANT (OTEAM). Dựa trên các dữ liệu từ các từ điển WikiLchí, chúng tôi đã đào tạo và thử nghiệm mẫu này để ghi số tiên đoán sai trong các công việc dịch ngữ âm và cần thiết ghép niên. Số điểm được ghi trên cắt thống 17 trùng với ước tính của những nghiên cứu khác. Thú vị đấy, kiểu mẫu cũng cho thấy những sai lầm điển hình do học giả mắc phải, người chỉ biết đọc và viết bằng ngữ pháp.', 'bg': 'За да се транскрибира говорим език в писмен носител, повечето азбуки позволяват недвусмислено правило звук към буква. Въпреки това, някои системи за писане са се отдалечили от тази проста концепция и в обработката на естествения език съществува малко работа за измерване на такова разстояние. В това проучване използваме модел на изкуствена неврална мрежа (АНН), за да оценим прозрачността между написаните думи и произношението им, откъдето идва и името му Ортографска прозрачност с АНН (АНН). Въз основа на набори от данни, получени от речници на Уикимедия, ние обучихме и тествахме този модел, за да оценим процента на фалшивите прогнози в задачите за превод на фонема-графема и графема-фонема. Резултатите, получени на 17 ортографии, са в съответствие с оценките на други проучвания. Интересното е, че моделът предоставя и представа за типичните грешки, допуснати от обучаемите, които разглеждат само фонемичното правило в четенето и писането.', 'nl': 'Om gesproken taal te transcriberen naar geschreven medium, maken de meeste alfabeten een ondubbelzinnige klank-letterregel mogelijk. Sommige schrijfsystemen hebben echter afstand genomen van dit eenvoudige concept en er is weinig werk in Natural Language Processing (NLP) om dergelijke afstand te meten. In deze studie gebruiken we een Artificial Neural Network (ANN) model om de transparantie tussen geschreven woorden en hun uitspraak te evalueren, vandaar de naam Orthographic Transparency Estimation with an ANN (OTEANN). Op basis van datasets afgeleid van Wikimedia woordenboeken hebben we dit model getraind en getest om het percentage valse voorspellingen te scoren in foneem-naar-grafeem en grafeem-naar-foneem vertaaltaken. De scores verkregen op 17-orthografieën waren in overeenstemming met de schattingen van andere studies. Interessant genoeg gaf het model ook inzicht in typische fouten gemaakt door leerlingen die alleen rekening houden met de fonemische regel bij lezen en schrijven.', 'da': 'For at transkribe talt sprog til skrevet medium, de fleste alfabeter muliggør en utvetydig lyd-til-bogstav regel. Nogle skrivesystemer har imidlertid taget afstand fra dette enkle koncept, og der findes ikke meget arbejde i Natural Language Processing (NLP) på at måle en sådan afstand. I dette studie bruger vi en kunstig neural netværk (ANN) model til at vurdere gennemsigtigheden mellem skrevne ord og deres udtale, heraf navnet Orthographic Transparency Estimation with an ANN (OTEANN). Baseret på datasæt afledt fra Wikimedia ordbøger, trænede og testede vi denne model til at score procentdelen af falske forudsigelser i fonem-til-grafem og grafem-til-fonem oversættelsesopgaver. Resultaterne fra 17 ortografier var i overensstemmelse med skønnene fra andre undersøgelser. Interessant nok gav modellen også indsigt i typiske fejl begået af elever, der kun overvejer den fonemiske regel i læsning og skrivning.', 'hr': 'Za prepisanje govornog jezika pisanom mediju, većina alfabeta omogućava nepromišeno pravilo zvuka do pisma. Međutim, neki pisaćni sustavi su se udaljili od ovog jednostavnog koncepta i mali rad postoji u procesu prirodnog jezika (NLP) o mjerenju takve udaljenosti. U ovom ispitivanju koristimo umjetnu neuronsku mrežu (ANN) model kako bi procijenili transparentnost između pisanih riječi i njihovih proglašavanja, zbog čega se zove pravografska procjena transparentnosti s ANN (OTEANN). Na temelju podataka iz Wikimedijskih diktorija, obučavali smo i testirali ovaj model kako bi postigli procentualno lažnih predviđanja u zadatkima prevoda telefoneme-to-grapheme i grapheme-to-phoneme. Rezultati dobiveni na 17 ortografija bili su u skladu s procjenama drugih ispitivanja. Zanimljivo, model je također pružio uvid u tipične greške učenika koji smatraju samo telefonskim pravilima čitanjem i pisanjem.', 'id': 'Untuk transkrip bahasa berbicara ke media tertulis, kebanyakan alfabet memungkinkan aturan suara-ke-huruf yang tidak jelas. Namun, beberapa sistem menulis telah menjauh diri dari konsep sederhana ini dan sedikit pekerjaan ada dalam Proses Bahasa Alami (NLP) untuk mengukur jarak tersebut. Dalam penelitian ini, kami menggunakan model jaringan saraf seniman (ANN) untuk mengevaluasi transparensi antara kata-kata tertulis dan pernyataan mereka, sehingga namanya Orthographic Transparency Estimation dengan ANN (OTEANN). Berdasarkan dataset dari kamus Wikimedia, kami melatih dan menguji model ini untuk mencetak persentase prediksi palsu dalam tugas terjemahan phoneme-to-grapheme dan grapheme-to-phoneme. Skor yang diperoleh pada 17 ortografi adalah sesuai dengan perhitungan studi lain. Menarik, model juga memberikan pengetahuan tentang kesalahan tipis yang dibuat oleh para pelajar yang hanya mempertimbangkan aturan fonemik dalam membaca dan menulis.', 'ko': '구어를 서면어로 번역하기 위해 대부분의 자모표는 명확한 음자모 변환 규칙을 지지한다.그러나 일부 쓰기 시스템은 이 간단한 개념에서 벗어났고 자연언어처리(NLP)에는 이런 거리를 측정하는 작업이 거의 없다.이 연구에서 우리는 단어를 쓰는 것과 발음 사이의 투명도를 평가하기 위해 인공신경망(ANN) 모델을 사용하기 때문에 ANN 정교투명도 평가(OTEANN)라고 불린다.위키 미디어 사전에서 나온 데이터 집합을 바탕으로 우리는 이 모델에 대해 훈련과 테스트를 실시하여 음소에서 자형과 자형에서 음소 번역 임무에 이르기까지 잘못된 예측의 백분율을 평가했다.17가지 정자법의 득점은 다른 연구의 예측과 일치한다.흥미로운 것은 이 모델은 학습자가 읽기와 쓰기에서 음위 규칙만 고려하는 전형적인 오류에 대한 통찰도 제공한다.', 'de': 'Um gesprochene Sprache in geschriebene Medien zu übertragen, ermöglichen die meisten Alphabete eine eindeutige Ton-zu-Buchstaben-Regel. Einige Schreibsysteme haben sich jedoch von diesem einfachen Konzept distanziert und es gibt wenig Arbeit in Natural Language Processing (NLP) an der Messung solcher Distanzen. In dieser Studie verwenden wir ein Artificial Neural Network (ANN)-Modell, um die Transparenz zwischen geschriebenen Wörtern und deren Aussprache zu bewerten, daher der Name Orthographic Transparency Estimation with an ANN (OTEANN). Basierend auf Datensätzen aus Wikimedia Wörterbüchern haben wir dieses Modell trainiert und getestet, um den Prozentsatz falscher Vorhersagen in Phonem-zu-Graphem- und Graphem-zu-Phonem-Übersetzungsaufgaben zu bewerten. Die Ergebnisse der 17-Orthographien entsprachen den Schätzungen anderer Studien. Interessanterweise gab das Modell auch Einblick in typische Fehler von Lernenden, die nur die phonemische Regel beim Lesen und Schreiben berücksichtigen.', 'fa': 'برای ترجمه زبان صحبت به رسانه نوشته، بیشتر الفبا قانون صدا به نامه نامه\u200cای را اجازه می\u200cدهند. با این حال، برخی سیستم نوشتن خود را از این مفهوم ساده دور کرده اند و کار کوچک در پردازش زبان طبیعی (NLP) در اندازه اندازه این فاصله وجود دارد. در این مطالعه، ما از یک شبکه مصنوعی مصنوعی (ANN) استفاده می\u200cکنیم تا شفاعت بین کلمات نوشته و تعریف آنها را ارزیابی کنیم، بنابراین اسمش ارزیابی شفاعت متروکز با یک ANN (OTEANN). بر اساس مجموعه\u200cهای داده\u200cها از لغو\u200cهای ویکیمیدی، ما این مدل را آموزش دادیم و آزمایش کردیم تا درصد پیش\u200cبینی\u200cهای غلط در کار\u200cهای ترجمه\u200cهای phoneme-to-grapheme و grapheme-to-phoneme را ثبت دهیم. نمونه\u200cهای ۱۷ ورتوگرافی به خط با ارزیابی تحقیقات دیگر بود. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.', 'sw': 'Kuandika lugha inayozungumzwa kwa ajili ya kuandika katikati ya kati, alfabu wengi huwezesha utawala wa sauti na barua zisizo na maana. Hata hivyo, baadhi ya mifumo ya kuandika imejiepusha mbali na dhana hii rahisi na kazi ndogo imekuwepo katika mchakato wa lugha ya asili (NLP) kwa kiasi kikubwa cha upasuaji. Katika utafiti huu, tunatumia muundo wa Mtandao wa Kisanaa wa Neural (ANN) ili kutathmini uwazi kati ya maneno yaliyoandikwa na utangazaji wao, na kwa hiyo jina lake la Hesabu ya Uwazi wa Kifaragha kwa ANN (OTEANN). Kutokana na seti za data zinazotoka kwenye madikteta ya Wikimedia, tulifundisha na kujaribu mtindo huu ili kuweka hisia ya utabiri wa uongo katika kazi za kutafsiri simu na picha za simu. Takwimu zilizopatikana kwenye orodha 17 zilikuwa zimekuwa zikifanana na kadiri ya tafiti nyingine. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.', 'af': "Om gespreek taal na skryf medium te transkripteer, die meeste alphabete aktiveer 'n onbepaalde klank- na- letter reël. Maar sommige skryfstelsels het hulleself afgelei van hierdie eenvoudige konsepte en klein werk bestaan in Natuurlike Taal Prosessering (NLP) op die maating van sodanige afstand. In hierdie studie gebruik ons 'n Kunstige Neurale Netwerk (ANN) model om die deursigtigheid tussen skryfe woorde en hulle uitspreiding te evalueer, daarom sy naam Ortografiese Transparency Estimation met 'n ANN (OTEAN). Basis op datastelle afgeleide van Wikimedia woordeboekvorms, het ons hierdie model opgelei en toets om die persentasie van valse voorskou te tel in foneme-to-grapheme en grapheme-to-phoneme vertalingstaak. Die aantal wat op 17 ortografie ontvang is, was in lyn met die aantal van ander studie. Interesante, die model het ook insig verskaf in tipiese foute gemaak deur leerders wat slegs die fonemiese reël in lees en skryf beskou.", 'sq': 'Për të transkriptuar gjuhën e folur në medium të shkruar, shumica e alfabetëve mundësojnë një rregull të qartë nga tingulli në letër. Megjithatë, disa sisteme shkrimi kanë distancuar veten nga ky koncept i thjeshtë dhe pak punë ekziston në Procesimin e Gjuhave Natyrore (NLP) mbi matjen e një distance të tillë. Në këtë studim, ne përdorim një model të Rrjetit Neural Artificial (ANN) për të vlerësuar transparencën midis fjalëve të shkruara dhe shprehjes së tyre, kështu që emri i saj është Vlerësimi i Transparencës Ortografike me një ANN (OTEANN). Bazuar në grupet e të dhënave të nxjerra nga fjalorët e Wikimedias, ne e trajnuam dhe testuam këtë model për të shënuar përqindjen e parashikimeve të rreme në detyrat e përkthimit telefonik-në-grafik dhe grafik-në-fonim. Rezultatet e fituara në 17 ortografi ishin në përputhje me vlerësimet e studimeve të tjera. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.', 'am': 'የተናገረውን ቋንቋ ለመጽሐፍ በመካከለኛ ላይ ለመጻፍ፣ አብዛኞቹ አልፋቤቶች የድምፅ-ለደብዳቤ ሥርዓት ማድረግ ይችላል፡፡ ነገር ግን አንዳንዶች የጽሕፈት ስርዓቶች ከዚህ ቀላል አካሄድ ራሳቸውን ራቀው እና ጥቂት ሥራ በናብሬካዊ ቋንቋ ፕሮግራም (NLP) እንደዚህ ርቀት በመለካት ነው፡፡ በዚህ ትምህርት ውስጥ በጽሑፍ ቃላት እና በንግግራቸው መካከል ያለውን ግልፅ እናስተውል ዘንድ የዐርቶግራፊ ነፃነት መረብ (ANN) ሞዴል እንጠይቃለን፡፡ Wikimedia መዝገብ ያሉትን ዳታተሮች በመሠረት ላይ፣ ይህንን ሞዴል በፎልክ-ወደ-grapheme-ወደ-ፎፎኒሜ ትርጉም ስራዎችን የሐሰት ትንቢት በመቶ ለመቀነስ እና ለመፈትነው ሞክረናል፡፡ የ17 የኦሮሮግራፊ ደረጃዎች ሌሎችን ትምህርት ማድረግ እንደተደረገ ይደረጋሉ፡፡ በአጠቃሚ፣ ሞዴል ደግሞ የፎፎፎኒክ ሥርዓት በመነበብ እና በመጽሐፍ ብቻ የሚያስተውሉ ተማሪዎቹ የተደረጉትን ስህተት ያሳየዋል፡፡', 'hy': "Գրված միջոցով հաղորդակցվելու համար բառացի մեծ մասը հնարավորություն է տալիս անբացահայտ ձայնի-տառի կանոն: Այնուամենայնիվ, որոշ գրողական համակարգեր հեռու են մնացել այս պարզ գաղափարից, և շատ քիչ աշխատանք կա Բնական լեզվի մշակույթի (ՆԼՊ) միջոցով այս հեռավորության չափման համար: Այս ուսումնասիրության ընթացքում մենք օգտագործում ենք Արվեստական Նյարդային ցանցի (ԱՆՆ) մոդել, որպեսզի գնահատենք գրված բառերի և նրանց արտահայտության միջև թափանցիկությունը, այսինքն' դրա անունը Օրթոգրական թափանցիկության գնահատում է ԱՆ-ի (ՕՏԵՆ)  Հաշվի առնելով Վիքիմեդիայի բառարաններից ստացված տվյալների համակարգերից, մենք ուսուցանեցինք և փորձեցինք այս մոդելը, որպեսզի ստանանք կեղծ կանխատեսումների տոկոսը հեռախոսային գրաֆեմի և գրաֆեմի-հեռախոսային թարգմանման գործերում: 17 օրտոգրաֆիայում ստացված գնահատականները համապատասխանում էին այլ ուսումնասիրությունների գնահատականներին: Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.", 'bs': 'Da bi prepisala govorni jezik pisanom mediju, većina alfabeta omogućava nepromišeno pravilo zvuka do pisma. Međutim, neki pisaćni sistemi su se udaljili od ovog jednostavnog koncepta i mali rad postoji u procesu prirodnog jezika (NLP) o mjerenju takve udaljenosti. U ovom ispitivanju koristimo umjetnu neuronsku mrežu (ANN) model kako bi procijenili transparentnost između pisanih riječi i njihovih proglašavanja, stoga se zove pravografska procjena transparentnosti s ANN (OTEANN). Na temelju podataka iz Wikimedijskih diktorija, obučili smo i testirali ovaj model kako bi postigli procenat lažnih predviđanja u funkcijama prevoda telefoneme-to-grafime i grafima-to-foneme. Rezultati dobiveni na 17 ortografija bili su u skladu s procjenama drugih ispitivanja. Zanimljivo, model je također pružio uvid u tipične greške koje učnici čine, koji smatraju samo telefonskim pravilima čitanjem i pisanjem.', 'ca': "Per transcriure la llengua parlada a un mitjà escrit, la majoria d'alfabets permeten una regla senzilla de so a lletra. However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance.  En aquest estudi, utilitzem un model de Rede Neural Artificial (ANN) per avaluar la transparència entre paraules escrites i la seva pronunciació, per tant el seu nom Estimat de Transparencia Ortogràfica amb un ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks.  Les puntuacions obtenides en 17 ortografies estaven en línia amb les estimacions d'altres estudis. Interessant, el model també va proporcionar una visió dels errors típics cometits pels alumnes que només consideran la regla fònèmica en llegir i escriure.", 'tr': 'Gürleýän dili ýazylýan orta faýla ýazmak üçin köp alfabetler ses-täze bir hatda mümkin däldir. Ýöne käbir ýazma sistemalary bu basit düşünmeden uzaklaşdyrylýar we tebigy dil işlemesinde kiçi işi bar. Bu aramda, biz ýazylýan sözleriň we olaryň aýdyşynyň arasynda ýazylşyklygyny deňlemek üçin bir Yap Näral Network (ANN) nusgasyny ulanýarys, şonuň üçin adynyň düzgün derejesi ANN (OTEANN) bilen tapylýar. Wikimedýän sözlüklerden çykan veri sanlaryna daýanýar, biz bu nusgany foneme-to-grafime we grafime-to-foneme terjime täbliklerinden ýalňyş öngörümlerniň ýüzüni gollaşdyrmak üçin bilip bardyk. 17 ortografyda alan sanlary başga aramalaryň takmynylygy bilen çykypdyr. Gyzykly bolsa, nusga okuw we ýazmak diňe fonemik düzgüni pikir eden öwrenmenler tarapyndan adatça ýalňyşlyklara üýtgedi.', 'cs': 'Chcete-li přepisovat mluvený jazyk na psané médium, většina abeced umožňuje jednoznačné pravidlo zvuku k písmenu. Nicméně, některé psací systémy se od tohoto jednoduchého konceptu distancovaly a v Natural Language Processing (NLP) existuje málo práce na měření takové vzdálenosti. V této studii používáme model umělé neuronové sítě (ANN) k vyhodnocení transparentnosti mezi psanými slovy a jejich výslovností, odtud jeho název Orthografický odhad transparentnosti s ANN (OTEANN). Na základě datových sad odvozených ze slovníků Wikimedia jsme tento model trénovali a testovali tak, abychom hodnotili procento falešných predikcí v úlohách překladu fonému na grafém a grafém na foném. Skóre získané na sedmnácti ortografiích byly v souladu s odhady jiných studií. Zajímavé je, že model také poskytl pohled na typické chyby studentů, kteří při čtení a psaní považují pouze fonemické pravidlo.', 'et': 'Kõneleva keele transkribeerimiseks kirjalikule andmekandjale võimaldavad enamik tähestikke üheselt mõistetavat heli-tähe reeglit. Mõned kirjutamissüsteemid on siiski sellest lihtsast kontseptsioonist eemale kaldunud ja looduskeele töötlemisel (NLP) on sellise kauguse mõõtmisel vähe tööd. Käesolevas uuringus kasutame kunstliku neurovõrgu (ANN) mudelit, et hinnata läbipaistvust kirjalike sõnade ja nende häälduse vahel, sellest tulenevalt nimetusest Orthographic Transparency Estimation with a ANN (OTEANN). Wikimedia sõnaraamatutest tuletatud andmekogumite põhjal koolitasime ja testisime seda mudelit, et hinnata valeennustuste protsendi foneemi-grafeemi ja grafeemi-foneemi tõlketöödes. 17 ortograafia skoorid olid kooskõlas teiste uuringute hinnangutega. Huvitav on, et mudel andis ka ülevaate tüüpilistest vigadest õppijate poolt, kes arvestavad ainult foneemilist reeglit lugemisel ja kirjutamisel.', 'fi': 'Useimmat aakkoset mahdollistavat yksiselitteisen ﾃ､ﾃ､nen kirjaimesta kirjaimeen -sﾃ､ﾃ､nnﾃｶn, jotta puhuttu kieli voidaan kﾃ､ﾃ､ntﾃ､ﾃ､ kirjalliseen vﾃ､lineeseen. Jotkin kirjoitusjﾃ､rjestelmﾃ､t ovat kuitenkin etﾃ､ﾃ､ntyneet tﾃ､stﾃ､ yksinkertaisesta kﾃ､sitteestﾃ､ ja luonnollisen kielen prosessoinnissa (NLP) on vﾃ､hﾃ､n tyﾃｶtﾃ､ tﾃ､llaisen etﾃ､isyyden mittaamiseksi. Tﾃ､ssﾃ､ tutkimuksessa kﾃ､ytﾃ､mme Artificial Neural Network (ANN) -mallia arvioidaksemme kirjoitettujen sanojen ja niiden ﾃ､ﾃ､ntﾃ､misen vﾃ､listﾃ､ lﾃ､pinﾃ､kyvyyttﾃ､, joten sen nimi Orthographic Transparency Estimation with a ANN (OTEANN). Wikimedia-sanakirjoista johdettujen aineistojen perusteella koulutimme ja testasimme tﾃ､tﾃ､ mallia pisteyttﾃ､mﾃ､ﾃ､n vﾃ､ﾃ､rien ennusteiden prosenttiosuuden foneemi-grafeemi- ja grafeemi-foneemi-kﾃ､ﾃ､nnﾃｶstehtﾃ､vissﾃ､. 17 ortografiasta saadut pisteet olivat linjassa muiden tutkimusten arvioiden kanssa. Mielenkiintoista on, ettﾃ､ malli antoi myﾃｶs kﾃ､sityksen tyypillisistﾃ､ virheistﾃ､, joita oppijat ovat tehneet, jotka ottavat huomioon vain foneemisen sﾃ､ﾃ､nnﾃｶn lukemisessa ja kirjoittamisessa.', 'az': 'Sözlü dili yazılmış ortaya yazmaq üçün çox alfabələrin səs-səs hökmünü fəallaşdırır. Lakin bəzi yazma sistemləri bu basit fikirlərdən uzaqlaşdılar və bu uzaqlaşma haqqında təbiətli dil işləməsi (NLP) içində az iş var. Bu təcrübədə, yazılı sözlər və sözləri arasındakı şəffaflığı değerləşdirmək üçün, bu yüzden onun adı Ortografik Şəflıq Nəbəni ANN (OTEANN) ilə istifadə edirik. Wikimedia sözlərindən çıxarılan verilən qurğular üzərində, biz bu modeli foneme-to-grapheme və grapheme-to-phoneme çevirilən işlərin yüzdesini müəyyən etmək üçün təhsil etdik və sınaydıq. 17 ortografiyada qazanmış nöqtələr başqa təhsillərin hesablamasına uyğun idi. İlginç ki, modeli də oxumaq və yazmaq üçün fonemik hökmünü düşünən öyrənənənlər tarafından etdikləri tipik xətalara baxırlar.', 'bn': 'লেখার মাধ্যমে কথা বলা ভাষা লেখার জন্য, বেশীরভাগ আলফাবেত শব্দ-থেকে চিঠি নিয়ম সক্রিয় করে। However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance.  এই গবেষণায় আমরা একটি শিল্প নেউরাল নেটওয়ার্ক (এন) মডেল ব্যবহার করি লিখিত শব্দ এবং তাদের প্রকাশিত স্বচ্ছতার মাঝে মূল্যায়ন করার জন্য। তাই এর নাম অর্থগ্রাফিক স্বচ্ছ উইকিমিডিয়া অভিভাবকগুলোর তথ্যের ভিত্তিতে আমরা এই মডেল প্রশিক্ষণ এবং পরীক্ষা করেছি ফোনেম-থেকে গ্রাফেম এবং গ্রাফেম-থেকে ফোনেম অনুবাদের কাজে মিথ্য অন্যান্য গবেষণার হিসাবে ১৭টি অর্থোগ্রাফিতে পাওয়া স্কোর লাইনে লাইনে থাকে। মডেলটি সাধারণ ভুলের ব্যাপারে দৃষ্টিভঙ্গি প্রদান করেছে যারা শিক্ষার্থীরা শুধুমাত্র ফোনেমিক নিয়ম পাঠ করে এবং', 'he': 'To transcribe spoken language to written medium, most alphabets enable an unambiguous sound-to-letter rule.  בכל אופן, מערכות כתיבה מסוימות מרחקו את עצמם מהרעיון הפשוט הזה והעבודה הקטנה קיימת בתהליך השפה הטבעית (NLP) על מידוד מרחק כזה. במחקר הזה, אנו משתמשים בדוגמא של רשת נוירולית מלאכותית (ANN) כדי להעריך את השינוי בין מילים כתובות לבטא שלהם, לכן שמו הערכת השינוי אורתוגרפית עם ANN (OTEANN). בהתבסס על קבוצות נתונים שנוצרו ממילוני ויקימידיה, אימנו ובדיקנו את המודל הזה כדי לקבוע את אחוז של חזיונות שווא במשימות התרגום של פונום-לגרפימה וגרפימה-לפונמה. התוצאות שנקבלו ב-17 אורטוגרפיות היו תואמות לערכות של מחקרים אחרים. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.', 'sk': 'Za prepis govorjenega jezika v pisni medij večina abeced omogoča nedvoumno pravilo zvoka v črko. Vendar pa so se nekateri pisalni sistemi oddaljili od tega preprostega koncepta in v obdelavi naravnega jezika (NLP) obstaja malo dela pri merjenju te razdalje. V tej študiji uporabljamo model umetnega živčnega omrežja (ANN) za ocenjevanje transparentnosti med pisanimi besedami in njihovo izgovorjavo, zato je njegovo ime Ortografska ocena transparentnosti z ANN (OTEANN). Na podlagi naborov podatkov iz Wikimedijskih slovarjev smo usposobili in testirali ta model, da bi ocenili odstotek napačnih napovedi pri prevajalskih nalogah fonem-grafem in grafem-fonem. Ocene, pridobljene na 17 ortografijah, so bile v skladu z ocenami drugih študij. Zanimivo je, da je model zagotovil tudi vpogled v tipične napake učencev, ki upoštevajo samo fonemično pravilo pri branju in pisanju.', 'ha': "Don ka rubũta harshen da aka yi magana zuwa mai rubũtãwa, masu yawa na alfabt na zartar da wata sharrin sauti-zuwa-rubutu wanda bã ya taƙaita. A lokacin da wasu na'urar rubutu sun kange kansu daga wannan zato mai sauƙi kuma aiki kaɗan yana da shi a kan aikin Taural na Jarayi (NLP) kan lissafa wannan wuri. A cikin wannan lõkaci, Munã yi amfani da wani misali na Naural Naural (ANN) don a yi evaluci ga transparanci a tsakanin magana na rubutun da nunarwa, don haka kuma suna suna suna suna na Hanan Istaniya na Orokographic Sura da ANN (OTAANN). Basan da tsaro masu tsaro daga dictionaries na Wikimedia, mun yi wa kõra kuma aka jarraba wannan motel dõmin ya score fomat na ƙidãya wa fassaran birnin ƙarya cikin aikin fassarar-zuwa-grapheme da fassarar-zuwa-foneme. Kinin da aka sãmu na 17 ortogogi sun yi daidai da ƙidãyayn wasu littafi. Ina mai amfani da shi, motel ya also gaura gannai a cikin karãtun da aka sani na karãtunsa.", 'jv': 'Name Nanging, ketahan karo sistem sing paling-sistem sing gawe diolah sakjane kapan sistem iki dadi kapan karo akeh mungkin ingkang Daerawé (NLP) nganggep kuwi nggawe barang iki. Nang barêng-barêng iki, kéné uwis modèl Artikhial Neral Network (ANN) kanggo kuwi nggawe Kemerdekaan karo urip kanggo Kemerdekaan karo perangkat dhéwé, dadi nambah ortHographic Tarjamahan kanggo Kemerdekaan karo ANN (OCETNN). Ngawe Perintah dataset kang diketeksi winih Puntuan sing wis rampungan sing wis digol 18 ortoggraphiya sing wis rampungan nggawe sapa pertualangan Isih, model kuwi nggawe ngerasakno kanggo ngerasahan kamarané diungaké kelas sing paling kelas nèng kelas nang basa lan pisan.', 'bo': 'འཇུག་སྣོད་ནང་དུ་བྲིས་པའི་སྐད་ཡིག ཡིན་ནའང་། འབྲི་ནུས་ལག་ལ་ཁ་ཤས་ཀྱིས་སྟབས་བདེ་བའི་ལྟ་བ་འདིའི་ནང་དུ་ལས In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. རྣམ་གྲངས་ཀྱི་ཚིག་འབྲི་ཚིག་17ཡིས་གྲངས་འདི་ལྟ་བུའི་ནང་གི་བཟོ་རྩིས་གཞན་དང་མཉམ་དུ་རྙེད་ཡོད། Interestingly, the model also provided insight into typical errors made by learners who only consider the phonemic rule in reading and writing.'}
{'en': 'Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Nets', 'ar': 'تحسين تحليل المشاعر عبر اللغات عبر شبكات الخصومة اللغوية الشرطية', 'fr': "Améliorer l'analyse des sentiments multilingues grâce à des réseaux contradictoires en langage conditionnel", 'pt': 'Melhorando a Análise de Sentimentos entre Idiomas por meio de Redes Adversariais de Linguagem Condicional', 'es': 'Mejorando el análisis de sentimientos en varios idiomas a través de redes adversarias de lenguaje condicional', 'ja': '条件付き言語対立ネットを介したクロスリンガル感情分析の改善', 'zh': '因言抗网络改入语言情析', 'hi': 'सशर्त भाषा प्रतिकूल जाल के माध्यम से क्रॉस-लिंगुअल भावना विश्लेषण में सुधार', 'ru': 'Улучшение кросс-лингвального анализа настроений с помощью состязательных сетей с условным языком', 'ga': 'Anailís Trastheangach Mothúchán a Fheabhsú trí Líonta Sáraimh Teanga Coinníollacha', 'hu': 'A nyelvközi érzelmek elemzésének javítása feltételes nyelvi reklámhálózatokkal', 'el': 'Βελτίωση της γλωσσικής ανάλυσης συναισθημάτων μέσω των δικτύων αντίθεσης υπό όρους γλώσσας', 'kk': 'Шартты тіл көтерілік желілер арқылы көтерілікті сезімді анализдерді жақсарту', 'it': "Migliorare l'analisi dei sentimenti cross-lingual tramite reti pubblicitarie di linguaggio condizionato", 'lt': 'Gerinti tarpkalbinę jautrumo analizę naudojant sąlyginius prieštaringus kalbų tinklus', 'mk': 'Подобрување на анализата на чувствата преку условни јазици', 'ms': 'Menembak Analisi Sensan Selata-Bahasa melalui Rangkaian Adversarial Bahasa Bersyarat', 'ka': 'კროსლიგუალური სენტიმენტის ანალიზაციის გასაკეთება კონდიციონალური ენის კონდერსარიალური ქსელებით', 'mn': 'Үндсэн хэл дамжуулагчдын шинжилгээг сайжруулах', 'ml': 'ക്രോസ്- ലിങ്ഗല്\u200d സെന്റിമെന്റ് അന്വേഷണം മുന്\u200dകൂട്ടുന്നു', 'no': 'Å forbetra krysslingssentralanalyse ved hjelp av vilkårleg språk', 'mt': 'Titjib fl-Analiżi tas-Sentiment Translingwali permezz ta’ Netwerks Adversarji tal-Lingwa Kundizzjonali', 'pl': 'Poprawa analizy sentymentów między językami za pomocą warunkowych sieci przeciwników językowych', 'ro': 'Îmbunătățirea analizei sentimentelor translingvistice prin intermediul rețelelor adversare condiționale de limbaj', 'sr': 'Poboljšanje križanske sentimentalne analize kroz uvjetne jezičke konservacijske mreže', 'si': 'සාමාන්තික භාෂාව ප්\u200dරවේශනය සඳහා ක්\u200dරොස් ලින්ගුවාල් සංවේශනය විශ්ලේෂණය විස්තර කරන්න', 'so': 'Horumarinta baaritaanka fasaxa luqada', 'ur': 'Cross-Lingual Sentiment Analysis through Conditional Language Adversarial Nets', 'sv': 'Förbättra tvärspråklig känsloanalys via villkorliga språkreklamnätverk', 'ta': 'கிருஸ்- Lingual Sentiment Analysis by Conditional Language Adversarial Network', 'uz': 'Name', 'vi': 'Tăng khả năng phân tích tâm lý chữ thập', 'bg': 'Подобряване на междулингвистичния анализ на чувствата чрез условни езикови противоречиви мрежи', 'hr': 'Poboljšanje analize međujezičkih sentimenta putem uvjetnih proizvodnjih mreža', 'da': 'Forbedring af tværsproget følelsesanalyse via betingede sprogadvarselsnetværk', 'nl': 'Verbetering van Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Nets', 'de': 'Verbesserung der sprachübergreifenden Sentimentanalyse über Adversarial Networks in Conditional Language', 'ko': '조건 언어 대항망을 통해 다중 언어 감정 분석을 개선하다', 'fa': 'توسط شبکه\u200cهای پیشرفت\u200cکننده\u200cی زبان\u200cهای متوسط زبان\u200c', 'id': 'Menembak Analisi Sentimen Selata-Lingua melalui jaringan Adversarial Bahasa Kondisional', 'sw': 'Uchambuzi wa Seneti ya Kusini-Lingua kupitia Mtandao wa Utawala wa Lugha', 'tr': 'Çot-Dilli Sentiment Analizi Durumsal Diller (Conditional Language Adversarial Nets)', 'af': 'Verbeter Kruis- Linguaal Sentiment Analisie deur betingelike Taal Rekursariale Netwerke', 'sq': 'Duke përmirësuar analizën e ndjenjave ndërgjuhësore nëpërmjet rrjeteve kundërshtare të gjuhës me kusht', 'am': 'አቀማመጥ', 'hy': 'Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Nets', 'bn': 'ক্রস-লিঙ্গুয়াল সেন্টাইমেন্ট বিশ্লেষণের মাধ্যমে সংস্থায়িত ভাষা প্রধান নেটওয়ার্কের মাধ্যমে', 'az': 'İşkil Dili İşkil Ağları vasitəsilə Xərc-Dil Sentiment Analizi', 'ca': "millorar l'anàlisi de sentiments translingües a través de xarxes adversaries de llenguatge condicional", 'cs': 'Zlepšení analýzy mezijazyčných sentimentů pomocí nepříznivých sítí podmíněného jazyka', 'bs': 'Poboljšanje krstoLingualne sentimentne analize putem uvjetnih naprednih mreža jezika', 'et': 'Keeleülese tunnete analüüsi parandamine tingimuslike keelevõrkude abil', 'fi': 'Kieltenvälisen tunneanalyysin parantaminen ehdollisten kielten adversariaaliverkkojen avulla', 'jv': 'Progress', 'sk': 'Izboljšanje medjezikovne analize čustev s pogojnimi jezikovnimi neželenimi mrežami', 'ha': 'Analyze na fassarar-Linguin', 'he': 'שיפור ניתוח רגשות בין שפתיים דרך רשתות נגד שפת תנאי', 'bo': 'Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Nets'}
{'en': 'Sentiment analysis has come a long way for high-resource languages due to the availability of large annotated corpora. However, it still suffers from lack of training data for low-resource languages. To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision. CLAN differs from prior work in that it allows the adversarial training to be conditioned on both learned features and the sentiment prediction, to increase discriminativity for learned representation in the cross-lingual setting. Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset. Our source code is released at https://github.com/hemanthkandula/clan.', 'ar': 'لقد قطع تحليل المشاعر شوطًا طويلاً بالنسبة للغات عالية الموارد نظرًا لتوافر مجموعة كبيرة من التعليقات التوضيحية. ومع ذلك ، لا يزال يعاني من نقص بيانات التدريب للغات منخفضة الموارد. لمعالجة هذه المشكلة ، نقترح شبكة الخصومة اللغوية الشرطية (CLAN) ، وهي بنية عصبية شاملة لتحليل المشاعر عبر اللغات دون إشراف عبر اللغات. تختلف CLAN عن العمل السابق من حيث أنها تسمح بتكييف التدريب العدائي على كل من الميزات المكتسبة والتنبؤ بالمشاعر ، لزيادة التمييز للتمثيل الذي تم تعلمه في الإعداد متعدد اللغات. توضح النتائج التجريبية أن CLAN تتفوق في الأداء على الأساليب السابقة في مجموعة بيانات مراجعة Amazon متعددة اللغات. تم تحرير كود المصدر الخاص بنا على https://github.com/hemanthkandula/clan.', 'fr': "L'analyse des sentiments a fait beaucoup de chemin pour les langues à ressources élevées en raison de la disponibilité de grands corpus annotés. Cependant, il souffre toujours d'un manque de données de formation pour les langues à faibles ressources. Pour résoudre ce problème, nous proposons le Conditional Language Adversarial Network (CLAN), une architecture neuronale de bout en bout pour l'analyse des sentiments multilingues sans supervision interlinguistique. Le CLAN diffère des travaux antérieurs en ce qu'il permet de conditionner l'entraînement contradictoire à la fois sur les caractéristiques apprises et sur la prédiction des sentiments, afin d'accroître la discrimination pour la représentation apprise dans le contexte multilingue. Les résultats expérimentaux démontrent que le CLAN surpasse les méthodes précédentes sur l'ensemble de données d'avis multilingues multi-domaines Amazon. Notre code source est publié à l'adresse https://github.com/hemanthkandula/clan.", 'pt': 'A análise de sentimento percorreu um longo caminho para linguagens de alto recurso devido à disponibilidade de grandes corpora anotados. No entanto, ainda sofre com a falta de dados de treinamento para linguagens de poucos recursos. Para resolver esse problema, propomos a Conditional Language Adversarial Network (CLAN), uma arquitetura neural de ponta a ponta para análise de sentimentos em vários idiomas sem supervisão em vários idiomas. O CLAN difere do trabalho anterior, pois permite que o treinamento do adversário seja condicionado tanto aos recursos aprendidos quanto à previsão de sentimentos, para aumentar a discriminação da representação aprendida no ambiente multilíngue. Os resultados experimentais demonstram que o CLAN supera os métodos anteriores no conjunto de dados multilíngue de vários domínios da Amazon. Nosso código fonte está disponível em https://github.com/hemanthkandula/clan.', 'es': 'El análisis de sentimientos ha recorrido un largo camino para los lenguajes de gran cantidad de recursos debido a la disponibilidad de grandes corpus anotados. Sin embargo, todavía adolece de falta de datos de capacitación para idiomas de bajos recursos. Para abordar este problema, proponemos Conditional Language Adversarial Network (CLAN), una arquitectura neuronal de extremo a extremo para el análisis de sentimientos multilingües sin supervisión multilingüe. CLAN se diferencia del trabajo anterior en que permite que el entrenamiento contradictorio esté condicionado tanto a las características aprendidas como a la predicción de sentimientos, para aumentar la discriminatividad de la representación aprendida en el entorno multilingüe. Los resultados experimentales demuestran que CLAN supera a los métodos anteriores en el conjunto de datos de revisión multilingüe multidominio de Amazon. Nuestro código fuente está publicado en https://github.com/hemanthkandula/clan.', 'ja': 'センチメント分析は、大規模な注釈付きコーパスが利用可能なため、高リソース言語にとって長い道のりを歩んできました。しかし、それでもなお、低資源言語のトレーニングデータの不足に悩まされている。この問題に取り組むために、私たちは、クロスリンガル監視なしでクロスリンガル感情分析を行うためのエンドツーエンドのニューラルアーキテクチャである条件付き言語対抗ネットワーク（ CLAN ）を提案します。クランは、対抗訓練が学習された機能と感情予測の両方に条件付けられ、クロスリンガルの場面で学習された表現に対する差別性を高めることを可能にするという点で、以前の仕事とは異なる。実験結果は、クランが多言語のマルチドメインAmazonレビューデータセットの以前の方法よりも優れていることを示しています。ソースコードはhttps://github.com/hemanthkandula/clanで公開されています。', 'zh': '情析于高资言已过长道,盖有大注语料库也。 然犹乏低资源语之数。 为此者,言而抗网络(CLAN),端到端之神经架构也,以跨言情析,而无跨言督也。 CLAN与前事异者,许对抗性训练而以习为资,以增跨语中习得表征之判。 实验结果表明,CLAN 于多言多域 Amazon 论数集上优于前法。 吾源代码发于 https://github.com/hemanthkandula/clan 。', 'ru': 'Анализ настроений прошел долгий путь для высокоресурсных языков благодаря наличию больших аннотированных корпусов. Однако она по-прежнему страдает от нехватки данных об обучении языкам с ограниченными ресурсами. Чтобы решить эту проблему, мы предлагаем сеть противников условного языка (КЛАН), сквозную нейронную архитектуру для анализа межъязыковых настроений без межъязыкового надзора. КЛАН отличается от предыдущей работы тем, что он позволяет обучению соперников быть обусловленным как изученными признаками, так и предсказанием настроений, чтобы увеличить дискриминативность для обученного представления в межъязыковой среде. Экспериментальные результаты показывают, что КЛАН превосходит предыдущие методы в многоязычном многодоменном наборе данных Amazon review. Наш исходный код доступен по адресу https://github.com/hemanthkandula/clan.', 'hi': 'भावना विश्लेषण बड़े एनोटेट कॉर्पोरेट की उपलब्धता के कारण उच्च संसाधन भाषाओं के लिए एक लंबा रास्ता तय किया है। हालांकि, यह अभी भी कम संसाधन वाली भाषाओं के लिए प्रशिक्षण डेटा की कमी से ग्रस्त है। इस समस्या से निपटने के लिए, हम सशर्त भाषा प्रतिकूल नेटवर्क (CLAN) का प्रस्ताव करते हैं, जो क्रॉस-भाषी पर्यवेक्षण के बिना क्रॉस-लिंगुअल भावना विश्लेषण के लिए एक एंड-टू-एंड तंत्रिका वास्तुकला है। CLAN पहले के काम से अलग है कि यह प्रतिकूल प्रशिक्षण को सीखा सुविधाओं और भावना की भविष्यवाणी दोनों पर वातानुकूलित करने की अनुमति देता है, क्रॉस-लिंगुअल सेटिंग में सीखा प्रतिनिधित्व के लिए भेदभाव को बढ़ाने के लिए। प्रयोगात्मक परिणामों से पता चलता है कि CLAN बहुभाषी बहु-डोमेन अमेज़ॅन समीक्षा डेटासेट पर पिछले तरीकों से बेहतर प्रदर्शन करता है। हमारा स्रोत कोड https://github.com/hemanthkandula/clan पर जारी किया जाता है।', 'ga': 'Tá anailís meoin tagtha chun cinn go mór do theangacha ard-acmhainne mar gheall ar an bhfáil ar mhórchorpóra anótáilte. Mar sin féin, tá sé fós thíos le heaspa sonraí oiliúna do theangacha íseal-acmhainne. Chun dul i ngleic leis an bhfadhb seo, molaimid Coinníollach Language Adversarial Network (CLAN), ailtireacht néarúil ceann go ceann le haghaidh anailíse tras-teangacha meon gan maoirseacht thrastheangach. Tá difríocht idir CLAN agus obair a rinneadh roimhe seo sa mhéid is go gceadaíonn sé an oiliúint sháraíochta a riocht ar ghnéithe foghlamtha agus ar thuar na meon, chun an t-idirdhealú a mhéadú maidir le hionadaíocht fhoghlamtha sa suíomh trasteangach. Léiríonn torthaí turgnamhacha go sáraíonn CLAN modhanna roimhe seo ar thacar sonraí athbhreithnithe il-fearainn ilteangach Amazon. Eisítear ár gcód foinse ag https://github.com/hemanthkandula/clan.', 'el': 'Η ανάλυση συναισθημάτων έχει κάνει μεγάλο δρόμο για γλώσσες υψηλής περιεκτικότητας λόγω της διαθεσιμότητας μεγάλων σχολιασμένων σωμάτων. Ωστόσο, εξακολουθεί να πάσχει από έλλειψη δεδομένων κατάρτισης για γλώσσες χαμηλής περιεκτικότητας σε πόρους. Για να αντιμετωπιστεί αυτό το πρόβλημα, προτείνουμε ένα Δίκτυο Αντιθετικής Γλώσσας (CLAN), μια νευρωνική αρχιτεκτονική για ανάλυση διγλωσσών συναισθημάτων χωρίς διεπαγγελματική εποπτεία. Το CLAN διαφέρει από την προηγούμενη εργασία στο ότι επιτρέπει στην αντίπαλη εκπαίδευση να εξαρτάται τόσο από τα μαθημένα χαρακτηριστικά όσο και από την πρόβλεψη συναισθημάτων, ώστε να αυξηθεί η διακριτικότητα για την μαθημένη αναπαράσταση στο γλωσσικό περιβάλλον. Τα πειραματικά αποτελέσματα καταδεικνύουν ότι το CLAN ξεπερνά τις προηγούμενες μεθόδους στο πολύγλωσσο σύνολο δεδομένων αναθεώρησης πολλών τομέων. Ο πηγαίος μας κώδικας κυκλοφορεί στο https://github.com/hemanthkandula/clan.', 'ka': 'სისტემისტის ანალიზაცია ძალიან ძალიან გზა, რომელიც უფრო მეტი რესურსისტის ენაზებისთვის დიდი ანალიზაციული კოპორაციის მისამართლად მოხდა. მაგრამ მას უკვე უფრო მცირე რესურსის ენათებისთვის მონაცემები არსებობს. ამ პრობლემას გადაწყვეტისთვის, ჩვენ შეგვეძლია კონდიციონალური ენის კონპერსაციალური ქსელი (CLAN), ნეიროლური აქტიქტიქტურა კრისი ენგუმენტის ანალიზაციისთვის, კრისი ენგ CLAN განსხვავებულია პირველი სამუშაოდან, რომელიც განსხვავებულია განსხვავებული განსხვავება განსხვავებულ განსხვავებას და განსხვავებულ განსხვავებას, რომ განსხვავებული განსხვავებას კრისი ენგუფიკაციის განსხვ ექსპერიმენტიური შედეგები გამოჩვენებენ, რომ CLAN წინახალი მეტოვების მრავალენგური მრავალენგური მონაცემების Amazon განაცემების მონაცემების შესახებ ჩვენი წიგნის კოდი გახსნა https://github.com/hemanthkandula/clan.', 'hu': 'Az érzelmek elemzése hosszú utat tett meg a nagy erőforrásokkal rendelkező nyelvek számára a nagy jegyzetelt korpuszok elérhetősége miatt. Azonban továbbra is hiányzik az alacsony erőforrású nyelvekre vonatkozó képzési adatok. Ennek a problémának a megoldása érdekében javasoljuk a Conditional Language Adversarial Network (CLAN), egy end-to-end neurális architektúrát, amely többnyelvű felügyelet nélküli, többnyelvű érzelmi elemzéshez szükséges. A CLAN különbözik a korábbi munkától abban, hogy lehetővé teszi, hogy az ellenséges képzés mind a tanult tulajdonságok, mind az érzelmek előrejelzése függvényében legyen, hogy növelje a diszkriminációt a tanult reprezentáció iránt a nyelvek között. A kísérleti eredmények azt mutatják, hogy a CLAN felülmúlja a korábbi módszereket a többnyelvű, több tartományból álló Amazon vizsgálati adatkészleten. A forráskódunk a https://github.com/hemanthkandula/clan.', 'kk': 'Сентименттің анализ үлкен белгіленген корпораға жеткізілген үлкен ресурс тілдерінің жоғары жолы болды. Бірақ ол әлі жеткілікті ресурс тілдерінің оқыту деректері жоқ. Бұл мәселеге шешу үшін, біз шарттарлық тіл конверсариялық желі (CLAN), тілдерді бірнеше тілдерді бақылау архитектурасы үшін бірнеше тілдерді шешу үшін невралдық архитектурасын ұсынамыз. КЛАН алдыңғы жұмыс істегеннен айырмашылық, бұл қарсы оқытуға мүмкіндік беретін қарсы оқытуға мүмкіндік береді, бірнеше тілді ортасында оқыту үшін дискриминациялықты көтеру үшін. Эксперименталдық нәтижелер КЛАН көп тілдік көп- домендік Amazon қарау деректер жиынында алдыңғы әдістерді орындайды деп көрсетеді. Біздің көзіміздің кодымыз https://github.com/hemanthkandula/clan.', 'lt': 'Sentimento analizė buvo labai didelė didelių išteklių kalbų atžvilgiu dėl didelių anotuotų korprų prieinamumo. Tačiau vis dar trūksta duomenų apie mažai išteklių turinčių kalbų mokymą. Siekiant išspręsti šią problem ą, siūlome „sąlyginio kalbos prieštaringo tinklo“ (CLAN), nuo vienos iki kitos neuralinės architektūros, skirtos tarpkalbinei jautrumo analizei be tarpkalbinės priežiūros. CLAN skiriasi nuo ankstesnio darbo, nes jis leidžia priešingam mokymui priklausyti nuo įgytų savybių ir jausmų prognozės, kad būtų padidintas diskriminavimas mokomo atstovavimo tarpkalbinėje aplinkoje. Eksperimentiniai rezultatai rodo, kad CLAN atitinka ankstesnius daugiakalbių Amazon peržiūros duomenų rinkinio metodus. Mūsų šaltinio kodas skelbiamas https://github.com/hemanthkandula/clan.', 'mk': 'Анализата на чувствата дошла долг пат за јазиците со високи ресурси поради достапноста на големи анотирани корпора. Сепак, таа сé уште страда од недостаток на податоци за обука за јазици со ниски ресурси. За да го решиме овој проблем, предлагаме Кондиционална Јазична Авенсериска мрежа (КЛАН), нервна архитектура од крај до крај за прекујазична анализа на сентиментите без прекујазичен надзор. КЛАН се разликува од претходната работа со оглед на тоа што овозможува противната обука да биде условена на научени карактеристики и предвидување на чувствата, за зголемување на дискриминативноста за наученото претставување во прекујазичното околинување. Експерименталните резултати покажуваат дека КЛАН ги надминува претходните методи на множјазичниот множјазичен компјутер на податоци за преглед на Амазон. Нашиот изворен код е објавен на https://github.com/hemanthkandula/clan.', 'ms': 'Analisis perasaan telah datang jauh untuk bahasa sumber-tinggi disebabkan kemampuan korpra besar yang dicatat. Namun, ia masih menderita oleh kekurangan data latihan untuk bahasa sumber rendah. To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision.  CLAN berbeza dari kerja sebelumnya kerana ia memungkinkan latihan lawan untuk digantung pada kedua-dua ciri belajar dan ramalan perasaan, untuk meningkatkan diskriminasi untuk mewakili belajar dalam tetapan saling bahasa. Keputusan percubaan menunjukkan bahawa CLAN melampaui kaedah terdahulu pada set data ulasan Amazon berbilang-domain berbilang bahasa. Kod sumber kita dibebaskan di https://github.com/hemanthkandula/clan.', 'mt': 'L-analiżi tas-sensazzjoni waslet fit-tul għal-lingwi b’riżorsi għoljin minħabba d-disponibbiltà ta’ korpora annotata kbira. Madankollu, għadha tbati minn nuqqas ta’ dejta ta’ taħriġ għal lingwi b’riżorsi baxxi. Biex nindirizzaw din il-problema, nipproponu Netwerk Kundizzjonali tal-Lingwi Adversarji (CLAN), arkitettura newrali minn tarf sa tarf għall-analiżi tas-sentimenti translingwistiċi mingħajr superviżjoni translingwistika. CLAN huwa differenti minn xogħol preċedenti billi jippermetti li t-taħriġ avversarju jkun ikkondizzjonat kemm fuq il-karatteristiċi mitgħallma kif ukoll fuq it-tbassir tas-sensazzjoni, biex tiżdied id-diskriminazzjoni għar-rappreżentanza mitgħallma fl-ambjent translingwistiku. Ir-riżultati esperimentali juru li CLAN iwettaq metodi preċedenti fuq is-sett ta’ dejta multilingwi ta’ reviżjoni Amazon b’diversi dominji. Il-kodiċi tas-sors tagħna jiġi rilaxxat fuq https://github.com/hemanthkandula/clan.', 'no': 'Sentimentanalysen har kommet ein lang måte for høg ressursspråk på grunn av tilgjengeleg stor merknad korpora. Det har imidlertid fremdeles mangling av treningsdata for låg ressursspråk. For å løse denne problemen, foreslår vi vilkårleg språk-konserversarialnettverk (CLAN), ein neuralarkitektur for krysspråk-sentimentanalyse utan krysspråk-oversikt. CLAN er forskjellig frå førre arbeid i at den tillater at den adversariale treninga skal vera kondicionalt på både lærte funksjonar og følelsesforhåndsvising, for å økja diskriminativ for lærte representasjon i krysspråk innstillinga. Eksperimentale resultat viser at CLAN utfører førre metodar på multilingual multidomene Amazon review dataset. Kjeldekode vårt er sletta på https://github.com/hemanthkandula/clan.', 'mn': 'Хэрвээ сэтгэл санааны шинжилгээ маш олон нийтлэг хэлнүүдийн хувьд маш урт зам ирсэн бөгөөд маш их сэтгэл хангалттай корпора байдаг. Гэвч энэ нь бага боловсролын хэл дээр суралцах өгөгдлийн алдаагүй байдаг. Энэ асуудлыг зогсоохын тулд бид шалтгаан хэл дамжуулагчийн сүлжээ (CLAN), хэл дамжуулагчгүй, олон хэл дамжуулагчдын шинжилгээний сэтгэл хөдлөлийн мэдрэмжтэй шинжилгээний сэтгэл хөдлөл, мэдрэмжтэй байгуул КЛАН өмнөх ажлын хоорондоо ялгаатай учраас тэдний эсрэг сургалтыг суралцах болон мэдрэмжтэй таамаглах боломжтой болгодог, олон хэл хэлний хэлбэрээр суралцаж суралцаж суралцах зан чанарын ялгааг нэмэгдүүлэх болом Үүний туршилтын үр дүнд CLAN олон хэл хэлний олон дотор Амазон шинжилгээний өгөгдлийн санд өмнө арга зам гаргадаг гэдгийг харуулж байна. Бидний эх үүсвэрийн код https://github.com/hemanthkandula/clan.', 'it': "L'analisi dei sentimenti ha fatto molta strada per i linguaggi ad alto contenuto di risorse grazie alla disponibilità di grandi corpora annotati. Tuttavia, soffre ancora della mancanza di dati di formazione per le lingue a basso contenuto di risorse. Per affrontare questo problema, proponiamo Conditional Language Adversarial Network (CLAN), un'architettura neurale end-to-end per l'analisi cross-lingual sentiment senza supervisione cross-lingual. CLAN differisce dal lavoro precedente in quanto permette alla formazione avversaria di essere condizionata sia dalle caratteristiche apprese che dalla previsione sentimentale, per aumentare la discriminazione per la rappresentazione appresa nell'ambiente cross-lingual. I risultati sperimentali dimostrano che CLAN supera i metodi precedenti sul set di dati multidominio Amazon multilingue. Il nostro codice sorgente è rilasciato a https://github.com/hemanthkandula/clan.", 'ml': 'വളരെ വിഭവങ്ങളുടെ ഭാഷകള്\u200dക്കുള്ള സെന്റിമെന്റ് അന്വേഷണം വളരെ ദൂരം വന്നിരിക്കുന്നു. എന്നാലും കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകള്\u200dക്കുള്ള പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200d ഇല്ലാത്തതില്\u200d ഇത് ഇപ്പോഴും അന ഈ പ്രശ്നത്തെ പരിചയപ്പെടുത്താന്\u200d, നിശ്ചയമായ ഭാഷ അഡ്രസറിയല്\u200d നെറ്റ്വര്\u200dക്ക്(CLAN), ക്രിസ്ലാങ്ഗല്\u200d നിരീക്ഷണമില്ലാത്ത ഒരു അവസാനത്തേക്ക് അവസാനിക് സിലാന്\u200d മുമ്പ് ജോലിയില്\u200d നിന്നും വ്യത്യസ്തമായിരിക്കുന്നു. അതിനാല്\u200d വിരോധമായ പരിശീലനം പഠിച്ചിരിക്കുന്ന വിഭാഗങ്ങള്\u200dക്കും പ്രവചനങ്ങള്\u200dക്കും നിയ പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു മുന്\u200dപ് സിലാന്\u200d മാത്രം രീതികള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത് പല ഭാ നമ്മുടെ ഉറവിട കോഡ് വിട്ടുപോകുന്നു https://github.com/hemanthkandula/clan.', 'sr': 'Sentimentna analiza je došla na dug naèin za jezike visokih resursa zbog raspoloženja velike annotirane korpore. Međutim, još uvijek pati od nedostatka podataka o obuci za jezike niskih resursa. Da bi se riješili ovog problema, predlažemo uslovnu konverzacionalnu mrežu jezika (CLAN), neuralnu arhitekturu za analizu preko jezika bez preko jezika nadzora. CLAN se razlikuje od prethodnog rada u tome što omogućava da se adversarna obuka uvodi na naučene karakteristike i predviđanje sentimenta, da povećava diskriminaciju za naučenu predstavu na međujezičkom postavljanju. Eksperimentalni rezultati pokazuju da CLAN iznosi prethodne metode na multijezičkim multidomeničkim podacima Amazon pregledanja. Naš izvorni kod je otpušten u https://github.com/hemanthkandula/clan.', 'pl': 'Analiza sentymentów przeszła długą drogę dla języków o wysokich zasobach ze względu na dostępność dużych adnotacji korpusów. Jednak nadal cierpi na brak danych szkoleniowych dotyczących języków o niskich zasobach. Aby rozwiązać ten problem, proponujemy Conditional Language Adversarial Network (CLAN), kompleksową architekturę neuronową umożliwiającą analizę sentymentów między językami bez nadzoru między językami. CLAN różni się od wcześniejszych prac tym, że umożliwia uwarunkowanie treningu przeciwnikowego zarówno nauczonych cech, jak i predykcji sentymentów, w celu zwiększenia dyskryminacyjności dla nauczonej reprezentacji w otoczeniu wielojęzycznym. Wyniki eksperymentów pokazują, że CLAN przewyższa poprzednie metody w wielojęzycznym wieloodomenowym zestawie danych przeglądów Amazon. Nasz kod źródłowy jest publikowany pod adresem: https://github.com/hemanthkandula/clan.', 'so': 'Shahaadada wakhtiga la xiriiray waxay u timid luuqado aad u dheer, sababtoo ah helitaanka shirkad aad u weyn. Si kastaba ha ahaatee waxay weli ugu dhibaataysaa baahida waxbarashada luqadaha hoose ee luqada. Si aan u tacliino dhibaatadan, waxaan u soo jeedaynaa shabakadda asalka ah (CLAN), dhismaha neurada ee dhammaadka ugu dambeeya, baaritaanka fikrada luuqadaha kala duwan ee aan ilaalinaynin luuqadaha kala duwan. CLAN wuxuu ka duwan yahay shaqada hore, taas oo u ogolaan karaa in waxbarashada cadaawayaasha ah lagu sharciyo tababarka bartay iyo sii sheegidda fikrada, si uu u kordhiyo takoorida aqoonta lagu baro wakiilka afka kala duwan. Imtixaanka waxaa ka muuqda in CLAN uu sameeyo qaabab hore oo ku saabsan baaritaanka macluumaadka kala duduwan ee Amazon. Qorada asalkayaga waxaa lagu furay https://github.com/hemanthkandula/clan.', 'ro': 'Analiza sentimentelor a parcurs un drum lung pentru limbajele cu resurse ridicate datorită disponibilității corporelor adnotate mari. Cu toate acestea, acesta suferă încă din cauza lipsei datelor de formare pentru limbile cu resurse reduse. Pentru a aborda această problemă, propunem Rețeaua Adversarială Condiționată a Limbajului (CLAN), o arhitectură neurală end-to-end pentru analiza sentimentelor interlingvistice fără supraveghere interlingvă. CLAN diferă de munca anterioară prin faptul că permite antrenamentului adversar să fie condiționat atât de trăsăturile învățate, cât și de predicția sentimentului, pentru a crește discriminarea pentru reprezentarea învățată în cadrul interlingvistic. Rezultatele experimentale demonstrează că CLAN depășește metodele anterioare în setul de date multilingv de revizuire Amazon multidomeniu. Codul nostru sursă este lansat la https://github.com/hemanthkandula/clan.', 'sv': 'Känsleanalys har kommit en lång väg för högresursspråk på grund av tillgängligheten av stora kommenterade korpora. Den lider dock fortfarande av brist på utbildningsdata för språk med låg resurs. För att ta itu med detta problem föreslår vi Conditional Language Adversarial Network (CLAN), en end-to-end neural arkitektur för tvärspråklig sentimental analys utan tvärspråklig övervakning. CLAN skiljer sig från tidigare arbete genom att det gör det möjligt för motståndarens träning att betyda både lärda egenskaper och sentimentprediktion, för att öka diskrimineringen för lärd representation i den tvärspråkiga miljön. Experimentella resultat visar att CLAN överträffar tidigare metoder på flerspråkiga Amazon-granskningsdatauppsättningar med flera domäner. Vår källkod släpps på https://github.com/hemanthkandula/clan.', 'si': 'විශේෂ විශ්ලේෂණයක් ලොකු කොර්පෝරා විශ්වාස කරලා තියෙන්නේ විශේෂ භාෂාවට ලොකු මාර්ගයක් ඇත ඒත්, ඒක තාමත් අඩුම සම්බන්ධ භාෂාවට තොරතුරු අවස්ථාවක් නෑ. මේ ප්\u200dරශ්නයක් හරිගන්න, අපි සාමාන්තික භාෂාව ප්\u200dරශ්නයක් ජාලය (CLAN) ප්\u200dරශ්නයක් කරනවා, ප්\u200dරශ්නයක් භාෂාව ප්\u200dරශ්නයක් නැත CLAN වෙනස් කලින් වැඩේ ඉදිරියට වෙනස් කරනවා කියලා, ඒකෙන් විරෝධ විශ්වාස කරනවා විරෝධ විශ්වාස කරනවා කියලා දැන් ඉගෙන ගත්ත අවශ්\u200dයා පරීක්ෂණාත්මක ප්\u200dරතික්\u200dරියාත්මක විදිහට CLAN ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200d අපේ ප්\u200dරධාන කෝඩ් නිදහස් කරලා තියෙනවා https://github.com/hemanthkandula/clan.', 'ur': 'سنٹیمینٹ تحلیل بہت زیادہ مضبوط کورپورا کے موجود ہونے کے باعث بہت سی سراسر زبانوں کے لئے ایک دور طریقہ آچکا ہے. لیکن اسے بھی کم منبع زبانوں کے لئے آموزش دادہ کی کمی کی وجہ سے ہے۔ اس مسئلہ کا حل کرنے کے لئے، ہم نے Conditional Language Adversarial Network (CLAN) کی پیشنهاد کرتا ہے، ایک مختلف زبان کے بغیر مختلف زبان نظارت کے لئے ایک نئورل معمار۔ CLAN پہلے کے کام سے مختلف ہے کہ یہ مخالف تعلیم کی اجازت دیتا ہے کہ دونوں تعلیم کی تعلیم اور احساسات کی پیش بینی پر قائم ہو جاتی ہے، اس کے لئے مخالف زبان کی تعلیم کی تعلیم کے لئے تقسیم کی زیادتی کرتا ہے۔ Experimental results demonstrate that CLAN performs previous methods on multilingual multi-domain Amazon review dataset. ہمارے سراسر کوڈ کو آزاد کیا گیا ہے https://github.com/hemanthkandula/clan.', 'ta': 'அதிக மூலத்தின் மொழிகளுக்கான உணர்வு விளக்கம் பெரிய குறிப்பிடப்பட்ட நிறுவனத்தினால் நீண்ட வழி வந்துள்ளது. ஆனால் அது இன்னும் குறைந்த மூலத்திற்கு பயிற்சி தரவு இல்லாமல் பாதிக்கும். இந்த பிரச்சனையை நிர்வகிக்க, நாம் பரிந்துரைய மொழி மொழி மேம்பாட்டாளர் வலைப்பின்னல் (CLAN), முடிவு இறுதி முடிவு புதிய நிரல் கட்டுப்பாடு CLAN முன் வேலையில் இருந்து வேறுபாடு இருக்கிறது அது கற்றுக் கொண்ட பண்புகள் மற்றும் உணர்வு முன்னதாகவும் கற்றுக் கொண்டு இருந்த பயிற்சியை நிர்ணயிக்க Name எங்கள் மூல குறியீடு வெளியேற்றப்பட்டது https://github.com/hemanthkandula/clan.', 'uz': "@ info: whatsthis Lekin, bu juda kam manbanli tillar uchun taʼminlovchi maʼlumot yoʻq. Bu muammolani boshqarish uchun, biz Konstant tilning davlat tarmoqni (CLAN), o'sha oxirgi neyron arxituvchisi, har bir necha xil hissiyasiga aniqlash uchun o'zgartiraymiz. Name Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset.  Bizning manba kodi https://github.com/hemanthkandula/clan.", 'vi': 'Bản phân tích tình cảm đã đi một chặng đường dài cho những ngôn ngữ giàu có nhờ có các hạ sĩ quan có ghi chú lớn. Tuy nhiên, nó vẫn bị thiếu dữ liệu đào tạo về ngôn ngữ nghèo. Để giải quyết vấn đề này, chúng tôi đề nghị hệ thống thần kinh ngôn ngữ ngữ tiếp cận (Clank), một kiến trúc thần kinh kết thúc-tới-cuối cho phân tích cảm xúc xuyên ngôn ngữ mà không cần giám sát ngôn ngữ khác. Bên nguyên thì khác với các hoạt động trước, bởi vì nó cho phép huấn luyện đối thủ được điều chỉnh từ các tính năng học tập và dự đoán cảm xúc, để tăng sự phân biệt học hỏi trong môi trường ngôn ngữ khác nhau. Kết quả thử nghiệm chứng minh rằng CLAY vượt trội với các phương pháp trước đây trên bộ dữ liệu đa miền của Amazon. Mã nguồn của chúng tôi được phát hành tại https://github.com/hemanthkandula/clan.', 'bg': 'Анализът на сентимента е изминал дълъг път за езици с висок ресурс поради наличието на големи анотирани корпуси. Въпреки това, тя все още страда от липса на данни за обучение за езици с нисък ресурс. За да се справим с този проблем, предлагаме условна езикова противоречива мрежа (CLAN), невронна архитектура от край до край за междуезичен анализ на сентименталните чувства без междуезичен надзор. Клан се различава от предишната работа по това, че позволява на съперническото обучение да бъде обусловено както от научените характеристики, така и от предсказването на сентимента, за да се увеличи дискриминацията за наученото представяне в междуезичната обстановка. Експерименталните резултати показват, че CLAN превъзхожда предишните методи в многоезичния многодомейнен набор от данни за преглед на Amazon. Нашият изходен код е публикуван на https://github.com/hemanthkandula/clan.', 'da': 'Sentiment analyse er kommet langt for høj ressource sprog på grund af tilgængeligheden af store annoterede korpora. Den lider dog stadig af manglende uddannelsesdata for sprog med lav ressource. For at løse dette problem foreslår vi Conditional Language Adversarial Network (CLAN), en end-to-end neural arkitektur til tværsproget sentimental analyse uden tværsproget overvågning. CLAN adskiller sig fra tidligere arbejde ved, at det gør det muligt for modstandernes træning at blive betinget af både lærte træk og sentiment forudsigelse, for at øge diskrimineringen for lært repræsentation i den tværsprogede indstilling. Eksperimentelle resultater viser, at CLAN overgår tidligere metoder på det flersprogede Amazon-gennemgangsdatasæt med flere domæner. Vores kildekode udgives på https://github.com/hemanthkandula/clan.', 'nl': 'Sentiment analyse heeft een lange weg afgelegd voor high-resource talen vanwege de beschikbaarheid van grote geannoteerde corpora. Het lijdt echter nog steeds aan een gebrek aan opleidingsgegevens voor talen met weinig middelen. Om dit probleem aan te pakken, stellen we Conditional Language Adversarial Network (CLAN) voor, een end-to-end neurale architectuur voor meertalige sentimentanalyse zonder meertalige supervisie. CLAN verschilt van eerder werk in dat het toelaat om de tegenstrijdige training te conditioneren op zowel de aangeleerde kenmerken als de sentiment voorspelling, om de discriminatie voor geleerde representatie in de cross-lingual setting te vergroten. Experimentele resultaten tonen aan dat CLAN eerdere methoden overtreft op de meertalige multi-domein Amazon review dataset. Onze broncode wordt vrijgegeven op: https://github.com/hemanthkandula/clan.', 'hr': 'Analiza osjetljivosti došla je na dug način za jezike visokog resursa zbog raspoloženja velikog annotiranog tijela. Međutim, ona još uvijek pati od nedostatka podataka o obuci za jezike niskih resursa. Za rješavanje ovog problema predlažemo uslovnu porazgovarajuću mrežu jezika (CLAN), neuralnu arhitekturu kraja do kraja za analizu preko jezika sentimenta bez preko jezika nadzora. CLAN se razlikuje od prethodnog rada u tome što omogućava da se adversarna obuka uvjeti na naučene funkcije i predviđanje osjećaja, povećati diskriminaciju za učenje zastupanja na međujezičkom postavljanju. Eksperimentalni rezultati pokazuju da CLAN iznosi prethodne metode na multijezičkim multidomeničkim podacima Amazon pregledanja. Naš izvorni kod je objavljen na https://github.com/hemanthkandula/clan.', 'de': 'Die Sentimentanalyse hat aufgrund der Verfügbarkeit großer kommentierter Korpora für ressourcenintensive Sprachen einen langen Weg zurückgelegt. Es leidet jedoch immer noch unter fehlenden Ausbildungsdaten für ressourcenarme Sprachen. Um dieses Problem anzugehen, schlagen wir Conditional Language Adversarial Network (CLAN) vor, eine End-to-End neuronale Architektur für die sprachübergreifende Stimmungsanalyse ohne sprachübergreifende Aufsicht. CLAN unterscheidet sich von früheren Arbeiten dadurch, dass es erlaubt, das gegnerische Training sowohl von erlernten Merkmalen als auch von der Sentiment-Vorhersage zu konditionieren, um die Diskriminierung der erlernten Repräsentation im crosslingualen Setting zu erhöhen. Experimentelle Ergebnisse zeigen, dass CLAN frühere Methoden auf dem mehrsprachigen Amazon Review Dataset mit mehreren Domänen übertrifft. Unser Quellcode wird veröffentlicht unter https://github.com/hemanthkandula/clan.', 'id': 'Analisis perasaan telah datang jauh untuk bahasa sumber daya tinggi karena keberhasilan dari corpora besar yang dicatat. Namun, masih menderita karena kekurangan data pelatihan untuk bahasa sumber daya rendah. Untuk mengatasi masalah ini, kami mengusulkan Jaringan Perlawanan Bahasa Kondisional (CLAN), arsitektur saraf akhir-akhir untuk analisis sentimen saling bahasa tanpa pengawasan saling bahasa. CLAN berbeda dari pekerjaan sebelumnya karena itu memungkinkan pelatihan lawan untuk tergantung pada kedua ciri-ciri belajar dan prediksi sentimen, untuk meningkatkan diskriminasi untuk perwakilan belajar dalam persediaan saling bahasa. Hasil eksperimen menunjukkan bahwa CLAN melampaui metode sebelumnya pada set data multi-domain Amazon review multibahasa. Kode sumber kita dibebaskan di https://github.com/hemanthkandula/clan.', 'fa': 'تحلیل احساسات برای زبانهای منابع بالا به دلیل موجودات شرکت بزرگی که مشخص شده است، راه طولانی برای زبانهای منابع بالا آمده است. ولی هنوز از دست داده های آموزش برای زبانهای کم منبع درد می یابد. برای حل این مشکل، ما شبکه مبارزه زبان شرایطی (CLAN) را پیشنهاد می\u200cکنیم، یک معماری عصبی برای تحلیل احساسات متوسط زبان بدون مدیریت متوسط زبان. CLAN از کار قبلی تفاوت می\u200cکند که به تمرین دشمنی اجازه می\u200cدهد که بر هر گونه ویژه\u200cهای آموزش یافته و پیش\u200cبینی احساسات وضعیت یافته شود، برای افزایش تفاوتی برای نمایش یافته در تنظیم متوسط زبان یافته شود. نتیجه\u200cهای تجربه نشان می\u200cدهند که CLAN روش\u200cهای قبلی را در مجموعه داده\u200cهای تجربه\u200cهای زیادی دامنه\u200cهای آمازون انجام می\u200cدهد. کد منبع ما در https://github.com/hemanthkandula/clan.', 'ko': '대형 주석 자료 라이브러리의 가용성 때문에 감정 분석은 고자원 언어에서 큰 발전을 이루었다.그러나 저자원 언어의 훈련 데이터가 여전히 부족하다.이 문제를 해결하기 위해 우리는 조건언어대항네트워크(CLAN)를 제시했는데 크로스 언어 감정 분석에 사용되는 단말기부터 단말기까지의 신경 구조로 크로스 언어 감독이 필요 없다.CLAN은 이전 연구와 달리 대항적인 훈련을 통해 학습 특징과 정서 예측을 조건으로 하여 언어 환경에서 학습 표징의 구분성을 높일 수 있다.실험 결과, CLAN은 다국어 다중 도메인 아마존 리뷰 데이터 세트에서 이전 방법보다 성능이 우수한 것으로 나타났다.우리의 원본 코드는https://github.com/hemanthkandula/clan.', 'sw': 'Uchambuzi wa muda mrefu umekuja kwa lugha za rasilimali zilizo juu kutokana na upatikanaji wa kampuni kubwa yenye matatizo. Hata hivyo, bado inaumia kutokuwepo na taarifa za mafunzo kwa lugha ndogo ya rasilimali. Ili kukabiliana na tatizo hili, tunapendekeza Mtandao wa Kimataifa wa Lugha (CLAN), ujenzi wa kisasa wa mwisho wa mwishoni kwa ajili ya uchambuzi wa hisia za lugha tofauti bila kufuatiliwa kwa lugha. CLAN inatofautiana na kazi za kabla katika kuwa inaruhusu mafunzo ya upinzani ya kuhusiana na tabia za kujifunza na utabiri wa hisia, kuongeza ubaguzi wa kujifunza uwakilishi katika mazingira ya lugha mbalimbali. Matokeo ya majaribio yanaonyesha kuwa CLAN inafanya mbinu zilizopita kuhusu taarifa za kurekebisha kwa lugha mbalimbali za Amazon. Kodi letu la vyanzo limetolewa https://github.com/hemanthkandula/clan.', 'sq': 'Analiza e ndjenjave ka ardhur një rrugë të gjatë për gjuhët me burime të larta për shkak të disponueshmërisë së korprave të mëdha të anotuara. Megjithatë, ajo vuan ende nga mungesa e të dhënave të trainimit për gjuhët me burime të ulta. Për të trajtuar këtë problem, propozojmë Rrjetin Kundërshtar të Gjuhave (CLAN), një arkitekturë nervore nga fundi në fund për analizën e ndjenjave ndërgjuhësore pa mbikqyrje ndërgjuhësore. CLAN ndryshon nga puna e mëparshme në atë që lejon trainimin kundërshtar të kushtëzohet si mbi karakteristikat e mësuara ashtu edhe parashikimin e ndjenjave, për të rritur diskriminimin për përfaqësimin e mësuar në ambientin ndërgjuhësor. Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset.  Kodi ynë burimi është lëshuar në https://github.com/hemanthkandula/clan.', 'tr': 'Ýük nähili möhüm bolan korpora ulaşandygyna sebäbi duýgymlyk çykyş diller üçin uzak yönden geldi. Ýöne bu ýerde iň azyk ressurs dilleri üçin maglumatlaryň ýok bolmagyndan täzeden bolýar. Bu meseleyi çözmek üçin, olaryň şartly dil jemgyýetli Network (CLAN), cross-lingual supervision bolmadyk bir nuýral arhitektura teklip edip bilýäris. CLAN öň öňki işden üýtgeşik edýän zada çykyş eğitimi hem öwrenmeli özellikler hem duýgular öňünde, cross-lingual düzeninde öwrenmeli terjime etmek üçin diskriminçylygy artmagy mümkin edýär. Aramanyň netijeleri CLAN multi-dilli Amazon duýdury barlamasynda öňki yönlerden çykarýandygyny görkez. Biziň çeşme kodymyz çykylýar https://github.com/hemanthkandula/clan.', 'am': 'ከፍተኛ የኩነቶች ቋንቋዎች በመጠቀም ምክንያት የሲንሰዓት analysis ረጅም ሆኖአል፡፡ ምንም እንኳን፣ የጎደለኛ ክፍል ቋንቋዎች ዳታዎችን ለማግኘት አይታሰቃትም፡፡ ይህንን ጉዳይ ለመቀናቀል፣ የባሕላዊ ቋንቋ አዳራዊ መረብ (CLAN), የቋንቋ ቋንቋ-ቋንቋ አስተያየት ሳይኖር የመጨረሻ የናውራዊ የመሠረታዊ አካውንተር ለመፍጠር እናቀርባታለን፡፡ CLAN ከቀድሞው ሥራ ይለየዋል፤ በተቃዋሚው ትምህርት እና ማስታወቂያውን በመስቀል ቋንቋ ውስጥ ለመማር መልዕክትን እንዲያበዛ በተቃዋሚ ትምህርት ይጨምርበታል፡፡ ፈተናው ውጤቶች CLAN የቀድሞውን የልዩ ቋንቋ-አሜዞን የዳታ ማተሚያ ማድረጊያውን እንዲያሳየው ያሳያል፡፡ ምንጭ https://github.com/hemanthkandula/clan.', 'af': "Sentiment-analiseer het 'n lang manier gekom vir hoë-hulpbronne tale vanweë die beskikbaarheid van groot aanmerkte korpora. Maar dit lyf nog steeds van die ontbreiding van onderwerp data vir lae-hulpbronne tale. Om hierdie probleem te probeer, voorstel ons die voorwaardige Taal Adversarial Network (CLAN), â\x80\x99n end-to-end neurale arkitektuur vir kruistale sentimentanalisie sonder kruistale supervisie. CLAN is verskillende van voorheede werk in dat dit toelaat dat die teenstandaarlike onderwerking op beide geleerde funksies en die sentiment voorskou moet wees, om diskriminasiteit te verhoog vir geleerde voorstelling in die kruistale opstelling. Eksperimentale resultate bevestig dat CLAN vorige metodes uitvoer op die multi-tale multi-domein Amazon oorskou dataset. Ons bronkode is verlos by https://github.com/hemanthkandula/clan.", 'hy': 'Զգացմունքների վերլուծությունը երկար ճանապարհ է գալիս բարձր ռեսուրսներ ունեցող լեզուների համար, որովհետև մեծ նշումներ ունեցող մարմնի հասանելիությունն է: Այնուամենայնիվ, այն դեռևս տառապում է ցածր ռեսուրսների լեզուների ուսուցման տվյալների բացակայությունից: Այս խնդիրը լուծելու համար մենք առաջարկում ենք պայմանավոր լեզվի հակառակ ցանց, որը վերջ-վերջ նյարդային ճարտարապետություն է լեզվային զգացմունքների վերլուծության համար առանց լեզվի հակառակ վերահսկման: Այն տարբերվում է նախորդ աշխատանքից, որովհետև հնարավորություն է տալիս հակառակյալ վարժումը կախված լինել սովորված հատկանիշների և զգացմունքների կանխատեսման վրա, որպեսզի աճի տարբերակությունը սովորված ներկայացման համար լեզվային միջավայրում: Փորձարկվող արդյունքները ցույց են տալիս, որ կլան արտադրում է նախորդ մեթոդները Amazon բազլեզու բազմաբնույթի վերանայման տվյալների համակարգում: Our source code is released at  https://github.com/hemanthkandula/clan.', 'az': 'Büyük nöqtəli korpora vasitəsilə yüksək ressurs dillərinin istifadə edilməsinin səbəbi təhsil analizi uzun yola gəldi. Ancaq hələ də zəif ressurs dillərinin təhsil edilməsi lazımdır. Bu problemi çəkmək üçün, müddətli Dil Adversarial Network (CLAN) təklif edirik, çox dilli hisslər analizi üçün çox-çox dəlil gözləmədən bir nöral arhitektür. CLAN əvvəlki işlərdən fərqli olar ki, bu təhsil öyrəndiyi təhsil və duyguların təsiri ilə öyrəndiyi təhsil ilə öyrənməsini artırmağa imkan verir. Həqiqətən, CLAN çoxlu dil çoxlu-domani Amazon gözləmə veri quruluğunda əvvəlki metodların üstünlüyünü göstərir. Bizim mənbə kodumuz https://github.com/hemanthkandula/clan.', 'bn': 'সেন্টাইমেন্ট বিশ্লেষণ বিশ্লেষণ হাই-সম্পদ ভাষার জন্য অনেক দীর্ঘ পথ এসেছে বিশাল কোর্পোরার কারণে। তবে এটা এখনো কম সম্পদ ভাষার প্রশিক্ষণের অভাবে কষ্ট পেয়েছে। এই সমস্যার মুখোমুখি হওয়ার জন্য আমরা পরিস্থিতি ভাষা এডভারেরিয়াল নেটওয়ার্ক (সিলান) প্রস্তাব করি, ক্রাশ-ভাষাভাষী পর্যবেক্ষণ ছাড়া একটি শেষ নিউরেল কাঠাম সিলান পূর্বের কাজ থেকে ভিন্ন ভিন্ন যে এটি শিক্ষিত বৈশিষ্ট্য এবং অনুভূতির উপর বিরোধীদের প্রশিক্ষণের সুযোগ প্রদান করে, যাতে ক্রিশ ভাষাভাষার প্রতিনি Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset.  আমাদের উৎস কোড প্রকাশ করা হয়েছে https://github.com/hemanthkandula/clan.', 'bs': 'Analiza osjetljivosti došla je na dug način za jezike visokog resursa zbog raspoloženja velikog annotiranog korporacije. Međutim, još uvijek pati od nedostatka podataka o obuci za jezike niskih resursa. Da bi se riješili ovog problema, predlažemo uslovnu reklamnu mrežu jezika (CLAN), neuralnu arhitekturu kraja do kraja za analizu preko jezika sentimenta bez preko jezika nadzora. CLAN se razlikuje od prethodnog rada u tome što omogućava da se adversarna obuka uvjeti na naučene karakteristike i predviđanje osjećaja, povećava diskriminaciju za naučenu predstavljanje na međujezičkom postavljanju. Eksperimentalni rezultati pokazuju da CLAN nadmašuje prethodne metode na multijezičkom multidomenu Amazon pregledavanje podataka. Naš izvorni kod je objavljen na https://github.com/hemanthkandula/clan.', 'ca': "L'anàlisi dels sentiments ha arribat a un llarg camí per a llengües d'alt recurso degut a la disponibilitat de grans corpores anotats. Tot i així, encara pateix la falta de dades de formació per llengües de baix recursos. Per abordar aquest problema, proposem una Rede Condicional Language Adversary Network (CLAN), una arquitectura neural de final a final per a l'an àlisi del sentiment translingüístic sense supervisió translingüística. CLAN diferèn de la feina anterior en que permet que la formació adversaria sigui condicionada tant per les característiques aprendides com per la predicció del sentiment, per incrementar la discriminació per la representació aprendida en un entorn translingüístic. Els resultats experimentals demostren que CLAN supera els mètodes anteriors en el conjunt de dades multillengües de revisió Amazon. El nostre codi fonts es publica a https://github.com/hemanthkandula/clan.", 'cs': 'Analýza sentimentů ušla dlouhou cestu pro jazyky s vysokými zdroji kvůli dostupnosti velkých anotovaných korpusů. Stále však trpí nedostatkem údajů o odborné přípravě pro jazyky s nízkými zdroji. Pro řešení tohoto problému navrhujeme CONditional Language Adversarial Network (CLAN), komplexní neuronovou architekturu pro analýzu sentimentů mezi jazyky bez nadhledu nad jazyky. CLAN se liší od předchozí práce tím, že umožňuje podmínit adversariální trénink jak na naučených rysech, tak na predikci sentimentu, tak zvýšit diskriminaci pro naučené reprezentace v cross-jazyčném prostředí. Experimentální výsledky ukazují, že CLAN překonává předchozí metody na vícejazyčné vícedoménové sadě recenzí Amazon. Náš zdrojový kód je vydán na adrese: https://github.com/hemanthkandula/clan.', 'et': 'Sentimendianalüüs on suurte märgetega korpuste kättesaadavuse tõttu tulnud suure ressursiga keelte puhul pika tee. Siiski kannatab ta endiselt vähese ressursiga keelte koolitusandmete puudumise tõttu. Selle probleemi lahendamiseks pakume välja Conditional Language Adversarial Network (CLAN), lõpp-otsa neuraalarhitektuuri keeleülese sentimentaalüüsi jaoks ilma keeleülese järelevalveta. CLAN erineb varasematest töödest selles osas, et see võimaldab vastandlikku koolitust sõltuda nii õppinud omadustest kui ka tunnete prognoosimisest, et suurendada diskrimineerimist õppinud esindatuse suhtes keeleüleses keskkonnas. Eksperimentaalsed tulemused näitavad, et CLAN ületab varasemaid meetodeid mitmekeelses mitmedomeenilises Amazoni ülevaateandmekogumis. Meie lähtekood avaldatakse aadressil https://github.com/hemanthkandula/clan.', 'fi': 'Tunteanalyysi on edennyt pitkälle korkean resurssin kielillä suurten merkintöjen ansiosta. Se kärsii kuitenkin edelleen koulutustietojen puutteesta vähävaraisten kielten osalta. Tämän ongelman ratkaisemiseksi ehdotamme Conditional Language Adversarial Network (CLAN), päästä päähän -neuroarkkitehtuuria monikieliseen tunteiden analysointiin ilman monikielistä valvontaa. CLAN eroaa aikaisemmasta työstä siinä mielessä, että se mahdollistaa vastustajan koulutuksen ehdollistamisen sekä opittuihin ominaisuuksiin että tunteiden ennustamiseen, mikä lisää oppitun edustuksen syrjintää kielienvälisessä ympäristössä. Kokeelliset tulokset osoittavat, että CLAN ylittää aiemmat menetelmät monikielisessä Amazon-tarkistusaineistossa. Lähdekoodimme julkaistaan osoitteessa https://github.com/hemanthkandula/clan.', 'jv': 'Sentiment Nanging, mbok saiki durung ono langkung dadi ora ono nggawe datang kanggo langkung Ngawe nglanggar perbudhakan iki, kita ngubah suaraning langkung Advertorial Network (CLAN), architecture end-to-end Neral kanggo ngawe langgar sampeyan seneng dipunanggé kuwi wis ana luwih-luwih bantuan. CLAN Writing direction context menu item Awak dhéwé kelompok punika dipoleh nang https://github.com/hemanthkandula/clan.', 'ha': "Anarari na zaman shawara ya zo da wata hanya mai tsawo wa harshen masu sarki, saboda haka da za'a samu'a da wata firma mai girma. A lokacin da, yana da kuma bã da data na amfani da lugha masu rauni. To, don mu buɗaɗe wa wannan masu husũma, Munã buɗaɗe Shirin Ayuka na Kwamfyuta (CLN), an ƙara-zuwa-ƙarshen matsakan neural dõmin a yi anarwa ga fassarar-harshe bila ya zama mai tsaro na-harshen. CLEN yana sãɓã wa zaman aikin da yake yarda da wa'anar motsi su zama sharri a kan laban zafi da abin da aka sanar da shi na kalmar, dõmin ya ƙara yin takanci wa masu karatun a cikin fassarar-harshen. Cikakken jarrabai ya nuna CCLEN na tafiyar da metoden zaman a kan kure danne-bayani na multiziman-multi-Domen amazon. Kodinmu na'urar da https://github.com/hemanthkandula/clan.", 'sk': 'Analiza čustev je prišla daleč za jezike z visokimi viri zaradi razpoložljivosti velikih korpusov z oznakami. Vendar pa še vedno trpi zaradi pomanjkanja podatkov o usposabljanju za jezike z nizkimi viri. Za reševanje tega problema predlagamo pogojno jezikovno adversarno mrežo (CLAN), celovito nevralno arhitekturo za medjezično analizo sentimentalnih občutkov brez medjezičnega nadzora. CLAN se razlikuje od predhodnega dela v tem, da omogoča, da je kontradiktorsko usposabljanje pogojeno tako z učenimi značilnostmi kot napovedovanjem čustev, da se poveča diskriminativnost za učeno reprezentacijo v medjezičnem okolju. Poskusni rezultati kažejo, da CLAN presega prejšnje metode v večjezičnem večdomenskem naboru podatkov o pregledu Amazon. Naša izvorna koda je objavljena na https://github.com/hemanthkandula/clan.', 'he': 'Sentiment analysis has come a long way for high-resource languages due to the availability of large annotated corpora.  עם זאת, הוא עדיין סובל מחוסר נתוני אימון לשפות משאבים נמוכות. כדי להתמודד עם הבעיה הזאת, אנו מציעים רשת התנגדות לשפה תנאי (CLAN), ארכיטקטורה עצבית סוף-סוף לניתוח רגשות דרך שפתיים ללא פיקוח דרך שפתיים. CLAN שונה מעבודה קודמת כי הוא מאפשר לאימון היריב להיות מונח על שני תכונות למדו וגם על חיזוי הרגשות, כדי לגדל את ההבדל לייצג למדו במסגרת השפה הצלבית. תוצאות ניסיוניות מראות שCLAN מציג שיטות קודמות על קבוצת נתונים של בדיקת אמאזון multilingual multi-domain. קוד המקור שלנו משוחרר ב https://github.com/hemanthkandula/clan.', 'bo': 'ཆུ་ཚོད་ལྟ་ཞིབ་བྱས་ཡོད་པའི་སྐད་རིགས་མཐོ་ཤིག་ཡོད་པའི་སྐད་རིགས་མཐོ་རིང་གི་ཐབས་ལམ་ཞིག་ཡིན། ཡིན་ནའང་། རྒྱ་ནག་ཏུ་ཡན་རྐྱེན་ཆེ་ཆུང་བའི་སྐད་རིགས་ལ་ཆུང་བའི་གནད་དོན་ཡིག་ཆ་ཡང་མེད། To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision. A CLAN Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset. ང་ཚོའི་ཐོག་ཁུངས་ཨང་རྩིས་ཀྱི་ནང་དུ་ཉར་ཚར་བ https://github.com/hemanthkandula/clan.'}
{'en': 'Anlirika : An LSTMCNN Flow Twister for Spoken Language Identification LSTM – CNN  Flow Twister for Spoken Language Identification', 'ar': 'Anlirika: أداة LSTM – CNN Flow Twister لتحديد اللغة المنطوقة', 'fr': "Anlirika\xa0: un Flow Twister LSTM—CNN pour l'identification de la langue parlée", 'es': 'Anlirika: Un flow twister de LSTM-CNN para la identificación del lenguaje hablado', 'pt': 'Anlirika: um LSTM–CNN Flow Twister para identificação de linguagem falada', 'zh': 'Anlirika:LSTM-CNN流捻线器', 'ja': 'Anlirika:口語識別のためのLSTM - CNNフローツイスタ', 'hi': 'Anlirika: बोली जाने वाली भाषा की पहचान के लिए एक LSTM-CNN फ्लो ट्विस्टर', 'ru': 'Anlirika: Вихрь потока LSTM-CNN для идентификации языка речи', 'ga': 'Anlirika: Sreabhadh Twister LSTM-CNN le haghaidh Aitheantas Teanga Labhartha', 'ka': 'Anlirika: LSTM- CNN წყალების გამოსახულებელი ენის იდენტიფიკაციისთვის გამოსახულებელი', 'el': 'Anlirika: Μια συστροφή ροής LSTM-CNN για τον προσδιορισμό της προφορικής γλώσσας', 'lt': 'Anlirika: LSTM-CNN srauto Twister kalbos identifikavimui', 'it': 'An LSTM-CNN Flow Twister for Spoken Language Identification', 'mk': 'Anlirika: An LSTM-CNN Flow Twister for Spoken Language Identification', 'hu': 'Leírás: An LSTM-CNN Flow Twister for Spoken Language Identification', 'mt': 'Anlirika: An LSTM-CNN Flow Twister for Spoken Language Identification', 'mn': 'Анлирика: Супек хэлний идентификацийн LSTM-CNN Flow Twister', 'no': 'Anlirika: Eit LSTM-CNN flytttwister for språk- identifikasjon', 'kk': 'Анлирика: Сызық тіл идентификациясы үшін LSTM- CNN жұмыс Twister', 'pl': 'Anlirika: LSTM-CNN Flow Twister do identyfikacji języka mówionego', 'ro': 'An LSTM-CNN Flow Twister for Spoken Language Identification', 'sr': 'Anlirika: LSTM-CNN Flow Twister za identifikaciju govornog jezika', 'ms': 'Anlirika: An LSTM-CNN Flow Twister for Spoken Language Identification', 'so': 'Anlirika: A LSTM-CNN Flow Twitter for Identification of Luqada', 'si': 'ඇන්ලිරිකා', 'ta': 'அன்லிரியா: பேசும் மொழி அடையாளம் ஒரு LSTM- CNN பாய்வு டுவிஸ்டர்', 'ml': 'ആന്\u200dലിരിക്ക: സംസാരിക്കുന്ന ഭാഷ തിരിച്ചറിയുന്നതിനുള്ള ഒരു LSTM- CNN മഞ്ഞുപാതക ട്ടീസ്റ്റര്\u200d', 'sv': 'Beskrivning: En LSTM-CNN Flow Twister för Spoken Language Identification', 'ur': 'انلیریکا: اسپاک زبان شناسایی کے لئے ایک LSTM-CNN فلو ٹیوسٹر', 'vi': 'Anlirika: An LSD-CNN Flower Twister for spoken language Nhận diện', 'uz': 'Name', 'bg': 'Анлирика: Туистер за поток за идентификация на говоримия език', 'hr': 'Anlirika: LSTM-CNN Flow Twister za identifikaciju govornog jezika', 'id': 'Anlirika: Sebuah LSTM-CNN Flow Twister untuk Identifikasi Bahasa Berbicara', 'ko': 'Anlirika: 구어 인식을 위한 LSTM-CNN 스트리밍 우회 명령', 'fa': 'Anlirika: یک LSTM-CNN Flow Twister برای شناسایی زبان حرف زده', 'da': 'Anmeldelse: An LSTM-CNN Flow Twister for Spoken Language Identification', 'tr': 'Anlirika: Gürjükli Dil Kimligi üçin bir LSTM-CNN Flow Twister', 'nl': 'Anlirika: Een LSTM-CNN flow twister voor gesproken taal identificatie', 'de': 'Anlirika: Ein LSTM-CNN Flow Twister zur Spracherkennung', 'sq': 'Anlirika: An LSTM-CNN Flow Twister for Spoken Language Identification', 'hy': 'Anlirika: An LSTM-CNN Flow Twister for Spoken Language Identification', 'am': 'Anlirika: LSTM-CNN የውሃ ትዊተር', 'bn': 'অ্যানিলিরিয়া: কথোপকথন ভাষা পরিচয়ের জন্য এলস্টিএম-সিএনএন ফুল টুইটার', 'sw': 'Anlirika: Mtumiaji wa Twita wa Mafuriko ya LSTM-CNN kwa ajili ya kutambulisha Lugha ya Mzungumzo', 'ca': 'Anlirika: Un girador de flux LSTM-CNN per identificar la llengua parlada', 'af': "Anlirika: ' n LSTM- CNN vloei Twister vir Spoken Taal Identifikasie", 'az': 'Anlirika: Sözlü Dil Kimlik üçün LSTM-CNN Flow Twister', 'fi': 'Anlirika: LSTM-CNN Flow Twister puhutun kielen tunnistamiseen', 'et': 'Anlirika: LSTM-CNN Flow Twister rääkiva keele tuvastamiseks', 'cs': 'Anlirika: LSTM-CNN Flow Twister pro identifikaci mluveného jazyka', 'bs': 'Anlirika: LSTM-CNN Flow Twister za identifikaciju govornog jezika', 'jv': 'anlirika', 'ha': 'Anlirika: An LstanM-CNN Taiwar ɗin Bayani wa Jarrafi', 'he': 'אנליריקה: טוויסטר זרימת LSTM-CNN לזהות שפה מדברת', 'sk': 'Anlirika: Pretok LSTM-CNN Twister za prepoznavanje govorjenega jezika', 'bo': 'Anlirika: an LSTM-CNN Flow Twister for Spoken Language Identification'}
{'en': 'The paper presents Anlirika’s submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification. The  task  aims at building a  robust system  that generalizes well across different domains and speakers. The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from diverse dataset and multiple speakers. We experiment with a neural system comprising a combination of dense, convolutional, and recurrent layers that are designed to perform better  generalization  and obtain speaker-invariant representations. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging. Our best  system  trained on the  data  augmented with  validation samples  achieves 29.9 %  accuracy  on the test data.', 'ar': 'تقدم الورقة تقديم Anlirika إلى المهمة المشتركة SIGTYP 2021 حول التعرف القوي على اللغة المنطوقة. تهدف المهمة إلى بناء نظام قوي يعمم جيدًا عبر مختلف المجالات والمتحدثين. تقتصر بيانات التدريب على مجال واحد فقط مع متحدث واحد في الغالب لكل لغة بينما يتم اشتقاق عينات بيانات التحقق والاختبار من مجموعة بيانات متنوعة ومتحدثين متعددين. نجرب نظامًا عصبيًا يتألف من مزيج من الطبقات الكثيفة والتلافيفية والمتكررة المصممة لأداء تعميم أفضل والحصول على تمثيلات المتحدث الثابت. نوضح أن المهمة في شكلها المقيد (بدون استخدام البيانات الخارجية أو زيادة مجموعة القطار بعينات من مجموعة التحقق) لا تزال صعبة. إن أفضل نظام لدينا مدرب على البيانات المعززة بعينات التحقق من الصحة يحقق دقة تبلغ 29.9٪ في بيانات الاختبار.', 'fr': "L'article présente la soumission d'Anlirika au SIGTYP 2021 Shared Task on Robust Spoken Language Identification. La tâche vise à créer un système robuste qui généralise bien les différents domaines et intervenants. Les données de formation sont limitées à un seul domaine avec principalement un seul locuteur par langue, tandis que les échantillons de données de validation et de test sont dérivés de divers ensembles de données et de plusieurs locuteurs. Nous expérimentons un système neuronal comprenant une combinaison de couches denses, convolutives et récurrentes conçues pour effectuer une meilleure généralisation et obtenir des représentations invariantes du locuteur. Nous démontrons que la tâche sous sa forme restreinte (sans utiliser de données externes ou augmenter le train de trains avec des échantillons provenant du jeu de validation) reste un défi. Notre meilleur système formé sur les données augmentées par des échantillons de validation atteint une précision de 29,9\xa0% sur les données de test.", 'es': 'El documento presenta la presentación de Anlirika a la tarea compartida SIGTYP 2021 sobre identificación robusta del lenguaje hablado. La tarea tiene como objetivo construir un sistema sólido que generalice bien en diferentes dominios y oradores. Los datos de entrenamiento se limitan a un solo dominio con predominantemente un solo hablante por idioma, mientras que las muestras de datos de validación y prueba se derivan de diversos conjuntos de datos y varios hablantes. Experimentamos con un sistema neuronal que comprende una combinación de capas densas, convolucionales y recurrentes que están diseñadas para realizar una mejor generalización y obtener representaciones invariantes del hablante. Demostramos que la tarea en su forma restringida (sin utilizar datos externos ni aumentar el conjunto de trenes con muestras del conjunto de validación) sigue siendo un desafío. Nuestro mejor sistema entrenado en los datos aumentados con muestras de validación logra una precisión del 29,9% en los datos de prueba.', 'pt': 'O artigo apresenta a submissão da Anlirika ao SIGTYP 2021 Shared Task on Robust Spoken Language Identification. A tarefa visa construir um sistema robusto que generalize bem em diferentes domínios e falantes. Os dados de treinamento são limitados a um único domínio apenas com um único falante predominante por idioma, enquanto as amostras de dados de validação e teste são derivadas de diversos conjuntos de dados e vários falantes. Experimentamos um sistema neural que compreende uma combinação de camadas densas, convolucionais e recorrentes que são projetadas para realizar uma melhor generalização e obter representações invariantes de falante. Demonstramos que a tarefa em sua forma restrita (sem fazer uso de dados externos ou aumentar o conjunto de trens com amostras do conjunto de validação) ainda é desafiadora. Nosso melhor sistema treinado nos dados aumentados com amostras de validação alcança 29,9% de precisão nos dados de teste.', 'ja': 'この論文は、AnlirikaがSIGTYP 2021に提出した、堅牢な口語識別に関する共有タスクを紹介している。このタスクは、さまざまなドメインとスピーカーにわたってよく一般化する堅牢なシステムを構築することを目的としています。トレーニングデータは、言語ごとに主に単一の話者のみを持つ単一のドメインに限定され、検証および試験データサンプルは、多様なデータセットおよび複数の話者に由来する。我々は、より良い一般化を実行し、話者不変の表現を得るように設計された、密度の高い、畳み込み、および再帰的な層の組み合わせを含むニューラルシステムを実験する。制約された形式のタスク（外部データを使用したり、検証セットからのサンプルで列車セットを増強することなく）は依然として困難であることを実証します。検証サンプルで拡張されたデータで訓練された当社の最高のシステムは、試験データで29.9 ％の精度を達成します。', 'hi': 'पेपर मजबूत बोली जाने वाली भाषा पहचान पर SIGTYP 2021 साझा कार्य के लिए Anlirika के प्रस्तुतीकरण को प्रस्तुत करता है। कार्य का उद्देश्य एक मजबूत प्रणाली का निर्माण करना है जो विभिन्न डोमेन और वक्ताओं में अच्छी तरह से सामान्यीकृत करता है। प्रशिक्षण डेटा केवल एक डोमेन तक सीमित है जिसमें मुख्य रूप से प्रति भाषा एकल स्पीकर होता है जबकि सत्यापन और परीक्षण डेटा नमूने विविध डेटासेट और कई वक्ताओं से प्राप्त होते हैं। हम एक तंत्रिका प्रणाली के साथ प्रयोग करते हैं जिसमें घने, कनवल्शनल और आवर्तक परतों का संयोजन होता है जो बेहतर सामान्यीकरण करने और स्पीकर-अपरिवर्तनीय प्रतिनिधित्व प्राप्त करने के लिए डिज़ाइन किए गए हैं। हम प्रदर्शित करते हैं कि अपने विवश रूप में कार्य (बाहरी डेटा का उपयोग किए बिना या सत्यापन सेट से नमूनों के साथ ट्रेन सेट को बढ़ाने के बिना) अभी भी चुनौतीपूर्ण है। सत्यापन नमूनों के साथ संवर्धित डेटा पर प्रशिक्षित हमारी सबसे अच्छी प्रणाली परीक्षण डेटा पर 29.9% सटीकता प्राप्त करती है।', 'zh': '本文引Anlirika向SIGTYP 2021所交稳健口语相识之共同任务。 务在构一统,统在异域演讲者间。 练数止于单个域,每言主于一言者为之,而验测试数据样本自异者数集及数语者。 吾试一神经系统,以密卷积循环层为之,以行其大略而得言者不变也。 吾证约束之务(不用外数、用验集者样本增练集)犹有挑战性。 至善统练于数,而增验样本,致29.9%之准确率于测试数据。', 'ru': 'В документе представлена информация о том, как Анлирика представила SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Задача заключается в создании надежной системы, которая хорошо обобщает данные по различным областям и докладчикам. Обучающие данные ограничиваются одной областью с преимущественно одним диктором на каждый язык, в то время как выборки валидационных и тестовых данных получены из различных наборов данных и нескольких дикторов. Мы экспериментируем с нейронной системой, содержащей комбинацию плотных, сверточных и рекуррентных слоев, которые предназначены для лучшего обобщения и получения динамико-инвариантных представлений. Мы демонстрируем, что задача в ее ограниченном виде (без использования внешних данных или дополнения набора поездов выборками из набора валидации) по-прежнему является сложной. Наша лучшая система, обученная данным, дополненным валидационными образцами, достигает 29,9% точности данных испытаний.', 'ga': "Cuireann an páipéar i láthair aighneacht Anlirika chuig SIGTYP 2021 Tasc Comhroinnte ar Shainaithint Láidir Teangacha. Tá sé mar aidhm ag an tasc córas láidir a thógáil a ghinearálú go maith thar réimsí agus cainteoirí éagsúla. Tá na sonraí oiliúna teoranta d'aon fhearann amháin le cainteoir singil den chuid is mó in aghaidh na teanga agus díorthaítear na samplaí sonraí bailíochtaithe agus tástála ó thacair sonraí éagsúla agus ó chainteoirí iolracha. Déanaimid turgnamh le córas néarach a chuimsíonn meascán de shraitheanna dlúth, réititheacha agus athfhillteacha atá deartha chun ginearálú níos fearr a dhéanamh agus léirithe cainteoir-athraithigh a fháil. Léirímid go bhfuil an tasc ina fhoirm shrianta (gan úsáid a bhaint as sonraí seachtracha nó an fhoireann traenach a mhéadú le samplaí ón tacar bailíochtaithe) fós dúshlánach. Baineann an córas is fearr atá againn oilte ar na sonraí méadaithe le samplaí bailíochtaithe amach cruinneas 29.9% ar na sonraí tástála.", 'hu': 'A tanulmány bemutatja Anlirika benyújtását a SIGTYP 2021 Shared Task on Robust Spoken Language Identification címre. A feladat célja egy robusztus rendszer kialakítása, amely jól általánosítja a különböző területeken és beszélőkön. A képzési adatok csak egyetlen tartományra korlátozódnak, nyelvenként elsősorban egyetlen beszélővel, míg az validálási és tesztadatminták különböző adatkészletekből és több beszélőből származnak. Egy olyan idegrendszerrel kísérletezünk, amely sűrű, konvolúciós és visszatérő rétegek kombinációjából áll, amelyeket úgy terveztek, hogy jobb általánosítást végezzenek és beszélőinvariáns reprezentációkat kapjanak. Bemutatjuk, hogy a feladat korlátozott formájában (külső adatok felhasználása vagy a vonatkészlet mintáival történő bővítése nélkül) továbbra is kihívást jelent. A validálási mintákkal bővített adatokra képzett legjobb rendszerünk 29,9%-os pontosságot biztosít a tesztadatok tekintetében.', 'ka': 'დოკუმენტი აჩვენებს ანლირიკას სიმბოლოდ 2021 წლის საზოგადომი საქაღალდე პრობსტი წლის იდენტიფიკაციაზე. პარამეტრების მიზეზი იქნება ძალიან სისტემის შექმნა, რომელიც განსხვავებული დიომენტების და საუკეთესების განმავლობაში გენერალურება. მონაცემები ერთი დიომენზე დაფარდება მხოლოდ ერთი სიტყვებით ერთი სიტყვებით, როცა განაწყვება და ტესტის მონაცემები განსხვავებული მონაცემებით და მრავალ სიტყვებით დაიწყ ჩვენ ექსპერიმენტირებთ ნეიროლური სისტემით, რომლებიც კომბულურიალური და რეკურველური სისტემის კომბუნციაციას, რომლებიც განაზღვრებულია უფრო მეტად გენერალურად ჩვენ ევმონსტრებით, რომ საქმე მუშაობაში (გარეშე მონაცემების გამოყენება ან გარეშე მონაცემების გამოყენება არაფერად გარეშე მონაცემების გამოყენება) მუშაობაში უკ ჩვენი საუკეთესო სისტემა, რომელიც მონაცემებით გავაკეთებული მონაცემებით გავაკეთებული მონაცემებით გავაკეთებული მონაცემებით 29,9% წარმოდგენა წარ', 'it': "L'articolo presenta la presentazione di Anlirika a SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Il compito mira a costruire un sistema robusto che si generalizzi bene su diversi domini e altoparlanti. I dati di formazione sono limitati a un solo dominio con prevalentemente un singolo parlante per lingua, mentre i campioni di dati di convalida e test sono derivati da diversi set di dati e da più parlanti. Sperimentiamo un sistema neurale comprendente una combinazione di strati densi, convoluzionali e ricorrenti che sono progettati per eseguire una migliore generalizzazione e ottenere rappresentazioni invarianti degli altoparlanti. Dimostriamo che il compito nella sua forma vincolata (senza utilizzare dati esterni o aumentare il set di treni con campioni del set di convalida) è ancora impegnativo. Il nostro miglior sistema addestrato sui dati aumentati con campioni di convalida raggiunge una precisione del 29,9% sui dati di prova.", 'lt': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  Šios užduoties tikslas – sukurti patikimą sistemą, kuri gerokai bendradarbiautų įvairiose srityse ir kalbėtojuose. The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from diverse dataset and multiple speakers.  Eksperimentuojame su nervine sistema, kurią sudaro tankių, konvoliucinių ir pasikartojančių sluoksnių derinys, suprojektuoti siekiant geriau generalizuoti ir gauti kalbėtojų-invariančių atstovavimų. Mes įrodome, kad užduotis ribotos formos (nepasinaudojant išoriniais duomenimis ar didinant traukinio rinkinį mėginiais iš patvirtinimo rinkinio) vis dar yra sudėtinga. Our best system trained on the data augmented with validation samples achieves 29.9% accuracy on the test data.", 'mk': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  The task aims at building a robust system that generalizes well across different domains and speakers.  Податоците за обука се ограничени на еден домен само со претежно еден говорник по јазик, додека примероците за валидација и тестирање на податоците се извлечени од различни податоци и многуте говорници. Експериментираме со нервен систем кој сочинува комбинација на густи, конволуционални и рецидентни слоеви кои се дизајнирани за да извршат подобра генерализација и да добијат интересни претставувања. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging.  Нашиот најдобар систем обучен на податоците зголемени со примероци за валидација постигнува прецизност од 29,9 отсто на податоците за тестот.", 'kk': 'Қағаз Анлириканың SIGTYP 2021- ге ортақ тапсырманы Робуст сөйлейтін тіл идентификациясына жіберіп береді. Тапсырма басқа домендерді және сөйлейтіншілерді жалпы жалпы жүйені құру үшін мақсатты. Оқыту деректері бір доменге шектелген, тек бір тілде тек жалғыз сөйлейтіншісімен, тексеру және сынақтар үлгілері әртүрлі деректер жиындан және бірнеше сөйлейтіншілерден шығарылады. Біз невралдық жүйесіне тәжірибе жақсы жалпы жалпы жалпы түрлендіру үшін құрылған және қайталанатын қабаттардың біріктірілген тәжірибелері бар. Біз тапсырманың шектелген пішінде (сыртқы деректерді қолдану немесе тексеру бағдарламасының үлгілерін қолдану үшін) тапсырманы көрсету мүмкіндікті болады. Біздің ең жақсы жүйеміз тексеру үлгілерімен өзгертілген деректерге оқылған мәліметтердің дұрыстығын 29,9% жеткізеді.', 'ml': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  ഈ ജോലി ഒരു റോബോസ്റ്റ് സിസ്റ്റം ഉണ്ടാക്കുവാന്\u200d ഉദ്ദേശിക്കുന്നു. അത് വ്യത്യസ്ത ഡോമീനുകളിലും സംസാര പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200d വ്യത്യസ്ത ഡാറ്റാസെറ്റില്\u200d നിന്നും വ്യത്യസ്ത ഡാറ്റാസറ്റില്\u200d നിന്നും പല സംസാരികളില്\u200d നിന്നും മാത്രമേ ഒര നമ്മള്\u200d ഒരു പുരുഷന്\u200d സിസ്റ്റത്തിലൂടെ പരീക്ഷിക്കുന്നു. കൂടുതല്\u200d തണുപ്പ്, കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d സംസാരിക്കുന്നതും പ് നിര്\u200dബന്ധിതമായ രീതിയിലുള്ള ജോലി (പുറത്തുള്ള ഡേറ്റാകള്\u200d ഉപയോഗിക്കാതെയോ ഉപയോഗിക്കാതെയോ ട്രെയിനില്\u200d നിന്നും കൂട്ടിച്ചേര്\u200dക് നമ്മുടെ ഏറ്റവും നല്ല പരിശീലന സിസ്റ്റം പരീക്ഷണത്തിന്റെ ഡേറ്റാകള്\u200d കൂട്ടിചേര്\u200dത്തിരിക്കുന്ന ഉപകരണങ്ങളില്\u200d നമ്മുട", 'el': 'Η εργασία παρουσιάζει την υποβολή της Anlirika στην κοινή εργασία για την εύρωστη αναγνώριση της ομιλούμενης γλώσσας. Το έργο στοχεύει στην οικοδόμηση ενός εύρωστου συστήματος που γενικεύεται καλά σε διαφορετικούς τομείς και ομιλητές. Τα δεδομένα εκπαίδευσης περιορίζονται σε έναν μόνο τομέα μόνο με κυρίως έναν ομιλητή ανά γλώσσα, ενώ τα δείγματα δεδομένων επικύρωσης και δοκιμής προέρχονται από διαφορετικό σύνολο δεδομένων και πολλούς ομιλητές. Πειραματιζόμαστε με ένα νευρωνικό σύστημα που αποτελείται από ένα συνδυασμό πυκνών, περίπλοκων και επαναλαμβανόμενων στρωμάτων που έχουν σχεδιαστεί για να εκτελέσουν καλύτερη γενίκευση και να αποκτήσουν αναπαραστάσεις αναλλοίωτες στον ομιλητή. Αποδεικνύουμε ότι η εργασία στην περιορισμένη μορφή της (χωρίς χρήση εξωτερικών δεδομένων ή αύξηση του συνόλου αμαξοστοιχιών με δείγματα από το σύνολο επικύρωσης) εξακολουθεί να είναι πρόκληση. Το καλύτερο σύστημά μας εκπαιδευμένο στα δεδομένα που εμπλουτίζονται με δείγματα επικύρωσης επιτυγχάνει την ακρίβεια 29,9% στα δεδομένα δοκιμής.', 'no': 'Papiret viser Anlirika sin tilføring til SIGTYP 2021 delt oppgåve på robust spoken language identifikasjon. Oppgåva måtar å bygge ein robust system som genereliserer godt over ulike domene og talerar. Øvingsdata er avgrensa til ei enkelt domenet berre med hovudsakelig enkelt taler per språk, mens prøvingsprøvingsparane for validering og testar er avgrensa frå ulike datasett og fleire taler. Vi eksperimenterer med eit neural system som inneheld ein kombinasjon av tett, konvolusjonell og rekurserande lag som er utvikla for å utføra betre generellisering og få opp talinvariant representasjonar. Vi viser at oppgåva i den begrensede formen (utan å bruka eksterne data eller augmentasjon toget sett med prøver frå valeringssettet) er fortsatt vanskeleg. Det beste systemet vårt trengte på data som er økt med prøver på validering, oppnår 29,9% nøyaktighet på testdata.', 'ms': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  The task aims at building a robust system that generalizes well across different domains and speakers.  Data latihan terbatas kepada domain tunggal sahaja dengan penutur tunggal per bahasa semasa sampel data pengesahihan dan ujian dibina dari set data berbeza dan penutur berbilang. Kami eksperimen dengan sistem saraf yang mengandungi kombinasi dari lapisan yang padat, konvolusi, dan berulang yang direka untuk melakukan generalisasi yang lebih baik dan mendapatkan perwakilan berbicara-invarian. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging.  Sistem terbaik kita dilatih pada data yang ditambah dengan sampel pengesahihan mencapai akurasi 29.9% pada data ujian.", 'mt': "Id-dokument jippreżenta s-sottomissjoni ta' Anlirika lis-SIGTYP 2021 Kompitu Konġunt dwar l-Identifikazzjoni b'Saħħitha tal-Lingwa Kkellma. The task aims at building a robust system that generalizes well across different domains and speakers.  Id-dejta tat-taħriġ hija limitata għal dominju wieħed biss b’kelliem wieħed fil-biċċa l-kbira għal kull lingwa filwaqt li l-kampjuni tad-dejta ta’ validazzjoni u ttestjar huma derivati minn sett ta’ dejta varjat u kelliema multipli. Aħna ninsperimentaw b’sistema newrali li tinkludi taħlita ta’ saffi densi, konvoluzzjonali u rikorrenti li huma ddisinjati biex iwettqu ġeneralizzazzjoni a ħjar u jiksbu rappreżentazzjonijiet invarji tal-kelliema. Aħna nuru li l-kompitu fil-forma ristretta tiegħu (mingħajr l-użu ta’ dejta esterna jew l-augmentazzjoni tas-sett tal-ferrovija b’kampjuni mis-sett ta’ validazzjoni) għadu ta’ sfida. Our best system trained on the data augmented with validation samples achieves 29.9% accuracy on the test data.", 'pl': 'W artykule przedstawiono zgłoszenie Anliriki do SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Celem zadania jest zbudowanie solidnego systemu, który dobrze uogólnia się w różnych dziedzinach i mówcach. Dane szkoleniowe są ograniczone do jednej domeny tylko z głównie jednym mówcą na język, podczas gdy próbki walidacji i danych testowych pochodzą z różnego zbioru danych i wielu mówców. Eksperymentujemy z układem neuronowym składającym się z połączenia gęstych, konwolucyjnych i powtarzających się warstw, które są zaprojektowane w celu lepszego uogólnienia i uzyskania reprezentacji niezmiennych dla mówców. Wykazujemy, że zadanie w jego ograniczonej formie (bez wykorzystania zewnętrznych danych lub rozszerzania zestawu pociągów o próbki z zestawu walidacji) nadal jest wyzwaniem. Nasz najlepszy system przeszkolony na danych uzupełniony o próbki walidacyjne osiąga 29,9% dokładności danych testowych.', 'mn': 'Энэ цаас Анлирикийн SIGTYP 2021 онд Робуст Супекийн хэлний идентификацийн хуваалтын ажлыг илтгэдэг. Үүний зорилго нь өөр хэсэг, илтгэгчдийн ерөнхийлөгч бүтээмжтэй системийг бүтээх зорилго юм. Сургуулийн өгөгдлийн мэдээллийг зөвхөн нэг хэл дээр ганц илтгэгч гэдэгт хязгаарлагддаг. Гэхдээ мэдээллийн жишээ нь олон өгөгдлийн хэлбэрээс болон олон илтгэгч гэдэг. Бид мэдрэлийн системтэй туршилт хийдэг нь илүү өндөр ерөнхийлөгч болон илтгэгчийн хүчирхийлэлтэй төлөвлөгөө гаргах зориулагдсан жинхэнэ, ховорхой, дахин дахин дахин дахин нийлүүлэгддэг. Бид үүнийг хязгаарлагдсан хэлбэрийн ажил (гадаад өгөгдлийг ашиглахгүй эсвэл давхарлах хэлбэрээс газрын өгөгдлийг нэмэгдүүлэхгүй) гэдгийг харуулж байна. Бидний хамгийн шилдэг систем шалгалтын өгөгдлийн тодорхойлолт дээр нэмэгдсэн мэдээлэл дээр шалгалтын өгөгдлийн тодорхойлолт 29.9%-ийг гаргадаг.', 'si': "The paper s presents Anlica's Sub-ssion to SIGTYP 2021 shared Job on Robst Spoken language ID. මේ වැඩේ අල්ලගන්නවා වෙනස් දේමින් සහ කතාකරුවන්ට සාමාන්\u200dය විදියට හොඳ විදියට පද්ධතියක් හදන්න. ප්\u200dරශ්නය දත්ත සීමාවිත විවිධ දත්ත සැමැලුම් වලින් විවිධ දත්ත සැමැලුම් සහ විවිධ සැමැලුම් වලින් භාෂාවට ප්\u200dරශ්න අපි පරීක්ෂණය කරන්නේ න්\u200dයූරල් පද්ධතියෙන් ප්\u200dරයෝජනයක් සමග සංවිධානය, සංවිධානය සහ ප්\u200dරයෝජනයක් සමග සංවිධානය කරනවා හ අපි ප්\u200dරකාශ කරනවා එයාගේ අවධානයක් තියෙන වැඩය (ප්\u200dරතිදේශ දත්ත නැතුව නැතුව නැතුව ප්\u200dරයෝජනය කරලා ප්\u200dරයෝජනය සමග සැමැල් අපේ හොඳම පද්ධතිය පරීක්ෂණ දත්ත විශේෂ කරලා තියෙන්නේ සැමැල්ම් වලින් විශේෂ කරලා තියෙන්නේ, පරීක්ෂණ", 'so': 'Warqadda waxaa soo bandhigaya Anlirika uu u soo diro SIGTYP 2021 Shaqada loo sharciyey aqoonsiga luqada Robust. Shaqada waxaa loogu talogalay in uu dhiso nidaam la dhacay oo si wanaagsan ugu soo kordha meelaha kala duduwan iyo kuwa hadla. Macluumaadka waxbarashadu waxay ku xadan yihiin hal domain oo kaliya oo ku qoran hadal keliya oo luuqad ah, isla markaasna sameynta imtixaanka iyo imtixaanka macluumaadka waxaa laga helaa kooban macluumaad kala duduwan iyo hadal badan. Waxaan ku jirrabnaa nidaam neurada ah oo ku qoran isku xiran, isku qasnaan, iyo xarumo soo socda oo loo qoray in la sameeyo dhalashada iyo in lagu helo noocyo ka mid ah dadka hadalka ku hadlaya. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging.  Tiradayada ugu wanaagsan ee lagu tababaray samooyinka xaqiijinta waxay gaadhaa 29.9% saxda macluumaadka imtixaanka.', 'ta': 'இந்த தாள் அன்லிரியா SIGTYP 2021 பகிர்ந்த பணிக்கு அனுப்புகிறது ரோப்ஸ்ட் பேச்சு மொழி அடையாளம் மூலம். இந்த செயல் ஒரு ராப்ட் அமைப்பை உருவாக்குவதற்கு எதிர்பார்க்கிறது அது வேறு தளங்கள் மற்றும் பேச்சாளர்கள் ம பயிற்சி தகவல் ஒரு களம் மட்டும் மொழிக்கு முக்கியமாக ஒரு பேச்சாளர் மட்டும் மட்டும் வரையறுக்கப்பட்டுள்ளது, செலுத்துதல் மற்றும் சோதனை தரவு ம நாம் ஒரு புதிய முறைமையில் சோதனைப்படுத்துகிறோம் கூட்டத்திற்கு, கூட்டத்திற்கு, மீண்டும் திரும்ப அடுக்குகளை சிறந்த பொதுவாக்கி  நாம் அதன் கட்டுப்படுத்தப்பட்ட வடிவத்தில் பணியை காட்டுகிறோம் (வெளி தரவுகளை பயன்படுத்தாமல் அல்லது மாதிரிகளில் இருந்து மாதிரி அமைக்கப்பட்டது  Our best system trained on the data augmented with validation samples achieves 29.9% accuracy on the test data.', 'sv': 'Uppsatsen presenterar Anlirikas bidrag till SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Uppgiften syftar till att bygga ett robust system som generaliserar väl över olika domäner och talare. Utbildningsdata är begränsade till en enda domän med huvudsakligen en talare per språk medan validerings- och testdataproverna härrör från olika datamängder och flera talare. Vi experimenterar med ett neuralt system som består av en kombination av täta, konvulutionella och återkommande lager som är utformade för att utföra bättre generalisering och erhålla högtalarinvarianta representationer. Vi visar att uppgiften i sin begränsade form (utan att använda externa data eller utöka tågsatsen med prover från valideringssatsen) fortfarande är utmanande. Vårt bästa system som utbildats på data förstärkta med valideringsprover uppnår 29,9% noggrannhet på testdata.', 'ro': 'Lucrarea prezintă depunerea Anlirika la SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Sarcina urmărește construirea unui sistem robust care să generalizeze bine în diferite domenii și vorbitori. Datele de formare sunt limitate la un singur domeniu numai cu predominant un singur vorbitor pe limbă, în timp ce eșantioanele de date de validare și testare provin din seturi de date diverse și mai mulți vorbitori. Experimentăm cu un sistem neural care cuprinde o combinație de straturi dense, convoluționale și recurente, concepute pentru a efectua o mai bună generalizare și pentru a obține reprezentări invariante ale vorbitorilor. Demonstrăm că sarcina în forma sa constrânsă (fără a utiliza date externe sau fără a mări setul de trenuri cu eșantioane din setul de validare) este încă o provocare. Cel mai bun sistem al nostru instruit pe datele amplificate cu probe de validare atinge o precizie de 29,9% a datelor de testare.', 'sr': 'U novinama se predstavlja podnošenje Anlirike na podnošenje SIGTYP 2021. podeljenog zadatka o identifikaciji robotnog govornog jezika. Taj zadatak je cilj da izgradi roban sistem koji generalizuje dobro preko različitih domena i govornika. Podaci o obuci ograničeni su na jedinstvenu domenu samo sa predominantno jednom govornikom po jeziku dok se uzorci podataka o validaciji i testiranju proizvode iz različitih seta podataka i višestrukih govornika. Eksperimentiramo sa neuralnim sistemom koja sastoji kombinaciju gustih, konvolucionih i rekonstrucionih slojeva koji su dizajnirani da izvedemo bolju generalizaciju i dobijemo invalidne predstave govornika. Pokazujemo da je zadatak u njegovoj ograničenoj formi (bez upotrebe vanjskih podataka ili povećanja vlaka postavljenog sa uzorcima iz seta validacije) još uvek izazovan. Naš najbolji sistem obučen na podacima povećanim uzorcima validacije postiže tačnost 29,9% na testovima.', 'ur': 'اس کاغذ نے انلیریکا کا SIGTYP 2021 میں مشترک ٹاکس کی تصدیق کرتا ہے۔ اس کام کا ارادہ ہے ایک مضبوط سیستم بنانے کی جگہ جو مختلف دامنین اور صحبت کرنے والوں میں اچھی طرح کامل کرتا ہے. تدریس دیٹا ایک ڈومین تک محدود ہے صرف ایک زبان میں ایک صحبت کرنے والے کے ساتھ، حالانکہ وکیل اور امتحان دیٹا نمونے مختلف ڈاٹ سٹ اور بہت سے صحبت کرنے والوں سے آتے ہیں. ہم ایک نئورل سیستم کے ساتھ آزمائش کرتے ہیں جس میں ایک گہرے, کنvolutional اور دوبارہ لہروں کی ترکیب ہے جو اچھی عمومی ترکیب کرنے کے لئے طراحی کی گئی ہیں اور اسپیکر-غیر غیر غیر غیر معجزات حاصل کرنے کے لئے۔ ہم دکھاتے ہیں کہ اس کے محدود فرم میں کام (بغیر بیرون ڈاٹ یا افزایش کے ساتھ ٹرین سیٹ کے نمونے کے ساتھ) یہاں تک بھی مشکل ہے۔ ہماری بہترین سیستمہ تدریس کی جگہ دی گئی ڈیٹا پر جو مطالب نمونے کے ساتھ اضافہ کی گئی تھی، آزمائش ڈیٹا پر 29.9% دقیق پہنچتی ہے۔', 'vi': 'Dự án công bố việc yêu cầu Anlirika chịu trách nhiệm SIDYP 2021 s ẻ chia sẻ Nhiệm vụ nhận diện ngôn ngữ Xà Ngữ. Nhiệm vụ nhằm mục đích xây dựng một hệ thống mạnh mẽ phổ biến rộng khắp các lĩnh vực và diễn giả. Thông tin về huấn luyện chỉ có một miền duy nhất với chủ yếu người phát ngôn cho mỗi ngôn ngữ trong khi các mẫu dữ liệu xác thực và thử nghiệm được lấy từ nhiều bộ dữ liệu khác nhau và nhiều người nói. Chúng ta thử nghiệm với hệ thần kinh bao gồm một sự kết hợp của các lớp dày đặc, xoắn ốc và các lớp quy định thường xuyên được thiết kế để tiến hành tổng hợp tốt hơn và có các biểu hiện loa-invariant. Chúng tôi chứng minh rằng nhiệm vụ trong dạng hạn chế (không sử dụng dữ liệu bên ngoài hay tăng trưởng bộ tàu với mẫu từ bộ sửa chữa) vẫn chưa được hoàn thành. Hệ thống tốt nhất được huấn luyện về dữ liệu gia tăng với các mẫu xác thực đạt độ chính xác tại 29.9.97 trên dữ liệu thí nghiệm.', 'uz': "Hujjatni Robust tilni aniqlash uchun SIGTYP 2021 bilan bogʻliq vazifani Anlirika ishga tayyorlaydi. Bu vazifa boshqa domen va gapiruvchilar bilan yaxshi ko'paytirish uchun robot tizimni yaratishga ega bo'ladi. Taʼminlovchi maʼlumot faqat bir xil domen tilda bir necha gapiruvchi bilan bir xil gapiruvchiga qaraydi. Biz bir necha taraf tizim bilan birlashtirish va davom etadigan qatlamlar bilan birlashtirish imtiyozni beramiz. Ular yaxshi generalisini bajarish va gapiruvchi qiymatiga ega bo'lgan qatlamlarni olish uchun qanday qilamiz. Biz bu vazifani qanday shaklga ko'rsatamiz (tashqi maʼlumotdan foydalanuvchi yoki misollarni yozib qo'shish mumkin) hosil qiladi. Bizning eng yaxshi tizimmiz haqiqiqiylik misollari bilan ishlatilgan maʼlumotlar sohasida 29.9% tizimni tekshirish maʼlumotga yetardi.", 'da': 'Artiklen præsenterer Anlirikas indlæg til SIGTYP 2021 Shared Task on Robust Talken Language Identification. Opgaven sigter mod at opbygge et robust system, der generaliserer godt på tværs af forskellige domæner og talere. Træningsdataene er begrænset til et enkelt domæne med overvejende én taler pr. sprog, mens validerings- og testdataprøverne stammer fra forskellige datasæt og flere talere. Vi eksperimenterer med et neuralt system bestående af en kombination af tætte, konvulutive og tilbagevendende lag, der er designet til at udføre bedre generalisering og opnå taler-invariant repræsentationer. Vi demonstrerer, at opgaven i sin begrænsede form (uden at bruge eksterne data eller udvidelse af togsættet med prøver fra valideringssættet) stadig er udfordrende. Vores bedste system, der er uddannet på data forstærket med valideringsprøver, opnår 29,9% nøjagtighed på testdata.', 'hr': 'U novinama se predstavlja podnošenje Anlirike podatku SIGTYP 2021. zajedničkom zadatku o jakoj identifikaciji jezika. Cilj zadataka je izgradnja robnog sustava koji generalizira dobro u različitim domenama i govornicima. Podaci o obuci ograničeni su na jednom domenu samo s predominantno jednom govornikom po jeziku, dok se uzorci podataka o validaciji i testiranju nalaze iz različitih seta podataka i višestrukih govornika. Eksperimentiramo s nervnim sustavom koji sastoji kombinaciju gustih, konvolucionalnih i rekonstruiranih slojeva koji su dizajnirani kako bi izvršili bolju generalizaciju i dobili neprijateljske predstave govornika. Pokazujemo da je zadatak u njegovom ograničenom obliku (bez upotrebe vanjskih podataka ili povećanja vlaka postavljenog s uzorcima iz seta validacije) još uvijek izazovan. Naš najbolji sustav obučen na podacima povećanim s uzorcima validacije postiže točnost 29,9% na testnim podacima.', 'bg': 'Статията представя представянето на Анлиика в Споделена задача за стабилна говорена езикова идентификация. Задачата е насочена към изграждане на здрава система, която обобщава добре в различни области и говорители. Данните за обучение са ограничени до един домейн само с преобладаващо един говорител на език, докато пробите от данни за валидиране и тестване се извличат от различни набори от данни и множество говорители. Експериментираме с невронна система, състояща се от комбинация от гъсти, конволюционни и повтарящи се слоеве, които са предназначени да извършват по-добра обобщаване и получаване на инвариращи представяния на говорителя. Доказваме, че задачата в ограничената си форма (без използване на външни данни или увеличаване на влаковата група с образци от комплекта за валидиране) все още е предизвикателство. Нашата най-добра система, обучена върху данните, допълнени с проби за валидиране, постига 29,9% точност на данните от теста.', 'de': 'Der Beitrag stellt Anlirikas Einreichung bei SIGTYP 2021 Shared Task on Robust Spoken Language Identification vor. Die Aufgabe zielt darauf ab, ein robustes System zu entwickeln, das sich gut über verschiedene Domänen und Sprecher hinweg verallgemeinern lässt. Die Trainingsdaten beschränken sich auf eine einzige Domäne mit überwiegend einem Sprecher pro Sprache, während die Validierungs- und Testdatenproben aus verschiedenen Datensätzen und mehreren Sprechern abgeleitet werden. Wir experimentieren mit einem neuronalen System, das aus einer Kombination von dichten, convolutionalen und rezidivierenden Schichten besteht, die entworfen sind, um eine bessere Verallgemeinerung durchzuführen und Sprecher-invariante Darstellungen zu erhalten. Wir zeigen, dass die Aufgabe in ihrer eingeschränkten Form (ohne Verwendung externer Daten oder Erweiterung des Zugsatzes mit Proben aus dem Validierungssatz) immer noch herausfordernd ist. Unser bestes System, das auf den mit Validierungsmustern angereicherten Daten geschult ist, erreicht 29,9% Genauigkeit der Testdaten.', 'ko': '본고는 앤리리카가 SIGTYP 2021에 제출한 루팡 구어 식별에 대한 공유 임무를 소개한다.이 임무의 목적은 건장한 시스템을 구축하여 서로 다른 분야와 말하는 사람에게 잘 보급하는 것이다.훈련 데이터는 단일 영역에만 한정되고 각 언어의 언어는 주로 한 사람이며 데이터 샘플을 검증하고 테스트하는 것은 서로 다른 데이터 집합과 여러 명의 언어에서 나온다.우리는 밀집층, 권적층, 귀속층으로 구성된 신경계통으로 실험을 진행했는데, 이 층들은 더욱 잘 범화되고 말하는 사람의 변하지 않는 표시를 얻기 위해 설계되었다.우리는 제약 형식의 임무(외부 데이터를 사용하지 않거나 검증 집중된 샘플을 사용하여 훈련 집합을 확장하는 것)가 여전히 도전적이라는 것을 증명했다.우리의 가장 좋은 시스템은 데이터 교육을 거쳐 검증 견본을 추가하여 테스트 데이터의 정확도가 29.9%에 달한다.', 'fa': 'این کاغذ تحویل آنلیریکا را به کارهای مشترک SIGTYP 2021 در مورد شناسایی زبان سخت\u200cگویی نشان می\u200cدهد. این وظیفه هدف دارد که یک سیستم قوی ساخته شود که در سرزمینه های مختلف و صحبت کننده\u200cها خیلی خوب متفاوت می\u200cکند. داده\u200cهای آموزش به یک دامنه محدود است تنها با کلی یک صحبت\u200cکننده در هر زبان در حالی که نمونه\u200cهای داده\u200cهای تصدیق و آزمایش از مجموعه\u200cهای داده\u200cهای مختلف و متعدد صحبت\u200cکننده\u200cاند. ما با یک سیستم عصبی آزمایش می کنیم که شامل یک ترکیب از لایه\u200cهای گسترده، گسترده و دوباره\u200cای است که طراحی شده\u200cاند تا عمومی بهتر انجام دهند و نمایش\u200cهای غیرقابل صحبت کننده را دریافت کنند. ما نشان می دهیم که کار در شکل محدودیت آن (بدون استفاده از داده های خارجی یا افزایش دادن قطار با نمونه\u200cهای از مجموعه تصدیق) هنوز سخت است. بهترین سیستم ما روی اطلاعات آموزش داده شده که با نمونه های تأیید افزایش شده، دقیق 29.9 درصد در داده های تأیید را می رساند.', 'nl': "Het artikel presenteert Anlirika's inzending aan SIGTYP 2021 Shared Task on Robust Spoken Language Identification. De taak is gericht op het bouwen van een robuust systeem dat goed generaliseert over verschillende domeinen en sprekers. De trainingsgegevens zijn beperkt tot een enkel domein met overwegend één spreker per taal terwijl de validatie- en testdata voorbeelden zijn afgeleid van diverse datasets en meerdere sprekers. We experimenteren met een neuraal systeem dat bestaat uit een combinatie van dichte, convolutionele en terugkerende lagen die zijn ontworpen om betere generalisatie uit te voeren en spreker-invariante representaties te verkrijgen. We tonen aan dat de taak in zijn beperkte vorm (zonder gebruik te maken van externe data of uitbreiding van de treinset met monsters uit de validatieset) nog steeds uitdagend is. Ons beste systeem getraind op de gegevens aangevuld met validatiemonsters bereikt 29,9% nauwkeurigheid op de testgegevens.", 'tr': 'Kagyzyň Anlirikanyň SIGTYP 2021-e paýlaşmaly dil kimligi barada paýlaşmaly işi görkezýär. Bu zadyň maksady beýleki alanlaryň we güýçli bir sistemasy guramagy maksady. Görniş maglumaty diňe dilde ýekeje sözler bilen mümkin edýän bir domena mümkin edýän data düzümlerinden we köp sözleri bilen mümkin edýän. Biz bir nöral sistemi ile deneyler, çöplük, gönüllük ve tekrarlı katlardan oluşan, daha iyi generalizasyon etmäge tasarlanmış ve konuşmak zorunda ifade etmek için tasarlanmış bir nöral sistemi ile deneyler yapıyoruz. Biz bu işiň çykyş şeklinde (daşaryk maglumatlary ýöne ulanmadyk ýa-da otlyň düzümleri bilen örän möhüm şeklinde) häli kynçylyklygyny görkeýäris. Bizim iň gowy sistemimiz teste verilerinde 29.9% dogrylygyny bilen daýatma örnekleri bilen gelişmiş verilerde eğitildi.', 'id': 'Kertas ini menunjukkan pengiriman Anlirika ke SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Tugas ini bermaksud membangun sistem yang kuat yang menyebar dengan baik di berbagai daerah dan pembicara. The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from diverse dataset and multiple speakers.  Kami bereksperimen dengan sistem saraf yang mengandung kombinasi dari lapisan yang padat, konvolusi, dan rekuren yang direncanakan untuk melakukan generalisasi yang lebih baik dan mendapatkan representati speaker-invariant. We demonstrate that the task in its constrained form (without making use of external data or augmentation the train set with samples from the validation set) is still challenging.  Sistem terbaik kami dilatih pada data yang ditambah dengan sampel validasi mencapai akurasi 29,9% pada data ujian.', 'am': 'የፕሬዝቡ ጉዳዩ በሮቦስት ንግግር ቋንቋ ማግኘት ላይ የSIGTYP 2021 ስራዎችን ለቀልጠዋል፡፡ ስራው በተለየ ውይይቶች እና በተናገሩ አካባቢዎች ላይ መልካም የሚያደርገውን የረጢት ስርዓት መሥራት ነው፡፡ የግንኙነት ዳታ ዳታዎች በተለየ የዳታ setup እና በብዙ ንግግር የሚናገሩ ከቋንቋ ብቻ በቀር አንድ ዶሜን ነው፡፡ በጥልቅ፣ ጉዳይ እና በተደጋጋጋሚ ደረጃዎች እና በተደጋጋጋሚ አካባቢ እና በንግግር-ተቃራኒ መልዕክቶችን ለማግኘት በተመሳሳይ የደብዳቤ ስርዓት እናሞክራለን፡፡ ስራውን በተጠበቀው ፎርማት እናሳየዋለን (ውጭ ዳታዎችን ወይም ምሳሌዎችን በማጠቀም ወይም በመጨመር ላይ የተደረገውን train) ገና የሚከራከር ነው፡፡ የመድረክ ምሳሌዎች በተጨማሪው ዳራዎችን የተማሩ የስርዓታችን ስርዓት በፈተናው ዳታ ላይ 29.9 በመቶ እርግጠኛ ነው፡፡', 'sw': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  Kazi hii inakusudia kutengeneza mfumo wa udanganyifu unaotengeneza vizuri katika maeneo mbalimbali na wazungumzaji. Takwimu za mafunzo zinazuiwa kwenye eneo moja tu ambalo husika moja kwa moja kwa lugha wakati sampuli za taarifa zinazothibitishwa na jaribio zinatoka kwenye seti mbalimbali za taarifa na hotuba kadhaa. Tunajaribu na mfumo wa neura unaohusisha muunganiko wa uchungu, na vipande vinavyoendelea ambavyo vinaendelea kutengeneza vizuri zaidi na kupata uwakilishi wa mazungumzo. Tunaonyesha kwamba jukumu hili linalolazimika (bila kutumia data za nje au kuongeza treni iliyoandaliwa na sampuli kutoka kwenye seti ya uhakika) bado inachangamoto. Mfumo wetu bora ulioelekezwa kwenye takwimu zilizoongezwa kwa sampuli za uhakika unafikia asilimia 29.9 kuhusiana na taarifa za jaribio.", 'sq': 'Gazeta paraqet paraqitjen e Anlirikës në SIGTYP 2021 Task Shared on Robust Spoken Language Identification. Detyra synon të ndërtojë një sistem të fortë që gjeneralizohet mirë nëpër fusha dhe fletës të ndryshme. Të dhënat e stërvitjes janë të kufizuara në një domeni të vetëm me kryesisht një folës për gjuhë ndërsa moshat e të dhënave të vlerësuara dhe të testuara nxirren nga grupe të dhënash të ndryshme dhe fletës të shumta. Ne eksperimentojmë me një sistem nervor që përbëhet nga një kombinim i shtresave të dendura, konvolutive dhe të përsëritura që janë dizajnuar për të kryer gjeneralizimin më të mirë dhe për të marrë përfaqësime të folurit-invariant. Ne demonstrojmë se detyra në form ën e saj të kufizuar (pa përdorur të dhënat e jashtme apo rritjen e trenit me shembuj nga grupi validimi) është ende e vështirë. Sistemi ynë më i mirë i trajnuar në të dhënat e rritura me mostrat e vlerësimit arrin 29.9% saktësi në të dhënat e testit.', 'hy': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  Այս խնդիրը նպատակն է ստեղծել ուժեղ համակարգ, որը լավ ընդհանուր է տարբեր ոլորտներում և խոսնակներում: Պատրաստման տվյալները սահմանափակվում են միայն մեկ ոլորտում, որտեղ յուրաքանչյուր լեզվի ընդհանուր մասամբ մեկ խոսնակ է, մինչդեռ հավասարման և փորձարկման տվյալների նմուշները տարբեր տվյալների համակարգում և բա Մենք փորձում ենք նյարդային համակարգի հետ, որը կազմում է խտություն, հակադարձ և կրկնօրինակ շերտերի համակցություն, որոնք նախագծված են ավելի լավ ընդհանուր գործողությունների կատարելու և խոսացողի-անընդհատ ներկայացման համար: Մենք ցույց ենք տալիս, որ խնդիրը իր սահմանափակ ձևով (առանց օգտագործելու արտաքին տվյալներ կամ աճեցնելու գնացքի համակարգը հավասարման համակարգից նմուշներով) դեռևս դժվար է: Մեր լավագույն համակարգը, որը պատրաստված է հավասարման նմուշներով ավելացված տվյալների վրա, ստանում է 29.9 տոկոս ճշգրտություն թեստի տվյալների վրա:", 'az': "Kağıt Anlirika'nın SIGTYP 2021 ilə robust Spoken Dil Kimlikləri barəsində paylaşılmış işi göstərir. Bu işin müxtəlif domenalar və danışanlar arasında güclü bir sistem inşa etmək məqsədildir. Bu təhsil məlumatları yalnız dildə təkrar təkrar bir domena müəyyən edilmişdir, çünki təhsil və sınama məlumatları müxtəlif veri setindən və çoxlu danışanlardan təkrar edilmişdir. Biz bir nöral sistemi ilə təcrübə edirik ki, daha yaxşı generalizasyon və danışmaq üçün müəyyən edilən yoxlu, konvoluksiyonlu və yenidən təcrübə düzəltmək üçün müəyyən edilmiş və danışmaq istisna olmaqla birlikdə istifadə edilir. Biz göstəririk ki, bu işin sıxıntılı formasında (dış verilən məlumatları istifadə etmədən və ya müəyyən edilən trenin nümunələri ilə birlikdə yüksələnmədən) hələ də çətin deyildir. Ən yaxşı sistemimiz təhsil edilən məlumatların üstünlüyündə təhsil edilən təhsil məlumatlarından 29.9% təhsil edər.", 'bs': 'U novinama se predstavlja podnošenje Anlirike podatku SIGTYP 2021. zajedničkom zadatku o identifikaciji robotnog govornog jezika. Taj zadatak je cilj izgradnje robnog sistema koji generalizuje dobro u različitim domenama i govornicima. Podaci o obuci ograničeni su na jedinstvenu domenu samo sa predominantno jednom govornikom po jeziku dok se uzorci podataka o validaciji i testiranju proizvode iz različitih seta podataka i višestrukih govornika. Eksperimentiramo sa neuralnim sistemom koja sastoji kombinaciju gustih, konvolucionih i rekonstruiranih slojeva koji su dizajnirani da izvedemo bolju generalizaciju i dobijemo invalidne predstave govornika. Pokazujemo da je zadatak u njegovoj ograničenoj formi (bez upotrebe vanjskih podataka ili povećanja vlaka postavljenog sa uzorcima iz seta validacije) još uvijek izazovan. Naš najbolji sustav obučen na podacima povećanim uzorcima validacije postiže točnost 29,9% na testovima.', 'ca': "El paper presenta la presentació d'Anlirika a SIGTYP 2021 Task Shared on Robust Spoken Language Identification. La tasca té l'objectiu de construir un sistema robust que s'generalitze bé a través de dominis i parlants diferents. Les dades d'entrenament estan limitades a un únic domini amb predominantement un únic parlant per llengua mentre les mostres de dades de validació i prova es deriven de diversos conjunts de dades i múltiples parlants. Experimentem amb un sistema neural que consisteix en una combinació de capes denses, convolucionals i recurrents dissenyades per a fer millor generalització i obtenir representacions invariants per parlar. Demostram que la tasca en forma limitada (sense utilitzar dades externes o augmentar el tren amb mostres del conjunt de validació) encara és difícil. El nostre millor sistema entrenat en les dades augmentates amb mostres de validació aconsegueix una precisió del 29,9% en les dades de prova.", 'af': "Die papier stel Anlirika se onderskrywing aan SIGTYP 2021 Gedeelde Opdrag op Robust Spoken Taal Identifikasie voorsien. Die taak doel om 'n kragtige stelsel te bou wat goed oor verskillende domeine en sprekkers genereer. Die oefening data is beperk na 'n enkele domein slegs met voordeel enkel sprekker per taal terwyl die geldigheid en toets data voorbeelde van verskeie datastel en veelvuldige sprekkers afgelei word. Ons eksperimenteer met 'n neurale stelsel wat 'n kombinasie van dens, konvolusionele en herhaalde laagte wat ontwerp word om beter generalisering te doen en sprekker-invariant voorstellings te kry. Ons wys dat die taak in sy beperkte vorm (sonder om eksterne data of vergroot te gebruik die trein stel met voorbeelde van die geldigheidstel) nog steeds uitgelaat is. Ons beste stelsel opgelei op die data wat met geldigheidsverbeelde vergroot is, bereik 29.9% presies op die toets data.", 'cs': 'Příspěvek představuje Anliriku podání SIGTYP 2021 Shared Task on Robust Spoken Language Identification. Cílem úkolu je vytvořit robustní systém, který se dobře zobecňuje napříč různými doménami a mluvčími. Data tréninku jsou omezena na jednu doménu pouze s převážně jedním mluvčím na jazyk, zatímco vzorky validačních a testovacích dat jsou odvozeny z různých datových sad a více mluvčích. Experimentujeme s neuronovým systémem sestávajícím z kombinace hustých, konvolučních a recidivujících vrstev, které jsou navrženy tak, aby prováděly lepší zobecnění a získaly reprezentaci invariantní řečníka. Dokazujeme, že úloha v omezené podobě (bez využití externích dat nebo rozšíření vlakové sady o vzorky z validační sady) je stále náročná. Náš nejlepší systém vyškolený na datech doplněných o validační vzorky dosahuje 29,9% přesnosti testovacích dat.', 'et': 'Töös tutvustatakse Anlirika esitlust SIGTYP 2021 Shared Task on Robust Speaken Language Identifikatsiooni kohta. Ülesande eesmärk on luua tugev süsteem, mis üldistab hästi erinevates valdkondades ja kõnelejates. Koolitusandmed on piiratud ainult ühe valdkonnaga, kus keele kohta on valdavalt üks kõneleja, samas kui valideerimis- ja testiandmete näidised on saadud erinevatest andmekogumitest ja mitmest kõnelejast. Me eksperimenteerime närvisüsteemiga, mis koosneb tihedate, konvolutsiooniliste ja korduvate kihtide kombinatsioonist, mis on loodud paremaks üldistamiseks ja kõnelejate invariantsete representatsioonide saamiseks. Näitame, et ülesanne piiratud kujul (ilma välisandmeid kasutamata või valideerimiskomplekti näidistega rongikomplekti täiendamata) on endiselt keeruline. Meie parim valideerimisnäidistega täiendatud andmetele koolitatud süsteem saavutab katseandmete täpsuse 29,9%.', 'bn': 'এই পত্রিকাটি রোবাস্ট ভাষার পরিচিতিতে সিজিটিইয়াপি ২০১১-এর সামনে অ্যানিরিকার প্রদান করেছে। এই কাজের লক্ষ্য হচ্ছে একটি রোবস্ট সিস্টেম তৈরি করার যা ভিন্ন ডোমেন এবং ভাষাকারীদের সাথে ভালোভাবে সা প্রশিক্ষণের তথ্য একটি ডোমেইনের সীমাবদ্ধ, যেখানে প্রধান ভাষায় একক ভাষায় কথাবার্তা প্রতিটি ভাষায় সীমাবদ্ধ, যখন বৈধ ও পরীক্ষা তথ্যের আমরা একটি নিউরেল সিস্টেমের সাথে পরীক্ষা করছি যার মধ্যে গভীর, বিশ্বাসী এবং পুনরাবর্তন স্তরের একটি সংযোগ রয়েছে যা ভাল জেনারেলেশন এবং কথাবার্তা প আমরা দেখাচ্ছি যে তার নির্ধারিত ফর্মে কাজ (বাইরের তথ্য ব্যবহার করা বা প্রমাণ ব্যবহার করা ছাড়া ট্রেনের সেট থেকে নির্ধারণ করা ট্রেনের প্রত পরীক্ষার তথ্য সম্পর্কে ২৯. ৯% সঠিকভাবে প্রাপ্ত হয়েছে।', 'fi': 'Artikkeli esittelee Anlirikan esityksen SIGTYP 2021 Shared Task on Robust Spoken Language Identification -ohjelmaan. Tehtävän tavoitteena on rakentaa vahva järjestelmä, joka yleistyy hyvin eri toimialoilla ja puhujilla. Koulutustiedot rajoittuvat vain yhteen verkkotunnukseen, jossa on enimmäkseen yksi puhuja per kieli, kun taas validointi- ja testiaineistonäytteet on saatu erilaisista aineistoista ja useista puhujista. Kokeilemme hermojärjestelmää, joka koostuu tiheistä, konvolutionaalisista ja toistuvista kerroksista, jotka on suunniteltu suorittamaan parempi yleistyminen ja saamaan puhujien invariantteja representaatioita. Osoitamme, että tehtävä rajoitetussa muodossa (ilman ulkoista dataa tai lisäämättä junajoukkoa validointiryhmän näytteillä) on edelleen haastava. Paras järjestelmämme, joka on koulutettu validointinäytteillä täydennetyihin tietoihin, saavuttaa 29,9% tarkkuuden testitiedoissa.', 'jv': 'Gambar nganggo tresnani anlirika nang SiGT YP 2020 1 Sampeyan Taaksi nang daftar luwih dumadhi Awak dhéwé éntuk nggawe sistem sing gawe bot sing wis jajal padha saking pangrungan karo pangrungan. The tutorial data is limited to a single domain only with prelomently single Speaker/language when the Valdata and test data samples are generated from Varie dataset and Multiple Speakrs. Awak dhéwé éntuk karo sistem nêrasên sing sumunggadi tanggal teka, teka-teka lan soko nggawe barang sing dibenalke nggawe nguasakno luwih apik lan kelangan langgar-invariant. Awak dhéwé éntuk sistem sing ditambah-sistem sing gak nggawe Sistem-sistem sing ditambahak barêng-barêng ngenggo data ogwek diutag-barêng. Samsulan pangan sing nyimpen mrêt.9% kuwi wis dipatensak data seneng pisan.', 'sk': 'V prispevku je predstavljen Anlirikov prispevek k skupni nalogi SIGTYP 2021 o robustni identifikaciji govorjenega jezika. Cilj naloge je izgradnja robustnega sistema, ki se dobro posploši na različnih področjih in govornikih. Podatki o usposabljanju so omejeni na eno samo domeno s pretežno enim govornikom na jezik, medtem ko so vzorci podatkov o potrjevanju in testiranju pridobljeni iz različnih podatkovnih naborov in več govornikov. Eksperimentiramo z nevronskim sistemom, ki sestavlja kombinacijo gostih, konvolucijskih in ponavljajočih se plasti, ki so zasnovane za boljšo generalizacijo in pridobivanje invariantnih predstavitev govornikov. Dokazujemo, da je naloga v omejeni obliki (brez uporabe zunanjih podatkov ali povečanja kompleta vlakov z vzorci iz kompleta validacije) še vedno zahtevna. Naš najboljši sistem, usposobljen za podatke, dopolnjene z vzorci validacije, dosega 29,9% natančnost preskusnih podatkov.', 'ha': "Kanarin na bãyar da shirin Anlirika zuwa SiGTYP 2021 Kayan aiki yana aimar ka gina wani na'ura na'ura, wanda ke samu mai kyau a tsakanin sauran da masu saurãre. Ana ƙayyade data ga shirin ayuka zuwa guda guda kawai da ke da maiyyan mai magana guda kowace lugha a lokacin da za'a samar da misãlai masu inganci da jarraba data daga tsari daban-daban da masu sauya masu yawa. Tuna jarraba da wani na'urar neura wanda ke samun komai da sauri, masu bastarwa, da kuma da ƙananan da za'a iya iya lissafa da sauri wanda aka yi nufin su samar da mafi kyãwo da kuma za'a sami mataimakon-mai-faɗi. Tuna nũna cewa aikin da aka tsare shi (bã ya amfani da data masu baka ko kuma ba Mu ƙara jerin da aka daidaita misãlai daga daidaita da gaskiyar) yana ƙaranci. Tsarin da muka fi tsari a kan data da aka ƙara da misãlai masu inganci, yana sãmu 29.9% na daidaita kan data na jarraba.", 'he': "The paper presents Anlirika's submission to SIGTYP 2021 Shared Task on Robust Spoken Language Identification.  המשימה מתכוונת לבנות מערכת חזקה שמגנרליזת היטב בכל תחומות ורמקולים שונים. נתוני האימונים מוגבלים לתחום אחד בלבד עם רמקול אחד בעיקר לשפה, בעוד דגימות נתוני האימונים והבדיקות מוצאות ממערכת נתונים ומספר רמקולים. אנו מנסים עם מערכת עצבית שמכילה שילוב של שכבות צפופופות, משתנות, ומחזרות שנועדו כדי לבצע כלליזציה טובה יותר אנו מראים שהמשימה בצורה המוגבלת שלה (בלי להשתמש בנתונים חיצוניים או הגדילה את קבוצת הרכבת עם דגימות מהקבוצת האישור) עדיין מאתגרת. המערכת הטובה ביותר שלנו מאומנת על המידע המוגדל בדגימות אישור משיגה מדויקה 29.9% על המידע המבחן.", 'bo': 'ཤོག་བྱང་འདིས་ཨ་ལི་རིཀ་ལ་SIGTYP 2021 རྣམས་ཉར་འཛུགས་པའི་བྱ་རིམ་སྟོན་པ། བྱ་འགུལ་གྱི་དམིགས་ཡུལ་ནི་ཡིས་ཁྲོད་ཆེན་པོ་ཞིག་དང་སྐད་པོ་སྣང་མ་འདྲ་བར་བཟོ་བྱེད་རྒྱུ་ཡིན། The training data is limited to a single domain only with predominantly single speaker per language while the validation and test data samples are derived from various dataset and multiple speakers. ང་ཚོས་རང་ཉིད་ཀྱི་མ་ལག་ཅིག་གིས་སྦྱོར་སྡུད་པ། སྡུད་ཚོགས་དང་ ཡང་བསྐྱར་རིམ་མཐུན་ཡོད་པའི་བགོ་རིམ་དང་འཁྲིལ་སྤྱོད་མཁན ང་ཚོས་ཀྱིས་བྱ་འགུལ་ནང་དུ་གཏན་ཁེལ་བྱེད་པའི་རྩ་བ་ཡིག་ཆའི་ནང་དུ་བཀོད་སྟོན་བྱས། ང་ཚོའི་མ་ལག'}
